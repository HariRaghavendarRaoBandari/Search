Generalized Estimating Equations for Vector Regression

Alan Huang

University of Queensland

15 Feb, 2016

Abstract

6
1
0
2

 
r
a

M
1

 

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
8
1
1
0
0

.

3
0
6
1
:
v
i
X
r
a

Generalized estimating equations (GEE; Liang & Zeger, 1986) are extended to general vec-
tor regression settings. When the response vectors are of mixed type (e.g. continuous–binary
response pairs), the proposed method is a semiparametric alternative to full-likelihood copula
methods. When the response vectors are of the same type (e.g. physical measurements on left
and right eyes), the proposed approach can be viewed as a “plug-in” to existing methods, such
as the vglm function from the state-of-the-art vgam R package of Yee (2015). In either scenario,
the proposed approach offers accurate inferences on model parameters regardless of whether the
working model is correctly or incorrectly speciﬁed. The ﬁnite-sample performance of the pro-
posed method is assessed using simulation studies based on a burn injury dataset (Song, 2007)
and a sorbinil eye trial dataset (Rosner et. al, 2006). Simulation results are complemented by data
analysis examples using the same two datasets.
keywords: sandwich estimator of variance; vector regression

Introduction

1
The immense popularity of generalized estimating equations (GEE; Liang & Zeger, 1986) for lon-
gitudinal data analysis owes much to the fact that it can account for within-cluster correlations
without requiring correct speciﬁcation of the working variance-covariance structure. It achieves
this via the much-celebrated sandwich estimator of variance, which is consistent for the true vari-
ance matrix of the estimated parameters even when the assumed variance-correlation structure is
incorrectly speciﬁed. The application of GEEs to general vector regression problems is alluded to
in Song (2007, Chapter 6), but an explicit connection has yet not been made in the literature. This
note makes the connection explicit.

Vector regression shares many features with longitudinal data – both exhibit within-vector
correlations and independence across vectors. However, vector regression is distinct from the
longitudinal setup in two important ways:

1. Each vector component may be measurements on different types of variables. In general, we
may specify marginal generalized linear models for each component k of a response vector
Yi,

E(Yik|Xik) ≡ µik = µk(X T
Var(Yik|Xik) ≡ σ2

(1)
(2)
for some set of mean functions {µk} and some set of variance functions {Vk}. The parame-
ters βk ∈ Rpk and φk are the regression coefﬁcients and dispersion parameter, respectively,
for component k. The Xiks are the corresponding vectors of covariates for each component.

ikβk) ,
ik = φkVk(µik) ,

2. The within-vector correlation between two components Yik and Yik(cid:48),

Corr(Yik, Yik(cid:48)|Xi) = ρkk(cid:48)(γ; µik, µik(cid:48)) ,

(3)

may depend on a vector of correlation parameters γ as well as on the marginal means µik
and µik(cid:48).

1

To specify a GEE model for data, one needs to specify (1) a set of marginal mean models, (2)
a set of variance functions, and (3) a set of within-vector correlation functions. We illustrate this
with the following two examples.

Example 1 ((Continuous-binary data)). Song (2007) describes a dataset from Fan & Gijbels (1996)
containing 981 cases of burn injuries, with two response variables of mixed type for each subject. These are
severity of burns as measured by Y1 = log(burn area + 1) and disposition of death as measured by Y2 = 1
for death and 0 for survival. It is of interest to see whether severity of burns and probability of death is
related to age.

Burn severity is continuous and disposition of death is binary, so a sensible set of mean functions may

be

E(Y1|age) = µ1 = β10 + β11age ,
E(Y2|age) = µ2 =

exp(β20 + β21age)

1 + exp(β20 + β21age)

,

with a corresponding set of variance functions,

Var(Y1|age) = σ2 ,
Var(Y2|age) = µ2(1 − µ2) .
Here, the dispersion parameters are φ1 = σ2 and φ2 ≡ 1, respectively.

A naive assumption here would be that the severity of burns is uncorrelated with death status within

each individual,

Corr(Y1, Y2|age) = 0 ,

or that there is some general correlation,

Corr(Y1, Y2|age) = ρ , for some ρ ∈ (−1, 1) .

Perhaps a more realistic model here is to allow correlations to change with the marginal means. As we show
in Section 3, any reasonable working variance and correlation model can be used, with model misspeciﬁca-
tions being adjusted for using a sandwich estimator of variance.

Example 2 ((Bivariate data on a lattice)). Rosner et. al (2006) describes a dataset consisting of pairs of
itching scores (YL, YR) from left and right eyes of 41 subjects in a Sorbinil Retinopathy Trial. The scores
range from 0 (no itch at all) to 4 (severe incapacitating itch) in increments of 0.5. The active treatment was
sorbinil, which could be applied to both eyes, just the left eye, just the right eye, or to neither eye. The data
are displayed in Table 1 of Appendix A.

Both YL and YR are scores between 0 and 4 inclusive, so it may be sensible to model YL/4 and YR/4
as pseudo-Bernoulli (c.f. example 9.2.4 in McCullagh & Nelder, 1989), using a pair of logistic mean
functions,

E(YL/4| treatment) ≡ µL =
E(YR/4| treatment) ≡ µR =

exp [βL0 + βL1I(sorbinilL = 1)]

1 + exp [βL0 + βL1I(sorbinilL = 1)]
exp [βR0 + βR1I(sorbinilR = 1)]

1 + exp [βR0 + βR1I(sorbinilR = 1)]

,

,

where I(sorbinilL = 1) is an indicator for sorbinil treatment in the left eye, and similarly for I(sorbinilR =
1). A corresponding pair of working variance functions is

Var(YL/4|treatment) = φ µL (1 − µL)
Var(YR/4|treatment) = φ µR (1 − µR) .

Here, we have assumed equal dispersion in the two eyes, so that the dispersion parameters are φ1 = φ2 = φ.

A working correlation model for the within-subject dependence between the two eyes may be taken as

Corr(YL, YR|treatment) = ρ , for some ρ ∈ (−1, 1) .

Again, perhaps a more realistic model is to allow correlations to change with the marginal means, such
as that induced by the odds ratio model of Yee (2015), with potential misspeciﬁcations being adjusted for
using a sandwich estimator of variance.

2

The primary interest here is to estimate and make inferences on the treatment effect of sorbinil on
reducing eye irritation, but another interesting hypothesis to test would be if there is certain symmetry in
the two eyes, i.e., whether βL0 = βR0 and βL1 = βR1. We want to be able to make valid inferences without
having to correctly specify the within-subject dependence structure.

As is typical in regression problems, the primary interest is in estimating and carrying out joint
inferences on the regression parameters β = (βT
K)T . The variance–correlation struc-
ture itself is of secondary importance, coming into consideration when evaluating the sampling
variability of parameter estimates.

2 , . . . , βT

1 , βT

A key feature of the proposed approach is that the variance and correlation structures need
not be correctly-speciﬁed. As in the longitudinal setting of Liang & Zeger (1986), we ﬁnd in
Section 3 that the sandwich estimator of variance is consistent even if the working variances and
correlations are misspeciﬁed. Of course, the closer the working variance-correlation structure is
to the truth, the more efﬁcient and accurate the proposed framework tends to be for ﬁnite sample
sizes.

Remark 1. In the longitudinal framework, each component is a repeated measure of the same variable, so
that the mean and variance models (1) and (2) have the same form for each component. That is,

µ1(.) ≡ µ2(.) ≡ . . . ≡ µK(.) = µ(.),
β1 ≡ β2 ≡ . . . ≡ βK = β,
V1(.) ≡ V2(.) ≡ . . . ≡ VK(.) = V (.), φ1 ≡ φ2 ≡ . . . ≡ φK = φ.
Moreover, the correlations ρkk(cid:48) are typically functions of the correlation parameters γ only.

Remark 2. It is possible for some components to share mean parameters. Sometimes this may be due to
symmetry arguments (e.g. symmetry in left and right eyes) or other special structures in the data. This
can be thought of as a hybrid between the longitudinal setting and the general vector regression setting.

There are two main existing approaches to vector regression. The method of Song (2007,
Chapter 6) uses copula functions to combine marginal distributions with association structures to
construct full probability models for the data. However, the marginal distributions, association
structures and copula function are all implicitly assumed to be correctly-speciﬁed, and no adjust-
ment is available in the case of model misspeciﬁcation. The recent book from Yee (2015), which
accompanies the state-of-the-art R package, vgam, covers marginal models for vector GLMs that
are similar in aims to the current proposal. However, the function vglm for ﬁtting vector gener-
alized linear models currently cannot handle vectors of mixed type, such as continuous-binary
pairs. For vectors with components of the same type, our proposed approach can be viewed as a
simple “plug-in” to vglm, offering an adjustment to model-based standard errors in cases where
the working model is incorrectly speciﬁed. This typically involves just a few lines of code; an
example is given in Appendix B.2.

2 Estimation
Given a set of variance functions (2) and correlation functions (3), a working variance-covariance
matrix Wi ≡ Wi(β; γ; φ) for each observation i can be constructed via

Wi = Σ1/2

i RiΣ1/2

i

,

i1, σ2

i2, . . . , σ2

where Σi = diag(σ2
iK) is a diagonal matrix of the variances of each component of
Yi. = (Yi1, Yi2, . . . , YiK)T , and Ri is the correlation matrix induced by (3). Note that, unlike the
longitudinal case, dispersion parameters are generally included in the working covariance ma-
trices Wi. This is because each component may have different dispersion parameters that cannot
be factorised out. If a working independence correlation structure is used, however, then the
dispersion parameters drop out, as in the longitudinal setting.

1 , βT

2 , . . . , βT

K)T can be deﬁned as the solution to the set of generalized

An estimator of β = (βT

estimating equations,

0 =

i W −1
DT
i Si

n(cid:88)

i=1

3

where Si ≡ Si(β) = (Yi1 − µi1, Yi2 − µi2, . . . , YiK − µiK)T are the residuals and Di ≡ Di(β) =
{∂µik/∂βk(cid:48)}k,k(cid:48)=1,2,...,K is a matrix of derivatives. We iteratively solve for the regression coefﬁ-
cients and the correlation and dispersion parameters by alternating the following two steps.

Given current estimates ˆβ, ˆφ and ˆγ, an update for β can be obtained via Fisher scoring (c.f.

equation 8 in Liang & Zeger, 1986)

ˆβ(1) = ˆβ −

i ( ˆβ)W −1
DT

i

( ˆβ; ˆγ; ˆφ)Di( ˆβ)

i ( ˆβ)W −1
DT

i

( ˆβ; ˆγ; ˆφ)Si( ˆβ)

.

i=1

i=1

Conversely, given an estimate of β, consistent estimates of the dispersion φ and correlation γ
parameters can be obtained via method-of-moment approaches analogous to those from Section
4 of Liang & Zeger (1986). For example, in the general case where each component k has its own
dispersion parameter φk, we can estimate φk via

(cid:40) n(cid:88)

(cid:41)−1(cid:40) n(cid:88)

(cid:41)

For an unstructured working correlation model, R(α) = {αkk(cid:48)}k,k(cid:48)=1,2,...,K can be estimated via

ˆφ−1
k =

1

n − pk

(Yik − ˆµik)2
Vk(ˆµik)

,

k = 1, 2, . . . , K .

n(cid:88)

i=1

n(cid:88)

i=1

ˆR =

ˆφ
n

−1/2
i

SiST

−1/2
i Σ
i

Σ

.

Note that other popular correlation models from the longitudinal setting, such as exchangeable,
m-dependence, auto-regressive and band diagonal structures, are generally not applicable to vec-
tor regression because the indices of the vector components are exchangeable labels. Thus, the
working independence and unstructured correlation models are perhaps the only two generally
applicable working correlation structures for vector regression. Other dependence models, such
as the odds ratio model for bivariate binary regression of Yee (2015), will be speciﬁc to the prob-
lem at hand.

3 Main results
The following results are vector regression analogues of the results in Liang & Zeger (1986), con-
cerning the asymptotic normality of the GEE estimator and consistency of the sandwich estimator
for the asymptotic variance.
√
Result 1 (Asymptotic normality). Under conditions of Theorem 2 from Liang & Zeger (1986), we have
n( ˆβ − β∗) → N (0, Vβ), where

Vβ = lim

n→∞ n

i W −1
DT

i Di

i W −1
DT

i

cov(Yi)W −1

i Di

i=1
Result 2 (Sandwich estimator of variance). Vβ can consistently estimated by

(cid:32) n(cid:88)
(cid:32) n(cid:88)

i=1

(cid:33)−1(cid:40) n(cid:88)
(cid:33)−1(cid:40) n(cid:88)

i=1

(cid:33)−1

.

(cid:41)(cid:32) n(cid:88)
(cid:41)(cid:32) n(cid:88)

i Di

i W −1
DT
(cid:33)−1

ˆVβ = n

ˆDT
i

ˆW −1

i

ˆDi

ˆDT
i

ˆW −1

i

ˆSi ˆST
i

ˆW −1

i

ˆDi

ˆDT
i

ˆW −1

i

ˆDi

,

i=1

i=1

i=1

where ˆDi = Di( ˆβ), ˆSi = Si( ˆβ), and ˆWi = Wi( ˆβ; ˆγ; ˆφ) are the plug-in estimators.
Results 1 and 2 can be combined to carry out joint inferences on regression coefﬁcients, as pre-
scribed in Result 3 below.
Result 3 (Joint inferences). Under the null hypothesis H0 : M β = δ, where M is a given r × p matrix
of full rank and δ a given vector, the quadratic form

(M ˆβ − δ)T(cid:16)

M ˆVβM T(cid:17)−1

(M ˆβ − δ)

F =

n
r

has an approximate Fr,n−p distribution for large n, where p = p1 + p2 + . . . + pK is the total number of
regression parameters.

4

4 Simulations
To assess the ﬁnite-sample accuracy of our asymptotic results, we carry out two sets of simula-
tions, one based on the continuous-binary burn injury dataset from Example 1 and the other on
the bivariate lattice sorbinil eye trial dataset from Example 2.

4.1 Burn injury simulations
To generate each dataset, we ﬁrst sample n = 200 ages from the 981 original observations, then,
conditional on the ages, we generate burn severity Y1 and incidence of death Y2 via the hierarchi-
cal model of Fitzmaurice & Laird (1995),

Y2|age ∼ Bernoulli{µ2} , where µ2 =

Y1|age, Y2 ∼ N(cid:8)6.6980 + 0.0039 age + γ(Y2 − µ2), 1.262(cid:9) ,

exp(−4.0521 + 0.0527 age)
1 + exp(−4.0521 + 0.0527 age)

,

By generating Y1 conditional on Y2, we induce within-vector correlation for each subject, with the
parameter γ controlling the strength of this correlation. Here, we set γ = 5. The parameter values
are taken from the ﬁtted model to the original dataset, so as to emulate the original values. We
repeat this procedure to generate 1,000 datasets.

For each synthetic dataset, we ﬁt the GEE model from Example 1 with the working indepen-
dence assumption, computing the GEE estimate of β along with its estimated variance matrix
using the sandwich estimator from Result 2. Note that the marginal variance function for Y1
is misspeciﬁed, along with the working independence assumption. It is in such cases where a
robust adjustment to the variances might be invaluable. The code for computing the sandwich
adjustment is particularly simple and provided in Appendix B.1.
To assess the accuracy of the proposed robust variance estimator ˆVβ prescribed in Result 2,
we compute the matrix 1-norm (cid:107) ˆVβ − Vβ(cid:107)1 for each simulation, where Vβ is the empirical “true”
variance across our simulations. We also examine the estimation accuracy for the precision ma-
trix, V −1
β , which is arguably more pertinent for inferences than the variance. For each simulation,
we compute the analogous matrix norm (cid:107) ˆV −1
β (cid:107)1. The results are summarised in Table 1.
We see that the sandwich adjustment is offering much improved performance in estimating
both the variance and precision matrices, with the improvement becoming more pronounced
when the sample size increases. Note that the unadjusted precision estimator actually diverges
with increasing sample size, which leads to biased inferences on the regression parameters.
Indeed, the Type 1 errors (see columns 3–5 in Table 1) for jointly testing the true parameter
values H0 : β10 = 6.6980, β11 = 0.0039, β20 = −4.0521 and β21 = 0.0527 are seen to be severely
biased when the unadjusted variances are used. In contrast, inferences using the adjusted vari-
ances have Type I error rates that are much closer to their nominal levels. These tests were carried
out using the F-test from Result 3, calibrated against the F-distribution with 4 and n − 4 degrees
of freedoms.

β − V −1

Table 1: Burn injury simulations – mean accuracy of the sandwich estimator for the variance (Vβ) and precision (V −1
β )
matrices, and Type I errors for jointly testing all model parameters at nominal 1%, 5% and 10% levels. N = 1000
simulations each with sample sizes of n = 200, 400 and 800.

variance
Type I errors
estimator variance precision 1% 5% 10%
3.8 11.3 17.1
1.9 7.2 13.2
3.7 10.1 15.4
1.4 6.0 11.3
3.1 9.1 13.4
0.9 5.1
9.7

1425.1
418.1
1555.0
281.4
1573.6
194.4

n = 200 unadjusted
adjusted
n = 400 unadjusted
adjusted
n = 800 unadjusted
adjusted

accuracy

40.6
28.3
30.7
17.7
26.2
12.5

5

4.2 Sorbinil eye trial simulations
We also examine the ﬁnite-sample accuracy of Result 3 using simulations based on the sorbinil eye
trial from Example 2. To emulate the original dataset from Rosner et. al (2006), we ﬁrst simulate
values from Binomial distributions with 8 trials and then divide by 2, thereby generating data
that take value only in {0, 0.5, 1, 1.5, . . . , 3.5, 4}. Speciﬁcally, each data pair is given by YL =
j=1 BRj, where (BLj, BRj), j = 1, 2, . . . , 8, are correlated bivariate

j=1 BLj and YR = 0.5(cid:80)8

0.5(cid:80)8

binary pairs generated from a random intercept and slope model,

BLj|treatment, α0, α1 ∼ Bernoulli{expit [0.303 + α0 + (−0.444 + α1)I(sorbinilL = 1)]}
BRj|treatment, α0, α1 ∼ Bernoulli{expit [0.303 + α0 + (−0.444 + α1)I(sorbinilR = 1)]} .

Here, the random intercept α0 ∼ N (0, 0.22) is independent of the random slope α1 ∼ N (0, 0.22),
and expit[·] = exp(·)/(1 + exp(·)). Thus, the baseline itchiness of 0.303 and treatment effect of
sorbinil of 0.444 are the same for both left and right eyes, with correlation between eyes induced
by the random effects terms α0 and α1. The parameter values were taken from a ﬁtted model to
the original dataset, so as to emulate the original values. We repeat this procedure to generate
5,000 datasets, each with n = 41 observations, preserving the design of the original study.
We analyze each simulated dataset using the GEE model from Example 2, with the work-
ing correlation either set to 0 exactly (working independence) or left unspeciﬁed in (−1, 1). We
also consider the constant odds ratio model of Yee (2015), which characterises the dependence
between individual bivariate binary responses (BL, BR) via

P (BL = 1, BR = 1) P (BL = 0, BR = 0)
P (BL = 0, BR = 1) P (BL = 1, BR = 0)

= eγ .

This induces a within-vector correlation between the two eyes of the form

Corr(BL, BR) =

p11(γ; µL, µR) − µLµR

(cid:112)µL(1 − µL) µR(1 − µR)

,

where p11(γ; µL, µR) is the solution to p11(1−µL−µR +p11) = (µL−p11)(µR−p11)eγ. Note that the
working variance functions and the correlation structures are all misspeciﬁed in the three models
considered here. It is in such situations where a sandwich adjustment may prove to be invaluable.
In particular, for the third model, the proposed approach can be viewed as a “plug-in” to the
vglm function from the vgam R package of Yee (2015), offering a robust post-ﬁtting adjustment
to the standard errors and variances in case the assumed model is misspeciﬁed. The code for
performing this post-ﬁtting adjustment is particularly simple and is provided in Appendix B.2.
The structure of the data leads us naturally to test for symmetry in the two eyes, i.e., H0 :
βL0 = βR0 and βL1 = βR1. We can do this using the F-test prescribed in Result 3, with M being
the 2 × 4 matrix of contrasts,

(cid:18)1 0 −1

0 1

M =

(cid:19)

0
0 −1

,

δ = (0, 0)T , and ˆVβ an estimate of the variance using either the unadjusted model-based variance
estimator, or the sandwich-adjusted variance estimator from Result 2 of Section 3. We compare
this statistic to an F distribution with 2 and 37 degrees-of-freedoms.

The Type I errors from 5000 simulations for testing for symmetry are given in Table 2. We see
that, even for small sample sizes of n = 41, the accuracy of joint inferences show a signiﬁcant
improvement after the sandwich adjustment, regardless of the working correlation model. In
contrast, the Type I errors using the naive variance estimator are consistently biased under model
misspeciﬁcations, and are particularly sensitive to the working correlation.

Table 2: Eye study simulations – Type I errors (%) for testing symmetry at nominal 10%, 5% and 1% levels using unad-
justed and sandwich-adjusted estimates of variance. N = 5000 simulations each with sample size n = 41.

unadjusted

adjusted

working correlation 10% 5% 1% 10% 5% 1%
5.3 2.0 0.1 10.6 5.3 0.9
6.9 3.8 0.7 10.2 5.8 1.2
8.9 4.1 0.8
7.4 3.2 0.5

independence
unspeciﬁed
odds ratio

6

5 Data analysis examples

5.1 Burn injury data
As mentioned in the introduction, there aren’t many models that can handle continuous-binary
response pairs. The method of Fitzmaurice & Laird (1995) is useful when it is sensible to think of
the continuous response being generated conditional on the binary response. However, here it is
perhaps more tenable to think of incidence of death as being conditional on burn severity, and not
vice versa. If we had observed the two variables separately, we would have ﬁtted two indepen-
dent models to the data. This corresponds to the GEE model from Example 1 with the working
independence correlation model. The proposed sandwich correction from Result 2 allows us to
adjust for within-subject correlations post-ﬁtting.

The ﬁtted marginal mean models using this GEE are

ˆE(burn severity| age) = 6.7118 + 0.0035 age ,

ˆP (death| age) =

exp(−3.6891 + 0.0508 age)
1 + exp(−3.6891 + 0.0508 age)

,

with the robust standard errors of the slopes estimated as se( ˆβ11) = 0.0017 and se( ˆβ21) = 0.0051,
respectively. We can conclude that age has signiﬁcant marginal relationships with both burn
severity and risk of death.
incidence of death. By inverting the F-test of Result 3, with

More interesting, perhaps, than marginal effects is the joint effect of age on burn severity and

(cid:18)0 1 0 0
(cid:19)

0 0 0 1

M =

and various values of δ, we can obtain joint conﬁdence regions for the two slopes β11 and β21.
For example, the 95% and 99% joint conﬁdence regions using the adjusted (solid) and unadjusted
(dashed) variances are displayed in Figure 1. In contrast to the unadjusted conﬁdence regions,
the adjusted regions place little conﬁdence in the top left or bottom right quadrants, indicating
that it is not plausible for age to have a strong relationship with burn severity without also having
a strong relationship with incidence of death, or vice versa.

Figure 1: Burn injury data – joint 95% and 99% adjusted (solid) and unadjusted (dashed) conﬁdence regions for the
slopes in age.

5.2 Sorbinil eye trial data
To analyze the sorbinil eye trial dataset from Rosner et. al (2006), we ﬁt the GEE model from
Example 2 with an unspeciﬁed correlation. The nature of the data leads us to test whether the
model can be simpliﬁed to one that is symmetric in the two eyes, that is, whether β10 = β20 and
β11 = β21. Using Result 3, the F statistic for this test is 0.91 on 2 and 37 degrees of freedom, giving
a p-value of 0.41. A symmetric model is therefore acceptable.

7

b11b21 95  99  95  99 0.0000.0020.0040.0060.040.050.06Joint confidence regions for the slopes in ageIn addition to symmetry considerations, the nature of the data also leads us to ask whether
there may be an interference effect – that is, does the treatment applied to one eye affect the re-
sponse in the other eye? It is plausible to think that the application of treatment simultaneously
to both eyes may have an effect on each eye that is different to the effect of treatment in isolation.
For this dataset, the estimated interference effect is 0.018, with a robust standard error of 0.162.
There is no evidence of interference here.
The ﬁnal ﬁtted model is summarized in Table 3. We see that sorbinil treatment is associated
with an estimated reduction in the itchiness score from 4×expit(0.303) = 2.30 to 4×expit(0.303−
0.444) = 1.86 on the original scale. This reduction is highly signiﬁcant, with an associated p-value
of P (T39 ≤ −3.42) = 7.5 × 10−4.

Table 3: Sorbinil eye trial dataset – estimated coefﬁcients, naive and robust standard errors and z-scores

Coefﬁcient Estimate Naive SE Robust SE Robust z
2.95
Intercept
Sorbinil
-3.42

0.303
-0.444

0.129
0.144

0.103
0.130

6 Discussion
The connection between GEEs and general vector regression made in this paper extends beyond
the bivariate cases considered here. The proposed framework will be particularly useful for re-
sponse vectors with three or more components, perhaps of mixed variable types, where the difﬁ-
culty in specifying appropriate joint distributions hinders existing methods. For response vectors
with components of the same type, the proposed method can be implemented as a “plug-in” to
existing methods, such as the vglm function in the vgam package of Yee (2015).

Acknowledgements
The author thanks Thomas Yee and Paul. J. Rathouz for comments that improved the paper.

Bibliography

Fan, J. and Gijbels, I. (1996) Local polynomial modelling and its applications. London: Chapman and Hall.

Fitzmaurice, G. M. and Laird, N. M. (1995) ’Regression Models for a Bivariate Discrete and Continuous

Outcome with Clustering’, Journal of the American Statistical Association, 90, 845–852.

Liang, K-L. and Zeger, S. (1986) ’Longitduinal data analysis using generalized linear models’, Biometrika,

73, 13–22.

McCullagh, P. and Nelder, J. A. (1989) Generalized Linear Models. 2nd edition. London: Chapman and Hall.

Rosner, B., Glynn, R. J., and Lee, M-L. T. (2006) ’Extension of the Rank Sum Test for Clustered Data: Two-
Group Comparisons with Group Membership Deﬁned at the Subunit Level’, Biometrics, 62, 1251–1259.

Song, P. X-K. (2007) Correlated data analysis: modeling, analytics and applications. Springer Series in Statistics.

Yee, T. W. (2015) Vector generalized linear and additive models. Springer Series in Statistics.

8

A Sorbinil trial dataset
Table 4 goes here.

Table 4: Sorbinil trial data – itching scores in left and right eyes by treatment group, from Rosner et. al (2006)

Treatment combination

sorbinil placebo

placebo placebo

left
1.0
2.0
3.0
2.0
3.0
2.0
3.0
0.5
3.0
3.0
3.0
1.0
1.0
1.5

right
1.5
2.5
1.0
3.0
2.5
3.0
3.0
1.5
3.0
3.0
3.0
2.0
2.0
2.5

placebo sorbinil
right
2.0
2.5
3.0
2.0
0.5
0.0
2.5
1.0
1.5
0.0
1.5
2.0
2.5
2.5

left
2.5
2.5
3.0
2.5
1.0
2.0
3.0
3.0
2.0
0.5
2.5
2.0
2.5
2.5

sorbinil sorbinil
right
2.0
1.0
2.0
1.0
2.5
2.5

left
2.0
1.0
0.5
2.5
3.0
2.0

left
3.0
2.0
2.5
1.0
2.0
2.0
2.0

right
3.0
3.0
2.5
3.0
2.5
1.0
2.0

B R Codes

B.1 GEE for continuous-binary pairs with working independence
# fit independent models for each component
fit1 = glm(y1˜X1)
fit2 = glm(y2˜X2, family = quasibinomial)

# fitted values
mu1 = fit1$fitted
mu2 = fit2$fitted

# working variances
W1 = rep(summary(fit1)$disp, n)
W2 = summary(fit2)$disp*mu2*(1-mu2)

# model-based variance-covariance matrix
naive.vcov = bdiag(summary(fit1)$cov.scaled, summary(fit2)$cov.scaled)

# compute sandwich estimator of variance
meat = 0
for (i in 1:n){

Di = bdiag(model.matrix(fit1)[i,],(mu2[i]-mu2[i]ˆ2)*model.matrix(fit2)[i,])
Wi.inv = diag(c(1/W1[i], 1/W2[i]))
Si = rbind(y1[i] - mu1[i], y2[i]-mu2[i])
meat = meat + Di%*%Wi.inv%*%Si%*%t(Si)%*%Wi.inv%*%t(Di)

}
robust.vcov = naive.cov%*%meat%*%naive.cov

B.2 A “plug-in” to vglm
library(vgam); library(Matrix)

# fit bivariate binary model to sorbinil eye trial data using vglm
fit = vglm(cbind(BL, BR) ˜ sorbinil, family=binom2.or,

xij = list(sorbinil ˜ sorbinil.l + sorbinil.r + fill1(sorbinil.l)),

9

form2 = ˜ sorbinil + sorbinil.l + sorbinil.r + fill1(sorbinil.l))

naive.vcov = vcov(fit)[c(1,4,2,5), c(1,4,2,5)]
# note that the order of terms outputted from vglm is:
# intercept1, intercept2, gamma, slope11, slope21, slope12, slope22,...
# which differs from our order, which is:
# intercept1, slope11, slope12,..., intercept2, slope21, slope22,...

# fitted marginal probabilities
mu1 = apply(fitted(fit)[,c(3,4)], 1, sum)
mu2 = apply(fitted(fit)[,c(2,4)], 1, sum)

# sandwich estimator of variance
meat = 0 ;
bread = 0
for (i in n){

p11 = fitted(fit)[i,4]
Wi = rbind(c(mu1[i]*(1-mu1[i]),

p11-mu2[i]*mu2[i]),
c(p11-mu1[i]*mu2[i], mu2[i]*(1-mu2[i])))

Di = bdiag(mu1[i]*(1-mu1[i])*cbind(1, sorbinil.l[i]),
mu2[i]*(1-mu2[i])*cbind(1, sorbinil.r[i]))

Si = rbind(y1[i] - mu1[i], y2[i] - mu2[i])
meat = meat + t(Di)%*%solve(Wi)%*%Si%*%t(Si)%*%solve(Wi)%*%Di
bread = bread + t(Di)%*%solve(Wi)%*%Di

}
robust.vcov = solve(bread)%*%(meat/8)%*%solve(bread)
# divide by 8 as each itchiness score is derived from 8 individual Binary scores

10

