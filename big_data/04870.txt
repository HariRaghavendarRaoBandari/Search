6
1
0
2

 
r
a

M
 
7
1

 
 
]

.

A
N
h
t
a
m

[
 
 

2
v
0
7
8
4
0

.

3
0
6
1
:
v
i
X
r
a

An Adaptive Finite Element Method in Quantitative

Reconstruction of Small Inclusions from Limited

Observations

John Bondestam Malmberg ∗

Larisa Beilina †

March 18, 2016

Abstract

We consider a coeﬃcient inverse problem for the dielectric permittivity in Maxwell’s
equations, with data consisting of boundary measurements of one or two backscattered or
transmitted waves. The problem is treated using a Lagrangian approach to the minimization
of a Tikhonov functional, where an adaptive ﬁnite element method forms the basis of the
computations. A new a posteriori error estimate for the coeﬃcient is derived. The method
is tested successfully in numerical experiments for the reconstruction of two, three, and four
small inclusions with low contrast, as well as the reconstruction of a superposition of two
Gaussian functions.

1

Introduction

In this note we study an adaptive ﬁnite element method for the reconstruction of a dielectric

permittivity function ε = ε(x), x = (x1, x2, x3) ∈ Ω, where Ω ⊂ R3 is a bounded domain

with (piecewise) smooth boundary Γ. We consider data consisting of boundary measurements
of a small number (one or two) backscattered or transmitted waves. This is a coeﬃcient inverse
problem (CIP) for Maxwell’s equations, where the dielectric permittivity function ε, acting as
the coeﬃcient in the equations, characterizes an inhomogeneous, isotropic, non-magnetic, non-
conductive medium in Ω. Although we are in this note concerned with the reconstruction of
a real-valued coeﬃcient ε, our future applications are, eventually, in medical imaging, such as
microwave imaging of breast cancer, and early diagnosis of stroke (see [1–4] for details).

The method studied is based on a Lagrangian approach to the minimization of a Tikhonov
functional, where the functions involved are approximated by piecewise polynomials in a ﬁnite
element method. Such an approach to coeﬃcient inverse problems of the type we consider has
previously been studied extensively in the context of a two-stage procedure in [5–8]. The main
application considered in those publications was detection of explosives. With such applications,
the low amount of data one can expect – usually only backscattered data for a single incident
wave of one frequency – makes the problem of reconstruction challenging.
In the context of
medical imaging, it is possible to gather more data, and the challenges are instead low contrast

∗Department of Mathematical Sciences, Chalmers University of Technology and Gothenburg University, SE-
†Department of Mathematical Sciences, Chalmers University of Technology and Gothenburg University, SE-

42196 Gothenburg, Sweden, e-mail: john.bondestam.malmberg@chalmers.se

42196 Gothenburg, Sweden, e-mail: larisa@chalmers.se

1

between healthy and non-healthy tissue (seldom larger than 2 in microwave imaging of malign
tumors, see for example [9]), and small size of inclusions.

In the theoretical part of this paper, we derive a new, direct a posteriori error estimate for the
dielectric permittivity function to be reconstructed. Qualitative computable, or a posteriori, error
estimates are an essential tool for ﬁnite element based adaptive algorithms in the optimization
approach to our inverse problem. Previously, in [5], such an estimate was given for our coeﬃcient
inverse problem. However, this estimate was an indirect one, estimating the size of an error in the
computed Lagrangian, as apposed to a direct estimate of the error in the computed permittivity
as presented here. A similar estimate, also in the computed Lagrangian, was shown for a modiﬁed
Maxwell system in [10].

We illustrate our theoretical results with several numerical examples. With the above-
mentioned aspects of contrast and size of inclusions in mind, we present reconstructions of two,
three, and four diﬀerent small inclusions, respectively, of low contrast. We also evaluate how
variations in the type of data collected aﬀect the reconstruction. More precisely, we consider the
eﬀect of working with only backscattered data, with only transmitted data, with both backscat-
tered and transmitted data, as well as backscattered data from two anti-parallel incident waves.
In addition to these reconstructions of inclusions, we also present a reconstruction of a more
complicated function, to wit, a superposition of two gaussians.

Here is an outline of the remaining part of this note: In the Section 2 we present the math-
ematical formulations of the direct and inverse problems and present the basic results prior to
discretization of the problems. In Section 3 we state the ﬁnite element formulations, perform the
error analysis, and summarize the results in terms of a mesh reﬁnement strategy. The adaptive
algorithm for solving the inverse problem is described in Section 4, and numerical examples are
given in Section 5. Section 6 concludes the paper.

2 The direct and inverse problems

Before proceeding with the mathematical statement of the problem, we introduce some notation.

For the bounded polygonal domain Ω ⊂ R3 with boundary Γ, we write ΩT := Ω × (0, T ) and
ΓT := Γ× (0, T ), where T > 0 is a (suﬃciently large) ﬁxed time. If X ⊂ Rn, n ∈ N, is a domain,
we denote by (cid:104)·, ·(cid:105)X and (cid:107)·(cid:107)X the L2-inner product and norm, respectively, over the domain X.

Let

In the spirit of [6], we deﬁne a ﬁnite dimensional subspace of piecewise linears

0 := {v ∈ C( ¯Ω) : ∇v ∈ [L∞(Ω)]3}.
V ε

V ε := {v ∈ V ε

0 : v|K ∈ P 1(K)∀K ∈ Tδ},

where Tδ = {K} is a very ﬁne triangulation of ¯Ω and P 1(K) denotes the set of polynomials of
degree no greater than 1 over K. We equip this space with the L2-norm over Ω, and deﬁne the
set of admissible dielectric permittivity functions

(1)

U ε := {v ∈ V ε : 1 ≤ v(x) ≤ εmax ∀x ∈ Ω, v|Γ ≡ 1, ∇v|Γ ≡ 0}

for some known but not necessarily small upper bound εmax. The space V ε can be thought of
as a very ﬁne ﬁnite element space (see Section 3), hence it is of (large but) ﬁnite dimension,
which justiﬁes the use of the L2-norm. Although ﬁnite dimensional, this space is considered too
large to handle numerically, and our goal is to approximate ε ∈ V ε by an element of a smaller
subspace.
The set U ε is deﬁned to describe a heterogeneous medium in Ω, immersed in a constant

background with permittivity 1 in R3 \ Ω.

2

Under the assumption that ε ∈ U ε we consider Maxwell’s equations for an isotropic, non-

magnetic, non-conductive medium in Ω:

(2)

(3)

(4)

∂(µH)

+ ∇ × E = 0
∂t
∂(εE)
∂t − ∇ × H = 0
∇ · (µH) = ∇ · (εE) = 0

in ΩT ,

in ΩT ,

in ΩT ,

where H = H(x, t) and E = E(x, t), (x, t) ∈ ΩT , denote the magnetic and electric ﬁelds,
respectively, and µ > 0 is the constant magnetic permeability. By scaling, we may assume that
µ = 1.

To obtain an equation involving only ε and E, we combine the curl of (2) and derivative of

(3) with respect to t to obtain the second order equation

ε

∂2E
∂t2 + ∇ × (∇ × E) = 0

in ΩT .

To incorporate (4) we introduce a penalty term −s∇(∇· (εE)), for a ﬁxed gauge parameter s ≥ 1
(see details in [11, 12]), thus, after completing with boundary and initial conditions, we obtain
the system

(5)

ε

= P

∂2E
∂t2 − ∆E + ∇(∇ · E) − s∇(∇ · (εE)) = 0
∂E
∂n
E(·, 0) =

(·, 0) = 0

∂E
∂t

in ΩT ,

on ΓT ,

in Ω,

where we have used the expansion ∇×(∇×E) = −∆E+∇(∇·E) to simplify further manipulations
of the equation. We use the notation ∂
∂n = n · ∇, where n denotes the outward unit normal on
Γ. P ∈ [L2(ΓT )]3 is given Neumann data (see Section 4 of [7] for details). For well-posedness of
problems of this class, we refer to [13, 14].

The mathematical statement of the coeﬃcient inverse problem is:

Problem 1. Given time-resolved boundary observations G ∈ [L2(ΓT )]3 of the electric ﬁeld,
determine ε ∈ U ε such that E = G on ΓT .

The observations G represents either experimental or (partially) simulated data. For details

on how to obtain such data, see [7].

Inverse problems, such as Problem 1, are typically ill-posed in nature. Thus we cannot expect
to be able to ﬁnd an exact unique solution for any given data G (which in practice will contain
noise). Instead we will follow the concept of regularization (see for instance [15, 16]) and assume
that the given data G is a perturbation of ideal data G∗, for which there exists a unique solution
ε∗ to Problem 1. The goal is then to systematically compute an approximation of ε∗, a so-called
regularized solution which hereafter will be denoted simply by ε, which is as close to ε∗ as can
be achieved given the level of noise (cid:107)G − G∗
. Such a regularized solution is obtained by

minimizing a Tikhonov functional, to be deﬁned below (see equation (7)).

(cid:107)ΓT

Uniqueness of the solution of coeﬃcient inverse problems of this type is typically obtained
via the method of Carleman estimates [17]. Examples where this method is applied to inverse
problems for Maxwell’s equations can be found in, for example, [18], [19] for simultaneous recon-
struction of two coeﬃcients, and [20, 21] for bi-isotropic and anisotropic media. However, this

3

technique requires non-vanishing initial conditions for the underlying partial diﬀerential equa-
tion, which is not the case here. Thus, currently, uniqueness of the solution for the problem we
study is not known. For the purpose of this work, we will assume that uniqueness holds. This
assumption is justiﬁed by the numerical reconstruction results presented in the experimental
works [7, 8].

We introduce the space

for solutions to the direct problem, and

V dir := {v ∈ [H 1(ΩT )]3 : v(·, 0) = 0}

V adj := {v ∈ [H 1(ΩT )]3 : v(·, T ) = 0}

for adjoint solutions. Both spaces are equipped with the usual norm and inner product on
[H 1(ΩT )]3. Then, by multiplying the ﬁrst equation in (5) by a test function φ ∈ V adj and
integration over ΩT , we obtain, after integration by parts,

0 = −

∂t , ∂φ
ε ∂E

∂t

ΩT

+(cid:10)ε ∂E
∂t (·, T ), φ(·, T )(cid:11)
(cid:10) ∂E
∂n , φ(cid:11)

(cid:10)ε ∂E
∂t (·, 0), φ(·, 0)(cid:11)

Ω

Ω −

+ (cid:104)∇ · E, n · φ(cid:105)ΓT

(cid:68)

(cid:68)

(cid:69)

(cid:69)

(6)

+ (cid:104)∇E, ∇φ(cid:105)ΩT −
+ s(cid:104)∇ · (εE), ∇ · φ(cid:105)ΩT − s(cid:104)∇ · (εE), n · φ(cid:105)ΓT

ΓT − (cid:104)∇ · E, ∇ · φ(cid:105)ΩT

= −

∂t , ∂φ
ε ∂E

∂t

+ (cid:104)∇E, ∇φ(cid:105)ΩT − (cid:104)∇ · E, ∇ · φ(cid:105)ΩT

ΩT

+ s(cid:104)∇ · (εE), ∇ · φ(cid:105)ΩT − (cid:104)P, φ(cid:105)ΓT

=: D(ε, E, φ),

where the second equality holds because φ(·, T ) = 0, ∂E
∇ · (εE) = 0 on ΓT . This leads to the following weak description of the electric ﬁeld:
Problem 2. Given ε ∈ U ε, determine E ∈ V dir such that D(ε, E, φ) = 0 for every φ ∈ V adj.
Let Eε ∈ V dir denote the solution to Problem 2 for a given ε ∈ U ε. We can then deﬁne the
Tikhonov functional F : U ε → R+,

∂n = P on ΓT , and ∇ · E =

∂t (·, 0) = 0, ∂E

(7)

F (ε) = F (ε, Eε) :=

1

2 (cid:107)(Eε − G)zδ(cid:107)2

ΓT

+

α

2 (cid:107)ε − ε0(cid:107)2
Ω ,

where α > 0 is a regularization parameter and zδ = zδ(t) ∈ C∞([0, T ]) is a cut-oﬀ function for
the data, dropping from a constant level of 1 to a constant level of 0 within the small interval
(T − δ, T − δ/2), 0 < δ (cid:28) T , as schematically shown in Figure 1. The function zδ is introduced
to ensure data compatibility in the adjoint problem arising in the minimization of (7).
How to choose the regularization parameter α with respect to the level of noise in the data
is a widely studied topic. Several methods exist, examples are the (generalized) discrepancy
principle [16] and iterative methods [22]. In future studies, we are planning to investigate iterative
methods, similarly with [23]. However, for the results presented here, we regard α as a ﬁxed
parameter.
We assume that the initial approximation ε0 is suﬃciently close to an ideal solution ε∗,
corresponding to noiseless data G∗ in Problem 1. If so, then by Theorem 3.1 of [6], the Tikhonov

4

Figure 1: Schematic illustration of the cut-oﬀ function zδ appearing in the Tikhonov functional
(7).

functional F is strongly convex in a neighborhood N ⊂ V ε of ε0. More precisely, we have the
estimate

(8)

α

2 (cid:107)ε1 − ε2(cid:107)2

Ω ≤ F (cid:48)(ε1; ε1 − ε2) − F (cid:48)(ε2; ε1 − ε2)

for every ε1, ε2 ∈ N ∩ U ε, where F (cid:48)(ε; ¯ε) denotes the Fr´echet derivative of F at ε, acting on ¯ε.
Throughout the remaining part of this text we will assume that the hypothesis of Theorem 3.1
of [6], and hence strong convexity, holds. Then we may seek a minimizer ε ∈ U ε of F by applying
any gradient based method (such as steepest descent, quasi-Newton, or conjugate gradient),
starting from ε0.

Such an approach requires that we compute the Fr´echet derivative of F , which is complicated
since it involves the implicit dependence of Eε upon ε. To simplify the analysis, in the spirit of
optimal control (see for example [24, 25] for the general theory and some speciﬁc examples), we
introduce the Lagrangian associated to the problem of minimizing F (ε, E), ε ∈ U ε, E ∈ V dir,
with D(ε, E, φ) = 0 for all φ ∈ V adj acting as a constraint. This Lagrangian is

L(u) := F (ε, E) + D(ε, E, λ),

where u = (ε, E, λ) ∈ U := U ε × V dir × V adj ⊂ V := V ε × V dir × V adj, F (ε, E) was deﬁned in
(7), and D(ε, E, λ) was deﬁned in (6).
We can now minimize F over U ε by ﬁnding a stationary point of L over U . With the strong

convexity as above, this would imply that we solve

Problem 3. Find u ∈ U such that L(cid:48)(u; v) = 0 for every v ∈ V .

Again we use the notation L(cid:48)(u; v) for the Fr´echet derivative of L at u, acting on v. It can

be shown that

L(cid:48)(u; v) =

∂L
∂ε

(u; ¯ε) +

∂L
∂E

(u; ¯E) +

∂L
∂λ

(u; ¯λ),

5

tTT−δzδ(t)1T−δ2∂t , ¯ε(cid:11)
(cid:10) ∂E
where u = (ε, E, λ) ∈ U , v = (¯ε, ¯E, ¯λ) ∈ V , and
(cid:68)
(cid:69)
(u; ¯E) :=(cid:10)(E − G)z2
δ , ¯E(cid:11)
∂t · ∂λ
∇ · λ, ∇ · (ε ¯E)(cid:11) =: A (ε, λ, ¯E),
+ s(cid:10)
(cid:10)
∇ · λ, ∇ · ¯E(cid:11)
∂t , ∂ ¯E
ε ∂λ
ΓT −

∇λ, ∇ ¯E(cid:11)

(u; ¯ε) := α(cid:104)ε − ε0, ¯ε(cid:105)Ω −

+ s(cid:104)∇ · λ, ∇ · (¯εE)(cid:105) ,

∂L
∂ε
∂L
∂E

+(cid:10)

−

(9)

ΩT

∂t

ΩT

ΩT

∂L
∂λ

(u; ¯λ) = D(ε, E, ¯λ).

ΩT

In particular, we note that the solution u = (ε, E, λ) to Problem 3 must satisfy D(ε, E, ¯λ) =
0 for every ¯λ ∈ V adj and A (ε, λ, ¯E) = 0 for every ¯E ∈ V dir. The former means that E solves

Problem 2 and the latter that λ solves the following adjoint problem:
Problem 4. Given ε ∈ U ε, determine λ ∈ V adj such that A (ε, λ, φ) = 0 for every φ ∈ V dir.
The functional A in Problem 4 was deﬁned in (9). The problem can be seen as a weak

analogue of the following system, adjoint to (5):

ε

∂2λ
∂t2 − ∆λ + ∇(∇ · λ) − sε∇(∇ · λ) = 0
∂λ
∂n
λ(·, T ) =

= −(E − G)z2

(·, T ) = 0

∂λ
∂t

δ

in ΩT ,

on ΓT ,

in Ω.

These observations will be used in the error analysis to be described below. But ﬁrst we
shall make some remarks concerning the relation between the Fr´echet derivative of Tikhonov
functional and that of the Lagrangian.

Let uε = (ε, Eε, λε) be the element of U obtained by taking Eε as the solution to Problem 2
and λε as the solution to Problem 4 for the given ε ∈ U ε. Then, under assumption of suﬃcient
stability of the weak solutions Eε and λε with respect to ε, the observation that

F (ε) = F (ε, Eε) = F (ε, Eε) + D(ε, Eε, λε) = L(uε),

(as D(ε, Eε, λε) = 0) leads to

(10)

F (cid:48)(ε; ·) =

∂L
∂ε

(uε; ·).

Estimate (8) and identity (10) will play an important role in the error analysis for the Tikhonov
functional and for the coeﬃcient.

3 Finite element formulations and error analysis

In this section we will give ﬁnite element formulations for discretizing Problems 2, 3 and 4. After
that we will turn to the error analysis. We begin by deﬁning ﬁnite-dimensional analogues of the
spaces V ε, V dir, V adj, and V , as well as subsets corresponding to U ε and U .

Let Th := {K} be a triangulation of Ω and let Iτ be a uniform partition of (0, T ) into
subintervals (tk, tk+1], tk = kτ , k = 0, . . . , Nτ , of length τ = T /Nτ . With Th we associate a
mesh-function h = h(x) such that

(11)

h(x) = diam(K)

6

for x ∈ K ∈ Th. On these meshes we deﬁne

h ∩ U ε,

V ε
h := {v ∈ V ε : v|K ∈ P q(K) ∀K ∈ Th},
h := V ε
U ε
:= {v ∈ V dir : v|K×I ∈ [P 1(K)]3 × P 1(I) ∀K ∈ Th ∀I ∈ Iτ},
V dir
h
V adj
:= {v ∈ V adj : v|K×I ∈ [P 1(K)]3 × P 1(I) ∀K ∈ Th ∀I ∈ Iτ},
h
Vh := V ε
Uh := U ε

h × V dir
h × V dir

h × V adj
h ,
h × V adj
h ,

where P n(X) denotes the space of polynomials of degree at most n ∈ N over X, and the degree
q used in the ﬁnite-dimensional analogue V ε
h of V ε is at least 1. Observe that the dependence on
the step size τ in time is not explicitly included in the notation for the ﬁnite-dimensional spaces.
This is justiﬁed by the fact that τ should be selected with regard to h in accordance with the
Courant-Friedrichs-Lewy condition.

Using these spaces we can state ﬁnite element versions of Problems 2 and 4 as Problem 5 and

Problem 6, respectively, as follows:
Problem 5. Given ε ∈ U ε, determine Eh ∈ V dir
V adj
h .
Problem 6. Given ε ∈ U ε, determine λh ∈ V adj

h

h

such that D(ε, Eh, φh) = 0 for every φh ∈

such that A (ε, λh, φh) = 0 for every φ ∈ V dir
h .

The ﬁnite-dimensional analogue for Problem 3 is:

Problem 7. Find uh = (εh, Eh, λh) ∈ Uh such that L(cid:48)(uh, v) = 0 for every v ∈ Vh.

The same remark that was made in conjunction with Problem 3 is also valid here: it holds

that Eh solves Problem 5 and λh solves Problem 6 for ε = εh.

Having stated problems 1–7, let us brieﬂy summarize how these problems relate to each other,

before turning to the error analysis.

Recall that our main goal is to ﬁnd the dielectric permittivity which gave rise to the ob-
served data G, in other words to solve Problem 1. Due to ill-posedness, this goal is practically
unattainable, and we focus instead on ﬁnding a regularized solution, which can be done by ﬁnding
a stationary point to the Lagrangian, that is, by solving Problem 3. This, in turn, relies upon
solving the direct and adjoint problems for the electric ﬁeld, problems 2 and 4, respectively.
However, problems 2–4 cannot, in general, be solved exactly, but approximately through their
ﬁnite-dimensional analogues, problems 5–7.

The purpose of the error estimation below is to quantify the discrepancy between the solutions
to problems 2–4, and the solutions to problems 5–7, in order to be able to adaptively reﬁne the
latter three problems so that the solution to Problem 7, the approximation of the regularized
solution, ﬁts the solution to Problem 3, the true regularized solution, as closely as desired. We
will now focus on this estimation.

We begin by introducing some additional notation. For v = (ε, E, λ) ∈ V we denote (with

some slight abuse of notation) its interpolant in Vh by

and the interpolation error by

Πhv = (Πhε, ΠhE, Πhλ),

rhv = v − Πhv = (rhε, rhE, rhλ).

7

We will also need to consider jumps of discontinuous functions over Th and Iτ . Let K1, K2 ∈ Th
share a common face f . For x ∈ f we deﬁne
lim
(12)

v(y) +

v(y),

lim

{v}s (x) :=

y→x, y∈K1

y→x, y∈K2

so that in particular if v = wn, where w is piecewise constant on Th and n is the outward unit
normal, then {v}s = {wn}s = (wn)|K1 + (wn)|K2 is the normal jump across f . We extend {·}s
to every face in Th by deﬁning {v}s (x) = 0 for x ∈ K ∩ Γ, K ∈ Th. The corresponding maximal
jump is deﬁned by

(13)

[v]s (x) := max

y∈∂K |{v}s (y)| , x ∈ K ∈ Th,

where ∂K denotes the boundary of K.

For jumps in time, we deﬁne

(cid:40) lim

s→0+
0

(cid:0)v(tk + s) − v(tk − s)(cid:1), k = 1, . . . , Nτ − 1,

k = 0, Nτ ,

{v}t (tk) :=

[v]t (t) := max{|{v}t (tk)| , |{v}t (tk+1)|} t ∈ (tk, tk+1).

In the theorems and proofs to be presented, we will frequently use the symbols ≈ and (cid:46) to

denote approximate equality and inequality, respectively, where higher order terms (with respect
to mesh-size or errors) are neglected. We let C denote variuos constants of moderate size which
are independent of mesh-sizes and the the unknown functions.

We now proceed with an error estimate for the coeﬃcient. An error estimate for the Tikhonov

functional will follow as a corollary.

Theorem 1. (A posteriori error estimate for the coeﬃcient.) Suppose that the initial approx-
imation ε0 and the regularization parameter α are such that the strong convexity estimate (8)
holds. Let u = (ε, E, λ) ∈ U be the solution to Problem 3, and let uh = (εh, Eh, λh) ∈ Uh be the
solution to Problem 7, computed on meshes Th and Iτ . Then there exists a constant C, which
does not depend on u, uh, h, or τ , such that

(14)

and

(15)

(16)

(17)

and

(18)

where η = η(uh) is deﬁned by

(cid:107)ε − εh(cid:107)Ω

(cid:46) 2C
α

(η + (cid:107)Rε(cid:107)Ω),

τ

τ

∂t

t

∂n

(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12) + s|∇ · λh|, h(cid:12)(cid:12)(cid:2) ∂Eh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂Eh
η :=(cid:10) 1
(cid:3)
(cid:3)
(cid:12)(cid:12)(cid:2) ∂Eh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12)(cid:11)
(cid:12)(cid:12), h(cid:12)(cid:12)(cid:2) ∂λh
(cid:3)
(cid:3)
(cid:3)
+(cid:10) 1
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂∇·Eh
(cid:12)(cid:12)(cid:11)
|∇ · λh|,(cid:12)(cid:12)(cid:2) ∂Eh
(cid:3)
(cid:3)
+ s(cid:10)
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂∇·λh
|∇ · Eh| + |Eh|,(cid:12)(cid:12)(cid:2) ∂λh
(cid:3)
(cid:3)
+ s(cid:10)
(cid:90) T
(cid:90) T

ΩT

ΩT

∂n

∂n

∂n

s

∂t

t

∂t

t

∂t

∂t

t

∂t

s

s

s

t

(cid:12)(cid:12)(cid:11)
(cid:3)
(cid:12)(cid:12)(cid:11)

,

t

ΩT

ΩT

Rε := α(εh − ε0) −

0

∂Eh
∂t

∂λh
∂t

·

dt +

s
2h

[(∇ · λh)(n · Eh)]s dt.

0

8

Proof. Using strong convexity (8), we obtain

(cid:107)ε − εh(cid:107)2

Ω ≤

2
α

(F (cid:48)(ε; ε − εh) − F (cid:48)(εh; ε − εh)) .

Since ε minimizes F (ε) we have F (cid:48)(ε; ε − εh) = 0 and thus

(19)

(cid:107)ε − εh(cid:107)2

Ω ≤

2

α |F (cid:48)(εh; ε − εh)| =

2
α

(cid:12)(cid:12)(cid:12)(cid:12) ∂L

∂ε

(cid:12)(cid:12)(cid:12)(cid:12) ,

(˜u; ε − εh)

where we have denoted by ˜E and ˜λ the solutions to Problem 2 and Problem 4, respectively, with
permittivity εh, and set ˜u = (εh, ˜E, ˜λ) ∈ U . The last equality follows from (10). We remark
α (cid:107)F (cid:48)(εh)(cid:107), which would be an eﬀective estimate. Unfortunately,
that (19) implies (cid:107)ε − εh(cid:107)Ω ≤ 2
we cannot compute F (cid:48)(εh) exactly, since it depends on the exact solutions ˜E and ˜λ as indicated
in the text, hence further estimation is needed.

(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

We expand

(cid:12)(cid:12)(cid:12)(cid:12) ∂L

∂ε

(20)

(cid:12)(cid:12)(cid:12)(cid:12) =

(cid:12)(cid:12)(cid:12)(cid:12) ∂L
(cid:12)(cid:12)(cid:12)(cid:12) ∂L

∂ε

∂ε

(˜u; ε − εh) −

≤
=: |Θ1| + |Θ2| ,

(˜u; ε − εh)

(˜u; ε − εh) −

(uh; ε − εh) +

(uh; ε − εh)

∂L
∂ε
∂L
∂ε

(cid:12)(cid:12)(cid:12)(cid:12) +

∂L
∂ε

(cid:12)(cid:12)(cid:12)(cid:12) ∂L

∂ε

(uh; ε − εh)

(uh; ε − εh)

and estimate the two terms |Θ1| and |Θ2| separately.

For Θ1 we assume that the second partial derivatives of L exist, and use the linearization

Θ1 =

=

∂L
∂ε

(uh; ε − εh)

(˜u; ε − εh) −

∂L
∂ε
∂2L
∂ε2 (uh; εh − εh; ε − εh) + o((cid:107)εh − εh(cid:107)Ω)
+

∂2L
∂E∂ε
∂2L
∂λ∂ε

+

(uh; ˜E − Eh; ε − εh) + o((cid:107) ˜E − Eh(cid:107)H 1(ΩT ))
(uh; ˜λ − λh; ε − εh) + o((cid:107)˜λ − λh(cid:107)H 1(ΩT )),

∂E∂ε and ∂2L

where ∂2L
∂λ∂ε denote mixed second partial Fr´echet derivatives of L. The ﬁrst two terms
vanish, since the ﬁrst components of ˜u and uh are both εh, and again the remainder terms are
neglected as they are of higher order with respect to the error. Thus, after exchanging the order
of diﬀerentiation, we are left with

(21)

Θ1 ≈

∂2L
∂E∂ε
= D1|ε−εh

(cid:18) ∂L

(uh; ˜E − Eh; ε − εh) +
(uh; ˜E − Eh) +

∂E

∂2L
∂λ∂ε
∂L
∂λ

(cid:19)
(uh; ˜λ − λh; ε − εh)
(uh; ˜λ − λh)

,

where D1|ε−εh denotes diﬀerentiation with respect to the ﬁrst component in uh and action on
ε − εh.
We split ˜E − Eh = ( ˜E − Πh ˜E) + (Πh ˜E − Eh) = rh ˜E + (Πh ˜E − Eh) and use the fact that λh
solves Problem 4 with coeﬃcient εh, so that ∂L
h . This
gives

∂E (uh; Πh ˜E − Eh) = 0 as Πh ˜E − Eh ∈ V dir

(22)

∂L
∂E

(uh; ˜E − Eh) =

∂L
∂E

(uh; rh ˜E) +

∂L
∂E

(uh; Πh ˜E − Eh) =

∂L
∂E

(uh; rh ˜E).

9

Similarly, we have

(23)

as Eh solves Problem 2 with coeﬃcient εh.

Combining (21), (22), and (23), and recalling (9) gives

∂L
∂λ

∂L
∂λ

(uh; ˜λ − λh) =
(cid:18) ∂L
(cid:68)
Θ1 ≈ D1|ε−εh
(cid:68)
(ε − εh) ∂rh ˜E
(ε − εh) ∂Eh

= −
−

∂E

∂t

(uh; rh

˜λ) +

∂L
∂λ

(uh; Πh

∂L
∂λ

(uh; rh

˜λ).

˜λ − λh) =
(cid:19)

(uh; rh ˜E) +

, ∂λh
∂t

∂t , ∂rh

∂t

˜λ

(cid:69)
(cid:69)

ΩT

ΩT

∂L
∂λ

+ s

+ s

(uh; rh

(cid:68)
(cid:68)

˜λ)

(cid:69)
(cid:69)
∇ · ((ε − εh)rh ˜E), ∇ · λh
˜λ
∇ · ((ε − εh)Eh, ∇ · rh

ΩT

.

ΩT

We now aim to lift time derivatives from the interpolation residuals rh ˜E and rh

˜λ by splitting
the integral over [0, T ] to the sum of integrals over the subintervals in Iτ , and integrating by
parts on each subinterval. Thus we obtain

(cid:68)
(ε − εh) ∂rh ˜E

∂t

(cid:69)

, ∂λh
∂t

ΩT

=

=

Nτ(cid:88)
Nτ(cid:88)

k=1

k=1

+

∂t

tk−1

(cid:69)

, ∂λh
∂t

(cid:68)
(ε − εh) ∂rh ˜E
(cid:90) tk
(cid:68)
(ε − εh)rh ˜E, ∂2λh

(cid:90) tk
(cid:32)
(cid:68)
(ε − εh)rh ˜E, ∂λh

(cid:69)

tk−1

−

∂t2

∂t

Ω

dt

Ω

(cid:69)
(cid:12)(cid:12)(cid:12)t=tk −
(cid:68)
(ε − εh)rh ˜E, ∂λh

dt

∂t

Ω

(cid:69)

Ω

(cid:19)

.

(cid:12)(cid:12)(cid:12)t=tk−1

∂t2 ≡ 0 on each subinterval, since λh is piecewise linear, and identify the jumps

We note that ∂2λh

form (14), obtaining(cid:68)

(cid:69)

(ε − εh) ∂rh ˜E

∂t

, ∂λh
∂t

=

ΩT

Next, we use the approximation

f (tk) ≈

1
τ

to obtain terms deﬁned on the whole time-interval. That is

(cid:68)
(ε − εh) ∂rh ˜E

∂t

(cid:69)

, ∂λh
∂t

ΩT ≈

(cid:69)

(cid:9)

t

Ω

(cid:12)(cid:12)(cid:12)t=tk

.

Nτ(cid:88)

k=1

(cid:68)

(ε − εh)rh ˜E,(cid:8) ∂λh
(cid:90) tk

∂t

f (t) dt

tk−1

(cid:69)

(cid:3)

t

Ω

dt

(cid:68)

(cid:90) tk

k=1

1
τ

tk−1

Nτ(cid:88)
(cid:68)
(ε − εh)rh ˜E, 1
(cid:68)

(ε − εh)rh ˜E,(cid:2) ∂λh
(cid:2) ∂λh
(cid:2) ∂Eh

(cid:3)
(cid:3)

(cid:69)

(cid:69)

ΩT

∂t

∂t

.

τ

t

t, rh

˜λ

∂t

=

ΩT

(ε − εh) 1

τ

=

(cid:69)

˜λ

.

ΩT

10

Similarly, we have(cid:68)

(ε − εh) ∂Eh

∂t , ∂rh

∂t

Thus

(24)

|Θ1| (cid:46)(cid:68)

τ

(cid:68)
|ε − εh| 1
|ε − εh| 1
+
≤ (cid:107)ε − εh(cid:107)L∞(Ω)

τ

t

t

∂t

∂t

ΩT

˜λ

+ s

+ s

(cid:12)(cid:12)(cid:12), |∇ · λh|
(cid:68)(cid:12)(cid:12)(cid:12)∇ · ((ε − εh)rh ˜E)
(cid:12)(cid:12)(cid:12)rh ˜E
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:69)
(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12),
(cid:3)
(cid:12)(cid:12)(cid:12)∇ · rh
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:12)(cid:12)(cid:12)rh
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:68)
(cid:12)(cid:12),
(cid:12)(cid:12)(cid:2) ∂Eh
(cid:3)
(cid:18)(cid:68) 1
(cid:19)
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:12)(cid:12)(cid:12)rh
(cid:12)(cid:12)(cid:12)rh ˜E
(cid:12)(cid:12),
(cid:12)(cid:12)(cid:2) ∂Eh
(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12),
(cid:3)
(cid:3)
(cid:18)(cid:68)(cid:12)(cid:12)(cid:12)∇ · rh ˜E
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:12)(cid:12)(cid:12)∇ · rh
(cid:12)(cid:12)(cid:12), |∇ · λh|
(cid:68)
(cid:69)
(cid:19)
(cid:18)(cid:68)(cid:12)(cid:12)(cid:12)rh ˜E
(cid:12)(cid:12)(cid:12), |∇ · λh|
(cid:12)(cid:12)(cid:12)(cid:69)
(cid:12)(cid:12)(cid:12)∇ · rh
(cid:68)
(cid:69)

|∇ · ((ε − εh)Eh)|,

|∇ · Eh|,

(cid:68) 1

|Eh|,

˜λ

˜λ

˜λ

˜λ

+

+

+

ΩT

ΩT

ΩT

ΩT

ΩT

ΩT

ΩT

∂t

∂t

τ

τ

t

t

ΩT

.

ΩT

(cid:19)

+ s(cid:107)ε − εh(cid:107)L∞(Ω)

+ s(cid:107)∇(ε − εh)(cid:107)L∞(Ω)

Note that, by the equivalence of norms on V ε, we have

(cid:107)ε − εh(cid:107)L∞(Ω) + (cid:107)∇(ε − εh)(cid:107)L∞(Ω) ≤ C (cid:107)ε − εh(cid:107)Ω .

Finally, we use standard interpolation estimates (see for instance [26]) for rh ˜E

(cid:12)(cid:12) + τ 2(cid:12)(cid:12)τ−1(cid:2) ∂Eh

∂t

(cid:3)

t

(cid:12)(cid:12)(cid:1)

s

and as well as for rh

(cid:18)
(cid:12)(cid:12)(cid:12) ≤ C
(cid:12)(cid:12)(cid:12)rh ˜E
h2(cid:12)(cid:12)(cid:12)D2 ˜E
(cid:46) C(cid:0)h(cid:12)(cid:12)(cid:2) ∂Eh
(cid:3)

(cid:3)

s

∂t

∂n

∂n

∂t2

(cid:12)(cid:12)(cid:12)(cid:12) ∂2E
(cid:12)(cid:12)(cid:12)(cid:12)(cid:19)
(cid:12)(cid:12)(cid:12) + τ 2
≈ C(cid:0)h2(cid:12)(cid:12)h−1(cid:2) ∂Eh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂Eh
(cid:12)(cid:12)(cid:1) ,
(cid:3)
(cid:12)(cid:12)(cid:12)rh
(cid:12)(cid:12)(cid:12) (cid:46) C(cid:0)h(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂λh
(cid:3)
(cid:3)
˜λ, ∇ · rh ˜E, and ∇ · rh
(cid:12)(cid:12)(cid:12)∇ · rh ˜E
(cid:12)(cid:12)(cid:12) (cid:46) C(cid:0)(cid:12)(cid:12)(cid:2) ∂Eh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂∇·Eh
(cid:3)
(cid:3)
(cid:12)(cid:12)(cid:12)∇ · rh
(cid:12)(cid:12)(cid:12) (cid:46) C(cid:0)(cid:12)(cid:12)(cid:2) ∂λh
(cid:12)(cid:12) + τ(cid:12)(cid:12)(cid:2) ∂∇·λh
(cid:3)
(cid:3)

˜λ

˜λ

˜λ

∂n

∂n

∂n

∂t

∂t

∂t

s

s

s

t

t

t

(cid:12)(cid:12)(cid:1) ,
(cid:12)(cid:12)(cid:1) ,
(cid:12)(cid:12)(cid:1) ,

t

where the jumps [·]s and [·]t were deﬁned in equations (12), (13), (14), and (15). Applying these
estimates in (24), we get

(25)

with η as in (17).

Θ1 (cid:46) Cη (cid:107)ε − εh(cid:107)Ω ,

Turning to Θ2 of (20), we recall from (9) that

Θ2 =

∂L
∂ε

(uh; ε − εh)

(26)

= α(cid:104)εh − ε0, ε − εh(cid:105)Ω −

(cid:11)

ΩT

+ s(cid:104)∇ · ((ε − εh)Eh), ∇ · λh(cid:105)ΩT

.

∂t , ∂λh

∂t

Starting with the last term in the above expression, we split the integral over Ω into the sum of
integrals over K ∈ Th, and integrate by parts to get

(cid:104)∇ · ((ε − εh)Eh), ∇ · λh(cid:105)ΩT

(cid:104)∇ · ((ε − εh)Eh), ∇ · λh(cid:105)KT

−(cid:104)(ε − εh)Eh, ∇(∇ · λh)(cid:105)KT

+(cid:104)(ε − εh)n · Eh, ∇ · λh(cid:105)∂KT

(cid:1) ,

(cid:10)(ε − εh) ∂Eh
(cid:88)
(cid:88)

K∈Th

=

=

(cid:0)

K∈Th

11

where KT := K × (0, T ), and ∂KT := (∂K) × (0, T ). we observe that ∇ · (∇λh) ≡ 0 on each
K ∈ Th for the piecewise linear λh, and identify the jumps from (12), obtaining

(cid:104)∇ · ((ε − εh)Eh), ∇ · λh(cid:105)ΩT

=

=

(cid:104)(ε − εh)n · Eh, ∇ · λh(cid:105)∂KT

(cid:104){(∇ · λh)(n · Eh)}s, ε − εh(cid:105)∂KT

,

(cid:88)
(cid:88)

K∈Th
1
2

K∈Th

(cid:90)
(cid:88)

f
hK

(cid:68) 1

hK

(cid:82) T

(cid:69)

(cid:69)(cid:12)(cid:12)(cid:12)

2 appears since every non-zero jump is encountered exactly twice in the sum

where the factor 1
over K ∈ Th.
Seeking to obtain expressions deﬁned over the whole of Ω, as opposed to once deﬁned only
on boundaries of elements K ∈ Th, we use the following approximation, similar to the one used
above for the jumps in time:

(cid:90)

This yields

∂K

f dS ≈

K

dx.

(cid:104)∇ · ((ε − εh)Eh), ∇ · λh(cid:105)ΩT ≈

1
2

=(cid:10) 1

[(∇ · λh)(n · Eh)]s, ε − εh

K∈Th
2h [(∇ · λh)(n · Eh)]s, ε − εh

(cid:11) .

With the above estimate in (26), we can now conclude that

|Θ2| (cid:46)(cid:12)(cid:12)(cid:12)(cid:68)

(cid:82) T

0

(27)

α(εh − ε0) −

∂Eh
∂t

· ∂λh
∂t dt + s

2h

0 [(∇ · λh)(n · Eh)]s dt, ε − εh

≤ (cid:107)Rε(cid:107)Ω (cid:107)ε − εh(cid:107)Ω ,

with Rε as deﬁned (18).

Combining estimates (25) and (27) with (19) and (20), we conclude that

(cid:107)ε − εh(cid:107)2

Ω

(cid:46) 2C
α

(η (cid:107)ε − εh(cid:107)Ω + (cid:107)Rε(cid:107)Ω (cid:107)ε − εh(cid:107)Ω) ,

and the result (16) follows.

We see that if the numerical errors for solving the direct and adjoint problems are relatively

small, that is, when ˜u ≈ uh with relatively high accuracy, then (cid:107)Rε(cid:107)Ω ≈ (cid:107)F (cid:48)(εh)(cid:107) dominates the

error estimate.

Corollary 1. (A posteriori error estimate for the Tikhonov functional.) Under the hypothesis
of Theorem 1, we have

(cid:16)

(cid:17)

|F (ε) − F (εh)| (cid:46) 4C 2

α2

η2 + (cid:107)Rε(cid:107)2

Ω

,

with η as deﬁned in (17), and Rε as in (18).

Proof. Using the deﬁnition of the Fr´echet derivative and (10) we get

F (ε) − F (εh) = F (cid:48)(εh; ε − εh) + o((cid:107)ε − εh(cid:107)Ω)
(˜u; ε − εh) + o((cid:107)ε − εh(cid:107)Ω).

∂L
∂ε

=

12

Neglecting the remainder term as it is of higher order with respect to the error, and estimating
∂L
∂ε (˜u; ε − εh) = Θ1 + Θ2 as in the proof of Theorem 1, we obtain

|F (ε) − F (εh)| (cid:46) 2C

α

(η + (cid:107)Rε(cid:107)Ω)(cid:107)ε − εh(cid:107)Ω .

Applying Theorem 1 to estimate (cid:107)ε − εh(cid:107)Ω, we arrive at

|F (ε) − F (εh)| (cid:46) 4C 2

α2 (η + (cid:107)Rε(cid:107)Ω)2 ≤ C

(cid:16)

η2 + (cid:107)Rε(cid:107)2

Ω

(cid:17)

.

We will conclude this section by describing how these theorems translates into concrete rec-
ommendations for reﬁning the computational mesh in the adaptive algorithm, outlined in the
Section 4.

3.1 Mesh reﬁnement recommendations

From Theorem 1 and Corollary 1, it is clear that the error in the reconstruction can be estimated
in terms of two quantities, η, and Rε. The former essentially represents how well the direct
and adjoint problems, problems 2, and 4, are approximated by their ﬁnite element counterparts,
problems 5, and 6, respectively. The latter, Rε, describes the error incurred by the approximation
of the coeﬃcient itself.

In our computational experience from [7, 8], on given meshes Th and Iτ , the solutions to
direct and adjoint problems are in generally approximated better than the coeﬃcient itself. As
remarked above, this implies that η (cid:28) (cid:107)Rε(cid:107)Ω, which tells us that the error is the greatest in
regions where |Rε| ≈ |F (cid:48)(εh)| is close to its maximum value. Thus we propose the following mesh
reﬁnement recommendation:

Mesh Reﬁnement Recommendation 1. Using Theorem 1 we conclude that we should reﬁne
the mesh in neighborhoods of those points in Ω where the function |Rε| attains its maximal values.
More precisely, let β ∈ (0, 1) be a tolerance number which should be chosen in computational
experiments. Then, reﬁne the mesh Th in such subdomains of Ω where

|Rε| ≥ β max

Ω |Rε| .

Since a relatively large value of the reconstructed coeﬃcient εh indicates a region where
the permittivity is diﬀerent from the background value of 1, we can also propose the following
heuristic:

Mesh Reﬁnement Recommendation 2. We should reﬁne the mesh in neighborhoods of those
points in Ω where the function |εh| attains its maximal values. More precisely, we reﬁne the mesh
in such subdomains of Ω where

where (cid:101)β ∈ (0, 1) is a number which should be chosen computationally and h is the mesh function

Ω |εh| ,

(11) of the ﬁnite element mesh Th.

|εh| ≥ (cid:101)β max

13

(cid:90) T

0

(cid:90) T
0 ∇ · En

4 Adaptive algorithms for the inverse problem

In this section we will present diﬀerent algorithms which can be used for solution of the inverse
problem we consider: usual conjugate gradient algorithm and two diﬀerent adaptive ﬁnite element
algorithms. Conjugate gradient algorithm is applied on every ﬁnite element mesh Th which we
use in computations. We note that in our adaptive algorithms the time mesh Iτ is reﬁned globally
accordingly to the Courant-Friedrichs-Lewy condition of [27].

Taking into account remark of Section 3.1 we denote by

(28) Rn

ε (x) := α(εh − ε0) −

∂En
h
∂t

(x, t) ·

∂λn
h
∂t

(x, t) dt + s

h(x, t)∇ · λn

h(x, t) dt

where functions λn
with ε := εn

h are ﬁnite element solutions of direct and adjoint problems computed
h, respectively, and n is the number of iteration in the conjugate gradient algorithm.

h, and En

4.1 Conjugate Gradient Algorithm

Here we outline the conjgate gradient algorithm, which will be used in the two adaptive algorithms
presented below.

Algorithm 1. (Conjugate Gradient Algorithm)

Step 0. Discretize the computational space-time domain Ω × [0, T ] using partitions Th and Iτ ,
h = ε0 and compute the

respectively, see Section 3. Start with the initial approximations ε0
sequence of εn

h, n = 1, 2, . . ., as:

Step 1. Compute solutions En

h and λn

h of problems 5 and 6, respectively, using the coeﬃcient εn
h.

Step 2. Update the coeﬃcient on Th and Iτ via the conjugate gradient method

εn+1
h

(x) = εn

h(x) + γn

ε dn

ε (x),

where

with

dn
ε (x) = −Rn

ε (x) + βn

ε dn−1

ε

(x),

ε (cid:107)2
ε = (cid:107)Rn
βn

(cid:13)(cid:13)Rn−1

ε

(cid:13)(cid:13)2

Ω

Ω

,

ε(x) = −R0
d0
[28]

ε(x), and γn

ε are step-sizes in the gradient update which can be computed as in

(29)

γn

ε , dn
ε = −(cid:104)Rn
ε(cid:105)Ω
ε(cid:107)2
α(cid:107)dn

Ω

.

Step 3. Stop computing updates εn

h if
ε (cid:107)Ω ≤ θ – where θ is the tolerance in n updates of the gradient method – or norms

h at the iteration M := n and obtain the function εh := εM

h(cid:107)Ω are stabilized. Otherwise update n to n + 1 and return to Step 1.

either (cid:107)Rn
(cid:107)εn

14

4.2 Adaptive algorithms

In this section we present two diﬀerent adaptive algorithms for the solution of our coeﬃcient
inverse problem (more precisely, Problem 7, approximating the solution to Problem 3), where in
the ﬁrst adaptive algorithm we apply Mesh Reﬁnement Recommendation 1 of Section 3.1, while
in the second adaptive algorithm we use Mesh Reﬁnement Recommendation 2 of Section 3.1.

We deﬁne the minimizer of the Tikhonov functional (7) and its approximated ﬁnite element
solution on k times adaptively reﬁned mesh Thk by ε and εhk , correspondingly. The latter is
obtained at the ﬁnal step of the conjugate gradient iteration of Section 4.1 on the mesh Thk .
Algorithm 2. (The First Adaptive Algorithm)

Step 0. Choose an initial space-time mesh Th0×Iτ0 in Ω×[0, T ]. Compute εhk , k > 0, via following

steps:

Step 1. Obtain numerical solution εhk on Thk using the Conjugate Gradient Method of Section 4.1.
Step 2. In accordance with the ﬁrst mesh reﬁnement recommendation, reﬁne such elements in the

mesh Thk where the expression
(30)

(cid:12)(cid:12)RMk

(cid:12)(cid:12) ≥ βk max

Ω

(cid:12)(cid:12)RMk

ε

(cid:12)(cid:12) ,

ε

is satisﬁed. Here, the tolerance numbers (cid:101)βk ∈ (0, 1) are chosen by the user.
(cid:13)(cid:13)Ω < θ1, or for some n, (cid:107)Rn

Step 3. Deﬁne a new reﬁned mesh as Thk+1 and construct a new time partition Iτk+1 such that the
Courant-Friedrichs-Lewy condition of [27] is satisﬁed. Interpolate εhk on the new mesh
Thk+1 and perform Steps 1–3 on the space-time mesh Thk+1 × Iτk+1.

Step 4. Stop mesh reﬁnements when either (cid:13)(cid:13)εhk − εhk−1

ε (cid:107)Ω < θ2,
where θi, i = 1, 2 are tolerances chosen by the user, and Rn
ε is the gradient on the n:th
iteration of the conjugate gradient method on the new mesh. We then set the ﬁnal number
of reﬁnements krec := k, and the reconstructed coeﬃcient εrec := εhk .

Algorithm 3. (The Second Adaptive Algorithm)

This algorithm follows the same procedure as the First Adaptive Algorithm, except that the
reﬁnement criterion (30) is replaced, in accordance with the second mesh reﬁnement recommen-
dation, by

|εhk| ≥ (cid:101)βk max

(31)

for some tolerance numbers βk ∈ (0, 1) , possibly diﬀerent from (cid:101)βk, chosen by the user. Here,

is the gradient on the last iteration of the conjugate gradient method on the k times adap-

Ω |εhk|

ε

RMk
tively reﬁned mesh.

Before continuiong with the details of our numerical examples, some remarks are in order:

• Firstly, we comment on how to choose the tolerance numbers βk, and(cid:102)βk in (30), (31). Their
(cid:12)(cid:12) and maxΩ |hkεhk|, correspondingly.
If we will take values of βk, and(cid:102)βk which are very close to 1 then we will reﬁne the mesh
in very narrow region of the domain Ω, and if we will choose βk, and (cid:102)βk ≈ 0 then almost

values depend on the concrete values of maxΩ

all elements in the ﬁnite element mesh will be reﬁned, and thus, we will get global and not
local mesh reﬁnement. Our numerical tests of Section 5 show that the choice of βk, and

(cid:12)(cid:12)RMk

ε

15

a) Test1: (cid:101)Ω = ΩFEM ∪ ΩFDM

b) Test 1: ΩFEM

ΩFEM ∪ ΩFDM. b) The ﬁnite element domain ΩFEM.

Figure 2: Domain decomposition in numerical tests of Section 5. a) The decomposed domain (cid:101)Ω =
(cid:101)βk = 0.7 is almost optimal one since with these values of the parameters βk, and (cid:102)βk the
(cid:13)(cid:13)Ω in Step 3 of the adaptive algorithms, the
• Secondly, to compute norms (cid:13)(cid:13)εhk − εhk−1

ﬁnite element mesh Thk is reﬁned exactly at the places where we have computed non-trivial
parts of the functions εhk .

solution εhk−1 is interpolated from the mesh Thk−1 to the mesh Thk .

5 Numerical examples

ΩFEM and ΩFDM such that ΩFEM = Ω, and ΩFEM ∩ ΩFDM = ∅. In ΩFEM we will use the ﬁnite

In this section we present numerical studies of the solution our inverse problem using the adaptive
algorithms of Section 4.2. The algorithms are eﬃciently implemented in the software package
WavES ([29]), using the domain decomposition technique of [30].

To do that we enlarge the domain Ω to a domain(cid:101)Ω ⊃ Ω, and decompose(cid:101)Ω into two subregions
element method (FEM) and, in ΩFDM, the ﬁnite diﬀerence method (FDM). The boundary ∂(cid:101)Ω
of the domain (cid:101)Ω is such that ∂(cid:101)Ω = ∂1(cid:101)Ω ∪ ∂2(cid:101)Ω ∪ ∂3(cid:101)Ω where ∂1(cid:101)Ω and ∂2(cid:101)Ω are, respectively, front
and back sides of (cid:101)Ω, and ∂3(cid:101)Ω is the union of left, right, top and bottom sides of this domain.
We will collect time-dependent observations over ST := ∂1(cid:101)Ω × (0, T ) at the backscattering side
∂1(cid:101)Ω of (cid:101)Ω. We also deﬁne S1, 1 := ∂1(cid:101)Ω × (0, t1], S1, 2 := ∂1(cid:101)Ω × (t1, T ), S2 := ∂2(cid:101)Ω × (0, T ) and
S3 := ∂3(cid:101)Ω × (0, T ).

As in [7, 8] we initialize only one component E2 of the electrical ﬁeld E = (E1, E2, E3) on

ST as a plane wave f (t) such that

(32)

f (t) =

(cid:40)

sin (ωt)
0

if 0 < t < 2π/ω,
if t > 2π/ω.

We assume that the function ε ≡ 1 inside ΩFDM. The numerical tests of our previous studies
[31] show that the best reconstruction results are obtained for ω = 40 in (32). Thus, we perform
our tests with ω = 40 in (32) in all our tests.

In our computations, we consider computational domains (cid:101)Ω := (−0.8, 0.8)3, and ΩFEM :=

(−0.7, 0.7)3, where the length scales are in decimeters. We choose the mesh size h0 = 0.05 in the

16

overlapping layers between ΩFEM and ΩFDM as well as in the coarse mesh. We note that we have
generated our transmitted data using a four times locally reﬁned initial mesh ΩFEM, and in a
such way we avoid variational crimes. To generate transmitted data we solve the model problem
in time T = [0, 3.0] with the time step τ = 0.006 which satisﬁes to the Courant-Friedrichs-Lewy
condition [27]. We then pollute our data additive noise of levels σ = 3%, and 10%, respectively.
Similarly with [5, 7, 8, 30, 31] in all our computations we choose constant regularization
parameter α = 0.01 because it gives smallest relative error in the reconstruction of the function
ε. This parameter was chosen via trial and error because of our computational experience: such
choice for the regularization parameter gave the smallest relative error eε = (cid:107)ε − εhk(cid:107)Ω /(cid:107)εhk(cid:107)Ω.
An iteratively regularized adaptive ﬁnite element method when both functions ε and µ are
reconstructed, has recently been presented in [23]. Here, iterative regularization is performed
via the algorithms of [22]. We also refer to [15, 16] for diﬀerent techniques for the choice of
regularization parameters.

We perform four diﬀerent tests:

Test 1: The goal of this numerical test is to reconstruct a smooth function ε only inside ΩFEM. We

deﬁne this function as

(33)

ε(x) := 1.0 + 1.0e−|x−x1|2/0.2 + 1.0e−|x−x2|2/0.2, x ∈ ΩFEM,
x1 := (0.3, 0.0, 0.0) ∈ ΩFEM,
x2 := (−0.4, 0.2, 0.0) ∈ ΩFEM.

Test 2: In this test we reconstruct three small inclusions of diameter d = 2 mm with the centers of
the inclusions at (−0.3, 0.0, −0.25), (0.3, 0.2, −0.25) and (0.3, −0.2, −0.25), respectively.
Test 3: In this test we reconstruct four small inclusions of diameter d = 2 mm with the centers of the
inclusions at (−0.3, 0.0, 0.25), (0.0, 0.2, 0.25), (0.0, −0.2, −0.25), and (0.3, −0.2, −0.25),
respectively.

Test 4: The inclusions of this test are the same as in Test 3, but here the data consists measurements
of two backscattered wave ﬁelds: one backscattered ﬁeld initiated at the front boundary

∂1(cid:101)Ω, and another one at the back boundary ∂2(cid:101)Ω.

We start to run the adaptive algorithm with a homogeneous initial approximation ε0 ≡ 1.0 in
ΩFEM. In our recent work [31], it was shown that such choice of the initial approximation gives
a good reconstruction. Such homogeneous initial approximations were also used in [32]. See
also [5, 7, 8, 30] for a similar choice of initial approximations. We also assume the upper bound
εmax = 5 in (1). This is a reasonable value, given that our target applications are in medical
imaging, and typically involves low contrasts.

To get ﬁnal images of our reconstructed function εhk we use a post-processing procedure

which has been described before in [5, 7, 30, 31].

5.1 Reconstructions

5.1.1 Test 1

In this section we present numerical results of the reconstruction of the function ε given by
(33). Tables 1–2 present computed results of the reconstructions on adaptively reﬁned meshes
after applying the First Adaptive Algorithm. Figures 3–8 display results of the reconstruction
of the function given by (33) with additive noise of the level σ = 10%. Quite similar results are

17

Table 1. Results obtained on the coarse mesh. We present reconstructions of the maximal contrast ˜ε =
maxΩFEM εM0
together with computational errors in percents. Here, M0 is the ﬁnal number of iteration in
h0
the conjugate gradient method on the coarse mesh.

σ = 3%

˜ε
1.93
2.94
1.77
1.9

error, % M0
3.5
47
11.5
5

2
2
2
2

Test 1
Test 2
Test 3
Test 4

σ = 10%

˜ε
1.94
2.81
2.04
2.03

error, % M0
3
40.5
2
1.5

2
2
2
2

Test 1
Test 2
Test 3
Test 4

Table 2. Results obtained on krec times adaptively reﬁned mesh. We present reconstructions of the maximal
contrast ˜ε = maxΩFEM εrec together with computational errors in percents.

Case
Test 1
Test 2
Test 3
Test 4

˜ε
2.04
1.99
1.55
1.9

σ = 3%
error, % Mkrec
2
0.5
22.5
5

5
1
1
1

krec
4
5
2
1

Case
Test 1
Test 2
Test 3
Test 4

˜ε
1.97
1.92
1.88
2.15

σ = 10%
error, % Mkrec
1.5
4
6
7.5

1
1
1
1

krec
5
5
2
1

x ∈ ΩFEM : εh0(x) = 1.2

x ∈ ΩFEM : εh0 (x) = 1.5

x ∈ ΩFEM : εh0(x) = 1.8

Figure 3: Test 1. Prospect views of reconstructed isosurfaces of εh0 obtained on a coarse mesh. In this
test we have reconstructed maxΩFEM εh0 = 1.94, see Table 1. Noise level in data is σ = 10%.

x1x2-view

x1x3-view

x2x3-view

Figure 4: Test 1. Five times adaptively reﬁned mesh when the level of the noise in the data was σ = 10%.

18

x ∈ ΩFEM : εrec(x) = 1.2

x ∈ ΩFEM : εrec(x) = 1.5

x ∈ ΩFEM : εrec(x) = 1.8

Figure 5: Test 1. Prospect views of reconstructed isosurfaces of εrec on a 5 times adaptively reﬁned
mesh. In this test we have obtained maxΩFEM εrec = 1.97, see Table 2. The noise level in the data is
σ = 10%.

obtained for σ = 3%, see Tables 1, and 2, and thus they are not presented here. In Figures 3–
8 we observe that the location of the maximal value of the function (33) is imaged correctly.
It follows from Figure 7 and Table 1 that on the coarse mesh we obtain good contrast, with
maxΩFEM εh0 = 1.94. However, Figure 7 reveals that it is desirable to improve the location of
the maxima of the reconstructed function in x3 direction as well as remove some artifacts which
appeared in the reconstruction on the coarse mesh.

The reconstruction εrec of ε on a ﬁnal, ﬁve times adaptively reﬁned mesh are presented in
Figure 8. We observe signiﬁcant improvement of the reconstruction of the function ε obtained
on the ﬁnal adaptively reﬁned mesh: the artifacts are removed and the reconstructed function is
moved more closer to the exact function in x3 direction, compared with results of Figure 7.

5.1.2 Test 2

In the test of this section we consider the problem arisen in microwave imaging: reconstruction of
high contrast in malign tumors and detection of small tumor sizes (less than 1 cm) in breast cancer
screening. Most of existing numerical methods for solution of these problems uses minimization
of conventional least-squares functionals and Gauss-Newton methods. See, for example, [1, 9, 33–
35], [36, 37]. We propose to use an adaptive ﬁnite element method which will allow achievement
of high contrast in the malign tumor and eﬃciently detect very small sizes of inclusions during
adaptive mesh reﬁnement. Although only reconstruction of a real dielectric permittivity function
is considered in our test, the obtained results can be extended for the reconstruction of the
complex permittivity function which is one of the goals of our current research.

We tested the Second Adaptive Algorithm on the reconstruction of three small inclusions with
centers at (−0.3, 0.0, −0.25), (0.3, 0.2, −0.25), and (0.3, −0.2, −0.25) located inside spherical
geometry of Figure 2, see also Figure 10 where they are visualized. These inclusions model three
small malign tumors of a size 2 mm. We performed simulations with two additive noise levels in
the data: σ = 3% and σ = 10%, see Tables 1–2 for the results.

The reconstruction of the three inclusions on the initial coarse mesh with σ = 10% is presented
on the left ﬁgures of Figure 12. In this ﬁgure and Table 1 we observe that, on the coarse mesh, we
obtain quite correct locations of all inclusions and achieve maximal contrast of maxΩFEM εh0 = 2.8
in the inclusions. However, Figures 12-e), and g) show us that the locations of all inclusions in x3-
direction can still be improved. The ﬁgures on the right of Figure 12 present the reconstruction
εrec of ε on the ﬁve times locally adaptively reﬁned mesh. In Figure 12-f), and h) we observe
an improvement of the reconstructions of the three inclusions in the x3-direction on the ﬁnal

19

t = 0.6

t = 0.6, x1x2 view

t = 1.2

t = 1.2, x1x2 view

t = 1.8

t = 1.8, x1x2 view

Figure 6: Test 1. Transmitted data of component E2 at diﬀerent times. The noise in the data is
σ = 10%.

20

40302010001020301.510.50-0.5-140×10-150510152025303505101520253035403020100010203086420-240×10-405101520253035051015202530354030201000102030-1-0.8-0.85-0.9-0.95400510152025303505101520253035x1x2 view

x2x3 view

x1x3 view

x1x2 view

x2x3 view

x1x3 view

x1x2 view

x2x3 view

x1x3 view

Figure 7: Test 1. In red: isosurfaces {x ∈ ΩFEM : εh0 (x) = 0.8 maxΩFEM εh0} on a coarse mesh. Here,
maxΩFEM εh0 = 1.94, and the noise level in the data is σ = 10%. For comparison we also present as
wireframes the corresponding isosurface of the function (33) in every ﬁgure.

21

x ∈ ΩFEM : εrec(x) = 1.2 x ∈ ΩFEM : εrec(x) = 1.5 x ∈ ΩFEM : εrec(x) = 1.8

prospect view

x1x2 view

x2x3 view

x1x3 view

Figure 8: Test 1. In red: isosurfaces {x ∈ ΩFEM : εrec = 0.8 maxΩFEM εrec}. Here, εrec was obtained
on a ﬁve times reﬁned mesh, maxΩFEM εrec = 1.97, and the noise level in the data is σ = 10%. For
comparison we also present as wireframes the corresponding isosurface of the function (33) in every
ﬁgure.

22

t = 0.6

t = 0.6, x1x2 view

t = 1.2

t = 1.2, x1x2 view

t = 1.8

t = 1.8, x1x2 view

Figure 9: Test 2. Transmitted data of the component E2 at diﬀerent times. The noise level in the data
is σ = 10%.

23

40302010001020302.5-1-0.500.511.5240×10-15051015202530350510152025303540302010001020301.81.21.41.62.2240×10-405101520253035051015202530354030201000102030-0.88-0.86-0.865-0.87-0.875-0.885-0.89400510152025303505101520253035x ∈ ΩFEM : εh0 (x) = 2.8

x ∈ ΩFEM : εrec(x) = 1.9

Figure 10: Test 2. Prospect views of reconstructions of three inclusions on a coarse mesh (on the left)
and on the ﬁve times adaptively reﬁned mesh (on the right). The noise level in the data is σ = 10%.
The top ﬁgures also present exact inclusions (in light blue and pink colors).

x1x2 view

x1x3 view

x2x3 view

Figure 11: Test 2. Five times adaptively reﬁned mesh when the noise level in the data was σ = 10%.

24

x ∈ ΩFEM : εh0 (x) = 2.8

x ∈ ΩFEM : εrec(x) = 1.9

a) prospect view

b) prospect view

c) x1x2 view

d) x1x2 view

e) x2x3 view

f) x2x3 view

g) x1x3 view

h) x1x3 view

Figure 12: Test 2. Reconstructions (in red color) εh0 of ε obtained on the coarse mesh (left ﬁgures), and
εrec on the ﬁve times adaptively reﬁned mesh (right ﬁgures). The noise level in the data is σ = 10%. For
comparison we also present exact isosurfaces of the three small inclusions to be reconstructed (in light
blue color).

25

adaptively reﬁned mesh, compared with reconstructions obtained on the coarse mesh. Comparing
Tables 1 and 2 we also can conclude that adaptive mesh reﬁnement allowed us to obtain more
correct contrast for all three inclusions.

5.1.3 Test 3

This test is similar to Test 3, only here the goal was to reconstruct four small inclusions located at
diﬀerent parts of ΩFEM: two inclusions were located closer to the backscattering boundary, and
another two inclusions were placed closer to the transmission boundary of ΩFEM, see Figure 14
where they are presented. These inclusions model four small malign tumors of a size 2 mm. We
performed simulations with two additive noise levels in the data: σ = 3% and σ = 10%, see
Tables 1–2 for the results.

The reconstruction on the initial coarse mesh with a noise level σ = 10% in the data is
presented on the left ﬁgures of Figure 14. From this ﬁgure and Table 1 we observe that we get
quite correct locations of all inclusions and achieve a maximal contrast of maxΩFEM εh0 = 2.04
on the coarse mesh. However, Figure 12-e), and g) show that the locations of all inclusions in the
x3-direction can still be improved. These ﬁgures also show that one of the four small inclusions
is almost not present in the initial reconstruction.

The ﬁgures on the right of Figure 14 present the reconstruction εrec on the two times locally
adaptively reﬁned mesh. In Figure 14-f), and h) we observe that the two lower inclusions are well
reconstructed. However, since in this quite challenging test we have used only transmitted data
resulted from a single measurement of a plane wave, we do not observe signiﬁcant improvement
of the reconstruction of the four inclusions in the x3-direction.

5.1.4 Test 4

In this test we decided improve the results of Test 3 and we tried to reconstruct the four inclusions
using measurements of two backscattered wave ﬁelds. First, we initialized a plane wave at the

front boundary ∂1(cid:101)Ω in time [0, T ] and collected backscattered data here. Next, we initialized
a plane wave at the back boundary ∂2(cid:101)Ω in time [T, 2T ] and collected backscattered data for

this wave ﬁeld. We choose T = 3 and τ = 0.006 as in all previous tests. Figure 17 and Tables
1–2 show the results of the reconstruction. Now we see that all inclusions are of the same size
and they are reconstructed in correct positions and with correct contrasts on the coarse mesh as
well as on the reﬁned mesh. From Tables 1–2 we see that adaptive algorithm converged already
after ﬁrst mesh reﬁnement. The drawback of this test is that computations of one optimization
iteration took twice as much time as the corresponding iterations of the previous tests, because
of two measurements of the backscattered wave ﬁelds.

6 Conclusion

In this work we have derived two a posteriori error estimates, for the direct error in the approx-
imated permittivity as well as in the Tikhonov functional, in the ﬁnite element approximation
of the Lagrangian approach to our coeﬃcient inverse problem. Both estimates are consisting of
two parts which can be interpreted as representing the error incurred by the approximation of
the solution to the direct and adjoint problems, and the error incurred by the approximation of
the coeﬃcient itself, respectively. These estimates are important in the adaptive algorithms we
have studied. Moreover, they further justify the use of similar error indicators in our previous
works [7, 8].

26

t = 0.6

t = 0.6, x1x2 view

t = 1.8

t = 1.8, x1x2 view

t = 2.4

t = 2.4, x1x2 view

Figure 13: Test 3. Transmitted data of the component E2 at diﬀerent times. The noise level in the data
is σ = 3%.

27

40302010001020301-1-0.500.540×10-1305101520253035051015202530354030201000102030-0.816-0.826-0.824-0.822-0.82-0.8184005101520253035051015202530354030201000102030-0.39-0.44-0.43-0.42-0.41-0.4-0.38400510152025303505101520253035x ∈ ΩFEM : εh0 (x) = 2.04 x ∈ ΩFEM : εrec(x) = 1.88

a) prospect view

b) prospect view

c) x1x2 view

d) x1x2 view

e) x2x3 view

f) x2x3 view

g) x1x3 view

h) x1x3 view

Figure 14:
Test 3. Reconstruction of four inclusions (in red color) obtained on the coarse mesh
(left ﬁgures) and on the two times adaptively reﬁned mesh (right ﬁgures). The noise level in the data is
σ = 10%. For comparison we also present exact isosurfaces of the four small inclusions to be reconstructed
(in light blue color).

28

t = 0.6

t = 0.6, x1x2 view

t = 1.2

t = 1.2, x1x2 view

t = 1.8

t = 1.8, x1x2 view

Figure 15: Test 4. Backscattered data of the component E2 at ∂1(cid:101)Ω at diﬀerent times. The level of noise

in the data is σ = 10%.

29

4030201000102030-0.5309-0.5309-0.5309-0.5309-0.53094005101520253035051015202530354030201000102030-0.553-0.56-0.559-0.558-0.557-0.556-0.555-0.5544005101520253035051015202530354030201000102030-0.545-0.575-0.57-0.565-0.56-0.555-0.55400510152025303505101520253035t = 0.6

t = 0.6, x1x2 view

t = 1.2

t = 1.2, x1x2 view

t = 1.8

t = 1.8, x1x2 view

Figure 16: Test 4. Backscattered data of the component E2 at ∂2(cid:101)Ω at diﬀerent times. The level of noise

in the data is σ = 10%.

30

4030201000102030-0.6223-0.6223-0.6223-0.6223-0.6223-0.6223-0.6223-0.62234005101520253035051015202530354030201000102030-0.568-0.57-0.572-0.574-0.576-0.5784005101520253035051015202530354030201000102030-0.545-0.54-0.55-0.555-0.56-0.565-0.57400510152025303505101520253035x ∈ ΩFEM : εh0(x) = 2.03

x ∈ ΩFEM : εrec(x) = 2.15

a) prospect view

b) prospect view

c) x1x2 view

d) x1x2 view

e) x2x3 view

f) x2x3 view

g) x1x3 view

h) x1x3 view

Figure 17: Test 4. Reconstruction obtained with two plane waves. We present reconstruction of the
four inclusions (in red color) obtained on the coarse mesh (left ﬁgures) and on the two times adaptively
reﬁned mesh (right ﬁgures). The level of noise in the data is σ = 10%. For comparison we also present
exact isosurfaces of the four small inclusions to be reconstructed (in light blue color).

31

Numerically we have tested the adaptive algorithms with two diﬀerent additive noise levels,
σ = 3%, and 10%, in the data. Our numerical tests show that with mesh reﬁnements, as was
expected, the quality of the reconstruction is improved a lot. Compare, for example, the results
of Figure 7 with those of Figure 8. Using these ﬁgures and tables 1 and 2 we observe that, with
mesh reﬁnements, the artifacts obtained on a coarse mesh are removed and the reconstructed
function εhk has more correct location in x3 direction.

We can conclude that we have supported the tests of our previous works [6–8, 30, 31, 38–40],
and have shown that the adaptive ﬁnite element method is powerful tool for the reconstruction
of coeﬃcients in Maxwell’s equations from limited observations.

Our adaptive algorithms can also be applied for the case when edge elements are used for the
numerical simulation of the solutions of forward and adjoint problems, see [41, 42] for ﬁnite ele-
ment analysis in this case. This, as well as development of diﬀerent techniques for iterative choice
of regularization the parameter in the Tikhonov functional, can be considered as a challenge for
future research.

For the applications to medical imaging, an additional important challenge, bot from a com-
putational and theoretical point of view, is the extension of the adaptive Lagrangian methods to
the case of a complex coeﬃcient. This corresponds to considering a conductive medium, which
is more realistic for organic tissues.

Acknowledgment

This research is supported by the Swedish Research Council (VR). The computations were per-
formed on resources at Chalmers Centre for Computational Science and Engineering (C3SE)
provided by the Swedish National Infrastructure for Computing (SNIC).

References

[1] A. Fhager, P. Hashemzadeh, and M. Persson. Reconstruction quality and spectral content of
an electromagnetic time-domain inversion algorithm. IEEE Trans. Biomed. Eng., 53:1594–
1604, 2006.

[2] P.M. Meaney, Q. Fang, T. Rubaek, E. Demidenko, and K.D. Paulsen. Log transformation
beneﬁts parameter estimation in microwave tomographic imaging. Med. Phys., 34:2014–
2023, 2007.

[3] P.M. Meaney, K.D. Paulsen, and T.P. Ryan. Two-dimensional hybrid element image recon-

struction for tm illumination. IEEE Trans. Antennas Propag., 43:239–247, 1995.

[4] T.M. Grzegorczyk, P.M. Meaney, P.A. Kaufman, R.M. diFlorio Alexander, and K.D.
Paulsen. Fast 3-d tomographic microwave imaging for breast cancer detection. IEEE Trans
Med Imaging., 31:1584–1592, 2012.

[5] L. Beilina. Adaptive ﬁnite element method for a coeﬃcient inverse problem for the Maxwell’s

system. Appl. Anal., 90:1461–1479, 2011.

[6] L. Beilina, M.V. Klibanov, and M.Yu. Kokurin. Adaptivity with relaxation for ill-posed
problems and global convergence for a coeﬃcient inverse problem. J. Math. Sci., 167:279–
325, 2010.

32

[7] L. Beilina, Nguyen T.T., M.V. Klibanov, and J.B. Malmberg. Reconstruction of shapes
and refractive indices from backscattering experimental data using the adaptivity. Inverse
Problems, 30:105007, 2014.

[8] L. Beilina, Nguyen T.T., M.V. Klibanov, and J.B. Malmberg. Globally convergent
and adaptive ﬁnite element methods in imaging of buried objects from experimental
backscattering radar measurements. J. Comput. Appl. Math., 2014. Article in press:
http://dx.doi.org/10.1016/j.cam.2014.11.055.

[9] W.T. Joines, Y. Zhang, C. Li, and R.L. Jirtle. The measured electrical properties of normal

and malignant human tissues from 50 to 900 mhz. Med. Phys., 21:547–550, 1994.

[10] J.B. Malmberg. A posteriori error estimate in the Lagrangian setting for an inverse problem
based on a new formulation of Maxwell’s system, volume 120 of Springer Proceedings in
Mathematics and Statistics, pages 42–53. Springer, 2015.

[11] P. Monk. Finite Element Methods for Maxwell’s Equations. Clarendon, Oxford, 2003.

[12] K.D. Paulsen and D.R. Lynch. Elimination of vector parasites in ﬁnite element Maxwell

solutions. IEEE Trans. Microwave Theory Techniques, 39:395–404, 1991.

[13] O.A. Ladyzhenskaya. The boundary value problems of mathematical physics, volume 49
of Applied Mathematical Sciences. Springer-Verlag, New York, 1985. Translated from the
Russian by Jack Lohwater [Arthur J. Lohwater].

[14] L.C. Evans. Partial diﬀerential equations, volume 19 of Graduate Studies in Mathematics.

American Mathematical Society, Providence, RI, second edition, 2010.

[15] H.W. Engl, M. Hanke, and A. Neubauer. Regularization of Inverse Problems, volume 375
of Mathematics and its Applications. Kluwer Academic Publishers Group, Dordrecht, 1996.

[16] A.N. Tikhonov, A.V. Goncharsky, V.V. Stepanov, and A.G. Yagola. Numerical Methods for

the Solution of Ill-Posed Problems. Kluwer Academic Publishers, Dordrecht, 1995.

[17] A.L. Bukhge˘ım and M.V. Klibanov. Uniqueness in the large of a class of multidimensional

inverse problems. Dokl. Akad. Nauk SSSR, 260(2):269–272, 1981.

[18] M.V. Klibanov. Uniqueness of the solution of two inverse problems for a Maxwell system.

Zh. Vychisl. Mat. i Mat. Fiz., 26(7):1063–1071, 1119, 1986.

[19] M. Bellassoued, M. Cristofol, and E. Soccorsi.

Inverse boundary value problem for the

dynamical heterogeneous Maxwell’s system. Inverse Problems, 28:095009, 2012.

[20] S. Li. An inverse problem for Maxwell’s equations in bi-isotropic media. SIAM J. Math.

Anal., 37:1027–1043, 2005.

[21] S. Li and M. Yamamoto. An inverse problem for Maxwell’s equations in anisotropic media.

Chin. Ann. Math. Ser. B, 28(1):35–54, 2007.

[22] A.B. Bakushinsky, M.Yu. Kokurin, and A. Smirnova. Iterative Methods for Ill-Posed Prob-

lems: An Introduction. De Gruyter, Berlin, 2011.

[23] S. Hosseinzadegan. Iteratively regularized adaptive ﬁnite element method for reconstruction
of coeﬃcients in Maxwell’s system. Master’s thesis in applied mathematics, Department
of Mathematical Sciences, Chalmers University of Technology and Gothenburg University,
2015.

33

[24] R. Becker, H. Kapp, and R. Rannacher. Adaptive ﬁnite element methods for optimal control
of partial diﬀerential equations: Basic concept. SIAM J. Control Optim., 39:113–132, 2000.

[25] K. Kraft and S. Larsson. The dual weighted residuals approach to optimal control of ordinary

diﬀerential equations. BIT, 50(3):587–607, 2010.

[26] C. Johnson and A. Szepessy. Adaptive ﬁnite element methods for conservation laws based

on a posteriori error estimates. Comm. Pure Appl. Math., 48:199–234, 1995.

[27] F. Courant, K. Friedrichs, and H. Lewy. On the partial diﬀerential equations of mathematical

physics. IBM J. Res. Develop., 11:215–234, 1967.

[28] O. Pironneau. Optimal shape design for elliptic systems. Springer-Verlag, 1984.

[29] WavES: the software package.

[30] L. Beilina. Energy estimates and numerical veriﬁcation of the stabilized domain decom-
position ﬁnite element/ﬁnite diﬀerence approach for the Maxwell’s system in time domain.
Cent. Eur. J. Math., 11:702–733, 2013.

[31] L. Beilina and S. Hosseinzadegan. An adaptive ﬁnite element method in reconstruction of
coeﬃcients in Maxwell’s equations from limited observations. To appear in Applications of
Mathematics, Springer, 2016. Preprint is available in arXiv:1510.07525, 2015.

[32] C. Eyraud, A. Litman, A. H´erique, and W. Kofman. Microwave imaging from experimental
data within a Bayesian framework with realistic random noise. Inverse Problems, 25:024005,
2009.

[33] A.E. Bulyshev, Souvorov A.E., S.Y. Semenov, V.G. Posukh, and Y.E. Sizov. Three-
dimensional vector microwave tomography: theory and computational experiments. Inverse
Problems, 20:1239–1259, 2004.

[34] W.C. Chew and Y.M. Wang. Reconstruction of two-dimensional permittivity distribution

using the distorted born iterative method. IEEE Trans. Med. Imaging, 9:218–225, 1990.

[35] N. Joachimowicz, C. Pichot, and J.P. Hugonin. Inverse scattering: and iterative numerical

method for electromagnetic imaging. IEEE Trans. Antennas Propag., 39:1991, 1991.

[36] C. Eyraud, J.-M. Geﬀrin, and A. Litman. Complex permittivity determination from far-ﬁeld

scattering patterns. IEEE Antennas and Wireless Propagation Lett., 14:309–312, 2015.

[37] C. Eyraud, J.-M. Geﬀrin, and A. Litman. 3-d imaging of a microwave absorber sample from
microwave scattered ﬁeld measurements. IEEE Microwave and Wireless Components Lett.,
25:472–474, 2015.

[38] L. Beilina. Adaptive hybrid FEM/FDM methods for inverse scattering problems. Inverse

problems and information technologies, 1:73–116, 2002.

[39] L. Beilina and C. Johnson. A posteriori error estimation in computational inverse scattering.

Math. Models Methods Appl. Sci., 1:23–35, 2005.

[40] L. Beilina and C. Clason. An adaptive hybrid fem/fdm method for an inverse scattering

problem in scanning acoustic microscopy. SIAM J. Sci. Comp, 28:382–402, 2006.

[41] P. Ciarlet Jr. and J. Zou. Fully discrete ﬁnite element approaches for time-dependent

Maxwell’s equations. Numerische Mathematik, 82:193–219, 1999.

34

[42] P. Ciarlet Jr., H. Wu, and J. Zou. Edge element methods for Maxwell’s equations with

strong convergence for gauss’ laws. SIAM J. Numer. Anal., 52:779–807, 2014.

35

