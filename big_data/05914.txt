6
1
0
2

 
r
a

M
 
8
1

 
 
]

.

M
R
n
i
f
-
q
[
 
 

1
v
4
1
9
5
0

.

3
0
6
1
:
v
i
X
r
a

Statistically similar portfolios and systemic risk

Stanislao Gualdi,1 Giulio Cimini,2, 3 Kevin Primicerio,1 Riccardo Di Clemente,4 and Damien Challet1, 5

1Laboratoire de Math´ematiques Appliqu´ees aux Syst`emes,

Centrale Sup´elec, 92290 Chˆatenay-Malabry, France

2IMT - School for Advanced Studies, 55100 - Lucca, Italy

3Istituto dei Sistemi Complessi (ISC)-CNR, 00185 Rome, Italy

4MIT - Massachusetts Institute of Technology, Cambridge, MA 02139, United States

5Encelade Capital SA, 1015 Lausanne, Switzerland

(Dated: March 21, 2016)

We propose a similarity measure between portfolios with possibly very diﬀerent numbers of assets
and apply it to a historical database of institutional holdings ranging from 1999 to the end of 2013.
The resulting portfolio similarity measure increased steadily before the 2008 ﬁnancial crisis and
reached a maximum when the crisis occurred. We argue that the nature of this measure implies
that liquidation risk from ﬁre sales was maximal at that time. After a sharp drop in 2008, portfolio
similarity resumed its growth in 2009, with a notable acceleration in 2013, reaching levels not seen
since 2007.

I.

INTRODUCTION

The 2007 − 2008 ﬁnancial crisis has drawn the attention of both academics and regulators to the complex inter-
connections between ﬁnancial institutions, and called for a better understanding of ﬁnancial markets especially from
the viewpoint of systemic risk [1–3].
In this respect, much eﬀort has been devoted to the study of counter-party
and roll-over risks caused by loans between institutions [1, 4, 5] while the ownership structure of ﬁnancial assets has
received relatively less attention, primarily because of lack of data and of powerful analysis techniques. Yet, while in
traditional asset pricing theory the ownership structure of ﬁnancial assets does not play any role, there is increasing
evidence that it is a potential source of non-fundamental risk, and, as such, can be used for instance to forecast stock
price ﬂuctuations unrelated to fundamentals [6, 7]. More worryingly, if institutional portfolios are too similar (as mea-
sured by the fraction of common asset holdings, or portfolio overlap), this may trigger ﬁre sales, which is an important
channel for ﬁnancial risk contagion and therefore contributes to systemic risk [3, 8–10]: in the presence of ﬁre sales,
losses by ﬁnancial institutions with overlapping holdings become self-reinforcing and trigger further simultaneous sell
orders, leading to downward spirals for asset prices. The point is that ﬁre sale risk builds up gradually, but reveals
itself rapidly.

This contribution proposes a new measure of portfolio overlap based on null statistical network models. Whereas
the data only contains links (investments) between institutions and assets, the problem consists in establishing links
between institutions based on the assets they own, or between assets based on their investors. In order to simplify the
present discussion, let us focus on institutions for the time being. In a naive view, two institutions are linked as soon
as their portfolios contain at least one common asset; this adds too many links. Another simple way is to compute
the fraction of common holdings between two institutions, which deﬁnes a weighted network with as many links as
the previous method. Here, we propose to ﬁnd which institutions have strikingly similar holdings, i.e., to build a
non-weighted network of institutions based on the probability that the similarity between two portfolios is not due
entirely to chance alone.

Determining this probability requires to solve a technical problem caused by the heterogeneity of both institution
sizes and asset capitalizations. For example, it is hard a priori to compare a portfolio with very few assets and one
with very many assets. However, as we shall see, bipartite conﬁguration models provide suitable null network models
that obey certain constraints, allowing us easily to build a proper statistical test and to ﬁnd signiﬁcant portfolio
overlaps.

When applied to a historical database of SEC 13-F ﬁlings, our method yields networks of statistically overlapping
portfolios whose properties turn out to be related to the occurrence of the 2008 ﬁnancial crisis. In particular, we
propose to regard the average number of links between institutions (i.e., the number of statistically similar portfolio
overlaps) as a simple measure of ﬁre sale risk. This measure gradually built up in 2004-2008, and quickly decreased in
2008. Because there is only one large crisis in our dataset, we refrain from making strong claims about the systematic
coincidence of highly connected validated networks and the occurrence of ﬁnancial crises. At any rate, our measure
of portfolio similarity has been increasing since 2009 and reached at the end of 2013 a value not previously seen since
2007.

The reminder of the paper is organized as follows: Sec. II introduces the dataset. In Sec. III we explain the method
used to build the network of similar portfolios. In Sec. IV we present and discuss the main results, while Sec. V is the

2

FIG. 1. Basic statistics of the dataset: number of securities |S(t)|, institutions |I(t)|, links L(t) (ownership relations) and total
market value M V (t) at diﬀerent dates.

conclusion.

II. DATASET

We extracted 13-F SEC ﬁlings (https://www.sec.gov/) from the Factset Ownership database from 1999Q1 to
2013Q4. Institutions holding more than 100 million dollars in qualifying assets must report their long positions to
the SEC at the end of each trimester. The dataset is composed of a set I(t) of approximately 1500÷ 3500 institutions
(Fig. 1 reports the time evolution of |I(t)|). They hold positions from a universe of S(t) securities, whose size |S(t)|
ﬂuctuates around 12500 (see Fig. 1). Note that the portfolios of sub-funds are merged into a single report. In addition
to the raw ownership data, our dataset is complemented by meta-data about both institutions and securities. An
institution is classiﬁed into several categories: Broker (BR), Hedge Fund (HF), Investment Adviser (IA), Mutual
Fund (MF), Pension Fund (PF), Private Banking (PB), or other.1 Meta-data about securities include price and the
number of outstanding shares for each date t. In addition, we classify securities according to the Bloomberg Industry
Classiﬁcation Systems (BICS) [11], which rests on their primary business, as measured ﬁrst by the source of revenue
and second by operating income, assets and market perception. Each security belongs to one of the following sectors:
Communications, Consumer Discretionary, Consumer Staples, Energy, Financials, Health Care, Industrials, Materials,
Technology, Utilities (or other).

III. METHODS

A. Data representation

The dataset of 13-F ﬁlings described above deﬁnes an ownership matrix W(t) for each quarter t, of dimension
|I(t)| × |S(t)| whose element Wis(t) denotes the number of shares of security s ∈ S held by institution i ∈ I(t). In
network theory language, this matrix represents a bipartite network: there are two distinct categories of elements
or nodes (institutions and securities), and connection or links (representing ownership relations) are established only

1 We label as ‘others’ funds having no classiﬁcation or belonging to an almost empty category.

1011121320002002200420062008201020122014datenumber of securities x 10-32320002002200420062008201020122014datenumber of institutions x 10-30.40.60.81.020002002200420062008201020122014datenumber of links x 10-6510152020002002200420062008201020122014datetotal market value x 10-123
between nodes of diﬀerent categories. We then map W(t) into a binary bipartite ownership matrix A(t) = sign Wt
(where its generic element Ais(t) = 1 if Wis(t) > 0 and 0 otherwise)2. Figure 1 summarizes the time evolution of the
main aggregate quantities characterising these bipartite networks: the number of institutions |I(t)|, the number of
is Wisps(t)
s Ais(t) of an institution i is
i Ais(t) of a security s is the number of
investors holding this security at t. In the following subsections we will omit the explicit time dependence of the
quantities considered, since the same procedure is repeated for each date.

securities |S(t)|, the number of links among them L(t) =(cid:80)
in the dataset, where ps(t) is the price of security s at time t. The degree di(t) = (cid:80)
the number of securities it owns at time t. Similarly, the degree ds(t) =(cid:80)

is Ais(t) and the total market value M V (t) =(cid:80)

B. Network projection and link validation

Using the bipartite network A of institutions and securities as the starting point, in this section we aim at inferring
links between institutions themselves, based on the similarity of their asset portfolios. Technically, our task is to
project the bipartite network into a monopartite network where links represent signiﬁcant portfolio overlaps between
institutions. The term “monopartite” here means that there is a single category of nodes, and links between nodes
can be established without restrictions. Note that the monopartite projection can be performed on either of the two
sets of the bipartite network. In the following, without loss of generality, we will speak about the projection on the
institutions layer and apply our method to the securities layer later on.
bipartite adjacency matrix, so that the generic element (i, j) of the monopartite portfolio overlap matrix O reads:

The simplest and most common approach to project a bipartite network consists in performing a contraction of the

oij =

AisAjs − δijdi

(1)

(cid:88)

s

where δij is the Kronecker delta. In our context, oij is the number of securities held by both institutions i and j,
namely their overlap. While straightforward, this method has the important drawback of generating unrealistically
dense projections, i.e., it yields too many links. This is because each realized overlap also includes the securities that
are held in common just by chance. Thus, in order to distinguish the true signal of overlapping portfolios from the
underlying random noise, each link of the projected network (i.e, each pair of institutions holding at least one asset
in common, so that oij ≥ 1), has to be independently validated against the null hypothesis of random co-occurrence
of common assets. In other words, we aim at identifying statistically signiﬁcant overlaps that cannot be explained by
the null hypothesis.
Link validation is achieved through the following procedure. For each pair of institutions (i, j) having overlap oij,
one ﬁrst computes the expected overlap (cid:104)oij(cid:105) and its probability distribution f (·|i, j) under the null hypothesis. The
signiﬁcance of oij is then quantiﬁed through a p-value P (oij):

P (oij) = 1 −

f (x|i, j),

(2)

where the right-hand size of Eq. (2) is the cumulative distribution function of f (·|i, j), namely the probability to have
an overlap larger or equal than the observed one (oij) under the null hypothesis. If such a p-value is smaller than
a certain threshold P ∗, we validate the link between i and j and place it on the monopartite validated network of
institutions, otherwise, the link is discarded. This procedure is repeated for all pairs of institutions, resulting in the
validated projection V of the original network: a monopartite network whose generic element Vij = 1 if P (oij) < P ∗,
and 0 otherwise.
Two issues remain open from the above-described procedure. The ﬁrst one is the choice of an appropriate threshold
P ∗, which has to account for the multiple hypothesis tested (corresponding to the number npairs of possible pairs
of institutions). Here we use the rather strict Bonferroni correction [12], meaning that we set the threshold to
P ∗ = /npairs.3 The second issue, that will be dealt with in the rest of the section, is the choice of a proper null
hypothesis to compute p-values from.
Before moving further, we should point out why we use the binary matrix A and not the original weighted W in the
validation procedure. Indeed, using directly W would allow to obtain weighted overlaps oW
s Wis,

ij =(cid:80)

s WisWjs−δij

(cid:80)

oij−1(cid:88)

x=0

2 As the 13-F dataset contains only positions greater than 10 000 shares or $ 200 000 , very small positions are already ﬁltered out.
3 The choice of the threshold is indeed arbitrary. In this work we use the Bonferroni correction with  = 10−3; yet, we have tested our
method with various values of , and tried also the less-strict false discovery rate (FDR) criterion [13], without ﬁnding major qualitative
diﬀerences. In fact, while the ﬁnal size of the validated network clearly depends on the threshold, the relative temporal changes of the
network are much less aﬀected by the particular threshold used.

which may seem more relevant than binary overlaps to identifying ﬁre sales propagation channels. Yet, in this case it
would be impossible to build an analytical null model, which would make the validation procedure extremely involving.
Thus, we are forced to rely on binary overlaps, keeping in mind that much of the original weighted information can be
inferred from the structure of the validated network (see section Results for more detailed discussions on this point).

4

1. p-values from the hypergeometric distribution

A method recently proposed by Tumminello et al. [14] builds on a null model based on homogeneous networks of
securities. This is achieved by dividing the original bipartite network A into subnetworks {A(k)}, each consisting of
all securities with degree ds = k and all institutions linked to them. In this way, the null hypothesis that institutions
randomly connect to securities translates into a probability for the pair (i, j) to have an overlap equal to x in A(k)
given by the hypergeometric distribution:

ρ (x| d(k)

i

, d(k)

j

, S(k)) =

,

(3)

(cid:0)d(k)

i
x

(cid:1)

(cid:1)(cid:0)S(k)−d(k)
(cid:1)
(cid:0)S(k)

j −x
d(k)

i

d(k)
j

ij −1(cid:88)

x=o(k)

and S(k) are, respectively, the degree of institution i and the number of securities in A(k). Now, if o(k)

is

ij

where d(k)
the actual overlap of i and j in A(k), eq. (2) becomes:

i

P (o(k)

ij ) = 1 −

ρ(x|d(k)

i

, d(k)

j

, S(k)).

(4)

x=0

Note that because of the initial division in homogeneous subnetworks, a link between two institutions may be validated
more than once.

Given that the applied validation threshold is strict enough to ensure that two institutions connected by a link
display a strikingly similar pattern of investments, this method has the advantage of drastically reducing the original
amount of links and of obtaining a much sparser validated network with a clearer meaning. However, there are some
intrinsic limitations of this procedure, which motivate us to adopt an alternative methodology that we discuss below.
The point is that in many real situations entities are characterized by a high degree of heterogeneity with respect
to nodes degree: some nodes have only a few links, some others instead have hundreds of them.
In our context,
for instance, securities are characterized by a strongly heterogeneous number of investors (approximately power-law
distributed). This implies that the process of splitting the original bipartite network into homogeneous subnetworks
with securities having the same degree often translates into almost empty subsets—especially for securities held by a
large number of investors. In these subsets, overlaps can assume only a few values, bounded by the limited number
of securities considered, resulting in a handful, spaced-out possible outcomes for the p-values. The problem then
In fact, since institutions are
arises with the use of a global threshold corrected for multiple hypothesis testing.
= I 2 maxs ds: the
compared on the many subnetworks of securities with the same degrees, npairs scales as I 2dmax
validation threshold becomes extremely small for large and heterogeneous systems and vanishes in the inﬁnite size
limit. These issues lead to a serious problem of resolution, since P ∗ is too small to validate even the smallest non-
zero p-value in most of the subnetworks. As a result, the validated network becomes almost empty by construction.
Overall, while the method works well for small networks with little degree heterogeneity, the same approach is not
feasible in the case of large scale and highly heterogeneous networks. A possible solution to the problem is to perform
the statistical validation of links without taking into account degree heterogeneity [14], which however cannot be
formalized analytically since the events of choosing diﬀerent securities have now diﬀerent occurrence probabilities.
Choosing an ad hoc threshold is also feasible but we advocate an alternative statistically-grounded method to validate
links.

s

2. p-values from the Bipartite Conﬁguration Model (BiCM)

The method we employ in this work builds on a null hypothesis derived from the Bipartite Conﬁguration Model
(BiCM) [15]—an extension of the standard Conﬁguration Model [16] to bipartite graphs. We use the BiCM as it
does not require the homogeneity of neither layer of the network. Additionally, it oﬀers a simple and general way to
generate null-model bipartite networks that preserve essential features of the real system. We remand the reader to
Park and Newman [16], Squartini and Garlaschelli [17] and Saracco et al. [15] for more details on the method.

In a nutshell, the BiCM prescribes to build the null model simply as the ensemble Ω of bipartite networks that are
maximally random, under the constraints that their degree sequence is, on average, equal to the one of the original
network. This is achieved through maximization of the Shannon entropy of the network subject to these constraints,
that are imposed through a set of Lagrange multipliers {θi}I
s=1 (one for each node of the network).
Solving the BiCM means exactly to ﬁnd these multipliers, that quantify the abilities of nodes to create links with
other nodes. Thus, importantly, nodes with the same degree have by construction identical values of their Lagrange
multipliers. Once these multipliers are found, the BiCM prescribes that the expectation values within the ensemble of
the network matrix element (cid:104)Ais(cid:105)Ω, i.e., the ensemble probability Qis of connection between nodes i and s belonging
to diﬀerent layers, is given by:

i=1 and {θs}S

5

(cid:104)Ais(cid:105)Ω ≡ Qis =

θiθs

(5)
and the probability of occurrence Q(A) of a network A in Ω is obtained as the product of these linking probabilities
Qis over all the possible I × S pairs of nodes. In other words, links are treated as independent random variables, by
deﬁning a probability measure where links correlations are discarded. The key feature of the BiCM model is that the
probabilities {Qis} can be used to directly sample the ensemble of bipartite graphs, or to compute the quantities of
interest. Here we use the matrix Q to compute the expectation values of portfolios overlap between two institutions
i and j as:

1 + θiθs

,

or to associate a p-value to each realized overlap oij through:

(cid:104)oij(cid:105)Ω =

QisQjs,

(cid:88)

s∈S

x=oij−1(cid:88)

x=0

P (oij) = 1 −

π(x|di, dj).

(6)

(7)

In the latter expression, π(·|di, dj) is the probability distribution of the expected overlap under the null hypothesis
of random connections in the bipartite network—which, according to the BiCM prescription, only depends on the
degrees of institutions i and j. Indeed, π(·|di, dj) is actually the distribution of the sum of S independent Bernoulli
trials, each with probability QisQjs. This distribution can be computed either analytically [18] or numerically.4 For
large-scale networks, the computational complexity of the numerics can be substantially reduced by recalling, again,
that Qis ≡ Qis(cid:48) if ds ≡ ds(cid:48) ∀i: connection probabilities only depends on nodes degree values. This is an important
observation, which translates into the following statement: the expected overlap between any two institutions i and j
restricted to the set of securities with a given degree follows a binomial distribution with probability QisQjs (where s
is one of these securities) and number of trials equal to the cardinality of such set. More formally, if { ˜dh}dmax
h=1 denotes
the set of diﬀerent degrees within securities, ˜nh is the number of securities having degree ˜dh, h is any security having
ij(cid:105)Ω between institutions i and j restricted to
degree ˜dh, and if we deﬁne qh
securities having degree ˜dh follows the binomial distribution

ij = QihQjh, then the expected overlap (cid:104)oh

s

(8)
The overall distribution π(·|di, dj) can now be more easily obtained as the sum of (much fewer than S) binomial
random variables [20]: if π≤h(·|di, dj) is the distribution of the overlap restricted to securities with degree smaller or
equal than h, we have

ij) =

x

πh(x|˜nh, qh

ij]x[1 − qh
[qh

ij]˜nh−x.

(cid:18)˜nh

(cid:19)

π≤h(x|di, dj) =

π≤h−1(x − k|di, dj)πh(x|˜nh, qh
ij)

(9)

x(cid:88)

k=0

and π(·|di, dj) = π≤dmax
binomial distribution: starting from πh(0|˜nh, qh

s

(·|di, dj). For this computation, it is useful to recall the peculiar recurrence relation of the

ij) = [1 − qh
˜nh − x + 1

x

πh(x|˜nh, qh

ij) =

ij]˜nh, each subsequent probability is obtained through:

qh
ij
1 − qh

ij

πh(x − 1|˜nh, qh
ij).

(10)

4 In order to compute the probabilities used in Eq. (7), alternatively to our optimized numerical approach, it is possible to use an

analytical method based on Hong [18]. The latter approach has been developed by Saracco et al. [19] in parallel with our research.

6

FIG. 2. Two examples of institutions pairs (green nodes) with the securities they own (yellow nodes). The composition of
each portfolio is denoted by diﬀerent colors (blue and orange links). The symbol size of a security is proportional to the total
number of its investors. Although both pairs in the plot have an overlap of 50 securities, the right pair is validated by the
algorithm whereas the left pair is not. This is due to the fact that the both the blue and orange portfolios on the left are
smaller (the blue one in particular) and therefore under the BiCM null model the chance of having the same overlap of the pair
on the right is considerably smaller.

Once the distribution π(·|di, dj) is obtained, the p-value P (oij) can be associate to the overlap between each pair of
institutions i and j, and the corresponding link can be placed on the validated monopartite network provided that
P (oij) ≤ P ∗. Note that since this computation is made on the whole network, i.e., considering all the securities,
we have a fairly large spectrum of possible p-values. Thus, also if we still use a threshold depending on the number
of hypothesis tested (which however now scales just as I 2), we have a much higher resolution than in the previous
case [14], and can obtain non-empty and denser validated networks.

IV. RESULTS

A.

Institutions

1. Examples

We analyse here the validated networks of institutions built from the validation procedure described above. Before
presenting the results we obtain at the aggregate level, it is useful to understand the results of our method in a speciﬁc
example. Fig. 2 shows two similar situations: two pairs of portfolios both sharing 50 securities. Only the left pair is
validated by our method, whereas, the right pair is not. This happens because the portfolios in the left pair are of
smaller size (especially the blue one) and the same overlap is therefore considerably less likely to happen by chance.
Hence, although the algorithm cannot directly take into account how much each institution is investing (particularly
with respect to the total asset managed by the institution), it does so indirectly by taking into account the degree
of institutions. Validated pairs of portfolios indeed correspond to overlaps which constitute a considerable fraction of
the total portfolio value of the pair. In short, pairs are validated when neither the diversiﬁcation of the investments
nor the degree sequence of the securities are suﬃcient to explain the observed overlap. As we shall see later, the same
mechanism is at play when we project the bipartite network on the securities side. In this case, since the degree of
a security is a good approximation of its capitalization and of the dilution of its ownership [21, 22], the method will
tend to validated links among securities whose ownership is relatively concentrated.

llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll7

FIG. 3. Validated networks of institutions at 2006Q4 (1293 institutions and 93602 validated links). Vertices colors are assigned
on the basis of institution types, while their size is given by the logarithm of their degree centrality (computed in the validated
network as dV

i =(cid:80)

j Vij).

2. Time evolution of validated institution networks

After these preliminary observations, we move to the analysis of the structural properties and of the temporal
evolution of the whole validated network. To get an idea of how the networks look like, we plot in Fig. 3 the snapshot
of the validated network taken at the end of 2006. In general, we observe the presence of multiple small clusters of
institutions, together with a signiﬁcantly larger cluster composed by many institutions linked by a complex pattern
of signiﬁcant overlaps. In Fig. 4 we show the fraction of validated institutions (deﬁned as the number of institutions
having at least one validated link, over the total number of institutions appearing in the bipartite network) as a
function of time. We also disaggregate data according to the type of institution and plot in this case both the
number of validated institutions and the original number of institutions (we avoid to use directly their ratio for a
better visualization). One sees that there is no particular pattern and the fraction of validated institutions is almost
constant in time. By looking at disaggregated data few interesting things emerge. Investment Advisors account for
the largest percentage of institutions and, more prominently, of validated institutions, followed by Hedge Funds and
Mutual Funds. The most interesting behavior is however that of Hedge Funds in the validated networks: they are
relatively under-represented until 2004, but after that their number displays a steep increase.

Fig. 5 display the temporal evolution of the average degree in the validated network, which measures how much
validated institutions are connected to each other. One clearly sees an overall increasing trend with a strong accelera-
tion during the years preceding the ﬁnancial crisis. In particular, the average degree reaches a maximum few months
before prices started to fall. Furthermore, our results suggest that a similar process is taking place after 2009, a fact
that might question the stability of ﬁnancial markets nowadays. The right-hand side plot of Figure 5 reports the same
quantity for each category of institutions, which also has peaks just before the 2008 crash. The notable exception
is Hedge Funds, whose average degree is roughly constant in time. In addition, the peak for Investment Advisors,
Private Banking funds and Brokers occurs roughly 1 − 2 quarters before the global peak.

8

FIG. 4. Top row: Fraction of institutions appearing in the validated network as a function of time. Bottom row: total number
of institutions in the original bipartite network (left plot) and number of validated institutions (right plot) for the diﬀerent
institution types.

FIG. 5. Average degree of institutions in the validated network, aggregated (left plot) and separated for the diﬀerent institutions
type (left plot) as a function of time. The vertical line correspond to the date in which we observe the maximum total market
value in the dataset just before prices started to fall during the ﬁnancial crisis (see Fig. 1). Remarkably, we observe a slow
but steady build-up of portfolios similarity with a clear acceleration in the years preceding the ﬁnancial crisis and from 2009
onwards.

0.4000.4250.4500.4750.50020002002200420062008201020122014datefraction of validated institutions1.52.02.53.020002002200420062008201020122014datenumber of institutions (log10)entity_sub_typeBRHFIAMFOthersPBPF1.52.02.53.020002002200420062008201020122014datenumber of validated institutions (log10)entity_sub_typeBRHFIAMFOthersPBPF405060708020002002200420062008201020122014dateaverage degree05010015020002002200420062008201020122014dateaverage degreeentity_sub_typeBRHFIAMFOthersPBPF9

FIG. 6. Scatter plot of the average share of securities market value in a portfolio (cid:104)wi(cid:105) = (cid:80)

s wis versus the inverse of the
portfolio diversiﬁcation 1/di. The average over all securities in a portfolio gives the inverse of the degree by construction
(corresponding to the straight line in the plot). Here we divide the average over overlapping securities (i.e., securities in the
portfolio belonging to the overlap with a validated neighbor) and non-overlapping securities (the complementary set). One
clearly sees that overlapping positions correspond to stronger weights in the portfolio. The plot refers to 2006Q4; the same
qualitative behavior is observed for other dates.

3. Statistically signiﬁcant overlap vs portfolio size and asset capitalization

A seemingly major shortcoming of using a binary holding matrix A is that it does not take into account neither the
concentration of ownership of a given security (i.e., which fraction of the outstanding shares a given fund is holding)
nor the relative importance of diﬀerent securities in a portfolio (i.e., which percentage of the total portfolio market
value a security is representing). These are clearly important types of information, since one would expect a mild
price impact following the liquidation of the asset by an institution if the latter owns only a small fraction of the
security’s outstanding shares. Conversely, if the asset represents a considerable fraction of the portfolio market value,
a price drop will have a stronger impact on the balance sheet of the institution. The dataset at our disposal allows
us however to measure these fractions and thus to check a posteriori the features of the portfolio positions which
contributed to the formation of validated pairs of institutions.

the fraction of the total market value of portfolio i represented by security s, namely wis = psWis/(cid:80)

To this end, using the information about the price ps and outstanding shares σs of diﬀerent securities s, we compute
x pxWix, and
the fraction of outstanding shares of s held by institution i, namely cis = Wis/σs. We apply this procedure to each
position Wis of the bipartite network. We can then characterise the inﬂuence of belonging to a statistically validated
network of portfolio overlap. For example, the average share of securities in a portfolio i equals 1/di by construction.
Using this simple measure we ﬁnd that, on average, ‘overlapping’ securities (i.e., securities making up the validated
overlaps) represent a larger average share of the portfolio, namely 6% more than the average 1/di. In Fig. 6 we show a
scatter plot of the average share for each fund (both over overlapping and non overlapping securities) as a function of
its diversiﬁcation of investments. We then see that overlapping securities correspond to larger shares of the portfolio.

for the liquidity of the security) as well as the average ownership fraction per fund (cid:104)ci(cid:105) =(cid:80)

Let us now turn to the concentration of ownership of diﬀerent securities. We use the following procedure: each
security s belongs by construction to ds(ds − 1)/2 pairs of overlapping portfolios and we can compute which fraction
fs of such pairs is validated by the algorithm. We then compute for each security the total capitalization (as a proxy
i cis/ds as a function of
fs. In Fig. 7 we show scatter plots of this quantities together with straight lines obtained from linear regressions. As
one can see, the probability that any pair of institutions investing in the same asset are validated by the algorithm
decreases as a function of the capitalization of the asset, increases as a function of the concentration (i.e., with the
average fraction of outstanding shares detained by a fund) and decreases as a function of the degree of the security.
The relation is stronger for securities with higher degree because of the larger number of available data points.

−8−6−4−2−3−2di-1 (log10)<wi> log(10)flagnon overlappingoverlapping10

FIG. 7. Scatter plots of the fraction fs of validated pairs owning a security s versus the security capitalization (left plot), its
concentration (central plot) and number of owners (right plot). The straight lines show linear regressions of the data, divided
according to securities degrees. Plots refer to 2006Q4; the same qualitative behavior is observed for other dates.

4. Fund distress in validated networks

As an additional test of the eﬀectiveness of the validation procedure we study the ability of the algorithm to
retrieve (pairs of) funds which are about to suﬀer signiﬁcant losses. The dataset at our disposal indeed covers periods
of ﬁnancial distress (in particular the 2008 ﬁnancial crisis) and it is in such periods that one would expect some
funds to incur ﬁre sales. Then, if the algorithm does ﬁlter information in a useful way, the presence of a validated
link between two funds would represent a channel for the propagation of losses. We do not attempt here to design a
test for detecting self-reinforcing ﬁre sales. Rather, we check if the presence of a validated link ultimately contains
information on the occurrence of losses.
To this end, we construct for each date t the set Ln of the n funds experiencing the highest drop in portfolio
value between t and t + dt (which we refer to as ‘distressed’ funds). We use here n = 300 (roughly corresponding
to 10% of the total number of funds) and omit in the following the n subscript. We then compute the fraction l
of distressed funds with respect to the total number of funds I and compare it with the fraction of distressed funds
lV in the validated network. The ratio GI = P (i ∈ L| i ∈ V)/P (i ∈ L) = lV /l then indicates if distressed funds
are over-represented in the validated network. Indeed, if GI = 1 the algorithm is not doing anything better than
putting distressed funds at random in the validated network, whereas, if GI > 1 we eﬀectively gain information
by knowing that a fund belongs to V. Similarly, we compare the fraction of links in the validated network which
connect institutions that are both distressed with the fraction of such links when all overlapping pairs (i.e. all pairs of
portfolios having at least one security in common) are considered. The ratio R between these two quantities, namely
RI = P (i, j ∈ L| Vij = 1)/P (i, j ∈ L|oij > 0), can then be used to assess the eﬀectiveness of the algorithm to establish
a link between two distressed institutions in the validated network.

Since all the positions in our data set are long positions, it makes sense to relate GI and RI to an index that
encompasses many securities. Fig. 8 shows GI(t) and RI(t) as a function of the market return r(t) between t and
t + dt as measured by the Russell 2000 index. Indeed, both ratios are correlated with the total loss and signiﬁcantly
larger than 1 when r(t) (cid:28) 0 (RI in particular reaches values close to 8 in periods of major ﬁnancial distress). Notably,
both ratio are close to 1 when the market loss is close to 0, and decline afterwards. This could be interpreted as
the fact that, in times of market euphoria, overlapping portfolios turn into self-reinforcing bubbles. Overall, these
analyses provide a strong evidence for the validity of the method we present in this paper.

B. Securities

We now discuss the results of the validation procedure applied to the layer of securities. In this case, the presence
of a validated link between two security reﬂects the fact that they share a signiﬁcantly similar set of owners, which
again translates into a potential contagion channel through ﬁre sales—but now connecting assets. Figure 9 shows
the temporal evolution of aggregate features for the validated projection on securities. Contrarily to the case of the
institutional projection (Figure 4 and Fig. 5), here we observe a stable growth of validated securities: there are
more and more stocks that can be involved in a potential ﬁre sale (or closing down of similar funds). Moreover, as
testiﬁed by the growth of the average degree of validated securities, the validated network becomes denser, signaling
the proliferation of contagion channels for ﬁre sales. Note the presence of local maximal that correspond to all major
ﬁnancial crises covered by the database: the dot-com bubble of 2001, the global ﬁnancial crisis of 2007-2008 and the

0.000.250.500.751.004681012psss (log10)fsds>1ds>5ds>5000.000.250.500.751.00−5−4−3−2−10<ci>fsds>1ds>5ds>5000.000.250.500.751.00123ds (log10)fsds>1ds>5ds>50011

FIG. 8. Scatter plots of the ratios GI (left panel), i.e. the ratio between the probability of observing a distressed fund in the
validated network and the a-priori probability of observing a distressed fund, and RI (right panel), i.e. the ratio between the
probability of observing a linked pair of distressed funds in the validated network and the probability of observing a distressed
pair of funds when all overlapping portfolios are considered, versus the return r(t) between t and t + dt of the Russell 2000
index. Red points correspond to dt equal to one quarter, blue points to dt equal to two quarters; solid lines are loess regressions
computed with the R package ’stats’ with default values. Panels are divided in four regions, corresponding to probabilities
larger/smaller than one (i.e., distressed funds over/under represented in the validated networks) and to r(t) larger/smaller than
zero (i.e., market contraction/growth).

FIG. 9. Fraction of securities appearing in the validated network (left plot) and average degree in the validated network (right
plot) as a function of time. Diﬀerently from the validated network of institutions, here the number of validated securities grows
steadily in time. Yet, the number of validated links grows at a faster peace, as demonstrated by the increasing average degree.
Remarkably, the latter show peaks in correspondence of ﬁnancial crises.

European sovereign debt crisis of 2010-2011. As for the case of institutions, the similarity in securities ownerships
reached its maximum levels at the end of the considered time span.

The fact that the average degree of the securities network keeps growing boils down to the fact that funds choose
securities, not the opposite. Whereas the number of institutions in our dataset has increased over the years, the
number of securities has been roughly constant. If a new institution selects at random which assets to invest in, then
the average degree of the securities network would stay constant. This is not the case, if only because of liquidity
constraints. Therefore, on average, a new institution’s portfolio is correlated with the ones of pre-existing institutions.
In order to detect if the observed patterns concern peculiar classes of securities, we perform an analysis of the
validated network distinguishing securities according to the BICS category they belong to (Fig. 10). In particular,
we try to detect whether securities of the same category tend to be connected together in the validated network. To
this end, we denote as ‘internal’ a validated link connecting two securities with the same BICS label, and we compute
the ‘internal’ degree as the degree of a security restricted to internal links. We thus observe that the categories of

0.51.01.5−0.2−0.10.00.10.2Russell 2000 returnGIdt1Q2Q02468−0.2−0.10.00.10.2Russell 2000 returnRIdt1Q2Q0.050.100.150.2020002002200420062008201020122014datefraction of validated securities25507520002002200420062008201020122014dateaverage degree12

FIG. 10. Statistics of the validated networks of securities, disaggregated by BICS category: fraction of validated securities
(upper left panel), total number of securities in the original bipartite network (upper right panel), average internal degree
(lower left panel) and internal links (lower right panel) in the validated network. The latter two quantities are obtained by
considering only validated links connecting securities of the same category.

securities that are more connected internally are (notably) Financials and, to a lesser extent, Consumer Discretionary.5
This does not show that portfolio overlaps concentrate on these categories, but rather that relatively more contagion
channels exist within securities belonging to them.

V. DISCUSSION

In this work, we have proposed a method to infer statistically robust links between funds based on similar patterns
of investment. The method solves the problem of evaluating the probability that the similarity of two portfolios of
very diﬀerent sizes is due to random holding of assets. The use of an appropriate model considerably improves the
statistical signiﬁcance of the detected features of the validated networks. Note that the method is general, and can
be applied to any bipartite network where the presence of (unlikely) similar sets of neighbors is of interest.

The present study then points to the conclusion that, just before ﬁnancial crises or bubble bursts, the similarity of
institutions holdings increases markedly. Perhaps worryingly for equity markets, the proposed proxy of ﬁre sale risk,
having reached a peak in 2008 and subsequently much decreased, has been increasing again from 2009 to the end of
our dataset (2013) up to levels not seen since 2007.

We have only investigated the portfolio overlap, not the probability that it leads to ﬁre sales. The relationship
between holdings and future portfolio changes must therefore be better characterized. Indeed, although two institu-
tions with diﬀerent strategies converge to a similar portfolio, this does not imply that they will update the latter in
the same way and at the same time. However, it is likely that part of the funds follow (in ﬁne) equivalent strategies,

5 Financials include the following level 2 sectors: Banking, Commercial Finance, Consumer Finance, Financial Services, Life Insurance,
Property & Casualty, Real Estate. Consumer Discretionary includes: Airlines, Apparal & Textile Products, Automotive, Casinos &
Gaming, Consumer Services, Distributors, Educational Services, Entertainment Resources, Home & Oﬃce Products, Home Builders,
Home Improvements, Leisure Products, Restaurants, Travel & Lodging.

0.10.20.30.420002002200420062008201020122014datefraction of validated securities2.02.53.03.54.020002002200420062008201020122014dateoriginal number of securities (log10)024620002002200420062008201020122014dateaverage internal degree1.01.52.02.53.03.520002002200420062008201020122014datenumber of validated internal links (log10)sectorCommunicationsConsumer DiscretionaryConsumer StaplesEnergyFinancialsHealth CareIndustrialsMaterialsOthersTechnologyUtilities13

which implies portfolio overlap and subsequent increased risk of ﬁre sales, which triggers further leverage adjustment,
as pointed by Caccioli et al. [3], Cont and Wagalath [8]. Finally, it will be useful to repeat our analysis on larger
datasets so as to encompass other bubbles and crises, and to examine diﬀerence in investment patterns across various
markets.

ACKNOWLEDGMENTS

We thank Fabio Saracco, Tiziano Squartini and Fr´ed´eric Abergel for useful discussions. Damien Challet and
Stanislao Gualdi thank Luciano Pietronero together with the (ISC)-CNR team for their kind hospitality. Giulio
Cimini and Riccardo Di Clemente acknowledge support from project GROWTHCOM (FP7-ICT, grant n. 611272).
Giulio Cimini also acknowledges support from projects MULTIPLEX (FP7-ICT, grant n. 317532) and DOLFINS
(H2020-EU.1.2.2., grant n. 640772). The funders had no role in study design, data collection and analysis, decision
to publish, or preparation of the manuscript.

[1] Prasanna Gai and Sujit Kapadia. Contagion in ﬁnancial networks. Proc. R. Soc. A, 466(2120):2401–2423, 2010.
[2] Andrew G. Haldane and Robert M. May. Systemic risk in banking ecosystems. Quantitative Finance, 469:351–355, 2011.
[3] Fabio Caccioli, Munik Shrestha, Cristopher Moore, and J Doyne Farmer. Stability analysis of ﬁnancial contagion due to

overlapping portfolios. Journal of Banking & Finance, 46:233–245, 2014.

[4] Robert M. May and Nimalan Arinaminpathy. Systemic risk: the dynamics of model banking systems. Journal of The

Royal Society Interface, 7(46):823–838, 2010.

[5] Jeremy Staum. Counterparty contagion in context: Contributions to systemic risk. In Jean-Pierre Fouque and Joseph A.

Langsam, editors, Handbook on Systemic Risk, pages 512–544. Cambridge University Press, 2013. ISBN 9781139151184.

[6] Robin Greenwood and David Thesmar. Stock price fragility. Journal of Financial Economics, 102(3):471–490, 2011.
[7] Miguel Anton and Christopher Polk. Connected stocks. The Journal of Finance, 69(3):1099–1127, 2014.
[8] Rama Cont and Lakshithe Wagalath. Fire sales forensics: measuring endogenous risk. Mathematical Finance, 2014.
[9] Andrei Shleifer and Robert W. Vishny. Fire sales in ﬁnance and macroeconomics. Technical report, National Bureau of

Economic Research, 2010.

[10] Andrei Shleifer and Robert W. Vishny. Liquidation values and debt capacity: A market equilibrium approach. The Journal

of Finance, 47(4):1343–1366, 1992.

[11] Bloomberg Finance L.P. Index METHODOLOGY - Global Fixed Income Family, 2013.
[12] Rupert G. Jr. Miller. Simultaneous Statistical Inference. Springer Series in Statistics. Springer-Verlag, New York, 1981.
[13] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: A practical and powerful approach to multiple

testing. Journal of the Royal Statistical Society. Series B (Methodological), 57(1):289–300, 1995.

[14] Michele Tumminello, Salvatore Miccich`e, Fabrizio Lillo, Jyrki Piilo, and Rosario N Mantegna. Statistically validated

networks in bipartite complex systems. PLoS ONE, 6(3):e17994, 2011.

[15] Fabio Saracco, Riccardo Di Clemente, Andrea Gabrielli, and Tiziano Squartini. Randomizing bipartite networks: the case

of the world trade web. Scientiﬁc Reports, 5:10595, 2015.

[16] Juyong Park and M. E. J. Newman. Statistical mechanics of networks. Phys. Rev. E, 70:066117, 2004.
[17] Tiziano Squartini and Diego Garlaschelli. Analytical maximum-likelihood method to detect patterns in real networks. New

Journal of Physics, 13(8):083001, 2011.

[18] Yili Hong. On computing the distribution function for the poisson binomial distribution. Computational Statistics & Data

Analysis, 59:41–51, 2013.

[19] Fabio Saracco, Riccardo Di Clemente, Andrea Gabrielli, and Tiziano Squartini. Grandcanonical projection of bipartite

networks. manuscript in preparation, 2016.

[20] Ken Butler and Michael Stephens. The distribution of a sum of binomial random variables. Technical report 467, Stanford

University, 1993.

[21] Gilles Zumbach. How trading activity scales with company size in the ftse 100. Quantitative Finance, 4(4):441–456, 2004.
[22] Zoltan Eisler and Janos Kertesz. Size matters: some stylized facts of the stock market revisited. The European Physical

Journal B-Condensed Matter and Complex Systems, 51(1):145–154, 2006.

