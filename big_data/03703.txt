6
1
0
2

 
r
a

 

M
1
1

 
 
]

G
L
.
s
c
[
 
 

1
v
3
0
7
3
0

.

3
0
6
1
:
v
i
X
r
a

Searching for Topological Symmetry in Data Haystack

Kallol Roy

Anh Tong

Jaesik Choi

Ulsan National Institute of Science and Technology

Ulsan, Korea

{kallol,anhth,jaesik}unist.ac.kr

Abstract

topological
Finding interesting symmetrical
structures in high-dimensional systems is an im-
portant problem in statistical machine learning.
Limited amount of available high-dimensional
data and its sensitivity to noise pose computa-
tional challenges to ﬁnd symmetry. Our paper
presents a new method to ﬁnd local symmetries
in a low-dimensional 2-D grid structure which
is embedded in high-dimensional structure. To
compute the symmetry in a grid structure, we in-
troduce three legal grid moves (i) Commutation
(ii) Cyclic Permutation (iii) Stabilization on sets
of local grid squares, grid blocks. The three grid
moves are legal transformations as they preserve
the statistical distribution of hamming distances
in each grid block. We propose and coin the term
of grid symmetry of data on the 2-D data grid
as the invariance of statistical distributions of
hamming distance are preserved after a sequence
of grid moves. We have computed and analyzed
the grid symmetry of data on multivariate
Gaussian distributions and Gamma distributions
with noise.

1 Introduction

The current hurdle in big data is to develop machine
learning representations which can extract meaningful fea-
tures. The principle of symmetry plays a natural foun-
dation in the development of such a learning representa-
tion by getting rid of unimportant variations, while mak-
ing the important ones easy to detect. Exploiting symme-
tries reduces computational complexity and leads to the
development of new generalizations of learning algorithms
and provides a new approach in deep symmetry networks
[Gens and Domingos, 2014; Badrinarayanan et al., 2015].
There is recent interest in exploiting cyclic symmetry in
convolution neural network architectures[Dieleman et al.,

2016; Dieleman et al., 2015]. Encoding these properties in
networks by using the transnational equivariance allows
the model for parameter budgeting efﬁciently.

Searching for symmetry in high-dimensional objects un-
der certain low complexity constraints though possible is
a computationally challenging task. Symmetry based ma-
chine learning are broadly classiﬁed as (1) Exchangeable
variable models [Niepert and Domingos, 2014] (2) Deep
Symmetry Networks (3) Symmetry based semantic pars-
ing [Poon and Domingos, 2009].

One way to solve this problem is to use a topology-
preserving dimensionality reduction method, and then
search for symmetrical structures. High-dimensional mod-
els with low-dimensional structures of patterns or symme-
try are ubiquitous. Extracting low-dimensional structures
in high-dimensional models have widespread uses in var-
ious disciplines including neuroscience, economics, and
genetics. Our work is inspired by the Noether’s Theorem
of uniﬁcation symmetry and conservation in theoretical
physics [Schwarzbach and Kosmann-Schwarzbach, 2010].
This paper presents a novel method of searching symmetry
on 2−D grid space, where the Betti number, an important
topological property in persistent homology, is computed
(or efﬁciently approximated). We deﬁne three grid moves
(i) Commutation (ii) Cyclic Permutation (iii) Stabilization
on grid blocks, consisting of a ﬁnite number of local grid
squares. Our algorithm ﬁnds symmetry in each grid block
after a ﬁnite sequence of grid moves.
We prove the upper bound of the Hamming distance H(n)
is bounded. We have used the metric of Hamming distance
as measure of randomness in the search of symmetry. The
randomness may come from the added noise in the sig-
nal data or inherently embedded in the data. Our proposed
method of topological data processing is immune the to ef-
fect of noise for most cases and is used for searching the
local symmetry. Our method of estimating the upper bound
of the Hamming distance H(n) can be useful in detecting
the phase change in data, which have profound implica-
tions in security, ﬁnance, and other areas.

The organization of the paper is as follows: Section 2

gives a quick introduction to Low-Dimensional Topolog-
ical Models, Subsection 2 will introduce the newly con-
struct of Grid Diagrams perspective, Section 3 will explain
our method of searching symmetry, Section 4 explain our
newly proposed Ising model of data, Section 5 explains the
related work, Section 6 presents our experimental results
and Section 7 concludes the paper. We have used the fol-
lowing important notations in our paper

Notations

Betti number
Hamming distance
Small square grid
2D Grid
Dimension of small grid

b
(1)
(2) H
(3)
g
(4) G
(5)
l
(6) H
(7)
(8)
(9)
(10) T1, T2, T3 Commutation, Cyclic Permutation, Stabi-
lization

s
Jg1,g2
Γ(l)

Hamiltonian
Conﬁguration
Grid interaction parameter
Scaling invariant parameter

2 Low-Dimensional Topological Models

Our Algorithm of ﬁnding the symmetry in Data uses the
topological features to search the local symmetry. Our
method is of general nature and features other than the
topological ones can be extended in it. We encode our
Data space as a topological space, because of its high-
dimensional features (symmetry and connectivity) can be
inferred from its low-dimensional, local representations as
in [Chen and Rong, 2010; Edelsbrunner, 2007; Carlsson,
2014].

Topological Invariants on Data Manifolds

Computing topological
invariants in low-dimensional
space is used for exploring the symmetry in data space
in our paper. Homology groups are increasingly used in
computing the invariants as their computations are more
feasible and provide the important information about the
shape of the object. The homology groups for the 2−D
object are computed efﬁciently by the digitization [Evako,
2006; Chen and Rong, 2010; Chen, 2004]. Digital topol-
ogy allows discretizing data object by integrating the ge-
ometric and topological constraints. The digital model
of a 2−dimensional continuous object is called a digital
2−surface. The intrinsic topology of the object is used
without referring to an embedding space. A set D is deﬁned
as a 2−cell if it is homeomorphic to a closed unit square,
similarly, a set D is a 1−cell if it is homeomorphic to a
closed unit segment and a set D is a circle(or 1−sphere)
if it is homeomorphic to a unit circle. The interior and the
boundary of an n−cell D, are denoted as IntD and ¶ D with

the following boundary condition

D = IntD ∪ ¶ D

(1)

Intuitively we can visualize the boundary of a 1− cell has
two endpoints, the boundary of a 2−cell is a circle. For
the sake of completeness, we deﬁne 0−cell as a single
point for which ¶ D = /0. The following properties hold for
digital topology
• For a circle C and a 1−cell D contained in C the set
C − IntD is a 1−cell.
• If 1−cells C1 and C2 are such that C1 ∩C2 = ¶ C1 ∩¶ C2 =
v holds, then C1 ∪C2 = E is a 1−cell.
• For 2−cells D1 and D2 such that D1 ∩D2 = ¶ D1 ∩¶ D2 =
C is a 1−cell holds, then D1 ∪ D2 = B is a 2− cell.
• An (i + 1)−cell can be formed by two disjoint i−cells
that are parallel
• An i−cell and it’s parallel move form an (i + 1)−cell.
We now formally deﬁne the Digital Surface as

Deﬁnition (Digital Surface). A digital surface is the set of
surface points each of which has two adjacent components
not in the surface in its neighborhood

In 2−D space, algorithms to compute Betti numbers are
of complexity O(n log2 n) or O(n log3 n). Our paper use
the properties of manifolds in 2−D digital spaces for the
computation of topological invariants. We formally deﬁne
digital manifold as

is a i−D digital manifold if

Deﬁnition (Digital Manifold). A connected subset S in dig-
ital space (cid:229)
• Any two i−cells are (i − 1) connected in S
• Every (i-1)cell in S has only one or two parallel-moves in
S
• S does not contain any (i + 1)−cell

We represent a compact 3−dimensional manifold in R3 by
a surface. Then the homology group is expressed in terms
of its boundary surface. The Betti numbers related to ho-
mology groups are used in topological classiﬁcation. For a
k− manifold, homology group Hi,
i = 0, · · · , k, indicates
the number of holes in each i−skeleton of the manifold.
For a topological space M, its homology groups, Hi(M)
are certain measures of i−dimensional holes in M.
Deﬁnition (Betti number). The Betti number b
deﬁned as the rank of the quotient group as

is formally

b = rankHi(M)

(2)

In our algorithm we use the statistical distribution of Betti
number b
in each small grid square of length l for comput-
ing of local symmetry.

Grid Diagrams for Low-Dimensional Topology

A grid diagram is deﬁned as a two dimensional square grid
such that each square inside the grid is ﬁlled with symbols
x, o or is left blank, with the constraint such that every col-
umn and every row has exactly one x and one o. The sym-
bols x and o are abstract decorations that ﬁll the small grid
square.

The grid number for the grid diagram is the number of
columns (or rows). The grid diagram is associated with an
equivalent knot by joining the x and o symbols in each col-
umn and row by a straight line with the convention of ver-
tical lines crosses over the horizontal lines (as shown by
the dotted red lines in Figure 1). These lines joining the
symbols x and o form the strands of the knot and remov-
ing the grid give us the planar projection of the knot (triv-
ial knot in our example) as shown in Figure 1 [Manolescu,
2012; Ozsváth et al., 2015; Sarkar, 2010]. Grid diagrams
are extensively used recently because of the use the grids
gives a combinatorial deﬁnition of knot Floer homology
[Sarkar and Wang, 2010].

x

o

o

x

x o
x

o

⇒

x

o

o

x

x o
x

o

x

o

⇒

o

x

x o
x

o

Figure 1: Knot Generation from Grid Diagram

Three grid moves (explained in Section 3) to relate the
grid diagrams are (1) Commutation (T1) (2) Cyclic Per-
mutations (T2) (3) Stabilization (T3) [Manolescu, 2012;
Ozsváth et al., 2015; Sarkar, 2010]. These grid moves are
analogous to Reidemeister moves for knot diagrams. The
grid moves are used to generate equivalent relations. The-
orem 1 explains that a sequence of grid moves gives the
invariant knots. A knot invariant is deﬁned in the form of
a polynomial such as the Alexander polynomial, Conway
polynomial, HOMFLY polynomial, Jones polynomial etc.
Theorem 1. [Reidemeister, 1932] G1 is a grid diagram
with its equivalent knot K1 and grid diagram G2 with its
equivalent knot K2. K1 and K2 are equivalent knots if and
only if there exists a sequence of commutation, stabilization
and cyclic permutation grid moves transform G1 to G2.

Our goal in this paper is to deﬁne the symmetrical in-
variance in grid diagrams under uncertainty. For search-
ing the local symmetry we have moved away from gen-
erating knots from the planar grid diagrams and instead
use the distribution of hamming distance among the grid
blocks explained in Section 3. A ﬁnite sequence of opera-
tions T comprising of Commutation, Cyclic Permutation,
Stabilization in a deﬁned order is

T = T a

1 ◦ T b

2 ◦ T c
3

(3)

where a, b, c ∈ R. The stabilization operations T3 of kink
addition and kink subtraction occur in pairs to maintain the
constant grid number.

3 Searching Symmetry with Uncertainty

Inference in high dimensional data is challenge because of
the curse of dimensionality. Thus, high dimensional data
are usually converted to low-dimensional codes by (1)
Neural Networks [Hinton and Salakhutdinov, 2006]; (2)
Nonlinear dimension reduction [Tenenbaum et al., 2000;
Lee and Verleysen, 2007]; and (3) Topological and Geo-
metric methods [Wang, 2012].

In this paper, we propose a new form of symmetry termed
a grid symmetry with the following hypothesis.
Hypothesis 2 (Invariance of Symmetric Probability). The
symmetry on a grid is represented by Commutation, Cyclic
Permutation and Stabilization. The statistical distribution
of the Betti numbers remains conserved during the above
deﬁned legal transformations.

Symmetry of a geometric object comes with the con-
cept of automorphisms. Legal transformations allowed for
grid diagrams are 1 Commutation (2) Cyclic Permuta-
tions (3) Stabilization deﬁned as in [Ozsváth et al., 2015;
Manolescu, 2012; Sarkar and Wang, 2010; Sarkar, 2010;
Ozs, 2004; Hedden, 2008; Reidemeister, 1932].
Commutation: Commutation is deﬁned as an interchange
of two consecutive rows or columns of a grid diagram. The
commutation is permitted only between rows or columns
those are non-nested.

b
b

b
b

⇒

b
b

b
b

Figure 2: Commutation of a grid diagram

Cyclic Permutation: Cyclic permutation preserves the
grid number and is deﬁned as the removal of an outer
row/column and replacing it to the opposite side of the grid.

b

b

b

b

b
b

b

b

⇒

b

b

b

b

b

b

b

b

Figure 3: Cyclic Permutation of a grid diagram

Stabilization: Stabilization is performed by kink addition
or removal and thus does not preserve the grid number. A

b

b

⇒

b

b

b

b

Figure 4: Stabilization of a grid diagram

kink is added either to the right or left of a column or above
or below of a row. Adding a kink to a column c is done by
inserting an empty row between the symbols x and o of the
column c. Then an empty column is inserted either to the
right or left of column c. We then move the either symbol
x or o to the adjacent grid square in the added column. We
then complete the added row and column with the sym-
bols x and o appropriately. To add a kink to a row, we have
to swap the row and column operations. To remove a kink
(grid number decreases by 1), we follow the instructions in
reverse order.

After projecting the high dimensional data to our 2D grid
space, we compute the Betti number b
in each small grid
square of length l. We compute only a particular order of
Betti number b k for a ﬁxed k and mark the grid square with
the Betti number if b k 6= 0 and leave the grid square empty
if b k = 0. For example we ﬁll up the small grid square if
the number of holes in it is at least 1 i.e b 2 6= 0 and leave
the grid square empty when b 2 = 0. We have used the sym-
bol b
to represent b k for ﬁxed k. We introduce this binary
topological marking to get the sparse representation. For
sufﬁciently sparse data we get a grid diagram where most
of small grid squares are left empty and others are marked
with b . This binary marking makes our model consistent
with the grid homology for the studying of invariance of
knots. Here, the difference is that we investigate the invari-
ance of the probabilistic distribution of Betti numbers using
the metric of Hamming distance.

After the marking of the grid squares, we randomly sam-
ple a square grid block of size l consisting of n2 small grid
squares and apply a ﬁnite sequence of operations T deﬁned
in Equation 8 on the sampled grid block as shown in Fig-
ure 6. The small grid squares colored red and green as il-
lustrated in Figure 6 are of dimension l. The sampled grid
block ABCD on which the sequence of operations T are ap-
plied is shown as shaded grey in Figure 6. The sequence of
ﬁnite operations changes the arrangements of Betti num-
bers in the sampled grid block denoted as H in Figure 6.
The grid squares which were not marked with Betti num-
ber b before the transformation T may now be marked or
ﬁlled with Betti number b . This means to say that the posi-
tion arrangements of Betti number b .

reshufﬂing happen because of

We now introduce the concept of symmetry as the amount
of
the application of
Transformation operation T . We have used the metric of
Hamming distance Hx to capture the degree of reshufﬂing.
We have moved away from the elementary concept of
mirror symmetry and introduced the concept of Grid
Symmetry. Our grid symmetry is with the respect to a
particular feature of the data like distribution of holes,
connected components etc. We have particularly used the
topological features as it is more robust to noise. Our
method is quite general and can be extended to other
features of the data. To compute the Hamming distance,
we have used the following notations

1. Each small grid square at location i and j is marked as

(i, j).

2. |(i,j)| represents the occupation of the small grid
6= 0) and is deﬁned

square with the Betti number (b
formally as,

|(i, j)| =(cid:26) 1

0

if the grid square is occupied
if the grid square is not occupied

3. The Hamming distance Hi, j computed along each row

is given by

Hi, j = |(i, j)| ⊕ |(i, j′

)|,

where the interchange of two consecutive columns
T = T1 is given by p ( j) = j′ , and pasting the outer-
most column before the ﬁrst T = T2 is given p (1) = j′
for. p
is the permutation operator. Here T1 and T2 are
commutation and cyclic permutations as deﬁned in the
Section 2.

4. The Hamming distance computed over the sampled

grid block H(n) is given by,

H(n) =

n(cid:229)

i=1

|(i, j)| ⊕ |(i, j′

)|,

(4)

where n is the grid number of the sampled block and
⊕ denotes the mod 2 operations.

Intuitively the Hamming distance H(n) denotes the
positional changes of the Betti number b after the ﬁnite
sequence of operations. We now formally deﬁne the sym-
metric distribution of Betti numbers in our grid diagram
context as the change positional changes of Betti number
in small grid squares as shown Figure 5. The Figure 5
shows the Hamming distance after the applications of
operations. The original grid block containing a particular
conﬁgurations s of Betti number b changes the number of
positional distribution after the application of T2 as 12. So
the hamming distance between the two conﬁgurations is

axis symmetry

C

D

B

A

l

l

(0,0)

H

Figure 6: A distribution of Betti numbers on grid

12. After the operation of T2 again the Hamming distance
decreases to 6, then after application of the operation T1
the hamming distance increases to 14 and lastly after the
operation of T1 again the Hamming distance falls back to
6. The oscillating nature of Hamming distance H is upper
bounded proved in our paper in the Section 4.

Deﬁnition (Symmetric Distribution). The probability dis-
tribution over Betti numbers b on a local grid block of size
n is symmetric, if the Hamming distance Hi, j computed over
the grid block (Equation (4)) is bounded by h after a ﬁnite
sequence of operations T ,

H(n) ≤ h (n, l)

(5)

where h (n, l) is a integer parameter of choice and it
depends on grid number of the sampled block and the grid
parameter l.

The conditional probability Pr(H ≤ h ) is computed as

Pr(H ≤ h ) = Pr(s |H ≤ h ) Pr(s )

(6)

For the case of Cyclic Permutation operation, it is intuitive
to see the local symmetry axis passing through the middle
of the sampled grid block if the H(n) = 0. The value of
H(n) gives us the sense of symmetry. More the value of
H(n) less will be the symmetry of the sampled grid block.
Next, we prove the upper bound of the Hamming distance
H(n) is bounded.

For our proof of bounded upper bound of Hamming dis-
tance, we assume some known discrete distribution of Betti
number b on the small grid square i.e the probability distri-
bution fb (i, j) of b on the grid square (i, j) follows some
distributions. This approximation is valid as the real world

data lies in between truly random distribution and a proba-
bility distribution.

To simplify the notations, we denote x = {(i, j), l} and the
probability density function fb = fb (x). From hence on-
ward we also denote fb (x) as f (x). Thus fb (x) deﬁnes the
probability that the grid square (i, j) will be occupied by
b . Note that, fb (x) is a multivariate function [Holtz, 2008;
Garcke and Pfülger, 2014].
In the proof, we have used 2 dimensions as (1) position of
the grid square (2) size of the small grid square l.

4 The Ising Model on a 2-D Grid

We formally propose a new Ising model of Data and com-
pute the statistical distribution of the Betti numbers. Our
modeling of data on a 2−D grid surface and digitization
of Betti numbers are analogous to the spin conﬁguration
as in the Quantum Ising Model. We draw those parallels
from the physical Ising model [Chakrabarti et al., 1996;
Grimmett, 2010] and propose an analogous Data Ising
Model. We then compute a probabilistic distribution of
conﬁgurations Betti numbers on the grid. This allows us to
ﬁnd the symmetric distribution for the sampled grid after
the ﬁnite sequence of operations of commutation, cyclic
permutation and stabilization. We introduce the following
notations.

We denote the 2−D planar grid G = (g, N), where g is
the small grid square and N is the set of neighboring grid
squares as shown in Figure 7. The small red square grid is
surrounded by the set N of four green squares grid as shown
in Figure 7. To each small square grid g ∈ G, we associate
a number 1 or 0 analogous to quantum spin as in Quantum
Ising Model with the local two-dimensional Hilbert space
C2 [Grimmett, 2010; Chakrabarti et al., 1996]. We asso-
ciate each small grid square g with 1 if the Betti number
computed on it is not equal to 0, and leave the grid square
g vacant(as in our model) or mark it with 0. This marking
leaves us the planar grid as a block spin conﬁguration. This
allows us to write the conﬁguration space for our planar
grid as the tensor product of the grid states (1) and 0 as
explained before.

1

1

1

1

1

Figure 7: Ising Model

The conﬁguration space H for the planar 2−D planar grid
is expressed as

H = Og∈G

C

(7)

for the local Hilbert space C. The eigenvectors for the

g = (cid:18)1

1(cid:1)T of
Hilbert space C2 are e1 = (cid:0)1 0(cid:1)T , e2 = (cid:0)0
0 −1(cid:19) at the small grid site g,
the matrix s (3)
with eigenvalues ±1. The other two matrices are s (1)
(cid:18)1
0 −1(cid:19) , s (2)
0 −1(cid:19). We the propose the opera-

g = (cid:18)1

tor H for our 2−D planar grid analogous to the Hamiltonian
concept as

g =

0

0

0

H = − (cid:229)

g1,g2∈G

Jg1,g2

s (3)
g1

g2 − Γ (cid:229)
s (3)

g∈G

s 1
g

(8)

where g1 and g2 are neighboring small grid squares as
shown in Figure 7.

The parameter Jg1,g2 is deﬁned as the interaction strength
between the small grid squares g1 and g2. The parameter
Jg1,g2 is critically dependent on the boundaries ¶ g1 ¶ g2
and grid length l. The interaction parameter indicates the
continuity of data manifold. The parameter Γ in our model
denotes the rate of change hierarchical continuity of across
the data manifold. The is hierarchical scaling variance pa-
rameter Γ(l) is a function of the dimension of small grid
square l.
The probability for a conﬁguration s of Betti numbers in
our 2−D planar grid G based on our data based Ising model
is

PG(s ) =

e−t H(s )

1
ZG

(9)

is a parameter. The normalization constant is for

where t
all possible conﬁgurations s
ZG = (cid:229)

is given by
e−t H(s )

(10)
The expected value for a function < f (s ) > of conﬁgura-
tions is

< f (s ) >= (cid:229)

f (s )PG(s )

s

(11)

We compute the expected value H(s ) of the number of
using our proposed Data Ising Model

< H(s ) >= (cid:229)

s

H(s )PG(s )

(12)

Remark (Symmetric Distributions: Trivial Cases). Given
a grid block, when either P(|(i, j)|) = 1 ∀i, j or
P(|(i, j)|) = 0 ∀i, j, the Hamming distance is 0 after any
sequence of legal grid moves.
Remark (The Bernoulli Distribution of the Betti Num-
bers). Given a grid block of size n, when the distribution

of the Betti numbers in each grid square independently fol-
lows the Bernoulli distribution with a parameter p, the ex-
pected Hamming Distance after a sequence of grid moves
is 2n2 p(1 − p).
Theorem 3 (Bounded Hamming Distance between Sym-
metric Grid). When Commutation, Cyclic Permutation and
Stabilization are allowed grid moves in a grid block,
the statistical distribution measured by Hamming distance
H(n) remains bounded after a sequence of grid moves.

Proof. Let Ω ⊆ R be a set and a d(= 2) dimensional
product measure deﬁned on Borel subsets of Ω2 using
dimension-wise decomposition approximations as
j(x j) = dm 1(x1) · dm 2(x2),

d(x) = (cid:213)

(13)

dm

where x = (x1, x2) and m
measures on Borel subsets of Ω. Here x1 = (i, j), x2 = l

j ( j = 1, · · · , d) are probability

Let V (2) is the Hilbert space of all functions. We deﬁne
f (x) as a multivariate density function deﬁned as

f : Ω2 → [0,1].

For a subset u ⊆ D, where D = {1,2}, the measure m
duces projection functions Pu : V (2) → V (|u|) by
f (x)dm D \u(x)

Pu f (xu) := ZΩd−||u|

Here xu denotes
dm D \u(x) := (cid:213)
j /∈u dm

|u|−dimensional vector

the
j(x j).

(14)

in-

(15)

and

For u = /0 the projection function is given as

P/0 f (x /0) = ZΩ2

f (x)dm (x) =: A

(16)

f ∈ V (2) is then decomposed using dimension-wise decom-
position and as

f (x) = (cid:229)

fu(xu)

u⊆D

with the orthogonality conditions

( fu, fu) = 0, u 6= v

(17)

(18)

The fu are computed recursively as
fu(xu) = Pu f (xu) − (cid:229)

v⊂u

fv(xv)

(19)

Using the classical ANOVA Decomposition and orthogonal-
ity condition we write the variance s ( f )2 as

s 2( f ) = ZΩd
= (cid:229)

( f (x) − A)2d(x)
s 2( fu)

u⊆D,
u6= /0

(20)

where s 2( fu) denotes the variance of fu.

Now we compute the probability of Hamming distance
H = m for a grid block consisting of n2 grid squares as

Pr[H] = Pr[

n(cid:229)

|(i, j)| ⊕ |(i, j′

)|]

i=1
Pr[|(i, j)| ⊕ |(i, j′

)|]

≤

n(cid:229)

i=1

(21)

Now for the case m > n2,
To get the tighter upper bound we use the transformation of
random variables and write as there exists a map g and g−1
1
as

Pr[H = m] = 0.

H = g1(X )
X = g−1
1 (H)

(22)

(23)

We prove the the upper bound of Hamming distance after a
ﬁnite sequence of Chebyshev’s inequality we write

Pr[H > kc (s )] = Pr[g1(X ) > kc (s )]

≤

1

kk (s )

(24)

where c (s ) and k (s ) are functions that depend on the
variance of f (x)

We have proposed a general Algorithm

5 Related Work

like rotation
The symmetric features of the data set
symmetry,
translation symmetry are used as a fea-
ture and used a priory in Bayesian machine learning
[Culbertson and Sturtz, 2013] or used in training the con-
volutional neural network layers [Dieleman et al., 2016;
Dieleman et al., 2015]. Analogous to our deﬁnitions of
symmetric operations of cyclic permutation, commutation
and stabilization, [Dieleman et al., 2016] proposes four op-
erations which is inserted in neural network model as layers
to model the translation equivariance into rotation equivari-
ance. The notion of equivariance is formally deﬁned as
Deﬁnition (Equivariant Function). The function f is de-
ﬁned as equivariant for a class of transformations T , if for
all transformations T ∈ T of the input x, there exists a cor-
responding transformation T′ of the output f (x), such that
the following condition holds

f (T(x)) = T′ f (x)

(25)

The patterns at different spatial positions are encoded simi-
larly in the feature representations by these layers. This al-
lows parameter sharing much more effectively than a fully

Algorithm 1 Searching Local Symmetry
Require: Marked Grid Diagram
1: procedure HAMMING DISTANCE(Sampled Grid

Block)

2 ◦ T c
3

then

1 ◦ T b

the sampled grid is symmetric

Call Generating Grid Diagram
Sample the grid diagram G
Call T1, T2, T3 to generate T (G) = T a
Apply T (G) on the sampled Grid Block
Compute H(n) = (cid:229) n
i=1 |(i, j)| ⊕ |(i, j′)|
if H(n) ≤ h

2:
3:
4:
5:
6:
7:
8:
9:
10:
11: end procedure
Generating Grid Diagram
Require: Marking Each Small Grid Square with b
12: function COMPUTING(Betti Number b )
13:
14:

else the sampled grid is not symmetric
end if

Construct the Grid G of parameters n and l
G(i, j) is the position of small grid square at (i, j)

position.

Construct Simplicial Complex for each G(i, j)
Compute the quotient space Hk(X ) = ker¶ k
ker¶ k+1
b = dim (Hk(X ))
if b
Mark G(i, j) with b
Leave G(i, j)e empty if b

6= 0
6= 0

end while

c ← 1
while c ≤ n − 1 do

swap column c and c + 1
c ← c + 2

15:
16:
17:
18:
19:
20: end function
Commutation Operation T1
21: procedure COMMUTATION(G)
22:
23:
24:
25:
26:
27: end procedure
Cyclic Permutation T2
28: procedure CYCLIC PERMUTATION(G)
29:
30:
31:
32:
33:
34:
35:
36: end procedure
Stabilization T3
37: procedure STABILIZATION(G)
38:
39:

for c ∈ 1 . . . n do

for r ∈ 1 . . . n do

end for

end for

if c = 1 then G(c, r) = G(n, r)
else G(c, r) = G(c − 1, r)
end if

⊲ T1

⊲ T2

⊲ T3

Randomly pick a column c and split it into two
insert an empty row and ﬁll the intersections with

two columns with b

40: end procedure

connected neural network under similar conditions. They
extended to rotation invariance by introducing the four op-
erations of (1) Slice (2) Roll (3) Pool (4) Stack to
build CNNs. The CNNs will detect the cyclic symmetry
in the input data by the rotation over the angles k.90o, k ∈
{0,1,2,3}. They this group of four rotations form a cyclic
group of order 4(C4) as a restricted form rotational symme-
try called cyclic symmetry. Similarly the dihedral symme-
tryD4 is deﬁned as a set of total eight possible orientations
after the operation of horizontal ﬂipping. [Dieleman et al.,
2016] proposes the computation of approximate invariance
by the method of data augmentation as presenting the net-
work during training with examples that are randomly per-
turbed. Given a network with sufﬁcient capacity, it learn
invariances.

6 Experimental Results

In this section, we setup a grid block with size 1000 ×1000.
We conduct two scenarios of sampling Betti number. In
the ﬁrst case, Betti number positions are sampled inside
the grid with by a mixtures two Gaussian distributions
N (m 1, Σ1) and N (m 2, Σ2). A 2-dimensional Gamma dis-
tribution Γ(k,q ) is chosen to generate Betti number posi-
tion in the second case. The grid block of sampled Betti
number position is divided into subsample grid squares
with size 5 × 5. We perform grid moves including commu-
tation, cyclic permutation, stabilization on these local grid
squares. After the transformations, the Hamming distances
are obtained between the original grid squares and the cor-
responding transformed grid squares. With this synthetic
data, we conduct four types of tests including (a) commu-
tation, (b) cyclic permutation, (c) chain of transformations,
and (d) chains of transformation with noise data. The con-
tour line illustrations of results are portrayed in Figure 8
and 9 respectively for the mixture of Gaussian case and
Gamma case.

7 Conclusions

We have proposed a novel method of ﬁnding symmetry
termed as grid symmetry
in data by developing a new
framework of 2−D grid space. We have proposed three
fundamental operations of commutation, cyclic permuta-
tion and stabilization to determine the symmetry. The meth-
ods of statistical topology i.e distribution of Betti number is
used as a feature in checking symmetry in data. Our method
is particularly helpful Bayesian machine learning where the
topological feature(Betti number) is encoded a priory. Our
method of spatial distribution of Betti numbers on 2D grid
can be encoded in constitutional neural network layers as
the property of translation equivariance [Dieleman et al.,
2016; Dieleman et al., 2015]. The method of data augmen-
tation as described in [Dieleman et al., 2016] for the train-
ing of CNN’s ﬁts particularly well with our approach, as

(a)

(b)

18

16

14

12

10

8

6

4

2

160

140

120

100

80

60

40

40

60

80

100

120

140

160

60

80

100

120

140

160

(c)

10

160

(d)

9

8

7

6

5

4

3

2

1

140

120

100

80

60

40

40

60

80

100

120

140

160

60

80

100

120

140

160

20

18

16

14

12

10

8

6

4

2

10

9

8

7

6

5

4

3

2

1

160

140

120

100

80

60

40

40

160

140

120

100

80

60

40

40

Figure 8: Mixture of Gaussian distribution case: (a) Ham-
ming distance between original and commutation; (b)
Hamming distance between original and cyclic permuta-
tion (c); Hamming distance between the original grid and
the grid after chains of transformation T = T1 ◦ T2 ◦ T1 ◦
T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2; (d) Hamming distance between
the original grid and the grid after chains of transformation
T = T1 ◦ T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2 with noise

(a) 

(b)

180

160

140

120

100

80

60

40

20

180

160

140

120

100

80

60

40

20

50

150

100

(c) 

50

100

150

18

16

14

12

10

8

6

4

2

10

9

8

7

6

5

4

3

2

1

180

160

140

120

100

80

60

40

20

180

160

140

120

100

80

60

40

20

50

150

100

(d) 

20

40

60

80

100

120

140

160

180

18

16

14

12

10

8

6

4

2

10

9

8

7

6

5

4

3

2

1

Figure 9: Gamma distributions case: (a) Hamming distance
between original and commutation; (b) Hamming distance
between original and cyclic permutation (c); Hamming dis-
tance between the original grid and the grid after chains of
transformation T = T1 ◦T2 ◦T1 ◦T2 ◦T1 ◦T2 ◦T1 ◦T2 ◦T1 ◦T2;
(d) Hamming distance between the original grid and the
grid after chains of transformation T = T1 ◦ T2 ◦ T1 ◦ T2 ◦
T1 ◦ T2 ◦ T1 ◦ T2 ◦ T1 ◦ T2 with noise

the random perturbations are well described the topolog-
ical deformations. Our method throws light on the direc-
tions of studying the deep machine learning using scale in-
variants. We have connected our low dimensional topology
models with Ising. Modeling invariances in deep learning
particularly so in unsupervised learning is an active area
of research[Srivastava et al., 2015]. The recent Google’s
breakthrough cat neuron paper the authors uses the un-
shared weights to allow learning of more invariances other
than translational invariances[Le et al., 2012]. Our model-
ing of topological invariances(Betti number) and priors in
the data set naturally ﬁts in the scheme. Further our Ising
model parameter Γ(l) captures scaling of invariants asymp-
totically, as we decrease the dimension of the small grid
square l.

References

Vijay Badrinarayanan, Bamdev Mishra, and Roberto
Cipolla. Understanding symmetries in deep networks.
CoRR, abs/1511.01029, 2015.

Gunnar Carlsson. Topological pattern recognition for point

cloud data. Acta Numerica, 23:289–368, 5 2014.

B.K. Chakrabarti, A. Dutta, and P. Sen. Quantum ising
phases and transitions in transverse ising models. Lec-
ture notes in physics: Monographs. Springer, 1996.

Li Chen and Yongwu Rong. Digital topological method for
computing genus and the betti numbers. Topology and
its Applications, 157(12):1931 – 1936, 2010.

L. Chen. Discrete Surfaces and Manifolds: A Theory of
Digital-discrete Geometry and Topology. Scientiﬁc &
Practical Computing, 2004.

Robert Gens and Pedro M Domingos. Deep symmetry net-
works. In Z. Ghahramani, M. Welling, C. Cortes, N.D.
Lawrence, and K.Q. Weinberger, editors, Advances in
Neural Information Processing Systems 27, pages 2537–
2545. 2014.

G. Grimmett. Probability on Graphs: Random Processes
on Graphs and Lattices. Institute of Mathematical Statis-
tics Textbooks. Cambridge University Press, 2010.

Matthew Hedden. An ozsvÃ ˛athâ ˘A¸SszabÃ¸s ﬂoer homology
invariant of knots in a contact manifold. Advances in
Mathematics, 219(1):89 – 117, 2008.

G E Hinton and R R Salakhutdinov. Reducing the di-
Science,

mensionality of data with neural networks.
313(5786):504–507, July 2006.

M. Holtz. Sparse Grid Quadrature in High Dimensions

with Applications in Finance and Insurance. 2008.

Quoc V. Le, Marc’Aurelio Ranzato, Rajat Monga, Matthieu
Devin, Greg Corrado, Kai Chen, Jeffrey Dean, and An-
drew Y. Ng. Building high-level features using large
scale unsupervised learning. In Proceedings of the 29th
International Conference on Machine Learning (ICML),
2012.

J.A. Lee and M. Verleysen. Nonlinear Dimensionality Re-
Information Science and Statistics. Springer,

duction.
2007.

Ciprian Manolescu. Grid diagrams in Heegaard Floer the-
ory. In 6th European Congress of Mathematics (ECM) ,
2012.

Mathias Niepert and Pedro M. Domingos. Exchangeable

variable models. CoRR, abs/1405.0501, 2014.

Holomorphic disks and knot invariants. Advances in Math-

J. Culbertson and K. Sturtz. Bayesian machine learning via

ematics, 186(1):58 – 116, 2004.

category theory. ArXiv e-prints, December 2013.

Sander Dieleman, Kyle Willett, and Joni Dambre.
Rotation-invariant convolutional neural networks for
galaxy morphology prediction. Monthly Notices of the
Royal Astronomical Society, 450(2):1441–1459, 2015.

S. Dieleman, J. De Fauw, and K. Kavukcuoglu. Exploit-
ing Cyclic Symmetry in Convolutional Neural Networks.
ArXiv e-prints, Feb 2016.

Herbert Edelsbrunner. An introduction to persistent homol-
In Proceedings of the 2007 ACM Symposium on
ogy.
Solid and Physical Modeling, Beijing, China, June 4-6,
2007, page 9, 2007.

Alexander V. Evako. Topological properties of closed dig-
ital spaces: One method of constructing digital models
of closed continuous surfaces by using covers. Comput.
Vis. Image Underst., 102(2):134–144, May 2006.

Jochen Garcke and Dirk Pfülger. Sparse Grids and Appli-

cations - Munich 2012. Springer, 2014.

P.S. Ozsváth, A.I. Stipsicz, and Z. Szabó. Grid Homology
for Knots and Links:. Mathematical Surveys and Mono-
graphs. 2015.

Hoifung Poon and Pedro M. Domingos. Unsupervised se-
mantic parsing. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Processing
(EMNLP), pages 1–10, 2009.

von K. Reidemeister. Knotentheorie. Springer, 1932.
Sucharit Sarkar and Jiajun Wang. A combinatorial descrip-
tion of some heegaard ﬂoer homologies. Annals of Math-
ematics, 171(2):1213 – 1236, 2010.

Sucharit Sarkar. Grid diagrams and the Ozsvath-Szabo tau-

invariant. 2010.

B.E. Schwarzbach and Y. Kosmann-Schwarzbach. The
Noether Theorems: Invariance and Conservation Laws
in the Twentieth Century. Sources and Studies in the
History of Mathematics and Physical Sciences. Springer,
2010.

N. Srivastava, E. Mansimov, and R. Salakhutdinov. Un-
supervised Learning of Video Representations using
LSTMs. ArXiv e-prints, February 2015.

J. B. Tenenbaum, V. Silva, and J. C. Langford. A Global
Geometric Framework for Nonlinear Dimensionality
Reduction. Science, 290(5500):2319–2323, 2000.

J. Wang. Geometric Structure of High-Dimensional Data

and Dimensionality Reduction. Springer, 2012.

b

b
b

b
b
b
b
Original

T2

b
b

b

b
b

b
b

H = 12

T2

b

b
b

b
b
b
b
H = 6

T1

b

b

b

T1

b
b

b
b

H = 14

b

b
b

b
b
b
b
H = 6

Figure 5: An illustrative example of computing Hamming distance as result of a sequence of operations T2 ◦ T2 ◦ T1 ◦ T1

