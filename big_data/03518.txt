High-dimensional Black-box Optimization

via Divide and Approximate Conquer

Peng Yang1, Ke Tang1∗, and Xin Yao2

1UBRI, School of Computer Science and Technology,

University of Science and Technology of China, Hefei, China, 230027

2CERCIA, School of Computer Science,

University of Birmingham, Birmingham B15 2TT, U.K.

Emails: trevor@mail.ustc.edu.cn; ketang@ustc.edu.cn; x.yao@cs.bham.ac.uk

6
1
0
2

 
r
a

 

M
1
2

 
 
]
I

A
.
s
c
[
 
 

2
v
8
1
5
3
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

Divide and Conquer (DC) is conceptually well
suited to high-dimensional optimization by decom-
posing a problem into multiple small-scale sub-
problems. However, appealing performance can
be seldom observed when the sub-problems are in-
terdependent. This paper suggests that the major
difﬁculty of tackling interdependent sub-problems
lies in the precise evaluation of a partial solu-
tion (to a sub-problem), which can be overwhelm-
ingly costly and thus makes sub-problems non-
trivial to conquer. Thus, we propose an approxi-
mation approach, named Divide and Approximate
Conquer (DAC), which reduces the cost of partial
solution evaluation from exponential time to poly-
nomial time. Meanwhile, the convergence to the
global optimum (of the original problem) is still
guaranteed. The effectiveness of DAC is demon-
strated empirically on two sets of non-separable
high-dimensional problems.

x∗ = arg maxx∈X f (x),

1 Introduction
Developing Artiﬁcial Intelligence (AI) applications often en-
counters a key task of solving challenging optimization prob-
lems. Formally, it can be stated as:
where f : X → R denotes a function on a bounded solu-
tion space X ⊆ RD and x∗ denotes the global optimum in
X . We consider f as a black-box function that the problem
information is completely unknown beforehand, where only
the function value of x ∈ X can be directly provided if ex-
plicitly queried. Therefore, only derivative-free approaches
can be brought to bear, which, however, often suffer from the
curse of dimensionality if D is considerably large.

An intuitive idea to handle a high-dimensional optimiza-
tion problem is to project its solution space onto lower di-
mensions, where traditional approaches perform well [Kab´an
et al., 2015]. However, it is nontrivial to identify an ap-
propriate projection. Typical approaches in this category,
e.g., Random Embedding techniques [Wang et al., 2013;
Qian and Yu, 2016], consider the high-dimensional problem
having low effective dimensionality, for which a random pro-
jection would sufﬁce to ﬁnd the global optimal solution of a

high-dimensional problem in a low-dimensional space. Al-
though these algorithms also showed appealing performance
in case the low effective dimensionality assumption is mildly
violated, their performance may not be satisfactory on the
wider range of irreducible problems.

Divide-and-Conquer (DC) is another general idea for tack-
ling large-scale problems. In case of high-dimensional black-
box optimization, DC can be implemented by dividing the
original problem into multiple sub-problems (say of dimen-
sionality di, where i = 1, ..., M, and di < D) [Yang et al.,
2008a]. For the i-th sub-problem, x is optimized along di di-
mensions, while its values on the other D−di dimensions are
ﬁxed. That is, each sub-problem concerns a low-dimensional
subspace of the original solution space. Applying an ex-
isting search method to the i-th sub-problem leads to a di-
dimensional partial solution to the original high-dimensional
problem. The solution to original problem can be obtained by
combining the partial solutions achieved on all sub-problems.
Given an appropriate sub-problems optimizer, the above-
described DC strategy works well on the so-called separable
problems, for which the global optimal optimum can be found
by optimizing one dimension at a time regardless of the val-
ues taken on the other dimensions [Chen et al., 2010].
If
this condition does not hold, the performance of DC heavily
relies on the decomposition method [Omidvar et al., 2014],
which aims to divide a black-box high-dimensional problem
in such a way that the global optimum can still be obtained
by solving the sub-problems in a fully independent manner.
In the past few years, a large variety of decomposition meth-
ods have been proposed [Mahdavi et al., 2015]. Despite the
performance enhancement brought by them, none of these
methods are guaranteed to achieve the desired sub-problems.
Meanwhile, a practical problem of interest may be fully non-
separable such that the ideal decomposition mentioned above
does not even exist. Therefore, how to deal with (conquer)
the interdependent sub-problems remains a challenge to DC
in the context of high-dimensional optimization.

In this paper, we suggest that the major challenge of tack-
ling interdependent sub-problems lies in the difﬁculty of eval-
uating the quality of a partial solution (to a sub-problem) dur-
ing the search course. To be speciﬁc, as the quality of a partial
solution (to the original problem) depends on the values taken
on the dimensions involved in other sub-problems, precisely
evaluating a partial solution requires overwhelming compu-

tation cost, which increases exponentially with the number
of interacting variables in other sub-problems. We propose
an approximation approach for partial solution evaluation,
which yields a novel framework, named Divide and Approx-
imate Conquer (DAC). With DAC, the computational cost in-
creases polynomially with the number of solutions generated
in each iteration while the convergence to global optimum (of
the original problem) is still guaranteed.

The major difﬁculty of

tackling interdependent sub-
problems is analyzed in Section 2. The proposed DAC is
detailed in Section 3. Section 4 reports empirical studies of
DAC on ﬁve synthetic high-dimensional optimization prob-
lems and the hyper-parameters ﬁne-tuning task for multi-
class SVM. Section 5 concludes this work.
2 Major challenge of dealing with

interdependent sub-problems

The DC strategy consists of three steps:
1) (Divide) Decompose a problem into M di-dimensional

sub-problems, where i = 1, ..., M and di < D;

2) (Conquer) Search the best partial solution in each sub-

problem by applying an existing search approach;

3) Merge the best partial solutions obtained on all sub-

problems as the ﬁnal output.

We restrict our discussions here to the Conquer phase.
Usually, a derivative-free search process in each sub-problem
is guided by the solutions with better function values, despite
a few exceptions [Kirkpatrick et al., 1983; Tang et al., 2016].
Before a di-dimensional partial solution is evaluated, it must
be complemented to D-dimensional by ﬁxing the values for
the variables in other sub-problems. Specially, we call a vec-
tor of such ﬁxed D − di values as a complement to a partial
solution. A partial solution will receive different function val-
ues with different complements. Fortunately, the indetermi-
nate function values of partial solutions will not inﬂuence the
search process unless the rank of partial solutions changes, on
which the search direction is actually determined. The rank
of partial solutions may change if sub-problems are interde-
pendent, which is deﬁned as follows:
Deﬁnition 1. (Interacting Variables) [Chen et al., 2010]
Given a D-dimensional problem, its i-th and j-th variables
are said to be interacting, if the rank of two partial solutions
xi and x(cid:48)
i in the i-th dimension may change with different
complements, e.g., xj and x(cid:48)
∃x, x(cid:48)
f (x1, ..., xi, ..., xj, ..., xD) < f (x1, ..., x(cid:48)
f (x1, ..., xi, ..., x(cid:48)
j, ..., xD) > f (x1, ..., x(cid:48)
Deﬁnition 2. (Interdependent Sub-problems)
Given two arbitrary sub-problems, they are said to be inter-
dependent if at least one variable in a sub-problem is inter-
acting with at least one variable in the other sub-problem.
Intuitively, two interacting variables of the 2-D Schwefel
function are depicted in Figure 1, where the rank of two par-
tial solutions x1 and x(cid:48)
1 in the ﬁrst dimension varies by ﬁxing
different values in the second dimension, i.e., x2 and x(cid:48)
2.

i, ..., xj, ..., xD)∧
i, ..., x(cid:48)
j, ..., xD).

j, in the j-th variable:

i, x(cid:48)
j :

Figure 1: Two interacting variables of the 2-D Schwefel function.

If a problem is separable, where no interdependency ex-
ists between sub-problems, partial solutions can be comple-
mented by arbitrary identical values in X , without perturbing
their rank. However, for many non-separable problems, the
sub-problems are interdependent, where the rank of partial
solutions signiﬁcantly relies on their complements. As a re-
sult, the search direction has a close relation to the choice
of complements. Hence, the choice of complements to par-
tial solutions should be carefully addressed. Otherwise, the
search process in a sub-problem will run the risk of being
misled, eventually resulting in an ineffective search.

Unfortunately, we ﬁnd that how to accurately complement

partial solutions is a difﬁcult optimization problem.
Lemma 1. (The Difﬁculty of Accurately Complementing)
Given a set of partial solutions in the di-dimensional i-th

sub-problem, let (cid:99)Di be the set of all D variables except the
ones in the i-th sub-problem, |(cid:99)Di| be the cardinality of (cid:99)Di,
P(cid:99)Di(j) be the probability of ﬁxing a correct value for the
j-th variable in (cid:99)Di, and P be the arithmetic mean of all
P(cid:99)Di(j), j = 1, ..., D − di, then the probability of accurately

complementing those partial solutions so that they can be cor-
rectly ranked, denoted as Pi, is:

|(cid:99)Di|(cid:89)

j=1

(cid:18)(cid:80)|(cid:99)Di|
j=1 P(cid:99)Di(j)
|(cid:99)Di|

(cid:19)|(cid:99)Di|

Pi =

P(cid:99)Di(j) ≤

= P D−di

(1)

Proof. By Deﬁnition 1, we learn that ﬁxing the correct val-
ues for variables are independent events. By Deﬁnition 2,
we know that variables in the same sub-problem are non-

interacting. Thus, we can directly have Pi = (cid:81)|(cid:99)Di|
j=1 P(cid:99)Di(j).
Notice that, P(cid:99)Di(j) = 1 if the (cid:99)Di(j)-th variable is not inter-

Finally, according to the AM-GM Inequality, we have Eq.(1).

acting with any variable in the i-th sub-problem. Lemma 1
shows that the computational cost of accurately complement-
ing partial solutions increases exponentially with the number
of variables that are interacting with the current sub-problem.
Hence, the interdependent sub-problems cannot be accurately
conquered within a reasonable time budget.

3 Divide and Approximate Conquer
3.1 The Accurate Complement
According to Lemma 1, only the brute-force method is appli-
cable to accurately complement partial solutions on interde-
pendent sub-problems. However, the required computational
costs are beyond being acceptable. On the other hand, it is
an effective way to derive the mathematical formulation of a
problem by observing its corresponding brute-force method,
as such a method usually has to scan the whole solution space
and thus reﬂects the problem characteristics naturally.

The core idea of the brute-force method is mathematically

described as follow ( the maximization case is considered):

∀xi ∈ Si :
f (x∗) = f (x∗

i , x∗

r ) = max
xr∈Sr

f (x∗

i , xr) ≥ max
xr∈Sr

f (xi, xr),

(2)

i , x∗

where xi denotes a partial solution in the i-th sub-problem,
i = 1, ..., M, and xr denotes its candidate complement, where
r = [1, ..., i − 1, i + 1, ..., M ] denotes all the sub-problems
except the i-th one. Si and Sr denote the corresponding sub-
space of the solution space subjecting to |Si| · |Sr| = |S|,
where S ⊆ X and x∗ = (x∗
r ) is the optimal solution in S.
Eq.(2) states a fact that the correct rank of partial solu-
tions can be obtained by comparing their best function val-
ues among all combinations with all possible complements.
On this basis, we mathematically deﬁne the problem of accu-
rately complementing partial solutions as follow:
Deﬁnition 3. (The Accurate Complement)
Given arbitrary xi ∈ Si, a complement x†
r ∈ Sr is said to be
the accurate complement ⇐⇒ x†
xr∈Sr

r = arg max

f (xi, xr).

Notice that, every partial solution has its own accurate
complement. To identify the accurate complement, the com-
binations of xi and all possible complements in Sr should be
evaluated by f, among which the complement with the largest
function value is chosen.
3.2 DAC: an approximate approach to DC
In fact, Deﬁnition 3 allows us to approximate the accurate
complements of partial solutions with only a limited set of
candidate complements S(cid:48)

r ⊆ Sr. That is,

x†
r = arg max

f (xi, xr) (cid:23)(cid:101)x†
xr∈Sr
r means that x†

r (cid:23)(cid:101)x†

where x†

f (xi, x(cid:48)
r).

r∈S(cid:48)
x(cid:48)

r = arg max
r⊆Sr

r is more accurate than(cid:101)x†

(3)

r, since,

max
xr∈Sr

f (xi, xr) ≥ max
r∈S(cid:48)
r⊆Sr
x(cid:48)

f (xi, x(cid:48)
r).

(4)

Based on Eq.(4), it is reasonable to assume that good approx-
imate complements will perturb the rank of partial solutions
slightly. Eq.(3) thus gives rise to the proposed Divide and
Approximate Conquer (DAC), as shown in Algorithm 1.

DAC shares the same framework as the basic DC. The only
difference between them is that: while complementing a par-
tial solution, DAC always selects the complement associated
with the largest function value among a given set of candidate

Algorithm 1 DAC(f, Tmax, N)
1: Randomly initialize N solutions x1:N .
2: Divide f into M sub-problems.
3: For t = 1 to Tmax
For i = 1 to M
4:
5:
6:
7:

x(cid:48)
1:N ;i = SearchOperator(x1:N ;i).
For j = 1 to N

(cid:101)x†
(cid:101)x(cid:48)†
x1:N ;r ← {(cid:101)x†

j;r = arg max
xr∈x1:N ;r
j;r = arg max
xr∈x1:N ;r
EndFor
x1:N ;i ← {x1:N ;i; x(cid:48)

1:N ;r;(cid:101)x(cid:48)†

f (xj;i, xr).
f (x(cid:48)

j;i, xr).

1:N ;i |(cid:101)x†
1:N ;r}.

EndFor

11:
12:
13: EndFor
14: Output the best solution found so far.

8:

9:
10:

1:N ;r;(cid:101)x(cid:48)†

1:N ;r} .

complements. Speciﬁcally, DAC works by ﬁrst randomly ini-
tializing N solutions x1:N (step 1). The problem f is de-
composed into M sub-problems with a certain decomposi-
tion strategy (step 2). After that, without loss of generality,
let us consider the i-th sub-problem. N new partial solutions
x(cid:48)
1:N ;i are generated by applying some search operator to the
current ones, i.e., x1:N ;i (step 5). To identify the approximate
complement to the j-th partial solution xj;i, j = 1, ..., N, all
the combinations of xj;i and the vectors of partial solutions in
other sub-problems x1:N ;r will be evaluated by f. The vec-
tor associated with the largest function value is chosen as the
j;r to xj;i (step 7). The same strat-
j;r to the
j-th new partial solution x(cid:48)
j;i (step 8). After that, according
to a certain selection criterion, N partial solutions will be re-
mained for the next iteration (step 10). Notice that, the selec-
tion of a partial solution is conditioned by its corresponding
approximate complement. At last, for the j-th selected par-
tial solution xj;i, its corresponding partial solutions in the rest
sub-problems xj;r will be replaced with its approximate com-
plement for further optimizing (step 11).

approximate complement(cid:101)x†
egy is used to obtain the approximate complement(cid:101)x(cid:48)†

As a result, DAC consumes 2M N 2 Function Evaluations
(FEs) in each iteration, which is a signiﬁcant reduction to
the brute force method. Meanwhile, albeit the computational
time is cut down, the convergence of DAC is still guaranteed.
Lemma 2. (The Convergence of DAC)
Given a search algorithm that can converge to the global op-
timum of each sub-problem (regarded as independent prob-
lems), DAC can approximately converge to the global opti-
mum x∗ of the original problem.
Proof. With out loss of generality, let us consider the function
values of the j-th solution at the t-th and t+1-th iteration, i.e.,
f (xt

). For the i-th sub-problem, we have:

j) and f (xt+1

j

f (xt

j;i, xt

j;r) ≤ max
r∈xt
xt

1:N ;r

f (xt

j;i, xt

r) ≤ max
r∈xt
xt

1:N ;r

f (xt+1

j;i , xt
r).

(5)

where the ﬁrst ’≤’ indicates the procedure of identifying the
approximate complements for the current partial solutions
(step 7 in Algorithm 1), and the second ’≤’ represents the
procedures of generating new partial solutions (step 5 in Al-
gorithm 1), identifying their approximate complements (step
8 in Algorithm 1), and selecting better ones from candidate
partial solutions, conditioned by their approximate comple-
ments (step 10 in Algorithm 1).

Then by repeating Eq.(5) for i = 1, ..., M, we have that:

f (xt

j;1, ..., xt

(6)
which means the function value of the j-th solution f (xt
j)
monotonically increases with the iteration index t.

j;1 , ..., xt+1

j;M ),

j;M ) ≤ f (xt+1

Note that, the equality of Eq.(6) holds in two cases:
1) The approximate complement of a partial solution hap-
pens to be its corresponding partial solutions in the rest

sub-problems, i.e., xj;r =(cid:101)x†

2) The search algorithm fails to produce new better solu-

j;r;

tions, i.e., max
xr∈Sr

f (xj;i, xr) ≥ max
xr∈Sr

f (x(cid:48)

j;i, xr).

The ﬁrst case actually explains the term ”approximate” in
DAC, as it happens at a probability of at least 1
N . Hence, if
the sub-problems optimizer of DAC can optimally solve each
sub-problem separately, the global optimum value f (x∗) can
be approximately approached by DAC.
3.3 DAC-HC: an instantiation of DAC
An instantiation of DAC is presented to illustrate the detail
steps of a DAC algorithm and for further empirical studies.

To instantiate DAC, both the decomposition strategy and
the sub-problems optimizer should be speciﬁed.
In order
to highlight the advantages of the DAC framework further
in empirical studies, the improvement of performance intro-
duced by these two speciﬁed components should be kept to
minimal. On this basis, we ﬁrst decompose a problem f via
random grouping [Yang et al., 2008a]. That is, in the begin-
ning of each iteration, M equal-sized sub-problems are ran-
domly generated. For the sub-problems optimizer, a Parallel
Hill Climbing (PHC) method is employed, which thus yields
the DAC-Hill Climbing (DAC-HC). The DAC-HC conducts
N RLS processes on each sub-problem. Speciﬁcally, at each
iteration of the i-th sub-problem, the j-th RLS produces one
new partial solution x(cid:48)
j;i by applying the Gaussian mutation
operator to the current partial solution xj;i, using Eq.(7):

j;i = xj;i + I · N (0, σj;i).
x(cid:48)

(7)
where N (0, σj;i) denotes a Gaussian random variable with
zero mean and standard deviation σj;i, and I is the identity
matrix of size di. Generally, the value of σj;i represents
the search step-size that can be adaptively varied during the
search and may also be distinct over RLSs or even dimen-
sions. To keep it simple, all RLSs in DAC-HC are initially
set to the same search step-size, i.e., 1.00. After that, each
search step-size is adapted at every iteration in terms of the
1/5 successful rule [Kern et al., 2004], using Eq.(8):

σj;i = σj;i × exp 1√

D+1 (I

j;i,(cid:101)x†

j;r)≥f (xj;i,(cid:101)x†

j;r) − 1

5

f (x(cid:48)

),

(8)

Randomly divide f into M equal-sized sub-problems.
For i = 1 to M

Algorithm 2 DAC-HC(f, Tmax, N, M)
1: Randomly initialize N solutions x1:N .
2: For t = 1 to Tmax
3:
4:
5:
6:
7:

For j = 1 to N

(cid:101)x†
j;i = xj;i + I · N (0, σj;i).
x(cid:48)
f (xj;i, xr).
j;r = arg max
xr∈x1:N ;r
σj;i = σj;i×exp 1√
xj;r ←(cid:101)x†
xj;i ← {xj;i, x(cid:48)

j;i |(cid:101)x†
D+1 (I
j;r}.

j;r.

f (x(cid:48)

9:
10:
11:
12:
13: EndFor
14: Output the best solution found so far.

EndFor

EndFor

8:

j;i,(cid:101)x†

j;r)≥f (xj;i,(cid:101)x†

j;r)− 1
5 ).

where Ia is a indicator function that returns 1 if a is true and
0 otherwise.

During the selection procedure, each new partial solution
in PHC only competes with its corresponding old one for
survival. Based on this one-on-one relation, we further re-
duce the FEs consumption of DAC-HC to a half of DAC, i.e.,
M N 2. This is conducted by letting two competing partial so-
lutions share the same approximate complement. The reason
behind this is that, by adopting RLSs with small search step-
sizes, pairwise partial solutions can be close to each other in
the solution space, in which case their respective approximate
complements may also be similar. Lastly, the pseudo-code of
DAC-HC is given in Algorithm 2 for illustration.

4 Empirical Studies
DAC is proposed for solving non-separable high-dimensional
optimization problems. That is where the empirical studies
should concentrate on to verify the effectiveness of DAC-HC.
For this purpose, two sets of non-separable high-dimensional
optimization problems are employed.

i=1 [100(x2

i=1((cid:80)i

2009], which are formulated as: fsch(x) =(cid:80)D
and fros(x) =(cid:80)D−1

4.1 Varied numbers of interacting variables tests
The ﬁrst set of problems is based on the fully non-separable
functions, i.e., Schwefel’s 1.2 and Rosenbrock [Tang et al.,
j=1 xj)2
i − xi+1)2 + (xi − 1)2]. In these
two functions, all variables are interacting. Meanwhile, it
has also been observed that, in many real-world problems,
only parts of variables are interacting [Friesen and Domin-
gos, 2015]. Hence, it is a necessity to test DAC-HC with
varied numbers of interacting variables. For this purpose,
we further consider three problems that combine Schwefel’s
1.2 function and the fully separable sphere function, i.e.,
i , in different formations. The dimension-
ality is set to 1000 for all 5 problems. All variables are ran-
domly perturbed to avoid any potential bias. All problems are
expected to be minimized to the global optimal value 0.00.

fsph(x) =(cid:80)D

i=1 x2

Table 1: The formulations of 5 tested functions. z = x − o is
a shifted solution and o is the global optimum. P is a random
permutation of [1, ..., D] and D = 1000, m = 50.

f1(x) = fsch(z(P1 : Pm)) ∗ 106 + fsph(z(Pm+1 : PD))

f2(x) =(cid:80) D
f3(x) =(cid:80) D
f5(x) =(cid:80) D

f4(x) = fsch(z)

m

2m

k=1 fsch(z(P(k−1)∗m+1 : Pk∗m))
+fsph(z(P D
k=1 fsch(z(P(k−1)∗m+1 : Pk∗m))

2 +1 : PD))

m

k=1 fros(z(P(k−1)∗m+1 : Pk∗m))

Table 2: The mean and standard derivation of ﬁnal outputs.

f1

f2

f3

Function
Mean
Std
Mean
Std
Mean
Std
Mean
Std
Mean
Std

f4

f5

CMA-ES
1.35e+09
3.29e+08
0.00e+00
0.00e+00
0.00e+00
0.00e+00
2.87e+06
6.61e+05
3.36e+03
1.81e+03

RESOO
2.52e+11
3.62e+10
1.28e+07
9.41e+05
3.62e+07
2.89e+06
7.80e+07
7.10e+06
1.41e+12
8.02e+09

DECC-I
2.97e+01
8.59e+01
1.48e+03
4.28e+02
3.91e+04
2.75e+03
1.74e+06
9.54e+04
1.17e+03
9.66e+01

DAC-HC
0.00e+00
0.00e+00
1.55e+00
1.25e+00
7.78e+02
7.12e+02
3.93e+05
2.52e+04
1.13e+03
2.32e+02

Speciﬁcally, f1(x) consists of a group of 50 interacting vari-
ables and 950 independent variables. f2(x) has 10 groups of
50 interacting variables and 500 independent variables. f3(x)
and f5(x) compose of 20 groups of 50 interacting variables.
f4(x) involves a group of 1000 interacting variables. The de-
tailed formulations are listed in Table 1.

On these ﬁve problems, two groups of comparisons are

conducted for different purposes.

Advantages of DAC-HC over existing approaches
In the ﬁrst group of comparison, DAC-HC is compared with
CMA-ES [Hansen and Ostermeier, 2001], RESOO [Qian and
Yu, 2016], and DECC-I [Omidvar et al., 2014], which are
representatives of three basic ideas for high-dimensional opti-
mization: the straightforward method, dimensionality reduc-
tion, and DC, respectively. Speciﬁcally, CMA-ES is widely
endorsed as a powerful global optimizer that has been applied
in many aspects. Here the basic version of CMA-ES is uti-
lized. RESOO is a recently proposed approach built on the
Random Embedding for reducing dimensionality. It should
be noted that, DECC-I is not an algorithm for black-box op-
timization. It is an ideal approach that perfectly decomposes
the problems using the priori knowledge of functions. Hence,
all sub-problems of DECC-I are independent, while it is not
the case for DAC-HC. Besides, the sub-problems of DECC-I
are optimized by a variant of Differential Evolution [Yang et
al., 2008b], which has been empirically observed more ad-
vanced than the employed RLSs [Tang et al., 2016]. On this
basis, if DAC-HC outperforms DECC-I, it is reasonable to
infer that the proposed DAC facilitates DC on non-separable
high-dimensional optimization problems.

All algorithms are repeated 25 runs on each problem to
diminish the noise introduced by their randomized search
essence. The time budget for each run is set to 3e6 FEs.
CMA-ES is parameterless that no parameter needs to be spec-
iﬁed. For RESOO, after some coarse-tuning, the probability
η is set to 1/3, the restart times is set to 10, and the reduced
dimensionality is set to 100. For DECC-I, the only parameter,
i.e., population size N, is set to 100 as Omidvar et al. [2014]
suggested. For DAC-HC, two parameters should be speciﬁed,
i.e., the number of RLSs N and the number of sub-problems
M. Recall that, the parameter N > 1 generally inﬂuences
the approximate ability of DAC. To test the extreme case of
DAC-HC, it is set to 2. To gain a relatively fair comparison
with RESOO, we set M = 10 so that each sub-problems op-
timizer faces a 100-dimensional problem as RESOO does.

The mean and standard derivation of the ﬁnal outputs in 25
runs are shown in Table 2. A gray cell indicates an algorithm
achieves the best mean value on a problem, while a light gray
cell indicates a second place. DAC-HC outperforms all the
compared algorithms on f1, f4 and f5. On f2 and f3, though
slightly inferior to CMA-ES, DAC-HC performs signiﬁcantly
better than DECC-I and RESOO. Since DAC-HC dominates
DECC-I on all ﬁve problems, the effectiveness of DAC for
promoting DC on non-separable high-dimensional optimiza-
tion problems is conﬁrmed. Besides, Lemma 1 is veriﬁed by
observing that the solution qualities of DAC-HC deteriorates
as the number of interacting variables increases. RESOO per-
forms poorly because the tested problems are irreducible.
Empirical support to the convergence of DAC
In the second group of comparison, the PHC with 2 RLSs is
compared. The only difference between PHC and DAC-HC
is that PHC complements a partial solution xj;i merely with
the corresponding partial solutions in the rest sub-problems
xj;r. On this basis, PHC does not satisfy Eq.(5), and its con-
vergence is not guaranteed. The experimental protocol is set
the same to the ﬁrst group of comparison.

The convergence rates of both algorithms are shown in Fig-
ure 2, where the x-axis denotes the FEs and y-axis denotes the
logarithm of function values. It can be seen that, DAC-HC al-
ways converges faster than PHC. Specially, log-linear conver-
gence of DAC-HC is observed on the ﬁrst two sphere function
based problems. It should be noted that, the employed RLS
has also been theoretically proved to converge log-linearly on
the sphere function [Jebalia et al., 2008]. This coincidence
actually supports the convergence of DAC stated in Lemma
2. Comparatively, the convergence rates of PHC are heavily
retarded due to the unﬁt complements to partial solutions.
4.2 Hyper-parameter tuning for multi-class SVMs
Given a set of labelled data {xi, yi}l
i=1, where xi ∈ Rn, the
classiﬁcation task is to train a classiﬁer in terms of {xi, yi}l
i=1
to predict the labels of incoming data. Support Vector Ma-
chines (SVMs) [Vapnik, 1998] is often considered as a fam-
ily of powerful tools for classiﬁcation. Here the SVM with
linear kernel is considered. Let y ∈ {−1, +1}, SVM re-
quires to ﬁne-tune three parameters w, b, λ by solving the fol-
lowing optimization problem: minw,b,λ
i=1 ξi,
subject to yi(wT xi + b) ≥ 1 − ξi ∧ ξi ≥ 0. Notice that,
λ > 0 is a hyper-parameter supplied by the user, which

2wT w + λ(cid:80)l

1

Table 3: Testing accuracies of tuned multi-class SVM.

usps

93.92%

DataSet GridSearch RESOO CMA-ES DAC-HC
94.60%
±0.04%
85.40%
±0.11%
85.72%
±0.24%

94.38%
93.33%
±0.37% ±0.24%
85.43%
84.34%
±0.21% ±0.17%
85.36%
84.03%
±0.12% ±1.44%

85.16%

85.12%

news20

letter

-

-

-

are supposed to be. The best hyper-parameters obtained in
a run will be tested on the testing set, and the testing accu-
racy is regarded as the performance of an algorithm in a run.
The time budget for the training phase in each run is set to
100 FEs. For RESOO, the probability η is set to 1/3, the
restart times is set to 2, and the reduced dimensionality is
set to 1/5 to the original dimensionality, i.e., 9, 38, 65, re-
spectively. For the grid search, 100 candidate solutions are
uniformly selected over the solution space. For DAC-HC, the
parameters N and M are set to 2 and 3, respectively.

Table 3 lists the mean and standard derivation of the testing
accuracies of the multi-class SVMs tuned by each algorithm.
It can be seen that, both RESOO and DAC-HC outperform the
grid search, although the improvement is marginal. Hence, it
can be inferred that tuning multiple hyper-parameters, rather
than one shared hyper-parameter, is beneﬁcial to the multi-
class SVMs. DAC-HC outperforms all the compared algo-
rithms on the usps and letter datasets. Although it shows
slightly lower accuracy than RESOO on the news20 dataset,
a more stable behavior is observed as its standard derivation
is smaller. CMA-ES is inferior to the grid search on all three
problems. This phenomenon suggests that, for tuning multi-
ple hyper-parameters for multi-class SVMs, an appropriate
optimization approach should be employed. Otherwise, it
would be better to tune just one shared hyper-parameter. It
is also worthwhile to notice that, CMA-ES does not adopt
any special treatment for high-dimensional optimization.
5 Conclusions and Future Directions
This work investigated the Divide and Conquer idea on high-
dimensional black-box optimization problems. We found that
the interdependent sub-problems after decomposition actu-
ally cannot be accurately conquered. Instead, we proposed
the Divide and Approximate Conquer (DAC) to solve each
sub-problem approximately. The convergence of DAC was
proved and empirically supported. For empirical studies, a
simple instantiation of DAC, i.e., DAC-HC, was also pro-
posed. The advantages of DAC-HC over existing represen-
tative approaches were veriﬁed on two sets of non-separable
high-dimensional problems.

For future work, we are interested in:
• Promoting the ability of DAC by adopting more ad-
• Theoretically analyzing the convergence rate of DAC.

vanced sub-problems optimizers.

References
[Chang and Lin, 2011] Chih-Chung Chang and Chih-Jen
Lin. LIBSVM: A library for support vector machines.

Figure 2: The convergence rates of DAC-HC and PHC. The x-axis
denotes the FEs (time) and y-axis denotes log(f (x)).

2
K(K−1)

2

hyper-parameters to tune.

penalizes the error vector ξ. When dealing with a multi-
class classiﬁcation problem, a typical idea is to divide it into
multiple binary classiﬁcation problems by adopting the one-
on-one strategy. Let K be the number of class, then we
binary classiﬁers to train, resulting in

(cid:1) = K(K−1)

have(cid:0)K

2
Of course, a simple strategy of specifying the same value of
λ for all binary classiﬁers works well [Chang and Lin, 2011].
It is also an intuition that varied λ can facilitate a multi-class
SVM better. On this basis, a potentially high-dimensional
optimization problem needs to be solved for more advanced
performance. Recall that, a ﬁnal output of a multi-class SVM
is based on the majority voting. Due to the overﬁtting risk
on each binary classiﬁer, the votes may introduce interde-
pendencies in between. To sum up, the problem of hyper-
parameter tuning for multi-class SVMs is non-separable and
high-dimensional in essence.

We thus apply the proposed DAC-HC to deal with it. RE-
SOO and CMA-ES are again included as the compared algo-
rithms. Since the ideal decomposition is no longer applicable
for this problem, DECC-I will not be compared with DAC-
HC. The grid search is also tested but on the assumption that
all binary classiﬁers share the same value of λ. That is , the
grid search actually solves a 1-dimensional problem. Three
data sets, i.e., usps [Hull, 1994], news20 [Lang, 1995], and
letter [Hsu and Lin, 2002], are used for comparison, which
contain 10, 20, 26 classes in each and yield three problems
with 45, 190, 325 dimensions, respectively. All the features in
each dataset are scaled to [−1, 1] or [0, 1]. The solution space
for each binary classiﬁer is bounded as [10−3, 102]. All algo-
rithms are repeated for 20 runs on each problem, except the
deterministic grid search. For each run, the hyper-parameters
are tuned on the training set with the 5-fold cross-validation.
The higher the accuracy is, the better the hyper-parameters

f1f3f4f5f2[Tang et al., 2009] Ke Tang, Xiaodong Li, P. N. Suganthan,
Zhenyu Yang, and Thomas Weise. Benchmark functions
for the cec2010 special session and competition on large-
scale global optimization. Technical report, Nature In-
spired Computation and Applications Laboratory, 2009.

[Tang et al., 2016] Ke Tang, Peng Yang, and Xin Yao. Neg-
atively correlated search. IEEE Journal on Selected Areas
in Communications, 34(3):542–550, March 2016.

[Vapnik, 1998] Vladimir Vapnik. Statistical learning theory,

volume 1. Wiley New York, 1998.

[Wang et al., 2013] Ziyu Wang, Masrour Zoghi, Frank Hut-
ter, David Matheson, and Nando De Freitas. Bayesian
optimization in high dimensions via random embeddings.
In Proceedings of the Twenty-Third international joint
conference on Artiﬁcial Intelligence (IJCAI 2013), pages
1778–1784, Beijing, China, 2013. AAAI Press.

[Yang et al., 2008a] Zhenyu Yang, Ke Tang, and Xin Yao.
Large scale evolutionary optimization using cooperative
Information Sciences, 178(15):2985–2999,
coevolution.
2008.

[Yang et al., 2008b] Zhenyu Yang, Ke Tang, and Xin Yao.
Self-adaptive differential evolution with neighborhood
In IEEE Congress on Evolutionary Computa-
search.
tion, 2008 (IEEE World Congress on Computational In-
telligence), pages 1110–1116. IEEE, 2008.

ACM Transactions on Intelligent Systems and Technology,
2:27:1–27:27, 2011.

[Chen et al., 2010] Wenxiang Chen, Thomas Weise, Zhenyu
Yang, and Ke Tang. Large-scale global optimization using
cooperative coevolution with variable interaction learning.
In Parallel Problem Solving from Nature, PPSN XI, pages
300–309. Springer, 2010.

[Friesen and Domingos, 2015] Abram L Friesen and Pedro
Domingos. Recursive decomposition for nonconvex opti-
mization. In Proceedings of the 24th International Joint
Conference on Artiﬁcial Intelligence, 2015.

[Hansen and Ostermeier, 2001] Nikolaus Hansen and An-
dreas Ostermeier.
Completely derandomized self-
adaptation in evolution strategies. Evolutionary compu-
tation, 9(2):159–195, 2001.

[Hsu and Lin, 2002] Chih-Wei Hsu and Chih-Jen Lin. A
comparison of methods for multiclass support vector
IEEE Transactions on Neural Networks,
machines.
13(2):415–425, 2002.

[Hull, 1994] Jonathan J Hull. A database for handwritten text
recognition research. IEEE Transactions on Pattern Anal-
ysis and Machine Intelligence, 16(5):550–554, 1994.

[Jebalia et al., 2008] Mohamed Jebalia, Anne Auger, and
Log-linear convergence and optimal
In Artiﬁcial Evolution, pages

Pierre Liardet.
bounds for the (1+ 1)-ES.
207–218. Springer, 2008.

[Kab´an et al., 2015] Ata Kab´an, Jakramate Bootkrajang, and
Robert John Durrant. Toward large-scale continuous eda:
A random matrix theory perspective. Evolutionary com-
putation, 2015.

[Kern et al., 2004] Stefan Kern, Sibylle D M¨uller, Nikolaus
Hansen, Dirk B¨uche, Jiri Ocenasek, and Petros Koumout-
sakos. Learning probability distributions in continuous
evolutionary algorithms–a comparative review. Natural
Computing, 3(1):77–112, 2004.

[Kirkpatrick et al., 1983] S. Kirkpatrick, C. D. Gelatt, and
M. P. Vecchi. Optimization by simulated annealing. Sci-
ence, 220(4598):671–680, 1983.

[Lang, 1995] Ken Lang. Newsweeder: Learning to ﬁlter net-
news. In Proceedings of the 12th international conference
on machine learning, pages 331–339, 1995.
Mahdavi,

Moham-
mad Ebrahim Shiri, and Shahryar Rahnamayan. Meta-
heuristics in large-scale global continues optimization: A
survey. Information Sciences, 295:407–428, 2015.

[Mahdavi et al., 2015] Sedigheh

[Omidvar et al., 2014] Mohammad Nabi Omidvar, Xi-
aodong Li, Yi Mei, and Xin Yao. Cooperative co-evolution
with differential grouping for large scale optimization.
IEEE Transactions
on Evolutionary Computation,
18(3):378–393, 2014.

[Qian and Yu, 2016] Hong Qian and Yang Yu. Scaling si-
multaneous optimistic optimization for high-dimensional
non-convex functions with low effective dimensions.
In
Proceedings of the 30th AAAI Conference on Artiﬁcial In-
telligence (AAAI 2016), Phoenix, AZ, 2016.

