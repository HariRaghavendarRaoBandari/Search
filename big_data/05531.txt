LOCAL ASYMPTOTICS FOR THE FIRST INTERSECTION OF

TWO INDEPENDENT RENEWALS

KENNETH S. ALEXANDER AND QUENTIN BERGER

Abstract. We study the intersection of two independent renewal processes, ρ =

τ∩σ. Assuming that P(τ1 = n) = ϕ(n) n−(1+α) and P(σ1 = n) = (cid:101)ϕ(n) n−(1+(cid:101)α) for
some α,(cid:101)α (cid:62) 0 and some slowly varying ϕ,(cid:101)ϕ, we give the asymptotic behavior ﬁrst
of P(ρ1 > n) (which is straightforward except in the case of min(α,(cid:101)α) = 1) and

then of P(ρ1 = n). The result may be viewed as a kind of reverse renewal theorem,
as we determine probabilities P(ρ1 = n) while knowing asymptotically the renewal
mass function P(n ∈ ρ) = P(n ∈ τ )P(n ∈ σ). Our results can be used to bound
coupling-related quantities, speciﬁcally the increments |P(n ∈ τ ) − P(n − 1 ∈ τ )|
of the renewal mass function.

1. Intersection of two independent renewals

We consider two independent (discrete) renewal processes τ and σ, whose law are
denoted respectively Pτ and Pσ, and the renewal process of intersections, ρ = τ ∩ σ.
We denote P = Pτ ⊗ Pσ.

The process ρ appears in various contexts.

In pinning models, for example, it
may appear directly in the deﬁnition of the model (as in [1], where σ represents
sites with nonzero disorder values, and τ corresponds to the polymer being pinned)
or it appears in the computation of the variance of the partition function via a
replica method (see for example [20]), and is central in deciding whether disorder is
relevant or irrelevant in these models, cf. [3].

When τ and σ have the same inter-arrival distribution, ρ1 is related to the coupling
time of τ and σ, if we allow τ and σ to start at diﬀerent points. In particular, in
the case µ := E[τ1] < +∞, the coupling time ρ1 has been used to study the rate of
convergence in the renewal theorem, see [16, 17], using that

|P(n ∈ τ ) − P(n ∈ σ)| (cid:54) E(cid:2)|1{n∈τ} − 1{n∈σ}|1{ρ1>n}(cid:3) (cid:54) P(ρ1 > n) .

6
1
0
2

 
r
a

 

M
7
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
1
3
5
5
0

.

3
0
6
1
:
v
i
X
r
a

Hence, if σ is delayed by a random X having the waiting time distribution ν of the
renewal process (and denoting Pν the delayed law of σ), we have that Pν(n ∈ σ) = 1
for all n, and so Pτ ⊗ Pν(ρ1 > n) gives the rate of convergence in the renewal
theorem. This question has also been studied via a more analytic method in [18, 13].
Denoting un := P(n ∈ τ ) the renewal mass function ot τ, Rogozin [18] proved that
un − 1
study |un − un−1|, see Theorem 1.6.

(cid:80)+∞
k>n P(τ1 > k) as n → ∞.

In this paper, we consider only the non-delayed case, with a brief exception to

µ ∼ 1

µ

µ2

1

2

K. ALEXANDER AND Q. BERGER

1.1. Setting of the paper. We assume that there exist α,(cid:101)α (cid:62) 0 and slowly varying
functions ϕ,(cid:101)ϕ such that
no loss of generality, we assume that α (cid:54) (cid:101)α. We deﬁne µn := E[τ1 ∧ n] and
(cid:101)µn := E[σ1 ∧ n] the truncated means, and also E[τ1] = µ = limn→∞ µn (cid:54) ∞, and
similarly(cid:101)µ = limn→∞(cid:101)µn.

(1.1)
(As mentioned above, τ and σ are non-delayed, if not speciﬁed otherwise.) With

P(σ1 = n) = (cid:101)ϕ(n) n−(1+(cid:101)α) .

P(τ1 = n) = ϕ(n) n−(1+α) ,

The assumption (1.1) is very natural, and is widely used in the literature (for
example, once again in pinning models).
It covers in particular the case of the
return times τ = {n , S2n = 0}, where (Sn)n (cid:62) 0 is the simple symmetric nearest-
neighbor random walk on Zd (see e.g. [8, Ch. III] for d = 1, [14, Thm. 4] for d = 2
and [6, Thm. 4] for d = 3), or the case τ = {n , Sn = 0} where (Sn)n (cid:62) 0 an aperiodic
random walk in the domain of attraction of a symmetric stable law, see [15, Thm. 8].
In Section 2, we recall the strong renewal theorems for τ and σ under assumption
(1.1) (from [2, 5, 7] in the recurrent case, [11, App. A.5] in the transient case), as
well as newer reverse renewal theorems (from [2]). We collect the results when τ is
recurrent in the following table, denoting rn := P(τ1 > n), and we refer to (2.1) for
the transient case.

P(n ∈ τ ) n→∞∼ (cid:0)µn

α (cid:62) 1

(cid:1)−1

α ∈ (0, 1)
n−(1−α)ϕ(n)−1

α sin(πα)

π

α = 0

ϕ(n)
n r2
n

Table 1. Asymptotics of the renewal mass function if τ is recurrent, and has
inter-arrival distribution P(τ1 = n) = ϕ(n)n−(1+α) with α (cid:62) 0.

From Table 1 and (2.1), the renewal mass function of ρ satisﬁes

P(n ∈ ρ) = P(n ∈ τ )P(n ∈ σ) = ψ∗(n) n−θ∗

(1.2)
for some θ∗ (cid:62) 0 and slowly varying function ψ∗(n). For example, if both τ and σ
are recurrent we have
(1.3)

if also α,(cid:101)α ∈ (0, 1), then ψ∗ is a constant multiple of 1/ϕ(cid:101)ϕ. If instead both τ and σ
are transient then θ∗ = 2 + α +(cid:101)α. Note that ρ is transient for θ∗ > 1 and recurrent
for θ∗ < 1. Recalling that α (cid:54)(cid:101)α, if we deﬁne

θ∗ = 2 − α ∧ 1 −(cid:101)α ∧ 1;

α

(1.4)

α∗ =

if ρ is recurrent and α (cid:62) 1,
if ρ is recurrent and α < 1,

1 − θ∗
θ∗ − 1 if ρ is transient,

then, based on Theorem 2.1 in the transient case and Table 1 in the recurrent case,
we expect P(ρ1 = n) to be expressed as n−(1+α∗) multiplied by a slowly varying
function.

INTERSECTION OF TWO INDEPENDENT RENEWALS

3

Observe that the renewal function of ρ, deﬁned as
P(n ∈ ρ),

U∗
n :=

n(cid:88)

is always regularly varying, with exponent α∗ = 1 − θ∗ in the recurrent case and 0
in the transient case.

k=0

Our goal is to derive from (1.1) the local asymptotics of the inter-arrival distri-
bution, that is, the asymptotics of P(ρ1 = n). For general renewal processes ρ these
asymptotics should not be uniquely determined by the asymptotic behavior of the
renewal mass function (1.2) (which is known is our case), but the extra structure
given by ρ = τ ∩ σ under (1.1) makes such determination possible.
Remark 1.1. For ρ to be recurrent, it is necessary that both τ and σ are recurrent,
so (1.3) holds. It follows from Table 1 that ρ is recurrent if and only if one of the
following also holds:

(i) α +(cid:101)α > 1,
(ii) α,(cid:101)α ∈ (0, 1), α +(cid:101)α = 1 and(cid:80)
(iii) α = 0,(cid:101)α = 1 and(cid:80)
n(cid:101)µn

ϕ(n)
n r2

n (cid:62) 1

nϕ(n)(cid:101)ϕ(n) = +∞,

1

n (cid:62) 1
= +∞.

1.2. Main results.
Case of transient ρ. Since P(n ∈ ρ) is summable (with sum E(|ρ|)), we must have
θ∗ (cid:62) 1. Here the following is immediate from ([2], Theorem 1.4), given below as
Theorem 2.1.
Theorem 1.2. Assume (1.1), and suppose that ρ is transient. Then

P(ρ1 = n) n→∞∼

1

E(|ρ|)2 P(n ∈ τ )P(n ∈ σ) .

Case of recurrent ρ. Here τ and σ must be recurrent, so (1.3) holds with θ∗ ∈ [0, 1],
and α∗ = 1 − θ∗ if α (cid:54) 1, α∗ = α if α (cid:62) 1.
Theorem 1.3. Assume (1.1), and suppose that ρ is recurrent. Then for α∗ from
(1.4) (with θ∗ deﬁned as in (1.3)), the following hold.

(i) If α∗ ∈ (0, 1) then

(1.5)

(ii) If α∗ = 0 then

(1.6)

P(ρ1 > n) n→∞∼ sin(πα∗)
(cid:32) n(cid:88)

P(ρ1 > n) n→∞∼

π

ψ∗(n)−1 n−α∗

.

(cid:33)−1

,

ψ∗(j)

j

j=1

which is slowly varying.

(iii) If α∗ (cid:62) 1 then

(1.7)

P(ρ1 > n) n→∞∼ (cid:101)µnP(τ1 > n) + µnP(σ1 > n).

4

K. ALEXANDER AND Q. BERGER

In Theorem 1.3(iii), (cid:101)µn, µn are slowly varying since (cid:101)α (cid:62) α (cid:62) 1 (recall (1.4)), and
they may be replaced by µ or(cid:101)µ if that mean is ﬁnite.

We will prove Theorem 1.3 in Sections 3–4. The cases (i) and (ii) are essen-
tially immediate from known relations of form P(ρ1 > n) ∼ c/U∗
n and are given in
Item (iii) seems to be a new result, and is treated in Section 4 via a
Section 3.
probabilistic method. Note that in all cases, P(ρ1 > n) is regularly varying with
exponent −α∗.

To obtain the asymptotics of P(ρ1 = n) from Theorem 1.3 (in the case α∗ > 0),
or using the weak reverse renewal Theorem 2.2 (in the case α∗ = 0), we only need
to show that P(ρ1 = k) is approximately constant on an interval [(1− ε)n, n] with ε
small. To that end we have the following lemma, which we will prove in Section 5.
Lemma 1.4. Assume (1.1), and suppose that ρ is recurrent. Let vn := P(ρ1 >
n)2P(n ∈ ρ). Then for every δ > 0, there exists some ε > 0 such that, if n is large
enough we have for all k ∈ (0, εn)
(1.8)

(1 − δ)P(ρ1 = n − k) − δvn (cid:54) P(ρ1 = n) (cid:54) (1 + δ)P(ρ1 = n + k) + δvn.

We will see later that vn = O(P(ρ1 = n)), so Lemma 1.4 is actually true without

the δvn terms, but we will not need this improved result.

We can now state our main theorem, which we will prove in Section 6.

Theorem 1.5. Assume (1.1) with (cid:101)α (cid:62) α, and suppose that ρ is recurrent. Let α∗

be as in (1.4).

(i) If α∗ ∈ (0, 1) then

(ii) If α∗ = 0 then

ψ∗(n)−1n−(1+α∗) .

P(ρ1 = n) n→∞∼ α∗ sin(πα∗)
(cid:32) n(cid:88)

P(ρ1 = n) n→∞∼

π

ψ∗(k)

k

k=1

(cid:33)−2

ψ∗(n)

n

.

n1+α∗

(iii) If α∗ (cid:62) 1 then

We now illustrate this theorem with some subcases, using Table 1.

P(ρ1 = n) n→∞∼ (cid:101)µn P(τ1 = n) + µn P(σ1 = n) n→∞∼ (cid:101)µnϕ(n) + µn(cid:101)ϕ(n)nα−(cid:101)α
As in Theorem 1.3, in (iii),(cid:101)µn, µn may be replaced by µ or(cid:101)µ if that mean is ﬁnite.
1. If τ, σ are recurrent with α,(cid:101)α ∈ (0, 1) and α +(cid:101)α > 1, then ρ is recurrent with
α∗ = α +(cid:101)α − 1 ∈ (0, 1) and
(1.9) P(ρ1 = n) n→∞∼ cα,(cid:101)α ϕ(n)(cid:101)ϕ(n) n−(α+(cid:101)α)
α(cid:101)α sin(πα) sin(π(cid:101)α)
with cα,(cid:101)α =
2. If τ, σ are recurrent with α,(cid:101)α ∈ (0, 1), α +(cid:101)α = 1 and(cid:80)∞
n=1 1/nϕ(n)(cid:101)ϕ(n) = ∞,
α,(cid:101)αϕ(n)−1(cid:101)ϕ(n)−1 with c(cid:48)
α,(cid:101)α = α(cid:101)α sin(πα) sin(π(cid:101)α)

then ρ is recurrent, α∗ = 0, ψ∗(n) ∼ c(cid:48)

πα∗ sin(πα∗)

π2

.

.

.

INTERSECTION OF TWO INDEPENDENT RENEWALS

5

(cid:32) n(cid:88)

(cid:33)−2

Therefore,

P(ρ1 = n) n→∞∼ 1
α,(cid:101)α
c(cid:48)

(1.10)
As a special case, suppose τ = {n, S2n = 0}, σ = {n, S(cid:48)

nϕ(n)(cid:101)ϕ(n)
of independent symmetric simple random walks (SSRW) on Z. Then α = (cid:101)α = 1/2
2n = 0} are the return times
and ϕ(n) = (cid:101)ϕ(n) → 1

kϕ(k)(cid:101)ϕ(k)

π so

k=1

√

1

1

.

2

(1.11)

P(ρ1 = n) n→∞∼

π

n(log n)2 .

3.

Rotating the lattice by π/4 shows that this is the same as the return time distribution
for (Sn)n (cid:62) 0 the SSRW on Z2 (the even return times: ρ = {n, S2n = 0}). Hence
(1.11) is a classical result of Jain and Pruitt [14].

If τ is recurrent with α ∈ (0, 1), and (cid:101)α (cid:62) 1 (so (cid:101)µn is slowly varying; this

includes the case when(cid:101)µ < +∞), then α∗ = α and

P(ρ1 = n) n→∞∼ (cid:101)µn ϕ(n)n−(1+α) n→∞∼ (cid:101)µn P(τ1 = n) .

(1.12)
1.3. Application to a coupling-related quantity. We now provide an applica-
tion of Theorem 1.3.
Theorem 1.6. Let τ be a recurrent renewal process satisfying (1.1), and let un :=
P(n ∈ τ ) be its renewal mass function. There exist constants ci > 0 such that
(1.13)

|un − un−1| (cid:54) c1 unP(ρ1 > n) (cid:54)

(cid:17)−1

1

jϕ(j)2

j=1

if α = 1/2
if α > 1/2.

c2 n−αϕ(n)−1

c2 n−1/2ϕ(n)−1(cid:16)(cid:80)n
(cid:88)

Note that the right side of (1.13) is of order P(τ1 > n) when α > 1/2.

It is
summable precisely when µ = E[τ1] < +∞, and then, by Theorem 1.3(iii), (1.13)
says |un − un−1| (cid:54) c3 P(τ1 > n). This gives additional information compared to the
known asymptotics

un − 1
µ

∼ 1
µ2

k>n

P(τ1 > k)
from [18]. We can sum (1.13) to obtain |un − 1/µ| (cid:54) c3
the right order, but we cannot obtain the proper constant 1/µ2.
We also mention the works of Topchii [21, 22], treating the case when τ1 is a con-
tinuous random variable with E[τ1] = ∞ and density f (t) t→∞∼ ϕ(t)t−(1+α), studying
k=0 f∗k(t) u(t) of the renewal function, and also u(cid:48)(t). Under
some additional regularity conditions on f(cid:48)(t), letting m(t) := E[τ1 ∧ t], it is proven
that

the density u(t) =(cid:80)∞

k>n P(τ1 > k), which is of

(cid:80)

ϕ(t)−1 t−(2−α)

if 0 < α < 1,
if α = 1 and E[τ1] = ∞.

(cid:40) α(α−1) sin(πα)

π

1

m(t)2 ϕ(t) t−1

u(cid:48)(t) t→∞∼

This is a better estimate than its analog in the inﬁnite-mean case in Theorem 1.6,
but the techniques of [21, 22] do not appear adaptable to the discrete setting.

6

K. ALEXANDER AND Q. BERGER

Proof of Theorem 1.6. The second inequality in (1.13) is a direct consequence of
Theorem 1.3(iii) and Table 1, so we prove the ﬁrst one. Take σ a renewal process
independent from τ, with the same inter-arrival distribution, but starting from σ0 =
1. We can couple τ and σ so that τ = σ on [ρ1,∞). Then denoting the corresponding
joint distribution by P0,1 we have

|un − un−1| =(cid:12)(cid:12)E0,1[1{n∈τ} − 1{n∈σ}](cid:12)(cid:12) (cid:54) P0,1(n ∈ τ, ρ1 > n) + P0,1(n ∈ σ, ρ1 > n).

By Lemma A.1 there is a constant C0 such that
P0,1(n ∈ τ, ρ1 > n) (cid:54) P0,1(n ∈ τ )P0,1(ρ1 > n/4 | n ∈ τ ) (cid:54) C0 unP0,1(ρ1 > n/4),
and similarly for P0,1(n ∈ σ, ρ1 > n), since un−1 ∼ un. Now, ﬁx k0 such that
P(τ1 = k0 + 1)P(τ1 = k0) > 0, and observe that for any x > 0

P(ρ1 > x + k0) (cid:62) P(σ1 = k0 + 1)P(τ1 = k0)P0,1(ρ1 > x).

Since P(ρ1 > n) is regularly varying (cf. Theorem 1.3), it follows that there is a
constant c4 > 0 such that P0,1(ρ1 > n/4) (cid:54) c4P(ρ1 > n), and hence Theorem 1.6
(cid:3)
follows.
1.4. Organization of the rest of the paper and idea of the proof. First of
all, we recall renewal and reverse renewal theorems in Section 2, which are used
throughout the paper.

Sections 3–4 are devoted to the proof of Theorem 1.3. Items (i)-(ii) are dealt with
using Theorem 8.7.3 in [4], and our main contribution is the proof of item (iii). The
underlying idea is that, in order to have {ρ1 > n} either one of τ or σ typically makes
a jump of order at least n. We decompose P(ρ1 > n) according to the number k of
steps before τ (resp. σ) escapes beyond n by a jump larger than (1 − ε)n: we ﬁnd

that the expected number of steps is approximately (cid:101)µn (resp. µn), giving Theorem

1.3(iii).

Sections 5–6 contain the proof of Theorem 1.5. In Section 5, we prove Lemma 1.4
in two steps. First, we show that when ρ1 = n, having only gaps of length (cid:54) δn
is very unlikely ; then, given that there is, say in τ, a gap larger than δn, we can
stretch it (together with associated σ intervals) by k (cid:28) δn at little cost: this proves
that P(ρ1 = n) ≈ P(ρ1 = n + k). In Section 6, we conclude the proof of Theorem
1.5 by combining Lemma 1.4 with Theorem 1.3.

2. Background on renewal and reverse renewal theorems

We consider a renewal τ = {τ0, τ1, . . .}, with τ0 = 0. The corresponding renewal

mass function is P(n ∈ τ ), n (cid:62) 0.
2.1. On renewal theorems. In what follows we assume that the inter-arrival dis-
tribution of τ satisﬁes (1.1).
Transient case. If τ is transient, then (see [11, App. A.5])

(2.1)
where pτ∞ := P(τ1 = +∞) ∈ (0, 1).

P(n ∈ τ ) n→∞∼

1

(pτ∞)2 P(τ1 = n) ,

INTERSECTION OF TWO INDEPENDENT RENEWALS

7

Recurrent case. Here there are multiple subcases, as follows.
• If E[τ1] < +∞, then the classical Renewal Theorem says

(2.2)

n→∞ P(n ∈ τ ) =

lim

1

.

E[τ1]
• If α = 1, E[τ1] = +∞, then from [7, eq. (2.4)],
P(n ∈ τ ) n→∞∼ (µn)−1 ,

(2.3)
where µn := E(τ1 ∧ n) is slowly varying.

• If α ∈ (0, 1) then by [5, Thm. B],

(2.4)

P(n ∈ τ ) n→∞∼ α sin(πα)

π

n−(1−α)ϕ(n)−1 .

(Note that there is a typo in [5, Eq. (1.8)].)

• If α = 0, then from [2, Thm. 1.2],

(2.5)

P(n ∈ τ ) n→∞∼ P(τ1 = n)
P(τ1 > n)2 .

We recall that the results in the case of a recurrent τ are collected in Table 1.

2.2. On reverse renewal theorems. In the opposite direction, if in place of (1.1),
one assumes that P(n ∈ τ ) is regularly varying with exponent 1 − α, then for
0 (cid:54) α < 1 the asymptotics of P(τ1 > n) follow from [4, Thm. 8.7.3].
It is not
possible in general to deduce the asymptotics of P(τ1 = n), which need not even be
regularly varying. However, in certain cases, one can recover at least some behavior
of P(τ1 = n) from that of P(n ∈ τ ) when the latter is regularly varying; we call
such a result a reverse renewal theorem. Speciﬁcally, if the renewal function

n(cid:88)

Un :=

P(k ∈ τ ), n (cid:54) ∞,

k=0

is slowly varying (as happens in the case of transient τ or α = 0), the following
theorems apply.

Transient case. We write |τ| for |{τ0, τ1, . . .}|, which is geometrically distributed in
the transient case, with E(|τ|) = 1/pτ∞.
Theorem 2.1 (Theorem 1.4 in [2]). If P(n ∈ τ ) is regularly varying and τ is
transient, then

P(τ1 = n) n→∞∼

1

E(|τ|)2 P(n ∈ τ ) .

8

K. ALEXANDER AND Q. BERGER

Recurrent case. If Un is growing to inﬁnity as a slowly varying function, then we
have only a weaker reverse renewal theorem corresponding to (2.5).
Theorem 2.2 (Theorem 1.3 in [2]). If P(n ∈ τ ) is regularly varying, and if Un is
slowly varying, then there exists some εn

n→∞→ 0 such that

n(cid:88)

1
εnn

k=(1−εn)n

P(τ1 = k) n→∞∼ (Un)−2P(n ∈ τ ) .

One can therefore obtain the local asymptotics of P(τ1 = n) from this last theorem
when one can show P(τ1 = n) is approximately constant over an interval of length
o(n), as done in Lemma 1.4.

In case (i) we have U∗

slowly varying. Hence by [4, Thm. 8.7.3], in case (i),

n =(cid:80)n

ψ∗(j)
j which is

j=1

ψ∗(n)−1 n−α∗

,

3. Proof of Theorem 1.3(i), (ii)
n ∼ 1
α∗ ψ∗(n)nα∗, and in case (ii) U∗
n→∞∼ sin(πα∗)
(cid:32) n(cid:88)
(cid:33)−1

Γ(1 − α∗)Γ(1 + α∗)

ψ∗(j)

π

1
U∗

n

1

P(ρ1 > n) n→∞∼ 1
U∗

n

=

j

j=1

.

P(ρ1 > n) n→∞∼

and in case (ii),

(3.1)

4. Proof of Theorem 1.3(iii)

For α∗ (cid:62) 1 (i.e. α (cid:62) 1), we cannot extract the behavior of P(ρ1 > n) directly
n as in Section 3, and we need a preliminary result: we prove that

from that of U∗
P(ρ1 > n) is regularly varying and hence for any ε > 0 we have
P(ρ1 > εn) = O(P(ρ1 > n)) as n → ∞.
(4.1)

In Section 4.1, we prove (4.1), with the help of [10]. In Section 4.3, we prove an
upper bound for P(ρ1 > n). Finally, in Section 4.4, we prove the corresponding
lower bound.
4.1. Proof of (4.1). A sequence {un} is said to be in the de Haan class Π if there
exists a slowly varying sequence (cid:96)n such that for all λ > 0,
→ log λ as n → ∞.

u(cid:98)λn(cid:99) − un

We write RVS−α for the set of regularly varying sequences of index −α. We can
state the results of Frenk [10] as follows.
Proposition 4.1 ([10], main theorem and Lemma 4). Let ν be a renewal process,
and denote un = P(n ∈ ν). Then, we have
(4.2)

P(ν1 > n) ∈ RVS−1 ⇔ un ∈ Π .

(cid:96)n

INTERSECTION OF TWO INDEPENDENT RENEWALS

9

Moreover, for any α > 1, denoting m = E[ν1] < +∞, we have
(4.3)

P(ν1 > n) ∈ RVS−α ⇔ un − 1
m

∈ RVS1−α ,

and each implies that

(4.4)

un − 1
m

n→∞∼

1

m2(α − 1)

nP(ν1 > n) .

Using Proposition 4.1, we prove that P(ρ1 > n) is regularly varying with exponent

−α, as follows, yielding (4.1).

If α = (cid:101)α = 1, then Proposition 4.1 tells that the slowly varying sequences un =
P(n ∈ τ ),(cid:101)un = P(n ∈ σ) are both in Π, with some corresponding slowly varying
sequences (cid:96)n,(cid:101)(cid:96)n. (One expects (cid:96)n ∼ ϕ(n) but we do not have or need proof of this.)
Therefore, letting Ln :=(cid:101)(cid:96)nun +(cid:96)n(cid:101)un, the product sequence P(n ∈ ρ) = un(cid:101)un satisﬁes

u(cid:98)λn(cid:99)(cid:101)u(cid:98)λn(cid:99) − un(cid:101)un

Ln

=

u(cid:98)λn(cid:99)
un

(cid:101)u(cid:98)λn(cid:99) −(cid:101)un
(cid:101)(cid:96)n

(cid:101)(cid:96)nun

Ln

u(cid:98)λn(cid:99) − un

+

(cid:96)n

(cid:96)n(cid:101)un

Ln

(4.5)

n→∞→ log λ

µ−1

(cid:96)n

+ un

µ−1(cid:96)n

µ−1(cid:96)n

u(cid:98)λn(cid:99) − un

n→∞→ log λ,

= (cid:101)u(cid:98)λn(cid:99)

(cid:101)u(cid:98)λn(cid:99) −(cid:101)un

u(cid:98)λn(cid:99)(cid:101)u(cid:98)λn(cid:99) − un(cid:101)un

for all λ > 0, so the product sequence is in Π. Applying Proposition 4.1 again, we
see that P(ρ1 > n) is regularly varying with index −1.

If α = 1, (cid:101)α > 1, then {un} is in Π (with some corresponding slowly varying
sequence (cid:96)n), and(cid:101)un − 1(cid:101)µ is regularly varying with index 1 −(cid:101)α. Hence,
where we used that(cid:101)u(cid:98)λn(cid:99) −(cid:101)un is in RVS1−(cid:101)α so that the second term in the sum goes
to 0 (since un/(cid:96)n is regularly varying with index 0). Hence P(n ∈ ρ) = un(cid:101)un is in
If 1 < α (cid:54)(cid:101)α, then using Proposition 4.1, we get that
(cid:16) 1
(cid:17) − 1
un(cid:101)un − 1
µ(cid:101)µ
µ(cid:101)µ
(cid:101)µµ2((cid:101)α − 1)
and therefore un(cid:101)un − 1

Π, and applying Proposition 4.1, we get that P(ρ1 > n) is regularly varying with
index −1.

µ(cid:101)µ ∈ RVS1−α. Applying Proposition 4.1 again, we get that
P(ρ1 > n) is regularly varying with index −α , and so (4.1) is proven. Proposition 4.1
and (4.6) further give that

(cid:101)µ2(α − 1)

1 + o(1)
µ2(α − 1)

1 + o(1)

(cid:17)(cid:16) 1(cid:101)µ
µ(cid:101)µ2((cid:101)α − 1)
(cid:16)

µ
1 + o(1)

nP(τ1 > n) +

nP(σ1 > n),

nP(σ1 > n)

nP(τ1 > n)

+

1 + o(1)

=

=

(4.6)

+

(µ(cid:101)µ)2(α − 1)

(cid:17)
un(cid:101)un − 1
µ(cid:101)µ
= (1 + o(1))(cid:101)µP(τ1 > n) + (1 + o(1))µ
(cid:101)α − 1

α − 1

1
n

(4.7)

The second term is negligible compared to the ﬁrst if (cid:101)α > α > 1, so this proves
Theorem 1.3(iii) when 1 < α (cid:54)(cid:101)α.

P(σ1 > n)

P(ρ1 > n) = (1 + o(1))

10

K. ALEXANDER AND Q. BERGER

We will present the rest of our proof of Theorem 1.3 in the whole range 1 (cid:54) α (cid:54)(cid:101)α

even though it is now needed only for α = 1; this adds no complexity. The advantage
is that it is a more probabilistic approach, in that we use Proposition 4.1 only to
get the regular variation of P(ρ1 > n), and avoid using the un-probabilistic (4.4)
(with ν = ρ) to estimate P(ρ1 > n) as in (4.7). The method also provides an

interpretation of the terms µn,(cid:101)µn appearing in Theorem 1.3(iii).

4.2. Some useful preliminary lemmas. Before we prove Theorem 1.3(iii), we
need two technical lemmas.
Lemma 4.2. Let τ, σ be independent renewal processes, suppose ρ = τ ∩ σ is recur-
rent with E(σ1) < ∞, and let K := min{k (cid:62) 1 : τk ∈ σ}. Then E(K) = E(σ1).
Proof Since P(n ∈ ρ) = P(n ∈ τ )P(n ∈ σ), the renewal theorem gives
(4.8)
Let K1, K2, . . . be i.i.d. copies of K and let Sm := K1 +··· + Km. Then τSm has the
distribution of ρm, so using (4.8),

E(ρ1) = E(σ1)E(τ1).

→ E[ρ1] = E[τ1]E[σ1] a.s.,

τSm
m

and τSm
m

=

τSm
Sm

Sm
m

→ E[τ1]E[K] a.s.,

and the lemma follows.

(cid:3)
Write Px,y(·) for P(· | τ0 = x, σ0 = y), and write Ex,y the corresponding expecta-

α +(cid:101)α > 1.) Given η > 0, provided δ is suﬃciently small we have for large n and all

tion.
Lemma 4.3. Assume (1.1), and suppose ρ is recurrent and α∗ > 0 (equivalently,
0 (cid:54) x (cid:54) δn:
(4.9)
If also α (cid:62) 1, then the same is true with δ > 0 arbitrary. The analogous results with
τ, σ interchanged hold as well.
Proof Fix x (cid:54) δn and let N := |ρ∩ [0, n]|. Then P−x,0(ρ∩ [0, n] = ∅) = P−x,0(N =
0) and E−x,0(N | N (cid:62) 1) (cid:54) U∗

P−x,0(ρ ∩ [0, n] = ∅) < η .

n, so
E−x,0(N | N (cid:62) 1) − E−x,0(N )

E−x,0(N | N (cid:62) 1)

(cid:54) U∗

n − E−x,0(N )

U∗

n

P(j ∈ σ)(cid:2)P(j ∈ τ ) − P(j + x ∈ τ )(cid:3) .

(4.10)

while

(4.11)

P−x,0(N = 0) =

n − E−x,0(N ) =
U∗

n(cid:88)

j=0

Since P(j ∈ τ ) is regularly varying, given η > 0, there exists A (large) such that for
δ > 0, for n large we have for all x (cid:54) δn and Aδn (cid:54) j (cid:54) n that
(4.12)

P(j ∈ τ ) .

P(j ∈ τ ) − P(j + x ∈ τ ) (cid:54) η
2

INTERSECTION OF TWO INDEPENDENT RENEWALS

11

Since U∗
Aδ, is suﬃciently small then for large n we have U∗
that for large n,

k is regularly varying, with positive index since α∗ > 0, if δ, and therefore
n. With (4.11) this gives

2 U∗

(cid:54) η

Aδn

(4.13)

n − E−x,0(N ) (cid:54) U∗
U∗
With (4.10), this proves (4.9) for large n.

Aδn +

U∗

n

(cid:54) ηU∗
n.

η
2

Now consider α (cid:62) 1, meaning P(k ∈ τ ) is slowly varying. Given η > 0, for any
δ > 0 we can choose A (small this time) so that U∗
n for large n. Inequality
(4.12) holds for all j (cid:62) Aδn and x (cid:54) δn, for n large, so (4.13) is valid and (4.9)
(cid:3)
follows.

2 U∗

(cid:54) η

Aδn

4.3. Upper bound for P(ρ1 > n). Let us ﬁx ε > 0. Let us call a gap τk − τk−1 or
σk − σk−1 long if it exceeds (1 − 2ε)n; the starting and ending points of such a gap
are τk−1, τk or σk−1, σk. Let S be the ﬁrst starting point of a long gap in τ or σ, and
let T be the ending point of the gap that starts at S. (To make things well-deﬁned,
if both τ and σ have long gaps starting at S, then we take T to be the ﬁrst endpoint
among these two gaps.) Then

P(ρ1 > n) (cid:54) P(ρ1 > n, σ ∩ [εn, (1 − ε)n] (cid:54)= ∅, τ ∩ [εn, (1 − ε)n] (cid:54)= ∅)

+ P(ρ1 (cid:62) T ).

(4.14)

For ﬁxed n, we let ¯τ1 have the distribution of τ1 given τ1 (cid:54) (1 − 2ε)n, and
similarly for ¯σ1. Let ¯τ and ¯σ be renewal processes with gaps distributed as ¯τ1 and
¯σ1, respectively, and let K := min{k (cid:62) 1 : τk ∈ σ} and ¯K := min{k (cid:62) 1 : ¯τk ∈ ¯σ}.
Then, we have

(cid:19)

P(ρ1 (cid:62) T, S ∈ τ )

(cid:18)

=

(cid:88)
(cid:54) (cid:88)

k (cid:62) 0

k (cid:62) 0

K > k, τi − τi−1 (cid:54) (1 − 2ε)n for all i (cid:54) k, τk+1 − τk > (1 − 2ε)n,

P

σi − σi−1 (cid:54) (1 − 2ε)n for all i with σi−1 (cid:54) τk

P( ¯K > k)P(τ1 > (1 − 2ε)n)

(4.15)

= E[ ¯K]P(τ1 > (1 − 2ε)n).

From Lemma 4.2 we have E[ ¯K] = E(σ1 | σ1 (cid:54) (1− 2ε)n) (cid:54)(cid:101)µn. Thus for large n we

have

P(ρ1 (cid:62) T, S ∈ τ ) (cid:54) (1 − 3ε)−α(cid:101)µnP(τ1 > n).

A similar computation holds for P(ρ1 (cid:62) T, S ∈ σ) so we have for large n:
(4.16)

P(ρ1 (cid:62) T ) (cid:54) (1 − 3ε)−(cid:101)α {(cid:101)µnP(τ1 > n) + µnP(σ1 > n)} .

12

K. ALEXANDER AND Q. BERGER

We now need a much smaller bound for the ﬁrst term on the right side of (4.14).

Deﬁne U := min τ ∩ (εn,∞) and V := min σ ∩ (εn,∞). Then

P(cid:0)ρ1 > n, σ ∩ (εn, (1 − ε)n) (cid:54)= ∅, τ ∩ (εn, (1 − ε)n) (cid:54)= ∅, U < V(cid:1)

P(ρ1 > εn, U = u, V = v)Pu−v,0(ρ1 > εn).

(4.17)

(cid:88)
(cid:101)α (cid:62) α (cid:62) 1 for n large enough,

(cid:54)

u<v,u,v∈(εn,(1−ε)n)

We may now apply Lemma 4.3 for the last probability. Fix η > 0. Then, since

for all 0 (cid:54) x (cid:54) n.

P−x,0(ρ1 > εn) < η

(4.18)
Therefore, summing over u, v, the right side of (4.17) is bounded by ηP(ρ1 > εn, U <
V ), and a similar bound holds when U > V . Hence, combining this with with (4.14)
and (4.16), we get that

(4.19) P(ρ1 > n) (cid:54) (1 − 3ε)−(cid:101)α {(cid:101)µnP(τ1 > n) + µnP(σ1 > n)} + ηP(ρ1 > εn) .

Now we may use (4.1) to control the last term: we ﬁnally get that, provided η is
small enough, for large n,
(4.20)
4.4. Lower bound for P(ρ1 > n). We use a modiﬁcation of our earlier truncation.

P(ρ1 > n) (cid:54) (1 + 4(cid:101)αε){(cid:101)µnP(τ1 > n) + µnP(σ1 > n)} .

Fix n and, analogously to ¯τ , ¯σ, let(cid:98)τ and(cid:98)σ be renewal processes with gaps(cid:98)τi−(cid:98)τi−1 =
(τi−τi−1)∧(n+1) and(cid:98)σi−(cid:98)σi−1 = (σi−σi−1)∧(n+1), respectively, and let(cid:98)ρ =(cid:98)τ ∩(cid:98)σ
and (cid:98)K := min{k (cid:62) 1 :(cid:98)τk ∈(cid:98)σ}. We call a gap in(cid:98)τ or(cid:98)σ large if its length is n + 1.
Let [S(cid:98)τ , T(cid:98)τ ] and [S(cid:98)σ, T(cid:98)σ] be the ﬁrst large gaps in (cid:98)τ and (cid:98)σ respectively, and let J(cid:98)τ
and J(cid:98)σ be the number of large gaps in(cid:98)τ and(cid:98)σ respectively before time (cid:98)ρ(n)
(4.21) P(ρ1 > n) = P((cid:98)ρ1 > n) (cid:62) P(J(cid:98)τ (cid:62) 1) + P(J(cid:98)σ (cid:62) 1) − P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1).

Observe that

1 .

We claim that
(4.22)
and
(4.23)

Assuming (4.22) and (4.23), we have

P(J(cid:98)τ (cid:62) 1) (cid:62) (1 − o(1))E[J(cid:98)τ ] as n → ∞
P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1) = o (P(J(cid:98)τ (cid:62) 1) + P(J(cid:98)σ (cid:62) 1))
(cid:19)
E[J(cid:98)τ ] + E[J(cid:98)σ]
Then using Lemma 4.2 to get E[(cid:98)K] = E[(cid:98)σ1] =(cid:101)µn+1 we obtain
(cid:17)
(cid:88)
= E[(cid:98)K]P(τ1 > n) =(cid:101)µn+1P(τ1 > n),

τk+1 − τk > n, (cid:98)K > k

P(ρ1 > n) (cid:62) (1 − o(1))

E[J(cid:98)τ ]

(4.24)

(cid:18)

(cid:16)

k (cid:62) 0

P

(4.25)
and similarly for E[J(cid:98)σ]. With (4.24) this shows that
(4.26)

P(ρ1 > n) (cid:62) (1 − o(1)){(cid:101)µnP(τ1 > n) + µnP(σ1 > n)} .

as n → ∞.

.

INTERSECTION OF TWO INDEPENDENT RENEWALS

13

This and (4.20) prove Theorem 1.3(iii).

It remains to prove (4.22) and (4.23). We begin with (4.23). We write
+ P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1, S(cid:98)τ > S(cid:98)σ),

P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1) = P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1, S(cid:98)τ < S(cid:98)σ)
(4.27)
the ﬁrst(cid:98)σ renewal in the interval (S(cid:98)τ , T(cid:98)τ ), to obtain that
and we control both terms separately. On the event {S(cid:98)τ < S(cid:98)σ}, we decompose over
P(J(cid:98)τ (cid:62) 1, J(cid:98)σ (cid:62) 1, S(cid:98)τ < S(cid:98)σ) (cid:54) P(J(cid:98)τ (cid:62) 1) × sup

Px,0 (J(cid:98)σ (cid:62) 1) .

(4.28)

x∈(0,n]

From Lemma 4.3 we have that for any η > 0, for n large enough, for all 1 (cid:54) x (cid:54) n/2,
(4.29)
If x ∈ (n/2, n], then we decompose over the ﬁrst σ renewal in the interval [x/2, x) if
it exists, to get
(4.30)

Px,0 (J(cid:98)σ (cid:62) 1) (cid:54) Px,0 (ρ1 (cid:62) n/2) (cid:54) η .

Px,0 (J(cid:98)σ (cid:62) 1) (cid:54) P(σ ∩ [x/2, x) = ∅) + sup

Py,0 (J(cid:98)σ (cid:62) 1) .

y∈[1,x/2]

The last sup in bounded as in (4.29). For the ﬁrst probability on the right, using
the renewal theorem when α > 1 and [7] when α = 1, we get that there is a constant
c5 such that

x/2(cid:88)

k=1

P(σ ∩ [x/2, x) = ∅) (cid:54)

P(k ∈ σ)P(σ1 > x/2) (cid:54) c5

x
µx

ϕ(x)x−α → 0 as x → ∞.

The convergence to 0 is straightforward when α > 1, and uses that ϕ(x)/µx → 0 as
x → ∞ when α = 1 (see for example Theorem 1 in [9, Ch. VIII, Sec. 9]). It follows
that the sup in (4.28) approaches 0 as n → ∞. The second probability on the right
side of (4.27) is handled similarly, and this proves (4.23).

We now turn to (4.22). We show that for any η > 0, we can take n large enough

so that for any j (cid:62) 1,
(4.31)

This easily gives that E [J(cid:98)τ ] =(cid:80)
P(J(cid:98)τ (cid:62) j + 1) (cid:54) ηP (J(cid:98)τ (cid:62) j) .
j (cid:62) 1 P(J(cid:98)τ (cid:62) j) (cid:54) 1
1−η P(J(cid:98)τ (cid:62) 1), which is (4.22).
the endpoint of the jth large gap in (cid:98)τ. Then,
To prove (4.31), we denote T (j)(cid:98)τ
decomposing over the ﬁrst(cid:98)σ renewal in the interval [T (j)(cid:98)τ − n, T (j)(cid:98)τ ), we get, similarly
to (4.28)

P(J(cid:98)τ (cid:62) j + 1) (cid:54) P (J(cid:98)τ (cid:62) j) × sup
(cid:54) P (J(cid:98)τ (cid:62) j) sup

P0,−x (J(cid:98)τ (cid:62) 1)
P0,−x (ρ1 (cid:62) n + 1) (cid:54) η P (J(cid:98)τ (cid:62) j) ,

x∈(0,n]

x∈(0,n]

where the last inequality is valid provided that n is large enough, thanks to Lemma 4.3.
This completes the proof of (4.22), and thus also of Theorem 1.7(iii).

14

K. ALEXANDER AND Q. BERGER

5. Proof of Lemma 1.4: Stretching of gaps

By assumption ρ is recurrent, and we need to show that when n is large P(ρ1 =
n) ≈ P(ρ1 = n + k) for all k ∈ (0, εn), with ε (cid:28) 1. The idea is to take the set
of trajectories of τ and σ such that ρ1 = n, and to stretch them slightly so that
ρ1 = n + k, see Figure 1. In Section 5.1, we prove that for some δ > 0, conditioned
on ρ1 = n, the largest gap of τ and σ in [0, n] is larger than δn with high probability;
see Lemma 5.1. Assume that it is a τ-gap, and that it has length m. Then, in Section
5.2, we show that for ε (cid:28) δ we can stretch this τ-gap by k (cid:54) εn (cid:28) m, and stretch
σ inside this τ-gap by the same k, without altering the probability signiﬁcantly.

τi − τi−1 = m (cid:62) δn

0

τ

σ

j

p

t1

t2

t3

ρ1 = n

Figure 1. How to “stretch” trajectories, to go from ρ1 = n to ρ1 = n + k : we
identify the largest gap in τ (which is larger than δn with great probability, see
Lemma 5.1) and we stretch it by k, while at the same time stretching one of the
three associated σ-intervals (the largest of t1, t2, t3). See the proof of Lemma 5.2
for more detailed explanations.

5.1. Probability of having a large gap. Denote by Aδ the event that there is a
gap (either in σ or τ) longer than δn:
(5.1)
We will show that Ac

Aδ :=(cid:8)∃ i : τi − τi−1 > δn , τi (cid:54) n or σi − σi−1 > δn , σi (cid:54) n(cid:9) .

δ contributes only a small part of {ρ1 = n}. Recall that

Lemma 5.1. Assume (1.1). There exist c6 > 0 and δ0 such that if δ ∈ (0, δ0), then
for n suﬃciently large,

vn = P(ρ1 > n)2P(n ∈ ρ) .

(cid:16)

ρ1 = n ; Ac

δ

P

(cid:17) (cid:54) e−c6/δvn .

Proof On the event {ρ1 = n} ∩ Ac
δ, all τ and σ gaps are smaller than δn, and
therefore all blocks of length at least δn are visited by both τ and σ. We control
probabilities in each third of [0, n] separately. To that end, deﬁne
(cid:96)σ = max σ ∩ (0, n/3),

(cid:96)τ = max τ ∩ (0, n/3),

and deﬁne events
(5.2)

G1 : τ ∩ σ ∩ (0, n/8) = ∅,

G2 : τ ∩ σ ∩ [n/3, 2n/3] = ∅,

G3 : τ ∩ σ ∩ (7n/8, n) = ∅,

Dδτ : τi − τi−1 (cid:54) δn for all i with [τi−1, τi] ∩ [n/3, 2n/3] (cid:54)= ∅,
Dδσ : σi − σi−1 (cid:54) δn for all i with [σi−1, σi] ∩ [n/3, 2n/3] (cid:54)= ∅,

INTERSECTION OF TWO INDEPENDENT RENEWALS

15

Assuming δ < 1/12, we have Ac

L1 : (cid:96)τ , (cid:96)σ ∈ (n/4, n/3).
δ ⊆ Dδτ ∩ Dδσ ⊆ L1.

P(cid:0)G1 | i ∈ τ, j ∈ σ) (cid:54) C0P(G1).

max

(5.3)

End thirds. By Lemma A.1, there exists C0 such that

P(cid:0)G1 | (cid:96)τ = i, (cid:96)σ = j) = max
(cid:12)(cid:12) n ∈ ρ(cid:1)
δ | n ∈ ρ) (cid:54) P(cid:0)G1 ∩ G2 ∩ G3 ∩ Dδτ ∩ Dδσ
= E(cid:0)P(G1 | (cid:96)τ , (cid:96)σ)(cid:12)(cid:12) G2 ∩ G3 ∩ Dδτ ∩ Dδσ ∩ {n ∈ ρ}(cid:1)

i,j∈(n/4,n/3)

i,j∈(n/4,n/3)
It follows that
P(ρ1 =n,Ac

= P (G1 | G2 ∩ G3 ∩ Dδτ ∩ Dδσ ∩ {n ∈ ρ}) P (G2 ∩ G3 ∩ Dδτ ∩ Dδσ | n ∈ ρ)

× P (G2 ∩ G3 ∩ Dδτ ∩ Dδσ | n ∈ ρ)

(cid:54) C0P(G1)P (G2 ∩ G3 ∩ Dδτ ∩ Dδσ | n ∈ ρ) .

P(cid:0)G2 ∩ G3 ∩ Dδτ ∩ Dδσ

(5.4)
Symmetrically we obtain
(5.5)
so, using Theorem 1.3,
P(ρ1 = n,Ac

δ | n ∈ ρ) (cid:54) C 2

(cid:12)(cid:12) n ∈ ρ(cid:1)
(cid:12)(cid:12) n ∈ ρ(cid:1) (cid:54) C0P(G3)P(cid:0)G2 ∩ Dδτ ∩ Dδσ
(cid:12)(cid:12) n ∈ ρ(cid:1)
0 P(ρ1 (cid:62) n/8)2P(cid:0)G2 ∩ Dδτ ∩ Dδσ
(cid:12)(cid:12) n ∈ ρ(cid:1) .
(cid:54) c7P(ρ1 > n)2P(cid:0)G2 ∩ Dδτ ∩ Dδσ

(5.6)

Middle third. We need to bound the last probability in (5.6). We divide the
interval [n/3, 2n/3] into blocks Bi = [ai−1, ai] of length Aδn where A is a (large)
constant to be speciﬁed. We denote by d(i)
the ﬁrst and last renewals,
σ . Let Bi,(cid:96) := [ai−1, ai−1 + δn]
respectively, of τ in Bi, and similarly for d(i)
and Bi,r := [ai − δn, ai]. On the event Dδτ ∩ Dδσ, we have d(i)
σ ∈ Bi,(cid:96) and
:= [ai−1, ai−1 + Aδn/3] denote the ﬁrst third of Bi. Deﬁne
f (i)
τ , f (i)
events

σ ∈ Bi,r. Let B(1)
D(i)
δτ : τj − τj−1 (cid:54) δn for all j with τj−1 ∈ B(1)
,
δσ : σj − σj−1 (cid:54) δn for all j with σj−1 ∈ B(1)
D(i)

τ and f (i)
τ

σ , f (i)

τ , d(i)

.

i

i

i

Using again Lemma A.1, we obtain

(cid:12)(cid:12) n ∈ ρ(cid:1)

(cid:18)

P(cid:0)G2 ∩ Dδτ ∩ Dδσ
(cid:54) (cid:89)
(cid:54) (cid:89)

i (cid:54) 1/3Aδ

max
h,k∈Bi,(cid:96)

i (cid:54) 1/3Aδ

(5.7)

τ ∩ σ ∩ B(1)

i = ∅,D(i)

δτ ,D(i)

δσ

max

h,k∈Bi,(cid:96), j,m∈Bi,r

P

(cid:12)(cid:12)(cid:12) d(i)
C0 P(cid:0)τ ∩ σ ∩ B(1)

τ = h, f (i)
i = ∅,D(i)

τ = j, d(i)
δτ ,D(i)

(cid:12)(cid:12) d(i)

δσ

σ = k, f (i)

τ = h, d(i)

(cid:19)
σ = k(cid:1) .

σ = m

16

K. ALEXANDER AND Q. BERGER

We claim that for any η > 0, there exists A > 0 such that, for δ small, for n large

enough, for all h, k ∈ [0, δn),
(5.8)
This bounds all the probabilities on the right side of (5.7) by η, which with (5.6)
and (5.7) shows that, provided η is small,

(cid:0)τ ∩ σ ∩ (0, 1

3Aδn] = ∅ , D(1)

(cid:1) (cid:54) η .

δτ ,D(1)

Ph,k

δσ

P(ρ1 = n,Ac

δ | n ∈ ρ) (cid:54) c7P(ρ1 > n)2(C0η)1/3Aδ (cid:54) e−c6/δP(ρ1 > n)2,

which completes the proof of the lemma.

It remains to prove (5.8). In the case of α (cid:62) 1,(cid:101)α (cid:62) 1, we can drop the events
D(1)
δτ ,D(1)
δσ and (5.8) follows from Lemma 4.3. So suppose α < 1; we will show that
δτ ) (cid:54) η. (This is suﬃcient, since Ph,k(D(1)
δτ ) for all h, k ∈ [0, δn)
P0,0(D(1)
3A − 1.)
and the last probability is unchanged if we replace δn with 0 and 1
We therefore drop the subscript 0, 0 in the notation.
Let J := min{j (cid:62) 1 : τj − τj−1 > δn}, let ¯τ1 have the distribution of τ1 given
τ1 (cid:54) δn, and let ¯τ be a renewal process with gaps distributed as ¯τ1. We have for
k (cid:62) 1:

δτ ) (cid:54) Pδn,0(D(1)

3A with 1

P(D(1)

δτ ) (cid:54) k−1(cid:88)
(cid:54) k−1(cid:88)
(cid:54) P(cid:0)¯τk > 1

j=0

j=0

P(J = j + 1, τj > Aδn/3) + P(J > k)

P(J = j + 1)P(cid:0)¯τj > 1
3Aδn(cid:1) + e−kP(τ1>δn) .

3Aδn(cid:1) + P

(cid:18)

(cid:19)

,

(τi − τi−1) (cid:54) δn

max
i (cid:54) k

(5.9)
Then we use that for any α ∈ [0, 1) there exist some c8, c9 > 0 such that for large n,
E[¯τ1] (cid:54) c8ϕ(n)(δn)1−α, and P(τ1 > δn) (cid:62) c9ϕ(n)(δn)−α (in fact P(τ1 > δn) (cid:29) ϕ(n)
for α = 0.) We obtain that
P(D(1)

(5.10)
Choosing k = A1/2ϕ(n)−1(δn)α with A large enough, we get that P(D(1)
δτ ) (cid:54) η. This
(cid:3)
completes the proof of (5.8).
5.2. Stretching argument. We next show that, on the event Aδ, we can formalize
the stretching previously described, and the cost of the stretching is small.
Lemma 5.2. Assume (1.1). Given δ > 0, if n is suﬃciently large, then for any
k ∈ [0, 2δ3n] we have

kϕ(n)(δn)−α + e−c9kϕ(n)(δn)−α.

δτ ) (cid:54) 3c8
A

P(ρ1 = n ; Aδ(n)) (cid:54) (1 + δ)P(ρ1 = n + k) .

Proof Fix n and denote

Mτ := max{τi − τi−1 : τi (cid:54) n} and Mσ := max{σi − σi−1 : τi (cid:54) n} ,

Aτ
δ (n) := {ρ1 = n} ∩ Aδ ∩ {Mτ (cid:62) Mσ}, Aσ

δ (n) := {ρ1 = n} ∩ Aδ ∩ {Mσ > Mτ}.

INTERSECTION OF TWO INDEPENDENT RENEWALS

17

We will show that provided that δ is small enough, for n large enough and k ∈
[0, 2δ3n]
(5.11)
The analogous statement also holds with Aσ
two completes the proof.

δ (n)) (cid:54) (1 + δ)P(ρ1 = n + k , Mτ (cid:62) Mσ) .
δ (n) instead of Aτ

δ (n); combining the

P(Aτ

To prove (5.11), deﬁne random indices
i0 := min{i (cid:62) 1 : τi − τi−1 = Mτ},

(cid:96)0 := min{(cid:96) (cid:62) 1 : σ(cid:96) > τi0−1},

(cid:96)1 := min{(cid:96) (cid:62) 1 : σ(cid:96) (cid:62) τi0}.

We call [τi0−1, τi0] the maximal gap, and the three intervals [σ(cid:96)i−1, σ(cid:96)i], i = 0, 1 and
[σ(cid:96)0, σ(cid:96)1−1] are called associated σ-intervals. We decompose the probability according
to the locations of this gap and the intervals: deﬁne the events
Aτ
δ (n, j, m, p, t1, t2, t3) := Aτ

δ (n) ∩(cid:8)τi0 = j, τi0 − τi0−1 = m, σ(cid:96)0−1 = p,

σ(cid:96)0 − σ(cid:96)0−1 = t1, σ(cid:96)1−1 − σ(cid:96)0 = t2, σ(cid:96)1 − σ(cid:96)1−1 = t3

(cid:9) .

This means the maximal gap (in τ) is from j to j + m, and σ has gaps from p to
p + t1 and from p + t1 + t2 to p + t1 + t2 + t3, each containing an endpoint of the
maximal τ gap, see Figure 1. For the event to be nonempty, we must have m (cid:62) δn
and
(5.12)
Given such indices let us deﬁne I (cid:54) 3 by tI = max{t1, t2, t3}, with ties bro-
ken arbitrarily. Consider now the map Φk which assigns to each nonempty event
Aτ
δ (n, j, m, p, t1, t2, t3) the event

0 (cid:54) p < j < p + t1 (cid:54) p + t1 + t2 < j + m (cid:54) p + t1 + t2 + t3 (cid:54) n.

Aτ

Φk(Aτ

δ (n, j, m, p, t1, t2, t3)) :=

δ (n + k, j, m + k, p, t1 + k, t2, t3)
Aτ
δ (n + k, j, m + k, p, t1, t2 + k, t3)
Aτ
δ (n + k, j, m + k, p, t1, t2, t3 + k)

if I = 1,
if I = 2,
if I = 3.

Applying Φk corresponds to stretching the maximal gap and the longest of the
It is easy to see that for distinct tuples
associated σ-intervals by the amount k.
(j, m, p, t1, t2, t3), the corresponding events Φk(Aτ
δ (n, j, m, p, t1, t2, t3)) are disjoint
subsets of Aτ
δ (n + k); this just means that the relevant interval and gap lengths
in the original conﬁguration are identiﬁable from the stretched conﬁguration. We
claim that provided δ is small enough, for n large enough and k ∈ [0, 2δ3n],
P (Aτ
(5.13)
whenever Aτ
δ (n, j, m, p, t1, t2, t3) (cid:54)= ∅. Due to the aforementioned disjointness, sum-
ming this over (j, m, p, t1, t2, t3) immediately yields (5.11). To prove (5.13), note
that if I = 1 then t1 (cid:62) m/3, so k/t1 (cid:54) 6δ2, while k/m < 2δ2, so provided δ is small,

δ (n, j, m, p, t1, t2, t3)) (cid:54) (1 + δ)P(cid:0)Φk

(cid:0)Aτ
δ (n, j, m, p, t1, t2, t3)(cid:1)(cid:1)

P (Aτ
P (Φk(Aτ

δ (n, j, m, p, t1, t2, t3))
δ (n, j, m, p, t1, t2, t3)))

=

P(τ1 = m)

P(σ1 = t1)

P(τ1 = m + k)

P(σ1 = t1 + k)

< 1 + δ.

18

K. ALEXANDER AND Q. BERGER

The same bound holds if I = 3. If I = 2 we have t2 (cid:62) m/3, so k/t2 (cid:54) 6δ2, and
provided that δ is small

P (Aτ
P (Φk(Aτ

δ (n, j, m, p, t1, t2, t3))
δ (n, j, m, p, t1, t2, t3)))

=

P(τ1 = m)

P(τ1 = m + k)

P(t2 ∈ σ)
P(t2 + k ∈ σ)

< 1 + δ.

The claim (5.13), and hence the lemma, now follow.

(cid:3)
We proceed with the proof of Lemma 1.4. Indeed, the second inequality in (1.8) is
immediate from Lemmas 5.1 and 5.2. Also, since vn is regularly varying, Lemma 5.1
gives that for δ small, for any j ∈ (0, δ3n],

P(ρ1 = n − j ; Ac

δ(n − j)) (cid:54) 2e−c6/δvn .

This and Lemma 5.2 yield that for any k ∈ (0, δ3n] ⊆ (0, 2δ3(n − k)],
(5.14)
and the ﬁrst inequality in (1.8) follows.

P(ρ1 = n − k) (cid:54) (1 + δ)P(ρ1 = n) + 2e−c6/δvn .

6. Proof of Theorem 1.5

Let

A+

n (ε) :=
A−
n (ε) :=

P(ρ1 > n) − P(ρ1 > (1 + ε)n)
P(ρ1 > (1 − ε)n) − P(ρ1 > n)

εn

,

.

εn

We claim that, if ρ is recurrent, there is a constant c10 > 0 such that for suﬃciently
small ε > 0, when n is large,
vn (cid:54) c10A±
(6.1)
It is suﬃcient to prove this for A+
n (ε), since vn is regularly varying. Consider ﬁrst
α∗ = 0. It follows readily from (3.1) and Theorem 2.2 that for small ε, when n is
large we have

n (ε) .

(6.2)
Next consider α∗ ∈ (0, 1). Here α∗ = 1 − θ∗, so by Theorem 1.3, for some c11, for
small ε we have for large n

n)−2P(n ∈ ρ) (cid:62) 1
4

n (ε) (cid:62) 1
A+
2

(U∗

vn .

n (ε) (cid:62) c11n−(1+α∗)ψ∗(n)−1 = c11n−θ∗
A+

Finally consider α∗ (cid:62) 1; here 1 (cid:54) α (cid:54) (cid:101)α. Since P(τ1 = n) and P(σ1 = n) are

regularly varying, it follows from Theorem 1.3 that for ε small and large n,

ψ∗(n)−2 (cid:62) c12vn .

ψ∗(n)n−2α∗

n (ε) (cid:62) 1
A+
2

((cid:101)µnP(τ1 = n) + µnP(σ1 = n)) =(cid:101)µn
(cid:101)ϕ(n)
n(cid:101)α

(cid:18)(cid:101)µn

ϕ(n)
n2α

ϕ(n)
µn

µn(cid:101)µn

Using (a + b)2 (cid:54) 2a2 + 2b2, we obtain
(6.3)
vn (cid:54) 2

(cid:19)2

(cid:18)(cid:101)µn

ϕ(n)
nα + µn

(cid:54) 4

1

(cid:101)ϕ(n)
2n1+(cid:101)α .
(cid:19)
(cid:101)ϕ(n)(cid:101)µn

ϕ(n)
2n1+α + µn

(cid:101)ϕ(n)
n2(cid:101)α

+ µn

(cid:54) A+

n (ε),

INTERSECTION OF TWO INDEPENDENT RENEWALS

19

where for last inequality we used that
when α = 1), and similarly

(cid:101)ϕ(n)
n(cid:101)α−1(cid:101)µn

ϕ(n)
nα−1µn

→ 0. The claim (6.1) is now proved.

→ 0 as n → ∞ (since ϕ(n)/µn → 0

For δ suﬃciently small, applying Lemma 1.4 and (6.1) we get that for n large and

c13 = c10 + 1,
(6.4)
Similarly, we get
(6.5)

P(ρ1 = n) (cid:62) (1 − c13δ)A−

n (δ3) .

P(ρ1 = n) (cid:54) (1 + c13δ)A+

n (δ3) .

If α∗ = 0, as with (6.2) it follows easily from Theorem 2.2 that for large n we have

n (δ3) (cid:62) (1 − δ)(U∗
A−

n)−2P(n ∈ ρ),
If α∗ ∈ (0, 1), then by Theorem 1.3(i), when δ is small we have for large n

and then part (ii) of the theorem follows from (6.4) and (6.5).

n)−2P(n ∈ ρ) and A+

n (δ3) (cid:54) (1 + δ)(U∗

and again part (i) of the theorem follows from (6.4) and (6.5).

If α∗ (cid:62) 1, then by Theorem 1.3(iii), when δ is small we have for large n

n (δ3) (cid:62) (1 − δ)
A−
n (δ3) (cid:54) (1 + δ)
A+

α∗ sin(πα∗)

π

α∗ sin(πα∗)

ψ∗(n)−1n−(1+α∗),

ψ∗(n)−1n−(1+α∗),

π

(cid:18)(cid:101)µn
(cid:18)(cid:101)µn

(cid:19)
(cid:19)

,

,

(cid:101)ϕ(n)
n1+(cid:101)α
(cid:101)ϕ(n)
n1+(cid:101)α

ϕ(n)
n1+α + µn
ϕ(n)
n1+α + µn

n (δ3) (cid:62) (1 − δ)
A−

n (δ3) (cid:54) (1 + δ)
A+

and part (iii) of the theorem follows once more from (6.4) and (6.5).
Appendix A. Extension of Lemma A.2 in [12]

(cid:3)

We generalize here Lemma A.2 of [12], which covers α > 0, to include α = 0. The

idea is essentially unchanged, but the computations are diﬀerent.
Lemma A.1. Assume that P(τ1 = k) = ϕ(k)k−(1+α) for some α (cid:62) 0 and some
slowly varying function ϕ(·). Then, there exists a constant C0 > 0 such that, for
all suﬃciently large n, for any non-negative function fn(τ ) depending only on τ ∩
{0, . . . , n}, we have

E[fn(τ ) | 2n ∈ τ ] (cid:54) C0E[fn(τ )] .

Proof We deﬁne Xn to be the last τ-renewal up to n. It is suﬃcient to show that
there exists c14 > 0 such that for large n, for any 0 (cid:54) m (cid:54) n
P(2n ∈ τ | Xn = m) (cid:54) c14P(2n ∈ τ ) .
(A.1)
To prove this, we write

(A.2)

P(2n ∈ τ | Xn = m) =

P(τ1 = j + n − m|τ1 (cid:62) n − m)P(n − j ∈ τ ).

n(cid:88)

j=1

20

K. ALEXANDER AND Q. BERGER

We split this sum into j (cid:54) n/2 and j > n/2.

For j (cid:54) n/2, we use that P(k ∈ τ ) is regularly varying and n− j (cid:62) n/2, to bound

the corresponding part of the sum in (A.2) by

P(τ1 = j + n − m|τ1 (cid:62) n − m) (cid:54) c15P(2n ∈ τ ) .

P(k ∈ τ ) × n(cid:88)

j=1

sup
k (cid:62) n/2

For j > n/2, we use that for n (cid:62) j > n/2 and n (cid:62) m (cid:62) 0,

P(τ1 = j + n− m | τ1 (cid:62) n− m) (cid:54) c16P(τ1 = n | τ1 (cid:62) n− m) (cid:54) c16P(τ1 = n | τ1 (cid:62) n)
to bound the corresponding part of the sum in (A.2) by

c16

P(τ1 = n)
P(τ1 (cid:62) n)

Un (cid:54)

c17P(2n ∈ τ )
if α = 0;
c18n−1Un (cid:54) c19P(2n ∈ τ )

if α > 0.

(cid:40)

Here for α = 0 we used (2.5), and for α > 0 we used the regular variation of
P(n ∈ τ ). This completes the proof of (A.1).
(cid:3)

References

[1] K. S. Alexander and Q. Berger, Pinning a renewal on a quenched renewal, in preparation.
[2] K. S. Alexander and Q. Berger, Renewal theory with index 0, preprint.
[3] Q. Berger and H. Lacoin, Pinning on a defect line: characterization of marginal disorder

relevance and sharp asymptotics for the critical point shift

[4] N. H. Bingham, C. M. Goldie and J. L. Teugels, Regular variations, Cambridge University

Press, Cambridge, 1987.

[5] R. A. Doney, One-sided local large deviation and renewal theorems in the case of an inﬁnite

mean, Probab. Theory Relat. Fields, 107 pp. 451–465, 1997.

[6] R. A. Doney and D. A. Korshunov, Local asymptotics for the time of ﬁrst return to the origin

of transient random walk, Stat. Probab. Letters, 81 5 pp. 363–365, 2011.

[7] K. B. Erickson, Strong renewal theorems with inﬁnite mean, Transaction of the Americ. Math.

Soc., 151, 1970.

[8] W. Feller, An introduction to probability theory and its applications, Vol. I, 2nd edition, Wiley
series in probability and mathematical statistics, John Wiley & Sons. Inc., New York-London-
Sydney, 1966.

[9] W. Feller, An introduction to probability theory and its applications, Vol. II, 2nd edition, Wiley
series in probability and mathematical statistics, John Wiley & Sons. Inc., New York-London-
Sydney, 1966.
[10] J. B. G. Frenk, The behavior of the renewal sequence in case the tail of the waiting-time
distribution is regularly varying with index −1, Adv. Applied Probab., 14, No. 4, pp. 870-884,
1982.

[11] G. Giacomin, Random polymer models, Imperial College Press, 2007.
[12] G. Giacomin, H. Lacoin and F. L. Toninelli, Marginal relevance of disorder for pinning models

Commun. Pure Appl. Math., 63 pp. 233–265, 2010.

[13] R. Grübel, Functions of discrete probability measures: rates of convergence in the renewal

theorem, Z. Wahrscheinlichkeitstheorie 64 pp. 341–357, 1983.

[14] N. C. Jain and W. E. Pruitt, The range of random walk, Proc. Sixth Berkeley Symp. Math.

Statist. Probab. 3 pp. 31–50, Univ. California Press, Berkeley, 1972.

[15] H. Kesten, Ratio Theorems for Random Walks II, J. Analyse Math. 11, pp. 323-379, 1963.
[16] T. Lindvall, On coupling of discrete renewal processes, Z. Wahrscheinlichkeitstheorie 48 pp.

57–70, 1979.

INTERSECTION OF TWO INDEPENDENT RENEWALS

21

[17] P. Ney A reﬁnment of the coupling method in renewal theory, Stochastic Process. Appl., 11

pp. 11–26, 1981.

[18] B. A. Rogozin, An estimate of the remainder term in limit theorems of renewal theory, Teor.

Verojatnost. i Primenen. 18 (1973), 703–717. MR0334339 (48 #12658)

[19] J. L. Teugels, The class of subexponential distributions, Ann. Probab. 3 6 pp. 1000–1011, 1975.
[20] F. L. Toninelli, A replica-coupling approach to disordered pinning models, Commun. Math.
[21] V. A. Topchii, Derivative of renewal density with inﬁnite moment with α ∈ (0, 1/2], Sib.

Phys. 280 pp. 389–401, 2008.

Èlektron. Mat. Izv. 7 pp. 340–349, 2010.
[22] V. A. Topchii, The asymptotic behaviour of derivatives of the renewal function for distributions
with inﬁnite ﬁrst moment and regularly varying tails of index β ∈ (1/2, 1], Discrete Math.
Appl. 22 (3) 315-344, 2012.

Department of Mathematics, KAP 108, University of Southern California, Los

Angeles, CA 90089-2532 USA

LPMA, Université Pierre et Marie Curie, Campus Jussieu, case 188, 4 place

Jussieu, 75252 Paris Cedex 5, France

E-mail address: quentin.berger@upmc.fr

