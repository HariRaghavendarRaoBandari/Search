6
1
0
2

 
r
a

M
 
0
2

 
 
]

.

M
P
n
i
f
-
q
[
 
 

1
v
3
8
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Risk-Constrained Kelly Gambling

Enzo Busseti

Ernest K. Ryu

Stephen Boyd

March 22, 2016

Abstract

We consider the classic Kelly gambling problem with general distribution of out-
comes, and an additional risk constraint that limits the probability of a drawdown of
wealth to a given undesirable level. We develop a bound on the drawdown probability;
using this bound instead of the original risk constraint yields a convex optimization
problem that guarantees the drawdown risk constraint holds. Numerical experiments
show that our bound on drawdown probability is reasonably close to the actual draw-
down risk, as computed by Monte Carlo simulation. Our method is parametrized
by a single parameter that has a natural interpretation as a risk-aversion parameter,
allowing us to systematically trade oﬀ asymptotic growth rate and drawdown risk.
Simulations show that this method yields bets that out perform fractional-Kelly bets
for the same drawdown risk level or growth rate. Finally, we show that a natural
quadratic approximation of our convex problem is closely connected to the classical
mean-variance Markowitz portfolio selection problem.

1

Introduction

In 1956 John Kelly proposed a systematic way to allocate a total wealth across a num-
ber of bets so as to maximize the long term growth rate when the gamble is repeated
[Kel56, MTZ11]. Similar results were later derived in the ﬁnance literature, under the name
of growth-optimum portfolio; see, e.g., [Mer90, Ch. 6]). It is well known that with Kelly op-
timal bets there is a risk of the wealth dropping substantially from its original value before
increasing, i.e., a drawdown. Several ad hoc methods can be used to limit this drawdown risk,
at the cost of decreased growth rate. The best known method is fractional Kelly betting, in
which only a fraction of the Kelly optimal bets are made [DL12]. The same method has been
proposed in the ﬁnance literature [Bro00]. Another ad hoc method is Markowitz’s mean-
variance portfolio optimization [Mar52], which trades oﬀ two objectives that are related to,
but not the same as, long term growth rate and drawdown risk.

In this paper we directly address drawdown risk and show how to ﬁnd bets that trade oﬀ
drawdown risk and growth rates. We introduce the risk-constrained Kelly gambling problem,
in which the long term wealth growth rate is maximized with an additional constraint that
limits the probability of a drawdown to a speciﬁed level. This idealized problem captures

1

what we want, but seems very diﬃcult to solve. We then introduce a convex optimization
problem that is a restriction of this problem; that is, its feasible set is smaller than that of
the risk-constrained problem. This problem is tractable, using modern convex optimization
methods.

Our method can be used in two ways. First, it can be used to ﬁnd a conservative set
of bets that are guaranteed to satisfy a given drawdown risk constraint. Alternatively, its
single parameter can be interpreted as a risk-aversion parameter that controls the trade-oﬀ
between growth rate and drawdown risk, analogous to Markowitz mean-variance portfolio
optimization [Mar52], which trades oﬀ mean return and (variance) risk. Indeed, we show
that a natural quadratic approximation of our convex problem can be closely connected to
Markowitz mean-variance portfolio optimization.
In §2 we review the Kelly gambling problem, and describe methods for computing the
optimal bets using convex optimization. In simple cases, such as when there are two possible
outcomes, the Kelly optimal bets are well known. In others, for example when the returns
come from inﬁnite distributions, the methods do not seem to be well known. In §3, we deﬁne
the drawdown risk, and in §4, we derive a bound on the drawdown risk. In §5, we use this
bound to form the risk-constrained Kelly gambling problem, which is a tractable convex
optimization problem. In §6, we derive a quadratic approximation of the risk-constrained
Kelly gambling problem, and relate it to classical Markowitz portfolio optimization. Finally,
in §7 we give some numerical examples to illustrate the methods.

2 Kelly gambling

In Kelly gambling, we place a ﬁxed fraction of our total wealth (assumed positive) on n bets.
We denote the fractions as b ∈ Rn, so b ≥ 0 and 1T b = 1, where 1 is the vector with all
components 1. The n bets have a random nonnegative payoﬀ or return, denoted r ∈ Rn
+, so
the wealth after the bet changes by the (random) factor rT b. We will assume that all bets
do not have inﬁnite return in expectation, i.e., that Eri < ∞ for i = 1, . . . , n. We will also
assume that the bet n has a certain return of one, i.e., rn = 1 almost surely. This means
that bn represents the fraction of our wealth that we do not wager, or hold as cash. The bet
vector b = en corresponds to not betting at all. We refer to the bets 1, . . . , n− 1 as the risky
bets.

We mention some special cases of this general Kelly gambling setup.
• Two outcomes. We have n = 2, and r takes on only two values: (P, 1), with probability
π, and (0, 1), with probability 1− π. The ﬁrst outcome corresponds to winning the bet
(π is the probability of winning) and P > 1 is the payoﬀ.

• Mutually exclusive outcomes. There are n−1 mutually exclusive outcomes, with return
vectors: r = (Pkek, 1) with probability πk > 0, for k = 1, . . . , n − 1, where Pk > 1 is
the payoﬀ for outcome k, and ek is the unit vector with kth entry one and all others
0. Here we bet on which of outcomes 1, . . . , n − 1 will be the winner (e.g., the winner
of a horse race).

2

• General ﬁnite outcomes. The return vector takes on K values r1, . . . , rK, with proba-
bilities π1, . . . , πK. This case allows for more complex bets, for example in horse racing
show, place, exacta, perfecta, and so on.

• General returns. The return r comes from an arbitrary inﬁnite distribution (with
rn = 1 almost surely). If the returns are log-normal, the gamble is a simple model of
investing (long only) in n − 1 assets with log-normal returns; the nth asset is risk free
(cash). More generally, we can have n − 1 arbitrary derivatives (e.g., options) with
payoﬀs that depend on an underlying random variable.

2.1 Wealth growth

The gamble is repeated at times (epochs) t = 1, 2, . . ., with IID (independent and identically
distributed) returns. Starting with initial wealth w1 = 1, the wealth at time t is given by

wt = (rT

1 b)··· (rT

t−1b),

where rt denotes the realized return at time t (and not the tth entry of the vector). The
wealth sequence {wt} is a stochastic process that depends on the choice of the bet vector
b, as well as the distribution of return vector r. Our goal is to choose b so that, roughly
speaking, the wealth becomes large.
Note that wt ≥ 0, since r ≥ 0 and b ≥ 0. The event wt = 0 is called ruin, and can
only happen if rT b = 0 has positive probability. The methods for choosing b that we discuss
below all preclude ruin, so we will assume it does not occur, i.e., wt > 0 for all t, almost
surely. Note that if bn > 0, ruin cannot occur since rT b ≥ bn almost surely.

With vt = log wt denoting the logarithm of the wealth, we have

vt = log(rT

1 b) + ··· + log(rT

t−1b).

Thus {vt} is a random walk, with increment distribution given by the distribution of log(rT b).
The drift of the random walk is E log(rT b); we have Evt = (t − 1)E log(rT b), and var vt =
(t − 1) var log(rT b). The quantity E log(rT b) can be interpreted as the average growth rate
of the wealth; it is the drift in the random walk {vt}. The (expected) growth rate E log(rT b)
is a function of the bet vector b.

2.2 Kelly gambling

In Kelly gambling, we choose b to maximize E log(rT b), the growth rate of wealth. This
leads to the optimization problem

maximize E log(rT b)
subject to 1T b = 1,

b ≥ 0,

(1)

with variable b. We call a solution b(cid:63) of this problem a set of Kelly optimal bets. The
Kelly gambling problem is always feasible, since b = en (which corresponds to not placing

3

any bets) is feasible. This choice achieves objective value zero, so the optimal value of the
Kely gambling problem is always nonnegative. The Kelly gambling problem (1) is a convex
optimization problem, since the objective is concave and the constraints are convex.

t , then w(cid:63)

t / ˜wt → ∞ with probability one as t → ∞.

Kelly optimal bets maximize growth rate of the wealth. If ˜b is a bet vector that is not
Kelly optimal, with associated wealth sequence ˜wt, and b(cid:63) is Kelly optimal, with associated
wealth sequence w(cid:63)
(This follows
t − log ˜wt has positive drift [Fel71, §XII.2]. Also
immediately since the random walk log w(cid:63)
see [CT12, §16] for a general discussion of Kelly gambling.)
We note that the bet vector b = en is Kelly optimal if and only if Eri ≤ 1 for i =
1, . . . , n−1. Thus we should not bet at all if all the bets are losers in expectation; conversely,
if just one bet is a winner in expectation, the optimal bet is not the trivial one en, and the
optimal growth rate is positive. We show this in the appendix.

2.3 Computing Kelly optimal bets

Here we describe methods to compute Kelly optimal bets, i.e., to solve the Kelly optimization
problem (1). It can be solved analytically or semi-analytically for simple cases; the general
ﬁnite outcomes case can be handled by standard convex optimization tools, and the general
case can be handled via stochastic optimization.

Two outcomes. For a simple bet with two outcomes, with win probability π and payoﬀ
P , we obtain the optimal bet with simple minimization of a univariate function. We have

(cid:18) πP − 1

P − 1

P − πP
P − 1

,

(cid:19)

,

b(cid:63) =

provided πP > 1; if πP ≤ 1, the optimal bet is b(cid:63) = (0, 1). Thus we should bet a fraction
(πP − 1)/(P − 1) of our wealth each time, if this quantity is positive.

General ﬁnite outcomes. When the return distribution is ﬁnite the Kelly gambling
problem reduces to

maximize (cid:80)K

subject to 1T b = 1,

i=1 πi log(rT

i b)
b ≥ 0,

(2)

which is readily solved using convex optimization methods [BV04]. Convex optimization
software systems like CVX [GB14], CVXPY [DB16] and Convex.jl [UMZ+14], based on DCP
(Disciplined Convex Programming) [GBY06], or others like YALMIP [L¨04], can handle such
problems directly. In our numerical simulation we use CVXPY with the open source solver
ECOS [DCB13], recently extended to handle exponential cone constraints [Ser15].

General returns. We can solve the Kelly gambling problem (1) even in the most general
case, when r takes on an inﬁnite number of values, provided we can generate samples from
the distribution of r. In this case we can use a projected stochastic gradient method with
averaging [RM51, NY83, Pol87, KY03, Bub15].

4

As a technical assumption we assume here that the Kelly optimal bet b(cid:63) satisﬁes (b(cid:63))n > 0,
i.e., the optimal bet involves holding some cash. We assume we know ε > 0 that satisﬁes
ε < (b(cid:63))n (which implies that rT b > ε a.s.) and deﬁne ∆ε = {b | 1T b = 1, b ≥ 0, bn ≥ ε}.
Then the gradient of the objective is given by

1
r
rT b
for any b ∈ ∆ε. So if r(k) is an IID sample from the distribution,

∇bE log(rT b) = E∇b log(rT b) = E

1

r(k)T b

r(k)

(3)

is an unbiased estimate of the gradient, i.e., a stochastic gradient, of the objective at b.
(Another unbiased estimate of the gradient can be obtained by averaging the expression (3)
over multiple return samples.)

The (projected) stochastic gradient method with averaging computes the iterates

(cid:32)

(cid:33)

¯b(k+1) = Π

¯b(k) +

r(k)

,

k = 1, 2, . . . ,

tk

(r(k)T ¯b(k))

where the starting point ¯b(1) is any vector in ∆ε, r(k) are IID samples from the distribution
of r, and Π is (Euclidean) projection onto ∆ε (which is readily computed; see Lemma 3).
The step sizes tk > 0 must satisfy

tk → 0,

tk = ∞.

∞(cid:88)

k=1

(cid:80)k
(cid:80)k

i=1 ti

¯b(i)
i=1 ti

b(k) =

√
k with any C > 0 satisﬁes this condition.) Then the (weighted)
(For example, tk = C/
running average

converges to Kelly optimal. The stochastic gradient method can be slow to converge, but it
always works; that is E log(rT b(k)) converges to the optimal growth rate.

In practice, one does not know a priori how small ε should be. One way around this
is to choose a small ε, and then check that (b(k))n > ε holds for large k, in which case we
know our guess of ε was valid. A more important practical variation on the algorithm is
batching, where we replace the unbiased estimate of the gradient with the average over some
number of samples. This does not aﬀect the theoretical convergence of the algorithm, but
can improve convergence in practice.

5

3 Drawdown

We deﬁne the minimum wealth as the inﬁmum of the wealth trajectory over time,

W min = inf

t=1,2,...

wt.

This is a random variable, with distribution that depends on b. With b = en, we have wt = 1
for all t, so W min = 1. With b for which E log(rT b) > 0 (which we assume), W min takes
values in (0, 1]. Small W min corresponds to a case where the initial wealth drops to a small
value before eventually increasing.
The drawdown is deﬁned as 1−W min. A drawdown of 0.3 means that our wealth dropped
30% from its initial value (one), before increasing (which it eventually must do, since vt → ∞
with probability one). Several other deﬁnitions of drawdown are used in the literature. A
large drawdown means that W min is small, i.e., our wealth drops to a small value before
growing.
The drawdown risk is deﬁned as Prob(W min < α), where α ∈ (0, 1) is a given target (un-
desired) minimum wealth. This risk depends on the bet vector b in a very complicated way.
There is in general no formula for the risk in terms of b, but we can always (approximately)
compute the drawdown risk for a given b using Monte Carlo simulation. As an example,
a drawdown risk of 0.1 for α = 0.7 means the probability of experiencing more than 30%
drawdown is only 10%. The smaller the drawdown risk (with any target), the better.

3.1 Fractional Kelly gambling

It is well known that Kelly optimal bets can lead to substantial drawdown risk. One ad hoc
method for handling this is to compute a Kelly optimal bet b(cid:63), and then use the so-called
fractional Kelly [DL12] bet given by

b = f b(cid:63) + (1 − f )en,

(4)
where f ∈ (0, 1) is the fraction. The fractional Kelly bet scales down the (risky) bets by f .
Fractional Kelly bets have smaller drawdowns than Kelly bets, at the cost of reduced growth
rate. We will see that trading oﬀ growth rate and drawdown risk can be more directly (and
better) handled.

3.2 Kelly gambling with drawdown risk

We can add a drawdown risk constraint to the Kelly gambling problem (1), to obtain the
problem

maximize E log(rT b)
subject to 1T b = 1,

b ≥ 0,

(5)

with variable b, where α, β ∈ (0, 1) are given parameters. The last constraint limits the
probability of a drop in wealth to value α to be no more than β. For example, we might

Prob(W min < α) < β,

6

take α = 0.7 and β = 0.1, meaning that we require the probability of a drawdown of more
than 30% to be less than 10%. (This imposes a constraint on the bet vector b.)

Unfortunately the problem (5) is, as far as we know, a diﬃcult optimization problem in
general. In the next section we will develop a bound on the drawdown risk that results in
a tractable convex constraint on b. We will see in numerical simulations that the bound is
generally quite good.

4 Drawdown risk bound

In this section we derive a condition that bounds the drawdown risk. Consider any λ > 0
and bet b. For any α ∈ (0, 1) and β ∈ (0, 1) that satisﬁes λ = log β/ log α we have

E(rT b)−λ ≤ 1 =⇒ Prob(W min < α) < β.

(6)
In other words, if our bet satisﬁes E(rT b)−λ ≤ 1, then its drawdown risk Prob(W min < α)
less than β.

To see this, consider the stopping time

τ = inf{t ≥ 1| wt < α},

and note τ < ∞ if and only if W min < α. From Lemma 5 of the appendix, we get

1 ≥ E(cid:2)exp(−λ log wτ − τ log E(rT b)−λ) | τ < ∞(cid:3) Prob(W min < α).

Since −τ log E(rT b)−λ ≥ 0 when τ < ∞, we have

1 ≥ E [exp(−λ log wτ ) | τ < ∞] Prob(W min < α).

Since wτ < α when τ < ∞, we have

1 > exp(−λ log α)Prob(W min < α).

So we have

Prob(W min < α) < αλ = β.

5 Risk-constrained Kelly gambling

Replacing the drawdown risk constraint in the problem (5) with the lefthand side of (6),
with λ = log β/ log α, yields the risk-constrained Kelly gambling problem (RCK)

maximize E log(rT b),
subject to 1T b = 1,

b ≥ 0,

E(rT b)−λ ≤ 1,

7

(7)

with variable b. We refer to a solution of this problem as an RCK bet. The RCK problem
is a restriction of problem (5), since it has a smaller feasible set: any b that is feasible for
RCK must satisfy the drawdown risk constraint Prob(W min < α) < β. In the limit when
either β → 1 or α → 0 we get λ → 0. For λ = 0, the second constraint is always satisﬁed,
and the RCK problem (7) reduces to the (unconstrained) Kelly gambling problem (1).
Let us now show that the RCK problem (7) is convex. The objective is concave and the
constraints 1T b = 1, b ≥ 0 are convex. To see that the function E(rT b)−λ is convex in b,
we note that for rT b > 0, (rT b)−λ is a convex function of b; so the expectation E(rT b)−λ is
a convex function of b (see [BV04, §3.2]). We mention that the last constraint can also be
written as log E(rT b)−λ ≤ 0, where the lefthand side is a convex function of b.
The RCK problem (7) is always feasible, since b = en is feasible. Just as in the Kelly
gambling problem, the bet vector b = en is optimal for RCK (7) if and only if Eri ≤ 1
for i = 1, . . . , n − 1. In other words we should not bet at all if all the bets are losers in
expectation; conversely, if just one bet is a winner in expectation, the solution of the RCK
problem will have positive growth rate (and of course respect the drawdown risk constraint).
We show this in the appendix.

5.1 Risk aversion parameter

The RCK problem (7) depends on the parameters α and β only through λ = log β/ log α.
This means that, for ﬁxed λ, our one constraint E(rT b)−λ ≤ 1 actually gives us a family of
drawdown constraints that must be satisﬁed:

Prob(W min < α) < αλ

(8)
holds for all α ∈ (0, 1). For example α = 0.7 and β = 0.1 gives λ = 6.46; thus, our constraint
also implies that the probability of a drop in wealth to α = 0.5 (i.e., we lose half our initial
wealth) is no more than (0.5)6.46 = 0.011. Another interpretation of (8) is that our risk
constraint actually bounds the entire CDF (cumulative distribution function) of W min:
it
stays below the function α (cid:55)→ αλ.

The RCK problem (7) can be used in two (related) ways. First, we can start from
the original drawdown speciﬁcations, given by α and β, and then solve the problem using
λ = log β/ log α. In this case we are guaranteed that the resulting bet satisﬁes our drawdown
constraint. An alternate use model is to consider λ as a risk-aversion parameter ; we vary it
to trade oﬀ growth rate and drawdown risk. This is very similar to traditional Markowitz
portofolio optimization [Mar52] [BV04, §4.4.1], where a risk aversion parameter is used to
trade oﬀ risk (measured by portfolio return variance) and return (expected portfolio return).
We will see another close connection between our method and Markowitz mean-variance
portfolio optimization in §6.

5.2 Light and heavy risk aversion regimes

In this section we give provide an interpretation of the drawdown risk constraint

E(rT b)−λ ≤ 1

(9)

8

in the light and heavy risk aversion regimes, which correspond to small and large values of
λ, respectively.

In the heavy risk aversion regime, i.e., in the limit λ → ∞, the
Heavy risk aversion.
constraint (9) reduces to rT b ≥ 1 almost surely. In other words, problem (7) only considers
risk-free bets in this regime.

Light risk aversion. Next consider the light risk aversion regime, i.e., in the limit λ → 0.
Note that constraint (9) is equivalent to

log E exp(−λ log(rT b)) ≤ 0.

1
λ

As λ → 0 we have

log E exp(−λ log(rT b)) =

1
λ

1
λ

log E

(cid:20)

1 − λ log(rT b) +

(cid:21)

λ2
2

(log(rT b))2 + O(λ3)

= −E log(rT b) +
= −E log(rT b) +

λ
2
λ
2

E(log(rT b))2 − λ
2

(E log(rT b))2 + O(λ2)

var log(rT b) + O(λ2).

(In the context of stochastic control, (1/λ) log EX exp(−λX) is known as the exponential
disutility or loss and λ as the risk-sensitivity parameter. This asymptotic expansion is well-
known see e.g. [Whi81, Whi90].) So constraint (9) reduces to

var log(rT b) ≤ E log(rT b)

λ
2

in the limit λ → 0. Thus the (restricted) drawdown risk contraint (9) limits the ratio of
variance to mean growth in this regime.

5.3 Computing RCK bets

Two outcomes. For the two outcome case we can easily solve the problem (7), almost
analytically. The problem is

maximize π log(b1P + (1 − b1)) + (1 − π)(1 − b1),
subject to 0 ≤ b1 ≤ 1,

π(b1P + (1 − b1))− log β/ log α + (1 − π)(1 − b1)− log β/ log α ≤ 1.

(10)

If the solution of the unconstrained problem,

(cid:18) πP − 1

P − 1

(cid:19)

,

P − πP
P − 1

,

9

satisﬁes the risk constraint, then it is the solution. Otherwise we reduce b1 to ﬁnd the value
for which

π(b1P + (1 − b1))−λ + (1 − π)(1 − b1)− log λ = 1.

(This can be done by bisection since the lefthand side is monotone in b1.) In this case the
RCK bet is a fractional Kelly bet (4), for some f < 1.

Finite outcomes case. For the ﬁnite outcomes case we can restate the RCK problem (7)
in a convenient and tractable form. We ﬁrst take the log of the last constraint and get

we then write it as

(cid:32) K(cid:88)

i=1

log

K(cid:88)

i=1

log

πi(rT

i b)−λ ≤ 0,

(cid:33)

exp(log πi − λ log(rT

i b))

≤ 0.

To see that this constraint is convex we note that the log-sum-exp function is convex and
increasing, and its arguments are all convex functions of b (since log(rT
i b) is concave), so the
lefthand side function is convex in b [BV04, §3.2]. Moreover, convex optimization software
systems like CVX, CVXPY, and Convex.jl based on DCP (disciplined convex programming)
can handle such compositions directly. Thus we have the problem

maximize (cid:80)K
(cid:16)(cid:80)K

subject to 1T b = 1,

log

i=1 πi log(rT

i b),
b ≥ 0,

i=1 exp(log πi − λ log(rT

i b))

(cid:17) ≤ 0.

(11)

In this form the problem is readily solved; its CVXPY speciﬁcation is given in appendix B.

General returns. As with the Kelly gambling problem, we can solve the RCK problem (7)
using a stochastic optimization method. We use a primal-dual stochastic gradient method
(from [NY78, NJLS09]) applied to the Lagrangian

L(b, κ) = −E log(rT b) + κ(E(rT b)−λ − 1),

(12)
with b ∈ ∆ε and κ ≥ 0. (As in the unconstrained Kelly optimization case, we make the
technical assumption that b(cid:63)
n > ε > 0.) In the appendix we show that the RCK problem (7)
has an optimal dual variable κ(cid:63) for the constraint E(rT b)−λ ≤ 1, which implies that solving
problem (7) is equivalent to ﬁnding a saddle point of (12). We also assume we know an
upper bound M on the value of the optimal dual variable κ(cid:63).

Our method computes the iterates

(cid:32)
(cid:32)

¯b(k+1) =Π

¯b(k) + tk

¯κ(k+1) =

¯κ(k) + tk

(cid:33)

r(k)

,

(r(k)T ¯b(k))λ + λ¯κ(k)

(r(k)T ¯b(k))λ+1

(cid:33)

1 − (r(k)T ¯b(k))λ
(r(k)T ¯b(k))λ

10

,

[0,M ]

where the starting points ¯b(1) and ¯κ(1) are respectively in ∆ε and [0, M ], r(k) are IID samples
from the distribution of r, Π is Euclidean projection onto ∆ε, and (a)[0,M ] is projection onto
[0, M ], i.e.,

(a)[0,M ] = max{0, min{M, a}}.

The step sizes tk > 0 must satisfy

tk → 0,

∞(cid:88)

k=1

tk = ∞.

We use the (weighted) running averages

b(k) =

,

κ(k) =

(cid:80)k
(cid:80)k

i=1 ti

¯b(i)
i=1 ti

(cid:80)k
(cid:80)k

i=1 ti¯κ(i)

i=1 ti

as our estimates of the optimal bet and κ(cid:63), respectively.
Again, this method can be slow to converge, but it always works; that is E log(rT b(k))
converges to the optimal value and max{E(rT b(k)))−λ − 1, 0} → 0. As in the unconstrained
Kelly case, we do not know a priori how small ε should be, or how large M should be. We
can choose a small ε and large M and later verify that (¯b(k))n > ε, and ¯κ(k) < M ; if this
holds, our guesses of ε and M were valid. Also as in the unconstrained case, batching can be
used to improve the practical convergence. In this case, we replace our unbiased estimates
of the gradients of the two expectations with an average over some number of them.

Finally, we mention that the optimality conditions can be independently checked. As we
show in Lemma 4 of the appendix, a pair (b(cid:63), κ(cid:63)) is a solution of the RCK problem if and
only if it satisﬁes the following optimality conditions:

1T b(cid:63) = 1,
κ(cid:63) ≥ 0,

E

ri
rT b(cid:63) + κ(cid:63)λE

b(cid:63) ≥ 0, E(rT b(cid:63))−λ ≤ 1

κ(cid:63)(E(rT b(cid:63))−λ − 1) = 0

(cid:26) ≤ 1 + κ(cid:63)λ bi = 0

ri

(rT b(cid:63))λ+1

= 1 + κ(cid:63)λ bi > 0.

(13)

These conditions can be checked for a computed approximate solution of RCK, using Monte
Carlo simulation to evaluate the expectations. (The method above guarantees that 1T b = 1,
b ≥ 0, and κ ≥ 0, so we only need to check the other three conditions.)

6 Quadratic approximation

In this section we form a quadratic approximation of the RCK problem (7), which we call
the quadratic RCK problem (QRCK), and derive a close connection to Markowitz portfolio
optimization. We use the notation ρ = r − 1 for the (random) excess return, so (with

11

1T b = 1) we have rT b − 1 = ρT b. Assuming rT b ≈ 1, or equivalently ρT b ≈ 0, we have the
(Taylor) approximations

log(rT b) = ρT b − 1
2
(rT b)−λ = 1 − λρT b +

(ρT b)2 + O((ρT b)3),

λ(λ + 1)

2

(ρT b)2 + O((ρT b)3).

Substituting these into the RCK problem (7) we obtain the QRCK problem

maximize EρT b − 1
subject to 1T b = 1,

2E(ρT b)2
b ≥ 0
−λEρT b + λ(λ+1)

2 E(ρT b)2 ≤ 0.

(14)

This approximation of the RCK problem is a convex quadratic program (QP) which is readily
solved. We expect the solution to be a good approximation of the RCK solution when the
basic assumption rT b ≈ 1 holds.

This approximation can be useful when ﬁnding a solution to the RCK problem (7). We
ﬁrst estimate the ﬁrst and second moments of ρ via Monte Carlo, and then solve the QRCK
problem (14) (with the estimated moments) to get a solution bqp and a Langrange multipler
κqp. We take these as good approximations for the solution of (7), and use them as the
starting points for the primal-dual stochastic gradient method, i.e., we set b(1) = bqp and
κ(1) = κqp. This gives no theoretical advantage, since the method converges no matter what
the initial points are; but it can speed up the convergence in practice.

We now connect the QRCK problem (14) to classical Markowitz portfolio selection. We

start by deﬁning µ = Eρ, the mean excess return, and

S = EρρT = Σ + (Eρ)(Eρ)T ,

the (raw) second moment of ρ (with Σ the covariance of the return). We say that an
allocation vector b is a Markowitz portfolio if it solves

maximize µT b − γ
subject to 1T b = 1,

2 bT Σb

(15)
for some value of the (risk-aversion) parameter γ ≥ 0. A solution to problem (14) is a
Markowitz portfolio, provided there are no arbitrages. By no arbitrage we mean that µT b > 0,
1T b = 1, and b ≥ 0, implies bT Σb > 0.

b ≥ 0,

Let us show this. Let bqp be the solution to the QRCK problem (14). By (strong)

Lagrange duality [Ber09], bqp is a solution of
maximize µT b − 1
subject to 1T b = 1,

2bT Sb + ν(µT b − λ+1

2 bT Sb)

b ≥ 0

2 E(ρT b)2 ≤ 0.
for some ν ≥ 0, which we get by dualizing only the constraint −λEρT b + λ(λ+1)
We divide the objective by 1 + ν and substitute S = µµT + Σ to get that bqp is a solution of

maximize µT b − η
subject to 1T b = 1,

2 (µT b)2 − η
b ≥ 0,

2 bT Σb

(16)

12

for some η > 0. In turn, bqp is a solution of

maximize
subject to 1T b = 1,

b ≥ 0,

(1 − ηµT bqp)µT b − η

2 bT Σb

(17)

since the objectives of problem (16) and (17) have the same gradient at bqp. If µT bqp < 1/η
then problem (17) is equivalent to problem (15) with γ = η/(1 − ηµT bqp).
Assume for contradiction that µT bqp ≥ 1/η, which implies (bqp)T Σbqp > 0 by the no
artibtrage assumption. Then for problem (17) the bet en achieves objective value 0, which
is better than that of bqp. As this contradicts the optimality of bqp, we have µT bqp < 1/η. So
we conclude a solution to problem (14) is a solution to problem (15), i.e., bqp is a Markowitz
portfolio.

7 Numerical simulations

In this section we report results for two speciﬁc problem instances, one with ﬁnite outcomes
and one with inﬁnite outcomes, but our numerical explorations show that these results are
typical.

7.1 Finite outcomes

1, . . . , K are drawn uniformly on [0, 1] and then normalized so that(cid:80)

We consider a ﬁnite outcomes case with n = 20 (so there are 19 risky bets) and K = 100
possible outcomes. The problem data is generated as follows. The probabilities πi, i =
i πi = 1. The returns
rij ∈ R++ for i = 1, . . . , K and j = 1, . . . , n − 1 are drawn from a uniform distribution in
[0.7, 1.3]. Then, 30 randomly selected returns rij are set equal to 0.2 and other 30 equal to 2.
(The returns rin for i = 1, . . . , K are instead all set to 1.) The probability that a return vector
r contains at least one “extreme” return (i.e., equal to 0.2 or 2) is 1− (1− 60/(19· 100))n−1 ≈
0.45.

7.1.1 Comparison of Kelly and RCK bets

We compare the Kelly optimal bet with the RCK bets for α = 0.7 and β = 0.1 (λ = 6.456).
We then obtain the RCK bets for λ = 5.500, a value chosen so that we achieve risk close to
the speciﬁed value β = 0.1 (as discussed in §5.1). For each bet vector we carry out 10000
Monte Carlo simulations of wt for t = 1, . . . , 100. This allows us to estimate (well) the
associated risk probabilities. Table 1 shows the results. The second column gives the growth
rate, the third column gives the bound on drawdown risk, and the last column gives the
drawdown risk computed by Monte Carlo simulation.

The Kelly optimal bet experiences a drawdown exceeding our threshold α = 0.7 around
40% of the time. For all the RCK bets the drawdown risk (computed by Monte Carlo) is
less than our bound, but not dramatically so. (We have observed this over a wide range of
problems.) The RCK bet with λ = 6.456 is guaranteed to have a drawdown probability not

13

Bet
Kelly
RCK, λ = 6.456
RCK, λ = 5.500

E log(rT b)

eλ log α Prob(W min < α)

0.062
0.043
0.047

-

0.100
0.141

0.397
0.073
0.099

Table 1: Comparison of Kelly and RCK bets. Expected growth rate and drawdown
risk are computed with Monte Carlo simulations.

exceeding 10%; Monte Carlo simulation shows that it is (approximately) 7.3%. For the third
bet vector in our comparison, we decreased the risk aversion parameter until we obtained a
bet with (Monte Carlo computed) risk near the limit 10%.

The optimal value of the (hard) Kelly gambling problem with drawdown risk (9) must be
less than 0.062 (the unconstrained optimal growth rate) and greater than 0.043 (since our
second bet vector is guaranteed to satisfy the risk constraint). Since our third bet vector
has drawdown risk less than 10%, we can further reﬁne this result to state that the optimal
value of the (hard) Kelly gambling problem with drawdown risk (9) is between 0.062 and
0.047.

Figure 1 shows ten trajectories of wt in our Monte Carlo simulations for the Kelly optimal
bet (left) and the RCK bet obtained with λ = 5.5 (right). Out of these ten simulations, four
of the Kelly trajectories dip below the threshold α = 0.7, and one of the other trajectories
does, which is consistent with the probabilities reported above.

Figure 2 shows the sample CDF of W min over the 10000 simulated trajectories of wt, for
the Kelly optimal bets and the RCK bets with λ = 6.46. The upper bound αλ is also shown.
We see that the risk bound is not bad, typically around 30% or so higher than the actual
risk. We have observed this to be the case across many problem instances.

7.1.2 Comparison of RCK and QRCK

Table 2 shows the Monte Carlo values of growth rate and drawdown risk for the QRCK bets
with λ = 6.456 (to compare with the RCK solution in table 1). The QRCK bets come with
no guarantee on the drawdown risk, but with λ = 6.456 the drawdown probability (evaluated
by Monte Carlo) is less than β = 0.1. The value λ = 2.800 is selected so that the risk is
approximately 0.10; we see that its growth rate is smaller than the growth rate of the RCK
bet with the same drawdown risk.

Figure 3 shows the values of each bi with i = 1, . . . , 20, for the Kelly, RCK, and QRCK
bets. We can see that the Kelly bet concentrates on outcome 4; the RCK and QRCK bets
still make a large bet on outcome 4, but also spread their bets across other outcomes as well.

7.1.3 Risk-growth trade-oﬀ of RCK, QRCK, and fractional Kelly bets

In ﬁgure 4 we compare the trade-oﬀ between drawdown risk and expected growth rate of
the RCK and QRCK problems for multiple choices of λ and the fractional Kelly bets (4) for

14

Figure 1: Wealth trajectories for the Kelly optimal bet (left) and the restricted
risk-constrained bet with λ = 5.5. The dashed line shows the wealth threshold
α = 0.7.

Bet
QRCK, λ = 0.000
QRCK, λ = 6.456
QRCK, λ = 2.800

E log(rT b)

0.054
0.027
0.044

eλ log α Prob(W min < α)
1.000
0.100
0.368

0.218
0.025
0.100

Table 2: Statistics for QRCK bets. Expected growth rate and drawdown risk are
computed with Monte Carlo simulations.

15

Figure 2: Sample CDF of W min (i.e., Prob(W min < α)) for the Kelly optimal bets
and RCK bets with λ = 6.46. The upper bound αλ is also shown.

Figure 3: Comparison of the values bi, i = 1, . . . , 20, for diﬀerent bet vectors. The
RCK and QRCK bets are both obtained with λ = 6.456.

16

Figure 4: Trade-oﬀ of drawdown risk and expected growth rate for the RCK,
QRCK, and fractional Kelly bets. The Kelly bet is also shown.

multiple choices of f . The plots are akin to the risk-return tradeoﬀ curves that are typical
in Markowitz portfolio optimization. We see that RCK yields superior bets than QRCK and
fractional Kelly (in some cases substantially better). For example, the Kelly fractional bet
that achieves our risk bound 0.1 has a growth rate around 0.035, compared with RCK, which
has a growth rate 0.047.

7.2 General returns

We show here an instance of the problem with an inﬁnite distribution of returns, deﬁned as
a mixture of lognormals

(cid:40)

r ∼

log N (ν1, Σ1) w.p. 0.5
log N (ν2, Σ2) w.p. 0.5,

with n = 20, ν1, ν2 ∈ Rn, and Σ1, Σ2 ∈ Sn
are such that rn has value 1 with probability 1.

+. We have ν1n = ν2n = 0, and the matrices Σ1, Σ2

We generate a sample of 106 observations from this returns distribution and use it to
√
solve the Kelly, RCK, and QRCK problems. In the algorithms for solving Kelly and RCK
k for some C > 0 and batching over 100 samples per iteration
we use step sizes tk = C/
(so that we run 104 iterations). We initialize these algorithms with the QRCK solutions
to speed up convergence. To solve the QRCK problem we compute the ﬁrst and second
moments of ρ = r − 1 using the same sample of 106 observations. We generate a separate

17

Bet
Kelly
RCK, λ = 6.456
RCK, λ = 5.700

E log(rT b)

eλ log α Prob(W min < α)

0.077
0.039
0.043

-

0.100
0.131

0.569
0.080
0.101

Table 3: Comparison of Kelly and RCK for the inﬁnite outcome case. Expected
growth rate and drawdown risk are computed with Monte Carlo simulations.

sample of returns for Monte Carlo simulations, consisting of 104 simulated trajectories of wt
for t = 1, . . . , 100.

7.2.1 Comparison of RCK and Kelly bets

In our ﬁrst test we compare the Kelly bet with RCK bets for two values of the parameter
λ. The ﬁrst RCK bet has λ = 6.456, which guarantees that the drawdown risk at α = 0.7 is
smaller or equal than β = 0.1. Table 3 shows that this is indeed the case, the Monte Carlo
simulated risk is 0.08, not very far from the theoretical bound. The second value of λ is
instead chosen so that the Monte Carlo risk is approximately equal to 0.1.

Figure 5 shows 10 simulated trajectories wt for the Kelly bet and for the RCK bet with
λ = 5.700. In this case 6 of the Kelly trajectories fall below α = 0.7 and one of the RCK
trajectories does, consistently with the values obtained above. Figure 6 shows the sample
CDF of W min for the Kelly bet and the RCK bet with λ = 6.456, and the theoretical bound
given by αλ.

7.2.2 Risk-growth trade-oﬀ of RCK, QRCK, and fractional Kelly bets

We compare the Monte Carlo simulated drawdown risk (α = 0.7) and expected growth rate
of the Kelly, RCK, QRCK, and fractional Kelly bets. We select multiple values of λ (for RCK
and QRCK) and f (for fractional Kelly) and plot them together in ﬁgure 7. We observe,
as we did in the ﬁnite outcome case, that RCK yields superior bets than QRCK. This is
particularly signiﬁcant since QRCK is closely connected to the classic Markowitz portfolio
optimization model, and this example resembles a ﬁnancial portfolio selection problem (a
bet with inﬁnite return distributions). The fractional Kelly bets, in this case, show instead
the (essentially) same performance as RCK.

18

Figure 5: Wealth trajectories for the Kelly optimal bet (left) and the RCK bet
with λ = 5.700, for the inﬁnite returns distribution. The wealth threshold α = 0.7
is also shown.

19

Figure 6: Sample CDF of W min for the Kelly optimal bet and RCK bet with
λ = 6.46, for the inﬁnite returns distribution. The bound αλ is also shown.

20

Figure 7: Trade-oﬀ of drawdown risk and expected growth rate for the RCK,
QRCK, and fractional Kelly bets, with the inﬁnite return distribution. The Kelly
bet is also shown.

21

A Miscellaneous lemmas

Here we collect the technical details and derivations of several results from the text.
Lemma 1. The bet en is optimal for problem (1) if and only if Eri ≤ 1 for i = 1, . . . , n− 1.
Likewise, the bet en is optimal for problem (7) if and only if Eri ≤ 1 for i = 1, . . . , n − 1.
Proof. Assume Eri ≤ 1 for i = 1, . . . , n − 1. Then by Jensen’s inequality,

E log(rT b) ≤ log ErT b ≤ 0

for any b ∈ {b | 1T b = 1, b ≥ 0}. So en, which achieves objective value 0, is optimal for both
problem (1) and problem (7).

Next assume Eri > 1 for some i. Consider the bet b = f ei + (1 − f )en and

for f ∈ [0, 1). By [Ber73, Proposition 2.1] we have the right-sided derivative

φ(f ) = E log(rT b)

∂+φ(f ) = E

r(ei − en)

rT b

,

and we have

∂+φ(0) = Er(ei − en) = Eri − 1 > 0.

Since φ(0) = 0, we have φ(f ) > 0 for a small enough f . So b = f ei + (1 − f )en has better
objective value than en for small enough f , i.e., en is not optimal for problem (1).
Again, assume Eri > 1 for some i. Write b(cid:63) for the Kelly optimal bet. (We have already
established that b(cid:63) (cid:54)= en and that E log(rT b(cid:63)) > 0.) Consider the bet ˜b = f b(cid:63) + (1 − f )en
and

ψ(f ) = E(rT ˜b)−λ
for f ∈ [0, 1). By a similar argument as before, we have

and

∂+ψ(f ) = −λE(rT ˜b)−λ−1rT (b(cid:63) − en),

∂+ψ(0) = −λ(cid:0)E(rT b(cid:63)) − 1(cid:1) .

By Jensen’s inequality we have

0 ≤ E log(rT b(cid:63)) ≤ log ErT b(cid:63).

So ∂+ψ(0) < 0. Since ψ(0) = 1, we have ψ(f ) < 1 for small enough f . So ˜b = f b(cid:63) + (1− f )en
is feasible for small enough f . Furthermore, ˜b has strictly better objective value than en for
f ∈ (0, 1) since the objective is concave. So en is not optimal.

Lemma 2. Problem (7) always has an optimal dual variable.

22

Proof. Assume en is optimal. By Lemma 1, en is optimal even without the constraint
E(rT b)−λ ≤ 1. So κ(cid:63) = 0 is an optimal dual variable.
Now assume en is not optimal. By the reasoning with the function ψ of Lemma 1’s proof,
there is a point strictly feasible with respect to the constraint E(rT b)−λ ≤ 1. So by [Roc74,
Theorem 17], we conclude a dual solution exists.
Lemma 3. Let ε ∈ [0, 1], and write Π(·) for the projection onto ∆ε. Deﬁne the function
(·)+,ε : Rn → Rn as ((x)+,ε)i = max{xi, 0} for i = 1, . . . , n − 1 and ((x)+,ε)n = max{xn, ε}.
Then

Π(z) = (z − ν1)+,ε,

where ν is a solution of the equation

1T (z − ν1)+,ε = 1.

The left-hand side is a nonincreasing function of ν, so ν can be obtained eﬃciently via
bisection on with the starting interval [maxi zi − 1, maxi zi].
Proof. By deﬁnition of the projection, x = Π(z) is the solution of

1

2(cid:107)x − z(cid:107)2
minimize
subject to 1T x = 1
x ≥ 0,

2

xn ≥ ε.

This problem is equivalent to

minimize
subject to x ≥ 0,

1

2(cid:107)x − z(cid:107)2

2 + ν(1T x − 1)
xn ≥ ε

for an optimal dual variable ν ∈ R. This follows from dualizing with respect to the constraint
1T x = 1 (and not the others), applying strong Lagrange duality, and using fact that the
objective is strictly convex [Ber09]. This problem is in turn equivalent to

minimize
subject to x ≥ 0,

2(cid:107)x − (z − ν1)(cid:107)2
xn ≥ ε,

2

1

which has the analytic solution

x(cid:63) = (z − ν1)+,ε.

An optimal dual variable ν must satisfy

1T (z − ν1)+,ε = 1,

by the KKT conditions. Write h(ν) = (z − ν1)+,ε. Then h(ν) a continuous nonincreasing
function with

zi) = ε.
So a solution of h(ν) = 1 is in the interval [maxi zi − 1, maxi zi].

h(max

h(max

i

i

zi − 1) ≥ 1,

23

Lemma 4. A pair (b(cid:63), κ(cid:63)) is a solution of the RCK problem if and only if it satisﬁes condi-
tions (13).

Proof. Assume (b(cid:63), κ(cid:63)) is a solution of the RCK problem. This immediately gives us 1T b(cid:63) = 1,
b(cid:63) ≥ 0, E(rT b(cid:63))−λ ≤ 1, and κ(cid:63) ≥ 0. Moreover b(cid:63) is a solution to
minimize −E log(rT b) + κ(cid:63)E(rT b)−λ
subject to 1T b = 1,
and κ(cid:63)(E(rT b(cid:63))−λ − 1) = 0, by Lagrange duality.
Consider bε = (1 − ε)b(cid:63) + εb, where b ∈ Rn satisﬁes 1T b = 1 and b ≥ 0. Deﬁne
ϕ(ε) = −E log(rT bε) + κ(cid:63)E(rT bε)−λ. Since bε is feasible for problem (18) for ε ∈ [0, 1) and
since b(cid:63) is optimal, we have ϕ(0) ≤ ϕ(ε) for ε ∈ [0, 1). We later show ϕ(ε) < ∞ for ε ∈ [0, 1).
So ∂+ϕ(0) ≥ 0, where ∂+ denotes the right-sided derivative.

b ≥ 0

(18)

By [Ber73, Proposition 2.1] we have
∂+ϕ(ε) = −E

rT (b − b(cid:63))

rT bε

− κ(cid:63)λE

rT (b − b(cid:63))
(rT bε)λ+1 .

So we have

0 ≤ ∂+ϕ(0) = 1 + κ(cid:63)λE(rT b(cid:63))−λ − E
Using κ(cid:63)(E(rT b(cid:63))−λ − 1) = 0, and reorganizing we get

(cid:18)

E

r
rT b(cid:63) + κ(cid:63)λE

r

(rT b(cid:63))λ+1

rT b

(rT b(cid:63))λ+1 .

rT b

rT b(cid:63) − κ(cid:63)λE
(cid:19)T

b ≤ 1 + κ(cid:63)λ,

(19)

(20)

for any b ∈ Rn that satisﬁes 1T b = 1 and b ≥ 0. With b = ei for i = 1, . . . , n, we get

E

ri
rT b(cid:63) + κ(cid:63)λE

ri

(rT b(cid:63))λ+1 ≤ 1 + κ(cid:63)λ,

Now assume b(cid:63)

for i = 1, . . . , n.
i > 0 for some i and let b = ei. Then bε is feasible for problem (18) for
small negative ε. We later show ϕ(ε) < ∞ for small negative ε. This means ∂+ϕ(0) = 0 in
this case, and we conclude

(cid:26) ≤ 1 + κ(cid:63)λ bi = 0

E

ri
rT b(cid:63) + κ(cid:63)λE

ri

(rT b(cid:63))λ+1

= 1 + κ(cid:63)λ bi > 0.

It remains to show that ϕ(ε) < ∞ for appropriate values of ε. First note that b(cid:63), a
solution, has ﬁnite objective value, i.e., −E log(rT b(cid:63)) < ∞ and E(rT b(cid:63))−λ < ∞. So for
ε ∈ [0, 1), we have

ϕ(ε) = −E log((1 − ε)rT b(cid:63) + εrT b) + κ(cid:63)E((1 − ε)rT b(cid:63) + εrT b)−λ

≤ −E log((1 − ε)rT b(cid:63)) + κ(cid:63)E((1 − ε)rT b(cid:63))−λ
= − log(1 − ε) − E log(rT b(cid:63)) + κ(cid:63)(1 − ε)−λE(rT b(cid:63))−λ < ∞.

24

Next assume bi > 0 for some i ∈ {1, . . . , n}. Then for ε ∈ (−bi, 0) we have

ϕ(ε) ≤ −E log(rT b(cid:63) + εri) + κ(cid:63)E(rT b(cid:63) + εri)−λ

≤ −E log(((bi + ε)/bi)rT b(cid:63)) + κ(cid:63)E(((bi + ε)/bi)rT b(cid:63))−λ
= − log((bi + ε)/bi) − E log(rT b(cid:63)) + κ(cid:63)((bi + ε)/bi)−λE(rT b(cid:63))−λ < ∞.

Finally, assume conditions (13) for (b(cid:63), κ(cid:63)), and let us go through the argument in reverse
order to show the converse. Conditions (13) implies condition (20), which in turn implies
condition (19) as 1T b = 1. Note b(cid:63) has ﬁnite objective value becuase E(rT b(cid:63))−λ < ∞
by assumption and −E log(rT b(cid:63)) ≤ (1/λ) log E(rT b(cid:63))−λ < ∞ by Jensen’s inequality. So
ϕ(0) ≤ ϕ(ε) for ε ∈ [0, 1) by the same argument as before, i.e., b(cid:63) is optimal for problem
(18). This fact, together with conditions (13), give us the KKT conditions of the RCK
problem, and we conclude (b(cid:63), κ(cid:63)) is a solution of the RCK problem by Lagrange duality
[Ber09].

Lemma 5. Consider an IID sequence X1, X2, . . . from probability measure µ, its random
walk Sn = X1 + X2 + ··· + Xn, a stopping time τ , and

(cid:90)

ψ(λ) = log E exp(−λX) = log

exp(−λx) dµ(x).

Then we have

E [exp(−λSτ − τ ψ(λ)) | τ < ∞] Prob(τ < ∞) ≤ 1.

This lemma is a modiﬁcation of an identity from [Wal44], [Fel71, §XVIII.2], and [Gal13,

§9.4].

Proof. Consider the tilted probability measure

dµλ(x) = exp(−λx − ψ(λ))dµ(x)

and write Probµλ for the probability under the tilted measure µλ. Then we have

Probµλ(τ = n) =

(cid:90)
(cid:90)
= E(cid:2)exp(−λSτ − τ ψ(λ))I{τ =n}(cid:3)
Probµλ(τ < ∞) = E(cid:2)exp(−λSτ − τ ψ(λ))I{τ <∞}(cid:3)

=

I{τ =n}dµλ(x1, x2, . . . , xn)
I{τ =n} exp(−λsn − nψ(λ))dµ(x1, x2, . . . , xn)

= E [exp(−λSτ − τ ψ(λ)) | τ < ∞] Prob(τ < ∞).

By summing through n = 1, 2, . . . we get

Since Probµλ(τ < ∞) ≤ 1, we have the desired result.

25

B DCP speciﬁcation

The ﬁnite outcome RCK problem (11) can be formulated and solved in CVXPY as

b = Variable(n)
lambda_risk = Parameter(sign = ’positive’)
growth = pi.T*log(r.T*b)
risk_constraint = (log_sum_exp (log(pi) - lambda_risk * log(r.T*b)) <= 0)
constraints = [ sum_entries(b) == 1, b >= 0, risk_constraint ]
risk_constr_kelly = Problem(Maximize(growth),constraints)
risk_constr_kelly.solve()

Here r is the matrix whose columns are the return vectors, and pi is the vector of probabil-
ities. The second to last line forms the problem (object), and in the last line the problem is
solved. The optimal bet is written into b.value. We note that if we set lambda_risk equal
to 0 this problem formulation is equivalent (computationally) to the Kelly problem.

Acknowledgments

We thank Andrea Montanari, B. Ross Barmish, and Minggao Gu for useful discussions.

References

[Ber73]

D. P. Bertsekas. Stochastic optimization problems with nondiﬀerentiable cost
functionals. Journal of Optimization Theory and Applications, 12(2):218–231,
1973.

[Ber09]

D. P. Bertsekas. Convex Optimization Theory. Athena Scientiﬁc, 2009.

[Bro00]

S. Browne. Risk-constrained dynamic active portfolio management. Management
Science, 46(9):1188–1199, 2000.

[Bub15]

S. Bubeck. Convex optimization: Algorithms and complexity. Foundations and
Trends in Machine Learning, 8(3–4):231–357, 2015.

[BV04]

[CT12]

[DB16]

S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University
Press, 2004.

T. Cover and J. Thomas. Elements of Information Theory. John Wiley & Sons,
2012.

S. Diamond and S. Boyd. CVXPY: A Python-embedded modeling language for
convex optimization. Journal of Machine Learning Research, 2016.

[DCB13] A. Domahidi, E. Chu, and S. Boyd. ECOS: An SOCP solver for embedded

systems. In European Control Conference (ECC), pages 3071–3076, 2013.

26

[DL12]

[Fel71]

[Gal13]

[GB14]

M. Davis and S. Lleo. Fractional Kelly strategies in continuous time: Recent de-
velopments.
In L. C. MacLean and W. T. Ziemba, editors, Handbook of the
Fundamentals of Financial Decision Making, pages 753–788. World Scientiﬁc
Publishing, 2012.

W. Feller. An Introduction to Probability Theory and Its Applications, volume 2.
Wiley, 2nd edition, 1971.

R. G. Gallager. Stochastic Processes: Theory for Applications. Cambridge Uni-
versity Press, 2013.

M. Grant and S. Boyd. CVX: Matlab software for disciplined convex program-
ming, version 2.1. http://cvxr.com/cvx, March 2014.

[GBY06] M. Grant, S. Boyd, and Y. Ye. Disciplined convex programming. In L. Liberti
and N. Maculan, editors, Global Optimization: From Theory to Implementation,
Nonconvex Optimization and its Applications, pages 155–210. Springer, 2006.

[Kel56]

[KY03]

[L¨04]

J. Kelly, Jr. A new interpretation of information rate.
Information Theory, 2(3):185–189, 1956.

IRE Transactions on

H. J. Kushner and G. G. Yin. Stochastic Approximation and Recursive Algorithms
and Applications. Springer, 2003.

J. L¨ofberg. YALMIP: A toolbox for modeling and optimization in MATLAB. In
Proceedings of the IEEE International Symposium on Computer Aided Control
Systems Design, pages 284–289, 2004.

[Mar52]

H. Markowitz. Portfolio selection. The Journal of Finance, 7(1):77–91, 1952.

[Mer90]

R. C. Merton. Continuous-Time Finance. Wiley-Blackwell, 1990.

[MTZ11] L. C. MacLean, E. O. Thorp, and W. T. Ziemba. The Kelly Capital Growth In-
vestment Criterion: Theory and Practice, volume 3. World Scientiﬁc Publishing,
2011.

[NJLS09] A. S. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approx-
imation approach to stochastic programming. SIAM Journal on Optimization,
19(4):1574–1609, 2009.

[NY78]

A. S. Nemirovski and D. B. Yudin. On Cesari’s convergence of the steepest
descent method for approximating saddle points of convex-concave functions.
Doklady Akademii Nauk SSSR, 239:1056–1059, 1978.

[NY83]

A. S. Nemirovski and D. B. Yudin. Problem Complexity and Method Eﬃciency
in Optimization. Wiley, 1983.

27

[Pol87]

[RM51]

[Roc74]

[Ser15]

B. T. Polyak. Introduction to Optimization. Optimization Software, New York,
1987.

H. Robbins and S. Monro. A stochastic approximation method. The Annals of
Mathematical Statistics, 22(3):400–407, 1951.

R. T. Rockafellar. Conjugate Duality and Optimization. Society for Industrial
and Applied Mathematics, Philadelphia, 1974.

S. A. Serrano. Algorithms for Unsymmetric Cone Optimization and an Implemen-
tation for Problems with the Exponential Cone. PhD thesis, Stanford University,
2015.

[UMZ+14] M. Udell, K. Mohan, D. Zeng, J. Hong, S. Diamond, and S. Boyd. Convex op-
timization in Julia. SC14 Workshop on High Performance Technical Computing
in Dynamic Languages, 2014.

[Wal44]

A. Wald. On cumulative sums of random variables. The Annals of Mathematical
Statistics, 15(3):283–296, 1944.

[Whi81]

P. Whittle. Risk-sensitive linear/quadratic/Gaussian control. Advances in Ap-
plied Probability, 13(4):764–777, 1981.

[Whi90]

P. Whittle. Risk-sensitive Optimal Control. Wiley, 1990.

28

