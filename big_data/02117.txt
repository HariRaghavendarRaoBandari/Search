6
1
0
2

 
r
a

M
7

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
7
1
1
2
0

.

3
0
6
1
:
v
i
X
r
a

One dimensional random walk killed on a ﬁnite set

Kˆohei UCHIYAMA

Department of Mathematics, Tokyo Institute of Technology

Oh-okayama, Meguro Tokyo 152-8551
e-mail: uchiyama@math.titech.ac.jp

running head: random walk killed on a ﬁnite set

key words: exterior domain; transition probability; escape from a ﬁnite set; hitting
probability of a ﬁnite set; potential theory

AMS Subject classiﬁcation (2010): Primary 60G50, Secondary 60J45.

Abstract

We study the transition probability, say pn

A(x, y), of a one-dimensional random
walk on the integer lattice killed when entering into a non-empty ﬁnite set A. The
random walk is assumed to be irreducible and have zero mean and a ﬁnite variance
σ2. We derive the asymptotic form of pn
A(x, y) for large n valid uniformly in the
regime characterized by the conditions |x| ∨ |y| = O(√n) and |x| ∧ |y| = o(√n), in
A (y)+g−A (x)bg −A (y)](σ2/2n)pn(y−x).
which pA
Here pn(y − x) is the transition kernel of the random walk (without killing); g±A
are the Green functions for the ‘exterior’ of A with ‘pole at ±∞’ normalized so
that g±A (x) ∼ 2|x|/σ2 as x → ±∞; andbg ±A are the corresponding Green functions
for the time-reversed walk.

t (x, y) behaves for large n like [g+

A (x)bg +

1

Introduction and main results

This paper concerns the transition probability of a one-dimensional random walk on the
integer lattice Z killed on a ﬁnite set A. For random walks on the multidimensional
integer lattice killed on a ﬁnite set H. Kesten [3] obtained, among others, the asymptotic
form of the transition probability under a quite general setting. For the important case
of one dimensional random walk with zero mean and ﬁnite variance, however, his result
is restricted to the special case when A consists of a single point. In this paper we extend
his result to every ﬁnite set A. Our result is stronger than his in another respect: the
asymptotic estimate is valid uniformly for space variables within a reasonable range of
relevant variables.

Let Sn = S0 + X1 + · · · + Xn, n = 1, 2, . . . be a random walk on the one-dimensional
integer lattice Z. Here the increments Xj are i.i.d. Z-valued random variables and the
initial state S0 independent of Xj’s is any Z-valued random variable left unspeciﬁed
for now, all of them being deﬁned on some probability space (Ω,F , P ). As usual the
conditional law given S0 = x of the walk (Sn) is denoted by Px and the corresponding
expectation by Ex. Throughout this paper we suppose that the random walk Sn is
irreducible, namely for every x ∈ Z, P0[Sn = x] > 0 for some n > 0, and that

EX = 0

and

σ2 := EX 2 < ∞.
1

(1.1)

Here as well as in the sequel X is a random variable having the same law as X1 and E
the expectation w.r.t. P .

Let p(x) = P [X = x] and pn(x) = P0[Sn = x] so that for y ∈ Z,

Px[Sn = y] = pn(y − x)

and p0(x) = δx,0,

where δy,x equals unity if x = y and zero if x 6= y. For a non-empty ﬁnite subset A of
Z, let pn
A(x, y) denote the transition probability of the walk Sn killed upon entering A,
deﬁned by

Thus p0

pn
A(x, y) = Px[Sk /∈ A for k = 1, . . . , n and Sn = y], n = 0, 1, 2, . . . .
A(x, y) = 0 whenever y ∈ A, n ≥ 1.

A(x, y) = δx,y (even if y ∈ A); and pn

The result of Kesten [3] mentioned above entails that for each x and y, as n → ∞

(x, y)

pn
{0}
f0(n)

lim
n→∞

= [a(x) + δx,0]a(−y) +

xy
σ4 ,

(1.2)

provided that the walk is (temporally) aperiodic in addition. Here a(x) is the potential
function of the walk deﬁned by

a(x) = lim
n→∞

nXk=0

[pk(0) − pk(−x)]

and

We know that

f0(n) = P0[Sk 6= 0 for k = 1, . . . , n − 1 and Sn = 0].

f0(n) =

σ2
n

pn(0)(1 + o(1))

as n → ∞ (Cf. [6] for the existence of a(x) and [3, Theorem 8] for the asymptotic form
of f0(n) stated above.)

Denote the Green function of pn

A by gA(x, y):

gA(x, y) =

∞Xn=0

pn
A(x, y),

x, y ∈ Z.

(To be precise this is not conform to the usual nomenclature, according to which a
green function is set zero on A × A, while our gA(x, y) is equal to δx,y if y ∈ A and to
P−y[Sσ(−A) = −x] if y /∈ A (the hitting probability of A for the dual walk).) According
to Theorem 30.1 of [6] gA(x, y) has limits as y → +∞ and y → −∞ for each x. We call
them

g+
A (x) = lim
y→∞

gA(x, y) and g−A (x) = lim
y→−∞

gA(x, y).

(g±A(x) may be interpreted as the expected number of visits to x made by the dual—or
time-reversed—random walk ‘started at ±∞’ before the ﬁrst entrance into A.) We write
−A for {−z : z ∈ A}; s∧ t and s∨ t for the minimum and maximum, respectively, of real
numbers s and t. In the following theorem we impose on the pair of x, y the condition

g+
A(x)g−

−A(−y) + g−A (x)g+

−A(−y) 6= 0.

(1.3)

2

Theorem 1. Let A be a non-empty ﬁnite subset of Z. Then, for each M ≥ 1, uniformly
for x ∈ Z and y ∈ Z \ A subject to the conditions (1.3), −M ≤ x ≤ M√n and
−M ≤ y ≤ M√n, as n → ∞ and (|x| ∧ |y|)/√n → 0
−A(−y)

−A(−y) + g−A(x)g+

g+
A (x)g−

(1.4)

pn
A(x, y) =

pn(y − x)[1 + o(1)].

2n/σ2

If condition (1.3) is violated, then pn
C that depend only on p and A.

A(x, y) < Ce−λn for some positive constants λ and

In (1.4) as well as in what follows, o(1) → 0 in the speciﬁed limit procedure and the

convergence is uniform under the speciﬁed condition.

Remark 1. (a) If the object corresponding to the dual (time-reversed) walk is indicated

A (y, x), we have

by puttingb, like bp n
g−A(−y,−x) =bgA(y, x) = gA(x, y) and g−

(cf. Appendix A for related matters).

−A(−y) =bg +

A (y) = lim
x→∞

gA(x, y)

(1.5)

(b) Because of the latter relation of (1.5) g−

−A(−y)) is positive if and
only if y can be reached by the walk starting at +∞ (resp. −∞). Taking account of this
and its analogue for g±A we see that the product g+
−A(−y)) is
positive if (and only if) the walk starting at x reaches y after a large excursion to the
right (resp. left) with a positive probability. Hence, if both of these two products vanish,
namely if condition (1.3) is violated, then one of the following (i) or (ii) must hold true:

−A(−y) (resp. g+

−A(−y) (resp. g+

A (x)g−

A (x)g−

A(x, y) vanish for all n;

(i) pn
(ii) all the random walk paths that connect x and y and avoid A \ {x, y} are

conﬁned in the convex hull of A with probability one.
In the second case the paths must enter A in a small number of steps. This shows the
second assertion of Theorem 1.

(c) We shall show g±A(x) = a(x) ± σ−2x + O(1) (see (2.3), (2.4)), which implies

g+
A (x)/x −→ 2/σ2 or 0 as x → +∞ or − ∞;

and similarly for g−A(x) and bg ±A (y). By substitution of these relations the formula (1)
is somewhat simpliﬁed in the case |x| ∨ |y| → ∞ (cf Lemma 4.2);
n ∧ x ∧ y → ∞ under x ∨ y < M√n and x ∧ y = o(√n),

in particular as

pn
A(x, y) =

2xy
σ2n

pn(y − x)[1 + o(1)],

where the condition x ∧ y = o(√n) cannot be relaxed (see (4.4)).
(d) Formula (1.4) may be equivalently stated as follows: The probability that the
walk S· started at x and pinned at y at time n avoids A is asymptotic to the ratio on
the right side of (1.4), namely

Px[σA > n| Sn = y] ∼

g+
A (x)g−

−A(−y) + g−A (x)g+

−A(−y)

.

2n/σ2

Here the symbol ∼ means that the ratio of two sides of it approaches unity.

3

For a non-empty set B ⊂ Zd, σB (resp. τB) denotes the ﬁrst time when Sn enters

into (resp. exits from) B:

σB = inf{n ≥ 1 : Sn ∈ B},

τB = inf{n ≥ 1 : Sn /∈ B}.

For typographical reason we shall sometimes write τ (B) for τB and similarly for σ(B).
For a positive integer R denote the interval {−R + 1, . . . , R − 2, R − 1} by

U(R).

The roles of g±A and g±

−A appearing in (1.4) may be explained by the formula

Px[τU (R) = σ[R,∞) < σA] =

g+
A (x)
R

(1 + o(1))

(1.6)

(Proposition 3) and its reverse and dual formulae (see the paragraph following Theorem
2 given near the end of this section for a little more details). Here o(1) → 0 as R → ∞
uniformly for −M < x ≤ R. Indeed formula (1.6) is a gist of the proof of Theorem 1,
and Section 2 will be devoted to its proof.

For ξ0 ∈ A and x ∈ Z, put

and

uA(x) = δx,ξ0 + a(x − ξ0) − Ex[a(Sσ(A) − ξ0)]

wA(x) = σ−2(x − Ex[Sσ(A)]).

We shall see (Lemma 2.1) that uA(x) does not depend on the choice of ξ0 and that

g+
A(x) = uA(x) + wA(x)

and g−A(x) = uA(x) − wA(x),

(1.7)

by which we obtain the identity

g+
A (x)g−

−A(−y) + g−A (x)g+

−A(−y)

2

= uA(x)u−A(−y) − wA(x)w−A(−y).

By substitution formula (1.4) becomes quite analogous to the one for the case A = {0}.

From the deﬁnition it follows that

Xy /∈A

p(ξ − y)g±

−A(−y) = g±

−A(−ξ),

ξ ∈ A.

(1.8)

Keeping this in mind we substitute the expression given in Theorem 1 for pn−1
the identity

A (x, y) in

Px[σA = n, Sn = ξ] =Xy /∈A

pn−1
A (x, y)p(ξ − y),

and observe that in view of a local limit theorem pn−1(y − x) is well approximated by
pn(ξ − x) for any suﬃciently large n with pn(ξ − x) > 0 and any y with p(ξ − y) > 0
uniformly under the constraints |y| = o(√n) and |x| < M√n, which leads to the following

4

Corollary 1. Let A be a non-empty ﬁnite subset of Z. Then, for each M > 1 and for
ξ ∈ A, as n → ∞

Px[σA = n, Sσ(A) = ξ] =

g+
A(x)g−

−A(−ξ) + g−A(x)g+

−A(−ξ)

2n/σ2

pn(ξ − x)(1 + o(1))

(1.9)

uniformly for x ∈ Z satisfying |x| < M√n and g+
−A(−ξ) > 0; if the
latter condition is violated, then the probability on the left side of (1.9) either vanishes
for every n or tends to zero exponentially fast as n → ∞.

−A(−ξ)+g−A(x)g+

A (x)g−

For a non-empty set B that is contained in (−∞, N] for some N, we put

H +∞B (y) = lim
x→∞

Px[Sσ(B) = y]

and similarly for H−∞B
30.1]). It is noted that g+
‘started at +∞’ hits A at ξ, which fact is expressed as

if B ⊂ [N,∞) (the existence of H±∞B
A (ξ) =Pz /∈A p(z − ξ)g+

is established in [6, Theorem
A(z) is the probability that the dual walk

g+
A (ξ) = H−∞

−A (−ξ),

ξ ∈ A,

and similarly g−A(ξ) = H +∞
started at −∞. Thus g−
−A at −ξ, whence

−A (−ξ), representing the same probability but for the dual walk
−A(−ξ) is the probability that the dual walk ‘started at −∞’ hits
(1.10)

g−
−A(−ξ) = H +∞A (ξ),

ξ ∈ A,

and similarly g+

−A(−ξ) = H−∞A (ξ).
By (1.10) and by (1.7) we have
Xξ∈A
A(ξ) =Xξ∈A

g+

g−A(ξ) = 1 and

g+
A(x) + g−A(x)

2

= uA(x)

hence (1.9) entails that if the random walk is aperiodic, then

Px[σA = n] =

σ2uA(x)

n

pn(−x)(1 + o(1))

and for ξ ∈ A,

lim
n→∞

Px[Sσ(A) = ξ | σA = n] =

g+
A (x)

g+
A(x) + g−A(x)

H +∞A (ξ) +

g−A (x)

g+
A(x) + g−A(x)

H−∞A (ξ).

Here the convergence is uniform for |x| < M√n, and as x → ∞ or −∞ we have only
the limits H +∞A (ξ) or H−∞A (ξ) in the second formula, quite reasonable ones.

When xy < 0, we need to perform somewhat delicate analysis to ﬁnd whether formula
(1.4) is true as |x| ∧|y| → ∞. We shall prove in Theorem 3 that it remains valid for x, y
satisfying the constraints |x|∨|y| < M√n and |x|∧|y| = o(√n ) under a mild additional
condition on p which is true at least if the tail F (y) = P [X < y] is regularly varying at
−∞ with an exponent less than −2. Under the assumption E[|X|3; X < 0] < ∞ things
are particularly simpliﬁed as given below.

5

Put

It holds that

C + :=

0Xy=−∞

H +∞(−∞,0](y)(σ2a(y) + |y|) ≤ ∞.

C + = lim
x→+∞

(σ2a(x) − x),

(1.11)

C + < ∞ if and only if E[|X|3; X < 0] < ∞, and C + > 0 unless the walk is left-
continuous, i.e., unless P [X ≤ −2] = 0 (cf. Corollary 2.1 and Remark 1 (a) of [8]). We
call
(1.12)

C +

H +∞A (ξ)[σ2a(ξ − ξ0) − (ξ − ξ0)].

A := σ2 lim
x→∞

g−A(x) = C + −Xξ∈A

(Of course ξ0 ∈ A: the sum does not depend on the choice of ξ0.) It will be proved that
C +
−A = C +
(1.13)

A , namely

C +

g−
−A(x)
(see (6.4)). By (1.7) σ2g+
A (x) ∼ 2x (x → ∞) and σ2g+
these together yields that if C + < ∞, as x ∧ (−y) → ∞

A = σ2 lim
x→∞

−A(−y) ∼ 2|y| (y → −∞). Putting

g+
A(x)g−

−A(−y) + g−A(x)g+

−A(−y)

2

= C +
A

x + |y|

σ4

(1 + o(1)).

In view of this relation the next result is a natural extension of Theorem 1 for the case
xy < 0.
Theorem 2. If E[|X|3; X < 0] < ∞, then as x∧ (−y)∧ n → ∞ subject to the condition
x ∨ (−y) < M√n

pn
A(x, y) = C +
A

x + |y|
σ2n

pn(y − x)(1 + o(1)).

We conclude this section by describing main steps of derivation of the formula of
Theorem 1. As mentioned before, the proof rests on formula (1.6) and its counter-
relation

Px[τU (R) = σ(−∞,−R] < σA] = R−1g−A (x)(1 + o(1).

In [8] we have shown that (1.2) holds uniformly in the regime |x| ∨ |y| = o(√n), which
in particular entails that as |x| ∧ |y| ∧ n → ∞ under the condition |x| ∨ |y| = o(√n)

pn
{0}(x, y) =

2xy
σ2n

pn(y − x) + o(cid:18)|x| ∨ |y|

n3/2 (cid:19) if xy > 0

and

pn

{0}(x, y) = o(cid:18)|x| ∨ |y|

n3/2 (cid:19) if xy < 0;

(x, y) in the same limit scheme. Taking R = o(√n ),
moreover, we shall see pn
so that τU (R) = o(n) (a.s.), we apply the strong Markov property with τU (R) and put all
the relations mentioned above together to deduce that for |x| < |y| = o(n), as |y|∧n → ∞

A(x, y) ∼ pn
{0}

pn
A(x, y) =

gsign(y)
(x)|y|
A
n

pn(y − x) + o(cid:18) (|x| + 1) ∨ |y|

n3/2

(cid:19),

6

where sign(y) is + or − according as y is positive or negative. Finally on applying the
last relation to the time-reversed walk the same argument leading to it shows the formula
of the theorem for x and y ﬁxed.

Although we shall apply the uniform estimate of pn

(x, y), as stated above, for the
proof of Theorem 1, our proof can be modiﬁed to derive from the point-wise result of
Kesten mentioned in (1.2) the corresponding point-wise result for pn

{0}

A(x, y).

In Section 2.1 we provide certain potential theoretic facts that prepare for the proof
of (1.6) given in Section 2.2. In Section 3 we state a few known facts for pn
(x, y) (cited
from [8]) and for pn
(−∞0](x, y) as well as some related results. Proofs of Theorems 1 and
2 are given in Sections 4 and 5, respectively. We provide in Section 6 some auxiliary
results that are used in Sections 2, 4 and 5.

{0}

2 Green’s function and escape from A

It is shown in [6, Theorem 29.1] that a(x + 1) − a(x) → ±1/σ2 as x → ±∞, which
implies

a(x + z) − a(x) = ±

z
σ2 (1 + o(1))

with o(1) → 0 as x → ±∞ uniformly for z with (x + z)x > 0, and a(x)/|x| → 1/σ2 as
|x| → ∞. It also holds that for all x, y ∈ Z,

σ2a(x) ≥ |x|

and

Xz∈Z

p(z − x)a(z − y) = a(x − y) + δx,y

and that a(x) is linear for x ≥ 0 (resp. x ≤) if and only if the walk is left-continuous
(resp. right-continuous, i.e., P [X ≥ 2] = 0). (cf. Theorem 28.1, Proposition 31.1 and
Proposition 30.3 of [6]). In the sequel these relations will be used without notice. We
shall designate by C, C′, C1, . . . etc. constants depending whose exact values are not
signiﬁcant for the present purpose and may vary at diﬀerent occurrences of them. The
letters x, y and z are used to denote the integers representing states of the walk.

2.1 Green’s function

We deﬁne a function uA(x) by

uA(x) = gA(x, y) + a(x − y) − Ex[a(Sσ(A) − y)],

y ∈ Z.

(2.1)

Lemma 2.1. The right side of (2.1) is independent of y ∈ Z for all x ∈ Z. In particular
for any ξ0 ∈ A
(2.2)

uA(x) = δx,ξ0 + a(x − ξ0) − Ex[a(Sσ(A) − ξ0)].

Proof. With x ∈ Z ﬁxed put f (y) := gA(x, y) + a(x − y) − Ex[a(Sσ(A) − y)], y ∈ Z. We
hence must be constant, for f is bounded. Remember that for all x, y ∈ Z2,

are to prove that f is dual-harmonic on Z, namely f (y) =Pz p(y − z)f (z) for all y ∈ Z,

gA(x, y) =

∞Xn=0

pn
A(x, y),

p0
A(x, y) = δx,y;

7

in particular gA(x, y) = δx,y for y ∈ A. We then observe that if bP denotes the dual
transition operator, i.e., bP f (y) =Pz p(y − z)f (z), then for all x ∈ Z2,

and

while

bP a(x − ·)(y) = a(x − y) + δx,y
bP gA(x,·)(y) =( gA(x, y) − δx,y
bP{Ex[a(Sσ(A) − ·)]}(y) =(cid:26) Ex[a(Sσ(A) − y)]
From these there readily follows the identity bP f = f as required.

Ex[a(Sσ(A) − y)] + Px[SσA = y]

(y /∈ A),
(y ∈ A),

Px[SσA = y]

(y /∈ A),
(y ∈ A).

Remark 2. The proof given above is valid for all recurrent walks. The result then is
essentially Proposition 4.6.3 of [4] if p is supported on a ﬁnite set. Our proof is diﬀerent
from one given there. For x restricted on A, (2.1) reduces to the dual of the formula of
Proposition 30.1 in [6], where the dual of uA(x), which therein is denoted by µA(x), is

deﬁned as the limit ofPz∈Z pn(z − y)Pz[Sσ(A) = x] as n → ∞. In other words, (2.1) is

an extension of the latter to the complement of A. The same approach of using formula
(2.1) to deﬁne uA(x) is adopted by Hunt [5] to deﬁne the (classical) Green’s function in
a plane region with pole at inﬁnity.

Passing to the limit in (2.1) we obtain

uA(x) = lim
y→+∞
A(x) − wA(x),

= g+

gA(x, y) − (x − Ex[Sσ(A)])/σ2

and similarly uA(x) = g−A(x)− wA(x), showing (1.7). Substitution from (2.2) then yields
expressions of g+

A and g−A, which we write down as

and

g+
A (x) = δx,ξ0 + a(x − ξ0) +

g−A(x) = δx,ξ0 + a(x − ξ0) −

where ξ0 is a point arbitrarily chosen from A.

x

σ2 − Exha(Sσ(A) − ξ0) +
σ2 − Exha(Sσ(A) − ξ0) −

x

1

σ2 Sσ(A)i
σ2 Sσ(A)i,

1

As y → ∞ we have a(Sσ(A) − y) = a(−y) − Sσ(A) + o(1), whence

gA(x, y) − g+

A(x) = −wA(x) − a(x − y) + Ex[a(Sσ(A) − y)]

= a(−y) − a(x − y) −

x
σ2 + o(1).

where o(1) → 0 as y → +∞ uniformly in x ∈ Z. In Section 6 ((6.9)) we shall see that
for |x| ≤ y,

(cid:12)(cid:12)(cid:12)a(−y) − a(x − y) −

x

σ2(cid:12)(cid:12)(cid:12) ≤ C(cid:16)a(−|x|) − |x|
σ2(cid:17);

in particular the right side of (2.5) is (1 + |x|) × o(1) as y → ∞ uniformly for |x| ≤ y.

8

(2.3)

(2.4)

(2.5)

(2.6)

to ﬁnd

Xz∈Z
A (x) =Xz∈Z

g+

Put

r+
A = 1 + max A and r−A = −1 + min A,
so that A ⊂ [r−A + 1, r+
A − 1], and bring in the following subsets of Z:
V − = {x ∈ Z : ∃n ≥ 1, pn
bV − = {y ∈ Z : ∃n ≥ 1, pn

V + = {x : ∃n ≥ 1, pn
bV + = {y : ∃n ≥ 1, pn

A) > 0},
A, y) > 0},

A(x, r+

A(r+

namely, V + is the set of those points x from which the walk can enter into the right half
[r+

A,∞) with positive probability, and similarly for V −A and bV ±A .

Noting that gA(·, y) is bounded for each y, we pass to the limit in the identity

A(x, r−A) > 0};
A(r−A, y) > 0};

p1
A(x, z)gA(z, y) = gA(x, y) − δx,y

p1
A(x, z)g+

A (z)

for all x ∈ Z;

(2.7)

A(x) > 0 for x ∈ V + and similarly for g−A. Since gA(x, y) = 0 if x /∈ V +

in particular g+
and y ≥ r+
Lemma 2.2. For each M > 1, uniformly for −M < x ≤ y, as y → +∞

A(x) ∼ 2x/σ2 as x → ∞, combined with (2.5) and (2.6) this shows

A, and g+

gA(x, y) = g+

A(x)(1 + o(1)).

It may be worth noting that

V ± = {x : g±A(x) > 0}

which are veriﬁed in the discussion made above.

and bV ± = {y : g∓

−A(−y) > 0},

(2.8)

2.2 Probabilities of escape from A and an overshoot estimate

What are advanced in this subsection are modiﬁcations of the corresponding results for
the case A = {0} that are given in [8, Section 2.3] and the arguments are parallel to
those in it.

We have the identity

Px[σ{y} < σA] =

gA(x, y)
gA(y, y)

.

From (2.1) and (2.2) we deduce

gA(y, y) = a(y) + a(−y) + O(1).

Hence, from Lemma 2.2 it follows that uniformly for −M < x < y,

Px[σ{y} < σA] =

σ2g+
A(x)
2y

(1 + o(1)) as

y → +∞

(2.9)

and similarly for the case when y → −∞ and y < x < M with g−A(x) replacing g+
the right side. In the sequel the letter R will always denote a positive integer.

A(x) on

9

Proposition 1. Uniformly for x < R,

Px[σ[R,∞) < σA] = Px[σ{R} < σA](1 + o(1)) as R → +∞.

And furthermore, for each M > 1, as R → ∞, uniformly for −M < x < R,

Px[σ[R,∞) < σA] =

σ2g+
A(x)
2R

(1 + o(1))

(2.10)

and

Px[σ[R,∞) < σA] ≤

σ2g+(x)

2R

(1 + o(1)) uniformly for x < 0.

(2.11)

Proof. The diﬀerence Px[σ[R,∞) < σA] − Px[σ{R} < σA] is expressed as
Px[σ [R,∞) < σA, Sσ([R,∞)) = z]Pz[σ{R} > σA].

Xz>R

For simplicity suppose A ⊂ (−∞, 0]. Then this sum is dominated by

Px[σ [R,∞) < σA] sup

z>R

Pz[σ{R} > σ(−∞,0]],

(2.12)

of which the supremum tends to zero as R → ∞ as is proved in [8, Lemma 2.3]. Thus
we obtain the ﬁrst relation of the proposition.
The second relation (2.10) follows immediately from the ﬁrst and (2.9). For the
A (x)(1 + o(1)), whose proof we relegate

proof of (2.11) we must show that gA(x, y) ≤ g+
to Appendix B (ii), (2.11) being not used for main results of this paper.

Proposition 2. (Overshoot estimate)
as R → ∞

For each M > 1, uniformly for −M ≤ x < R,

1
R

Ex[ Sσ([R,∞)) − R| σ [R,∞) < σA ] = o(1)

and for all x ∈ Z and ξ0 ∈ A,

Ex[ Sσ([R,∞)); σ [R,∞) < σA ] ≤

1
2

[σ2a(x − ξ0) + x − ξ0] + cA

(2.13)

(2.14)

2σ2a(ξ − ξ0) + |ξ − ξ0|] + 1

for some constant cA (≤ supξ∈A[ 1
Proof. Suppose 0 ∈ A, which gives rise to no loss of generality since R does not appear
in the right side of (2.14). That g+
A is non-negative and harmonic on Z \ A in the sense
of the identity (2.7) implies that for all x ∈ Z,

2σ2).

Ex[g+

A(Sσ([R,∞))); σ [R,∞) < σA ] ≤ g+

A(x),

which shows (2.14), because y ≤ 1
σ2g+
it also follows that

A (x) ≤ σ2[1 + a(x)] + x + supξ∈A |ξ|. For R so large that g+

A(y) + supξ∈A(σ2a(ξ) + |ξ|)] (for all y ∈ Z) and
A(z) is monotone in z ≥ R,

2[σ2g+

0 ≤ Ex[g+

A (Sσ([R,∞))) − g+

A(R); σ [R,∞) < σA ]

≤ g+

A (x) − g+

A(R)Px[σ [R,∞) < σA ].

(2.15)

10

Owing to Proposition 1 the last member is dominated by

g+

A (x)(cid:18)1 −

g+
A (R)

2R/σ2(cid:19) + (1 ∨ x) × o(1) = (1 ∨ x) × o(1),

where o(1) → 0 as R → ∞ uniformly for −M ≤ x < R. Dividing by RPx[σ [R,∞) < σA]
and applying Proposition 1 again we ﬁnd

1
R

Ex[g+

A(Sσ([R,∞))) − g+

A (R)|σ [R,∞) < σA ] = o(1).

Finally substitution from limz→+∞ g+
2σ2g+

1

A(z)(1 + o(1)) (z → +∞), yields the formula (2.13).
By Markov’s inequality we deduce from Propositions 1 and 2 the following

A(z)/z = 2/σ2, or what is the same thing, z =

Corollary 2. Uniformly for −M < x < R and for R′ > R, as R → ∞

Px[Sσ([R,∞)) ≥ R′, σ[R,∞) < σA] =
=

RPx[σ[R,∞) < σA]

g+
A(x)

R′ − R
R′ − R × o(1).

× o(1)

(2.16)

Corollary 3. For any ε > 0, uniformly for −M < x < R, as R → ∞

Ex[Sσ([R,∞)); Sσ([R,∞)) ≥ (1 + ε)R, σ[R,∞) < σA] = g+

A(x) × o(1).

(2.17)

Proof. We have only to decompose Sσ([R,∞)) into the sum of Sσ([R,∞)) − R and R and to
apply Propositions 2 and 1 for the ﬁrst term and Corollary 2 for the second.

Proposition 3. For each M > 1, as R → ∞

Px[τU (R) = σ[R,∞) < σA] = Px[σ[R,∞) < σA](1 + o(1))

=

σ2g+
A(x)
2R

(1 + o(1)),

where o(1) → 0 uniformly for −M ≤ x ≤ R.
Proof. Given ξ0 ∈ A, we put f (z) = a(z − ξ0) + σ−2z, so that

g+
A(x) = f (x) − Ex[f (SσA)].

Suppose x 6= ξ0, the case x = ξ0 being readily reduced to this case (see (2.7)). In view
of the optional sampling theorem Mn = f (Sn∧σA∧τU (R)) is then a martingale under the
law Px. It is uniformly integrable and hence, according to the martingale convergence
theorem,

Breaking this expectation according as τU (R) is larger or smaller than σA we ﬁnd

f (x) = Ex[f (SσA∧τU (R))].

g+
A(x) = Ex[f (SσA∧τU (R))] − Ex[f (SσA)]

= Ex[f (SτU (R)) ; τU (R) < σA] − Ex[f (SσA); τU (R) < σA]

11

The last expectation on the right side uniformly converges to zero as R → ∞. In view of
Proposition 1 and the relation f (R) = 2R/σ2(1 + o(1)), for the proof of the proposition
it therefore suﬃces to show

Ex[f (SτU (R)) ; τU (R) < σA] − f (R)Px[σ[R,∞) = τU (R) < σA] = (1 ∨ x) × o(1)

(2.18)

as R → ∞ uniformly for −M < x < R. By the dual relation of (2.14) we deduce

Ex[f (SτU (R)) ; σ(−∞,−R] = τU (R) < σA] ≤ (cid:20) sup

y≤−R

f (y)

−y (cid:21)Ex[Sσ(−∞,−R] ; σ(−∞,−R] < σA]

≤ [σ2a(−x) − x + 1] × o(1)

(uniformly for all x). On the other hand, owing to the overshoot estimate (2.13)

Ex[f (SτU (R)) − f (R) ; σ[R,∞) = τU (R) < σA] = (x ∨ 1) × o(1)
uniformly for −M < x < R. Adding these relations we obtain (2.18).
Corollary 4. For any M > 1, uniformly for −M < x ≤ R and z ≥ R, as R → ∞

Px[Sσ[R,∞) = z | τU (R) = σ[R,∞) < σA]

≤ Px[Sσ[R,∞) = z | σ[R,∞) < σA](1 + o(1)).

(2.19)

Proof. Denote the conditional probabilities on the left and on the right of (2.19) by µ(z)
and ˜µ(z), respectively. Then we see

µ(z) ≤

= ˜µ(z)

Px[σ[R,∞) < σA, Sσ[R,∞) = z]

Px[τU (R) = σ[R,∞) < σA]
Px[σ[R,∞) < σA]

Px[τU (R) = σ[R,∞) < σA]

.

According to Proposition 3 this yields µ(z) ≤ ˜µ(z)(1 + o(1)), as desired.

The next result concerns the probability of the walk escaping from A, which, though

not applied in this paper, we record.

Corollary 5.

Uniformly for |x| < R, as R → ∞
σ2uA(x)

Px[τU (R) < σA] =

R

(1 + o(1)).

Proof. The inclusion-exclusion formula derives the assertion of the proposition from
Proposition 3 if Px[σ(−∞,−R] ∨ σ[R,∞) < σ{0}] = o(x/R) uniformly for for 0 < |x| < R,
which is readily veriﬁed (cf. [8, Proposition 2.4]).

3 Results for a single point set and a half line.

Put

gt(u) =

1

√2πσ2t

e−u2/2σ2t

(u ∈ R, t > 0)

12

and

a†(x) = δx,0 + a(x).

We shall apply the following version of local limit theorem (cf. e.g., [6], [9]): as n → ∞
uniformly for x ∈ Z

(3.1)

n ∨ x2(cid:19),
pn(x) = νgn(x) + o(cid:18) √n

where ν designates the (temporal) period of the walk: ν = g.c.d. of {n : pn(0) > 0}.

3.1 Results for the case A = {0}.
Here we state two results from [8] and [7] for the case A = {0} that are used later.
Theorem A. Given a constant M > 1, the following asymptotic estimates of pn
(x, y)
{0}
as n → ∞, stated in three cases of constraints on x and y, hold true uniformly for x and
y subject to the respective constraints.

(i) Under |x| ∨ |y| < M√n and |x| ∧ |y| = o(√n),

pn
{0}

(x, y) =

σ4a†(x)a(−y) + xy

σ2n

pn(y − x) + o(cid:18)(|x| ∨ 1)|y|

n3/2

(cid:19).

(3.2)

(ii) Under M−1√n < |x|, |y| < M√n (both |x| and |y| are between the two extremes),

(x, y) = νhgn(y − x) − gn(y + x)i + o(cid:18) 1
√n(cid:19)
(x, y) = o(cid:18) 1
√n(cid:19)

pn
{0}

pn
{0}

if xy > 0 and pn(y − x) > 0,
if

xy < 0.

(3.3)

(3.4)

(iii) Let 0 < |x| ∧ |y| < √n < |x| ∨ |y|. Then, if E|Y |2+δ < ∞ for some δ ≥ 0,

pn

{0}(x, y) = O(cid:18)|x| ∧ |y|

|x| ∨ |y|

g4n(|x| ∨ |y|)(cid:19) + |x| ∧ |y|

(|x| ∨ |y|)2+δ × o(1).

Theorem B. Uniformly in x, as n → ∞
σ2a†(x)

Px[σ{0} = n] =

n

pn(−x) + |x| ∨ 1

n3/2 ∨ |x|3 × o(1).

(3.5)

Theorem A is Theorem 1.1 of [8]. Theorem B is an immediate consequence of Corol-
lary 1.1 of [7] and a local limit theorem (3.1), if ν = 1, i.e., if the walk S· is aperiodic.
For ν > 1, apply this result to the walk ˜Sn = ν−1Sνn, whose increment has variance
σ2/ν.

13

3.2 Hitting distribution of a half line.
Here we consider the walk killed when it enters (−∞, 0]. The results given in this
subsection will be used in the proof of Theorem 3 given in Section 5 but not needed for
Theorems 1 nor 2.

Let f +(x) (resp. f−(x)) (x = 1, 2, . . .) be the positive function on x > 0 that is
asymptotic to x as x → ∞ and harmonic with respect to the walk Sn (resp −Sn)
absorbed on (−∞, 0]:

f±(x) = E[f±(x ± X); x ± X > 0] (x ≥ 1) and

lim
x→∞

f±(x)/x = 1,

(3.6)

each of which exists uniquely; the diﬀerences u±(x) := f±(x) − f±(x − 1) (for x ≥ 1
with f±(0) = 0) are all positive and limx→∞ u±(x) = 1 (cf. Sections 18 and 19 of [6];
in particular Proposition 19.5 for the uniqueness). (It is warned that it is not [1,∞)
but [0,∞) on which the harmonic function is considered in [6].) The following result is
established in [1].
Theorem C. For each M > 1, uniformly for 0 < x, y ≤ M√n, as xy/n → 0

pn
(−∞,0](x, y) =

2f +(x)f−(y)

σ2n

pn(y − x)(1 + o(1)).

From Theorem C one derives an asymptotic form of the space-time distribution of

the ﬁrst entrance into (−∞, 0], which we denote by hx(n, y): for y ≤ 0

hx(n, y) = Px[Sσ(−∞,0] = y, σ(−∞,0] = n].

According to our notation H x
for the walk Sn started at x, so H x
of [6]

exists and is given by

(−∞,0](y) (y ≤ 0) denotes the hitting distribution of (−∞, 0]

(−∞,0](y) =Pn hx(n, y). According to Proposition 19.4
H +∞(−∞,0](y) := lim
x→∞

H x
(−∞,0](y)

H +∞(−∞,0](y) =

2
σ2 E[f−(y − X); X < y] =

2
σ2

∞Xj=1

Let F be the distribution function of X:

Then by summation by parts we have

F (t) = P [X ≤ t].

f−(j)p(y − j)

(y ≤ 0).

(3.7)

H +∞(−∞,0](y) =

2
σ2

∞Xj=1

u−(j)F (y − j),

which entails that H +∞(−∞,0](y) is monotone.

Green’s function of the walk killed at the origin is given by

g(z, y)

:= g{0}(z, y) − δ0,zδ0,y
= a(z) + a(−y) − a(z − y)

14

(3.8)

(3.9)
(3.10)

([6, Proposition 29.4]). By the strong Markov property of the walk S we have

0Xz=−∞

H x
(−∞,0](z)g(z, y) = g(x, y)

for

y ≤ 0.

(3.11)

By employing the bound H x

(−∞,0](z) ≤ CH +∞(−∞,0](z) ([8, (2.5)]) we let x → ∞ to obtain

(3.12)

(3.13)

(3.14)

0Xz=−∞

H +∞(−∞,0](z)g(z, y) = a(−y) +

y
σ2 .

Lemma 3.1. Suppose E[|X|3; X < 0] = ∞. Then, as x → ∞
H +∞(−∞,0](w).

x
σ2 ∼

a(x) −

2
σ2

−1Xz=−x

zXw=−∞

Proof. Consider asymptotics as y := −x → −∞ in (3.12). Noting

g(z, y) =(cid:26) [a(z) − σ−2z](1 + o(1)) ∼ 2σ−2|z|

(y < z < 0),
(z ≤ y),
where o(1) is uniform in z, we then deduce that if E[|X|3; X < 0] = ∞,

g(y, y)(1 + o(1)) ∼ 2σ−2|y|

a(−y) +

y
σ2 ∼

2
σ2

(|z| ∧ |y|)H +∞(−∞,0](z).

−1Xz=−∞

By summation by parts the right side equals that of (3.13) with x = −y. The proof is
complete.

For later use here we record the following identity

H x

(−∞,0](z)(cid:18)a(z) −

z

σ2(cid:19) = a(x) −

x
σ2

for x > 0,

(3.15)

0Xz=−∞

which is obtained by letting y → −∞ in (3.11), the limit procedure being justiﬁed by
H x
Lemma 3.2. Deﬁne αn(x, y) for y ≤ 0 < x via the equation

(−∞,0](z) ≤Py>0 g(x, y)p(z − y) ≤ CxF (z).

hx(n, y) =

νf +(x)gn(x)

n

hH +∞(−∞,0](y) + αn(x, y)i

(3.16)

if pn(y − x) > 0, and put αn(x, y) = 0 if pn(y − x) − 0. For any M > 1 put

αn(y) = sup

0<x<M√n |αn(x, y)|.

Then

and

0Xz=y

αn(y) ≤ CH +∞(−∞,0](y),

lim
n→∞

0Xy=−∞

αn(y) = 0

(3.17)

αn(z)|z| = [σ2a(−y) + y] × o(1) as

√n
y → −∞ and n → ∞.

(3.18)

15

Proof. Suppose the walk is aperiodic for simplicity. We have the representation

hx(n, y) =

∞Xj=1

pn−1
(−∞,0](x, j)p(y − j).

(3.19)

In view of Theorem C and the local limit theorem (3.1), for each ε > 0, the sum on the
right over j < ε√n may be replaced by

f +(x)gn(x)

n

·

2

σ2 X1≤j≤ε√n

f−(j)p(y − j)(1 + oε(1)),

where oε(1) → 0 as n → ∞ and ε → 0. On the other hand the sum over j > ε√n is

(x, j) in Theorem A (iii). Taking these into account

evaluated by using the bound of pn−1
{0}
we ﬁnd

αn(x, y) = H +∞(−∞,0](y) × oε(1) + ηn(x, y)

(3.20)

with

|ηn(x, y)| ≤ C0 Xj>ε√n

jp(y − j).

The veriﬁcation of (3.17) is now immediate.

For the proof of (3.18) note that in view of (3.13) [σ2a(−y) + y]/|y| is asymptotically

equivalent to a function that is decreasing in |y|, y < 0. By (3.14)

|z|H +∞(−∞,0](z) ≤ C1(σ2a(−y) + y),

(3.21)

and in view of the monotonicity mentioned above we see that whenever y′ ≤ y < 0,

|z|H +∞(−∞,0](z) ≤ C′1

σ2a(−y) + y

|y|

.

(3.22)

Xy<z<0
|y′| Xy′≤z<0
4 ε√n,

1

where we have applied (3.22) with y′ = ⌊ε√n⌋ for the last inequality. This together with

(3.20) and (3.21) entails (3.18).

jp(z − j) ≤ CH +∞(−∞,0](z′)

if −

3
4

ε√n < z′ < 0

Observing that for 0 > z > − 1

Xj>ε√n
we see that if |y| < ε√n,
|z| sup

1
|y|

−1Xz=y

x |ηn(x, z)| ≤ C0

jp(z − j)

−1Xz=y Xj>ε√n
ε√n X− 3
≤ 2C0C |y|
ε√n X− 3
≤ C′ |y|
ε√n ·
≤ C′′ |y|
ε√n ·

4 ε√n<z<0

σ2a(−y) + y

1

,

4 ε√n<z<0

|y|

H +∞(−∞,0](z)

|z|H +∞(−∞,0](z)

16

4 Proof of Theorem 1

We break Theorem 1 into three assertions by dividing the range of variables into three
regimes according as |x| ∧ |y| → ∞, |x| ∨ |y| → ∞ or |x| ∨ |y| = O(1), of which the ﬁrst
case is dealt with by Lemma 4.1, the second by Lemma 4.2 and the third at the end of
this section.

Lemma 4.1. As x ∧ y ∧ n → ∞ under the constraint x ∨ y < M√n,
{0}(x, y) × O(cid:16) 1
x ∧ y(cid:17)

pn
{0}(x, y) − pn

A(x, y) = pn

and

A(−x, y) = o(xyn−3/2).
pn

(4.1)

(4.2)

Proof. The second relation (4.2) follows from (i) and (ii) of Theorem A in Section 3.1.
For the proof of (4.1) suppose, for simplicity, 0 ∈ A so that

pn
{0}(x, y) − pn

A(x, y) =

nXk=0 Xξ∈A\{0}

Px[σA = k, Sk = ξ]pn−k
{0}

(ξ, y).

(4.3)

We split the outer sum at k = ⌊n/2⌋, and denote the double sum restricted to k < n/2
by I[0,n/2) and the other part of the sum by I[n/2,n]. According to Theorem A (i)

I[0,n/2) ≤ ♯A sup

k<n/2

sup

ξ

pn−k
{0}

(ξ, y) ≤ C

y
n

pn(y),

where ♯A denotes the cardinality of A. In a similar way we apply Theorem B to ﬁnd
that

I[n/2,n] ≤

Cx
n3/2 sup

ξ X1≤j≤n/2

pj
{0}

(ξ, y) ≤

C′x
n3/2 .

Adding these two bounds concludes the proof of Lemma 4.1.

where we have used P1≤j≤n/2 pj
that as x ∧ y ∧ n → ∞ under the constraint x ∨ y < M√n,

{0}

(ξ, y) ≤ g{0}(x, y) ≤ C′′ for the second inequality.

In view of Theorem A and the local limit theorem (3.1) it follows from Lemma 4.1

pn
A(x, y) = ν[gn(y − x) − gn(x + y)](1 + o(1)),

(4.4)

provided pn(y − x) > 0. This conforms to and prove the corresponding part of Theorem
1.
Lemma 4.2. For any M ≥ 1, uniformly for −M < x < √n/ lg n, as y ∧ n → ∞ under
y < M√n,

pn
A(x, y) =

g+
A(x)y

n

pn(y − x)(1 + o(1));

and uniformly for −√n/ lg n < x < M, as (−y) ∨ n → ∞ under |y| < M√n,

pn
A(x, y) =

g−A (x)|y|

n

pn(y − x)(1 + o(1)).

17

Proof. We have only to prove the ﬁrst relation, the second one being the dual of it. Put

R = ⌊√n/ lg n⌋ and N = mR2⌊lg n⌋ with m determined shortly and decompose

pn
A(x, y) =

Px[τU (R) = k < σA, Sk = z]pn−k

A (z, y)

(4.5)

Here

N−1Xk=1 X|z|≥R
ε(x, y; R) =Xz

+ ε(x, y; R).

Px[τU (R)\A ≥ N, SN = z]pn−N

A

(z, y)

(4.6)

and ⌊t⌋ denotes the largest integer that does not exceed t. Using the central limit
theorem we deduce supx∈U (R) Px[τU (R) > R2] < c for all suﬃciently large R with a
universal constant c < 1, and hence that

with λ = − lg c. Now take m = 2/λ so that

ε(x, y; R) ≤ Ce−λN/R2

/√n

ε(x, y; R) = O(n−2);

(4.7)

hence ε(x, y; R) is negligible.

As for the double sum in (4.5) we ﬁrst notice that the contribution from the half line
z ≤ −R is negligible in comparison with that from z ≥ R owing to (4.2) and (2.11). It
therefore remains to evaluate

so as to verify

W :=

N−1Xk=1Xz≥R

Px[τU (R) = k < σA, Sk = z]pn−k

A (z, y)

W =

g+(x)y

n

pn(y − x)(1 + o(1)).

(4.8)

(4.9)

From (4.1) and Theorem A of Section 3.1 it follows that if k < N,

pn−k

A (z, y)

2zy
σ2n

=
≤ zy/n3/2

pn(y − z)(1 + o(1))

for R ≤ z < 2R,
for 2R ≤ z < √n.

Px[τU (R) = k < σA, Sk = z] − O(n−2).

By the same reasoning as for (4.7) it also follows that

From these observations we infer that

Px[σ[R,∞) = τU (R) < σA] =

N−1Xk=1Xz≥R
(cid:12)(cid:12)(cid:12)(cid:12)W − Px[σ[R,∞) = τU (R) < σA]
≤ XR≤z<2R

Px[τU (R) < σA, SτU (R) = z](cid:12)(cid:12)(cid:12)(cid:12)

2Ry
σ2n

pn(y − x)(cid:12)(cid:12)(cid:12)(cid:12)

2zy
σ2n

+

+

y
n3/2 Ex[SτU (R); τU (R) < σA, SτU (R) ≥ 2R]
CRy
n3/2 Px[τU (R) < σA, SτU (R) ≥ 2R]

+ Cn−2.

18

pn(y − z)(1 + o(1)) −

2Ry
σ2n

pn(y − x)(cid:12)(cid:12)(cid:12)(cid:12)

(4.10)

On the right side we may replace τU (R) by σ[R,∞) by obvious reason. In view of the local
limit theorem, pn(y − z) = pn(y − x)(1 + o(1)) uniformly for |z| < √n, hence
|zpn(y − z) − Rpn(y − x)| ≤ zpn(y − z) × o(1) + |z − R|/√n,

provided pn(y − x)pn(y − z) > 0, and we infer that the ﬁrst term on the right side of
(4.10) is at most a constant multiple of

XR≤z<2R

Px[σ[R,∞) < σA, Sk = z](cid:20) 2zy

σ2n

pn(y − z) × o(1) +

2(z − R)y

σ2n3/2 (cid:21),

which, on applying Propositions 2 and 1 in turn, is

Px[σ[R,∞) < σA]

Ry
n3/2 × o(1) =

yg+
A(x)
n3/2 × o(1).

By Corollary 3 the second term on the right side of (4.10) is at most

yg+
A(x)
n3/2 × o(1).

Similarly by Corollary 2 the third term admits this same bound. Thus we see the
diﬀerence on the left side of (4.10) is negligible. On the other hand by Proposition 3

Pz[σ[R,∞) = τU (R) < σA]

2Ry
σ2n

pn(y − x) =

g+
A(x)y

n

pn(y − x)(1 + o(1)).

Consequently we obtain (4.9) as required.

Proof of Theorem 1.

Owing to Lemmas 4.1 and 4.2 we may and do suppose
|x| ∨ |y| ≤ M for a constant M. We make the same argument (with the same R) as
in the preceding proof except that in it y is supposed to tend to +∞ and we have
neglected the contribution of the sum over z ≤ −R to the double sum in (4.5) but here
the contributions both from z ≥ R and from z ≤ −R become relevant. We apply Lemma
4.2 to see that if R ≤ |z| < √n, then in the double sum in (4.5),
pn(y − z)(1 + o(1))

g−
−A(−y)z

n

for

z ≥ R,

−A (−y,−z) =

pn−k
A (z, y) = pn−k

g+
−A(−y)(−z)
also by Theorem A (iii), if |z| ≥ √n, then pn−k

n

A (z, y) ≤ C|y|/z2. The evaluation of the
term ε(n, x, y) given in (4.6) is valid and making estimation of the overshoots as in the
last several lines of the preceding proof we deduce

pn(y − z)(1 + o(1))

for

z ≤ −R;

pn
A(x, y) = Px[τU (R) = σ[R,∞) < σA]

pn(y − x)(1 + o(1))

+ Px[τU (R) = σ(−∞,−R] < σA]
+ O(n−2).

pn(y − x)(1 + o(1))

g−
−A(−y)R

n
g+
−A(−y)R

n

Substitution from the formula of Proposition 3 and its dual therefore concludes the
required relation of Theorem 1.

19

5 Reﬁnements in the case xy < 0

In the case xy < 0 the range of validity of formula (1.4) is restricted to |x| ∧ |y| < M in
Theorem 1 . In this section we remove this restriction under an additional condition on
p.

We call

D+

A = lim
x→∞

[σ2a(x) − x − σ2g−A(x)].

By (2.4) the limit exists and for all ξ0 ∈ A,

D+

A =Xξ∈A

H +∞A (ξ)[σ2a(ξ − ξ0) − (ξ − ξ0)].

(5.1)

A is positive unless either A consists of a single point or the walk S is left-continuous,

D+
when it vanishes and what we consider below becomes trivial.

Proposition 4. For any M > 1 and c ∈ Z, as x ∧ (−y) ∧ n → ∞ under the condition
x ∨ (−y) < M√n

pn
{c}

(x, y) − pn

A(x, y) = D+
A

x + |y|
σ2n

pn(y − x)(1 + o(1));

(5.2)

in other words, the probability that the walk S· started at x and pinned at y at time n
enters A but avoid the point c is asymptotic to D+

A(x + |y|)/σ2n.

Proof. Through out the proof the variables x, y and n are assumed subject to the

restriction x ∨ |y| < M√n and y < 0 < x.
We can suppose that c ∈ A. Indeed, if (5.2) is valid under this condition, taking
any b /∈ A and applying (5.2) with {c, b} in place of A, we have two equalities and the
subtraction of them yields

pn
{c}

(x, y) − pn
{b}

(x, y) = (x + |y|) × o(n−3/2),

which, combined with the expression for pn

A, shows (5.2) with b in place of c.

Now suppose c ∈ A. Then

{c} − pn

pn
{c}(x, y) − pn

A(x, y) =

nXk=1 Xξ∈A\{c}

Px[σA = k, Sk = ξ]pn−k
{c}

(ξ, y).

(5.3)

Let ε be a positive number (small enough that εM 2 < 1/2). For ξ ∈ A, by Corollary 1
and (1.10) uniformly for k > εx2, as x → ∞

Px[σA = k, Sk = ξ] =

σ2a(x) + x

2k

pk(ξ − x)H +∞A (ξ)(1 + o(1))

whereas by Theorem 1 (or Theorem A) as y → −∞, uniformly for 0 ≤ k ≤ n − εy2,

pn−k
{c}

(ξ, y) =

(ξ)

g−
{c}

n − k |y|pn−k(y − ξ)(1 + o(1))

for

ξ ∈ A.

20

Denote the outer sum in (5.3) restricted on an interval a < k ≤ b by I(a,b]. We then
obtain

I(εx2, n−εy2]

= Xξ∈A\{c}

H +∞A (ξ)g−
{c}

(ξ) Xεx2<k≤n−εy2

xpk(ξ − x)

k

· |y|pn−k(y − ξ)

n − k

(1 + o(1)).

Suppose pn(y − x) > 0. Then recalling that ν denotes the period of the walk, we apply
the local limit theorem (3.1) to rewrite the inner sum as

νZ n−εy2

εx2

xgs(x)

s

· |y|gn−s(y)
n − s

ds(1 + o(1)).

Since xgs(x)/s is the passage time density of Brownian motion, the integral above, if the
range of integration is extended to the interval (0, n), becomes

x + |y|

n

gn(x + |y|) =

x + |y|
νn

pn(y − x)(1 + o(1)).

xgs(x)s−1ds =Z ε

0

Plainly

Z εx2
as ε ↓ 0 and similarlyR n
n−εy2(cid:19)xgs(x)
+Z n

(cid:18)Z εx2

s

0

0

n−εy2 |y|gn−s(y)(t − s)−1ds = o(ε), so that for ε small enough,

· |y|gn−s(y)
n − s

ds ≤

ε
n

[|y|gn(y) + xgn(x)].

gu(1)u−1du = o(ε)

Since g−
{c}

(ξ) = a(ξ − c) − (ξ − c)/σ2 for ξ 6= c, we also have
A/σ2.

(ξ) = D+

H +∞A (ξ)g−
{c}

Xξ∈A\{c}

We then put these together to obtain

I(εx2, n−εy2] = D+

A

x + |y|
σ2n

pn(y − x)h1 + o(1) + O(ε)i,

(5.4)

where o(1) → 0 as x ∧ (−y) ∧ n → ∞ for each ε > 0 and O(ε) is uniform in x, y and n.

As for the remaining parts of the double sum in (5.3) we observe

I(0, εx2] ≤ CPx[σA ≤ εx2]pn
{c}

(ξ, y)

≤ C′P0[max
k≤εx2

(−Sk) ≥ x] |y|

n3/2 ≤ C′′

ε|y|
n3/2 ,

(5.5)

where Kolmogorov’s inequality is used for the last inequality. From (i) and (iii) of
Theorem A we derive

pj
{0}

(ξ, y) ≤

≤

Cy
j3/2 e−y2/2σ2j
C
y√j

e−y2/8σ2j +

for

j > y2,

1
y2 × o(1)

for 1 ≤ j ≤ y2,

21

where o(1) is bounded and tends to zero as j → ∞ uniformly in y, and on using these
bound easy computations yield

I(n−εy2, n] ≤ C(cid:20) X1≤j≤εy2

e−y2/8σ2j(cid:21) x

n3/2 < C′

1

|y|√j

εx
n3/2 .

This together with (5.5) and (5.4) completes the proof.

A = C + − D+

Because of the identity C +

A Theorem 2 follows immediately from Propo-
sition 4 and the result for the case A = {0} that is established in [8, Theorem 1.4]. (For
veriﬁcation of the latter we can readily adapt the proof of Proposition 5 below.)
Theorem 2 says that (1.4), the formula of Theorem 1, is true uniformly under |x| ∨
|y| = O(√n) and |x| ∧ |y| = o(√n), if E[|X|3; X < 0] < ∞. The next result asserts that
the same is true under a much weaker condition on p. We write down the condition by
means of a (see (5.8) below for another way) as follows: for x, y > 0,

(σ2a(y) − y)/y
(σ2a(x) − x)/x → 0 as

y
x → +∞.

(5.6)

Theorem 3.

Suppose (5.6) to hold true. Then, for any M > 1, uniformly for

−M√n ≤ y < 0 < x ≤ M√n,

as n → ∞ and (x ∧ |y|)/√n → 0 formula (1.4) of Theorem 1 holds true; in particular if
E[|X|3; X < 0] = ∞ (so that σ2a(x) − x → ∞ as x → ∞),

pn
A(x, y) =

(σ2a(x) − x)|y| + (σ2a(−y) + y)x

σ2n

pn(y − x)(1 + o(1)).

(5.7)

If E[|X|3; X < 0] < ∞, then (5.3) holds in view of (1.11); if E[|X|3; X < 0] = ∞, by

(3.8) and (3.13),

σ2a(x) − x ∼

4
σ2

−1Xz=−x−1

zXw=−∞

wXj=−∞

F (j)

(5.8)

as x → ∞, hence the condition (5.6) may be expressed explicitly in terms of p.

In view of Proposition 4 Theorem 3 follows if we show

Proposition 5.
is not left-continuous (so that pn

Suppose (5.6) to hold true. Let y < 0 < x and suppose the walk
(x, y) is not identically zero). Then for any M > 1,

uniformly for x,|y| ≤ M√n, as n → ∞ and (x ∧ |y|)/√n → 0

{0}

pn
{0}

(x, y) =

(σ2a(x) − x)|y| + (σ2a(−y) + y)x

σ2n

pn(y − x)(1 + o(1)).

(5.9)

Proof. The proof parallels that given for the same formula but under the additional
condition E[|X|3; X < 0] < ∞ in [8]. For simplicity we suppose ν = 1, i.e., the walk is
aperiodic. Recall that hx(n, z) is the space-time hitting probability of (−∞, 0]. Making
decomposition

pn
{0}

(x, y) =

hx(k, z)pn−k
{0}

(z, y),

nXk=1Xz<0

22

we break the double sum into three parts by partitioning the range of the outer summa-
tion as follows

1 ≤ k < εn; εn ≤ k ≤ (1 − ε)n;

(1 − ε)n < k ≤ n

and call the corresponding sums I, II and III, respectively. Here ε is a positive constant
less than 1/4 that will be chosen small.

We call

(5.10)
and suppose λ(x) → ∞ as x → ∞, or equivalently E[|X|3; X < 0] = ∞; otherwise (5.9)
is already veriﬁed in Theorem 2. This supposition permits using (3.14), which states

λ(x) := σ2a(x) − x

−1Xz=−∞

H +∞(−∞,0](z)(|z| ∧ |y|) ∼

1
2

λ(−y)

(y → −∞).

(5.11)

Let x∧|y| = o(√n ). By duality one may suppose that y = o(√n). Then the hypothesis

(5.6) says

|y|λ(√n ) = √n λ(−y) × o(1).

Theorem A implies

pn−k
{0}

(z, y) ≤

C(|z| ∧ √n )|y|

n3/2

(k ≤ εn, z ≤ −1),

whereas from Lemma 3.2 and (5.11) one deduces

hx(k, z)(|z| ∧ √n ) ≤ Mεx

λ(√n )
√n

.

Xk≥εnXz<0

(5.12)

(5.13)

Here (and below) Mε designates a constant that may depend on ε but not on the other
variables. Using (5.12) we therefore obtain

II ≤ Mε

x|y|
n3/2 ·

λ(√n )
√n

= oε(cid:18)λ(−y)x
n3/2 (cid:19)

(as n → ∞ under the constraints on x, y in the proposition).

Similarly, on using Theorem A again

I = X1≤k<εn X−√n/ε ≤z<0

hx(k, z) ·

σ4a(z)a(−y) + zy

σ2(n − k)

+ Xz<−√n/ε

H x

(−∞,0](z) × O(cid:18) y
n(cid:19).

gn−k(y)(1 + oε(1))

(5.14)

To ﬁnd an upper bound of the last sum we use the identity (3.15), which may be written
as

Xz<0

H x
(−∞,0](z)λ(z) = λ(x).

(5.15)

23

By Markov’s inequality this entails

Xz<−√n/ε

H x
(−∞,0](z) ≤

ε

√n Xz<−√n/ε

|z|H x

(−∞,0](z) ≤

ελ(x)
√n

.

(5.16)

For the evaluation of the double sum in (5.14) we may replace (n − k)−1
gn−k(y) by
gn(y)(1+O(ε)). Since y is supposed to go to −∞, we may also replace σ4a(z)a(−y)+
n−1
zy by λ(z)|y| and in view of (5.13) we may extend the range of the outer summation to
the whole half line k ≥ 1. Using (5.12), (5.14), (5.15) and (5.16) we then deduce that

I =

λ(x)|y|gn(y)

σ2n

[1 + O(ε) + oε(1)].

As for III observe that

pk
{0}

(z, y) = g(z, y) − rn(z, y)

(z, y) ≤ C(|z| ∧ √n )|y|/√εn, as deduced from Theorem

hx(k, z)rn(z, y) ≤ M′ε

x|y|
n3/2 ·

λ(√n )
√n

= oε(cid:18)xλ(−y)
n3/2 (cid:19).

εnXk=1
with 0 ≤ rn(z, y) :=Pk>εn pk

A; hence by (5.13) and (5.12)

{0}

Xk≥εnXz<0

Recalling y = o(√n) we apply (3.18) of Lemma 3.2 to ﬁnd that

III =

f +(x)gn(x)

σ2n Xz<0

H +∞(−∞,0](z)g(z, y)[1 + oε(1) + O(ε)],

hence by the identity (3.12)

III =

xλ(−y)gn(x)

σ2n

[1 + oε(1) + O(ε)].

Adding these contributions yields the desired formula, since ε can be made arbitrarily
small.
Remark 3. In view of (3.13) λ(x)/x is asymptotically decreasing (as x → ∞) in the
sense that λ(x)/x ∼ µ(x) with a decreasing µ, as is noted previously. Examining the
proof above one readily infers from this that

pn
{0}

(x, y) ≤ C

xλ(−y) + |y|λ(x)]

n3/2

(y < 0 < x)

(without assumption (5.6)), whereas pn

(x, y) may be of smaller order of the right side

for suitably chosen x, y with x∨|y| = o(√n ) if e.g. P [X < z] ∼ 1/z2(log |z|)2 (z → −∞).

{0}

24

6 Appendices

A. A consequence of duality.

In (3.9) we have brought in the Green function

g(x, y) = a(x) + a(−y) − a(x − y)

on the space Z \ {0}. By means of g the identity (2.2) may be written as

gA(x, y) = δx,ξ0 + a(x − ξ0) − a(x − y) + Ex[a(Sσ(A) − y)] − Ex[a(Sσ(A) − ξ0)]

= δx,ξ0 + g(x − ξ0, y − ξ0) − Ex[g(Sσ(A) − ξ0, y − ξ0)]

(6.1)

(for any ξ0 ∈ A) and observe that for all x, y with gA(x, y) > 0,

gA(x, y) = g(x, y) + O(1).

(6.2)

transition probability

We consider the dual (or time-reversed) walk, denoted by bSn, that is a random walk with
P [bSn = y |bS0 = x] = pn(x − y).
The objects associated with this walk are denoted by bPx,bEx,bp n
bp n

A, etc. Then for x, y /∈ A,
−A(−y,−x): the ﬁrst equality is veriﬁed by writing down the

A(x, y) = pn
A(x, y) and the second by the same way; indeed

A(y, x) = pn
deﬁnition of pn

A(y, x) = P [−S1 /∈ A, . . . ,−Sn /∈ A,−Sn = x| − S0 = y] = pn

−A(−y,−x).

bp n

Hence

for x, y /∈ A.

We write down the relation (6.1) for the dual walk: for x, y /∈ A and ξ0 ∈ A,

bgA(y, x) = gA(x, y) = g−A(−y,−x)
bgA(y, x) =bg(y − ξ0, x − ξ0) − bEy[bg(bSbσ(A) − ξ0, x − ξ0)].
Ex[g(Sσ(A) − ξ0, y − ξ0)] = bEy[g(x − ξ0,bSbσ(A) − ξ0)]

Comparing this with (6.1) and notingbg(y, x) = g(x, y) we have

= E−y[g(x − ξ0,−Sσ(−A) − ξ0)],

where the second equality is due to the identity bPy[bSbσ(A) = ξ] = P−y[Sσ(−A) = −ξ].

Hence

a(−y + ξ0) + Ex[a(Sσ(A) − ξ0) − a(Sσ(A) − y)]
= a(x − ξ0) + E−y[a(Sσ(−A) + ξ0) − a(Sσ(−A) + x)].

On passing to the limit as x → ±∞ and y → ±∞ there arise four identities. In the case
x → +∞ and y → −∞, this results in
Lemma 6.1. For any ξ0 ∈ A,

Xξ∈A

H +∞A (ξ)hσ2a(ξ − ξ0) − (ξ − ξ0)i =Xξ∈A

H +∞

−A (−ξ)hσ2a(ξ0 − ξ) − (ξ0 − ξ)i.

(6.3)

25

If A is symmetric with respect to some point, namely −A is a translation of A, this
lemma is trivial, but otherwise it seems quite non-trivial.
Since the left and right sides of (6.3) are the limits of g−
±A(x)−a(x) + x/σ2 as x → ∞,

this lemma is equivalent to the identity

−A(x)] = 0,
which in particular entails (1.13). Similarly limy→−∞[g+
B. Some estimates concerning a(x).

[g−A(x) − g−

lim
x→∞

A(y) − g+

−A(y)] = 0.

(6.4)

Let λ(x) be the function deﬁned by (5.10) andbλ(x) its dual:
λ(x) = σ2a(x) − x and bλ(x) = σ2a(−x) − x.

Here we collect several formulae satisﬁed by λ(x), all of which are almost immediate
consequences of the properties of a(x) presented at the beginning of Section 2 and the
fact that g(x, y) is the Green function on Z \ {0}. It is noted that

λ(x + y) − λ(y)

σ2

= a(x + y) − a(y) −

x
σ2

and

and

(i) For x > 0 and y ≥ 0,

bλ(x + y) −bλ(y)

σ2

= a(−x − y) − a(−y) −

x
σ2 .

− λ(x) × o(1) ≤ λ(x + y) − λ(y) ≤ λ(x)

(6.5)

(6.6)

where o(1) is bounded and, as x ∨ y → ∞, tends to zero.

−bλ(x) × o(1) ≤bλ(x + y) −bλ(y) ≤bλ(x),

The second inequality of (6.5) is the same as g(x,−y) ≥ 0. Using the identity (3.15)

as well as g(x,−y) =P H x

(−∞,0](z)g(z,−y) we observe

−λ(x + y) + λ(y) = g(x,−y) − [a(x) − x/σ2]

= X H x
= X H x
≤ X H x

(−∞,0](z)(cid:16)g(z,−y) − [a(z) − z/σ2](cid:17)
(−∞,0](z)[a(y) − a(y + z) + z/σ2]
(−∞,0](z)[a(−z) + z/σ2],

which shows the ﬁrst inequality of (6.5) in view of (3.15).

(ii) For x > 0 and y > max A,

gA(−x, y) ≤ g+(−x)(1 + o(1)),

(6.7)

where o(1) is bounded and, as y → ∞, tends to zero uniformly in x.

26

For simplicity suppose 0 ∈ A and let ξ0 = 0 in (2.3). Then for x > 0,

gA(−x, y) − g+

Since the expectation on the right side is bounded, and tends to zero as y → ∞ and since
g+
A(−x) > 0 (entailing g+
an application of (6.6) concludes the proof.

+ E−x[a(Sσ(A) − y) − a(−y) + Sσ(A)/σ2].

A (−x) = −[bλ(x + y) −bλ(y)]/σ2
A(−x) =bλ(x) + O(1)) unless gA(−x, y) vanish for y > max A,
−bλ(x) ≤bλ(y − x) −bλ(y) ≤bλ(x) × o(1),

(6.8)

(iii) For 0 < x ≤ y,

where o(1) is bounded and, as (y − x) ∨ x → ∞, tends to zero.

On putting y′ = y−x and writingbλ(y−x)−bλ(y) =bλ(y′)−bλ(y′+x), there follows from

(6.6) the formula (6.8) with the second inequality restricted to the case when y′∨x → ∞.
This entails that there exists M ≥ 1 such that (6.8) with o(1) replaced by 1 is true if
y − x ≥ M. If y − x < M,

a(x − y) − a(−y) +

x
σ2 ≤ a(x − y) − a(−y) + a(−x)

is bounded above since −a(−y) + a(−x) → −(y− x)/σ2 as x → ∞, showing the required
boundedness of o(1), for the diﬀerence a(−x)− x/σ2 is bounded away from 0 (for x > 0)
unless it is identically zero when (6.8) is trivial.

(iv) If |x| ≤ y,

This follows from (6.6) if x < 0 and from (6.8) if x ≥ 0.

|bλ(y − x) −bλ(y)| ≤ Cbλ(|x|).

(6.9)

References
[1] R. A. Doney, Local behaviour of ﬁrst passage probabilities, Probab. Theory Rel.

Fields, 152, (2012), 559-588.

[2] H. Kesten, F. Spitzer, Ratio limit theorems I, Journal d’Analyse Math. 11, (1963),

285-322.

[3] H. Kesten, Ratio limit theorems II, Journal d’Analyse Math. 11, (1963), 323-379.

[4] G. F. Lawler, V. Limic, Random walk: a modern introduction, Cambridge univ.

press, 2010.

[5] G. Hunt, Some theorems concerning Brownian motion, TAMS. s1, (1956), 294-319.

[6] F. Spitzer, Principles of Random Walk, Van Nostrand, Princeton, 1964.

[7] K. Uchiyama, The ﬁrst hitting time of a single point for random walks. Elect. J.

Probab. 16, (2011), 1160-2000.

[8] K. Uchiyama, One dimensional lattice random walks with absorption at a point/on

a half line. J. Math. Soc. Japan 63, (2011), 675–713.

[9] G. Woess, Random walks on inﬁnite graphs and groups, Cambridge tracts in math-

ematics 138, Cambridge Univ. Press, 2000.

27

