6
1
0
2

 
r
a

 

M
9
1

 
 
]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[
 
 

1
v
4
6
0
6
0

.

3
0
6
1
:
v
i
X
r
a

Adaptive heat engine

A.E. Allahverdyan1, S.G. Babajanyan1, N.H. Martirosyan1, A.V. Melkikh2

1Yerevan Physics Institute, Alikhanian Brothers Street 2, Yerevan 375036, Armenia and

2Ural Federal University, Mira Street 19, Yekaterinburg 620002, Russia

A major limitations for many heat engines is that their functioning demands on-line control,
and/or an external ﬁtting between environmental parameters (e.g. temperatures of thermal baths)
and internal parameters of the engine. We study a model for an adaptive heat engine, where—due to
feedback from the functional part—the engine’s structure adapts to given thermal baths. Hence no
on-line control and no external ﬁtting are needed. The engine can employ unknown resources; it can
also adapt to results of its own functioning that makes the bath temperatures closer. We determine
thermodynamic costs of adaptation and relate them to the prior information available about the
environment. We also discuss informational constraints on the structure-function interaction that
are necessary for adaptation.

Introduction. Heat-engines drove the Industrial Rev-
olution and their foundation, viz. thermodynamics, be-
came one of the most successful physical theories [1]. Its
extensions to stochastic [2, 3] and quantum domain [4]
led to new generations of heat engines [3–15]. As every-
one could observe, the work-extraction function of macro-
scopic heat-engines requires external on-line control, e.g.
the speciﬁc sequence of adiabatic and isothermal pro-
cesses for the Carnot cycle [1, 16]. Smaller engines may
not demand on-line control, i.e.
they are autonomous
[13, 14], but they do demand ﬁtting between internal
and environmental parameters [6–12], e.g. because for
ﬁxed environment (thermal baths) there are internal pa-
rameters, under which the machine acts as a heat-pump
or refrigerator performing tasks just opposite to that of
heat-engine. Such ﬁtted engines are susceptible to envi-
ronmental changes, e.g. when the bath temperatures get
closer due to the very engine functioning. Car engines
treat this problem by abandoning the partially depleted
fuel (i.e. the hot bath), and using fresh fuel.

Here we study a rudimentary model of autonomous,
adaptive heat engine. Adaptive means that the engine
can work for a suﬃciently general class of environments,
i.e. it does need neither on-line control, nor an externally
imposed ﬁtting between its internal parameters and the
bath temperatures. In particular, the engine can adapt
to the results of its own functioning.

The major biophysical heat engine, viz photosynthe-
sis—which operates between the hot Sun temperature
and the low-temperature Earth environment [17]—does
have adaptive features that allow its functioning under
decreased hot temperature (partial shadowing) or in-
creased cold temperature (hot whether) [18, 19]. Hence
adaptive engines can be useful for fueling devices em-
ploying unknown or scarce resources. They are already
employed in engineering for photovoltaic engines that can
operate under partial shadow [20].

Recently, several physical models concentrated on
adaptive sensors (learning and memorizing environmen-
tal changes), adaptive transport models etc [18, 21–27].
These studies clariﬁed thermodynamic costs of adapta-

tion scenarios [18, 23–27]. Other research lines related
adaptation with (poly)homeostasis [28] and models of ar-
tiﬁcial life [16, 29].

For analyzing the adaptation and its costs for heat en-
gines, we need a tractable and realistic model that is
much simpler than its prototypes in photovoltaics or pho-
tosynthesis. The model ought to consist of functional
and structural parts. For the former we choose one of
the most known models of quantum/stochastic thermo-
dynamics [6–10].

The functional degree of freedom of the model engine
has three states: i = 1, 2, 3 [6–10]. Its dynamics is de-
scribed by a Markov master equation [30]:

˙pi ≡ dpi/dt =Xj

[ρi←j pj − ρj←ipi],

i, j = 1, 2, 3, (1)

where pi is the probability of i, and ρi←j is the transition
rate from j to i. The stationary solution of (1) is

p1 =

p2 =

p3 =

1
Z
1
Z
1
Z

[ρ1←2ρ1←3 + ρ3←2ρ1←3 + ρ2←3ρ1←2],

[ρ2←1ρ2←3 + ρ3←1ρ2←3 + ρ2←1ρ1←3],

[ρ3←1ρ3←2 + ρ2←1ρ3←2 + ρ1←2ρ3←1],

(2)

(3)

(4)

where Z ensures p1 + p2 + p3 = 1. We assume that
each transition i ↔ j couples with the bath at inverse
temperatures βij = βji. The detailed balance reads [30]:

ρi←j e−βijEj = ρj←i e−βij Ei,

βij = βji,

(5)

where Ei is the energy of i. One of the baths has inﬁ-
nite temperature: β12 = 0. It is standardly associated
with a work-source, because due to dS12 = β12dQ12 = 0
it exchanges energy dQ12 6= 0 at zero entropy increase
dS12 = 0. Eﬀectively large temperatures arise natu-
rally in biomolecular systems due to the stored energy,
which—when recalculated in terms of temperature—is
some 20–50 times larger than the room temperature [31].
The model (1, 5) was introduced and studied in the
quantum setting [6–10], as a model for maser. Closely

related models were studied recently in the context of
photovoltaic engines [15].

regime reads from (1): P3

The average energy conservation in the stationary
k=1 ˙pkEk = J31 + J32 + J21 = 0,
where Ji>j is the energy current from the bath that drives
the transition i ↔ j:

We assume in (12) that x is slow: 1

γ , D ≪ ρi←j (x).
This limit is implemented by introducing in (13, 12) the
conditional probability pi|x(t) [43],

pi(x, t) = pi|x(t)p(x, t), Z dx p(x, t) = 1, Xi

pi|x(t) = 1,

Ji>j = (Ei − Ej)(ρi←j pj − ρj←ipi).

(6)

and collecting fast terms:

2

Ji>j is positive when the energy comes out from the bath.
Using (2–4) we get in the stationary state

J21 =

ˆE2
Z

ρ1←3 ρ3←2 ρ1←2h1 − e(β32−β31) ˆE3−β32 ˆE2i , (7)

J31 = − ˆE3J21/ ˆE2, J32 = ( ˆE3 − ˆE2)J21/ ˆE2,

ˆE2 ≡ E2 − E1,

ˆE3 ≡ E3 − E1.

(8)

(9)

The heat-engine functioning is deﬁned as [cf. (5, 6)]

0 > J21 = (E2 − E1)(p1 − p2)ρ1←2,

(10)

i.e. the energy goes to the work-source. Note that (10)
relates to population inversion between energy levels E1
and E2. Using (7) we write (10) as

ˆE2[(1 − ϑ) ˆE3 − ˆE2] > 0, ϑ ≡ β31/β32.

(11)

Eq. (11) demands diﬀerent temperatures: β32 6= β31. It
also demands tuning between the energies ˆE2, ˆE3 and
ϑ: it is impossible to hold (11) for a wide range of ϑ by
means of constant ˆE2 and ˆE3; e.g. if (11) holds for 1 > ϑ
ˆE2
due to ˆE3 > ˆE2 > 0, then it is violated for 1 − ϑ <
.
ˆE3
Tuning is necessary, since for suitable values of ˆE2 and
ˆE3, the machine can function also as a refrigerator (i.e.
J21 > 0 and J32 > 0 for β32 > β31) or as a heat-pump.

The structural degree of freedom x is continuous, since
it should ensure adaptation to continuous environmental
variations. x governs the behavior of interaction energies
Ei(x) between x and i. The joint probability pi(x, t) of x

and i,R dxPi pi(x, t) = 1, evolves via the Fokker-Planck
˙pi(x, t) = Xj

[ρi←j (x)pj (x, t) − ρj←i(x)pi(x, t)] (12)

plus master equations [cf. (1)] [30]:

+

∂x[pi(x, t)E′

i(x)] + D∂2

xpi(x, t),

(13)

1
γ

i(x) ≡ dEi(x)

where i, j = 1, 2, 3, E′
dx , γ > 0 is the damping
constant, and D > 0 is the diﬀusion constant. ρi←j(x)
is speciﬁed in (19); it holds (5) with Ei → Ei(x) and
Ej → Ej (x).

Eqs. (12, 13) is well-known in chemical and biological
applications [32–38]. The limit when Ei(x) = E(x) does
not depend on i refers to a dynamic disorder [32–35]. It
was applied to a variety of problems including the confor-
mational dynamics of enzymes and ion channels [32–35].
These systems also provide examples, where the depen-
dence of Ei(x) on i (feedback) is essential [35–38].

˙pi|x =Xj

[ρi←j (x)pj|x − ρj←i(x)pi|x].

(14)

Slow terms are found from (13, 14) by summing over i:

˙p(x, t) =

1
γ

∂x[p(x, t)Xi

pi|xE′

i(x)] + D∂2

xp(x, t). (15)

Since i is fast, pi|x in (15) can be taken as time-
independent, i.e. pi|x is found from (2–4) upon replac-
ing there ρij → ρij (x) [43]. The stationary probability
of x is found from (15) via the zero-current condition
p(x)

i(x) + D∂xp(x) = 0:

γ Pi pi|xE′
p(x) ∝ e−Ψ(x)/(γD), Ψ′(x) ≡X3

pi|xE′

i(x),

(16)

i=1

where Ψ(x) is an eﬀective potential of x, and Ψ′(x) = dΨ
dx .
Adaptation. Naturally, the energies Ei(x) do not de-
pend on β31 and β32. We choose Ei(x) such that two
conditions hold. First, Ψ(x) has a unique minimum ˆx:

Ψ′(ˆx) =X3

i=1

pi|ˆxE′

i(ˆx) = 0, Ψ′′(ˆx) > 0. (17)

ˆx is the unique maximally probable value of x; cf. (16).
Second, the heat-engine condition J21(x) < 0 holds in

a vicinity of the maximally probable value ˆx [cf. (11)]:

ˆE2(x)[(1 − ϑ) ˆE3(x) − ˆE2(x)] > 0, x ≃ ˆx,

(18)

where ˆEi(x) = Ei(x) − E1(x); cf.
(9). Eqs. (17, 18)
imply feedback adaptation: if β31 or β32 change, the sys-
tem is not anymore in a stationary state. It then goes
to new stationary state, where the heat-engine function
most probably holds.

Note that x is continuous, because we shall assume
that β31 and β23 change in continuous domains. Using
here a feed-forward (instead of feedback) control does
not lead to adaptation, because it inﬂuences only the
diﬀusion constant D; see sect. 1 of suppl. material.

To get a general method for studying (17, 18), we focus
on the following class of transition rates ρij [cf. (1, 5)]:

ρij(x) = f [ βij(Ej(x) − Ei(x)), βij ],

βij = βji, (19)

where f [y, β] holds (5). Eq. (19) implies that ρij(x)
and the stationary probabilities pi|x depend only on
ˆE3(x) and ˆE2(x); cf. (19, 9). This holds in the high-
temperature limit for any ρij ; see (5). Two other exam-
ples of (19) is the Kramers’ rate f [y, β] = eβδ+min(y,0),

0.0

-0.2

-0.4


x

'
1
E

,

x

'
F

-0.6

-0.8

-1.0

1

3

0.60


x

'
1
E

,

x

'
F

0.55

0.50

0.45

2
x

3

0.40

0

1

3

4

2
x

2

2

FIG. 1: Φ′(x) given by (20, 19) with f [y, β] = ey/2 for varying
β31 and ﬁxed β32 = 1 (ﬁrst type of varying environment).
We assume ˆE3(x) = −x, ˆE2(x) = x − 2, and (18) holds for
x > 2 if ϑ > 2, for
2−ϑ > x > 2 if 1 < ϑ < 2, and for
2−ϑ < x < 2 if ϑ < 1. Φ′(x) is shown for various ϑ = β31/β32
and those x that support (18): ϑ = 0.1 (red curve), ϑ =
0.25 (green), ϑ = 0.5 (blue), ϑ = 0.75 (brown), ϑ = 0.95
(black), ϑ = 1.2 (black-dashed), ϑ = 1.5 (brown-dashed),
ϑ = 2.5 (blue-dashed). The magenta curve shows −E ′
1(x),
1(x) = 1.8(x − 2) + 0.680289. Intersections of −E ′
where E ′
1(x)
with Φ′(x) determine ˆx. Eqs. (21) hold for all ϑ.


x

'
1
E

,

x

'
F

0.2

0.0

-0.2

-0.4

-0.6

-0.8

-1.0

1.0

1.5

2.0
x

2.5

3.0

FIG. 2: The same as in Fig. 1, but for β32 = 0.7. It is seen
that for ϑ close to 1, no heat-engine functioning exists ((18)
does not hold), i.e.
the magenta curve does not cross the
curves with ϑ = 0.95, ϑ = 1.2 and ϑ = 1.5.

where δ is the barrier height [30], and f [y, β] = ey/2 that
corresponds to the discrete-space Fokker-Planck equation

i=1 pi|x = 1 and deﬁne from (17, 19)

[34]. We use P3

Φ′(x) =X3

i=2

pi|x

ˆE′

i(x),

(20)

where the analogues of (17) read

1(ˆx),

Φ′(ˆx) = −E′

Φ′′(ˆx) > −E′′

1 (ˆx).

(21)
For given ˆE3(x) and ˆE2(x), Φ′(x) does not depend on
E1(x); see (2–4). Hence one can study Φ′(x) for given
ˆE3(x) and ˆE2(x) [cf. (18)] and for diﬀerent values of β31
and β32. Then one can deﬁne ˆx via (21) by choosing a
suitable E1(x) that does not depend on β31 and on β32.
Since (18) should hold for ϑ → 1, there exists x0 such
that ˆx → x0 for ϑ → 1, and ˆE2(x0) = 0. In the vicinity

4

FIG. 3: Adaptation for a negative friction γ < 0, β32 = 1
and varying β13. The same parameters as in Fig. 1, but now
ˆE3(x) = x/2. Conditions (18) amount to
1+ϑ > x > 2 if
1+ϑ < x < 2 if ϑ > 1. Φ′(x) is shown
ϑ < 1, and to
for: ϑ = 0.1 (red curve), ϑ = 0.25 (green), ϑ = 0.5 (blue),
ϑ = 0.75 (brown), ϑ = 0.95 (black), ϑ = 1.2 (black-dashed),
ϑ = 1.5 (brown-dashed), ϑ = 2.5 (blue-dashed), ϑ = 4 (green-
dashed), ϑ = 6 (red-dashed). The magenta curve shows
−E ′

1(x) = −0.1(x − 2) − 0.5. Eq. (23) holds.

1(x), where E ′

4

of x0, ˆE3(x) is either ﬁnite or goes to zero slower than
ˆE2(x), so that (18) still holds for ϑ → 1 and ˆx → x0.

Let us ﬁrst assume that one temperature (say β31)
takes arbitrary positive values, while another one (β32) is
ﬁxed. Adaptation is necessary here, since ϑ = β31/β32 is
an arbtrary positive number, hence (18) cannot be valid
for x-independent Ei. Now (17, 18) for adaptation can
be satisﬁed; see Fig. 1 for the simplest but representative
choice, where Ei(x) are parabolic functions of x. This
choice of Ei(x) is realistic [35–38].

Since the validity domain (18) of the heat-engine
shrinks to a point for ϑ → 1, we need progressively
smaller values of Dγ in (16) for ensuring the average
work-extraction

hJ21i ≡Z dx p(x) J21(x) < 0

(22)

for ϑ → 1. If the diﬀusion of x is caused by an equilibrium
bath, we get Dγ = T [30], and the temperature T of this
bath should be suﬃciently low for (22) to hold. If this is
the lowest temperature, there is a heat current towards
it tending to increase it. Hence this low temperature is
a thermodynamic resource. For a given Dγ, there is a
vicinity of ϑ = 1, where no work is extracted in average:
hJ21i > 0.

Consider now a general situation, where both β31 and
β32 vary. Fig. 2 shows that the set-up which worked for
a ﬁxed β32 does not apply here. Now condition Φ′(ˆx) =
1(ˆx) in (21) implies such a behavior for Φ′(ˆx) under
−E′
β31 ≈ β32 that the second condition Φ′′(ˆx) > −E′′
1 (ˆx) in
(21) cannot hold; e.g. because Φ′(ˆx) has the shape shown
in Figs. 3 and 4. This fact is shown in sect. 2 of suppl.
material. The only possibility to recover the adaptive
heat engine function is to assume that x is subject to

0.60

0.55


x

'
1
E

0.50

0.45

,

x

'
F

0.40

0

1

3

4

2
x

FIG. 4: The same as in Fig. 3, but for β32 = 3. Eqs. (23, 18)
hold.

an external force that adds to RHS of (15) a contribu-
tion making the eﬀective friction negative: γ < 0. Then
Dγ < 0 in (16), and the most probable ˆx means that
inequalities in (17) and (21) are reversed. Now the adap-
tation conditions are (18) and [instead of (21)]

Φ′(ˆx) = −E′

1(ˆx),

Φ′′(ˆx) < −E′′

1 (ˆx).

(23)

i.e.

These conditions can be satisﬁed, as illustrated in Figs. 3
and 4. Now x should change in a bounded domain; oth-
erwise for the natural shape of energies (Ei(x) → ∞ for
x → ±∞) one gets a non-normalizable p(x) in (16).
Note that for γ < 0 and D > 0, (15) does predict
relaxation to (16),
the negative-friction situation
is stable. The external force that simulates the nega-
tive friction does dissipate energy with a constant rate
Π = 1
rial. We still demand a suﬃciently small |γ|D to ensure
hJ21i < 0. For a small |γ|D we get Π ≃ |Ψ′′(ˆx)|D. This
energy dissipation is another cost for adaptation; see [23–
27] for related results. A negative friction is known in sev-
eral classes of active (non-equilibrium) systems [39–42].
Two examples relevant to our situation is the negative
resistance of electric circuits [40] and negative viscosity
of driven ﬂuids [41].

|γ|R dx p(x)[Ψ′(x)]2; see sect. 3 of suppl. mate-

R dx p(x)Q3

Above examples of adaptation are obtained for Ei
being correlated random variables, P (E1, E2, E3) =
k=1 δ(Ek − Ek(x)), and for speciﬁc forms of
Ei(x). To see why such assumptions are necessary, take
an extreme case, where the probability density of en-
ergies Π(E1, E2, E3) is non-informative in terms of the
Bayesian statistics [11, 44]. Since we do not have prior
expectations about correlations between random vari-
ables E1, E2 and E3, they are taken as independent
k=1 Π(Ek) [44]. Also, since E1 can
assume either sign, the non-informative density Π(Ek) is
the homogeneous one: Π(Ek) = const [44]. Employing
this density we calculate from (11) that the probability of
the heat-engine functioning is low 1−min(ϑ, 1
ϑ )
3 . Hence
the current J21 averaged over Π(E1, E2, E3) is positive,
i.e. the machine does not function as a heat-engine; cf.

Π(E1, E2, E3) = Q3

< 1

3

4

(7). Thus the coupling between structure and function,
which is encoded in P (E1, E2, E3) must be informative.
In sum, we studied a model for an adaptive heat engine
that can function under scarce or unknown resources.
Several physical limitations for the adaptation concept
were uncovered; they relate to the prior information
available about the environment. One problem generated
by this research is that in the model the resources needed
for adaptation are detached from the work extracted by
the engine. Employing the extracted work for ensuring
the adaptation will make the situation more interesting.
This work is partially supported by COST MP1209

and by the ICTP through the OEA-AC-100.

[1] H.B. Callen, Thermodynamics and an introduction to

thermostatistics (John Wiley & Sons, NY, 1985).

[2] K. Sekimoto, Stochastic Energetics (Springer-Verlag,

Berlin 2010).

[3] U. Seifert, Rep. Prog. Phys. 75, 126001 (2012).
[4] G. Mahler, Quantum Thermodynamic Processes (Pan

Stanford, Singapore, 2015).

[5] D. Chowdhury, Am. J. Phys. 77, 583 (2009).
[6] H.E.D. Scovil and E.O. Schultz-DuBois, Phys. Rev. Lett.,

2, 262 (1959).
J.E. Geusic et al., Phys. Rev., 156, 343 (1967).

[7] V.K. Konyukhov and A.M. Prokhorov, Uspekhi Fiz.

Nauk, 119, 541 (1976).

[8] E. Geva and R. Kosloﬀ, Phys. Rev. E 49, 3903 (1994).
[9] E. Boukoza and D. Tannor, Phys. Rev. Lett., 98, 240601

(2007).

[10] R. Uzdin, A. Levy, and R. Kosloﬀ, Phys. Rev. X 5,

031044 (2015).

[11] G. Thomas and R.S. Johal, Phys. Rev. E 85, 041146

(2012).

[12] A. E. Allahverdyan, K. V. Hovhannisyan, A. V. Melkikh,
and S. G. Gevorkian, Phys. Rev. Lett. 109, 248903
(2013).

[13] N.

Linden,

S. Popescu,

and P Skrzypczyk,

arxiv.1010.6029.

[14] A.S.L. Malabarba, A.J. Short, and P. Kammerlander,

New J. Phys. 17, 045027 (2015).
M.F. Frenzel, D. Jennings, and T. Rudolph, New J. Phys.
18, 023037 (2016).

[15] M.O. Scully, Phys. Rev. Lett. 104, 207701 (2010). M.O.

Scully et al., PNAS, 108, 15097 (2011).

[16] S. Kauﬀman, Phil. Trans. R. Soc. A 361, 1089 (2003).
[17] E. Albarran-Zavala and F. Angulo-Brown, Entropy, 9,

152 (2007).

[18] I. Rojdestvenski, M. G. Cottam, G. Oquist, and N.

Huner, Physica A 320, 318 (2003).

[19] S. Falk et al., Photosynthetic adjustment to temperature,
in Photosynthesis and the environment, pp. 367-385, ed.
by N.R. Baker (Springer, Netherlands, 1996).

[20] D. La Manna et al., Renewable and Sustainable Energy

Reviews, 33, 412 (2014).

[21] T. Friedlander and N. Brenner, PNAS, 106, 22558

(2009).

[22] M. Inoue and K. Kaneko, Phys. Rev. E 81, 026203

(2010).

[23] G. Lan, P. Sartori, S. Neumann, V. Sourjik, Y. Tu, Na-

ture Phys. 8. 422 (2012).

[24] A. E. Allahverdyan and Q.A. Wang, Phys. Rev. E 87,

032139 (2013).

[25] A. C. Barato, D. Hartich, and U. Seifert, Phys. Rev. E

87, 042104 (2013). New J. Phys. 16, 103024 (2014).

[26] S. Bo, M. Del Giudice, and A. Celani, JSTAT, P01014

(2015).

[27] P. Sartori and Y. Tu, Phys. Rev. Lett. 115, 118102

(2015).

[28] D. Markovic and C. Gros, Phys. Rev. Let. 105, 068702

(2010).

[29] S. McGregor and N. Virgo, in Advances in Artiﬁcial Life:
Darwin Meets von Neumann, pp. 230-237 (Springer,
Berlin, 2009).

[30] N.G. van Kampen, Stochastic Processes in Physics and

Chemistry (Elsevier, Amsterdam, 2007).

[31] C.W.F. McClare, J. Theor. Biol. 35, 233 (1972).

E.T. Jaynes, The muscle as an engine
http://bayes.wustl.edu/etj/articles/muscle.pdf

(1983),

[32] R. Zwanzig, Acc. Chem. Res. 23, 148 (1990).
[33] H. Frauenfelder, P.G. Wolynes, and R.H. Austin, Rev.

Mod. Phys. 71, S419 (1999).

[34] N. Agmon and J.J. Hopﬁeld, J. Chem. Phys. 78, 6947

(1983).

[35] M. Kurzynski, The thermodynamic machinery of life,

(Springer-Verlag, Berlin 2010).

[36] L.A. Blumenfeld and A.N. Tikhonov, Biophysical Ther-
modynamics of Intracellular Processes (Springer, Berlin,
1994).

[37] H.-P. Lerch et al., PNAS, 99, 15410 (2002). A.O.
Gouschcha et al., Biophys. J., 79, 1237 (2000). Z.D.
Nagel and J.P. Klinman, Nat. Chem. Biol. 5, 543 (2009).
K.V. Shaitan and A.B. Rubin, Biophysics, 30, 517
(1984). K.V. Shaitan, Biophysics, 39, 993 (1994)

[38] L.N. Christophorov, A.R. Holzwarth, V.N. Kharkyanen,

and F. van Mourik, Chemical Physics 256, 45 (2000)

[39] Yu. I. Samoilenko, Autom. Remote Control, 39, 632
(1978);
ibid. 1745 (1979). A.G. Butkovskii and Yu.I.
Samoilenko, Control of Quantum Mechanical Processes
(Springer, Berlin, 1991).

[40] See https://en.wikipedia.org/wiki/Negative resistance
[41] V.P. Starr, Physics of negative viscosity phenomena

(McGraw-Hill, 1968).

[42] B. Cleuren and C. Van den Broeck, Phys. Rev. E. 65,
030101(R) (2002). A. Haljas, R. Mankin, A. Sauga, E.
Reiter, Phys. Rev. E. 70, 041107. (2004). J. Spiechowicz,
J. Luczka, P. Hanggi, JSTAT P02044 (2013).

[43] A.E. Allahverdyan and Th.M. Nieuwenhuizen, Phys.

Rev. E, 62, 845 (2000).

[44] E.T. Jaynes, IEEE Trans. Syst. Science & Cyb. 4, 227

(1968).

SUPPLEMENTARY MATERIAL

1. Feed-forward control

Feed-forward amounts to no direct interaction between
the functional degree of freedom i and the structural de-
gree of freedom x. But now x couples directly to the
baths at temperatures T31 = 1/β31 and T32 = 1/β32, i.e.

5

we try to implement temperature sensors via x. This
means taking in (13) of the main text Ei(x) = E(x) and
adding there the following term

Xα=31,32

γ−1
α [∂x[pi(x, t)E′(x)] + Tα∂2pi(x, t)].

(24)

Instead of (16) [of the main text] we get for the stationary
probability

¯p(x) ∝ e−E(x)/ eD,

eD =

D +Pα=31,32 γ−1
γ−1 +Pα=31,32 γ−1

α Tα

α

, (25)

where E(x) does not depend on β31 and β32. Hence no
adaptation is possible.

2. Derivation of the no-adaptation condition

If both β31 and β32 can vary, the adaptation condi-
tion Φ′(ˆx) = −E′
1(ˆx) [see (21) of the main text] should
In particular, this means
hold for all β31 and β32.
that—since E′
1(x) does not depend on β31 and β32—
Φ′(x0) |β31=β32=β should not depend on β31 = β32 = β,
where ˆE2(ˆx = x0) = 0. Now (2–4) of the main text show
that pi|x0 are at equilibrium for β31 = β32 = β and

p1|x0 = p2|x0 =

1
Z

,

p3|x0 =

e−β ˆE3

Z

.

(26)

Hence we get

Φ′(x0) |β32=β31=β =

ˆE′

2(x0) + ˆE′

3(x0)e−β ˆE3(x0)

2 + e−β ˆE3(x0)

This expression is not a function of β only for

ˆE′

2(x0) = 2 ˆE′

3(x0),

where

Φ′(x0) |β31=β32=β = ˆE′

3(x0).

Using (28) we ﬁnd Φ′(x) for x ≈ x0:

.

(27)

(28)

(29)

Φ′(x) = Φ′′(x0)(x − x0) + ˆE′
= Φ′′(x0)(x − x0) + ˆE′

2(x0)p2|x0 + ˆE′

3(x0)p3|x0
3(x0)[p2|x0 − p1|x0].

3(x0) + ˆE′

We shall focus on the last term in (30) that determines
the shape of Φ′(x) as a function of β31 and β32. This
term is expanded for β31 ≈ β, β32 ≈ β:

(30)

b ≡ ˆE′

3(x0)[p2|x0 − p1|x0]

(βα − β)∂βα [p2|x0 − p1|x0].

(31)

= ˆE′

3(x0)Xα=31,32

To work out (31) via (2–4) of the main text, we shall
assume for the transition rates ρi←j :

ρij(x) = fij[ βij(Ej (x) − Ei(x)), βij ],

βij = βji, (32)

where fij[y, β] holds the detailed balance conditions; see
(5) of the main text. Eq. (32) is more general than its
analogue (19) in the main text. Combining (31) with
(32) and with (2–4) of the main text, we get

p2|x0 − p1|x0 =

1

Z(x0)

[f32(β32 ˆE3(x0))f31(−β31 ˆE3(x0))−

f31(β31 ˆE3(x0))f32(−β32 ˆE3(x0)) ],

(33)

b =

ˆE3(x0) ˆE′

3(x0)

Z(x0) Xα=31,32

(β − βα)ψα[β ˆE3(x0)],

where we denoted f ′

ij[y, β] ≡ ∂yfij[y, β],

(34)

(35)

ψ31[x] ≡ f ′
ψ32[x] ≡ −f ′

31[x, β]f32[−x, β] + f ′

31[−x, β]f32[x, β],

32[−x, β]f31[x, β] − f ′

32[x, β]f31[−x, β].

Now note the following inequality

f ′
ij[y, β] = ∂yfij[y, β] ≥ 0.

(36)

It means that the transition from a lower energy to a
higher energy is facilitated, if the lower energy increases
or the higher energy decreases. This inequality does
follow from the detailed balance [see (5) of the main
text], but it still holds for all physical examples we are
aware of. The inequality implies ψ31[β ˆE3(x0)] ≥ 0 and
ψ32[β ˆE3(x0)] ≤ 0. Choosing β in between of β31 and β32
we see that

sign[b] = sign[ ˆE3(x0) ˆE′

2(x0)(1 − ϑ)]

(37)

Working out the heat-engine condition [see (18) of the
main text] in the considered order O(|1 − ϑ|) and O(|x −
x0|) we obtain

ˆE3(x0)(1 − ϑ). ˆE′
ˆE3(x0)(1 − ϑ). ˆE′

2(x0) > x − x0 > 0,

2(x0) < x − x0 < 0.

or (38)

(39)

Conditions (37–39) imply that depending on the sign of
Φ′′(x0) in (30), Φ′(x) can assume in the vicinity of x0
only two possible shapes; one of them is shown in Figs.
3 and 4 of the main text. Obviously, neither of them is
compatible with Φ′′(ˆx) > −E′′
1 (ˆx); see (21) of the main
text.

6

3. Energy dissipation due to external force that

generates negative friction

Consider (15, 16) of the main text that we generalize

as follows:

˙p(x, t) =

1
γ

∂x[p(x, t)Ψ′(x)] +

+∂x[p(x, t)G′(x)],

T
γ

∂2
xp(x, t)

(40)

(41)

where we assume that x couples with a thermal bath at
temperature T ,

γ > 0,

(42)

is the friction constant, and G′(x) = d
nal force. If now we set

dx G(x) is an exter-

G(x) = −

2
γ

Ψ(x),

(43)

the resulting inﬂuence of G(x) and Ψ(x) is equivalent to
a negative friction.

The average energy Π dissipated per unit of time due to
the external force G′(x) can be estimated via the change
of the free energy

F =Z dx p(x, t)[Ψ(x) + T ln p(x, t)],

(44)

of x due to the external part (41) of the dynamics

Π =Z dx ∂x[p(x, t)G′(x)] [Ψ(x) + T ln p(x, t)].

(45)

In the stationary state:

Π = −Z dx p(x)G′(x) [Ψ′(x) + T
= γZ dx p(x)[G′(x)]2,

d
dx

ln p(x)]

(46)

(47)

where p(x) ∝ exp[−(Ψ(x) + γG(x))/T ]. Using (43) we
ﬁnally obtain:

Π =

1

γ Z dx p(x)[Ψ′(x)]2.

(48)

