IEEE TRANSACTIONS ON

1

Regression-based Hypergraph Learning for Image

Clustering and Classiﬁcation

Sheng Huang Student Member, IEEE, Dan Yang, Bo Liu, Xiaohong Zhang

6
1
0
2

 
r
a

 

M
4
1

 
 
]

V
C
.
s
c
[
 
 

1
v
0
5
1
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Inspired by the recently remarkable successes of
Sparse Representation (SR), Collaborative Representation (CR)
and sparse graph, we present a novel hypergraph model named
Regression-based Hypergraph (RH) which utilizes the regression
models to construct the high quality hypergraphs. Moreover,
we plug RH into two conventional hypergraph learning frame-
works, namely hypergraph spectral clustering and hypergraph
transduction, to present Regression-based Hypergraph Spectral
Clustering (RHSC) and Regression-based Hypergraph Trans-
duction (RHT) models for addressing the image clustering and
classiﬁcation issues. Sparse Representation and Collaborative
Representation are employed to instantiate two RH instances
and their RHSC and RHT algorithms. The experimental results
on six popular image databases demonstrate that the proposed
RH learning algorithms achieve promising image clustering and
classiﬁcation performances, and also validate that RH can inherit
the desirable properties from both hypergraph models and
regression models.

Index Terms—Graph Embedding, Dimensionality Reduction,
Sparse Learning, Subspace Learning, Collaborative Representa-
tion

I. INTRODUCTION

As the generalization of the graph model [1], [2],

the
hypergraph model is more ﬂexible and more intuitive to depict
the complex relation of data, since the edge of hypergraph,
which is known as the hyperedge, can contain more than two
vertices. Due to this desirable property, hypergraph learning
is recently drawn intensive attention. Over past decades,
extensive hypergraph learning approaches has been proposed
and successfully applied to tackle a lot of fundamental tasks,
such as clustering [1], [3], classiﬁcation [4], [5], [6], segmen-
tation [7], dimensionality reduction [8], [9] and multi-label
learning [10], [11].

As same as graph learning, the hypergraph construction
process plays a vital role in hypergraph learning and a
good quality hypergraph should well reveal the real relation
of samples. Hypergraph learning is a frequently used tool
for unsupervised and semi-supervised learning. In these two
cases, the previous hypergraph learning works often adopt
the neighbourhood-based (distance-based) strategy to build the
hypergraph [1], [12], [13]. More speciﬁcally, for each sample,
a hyperedge is generated by connecting this centroid sample
and its k nearest neighbors. However, as such neighborhood-
based often cannot well even correctly discover the real

Sheng Huang, Dan Yang and Xiaohong Zhang are with the School of
Software Engineering, Chongqing University, Chongqing, 40004 PRC Email:
{huangsheng, dyang, xhongz}@cqu.edu.cn

Bo Liu is with the Department of Computer Science, Rutgers University,

Piscataway, NJ, 08854 USA Email: lb507@rutgers.edu

relations of samples and it is also very sensitive to noises,
the quality of hypergraph is lowered which directly degrades
the performance of hypergraph learning.

In the recent decade, Sparse Representation (SR) has
achieved remarkable successes for addressing dozens of com-
puter vision and machine learning issues [14], [15], [16].
The main merits of SR are the strong discriminating power
and the excellent robustness to noises which endow SR
with a better related sample selection capacity for a given
sample in comparison with the conventional neighborhood-
based approaches (We refer to an toy example in our early
work [17] to experimentally verify this argument, please see
Fig 1). In other words, SR can better discover the real
relations of data. Motivated by this fact, several novel graph
learning approaches have been developed via leveraging SR
to construct the graphs [18], [17], [19], [20], [21]. Compared
to the traditional graph learning approaches, these works have
achieved better performances. Since the hypergraph model is
the generalization of the graph model and hypergraph learning
is closely related to graph learning, we believe that the success
of SR in graph learning should also be applied to hyper-
graph learning. Moreover, SR is essentially a L1 or L0-norm
regularized regression model and its success also motivates
the presentations of many inﬂuential regression models which
often enjoy some desirable properties [14], [15], [22], [23],
[24], [25]. Cleary, these successful works can also provide
some new ways for graph or hypergraph construction.

to construct

In this paper, we generalize the idea of sparse graph to
present a novel hypergraph construction framework, which
can leverage the regression model
the high
quality hypergraph. We name such framework Regression-
based Hypergraph (RH) model. More speciﬁcally, in RH, each
sample represents a vertex and constructs a regression system
together with the rest samples for measuring correlations
of samples. Then, based on the obtained correlations, each
sample and its top m most relevant samples are employed to
deﬁne a hyperedge. Moreover, the mean of the correlations
among samples in a hyperedge is considered as the weight of
this hyperedge, since the correlation is an intuitive measure
of the closeness between two samples. We also plug the
regression-based hypergraph into two classical hypergraph
learning frameworks, namely hypergraph spectral clustering
and hypergraph transduction, to present Regression-based Hy-
pergraph Spectral Clustering (RHSC) and Regression-based
Hypergraph Transduction (RHT) models for addressing the
clustering and classiﬁcation issues. As two of the most inﬂu-
ential regression models for visual learning, Sparse Represen-
tation (SR) and Collaborative Representation (CR) are adopted

IEEE TRANSACTIONS ON

2

(a) Raw Samples and their rank scores

(b) Samples with noise and their rank scores

Fig. 1. This ﬁgure was originally shown in our early work [17]. We use it here for intuitively specifying the advantages of SR over the conventional
neighbourhood-based method in the relevant sample selection procedure. The ﬁgure shows the top 10 most relevant face images selected by SR and K-Nearest
Neighbour (KNN) based on a given query face image. This experiment is conducted in a subset of FERET database [26] (72 subjects with 6 images in each
subject). The ﬁrst two rows of the ﬁgure are the selection results of SR while the last two rows are the selection results of KNN. The left subﬁgure
reports the results on the original FERET database while the right one reports the results on the modiﬁed FERET database in which 30% of pixels of each
image has been corrupted by noise. In the ﬁgure, the ﬁrst face image of each image array is the query image and the rest ten images are the relevant face
images selected by SR or KNN. The histograms above the image array demonstrates the conﬁdence scores of these top ten relevant face images. If the subjects
of the return face image and the query face image are identical, its corresponding histogram is positive otherwise it is negative. In the ﬁgure, SR gets ﬁve hits
either on the original FERET database or on the noisy FERET database while KNN only gets three and two hits on these two datasets respectively. Clearly,
this phenomenon demonstrates the advantages of SR in relevant sample selection.

as two examples to instantiate two RH instances. Since SR
and CR are actually the L1-norm and L2-norm regularized re-
gression models, we name these two instances L1-Hypergraph
(L1H) and L2-Hypergraph (L2H) respectively. Similarly, their
hypergraph spectral clustering and hypergraph transduction
algorithms are named as Ln-Hypergraph Spectral Clustering
(LnHSC) and Ln-Hypergraph Transduction (LnHT) where
n = 1 or 2 if L1H or L2H is applied.

Regression-based Hypergraph (RH) model inherits the ad-
vantages of both hypergraph and regression models. Compared
to the conventional hypergraph models, RH can incorporate
some properties from the chosen regression models. For
example, if the Sparse Representation (SR) or Collaborative
Representation (CR) is selected for hypergraph construction,
the constructed RH should be more discriminative and robust,
since these two regression models are better to discover the rel-
evances among samples over the conventional neighborhood-
based hypergraph construction fashions. Compared to the
regression approaches, RH constructs a hypergraph to sufﬁ-
ciently exploit the correlation of each pair of samples instead
of just utilizing the correlations between the target sample and
the other samples as the regression approaches do. Compared
to the regression-based graph approaches, such as the sparse
graph, RH is a hypergraph model which owns a better ca-
pability and ﬂexibility to depict the complex high-order data
relations.

We employ six popular visual databases to validate our
works. The experimental results demonstrate the superiority of
the RH model over the conventional hypergraph models. We
conclude three main contributions of our works as follows:

1) We provide a general idea which utilizes the regression
models to construct the high quality hypergraphs. To

the best of our knowledge, this paper is the ﬁrst to
formally and systematically build a bridge between the
hypergraph model and the regression model.

2) We present two novel hypergraph learning frameworks
based on the RH model to tackle the clustering and
classiﬁcation tasks respectively.

3) We adopt two recently inﬂuential regression models,
namely Sparse Representation (SR) and Collaborative
Representation (SR), to instantiate two RH instances
called L1-Hypergraph (L1H) and L2-Hypergraph (L2H)
which are experimentally proved to be more discrimina-
tive and robust than the conventional hypergraphs.

The rest of paper is organized as follows: the previous
works are reviewed in Section II. Section III introduces the
methodology of our works; experiments are presented in
section IV; the conclusion is ﬁnally summarized in section V.

II. PREVIOUS WORKS

A. Regression Models

Regression model is a common technique for data analysis
and has been successfully applied to almost all the areas in
computer vision, machine learning and image processing [27],
[14], [22]. Sparse Representation (SR) may be the most inﬂu-
ential regression approach in the recent decade. SR is mainly
inspired by the idea of compressed sensing [28]. In SR, a L0
or L1-norm constraint is introduced to the common regression
model for compulsively selecting only a few of relevant mea-
surements and ignoring the irrelevant ones by assigning their
corresponding regression coefﬁcients to zero. This endows SR
with a strong discriminating power and a good robustness.
However, Zhang et al. [22], [24] argued that the collaboration
of samples instead of the sparsity is the essential factor

IEEE TRANSACTIONS ON

3

that leads to such good discriminating ability and robustness.
They proposed a linear regression model named Collaborative
Representation (CR) via employing a relatively mild L2-norm
constraint to replace the L1-norm constraint to achieve the
collaboration property. Many works have shown that CR is
more efﬁcient and can get a similar or even better performance.
Due to the desirable properties of SR and CR, they have
achieved remarkable successes in many areas and promotes
the presentations of many impressive regression approaches
for addressing different computer vision, machine learning and
image processing issues. For examples, Gao et al. kernelized
SR for face recognition and image classiﬁcation [15]. Yuan
et al. presented a multitask joint sparse representation model
to combine the strength of multiple features and/or instances
for visual classiﬁcation [29]. Huang et al. presented a SR-
based classiﬁer named Class Speciﬁc Sparse Representation
(CSSR) which incorporated the properties of both SR and
CR [25] via deﬁning the homogenous samples as a group
and making them competition for representing the test sample.
Yang et al. proposed Relaxed Collaborative Representation
(RCR) to effectively exploit the similarity and distinctiveness
of samples [23]. Although these regression approaches have
obtained promising performances in different ﬁelds, they all
have an obvious drawback that they can only utilize the cor-
relation between the testing sample and the training samples.
On the contrary, the proposed Regression-based Hypergraph
(RH) model can sufﬁciently exploit the correlations among all
samples. Another merit of RH is that there exists extensive
regression approaches which can bring more ﬂexility to the
hypergraph model.

B. Sparse Graph

Since Sparse Representation (SR) is good at selecting the
relevant samples for a test sample even in the noisy conditions,
some researchers have attempted to use SR to construct high
quality graphs for addressing different issues. In these works,
such constructed graphs are often called L1-graph or sparse
graph and have achieved very promising performances. More
speciﬁcally, Qiao et al. and Timofte et al. successively use SR
to construct a sparse graph for dimensionality reduction [19],
[20]. Huang et al. leverage SR to measure the correlations
between each two samples and then construct a sparse graph
for transduction [30]. The Sparse Subspace Clustering (SSC)
algorithms [21], [31], [32] learn a sparse graph for clustering
via considering the data self representation problem as a
SR issue. Similar to [19], [20], Cheng et al. utilize SR to
construct the L1-graph (sparse-graph) for spectral clustering,
subspace learning and semi-supervised learning [33]. Although
the applications and the learning (or construction) procedures
of these works are very different, the obtained sparse graphs
are very similar which all demonstrate the better discrimi-
native abilities and robustness over the conventional graph
models. The main drawback of the sparse graph models is that
they cannot intuitively describe the high-order complex data
relations, because these sparse graph models are essentially
graph model whose edges can only depict the simple pairwise
data relation. Since Regression-based Hypergraph (RH) model

is deemed as a generalization of sparse graph from the
perspectives of both regression and hypergraph, it does not
suffer from this issue.

C. Hypergraph Models

As a generalization of graph, hypergraph represents the
structure of data via measuring the similarity between groups
of points [13], [12], [4], [34], [1], [35]. The main difference
between graph and hypergraph is that the edge of hypergraph
can own more than two vertices which endows hypergraph
with a high ﬂexility for depicting the high-order relation.
Beneﬁtted by this desirable property, hypergraph models have
been successfully applied into dozens of computer vision,
machine learning and pattern recognition areas. In the past,
the researchers were more keen to develop different hyper-
graph frameworks which deﬁne different theories to depict the
hypergraph structure. The representative approaches include
Clique Expansion [2], Star Expansion [2], Zhou’s Normalized
Laplacian [1], Clique Averaging [36], Bolla’s Laplacian [37]
and so on. However, as was shown in [38], all of the previous
approaches, despite their very different formulations, can be
proved to be equivalent to each other under speciﬁc conditions.
Currently, the researchers pay more attention on developing
the algorithms for the hypergraph constructions under the
aforementioned hypergraph frameworks. In hypergraph, hy-
peredge deﬁnes the relation of data. Therefore, the hyperedge
generation is very crucial to the quality of the constructed
hypergraph. Conventionally, most of hypergraph models adopt
the neighbourhood-based fashion to generate the hyperedges.
For examples, Huang et al. proposed a hypergraph learning
framework for image retrieval, in which each image and its
k-nearest neighbors form the hyperedge [12]. Zhou et al. also
adopted such neighbourhood-based fashion to generate the
hyperedges for unsupervised and semi-supervised hypergraph
learning [1]. The main problems of these approaches are that
they often cannot well reveal the real relation of data and
are sensitive to noise. Some researchers also employed the
clustering techniques to generate the hyperedges and then
construct the hypergraph. As the representative approach of
such category, Gao et al. proposed a hypergraph-based 3-D
object retrieval approach via utilizing the k-means to cluster
the views of the 3-D objects and consider each cluster as
a hyperedge [13]. Since the hyperedges, which are formed
by the clusters, cannot share intersection vertices, these hy-
pergraphs cannot capture the correlations of data. Another
popular method is to adaptively contruct the hypergraph via
imposing some meaningful constraints. As an instance of this
category, Yu et al. introduced a L2-norm constraint to the
hyperedge weight matrix to present a hypergraph transduction
approach for image classiﬁcation [4]. This method generates
the hyperedges via adaptively assigning the weights to the
hyperedges. However, it cannot guarantee the inexistence of
the isolated vertices. Similar to the work [4], Wang et al. im-
posed a Laplacian cost constraint and a L1-norm constraint to
the hyperedge weights for adaptively learning the hyperedge
weights in a hypergraph model [5]. In its hyperedge gener-
ation procedure, the traditional neighbourhood-based fashion

IEEE TRANSACTIONS ON

4

is employed to deﬁne a candidate hyperedge vertex set and
then SR is applied to prune noisy vertices in this set for
forming the ﬁnal hyperedge. Such idea is similar but also
different to us. It still considers the neighbours of a sample
as its relevant samples and SR here only plays a role as a
noise remover. On the contrary, Regression-based Hypergraph
(RH) model thoroughly utilizes the regression model (includes
SR) to generate the hyperedged. And RH is more formal
and systematic to introduce how to use regression models to
construct the high quality hypergraph.

III. METHODOLOGY

A. Regression-based Hypergraph

In order to incorporate some desirable properties of the
regression algorithms, we introduce a new hypergraph learning
framework named Regression-based Hypergraph (RH), which
leverages different regression models to construct the hyper-
graphs. Let a d × n-dimensional matrix X = [x1, x2,··· , xn]
be the sample matrix, where d is the dimension of sample
and n is the number of sample. The d-dimensional column
vector xi is a sample which is also the i-th column of sample
matrix. We apply the general formulation of regression model
to estimate the correlations between each sample and the rest
samples,

ˆCi = arg min
Ci

∆(xi, Xt(cid:54)=iCi) + βΦ(Ci)

(1)
where ∆(·) and Φ(·) are the regression error and the regu-
larization term respectively. Xt(cid:54)=i is the sample matrix which
excludes the i-th sample xi. The (n − 1)-dimensional column
vector Ci = [ci1,··· , ci(i−1), ci(i+1),··· , cin]T is the regres-
sion coefﬁcient vector with respect to the sample xi. Each
element of regression coefﬁcient vector encodes the correlation
between the target sample and the sample. According to the
aforementioned correlation computation fashion, each pair of
samples can get two correlations, i.e., the samples xi and xj
has two correlations cij and cji. Extensive literatures [18],
[19], [39], [30], [40] show that such correlation between
two samples is a high quality similarity measure of samples.
Therefore, following the sample similarity computation fash-
ion in [18], [19], we deﬁne the sample similarity as the mean
of the correlation absolute values of each pair of samples to
guarantee the nonnegativity and symmetry of the similarity.
More speciﬁcally, the similarity between the sample xi and
the sample xj can be mathematically denoted as follows

sij = sji =

.

(2)

|cij| + |cji|

2

this sample and the rest samples, sii =(cid:80)

The regression model cannot compute the self-correlations of
samples. In other words, the self-similarity computation of a
sample is still not provided. In such case, we deﬁne the self-
similarity of a sample as the sum of the similarities between
t(cid:54)=i sit. According to
the obtained similarities among all the samples, it is not hard
to construct a similarity matrix (or afﬁnity matrix) S where
sij is the ij-th element of S. Then, the normalization of the
sample similarities can be done as follows

√

√

S =

M S

M

(3)

t sit.

where n× n-dimensional matrix M is diagonal matrix whose
i-th diagonal element is the sum of elements in the i-th row

of S, mii =(cid:80)

After obtaining the similarities, we deﬁne a hypergraph
G(V, E) for depicting the relations among samples where
V and E are the collections of its vertices and hyperedges
respectively. In this hypergraph, each sample is deemed as
a vertex, i.e., the sample xi is corresponding to the vertex
vi ∈ V . Same as the conventional hypergraph construction
fashion, a sample xi and its top t− 1 most similar samples are
employed to deﬁne a t-length hyperedge ei ∈ E. Therefore,
for a data collection constructed by n samples, we can obtain
n hyperedges. The weight of the hyperedge ei is deﬁned as
the mean similarity of samples in this hyperedge,

(cid:80){va,vb}∈ei

li

wi =

sab

(4)

where li is the number of pairs of vertices in the hyperedge
ei.

B. Learning with Regression-based Hypergraph

respectively reformulated as d(vi) = (cid:80){vi∈ej|ej∈E} wj and

Spectral clustering and hypergraph transduction are the
most common unsupervised and supervised hypergraph learn-
ing techniques respectively. In this subsection, we apply
our Regression-based Hypergraph (RH) model to these two
techniques for validating the effectiveness of our model. We
develop a novel spectral clustering and hypergraph transduc-
tion framework and name them Regression-based Hypergraph
Spectral Clustering (RHSC) and Regression-based Hypergraph
Transduction (RHT) respectively. We begin by introducing
some common deﬁnitions of hypergraph learning [1]. We
denote the degrees of vertex and hyperedge as the sum of
weights of hyperedges which are incident to the given vertex
and the number of vertices in the hyperedge respectively.
Mathematically,
the degrees of vertex and hyperedge are
δ(ei) = |ei|. The vertex-edge incident matrix H is a common
tool for depicting the structure of hypergraph. each of its rows
and columns are corresponding to the vertex and the hyperedge
of hypergraph respectively. More speciﬁcally, for a hypergraph
consisted by n vertices and m hyperedges, its vertex-edge
incident matrix is a n × m-dimensional binary matrix. If the
vertex vi is on the hyperedge ej, the (i, j)-th element of H is
1, otherwise, 0. Due to the hyperedge generation fashion of
RH, the dimension of its vertex-edge incident matrix is n× n.
From the perspective of graph learning, the spectral clus-
tering is actually a graph (or hypergraph) partition issue [1],
[41], [42]. Then, we can consider the regression hypergraph-
based spectral clustering problem as a normalize hypergraph
cut issue. According to Zhou’s work [1], such issue can be
solved by following optimization model,

(cid:88)

(cid:88)

ei∈E

(v,u)∈ei

wi
δ(ei)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) F (u)(cid:112)d(u)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

,

− F (v)(cid:112)d(v)

ˆF = arg min

F

Ω(F, G) :=

1
2

(5)
where the n × m-dimensional matrix F = [f1,··· , fm] is
the collection of the hypergraph cuts of the given regression
hypergraph G(V, E). The n-dimensional column vector f is

IEEE TRANSACTIONS ON

5

THE DETAIL INFORMATION OF TWO MENTIONED RH INSTANCES.

TABLE I

Name
L1H
L2H

Regression model ∆(·) in Equation 1
||xi − Xt(cid:54)=iCi||2
||xi − Xt(cid:54)=iCi||2

SR [14]
CR [22]

2

2

Φ(·) in Equation 1

||Ci||1
||Ci||2

2

THE RELATIONS OF THE PROPOSED FOUR HYPERGRAPH LEARNING

TABLE II

APPROACHES.

RH Instances

L1H (SR [14])
L2H (CR [22])

Hypergraph Learning Frameworks

RHT (Semi-Supervised)

RHSC (Unsupervised)

L1HT
L2HT

L1HSC
L2HSC

a hypergraph cut which introduces a binary partition to the
given hypergraph and its elements indicate the conﬁdences
of how the corresponding vertices belonging to a subgraph
after partition. F (v) is a row of matrix F which encodes the
elements of hypergraph cuts corresponding to the vertex v.

According to the normalized cut criterion [42], the optimal
hypergraph cuts should maximize the compactness of parti-
tioned subgraphs and minimize the compactness of the bound-
aries between the subgraphs simultaneously. The compactness
of subgraphs and boundaries is measured by the normalized
summation of the hyperedge weights of a vertex set. With
several reductions, Equation 5 can be further translated into
the following matrix expression,

ˆF = arg min

Ω(F, G)

F

(cid:88)

(cid:88)

:=

1
2

ei∈E

wi
δ(ei)
:= Trace{F T (I − D−1/2
v HW D−1
:= Trace(F T LRF ),

(v,u)∈ei

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) F (u)(cid:112)d(u)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2

− F (v)(cid:112)d(v)

e H T D−1/2

v

)F}

where function Trace(·) returns the trace of matrix. Dei, Dv
and W are the diagonal matrix forms of δ(ei), d(v) and wi
respectively. I is the identity matrix and LR is the derived
normalized hypergraph Laplacian matrix which encodes the
structure of the regression hypergraph G. The detail deductions
of this equation can be referred to the works [1], [11].

The problem in Equation 6 is a typical eigenvalue problem.
It can be easily solved by eigenvalue decomposition technique.
The top m optimal hypergraph cuts F = [f1,··· , fm] are
exactly the top m eigenvectors corresponding the top m
minimal nonzero eigenvalues. Finally, the learned hypergraph
cut collection F is deemed as the new representation of data
for clustering.

Graph-based transduction is a semi-supervised learning
technique which is often leveraged to address the labeling
and classiﬁcation issues. In the semi-supervised case,
the
labels of some of data are available. Therefore, an optimal
hypergraph cut should not only minimize the loss of the
geometric structure of data (the loss of data relation) but also
minimize the labeling error. Conventionally, the labeling error
is measured by the Euclidean distance between the labels
and the hypergraph cuts, since the hypergraph cuts can be
deemed as the collection of the label indicator of vertex. Thus,
the original hypergraph partition model in Equation 5 can
be further improved as the following regularized hypergraph
partition model for considering the labeling error of data,

ˆF = arg min

{Ω(F, G) + λ∆(F, Y )}
= Trace(F T LRF ) + λ||F − Y ||2

F

(7)

(6)

here the collection of hypergraph cuts F has the same size as
Y where m = c.

Such problem is a typical Least Square (LS) problem which
can be efﬁciently solved. According to works [1], [4], its
solution is as follows

(cid:18) LR + λI

(cid:19)−1

1

F =

1 + λ
After obtaining F ,
the labeling (or classiﬁcation) of i-th
sample can be accomplished by assigning it to the t-th class
that satisﬁes t = argmaxjFij.

1 + λ

Y.

(8)

C. Two RH Instances: L1-Hypergraph and L2-Hypergraph

Sparse Representation (SR) and Collaborative Representa-
tion are two of the recent most inﬂuential regression models
in computer vision and machine learning. We employ them to
instantiate two Regression-based Hypergraph (RH) instances.
Since SR and CR are actually the L1-norm and L2-norm reg-
ularized regression models, we name these two RH instances
L1-Hypergraph (L1H) and L2-Hypergraph (L2H) respectively.
The detail information of L1H and L2H are presented in
Table 1. We have also plug L1H and L2H into Regression-
based Hypergraph Transduction (RHT) and Regression-based
Hypergraph Spectral Clustering (RHSC) frameworks to pro-
duce four new semi-supervised or unsupervised hypergraph
learning approaches respectively named L1-Hypergraph Trans-
duction (L1HT), L2-Hypergraph Transduction (L2HT), L1-
Hypergraph Spectral Clustering (L1HSC), and L2-Hypergraph
Spectral Clustering (L2HSC). The relations of these ap-
proaches are shown in Table II. In the next section, we
apply these four RH instance algorithms to demonstrate the
superiorities of our models over the conventional hypergraph
models and verify the assumption that RH should inherit some
desirable properties from the chosen regression models.

where λ is a positive parameter to reconcile these two losses
and the n × c-dimensional matrix Y = [y1,··· , yc] is the
collection of labels. yi is the label vector of the i-th class.
Let us denote yi(v) is the label of vertex v. Then, we have
yi(v) = 1 or -1 if the vertex v belonging to i-th class or other
classes respectively, and 0 if the vertex v is unlabeled. Note,

IV. EXPERIMENTS

In this section, we conduct some experiments to employ
the aforementioned four RHSC and RHT intances, namely
L1HSC, L2HSC, L1HT and L2HT,
to tackle the image
clustering and classiﬁcation tasks respectively. Since these

IEEE TRANSACTIONS ON

6

(a) AR

(b) ORL

(c) COIL20

(d) ETH80

(e) Scene15

(f) Caltech256

Fig. 2. The samples from six involved image databases.

four algorithms are all generated from Sparse Representation
(SR) or Collaborative Representation (CR) which enjoy the
robustness to noise and occlusion, we also conduct some
experiments to discuss if these four algorithms have inherited
such desirable property.

A. Datasets and Compared Methods

Six

image

datasets,

named AR [43], ORL [44],
COIL20 [45], ETH80 [46], Scene15 [47] and Caltech256 [48],
are leveraged for validating our works. AR face database
consists of more than 4,000 color images of 126 subjects [43].
Following paper [27], [8], a subset contains 2600 images
with 100 subjects are constructed in our experiment. Each
subject has 26 images. The ﬁrst 14 images of each subject
are not involved any occlusion while the rest 12 images are
involved the occlusions. In these 12 images,
the faces in
the ﬁrst six images are occluded by the sunglasses and the
faces in the other six images are occluded by the scarfs. In
the general image classiﬁcation and clustering experiments,
only the images without any occlusion are utilized. The
whole dataset is leveraged to analysis the robustness of the
proposed work to disguise. The size of face image on AR
database is 60×43 pixels. ORL database is a face image
database, which contains 400 images from 40 subjects [44].
Each subject has ten images acquired at different
times.
The size of face image on ORL database is 32×32 pixels.
The COIL-20 database has 20 objects and each object has

72 images which are obtained by the rotation of the object
through 360◦ in 5◦ steps (1440 images in total) [45]. The
size of each image is 32×32 pixels on COIL20 database.
The ETH80 object database [46] contains 80 objects from 8
categories. Each object is represented by 41 views spaced
evenly over the upper viewing hemisphere (3280 images
in total). The original size of each image in this dataset is
128×128 pixels. We resize them to 32×32 pixels. Scene15
database [47] is a scene database, which has 15 classes with
100 samples per category. Following paper [1], a subset of
Caltech256 database [48], which has 20 classes with 100
samples per category, is used in our experiments. We directly
use grayscale as the feature on ORL, AR, COIL20 and
ETH80 databases. PiCoDes [49] is adoptted to represent the
images on Scene15 and Caltech256 databases, since they are
more challenging. The dimension of PiCoDes feature is 2048.
Figure 2 shows some samples of these six image databases.
Nonnegative Matrix Factorization (NMF) [50], Graph reg-
[51],
ularized Nonnegative Matrix Factorization (GNMF)
Normalized Cut (NCut) [42], Normalized Hypergraph Spec-
tral Clustering (NHSC) [1], Large-scale Spectral Clustering
(LSC) [52], Clique Expansion-based Hypergraph Spectral
Clustering using Matrix Trace Weights (CEHSC+Trace) [3],
Normalized Hypergraph Spectral Clustering using the mean
of distances between the centroid and the vertices in a hy-
peredge (NHSC+Cent) [3], and L1-Graph Spectral Clustering
(L1GSC) [18] are chosen as the compared approaches in the
image clustering experiments. NCut can be deemed as a sort
of regular graph spectral clustering algorithm. So there are
three graph spectral clustering algorithms. They are Ncut, LSC
and L1GSC. NHSC, CEHSC+Trace and NHSC+Cent are three
hypergraph spectral clustering methods. The only difference
between NHSC and NHSC+Cent is the weights of hyperedges.
NHSC uses the mean of distances between each two samples
in a hyperedge while NHSC+Cent uses the mean of distances
between the hyperedge centroid and the samples in a hyper-
edge. NHSC+Cent and CEHSC+Trace are referenced from
our recent work [3] which empirically studied the effect of
hyperedge weighting scheme to hypergraph learning and select
the most optimal weighting schemes for different hypergraph
frameworks. NHSC+Cent and CEHSC+Trace are the best hy-
peredge weighting scheme and hypergraph spectral clustering
combinations for addressing clustering issue reported in [3].
Sparse Representation-based Classiﬁer
employ
We
(SRC)
[14], Collaborative Representation-based Classiﬁer
(CRC) [22], LIB-Support Vector Machine (LIBSVM) [53],
Normalized Hypergraph Transduction (NHT)
[1], Graph
Transduction
[54], Adaptive Hypergraph-based
Classiﬁer (AHC) [4], Normalized Hypergraph Transduction
using Matrix Trace Weights (NHT+Trace) [3], Normalized
Hypergraph Transduction using the Volume of Simplex
Weights
and Sparse Graph-based
Classiﬁer
for
image classiﬁcation. GT and SGC are the graph transduction
algorithms while AHC, NHT, CEHT+Trace and NHT+Volume
are the hypergraph transduction algorithms. CEHT+Trace
and NHT+Volume are the best hyperedge weighting scheme
and hypergraph transduction combinations for addressing

[3],
the compared approaches

(NHT+Volume)
(SGC)

[17] as

(GT)

IEEE TRANSACTIONS ON

7

classiﬁcation issue reported in [3]. In the experiments, all the
compared methods are well tuned.

B. Image Clustering

We conduct the image clustering experiments on all six
image databases. For each database, the cluster number is
ﬁxed to its category number. Following [51], [55], Clustering
Accuracy and Normalized Mutual Information (NMI) are
leveraged as two evaluation metrics.

Table III reports the clustering performances of different
clustering methods. The bold number indicates the best accu-
racy in a dataset under same metric. We can ﬁnd that L1HSC
and L2HSC outperform almost all compared approaches in
all experiments and achieve remarkable improvements over
the conventional hypergraph spectral clustering algorithms. For
examples, the clustering accuracy gains of L1HSC over NHSC
are 33.50%, 11.50%, 6.25%, 5.49%, 9.73% and 5.75% on
AR, ORL, COIL20, ETH80, Scene15 and Caltech256 datasets
respectively. Similarly, such gains of L2HSC are 36.72%,
11.75%, 5.55%, 10.33% and 8.55%. The experimental results
also show that, as the generalization of sparse graph spectral
clustering, L1HSC and L2HSC obtain the better performances
over L1GSC which is known as a sparse graph spectral cluster-
ing algorithm. More speciﬁcally, The NMI gains of L1HSC
over L1GSC on AR, ORL, COIL20, ETH80, Scene15 and
Caltech256 datasets are 7.94%, 4.71%, 13.23%, 8.72%, 7.66%
and 4.02% respectively. Similarly,
the NMI improvements
of L2HSC over L1GSC are 7.96%, 4.72%, 11.50%, 3.97%,
9.06% and 5.74% on AR, ORL, COIL20, ETH80, Scene15
and Caltech256 datasets. Another interesting phenomenon can
be observed from the experimental results is that L2HSC per-
forms much better than L1HSC comprehensively. We attribute
this to the fact that Collaborative Representation (CR) is often
more discriminative than Sparse Representation (SR) [22],
[23].

CLASSIFICATION PERFORMANCE COMPARISON (IN PERCENTS) USING AR,

COIL20, ETH80 AND SCENE15 DATABASES.

TABLE IV

COIL20

ETH80

Scene15

AR

LIBSVM [53]

Methods
CRC [22]
SRC [14]

Classiﬁcation Errors (Mean ± Standard Deviation, %)
25.07±1.31 11.19±1.10 20.34±6.34 26.73±1.43
19.57±2.22 11.81±0.98 29.70±8.80 26.80±2.83
26.50±0.10 12.50±1.18 30.82±5.99 25.40±2.17
32.00±1.41 4.86±0.00
27.59±2.98 26.80±1.89
29.57±0.81 43.13±0.49 27.32±0.95 32.40±2.07
33.14±1.21 10.13±1.41 27.13±2.85 25.54±1.59
32.21±1.31 3.68±0.69
26.10±4.31 25.47±1.89
NHT+Trace [3]
25.82±4.61 25.40±1.98
NHT+Volume [3] 32.29±1.21 4.79±0.29
16.79±1.91 9.44±1.18
28.38±6.25 26.13±0.42
17.44±1.98 26.13±3.96
10.50±1.91 2.15±0.49
4.79±0.10
4.51±4.42
17.32±0.43 25.27±2.92

NHT [1]
GT [54]
AHC [4]

SGC [17]
L1HT
L2HT

C. Image Classiﬁcation

We employ AR, COIL20, ETH80 and Scene15 databases
for evaluating image classiﬁcation performances of different
classiﬁers. The two-fold cross-validation scheme is applied in
the image classiﬁcation experiments.

(a) Noise Level = 0.1

(b) Noise Level = 0.2

(c) Noise Level = 0.3

(d) Noise Level = 0.4

(e) Noise Level = 0.5

Fig. 3. The samples from ﬁve noisy versions of COIL20 database.

Table IV reports the classiﬁcation errors of different clas-
siﬁers on different databases. Similar to the experimental
results of image clustering, the proposed approaches, L1HT
and L2HT achieve very promising classiﬁcation performance
and consistently outperform the other hypergraph transduction
approaches. Particularly, It is worthwhile to point out that
L2HT ranks ﬁrst on three databases among all four databases.
More speciﬁcally, the classiﬁcation accuracy gains of L2HT
over the other hypergraph transduction approaches, namely
NHT, AHC, NHT+Trace and NHT+Volume on AR database
are 27.21%, 28.35%, 27.42% and 27.50% respectively. Such
numbers of L1HT on ETH80 database are 10.15%, 9.69%,
8.66% and 8.50% respectively. From the observations, it is
not hard to ﬁnd that L1HT often performs much better than
the SGC which can be deemed as the pairwise version of
L1HT. We believe that such phenomenon well veriﬁes the
better representational power of L1-hypergraph over L1-graph.

D. Robustness Analysis

It

is well known that Sparse Representation (SR) and
Collaborative Representation (CR) are robust to the disguise
and noise. Since L1-Hypergraph (L1H) and L2-Hypergraph
(L2H) are generated by SR and CR, here we conduct several
experiments to see if L1H and L2H also enjoy such desirable
properties.

1) Robust to Noise:

In order to evaluate the robustness
of our works to noise, we construct ﬁve noisy versions of
COIL dataset via randomly assigning zero or 255 to a certain
proportion of pixels in the image. In these noisy COIL20
databases, we use the Noise Level
to measure the noise
degree of data where the Noise Level is deﬁned as the ratio
of the number of noisy dimensions to the number of total
dimensions. The Noise Levels of these ﬁve noisy versions of
COIL20 database are 0.1, 0.2, 0.3, 0.4 and 0.5 respectively

IEEE TRANSACTIONS ON

8

IMAGE CLUSTERING PERFORMANCE COMPARISON (IN PERCENTS) ON AR, ORL, COIL20, ETH80, SCENE15 AND CALTECH256 DATABASES. (IN

TABLE III

PERCENTAGE)

Clustering Accuracy

Normalized Mutual Information (NMI)

Methods
NMF [50]

GRNMF [51]

NCut [42]
NHSC [1]
LSC [52]

CEHSC+Trace [3]
NHSC+Cent [3]

L1GSC [18]

L1HSC
L2HSC

AR
24.29
28.86
61.79
36.71
35.86
35.50
36.71
59.93
70.21
73.43

ORL
51.25
65.75
67.75
66.75
66.00
70.50
69.50
69.50
78.25
79.50

COIL20
60.59
82.22
69.60
76.60
76.04
82.29
76.60
68.13
82.85
82.15

ETH80
46.86
52.16
45.61
50.85
55.55
51.89
46.86
51.77
56.34
53.38

Scene15
59.33
62.87
56.87
58.87
66.33
67.47
63.33
56.27
67.60
69.20

Caltech256

38.25
39.80
38.00
36.40
43.95
36.30
44.15
34.30
42.15
44.95

AR
56.12
60.52
80.71
64.34
65.43
64.00
64.36
78.77
86.71
86.73

ORL
70.31
82.19
82.01
81.57
82.39
82.75
81.62
82.50
87.21
87.22

COIL20
70.89
89.99
77.00
85.26
86.13
89.12
85.26
77.76
90.99
89.26

ETH80
41.13
46.93
38.02
47.76
56.22
46.83
46.72
50.00
58.72
53.97

Scene15
58.41
61.32
60.21
58.46
64.01
62.03
59.53
56.74
64.40
65.80

Caltech256

38.89
38.45
38.69
37.32
41.32
34.01
43.29
37.86
41.88
43.60

(a) Accuracy (Image Clustering) ↑

(b) NMI (Image Clustering) ↑

(c) Error (Image Classiﬁcation) ↓

Fig. 4. The image clustering or classiﬁcation performances of different hypergraph-based approaches using different noisy versions of COIL20 database. ↑
means the higher the better while ↓ means the lower the better.

(see the examples in Figure 3). We follow the same fashions
as mentioned in the previous sections to conduct the image
classiﬁcation and clustering experiments in these noisy image
databases.

We plot the experimental results of different approaches
under different Noise Levels in Figure 4. Figures 4(a) and 4(b)
report the clustering accuracy and NMI respectively. From
these observations, we can see that the clustering performances
of all approaches are decreased along with the increasing
of Noise Levels. However, compared with the conventional
hypergraph methods, such as NHSC and CEHSC, L1GSC,
L1HSC and L2HSC perform much better and their clustering
performances are apparently decreased much slower along
with the increasing of Noise Level. Clearly, such phenomenon
shows that L1HSC and L2HSC are more robust to noise in
comparison with the conventional hypergraph spectral clus-
tering models. Figure 4(c) shows the classiﬁcation errors
of different approaches under different Noise Levels. The
observations of image classiﬁcation experiments are quite
different to the ones of the aforementioned image clustering
experiments. The performances of all approaches are very
similar, and only L2HT slightly outperforms the others. We
mainly attribute this phenomenon to the fact that the training
samples all contain noise and the supervision from category
labels compulsively introduces the noise samples to the hy-
pergraph learning models. Therefore, the contributions of the
robust sample selection procedures from Collaborative Repre-
sentation (CR) and Sparse Representation (SR) are weakened.

CLASSIFICATION PERFORMANCE COMPARISON (IN PERCENTS) ON AR

DATABASE WITH REAL DISGUISE.

TABLE V

Metric

AC
NMI

NHSC
20.32
46.11

Methods

NHSC+Cent CEHSC+Trace L1HSC
48.00
67.81

19.06
46.60

20.38
45.99

L2HSC
68.19
80.42

CLASSIFICATION PERFORMANCE COMPARISON (IN PERCENTS) USING AR,

COIL20, ETH80 AND SCENE15 DATABASES.

TABLE VI

Methods
CRC [22]
SRC [14]
NHT [1]
AHC [4]

SGC [17]
L1HT
L2HT

NHT+Trace [3]
NHT+Volume [3]

Classiﬁcation Errors (%)

17.08
58.25
92.67
92.83
92.67
92.92
20.00
20.42
4.00

Comprehensively speaking, L1H and L2H enjoy a certain
amount of robustness to noise particularly in the unsupervised
way.

2) Robust to Disguise: We employ AR database to evaluate
the image clustering and classiﬁcation performances under the
disguise case, since AR database have already provided the
face images with natural disguise (sunglasses and scarfs) for

0.10.20.30.40.50.10.20.30.40.50.60.70.8Noise LevelClustering Accuracy  L2HSCL1HSCL1GSCNHSCNHSC+CentCEHSC+Trace0.10.20.30.40.50.20.40.60.81Noise LevelNormalized Mutual Information  L2HSCL1HSCL1GSCNHSCNHSC+CentCEHSC+Trace0.10.20.30.40.500.10.20.30.40.5Noise LevelClassification Error  L2HTL1HTNHTAHCNHT+VolumeNHT+TraceIEEE TRANSACTIONS ON

9

E. Parameter Settings

In this section, we discuss the inﬂuences of different pa-
rameters to our works. The RHSC methods, such as L1HSC
and L2HSC, mainly involve two parameters, β and t, where
β is used for controlling the regression regularization term
in a regression model while t is the hyperedge length. The
RHT methods, such as L1HT and L2HT, have one more
parameter, λ, which is used for balancing the labeling error
of data and the loss of hypergraph partition. Although the
hyperedge length t is an important parameter which can
deeply inﬂuence the quality of hypergraph, it has numerous
possible values and it is impossible for us to evaluate each
possible value. So, in our experiments, we deﬁne a hyperedge
length candidate collection and then conduct experiments
to empirically ﬁnd the optimal value of hyperedge length.
Tables VII and VIII respectively list the hyperedge length
candidate collections of the proposed RH works and report
their optimal hyperedge lengths. Figure 5 demonstrates the
inﬂuences of β to the clustering performances of L1HSC
and L2HSC. We choose the mean of clustering accuracy and
NMI as the comprehensive clustering performance evaluation
metrics. From the observations in Figure 5, we can ﬁnd that
the performance of L1HSC is quite insensitive to β and
the optimal beta of L1HSC on ORL, AR, COIL20, ETH80,
Scene15 and Caltech256 databases, are 10−5, 10−4, 10−3,
10−2 and 10−1 respectively. With regard to L2HSC, a higher
value of β is much better on Scene15, Caltech256, COIL20
and ETH80 databases while a medium β is more suitable to the
AR and ORL databases. Figure 6 shows the impacts of β and
λ to the classiﬁcation performances of L1HT and L2HT. The
phenomena as similar as the ones in Figure 5 are observed.
L1HSC is not very sensitive to β and the best β for AR,
COIL20, ETH80 and Scene15 databases are 10−5, 10−3, 10−5
and 10−2 respectively. A medium β works well for L2HT on
AR and COIL20 databases while L2HT with a higher β shows
the better performances on Scene15 and ETH80 databases.
Moreover, from the observations in Figures 6(c) and 6(d),
both L1HT and L2HT can achieve the best classiﬁcation
performances when λ is larger than 1.

V. CONCLUSION

In this paper, we presented a new solution for hyper-
graph construction in which the regression models are used
for measuring the closeness among samples. We named
this new hypergraph framework Regression-based Hyper-
graph (RH). Based on two conventional hypergraph learn-
ing models, namely Hypergraph Spectral Clustering (HSC)
and Hypergraph Transduction (HT), We also developed the
Regression-based Hypergraph Spectral Clustering (RHSC) and
Regression-based Hypergraph Transduction (RHT) models for
addressing the clustering and classiﬁcation issues. As two
inﬂuential regression approaches for visual learning, Sparse
Representation (SR) and Collaborative Representation (CR)
are employed to instantiate two instances of RH and their
RHSC and RHT algorithms. Six popular image databases are
leveraged for validating the effectiveness of our works. It can
be concluded from observations of the experiments that RH

(a) The impact of β to L1HSC

(b) The impact of β to L2HSC

Fig. 5. The impacts of different parameters to the clustering performances
of L1HSC and L2HSC.

THE HYPEREDGE LENGTH (t) CANDIDATE COLLECTIONS OF L1HSC AND

L2HSC AND THEIR OPTIMAL HYPEREDGE LENGTHS IN DIFFERENT

TABLE VII

DATASETS.

Database

ORL
AR

COIL20
ETH80
Scene15
Caltech256

Candidates
{2:11}
{2:14}

{3,5,10,20,36,54,72}
{3,5,10,41:41:410}
{5:5:50,60:10:100}
{5:5:50,60:10:100}

The optimal t

L1HSC
t = 9
t = 13
t = 3
t = 10
t = 50
t = 100

L2HSC
t = 11
t = 14
t = 5

t = 123
t = 100
t = 100

THE HYPEREDGE LENGTH (t) CANDIDATE COLLECTIONS OF L1HT AND

L2HT AND THEIR OPTIMAL HYPEREDGE LENGTHS IN DIFFERENT

TABLE VIII

DATASETS.

Database

AR

COIL20
ETH80
Scene15

Candidates
{2:14}

{3,5,10,20,36,54,72}
{3,5,10,41:41:410}
{5:5:50,60:10:100}

The optimal t
L2HT
L1HT
t = 5
t = 8
t = 3
t = 5
t = 10
t = 10
t = 20
t = 35

each subject. In the image clustering experiments, all the face
images are applied. In the image classiﬁcation case, we use
the face images without any occlusion for training while use
the face images with occlusion for testing.

Table V lists the clustering performances of our works
and three other conventional hypergraph approaches. In these
experiments, L1HSC and L2HSC show the signiﬁcant ad-
vantages. For examples,
the clustering accuracy gains of
L1HSC over NHSC, NHSC+Cent and CEHSC+Trace are
27.68%, 27.62% and 29.00% respectively. L2HSC performs
even better. The clustering accuracy improvements of L2HSC
over these conventional hypergraph approaches are 47.87%,
47.81% and 49.13% respectively. Table VI tabulates the clas-
siﬁcation errors of different approaches in the disguise case.
From the observations, L1HT and L2HT obtain very promis-
ing performance while all the other traditional hypergraph
transduction approaches are totally failed. The classiﬁcation
error of L2HT is 23 times lower than the ones of NHT, AHC,
NHT+Trace and NHT+Volume. Clearly, the experimental re-
sults demonstrate that L1HT and L2HT are robust to disguise.

10−610−410−200.20.40.60.81β(AC+NMI)/2  ARCOIL20ETH80Scene15Caltech256ORL10−410−210010200.20.40.60.81β(AC+NMI)/2  ARCOIL20ETH80Scene15Caltech256ORLIEEE TRANSACTIONS ON

10

(a) The impact of β to L1HT

(b) The impact of β to L2HT

(c) The impact of λ to L1HT

(d) The impact of λ to L2HT

Fig. 6. The impacts of different parameters to the classiﬁcation performances of L1HT and L2HT.

inherits the desirable properties from both hypergraph and
regression model.

There still exist many interesting future works based on our
models, since RH is a general framework for hypergraph con-
struction in which researchers can ﬂexibly choose their own
appropriate regression models to construct RHs for tackling
different tasks. For examples, RH can be further applied to
hypergraph-based subspace learning [8], feature selection [56],
multi-label learning [6], [57] or attribute learning [11]. More-
over, to investigate the adaptive and efﬁcient RH construction
fashion is also a very meaningful direction for improving the
utility and efﬁciency [4], [58].

ACKNOWLEDGEMENT

REFERENCES

[1] D. Zhou, J. Huang, and B. Sch¨olkopf, “Learning with hypergraphs: Clus-
tering, classiﬁcation, and embedding,” in Advances in neural information
processing systems (NIPS), 2006, pp. 1601–1608.

[2] J. Y. Zien, M. D. Schlag, and P. K. Chan, “Multilevel spectral hyper-
graph partitioning with arbitrary vertex sizes,” IEEE Transactions on
Computer-Aided Design of Integrated Circuits and Systems, vol. 18,
no. 9, pp. 1389–1399, 1999.

[3] S. Huang, A. Elgammal, and D. Yang, “On the effect of hyperedge
weights on hypergraph learning,” arXiv preprint arXiv:1410.6736, 2014.
[4] J. Yu, D. Tao, and M. Wang, “Adaptive hypergraph learning and
its application in image classiﬁcation,” IEEE Transactions on Image
Processing, vol. 21, no. 7, pp. 3262–3272, 2012.

[5] M. Wang, X. Wu et al., “Visual classiﬁcation by l1-hypergraph model-
ing,” IEEE Transactions on Knowledge and Data Engineering, vol. 27,
no. 9, pp. 2564–2574, 2015.

[6] G. Chen, J. Zhang, F. Wang, C. Zhang, and Y. Gao, “Efﬁcient multi-
label classiﬁcation with hypergraph regularization,” in IEEE Conference
on Computer Vision and Pattern Recognition (CVPR), 2009, pp. 1658–
1665.

[7] P. Ochs and T. Brox, “Higher order motion models and spectral cluster-
ing,” in IEEE conference on Computer Vision and Pattern Recognition
(CVPR), 2012, pp. 614–621.

[8] S. Huang, D. Yang, Y. Ge, D. Zhao, and X. Feng, “Discriminant hyper-
laplacian projections with its applications to face recognition,” in IEEE
conference on Multimedia and Expo Workshop on HIM (ICMEW), 2014,
pp. 1–6.

[9] S. Huang, D. Yang, J. Zhou, and X. Zhang, “Graph regularized lin-
ear discriminant analysis and its generalization,” Pattern Analysis and
Applications, vol. 18, no. 3, pp. 639–650, 2015.

[10] L. Sun, S. Ji, and J. Ye, “Hypergraph spectral learning for multi-label
classiﬁcation,” in ACM international conference on Knowledge discovery
and data mining (SIGKDD), 2008, pp. 668–676.

[11] S. Huang, M. Elhoseiny, A. Elgammal, and D. Yang, “Learning
hypergraph-regularized attribute predictors,” in IEEE Conference on
Computer Vision and Pattern Recognition (CVPR), 2015, pp. 409–417.
[12] Y. Huang, Q. Liu, S. Zhang, and D. N. Metaxas, “Image retrieval via
probabilistic hypergraph ranking,” in IEEE conference on Computer
Vision and Pattern Recognition (CVPR), 2010, pp. 3376–3383.

[13] Y. Gao, M. Wang, D. Tao, R. Ji, and Q. Dai, “3-D object retrieval
and recognition with hypergraph analysis,” IEEE Transactions on Image
Processing, vol. 21, no. 9, pp. 4290–4303, 2012.

[14] J. Wright, A. Y. Yang, A. Ganesh, S. S. Sastry, and Y. Ma, “Robust face
recognition via sparse representation,” IEEE Transactions on Pattern
Analysis and Machine Intelligence, vol. 31, no. 2, pp. 210–227, 2009.
[15] S. Gao, I. W.-H. Tsang, and L.-T. Chia, “Kernel sparse representation
for image classiﬁcation and face recognition,” in European Conference
on Computer Vision (ECCV), 2010, pp. 1–14.

[16] C.-Y. Lu, H. Min, J. Gui, L. Zhu, and Y.-K. Lei, “Face recognition via
weighted sparse representation,” Journal of Visual Communication and
Image Representation, vol. 24, no. 2, pp. 111–116, 2013.

[17] S. Huang, D. Yang, J. Zhou, and L. Huangfu, “Sparse graph-based
transduction for image classiﬁcation,” Journal of Electronic Imaging,
vol. 24, no. 2, p. 023007, 2015.

[18] B. Cheng, J. Yang, S. Yan, Y. Fu, and T. S. Huang, “Learning with
L1-graph for image analysis,” IEEE Transactions on Image Processing,
vol. 19, no. 4, pp. 858–866, 2010.

[19] R. Timofte and L. Van Gool, “Sparse representation based projections,”

in British machine vision conference (BMVC), 2011, pp. 61–1.

[20] L. Qiao, S. Chen, and X. Tan, “Sparsity preserving projections with
applications to face recognition,” Pattern Recognition, vol. 43, no. 1,
pp. 331–341, 2010.

[21] E. Elhamifar and R. Vidal, “Sparse subspace clustering,” in IEEE
Conference on Computer Vision and Pattern Recognition (CVPR), 2009,
pp. 2790–2797.

[29] X.-T. Yuan, X. Liu, and S. Yan, “Visual classiﬁcation with multitask
joint sparse representation,” IEEE Transactions on Image Processing,
vol. 21, no. 10, pp. 4349–4360, 2012.

[30] S. Huang, D. Yang, J. Zhou, L. Huangfu, and X. Zhang, “Sparse
graph-based transduction for image classiﬁcation,” Journal of Electronic
Imaging, vol. 24, no. 2, p. 023007, 2014.

[31] X. Peng, L. Zhang, and Z. Yi, “Scalable sparse subspace clustering,” in
IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
2013, pp. 430–437.

[32] G. Liu, Z. Lin, and Y. Yu, “Robust subspace segmentation by low-
rank representation,” in International Conference on Machine Learning
(ICML), 2010, pp. 663–670.

[33] B. Cheng, J. Yang, S. Yan, Y. Fu, and T. S. Huang, “Learning with

[22] L. Zhang, M. Yang, and X. Feng, “Sparse representation or collabo-
rative representation: Which helps face recognition?” in International
Conference on Computer Vision (ICCV), 2011, pp. 471–478.

[23] M. Yang, L. Zhang, D. Zhang, and S. Wang, “Relaxed collaborative rep-
resentation for pattern classiﬁcation,” in IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), 2012, pp. 2224–2231.

[24] R. Timofte and L. Van Gool, “Weighted collaborative representation
and classiﬁcation of images,” in International Conference on Pattern
Recognition (ICPR), 2012, pp. 1606–1610.

[25] S. Huang, Y. Yang, D. Yang, L. Huangfu, and X. Zhang, “Class speciﬁc
sparse representation for classiﬁcation,” Signal Processing, vol. 116, pp.
38–42, 2015.

[26] P. J. Phillips, H. Wechsler, J. Huang, and P. J. Rauss, “The feret database
and evaluation procedure for face-recognition algorithms,” Image and
Vision Computing, vol. 16, no. 5, pp. 295–306, 1998.

[27] I. Naseem, R. Togneri, and M. Bennamoun, “Linear regression for
face recognition,” IEEE Transactions on Pattern Analysis and Machine
Intelligence, vol. 32, no. 11, pp. 2106–2112, 2010.

[28] D. L. Donoho, “Compressed sensing,” IEEE Transactions on Informa-

tion Theory, vol. 52, no. 4, pp. 1289–1306, 2006.

10−610−510−410−310−200.10.20.30.40.50.60.7βClassification Error  ARCOIL20ETH80Scene1510−410−210010200.20.40.60.81βClassification Error  ARCOIL20ETH80Scene1510−210010200.20.40.60.81λClassification Error  ARCOIL20ETH80Scene1510−210010200.20.40.60.81λClassification Error  ARCOIL20ETH80Scene15IEEE TRANSACTIONS ON

11

L1-graph for image analysis,” IEEE Transactions on Image Processing,
vol. 19, no. 4, pp. 858–866, 2010.

[34] L. Pu and B. Faltings, “Hypergraph learning with hyperedge expansion,”
in Machine Learning and Knowledge Discovery in Databases, 2012, pp.
410–425.

[35] A. Panagopoulos, C. Wang, D. Samaras, and N. Paragios, “Simultaneous
cast shadows, illumination and geometry inference using hypergraphs,”
IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 35, no. 2, pp. 437–449, 2013.

[36] S. Agarwal, J. Lim, L. Zelnik-Manor, P. Perona, D. Kriegman, and
S. Belongie, “Beyond pairwise clustering,” in IEEE conference on
Computer Vision and Pattern Recognition (CVPR), vol. 2, 2005, pp.
838–845.

[37] M. Bolla, “Spectra, euclidean representations and clusterings of hyper-

graphs,” Discrete Mathematics, vol. 117, 1993.

[38] S. Agarwal, K. Branson, and S. Belongie, “Higher order learning with
graphs,” in International Conference on Machine Learning (ICML),
2006, pp. 17–24.

[39] S. Yan and H. Wang, “Semi-supervised learning by sparse representa-
tion.” in SIAM International Conference on Data Mining (SDM). SIAM,
2009, pp. 792–801.

[40] L. Zhuang, H. Gao, Z. Lin, Y. Ma, X. Zhang, and N. Yu, “Non-
negative low rank and sparse graph for semi-supervised learning,” in
IEEE Conference on Computer Vision and Pattern Recognition (CVPR).
IEEE, 2012, pp. 2328–2335.

[41] A. Y. Ng, M. I. Jordan, Y. Weiss et al., “On spectral clustering: Analysis
and an algorithm,” Advances in neural information processing systems
(NIPS), vol. 2, pp. 849–856, 2002.

[42] J. Shi and J. Malik, “Normalized cuts and image segmentation,” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 22,
no. 8, pp. 888–905, 2000.

[43] A. Mart´ınez and R. Benavente, “The ar face database,” Bellatera, Jun

1998.

[44] F. S. Samaria and A. C. Harter, “Parameterisation of a stochastic model
for human face identiﬁcation,” in Proceedings of the Second IEEE
Workshop on Applications of Computer Vision, 1994, pp. 138–142.

[45] S. A. Nene, S. K. Nayar, H. Murase et al., “Columbia object image
library (COIL-20),” Technical Report CUCS-005-96, Tech. Rep., 1996.
[46] B. Leibe and B. Schiele, “Analyzing appearance and contour based
methods for object categorization,” in IEEE Conference on Computer
Vision and Pattern Recognition, vol. 2, 2003, pp. II–409.

[47] S. Lazebnik, C. Schmid, and J. Ponce, “Beyond bags of features: Spatial
pyramid matching for recognizing natural scene categories,” in IEEE
conference on Computer Vision and Pattern Recognition (CVPR), vol. 2,
2006, pp. 2169–2178.

[48] G. Grifﬁn, A. Holub, and P. Perona, “Caltech-256 object category

dataset,” 2007.

[49] A. Bergamo, L. Torresani, and A. W. Fitzgibbon, “Picodes: Learning a
compact code for novel-category recognition,” in Advances in Neural
Information Processing Systems (NIPS), 2011, pp. 2088–2096.

[50] D. D. Lee and H. S. Seung, “Learning the parts of objects by nonnegative

matrix factorization,” Nature, vol. 401, pp. 788–791, 1999.

[51] D. Cai, X. He, J. Han, and T. S. Huang, “Graph regularized nonnegative
matrix factorization for data representation,” IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol. 33, no. 8, pp. 1548–
1560, 2011.

[52] X. Chen and D. Cai, “Large scale spectral clustering with landmark-
based representation.” in AAAI Conference on Artiﬁcial Intelligence
(AAAI), 2011.

[53] C.-C. Chang and C.-J. Lin, “LIBSVM: A library for support vector
machines,” ACM Transactions on Intelligent Systems and Technology,
vol. 2, pp. 27:1–27:27, 2011.

[54] O. Duchenne, J.-Y. Audibert, R. Keriven, J. Ponce, and F. S´egonne,
“Segmentation by transduction,” in IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), 2008, pp. 1–8.

[55] D. Cai, X. He, and J. Han, “Document clustering using locality preserv-
ing indexing,” IEEE Transactions on Knowledge and Data Engineering,
vol. 17, no. 12, pp. 1624–1637, 2005.

[56] Z. Zhang, P. Ren, and E. R. Hancock, “Unsupervised feature selection
via hypergraph embedding.” in Birtish Machine Vision Conference
(BMVC), 2012, pp. 1–11.

[57] L. Sun, S. Ji, and J. Ye, “Hypergraph spectral learning for multi-label
classiﬁcation,” in ACM international conference on Knowledge discovery
and data mining (SIGKDD), 2008, pp. 668–676.

[58] W. Liu, J. He, and S.-F. Chang, “Large graph construction for scal-
able semi-supervised learning,” in International conference on machine
learning (ICML), 2010, pp. 679–686.

