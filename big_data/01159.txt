6
1
0
2

 
r
a

M
 
3
 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
9
5
1
1
0

.

3
0
6
1
:
v
i
X
r
a

Variational estimation of the drift for stochastic
diﬀerential equations from the empirical density

Philipp Batz, Andreas Ruttor and Manfred Opper
Artiﬁcial Intelligence Group, Technische Universit¨at Berlin, Marchstraße 23, Berlin
10587, Germany

E-mail: philipp.batz@tu-berlin.de, andreas.ruttor@tu-berlin.de,
manfred.opper@tu-berlin.de

Abstract. We present a method for the nonparametric estimation of the drift
function of certain types of stochastic diﬀerential equations from the empirical
density. It is based on a variational formulation of the Fokker-Planck equation. The
minimization of an empirical estimate of the variational functional using kernel based
regularization can be performed in closed form. We demonstrate the performance of
the method on second order, Langevin-type equations and show how the method can
be generalized to other noise models.

PACS numbers: 02.50.Tt, 02.50.Ey, 05.10.Gg, 05.45.Tp, 45.10.Db

1. Introduction

An important problem in modelling a random process by a stochastic diﬀerential
equation (SDE) is the ﬁtting of the model to observed data. An SDE is determined
by its drift function and the diﬀusion. For models of thermal equilibrium, where the
diﬀusion is proportional to the unit matrix and the drift is the gradient of a potential,
a rather simple and well known approach for estimating the drift from data is available
(see e.g. [1]): One can use the fact that the potential is proportional to the logarithm
of the stationary density. Hence, from an estimator of the density, provided e.g. by a
kernel density estimator (KDE) one can get an explicit estimator for the drift. This
estimator is based on the empirical distribution of data alone which completely ignores
the temporal ordering of observations and the time lag between them. One only needs
an ergodic sample of the process. The KDE estimator is also nonparametric i.e. it
does not assume a speciﬁc parametric functional form of the drift. For non-equilibrium
models such an explicit expression of the density in terms of the drift is, in general, not
known. Also in higher dimensions the convergence of the KDE to the true density with
increasing data sample size maybe slow [2].

Other parametric and nonparametric approaches to drift estimation have to deal
with the problem of low data sampling rates [3]. E.g. a nonparametric method based
on Kramers-Moyal coeﬃcients [4] (conditional moments) requires numerical solutions of

Variational estimation of the drift for stochastic diﬀerential equations

2

the Kolmogorov backward equation over a time interval given by the time lag. Bayesian
estimators using a Gaussian process prior over drift functions provide an elegant solution
to estimation [5] when a complete path of dense observations is available. But in general
it requires the imputation of unobserved diﬀusion paths as hidden random variables
between neighboring observations. This can lead to time consuming computations or
requires further approximations. [5] introduced a Monte Carlo Gibbs sampler, which
switches between sampling hidden paths of the process and sampling drift functions.
An alternative approach was given in [6], where the latent path was treated by an
expectation maximization approach with the hidden process approximated by a linear
stochastic diﬀerential equation. This seems to work faster, but the quality of the linear
approximation deteriorates for larger time lags leading to an asymptotic bias in the
inference of the drift.

The goal of this paper is to construct classes of nontrivial SDE models for which
a computationally eﬃcient nonparametric estimation of the drift is possible using the
empirical distribution alone. Our method is based on a variational formulation of the
stationary Fokker-Planck equation which gives a unique solution to the drift under
certain conditions. These generalize the potential condition of thermal equilibrium.
The functional to be minimized is an expectation over the stationary density. By
replacing this density with the empirical one, i.e. with an unordered data sample and
by minimizing the empirical functional (e.g. in a parametric family of potentials), one
can get an estimator of the drift. The method can be generalized to a nonparametric
estimate if the empirical functional is regularized with a kernel based penalty term. Our
approach is not based on an explicit representation of the drift in terms of the density.
Hence, it does not use a direct estimator of the density such as the KDE. Thus it is not
expected to suﬀer from the bad convergence properties of the KDE in higher dimensions.
The paper is organized as follows. The second chapter introduces the variational
formulation of the Fokker-Planck equation from which the drift can be derived by
minimization of a functional. The third chapter shows how a regularized empirical
approximation of the functional leads to a nonparametric estimate. The fourth chapter
presents examples of this estimator for the class of Langevin equations for which the
extra conditions lead to only mild restrictions. The ﬁfth chapter explains how the
method can be extended to other types of noise, such as jump processes. We conclude
with a discussion and possible extensions of the method in chapter six.

2. A variational formulation for the Fokker-Planck equation

We consider stochastic diﬀerential equations for the dynamics of a d-dimensional
diﬀusion process Zt ∈ Rd given by

dZt = g(Zt)dt + σ(Zt)dWt.

(1)
The drift function g(·) ∈ Rd represents the deterministic part of the driving force and
W is a k-dimensional (k ≤ d) vector of independent Wiener processes acting as a white

Variational estimation of the drift for stochastic diﬀerential equations
3
noise source. The strength of the noise is determined by the state dependent d × k
dimensional noise matrix σ(Z).

Suppose that we are given the stationary density p(x) of the process. How can we
determine the drift g which corresponds to this density? To give a partial answer
to this question, we assume that σ(·) is known and the drift splits into two parts
g(z) = r(z)+f (z), where r(z) is a known part and we try to compute f . Of course in the
multivariate case there is not enough information to reconstruct f uniquely. However
we may search for a minimal solution which minimizes a quadratic functional

p(z) f (z) · A−1(z)f (z) dz

(2)

for a given positive deﬁnite matrix A(z). Introducing a Lagrange multiplier function
ψ(z) for the condition that the density p fulﬁls the stationary Fokker-Planck equation
with drift g, we can derive the minimal f from the variation of the Lagrange-functional

f (z) · A−1(z)f (z) dz −

ψ(z){Lp(z) − ∇ · (f (z)p(z))} dz

(3)
where the Fokker-Planck operator L corresponding to the known drift r(z) is given by

Lp(z) = −∇ · (r(z)p(z)) +

(4)
= σ(z)σ(z)(cid:62). Variation of (3) with respect to f yields f (z) = A(z)∇ψ(z).
.
with D(z)
Inserting this solution back into (3) shows that the unknown ’potential’ ψ can be derived
from the minimization of the functional

tr

(cid:104)∇∇(cid:62)(D(z)p(z))
(cid:105)

(cid:90)

1
2

(cid:90) (cid:26)1

(cid:90)

(cid:90)

1
2

1
2

(cid:90)

(cid:27)

p(z)dz

∇ψ(z) · A(z) ∇ψ(z) + L∗ψ(z)
where L∗ is the adjoint operator of L, (4) which fulﬁls

ε[ψ] =

2

ψ(z)Lp(z)dz =

p(z)L∗ψ(z)dz

(cid:90)

and is given by

L∗ψ(z) = r(z) · ∇ψ(z) +

1
2

tr

(cid:104)
(cid:105)
D(z)∇∇(cid:62)ψ(z)

In fact, a direct minimization of (5) with respect to ψ yields
= Lp(z) − ∇ · (A(z)∇ψ(z)p(z)) = 0.
.

L[ψ]p(z)

(5)

(6)

(7)

(8)

which is the stationary Fokker-Planck equation corresponding to the density p(z) and
the drift g(z) = r(z) + A(z)∇ψ. Hence, if the drift is actually of this form, then the
minimization of (5) will give us the desired unique result. For the special case D = A = I
and r = 0 the functional (5) was introduced in the ﬁeld of machine learning as a score-
function for estimating ln p(x) up to a normalization constant [7]. This case corresponds
to an SDE for thermal equilibrium where the drift f (z) = ∇ψ(z) is the gradient of a
potential ψ and the stationary density fulﬁls p(z) ∝ e2ψ(z).

The matrix A introduces an extra degree of freedom which could be chosen using
prior knowledge of the SDE model. Of special interest are models with A = D. As we
show in Appendix A, for such models we have asymptotically ε[ψ] (cid:39) 1
T εM L[ψ], where

Variational estimation of the drift for stochastic diﬀerential equations

4

εM L is the negative log-likelihood, when the process Zt was sampled continuously in
time over a large time T . Hence if observations are dense in time a minimization of ε[ψ]
using the empirical distribution should become asymptotically equivalent to maximum
likelihood estimation. The discussion in Appendix A also gives another interpretation
of the cost function (5) for A = D. The drift given by the minima of (5) leads to
the process with path measure that is closest in relative entropy (Kullback-Leibler
divergence) rate [8, 9] to the path measure of the process with drift r(z), when p(z)
is given.

3. Minimizing the empirical functional

Our goal is to estimate ψ from data by replacing the average over the stationary density
p(z) in the functional (5) by the empirical distribution

ˆp(z) =

1
n

δ(z − zi)

(9)

where z1, . . . , zn is a random, ergodic sample drawn from this density. An obvious
possibility to construct estimators is to work with a parametric representation

n(cid:88)

i=1

K(cid:88)

k=1

ψw(z) =

wkφk(x)

(10)

where the φk are set of given ’basis’ functions. The weights wk could be determined by
minimization of the empirical version of the functional (5)

(cid:26)1

n(cid:88)

2

i=1

(cid:27)
∇ψw(zi) · A(zi) ∇ψw(zi) + L∗ψw(zi)

εemp[ψw] =

(11)

k w2

which is a quadratic form in the wk and can thus be performed in closed form. We
are however interested in the case where a representation in terms of a ﬁnite set of
basis functions is not rich enough to represent ψ. Thus we will resort to a more
general, nonparametric representation allowing for an inﬁnite set of functions φk. Since
one has only a ﬁnite number of data zi for estimation, the estimator needs to be
(cid:80)
regularized by introducing an extra penalty term. This will be chosen as a quadratic form
1
k/λk, where the λk are hyper-parameters. This penalty can also be viewed from
a pseudo-Bayesian perspective where exp{−Cεemp[ψw]} is interpreted as a likelihood
2
k/λk} as a Gaussian prior distribution over parameters wk. C can be
and exp{− 1
chosen to give diﬀerent weight to the data and to the penalty. In this interpretation,
(10) could be understood as a Gaussian process model [10] for the function ψ. As shown
in Appendix A, the likelihood interpretation becomes correct asymptotically for densely
sampled observations if A = D for which we would set C ≈ T /n being the time between
observations.

(cid:80)

k w2

2

Motivated by the Gaussian process point of view we will introduce the kernel trick
into our formalism avoiding an explicit speciﬁcation of φk and λk and assume instead

Variational estimation of the drift for stochastic diﬀerential equations

5

that these are deﬁned implicitly as orthonormal eigenfunctions and eigenvalues of a
positive deﬁnite kernel function K(z, z(cid:48)) via

K(z, z(cid:48))

.
=

λkφk(z)φk(z(cid:48))

(cid:88)

k

This can be viewed as the covariance kernel of a Gaussian process prior distribution for
functions ψ(z) [10]. Kernels can be adapted to the prior knowledge which is available
about the function ψ. This might include a known periodicity of the function, the
length scale of its typical variation, or the fact that ψ is a polynomial of a given order.
Appendix B gives a short summary of the kernels used in our experiments.

In the kernel approach the regularized functional can be written as

(cid:26)1
∇ψ(zi) · A(zi) ∇ψ(zi) + L∗ψ(zi)
(cid:90) (cid:90)

ψ(z)K−1(z, z(cid:48))ψ(z(cid:48)) dzdz(cid:48),

2

(cid:27)

C

n(cid:88)

i=1
1
2

+

(12)
where K−1(z, z(cid:48)) is the inverse of the kernel operator. One can also show that the penalty
term on the right hand side equals the so-called reproducing kernel Hilbert space (RKHS)
norm of ψ deﬁned by the kernel K. Using this formalism a nonparametric extension of
the score function approach for estimating ln p(x) was introduced in [2]. Our discussion
shows, that there are two ways for computing the estimator of ψ(z) explicitly, both
leading to the same result. The ﬁrst one is based on setting the variational derivative of
(12) equal to zero and the second uses the formalism of Gaussian process regression [10].
We will next give a derivation of this result using the ﬁrst method. Performing the
variation with respect to ψ yields

CnL[ψ]ˆp(z) +

K−1(z, z(cid:48))ψ(z(cid:48)) dz(cid:48) = 0,

where L[ψ] was deﬁned in (8). Multiplying both sides of this equation with the operator
K we get

(cid:90)

n(cid:88)

ψ(z) + C

L∗
z(cid:48)[ψ] K(z, z(cid:48))z(cid:48)=zj = 0

where the adjoint operator acts on functions h as

j=1

(cid:104)

(cid:105)
D(z(cid:48))∇∇(cid:62)h(z(cid:48))

1
2

tr

(13)

(14)

z(cid:48)[ψ]h(z(cid:48)) = (r(z(cid:48)) + A(z(cid:48))∇ψ(z(cid:48)))∇h(z(cid:48)) +
L∗
(cid:90)

We can understand (13) as a regularized version of the equation
h(z(cid:48))Lz(cid:48)[ψ]p(z(cid:48))dz(cid:48) = 0

z(cid:48)[ψ]h(z(cid:48))dz(cid:48) =

p(z(cid:48))L∗

(cid:90)

(15)
applied to the family of kernel functions hz(z(cid:48)) = K(z, z(cid:48)) when the stationary density
p is replaced by its empirical approximation ˆp (9).
Equations (13) and (14) show that if ∇ψ(z) is known at all sample points z = zi,
we can evaluate the second term and get then the function ψ(z) for all z. The gradient

Variational estimation of the drift for stochastic diﬀerential equations

6

of ψ at the data points is computed by taking the gradient of (13) and setting z = zi.
This yields the set of linear equations

∇ψ(zi) + C

L∗
z(cid:48)[ψ]∇zK(z, z(cid:48))z=zi,z(cid:48)=zj = 0

(16)
for the d × n unknowns ∇ψ(zi) which can be plugged into (13) to obtain the explicit
result for the estimator.

j=1

n(cid:88)

4. Application: Langevin dynamics
To show that the condition f (z) = A(z)∇ψ(z) includes classes of nontrivial non-
equilibrium models, we will specialize to second order (Langevin-type) SDE which
appear naturally when systems of classical mechanics are driven by deterministic and
random forces. The time evolution is described in terms of (generalized) coordinates
and velocities X, V ∈ Rd as
dXt = Vtdt,

dVt = gv(Xt, Vt)dt + σv(Xt, Vt)dWt.

(17)

The noise acts only on the acceleration and the drift for this model is of the form (gx, gv)
where gx = v is known. Hence, we may choose the matrix elements of A in (5) to be
zero except for the sub-matrix Avv which we will set to the unit matrix Avv = I for
simplicity. Thus the reduced drift vector for the velocity is assumed to be of the form
(cid:27)
gv(x, v) = rv(x, y) + ∇vψ(x, v) and the functional (5) becomes

(cid:26)

(cid:90)

ε[ψ] =

p(x, v)

L∗ψ(x, v) +

(∇vψ(x, v))2

dx dv

(18)

1
2

(cid:18)
v · ∇x + rv(x, v) · ∇v +

(cid:19)
v ∇v)

tr(Dv(x, v)∇(cid:62)

1
2

ψ(x, v),

(19)

where

L∗ψ(x, v) =

with Dv = σvσ(cid:62)
v . The integrability condition on the unknown part of the drift
fv(x, v) = ∇vφ(x, v) restricts the velocity dependency rather than its coordinate
dependency. We will specialize on dynamical systems with a position dependent external
force f (x) and a friction term which is linear in the velocity. This is given by

(cid:26)

(cid:27)

fv(x, v) = f (x) − Λv = ∇v

v · f (x) − 1
2

v · Λv

,

(20)

with a positive diagonal matrix Λ and an arbitrary (e.g. non-conservative) vector ﬁeld
f (x). Since the velocity dependency is parametric, we use a kernel which is a product
of a ﬁrst order polynomial kernel in v and an RBF kernel (B.1) in x and set r = 0 to
estimate Λ and f (·) from n pairs of observations (xi, vi).
We illustrate this method for the case of a bistable system with two locally stable
equilibria (double well model) which corresponds to the drift f (x) = −4(x − x3). We
simulated the process with diﬀusion σ = 1.3 and friction constant λ = 1.1 and generated
a data set of size n = 3000 observations with time lag τ = 0.5. We found that the
constant C in (13) did not have a strong inﬂuence on the accuracy of the estimator
and have used C = 1 throughout the experiments.
In order to optimize the length

Variational estimation of the drift for stochastic diﬀerential equations

7

Figure 1. Left: Estimates of the double well drift function f (x, v) as a function of the
coordinate x with ﬁxed velocities v. The RBF kernel uses the length scale lopt = 1.29.
Right: MSE of the estimator on hold out data (prediction error, triangles) and on
the observations (training error, circles) for the double well model as a function of
number n of observations. The lines in this log-log plot were ﬁtted using the model
MSE ∝ n−1/2. Each point represents the average over m = 5 diﬀerent data sets.

Figure 2. The ﬁgure shows the vector ﬁelds of both the true drift function given
as grey lines and the estimated drift function given as arrows. In order to enhance
visibility, we scaled the length of the vectors logarithmically.

scale hyperparameter of the RBF kernel, we randomly divided the observation into two
subsets of equal size and used a conjugate gradient optimization to minimize the cost
function (18) approximated by the hold out data.

The left of ﬁgure 1 shows the estimate fv(x, v) as a function of the state x with
the velocity v ﬁxed to three diﬀerent values. We also studied a measure of convergence
of our estimator fv to the true drift for the double well model. For that purpose we
have computed the mean squared error (MSE) for diﬀerent number n of observations,
both as training error at the observed data points and as prediction error estimate on a
hold out data set. We have used a Gaussian process with RBF kernel and length scale
l = 1.25. The data sets have been generated with diﬀusion constant σ = 1, friction
constant λ = 1.1, and time lag τ = 4. The resulting learning curves are shown in the
right of ﬁgure 1. Comparing the asymptotic power law ﬁts for both MSEs shows that,
while naturally the prediction error has a higher baseline error rate than the training
error, both are consistent with a decay of the form ≈ n−1/2.

−1.5−0.50.51.01.5−6−2246xf(x, v)v = −1v = 0v = 1lllllllllllllllllllllllllllllll5001000200050000.10.20.51.02.0Obs No.MSE−3−2−10123−3−10123Variational estimation of the drift for stochastic diﬀerential equations

8

Figure 3. Left: Snippet of the full sample path of the Cart and pole model. Right:
Estimated drift function for Cart and pole, where the red dashed line denotes the true
drift function and the black line the estimate.

So far we have assumed that the diﬀusion Dv is known.

If on the other hand,
the friction parameter Λ is known, i.e. rv = −Λv then L∗ψ(x, v) = L∗(v · f (x)) is
independent of the diﬀusion term Dv(x, v) and we can estimate f (x) without knowing
the diﬀusion. We demonstrate this estimate on a two dimensional Langevin model with
a nonconservative drift with components f (1)(x) = x(1)(1 − (x(1))2 − (x(2))2) − x(2) and
f (2)(x) = x(2)(1−(x(1))2−(x(2))2)−x(1), and friction constants λ(1,2) = 0.8. The n = 2000
four-dimensional data (position and velocity) observations were generated with constant
diﬀusion constants Dv = 9I and time lag τ = 0.5. The drift vector was estimated by
penalizing each component of f (x) independently using a polynomial kernel (B.3) of
order p = 4, assuming that the true drift is at most a polynomial of order 4. The results
are shown in ﬁgure 2.

To show that this approach also works for state dependent diﬀusion (multiplicative
noise), we consider a model of a pendulum on which gravitation and friction act as
drift terms given by f (x) = a sin x and −λv in (20). Here x is the angle relative to
the upward position and v the angular velocity. The pendulum is mounted on a cart
that is accelerated ‡ in the horizontal direction by a white noise force. This leads to
an additional stochastic angular acceleration with diﬀusion Dv = (σ cos(x))2. For the
simulation, we used a data set of n = 2000 observations with time lag τ = 0.25, diﬀusion
σ = 1, a = 9.81 and λ = 0.05. As kernel function we chose a periodic kernel (B.2) with
hyperparameter lPer = 1.2. One can clearly see from the left of ﬁgure 3 that most of
the time the pendulum stays in the downward position and only occasionally crosses
the upright position (corresponding to x = 0). Nevertheless, the right panel of ﬁgure
3 shows that regularization with the periodic kernel leads to an excellent estimation of
the drift for all values of x.

One might wonder if the estimation of the drift could have also be achieved
by a kernel density approach. While for a general model (1) with drift f (z) =
r(z) + A(z)∇ψ(z) there does not seem to be a way of expressing f (z) in terms of p(z)
in closed form, a somewhat complicated expression can be given for Langevin equations
‡ This toy model is known as cart and pole, frequently used to test control methods for stabilizing the
pendulum in the upright position [11].

0246810−404tX(t)lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll0246810−55tV(t)lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll−6−4−20246−10−50510xf(x)Variational estimation of the drift for stochastic diﬀerential equations

9

d(cid:88)

∂E[v(i)v(j)|x]

d(cid:88)

with drifts of the form (20). Multiplying the Fokker-Planck equation for the process
(17) with a component v(i) of the velocity vector and integrating over v, one obtains the
following explicit representation for the drift

E[v(i)v(j)|x]

∂ ln p(x)

∂x(j) − E[r(i)|x],

f (i)(x) =

+

j=1

j=1

∂x(j)

(21)
where components of vectors are denoted by superscripts and E[·|x] denote conditional
expectations. This shows that, in general, one would need not only a KDE for estimating
p(x) but also a nonparametric regression method for estimating the conditional
expectations as a function of x. Of course, for the equilibrium case where f (x) = ∇φ
and Dv ∝ Σ, r = −Λv where Λ and Σ are diagonal matrices which satisfy 2λi/σ2
i = β,
which is the inverse temperature, (21) simpliﬁes because one has E[v(i)v(j)|x] = 1
2β δij
and E[r(i)|x] = 0. For this case, the velocity samples vi are not needed.

5. Generalization to other noise processes

For applications where noise is used as a part of an external control signal acting on
a dynamical system, the assumption of white noise is not realistic, because its non-
decaying high frequency components are, in practice, ﬁltered out in the control circuit.
Hence, we would like to include other processes, e.g. colored noise or a noise source with
a ﬁnite state space. To adapt our method to this situation, we replace the white noise
σv(x, v)dW in (17) by utdt where ut is a Markov process, which is included in the state
variable z = (x, v, u) and observed at the same time times as X and V . Our formalism
does not change when u is a diﬀusion process itself, because the entire system can be
described by a Fokker-Planck equation for the density p(x, v, u). But it is also possible
to include other Markov processes such as jump processes as noise sources. We just
have to replace the Fokker-Planck equation by the appropriate Master equation in the
deﬁnition (4). We will illustrate this idea for ut being a random telegraph process [12]
that switches with equal rates γ between u = ±1. We study a one-dimensional system
x, v, u ∈ R with drift given by gv(x, v) = −λv + f (x) with a known friction constant λ.
The Master equation [12] for the stationary density is given by

− ∂xvp(x, v, u) − ∂v [(f (x) − λv + u)p(x, v, u)]
+ γ (p(x, v,−u) − p(x, v, u)) = 0

(22)

The drift f can be estimated by the minimization of the functional (18), when we use
the adjoint operator given by

L∗ψ(x, v, u) = {v∂x + (u − λv)∂v} ψ(x, v, u) + γ (ψ(x, v,−1) − ψ(x, v, 1))

The parameterization ψ(x, v) = vf (x) leads to the functional

(cid:90)

(cid:88)

u=±1

ε[f ] =

1
2

(cid:110)
f 2(x) + 2f(cid:48)(x)v2 + 2f (x)(u − λv)

(cid:111)

p(x, v, u)

dxdv

(23)

to be minimized with respect to f . Experiments (not included here) for the cart and
pole model show that this method achieves similar performance as the one shown in
ﬁgure 3.

Variational estimation of the drift for stochastic diﬀerential equations

10

6. Discussion and Outlook

We have presented a method for a nonparametric estimation of the drift of certain
types of stochastic diﬀerential equations from the empirical density alone. The method
is not related to kernel density estimation and can be applied to cases where the use
of a KDE would not be simple or impossible. The method should be of interest for
situations where external noise is used to explore the state space of a mechanical system
in order to learn the deterministic part of the forces which can be used to later control
the system. On the other hand, one might use our variational approach for solving a
speciﬁc type of stochastic control problem [9]: We would be able to compute a state
dependent control f (z) which has to be added to the known drift r(z) of a system such
that a new desired stationary density p(z) will be reached.

In future work we will explore diﬀerent possibilities to increase the applicability of
our methods. We will investigate carefully the role of the matrix valued model parameter
A in (4) but also try to generalize the functional (5) by including other types of operators.
E.g. a second derivative of a convex potential ψ could be used to estimate the diﬀusion
for known drift. It will also be interesting to analyze the theoretical properties of the
estimator, especially the asymptotic convergence rate towards the true drift function.

Another question is how to lift the restriction that all coordinates of the random
state vector z need to be observed jointly. For the Langevin type equations with a drift
of the form (20) it would be interesting to see if the method could be generalized to
estimating a drift f (x) based on coordinate observations xi alone. For potentials of
the type v · f (x) one can integrate over the velocities in (18) to obtain a functional
which depends on f (x), p(x) and conditional moments of the velocities (see (21)).
For an equilibrium problem, these conditional moments are constant and known and
the velocity observations are not needed. For the general case one could use the
temporal order of coordinate observations to obtain a preliminary approximation to
the unobserved velocities. An initial estimate of the drift f (x) could then be derived
by a minimization of the functional (18). This estimate could be used to create new
velocity samples and estimates for conditional velocity moments by performing forward
sampling of the SDE (17) and the method could be iterated. Preliminary experiments
using this iterative procedure are promising but we do not yet have conditions on the
convergence of such a procedure.

Acknowledgments

This work was supported by the European Community’s Seventh Framework Pro-
gramme (FP7, 2007-2013) under the grant agreement 270327 (CompLACS).

Variational estimation of the drift for stochastic diﬀerential equations

11

Appendix A. Likelihood for dense observations

We will derive the likelihood function for the drift g of an SDE assuming that we have
access to a dense path Z0:T of observations in a time window from t = 0 to t = T .
Discretizing time into small intervals of length ∆t and using the fact that for ∆t → 0,
the transition density of (1) becomes Gaussian, we ﬁnd that the part of the negative
log-likelihood (NLL) which depends on the drift function g can be approximated by

(cid:88)

(cid:110)||g(Zt)||2∆t − 2(cid:104)g(Zt), (Zt+∆t − Zt)(cid:105)(cid:111)

+const(A.1)

−ln p(Z0:T|g) (cid:39) 1
2

t

where we have introduced the inner product (cid:104)u, v(cid:105) .
= u(cid:62)D−1v and the corresponding
squared norm ||u||2 .
= u(cid:62)D−1u. For ∆t → 0, the second sum becomes a Ito stochastic
integral [12]. If the drift can be written as g = r +D∇ψ where r is a known function and
we are only interested in estimating ψ, we can transform the Ito integral into an ordinary
time integral using Ito’s formula. The part of the NLL which contains ψ becomes

(cid:90) T

εM L[ψ] =

1
2

{∇ψ · D ∇ψ dt + 2r · ∇ψ dt − 2∇ψ · dZt}

(cid:110)∇ψ · D ∇ψ + 2r · ∇ψ + tr(D∇∇(cid:62)ψ)
(cid:111)

0

dt − ψ(ZT ) + ψ(Z0)

(A.2)

(cid:90) T

0

=

1
2

We will now assume that for large T , the process becomes stationary with density p(z).
We can then replace the time integral by an integral over p. For a mathematical rigorous
treatment see e.g [5]. Neglecting the contribution from the boundary terms in (A.2) for
large T we arrive at

(cid:90) (cid:110)∇ψ · D ∇ψ + 2r · ∇ψ + tr(D∇∇(cid:62)ψ)

(cid:111)

p(z)dz.

(A.3)

εM L[ψ] (cid:39) T
2

Using the Gaussian form of the transition density for short times ∆t it can also
be shown that the relative entropy or Kullback-Leibler (KL) divergence between the
path probabilities for two diﬀusion processes but diﬀerent drifts g(z) and r(z), where
g(z) = r(z) + f (z) is given by

D(p(Z0:T|g)||p(Z0:T|r) =

dt

pt(z)f (z) · D−1(z)f (z)dz

(cid:90)

(cid:90) T

0

assuming they have the same diﬀusion term D(z) and the same non-random initial state
(see e.g. [8]). Here pt(z) is the marginal density of the process with drift g at time t.
Hence, assuming that the process becomes stationary with density p(z), we get for the
relative entropy rate
1
T

D(p(Z0:T|g)||p(Z0:T|r) =

p(z)f (z) · D−1(z)f (z)dz.

lim
T→∞

(A.4)

(cid:90)

A comparison with (3) shows that for A = D the minimization of (5) leads to a process
with given stationary density that is closest to the process with drift r(z) in relative
entropy. Hence, this may be understood as a generalized maximum entropy (minimum
relative entropy) solution where the stationary density is given as a constraint.

Variational estimation of the drift for stochastic diﬀerential equations

12

Appendix B. Kernel functions

For the experiments we have used the following kernels:

• The radial basis function (RBF) kernel

(cid:32)
−(x − y)(cid:62)(x − y)

(cid:33)

,

(B.1)

KRBF(x, y) = exp

This has the length scale lRBF as a hyper parameter and is used for estimating
smooth functions.

• The (one-dimensional) periodic kernel

2l2

RBF

(cid:16) x−y

(cid:17)2

2

l2
Per



−2 sin
(cid:17)p

(cid:16)

KPer(x, y) = exp

is used for estimating smooth periodic functions.

• The polynomial kernel of degree p

KPoly(x, y) =

1 + x(cid:62)y

(B.2)

(B.3)

is used for estimating functions which are polynomials with degrees at most p.

References

[1] Iacus S M 2008 Simulation and Inference for Stochastic Diﬀerential Equations (Springer)
[2] Sriperumbudur B K, Fukumizu K, Kumar R, Gretton A and Hyv¨arinen A 2014 Density estimation

in inﬁnite dimensional exponential families arXiv:1312.3516v3

[3] Gottschall J and Peinke J 2008 New Journal of Physics 10 083034
[4] Honisch C and Friedrich R 2011 Physical Review E 83 066701
[5] Papaspiliopoulos O, Pokern Y, Roberts G O and Stuart A M 2012 Biometrika 99 511–531
[6] Ruttor A, Batz P and Opper M 2013 Approximate gaussian process inference for the drift function
in stochastic diﬀerential equations Advances in Neural Information Processing Systems 26 ed
Burges C, Bottou L, Welling M, Ghahramani Z and Weinberger K (Curran Associates, Inc.) pp
2040–2048

[7] Hyv¨arinen A 2005 Journal of Machine Learning Research 6 695–709
[8] Archambeau C, Opper M, Shen Y, Cornford D and Shawe-Taylor J 2008 Variational inference for
diﬀusion processes Advances in Neural Information Processing Systems 20 ed Platt J, Koller D,
Singer Y and Roweis S (Cambridge, MA: MIT Press) pp 17–24

[9] Chernyak V Y, Chertkov M, Bierkens J and Kappen H J 2013 Journal of Physics A: Mathematical

and Theoretical 47 022001

[10] Rasmussen C E and Williams C K I 2006 Gaussian Processes for Machine Learning (MIT Press)
[11] Deisenroth M P, Rasmussen C E and Peters J 2009 Neurocomputing 72 1508–1524
[12] Gardiner C W 1996 Handbook of Stochastic Methods 2nd ed (Berlin: Springer)

