6
1
0
2

 
r
a

 

M
4
1

 
 
]

C
D
.
s
c
[
 
 

1
v
4
3
2
4
0

.

3
0
6
1
:
v
i
X
r
a

Convergecast and Broadcast by Power-Aware Mobile

Agents∗

Julian Anaya1, Jérémie Chalopin2, Jurek Czyzowicz1,

Arnaud Labourel2, Andrzej Pelc1,†, Yann Vaxès2

1Université du Québec en Outaouais, C.P. 1250, Gatineau, Qc. J8X 3X7 Canada.

E-mails: ingjuliananaya@gmail.com, jurek@uqo.ca, pelc@uqo.ca
2 LIF, CNRS & Aix-Marseille University, 13288 Marseille, France.

E-mails: {jeremie.chalopin,arnaud.labourel,yann.vaxes}@lif.univ-mrs.fr

March 15, 2016

Abstract

A set of identical, mobile agents is deployed in a weighted network. Each agent has a battery – a
power source allowing it to move along network edges. An agent uses its battery proportionally to the
distance traveled. We consider two tasks : convergecast, in which at the beginning, each agent has some
initial piece of information, and information of all agents has to be collected by some agent; and broadcast
in which information of one speciﬁed agent has to be made available to all other agents. In both tasks,
the agents exchange the currently possessed information when they meet.

The objective of this paper is to investigate what is the minimal value of power, initially available to
all agents, so that convergecast or broadcast can be achieved. We study this question in the centralized
and the distributed settings. In the centralized setting, there is a central monitor that schedules the
moves of all agents. In the distributed setting every agent has to perform an algorithm being unaware
of the network.

In the centralized setting, we give a linear-time algorithm to compute the optimal battery power and
the strategy using it, both for convergecast and for broadcast, when agents are on the line. We also show
that ﬁnding the optimal battery power for convergecast or for broadcast is NP-hard for the class of trees.
On the other hand, we give a polynomial algorithm that ﬁnds a 2-approximation for convergecast and a
4-approximation for broadcast, for arbitrary graphs.

In the distributed setting, we give a 2-competitive algorithm for convergecast in trees and a 4-
competitive algorithm for broadcast in trees. The competitive ratio of 2 is proved to be the best for
the problem of convergecast, even if we only consider line networks. Indeed, we show that there is no
(2 − )-competitive algorithm for convergecast or for broadcast in the class of lines, for any  > 0.

Introduction

1
1.1 The model and the problem
A set of agents is deployed in a network represented by a weighted graph G. An edge weight is a positive
real representing the length of the edge, i.e., the distance between its endpoints along the edge. The agents
start simultaneously at diﬀerent nodes of G. Every agent has a battery: a power source allowing it to move
∗A preliminary version of this paper appeared in Proc. 26th International Symposium of Distributed Computing (DISC
†Partially supported by NSERC discovery grant and by the Research Chair in Distributed Computing at the Université du

2012).

Québec en Outaouais.

1

in a continuous way along the network edges. An agent may stop at any point of a network edge (i.e. at
any distance from the edge endpoints, up to the edge weight). The movements of an agent use its battery
proportionally to the distance traveled. We assume that all agents move at the same speed that is equal to
one, i.e., we can interchange the notions of the distance traveled and the time spent while traveling. In the
beginning, the agents start with the same amount of power noted P , allowing all agents to travel the same
distance P .

We consider two tasks: convergecast, in which at the beginning, each agent has some initial piece of
information, and information of all agents has to be collected by some agent, not necessarily predetermined;
and broadcast in which information of one speciﬁed agent has to be made available to all other agents. In
both tasks, agents notice when they meet (at a node or inside an edge) and they exchange the currently held
information at every meeting.

The task of convergecast is important, e.g., when agents have partial information about the topology of
the network and the aggregate information can be used to construct a map of it, or when individual agents
hold measurements performed by sensors located at their initial positions and collected information serves to
make some global decision based on all measurements. The task of broadcast is used, e.g., when a preselected
leader has to share some information with others agents in order to organize their collaboration in future
tasks.

Agents try to cooperate so that convergecast (respectively broadcast) is achieved with the smallest possi-
OP T ), i.e., minimizing the maximum distance traveled

ble agent’s initial battery power P c
by an agent. We investigate these two problems in two possible settings, centralized and distributed.

OP T (respectively P b

In the centralized setting, the optimization problems must be solved by a central authority knowing the
network and the initial positions of all the agents. We call strategy a ﬁnite sequence of movements executed by
the agents. During each movement, starting at a speciﬁc time, an agent walks between two points belonging
to the same network edge. A strategy is a convergecast strategy if the sequence of movements results in one
agent getting the initial information of every agent. A strategy is a broadcast strategy if the sequence of
movements results in all agents getting the initial information of the source agent. We consider two diﬀerent
versions of the problem : the decision problem, i.e., deciding if there exists a convergecast strategy or a
broadcast strategy using power P (where P is the input of the problem) and the optimization problem, i.e.,
computing the smallest amount of power that is suﬃcient to achieve convergecast or broadcast.

In the distributed setting, the task of convergecast or broadcast must be approached individually by
each agent. Each agent is unaware of the network, of its position in the network and of the positions (or
even the presence) of any other agents. The agents are anonymous and they execute the same deterministic
algorithm. Each agent has a very simple sensing device allowing it to detect the presence of other agents at
its current location in the network. Each agent is also aware of the degree of the node at which it is located,
as well as the port through which it enters a node, called an entry port. We assume that the ports of a node
of degree d are represented by integers 1, 2, . . . , d. Agents can meet at a node or inside an edge. When two
or more agents meet at a node, each of them is aware of the direction from which the other agent is coming,
i.e., the last entry port of each agent.

Since the measure of eﬃciency in this paper is the battery power (or the maximum distance traveled by
an agent, which is proportional to the battery power used) we do not try to optimize the other resources (e.g.
global execution time, local computation time, memory size of the agents, communication bandwidth, etc.).
In particular, we conservatively suppose that, whenever two agents meet, they automatically exchange the
entire information they hold (rather than the new information only). This information exchange procedure
is never explicitly mentioned in our algorithms, supposing, by default, that it always takes place when a
meeting occurs. The eﬃciency of a distributed solution is expressed by the competitive ratio, which is the
worst-case ratio of the amount of power necessary to solve the convergecast or the broadcast problem by the
distributed algorithm with respect to the amount of power computed by the optimal centralized algorithm,
which is executed for the same agents’ initial positions.

It is easy to see, that in the optimal centralized solution for the case of the line and the tree, the original
network may be truncated by removing some portions and leaving only the connected part of it containing
all the agents (this way all leaves of the remaining tree contain initial positions of agents). We make this

2

assumption also in the distributed setting, since no ﬁnite competitive ratio is achievable if this condition is
dropped. Indeed, two nearby anonymous agents inside a long line need to travel, in the worst case, a long
distance to one of its endpoints in order to meet.

1.2 Related work
Rapidly developing network and computer industry fueled the research interest in mobile agents computing.
Mobile agents are often interpreted as software agents, i.e., programs migrating from host to host in a
network, performing some speciﬁc tasks. However, the recent developments in computer technology bring
up problems related to physical mobile devices. These include robots or motor vehicles and various wireless
gadgets. Examples of agents also include living beings: humans (e.g. soldiers in the battleﬁeld or disaster
relief personnel) or animals (e.g. birds, swarms of insects).

In many applications the involved mobile agents are small and have to be produced at low cost in massive
numbers. Consequently, in many papers, the computational power of mobile agents is assumed to be very
limited and feasibility of some important distributed tasks for such collections of agents is investigated.
For example [6] introduced population protocols, modeling wireless sensor networks by extremely limited
ﬁnite-state computational devices. The agents of population protocols move according to some mobility
pattern totally out of their control and they interact randomly in pairs. This is called passive mobility,
intended to model, e.g., some unstable environment, like a ﬂow of water, chemical solution, human blood,
wind or unpredictable mobility of agents’ carriers (e.g. vehicles or ﬂocks of birds). On the other hand,
[38] introduced anonymous, oblivious, asynchronous, mobile agents which cannot directly communicate, but
they can occasionally observe the environment. Gathering and convergence [5, 21, 22, 23], as well as pattern
formation [24, 27, 38, 39] were studied for such agents.

Apart from the feasibility questions for limited agents, the optimization problems related to the eﬃcient
usage of agents’ resources have been also investigated. Energy management of (not necessarily mobile)
computational devices has been a major concern in recent research papers (cf. [1]). Fundamental techniques
proposed to reduce power consumption of computer systems include power-down strategies (see [1, 8, 31]) and
speed scaling (introduced in [40]). Several papers proposed centralized [19, 37, 40] or distributed [1, 4, 8, 31]
algorithms. However, most of this research on power eﬃciency concerned optimization of overall power used.
Similar to our setting, assignment of charges to the system components in order to minimize the maximal
charge has a ﬂavor of another important optimization problem which is load balancing (cf. [12]).

In wireless sensor and ad hoc networks the power awareness has been often related to the data commu-
nication via eﬃcient routing protocols (e.g.
[4, 37]. However in many applications of mobile agents (e.g.
those involving actively mobile, physical agents) the agent’s energy is mostly used for it’s mobility purpose
rather than communication, since active moving often requires running some mechanical components, while
communication mostly involves (less energy-prone) electronic devices. Consequently, in most tasks involving
moving agents, like exploration, searching or pattern formation, the distance traveled is the main optimiza-
tion criterion (cf. [2, 3, 10, 13, 17, 18, 25, 26, 28, 34]). Single agent exploration of an unknown environment
has been studied for graphs, e.g. [2, 25], or geometric terrains, [13, 18].

While a single agent cannot explore a graph of unknown size unless pebble (landmark) usage is permitted
(see [16]), a pair of robots are able to explore and map a directed graph of maximal degree d in O(d2n5)
time with high probability (cf.
[15]). In the case of a team of collaborating mobile agents, the challenge
is to balance the workload among the agents so that the time to achieve the required goal is minimized.
However this task is often hard (cf. [29]), even in the case of two agents in a tree, [9]. On the other hand,
the authors of [28] study the problem of agents exploring a tree, showing O(k/ log k) competitive ratio of
their distributed algorithm provided that writing (and reading) at tree nodes is permitted.

Assumptions similar to our paper have been made in [10, 18, 26] where the mobile agents are constrained
to travel a ﬁxed distance to explore an unknown graph [10, 18], or tree [26]. In [10, 18] a mobile agent has to
return to its home base to refuel (or recharge its battery) so that the same maximal distance may repeatedly
be traversed. [26] gives an 8-competitive distributed algorithm for a set of agents with the same amount of
power exploring the tree starting at the same node.

3

The convergecast problem is sometimes viewed as a special case of the data aggregation question (e.g.
[33, 35]) and it has been studied mainly for wireless and sensor networks, where the battery power usage
is an important issue (cf. [32, 7]). Recently [20] considered the online and oﬄine settings of the scheduling
problem when data has to be delivered to mobile clients while they travel within the communication range
of wireless stations.
[32] presents a randomized distributed convergecast algorithm for geometric ad-hoc
networks and study the trade-oﬀ between the energy used and the latency of convergecast. The broadcast
problem for stationary processors has been extensively studied both for the message passing model, see e.g.
[11], and for the wireless model, see e.g.
[14]. To the best of our knowledge, the problem of the present
paper, when the mobile agents perform convergecast or broadcast by exchanging the held information when
meeting, while optimizing the maximal power used by a mobile agent, has never been investigated before.

1.3 Our results
In the centralized setting, we give a linear-time algorithm to compute the optimal battery power and the
strategy using it, both for convergecast and for broadcast, when agents are on the line. We also show that
ﬁnding the optimal battery power for convergecast or for broadcast is NP-hard for the class of trees. In fact,
the respective decision problem is strongly NP-complete. On the other hand, we give a polynomial algorithm
that ﬁnds a 2-approximation for convergecast and a 4-approximation for broadcast, for arbitrary graphs.

In the distributed setting, we give a 2-competitive algorithm for convergecast in trees and a 4-competitive
algorithm for broadcast in trees. The competitive ratio of 2 is proved to be the best for the problem of
convergecast, even if we only consider line networks. Indeed, we show that there is no (2 − )-competitive
algorithm for convergecast or for broadcast in the class of lines, for any  > 0.

The following table gives the summary of our results.

Problems

Setting

Centralized

Distributed

Convergecast

Broadcast

• linear-time algorithm to compute optimal battery power and strategy on lines
• proof that the above problem is NP-hard on trees
• polynomial 2-approximation on arbi-
trary graphs
• 2-competitive algorithm for trees
• proof that there is no (2−)-competitive algorithm
on lines, for any  > 0

• polynomial 4-approximation on arbi-
trary graphs
• 4-competitive algorithm for trees

Table 1: Summary of our results

Roadmap

In Section 2, we show that we can restrict the search for the optimal strategy for convergecast or broad-
cast on the line to some smaller subclass of strategies called regular strategies. In Section 3, we present
our centralized algorithms for convergecast and broadcast on lines. Section 4 is devoted to centralized con-
vergecast and broadcast on trees and graphs. In Section 5, we investigate convergecast and broadcast in the
distributed setting. Section 6 contains conclusions and open problems.

2 Regular strategies for convergecast and broadcast on lines
In this section, we show that if we are given a convergecast (respectively broadcast) strategy for some
initial positions of agents in the line, then we can always modify it in order to get another convergecast
(respectively broadcast) strategy, using the same amount of maximal power for every agent, satisfying some
simple properties. Such strategies will be called regular. These observations permit to restrict the search for
the optimal strategy to some smaller and easier to handle subclass of strategies.

4

We order agents according to their positions on the line. Hence we can assume w.l.o.g., that agent ai,
for 1 ≤ i ≤ n is initially positioned at point P os[i] of the line of length (cid:96) and that 0 ≤ P os[1] < P os[2] <
. . . < P os[n] ≤ (cid:96). The set P os[1 : n] will be called a conﬁguration for the line of length (cid:96).
2.1 Regular carry strategies
Given a conﬁguration P os[1 : n], a starting point s, a target point t (s < t), and an amount of power P , we
want to know if there exists a strategy S for the agents enabling them to move the information from s to t so
that the amount of power spent by each agent is at most P . Strategies that move information from point s to
point t will be called carry strategies for (P os[1 : n], s, t, P ). We restrict attention to conﬁgurations P os[1 : n]
such that |s − P os[1]| < P and |t − P os[n]| < P because otherwise either P os[1] (respectively P os[n]) is
useless or it is impossible to carry information from s to t. A regular carry strategy for (P os[1 : n], s, t, P ) is
the set of moves for agents a1, a2, . . . , an deﬁned as follows: agent ai ﬁrst goes back to a point bi ≤ P os[i],
getting there the information from the previous agent (except a1 that has to go to s), then it goes forward
to a point fi ≥ bi. Moreover, we require that each agent travels the maximal possible distance, i.e., it spends
all its power.

Lemma 1. If there exists a carry strategy for (P os[1 : n], s, t, P ), then there exist the following two regular
carry strategies.

The pull strategy that can be computed iteratively (in linear time) starting with the last agent:
1. b1 ≤ s, fn = t,
2. bi = fi−1,∀2 ≤ i ≤ n,
3. fi = P + 2bi − P os[i] ≥ bi,∀1 ≤ i ≤ n.
The push strategy that can be computed iteratively (in linear time) starting with the ﬁrst agent:
1. b1 = min{P os[1], s}, fn ≥ t,
2. bi = min(fi−1, P os[i]),∀2 ≤ i ≤ n,
3. fi = P + 2bi − P os[i] ≥ bi,∀1 ≤ i ≤ n.

Proof. We ﬁrst show that there exists a pull strategy. Consider (P os[1 : n], s, t, P ) with the minimum number
of agents such that there exists a carry strategy, but no pull strategy. We consider the smallest value s such
that (P os[1 : n], s, t, P ) admits a carry strategy but no pull strategy.

If P os[1] < s, then either P os[1] + P < s, or P os[1] + P ≥ s. In the ﬁrst case, a1 cannot move the
information between s and t, and then (P os[2 : n], s, t, P ) admits a carry strategy but not a pull strategy
and has fewer agents. In the second case, S is also a carry strategy for (P os[1 : n], P os[1], t, P ) and there is
no pull strategy for (P os[1 : n], P os[1], t, P ), contradicting our choice of s.
Hence, we may suppose that P os[1] ≥ s. Since there exists a carry strategy S, let ai be the ﬁrst agent
that reaches s. The rightmost point where ai can move the information from s is s(cid:48) = 2s + P − P os[i]. Since
S is a carry strategy, when considering all the agents except i, S is a carry strategy for (P os[S \{i}], s(cid:48), t, P ).
By minimality of the number of agents, the pull strategy solves the subproblem on (P os[S \ {i}], s(cid:48), t, P ).
Consequently, we can assume that S is a pull strategy on (P os[S \{i}], s(cid:48), t, P ). If i = 1, by minimality of s,
we have s(cid:48) = b2 and thus S is a pull strategy which is a contradiction. Hence, suppose that i > 1. Note that
if P os[i] = P os[1], we can exchange the roles of ai and a1 and we are in the previous case. Hence, suppose
that P os[i] > P os[1] and let [b1, f1] be the interval that a1 traverses with the information when S is applied;
by minimality of s, b1 = s(cid:48) and consequently we have P = P os[i] + b1 − 2s = P os[1] + f1 − 2b1, and thus
s = (2P os[i]+P os[1]+f1−3P )/4. Consider now the strategy where we exchange the roles of a1 and ai: a1 gets
the information from s, gives it to ai, and ai goes to f1. More formally, let f(cid:48)
i = f1, b(cid:48)
i − P )/2,
f(cid:48)
1 = b(cid:48)
1 and s(cid:48)
1 and the ﬁrst part of the proof,

1 = (P os[1] + f(cid:48)

i = (P os[i] + f(cid:48)

i and b(cid:48)

1 − P )/2. From our deﬁnition of f(cid:48)

5

1, t, P ). However, b(cid:48)

there exists a carry strategy for (P os[1 : n], b(cid:48)
s + (P os[1] − P os[i])/4 < s, contradicting the minimality of s.
on (P os[1 : n], s, t, P ).

1 = (2P os[1] + P os[i] + f1 − 3P )/4 =
Consequently, if there exists a carry strategy S for (P os[1 : n], s, t, P ), then there exists a pull strategy
Now suppose that (P os[1 : n], s, t, P ) admits a carry strategy. From the ﬁrst part of the proof, we
know that it admits a pull strategy. The push strategy for (P os[1 : n], s, t, P ) can be obtained inductively
from the pull strategy. Let [bi, fi] for i = 1, ..., n be the set of intervals that induces the pull strategy for
(P os[1 : n], s, t, P ). Notice that [bi, fi] for i = 1, ..., n− 1 induces the pull strategy for (P os[1 : n− 1], s, bn, P ).
By induction, there exists a set of intervals [b(cid:48)
i ] that induces a push strategy for (P os[1 : n−1], s, bn, P ) with
f(cid:48)
n = min{P os[n], f(cid:48)
n−1 ≥ bn. We deﬁne b(cid:48)
n−1 ≥ bn, we deduce
that f(cid:48)
Remark 1. Note that the pull strategy is uniquely deﬁned by a conﬁguration P os[1 : n], a target point t, and
an amount of power P and enables to compute the smallest s such that (P os[1 : n], s, t, P ) admits a carry
strategy.

i, f(cid:48)
n−1} and f(cid:48)
n ≥ fn ≥ t and therefore the set of intervals [b(cid:48)

i ] induces a push strategy for (P os[1 : n], s, t, P ).

Similarly, the push strategy is uniquely deﬁned by a conﬁguration P os[1 : n], a starting point s, and an
amount of power P and enables to compute the largest t such that (P os[1 : n], s, t, P ) admits a carry strategy.

n = P + 2b(cid:48)
i, f(cid:48)

n − P os[n]. Since b(cid:48)

n ≥ f(cid:48)

Note that carry strategies are deﬁned for the target t larger than the starting point s. A carry strategy
will be called reverse if the target t is smaller than s and all moves to the right are replaced by moves to the
left and vice-versa.

2.2 Regular convergecast strategies
We now deﬁne the notion of a regular convergecast strategy for P os[1 : n] on the segment [0, (cid:96)], using power
at most P . Without loss of generality, we suppose that P os[1] = 0 and P os[n] = (cid:96). Intuitively, a regular
convergecast strategy divides the set of all agents into the set of left agents and the set of right agents such
that left agents execute a push strategy from P os[1] and right agents execute a reverse push strategy from
P os[n].

More formally, a regular convergecast strategy is given by a partition of the agents into two sets LR =
{ai | i ≤ p} and RL = {ai | i > p} for some p, and by two points bi, fi of segment [0, (cid:96)] for each agent ai,
such that
(1) if ai ∈ LR, bi = min{fi−1, P os[i]} and fi = 2bi + P − P os[i],
(2) if ai ∈ RL, bi = max{fi+1, P os[i]} and fi = 2bi − P − P os[i],
(3) FLR = max{fi | ai ∈ LR} ≥ FRL = min{fi | ai ∈ RL}.

Suppose that we are given a partition of the agents into two disjoint sets LR and RL and values bi, fi for
each agent ai satisfying conditions (1)-(3). Then the following moves deﬁne a regular convergecast strategy:
ﬁrst, every agent ai ∈ LR ∪ RL moves to bi; subsequently, every agent in LR moves to fi once it learns
the initial information of a1; then, every agent in RL moves to fi once it learns the initial information of
an. Let ak be an agent from LR such that fk is maximum. Once ak has moved to fk, it knows the initial
information of all the agents ai such that bi ≤ fk. If fk ≥ (cid:96), convergecast is achieved. Otherwise, since
fk = max{fi | ai ∈ LR} ≥ min{fi | ai ∈ RL}, we know that there exists an agent aj ∈ RL such that
fj ≤ fk < bj. When aj reaches fk it knows the initial information of all the agents such that bi ≥ fk and
thus, aj and ak know the initial information of all agents, which accomplishes convergecast.

The following lemma shows that we can restrict attention to regular convergecast strategies.

Lemma 2. If there exists a convergecast strategy for a conﬁguration P os[1 : n] using power at most P then
there exists a regular convergecast strategy for the conﬁguration P os[1 : n] using power at most P .

6

Proof. Consider a convergecast strategy S for a conﬁguration P os[1 : n] using power at most P . Suppose
that convergecast occurred at time t at some point q. If an agent ai does not get the initial information of a1,
then at time t it must have been in the segment [q, P os[n]]. Hence, by time t, it must have learned the initial
information of an. It follows that every agent ai, for 1 < i < n, must learn either the initial information of
agent a1 or of an. Therefore, we can partition the set of agents performing a convergecast strategy into two
subsets LR and RL, such that each agent ai ∈ LR learns the initial information of agent a1 before learning
the initial information of agent an (or not learning at all the information of an). All other agents belong to
RL. We denote by [bi, fi] the interval of all points visited by ai ∈ LR and by [fj, bj] the interval of points
visited by aj ∈ RL.
Let FLR = max{fi | ai ∈ LR} and FRL = min{fj | aj ∈ RL}. Since S is a convergecast strategy, we
have FLR > FRL. Observe that the agents in LR move the initial information of a1 from P os[1] to FLR
and that the agents in RL move the initial information of an from P os[n] to FRL. From Lemma 1, we can
assume that the agents in LR (resp. RL) execute a push strategy (resp. a reverse push strategy) and thus
conditions (1)-(3) hold.

i = min{fLR(i + 1), P os[i]}, b(cid:48)

Suppose now that there exists an agent ai ∈ RL such that ai+1 ∈ LR. Let fRL(i) = min{fj | aj ∈ RL, j >
i} and fLR(i + 1) = max{fj | aj ∈ LR, j < i}; note that bi = max{fRL(i), P os[i]} and bi+1 = min{fLR(i +
1), P os[i + 1]}. Consider the strategy where we exchange the roles of ai and ai+1, i.e., we put ai ∈ LR and
ai+1 ∈ RL. Let b(cid:48)
i + P − P os[i] and
i+1 = 2b(cid:48)
f(cid:48)
If fRL(i) ≤ P os[i + 1], then f(cid:48)
i+1 = P os[i + 1] − P ≤ bi+1 ≤ fLR(i + 1). If fLR(i + 1) ≥ P os[i], then
f(cid:48)
i = P os[i] + P ≥ bi ≥ fRL(i). In both cases, we still have a convergecast strategy.
If fRL(i) ≥ P os[i + 1] and fLR(i + 1) ≤ P os[i], then f(cid:48)
i = 2fLR(i + 1) + P − P os[i] > 2fLR(i + 1) + P −
P os[i + 1] = fi+1, and f(cid:48)
i+1 = 2fRL(i) − P − P os[i + 1] < 2fRL(i) − P − P os[i] = fi. Consequently, we still
have a convergecast strategy.

i+1 = max{fRL(i), P os[i + 1]}, f(cid:48)

i+1 − P − P os[i + 1].

i = 2b(cid:48)

Applying this exchange a ﬁnite number of times, we get a regular convergecast strategy.

2.3 Regular broadcast strategies
We now deﬁne the notion of a regular broadcast strategy for P os[1 : n] where the source agent is ak, on
the segment [0, (cid:96)], using power at most P . Without loss of generality, we suppose that P os[1] = 0 and
P os[n] = (cid:96). Intuitively, a regular broadcast strategy divides the set of all agents into the set of left agents
and the set of right agents such that left agents execute a reverse pull strategy from P os[k] and right agents
execute a pull strategy from P os[k].

More formally, a regular broadcast strategy is given by points bi, fi of segment [0, (cid:96)] deﬁned for each

agent ai such that

1. b1 = f1 = P os[1] + P , bn = fn = P os[n] − P ,
2. if 1 < i < k, fi = bi−1 and bi = (fi + P os[i] + P )/2,
3. if k < i < n, fi = bi+1 and bi = (fi + P os[i] − P )/2,
4. {bk, fk} = {bk−1, bk+1} and |2bk − P os[k] − fk| ≤ P

Suppose that we are given points bi, fi for each agent ai, satisfying conditions (1)-(4). Then the following
moves deﬁne a regular broadcast strategy: initially every agent ai moves to bi. Once ai learns the source
information, ai moves to fi. Since (1)-(4) hold, this is a broadcast strategy and the maximum amount of
power spent is at most P .

Before proving that it is enough to only consider regular broadcast strategies, we need to prove the

following technical lemma.
Lemma 3. There exists a broadcast strategy S for a conﬁguration (P os[1 : n], k, P ) if and only if for every
i, there exist positions li, xi, ri such that
(1) for each i, li ≤ xi ≤ ri

7

(2) xk = P os[k];
(3) for each i, |xi − P os[i]| + min(xi + ri − 2li, 2ri − xi − li) ≤ P .
(4) for each i, if xi < P os[k] (resp. xi > P os[k]), there exists j such that xi ∈ [lj, rj] and xj > xi (resp.

xj < xi).

Proof. Consider a broadcast strategy S where the maximum amount of power spent is P . For every agent
ai, let xi be the position where ai learns the information that has to be broadcast, and let li (resp. ri) be
the leftmost (resp. rightmost) position reached by ai once it got the information. By deﬁnition of li, xi, ri,
(1) and (2) hold. Since the maximum amount of power spent by an agent is at most P , and since the agent
has to go from P os[i] to xi and then to ri and li, (3) holds. Since every agent learns the information, for
every agent ai, either xi = P os[k], or ai meets an agent aj in xi such that aj already has the information.
Assume that xi < P os[k] (the other case is symmetric).
If xi < xj, then (4) holds for i. Suppose now
that xj ≤ xi ≤ P os[k] and let A be the non-empty set of agents aj such that xj ≤ xi and aj learns the
information before ai. Let aj ∈ A be the agent that is ﬁrst to learn the information. Since xj ≤ xi < P os[k],
aj learns the information from an agent aj(cid:48) that does not belong to A. Consequently, xj(cid:48) > xi ≥ xj and
thus xi ∈ [xj, xj(cid:48)] ⊆ [lj(cid:48), rj(cid:48)]. Thus (4) holds for i.
Conversely, if we are given values xi, li, ri satisfying (1)-(4), we can exhibit a strategy for broadcast:
initially every agent ai moves to xi. Once ai learns the information, if xi + ri − 2li ≤ 2ri − xi − li, then ai
moves to li and to ri and if xi + ri − 2li > 2ri − xi − li, then ai moves to ri and to li. Since (4) holds, this
is a broadcast strategy and since (3) holds, the maximum amount of power spent is at most P .

The following lemma shows that we can restrict attention to regular broadcast strategies.

Lemma 4. If there exists a broadcast strategy for a conﬁguration P os[1 : n] with source agent ak, using
power at most P , then there exists a regular broadcast strategy for the conﬁguration P os[1 : n] with source
agent ak, using power at most P .
Proof. Suppose that there exists a broadcast strategy for (P os[1 : n], k, P ). For every agent ai, i (cid:54)= k we
deﬁne bi, fi as in the deﬁnition of a regular broadcast strategy. Note that the agents {ai | 1 < i < k} execute
a reverse pull strategy between bk−1 and P os[1] + P . Similarly, the agents {ai | k < i < n} execute a pull
strategy between bk+1 and P os[n] − P . By Remark 1, it means that there exists i > k (resp. i < k) such
that ai reaches bk−1 (resp. bk+1) with the information from ak. Moreover, since the agents execute either a
reverse pull strategy or a pull strategy, we have P os[k − 1] ≤ bk−1, and P os[k + 1] ≥ bk+1.
Suppose the lemma does not hold. This means that 2bk+1−P os[k]−bk−1 > P , and bk+1+P os[k]−2bk−1 >
P . Consequently, ak cannot reach both bk−1 and bk+1, i.e., there exists i < k such that ai reaches bk+1,
or there exists i > k such that ai reaches bk−1.
If P os[k] ≤ bk−1, it implies that bk+1 > P os[k] + P ,
and consequently, there cannot exist a broadcast strategy since there is no carry strategy on (P os[k :
n − 1], P os[k], P os[n] − P, P ). Consequently, we can assume that P os[k] > bk−1. Using a similar argument
we can also assume that P os[k] < bk+1.
| i <
k and ai reaches bk+1}∪{ai | i > k and ai reaches bk−1}. Without loss of generality, assume that ak does not
reach bk−1, and let i > k such that ai reaches bk−1. For each agent aj, let xj, lj, rj be deﬁned as in Lemma 3.
Note that rk ≤ P os[k] + P and ri ≤ li + P ≤ bk−1 + P ≤ P os[k] + P . Moreover, P os[i]− P ≤ li ≤ bk−1 ≤ lk.
Consider the new strategy deﬁned as follows: for each agent j /∈ {i, k}, let x(cid:48)
j = xj, l(cid:48)
j = lj and rj = r(cid:48)
j;
k = (P os[k] + P os[i])/2 and l(cid:48)
let x(cid:48)
k = xk = P os[k], r(cid:48)
i = l(cid:48)
i = (P os[k] + P os[i])/2 and
r(cid:48)
i = P os[k] + P . Note that r(cid:48)
i ≤ P and 2r(cid:48)
i + P os[i]− 2l(cid:48)
k ≤ P . Since [li, ri]∪ [lk, rk] ⊆ [P os[i]−
i, r(cid:48)
k] ∪ [l(cid:48)
k, r(cid:48)
P, P os[k] + P ] = [l(cid:48)
i], this is still a broadcast strategy, in view of Lemma 3. However, in this new
strategy, there is one agent less in A(cid:48) = {ai | i < k and ai reaches bk+1} ∪ {ai | i > k and ai reaches bk−1}
than in A, contradicting the choice of our strategy.

Among all broadcast strategies, consider the strategy that minimizes the size of A = {ai

Consequently, either 2bk+1 − P os[k]− bk−1 > P , or bk+1 + P os[k]− 2bk−1 > P and the lemma holds.

k = P os[i] − P ; let x(cid:48)
k − P os[k]− l(cid:48)

8

3 Centralized convergecast and broadcast on lines
3.1 Centralized convergecast on lines
In this section we consider the centralized convergecast problem for lines. We give an optimal, linear-time,
deterministic centralized algorithm, computing the optimal amount of power needed to solve convergecast
for line networks and we provide a regular convergecast strategy for this amount of power. As the algorithm
is quite involved, we start by observing some properties of the optimal strategies.

3.1.1 Properties of a convergecast strategy
In the following, we only consider regular convergecast strategies. Note that a regular convergecast strategy
is fully determined by the value of P and by the partition of the agents into the two sets LR and RL. For
RL(i, P )). Observe that
each agent ai ∈ LR (resp. ai ∈ RL), we denote fi by Reachc
LR(i, P ) is the rightmost point on the line to which the set of i agents at initial positions P os[1 : i],
Reachc
each having power P , may transport their total information. Similarly, Reachc
RL(i, P ) is the leftmost such
point for agents at positions P os[i : n].

LR(i, P ) (resp. Reachc

Lemma 2 permits to construct a linear-time decision procedure verifying if a given amount P of battery
power is suﬃcient to design a convergecast strategy for a given conﬁguration P os[1 : n] of agents. We ﬁrst
RL(i, P ), for 1 ≤ i ≤ n. Then we scan them
compute two lists Reachc
RL(j + 1, P ). In such a case, we
to determine if there exists an index j, such that Reachc
set LR = {ar | r ≤ j} and RL = {ar | r > j} and we apply Lemma 2 to obtain a regular convergecast
strategy where agents aj and aj+1 meet and exchange their information which at this time is the entire
initial information of the set of agents. If there is no such index j, no convergecast strategy is possible. This
implies

LR(i, P ), for 1 ≤ i ≤ n and Reachc

LR(j, P ) ≥ Reachc

Corollary 1. In O(n) time we can decide if a conﬁguration of n agents on the line, each having a given
maximal power P , can perform convergecast.

The remaining lemmas of this subsection bring up observations needed to construct an algorithm ﬁnding

the optimal power P c

OP T and designing an optimal convergecast strategy.

1, P ) ≥ P os[p], or Reachc
second case, Reachc

Note that if the agents are not given enough power, then it can happen that some agent ap may never
learn the information from a1 (resp. from an). In this case, ap cannot belong to LR (resp. RL). We denote
LR(p) the minimum amount of power needed to ensure that ap can learn the information from a1:
by Actc
if p > 0, Actc
RL(p) = min{P |
RL(p + 1, P ) − P ≤ P os[p]}.
Reachc
LR(p −
LR(p, P ) = P os[p] + P , while in the

Given a strategy using power P , for each agent p ∈ LR, we have P ≥ Actc

LR(p − 1, P ) + P ≥ P os[p]}. Similarly, we have Actc

LR(p) = min{P | Reachc

LR(p − 1, P ) ≤ P os[p]. In the ﬁrst case, Reachc

LR(p) and either Reachc

LR(p, P ) = 2Reachc
We deﬁne threshold functions T H c

LR(p − 1, P ) + P − P os[p].
LR(p) and T H c
LR(p − 1, P ) = P os[p] (respectively Reachc

RL(p) that compute, for each index p, the minimal
amount of power ensuring that agent ap does not go back when ap ∈ LR (respectively ap ∈ RL), i.e., such
that Reachc
LR(p) =
RL(p, P ) = P os[p] − P}. Clearly,
min{P | Reachc
T H c
LR(1) = T H c
The next lemma shows how to compute Reachc
LR(p) and
RL(q, P ) if we know T H c
RL(p) for every agent p.

RL(p) = min{P | Reachc
LR(q, P ) and Reachc

LR(p, P ) = P os[p] + P} and T H c
RL(n) = 0.

RL(p + 1, P ) = P os[p]). For each p, let T H c

T H c

Lemma 5. Consider an amount of power P and an index q.
then Reachc
T H c

LR(q, P ) = 2q−pP os[p] + (2q−p+1 − 1)P −

RL(q, P ) = 2p−qP os[p] − (2p−q+1 − 1)P −

RL(p(cid:48)) < P}, then Reachc

(cid:80)q
i=p+1 2q−iP os[i]. Similarly, if p = min{p(cid:48)

If p = max{p(cid:48)

(cid:80)p−1
i=q 2i−qP os[i].

≤ q | T H c

LR(p(cid:48)) < P},
≥ q |

Proof. We prove the ﬁrst statement of the lemma; the proof of the other statement is similar. We ﬁrst show
the following claim.

9

Claim. If for every i ∈ [p + 1, q], P ≤ T H c

LR(i), then

Reachc

LR(q, P ) = 2q−pReachc

LR(p, P ) + (2q−p − 1)P −

q(cid:88)

i=p+1

2q−iP os[i].

We prove the claim by induction on q−p. Note that since P ≤ T H c

LR(q−
1, P ) + P − P os[q]. Thus if q = p + 1, the statement holds. Suppose now that q > p + 1. Since q − 1 > p, by
the induction hypothesis, we have

LR(q, P ) = 2Reachc

LR(q), Reachc

q−1(cid:88)

i=p+1

2q−1−iP os[i].

Reachc

LR(q − 1, P ) = 2q−1−pReachc

LR(p, P ) + (2q−1−p − 1)P −

Consequently, we have

Reachc

LR(q, P ) = 2Reachc

LR(q − 1, P ) + P − P os[q]

= 2q−pReachc

= 2q−pReachc

LR(p, P ) + (2q−p − 2)P −
LR(p, P ) + (2q−p − 1)P −

q−1(cid:88)
q(cid:88)

i=p+1

i=p+1

2q−iP os[i] + P − P os[q]
2q−iP os[i].

This concludes the proof of the claim.

If p = max{p(cid:48)

≤ q | T H c
P os[p] + P . Consequently,

LR(p(cid:48)) < P}, then for each p(cid:48)

Reachc

LR(q, P ) = 2q−pP os[p] + (2q−p+1 − 1)P −

LR(p, q) =(cid:80)q

LR(p, P ) =

LR(p(cid:48)) ≥ P and Reachc
∈ [p + 1, q], T H c
q(cid:88)
RL(p, q) =(cid:80)p−1

i=q 2i−qP os[i].

2q−iP os[i].

i=p+1

In the following, we denote Sc

Remark 2. For every p ≤ q ≤ r, we have Sc

i=p+1 2q−iP os[i] and Sc
LR(p, r) = 2r−qSc

LR(p, q) + Sc

LR(q, r).

We now show that for an optimal convergecast strategy, the last agent of LR and the ﬁrst agent of RL
meet at some point between their initial positions and that they need to use all the available power to meet.

Lemma 6. Suppose there exists an optimal convergecast strategy for a conﬁguration P os[1 : n], where the
maximum power used by an agent is P . Then, there exists an integer 1 ≤ p < n such that P os[p] <
Reachc

RL(p + 1, P ) < P os[p + 1].

LR(q) < P < T H c

RL(q) and ∀q > p, Actc

RL(q) < P < T H c

LR(q).

LR(p, P ) = Reachc
Moreover, ∀q ≤ p, Actc

Proof. In the proof we need the following claim.
Claim. For every 1 ≤ p ≤ n, the function Reachc
argument P , is an increasing, continuous, piecewise linear function with at most p pieces on [Actc

LR(p,·) which assigns the value Reachc

P , is a decreasing continuous piecewise linear function with at most p pieces on [Actc

For every 1 ≤ p ≤ n, the function Reachc
RL(p,·) which assigns the value Reachc
We prove the ﬁrst statement of the claim by induction on p. For p = 1, Reachc

RL(p), +∞).
LR(p,·) is a continuous piecewise linear function on [Actc

the claim holds. Suppose that Reachc
and consider Reachc

LR(1, P ) = P os[1] + P and
LR(p), +∞)

LR(p, P ) for any
LR(p), +∞).
RL(p, P ) for any argument

LR(p + 1,·).

10

LR(p,·) is a continuous,
LR(p, P ) = P os[p + 1].

LR(p) < Actc
LR(p+1) such that Reachc

First note that Actc
exists a unique P = Actc
Reachc

LR(p + 1). Since Reachc
LR(p, P (cid:48)) + P (cid:48) > P os[p + 1]. Consequently, Reachc

LR(p, P )+P = P os[p+1] and for every P (cid:48) > Actc
increasing function, there exists a unique P = T H c
If Actc
LR(p, P )+P −P os[p+1] and thus Reachc

LR(p,·) is a continuous, increasing function, there
LR(p+1),
LR(p + 1,·) is well deﬁned on [Actc
LR(p + 1), +∞).
LR(p + 1)
LR(p + 1), Reachc
LR(p + 1) ≥ P ≥ T H c
LR(p + 1, P ) =
LR(p+1,·) is an increasing, continuous, piecewise linear func-
LR(P ) = P os[p+1]+P
LR(p + 1), +∞). Since
LR(p + 1), the function
LR(p + 1), +∞) with at
One can show the second statement of the claim using similar arguments. This ends the proof of the

Since Reachc
such that Reachc
2Reachc
LR(p+1), Reachc
tion on [Actc
LR(p + 1,·) is an increasing, continuous, linear function on [T H c
and thus, Reachc
LR(p + 1)) + T H c
LR(p + 1) − P os[p + 1] = P os[p + 1] + T H c
LR(p, T H c
2Reachc
LR(p + 1,·) is an increasing, continuous, piecewise linear function on [Actc
Reachc
most p + 1 pieces.

LR(p+1)] with at most p pieces. If P ≥ T H c

LR(p+1), T H c

claim.

LR(p), Actc

RL(p + 1, P ).

LR(p,·) − Reachc

[Actc
diﬀerence Reachc

RL(p + 1,·) is a decreasing continuous function on [Actc

Let Q = max{Actc
LR(p), +∞) and Reachc
Consider the case where Q = Actc

Suppose we are given p and consider the partition of the agents into LR = {aq | q ≤ p} and RL = {aq |
q > p}. Consider a regular convergecast strategy for this partition and where the maximum amount of power
P used by an agent is minimized. We ﬁrst show that Reachc
LR(p, P ) = Reachc
LR(p,·) is an increasing continuous function on
RL(p + 1)}. Since Reachc
RL(p + 1), +∞), the
RL(p + 1,·) is a continuous increasing function on [Q, +∞).
LR(p) (the other case is similar). Since Reachc
RL(p +
LR(p, Q) ≤ P os[p] + Q < P os[p + 1] + Q = Reachc
RL(p +
RL(p + 1, Q) < 0. By deﬁnition of a regular convergecast strategy,
LR(p, Q) − Reachc
RL(p + 1, Q(cid:48)) ≥ 0. Consequently, since the diﬀerence
RL(p + 1,·) is a continuous increasing function on [Q, +∞), there exists a unique
Consider an optimal regular convergecast strategy and let P be the maximum amount of power used by
LR(p, P ) =

1, Q) = Reachc
1, Q) and thus, Reachc
there exists Q(cid:48) such that Reachc
Reachc
Q < P ≤ Q(cid:48) such that Reachc
any agent. By deﬁnition of a regular convergecast strategy, there exists an index p such that Reachc
Reachc

RL(p + 1) ≥ Actc
RL(p + 2, Q) = P os[p + 1] + Q, Reachc
LR(p, Q(cid:48)) − Reachc

LR(p,·) − Reachc

LR(p, P ) = Reachc

RL(p + 1, P ).

RL(p + 1, P ).

Suppose that Reachc

For similar reasons, if Reachc

convergecast. This contradiction shows that Reachc

1, P ) since P > Actc
that Reachc
This contradiction shows that P os[p] < Reachc

RL(p, P (cid:48)) ≤ Reachc

LR(p, P ).

RL(p, P ) = P os[p]−P < Reachc

LR(p, P ) ≤ P os[p]. In this case, we have Reachc

LR(p−
LR(p). Consequently, according to what we have shown above, there exists P (cid:48) < P such
LR(p − 1, P (cid:48)) and P is not the optimal value needed to solve convergecast.
RL(p + 1, P ) ≥ P os[p + 1], P is not the optimal value needed to solve
LR(q) < P . This follows from the fact that for each aq ∈ LR such
LR(p).
LR(p, P ) =
LR(p, P ). This contradicts

LR(q − 1). Consequently, for each q ∈ [1, p − 1], Actc

RL(p + 1, P ) ≥ P os[p + 1] − P > P os[p] − P ≥ Reachc

RL(p + 1, P ) > P os[p + 1].

LR(p), then Reachc

LR(q) > Actc

If P = Actc

LR(p).

We now prove that for each q ∈ [1, p], Actc

LR(q) > Actc

that q > 1, we have Actc
Moreover, if Reachc
P os[p] − P and thus, Reachc
the ﬁrst statement of the lemma. Hence, we have P > Actc
RL(q) < P .

LR(p, P ) is deﬁned, then P ≥ Actc

For similar reasons, for each q ∈ [p + 1, n], Actc
We ﬁnally prove that for each q ∈ [1, p], P < T HRL(q). Suppose there exists q such that P ≥ T HRL(q)
LR(q − 1, P ) >
RL(q, P ) and consequently, the ﬁrst statement of the lemma implies that there exists
RL(q, P (cid:48)). This implies that P is not the optimal value needed

and consider LR = {ar | r ≤ q − 1} and RL = {ar | r ≥ q}. Since P > Actc
P os[q] − P = Reachc
P (cid:48) < P such that Reachc
to solve convergecast. This contradiction implies that for each q ∈ [1, p], P < T HRL(q).

LR(q− 1, P (cid:48)) > Reachc

LR(q), Reachc

For similar reasons, for each q ∈ [p + 1, n], P < T HLR(q).

LR(p).

3.1.2 A linear algorithm to compute the optimal power needed for convergecast
We ﬁrst sketch a suboptimal but much easier algorithm and later present and analyze in detail a more
LR(p,·) and
involved linear-time solution to our problem. First, we need to compute the functions Reachc

11

LR(p) = min{P | Reachc

LR(p,·), since each value T H c

RL(p,·) for all p such that 1 ≤ p ≤ n. By Lemma 5, the function Reachc

LR(p,·) can be computed
Reachc
from the values T H c
LR(q) for all q such that 1 ≤ q ≤ p. Starting from p = 1, one can compute all these
functions Reachc
LR(p − 1, P ) = P os[p]} can be deduced
from Reachc
LR(p − 1,·). The computation at step p has a time complexity in O(p) and so the computation
of all the functions Reachc
LR(p,·) takes time O(n2). Similarly, it is possible to compute all the functions
Reachc
RL(p + 1,·)
are increasing, continuous, piecewise linear functions with at most n pieces, by the claim from the proof
of Lemma 6, it is possible to compute the value P such that Reachc
RL(p + 1, P ) in time
O(n). Hence the optimal value of power needed to achieve convergecast on lines, which is min1≤p≤n{P |
Reachc
The following result shows that the optimal power needed for convergecast on the line can in fact be

RL(p,·), for all p such that 1 ≤ p ≤ n, in time O(n2). Since Reachc

RL(p + 1, P )} by Lemma 6, can be computed in time O(n2).

LR(p,·) and Reachc

LR(p, P ) = Reachc

LR(p, P ) = Reachc

computed in linear time.

Theorem 1. In O(n) time it is possible to compute the optimal power needed to achieve convergecast on the
line for conﬁguration P os[1 : n] and to compute the optimal convergecast strategy.

We ﬁrst explain how to compute a stack of couples (p, T H c

LR(p)) that we can subsequently use to calculate
LR(p, P ) for any given P . Then, we present a linear algorithm that computes the value needed to
Reachc
solve convergecast when the last index r ∈ LR is provided: given an index r, we compute the optimal power
needed to solve convergecast assuming that LR = {aq | q ≤ r} and RL = {aq | q > r}. Finally, we explain
how to use techniques introduced in the two previous algorithms in order to compute the optimal power
needed to solve convergecast.

LR(r) > T H c

LR(r) > T H c

LR(p)}.

if we want to compute T H c

In particular,
LR(q, T H c

LR(p) and min{T H c

In order to describe explicitly the function Reachc

LR(r)) < P os[q + 1]}, and then T H c

LR(q, P ) = 2q−pP os[p] + (2q−p+1 − 1)P − Sc

LR(q,·), we need
LR(p). They correspond
LR(q,·) change. Indeed, if we
LR(r) | p < r ≤ q},
LR(p, q). We denote by XLR(q) this set of indices
LR(q + 1), we just need to ﬁnd p = max{r ≤ q |
LR(q + 1) is the value of power P such that
LR(p, q) = P os[q + 1]. Moreover, by the choice of p, we have XLR(q + 1) =

Computing the threshold values.
to identify the indices p such that for every r ∈ [p + 1, q], we have T H c
to the breakpoints at which the slopes of the piecewise linear function Reachc
are given such an index p, then for every P comprised between T H c
we have Reachc
{p ≤ q | ∀r ∈ [p + 1, q], T H c
Reachc
2q−pP os[p] + (2q−p+1 − 1)P − Sc
{r ∈ XLR(q) | r ≤ p} ∪ {q + 1}.
containing couples (p, P ) such that p ∈ XLR(r) and P = T H c
(p, P ) are sorted along both components, the largest being on the top of the stack.
The function is described as follows. Initially, the stack THc

Using these remarks, the function ThresholdLR, with an input index r of an agent, returns a stack THc
LR, the elements

LR(1)). At
each iteration, given the stack corresponding to the index q, in order to compute the stack for the index
q + 1, we ﬁrst pop out all elements (p, P ) such that Reachc
LR(q, P ) > P os[q + 1]. After that, the integer p
needed to compute T H c
LR(q + 1))
is pushed on the stack before we proceed with the subsequent index q. The function returns the stack THc
LR
corresponding to the index r.

LR(q + 1) is located on the top of the stack. Finally, the couple (q + 1, T H c

LR contains only the couple (1, T H c

LR(p). Note that in the stack THc

LR

12

Below, we give the pseudo-code of the function.

Function ThresholdLR(array P os[1 : n] of real; r:integer):stack

LR,(1, 0));

LR = empty_stack;
THc
push (THc
for q = 1 to r − 1 do
(p, P ) = pop(THc
LR);
while 2q−p ∗ P os[p] + (2q−p+1 − 1) ∗ P − Sc

(p, P ) = pop(THc

LR);

LR,(p, P ));

// while Reachc
push (THc
Q = (2q−p ∗ P os[p] − P os[q + 1] − Sc
/* Q is the solution of Reachc
push (THc
LR);

LR,(q + 1, Q));

LR(p, q) ≥ P os[q + 1] do

/* p = q and P = T H c

LR(p) */

LR(q, P ) ≥ P os[q + 1] we consider the next element in THc

LR

LR(p, q))/(2q−p+1 − 1);
LR(q, P ) = P os[q + 1]

*/

order to obtain a linear number of arithmetic operations, we need to be able to compute 2q−p and Sc
in constant time.

return (THc
The number of stack operations performed during the execution of this function is O(r). However, in
LR(p, q)
In order to compute 2q−p eﬃciently, we can store the values of 2i, i ∈ [1, n−1] in an auxiliary array, that we
LR(p, q) since this requires calculating
LR(1, q)− 2q−pSc
LR(1, p). Consequently,
LR(1, i) + P os[i + 1], this
LR(1, i + 1) = 2Sc

have precomputed in O(n) time. We cannot precompute all values of Sc
Θ(n2) values. However, from Remark 2, we know that Sc
it is enough to precompute Sc
can be done using O(n) arithmetic operations.

LR(1, i) for each i ∈ [2, n]. Since Sc

LR(p, q) = Sc

Similarly, we can deﬁne the function ThresholdRL (array P os[1 : n] of real, r:integer):stack that
RL(p) >

RL(q)) such that for every p ∈ [r, q − 1], we have T H c

RL containing all pairs (q, T H c

returns a stack THc
T H c

RL(q).

Computing the optimal power when LR and RL are known. To facilitate further reading, we ﬁrst
OP T , if the sets LR and RL are known. This will be done by
show how to compute the optimal power P c
function OptimalAtIndex which will be not used in our ﬁnal algorithm to compute optimal power but whose
role is to explain some of the techniques under these additional assumptions.

Suppose that we are given an agent index r and we want to compute the optimal power needed to solve
convergecast when LR = {ap | p ≤ r} and RL = {aq | q > r}. From Lemma 6, we know that there exists a
unique value P c
As previously, by Lemma 5, we know that the value of Reachc
≤ r |
LR(p(cid:48)) < P c
OP T}.

OP T ).
LR(r, P c
OP T ) depends on q = max{q(cid:48)

OP T such that Reachc
OP T}. Similarly, Reachc

OP T ) depends on p = max{p(cid:48)
RL(q(cid:48)) < P c

≥ r + 1 | T H c

OP T ) = Reachc

RL(r + 1, P c

RL(r + 1, P c

LR(r, P c

T H c
If we are given the values of p and q, then P c
2r−pP os[p] − (2r−p+1 − 1)P − Sc

OP T is the unique value of P such that
LR(p, r) = 2q−r−1P os[q] − (2q−r − 1)P − Sc

RL(q, r + 1).

LR and THc

RL containing respectively {(p, T H c

In Function OptimalAtIndex, we ﬁrst use functions ThresholdLR and ThresholdRL to compute the two
stacks THc
RL(q)) | q ∈ XRL(r +
1)}. Then at each iteration, we consider the two elements (p, PLR) and (q, PRL) that are on top of both stacks.
RL(r + 1, PLR).
If PLR ≥ PRL (the other case is symmetric), we check whether Reachc
In this case, we have P > P c
LR and we proceed to the next
iteration.
OP T ≥ PLR ≥ PRL and we can
compute the value of P c
LR(p) < P} and YRL(r + 1, P ) =

OP T , so we remove (p, PLR) from the stack THc

LR(p)) | p ∈ XLR(r)} and {(q, T H c

Let YLR(r, P ) denote {(p, T H c

| p ∈ XLR(r) and T H c

RL(r + 1, PLR), we know that P c

LR(r, PLR) ≥ Reachc

OP T using Lemma 5.

LR(r, PLR) < Reachc

If Reachc

LR(p))
RL(q)) | q ∈ XRL(r + 1) and T H c

{(q, T H c
Remark 3. At the end of the execution of Function OptimalAtIndex, THc
YLR(r, P c

OP T ) and YRL(r + 1, P c

RL(q) < P}.

RL contain respectively

LR and THc

OP T ).

13

Moreover, if initially the two stacks THc

LR and THc

RL contain respectively YLR(r, P ) and YRL(r + 1, P ) for

some P ≥ P c

OP T , then the value computed by the function is also P c

OP T .
The pseudo-code of the of Function OptimalAtIndex is given below.

Function OptimalAtIndex(array P os[1 : n] of real; r:integer):stack

RL = ThresholdRL(r + 1);

LR = ThresholdLR(r); THc

THc
(p, PLR) = pop(THc
/* p = r, PLR = T H c
while 2r−pP os[p] + (2r−p+1 − 1)P − Sc
/* While Reachc

LR(r, P ) ≥ Reachc

LR); (q, PRL) = pop(THc

if PLR ≥ PRL then (p, PLR) = pop(THc

RL(r + 1, P ) do

LR(r), q = r + 1, PRL = T H c

RL(r + 1).

RL); P = max{PLR, PRL};

OP T = (2q−r−1P os[q] − Sc
P c
/* P c
return (P c

OP T );

OP T is the solution of Reachc

RL(q, r + 1) − 2r−pP os[p] + Sc

LR(p, r))/(2r−p+1 + 2q−r − 2);

LR(r, P c

OP T ) = Reachc

RL(r + 1, P c

OP T )

LR(p, r) ≥ 2q−r−1P os[q] − (2q−r − 1)P − Sc

RL(q, r + 1) do

LR) else (q, PRL) = pop(THc

RL) P = max{PLR, PRL};

*/

*/

*/

Computing the optimal power for convergecast. We now explain how to compute the optimal amount
of power needed to achieve convergecast using a linear number of operations. Notice that Function Optimal-
AtIndex does it only provided the partition of the agents in LR and RL.

Let P<r be the optimal value needed to solve convergecast when max{s | as ∈ LR} < r, i.e., when
the two agents whose meeting results in merging the entire information are ai and ai+1 for some i < r. If
Reachc
RL(r +
1, P<r), then P<r+1 < P<r and P<r+1 is the unique value of P such that Reachc
RL(r+1, P ).
This corresponds to the value returned by function OptimalAtIndex (P os, r).

RL(r + 1, P<r), then P<r+1 = P<r. However, if Reachc

LR(r, P<r) ≤ Reachc

LR(r, P<r) > Reachc

LR(r, P ) = Reachc

The general idea of Function ComputeOptimal is to iteratively compute the value of P<r. If we need a
linear time algorithm, we cannot call repeatedly the function OptimalAtIndex. However, from Remark 3,
in order to compute P<r+1 when P<r+1 ≤ P<r, it is enough to know YLR(r, P<r) and YRL(r + 1, P<r). If we
know YLR(r, P<r) and YRL(r + 1, P<r), then we can use the same algorithm as in OptimalAtIndex in order
to compute P<r+1. Moreover, from Remark 3, we also get YLR(r, P<r+1) and YRL(r + 1, P<r+1) when we
compute P<r+1.

RL(r + 1) ≤ P<r+1, then either P os[r + 1] − P<r+1 ≥ Reachc

from YLR(r, P<r+1) and YRL(r + 1, P<r+1). Note that if T H c
YLR(r, P<r+1). If T H c
1, P<r+1) = {(p, T H c
1) > P<r+1, then (r + 1, T H c
If T H c
P os[r + 1]− P<r+1 = Reachc
that Actc
the value of P<r+1.

Before proceeding to the next iteration, we need to compute YLR(r + 1, P<r+1) and YRL(r + 2, P<r+1)
LR(r) > P<r+1, then YLR(r + 1, P<r+1) =
LR(r) ≤ P<r+1, we can use the same function as in ThresholdLR to compute YLR(r +
LR(p)) | p ∈ XLR(r)} from YLR(r, P<r+1). Consider now YRL(r+2, P<r+1). If T H c
RL(r+
RL(r + 1)) /∈ YRL(r + 1, P<r+1), and YRL(r + 2, P<r+1) = YRL(r + 1, P<r+1).
RL(r + 1, P<r+1) if P<r+1 = P<r, or
LR(r, P<r+1) if P<r+1 < P<r. In both cases, it implies
RL(r + 1, P<r+1) = Reachc
LR(r + 1) ≥ P<r+1. Therefore, by Lemma 6, P<i = P<r+1 for every i ≥ r + 1 and we can return
LR contains YLR(r, P<r) (except its top
LR is empty and
LR and no
RL. Consequently, the number of stack operations performed by Function

RL contains O(n) elements. In each iteration, at most one element is pushed into the stack THc

RL contains YRL(r + 1, P<r) (except its top element). Initially, THc

In Function ComputeOptimal, at each iteration, the stack THc

element) and the stack THc
THc
element is pushed into the stack THc
ComputeOptimal is linear.

Notice that the partition of agents into sets LR and RL is given by the value of index r when P c

OP T is
returned by Function ComputeOptimal. Since an optimal regular convergecast strategy is fully determined
by the value of P c
OP T and by the partition of the agents into the sets LR and RL, Function ComputeOptimal
also yields an optimal convergecast strategy. Hence, this concludes the proof of Theorem 1.

14

Function ComputeOptimal(array P os[1 : n] of real):real

LR = empty_stack; THc
RL); P c
RL(1)

THc
(q, PRL) = pop(THc
/* q = 1, PRL = T H c
(q, PRL) = pop(THc
for r = 1 to n − 1 do

RL); p = 1;PLR = 0;

RL = ThresholdRL(P os);

OP T = PRL;

OP T = P<r ≥ PLR, PRL

/* P c
if 2r−pP os[p] + (2r−p+1 − 1)P c

/* If Reachc

LR(r, P c

OP T − Sc
OP T ) > Reachc

to solve convergecast at position r.
OptimalAtIndex.
P = max{PLR, PRL};
while 2r−pP os[p] + (2r−p+1 − 1)P − Sc

if PLR ≥ PRL then (p, PLR) = pop(THc

OP T = (2q−r−1P os[q] − Sc
P c
/* P c

OP T = P<r+1 is the solution of Reachc

*/

*/

*/

*/

LR(p, r) > 2q−r−1P os[q] − (2q−r − 1)P c
RL(r + 1, P c

RL(q, r + 1) then
OP T is larger than the value needed
We apply now the same algorithm as in function
*/

OP T ) then P c

OP T − Sc

LR(p, r) ≥ 2q−r−1P os[q] − (2q−r − 1)P − Sc

LR) else (q, PRL) = pop(THc

RL(q, r + 1) do

RL) P = max{PLR, PRL};

RL(q, r + 1) − 2r−pP os[p] + Sc
LR(r, P c

LR(p, r))/(2r−p+1 + 2q−r − 2);
OP T ) = Reachc
OP T )
OP T ≥ T H c
RL(r + 1) and thus
LR(p, r) ≥ P os[r + 1] then

RL(r + 1, P c

P c

OP T /* In this case, P c

OP T = P<r = Actc

if q = r + 1 then return P c
if 2r−p ∗ P os[p] + (2r−p+1 − 1) ∗ P c

LR(r + 1):
OP T ) ≥ P os[r + 1] then T H c
same algorithm as in function ThresholdLR.

/* If Reachc
while 2r−p ∗ P os[p] + (2r−p+1 − 1) ∗ PLR − Sc

for any s > r, P<s = P<r
OP T − Sc

LR(p, r) do

LR(r, P c

LR(r + 1) ≤ P c

OP T and we update THc

LR, using the
*/

LR);

(p, PLR) = pop(THc
push (THc
LR,(p, PLR));
PLR = (P os[r + 1] + Sc
p = r + 1;

LR(p, r) − 2r−p ∗ P os[p])/(2r−p+1 − 1);

3.2 Centralized broadcast on lines
In this section we consider the centralized broadcast problem for lines. We give an optimal, linear-time,
deterministic centralized algorithm, computing the optimal amount of power needed to solve broadcast for
line networks and computing an optimal broadcast strategy.

3.2.1 Properties of a broadcast strategy
In the following, we only consider regular broadcast strategies. Note that a regular broadcast strategy is
fully determined by the value of P and by the two possible values of bk for the source agent ak (bk = bk−1
or bk = bk+1).
(Note that we slightly abuse notation
by using the same names LR and RL for subsets of agents as in convergecast.) For each agent ai ∈ LR
(resp. ai ∈ RL ), we denote bi by Reachb
LR(i, P ) is the
rightmost point on the line from which the set of i agents at initial positions P os[1 : i], each having power
P , may pick the information and bring it back to a1. Similarly, Reachb
RL(i, P ) is the leftmost point from
which the agents at positions P os[i : n] may pick the information and bring it back to an.

Let LR = {a1, a2, . . . , ak−1} and RL = {ak+1, ak+2, . . . , an}.

RL(i, P )). Observe that Reachb

LR(i, P ) (resp. Reachb

Lemma 4 permits to construct a linear-time decision procedure verifying if a given amount P of battery
power is suﬃcient to design a broadcast strategy for a given conﬁguration P os[1 : n] of agents and a speciﬁed
RL(k + 1, P ). Then we test
source agent ak. We ﬁrst compute bk−1 = Reachb
if |2Reachb
LR(k − 1, P )|
are less or equal than P . If one of the inequalities is true then there is a broadcast strategy. Otherwise,
broadcast is not possible. This implies

LR(k − 1, P ) and bk+1 = Reachb

RL(k + 1, P )− P os[k]− Reachb

LR(k − 1, P )− P os[k]− Reachb

RL(k + 1, P )| or |2Reachb

15

Corollary 2. In O(n) time we can decide if a conﬁguration P os[1 : n] of n agents on the line, each having
a given maximal power P , can perform broadcast for a given source agent.

LR(1) = Actb

LR(p) = min{P | Reachb

RL(q + 1, P )). We have : Actb

LR(p − 1, P ) (resp. Reachb

LR(p − 1, P ) (resp. Reachb

Note that if the agents are not given enough power, then it can happen that some agent ap, 1 ≤ p ≤ k
(resp. k ≤ q ≤ n) cannot reach the point Reachb
RL(q + 1, P )). We denote by
LR(p) (resp. Actb
RL(q)) the minimum amount of power P we have to give the agents to ensure that ap
Actb
(resp. aq) can reach Reachb
RL(n) = 0
LR(p − 1, P ) ≥ P os[p] − P}. Similarly, if k ≤ q ≤ n − 1, we
and if 2 ≤ p ≤ k, Actb
RL(q + 1, P ) ≤ P os[q] + P}.
have Actb
LR(p), we
LR(p − 1, P ) + P + P os[p])/2. Similarly, for each agent q ∈ RL such that
RL(q + 1, P ) − P + P os[q])/2. The next lemma shows how
RL(q, P ) = (Reachb
RL(q,·) on

In a regular broadcast strategy using power P , for each agent p ∈ LR such that P ≥ Actb

RL(q) = min{P | Reachb
LR(p, P ) = (Reachb
RL(q), we have Reachb

LR(p), +∞) for every p ∈ {1, 2, . . . , k} and Reachb

LR(p,·) on the interval [Actb
RL(q), +∞) for every q ∈ {k, k + 1, . . . , n}.

have Reachb
P ≥ Actb
to compute Reachb
the interval [Actb
Lemma 7. Consider an index p ∈ {1, 2, . . . , k} and an amount of power P ≥ Actb
Reachb
LR(p, Actb
and an amount of power P ≥ Actb
RL(q)) − P + Actb
Proof. First, we show by induction on p that for any p ∈ {1, 2, . . . , k} and an amount of power P ≥ Actb
we have Reachb
P , Actb
Reachb
for all P ≥ Actb

then
LR(p). Analogously, for an index q ∈ {k, k + 1, . . . , n},
RL(q).
LR(p),
LR(p))+P−Actb
LR(1, P ) =
LR(p − 1, P ) =
LR(p − 1). By deﬁnition of a regular broadcast strategy, we have

LR(1) = 0 and Reachb
LR(p − 1, Actb
LR:

LR(1)) = 0. Now, assume by induction that Reachb

LR(p). This is true for p = 1 since Reachb

LR(p)) + P − Actb
RL(q), we have Reachb

LR(p − 1)) + P − Actb

LR(p, P ) = Reachb

LR(p, P ) = Reachb

RL(q, P ) = Reachb

LR(p, Actb

LR(1, Actb

RL(q, Actb

LR(p),

Reachb

LR(p, P ) =

=

Reachb

Reachb

2

LR(p − 1, P ) + P os[p] + P
LR(p − 1, Actb
Reachb

LR(p − 1)) + P − Actb
LR(p − 1)) − Actb

LR(p − 1, Actb

2

= P +

LR(p − 1) + P os[p] + P

LR(p − 1) + P os[p]

2

Observe that for P = Actb

LR(p), we have:

Reachb

LR(p, Actb

LR(p)) =

Hence we have:

Reachb

LR(p − 1, Actb

LR(p − 1)) − Actb

LR(p − 1) + P os[p]

2

+ Actb

LR(p).

Reachb

LR(p, P ) = Reachb

LR(p, Actb

LR(p)) + P − Actb

LR(p).

LR(q, P ) = Reachb

LR(p), we have Reachb

This concludes the proof by induction.
Similarly, we can show by induction on q that for any ∈ {k, k + 1, . . . , n} and an amount of power

P ≥ Actb
3.2.2 A linear algorithm to compute the optimal power needed for broadcast
In this section, we prove the following theorem.
Theorem 2. In O(n) time it is possible to compute the optimal power needed to achieve broadcast for a
conﬁguration P os[1 : n] of n agents on the line for any source agent and to compute an optimal broadcast
strategy.

LR(q)) − P + Actb

LR(q, Actb

LR(q).

Proof. We formulate Function OptimalBroadcast which computes in linear time the optimal power for the
broadcast in the line.

In order to compute this value, Function OptimalBroadcast ﬁrst computes the minimal amount of power
RL(k + 1)). In order to

Q such that all agents in LR ∪ RL are activated, i.e., Q = max(Actb

LR(k − 1), Actb

16

Function OptimalBroadcast(array P os[1 : n] of real; r:integer):real

Actb
LR(1) = 0, Reachb
while p < k − 1 do
while (p < k − 1) and (P os[p + 1] − Actb

LR(1)) = 0, p = 1;

LR(1, Actb

LR(p) ≤ Reachb

LR(p, Actb

LR(p))) do

LR(p);
LR(p + 1)) = (P os[p + 1] + Actb

LR(p + 1) + Reachb

LR(p, Actb

LR(p + 1)))/2;

LR(p + 1) = Actb
LR(p + 1, Actb

Actb
Reachb
p = p + 1;

if (p < k − 1) then

δLR = (P os[p + 1] − Actb
Actb
Reachb
p = p + 1;

LR(p + 1) = Actb
LR(p + 1, Actb

LR(p) − Reachb

LR(p, Actb

LR(p)))/2;

LR(p) + δLR;
LR(p + 1)) = P os[p + 1];

Actb
RL(n) = 0, Reachb
while q > k + 1 do
while (q > k + 1) and (P os[q − 1] + Actb

RL(n, Actb

RL(n)) = P os[n], q = n;

RL(q) ≥ Reachb

RL(q, Actb

RL(q)) do

RL(q);
RL(q − 1)) = (P os[q − 1] − Actb

RL(q − 1) + Reachb

RL(q − 1, Actb

RL(q − 1))/2;

RL(q − 1) = Actb
RL(q − 1, Actb

Actb
Reachb
q = q − 1;

δRL = (Reachb
Actb
Reachb
q = q − 1;

RL(q − 1) = Actb
RL(q − 1, Actb

if (q > k + 1) and (p = k − 1 or δLR < δLR) then

RL(q, Actb

RL(q)) − Actb

RL(q) − P os[q − 1])/2;

RL(q);
RL(q − 1)) = P os[q − 1];

P = max(Actb
LR(k − 1) > Actb
if Actb
LR = Reachb
X b
RL = Reachb
Y b

LR(k − 1), Actb

RL(k + 1));
RL(k + 1)) then

LR(k − 1, Actb
RL(k + 1, Actb

LR(k − 1));
RL(k + 1)) + Actb

LR(k − 1) − Actb

RL(k + 1));

else

LR = Reachb
X b
RL = Reachb
Y b

LR(k − 1, Actb
RL(k + 1, Actb

LR(k − 1)) − Actb
RL(k + 1));

RL(k + 1) + Actb

LR(k − 1));

if P os[k] ≤ X b

LR then

if X b

RL − P os[k] − P )/2;
RL then
LR, Y b

δ = (Y b
LR < P os[k] < Y b
δ = (min(P os[k] − X b
RL ≤ P os[k] then
δ = (P os[k] − X b
return P + max(0, δ)

LR − P )/2;

if Y b

RL − P os[k]) + (Y b

RL − X b

LR) − P )/2;

compute Q, the function iteratively increases the power suﬃcient to activate all agents in LR. Then, it
does the same with agents in RL. The function computes iteratively for each agent ai from a1 to ak−1
in LR (respectively from an to ak+1 in RL), the value Actb
RL(i)) and the value
RL(i))). Once Q is known, the function computes the
Reachb
RL(k+1, P ).
minimal amount of power P ≥ Q that enables the agent ak to reach Reachb
This will be proved to be the minimal power to accomplish broadcast.

LR(k−1, P ) and Reachb

LR(i)) (respectively Reachb

LR(i) (respectively Actb

RL(i, Actb

LR(i, Actb

Notice that in order to accomplish broadcast, agent ak−1 must be able to reach Reachb
LR(k − 2)). Hence the optimal value P b

LR(k −
OP T of power suﬃcient to accomplish broadcast must be at
RL(k + 1). Hence, we will ﬁrst prove that the
RL(q)) and Actb
RL(q) are correctly computed for

OP T must be at least Actb
RL(q, Actb

LR(k − 1). Similarly, P b

2, Actb
least Actb
values of Reachb

LR(p), Reachb

LR(p)), Actb

LR(p, Actb

17

LR(p)) and Actb

LR(1, Actb

LR(p, Actb

LR(p)) and Actb

RL(q, Actb

RL(q)) and Actb

LR(1)) = 0 and Actb

We only prove that the values of Reachb

LR(p) are correctly computed. If Reachb

1 ≤ p < k and k < q ≤ n.
p < k, as the proof that Reachb
similar. The proof is by induction on p. For p = 1, the values of Reachb
are correctly computed since Reachb
Reachb
then Actb
on [Actb
Actb
remains to show that Reachb
strategy, we have Reachb
If Reachb
formula is used by the function. Otherwise, we have : Actb
LR(p)))/2. Using the notation r = Reachb
Reachb
a = Actb

LR(p) are correctly computed for 1 ≤
RL(q) are correctly computed for k < q ≤ n is
LR(p)
LR(1) = 0. Suppose that the values of
LR(p)) ≥ P os[p + 1] − P ,
LR(p, P ) are linear with coeﬃcient 1
LR(p), we have Actb
LR(p + 1) =
LR(p+1) is correctly computed. It
LR(p+1)) is correctly computed. By deﬁnition of a regular broadcast
LR(p + 1) + P os[p + 1])/2.
LR(p + 1) is correctly computed as the above
LR(p) −
LR(p + 1)),

LR(p, Actb
LR(p + 1) = Actb
LR(p), +∞). Hence, if Reachb
LR(p+1, Actb

LR(p)) < P os[p + 1] − Actb
LR(p)))/2. This shows that Actb

LR(p). By Lemma 7, all functions Reachb

LR(p)+(P os[p+1]−P−Reachb

LR(p)) ≥ P os[p + 1] − Actb

LR(p + 1) = Actb
LR(p, Actb

LR(p)), r(cid:48) = Reachb

LR(p) + (P os[p + 1] − Actb

LR(p, Actb

LR(p), then Reachb

LR(p + 1, Actb

LR(p + 1)) = (Reachb

LR(p, Actb

LR(p + 1)) + Actb

LR(p)) and Actb

LR(p, Actb

LR(p, Actb

LR(p, Actb
LR(p), a(cid:48) = Actb

LR(p + 1) we have :

LR(p, Actb

LR(p, Actb

LR(p, Actb

Reachb

LR(p + 1, Actb

LR(p + 1)) =

=

=

r(cid:48) + a(cid:48) + P os[p + 1]
(r + a(cid:48)

2

− a) + (a + (P os[p + 1] − a − r)/2) + P os[p + 1]

2

(r + (P os[p + 1] − a − r)/2)) + (a + (P os[p + 1] − a − r)/2) + P os[p + 1]

2

= P os[p + 1].

This completes the proof by induction.
Again, using the fact that all functions Reachb

RL = Reachb

LR = Reachb
RL(k + 1, Q). Finally, we consider three cases : P os[k] ≤ X b

LR(p), +∞),
LR(k − 1, Q). The same is true
the function OptimalBroadcast computes correctly the value X b
RL or
LR, X b
for Y b
RL ≤ P os[k] to compute the additional power δ that has to be used. By deﬁnition of Reachb
Y b
LR(k − 1, P )
and Reachb
RL(k + 1, P ), we conclude that P is the optimal value of power to achieve broadcast by a regular
strategy. In view of Lemma 4, this concludes the proof that P is the optimal value of power to achieve
broadcast. The complexity O(n) of the function is straightforward by its formulation.

LR(p, P ) are linear with coeﬃcient 1 on [Actb

LR < P os[k] < Y b

Since a regular broadcast strategy is fully determined by the value of P and by the two possible values
of bk for the source agent ak (bk = bk−1 or bk = bk+1), computing the optimal power P yields an optimal
broadcast strategy. This concludes the proof of Theorem 2.

4 Centralized convergecast and broadcast on trees and graphs
We start the section by showing that for arbitrary trees the centralized convergecast problem and the
centralized broadcast problem are substantially harder than on lines.

A conﬁguration for convergecast on arbitrary graphs is a couple (G, A) where G is a n-node weighted
graph representing the network and A of size k is the set of the starting nodes of the agents. A conﬁguration
for broadcast additionally speciﬁes the starting node of the source agent. We consider the centralized
convergecast decision problem and the broadcast decision problem formalized as follows.
Centralized convergecast decision problem
Instance: a conﬁguration (G, A) and a real P .
Question: Is there a convergecast strategy for (G, A), in which each agent uses at most P battery power ?

Centralized broadcast decision problem
Instance: a conﬁguration (G, A) with a speciﬁed source agent and a real P .

18

Question: Is there a broadcast strategy for (G, A) with the speciﬁed source agent, in which each agent uses
at most P battery power ?

We will prove that both these problems are strongly NP-complete. In order to do this, we consider star
conﬁgurations, i.e., conﬁgurations (G, A) in which G is a star, i.e., a tree of diameter 2. We deﬁne a class of
strategies in a star called simple that consist of the following two phases :

• The strategy starts with a gathering phase lasting time P , in which each agent uses all its available
power to move towards the center of the star and then waits until time P . The agents that have used
all their power during this phase without reaching the center are called depleted.
• In the second phase, the agents does not move past depleted agents, i.e., never enter the segment
between a leaf and a depleted agent.

The following lemma shows that it is enough to consider simple strategies for convergecast and broadcast.

(cid:48), the agent executes at time t(cid:48) + P each movement performed at time t(cid:48)

Lemma 8. If there exists a convergecast strategy (respectively a broadcast strategy) in a star using power P ,
then there exists a simple convergecast strategy (respectively a simple broadcast strategy) using power P .
(cid:48) as follows. In
Proof. Let S be a convergecast or a broadcast strategy. We construct a simple strategy S
(cid:48), each agent moves towards the center of the star until it has used all its battery power or has reached the
S
center of the star. This gathering phase lasts from time 0 to time P . If an agent has not reached the center
(cid:48). Otherwise, consider time t at which it arrives at the center in S.
in strategy S, then it stops forever in S
Then, in strategy S
≥ t in strategy
S. However, if a movement of an agent would result in the agent moving past a depleted agent from time r
(cid:48) the agent waits at the position of the depleted agent instead of moving past
to r(cid:48) in S, then in strategy S
(cid:48), the non-depleted agents share all
it. By construction, S
their information at the center of the star at time P . Since two depleted agents cannot meet, it remains to
show that when a non-depleted agent b meets a depleted agent a at time t in strategy S, they meet at time
(cid:48) than in S. Hence, any agent b
t + P in S
(cid:48) at time t + P . Hence, the meeting between a
that meets agent a at time t is at the new position of a in S
(cid:48) is a
and b occurs in S
simple convergecast strategy (respectively a simple broadcast strategy).

(cid:48) as well. If S was a convergecast strategy (respectively a broadcast strategy) then S

(cid:48) is a simple strategy. Observe that in strategy S

(cid:48). The ﬁnal position of agent a is not farther from the center in S

Theorem 3. The centralized convergecast decision problem and the centralized broadcast decision problem
are strongly NP-complete for trees.

The proof of Theorem 3 is split into three lemmas. We ﬁrst show that the centralized convergecast decision
problem is strongly NP-hard, then that the centralized broadcast decision problem is strongly NP-hard, and
ﬁnally that both problems are in NP.

Lemma 9. The centralized convergecast decision problem is strongly NP-hard for trees.

Question: Can S be partitioned into m disjoint sets S1, S2, . . . , Sm of size 3, such that (cid:80)

Proof. We construct a polynomial-time many to one reduction from the following strongly NP-Complete
problem [30].
3-Partition problem
Instance: a multiset S of 3m positive integers xi such that for 1 ≤ i ≤ 3m, R/4 < xi < R/2 with R =
1 ≤ j ≤ m ?
We construct an instance (G, U ) of the centralized convergecast problem from an instance of 3-Partition
as follows. The graph G is a star with 4m + 2 leaves and U is the set of leaves of G. Hence, there are 4m + 2
agents, each located at a leaf of the star. We consider a partition of the set of agents into three subsets: A,
B and C. The subset A = {ai | 1 ≤ i ≤ m + 1} contains m + 1 agents. The leaves containing these agents
are incident to an edge of weight 1. The subset B = {bi | 1 ≤ i ≤ 3m} contains 3m agents. For 1 ≤ i ≤ 3m,

(cid:80)3m
m .
i=1 xi
x∈Sj x = R for

19

the weight of the edge incident to the leaf containing agent bi is 2R + 1 + xi. The subset C = {c} contains
one agent. The leaf containing agent c is incident to an edge of weight 4R + 1. Figure 1 depicts the star
obtained in this way. The battery power P allocated to each agent is equal to 2R + 1. The construction can
be done in polynomial time. We show that the constructed instance of the centralized convergecast problem
gives answer yes if and only if the original instance of 3-partition gives answer yes.

Figure 1:
partition.

Instance of the centralized convergecast decision problem constructed from an instance of 3-

ai moves to meet bj and goes back to the center of the star. The cost of this movement is 2(cid:80)

First, assume that there exists a solution S1, S2, . . . , Sm for the instance of the 3-partition problem. We
show that the agents can solve the corresponding instance of the centralized convergecast problem using the
following strategy. Agent c moves at distance 2R from the center and for each 1 ≤ i ≤ 3m, agent bi moves at
distance xi from the center. At this point, all these agents have used all their battery power. Each agent in
A moves to the center of the star. For 1 ≤ i ≤ m and for each of the three agents bj such that xj ∈ Si, agent
xj∈Si = 2R,
which is exactly the remaining battery power of agent ai. Observe that since agents in A have met all agents
in B, agents in A, located at the center of the star, have the information of all agents except agent c. Then
agent am+1 moves to meet agent c. Agents am+1 and c have the information of all the agents. Hence, this
is a solution of the instance of the centralized convergecast problem.

Now assume that there exists a solution (strategy) to the convergecast problem. By Lemma 8, we can
assume that the convergecast strategy is simple. Consider the star G after the gathering phase of the simple
strategy. Each agent in A is at the center of the star. For 1 ≤ i ≤ m + 1, the agent ai has the remaining
power of 2R. For 1 ≤ i ≤ 3m, the agent bi is at distance xi from the center of the star and agent c is at
distance 2R from the center. Since the agents in A are the only agents with remaining battery power, they
must move to collect the information of agents in B∪C. We call this phase the collecting phase. Observe that
since agent c is at distance 2R from the center, it is impossible for agents in A to transport this information.
Indeed, when an agent reaches c, it has used all its battery power. Hence, the entire information must be
collected at the position of c. In order to collect the information, agents in A must go to the position of
each agent in B and transport the information of these agents to the center. The total cost to move these
information is at least twice the sum of the distances between each agent in B and the center. This is equal
i=1 3mxi = 2Rm. Then, this information must be moved to the position of c. This costs at least 2R.
Hence, the total cost of collecting information after the gathering phase is at least 2R(m + 1). The amount
of power available to the agents for the collecting phase is equal to the amount of power needed to collect
the information, since there are m + 1 agents each having power 2R. This means that during the collecting
phase, for 1 ≤ j ≤ 3m, agents cannot collectively use a power larger than 2xi to collect the information of
bi.
Suppose by contradiction that during the collecting phase, more than one agent in A enters an edge f
to collect the information of agent bi at distance xi from the center, for some i such that 1 ≤ i ≤ 3m. Let

to 2(cid:80)

20

setAof3magents......12R+1+x12R+1+x3m2R+1+x211setBofm+1agents1agentsetCofa1a2am+1b1b2b3mc4R+1uw be the agent that has reached the position of bi. If w comes back to the center, it has used at least power
2xi. Since at least one other agent has used some power to enter edge f, these agents have used more than
2xi battery power to collect information of agent bi. If w does not come back to the center, then some other
agent has to move the information to the center. If the agent w stops at distance r from the center, then at
least one other agent has to go to this position (at distance r from the center) and come back. Thus, the
cost is at least (2xi − r) + 2r > 2xi. In both cases, the agents have used more power than 2xi, which leads to
a contradiction. Hence, for each 1 ≤ i ≤ 3m, there is only one agent that collects the information of agent
bi and enters the corresponding edge.
We can assume, without loss of generality, that agent am+1 is the agent that transports the information
to c. Observe that am+1 cannot collect information from other nodes since moving to c uses exactly all
each 1 ≤ i ≤ m. We have 2(cid:80)
its remaining power. Hence, only agents in A(cid:48) = A \ {am+1} can collect the information of agents in B.
Let S1, S2, . . . , Sm be the partition of S deﬁned by Si = {xj | the information of bj is collected by ai}, for
x∈Si x ≤ 2R since each agent from A(cid:48) has battery power at most 2R. The
2(cid:80)
power needed to collect information of agents in B is 2mR which is exactly equal to the combined power
available to agents in A(cid:48). This means that each agent in A(cid:48) must use all its power to collect information and

x∈Si x = 2R. Hence, S1, S2, . . . , Sm is a solution to the instance of 3-partition.

Lemma 10. The centralized broadcast decision problem is strongly NP-hard for trees.

Proof. Again, we construct a polynomial-time many to one reduction from 3-Partition. The general structure
of the proof is similar as in Lemma 9 but details diﬀer.

We construct an instance (G, U ) of the centralized broadcast problem from an instance of 3-Partition as
follows. The graph G is a star with 5m leaves and U is the set of leaves of G. Hence, there are 5m agents,
each located at a leaf of the star. We consider a partition of the set of agents into three subsets: A, B and
C. The subset A = {ai | 1 ≤ i ≤ m} contains m agents. The leaves containing these agents are incident to
an edge of weight 1. The subset B = {bi | 1 ≤ i ≤ 3m} contains 3m agents. For 1 ≤ i ≤ 3m, the weight of
the edge incident to the leaf containing agent bi is 4R + 1 + xi. The subset C = {ci | 1 ≤ i ≤ m} contains m
agents. All leaves containing an agent in C are incident to an edge of weight 6R + 1. Figure 2 depicts the
star obtained in this way. The battery power P allocated to each agent is equal to 4R + 1 and agent a1 is
the source agent. The construction can be done in polynomial time. We show that the constructed instance
of the centralized broadcast problem gives answer yes if and only if the original instance of 3-partition gives
answer yes.

Figure 2: Instance of centralized broadcast problem from an instance of 3-partition.

First, assume that there exists a solution S1, S2, . . . , Sm for the instance of the 3-partition problem. We
show that the agents can solve the corresponding instance of the centralized broadcast problem using the
following strategy. For each i, agent ci moves at distance 2R from the center and for each 1 ≤ i ≤ 3m, agent
bi moves at distance xi from the center. At this point, all these agents have used all their battery power.
Each agent in A moves to the center of the star. Hence, each agent ai obtains the information of a1. For

21

setAof3magents......14R+1+x14R+1+x3m4R+1+x211setBofmagentsmagentssetCofa1a2amb1b2b3m6R+1ucmc1c26R+16R+1...center of the star. The cost of this movement is 2(cid:80)

1 ≤ i ≤ m and each of the three agents bj such that xj ∈ Si, agent ai moves to meet bj and goes back to the
xj∈Si = 2R. Observe that since agents in A have met
all agents in B, all agents except those in C have the information of a1. Each agent ai moves to meet agent
ci. Each agent ci obtains the information of a1. Hence, this is a solution to the instance of the centralized
broadcast problem.

between each agent in B and the center. This is equal to 2(cid:80)

Now assume that there is a solution (strategy) to the broadcast problem. By Lemma 8, we can assume
that the centralized broadcast strategy is simple. Consider the star G after the gathering phase of the simple
strategy. Each agent in A is at the center of the star. For 1 ≤ i ≤ m, the agent ai has the remaining power
of 4R. For 1 ≤ i ≤ 3m, the agent bi is at distance xi from the center of the star. For 1 ≤ i ≤ m, agent ci
is at distance 2R from the center. Since the agents in A are the only agents with remaining battery power,
they must move to give the information to agents in B ∪ C. Observe that since each agent ci is at distance
2R from the center, an agent in A that moves to meet an agent ci has not enough power to meet another
depleted agent afterwards. Hence, each agent ai must meet exactly one agent cj. Without loss of generality,
we can assume that each agent ai meets ci. Before agents in A meet agents in C, they must meet agents
in B. The total cost to give the information to all agents in B is at least twice the sum of the distances
i=1 3mxi = 2Rm. The total cost to give the
information to agents in C is 2Rm. The amount of power available to the agents in A is 4Rm, which is
exactly the power needed for broadcast. Assume for the sake of contradiction that two or more agents in A
enter the same edge incident to the leaf of an agent bi. In this case, one of the agents must meet bi. This
costs the agent 2xi and other agents have used some power to enter this edge. This gives a contradiction
because the total cost is more than the available power. Thus, we can assume that each agent bj meets
exactly one agent ai. Let S1, S2, . . . , Sm be the partition of S deﬁned by Si = {xj | bj met ai}, for each
x∈Si x ≤ 2R since the total power that agents in A can use to meet agents in B is
at most 2Rm. The power needed to give information to agents in B is 2mR which is exactly equal to the
combined power available to agents in A. This means that each agent in A must use all its power to meet

1 ≤ i ≤ m. We have 2(cid:80)
agents in B and 2(cid:80)

x∈Si x = 2R. Hence, S1, S2, . . . , Sm is a solution to the instance of 3-partition.

Lemma 11. The centralized convergecast decision problem and the centralized broadcast decision problem
are in NP.
Proof. We consider the veriﬁer-based deﬁnition of NP. Consider the strategy S of the agents for an instance of
the centralized convergecast or centralized broadcast problems. We construct the certiﬁcate for the instance
as follows. We say that a meeting of two or more agents is useful if at least one of the agents received a new
piece of information during this meeting. Each agent participates in at most k − 1 useful meetings where
k is the number of agents. Hence, there are at most k(k − 1) useful meetings. The certiﬁcate contains the
list of all useful meetings in chronological order. For the i-th meeting, the certiﬁcate encodes the identities
of the meeting agents and the location of the meeting: a node xi or an edge (ui, vi) of the graph G.
If
the meeting has occurred on an edge, the certiﬁcate encodes a variable di. The variable di represents the
distance between ui and the meeting point pi. If a previous meeting of number j has occurred on the same
edge, the certiﬁcate encodes if di < dj, or di = dj or di > dj. For each of the meeting agents, the certiﬁcate
also encodes the node from which it has entered the edge (ui or vi) just before the meeting and the node
(cid:48) deﬁned as follows. For each
from which it exits the edge just after the meeting. We consider the strategy S
useful meeting in chronological order, the meeting agents move to the meeting location following a shortest
path from their previous position. If the meeting occurs on an edge, the meeting agents enter and exit the
(cid:48) is a convergecast strategy since each time an agent has
edge using the node encoded in the certiﬁcate. S
collected a new piece of information in S, it collects the same information during the corresponding meeting
(cid:48) as in S since they move to the same meeting
in S
(cid:48) deﬁned by the certiﬁcate. The veriﬁer
points using shortest paths. The veriﬁer simulates the strategy S
ﬁrst checks that all the agents possess the entire information at the end of the algorithm. This can be done
in polynomial time. Then, the veriﬁer computes the distance traveled by each agent. These distances are
linear sums of variables di with 1 ≤ i ≤ k(k − 1) and of a constant. Finding an assignment of the variables,

(cid:48). Moreover, the agents use at most as much power in S

22

such that the distance traveled by each agent is less or equal than P , can be done in polynomial time using
linear programming. Thus, the certiﬁcate can be veriﬁed in polynomial time.

Theorem 3 is a direct consequence of Lemmas 9, 10 and 11.
Since both decision problems concerning convergecast and broadcast are NP-hard for the class of trees,
the same is true for their optimization counterparts, i.e., computing the smallest amount of power that is
suﬃcient to achieve convergecast or broadcast. In spite of that, we will show how to obtain, in polynomial
time, a 2-approximation of the power needed to achieve centralized convergecast on arbitrary graphs and a
4-approximation of the power needed to achieve centralized broadcast on arbitrary graphs.

Let D(G, A) = max∅(cid:40)X(cid:40)A{minx∈X,y∈A\X{dG(x, y)}}, where dG(x, y) is the distance between x and y in

G. The following proposition shows a relation between D(G, A) and the above optimal power values.

Proposition 1. Consider a conﬁguration (G, A) for convergecast and a conﬁguration (G, A) with a speciﬁed
OP T for any source agent in (G, A).
source agent for broadcast. Then D(G, A) ≤ 2P c
Proof. We prove the proposition for the case of convergecast. The proof for broadcast is similar. Suppose,
by contradiction, that there is a partition of A into X and A \ X such that for each x ∈ X and y ∈ A \ X
the distance between x and y is greater than 2P c
OP T . It means that no agents in X can meet an agent in
A \ X using power P c
OP T . This contradicts the fact that there is a convergecast strategy in G using battery
power P c
OP T . Hence, for every partition of A into X and A \ X, there exist agents x ∈ X and y ∈ A \ X
that are at distance at most 2P c

OP T and D(G, A) ≤ 2P b

OP T .

In view of Proposition 1, the following theorem shows that the convergecast problem has a polynomial-

time 2-approximation.

Theorem 4. Consider a conﬁguration (G, A). There is a polynomial algorithm computing a convergecast
strategy in which each agent uses power D(G, A).

Proof. We formulate algorithm KnownGraph which produces the desired convergecast strategy. The param-
eters of the algorithm are the graph G and the nodes corresponding to the initial positions of agents (stored
in A[1 : k]).

Algorithm 1: KnownGraph(a weighted graph G, an array A[1:k] of nodes)

strategy = empty_stack;
V := {A[1]};
P := 0;
repeat

choose a couple (u, v) ∈ V × (A \ V ) such that d(u, v) is minimal;
V := V ∪ {v};
P ath := shortest path between u and v;
push(strategy, (v, P ath, u));
P = max{P, d(u, v)};

until V = A;
repeat

(v, P ath, u) = pop(strategy);
agent starting in v moves to u following path P ath;

until strategy = empty_stack;

Let (ui, vi) be the nodes chosen at the i-th iteration of the ﬁrst loop and let Vi be the value of V at the
end of the i-th iteration. We set u0 = A[1] and V0 = {v0}. We show, by induction, that at the start of
the i-th iteration of the second loop, agents that started in Vk−i hold collectively all the information. It is
clearly true for i = 1. Assume by induction that it is true for i. The agent that started at vk−i moves to
node uk−i = vk−j for some j > i, during the i-th iteration of the second loop. After this move, the agent
that started at vk−j has the information of the agent that started at vk−i. Agents in Vk−(i+1) collectively

23

hold all the information. Hence, the property is true for i + 1 and this concludes the argument by induction.
At the end of the algorithm, the agent at A[1] has all the information since V0 = {A[1]}.
Let A be the set of agents. Consider the partition of A into sets Vi−1 and A \ Vi−1. We have d(ui, vi) ≤
D(G, A) since (ui, vi) is the couple (u, v) ∈ Vi−1 × (A \ Vi−1) such that d(u, v) is minimal. Hence, no agent
will traverse distance larger than 2P c
In O(n3) time, it is possible to precompute all shortest paths between u and v for all u, v ∈ A. Each
iteration of the ﬁrst repeat loop can be computed in O(n2) time and there are k − 1 such iterations where
k ≤ n is the number of agents. Hence, executing the ﬁrst repeat loop takes time O(n3). The execution the
second repeat loop takes time O(n2). Hence, the overall complexity of the algorithm is O(n3).

OP T by Proposition 1.

The above theorem gives the following corollary for the broadcast problem on arbitrary graphs.

Corollary 3. The broadcast problem on arbitrary graphs has a polynomial-time 4-approximation.

Proof. Let (G, A) be a conﬁguration with an arbitrary source agent a. By Theorem 4, there is a convergecast
strategy S for (G, A) using power at most D(G, A) that can be computed in polynomial time. Let b be the
agent that collects all information upon completion of this strategy. Consider the strategy S(cid:48) which consists
of performing the reverse of all moves of S in the reverse order. The strategy S(cid:48) is a broadcast strategy
for source agent b. Hence, the strategy S followed by S(cid:48) is a broadcast strategy for source agent a. The
required power is at most 2D(G, A) which gives a 4-approximation of the broadcast problem in view of
Proposition 1.

5 Distributed convergecast and broadcast on trees
In this section, we consider the convergecast and the broadcast problem in the distributed setting. As
explained in the introduction, we consider weighted trees with agents at every leaf. In view of Proposition 1,
the following theorem implies that there exists a 2-competitive distributed algorithm for the convergecast
problem on trees.

Theorem 5. Consider a conﬁguration (T, A) where T is a tree and A contains all the leaves of T . There
exists a distributed convergecast algorithm in which each agent uses power at most D(T, A).
Proof. The idea behind the algorithm is similar to the saturation technique used for message passing systems
(see chapter 2.6.1 of [36]). Each agent starting at a leaf moves until it reaches the neighbor of its starting
position. When an agent reaches a node, it waits until an agent has arrived from each incident edge except
one. When this happens, the agent with the most remaining power moves via the edge from which no agent
has arrived. One can show that each agent will not move more than D(T, A) and thus twice P c
OP T by
Proposition 1. At some point, the saturation occurs, i.e., two agents meet inside an edge or agents meet at
a node coming from all incident edges. At this point, the convergecast is achieved.

The pseudocode of the algorithm (executed distributedly by all agents) is the following.

Algorithm 2: UnknownTree

collecting = false;
while collecting = false do

Wait until there is at most one port unused by an agent incoming at the current node;
if all ports of the current node were used by incoming agents then

collecting = true

if the agent has used less power than any other agent present at the node and collecting = false then

Move through the unused incoming port until you meet another agent or reach a node;

else collecting = true if the agent is inside an edge then collecting = true

First, we show that if each agent executes Algorithm 2 then, eventually, one agent will hold all the
information. Consider an agent a executing the algorithm. Let Ta(t) be the subtree rooted at the last
visited node and containing all nodes accessible from the current position of a by shortest paths containing

24

a non-null part of the last edge traversed by agent a. Hence, when a enters a new node u, u is added to Ta.
We show by induction on the number of nodes of Ta that a has the initial information of every agent that
started at a node of Ta. For |Ta| = 1, this is true since a is the only agent that started in Ta. The size of
Ta grows only when a enters or exits some node v. When a enters a new node v, we show that any agent
that started at v did not move yet. Assume by contradiction that there is an agent b that started at v and
has moved before the arrival of a. It means that agents have arrived from all but one edge incident to v.
In that case, agent b follows the edge from which no agent has arrived. Hence, the only possible edge that
agent b can follow is the edge taken by agent a to arrive at v. This leads to a contradiction since agents a
and b must have met inside the edge and agent a would have stopped before reaching v.

When an agent a moves from a node v of degree δ, there were δ − 1 agents b1, b2, . . . , bδ−1 that have
arrived at v before. By the induction hypothesis, each agent bi, for 1 ≤ i ≤ δ − 1, has collected all the
information from agents starting inside the subtree Tbi. Since agent a moves in the only direction from
which no agent has arrived, it has the information of every agent that started in Ta = Tb1 ∪ Tb2 ∪···∪ Tbδ−1.
This concludes the proof by induction.
Observe that for each 1 ≤ i ≤ k the tree Tai grows until either ai meets agents that have arrived from
all incoming ports of its current position, or another agent aj with more power moves in a yet unexplored
In the latter case, Tai ⊆ Taj and the tree Taj will grow under the same conditions. Thus,
direction.
i=1Tai will eventually be equal to T . This happens when either two agents u1, u2 meet inside an edge
∪k
or δ agents u1, u2, . . . , uδ meet at a node of degree δ. These agents have the entire information since
Tu1 ∪ Tu2 ∪ ··· ∪ Tuδ = T (δ = 2 if the meeting occurs on an edge).
It remains to show that the agents do not use more battery power than D(T, A). Let p be the point where
some agent a has ﬁnished the execution of the algorithm (when the value of collecting becomes true for this
agent) and let v be the last node visited by a before reaching p. Consider Ta when a exited v. Agent a is the
agent starting in Ta for which the distance between its initial position and the node v was the smallest, since
it was the agent that has used the least power when it arrived at v. Thus, the distance between the initial
position of an agent in Ta and an agent in G \ Ta is less or equal than D(G, A). Hence we conclude that
P ≤ D(T, A). By Property 1, we have that D(T, A) ≤ 2P c

OP T and hence the algorithm is 2-competitive.

Again in view of Proposition 1, the following corollary implies that there exists a 4-competitive distributed

algorithm for the broadcast problem on trees.

Corollary 4. Consider a conﬁguration (T, A) with a speciﬁed source agent, where T is a tree and A contains
all the leaves of T . There exists a distributed broadcast algorithm in which each agent uses power at most
2D(T, A).
Proof. Let (T, A) be a conﬁguration with a speciﬁed source agent a. All agents execute the following
algorithm consisting of two phases. In the ﬁrst phase, each agent executes algorithm UnknownTree from
the proof of Theorem 5 to achieve convergecast. Suppose that B is the set of agents that get the total
information at the end of the execution of this phase. All agents in B are aware of this fact. Agents in B
start the second phase. We call them active agents. Each active agent backtracks to its initial position, by
walking along the path reverse to the one used in phase 1. On its way, it activates all agents it meets and
conveys all the information to each of them. The process continues until each agent is activated and is back
at its initial position. At this time, all information and in particular information of the source agent a is
known to all agents. The energy spent is at most 2D(T, A).

The following theorem shows that no distributed algorithm may oﬀer a better competitive ratio than 2

for convergecast or for broadcast, even if we only consider line networks.

Theorem 6. Consider any δ > 0, and any value of power P . There exists an integer n and a conﬁguration
P os[1 : n] of n agents on the line such that :

• there exists a centralized convergecast strategy using power P and there is no deterministic distributed
strategy allowing the agents to solve convergecast when the amount of power given to each agent is
(2 − δ)P .

25

• there exists a centralized broadcast strategy using power P for source agent starting at P os[1] and there
is no deterministic distributed strategy for source agent starting at P os[1] allowing the agents to solve
broadcast when the amount of power given to each agent is (2 − δ)P .
Before proving Theorem 6, we prove two technical lemmas.

Lemma 12. Consider any ε > 0, an amount of power P , and a set {a1, a2, . . . , ak, ak+2} of k + 2 agents
located at positions P os[1 : k + 2]. If P os[k + 2] − Reachc
LR(1, P ) ≤ P − ε, and if k ≥ log(P/ε), there exists
i ≤ k + 1 such that Reachc
Proof. Suppose, by contradiction, that the lemma does not hold. It means that for each 1 ≤ i ≤ k + 1,
Reachc

LR(i, P ) < P os[i + 1]. Therefore, in view of the claim from the proof of Lemma 5, we have

LR(i, P ) ≥ P os[i + 1].

Reachc

LR(k + 1, P ) = 2kReachc

LR(1, P ) + (2k − 1)P − Σk

i=12k−iP os[i]
i=12k−i(P os[i] − Reachc
LR(1, P ) + (2k − 1)P − Σk
i=12k−i(P − ε)
LR(1, P ) + (2k − 1)P − Σk
LR(1, P ) + (2k − 1)P − (2k − 1)(P − ε)
LR(1, P ) + (2k − 1)ε

= Reachc
≥ Reachc
≥ Reachc
≥ Reachc

LR(1, P ))

LR(1, P ) + P − ε ≥ P os[k + 2], a

Consequently, if k ≥ log(P/ε), we have Reachc

LR(k + 1, P ) ≥ Reachc

contradiction.
Lemma 13. Consider an amount of power P , a distance d > 0, and a set {a1, a2, . . . , ak} of k agents located
at positions P os[1 : k]. Let R1 be the closest point from P os[2] that a1 reached. Assume that P os[2]−R1 = d.
Suppose that all the agents execute the same distributed deterministic algorithm and do not know their
initial position, and assume that some agent a ∈ {a2, a3 . . . , ak} meets agent a1 before any couple of agents
in {a1, a2, . . . , ak} meet. Then, a = a2 and when a2 meets a1, for each 2 ≤ i ≤ k, agent ai is located on
P os[i] − d.
Moreover, if Rmax is the rightmost point reached by some agent knowing the initial information of agent
a1, then Rmax ≤ P os[k] + P − 2d.
Proof. Since all agents are executing the same distributed deterministic algorithm, let us consider the exe-
cution of the algorithm until some agent meets agent a1. During this period, all the agents perform exactly
the same moves. Since they started simultaneously, no agent meets another agent before agent a2 meets
a1 at point R1 or to the left of R1. When agent a2 meets a1, it has moved at least a distance of d. Until
this meeting between a1 and a2, every other agent has also moved a distance of at least d, and is located at
distance d to the left of its starting position. Consequently, no agent can go further than P − 2d to the right
of P os[k].

Proof of Theorem 6 :
n = 2l(l + 2) + 2.
on the left (resp. right) end of the line on position s(cid:48)
a set Ai of k agents that start on distinct positions within a segment [si, s(cid:48)
1 ≤ i ≤ 2l + 1, the distance between si and s(cid:48)
and s(cid:48)

Let ε = δP/4 and σ = ε/2 = δP/8. Let l = (cid:98)log(8/δ)(cid:99), k = l + 2 and
Consider a set of n agents positioned on a line as follows (See Figure 3). There is an agent a1 (resp. an)
0 = 0 (resp. s2l+1 = (cid:96)). For each 1 ≤ i ≤ 2l, there is
i] of length σ such that for each
i−1 is 2(P − ε). In other words, for each i, si = (2P − 3σ)i − σ
i = (2P − 3σ)i.
First, let us consider the execution of the optimal convergecast centralized algorithm for this conﬁguration.
We claim that if the amount of power given to each agent is P , then convergecast is achievable. We show by
LR(ik + 1, P ) ≥ s(cid:48)
induction on i that for every i, Reachc
i + P −  = si+1 − P + . For i = 0, Reachc
LR(1, P ) =
LR((i− 1)k + 1, P ) ≥ si − P + . Consider the agents in
P os[1] + P > P −  = s1 − P + . Suppose that Reachc
Ai, i.e., the agents aik+1−j, j ∈ [0, k − 1]. Since s(cid:48)
LR((i− 1)k + 1, P ) ≤ P −  + σ = P − σ < P , and
i − Reachc
since l + 1 ≥ log(P/σ), we know by Lemma 12 that Reachc
LR(k(i− 1) + l + 2, P ) ≥ P os[k(i− 1) + l + 3]. Since
k > l + 1, it follows that Reachc
i + P − . Consequently,

LR(ik, P ) = P os[ik] + P ≥ si + P = s(cid:48)

i + P − σ ≥ s(cid:48)

26

Figure 3: The conﬁguration in the proof of Theorem 6.

this concludes the proof by induction. Since Reachc
RL(2lk + 2, P ),
P is suﬃcient to solve convergecast. Notice that the same strategy guarantees broadcast for source agent a1
for conﬁguration P os[1 : n] and power P .

LR(2lk + 1, P ) ≥ s2l+1 − P +  ≥ Reachc

∈ [l + 1, j − 1],

j−1 + (22l−1−j − 2)ε,

Consider any distributed deterministic algorithm where the amount of power given to each agent is
(2 − δ)P , yielding a strategy S of the agents. A step in S is a moment when two agents meet. Let tl,i (resp.
tr,i) be the ﬁrst step where an agent from Ai meets an agent from Ai(cid:48) with i(cid:48) < i (resp. i(cid:48) > i). Let Ri (resp.
Li) be the rightmost point (resp. the leftmost point) reached by any agent from Ai after some agent in Ai
has met an agent from Ai(cid:48) with i(cid:48) < i (resp. i(cid:48) > i). For any 1 ≤ i < j ≤ 2l + 1, let Ai,j = Ai ∪ Ai+1 . . .∪ Aj.
We show by induction on time t that for each i ∈ [1, l] such that tl,i ≤ t and for each j ∈ [l + 1, 2l] such
that tr,j ≤ t, the following properties hold:
(i) tl,i < tl,i(cid:48) for each i(cid:48)
(ii) for each i(cid:48)
(iii) Ri ≤ si+1 − (2i+2 − 2)ε and Lj ≥ s(cid:48)
(iv) no agent in Ai(cid:48), i(cid:48)

∈ [i + 1, l], if tl,i(cid:48) > t then tr,i(cid:48) > t, and for each j(cid:48)

∈ [i + 1, l] and tr,j < tr,j(cid:48) for each j(cid:48)

∈ [l + 1, j − 1], if tr,j(cid:48) > t then tl,j(cid:48) > t

≥ l meets any agent from A1,l−1 and no agent in Aj(cid:48), j(cid:48)

≤ l + 1 meets any agent

from Al+2,2l+1.
First, consider t = 0. Clearly, R1 ≤ s(cid:48)

≤ j has met any other agent from a set Ai(cid:48)(cid:48), i(cid:48)

Suppose that the induction hypothesis holds for all t(cid:48) < t and let i = max{i(cid:48)

0+2P−δP = 2P−4ε = s1−2ε and L2l+1 ≥ s2l+1−2P +δP = s2l+2ε.
Since all agents in A1,2l execute the same algorithm, they all perform the same moves until either the leftmost
agent of A1 meets a0 (at step tl,1), or the rightmost agent of A2l meets a2l+1 (at step tr,2l). In the ﬁrst case,
it shows that tl,1 < tl,i and tl,1 < tr,i for any i ≥ 2. By Lemma 13, R1 ≤ s(cid:48)
1 + (2 − δ)P − 2(s1 − R0) ≤
s2 − 2P + 2ε + 2P − 4ε − 2(2ε) = s2 − 6ε. By symmetry, in the second case, tr,2l < tr,i and tr,2l < tl,i for
any i ≤ 2l − 1 and L2l ≥ s(cid:48)
2l−1 + 6ε. In both cases, properties for (i) − (iii) hold for t = 0. Notice that for
any i, j ∈ [1, 2l], no agent in Ai has met an agent of Aj. Hence, property (iv) hold for t = 0.
| tl,i(cid:48) < t} + 1 and
j = min{j(cid:48) + 1 | tr,j(cid:48) < t}− 1. Note that by (iv), we have i ≤ l − 1 and j ≥ l + 2. By (i) and (ii), before step
(cid:54)= i(cid:48)(cid:48). Thus, since all agents in Aij
t, no agent in Ai(cid:48), i ≤ i(cid:48)
execute the same deterministic distributed algorithm starting simutaneously, they have performed exactly
the same moves and they have not met any other agent before step t. Suppose that an agent from Aij meets
another agent at step t. Then, either the leftmost agent ai from Ai meets an agent ai(cid:48) from Ai(cid:48) with i(cid:48) < i,
or the rightmost agent from Aj meets an agent from Aj(cid:48) with j(cid:48) > j.
By symmetry, it is enough to consider only one case. In the following, we assume that ai ∈ Ai meets
an agent ai(cid:48) ∈ Ai(cid:48) with i(cid:48) < i at step t. In this case, t = tl,i and thus tl,i < tl,i(cid:48) and tl,i < tr,i(cid:48) for each
i < i(cid:48)
≤ j; consequently, properties (i) and (ii) hold for t. Moreover, by induction hypothesis, the meeting
between ai and ai(cid:48) occurs at a point p ≤ Ri(cid:48) ≤ Ri−1 ≤ si − (2i+1 − 2)ε. First suppose that i ≤ l − 1.
By Lemma 13, we have Ri ≤ s(cid:48)
i + 2P − δP − 2(2i+1 − 2)ε = si+1 − 2P + 2ε + 2P − 4ε − 2i+2ε + 4ε =
si+1 − (2i+2 − 2)ε, and thus property (iii) and (iv) holds for t. Then suppose that i = l ≥ log(8/δ) − 1. We
have R(cid:48)
i ≤ sl − (8/δ − 2)δP/4 = sl − 2P + δP/2 < sl − 2P + δP . But this is impossible since the initial
position of the leftmost agent a of Al is P os[lk + 1] ≥ sl and the power available to a is 2P − δP . This
concludes the proof by induction. In particular, no agent from A1,l ever meets any agent from Al+1,2l+1 and

27

s00s1s012(P−)2(P−)σσσ2(P−)s2s2ls2l+1s02s02lconsequently, S is neither a distributed convergecast strategy nor a distributed broadcast strategy for any
source agent.
Theorems 5 and 6 show that for the distributed convergecast problem on the class of trees, the competitive

ratio 2 is optimal.

6 Conclusion and open problems
In the centralized setting, we showed that the breaking point in complexity between polynomial and NP-
hard, both for the convergecast and for the broadcast problem, is already present inside the class of trees.
Namely, agents’ optimal power and the strategy using it can be found in polynomial time for the class of
lines but it is NP-hard for the class of arbitrary trees. Nevertheless, we found polynomial approximation
algorithms for both these problems. It remains open if better approximation constants can be found.

The problem of a single information transfer by mobile agents between two stationary points of the
network, which we called carry in the case of lines, is also interesting. In particular, it is an open question
whether the problem of ﬁnding optimal power for this task is NP-hard for arbitrary tree networks or if a
polynomial-time algorithm is possible in this case. Our reduction from 3-partition is no longer valid for this
problem.

In the distributed setting, we showed that 2 is the best competitive ratio for the problem of convergecast.
However, our distributed algorithm for the broadcast problem is only 4-competitive. It remains open to ﬁnd
the best competitive ratio for the broadcast problem.

Additional natural questions related to our research include other variations of the agent model, e.g.,
agents with unequal power, agents with non-zero visibility, labeled agents in the distributed setting, as well
as fault-tolerant issues, such as unreliable agents or networks with possibly faulty components.

References
[1] S. Albers. Energy-eﬃcient algorithms. Communications of the ACM, 53(5):86–96, 2010.

[2] S. Albers and M. R. Henzinger. Exploring unknown environments. In Proceedings of the 29th Annual

ACM Symposium on Theory of Computing (STOC), pages 416–425, 1997.

[3] S. Alpern and S. Gal. The theory of search games and rendezvous, volume 55, Springer, 2003.

[4] C. Ambühl. An optimal bound for the mst algorithm to compute energy eﬃcient broadcast trees
In Proceedings of the International Colloquium on Automata, Languages, and

in wireless networks.
Programming (ICALP), volume 3580 of Lecture Notes in Computer Science, pages 1139–1150, 2005.

[5] H. Ando, Y. Oasa, I. Suzuki, and M. Yamashita. Distributed memoryless point convergence algorithm
for mobile robots with limited visibility. IEEE Transactions on Robotics and Automation, 15(5):818–828,
1999.

[6] D. Angluin, J. Aspnes, Z. Diamadi, M. Fischer, and R. Peralta. Computation in networks of passively

mobile ﬁnite-state sensors. Distributed Computing, 18(4):235–253, 2006.

[7] V. Annamalai, S. Gupta, and L. Schwiebert. On tree-based convergecasting in wireless sensor networks.

In IEEE Wireless Communications and Networking, volume 3, pages 1942–1947, 2003.

[8] J. Augustine, S. Irani, and C. Swamy. Optimal power-down strategies. In Proceedings of the 45th Annual

IEEE Symposium on Foundations of Computer Science (FOCS), pages 530–539, 2004.

[9] I. Averbakh and O. Berman. A heuristic with worst-case analysis for minimax routing of two travelling

salesmen on a tree. Discrete Applied Mathematics, 68(1–2):17 – 32, 1996.

28

[10] B. Awerbuch, M. Betke, R. L. Rivest, and M. Singh. Piecemeal graph exploration by a mobile robot.

Information and Computation, 152(2):155 – 172, 1999.

[11] B. Awerbuch, O. Goldreich, R. Vainish, and D. Peleg. A trade-oﬀ between information and communi-

cation in broadcast protocols. Journal of the ACM, 37(2):238–256, 1990.

[12] Y. Azar. On-line load balancing. A. Fiat and G.Woeginger, Online Algorithms: The State of the Art,

Lecture notes in computer science, 1442:178–195, 1998.

[13] R. Baezayates, J. Culberson, and G. Rawlins. Searching in the plane. Information and Computation,

106(2):234 – 252, 1993.

[14] R. Bar-Yehuda, O. Goldreich, and A. Itai. On the time-complexity of broadcast in multi-hop radio
networks: An exponential gap between determinism and randomization. Journal of Computer and
System Sciences, 45(1):104 – 126, 1992.

[15] M. Bender and D. Slonim. The power of team exploration: two robots can learn unlabeled directed
graphs. In Proceedings of the 35th Annual Symposium on Foundations of Computer Science (FOCS),
pages 75–85, 1994.

[16] M. A. Bender, A. Fernández, D. Ron, A. Sahai, and S. Vadhan. The power of a pebble: Exploring and

mapping directed graphs. Information and Computation, 176(1):1 – 21, 2002.

[17] M. Betke, R. Rivest, and M. Singh. Piecemeal learning of an unknown environment. Machine Learning,

18(2-3):231–254, 1995.

[18] A. Blum, P. Raghavan, and B. Schieber. Navigating in unfamiliar geometric terrain. SIAM Journal on

Computing, 26(1):110–137, 1997.

[19] D. Bunde. Power-aware scheduling for makespan and ﬂow. Journal of Scheduling, 12(5):489–500, 2009.

[20] F. Chen, M. Johnson, Y. Alayev, A. Bar-Noy, and T. La Porta. Who, when, where: Timeslot assignment

to mobile clients. IEEE Transactions on Mobile Computing, 11(1):73–85, 2012.

[21] M. Cieliebak, P. Flocchini, G. Prencipe, and N. Santoro. Solving the robots gathering problem. In Pro-
ceedings of the International Colloquium of Automata, Languages and Programming (ICALP), volume
2719 of Lecture Notes in Computer Science, pages 1181–1196. Springer Berlin Heidelberg, 2003.

[22] R. Cohen and D. Peleg. Convergence properties of the gravitational algorithm in asynchronous robot

systems. SIAM Journal on Computing, 34(6):1516–1528, 2005.

[23] A. Cord-Landwehr, B. Degener, M. Fischer, M. Hüllmann, B. Kempkes, A. Klaas, P. Kling, S. Kur-
ras, M. Märtens, F. Meyer auf der Heide, C. Raupach, K. Swierkot, D. Warner, C. Weddemann, and
D. Wonisch. A new approach for analyzing convergence algorithms for mobile robots.
In L. Aceto,
M. Henzinger, and J. Sgall, editors, In Proceedings of the International Colloquium of Automata, Lan-
guages and Programming (ICALP), volume 6756 of Lecture Notes in Computer Science, pages 650–661,
2011.

[24] S. Das, P. Flocchini, N. Santoro, and M. Yamashita. On the computational power of oblivious robots:
Forming a series of geometric patterns. In Proceedings of the 29th ACM SIGACT-SIGOPS Symposium
on Principles of Distributed Computing (PODC), pages 267–276, 2010.

[25] X. Deng and C. H. Papadimitriou. Exploring an unknown graph. Journal of Graph Theory, 32(3):265–

297, 1999.

[26] M. Dynia, M. Korzeniowski, and C. Schindelhauer. Power-aware collective tree exploration.

In Ar-
chitecture of Computing Systems (ARCS), volume 3894 of Lecture Notes in Computer Science, pages
341–351, 2006.

29

[27] P. Flocchini, G. Prencipe, N. Santoro, and P. Widmayer. Gathering of asynchronous robots with limited

visibility. Theoretical Computer Science, 337(1–3):147 – 168, 2005.

[28] P. Fraigniaud, L. Gasieniec, D. R. Kowalski, and A. Pelc. Collective tree exploration. Networks,

48(3):166–177, 2006.

[29] G. Frederickson, M. Hecht, and C. Kim. Approximation algorithms for some routing problems. SIAM

Journal on Computing, 7(2):178–193, 1978.

[30] M. R. Garey and D. S. Johnson. Computers and Intractability: A Guide to the Theory of NP-

Completeness. W. H. Freeman & Co., New York, NY, USA, 1979.

[31] S. Irani, S. Shukla, and R. Gupta. Algorithms for power savings. ACM Transactions on Algorithms,

3(4), 2007.

[32] A. Kesselman and D. R. Kowalski. Fast distributed algorithm for convergecast in ad hoc geometric
radio networks. Journal of Parallel and Distributed Computing, 66(4):578 – 585, 2006. Algorithms for
Wireless and Ad-Hoc Networks.

[33] B. Krishnamachari, D. Estrin, and S. Wicker. The impact of data aggregation in wireless sensor net-
works. In Proceedings of the 22nd International Conference on Distributed Computing Systems Work-
shops, pages 575–578, 2002.

[34] N. Megow, K. Mehlhorn, and P. Schweitzer. Online graph exploration: New results on old and new

algorithms. Theoretical Computer Science, 463:62–72, 2012.

[35] R. Rajagopalan and P. Varshney. Data-aggregation techniques in sensor networks: a survey. IEEE

Communications Surveys & Tutorials, 8(4):48–63, 2006.

[36] N. Santoro. Design and analysis of distributed algorithms, volume 56. John Wiley & Sons, 2006.

[37] I. Stojmenovic and X. Lin. Power-aware localized routing in wireless networks. IEEE Transactions on

Parallel and Distributed Systems, 12(11):1122–1133, 2001.

[38] I. Suzuki and M. Yamashita. Distributed anonymous mobile robots: Formation of geometric patterns.

SIAM Journal on Computing, 28(4):1347–1363, 1999.

[39] M. Yamashita and I. Suzuki. Characterizing geometric patterns formable by oblivious anonymous mobile

robots. Theoretical Computer Science, 411(26–28):2433 – 2453, 2010.

[40] F. Yao, A. Demers, and S. Shenker. A scheduling model for reduced cpu energy. In Proceedings of the

36th Annual Symposium on Foundations of Computer Science, pages 374–382, 1995.

30

