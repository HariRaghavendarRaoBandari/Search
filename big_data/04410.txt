6
1
0
2

 
r
a

 

M
4
1
 
 
]

.

A
C
h
t
a
m

[
 
 

1
v
0
1
4
4
0

.

3
0
6
1
:
v
i
X
r
a

Exponentials and Laplace transforms

on nonuniform time scales

CTS-UNINOVA, Department of Electrical Engineering, Faculty of Science and Technology,

Manuel Ortigueira

Universidade Nova de Lisboa, Portugal

Delﬁm F. M. Torres

Center for Research and Development in Mathematics and Applications (CIDMA),

Department of Mathematics, University of Aveiro, 3810–193 Aveiro, Portugal

Juan Trujillo

Universidad de La Laguna, Departamento de An´alisis Matem´atico,

38271 La Laguna, Tenerife, Spain

Abstract

We formulate a coherent approach to signals and systems theory on time scales.
The two derivatives from the time-scale calculus are used,
i.e., nabla (for-
ward) and delta (backward), and the corresponding eigenfunctions, the so-called
nabla and delta exponentials, computed. With these exponentials, two gener-
alised discrete-time Laplace transforms are deduced and their properties studied.
These transforms are compatible with the standard Laplace and Z transforms.
They are used to study discrete-time linear systems deﬁned by diﬀerence equa-
tions. These equations mimic the usual continuous-time equations that are
uniformly approximated when the sampling interval becomes small.
Impulse
response and transfer function notions are introduced. This implies a uniﬁed
mathematical framework that allows us to approximate the classic continuous-
time case when the sampling rate is high or to obtain the standard discrete-time
case, based on diﬀerence equations, when the time grid becomes uniform.

time-scale calculus, exponentials, generalized Laplace and Z

Keywords:
transforms, systems theory, fractional derivatives.
2010 MSC: 26E70, 44A10, 65T50.

1. Introduction

The analysis of nonuniformly sampled data is a very important task having
large spread application in ﬁelds like astronomy, seismology, paleoclimatology,
genetics and laser Doppler velocimetry [5]. The “jitter” in Telecommunications
is a well known problem [24]. Very interesting is the heart rate variability of
the signal obtained from the “R” points [37]. Traditionally, most interesting

Email addresses: mdo@fct.unl.pt (Manuel Ortigueira), delfim@ua.pt (Delﬁm F. M.

Torres), jtrujill@ullmat.es (Juan Trujillo)

Submitted 30/Dec/2015; revised 28/Feb/2016; accepted 14/Mar/2016 in Commun. Nonlinear Sci. Numer. Simul.

techniques for dealing with this kind of signals pass by interpolation, to obtain
a continuous-time signal that is analysed by current methods [2, 22, 23]. An
alternative approach proposed in [25] allows a conversion from irregular to regu-
lar samples, maintaining the discrete-time character. Other approaches, include
the study of diﬀerence equations with fractional delays [6, 32]. However, no spe-
ciﬁc tools for dealing directly with such signals were developed. In particular,
no equivalent to the Laplace or Z transforms were proposed. As well-known,
the use of Laplace and Z transforms, to solve diﬀerential and diﬀerence linear
equations, is very common in almost all scientiﬁc activities [38]. Normally, uni-
form time scales are used, but frequent applications use nonuniform scales. This
makes important to obtain generalisations of such transforms for other kinds of
scales. Some attempts have been made [1, 3, 4, 11, 12], but let us an unsat-
isfactory feeling: they are not true generalisations of the classic formulations.
The main diﬃculty is in the starting point, i.e., the exponentials used to deﬁne
the transforms. Usually, on time scales, causal exponentials are used instead of
two-sided exponentials [18, 26, 27, 31]. On the other hand, no correct interplay
between nabla and delta derivatives and exponentials and transforms has been
established. Such interplay was stated for fractional derivatives in the recent
paper [36].

Here, in a ﬁrst step, we clarify nabla and delta deﬁnitions and their mean-
ing and relation with causality. With nabla (causal) and delta (anti-causal)
derivatives, we deﬁne corresponding linear systems. Each concept is used to
deﬁne two exponentials over the whole time scale and not only above or below a
given time reference. With each exponential, a given transform is deﬁned. We
start from the inverse transform and only later we deﬁne the direct transform.
With the nabla exponential, we deﬁne the inverse nabla transform through a
Mellin-like integral on the complex plane. The direct nabla transform is de-
ﬁned with the help of the delta exponential. For the delta transform we reverse
the exponentials. Having deﬁned the exponentials, we study the question of
existence, arriving to the concept of region of convergence. The unicity of the
transforms is also investigated. This lead us to generalise the convolution and
correlation concepts with the help of equivalent time scales. The concept of
transfer function, as the eigenvalue corresponding to the respective exponential,
is introduced. The inverse Laplace transform is the so called impulse response,
i.e., the response of the system when the input is a delta function. We consider
also the conversion from one time scale to another one that is equivalent to
it. In passing, we prove the existence of no periodicity and, consequently, the
inability to deﬁne Fourier transforms and series. This is the main drawback of
the theory.

2. On the calculus on time scales

A powerful approach into the continuous/discrete uniﬁcation/generalization
was introduced by Aulbach and Hilger through the calculus on measure chains
[3, 28]. However, the main popularity was gained by the calculus on time scales
[4, 14, 16]. These are nonempty closed subsets T of the set R of real numbers,
particular cases of measure chains. We remark that the name may be misleading,
since the term scale is used in Signal Processing with a diﬀerent meaning. On
the other hand, in many problems we are not dealing with time.

2

Let t be the current instant. Using the language of the time-scale calculus,
the previous next instant is denoted by ρ(t). Similarly, the next following point
on the time scale T is denoted by σ(t). One has

ρ(t) = t − ν(t),

σ(t) = t + µ(t),

where ν(t) and µ(t) are called the graininess functions. We avoid here the use
of the terms forward and backward graininess, since they have meanings that
are diﬀerent from the ones used in Signal Processing applications. Let us deﬁne

ν0(t) := 0,

νn(t) := νn−1(t) + ν(cid:0)t − νn−1(t)(cid:1) , n ∈ N,

and ρ0(t) := t, ρn(t) := ρ(cid:0)ρn−1(t)(cid:1), n ∈ N. Note that ν1(t) = ν(t) and

ρ1(t) = ρ(t). When moving into the past, we have

ρ0(t) = t = t − ν0(t),
ρ1(t) = ρ(t) = t − ν(t) = t − ν1(t),
ρ2(t) = ρ(ρ(t)) = ρ(t) − ν(ρ(t)) = t − ν(t) − ν(t − ν(t)) = t − ν2(t),

...

ρn(t) = t − νn(t).

Moving into the future, the deﬁnitions and results are similar:

µ0(t) := 0, µn(t) := µn−1(t) + µ(cid:0)t + µn−1(t)(cid:1) ,

σ0(t) := t,

σn(t) := σ(cid:0)σn−1(t)(cid:1) ,

n ∈ N, and we have σn(t) = t + µn(t).

Example 1. Let T = hZ, h > 0. In this case one has µn(t) = νn(t) = nh,
σn(t) = t + nh, and ρn(t) = t − nh, n = 0, 1, 2, . . .

With our notations, a time scale of isolated points is written in the form

T = {. . . , ρm(t), . . . , ρ2(t), ρ1(t), t, σ1(t), σ2(t), . . . σn(t), . . .}.

This means that we can refer to all instants in the time scale T with respect to
only one point t, taken as the reference. For example, if T = Z, such instant is
usually taken as t = 0. We must be careful with the meaning of diﬀerences like
t − τ , because they can make no sense. Assume that t and τ are in T with t > τ .
This means that there exits an integer N such that τ = ρN (t) = t − νN (t) and
t = σN (τ ) = τ + µN (τ ). It follows that t − τ = νN (t) = µN (τ ). Let us now
deﬁne

νn(t) := ρn−1(t) − ρn(t), µn(t) := σn(t) − σn−1(t),

as the nth values of the graininess functions from t. One can then see that the
diﬀerence t − τ above is equal to the sum of the graininess values µn to go from
τ to t,

t − τ = µN (τ ) = µ(τ ) + µ(τ + µ(τ )) + · · · =

µn(τ ),

N

Xn=1

3

or, which is the same, the sum of the graininess values νn to go from t to τ ,

t − τ = νN (t) = ν(t) + ν(t − ν(t)) + · · · =

νn(t).

N

Xn=1

interval to be the width of the interval. Let T =S∞

In this work we consider time scales T deﬁned by a set of discrete instants
tn, n ∈ Z, and by the corresponding graininess functions. These instants are
isolated points or the consecutive boundary points deﬁning a closed interval, in
which the graininess functions are null. In this case, we deﬁne the graininess
n=1 [2n, 2n + 1]. Accordingly
to what we just said, the graininess functions are zero inside the intervals starting
at the even integers 2n and ﬁnishing at the odd 2n+ 1. Moreover, µ(2n+ 1) = 1.
To ﬁx ideas and have a useful framework, we assume that our domain is
a set formed by joining two sets: a set of isolated points and a set made by
closed intervals. Now we consider that T is the set of the given discrete set
and the extreme points of the intervals. We consider the discrete set T =
{tn : n ∈ Z} and attach to each point a label with:
isolated, left dense, or
right dense. Each left dense point (say tk) represents all the points tk−1 + h
with the convention of inserting a limit computation when computing the nabla
derivative and transforming a summation into an integral. If the point is right
dense the situation is similar for the interval deﬁned by tk − h and for the delta
derivative. We deﬁne a direct graininess

and reverse graininess

tn = tn−1 + νn, n ∈ Z,

tn = tn+1 − µn, n ∈ Z,

where we avoid representing the reference instant t0. These deﬁnitions are
suitable for dealing with some of the most interesting time scales we ﬁnd in
practice. However, we have some diﬃculties in doing some kind of manipulations
that are also very common. Let us consider a time scale deﬁned on R and
unbounded when t → ±∞. For example, a time scale deﬁned by

tn = nT + τn, n ∈ Z,

T > 0,

|τn| <

T
2

,

which we can call “almost linear sequence” [33], or

tn = tn−1 + τn, n ∈ Z,

τn > 0.

We can consider intervals with null graininess. These time scales lead to the
generalized Laplace and Z transforms. Now, consider a power transformation
of the time scale:

θ = qt.

It is clear that the new time scale Θ may have zones with null graininess that
cannot be treated as referred above.
In doing limit computations, when the
graininess is null, in the above case we substitute it by an h that decreases to
zero. In this case we must substitute by t(1 − q) or t(q−1 − 1), with q < 1.
Besides, the new time scale is in R+. We will have time scales like

θn = θn, n ∈ Z,

θ > 0,

4

or

θn = θn−1 · τn, n ∈ Z,

τn > 0.

Now, consider a new time scale T, called a super time scale, resulting from T
through

T = {¯t ∈ R : ¯t = tn − tk, tn, tk ∈ T} .

If the origin 0 is in T, then T contains T. If not, join both and continue to call
it T that will surely have 0 as an element. Let us consider all possible sub time
scales that we construct from T and that we can put in bijection with T. Call
them equivalent grids; later we will give some justiﬁcation for this name.

3. On the Laplace and Z transforms

The importance of Laplace and Z transforms in the study of linear time
invariant systems is unquestionable. Many books enhance such fact. However,
most of them do not show clearly why they are important and this led to mis-
interpretations that conditioned their generalizations to time scales [10, 30].

3.1. Relations between transforms and linear time invariant systems

Let us ﬁrst consider the continuous time case. In this case, the input-output

relation for linear time invariant (LTI) systems is given by convolution [39]:

y(t) =

+∞

Z−∞

h(τ )x(t − τ )dτ,

(1)

where x(t) is the input signal and h(t) is the impulse response. Let x(t) = est,
t ∈ R. As it is easy to see, the output is given by y(t) = H(s)est with H(s)
given by

H(s) =

+∞

Z−∞

h(t)e−stdt,

which is called the transfer function. As we see, H(s) is the bilateral (two-
sided) Laplace transform of the impulse response of the system. We showed
that the exponential, deﬁned in R, is the eigenfunction of a continuous-time
LTI system. This shows why we must use the two-sided Laplace transform,
although the one-sided has greater popularity. However, the exponential used
in this transform is not an eigenfunction of a LTI system. It is currently used
because of the initial conditions, but it fails in the fractional case [34]. Moreover,
the two-sided has as special case the Fourier transform: we only have to make
s = iω. In the following, we always consider the two-sided Laplace transform.1
Now we consider the Laplace transform of a signal resulting from the uniform
sampling of a given function, f (t), deﬁned in R. Let the ideal sampler be the
comb deﬁned by a sequence of Dirac deltas [33]:

p(t) =

+∞

Xn=−∞

δ(t − nh),

1We easily obtain the one-sided Laplace transform by multiplying the function to be trans-

formed by the Heaviside unit step.

5

where h > 0 is the sampling interval. The ideal sampled function is, by the
properties of the Dirac delta,

+∞

fp(t) =

f (nh)δ(t − nh).

Xn=−∞

Its Laplace transform is given by

Fp(s) =

+∞

Xn=−∞

f (nh)e−shn,

which can be considered the discrete Laplace transform of function fn = f (nh).
With a change of variable z = esh, we obtain the Z transform

+∞

F (z) =

fnz−n.

(2)

Xn=−∞

As it is easy to verify, the discrete exponential zn is also the eigenfunction
of a discrete-time linear system deﬁned by linear diﬀerence equations.
It is
important to remark that z−1 represents a delay in time. Frequently, we convert
continuous-time systems to discrete-time systems by doing a conversion from s
to z through the Euler transformation

or the bilinear transformation

s =

1 − z−1

h

s =

2
h

1 − z−1
1 + z−1 .

The former seems more natural, due to its relation to the incremental ratio used
to deﬁne the derivative,

f ′(t) = lim
h→0

f (t) − f (t − h)

h

,

(3)

and to the approximation z−1 ≈ 1 − sh for small h. However, the bilinear
transformation is considered to be more useful, since on converting the left s
half plane into the unit circle in the z plane allows the design of discrete-time
systems from continuous-time prototypes. From these considerations, we must
restate that:

• The two-sided transforms appear naturally as consequence of the fact that

exponentials are eigenfunctions of LTI systems.

• The variable s in the Laplace transform represents the derivative, while
z−1 in the Z transform represents a delay and (2) establishes a relation
between them.

• The derivative in (3) is preferable because it uses the present and past

values in contra-position to

f ′(t) = lim
h→0

f (t + h) − f (t)

h

(4)

that uses the present and future values. We say that the former is causal,
while this one is anti-causal.

6

So, when going into a general formulation using time scales as domain, we should

• use two-sided transforms;

• deﬁne systems with causal derivatives;

• be careful about the meanings of s and z.

3.2. The current Laplace transform on time scales

The Laplace transform deﬁned on time scales was subject of several publi-
cations but most of them consider the one-sided Laplace transform [1, 8, 11, 12,
13, 15, 19, 20, 29, 40]. Anyway, the bilateral was considered in [21], where it
was deﬁned by

F (s) =

+∞

Z−∞

f (t)eσ

⊖s(t)∆t,

where es(t) is the generalized exponential

es(t) = exp

t

Z0

ln (1 + sµ(τ ))

µ(τ )

∆τ,

⊖s(t) = e⊖s(σ(t)), and ⊖s = −s
eσ
(1), but if the time scale is Z, then we obtain

1+sµ(t) . When the time scale is R, we reobtain

F (s) =

+∞

Xn=−∞

f (n)(1 + s)−(n+1).

Let us make the substitution z = 1 + s. We have

F (z) =

+∞

Xn=−∞

f (n)z−(n+1)

that does not coincide with the Z transform (2) since we have n + 1 instead of
n. This seems to be insigniﬁcant but may create great diﬃculties as the results
we obtain are diﬀerent from the conventional ones.

4. Derivatives and inverses

In what follows h ∈ R+.

4.1. Nabla and delta derivatives

We deﬁne the nabla derivative by

f ∇(t) =( f (t)−f (ρ(t))

ν(t)

h

lim
h→0

f (t)−f (t−h)

and the delta derivative by

f ∆(t) =( f (σ(t))−f (t)

µ(t)

lim
h→0

h

f (t+h)−f (t)

7

if ν(t) 6= 0

if ν(t) = 0

if µ(t) 6= 0

if µ(t) = 0.

(5)

(6)

As it can be seen, the ﬁrst one is causal, while the delta derivative is anti-causal.
One is the dual of the other [17]. We can give another form to these derivatives,
in agreement with our comments done before about time scales. We deﬁne the
nabla derivative by

f ∇(tn) =(

f (tn)−f (tn−1)

νn

f (tn)−f (tn−h)

h

lim
h→0+

for any tn that is not left dense,
for tn left dense,

where νn = tn − tn−1, and the delta derivative by

f ∆(tn) =(

f (tn+1)−f (tn)

µn

f (tn+h)−f (tn)

h

lim
h→0+

for any tn that is not right dense,
for tn right dense,

(7)

(8)

= f ∆0

where µn = tn+1 − tn. The derivatives of higher-order are deﬁned as usual.
Let f ∇0
= f . We deﬁne the nabla and delta derivatives of order n as
f ∇n
= f ∇
and f ∆1

= (cid:16)f ∇n−1(cid:17)∇

= (cid:16)f ∆n−1(cid:17)∆

, n = 1, 2, . . . In particular, f ∇1

and f ∆n

= f ∆.

4.2. Nabla and delta anti-derivatives

We are going to obtain the inverses of the above derivatives that we will call
derivatives of order −1 or anti-derivatives. To obtain the searched formulae, we
proceed as if ν(t) and µ(t) are nonnull. The null situation will be included later.
We rewrite (5) as

f (t) − f (t − ν(t))

ν(t)

= g(t)

and manipulate it to obtain f (t) as a function of g(t):

f (t) = f (t − ν(t)) + ν(t)g(t).

To obtain the nabla and delta inverses, we proceed recursively as stated above.
We then have

∞

f ∇−1

(t) =

νn+1(t)f (t − νn(t))

and

f ∆−1

(t) = −

µn+1(t)f (t + µn(t)),

Xn=0
Xn=0

∞

where we assume that f ∇−1
(+∞) = 0. It is easy to show that
these functions are really the inverses corresponding to (6) and (7). To obtain
a diﬀerent formulation, start from (7) and (8) and proceed similarly. We obtain

(−∞) = f ∆−1

and

f ∇−1

(tn) =

n

Xm=−∞

νmf (tm)

µmf (tm).

(9)

f ∆−1

(tn) = −

∞

Xm=n

8

In the constant graininess situation, νn = µn = nh, νn = µn = h, and we recover
the expressions obtained in [36] from the generalized fractional derivative. If
f (t) ≡ 1, then we conclude immediately that

f ∇−1

(t) = t

and

f ∆−1

(t) = −t.

This is a special case that does not verify the above condition:
it is nonnull
at inﬁnite. This means that we must be careful when trying to obtain the
polynomials by computing the anti-derivatives. We return to this subject later.
Those expressions lead us to deﬁne the corresponding nabla and delta integrals
over the interval [a, b] respectively by

and

I ∇f = f ∇−1

(b) − f ∇−1

(a)

I ∆f = f ∆−1

(a) − f ∆−1

(b).

Putting a = b − νk(b), one has νn+1(a) = νn+1+k(b) and νn(a) = νn+k(b), and
we can write

I ∇f =:

b

Zσ(a)

f (t)∇t =

k−1

Xn=0

νn+1(b)f (b − νn(b)).

Similarly, with b = a + µk(a), we have µn+1(b) = µn+1+k(a) and µn(b) =
νn+k(a) that leads to

ρ(b)

I ∆f =:

Za

f (t)∆t =

k−1

Xn=0

µn+1(a)f (a + µn(a)).

5. The nabla and delta general exponentials

We consider ﬁrst the nabla derivative. We want to discover the eigenfunction
of this operator. We begin by introducing the reference instant t0 and the
current instant t. The relations between both depend on the two cases t > t0
or t < t0. We start from t0 and go to t using the values of the graininess. In
the ﬁrst case, we easily write t = t0 + µn(t0), where n is the number of steps to
go from t0 to t. For the second case, we have t0 − νm(t0).

5.1. The nabla exponential

Starting from (5), we write successively

and

f (t) − f (t − ν(t))

ν(t)

= sf (t),

f (t) − f (t − ν(t)) = sν(t)f (t),

f (t) [1 − sν(t)] = f (t − ν(t)).

9

On the other hand, going back in time, we have

f (t − ν(t)) [1 − sν(t − ν(t))] = f (t − ν(t − ν(t)))

that can be substituted above to get

f (t) [1 − sν(t)] [1 − sν(t − ν(t))] = f (t − ν(t − ν(t))).

We can write

n

f (t) ·

[1 − sνk(t)] = f (t − νn(t)).

Yk=1

Consider now a time t0 at which we assume f (t0) = 1. For t = t0 + µn(t0) we
then have

that can be written as

n

[1 − sµk(t0)]−1 ,

f (t) =

Yk=1

f (t) = exp"−

n

Xk=1

(1 − sµk(t0))#

f (t) = exp
−

t

Zt0

ln (1 − sµ(τ ))

µ(τ )

∇τ
 .

From these equalities, we conclude that the nabla generalized exponential is
given by

e∇(t, t0) =

n

1
m


Qk=1

Qk=1

if

if

if

t = tn > t0

t = t0

t = tm < t0

(10)

[1 − sµk(t0)]−1

[1 − sνk(t0)]

10

or

or

For t < t0 we must invert the above recursion. In fact, we have

f (t0) [1 − sν(t0)] = f (t0 − ν(t0))

and with repetition, and noting that f (t0) = 1, we have

m

Yk=1

[1 − sνk(t0)] = f (t0 − νm(t0)),

m

f (t) =

Yk=1
f (t) = exp" m
Xk=1
f (t) = exp
Zt


t0

[1 − sνk(t0)] ,

ln (1 − sνk(t0))#
∇τ


ν(τ )

ln (1 − sν(τ ))

.

or

e∇(t, t0) =

1

exp"−


exp(cid:20) t0
Rt

ln(1−sµ(τ ))

µ(τ ) ∇τ#

t

Rt0

ln(1−sν(τ ))

ν(τ ) ∇τ(cid:21)

if

if

if

t = tn > t0

t = t0

t = tm < t0.

(11)

To illustrate (10) and (11), we are going to compute them for particular cases.

Example 2. We obtain the nabla generalized exponential (10)–(11) in diﬀerent
time scales.

• Let T = hZ, h > 0. We make t0 = 0 and put ν(t) = µ(t) = h, t = nh,
n ∈ Z, leading to e∇(t, 0) = [1 − sh]−n. Putting z−1 for [1 − sh], as
suggested by (2), we obtain the current discrete-time exponential, zn.

• Let T = R. Return to the above case and put h = t

n . As

lim

n→∞(cid:18)1 −

st

n(cid:19)−n

= est,

we obtain e∇(t, 0) = est.

also have t0 = 0 and the graininess functions are given as follows:

m=0(2n + mh) with N ∈ N+

0 and h = 1/N . Here we

• Let T = S∞

n=−∞SN

ν(t) =(1

h

if t = 2n, n ∈ Z,
otherwise

and

µ(t) =(1

h

if t = 2n + 1, n ∈ Z,
otherwise.

This time scale leads to the following exponential:

– if t = 2n + M h, n ≥ 0, 0 ≤ M ≤ N , then

e∇(t, 0) = [1 − s]−n [1 − sh]−nN −M ;

– if t = −2n + 1 − M h, n > 0, 0 ≤ M ≤ N , then

e∇(t, 0) = [1 − s]n [1 − sh]nN +M .

(12)

(13)

• Let T = S∞

n=−∞ [2n, 2n + 1]. This case can be treated from the last one.
More precisely, we only have to make h going to zero. We start by noting
that since N h = 1, one has t = 2n + M h = n + nN h + M h, which is
equivalent to nN + M = t−n

h . We ﬁrst obtain that
h ] = e−s(t−n),

t ∈ [2n, 2n + 1] .

[1 − sh]−[ t−n

lim
h→0

Therefore, if t ≥ 0, then

e∇(t, 0) = [1 − s]−n e−s(t−n),

t ∈ [2n, 2n + 1] .

Similarly, if t < 0, then

e∇(t, 0) = [1 − s]n es(t−n+1),

t ∈ [−2n, −2n + 1] .

11

• We now consider a time scale with a periodic graininess µ(t + τ ) = µ(t).
Consider a set of positive real numbers M = {µi ∈ R+, i = 1, . . . N }, and
the time scale

T0 = {τ0, τ1, . . . τN −1} =(0, µ1, µ1 + µ2, µ1 + µ2 + µ3, . . . ,
Let τ =PN

a time scale T with periodic graininess τ :

i=1 µi and prolong the time scale T0 to left and right to obtain

µi) .

N −1

Xi=1

T =

+∞

[n=−∞

Tτ

0 (n),

(14)

where Tτ

0 (n) = {t + nτ : t ∈ T0}. The nabla exponential in T is given by:

– if t = nτ + τi, 0 ≤ i < N , n = 0, 1, . . ., then

e∇(t, 0) =

N −1

Yk=0

[1 − sµk]−n

i

Yk=0

[1 − sµk]−1 ;

– if t = −nτ + τi, 0 ≤ i < N , n = 1, 2, . . ., then

e∇(t, 0) =

[1 − sµk]n

N −1

Yk=0

i

Yk=0

[1 − sµk] .

5.2. The delta exponential

Following a similar procedure as in Section 5.1, we can obtain the exponential
corresponding to the delta derivative. Starting from (6), we write successively

and

f (t + µ(t)) − f (t) = sµ(t)f (t)

f (t + µ(t)) = f (t) [1 + sµ(t)] .

Starting from t0 and repeating the above relation n times, we obtain that

f (t0 + µn(t0)) = f (t0) ·

[1 + sµk(t0)] ,

n

Yk=1

leading to

n

Similarly to the nabla case, it is not a hard task to conclude that if t < t0, then

f (t) =

[1 + sµk(t0)] .

Yk=1

f (t) =

n

Yk=1

[1 + sνk(t0)]−1 ,

12

n

1
m


Qk=1

Qk=1
exp" t
Rt0
exp(cid:20)−

1




[1 + sµk(t0)]

[1 + sνk(t0)]−1

ln(1+sµ(τ ))

µ(τ ) ∆τ#

ln(1+sν(τ ))

ν(τ ) ∆τ(cid:21)

t0

Rt

if

if

if

t = tn > t0

t = t0

t = tm < t0

if

if

if

t = tn > t0

t = t0

t = tm < t0.

(15)

(16)

leading to the delta exponential

e∆(t, t0) =

or

e∆(t, t0) =

Let us see what happens in the particular cases considered in Example 2.

Example 3. We obtain the delta exponential (15)–(16) in diﬀerent time scales.

• If T = hZ, h > 0, then we make again t0 = 0, ν(t) = µ(t) = h, and t = nh,
n ∈ Z, leading to e∆(t, 0) = [1 + sh]n. Putting z for [1 + sh], as suggested
by (4), we obtain once again the current discrete-time exponential, zn.

• If T = R, then we return to the previous case and put h = t

n . As

lim

n→∞(cid:20)1 +

st

n(cid:21)n

= est,

we obtain that e∆(t, 0) = est.

• Let T = S∞

n=−∞SN

0 and h = 1/N , and t0 = 0.
The graininess functions ν and µ are given by (12) and (13), respectively.
This time scale leads to the following delta exponential:

m=0 2n + mh with N ∈ N+

– if t = 2n + M h, n ≥ 0, 0 ≤ M ≤ N , then

e∆(t, 0) = [1 + s]n [1 + sh]nN +M ;

– if t = −2n + 1 − M h, n > 0, 0 ≤ M ≤ N , then

e∆(t, 0) = [1 + s]n [1 + sh]−nN −M .

• Let T = S∞

n=−∞ [2n, 2n + 1]. This case can be treated from the last one.
We only have to make h tend to zero. We start by noting that N h = 1
and t = 2n + M h = n + nN h + M h, that is, nN + M = t−n
h . We ﬁrst
obtain that

[1 + sh][ t−n

h ] = es(t−n),

t ∈ [2n, 2n + 1] ,

lim
h→0

concluding that if t ≥ 0, then

e∆(t, 0) = [1 + s]n es(t−n),

t ∈ [2n, 2n + 1] .

Similarly, if t < 0, then

e∆(t, 0) = [1 + s]−n e−s(t−n+1),

t ∈ [−2n, −2n + 1] .

13

• Consider now the time scale (14) with periodic graininess µ(t + τ ) = µ(t).

The corresponding delta exponential is given by:

– if t = nτ + τi, 0 ≤ i < N , n = 0, 1, . . ., then

e∆(t, 0) =

[1 + sµk]n

N −1

Yk=0

i

Yk=0

[1 + sµk] ;

– if t = −nτ + τi, 0 ≤ i < N , n = 1, 2, . . ., then

e∆(t, 0) =

N −1

Yk=0

[1 + sµk]−n

i

Yk=0

[1 + sµk]−1 .

5.3. Properties of the exponentials

The exponentials (10)–(11) and (15)–(16) have interesting properties that
we describe in the following. To enhance the importance of the parameter s, in
the sequel we use the notations e∇(t, t0; s) and e∆(t, t0; s).

1. Changing the role of instants. If we change the role of t and t0, then

e∇(t0, t; s) = 1/e∇(t, t0; s).

The delta exponential satisﬁes similar relation: e∆(t0, t; s) = 1/e∆(t, t0; s).
2. Relation between nabla and delta exponentials. The function deﬁned in

(15) with the substitution of −s for s is the inverse of (9):

e∆(t, t0; s) = 1/e∇(t, t0; −s).

3. As h → 0, both nabla and delta exponentials converge to est. This was

already seen in Examples 2 and 3.

4. Attending to the way how both exponentials were obtained, we can easily

conclude that

and

[e∇(t, t0; s)]∇N

= sN e∇(t, t0; s)

[e∆(t, t0; s)]∆N

= sN e∆(t, t0; s),

where ∇N and ∆N denote respectively the N th order nabla and delta
derivative, N ∈ N. Later we try to generalize this property. We can say
that the exponentials are also eigenfunctions of the higher-order deriva-
tives.

5. Translation. An exponential deﬁned on a given time scale is called trans-
lation of e∇(t, t0; s) if it is obtained by a similar procedure but using a
diﬀerent reference instant τ0 ∈ T. This translation can be obtained by a
product of exponentials (cf. (17)).

6. It is important to know how exponentials increase/decrease for s ∈ C.
Let us consider the nabla case. The delta situation is similar and follows
straightforwardly, so we omit it here. Let hM = max(νk, µl) and hm =
min(νk, µl), k, l ∈ Z. The nabla exponential e∇(t, t0; s)

• is a real number for any real s;
• is positive for any real number s such that s < 1
hM

;

14

• oscillates for any real number s such that s > 1
hm
• is bounded for values of s inside the inner Hilger circle |1 − shm| = 1;
• has an absolute value that increases as |s| increases outside the outer

;

Hilger circle |1 − shM | = 1, going to inﬁnite as |s| → ∞.

This means that each graininess deﬁnes a circle centred at its inverse and
passing at s = 0. In general, we have inﬁnite circles that reduce to one
when the graininess is constant. When it is null, it degenerates into the
imaginary axis.

7. Product of exponentials. The following relations hold:

e∇(t, t0; s) · e∆(τ, t0; −s) = e∇(t, τ ; s)

= e∆(τ, t; −s).

(17)

Note that the product e∇(t, t0; s) · e∆(t, t0; v), s 6= v, is well deﬁned but
does not lead, in general, to an exponential as we deﬁned above, because
its parameter s (eigenvalue) is time dependent. The same happens with
the product of exponentials of the same type: e∇(t, t0; s) · e∇(t, t0; v) or
e∆(t, t0; s) · e∆(t, t0; v). Now let tn > tm. We have

e∇(tn, t0; s) = e∇(tm, t0; s) · e∇(tn, tm; s)

= e∇(tm, t0; s) · e∆(tm, tn; −s)

and

e∆(tn, t0; s) = e∆(tm, t0; s) · e∆(tn, tm; s)

= e∆(tm, t0; s) · e∇(tm, tn; −s).

In particular, if tm = tn − τ , then

e∇(tn, t0; s) = e∇(tn − τ, t0; s) · e∇(tn, tn − τ ; s)

(18)

(19)

and

e∇(tn − τ, t0; s) = e∇(tn, t0; s) · e∇(tn, tn − τ ; −s).

(20)

Relation (20) states the translation or shift property of an exponential,
and will be used later.

8. Scale change. Let a be a positive real number. We have:

e∇(at, t0; s) = e∇(t, t0; as).

If a < 0, a similar relation is obtained but involving the delta exponential.
9. Cisoids. For T = R the exponentials degenerate into the cisoids eiωt when
s = iω. Similarly, in T = hZ, h > 0, we obtain eiωnh. We put the question:
what happens in the general case? The answer is easy: on a general time
scale there are no cisoids. Thus, in general, there are no periodic signals.
This has a very important consequence: on a general time scale we cannot
deﬁne Fourier transforms, which is a powerful drawback of the theory.

The properties of the exponentials are here enlarged for measure chains T.
In the real line case, i.e., T = R, we obtain the ordinary exponential, whose
properties are well known. Very interesting and important is also the case
T = hZ, studied in [36].

15

6. Suitable general Laplace transforms

To deﬁne a Laplace transform, we adopt a point of view somehow diﬀerent
from the usual. We obtained exponentials that are eigenfunctions of the nabla
and delta derivatives. This means that we would like to express a given function
in terms of these exponentials. To do it, we start from the inverse transform.

6.1. The nabla inverse transform

Assume that we have a signal, f (t), deﬁned on a given time scale, that
has a given transform F∇(s) (undeﬁned for now; deﬁned later by (24)).
Its
inverse transform would serve to synthesize it from a continuous set of elemental
exponentials:

f (t) =

F∇(s)e∇(t, t0; s)ds,

(21)

1

2πiIC

1

=

min(νk ,µl) , centred at 1

where the integration path, C, is a simple closed contour in a region of analyt-
icity of the integrand and the poles introduced by the exponential. Consider
the Hilger circle with radius R > 1
R , and described
hm
in the counterclockwise direction. We will not consider other circles here, leav-
ing the subject for future studies. We call this region the fundamental region,
and we represent it by Rc. In the continuous case it degenerates into a vertical
straight line. Let us start with the simple situation corresponding to F∇(s) ≡ 1.
We are expecting to obtain an impulse as the inverse transformed function. Let
us try to compute it. As it is easy to observe, the integral is zero for t ≤ t0,
because the integrand is analytical. For t > t0, the integrand has n poles at the
points sk = 1
νk(t0) , k = 1, 2, . . . If n > 1 and the integration path includes all
the poles, then the integral is zero. So, only for n = 1 the integral is nonnull.
This means that to have a pole at n = 0 we have to introduce one. This leads
to change the integrand in the above formula (21) into

f (t) = −

1

2πiIC

F∇(s)e∇(t + µ(t), t0; s)ds,

(22)

which is our deﬁnition of inverse nabla Laplace transform. It is a simple task
to show that the inverse nabla Laplace transform of F∇(s) ≡ 1 is the impulse
δ(tn − t0) = 1
ν1(t0) . We can show that it is the derivative of the Heaviside unit
step deﬁned by

ǫ(t, t0) =(1

0

if
if

t ≥ t0,
t < t0,

t ∈ T. Now we are going to compute the nabla derivative of e∇(t + µ(t)). We
can immediately write that

[e∇(t + µ(t))]∇ =

e∇(t + µ(t), t0) − e∇(t + µ(t) − ν(t + µ(t)), t0)

ν(t + µ(t))

.

Let t ≥ t0. We have

[e∇(t + µ(t))]∇ =

n+1

Qk=1

[1 − sµk(t0)]−1 −

n

Qk=1

νn+1(t0)

[1 − sµk(t0)]−1

= s · e∇(t + µ(t)).

16

For t < t0 the situation is similar. With this result we prove one of the most
important properties of the nabla Laplace transform N LT :

where F∇(s) is the nabla Laplace transform of f (t), i.e., F∇(s) = N LT [f (t)].

N LT(cid:2)f ∇(t)(cid:3) = sF∇(s),

(23)

6.2. Properties of the nabla Laplace transform

We deduce the properties of the nabla Laplace transform from the inversion
integral. Precisely, the following properties hold (we assume s to be inside the
region of convergence of the nabla Laplace transform; this region will be deﬁned
soon):

• Linearity. It is an evident property that does not need any computation.

• Transform of the derivative. Attending to the equality (23), we easily

deduce, by repeated application of (23), that if N ∈ N0, then

restating a well known result in the context of the Laplace transform.

N LThf ∇N

(t)i = sN F∇(s),

• Time scaling. Let a be a positive real number.2 We have

N LT [f (at)] =

6.3. The nabla direct transform

1
a

F∇(cid:16) s
a(cid:17) .

The shift property (20) gives a suggestion of how to deﬁne the nabla Laplace
transform. In fact it must be deﬁned in terms of the delta exponential, due to
property (17) particularised to t → t + µ(t) and τ = t. We then have

+∞

F∇(s) =

νnf (tn)e∆(tn, t0; −s).

(24)

Xn=−∞

The region in the complex plane where the series (24) converges, is called “region
of convergence” of the nabla Laplace transform. In a general time scale, as we are
assuming, we cannot obtain current properties of the Laplace or Z transforms.
Particularising for the time scale hZ we easily deduce the modulation or shift
in s property [36]:

N LT [f (nh)e∇(nh, −s0)] = F∇(cid:18) s − s0

1 − s0h(cid:19) .

To obtain this result we only have to use the inverse transform (18). Similarly,
we can obtain that

N LT [f (nh)e∆(nh, −s0)] = F∇(s + s0 − ss0h).

Concerning the product or convolution in s, we easily obtain that

N LT [f (nh)g(nh)] = −

1

2πiI F∇(v)G∇(cid:18) v − s

1 − vh(cid:19) 1

dv.

1 − vh

To obtain this result, its enough to insert (22) into the ﬁrst member and use
the second equality of (18).

2It could be negative, but it is not interesting.

17

6.4. Examples

In general, it is diﬃcult to compute the direct transform. So we are going

to invert the problem: we look for the inverses of well known functions.

• Causal and anti-causal exponentials. A nabla causal exponential is deﬁned
by the inverse transform of the function 1
s−p . Begin by assuming that p
is in the region outside the Hilger circle deﬁned in Section 6.1. We have:

f (t) = −

1

2πiIC

1

s − p

e∇(t + µ(t), t0; s)ds.

If t < t0, then there are no poles in the region delimited by the integration
path C and the function is identically null. If t ≥ t0, then we can have
several poles inside and one outside the region bounded by the integration
path. The residue corresponding to p is equal to the negative sum of the
residues for the inner poles. We conclude that the nabla Laplace transform
N LT of the causal exponential is given by

N LT [e∇(t, t0; p)ǫ(t, t0)] =

1

s − p

(25)

for s inside Rc. In fact, and as a simple reasoning can show, the region
of convergence is larger than Rc, since the integrand is analytical outside
the C circle. This can be enlarged until it meets the point s = p. We can
say that the region of convergence Rp is the interior of a circle with center
at rp = |p|2
2ℜ(p) and passes on p. With a likewise reasoning, we obtain a
similar result for the anti-causal exponential. In this case the pole must
be inside the region referred above. We conclude that when t ≥ t0 all the
poles of the integrand are inside the integration region. The integral is
zero for t < t0 and there is only one pole s = p in this case. We obtain

N LT [−e∇(t, t0; p)ǫ(−t − µ(t), t0)] =

1

s − p

for s outside Rp.

• Unit steps. From the above results, a passage to the limit as p → 0 allow

us to conclude that the nabla Laplace transform of the unit step is 1/s:

N LT [ǫ(t)] =

1
s

N LT [−ǫ(−t − µ(t))] =

1
s

for s inside Rc and

for s outside Rc.

• Causal power-exponential. Take (25) and compute the usual derivative
(s−p)2 . The derivative
with respect to p. The right hand side is equal to
of the exponential in the left hand side can be computed with the help of
the logarithm:

1

d
dp

ln e∇(t, t0; p) =

18

n

µk,

Xk=0

and

d
dp

e∇(t, t0; p) =

n

Xk=0

µke∇(t, t0; p) = (t − t0)e∇(t, t0; p)

N LT [(t − t0)e∇(t, t0; p)ǫ(t, t0)] =

1

(s − p)2

for s inside Rc. We can generalise this result for any order and also for
anti-causal exponentials.

Extending the approach of [35], these results can be used to compute the im-
pulse response of a linear system described by diﬀerential equations of constant
coeﬃcients. Consider a dynamic equation on time scales with the general format

ak (y(t))∇k

=

N

Xk=0

bk (x(t))∇k

,

M

Xk=0

where aN = 1. The orders N and M are any given positive integers. With the
nabla Laplace transform, we obtain the transfer function

H(s) =

Y (s)
X(s)

=

N

Pk=0
Pk=0

M

bksk

aksk

.

(26)

Its inverse gives the impulse response of the system [36, 39]. To obtain it, we ﬁx
a region of convergence, decompose it in partial fractions, and invert each one
using the above results. Most of the results presented in [36] apply also here
and are left to the reader.

6.5. Uniqueness of the nabla transform

From relation (22), we state a very important conclusion:

For a given nabla Laplace transform, there are doubly inﬁnite in-
verse transforms, accordingly to the chosen time scale and the region
of convergence.

This means that with a given region of convergence and a ﬁxed time scale, the
inverse nabla Laplace transform is unique. Changing the region of convergence,
we obtain a function with diﬀerent characteristics. Let us return back to the
shift property (20) and rewrite it in the format

N LT [f (¯t)] = e∆(¯t + τ, ¯t; −s)F∇(s).

This shows how to interpolate the original function f (t), t ∈ T, to a new time
scale deﬁned by the “diﬀerences” between all the elements in T. Let T be the
super time scale associated with T, i.e., T = {¯t : ¯t = t − τ with t, τ ∈ T}. This
means that we have a function ¯f (t) deﬁned in T such that ¯f (t) = f (t) for t ∈ T,
because T ⊂ T. This function can be considered as an interpolated version of
the original function. Each new time grid extracted from T and equivalent to T
originates another function with the same transform. We can write:

+∞

Xn=−∞

νnf (tn)e∆(tn, t0; −s) =

+∞

Xn=−∞

¯νnf (τn)e∆(τn, t0; −s).

19

Multiplying both sides by e∇(tn+1, t0; s) and integrating accordingly to (22), we
obtain that

f (tn) = −

+∞

Xk=−∞

¯νkf (τk)

1

2πiIC

e∆(τk, t0; −s)e∇(tn+1, t0; s)ds

and

+∞

f (tn) = −

Xk=−∞

¯νkf (τk)

1

2πiIC

e∇(tn+1, τk; s)ds.

In particular, for tn = nh (we can choose h as the average of ¯νk)

f (nh) = −

+∞

Xk=−∞

¯νkf (τk)

1

2πiIC

e∇((n + 1)h, τk; s)ds.

This shows how we can convert a nonuniformly sampled function into another
regularly sampled (cf. [33]). This is very important, because in this framework,
we can use the results presented in [36]. The function

ϕ((n + 1)h, τk) = ¯νk

1

2πiIC

e∇((n + 1)h, τk; s)ds

is a generalisation of the well-known sinc function and (26) can be considered
as a generalisation of the Shanon–Whitacker theorem [39].

6.6. Existence

As for both the standard Laplace and Z transforms, also for the nabla
Laplace transform it is not an easy task to formulate necessary and suﬃcient
conditions of existence. We can easily state, however, suﬃcient conditions. Let
us consider a function f (t) assuming ﬁnite values for every ﬁnite tn, n ∈ Z. We
assume that it is asymptotically bounded by two exponentials:

|f (t)| < A · e∇(t, t0; a),

t > tna,

|f (t)| < B · e∇(t, t0; b),

t < tnb.

We can write that

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

na

+∞

f (tn)e∆(tn, t0; −s)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xn=−∞
Xn=nb
Xn=na+1

+ B

+∞

<

|f (tn)e∆(tn, t0; −s)| + A

nb−1

Xn=−∞

|e∇(t, t0; b)e∆(tn, t0; −s)|

≤

+∞

Xn=−∞

|f (tn)e∆(tn, t0; −s)|

|e∇(t, t0; a)e∆(tn, t0; −s)| .

According to the results obtained in Sections 5.3 and 6, we conclude that the
two inﬁnite summations converge inside and outside two circular regions with
center on the positive real line and passing at s = 0.

Remark 4. As pointed out in [7, 19], there are two deﬁnitions of “exponential
function”: “type I” and “type II”. The ﬁrst is essentially the deﬁnition currently
used when the time scale is R, which does not make sense on a general time scale.
Only the type II, as we do here, is suitable.

20

6.7. The delta transform

We studied carefully the transform suitable for dealing with causal systems.
This does not mean that we cannot formulate another transform taking the
delta exponential as the basis. It is not very diﬃcult to realise its formulation.
Similarly as before, each function f (t) can be synthesized by

f (t) =

1

2πiIC

F∆(s)e∆(t − ν(t), t0; s)ds,

where the integration path is the one used for the nabla transform. The relation
between the two exponentials suggests that we deﬁne the direct transform by

F∆(s) =

+∞

Xn=−∞

νnf (tn)e∇(tn, t0; −s).

(27)

6.8. Shift, convolution, and correlation

Although we already discussed something about the shift property, we need
to tell something more. Consider f (t) as an application from R to R. When
we write f (t − t0), t0 ∈ R, we know exactly its meaning and we can associate a
geometrical interpretation to it. We have no problem because both t − t0 and
f (t − t0) are well deﬁned. Now consider the situation we are dealing with: f (t)
is an application from T to R. In this case it may happen that t − t0 does not
belong to T and consequently f (t − t0) is not deﬁned. This means that we must
devise a meaning for f (t − t0). As we mentioned before, mainly in Section 5,
we took a reference point t0 that we used to state any instant in terms of the
graininess. So, instead of f (t), we should write f (t−t0). When writing f (t−t5),
for example, we are meaning that a new reference point was took. We can say
that we produced a shift. In conclusion, a shift is nothing else than a change in
the reference point. As consequence we can say that

F∇(s) =

+∞

Xn=−∞

νnf (tn)e∆(tn, t0; −s) =

+∞

Xn=−∞

νnf (tn − tN )e∆(tn, tN ; −s).

Our main problem here is to compute the nabla Laplace transform of a shifted
function. Let us consider a function g(tn) = f (tn − tm) for some instants
tn, tm ∈ T. The nabla Laplace transform of g(t) is

G∇(s) =

+∞

Xn=−∞

νnf (tn − tm)e∆(tn, t0; −s).

From (19) we can write

e∆(tn, t0; −s) = e∆(tm, t0; −s)e∆(tn, tm; −s)

that leads to

+∞

G∇(s) =

Xn=−∞

νnf (tn − tm)e∆(tn, tm; −s)e∆(tm, t0; s)

(28)

= e∆(tm, t0; s)F∇(s).

21

So, as in the classical case, the shift in time produces a multiplication by an
exponential in the transform domain.

Attending to (20) and (22), we have

f (t − tm) = −

1

2πiIC

F∇(s)e∇(t + µ(t), tm; s)e∆(tm, t0; s)ds.

Inserting the nabla Laplace transform expression inside the integral, we obtain
that

f (t−tm) =

+∞

Xn=−∞

νnf (tn)−

1

2πiIC

e∆(tn, t0; −s)e∇(t+µ(t), tm; s)e∆(tm, t0; s)ds,

where we attend to the fact that the nabla Laplace transform converges uni-
formly in the region of convergence. Then,

f (t − tm) =

+∞

Xn=−∞

νnf (tn)φ(t, tm)

(29)

with

φ(t, tm) = −

1

2πiIC

Using (19),

e∆(tn, t0; −s)e∇(t + µ(t), tm; s)e∆(tm, t0; s)ds.

e∆(tn, t0; −s)e∆(tm, t0; s) = e∆(tn, t0; −s)e∆(tn, t0; s)e∆(tm, tn; −s)

= e∆(tn, t0; −s2)e∆(tm, tn; −s),

φ(t, tm) = −

e∇(σ(tn), tm; s)e∆(tm, tn; −s)e∆(tn, t0; −s2)ds.

1

2πiIC

As we can see, (29) is an interpolation formula that obtains function values
for the extended time scale in a way that keeps constant the nabla Laplace
transform. The function φ(t, tm) has the role of an interpolating function.

Now it is a simple task to deﬁne convolution f (t) ∗ g(t) and correlation

f (t) ∗ g(−t) on time scales, having in mind to preserve the property

N LT [f (t) ∗ g(t)] = F∇(s)G∇(s).

We deﬁne convolution by

f (t) ∗ g(t) =

+∞

Xm=−∞

νmf (tm)g(tn − tm),

where g(tn − tm) is deﬁned by (29). With this convolution we can show that
the output of the system deﬁned by (27) is given, as usually, by the convolution
of the input and the impulse response deﬁned as the inverse of (28). For the
correlation the situation is similar but we have to involve both transforms [36].
In fact we can deﬁne it by the convolution with the reﬂected function g(−t):

N LT [f (tk) ∗ g(−tk)] = F∇(s)G∆(−s).

22

6.9. Higher-order and fractional derivatives

The study of fractional derivatives on arbitrary time scales is a subject of
great interest [8, 9, 6, 41]. Having deﬁned convolution, we are able to use
it to obtain a general formula for nabla and delta higher-order and fractional
derivatives through the inversion of sN , N ∈ Z+
0 , and in general sα, α ∈ R.
As the ﬁrst case is a particular case, we solve the second that is more general.
Let δ(α)
∇ (t) be the causal inverse of such function in order to obtain the nabla
derivative. With the anti-causal we would obtain the delta derivative. We have

δ(α)
∇ (t) = −

1

2πiIγ

sαe∇(t + µ(t), t0; s)ds,

allowing us to deﬁne a general fractional derivative of order α by

x(α)(t) = δ(α)

∇ (t) ∗ x(t),

in agreement with an old classical result [39]. As sα has a branch point at
s = 0 in the general case or a pole if α is a negative integer, we use a deformed
integration path γ that deviates slightly from s = 0 in such a way that it remains
outside the integration region. If α is not an integer we choose the negative real
half axis as the branch cut line. This means that

• δ(α)

∇ (t) = 0 for t < t0;

• for t = tn ≥ t0 the integrand has n + 1 poles, so

δ(α)
∇ (t) = −

[1 − sµk(t0)]−1 ds

sα

n+1

Yk=1(cid:20)s −

1

µk(t0)(cid:21)−1

ds.

n+1

1

sα

2πiIγ
Yk=1
µk(t0)Iγ

(−1)n

=

n+1

Qk=1

We have several diﬀerent situations between the two extreme cases.

• Diﬀerent graininess values. In this case the integrand has n + 1 simple

poles. The corresponding residues are easily computed:

δ(α)
∇ (t) = (−1)n

µk(t0)−α+n

n+1

Xk=1

n+1

Ym=1;m6=k(cid:20)

1

µm(t0) − µk(t0)(cid:21) ǫ(t).

• Constant graininess µn(t0) = h. In this case we have a pole with order

n + 1 at s = 1/h. The residue theorem allows us to write that

which gives

∇ (t) = (−1)nh−n−1 1
δ(α)
n!

∇ (t) = h−α (−α)n
δ(α)
n!

,

dnsα

dsn (cid:12)(cid:12)(cid:12)(cid:12)s= 1

h

ǫ(nh)

(30)

and leads to the discrete version of the Gr¨unwald–Letnikov fractional
derivative recently introduced in [36], conﬁrming the coherence of our
results. When h → 0, we recover the Liouville derivative [34].

23

In passing, we obtained results useful in deﬁning polynomials on time scales.
Similarly to the ordinary case, we deﬁne the “power function” of degree N as
the N th order anti-derivative of the Heaviside unit step multiplied by N ! (cf.
[36]). As the Heaviside unit step has nabla Laplace transform 1/s, the N th
order power has nabla Laplace transform N !s−N −1.
In fact, with α = −N ,
N ∈ Z+
0 , we obtain the “power function”, agreeing with the time scale and
derivative at hand. For the nabla case, we can use the above results as follows.

• Diﬀerent graininess values. In this case we obtain

[ǫ(t)]∇−N

= δ(−N −1)

∇

(t)

= (−1)n

n+1

Xk=1

µk(t0)N +n

n+1

Ym=1;m6=k(cid:20)

1

µm(t0) − µk(t0)(cid:21) .

• Constant graininess µn(t0) = h. This case was considered in [36]. It is

easy to obtain from (30):

[ǫ(nh)]∇−N

= hN (N )n
n!

= hN (N + n)!

N !n!

ǫ(nh).

Remark 5. The polynomials we obtain here are “causal” in the sense they are
nonnull for t ≥ t0. For the delta case we obtain “anti-causal” polynomials.
These “power functions” are univocally deﬁned, contrarily to those obtained by
the approach followed in [14].

6.10. Initial and ﬁnal value theorems

We now consider the nabla Laplace transform of causal functions

g(t) = f (t)ǫ(t).

Using the nabla Laplace transform deﬁnition, particularized to this case, we
verify that, in general, it is not possible to obtain an Initial Value Theorem.
We only have to remark that the summation goes from 0 to ∞ and all the
terms except one (ν0 · g(0)) depend on s that is inside the region Rc. So there
is no value of s that could make zero all terms. For example, in the constant
graininess case, we have

g(0) = lim
s→ 1

h

sF (s).

n

To deduce the Final Value Theorem we only have to deﬁne y(tn) = h

g(tk).

As it is easy to conclude, if g(t) is a causal function, then y(t) is the convolution
of g(t) with the unit step. So the transform of y(t) is G(s)
s . As it is easy to see,

Pk=0

y(∞) = lim
s→0

G(s) = lim
s→0

sY (s),

which is equal to the usual theorem.

24

6.11. Backward compatibility

Accordingly to what we just said, when the graininess is the constant h, we
In particular, we make two variable

recover all the results presented in [36].
transformations: s = 1−z−1

in the nabla case and s = z−1
h

h

in the delta case.

• With the above transformations both exponentials degenerate into the

current exponential: zn.

• Both transforms recover the classic Z transform.

• Putting s = eiω we obtain the discrete-time Fourier transform.

Going further, and taking the limit as h → 0,

• The derivatives convert into the classic derivatives. The negative integer

order gives a well-known formulation of the Riemann integral.

• The exponentials degenerate into one: est.

• The two nabla Laplace transforms degenerate also into the classic two-

sided Laplace transform.

• Putting s = iω, we obtain the Fourier transform.

7. Generalising the transforms

In Section 5 we presented the general forms assumed by the exponentials:
(11) and (16). With these we are able to generalise the nabla and delta Laplace
transforms. It is a simple task to rewrite both transforms for a general time
scale. In the nabla case we have

F∇(s) =

+∞

Z−∞

ν(t)f (t)e∆(t, t0; −s)∆t =

+∞

Z−∞

f (t)e∆(t, t0; −s)∆t

and

f (t) = −

1

2πiIC

while for the delta case we have, similarly,

F∇(s)e∇(σ(t), t0; s)ds;

F∆(s) =

+∞

Z−∞

ν(t)f (t)e∇(t, t0; −s)∇t =

+∞

Z−∞

f (t)e∇(t, t0; −s)∇t

and

f (t) =

1

2πiIC

F∆(s)e∆(ρ(t), t0; s)ds.

It is important to remark here that the integration path in the inverse transforms
becomes the imaginary axis if the graininess is zero at all but one value of t in
the time scale.

25

8. Conclusion

We introduced a general approach to deﬁne exponentials and transforms on
time scales. Starting from the nabla and delta derivatives, we studied them in
parallel and derived general formulae for deﬁning exponentials as their eigen-
functions. With these exponentials, we deﬁned two new Laplace transforms and
deduced their most important properties. We obtained existence and unicity,
and deﬁned convolution and correlation. We also considered linear systems and
corresponding transfer functions and impulse response, and deﬁned a general
fractional derivative on time scales from convolution.

Acknowledgements

This work was partially supported by National Funds through the Foun-
dation for Science and Technology of Portugal (FCT), under project PEst–
UID/EEA/00066/2013 (Ortigueira); by CIDMA and FCT within project UID-
/MAT/04106/2013 (Torres); and by project MTM2013-41704-P from the gov-
ernment of Spain (Trujillo). The authors would like to thank two referees for
their valuable comments and helpful suggestions.

References

[1] C. R. Ahrendt, The Laplace transform on time scales, Panamer. Math. J.

19 (2009), no. 4, 1–36.

[2] A. Aldroubi and K. Gr¨ochenig, Nonuniform sampling and reconstruction

in shift-invariant spaces, SIAM Rev. 43 (2001), no. 4, 585–620.

[3] B. Aulbach and S. Hilger, A uniﬁed approach to continuous and discrete
dynamics, in Qualitative theory of diﬀerential equations (Szeged, 1988),
37–56, Colloq. Math. Soc. J´anos Bolyai, 53 North-Holland, Amsterdam,
1990.

[4] B. Aulbach and S. Hilger, Linear dynamic processes with inhomogeneous
time scale, in Nonlinear dynamics and quantum dynamical systems (Gaus-
sig, 1990), 9–20, Math. Res., 59 Akademie Verlag, Berlin, 1990.

[5] P. Babu and P. Stoica, Spectral analysis of nonuniformly sampled data – a

review, Digit. Signal Process. 20 (2010), 359–378.

[6] D. Baleanu, S. Rezapour and S. Salehi, A k-dimensional system of frac-
tional ﬁnite diﬀerence equations, Abstr. Appl. Anal. 2014 (2014), Art. ID
312578, 8 pp.

[7] N. R. O. Bastos, Fractional calculus on time scales, Ph.D. Thesis, Univer-

sity of Aveiro, 2012.

[8] N. R. O. Bastos, D. Mozyrska and D. F. M. Torres, Fractional derivatives
and integrals on time scales via the inverse generalized Laplace transform,
Int. J. Math. Comput. 11 (2011), J11, 1–9. arXiv:1012.1555

26

[9] N. Benkhettou, A. M. C. Brito da Cruz and D. F. M. Torres, A fractional
calculus on arbitrary time scales: fractional diﬀerentiation and fractional
integration, Signal Process. 107 (2015), 230–237. arXiv:1405.2813

[10] M. Bohner and G. Sh. Guseinov, The convolution on time scales, Abstr.

Appl. Anal. 2007 (2007), Art. ID 58373, 24 pp.

[11] M. Bohner and G. Sh. Guseinov, The Laplace transform on isolated time

scales, Comput. Math. Appl. 60 (2010), no. 6, 1536–1547.

[12] M. Bohner and G. Sh. Guseinov, The h-Laplace and q-Laplace transforms,

J. Math. Anal. Appl. 365 (2010), no. 1, 75–92.

[13] M. Bohner, G. Sh. Guseinov and B. Karpuz, Properties of the Laplace trans-
form on time scales with arbitrary graininess, Integral Transforms Spec.
Funct. 22 (2011), no. 11, 785–800.

[14] M. Bohner and A. Peterson, Dynamic equations on time scales, Birkh¨auser

Boston, Boston, MA, 2001.

[15] M. Bohner and A. Peterson, Laplace transform and Z-transform: uniﬁca-

tion and extension, Methods Appl. Anal. 9 (2002), no. 1, 151–157.

[16] M. Bohner and A. Peterson, Advances in dynamic equations on time scales,

Birkh¨auser Boston, Boston, MA, 2003.

[17] M. C. Caputo, Time scales: from nabla calculus to delta calculus and vice

versa via duality, Int. J. Diﬀerence Equ. 5 (2010), no. 1, 25–40

[18] J. L. Cie´sli´nski, New deﬁnitions of exponential, hyperbolic and trigonomet-
ric functions on time scales, J. Math. Anal. Appl. 388 (2012), no. 1, 8–22.

[19] J. M. Davis, I. A. Gravagne, B. J. Jackson, R. J. Marks, II and A. A.
Ramos, The Laplace transform on time scales revisited, J. Math. Anal.
Appl. 332 (2007), no. 2, 1291–1307.

[20] J. M. Davis, I. A. Gravagne and R. J. Marks, II, Convergence of unilateral
Laplace transforms on time scales, Circuits Systems Signal Process. 29
(2010), no. 5, 971–997.

[21] J. M. Davis, I. A. Gravagne and R. J. Marks, II, Bilateral Laplace trans-
forms on time scales: convergence, convolution, and the characterization
of stationary stochastic time series, Circuits Systems Signal Process. 29
(2010), no. 6, 1141–1165.

[22] H. G. Feichtinger and K. Gr¨ochenig, Irregular sampling theorems and series
expansions of band-limited functions, J. Math. Anal. Appl. 167 (1992),
no. 2, 530–556.

[23] H. G. Feichtinger and K. Gr¨ochenig, Theory and practice of irregular sam-
pling, in Wavelets: mathematics and applications, 305–363, Stud. Adv.
Math, CRC, Boca Raton, FL, 1994.

[24] I. A. Glover and P. M. Grant, Digital Communications, Pearson Education
Limited, Edinburgh Gate, Harlow, Essex, CM20 2JE, England, 3rd edition,
2010.

27

[25] K. Gr¨ochenig, A discrete theory of irregular sampling, Linear Algebra Appl.

193 (1993), 129–150.

[26] A. E. Hamza and M. A. Al-Qubaty, A remark on the exponential matrix
functions on time scales, Assiut Univ. J. Math. Comput. Sci. 39 (2010),
no. 2, 21–30.

[27] A. E. Hamza and M. A. Al-Qubaty, On the exponential operator functions

on time scales, Adv. Dyn. Syst. Appl. 7 (2012), no. 1, 57–80.

[28] S. Hilger, Analysis on measure chains—a uniﬁed approach to continuous

and discrete calculus, Results Math. 18 (1990), no. 1-2, 18–56.

[29] B. Karpuz, On uniqueness of the Laplace transform on time scales,

Panamer. Math. J. 21 (2011), no. 2, 101–110.

[30] R. J. Marks, II, I. A. Gravagne and J. M. Davis, A generalized Fourier
transform and convolution on time scales, J. Math. Anal. Appl. 340 (2008),
no. 2, 901–919.

[31] D. Mozyrska and D. F. M. Torres, A study of diamond-alpha dynamic
equations on regular time scales, Afr. Diaspora J. Math. (N.S.) 8 (2009),
no. 1, 35–47. arXiv:0902.1380

[32] M. D. Ortigueira, Introduction to fractional signal processing. Part 2:
Discrete-time systems, IEE Proc. on Vision, Image and Signal Processing
147 (2000), no. 1, 71–78.

[33] M. D. Ortigueira, The comb signal and its Fourier transform, Signal Pro-

cessing 81 (2001), no. 3, 581–592.

[34] M. D. Ortigueira, Fractional calculus for scientists and engineers, Lecture

Notes in Electrical Engineering, 84, Springer, Dordrecht, 2011.

[35] M. D. Ortigueira, On the particular solution of constant coeﬃcient frac-

tional diﬀerential equations, Appl. Math. Comput. 245 (2014), 255–260.

[36] M. D. Ortigueira, F.J. Coito and J. J. Trujillo, Discrete-time diﬀerential

systems, Signal Process. 107 (2015), 198–217.

[37] M. A. Peltola, Role of editing of RR intervals in the analysis of heart rate

variability, Front Physiol. 3 (2012), Art. ID 148, 10 pp.

[38] J. G. Proakis and D. G. Manolakis, Digital signal processing: Principles,

algorithms, and applications, Prentice Hall, 2007.

[39] M. J. Roberts, Signals and systems: Analysis using transform methods and

Matlab, McGraw-Hill, 2003.

[40] M. R. Segi Rahmat, The (q, h)-Laplace transform on discrete time scales,

Comput. Math. Appl. 62 (2011), no. 1, 272–281.

[41] G.-C. Wu, D. Baleanu and S.-D. Zeng, Discrete chaos in fractional sine and

standard maps, Phys. Lett. A 378 (2014), no. 5-6, 484–487.

28

