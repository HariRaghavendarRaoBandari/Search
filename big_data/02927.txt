The Effects of Mobility on the Hit Performance of

Cached D2D Networks

Chedia Jarray† and Anastasios Giovanidis∗

6
1
0
2

 
r
a

M
9

 

 
 
]
I

N
.
s
c
[
 
 

1
v
7
2
9
2
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—A device-to-device (D2D) wireless network is consid-
ered, where user devices also have the ability to cache content.
In such networks, users are mobile and communication links
can be spontaneously activated and dropped depending on the
users’ relative position. Receivers request ﬁles from transmitters,
these ﬁles having a certain popularity and ﬁle-size distribution.
In this work a new performance metric is introduced, namely
the Service Success Probability, which captures the speciﬁcities
of D2D networks. For the Poisson Point Process case for node
distribution and the SNR coverage model, explicit expressions are
derived. Simulations support the analytical results and explain
the inﬂuence of mobility and ﬁle-size distribution on the system
performance, while providing intuition on how to appropriately
cache content on mobile storage space. Of particular interest is
the investigation on how different ﬁle-size distributions (Expo-
nential, Uniform, or Heavy-Tailed) inﬂuence the performance.

Keywords—Wireless cache; Device-to-device; Poisson point pro-

cess; Mobility; File-size; Content popularity; Heavy-tailed.

I.

INTRODUCTION

The relatively recent commercial spread of new generation
mobile devices such as tablets and smart-phones has triggered
an explosive increase of data trafﬁc and has made trafﬁc
management crucial for communication networks. Currently,
mobile video streaming accounts for almost half of the mobile
data trafﬁc and is expected to have a considerable increase over
the next years. These developments compel mobile operators
to redesign their current networks and seek more advanced
techniques to increase coverage, boost network efﬁciency, and
cost-effectively bring content closer to the user, either by
deploying small base-stations (BSs) [11], [4], or by exploring
the possibilities for inter-device communication, known as
D2D (device-to-device) [11], [2].

We are particularly interested here in the potential of
D2D communications, where mobile devices also play role
in content delivery, and direct communication links between
users are enabled. Such solution will possibly exist on top of
the existing cellular infrastructure and is already envisioned
for 5G networks. Furthermore, we consider the possibility
of on-device content caching. The motivation is that, among
existing (multimedia) content, only a small fraction is re-
peatedly used, which however triggers the majority of the
total data trafﬁc. Motivated by this, and the fact that mobile
devices are equipped with cheap and relatively large storage
capacity, caching ﬁnite popular ﬁles on mobile devices in

†UR MACS, ENIG-University of Gabes, Rue Omar Ibn Elkhattab, 6029
Gabes, Tunisia; jarray.chedia@hotmail.fr,
The doctoral visit of Chedia Jarray at T´el´ecom ParisTech was funded as a
scholarship by the Ministry of Higher Education of Tunisia.
∗CNRS-LTCI and T´el´ecom ParisTech, 23 avenue d’Italie, 75013 Paris, France;
anastasios.giovanidis@telecom-paristech.fr

advance could be promising to relieve the overloaded network
trafﬁc [17], [14]. The idea of D2D caching can signiﬁcantly
ofﬂoad different parts of the network including the radio access
network, core network, and backhaul, by smartly prefetching
and storing contents on the user nodes. Because of the D2D
links, multimedia ﬁles can be transmitted from one user to
another with reduced latency.

An important aspect in D2D communication that makes
its design challenging is user mobility. The fact that user
nodes constantly change relative position is one of the major
factors that can diminish possible beneﬁts of this type of data
transmission. A partly transmitted ﬁle due to connection loss
can be completely useless.

In this work the performance of caching in D2D networks
is studied, for different degrees of node mobility. Speciﬁ-
cally, a D2D network is considered, where devices (mobile
nodes) are spatially distributed on the plane. The possibility
of communication between a mobile node and a ﬁxed station
is left out, in this scenario. At some point in time a subset of
these devices (receivers) requests for data ﬁles, whereas the
other nodes can serve them as potential transmitters. Based
on channel quality, reliable wireless links can be established
between receivers and transmitters,
that satisfy a required
Quality-of-Service (QoS). If some of these transmitters also
have the desired content cached, then transmission is initialised
(at most one transmitter per receiver). However, nodes change
position over time and consequently the link quality between
receivers and transmitters is affected. An established link with
sufﬁcient quality at to, can be later dropped at some t1 > to
due to displacement of one of the two nodes in pair, and the
consequent quality degradation. In our model, connection loss
due to transmitter displacement is considered an unsuccessful
effort. The node mobility inherent
in the nature of D2D
communications is what this work wishes to study and provide
a method to analyse performance metrics of interest.

Our contributions are the following:
•

A mobility concept is introduced, where a node keeps
its position for an exponential amount of time before
being displaced far from the receiver.
Content does not have the same size, rather ﬁle-sizes
take values sampled from relevant probability distribu-
tions. Possible such distributions are the Exponential,
Uniform or a Heavy-Tailed one.
New performance metrics are introduced: the Total
and Expected Service Success Probability. For these,
explicit expressions are provided for the case when
node positions follow a Poisson Point Process (PPP).
and for the SNR connectivity model.

•

•

•

Performance evaluation is provided through compar-
ison plots, both from simulations and analysis. Con-
clusions are drawn over the inﬂuence of mobility and
ﬁle-size distribution on cached D2D performance.

at xi is denoted by ri := |xi|. According to the Slivnyak-
Mecke theorem and the stationarity and isotropy of the PPP,
the results for the typical receiver are valid for any receiver of
Φr randomly located on the 2D plane [3].

A. Literature

In the literature, a signiﬁcant amount of work analyses con-
tent caching in wireless networks. Speciﬁcally, FemtoCaching
is proposed by Shanmugam et al
in [21] where caching
helpers optimally store popular content for delay performance
improvement. Bastug et al in [4], treat the problem of proactive
caching by use of stochastic geometry, and show the gains in
terms of backhaul savings and user satisfaction. Błaszczyszyn
and Giovanidis in [5] study the optimal probabilistic placement
policy for maximizing the total hit probability in random net-
work topologies. Molisch et al [17] evaluate the performance
of caching on helper station/devices and optimise video quality
by proposing optimal storage schemes. Content placement for
delay-tolerant service satisfaction is analysed by Sermpezis et
al in [20]. Asymptotic laws of the required link capacity of
a cached multi-hop wireless network are studied by Paschos
et al in [18]. Related to the problem of routing and replica
placement in a network, Sourlas et al propose various on-line
autonomous cache management algorithms [22].

Cached D2D communications is treated by Ji et al in
[14], where the authors ﬁnd asymptotic throughput scaling
laws with coded caching and D2D spatial reuse. Afshang
et al analyse cached coverage in a clustered PPP model in
[2]. Mobility in cellular networks is an important topic and
interesting analytical models have been proposed by Lin et al
[16], and Hsu et al [13]. The optimal storage allocation when
user mobility is modelled by a a Markov chain random walk
is approximately solved by Poularakis and Tassiulas in [19].
To optimally store content, the authors in [24] formulate and
solve a contact-duration-aware data replication optimisation
problem.

The remainder of this paper is organized as follows. Section
II describes in detail the system model, whereas the relevant
performance metrics are introduced in Section III. Section IV
contains the main analytical results of the stochastic geometry
analysis, followed by certain special cases of interest and a
discussion. Performance evaluation of the model is provided
in Section V, where simulations conﬁrm the validity of the
derived analytical expressions. Furthermore, plots illustrate
how the performance is inﬂuenced by system parameters, such
as the mean node lifespan or the ﬁle-size order and distribution.
Conclusions of the work are drawn in Section VI.

II. SYSTEM MODEL

A. Physical Aspects

The transmitters and receivers are placed following two
independent planar homogeneous PPPs Φt and Φr with inten-
sity λt > 0 and λr > 0, respectively. Their superposition is
also a PPP with sum intensity λ = λt + λr [devices/m2].
The transmitter devices are enumerated i = 1, 2, . . . , and
we denote by xi the location of the ith transmitter. Since
the receivers follow a PPP as well, we can condition on a
typical receiver located at the Cartesian origin o = (0, 0). The
Euclidian distance between the origin and each transmitter

i

For the signal propagation model, the path-loss from trans-
mitter to receiver is equal to l(ri) = r−α
, where α > 2. All
transmitters are assumed to emit the same power level equal to
P [W att]. Let Hi be the random variable for channel fading
between xi and o, with unit average. These variables indexed
by i are independent and identically distributed and the generic
fading variable is denoted by H (no speciﬁc distribution is
considered). The received signal power is P Hl(ri). In the
case of no interference (or at least not considerable) between
devices, the signal reception at o is only affected by noise, with
constant power N > 0 [W att]. For each link, communications
takes place within a frequency band of W [Hz], assigned by
the operating system to guarantee the interference-free link
(as in OFDMA). The quality of coverage provided by the
transmitter xi to the origin is described by the Signal-to-Noise-
Ratio SNR(ri), equal to

SNR(ri) =

P Hr−α

i

N

.

(1)

The maximum transmission rate from xi to o in [bits/sec]

is given by the Shannon formula

R(ri) = W log2 (1 + SNR(ri)) .

(2)

B. Content and its Popularity

The receiver at o demands a ﬁle (say audio or video) from
a ﬁnite set of F > 1 available ones. This set is called content
catalogue and is denoted by C := {c1, c2...., cF}. Each content
(ﬁle) cj is related to a popularity value, assumed constant and
known a priori. The ﬁle popularity can be understood as the
frequency of a particular content being called from an inﬁnite
stream of requests, and its law {aj}, j = 1, . . . , F , can be any
probability mass function of F objects, with

aj = 1.

F

Xj=1

(3)

(IRM), with aj = A−1j−γ, and A := PF

If we assume that content is indexed in decreasing order
of popularity j = 1, . . . , F , and is Zipf-like distributed [7],
we ﬁnd the trafﬁc case of the Independent Reference Model
j=1 j−γ being the
normalising constraint. The Zipf exponent γ characterises the
distribution and depends on the type of content. The Zipf
distribution is heavy-tailed1, which means that it can give
rise to extremely large values with non-negligible probability.
When γ < 2, and for F → ∞ the Zipf distribution has inﬁnite
mean value.

1The deﬁnition of a heavy-tailed distribution is ambiguous in the literature.
It often refers to distributions that are heavier than the Exponential. In a
stronger sense it refers to distributions that have certain moments inﬁnite, i.e.
the mean, or just the variance. We will apply here the ﬁrst deﬁnition, and as a
consequence, the log-normal distribution, which has all moments ﬁnite, will
be considered also as heavy-tailed.

C. Content Size

Furthermore, we consider that each content cj ∈ C has a
positive size zj > 0 given in [bits]. The size generally varies
among different ﬁles, it is constant and known, and depends
on the content type. A realisation of sizes for F ﬁles can
be sampled from a probability distribution. There are many
related studies in the literature that propose and make use
of the distribution for the ﬁle sizes. Certain authors suggest
that this distribution should be heavy-tailed as well, as for
the popularities, the reason being that trafﬁc is dominated by
multimedia content that is allowed to have very long duration.
We found and propose here the following possibilities.

(A) Crovella and Bestavros [9] attribute a Pareto distribu-
tion with parameter 0.9 ≤ a ≤ 1.1, which is veriﬁed to ﬁt well
with available network data sets. Its tail probability is

¯FP (z) := P [Z > z] = (β/z)a,

(4)
with shape parameter a and scale parameter β > 0, and z ≥
β. The Pareto distribution has inﬁnite variance for a ≤ 2, and
inﬁnite mean for a ≤ 1.

(B) Lee et al in [15], and Abhari and Soraya [1] analysed
measurements from YouTube videos and proposed a Weibull
distribution for video ﬁles, with tail

¯FW (z) = exp(−(z/µ)k).

(5)

In general, for shape k < 1 the Weibull distribution exhibits
inﬁnity of certain ﬁrst moments, and it becomes heavier as k
gets smaller. In these references, audio ﬁles are modelled by
the Exponential distribution (Weibull with k = 1).

(C) Certain authors, such as Downey in [10], give evidence
that the ﬁle-size distribution in the WWW, rather than Pareto,
is actually Log-normal; lnN (µ, σ). A random variable is
log-normally distributed, if its natural logarithm follows the
Normal distribution N (µ, σ). An easy way to describe it is
through its p.d.f.

flog(z) =

1

zσ√2π

exp(cid:18) (ln z − µ)2

2σ2

(cid:19) .

(6)

The aforementioned publications, are not speciﬁc for mo-
bile trafﬁc - where users differ from wired networks in be-
havioural patterns and service needs. Mobile users are expected
to show less interest for very large ﬁles, due to limited band-
width of wireless links, storage limitations, and shorter mobile
sessions especially outside home and work environments (see
also [23]). For these reasons, we can propose to limit the ﬁle
size by upper zmax (also lower zmin) bounds, depending on the
service type. This can be achieved by a truncated distribution,
e.g. truncated Log-normal, or simply by use of a Uniform one.
Video ﬁles are often larger (even of an order of magnitude)
than audio ﬁles. A reasonable size range for these two media
types related to mobile ofﬂoading is proposed in Table I.

TABLE I.
Content Type

Audio ﬁle
Video ﬁle

UNIFORM DISTRIBUTION
Size Range (z)
100 Kb - 20 Mb
50 Mb - 2 Gb

Altogether, a tuple of a-priori known values (aj, zj) is
related to each content cj. It is important to note that in [7]
no strong correlation between ﬁle size and popularity was
observed, except from the average size of popular contents
being slightly smaller than that of the unpopular ones.

D. Content Placement to Caches

The storage inventory of a D2D transmitter xi ∈ Φt is
denoted by Ξ(i) and contains a number of |Ξ(i)| ≤ K distinct
entire ﬁles from the catalogue C. We consider that the content
is independently installed in the caches by some probability
distribution which guarantees that

bj = P r(cj ∈ Ξ),

0 ≤ bj ≤ 1, ∀j,

(7)

i.e the probability (consequently frequency) that content cj is
stored in any of the memory caches of the network devices is
bj. In the above, due to independence, the superscript on in-
ventories (i) is dropped. These content placement probabilities
are (pre)determined by the content placement policy.

Since each transmitter xi has a memory of size K [objects]
irrespective of their ﬁle size, no more than K distinct objects
should be made available in each cache. In [5], a probabilistic
block placement (PBP) policy was suggested, that satisﬁes the
sum constraint

F

Xj=1

bj ≤ K,

(8)

and at the same time guarantees the hard constraint |Ξ(i)| ≤ K,
for all i. This is the policy we consider here as well.

E. Device Mobility

Node mobility is modelled in a simpliﬁed way as follows.
At instant t = 0, the receiver at the Cartesian origin sees a set
of transmitters with ﬁxed positions on the plane. The distance
between the receiver and each transmitter varies over time, as
a function ri(t), ∀i. Then, SNR(ri(0)) in (1) gives the signal
quality and R(ri(0)) in (2) the achievable rate for the link
between o and xi at time origin.

We need to include in the model that

the position of
each node, due to mobility, is bound to change. To do so,
each link is considered active for a time period of τi [sec],
different for each xi, with SNR(ri(t)) = SNR(ri(0)), within
the link is
0 ≤ t < τi. This is called its lifespan. At τi
immediately dropped, because the transmitter instantly moves
far away from its position so that SNR(ri(τi)) ≈ 0. Of
course, such a model with sudden node displacement does not
describe the full complexity of random user movements and
their trajectories on the plane, it is however sufﬁcient in its
simplicity to capture the main effects of mobility and to help
better manage the cache inventories.

The time intervals τi are random i.i.d. variables, that are
also independent of all other parameters of the model, such
as node position or fading. They can be seen as a mark of
the process Φt. The generic random variable for all τi is T ∼
Exponential(¯τ−1), with mean E [T ] = ¯τ .

As a consequence of the model, the number of possible

active links gradually reduces over time.

III. PERFORMANCE METRICS

The user at the origin requests for a certain content from
the catalogue C, which follows the popularity law {aj}. We
remind the reader that the placement probabilities on caches
follow {bj}. For a given content cj, its service is successful
if there exists at least one transmitter xi ∈ Φt who satisﬁes
both conditions:

(i) the object is found in its inventory, i.e. the event is true

Aij := {cj ∈ Ξ(i)},

(9)

(ii) the communication link between o and xi is sufﬁcient
for the entire ﬁle to be transmitted, before the transmitter leaves
its position and becomes unavailable. This can be formally
expressed as the event

Bij := {τiW log2(1 + SNR(ri)) ≥ zj},

(10)

i.e. that the amount of information in [bits] transmitted over
the link between xi and o within the lifespan τi is greater
than or equal to the total size zj of the object. Alternatively,
we can write {R(ri) ≥ zj/τi}, which poses a requirement for
the throughput, to be greater than or equal to a threshold of
minimum rate (ﬁle-size over transmitter’s lifespan).

As mentioned, uninterrupted service is guaranteed when
at least one transmitter satisﬁes (i) and (ii), but the case that
more than one may exist with these conditions is not excluded.
If so, we assume a random choice among these possibilities
for a communication link with o to be established, and also
the existence of a schedule to achieve this. Our work mainly
focuses on the probability that the service is satisﬁed. It does
not consider issues on scheduling, resource allocation or load
balancing (the load here being the receivers), when many users
compete for access to the same transmitter. It neither considers
the possibility for transmitters to cooperate for service. This
option can be left open for future investigations.

Having said this, service is achieved from xi to o for object

cj, when

Ψij := 1{Aij}1{Bij} = 1,

(11)
where 1{E} is the indicator function, which yields one, if the
event E is true, otherwise zero. We say that the receiver’s
demand is served successfully, when at least one transmitter
xi ∈ Φt exists, that satisﬁes Ψij = 1, i.e. if the following
event is true
(12)

Sj := {

Ψij ≥ 1}.

∞Xi=1

By denoting the probability of service for content cj ∈ C

by Psrv,j(bj; zj), we have

Psrv,j(bj; zj) = P r(Sj ) = P r" ∞Xi=1

Ψij ≥ 1# .

(13)

The performance metric is the Total Service Success Prob-
ability, denoted by Psrv, and it is equal to the expected service
probability over the content popularity, given the ﬁle sizes,

Psrv ({bj};{aj} ,{zj}) =

F

Xj=1

ajPsrv,j (bj; zj).

(14)

Furthermore, we can take the distribution of ﬁle-size into
consideration, by taking expectation of the above metric over
the ﬁle-size variables. These are i.i.d. with c.d.f FZ (z) for each
ﬁle size zj, j = 1, . . . , F . We deﬁne the Expected Service
Success Probability, denoted by ˜Psrv({bj};{aj}), as

˜Psrv({bj};{aj})

:=

(14),indep.

=

F

E [Psrv ({bj} ;{aj} ,{zj})]
Xj=1
aj E [Psrv,j(bj; Z)] . (15)

IV. MAIN RESULTS

A. Per-Object Service Success Probability

Proposition 1. The probability that the typical receiver re-
questing for object cj ∈ C is served by at least one transmitter
in the downlink, for the SNR coverage model, is equal to
Psrv,j(bj; zj) = 1 − exp(cid:18)−πλtbj

N 2/α IT (zj, ¯τ )(cid:19) ,

(16)

IH

where

IH := P E[H 2/α],

IT (zj, ¯τ )

:= E[(

1

2

zj

W T − 1

)2/α].

(17)

(18)

Proof: We need to calculate (13). The randomness of the
event (12) is due to (a) the position of the transmitters, which
in our model follows a PPP, (b) the lifespan τi ∼ T of each
node, (c) the channel fading hi ∼ H between each transmitter
xi and the the origin o. Hence,
Ψij = 0#

(a)

Ψij ≥ 1# = 1 − P r" ∞Xi=1
Psrv,j = P r" ∞Xi=1
{Ψij = 0}#
= 1 − P r" ∞\i=1
1{Ψij =0}#
= 1 − E" ∞Yi=1
P r(Ψij = 0)#
= 1 − E" ∞Yi=1
= 1 − exp
(1 − uj(x))λtdx
−ZR2

(1 − uj(r))rdr
= 1 − exp
∞Z0
−2πλt
 .

(d)

(c)

(b)

(19)

In the above, (a) is due to the independence of the events
Ψij, (b) results by taking expectation over the i.i.d. variables
{τi}, {hi}, (c) is obtained from the probability generating
functional (PGFL) of the PPP, which states that for some func-
tion u(x) it holds E[Qx∈Φ u(x)] = exp(−λRR2(1 − u(x))dx)

[12], [3]. In our case, uj(x) := P r(Ψij = 0) and λt is the
density of D2D transmitters. The last step (d) comes from
Cartesian-to-Polar transformation.

To derive an explicit expression for the per-object Service
Success Probability Psrv,j, the function uj(xi) needs to be
calculated.

uj(xi) = P r(Ψij = 0) = P r(1Aij

1Bij = 0)

= P r(1{Aij∩Bij} = 0)
= 1 − P r(Aij ∩ Bij)
= 1 − P r(Aij )P r(Bij )
:= 1 − fj(|xi|).

(e)

(20)

In the above, (e) comes from the independence of the
two events Aij and Bij. We have replaced fj(|xi|)
:=
P (Aij )P (Bij ), equal to fj(ri), so that the function uj(xi),
depends only on the radial distance from o to the transmitter.
The reason is that,

fj(ri)

Substituting (20) into (19) yields the following

zj

(i)

(ii)

|

τi∼T

{z

:= P r(cj ∈ Ξi)
P r(τiW log2(1 + SNR(ri)) ≥ zj)
}
}
|
= bjP r(cid:16)SNR(ri) ≥ 2
Psrv,j = 1 − exp

{z
W T − 1(cid:17) .
∞Z0

(22)

(21)

fj(r)rdr
 .

−2πλt

Using also the equality in (21) and the SNR deﬁnition in

(1), the expression becomes

(k)

Psrv,j

where in (k) we substitute ˜Rj

. Hence

1
zj
W T −1

2

E[ ˜R2/α] = P E[H2/α]
gration is interchanged in (ℓ) due to Fubini’s theorem.

]. The order of inte-

Discussion on Proposition 1: From Eq. (16) we observe
that the service probability for object cj is a function of
its content placement probability bj and its ﬁle-size zj. In
fact, the function Psrv,j is increasing in bj. Regarding the
ﬁle-size,
the function is decreasing in zj. Hence, service
exhibits the behaviour that one would expect related to object
characteristics. Another dependence of the function is on the
average lifespan ¯τ , and it is increasing as the mean lifespan

P r(rα ≤ ˜Rj)rdr

]rdr

rdr


{rα≤ ˜Rj}

{r≤ ˜R1/α

}

1

j




rdr#!
(cid:21)(cid:19)

(ℓ)

E[1

= 1 − exp
∞Z0
−2πλtbj
= 1 − exp
∞Z0
−2πλtbj
= 1 − exp
−2πλtbj E
∞Z0

= 1 − exp −2πλtbj E"Z ˜R1/α
= 1 − exp(cid:18)−2πλtbj E(cid:20) r2
2 |
](cid:17) ,
= 1 − exp(cid:16)−πλtbj E[ ˜R2/α
W T − 1(cid:17)−2/α

E[(cid:16)2

:= P H
N

N 2/α

zj

0

j

j

˜R1/α
0

j

TABLE II.

FADING DISTRIBUTIONS, TAKEN FROM [6].

Distribution

Log-normal
Exponential

Weibull

Nakagami

Rice

Probability density of H

1/(h√2πσ)

λe−λh

×e−(ln h−µ)2 /2σ2
(k/λ)(h/λ)k−1
×e(−h/λ)k
×e−(m/Ω)h2
(h/σ2)I0(hν/σ2)
e−(h2 +ν2)/(2σ2 )

2mm/Γ(m)Ωmh2m−1

E[H2/α]

e2(σ2 +µα)/α2

λ−2/αΓ(2/α + 1)

λ2/αΓ(2/(αk) + 1)

Γ(1/α + m)Γ(m)(Ω/m)1/α

(2σ2)(1/α)Γ(1/α + 1)1
×F1(−1/α, 1; −ν2/(2σ2)

increases. Actually, a larger lifespan corresponds in our model
to low mobility.

Furthermore, the service probability depends also on sys-
tem parameters, such as the path-loss exponent α, the transmit-
ter density λt, their transmit power P and bandwidth W . As λt
increases, and for bj > 0, the Psrv,j tends to 1. The reason for
such behaviour is the SNR communications model, which does
not consider interference, so densifying the network, simply
guarantees that the receiver will ﬁnd its request somewhere
close with sufﬁciently high probability. The function is further
increasing in P and W and decreasing in α, the latter because
the coverage area of each transmitter decreases for increasing
path-loss exponent.

The expression Psrv,j depends on the expectations IH and

IT in (17) and (18) respectively.

1) Fading distribution for IH: To obtain speciﬁc expres-
sions for E[H 2/α] we need to determine the type of distribution
for the propagation effects H (shadowing, and/or fading)
experienced by the typical receiver. A list of such distributions
with their density function and the calculation of IH is found
in [6]. We reproduce this here in Table II. As an example, if
we assume exponential fading with mean 1 (as is often the
case), the expression for the service probability gives

Psrv,j (bj; zj) = 1 − exp(−πλtbj

P 2/αΓ( 2
N 2/α

α + 1)

IT (zj, ¯τ )).

2) Lifespan distribution for IT : The distribution for node
lifespan T plays an important role for performance. To get
ﬁrst intuition we can use (i) a ﬁxed period τi = ¯τ , ∀xi. In this
case, all nodes will be available for data transmission during
the period [0, ¯τ ] and after that, no service will be provided.
Since lifespan does not vary, the probability of service mostly
depends on the probability a transmitter with the desired object
to be sufﬁciently close to the origin. This distribution simpliﬁes
the calculations, giving

IT (zj, ¯τ ) T =¯τ= (cid:16)2

zj

W ¯τ − 1(cid:17)−2/α

.

(23)

A more realistic assumption is that of an exponential distri-
bution. Each node has the ability to provide service for an ex-
ponential time while keeping its position, before moving away
from the origin. In this case, where T ∼ Exponential(¯τ−1),
the factor IT can be calculated by the integral

IT (zj, ¯τ )

Exp

= Z ∞

0

1
¯τ

exp(−

s
¯τ

)(cid:16)2

zj

W s − 1(cid:17)−2/α

ds.

(24)

B. Total and Expected Service Success Probability

Using Prop. 1, and applying this to the expression in (14)

for the total success metric, we get the following result.
Corollary 1. The Total Service Success Probability for the
SNR coverage model is equal to (we omit the dependence on
({bj};{aj},{zj}) due to space limitation),

Psrv = 1 −

F

Xj=1

aj exp(cid:18)−πλtbj

IH

N 2/α IT (zj, ¯τ )(cid:19) .

(25)

By further assuming independently sampled ﬁle-sizes from
a distribution with c.d.f. FZ (z) and p.d.f. (for continuous
functions) or p.m.f. (for discrete functions) fZ(z), the expected
success metric takes the following expression.
Corollary 2. The Expected Service Success Probability for the
SNR coverage model is equal to (we omit the dependence on
({bj};{aj}) due to space limitation),
aj E(cid:20)exp(cid:18)−πλtbj
˜Psrv = 1 −

N 2/α IT (Z, ¯τ )(cid:19)(cid:21) .

(26)

IH

F

Xj=1

V. NUMERICAL EVALUATION

In this section, the expressions derived for the performance
of the D2D model under study are numerically evaluated.
Additionally, we have run extended simulations of the system,
to validate their correctness.

Speciﬁcally for the simulation environment, we consider
the following. Geometry Parameters: The simulation is ob-
served within a window of size 100 × 100 [km2], where
transmitter devices are distributed as a Poisson point process
(PPP) of density λt = 2.5 · 10−3 [transmitters/m2]. With
this transmitter density, the mean distance from o to the closest
transmitter is rf irst = (2√λt)−1 = 10 [m]. Each node has
a lifespan that is exponentially distributed with mean value
that varies for (a) Audio ﬁles ¯τ ∈ [0, 100] [sec], and (b) for
Video ﬁles ¯τ ∈ [0, 1000] [sec]. The receivers form also a PPP
but we consider just one receiver per realisation placed at the
Cartesian origin o, since no resource sharing is assumed. The
simulation results are averaged over Tsim = 2000 iterations
(a larger number gives even better ﬁt). Wireless Parameters:
The transmission is interference free. Each node operates on
a bandwidth of 5 [M Hz] and emits with Power P = 0.5
[W att/Hz], whereas noise power is N = 10−11 [W att/Hz].
The path-loss exponent is α = 4 and fading is Rayleigh (hence
exponential distribution). Content Parameters: We consider a
catalogue of size F = 100 objects, and a Zipf distribution
for popularity, with exponent γ = 0.78. The objects can be
(a) Audio ﬁles, or (b) Video ﬁles. The cache size is K = 5
[objects] and we do not consider the inﬂuence of ﬁle-sizes
when ﬁlling in the node inventories.

Content Placement: We use the probabilistic block place-
ment policy (PBP) proposed in [5], which for each node
samples an independent vector of at most K objects, and
satisﬁes the placement probabilities bj ≥ 0 for every object cj.
The vector {bj} should be given as system input. The choice
of entries is critical for the system performance itself and is
a design parameter. In the current simulation we take bj > 0,

P2K

k=1 aj

, 1o, so that PF

for 1 ≤ j ≤ 2K and 0, otherwise. Then, for 1 ≤ j ≤ 2K,
bj = a∗j , where a∗j is a sort of normalised popularity a∗j :=
minn Kaj
We investigate different ﬁle-size distributions for the ran-
dom variable Z. In all cases, the choice of ﬁle-size per object
cj is i.i.d. and zj ∼ Z, ∀cj ∈ C, so that the mean size for
Audio is ≈ 10 [M b] and for Video ≈ 1 [Gb]. In the case of
a Uniform distribution, the range of ﬁle-sizes for Audio and
Video given in Table I satisfy the values of the expectation.

j=1 bj =P2K

j=1 bj ≤ K.

A. Validation

The correctness of the expression in (25) is validated for
the case of Audio and Video ﬁles separately. Both sets of
ﬁle-sizes (100 in total
in each set) are sampled from an
exponential distribution with mean values 10 [M b] (audio) and
1 [Gb] (video) respectively. The expression for IT is given
in (24) because lifespan distribution is exponential as well.
The comparison between analysis and simulation is illustrated
in Fig. 1 for the Total Service Success Probability over a
range of mean lifespan values, which is chosen differently for
the two ﬁle categories. The plots show an excellent match
between analysis and simulations. Interestingly, we observe
that for ¯τ = 100 [sec], audio ﬁles have a success probability
Psrv,Audio ≈ 0.37, much higher than the success probability of
videos for the same value of mean lifespan Psrv,V ideo ≈ 0.04.
This is reasonable due to the difference in mean ﬁle-size.
Both sub-ﬁgures show a diminishing increase of Psrv. The
probability should converge to some value less than one,
because of the placement policy, which leaves F − 2K objects
deﬁnitely uncached. Moving on the x-axis in both plots from
left to right represents a change in the D2D behaviour, from
higher to lower mobility.

(a) Audio: Total Service Success Probability

 (F=100, K=5, T~Exp, Z~Exp)

(b) Video: Total Service Success Probability

 (F=100, K=5, T~Exp, Z~Exp)

0.4

0.35

0.3

0.25

0.2

0.15

0.1

v
r
s

P
 
y
t
i
l
i

b
a
b
o
r
P
 
s
s
e
c
c
u
S

0.05
 
0

20

 

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

v
r
s

P
 
y
t
i
l
i

b
a
b
o
r
P
 
s
s
e
c
c
u
S

 

Total Success Video (Simul.)
Total Success Video (Analytical)

Total Success Audio (Simul.)
Total Success Audio (Analytical)

40

60

Mean Lifespanτ [sec] 

80

100

0
 
0

500

1000

Mean Lifespanτ [sec] 

1500

2000

Fig. 1.
cached (a) Audio ﬁles and (b) Video ﬁles.

Total service probability with respect to mean node lifespan, for

B. Evaluation

1) Inﬂuence of ﬁle-size order related to popularity: The
results in Fig. 1 are obtained when the ﬁle-size of each content
is independently sampled from an exponential distribution.
There is, hence, no correlation between popularity and ﬁle-
size, meaning that the most popular ﬁle may have any size. We
investigate how the service success probability is inﬂuenced
from a possible correlation between the two ﬁle characteristics.

More speciﬁcally, we simulate (and analytically calculate) two
scenarios, one when the ﬁle-sizes are in decreasing order in
relation to the popularity index (the most popular ﬁle is the
largest one from the sample set, the second most popular the
second largest and so on), and another scenario when the ﬁle
sizes are in increasing order (most popular ﬁle is the smallest
one). These two curves over the mean lifespan are produced
for Video in Fig. 2 (for Audio the behaviour is similar), and
can be directly compared to those in Fig. 1(b). We observe
that when the ﬁle-sizes are in increasing order, the Psrv is
higher than in the independent case, because more popular
ﬁles (which are also cached due to the choice of the placement
policy) are smaller and thus more likely to be fully transmitted
within the lifespan. On the other hand, when the sizes are in
decreasing order, the Psrv is lower than in the independent
case, for exactly the opposite reason.

Video: Total Service Success Probability

(F=100, K=5, T~Exp, Z~Exp−Increase/Decrease)

 

0.45

0.4

0.35

0.3

v
r
s

P

 
 
y
t
i
l
i

b
a
b
o
r
P
 
s
s
e
c
c
u
S

0.25

0.2

0.15

0.1

0.05

0
 
0

200

400

600

Total Success Video Increasing (Simul.)
Total Success Video Increasing (Analytical)
Total Success Video Decreasing (Simul.)
Total Success Video Decreasing (Analytical)

800
1200
Mean lifespan τ [sec]

1000

1400

1600

1800

2000

Fig. 2.
Increasing/Decreasing ﬁle-size with popularity order and how it
inﬂuences the total service probability, for cached Video ﬁles, over the mean
node lifespan.

2) Inﬂuence of ﬁle-size distribution in the Expected/Total
Service Success Probability: We investigate this very impor-
tant issue with the following methodology. We consider ﬁve
possible distributions for the ﬁle-size of Videos: A. Uniform
within [zmin, zmax], B. Exponential with parameter λ, C. Pareto
with parameters (a, β), D. Weibull with parameters (µ, k), E.
Log-Normal with parameters (µ, σ). Each one of these has very
different characteristics and the system performance depends
on the parameter values.

To keep comparison fair, we choose the parameters so that
E [Z] = 1 [Gb], which is the mean value of the video ﬁle-size.
Having this in mind, A. the Uniform is in agreement with the
expected value when using the upper and lower bounds in
Table I. B. For Exponential λ = 10−9. C. For Pareto it holds
that E[Z] = βa
a−1 , and a > 1 to have ﬁnite ﬁrst moment. Then
we choose a = 20/19 and β = 0.05· 109 which not only gives
the desired expected value but also guarantees the same lower
bound z ≥ β = zmin with the Uniform distribution. D. For
Weibull, E [Z] = µΓ(1 + 1
k ), so that the choice is µ = 276 and
k = 0.1 < 1. Finally, E. for Log-normal, E [Z] = exp(µ + σ2
2 )

and we choose µ = 5 ln(10), σ =p8 ln(10).

To observe the inﬂuence of these ﬁle-size distributions
on the probability of service, we ﬁrst make use of the Ex-
pected Service Success Probability metric, in (26). To simplify
numerical evaluation, we use a ﬁxed lifespan for all nodes
T = ¯τ = 1000 sec, so that IT is given in (23). The results
of the evaluations, with the parameters of each distribution
chosen as above, are given in Fig. 3. From the plots, we
observe that
the distributions are ordered as: A. U ni <
B. Exp < C. P ar < E. Log < D. W eib. We note that
the three heavy-tailed (or just heavier than the exponential)
distributions Weibull, Pareto and Log-Normal, with the param-
eter set chosen, give the maximum service performance. The
reason that the exponential performs poorly is that, although
it does not have the tendency to generate very high values,
it does however produce a sufﬁcient number of samples large
enough to keep the Psrv low. Contrary to this, the heavy-tailed
distributions may produce extremely large samples, however
not a large number of them, so that small ﬁles tend to have
smaller size than the ones from the exponential. Different
heavy-tailed distributions can generate samples which deviate
considerably from the mean towards higher values, but with
even smaller low values, in order to keep the same E[Z] = 1
[Gb]. The reason for the poor performance of the uniform is
that, although bounded between [zmin, zmax] = [0.05, 2] [Gb],
a considerable amount of samples, due to uniform sampling,
will be around the highest value, whereas no samples can
be smaller than the lowest bound. The performance in the
plots converges to an upper bound E[Psrv] ≈ 0.3433, equal to
the sum of popularities of the 2K cached most popular ﬁles
P2K

j=1 aj for γ = 0.78.

Video: Expected Total Service Success Probability

Various Distributions for file size with E[Z]=1Gb

0.35

0.3

]
 

v
r
s

P

0.25

 
[

E
 
y
t
i
l
i

b
a
b
o
r
P
 
s
s
e
c
c
u
S
d
e

 

t
c
e
p
x
E

0.2

0.15

0.1

0.05

 

Exponential
Uniform
Pareto
Weibull
Log−normal

0
 
0

200

400

600

800
1200
Mean lifespan τ [sec]

1000

1400

1600

1800

2000

Fig. 3. Comparison of Expected Service Success Probability, with different
ﬁle-size distributions for Video.

To further give intuition on the effect of the tail distribution
on the performance, we proceed in an alternative way: a
larger sample set of size F = 200 values is produced from
each distribution. The samples of each set are then indexed
in decreasing order. Table III shows the ﬁve highest values
per set. Using these, the Total Service Success Probability per

mean lifespan is plotted, which shows the same results as the
expected case, with the difference in the performance of the
Uniform distribution, which is higher due to the ﬁle-size upper
bound of 2 [Gb]. Both Fig. 4 and Table III support the intuition
and our explanations given above.

TABLE III.

SAMPLES OF FILE-SIZES [Gb] IN DESCENDING ORDER.

Distrib./Obj.
A. Uniform
B. Exponential
C. Pareto
D. Weibull
E. Log-Normal

c1
2.00
6.21
8.93
24.00
7.28

c2
1.99
5.64
6.37
18.07
7.05

c3
1.98
5.33
5.70
1.45
2.49

c4
1.97
4.22
4.92
0.07
1.13

c5
1.97
4.01
1.47
0.04
1.05

Video: Total Service Success Probability

Various Distributions for file size − Decreasing order, E[Z]=1Gb

 

Weibull
Uniform
Exponential
Pareto
Log−Normal

0.2

0.18

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

v
r
s

P
 
y
t
i
l
i

b
a
b
o
r
P
 
s
s
e
c
c
u
S

0
 
0

200

400

600

800
1200
Mean lifespan τ [sec]

1000

1400

1600

1800

2000

Fig. 4. Comparison of Total Service Success Probability, with different ﬁle-
size distributions for a Video sample set of F = 200 objects in decreasing
order related to popularity.

VI. CONCLUSIONS

The inﬂuence of mobility in the performance of cached
D2D networks has been investigated. In the proposed model,
a link is successful if the object request from the transmitter is
cached at the memory of the receiver, and the link quality
is sufﬁcient for the entire object
to be transferred before
the transmitter leaves its place. The change in position is
assumed sudden and the link is immediately dropped after-
wards. This is a simpliﬁed approach to model mobility, and
more realistic approaches can be considered in the future
where the link quality could evolve more gradually. The
work further investigates the inﬂuence of different ﬁle-size
distributions on the network performance, and the analysis
concludes that the exponential distribution may underestimate
performance compared to heavy-tailed ones. Furthermore, it
is shown that caching smaller ﬁles is in general beneﬁcial,
since these are more probable to be successfully transferred.
Further extensions of the work may include the possibility of
cooperative transmission [8], as well as an evaluation when
interference inﬂuences the coverage probability.

VII. ACKNOWLEDGEMENT

The authors would like to thank Bartłomiej Błaszczyszyn
for the discussions and contributions throughout this research.

REFERENCES

[1] A. Abhari and M. Soraya. Workload generation for YouTube. Multimed.

Tools Appl., 49:91–118, 2010.

[2] M. Afshang, Dhillon H.S., and P.H.J. Chong. Fundamentals of cluster-
centric content placement in cache-enabled Device-to-Device networks.
arXiv:1509.04747, 2015.

[3] F. Baccelli and B. Błaszczyszyn. Stochastic Geometry and Wireless
Networks, Volume I — Theory, volume 3, No 3–4 of Foundations and
Trends in Networking. NoW Publishers, 2009.

[4] E. Bastug, M. Bennis, and M. Debbah. Living on the edge: The role of
proactive caching in 5g wireless networks. Communications Magazine,
IEEE, 52(8):82–89, 2014.

[5] B. Błaszczyszyn and A. Giovanidis. Optimal geographic caching in

cellular networks. IEEE ICC, 2015.

[6] B. Błaszczyszyn and H. P. Keeler. Equivalence and comparison of

heterogeneous cellular networks. IEEE PIMRC (WDN-CN), 2013.

[7] L. Breslau, P. Cao, Fan L., G. Phillips, and S. Shenker. Web Caching and
Zipf-like distributions: Evidence and Implications. INFOCOM, 1999.
[8] Z. Chen, J. Lee, T.Q.S. Quek, and M. Kountouris. Cooperative
caching and transmission design in cluster-centric small cell networks.
arXiv:1601.00321, 2016.

[9] M. E. Crovella and A. Bestavros.

Web Trafﬁc: Evidence and Possible Causes.
Networking, 5(6):835–846, Dec. 1997.

Self-Similarity in World Wide
IEEE/ACM Trans. on

[10] A. B. Downey. The structural cause of ﬁle size distributions. Proc.
9th International Symposium on Modeling, Analysis and Simulation of
Computer and Telecommunication Systems, 2001.

[11] N. Golrezaei, A. Molisch, A. Dimakis, and G. Caire. Femtocaching and
device-to-device collaboration: A new architecture for wireless video
distribution. Communications Magazine, IEEE, 51(4):142–149, 2013.
[12] Martin Haenggi. Stochastic Geometry for Wireless Networks. Cam-

bridge University Press, 2013.

[13] W.-J. Hsu, T. Spyropoulos, K. Psounis, and A. Helmy. Modeling
spatial and temporal dependencies of user mobility in wireless mobile
networks. IEEE/ACM Trans. on Networking, 17(5), Oct. 2009.

[14] M. Ji, G. Caire, and A. Molisch. Fundamental limits of distributed
In Information Theory Workshop

caching in d2d wireless networks.
(ITW), 2013, pages 1–5. IEEE, 2013.

[15] K. Lee, J. Lee, Y. Yi, I. Rhee, and S. Chong. Mobile data ofﬂoading:
IEEE/ACM Trans. on Networking,

How much can WiFi deliver?
21(2):536–550, April 2013.

[16] X. Lin, R.K. Ganti, P.J. Fleming, and J.G. Andrews. Towards under-
standing the fundamentals of mobility in cellular networks. IEEE Trans.
on Wireless Communications, 12(4):1686–1698, 2013.

[17] A. Molisch, G. Caire, D. Ott, J. Foerster, D. Bethanabhotla, and M. Ji.
Caching eliminates the wireless bottleneck in video aware wireless
networks. Advances in Electrical Engineering, 2014.

[18] G. Paschos, S. Gitzenis, and L. Tassiulas. The effect of caching in
sustainability of large wireless networks. In WIOPT-SPASWIN, 2012.
[19] K. Poularakis and L. Tassiulas. Exploiting user mobility for wireless
content delivery. In Information Theory Proceedings (ISIT), 2013 IEEE
International Symposium on, pages 1017–1021. IEEE, 2013.

[20] P. Sermpezis, L. Vigneri, and T. Spyropoulos. Ofﬂoading on the
edge: Analysis and optimization of local data storage and ofﬂoading
in HetNets. arXiv:1503.00648, 2015.

[21] K. Shanmugam, N. Golrezaei, A. Dimakis, A. Molisch, and G. Caire.
Femtocaching: Wireless content delivery through distributed caching
helpers. Information Theory, IEEE Trans. on, 59(12):8402–8413, 2013.
[22] V. Sourlas, L. Gkatzikis, P. Flegkas, and L. Tassiulas. Distributed cache
management in information-centric networks. Network and Service
ManNetwork, IEEE Trans. on, 10(3):286–299, Sept. 2013.

[23] Y. Zhang and A.

˚Arvidsson. Understanding the Characteristics of
Cellular Data Trafﬁc. In Proc. of the 2012 ACM SIGCOMM workshop
on Cellular networks, CellNet ’12, 2012.

[24] X. Zhuo, Q. Li, W. Gao, G. Cao, and Y. Dai. Contact duration aware
data replication in delay tolerant networks. In 19th IEEE International
Conference on Network Protocols (ICNP), 2011.

