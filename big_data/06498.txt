Optimal Liquidation under

Stochastic Resilience of Price Impact

Dirk Becherer, Todor Bilarev∗, Peter Frentrup†

Institute of Mathematics, Humboldt-Universit¨at zu Berlin

March 22, 2016

We solve explicitly a two-dimensional singular control problem of ﬁnite
fuel type in inﬁnite time horizon. The problem stems from the optimal
liquidation of an asset position in a ﬁnancial market with multiplicative
price impact with stochastic resilience. The optimal control is obtained
as a diﬀusion process reﬂected at a non-constant free boundary. To solve
the variational inequality and prove optimality, we show new results of
independent interest on constructive approximations and Laplace transforms
of the inverse local times for diﬀusions reﬂected at elastic boundaries.

Keywords: Singular control, ﬁnite-fuel problem, free boundary, illiquid-
ity, transient price impact, stochastic resilience, optimal execution, Sko-
rokhod problem, oblique reﬂection, inverse local time

MSC2010 subject classiﬁcations: 35R35, 49J40, 49L20, 60H30, 60J50,

60J55, 93E20, 91G80

1 Introduction

Trading actions of large investors typically have an adverse eﬀect on the prices in
ﬁnancial markets. If liquidity is ﬁnite, trading large quantities over short time pe-
riods can cause high liquidity costs. Therefore, a large trader needs to balance her
preference to complete a trading objective early against the wish to reduce liquidity
costs. Considering the intertemporal modeling of price impact one can diﬀerentiate
between permanent impact and temporary impact. Permanent impact of a trade is a
price change which is of the same size for the current price and for all future prices. In
contrast, temporary impact could be persistent but it lessens and eventually vanishes
∗Support by German Science foundation DFG via Berlin Mathematical School BMS and research
†Email addresses: becherer,bilarev,frentrup@math.hu-berlin.de

training group RTG1845 StoA is gratefully acknowledged.

1

6
1
0
2

 
r
a

 

M
1
2

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
8
9
4
6
0

.

3
0
6
1
:
v
i
X
r
a

over time. Basically two approaches to temporary impact can be distinguished in the
extensive literature on illiquid markets and, more speciﬁcally, on the optimal execution
problem, see e.g. [GS13] and the references therein. The ﬁrst approach takes temporary
impact to be strictly instantaneous, like in the model by Almgren and Chriss, such that
it does not depend on past trades but only on the present trade. Such an impact can be
perceived as a transaction cost that could be non-proportional to the volume traded. A
second approach, to which our paper belongs, is inspired by the idea of a shadow limit
order book (LOB), see e.g. [PSS11, ASS12, LS13], and considers temporary impact
to be transient, in the sense that it is persistent but decreases over time. If transient
price impact is additive as in many papers, instead of multiplicative [Løk12, BBF16],
negative asset prices can occur with (small) positive probability. The article [Kyl85]
distinguishes depth, resilience and tightness as key characteristics of liquidity. Depth
corresponds to the (current) shape of the LOB. Finite resilience corresponds to the
extent and swiftness of transient impact. Tightness is reﬂected by closeness of the
bid-ask spread. Yet, our control problem requires only one (bid) side of the LOB, being
posed over monotone strategies.

To analyze how certain liquidity characteristics aﬀect the optimal behavior of a large
trader, it is sensible to keep other parts simple, cf. [LS13]. The optimal trade execution
literature considers mostly deterministic or even constant parametrizations for depth
and resilience. We are only aware of one notable exception with analytical results in
continuous time for transient impact. [FSU15] study stochastic height (depth) of a
block-shaped LOB in an additive impact model in continuous time. They investigate
how the state space divides into an action region and an inaction region separated by
a boundary. Apart from existence no explicit description of the separating boundary
is obtained. Let us note that stochastic instantaneous impact is studied in [Alm12],
and stochastic non-zero drift of the fundamental price is studied in [LS13] for transient
additive impact. We note that stochastic LOB shapes (depth) could also arise if one
wishes to rewrite a multiplicative LOB model as a (more complex) additive LOB model
with additional state dependencies, cf. [Løk12, Sect. 5]. In this paper, resilience of prices
is stochastic in the sense that prices which have been aﬀected by large trades revert
in a transient fashion back towards the fundamental prices, by following stochastic
dynamics of Ornstein-Uhlenbeck (OU) type. More speciﬁcally, the price process
S = (St)t≥0 = (f (Yt) ¯St)t≥0 observed in the market deviates by a factor f (Y ) from a
fundamental price process ¯S = ( ¯St)t≥0, which would prevail in the absence of large
traders. The price impact function f (·) is non-negative and increasing with f (0) = 1,
and the market impact process Y is an OU-process controlled by the large trader’s
strategy, see (2.6). We note that the relative price impact ∆θt (cid:55)→ f (Yt− + ∆θt)/f (Yt−)
by current trades, and hence the depth oﬀered by the LOB to the large trader, can
vary stochastically with Y as well, since the impact function f is not required to be
exponential. We take ¯S to be an exponential Brownian motion and admit for non-zero
drift and correlation with Y . For such a model, we study the optimal liquidation
problem in inﬁnite time horizon as a singular stochastic control problem of ﬁnite fuel
type. Our control objective (see (2.7)) involves terms like in [Tak97, DZ98, DM04]
which depend explicitly on ( ¯S, Y ) with a summation of integrals over any jump of the
control. [DM04] consider a ﬁnite horizon and prove general existence of a weak optimal

2

control, but do not obtain structural properties of those.

We construct an explicit solution to the singular control problem. The unique optimal
strategy is given by the local-time process of an obliquely reﬂected diﬀusion on a curved
boundary in R2, the state space of our impact process and the holdings in the risky asset.
To construct a candidate solution, we ﬁrst restrict the set of optimization strategies to
these described by reﬂected diﬀusions on monotone boundaries, and optimize over the
set of possible boundaries. In order to apply calculus of variations methods, we derive
an explicit formula for the Laplace transform of the inverse local times of diﬀusions
reﬂected on elastic boundaries, which retract according to the local time that the
reﬂected process has spent on the boundary. Having derived a (one-sided) optimal
boundary (Theorem 5.6), we construct a candidate value function from the variational
inequality for the control problem. Obtaining a classical solution of the variational
inequality, one can apply a martingale optimality principle (Proposition 3.3).

Reﬂected diﬀusions at elastic boundaries are an interesting topic in itself. Hence we
study them in greater generality, beyond the OU setup of the control problem. There is
a rich literature on the Skorokhod problem of reﬂected diﬀusions in time-independent
domains, going back to [Tan79] for normal reﬂection in convex domains. [DI93] study
oblique reﬂection in non-smooth domains while [N ¨O10] generalize the problem to
oblique reﬂection in time-dependent domains. For an extensive literature overview we
refer to the latter. We investigate one-dimensional diﬀusions reﬂected at (monotone)
boundaries that vary with local-time. Our main contribution (Theorem 7.2) here is the
Laplace transform of the inverse local time, derived by a constructive approximation
of the reﬂected diﬀusion. A byproduct of this construction is global existence, see
Remark 7.3.

Typically solutions to singular control problems are described by reﬂected diﬀusions.
In most of the examples in the literature, e.g. on the ﬁnite fuel monotone follower
problem and its generalizations, cf. [BSW81, KS86, KOWZ00], where so explicit so-
lutions of singular control problems are derived, the controlled process is the sum
of a Brownian motion and the control, Wt + Θt, and the optimal control is again
obtained by reﬂecting the Brownian motion at an (elastic) boundary. In this case,
however, the local time process has an explicit representation due to the particular
nature of the controlled process (see though [SS89] for a remarkable exception where
the existence of an optimally controlled two-dimensional Brownian motion is proved
without explicitly constructing the reﬂecting boundary). In contrast, motivated by our
application we consider a mean-reverting process of Ornstein-Uhlenbeck type driven by
a Brownian motion and a control, see (2.6), which does not permit for such an explicit
representation. Complications in the veriﬁcation arguments for optimality arise from
the implicit nature of the eigenfunctions for the OU generator, that are given in terms
of Hermite functions.

The main contributions of the present paper are the following. We solve explicitly a
two-dimensional singular control problem and characterize the optimal control, which is
stochastic and given by the local-time process of a reﬂected Ornstein-Uhlenbeck process
at a moving non-constant boundary. The latter is deﬁned through an ODE given in
terms of special functions, see Theorem 3.1. To this end, we investigate (approximations
of) SDEs with reﬂections at an elastic boundary and derive the representation (7.12)

3

for the Laplace transform of the inverse local time at the boundary. For the application
problem, our main contribution is to solve the optimal liquidation problem in a
multiplicative transient impact model with stochastic noise in the dynamics of the
volume eﬀect process, i.e. stochastic resilience of actual prices S towards fundamental
(unaﬀected) prices ¯S.

The paper is organized as follows. Section 2 formulates the singular stochastic control
problem. The solution of the optimization problem is stated in Section 3. In Section 4
a calculus of variations problem is posed, by restricting to strategies given by diﬀusions
reﬂected at smooth boundaries. This builds on results on the inverse local time of
reﬂected diﬀusions at elastic boundaries from Section 7. The latter section appears to
be of interest in its own, and is presented so that it can be read independently. The
free boundary is constructed in Section 5. By solving a variational inequality, the value
function and the optimal control are obtained in Section 6.

2 Problem setting
We consider a ﬁltered probability space (Ω,F, (Ft)t≥0, P) with two correlated Brownian
motions W and B with correlation coeﬃcient ˆρ ∈ [−1, 1], such that we have

t ≥ 0.

[W, B]t = ˆρt ,

(2.1)
for the quadratic co-variation of W and B. The ﬁltration (Ft)t≥0 is assumed to satisfy
the usual conditions of completeness and right continuity, so we can take RCLL versions
for semimartingales. We refer to [JS03] for notions from stochastic analysis.
We consider a market with a risky asset in addition to the riskless numeraire asset,
whose (discounted) price is constant at 1. The large investor holds Θt ≥ 0 shares of the
risky asset at time t. He tries to liquidate his initial position of Θ0− shares by trading
according to

Θt := Θ0− − At ,

(2.2)

where A is a predictable, c`adl`ag, monotone process describing the cumulative number
of assets sold up to time t. We deﬁne the set of admissible strategies A as

A(Θ0−) := {A | A non-decreasing, c`adl`ag, previsible,

with 0 =: A0− ≤ At ≤ Θ0−}.

(2.3)

The unaﬀected fundamental price ¯S = ( ¯St)t≥0 of the risky asset evolves according to

d ¯St = µ ¯St dt + σ ¯St dWt , S0 ∈ (0,∞),

(2.4)

as a geometric Brownian motion, in absence of perturbations by large investor’s trades.
By trading, however, the large investor has market impact on the actual price

St := f (Yt) ¯St ,

(2.5)

of the risky asset through some impact process Y , by an increasing positive function
f > 0 in C 1 with f (0) = 1. The process Y can be interpreted as a volume eﬀect

4

(cid:90) t
t +(cid:80)

0

(cid:88)

0≤u≤t
∆Au(cid:54)=0

(cid:90) ∆Au

0

proccess, representing the transient volume displacement by large trades in a shadow
limit order book (LOB) whose shape corresponds to the price impact function f , cf.
[PSS11] or [BBF16, Sect. 2.1]. The eﬀect from perturbations dBt − dAt on the process

dYt = −hY (Yt) dt + dBt − dAt ,

Y0− = y,

(2.6)

with hY (0) = 0 and h(cid:48)
Y > 0 are transient over time, in that Y is mean reverting
towards zero. Sometimes we shall write Y y,A to stress the dependence of Y on its
initial state y and the strategy A. For linear hY (y) := βy, β > 0, dynamics of Y are of
Ornstein-Uhlenbeck type, driven by dB − dA. The stochastic noise herein constitutes
own stochasticity for the transient evolution of market impact; one may interpret dBt
as cumulative transient inﬂuence on dYt from other (uninformed) large ‘noise traders’.
For γ ≥ 0, the γ-discounted proceeds up to time t from a liquidation strategy A are

Lt(y; A) :=

e−γuf (Yu) ¯Su dAc

u +

e−γu ¯Su

f (Yu−−x) dx,

t ≥ 0, (2.7)

where At = Ac
u≤t ∆Au is the (pathwise) decomposition of A into its continuous and
pure jump part, and Y = Y y,A is given by (2.6). Jump terms in (2.7) can be explained
by an LOB perspective or from stability considerations, cf. [BBF15, Sections 2.1, 6].
As L is increasing, the limit L∞ := limt→∞ Lt exists. The large trader’s optimization

problem is to maximize expected (discounted) proceeds

max

A∈A(Θ0−)

E[L∞(y; A)]

with

v(y, θ) := sup

A∈A(θ)

E[L∞(y; A)],

(2.8)

over an inﬁnite time horizon, with the value function v(y, θ) for y ∈ R and θ ∈ [0,∞).

Remark 2.1. The value function v is increasing in y and θ. Indeed, monotonicity in θ
follows from A(θ1) ⊂ A(θ2) for θ1 ≤ θ2. For monotonicity in y, note that for y1 ≤ y2 and
any strategy A ∈ A(θ) one has Y y1,A
for all t, implying Lt(y1; A) ≤ Lt(y2; A).
For Sections 3–6, the functions f, h and the scalars µ, γ, σ, ˆρ satisfy the conditions of

≤ Y y2,A

t

t

Assumption 2.2. C1. The resilience function hY (y) = βy in (2.6) is linear with a

constant positive rate of resilience β ∈ (0,∞).

C2. The impact function f satisﬁes f, f(cid:48) > 0 and (f(cid:48)/f )(cid:48) < (Φ(cid:48)/Φ)(cid:48) where Φ := Φδ
is the (up to a constant) unique positive and increasing solution to the ODE
δΦ = 1

2 σ2Φ(cid:48)(cid:48) + (σ ˆρ − hY )Φ(cid:48), that is given in (4.9).

C3. The impact function f furthermore satisﬁes (f(cid:48)/f )(cid:48) < (Φ(cid:48)(cid:48)/Φ(cid:48))(cid:48)
C4. Moveover, the function λ(y) := f(cid:48)(y)/f (y), y ∈ R, is bounded, i.e. there is

λmax ∈ (0,∞) such that 0 ≤ λ(y) ≤ λmax for all y ∈ R.

C5. δ := γ − µ < 0, that means the drift −δ ¯S of the γ-discounted fundamental price

e−γt ¯St is negative.

5

C6. The function k(y) := 1
2
C7. There exist solutions y0 and y∞ of f(cid:48)/f = Φ(cid:48)/Φ and f(cid:48)/f = Φ(cid:48)(cid:48)/Φ(cid:48), respectively.

f (y) is strictly decreasing.

f(cid:48)(cid:48)(y)
f (y) − (β + δ) + (σ ˆρ − βy) f(cid:48)(y)

The conditions above are all satisﬁed by e.g. f (y) = exp(λy) with λ > 0; see [BBF16,

Section 2.1] for the shape of the related multiplicative LOB.

Assumption C1 is needed twice: to pinpoint the special function Φ in Assumption C2
as a Hermite function, for which we can prove certain Turan-like inequalities in
Lemma 5.1, that are crucial – together with C2 and C3 – to obtain a well-behaved
free boundary in Lemma 5.3. Moreover, C1 and C6 are needed for our veriﬁcation
arguments, see the proof of Lemma 6.5. Assumptions C2 and C3 ensure uniqueness
of certain boundary points y0 and y∞ from Assumption C7 which are needed in
Lemma 5.3. While C3, uniqueness of y∞, is not crucial there, it will be needed in (6.17)
for the veriﬁcation. The bound on λ in Assumption C4 is utilized to show some growth
condition on the value function in Lemma 6.3, that is required to apply the martingale
optimality principle (Proposition 3.3). The overall negative drift in Assumption C5 is
needed to have a ﬁnitely-valued optimization problem on an inﬁnite time horizon.

3 Heuristic derivation of the solution

In this section, we will show how the variational inequality describing the value function
is suggested by an application of the martingale optimality principle. To see how this
applies to our problem, consider for an admissible strategy A the process

Gt(y; A) := Lt(y; A) + e−γt ¯St · V (Yt, Θt),

(3.1)
where V ∈ C 2,1(R × [0,∞); [0,∞)) is to be chosen later. Suppose that G is a super-
martingale; thus decreasing in expectation. So we will expect to have

¯S0V (y, Θ0−) = E[G0−(y; A)] ≥ lim
T→∞

E[LT (y; A)] + lim

T→∞ e−γT E[ ¯ST V (YT , ΘT )]

= E[L∞(y; A)],

provided that the second term in the right-hand side converges to 0. Hence, for V being
such that G is a supermartingale for every admissible strategy A and a martingale for
at least one strategy A∗, one can conclude that V is essentially the value function for
(2.8) (modulo the factor ¯S0). To ﬁnd V , let us apply Itˆo’s formula to obtain

dGt = e−γt ¯St

Vy(Yt−, Θt−) dBt + σV (Yt−, Θt−) dWt

(cid:16)
+(cid:0)(µ − γ)V + (σ ˆρ − βYt−)Vy + 1
+(cid:0)f − Vy − Vθ
(cid:1)(Yt−, Θt−) dAc
(cid:90) ∆At

(cid:0)f − Vy − Vθ

+

(cid:1)(Yt−, Θt−) dt

2 Vyy

(cid:1)(Yt− − x, Θt− − x) dx

t

(cid:17)

(3.2)

.

0

6

To ease notation, deﬁne a diﬀerential operator on C 2,0 functions ϕ by
ϕyy(y, θ) + (σ ˆρ − βy)ϕy(y, θ) − δϕ(y, θ),

Lϕ(y, θ) :=

1
2

where δ := γ − µ. So G is a local (super-)martingale if we have

0 = max{f − Vy − Vθ , LV }.

(3.3)
This suggests the existence of a sell region S where the dA-integrand f − Vy − Vθ is
zero and it is optimal to trade (i.e. sell), and a wait region W in which the dt-integrand
LV is zero and it is optimal not to trade. Assume that both regions

S = {(y, θ) ∈ R × (0,∞) | y(θ) < y},
W = {(y, θ) ∈ R × (0,∞) | y < y(θ)},

are separated by a smooth boundary y(θ). An optimal strategy, i.e. a strategy for
which G is a martingale, would be described as follows: if (Y0−, Θ0−) ∈ S, perform a
block sell of size ∆A0 such that (Y0, Θ0) = (Y0− − ∆A0, Θ0− − ∆A0) ∈ ∂S . Threafter,
sell just enough as to keep the process (Y, Θ) within W. In this way, the process (Y, Θ)
should be described by a diﬀusion process that is reﬂected at the boundary ∂W ∩ ∂S
in direction (−1,−1), i.e. there is waiting in the interior and selling at the boundary,
until all shares are sold at {(y, 0) | y < y(0)} = ∂W\∂S. For such reﬂected diﬀusions,
Section 7 will discuss existence, uniqueness and some properties that will be key for the
subsequent construction of the optimal control. The solution of the optimal liquidation
problem is indeed described by the (local time process) of a reﬂected diﬀusion along a
boundary explicitly given by an ODE. This main result for the paper is stated as
Theorem 3.1. Let Assumption 2.2 be satisﬁed. Consider the boundary y : [0,∞) → R
given by the ordinary diﬀerential equation

f(cid:48)(cid:48) · (ΦΦ(cid:48)(cid:48) − (Φ(cid:48))2) + f(cid:48) ·(cid:0)Φ(cid:48)Φ(cid:48)(cid:48) − ΦΦ(cid:48)(cid:48)(cid:48)(cid:1) + f ·(cid:0)Φ(cid:48)Φ(cid:48)(cid:48)(cid:48) − (Φ(cid:48)(cid:48))2(cid:1)(cid:19)(cid:0)y(θ)(cid:1),

(cid:0)(Φ(cid:48))2 − ΦΦ(cid:48)(cid:48)(cid:1)(f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48))

y(cid:48)(θ) =

(cid:18) 1

Φ

with initial condition y(0) = y0. Then y is strictly decreasing and maps [0,∞) bijectively
onto (y∞, y0].
The optimal liquidation problem (2.8) admits a unique optimal liquidation strategy A∗
that is described as follows:

1. If Y0− ≥ y0 + Θ0−, sell everything immediately at time 0 and stop trading.
2. Otherwise, if y(Θ0−) < Y0− < y0 + Θ0−, perform at time 0 a block trade of
0 := ∆ > 0 so that Y0− − ∆ = y(Θ0− − ∆), i.e. Y0 = Y0− − ∆ is on the
size A∗
boundary y. Afterwards, sell according to the local time process L until the asset
position is liquidated (at some time τ ) and then stop trading. That means to
choose A∗ := (∆ + L)1[[0,τ ]], for (Y, L) being continuous adapted processes with

7

non-decreasing L, starting in (Y0, 0), and solving the y-reﬂected SDE

Yt ≤ y(Θ0− − ∆ − Lt) ,
dYt = (σ ˆρ − βYt) dt + dBt − dLt ,
dLt = 1{Yt=y(Θ0−−∆−Lt)} dLt ,

on time interval [[0, τ ]] with τ := inf{t ≥ 0 | Lt = Θ0− − ∆}.

Furthermore, the Laplace transform of the inverse local time τ(cid:96) := inf{t > 0 | Lt > (cid:96)}
in case 2. is given by

E(cid:2)e−λτ(cid:96)(cid:3) =

(cid:1)

(cid:0)Y0
(cid:0)y(Θ0)(cid:1) · exp

Φλ

Φλ

(cid:18)(cid:90) (cid:96)

0

(cid:0)y(cid:48)(Θ0 − a) + 1(cid:1) Φ(cid:48)

(cid:0)y(Θ0 − a)(cid:1)
(cid:19)
(cid:0)y(Θ0 − a)(cid:1) da

,

λ
Φλ

for λ > 0, 0 ≤ (cid:96) ≤ Θ0 (= Θ0− − ∆). In particular, time to liquidation τ is ﬁnite a.s.
The optimality conditions that have already been motivated previously are proven
next. In subsequent sections we construct the function V . To check that the stochastic
integral processes in (3.2) are true (not just local) martingales, we use
Lemma 3.2. Let Θ0− ≥ 0 be given and F ∈ C 2,1(R × [0,∞); R) be such that there
exist constants C1, C2 ≥ 0 with |F (y, θ)| ≤ C1 exp(C2y)∨ 1 for all (y, θ) ∈ R× [0, Θ0−].
For an admissible strategy A ∈ A(Θ0−) let Y A =: Y denote the impact process deﬁned
by (2.6) for y ∈ R. Then the stochastic integral processes

¯SuF (Yu, Θu) dBu

and

¯SuF (Yu, Θu) dWu

are true martingales.

Proof. By the exponential growth of F it suﬃces to check E[(cid:82) t

u exp(2C2Yu) du] < ∞
¯S2
for every t ≥ 0. Consider the Ornstein-Uhlenbeck process dXt = −βXt dt + dBt, with
X0 = y. By applying Itˆo’s formula to the processes eβtXt and eβtYt, one gets that

0

eβt(Yt − Xt) =

eβu dΘu

for t ≥ 0.

(cid:90) ·

0

(cid:90) ·

0

Since Θ is non-increasing, we conclude that Yt ≤ Xt for all t ≥ 0. In particular,

(cid:105)

E

¯S2
u exp(2C2Yu) du

¯S2
u exp(2C2Xu) du

E[ ¯S2

u exp(2C2Xu)] du ≤

E[ ¯S4

u]E[exp(4C2Xu)] du < ∞,

[0,t]

(cid:90)
(cid:104)(cid:90) t
(cid:105) ≤ E
(cid:90) t

0

(cid:113)

0

(cid:104)(cid:90) t
(cid:90) t

0

=

0

using Cauchy-Schwarz and the fact that X is a Gaussian process.

The next result shows optimality, provided that essential variational inequalities for

the (candidate) solution have been veriﬁed.

8

Proposition 3.3 (Martingale optimality principle). Let V : R × [0,∞) → [0,∞) be a
C 2,1 function with the following properties:

1. For every Θ0− ≥ 0, there exists constants C1, C2 so that

V (y, θ) ≤ C1 exp(C2y) ∨ 1 ∀(y, θ) ∈ R × [0, Θ0−];

2. For every Θ0− ≥ 0 and A ∈ A(Θ0−), the process

Gt(y; A) := Lt(y; A) + e−γt ¯St · V (Yt, Θt),

is a supermartingale, where Y = Y y,A is deﬁned in (2.6), and additionally
G0(y; A) ≤ G0−(y; A) := ¯S0V (Y0−, Θ0−)

Then we have ¯S0 · V (y, θ) ≥ v(y, θ). Moreover, if there exists A∗ ∈ A(Θ0−) such that
G(y; A∗) is a martingale and it holds G0(y; A∗) = G0−(y; A∗), then ¯S0V (y, θ) = v(y, θ)
and v(y, θ) = E[L∞(y; A∗)] with Θ0− = θ.
Proof. By the supermartingale property we have for every T ≥ 0

¯S0V (Y0−, Θ0−) ≥ E[G0(y; A)] ≥ E[LT (y; A) + e−γT ¯ST V (YT , ΘT )]

= E[LT (y; A)] + e−γT E[ ¯ST V (YT , ΘT )]
= E[LT (y; A)] + e−δT ¯S0E[E(σW )T V (YT , ΘT )].

(3.4)
By monotone convergence, the ﬁrst summand above tends to E[L∞(y; A)] for T → ∞.
To see that the second summand converges to 0, consider the Ornstein-Uhlenbeck
process dXt = −βXt dt + dBt, X0 = y. Applying Itˆo’s formula to eβtXt and eβtYt
shows that

eβt(Yt − Xt) =

eβu dΘu ∀t ≥ 0.

(cid:90)

[0,t]

K ≤ 1 + C1 exp

qC2E[XT ] +

1
2

q2C 2

2 Var(XT )

qC2y +

1
4β

q2C 2
2

9

Since Θ is non-increasing, we conclude that Yt ≤ Xt for all t ≥ 0. Let p, q > 1 be
conjugate, i.e. 1 = 1/q + 1/p. Using H¨older’s inequality, one gets

E(cid:2)E(σW )T V (YT , ΘT )(cid:3) ≤ E(cid:2)E(σW )p
(cid:0) 1
2 p2σ2T − 1

(cid:3)1/pE(cid:2)V (YT , ΘT )q(cid:3)1/q
2 pσ2T(cid:1)(cid:3)1/pE[V (YT , ΘT )q]1/q
(cid:16) 1
2 pσ2T(cid:1)(cid:17)
E(cid:2)V (YT , ΘT )q(cid:3)1/q
(cid:17)
(cid:16) p − 1

= E[E(pσW )T ]1/p exp

T

p

= E(cid:2)exp(cid:0)pσWT − 1
(cid:17)
(cid:17)

(cid:16) p − 1
(cid:16) p − 1

= exp
≤ exp

σ2T

σ2T

E[V (YT , ΘT )q]1/q ≤ exp
E[C1 exp(qC2XT ) ∨ 1]1/q

σ2T

2

E[C1 exp(qC2YT ) ∨ 1]1/q

Using the fact that X is a Gaussian process with mean E[XT ] = ye−βT and variance
Var(XT ) = 1

2β (1 − e−2βT ), one obtains for K := E[C1 exp(qC2XT ) ∨ 1] that

(cid:17) ≤ 1 + C1 exp

(cid:16)

(cid:17)

.

2

2

(cid:16)

one gets that exp(−δT ) exp(cid:0) p−1

2 σ2T(cid:1) is exponentially decreasing in T , and can con-

This bound on K is independent of T . By choosing p > 1 such that p−1
2 σ2 < δ,
clude that the second summand in (3.4) converges to 0 for T → ∞. This implies
that ¯S0V (y, θ) ≥ E[L∞(y; A)] for all A ∈ A(θ) and yields the ﬁrst part of the claim.
The second part follows similarly by noting that, if A∗ ∈ A(θ) is such that G(y; A∗)
is a martingale and G0(y; A) = G0−(y; A), then we have equalities instead of in-
equalities in the estimates leading to (3.4). By taking T → ∞ we conclude that
¯S0V (y, θ) = E[L∞(y; A∗)]. Since ¯S0V (y, θ) ≥ v(y, θ) by the ﬁrst part of the claim, we
deduce the optimality of A∗.

In the remainder, we will ﬁnd the (candidate) value function for our stochastic control
problem by constructing a classical solution of the variational inequality (3.3) with
boundary condition V (y, 0) = 0, for y ∈ R. We will verify optimality of this candidate
value function and prove that the optimal control is given by a process reﬂected on a
free boundary curve, which is constructed fairly explicitly as solution to an ODE.

4 Reformulation as a calculus of variations problem

In this section we will restate the free boundary problem of the variational (in-)equa-
lity (3.3) as an isoperimetric calculus of variations problem (see (4.15)–(4.16)), whose
solution should describe the boundary (via the reparametrization (4.14)).
To sketch the main idea, suppose that the large trader has to liquidate Θ0 ≥ 0
shares and that (Y0, Θ0) is already on the free boundary (after possible initial jump).
Also, suppose that the boundary below level Θ0 is parametrized by a suitable function
g : [0, Θ0] → R, i.e. the boundary up to level Θ0 is given by {(g(θ), Θ0−θ) | θ ∈ [0, Θ0]},
i.e. g(0) = Y0. In this case, the proceeds corresponding to a strategy Ag that sells only
when the state process (Y, Ag) is on the boundary g can be expressed in terms of the
Laplace transform of the local time of a diﬀusion reﬂected at the boundary, namely
(Y, Ag), see (4.7) below. Thus, our candidate boundary g should be a maximizer of
these proceeds and this maximizer can be characterized using tools from calculus of
variations. In what follows, we will implement these ideas.
Let τΘ0 be the stopping time when Ag = Θ0 under the measure P. For the continuous
strategy Ag = A we have by [DM82, Theorem 57] for any T ∈ [0,∞), that E[LT ] equals

E

f (Yt)e−δtE(σW )t dAt

f (Yt)e−δt dAt
.
For ﬁxed T , let Q be the measure given by dQ/dP = E(σW )T on FT . Then

= E

0

(4.1)

(cid:104)(cid:90) τΘ0∧T

(cid:105)

(cid:105)

(cid:104)E(σW )T

(cid:90) τΘ0∧T
(cid:105)

0

E[LT ] = EQ(cid:104)(cid:90) τΘ0∧T
dYt = (σ ˆρ − βYt) dt + d(cid:101)Bt − dAt ,

f (Yt)e−δt dAt

0

.

10

Girsanov’s theorem gives that under Q, the process (cid:101)Bt := Bt − [B, σW ]t = Bt − σ ˆρt is

(4.2)

a Brownian motion. Therefore, we have under Q

(4.3)

i.e. the impact process Y is a (reﬂected) Ornstein-Uhlenbeck process with shifted
(non-zero) mean reversion level, and A is its local time on the boundary. We cannot
directly pass to the limit T → ∞ in (4.2) because the measure change Q depends on T .
However, note that the right-hand side of (4.2) depends only on the law of the reﬂected
diﬀusion (Y, A) under the measure Q. That is why we consider the reﬂected diﬀusion
(X, AX ) with the following dynamics under the initial measure P:

dXt = (σ ˆρ − βXt) dt + dBt − dAX
t ,
t ) dAX
dAX
t = 1
t ,
(cid:96) = inf{t > 0 | AX
t > (cid:96)}.
τ X

Xt=g(AX

X0 = g(0) ,
AX
0 = 0 ,

(4.4)

(4.5)

(4.6)

Note that the diﬀerence between the impact process Y and the process X is just the
shift in the drift of X by σ ˆρ, and hence we will occasionally refer to X as the shifted
impact process. Now, by (4.2) we have E[LT ] = E
gives for T → ∞ by monotone convergence on both sides

f (Xt)e−δt dAX

, which

∧T

Θ0

0

t

(cid:105)

(cid:104)(cid:82) τ X
(cid:104)(cid:90) τ X
(cid:105)
(cid:90) Θ0
t ))e−δt dAX
(cid:105)
f (g((cid:96)))E(cid:2)e−δτ X
(cid:96) (cid:3) d(cid:96)
(cid:17)
(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)

f (g(AX

= E

d(cid:96) ,

da

=

Θ0

0

0

t

δ(g(a))
Φδ(g(a))

(cid:105)

(cid:16)−

(cid:90) (cid:96)

0

Θ0

(cid:104)(cid:90) τ X
(cid:104)(cid:90) Θ0
(cid:90) Θ0

0

0

0

E[L∞] = E

f (Xt)e−δt dAX

t

= E

f (g((cid:96)))e−δτ X

(cid:96) d(cid:96)

=

f (g((cid:96))) exp

(4.7)

(4.8)

using (4.5) and Theorem 7.2 under the assumption g(cid:48) ≥ 0.

A simple corollary of Theorem 7.2 is that the inverse local time in the case of reﬂected
Ornstein-Uhlenbeck process is almost surely ﬁnite and we can express its moments in
terms of the Hermite functions. Note that up to a positive multiplicative constant

(cid:16)

(σ ˆρ − βx)/(cid:112)β

(cid:17)

Φδ(x) = H−δ/β

,

(4.9)

where Hν(x) denotes the Hermite function with parameter ν, i.e. Hν is a positive
solution of the ODE ϕ(cid:48)(cid:48)(x) − 2xϕ(cid:48)(x) + 2νϕ(x) = 0, see [Leb72, (10.2.8) on p. 285] for
the precise deﬁnition. Recall the following facts about the Hermite functions that will
be needed for the rest of the paper. We will concentrate on real parameters ν ∈ R, but
similar statements hold for ν ∈ C, see the references given.

1. H is analytic both on the argument and the parameter, see [Leb72, p. 285].

2. The derivative is given [Leb72, (10.4.4), p. 289] by

H(cid:48)
ν(x) = 2νHν−1(x).

(4.10)

3. If ν < 0, Hermite functions have [Leb72, (10.5.2), p. 290] an integral representation

Hν(x) =

1

Γ(−ν)

e−t2−2xtt−ν−1 dt.

(4.11)

(cid:90) ∞

0

11

4. If ν < 0, Hv is strictly decreasing and limx→+∞ Hν(x) = 0 [Leb72, (10.6.4),p. 292].

Corollary 4.1. Consider the setup from Theorem 7.2 with the reﬂected OU process X
solving (4.4) – (4.5) with its inverse local time τ X as deﬁned in (4.6). Then for every
k ∈ N the k-th moment of the inverse local time exists and is given by

(cid:12)(cid:12)(cid:12)δ=0

(cid:16)−

(cid:90) (cid:96)

0

exp

(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)

δ(g(a))
Φδ(g(a))

(cid:17)

da

.

(4.12)

E[(τ X

(cid:96) )k] = (−1)k d
dδ

In particular, τ(cid:96) < ∞ a.s. for every (cid:96) ≥ 0.
Proof. Note that equality (7.12) is trivially satisﬁed also for δ = 0 since Φ0(·) = 1. By
the analyticity of the Hermite functions on the parameter, the right-hand side of (7.12),
as a function of δ, is inﬁnitely often diﬀerentiable at 0, because Φ0(·) = 1, see also [Kle08,
Thm. 6.28] for an argument of why we can exchange integration w.r.t. the variable
a and diﬀerentiation w.r.t. δ. On the other hand, dominated convergence gives that
these derivatives are exactly equal to E[(−τ X
(cid:96) )k] by considering the right-derivatives
(δ (cid:38) 0), see [Kle08, Example 6.29] for a more detailed account.
In the following we often abbreviate Φ := Φδ. Since g(a) = y(Θ0 − a) we get from (4.8)

with ρ((cid:96)) :=(cid:82) (cid:96)

(cid:0)1 − y(cid:48)(a)(cid:1) Φ(cid:48)(y(a))

Φ(y(a)) da that

0

(cid:90) Θ0

0

f(cid:0)y((cid:96))(cid:1)eρ((cid:96)) d(cid:96).
(cid:19)

Φ(w(z))
Φ(cid:48)(w(z))

(cid:90) r

(cid:18)

0

E[L∞] = e−ρ(Θ0)

(4.13)

Since Φ(cid:48), Φ > 0 and by assumption y(cid:48) < 0, the function ρ in strictly increasing and so
has an inverse ρ−1. Fixing R := ρ(Θ0) and setting w(r) := y(ρ−1(r)), we ﬁnd

ρ−1(r) =

w(cid:48)(z) +

dz.

(4.14)

Hence, ﬁnding a maximizing function y for (4.13) can be reduced to the problem of
ﬁnding a function w which maximizes

(cid:18)

(cid:19)

J(w) :=

with subsidiary condition

K(w) :=

f (w(r))e−(R−r)

w(cid:48)(r) +

Φ(w(r))
Φ(cid:48)(w(r))

dr

(4.15)

(cid:19)

w(cid:48)(r) +

Φ(w(r))
Φ(cid:48)(w(r))

dr = Θ0 .

(4.16)

(cid:90) R

0

(cid:90) R

(cid:18)

0

The requested boundary function then is y(θ) = w(ρ(θ)).

12

5 Solving the calculus of variations problem

In this section, we solve the calculus of variations problem of maximizing (4.15) subject
to (4.16) locally by employing necessary and suﬃcient conditions on the ﬁrst and
second variation of functionals involved. We obtain the candidate free boundary y(θ),
see equations (5.11) and (5.12), and show its local optimality in Lemma 5.4. We then
relate our results on the calculus of variations problem to the optimal trading problem
in Theorem 5.6 that will be crucial later to verify the desired inequality in the sell
region, presented in Lemma 6.5.

A maximizer w of the isoperimetric problem (4.15) – (4.16) is also a maximizer of
J + mK for some constant m = m(R) that is the Lagrange multiplier, c.f. [GF00,
Theorem 2.12.1]. The ﬁrst variation δ(J + mK) vanishes if its corresponding Euler-
Lagrange equation holds:

Fw(cid:48) + m ·(cid:16)

0 = Fw − d
dr

Gw − d
dr

Gw(cid:48)

(cid:17)

Inserting r = 0 gives a condition for y0, namely

f(cid:48)(y0)Φ(y0) = f (y0)Φ(cid:48)(y0).

Assumption C7 guarantees existence and C2 uniqueness of y0. On the other hand,
diﬀerentiating both sides of (5.3) with respect to r gives an ODE for w, namely

0 = w(cid:48) ·(cid:0)er(f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48))Φ(cid:48) + er(f(cid:48)(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48)(cid:48))Φ − f (y0)(Φ(cid:48)Φ(cid:48)(cid:48) − ΦΦ(cid:48)(cid:48)(cid:48))(cid:1)

+ er(f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48))Φ

with abbreviations f := f(cid:0)w(r)(cid:1), Φ := Φ(cid:0)w(r)(cid:1), etc.

Both sides in the above equality (5.3) are negative on the boundary w(r), due to

Lemma 5.1. The positive, increasing eigenfunctions Φ = Φδ corresponding to the
eigenvalue δ > 0 of the generator of an Ornstein-Uhlenbeck process satisfy

(Φ(n)(y))2 < Φ(n−1)(y)Φ(n+1)(y)

for all y ∈ R and n ∈ N. Especially, (Φ(cid:48))2 < ΦΦ(cid:48)(cid:48).

13

with G(r, w, w(cid:48)) := w(cid:48) + Φ(w)/Φ(cid:48)(w) and F (r, w, w(cid:48)) := f (w)e−(R−r)G(r, w, w(cid:48)), the
integrands of K and J, respectively. One side of the boundary is ﬁxed w(R) = y(Θ0),
but the other side w(0) is free, which gives rise to the natural boundary condition

(5.2)
which yields m(R) = −f (y0)e−R for y0 := y(0) = w(0). After multiplication with
eRΦ(cid:48)(w)2, equation (5.1) simpliﬁes to

erΦ(w)(cid:0)f(cid:48)(w)Φ(cid:48)(w) − f (w)Φ(cid:48)(cid:48)(w)(cid:1) = f (y0)(cid:0)Φ(cid:48)(w)2 − Φ(w)Φ(cid:48)(cid:48)(w)(cid:1) .

0 = Fw(cid:48) + mGw(cid:48)(cid:12)(cid:12)r=0 ,

(5.1)

(5.3)

(5.4)

(5.5)

Proof. By equations (4.9) and (4.10), we have

−(cid:0)Φ(n+1)

(cid:1)2

δ

=(cid:0)Φδ+nβΦ(cid:48)(cid:48)

δ+nβ − (Φ(cid:48)

Φ(n)
δ Φ(n+2)

δ

δ+nβ)2(cid:1) 22n

σ2nβn

n(cid:89)

(δ + kβ)2 ,

k=0

so it suﬃces to prove (Φ(cid:48))2 < Φ(cid:48)(cid:48)Φ for every δ, β, σ > 0 and ˆρ ∈ [−1, 1] in (4.9). This is
ν Hν for every ν < 0. By (4.11) and since Γ(−ν) > 0,
equivalent to showing (H(cid:48)
the function ϕx(t) := e−t2−2xtt−ν−1 is the density of some absolutely continuous ﬁnite
measure µ on [0,∞). For the probability measure ˜P[A] := µ([0,∞))−1µ(A) consider
two independent random variables X, Y ∼ ˜P. By [Kle08, Thm. 6.28], we can exchange
integration and diﬀerentiation, so

ν)2 < H(cid:48)(cid:48)

ν (x)Hν(x) −(cid:0)H(cid:48)

ν(x)(cid:1)2

H(cid:48)(cid:48)

= 4 ˜E[X 2 − XY ].

Symmetry gives 2 ˜E[X 2 − XY ] = ˜E[(X − Y )2] ≥ 0. Since X and Y are independent
with absolutely continuous distribution, Fubini’s theorem yields ˜P[X = Y ] = 0, so
˜E[(X − Y )2] > 0.

This gives a representation of r given y0 and w as

r = log

f (y0)
Φ(w)

+ log

Φ(cid:48)(w)2 − Φ(w)Φ(cid:48)(cid:48)(w)

f(cid:48)(w)Φ(cid:48)(w) − f (w)Φ(cid:48)(cid:48)(w)

,

which we can use to simplify the ODE (5.5) (assuming w(cid:48) (cid:54)= 0 everywhere) to

1

w(cid:48) = − Φ(cid:48)

Φ

f Φ(cid:48)(cid:48)(cid:48) − f(cid:48)(cid:48)Φ(cid:48)
f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48) +

Φ(cid:48)Φ(cid:48)(cid:48) − ΦΦ(cid:48)(cid:48)(cid:48)
(Φ(cid:48))2 − ΦΦ(cid:48)(cid:48) ,

+

(5.6)

(5.7)

reading the right hand side as a function of w(r). With y(θ) = w(ρ(θ)) and r := ρ(θ),
we get y(cid:48)(θ) = w(cid:48)(r)ρ(cid:48)(θ) = w(cid:48)(r)(1 − y(cid:48)(θ))Φ(cid:48)(y(θ))/Φ(y(θ)), which simpliﬁes to

(cid:0)(Φ(cid:48))2 − ΦΦ(cid:48)(cid:48)(cid:1)(f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48))

f(cid:48)(cid:48)(ΦΦ(cid:48)(cid:48) − (Φ(cid:48))2) + f(cid:48)(Φ(cid:48)Φ(cid:48)(cid:48) − ΦΦ(cid:48)(cid:48)(cid:48)) + f (Φ(cid:48)Φ(cid:48)(cid:48)(cid:48) − (Φ(cid:48)(cid:48))2)

y(cid:48)(θ) =

=

=

Φ(cid:48)(y)

Φ(cid:48)(y) + Φ(y)/w(cid:48)(r)
1
Φ
M2(y(θ))
M(cid:48)
1(y(θ))

(5.8)

(5.9)

(5.10)

where

M1 =

f Φ(cid:48) − f(cid:48)Φ
(Φ(cid:48))2 − ΦΦ(cid:48)(cid:48)

f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48)
(Φ(cid:48))2 − ΦΦ(cid:48)(cid:48) .
By (5.3) and Lemma 5.1 we have M2(y(θ)) > 0 for any θ. We get M(cid:48)
Lemma 5.2. Assume f ∈ C 2(R) satisﬁes Assumption C2, i.e. f, f(cid:48) > 0 with
(f(cid:48)/f )(cid:48) < (Φ(cid:48)/Φ)(cid:48). Then M(cid:48)

1(y) < 0 for all y ∈ R.

1(y(θ)) < 0 by

M2 =

(5.11)

and

14

Proof. Let G := Φ(cid:48)/Φ and H := Φ(cid:48)(cid:48)/Φ(cid:48). By Lemma 5.1, we have G, G(cid:48), H, H(cid:48) > 0 and
G < H. With λ(y) = f(cid:48)(y)/f (y) > 0, so f(cid:48)(cid:48)/f = λ(cid:48) + λ2 and we get
1/f = λ(cid:48)G(cid:48) + (λ2 − λH)G(cid:48) + (G2 − λG)H(cid:48).

(G(cid:48))2ΦM(cid:48)

1(y) < 0 if and only if λ(cid:48)(y)G(cid:48)(y) < q(λ(y)) where q(λ) := (H−λ)λG(cid:48)+(λ−G)GH(cid:48).

So M(cid:48)
The function q is quadratic in λ and takes its minimum in

λ∗ :=

HG(cid:48) + GH(cid:48)

2G(cid:48)

with value

q(λ∗) =

(HG(cid:48) + GH(cid:48))2

4G(cid:48)

− G2H(cid:48).

Note also, that G(cid:48) = (H − G)G. Noting that λ(cid:48)(y) < G(cid:48)(y) for all y ∈ R, we ﬁnd

4G(cid:48) (λ(cid:48)G(cid:48) − q(λ)) ≤ 4G(cid:48) (λ(cid:48)G(cid:48) − q(λ∗)) < 4G(cid:48)(cid:0)(G(cid:48))2 − q(λ∗)(cid:1)

= 4(G(cid:48))3 − (GH(cid:48) + G(cid:48)H)2 + 4G(cid:48)G2H(cid:48)

= G2(cid:0)4G(H − G)3 − (H(cid:48) + (H − G)H)2 + 4(H − G)GH(cid:48)(cid:1)
= −G2(cid:0)H(cid:48) + H 2 + 2G2 − 3GH(cid:1)2

< 0.

1(y) < 0 for all y ∈ R.

So M(cid:48)
Lemma 5.3. Let f ∈ C 2(R) satisfy Assumptions C2 and C3, that is f, f(cid:48) > 0,
(f(cid:48)/f )(cid:48) < (Φ(cid:48)/Φ)(cid:48) and (f(cid:48)/f )(cid:48) < (Φ(cid:48)(cid:48)/Φ(cid:48))(cid:48). Then the solution θ (cid:55)→ y(θ), θ ∈ [0,∞), of
the ODE

y(cid:48) = M2(y)/M(cid:48)

1(y),

y(0) = y0,

(5.12)

is strictly decreasing with values in (y∞, y0] with y0 and y∞ from Assumption C7.
Proof. Since M2(y(θ)) > 0 and M(cid:48)
1 < 0 by Lemma 5.2, it is y(cid:48)(θ) < 0. The equation for
y0 is already derived in (5.4). Uniqueness of y0 is guaranteed by λ(cid:48) < G(cid:48). Since M2/M(cid:48)
is locally Lipschitz, the maximal solution θ (cid:55)→ y(θ) is unique and deﬁned on θ ∈ [0,∞)
with lower co-domain bound y∞ := limθ→∞ y(θ) satisfying limθ→∞ y(cid:48)(θ) = 0. In the
latter case, M2(y∞) = 0 which reduces to f(cid:48)(y∞)Φ(cid:48)(y∞) = f (y∞)Φ(cid:48)(cid:48)(y∞).

1

By considering the ﬁrst variation δ(J + mK), we found a candidate boundary y
by means of a possible extremum w : [0, R] → R of J + mK. Calculating the second
variation δ2(J + mK) at w, we ﬁnd that w is indeed a local maximizer.

For a C 1-perturbation h : [0, R] → R of w with h(0) = h(R) = 0 we have

δ2(J + mK)[w; h] =

(cid:90) R

0

(cid:0)P h(cid:48)(r)2 + Qh(r)2(cid:1) dr

with P = P (r, w(r), w(cid:48)(r)) and Q = Q(r, w(r), w(cid:48)(r)) given by

(cid:0)Fw(cid:48)w(cid:48) + mGw(cid:48)w(cid:48)(cid:1) = 0,
(cid:16)
(cid:16)
Φ(cid:48) + 2f(cid:48) ·(cid:16) Φ

Fww + mGww − d
dr
e−(R−r)

f(cid:48)(cid:48) Φ

(cid:18)

Φ(cid:48)

Fww(cid:48) + mGww(cid:48)

(cid:17)(cid:17)
(cid:17)(cid:48)(cid:48) − f(cid:48)(cid:19)
+ f ·(cid:16) Φ

Φ(cid:48)

(cid:17)(cid:48)

Q =

P = 1
2
1
2
1
2

=

m ·(cid:16) Φ

Φ(cid:48)

(cid:17)(cid:48)(cid:48)

,

+

1
2

(5.13)

(5.14)

(5.15)

(5.16)

15

with f , Φ and their derivatives being evaluated at w(r) when no argument is mentioned.
The d/dr-diﬀerentiation of (5.1) yields

(cid:18)

Φ(cid:48)

+ m

f(cid:48) · Φ

(cid:19)
(cid:17)(cid:48) − f
Φ(cid:48) + f ·(cid:16) Φ
(cid:19)
(cid:17)(cid:48) − f
Φ(cid:48) + f ·(cid:16) Φ
(cid:18)
(cid:17)(cid:48)
Φ(cid:48) + 2f(cid:48) ·(cid:16) Φ
+ f ·(cid:16) Φ
(cid:19)
Φ(cid:48) + f ·(cid:16) Φ
(cid:17)(cid:48) − f
(cid:0)f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48)(cid:1) + 2Qw(cid:48) .

Φ(cid:48)
+ 2Qw(cid:48)

f(cid:48)(cid:48) Φ

Φ(cid:48)

Φ(cid:48)

Φ(cid:48)

(cid:18)

(cid:18)

0 =

d
dr

e−(R−r)

= e−(R−r)

f(cid:48) · Φ

+ e−(R−r)

= e−(R−r)

f(cid:48) · Φ

= e−(R−r) Φ
(Φ(cid:48))2

Φ(cid:48)

d
dr

(cid:17)(cid:48)
(cid:16) Φ
(cid:17)(cid:48)(cid:48) − f(cid:48)(cid:19)

w(cid:48) + m ·(cid:16) Φ

Φ(cid:48)

(cid:17)(cid:48)(cid:48)

w(cid:48)

(5.17)

(cid:90) R

(cid:90) R

By equation (5.3) and Lemma 5.1, the ﬁrst summand in (5.17) is negative along w(r).
Since w(r) = y(ρ−1(r)) and ρ−1 is strictly increasing, we have w(cid:48) < 0 by Lemma 5.3. So
it must hold Q(r, w(r), w(cid:48)(r)) < −κ < 0 on [0, R] by (5.17) for some constant κ = κR,
which gives that the second variation is negative deﬁnite at w,

δ2(J + mK)[w; h] =

Q(r, w(r), w(cid:48)(r))h(r)2 dr < −κ

h(r)2 dr < 0 ,

(5.18)

0

0

for h (cid:54)≡ 0. Hence we get the following
Lemma 5.4. The functional ˆJ := J + mK : C 1([0, R]) → R deﬁned by (4.15) – (4.16)
with m = −f (y0)e−R has a strict local maximizer w(r) = y(ρ−1(r)) given by (5.12) in
the following sense. There exists ε > 0 such that for all perturbations 0 (cid:54)≡ h ∈ C 1([0, R])
with h(0) = h(R) = 0 and (cid:107)h(cid:107)W 1,∞ = (cid:107)h(cid:107)∞ ∨ (cid:107)h(cid:48)(cid:107)∞ < ε it holds

ˆJ(w + h) < ˆJ(w).

Proof. To shorten notation, let ˆF := F + mG so ˆJ :=(cid:82) R
variation δ ˆJ[w; h] = 0 by (5.1), second variation δ2 ˆJ[w; h] =(cid:82) R
(cid:19)
∂α ˆF(cid:0)r, w + ξrh(cid:1) hα

ˆF dr. Unless the arguments
are explicitly written, take ˆF = ˆF (r, w(r), w(cid:48)(r)). Note that ˆF is linear in w(cid:48), so
Taylor’s theorem gives ˆJ(w + h) − ˆJ(w) = δ ˆJ[w; h] + δ2 ˆJ[w; h] + E(h) with ﬁrst
0 Qh2 dr < 0 by (5.18)

(cid:18)(cid:88)

and remainder

(cid:90) R

E(h) =

dr

0

0

|α|=3

α!

for some ξr ∈ [0, 1], with w = (w(r), w(cid:48)(r))(cid:62), h = (h(r), h(cid:48)(r))(cid:62) and multi-index
α ∈ N2

(cid:90) R
(cid:90) R
0, considering ˆF (r,·) as an function on R2. Since ˆF is linear in w(cid:48) we get
(cid:16) 1

ˆFwww(cid:48)(r, w + ξrh) · h(cid:48)(cid:17)

ˆFwww(r, w + ξrh) · h +

A · h2 dr

E(h) =

h2 dr =:

1
2

6

0

0

16

Note that by compactness of [0, R] it is A → 0 uniformly as (cid:107)h(cid:107)W 1,∞ → 0. Now choose
ε > 0 small enough such that |A| < κ/2 for all (cid:107)h(cid:107)W 1,∞ < ε where −κ < 0 is an upper
bound of Q. Hence with h (cid:54)≡ 0,

ˆJ(w + h) − ˆJ(w) =

(Q + A)h2 dr < − κ
2

h2 dr < 0 .

Note that the deﬁnition w(r) := y(ρ−1(r)) does not depend on the interval boundary
R. Hence the optimizer w over [0, R] from Lemma 5.4 is optimal for all R > 0. We can
calculate the value J(w) of our optimizer explicitly.

Lemma 5.5. For the optimal w from Lemma 5.4 we have

(cid:90) R

0

(cid:90) R

0

J(w) = (ΦM1)(y(Θ0)) = (ΦM1)(w(R))

Proof. By direct calculation we have f M(cid:48)
er = f (y0)/(ΦM2)(w(r)). Substituting r := ρ((cid:96)) to (4.13) and y(cid:48) = (M2/M(cid:48)

. Moreover, (5.3) gives
1)(y) yields

1
ΦM 2
2

(cid:1)(cid:48)
= (cid:0) f Φ(cid:48)−f(cid:48)Φ
(cid:90) Θ0
(cid:16) f

f(cid:48)Φ(cid:48)−f Φ(cid:48)(cid:48)

0

ΦM2

(x) dx = (ΦM2)(y(Θ0))

(cid:17)
(cid:104) f Φ(cid:48) − f(cid:48)Φ

(y((cid:96))) d(cid:96)

f(cid:48)Φ(cid:48) − f Φ(cid:48)(cid:48)

(cid:105)y(Θ0)

y0

J(w) = e−ρ(Θ0)

f (y((cid:96)))eρ((cid:96)) d(cid:96) = (ΦM2)(y(Θ0))

(cid:90) y(Θ0)

(cid:17)

(cid:16) f M(cid:48)

1
ΦM 2
2

0

= (ΦM2)(y(Θ0))

= (ΦM1)(y(Θ0)).

y0

(cid:90) Θ0

To translate the results obtained so far back to the state space of impact and asset

position, let us make the
Deﬁnition (˜y-reﬂected strategy). For a boundary function ˜y : [0,∞) → R with ˜y(cid:48) ≤ 0
and initial assets Θ0 ≥ 0, denote by Areﬂ(˜y) the selling strategy for which the shifted
impact process X starting at ˜y(Θ0) is continuous and reﬂected at ˜y until all the
shares are sold. More precisely, A = Areﬂ(˜y) is such that the (unique) pair (X, A) of
continuous adapted processes with non-decreasing A solves (4.4)–(4.5) for boundary
g(·) := ˜y(Θ − ·) deﬁned on [0, Θ0], until the liquidation time τ = inf{t > 0 | At ≥ Θ0}.
Now we can formulate and prove the following result that will be crucial for our

analysis in the veriﬁcation argument in Section 6.
Theorem 5.6. The function y : [0,∞) → R deﬁned by equation (5.12) and y0 is a
(one-sided) local maximizer of E[L∞(y) | Θ0] in the sense that for every θ > 0 there
exists some ε > 0 such that for any decreasing ˜y : [0,∞) → R with y(·) ≤ ˜y(·) ≤ y0,
y = ˜y on [θ,∞) and 0 < (cid:107)y − ˜y(cid:107)W 1,∞ < ε it holds

E[L∞(y) | Θ0 = θ] > E[L∞(˜y) | Θ0 = θ].

Proof. For sake of clarity, we write J = JR and K = KR to emphasize the depen-
dence of the functionals J, K on R. Call w(r) the parametrization of y and ˜w(r) the
parametrization of ˜y.

17

0

Φ(˜y(x)) dx +(cid:82) ˜y(0)

Φ(cid:48)(˜y(x))

˜y(θ)

So R := ρy(θ), ˆR := ρ˜y(θ) =(cid:82) θ

Φ(cid:48)(u)
Φ(u) du and ˆθ := ρ−1

Fix θ > 0 and choose R, ˆR, ˆθ such that y(θ) = w(R), ˜y(θ) = ˜w( ˆR) and w( ˆR) = y(ˆθ).
y ( ˆR). By y (cid:54)≡ ˜y,
y(·) ≤ ˜y(·) with equality outside (0, θ) and monotonicity of Φ(cid:48)/Φ, we have ˆR > R and
thus ˆθ > θ.
So if (cid:107)w − ˜w(cid:107)W 1,∞ is small enough, by Lemma 5.4 we get
JR(w) = (ΦM1)(w(R)) − (ΦM1)(w( ˆR)) + J ˆR(w)

Now, K ˆR(w) = ˆθ and K ˆR( ˜w) = θ. Moreover, Jr(w) = (ΦM1)(w(r)) by Lemma 5.5.

= (ΦM1)(w(R)) − (ΦM1)(w( ˆR)) + e− ˆRf (y0)ˆθ +(cid:0)J ˆR − e− ˆRf (y0)K ˆR
> (ΦM1)(w(R)) − (ΦM1)(w( ˆR)) + e− ˆRf (y0)ˆθ +(cid:0)J ˆR − e− ˆRf (y0)K ˆR

(cid:1)(w)
(cid:1)( ˜w)

= (ΦM1)(y(ˆθ − η)) − (ΦM1)(y(ˆθ)) + e− ˆRf (y0)η + J ˆR( ˜w) =: g(η) + J ˆR( ˜w) .
where η := ˆθ − θ > 0. By (5.6) we get e− ˆRf (y0) = (ΦM2)(y(ˆθ)). With (5.10) follows

(cid:19)

(cid:18)
(cid:18) Φ(cid:48)M1M2

(ΦM1)(cid:48) M2
M(cid:48)

1

(cid:19)

g(cid:48)(η) = −

= −

(y(ˆθ − η)) + (ΦM2)(y(ˆθ))

M(cid:48)
1)(y(ˆθ)). Since M1 > 0 on (−∞, y0), M2 > 0 on (y∞, y0],
1 < 0 by Lemma 5.2 and Φ(cid:48) > 0 it follows g(cid:48)(0) > 0. So g(η) > 0 for η > 0 small

Hence g(cid:48)(0) = −(Φ(cid:48)M1M2/M(cid:48)
M(cid:48)
enough. Hence it follows

+ ΦM2

1

(y(ˆθ − η)) + (ΦM2)(y(ˆθ))

E[L∞(y) | Θ0 = θ] = JR(w) > J ˆR( ˜w) = E[L∞(˜y) | Θ0 = θ]

The bounds on η and (cid:107)w − ˜w(cid:107)W 1,∞ are satisﬁed for small enough ε > 0, because
(y, (cid:96)) (cid:55)→ ρy((cid:96)) and (y, (cid:96)) (cid:55)→ ρ−1
y ((cid:96)) are continuous in W 1,∞ × R, so (cid:107)w − ˜w(cid:107)W 1,∞ → 0,
ˆR → R and ˆθ → θ as ε → 0.

6 Constructing the value function and veriﬁcation

In this section, we construct a candidate for the value function and verify the variational
inequality (3.3) in Lemmas 6.4 and 6.5 relying on results from the previous sections.
This will be suﬃcient to conclude the proof of our main result, Theorem 3.1.
Having deﬁned a candidate boundary between the sell region S and the wait region
W via the ODE (5.12), we will now construct a candidate solution V of the variational
inequality (3.3) that will be the value function of the optimal liquidation problem (up
to the multiplicative factor ¯S0). As a direct consequence of Lemma 5.5, we get the
value along the boundary

Vbdry(θ) := V(cid:0)y(θ), θ(cid:1) = Φ(cid:0)y(θ)(cid:1)M1

(cid:0)y(θ)(cid:1) .

(6.1)
Inside the wait region W, which we assume is to the left of the boundary, we require
2 Vyy + (σ ˆρ − βy)Vy = δV . Note that this is actually GV = δV ,
V = V W to satisfy 1

18

i.e. V W should be an eigenfunction to the eigenvalue δ of the generator G of a diﬀusion
as in Theorem 7.2. Since V should be also monotonically increasing, the only possibility
is that V W (y, θ) = C(θ)Φ(y) for some increasing function C : [0,∞) → [0,∞). Using
the boundary condition V W (y(θ), θ) = Vbdry(θ), with equation (6.1) we then have

(6.2)
for y ≤ y(θ) and θ ≥ 0, where C(θ) := M1(y(θ)). In the sell region, we require for
V = V S to satisfy f = V S

θ . Therefore, we divide S in two parts:

y + V S

V W (y, θ) := Φ(y)C(θ)

S1 := {(y, θ) ∈ R × (0,∞) | y(θ) < y ≤ y0 + θ} ,
S2 := {(y, θ) ∈ R × (0,∞) | y0 + θ < y} .

(6.3)

Let ∆ := ∆(y, θ) ≥ 0 denote the (cid:107)·(cid:107)1-distance of a point (y, θ) ∈ S to the boundary
∂S in direction (−1,−1). This means in S 1 (but not in S2) that

(6.4)
In the following let (y, θ) ∈ S 1 and (yb, θb) := (y − ∆, θ − ∆) ∈ W ∩ S. We ﬁnd
∆y = 1/(1 − y(cid:48)(yb)) = 1 − ∆θ. Inside S 1, we need to have

y(θ − ∆) = y − ∆ .

V S1(y, θ) := V W (y − ∆, θ − ∆) +

f (x) dx ,

(6.5)

(cid:90) y

y−∆

since V S1

y + V

θ = f in S and V S1 (y(θ), θ) = Vbdry(θ) = V W (y(θ), θ). Similarly, in S2,
S1

(cid:90) y

y−θ

V S2(y, θ) :=

f (x) dx.

(6.6)

(6.7)

To wrap up, the candidate value function is deﬁned by:

V = V W on W,

V = V S1 on S 1,

V = V S2 on S 2.

Now we verify that V is a classical solution of the variation inequality equation (3.3)
with the boundary condition V (y, 0) = 0 for all y ∈ R. That V (y, 0) = 0 is clear
because M1(y0) = 0. The rest will be split into several lemmas.
Lemma 6.1 (Smooth pasting). Let (yb, θb) ∈ W ∩ S. Then
Φ(yb)C(cid:48)(θb) + Φ(cid:48)(yb)C(θb) = f (yb) ,
Φ(cid:48)(yb)C(cid:48)(θb) + Φ(cid:48)(cid:48)(yb)C(θb) = f(cid:48)(yb) .

(6.9)
Proof. This follows easily from the fact that C(θb) = M1(yb) and C(cid:48)(θb) = M2(yb),
see the deﬁnition of C and (5.12), together with the deﬁnitions of M1 and M2, see
(5.11). Note that when (yb, θb) = (y0, 0) we take the right derivative of C at 0 and the
equalities still hold true.

(6.8)

19

Remark 6.2. It might be interesting to point out that (6.8) and (6.9) are suﬃcient
to derive the boundary between the sell and the wait regions. Indeed, solving (6.8)
– (6.9) with respect to C(θb) and C(cid:48)(θb), it is easy to see that C(θb) = M1(yb) and
C(cid:48)(θb) = M2(yb). On the other hand, by the chain rule we get θ(cid:48)(yb)C(cid:48)(θb) = M(cid:48)
1(yb)
from where we derive for the boundary θ(·) in the appropriate range

θ(cid:48)(yb) =

M(cid:48)
1
M2

(yb),

which gives the ODE for the boundary in (5.12). To get the initial condition y0, note
that the boundary condition V (·, 0) ≡ 0 gives C(0) = 0, i.e. M1(y0) = 0, exactly as
in Lemma 5.3. Hence, one could guess the candidate boundary y(·) if one assumes
suﬃcient smoothness of the function V along the boundary. This is similar to the usual
approach in the singular stochastic control literature, cf. [KS86, Section 6]. The reason
why we chose the seemingly longer derivation via calculus of variation techniques is the
local (one-sided) optimality that we derived in Theorem 5.6 and this will be crucial in
our veriﬁcation of the inequalities of the candidate value function in the sell region,
see Lemma 6.5 below. A more direct approach based on direct veriﬁcation leads to, to
the best of our knowledge, new unproved properties of quotients of parabolic cylinder
functions that might be of independent interest, see Remark 6.6.

A simpliﬁed proof of the regularity of V , stated next, is due to the smooth pasting
property. Moreover, the growth condition of V will be needed to justify later why the
stochastic integrals in (3.2) are true martingales by application of Lemma 3.2.
Lemma 6.3. The function V is C 2,1(R× [0,∞)). Moreover, for every Θ0− there exist
constants C1, C2 such that

0 ≤ Vy(y, θ) ,

V (y, θ) ≤ C1 exp(C2y) ∨ 1

∀(y, θ) ∈ R × [0, Θ0−].

Proof. In W, V is already C 2,1 by construction and the fact that C(θ) = M1(y(θ)) is
continuously diﬀerentiable since y(·) and M1(·) are so.
For (y, θ) ∈ S1, set (yb, θb) := (y − ∆(y, θ), θ − ∆(y, θ)) and ∆ := ∆(y, θ). We have

by (6.5) for the ﬁrst and (6.8) for the second equality

y = Φ(cid:48)(yb)C(θb) (1 − ∆y) + Φ(yb)C(cid:48)(θb) (−∆y) + f (y) − f (yb) (1 − ∆y)
V S1

= Φ(cid:48)(y − ∆)C(θ − ∆) + f (y) − f (y − ∆),

(6.10)

Since f , ∆, C and Φ are continuously diﬀerentiable, Vy will also be so. Hence by (6.9),

yy = Φ(cid:48)(cid:48)(yb)C(θb) (1 − ∆y) + Φ(cid:48)(yb)C(cid:48)(θb) (−∆y) + f(cid:48)(y) − f(cid:48)(yb) (1 − ∆y)
V S1

(6.11)

(6.12)

= V W

yy (yb, θb) + f(cid:48)(y) − f(cid:48)(yb),

which is continuous. On the other hand, by (6.5) and (6.9)

V

θ (y, θ) = Φ(cid:48)(yb)C(θb)(−∆θ) + Φ(yb)C(cid:48)(θb)(1 − ∆θ) − f (yb)(−∆θ)
S1

= Φ(yb)C(cid:48)(θb),

20

which is continuous. For (y, θ) ∈ W ∩ S on the boundary, the left derivative w.r.t. y is

V (y, θ) − V (y − x, θ)

x

lim
x(cid:38)0

= Φ(y)C(θ),

y = f (y)− f (y − θ), V S2

θ = f (y − θ), which are all continuous.
S2

while the right derive is again given by (6.10) and is equal to the left derivative
since ∆(y, θ) = 0 in this case. Hence, V is continuously diﬀerentiable w.r.t. y on the
boundary with derivative Vy(y, θ) = Φ(cid:48)(y)C(θ). Similarly, the left derivative of Vy on
the boundary is Φ(cid:48)(cid:48)(y)C(θ) and equal to the right derivative which is given by (6.11)
with y = yb. Similarly, the left derivative of V w.r.t. θ on the boundary is equal to the
right derivative (given by (6.12)). Therefore, V is C 2,1 inside W ∪ S1.
For (y, θ) ∈ S2, we have by (6.6) that V S2
yy = f(cid:48)(y)− f(cid:48)(y − θ)
and V
On the boundary between S1 and S2, the left derivative of V w.r.t. y is given by
(6.10) while the right derivative is f (y) − f (y0). Since θ − ∆ = 0 in this case and
C(0) = 0, they are equal and hence V is continuously diﬀerentiable w.r.t. y there.
Similarly for Vyy there. The left derivative of V w.r.t. θ there is given by (6.12) with
(yb, θb) = (y0, 0). The right derivative w.r.t. θ is f (y − θ) = f (y0). They are equal by
(6.9) and C(0) = 0. Therefore, V is C 2,1 on S 1 ∪ S2.
It remains to check smoothness on the boundary {(y, 0) | y ∈ R}. The derivatives
w.r.t. y there are 0. V is continuously diﬀerentiable w.r.t. θ in this case because y(·),
C, and ∆ are continuously diﬀerentiable w.r.t. θ also at θ = 0 (we consider the right
derivatives there).
In the wait re-
gion, which is contained in (−∞, y0] × [0,∞), we have V (y, θ) = C(θ)Φ(y) and
Vy(y, θ) = C(θ)Φ(cid:48)(y). Since Φ, Φ(cid:48) are strictly increasing in y (see (4.9) and the
properties after it), V and Vy will be bounded by a constant there. Now, in the
sell region we have f − Vy − Vθ = 0. However, Vθ > 0 because in S1 (6.12) holds
and C(cid:48)(θb) = M2(y(θb)) > 0, while in S2 we have that Vθ(y, θ) = f (y − θ) > 0.
Similarly, Vy > 0 in the sell region. Therefore, 0 < Vy(y, θ) < f (y) ≤ exp(λ∞y) by
Assumption C4, and hence also the exponential bound on V .

To conclude the proof, the growth condition follows as follows.

Next we prove that V satisﬁes the variational inequality (3.3). To this end, consider

Lemma 6.4. The function V W : W → [0,∞) from (6.2) satisﬁes

LV W (y, θ) = 0 and

f (y) < V W

θ (y, θ) for y < y(θ).

Proof. We have V W
by (5.10). Recall that at y = y(θ) we have by (6.8) the equality V W
Now consider y < y(θ). By Lemma 5.2, we then have M1(y) > M1(y(θ)) giving

1(y(θ))y(cid:48)(θ) = Φ(y)M2(y(θ))
θ = f (y(θ)).

y = Φ(cid:48)(y)M1(y(θ)) and V W

y + V W

y (y, θ) + V W
θ = Φ(y)M(cid:48)

(cid:18)

d
dy

21

(cid:17)(cid:48)

(cid:16) f

(cid:16) Φ(cid:48)
Therefore, y (cid:55)→(cid:0)f − V W

(y) >

Φ

(cid:17)(cid:48)

(y)M1(y(θ)) =

Φ
y (y, θ) + V W

M1(y(θ))

θ (y, θ)(cid:1)/Φ(y) is increasing in y. Since at y = y(θ)

+ M2(y(θ))

.

Φ(cid:48)(y)
Φ(y)

(cid:19)

it equals to 0, we get the claimed inequality.

Recall Assumption 2.2 and note that y∞ from Lemma 5.3 is unique by condition C3.

Lemma 6.5. The functions V S1 and V S2 satisfy on S 1 and S2 respectively

LV S1 ≤ 0, LV S2 < 0.

Moreover, the inequality inside S 1 is strict except on the boundary between the wait
region and the sell region (W ∩ S 1) where we have equality.
Proof. First we consider the region S 1. Recall from the proof of Lemma 6.3 (see (6.10)
and (6.11)) that

V S1
y = V W
V S1
yy = V W

y (y − ∆, θ − ∆) + f (y) − f (y − ∆),
yy (yb, θb) + f(cid:48)(y) − f(cid:48)(yb).

Fix (yb, θb) ∈ W ∩ S 1 and consider the perturbation ∆ (cid:55)→ (y, θ) = (yb + ∆, θb + ∆). Set

h(∆) := LV S1(yb + ∆, θb + ∆)

= 1

2 V W
+ 1

yy (yb, θb) − 1
2 f(cid:48)(y) − βyV W

2 f(cid:48)(yb) + σ ˆρV W
y (yb, θb) + βyf (yb) + (σ ˆρ − βy)f (y) − δ

(cid:90) y
y (yb, θb) − σ ˆρf (yb) − δV W (yb, θb)

f (x) dx .

yb

(6.13)

(6.14)

We have h(0) = 0 by Lemma 6.4 and to show h(∆) < 0 for ∆ > 0, it suﬃces to prove
h(cid:48)(∆) < 0 for all ∆ > 0. We have for all ∆ ≥ 0 at y = yb + ∆ that

h(cid:48)(∆) = β(cid:0)f (yb)− V W

(cid:18) 1
y (yb, θb)(cid:1) + f (y)
(cid:124)

2

f(cid:48)(cid:48)(y)
f (y)

− (β + δ) + (σ ˆρ − βy)

(cid:123)(cid:122)

=k(y)

f(cid:48)(y)
f (y)

, (6.15)

(cid:19)
(cid:125)

where at ∆ = 0 we consider the right derivative h(cid:48)(0+). Now we show that k(y) < 0 for
all y ≥ y∞. Recall that Φ is a solution of the ODE 0 = 1
2 Φ(cid:48)(cid:48)(x)+(σ ˆρ−βx)Φ(cid:48)(x)−δΦ(x).
Diﬀerentiating w.r.t. x and dividing by Φ(cid:48)(x) yields

0 =

1
2

Φ(cid:48)(cid:48)(x)2
Φ(cid:48)(x)2 − (β + δ) + (σ ˆρ − βx)

Φ(cid:48)(cid:48)(x)
Φ(cid:48)(x)

1
2

+

(6.16)

(cid:19)(cid:48)

Φ(cid:48)(x)

(cid:18) Φ(cid:48)(cid:48)(x)
(cid:19)(cid:48)
(cid:18) f(cid:48)
(cid:18) f(cid:48)
(cid:19)(cid:48)

f

f

So at the left end y∞ of our boundary, we have

k(y∞) =

=

1
2

1
2

(y∞) +

1
2
(y∞) − 1
2

Φ(cid:48)(cid:48)(y∞)2
(cid:18) Φ(cid:48)(cid:48)
Φ(cid:48)(y∞)2 − (β + δ) + (σ ˆρ − βy∞)

(cid:19)(cid:48)

(y∞) < 0

Φ(cid:48)

Φ(cid:48)(cid:48)(y∞)
Φ(cid:48)(y∞)

(6.17)

by Assumption C3. With Assumption C6 we get k(y) < 0 for every y ≥ y∞.
In particular, k(yb + ∆) < 0 for all ∆ ≥ 0. Since f is positive and increasing,
the product ∆ (cid:55)→ (f k)(yb + ∆) is decreasing. Therefore, proving h(cid:48)(0+) ≤ 0 is

22

θb

Assume h(cid:48)

suﬃcient to show the inequality in S1. To stress the dependence of h on the point
(yb, θb) = (y(θb), θb), we also write h(∆) = hθb (∆). Note that hθ(∆) is continuous in θ
and ∆ on [0,∞) × [0,∞).
(0+) > 0 at some boundary point (yb, θb) with θb > 0. By continuity of
h(cid:48) on θ and ∆ there exists some ε > 0 such that LV S1 > 0 on U := S 1 ∩ Bε(yb, θb).
This will lead to a contradiction to the fact that the candidate boundary is a (one-sided)
strict local maximizer of our stochastic optimization problem with strategies described
by the local times of reﬂected diﬀusions, see Theorem 5.6.
Indeed, ﬁx Θ0 > θb + ε and consider a perturbation ˜y(·) ∈ C 1 of the boundary y(·)
which satisﬁes the conditions of Theorem 5.6 as well as y(θ) < ˜y(θ) ≤ y0 in (˜y(θ), θ) ∈ U
and such that ˜y and y coincide outside of U . For the corresponding reﬂection strategies
˜A := Areﬂ(˜y) and A := Areﬂ(y) denote by ˜Θt := Θ0 − ˜At and Θt := Θ0 − At their asset
position processes. The liquidation times of ˜A and A are ˜τ := inf{t ≥ 0 | ˜At = Θ0} and
τ := inf{t ≥ 0 | At = Θ0}, respectively. By Theorem 7.2, we have T := ˜τ ∨ τ < ∞ a.s.
Fix initial impact Y ˜A
0− = y(Θ0). To compare the strategies A and ˜A, consider
the processes G(y(Θ0), A) and G(y(Θ0), ˜A) for our candidate value function (which is
C 2,1 by Lemma 6.3). Since V (·, 0) = 0, it holds LT ( ˜A) = GT ( ˜A) and LT (A) = GT (A).
However, since (Y ˜A, ˜Θ) spends a positive amount of time in the {LV > 0} region until
time T and always remains in the region {LV ≥ 0}, the perturbed strategy ˜A generates
larger proceeds (in expectation) than A.

0− = Y A

Indeed, by (3.2) for G( ˜A) and G(A), using monotone convergence and Lemma 3.2

for the stochastic integrals (noting growth condition from Lemma 6.3) we get
E[L∞( ˜A) − L∞(A)] = lim

(cid:104)(cid:90) n∧T
n→∞ E[Gn∧T ( ˜A) − Gn∧T (A)]

(cid:90) n∧T

. . . dWt −

. . . dBt +

(cid:90) n∧T

0

LV (Y ˜A

t , ˜Θt) dt

0

> 0 .

0

(cid:105)

= lim

n→∞ E

(cid:104)(cid:90) T

= E

0

LV (Y ˜A

t , ˜Θt) dt

(cid:105)

(6.18)

(6.19)

(6.20)

This is a contradiction to Theorem 5.6, so it must hold h(cid:48)(0+) ≤ 0 and hence the
inequality in S1. It remains to consider (y, θ) ∈ S 2. Note that V S2
y = f (y) − f (y − θ)
yy = f(cid:48)(y) − f(cid:48)(y − θ). Fix y − θ =: a ≥ y0 and consider LV S2 as a function of
and V S2
θ. We have

(cid:0)f(cid:48)(a+θ)−f(cid:48)(a)(cid:1)+(cid:0)σ ˆρ−β(a+θ)(cid:1)(cid:0)f (a+θ)−f (a)(cid:1)−δ

f (x) dx.

LV S2(y, θ) =

1
2

(cid:90) a+θ

a

Diﬀerentiating the right-hand side w.r.t. θ we get the expression f (a + θ)k(a + θ),
which is again decreasing in θ because a ≥ y0. Since at θ = 0 we have LV S2 (y, θ) = 0
we deduce the desired inequality.
Remark 6.6 (Conjecture on properties of special functions). In the case when λ(·) is
the constant function, a more direct approach based on direct calculations leads to a
conjectured property about quotients of Hermite functions. More precisely, to prove

23

h(cid:48)(0+) ≤ 0 in this case it turns out to be suﬃcient to verify that the map yb (cid:55)→ h(cid:48)(0)
is monotone in [y∞, y0] because at y∞ and y0 one can check that h(cid:48)(0+) < 0. The
monotonicity in yb would then follow from the following conjectured property of the
Hermite functions:

For every ν < 0, the function

x (cid:55)→ (Hν−1(x))2
Hν(x)Hν−2(x)

is decreasing.

Numerical computations indicate the validity of the this property but, to our best
knowledge, it is not yet proven and may be of independent interest. Note that such
quotients of special functions are related to so called Turan-type inequalities, cf. [BI13].

Now we have all the ingredients in place to proceed with the

Proof of Theorem 3.1. The function V constructed in (6.7) is a classical solution
of the variational inequality (3.3) because of Lemmas 6.3, 6.4 and 6.5. Thus, for
each admissible strategy A the process G(y; A) from (3.1) is a supermartingale with
G0(y; A) ≤ G0−(y; A): the growth condition on Vy and V from Lemma 6.3 guarantee
that the stochastic integral processes in (3.2) are true martingales by an application
of Lemma 3.2, while the variational inequality give the supermatingale property on
[0−,∞). Moreover, for the described strategy A∗ the process G(y; A∗) is a true martin-
gale with G0(y; A) = G0−(y; A) by our construction of the boundary and the validity
of the variational inequality in the respective regions. Any other strategy will be
suboptimal because the respective inequalities are strict in the sell and wait region, i.e.,
for any other strategy the process G will not be martingale.

The Laplace transform formula will be derived in Theorem 7.2 for a y-reﬂected
strategy when the state process starts on the boundary. In the case when the state
process starts in the wait region, note that the ﬁrst excursion to the boundary is
independent from the future and its Laplace transform is given by equation (7.8), hence
the factor in the formula.

7 SDEs with reﬂection at an elastic boundary

In Section 4, we need the Laplace transform of the inverse local time of a reﬂected
Ornstein-Uhlenbeck process at some local-time-dependent boundary. The analysis in
this section appears interesting in its own. We present it in a self-contained way so it
can be read independently from the other sections.

The classical Skorokhod problem is that of reﬂecting a path at a boundary. It is the
standard tool for constructing solutions to SDEs with reﬂecting boundary conditions,
where the boundary remains constant over time. The most basic example is a Brownian
motion with values in [0,∞) and reﬂection at zero, solved in [Sko61]. Starting with
[Tan79], well known generalizations concern diﬀusions in multiple dimensions with
normal or oblique reﬂection at the boundary of some given (time-invariant) domain in
the Euclidian space of certain smoothness or other kinds of regularity, cf. [LS84, DI93].
Other generalizations admit for an a-priori given but time-dependent boundary, cf.
[EKK91, N ¨O10]. In the present section we restrict ourselves to a one-dimensional

24

(a) X against real time t.

(b) X against local time L.

√

Figure 1: Brownian Motion X (blue) reﬂected at the moving boundary

L (purple)

against diﬀerent clocks, where L is the local time of X at that boundary.

setting but with a local-time-dependent boundary, as we need it in Section 4, with the
interpretation that the boundary interacts with the diﬀusion, cf. Fig. 1a. Taking local
time L at the boundary as a second coordinate, this can be seen as a special case of a
degenerate diﬀusion (X, L) in R2 with oblique reﬂection at a smooth boundary, see
Fig. 1b. The main result (Theorem 7.2) is an explicit construction of (X, L) through
approximations of reﬂections by small jumps and the explicit formula (7.12) for the
Laplace transform of the inverse local time.
Brownian motion W and a ﬁltration (Ft) satisfying the usual conditions of right-
continuity and completeness. Let X be a continuous regular recurrent R-valued
diﬀusion, which is reﬂected at an elastic boundary. This means the boundary moves
back whenever it is hit by the diﬀusion. More precisely,

Consider a ﬁltered probability space(cid:0)Ω,F, (Ft)t≥0, P(cid:1) with a one-dimensional (Ft)-

dXt = b(Xt) dt + σ(Xt) dWt − dLt ,

X0 = g(0)

(7.1)

for Lipschitz-continuous functions σ > 0 and b. The process L is called local time of X
at the (time-dependent) boundary g(L) described by a non-decreasing, diﬀerentiable
function g ∈ C 1([0,∞)). So L is a continuous, non-decreasing process satisfying

dLt = 1{Xt=g(Lt)} dLt ,

L0 = 0 ,

Xt ≤ g(Lt) ∀t ≥ 0.

We are particularly interested in the inverse local time
τ(cid:96) := inf{t > 0 | Lt > (cid:96)}.

(7.2)

(7.3)

Let H y denote the ﬁrst hitting time of a point y by some (b, σ)-diﬀusion. We write
H x → z for the hitting time when the diﬀusion starts in x. Note that P[H x → y < ∞] = 1
for all x, y by our assumption on the diﬀusion being regular and recurrent.

25

20406080100t-10-55X51015202530L-10-505X(cid:88)

(cid:40)
t ) dWt − dLε
t ,

with ∆Lε

t :=

ε
0

dX ε

t = b(X ε

t ) dt + σ(X ε

∆Lε
s

Lε
t :=
(cid:96) := inf{t > 0 | Lε
τ ε

0≤s≤t

t > (cid:96)}.

t− = g(Lε

if X ε
otherwise,

t−),

X ε

0− := g(0) ,

(7.4)

Lε

0− := 0 ,

(7.5)

(7.6)
0 = g(0)−ε

Figure 2: Approximation X ε for ε = 10

7.1 Approximation

We construct solutions to (7.1)–(7.2) and derive explicit representation (7.12) of the
Laplace transform of the inverse local time at boundary g by approximating reﬂection
by jumps in the system of SDEs below. As soon as our process hits the boundary, we
let it retract by a jump of size ε > 0.

0 = ε away from X ε

Since the target reﬂected diﬀusion X starts at the boundary g, we now have X ε
after an initial jump ∆Lε
Lemma 7.1. Let b and σ be Lipschitz with σ > 0. Let also g ∈ C 1 with g(cid:48) ≥ 0. For
every ε > 0, the above SDE has a unique (up to indistinguishability) strong solution
t )t≥0 on [0,∞), and uniqueness in law holds (for solutions living on diﬀerent
(X ε
ﬁltered probability spaces, with diﬀerent W ).

0− := g(0).

t , Lε

τn−1

Proof. Indeed, one can argue by results [RW87, V.9–11, V.17] for classical diﬀusion
SDEs with Lipschitz coeﬃcients (b, σ) by inductive construction on [[0, τn[[ where
τn := inf{t > τn−1 | X ε
t equals
, (Wτn−1+s)s≥0)u−τn−1
Lε
on [[τn−1, τn[[ holds for a suitable functional representation F of strong solutions to
(b, σ)-diﬀusions [RW87, Theorem V.10.4]. Such construction extends to [[0, τ∞[[ for the
monotone limit τ∞ := limn τn.

εn for n ≥ 1, with τ0 := 0. Clearly Lε
+ε, while X ε

for t ∈ [[τn−1, τn[[ and Lε

t− = g(nε)} = τ ε

It suﬃcies to argue that τ∞ = ∞ (a.s.). To this end, let us consider

u = F (X ε

= Lε

τn−1

τn−1

τn

n := inf{t > τn−1 | X ε
τ(cid:48)

t− = g((n − 1)ε)} , n ≥ 1,

26

20406080100t-20-15-10-55Xε= g((n − 1)ε) = X ε

so that τn−1 < τ(cid:48)

change ϕt :=(cid:82) t

(cid:80)∞
n ≤ τn and X ε
τ(cid:48)
n=1 1[[τ(cid:48)
t) dt + σ(X(cid:48)

n

0

0

Tn

t) dW (cid:48)

n,τn[[ dWu.

t = b(X(cid:48)

t =(cid:82) st

→ ∞ for Tn :=(cid:80)n

(τn−1)−. Considering the time
n,τn[[ du with right-continuous inverse st := inf{u | ϕu > t},
, t ≥ 0, is the solution to the diﬀusion
(cid:80)∞
one has (using [RW87, IV.30.10]) that X(cid:48)
t := X ε
st
SDE dX(cid:48)
t , X(cid:48)
0 = g(0), on [[0, ϕ∞[[ for ϕ∞ := supt ϕt, with
respect to the driving Brownian motion W (cid:48)
n=1 1[[τ(cid:48)
To show that {τ∞ < ∞} is a nullset, let g∞ := limn g(nε) ∈ R ∪ {∞}. If g∞ = ∞,
i ) ≤ τn and T∞ = limn Tn ≤ τ∞
i=1(τi − τ(cid:48)
we get from X(cid:48)
= X ε
t = ∞. This implies that P [τ∞ < ∞] = 0, since the Lipschitz diﬀusion
τn
that supt<T∞ X(cid:48)
SDE for X(cid:48) is pathwise exact, i.p. its continuous solution X(cid:48) almost surely remains
bounded on any ﬁnite time interval [[0, T [[ and T∞ ≤ τ∞.
In the case g∞ < ∞ , one can ﬁnd x, y ∈ R with g∞−ε < x < y < g∞. The durations
n := inf{t≥ τn−1 | X ε = x}
n , n ∈ N, for upcrossings of the interval [x, y] between τ x
n−τ x
(cid:80)n
τ y
n := inf{t ≥ τn−1 | X ε = y} are i.i.d., by the strong Markov property of the
and τ y
i=1 exp(−λ(τ y
i − τ x
time-homogeneous diﬀusion. By the law of large numbers, 1
i ))
converges almost surely for n → ∞ to the Laplace transform Ex[exp(−λH y)], λ ≥ 0, of
n
the hitting time H y for y by the (b, σ)-diﬀusion process (started at x). This expectation
is strictly less than 1 for λ > 0, as H y > 0 Px-a.s. for y > x, whereas the limit on the
sequence equals 1 on {τ∞ < ∞}, where limi(τ y

i ) = 0. Hence P [τ∞ < ∞] = 0.

i − τ x

Note that the approximating process X ε is a continuous (b, σ)-diﬀusion on stochastic
(cid:96)− )−ε = g((cid:96)−ε)−ε.

intervals [[τ ε
(cid:96) [[. At jump times we have the equality X ε
(cid:96)− = g(Lε
τ ε
τ ε
Hence the length of an excursion of X ε away from the boundary is

(cid:96)−, τ ε

(cid:96) − τ ε
τ ε

(cid:96)− ∼ H g((cid:96))

under Pg((cid:96)−ε)−ε ,

(7.7)

(cid:96)− d= H g((cid:96)−ε)−ε → g((cid:96)). The Laplace transform of ﬁrst hitting
also denoted as τ ε
times H z of a (b, σ)-diﬀusion starting in x is well-known by e.g. [RW87, Section V.50].
For states x, z ∈ R and λ > 0 we have

(cid:96) − τ ε

E(cid:2)e−λH x → z(cid:3) ≡ Ex

(cid:2)e−λH z(cid:3) =

(cid:40)

Φλ,−(x)/Φλ,−(z)
Φλ,+(x)/Φλ,+(z)

if x < z,
if x > z,

(7.8)

where the functions Φλ,± are uniquely determined up to a constant factor as the
increasing (Φλ,−) respectively decreasing (Φλ,+) positive solutions Φ of the diﬀerential
equation

with generator G := 1
boundary function g to be non-decreasing, only Φλ,− is of interest for our purpose.

GΦ = λΦ
dx of the (b, σ)-diﬀusion. Since we assume the

dx2 + b(x) d

2 σ(x)2 d2

By independence of Brownian increments over disjoint time intervals, the Laplace
transform of the inverse local time can be calculated as a sum of excursion lengths at

27

= exp

for (cid:96) ≥ 0 and λ > 0. With hn(ξ) := Φλ,−(cid:0)g((cid:96)n − ξ) − ξ(cid:1), each summand in (7.9) equals

n=1

(7.9)

log

,

local times (cid:96)n := εn as

E(cid:2)exp(cid:0)−λτ ε

(cid:96)

−λ

exp

(cid:18)

(cid:20)
(cid:1)(cid:3) = E
(cid:98)(cid:96)/ε(cid:99)(cid:89)
(cid:32)(cid:98)(cid:96)/ε(cid:99)(cid:88)

n=1

=

Eg((cid:96)n−ε)−ε

log hn(ε) − log hn(0) =

Therefore, we obtain

E(cid:2)exp(cid:0)−λτ ε

(cid:96)

(cid:18)
(cid:1)(cid:3) = exp

−

(cid:90) ε(cid:98)(cid:96)/ε(cid:99)

0

E

exp

(cid:96)n−(cid:1)(cid:17)(cid:105)
(cid:16)−λ(cid:0)τ ε
(cid:104)
Φλ,−(cid:0)g((cid:96)n − ε) − ε(cid:1)
Φλ,−(cid:0)g((cid:96)n)(cid:1)

− τ ε

(cid:96)n

(cid:96)n

=

n=1

n=1

n=1

− τ ε

(cid:96)n−(cid:1)(cid:19)(cid:21)
(cid:98)(cid:96)/ε(cid:99)(cid:88)
(cid:98)(cid:96)/ε(cid:99)(cid:89)
(cid:0)τ ε
(cid:98)(cid:96)/ε(cid:99)(cid:89)
(cid:2)exp(cid:0)−λH g((cid:96)n)(cid:1)(cid:3) =
(cid:19)(cid:33)
(cid:18) Φλ,−(cid:0)g((cid:96)n − ε) − ε(cid:1)
Φλ,−(cid:0)g((cid:96)n)(cid:1)
(cid:90) ε
(cid:90) ε
(cid:0)g(cid:48)((cid:96)n − ξ) + 1(cid:1) Φ(cid:48)
(cid:90) (cid:96)n
(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)
(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)

h(cid:48)
n(ξ)
hn(ξ)

λ,−

λ,−

(cid:96)n−1

dξ

0

0

= −

= −

λ,−

(cid:0)g((cid:96)n − ξ) − ξ(cid:1)
Φλ,−(cid:0)g((cid:96)n − ξ) − ξ(cid:1) dξ
(cid:0)g(a) + a − (cid:96)n
(cid:1)
(cid:1) da .
Φλ,−(cid:0)g(a) + a − (cid:96)n
(cid:0)g(a) + a − ε(cid:100)a/ε(cid:101)(cid:1)
Φλ,−(cid:0)g(a) + a − ε(cid:100)a/ε(cid:101)(cid:1) da

(cid:19)

(7.10)

.

(7.11)

This suggests the following
Theorem 7.2. Let g : [0,∞) → R be a non-decreasing, continuously diﬀerentiable
function, W be a one-dimensional Brownian motion and b : R → R and σ : R → (0,∞)
be Lipschitz-continuous functions.
with non-decreasing L, that solve on [0,∞) the SDE

Then there exists a pair (X, L) of continuous adapted processes, starting in (g(0), 0),

Xt ≤ g(Lt) ,
dXt = b(Xt) dt + σ(Xt) dWt − dLt ,
dLt = 1{Xt=g(Lt)} dLt .

That is, X is a (b, σ)-diﬀusion, but reﬂected at the boundary g(L) and L is its local
time at that boundary. Moreover, the pair (X, L) is the unique weak limit (as ε → 0)
of (X ε, Lε) from (7.4)–(7.5) obtained by approximating reﬂections by jumps of size ε.
Further, the inverse local time τ(cid:96) := inf{t > 0 | Lt > (cid:96)} has the Laplace transform

(cid:18)
E(cid:2)e−λτ(cid:96)(cid:3) = exp

−

(cid:90) (cid:96)

(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)

(cid:0)g(a)(cid:1)
Φλ,−(cid:0)g(a)(cid:1) da

λ,−

(cid:19)

,

(7.12)

0

28

for λ > 0, (cid:96) ≥ 0 and where Φλ,− is the (up to a constant) unique positive increasing
solution of the diﬀerential equation GΦ = λΦ, where G is the generator of the (b, σ)-
diﬀusion.

Proof. Existence and uniqueness of (X, L) is shown in Lemma 7.11 below. Using
dominated convergence for the right-hand side of equation (7.11), we ﬁnd

E(cid:2)e−λτ ε

(cid:18)
(cid:96)(cid:3) = exp

−

(cid:90) (cid:96)

0

(cid:0)g(cid:48)(a) + 1(cid:1) Φ(cid:48)

(cid:0)g(a)(cid:1)
Φλ,−(cid:0)g(a)(cid:1) da

λ,−

(cid:19)

.

lim
ε→0

For the left-hand side, it suﬃces to prove weak convergence τ ε
(cid:96) ≥ 0. This is done in Corollary 7.12 below.

(cid:96) ⇒ τ(cid:96) as ε → 0 for all

Remark 7.3. One can view the process (X, L) as a two-dimensional diﬀusion reﬂected
at the boundary g with constant oblique direction of reﬂection (−1, +1). But global
existence would not directly follow from results on SDEs with oblique reﬂection in
[DI93], where boundedness of the domain is assumed and used for certain arguments.
Yet, global existence of (X, L) follows from the fact that the approximating process
(X ε, Lε) is deﬁned globally, see the proof of Lemma 7.1.

7.2 Weak convergence and tightness

In order to show weak convergence of (τ ε
(cid:96) )ε, we will prove that the pair of c`adl`ag
processes (X ε, Lε) forms a tight sequence in ε. For this purpose, let (εn)n∈N be any
sequence with εn (cid:38) 0. We consider (X εn, Lεn )n. Recall [Ald78, Theorem 1]:
Proposition 7.4 (Aldous’ criterion for tightness). Let (E,|·|) be a Banach space. If
a sequence (Y n)n∈N of adapted, E-valued c`adl`ag processes satisﬁes the following two
conditions, then it is tight.

(a) The sequences (cid:0)JT (Y n)(cid:1)

every T ∈ (0,∞), where JT denotes the largest jump until time T , i.e.

0 )n are tight (in R and E, respectively) for

n and (Y n

(cid:12)(cid:12)Y n

t − Y n
t−

(cid:12)(cid:12) .

JT (Y n) := sup
0<t≤T

(b) For every time T > 0 and ε0, η > 0 there exist δ > 0 and n0 ∈ N such that for

all n ≥ n0 and all Y n-stopping times σ ≤ T it holds

P(cid:2)|Y n

σ+δ − Y n

σ | ≥ ε0

(cid:3) ≤ η .

To get tightness one needs to control both jump size and frequency of jumps simulta-
neously. As the processes we are interested in have jumps of constant size ±ε, only
the latter property remains to be conﬁned. For this we use two lemmas. The ﬁrst is
technical and the second gives an estimate for the probability that X εn (respectively
Lεn ) performs a number of Nn jumps during a time interval of ﬁxed length.

29

Lemma 7.5 (Upper bound). Fix a time horizon T ∈ (0,∞) and a probability η > 0.
Then there exists a constant M ∈ R such that P[∃n : g(Lεn
T − εn) > M ] ≤ η for the
boundary function g extended by g(−x) := g(0) for −x < 0.
Proof. Fix n ∈ N and let ε := εn as well as (cid:96)k := kε. It holds

T ≥ τ ε

T − =
Lε

− τ ε

(cid:96)k−1

H g((cid:96)k−1)−ε → g((cid:96)k)

k

(cid:88)

(cid:0)τ ε

(cid:96)k

k∈N
(cid:96)k<Lε
T

(cid:1) d=

(cid:88)

(cid:96)k<Lε
T

k

(cid:96)k<Lε
T

with hitting times H···
side. If g(Lε

(cid:88)

k determined by independent (b, σ)-diﬀusions Zk on the right-hand
T − ε) > M ≥ g(0) then by continuity of Zk and monotonicity of g we have
H g((cid:96)k−1)−ε → g((cid:96)k)

T −ε) ≥ H g(0) → M .

= H g(0) → g(Lε

k

H g((cid:96)k−1) → g((cid:96)k)

≥ (cid:88)
T − εn) > M ] ≤ P(cid:2)H g(0) → M ≤ T(cid:3) ≤ η .

(cid:96)k<Lε
T

But since a (b, σ)-diﬀusion has continuous paths, it cannot take arbitrarily large values,
i.e. we have that limM→∞ P[H g(0) → M (Z) ≤ T ] = 0. Hence, there exists a number
M ≥ g(0) such that P[∃n : g(Lεn
Lemma 7.6 (Frequency of jumps). Fix a time horizon T ∈ (0,∞).
(a) Fix a constant δ > 0 and an index n ∈ N. Let σ ≤ T be a ﬁnite (Ft)-stopping
time and Nn an N-valued Fσ-measurable random variable. Then for every λ > 0
there exists an Fσ-measurable random variable kn,λ ∈ {0, 1, . . . , Nn − 1} s.t.

n jumps at least Nn times in ]]σ, σ + δ]](cid:12)(cid:12) Fσ
P(cid:2)X ε

(cid:3) ≤ eλδ

(cid:18) Φλ,−(xn − εn)

(cid:19)Nn−1

Φλ,−(xn)

for xn := g(Lεn

σ + εnkn,λ).

(b) Let C, η > 0. Then there exists a positive constant δ > 0 s.t.

for each ﬁnite
(Ft)-stopping time σ ≤ T and each sequence of N-valued Fσ-measurable random
variables (Nn) satisfying lim inf n→∞ Nnεn ≥ C it holds

P(cid:2)X εn jumps at least Nn times in ]]σ, σ + δ]](cid:3) ≤ η .

lim sup
n→∞

Proof. (a) We enumerate the jumps and estimate the sum of excursion lengths by δ.
σ + kεn be the local time of the k-th jump after time σ. If X εn performs
Let (cid:96)k := Lεn
at least Nn many jumps in the interval ]]σ, σ + δ]], then we have (cid:96)Nn−1 < Lεn
σ+δ. Hence,

δ = (σ + δ) − σ ≥ τ εnLεn

σ+δ

− τ εn
Lεn
σ

≥ Nn−1(cid:88)

(cid:0)τ εn

(cid:96)k

− τ εn

(cid:96)k−1

Nn−1(cid:88)

(cid:1) d=

Hk

k=1

k=1

30

for independent Hk
Hk given Fσ, an application of the Markov inequality yields for λ > 0 that

d= H g((cid:96)k−1)−εn → g((cid:96)k) given Fσ. Knowing the Laplace transform of

k=1

(cid:20)

(cid:21)

(cid:21)

exp

−λ

(cid:18)

≤ P

≤ eλδE

Hk ≤ δ

P(cid:2)X εn jumps at least Nn times in ]]σ, σ + δ]](cid:12)(cid:12) Fσ
(cid:3)
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) Fσ
(cid:12)(cid:12)(cid:12)(cid:12) Fσ
Nn−1(cid:88)
(cid:17)(cid:12)(cid:12)(cid:12) Fσ
(cid:105)
(cid:104)
(cid:16)−λH g((cid:96)k−1)−εn → g((cid:96)k)(Z)
Φλ,−(cid:0)g((cid:96)k−1) − εn
(cid:1)
Φλ,−(cid:0)g((cid:96)k) − εn
Nn−1(cid:89)
Φλ,−(cid:0)g((cid:96)k)(cid:1)
Φλ,−(cid:0)g((cid:96)k)(cid:1)
Φλ,−(cid:0)g((cid:96)k) − εn
Φλ,−(cid:0)g((cid:96)k)(cid:1) (cid:19)Nn−1
(cid:19)Nn−1

(cid:20)Nn−1(cid:88)
Nn−1(cid:89)
Nn−1(cid:89)
(cid:18)
(cid:18) Φλ,−(xn − εn)

max
0≤k<Nn

≤ eλδ

≤ eλδ

E

exp

= eλδ

= eλδ

(cid:1)

Hk

k=1

k=1

k=1

k=1

(cid:1)

= eλδ

Φλ,−(xn)

where pathwise xn := g((cid:96)k) for an index k = kn,λ at which the maximum is attained.
(b) First consider an arbitrary δ > 0 and any ﬁnite stopping time σ ≤ T . For the
limit n → ∞ recall the Taylor expansion

Φλ,−(x − ε)
Φλ,−(x)

log

= −ε

Φ(cid:48)
λ,−(x)
Φλ,−(x)

+ εr(x, ε),

yields a constant M ∈ R such that P(cid:2)∃n : xn > M(cid:3) ≤ η

where r(·, ε) → 0 uniformly on compacts as ε → 0. Since σ + δ is bounded, Lemma 7.5
2 for the Fσ-measurable xn
from above. Now for the paths where xn ∈ I := [g(0), M ] for all n. Here we can apply
uniform convergence to r(xn, εn):

(cid:18) Φλ,−(xn − εn)

(cid:19)Nn−1

eλδ

Φλ,−(xn)

(cid:18)

= exp

≤ exp

≤ exp

(Nnεn − εn)
λδ + lim sup
n→∞
Φ(cid:48)
λ,−(x)
λδ − C inf
x∈I
Φλ,−(x)

(cid:19)

(cid:18)
(cid:18)

(Nn − 1) log

λδ + lim sup
n→∞

(cid:16)
r(xn, εn) − Φ(cid:48)
λδ − C

(cid:18)

exp

= sup
x∈I

λ,−(xn)
Φλ,−(xn)
Φ(cid:48)
λ,−(x)
Φλ,−(x)

(cid:17)(cid:19)
(cid:19)

.

(cid:19)

Φλ,−(xn − εn)

Φλ,−(xn)

By [PY03, Theorem 1] we know that ψx(λ) := 1
exponent of Ax(κx), where κx
level x and Ax(t) is the occupation time

λ,−(x)/Φλ,−(x) is the Laplace
(cid:96) is the inverse local time of the diﬀusion Z at the constant

2 Φ(cid:48)

Ax(t) :=

1{Zs≤x} ds .

(cid:90) t

0

31

Hence we ﬁnd exp(cid:0)−2Cψx(λ)(cid:1) = Ex
(cid:18) Φλ,−(xn − εn)

(cid:2)exp(cid:0)−λAx(κx
(cid:19)Nn−1 ≤ eλδ sup

2C)(cid:1)(cid:3) → 0 for λ → ∞. Thus, by
exp(cid:0)−2Cψx(λ)(cid:1) ≤ η

compactness of I, there exists λ = λC,η,M such that for δ := 1/λ we have

lim sup
n→∞

eλδ

Φλ,−(xn)

x∈I

2

under the condition that xn ≤ M for all n. Together with P[∃n : xn > M ] ≤ η/2, a
direct application of Fatou’s lemma and part (a) ﬁnishes the proof (recall that the
points xn depend on λC,η,M , but the bound M only depends on T , δ and η):

P(cid:2)X ε
n jumps at least Nn times in ]]σ, σ + δ]](cid:3)
≤ P(cid:2)1{∃m:xm>M} + 1{∀m:xm≤M} · lim sup

P[··· | Fσ](cid:3) ≤ η .

lim sup
n→∞

n→∞

Using the preceding two lemmas, we will ﬁrst prove tightness of (Lεn )n and of (X εn )n
for εn (cid:38) 0 separately. Tightness of the pair (X εn , Lεn )n is handled afterwards.
Lemma 7.7 (Tightness of the local time approximations). Consider a sequence of
positive real numbers εn > 0 with εn → 0 as n → ∞. Then the sequence (Lεn)n of
c`adl`ag processes deﬁned by (7.4) and (7.5) is tight.

Proof. Part (a) of Proposition 7.4 is trivial, because initial value Lεn
0 = εn and largest
jump JT (Lεn ) = εn are deterministic. For part (b), consider T, η, ε0 > 0 and any ﬁnite
Lεn -stopping time σ ≤ T . The condition |Lεn
σ | ≥ ε0 means that Lεn performs
at least Nn := (cid:100)ε0/εn(cid:101) many jumps in the stochastic interval ]]σ, σ + δ]]. Since Lεn
jumps whenever X εn does and C := limn→∞ εnNn = ε0 > 0, we can apply Lemma 7.6.
This yields some n0 and δ = δ(C) such that Aldous’ criterion is satisﬁed for all n ≥ n0.
Hence, (Lεn )n is tight by Proposition 7.4.

σ+δ − Lεn

Now for the approximated reﬂected diﬀusion X εn . Condition (a) of Proposition 7.4
σ − ε0
is again trivial. For Aldous’ criterion 7.4(b), ﬁrst consider the case X εn
with bounded stopping time σ ≤ T , constant δ > 0 and w.l.o.g. ε0 > εn. Let τ be the
last jump time in [[σ, σ + δ]] or σ when no jump occurred, i.e. pathwise

σ+δ ≤ X εn

τ := σ ∨ sup(cid:8)t ∈ (σ, σ + δ](cid:12)(cid:12) X εn

(cid:9) .

t− (cid:54)= X εn
σ − εn > X εn

t

τ ≥ X εn

σ+δ. Therefore,
τ +· is a continuous (b, σ)-diﬀusion and hits

σ − ε0 ≥ X εn

Since g is non-decreasing, we have X εn
until shifted time σ + δ − τ the process X εn
σ − ε0 before or at time σ + δ − τ , i.e.
X εn
τ → X εn

H X εn

σ −ε0 ≤ σ + δ − τ .

P(cid:2)X εn

This gives the estimate
σ − ε0

σ+δ ≤ X εn

(cid:3) ≤ P(cid:2)H X εn
≤ P(cid:2)H X εn

σ −ε0 ≤ σ + δ − τ(cid:3) ≤ P(cid:2)H X εn
σ −ε0 ≤ δ(cid:3) .

τ → X εn
σ −εn → X εn

σ −ε0 ≤ δ(cid:3)

τ → X εn

(7.13)

32

Since σ ≤ T is bounded, there exists some Mn ∈ R such that P[|X εn
σ | > Mn] ≤ η/4 by
Lemma 7.5 and because an explosion to −∞ is ruled out by continuity of X ε between
jumps. On the other hand, continuity of a (b, σ)-diﬀusion allows estimating the hitting
times H y → y−d ≤ H x−εn → x−ε0 for x − εn ≥ y ≥ y − d ≥ x − ε0. Hence, with distance
d := (ε0 − εn)/2 > 0, number K := (cid:98)2Mn/d(cid:99) and yk := kd − M − εn we get

P(cid:2)H X εn

σ | ≤ Mn

(cid:3)
P(cid:2)H x−εn → x−ε0 ≤ δ(cid:3)
P(cid:2)H x−εn → x−ε0 ≤ δ(cid:3)
P(cid:2)H yk → yk−d ≤ δ(cid:3) .

σ −εn → X εn−ε0 ≤ δ,|X εn
≤
sup
≤ max
≤ max

x∈[kd−M,(k+1)d−M ]

−Mn≤x≤Mn

k=0,...,K

sup

k=0,...,K

(7.14)

This gives us a suﬃciently small δ = δ1 > 0 such that the right-hand side of (7.14) is
less than η/4. Hence, for all 0 < δ ≤ δ1 we have

σ − ε0] ≤ η
2

P[X εn

σ+δ ≤ X εn
σ+δ ≥ X εn

.

(7.15)

Now consider the second case X εn
σ ) < X εn + ε0
holds (otherwise X εn
σ + ε0 and we could
argue as in the ﬁrst case). So the process X εn performs a positive number of Nn jumps
during the time ]]σ, σ + δ]], which is at least

σ+· would be continuous until it reaches X εn

σ + ε0. W.l.o.g. assume g(Lεn

σ ) > X εn

If g(Lεn
As above, we can estimate the probability of this event

σ + ε0/2, then the process X εn

σ+· is continuous until it reaches X εn

σ + ε/2.

σ + εnN(cid:1) ≥ X εn

Nn := inf(cid:8)N ∈ N(cid:12)(cid:12) g(cid:0)Lεn
(cid:105) ≤ P(cid:2)H X εn
(cid:1) > X εn
(cid:110)
c > 0(cid:12)(cid:12) g((cid:96) + c) ≥ g((cid:96)) +

σ → X εn

C(cid:96) := inf

σ +

ε0
2

(cid:111)

ε0
2

> 0 .

(cid:9) .

σ + ε0

(7.16)

σ +ε0/2(Z) ≤ δ(cid:3) ≤ η

(7.17)

4
σ ) ≤ X εn

σ + ε0/2, we

for all 0 < δ ≤ δ2 small enough. On the other hand, when g(Lεn
ﬁnd a positive lower bound for lim inf n→∞ Nnεn. Let

(cid:104)

σ+δ > g(cid:0)Lεn

σ

P

X εn

(cid:104)

T > M ]≤ η/8.
Note that CLεn
Continuity of g gives C := inf{C(cid:96) | 0 ≤ (cid:96) ≤ M} > 0 . Let ˜Nn := Nn ∨ C/εn, so
C ≤ lim inf n→∞ εn ˜Nn and ˜Nn = Nn whenever Lεn

σ ≤ εnNn. By tightness of (Lεn )n there exists M > 0 s.t. P[Lεn
T ≤ M . Lemma 7.6 gives

σ + ε0 ≥ g(cid:0)Lεn
(cid:1) +
≤ P(cid:2)Lεn
T > M(cid:3) + P(cid:2)Lεn
T ≤ M and X εn jumps Nn times in ]]σ, σ + δ]](cid:3)
+ P(cid:2)X εn jumps ˜Nn times in ]]σ, σ + δ]](cid:3) ≤ η

σ+δ ≥ X εn
X εn

(7.18)

ε0
2

(cid:105)

+

=

P

σ

η
8

η
4

8

≤ η
8

33

P(cid:2)|X εn

(cid:3) ≤ η

for all 0 < δ ≤ δ3 suﬃciently small. With (7.15) and (7.17) we conclude

σ | ≥ ε0

σ+δ − X εn
for all 0 < δ ≤ δ1 ∧ δ2 ∧ δ3. Hence we have
Lemma 7.8 (Tightness of the reﬂected diﬀusion approximations). Let εn > 0 with
εn → 0 as n → ∞. Then the sequence (X εn )n of c`adl`ag processes from (7.4) and (7.5)
is tight.

(7.19)

Proof. As shown above, Proposition 7.4 applies.

Having two tight sequences of c`adl`ag processes, it is generally not clear whether the
pair is also tight in the product space, c.f. [SK85]. However, in our case of X ε and Lε
we not only have the stronger condition by Aldous, but we also know that jump times
and sizes of both process are identical.

Lemma 7.9 (Tightness of the pair of approximated diﬀusion and local times). Let
εn > 0 with εn → 0. Then the sequence (X εn, Lεn )n of c`adl`ag R2-valued processes
deﬁned by (7.4) and (7.5) is tight.

clidean norm |·| and let Y n := (X εn , Lεn) ∈ D(cid:0)[0,∞), E(cid:1). Then Y n

Proof. In view of Proposition 7.4, choose the space E := R2 equipped with Eu-
0 = (−εn, εn) and

2εn form tight sequences in E and R, respectively. Furthermore,
σ | ≥ ε0
σ+δ − Y n
2

σ+δ − X εn

σ | ≥ ε0
2

σ+δ − Lεn

σ | ≥ ε0

+ P

(cid:3) ≤ P

(cid:104)|X εn

(cid:104)|Lεn

(cid:105)

(cid:105)

.

JT (Y n) =

√

P(cid:2)|Y n

Hence Y n also satisﬁes Aldous’ criterion and therefore is tight.

Tightness only implies weak convergence of a subsequence. It remains to show in
Lemma 7.11 that every limit point satisﬁes (7.1) and (7.2) and that uniqueness in law
holds. The semimartingales driving our approximated diﬀusion and local time form a
good sequence (c.f. [KP96, Deﬁnition 7.3]), as shown in the following
Lemma 7.10. Let εn > 0 with εn → 0. Then the semimartingale sequence (Lεn )n∈N
is of uniformly controlled variation and therefore good.
Proof. Let δ := supn εn. Then all processes Lεn have jumps of size at most δ < ∞. Fix
α > C] → 0 for C → ∞, there exists some C ∈ R such
some constant α > 0. Since P[Lεn
t > C} satisﬁes
that P[Lεn
P[τn,α ≤ α] = P[Lεn

α > C] ≤ 1/α. So the stopping time τn,α := inf{t ≥ 0 | Lεn

α > C] ≤ 1/α . Moreover, by monotonicity of Lεn we have

(cid:104)(cid:90) t∧τn,α

E

0

(cid:105)

d|Lεn|s

= E[Lεn

t∧τn,α] ≤ C < ∞ .

Hence (Lεn ) is of uniformly controlled variation in the sense of [KP96, Deﬁnition 7.5].
So by [KP96, Theorem 7.10] it is a good sequence of semimartingales.

34

We have gathered all tools to prove convergence of our approximating diﬀusion and

local time to the continuous reﬂected diﬀusion we are interested in.
Lemma 7.11 (Weak convergence of the approximations). Let εn > 0 satisfy εn → 0.
Then the sequence (X εn, Lεn )n∈N of c`adl`ag processes deﬁned by (7.4) and (7.5) con-
verges weakly to the unique continuous solution (X, L) of (7.1) – (7.2).

of a subsequence to some limit point, (X εnk , Lεnk , W )k ⇒ ( ˜X, ˜L, ˜W ) ∈ D(cid:0)[0,∞), R3(cid:1).

Proof. By Prokhorov’s theorem, tightness of (X εn , Lεn, W )n implies weak convergence
Continuity of ( ˜X, ˜L) is clear since εn → 0 is the maximum jump size. First we prove
that ( ˜X, ˜L) satisﬁes the asserted SDEs. Afterwards, we will prove uniqueness of the
limit point. To ease notation, let w.l.o.g. the subsequence (nk) be (n).

Thm. 1.9]. As D(cid:0)[0,∞), R3(cid:1) is separable we ﬁnd, by an application of the Skorokhod

By [KP96, Theorem 8.1] we get that ( ˜X, ˜L) satisfy (7.1) for the semimartingale ˜W .
That ˜W is a Brownian motion follows from standard arguments, cf. [N ¨O10, proof of
representation theorem, that ˜L is non-decreasing and ˜Xt ≤ g( ˜Lt) for all t ≥ 0, P-a.s.
because these properties already hold for (X εn, Lεn ).

To prove that ˜L grows only at times t with ˜Xt = g( ˜Lt), we have to approximate the

indicator function by continuous functions. For δ > 0 deﬁne

(cid:0)x − g((cid:96))(cid:1)/δ + 1
1 −(cid:0)x − g((cid:96))(cid:1)/δ



0

hδ(x, (cid:96)) :=

for g((cid:96)) − δ ≤ x ≤ g((cid:96)),
for g((cid:96)) ≤ x ≤ g((cid:96)) + δ,
otherwise,

h0(x, (cid:96)) := 1{x=g((cid:96))} and H δ,n

t

:= hδ(X εn
t

, Lεn

t ) and ˜H δ

t := hδ( ˜Xt, ˜Lt) .

0

0

˜H δ

0

0

s =

(cid:90) ·

H δ,n

s− dLεn

s =

(cid:90) ·

0 H δ,n

s− dLεn

H δ,n

s− H 0,n

s− dLεn

s ⇒(cid:82) ·

s− d ˜Ls . Note that dLεn

The functions hδ for δ (cid:38) 0 converge pointwise and monotonically, hδ (cid:38) h0. Continuity
of hδ implies weak convergence (H δ,n, Lεn ) ⇒ ( ˜H δ, ˜L). By Lemma 7.10, (Lεn ) is a
good sequence and hence for every δ > 0 we have weak convergence of the stochastic
. Hence, for every

integrals(cid:82) ·
δ > 0 we have(cid:90) ·
With weak convergence Lεn ⇒ ˜L it follows for every δ > 0 that ˜Lt = (cid:82) t

s− d ˜Ls .
By monotonicity of ˜L, d ˜Lt deﬁnes a random measure on [0,∞). Hence monotone
convergence of ˜H δ

t yields d ˜Lt = h0( ˜Xt, ˜Lt) d ˜Lt .

t = H 0,n

t− dLεn
t

Thus, we showed that (X ε, Lε) converges in distribution to a weak solution ( ˜X, ˜L) of
the reﬂected SDE, i.e. that might be deﬁned on a diﬀerent probability space with its own
Brownian motion. Note that ( ˜X, ˜L) is continuous on [0,∞) and that ˜τ∞ := supk ˜τk = ∞
a.s., where ˜τk := inf{t > 0 | | ˜Xt| ∨ ˜Lt > k}. To show the existence and (pathwise)
uniqueness of a strong solution as stated in the theorem, we will use the results
from [DI93]. Consider the domain ¯G := {(x, (cid:96)) ∈ R2 | x ≤ g((cid:96)), (cid:96) ≥ 0}. We may
interpret the process (Xt, Lt) as a continuous diﬀusion in ¯G with oblique reﬂection
in direction (−1, +1) at the boundary, although the notion of a two-dimensional

s− dLεn

s = Lεn .

t (cid:38) ˜H 0

H 0,n

˜H δ

0

35

reﬂection seems unusual here, because (X, L) only varies in one dimension in the
interior of G. The unbounded domain G can be exhausted by bounded domains

Gk :=(cid:8)(x, (cid:96)) ∈ G(cid:12)(cid:12) |x|,|(cid:96)| < k(cid:9), which might have a non-smooth boundary especially

at (g(0), 0), but still satisfy [DI93, Condition (3.2)]. Hence, by [DI93, Cor. 5.2] the
process (X, L) exists (up to explosion time) on the initial probability space and is
(strongly) unique on [[0, τk[[ with exit time τk := inf{t > 0 | |Xt| ∨ Lt > k}, for all
k ∈ N. So (X, L) is unique until explosion time τ∞ := supk τk. Moreover, by [DI93,
Theorem 5.1] we have the following pathwise uniqueness result: for any two continuous
solutions (X 1, L1) and (X 2, L2) with explosion times τ 1∞ and τ 2∞, respectively deﬁned
on the same probability space with the same Brownian motion and the same initial
k ]] for every k ∈ N a.s.
condition, we have that X 1 = X 2 and L1 = L2 on [[0, τ 1
Now, using a standard argument due to Yamada and Watanabe, see [KS91, Ch. 5.3
D], we can bring the two (weak) solutions ( ˜X, ˜L, ˜W ) and (X, L, W ) to a canonical
space with a common Brownian motion. By this pathwise uniqueness there we can
now conclude that τ∞ = ∞ a.s. (since ˜τ∞ = ∞), and hence the strong solution (X, L)
does not explode in ﬁnite time. Moreover, we obtain uniqueness in law like in [KS91,
Prop. 5.3.20] and thus any weak limit of the approximating sequence (X ε, Lε) will have
the same law as (X, L).
Corollary 7.12 (Weak convergence of the inverse local times). Let εn > 0 with εn → 0.
Then the sequence (τ εn
(cid:96) )n deﬁned by (7.6) converges weakly to the inverse local time τ(cid:96)
deﬁned by (7.3) at every local time (cid:96) > 0.

k ∧ τ 2

Proof. The approximated local times Lεn converge weakly at all continuity points of

L, i.e. at all points. Hence P(cid:2)τ εn

(cid:96) ≤ t(cid:3) = P(cid:2)Lεn

t ≥ (cid:96)(cid:3) εn→0−−−−→ P[Lt ≥ (cid:96)] = P[τ(cid:96) ≤ t] .

This completes the proof of Theorem 7.2.

References

[Ald78]

[Alm12]

[ASS12]

[BBF15]

David Aldous. Stopping times and tightness. Ann. Probability, 6(2):335–340,
1978.

Robert Almgren. Optimal trading with stochastic liquidity and volatility.
SIAM J. Financial Math., 3(1):163–181, 2012.

Aur´elien Alfonsi, Alexander Schied, and Alla Slynko. Order book resilience,
price manipulation, and the positive portfolio problem. SIAM J. Financial
Math., 3(1):511–533, 2012.

Dirk Becherer, Todor Bilarev, and Peter Frentrup. Multiplicative limit order
markets with transient impact and zero spread. 2015. arXiv:1501.01892,
ver. 1.

[BBF16]

Dirk Becherer, Todor Bilarev, and Peter Frentrup. Optimal asset liquidation
with multiplicative transient price impact. 2016. arXiv:1501.01892, ver. 2.

36

[BI13]

´Arp´ad Baricz and Mourad E. H. Ismail. Tur´an type inequalities for Tricomi
conﬂuent hypergeometric functions. Constr. Approx., 37(2):195–221, 2013.

[BSW81] V´aclav E. Beneˇs, Lawrence A. Shepp, and Hans S. Witsenhausen. Some

solvable stochastic control problems. Stochastics, 4(1):39–83, 1980/81.

[DI93]

[DM82]

[DM04]

[DZ98]

Paul Dupuis and Hitoshi Ishii. SDEs with oblique reﬂection on nonsmooth
domains. Ann. Probab., 21(1):554–580, 1993.

Claude Dellacherie and Paul-Andr´e Meyer. Probabilities and Potential B:
Theory of Martingales. North-Holland, Amsterdam, 1982.

Fran¸cois Dufour and Boris Miller. Singular stochastic control problems.
SIAM J. Control Optim., 43(2):708–730, 2004.

M. H. A. Davis and M. Zervos. A pair of explicitly solvable singular
stochastic control problems. Appl. Math. Optim., 38(3):327–352, 1998.

[EKK91] Nicole El Karoui and Ioannis Karatzas. A new approach to the Skorohod
problem, and its applications. Stochastics Stochastics Rep., 34(1-2):57–82,
1991.

[FSU15]

Antje Fruth, Torsten Sch¨oneborn, and Mikhail Urusov. Optimal trade
execution in order books with stochastic liquidity. Preprint, available from
www.antje-fruth.de, 2015.

[GF00]

[GS13]

[JS03]

[Kle08]

Israel M. Gelfand and Sergei V. Fomin. Calculus of Variations. Dover
Books on Mathematics. Dover Publications, 2000.

Jim Gatheral and Alexander Schied. Dynamical models of market impact
and algorithms for order execution. In J.P. Fouque and J. Langsam, editors,
Handbook on Systemic Risk, pages 579–602. Cambridge U. Press, 2013.

Jean Jacod and Albert N. Shiryaev. Limit Theorems for Stochastic Pro-
cesses. Springer, Berlin, 2003.

Achim Klenke. Probability Theory: A Comprehensive Course. Universitext.
Springer London, 2008.

[KOWZ00] Ioannis Karatzas, Daniel Ocone, Hui Wang, and Mihail Zervos. Finite-fuel
singular control with discretionary stopping. Stochastics Stochastics Rep.,
71(1-2):1–50, 2000.

[KP96]

Thomas.G. Kurtz and Philip E. Protter. Weak convergence of stochastic
integrals and diﬀerential equations. In D. Talay and L. Tubaro, editors,
Probabilistic Models for Nonlinear Partial Diﬀerential Equations, volume
1627 of LNM, pages 1–41. Springer Berlin, 1996.

[KS86]

Ioannis Karatzas and Steven E. Shreve. Equivalent models for ﬁnite-fuel
stochastic control. Stochastics, 18(3-4):245–276, 1986.

37

[KS91]

[Kyl85]

[Leb72]

[Løk12]

[LS84]

[LS13]

[N ¨O10]

[PSS11]

[PY03]

[RW87]

[SK85]

[Sko61]

[SS89]

[Tak97]

[Tan79]

Ioannis Karatzas and Steven E. Shreve. Brownian motion and stochastic
calculus, volume 113 of Graduate Texts in Mathematics. Springer-Verlag,
New York, second edition, 1991.

Albert S. Kyle. Continuous auctions and insider trading. Econometrica,
53(6):1315–1335, 1985.

Nikola˘ı N. Lebedev. Special Functions and Their Applications. Dover Books
on Mathematics. Dover Publications, 1972.

Arne Løkka. Optimal execution in a multiplicative limit order book.
Preprint 2012, London School Econ., 2012.

Pierre-Louis Lions and Alain-Sol Sznitman. Stochastic diﬀerential equations
with reﬂecting boundary conditions. Communications on Pure and Applied
Mathematics, 37(4):511–537, 1984.

Christopher Lorenz and Alexander Schied. Drift dependence of optimal
trade execution strategies under transient price impact. Finance Stoch.,
17(4):743–770, 2013.

Kaj Nystr¨om and Thomas ¨Onskog. The Skorohod oblique reﬂection problem
in time-dependent domains. Ann. Probab., 38(6):2170–2223, 2010.

Silviu Predoiu, Gennady Shaikhet, and Steven Shreve. Optimal execution
in a general one-sided limit-order book. SIAM J. Financial Math., 2(1):183–
212, 2011.

Jim Pitman and Marc Yor. Hitting, occupation and inverse local times of
one-dimensional diﬀusions: martingale and excursion approaches. Bernoulli,
9(1):1–24, 2003.

L. Chris G. Rogers and David Williams. Diﬀusions, Markov Processes and
Martingales, Vol. II: Itˆo Calculus. Cambridge University Press, 1987.

Ioana Schiopu-Kratina. Tightness of pairs of tight c`adl`ag processes. Stochas-
tic Process. Appl., 21(1):167–177, 1985.

Anatoli V. Skorokhod. Stochastic equations for diﬀusion processes in a
bounded region. Teoriya Veroyatnostej i Ee Primeneniya, 6:287–298, 1961.

H. Mete Soner and Steven E. Shreve. Regularity of the value function for
a two-dimensional singular stochastic control problem. SIAM J. Control
Optim., 27(4):876–907, 1989.

Michael I. Taksar. Inﬁnite-dimensional linear programming approach to
singular stochastic control. SIAM J. Control Optim., 35(2):604–625, 1997.

Hiroshi Tanaka. Stochastic diﬀerential equations with reﬂecting boundary
condition in convex regions. Hiroshima Math. J., 9(1):163–177, 1979.

38

