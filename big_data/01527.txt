6
1
0
2

 
r
a

M
4

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
7
2
5
1
0

.

3
0
6
1
:
v
i
X
r
a

Random Locations of Periodic Stationary Processes

Jie Shen, Yi Shen, Ruodu Wang

Department of Statistics and Actuarial Science

University of Waterloo

March 7, 2016

Abstract

In this paper we consider a large family of random locations, called intrinsic location
functionals, of periodic stationary processes. This family includes but is not limited to
the location of the path supremum, the ﬁrst hitting time, and the last hitting time. We
ﬁrst show that the set of all possible densities of intrinsic location functionals for periodic
stationary processes is the convex hull generated by a speciﬁc group of density functions.
Next, we focus on two special types of intrinsic locations, the invariant and the ﬁrst-time
intrinsic locations. For the former, we show that the density has a uniform lower bound,
and the corresponding distribution can always be constructed via the location of the
path supremum. For the latter, the structure of the set of the densities is closely related
to the concept of joint mixability.

Keywords: periodic stationary process, random location, joint mixability

1

Introduction

Random locations of stationary processes have been studied for a long time, and various
results exist for special random locations and processes. For example, the results regarding
the hitting time for Ornstein-Uhlenbeck processes date back to Breiman (1967), with recent
developments such as Leblanc et al. (2000) and Alili et al. (2005). Early discussions about
the location of path supremum over an interval can be found in Leadbetter et al. (1983).
The book Lindgren (2012) provides an excellent summary of the general results in stationary
processes.

Recently, properties of possible distributions of the location of the path supremum have
been obtained, and the suﬃciency of the properties was proven (Samorodnitsky and Shen
(2012, 2013b)).
In Samorodnitsky and Shen (2013a), the authors proceeded to introduce
a general type of random locations called intrinsic location functionals, including but also
extending far beyond random locations mentioned above. In Shen (2016), equivalent repre-
sentations of intrinsic location functionals were established using partially ordered random
sets and piecewise linear functions.

In this paper, we consider intrinsic locations of periodic stationary processes and charac-
terize all possible distributions of these random locations. For periodic stationary processes,

1

the densities of intrinsic locations share many properties with their counterparts on the real
line, such as the existence of a c`adl`ag version of the density function and the so-called vari-
ation constraints. Moreover, the periodic setting leads to several new properties along with
challenges, which are the focus of this paper. For instance, the density of a certain type of
random locations has a uniform lower bound. The periodicity also adds a discrete ﬂavor to
the problem, which, surprisingly, suggests a link with other well-studied properties such as
joint mixability (Wang and Wang, 2016).

The rest of the paper is organized as follows. In Section 2, we introduce some notation
and assumptions for intrinsic location functionals and stationary and ergodic processes. In
Section 3, we show some general results on intrinsic locations of periodic stationary processes.
At the same time, suﬃcient and necessary conditions are established to characterize the
densities of these intrinsic locations. The following two sections are devoted to two special
types of intrinsic locations. In Section 4, the class of invariant intrinsic location functionals is
studied. The density of any invariant intrinsic location functional has a uniform lower bound
and such a density can always be constructed via the maximum location over the interval.
In Section 5, we show that the density of the ﬁrst-time intrinsic location is decreasing, and
establish a link between the structure of the set of ﬁrst-time intrinsic locations’ distributions
and the joint mixability of some distributions.
In this paper, we always use the terms
“increasing” and “decreasing” in the non-strict sense.

2 Notation and Assumptions

Throughout the paper, X = {X(t), t ∈ R} will denote a periodic stationary process.
Without loss of generality, assume it has period 1. Moreover, we assume that X is continuous
unless speciﬁed otherwise. Indeed, all the arguments in the following parts also work for X
with c`adl`ag sample paths.

An equivalent description of a periodic stationary stochastic process is a process on a
circle. That is, consider {X(t), t ∈ R} as a process deﬁned on S1, where S1 is a circle with
perimeter 1.

Below we deﬁne intrinsic location functionals as in Samorodnitsky and Shen (2013a).
Let H be a set of functions on R with period 1, and it is invariant under shifts. The latter
means, for all f ∈ H and d ∈ R the function θdf (x) := f (x + d), x ∈ R belongs to H. We
equip H with its cylindrical σ-ﬁeld. Let I be the set of all compact, non-degenerate intervals
in R: I = {[a, b] : a < b, [a, b] ⊂ R}.

Deﬁnition 2.1. (Samorodnitsky and Shen, 2013a) A mapping L: H × I → R ∪ {∞} is
called an intrinsic location functional, if it satisﬁes the following conditions:

1. For every I ∈ I, the mapping L(·, I) : H → R ∪ {∞} is measurable.

2. For every f ∈ H and I ∈ I, L(f, I) ∈ I ∪ {∞}.

3. (Shift compatibility) For every f ∈ H, I ∈ I and c ∈ R,

L(f, I) = L(θcf, I − c) + c,

2

where I − c means the interval I shifted by −c and by convention, ∞ + c = ∞.

4. (Stability under restrictions) For every f ∈ H and I1, I2 ∈ I, I2 ⊆ I1, if L(f, I1) ∈ I2,

then L(f, I2) = L(f, I1).

5. (Consistency of existence) For every f ∈ H and I1, I2 ∈ I, I2 ⊆ I1, if L(f, I2) 6= ∞,

then L(f, I1) 6= ∞.

Remark 2.2. Some intrinsic location functionals may not be well deﬁned naturally for certain
paths in some intervals; to overcome this we add ∞ to the range of the intrinsic location
functionals. The σ-ﬁeld on R ∪ {∞} is given by treating {∞} as a seperate point and taking
the σ-ﬁeld generated by Borel sets in R and {∞}.

Let (Ω, F, P) be a probability space. Recall that a measurable function f is called

T -invariant for a measurable mapping T : Ω → Ω, if

f (T ω) = f (ω) P − almost surely.

For a stationary process {X(t), t ∈ R}, let ˜Ω be the path space equipped with the

cylindrical σ-ﬁeld ˜F, and θt be the shift operator as deﬁned earlier. That is,

θt ˜ω(s) = ˜w(s + t), for ˜ω ∈ ˜Ω.

Denote by PX(·) = P(X ∈ ·) the measure on ( ˜Ω, ˜F ) generated by X.

A stationary process {X(t), t ∈ R} is called ergodic if each measurable function f

deﬁned on ( ˜Ω, ˜F ), which is θt-invariant for every t, is constant PX-almost surely.

It is known that the set of all stationary processes is a convex set and the extreme points
of this set are the ergodic processes. Thus, we have the ergodic decomposition for stationary
processes.

Theorem 2.3. (Kifer, 1988) Let M be the space of all stationary distributions, and Me
the subset of M consisting of all ergodic distributions. Equip M and Me with the natural
σ-ﬁeld: σ(µ → µ(A) : A ∈ F). For any stationary measure µX ∈ M, there exists a measure
λ on Me such that

µX =Zρ∈Me

ρdλ.

The following proposition shows that for periodic stationary processes, ergodicity simply

means that all the paths have the same shape, up to translation.

Proposition 2.4. For any continuous periodic ergodic process X with period 1, there exists
a deterministic function g with period 1, such that X(t) = g(t + U ) for t ∈ R, where U
follows a uniform distribution on [0, 1].

Proof. For any n, t1 < t2 < · · · < tn and non-degenerate open intervals A1, ..., An, de-
note a set HAn := {g ∈ C(R) : g(t1) ∈ A1, . . . , g(tn) ∈ An} and H0 := {f ∈ C(R) :
there exists a constant c, θcf ∈ HAn}. We claim that P({X ∈ H0}) is either 0 or 1. Sup-
pose this is not true. It is not diﬃcult to see that X restricted to H0 is still a stationary

3

process. More precisely, deﬁne probability ˜P by ˜P (B) = 1
where p = P({X ∈ H0}). For any k ∈ N+, s1, . . . , sk and B1, . . . , Bk ∈ B(R), we have

p P(B ∩ {X ∈ H0}), for B ∈ F,

˜P ((X(s1), . . . , X(sk)) ∈ (B1, . . . , Bk)) =

1
p

P ((X(s1), . . . , X(sk)) ∈ (B1, . . . , Bk), X ∈ H0) .

Since

{(X(s1), . . . , X(sk)) ∈ (B1, . . . , Bk), X ∈ H0}

= {X(s1) ∈ B1, . . . , X(sk) ∈ Bk, X(t1 + c) ∈ A1, . . . , X(tn + c) ∈ An, for some c},

and X is stationary,

P ((X(s1), . . . , X(sk)) ∈ (B1, . . . , Bk), X ∈ H0)

= P (X(s1) ∈ B1, . . . , X(sk) ∈ Bk, X(t1 + c) ∈ A1, . . . , X(tn + c) ∈ An, for some c ∈ R)

= P (∪c∈Q{X(s1) ∈ B1, . . . , X(sk) ∈ Bk, X(t1 + c) ∈ A1, . . . , X(tn + c) ∈ An})

= P (∪c∈Q{X(s1 + h) ∈ B1, . . . , X(sk + h) ∈ Bk, X(t1 + h + c) ∈ A1, . . . , X(tn + h + c) ∈ An})

= P (X(s1 + h) ∈ B1, . . . , X(sk + h) ∈ Bk, X(t1 + c) ∈ A1, . . . , X(tn + c) ∈ An, for some c ∈ R)

= P ((X(s1 + h), . . . , X(sk + h)) ∈ (B1, . . . , Bk), X ∈ H0) ,

The second and fourth equalities come from the fact that X is continuous and A1, . . . , An
are open. It follows that

˜P((X(t1), . . . , X(tk)) ∈ (B1, . . . , Bk)) = ˜P((X(t1 + h), . . . , X(tk + h)) ∈ (B1, . . . , Bk)),

for any h ∈ R. Thus, X restricted to H0 is a stationary process. Similarly, stationarity
also holds when X is restricted to H c
0. Therefore, we can decompose X as a mixture of
two diﬀerent stationary processes. It contradicts the assumption that X is ergodic. Then
P({X ∈ H0}) = 1 or 0. Since this holds for any H0, there exists a periodic function g with
period 1 such that almost surely X(t) = g(t + U ) for some random variable U . It is then
obvious that U can be chosen to follow a uniform distribution.

3 Characterization of intrinsic location functionals

For a compact interval [a, b], denote the value of an intrinsic location functional L for
the process X on that interval by L(X, [a, b]). With the stationarity of the process and shift
compatibility of L, the distribution of L depends only on the length of the interval. Thus,
we will study intervals starting from 0, in which case we further abbreviate L(X, [0, b]) as
L(X, b). With the periodicity of X, we only need to consider the case when b ≤ 1. In the
following we assume b ≤ 1 throughout.

Denote by F X

L,[a,b] the law of L(X, [a, b]). It is a probability measure with support on

[a, b] ∪ {∞}.

It is shown that the distribution of an intrinsic location functional for any stationary
process over the real line, not necessarily periodic, has the following properties. Adding
periodicity obviously will not change these results.

4

Proposition 3.1. (Samorodnitsky and Shen, 2013a) Let L be an intrinsic location func-
tional and {X(t), t ∈ R} a stationary process. The restriction of the law F X
L,T to the
interier (0, T ) of the interval is absolutely continuous. Moreover, the density f X
L,T can be
taken as the right derivative of the cdf F X
L,T is right continuous, has left
limits and has the following properties:
(a) The limits

L,T . The density f X

f X
L,T (0+) = lim
t↓0

L,T (t) and f X
f X

L,T (T −) = lim
t↑T

f X
L,T (t)

(3.1)

exist.
(b) The density has a universal upper bound given by

f X

L,T (t) ≤ max(cid:18) 1

t

,

1

T − t(cid:19) ,

0 < t < T.

(3.2)

(c) The density has a bounded variation away from the endpoints of the interval. Further-
more, for every 0 < t1 < t2 < T ,

TV(t1,t2)(f X

L,T ) ≤ min(cid:0)f X

L,T (t1), f X

where

L,T (t2), f X

L,T (t2−)(cid:1) ,

(3.3)

TV(t1,t2)(f X

L,T ) = sup

L,T (t1−)(cid:1) + min(cid:0)f X
Xi=1(cid:12)(cid:12)f X

L,T (si+1) − f X

n−1

L,T (si)(cid:12)(cid:12)

L,T on the interval (t1, t2), and the supremum is taken over all

is the total variation of f X
choices of t1 < s1 < · · · < sn < t2.
(d) The density has a bounded positive variation at the left endpoint and a bounded negative
variation at the right endpoint. Furthermore, for every 0 < ǫ < T ,

(3.4)

(3.5)

and

where for any interval 0 ≤ a < b ≤ T ,

TV+

(0,ǫ)(f X

L,T (ǫ), f X

L,T ) ≤ min(cid:0)f X
L,T ) ≤ min(cid:0)f X

L,T (ǫ−)(cid:1)
L,T (T − ǫ−)(cid:1) ,

TV−

(T −ǫ,T )(f X

L,T (T − ǫ), f X

TV±

(a,b)(f X

L,T ) = sup

L,T (si+1) − f X

n−1

Xi=1(cid:0)f X

L,T (si)(cid:1)±

is the positive (negative) variation of f X
over all choices of a < s1 < · · · < sn < b.
(e) The limit f X
0 < ǫ < T , in which case

L,T on the interval (a, b), and the supremum is taken

L,T (0+) < ∞ if and only if TV(0,ǫ)(f X

L,T ) < ∞ for some (equivalently, any)

TV(0,ǫ)(f X

L,T ) ≤ f X

L,T (0+) + min(cid:0)f X

L,T (ǫ), f X

L,T (ǫ−)(cid:1) .

L,T (T −) < ∞ if and only if TV(T −ǫ,T )(f X

L,T ) < ∞ for some (equivalently, any)

(3.6)

Similarly, f X
0 < ǫ < T , in which case

TV(T −ǫ,T )(f X

L,T ) ≤ f X

L,T (T −) + min(cid:0)f X

L,T (T − ǫ), f X

L,T (T − ǫ−)(cid:1) .

(3.7)

5

While the above properties remain intact with the periodicity condition, periodicity does
play a role when we consider the structure of the set consisting of all possible distributions.
To study this set, we propose a condition which will be widely used in the following sections.
We say a function f satisﬁes condition (T V ), if for any 0 < t1 < t2 < T ,

TV(t1,t2)(f ) ≤ f (t1) + f (t2).

Then condition (T V ) is equivalent to condition (T V ′): there exists a sequence {tn}, tn ↓ 0,
such that

TV(tn,T −tn)(f ) ≤ f (tn) + f (T − tn), n ∈ N.

It is not diﬃcult to see that Conditions (T V ) and (T V ′) are simpliﬁed versions of the
variation constraints (3.3) to (3.7).

For any intrinsic location functional L and T ≤ 1, let IL,T be the set of densities f X
L,T
on (0, T ) for periodic stationary processes X with period 1. Denote by ET the collection of
densities f on (0, T ), which have a c`adl`ag version with the following properties:

1. f takes values in non negative integers;

2. If f (0+) ≥ 1 and f (T −) ≥ 1, then f (t) ≥ 1 for all t ∈ (0, T );

3. f satisﬁes the condition (T V );

0 f (t)dt ≤ 1.

4. R T

Let PT be the collection of all density functions on the interval (0, T ) whose total mass is
less than or equal to 1. For the rest of the paper, denote by C(A) the convex hull generated
by the set A.

Theorem 3.2. IL,T is a convex subset of PT . Moreover, IL,T ⊆ C(ET ).

The proof of this theorem relies on the following representation result given in Shen
(2016): a mapping L(f, I) : H × I → R ∪ {∞} is an intrinsic location functional if and only
if,
(1) L(·, I) is measurable for I ∈ I;
(2) There exists a subset of R determined by f , denoted as S(f ), and a partial order (cid:22) on
it, satisfying:

1. For any c ∈ R, S(f ) = S(θcf ) + c;

2. For any c ∈ R and t1, t2 ∈ S(f ), t1 (cid:22) t2 implies t1 − c (cid:22) t2 − c in S(θcf ),

such that for any I ∈ I, either S(f ) ∩ I = ∅, in which case L(f, I) = ∞, or L(f, I) is the
unique maximal element in S(f ) ∩ I according to (cid:22).

Proof of Theorem 3.2. The convexity of IL,T is obvious. Indeed, by Theorem 2.3, the set
of stationary processes is the convex hull generated by ergodic processes. Thus, IL,T is the
convex hull generated by the densities of L for periodic ergodic processes with period 1.

6

Therefore, it suﬃces to show that for this intrinsic location function L and any periodic
ergodic process with period 1, the density f satisﬁes four properties in the deﬁnition of ET .
Property 4 is trivial and property 3 directly comes from Proposition 3.1. We only need to
check properties 1 and 2. Since X is a periodic ergodic process with period 1, by Proposition
2.4, there exists a periodic deterministic function g with period 1 such that X(t) = g(t + U )
for t ∈ R, where U follows a uniform distribution on [0, 1]. Thus, X has the same shape for
every sample path. Let (S, (cid:22)) be a partially ordered random set representation of L. For
any t ∈ S(X), deﬁne

at := sup{s ∈ R : r (cid:22) t for all r ∈ (t − s, t) ∩ S(X)},

bt := sup{s ∈ R : r (cid:22) t for all r ∈ (t, t + s) ∩ S(X)},

and deﬁne sup ∅ = ∞ by convention. Intuitively, at and bt are the largest distance by which
we can go to the left and right of the point t without passing a point with higher order than
t according to (cid:22), respectively. Thus, we have

P (there exists s ∈ [t, t + ∆t] ∩ S(X) : as > t + ∆t, bs > T − t)

≤ P (t ≤ L(X, (0, T )) ≤ t + ∆t)

≤ P (there exists s ∈ [t, t + ∆t] ∩ S(X) : as ≥ t, bs ≥ T − t − ∆t) .

(3.8)

Seeing that X(t) = g(t + U ), S(X) = S(g) − U and

P (there exists s ∈ [t, t + ∆t] ∩ S(X) : as > t + ∆t, bs > T − t)

= P (there exists s ∈ S(g) ∩ (0, 1] such that as > t + ∆t, bs > T − t, and s − U ∈ [t, t + ∆t]) .

Therefore, for ∆t small enough,

P (there exists s ∈ [t, t + ∆t] ∩ S(X) : as > t + ∆t, bs > T − t)

= |{s ∈ S(g) ∩ (0, 1] : as > t + ∆t, bs > T − t}| · ∆t,

where |A| denotes the cardinal of set A. Therefore, we have

f (t) = lim
∆t→0

P (t ≤ L(X, (0, T )) ≤ t + ∆t)

∆t

≥ |{s ∈ S(g) ∩ (0, 1] : as > t, bs > T − t}| .

(3.9)

Symmetrically,

f (t) = lim
∆t→0

P (t ≤ L(X, (0, T )) ≤ t + ∆t)

∆t

≤ |{s ∈ S(g) ∩ (0, 1] : as ≥ t, bs ≥ T − t}|.

(3.10)

Moreover, it is easy to see that the set Σ := {s ∈ S(g) ∩ (0, 1] : as > 0 and bs > 0} is at most
countable, then {t : as = t or bs = T −t for some s ∈ Σ} is also at most countable. Hence the
density can be taken as the c`adl`ag modiﬁcation of |{s ∈ S(g) ∩ (0, 1] : as ≥ t, bs ≥ T − t}|,
which only takes values in non-negative integers.

For property 2, assume f (0+) ≥ 1 and f (T −) ≥ 1. Suppose for the purpose of con-
tradiction that there exists a non-degenerate interval [u, T − v] such that f (t) = 0 for all

7

t ∈ [u, T − v]. For t ∈ S(X), we distinguish four diﬀerent types: A := {t ∈ S(X) : at ≤
u, bt > T − u − ǫ}, B := {t ∈ S(X) : at > T − v − ǫ, bt ≤ v}, C := {t ∈ S(X) : at > u, bt >
v, at + bt > T } and D := {at > u, bt > v, at + bt = T }, where 0 < ǫ < T −u−v
. Sets A, B,
C and D are disjoint, and for any t ∈ S(X) such that t = L(X, I) for some interval I with
length T , t ∈ A ∪ B ∪ C ∪ D. By the assumption about f , it is easy to see that A 6= ∅, B 6= ∅
and C = ∅. We claim that for any x ∈ A and y ∈ B, if x > y, then x − y > T . Suppose
it is not true, then for interval I = [t, t + T ], where t satisﬁes 0 ≤ y − t < T − v − ǫ and
0 ≤ t + T − x < T − u − ǫ, if z is the maximal element in S(X) ∩ I according to (cid:22), then
z ∈ [y, x]. Notice that since x, y ∈ S(X), z always exists. For such z, it satisﬁes

2

az ≥ ay > T − v − ǫ > u, bz ≥ bx > T − u − ǫ > v,

and az + bz > T − v − ǫ + T − u − ǫ > T when ǫ is small enough, which means z ∈ C.
However, C = ∅ by assumption. Therefore, for any x ∈ A, y ∈ B and x > y, we have
x − y > T . We now take a further step to consider a number of intervals [y − ǫi, y − ǫi + T ] for
some ﬁexed point y ∈ B and ǫi = 1
2i u for i = 1, 2, . . . . Denote li as the maximal element in
[y − ǫi, y − ǫi + T ] ∩ S(X) according to (cid:22). Notice that since y ∈ S(X), li always exists. Seeing
that T − v − ǫ > u, li must be in [y, y + T ]. Since |li − y| ≤ T , li must be in the set B ∪ D.
Suppose li ∈ D for all i. If there exist li = lj ∈ D for some i < j, then by the deﬁnition of
set D, there exists an increasing sequence of points tj
n = y − ǫj
and lj (cid:22) tj
n. However, li = lj implies for any t ∈ S(X) ∩ [y − ǫi, y − ǫi + T ], t (cid:22) li = lj.
It contradics that lj (cid:22) tj
n ∈ [y − ǫi, y − ǫi + T ]. Thus, for any i 6= j, li 6= lj. By
min{u,v} points in the set D ∩ [y, y + T ],
the fact that ali > u and bli > v, there are at most
which contradicts the assumption that li ∈ D ∩ [y, y + T ] for all i = 1, 2, . . . . As a result,
there exists at least one point li such that li ∈ B. If li − y ≤ u

n ∈ S(X) such that limn→∞ tj

n, since tj

T

2 , then

bli ≥ T −

u
2

− ǫi ≥ T − u > v, ali ≥ ay > T − v − ǫ > u,

and ali + bli > T , which means li ∈ C. It contradicts the fact that C = ∅. Therefore for any
y ∈ B, there always exists a point li ∈ B, such that

u
2

< li − y ≤ T.

As a result, for any periodic function f with period 1, there exists y1 ∈ B and then a
sequence of points {yi, i = 2, . . . , k} in B such that for i = 1, . . . , k − 1,

and k is chosen such that

u
2

< yi+1 − yi ≤ T,

yk−1 < 1 + y1 ≤ yk.

Seeing that f is a periodic function with period 1 and A 6= ∅, there must exist some points
x ∈ A and y ∈ B such that x − y ≤ T , which contradicts the result we derived before.
Therefore, we conclude that there does not exist a non-degenerate interval [u, T − v] such
that f (t) = 0 for all t ∈ [u, T − v], if f (0+) ≥ 1 and f (T −) ≥ 1.

8

The next result shows that any member in C(ET ) can be the density on (0, T ) for
some intrinsic location functional and some periodic stationary process with period 1. In
other words, deﬁne IT = ∪LIL,T to be the set of all possible densities of intrinsic location
functionals on (0, T ), then IT = C(ET ).

Theorem 3.3. For any f ∈ C(ET ), there exists an intrinsic location functional and a
periodic stationary process with period 1 such that f is the density of this intrinsic location
for such process.

Proof. We deﬁne an intrinsic location as

LT,1

LT,2

LT,3

if X(t) ≥ 0, for all t ∈ R,

if there exists t such that X(t) = −1,

otherwise,

LT =


where LT,1 = inf(cid:8)t ∈ [0, T ] : X(t) = sups∈[0,T ] X(s)(cid:9), LT,2 = inf{t ∈ [0, T ] : X(t) = −1},

LT,3 = sup{t ∈ [0, T ] : X(t) = −2}. We ﬁrst show that such LT is an intrinsic location
functional, by using the partially ordered random set representation of intrinsic location
functionals. LT,1, LT,2 and LT,3 are all intrinsic locations and they all have their own partially
ordered random set representations, denoted as (S1(f ), (cid:22)1), (S2(f ), (cid:22)2) and (S3(f ), (cid:22)3). If
X has non-negative sample path, then LT has (S1(X), (cid:22)1) as its partially ordered random
representation; otherwise if X reaches level −1, LT has (S2(X), (cid:22)2); otherwise, LT has
(S3(X), (cid:22)3). Therefore, by Corollary 3.7 of Shen (2016), LT is indeed an intrinsic location
functional.

Next, we are going to show that for any f ∈ ET , there exists a periodic ergodic process
with period 1 such that f is the density of LT for such process. For any f ∈ ET , we discuss
two possible scenarios depending whether f (t) ≥ 1 for all t or not.
(1) If f (t) ≥ 1 for all t ∈ (0, T ), there exists a periodic ergodic process with period 1 and
positive sample paths, such that f is the density on (0, T ) of LT for that process. The details
are discussed in the proof of Theorem 4.7, where we focus on the distribution of the location
of path supremum.
(2) Otherwise, f (t) = 0 for some t. In this case, it is easy to see that f satisﬁes the following
properties:

1. f takes values in non negative integers;

2. Either there exists u ∈ (0, T ) such that f is a decreasing function in the interval (0, u)
and f (t) = 0 for t ∈ [u, T ), or there exists v ∈ (0, T ) such that f is an increasing
function in the interval [v, T ) and f (t) = 0 for t ∈ (0, v).

By symmetry, we only prove the case where f is decreasing in the interval (0, u) and f (t) = 0
for t ∈ [u, T ). In the following part, we show that there exists a periodic ergodic process
with period 1 such that the density of the ﬁrst time reaching level −1 between 0 and T for
such process is f . For any decreasing function f with integer values, it can be written as

I(0,ui)(t),

f (t) =

∞

Xi=1

9

where ui ≥ ui+1 for i ∈ N. Deﬁne si =Pi

g(si) = −1, for i = 0, 1, . . .

k=1 uk, i = 1, 2, ... and s0 = 0. Let

By the fact that

Z T

0

f (t)dt =

ui ≤ 1,

∞

Xi=1

The points si, i = 0, 2, . . . are in the interval [0, 1]. In addition to s0, s1, . . . , we set g(t) = −1
for t ∈ (s∞, 1). Next we join the consecutive points (si, −1) and (si+1, −1), i = 0, 1, . . . using
V-shaped curves satisfying some Lipschitz condition with, for example, Lipschitz constant
1. Therefore, we can construct a periodic deterministic function g with period 1, and the
required periodic ergodic process can be written as X(t) = g(t + U ) for t ∈ R, where U
follows a uniform distribution on [0, 1]. Since X has negative sample path and reaches −1,
the location LT = LT,2, which is the ﬁrst time reaching −1. It is easy to check that the
density of LT is exactly f .

By a similar construction, for any density function f increasing in [v, T ) and f (t) = 0
for t ∈ (0, v), we can ﬁnd a periodic ergodic process with period 1 and an intrinsic location
functional as the last time reaching level −2 such that the density of this location is f .

We have obtained all the density functions in ET using the same intrinsic location
functional LT . By Theorem 2.3, the set of stationary processes is the convex hull generated
by ergodic processes. Hence, for any f ∈ C(ET ), we can ﬁnd a periodic stationary process
with period 1, as the mixture of periodic ergodic processes, such that f is the density of LT
for such process.

Remark 3.4. The proof of Theorem 3.3 actually implies a stronger result: all the density
functions in C(ET ) can be generated by a single intrinsic location functional, which is the
location LT deﬁned in the proof of the theorem.

Remark 3.5. Denote by AT the class of density functions on (0, T ) with the following prop-
erties:

1. f is c`adl`ag and R T

0 f (s)ds ≤ 1.

2. f satisﬁes the variation constraints (3.3)-(3.7).

As already observed, IT ⊆ AT . Indeed, IT is a proper subset of AT . Here is an example.
Let T = 1 and

4
3 ,
0,

f (t) =


t ∈ (0, 3

4 ),
4 , 1).

t ∈ [ 3

From the deﬁnition of f , it is easy to check that f ∈ AT . Suppose f is also in the set IT ,
then it can be written as a convex combination of elements in the set ET . Since f (t) = 0
for all t ∈ [ 3
4 , 1), any candidate density g to construct f must be decreasing on the interval

10

4 ) and g(t) = 0 for all t ∈ [ 3

(0, 3
that g(t) = 2 for t ∈ (0, 3

4 , 1). Moreover, g takes integer values, so there exists g such

4 ). However, the integral of g is

Z T

0

g(t)dt =

3
2

> 1,

which means g /∈ ET . Therefore, IT is a proper subset of AT .

4

Invariant intrinsic location functionals

In this section, we consider a special type of intrinsic location functionals, referred to

as the invariant intrinsic location functionals.

Deﬁnition 4.1. An intrinsic location functional L is called invariant, if it satisﬁes

1. L(f, I) 6= ∞ for any compact interval I ∈ I and f ∈ H.

2. L(f, [0, 1]) = L(f, [a, a + 1]) mod 1, for any a ∈ R and f ∈ H.

Remark 4.2. Invariance is a natural requirement for an intrinsic location functional on S1.
The projection of an interval with length of 1 in S1 forms a loop, with the starting and
ending point being mapped to the same point. The above deﬁnition then requires that the
location over the whole circle does not depend on the location of the starting/ending point.

Example 4.3. It is easy to see that the location of the path supremum

τX,[a,b] = infnt ∈ [a, b] : X(t) = sup

a≤s≤b

X(s)o

is an invariant intrinsic location functional, provided that the location of the path supremum
is unique.

Proposition 4.4. For T ∈ (0, 1], any invariant intrinsic location functional L and any
periodic stationary process X with period 1, the density f X

L,T of L on (0, T ) satisﬁes

f X
L,T (t) ≥ 1 for all t ∈ (0, T ).

(4.1)

Proof. Let 0 < a < b < 1. By the stationarity of the process X, we have

P(L(X, [0, 1]) ∈ (0, b − a)) = P(L(X, [a, a + 1]) ∈ (a, b)).

(4.2)

By the assumption of invariant intrinsic locations, for any a ∈ R,

L(X, [0, 1]) = L(X, [a, a + 1]) mod 1.

Then

P(L(X, [0, 1]) ∈ (0, b − a)) = P(L(X, [a, a + 1]) ∈ (a, b))

= P(L(X, [0, 1]) ∈ (a, b)).

11

It means that L(X, [0, 1]) follows a uniform distribution on the interval [0, 1]. Thus, for any
t ∈ (0, 1),

From lemma 3.1 of Samorodnitsky and Shen (2013b), for any Borel set B ∈ B([0, T ]),

f X
L,[0,1](t) = 1.

Therefore, for any 0 < t < T ,

F X
L,[0,T ](B) ≥ F X

L,[0,1](B).

f X
L,T (t) ≥ f X

L,1(t) = 1.

For any invariant intrinsic location functional L and T ≤ 1, let I 1

L,T be the class of
L,T of L on (0, T ) for periodic stationary processes X with period 1. Let E1
densities f X
T
be the collection of densities f on (0, T ), which have a c`adl`ag version with the following
properties:

1. f takes values in positive integers for all t ∈ (0, T );

2. f satisﬁes the condition (T V );

0 f (t)dt ≤ 1.

3. R T

Corollary 4.5. I 1

L,T is a convex subset of PT . Moreover, I 1

L,T ⊆ C(E1

T ).

Proof. From the proof of Theorem 3.2, it remains to show that the density f for any periodic
ergodic stationary process X with period 1 satisﬁes f (t) ≥ 1 for all t ∈ (0, T ). It directly
comes from the result of Proposition 4.4.

To understand the invariant intrinsic location functionals, it is useful to see the close
relationship between invariant intrinsic location functionals and the location of path supre-
mum. In the following result, we show that the set of all possible distributions for invariant
intrinsic location functionals is contained in the set of possible distributions solely for the
location of path supremum. In this sense, the location of path supremum is a representative
of the invariant intrinsic locations. This fact is related to the partially ordered random set
representation of the intrinsic location functionals.

Remark 4.6. For any periodic stationary process X with period 1 and c`adl`ag sample paths,
let X ′(t) = lim sups→t X(s), t ∈ R. Then X′ = {X ′(t), t ∈ R} has upper semi-continuous
sample paths and its supremum over the interval can be attained. As a result, for any X
with c`adl`ag sample paths, the location of the path supremum for X can be deﬁned as

τX,T := inf(t ∈ [0, T ] : X ′(t) = sup

s∈[0,T ]

X ′(s), for any s ∈ [0, T ]) .

Denote by SI the set of invariant intrinsic locational functionals and P1 the set of

periodic stationary processes with period 1.

12

Theorem 4.7. Let MT be the collection of distributions of the location of path supremum
over [0, T ] for periodic stationary processes with period 1, then

{F X

L,T : L ∈ SI, X ∈ P1} ⊆ MT .

Proof. From Corollary 4.5, for any invariant intrinsic location functional L and periodic
ergodic process X with period 1, the distribution F of L consists of a possible point mass at
0 with F (0) = a, a possible point mass at T with 1 − F (T −) = b and a density f on (0, T ),
which satisﬁes the following properties:

1. f takes values in positive integers for all t ∈ (0, T );

2. f satisﬁes the condition (T V );

0 f (t)dt ≤ 1.

3. R T

We are going to show that there exists a periodic ergodic process Y with period 1 such that
F is the distribution of the location of path supremum for Y. It is easy to see that f is a
piecewise constant function of a special form as

f (t) =

m

Xi=1

I(ui,vi](t),

(4.3)

where m can be inﬁnity and the intervals are maximal, in the sense that for any i, j =
1, . . . , m, (ui, vi] and (uj, vj] have only three possibilities:

(ui, vi] ⊂ (uj, vj],

or

(uj, vj] ⊂ (ui, vi],

or

[ui, vi] ∩ [uj, vj] = ∅.

According to whether ui = 0 or vi = T , we call the intervals of the form (0, T ], (0, vi], (ui, T ]
and (ui, vi] the base, left, right and central block(s), respectively. Observe that property 1
and 2 are equivalent to requiring that there is at least one base block, and the number of
the central blocks does not exceed the number of the base blocks.

We construct the stationary process by ﬁrst constructing a periodic determinstic func-
tion, and then uniformly shift the starting point. Let m1 be the number of the base blocks in
the collection. We categorize the entire collection of blocks into m1 components by assigning
to each base block with at most one central block, and assigning the left and the right blocks
in an arbitrary way. Assume a > 0 and b > 0. Let

d1 =

1
m1

a and d2 =

1
m1

b.

For j = 1, . . . , m1, let

Lj = d1 + the total length of the blocks in the jth component + d2,

i=1 Li = 1. Set g(0) = 2 and g(L1) = 2. Using the blocks of the ﬁrst component,
we will deﬁne the function g on the interval (0, L1]. If the component has l left blocks, r

then Pm1

13

right blocks and a central block, where l and r can potentially be inﬁnity, we denote them
by (0, vj ], j = 1, . . . , l, (uk, T ], k = 1, . . . , r and (u, v] respectively. Set

g j−1
Xi=1

vi +

j

Xi=1

1

2i+1 d1! = g  j
Xi=1

vi +

j

Xi=1

1

2i+1 d1! = 1 + 2−j, j = 1, . . . , l,

(4.4)

g d1 +

l

Xi=1

vi! = g d1 +

l

Xi=1

vi + v! = g d1 +

l

Xi=1

vi + v + T − u! =

1
2

,

and

g L1 −

j

Xi=1

1
2i+1 d2 −

j−1

Xi=1

j

(T − ui)! = g L1 −

1
2i+1 d2 −
= 1 + 2−j, j = 1, . . . , r.

Xi=1

j

(T − ui)!
Xi=1

(4.5)

Next, if the values of g at two adjacent points constructed above, a < b, are equal, we join
them by a V-shaped curve satisfying some Lipschitz condition. We complete the function
g by ﬁlling in the other gaps with straight lines between adjacent points (with diﬀerent
values). With the similar construction, we can also deﬁne g on the interval [Li, Li+1], for
i = 1, . . . , m1 − 1. Then g is well deﬁned on the interval [0, 1] and we extend g as a periodic
function with period 1. If a or b equals to 0, we take (the c`adl`ag verion of) the limit of the
corresponding construction with a ↓ 0 or b ↓ 0. We have a periodic ergodic process Y as
Y (t) = g(t + U ) for t ∈ R, where U is uniformly distributed on [0, 1]. It is not diﬃcult to see
that the distribution of the location of the path supremum for Y is F . The proof is ﬁnally
complete with an application of ergodic decompostion. For more details, for example, the
case where there is no central block, we refer the readers to the proof of Theorem 3.1 in
Samorodnitsky and Shen (2012).

From Theorem 4.7, a parallel result of Theorem 3.3 for invariant intrinsic location

functionals can be derived.

Corollary 4.8. For any f ∈ C(E1
T ), there exists an invariant intrinsic location functional
and a periodic stationary process with period 1, such that f is the density of this invariant
intrinsic location for such process.

In Proposition 3.1, an upper bound of the density has been established for intrinsic

location functionals and stationary processes:

f X

L,T (t) ≤ max(cid:18) 1

t

,

1

T − t(cid:19) ,

0 < t < T.

Moreover, such an upper bound was proved to be optimal (Samorodnitsky and Shen, 2013b).
With periodicity and the invariant property, we can now improve the above bound, and show
that the improved upper bound is also optimal.

14

Proposition 4.9. Let X be a periodic stationary process with period 1, L an invariant
intrinsic location functional and T ∈ (0, 1]. Then density f X

L,T satisﬁes

f X

L,T (t) ≤ max(cid:18)⌊

1 − T

t

⌋, ⌊

1 − T
T − t

⌋(cid:19) + 2.

(4.6)

Moreover, for any t ∈ (0, T
2 ) such that 1−T
is not an integer, (4.6) is pointwise optimal.

t

is not an integer and t ∈ [ T

2 , T ) such that 1−T

T −t

Proof. Let gX
be

L,T (t) = f X

L,T − 1, then for every 0 < t1 < t2 < T , the variation constraint will

TV(t1,t2)(gX

L,T ) = TV(t1,t2)(f X

L,T ) ≤ f X

L,T (t1) + f X

L,T (t2) = gX

L,T (t1) + gX

L,T (t2) + 2.

Denote a = inf 0<s≤t gX
exists u ∈ (0, t] of the function gX

L,T (s), b = inf t≤s<T gX
L,T such that

L,T (s). Note that, for any given ǫ > 0, there

and there exists v ∈ [t, T ) such that

gX
L,T (u) ≤ a + ǫ,

gX
L,T (v) ≤ b + ǫ.

Note that

at + b(T − t) ≤Z T

0

gX

L,T (s)ds =Z T

0

(f X

L,T (s) − 1)ds ≤ 1 − T.

(4.7)

Now appying the variation constraint to the interval [u, v], we have

a + b + 2ǫ ≥ gX

L,T (v) − gX
L,T (t)| − 2
L,T (t) − b − ǫ)+ − 2.

L,T (u) + gX
L,T (v)
L,T (t) − gX
L,T (u)| + |gX
L,T (t) − a − ǫ)+ + (gX

≥ |gX

≥ (gX

From the deﬁnition of a and b, we have

a ≤ gX

L,T (t) and b ≤ gX

L,T (t).

Letting ǫ → 0, we have

By (4.7) and (4.8), we obtain

gX
L,T (t) ≤ a + b + 1.

(4.8)

gX

L,T (t) ≤ max(cid:18) 1 − T

t

,

1 − T

T − t(cid:19) + 1.

Then for every 0 < t < T , an upper bound of f X

L,T (t) is

f X

L,T (t) ≤ max(cid:18) 1 − T

t

,

1 − T

T − t(cid:19) + 2.

15

From the proof of Theorem 3.2, f Y
with period 1. Through ergodic decomposition, we further have the upper bound:

L,T takes integer values for any periodic ergodic process Y

f X

L,T (t) ≤ max(cid:18)⌊

1 − T

t

⌋, ⌊

1 − T
T − t

⌋(cid:19) + 2.

It remains to prove that such upper bound can be approached by a periodic ergodic process.
For any t ∈ (0, T

is not an integer, deﬁne f by

2 ) such that 1−T

t

f (s) =

where ε is small enough so that R T

1 + ⌊ 1−T

2 + ⌊ 1−T

t ⌋,
t ⌋,

1,

s ∈ (0, t),

s ∈ [t, t + ε)

s ∈ [t + ε, T ),

1
t

1

0 f (s)ds ≤ 1. As f takes integer values and satisﬁes the
condition (T V ), by Proposition 4.8, there exists a periodic ergodic stationary process with
period 1 such that f is the density of the invariant intrinsic location functional L for such
process.

By similar construction, we can also ﬁnd a periodic ergodic process with period 1 such
2 , T ) such

T −t ⌋+2 at point t for t ∈ [ T

that the density of L for such process approaches ⌊ 1−T
that 1−T

T −t is not an integer.

Let us compare the upper bound (4.6) with the result (3.2) for general stationary pro-
2 , the following inequality holds between the upper bounds in (3.2) and

cesses. For t ≤ T
(4.6):

max(cid:26)⌊

1 − T

t

⌋, ⌊

1 − T
T − t

⌋(cid:27) + 2 ≤

1 − T

t

+ 2 ≤

For t ≥ T
2 ,

= max(cid:26) 1

t

,

1

T − t(cid:27) .

max(cid:26)⌊

1 − T

t

⌋, ⌊

1 − T
T − t

⌋(cid:27) + 2 ≤

1 − T
T − t

+ 2 ≤

T − t

= max(cid:26) 1

t

,

1

T − t(cid:27) .

Therefore, the upper bound in (4.6) is always sharper than that in (3.2).

A stationary process {X(t), t ∈ R} is time-reversible, if {X(−t), t ∈ R} d= {X(t), t ∈
R}. From the deﬁnition of time-reversible stationary processes, the distribution of the in-
d
= T − τX,T .
variant intrinsic location τX,T is symmetric in the interval [0, T ], that is, τX,T
Therefore, the density satisﬁes

fX,T (t) = fX,T (T − t), a.e.

This extra condition allows us to further sharpen the upper bound.

Proposition 4.10. Let {X(t), t ∈ R} be a time-reversible stationary process with period 1,
L be an invariant intrinsic location functional and fX,T be the density of L on the interval
(0, T ) for X, then

fX,T (t) ≤




⌊ 1−T

2t ⌋ + 1
⌊ 1
T −t ⌋
⌊ 1
t ⌋
⌊ 1−T
2(T −t) ⌋ + 1

16

1

0 < t < 1
3 T,
3 T ≤ t < 1
2 T,
2 T ≤ t < 2
3 T,
2
3 T ≤ t < T.

1

(4.9)

Proof. Let gX,T (t) = fX,T (t) − 1 for 0 < t < T , so gX,T (t) ≥ 0. The variation bound is

TV(t1,t2)(gX,T ) = TV(t1,t2)(fX,T ) ≤ fX,T (t1) + fX,T (t2) = gX,T (t1) + gX,T (t2) + 2.

Let a = inf 0<s≤t gX,T (s) and b = inf t≤s<T /2 gX,T (s). Then

at + b(T /2 − t) ≤Z T /2

0

gX,T (s)ds =Z T /2

0

(fX,T (s) − 1)ds ≤

1
2

−

T
2

.

(4.10)

For any given ǫ > 0, there exists u ∈ (0, t] such that gX,T (u) ≤ a + ǫ, and v ∈ [t, T
2 ] such
that gX,T (v) ≤ b + ǫ. Therefore, in the interval [u, T − u], the variation constraint implies,

2(a + ǫ) ≥ gX,T (u) + gX,T (T − u)

≥ |gX,T (t) − gX,T (u)| + |gX,T (v) − gX,T (t)| + |gX,T (T − v) − gX,T (v)|

+ |gX,T (T − t) − gX,T (T − v)| + |gX,T (T − u) − gX,T (T − t)| − 2

≥ 2(gX,T (t) − a − ǫ)+ + 2(gX,T (t) − b − ǫ)+ − 2.

Letting ǫ → 0, we have

Since b ≤ gX,T (t), we have

gX,T (t) ≤ a +

b
2

+

1
2

.

b ≤ 2a + 1.

(4.11)

If T
a + b

2 − t ≥ t
2 + 1

2 with the constraints (4.10) and (4.11), then

2 , or equivalently t ≤ T

3 , taking b = 0 and a = 1−T

2t

leads to the maximum of

fX,T (t) = gX,T (t) + 1 ≤

1 − T

2t

+ 1.

2 − t < t

If T
maximum of a + b

2 , or equivalently T

3 < t < T

2 , taking a =

1

2(T −t) and b = 1

T −t leads to the

2 + 1

2 with the constraints (4.10) and (4.11), then

fX,T (t) ≤

1

T − t

.

From the proof of Theorem 3.2, fX,T takes integer values for any periodic ergodic process.
We futher have

fX,T (t) ≤ ⌊

1 − T

2t

⌋ + 1, for t ∈ (0,

T
3

) and fX,T (t) ≤ ⌊

1

T − t

⌋, for t ∈ [

T
3

,

T
2

).

By ergodic decomposition and symmetry of the distribution, we get (4.9).

Remark 4.11. The upper bound (4.9) is not necessarily attainable. If t ∈ (0, T

3 ], let

f (s) =


⌊ 1−T

2t ⌋ + 1,

s ∈ (0, t),

1,

⌊ 1−T
2(T −t) ⌋ + 1,

s ∈ [t, T − t),

s ∈ [T − t, T ).

17

f takes integer values and satisﬁes condition (T V ), so there exists a periodic ergodic process
with period 1 and an invariant intrinsic location such that f is the density of this invariant
intrinsic location for such process by Corollary 4.8. However, for t ∈ ( T
2 ), there are two
scenarios depending on whether ⌊ 1
T −t ⌋ can be achieved. Denote a = 1
T −t . If
condition (T − 2t)(b − ⌊b⌋) ≥ 2t(⌈a⌉ − a) holds, let

2(T −t) and b = 1

3 , T

1

1

⌈

⌊

2(T −t) ⌉,
(T −t) ⌋,
⌈ 1
2t ⌉,

s ∈ (0, t),

s ∈ [t, T − t),

s ∈ [T − t, T ).

f (s) =


From Corollary 4.8, there exists a periodic ergodic process with period 1 and an invariant
intrinsic location such that f is the density of this invariant intrinsic location for such process.
If (T − 2t)(b − ⌊b⌋) < 2t(⌈a⌉ − a), let

1

1

⌊

2(T −t) ⌋,
2(T −t) ⌋,
2⌊
⌊ 1
2t ⌋,

f (s) =


s ∈ (0, t),

s ∈ [t, T − t),

s ∈ [T − t, T ).

Intuitively, the above condition determines whether f can achieve ⌊ 1
the total mass 1 or violating the variation constraints.

T −t ⌋ without exceeding

5 First-time intrinsic location functionals

In this section, we introduce another type of intrinsic location functionals called the
ﬁrst-time intrinsic location functionals via the partially ordered random set representation.

Deﬁnition 5.1. An intrinsic location functioanal L is called a ﬁrst-time intrinsic location
functional, if it has a partially ordered random set representation (S(X), (cid:22)) such that for
any t1, t2 ∈ S(X), t1 ≤ t2 implies t2 (cid:22) t1.

Proposition 5.2. Let X be a periodic stationary process with period 1, and L be a ﬁrst-
time intrinsic location functional. Fix T ∈ (0, 1]. Then the density of L on (0, T ) for X is
decreasing.

Proof. By ergodic decomposition, it suﬃces to prove the result for periodic ergodic process
X with period 1 having the representation X(t) = g(t + U ), where U is a uniform random
variable on [0, 1]. Let (S(X), (cid:22)) be a partially ordered random set representation for L. By
a similar argument as the discussion below (3.10), we have

f (t2) = |{s ∈ S(g) ∩ (0, 1] : as ≥ t2, bs ≥ T − t2}| ,

and

f (t1) = |{s ∈ S(g) ∩ (0, 1] : as ≥ t1, bs ≥ T − t1}| ,

18

where at = sup{s ∈ R : r (cid:22) t for all r ∈ (t − s, t) ∩ S(X)}, bt = sup{s ∈ R : r (cid:22) t for all r ∈
(t, t + s) ∩ S(X)}. By the deﬁnition of ﬁrst-time intrinsic location functionals and that of
bs, we have

bs = ∞,

for any s ∈ S(X).

Thus,

f (t2) = |{s ∈ S(g) ∩ (0, 1] : as ≥ t2}| and f (t1) = |{s ∈ S(g) ∩ (0, 1] : as ≥ t1}| .

If there exists s ∈ S(g) ∩ (0, 1] such that as ≥ t2, then as ≥ t2 ≥ t1, which means that
f (t1) ≥ f (t2). As a result, f is decreasing on the interval (0, T ).

For any ﬁrst-time intrinsic location functional L and T ≤ 1, let I M

L,T be the collection
of the density functions of L on (0, T ) for all periodic stationary processes with period 1.
Denote by EM
the subset of PT , in which the density f has a c`adl`ag version with the
T
following properties:

1. f takes values in non negative integers for all t ∈ (0, T );

2. f is decreasing on (0, T );

0 f (t)dt ≤ 1.

3. R T

Combining the proof of Theorem 3.2 and Proposition 5.2, we have the following result

of the structure of I M

L,T , parallel to Section 4.

Proposition 5.3. I M

L,T is a convex subset of PT and I M

L,T ⊆ C(EM

T ).

As in the previous cases, the other direction also holds.

Proposition 5.4. For any f ∈ C(EM
T ), there exists a ﬁrst-time intrinsic location functional
and a periodic stationary process with period 1 such that f is the density of this ﬁrst-time
intrinsic location for such process.

The proof of Proposition 5.4 is indeed included in the second part of the proof of

Theorem 3.3.

Denote by AM

T the class of densities f on (0, T ) with the properties that f is c`adl`ag
M is also in I M
T .

and decreasing. We would like to give a veriﬁcation whether a function in AT
The recently developed concept of joint mixability (Wang et al., 2013) is helpful.

In the deﬁnition below, we slightly generalize the concept of joint mixability to the case
of possibly countably many distributions. In the following N is either a positive integer or
it is inﬁnity. If N = ∞, we interpret any tuple (x1, . . . , xN ) as (xi, i = 1, 2, . . . ). Joint
mixability and intrinsic locations are connected in Proposition 5.6 below.

Deﬁnition 5.5. (Wang et al., 2013) Suppose n ∈ N ∪ {∞}. A random vector (X1, . . . , XN )
i=1 Xi = C) = 1 for some C ∈ R. An N -tuple of distributions
(F1, . . . , FN ) is said to be jointly mixable if there exists a joint mix X = (X1, . . . , XN ) such
that Xi ∼ Fi, i = 1, . . . , N .

is said to be a joint mix if P(PN

19

Proposition 5.6. For any f ∈ AM

T , let N = ⌈f (0+)⌉, and deﬁne the distribution functions

Fi : R → [0, 1], x 7→ min{(i − f (x))+, 1}I{x>0},

i = 1, . . . , N.

(5.1)

if there exists a random vector X = (X1, . . . , XN ) such that Xi ∼ Fi, i =
T if (F1, . . . , FN ) is jointly mixable.

i=1 Xi ≤ 1) = 1. In particular, f ∈ I M

Proof. Suppose that there exists a random vector X = (X1, . . . , XN ) such that Xi ∼ Fi,
+ the essential support of the

i=1 Xi ≤ 1) = 1. Denote by D ⊂ RN

Then f ∈ I M
T

1, . . . , N and P(PN
i = 1, . . . , N and P(PN

random vector X.

For each x = (x1, . . . , xN ) ∈ D, deﬁne

fx : [0, T ] → R+, y 7→

N

Xi=1

I{y≤xi}.

Obviously fx is a decreasing function and we can check

Z T

0

fx(y)dy =

N

Xi=1Z T

0

I{y≤xi}dy =

N

Xi=1

xi ≤ 1, x ∈ D.

fx is in EM

T . Moreover, for y ∈ [0, T ],

Thus, fx is a decreasing function on [0, T ] taking values in N0, R T
E[fX(y)] = E" N
Xi=1

I{y≤Xi}# = ⌊f (y)⌋ + EhI{y≤X⌊f (y)⌋}i = ⌊f (y)⌋ + (f (y) − ⌊f (y)⌋) = f (y).

0 fx(y)dy ≤ 1, and hence

Therefore, we conclude that f ∈ I M

T since it is a convex combination of fx, x ∈ D.

Now suppose that (F1, . . . , FN ) is jointly mixable. Then there exists a joint mix X =
i=1 Xi = C) = 1 for some C ∈ R. It

(X1, . . . , XN ) such that Xi ∼ Fi, i = 1, . . . , N and P(PN

suﬃces to verify that C ≤ 1, which follows from

C =

N

Xi=1

E[Xi] =

=

This completes the proof.

N

0

Xi=1Z T
Xi=1Z T

N

0

(1 − Fi(x))dx

min{(f (x) − i + 1)+, 1}dx =Z T

0

f (x)dx ≤ 1.

(5.2)

Remark 5.7. In this section, N might be inﬁnity. It can be easily checked that in the case
i=1 E[Xi] ≤ 1 and

i=1 Xi in the above proof is well-deﬁned since PN

of N = ∞, the limit PN

Xi ≥ 0, i = 1, . . . , N .

Corollary 5.8. For a given density function f ∈ AM
such that

T , if there exists a step function g ∈ EM
T

then f ∈ I M
T .

g(t) ≥ f (t),

∀t ∈ (0, T ),

20

Proof. For any f ∈ AM
random vector X = (X1, . . . , XN ) such that Xi ∼ Fi, i = 1, . . . , N , denote by D ⊂ RN
essential support of the random vector X. For each x = (x1, . . . , xN ) ∈ D,

T , take N and Fi, i = 1, . . . , N as deﬁned in Proposition 5.6. For a
+ the

x1 + · · · + xN ≤

N

Xi=1

f −1(i − 1) ≤Z T

0

g(t)dt ≤ 1.

Thus, f ∈ I M

T by Proposition 5.6.

Corollary 5.9. Suppose that f ∈ AM

T is convex on [0, T ] and

f −1(i) ≤ 1 + f −1(1).

(5.3)

N

Xi=0

Then f ∈ I M
T .

Proof. Let N = ⌈f (0+)⌉ and Fi, i = 1, . . . , N be as in (5.1). Denote by µi the mean of Fi
for i = 1, . . . , N . Apparently Fi has a decreasing density supported in [f −1(i), f −1(i − 1)]
for each i = 1, . . . , N . By the convexity of f , we have

f −1(i) + max{f −1(i − 1) − f −1(i) : i = 1, . . . , N } =

N

Xi=1

f −1(i) − f −1(1) ≤ 1.

N

Xi=0

Since each Fi has decreasing densities, conditions in Corollary 4.7 of Jakobsons et al. (2015)
are satisﬁed, giving that there exists X = (X1, . . . , XN ) such that Xi ∼ Fi, i = 1, . . . , N and

ess-sup  N
Xi=1

Xi! = max( N
Xi=1

f −1(i) + max
i=1,...,N

{f −1(i − 1) − f −1(i)},

µi) ≤ 1.

N

Xi=1

The corollary follows from Proposition 5.6.

Remark 5.10. Formally, Corollary 4.7 of Jakobsons et al. (2015) only gives, for any ǫ > 0
and N ∈ N, the existence of X = (X1, . . . , XN ) such that

ess-sup  N
Xi=1

Xi! < max( N
Xi=1

f −1(i) + max
i=1,...,N

{f −1(i − 1) − f −1(i)},

µi) + ǫ.

N

Xi=1

A standard compactness argument would justify the case ǫ = 0 and N = ∞. Corollary 4.7
of Jakobsons et al. (2015) requires the joint mixability of decreasing densities; see Theorem
3.2 of Wang and Wang (2016). For f ∈ AM
T , there is generally no constraints (except for
location constraints) on the distributions F1, . . . , FN . It is a diﬃcult task to analytically
verify whether a given tuple of distributions is jointly mixable. For some other known
necessary and suﬃcient conditions for joint mixability, see Wang and Wang (2016).

Corollary 5.11. Suppose that f ∈ AM
Then f ∈ I M
T .

T is linear on its essential support [0, b] and f (b) = 0.

Proof. Obviously the slope of the linear function f on its support is not zero.

21

0 f (x)dx = 1. In this case, f is convex on [0, T ]. We only need to verify (5.3) in
Corollary 5.9. Since T < 1 and since f integrates to 1, we have N ≥ 3. Note that,
0 f (x)dx = 1. It

1. R T
from integration by parts and change of variables, R N

0 f −1(t)dt = R T

follows from the linearity of f that

N

Xi=0

N

f −1(i) − f −1(1) =

N

=

Xi=3
Xi=3
≤Z N

2

f −1(i) + f −1(0) + f −1(2)

f −1(t)dt

0

f −1(i) +Z 2
f −1(t)dt +Z 2

0

f −1(t)dt = 1.

The desired result follows from Corollary 5.9.

0 f (x)dx < 1. This case can be obtained from a mixture of (a) and g ∈ EM
g : [0, T ] → {0}.

T where

2. R T
When R T

0 f (x)dx < 1, we obtain a suﬃcient condition for f in AT

M to be in I M

T using

Proposition 5.6 together with a result in Embrechts et al. (2015).

Corollary 5.12. For any f ∈ AM

T , let N = ⌈f (0+)⌉. Then f ∈ I M

T if

max

i=1,...,N

{f −1(i − 1) − f −1(i)} ≤ 1 −Z T

0

f (x)dx.

Proof. Let Fi, i = 1, . . . , N be as in (5.1). Apparently Fi is supported in [f −1(i), f −1(i − 1)]
for each i = 1, . . . , N . Denote L = max{f −1(i − 1) − f −1(i) : i = 1, . . . , N }. From Corollary
A.3 of Embrechts et al. (2015), there exists a random vector X = (X1, . . . , XN ) such that
Xi ∼ Fi, i = 1, . . . , N and

N

N

Xi −

P (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1
i=1 E [Xi] =R T
From (5.2), we have PN
P  N
Xi ≤ 1! ≥ P  N
Xi=1
Xi=1

Xi=1

E [Xi](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi ≤ L +Z T

0

0 f (x)dx and therefore,

≤ L! = 1.

f (x)dx! = 1.

Acknowledgement

Jie Shen acknowledges ﬁnancial support from the China Scholarship Council. Yi Shen
and Ruodu Wang acknowledge ﬁnancial support from the Natural Sciences and Engineering
Research Council of Canada (RGPIN-2014-04840 and RGPIN-435844-2013, respectively).

22

References

Alili, L., Patie, P., and Pedersen, J. L. (2005). Representations of the ﬁrst hitting time

density of an ornstein-uhlenbeck process 1. Stochastic Models, 21(4):967–980.

Breiman, L. (1967). First exit times from a square root boundary. In Proceedings of the Fifth
Berkeley Symposium on Mathematical Statistics and Probability, Volume 2: Contributions
to Probability Theory, Part 2, pages 9–16, Berkeley, Calif. University of California Press.

Embrechts, P., Wang, B., and Wang, R. (2015). Aggregation-robustness and model uncer-

tainty of regulatory risk measures. Finance and Stochastics, 19(4):763–790.

Jakobsons, E., Han, X., and Wang, R. (2015). General convex order on risk aggregation.

Scandinavian Actuarial Journal, (ahead-of-print):1–28.

Kifer, Y. (1988). Ergodic theory of random transformations. Birkhauser Boston, Inc., Dunod.

Leadbetter, M. R., Lindgren, G., and Rootz´en, H. (1983). Extremes and related properties

of random sequences and processes. Springer Science & Business Media.

Leblanc, B., Renault, O., and Scaillet, O. (2000). A correction note on the ﬁrst passage time

of an ornstein-uhlenbeck process to a boundary. Finance and Stochastics, 4(1):109–111.

Lindgren, G. (2012). Stationary stochastic processes: theory and applications. CRC Press.

Samorodnitsky, G. and Shen, Y. (2012). Distribution of the supremum location of stationary

processes. Electronical Journal of Probability, 17(42):1–17.

Samorodnitsky, G. and Shen, Y. (2013a). Intrinsic location functionals of stationary pro-

cesses. Stochastic Processes and their Applications, 123(11):4040–4064.

Samorodnitsky, G. and Shen, Y. (2013b). Is the location of the supremum of a stationary

process nearly uniformly distributed? The Annals of Probability, 41(5):3494–3517.

Shen, Y. (2016). Random locations, ordered random sets and stationarity. Stochastic Pro-

cesses and their Applications, 126(3):906–929.

Wang, B. and Wang, R. (2016). Joint mixability. Mathematics of Operations Research,

forthcoming.

Wang, R., Peng, L., and Yang, J. (2013). Bounds for the sum of dependent risks and worst
value-at-risk with monotone marginal densities. Finance and Stochastics, 17(2):395–417.

23

