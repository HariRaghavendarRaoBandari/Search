Adaptive Component-wise Multiple-Try

Metropolis Sampling

Jinyoung Yang∗ , Radu Craiu† , and Jeﬀrey S. Rosenthal‡

March, 2016

Abstract

One of the most widely used samplers in practice is the component-wise Metropolis-

Hastings (CMH) sampler that updates in turn the components of a vector spaces

Markov chain using accept-reject moves generated from a proposal distribution.

When the target distribution of a Markov chain is irregularly shaped, a ‘good’ pro-

posal distribution for one part of the state space might be a ‘poor’ one for another

part of the state space. We consider a component-wise multiple-try Metropolis

(CMTM) algorithm that can automatically choose a better proposal out of a set

of proposals from diﬀerent distributions. The computational eﬃciency is increased

using an adaptation rule for the CMTM algorithm that dynamically builds a better

set of proposal distributions as the Markov chain runs. The ergodicity of the adap-

tive chain is demonstrated theoretically. The performance is studied via simulations

and real data examples.

∗Department of Statistics, University of Toronto, Toronto, Ontario, Canada M5S 3G3. Email: jiny-

oung.yang@mail.utoronto.edu

†Department of Statistics, University of Toronto, Toronto, Ontario, Canada M5S 3G3. Email:

craiu@utstat.utoronto.ca

‡Department of Statistics, University of Toronto, Toronto, Ontario, Canada M5S 3G3. Email:

jeﬀ@math.toronto.edu

6
1
0
2

 
r
a

 

M
1
1

 
 
]

O
C

.
t
a
t
s
[
 
 

1
v
0
1
5
3
0

.

3
0
6
1
:
v
i
X
r
a

1

1

Introduction

Markov chain Monte Carlo (MCMC) methods are widely used to analyze complex prob-

ability distributions, especially within the Bayesian inference paradigm. One of the most

used MCMC algorithms is the Metropolis-Hastings (MH) algorithm, ﬁrst developed by

Metropolis et al. (Metropolis et al. (1953)), and later expanded by Hastings (Hastings

(1970)). At each iteration the MH algorithm samples a candidate new state from a

proposal distribution which is subsequently accepted or rejected. When the state space

of the chain is high dimensional or irregularly shaped, ﬁnding a good proposal distri-

bution that can be used to update all the components of the chain simultaneously is

very challenging, often impossible. The optimality results for the acceptance rate of the

Metropolis-Hastings algorithm (Gelman et al., 1996; Roberts and Rosenthal, 2001) have

inspired the development of the so-called adaptive MCMC (AMCMC) samplers that are

designed to adapt their transition kernels based on the gradual information about the

target that is collected through the very samples they produce. Successful designs can

be found in Haario et al. (2001), Haario et al. (2006), Turro et al. (2007),Roberts and

Rosenthal (2009), Craiu et al. (2009), Giordani and Kohn (2010), and Vihola (2012)

among others. Theoretical diﬃculties arise because the adaptive chains are no longer

Markovian so ergodicity properties must be proven on a case-by-case basis. Attempts at

streamlining the theoretical validation process for AMCMC samplers have been increas-

ingly successful including Atchad´e and Rosenthal. (2005), Andrieu and Moulines (2006),

Andrieu and Atchad´e (2007), Roberts and Rosenthal (2007), Fort et al. (2011) and Craiu

et al. (2015). For useful reviews of AMCMC we refer to Andrieu and Thoms (2008) and

Roberts and Rosenthal (2009). Despite many success stories, it is our experience that

existing adaptive strategies for MH may take a very long time to “learn” good simulation

parameters or may be remain ineﬃcient in high dimensions and with irregular shaped

targets.

One can increase the computational eﬃciency if instead of using a full MH to update

all the components at once, one chooses to update the components of the chain one-at-a-

time. In this case the update rule follows the MH transition kernel but the acceptance or

rejection is based on the target’s conditional distribution of that component given all the

2

other ones. More precisely, if we are interested in sampling from the continuous density
π(x) : X ⊂ Rd → R+; the component-wise MH (CMH) will update the ith component
of the chain, xi, using a proposal yi ∼ Ti(·|xi) and setting the next value of the chain as

 (x1, . . . , xi−1, yi, xi+1, . . . , xd)

x

z =

where

(cid:26)

αi = min

1,

T (xi|yi)π(yi|x[−i])
T (yi|xi)π(xi|x[−i])

w.p. αi
w.p. 1 − αi

(cid:27)

,

and π(·|x[−i]) is the target conditional distribution of the ith component given all the
other components x[−i] = (x1, . . . , xi−1, xi+1, . . . , xd). One can see that the CMH replaces

the diﬃcult problem of ﬁnding one good proposal in d dimensions with an apparently eas-

ier problem of ﬁnding d good 1-dimensional proposals. However, the latter task can also
prove diﬃcult if the conditional density π(·|x[−i]) turns out to have diﬀerent properties as
x[−i] varies. Intuitively, imagine that for a region of the sample space of x[−i] the proposal

Ti should have a higher spread for the chain to mix well and for the remaining support Ti

should have a smaller spread. Some success has been obtained in lower dimensions or for

distributions with a well-known structure using the regional adaptive MCMC strategies

of Craiu et al. (2009) or Bai et al. (2011), but extending those approaches will be very

cumbersome when d is even moderately large and the geography of π exhibits unknown

irregularities. Other adaptive MCMC ideas proposed for the CMH too include Haario

et al. (2005) where the authors propose to use component-wise random walk Metropolis

(RWM) and to use the component-speciﬁc sample variance to tune the proposal’s vari-

ance, along the same lines that were used by Haario et al. (2001) to adapt the proposal

distribution for the joint RWM. Another intuitive approach is proposed in Roberts and

Rosenthal (2009). The algorithm we propose here will be compared with these existing

algorithms in the simulations section.

The strategy we propose here aims to close the gap that still exists between AMCMC

and eﬃcient CMH samplers. When contemplating the problem, one may be tempted to
try to “learn” each conditional distribution π(·|x[−i]), but parametric models are likely
not ﬂexible enough and nonparametric models will face the curse of dimensionality even

for moderate values of d. Note that here the diﬃcult part is understanding how the
conditional distribution changes as x[−i] varies, which is a d − 1-dimensional problem.

3

Before getting to the technical description of the algorithm, we present here the intu-

itive idea behind our design. Within the CMH algorithm imagine that for each component

we can propose m candidate moves, each generated from m diﬀerent proposal distribu-

tions. Naturally, the latter will be selected to have a diverse range of variances so that

we generate some proposals close to the current location of the chain and some that are

further away. If we assume that the transition kernel for each component is such that

among the proposed states it will select the one that is most likely to lead to an accep-

tance, then one can reasonably infer that this approach will improve the mixing of the

chain provided that the proposal distributions are reasonably calibrated. To mirror the

discussion above, in a region where Ti should have small spread, one wants to have among

the proposal distributions a majority with small variances, and similarly in regions where

Ti should be spread out we want to include among our proposal densities a majority with

larger variances.

This intuition can be put to rigorous test using an approach based on the Multiple-try

Metropolis (MTM) that originated with Liu et al. (2000) and was further generalized by

Casarin et al. (2013). The theoretical validity of the sampler is demonstrated using the

results in Craiu et al. (2015) and the reﬁnement brought by Rosenthal and Yang (2016).

Section 2 introduces a component-wise multiple-try Metropolis (CMTM) algorithm; in

Section 3 we add the adaptive ﬂavour to CMTM so the proposal distributions will modify

according to the local shape of the target distribution and we prove the validity of our

construction. Section 4 applies the adaptive CMTM algorithm to numerical examples.

Section 5 compares the eﬃciency of the adaptive CMTM algorithm to other adaptive

Metropolis algorithms.

2 Component-wise Multiple-Try Metropolis

2.1 Algorithm
Assume that a Markov chain {Xn} is deﬁned on X ⊂ Rd with a target distribution π,
and T1, . . . , Tm are proposal distributions, each of which generates a new proposal yj at

every iteration. The transition rule for the MTM algorithm is described below.

4

1. Let Xn = x. Draw proposals y1, . . . , ym where yj ∼ Tj(·|x).
2. Compute

wj(yj, x) = π(yj)Tj(x|yj)λj(yj, x),

(2.1)

for each yj, where λj(x, y) is a nonnegative symmetric function and λj(x, y) > 0 whenever
Tj(y|x) > 0.
3. Select one y = ys out of y1, . . . , ym with probabilities proportional to wj(yj, x).
4. Draw x∗

m where x∗

1, . . . , x∗

s−1, x∗

s+1, . . . , x∗

5. Accept y with a probability

ρ = min

(cid:104)

s = x

j ∼ Tj(·|y) and let x∗
(cid:105)

1,

w1(y1, x) + . . . + wm(ym, x)
w1(x∗
m, y)

1, y) + . . . + wm(x∗

Throughout the paper, we use the component-wise multiple-try Metropolis (CMTM)

algorithm in which each coordinate is updated using an MTM transition kernel with

Gaussian proposals for each coordinate. More precisely, suppose that we are updating the
kth component of the current state x using m 1-dimensional proposals, Tj(·|x), 1 ≤ j ≤ m.
Then a candidate yj ∼ Tj(·|x) is generated by sampling zk ∼ N (xk, σ2
k,j) and by replacing
the kth coordinate of current state x with zk, i.e. yj = (x1, . . . , xk−1, zk, xk+1, . . . , xd).
j ∼ Tj(·|y), by replacing kth coordinate of y
Similarly, within the same iteration we get x∗
with z∗

k ∼ N (yk, σ2

k,j).

Whether a proposal distribution is ‘good’ or not will depend on the current state of

the Markov chain, especially if the target distribution π has irregular shaped support. In

addition to choosing the m proposals, an added ﬂexibility of the CMTM algorithm is that
we can choose any nonnegative symmetric map λ with λj(x, y) > 0 whenever Tj(y|x) > 0.
In subsequent sections we show that the CMTM algorithm with a particular form of the

function λ(x, y) inﬂuences positively the mixing of the chain and its eﬀects depend in a

subtle manner on the local shape, i.e. the geography of the target distribution around

the current state, and the proposal’s scale.

Our choice of λ is guided by a simple and intuitive principle. Between two candidate

moves y1 and y2 that are equally far from the current state we favour y1 over y2 if π(y1)

is greater than π(y2), but if π(y1) is similar to π(y2), we would like CMTM to favour

whatever candidate is further away from the current state. These simple rules lead us to

5

consider

λj(x, y) = Tj(y|x)−1(cid:107)(y − x)(cid:107)α,

(2.2)

where (cid:107)·(cid:107) is the Euclidean norm. Note that this choice of λ is possible because Tj(y|x) is
a symmetric function in x and y as it involves only one draw from a normal distribution

with mean xk.

Replacing (2.2) in the weights equation (2.1) results in

wj(yj, x) = π(yj)Tj(x|yj)λj(yj, x)

= π(yj)(cid:107)(y − x)(cid:107)α.

(2.3)

With this choice of λ, the selection probabilities are only dependent on the value of the

target density at the candidate point yj and the size of the potential jump of the chain,

were this candidate accepted. From (2.2) we can see that the size of α will balance of

importance of the attempted jump distance from the current state over the importance

of the candidate under π. However, while we understand the trade-oﬀ imposed by the

choice of α for selecting a candidate move, it is less clear how it will impact the overall

performance of the CMTM, e.g acceptance rate or average jump distance.

Therefore, it is paramount to gauge what are good choices for the parameter α for

the mixing of the CMTM chain. In the next section we tackle this using the average

squared jumping distance as the measure of performance of a Markov chain. An estimate

is obtained by averaging over the realized path of the chain. If a new proposal is rejected
and (Xn+1− Xn)2 is equal to zero, that contribution is not discarded. Because of this, the
measure of eﬃciency takes into account not only the jump distance but also the acceptance

rate, a combination that has turned out to be useful in other AMCMC designs (see for

instance Craiu et al., 2009).

2.2 Optimal α

In order to study the inﬂuence of the parameter α on the CMTM eﬃciency we have

conducted a number of simulation studies, some of which are described here.

We considered ﬁrst a 2-dimensional mixture of two normal distributions

6

1
2

∗ N (µ1, Σ1) +

∗ N (µ2, Σ2)

1
2

(2.4)

where 

µ1 = (5, 0)T

µ2 = (15, 0)T

Σ1 = diag(6.25, 6.25)

Σ2 = diag(6.25, 0.25)

Figure 2.1: Target density plot.

2-

dimensional mixture of two normals

An iid sample of size 2000 from (2.4) is plotted in Figure 2.1. We run the CMTM

algorithm repeatedly with λj(x, yj) functions in (2.2) while changing the value of α from

0.1 to 15. We choose m = 5 as the number of proposals for each coordinate, while the

proposal variances σk,j’s are for each coordinate 1, 2, 4, 8 and 16.

As we see in Figure 2.2, the propor-

tion of each proposal distribution selected

increases/decreases as α changes. As ex-

pected, when α increases we see the se-

lection percentages of the proposal distri-

butions with smaller σk,j’s drop and those

with larger σk,j’s increase. Figure 2.2 shows,

with larger α’s, our algorithm favours pro-

Figure 2.2: Proportion of proposal distri-

posal distributions with larger scales, which

bution selected. Coordinate 1: Red, Blue,

makes sense based on the equation (2.3).

Green, Orange and Purple lines show be-

haviour when σk,j = 1, 2, 4, 8, 16, respec-

tively.

Figure 2.3 shows how the average squared jumping distance changes as the value of

α changes. From Figure 2.3a, we see that the average squared jumping distance peaks

in-between α = 2 and α = 4. Next, we run the CMTM algorithm independently 100

7

times for each of α = 2.0, 2.1, . . . , 3.5 and average the average squared jumping distances

over the 100 runs. From Figure 2.3b we can infer that the highest eﬃciency is achieved
for α ∈ (2.5, 3.2).

(a)

(b) (averaged over 100 runs)

Figure 2.3: Two-Dimensional Mixture of two Gaussians: Mean squared jumping distance

vs. α for one run (left panel) and averaged over 100 runs (right panel).

We also examined a 4-dimensional mixture of two normal distributions as our target

density:

where

1
2

∗ N (µ1, Σ1) +

∗ N (µ2, Σ2),

1
2



µ1 = (5, 5, 0, 0)T

µ2 = (15, 15, 0, 0)T

Σ1 = diag(6.25, 6.25, 6.25, 0.01)

Σ2 = diag(6.25, 6.25, 0.25, 0.01).

The number of proposals, m = 5 and σk,j’s of the set of proposal distributions for

each coordinate are 0.5, 1, 2, 4 and 8. Figure 2.4 shows the results. Figure 2.4a shows the

average squared jumping distance is the largest between α = 2 and α = 4. After 100

8

independent replicates for each α = 2.0, 2.1, . . . , 3.5, we can see from Figure 2.4b that
the average squared jumping distances are largest for α ∈ (2.5, 3.2).

(a)

(b) (averaged over 100 runs)

Figure 2.4: 4-Dimensional Mixture of two Gaussians: Means squared jumping distance

vs. α for one run (left panel) and averaged over 100 runs (right panel).

Other numerical experiments not reported here agree with the two examples presented

and suggest that optimal values of α are between 2.5 and 3.2. Henceforth we ﬁx α = 2.9

in all simulations involving CMTM.

3 Adaptive Component-wise Multiple-Try Metropo-

lis

3.1 CMTM Favours Locally ‘Better’ Proposal Distributions

The intuition behind our construction as described in the Introduction, relies on the idea

that CMTM will automatically tend to choose the “right” proposal among the m possible

ones. In this section we verify empirically that this is indeed the case.

We consider the same 2-dimensional mixture of normal distributions from Section 2.2

as our target distribution and run the CMTM algorithm. The simulation parameter are

9

the same, m = 5 and σk,j = 1, 2, 4, 8, 16. As shown in Figure 2.1, the shape of our target
distribution is quite diﬀerent between the two regions of {Xn,1 < 10} and {Xn,1 ≥ 10}.

Table 3.1: Proportion of selected proposals

coordinate 1

coordinate 2

σk,j

σk,j

1

2

4

8

16

1

2

4

8

16

Xn,1 < 10
Xn,1 ≥ 10

0.05

0.15

0.28

0.31

0.22

0.04

0.12

0.25

0.34

0.25

Xn,1 < 10
Xn,1 ≥ 10

0.06

0.19

0.33

0.26

0.16

0.37

0.29

0.19

0.11

0.05

Table 3.2: Acceptance rate of selected proposals

coordinate 1

coordinate 2

σk,j

σk,j

1

2

4

8

16

1

2

4

8

16

Xn,1 < 10
Xn,1 ≥ 10

0.39

0.50

0.51

0.53

0.50

0.40

0.44

0.44

0.45

0.38

Xn,1 < 10
Xn,1 ≥ 10

0.46

0.52

0.50

0.47

0.44

0.44

0.41

0.30

0.28

0.28

Tables 3.1 and 3.2 present the proportion of candidate selection and acceptance rates
for each proposal. We compare the proportion of proposals selected in the regions {Xn,1 ≥
10} and {Xn,1 < 10}. While these regions are deﬁned based on knowing the target exactly,
they do not enter in any way in the design of the CMTM and are used here only to verify

that the sampler indeed automatically adapts to local characteristics of the target. We

can see that the CMTM favours the proposal distributions with smaller σk,j’s in the region
{Xn,1 ≥ 10} which seems appropriate given that in that region larger moves for the second
coordinate will tend to be rejected. This pattern does not hold for the ﬁrst coordinate

for which larger moves are appropriate throughout the sample space. In addition, Table
3.1 shows that in the region where {Xn,1 < 10} the proportions of proposal distribution
selected are similar for the two coordinates. This is in line with what is expected since

the target variances (= 6.25) are the same in both directions in that region.

This suggests that indeed the CMTM algorithm tends to choose the ‘better’ proposal

distribution out of the available choices provided at each iteration. Also, as shown in Table

3.2, none of proposal distributions once selected has too high or too low acceptance rate

even though their variances are quite diﬀerent. This also hints that the CMTM assigns

a selection probability to the multiple proposals at each iteration in such a way that

10

improves the eﬃciency of the Markov chain by avoiding too low and too high acceptance

rate. This observation will help us design the adaptive version of the CMTM.

3.2 Comparison with a Mixture Transition Kernel

An astute reader may wonder about a diﬀerent strategy for using the diﬀerent proposals

that one may have at one’s disposal. Maybe the most natural alternative is a random

mixture of the component-wise Metropolis algorithms. The set of proposal distributions

used in both algorithms is the same and we assign equal weights for the proposal distribu-

tions in the mixture. This comparison is to see empirically how automatically adjusting

the selection probabilities of proposal distributions in the CMTM algorithm improves the

eﬃciency of a MCMC algorithm compared to the uniform selection of proposal distribu-

tions. Our target distribution is the 4-dimensional mixture of two normals introduced in

Section 2.2. The σk,j’s for both algorithms are 0.5, 1, 2, 4 and 8 for each coordinate, and

each independent run has 60000 iterations (15000 updates per coordinate) in total.

A useful comparison of the eﬃciency of MCMC algorithms is based on estimates of

integrated autocorrelation time (ACT) which can be calculated using

∞(cid:88)

τ = 1 + 2

ρk,

k=1

where ρk = Cov(X0, Xk)/V ar(X0) is the autocorrelation at lag k. Higher ACT for a

Markov chain implies successive samples are highly correlated, which reduces the eﬀective

information contained in any given number of samples produced by the chain.

To compare the eﬃciency of two algorithms, we compare the ACT calculated from

the runs of two algorithms. We also look at the CPU time taken for the runs (for the

same number of iterations) and the average squared jumping distances. We calculate the

ACT only from the second-half the chain since we discard the ﬁrst-half as burn-in, but

we calculate the average squared jumping distance for the whole length of the chain.

Table 3.3 shows the proportion of each proposal distribution selected for the CMTM

algorithm.

It is quite diﬀerent from what can be obtained by the uniform sampling,

which is used for the random mixture of the component-wise Metropolis algorithm. By

assigning diﬀerent selection probabilities than uniform, the CMTM algorithm controls

11

the acceptance rate, avoiding too high and too low acceptance rate, as shown in Table

3.4.

Table 3.4: Acceptance rate on selected proposals

(a) Mix. of component-wise Metropolis

σk,j

(b) CMTM

σk,j

0.5

1

2

4

8

0.5

1

2

4

8

coord1

0.94

0.88

0.76

0.56

0.36

coord1

0.41

0.49

0.55

0.53

0.47

coord2

0.94

0.89

0.76

0.58

0.35

coord2

0.40

0.49

0.55

0.53

0.45

coord3

0.83

0.70

0.54

0.38

0.23

coord3

0.48

0.47

0.50

0.50

0.47

coord4

0.25

0.12

0.06

0.04

0.02

coord4

0.27

0.27

0.27

0.31

0.29

Table 3.5: Performance comparison (averaged over 100 runs)

(a) Mix. of component-wise Metropolis

(b) CMTM

Min. Median Mean

Max.

Min. Median Mean

Max.

cputime(s)

sq. jump

14.92

1.443

19.08

1.555

19.98

1.553

29.94

1.650

cputime(s)

sq. jump

126.3

4.657

144.3

4.913

146.0

4.921

197.5

5.131

coord1

coord2

coord3

coord4

coord1

coord2

coord3

coord4

ACT 1109.67

1105.99

39.93

68.74

ACT 316.79

318.28

9.68

13.59

Table 3.5 compares the performance of

two algorithms. We see that the aver-

Table 3.3: CMTM. Proportion of proposal

age squared jumping distance signiﬁcantly

distribution selected

improves with the CMTM compared to

the random mixture of the component-wise

Metropolis. We can also see that the ACT

is smaller for the CMTM than the random

mixture of the component-wise Metropolis.

σk,j

0.5

1

2

4

8

coord1

0.02

0.07

0.22

0.37

0.32

coord2

0.02

0.07

0.21

0.36

0.34

coord3

0.13

0.20

0.23

0.25

0.19

coord4

0.56

0.24

0.12

0.06

0.03

Thus, we conclude that a selection proba-
bility assignment by the CMTM algorithm through the wj(yj|x) function in (2.3) improves
the eﬃciency of the CMTM algorithm. One concern for the CMTM is the increased com-

putation cost. We see in Table 3.5 the runtime for the CMTM is about 7 to 8 times

longer than the random mixture of the component-wise Metropolis. We will discuss the

eﬃciency issue further in Section 5.

12

3.3 The Adaptive CMTM

Given its propensity to choose the best candidate put forward by the proposal distribu-

tions, it is reasonable to infer that CMTM’s performance will be roughly aligned with the

most suitable proposal for the region where the chain current state lies. The other side of

the coin is that a whole set of bad proposals will compromise the eﬃciency of the CMTM

algorithm. Therefore, we focus our eﬀorts in developing an adaptive CMTM (AMCTM)

design that aims to minimize, possibly annihilate, the chance of having at our disposal

only poorly calibrated proposal distributions in any region of the space.

The adaptation strategy is centred on ﬁnding well-calibrated values for the set Sk =
1 ≤ j ≤ m} for every coordinate 1 ≤ k ≤ d. Note that Sk varies across

:

{σk,j
coordinates.

Consider an arbitrarily ﬁxed coordinate and suppose we label the m proposal distri-

butions such that σk,1 < σk,2 < . . . < σk,m. Changes in the kernel occur at ﬁxed points in

the simulation process, called adaption points. The changes will occur only if an alarm

is triggered at an adaption point. An alarm is triggered only if we notice that the candi-

dates generated by the proposal distributions with the smallest scale σk,1 or the largest

one σk,m are over-selected. For instance, suppose that in an inter-adaptation time inter-

val the candidates generated by σk,1 are selected more than 40% of the time. The latter

threshold the latter threshold is more than double the selection percentage for the least

ated using σk,j we have(cid:80)

selected candidate since, if we denote pj the frequency of selecting the candidate gener-
= 1 ≥ m min pj and m = 5 in our implementation. The high
selection percentage for σk,1 suggests that the chain tends to favour, when updating the

pj

kth coordinate, proposals with smaller scale so the ACMTM design requires to: 1) half

the value of σk,1; 2) not modify the largest element in Sk; 3) recalculate the intermediate

values, σk,2, . . . , σk,m−1 to be equidistant between σk,1 and σk,m on the log-scale.

Similarly, if the largest element in Sk, σk,m, produces proposals that are selected with

frequency higher than 40% we consider this indicative of the chain requiring larger scale

proposals for the kth coordinate and we replace σk,m by its double, we keep the smallest

value in Sk and the intermediate values are recalculated to be equidistant on log-scale.

If neither the smallest nor the largest elements in Sk produce proposals that are

13

selected more than 40% of the time, we wait until the algorithm reaches the next ‘adaption

point’ and recalculate the proportion of each proposal candidate being selected during

the last inter-adaption time interval.

An adaptive algorithm must adapt less and less as the simulation proceeds, a condition

known as diminishing adaptation (DA) and long recognized to be essential for the chain’s

valid asymptotic behaviour (Roberts and Rosenthal, 2007). However, the adaption strat-

egy proposed above may not diminish in the long run, so we ensure the DA condition
is satisﬁed by allowing a modiﬁcation at the rth adaption point with probability pr ≤ 1
where

pr = max(0.99r−1,

1√
r

),

r = 1, 2, 3, . . .

(3.1)

We chose pr in (3.1) so that it is decreasing slowly and has high values at the beginning

of the run when most calibrations will take place. The form of (3.1) along with the

Borel-Cantelli lemma allows the adaption to keep occurring for as long as we run the

chain since(cid:80)∞

r=1 pr = ∞.

There are three minor technical details required in our adaptive CMTM algorithm

to ensure the convergence of the algorithm. Those details are to satisfy the conditions

listed in Rosenthal and Yang (2016), which extends the theory developed by Craiu et al.

(2015). The convergence of our adaptive CMTM algorithm is proved in Section 3.5.

1. Fix a (large) constant D > 0. We reject Yn+1 if |Yn+1−Xn| > D. If |Yn+1−Xn| < D,
we accept/reject Yn+1 by the usual rule for the CMTM algorithm described in

Section 2.1.

2. Fix a (large) constant L > 0 and a (really small) constant  > 0. Let σn,k,j be the

σk,j used at n-th iteration in our adaptive CMTM algorithm. If σn,k,j obtained from

the adaption is greater than L, set σn,k,j = L. If σn,k,j obtained from the adaption
is less , set σn,k,j = . (Of course the initial σn,k,j, σ0,k,j, should be  ≤ σ0,k,j ≤ L.)
3. Deﬁne a non-empty bounded (large) subset K ⊂ X . If Xn (cid:54)∈ K, then Yn+1,k,j ∼
k,j), where Yn,k and Xn,k is the kth coordinate of Yn and Xn respectively

k,j is ﬁxed with  ≤ σ∗

k,j ≤ L. If Xn ∈ K, then Yn+1,k,j ∼ N (Xn,k, σ2

n,k,j).

N (Xn,k, σ∗2
and σ∗

14

3.4 To Adapt or Not To Adapt?

We compare the ACMTM algorithm with the CMTM algorithm without adaption to see

if the adaption indeed improves the eﬃciency of the algorithm. We use the 4-dimensional

mixture of two normal distributions from Section 2.2 as our target distribution. The

σk,j’s for the non-adaptive algorithm are given in Table 3.6a and they are the same with

the starting σk,j’s for the adaptive algorithm. We also provide in Table 3.6b the ﬁnal

versions of the σk,j’s obtained after the last adaption in one random run of ACMTM. For

this particular run, the last adaption occurred right after 3600 iterations out of 40000

iterations in total. The comparison is based on 100 independent replicates, each of which

yields the average squared jumping distance and the ACT.

Performance comparison is shown in Table 3.7.

Table 3.6: Ending σk,j’s

(a) Non-adaptive CMTM

(b) Adaptive CMTM

coord1

coord2

coord3

coord4

coord1

coord2

coord3

coord4

prop1

prop2

prop3

prop4

prop5

16

32

64

128

256

16

32

64

128

256

16

32

64

128

256

1

2

4

8

16

prop1

prop2

2.0000

6.7272

2.0000

6.7272

0.2500

0.0625

1.4142

0.2500

prop3

22.6274

22.6274

8.0000

1.0000

prop4

76.1093

76.1093

45.2548

4.0000

prop5

256.0000

256.0000

256.0000

16.0000

Table 3.7: Performance comparisons (averaged over 100 runs)

(a) Non-adaptive CMTM

(b) Adaptive CMTM

Min. Median Mean

Max.

Min. Median Mean

Max.

cputime(s)

sq. jump

79.21

3.463

90.98

3.688

92.88

114.60

3.683

4.036

cputime(s)

sq. jump

77.85

4.180

92.49

4.715

92.61

120.10

4.693

5.181

coord1

coord2

coord3

coord4

coord1

coord2

coord3

coord4

ACT 336.82

332.02

19.39

26.00

ACT 249.08

249.96

13.56

11.47

15

Table 3.8: Proportion of proposal distribution selected

(a) Non-adaptive CMTM

(b) Adaptive CMTM

coord1

coord2

coord3

coord4

coord1

coord2

coord3

coord4

prop1

prop2

prop3

prop4

prop5

0.56

0.24

0.11

0.06

0.03

0.55

0.25

0.12

0.05

0.03

0.56

0.24

0.11

0.06

0.03

0.57

0.24

0.11

0.05

0.03

prop1

prop2

prop3

prop4

prop 5

0.33

0.46

0.16

0.05

0.01

0.33

0.45

0.16

0.05

0.01

0.17

0.44

0.32

0.06

0.01

0.31

0.50

0.14

0.04

0.01

Table 3.9: Acceptance rate on selected proposals

(a) Non-adaptive CMTM

(b) Adaptive CMTM

coord1

coord2

coord3

coord4

coord1

coord2

coord3

coord4

prop1

prop2

prop3

prop4

prop5

0.23

0.23

0.24

0.27

0.24

0.24

0.23

0.22

0.24

0.21

0.16

0.17

0.15

0.16

0.17

0.17

0.16

0.18

0.18

0.22

prop1

prop2

prop3

prop4

prop5

0.49

0.41

0.37

0.34

0.33

0.47

0.41

0.39

0.40

0.34

0.43

0.44

0.41

0.35

0.39

0.45

0.42

0.38

0.37

0.46

We notice that ‘prop1’ was the most favoured proposal distribution for every coordi-

nate if there was no adaption (Table 3.8a) whereas with adaption it was ‘prop2’ selected

most often (Table 3.8b). The σk,j’s got smaller with adaption (Table 3.6), and the two

smallest σk,j’s obtained only after the multiple adaptions are the most favoured ones in

the adaptive run (Table 3.8b). In return, the acceptance rates in the adaptive algorithm

increase to the range of 0.36 to 0.50 compared to 0.15 to 0.27 in the non-adaptive algo-

rithm, as shown in Table 3.9. It is important to note that the increase in acceptance rates

is coupled with an increase in average square distance, as shown in Table 3.7. Altogether

we can see from the same Table that these result in important reductions for the ACT.

The runtime between the non-adaptive and the adaptive algorithm is pretty much the

same as seen in Table 3.7. Altogether, the results show that using an adaptive strategy

made a signiﬁcant diﬀerence.

16

3.5 Convergence of Adaptive CMTM

To conﬁrm the convergence of the adaptive CMTM algorithm described in Section 3.3, we

verify the conditions listed in Theorem 2 of Rosenthal and Yang (2016). As explained in

Section 3.3, Diminishing Adaptation condition holds by the construction of the adaption

mechanism.

Theorem 1. Consider the adaptive CMTM algorithm in Section 3.3 to sample from
state space X that is an open subset of Rd for some d ∈ N. Let π be a target probability
distribution, which has a continuous positive density on X with respect to the Lebesgue
measure. Then, the adaptive CMTM algorithm converges to stationarity as in

|P(Xn ∈ A) − π(A)| = 0.

n→∞ sup
lim
A∈F

(3.2)

Proof. To prove the convergence of the algorithm as in (3.2), we follow the Theorem 2 of

Rosenthal and Yang (2016).

Let m be the number of proposals at each iteration. Let Y be the collection of all
d× m matrices which elements are positive real numbers in [, L] which implies that Y is
compact. Let γ ∈ Y and Qγ be a set of d × m Markov chain proposal kernels with each
kernel Qk,j corresponding to the jth proposal kernel for kth coordinate. By the description
of the adaptive algorithm in Section 3.3, Qγ = Q∗ whenever Xn (cid:54)∈ K, where Q∗ is the set
of d × m proposal kernels with each kernel Q∗
k,j ﬁxed throughout the simulation. Also,
k,j’s, the densities of them equals to zero whenever |Yn+1 − Xn| > D.
for all Qk,j’s and Q∗
Then {Qγ}γ∈Y is the collection of all possible sets of proposal kernels to update all d
coordinates in the adaptive CMTM algorithm. Based on the adaption rule, choosing

which set of Qγ’s to be on at each iteration n is determined by the past and/or current

information obtained from the chain.

As long as the Metropolis-Hastings algorithm is reversible and π is everywhere posi-
tive on X , the transitions being truncated at some ﬁxed distance D does not aﬀect the
ergodicity to π if the Metropolis-Hastings algorithm with the proposal kernels before

truncated was ergodic to π. (Rosenthal and Yang (2016)) Thus, a non-adaptive CMTM

algorithm with any Qγ, even though the proposal kernels are truncated, is ergodic to π

(Casarin et al. (2013), Liu et al. (2000)).

17

The condition (a), (b), (c), (d) and (e) from Rosenthal and Yang (2016) are veriﬁed

as follows:

• Condition (a), the bounded jump condition, is satisﬁed because we reject Yn+1 if

|Yn+1 − Xn| > D > 0.

• Condition (b), no adaption outside of a non-empty bounded subset K ⊂ X , is
k,j) with

satisﬁed since, as described in Section 3.3, we generate Yn+1,k,j ∼ N (Xn,k, σ∗2
k,j ∈ Y ﬁxed whenever Xn (cid:54)∈ K.
σ∗

k,j

• Also, we need to meet the condition (c) and (d) that the ﬁxed proposal kernel Q∗
is bounded above and below. Q∗
k,j(x, dy) needs to be bounded above by M Leb(dy)
for some M > 0 for ∀x ∈ KD\K and ∀y ∈ K2D\K, where Ka is a set containing all
x ∈ X with η(x, K) ≤ a. (η is a metric deﬁned on X , e.g. the Euclidean distance
when X ⊂ Rd.) Indeed, Q∗
k,j(x, dy) ≥ M Leb(dy) everywhere since our transition
kernel Q∗
k,j has a truncated normal density, satisfying condition (c) of Rosenthal
and Yang (2016). We also need Q∗
k,j(x, dy) to be bounded below. More speciﬁcally,
k,j(x, dy) ≥ (cid:48)Leb(dy) whenever |y − x| < δ(cid:48)
we need some (cid:48), δ(cid:48) > 0 such that Q∗
and x, y ∈ J, where J is some bounded rectangle with K2D\KD ⊂ J ⊂ X . It is
condition (d’) in Rosenthal and Yang (2016), which implies condition (d) in our
case since X is an open subset of Rd. Because Q∗
k,j is a normal distribution and
π has a continuous positive density on X satisﬁes condition (d’), we conclude that
condition (d) is satisﬁed.

• Our proposal density functions satisfy condition (e) from Rosenthal and Yang (2016)
since they satisfy their conditions for combocontinuous (in particular, truncated)

functions.

Since the ACMTM algorithm satisﬁes the diminishing adaptation condition as ex-

plained in Section 3.3, we can conclude that it satisﬁes all the conditions listed by The-

orem 2 in Rosenthal and Yang (2016) so the adaptive CMTM algorithm converges to π

as in (3.2).

18

4 Applications

In the following examples we compare the CMTM and the AMCTM when started with

the same set of σk,j’s.

In a second comparison we also consider the CMTM and the CMH samplers in which

we use the σk,j’s identiﬁed by the ACMTM adaptive process in the following way: we
run one ACMTM sampler started at σk,j = 2j for 1 ≤ j ≤ m and 1 ≤ k ≤ d and we
use the ﬁnal σk,j’s from the run to set up the CMTM and the m CMH samplers. If we
assume the labelling such that for each coordinate k we have σk,1 ≤ . . . ≤ σk,m then the
jth CMH sampler uses σk,j to generate moves in the kth coordinate, 1 ≤ k ≤ d. For the
CMTM we use all the σk,j’s identiﬁed by the adaptive process. Throughout this section

we use m = 5.

For all the examples we use the eﬀective sample size (ESS) to compare the eﬃciency

of MCMC algorithms. Since ESS = w/τ , where w is the number of samples obtained

from a Markov chain and τ is the ACT, one can see that ESS is tightly connected to the

degree of correlation of the samples. One may intuitively interpret ESS the number of iid

samples from the target that would contain the same amount of information about the

target as the MCMC sample. Only the second half of the chain’s run is used to calculate

the ACT. We average the ACT over 50 or 100 independent runs, and with that average

we calculate ESS.

4.1 Variance Components Model

The Variance Components Model (VCM) is a typical hierarchical model, well-used in

Bayesian statistics community. Here, we use the data on batch to batch variation in

dyestuﬀ yields. The data were introduced in Davies (1967) and later analyzed by Box

and Tiao (1973). The Bayesian set-up of the Variance Components Model on dyestuﬀ

yields is also well-described in Roberts and Rosenthal (2004). The data records yields

on dyestuﬀ of 5 samples, from each of 6 randomly chosen batches. The data is shown in

Table 4.1.

19

Table 4.1: Dyestuﬀ Batch Yield (in grams)

Batch 1

1545

1440

1440

1520

1580

Batch 2

1540

1555

1490

1560

1495

Batch 3

1595

1550

1605

1510

1560

Batch 4

1445

1440

1595

1465

1545

Batch 5

1595

1630

1515

1635

1625

Batch 6

1520

1455

1450

1480

1445

Let yij be the yield on the dyestuﬀ batch, with i indicating which batch it is from and j

indexing each individual sample from the batch. The Bayesian model is then constructed

as:

yij|θi, σ2

e ∼ N (θi, σ2
e ),

i = 1, 2, ..., K,

j = 1, 2, ..., J

where θi|µ, σ2
The priors for the σ2

θ ∼ N (µ, σ2
θ , σ2

θ ). θi’s are conditionally independent of each other given µ, σ2
θ .
e ∼ IG(a2, b2) and µ ∼ N (µ0, σ2
e and µ are: σ2
0).

θ ∼ IG(a1, b1), σ2

Thus, the posterior density function of this VCM model is

f (σ2

θ , σ2
θ )−(a1+1)e−b1/σ2

(σ2

e , µ, θi|yij, a1, a2, b1, b2, σ2

0) ∝
e )−(a2+1)e−b2/σ2

θ (σ2

e e−(µ−µ0)2/2σ2

0

K(cid:89)

i=1

e(θi−µ)2/2σ2

θ

σθ

K(cid:89)

J(cid:89)

i=1

j=1

e(yij−θi)2/2σ2

e

σe

We set the hyperparameters a1 = a2 = 300 and b1 = b2 = 1000, making inverse

gamma priors very concentrated. We also set σ2

0 = 1010.

Figure 4.1 shows ESS of the CMTM algorithms with and without adaption. For both

CMTM algorithms (with and without adaption), the starting σk,j’s are 0.1, 0.2, 0.4, 0.8

and 1.6 for every coordinate.

20

Figure 4.1: Adaptive CMTM vs. non-adaptive CMTM. Variance components model.

The red represents the adptive CMTM runs and the blue represents the non-adaptive

CMTM runs. ESS is calculated after averaging ACT over 50 independently replicated

runs.

Note that ACMTM yields ESS’s that are considerably larger than the corresponding

values for CMTM.

Next, we want to compare the standard (non-adaptive) CMTM algorithm with the

standard CMH.

The σk,j’s used to set up the CMH and CMTM samplers can be found in Table 4.2.

With this proposal scales, we run the standard CMTM and the standard component-wise

Metropolis and compare the ESS from these two algorithms, averaged over 100 runs.

Table 4.2: σk,j’s used in comparing the standard CMTM and the standard component-

wise Metropolis. Variance components model

coord1

coord2

coord3

coord4

coord5

coord6

coord7

coord8

coord9

prop1

prop2

prop3

prop4

1.00

3.36

1.00

4.76

11.31

22.63

38.05

107.63

prop5

128.00

512.00

1.00

2.83

8.00

22.63

64.00

1.00

2.38

5.66

13.45

1.00

3.36

11.31

38.05

1.00

3.36

11.31

38.05

1.00

3.36

11.31

38.05

1.00

3.36

11.31

38.05

1.00

3.36

11.31

38.05

32.00

128.00

128.00

128.00

128.00

128.00

21

Figure 4.2: Standard (non-adaptive) CMTM vs. standard component-wise Metropolis.

Variance components model. The red represents the CMTM runs and the blue represents

the component-wise Metropolis runs. ESS is calculated after averaging ACT over 100

replicative runs.

Figure 4.2 shows that if we ignore the CPUtime loss for the CMTM algorithm com-

pared to the component-wise Metropolis algorithm, the CMTM algorithm is the most

eﬃcient one based on ESS. However, when we divide ESS by CPUtime to account for

the computation time, the CMTM becomes the third best algorithm compared with the

5 diﬀerent component-wise Metropolis algorithms. We will discuss about this eﬃciency

issue further in Section 5.

4.2 “Banana-shaped” Distribution

The “Banana-shaped” distribution was originally presented in Haario et al. (1999) as an

irregularly-shaped target that may call for diﬀerent proposal distributions for the diﬀerent

parts of the state space.

The target density function of the “banana-shaped” distribution is constructed as
fB = f ◦ φB, where f is the density of d−dimensional multivariate normal distribution
1 − 100B, x3, . . . , xd). B > 0 is the
N (0, diag(100, 1, 1, . . . , 1)) and φB(x) = (x1, x2 + Bx2

22

nonlinearity parameter and the non-linearity or “bananacity” of the target distribution

increases with B. The target density function is

fB(x1, x2, . . . , xd) ∝ exp[−x2

1/200 − 1
2

(x2 + Bx2

1 − 100B)2 − 1
2

(x2

3 + x2

4 + . . . + x2

d)].

We set B = 0.01 and d = 10 and set the starting σk,j’s equal to 0.1, 0.2, 0.4, 0.8 and 1.6

for every coordinate. The results are shown in Figure 4.3. You see that the ESS is larger

in every coordinate for the adaptive CMTM algorithm compared to the non-adaptive

CMTM algorithm, conﬁrming that the adaption improved the eﬃciency in this example.

Figure 4.3: Adaptive CMTM vs. non-adaptive CMTM. “Banana-shaped” distribution.

The red represents the adptive CMTM runs and the blue represents the non-adaptive

CMTM runs. ESS is calculated after averaging ACT over 50 replicative runs.

In the second comparison we notice that in 45 out of 50 independently replicated

runs, the starting σk,j’s did not change under the adaptive CMTM algorithm. Therefore,

we take 1,2,4,8,16 for every coordinate as our default σk,j’s for the standard CMTM

algorithm we run here. And for the standard CMH algorithms, we run with ﬁve diﬀerent
sets of proposal standard deviation, (1, 1,··· , 1), (2, 2,··· , 2), (4, 4,··· , 4), (8, 8,··· , 8),
and (16, 16,··· , 16), with one set at a time. As we see in Figure 4.4, ESS is larger in
every coordinate for the CMTM compared to the component-wise Metropolis if CPUtime

23

is ignored. If we look at ESS/CPUtime, the CMTM is in the middle of the pack in terms

of eﬃciency.

Figure 4.4: Standard (non-adaptive) CMTM vs. standard component-wise Metropolis.

“Banana-shaped” distribution. The red represents the CMTM runs and the blue repre-

sents the component-wise Metropolis runs. ESS is calculated after averaging ACT over

50 replicative runs.

4.3 Orange Tree Growth Data

The orange tree growth data was ﬁrst presented by Draper and Smith (1981) and was

further analyzed by Lindstrom and Bates (1990). Here, we follow the Bayesian model

set-up speciﬁed in Craiu and Lemieux (2007). The data consists of the measures of trunk

circumferences of ﬁve diﬀerent orange trees on seven diﬀerent time points. You can ﬁnd

the data in Table 4.3.

24

Table 4.3: Growth of Orange Trees

Age (days)

Circumference (mm)

Tree1 Tree2 Tree3 Tree4 Tree5

118

484

664

1004

1231

1372

1582

30

58

87

115

120

142

145

33

69

111

156

172

203

203

30

51

75

108

115

139

140

32

62

112

167

179

209

214

30

49

81

125

142

174

177

Let yij be the trunk circumference measure, where i = 1, . . . , 5 indexes for the ﬁve

diﬀerent trees and j = 1, . . . , 7 indexes for the seven diﬀerent time points. The logistic
growth model has yij ∼ N (µij, σ2

c ) where

µij =

exp(θi1)

1 + (exp(θi2) − 1)exp(−exp(θi3)xj)

c ∼
with xj being the time point. The priors for the σ2
IG(0.001, 0.001) and θik ∼ N (0, 100). Note that θik’s are independent of each other and
yij are conditionally independent of each other given µij and σ2
c . Thus, the posterior

c and the θik, k = 1, 2, 3, are: σ2

density of interest is

f (θik, σ2

c|yij, xj) ∝ (σ2

c )−(0.001+1)e−0.001/σ2

c

5(cid:89)

3(cid:89)

i=1

k=1

e(θik)2/200

10

× 5(cid:89)

7(cid:89)

i=1

j=1

(yij−

e

1+(exp(θi2)−1)exp(−exp(θi3)xj ) )2/2σ2

c

exp(θi1)

σc

.

First, we compare the adaptive CMTM with the non-adaptive CMTM. The starting

σk,j’s here for the both algorithms are 1, 2, 4, 8, and 16 for every coordinate and the

results, shown in Figure 4.5, conﬁrm that the ESS is larger in every coordinate for the

adaptive CMTM algorithm.

25

Figure 4.5: Adaptive CMTM vs. non-adaptive CMTM. Orange tree growth data. The

red represents the adptive CMTM runs and the blue represents the non-adaptive CMTM

runs. ESS is calculated after averaging ACT over 50 replicative runs.

When comparing the CMTM with the CMH the proposal scales used can be found in

Table 4.4

Table 4.4: σk,j’s used in comparing the standard CMTM and the standard component-

wise Metropolis. Orange tree growth data

coord1

coord2

coord3

coord4

coord5

coord6

coord7

coord8

1.00

2.38

5.66

13.45

32.00

1.00

2.83

8.00

22.63

64.00

1.00

2.83

8.00

22.63

64.00

1.00

2.38

5.66

13.45

32.00

1.00

2.83

8.00

22.63

64.00

1.00

2.38

5.66

13.45

32.00

1.00

2.38

5.66

13.45

32.00

1.00

2.83

8.00

22.63

64.00

coord9

coord10

coord11

coord12

coord13

coord14

coord15

coord16

1.00

2.38

5.66

13.45

32.00

1.00

2.38

5.66

13.45

32.00

1.00

2.83

8.00

22.63

64.00

1.00

2.38

5.66

13.45

32.00

1.00

2.38

5.66

13.45

32.00

1.00

2.83

8.00

22.63

64.00

1.00

2.38

5.66

1.00

22.63

512.00

13.45

11585.24

32.00

262144.00

prop1

prop2

prop3

prop4

prop5

prop1

prop2

prop3

prop4

prop5

The results for the runs are shown in Figure 4.6. Again, ESS is larger in every coor-

dinate for the CMTM algorithm compared to the component-wise Metropolis algorithm,

but ESS/CPUtime is only the fourth largest for the CMTM algorithm.

26

Figure 4.6: Standard (non-adaptive) CMTM vs. standard component-wise Metropolis.

Orange tree growth data. The red represents the CMTM runs and the blue represents

the component-wise Metropolis runs. ESS is calculated after averaging ACT over 100

replicative runs

5 Comparsion of Adaptive Algorithms

The CMTM algorithm has a higher computational cost compared to the standard component-

wise Metropolis algorithm. For the same number of iterations, CMTM takes longer CPU
time as it has to evaluate 2m − 1 points under the target distribution at each iteration
compared to 1 for the simple Metropolis algorithm. (m is the number of proposals for each

iteration.) On the other hand, CMTM does improve eﬃciency per iteration as implied by

the increase in ESS in Table 4.2, Table 4.4, and Table 4.6. In Section 4, the magnitude

of ESS diﬀerence between the CMTM and the standard component-wise Metropolis, or

equivalently the magnitude of eﬃciency gain, was dependent on the proposal variances of

the standard component-wise Metropolis. Moreover, ﬁnding the best or close to the best

proposal scales for the component-wise Metropolis is not always easy. If we fail to ﬁnd a

‘good’ scale for the component-wise Metropolis or even the full-dimensional Metropolis

these samplers will do a lot worse than the CMTM algorithm, even after accounting for

27

the additional computation cost with the CMTM. In a practical application one cannot

know which one of the CMH’s designed along the lines used in the previous section is

better than the ACMTM until all the CMH’s have been run and compared. Even then

there is no guarantee that the most eﬃcient CMH will be surpass the ACMTM. In our

applications we can see that the ACMTM represents a solid bet in terms of eﬃciency

even after accounting for CPU time.

Researchers have tried several adaptive Metropolis algorithms to ﬁnd a ‘good’ scale

for the Metropolis algorithm. We compare a few known adaptive Metropolis algorithms

with the ACMTM algorithm.

The adaptive Metropolis algorithm we examine are: Adaptive Metropolis-within-

Gibbs (AMwG) algorithm from Roberts and Rosenthal (2009), Single Component Adap-

tive Metropolis (SCAM) algorithm from Haario et al. (2005), and Adaptive Random Walk

Metropolis (ARWM) algorithm from Haario et al. (2001). The AMwG algorithm uses

the ﬁnding that the optimal acceptance rate for one-dimensional Metropolis algorithm

is 0.44 (Gelman et al. (1996), Roberts and Rosenthal (2001)) and adjusts the proposal

variance to get the acceptance rate close to 0.44 for each coordinate. The SCAM al-

gorithm ﬁnds the empirical variance for each coordinate from the entire history of the

Markov chain and tunes the proposal variance for each coordinate based on this. The

ARWM algorithm also looks at the entire history of the chain and tunes the proposal’s

full-dimensional covariance matrix using the empirical covariance matrix calculated from

the samples collected up to that iteration.

We look at the three examples from Section 4 and compare how these adaptive algo-

rithms fare against the ACMTM algorithm. For the latter the default σk,j’s are 0.1, 0.2,

0.4, 0.8 and 1.6 for every coordinate.

For the AMwG algorithm, the default σj is 1 for each coordinate, and it gets adjusted

upward if the acceptance rate is higher than 0.44 based on the recent “batch” of 100

iterations and adjusted downward if the acceptance rate is lower than 0.44. The σj is

adjusted by adding or subtracting min(0.05,(cid:112)(h)) in log scale based on the h-th “batch”

of 100 iterations. One can see how this strategy may not be ideal when the chain alternates

between regions in which the proposal must have diﬀerent scales.

For the SCAM algorithm, the default σj for each coordinate is 1, and the chain runs

28

for 10d iterations (10 updates per coordinate) with the default σj’s. After 10d iterations,

the proposal variance is tuned based on the empirical variance for each coordinate from

the entire history of the chain, multiplied by the scaling parameter 2.382 given by Gelman

et al. (1996).

For the ARWM, the default Σ is an identity matrix, and after 100 iterations with

default Σ, the algorithm starts to tune the proposal covariance matrix by multiplying

the empirical covariance matrix with the choice of scaling parameter 2.382/d (d is the

dimension of the Markov chain.) given by Gelman et al. (1996). The results of the

comparison of these four adaptive algorithms are shown in Figure 5.1 and Figure 5.2.

29

(a) Variance components model

(b) “Banana-shaped” distribution

(c) Orange tree growth data

30

Figure 5.1: Comparison of ESS for diﬀerent adaptive schemes. The red represents the

ACMTM algorithm; the purple represents the AMwG algorithm; the green represents

the SCAM algorithm; and the orange represents the ARWM algorithm. In each row, the

(a) Variance components model

(b) “Banana-shaped” distribution

(c) Orange tree growth data

31

Figure 5.2: Comparison of ESS/CPUtime for diﬀerent adaptive schemes. The red rep-

resents the ACMTM algorithm; the purple represents the AMwG algorithm; the green

represents the SCAM algorithm; and the orange represents the ARWM algorithm. In

Comparison between samplers is achieved by comparing the worst coordinate-wise

ESS and ESS/CPUtime. To be precise, we compare the

and

min
1≤k≤d

ESSk

min
1≤k≤d

ESSk

CP U time

for each algorithm. We see in Figure 5.1 that if we disregard the additional computational

cost for the CMTM, adaptive CMTM is the best choice out of 4 adaptive algorithms

in every examples we run. To account for the computational cost, we calculate the

ESS/CPUtime, and the results are shown in Figure 5.2. Adaptive CMTM is not the best

algorithm based on this measure for each individual example. But, if we look at all three

examples together, it is hard to say which one is the best algorithm out of all. The SCAM

algorithm is the best one for the Orange tree growth data, but it is close to the worst one

for the Variance Components Model. The Adaptive Metropolis-within-Gibbs algorithm

is the best algorithm for the Variance Components Model, but it clearly did a lot worse

than the CMTM algorithm for the Orange tree growth data. The Adaptive Metropolis

did worse than the CMTM algorithm in two our of three examples. Once again, while

not uniformly dominating, the ACMTM seems to perform robustly in all examples thus

minimizing the risk of using an ineﬃcient sampler in a given example.

6 Conclusion and Discussion

It is known that adaptive algorithms can be highly inﬂuenced by initial values given to

their simulation parameters and by the quality of the chain during initialization period,

i.e. the period during which no modiﬁcations of the transition kernel take place. ACMTM

is no exception, but there certain of its features can be thought of as means towards a more

robust behaviour. For instance, the fact that we can start with multiple proposals makes

it less likely that all ﬁve will be poor choices for a given coordinate. The motivation for

ACMTM was given by situations in which the sampler requires very diﬀerent proposals

across coordinates and across regions of the state space. In such situations, traditional

32

adaptive samplers are known to fail unless special modiﬁcations are implemented (Craiu

et al., 2009; Bai et al., 2011), but even these tend to underperform when d is high.

The adaption mechanism is very rapid as, once an alarm is triggered, the scales can

change in multiple of 2’s. The adaption mechanism is also stable since modiﬁcations to the

kernel occur only if over selection from one of the boundary scale proposals is detected.

Thus, if proposal scales are not perfect but good enough, they wouldn’t be changing

under this adaptive design since it is hard to keep choosing one proposal distribution

out of multiple proposal distributions if each of them is useful in a big enough region of

the state space. In other words, once the adaption reaches a good level, the proposal

distributions would be stable and would not be constantly changing.

A general recommendation has been made by Craiu et al. (2009) to run, at least for

a while, a number of adaptive samplers in parallel in order to insulate against a poor

exploration of the state space during the initialization period. This idea can be extended

easily to the ACMTM, especially in this age in which parallel processing is the norm

rather than the exception. The increase in CPU time is the price we pay for the added

ﬂexibility of having multiple proposals and the ability to dynamically choose the ones

that ﬁt the region of the space so that acceptance rate and mixing rates are improved.

And while this tend to attenuate the ACMTM’s eﬃciency dominance, one cannot ﬁnd

among the algorithms we used for comparison in this paper one that is performing better

on average even after taking CPU time into account. This makes ACMTM a safe choice

for multivariate MCMC sampling.

Finally, it is the authors belief that AMCMC samplers will be more used in practice if

their motivation is intuitive and their implementation is easy enough. We believe that the

ACMTM fulﬁlls these basic criteria and further modiﬁcations can be easily implemented

once new needs are identiﬁed.

Acknowledgement

Funding support for this work was provided by individual grants to RC and JSR from

the Natural Sciences and Engineering Research Council of Canada.

33

References

Andrieu, C. and Atchad´e, Y. F. (2007). On the eﬃciency of adaptive MCMC algo-

rithms. Electronic Communications in Probability 12 336–349.

Andrieu, C. and Moulines, E. (2006). On the ergodicity properties of some adaptive

Markov Chain Monte Carlo algorithms. The Annals of Applied Probability 16 1462–

1505.

Andrieu, C. and Thoms, J. (2008). A tutorial on adaptive MCMC. Statist. Comput.

18 343–373.

Atchad´e, Y. F. and Rosenthal., J. S. (2005). On adaptive Markov Chain Monte

Carlo algorithms. Bernoulli 11 815–828.

Bai, Y., Craiu, R. V. and Di Narzo, A. (2011). Divide and C onquer: A mixture-

based approach to regional adaptation for MCMC. J. Comput. Graph. Statist. 20

63–79.

Box, G. E. P. and Tiao, G. C. (1973). Bayesian inference in statistical analysis.

Addison-Wesely, Reading, MA.

Casarin, R., Craiu, R. V. and Leisen, F. (2013). Interacting multiple try algorithms

with diﬀerent proposal distributions. Statistics and Computing 23 185–200.

Craiu, R. V., Gray, L., Latuszynski, K., Madras, N., Roberts, G. O. and

Rosenthal, J. S. (2015). Stability of adversarial markov chains, with an application

to adaptive mcmc algorithms. Annals of Applied Probability 25 3592–3623.

Craiu, R. V. and Lemieux, C. (2007). Acceleration of the multiple-try metropolis

algorithm using antithetic and stratiﬁed sampling. Statistics and Computing 17 109–

120.

Craiu, R. V., Rosenthal, J. S. and Yang, C. (2009). Learn from thy neighbor:

Parallel-chain adaptive and regional MCMC. J. Amer. Statist. Assoc. 104 1454–1466.

34

Davies, O. L. (1967). Statistical methods in research and production. Oliver & Boyd,

Edinburgh and London.

Draper, N. and Smith, H. (1981). Applied regression analysis. John Wiley, New York.

Fort, G., Moulines, E. and Priouret, P. (2011). Convergence of adaptive and

interacting Markov chain Monte Carlo algorithms. The Annals of Statistics 39 3262–

3289.

Gelman, A., Roberts, G. O. and Gilks, W. R. (1996). Eﬃcient Metropolis jumping

rules. In Bayesian Statistics (J. M. B. et al., ed.), vol. 5. Oxford University Press, 599–

607.

Giordani, P. and Kohn, R. (2010). Adaptive independent Metropolis–Hastings by fast

estimation of mixtures of normals. Journal of Computational and Graphical Statistics

19 243–259.

Haario, H., Laine, M., Mira, A. and Saksman, E. (2006). DRAM: eﬃcient adaptive

MCMC. Statistics and Computing 16 339–354.

Haario, H., Saksman, E. and Tamminen, J. (1999). Adaptive proposal distribution

for random walk metropolis algorithm. Computational Statistics 14 375–396.

Haario, H., Saksman, E. and Tamminen, J. (2001). An adaptive Metropolis algo-

rithm. Bernoulli 7 223–242.

Haario, H., Saksman, E. and Tamminen, J. (2005). Componentwise adaptation for

high dimensional MCMC. Computational Statistics 20 265–273.

Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and

their applications. Biometrika 57 97–109.

Lindstrom, M. J. and Bates, D. M. (1990). Nonlinear mixed eﬀects models for

repeated measures data. Biometrics 46 673–687.

Liu, J. S., Liang, F. and Wong, W. H. (2000). The multiple-try method and local

optimization in metropolis sampling. Journal of the American Statistical Association

95 121–134.

35

Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H. and

Teller, E. (1953). Equation of state calculations by fast computing machines. The

journal of chemical physics 21 1087–1092.

Roberts, G. O. and Rosenthal, J. S. (2001). Optimal scaling for various Metropolis-

Hastings algorithms. Statistical science 16 351–367.

Roberts, G. O. and Rosenthal, J. S. (2004). General state space Markov chains

and MCMC algorithms. Probability Surveys 1 20–71.

Roberts, G. O. and Rosenthal, J. S. (2007). Coupling and ergodicity of adaptive

Markov chain Monte Carlo algorithms. Journal of Applied Probability 44 458–475.

Roberts, G. O. and Rosenthal, J. S. (2009). Examples of adaptive MCMC. Journal

of Computational and Graphical Statistics 18 349–367.

Rosenthal, J. S. and Yang, J. (2016). Ergodicity of discontinuous adaptive MCMC

algorithms. Submitted for publication. Available at http://probability.ca/jeff/

ftpdir/adversarial.pdf.

Turro, E., Bochkina, N., Hein, A. M. K. and Richardson, S. (2007). BGX: a

Bioconductor package for the Bayesian integrated analysis of Aﬀymetrix GeneChips.

BMC bioinformatics 8 439–448.

Vihola, M. (2012). Robust adaptive Metropolis algorithm with coerced acceptance

rate. Statistics and Computing 22 997–1008.

36

