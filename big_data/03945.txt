6
1
0
2

 
r
a

 

M
2
1

 
 
]

A
N
.
s
c
[
 
 

1
v
5
4
9
3
0

.

3
0
6
1
:
v
i
X
r
a

On the Petras algorithm for veriﬁed integration of piecewise

analytic functions

Ma lgorzata Moczurad, Piotr Zgliczy´nski

March 15, 2016

Abstract

We consider the algorithm for veriﬁed integration of piecewise analytic functions presented in
Petras’ paper [6]. The analysis of the algorithm contained in that paper is limited to a narrow class
of functions and gives upper bounds only. We present an estimation of the complexity (measured
by a number of evaluations of an integrand) of the algorithm, both upper and lower bounds, for a
wider class of functions. We show examples with complexity Θ(| ln ε|/εp−1), for any p > 1, where
ε is the desired accuracy of the computed integral.

Keywords: rigorous integration, complexity

1

Introduction

In the paper we discuss the complexity of the Petras’ algorithm for veriﬁed integration of piecewise
analytic functions [6]. Reader should be warned that we measure the complexity by a number of
evaluations of an integrand. Therefore we omit the complexity of subroutines in the algorithm, which
the full complexity analysis of the algorithm should take into account. We should mention the proper
treatment of these issues will require a deﬁnition of computable analytic functions. Such deﬁnitions
exist in the literature (see for example [2, 3] and the references given there), however in the present
work we skip these issues and concentrate on the geometric aspects of the problem.
Our task is, given f a piecewise analytic function on [a, b] and ε > 0, to ﬁnd a number I, such that

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z b

a

f (x)dx − I(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

6 ε.

If f is analytic, then there are algorithms for integration (based for example on Gauss-Legendre quadra-
ture) with the apparent complexity O(| ln ε|), where ε is the desired accuracy. It should be stressed that
the constant in O(| ln ε|) depends on the function f , mainly on the shape of its domain of analyticity;
see [4] for a discussion of optimal quadratures depending on the domain of analyticity.

However, a disturbance of analyticity at some points makes the convergence rate deteriorate. For the
sake of discussion, let us call them breakpoints or singularities.

Knowing the location of singularities is not enough; we cannot simply partition the interval at those
points and apply a standard algorithm for analytic functions to smaller intervals. The problem is that
algorithms require the function to be analytic on the interval of integration and its neighbourhood (disk
or ellipse containing the interval in the complex plane).

1

Our case is (seemingly) even more diﬃcult: we know neither the number, nor the location of the
breakpoints; we might not even know whether they exist.

We consider Petras’ algorithm for veriﬁed integration of piecewise analytic functions. The analysis of
the algorithm contained in [6] is not suﬃcient, because the class of functions considered is unnaturally
restricted and only an upper bound for this class is given.

The main result of the paper is a more sophisticated estimation of the complexity of the algorithm for a
wider class of functions. Our results still do not cover the whole range of (piecewise) analytic functions,
but only those that satisfy Petras-type conditions (PPC and NPC) of the order p (see Deﬁnitions 6
and 7). The class of functions considered by Petras in [6] satisﬁes PPC condition of order p 6 1.

The main idea explored in our paper is that the complexity depends mainly on the region of analyticity.
The diﬀerence between a “simple” and a “diﬃcult” function is not that the former is analytic, while
the latter is not. Even an analytic function might be hard for integration, if it has singularities very
close to the real axis. On the other hand, a piecewise analytic function might be relatively simple, if
the region of analyticity around breakpoints is wide (p 6 1 in the Deﬁnition 2).

condition, which in our paper is PPC condition of order p = 1. We show that the complexity depends
on the order p of PPC and NPC conditions that an integrated function satisﬁes, i.e. if p > 1, then the

Originally in [6] Petras showed that the complexity is O(cid:0)ln2 ε(cid:1) for a class of functions satisfying a
complexity is Θ(cid:0)| ln ε|/εp−1(cid:1), while for p 6 1 the complexity is indeed Θ(cid:0)ln2 ε(cid:1). Moreover, we show

examples of functions (see Section 8) for which the complexity scales as | ln ε|/εp−1 for any p > 1.
Notice that the complexity analysis focuses on the phenomena occurring in the close neighbourhood
of singular points, since the most signiﬁcant increase in the number of evaluations of the integrand
takes place there. The number of evaluations generated in the last step of the algorithm (i.e. near
breakpoints) is comparable to the number of evaluations generated in all previous steps. Moreover,
properties considered do not occur globally, but only in the proximity of the breakpoints.

The paper is organized in the following way. Section 2 contains basic deﬁnitions and notations. In
Section 3 we present the Petras’ algorithm. In Section 4 we introduce main tools for the analysis of the
Petras’ algorithm; in particular the Petras-type conditions PPC and NPC are given there. In Sections 5
and 6 we show lower and upper bounds for the complexity of the Petras’ algorithm. Section 7 contains
the main theorem of the paper.

2 Notations and core deﬁnitions

As usual, by N, Z, R, C we denote the sets of natural (including 0), integer, real and complex numbers,
respectively. By N+ and R+ we denote the set of positive natural and real numbers. We use A to
denote the closure of a set A. We will use |z| to denote the absolute value of z ∈ C or z ∈ R. For a
point x ∈ C and a set Z ⊂ C we deﬁne

dist(x, Z) = inf

y∈Z |x − y|.

Deﬁnition 1 Assume that a, b ∈ R and a < b.

1. We say that a function f : C ⊃ dom f → C is a piecewise analytic function on [a, b] if there exist

open, pairwise disjoint sets Dj ⊂ C such that
(a) f is analytic on Dj and

dom f ∩ {x + iy : a 6 x 6 b} ⊂

∞[j=1

Dj,

2

(b) Dj ∩ [a, b] = (aj, bj) and

2. The domain of analyticity of f is

[a, b] =

doa f =

(aj, bj)

∞[j=1
∞[j=1

Dj.

Example 1 Some examples of piecewise analytic functions on [−1, 1]:

• all analytic functions, such that their domain contains [−1, 1],
• the function f (z) = exp(−1/z2),
• the function f (z) = | sin(1/z)|.

Let S = {s1, . . . , sm} ⊂ R, where a 6 s1 < . . . < sm 6 b, be a set of points such that the function f is
analytic in each open interval (si, si+1) for i = 1, . . . , m − 1.

Deﬁnition 2 For a given γ, p > 0 and a set S deﬁne a region (see Figure 1)

Dp
γ,S := {x + iy : |y| 6 γ · dist(x, S)p}.

When S is a singleton and its element is clear from the context, we omit the subscript S and write Dp
γ.
Notice that Vγ,S used in [6] is a special case of Dp

γ,S, i.e. Vγ,S = D1

γ,S.

si−1

si

si+1

Figure 1: Region Dp

γ,S between si−1 and si+1 with p > 1.

As usual we use Qn,[α,β][f ] to indicate an n-point quadrature formula for the evaluation of an integral
of f over [α, β]. Rn,[α,β][f ] is the error of the quadrature, i.e.

α

Rn,[α,β][f ] =(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z β
̺(α, β, A, B) =(cid:26)x + iy :(cid:12)(cid:12)(cid:12)(cid:12)x −

f (x)dx − Qn,[α,β][f ](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12) 6 A

β − α

2

2

β + α

.

,|y| 6 B

β − α

2 (cid:27) .

Deﬁnition 3 For ﬁxed A > 1, B > 0, let the rectangle ̺(α, β, A, B) in the complex plane (see Figure 2)
be deﬁned as

When parameters A, B are clear from the context, we omit them and write ̺(α, β).

Deﬁnition 4 For ﬁxed A > 1, B > 0, let m(f ; α, β, A, B) be given by

m(f ; α, β, A, B) = sup{|f (z)| : z ∈ ̺(α, β, A, B) ∩ dom f}.

When parameters A, B are clear from the context, we omit them and write m(f ; α, β).

3

d
2

− d

2

α

β

α+β

2

d = β − α

Figure 2: Rectangle ̺(α, β, A, B) = {x + iy : α+β

2 − A d

2

6 x 6 α+β

2 + A d

2 , −B d

2

6 y 6 B d
2}

Originally in [6] the functional m has a diﬀerent meaning: it is a functional (or perhaps an algorithm)
which returns a value greater or equal to

sup{|f (z)| : z ∈ ̺(α, β, A, B) ∩ dom f},

which in this paper is realized by a function ComplexBound (see the beginning of Section 3).

For the estimation of error of the quadrature we need to see what is the size of the largest ellipse with
the foci at (α, 0) and (β, 0) which is contained in ̺(α, β, A, B).

Lemma 1 Let A > 1. If an ellipse with foci at F1 = (α, 0), F2 = (β, 0), major a = A(β − α)/2
and minor semi-axis b = B(β − α)/2 is inscribed (i.e. tangent to the edges) in ̺(α, β, A, B), then
B = √A2 − 1.

Proof. By deﬁnition of an ellipse the distance from the center of the ellipse to the focal point is

√a2 − b2, thus

This gives

β − α

2

−(cid:18) B(β − α)

2

(cid:19)2

.

=s(cid:18) A(β − α)

2

(cid:19)2
B =pA2 − 1.

By the above lemma parameters A and B of ̺ are not independent if we want to inscribe an ellipse

into ̺(α, β, A, B). Therefore, in the sequel, we will use B = √A2 − 1, only.
For [α, β] = [−1, 1] we have a = A and b = B. In particular for A = 5
ellipse contained in ̺(−1, 1, A, B) has c = a + b = 2.

4 we have B = 3

4 and the largest

Remark 2 Let A = 5

4 and B = 3

4 . Then

Rn,[α,β][f ] 6 2 · 4−n · (β − α)m(f ; α, β)
Rn,[α,β][f ] 6 3 · 2−n · (β − α)m(f ; α, β)

(Gaussian quadrature)

(Clenshaw-Curtis quadrature)

(1)

(2)

for functions analytic on ̺(α, β, A, B).

Proof. This not a real proof, but an explanation of the denominators in these formulas. For references
regarding the constants used see [1] and [5].

The map

T (z) =

α + β

2

+

β − α

2

z

4

is an aﬃne isomorphism, such that T (̺(−1, 1, A, B)) = ̺(α, β, A, B). The formulas for Gauss or
Clenshaw-Curtis quadratures and their errors are transported from [−1, 1] to [α, β] by this map.
On the normalized interval [−1, 1] the error of Gauss quadrature contains the term 1/c2n, where c is
the sum of major and minor semi-axes. The transformation of [α, β] onto [−1, 1] multiplies this error
by β − α and gives c = 2 (see Lemma 1). Therefore we obtain the factor (β − α)/22n = 4−n · (β − α).

3 Petras’ algorithm

In this section we recall an algorithm from [6] for the veriﬁed integration of piecewise analytic functions.
We will call it the Petras’ algorithm. There are three enigmatic points in the algorithm: (1) calculating
an upper bound for ||f||∞, (2) checking the analyticity and (3) boundedness of f . We assume that
there exist subroutines (or oracles):

require that the converse is true,

• UpperBound(f, a, b) which returns an upper bound M for ||f||∞ = supx∈[a,b] |f (x)|,
• IsAnalytic(f, α, β, A) such that if it is true, then f is analytic on ̺(α, β, A,√A2 − 1); we do not
• ComplexBound(f, α, β, A) returning a value greater than or equal to m(f ; α, β, A,√A2 − 1) pro-
vided that f is analytic on ̺(α, β, A,√A2 − 1).

In further analysis of Petras’ algorithm we will formulate some conditions regarding the properties of
the above functions, however we will not include their cost in the complexity estimations, even though
they might be hard to compute and depend substantially on f . These issues will require the precise
deﬁnition of computable analytic functions (see for example [2, 3] and the references given there), which
we do not consider in this paper.

3.1 Formulation of the algorithm

The input of the algorithm consists of:

• the integrand f and the interval of integration [a, b]; we require that f is piecewise analytic and

bounded on [a, b],

• an accuracy bound, ε > 0.

The algorithm also uses conﬁguration constants:

• A > 1 is used in the deﬁnition of the area ̺ (see Deﬁnition 3) which is needed to compute
IsAnalytic and ComplexBound functions (recall that B = √A2 − 1),
• the number c > 1 for the estimation of function values.

The algorithm is as follows.

In: f, [a, b], ε

1. We choose a sequence (Qn)n∈N of quadrature formulas to be Gaussian or Clenshaw-Curtis, i.e.
we determine constants D and E (compare with (1) and (2) in Remark 2). These quadratures
satisfy error estimates of the form

Rn,[α,β][f ] 6 D · E−n · (β − α)m(f ; α, β)

5

for functions analytic on ̺(α, β, A,√A2 − 1).

2. M := UpperBound(f, a, b);

3. Assume that we have already partitioned [a, b] into k intervals, i.e.

[a, b] := [a0, a1] ∪ [a1, a2] ∪ . . . ∪ [ak−1, ak]

and there is J ⊂ {1, . . . , k} such that

IsAnalytic(f, aj−1, aj, A) and ComplexBound(f, aj−1, aj, A) 6 cM,

|aj − aj−1| >

ε
2M

.

Xj6∈J

for j ∈ J

(3)

(4)

We choose among intervals not belonging to J the longest interval and bisect it. Repeat step 3
as long as the condition (4) holds.

4. NowPj6∈J |aj − aj−1| 6 ε

Qn, where

2M (condition (4) does not hold) and

a) for the intervals [aj−1, aj] where j ∈ J we calculate the integral using a quadrature formula

n >

1

ln E

ln

2D(b − a)cM

ε

,

(5)

b) for all remaining intervals we take the value of the integral to be 0.

Out: q :=Pj∈J Qn;[aj−1,aj ][f ]
Remark 3 The requirement in (3) that f is analytic on ̺(aj−1, aj, A,√A2 − 1) was missing in Petras’

original paper [6].

3.2 Numerical accuracy

Lemma 4 Assume that the Petras’ algorithm stops returning q. Then

Z b

a

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f (x)dx − q(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

< ε.

(6)

Proof. For each [α, β] for which m(f ; α, β) 6 cM we want the error of the quadrature to be less than

(β − α)

ε

2(b − a)

,

so that summing the error over all intervals we obtain the global error on [a, b] less than or equal to
ε/2. We can calculate n, for all intervals, using an estimate

Rn,[α,β][f ] 6 D · E−n · (β − α)m(f ; α, β) 6 D · E−n · (β − α)cM < (β − α)

ε

2(b − a)

and obtain

Now we can estimate the total error of the quadrature on all the intervals belonging to J:

n >

1

ln E

ln

2D(b − a)cM

ε

.

Xj∈J

Rn;[aj−1,aj ][f ] 6 Xj∈J

(aj − aj−1)
ε

2(b − a)

6

(b − a) =

2(b − a)

ε

ε
2

6

6

ε

2(b − a)Xj∈J

(aj − aj−1)

The error of the integration on the intervals not belonging to J is not greater than M · ε/(2M ) = ε/2
(an upper bound for ||f||∞ times the total length of intervals where we do not use a quadrature).
Therefore we obtain

Rn,[a,b][f ] = Xj∈J

Rn;[aj−1,aj ][f ] +Xj6∈J

Rn;[aj−1,aj ][f ] 6

ε
2

+

ε
2

= ε.

3.3 The algorithm stops under reasonable assumptions

It is not obvious whether the algorithm stops. If the function ComplexBound returns values which do not
“match” the bound c·supx∈[a,b] |f (x)| (for example, it always returns 2, while c·supx∈[a,b] |f (x)| ≈ 1) the
algorithm might run forever. Thus we have to assure that such case will never happen. For this we need
to provide certain assumptions regarding the quality (but not complexity) of functions IsAnalytic and
ComplexBound.

Deﬁnition 5 Let A > 1. We say that the algorithms IsAnalytic and ComplexBound satisfy the
compatibility condition if for any z ∈ [a, b] such that f is analytic in some neighbourhood of z, there
exists an open set U ⊂ C, such that z ∈ U and

if [α, β] ⊂ U then IsAnalytic(f, α, β, A) and ComplexBound(f, α, β, A) 6 c · UpperBound(f, a, b).

Theorem 5 Assume that f is piecewise analytic and the Lebesgue measure of points in [a, b] in which
f is not analytic is equal to zero. If functions IsAnalytic and ComplexBound satisfy the compatibility
condition, then Petras’ algorithm stops.

Proof. From the assumptions about IsAnalytic and ComplexBound functions it follows that any
interval created during the Petras’ algorithm containing only the points of analyticity will be subdivided
(possibly after several subdivisions) into smaller intervals that will eventually be accepted.

Hence the total length of bad intervals (not in J) goes to zero and the algorithm stops.

Remark 6 From now on, suprema on the real axis, analyticity check and the functional m should be
understood as values returned by the above subroutines. For the sake of simplicity we use M to denote
UpperBound(f, a, b).

3.4 The case of analytic functions

Lemma 7 Assume that f is analytic on [α, β] ⊂ [a, b] and algorithms IsAnalytic and ComplexBound
satisfy the compatibility condition. Then the number of intervals accepted in the Petras’ algorithm and
covering [α, β] is ﬁnite and does not depend on ε.

It follows from the compactness of [α, β] and the compatibility condition (see Deﬁnition 5)
Proof.
that there exists δ, such that any interval of length less than or equal to δ is accepted by the Petras’
algorithm.

7

4 Tools for the analysis of the algorithm

The Petras’ algorithm has two parts: geometrical and computational. During the geometrical part
(step 3) a partition of an interval [a, b] is constructed based on a region of analyticity and boundedness D.
In the computational part (step 4), the integral is computed using a chosen quadrature on each of the
resulting sub-intervals.
For a piecewise analytic function f and a ∈ R+ we deﬁne the region of analyticity and boundedness as

D(f, a) = {z ∈ C | z ∈ doa f ∧ |f (z)| 6 a}.

Notice that in the perfect world, in the geometrical part the actual object of concern should be the
set D = D(f, c · supx∈[a,b] |f (x)|). However, the set D is not known explicitly. Instead, the algorithm
implicitly analyses the set D(f, cM ) ⊂ D. It follows that (in our analysis) it is the geometric properties
of D (and not the details of the function f ) that inﬂuence the actual complexity of the algorithm.
Further in the complexity estimations we use the following notations: intervals to be bisected are called
“bad” and those that need not be bisected are “proper.”

The number of proper intervals generated by Petras’ algorithm is denoted by

Z(D(f, cM ), ε).

Recall that on each of the proper intervals the quadrature (Gauss-Legendre or Clenshaw-Curtis) with

n =(cid:24) 1

ln E

ln(cid:18)2Dc ·

M (b − a)

ε

(cid:19)(cid:25) = Θ(| ln ε|)

points (see (5) in step 4 of the algorithm) is calculated, thus the algorithm performs

evaluations of f . To complete the estimation of complexity we need to count the number of proper
intervals generated by the algorithm.

N (f, ε) = Θ(| ln ε|) · Z(D(f, cM ), ε)

For any p > 1 we give examples of functions for which

Z(D(f, cM ), ε) = Θ(cid:18) 1

εp−1(cid:19) ,

while the analysis in Petras’ paper deals with the classes of functions for which

Z(D(f, cM ), ε) = O(| ln ε|).

4.1 Petras-type conditions

Let us ﬁx A and B = √A2 − 1. In [6] Petras proposed a condition (we added the analyticity requirement

missing in [6])

∃γ > 0 ∀α, β : "̺(α, β) ⊂ Vγ,S =⇒ f is analytic on ̺(α, β) and m(f ; α, β) 6 c

x∈[−1,1]|f (x)|#

sup

to estimate the complexity of the algorithm. We ﬁnd this requirement too strong as it excludes a lot
of functions.

Before presenting our generalization of the Petras’ condition we state several theorems for the function
f (x) = sin(1/x) for x ∈ [−1, 1], in order to illustrate that this condition does not hold and to motivate
the use of the sets Dp

γ,S in further analysis.

8

Theorem 8 Let us take an arbitrary Z > 0. Let f (z) = sin(1/z).
condition

∃γ > 0 ∀α, β ∈ [−1, 1] :  ̺(α, β) ⊂ Vγ,{0} =⇒

z∈̺(α,β)|f (z)| 6 Z!

sup

In the neighborhood of 0 the

does not hold for any γ > 0, i.e.

∀γ > 0 ∃α, β ∈ [−1, 1] :  ̺(α, β) ⊂ Vγ,{0} ∧

z∈̺(α,β)|f (z)| > Z! .

sup

Proof. Assume z = x + iy. Let r2 = x2 + y2. Then

(7)

(8)

(9)

Since

we obtain

and

sin(1/z) =

1
z

=

x − iy

r2

.

sin(1/z) =

exp (i/z) − exp (−i/z)

2i

1

2i(cid:16)exp(cid:16)i

x

x

r2(cid:17) exp(cid:16) y
2(cid:18)exp(cid:18)|y|

r2(cid:17) − exp(cid:16)−i
r2(cid:19) − exp(cid:18)−|y|

r2(cid:17) exp(cid:16)−
r2(cid:19)(cid:19) .

1

y

r2(cid:17)(cid:17)

| sin(1/z)| >

For any γ > 0 consider a point z = x + iγx with x > 0. Since y = γx > 0 there is

|y|
r2 =

γx

γ2x2 + x2 =

γ

x(γ2 + 1)

and ﬁnally by (9) we have

| sin(1/z)| >

1

2(cid:18)exp(cid:18)

γ

x(γ2 + 1)(cid:19) − exp(cid:18)−

γ

x(γ2 + 1)(cid:19)(cid:19)

→ ∞,

as x → 0.

Condition (7) in the above theorem is not satisﬁed since on the border of Vγ the absolute value of

sin(1/z) is too large. This is due to the fact that the term exp(cid:0)|y|/r2(cid:1) grows to inﬁnity as z → 0. A
workaround is to restrict the values of exp(cid:0)|y|/r2(cid:1); however this leads to a diﬀerent region, i.e. D2

Theorem 9 Let S = {0} and let f (z) = sin(1/z). Then for any c > 1 there exists γ > 0 such that

γ,S.

sup
z∈D2
γ

|f (z)| 6 c ·

x∈[−1,1]|f (x)|.
sup

(10)

Therefore for any α, β ∈ [−1, 1]

̺(α, β) ⊂ D2

γ =⇒ f is analytic on ̺(α, β) ∧

z∈̺(α,β)|f (z)| 6 c ·
sup

x∈[−1,1]|f (x)|.
sup

(11)

If ̺(α, β) ⊂ D2
Proof.
second part of the thesis.

γ then it is obvious that f is analytic on ̺(α, β). Thus it is enough to check the

9

Assume z = x + iy. Let r2 = x2 + y2. As in the proof of Theorem 8 we have

sin(1/z) =

and then

For γ > 0 let us deﬁne Wγ by

| sin(1/z)| 6

y

r2(cid:17)(cid:17)

1

2i(cid:16)exp(cid:16)i

1

x

x

r2(cid:17) exp(cid:16) y
2(cid:18)exp(cid:18)|y|
Wγ =(cid:26)x + iy :

r2(cid:17) exp(cid:16)−
r2(cid:17) − exp(cid:16)−i
r2(cid:19)(cid:19) .
r2(cid:19) + exp(cid:18)−|y|
6 γ(cid:27) .

|y|
r2

We have (because function x 7→ x + 1

x is increasing for x > 1)

Since

| sin(1/z)| 6

1
2

(exp(γ) + exp(−γ)) ,

z ∈ Wγ.

1
2

lim
γ→0

(exp(γ) + exp(−γ)) = 1,

by taking γ suﬃciently close to 0 we get

z∈Wγ |sin (1/z)| < c ·
sup

x∈[−1,1]| sin(1/x)|.
sup

To complete the proof it is enough to show that D2
is easy to see that Wγ describes the complement of a disk of radius 1

γ ⊂ Wγ. Let y > 0 (the other case is symmetric). It

2γ centred at(cid:16)0, 1

2γ(cid:17), i.e.

z = x + iy ∈ Wγ ⇐⇒ (cid:18)y −

1

2γ(cid:19)2

+ x2 >

1
4γ2 .

Observe that Wγ contains the following set

fWγ =(x + iy :

and notice that for |x| 6 1

2γ

|x| 6

1
2γ

;

|y| 6

1 −p1 − 4γ2x2

2γ

) ∪(cid:26)x + iy :

|x| >

1

2γ(cid:27)

1 −p1 − 4γ2x2

2γ

> γx2.

γ ⊂ fWγ ⊂ Wγ.

This shows that D2
Theorem 9 says that for z 7→ sin(1/z) there exists a region D2
γ where the function is analytic and
appropriately bounded. The next theorem says the opposite: there exists a region of the same shape
as before, but such that (on the boundary of this region close to the singular point) the values of the
function are arbitrarily large.

Theorem 10 Let S = {0} and let f (z) = sin(1/z). For any c > 1 there exists γ > 0 such that for any
α ∈ [−1/γ, 1/γ] and β ∈ (α, 1]
̺(α, β) 6⊂ D2

γ =⇒ f is not analytic on ̺(α, β) ∨ sup

z∈̺(α,β)|f (z)| > c.

(12)

10

Proof. Let us ﬁx c > 1. If α < 0 < β then f is not analytic on ̺(α, β).
Let us consider the case when f is analytic on ̺(α, β). Notice that if ̺(α, β) 6⊂ D2
∅, where ∂D2

γ is a border of D2

γ. Thus let us consider the region
Wγ = ∂D2

γ ∩ {z : Re(z) ∈ [−1/γ, 1/γ]} \ {0}.

γ then ̺(α, β)∩ ∂D2

γ 6=

Then

z∈̺(α,β)|sin(1/z)| > inf
sup

z∈Wγ |sin(1/z)| .

Assume z = x + iy ∈ Wγ and let r2 = x2 + y2. Then (for |x| 6 1/γ)
γ
2

x2 + (γx2)2 =

|y|
r2 =

1 + γ2x2

γx2

>

γ

.

Since (see proof of Theorem 8)

|sin(1/z)| >

and x 7→ x − 1

x is an increasing function we have
1

1

2(cid:18)exp(cid:18)|y|
2(cid:16)exp(cid:16) γ

r2(cid:19) − exp(cid:18)−|y|
r2(cid:19)(cid:19)
2(cid:17)(cid:17) .
2(cid:17) − exp(cid:16)−

γ

z∈Wγ |sin(1/z)| >
inf

γ > 2 ln(c +p1 + c2)

Now, for any c > 1 it is enough to take γ > 0 such that inf z∈Wγ | sin(1/z)| > c, i.e.

and the condition (12) holds.

The above investigations justify why we consider regions bounded by curves γxp. We do realize that
this choice is arbitrary and non-exhaustive. Nevertheless it allows us to show that region of analyticity
is an important parameter in the complexity investigations. In Section 8 we consider the functions
f (z) = zk sin(1/z) which need regions of the form Dp
γ.
Although so far we have considered only p > 1, we can in fact state deﬁnitions for any p ∈ R+. We
present modiﬁed Petras’ condition introducing the notion of order and a converse implication. Notice
that in Deﬁnitions 6 and 7, ̺ and m are implicitly dependent on A and B.

Deﬁnition 6 Let us ﬁx A, B and c > 1. We say that a function f satisﬁes positive Petras’ condition
of order p (abbreviated as PPC(p, γ, S)) on [a, b], if there exist S = {s1, . . . , sm} with a 6 s1 < . . . <
sm 6 b and γ > 0 such that
̺(x, y) ⊂ Dp

γ,S =⇒ f is analytic on ̺(x, y) and m(f ; x, y) 6 cM,

(13)

Deﬁnition 7 Let us ﬁx A, B and c > 1. We say that a function f satisﬁes negative Petras’ condition
of order p (NPC(p, γ, s, β)) on [a, b], if there exist s ∈ [a, b], γ > 0 and β > 0 such that one of the
following two conditions is satisﬁed

for all x, y such that [x, y] ⊂ [a, b].

̺(x, y) 6⊂ Dp

γ =⇒ either (f is not analytic on ̺(x, y)) or m(f ; x, y) > cM,

for all x, y such that x ∈ [s, s + β] and y ∈ (x, b],

̺(x, y) 6⊂ Dp

γ =⇒ either (f is not analytic on ̺(x, y)) or m(f ; x, y) > cM,

for all x, y such that y ∈ (s − β, s] and x ∈ [a, y],

(14)

(15)

We refer to (14) as (NPC(p, γ, s, β))-right and (15) as (NPC(p, γ, s, β))-left.

11

γ = Dp

γ,{s}.

Notice that in the above deﬁnition Dp
The idea (how we use PPC and NPC conditions to estimate the number of proper intervals) is presented
in Remark 11 and a more detailed treatment follows in Section 5.1. Notice that, in general, we want
to point out the classes of functions for which the complexity of Petras’ algorithm is Θ(| ln ε|/εp−1).
Therefore we consider only those functions for which NPC and PPC are satisﬁed. To show that the
complexity of the algorithm cannot be better it is enough to show one singular point of f where the
number of proper intervals generated by the algorithm is Ω(1/εp−1) — a lower bound. To show that
the complexity of the algorithm is not worse we have to prove that in any point of S the algorithm
cannot produce more proper intervals than O(1/εp−1) — an upper bound.
Remark 11 Let D = D(f, cM ). Assume that a function f satisﬁes PPC(p, γ,{s}) and NPC(p′, γ′, s, β)
(with γ′ > γ, p′ 6 p) on the whole interval, i.e. x ∈ [a, b] in (14,15), therefore Dp
γ ′. If
we consider intervals [α, x], [α, α′] and [α, y] such that ̺(α, x) ⊂ Dp
γ, ̺(α, α′) ⊂ D and (̺(α, y) 6⊂
intDp′
γ ′), then [α, x] ⊂ [α, α′] ⊂ [α, y]. Thus investigating intervals in Dγ (they are
the shortest and therefore their number is the largest) we are able to estimate the number of proper
intervals from above. And while investigating intervals on the edge of Dγ ′ (the longest ones) we are
able to estimate the number of proper intervals from below.

γ ′ ∧ ̺(α, y) ⊂ Dp′

γ ⊂ D ⊂ Dp′

4.2 Geometric lemmas

Let us ﬁx S = {0}. We deﬁne

DΓ = {x + iy :

|y| 6 Γ(x)},

where Γ :
this section is to ﬁnd, for a ﬁxed x or y, the largest possible d = y − x such that ̺(x, y, A, B) ⊂ DΓ.

[0,∞) → [0,∞) is continuous, Γ(0) = 0 and Γ is strictly increasing for x > 0. The goal of

Γ(x)

0

x

y

Figure 3: Points x and y are chosen so that the top left corner of ̺(x, y, A, B) belongs to the line
x 7→ Γ(x).
By the deﬁnition of ̺ the top left corner of ̺(x, x + d, A, B) is at

and we want this point to lie on the line x 7→ Γ(x), thus (see Figure 3)

d
2

.

(16)

(cid:18)x −
Γ(cid:18)x −

d
2

d

(A − 1), B

2(cid:19)
(A − 1)(cid:19) = B

d
2

This is the desired formula for d = y − x parametrized by x, the left end of the interval. To obtain a
formula parametrized by y we substitute y − d for x in equation (16) and obtain

Γ(cid:18)y −

d
2

(A + 1)(cid:19) = B

d
2

.

(17)

12

Theorem 12 There exist strictly increasing, continuous functions dL, dR : [0,∞) → [0,∞) solving
equations (16), (17), respectively. Moreover:

dL(x) <

dR(y) <

2
B
2
B

Γ(x),

x > 0,

Γ(y),

y > 0.

(18)

(19)

It is clear that dL is strictly increasing in x. It is enough to translate ̺(x, y, A, B), with top
Proof.
left corner on the line x 7→ Γ(x), to the right. The shifted rectangle will be contained in the interior of
DΓ. Similarly, dR is increasing in y.
For the proofs of (18) and (19) observe that for x > 0 it holds

B
2
B
2

dL(x) = Γ(cid:18)x −
dR(y) = Γ(cid:18)y −

A − 1

2

A + 1

2

dL(x)(cid:19) < Γ (x)
dR(x)(cid:19) < Γ(y).

We would like to obtain bounds of the following form

c2Γ(x) 6 dL(x), dR(x) 6 c1Γ(x),

(20)

for some c1, c2 > 0. The existence of c1 follows from Theorem 12. The existence of c2 is treated in
Section 4.2.1 for Γ(x) = γxp, p > 1. It turns out that for p 6 1 this is not true; in fact we obtain linear
estimates from above and from below (see Theorem 16 and equation (33)).

For the case Γ(x) = γxp let us set

h =

B
2γ

.

Then observe that equations (16) and (17) have the following form

provided that we set either

or

(x − g · d)p = h · d,

g = gL = (A − 1)/2,

g = gR = (A + 1)/2,

(21)

respectively. Equation (21) deﬁnes implicitly a function d(x).
estimate d(x).

In the following subsections we will

4.2.1 The case p > 1

Our goal in this section is to develop some estimates for the solution of (21) for p > 1. To develop
intuitions consider an integer p and a series expansion of d(x) = d0 + d1x + d2x2 + . . . . Regrouping
the terms in (21) and taking d0 = 0 we obtain

d(x) =

=

=

xp + dp+1xp+1 + ...

xp(1 + dp+1x + ...)

1
h
1
h
c(x)
h · xp,

13

where c(x) = O(1) for small x. These considerations lead us to a hypothesis that

d(x) =

c(x)
h · xp

(22)

for any p > 1, such that there exist c1, c2 and

0 < c2 6 c(x) 6 c1,

for a bounded range of x. Therefore from (21) and (22) we have the following implicit equation for c(x)

(cid:18)1 − g ·

For given g, h and p > 1 deﬁne

Lemma 13 Let us consider the equation

c(x)

h · xp−1(cid:19)p
˜x =(cid:18) h
g(cid:19) 1

p−1

= c(x).

.

F (x, c(x)) =(cid:16)1 − c(x) ·

g

h · xp−1(cid:17)p

− c(x) = 0.

This equation has exactly one solution c(x) ∈ [0, 1] which is continuous on [0, ˜x] and

(23)

(24)

∀x ∈ [0, ˜x] ∃c′, c′′ : (0 < c′′ < c′ = 1) ∧ (c′′ 6 c(x) 6 c′).

Proof. Notice that for every x, F (x, 1) < 0 and F (x, 0) = 1 > 0 thus there exists c ∈ (0, 1] such that
F (x, c) = 0. We now show the uniqueness of c:

∂F
∂c

= p(cid:16)1 − c ·

g
h

xp−1(cid:17)p−1(cid:16)−

g
h

xp−1(cid:17) − 1 < 0.

The function c : [0, ˜x] → (0, 1] is continuous. Since [0, ˜x] is compact, there exists x0 ∈ [0, ˜x] such that

hence c′′ = c(x0) is the bound we need.

∀x ∈ [0, ˜x] : 0 < c(x0) 6 c(x)

The following theorem gives us the desired upper and lower estimates for d(x).

Theorem 14 Let p > 1 and d(x) be the smallest nonnegative solution of (21). Then there exist
0 < c2 < c1 such that for x ∈ [0, 1]

(25)

c2 · xp 6 d(x) 6 c1 · xp.

Proof. By (22) we have d(x) = xpc(x)/h. Let ˜x be as in (23), then by Lemma 13 we immediately
obtain:

for some 0 < ˜c2 < ˜c1. For x ∈ [˜x, 1] by Theorem 12 we have:

˜c2 · xp 6 d(x) 6 ˜c1 · xp,

x ∈ [0, ˜x]

• d(x) is strictly increasing, thus there exists ¯c2 > 0 such that d(x) > ¯c2xp;
• d(x) < 2γxp/B, thus there exists ¯c1 > ¯c2 such that d(x) 6 ¯c1 · xp.

Taking c1 = max{˜c1, ¯c1} and c2 = min{˜c2, ¯c2} we obtain the thesis.

14

4.2.2 The case p < 1

Consider the equation (21) for 0 < p < 1:

(x − g · d)p = h · d
p · d

x − g · d = h

1

1

p .

Similar considerations as before for p > 1 lead us to a hypothesis that

d(x) =

x

g 1 − c(x) ·

h

g

1
p

1

p · x

1

p −1!

(26)

(27)

where c(x) is a bounded positive function. Substituting (27) for d in (26) we obtain the following
implicit equation for c(x)

c(x) = 1 − c(x) ·

1
p

1

p · x

h

g

p

1

p −1! 1

.

As in the case p > 1 let us deﬁne, for given g, h and p < 1

Now, for p < 1 we have an analogue of Lemma 13.

1−p

h(cid:17) 1
˜x =(cid:16) g

Lemma 15 Let us consider the equation

F (x, c(x)) = 1 − c(x) ·

h

g

1
p

1

p · x

.

p

1

p −1! 1

− c(x) = 0.

This equation has exactly one solution c(x) ∈ [0, 1] which is continuous on [0, ˜x] and

∀x ∈ [0, ˜x] ∃c′, c′′ : (0 < c′′ < c′ = 1) ∧ (c′′ 6 c(x) 6 c′).

From (27) and the above lemma we obtain the following bounds for d(x).

Theorem 16 Let p < 1 and d(x) be the smallest nonnegative solution of (21). Then there exist
0 < c2 < c1 such that for x ∈ [0, ˜x], where ˜x is as in (29),

x(cid:18) 1

g − c1 · x

1

p −1(cid:19) 6 d(x) 6 x(cid:18) 1

g − c2 · x

1

p −1(cid:19) .

(28)

(29)

(30)

(31)

(32)

(33)

4.2.3 The case p = 1

The equation (21) for p = 1 has a form

thus we obtain

x − g · d = h · d,

d(x) =

x

g + h

.

Remark 17 In further analysis we will refer to Theorem 16 with p = 1 (as it holds for p 6 1). Thus
it is suﬃcient to consider two cases, p > 1 and p 6 1.

15

5 Lower bound under NPC condition

We assume

• [a, b] = [−1, 1],
• D = D(f, cM ),
• f satisﬁes NPC(p′, γ′, s, β)-right (with s ∈ S, γ′ > γ, p′ 6 p).

Therefore D ∩ {x + iy | x ∈ [s, s + β]} ⊂ Dp′

calculations we assume that s = 0.

γ ′ ∩ {x + iy | x ∈ [s, s + β]}. For the sake of simplicity of

5.1 Rightward ﬂow

We are interested in the number of proper intervals generated in the segment [s, β] by the Petras’
algorithm (computing the integral attaining global precision ε on [a, b]). In this section we deﬁne a
rightward ﬂow and we estimate this number from below by the number of steps in this ﬂow. For the
estimation from above we deﬁne, in Section 6.2, a leftward ﬂow.

We will refer to the manner in which the algorithm creates successive intervals as a Petras’ process.
During this process we obtain a sequence of proper intervals

s 6 α0 < α1 < . . . < αn, with αn−1 < β 6 αn,

(34)

where α0 6

ε
2M

.

The NPC(p′, γ′, s, β)-right condition implies that there exist s and β, such that NPC(p′, γ′, s, β) holds
for x ∈ [s, s + β]. Recall that we use s = 0 thus β can be treated as a distance from the singular point.
1. We start from x0 = α0, where α0 is the point (close to s) where Petras’ process has ﬁnished

bisecting intervals.

2. Each new interval [xi, xi+1] is created in such a way that ̺(xi, xi+1) ⊂ Dp′

γ ′ and upper left corner
γ ′. Observe that all longer intervals [xi, xi+1 + δ], δ > 0

of ̺(xi, xi+1) is on the boundary of Dp′

lack this property.

3. We count the number of steps needed to exit the interval [s, β] to the right, i.e. to have xm−1 <

β 6 xm.

This process creates a sequence of intervals

α0 = x0 < x1 < . . . < xm−1 < β 6 xm.

Each successive point xn+1 is chosen as

where function dL(x) is equal to d(x) that solves equation (21) with

xn+1 = xn + dL(xn),

h =

B
2γ′ ,

g = gL =

A − 1

2

.

(35)

(36)

(37)

By (14) if xn 6 β, then on any rectangle ̺(w1, w2) containing ̺(xn, xn+1), either the function f is not
analytic, or supz∈̺(xn,xn+1) |f (z)| > cM , so that [w1, w2] will not be accepted by the Petras’ algorithm
as a proper interval.

Estimates for dL(x) are given by Theorem 14 (for p > 1), Theorem 16 (for p < 1) and (33) (for p = 1).

16

5.2 Estimation of the number of proper intervals from below

Below we consider functions that satisfy NPC(p, γ, 0, β)-right (Lemma 18 and 19). The case of functions
satisfying NPC(p, γ, 0, β)-left is analogous.

5.2.1 Case p > 1

Lemma 18 Assume that p > 1 and f satisﬁes NPC(p, γ, 0, β)-right. Then, for suﬃciently small ε, in
the segment [0, β]

Z(D, ε) = Ω (cid:18) 1

ε(cid:19)p−1! .

Proof. Let
follows that there exists c1 > 0, such that

ε
2M

< β. Let t be the number of proper intervals in [0, β]. From (36) and Theorem 14 it

therefore

dR(x) 6 c1 · xp,

αi+1 − αi < dR(αi) 6 c1 · αp
i .

It is easy to see that if x(t) is a solution of x′ = c1 · xp with an initial condition x(0) =

x(i) > αi,

i = 0, . . . , t.

ε
2M

, then

The solution of x′ = c1 · xp is given by
x(t) =

x(0)

,

1

p−1

[1 − x(0)p−1c1(p − 1)t]

hence we can calculate the exit time to the right fromh ε
c1(p − 1) −
Z(D, ε) = Ω (cid:18) 1

, βi (taking x(t) = β), i.e.
c1(p − 1)βp−1 .
ε(cid:19)p−1! .

Therefore (see Deﬁnition 8)

1
εp−1 ·

(2M )p−1

t >

2M

1

(38)

5.2.2 Case p 6 1

Lemma 19 Assume that p 6 1 and f satisﬁes NPC(p, γ, 0, β)-right. Then, for suﬃciently small ε, in
the segment [0, η], where η = min{˜x, β}, for ˜x as in (29),

Z(D, ε) = Ω(cid:18)ln

1

ε(cid:19) .

Proof. Let η = min{˜x, β} and
(37) we set

ε
2M

< η. Let k be the number of proper intervals in [0, η]. Following

gR =

A − 1

2

.

17

(39)

By Theorem 16 it follows that there exists c2 such that for x ∈ [0, ˜x]
x
.
gR

gR − c2 · x

dR(x) 6 x(cid:18) 1

p −1(cid:19) 6

1

Now, for αi ∈ [0, η], we have

thus

and, since α0 6

ε
2M

αi+1 − αi 6 dR(αi) 6

αi
gR

αi+1 6 αi(cid:18)1 +

1

gR(cid:19)

, we obtain

αi 6 α0(cid:18)1 +

Therefore in particular

and

η 6

k >

ε

1

gR(cid:19)i

.

ε

1

1

6

2M (cid:18)1 +
gR(cid:19)i
2M (cid:18)1 +
gR(cid:19)k
ε (cid:17)
ln(cid:16) 2Mη
gR(cid:17) − 1,
ln(cid:16)1 + 1

thus according to the Deﬁnition 8 we obtain the thesis.

6 Upper bound from PPC condition

We assume:

• [a, b] = [−1, 1],
• D = D(f, cM ),
• f satisﬁes PPC(p, γ, S), therefore Dp

γ ⊂ D.

6.1 Modiﬁed Petras’ algorithm

We consider a modiﬁed Petras’ algorithm (abbreviated MPA) in which a decision if an interval is proper
or bad is made using PPC condition instead of checking IsAnalytic and ComplexBound. Additionally,
if MPA decides that it is still running (the length of all bad intervals is greater than ε/(2M )), then it
bisects all bad intervals in step 3 in the Petras’ algorithm before checking condition (4); thus in MPA
all bad intervals have the same length.

Notice that any interval accepted by MPA is contained in an interval accepted by Petras’ algorithm.
Thus we can state:

1. a sum of lengths of proper intervals generated in Petras’ algorithm is greater than or equal to a

sum of lengths of proper intervals generated in MPA:

Xj∈J(PA)

|aj − aj−1| > Xj∈J(MPA)

|aj − aj−1|,

where J(PA) and J(MPA) are sets of indices of proper intervals in Petras’ algorithm and MPA,
respectively; it is obvious that for bad intervals the converse inequality holds;

18

2. a sum of proper intervals generated in Petras’ algorithm is greater than or equal to a sum of

proper intervals generated in MPA:

[j∈J(MPA)

[aj−1, aj] ⊆ [j∈J(PA)

[aj−1, aj];

3. if MPA stops then Petras’ algorithm stops as well, since by (i) we have

Xj6∈J(PA)

|aj − aj−1| 6 Xj6∈J(MPA)

|aj − aj−1| 6

ε
2M

.

Thus we have proved the following lemma.

Lemma 20 MPA provides an upper bound for the complexity of Petras’ algorithm.

6.2 Leftward ﬂow

The leftward ﬂow is the ‘opposite’ of the rightward ﬂow, i.e. we take the longest proper interval in Dp
γ,
but we move from right to left. Thus we can describe the leftward ﬂow analogously as before:

1. We start from y0 = β (somewhere in the middle of (s, s′), for s, s′ ∈ S; the exact value of β is

irrelevant).

2. Each new interval [yi+1, yi] is created so that ̺(yi+1, yi) ⊂ Dp

γ and upper left corner of ̺(yi+1, yi)
γ. Observe that all longer intervals [yi+1 − δ, yi], for δ > 0, lack this
γ, the interval [yi+1, yi] must have been accepted during the

is on the boundary of Dp
property. Since ̺(yi+1, yi) ⊂ Dp
execution of the MPA and Petras’ algorithms.

3. We count the number of steps needed to exit the interval [αL, β] to the left, i.e. to have ym 6

αL < ym−1.

This process creates a sequence of intervals

Each successive point yn+1 is chosen as

ym 6 αL < ym−1 < . . . < y0 = β.

yn+1 = yn − dR(yn),

(40)

(41)

where function dR(x) (depends on the right end of an interval) is equal to d(x), which solves equation
(21) with

h =

B
2γ

,

g = gR =

A + 1

2

.

(42)

Estimates for dR(y) are given by Theorem 14 (for p > 1), Theorem 16 (for p < 1) and (33) (for p = 1).

6.2.1 Estimations of αL for MPA algorithm

In this subsection we will write x for both the coordinate x and the distance dist(x, S), and the precise
meaning should be clear from the context. Our goal is to ﬁnd a lower bound for αL, the distance to
the singular point from the right of the set of proper intervals obtained in the MPA algorithm.

Consider two cases:

19

γxp

s

x − d

x

x + d

Figure 4: An interval [x, x + d] is proper, but [x − d, x] is bad.

1. For p > 1 the shape of Dp

γ,S is as in Figure 4.

From Theorem 14 we know that:

interval [x, x + d] is proper, iﬀ d 6 dL(x), where dL(x) 6 c1,L · xp,
interval [x − d, x] is proper, iﬀ d 6 dR(x), where c2,R · xp 6 dR(x).

Consider x (as in Figure 4). Since [x, x + d] is proper (i.e. d 6 dL(x)) and [x − d, x] is bad (i.e.
d > dR(x)), we have:

c2,R · xp < d 6 c1,L · xp.

(43)

Hence, at any stage of the algorithm, all points x which are the closest to the points from S
satisfy the estimate (recall that all bad intervals have the same length):

p

(cid:18) d
c1,L(cid:19) 1

6 x <(cid:18) d

c2,R(cid:19) 1

p

.

Thus, if x1 and x2 are the closest to some singular point, then

c1,L(cid:19) 1
0 <(cid:18) c2,R

p

<

x1
x2

p

< (cid:16) d
c2,R(cid:17) 1
(cid:16) d
c1,L(cid:17) 1

p

p

=(cid:18) c1,L
c2,R(cid:19) 1

< +∞.

2. For p 6 1 from Theorem 16 we know that for suﬃciently small x

interval [x, x + d] is proper, iﬀ d 6 dL(x), where dL(x) 6 x
gL
interval [x − d, x] is proper, iﬀ d 6 dR(x), where there exists g+
p −1(cid:19) 6 dR(x).

< x(cid:18) 1

gR − c1,Rx

x
g+
R

,

R such that

1

Since [x, x + d] is proper and [x − d, x] is bad, we have:
x
.
gL

< d 6

x
g+
R

(44)

Hence, at any stage of the algorithm, all points x which are the closest to the points from S
satisfy the estimate (recall that all bad intervals have the same length):

d · gL 6 x < d · g+
R.

Thus if we have points x1 and x2 which are the closest to some singular point, then

0 <

A − 1
A + 1 ≈

gL
g+
R

6

x1
x2

6

R

d · g+
d · gL

=

g+
R
gL ≈

A + 1
A − 1

< +∞.

20

Now we know that for any p > 0, at any stage of the MPA, for any points xi, xj which are the closest
to a singular point from S:

0 <

xi
xj

6 T < +∞,

(45)

where T is a constant independent of ε. Because (45) holds for the minimal and maximal distance
denoted by xmin, xmax we have

Bad intervals are in the neighbourhood of any singular point from S, so there exists I 6 2m such that
for any 1 6 i 6 I a point xi is an end of the connected block of proper intervals (see Figure 5).

xmax 6 T · xmin.

(46)

s1

s2

x1 x2

x3

x4

. . .

x2m−1

sm = 1

−1

Figure 5: Singularities s1, . . . , sm and blocks of bad intervals between x2i−1 and x2i for i = 1, . . . , m.

While the algorithm is running

and from (46) we have

obtaining

ε
2M

ε
2M

< X16i6I
< X16i6I

xi 6 X16i6I

xmax

T · xmin 6 2m · T · xmin

xmin >

ε

4mM T

.

(47)

Let us stress that (47) holds as long as the stopping condition in MPA algorithm is not satisﬁed. We
need to estimate how far we can go in the last stage (i.e. αL).
Let x1 be a point from the proper interval, which is the closest to some s ∈ S from right or left. For
simplicity we will assume that s < x1, the other case is analogous. Let d be the length of bad intervals,
which will be now divided by 2. Let x2 (with s < x2 < x1) be such that [x2, x1] is covered by proper
intervals of length d/2. Therefore interval [x2, x2 + d/2] is proper.

1. Case p > 1. By (43), (47) and Theorem 14 we have the following estimations

1 < d

c2,R · xp
< dL(x2)

6 c1,L · xp

2

d
2

=⇒ x2 >(cid:18) 1

2 ·

c2,R

c1,L(cid:19)1/p

x1 >(cid:18) 1

2 ·

c2,R

c1,L(cid:19)1/p

ε

4mM T

.

2. Case p 6 1. By (44), (47) and Theorem 16 we obtain





x1
g+
R

< d

d
2

< dL(x2) 6

x2
gL

=⇒ x2 >

1
2 ·

gL
R · x1 >
g+

1
2 ·

gL
R ·
g+

ε

4mM T

.

Observe that in both above cases we have obtained

for some constant T0.

αL >

ε

M T0

,

21

(48)

6.3 Estimation of the number of proper intervals from above

6.3.1 Case p > 1

Lemma 21 Assume that p > 1 and f satisﬁes PPC(p, γ,{0}). Then

Z(D, ε) = O (cid:18) 1

ε(cid:19)p−1! .

Proof. Let us assume that [αi, αi+1] is obtained during MPA by bisecting an interval [u, v]. Since
[u, v] was bisected, it was bad, thus

v − u > dR(v).

(49)

From Theorem 14 we know that dR(x) > c2 · xp, where c2 > 0. Let us denote

w(x) = c2 · xp.

L

R

L

R

0

αi

αi+1

z
k
αi+1 + (αi+1 − αi)
Figure 6: The case (L)

0

z

αi

αi+1

kαi − (αi+1 − αi)

Figure 7: The case (R)

Two cases are possible as a result of the bisection:

(L) [αi, αi+1] is the left part in [αi, z] (see Figure 6), where z = αi+1 + (αi+1 − αi), and from (49) we

have

z − αi = 2(αi+1 − αi) > dR(αi+1 + (αi+1 − αi))

> w(αi+1 + (αi+1 − αi)) > w(αi+1).

(R) [αi, αi+1] is the right part in [z, αi+1] (see Figure 7) so for both z > 0 and z 6 0 it holds

2(αi+1 − αi) = αi+1 − z > dR(αi+1), by (49)

i+1

> c2 · αp
= w(αi+1).

Therefore in both cases the following estimate holds:

αi+1 − αi >

1
2 · w(αi+1).

(50)

In the leftward process we are moving from right to left thus we have to look at these α’s in the opposite
direction:

ε

M T0

= α0

. . . αi

αi+1

. . . αn = β

yn

. . .

yi+1

yi

. . .

y0.

22

Consequently substituting αn−i by yi (0 6 i 6 n) in (50) we obtain exactly the recurrence of the
leftward ﬂow:

yi+1 6 yi −

.

i

1
2 · c2 · yp
| {z }

w(yi)

yi 6 y(i),

It is easy to see that

where y(t) is a solution of

1
2 · c2 and y(0) = y0. Knowing that the solution of (52) is of the form

y′ = −a · yp
i ,

with a =

(51)

(52)

and setting y(0) = β and y(t) =

ε

M T0

y(t) =

y(0)

(1 + a · y(0)p−1(p − 1)t)
(compare (48)) we calculate

1

p−1

Observe that t is un upper bound for n, thus (see Deﬁnition 8)

t = (cid:16) MT0β

ε (cid:17)p−1

− 1
aβp−1(p − 1)
(M T0)p−1

1

=

1

a(p − 1)βp−1 .

·

εp−1

a(p − 1) −
Z(D, ε) = O (cid:18) 1

ε(cid:19)p−1! .

The above theorem holds also for |S| = m > 1, but in such a case β is in the middle of [si−1, si] for
each 1 < i 6 m.

6.3.2 Case p 6 1

Lemma 22 Assume that p 6 1 and f satisﬁes PPC(p, γ,{0}). Then there exists η > ε such that in
the segment [0, η]

Z(D, ε) = O(cid:18)ln

1

ε(cid:19) .

Proof. Following (42) we set

Let c1 be as in Theorem 16. Let us take

and notice that for all x ∈ [0, η]

gR =

A + 1

2

> 1.

η =

1

(2gRc1)

p

p−1

1
gR − c1 · x

1

p −1 >

1
2gR

23

thus from Theorem 16 we have

x
2gR

6 dR(x).

(53)

Let k be the number of proper intervals in [0, η]. Now, as in Lemma 21, we have two cases. In the case
(R) (see Figure 7) we have

αi+1 − z = 2(αi+1 − αi) > dR(αi+1) >

αi+1
2gR

.

In the case (L) (see Figure 6) using (53) we obtain

z − αi = 2(αi+1 − αi) > dR(z) >

z

2gR

>

αi+1 + (αi+1 − αi)

2gR

>

αi+1
2gR

.

In both cases we get

Since gR > 1, we obtain

Therefore from (48)

(cid:18)1 −
αi+1 > αi(cid:18)1 +

gR(cid:19) αi+1 > αi.
4gR − 1(cid:19) .

4

1

η > αi > α0(cid:18)1 +

1

4gL − 1(cid:19)i

>

ε

M T0(cid:18)1 +

1

4gL − 1(cid:19)i

.

(54)

Hence we obtain the following upper bound for k

k 6

ε (cid:17)
ln(cid:16) ηMT0
ln(cid:16)1 + 1
4gL−1(cid:17) + 1.

7 Complexity of Petras’ algorithm

Finally we can state a theorem estimating the complexity of Petras’ algorithm for functions satisfying
PPC and NPC conditions. As we mentioned in the introduction by the complexity we understand the
number of evaluations of an integrand at the nodes produced by the algorithm. Therefore this is not
a comprehensive evaluation, because we neglect complexity of checking analyticity, calculating bounds
and the precision of arithmetic operations.

Theorem 23 Assume that S = {s1, . . . , sm}, m > 1. For functions satisfying PPC(p, γ, S) and
NPC(p, γ′, s0, β) for some s0 ∈ S, the complexity of Petras’ algorithm is

Θ(| ln ε|/εp−1),
Θ(ln2 ε),

for p > 1,

for p 6 1.

(55)

(56)

24

Proof. First notice that by Lemmas 18 and 19 for s0 ∈ S the number of proper intervals created
during the execution of the algorithm is

Ω(1/εp−1),
Ω(| ln ε|),

for p > 1,

for p 6 1.

(57)

(58)

On the other hand for some small neighbourhood of each s ∈ S in Lemmas 21 and 22 we obtained an
upper bound for the number of proper intervals created during the execution of the algorithm:

O(1/εp−1),
O(| ln ε|),

for p > 1,

for p 6 1.

(59)

(60)

Next use Lemma 7 to estimate the number of proper intervals outside the neighbourhood of S. This
estimate is a constant (dependent on f ).

Hence we obtain the assertion of the theorem.

8 Functions giving rise to the complexity O(cid:16)| ln ε|
εp−1(cid:17)
The complexity of Petras’ algorithm for such functions is O(cid:18)| ln ε|
of functions for which the complexity is O(cid:18)| ln ε|
εp−1(cid:19), for any p > 1.

In Section 4.1 we have shown that function f (z) = sin(1/z) satisﬁes PPC(2, γ,{0}) and NPC(2, γ, 0, 1).

ε (cid:19). In this section we give examples

Theorem 24 Let S = {0} and let f (z) = sin(1/zp−1), where p ∈ N, p > 1. Then for any c > 1 there
exists γ > 0 such that

sup
z∈Dp

γ |f (z)| 6 c ·

x∈[−1,1]|f (x)|.
sup

Therefore for any α, β ∈ [−1, 1]

̺(α, β) ⊂ Dp

γ =⇒ f is analytic on ̺(α, β) ∧

z∈̺(α,β)|f (z)| 6 c ·
sup

x∈[−1,1]|f (x)|.
sup

Proof. Let γ 6 1. If ̺(α, β) ⊂ Dp
to check the second part of the thesis.
Let us set n = p − 1. Assume z = x + iy ∈ Dp
of Theorem 8, we have

γ then it is obvious that f is analytic on ̺(α, β). Thus it is enough

γ ∩ {z : |Re (z)| 6 1}. Let r2 = x2 + y2. As in the proof

| sin(1/zn)| 6

1
2

(exp (|Im (1/zn)|) + exp (−|Im (1/zn)|)) .

By (8) we have

Im (1/zn) =

1

r2n(cid:18)(cid:18)n

1(cid:19)xn−1y −(cid:18)n

3(cid:19)xn−3y3 + . . .(cid:19)

and it is easy to see that for z ∈ Dp

γ ∩ {z : |Re (z)| 6 1} and for some constant Φ = Φ(n),

|Im (1/zn)| 6

Φ
r2n |xn−1y| 6 Φ

γ|x|n−1|x|p

|x|2n

= Φγ.

25

For z ∈ Dp

γ ∩ {z : |Re (z)| 6 1} we have (because x 7→ x + 1

x is increasing for x > 1)

(exp(Φγ) + exp(−Φγ)) → 1,
Thus there exists c > 1 such that taking γ suﬃciently small we get

| sin(1/zn)| 6

1
2

as γ → 0.

z∈Dp

sup

γ ∩{z:|Re(z)|61}(cid:12)(cid:12)sin(cid:0)1/zp−1(cid:1)(cid:12)(cid:12) < c ·

x∈[−1,1]| sin(1/xp−1)|.
sup

dx(̺)

dy(̺)

0

1

Figure 8: Rectangle ̺(α, β) does not have to be entirely contained in Dp
small γ the projecting part (̺(α, β)\(Dp
Note that (see Figure 8) the rectangle ̺(α, β) does not have to be entirely contained in the region
Dp
γ ∩ {z : |Re (z)| 6 1}, but the width and height of the projecting area linearly depend on γ (dx(̺) <
A − 1
and dy(̺) < γ — see Theorem 12) and the function is continuous in the wide neighbourhood
γ
B
of 1, therefore further reducing γ we obtain

γ ∩ {z : |Re (z)| 6 1}) = 2(dx(̺) × dy(̺))) is small.

γ ∩ {z : |Re (z)| 6 1}, but for

sup

z∈̺(α,β)(cid:12)(cid:12)sin(cid:0)1/zp−1(cid:1)(cid:12)(cid:12) 6 c ·

sup

x∈[−1,1]| sin(1/xp−1)|.

Theorem 24 says that for z 7→ sin(1/zp−1) there exists a region Dp
γ ∩ {z : |Re (z)| 6 1} where the
function is analytic and appropriately bounded. The next theorem says that there exists a region of
the same shape as before, but such that (on the boundary of this region close to the singular point)
the values of the function are arbitrarily large.

Theorem 25 Let S = {0} and let f (z) = sin(1/zp−1), where p ∈ N, p > 1. Then for any c > 1 there
exist γ > 0 and η > 0 such that for any α ∈ [−η, η] and β ∈ (α, 1]
γ =⇒ f is not analytic on ̺(α, β) ∨ sup

̺(α, β) 6⊂ Dp

z∈̺(α,β)|f (z)| > c

x∈[−1,1]|f (x)|.
sup

Proof. Let us ﬁx γ > 0 and consider points z = x + iy ∈ ∂Dp
|Re (z)| 6 1}. We will restrict our
attention to x > 0 and y = γxp > 0. By (8), for suﬃciently small x and for some constants Φ, Φ′ > 0
there is

γ ∩{z :

Im(cid:18) 1

zp−1(cid:19) =

>

=

=

1

r2(p−1)(cid:18)(cid:18)p − 1

1 (cid:19)xp−2y −(cid:18)p − 1

3 (cid:19)xp−4y3 + . . .(cid:19)

γΦx2(p−1)

r2(p−1)

γΦx2(p−1)

x2(p−1)(1 + γ2x2(p−1))p−1

γΦ

(1 + γ2x2(p−1))p−1

> γΦ′.

26

Observe that (compare the proof of Theorem 10), since x 7→ x − 1

x , we have

z∈Wγ | sin(1/zl)| >
inf

1
2
γ ∩ {z : |Re (z)| 6 η}\{0}.

>

1

2(cid:0)exp(|Im(cid:0)1/zl(cid:1)|) − exp(−|Im(cid:0)1/zl(cid:1)|)(cid:1)
(exp(γΦ′) − exp(−γΦ′)) ,

where Wγ = ∂Dp
Now, for any c > 1 it is enough to take γ > 0 big enough to have inf z∈Wγ | sin(1/zl)| > c.
From the above theorems it follows that functions f (z) = sin(1/zp−1) for p ∈ N, p > 1 satisfy the
assumptions of Theorem 23, thus their complexity scales as | ln ε|/εp−1.

9 Appendix: asymptotic rate of growth

Let us adopt the notation used in the classical (discrete) complexity theory to describe asymptotic rate
of growth.

Deﬁnition 8 Let f, g : R → R+ .

1. We say that f is at least of order g, if there exist ε0 > 0 and c > 0, such that:

∀ 0 < x 6 ε0 : f (x) > c · g(x).

Notation: f (x) ∈ Ω(g(x)).

2. We say that f is at most of order g, if there exist ε0 > 0 and c > 0, such that:

Notation: f (x) ∈ O(g(x)).

∀ 0 < x 6 ε0 : f (x) 6 c · g(x).

3. We say that f is exactly of order g, if there exist ε0 > 0, c1 > 0 and c2, such that:

∀ 0 < x 6 ε0 : c1 · g(x) 6 f (x) 6 c2 · g(x).

Notation: f (x) ∈ Θ(g(x)).

References

[1] H. Brass. Quadraturverfahren. Vandenhoeck and Ruprecht, G¨ottingen, 1997.

[2] T. Gaertner and G. Hotz. Representation theorems for analytic machines and computability of

analytic functions. Theory of Computing Systems, 51:65–84, 2012.

[3] J. van der Hoeven. Eﬀective analytic functions. Journal of Symbolic Computation, 39:433–449,

2005.

[4] K. Petras. Gaussian Versus Optimal Integration of Analytic Functions. Constructive Approximation,

14:231–245, 1998.

27

[5] K. Petras. On the complexity of self-validating numerical integration and approximation of functions

with singularities. Journal of Complexity, 14:302–318, 1998.

[6] K. Petras. Self-validating integration and approximation of piecewise analytic functions. Journal

of Computational and Applied Mathematics, 145:345–359, 2002.

28

This figure "elipsa-gothic.jpg" is available in "jpg"(cid:10) format from:

http://arxiv.org/ps/1603.03945v1

This figure "obszarD.jpg" is available in "jpg"(cid:10) format from:

http://arxiv.org/ps/1603.03945v1

This figure "region-of-analyticity.jpg" is available in "jpg"(cid:10) format from:

http://arxiv.org/ps/1603.03945v1

