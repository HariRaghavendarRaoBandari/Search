Copositive matrices with circulant zero pattern

Roland Hildebrand ∗

March 17, 2016

Abstract

1

1

, . . . , u

, . . . , u

Let n ≥ 5 and let u

n be nonnegative real n-vectors such that the indices of their positive
elements form the sets {1, 2, . . . , n − 2}, {2, 3, . . . , n − 1}, . . . , {n, 1, . . . , n − 3}, respectively. Here each
index set is obtained from the previous one by a circular shift. The set of copositive forms which vanish
n is a face of the copositive cone C n. We give an explicit semi-deﬁnite description
on the vectors u
of this face and of its subface consisting of positive semi-deﬁnite matrices, and study their properties. If
n and their positive multiples exhaust the zero set of an exceptional copositive form
the vectors u
belonging to this face, then we call this form regular, otherwise degenerate. We show that degenerate
forms are always extremal, and regular forms can be extremal only if n is odd. We construct explicit
examples of extremal degenerate forms for any order n ≥ 5, and examples of extremal regular forms for
any odd order n ≥ 5. The set of all degenerate forms, i.e., deﬁned by diﬀerent collections u
n of
zeros, is a submanifold of codimension 2n, the set of all regular forms a submanifold of codimension n.

, . . . , u

1

, . . . , u

1

1

Introduction

6
1
0
2

 
r
a

 

M
6
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
1
1
1
5
0

.

3
0
6
1
:
v
i
X
r
a

Let Sn be the vector space of real symmetric n × n matrices.
In this space, we may deﬁne the cone
+ of positive semi-deﬁnite matrices, and the cone Cn
N n of element-wise nonnegative matrices, the cone Sn
of copositive matrices, i.e., matrices A ∈ Sn such that xT Ax ≥ 0 for all x ∈ Rn
+. Obviously we have
+ + N n ⊂ Cn, but the converse inclusion holds only for n ≤ 4 [6, Theorem 2]. Copositive matrices which
Sn
are not elements of the sum Sn
+ + N n are called exceptional. Copositive matrices play an important role
in non-convex and combinatorial optimization, see, e.g., [5] or the surveys [10],[17],[4],[8]. Of particular
interest are the exceptional extreme rays of Cn.

A fruitful concept in the study of copositive matrices is that of zeros and their supports, initiated in the
works of Baumert [2],[3], see also [16],[7], and [19] for further developments and applications. A non-zero
vector u ∈ Rn
+ is called a zero of a copositive matrix A ∈ Cn if uT Au = 0. The support supp u of a zero u
is the index set of its positive elements.
Note that each of the cones N n, Sn

+, Cn is invariant with respect to a simultaneous permutation of the
row and column indices, and with respect to a simultaneous pre- and post-multiplication with a positive
deﬁnite diagonal matrix. These operations generate a group of linear transformations of Sn, which we shall
call Gn.

Exceptional copositive matrices ﬁrst appear at order n = 5. The Horn matrix

1 −1

1
1 −1

−1

1 −1
1
−1

1 −1
1

1 −1
1
1
1 −1
1
1 −1
1

1 −1

H =


named after its discoverer Alfred Horn, and the other matrices in its G5-orbit have been the ﬁrst examples
of exceptional extremal copositive matrices [14]. Any other exceptional extremal matrix in C5 lies in the

∗WIAS, Mohrenstrasse 39, 10117 Berlin, Germany (roland.hildebrand@wias-berlin.de). This research was carried out

in the framework of Matheon supported by Einstein Foundation Berlin.

1

,

(1)




1

− cos θ1

cos(θ1 + θ2)

− cos θ1

cos(θ1 + θ2)
cos(θ4 + θ5)

− cos θ5

1

− cos θ2

cos(θ2 + θ3)
cos(θ5 + θ1)

− cos θ2

1

− cos θ3

cos(θ3 + θ4)

− cos θ4

cos(θ4 + θ5)
cos(θ2 + θ3)

− cos θ3

1

− cos θ5

cos(θ5 + θ1)
cos(θ3 + θ4)

− cos θ4

1




(2)

G5-orbit of a matrix

T (θ) =




for some angles θk ∈ (0, π) satisfying P5

k=1 θk < π [15, Theorem 3.1]. Both the Horn matrix H and the
matrices T (θ) possess zeros with supports {1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 1}, {5, 1, 2}, respectively. Note
that these supports are exactly the vertex subsets obtained by removing the vertices of a single edge in the
cycle graph C5.

In this contribution we shall generalize the exceptional extremal elements of C5 to arbitrary order n ≥ 5
by taking the above property of the supports as our point of departure. Fix a set u = {u1, . . . , un} ⊂ Rn
+
of nonnegative vectors with supports {1, 2, . . . , n − 2}, {2, 3, . . . , n − 1}, . . . , {n, 1, . . . , n − 3}, respectively,
i.e., the supports of the vectors uj are the vertex subsets obtained by removing the vertices of a single edge
in the cycle graph Cn. We then consider the faces

Fu = {A ∈ Cn | (uj)T Auj = 0 ∀ j = 1, . . . , n},

Pu = {A ∈ Sn

+ | (uj)T Auj = 0 ∀ j = 1, . . . , n}

of the copositive cone and the positive semi-deﬁnite cone, respectively. Note that Pu ⊂ Fu.

One of our main results is an explicit semi-deﬁnite description of the faces Fu and Pu (Theorem 4.8).
In order to obtain this description, we associate the set u to a discrete-time linear dynamical system Su of
order d = n − 3 and with time-dependent coeﬃcients having period n. If Lu is the d-dimensional solution
space of this system, then there exists a canonical bijective linear map between Fu and the set of positive
semi-deﬁnite symmetric bilinear forms on the dual space L∗
u satisfying certain additional homogeneous
linear equalities and inequalities. For an arbitrary collection u in general only the zero form satisﬁes the
corresponding linear matrix inequality (LMI) and the face Fu consists of the zero matrix only. However,
for every n ≥ 5 there exist collections u for which the LMI has non-trivial feasible sets.

The properties of the copositive matrices in Fu are closely linked to the properties of the periodic linear
dynamical system Su. Such systems are the subject of Floquet theory, see, e.g., [11, Section 3.4]. We
need only the concept of the monodromy matrix and its eigenvalues, the Floquet multipliers, which we shall
review in Section 3. We show that the face Pu is isomorphic to Sd1
+ , where d1 is the geometric multiplicity
of the Floquet multiplier 1, or equivalently, the dimension of the subspace of n-periodic solutions of Su.
For the existence of exceptional copositive matrices in Fu it is necessary that all or all but one Floquet
multiplier are located on the unit circle (Corollary 5.5).

We are able to describe the structure of Fu explicitly in general. Exceptional matrices A ∈ Fu can
be divided in two categories. If every zero of A is proportional to one of the zeros u1, . . . , un, then we
call the copositive matrix A regular, otherwise we call it degenerate1. We show that degenerate matrices
are always extremal, while regular matrices can be extremal only for odd n. For even n a regular matrix
can be represented as a non-trivial sum of a degenerate matrix and a positive semi-deﬁnite rank 1 matrix,
the corresponding face Fu is then isomorphic to R2
+. For odd n a suﬃcient condition for extremality of a
regular matrix is that −1 does not appear among the Floquet multipliers (Theorem 5.12). For every n ≥ 5
the degenerate matrices constitute an algebraic submanifold of Sn of codimension 2n (Theorem 6.3), while
the regular matrices form an algebraic submanifold of codimension n (Theorem 6.1), in which the extremal
matrices form an open subset (Theorem 6.2).

Finally, in Section 7.2 we construct explicit examples of circulant (i.e., invariant with respect to simulta-
neous circular shifts of row and column indices) exceptional extremal copositive matrices, both degenerate
and regular. We also give an exhaustive description of all degenerate exceptional matrices for order n = 6
in Section 8. Some auxiliary results whose proofs would interrupt the ﬂow of exposition are collected in
two appendices.

1The terms regular and degenerate are used in this very speciﬁc sense in this paper. The motivation is that whether an
exceptional matrix A ∈ Fu is regular or degenerate depends on whether certain principal submatrices of A of size n − 3 are
regular or degenerate in the ordinary sense.

2

1.1 Further notations

For n ≥ 5 an integer, deﬁne the ordered index sets I1 = (1, 2, . . . , n − 2), I2 = (2, 3, . . . , n − 1), . . . , In =
(n, 1, . . . , n − 3) of cardinality n − 2, each obtained by a circular shift of the indices from the previous one.
We will need also the index sets I ′

n = (n, 1, . . . , n − 4) deﬁned similarly.

1 = (1, 2, . . . , n − 3), . . . , I ′

Let k > 0 be an integer. For a vector u ∈ Rk, a k × k matrix M , and an ordered index set I ⊂ {1, . . . , k}
of cardinality |I|, we shall denote by ui the i-th entry of u, by uI the subvector (ui)i∈I ∈ R|I| of u composed
of the elements with index in the ordered set I, by Mij the (i, j)-th entry of M , and by MI the principal
submatrix (Mij )i,j∈I ∈ R|I|×|I| of M composed of the elements having row and column index in I.

In order to distinguish it from the index sets I1, . . . , In deﬁned above, we shall denote the identity
matrix or the identity operator by Id or Idk if it is necessary to indicate the size of the matrix. Denote by
Eij ∈ N n the matrix which has ones at the positions (i, j) and (j, i) and zeros elsewhere. For a real number
r, we denote by ⌊r⌋ the largest integer not exceeding r and by ⌈r⌉ the smallest integer not smaller than r.

Deﬁnition 1.1. Let A ∈ Cn be an exceptional copositive matrix possessing zeros u1, . . . , un ∈ Rn
+ such
that supp uj = Ij , j = 1, . . . , n. We call the matrix A regular if every zero v of A is proportional to one of
the zeros u1, . . . , un, and we call it degenerate otherwise.

2 Conditions for copositivity

In this section we consider matrices A ∈ Sn such that the submatrices AI1 , . . . , AIn are all positive semi-
deﬁnite and possess element-wise positive kernel vectors. We derive necessary and suﬃcient conditions for
such a matrix to be copositive. The goal of the section is to prove Theorem 2.8 below. We start with a few
simple auxiliary lemmas.

Lemma 2.1. [9, Lemma 2.4] Let A ∈ Cn and let u be a zero of A. Then the principal submatrix Asupp u is
positive semi-deﬁnite.

Lemma 2.2. [2, p.200] Let A ∈ Cn and let u be a zero of A. Then Au ≥ 0 element-wise.

Lemma 2.3. Let n ≥ 5, and let i, j ∈ {1, . . . , n} be arbitrary indices. Then there exists k ∈ {1, . . . , n} such
that i, j ∈ Ik.

Proof. For every index i ∈ {1, . . . , n}, there exist exactly two indices k such that i 6∈ Ik. The assertion of
the lemma then follows from the Dirichlet principle.

Corollary 2.4. Let n ≥ 5 and let A ∈ Cn have zeros u1, . . . , un with supports I1, . . . , In, respectively. Then
for every pair of indices i, j ∈ {1, . . . , n}, the matrix A − εEij is not copositive for every ε > 0.

Proof. Let i, j ∈ {1, . . . , n}. By Lemma 2.3 there exists a zero uk of A such that i, j ∈ supp uk. The
assertion then follows by (uk)T (A − εEij)uk < 0 for every ε > 0, see [3, p. 10].

Corollary 2.5. [2, Corollary 3.7] Let A ∈ Cn be such that A − εEij is not copositive for every ε > 0 and
all i, j = 1, . . . , n. If A has a zero with support of cardinality n − 1, then A is positive semi-deﬁnite.

A zero u ∈ Rn

+ of A is called minimal if there is no other zero v ∈ Rn

+ of A such that the inclusion
supp v ⊂ supp u is strict. For a ﬁxed copositive matrix, the number of its minimal zeros whose elements
sum up to 1 is ﬁnite [16, Corollary 3.6]. The next result furnishes a criterion involving minimal zeros to
check whether a copositive matrix is extremal.

Lemma 2.6. [7, Theorem 17] Let A ∈ Cn, and let u1, . . . , um be its minimal zeros whose elements sum up
to 1. Then A is extremal if and only if the solution space of the linear system of equations on the matrix
X ∈ Sn given by

(Xuj)i = 0

∀ i, j : (Auj)i = 0

is one-dimensional (and hence generated by A).

3

Lemma 2.7. [16, Lemma 4.3] Let A ∈ Cn be a copositive matrix and let w ∈ Rn. Then there exists ε > 0
such that A − εwwT is copositive if and only if hw, ui = 0 for all zeros u of A.

These results allow us to prove the following theorem on matrices A ∈ Sn having zeros u1, . . . , un with

supports I1, . . . , In, respectively.

Theorem 2.8. Let n ≥ 5 and let A ∈ Sn be such that for every j = 1, . . . , n there exists a nonnegative
vector uj with supp uj = Ij satisfying (uj)T Auj = 0. Then the following are equivalent:

(i) A is copositive;
(ii) every principal submatrix of A of size n − 1 is copositive;
(iii) every principal submatrix of A of size n − 1 is in Sn−1
(iv) AIj is positive semi-deﬁnite for j = 1, . . . , n, (un)T Au1 ≥ 0, and (uj)T Auj+1 ≥ 0 for j = 1, . . . , n − 1.

+ + N n−1;

Moreover, given above conditions (i)—(iv), the following are equivalent:

(a) A is positive semi-deﬁnite;
(b) at least one of the n numbers (un)T Au1 and (uj)T Auj+1, j = 1, . . . , n − 1, is zero;
(c) all n numbers (un)T Au1 and (uj)T Auj+1, j = 1, . . . , n − 1, are zero;
(d) A is not exceptional.

Proof. (i) ⇒ (iv) is a consequence of Lemmas 2.1 and 2.2.

(iv) ⇒ (iii) is a consequence of Lemma A.1 in the Appendix, applied to the (n − 1) × (n − 1) principal

submatrices of A.

(iii) ⇒ (ii) is trivial.
(ii) ⇒ (i): Let ∆ = {v = (v1, . . . , vn)T ∈ Rn

j=1 vj = 1} be the standard simplex. By (ii) the
quadratic form A is nonnegative on ∂∆. On ∂∆ it then reaches its global minimum 0 at appropriate
positive multiples αjuj ∈ ∆ of the zeros uj for all j = 1, . . . , n. Since the line segment connecting α1u1
and α2u2 still lies in ∂∆, the quadratic function Q(v) = vT Av cannot be strictly convex on ∆. But then it
reaches its global minimum over ∆ on the boundary ∂∆. This minimum over ∆ then also equals 0, which
proves the copositivity of A.

+ | Pn

We have shown the equivalence of conditions (i)—(iv). Let us now assume that A satisﬁes (i)—(iv) and

pass to the second part of the theorem.

(a) ⇒ (c): If A (cid:23) 0, then all vectors uj, j = 1, . . . , n, are in the kernel of A. This implies (c).
(c) ⇒ (b) is trivial.
(b) ⇒ (a): Without loss of generality, let (u1)T Au2 = 0. It then follows that u+ = u1 + u2 is also a
zero of A, with supp u+ = {1, . . . , n − 1}. By Corollaries 2.4 and 2.5 A is then positive semi-deﬁnite, which
proves (a).

(a) ⇒ (d) holds by deﬁnition.
(d) ⇒ (a): Assume that A can be written as a sum A = P + N with P ∈ Sn
2.4 none of the elements of N can be positive and hence A = P , implying (a).

+ and N ∈ N n. By Corollary

Let us comment on Theorem 2.8. It states that the presence of n zeros with supports Ij , j = 1, . . . , n
place stringent constraints on a copositive matrix A ∈ Cn. Such a matrix must either be exceptional or
positive semi-deﬁnite. Which of these two cases arises is determined by any of the n numbers in condition
(iv) of the theorem, which are either simultaneously positive or simultaneously zero.

3 Linear systems with periodic coeﬃcients

In this section we investigate the solution spaces of linear periodic dynamical systems and perform some
linear algebraic constructions on them. These will be later put in correspondence to copositive forms. First
we shall introduce the monodromy and the Floquet multipliers associated with such systems, for further
reading about these and related concepts see, e.g., [11, Section 3.4].

We consider real scalar discrete-time homogeneous linear dynamical systems governed by the equation

xt+d +

d−1

Xi=0

ct
ixt+i =

d

Xi=0

ct
ixt+i = 0,

t = 1, 2, . . .

(3)

4

d)T ∈ Rd+1,
where xt ∈ R is the value of the solution x at time instant t, d > 0 is the order, and ct = (ct
t ≥ 1, are the coeﬃcient vectors of the system. For convenience we have set ct
d = 1 for all t ≥ 1. We assume
that the coeﬃcients are periodic with period n > d, i.e., ct+n = ct for all t ≥ 1. Denote by L the linear
space of all solutions x = (xt)t≥1. This space has dimension d and can be parameterized, e.g., by the vector
(x1, . . . , xd) ∈ Rd of initial conditions.

0, . . . , ct

If x = (xt)t≥1 is a solution of the system, then y = (xt+n)t≥1 is also a solution by the periodicity of
the coeﬃcients. The corresponding linear map M : L → L taking x to y is called the monodromy of the
periodic system. Its eigenvalues are called Floquet multipliers. The following result is a trivial consequence
of this deﬁnition.

Lemma 3.1. Let Lper ⊂ L be the subspace of n-periodic solutions of system (3). Then x ∈ Lper if and
only if x is an eigenvector of the monodromy operator M with eigenvalue 1. In particular, dim Lper equals
the geometric multiplicity of the eigenvalue 1 of M.

System (3) is time-reversible if and only if ct

0 6= 0 for all t = 1, . . . , n, in this case we may express xt as

a function of xt+1, . . . , xt+d. In fact, the following result holds.

Lemma 3.2. The determinant of the monodromy matrix is given by det M = (−1)ndQn
linear map taking the vector (x1, . . . , xd) to (xn+1, . . . , xn+d) equals (−1)ndQn

Proof. From (3) it follows that the determinant of the linear map taking the vector (xt, xt+1, . . . , xt+d−1)
to (xt+1, . . . , xt+d) equals (−1)dct
0. Iterating this map for t = 1, . . . , n, we get that the determinant of the
0. The claim now follows

from the fact that the vector (x1, . . . , xd) parameterizes the solution space L.

t=1 ct
0.

t=1 ct

Let us now consider the space L∗ of linear functionals on the solution space L. For every t ≥ 1, the map
taking a solution x = (xs)s≥1 to its value xt at time instant t is such a linear functional. We shall denote
this evaluation functional by et ∈ L∗. By deﬁnition of the monodromy we have et+n = M∗et for all t ≥ 1,
where M∗ : L∗ → L∗ is the adjoint of M. Moreover,

ct
iet+i = 0

∀ t ≥ 1

(4)

d

Xi=0

as a consequence of (3).

Our main tool in the study of copositive forms in this paper are positive semi-deﬁnite symmetric bilinear

forms B on L∗ which are invariant with respect to a time shift by the period n, i.e.,

B(et+n, es+n) = B(et, es)

∀ t, s ≥ 1.

(5)

Deﬁnition 3.3. We call a symmetric bilinear form B on L∗ satisfying relation (5) a shift-invariant form.

Lemma 3.4. Assume above notations. A symmetric bilinear form B on L∗ is shift-invariant if and only
if it is preserved by the adjoint of the monodromy, i.e., B(w, w′) = B(M∗w, M∗w′) for all w, w′ ∈ L∗. An
equivalent set of conditions is given by B(et+n, es+n) = B(et, es) for all t, s ∈ {1, . . . , d}.

Proof. The assertions hold because the evaluation functionals e1, . . . , ed form a basis of L∗ and et+n = M∗et
for all t ≥ 1.

The shift-invariant forms are hence determined by a ﬁnite number of linear homogeneous equations and

constitute a linear subspace of the space of symmetric bilinear forms on L∗.

The space of symmetric bilinear forms on L∗ can be viewed as the space of symmetric contra-variant
second order tensors over L, i.e., it is the linear hull of tensor products of the form x ⊗ x, x ∈ L.
It
is well-known that a symmetric bilinear form can be diagonalized, i.e., represented as a ﬁnite sum B =
k=1 σkxk ⊗ xk with σk ∈ {−1, +1}, xk ∈ L, k = 1, . . . , r, the vectors xk being linearly independent. The
vectors xk in this decomposition are not unique, but their number r and their linear hull depend only on
B and are called the rank rk B and the image Im B of B, respectively. The form is positive semi-deﬁnite
if all coeﬃcients σk in its decomposition equal 1.

Pr

Lemma 3.5. Let B be a shift-invariant symmetric positive semi-deﬁnite bilinear form B on L∗, of rank r.
Then there exist at least r (possibly complex) linearly independent eigenvectors of M with eigenvalues on
the unit circle.

5

Proof. Let B =Pr

k=1 xk ⊗ xk be a decomposition of B as above and complete the linearly independent set
{x1, . . . , xr} to a basis {x1, . . . , xn} of L. In the coordinates deﬁned by this basis and its dual basis in L∗
the form B is then given by the diagonal matrix diag(Idr, 0, . . . , 0). Let M be the coeﬃcient matrix of M
in this basis, partitioned into submatrices M11, M12, M21, M22 corresponding to the partition of the basis
into subsets {x1, . . . , xr} and {xr+1, . . . , xn}. Then by Lemma 3.4 the shift-invariance of B is equivalent to
the condition

(cid:18)Idr

0

0

0(cid:19) =(cid:18)M11 M12

M21 M22(cid:19)(cid:18)Idr

0

0

M21 M22(cid:19)T
0(cid:19)(cid:18)M11 M12

=(cid:18)M11M T

M21M T

11 M11M T
21
11 M21M T

21(cid:19) .

It follows that M21 = 0 and M11 is an r × r orthogonal matrix. However, it is well-known that orthogonal
matrices possess a full basis of eigenvectors with eigenvalues on the unit circle. The assertion of the lemma
now readily follows.

4 Copositive matrices and linear periodic systems

In this section we establish a relation between the objects considered in the preceding two sections. Through-
out this and the next section, we ﬁx a collection u = {u1, . . . , un} ⊂ Rn
+ of nonnegative vectors such that
supp uj = Ij , j = 1, . . . , n. Moreover, we assume these vectors are normalized such that the last elements
of their positive subvectors uj
all equal 1. To the collection u we associate a discrete-time linear periodic
Ij
system Su of order d = n − 3 and with period n, given by (3) with coeﬃcient vectors ct = ut
, t = 1, . . . , n.
It
The coeﬃcient vectors ct for all other time instants t > n are then determined by the periodicity relation
ct+n = ct. Equivalently, the dynamics of Su is given by the equations

ut′
s xt+i = 0,

t ≥ 1,

d

Xi=0

(6)

where t′, s ∈ {1, . . . , n} are the unique indices such that t ≡ t′ and t + i ≡ s modulo n. Relation (4) then
becomes

with t′, s deﬁned as above.

Xi=0

d

ut′
s et+i = 0,

∀ t ≥ 1,

(7)

(8)

By Lemma 3.2 the monodromy of Su then satisﬁes

det M =

uj
j > 0.

n

Yj=1

In particular, the system Su is time-reversible. Denote by Lu the space of solutions of Su.

Let Au ⊂ Sn be the linear subspace of matrices A satisfying AIj uj
= AIj cj = 0 for all j = 1, . . . , n. To
Ij
A ∈ Au we associate a symmetric bilinear form B on the dual space L∗
u by setting B(et, es) = Ats for every
t, s = 1, . . . , d and deﬁning the value of B on arbitrary vectors in L∗
u by linear extension. In other words,
in the basis {e1, . . . , ed} of L∗
. Let Λ : A 7→ B
be the so-deﬁned linear map from Au into the space of symmetric bilinear forms on L∗
u. Our ﬁrst step will
be to describe the image of Λ. To this end, we need the following lemma.

u the coeﬃcient matrix of B is given by the submatrix AI ′

1

Lemma 4.1. Let A ∈ Au and B = Λ(A). Then for every integer r ≥ 1, the (n − 2) × (n − 2)-matrix
Br = (B(et+r, es+r))t,s=0,...,d equals the submatrix AIr′ , where r′ ∈ {1, . . . , n} is the unique index satisfying
r ≡ r′ modulo n. Equivalently,

B(et, es) = At′s′

∀ t, s ≥ 1 :

|t − s| ≤ n − 3,

(9)

where t′, s′ ∈ {1, . . . , n} are the unique indices such that t ≡ t′, s′ ≡ s modulo n.

6

Proof. We proceed by induction over r. By deﬁnition of Λ the upper left (n − 3) × (n − 3) submatrix of B1
equals the corresponding submatrix of AI1 . However, we have AI1 c1 = 0 by virtue of A ∈ Au and B1c1 = 0
by virtue of (4) for t = 1. Hence the diﬀerence AI1 − B1 is a symmetric matrix, with possibly non-zero
elements only in the last row or in the last column, which possesses a kernel vector with all elements positive.
It is easily seen that this diﬀerence must then be the zero matrix, proving the assertion of the lemma for
r = 1.

The induction step from r − 1 to r proceeds in a similar manner, with equality of the upper left

(n − 3) × (n − 3) submatrices of Br and AIr′ now guaranteed by the induction hypothesis.

The lemma asserts that the submatrices AI1 , . . . , AIn are all of the form (B(et, es))t,s∈I for certain index

sets I. Some of their properties are hence determined by the corresponding properties of B.

Corollary 4.2. Let A ∈ Au and B = Λ(A). Then the ranks of the matrices AIj , j = 1, . . . , n, and of all
their submatrices of size (n − 3) × (n − 3), are equal to the rank of the symmetric bilinear form B.

Proof. Since the system Su is time-reversible, the evaluation operators et, . . . , et+d−1 form a basis of L∗
for every t ≥ 1. On the other hand, the operators et, . . . , et+d are linearly dependent for all t ≥ 1, the
dependence being given by (7). All coeﬃcients in this relation are non-zero, hence any of the operators
et, . . . , et+d can be expressed as a linear combination of the d other operators. It follows that every subset
of {et, . . . , et+d} of cardinality d is a basis of L∗
u. Therefore the d × d matrix (B(es, es′))s∈I,s′∈I ′ , where
I, I ′ are such subsets, has rank equal to rk B. The same holds for the matrices (B(es, es′))s,s′=t,...,t+d for
all t ≥ 1. The corollary now follows from Lemma 4.1.

u

Corollary 4.3. Let A ∈ Au and B = Λ(A). Then the symmetric bilinear form B is shift-invariant and
satisﬁes the linear relations

B(et, es) = B(et+n, es)

∀ t, s ≥ 1 : 3 ≤ s − t ≤ n − 3.

(10)

Proof. By (9) we have B(et, es) = Ats = B(et+n, es+n) for all t, s = 1, . . . , d. This in turn implies the
shift-invariance of B by Lemma 3.4.

The inequalities 3 ≤ s − t ≤ n − 3 imply |t − s| ≤ n − 3, |t + n − s| ≤ n − 3. Relations (10) then follow

from (9) in a similar way as the shift-invariance.

Now we are ready to describe the image of the map Λ.

Lemma 4.4. Suppose that n ≥ 5. Then the linear map Λ is injective, and its image consists of those
shift-invariant symmetric bilinear forms B on L∗

u which satisfy relations (10).

Proof. In view of Corollary 4.3 it suﬃces to show that for every shift-invariant symmetric bilinear form B
satisfying (10) there exists a unique matrix A ∈ Au such that B = Λ(A).

Let B be such a form. We deﬁne the corresponding matrix A as follows. Let i, j ∈ {1, . . . , n} be

arbitrary indices such that i ≤ j. Put

Aij = Aji =(cid:26)

B(ei, ej),
B(ei+n, ej),

j − i ≤ n − 3;
j − i > n − 3.

(11)

The shift-invariance of B and relations (10) then imply (9). This yields Br = (B(et+r, es+r))t,s=0,...,d = AIr
for every r = 1, . . . , n. Now Brcr = 0 by virtue of (4), which implies AIr cr = 0 and hence A ∈ Au. Moreover,
Λ(A) = B by construction of A.

Uniqueness of A follows from Lemmas 4.1 and 2.3.

Now we shall investigate which symmetric bilinear forms B in the image of Λ are the images of copositive

matrices. First we consider positive semi-deﬁnite bilinear symmetric forms B.

Lemma 4.5. Suppose n ≥ 5 and let A ∈ Au and B = Λ(A). Then the following are equivalent:

(i) the form B is positive semi-deﬁnite;

7

(ii) the submatrices AIj are positive semi-deﬁnite for all j = 1, . . . , n;
(iii) any of the submatrices AIj , j = 1, . . . , n, is positive semi-deﬁnite.

Moreover, given above conditions (i)—(iii), the following holds:

(a) the diﬀerence B(en, en−2) − B(en, e2n−2) has the same sign as (un)T Au1;
(b) the diﬀerence B(ej+n, ej+n−2) − B(ej+n, ej+2n−2) has the same sign as (uj)T Auj+1, j = 1, 2;
(c) the diﬀerence B(ej, ej−2) − B(ej, ej+n−2) has the same sign as (uj)T Auj+1, j = 3, . . . , n − 1.

Proof. The ﬁrst part of the lemma is a direct consequence of Lemma 4.1 and of the fact that the set
{et, . . . , et+d} spans the whole space L∗

u for all t ≥ 1.

Let us prove the second part and assume conditions (i)—(iii). Consider the (n − 1) × (n − 1) matrix
A(1,...,n−1). By Lemma 4.1 its upper left and its lower right principal submatrix of size n − 2 coincides
with the matrix (B(et, es))t,s∈I with I = {1, . . . , n − 2} and I = {2, . . . , n − 1}, respectively. Hence it
can be written as a sum (B(et, es))t,s=1,...,n−1 + δE1,n−1 for some real δ. Note that the ﬁrst summand
is positive semi-deﬁnite by condition (i). On the other hand, A1,n−1 = B(en+1, en−1) by (9). Hence
δ = B(en+1, en−1) − B(e1, en−1) = B(en+1, en−1) − B(en+1, e2n−1), where the second equality follows
from the shift-invariance of B which is in turn a consequence of Lemma 4.4. By virtue of Lemma A.1 we
then get (b) for j = 1.

The other assertions of the second part are proven in a similar way by starting with the remaining

(n − 1) × (n − 1) principal submatrices of A.

Lemma 4.6. Let n ≥ 5, and let A ∈ Cn be such that (uj)T Auj = 0 for all j = 1, . . . , n. Then A ∈ Au,
and B = Λ(A) is positive semi-deﬁnite and satisﬁes the inequalities

B(et, et+2) ≥ B(et+n, et+2)

∀t ≥ 1.

(12)

Moreover, either B satisﬁes all inequalities (12) with equality, namely when A is positive semi-deﬁnite, or
all inequalities (12) are strict, namely when A is exceptional.

Proof. Let A ∈ Cn such that (uj)T Auj = 0 for all j = 1, . . . , n. Then AIj (cid:23) 0 for j = 1, . . . , n by Lemma
2.1. The relation (cj)T AIj cj = (uj)T Auj = 0 then implies AIj cj = 0 for all j = 1, . . . , n, and we get
indeed A ∈ Au. By Lemma 4.5 we then have B (cid:23) 0. From Theorem 2.8 and Lemma 4.5 we obtain (12)
for t = 1, . . . , n, with equality or strict inequality for positive semi-deﬁnite or exceptional A, respectively.
For all other t > n these relations follow by the shift-invariance of B which in turn is implied by Corollary
4.3.

Lemma 4.7. Let B be a positive semi-deﬁnite symmetric bilinear form in the image of Λ which satisﬁes
inequalities (12). Then its pre-image A = Λ−1(B) is copositive and satisﬁes (uj)T Auj = 0 for all j =
1, . . . , n.

Proof. Let B be as required, and let A be its pre-image, which is well-deﬁned by Lemma 4.4. By Lemma 4.5
the submatrices AIj are positive semi-deﬁnite for all j = 1, . . . , n. From A ∈ Au it follows that (uj)T Auj = 0
for all j = 1, . . . , n. Finally, by Lemma 4.5 (12) implies the inequalities (un)T Au1 ≥ 0 and (uj)T Auj+1 ≥ 0,
j = 1, . . . , n − 1. Therefore A ∈ Cn by Theorem 2.8.

Now we are in a position to describe the faces Fu = {A ∈ Cn | (uj)T Auj = 0 ∀ j = 1, . . . , n} of the
+ | (uj)T Auj = 0 ∀ j = 1, . . . , n} of the positive semi-deﬁnite cone which

copositive cone and Pu = {A ∈ Sn
are deﬁned by the zeros uj, by linear matrix inequalities.

Theorem 4.8. Let n ≥ 5, and let Fu be the set of positive semi-deﬁnite symmetric bilinear forms B on
L∗

u satisfying the linear equality relations

B(et, es) = B(M∗et, M∗es),
B(et, es) = B(M∗et, es),

t, s = 1, . . . , n − 3;
1 ≤ t < s ≤ n : 3 ≤ s − t ≤ n − 3

and the linear inequalities

B(et, et+2) ≥ B(M∗et, et+2),

t = 1, . . . , n.

8

Let Pu ⊂ Fu be the subset of forms B which satisfy all linear inequalities with equality.

Then the face of Cn deﬁned by the zeros uj, j = 1, . . . , n, is given by Fu = Λ−1[Fu], and the face of Sn
+
deﬁned by these zeros is given by Pu = Λ−1[Pu]. Moreover, for all forms B ∈ Fu \ Pu the linear inequalities
are satisﬁed strictly, and Fu \ Pu consists of exceptional matrices.

Proof. By virtue of Lemmas 4.4, 4.6, and 4.7 we have only to show that the ﬁnite number of equalities
and inequalities stated in the formulation of the theorem are necessary and suﬃcient to ensure the inﬁnite
number of equalities and inequalities in (5),(10),(12). Necessity is evident, since the relations in the theorem
are a subset of relations (5),(10),(12).

Suﬃciency of the ﬁrst set of equalities in the theorem to ensure (5) follows from Lemma 3.4. By the
resulting shift-invariance of B it is also suﬃcient to constrain the index t to 1, . . . , n in (10). Now suppose
that t ∈ {1, . . . , n}, s > n, and 3 ≤ s − t ≤ n − 3. We then have B(et, es) = B(es, et), B(et+n, es) =
B(et, es−n) = B(es−n, et). Relation (10) for the index pair (t, s) is hence equivalent to the same relation
for the index pair (t′, s′) = (s − n, t), which also satisﬁes 1 ≤ t′ ≤ n and 3 ≤ s′ − t′ ≤ n − 3. For the latter
index pair we now have s′ ≤ n, however. Thus (10) also follows from the linear equalities in the theorem.
Finally, the set of inequalities in the theorem implies (12) by the shift-invariance of B.

Corollary 4.9. Let rmax be the rank achieved by the forms in the (relative) interior of Fu. Then for every
B ∈ ∂Fu \ Pu we have rk B < rmax.

Proof. Let B ∈ ∂Fu \ Pu, and let B′ be a form in the relative interior of Fu. Let l be the line segment
connecting B with B′. When we reach the boundary point B by moving along l, either a rank drop must
occur or one of the linear inequalities must become active. However, the second case cannot happen, because
B 6∈ Pu.

If the vectors in the collection u are in generic position, then the set Fu deﬁned in Theorem 4.8 consists

of the zero form only. In the next section we investigate the consequences of a non-trivial set Fu.

5 Structure of the cones Fu and Pu

As was mentioned in the introduction, the eigenvalues of the monodromy M, the Floquet multipliers, largely
determine the properties of the matrices in the face Fu of Cn. In this section we shall investigate these
connections in detail. In particular, we will be interested in the structure of the cones Pu and Pu = Λ[Pu]
deﬁned by the positive semi-deﬁnite matrices in the face Fu ⊂ Cn and its connections to the periodic
solutions of the system Su. We also investigate the properties of the regular and the degenerate exceptional
copositive matrices as deﬁned in Deﬁnition 1.1.

Denote by Lper ⊂ Lu the subspace of n-periodic solutions. We have the following characterization of

Lper.

Lemma 5.1. An n-periodic inﬁnite sequence x = (x1, x2, . . . ) is a solution of Su if and only if the vector
(x1, . . . , xn)T ∈ Rn is orthogonal to all vectors uj, j = 1, . . . , n. In particular, the dimension of Lper equals
the corank of the n × n matrix U composed of the column vectors u1, . . . , un.

Proof. From the n-periodicity of x it follows that (6) are exactly the orthogonality relations between
(x1, . . . , xn)T and uj. The lemma now readily follows.

We are now in a position to describe the set Pu in terms of the subspace Lper.

Lemma 5.2. Suppose that n ≥ 5. Then Pu equals the convex hull of all tensor products x ⊗ x, x ∈ Lper.
In particular, Pu ≃ Sdim Lper
, and for every B ∈ Pu we have Im B ⊂ Lper. Moreover, for every B ∈ Pu
the preimage A = Λ−1(B) is given by A = (B(et, es))t,s=1,...,n.

+

Proof. Assume x ∈ Lper and set B = x ⊗ x. The n-periodicity of the solution x implies that xt+n = xt
for all t ≥ 1. For every t, s ≥ 1 we then have B(et, es) = xtxs = xt+nxs = B(et+n, es), which yields
(10) and (12) with equality. In a similar way we obtain (5), and hence B ∈ Pu. Moreover, (11) yields
A = Λ−1(B) = (B(et, es))t,s=1,...,n.

9

By convexity of Pu it follows that the convex hull of the set {x ⊗ x | x ∈ Lper} is a subset of Pu, and by

linearity the above expression for A = Λ−1(B) holds also for every B in this convex hull.

Let us prove the converse inclusion. Let B ∈ Pu be arbitrary and set A = Λ−1(B). Then A ∈ Pu by
Theorem 4.8. Since A (cid:23) 0 and (uj)T Auj = 0, it follows that Auj = 0 for all j = 1, . . . , n. Therefore A is in
the convex hull of the set {vvT | hv, uji = 0 ∀ j = 1, . . . , n}. It hence suﬃces to show that for every v ∈ Rn
such that hv, uji = 0, j = 1, . . . , n, we have Λ(vvT ) = x ⊗ x for some x ∈ Lper.

Let v ∈ Rn be orthogonal to all zeros uj. By Lemma 5.1 the n-periodic inﬁnite sequence x = (x1, x2, . . . )
deﬁned by the initial conditions xi = vi, i = 1, . . . , n, is an n-periodic solution of Su, x ∈ Lper. But
Λ(vvT ) = x ⊗ x by construction. This completes the proof.

We now consider the ranks of the forms in Fu and Pu. Let rmax be the maximal rank achieved by forms

in Fu, and rP SD the maximal rank achieved by forms in Pu.

Corollary 5.3. Suppose n ≥ 5. Then rP SD equals the geometric multiplicity of the eigenvalue 1 of the
monodromy operator M of the dynamical system Su.

Proof. The corollary follows from Lemmas 3.1 and 5.2.

Lemma 5.4. Let n ≥ 5, and let B ∈ Fu \ Pu. Then for every k ≥ 1 the matrix

Mk = (B(et+k − et+n+k, es+k))t=0,...,n−5;s=2,...,n−3 = (B((Id − M∗)et+k, es+k))t=0,...,n−5;s=2,...,n−3

has full rank n − 4.

Proof. By Lemma 4.6 the form B satisﬁes inequalities (12) strictly, which implies that Mk has all diagonal
elements positive. By (10) Mk is lower-triangular, and hence has full rank n − 4.

Corollary 5.5. Let n ≥ 5, and let B ∈ Fu \ Pu. Then the bilinear form on L∗
B((Id − M∗)w, w′) has corank at most 1.
Moreover, M has at least n − 4 linearly independent eigenvectors with eigenvalues on the unit circle.

u given by (w, w′) 7→
In particular, both B and Id − M∗ have corank at most 1.

Proof. The bilinear form in the statement of the lemma has at least the same rank, namely n − 4, as the
matrices Mk in Lemma 5.4. Hence it has corank at most 1. It follows that B has corank at most 1, and
the proof is concluded by application of Lemma 3.5.

Corollary 5.6. Suppose n ≥ 5. If Fu 6= Pu, then rmax −rP SD ≥ n−4. In particular, in this case rP SD ≤ 1
and either rmax = n − 4 or rmax = n − 3.

Proof. Let B ∈ Fu \ Pu. Suppose there exists B′ ∈ Pu such that B (cid:23) B′. Then also B − B′ ∈ Fu \ Pu.
Therefore we may assume without loss of generality that there does not exist a non-zero B′ ∈ Pu such
that B − B′ (cid:23) 0. By Lemma 5.2 we then have Im B ∩ Lper = {0}, and hence for every B′ ∈ Pu we get
rk(B + B′) = rk B + rk B′, again by Lemma 5.2.

Let now B′ ∈ Pu such that rk B′ = rP SD. By Corollary 5.5 we have rk B ≥ n − 4, and hence

rmax ≥ rk B + rk B′ = n − 4 + rP SD. This completes the proof.

These results allow us to completely characterize the face Fu in the case when Fu does not contain

positive deﬁnite forms.

Lemma 5.7. Suppose n ≥ 5 and assume rmax = n − 4. Then either Fu consists of positive semi-deﬁnite
matrices only, or Fu is 1-dimensional and generated by an extremal exceptional copositive matrix A. In the
latter case the submatrices AIj of this exceptional matrix have corank 2 for all j = 1, . . . , n.

Proof. By Corollaries 4.9 and 5.5 we have the inclusion ∂Fu ⊂ Pu. Therefore either Fu = Pu, or Fu is
1-dimensional and Pu = {0}. The ﬁrst claim of the lemma now follows from Theorem 4.8. The second
claim then follows from Corollary 4.2.

We shall now concentrate on the case when Fu contains positive deﬁnite forms, i.e., the maximal rank

achieved by matrices in Fu equals rmax = d = n − 3.

Lemma 5.8. Let n ≥ 5. Then the following are equivalent:

10

(i) the set Fu contains a positive deﬁnite form and Fu = Pu;
(ii) the monodromy operator M of the system Su equals the identity;
(iii) the rank of the n × n matrix U with columns u1, . . . , un equals 3.

Proof. Assume (ii). The LMIs in Theorem 4.8 reduce to the condition B (cid:23) 0, and hence Fu = Pu = Sn−3
+ ,
implying (i).

Assume (i). We have rmax = rP SD = n − 3, and (ii) follows from Corollary 5.3.
By Lemma 3.1 we have M = Id if and only if dim Lper = n − 3. By Lemma 5.1 this is equivalent to the

condition rk U = 3, which proves (ii) ⇔ (iii).

In order to treat the case rmax = n − 3 and Fu 6= Pu we shall distinguish between odd and even orders

n.

Lemma 5.9. Let n > 5 be even, and suppose rmax = n − 3 and Fu 6= Pu. Then Fu is linearly isomorphic
to R2
+, where one boundary ray of Fu is generated by a rank 1 positive semi-deﬁnite matrix, and the other
boundary ray is generated by an extremal exceptional copositive matrix A. The submatrices AIj of this
exceptional matrix have corank 2 for all j = 1, . . . , n.

Proof. By Lemma 3.5 all eigenvalues of the monodromy M of the system Su lie on the unit circle and
their geometric and algebraic multiplicities coincide. However, since M is real, its complex eigenvalues
are grouped into complex-conjugate pairs. Since the dimension d = n − 3 of L∗
u is odd, there must be
exactly one real eigenvalue with an odd multiplicity. By (8) this eigenvalue equals 1. Hence rP SD is odd
by Corollary 5.3, but cannot exceed 1 by Corollary 5.6. Therefore dim Lper = 1 and dim Pu = dim Pu = 1,
and Pu is generated by a rank 1 positive semi-deﬁnite matrix AP .

Denote the 1-dimensional eigenspace of M∗ to the eigenvalue 1 by W1, and let L⊥

orthogonal complement of Lper. Then L⊥
now w1 ∈ W1 and w ∈ L⊥
B(w1, w) = B(M∗w1, M∗w) = B(w1, M∗w), and hence B(w1, (Id − M∗)w) = 0 for all w ∈ L⊥
(Id − M∗)[L⊥
with the kernel W1 of Id − M∗. It follows that W1 and L⊥

u be the
per. Let
per be arbitrary vectors. Then for every B ∈ Fu we get by the shift-invariance
per. But
per is an invariant subspace of Id − M∗ and it has a zero intersection

per is an invariant subspace of M∗ and L∗

per ⊂ L∗
u = W1 + L⊥

per are orthogonal under B.

per, because L⊥

per] = L⊥

This implies that every B ∈ Fu can in a unique way be decomposed into a sum B = B′ + P of
positive semi-deﬁnite forms, with P ∈ Pu and W1 ⊂ ker B′. Moreover, for every B ∈ Fu the corresponding
summand B′ is also in Fu, because P satisﬁes inequalities (12) with equality. Thus the cone Fu splits into
a direct sum F ′

u = {B ∈ Fu | W1 ⊂ ker B}.

u + Pu, where F ′

By assumption F ′

u 6= {0}. Any non-zero form in F ′

u lies in ∂Fu \ Pu and hence must be rank deﬁcient
by Corollary 4.9. On the other hand, any such form has corank at most 1 by Corollary 5.5, and hence its
rank equals n − 4. Thus the rank is constant over all forms in F ′
u \ {0} and inequalities (12) are satisﬁed
strictly. Hence F ′
u is a ray
generated by a single form B′. By Theorem 4.8 A′ = Λ−1(B′) is then an exceptional extremal copositive
matrix, and Fu ≃ R2
also have rank
n − 4 by Corollary 4.2, and hence corank 2.

+ is generated by A′ and AP . Since rk B′ = n − 4, the submatrices A′
Ij

u \ {0} must be contained in the relative interior of F ′

u, which implies that F ′

Lemma 5.10. Let n ≥ 5 be odd, and suppose rmax = n − 3 and Fu 6= Pu. Then Fu does not contain
non-zero positive semi-deﬁnite matrices.

If Fu is 1-dimensional, then it is generated by an extremal exceptional copositive matrix A such that the

submatrices AIj have corank 1 for all j = 1, . . . , n.

If dim Fu > 1, then the monodromy M of the system Su possesses the eigenvalue −1, and all boundary
rays of Fu are generated by extremal exceptional copositive matrices. For any such boundary matrix A, its
submatrices AIj have corank 2 for all j = 1, . . . , n.

Proof. As in the proof of the previous lemma, M has all eigenvalues on the unit circle, with equal geometric
and algebraic multiplicities. However, now dim L∗
u = n − 3 is even, and by (8) the real eigenvalues ±1, if
they appear, have even multiplicity. By Corollaries 5.3 and 5.6 the multiplicity of the eigenvalue 1 cannot
exceed 1 and this eigenvalue does not appear. By Lemma 5.2 we get Pu = {0} and by Theorem 4.8 the
face Fu does not contain non-zero positive semi-deﬁnite matrices.

11

Suppose now that Fu is not 1-dimensional. Then ∂Fu \Pu = ∂Fu \{0} is not empty and by Corollary 4.9
consists of rank deﬁcient forms. On the other hand, the rank can drop at most by 1 by virtue of Corollary
5.5. Hence dim ker B = 1 for all B ∈ ∂Fu \ {0}. This kernel must be a real eigenspace of M∗, because
M∗ preserves the form B by shift-invariance. Therefore M∗ must have a real eigenvalue, which can only
be equal to −1. Moreover, since the boundary subset ∂Fu \ {0} consists of forms of corank 1, it must be
smooth and every boundary ray is extremal. Indeed, if ∂Fu would contain a face of dimension exceeding
1, then the boundary of this face would be diﬀerent from {0}, but no further rank drop could occur there.
Hence the pre-image Λ−1[∂Fu \ {0}] consists of extremal exceptional copositive matrices. By Corollary 4.2
the submatrices AIj of such a matrix A have rank n − 4, or corank 2, for all j = 1, . . . , n.

If, on the contrary, dim Fu = 1, then Fu is generated by an extremal exceptional copositive matrix A.
By assumption the form B = Λ(A) is positive deﬁnite and has rank n − 3. By Corollary 4.2 the submatrices
AIj also have rank n − 3 for all j = 1, . . . , n.

Finally, we shall investigate the zero set of exceptional copositive matrices A ∈ Fu.

Lemma 5.11. Suppose n ≥ 5, and let A ∈ Fu be an exceptional copositive matrix. If v ∈ Rn
A, then there exists an index j ∈ {1, . . . , n} such that supp v ⊂ Ij.

+ is a zero of

Proof. Since A is exceptional, we cannot have supp v = {1, . . . , n} by Lemma 2.1. Therefore supp v is
a subset of {1, . . . , n} \ {k} for some k ∈ {1, . . . , n}. Without loss of generality, assume that supp v ⊂
{1, . . . , n − 1}. By Theorem 2.8 we have (u1)T Au2 > 0, and hence by Lemma A.1 we have A(1,...,n−1) =
P + δE1,n−1 for some positive semi-deﬁnite matrix P ∈ Sn−1
and some δ > 0. Since v is a zero of A, we get
that the subvector v(1,...,n−1) ∈ Rn−1
is a zero of both P and E1,n−1. It follows that the ﬁrst and the last
element of this subvector cannot be simultaneously positive, which implies supp v ⊂ I1 or supp v ⊂ I2.

+

+

Theorem 5.12. Let A ∈ Fu be an exceptional copositive matrix and set B = Λ(A). Then either

(i.a) A is regular;
(i.b) B is positive deﬁnite;
(i.c) the corank of the submatrices AIj equals 1, j = 1, . . . , n;
(i.d) the minimal zero pattern of A is {I1, . . . , In}, with minimal zeros u1, . . . , un;
(i.e) for even n the matrix A is the sum of a degenerate exceptional copositive matrix and a rank 1 positive

semi-deﬁnite matrix;

(i.f ) if n is odd and the monodromy operator M has no eigenvalue equal to −1, then A is extremal;

or

(ii.a) A is degenerate;
(ii.b) the corank of B equals 1;
(ii.c) the corank of the submatrices AIj equals 2, j = 1, . . . , n;
(ii.d) the support of any minimal zero of A is a strict subset of one of the index sets I1, . . . , In, and every

index set Ij has exactly two subsets which are supports of minimal zeros of A;

(ii.e) every non-minimal zero of A has support equal to Ij for some j = 1, . . . , n and is a sum of two

minimal zeros;
(ii.f ) A is extremal.

Proof. By Corollary 5.5 the form B is either positive deﬁnite or has corank 1. By Corollary 4.2 the
submatrices AIj have corank 1 in the ﬁrst case and corank 2 in the second case, for all j = 1, . . . , n. Hence
the zeros uj are minimal in the ﬁrst case and not minimal in the second case, for all j = 1, . . . , n. By Lemma
5.11 A is regular in the ﬁrst case, and there are no index sets other than I1, . . . , In which are supports of
minimal zeros of A. Thus either (i.a)—(i.d) or (ii.a)—(ii.c) hold.

Assume the second case. By Lemma 5.11 every support of a minimal zero of A is then a strict subset of
one of the sets I1, . . . , In. The set of zeros v of A satisfying supp v ⊂ Ij is determined by the intersection of
the two-dimensional kernel of AIj with the nonnegative orthant. However, every two-dimensional convex
cone is linearly isomorphic to R2
+ and is hence the convex hull of two extreme rays. Assertions (ii.d),(ii.e)
then readily follow. The maximal rank achieved by forms in Fu equals either n − 4 or n − 3 by Corollary

12

5.6. In the ﬁrst case (ii.f) follows from Lemma 5.7, in the second case from Lemma 5.9 or 5.10, dependent
on the parity of n.

Assume (i.a)—(i.d). Then (i.e) and (i.f) follow from Lemmas 5.9 and 5.10, respectively.

The prototype of exceptional copositive matrices satisfying conditions (i.a)—(i.f) are the T -matrices

(2), while the prototype of those satisfying (ii.a)—(ii.f) is the Horn matrix (1).

6 Submanifolds of extremal exceptional copositive matrices

In the previous two sections we considered the face Fu ⊂ Cn for a ﬁxed collection u of zeros. In Theorem
5.12 we have shown that there are two potential possibilities for an exceptional copositive matrix A in such
a face Fu. Namely, either A is regular, or A is degenerate, either imposing its own set of conditions on A. In
this section we show that in each of these cases, the matrix A is embedded in a submanifold of codimension
n or 2n, respectively, which consists of exceptional copositive matrices with similar properties. However,
diﬀerent matrices in this submanifold may belong to faces Fu corresponding to diﬀerent collections u. Recall
that regular and degenerate are understood in the sense of Deﬁnition 1.1.

Theorem 6.1. Let n ≥ 5, and let ˆA ∈ Cn be a regular exceptional matrix with zeros ˆu1, . . . , ˆun ∈ Rn
that supp ˆuj = Ij . Then there exists a neighbourhood U ⊂ Sn of ˆA with the following properties:

+ such

(i) if A ∈ U and det AIj = 0 for all j = 1, . . . , n, then A is a regular exceptional copositive matrix;
(ii) the set of matrices A ∈ U satisfying the conditions in (i) is an algebraic submanifold of codimension

n in Sn.

Proof. By Theorem 5.12 the submatrices ˆAIj have rank n − 3 for j = 1, . . . , n. Let A be suﬃciently close
to ˆA and such that det AIj = 0 for all j = 1, . . . , n. The submatrix AIj has n − 3 positive eigenvalues by
continuity and one zero eigenvalue by assumption, and hence is positive semi-deﬁnite for all j = 1, . . . , n.
Moreover, the kernel of AIj is close to the kernel of ˆAIj and hence is generated by an element-wise positive
vector for all j = 1, . . . , n. We then ﬁnd vectors u1, . . . , un ∈ Rn
+, close to ˆu1, . . . , ˆun, such that supp uj = Ij
and the subvector uj
is in the kernel of AIj . Then (uj)T Auj = 0 for all j = 1, . . . , n, and (uj)T Auk
Ij
is close to (ˆuj)T ˆAˆuk for all j, k = 1, . . . , n. By Theorem 2.8 we have (ˆun)T ˆAˆu1 > 0, (ˆuj)T ˆAˆuj+1 > 0,
j = 1, . . . , n − 1, and hence also (un)T Au1 > 0, (uj)T Auj+1 > 0, j = 1, . . . , n − 1. By Theorem 2.8 we then
get that A is a copositive exceptional matrix. By Theorem 5.12 the matrix A is regular, which proves (i).
Consider the set M = {X ∈ Sn | det XIj = 0 ∀ j = 1, . . . , n}. It is deﬁned by n polynomial equations,
and ˆA ∈ M. By virtue of Lemma A.2 the gradient of the function det XIj at X = ˆA is proportional to
the rank 1 matrix ˆuj(ˆuj)T . By Lemmas 5.1, 5.2, and Corollary 5.6 the linear span of the zeros ˆuj has
dimension at least n − 1. Since no two of these zeros are proportional, the gradients of the functions det XIj
are linearly independent at X = ˆA by Lemma A.3. It follows that M is a smooth algebraic submanifold of
codimension n in a neighbourhood of ˆA. This proves (ii).

Theorem 6.2. The extremal regular exceptional copositive matrices form an open subset of the manifold
of all regular exceptional matrices.

Proof. Assume the notations in the proof of the previous theorem, and suppose that ˆA is extremal. The
inequalities (un)T Au1 > 0, (uj)T Auj+1 > 0, j = 1, . . . , n − 1 imply that the element (Auj)i vanishes if and
only if i ∈ Ij . Thus by Lemma 2.6 the matrix A is extremal if and only if the linear system of equations on
the matrix X ∈ Sn given by

(Xuj)i = 0

∀ i ∈ Ij, j = 1, . . . , n

(13)

has a 1-dimensional solution space. The coeﬃcients of this system depend linearly on the entries of the
zeros uj. Moreover, since ˆA is extremal, system (13) has a 1-dimensional solution space for uj = ˆuj. But
the rank of a matrix is a lower semi-continuous function, hence the solution space of (13) has dimension at
most 1 if the zeros uj are suﬃciently close to ˆuj. However, X = A is always a solution, and therefore A is
an extremal copositive matrix.

13

The simplest manifold of the type described in Theorem 6.2 is the 10-dimensional union of the G5-orbits
of the T -matrices (2). Matrices (2) themselves depend on 5 parameters, while the action of G5 adds another
5 parameters.

Theorem 6.3. Let n ≥ 5, and let ˆA ∈ Cn be a degenerate exceptional matrix having zeros ˆu1, . . . , ˆun ∈ Rn
+
such that supp ˆuj = Ij. Then there exists a neighbourhood U ⊂ Sn of ˆA with the following properties:

(i) if A ∈ U and rk AIj = n − 4 for all j = 1, . . . , n, then A is a degenerate exceptional extremal copositive

matrix;

(ii) the set of matrices A ∈ U satisfying the conditions in (i) is an algebraic submanifold of codimension

2n in Sn.

Proof. By Theorem 5.12 the submatrices ˆAIj have rank n − 4 for j = 1, . . . , n. Let A be suﬃciently close to
ˆA and suppose that rk AIj = n − 4 for all j = 1, . . . , n. By continuity the n − 4 largest eigenvalues of AI1 are
then positive. However, the remaining two eigenvalues of AI1 are zero by assumption, and hence AI1 (cid:23) 0.
Now the kernel of AI1 is close to that of ˆAI1 , hence ker AI1 contains a positive vector close to ˆu1
I1. Then
+, close to ˆu1, such that supp u1 = I1 and (u1)T Au1 = 0. In a similar way we
there exists a vector u1 ∈ Rn
construct vectors uj ∈ Rn
+, close to ˆuj, such that supp uj = Ij and (uj)T Auj = 0, for all j = 1, . . . , n. By
virtue of Theorem 2.8 we have (ˆun)T ˆAˆu1 > 0 and (ˆuj)T ˆAˆuj+1 > 0 for all j = 1, . . . , n − 1. By continuity
we then get (un)T Au1 > 0 and (uj)T Auj+1 > 0 for all j = 1, . . . , n − 1. Again by Theorem 2.8 it then
follows that A is an exceptional copositive matrix. By Theorem 5.12 the matrix A is also degenerate and
extremal, which proves (i).

The proof of (ii) is a bit more complicated. Set ˆu = {ˆu1, . . . , ˆun}. By Lemma 4.6 we have ˆA ∈ Aˆu. Let

ˆB = Λ( ˆA) be the positive semi-deﬁnite symmetric bilinear form corresponding to ˆA.

By Corollary 4.2 each of the principal submatrices ˆAI ′
i = 0 for all i 6∈ I ′

we deﬁne a vector ˆvj ∈ Rn such that ˆvj
We now claim the following:

j

has a 1-dimensional kernel. For every j = 1, . . . , n,
generates the kernel of ˆAI ′
j and the subvector ˆvj
I ′
j

.

j

(a) for every j = 1, . . . , n − 1 we have ker ˆAIj = span{ˆvj, ˆvj+1}, and ker ˆAIn = span{ˆvn, ˆv1};
(b) the ﬁrst and the last element of the subvector ˆvj
I ′
j
(c) the vectors ˆv1, . . . , ˆvn are linearly independent.

is non-zero for all j = 1, . . . , n;

Since the positive semi-deﬁnite quadratic form ˆAI2 vanishes on the subvectors ˆv2
I2
I2 ∈ ker ˆAI2 . Now dim ker ˆAI2 = 2, and hence either ker ˆAI2 = span{ˆv2
, ˆv3

I2 , we have that
I2 }, or ˆv2, ˆv3 are linearly

, ˆv3

, ˆv3

I2

ˆv2
I2
dependent.

2 ∩ I ′

3 = {3, . . . , n − 2}. The relation ˆAI2 ˆv2

intersection I ′
for all t = 2, . . . , n − 1. The evaluation functionals e2, . . . , en−1 span the whole space L∗

Assume the latter for the sake of contradiction. Then the non-zero elements of ˆv2 have indices in the
ˆB(et, es) = 0
ˆu, and therefore
ˆB(et − et+n, es) = 0 for
all t = 1, . . . , n − 4. Since ˆA is exceptional, by virtue of Lemma 5.4 the coeﬃcient matrix of this linear
homogeneous system on the elements of ˆv2 is regular. Therefore ˆv2 = 0, leading to a contradiction.

ˆB(et, es) = 0 for all t ≥ 1. In particular, we get Pn−2

I2 = 0 together with (9) yieldsPn−2

we must have Pn−2

s=3 ˆv2
s

s=3 ˆv2
s

s=3 ˆv2
s

It follows that ker ˆAI2 = span{ˆv2
I2

I2 }, and by repeating the argument after circular shifts of the indices
we obtain (a). Since ˆu1 ∈ ker ˆAI1 , we have ˆu1 = αˆv1 + βˆv2 for some coeﬃcients α, β. In particular, we have
ˆu1
1 = αˆv1
n−2 6= 0. Repeating the argument
after circular shifts of the indices we obtain (b).

1 6= 0. Similarly, ˆu1

n−2 > 0 implies ˆv2

1 > 0, implying ˆv1

n−2 = βˆv2

, ˆv3

Finally, let w ∈ Rn be such that hˆvj , wi = 0 for all j = 1, . . . , n. By (a) and by Lemma 5.11 we have
that every zero of ˆA is a linear combination of the vectors ˆvj. It follows that w is orthogonal to all zeros
of ˆA. By Lemma 2.7 there exists ε > 0 such that ˆA − εwwT ∈ Cn. But by Theorem 5.12 ˆA is extremal.
Therefore we must have w = 0, which yields (c).

We now prove (ii). Consider the set

M =(X ∈ Sn (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

= 0 ∀j = 1, . . . , n;

det XI ′
det(Xik)i∈I ′

j

j ;k∈I ′

j+1

= 0 ∀j = 1, . . . , n − 1; det(Xik)i∈I ′

n;k∈I ′

1

14

= 0 ) .

It is deﬁned by 2n polynomial equations, and ˆA ∈ M. By Lemma A.4 in a neighbourhood of ˆA the manifold
M coincides with the set of matrices A satisfying condition (i).

Now by virtue of Lemma A.2 the gradient of the function det XI ′

at X = ˆA is proportional to the rank
1 matrix ˆvj(ˆvj )T , the gradient of det(Xik)i∈I ′
is proportional to the rank 1 matrix ˆvj(ˆvj+1)T , and
is proportional to ˆvn(ˆv1)T . By (c) the vectors ˆvj are linearly independent,
the gradient of det(Xik)i∈I ′
hence these 2n gradients are also linearly independent. It follows that M is a smooth algebraic submanifold
of codimension 2n in a neighbourhood of ˆA. This proves (ii).

n;k∈I ′

j ;k∈I ′

j+1

1

j

The simplest manifold of the type described in Theorem 6.3 is the 5-dimensional G5-orbit of the Horn

matrix (1).

7 Existence of non-trivial faces

So far we have always supposed that the feasible sets Fu or Pu of the LMIs in Theorem 4.8 contain non-
zero forms. In this section we shall explicitly construct non-zero faces Fu and Pu for arbitrary matrix sizes
n ≥ 5.

7.1 Faces consisting of positive semi-deﬁnite matrices

In this subsection we construct non-zero faces Fu of Cn which contain only positive semi-deﬁnite matrices,
i.e., which satisfy Fu = Pu.

We shall need the following concept of a slack matrix, which has been introduced in [20] for convex
polytopes. Let K ⊂ Rm be a polyhedral convex cone, and let K ∗ = {f ∈ Rm | hf, xi ≥ 0 ∀ x ∈ K} be its
dual cone, where Rm is the space of linear functionals on Rm. Then K ∗ is also a convex polyhedral cone.
Let x1, . . . , xr be generators of the extreme rays of K, and f1, . . . , fs generators of the extreme rays of K ∗.

Deﬁnition 7.1. Assume the notations of the previous paragraph. The slack matrix of K is the nonnegative
s × r matrix (hfi, xji)i=1,...,s;j=1,...,r.

+ be such that supp uj = Ij for all j = 1, . . . , n.
Theorem 7.2. Assume n ≥ 5, and let u = {u1, . . . , un} ⊂ Rn
Let U be the n × n matrix with columns u1, . . . , un. Then the face Fu consists of positive semi-deﬁnite
matrices up to rank n − 3 inclusively if and only if U is the slack matrix of a convex polyhedral cone K ⊂ R3
with n extreme rays.

Proof. By Theorem 4.8 and Lemma 5.8 we have Fu = Pu ≃ Sn−3

if and only if rk U = 3.

+

Assume rk U = 3. Choose a factorization U = ULU T

R , with UL, UR being rank 3 matrices of size n × 3.
No two columns of U and hence no two rows of UR are proportional, because Ij 6⊂ Ik for every j 6= k.
Denote the convex conic hull of the rows of UR by K. Row n of UL is orthogonal to rows 1 and 2 of UR
and has a positive scalar product with the other rows of UR. Therefore row n of UL deﬁnes a supporting
hyperplane to K, and the two-dimensional convex conic hull of row 1 and row 2 of UR is a subset of the
boundary of K. By a circular shift of the indices and by repeating the argument we extend the construction
of the boundary of K until it closes in on itself. We obtain that K is a polyhedral cone with n extreme rays
generated by the rows of UR. On the other hand, the rows of UL deﬁne exactly the supporting hyperplanes
to K which intersect K in its two-dimensional faces. Therefore the dual cone K ∗ is given by the convex
conic hull of the rows of UL. The relation U = ULU T

R then reveals that U is the slack matrix of K.

On the other hand, a convex polyhedral cone K ⊂ R3 with n ≥ 3 extreme rays as well as its dual K ∗
have a linear span of dimension 3. Therefore the slack matrix of such a cone has rank 3. This completes
the proof.

Theorem 7.2 provides a way to construct all collections u ⊂ Rn

+ of vectors u1, . . . , un satisfying supp uj =
Ij , j = 1, . . . , n, such that the face Fu of Cn consists of positive semi-deﬁnite matrices only and is linearly
isomorphic to Sn−3
+ . By perturbing some of the zeros uj in such a collection, we obtain faces Fu for which
the subset Pu of positive semi-deﬁnite matrices is isomorphic to Sk
+ with arbitrary rank k = 0, . . . , n − 3.
For k ≥ 2 we have by Corollary 5.6 that Fu = Pu.

15

7.2 Circulant matrices

In this section we consider faces Fu deﬁned by special collections u. Let u ∈ Rn−2
be palindromic,
invariant with respect to inversion of the order of its entries, and with positive entries. Deﬁne
i.e.,
u = {u1, . . . , un} ⊂ Rn
= u for all j = 1, . . . , n. By construction,
the linear dynamical system Su deﬁned by u has constant coeﬃcients, namely the entries of u. Let

+ such that supp uj = Ij and uj
Ij

+

p(x) =Pn−3

k=0 uk+1xk be the characteristic polynomial of Su.

We provide necessary and suﬃcient conditions on u such that the corresponding face Fu ⊂ Cn contains
exceptional copositive matrices, and construct explicit collections u which satisfy these conditions. We show
that the copositive matrices in these faces must be circulant, i.e., invariant with respect to simultaneous
circular shifts of its row and column indices.

Lemma 7.3. Suppose the collection u is as in the ﬁrst paragraph of this section. If Fu 6= Pu, then Fu
contains exceptional circulant matrices.

Proof. Let A1 ∈ Fu be exceptional. By simultaneous circular shifts of the row and column indices of A1
we obtain copositive matrices A2, . . . , An which are also elements of Fu. Then A = 1
j=1 Aj ∈ Fu is a
copositive circulant matrix. By Theorem 2.8 it is also exceptional.

nPn

Lemma 7.4. Suppose the collection u is as above, let n ≥ 5, and let A ∈ Fu be a circulant matrix. Then
the symmetric bilinear form B = Λ(A) satisﬁes B(et, es) = B(et+l, es+l) for all t, s, l ≥ 1.

Proof. Deﬁne matrices Br,l = (B(er+t, er+s))t,s=0,...,l of size (l + 1) × (l + 1), r ≥ 1, l ≥ d. By Lemma 4.1
for l = d the matrices Br,l are equal to a single matrix Bl for all r ≥ 1, and this matrix Bl is Toeplitz,
rank-deﬁcient, and has an element-wise positive kernel vector. We now show by induction that this holds
also for all l > d.

Indeed, the entries of the positive semi-deﬁnite matrices Br,l+1 are all determined by the matrix Bl,
except the upper right (and lower left) corner element. Since Bl has a kernel vector with positive elements,
Lemma A.1 is applicable and these corner elements are unique and hence all equal for all r ≥ 1. It follows
that the matrices Br,l+1 are all equal to a single matrix Bl+1. By construction this matrix is also Toeplitz
and rank-deﬁcient. Moreover, if w ∈ ker Bl is element-wise positive, then (wT , 0)T + (0, wT )T ∈ ker Bl+1 is
also element-wise positive.

The claim of the lemma now easily follows.

Corollary 7.5. Assume the conditions of the previous lemma and set r = ⌊ rk B
angles ϕ0 = π, ϕ1, . . . , ϕr ∈ (0, π) and positive numbers λ0, . . . , λr such that

2 ⌋. Then there exist distinct

B(et, es) =(cid:26) Pr
Pr

j=0 λj cos(|t − s|ϕj ),
j=1 λj cos(|t − s|ϕj ),

rk B odd;
rk B even

for all t, s ≥ 1. Moreover, e±iϕj are roots of p(x) for all j = 1, . . . , r. In addition, if rk B is odd, then −1
is also a root of p(x).

Proof. By Theorem 4.8 we have B ∈ Fu. Hence the Toeplitz matrix T = (B(ei, ej))i,j=1,...,n−2 is positive
semi-deﬁnite, rank-deﬁcient and of the same rank as B, and has the element-wise positive kernel vector u.
The corollary follows by application of Lemma A.5 to T and by Lemma 7.4.

With the representation for B(et, es) given by Corollary 7.5 relations (10) become

j=0 λj(cos((n − k)ϕj ) − cos(kϕj)) = 0,
j=1 λj(cos((n − k)ϕj ) − cos(kϕj)) = 0,

rk B odd,
rk B even,

3 ≤ k <

n
2

,

where k takes integer values, and inequalities (12) become

(14)

(15)

Pr
Pr

Pr
Pr

j=0 λj(cos((n − 2)ϕj) − cos(2ϕj)) ≤ 0,
j=1 λj(cos((n − 2)ϕj) − cos(2ϕj)) ≤ 0,

rk B odd,
rk B even.

Note that (14) is a linear homogeneous system of equations on the weights λj.

16

Lemma 7.6. Let n > 5 be even, let u be as above, and let A ∈ Fu be an exceptional copositive circulant
matrix. Then there exist m = n
2 − 2 distinct angles ζ1, . . . , ζm ∈ (0, π), arranged in increasing order, with
the following properties:

(a) the fractional part of nζj

4π is in (0, 1

2 ) for odd j and in ( 1

2 , 1) for even j;

(b) the polynomial p(x) is proportional to the polynomial (x + 1) ·Qm

(c) there exist c > 0, λ ≥ 0 such that for all k = 1, . . . , n

2 + 1 we have

j=1(x2 − 2x cos ζj + 1);

A1k = (−1)k−1λ + c ·

m

Xj=1

cos(k − 1)ζj

sin ζj sin nζj

2 Ql6=j(cos ζj − cos ζl)

.

(16)

If λ = 0, then A is degenerate and extremal. If λ > 0, then A is regular and not extremal.

Proof. Let B = Λ(A) and apply Corollary 7.5. By Corollary 5.5 we have either rk B = n − 4 or rk B = n − 3
and hence m = r. Deﬁne ζ1, . . . , ζm to be the angles ϕ1, . . . , ϕr, arranged in increasing order. Then e±iζj
j=1(x2 − 2x cos ζj + 1) for some
α > 0 and real β. Since the coeﬃcient vector u of p(x) is palindromic, we must have β = −1, which proves
(b).

are roots of p(x) by Corollary 7.5, and p(x) is of the form α · (x − β) ·Qm

By (9) we have A1k = B(e1, ek), k = 1, . . . , n+1

2 , which in turn is given by Corollary 7.5. Here the
weights λj satisfy relations (14),(15), the inequality being strict by Lemma 4.6. We have ϕ0 = π and
hence cos((n − k)ϕ0) = cos(kϕ0) for all integers k. Therefore (14),(15) do not impose any conditions on
the coeﬃcient λ0, and these m relations can be considered as conditions on λ1, . . . , λm only. By Corollary
A.8 there are no multiples of 2π
n among the angles ζ1, . . . , ζm, and the coeﬃcient vector (λ1, . . . , λm) is
proportional to solution (27) in this corollary. This yields (c) with c > 0, with λ = 0 if rk B = n − 4, and
with λ = λ0 > 0 if rk B = n − 3.

The last assertions of the lemma now follow from Theorem 5.12.
Finally, the weights λ1, . . . , λm are positive by Corollary 7.5, and their explicit expression from Corollary

A.8 yields sin ζj sin nζj
and the ζj are arranged in increasing order, it follows that sgn sin nζj
which implies (a).

2 Ql6=j(cos ζj − cos ζl) > 0. Since the cosine function is strictly decreasing on (0, π)
2 = sgnQl6=j(cos ζj − cos ζl) = (−1)j+1,

Lemma 7.7. Let n ≥ 5 be odd, let u be as above, and let A ∈ Fu be an exceptional copositive circulant
matrix. Then there exist m = n−3
2 distinct angles ζ1, . . . , ζm ∈ (0, π], arranged in increasing order, with the
following properties:

(a) the fractional part of nζj

4π is in (0, 1

2 ) for odd j and in ( 1

(b) the polynomial p(x) is proportional to the polynomial Qm

(c) there exists c > 0 such that for all k = 1, . . . , n+1

2 we have

2 , 1) for even j;
j=1(x2 − 2x cos ζj + 1);

A1k = c ·

m

Xj=1

cos(k − 1)ζj

sin ζj

2 sin nζj

2 Ql6=j (cos ζj − cos ζl)

.

(17)

The matrix A is degenerate if ζm = π and regular if ζm < π. In both cases A is extremal.

Proof. Let B = Λ(A) and apply Corollary 7.5. By Corollary 5.5 we have either rk B = n− 4 or rk B = n− 3,
which gives m = r + 1 or m = r, respectively. Deﬁne ζ1, . . . , ζm to be the angles ϕ0, . . . , ϕr in the ﬁrst
case and ϕ1, . . . , ϕr in the second case, arranged in increasing order. Then ζm = π if rk B = n − 4 and
ζm < π if rk B = n − 3. By Corollary 7.5 the numbers e±iζj are roots of p(x), and p(x) is of the form
j=1(x2 − 2x cos ζj + 1) if ζm < π, for
some α > 0 and real β. Since the coeﬃcient vector u of p(x) is palindromic, we must have β = −1, which
proves (b).

j=1 (x2 − 2x cos ζj + 1) if ζm = π and p(x) = α ·Qm

α · (x + 1) · (x − β) ·Qm−1

By Theorem 5.12 the matrix A is degenerate and extremal if ζm = π, and regular if ζm < π.
By (9) we have A1k = B(e1, ek), k = 1, . . . , n+1

2 , which in turn is given by Corollary 7.5. Here the m
coeﬃcients λj satisfy the m relations (14),(15), the inequality being strict by Lemma 4.6. By Corollary
A.8 there are no multiples of 2π
n among the angles ζ1, . . . , ζm, and the coeﬃcient vector (λ1, . . . , λm) is
proportional to solution (27) in this corollary. This yields (c) with c > 0.

Assertion (a) is obtained in the same way as in the proof of Lemma 7.6.

17

It remains to show the extremality of A for ζm < π. By Lemma B.4 in Appendix B the dimension of
the space Au cannot exceed 1, otherwise we obtain a contradiction with the nonnegativity of u. It follows
that dim Fu = 1 and A is extremal in Cn.

Note that the elements A1k, k = 1, . . . , ⌈ n+1

2 ⌉, determine the matrix A completely by its circulant prop-
erty. We obtain the following characterization of collections u deﬁning faces Fu which contain exceptional
matrices.

Theorem 7.8. Let n > 5 be even, m = n
2 − 2, and let u and p(x) be as in the ﬁrst paragraph of this section.
Then Fu 6= Pu if and only if there exist distinct angles ζ1, . . . , ζm ∈ (0, π), arranged in increasing order,
such that conditions (a),(b) of Lemma 7.6 hold. In this case the face Fu is linearly isomorphic to R2
+ and
consists of the circulant matrices A with entries A1k, k = 1, . . . , n
2 + 1, given by (16) with c, λ ≥ 0. The
subset Pu ⊂ Fu is given by those A with c = 0.

Proof. Suppose Fu 6= Pu. Then by Lemma 7.3 there exists a circulant matrix A ∈ Fu \ Pu. Hence Lemma
7.6 applies and conditions (a),(b) hold.

they satisfy system (26). Let A ∈ Sn be the circulant matrix satisfying A1k =Pm

Let now ζ1, . . . , ζm ∈ (0, π) be an increasing sequence of angles satisfying conditions (a),(b) of Lemma
7.6. Deﬁne weights λ1, . . . , λm by (27). By condition (a) these weights are positive, and by Corollary A.8
j=1 λj cos(k − 1)ζj for k =
1, . . . , n
j=1 λj cos(n−2)ζj.
By construction the submatrices AIj are positive semi-deﬁnite of rank 2m = n − 4 and by condition (b)
they possess the kernel vector u = uj
. Moreover, the preceding inequality implies that (un)T Au1 > 0 and
Ij
(uj)T Auj+1 > 0 for j = 1, . . . , n − 1. By Theorem 2.8 we then have A ∈ Fu \ Pu, proving the equivalence
claimed in the theorem.

2 +1. By (26) the last relation actually holds for k = 1, . . . , n−2, and A1,n−1 >Pm

Let P ∈ Sn

+ be the positive semi-deﬁnite circulant rank 1 matrix given element-wise by Pkl = (−1)k−l.
Since the subvectors uj
are palindromic and have an even number of entries, we get that (uj)T P uj = 0
Ij
for all j = 1, . . . , n. Hence P ∈ Pu and rP SD ≥ 1, where rP SD is the maximal rank achieved by matrices in
Pu. But then rP SD = 1 and rmax = n − 3 by Corollary 5.6, and the last assertion of the theorem follows.
+. However, the matrices A and P constructed above are linearly
independent elements of Fu, and therefore Fu ⊂ span{A, P } consists of circulant matrices only. The
remaining assertions now follow from Lemma 7.6.

By Lemma 5.9 we have Fu ≃ R2

Theorem 7.9. Let n ≥ 5 be odd, m = n−3
2 , and let u and p(x) be as in the ﬁrst paragraph of this section.
Then Fu 6= Pu if and only if there exist distinct angles ζ1, . . . , ζm ∈ (0, π], arranged in increasing order, such
that conditions (a),(b) of Lemma 7.7 hold. In this case the face Fu is an extreme ray of Cn and consists of
the circulant matrices A with entries A1k, k = 1, . . . , n+1

2 , given by (17) with c ≥ 0.

Proof. The proof of the theorem is similar to the proof of Theorem 7.8, with obvious modiﬁcations.

The question which collections u, of the type described at the beginning of this subsection, yield faces
Fu containing exceptional copositive matrices hence reduces to the characterization of real polynomials of
the form given in (b) of Lemmas 7.6 or 7.7, with positive coeﬃcients and satisfying condition (a) of these
lemmas. This is seemingly a diﬃcult question, and only limited results are known. However, the existence
of faces Fu containing exceptional copositive matrices is guaranteed for every n ≥ 5 by the following result
on polynomials with equally spaced roots on the unit circle.

Lemma 7.10. [12, Theorem 2] Let m ≥ 1 be an integer, and let α > 0, θ ≥ 0 be such that π
π and 0 < α < π

2 ≤ θ+ (m−1)α
≤
j=1(x2 − 2x cos(θ + (j − 1)α)+ 1) has positive coeﬃcients.

2

Indeed, the lemma allows to construct the following explicit examples.

m . Then the polynomial q(x) =Qm

Degenerate extremal matrices. Let n ≥ 5, m = ⌈ n

(xn+1)(x+1)
n +1) . Then
n +1)(x2−2x cos 3π
p(x) is a palindromic polynomial of degree n − 3. Set also q(x) = p(x) for odd n and q(x) = p(x)
x+1 for even
n , θ = 5π
n. Then q(x) is of degree 2m and has positive coeﬃcients by virtue of Lemma 7.10 with α = 2π
n .
It follows that also p(x) has positive coeﬃcients. Let u ∈ Rn−2
be the vector of its coeﬃcients, and let u
be the collection of nonnegative vectors constructed from u as in the ﬁrst paragraph of this section. Then
the angles ζj = (2j+3)π
, j = 1, . . . , m, satisfy conditions (a),(b) of Lemmas 7.6 and 7.7, for even and odd

2 ⌉ − 2, and p(x) =

(x2−2x cos π

+

n

18

n, respectively. By Theorems 7.8 and 7.9 we obtain that Fu ≃ R2
+ for even n and Fu ≃ R+ for odd n,
their elements being circulant matrices given by (16) and (17), respectively. One extreme ray of Fu is then
generated by an extremal degenerate copositive circulant matrix A. For even n the other extreme ray is
generated by a circulant positive semi-deﬁnite rank 1 matrix P . Their elements are given by Pij = (−1)i−j
and

2(1 + 2 cos π
−2(cos π

n cos 3π
n + cos 3π

n ),
n ),
1,
0,

i = j,
|i − j| ∈ {1, n − 1},
|i − j| ∈ {2, n − 2},
|i − j| ∈ {3, . . . , n − 3},

(18)

Aij =


i, j = 1, . . . , n.

Regular extremal matrices. Let n ≥ 5 be odd, and set m = n−3

n+1 +1) .
Then p(x) is a palindromic polynomial of degree 2m = n − 3, and it has positive coeﬃcients by virtue of
n+1 . Construct u ∈ Rn−2
Lemma 7.10 with α = 2π
+ as above from the coeﬃcients of
p(x). Then the angles ζj = (2j+3)π
, j = 1, . . . , m, satisfy conditions (a),(b) of Lemma 7.7. By Theorem 7.9
n+1
Fu is one-dimensional and generated by a circulant regular extremal copositive matrix whose elements are
given by (17). Explicitly this gives

n+1 , θ = 5π

n+1 +1)(x2−2x cos 3π

and u ⊂ Rn

2 , p(x) =

(x2−2x cos π

+

xn+1+1

Aij =


i, j = 1, . . . , n.

2(1 + 2 cos π
−2(cos π

n+1 cos 3π
n+1 + cos 3π

n+1 ),
n+1 ),
1,
0,

i = j,
|i − j| ∈ {1, n − 1},
|i − j| ∈ {2, n − 2},
|i − j| ∈ {3, . . . , n − 3},

(19)

However, Lemma 7.10 allows also for other choices of regularly spaced angles ζ1, . . . , ζm or regularly
spaced angles ζ1, . . . , ζm−1, 2π − ζm. The following result guarantees the positivity of the coeﬃcients of
p(x) also in the case when only ζ2, . . . , ζm (or ζ2, . . . , ζm−1, 2π − ζm) are regularly spaced, and the spacing
between ζ1 and ζ2 is inferior to the spacing between the other angles.

Lemma 7.11. [1, Corollary 1.1] Let p(x) be a real polynomial with nonnegative coeﬃcients, and let x0 be
the root of p(x) which has the smallest argument among all roots of p(x) in the upper half-plane. If x1 is any
number such that |x1| ≥ |x0| and Re x1 ≤ Re x0, then the coeﬃcients of the polynomial p(x) (x−x1)(x−¯x1)
(x−x0)(x−¯x0)
are not smaller than the corresponding coeﬃcients of p(x).

As to the general case, we establish the following conjecture.

Conjecture 7.12. Let n ≥ 5 be an integer, and set m = ⌈ n
sequence of angles such that the fractional part of nζj

2 ⌉ − 2. Let ζ1, . . . , ζm ∈ (0, π] be an increasing
2 , 1) for even j. Deﬁne
j=1(x2 −2x cos ζj +1), and set p(x) = q(x) for odd n and p(x) = (x+1)q(x) for even

2 ) for odd j and in ( 1

4π is in (0, 1

n. Then the coeﬃcients of p(x) are all positive if and only if ζj ∈ ( (2j+2)π

, (2j+4)π

n

) for all j = 1, . . . , m.

n

the polynomial q(x) =Qm

We have veriﬁed this conjecture for n ≤ 8.

8 Matrices of order 6

In this section we compute all exceptional extremal copositive matrices A of size 6 × 6 which have zeros
uj with supp uj = Ij, j = 1, . . . , 6. We assume without loss of generality that diag A = (1, . . . , 1), because
every other such matrix lies in the G6-orbit of a matrix normalized in this way.

Let A ∈ C6 be exceptional and extremal, diag A = (1, . . . , 1), and let u = {u1, . . . , u6} ⊂ R6

+ be
zeros of A satisfying supp uj = Ij . By Theorem 5.12 the matrix A is degenerate, and rk AIj = 2 for all
j = 1, . . . , 6. Therefore B = Λ(A) has rank 2 by Corollary 4.2, and B = x ⊗ x + y ⊗ y for some solutions
x = (x1, x2, . . . ), y = (y1, y2, . . . ) ∈ Lu. Extremality of A implies that the linear span of {x, y} does not
contain non-zero periodic solutions. Indeed, let v ∈ span{x, y} be such a solution. Then v ⊗ v ∈ Pu, and
B ± ε · v ⊗ v ∈ Fu for ε small enough. Hence A can be represented as a non-trivial convex combination of
the elements Λ−1(B ± εv ⊗ v) ∈ Fu, contradicting extremality.

19

Shift-invariance of B implies that the monodromy M of the system Su acts on x, y ∈ Lu by

(cid:18)Mx
My(cid:19) = M(cid:18)x
y(cid:19) ,

where M is an orthogonal 2 × 2 matrix. If M is a reﬂection, then M has an eigenvector with eigenvalue 1 in
the span of {x, y}, leading to a contradiction by Lemma 3.1. Hence M is a rotation by an angle ζ ∈ (0, 2π),
i.e.,

Mx = cos ζ · x − sin ζ · y,

My = sin ζ · x + cos ζ · y.

(20)

By (9) and by the normalization adopted above we have x2

k = 1 for all k ≥ 1. Without loss
of generality we may assume that x1 = 1, y1 = 0, otherwise we rotate the basis {x, y} of span{x, y}
appropriately by redeﬁning x, y. Then we have

k + y2

k−1

xk = cos

Xj=1

(π − ϕj ),

yk = sin

(π − ϕj)

k−1

Xj=1

for some angles ϕ1, ϕ2, · · · ∈ [0, 2π), for all k ≥ 1. By virtue of (20) we get

k+5

(π − ϕj ) ≡ −

Xj=k

k+5

Xj=k

ϕj ≡ ζ

mod 2π

∀ k ≥ 1.

It follows that ϕk ≡ ϕk+6 modulo 2π for all k ≥ 1, and the sequence {ϕk} is 6-periodic.

We have

B(et, es) = xtxs + ytys = (−1)s−t cos

max(t,s)−1

Xj=min(t,s)

ϕj ,

∀ t, s ≥ 1.

(21)

Conditions (10) reduce to B(et, et+3) = B(et+3, et+6) for all t ≥ 1, which yields

cos(ϕt + ϕt+1 + ϕt+2) = cos(ϕt+3 + ϕt+4 + ϕt+5) = cos(ζ + ϕt + ϕt+1 + ϕt+2)

∀ t ≥ 1.

(22)

By virtue of ζ 6= 0 it follows that ϕt + ϕt+1 + ϕt+2 ≡ −(ζ + ϕt + ϕt+1 + ϕt+2) modulo 2π, or equivalently,

ϕt + ϕt+1 + ϕt+2 ≡ −

ζ
2

mod π

∀ t ≥ 1.

This yields ϕt ≡ ϕt+3 modulo π, or ϕt+3 = ϕt + δt with δt ∈ {−π, 0, π}, for all t ≥ 1.

By Lemma 4.6 inequalities (12) hold strictly, which yields

cos(ϕt + ϕt+1) > cos(ϕt+2 + ϕt+3 + ϕt+4 + ϕt+5) = cos(ζ + ϕt + ϕt+1)

∀ t ≥ 1.

(23)

Equivalently, ϕt + ϕt+1 ∈ 2πlt + (− ζ
get ϕt+3 + ϕt+4 = ϕt + ϕt+1 + δt + δt+1 ∈ 2πlt+3 + (− ζ
all t ≥ 1. It follows that either δt = 0 for all t, or δt ∈ {−π, π} for all t.

2 ) for some lt ∈ {0, 1, 2}, for all t ≥ 1. Replacing t by t + 3, we
2 ), and therefore δt + δt+1 ≡ 0 modulo 2π, for

2 , π − ζ

2 , π − ζ

Assume the second case, for the sake of contradiction. Then cos(ϕt+3 + ϕt+4 + ϕt+5) = − cos(ϕt +
ϕt+1 + ϕt+2), which together with (22) gives ϕt + ϕt+1 + ϕt+2 ≡ π
2 modulo π for all t ≥ 1, and ζ = π.
Inequality (23) yields cos(ϕt + ϕt+1) > 0 for all t ≥ 1. We then get x1 = 1, x3 > 0, x4 = 0. But x is
the solution of a 3-rd order linear system with positive coeﬃcients. Hence x2 < 0, and ϕ1 6∈ [ π
2 ]. By a
similar argument, this has to be true for all ϕt, t ≥ 1, contradicting δt ∈ {−π, π}.

2 , 3π

Therefore ϕt+3 = ϕt for all t ≥ 1. Set σ = ϕ1 + ϕ2 + ϕ3. Then (23) reduces to cos(σ − ϕj) > cos(σ + ϕj),
or equivalently sin σ sin ϕj > 0 for j = 1, 2, 3. Therefore sin ϕj and sin σ have the same sign for all j = 1, 2, 3.
By possibly replacing the solution y by −y, we may assume without loss of generality that sin ϕ1 > 0 and
j=1(π − ϕj) ∈ (0, π), and yk > 0
for k = 2, 3, 4. Since also y1 = 0, this contradicts the condition that y is a solution of a linear 3-rd order

hence ϕj ∈ (0, π), π − ϕj ∈ (0, π) for all j = 1, 2, 3. If σ ∈ (2π, 3π), then P3

20

system with positive coeﬃcients. Therefore ϕ1 + ϕ2 + ϕ3 < π. By (9),(21) the matrix A is then given by





1

− cos ϕ1

− cos ϕ1

cos(ϕ1+ϕ2)

− cos(ϕ1+ϕ2+ϕ3)

cos(ϕ2+ϕ3)

− cos ϕ3

1

− cos ϕ2

cos(ϕ2+ϕ3)

− cos(ϕ1+ϕ2+ϕ3)

cos(ϕ1+ϕ3)

cos(ϕ1+ϕ2)

− cos ϕ2

1

− cos ϕ3

cos(ϕ1+ϕ3)

− cos(ϕ1+ϕ2+ϕ3)

− cos(ϕ1+ϕ2+ϕ3)

cos(ϕ2+ϕ3)

− cos ϕ3

1

− cos ϕ1

cos(ϕ1+ϕ2)

cos(ϕ2+ϕ3)

− cos(ϕ1+ϕ2+ϕ3)

cos(ϕ1+ϕ3)

− cos ϕ1

1

− cos ϕ3

cos(ϕ1+ϕ3)

− cos(ϕ1+ϕ2+ϕ3)

cos(ϕ1+ϕ2)

− cos ϕ2

− cos ϕ2

1

(24)
On the other hand, let ϕ1, ϕ2, ϕ3 > 0 such that ϕ1 + ϕ2 + ϕ3 < π, and consider the matrix A given by

.





(24). Let v1, . . . , v6 ∈ R6

+ be the columns of the matrix

sin ϕ2

sin(ϕ1 + ϕ2)

0

sin ϕ3

0
0

sin ϕ1

sin(ϕ2 + ϕ3)

sin ϕ1

0
0
0

V =





0
0
0

sin ϕ2

sin(ϕ1 + ϕ3)

sin ϕ2

0
0

sin ϕ3

0

sin(ϕ1 + ϕ2)

sin ϕ3

sin ϕ1

sin(ϕ2 + ϕ3)

sin ϕ1

sin ϕ2

0
0
0

sin(ϕ1 + ϕ3)

sin ϕ3

0
0
0





,

(25)

and deﬁne uj = vj + vj+1, j = 1, . . . , 5, u6 = v6 + v1. By construction the submatrices AIj are positive
semi-deﬁnite and of rank 2, and (uj)T Auj = 0, supp uj = Ij for all j = 1, . . . , 6. Moreover, (uj)T Auj+1 > 0
for all j = 1, . . . , 5 and (u6)T Au1 > 0. Hence A is an exceptional copositive matrix by Theorem 2.8, and
it is degenerate and extremal by Theorem 5.12. By (ii.d) of Theorem 5.12 the columns of V are minimal
zeros of A, and every minimal zero of A is a positive multiple of some column of V . We have proven the
following result.

Theorem 8.1. Let A ∈ C6 be exceptional and extremal with zeros u1, . . . , un satisfying supp uj = Ij for all
j = 1, . . . , 6. Then A is in the G6-orbit of some matrix of the form (24), with ϕ1, ϕ2, ϕ3 > 0 and ϕ1 + ϕ2 +
ϕ3 < π. The minimal zero pattern of A is given by {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {1, 5, 6}, {1, 2, 6}}.
On the other hand, every matrix A of the form (24) with ϕ1, ϕ2, ϕ3 > 0 and ϕ1 + ϕ2 + ϕ3 < π is exceptional
and extremal, and every minimal zero of A is proportional to one of the columns of the matrix (25).
Remark 8.2. We do not claim that every extremal exceptional copositive matrix in C6 with diag A =
(1, . . . , 1) and with this minimal zero pattern has to be of the form (24).

9 Conclusions

In this contribution we considered copositive matrices with zeros u1, . . . , un ∈ Rn
+ having supports supp uj =
Ij . Exceptional copositive matrices with this property exist for all matrix sizes n ≥ 5 and are of two types,
in dependence on whether the zeros uj are minimal or not. The matrices of each type make up an algebraic
submanifold of Sn, of codimensions n and 2n, respectively. The prototypes of these matrices are the T -
matrices and the Horn matrix, respectively. Explicit examples of such matrices have been given in (19)
and (18), respectively. We show that if the zeros uj are not minimal, then the corresponding exceptional
If the zeros uj are minimal, then the corresponding matrices can be
copositive matrices are extremal.
extremal only for odd n.

Some open questions within this framework remain:

• Do regular non-extremal matrices exist for odd matrix size?

• Do degenerate matrices with minimal zero pattern diﬀerent from {I ′

1, . . . , I ′

n} exist?

• Which types of extremal copositive matrices can appear on the boundary of the submanifolds of

regular and degenerate matrices, respectively?

• What is the global topology of these submanifolds?

21

References

[1] R.W. Barnard, W. Dayawansa, K. Pearce, and D. Weinberg. Polynomials with nonnegative coeﬃcients.

P. Am. Math. Soc., 113(1):77–85, 1991.

[2] L. D. Baumert. Extreme copositive quadratic forms. Paciﬁc J. Math., 19(2):197–204, 1966.

[3] L. D. Baumert. Extreme copositive quadratic forms. II. Paciﬁc J. Math., 20(1):1–20, 1967.

[4] Immanuel M. Bomze, Werner Schachinger, and Gabriele Uchida. Think co(mpletely )positive ! –
matrix properties, examples and a clustered bibliography on copositive optimization. J. Global Optim.,
52:423–445, 2012.

[5] Samuel Burer. On the copositive representation of binary and continuous nonconvex quadratic pro-

grams. Math. Program., Ser. A, 120:479–495, 2009.

[6] P. H. Diananda. On nonnegative forms in real variables some or all of which are nonnegative. Proc.

Cambridge Philos. Soc., 58:17–25, 1962.

[7] Peter Dickinson and Roland Hildebrand. Considering copositivity locally. J. Math. Anal. Appl.,

437(2):1184–1195, 2016.

[8] Peter J.C. Dickinson. The Copositive Cone, the Completely Positive Cone and their Generalisations.

PhD thesis, University of Groningen, 2013.

[9] Peter J.C. Dickinson, Mirjam D¨ur, Luuk Gijben, and Roland Hildebrand. Irreducible elements of the

copositive cone. Linear Algebra Appl., 439:1605–1626, 2013.

[10] Mirjam D¨ur. Copositive programming - a survey. In Moritz Diehl, Fran¸cois Glineur, Elias Jarlebring,
and Wim Michiels, editors, Recent advances in optimization and its applications in engineering, pages
3–20. Springer, Berlin, Heidelberg, 2010.

[11] Saber Elaydi. An Introduction to Diﬀerence Equations. Undergraduate Texts in Mathematics. Springer,

New York, 2005.

[12] Ronald Evans and John Greene. Polynomials with nonnegative coeﬃcients whose zeros have modulus

one. SIAM J. Math. Anal., 22(4):1173–1182, 1991.

[13] R. Grone, C.R. Johnson, E.M. Sa, and H. Wolkowicz. Positive deﬁnite completions of partial Hermitian

matrices. Linear Algebra Appl., 58:109–124, 1984.

[14] M. Jr. Hall and M. Newman. Copositive and completely positive quadratic forms. Proc. Cambridge

Philos. Soc., 59:329–339, 1963.

[15] Roland Hildebrand. The extreme rays of the 5 × 5 copositive cone. Linear Algebra Appl., 437(7):1538–

1547, 2012.

[16] Roland Hildebrand. Minimal zeros of copositive matrices. Linear Algebra Appl., 459:154–174, 2014.

[17] Jean-Baptiste Hiriart-Urruty and Alberto Seeger. A variational approach to copositive matrices. SIAM

Rev., 52(4):593–629, 2010.

[18] N. Macon and A. Spitzbart. Inverses of Vandermonde matrices. Am. Math. Month., 65(2):95–100,

1958.

[19] Naomi Shaked-Monderer. On the DJL conjecture for order 6. arXiv 1501.02426, 2015.

[20] Mihalis Yannakakis. Expressing combinatorial optimization problems by linear programs. J. Comput.

Syst. Sci., 43:441–466, 1991.

[21] Martin Zarrop. Optimal experiment design for dynamic system identiﬁcation, volume 21 of Lecture

Notes in Control and Inform. Sci. Springer, Berlin, New York, 1979.

22

A Auxiliary results

In this section we collect a few auxiliary results of general nature.

Lemma A.1. Let A ∈ Sn and deﬁne the ordered index subsets I = (1, . . . , n − 1), I ′ = (2, . . . , n). Suppose
that the principal submatrices AI , AI ′ are positive semi-deﬁnite, and that there exist vectors u, v ∈ Rn such
that u1, vn > 0, v1 = un = 0, and uT Au = vT Av = 0. Then there exists a unique real number δ such that
A − δ · E1n is positive semi-deﬁnite, and this number has the same sign as the product uT Av.

Proof. Consider the matrix-valued function P (δ) = A − δE1n. All elements of P (δ) except the upper right
(and correspondingly lower left) corner element coincide with the corresponding elements of A. Therefore the
posed problem on the unknown δ can be considered as a positive semi-deﬁnite matrix completion problem.
Namely, we wish to modify the corner elements of A to make it positive semi-deﬁnite. By a standard result
on positive semi-deﬁnite matrix completions [13] there exists a solution δ such that P (δ) (cid:23) 0.

On the other hand, for every solution δ we have uT P (δ)u = vT P (δ)v = 0 and therefore must have
uT E1nv . The

uT P (δ)v = 0. Uniqueness of the solution follows and we have the explicit expression δ = uT Av
assertion of the lemma now follows from the strict inequality uT E1nv > 0.

Lemma A.2. Deﬁne the set M = {M ∈ Rn×n | det M = 0}, and let M ∈ M be a matrix of corank
1. Let the vectors u, v ∈ Rn be generators of the left and the right kernel of M , respectively. Then the
orthogonal complement under the Frobenius scalar product hA, Bi = tr(ABT ) of the tangent space to M at
M is generated by the rank 1 matrix uvT .

R)T be a factorization of M , where F 0

Proof. Let M = F 0
The set M can be written as {FLF T
by all matrices of the form F 0
H ∈ Rn×n is orthogonal to M at M if and only if hF 0
0 for all ∆L, ∆R ∈ Rn×(n−1). Equivalently, HF 0
the lemma now readily follows.

R are full column rank n × (n − 1) matrices.
R | FL, FR ∈ Rn×(n−1)}. Therefore the tangent space to M at M is given
R)T , where ∆L, ∆R ∈ Rn×(n−1) are arbitrary. Therefore a matrix
L)T H) =
L = 0, or HM T = H T M = 0. The assertion of

R)T , Hi = tr(∆L(F 0

R)T H T +∆R(F 0

R = H T F 0

R + ∆L(F 0

R+∆L(F 0

L, F 0

L(F 0

L∆T

L∆T

Lemma A.3. Let u1, . . . , un ∈ Rn be non-zero vectors, such that no two of these are proportional and the
dimension of the linear span span{u1, . . . , un} has corank at most 1. Then the rank 1 matrices uj(uj)T ,
j = 1, . . . , n, are linearly independent.

Proof. Without loss of generality we may assume that u1, . . . , un−1 are linearly independent. In an ap-
propriate coordinate system these vectors then equal the corresponding canonical basis vectors. Then
uj(uj)T = Ejj for j = 1, . . . , n − 1. Hence the rank 1 matrices uj(uj)T are linearly dependent only if
un(un)T is diagonal with at least two non-zero entries, which leads to a contradiction.

Lemma A.4. Deﬁne the set M = {S ∈ Sn | det S(1,...,n−1) = det S(2,...,n) = det(Sij )i=1,...,n−1;j=2,...,n = 0},
and let S ∈ M be a positive semi-deﬁnite matrix of corank 2. Suppose there exists a basis {u, v} ⊂ Rn of
ker S such that u1 6= 0, vn 6= 0, un = v1 = 0. Then there exists a neighbourhood U ⊂ Sn of S such that a
matrix S′ ∈ U is positive semi-deﬁnite of corank 2 if and only if S′ ∈ U ∩ M.

Proof. By un = 0 the subvector u(1,...,n−1) is in the kernel of S(1,...,n−1). Hence S(1,...,n−1) is of corank at
least 1. If w ∈ ker S(1,...,n−1) is another kernel vector, then w′ = (wT , 0)T ∈ Rn is in the kernel of S and
must therefore be proportional to u, because v cannot be in span{u, w} by vn 6= 0. Therefore S(1,...,n−1) is
positive semi-deﬁnite of corank 1. Similarly, the submatrix S(2,...,n) is positive semi-deﬁnite of corank 1.

Let S′ ∈ M be close to S. Then by continuity the n − 2 largest eigenvalues of S′

and the remaining eigenvalue is zero by deﬁnition of M. Therefore S′
The kernel of S′
(u′)T S′u′ = 0 and u′
close to v, such that (v′)T S′v′ = 0 and v′

(1,...,n−1) are positive,
(1,...,n−1) (cid:23) 0 and rk S′ ≥ n − 2.
(1,...,n−1) is close to that of S(1,...,n−1), hence there exists a vector u′, close to u, such that
(2,...,n) is positive semi-deﬁnite and there exists a vector v′,
1 = 0.

n = 0. Similarly, S′
n 6= 0, v′

1 6= 0 the ﬁrst column of the submatrix S′

These n − 2 columns must therefore be linearly independent. It follows that the submatrix S′
positive deﬁnite. Therefore the (n−2)×(n−1) submatrix (S′

(1,...,n−1) is a linear combination of the other columns.
(2,...,n−1) is
ij )i=2,...,n−1;j=2,...,n has full row rank, and every

1 6= 0, u′

By u′

23

vector in its right kernel must be proportional to v′
ij )i=1,...,n−1;j=2,...,n must also be generated by v′
(S′
generated by u′

(1,...,n−1), and we get that (u′)T S′v′ = 0.

(2,...,n). Hence the right kernel of the singular submatrix
(2,...,n). Similarly, the left kernel of this submatrix is

By possibly replacing u′ by −u′ or v′ by −v′, we may enforce u′

n > 0. By Lemma A.1 we then
have that S′ is positive semi-deﬁnite. Now both u′ and v′ are in the kernel of S′, and these vectors are
linearly independent. Therefore rk S′ ≤ n − 2, and S′ is of corank 2.

1 > 0, v′

On the other hand, every matrix S′ of corank 2 is in M. This completes the proof.

Lemma A.5. Let T be a singular real symmetric positive semi-deﬁnite Toeplitz matrix of rank k and with
an element-wise nonnegative non-zero kernel vector u. Then there exist distinct angles ζ0 = π, ζ1, . . . , ζm ∈
(0, π) and positive numbers λ0, . . . , λm, where m = ⌊ k
j=0 λj T (ζj) for odd k and T =
j=1 λjT (ζj) for even k, where T (ζ) is the symmetric Toeplitz matrix with ﬁrst row (1, cos ζ, cos 2ζ, . . . ).
Moreover, if p(x) is the polynomial whose coeﬃcients equal the entries of u, then e±iζj are roots of p(x) for
j = 1, . . . , m, and −1 is a root of p(x) if k is odd.

2 ⌋, such that T = Pm

Pm

Proof. Any positive semi-deﬁnite Toeplitz matrix T of rank k can be represented as a weighted sum of
k rank 1 positive semi-deﬁnite Toeplitz matrices with positive weights. Each of these rank 1 matrices
is complex Hermitian with ﬁrst row (1, eiζ , e2iζ , . . . ) for some ζ ∈ [0, 2π), and the angles ζ are pairwise
distinct. If T is singular, then the weights and the angles are determined uniquely [21, Chapter 3]. For real
T the complex rank 1 matrices appear in complex conjugate pairs, each of which sums to a Toeplitz matrix
of the form T (ζ) with ζ ∈ (0, π).

The kernel of T equals the intersection of the kernels of the rank 1 summands. The angle ζ = 0 then
cannot appear in the sum due to the presence of an element-wise nonnegative non-zero kernel vector. Hence
the angle ζ = π, which corresponds to the only remaining real rank 1 Toeplitz matrix, appears in the sum
if and only if k is odd.

Finally, u is in the kernel of every rank 1 summand in the decomposition of T . This directly yields the

last assertion of the lemma.

j=1(x2 − 2x cos ζj + 1) if k is odd.

Lemma A.6. Assume the notations and conditions of the previous lemma and let v ∈ Rk+1 be a non-
zero kernel vector of the upper left principal submatrix of T of size k + 1. Then v is proportional to the
j=1(x2 − 2x cos ζj + 1) if k is even and of the polynomial

coeﬃcient vector of the polynomial p(x) = Qm
p(x) = (x + 1)Qm
component in the decomposition of T from the proof of the previous lemma, we have Pk
polynomial pv(x) =Pk

Proof. Let v = (v0, . . . , vk)T . Since v is also in the kernel of the principal submatrix of each rank 1
l=0 vleilζj = 0 for
all j = 0, . . . , m if k is odd, and for all j = 1, . . . , m if k is even. This means that e±iζj are the roots of the
l=0 vlxl for all j. Since these are already k distinct roots, these must be all roots of

pv. Noting that (x − eiζ)(x − e−iζ) = x2 − 2x cos ζ + 1 and x − eiπ = x + 1 completes the proof.

Lemma A.7. Let n ≥ 5, r, s be positive integers, γ ∈ R arbitrary, and ζ1, . . . , ζs ∈ [0, π]. Then the system
of r linear equations

λj(cos(n − k)ζj − cos kζj) = 0,

k = ⌈

n
2

⌉ + 1 − r, . . . , ⌈

n
2

⌉ − 1,

s

Xj=1

λj(cos(n − (⌈

n
2

⌉ − r))ζj − cos(⌈

n
2

⌉ − r)ζj ) = γ

s

Xj=1

on the unknowns λ1, . . . , λs is equivalent to the system

· · ·
· · ·

1

cos ζ1

...

1

cos ζs

...

cosr−1 ζ1

· · ·

cosr−1 ζs







2

λ1 sin ζ1
2 sin nζ1
...
λs sin ζs
2 sin nζs

2




0
...
0

−2−rγ




=





24

for odd n and

for even n.

· · ·
· · ·

1

cos ζ1

...

1

cos ζs

...

cosr−1 ζ1

· · ·

cosr−1 ζs




λ1 sin ζ1 sin nζ1
2

...

λs sin ζs sin nζs
2







0
...
0

−2−rγ




=





Proof. Due to the identity cos(2α − β) − cos β = −2 sin α sin(α − β) the system is equivalent to

sin( n

sin( n

2 − ⌈ n
2 ⌉ + 1)ζ1
...
2 − ⌈ n
2 ⌉ + r)ζ1

· · ·

· · ·




sin( n

sin( n

2 − ⌈ n
2 ⌉ + 1)ζs
...
2 − ⌈ n
2 ⌉ + r)ζs







λ1 sin nζ1
2

...

λs sin nζs
2




0
...
0
− γ
2

=


.




Column j of the coeﬃcient matrix above is given by (sin ζj
)T for odd n and by
(sin ζj , sin 2ζj, . . . , sin rζj )T for even n. Apply the formula sin kϕ = sin ϕ(e(k−1)iϕ +e(k−3)iϕ+· · ·+e−(k−1)iϕ)
to the coeﬃcients in column j with ϕ = ζj

2 , . . . , sin (2r−1)ζj

2 for odd n and ϕ = ζj for even n.

2 , sin 3ζj

By adding to each row of the coeﬃcient matrix appropriate multiples of the rows above it, we may
obtain a matrix whose column j is given by sin ζj
2 (1, eiζj + e−iζj , . . . , (eiζj + e−iζj )r−1)T for odd n and by
sin ζj(1, eiζj + e−iζj , . . . , (eiζj + e−iζj )r−1)T for even n. The right-hand side of the system does not change
under this operation. Recalling that eiζ +e−iζ = 2 cos ζ, we obtain the equivalent systems in the formulation
of the lemma.

2

Corollary A.8. Let n ≥ 5 be an integer, and set m = ⌈ n
Then the inhomogeneous linear system of the m equations

2 ⌉ − 2. Let ζ1, . . . , ζm ∈ (0, π] be distinct angles.

λj (cos(n − k)ζj − cos kζj) = 0,

3 ≤ k ≤ m + 1,

(26)

λj(cos(n − 2)ζj − cos 2ζj) = −1

m

m

Xj=1
Xj=1

on the unknowns λ1, . . . , λm has a solution if and only if among the angles ζj there are no multiples of 2π
n ,
and this solution is unique and given by

λj =


(cid:16)2m sin ζj
2 sin nζj
(cid:16)2m sin ζj sin nζj

2 Ql6=j(cos ζj − cos ζl)(cid:17)−1
2 Ql6=j(cos ζj − cos ζl)(cid:17)−1

,

,

n odd,

n even.

(27)

Proof. Apply Lemma A.7 with r = s = m. Since the cosine function is strictly monotonous on (0, π], the
Vandermonde matrix in the equations in this lemma is non-singular. Using explicit formulas for the inverse of
the Vandermonde matrix [18], we obtain for every j = 1, . . . , m that λj sin ζj
for odd n and λj sin ζj sin nζj
follows.

2m Ql6=j (cos ζj −cos ζl)
2m Ql6=j(cos ζj −cos ζl) for even n. The claim of the corollary now easily

2 sin nζj

2 =

2 =

1

1

B Extremality of exceptional circulant matrices

In this section we provide Lemma B.4, which is the technically most diﬃcult part of the proof of Lemma
7.7. Its proof uses a bit more advanced mathematical concepts, in particular, linear group representations.
Let LC ⊂ Sn be the subspace of circulant matrices, i.e., matrices which are invariant with respect to
simultaneous circular shifts of the row and column indices. Let PS : Sn → Sn be the linear map which

25

corresponds to a circular shift by one entry. Then P n
S is the identity map Id, and PS generates a symmetry
group which is isomorphic to the cyclic group Cn. However, symmetric circulant matrices possess yet
another symmetry. Namely, they are persymmetric, i.e., invariant with respect to reﬂection about the main
skew diagonal. Denote this reﬂection by PP : Sn → Sn. The symmetry group generated by PS and PP
is isomorphic to the dihedral group Dn, which has 2n elements. The action of Dn on Sn deﬁnes a linear
unitary representation RS n of Dn of dimension n(n+1)
, which decomposes into a direct sum of irreducible
representations. This decomposition corresponds to an orthogonal decomposition of Sn into a direct sum
of invariant subspaces.

2

2

In this section we suppose n ≥ 5 to be an odd number. Then the group Dn has two irreducible represen-
tations of dimension 1. Both of these send PS to the identity Id. The element PP is sent to Id by the trivial
representation and to −Id by the other 1-dimensional representation. The n+1
2 -dimensional subspace LC is
exactly the invariant subspace corresponding to the trivial representation. The other 1-dimensional repre-
sentation does not participate in RS n , because there is no non-zero matrix A ∈ Sn such that PS(A) = A and
PP (A) = −A. Besides the 1-dimensional representations, Dn possesses n−1
2-dimensional representations
2
. Here Rk sends PS to the rotation of the 2-dimensional representing subspace by the angle
R1, . . . , R n−1
2πk
n , and PP to a reﬂection of this subspace.

p(x) = Qm

and let ζ1, . . . , ζm ∈ (0, π) be distinct angles in increasing order. Deﬁne the polynomial
j=1(x2 − 2x cos ζj + 1), which has roots e±iζj , and let u ∈ Rn−2 be its coeﬃcient vector. Note
that p is palindromic, i.e., u does not change if the order of its entries in inverted. For j = 1, . . . , n, deﬁne
vectors uj ∈ Rn such that uj
i = 0 for all i 6∈ Ij. We do not make further assumptions on the
Ij
collection u = {u1, . . . , un}, in particular, we do not demand u to be positive.

= u and uj

Set m = n−3
2

For every k = 1, . . . , n−1

j=1(x2 − 2xe−πik(n−1)/n cos ζj +
1 = 1 being the coeﬃcient at x2m.
e−2πik(n−1)/n) and denote by vk ∈ Rn−2 its coeﬃcient vector, with vk
Then the roots of pk all lie on the unit circle and equal ei(±ζj −πk(n−1)/n), j = 1, . . . , m, and the elements
of vk are given by vk

2 we also deﬁne the polynomial pk(x) = Qm

l = eπik(n+1−l)(n−1)/nul, l = 1, . . . , n − 2.

For given u, deﬁned by angles ζ1, . . . , ζm as above, we are interested in the linear subspace Lu ⊂ Sn of
symmetric matrices A such that AIj u = 0 for all j = 1, . . . , n. If A ∈ Lu is a solution of the corresponding
linear system of equations, then the matrices P k
S (A) obtained from A by circular shifts of the row and
column indices are also solutions. Moreover, since u is palindromic, PP (A) is a solution too. Therefore Lu
is an invariant subspace under the action of the group Dn, and this action deﬁnes a linear representation Ru
of Dn on Lu. This representation decomposes into a direct sum of irreducible representations and induces
an orthogonal decomposition of Lu into a direct sum of invariant subspaces Lu,Id, Lu,k, k = 1, . . . , n−1
2 ,
corresponding to the trivial irreducible representation and the representations Rk of Dn. As noticed above,
the non-trivial 1-dimensional representation of Dn does not contribute to RS n and hence neither to Ru.

The subspace Lu,Id then consists exactly of those matrices A which are circulant and satisfy AI1 u = 0.

The next result characterizes the subspaces Lu,k.

Lemma B.1. Let A ∈ Lu,k be a non-zero matrix. Then there exists a complex symmetric matrix B such that
ReB, ImB ∈ Lu,k, A ∈ span{ReB, ImB}, and B can be represented as a Hadamard product B = C ◦ H
of a non-zero real symmetric circulant matrix C and a Hankel rank 1 matrix H given element-wise by
Hjl = eπik(n+1−j−l)(n−1)/n. Moreover, we have CI1 vk = 0.

Proof. Let L be a 2-dimensional subspace which is invariant under the action of Dn and such that A ∈ L ⊂
Lu,k. Then the action of Dn on L is given by the representation Rk, i.e., there exists a basis {B1, B2} of L
such that

PS(B2)(cid:19) =(cid:18) cos 2πk
(cid:18)PS(B1)

− sin 2πk
n

n

sin 2πk
n
cos 2πk

B2(cid:19) ,
n (cid:19)(cid:18)B1

(cid:18)PP (B1)
PP (B2)(cid:19) =(cid:18)1

B2(cid:19) .
0 −1(cid:19)(cid:18)B1

0

Setting B = B1 + iB2, we obtain that PS(B) = e−2πik/nB, PP (B) = B.

The ﬁrst condition is equivalent to the condition Bjl = e2πik/nBj−l− for all j, l = 1, . . . , n, where
j−, l− ∈ {1, . . . , n} are the unique indices satisfying j− ≡ j − 1 and l− ≡ l − 1 modulo n. For every

26

j, l = 1, . . . , n we then have

Bjl =


exp(cid:16) 2πik

n

j+l−n−1

2

n

exp(cid:16) 2πik
exp(cid:16) 2πik

n

j+l−1

j+l−1

2

(cid:17) · Bj− j+l−n−1
2 (cid:17) · Bj+n− j+l−1
2 (cid:17) · Bj− j+l−1

2

2

,l− j+l−n−1

2

,l− j+l−1

2

,l+n− j+l−1

2

,

,

,

(j + l) even;

j < l, (j + l) odd;

j > l, (j + l) odd.

Since n is odd, the ﬁrst factors in this representation of the elements of B form the Hankel matrix H, while
the second factors form a circulant matrix C which coincides with B on the main skew-diagonal. However,
the condition PP (B) = B implies that the elements on the main skew diagonal of B are real. Hence C is
also real. This yields the claimed representation B = C ◦ H. Since B 6= 0, we also have C 6= 0.

Since B1, B2 ∈ Lu, we have that BI1 u = 0. However, for all l = 1, . . . , n − 2 we have (BI1 u)l =

e−πikl(n−1)/n(CI1 vk)l by deﬁnition of vk, and hence also CI1 vk = 0. This completes the proof.

Recall that for a circulant matrix A, the submatrix AI1 is Toeplitz. The next result shows that the

conditions T u = 0 or T vk = 0 impose stringent constraints on a real symmetric Toeplitz matrix T .

the polynomial p(x) = Qd

Lemma B.2. Let ϕ1, . . . , ϕd ∈ (−π, π] be distinct angles, and let w ∈ Rd+1 be the coeﬃcient vector of
k=1(x − eiϕk ), with w1 = 1 being the coeﬃcient at xd. Let Ξ ⊂ [0, π] be the set
of angles ξ such that either both ±ξ appear among the angles ϕk, k = 1, . . . , d, or ξ = ϕj = π for some
j. Let T be a real symmetric Toeplitz matrix satisfying T w = 0. Then T ∈ span{Tξ}ξ∈Ξ, where Tξ is the
symmetric Toeplitz matrix with ﬁrst row (1, cos ξ, . . . , cos dξ).

Proof. Let ϕd+1, . . . , ϕ2d+1 ∈ (−π, π] be such that ϕj are mutually distinct for j = 1, . . . , 2d + 1. For any
ϕ ∈ (−π, π], let hϕ = (eikϕ)k=0,...,d ∈ Cd+1 be a column vector and Hϕ = hϕh∗
ϕ the corresponding complex
Hermitian rank 1 Toeplitz matrix. Then Hϕ1 , . . . , Hϕ2d+1 are linearly independent over the complex num-
bers, and hence also over the reals. Indeed, the matrix Hϕ contains 2d + 1 distinct elements e−idϕ, . . . , eidϕ.
However, the vectors (e−idϕj , . . . , eidϕj ), j = 1, . . . , 2d + 1, are linearly independent, because suitable multi-
ples of these vectors can be arranged into a Vandermonde matrix. Therefore Hϕ1 , . . . , Hϕ2d+1 form a basis
of the (2d + 1)-dimensional real vector space of complex Hermitian (d + 1) × (d + 1) Toeplitz matrices.

The real symmetric Toeplitz matrix T is also complex Hermitian and can hence be written as a linear
j=1 αjHϕj , αj ∈ R. Now h∗
ϕj w = 0 for j = 1, . . . , d by construction of w, and therefore
ϕj w)hϕj = 0. But the vectors hϕd+1, . . . , hϕ2d+1 again form a Vandermonde matrix and
ϕj w = e−idϕj p(eiϕj ) 6= 0 for all j = d + 1, . . . , 2d + 1.

j=d+1 αj(h∗

are hence linearly independent. Moreover, we have h∗

combination T =P2d+1
T w =P2d+1
It follows that αj = 0 for all j = d + 1, . . . , 2d + 1, and T =Pd
hence Pd

Now the ﬁrst column of the imaginary part ImHϕj is given by Imhϕj = (0, sin ϕj , . . . , sin dϕj)T , and
j=1 αj sin lϕj = 0 for all l = 1, . . . , d. As in the proof of Lemma A.7, we may use the formula
sin lϕ = sin ϕ(e(l−1)iϕ +e(l−3)iϕ +· · ·+e−(l−1)iϕ) to rewrite this system of linear equations on the coeﬃcients
αj as

j=1 αjHϕj .

· · ·
· · ·

1

cos ϕ1

...

1

cos ϕd

...

cosd−1 ϕ1

· · ·

cosd−1 ϕd







α1 sin ϕ1

...

αd sin ϕd




= 0.




It follows that a coeﬃcient αj can only be non-zero if either sin ϕj = 0, in which case ϕj ∈ Ξ and Hϕj = Tϕj ,
or there exists another index j′ ∈ {1, . . . , d} such that ϕj′ = −ϕj and αj′ = αj, and therefore |ϕj| ∈ Ξ and
αjHϕj + αj′ Hϕj′ = 2αjT|ϕj|. This completes the proof.

The restrictions on the Toeplitz matrices translate into the following restrictions on matrices A ∈ Lu,Id

and on the circulant factor in Lemma B.1.

Corollary B.3. Let n ≥ 5 be an odd integer, set m = n−3
such that there are no multiples of 2π
in Lemma B.2, with d = 2m.

2 , and let ϕ1, . . . , ϕ2m ∈ (−π, π] be distinct angles,
n among them. Deﬁne the vector w ∈ Rn−2 and the set Ξ ⊂ [0, π] as

27

Let Lw ⊂ LC be the linear subspace of real symmetric circulant matrices C such that CI1 w = 0. Then
dim Lw ≤ 1. If dim Lw = 1, then Ξ has m elements. In particular, for dim Lw = 1 either the values eiϕj
group into m complex-conjugate pairs, or they group into m − 1 complex conjugate pairs and among the two
remaining values one equals −1.

Proof. Since ϕj 6= 0 for all j = 1, . . . , 2m, the set Ξ can have at most m elements. Set r = |Ξ|.

Let C ∈ Lw be non-zero. By Lemma B.2 the Toeplitz matrix T = CI1 can be written as a non-zero
j=1 λjTξj , ξj ∈ Ξ for all j = 1, . . . , r. Since the elements of CI1
determine the circulant matrix C completely by Lemma 2.3, we also have dim Lw ≤ r. Since C 6= 0, the
set Ξ contains at least one element.

linear combination of {Tξ}ξ∈Ξ, T = Pr

k = 4, . . . , n+1
k)ξj , k = 3, . . . , n−1

For n = 5 we then get r = m = 1, which proves the assertion in this case.
Suppose that n ≥ 7. We have C1k = C1,n+2−k for all k = 2, . . . , n. It follows that T1k = T1,n+2−k for all
j=1 λj cos(n −

2 , on the coeﬃcients λj. By Lemma A.7 this system is equivalent to the system

2 . This yields the linear homogeneous system of equationsPr
j=1 λj cos kξj =Pr



λ1 sin ξ1
2 sin nξ1
...
λr sin ξr
2 sin nξr

cosm−2 ξ1

cosm−2 ξr




· · ·
· · ·

cos ξ1

cos ξr

= 0.

· · ·

1

2

2

1

...




...




Since there are no multiples of 2π
and hence sin ξj
has a non-trivial kernel, implying r > m − 1 and hence r = m.

n among the angles ϕj , there are no multiples of 2π

n among the ξj neither,
6= 0 for all j = 1, . . . , r. It follows that the coeﬃcient matrix in the system above

2 sin nξj

2

However, the coeﬃcient matrix has full row rank m − 1, and therefore the solution λ1, . . . , λm is deter-
mined by the angles ξ1, . . . , ξm up to multiplication by a common scalar. Hence CI1 and by Lemma 2.3
also C is determined up to a scalar factor, and dim Lw ≤ 1.

We are now in a position to prove the result we need for Lemma 7.7.

Lemma B.4. Let n ≥ 5 be odd. Set m = n−3
2
order such that the fractional part of nζj

and let ζ1, . . . , ζm ∈ (0, π) be distinct angles in increasing
2 ) for odd j and in ( 1
2 , 1) for even j. Let u ∈ Rn−2 be
j=1(x2 − 2x cos ζj + 1) and let Lu ⊂ Sn be the subspace
of all matrices A satisfying AIj u = 0 for all j = 1, . . . , n. Then the condition dim Lu > 1 implies that
ζj = (2j−1)π

the coeﬃcient vector of the polynomial p(x) = Qm

for all j = 1, . . . , m. In particular, the vector u has negative elements.

4π is in (0, 1

n

Proof. By assumption there are no multiples of 2π
among the angles ±ζj − πk(n−1)
for all j = 1, . . . , m and k = 1, . . . , n−1
multiple of 2π for these values of k, and hence the angles ±ζj − πk(n−1)
by a shift by a non-zero value modulo 2π.

n among the angles ±ζj and, since n − 1 is even, also
is not a
are obtained from the angles ±ζj

2 . Note also that πk(n−1)

n

n

n

The solution space Lu is a direct sum of the subspaces Lu,Id and Lu,k, k = 1, . . . , n−1
2

corresponding
to the irreducible representations of the group Dn. By Corollary B.3 with w = u we have dim Lu,Id ≤ 1.
Therefore dim Lu > 1 implies that Lu,k is non-zero for some k.

Let A ∈ Lu,k be a non-zero matrix. Then by Lemma B.1 there exists a non-zero real symmetric circulant
matrix C satisfying CI1 vk = 0. By Corollary B.3 with w = vk the roots ei(±ζj −πk(n−1)/n), j = 1, . . . , m, of
pk(x) either group into m complex-conjugate pairs, or they group into m − 1 complex conjugate pairs and
among the two remaining roots one equals −1. We shall now show that this condition uniquely determines
the angles ζj.

For l = 1, . . . , n, deﬁne open arcs al = {eiϕ | ϕ ∈ ( 2π(l−1)

e±iζj , ei(±ζj −πk(n−1)/n) ∈Sn

n on the unit circle. Then
2 . Moreover, by the assumptions on ζj
we can have eiζj ∈ al only if the parity condition l ≡ j modulo 2 holds. Since ζ1, . . . , ζm is an increasing
sequence, we also have that each interval al contains at most one of the values eiζ1 , . . . , eiζm. We consider
two cases.

l=1 al for all j = 1, . . . , m, k = 1, . . . , n−1

n )} of length 2π

1. ζm > (n−1)π

. Then e±iζm ∈ a(n+1)/2. Any other arc al contains at most one of the values e±iζj .
Hence there are exactly 4 of these arcs containing no such value, and these are located symmetrically about

, 2πl

n

n

28

the real axis. Now consider how the rotated values ei(±ζj −πk(n−1)/n), j = 1, . . . , m, are distributed over the
arcs al. In a similar way there must be 4 arcs, call them α1, α2, α3, α4, containing no value and one arc,
call it β, containing two values, but β 6= a(n+1)/2. We distinguish again two possibilities.

1.1.

If the complex conjugate arc to β is one of the arcs α1, . . . , α4, then the two complex values

contained in β are not matched by complex conjugate values.

1.2. If none of the arcs α1, . . . , α4 is complex conjugate to β, then at least one of these arcs, let it be
α1, is matched by a complex conjugate arc containing exactly one value. Hence at least one of the values
in β and the value in the complex conjugate arc to α1 are not matched by complex conjugate values.

It follows in both cases that there are at least two complex values among ei(±ζj −πk(n−1)/n) which are

not matched by a complex conjugate, leading to a contradiction.

n

2. ζm < (n−1)π

. Since eiζm 6∈ am+1 by the parity condition, we must have eiζj ∈ aj, e−iζj ∈ an+1−j
for all j = 1, . . . , m. Now we again consider the distribution of the values ei(±ζj −πk(n−1)/n), j = 1, . . . , m.
There are 3 consecutively located arcs which do not contain any of the values ei(±ζj −πk(n−1)/n), call them
α1, α2, α3. The remaining arcs contain exactly one value each. The arcs α1, α2, α3 are obtained from
the arcs a(n−1)/2, a(n+1)/2, a(n+3)/2 by multiplication with e−iπk(n−1)/n and are not located symmetrically
about the real axis. Hence at least one value among ei(±ζj −πk(n−1)/n), j = 1, . . . , m, is not matched by
a complex conjugate. It follows that among these values the value −1 must appear, and two of the arcs
α1, α2, α3 must be complex conjugate to each other. The second condition is only possible if these two
arcs border the point z = 1 on the unit circle. Equivalently, eiπk(n−1)/n must lie on the boundary of the
arc a(n+1)/2, implying k = 1. Recall that the value among ei(±ζj −π(n−1)/n), j = 1, . . . , m which lies in the
interval a(n+1)/2 must equal −1. This is the value ei(−ζ1−π(n−1)/n), and hence ζ1 = π
n . Finally, using that
the values ei(ζj −π(n−1)/n) and ei(−ζj+1−π(n−1)/n) are mutually complex conjugate for all j = 1, . . . , m − 1,
we obtain the values ζj = (2j−1)π

for all j = 1, . . . , m.

+ 1). The coeﬃcient at the linear term is given by

Thus we have p(x) = Qm
u1 = −2Pm

j=1 cos (2j−1)π

n

n

j=1(x2 − 2x cos (2j−1)π

n

< 0, which concludes the proof.

29

