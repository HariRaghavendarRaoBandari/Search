Performance Localisation

Brendan Cody-Kenny, Stephen Barrett∗
School of Computer Science & Statistics,

Trinity College Dublin

6
1
0
2

 
r
a

M
4

 

 
 
]
E
S
.
s
c
[
 
 

1
v
9
8
4
1
0

.

3
0
6
1
:
v
i
X
r
a

1

Introduction

Proﬁling is a prominent technique for ﬁnding the location of performance "bottlenecks" in code. Proﬁling
can be performed by adding code to a program which increments a counter for each line of code each time
it is executed. Any lines of code which have a large execution count relative to other lines in the program
can be considered a bottleneck. Though code proﬁling can determine the location of a performance issue
or bottleneck, we posit that the code change required to improve performance may not always be found
at the same location. Developers must frequently trace back through a program to understand what code
is contributing to a bottleneck. We seek to highlight code which is likely causing or has the most eﬀect on
the overall execution cost of a program. Much work has been done in the area of "fault localisation" where
"suspicious" lines of code are highlighted [6]. As fault localisation techniques have enabled automatic bug
ﬁxing [13] similar techniques for performance localisation can aid performance improvement [7].

In this document we compare diﬀerent methods for localising potential performance improvements.
We inspect the use of mutation to indicate the location of performance improvements in programs. By
modifying a program exhaustively at each modiﬁcation point, we can generate a set of program variants for
each location. In other words, we generate all possible ﬁrst order mutants [8] for each modiﬁcation point
in a program. The characteristics of program variants for each location can be summarised. Using simple
heuristics across the summarised information for each location, it is possible to determine the likelihood
of a location being important for improving performance.

In the following sections, we compare the use of a proﬁler, statement deletion and exhaustive code

mutation for highlighting potential performance improvements in code.

2 Problem Set

We use a variety of sort algorithms and a Huﬀman codebook generation algorithm to observe how proﬁling,
statement deletion and exhaustive mutation can ﬁnd improvement locations. A full code listing of all
algorithms in our problem set is available 1.

Table 1 gives an overview of the algorithms used.

• LOC refers to the number of lines of code in the program.

• AST nodes refers to the number of modiﬁcation points in each program when it is parsed into an

Abstract Syntax Tree representation [11].

∗codykenb@scss.tcd.ie, stephen.barrett@scss.tcd.ie
1https://www.scss.tcd.ie/~codykenb/locoGP-ImprovementsFound.html

1

Problem Name
Insertion Sort
Bubblesort
BubbleLoops
Selection Sort 2
Selection Sort
Shell Sort
Radix Sort
Quick Sort
Cocktail Sort
Merge Sort
Heap Sort
Huﬀman Codebook

LOC AST Nodes

Imp Nodes

Improvement

13
13
14
16
18
23
23
31
30
51
62
115

60
62
72
72
73
85
100
116
126
216
246
411

3
5
8
1
1
3
3
2
1
1
2
5

9%
45%
71%
11%
2%
5%
3%
54%
15%
5%
41%
43%

Table 1: Problem Improvement Overview.

• Imp Nodes refers to the number of nodes or locations in the program which need to be changed
to achieve an improved version of the program. Although there are a number of diﬀerent code
modiﬁcations which can yield an improved variant of a program, we use the improvements which
give the greatest reduction in execution cost with the smallest number of modiﬁcations. Modiﬁcations
which reduce program functionality the least when applied individual are also favoured. We thus
use the improvements that are the ’easiest’ or most probable set of modiﬁcations to be found with
a search algorithm.

• Improvement refers to the largest percentage improvement in execution cost known for each pro-

gram [2].

2.1

Improvement Nodes

Table 2 lists the nodes in each program which are required to change for a known improved variant of a
program to be created. The ranking given to these nodes is taken as the the accuracy of a technique in
highlighting improvements. The higher these nodes are ranked by a technique, the more accurate that
technique can be considered.

Table 2: Important nodes & Change Types

Problem
Insertion
Sort

BubbleSort

Selection
Sort 2

Node # Details of Change
9
17
25
46
50
5
9
21
13
16
30

operator change = to +=
clone into block 17
replace j with a[j]
replace j with i
replace j with 1
replace 0 with 1
replace i++ with length--
replace 1 with i
replace 0 with k
replace length - 1 with length
replace i + 1 with k

2

Improvement Type
Loop unrolling

Redundant Traversal

Removed redundant
increments during tests

Continued on next page

Table 2: Important nodes & Change Types

Problem

BubbleLoops

Selection
Sort

Shell Sort

Radix Sort

Quick Sort

Cocktail
Sort

Merge Sort
Heap Sort

Huﬀman
CodeBook

Improvement Type

Redundant Traversal

Removed redundant
array access

Various changes in
increment size

Node # Details of Change
31
5
8
16
20
32
13
15
20
62
0
4
74
0
5
6
7
9
26
43
44
46
59
5
59
62
120
148
7
10
31
55
211
218
324
328
340

replace i with k
replace 2 with 1
replace 0 with 1
replace 0 with 1
replace i++ with length--
replace 1 with i
clone into block 13
replace Integer.MAX_VALUE
replace currentPlace + 1
replace a[smallestAt] with smallest
clone into block 0
operator change / to +
operator change = to -=
clone For loop into Block 0
replace Integer.SIZE - 1 with 0
replace 1
operator change > to >= or ==
replace -1 with 0
replace 0 with shift
replace i < r && a[i] < x with a[i] < x Reduced iterations
replace i < r with j < r && j++ < x
replace r with j
replace j > p && a[j] > x with a[j] > x
clone into do loop block 5
delete swapped=true
replace if (!swapped) { break;}
replace swapped=true with i--
delete for statement
operator change / to +
replace 1 with 2
replace 1 with 2
replace child with root
replace a[root] with temp
delete statement
replace 0 with 1
replace i++ with length--
replace 1 with i

Same as Bubblesort

Reduced iteration,
comparison with 0
instead of -1
loop unrolling, to avoid
comparison with -1
with 0 handled in own loop

remove tests

Cloned and perforated loops
Exclude sorted portion

Remove redundant array clone
Remove redundant array
access and assignment

3 Proﬁling

Proﬁling measures the number of times each statement in a program is executed. As statements are
attributed cost in response to their execution frequency, proﬁling is useful in ﬁnding what statements
contribute most to the overall execution cost of the program. Proﬁling is useful in highlighting the most
frequently executed (and assumed most costly) statements in a program. The most frequently executed
statements are perceived as a bottleneck in the code. As a large amount of program execution is spent

3

on bottleneck code, it is worth investing time in understanding how to alleviate the bottleneck in order to
improve performance as much as possible.

We apply proﬁling to our test problems and measure the ranking of those nodes which must be modiﬁed

to produce an improved variant program.

Table 3 shows the results of this experiment where:

• Line Rank refers to the execution frequency of each statement. The line ranking is applied to all

nodes in the statement.

• Ranking refers to the ranking of the important node. Fractional ranking is used as all nodes in a
statement jointly share a given ranking. E.g.
if two nodes share ﬁrst place, then both nodes are
given the ranking of "1.5" as this will be the ranking of the nodes on average if they are selected
randomly.

• Percentile refers to the percentage of all nodes which an important node is considered better than.

Nodes ranked in the upper 50 percentile of all the nodes represent instances where proﬁling has ac-
curately highlighted the location of an improvement. Although somewhat arbitrary, we chose the 50
percentile as a simple way to show how the nodes in a program can be segregated. Nodes which have
a ranking in the lower 50 percentile of all nodes represent instances where proﬁling can be said to have
been "deceived". This is most obviously exempliﬁed in the hand-crafted "BubbleLoops" problem, where
an extra redundant outer loop has been added to Bubblesort. Proﬁling attributes a very low ranking
to locations where simple changes which would half the execution cost of the program. Other examples
which were not speciﬁcally crafted to be deceptive problems include Selection 2, Selection, Shell, Radix
and Cocktail sort. In table 3, nodes which are important but receive a ranking in the upper half of all
nodes are in bold font.

This experimentation is intended to show that the location of a performance bottleneck, as typically
found using a proﬁler, does not always highlight potential performance improvements. When a performance
improvement receives a low ranking, a search algorithm such as genetic programming will be even less
likely to ﬁnd the improvement than had there been no node ranking at all. In this sense, we say that
the proﬁling technique has been "deceived". This scenario expresses the need for a technique which can
determine more accurately where an improvement is likely to exist within a program.

Table 3: Proﬁler Ranking for Important nodes

Problem
Insertion
Sort

BubbleSort

Selection
Sort 2

Imp Node Line Rank Ranking Percentile
29
72
72
72
86
9
9
86
65
65
89
89
Continued on next page

5 / 7
2 / 7
2 / 7
2 / 7
1 / 7
6.5 / 7
6.5 / 7
1 / 7
3 / 10
3 / 10
1 / 10
1 / 10

42.6
16.8
16.8
16.8
8.4
56.12
56.12
8.54
21.6
21.6
7.2
7.2

9
17
25
46
50
5
9
21
13
16
30
31

4

Table 3: Proﬁler Ranking for Important nodes

Problem
BubbleLoops

Selection
Sort

Shell Sort

Radix Sort

Quick Sort

Cocktail Sort

Merge Sort
Heap Sort

Huﬀman
CodeBook

5
8
16
20
32
13
15
20
62
0
4
74
0
5
6
7
9
26
43
44
46
59
5
59
62
120
148
7
10
31
55
211
218
324
328
340

Imp Node Line Rank Ranking Percentile
13
13
25
25
82
28
28
28
28
8
8
8
39
39
39
39
39
93
93
93
93
93
28
55
28
64
58
43
43
32
20
89
86
90
90
99

7 / 8
7 / 8
6 / 8
6 / 8
1.5 / 8
8 / 11
8 / 11
8 / 11
8 / 11
12 / 13
12 / 13
12 / 13
8 / 13
8 / 13
8 / 13
8 / 13
8 / 13
1 / 13
1.5 / 20
1.5 / 20
1.5 / 20
1.5 / 20
13 / 18
10 / 18
13 / 18
6.5 / 18
14 / 32
20 / 35
20 / 35
24 / 35
28 / 35
4 / 35
5 / 35
7 / 62
7 / 62
1 / 62

63.51
63.51
54.75
54.75
13.14
52.56
52.56
52.56
52.56
80.04
80.04
80.04
61
61
61
61
61
7
8.12
8.12
8.12
8.12
90.72
70
90.72
45.5
94
140.22
140.22
168.7
196.8
28
34.44
45
45
4.1

4 Exhaustive Mutation

We inspect how repeated modiﬁcations to a program can give hints as to where an improvement is likely
to exist under further modiﬁcation. A set of program variants is produced by repeatedly replacing a
node with every other valid alternative node as found in the original program. Program variants may
not compile, throw a run-time error or run with diﬀerent functionality and/or performance characteristics
than the original program. From the set of programs produced for each node, we count the number of
variants which compile, and the number of variants which have execution cost lower than the original

5

program. Dividing frequency of execution reduction by frequency of compilation gives an "importance"
value for each node in the original program. This quotient is used as a recommendation for which nodes
are most likely to yield performance improvements under further modiﬁcation.

Results are shown in Table 4:

• Comp refers to the number of times a modiﬁcation to a node results in a program variant which
compiles. Modiﬁcation is attempted with every other possible node available in the program. Re-
placements which do not change the program are excluded (we do not count "a" being replaced by
"a" if a reference to a diﬀerent variable "a" is used elsewhere in the program). A dash indicates
instances where no program variant compiles.

• Red refers to the number of times variant programs have reduced execution cost when compared to

the original seed program.

• Red/Comp refers to the number of times a variant program has reduced execution cost divided by

the number of times the program compiled.

4.1

Issues

This approach raises a number of issues. It is expensive, requiring the attempted replacement of every
node with every other node. Many replacements are not possible due to language typing constraints as
enforced by the AST representation used. Many replacements will result in programs which can be quickly
found to not compile, and therefore do not incur the comparatively large evaluation cost of repeat variant
program execution with several diﬀerent test input values.

Table 4: Ranking of Important Nodes Per Number of Times
Performance Reduction / Times Compiled.

Problem
Insertion
Sort

BubbleSort

Selection
Sort 2

BubbleLoops

Selection
Sort

Node Comp Red
0.00
9
17
2.00
0.00
25
12.00
46
3.00
50
5
5.00
0.00
9
23.00
21
13
0.00
12.00
16
25.00
30
28.00
31
5
0.00
0.00
8
23.00
16
0.00
20
32
18.00
1.00
13
0.00
15
20
16.00

0
3
0
36
36
6
0
31
0
14
37
37
0
7
29
25
27
1
0
19

Red/Comp Ranking Percentile
-
.66
-
.33
.08
.83
-
.74
-
.85
.67
.75
-
0
.79
0
.66
1.00
-
.84

-
6.00
-
14.00
27.50
9.50
-
13.50
-
8.00
21.50
16.50
-
51.00
9.50
51.00
14.00
2.00
-
6.50

-
90
-
77
55
85
-
79
-
90
71
78
-
30
87
30
81
98
-
92

Continued on next page

6

Table 4: Ranking of Important Nodes Per Number of Times
Performance Reduction / Times Compiled.

Problem

Shell Sort

Radix Sort

Quick Sort

Cocktail Sort

Merge Sort
Heap Sort

Huﬀman
CodeBook

Node Comp Red
62
0
4
74
0
5
6
7
9
26
43
44
46
59
5
59
62
120
148
7
10
31
55
211
218
324
328
340

29
18
8
2
18
8
8
1
14
22
7
8
52
7
5
1
4
1
19
28
27
69
113
129
38
34
5
88

Red/Comp Ranking Percentile
.75
22.00
0
0.00
.37
3.00
.50
1.00
0
0.00
.87
7.00
.25
2.00
*1.00
1.00
1.00
14.00
.45
10.00
.14
1.00
.25
2.00
.75
39.00
.42
3.00
0
0.00
1.00
1.00
0
0.00
1.00
1.00
.10
2.00
.71
20.00
.40
11.00
.23
16.00
17.00
.15
124.00 .96
.55
21.00
.52
18.00
0
0.00
10.00
.11

11.00
64.00
24.00
16.00
66.00
8.00
32.50
3.00
3.00
23.50
42.00
36.50
10.50
23.50
66.00
17.00
66.00
17.00
112.00
56.50
124.50
142.00
153.50
9.50
96.50
66.50
260.50
139.50

85
25
72
82
34
92
68
97
97
77
64
69
91
80
48
87
48
87
49
78
50
43
38
97
61
84
37
67

5 Deletion Analysis

Deletion analysis was designed in an attempt to shift focus from bottlenecks towards code which has some
inﬂuence over performance. In an attempt to exploit the ordered and hierarchical structure of imperative
code, execution cost is attributed to statements which appear earlier in the code and to statements higher
in the hierarchy. For example, the body of a "FOR" loop which may contain many statements can be
considered the child of a "FOR" statement. The hierarchical structure of imperative code is supported by
AST parsers [11] and is also used in scoping variables in code. The parent "FOR" statement is attributed
the execution cost of all child statements, however deeply nested, by deleting the "FOR" statement
including all child statements and measuring the execution cost reduction of the variant program when
compared with the original.

Table 5 shows the results for improvement node rankings under deletion analysis. Nodes that did not
compile at all under exhaustive mutation as previously represented by a dash in 4 are underlined in 5 for
comparison. Nodes that receive a ranking in the upper 50 percentile are in bold font.

7

Table 5: Ranking of Important Nodes Per Performance Re-
duction Due to Deletion

BubbleSort

BubbleLoops

Selection
Sort 2

Problem
Insertion
Sort

Node Ranking Percentile
9
17
25
46
50
5
9
21
13
16
30
31
5
8
16
20
32
13
15
20
62
0
4
74
0
5
6
7
9
26
43
44
46
59
Cocktail Sort 5

Selection
Sort

Shell Sort

Radix Sort

Quick Sort

20.00
20.00
20.00
45.00
45.00
5.50
5.50
17.50
29.50
29.50
42.50
42.50
5.50
5.50
16.50
16.50
28.50
17.00
17.00
17.00
69.00
80.50
80.50
10.00
98.50
22.50
22.50
22.50
22.50
55.50
92.50
92.50
92.50
79.50
7.00
54.00
7.00
108.00
203.50
119.00
119.00
119.00
156.50
214.50
229.00

67
67
67
25
25
92
92
72
60
60
41
41
93
93
78
78
61
77
77
77
06
06
06
89
02
78
78
78
78
45
21
21
21
32
95
58
95
15
06
52
52
52
37
13
07

Merge Sort
Heap Sort

59
62
120
148
7
10
31
55
211
218

Continued on next page

8

Table 5: Ranking of Important Nodes Per Performance Re-
duction Due to Deletion

Problem
Huﬀman
CodeBook

Node Ranking Percentile
324
328
340

40.50
40.50
66.00

91
91
84

6 Exhaustive & Deletion Gap Filling

In section Exhaustive Mutation exhaustive mutation analysis is used to attribute rankings to nodes. An
issue with this approach is that for some important nodes no allowed modiﬁcation produces a compilable
program as noted in table 4. Where nodes cannot be mutated to show any compiled programs, we
subsequently use deletion analysis as a reﬁnement to allocate missing values where there is a gap in the
results as shown in table 6.

Table 6: Exhaustive analysis with Deletion Reﬁnement

Problem
Insertion
Sort

BubbleSort

Selection
Sort 2

BubbleLoops

Selection
Sort

Shell Sort

Radix Sort

Node Ranking Percentile
9
17
25
46
50
5
9
21
13
16
30
31
5
8
16
20
32
13
15
20
62
0
4
74
0
5
6
7
9

4.50
17.50
4.50
25.50
38.50
3.50
9.00
18.50
12.00
3.50
29.50
24.50
47.00
56.50
18.50
56.50
24.50
2.50
11.00
21.50
26.50
72.00
36.00
26.50
80.00
20.00
46.50
3.50
3.50

93
71
93
58
.36
95
86
71
84
96
60
67
.35
.22
75
.22
66
97
85
71
64
.16
58
69
.20
80
54
97
97

Continued on next page

9

Table 6: Exhaustive analysis with Deletion Reﬁnement

Problem

Quick Sort

Cocktail Sort

Merge Sort
Heap Sort

Huﬀman
CodeBook

Node Ranking Percentile
26
43
44
46
59
5
59
62
120
148
7
10
31
55
211
218
324
328
340

36.50
54.50
44.50
20.50
32.50
106.50
6.50
89.50
6.50
143.00
83.50
119.50
185.50
195.50
18.00
142.50
16.50
75.00
149.50

64
54
62
83
72
.16
95
29
95
.34
67
52
.25
.21
93
.43
96
82
64

7 Comparison

Table 7 shows a comparison between the previously mentioned techniques with the most accurate values
for each node highlighted in bold font.

Table 7: Comparison

Problem
Insertion
Sort

BubbleSort

Selection
Sort 2

BubbleLoops

Imp Node Proﬁler Deletion Exhaustive Exhaustive & Deletion
9
17
25
46
50
5
9
21
13
16
30
31
5
8
16
20

29
72
72
72
86
09
09
86
65
65
89
89
13
13
25
25

93
71
93
58
36
95
86
71
54
75
43
47
70
96
96
12

67
67
67
25
25
92
92
72
60
60
41
41
93
93
78
78

-
90
-
77
55
85
-
79
-
90
71
78
-
30
87
30

Continued on next page

10

Table 7: Comparison

Problem

Selection
Sort

Shell Sort

Radix Sort

Quick Sort

Cocktail Sort

Merge Sort
Heap Sort

Huﬀman
CodeBook

Imp Node Proﬁler Deletion Exhaustive Exhaustive & Deletion
32
13
15
20
62
0
4
74
0
5
6
7
9
26
43
44
46
59
5
59
62
120
148
7
10
31
55
211
218
324
328
340

70
97
85
71
64
16
58
69
20
80
54
97
97
64
54
62
83
72
16
95
29
95
34
67
52
25
21
93
43
96
82
64

81
98
-
92
85
25
72
82
34
92
68
97
97
77
64
69
91
80
48
87
48
87
49
78
50
43
38
97
61
84
37
67

82
28
28
28
28
08
08
08
39
39
39
39
39
93
93
93
93
93
28
55
28
64
58
43
43
32
20
89
86
90
90
99

61
77
77
77
06
06
06
89
02
78
78
78
78
45
21
21
21
32
95
58
95
15
06
52
52
52
37
13
07
91
91
84

8 Summary

Table 8: Overview

Nodes most accurate (48)
Nodes Deceived (48)
Problems with Deceived Nodes (12)
Problems Majority Nodes Deceived (12)
Best on Problems (12)
Cost

Deletion Exhaustive Ex & Del
Proﬁler
10
13
19
25
8
8
2
6
3
1
Instrumentation + 1 n

12
16
7
2
4
n * (n - 1)

12
12
7
2
4
n * (n - 1) + n

11

Table 8 shows summary values for each technique.

The proﬁler has the highest accuracy values on the most nodes (13 out of a total of 48 important
nodes) although is deceived on a large number of nodes (25) across 8 problems. It is also deceived on a
majority of the improvement nodes for 6 of the problems. It did however perform better than any other
approach on 3 of the 12 problems including the Huﬀman Codebook problem which is the largest in our
test set. The major advantage of this approach is the relatively low computational cost required. A single
run of an instrumented program is enough to proﬁle.

Deletion analysis requires a program execution for each of "n" lines in a program though is less deceived
on average than a proﬁler. Exhaustive is more accurate but also close to exponentially more expensive to
perform.

The use of Exhaustive analysis with deletion reﬁnement ("Ex & Del" in table 8) was least deceived
of all techniques across all nodes, with only 12 nodes lower than the 50 percentile of all nodes. It was
deceived on at least 1 node in 7 of the 12 problems and was deceived on the majority of important nodes
in 2 of the problems. It also has the highest accuracy on 12 of the 48 important nodes. It performs the
best across 4 of the problems. A major disadvantage of this approach is the high computational cost to
perform localisation.

In these results we assume that if an approach is deceived on a majority of important nodes in a
problem, it is likely that it will take longer to ﬁnd an improvement as GP modiﬁes other locations in the
program. If half or more of the nodes are ranked highly, then it is likely that the approach will help GP
ﬁnd at least one of the possible improvements more quickly.

We consider a technique’s ability to avoid being deceived as being more important than being the most
accurate. We expect that there is some threshold value below which the use of a technique to guide a
search process would lower the chances of ﬁnding an improvement. This threshold value is likely to have a
polarising eﬀect on a search algorithm. Eﬀort spent modifying irrelevant nodes is eﬀort that is not spent
on important nodes. Due to this, we can hypothesise that a search algorithm would be delayed in ﬁnding
performance improvements when focusing too much search eﬀort on irrelevant nodes.

9 Threats to validity

Though the problem set of Sort and Huﬀman Codebook problems appears to be varied enough to make
ranking improvement nodes highly across all problems currently unattainable, there remains a potential
issue that the approach of exhaustive mutation and deletion analysis has been specialised to the algorithms
in our problem set, and do not generalise outside this set.

Our choice of threshold value for when techniques can be considered "deceived" may not be an accurate

indicator as to whether a localisation technique would actually mis-guide a search process.

The important nodes listed in our tables are sometimes part of multiple possible improvements. There
are dependencies amongst some of the nodes where modiﬁcations must be made in a certain sequence
to yield an improved program making some improvements easier to ﬁnd than others. Not all nodes are
equal, given that a change in some may produce low functionality programs and are dependent on other
modiﬁcations. As not all nodes are equal in terms of dependencies a simple summation summary may
not appropriately capture a localisation techniques ability to guide GP search. If a majority of important
nodes in a program are highly accurately identiﬁed it may not improve search where these nodes depend
on one speciﬁc node which has unfortunately been misidentiﬁed. The "importance" of nodes is thus not
uniform.

12

10 Related Work

Proﬁling is most often used to show people where a performance issue is occurring [5, 12, 4]. These
techniques are beginning to be used to guide performance improvement [7]

Many advances in proﬁling performance are made with respect to the input values of a program [3].
They are also concerned with ﬁnding the location of "bottlenecks" or where the symptoms of performance
issues can be observed [10]

Where there are many input values to a program, such as the large number of conﬁguration options
made available for a web server, trace analysis can be used to highlight which input values are most likely
associated with performance issues [1].

Methods for locating the cause of performance issues internal to a programs source code address speciﬁc
types of performance improvement and can be used to recommend a speciﬁc technique to alleviate the
issue such as memoisation [9]. As such we seek further methods which can give a probabilistic indicator
for where change should be focused in a program as per the operation of a GP or similar search algorithm.

11 Future Work

Our analysis and claims should be further validated by using the node rankings from each technique
to guide GP search for performance improvements. Provided such experiments corroborate the ﬁndings
in this analysis we can measure by how much each technique improves the search process. We may also
determine what node importance value should be used as a threshold for classifying a localisation technique
as "deceived" where it slows down a search process.

Although using deletion and especially exhaustive mutation is very expensive there may be an op-
portunity to oﬀset this cost by performing this type of localisation during GP given that GP relies on
mutation to perform search. There is a question as to whether localisation can be accurate when multiple
program variants are being modiﬁed and any one program variant is not exhaustively modiﬁed. How to
accurately discern the performance improvement "signal" from the noisy GP environment is an interesting
follow-on problem.

Deletion based localisation strikes a balance between being relatively accurate across many problems
and having an execution cost linear to program size. It appears possible to calculate the same importance
values with a single execution. By taking into account the hierarchy of code elements in a program, the
execution count of each line of code can be attributed to parent lines of code. The execution count of a
parent line of code includes a sum of all child code execution count. For example, the execution count for
each line of code within a "FOR" loop can be added to the outer "FOR" statement. The outer "FOR"
statement can in some sense be made "responsible" for the execution cost of it’s child code.

It also appears that the diﬀerent approaches to performance localisation are not mutually exclusive.
When committing to using GP to create and evaluate hundreds and thousands of variant programs it may
be very worthwhile to perform proﬁling before using GP if mutation-based performance localisation can
ﬁne tune values during GP.

13

References

[1] Attariyan, M., Chow, M., and Flinn, J. X-ray: Automating root-cause diagnosis of performance
anomalies in production software. In Symposium on Operating Systems Design and Implementation
(OSDI) (2012), pp. 307–320.

[2] Cody-Kenny, B., Lopez, E. G., and Barrett, S. locoGP: improving performance by genetic
programming java source code. In Genetic Improvement 2015 Workshop (Madrid, 11-15 July 2015),
W. B. Langdon, J. Petke, and D. R. White, Eds., ACM, pp. 811–818.

[3] Coppa, E., Demetrescu, C., and Finocchi, I.

Input-sensitive proﬁling.

In ACM SIGPLAN

Notices (2012), vol. 47, ACM, pp. 89–98.

[4] Gutiérrez, I. L. M., Pollock, L. L., and Clause, J. SEEDS: a software engineer’s energy-
optimization decision support framework. In ICSE (2014), P. Jalote, L. C. Briand, and A. van der
Hoek, Eds., ACM, pp. 503–514.

[5] Jin, G., Song, L., Shi, X., Scherpelz, J., and Lu, S. Understanding and detecting real-
In ACM SIGPLAN Conference on Programming Language Design and

world performance bugs.
Implementation (PLDI’12) (Beijing, China, June 2012), ACM Press, pp. 77–88.

[6] Jones, J. A., and Harrold, M. J. Empirical evaluation of the tarantula automatic fault-
localization technique. In IEEE/ACM International Conference on Automated Software Engineering
(2005), ACM, pp. 273–282.

[7] Langdon, W. B., and Harman, M. Optimising existing software with genetic programming. IEEE

Transactions on Evolutionary Computation (2013).

[8] Langdon, W. B., and Petke, J. Software is not fragile. In Complex Systems Digital Campus
E-conference, CS-DC’15 (Sept. 30-Oct. 1 2015), P. Bourgine and P. Collet, Eds., Proceedings in
Complexity, Springer, p. Paper ID: 356. Invited talk, Forthcoming.

[9] Olivo, O., Dillig, I., and Lin, C. Static detection of asymptotic performance bugs in collection

traversals. In PLDI (2015), D. Grove and S. Blackburn, Eds., ACM, pp. 369–378.

[10] Shen, D., Luo, Q., Poshyvanyk, D., and Grechanik, M. Automating performance bottleneck
In ISSTA (2015), M. Young and T. Xie, Eds.,

detection using search-based application proﬁling.
ACM, pp. 270–281.

[11] The Eclipse Foundation. Java development tools. http://www.eclipse.org/jdt/, Nov. 2012.

[12] Vásquez, M. L., Vendome, C., Luo, Q., and Poshyvanyk, D. How developers detect and
ﬁx performance bottlenecks in android apps. In ICSME (2015), R. Koschke, J. Krinke, and M. P.
Robillard, Eds., IEEE, pp. 352–361.

[13] Weimer, W., Nguyen, T., Le Goues, C., and Forrest, S. Automatically ﬁnding patches using
In International Conference on Software Engineering (ICSE) (2009), IEEE

genetic programming.
Computer Society, pp. 364–374.

14

