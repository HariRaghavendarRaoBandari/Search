Dynamic Analysis of Bet-Hedging Strategies as a Protection Mechanism

against Environmental Fluctuations

Masaki Ogura1, Masashi Wakaiki2, and Victor M. Preciado1

6
1
0
2

 
r
a

 

M
5
1

.

 
 
]
E
P
o
i
b
-
q
[
 
 

1
v
2
8
6
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract— In order to increase their robustness against
environmental ﬂuctuations, many biological populations have
developed bet-hedging mechanisms in which the population
‘bets’ against the presence of prolonged favorable environ-
mental conditions by having a few individual behaving as if
they sensed a threatening or stressful environment. As a result,
the population (as a whole) increases its chances of surviving
environmental ﬂuctuations in the long term, while sacriﬁcing
short-term performance. In this paper, we propose a theoretical
framework, based on Markov jump linear systems, to model
and evaluate the performance of bet-hedging strategies in the
presence of stochastic ﬂuctuations. We illustrate our results
using numerical simulations.

I. INTRODUCTION

Biological populations, such as bacterial colonies, are
subject to multiple sources of environmental ﬂuctuations,
from regular cycles of daily light and temperature to irregular
ﬂuctuations of nutrients and pH levels [1]–[3]. In order to
increase their robustness against environmental ﬂuctuations,
many biological systems have developed bet-hedging mech-
anisms [3], [4] in which the population ‘bets’ against the
presence of prolonged favorable environmental conditions by
having a few individual behaving as if they sensed a threat-
ening or stressful environment. For example, in bacterial
colonies, some bacteria may stochastically switch into a state
of slow metabolic state, in which they are more robust against
pH ﬂuctuations. As a result, the population (as a whole)
increases its chances of surviving pH ﬂuctuations in the long
term, while sacriﬁcing short-term performance. Similar bet-
hedging strategies can be found in many other biological
systems, such as the lysis-lysogeny switch of bacteriophage
λ [5], delayed germination in plants [6], and phenotypic
variations in bacteria [7].

In this paper, we pay special attention to a particular
type of bet-hedging mechanism based on introducing delays
in the function of a few individuals in the population.
For example, in the case of cell populations, the presence
of time-delays in some basic patterns of cell proliferation
can signiﬁcantly improve the overall population ﬁtness [8].
Similarly, delayed germination in plant populations [6] and
delayed disease activation of viruses [9] have also been
reported as bet-hedging strategies in biological systems.

1M. Ogura and V. M. Preciado are with the Department of Electrical
and Systems Engineering, University of Pennsylvania, PA 19104, USA.
{ogura,preciado}@seas.upenn.edu

2M. Wakaiki is with the Department of Electrical and Electronic En-
gineering, Chiba University, 1-33 Yayoi-cho, Inage-ku, Chiba 263-8522,
Japan. wakaiki@chiba-u.jp

This work was supported in part by the NSF under grants CNS-1302222

and IIS-1447470.

literature,

In the current
the performance of bet-hedging
strategies is evaluated using either extensive numerical simu-
lations, or overly simplistic assumptions. Based on numerical
simulations,
the authors in [10] found the optimal rates
of adaptation (e.g., the rate at which bacteria switch into
a slow metabolic state) to maximize the growth rate of
cell populations. Based on overly simplistic assumptions,
analytical calculations of growth rates of phenotypically
heterogeneous populations are performed by assuming that
environmental ﬂuctuations are either slow enough [1], fast
enough [11], or periodic [12]. Although the works mentioned
above provide intuitive explanations about the effects of bet-
hedging strategies, there is still a lack of a solid mathematical
framework for the evaluation of bet-hedging strategies under
complex environmental ﬂuctuations.

The aim of this paper is to present a rigorous and tractable
framework to quantify the growth rates of cell populations
using bet-hedging strategies involving time-delays. Building
on the models in the literature [1], [10], [13], we introduce
a population model in terms of positive Markov jump linear
systems [14] with delays. Among various types of delays, we
speciﬁcally focus on those in proliferation (i.e., in the state
variables) and in adaptation to environmental changes (i.e.,
in the switching signals). In the former case, we show that
the growth rate of a population exhibiting both point and
distributed delays is upper-bounded by the maximum real
eigenvalue of a particular Metzler matrix. In the latter case,
we consider stochastic delays in adaptation to environmental
ﬂuctuation and show that the growth rate coincides with
the maximum real eigenvalue of a Metzler matrix. The
proposed framework can also be used to study both point and
distributed delays in the state variables in a uniﬁed manner,
whereas these delays have been studied separately in the
literature [15], [16].

This paper is organized as follows. After presenting the
notation in Section II, we introduce several linear growth
models of bet-hedging populations involving time delays.
Then, in Section III, we derive an upper bound on the growth
rates for the case of delayed proliferation. Section IV shifts
our focus to delayed adaptation and shows that the growth
rate equals the maximum eigenvalue of a Metzler matrix.
Numerical simulations are presented in Section V.

A. Mathematical Preliminaries

We denote by R+ the set of nonnegative real numbers.
The 1-norm of x ∈ Rn is deﬁned by (cid:107)x(cid:107) = ∑n
i=1|xi|. The
symbol 1n denotes the column vector of length n whose
entries are all one. By ui, we denote the i-th canonical

basis vector in Rn. Let Ui j = uiu(cid:62)
j . We say that a matrix is
nonnegative if its entries are nonnegative. A square matrix is
said to be Metzler if its off-diagonal entries are nonnegative.
We say that a matrix is Hurwitz stable if all of its eigenvalues
have negative real parts. The Kronecker product [17] of
matrices is denoted by ⊗. It is known [17] that, if the
standard product of matrices AB and CD are well-deﬁned,
then

(AB)⊗ (CD) = (A⊗ B)(C⊗ D).

(1)

´ b
a (cid:107)x(t)(cid:107)dt.

For a closed interval [a,b], the space C([a,b],Rn
ﬁned as the set of Rn
equipped with the norm (cid:107)x(cid:107) =

+) is de-
+-valued continuous functions on [a,b]
Let A0 be an n× n Metzler matrix, A1, . . ., Am be n× n
nonnegative matrices, h1, . . ., hm be nonnegative constants,
and B: [0,∞) → Rn×n
be a continuous function having a
compact support. Consider the positive linear system with
delay [18]:

+

m

i=1

∑

dx
dt = A0x(t) +

Aix(t − hi) + (B∗ x)(t),

(2)
where ∗ denotes the convolution. Let T be the minimum
number such that T ≥ hi for every i ∈ {1, . . . ,m} and the in-
terval [0,T ] contains the support of B. We set the initial con-
dition of (2) as x|[−T,0] = φ for a function φ ∈ C([−T,0],Rn
+).
We say that the system (2) is exponentially stable if there
exist C > 0 and λ < 0 such that (cid:107)x(t)(cid:107) ≤ Ceλt(cid:107)φ(cid:107) for all φ
and t ≥ 0. The following stability characterization is given
in [18]:

Proposition 1.1 ([18, Theorem III.1]): The system (2) is
i=1 Ai +

´ ∞
exponentially stable if and only if the matrix A0 +∑m
0 B(τ)dτ is Hurwitz stable.
We also give a review on random variables and stochastic
processes. Let (Ω,M,P) be a probability space. For an
integrable random variable X on Ω, its expected value is
denoted by E[X]. If M1 ⊂ M is a σ-algebra, then E[X | M1]
denotes the conditional expectation of X given M1. It is well
known (see, e.g., [19]) that

E[X] = E[E[X | M1]].

(3)
f ,g: R → Rn be continuous functions having their
Let
compact supports in [0,∞). Let N1, . . ., Nm denote Poisson
counters. We say that a left-continuous function x taking
values in Rn is a solution of the stochastic differential
equation

dx = ( f ∗ x)dt +

(gi ∗ x)dNi

(4)

m

∑

i=1

if we have dx/dt = ( f ∗x)(t) when no jump occurs at time t,
and x(t+) = x(t−) + (gi∗x)(t−) when Ni jumps at time t. For
the sake of completeness, we state the Itˆo rule for stochastic
differential equations with Poisson jumps (see, e.g., [20]):
Lemma 1.2: Assume that x follows the stochastic dif-
ferential equation (4). Let ψ : Rn → Rm be a differ-
entiable function and deﬁne y(t) = ψ(x(t)) for every
t ≥ 0. Then, y follows the stochastic differential equation
dy = (dψ/dx)( f ∗ x)dt + ∑m
i=1 (ψ(x + (gi ∗ x))− ψ(x)) dNi.

II. DELAYED MODELS FOR BET-HEDGING POPULATIONS
The aim of this section is to introduce models of bet-
hedging populations involving delays. We ﬁrst review the
delay-free population model given in [1], [10]. Building on
this model, we then introduce two models of bet-hedging
populations involving delays in their state variable and mode
signals, respectively.

Let us consider a biological population growing in an en-
vironment ﬂuctuating among n different environment types.
The ﬂuctuation is modeled [1] by a time-homogeneous
Markov process ε = {ε(t)}t≥0 taking values in {1, . . . ,n}
and having the inﬁnitesimal generator Π = [πi j]i, j ∈ Rn×n.
Therefore, the transition probability of the environment is
given by

(cid:40)

P(ε(t + h) = j | ε(t) = i) =

i (cid:54)= j,

πi jh + o(h),
1 + πiih + o(h),

i = j,

i ≥ 0 under environment

where o(h)/h → 0 as h → 0. Each individual in the popu-
lation can exhibit one of n different phenotypes 1, . . ., n.
We assume that the population having phenotype k grows
with the instantaneous rate gk
i.
The phenotypes of individuals are assumed to dynamically
change, and the rate of switch from phenotype k to phenotype
i ≥ 0. We deﬁne
(cid:96) under environment i is denoted by ωk(cid:96)
i = −∑(cid:96)(cid:54)=k ωk(cid:96)
ωkk
. Let xk(t) denote the number of individuals
having phenotype k at
the growth of the
population can be modeled [1], [10] by the differential
equations

time t. Then,

i

Σ0 :

dxk
dt = gk

ε(t)xk(t) +

n

∑

(cid:96)=1

ω (cid:96)k
ε(t)x(cid:96)(t), k = 1, . . . ,n.

Building on this model, we below introduce two growth
models of population involving delays.

A. Delayed Proliferation

We ﬁrst consider a dynamic model of bet-hedging consist-
ing in introducing delays in state variables of the population.
Such delays, which can arise from delayed bet-hedging [9] or
delayed proliferation [8], make the derivative dxk/dt depend
not only on the size of the current populations, but also on
their past values. To deal with this case, we extend the basic
model Σ0 as follows

n

(cid:96)=1

Σ1 :

dxk
dt = gk

ε(t)xk(t − dk

∑
ε(t)xk(t) +
ˆ ∞

ω (cid:96)k
ε(t)x(cid:96)(t) + pk
ε(t))+
ε(t)(τ)xk(t − τ)dτ, k = 1, . . . ,n.
qk
It is naturally assumed that pi
k is a nonnegative number and
qi
k is a nonnegative function having a ﬁnite support in [0,∞)
for all k,i ∈ {1, . . . ,n}. We specify the initial condition of
the system Σ1 by

0

xk|[−T,0] = φk ∈ C([−T,0],R+), k = 1, . . . ,n,

where T is the minimum number such that dk
contains the support of function qk

i ≤ T and [0,T ]
i for all k,i ∈ {1, . . . ,n}.
We deﬁne the growth rate of the model Σ1 as follows:

Deﬁnition 2.1: For λ ∈ R, we say that Σ1
is λ -
there exists C > 0 such that
exponentially stable if
k=1 xk(t)] ≤ Ceλt ∑n
E[∑n
. . ., φn, and
ε(0) ∈ {1, . . . ,n}. We deﬁne the growth rate of Σ1 as the
inﬁmum of λ such that Σ1 is λ -exponentially stable. If
the growth rate of Σ1 is negative, then we say that Σ1 is
exponentially stable.

k=1(cid:107)φk(cid:107) for all φ1,

B. Delayed Adaptation

Another type of delay in bet-hedging populations can be
present in the adaptation of the population to environmental
ﬂuctuations. In this case, each individuals’ information σ
about the environment (on which their adaptation is based
on) does not necessarily coincide with the environment ε
due to delays. This implies that, mathematically speaking,
there exists a nonnegative stochastic process h = {h(t)}t≥0
such that σ (t) = ε(t − h(t)). We assume that the growth
rates depends on the environmental variable ε, while the
adaptation rates between phenotypes depend on the de-
layed information σ. In this situation, the basic population
model Σ0 has to be rewritten as

Σ2 :

dxk
dt = gk

ε(t)xk(t) +

n

∑

(cid:96)=1

ω (cid:96)k
σ (t)x(cid:96)(t), k = 1, . . . ,n.

(5)

We postpone the detailed description of the delay process h
as well as the deﬁnition of the growth rates to Section IV.

III. GROWTH RATE WITH DELAYED PROLIFERATION
The aim of this section is to prove the following theorem,
which enables us to ﬁnd an upper bound of the growth rate
of Σ1:
i, j ∈
{1, . . . ,n} and t ≥ 0, deﬁne f (λ )
i )⊗u(cid:62)
j )
and g(λ )

Theorem 3.1: Let λ ∈ R be arbitrary. For all
i ((UjieΠ(cid:62)d j

i e−λ d j
j ). Let

i j (t) = q j

i j = p j
i (t)e−λt ((UjieΠ(cid:62)t )⊗ u(cid:62)
i j = ui ⊗ f (λ )
¯A(λ )
i j (t) = ui ⊗ g(λ )
¯B(λ )

,

Then, the growth rate of Σ1 is less than λ if the matrix

¯T (λ ) = ¯A0 − λ I +

n

∑

i, j=1

¯A(λ )
i j +

¯B(λ )
i j (t)dt

is Hurwitz stable.

Remark 3.2: We can use Theorem 3.1 and a bisection
search to ﬁnd the suboptimal upper bound on the growth
rates. We also remark that, when Σ1 has no delay,
the
sufﬁcient condition in Theorem 3.1 is also necessary by [14,
Theorem 5.1].

The rest of this section is devoted to the proof of The-
orem 3.1. We ﬁrst introduce a vectorial representation of
Σ1. For each i ∈ {1, . . . ,n}, deﬁne Gi = diag(g1
i , . . . ,gn
i ),
Ωi = [ωk(cid:96)
i , . . . ,qn
i ). Let
i

]k,(cid:96), Ai = Gi + Ω(cid:62)

i , and Qi = diag(q1

 , (Pix)(t) =

p1

x1

...
xn

x =

i x1(t − d1
i )

i xn(t − dn
pn
i )

...

 , φ =

 .

φ1

...
φn

i j
i j (t).
ˆ ∞

n

∑

i, j=1

0

We can then write Σ1 in a vector form as

Σ1 :

dx

dt = Aε(t)x(t) + (Pε(t)x)(t) + (Qε(t) ∗ x)(t)

with initial condition x|[−T,0] = φ. Let us also introduce the
vectorial representation η = {η(t)}t≥0 for the environmental
variable ε by ηi(t) = 1 if ε(t) = i and ηi(t) = 0 otherwise.
Notice that η(t) = uε(t).

In what follows,

instead of directly dealing with the
process x(t), we shall study the auxiliary processes given
by [14]

z(t) = η(t)⊗ x(t), ζ (t) = E[z(t)], t ≥ 0.

Notice that neither z(t) nor ζ (t) is deﬁned when t < 0
because η(t) is deﬁned only for t ≥ 0. The next lemma shows
that these auxiliary processes preserve the norm of x(t):
if x ∈ Rn is nonnegative,

Lemma 3.3: (cid:107)ζ (t)(cid:107) = E[(cid:107)x(t)(cid:107)] for every t ≥ 0.

then
n x. Therefore, since ζ (t) ≥ 0 and x(t) ≥ 0, we have
n2E[ζ (t)] = E[(1nη(t))(1nx(t))] = E[1nx(t)] =

Proof: Notice that,

(cid:107)x(cid:107) = 1(cid:62)
(cid:107)ζ (t)(cid:107) = 1(cid:62)
E[(cid:107)x(t)(cid:107)].

The following lemma plays an important role in the proof
Lemma 3.4: For all i ∈ {1, . . . ,n}, h ∈ [0,T ], and t ≥ T ,

of the main result:
we have E[ηi(t)x(t − h)] = ((u(cid:62)

i eΠ(cid:62)h)⊗ In)ζ (t − h).

Proof: Equation (3) shows that

E[ηi(t)x(t − h)] = E(cid:2)E[ηi(t)x(t − h) | η(t − h)](cid:3)
= E(cid:2)E[ηi(t) | η(t − h)]x(t − h)(cid:3).

(6)

Since ηi = u(cid:62)
η(t−h)] = u(cid:62)
the proof.

i η, we can show E[ηi(t)| η(t−h)] = E[u(cid:62)
i η(t)|
i eΠ(cid:62)hη(t−h). This equation and (6) completes

The next corollary easily follows from Lemma 3.4.
Corollary 3.5: Let

i, j ∈ {1, . . . ,n} and t ≥ T be ar-
i ((UjieΠ(cid:62)d j
j ) and gi j(t) =

fi j = p j
j ). Then, for all i and t, we have

bitrary. Deﬁne
i (t)((UjieΠ(cid:62)t )⊗ u(cid:62)
q j

i ) ⊗ u(cid:62)

fi jζ (t − d j
i ),

(7)

E[ηi(t)(Pix)(t)] =

E[ηi(t)(Qi ∗ x)(t)] =

n

∑

j=1
n

∑

j=1

(gi j ∗ ζ )(t).

Proof: From the deﬁnition of the operator Pi, we
can show that ηi(t)(Pix)(t) = ∑n
i ) =
i u ju(cid:62)
j=1 p j
∑n
i ). Taking the expectations in the
(cid:16)
both hand sides of this equation, from Lemma 3.4 we obtain
E[ηi(t)(Pix)(t)] =

i x j(t − d j
(cid:17)

j ηi(t)x(t − d j

j=1 u jηi(t)p j

i eΠ(cid:62)d j
(u(cid:62)

ζ (t − d j
i )

i )⊗ In

n

(cid:17)

(u ju(cid:62)

i eΠ(cid:62)d j

i )⊗ u(cid:62)
j

ζ (t − d j
i ),

where we used u ju(cid:62)
j and (1) to derive the last
equation. This equation proves (7). We can prove the other
equation in the same way and hence omit its proof.

∑

j=1
n

j

i u ju(cid:62)
p j
(cid:16)

j=1

p j
i

∑
j = u j ⊗ u(cid:62)

=

Using Corollary 3.5, we can then derive the dynamics of

Proposition 3.6: Deﬁne ¯A0 = Π(cid:62) ⊗ In +(cid:76)n

the variable ζ as follows:
¯Ai j =
ui ⊗ fi j, and ¯Bi j(t) = ui ⊗ gi j(t), for all i, j ∈ {1, . . . ,n} and
t ≥ T . Then, for every t ≥ T , we have

i=1 Ai,

dζ
dt = ¯A0ζ (t) +

n

∑

i, j=1

¯Ai jζ (t − d j

i ) +

( ¯Bi j ∗ ζ )(t).

n

∑

i, j=1

(8)

Proof: We ﬁrst derive a differential equation for the

extended state variable

(cid:20) x

(cid:21)

η

.

y =

For each i ∈ {1, . . . ,n}, deﬁne the operator Ai by
(Aix)(t) = Aix(t)+(Pix)(t)+(Qi∗x)(t). Then, Σ1 admits the
representation dx/dt = Aε(t)x. Therefore, from the deﬁnition
of the variables ηi, we can write Σ1 as

Σ1 :

dx
dt =

n

∑

i=1

ηi(Aix)(t).

(9)

Also, we know that η follows the stochastic differential
i=1 ∑ j(cid:54)=i(Uji − Uii)η dNi j, where Ni j
equation [20] dη = ∑n
denotes the Poisson counter of rate πi j for each distinct
(cid:21)
pair (i, j) ∈ {1, . . . ,N}2. This equation and (9) show that
i=1 ηi(Aix)

(cid:20)∑n

(cid:20)

(cid:21)

0

n

dy =

dt +

∑

i=1

∑
j(cid:54)=i

(Uji −Uii)η

dNi j.

0

Now, applying Lemma 1.2 to the function ψ(y) = η ⊗x =

(cid:20)∑n

(cid:21)
i=1 ηi(Aix)
(cid:18)
(cid:20)

n

0
∑
j(cid:54)=i

∑

i=1

ψ

y +

dt+

(cid:20)

z, we obtain

dz =

∂ z
∂ y

=

n

∑

i=1

(η ⊗ In)ηi(Aix)dt+

n

∑

i=1

∑
j(cid:54)=i

(cid:2)(cid:0)(Uji −Uii)η(cid:1)⊗ x(cid:3) dNi j,

where we used the identity ∂ψ/∂ y = [η ⊗In In⊗x] in the last
equation. Therefore, the expectation ζ obeys the differential
equation

dζ
dt =

n

∑

i=1

E[(η ⊗ In)ηi(Aix)]+

E(cid:2)(cid:0)(Uji −Uii)η(cid:1)⊗ x(cid:3)πi j.

(10)

n

∑

i=1

∑
j(cid:54)=i

Let us compute the expectations in the right hand side of
this equation. Since ηiη j = 0 for i (cid:54)= j and η2
i = ηi, we have
ηηi = ηiui. Therefore, it follows that (η ⊗In)ηi(Aix) = (ui⊗
Ai)ηix + (ui⊗In)ηi(Pix) + (ui⊗In)ηi(Qi∗ x). Hence, we can

(cid:21)(cid:19)

(cid:21)

− ψ(y)

dNi j

˜Σ1 :

where

0

(Uji −Uii)η

n

i=1

∑

(cid:18) n(cid:77)
(cid:18) n(cid:77)

i=1

i=1

=

Ai

compute the ﬁrst term in the right hand side of (10) as

E[(η ⊗ In)ηi(Aix)]
(cid:19)

n

=

Ai

ζ +

(ui ⊗ I)E[ηi(Pix)]+

∑

i=1

(cid:19)

ζ +

(ui ⊗ In)E[ηi(Qi ∗ x)]

n

∑

i=1

n

∑

i, j=1

¯Ai jζ (t − d j

i ) +

( ¯Bi j ∗ ζ )(t),

n

∑

i, j=1

where we used Corollary 3.5 for deriving the last identity.
On the other hand, it is shown in the proof of [14, Proposi-
tion 5.3] that the second term of the right hand side of (10)
equals (Π(cid:62) ⊗ In)ζ . This completes the proof.
We are now ready to prove Theorem 3.1:

Proof of Theorem 3.1: Let φ and ε(0) be arbitrary.
We ﬁrst consider the special case of λ = 0. Assume that
the matrix ¯T (0) is Hurwitz stable. Then, by Proposition 1.1,
the delayed positive linear system (8) is exponentially stable.
Notice that the equation (8) is deﬁned only for t ≥ T . By the
stability of the system (8), there exist C1 > 0 and ρ > 0 such
that

(cid:107)ζ (t)(cid:107) ≤ C1e−ρ(t−T )(cid:107)ζ|[0,T ](cid:107).

(11)
On the other hand, due to the linearity of the system Σ1,
there exists C2 > 0 such that (cid:107)x|[0,T ](cid:107) ≤ C2(cid:107)φ(cid:107). Using
this inequality, (11), and Lemma 3.3, we can show that
E[(cid:107)x(t)(cid:107)] ≤ C1C2e−ρ(t−T )(cid:107)φ(cid:107). This shows the exponential
stability of Σ1.
e−λtx(t) satisﬁes the stochastic differential equation

For the general case, observe that the variable ˜x(t) =

d ˜x

dt = (Aε(t) − λ I) ˜x(t) + (P (λ )

ε(t) ˜x)(t) + (Q(λ )

ε(t) ∗ ˜x)(t),

p1

i e−λ d1

i e−λ dn
pn

i ˜x(t − d1
i )
...
i ˜x(t − dn
i )

 , Q(λ )

i

(P (λ )

i

˜x)(t) =

(t) = e−λtQi(t),

for all i ∈ {1, . . . ,n} and t ≥ 0. Applying the above argument
on exponential stability to ˜Σ1, we can show that
˜Σ1 is
exponentially stable if ¯T (λ ) is Hurwitz stable. This completes
the proof of the theorem because ˜Σ1 is exponentially stable
if and only if the growth rate of Σ1 is less than λ .

IV. GROWTH RATE WITH DELAYED ADAPTATION

In this section, we study the population model Σ2 given
in (5) for the case of delayed adaptation. We show that
we can characterize the growth rate of the populations as
the maximum real eigenvalue of a Metzler matrix, under
the assumption that the delays are described by a class of
distributions called Coxian distributions. We focus on the
case n = 2 for simplicity of presentations.

We consider the situation where the population as a
whole updates its knowledge σ about the environment in
the following stochastic manner:

α1 /

2

1

α2 /

··· αs−1/
β1
β2

s

βs

Fig. 1. State transition diagram of the Coxian distribution describing the
response delay T12. 1 is the entering state and s + 1 is the absorbing state.

s + 1

1) When the environment changes from i

to j at a
time t0 such that σ (t0) = i, a random number Ti j is
independently drawn from a distribution Xi j.

2) If the environment ε remains to be j until the time

t0 + Ti j, then σ (t) becomes j at time t0 + Ti j.

3) If the value of ε changes before the time t0 + Ti j, then
we discard the number Ti j and go back to the ﬁrst step.
In other words, if we let t1 > t0 denote the next (minimum)
time at which ε changes, then we have

(cid:40)

σ (t) =

σ (t0),
ε(t+

t0 ≤ t ≤ min(t0 + Ti j,t1),
0 ), min(t0 + Ti j,t1) ≤ t < t1.

We call the distributions Xi j, or, the random times Ti j as the
response delays.

+ and β ∈ Rs

We allow the response delays to follow a general class of
distributions called Coxian distributions deﬁned as follows.
For α ∈ Rs−1
+, consider the time-homogeneous
Markov process having the state transition diagram in Fig. 1.
We say that a random variable follows the Coxian distri-
bution (see, e.g., [22]), denoted by C(α,β ),
is the
absorption time of the Markov process into state s+1 starting
from state 1. It is known that the set of Coxian distributions
is dense in the set of positive valued distributions [21]. More-
over, there are efﬁcient ﬁtting algorithms to approximate a
given arbitrary distribution by a Coxian distribution [22].
We can now formally state our assumptions on the response
delays:
+ and β ,δ ∈ Rs
+
such that T12 and T21 follow the Coxian distributions C(α,β )
and C(γ,δ ), respectively.

Assumption 4.1: There exist α,γ ∈ Rs−1

if it

Combining the Markovian dynamics of the environment
ε as well as the state transition diagrams for the response
delays T12 = C(α,β ) and T21 = C(γ,δ ), we can easily prove
the following proposition.

Proposition 4.2: Consider the time-homogeneous Markov

process θ having the state space
S = {(1,10), (2,11), . . . (2,1s), (2,20), (1,21), . . . , (1,2s)}
and the state transition diagram in Fig. 2. Assume that θ (0) =
(ε(0),ε(0)0). Deﬁne the function f : S → {1,2}×{1,2} by
f (i, jk) = (i, j) for all i, j ∈ {1,2} and k ∈ {0, . . . ,s}. Then,
f (θ ) = (ε,σ ).

From Proposition 4.2, we can represent

the popula-
tion dynamics Σ2 as dx/dt = A f (θ (t))x(t), where, for each
i, j ∈ {1,2}, the matrix A(i, j) is deﬁned by
ω21
j
i − ω21
g2

i − ω12
ω12
j

(cid:20)g1

A(i, j) =

(12)

(cid:21)

.

j

j

π21

π21

(1,10)

π21
π12

/(2,11)

α1 /

(2,12)

α2 /

··· αs−1/
/(2,1s)
β1
β2

βs

δs

δ2

(1,2s)

γs−1

δ1
···

(1,22)

γ1

γ2

(1,21)

π21
π12

/(2,20)

π12

π12

Fig. 2. Markov chain for the dynamics of the pair (ε,σ ). The thick arrows
represent the dynamics of phase-type distributions, while the thin arrows
represent changes in the environment.

We now present the second main result of this paper, which
gives the growth rate of Σ2:

Theorem 4.3: Deﬁne Ξ ∈ R(2s+2)×(2s+2) by

π12u(cid:62)

1

0
π211s Ξα − π21Is − diag(β ) β
−π21
Os,1
π121s Ξγ − diag(δ )− π12Is
δ

O1,s
Os,s
π21u(cid:62)
1

Os,s
O1,s

 ,

−π12
(cid:20)Os−1,1

Ξα =

0

Ξ =

where

(cid:21)

(cid:20)diag(α) Os−1,1

(cid:21)

O1,s−1

0

diag(α)
O1,s−1

−

and Ξγ is deﬁned in the same manner. Then, the growth rate
of Σ2 equals the maximum real eigenvalue of the matrix

(cid:77)
( ¯A(1,1),Is ⊗ ¯A(2,1), ¯A(2,2),Is ⊗ ¯A(1,1)).

(13)

It is easy to see that Ξ deﬁned in the theorem
gives the inﬁnitesimal generator of the Markov process θ.
Therefore, by [14, Theorem 5.2], the growth rate of Σ2 equals
the maximum real eigenvalue of the Metzler matrix

Ξ(cid:62) ⊗ I2 +
Proof:

(cid:77)

Ξ(cid:62) ⊗ I2 +

(A f (1,10),A f (2,11), . . . ,A f (2,1s),

A f (2,20),A f (1,21), . . . ,A f (1,2s)).

The direct sum in this matrix equals the second term of (13)
since A f (2,1k) = A(2,1) and A f (1,2k) = A(1,2) for all k by the
deﬁnition of the matrices A(i, j) in (12). This completes the
proof of the theorem.

V. NUMERICAL SIMULATIONS

In this section, we present numerical simulations to il-
lustrate the results obtained in the previous sections. For
simplicity of presentation, we focus on the case n = 2;
i.e., there are only two phenotypes in the population under
consideration. We use the parameters g1
1 = 0.05,
2 = −2, and g2
g1
2 = 0.95. These parameters indicate that the
phenotypes 1 and 2 are ﬁtted to the environment 1 and
2, respectively. We set the phenotypic transition rates as
ω12
1 = ω21

2 = 0.1 and ω21

1 = 1, g2

1 = ω12

2 = 1.

/
/
/
/
/
/
/
/
/
"
"
"
"
"
"
"
"
"
"
/
/
/
/
/
/
/
/
/










/
/
/
/
/
/
/
/
/










/
/
/
/
/
/
/
/
/
/
o
o
"
"
"
"
"
"
"
"
"
"
/
/
/
/
/
/
/
/
/
y
y










/
/
/
/
/
/
/
/










|
|
L
L
L
L
L
L
L
L
L
L
<
<
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
o
T
T
T
T
T
T
T
T
T
T
9
9
o
o
o
o
o
o
o
o
o
o
b
b
b
b
b
b
b
b
b
b
/
o
o
Fig. 3. Growth rates of Σ1. Solid: Upper bounds (Theorem 3.1). Dashed:
Sample averages of T−1 log((cid:107)x(T )(cid:107)/(cid:107)φ(cid:107)) with T = 50.

Fig. 4. Growth rate of Σ2 versus µ

i = d and pk

First, we illustrate Theorem 3.1 for the case of delayed
proliferation. We consider only point delays; therefore, it is
i (t) ≡ 0 for all i,k ∈ {1,2}. Furthermore, we
assumed that qk
assume that both the delays and the rate of delayed prolifer-
ation are homogeneous, that is, there exist d ≥ 0 and p ≥ 0
i = p for every i,k ∈ {1,2}. We set
such that dk
the initial state as φ (t) = [1 1](cid:62) for every t ∈ [−d,0]. Using
Theorem 3.1 and bisection search, we compute the subopti-
mal upper bounds on the growth rates of Σ1 for p = 2.5 and
d ∈ [0,5]. To examine the accuracy of the upper bounds, we
numerically compute the quantity 50−1 log(E[(cid:107)x(50)(cid:107)]/(cid:107)φ(cid:107))
using 500 sample paths for each pair of (d, p). The above two
quantities are shown in Fig 3. Their relative differences are
less than 10%, showing the accuracy of the upper bounds
by Theorem 3.1. We have also conﬁrmed that, as d → ∞
or p → 0, the upper bounds approach to the common value
0.6863, which equals the growth rate of the population model
Σ0 without delays.

We then focus on delayed adaptation studied in Section IV.
Assume that delays X12 and X21 both follow the Erlang
distribution with shape k and mean µ. This distribution is the
k-sum of independent exponential distributions with mean
µ/k and,
therefore, approximates the normal distribution
with mean µ and the variance µ2/k when k is large.
From this fact, we can also see that the Erlang distribu-
tion is a Coxian distribution having the parameters s = k,
α1 = ··· = αk−1 = βk = λ = k/µ, and β1 = ··· = βk−1 = 0.
Using Theorem 4.3, we compute the growth rate of Σ2 when
µ varies over the interval [0,10]. We have used k = 100 in
this simulation. We show the obtained growth rates in Fig. 4.
We have conﬁrmed the following limit phenomena. First, as
µ tends to zero, the growth rate approaches to that of the
population model Σ0 without delay. Second, as µ tends to ∞,
the growth rate approaches to that of the population model
without adaptation, as expected.

VI. CONCLUSION

In this paper, we have studied the growth rate of bet-
hedging populations experiencing delays and environmental
changes. By modeling the population dynamics using posi-
tive Markov jump linear systems with delays, we have shown

that the growth rates can be upper-bounded by the maximum
real eigenvalue of Metzler matrices. In particular, in the case
of adaptation delays, the upper bounds give the exact value
of the growth rates. We have conﬁrmed the effectiveness of
the proposed methods via numerical simulations.

REFERENCES

[1] E. Kussell and S. Leibler, “Phenotypic diversity, population growth,
and information in ﬂuctuating environments.” Science, vol. 309, pp.
2075–2078, 2005.

[2] M. Acar, J. T. Mettetal, and A. van Oudenaarden, “Stochastic switch-
ing as a survival strategy in ﬂuctuating environments.” Nature Genet-
ics, vol. 40, pp. 471–475, 2008.

[3] B.-E. Sæther and S. Engen, “The concept of ﬁtness in ﬂuctuating
environments,” Trends in Ecology & Evolution, vol. 30, pp. 273–281,
2015.

[4] J. Seger and H. J. Brockmann, “What is bet-hedging?” in Oxford
Surveys in Evolutionary Biology. Oxford University Press, 1987,
vol. 4, pp. 182–211.

[5] A. B. Oppenheim, O. Kobiler, J. Stavans, D. L. Court, and S. Adhya,
“Switches in bacteriophage lambda development,” Annual Review of
Genetics, vol. 39, pp. 409–429, 2005.

[6] J. R. Gremer and D. L. Venable, “Bet hedging in desert winter annual
plants: optimal germination strategies in a variable environment,”
Ecology Letters, vol. 17, pp. 380–387, 2014.

[7] M. W. van der Woude and A. J. Baumler, “Phase and antigenic
variation in bacteria,” Clinical Microbiology Reviews, vol. 17, pp. 581–
611, 2004.

[8] C. T. H. Baker, G. A. Bocharov, C. A. H. Paul, and F. A. Rihan,
“Modelling and analysis of time-lags in some basic patterns of cell
proliferation.” Journal of mathematical biology, vol. 37, pp. 341–71,
1998.

[9] M. P. H. Stumpf, Z. Laidlaw, and V. A. A. Jansen, “Herpes viruses
hedge their bets,” Proceedings of the National Academy of Sciences
USA, vol. 99, pp. 15 234–7, 2002.

[10] M. K. Belete and G. Bal´azsi, “Optimality and adaptation of phenotyp-
ically switching cells in ﬂuctuating environments,” Physical Review E,
vol. 92, p. 62716, 2015.

[11] J. M¨uller, B. Hense, T. Fuchs, M. Utz, and C. P¨otzsche, “Bet-hedging
in stochastically switching environments,” Journal of Theoretical
Biology, vol. 336, pp. 144–157, 2013.

[12] B. Ga´al, J. W. Pitchford, and A. J. Wood, “Exact results for the evo-
lution of stochastic switching in variable asymmetric environments.”
Genetics, vol. 184, pp. 1113–9, 2010.

[13] M. Thattai and A. Van Oudenaarden, “Stochastic gene expression in

ﬂuctuating environments,” Genetics, vol. 167, pp. 523–530, 2004.

[14] M. Ogura and C. F. Martin, “Stability analysis of positive semi-
Markovian jump linear systems with state resets,” SIAM Journal on
Control and Optimization, vol. 52, pp. 1809–1831, 2014.

[15] W. Qi and X. Gao, “L1 control for positive Markovian jump systems
with time-varying delays and partly known transition rates,” Circuits,
Systems, and Signal Processing, vol. 34, pp. 2711–2726, 2015.

d01234501234µ02468100.60.650.7[16] L. Jiao, H. Jianjun, L. Jie, and Z. Yan, “Stochastic stability and
stabilization for positive Markov jump systems with distributed time
delay and incomplete known transition rates,” in 27th Chinese Control
and Decision Conference, 2015, pp. 2389–2394.

[17] J. Brewer, “Kronecker products and matrix calculus in system theory,”
IEEE Transactions on Circuits and Systems, vol. 25, pp. 772–781,
1978.

[18] P. H. A. Ngoc, “Stability of positive differential systems with delay,”
IEEE Transactions on Automatic Control, vol. 58, pp. 203–209, 2013.
[19] V. S. Borkar, Probability Theory. Springer-Verlag New York, 1995.
[20] R. W. Brockett, “Stochastic Control,” 2009. [Online]. Available:

http://www.eeci-institute.eu/pdf/M015/RogersStochastic.pdf

[21] D. R. Cox, “A use of complex probabilities in the theory of stochastic
processes,” Mathematical Proceedings of the Cambridge Philosophical
Society, vol. 51, pp. 313–319, 1955.

[22] S. Asmussen, O. Nerman, and M. Olsson, “Fitting phase-type dis-
tributions via the EM algorithm,” Scandinavian Journal of Statistics,
vol. 23, pp. 419–441, 1996.

