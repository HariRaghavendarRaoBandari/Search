6
1
0
2

 
r
a

 

M
8
1

 
 
]

H
O
.
s
c
[
 
 

1
v
5
7
7
5
0

.

3
0
6
1
:
v
i
X
r
a

39

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph
Considering Mode Transition Delay

HANWOONG JUNG, Seoul National University
HYUNOK OH, Hanyang University
SOONHOI HA, Seoul National University

Synchronous Data Flow (SDF) model is widely used for specifying signal processing or streaming applica-
tions. Since modern embedded applications become more complex with dynamic behavior changes at run-
time, several extensions of the SDF model have been proposed to specify the dynamic behavior changes
while preserving static analyzability of the SDF model. They assume that an application has a ﬁnite num-
ber of behaviors (or modes) and each behavior (mode) is represented by an SDF graph. They are classiﬁed as
multi-mode dataﬂow models in this paper. While there exist several scheduling techniques for multi-mode
dataﬂow models, no one allows task migration between modes. By observing that the resource requirement
can be additionally reduced if task migration is allowed, we propose a multiprocessor scheduling technique
of a multi-mode dataﬂow graph considering task migration between modes. Based on a genetic algorithm,
the proposed technique schedules all SDF graphs in all modes simultaneously to minimize the resource
requirement. To satisfy the throughput constraint, the proposed technique calculates the actual through-
put requirement of each mode and the output buffer size for tolerating throughput jitter. We compare the
proposed technique with a method which analyzes SDF graphs in each execution mode separately and a
method that does not allow task migration for synthetic examples and three real applications: H.264 de-
coder, vocoder, and LTE receiver algorithms.

CCS Concepts: •Theory of computation → Streaming models; •Computer systems organization →
Embedded software;

Additional Key Words and Phrases: Synchronous dataﬂow, Multi-mode dataﬂow, Mode transition delay, Task
migration, Throughput requirement

ACM Reference Format:
Hanwoong Jung, Hyunok Oh, and Soonhoi Ha, 2016. Multiprocessor Scheduling of a Multi-mode Dataﬂow
Graph Considering Mode Transition Delay. ACM Trans. Embedd. Comput. Syst. 9, 4, Article 39 (March
2010), 21 pages.
DOI: 0000001.0000001

1. INTRODUCTION
Model-based design methodology is widely accepted for embedded system design since
it enables us to cope with ever increasing system complexity by maximizing the beneﬁt
of abstraction. As an algorithm speciﬁcation model, this paper adopts a coarse-grain
dataﬂow model which is suitable for specifying signal processing or streaming appli-
cations. In a dataﬂow graph, a node presents a function module and an arc represents

This research was supported by a grant to Bio-Mimetic Robot Research Center Funded by Defense Ac-
quisition Program Administration, and by Agency for Defense Development (UD130070ID), Basic Science
Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of
Science, ICT & Future Planning (NRF-2013R1A2A2A01067907, 2013R1A1A1013384), and IT R&D program
MKE/KEIT (No. 10041608, Embedded system Software for New-memory based Smart Device).
Author’s addresses: H. Jung and S. Ha, Department of Computer Science and Engineering, Seoul National
University; H. Oh, Department of Information System, Hanyang University;
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted
without fee provided that copies are not made or distributed for proﬁt or commercial advantage and that
copies bear this notice and the full citation on the ﬁrst page. Copyrights for components of this work owned
by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or repub-
lish, to post on servers or to redistribute to lists, requires prior speciﬁc permission and/or a fee. Request
permissions from permissions@acm.org.
c(cid:13) 2010 ACM. 1539-9087/2010/03-ART39 $15.00
DOI: 0000001.0000001

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:2

H. Jung et al.

the ﬂow of data samples (or tokens) through the FIFO channel between two end nodes.
When a node is invoked, it consumes a speciﬁed number of data samples (called sample
rate) from each input arc and produces a speciﬁed number of samples to each output
arc. A node becomes executable when all input arcs have as many data samples as
the speciﬁed sample rates. If the sample rate is a ﬁxed integer number which does not
change at run-time, the dataﬂow graph is called a synchronous dataﬂow (SDF) graph
[Lee and Messerschmitt 1987].

For a given multiprocessor system, we need to determine the mapping of nodes to
the processors and the execution order of mapped nodes on each processor. The static
sample rate in the SDF model allows us to make the mapping and scheduling de-
cision statically. From the static mapping and scheduling result for an SDF graph
on a multiprocessor, we can estimate the performance and the resource requirement,
which is very desirable for the design of embedded systems with tight real-time and
resource constraints. If the implemented system follows the pre-determined mapping
and execution order of nodes at run-time, the system can be claimed to be “correct by
construction”.

But the SDF model has a severe restriction to be used for modern embedded ap-
plications. It cannot express the dynamic behavior of an application, while modern
embedded applications become more complex with dynamic behavior changes at run-
time. For example, advanced video CODEC algorithms have several function modules
that are conditionally invoked depending on the contents of the input frame. In ad-
dition, an application may have multiple implementations of the same algorithm to
support various levels of quality of service.

SDF

To express such dynamic behavior of an application in the SDF model with keeping
the static analysis capability, several extensions have been proposed to the SDF model,
including FSM-based scenario-aware dataﬂow (FSM-SADF)
[Stuijk et al. 2011],
[Bhattacharya and Bhattacharyya 2001], MTM-
parameterized
SADF [Jung et al. 2014], mode-aware dataﬂow (MADF)
[Zhai 2015], and so on
[Girault et al. 1999] [Wiggers et al. 2008]. They all assume that an application has a
ﬁnite number of behaviors (or modes) and each behavior (mode) can be represented
by an SDF graph. We denote those MoCs (Models of Computation) as multi-mode
dataﬂow (MMDF) graphs in this paper and deﬁne a representative MMDF model that
can be implemented by any speciﬁc extension.

(PSDF)

Because an MMDF graph is composed of SDF graphs in multiple modes, the static
schedule of the SDF graph on each mode can be constructed to estimate the overall
performance and the resource requirement of the MMDF graph. Also, for more accu-
rate estimation, the mode transition delay during mode changes should be considered.
If the mode change occurs frequently and periodically, the mode transition delay will
seriously degrade the overall performance of the MMDF graph. While there exist sev-
eral techniques to schedule a multi-mode dataﬂow graph with considering the mode
transition delay, the existing approaches do not allow task migration between modes.
However, we observe that the resource requirement for a given throughput constraint
can be additionally reduced if task migration is allowed. Since task migration will
cause additional run-time overhead during mode transitions, we should take into ac-
count the effect task migration overhead on the throughput performance.

In this paper, we propose a multiprocessor scheduling technique of a multi-mode
dataﬂow graph considering the mode transition delay conservatively. Our schedul-
ing objective is to minimize the number of processors allowing task migration among
all modes, while satisfying the overall throughput constraint. Also, from the schedul-
ing result, we compute the output buffer size to tolerate the time ﬂuctuation of out-
put results. Experiment results show that the proposed scheduling approach provides
better solutions than the existing approaches which determine the mapping and the

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay 39:3

scheduling for graphs either each mode independently incurring task migration be-
tween modes, or all modes at the same time disallowing task migration.

The rest of this paper is organized as follows. The next section gives a motivational
example to clarify the problem addressed in this paper, and introduces the key idea
of the proposed technique. Section 3 reviews the related work. The problem addressed
in this paper will be deﬁned and formulated in Section 4. In Section 5 and 6, the
throughput requirement analysis technique and the proposed scheduling technique
considering the mode transition delay are explained in detail, respectively. In Section
7, we discuss our experimental results, and draw conclusions in Section 8.

2. MOTIVATIONAL EXAMPLE
2.1. Throughput Requirement Calculation Considering Mode Transition Delay

Actual throughput

1/throughput constraint

Streaming application

Playback buffer

Display

(a) Relation between the playback buffer and throughput

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:47)(cid:81)(cid:70)(cid:71)(cid:3)

(cid:86)(cid:84)(cid:67)(cid:80)(cid:85)(cid:75)(cid:86)(cid:75)(cid:81)(cid:80)(cid:3)

(cid:70)(cid:71)(cid:78)(cid:67)(cid:91)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:31)(cid:3)(cid:55)(cid:76)(cid:80)(cid:72)(cid:79)(cid:76)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:70)(cid:75)(cid:72)(cid:71)(cid:88)(cid:79)(cid:72)(cid:3)(cid:20)(cid:3)(cid:33)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1004)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:47)(cid:81)(cid:70)(cid:71)(cid:3)

(cid:86)(cid:84)(cid:67)(cid:80)(cid:85)(cid:75)(cid:86)(cid:75)(cid:81)(cid:80)(cid:3)

(cid:70)(cid:71)(cid:78)(cid:67)(cid:91)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1005)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:17)(cid:437)(cid:296)(cid:855)(cid:3)(cid:1006)

(cid:31)(cid:3)(cid:55)(cid:76)(cid:80)(cid:72)(cid:79)(cid:76)(cid:81)(cid:72)(cid:3)(cid:82)(cid:73)(cid:3)(cid:86)(cid:70)(cid:75)(cid:72)(cid:71)(cid:88)(cid:79)(cid:72)(cid:3)(cid:21)(cid:3)(cid:33)

(b) Throughput requirement considering the mode transition delay

(cid:100)(cid:346)(cid:396)(cid:381)(cid:437)(cid:336)(cid:346)(cid:393)(cid:437)(cid:410)(cid:3)
(cid:272)(cid:381)(cid:374)(cid:400)(cid:410)(cid:396)(cid:258)(cid:349)(cid:374)(cid:410)

(cid:4)(cid:272)(cid:410)(cid:437)(cid:258)(cid:367)(cid:3)

(cid:410)(cid:346)(cid:396)(cid:381)(cid:437)(cid:336)(cid:346)(cid:393)(cid:437)(cid:410)

(cid:100)(cid:346)(cid:396)(cid:381)(cid:437)(cid:336)(cid:346)(cid:393)(cid:437)(cid:410)(cid:3)
(cid:272)(cid:381)(cid:374)(cid:400)(cid:410)(cid:396)(cid:258)(cid:349)(cid:374)(cid:410)

(cid:4)(cid:272)(cid:410)(cid:437)(cid:258)(cid:367)(cid:3)

(cid:410)(cid:346)(cid:396)(cid:381)(cid:437)(cid:336)(cid:346)(cid:393)(cid:437)(cid:410)

Fig. 1. Motivational example of throughput requirement calculation considering the mode transition delay

To cope with ﬂuctuation of output intervals of streaming applications, an output
buffer is usually used to obtain the steady output stream in streaming applications
as depicted in Figure 1 (a). The system will require data from the output buffer peri-
odically and the period is deﬁned by the inverse of the throughput constraint. If the
throughput performance of an application is lower than the throughput constraint, the
output buffer will be eventually empty.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:4

H. Jung et al.

If a streaming application is speciﬁed in an MMDF graph, it can be scheduled at
compile-time to meet the given throughput constraint. To guarantee the throughput
constraint, not only throughput performance of each mode, but also the mode transi-
tion delay should be considered. Although a mapping/scheduling result of each SDF
graph keeps the throughput constraint, the average throughput performance can be
lower than the constraint because of additional time delay during mode transition.

Various factors have an effect on the mode transition delay. In [Stuijk et al. 2010]
and [Geilen et al. 2012], the system reconﬁguration overhead and DVFS delay are
considered as the mode transition delay. Also, [Zhai 2015] deﬁnes the mode transi-
tion delay to quantify the proposed transition protocols. Especially, it proposes a MOO
(Maximum-Overlap Offset) transition protocol which calculates an offset that guaran-
tees no interference between the execution of both old and new modes. When a mode
transition occurs, an application will be delayed until this offset, which should be con-
sidered in the throughput calculation. In addition to such rescheduling delay, we need
to consider the task migration overhead in the computation of mode transition delay.

Since the mode transition delay degrades the average throughput of an MMDF ap-
plication, the throughput constraint can be violated even if the throughput of each
mode is higher than the throughput constraint. Figure 1 (b) shows an example of two
different schedules for an MMDF graph. The MMDF graph consists of two different
modes, and there exists additional time delay during mode transition. As represented
by arrows on an upper line, the system dequeues data from the output buffer peri-
odically with the same rate as the throughput constraint. The arrows on a lower line
tell when an MMDF application enqueues data to the output buffer. A number anno-
tated on each arrow denotes the number of data in the output buffer after the access
is completed.

In case of schedule 1 in Figure 1 (b), even though the schedule of each mode satis-
ﬁes the throughput constraints, the throughput constraint is eventually violated since
the mode transition delay is accumulated. To avoid this problem, we need to set the
throughput constraint of each mode tighter than that of the application as schedule 2
illustrates in the ﬁgure; it keeps the throughput constraint because it ﬁlls the output
buffer faster than the throughput constraint. Therefore we need to calculate the actual
throughput requirement for each mode considering the mode transition delay, in order
not to violate the given constraint. Details will be discussed in Section 5.

2.2. Task Migration Between Mode Transition
Figure 2 (a) shows an MMDF graph example which consists of two modes: M1 and M2.
We assume that the throughput constraint of the MMDF graph is given as 1/35. Each
execution mode of an MMDF graph is represented with an SDF graph. The execution
time and sample rates of each node may vary depending on the execution mode. In
mode M1, the execution times of nodes A, B, C, and D are 17, 13, 14, and 16, respec-
tively and in mode M2, they are 12, 10, 8, and 10. The output sample rates of nodes B
and C are unity in mode M1 while they are 3 in mode M2. Refer to Section 4 for the
formal description of the MMDF model assumed in this paper. Also, in this section, we
only consider the task migration overhead as the mode transition delay to simply show
the effect of task migration during mode transition.

A naive approach to schedule an MMDF graph is to schedule an SDF graph in each
mode independently with multiple objectives of resource minimization and throughput
maximization. For example, for the given throughput constraint, we ﬁnd an optimal
mapping/scheduling result in each execution mode as shown in Figure 2 (b). Since it
does not consider mapping results in the other modes, a node may be mapped onto
different processors between modes. Therefore, the mapping result requires task mi-

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay 39:5

(1, 1)

B

{M1: 13, 
M2: 10}

(1, 3)

(1, 1)

(1, 1)

A

{M1: 17, 
M2: 12}

(1, 1)

D

{M1: 16, 
M2: 10}

Throughput constraint : 1/35

Task migration cost = 10
Mode repetition count = 5

C

(1, 1)

{M1: 14, 
M2: 8}

(1, 3)

(1, 1)

(a) An MMDF graph example

Throughput : 1/30

Throughput : 1/30

A

Proc 0

Proc 1

B
C

(M1)

D

Proc 0

Proc 1

A C
B

D
D D

(M2)MM2M )2

(b) Mapping/scheduling result when each SDF graph is scheduled independently

Throughput : 1/30

Proc 0

Proc 1

Proc 2

A

B
C

(M1)

D

A

B
C

Proc 0

Proc 1

Proc 2

Throughput : 1/30

D D D

(M2)

(c) Mapping/scheduling result considering all modes simultaneously disallowing task migration

Throughput : 1/30

Throughput : 1/32

Proc 0

Proc 1

A

B
C

(M1)

D

Proc 0

Proc 1

A B
C

D
D D

(M2)
(M( 2M
)2M )2

(d) Mapping/scheduling result considering all modes and task migration

Fig. 2. Motivational Example of Task Migration

gration when the mode changes. In Figure 2 (b), nodes B, C and D will be migrated to
other processors when the mode transition occurs.

Another approach to schedule an MMDF graph is to consider all modes simulta-
neously disallowing task migration [Stuijk et al. 2008] [Geilen and Stuijk 2010]. Since
the mapping is constrained in these approaches, the scheduling results generally re-
quire more processors than those that allow task migration. For instance, three proces-
sors are required to meet the given throughput constraint for the mapping/scheduling
result without task migration as shown in Figure 2 (c), while two processors are
enough for the scheduling result with task migration in Figure 2 (b). Since the objec-
tive of this paper is to minimize the resource requirement under a given throughput
constraint, the proposed approach allows task migration. Their approach is used as a
reference technique for comparison with the proposed technique in experiments.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:6

H. Jung et al.

Consider the former approach that allows task migration in Figure 2 (b). If the mode
transition occurs frequently and the task migration overhead is non-negligible, then
the given throughput constraint may not be satisﬁed. For instance, assume that the
mode transition occurs every 5 iterations and the task migration overhead of each
node is 10. In Figure 2 (b), 30 time unit is added every 5 iterations because nodes
B, C and D should be migrated for mode transition. Then, the output buffer will be
eventually empty, because the average throughput performance of the MMDF graph
becomes lower then the throughput constraint.

Therefore, in this paper, we propose another approach that schedules the SDF
graphs of all modes simultaneously allowing task migration among execution modes.
Figure 2 (d) shows a mapping and scheduling result produced by the proposed tech-
nique. It requires 2 processors and only 10 additional time units for task migration,
which may satisfy the throughput requirement with proper output buffering. Through-
put analysis considering task migration overhead will be discussed in Section 5.

3. RELATED WORK
As the related work to the proposed technique, we review several extensions of the SDF
model that have been proposed to express the dynamic behavior of an application.

One of the most representative multi-mode dataﬂow models is FSM-based SADF
(Scenario-Aware Data Flow) model [Stuijk et al. 2008], shortly FSM-SADF. In the
FSM-SADF model, an application consists of multiple scenarios (modes) and each
scenario is speciﬁed by an SDF graph. To specify multiple scenarios and their tran-
sitions, it deﬁnes a special control task called detector that has an FSM inside.
The detector task sends the control information to the normal computation tasks
that may change its behavior. For the FSM-SADF model, several techniques to
statically analyze the timing behavior such as worst case latency and throughput
[Geilen and Stuijk 2010] have been proposed. Also, a binding-aware scenario graph
[Stuijk et al. 2010] has been proposed to take into account the resource constraint.
And, in [Damavandpeyma et al. 2013], it considers reconﬁguration overhead for DVFS
(Dynamic Voltage Frequency Scaling) as the mode transition delay. However, it only
considers the worst-case performance analysis of the FSM-SADF graph for the given
task mapping, and requires inherently exponential time-complexity for exact analysis.
As a similar model to the FSM-SADF, an MTM-SADF [Jung et al. 2014] has been
proposed to specify application level dynamism based on an SDF. Instead of an FSM,
it uses a Mode Transition Machine (MTM) which is a simpliﬁed form of the FSM to
represent the mode transition. It proposes a hybrid task mapping technique with min-
imizing the overall energy consumption under the throughput constraints. However, it
analyzes each SDF graph independently.

PSDF (Parameterized Synchronous Data Flow) [Bhattacharya and Bhattacharyya 2001]

proposes a meta-modeling technique for run-time adaptation of parameters in a struc-
tured way. In the PSDF model, the dynamic behavior of a task is modeled by
parameters and the task behavior can change at the iteration boundary at run-time.
Since the PSDF becomes an SDF graph at each iteration, the PSDF can be regarded
as a multi-mode dataﬂow graph that may change modes every iteration.

MCDF (Mode-Controlled Data Flow) [Moreira 2012] is one of data ﬂow MoCs which
enables the expression of the data-dependent functional behavior. However, it mainly
focuses on SDR (Software-Deﬁned Radio) applications, where different sub-graphs
need to be active in different modes.

In VRDF (Variable-Rate Data Flow) [Wiggers et al. 2008] model, it allows vari-
able port rates within a speciﬁed range, and VPDF (Variable-rate Phase Data Flow)
[Wiggers et al. 2008] is proposed to combine characteristics of VRDF and CSDF where
each actor has a sequence of phases, and for every phase, the number of ﬁrings can be

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay 39:7

parameterized. For these MoCs, buffer size analysis technique is proposed to satisfy a
throughput constraint.

MADF (Mode-Aware Data Flow)

[Zhai 2015] has been proposed to support
hard real-time scheduling for multi-mode CSDF (Cyclo-Static Data Flow) model
[Bilsen et al. 1995]. It combines advantages of SADF and VPDF to specify application
level dynamism. Also, it proposes MOO (Maximum-Overlap Offset) mode transition
protocol to derive an efﬁcient analysis for a hard real-time scheduling of an MADF
graph. With this mode transition protocol, the timing behavior of individual modes
and during mode transitions can be analyzed independently.

BPDF (Boolean Parametric Data Flow) [Bebelis et al. 2013] supports change of port
rates and graph topology at run-time using integer and boolean parameters. In BPDF
model, integer parameters are used to change port rates at each iteration, and boolean
parameters are used for activation and deactivation of edges to change graph topology.
HDF (Heterogeneous Data Flow) (or *-chart) [Girault et al. 1999] supports multi-
mode applications through an FSM that executes an iteration of an SDF graph in each
state. So, an application is speciﬁed with a set of different SDF graphs combined with
an FSM.

While various analysis and scheduling techniques have been proposed for those
MoCs, no one considers task migration between modes. In [Lee et al. 2013], task mi-
gration is considered in the failure-aware task scheduling technique where an SDF
graph is scheduled multiple times with different number of processors allocated, aim-
ing to maximize the throughput with the allocated number of processors. When a
processor fails in the middle of execution, it changes the schedule that uses the re-
duced number of processors by one. Then task migration occurs between two different
schedules before and after processor failure. They try to minimize the migration cost
between two SDF schedules. This method is similar to the base method that will be
used for comparison in this paper: schedule each mode separately and ﬁnd the best
processor-to-processor mapping (or processor renaming) in order to minimize the mi-
gration cost.

In summary, to the best of our knowledge, this paper is the ﬁrst work which pro-
poses a multiprocessor scheduling technique of an MMDF graph allowing task migra-
tion between modes, and analyzes the throughput requirement considering the mode
transition delay.

4. PROBLEM DEFINITION
The MMDF model assumed in this paper is not a speciﬁc model but a generic model en-
compassing existing similar models such as FSM-SADF [Stuijk et al. 2008] and MTM-
SADF [Jung et al. 2014]. In those models, mode transition is speciﬁed by an FSM and
all modes are integrated into a single graph with varying conﬁguration parameters.
Figure 3 shows an MMDF graph example. We ﬁrst deﬁne the MMDF model and the
problem formally.

Application model: An MMDF graph is speciﬁed by a combination of a task graph

and a mode transition graph (M T G), or (T, C, D) × M T G, where

— M T G is speciﬁed by a tuple (M ode, T rans) where M ode is a ﬁnite set of modes
and T rans is a ﬁnite set of transitions. T rans is speciﬁed as follows: T rans =
{(cm, nm)|cm ∈ M ode, nm ∈ M ode} where cm denotes a current mode and nm de-
notes a next mode.

— T is a ﬁnite set of computational tasks. Each task t ∈ T has a set of ports Pt to
send/receive data to/from other adjacent tasks. Pt = IPt ∪ OPt where IPt is a set of
input ports and OPt is a set of output ports. For each port p ∈ Pt, it is assigned a ﬁxed

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:8

H. Jung et al.

(cid:17)

(cid:4)

(cid:24)

(cid:18)
(cid:100)(cid:258)(cid:400)(cid:364)(cid:3)(cid:336)(cid:396)(cid:258)(cid:393)(cid:346)

(cid:28)

(cid:38)

(cid:39)

(cid:1007)(cid:1004)
(cid:4)

(cid:17)
(cid:1006)(cid:1004)

(cid:1008)(cid:1004)
(cid:24)

(cid:28)
(cid:1007)(cid:1004)

(cid:1005)(cid:1005)(cid:1004)
(cid:39)

(cid:1005)(cid:1004)(cid:1004)
(cid:4)

(cid:68)(cid:381)(cid:282)(cid:286)(cid:3)(cid:1005)

(cid:4)
(cid:1007)(cid:1004)

(cid:1005)(cid:1005)(cid:1004)
(cid:18)

(cid:24)
(cid:1008)(cid:1004)

(cid:1007)(cid:1004)
(cid:38)

(cid:68)(cid:381)(cid:282)(cid:286)(cid:3)(cid:1007)

(cid:100)(cid:258)(cid:400)(cid:364)
(cid:68)(cid:18)(cid:894)(cid:410)(cid:895)

(cid:4)
(cid:1007)(cid:1004)

(cid:17)
(cid:1006)(cid:1004)

(cid:39)
(cid:1009)(cid:1004)

(cid:18)
(cid:1005)(cid:1004)

(cid:68)(cid:90)(cid:18)(cid:894)(cid:1005)(cid:895)
(cid:1089)(cid:1006)(cid:1009)
(cid:1005)

(cid:1007)(cid:1004)
(cid:1006)

(cid:1006)(cid:1004)

(cid:1007)

(cid:1008)

(cid:1005)(cid:1009)

(cid:68)(cid:100)(cid:39)

(cid:1008)(cid:1004)
(cid:24)

(cid:68)(cid:381)(cid:282)(cid:286)(cid:3)(cid:1006)

(cid:24)
(cid:1005)(cid:1004)(cid:1004)
(cid:68)(cid:381)(cid:282)(cid:286)(cid:3)(cid:1008)

(cid:1007)(cid:1004)
(cid:38)

(cid:28)
(cid:1007)(cid:1004)

(cid:17)
(cid:1007)(cid:1004)

(cid:1008)(cid:1004)
(cid:18)

(cid:1007)(cid:1004)
(cid:4)

(cid:24)
(cid:1009)(cid:1004)

(cid:28)
(cid:1008)(cid:1004)

(cid:38)
(cid:1007)(cid:1004)

(cid:1008)(cid:1004)
(cid:39)

(cid:39)
(cid:1008)(cid:1004)

(cid:39)
(cid:1008)(cid:1004)

Fig. 3. An MMDF graph example

rate, Rate(p, mode), in each execution mode. Thus the graph becomes an SDF graph
for each mode.

— C is a ﬁnite set of FIFO channels. A channel deﬁnes a one-to-one connection between

two end ports.

— D is a set of the number of initial tokens in all channels. dc(m) ∈ {0} ∪ N for ∀dc ∈ D

is the number of initially stored tokens in the channel c in mode m.

Architecture model: the target architecture consists of a set of processing ele-

ments.

— P E is a set of processing elements. For each p ∈ P E and m ∈ M ode, M ap(m, p) =

{t|t ∈ T where t is mapped onto a processor p in mode m}

Note that even though the proposed technique is applicable to heterogeneous multi-
processor systems, this paper assumes a homogeneous multiprocessor system for sim-
ple explanation and implementation.

To analyze the scheduling performance of an MMDF graph, we assume proﬁling

information is available as follows:

Proﬁling information

— Worst case execution time (W CET ) for each task t ∈ T and m ∈ M ode is given
as W CET (tm, p) for each processing element p ∈ P E of the target architecture. In
Figure 3, the W CET of a node is annotated in each mode. For example, W CET of
node A is 30 in modes 1, 3, and 4, and 100 in mode 2.

— For each m ∈ M ode, we are given a minimum number of iterations that the appli-
cation stays at the mode, which is denoted by M RC(m) where M RC stands for the
minimum repetition count. As M RC becomes smaller, the mode transition occurs

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay 39:9

more frequently. A mode is associated with an M RC value as shown in Figure 3
where M RC is 25, 30, 20 and 15 in modes 1, 2, 3, and 4, respectively.

— For each t ∈ T , task migration cost is given by M C(t). If the system is a distributed
memory system, the migration cost will include the time overhead of moving the code
and the context of a task between two processors. If it is a shared memory system,
the migration cost will be small as cold miss penalty for task execution. A table in
Figure 3 shows the M C value of each task. For instance, M C of node A is 30.

We assume that the mode transition of an MMDF graph occurs at the iteration
boundary of the SDF schedule associated with the current mode (cm). For each task
t ∈ T , after the mode transition to the next mode (nm), Rate(p, cm) of all Pt and
W CET (tcm) changes to Rate(p, nm) and W CET (tnm). And the SDF schedule associ-
ated with the next mode is followed.

With those application and architecture models and proﬁling information, the prob-

lem addressed in this paper is summarized as follows:

PROBLEM: Find a mapping and scheduling result of an MMDF graph which satis-

ﬁes the given throughput constraint

minimize. the number of required processors

subject to. the overall throughput performance of the MMDF graph should be

higher than the given throughput constraint.

The proposed MMDF scheduling framework is based on a genetic algorithm. So, it
needs to evaluate all candidate solutions in every iterations. How to evaluate whether
a given mapping and scheduling result of an MMDF graph satisﬁes the given through-
put constraint will be explained in the next section.

5. THROUGHPUT REQUIREMENT ANALYSIS

(cid:37)(cid:87)(cid:84)(cid:84)(cid:71)(cid:80)(cid:86)(cid:3)(cid:79)(cid:81)(cid:70)(cid:71)(cid:10)(cid:69)(cid:79)(cid:11)

(cid:54)(cid:84)(cid:67)(cid:80)(cid:85)(cid:38)(cid:71)(cid:78)(cid:67)(cid:91)(cid:10)(cid:69)(cid:79)(cid:14)(cid:3)(cid:80)(cid:79)(cid:11)

(cid:48)(cid:71)(cid:90)(cid:86)(cid:3)(cid:79)(cid:81)(cid:70)(cid:71)(cid:10)(cid:80)(cid:79)(cid:11)

(cid:5)(cid:19)(cid:3)

(cid:5)(cid:20)

(cid:35)

(cid:36)

(cid:35)

(cid:37) (cid:38)

(cid:36)

(cid:37)

(cid:35)

(cid:38)

(cid:5)(cid:21)

(cid:36)

(cid:5)(cid:19)

(cid:5)(cid:20)

(cid:35) (cid:37) (cid:38)

(cid:35) (cid:37) (cid:38)

(cid:37) (cid:38)

(cid:38) (cid:38) (cid:38)

(cid:38) (cid:38) (cid:38)

(cid:43)(cid:80)(cid:75)(cid:86)(cid:75)(cid:67)(cid:86)(cid:75)(cid:81)(cid:80)(cid:3)(cid:43)(cid:80)(cid:86)(cid:71)(cid:84)(cid:88)(cid:67)(cid:78)(cid:10)(cid:69)(cid:79)(cid:11)

(cid:47)(cid:75)(cid:73)(cid:37)(cid:81)(cid:85)(cid:86)(cid:10)(cid:69)(cid:79)(cid:14)(cid:3)(cid:80)(cid:79)(cid:11)

(cid:46)(cid:67)(cid:86)(cid:71)(cid:80)(cid:69)(cid:91)(cid:10)(cid:80)(cid:79)(cid:11)

(cid:43)(cid:80)(cid:75)(cid:86)(cid:75)(cid:67)(cid:86)(cid:75)(cid:81)(cid:80)(cid:3)(cid:43)(cid:80)(cid:86)(cid:71)(cid:84)(cid:88)(cid:67)(cid:78)(cid:10)(cid:80)(cid:79)(cid:11)

Fig. 4. Mode transition delay

In this section, we explain how to compute the throughput of an MMDF graph con-
sidering the mode transition delay with a given static scheduling results of modes. For
simple coordination of task migration and conservative estimation of the mode transi-
tion overhead, we assume that mode transition and task migration is performed in a
blocking fashion. In the blocking scheme, the task schedule is blocked at the mode tran-
sition boundary. Task migration is initiated after all tasks in the current mode ﬁnish
and the next mode starts after task migration is completed. During mode transitions,

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:10

H. Jung et al.

no task is executed. Note that the throughput may be degraded due to the blocking
even if there is no task migration when a mode transition occurs.

Figure 4 shows a mode transition scenario. It is assumed that a mode changes af-
ter the end of iteration 3 in the current mode cm. Task A at iteration 1 in next mode
nm can start after task D is completed at iteration 3 in mode cm and task migration
is completed although a processor is available to execute task A earlier. In the block-
ing scheme of task migration, the mode transition delay consists of two terms: task
migration delay and block scheduling effect.

Deﬁnition 5.1 (Mode Transition Delay).

∀(cm, nm) ∈ T rans, T ransDelay(cm, nm) = M igCost(cm, nm) + Latency(nm)
−InitiationInterval(nm)

where M igCost(cm, nm) represents the task migration delay between current mode
cm and next mode nm, Latency(nm) denotes the latency between the earliest start time
of a task and the latest ﬁnish time of a task in mode nm, and InitiationInterval(nm)
is the start time interval between two consecutive iterations in mode nm. Note that
InitiationInterval(nm) is equal to the time interval between two consecutive output
samples in a streaming application without mode transition. The inverse of the initia-
tion interval denotes the throughput performance if no mode transition occurs.

5.1. Buffer Size Determination
As discussed in Section 2.1, an output buffer is adopted to produce data samples pe-
riodically. Since the mode transition delay causes the jitter of output production in
an MMDF application, the output buffer should be large enough to provide the data
samples during mode transitions. The required output buffer size depends on the max-
imum mode transition delay and the throughput difference between the input stream
and the output stream in the buffer.

To determine the buffer size, we compute the arrival curves of the input and the
output streams in the buffer. The arrival curve of a stream informs the number of
arriving (or departing) samples (y-axis) within a time interval (x-axis) as shown in
Figure 5 [Thiele et al. 2000]. For conservative estimation, we utilize the maximum ar-
rival curve for the output stream and the minimum arrival curve for the input stream.
In Figure 1 (a), task Display dequeues data from the output buffer periodically with
satisfying the throughput constraint, which is depicted as the output curve (gray solid
line) in Figure 5. The black solid line represents the minimum arrival curve of the in-
put stream which presents the number of generated samples to the output buffer. The
buffer size is computed based on the minimum repetition count (M RC), the inverse of
the throughput, and the maximum mode transition delay among all possible transition
scenarios to the mode. In each mode, we compute the buffer size and then choose the
maximum buffer size in all modes.

The maximum mode transition delay to mode m is computed as following:

Deﬁnition 5.2 (Worst-case Mode Transition Delay to mode m).

M axT ransDelay(m) = max

∀(cm,nm)
∈T rans,
nm=m

T ransDelay(cm, nm)

Note that since the slope of the curve depends on the mode transition delay, the mode
repetition count, and the throughput performance of the MMDF schedule, the buffer
size is determined after constructing an MMDF schedule meeting the throughput con-
straints in all modes.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:11

# of in/out data

Required output 

buffer size

1/throughput 

constraint

Output 
curve

Input 
curve

1/throughput

Mode transition delay

Mode transition

Execution

Mode transition

Execution

(cid:749)t

Fig. 5. Arrival curves for input and the output streams in the output buffer

From the arrival curves, we obtain the minimum output buffer size which is the
maximum difference between the curves in every time interval (∆t). If the overall
throughput constraint is satisﬁed, the output buffer size is computed as following.

THEOREM 5.3 (OUTPUT BUFFER SIZE). The minimum size of the output buffer to

satisfy the overall throughput constraint is decided by the following equation:

Output buf f er size = ⌈M axIntervaloverall × T hrConst⌉

where M axIntervaloverall = max

∀(cm,nm)

∈T rans

T ransDelay(cm, nm) + InitiationInterval(nm)

PROOF. The buffer size is determined by the maximum distance between the input
and the output curves, which is illustrated in Figure 5. It is evident that the maximum
distance between two curves occurs during the ﬁrst period of the input curve since the
tangential slope of the input curve cannot be smaller than that of the output curve.
Then the maximum distance is obtained just before the ﬁrst jump of the input curve.
Therefore,

Output buf f er size = ⌈M axIntervaloverall ÷

1

T hrConst

⌉

= ⌈M axIntervaloverall × T hrConst⌉

5.2. Throughput Requirement Analysis
As discussed above, the throughput requirement at the next iteration depends on the
mode transition delay and the minimum repetition counts of the mode. For conserva-

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:12

H. Jung et al.

tive estimation, the input curve should be steeper than the output curve in all modes.
The throughput requirement in each mode can be formulated as follows:

THEOREM 5.4 (THROUGHPUT REQUIREMENT). The throughput requirement

in

mode m denoted as ThrRequire(m), is formulated as following:

T hrRequire(m) =

T hrConst × M RC(m)

M RC(m) − (M axT ransDelay(m) × T hrConst)

PROOF.

T he slope of input curve =

M axT ransDelay(m) + 1/T hrRequire(m) × M RC(m)

M RC(m)

And the slope of output curve =

1

1/T hrConst

= T hrConst

Since the slope of input curve should be steeper than the output curve,

M axT ransDelay(m) + 1/T hrRequire(m) × M RC(m)

M RC(m)

≥ T hrConst

and T hrRequire(m) ≥

M RC(m)

M RC(m)/T hrConst − M axT ransDelay(m)

If the throughput requirement calculated by Theorem 5.4 is not higher than the
throughput in each mode for every MMDF graph, there is a task mapping/scheduling
result which satisﬁes the throughput constraint considering the mode transition delay.

6. PROPOSED MMDF SCHEDULING FRAMEWORK
For MMDF scheduling problem, we adopt a genetic algorithm. The overall GA proce-
dure of the proposed framework is shown in Figure 6.

6.1. GA Conﬁguration
Initialization & Selection: Since a task (or node) can be mapped to different proces-
sors in modes, each task is regarded as a unit of mapping in each mode. The chromo-
some for GA is conﬁgured as shown in Figure 7. A chromosome is a set of mapping
for each execution mode. Each gene of the chromosome represents to which processor
a task in each execution mode is mapped. Chromosomes of initial population are ran-
domly generated and selected for crossover and mutation. The number of selection is
a conﬁgurable parameter of the GA framework.

Local optimization: In order to help the convergence of evolutionary process, a
local optimization step is performed before the evaluation step. For local optimization,
we devise a processor renaming heuristic that changes the processor id in each mode
to reduce the migration cost. The details will be explained later.

Evaluation & Replacement: In this step, we apply a list scheduling heuristic to
ﬁnd a static task schedule in each mode, based on the mapping information given by
each chromosome. Once we construct a static schedule, we evaluate the ﬁtness value
of each offspring and check whether the throughput constraint is satisﬁed or not. The
ﬁtness function will be described in the next section. Chromosomes in the population
are sorted by their ﬁtness values and poor chromosomes are eliminated.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:13

MMDF graph

Architecture/Profile 

information

Throughput 
constraint

Chromosomes in the population are randomly initialized

GA initialization

Chromosomes are selected based on fitness values 

Selection

Offsprings are generated by N-point crossover and mutation

Crossover and Mutation

Local optimization

Processor renaming heuristic

Evaluation and Replacement

Offsprings are evaluated and sorted by SPEA-2 algorithm  to the population 

Finalize and Report

Get pareto solutions in the population

Fig. 6. The overall GA framework

Mapping for mode 0

Mapping for mode N

P0

P1

P2

P1

...

P1

P2

P2

P0

Fig. 7. Chromosome structure

6.2. Fitness Function
The objective of the MMDF scheduling is to minimize the number of processors. The
required number of processors is deﬁned as the maximum number of processors in all
modes.

Deﬁnition 6.1 (The Number of Processors for an MMDF Graph).

T he number of processor = max

m∈M ode

|P rocm|

where P rocm = {p ∈ P E | M ap(m, p) 6= ∅}

Since the large mode transition delay will degrade the throughput performance and
more processors are likely to be required to meet the given throughput constraint,
the mode transition delay including task migration overhead is considered to evaluate
the number of required processors. And, the GA framework also aims to minimize the
overall task migration cost as the secondary objective. The reduction of task migration
will save energy consumption of the system, and reduce the network trafﬁc in an NOC
architecture. Therefore it is very desirable to reduce the total task migration cost (or
delay) in an MMDF graph considering all mode transition scenarios; the total task
migration cost of an MMDF graph is deﬁned as follows:

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:14

H. Jung et al.

Deﬁnition 6.2 (Total Task Migration Cost).

M igCosttotal = X

M igCost(cm, nm)

(cm,nm)∈T rans
where M igCost(cm, nm) = X
p∈P E

X

M C(t)

t∈{M ap(nm,p)
−M ap(cm,p)}

We sum up the migration cost of all possible migration scenarios that are deﬁned
by the M T G. For each transition in the M T G, we accumulate the migration cost of all
tasks that are mapped to different processors after the mode transition.

6.3. Local Optimization Technique

PE0

A

B

PE1

PE2

F

E

D

C

PE0

PE1

PE2

A

C

B

F

E

D

(a) Mapping in mode 0

(b) Mapping in mode 1

Fig. 8. Without processor renaming, every task should be migrated when mode transition occurs. If P E0 in
mode 0 is renamed to P E2 in mode 1, P E1 to P E0, and P E2 to P E1, no task migration is required

Figure 8 shows a motivational example for local optimization, where two modes have
different task mappings deﬁned in the chromosome and a mode transition from mode
0 to mode 1 occurs. In the mapping result, all tasks should be migrated. However, since
this paper assumes a homogeneous multiprocessor system, it is possible to rename the
processor id in each mode, which is called processor renaming. If P E0 in mode 0 is
renamed to P E2 in mode 1 then tasks A and B do not need to be migrated. Similarly, if
P E1 in mode 0 is renamed to P E0 in mode 1, and P E2 to P E1 then no task migration
is required. Without the processor renaming technique, good solutions such as Figure 8
will be evaluated as poor solutions due to high migration delay, which seriously hinders
the convergence of GA.

The time complexity of the processor renaming algorithm is given as P M where P
denotes the number of processors and M is the number of mode transition scenarios.
Therefore, we devise a simple greedy processor renaming heuristic as shown in Algo-
rithm 1 to reduce the time complexity. In the proposed heuristic, the time complexity
becomes O(P 2 × M ). Note that processor renaming is only applicable for homogeneous
processor systems.

The heuristic measures the similarity between processors. The similarity between

processors is deﬁned by how many tasks are mapped on both processors in common.

Deﬁnition 6.3 (Similarity between processors).

F or(cm, nm) ∈ T rans, Similarity(pi, pj) = |M ap(cm, pi) ∩ M ap(nm, pj)|

For each mode transition, processors in the next mode are renamed to the processors
in the current mode with the maximum similarity. Even though the proposed heuristic
does not consider all possible processor renaming scenarios and does not provide the

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:15

ALGORITHM 1: Processor Renaming Heuristic

for all mode transition scenarios do

curr ← mapping information of src mode of the transition;
next ← mapping information of dst mode of the transition;
for all mapping information of each processor (cId) in curr do

for all mapping information of each processor (nId) in next do

similarity ← check similarity between curr[cId] & next[nId];
if (similarity ≥ maxSimilarity) then

maxSimilarity ← similarity;
swapProcId ← nId;

end

end
change mapping of next between cId & swapProcId;

end

end

optimal renaming result, it reduces the time complexity signiﬁcantly while generating
good quality solutions as conﬁrmed by experimental results.

7. EXPERIMENTAL RESULTS
To prove the viability of the proposed framework, we experiment with four synthetic
examples and three real applications: H.264 decoder, vocoder [Zhai 2015] and LTE
receiver [Siyoum et al. 2011] algorithms as shown in Figure 9. All experiments have
been performed on Intel Core i7-4790K 4.00GHz machine with 8GB main memory.
Internal parameters of the GA framework are set as shown in Table I. µ and λ denote
the number of parents and offspring.

Table I. Conﬁguration of the GA framework

Population size
µ and λ
Probabilities of crossover/mutation
Maximum generations

100
100
0.9
30000

7.1. MMDF Scheduling Technique
We compare the proposed technique with two different heuristics. The ﬁrst heuristic
schedules SDF graphs independently and performs the processor renaming heuris-
tic. We denote this technique as Base. The Base technique is an iterative algorithm.
First, for each mode, it constructs pareto-optimal solutions which are optimized with
throughput and the number of processors using a genetic algorithm. Then it selects a
initial schedule which satisﬁes the throughput constraint with the minimum number
of processors for each mode. Based on the mapping/scheduling results, it performs the
processor renaming heuristic and adjusts the throughput requirement as discussed
in the previous section, considering the mode transition delay incurred by the initial
schedules. If a schedule does not satisfy the calculated throughput requirement, it is
replaced with another schedule which uses one more processor. Unless all scheduling
results satisfy the new adjusted throughput requirement in all modes, it repeats the
mapping/scheduling with the new adjusted throughput requirement until the map-
ping/scheduling results satisfy the adjusted throughput requirement.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:16

H. Jung et al.

(20, 30, -, -)
B

(40, 40, 
40, 100)

(30, -, -, 30)

A
(30, 100,
30, 30)

D

C

(-, -, 110, 40)

(-, 30, 30, -)

E

F

1

3

G

(110, 40, 
50, 40)

2

4

(130, 30, -)

(140, 40, -)

(120, 40, -)

(30, 50, 100)

A

B

C

E

(40, -, 120)

H

I

(110, 50, 30)

1

K

F

G

(30, -, 140)

J

2

3

Example 1

(120, 30, 140)

(30, 50, -)

(-, 30, 30)

(150, 50, 150)

D

G

I

K M

(50, 140, 140)

F

(30, 40, 140)

(30, 20, 30)

(-, -, 30)

(140, 130, 50)

(100, 100

,90)

O

1

(100, 50, 

100)

A

B

C

E

(140, 150, 30)

(40, -, 20)

H

J

L

N

(40, 30, 40)

(40, 130, 40)

Example 3

(30, -, 120)

D
(-, 120, 30)

2

3

(-, 40, 140)

(-, 30, 130)

Example 2

(20)

A

(35)

B

C
(40)

Mode 6, 9

(30, -)

D

1

…

2

11

Example 4

(3704)

(16775, 35121,
71337, 144531)

(1024, 2240,
4800, 9600)

(5760, 11712,
23424, 73984)

(22976, 44224,
89152, 150144)

ReadWave

2

2

DFT

2

1

AddCos

1

1

Win

Rec2Polar

1

1

Unwrap

S8

S16

WriteWave

2

2

InvDFT

2

1

Polar2Rec

1

1

(3660)

(236, 644,
988, 3630)

(192, 16640,
32448, 67584)

Vocoder

1

1

Male2
female

(69952, 8832,
13440, 27264)

1

1

1

1

Spec2Env

S32

S64

(458752, 74432,
89088, 108544)

(343, 341)

ReadFileH

Decode

(4872, 1345)

(2224, 2931)

InterPredY

(559, 568)

InterPredU

(554, 562)

InterPredV

(1916, -)

IntraPredY

(336, -)

IntraPredU

(340, -)

IntraPredV

1

1

1

(1430, 504)

Deblock

I

P

WriteFileH

(1051, 1055)

(71)

src

(60)

mem dem

(2)

5

1

3

2

4

Rate: 1, 1, 13, 12, 11

6

(16)

est

mimo

dmp

dec

(33)

(50)

(192, 192, 970,
895, 820)

1

adp

(8)

cqi

(70)

md

(5)

H.264 decoder

LTE receiver

Fig. 9. MMDF graph examples used in experiments

The second approach ﬁxes task mapping in all modes disallowing task migration as
the existing approaches usually assume. This technique is denoted as Fixed. The Fixed
technique is implemented in the same GA framework as the proposed framework with
disallowing task migration only.

Each MMDF graph consists of a task graph and the associated MTG. For all graphs
in Figure 9 exclude the vocoder application, Rate(p, mode) for each port p ∈ Pt is one
except the input port of node dec in the LTE receiver application. For the vocoder ap-
plication, port rates are ﬁxed among all modes and speciﬁed in the ﬁgure. For the task
graph of vocoder application in [Zhai 2015], we reduce the number of invocations for
speciﬁc tasks (from AddCosWin to Polar2Rec) from 128 to 2 by clustering, so the given

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:17

WCETs of those tasks in [Zhai 2015] are multiplied by 64. Also, we allow that each in-
stance of the same node can be mapped onto different processors for data parallelism.
The numbers above or under the tasks in Figure 9 indicate the W CET (tm) in each
mode. In case that the W CET (tm) of a task is constant in all modes, a single number
is denoted. For synthetic examples, the WCET of each task is set to an arbitrary value,
and the WCET of each task in the H.264 decoder application is set to proﬁled data with
us unit. Also, the WCET of each task in the vocoder and LTE receiver applications is
set to a value given in [Zhai 2015] and [Siyoum et al. 2011].

Table II. Conﬁgurations for experiments

Example 1

Example 2

Example 3

Example 4

Vocoder

M RC(m)

T hrConst

∀m ∈ M ode, M RC(m) = 5

1/150 iteration/time-unit

∀m ∈ M ode, M RC(m) = 5

∀m ∈ M ode, M RC(m) = 5

1/260 iteration/time-unit
1/330 iteration/time-unit

∀m ∈ M ode, M RC(m) = 5

1/80 iteration/time-unit

∀m ∈ M ode, M RC(m) = 5

1/500000 iteration/cycle

H.264 decoder

M RC(I) = 1, M RC(P ) = 5

1/12500 iteration/us (80 fps)

LTE receiver

∀m ∈ M ode, M RC(m) = 5

1/1800 sub-frames/time-unit

For all conﬁgurations in Table II, we compare the following three techniques: Base,
Fixed, and Proposed. We assume that the minimum repetition count (M RC) for all
modes in each example is set to 5 except the H.264 decoder application, since the mode
transition pattern of the H.264 decoder is known and ﬁxed (eg. I-P-P-P-P-P-I-P-P-P-...).
Throughput constraints are set arbitrarily with considering the WCET of tasks.

Figure 10 shows the experimental results for all applications. The y-axis indicates
the number of required processors and the x-axis presents migration cost (M C(t)). To
show the viability of the proposed framework, we examine how the mode transition
delay takes effect on the number of processors. For each example, we vary the task
migration cost or M C(t) using four different values. In the synthetic examples and
the vocoder/LTE receiver applications, the task migration cost is ﬁxed as M C(t) for
all tasks. In H.264 decoder applications, however, M C(t) is scaled based on the actual
task code size for all t ∈ T : the task migration cost of a task is computed as the product
of M C(t) values in x-axis and its task code size.

The results show that the Proposed method requires no more processors than Base
and Fixed approaches. The Fixed approach requires more processors in most cases
than Base and Proposed approaches. Since the Fixed approach does not allow task mi-
gration, the number of required processors to meet the given throughput constraint is
independent of the task migration cost. Since the mode transition delay is determined
by not only the task migration delay but also the latency in the blocking scheme of
task migration, when M C(t) is small, the mode transition delay is mostly dependent
on the latency. Therefore, the Base approach shows the similar results to the Proposed
approach for small migration costs. However, as M C(t) increases, the Base approach
requires more processors than the Proposed approach or could not ﬁnd a feasible solu-
tion for large M C(t) values in cases which are highlighted with a green box in Figure
10.

In the H.264 decoder application, there exists a dominant mode in which all tasks in
an MMDF graph are executed. Since the dominant mode creates a critical path in all
modes, if a mapping and scheduling result satisﬁes the throughput constraint in the
dominant mode then results in the other modes automatically satisfy the throughput

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:18

H. Jung et al.

EXAMPLE 1

EXAMPLE 2

6

4

2

0

10

8

6

4

2

0

8

6

4

2

0

MC=1 MC=10 MC=50 MC=100

MC=1

MC=10 MC=50 MC=100

(unit: time-unit)

(unit: time-unit)

EXAMPLE 3

EXAMPLE 4

5

4

3

2

1

0

MC=1 MC=10 MC=50 MC=100
(unit: time-unit)

MC=1

MC=10 MC=50 MC=100
(unit: time-unit)

VOCODER

H.264 DECODER

LTE RECEIVER

6

4

2

0

MC=10 MC=50 MC=100 MC=500

(unit: x 1000 cycles)

3

2

1

0

(cid:58)

6

4

2

0

MC=1 MC=10 MC=50 MC=100
(unit: us)

MC=10 MC=100 MC=500 MC=1000
(unit: time-unit)

Base

Fixed

Proposed

Fig. 10. Comparison results in terms of the number of processors: Base, Fixed and Proposed

constraint. Hence, no task migration is required and Fixed and Proposed approaches
produce the same results for the application.

Table III. Experimental results of Proposed in case of M C(t) = 10

maxm∈M ode

minm∈M ode

Output

M axT ransDelay(m)

T hrRequire(m)

buf f er size

Example 1

Example 2

Example 3

Example 4

Vocoder

150 time-unit
380 time-unit
640 time-unit
70 time-unit
280373 cycles

H.264 decoder

746 us

LTE receiver

980 time-unit

1/120
1/184
1/202
1/66

1/443925
1/12350.8

1/1604

2
3
3
2
2
1
2

M igCosttotal

20 time-unit
20 time-unit
60 time-unit
50 time-unit
150000 cycles

0 time-unit
30 time-unit

Table III presents the detailed experimental results from the Proposed approach in
Figure 10 when M C(t) = 10 for instance. The table informs that the throughput which
an application should satisfy becomes tighter than the given throughput constraint
in Table II due to the mode transition delay. The table also presents the total task
migration cost and the required output buffer sizes for benchmark applications.

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:19

7.2. Scalability of the Proposed Framework

(cid:18)(cid:381)(cid:374)(cid:448)(cid:286)(cid:396)(cid:336)(cid:286)(cid:374)(cid:272)(cid:286) (cid:410)(cid:349)(cid:373)(cid:286)(cid:3)(cid:894)(cid:400)(cid:286)(cid:272)(cid:895)

(cid:1012)(cid:1004)(cid:1004)(cid:1004)

(cid:1010)(cid:1004)(cid:1004)(cid:1004)

(cid:1008)(cid:1004)(cid:1004)(cid:1004)

(cid:1006)(cid:1004)(cid:1004)(cid:1004)

(cid:1004)

(cid:68)(cid:381)(cid:282)(cid:286)

(cid:894)(cid:951) (cid:381)(cid:296)(cid:3)(cid:374)(cid:381)(cid:282)(cid:286)(cid:400)(cid:3)(cid:1089)(cid:3)(cid:1005)(cid:1009)(cid:895)

(cid:69)(cid:381)(cid:282)(cid:286)

(cid:894)(cid:951)(cid:3)(cid:381)(cid:296)(cid:3)(cid:373)(cid:381)(cid:282)(cid:286)(cid:400)(cid:3)(cid:1089)(cid:3)(cid:1009)(cid:895)

(cid:1007)

(cid:1009)

(cid:1010)

(cid:1005)(cid:1004)

(cid:1013)

(cid:1005)(cid:1009)

(cid:1005)(cid:1006)

(cid:1006)(cid:1004)

Fig. 11. Experimental result for the scalability property

(cid:68)(cid:381)(cid:282)(cid:286)
(cid:69)(cid:381)(cid:282)(cid:286)

(cid:1005)(cid:1009)

(cid:1006)(cid:1009)

Because the proposed framework is based on the multi-objective genetic algorithm,
its convergence speed depends on the size of solution space. As shown in Figure 7, the
size of the solution space depends on the number of nodes and modes. So, we perform
experiments for different conﬁgurations of these factors. Figure 11 shows the exper-
imental results of the scalability of the proposed framework for synthetic examples.
The results show that the number of nodes more contributes to the convergence speed
than the number of modes.

8. CONCLUSION
In this paper, we address the multiprocessor scheduling problem of a multi-mode
dataﬂow (MMDF) graph allowing task migration with non-negligible mode transition
delay. An MMDF graph has a ﬁnite set of modes and each mode is speciﬁed by an
SDF graph. We observe that the mode transition delay should be considered in many
streaming applications in which the mode transition occurs frequently, in order to
satisfy the throughput constraint. Thus we propose a mapping/scheduling framework
based on a genetic algorithm which schedules all SDF graphs simultaneously to mini-
mize the number of processors while keeping the throughput constraint. Also, we pro-
pose the formulations to compute the required buffer size and the required throughput
performance of the MMDF graph to satisfy the given throughput constraint of the sys-
tem, by estimating the mode transition delay conservatively from an obtained schedul-
ing result under the assumption of blocking scheme of task migration. To show the
viability of the proposed technique, we compare the proposed technique with two other
approaches with some synthetic examples and three real applications. Experimental
results conﬁrm the superiority of the proposed technique over other approaches.

Because the mode transition delay is conservatively calculated with blocking scheme
of task migration, as a future work, we plan to calculate the throughput requirement
with more exact model of mode transition.

ACKNOWLEDGMENTS

This research was supported by a grant to Bio-Mimetic Robot Research Center Funded by Defense Ac-
quisition Program Administration, and by Agency for Defense Development (UD130070ID), Basic Science
Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

39:20

H. Jung et al.

Science, ICT & Future Planning (NRF-2013R1A2A2A01067907, 2013R1A1A1013384), and IT R&D program
MKE/KEIT (No. 10041608, Embedded system Software for New-memory based Smart Device).

REFERENCES
Vagelis Bebelis, Pascal Fradet, Alain Girault, and Bruno Lavigueur. 2013. BPDF: A Statically Analyzable
DataFlow Model with Integer and Boolean Parameters. In Proceedings of the Eleventh ACM Interna-
tional Conference on Embedded Software (EMSOFT ’13). IEEE Press, Piscataway, NJ, USA, Article 3,
10 pages. http://dl.acm.org/citation.cfm?id=2555754.2555757

Bishnupriya Bhattacharya and Shuvra S. Bhattacharyya. 2001. Parameterized dataﬂow modeling
IEEE Transactions on 49, 10 (Oct 2001), 2408–2421.

for DSP systems. Signal Processing,
DOI:http://dx.doi.org/10.1109/78.950795

Greet Bilsen, Marc Engels, Rudy Lauwereins, and J.A. Peperstraete. 1995. Cyclo-static data ﬂow. In Acous-
tics, Speech, and Signal Processing, 1995. ICASSP-95., 1995 International Conference on, Vol. 5. 3255–
3258 vol.5. DOI:http://dx.doi.org/10.1109/ICASSP.1995.479579

Morteza Damavandpeyma, Sander Stuijk, Twan Basten, Marc Geilen, and Henk Corporaal.
2013. Throughput-constrained DVFS for scenario-aware dataﬂow graphs.
In Real-Time and
Embedded Technology and Applications Symposium (RTAS), 2013 IEEE 19th. 175–184.
DOI:http://dx.doi.org/10.1109/RTAS.2013.6531090

Marc Geilen and Sander Stuijk. 2010. Worst-case Performance Analysis of Synchronous Dataﬂow
Scenarios. In Proceedings of
the Eighth IEEE/ACM/IFIP International Conference on Hard-
ware/Software Codesign and System Synthesis (CODES/ISSS ’10). ACM, New York, NY, USA, 125–
134. DOI:http://dx.doi.org/10.1145/1878961.1878985

Marc Geilen, Sander Stuijk, and Twan Basten. 2012. Predictable dynamic embedded data pro-
cessing. In Embedded Computer Systems (SAMOS), 2012 International Conference on. 320–327.
DOI:http://dx.doi.org/10.1109/SAMOS.2012.6404194

Alain Girault, Bilung Lee, and Edward A. Lee. 1999. Hierarchical ﬁnite state machines with multiple con-
currency models. Computer-Aided Design of Integrated Circuits and Systems, IEEE Transactions on 18,
6 (Jun 1999), 742–760. DOI:http://dx.doi.org/10.1109/43.766725

Hanwoong Jung, Chanhee Lee, Shin haeng Kang, Sungchan Kim, Hyunok Oh, and Soonhoi Ha.
2014. Dynamic Behavior Speciﬁcation and Dynamic Mapping for Real-Time Embedded Systems:
HOPES Approach. ACM Trans. Embed. Comput. Syst. 13, 4s, Article 135 (April 2014), 26 pages.
DOI:http://dx.doi.org/10.1145/2584658

Chanhee Lee, Sungchan Kim, Hyunok Oh, and Soonhoi Ha. 2013. Failure-Aware Task Scheduling of Syn-
chronous Data Flow Graphs Under Real-Time Constraints. Journal of Signal Processing Systems 73, 2
(2013), 201–212. DOI:http://dx.doi.org/10.1007/s11265-013-0753-3

Edward A. Lee and David G. Messerschmitt. 1987. Synchronous data ﬂow. Proc. IEEE 75, 9 (Sept 1987),

1235–1245. DOI:http://dx.doi.org/10.1109/PROC.1987.13876

Orlando Moreira. 2012. Temporal analysis and scheduling of hard real-time radios running on a multi-

processor. ser. PHD Thesis, Technische Universiteit Eindhoven (2012).

Firew Siyoum, Marc Geilen, Orlando Moreira, Rick Nas, and Henk Corporaal. 2011. Analyzing synchronous
dataﬂow scenarios for dynamic software-deﬁned radio applications. In System on Chip (SoC), 2011 In-
ternational Symposium on. 14–21. DOI:http://dx.doi.org/10.1109/ISSOC.2011.6089222

Sander Stuijk, Marc Geilen, and Twan Basten. 2010. A Predictable Multiprocessor Design Flow for Stream-
ing Applications with Dynamic Behaviour. In Digital System Design: Architectures, Methods and Tools
(DSD), 2010 13th Euromicro Conference on. 548–555. DOI:http://dx.doi.org/10.1109/DSD.2010.31

Sander Stuijk, Marc Geilen, Bart D. Theelen, and Twan Basten. 2011. Scenario-aware dataﬂow: Modeling,
analysis and implementation of dynamic applications. In Embedded Computer Systems (SAMOS), 2011
International Conference on. 404–411. DOI:http://dx.doi.org/10.1109/SAMOS.2011.6045491

Sander Stuijk, Amirhossein Ghamarian, Bart D. Theelen, Marc Geilen, and Twan Basten. 2008. FSM-based

SADF. Technical Report. Citeseer.

Lothar Thiele, Samarjit Chakrabort, and Martin Naedele. 2000. Real-time calculus for scheduling hard
real-time systems. In Circuits and Systems, 2000. Proceedings. ISCAS 2000 Geneva. The 2000 IEEE
International Symposium on, Vol. 4. 101–104 vol.4. DOI:http://dx.doi.org/10.1109/ISCAS.2000.858698

Maarten H. Wiggers, Marco J. G. Bekooij, and Gerard J. M. Smit. 2008. Buffer Capacity Computation for
Throughput Constrained Streaming Applications with Data-Dependent Inter-Task Communication. In
Real-Time and Embedded Technology and Applications Symposium, 2008. RTAS ’08. IEEE. 183–194.
DOI:http://dx.doi.org/10.1109/RTAS.2008.10

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

Multiprocessor Scheduling of a Multi-mode Dataﬂow Graph Considering Mode Transition Delay39:21

Jiali Teddy Zhai. 2015. Adaptive streaming applications : analysis and implementation models. ser. PHD

Thesis, Universiteit Leiden (2015).

ACM Transactions on Embedded Computing Systems, Vol. 9, No. 4, Article 39, Publication date: March 2010.

