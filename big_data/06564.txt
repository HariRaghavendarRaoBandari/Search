6
1
0
2

 
r
a

 

M
1
2

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
4
6
5
6
0

.

3
0
6
1
:
v
i
X
r
a

Weak limits for the largest subpopulations in Yule

processes with high mutation probabilities

Erich Baur∗ and Jean Bertoin†
ENS Lyon and Universit¨at Z¨urich

March 22, 2016

Abstract

We consider a Yule process until the total population reaches size n (cid:29) 1, and as-
sume that neutral mutations occur with high probability 1 − p (in the sense that each
child is a new mutant with probability 1 − p, independently of the other children), where
p = pn (cid:28) 1. We establish a general strategy for obtaining Poisson limit laws for the num-
ber of subpopulations exceeding a given size and apply this to some mutation regimes of
particular interest. Finally, we give an application to subcritical Bernoulli bond percola-
tion on random recursive trees with percolation parameter pn tending to zero.

Key words: Branching processes, mutation, percolation, random increasing trees.
Subject Classiﬁcation: 60J27; 60J80; 60K35.

1

Introduction

We consider a system of branching processes with mutations speciﬁed as follows. The underlying
total population process is modeled by a standard Yule process Z, that is a continuous-time
birth process started from one individual with unit birth rate per unit population size. We

∗erich.baur@ens-lyon.fr
†jean.bertoin@math.uzh.ch
Acknowledgment of support. The research of the ﬁrst author was supported by the Swiss National Sci-
ence Foundation grant P300P2 161011, and performed within the framework of the LABEX MILYON (ANR-
10-LABX-0070) of Universit´e de Lyon, within the program “Investissements d’Avenir” (ANR-11-IDEX-0007)
operated by the French National Research Agency (ANR).

superpose independent mutations, by declaring that a new-born child is a clone of its parent
with probability p ∈ (0, 1), and a mutant otherwise. Being a mutant means that the individual
obtains a new genetic type which was not present before. We observe the process Z at the
instant when the nth individual is born and group individuals of the same genetic type into
subpopulations.

In this paper, we are interested in questions concerning the (asymptotic) sizes of these
subpopulations under strong mutations, the sense that p = pn → 0. By approximating the
population system from below and above by two diﬀerent processes, where sub-populations are
independent and have an explicit distribution, we develop a general strategy to obtain non-
trivial (Poisson) weak limits for the number of subpopulations exceeding a given size (which
might grow with n as well).

We then discuss our strategy in the context of three qualitatively diﬀerent mutation regimes.
For ﬁxed (cid:96) ∈ N, we identify ﬁrst pn ∼ an−1/(cid:96), a > 0 ﬁxed, as the regime in which, in the limit
n → ∞, the largest subpopulations have size (cid:96) + 1. For its number, we obtain a Poisson limit
law and show that the number of subpopulations of size j for j ∈ {1, . . . , (cid:96)} tends to inﬁnity
(Theorem 1 and Corollary 2).

Secondly, we discuss the regime pn ∼ a/ ln n. Since the size of the subpopulation containing
the ancestor is of order npn, see Proposition 1, this is the border-line case between a bounded
and an unbounded size for the ancestral subpopulation. We show that the sizes of the largest
subpopulations are concentrated around c1 ln n+c2 ln ln n, where c1 and c2 are positive constants
depending on a (Theorem 3). For the exact choice pn = a/ ln n and λ > 0, we ﬁnd a correction
c3 = c3(a, λ) ∈ R such that, with yn = c1 ln n + c2 ln ln n + c3, the number of subpopulations
greater than yn converges along subsequences (yn(m)) ⊂ (yn) with converging fractional part
to a Poisson(Λ)-distributed random variable, where Λ is expressed in terms of a, λ and (yn(m))
(Theorem 2).

Thirdly, we study the case 1/ ln n (cid:28) pn (cid:28) 1. Here, it turns out that the sizes of the largest
n npn. For pn ≥ ln ln n/ ln n and given λ > 0,
subpopulations are to ﬁrst order given by e−1p−1
we compute a precise barrier such that the number of subpopulations exceeding this barrier
follows in the limit the Poisson-law with parameter λ (Theorem 4).

This work originates from questions about Bernoulli bond percolation on so-called random
recursive trees, when their size n tends to inﬁnity and the percolation parameter p = pn satisﬁes
pn → 0. The connection to branching processes stems from the fact that the genealogical tree
built from the ﬁrst n individuals in a standard Yule process can be interpreted as a random
recursive tree Tn on {1, . . . , n}. Mutations in the Yule process can naturally be modeled on its
genealogical tree, by cutting the edges that connect mutants to its parent. Then the connected
subsets of vertices form the subpopulations of the same genetic type. To put it diﬀerently,

2

the connected components (clusters) on a random recursive tree Tn that arise from a Bernoulli
bond percolation, where each edge is erased with probability 1− p independently of each other,
can be viewed as the subpopulations in a Yule process with mutation rate 1 − p, observed at
the instant when there are n individuals in total in the system. The strategy we develop here
in terms of Yule processes allows a concise analysis of cluster sizes, for any choice of pn tending
to zero. For sequences of pn such that pn → 1 or pn = p ∈ (0, 1) remains constant, similar
connections between systems of branching processes and percolation on increasing tree families
have been utilized before in, e.g., [9, 8, 4, 5]. The precise deﬁnition of a random recursive tree,
its connection to Yule processes and more references to existing results on percolation will be
discussed in Section 5.

The rest of this paper is organized as follows.

In the next Section 2, we properly deﬁne
the population system and provide some heuristics for regimes of interest and Poisson limits.
Then, in Section 3, we explain our strategy for obtaining Poisson limit laws for the number of
subpopulations (or clusters) greater than a given size. Section 4 contains our main results; we
exemplify our strategy by proving limit results for certain mutation rates of particular interest.
In the last Section 5, we establish the link to percolation on random recursive trees. Appendix A
contains some (standard) estimates on Yule processes, which we use in our analysis.

Notation: We let N = {1, 2, . . .}. If (an : n ∈ N), (bn : n ∈ N) are two sequences of real
numbers, we write an ∼ bn if an/bn → 1 as n → ∞, and we write an (cid:28) bn or bn (cid:29) an if and
only if an/bn → 0 as n → ∞. Moreover, if f (n) and g(n) are two positive functions, we say
g(n) = O(f (n)) if there exists M > 0 such that g(n) ≤ M f (n) for all n ∈ N, and we write
f (n) = o(g(n)) if g(n)/f (n) → 0 as n → ∞. We will use the letters c or C for small or large
generic constants that do not depend on n. Their values may change from line to line.

2 Yule processes with mutations

In this section, we introduce the population system we work with, and present some basic
results and heuristics. For background on Yule processes, we refer to Appendix A, and for
more information to Chapter 3 of [3].

2.1 A population system with inﬁnitely many types
Let Z = (Z(t) : t ≥ 0) be a standard Yule process with unit birth rate per individual and
started from one single particle, i.e. Z(0) = 1. Let p ∈ [0, 1]. We superpose mutations on Z
as follows: When a new child is born, we declare it to be a clone of its parent with probability
p, and a mutant with a new genetic type diﬀerent from all the previous types with probability

3

2 < b(p)

1 = 0 and write 0 < b(p)

1 − p. We let b(p)
3 < . . . for the sequence of consecutive birth
times of individuals which are mutants. More speciﬁcally, the ancestor present at time b(p)
1 = 0
has genetic type 1, as well as its clone children. The ﬁrst mutant is born at time b(p)
2 and has
genetic type 2. The next mutant appears in the system at time b(p)
3 and receives genetic type
3; it is a mutant of an individual of either type 1 or of type 2, and so on. We group individuals
of the same genetic type into subpopulations, so that at time t, the population system consists
of at most Z(t) many subpopulations. In contrast to [8], we will here not be interested in the
genealogical structure, but only in the sizes of the subpopulations.

i

For i ∈ N, we let (Y (p)

(t) : t ≥ 0) denote the subpopulation process counting the individuals
i +t) : t ≥ 0),
of type i, with Y (p)
(b(p)
i ∈ N, form independent Yule processes with birth rate p per individual and started from one
single individual each. The number of subpopulations of diﬀerent genetic types present at time
t ≥ 0 is denoted by

. It should be clear that the processes (Y (p)

(t) = 0 if t < b(p)

i

i

i

(cid:110)

(cid:111)
i ≤ t

.

T (p)(t) = max

i ∈ N0 : b(p)

Viewed as a process in t, T (p) = (T (p)(t), t ≥ 0) is a counting process started from 1 which
grows at rate (1 − p)Z(t). Its predictable compensator is absolutely continuous with density
(1 − p)Z(t), that is

T (p)(t) −

(1 − p)Z(s)ds,

t ≥ 0,

is a martingale. See, e.g., [16, Theorem 9.15].

0

We next build a process Y(p) = (Y(p)(t) : t ≥ 0) by setting

(cid:90) t

(cid:16)

Y(p)(t) =

Y (p)
1

(t), Y (p)

2

(t), . . .

t ≥ 0.

,

(cid:17)

Note that Y(p)(0) = (1, 0, . . .). Clearly, we can retrieve the total population size Z(t) at time t
from Y(p),

∞(cid:88)

Z(t) =

Y (p)
i

(t).

It follows from its construction that the process Y(p) is Markovian with transition rates at time
t ≥ 0 for y1, . . . , yk ∈ N given by

i=1

(y1, . . . , yk, 0, . . .) (cid:55)→ (y1, . . . , yk, 1, 0, . . .) at rate (1 − p)(y1 + . . . + yk),
(y1, . . . , yk, 0, . . .) (cid:55)→ (y1, . . . , yi−1, yi + 1, yi+1, . . . , yk, 0, . . .) at rate pyi.

Mostly we will stop Y(p) at the instant when the nth particle is born,

τn = inf {t ≥ 0 : Z(t) = n} .

4

Obviously, we have τi ≤ b(p)
for all i ∈ N and all p ∈ [0, 1]. Moreover, since e−tZ(t) is a
martingale which converges almost surely to a standard exponential E as t tends to inﬁnity, see
Appendix A,

i

n→∞ (τn − ln n) = − lnE

lim

almost surely.

(1)

2.2 The size of the ancestral subpopulation

In this section, we point at a simple limit theorem in distribution for the size Y (p)
(τn) of the
subpopulation at time τn having the same genetic type as the ancestor individual. We obtain
the following characterization when p = pn (cid:28) 1.

1

Proposition 1. For λ > 0, denote by Geo(λ) a geometrically distributed random variable of
parameter λ, and by Exp(1) a standard exponential random variable. Then the following holds:

(a) If 0 ≤ pn (cid:28) 1/ ln n, then Y (pn)

(d)−−−→
n→∞ 1.
(b) If pn ∼ a/ ln n for some a > 0, then Y (pn)

(τn)

1

1

(τn)

(d)−−−→
n→∞ Geo(e−a).

(c) If 1/ ln n (cid:28) pn (cid:28) 1, then n−pnY (pn)

1

(τn)

(cid:111)

(d)−−−→
n→∞ Exp(1).

(cid:110)|τn − ln n| ≤ p
(cid:17) → 1 − F (x) as n → ∞,

P(cid:16)

Y (pn)
1

(τn) > x; Gn

Proof: Assume pn → 0, and let Gn =
as n → ∞. For (a) and (b), it thus suﬃces to show that for x ∈ N,

−1/2
n

. From (1), we know P(Gn) → 1

P(cid:16)

(cid:17) ≤ P(cid:16)

(cid:17) ≤ P(cid:16)

(cid:17)

where F is the distribution function of the stated limit in (a) or (b), respectively. Since Y (pn)
is monotone increasing in t, we have

1

(t)

Y (pn)
1

(ln n − p−1/2

n

) > x; Gn

Y (pn)
1

(τn) > x; Gn

Y (pn)
1

(ln n + p−1/2

n

) > x

. (2)

Since Y (pn)(t) has a geometric law with success probability exp(−pnt), we obtain

(cid:17)

=(cid:0)1 − exp(cid:0)−(cid:0)pn ln n + p1/2

n

(cid:1)(cid:1)(cid:1)x

.

P(cid:16)

Y (pn)
1

(ln n + p−1/2

n

) > x

It is readily checked that when x ∈ N and n → ∞, the right side converges for pn (cid:28) 1/ ln n to
zero, whereas for pn ∼ a/ ln n, it converges to (1 − e−a)x. Writing
(ln n − p−1/2

= P(cid:16)

(ln n − p−1/2

P(cid:16)

+ P(Gc

) > x

(cid:17)

(cid:17)

) > x; Gn

Y (pn)
1

Y (pn)
1

n),

n

n

5

we see that the same convergence holds for the probability on the left side in (2). This shows
(cid:3)
(a) and (b). The proof of (c) is entirely similar and left to the reader.

Remark 1.

(a) The above statements remain true Y (p)

(τn) is replaced by any Y (p)

i

(τn) for

1

i ∈ N ﬁxed.

(b) For p ∈ (0, 1) ﬁxed, it has been shown independently in [5] and [20] that n−pY (p)

(τn)
converges to a Mittag-Leﬄer distributed random variable with parameter p. In turn, the
latter converges to a standard exponential random variable when p → 0. If pn → 1 as
n → ∞, then n−pnY (pn)

(τn) → 1 a.s., see [4].

1

1

(c) We note that for each p ∈ [0, 1], the mean of Y (p)

(τn) can be computed exactly. Indeed,

1

we have

E(cid:104)

(cid:105)

n(cid:88)

P(cid:16)

Y (p)
1

(τn)

=

i ∈ Y (p)

1

(τn)

=

i=1

i=1

(cid:17)

n(cid:88)

E(cid:2)pD(i)(cid:3) ,

=(cid:80)i−1
n(cid:88)

where D(i) is the insertion depth of i, i.e., D(i) is the height of i in the genealogical
tree of the Yule process stopped at time τn (with D(1) = 0). From [12] we know that
j=1 ξj, where ξj are independent Bernoulli random variables of parameter 1/j.
D(i)
Consequently,

(d)

E(cid:2)pD(i)(cid:3) = 1 + p

n(cid:88)

i−1(cid:89)

E(cid:2)pξ(j)(cid:3) = 1 + p

i=1

i=2

j=2

= 1 + p

n(cid:88)
n−1(cid:88)

i=2

(cid:18) p
i−1(cid:89)
i(cid:89)

j=2

j

1
i!

i=1

j=2

(cid:19)

+ 1 − 1
j

(j − 1 + p).

2.3 Poisson heuristic for the number of large subpopulations
Clearly, when pn (cid:28) 1/n, the n ﬁrst individuals are all mutants and all subpopulations at time
τn are singletons with high probability. When pn ∼ a/n, standard Poisson approximation to the
binomial law (and the fact that the genealogical tree of Z(τn) is not star-like) shows that the
number of subpopulations of size 2 is asymptotically Poisson(a)-distributed. For general (cid:96) > 1,
it is however a priori not obvious in which regime subpopulations of size (cid:96) + 1 will emerge,
and if so, how many of them. Following the tradition of Aldous [1], we shall now present an
heuristic argument to determine this regime, and will check later on that our informal approach
can actually be made rigorous.

We are interested in the number of subpopulations of size > (cid:96) at time τn,

N n,p((cid:96)) =

11(cid:110)

Y (p)
i

(cid:111).

(τn)>(cid:96)

∞(cid:88)

i=1

6

For i (cid:29) 1 and p (cid:28) 1, the birth time b(p)

of the ith mutant is close to the birth time τi of
the ith individual, and by (1), we have b(p)
(τn)
should be close to that of a Yule process with birth rate p evaluated at time τn − b(p)
i ∼ ln(n/i),
that is to a geometric distribution with parameter exp(−p ln(n/i)) = (i/n)p. Therefore, the
Bernoulli variable 11(cid:110)

i − ln i ∼ − lnE a.s. Thus the distribution of Y (p)

i

i

Y (p)
i

(τn)>(cid:96)

(cid:111) has parameter
(τn) > (cid:96)) ∼ (1 − (i/n)p)(cid:96) ∼(cid:16)

P(Y (p)

i

(cid:17)(cid:96)

.

p ln

n
i

Let us now recall Le Cam’s inequality for the reader’s convenience.

Inequality of Le Cam [18] Let (an)n ⊂ N be a sequence of integers. For each n ∈ N,
let ξn,i, 1 ≤ i ≤ an, be independent Bernoulli random variables with parameters qn,i. Set

Sn = ξn,1 + ··· + ξn,an, and let λn = E[Sn] =(cid:80)an
(cid:12)(cid:12)(cid:12)(cid:12)P (Sn = j) − λj

(cid:12)(cid:12)(cid:12)(cid:12) ≤ 2
In particular, if limn→∞ λn = λ ∈ (0,∞) and limn→∞(cid:80)an

i=1 qn,i. Then
ne−λn
j!

∞(cid:88)

j=1

an(cid:88)

i=1

Poi(λ) is a Poisson(λ)-distributed random variable.

q2
n,i.

i=1 q2

n,i = 0, then Sn

(d)−→ Poi(λ), where

Even though the variables Y (p)

section that 11(cid:110)

(τn), i ∈ N, which describe the sizes of the subpopulations,
(cid:111) for i = 1, . . . , n, form a sequence of independent Bernoulli variables.
are clearly not independent (obviously, they add up to n), let us pretend for the purpose of this
n(cid:88)

(cid:90) 1

Since

(cid:16)

(τn)>(cid:96)

Y (p)
i

i

(cid:17)(cid:96) ∼ p(cid:96)n

(ln 1/t)(cid:96)dt = p(cid:96)n(cid:96)!,

p ln

n
i

we infer that for a > 0,

i=1

0

p = pn ∼ a
n1/(cid:96)

should be the regime in which the largest subpopulations have size (cid:96) + 1, and more precisely,
then

N n,pn((cid:96))

(d)−→ Poi((cid:96)!a(cid:96)).

These informal calculations are of course far from a rigorous proof; nonetheless we shall show
in the forthcoming Theorem 1 that the above weak convergence actually holds. For this, we
shall ﬁrst develop a general strategy to analyze the asymptotic behavior of the number of large
subpopulations in the next section.

7

3 The number of subpopulations exceeding a given size

We will establish limit laws for the number of subpopulations of size > x ∈ N at time τn,

N n,p(x) =

11(cid:110)

Y (p)
i

(cid:111),

(τn)>x

(3)

∞(cid:88)

i=1

(p)

when p = pn → 0. The threshold x may be ﬁxed or x = xn → ∞ (depending on the choice of
(pn)n). Roughly speaking, the key step consists in approximating the population system Y(p)
at time τn by systems Y(p) and Y
in which mutants are born at deterministic times, and such
that Y(p) is bounded by Y(p) from below and by Y
from above. The advantage of working
with deterministic times comes from the fact that we can in this way decouple populations
sizes from birth times and then deal with independent Bernoulli variables. In the new systems,
we can compute moments of the quantities corresponding to N n,p(x) more easily. Provided we
construct Y(p) and Y
such that the expected numbers of subpopulations of a size larger than
x match asymptotically in the two systems, this will ultimately lead to limit statements for
N n,p(x) in the original system.

(p)

(p)

In fact, it will be suﬃcient to control Y(p) on a set of large probability. In this regard, recall
that convergence in distribution of a sequence of random variables (Un : n ∈ N) to some random
variable U is equivalent to convergence in distribution of Un11En to U , provided (En : n ∈ N)
is a sequence of events with P(En) → 1. Concerning limit results for N n,p, we can therefore
restrict ourselves to certain “good” events En of large probability, which we specify next.
Lemma 1. Assume that pn → 0, and let (kn)n ⊂ N be a sequence of integers such that kn → ∞
and knpn → 0 as n → ∞. There exists an event En (depending on n, pn and kn) of probability
P(En) → 1, on which the following holds true:

(a) τkn = b(p)
kn
(b) (1 − k
−1/3
n
(c) (1 − 3k

−1/3
n

≤ (ln kn)2,
)knet ≤ Z(τkn + t) ≤ (1 + k
)knet ≤ T (pn)(b(p)

+ t) ≤ (1 + 3k

kn

−1/3
n

)knet
−1/3
n

for all t ≥ 0,

)knet

for all t ≥ 0.

We call En the good event, and for establishing our limit results for N n,pn(xn), we will work
on En. The proof of the lemma uses standard estimates on Yule processes and is given in the
appendix.

Note that the event {τkn = b(p)

} under (a) is precisely the event that the ﬁrst k − 1 born
individuals (discounting the ancestor individual) are all mutants. The choice of kn will depend
on our applications and will be speciﬁed later on. Roughly speaking, we choose kn in such a
way that with high probability, the ﬁrst 2kn born individuals do not contribute to N n,pn(xn).

kn

8

Deﬁne for i ∈ N

β(i) = ln i − ln(cid:0)1 − 3k−1/3
β(i) = ln i − ln(cid:0)1 + 3k−1/3
)kn exp(cid:0)β(i)(cid:1) = (1 + 3k−1/3

(cid:1) − ln kn,
(cid:1) − ln kn,
)kn exp(cid:0)β(i)(cid:1) = i.

n

n

n

so that

(1 − 3k−1/3

n

(4)

Lemma 1 immediately implies the following control over birth times on the event En.

Corollary 1. On the good event En, we have the bounds

τkn + β(i) ≤ τi ≤ τkn + β(i).

and

b(p)
kn

+ β(i) ≤ b(p)

i ≤ b(p)

kn

+ β(i).

In the next two sections, we show how to upper and lower bound N n,pn(xn) on the good
event En for (xn)n a sequence of positive integers (possibly constant). For ease of notation, we
write p instead of pn, and x instead of xn. We shall always work on the event En, with the
properties stated in Lemma 1.

3.1 An upper bound
Recall the notation (3). We treat the summands i with i ≤ 2kn − 1 and i ≥ 2kn separately and
ﬁrst consider the case i ≥ 2kn. From Corollary 1, we deduce that for i ≥ 2kn,

τn ≤ b(p)

kn

i + β(n) − β(i).

+ β(n) ≤ b(p)
(5)
i ≤ τn do contribute. Thus we can restrict ourselves to

In the sum (3), only the terms with b(p)
summands with 2kn ≤ i ≤ n∗, where

n∗ = max(cid:8)i ∈ N : β(i) ≤ β(n)(cid:9) .

(6)

(t) is monotone

Setting U n,p
increasing in t the almost-sure upper bound

i = Y (p)

i

i + β(n)− β(i)), we obtain from (5) and the fact that Y (p)
(b(p)

i

n∗(cid:88)

i=2kn

11(cid:110)

Y (p)
i

(τn)>x

(cid:111)11En ≤ n∗(cid:88)

i=2kn

9

11{U n,p

i >x}.

Note that the variables U n,p
has the
law of the population size of a Yule process with birth rate p at time β(n) − β(i) when started
from a single individual.

, 2kn ≤ i ≤ n∗, are independent of each other, and U n,p

i

i

The summands with 1 ≤ i ≤ 2kn − 1 we all bound in the same (rough) way, by disregarding
the individual birth times of the corresponding subpopulations. More speciﬁcally, we remark
that on En,

so that, deﬁning U n,p
have almost surely

i = Y (p)

i

τn ≤ τkn + β(n)+ ≤ β(n) + ln2(kn).
i + β(n) + ln2(kn)) and using again monotonicity of Y (p)
(b(p)
2kn−1(cid:88)
11(cid:110)

(cid:111)11En ≤ 2kn−1(cid:88)

i

11{U n,p

i >x}.

(τn)>x

Y (p)
i

i=1

i=1

(t), we

For 1 ≤ i ≤ 2kn− 1, the U n,p
’s are independent and identically distributed according to the law
of the population size of a Yule process with birth rate p at time β(n)+ln2(kn) when started from
: 2kn ≤ i ≤ n∗)
a single individual. Moreover, the families (U n,p
are independent of each other. Letting

: 1 ≤ i ≤ 2kn − 1) and (U n,p

i

i

i

n∗(cid:88)

n,p

S

(x) =

11{U n,p

i >x},

we note that our above estimates yield

i=1

N n,p(x)11En ≤ S

n,p

(x) almost surely.

(7)

3.2 A lower bound

Our lower bound on N n,p(x)11En begins with the trivial estimate

N n,p(x) ≥

11(cid:110)

Y (p)
i

(cid:111),

(τn)>x

∞(cid:88)

i=2kn

that is we will consider only summands with an index i ≥ 2kn. From Corollary 1, we see that
on the good event En,

Now let

τn ≥ τkn + β(n) = b(p)

kn

+ β(n) ≥ b(p)

i + β(n) − β(i).

n∗ = max(cid:8)i ∈ N : β(i) ≤ β(n)(cid:9) .

(8)

10

Deﬁning V n,p

i = Y (p)

i

i + β(n) − β(i)), we arrive with (8) at the almost-sure lower bound
(b(p)
∞(cid:88)

(cid:111)11En ≥ n∗(cid:88)

11(cid:110)

11{V n,p

i >x}11En.

(τn)>x

Y (p)
i

i=2kn

i=2kn

, 2kn ≤ i ≤ n∗, are independent, and V n,p

The variables V n,p
is distributed as the population
size of a Yule process with birth rate p at time β(n)−β(i) when started from a single individual.
With

i

i

n∗(cid:88)

Sn,p(x) =

11{V n,p

i >x},

we have shown that

N n,p(x)11En ≥ Sn,p(x)11En

almost surely.

i=2kn

Note that the V n,p
almost surely for 2kn ≤ i ≤ n∗.

i

’s are not independent of the event En. By construction, we have V n,p

(9)
i ≤ U n,p

i

3.3 Bounds on the mean

The crucial step of our approach is to control the means E [Sn,p(x)11En] and E(cid:2)S

(x)(cid:3). In

n,p

this section, we develop bounds valid for all regimes. The exact asymptotic analysis will then
depend on the choices of (pn)n and (xn)n and will be postponed to Section 4.

The behavior of both expectations will be dominated by the following integral.

Lemma 2. Let p > 0, x > 0. Then

(cid:90) ∞

(cid:0)1 − e−ps(cid:1)x e−sds =

0

where Γ denotes the Gamma-function.

Γ(1/p + 1)Γ(x + 1)

Γ(1/p + x + 1)

,

Proof: We let ﬁrst u = e−s and then v = up to obtain

(cid:90) ∞

(cid:0)1 − e−ps(cid:1)x e−sds =

(cid:90) 1

(1 − up)xdu =

0

0
1
p

B(1/p, x + 1) =

=

(cid:90) 1

(1 − v)xv1/p−1dv

1
p
Γ(1/p + 1)Γ(x + 1)

0

,

Γ(1/p + x + 1)

where the last two identities follow from well-known expressions for the Beta- and Gamma-
(cid:3)
functions B and Γ, respectively.

11

From now on, we let for n, x ∈ N and p > 0,

I(n, p, x) = n

Γ(1/p + 1)Γ(x + 1)

Γ(1/p + x + 1)

.

The following asymptotics as n → ∞ are immediately derived from Stirling’s formula.
Lemma 3. When p = pn → 0 and x = xn → ∞, then

√

I(n, p, x) ∼

2πn

(1/p)1/p+1/2 xx+1/2
(1/p + x)1/p+x+1/2 ,

whereas if p = pn → 0 and x ∈ N is ﬁxed, then

I(n, p, x) ∼ x!npx.

3.3.1 An upper bound on the mean

In order to evaluate E(cid:2)S

for 1 ≤ i ≤ n∗. When evaluated
at time t ≥ 0, a Yule process with birth rate p, started from a single individual, follows the
geometric law with success probability exp(−pt). For 1 ≤ i ≤ 2kn − 1, this implies

n,p

i

(x)(cid:3), recall the deﬁnition of U n,p
i > x) =(cid:0)1 − exp(cid:0)−p(β(n) + ln2(kn))(cid:1)(cid:1)x
(cid:0)1 − exp(cid:0)−p(β(n) + ln2(kn))(cid:1)(cid:1)x

i >x}], we thus have

11{U n,p

.

Σn,p

1 (x) = 2kn

P (U n,p

1 (x) = E[(cid:80)2kn−1

i=1

Letting Σn,p

In our applications, we will choose kn such that Σn,p
summands are negligible. For the summands with i ≥ 2kn, we get

(cid:34) n∗(cid:88)

E

(cid:35)

n∗(cid:88)

(cid:0)1 − exp(cid:0)−p(β(n) − β(i))(cid:1)(cid:1)x

,

(10)
1 (x) → 0 as → ∞, that is, the ﬁrst 2kn − 1

.

11{U n,p

i >x}

=

i=2kn

i=2kn

12

)knet and obtain

f (n, t)dt

=

i=2kn

n∗(cid:88)

−1/3
and it remains to analyze the sum on the right. We put f (n, t) = (1 + 3k
n

(cid:0)1 − exp(cid:0)−p(β(n) − β(i))(cid:1)(cid:1)x

(cid:0)1 − exp(cid:0)−p(β(n) − β(i))(cid:1)(cid:1)x(cid:90) β(i)
n∗(cid:88)
(cid:90) β(n∗)
(cid:0)1 − exp(cid:0)−p(β(n) − t)(cid:1)(cid:1)x
(cid:90) β(n)
(cid:0)1 − exp(cid:0)−p(β(n) − t)(cid:1)(cid:1)x
In the ﬁrst step, we used the fact that(cid:82) β(i)

β(2kn−1)

i=2kn

≤

≤

0

β(i−1)

f (n, t)dt

β(i−1) f (n, t)dt = 1 by (4), and for the last equality that
β(n∗) ≤ β(n) by deﬁnition of n∗, see (6). With the change of variables s = β(n) − t and again
(4), the last integral is equal to

f (n, t)dt.

(11)

(cid:90) β(n)

−1/3
1 + 3k
n
1 − 3k
−1/3
n

n

0

(cid:0)1 − e−ps(cid:1)x e−sds ≤(cid:0)1 + 10k−1/3

(cid:1) n

n

(cid:0)1 − e−ps(cid:1)x e−sds,

(cid:90) ∞

0

where the bound on the right holds for n suﬃciently large, recalling that kn → ∞. For
evaluating the integral on the right side, we use Lemma 2. We have shown that for n large
enough,

(x)(cid:3) ≤ Σn,p

1 (x) +(cid:0)1 + 10k−1/3

n

(cid:1) I(n, p, x).

E [N n,p(x)11En] ≤ E(cid:2)S

n,p

(12)

(13)

3.3.2 A lower bound on the mean

We turn to E [Sn,p(x)11En] and write

E [Sn,p(x)11En] = E [Sn,p(x)] − E(cid:2)Sn,p(x)11(En)c

(cid:3) .

2 (x) = E[Sn,p(x)11(En)c]. In our applications, Σn,p

Put Σn,p
2 (x) will tend to zero. Indeed, provided
E[Sn,p(x)] remains uniformly bounded in n, the same holds true for its second moment, see
2 (x) ≤ C(1 − P(En))1/2 = o(1) as n → ∞.
Remark 2 below. We get with Cauchy-Schwarz Σn,p

Concerning the ﬁrst term on the right side of (13), we have

E [Sn,p(x)] =

(cid:0)1 − exp(cid:0)−p(β(n) − β(i))(cid:1)(cid:1)x

.

n∗(cid:88)

i=2kn

Then, with g(n, t) = (1 − 3k

−1/3
n

n∗(cid:88)

(cid:0)1 − exp(cid:0)−p(β(n) − β(i))(cid:1)(cid:1)x ≥

)knet, a similar calculation as under (11) shows

(cid:90) β(n)

(cid:0)1 − exp(cid:0)−p(β(n) − t)(cid:1)(cid:1)x g(n, t)dt.

i=2kn

β(2kn)

13

Putting s = β(n) − t, the last integral is bounded from below by

Now let

0

n

) n

Σn,p

(1 − 10k−1/3

(cid:90) β(n)−β(2kn)
(cid:90) ∞
(cid:1) n
3 (x) =(cid:0)1 − 10k−1/3
E [Sn,pn(x)] ≥(cid:0)1 − 10k−1/3
E [N n,p(x)11En] ≥ E [Sn,p(x)11En] ≥(cid:0)1 − 10k−1/3

n

The term Σn,p
that

and therefore

(cid:0)1 − e−ps(cid:1)x e−sds.

(cid:0)1 − e−ps(cid:1)x e−sds.

β(n)−β(2kn)

(cid:1) I(n, p, x) − Σn,p
(cid:1) I(n, p, x) − (Σn,p

3 (x),

n

n

3 (x) will be negligible in our applications. Using again Lemma 2, we have shown

(14)

(15)

2 (x) + Σn,p

3 (x)) .

For the rest of this text, we refer to the quantities Σn,p

3 (x) as the error
(x)] and E[Sn,p(x)11En], respectively, whereas the term I(n, p, x) involving the

terms of E[S
Gamma-function (which is the same for both expectations) is referred to as the main term.

1 (x) and Σn,p

2 (x), Σn,p

n,p

3.4 General strategy

Here we outline our general program how to obtain non-degenerate (Poisson) limit laws for
N n,p(x) when p = pn → 0 and x = xn may depend on n as well. We will control N n,p(x) on
the good event En in terms of the lower and upper bounds Sn,p(x) and S

(x).

n,p

Our strategy is based on the following general observation.

(d)−→ V as n → ∞.

Lemma 4. Let (Un : n ∈ N), (Vn : n ∈ N) be sequences of R-valued uniformly integrable
random variables with Un ≤ Vn almost surely for all n ∈ N. Assume Vn
(d)−→ V for some random
variable V . Then, if E[Un] → E[V ], we have Un
Proof: Writing Un = Vn + (Un − Vn), the claim follows if we show that Un − Vn → 0 in
probability. Since Un ≤ Vn almost surely, we have E[|Vn − Un|] = E[Vn] − E[Un]. Uniform
integrability and the fact that Vn → V in distribution implies E[Vn] → E[V ], see, e.g., [10,
Theorem 3.5]. Since E[Un] → E[V ] by assumption, the proof is complete.
(cid:3)
(d)−→ V and E[Un] → E[V ], one could also assume Un
(d)−→
We stress that instead of assuming Vn
(d)−→ V (in fact, for positive integrable random variables,
V and E[Vn] → E[V ] and then deduce Vn
this can be proved by Fatou’s lemma via Skorokhod’s representation theorem, without assuming
uniform integrability). However, for us it is more natural to work under the assumption of

14

Lemma 4.

Remark 2. Uniform integrability will not pose any problem in our setting: If Vn is a sum of
indicators of independent events, then

E(cid:2)V 2

n

(cid:3) ≤ E [Vn] + E [Vn]2 ,

implying that if supn∈N E [Vn] < ∞, then (Vn : n ∈ N) has a uniformly bounded second moment
as well and is therefore uniformly integrable.

We now assume that the sequence (pn)n is ﬁxed and satisﬁes pn → 0. We ask for non-
n,pn(xn). Our strategy consists of the

degenerate limits of N n,pn(xn). Recall the deﬁnition of S
following steps. We use the notation from the preceding sections.
Step 1. Find a sequence (xn)n ⊂ N such that, for a suitable choice of (kn)n with pnkn → 0,

lim inf
n→∞

E [Sn,pn(xn)11En] ≥ λ and

E(cid:2)S
n,pn(xn)(cid:3) ≤ λ
E [Sn,pn(xn)11En] ∼ E [N n,pn(xn)11En] ∼ E(cid:2)S
n,pn(xn)(cid:3) ∼ λ.

lim sup
n→∞

for some strictly positive constant λ > 0. By construction, this implies

Step 2. Show that for (kn)n as under Step 1, with an = n∗ and qn,i = P (U n,pn

> xn),

i

an(cid:88)

i=1

lim
n→∞

q2
n,i = 0.

Step 3. Le Cam’s inequality applied to the sum S

Lemma 4 to deduce that N n,pn(xn)11En
n → ∞.

n,pn(xn) gives S

n,pn(xn)

(d)−−→ Poi(λ) and hence N n,pn(xn)

(d)−−→ Poi(λ). Apply
(d)−−→ Poi(λ) as

Note that the constant λ under Step 1 does not depend on the sequence (kn)n. Of course,
depending on the point of view, one can also ﬁx a sequence of thresholds (xn)n and then ask
for a choice of (pn)n such that non-degenerate limits of N n,pn(xn) appear.

It is also of interest to understand when N n,pn(xn) → 0 or N n,pn(xn) → ∞ in probability.
In order to prove such behaviors, we will in the ﬁrst case apply Markov’s inequality and then
show that the expectation converges to zero, while for the second case, we will make use of the
following lemma.

15

Lemma 5. In the setting of Le Cam’s inequality, cf. Section 2.3, assume that λn = E[Sn] → ∞
as n → ∞. Then Sn

(p)−→ ∞, i.e., for each K > 0, P(Sn ≥ K) → 1 as n → ∞.

The proof follows from an application of the Bienaym´e-Chebycheﬀ inequality.

We remark that Le Cam’s inequality can be used to obtain quantitative bounds on the rate
of convergence. In our case, since we regard N n,pn(xn) only on the good event En, one would
have to optimize the choice of this event for establishing good bounds. This will not be our
concern here.

4 Limit results for subpopulation sizes

We will now work out our strategy explained in the last section. Even though it can be applied
to any choice of pn such that pn → 0, we will restrict ourselves to discussing three regimes of
particular interest. Each of them corresponds to a diﬀerent limiting behavior of the ancestral
subpopulation, as discussed in Proposition 1.

4.1 The regime of bounded subpopulations

In Section 2.3, we argued heuristically that in the regime

pn ∼ a

n1/(cid:96) ,

a > 0 and (cid:96) ∈ N ﬁxed,

there should be a Poissonian number of subpopulations of size > (cid:96) when n → ∞. We shall now
prove this rigorously, together with the fact that there are no subpopulations of a size strictly
larger than (cid:96) + 1, and an unbounded number of subpopulations of size (cid:96) (or, more generally, of
size j for each 1 ≤ j ≤ (cid:96), see Corollary 2). We point to Theorem 5.4 of [11] for similar results
for percolation on the complete graph, that is, the Erd˝os-R´enyi random graph model.

It will be convenient to use the notation ∆n,pn((cid:96)) = N n,pn((cid:96) − 1) − N n,pn((cid:96)) for the number
of subpopulations of size equal to (cid:96). Recall that c and C denote generic constants whose values
may change from line to line.
Theorem 1. Fix (cid:96) ∈ N and a > 0, and assume pn ∼ an−1/(cid:96). Then, as n → ∞,

∆n,pn((cid:96) + 1)

(d)−→ Poi((cid:96)!a(cid:96)).

Moreover, N n,pn((cid:96) + 1)

(p)−→ 0, and ∆n,pn((cid:96))

(p)−→ ∞.

Proof: Our ﬁrst two claims follow if we show that N n,pn((cid:96))

(d)−→ Poi((cid:96)!a(cid:96)) and N n,pn((cid:96)+1)

(p)−→ 0

16

as n tends to inﬁnity. We follow the strategy outlined in Section 3. We choose kn = (cid:98)ln n(cid:99) and

ﬁrst bound E(cid:2)S

n,pn((cid:96))(cid:3) from above, via (12). The error term Σn,pn

((cid:96)) is estimated by

1

Σn,pn

1

((cid:96)) ≤ 3a(cid:96) ln(cid:96)+1 n

n

= o(1).

For the main term in (12), we obtain with Lemma 3 as n → ∞,

I(n, pn, (cid:96)) = n

The last two display imply

Γ(1/pn + 1)Γ((cid:96) + 1)

∼ (cid:96)!np(cid:96)

n = (cid:96)!a(cid:96) + o(1).

Γ(1/pn + (cid:96) + 1)

E(cid:2)S

n,pn((cid:96))(cid:3) ≤ (cid:96)!a(cid:96) + o(1).

We turn to a lower bound on E [Sn,pn((cid:96))11En], which we will establish via expression (15). We
ﬁrst show that the error terms Σn,pn
((cid:96)) tend to zero. For that purpose, recall that
by construction,

2

((cid:96)) and Σn,pn

E [Sn,pn((cid:96))] ≤ E(cid:2)S

3

n,pn((cid:96))(cid:3) ≤ C.

Hence the second moment of Sn,pn((cid:96)) is uniformly bounded as well, see Remark 2, so that with
Cauchy-Schwarz,

Σn,pn

2

((cid:96)) ≤ C(1 − P(En))1/2 = o(1).

For the error term Σn,pn

3

((cid:96)) in (15), we note that β(n) − β(2kn) ≥ ln n − 3 ln ln n, whence

(cid:90) ∞

Σn,pn

3

((cid:96)) ≤ n

β(n)−β(2kn)

(cid:90) 2 ln n

≤ 1
n

+ n

ln n−3 ln ln n

(cid:0)1 − e−pns(cid:1)(cid:96) e−sds
(cid:0)1 − e−pns(cid:1)(cid:96) e−sds+ ≤ C

ln4(cid:96) n

n

= o(1).

(16)

Since the main term of (15) agrees with that of (12), we get E [Sn,pn((cid:96))11En] ≥ (cid:96)!a(cid:96) − o(1), and
consequently

E [Sn,pn((cid:96))11En] ∼ E[N n,pn((cid:96))11En] ∼ E(cid:2)S

n,pn((cid:96))(cid:3) ∼ (cid:96)!a(cid:96)

for n → ∞.

Step 1 of the strategy is therefore established (with the constant λ there given by (cid:96)!a(cid:96)), and so
is Step 2, since

n∗(cid:88)

i=1

> (cid:96)) E(cid:2)S

n,pn((cid:96))(cid:3)

P (U n,pn

i

> (cid:96))2 ≤ max

i

P (U n,pn

≤ C(cid:0)1 − exp(cid:0)−pn(β(n) + ln2(kn))(cid:1)(cid:1)(cid:96)

i

= o(1).

17

We follow Step 3 and obtain N n,pn((cid:96))

(d)−→ Poi((cid:96)!a(cid:96)) as n tends to inﬁnity.

For the second part of the theorem, we use Markov’s inequality to obtain

P (N n,pn((cid:96) + 1) ≥ 1) ≤ E [N n,pn((cid:96) + 1)11En] + P(Ec

Using again the bound (12) for E(cid:2)S
and then the main term similarly to above and obtain E(cid:2)S

n,pn((cid:96) + 1)(cid:3) + o(1).
n,pn((cid:96) + 1)(cid:3), we ﬁrst estimate the error term Σn,pn

n) ≤ E(cid:2)S
n,pn((cid:96) + 1)(cid:3) ≤ Cn−1/(cid:96). This proves

((cid:96) + 1)

1

N n,pn((cid:96) + 1)

(p)−→ 0 as n → ∞.

It remains to show that ∆n,pn((cid:96))

(p)−→ ∞, that is for each K ∈ N, P(∆n,pn((cid:96)) > K) → 1
as n tends to inﬁnity. Writing ∆n,pn((cid:96)) = N n,pn((cid:96) − 1) − N n,pn((cid:96)), we have seen that N n,pn((cid:96))
converges in distribution to a Poisson random variable, so we may prove the claim for N n,pn((cid:96)−
1) instead of ∆n,pn((cid:96)). Since N n,pn((cid:96) − 1)11En ≥ Sn,pn((cid:96) − 1)11En almost surely, cf. (9), we can
estimate

P (N n,pn((cid:96) − 1) ≥ K) ≥ P (N n,pn((cid:96) − 1) ≥ K; En) − o(1) ≥ P (Sn,pn((cid:96) − 1) ≥ K; En) − o(1)

≥ P (Sn,pn((cid:96) − 1) ≥ K) − o(1).

We analyze the mean of Sn,pn((cid:96) − 1) via (14) and obtain with Stirling’s formula

E [Sn,pn((cid:96) − 1)] ≥ cn1/(cid:96).

An application of Lemma 5 shows Sn,pn((cid:96) − 1)

(p)−→ ∞ and thus ﬁnishes the proof.

(cid:3)

Theorem 1 does not tell us how the number of subpopulations equal to j behave when j is
strictly less than (cid:96). This can however be deduced from the cases j = (cid:96) and j = (cid:96) + 1, as we
show next.

Corollary 2. In the setting of Theorem 1, we have ∆n,pn(j)
1 ≤ j ≤ (cid:96).

(p)−→ ∞ as n → ∞ for each

Proof: For j = (cid:96), the statement forms already part of the theorem, so we ﬁx j ∈ N with
1 ≤ j < (cid:96). Put αn = (cid:98)n1−j/(cid:96)(cid:99). We will show that the number of subpopulations of size j that
stem from the αnth individual is already unbounded as n → ∞, see Figure 1.

In this regard, we let Zαn = (Zαn(t + ταn) : t ≥ 0) denote the process that counts the
individuals which are descendants of the αnth individual of Z, i.e. Zαn(t + ταn) is the number
of individuals in the original system at time t + ταn which have the αnth individual as their
common ancestor, no matter whether there are clones or mutants. It should be clear that Zαn

18

evolves as a standard Yule process started from one individual. Next, note that by construction,

τn − ταn

(d)
=

n−1(cid:88)

j=αn

Ej

1
j

for (Ej : j ∈ N) a sequence of independent standard exponentials. In particular,

E [τn − ταn] = (j/(cid:96)) ln n + o(1), Var (τn − ταn) = o(1),

hence (τn − ταn) − (j/(cid:96)) ln n → 0 in probability as n → ∞. Since e−tZαn(t) converges almost
surely to a standard exponential variable E as t → ∞, this implies

n→∞ n−j/(cid:96)Zαn (τn − ταn) = E

lim

in probability.

(17)

Write N n,pn
|αn

(k) for the number of subpopulations of size > k ∈ N in the system Y(p) stopped at

Figure 1: Schematic of the proof of Corol-
lary 2. The outer triangle represents the ge-
nealogical tree Tn of Z(τn), and the small
triangles are the subpopulations of size j in
Y(pn)(τn). When αn ∼ n1−j/(cid:96), the subtree Tn(cid:48)
of Tn rooted at the αnth individual has size
n(cid:48) ≈ nj/(cid:96). Since pn ≈ (n(cid:48))
−1/j, Theorem 1
shows that within Tn(cid:48), the number of sub-
populations of size j tends to inﬁnity when
n → ∞. A fortiori, the same must hold for
∆n,pn(j).

time τn, whose common ancestor is given by the αnth individual, and similarly, deﬁne ∆n,pn
(k)
|αn
by counting only the subpopulations of size equals k that stem from individual αn. Obviously,
N n,pn
|αn

(k) ≤ ∆n,pn(k). For K > 0, we estimate

(k) ≤ N n,pn(k) and ∆n,pn
|αn

P (∆n,pn(j) ≥ K) ≥ P(cid:0)∆n,pn
≥ P(cid:16)

N n,pn
|αn

αn (j) ≥ K(cid:1) = P(cid:16)

(j − 1) ≥ 2K

N n,pn
|αn

(cid:17) − P(cid:16)

(cid:17)

(j − 1) ≥ K + N n,pn
|αn

(j)

(cid:17)

N n,pn
|αn

(j) > K

.

(18)

We will show that the ﬁrst probability tends to 1 for each choice of K, while the second can be
made as small as we wish provided K is suﬃciently large.

For that purpose, we remark that conditionally on Zαn (τn − ταn) = m, as a consequence of
(k) for k ∈ N has same law as N m,pn(k), the number of subpopulations
the dynamics, N n,pn
|αn
exceeding k in Y(pn)(τm). Moreover, if m, m(cid:48) ∈ N with m ≤ m(cid:48), the variable N m,pn(k) is

19

stochastically dominated by N m(cid:48),pn(k) (adding individuals can only increase subpopulations).
Now ﬁx ε > 0. By (17), we ﬁnd n0 ∈ N and c1, C1 > 0 such that for all n ≥ n0, with
mn = (cid:98)c1nj/(cid:96)(cid:99) and Mn = (cid:100)C1nj/(cid:96)(cid:101), the event

An = {Zαn (τn − ταn) ∈ [mn, Mn]}

has probability at least 1−ε. We ﬁrst look at the second probability in (18). By our observations
from above, we have for n ≥ n0,

P(cid:16)

(cid:17) ≤ P(cid:16)

N n,pn
|αn

(j) > K

N n,pn
|αn

(j) > K | An

(cid:17)

+ ε ≤ P(cid:0)N Mn,pn(j) > K(cid:1) + ε.

Recalling that pn ∼ an−1/(cid:96) ∼ (C 1/j

, we deduce from Theorem 1 that for K ∈ N,

−1/j
1 a)M
n

P(cid:0)N Mn,pn(j) > K(cid:1) → P(cid:0)Poi(C1j!aj) > K(cid:1)

as n → ∞.

The right side is smaller than ε provided K is large enough. For the ﬁrst probability in (18),
we have similarly

(cid:17) ≥ (1−ε)P (N mn,pn(j − 1) ≥ 2K) .

P(cid:16)

(cid:17) ≥ (1−ε)P(cid:16)

(j − 1) ≥ 2K

N n,pn
|αn

N n,pn
|αn

(j − 1) ≥ 2K | An

By Theorem 1, N mn,pn(j − 1) → ∞ in probability as n tends to inﬁnity, hence the probability
on the right tends to 1 for each choice of K. Since ε > 0 was arbitrary, this concludes the proof
(cid:3)
of the corollary.

The next corollary of Theorem 1 characterizes the regime where unbounded subpopulations
appear in the limit n → ∞. For the sake of clarity, we write Ppn for the law of the system
Y(pn).
(cid:104)
Corollary 3. Let (pn)n ⊂ [0, 1]. Then

(cid:16)∃i ∈ N such that Y (pn)

(cid:17)

(τn) > K

Ppn

i

(cid:105) ⇔(cid:2)pn n1/(cid:96) → ∞ for each (cid:96) ∈ N(cid:3) .
(cid:17)
(cid:16)∃i ∈ N such that Y (pn)

(τn) > K

= 1

= 0.

i

If one of the statements fails, limK→∞ lim inf n→∞ Ppn

K→∞ lim inf
lim
n→∞

The proof is a direct application of Theorem 1 and left to the reader.

4.2 The regime pn ∼ a ln−1 n

Parts (a) and (b) of Proposition 1 identify

pn ∼ a
ln n

,

a > 0 ﬁxed,

20

as the regime in which the ancestral subpopulation becomes non-trivial.
Its size however
remains bounded. What are the sizes of the largest subpopulations that do appear? As a
consequence of Theorem 3, we will see that if we shift the subpopulation sizes by −(c1 ln n +
c2 ln ln n) for some explicit constants c1, c2 > 0, then for any (cid:96) ∈ N and any ε > 0, we ﬁnd
C = C((cid:96), ε) such that the (cid:96) largest (shifted) sizes are contained in [−C, C] with probability at
least 1 − ε, provided n is large enough.

While Theorem 3 holds true whenever pn ∼ a ln−1 n, we will ﬁrst prove Theorem 2, which
provides a stronger result valid for the case pn = a ln−1 n. Here we will compute a correction
c3 of order one to the above shift, such that the number of subpopulations greater than yn =
c1 ln n + c2 ln ln n + c3 converges to a Poisson limit along all subsequences (yn(m))m of (yn)n,
whose fractional part has a limit as m tends to inﬁnity. Theorem 3 then readily follows from
adapting some estimates used in the proof of Theorem 2.

Before we give the precise formulation of our results, we need some preparation. For a > 0,

deﬁne

fa(t) = 1 + t ln(at) − 1 + at

a

(19)
On (0,∞), fa is a smooth function with fa(t) → 1 as t → 0 and fa(t) → −∞ for t → ∞.
Moreover, since on (0,∞),

ln(1 + at),

t > 0.

a(t) = ln(at) − ln(1 + at) < 0,
f(cid:48)

the function fa is strictly decreasing, and there is a unique t∗ = t∗(a) ∈ (0,∞) for which
fa(t∗) = 0. See Figure 2.

Figure 2: The function fa for a = 1.

Now, for a > 0 and λ > 0 ﬁxed and t∗ the root of fa, put

yn = t∗ ln n − 1
2f(cid:48)

a(t∗)

(cid:18)

2πt∗

λ2(1 + at∗)

(cid:19)(cid:19)

(20)

(cid:18)

ln ln n + ln

21

We use the standard notation {y} = y − (cid:98)y(cid:99) to denote the fractional part of a real y ∈ R.
As we will see in the following theorem, the barrier yn deﬁnes a precise threshold, in the
following sense: Whenever (yn(m))m is a subsequence of (yn)n such that limm→∞{yn(m)} =: b ∈
[0, 1) exists, then the number of subpopulations exceeding size yn(m) converges weakly to a
Poisson(Λ(a, b, λ))-distributed random variable with intensity given by

(cid:18)

(cid:19)b

1
at∗

Λ(a, b, λ) = λ

1 +

.

(21)

We will see in Corollary 4 that the restriction to subsequences with converging fractional part
is actually necessary.
Theorem 2. Assume pn = a ln−1 n for some a > 0. Let λ > 0, and deﬁne yn = yn(a, λ) as
in (20). Let (yn(m))m be a subsequence of (yn)n such that {yn(m)} → b for some b ∈ [0, 1). Then,
with Λ(a, b, λ) as above, for m → ∞,

N n(m),pn(m)((cid:98)yn(m)(cid:99))

(d)−→ Poi (Λ(a, b, λ)) .

Proof: We again follow the strategy explained in Section 3. Recall that we require pnkn → 0,
and we will here choose kn = (cid:98)ln1/2 n(cid:99). Putting tn = yn/ ln n, the ﬁrst part of Lemma 3 and a
small calculation show that as n tends to inﬁnity,

(cid:114) 2πtn
(cid:18)

1 + atn

1
2

(cid:18)

(cid:19){tn ln n}

√
ln n

n

(atn)tn ln n

(1 + atn)(a−1+tn) ln n

1 +

1
atn

(cid:18) 2πtn

(cid:19)(cid:19)

1 + atn

+ {tn ln n} ln

1 +

1
atn

.

(cid:19)

,

(22)

I(n, pn,(cid:98)yn(cid:99)) ∼

fa(tn) ln n +

ln ln n + ln

Taking the logarithm of the right hand side, we arrive at the expression

for fa as deﬁned under (19). Obviously, tn = t∗ + O( ln ln n

ln n ), and by Taylor’s formula,

(cid:18)

,

+ o(1).

so that

Taking exponentials, (22) and the last display show that for m tending to inﬁnity,

fa(tn) = f(cid:48)

ln n

(cid:32)(cid:18)ln ln n

a(t∗)(tn − t∗) + O
(cid:18)
(cid:18)

(cid:19)2(cid:33)
(cid:19)(cid:19)
I(cid:0)n(m), pn(m),(cid:98)yn(m)(cid:99)(cid:1) ∼ Λ(a, b, λ).

λ2(1 + atn)

ln ln n + ln

2πtn

fa(tn) ln n = −1
2

22

We next control the error terms Σn,pn
we have for n suﬃciently large,

1

Σn,pn

1

((cid:98)yn(cid:99)) = 2kn

(cid:0)1 − exp(cid:0)−pn(β(n) + ln2(kn))(cid:1)(cid:1)(cid:98)yn(cid:99)

, Σn,pn

2

and Σn,pn

3

. First, recalling that β(n) ≤ ln n + o(1),

n(m),pn(m)
and, with Cauchy-Schwarz and Remark 2, Σ
2

((cid:98)yn(m)(cid:99)) = o(1). Finally,

= o(1).

≤ 2(ln1/2 n) (1 − exp(−2a))

(cid:98)yn(cid:99)

n(m),pn(m)((cid:98)yn(m)(cid:99))

(cid:105) ≤ Λ(a, b, λ) + o(1),
(cid:90) ∞
(cid:0)1 − e−pns(cid:1)(cid:98)yn(cid:99)
+ n(cid:0)1 − e−2a(cid:1)(cid:98)yn(cid:99)(cid:90) 2 ln n
(cid:105) ∼ E[N n(m),pn(m)((cid:98)yn(m)(cid:99))11En(m)] ∼ E(cid:104)

β(n)−β(2kn)

ln n−2 ln ln n

e−sds

≤ 1
n

e−sds = o(1),

(cid:105)

n(m),pn(m)((cid:98)yn(m)(cid:99))

S

In particular,

E(cid:104)

S

Σn,pn

3

((cid:98)yn(cid:99)) ≤ n

so that as m → ∞,

E(cid:104)

Sn(m),pn(m)((cid:98)yn(m)(cid:99))11En(m)

The condition under Step 2 is fulﬁlled as well, see the estimate for Σn,pn
follows that N n(m),pn(m)((cid:98)yn(m)(cid:99)) converges to a Poisson(Λ(a, b, λ)) random variable.

. Performing Step 3, it
(cid:3)

1

∼ Λ(a, b, λ).

Theorem 2 implies the following remarkable weak convergence along subsequences for the
of the largest subpopulation at time τn. For a > 0, r ∈ R and t∗ the root of fa, put

size C n,pn∗

(cid:19)1/2

(cid:18) 2πt∗

1 + at∗

e−r/2.

λa,r =

Corollary 4. Let a > 0, pn = a ln−1 n and r ∈ R. Deﬁne λa,r as above, and yn = yn(a, λa,r)
in terms of λa,r as in (20). Let (yn(m))m be any subsequence of (yn)n such that {yn(m)} → b for

some b ∈ [0, 1). Then, for m → ∞, with µ = ln(cid:0)2π/a2b(cid:1) + (1 − 2b) ln (t∗/(1 + at∗)),
→ exp(cid:0)−e−(r−µ)/2(cid:1) .

− t∗ ln n(m) +

ln ln n(m) ≤ r

(cid:19)

(cid:18)

n(m),pn(m)
∗

P

C

1
a(t∗)
2f(cid:48)

Proof: The probability on the left hand side is equal to

≤ (cid:98)yn(m)(cid:99)(cid:17)

= P(cid:0)N n(m),pn(m)((cid:98)yn(m)(cid:99)) = 0(cid:1) ∼ P (Poi(Λ(a, b, λa,r)) = 0) ,

n(m),pn(m)
∗

C

P(cid:16)

23

with Λ(a, b, λa,r) deﬁned as in (21). The last asymptotics holds thanks to Theorem 2. The
(cid:3)
claim follows.

Remark 3. The limit expression on the right hand side in the above corollary is the distribution
function of the Gumbel law with location parameter µ and scale parameter 2. In view of our
heuristics explained in Section 2.3 and of what is known about the maximum of n independent
geometrically distributed random variables, it should not come as a surprise that a Gumbel
distribution appears in the limit for the recentered size of the largest subpopulation. Since C n,pn∗
is a discrete random variable and the Gumbel law is a continuous distribution, convergence along
the full sequence cannot hold.

It is instructive to compare our previous two results with Theorem 5.10 and Corollary 5.11

of [11] for the Erd˝os-R´enyi random graph model.

From the proof of Theorem 2, we easily derive that in the general case pn ∼ a ln−1 n, the

sizes of the largest subpopulations are concentrated around

bn = t∗ ln n − 1
2f(cid:48)

a(t∗)

ln ln n.

(23)

Theorem 3. Assume pn ∼ a ln−1 n for some a > 0. Deﬁne bn = bn(a) as in (23), and let (xn)n
be a sequence of positive integers. Then the following holds as n → ∞.
(a) If (xn − bn) (cid:29) 1, then N n,pn(xn) → 0.
(b) If (bn − xn) (cid:29) 1, then N n,pn(xn) → ∞.

Proof: We only have to adapt the estimates given in the proof of Theorem 2, so we will
only sketch the necessary modiﬁcations. We again choose kn = (cid:98)ln1/2 n(cid:99). We treat (a) and
(b) together, and in this regard, we note that for (b), by monotonicity of N n,pn(x) we can
assume that xn (cid:29) ln ln n. With yn everywhere replaced by xn, we deduce from (22) that if
(xn − bn) (cid:29) 1, then I(n, pn, xn) → −∞, whereas if (bn − xn) (cid:29) 1, then I(n, pn, xn) → ∞. The
error term Σn,pn
(xn) is seen to be of order o(1) with exactly the same argument as in the proof
of Theorem 2, and so is the error term Σn,pn

(xn), using here that xn (cid:29) ln ln n.

1

3

Now if (xn − bn) (cid:29) 1, we have by Markov’s inequality and (12),

P (N n,pn(xn) ≥ 1) ≤ E(cid:2)S

n,pn(xn)(cid:3) + o(1) = o(1),

and if (bn − xn) (cid:29) 1, then, as in the second part of the proof of Theorem 1, for any K ∈ N,

P (N n,pn(xn) ≥ K) ≥ P (Sn,pn(xn) ≥ K) − o(1).

24

The probability on the right tends to 1 by an appeal to Lemma 5.

(cid:3)

4.3 The regime ln−1 n (cid:28) pn (cid:28) 1.
In the regime pn (cid:29) 1/ ln n, the ancestral subpopulation grows like npn, see part (c) of Propo-
sition 1. As we shall prove in the following theorem, when 1/ ln n (cid:28) pn (cid:28) 1, the sizes of the
n npn. For the case ln ln n/ ln n ≤ pn (cid:28) 1
largest subpopulations are to ﬁrst order given by e−1p−1
(cid:17)pn
and λ > 0, we will show that the number of subpopulations greater than

is asymptotically Poisson(λ)-distributed. Note that as n → ∞, gλ(pn) = (λ−1(cid:112)2πp−1

(cid:106)(cid:16)
λ−1(cid:112)2πp−1

xn = xn(pn, λ) =

n )pn ∼ 1,

(cid:107)

e−1p−1

n npn

n

(24)

cf. Figure 3.

Figure 3: The function gλ(p) on [0, 10−5] for λ = 200 (left side) and λ = 1000 (right side).
As it will become clear from the proof, we require pn ≥ ln ln n/ ln n (and not merely pn (cid:29)
1/ ln n) only to simplify the calculation; without this assumption, the exact behavior of pn has
to be taken into account more carefully.
Theorem 4. Assume ln−1 n (cid:28) pn (cid:28) 1. Then the following holds as n → ∞.
(a) If u > e−1, then N n,pn((cid:98)up−1
(p)−→ 0. If u < e−1, then N n,pn((cid:98)up−1
n npn(cid:99))
(b) Assume additionally pn ≥ ln ln n/ ln n for large n. Then, with xn as in (24),

n npn(cid:99))

(p)−→ ∞.

N n,pn(xn)

(d)−→ Poi(λ).

(cid:99) and follow the steps of the strategy presented
Proof: We work with the choice kn = (cid:98)p
in Section 3. Since our proof is similar to the proofs of Theorem 1 and Theorem 2, we do not
provide every detail.

−1/2
n

25

We ﬁx a real number u > 0 and let yn = (cid:98)up−1

n npn(cid:99), n ∈ N. For the main term I(n, pn, yn),

Lemma 3 shows

I(n, pn, yn) ∼

√

2π n

(25)

Note that since pn (cid:29) 1/ ln n, we have pnyn → ∞ as n → ∞. By Taylor’s formula,

(cid:19)

(cid:18) 1

pn

ln

+ yn

= ln(yn) +

(1/pn)1/pn+1/2 yyn+1/2
(1/pn + yn)1/pn+yn+1/2 .

n

(cid:18) 1

p2
ny2
n

(cid:19)

.

1

pnyn

+ O

From the last display, we deduce after a short calculation that the logarithm of the right hand
side of (25) behaves asymptotically like

(cid:19)

(cid:18) 1
(cid:0)1 + ln(u) + O(n−pn)(cid:1) − 1

ln pn − 1
pn

1
2

pn

+

ln(yn) − 1
pn

+ O

(cid:18) 1

(cid:19)

p2
nyn

ln pn +

1
2

ln(2π).

(26)

2

ln(2π) + ln n −

1
2

= − 1
pn

In particular, if u > e−1, then the right hand side diverges to −∞, whereas if u < e−1, it
diverges to +∞. Consequently, I(n, pn, yn) → 0 in the ﬁrst and I(n, pn, yn) → ∞ in the second
case. In order to ﬁnish the proof of (a), it remains to convince ourselves that the error terms
Σn,pn
(yn) do not contribute when n tends to inﬁnity. For the ﬁrst one, we have

(yn) and Σn,pn

3

1

Σn,pn

1

(yn) ≤ 2p−1/2

n

(cid:0)1 − exp(cid:0)−pn(β(n) + ln2((cid:98)p−1/2

(cid:99)))(cid:1)(cid:1)yn .

n

Since β(n) ≤ ln n + o(1), we see from taking logarithms that Σn,pn
error term Σn,pn
follow from the same arguments as in the proof of Theorem 3 (or Theorem 1).

(yn) = o(1), as wanted. The
(yn) is readily seen to be of order o(1) as well, and the claims under (a) now

3

1

We turn to (b) and ﬁx λ > 0. If pn ≥ ln ln n/ ln n for n large, then, with xn deﬁned as in (24),

Performing the above calculation with yn replaced by xn and u by

O

= o(1).

pnnpn

(cid:19)

(cid:18) 1
(cid:16)
λ−1(cid:112)2πp−1

n

(cid:17)pn

e−1,

un =

we deduce from (26) that the logarithm of right side in (25) behaves as ln λ + o(1), and thus

I(n, pn, xn) ∼ λ.

Part (b) now follows from the same line of reasoning as in the proof of Theorem 2, using that

26

all the error terms Σn,pn

i

(xn), i = 1, 2, 3, are of order o(1).

(cid:3)

5 Subcritical percolation on random recursive trees

In this ﬁnal section, we make the precise link between the population system Y(p) deﬁned in
Section 2 and percolation on random recursive trees.

A recursive tree with vertex set [n] = {1, . . . , n} is a tree rooted at 1 with the property
that the labels along the unique path from the root to any other vertex form an increasing
sequence. A tree chosen uniformly at random among all these (n − 1)! recursive trees is called
random recursive tree and denoted Tn. The study of Bernoulli bond percolation on large
random recursive trees can be traced back to the analysis of an algorithm for isolating the root
by Meir and Moon [19]; see also Drmota et al.
[13] , Iksanov and M¨ohle [15] and Kuba and
Panholzer [17] for more recent developments in this direction. It further plays a key role in the
construction of the Bolthausen-Sznitman coalescent by Goldschmidt and Martin [14].

We choose p = pn ∈ (0, 1) and write C n,p

, C n,p

2

1

We use the convention that C n,p

, . . . for the percolation clusters of a Bernoulli
bond percolation on Tn with parameter p. That is, we erase each edge of Tn with probability
1 − p and independently of each other, and enumerate the connected components according to
the increasing order of the label of their root vertex (i.e. their vertex with the smallest label).
i = ∅ if there are less than i connected components after
always represents the root cluster containing 1; C n,p
, and

percolation on Tn. With our ordering, C n,p
is the cluster rooted at the smallest vertex which does not belong to the root cluster C n,p
so on. We write |C n,p
Lemma 6. Let p ∈ [0, 1]. The families (|C n,p
same law.

| for the number of vertices of C n,p

. Then the following holds.

|,|C n,p

|, . . .) and (Y (p)

(τn), . . .) have the

(τn), Y (p)

2

1

1

1

2

1

i

i

2

Proof: We construct percolation on a random recursive tree as a growth process in continuous
time as follows. At time t = 0, we start from the singleton {1}. Given percolation with
parameter p on a random recursive tree on [k], k ≥ 1, has been constructed, we equip each
vertex i ∈ [k] with an independent exponential clock Ei of parameter 1. At time mini=1,...,k Ei,
we ﬂip a coin with heads probability p. If head shows up, we attach a vertex labeled k + 1 to
the vertex with label argmini=1,...,k Ei. Otherwise, we add vertex k + 1 to the system without
connecting it to any other vertex. It follows from the construction of random recursive trees
and the independence of the coin ﬂips that we observe at the instant when the nth vertex is
incorporated a Bernoulli bond percolation on Tn with parameter p. Moreover, if we keep track
of the sizes C(p)(t) = (|C (p)
(t)|
stores the size of the ith cluster at time t and clusters are ordered according to their birth

2 (t)|, . . .) of the growing percolation clusters, where |C (p)

1 (t)|,|C (p)

i

27

times, we obtain a Markov chain with initial state C(p)(0) = (1, 0, . . .) and transition rates at
time t ≥ 0 for c1, . . . , ck ∈ N given by

(c1, . . . , ck, 0, . . .) (cid:55)→ (c1, . . . , ck, 1, 0, . . .) at rate (1 − p)(c1 + . . . + ck),
(c1, . . . , ck, 0, . . .) (cid:55)→ (c1, . . . , ci−1, ci + 1, ci+1, . . . , ck, 0, . . .) at rate pci.

From the very construction of Y(p), it follows that the processes (Y(p)(t) : t ≥ 0) and (C(p)(t) :
t ≥ 0) grow according to the same dynamics, and the statement follows.
(cid:3)

If we think of the individuals of Y(p) as being labeled 1, 2, . . ., according to the increasing
order of their birth times, there is in fact a one-to-one correspondence between subpopulations
and clusters that respects the genealogy, as illustrated by Figure 4.

Figure 4: The genealogical tree of a Yule pro-
cess with mutation, stopped after the birth
of the 11th individual. Subpopulations of dif-
ferent genetic types have diﬀerent colors, and
the edges connecting mutants to their par-
ent are represented by dashed lines. Alter-
natively, the subpopulations can be viewed
as the clusters of a Bernoulli bond percola-
tion on a recursive tree on {1, . . . , 11}.

With the above lemma at hand, the results from Section 4 have a direct interpretation
in terms of clusters stemming from a percolation on Tn with parameter pn. For example,
Corollary 3 gives a necessary and suﬃcient condition on the percolation parameter pn such
that in the limit n → ∞, clusters of unbounded size appear.

More generally, the strategy developed in Section 3 gives a concise tool to decide whether
for a given percolation sequence pn → 0 and thresholds xn, there are clusters of a size of order
xn, and if so, how many. Indeed, as exempliﬁed in Section 4, basically one only has to check
the asymptotic behavior of the expression I(n, pn, xn) introduced below Lemma 2.

This work completes the study of percolation on random recursive trees initiated in [6], where
percolation with supercritical parameter pn ∼ 1 − a/ ln n, a > 0 ﬁxed, is studied. In [7], non-
Gaussian ﬂuctuations of the root cluster were proved, and the analysis of percolation clusters
was extended in [4] to all regimes pn → 1. The works [6, 4] do additionally contain information
on the genealogy of clusters (and not merely on their sizes), a type of question we did not
investigate here.

28

1

As a common feature when pn → 1, the root cluster containing 1 has size ∼ npn, while the
sizes of the next largest clusters are of order (1 − pn)npn. This motivated a sub-classiﬁcation
| (cid:28) n, supercritical
of regions into weakly supercritical [1/ ln n (cid:28) 1 − pn (cid:28) 1] when |C n,pn
| ∼ e−tn, and strongly supercritical [1 − pn (cid:28) 1/ ln n]
[1 − pn ∼ t/ ln n, t > 0 ﬁxed] when |C n,pn
when |C n,pn

| ∼ n.

1

1

The regime of constant p ∈ (0, 1) may best be termed “critical”, since in this case, the root
cluster loses its dominating role (with respect to the size). Some results can be found in [20]
and [5], although the motivation there is somehow diﬀerent. For similar reasons, we term the
regime p = pn → 0 considered here “subcritical”. The classiﬁcation into diﬀerent regimes draws
on the terminology which is usually used to describe the Erd˝os-R´enyi random graph model (see,
e.g., [2]).

We stress that there are other natural families of trees which can be grown according to a
probabilistic evolution algorithm, like, e.g., scale-free random trees or b-ary random increasing
trees.
Indeed, branching systems with mutations were used in [8] to study percolation on
scale-free random trees when pn ∼ a/ ln n, and in a similar fashion by Berzunza in [9] for b-
ary random increasing trees. In the case of random recursive trees, the underlying population
system is particularly simple, so we restricted our discussion of the subcritical regime to these
trees, but we certainly expect similar results to hold true for other classes of increasing tree
families.

A Proof of Lemma 1

In this appendix, we will construct an event En with the “good” properties speciﬁed in Lemma 1.
We ﬁrst collect some properties of Yule processes.

A.1 Some properties of Yule processes
For p ∈ [0, 1], denote by Y (p) = (Y (p)(t) : t ≥ 0) a Yule process with birth rate p per unit
population size. Given y ∈ N, write Py for its law under which Py(Y (p)(0) = y) = 1, and
similarly Ey for its expectation. It is well-known that W (p)(t) = e−ptY (p)(t), t ≥ 0, is a square-
integrable martingale. Under Py and for p > 0, its terminal value W (p)(∞) is distributed as
a sum of y standard exponentials and follows thus the Gamma(y, 1)-law. Note that Doob’s
inequality applied to the square-integrable martingale W (p)(t) − y gives

(cid:2)|W (p)(∞) − W (p)(0)|2(cid:3) = 4y.

(27)

(cid:20)

Ey

sup
t≥0

(cid:12)(cid:12)W (p)(t) − W (p)(0)(cid:12)(cid:12)2

(cid:21)

≤ 4Ey

29

We now work in the setting of Section 2. Recall the deﬁnition of the process T (p) = (T (p)(t) :
t ≥ 0) counting the number of diﬀerent genetic types in the population system Y(p), starting
from T (p)(0) = 1. For i ∈ N, τi = inf {t ≥ 0 : Z(t) = i} denotes the birth time of the ith indi-
vidual in the system Y(p) (counting both clones and mutants), with Z denoting the underlying
standard Yule process. The time b(p)
i denotes the ﬁrst time when an individual of genetic type
i appears, i.e., the b(p)
’s are the jump times of T (p)(t). We need the following control over T (p).
Lemma 7. Let p ∈ (0, 1). For k ∈ N, let P|k be the conditional law given {τk = b(p)
k } (i.e. the
ﬁrst k − 1 children are all mutants), and let E|k be its expectation. For every t ≥ 0, we have

i

(1 − p)Z(r)dr

≤ 4(1 − p)k(et − 1),

(cid:34)

E|k

sup
0≤s≤t

and

(cid:34)

E|k

sup
s≥t

e−5s/3

(cid:12)(cid:12)(cid:12)(cid:12)T (p)(τk + s) −
(cid:18)
(cid:12)(cid:12)(cid:12)(cid:12)T (p)(τk + s) −

k +

(cid:18)

(cid:90) τk+s

τk

(cid:90) τk+s

τk

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)2(cid:35)
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)2(cid:35)

k +

(1 − p)Z(r)dr

≤ 324(1 − p)k e−2t/3.

Proof: Let Ft denote the natural ﬁltration generated by the process (Y(p)(t) : t ≥ 0). Both
processes T (p) and Z are Ft-adapted, and τk is a stopping time. We work now under the
probability measure P|k. From the strong Markov property and the dynamics of Y(p) described
(1 − p)Z(r)dr) is a martingale with
M (p)(0) = 0. Its quadratic variation is given by [M (p)](s) = T (p)(τk + s) − k, and its second
moment takes the form

above, we see that M (p)(s) = T (p)(τk + s) − (k +(cid:82) τk+s
(cid:2)T (p)(τk + s)(cid:3) − k
(cid:2)|M (p)(s)|2(cid:3) = E|k
(cid:21)

(cid:2)[M (p)](s)(cid:3) = E|k
(cid:20)(cid:90) τk+s

(cid:90) s

E|k

τk

(1 − p)Z(r)dr

=

(1 − p)E[Z(τk + r)]dr = (1 − p)k(et − 1).

= E|k

τk

0

For the last equality, we used the strong Markov property, which entails that (Z(τk + r) : r ≥ 0)
is independent of Fτk and distributed as a standard Yule process started from k individuals.
An appeal to Doob’s inequality gives

(cid:20)

(cid:21)

E|k

sup
0≤s≤t

|M (p)(s)|2

≤ 4E|k

(cid:2)|M (p)(t)|2(cid:3) = 4(1 − p)k(et − 1).

For the second statement, we bound for every n ∈ N

sup

n≤s<n+1

e−5s/6|M (p)(s)| ≤ e−5n/6

|M (p)(s)|.

sup

n≤s<n+1

30

By Doob’s inequality, see the ﬁrst part, the L2-norm of the right side (with respect to the
conditional measure P|k) is bounded by

n≤s<n+1

e−5n/6

(cid:13)(cid:13)(cid:13)(cid:13) sup
(cid:13)(cid:13)(cid:13)(cid:13)sup

s≥t

e−5s/6|M (p)(s)|

|M (p)(s)|

(cid:13)(cid:13)(cid:13)(cid:13)2

(cid:13)(cid:13)(cid:13)(cid:13)2
≤ 2e−5n/6(cid:112)(1 − p)ken+1 ≤ 2e1/2(cid:112)(1 − p)k e−n/3.
≤ 2e1/2(cid:112)(1 − p)k
e−n/3 ≤ 18(cid:112)(1 − p)k e−t/3.

(cid:88)

n≥(cid:98)t(cid:99)

Thus, summing over n and applying the triangle inequality,

Squaring both sides, the claim follows.

(cid:3)

We ﬁnally turn to the construction of an event En = En,pn,kn that satisﬁes the properties of

Lemma 1.
Proof of Lemma 1: We assume pn → 0 and ﬁx any sequence of integers kn ∈ N satisfying
kn → ∞ and knpn → 0 as n → ∞. Concerning property (a) in Lemma 1, we ﬁrst note that
since each new-born child is a mutant with probability 1 − pn, we have

P(cid:16)

(cid:17)

τkn = b(pn)
kn

= (1 − pn)kn−1 = 1 − o(1).

(cid:110)

(cid:111) ∩(cid:8)τkn < (ln kn)2(cid:9)

Moreover, by (1), we also have P(τkn < (ln kn)2) = 1 − o(1), so that the event

τkn = b(pn)
kn
has probability 1 − o(1) as n tends to inﬁnity.

n =

E1

We turn to property (b). Since conditionally on τkn, (Z(t + τkn) : t ≥ 0) is a Yule process

started from kn individuals, we obtain from (27) and Chebycheﬀ’s inequality

(cid:18)

P

sup
t≥0

(cid:12)(cid:12)e−tZ(t + τkn) − kn| > k2/3

n

(cid:19)

≤ 4
k1/3
n

.

In particular, if we let

n =(cid:8)(1 − k−1/3

n

)knet ≤ Z(τkn + t) ≤ (1 + k−1/3

n

)knet

for all t ≥ 0(cid:9) ,

E2

then P(E2

n) ≥ 1 − 4/k1/3

n = 1 − o(1).

Finally, for property (c) we need control over (T (p)(t) : t ≥ 0). In this regard, Lemma 7 in

31

combination with Chebycheﬀ’s inequality shows that conditionally on {τkn = b(pn)

}, the event

kn

(cid:40)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)T (pn)(τkn + t) −

(cid:32)

E3

n =

(cid:90) τkn +t

kn +

τkn

(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ e5t/6k2/3

n

(cid:41)

(1 − pn)Z(r)dr

for all t ≥ 0

has probability at least 1− 324/k1/3
that pnkn → 0,

n . On E2

n∩ E3

n, we note that for n suﬃciently large, recalling

T (pn)(τkn + t) ≥ kn + (1 − pn)(1 − k−1/3

n

)kn

erdr − e5t/6k2/3

n ≥ (1 − 3k−1/3

n

)knet,

(cid:90) t

0

and similarly

Setting

T (pn)(τkn + t) ≤ (1 + 3k−1/3

n

)knet.

En = E1

n ∩ E2

n ∩ E3
n,

we have constructed an event of probability 1 − o(1) on which for n suﬃciently large, (a), (b)
(cid:3)
and (c) in the statement of Lemma 1 are fulﬁlled.

References

[1] Aldous, D. Probability approximations via the Poisson clumping heuristic. Springer-Verlag,

New York, (1989).

[2] Alon, N., Spencer, J. The probabilistic method. Wiley, Third Edition (2008).

[3] Athreya, K.B., Ney, P.E. Branching Processes. Dover Books on Mathematics (2004).

[4] Baur, E. Percolation on random recursive trees. Preprint

(2014), available at

arXiv:1407.2508. To appear in Random Struct. Algor.

[5] Baur, E., Bertoin, J. The fragmentation process of an inﬁnite recursive tree and Ornstein-

Uhlenbeck type processes. Electron. J. Probab. 20 (98) (2015), 1–20.

[6] Bertoin, J. Sizes of the largest clusters for supercritical percolation on random recursive

trees. Random Struct. Algor. 44 (1) (2014), 1098–2418.

[7] Bertoin, J. On the non-Gaussian ﬂuctuations of the giant cluster for percolation on random

recursive trees. Electron. J. Probab. 19 (2014), no. 24, 1–15.

[8] Bertoin, J., Uribe Bravo, G. Supercritical percolation on large scale-free random trees.

Ann. Appl. Probab. 25 (1) (2015), 81–103.

32

[9] Berzunza, G. Yule processes with rare mutation and their applications to percolation on

b-ary trees. Electron. J. Probab. 20 (2015), 1–23.

[10] Billinsgley, P. Convergence of Probability Measures. Second edition. Wiley series in Prob-

ability and Statistics (1999).

[11] Bollob´as, B. Random Graphs. Second edition. Cambridge University Press (2001).

[12] Dobrow, R. P., Smythe R. T. Poisson approximations for functionals of random trees.

Random Struct. Algor., 9 (1-2) (1996), 79–92.

[13] Drmota, M., Iksanov, A., M¨ohle, M. and R¨osler, U. A limiting distribution for the number
of cuts needed to isolate the root of a random recursive tree. Random Struct. Algor. 34
(3) (2009), 319–336.

[14] Goldschmidt, C. and Martin, J. B. Random recursive trees and the Bolthausen-Sznitman

coalescent. Electron. J. Probab. 10 (2005), 718–745.

[15] Iksanov, A. and M¨ohle, M. A probabilistic proof of a weak limit law for the number of cuts
needed to isolate the root of a random recursive tree. Electron. Comm. Probab. 12 (2007),
28–35.

[16] Klebaner, F. C. Introduction to Stochastic Calculus with Applications. Imperial College

Press, 2nd edition (2005).

[17] Kuba, M. and Panholzer, A. Multiple isolation of nodes in recursive trees. Online J. Anal.

Comb. 9, (2014). Available at http://www.math.rochester.edu/ojac/vol9/98.pdf

[18] Le Cam, L. An approximation theorem for the Poisson binomial distribution. Paciﬁc J.

Math. 10 (1960), 1181–1197.

[19] Meir, A. and Moon, J. W. Cutting down recursive trees. Math. Biosci. 21 (1974), 173–181.

[20] M¨ohle, M. The Mittag-Leﬄer process and a scaling limit for the block counting process
of the Bolthausen-Sznitman coalescent. Lat. Am. J. Probab. Math. Stat. 12 (1) (2015),
35–53.

33

