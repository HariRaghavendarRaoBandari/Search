6
1
0
2

 
r
a

 

M
3
1

 
 
]

.

A
N
h
t
a
m

[
 
 

1
v
3
7
0
4
0

.

3
0
6
1
:
v
i
X
r
a

ANALYSIS OF SCHWARZ METHODS FOR A HYBRIDIZABLE

DISCONTINUOUS GALERKIN DISCRETIZATION: THE MANY

SUBDOMAIN CASE

MARTIN J. GANDER AND SOHEIL HAJIAN

Abstract. Schwarz methods are attractive parallel solution techniques for
solving large-scale linear systems obtained from discretizations of partial dif-
ferential equations (PDEs). Due to the iterative nature of Schwarz methods,
convergence rates are an important criterion to quantify their performance.
Optimized Schwarz methods (OSM) form a class of Schwarz methods that are
designed to achieve faster convergence rates by employing optimized transmis-
sion conditions between subdomains. It has been shown recently that for a
two-subdomain case, OSM is a natural solver for hybridizable discontinuous
Galerkin (HDG) discretizations of elliptic PDEs. In this paper, we generalize
the preceding result to the many-subdomain case and obtain sharp convergence
rates with respect to the mesh size and polynomial degree, the subdomain di-
ameter, and the zeroth-order term of the underlying PDE, which allows us
for the ﬁrst time to give precise convergence estimates for OSM used to solve
parabolic problems by implicit time stepping. We illustrate our theoretical
results with numerical experiments.

1. Introduction

For the numerical treatment of a parabolic equation, e.g.,

(1.1)

∂u
∂t − ∇ · (a(x)∇u) = f (x, t)

u(x, t) = 0
u(x, 0) = g(x)

in Ω × (0, T ],
on ∂Ω × (0, T ],
on Ω,

one often ﬁrst discretizes the spatial dimension using a ﬁnite diﬀerence (FD), ﬁ-
nite element (FE) or discontinuous Galerkin (DG) method. This approach, called
method of lines, results in a semi-discrete system where the unknown u(x, t) is
approximated by a ﬁnite dimensional vector uh(t) and the diﬀerential operator
−∇· (a(x)∇) by a stiﬀness matrix which we denote by Ah. More precisely we then
have

(1.2)

∂uh(t)

∂t

+ Ahuh(t) = f (t),

and uh(t = 0) = gh. We then discretize in time using for example a backward
Euler method with time step τ , i.e.,

(1.3)

(cid:16) 1

τ

Mh + Ah(cid:17)un =

1
τ

Mhun−1 + f (tn),

Date: –.
2000 Mathematics Subject Classiﬁcation. 65N22, 65F10, 65F08, 65N55, 65H10.
Key words and phrases. Additive Schwarz, optimized Schwarz, discontinuous Galerkin meth-

ods, scalability, parabolic problems.

1

2

Martin J. Gander and Soheil Hajian

where Mh is called the mass matrix and un is an approximation of uh(tn). There-
fore, at each time-step, a linear system has to be solved.

One approach for solving (1.3) eﬃciently is to use a domain decomposition
method where we decompose the original spatial domain Ω into overlapping or
non-overlapping subdomains and then solve smaller linear systems in parallel. In
this paper we choose the spatial discretization to be a DG method, more precisely
a hybridizable interior penalty (IPH) method.

It has been shown that optimized Schwarz methods are attractive and natural
solvers for hybridizable DG discretizations, see [9, 13]. This is due to the fact that
hybridizable DG methods impose continuity across elements and subdomains us-
ing a Robin transmission condition, see [8]. Robin transmission conditions and a
suitable choice of the Robin parameter are the core of OSM to achieve fast conver-
gence [7]. Special care is needed when OSM is used as a solver for classical FEM
when cross-points are present, see, e.g., [17, 10, 11, 12]. Those are points which are
shared by more than two subdomains. This is not the case when we apply OSM to
a hybridizable DG method, e.g., IPH, since subdomains only communicate if they
have a non-zero measure interface with each other.

We generalize here our previous results for a two subdomain conﬁguration in [9]
to the case of many subdomains, perform an analysis with respect to the polynomial
degree of the IPH, and study for the ﬁrst time the inﬂuence of the time-step τ on
the performance and scalability of the OSM. In Section 2 we recall the deﬁnition of
IPH in a hybridizable formulation and introduce the domain decomposition settings.
In Section 3 we introduce an OSM for IPH and analyze its convergence properties.
The main contributions of the paper are Theorem 3.3, Corollary 3.4 and the reﬁned
analysis in Section 3.3. We validate our theoretical ﬁndings by performing numerical
experiments in Section 4.

2. The IPH method

In this section we recall the IPH method and its properties. We can deﬁne
many DG methods by two equivalent formulations, namely the primal and ﬂux
formulation, see for instance [1]. However there is also a third equivalent formulation
for a class of hybridizable DG methods introduced in [5]. For the sake of simplicity
we use only the hybridized formulation for IPH and refer the reader to [13, 15] for
its primal and ﬂux formulations.

2.1. Notation. We now deﬁne the necessary operators and function spaces needed
to analyze DG methods. We follow the notation in [1]. Let Th = {K} be a
shape-regular and quasi-uniform triangulation of the domain Ω. We denote the
diameter of an element of the triangulation by hK := maxx,y∈K |x − y| and deﬁne
h := maxK∈Th hK. If e is an edge of an element, we denote the length of that edge
by he. The quasi-uniformity of the mesh implies h ≈ hK ≈ he. Let us denote
the set of interior edges shared by two elements in Th by E 0, i.e., E 0 := {e =
∂K1 ∩ ∂K2,∀K1, K2 ∈ Th}. Similarly we deﬁne the set of boundary edges by E ∂
and all edges by E := E ∂ ∪ E 0.

We seek a DG approximation which belongs to the ﬁnite dimensional space

(2.1)
where Pk(K) is the space of polynomials of degree less than k in the simplex K ∈ Th.
Note that a function in Vh is not necessarily continuous. More precisely Vh is a ﬁnite

Vh := (cid:8)v ∈ L2(Ω) : v|K ∈ Pk(K),∀K ∈ Th(cid:9) ,

OSM and DG

3

y

x

Figure 1. An unstructured mesh with the interface Γ (blue-
dashed) and cross-points.

dimensional subspace of a broken Sobolev space Hl(Th) := QK∈Th
Hl(K), where
Hl(K) is the usual Sobolev space in K ∈ Th and l is a positive integer. Since Hl(Th)
contains discontinuous functions, its trace space along E 0 can be double-valued. We
deﬁne the trace space of functions in Hl(Th) by T(E) := QK∈Th
L2(∂K). Observe
that q ∈ T(E) can be double-valued on E 0 but it is single-valued on E ∂.
e = ∂K1 ∩ ∂K2 we deﬁne the average and jump operators

let q ∈ T(E) and qi := q|∂Ki. Then on

We now deﬁne two trace operators:

{{q}} := 1

2 (q1 + q2),

[[q]] := q1 n1 + q2 n2,

where ni is the unit outward normal from Ki on e ∈ E 0. Note that the jump
and average deﬁnition is independent of the element enumeration. Similarly for a
vector-valued function σ ∈ [T(E)]2 we deﬁne on interior edges

{{σ}} := 1

2 (σ1 + σ2),

[[σ]] := σ1 · n1 + σ2 · n2.

On the boundary, we set the average and jump operators to {{σ}} := σ and [[q]] = q n
and we do not need to deﬁne {{q}} and [[σ]] on e ∈ E ∂ since they do not appear in
the discrete formulation.
Since Hl(Th) contains discontinuous functions, we need to deﬁne some piecewise

gradient operators. For all u, v ∈ Hl(Th) we deﬁne

For a, b ∈ T(E) and single-valued on E 0 we deﬁne the edge integrals by

ZK ∇u · ∇v.

ZTh ∇u · ∇v := XK∈Th
Ze

a b := Xe∈E

ZE

a b.

2.2. Domain decomposition setting. In order to deﬁne IPH in a hybridizable
form we ﬁrst decompose the domain into Ns non-overlapping subdomains {Ωi}Ns
i=1.
We denote the interface between subdomains by Γ and assume the interface is a
subset of internal edges, E 0. More precisely, we denote the interface between two
subdomains by Γij := ∂Ωi∩∂Ωj for i 6= j and the global interface by Γ := ∪i6=jΓij ⊂
E 0. In other words the domain decomposition does not go through any element of
the triangulation. For convenience we denote the interface belonging to subdomain
Ωi by Γi := ∪j∈N (i)Γij where N (i) is a set containing neighbors of the subdomain
Ωi, for an example see Figure 1.

4

Martin J. Gander and Soheil Hajian

This domain decomposition induces a set of non-overlapping triangulations {Ti}Ns
i=1.
Moreover we can deﬁne local DG spaces on each subdomain and represent each
function in Vh as a direct sum,

where Vh,i for i = 1, . . . , Ns is a local space deﬁned as

Vh = Vh,1 ⊕ Vh,2 ⊕ . . . ⊕ Vh,Ns,

We also need a ﬁnite dimensional space on the interface which we denote by Λh,

Vh,i := (cid:8)v ∈ L2(Ωi) : v|K∈Ti ∈ Pk(K)(cid:9).
Λh := (cid:8)ϕ ∈ L2(Γ) : ϕ|e∈Γ ∈ Pk(e)(cid:9).

For the analysis of our Schwarz methods we also need to deﬁne local spaces on Γi
for all i = 1, ..., Ns,

Λi := (cid:8)ϕ ∈ L2(Γi) : ϕ|e∈Γi ∈ Pk(e)(cid:9),

and its global counterpart QNs
i=1 Λi. Note that Λh is single-valued across Γ while
QNs
i=1 Λi is double-valued. We denote the maximum diameter of the subdomains by
H and the diameter of the mono-domain Ω by HΩ. We assume 0 < h ≤ H < HΩ.
For convenience we deﬁne a function for the set of neighboring subdomains of Ωi
and denote it by N (i).

2.3. Hybridizable formulation. We now present IPH in a hybridizable form. A
DG method is hybridizable if one can eliminate the degrees of freedom inside each
element and obtain a linear system in terms of a single-valued function along edges.
Not all DG methods can be written in a hybridized form, for instance the classical
IP method is not hybridizable. A hybridization procedure for DG methods has
been developed and studied in [5] where IPH is also included.

In a DG context the continuity of the exact solution is imposed weakly through
a Nitsche penalization technique. Penalization is regulated through a parameter,
µ ∈ T(E) and scaled like µ = αk2/h for α > 0, independent of h and k and
suﬃciently large. This choice of µ guarantees coercivity of the DG bilinear form
and optimal approximation. Let (u, λ), (v, ϕ) ∈ Vh × Λh and ui, vi ∈ Vh,i be the
restriction of u and v to Ωi. Then the IPH bilinear form reads

(2.2)

a((u, λ), (v, ϕ)) := aΓ(λ, ϕ) +

Ns

Xi=1(cid:16)ai(ui, vi) + aiΓ(vi, λ) + aiΓ(ui, ϕ)(cid:17),

where

(2.3)

aΓ(λ, ϕ) := µ

Ns

Xi=1

ZΓi

λ ϕ,

aiΓ(vi, ϕ) := ZΓi(cid:16) ∂vi

∂ni − µvi(cid:17)ϕ,

ai(ui, vi)

and the local solvers ai(·,·) are deﬁned as
(2.4)
η ui vi + ∇ui · ∇vi −ZE 0
:= ZTi
+ZE 0

[[ui]] · [[vi]] −

1
2µ

µ
2

i

i

{{∇ui}} · [[vi]] + {{∇vi}} · [[ui]]
∂ui
∂ni

[[∇ui]][[∇vi]] +Z∂Ωi

µ ui vi −

vi −

∂vi
∂ni

ui.

This is an IPH discretization of the model problem in Ωi, and ∂Ωi is treated as a
Dirichlet boundary. Observe that ai(·,·) and aΓ(·,·) are symmetric and therefore
a(·,·) is symmetric too.

OSM and DG

5

The global bilinear form a(·,·) is coercive at the discrete level.

In order to
show coercivity we ﬁrst introduce a semi-norm on each subdomain for all (vi, ϕ) ∈
Vh,i × Λh,
(2.5)

,

k(vi, ϕ)k2

i := ηkvik2
Ti

+ k∇vik2
Ti

+ µk[[vi]]k2

Ei\Γi

+ µkvi − ϕk2

Γi

for i = 1, .., Ns. Note that if a subdomain is ﬂoating, that is it does not touch
the Dirichlet boundary condition, and η = 0, then k(vi, ϕ)ki = 0 implies vi and ϕ
are constants and not necessarily zero. The energy norm over the whole domain is
deﬁned by

(2.6)

k(v, ϕ)k2 :=

NsXi=1

k(vi, ϕ)k2
i .

In order to verify that this is actually a norm, we just need to check its kernel: if
k(v, ϕ)k = 0 then v and ϕ are both constants and v|Γ = ϕ. Moreover there are
subdomains that touch the Dirichlet boundary condition and therefore v|∂Ω = 0.
Hence (v, ϕ) = 0.
The proof of coercivity for IPH is done subdomain by subdomain: we ﬁrst collect

the contribution of each subdomain

(2.7)

a((v, ϕ), (v, ϕ)) = aΓ(ϕ, ϕ) +PNs

i=1(cid:0)ai(vi, vi) + 2aiΓ(vi, ϕ)(cid:1),
Γi(cid:1).
i=1(cid:0)ai(vi, vi) + 2aiΓ(vi, ϕ) + µkϕk2

= PNs

Each right-hand side can be bounded from below by semi-norms k(vi, ϕ)ki for i =
1, .., Ns; for details see [9, 15]. Then we obtain

a((v, ϕ), (v, ϕ)) ≥ c

i = ck(v, ϕ)k2,
where 0 < c < 1 and c does not depend on h and k.

k(vi, ϕ)k2

Ns

Xi=1

∀(v, ϕ) ∈ Vh × Λh,

An IPH approximation of the exact solution is obtained by solving the following

problem: ﬁnd (uh, λh) ∈ Vh × Λh such that
a((uh, λh), (v, ϕ)) = ZΩ
f v,
(2.8)

∀(v, ϕ) ∈ Vh × Λh,

which has a unique solution since a(·,·) is coercive on Vh × Λh. We can also show
that IPH has optimal approximation properties, i.e., if the weak solution u is regular
enough then

see details in [1, 15].

kuh − uk0 ≤ c hk+1|u|k+1,Ω,

We now describe how subdomains in the discrete problem (2.8) communicate. If

we test (2.8) with ϕ = 0 and v = 0 in all subdomains except Ωi we obtain

(2.9)

ai(ui, vi) + aiΓ(vi, λh) = ZΩi

f vi,

∀vi ∈ Vh,i, for i = 1, . . . , Ns,

where ui := uh|Ωi . This shows that ui is determined if λh is known. More precisely
λh is used as a Dirichlet boundary data on ∂Ωi in a weak sense using a Nitsche
penalization technique. Now if we test (2.8) with v = 0 and ϕ 6= 0, we obtain an
equation for λh:

(2.10)

aΓ(λh, ϕ) +

Ns

Xi=1

aiΓ(ui, ϕ) = 0,

∀ϕ ∈ Λh.

6

Martin J. Gander and Soheil Hajian

If we further let ϕ be non-zero only on Γij, a segment shared by Ωi and Ωj, then
(2.10) reads

(2.11)

λh =

1

2µ(cid:16)µui −

∂ui

∂ni(cid:17) +

1

2µ(cid:16)µuj −

∂uj

∂nj(cid:17),

on Γij.

In the language of HDG methods, equation (2.11) is called continuity condition.
The continuity condition (2.11) is the core of the optimized Schwarz method that
we will describe in Section 3. We have shown in [9] for the case of two subdomains
how to exploit (2.11) to design a fast solver which we extend to many subdomains
in this paper.

2.4. Schur complement and matrix formulation. The discrete problem (2.8)
can be written in an equivalent matrix form. We ﬁrst choose nodal basis functions
for Pk(K) and denote the space of degrees of freedoms (DOFs) of Vh by V and sim-
ilarly for subspaces, denoted by {Vi}. Then the discrete problem (2.8) is equivalent
to

A:=

{z

(2.12)

0 (cid:19) ,

(cid:18) u
λ (cid:19) = (cid:18) f

A⊤IΓ AΓ (cid:21)
(cid:20) AI AIΓ
|
}
where u and λ are DOFs corresponding to uh and λh, respectively. Here AI
i=1 ai(·,·), AIΓ corresponds to PNs
corresponds to the bilinear form PNs
i=1 aiΓ(·,·)
and AΓ corresponds to aΓ(·,·).
Since the bilinear form (2.2) is symmetric and positive deﬁnite we can conclude
that A is s.p.d. Hence its diagonal blocks, AI and AΓ, are also s.p.d. If we eliminate
the interface unknown, λ, we arrive at a linear system in terms of primal variables
u only. This coincides with the primal formulation of IPH, see [9, 15] for details.
On the other hand we can eliminate u and obtain a Schur complement formulation

(2.13)

where

(2.14)

SΓλ = g,

SΓ := AΓ − A⊤IΓA−1

I AIΓ,

g := −A⊤IΓA−1

I f .

The Schur complement matrix has smaller dimension compared to (2.12) and is
also s.p.d. Therefore one approach in solving (2.13) is to use the conjugate gradient
(CG) method. However the convergence of CG is aﬀected by the condition number
of SΓ, which is similar to the condition number of classical FEM Schur complement
systems:

Proposition 1. Let SΓ be the Schur complement of the IPH discretization. Then
for all ϕ ∈ Λh we have
(2.15)

k2
h kϕk2
Γ,
and therefore the condition number κ(SΓ) is bounded by

Γ ≤ ϕ⊤SΓϕ ≤ Cα

H
Ωkϕk2
H 2

c

(2.16)

κ(SΓ) ≤ C α

H 2
Ωk2
Hh

κ(MΓ),

where MΓ is the mass matrix along the interface. Moreover all constants are inde-
pendent of α, k, h and H.

Proof. See [14, Appendix 3].

(cid:3)

OSM and DG

7

Ω1

Ω2

λ1

λ3

λ2

Ω3

Figure 2. A many subdomain conﬁguration with unknown dupli-
cation along interfaces.

3. Optimized Schwarz method for IPH

In this section we deﬁne and analyze an optimized Schwarz method (OSM) for
IPH discretizations. Since an IPH discretization is s.p.d. we can use an additive
Schwarz preconditioner in conjunction with CG. However it was ﬁrst observed in [8]
that the convergence mechanism of the additive Schwarz method for IPH is diﬀerent
from classical FEM. For an FEM discretization, the overlap between subdomains
makes the additive Schwarz method converge, while for IPH convergence is due
to a Robin transmission condition in a non-overlapping setting, and the Robin
parameter is exactly the penalty parameter of IPH, µ = α k2/h.

Robin transmission conditions are the core of OSM to obtain faster convergence
compared to the additive Schwarz method. It was shown in [7] that OSM’s best
performance is achieved if the Robin parameter is scaled like 1/√h. This how-
ever poses a contradiction with the IPH discretization penalty parameter since the
scaling of µ cannot be weakened otherwise coercivity and optimal approximation
properties are lost. In [9], the authors modiﬁed and analyzed an OSM while not
changing the scaling of µ. They showed that for the two subdomain case the OSM’s

contraction factor is ρ ≤ 1 − O(√h). This is a superior convergence factor com-
pared to additive Schwarz with ρ ≤ 1 − O(h). If OSM is used as preconditioner for
a Krylov subspace method, then a contraction factor of ρ ≤ 1−O(h1/4) is observed.
We will now deﬁne a many subdomain OSM for IPH with this property and
then analyze the solver and optimize the performance with respect to the mesh
parameter h and the polynomial degree k.

3.1. Deﬁnition of OSM. We now construct an OSM for the IPH discretization.
Observe that from (2.9), we can conclude that ui ∈ Vh,i is determined provided λh
is known. Recall also from (2.11) that two subdomains, say Ωi and Ωj for i 6= j,
are communicating using

λh =

1

2µ(cid:16)µui −

∂ui

∂ni(cid:17) +

1

2µ(cid:16)µuj −

∂uj

∂nj(cid:17),

on Γij.

Let us now assume that λh is double-valued across the interface Γ. Then we can
assign an interface unknown to each subdomain which we call λi for i = 1, . . . , Ns,
as illustrated in Figure 2. Therefore on each interface between two subdomains,

8

Martin J. Gander and Soheil Hajian

say Γij , we should introduce two conditions. We do so by splitting the continuity
condition in the following fashion:

(3.1)

γλi + (1 − γ)λj = 1
γλj = 1

(1 − γ)λi +

2µ(cid:16)µui − ∂ui
2µ(cid:16)µui − ∂ui

∂ni(cid:17) + 1
∂ni(cid:17) + 1

∂nj(cid:17),
2µ(cid:16)µuj − ∂uj
∂nj(cid:17),
2µ(cid:16)µuj − ∂uj

where γ ∈ R+ is a “suitable” parameter that we will use to optimize the iterative
method. Observe that if we subtract the two conditions in (3.1), we arrive at
(1 − 2γ)(λi − λj) = 0. If γ 6= 1
2 then we have λi = λj = λh on all Γij, i.e., we
recover the single-valued λh and therefore the solution to the augmented system
coincides with the original IPH approximation.

The conditions in (3.1) can be written in an equivalent variational form by mul-
tiplying them with appropriate test functions with support on ∂Ωi \ ∂Ω. The
advantage is that we can then use the original blocks of the IPH linear system. For
a subdomain, e.g., Ωi, we obtain
(3.2)
γ a(i)

λj ϕi +ZΓij (cid:16) ∂uj

∂nj − µuj(cid:17)ϕi = 0.

Γ (λi, ϕi) + aiΓ(ui, ϕi) + Xj∈N (i)

2µ(1 − γ)ZΓij

In order to clarify the deﬁnition of the new linear system we provide an example
in the case of two subdomains.

Example 3.1 (two subdomain case). Suppose we have two subdomains and we call
the interface between them Γ. Then an IPH discretization with this conﬁguration
looks like

(3.3)




A1

A1Γ
A2 A2Γ
A⊤1Γ A⊤2Γ AΓ







u1
u2
λ


 = 


f 1
f 2
0


 .

Observe that continuity between the two subdomains is imposed through the last
row of (3.3). We now suppose λ is double-valued across the interface, λ1, λ2. Then
we introduce two conditions for the two interface unknowns, λ1 and λ2,
γAΓλ1 + (1 − γ)AΓλ2 + A⊤1Γu1 + A⊤2Γu2 = 0,
γAΓλ2 + A⊤1Γu1 + A⊤2Γu2 = 0,

(1 − γ)AΓλ1 +

2 . If we regroup the unknowns according to the subdomain enumeration,

where γ 6= 1
then the “augmented” linear system looks like



A⊤2Γ
A2
(1 − γ)AΓ A⊤2Γ

A1Γ
γAΓ

A2Γ
γAΓ

A1
A⊤1Γ

(1 − γ)AΓ

A⊤1Γ

(3.4)







v1
λ1
v2
λ2




=




f 1
0
f 2
0




.

Note that provided γ 6= 1
sense that v1 = u1 and u2 = v2 and λ1 = λ2 = λ.

2 , the linear systems (3.3) and (3.4) are equivalent in the

The authors showed in [9] that for the convergence analysis of a block Jacobi
method applied to (3.4) we need to obtain sharp bounds on the eigenvalues of
A−1

Γ Bi where

(3.5)

Bi := A⊤iΓA−1

i AiΓ,

i = 1, 2.

OSM and DG

9

Such bounds were obtained in [9, Lemma 3.7]. We will further improve the eigen-
value bounds and also obtain sharp estimates with respect to the time step τ ,
η = τ−1.

We are now in the position to deﬁne the OSM for an IPH discretization. Formally
we ﬁrst construct the augmented system with double-valued interface unknowns
along the interfaces, i.e., (3.4). Then we rearrange the unknowns subdomain by
subdomain, i.e., collect {(ui, λi)}Ns
i=1 and ﬁnally we perform a block Jacobi method
on the augmented linear system with a suitable optimization parameter γ.
)(cid:9)Ns
Algorithm 3.2. Let (cid:8)(u(0)
Then for n = 1, 2, . . . ﬁnd (cid:8)(u(n)

be a set of initial guesses for all subdomains.

i=1
, λ(n)

such that

, λ(0)

i

i

i

i

)(cid:9)Ns
) = ZΩi
, vi) + aiΓ(vi, λ(n)

i=1

i

(3.6)

ai(u(n)

i

f vi,

∀vi ∈ Vh,i,

and the continuity condition on Γij reads

(3.7)

γλ(n)

i −

1

2µ(cid:16)µui −

∂ui

∂ni(cid:17)(n)

= −(1 − γ)λ(n−1)

j

+

1

2µ(cid:16)µuj −

∂uj

∂nj(cid:17)(n−1)

.

Since the solution of the augmented system coincides with the original IPH
linear system, we can conclude that Algorithm 3.2 has the same ﬁxed point as
the solution of the IPH discretization. There are some questions to be addressed
concerning Algorithm 3.2, e.g.,

(1) Is Algorithm 3.2 well-posed?
(2) Does Algorithm 3.2 converge? If yes, then can we obtain a contraction

factor?

(3) How to use the optimization parameter γ to improve the contraction factor?
(4) How do diﬀerent choice of η aﬀect the algorithm and its scalability?

We will answer these questions now in Section 3.2.

3.2. Analysis of OSM. The main goal of this section is to analyze Algorithm
3.2 and answer the questions regarding its well-posedness and convergence. Our
analysis is inspired by a similar result for FEM in [18, 19], and we refer the reader
to the original work of Lions in [16] for an analysis at the continuous level. Our
analysis is however substantially diﬀerent since DG methods impose continuity
across elements weakly. We will ﬁrst prove

Theorem 3.3 (Convergence estimate). Let the optimization parameter satisfy 1
2 <
γ ≤ 1. Then Algorithm 3.2 is well-posed and converges with the contraction factor
(3.8)

(2γ − 1)

,

ρ ≤ 1 − min

µ(2γ − 1)2 C(H, η) + 1

where µ = αk2/h is the penalization parameter and

C(H, η) := (cid:26) H in the case of no ﬂoating subdomains,

in the case of ﬂoating subdomains.

1
Hη

The choice γ = 1 is a special case.

It is shown in [9, 13] that in this case
Algorithm 3.2 is equivalent to a non-overlapping additive Schwarz method1 applied

1Non-overlapping additive Schwarz method for DG methods means non-overlapping both at

the algebraic level as well as continuous level in contrast to FEM.

10

Martin J. Gander and Soheil Hajian

to the primal formulation of IPH. The theory for s.p.d. preconditioners, i.e., the
abstract Schwarz framework, shows that the condition number of the one-level
additive Schwarz method for IPH is bounded by k2h−1H−1. This is equivalent to
a contraction factor ρ ≤ 1 − O( hH
k2 ). It is easy to see that our analysis also reveals
the same contraction factor in this special case: Let γ = 1 in (3.8) and recall that
µ = αk2/h. Then we have

(3.9)

k2 (cid:17),
ρ ≤ 1 − O(cid:16) hH

as h and H go to zero or k goes to inﬁnity.

Our Second objective of this section is to minimize the contraction factor through

a suitable choice of the optimization parameter γ. This is stated in

Corollary 3.4 (Optimized contraction factor). Let η = τ−1 where τ is the time-
step which is chosen to be O(1) or O(H) or O(H 2). Then the optimized contraction
factor for Algorithm 3.2 for the diﬀerent choices of τ is

(3.10)

ρopt ≤

√hH
k )
√h
k )

1 − O(
1 − O(
1 − O(q h

H

1
k )

for τ = O(1),
for τ = O(H),
for τ = O(H 2),

√hH
k ),
√h
k ),

if γopt = 1
if γopt = 1
if γopt = 1

2 (1 +
2 (1 +

2 (1 +q h

H

1
k ).




Observe that the h-dependency and k-dependency is weakened by a square-root
compared to (3.9). Moreover if the time-step is chosen to scale like a forward Euler
time-step, i.e., O(H 2), then Algorithm 3.2 is scalable.

Proof of Theorem 3.3. We ﬁrst show that Algorithm 3.2 is well-posed, i.e., we
satisfying

can actually iterate. By linearity we assume that f = 0. We call u(n)
(3.6) with f = 0 a discrete harmonic extension of λi in Ωi:

i

Deﬁnition 3.5 (Discrete harmonic extension). For all ϕi ∈ Λi, we denote by
Hi(ϕi) ∈ Vh,i the discrete harmonic extension into Ωi,
(3.11)

Hi(ϕ) ≡ −A−1

i AiΓϕi,

where Ai and AiΓ correspond to the bilinear forms ai(·,·) and aiΓ(·,·). The cor-
responding ϕi is called generator. In other words ui := Hi(ϕi) is an approxima-
tion obtained from the IPH discretization in Ωi using ϕi as Dirichlet data, i.e.,
Aiui + AiΓϕi = 0.

for all subdomains and simplify Algorithm 3.2

We proceed by eliminating u(n)

i
to: for all subdomains, ﬁnd λ(n)
(3.12)
γλ(n)

∂

1

i

such that

i

i −

2µ(cid:16)µ −

∂ni(cid:17)Hi(λ(n)

) = −(1 − γ)λ(n−1)

∂nj(cid:17)Hj(λ(n−1)
on Γij for all j ∈ N (i), where N (i) is the set of neighboring subdomains of Ωi. Let
us denote the linear operator on the left-hand side by Ri : Λi → Λi, that is
(3.13)

2µ(cid:16)µuj −

∂uj

+

),

1

j

j

Ri(ϕi) := γϕi −

1

2µ(cid:16)µ −

∂

∂ni(cid:17)Hi(ϕi).

If we show that Ri(·) is an invertible operator, then Algorithm 3.2 is well-posed.
We show Ri(·) is invertible by showing that it is injective:

OSM and DG

11

Lemma 3.6. If γ > 1
More precisely we have the estimate

2 then the operator Ri(·) is injective for all i = 1, . . . , Ns.

(3.14)

where

kRi(ϕi)kΓi ≥ (cid:16)γ −
c(h, H, k) := (cid:26) c h

0

H

1
2

+ c(h, H, k)(cid:17)kϕikΓi

,

∀ϕi ∈ Λi,

1
k2

for non-ﬂoating subdomains,
for ﬂoating subdomains.

Proof. We multiply Ri(ϕi) by ϕi and integrate over Γi,

ZΓi Ri(ϕi) ϕi = γkϕik2

Γi

+

1
2µ

aiΓ(ui, ϕi),

Γi

1
2

If γ > 1

where ui := Hi(ϕi). Recall that if ui is the harmonic extension of ϕi then ai(ui, ui)+
aiΓ(ui, ϕi) = 0. Therefore we have RΓi Ri(ϕi) ϕi = γkϕik2
2µ ai(ui, ui). We can
show that a(ui, ui) ≤ (cid:0)1 − c(h, H, k)(cid:1)µkϕik2

, see Appendix A, and obtain

Γi − 1

ZΓi Ri(ϕi) ϕi ≥ (cid:0)γ −

which completes the proof.

2 , then the right-hand side is positive. Now we apply the Cauchy-Schwarz

+ c(h, H, k)(cid:1)kϕik2
inequality to the left-hand side and obtain kRi(ϕi)kΓi ≥ (cid:0)γ − 1
2 + c(h, H, k)(cid:1)kϕikΓi
Since Ri(·) is linear and injective we conclude that it induces a local norm on
Λi. We can also deﬁne a global norm on the space of QNs
Yi=1
∀ϕ ∈

kR(ϕ)k2 :=

kRi(ϕi)k2

i=1 Λi by

Xi=1

(3.15)

Λi,

,

Γi

.

Γi

Ns

Ns

(cid:3)

where ϕ := (ϕ1, ϕ2, . . . , ϕNs). This turns out to be the right norm for the conver-
gence analysis of Algorithm 3.2.

We can now show that Algorithm 3.2 converges with a concrete contraction factor
estimate. The right-hand side of the iteration equation (3.12) can be simpliﬁed to

(3.16)

Ri(ϕ(n)

i

) = (2γ − 1)ϕ(n−1)

j

− Rj(ϕ(n−1)

j

),

on Γij for all j ∈ N (i). Note that 2γ−1 is strictly-positive with our condition γ > 1
2 .
For a given subdomain, say Ωi, we take the L2-norm on both sides. To simplify
the presentation, we suppress the iteration index for the moment, but terms on the
left-hand side are evaluated at iteration (n) while on the right-hand side they are
evaluated at iteration index (n − 1):

kRi(ϕi)k2

Γij

= kRj(ϕj) − (2γ − 1)ϕjk2
= kRj(ϕj)k2
= kRj(ϕj)k2

Γij

Γij

Γij

Γij − 2(2γ − 1)RΓij Rj (ϕj) ϕj

+ k(2γ − 1)ϕjk2
+(cid:2)(2γ − 1)2 − 2(2γ − 1)γ(cid:3)kϕjk2
∂nj(cid:1)ϕj
µ (2γ − 1)RΓij (cid:0)µuj − ∂uj
µ RΓij (cid:0)µuj − ∂uj
Γij − 1

Γij − (2γ − 1)hkϕjk2

∂nj(cid:1)ϕji.

+ 1

Γij

= kRj(ϕj)k2

12

Martin J. Gander and Soheil Hajian

Then we sum over all interfaces of Ωi and all subdomains to obtain
(3.17)

kR(ϕ)k2 = PNs

i=1Pj∈N (i) kRj(ϕj )k2

Γij

where for the left-hand side we used

kRi(ϕi)k2

Γi

=: kR(ϕ)k2,

∂nj(cid:1)ϕji

−(2γ − 1)µ−1hµkϕjk2
m=1hµkϕmk2
m=1hµkϕmk2

Γij −RΓij (cid:0)µuj − ∂uj
+ amΓ(um, ϕm)i
Γm − am(um, um)i

Γm

m=1 k(um, ϕm)k2
m,

= kR(ϕ)k2

−(2γ − 1)µ−1PNs
−(2γ − 1)µ−1PNs

= kR(ϕ)k2
≤ kR(ϕ)k2 − c(2γ − 1)µ−1PNs
Xi=1 Xj∈N (i)
µkϕmk2

kRi(ϕi)k2

Xi=1

=

Γij

Ns

Ns

and for the right-hand side we used the coercivity inequality
Γm − am(um, um) ≥ ck(um, ϕm)k2
m,

see Appendix A for details. Note that k(um, ϕm)km is subdomain-wise positive
deﬁnite if η > 0. More precisely we can show that if η > 0 then for all subdomains,
even ﬂoating ones, we have the estimate

(3.18)

where

(3.19)

kRm(ϕm)k2

Γm ≤ (cid:16)(2γ − 1)2C(H, η) + µ−1(cid:17)k(um, ϕm)k2

m,

C(H, η) := (cid:26) H for non-ﬂoating subdomain,

for ﬂoating subdomain.

1
Hη

We then insert the norm estimate (3.18) into the last inequality of (3.17) and

Note that (3.18) makes sense only if η > 0 since k(·,·)km is only a semi-norm
is a norm, see Appendix A, in
for ﬂoating subdomains if η = 0 while kRm(·)kΓm
term in (A.7) for simplicity
particular (A.9) and (A.7). We have ignored the ηkuikΩi
of the exposition; the ηkuikΩi
reintroduce the iteration index to obtain
(3.20)
kR(ϕ(n))k
which shows convergence and proves Theorem 3.3.

µ(2γ − 1)2(Hη)−1 + 1o(cid:17)kR(ϕ(n−1))k

term in (A.7) will be exploited in Section 3.3.

≤ (cid:16)1−minn

µ(2γ − 1)2H + 1

2γ − 1

2γ − 1

2

2

,

,

Proof of Corollary 3.4. We need to choose a suitable γ > 1

2 to achieve the best
possible contraction factor. In order to weaken dependencies on the mesh param-
eter, subdomain diameter and polynomial degree, we make for the optimization
parameter the ansatz

(3.21)

γ =

1

2(cid:16)1 +

hξH ζ

kψ (cid:17),

with ξ, ζ, ψ ∈ R to be chosen. We would like to minimize the contraction factor,
i.e.,
k2−ψh2ξ−1H 2ζ−1η−1 + kψo.

k2−ψh2ξ−1H 2ζ+1 + kψ ,

(3.22) ρopt ≤ 1 − max

minn

hξH ζ

hξH ζ

ξ,ζ,ψ

OSM and DG

13

When dealing with parabolic problems, η = τ−1 and τ is the time-step. Therefore
it is reasonable to optimize γ for diﬀerent choices of the time-step.

• τ = O(1): we start with the dependence on the polynomial degree. Observe
that the weakest dependence is achieved if we let ψ = 1. This leads to
ρ ≤ 1 − O( 1
k ), which compares very favorably to (3.9). Now we consider
the case where H is ﬁxed and we reﬁne the mesh, h → 0. Then ξ = 1
2 is
√h
the optimal choice which yields ρ ≤ 1 − O(
k ). This leads to a simpliﬁed
bound for ρopt, namely

ρopt ≤ 1 − max

ζ

minn

H ζ

H 2ζ+1 + 1

,

H ζ

H 2ζ−1 + 1oO(

√h
k

).

The optimal value for ζ is therefore 1
eter and corresponding contraction factor

2 . We thus obtain the optimal param-

(3.23)

γopt :=

1

2(cid:16)1 +

√hH
k (cid:17),

ρopt ≤ 1 − O(cid:0)

√hH
k (cid:1),

if τ = O(1).

• τ = O(H): The best parameters with respect to k and h follow the same

argument as before. For optimization with respect to H we have now

ρopt ≤ 1 − max

ζ

minn

H ζ

H 2ζ+1 + 1

,

H ζ

H 2ζ + 1oO(

√h
k

).

In this case we can eliminate the H-dependence by choosing ζ = 0. Hence
we have

(3.24)

γopt :=

1

2(cid:16)1 +

√h
k (cid:17),

ρopt ≤ 1 − O(cid:0)

√h
k (cid:1),

if τ = O(H).

• τ = O(H 2): This case is comparable to using a forward Euler method
where τ is required to be proportional to h2. This is a typical constraint
when dealing with parabolic problems and accurate trajectories in time are
needed, but one could still take larger time steps in our setting than with
forward Euler due to a larger constant. We proceed as before by choosing
the same parameters with respect to k and h. For the H-dependence we
have

ρopt ≤ 1 − max

H 2ζ+1 + 1
The optimal parameter hence is ζ = − 1

ζ

minn

H ζ

,

H ζ

H 2ζ+1 + 1oO(

2 which yields

√h
k

).

(3.25)

γopt :=

1

2(cid:16)1 +r h

H

1

k(cid:17),

ρopt ≤ 1 − O(cid:0)r h

H

1

k(cid:1),

if τ = O(H 2).

Note that this choice of γopt is still feasible since h ≤ H and therefore
γopt ≤ 1. This shows that the method is weakly scalable if we choose a
small enough time-step, without the need of a coarse solver. A similar
result for the additive Schwarz method and FEM exists, see [3, Theorem
4].

This completes the proof of Corollary 3.4.

14

Martin J. Gander and Soheil Hajian

3.3. A reﬁned contraction factor with respect to the time-step. In the
previous section we have shown how diﬀerent choices of η aﬀect the contraction
factor when we reﬁne subdomains. However one may also ask how diﬀerent choices
of η aﬀect the contraction factor when the number of subdomains is ﬁxed. This has
so far not been addressed, neither in [18] nor in the authors’ paper [9] which deals
with two subdomains only.

Suppose for the moment that we have two subdomains. Then as mentioned in
Example 3.1 and proved in [9] the convergence of the OSM is governed by the
eigenvalues of A−1
i AiΓ. We would like to obtain eigenvalue
estimates that depend on η.

Γ Bi where Bi := A⊤iΓA−1

Recall the deﬁnition of Ai from (2.4), and let us decompose Ai into the mass

matrix Mi and the stiﬀness matrix Ki,

Ai := ηMi + Ki,

where Ki is deﬁned as v⊤i Kiu⊤i

ui vi. Consider now

:= ai(ui, vi) − ηRΩi
ˆA := (cid:20) Ki + ηMi AiΓ

A⊤iΓ

2 AΓ (cid:21) ,

1

which is coercive, i.e., for all w := (ui, ϕ) we have (see [9, Equation 3.6]),

(3.26)

w⊤ ˆAw ≥ ck(ui, ϕ)k2

i ≥ η u⊤i Miui +

c
H kϕk2
Γ,

where the last inequality is Lemma A.1. On the other hand we can easily verify
that for ui := Hi(ϕ) we have
(3.27)

ϕ⊤Biϕ = u⊤i (cid:0)Ki + ηMi(cid:1)ui ≤ (cid:0)Ch−2 + η(cid:1)u⊤i Miui,

where we have used the fact that σ(M−1
i Ki) ∈ [c1, c2 h−2], which is usual for elliptic
operators, see for instance [4, Theorem 3.4]. For w := (Hi(ϕ), ϕ), observing that

1
2

ϕ⊤AΓϕ − ϕ⊤Biϕ = w⊤ ˆAw,

and using (3.26) we have

1
ϕ⊤AΓϕ − ϕ⊤Biϕ ≥
2
2 ϕ⊤AΓϕ = µkϕk2

Recalling that 1

Γ we can conclude

η

Ch−2 + η

ϕ⊤Biϕ +

c
H kϕk2
Γ.

(3.28)

(cid:18)

1

1+Cη h2 (cid:19)(cid:16)1 − c

1 + Cη h2

h

Hα(cid:17)µkϕk2

Γ ≥ ϕ⊤Biϕ.

We can then use a Rayleigh quotient argument and obtain an upper bound for
σ(A−1
Γ Bi). Inequality (3.28) is of great importance since it shows the dependency of
Algorithm 3.2 on η when the number of subdomains is ﬁxed. In particular, observe
that for η = O(h−2) we have

ϕ⊤Biϕ ≤ (cid:16) 1 − C2 h

1 + C3 (cid:17)µkϕk2

Γ ≤ (cid:16)

1

1 + C3(cid:17)µkϕk2

Γ.

This shows that with a time-step of the size of a forward Euler method, the algo-
rithm converges in a ﬁxed number of iterations since

< 1 uniformly in h.

1

1+C3

OSM and DG

15

We now focus on the case where we have many non-ﬂoating subdomains. In the
previous section we did not fully exploit (A.7), i.e., the right-hand side ηkuikΩi
term. The main step is to establish the inequality

(3.29)

c µkRi(ϕi)k2

i ≤ ϕ⊤Biϕ,

and then to use (3.27) to obtain

(cid:16)

η

η + C h−2(cid:17) · c µkRi(ϕi)k2

i ≤ ηkuik2

Ωi

.

Let us consider the case with γ = 1. Inserting the above estimate back into (A.7)
and then into (3.17) gives

2

kR(ϕ(n))k

≤ (cid:16)1 − C1

η

η + C2h−2 − CDD(h, k)(cid:17)kR(ϕ(n−1))k

2

,

where CDD(h, k) is the constant in (3.20). Note that for η = O(h−2) the above
estimate provides a contraction factor independent of the mesh parameter.

It remains to prove (3.29). We take the L2 norm of R(ϕi) and use the triangle

and Young’s inequality to obtain
kRi(ϕi)k2

Γi ≤ 2γ2kϕik2

Γi

+

1
2µ2kzik2

Γi

,

Γi

= ϕ⊤i BiM−1
Γi

Biϕi. Then we have

:= (µ − ∂ni )ui ∈ Λi. We know from [9, Proposition 2.4] that zi =

where zi
M−1
Γi
kzik2
since Bi is s.p.d. A simple calculation shows that σ(B1/2
Recall that AΓi = 2µMΓi. Then for zi we have from the eigenvalues of A−1
Γi
[9, Equation 3.1],

) = σ(M−1
Bi).
Γi
Bi, see

Biϕ = ϕ⊤i BiM−1
Γi

Biϕi = ϕ⊤i B1/2

(B1/2

i M−1
Γi

MΓi M−1
Γi

i M−1
Γi

B1/2

i

i

B1/2

i

)B1/2

i ϕi,

kzik2

Γi ≤ 2µ · σmax(A−1

Γi

Bi) · ϕ⊤i Biϕi ≤ 2µ · ϕ⊤i Biϕi.

This yields

kRi(ϕi)k2

Γi ≤ 2γ2kϕik2

Γi

+ µ−1ϕ⊤i Biϕi ≤ 2kϕik2

Γi

+ µ−1ϕ⊤i Biϕi,

since γ ≤ 1. The last step is to use kϕik2
for the eigenvalues of A−1
Γi
Hence we proved (3.29).

B µ−1ϕ⊤i Biϕi, i.e., the lower bound
Bi, see [9, Equation 3.1] where cB is independent of η.

Γi ≤ c−1

4. Numerical experiments

We now illustrate our theoretical results by performing some numerical experi-

ments for the model problem

(4.1)

(η − ∆)u = f,
u = 0,

in Ω,
on ∂Ω,

where Ω is either the unit square, i.e. Ω = (0, 1)2, or the domain presented in Figure
1. The interface is such that it does not cut through any element, therefore Γ ⊂ E.
We use Pk elements and α = c(k + 1)(k + 2) where c > 0 is a constant independent
of h and k. We choose also a randomized initial guess for Algorithm 3.2.

16

Martin J. Gander and Soheil Hajian

✶

✵

✵

1

y

①

✶

0

0

x

1

Figure 3. An unstructured mesh with the interface Γ (blue-dashed).

Mesh size
# iterations

h0 h0/2 h0/4 h0/8 h0/16
117
25

57

82

35

Table 1. Convergence of OSM for four subdomains (h-dependence).

Polynomial degree
# iterations

3

2
446 555 685 812 938

5

6

4

Table 2. Convergence of OSM for two subdomains (k-dependence).

Polynomial degree
# iterations

3

2
732 1120 1600 2102 2640

5

6

4

Table 3. Convergence of OSM for seven subdomains (k-dependence).

4.1. Dependence on the mesh size. In [9, Section 6.3], we have already investi-
gated numerically the convergence behavior of OSM for IPH for a many subdomain
conﬁguration, and we show in Table 1 from [9, Section 6.3] that indeed for a unit
square domain decomposed into four subdomains (see Figure 3 left) the number of
iterations grows like h−1/2 when we reﬁne the mesh, provided that γ = 1
as our new theoretical analysis predicts.

2 (1 + √h),

4.2. Dependence on the polynomial degree. We next illustrate how the con-
traction factor of Algorithm 3.2 depends on the polynomial degree. First, we choose
a two subdomain conﬁguration with a non-straight interface (see Figure 3 right)
for Ω = (0, 1)2. Then we choose γ = 1
2 (1 + 1
k ), η = 1 and run Algorithm 3.2. We
expect from our analysis to obtain ρ ≤ 1− O( 1
k ), which is indeed observed in Table
2.

Then we choose Ω to be the domain in Figure 1 with seven subdomains (including
ﬂoating ones). We observe in Table 3 that the number of iterations grows like
O(k−1), which is expected from our analysis.

4.3. Eﬀect of the time-step on convergence. In Section 3.3 we showed how the
convergence of the two subdomain algorithm is aﬀected by the choice of η. In Table

②
OSM and DG

17

case η = O(1)
case η = O(h−1)
case η = O(h−2)

h0
103
41
16

h0/2 h0/4 h0/8
214
820
115
60
16
14

405
83
15

Table 4. Convergence of Algorithm 3.2 with γ = 1 and diﬀerent
choices of η.

experiments

theoretical

case η = O(1)
case η = O(h−1)
case η = O(h−2)

1 − h
1 − √h
1 − c

Table 5. Comparison of contraction factors between the theoret-
ical estimates of Section 3.3 and the numerical experiments.

1 − h
1 − h
1 − c

(sharp)

(not sharp)

(sharp)

Mesh size
h0
# iterations 144

h0/2 h0/4 h0/8
157
164

168

Table 6. Convergence of OSM for four subdomains with η = O(h−2).

4 we see the number of iterations required to reach a given accuracy for diﬀerent
choices of η. The domain decomposition setting is same as Figure 3 (right).

Observe that for η = O(1), the number of iterations grows like O(h−1) while for
η = O(h−1) we observe O(h−1/2) for the growth of the number of iterations. If
we choose η = O(h−2), we obtain an optimal solver since the number of iterations
does not depend on the mesh parameter.

In Table 5 we compare the theoretical estimate in (3.28) with the numerical
experiments of Table 4. Note that the estimates of Section 3.3 can capture the
optimality of the solver when η = O(h−2). However it is not sharp when η =
O(h−1).

We perform the same experiment with four subdomains on Ω = (0, 1)2 and we
choose η = O(h−2). We see in Table 6 that the number of iterations remains
constant as we reﬁne the mesh.

5. Conclusion

We designed and analyzed an optimized Schwarz method (OSM) for the solution
of elliptic problems discretized by hybridizable interior penalty (IPH) discontinuous
Galerkin methods. Our results are a generalization of the two subdomain analysis
in [9] to the case of many subdomains, and we also study theoretically for the ﬁrst
time the inﬂuence of the polynomial degree of IPH discretizations, and the eﬀect
of the time-step on the convergence of OSM when solving parabolic problems. We
derived the optimized parameter and corresponding contraction factor for various
asymptotic regimes of the mesh and subdomain size and the time-step, and obtained
scalability without a coarse space and also mesh independent solvers in certain
speciﬁc regimes. We validated our theoretical results by numerical experiments.
The optimized contraction factor shows a clear advantage of OSM compared to
the additive Schwarz method. The next step is to design and analyze a coarse

18

Martin J. Gander and Soheil Hajian

correction for these OSM solvers applied to IPH in the regimes where Algorithm
3.2 is not scalable.

Appendix A. Proof of some estimates

We now prove several technical estimates we used in the analysis of the OSM for

IPH. For all subdomains when η ≥ 0 we have the inequalites
(A.1)

Γi − ai(vi, vi) ≥ ck(vi, ϕi)k2
i ,

µkϕik2

∀ϕi ∈ Λi, vi = Hi(ϕi),
∀ϕi ∈ Λi, vi = Hi(ϕi),

(A.2)

where

(cid:0)1 − c(h, H, k)(cid:1)µkϕik2
c(h, H, k) := (cid:26) h

H
0

Γi ≥ ai(vi, vi),

1
k2

for non-ﬂoating subdomains,
for ﬂoating subdomains.

We also have for all subdomains when η > 0 the estimate

(A.3)

where

Γi ≤ (cid:16)(2γ − 1)2C(H, η) + µ−1(cid:17)k(ui, ϕi)k2
kRi(ϕi)k2
C(H, η) := (cid:26) H for non-ﬂoating subdomain,

for ﬂoating subdomain.

1
Hη

i ,

We ﬁrst recall an inequiality related to the coercivity of the IPH method, that is

ai(vi, vi) + 2aiΓ(vi, ϕi) + µkϕik2

(A.4)
For a proof see [15, 9]. The proof of (A.1) is obtained by choosing vi := Hi(ϕi)
in (A.4) and recalling the deﬁnition of the harmonic extension which leads to
ai(vi, vi) + aiΓ(vi, ϕi) = 0. Substituting this into (A.4) proves (A.1).

Γi ≥ ck(vi, ϕi)k2
i ,

∀ϕi ∈ Λi, vi ∈ Vh,i.

In order to prove (A.2) we decompose the proof into two parts: ﬂoating sub-
domains and non-ﬂoating ones. Recall that k(·,·)ki is a semi-norm for ﬂoating
subdomains if η = 0, i.e., the kernel consists of constant functions. This concludes
the proof for ﬂoating subdomains with c(h, H, k) = 0. For non-ﬂoating subdomains
we recall a trace inequality for totally discontinuous functions, see [9, Lemma 3.6]
and [2]:
Lemma A.1. Let ϕi ∈ Λi and ui ∈ Vh,i. Let Hi be the diameter of a non-ﬂoating
subdomain. Then we have

(A.5)

c

Hikϕik2

Γi ≤ k∇uik2

Ωi

+ µk[[ui]]k2

Ei\Γi

+ µkui − ϕik2

Γi

.

proves (A.2) for non-ﬂoating subdomains with c(h, H, k) = h
H

We then substitute (A.5) into (A.1) and recalling the deﬁnition of k(ui, ϕi)ki
We now prove (A.3). Recall that the L2-norm of the Ri(·) is a norm while k(·,·)ki
is only a semi-norm for ﬂoating subdomains if η = 0. Therefore (A.3) makes sense
for η > 0. Recall the deﬁnition of the Ri(·) operator,
2(cid:1)ϕi +

∂ni(cid:17)ui = (cid:0)γ −

2(cid:0)ϕi − ui(cid:1) +

Ri(ϕi) := γϕi −

2µ(cid:16)µ −

where ui = Hi(ϕi). We then take the L2-norm over Γi and apply the triangle
inequality,

∂ui
∂ni

1
2µ

1
k2 .

∂

1

1

1

,

(A.6)

kRi(ϕi)k2

Γi ≤ 4(cid:0)γ − 1
2(cid:1)2
≤ 4(cid:0)γ − 1
2(cid:1)2
2(cid:1)2
≤ 4(cid:0)γ − 1

Γi

kϕik2
kϕik2
kϕik2

Γi

Γi

Γi

2 )2kϕi − uik2
+ 4( 1
+ kϕi − uik2
+ cµ−1(cid:0)µkϕi − uik2

+ 4(cid:0) 1
2µ(cid:1)2
k ∂ui
∂nik
+ cµ−1k∇uik2
,
Ωi(cid:1).
+ k∇uik2

Ωi

Γi

Γi

2

Γi

,

OSM and DG

19

For non-ﬂoating subdomains we use Lemma A.1 for the ﬁrst term on the right-hand
side and obtain
(A.7)

(cid:16)(2γ − 1)2Hi + cµ−1(cid:17)ηkuik2

Ωi

+ kRi(ϕi)k2

Γi ≤ (cid:16)(2γ − 1)2Hi + cµ−1(cid:17)k(ui, ϕi)k2

i .

For ﬂoating subdomains we use a trace inequality by Feng and Karakashian [6,
Lemma 3.1],

kuik2

(A.8)
We then invoke kϕik2
of k(ui, ϕi)k to obtain

Γi ≤ chH−1

i kuik2
Γi ≤ 2kuik2

Γi

Ωi

+ Hi(cid:0)k∇uik2
+ 2kui − ϕik2

Γi

Ωi

kϕik2

Γi ≤

C

Hiηk(ui, ϕi)k2
i .

+ h−1k[[ui]]k2

Ei\Γi(cid:1)i.

, use (A.8) and recall the deﬁnition

Substituting this estimate back into (A.6) yields

(A.9)

kRi(ϕi)k2

Γi ≤ (cid:16)(2γ − 1)2 · C · (Hiη)−1 + cµ−1(cid:17)k(ui, ϕi)k2

i .

References

1. Douglas N. Arnold, Franco Brezzi, Bernardo Cockburn, and L. Donatella Marini, Uniﬁed
analysis of discontinuous Galerkin methods for elliptic problems, SIAM J. Numer. Anal. 39
(2001/02), no. 5, 1749–1779. MR 1885715 (2002k:65183)

2. Susanne C. Brenner, Poincar´e-Friedrichs inequalities for piecewise H 1 functions, SIAM J.

Numer. Anal. 41 (2003), no. 1, 306–324. MR 1974504 (2004d:65140)

3. Xiao-Chuan Cai, Additive Schwarz algorithms for parabolic convection-diﬀusion equations,

Numerische Mathematik 60 (1991), no. 1, 41–61 (English).

4. Paul Castillo, Performance of discontinuous Galerkin methods for elliptic PDEs, SIAM J.

Sci. Comput. 24 (2002), no. 2, 524–547. MR 1951054 (2003m:65200)

5. Bernardo Cockburn, Jayadeep Gopalakrishnan, and Raytcho Lazarov, Uniﬁed hybridization
of discontinuous Galerkin, mixed, and continuous Galerkin methods for second order elliptic
problems, SIAM J. Numer. Anal. 47 (2009), no. 2, 1319–1365. MR 2485455 (2010b:65251)

6. Xiaobing Feng and Ohannes A. Karakashian, Two-level additive Schwarz methods for a dis-
continuous Galerkin approximation of second order elliptic problems, SIAM J. Numer. Anal.
39 (2001), no. 4, 1343–1365 (electronic). MR 1870847 (2003a:65113)

7. Martin J. Gander, Optimized Schwarz methods, SIAM J. Numer. Anal. 44 (2006), no. 2,

699–731 (electronic). MR 2218966 (2007d:65121)

8. Martin J. Gander and Soheil Hajian, Block Jacobi for discontinuous Galerkin discretizations:
no ordinary Schwarz methods, Domain Decomposition Methods in Science and Engineering
XXI, Lect. Notes Comput. Sci. Eng. Springer (2013).

9. Martin J. Gander and Soheil Hajian, Analysis of Schwarz methods for a hybridizable dis-
continuous Galerkin discretization, SIAM Journal on Numerical Analysis 53 (2015), no. 1,
573–597.

10. Martin J Gander and Felix Kwok, Best Robin parameters for optimized Schwarz methods at

cross points, SIAM Journal on Scientiﬁc Computing 34 (2012), no. 4, A1849–A1879.

11.

, On the applicability of Lions energy estimates in the analysis of discrete optimized
Schwarz methods with cross points, Domain Decomposition Methods in Science and Engineer-
ing XX, Springer, 2013, pp. 475–483.

12. Martin J. Gander and K´evin Santugini, Cross-points in domain decomposition methods with

a ﬁnite element discretization, revised (2015).

13. Soheil Hajian, An optimized Schwarz algorithm for discontinuous Galerkin methods, Domain

Decomposition Methods in Science and Engineering XXII (2014).

14. Soheil Hajian, Analysis of Schwarz methods for discontinuous Galerkin discretizations, 06/04

2015, ID: unige:75225.

15. Christoph Lehrenfeld, Hybrid discontinuous Galerkin methods for incompressible ﬂow prob-

lems, Master’s thesis, RWTH Aachen, 2010.

20

Martin J. Gander and Soheil Hajian

16. P.-L. Lions, On the Schwarz alternating method. III. A variant for nonoverlapping sub-
domains, Third International Symposium on Domain Decomposition Methods for Partial
Diﬀerential Equations (Houston, TX, 1989), SIAM, Philadelphia, PA, 1990, pp. 202–223.
MR 1064345 (91g:65226)

17. S´ebastien Loisel, Condition number estimates for the nonoverlapping optimized Schwarz
method and the 2-Lagrange multiplier method for general domains and cross points, SIAM
Journal on Numerical Analysis 51 (2013), no. 6, 3062–3083.

18. LiZhen Qin, ZhongCi Shi, and XueJun Xu, On the convergence rate of a parallel nonover-
lapping domain decomposition method, Sci. China Ser. A 51 (2008), no. 8, 1461–1478.
MR 2426076 (2010d:65364)

19. Lizhen Qin and Xuejun Xu, On a parallel Robin-type nonoverlapping domain decomposition

method, SIAM Journal on Numerical Analysis 44 (2006), no. 6, pp. 2539–2558 (English).

Section de math´ematiques, Universit´e de Gen`eve, Geneva, Switzerland
E-mail address: martin.gander@unige.ch

Institut f¨ur Mathematik, Humboldt-Universit¨at zu Berlin, Berlin, Germany
E-mail address: soheil.hajian@hu-berlin.de

