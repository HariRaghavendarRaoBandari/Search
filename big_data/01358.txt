ADAPTIVE FINITE ELEMENT METHOD FOR FRACTIONAL

DIFFERENTIAL EQUATIONS USING HIERARCHICAL MATRICES ∗

XUAN ZHAO † , XIAOZHE HU‡ , WEI CAI§ , AND GEORGE EM KARNIADAKIS¶

Abstract. We develop a fast solver for the fractional diﬀerential equation (FDEs) involving
It is based on the use of hierarchical matrices (H-Matrices) for the
Riesz fractional derivative.
representation of the stiﬀness matrix resulting from the ﬁnite element discretization of the FDE and
employs a geometric multigrid method for the solution of the algebraic system of equations. We
also propose an adaptive algorithm based on a posteriori error estimation to deal with general-type
singularities arising in the solution of the FDE. Through various test examples we demonstrate the
eﬃciency of the method and the high-accuracy of the numerical solution even in the presence of
singularities.

Key words. Riesz derivative, Hierarchical Matrices, geometric multigrid method, adaptivity,

non-smooth solutions, ﬁnite element method

AMS subject classiﬁcations. 80M10, 65M15, 65M55, 26A33, 41A25

1. Introduction. Numerical methods for diﬀerential equations involving frac-
tional derivatives either in time or space have been studied widely since they have
various new scientiﬁc applications [5, 27, 28, 30, 31, 33, 34]. However, as the size
of the problem increases, the time required to solve the ﬁnal system of equations
increases considerably due to the nonlocality of the fractional diﬀerential opera-
tors [4, 9–11, 22, 25, 29, 35, 36, 39, 42]. Generally, there are two main diﬃculties in
solving space fractional problems. First, the discretization matrix obtained by the
utilization of the numerical methods is fully populated. This leads to increased stor-
age memory requirements as well as increased solution time. Since the matrix is dense,
the memory required to store its coeﬃcients is of order O(N 2), where N denotes the
number of unknowns, and the solution of the system requires O(N 3) operations if
direct solvers are used. Second, the solution of a space fractional problem has sin-
gularities around the boundaries even with smooth input data since the deﬁnition
involves the integration of weak singular kernels.

So far good progress has been made on reducing the computational complexity
of the space FDEs for uniform mesh discretizations based on the observation that
the coeﬃcient matrices are Toeplitz-like if a uniform mesh is employed. This results
in eﬃcient matrix-vector multiplications [16, 19, 26, 37, 40], which in conjunction with
eﬀective preconditioners lead to enhanced eﬃciency [15, 18, 21, 24, 38]. The multigrid
method [7, 17, 26, 46] has also been employed to reduce the computational cost to
O(N log(N )). However, to the best of our knowledge, most of the existing fast solvers
depend on the Toeplitz-like structure of the matrices, which implies that the under-

6
1
0
2

 
r
a

M
4

 

 
 
]

.

A
N
h
t
a
m

[
 
 

1
v
8
5
3
1
0

.

3
0
6
1
:
v
i
X
r
a

and Beyond: Theory, Numerics and Applications (W911NF-15-1-0562)” .

∗This work was supported by the OSD/ARO/MURI on ”Fractional PDEs for Conservation Laws
†Division of Algorithms, Beijing Computational Science Research Center, Beijing 100084, P.
R. China, Department of Mathematics, Southeast University, Nanjing 210096, P. R. China,
(xuanzhao11@gmail.com; xuanzhao11@seu.edu.cn).

(xiaozhe.hu@tufts.edu).

‡Department
Tufts University, Medford, MA 02155 USA,
§Division of Algorithms, Beijing Computational Science Research Center, Beijing 100084, P. R.
China, and Department of Mathematics and Statistics, University of North Carolina at Charlotte,
Charlotte, NC 28223-0001, (wcai@csrc.ac.cn).
¶Division of Applied Mathematics, Brown University, Providence, RI 02912, USA,

of Mathematics,

(george karniadakis@brown.edu).

1

2

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

lying meshes have to be uniform. Therefore, the existing eﬃcient solvers cannot be
readily applied when a nonuniform mesh is used, including the important case of non-
uniform (geometric) meshes generated by adaptive discretizations employed to deal
with boundary singularities. Another eﬀective approach in dealing with such singu-
larities is by tuning the appropriate basis, e.g.. in Galerkin and collocation spectral
methods. For example, the weighted Jacobi polynomials can be used to accommo-
date the weak singularity if one has some information about the solution [8, 43–45];
the proper choice of the basis results in signiﬁcant improvement in the accuracy of
numerical solutions. However, in the current work we assume that we do not have
any information on the non-smoothness of the solution.

H-Matrices [13, 20] have been developed over the last twenty years as a powerful
data-sparse approximation of dense matrices. This representation has been used for
solving integral equations and elliptic partial diﬀerential equations [1, 3, 14, 32]. The
main advantage of H-Matrices is the reduction of storage requirement, e.g. when
storing a dense matrix, which requires O(N 2) units of storage, while H-Matrices
provide an approximation requiring only O(N k log(N )) units of storage, where k is
a parameter controlling the accuracy of the approximation.

In this work, instead of using the Topelitz-like structure of the matrices to reduce
the computational complexity, we adapt the H-Matrices representation to approxi-
mate the dense matrices arising from the discretization of the FDEs. Our H-Matrices
approach does not restrict to the uniform meshes and can be easily generalized to the
non-uniform meshes Therefore, it is suitable for the adaptive ﬁnite element method
(AFEM) for FDEs. We will show theoretically that the error of such H-Matrices
representation decays like O(3−k) while the storage complexity is O(N k log(N )).
Moreover, in order to solve the linear system involving H-Matrices eﬃciently, we de-
velop a geometric multigrid (GMG) method based on the H-Matrices representations
and the resulting GMG method converges uniformly, which implies that the over-
all computational complexity for solving the linear system is O(N k log(N )). Since
our H-Matrices and GMG methods can be applied to non-uniform meshes, we also
designed an adaptive ﬁnite element method (AFEM) for solving the FDEs. Similar
to the standard AFEM for integer-order partial diﬀerential equations, our AFEM
algorithm involves four main modules: SOLVE, ESTIMATE, MARK, and REFINE. Here,
the H-Matrices approach and GMG method are used in the SOLVE module to reduce
the computational cost. An a posteriori error estimator based on gradient recovery
approach is applied in the ESTIMATE module. Standard D¨oﬂers marking strategy
and bisection reﬁnement are employed in the MARK and REFINE, respectively. Thanks
to the newly designed algorithm for solving the linear system of equations, the new
AFEM for FDEs achieves the optimal computational complexity, while it also obtains
the optimal convergence order. The key to such AFEM algorithm for FDEs is the
optimal linear solver we developed based on H-Matrices representation and the GMG
method.

The remainder of the paper is structured as follows. In Section 2, we introduce
the FDE considered in this work. Its ﬁnite element discretization and H-Matrices rep-
resentation are discussed in Section 3. In Section 4, we introduce the GMG method
based on the H-Matrices representation. The overall AFEM algorithm is discussed in
detail in Section 5, and numerical experiments are presented in Section 6 to demon-
strate the high eﬃciency and accuracy of the proposed new method.

Adaptive FEM for FDEs using H-Matrices

3

2. Preliminaries. In this section, we present some notations and lemmas which

will be used in the following sections.

Definition 2.1. The fractional integral of order α, which is a complex number

in the half-plane Re(α) > 0, for the function f (x) is deﬁned as

(cid:90) x

I α
x f )(x) =

(xL

1

Γ(α)

xL

f (s)

(x − s)1−α ds,

x > xL.

Definition 2.2. The Caputo fractional derivative of order α ∈ (1, 2) for the

function f (x) is deﬁned as

Dα
x f )(x) = xL

I 2−α

x

( C
xL

(cid:20) d2

(cid:21)

dx2 f (x)

=

1

Γ(2 − α)

f(cid:48)(cid:48)(s)

(x − s)α−1 ds,

x > xL.

Definition 2.3. The Left Riemann-Liouville fractional derivative of order α ∈

(1, 2) for the function f (x) is deﬁned as

(cid:2)(xL

I 2−α

x

f )(x)(cid:3) =

Dα
x f )(x) =

(RL
xL

d2
dx2

1

Γ(2 − α)

d2
dx2

f (s)

(x − s)α−1 ds,

x > xL.

Definition 2.4. The Right Riemann-Liouville fractional derivative of order α ∈

(1, 2) for the function f (x) is deﬁned as

(RL

xDα

xR

f )(x) =

1

Γ(1 − α)

− d2
dx2

f (s)

(s − x)α−1 ds,

x < xL.

(cid:18)

(cid:19)(cid:90) xR

x

Definition 2.5. [31] The Riesz fractional derivative of order α ∈ (1, 2) for the

function f (x) is deﬁned as

(cid:90) x

xL

(cid:90) x

xL

(cid:90) xR

x f (x) = −
Dα
= −

1

d2
dx2

2 cos(απ/2)Γ(2 − α)
xL
Dα
x f (x) + RL

(cid:2)RL

1

xL

2 cos(απ/2)

x Dα

xR

f (x)(cid:3) .

|x − ξ|1−αf (ξ) dξ

3. Discretization of the problem based on H-Matrices representation.

We consider the following fractional diﬀerential equation

Dα
x u(x) = f (x), x ∈ (b, c), 1 < α < 2,

(3.1)

where f ∈ L2([b, c]), subjected to the boundary conditions u(b) = 0, u(c) = 0.
Following the Galerkin approach, we solve equation (3.1) projected onto the ﬁnite
dimensional space V := span{ϕ1,··· , ϕN} and V ⊂ H 1
0 ([b, c]) is the
standard Sobolev space on [b, c] and {ϕi} are standard piecewise linear basis functions
deﬁned on a mesh b = x0 < x1 < ··· < xN < xN +1 = c with meshsize hi = xi+1 − xi,
i = 1, 2,··· , N . We multiply v ∈ V by (3.1) and integrate over [b, c],

0 ([b, c]), where H 1

(cid:90) c

b

(cid:90) c

b

Dα
x u(x)ϕi(x) dx =

f (x)ϕi(x) dx.

(3.2)

4

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

(cid:21)

(cid:90) c

(cid:20) 1

By integration by parts, we obtain the following weak formulation of (3.1): ﬁnd
u(x) ∈ V, such that
d
dx

(cid:90) c
We rewrite the discrete solution un = (cid:80)N

where c(α) = cos(απ/2)Γ(2 − α).
vector u = (u1, u2,··· , uN ) is the solution of the linear system

j=1 ujϕj ∈ V and then the coeﬃcient

|x − ξ|1−αu(ξ) dξ

v(cid:48)(x) dx =

f (x)v(x) dx,

∀v ∈ V

(cid:90) c

b

2c(α)

b

b

(cid:90) c

(cid:20)

b

where

Aij :=

and

1

2 cos(απ/2)Γ(2 − α)

|x − ξ|1−αϕj(ξ) dξ

(cid:21)

ϕ(cid:48)
i(x) dx,

(3.3)

Au = f,

(cid:90) c

b

d
dx

(cid:90) c

b

k−1(cid:88)

ν=0

˜S(x, ξ) =

fi :=

ϕi(x)f (x) dx.

(3.4)

The matrix A is dense as all entries are nonzero. Our aim is to approximate A
by a matrix ˜A which can be stored in a data-sparse (not necessarily sparse) format.
The idea is to replace the kernel S(x, ξ) = |x − ξ|1−α by a degenerate kernel

pν(x)qν(ξ).

(3.5)

3.1. Taylor Expansion of the Kernel. Let τ := [a(cid:48), b(cid:48)], σ := [c(cid:48), d(cid:48)], τ × σ ⊂
[c, d] × [c, d] be a subdomain with the property b(cid:48) < c(cid:48) such that the intervals are
disjoint: τ ∩ σ = ∅. Then the kernel function is nonsingular in τ × σ.

Lemma 3.1 (Derivative of left/right kernel).

(cid:2)(x − ξ)1−α(cid:3) = (−1)ν
ν(cid:89)
(cid:2)(ξ − x)1−α(cid:3) =

ν(cid:89)

l=1

∂ν
x

∂ν
x

l=1

(α + l − 2)(x − ξ)1−α−ν,

(α + l − 2)(ξ − x)1−α−ν.

Then we can use the truncated Talyor series at x0 := (a(cid:48) + b(cid:48))/2 to approximate

the kernel and eventually obtain an approximation of the stiﬀness matrix.

(cid:35)

(α + l − 2)(ξ − x0)1−α−ν

(x − x0)ν

(cid:34) ν(cid:89)

l=1

1
ν!

k−1(cid:88)
k−1(cid:88)

ν=0

pν(x)qν(ξ),

˜S(x, ξ) :=

:=

where

ν=0

pν(x) = (x − x0)ν,

ν(cid:89)

l=1

qν(ξ) =

1
ν!

(α + l − 2)(ξ − x0)1−α−ν.

(3.6)

(3.7)

(3.8)

(3.9)

Adaptive FEM for FDEs using H-Matrices

5
3.2. Low rank approximation of Matrix Blocks. If τ ×σ is admissible, then
we can approximate the kernel S in this subdomain by the truncated Taylor series
˜S from (3.6) and replace the matrix entries Aij by the use of the degenerate kernel
˜S(x, ξ) for the indices (i, j) ∈ t × s :

˜Aij =

1

2 cos(απ/2)Γ(2 − α)

d
dx

˜S(x, ξ)ϕj(ξ) dξ

ϕ(cid:48)
i(x) dx,

(3.10)

in which the double integral is separated into two single integrals:

(cid:21)

(cid:35)

(cid:90) c

(cid:90) c

b

k−1(cid:88)

˜Aij =

1

2 cos(απ/2)Γ(2 − α)

=

1

2 cos(απ/2)Γ(2 − α)

d
dx

(cid:20)(cid:90) c

k−1(cid:88)

ν=0

b

pν(x)qν(ξ)ϕj(ξ) dξ

b

ν=0

p(cid:48)
ν(x)ϕ(cid:48)

i(x) dx

(cid:21)(cid:20)(cid:90) c

b

(3.11)

ϕ(cid:48)
i(x) dx

(cid:21)

qν(ξ)ϕj(ξ) dξ

(3.12)

Thus, the submatrix A|t×s can be represented in a factorized form

(cid:20)

(cid:90) c
(cid:34)

b

(cid:90) c

b

A|t×s =

2 cos(απ/2)Γ(2 − α)

CRT , C ∈ Rt×{0,··· ,k−1}, R ∈ Rs×{0,··· ,k−1}

where the entries of the matrix factors C and R are

(cid:90) c

1

(cid:90) c

p(cid:48)
ν(x)ϕ(cid:48)

b

Ciν :=

i(x) dx, Rjν :=

(3.13)
3.3. H-Matrix Representation Error Estimate. Now we estimate the error
of the H-Matrix representation. Here we consider the case b(cid:48) < c(cid:48)(i < j) and the case
d(cid:48) < a(cid:48)(i > j) follows exactly the same procedure. We ﬁrst need to rewrite Ciν and
Rjν using Taylor expansions. For b(cid:48) < c(cid:48)(i < j), using the following Taylor expansions
with hi the length of the element (xi, xi+1), we have

qν(ξ)ϕj(ξ) dξ.

b

(xi−1 − x0)ν = (xi − x0)ν + ν(xi − x0)ν−1(−hi)
(ξi − x0)ν−2(−hi)2,

ν(ν − 1)

+

(xi+1 − x0)ν = (xi − x0)ν + ν(xi − x0)ν−1(hi+1)
(ξi+1 − x0)ν−2(hi+1)2,

ν(ν − 1)

+

2!

2!

ξi ∈ [xi−1, xi],

ξi+1 ∈ [xi, xi+1],

we have, for ν ≥ 2,

Ciν = − ν(ν − 1)

2!

(cid:2)(ξi − x0)ν−2hi + (ξi+1 − x0)ν−2hi+1

(cid:3) .

(3.14)

Similarly, using the following Taylor expansions

(xj−1 − x0)3−α−ν = (xj − x0)3−α−ν + (3 − α − ν)(xj − x0)2−α−ν(−hj)

(3 − α − ν)(2 − α − ν)

+

(ξj − x0)1−α−ν(−hj)2,

ξj ∈ [xj−1, xj],

(xj+1 − x0)3−α−ν = (xj − x0)3−α−ν + (3 − α − ν)(xj − x0)2−α−ν(hj+1)
ξj+1 ∈ [xj−1, xj],

(ξj+1 − x0)1−α−ν(hj+1)2,

(3 − α − ν)(2 − α − ν)

+

2!

2!

6

we have,

Rjν =

1

2!ν!

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

l=1(α + l − 2)(cid:2)(ξj − x0)1−α−νhj + (ξj+1 − x0)1−α−νhj+1

Πν

(cid:3) .

(3.15)

Based on (3.14) and (3.15), we can analyze the element-wise error in the following
theorem.
b(cid:48) < c(cid:48), x0 = (a(cid:48) + b(cid:48))/2, and k ≥ 2, we have

Theorem 3.2 (Element-wise Approximation Error). Let τ := [a(cid:48), b(cid:48)], σ := [c(cid:48), d(cid:48)],

|Aij − ˜Aij|
≤ 1

8c(α)

k(k − 1)(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α−1 |x0 − a(cid:48)|2

(cid:20) diam(τ ) + 2dist(τ, σ)

(cid:21)3(cid:20)

2dist(τ, σ)

1 + 2

dist(τ, σ)
diam(τ )
(3.16)

where diam(τ ) is the diameter of τ and dist(τ, σ) is the distance between the intervals
τ and σ. If dist(τ,σ)

diam(τ ) ≥ 1, we have

|Aij − ˜Aij| ≤ 27
64

1

c(α)

k(k − 1)(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α−1 |x0 − a(cid:48)|2

−k .

(3)

(3.17)

Proof. Let us consider the case b(cid:48) < c(cid:48)(i < j), according to (3.14) and (3.15), for

ν ≥ 2, we have

|Ciν| ≤ ν(ν − 1)
|Rjν| ≤ 1
2ν!

[Πν

2

(hi + hi+1)|x0 − a(cid:48)|ν−2,
l=1(α + l − 2)] (hj + hj+1)

(cid:18)

1

|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|

(cid:19)ν+α−1

.

Denote r :=

|x0−a(cid:48)|

|x0−a(cid:48)|+|c(cid:48)−b(cid:48)| < 1 and use the fact that Πν

|CiνRjν| ≤ 1
4

(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α+1

≤ 1, we have

l=1(α+l−2)

ν!

(cid:2)ν(ν − 1)rν−2(cid:3) .

Therefore, for k ≥ 2

|Aij − ˜Aij| ≤ 1

2c(α)

|

∞(cid:88)

ν=k

CiνRjν| ≤ 1

2c(α)

≤ 1

8c(α)

=

1

8c(α)

≤ 1

8c(α)

(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α+1
(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α+1
(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α+1

(cid:35)

ν(ν − 1)rν−2

|CiνRjν|

∞(cid:88)
(cid:34) ∞(cid:88)

ν=k

ν=k

k(k − 1)
(1 − r)3 rk−2

(cid:21)−k

.

rk−2

(k − 1)(k − 2)r2 − 2k(k − 2)r + k(k − 1)

(1 − r)3

=

1

8c(α)

(hi + hi+1)(hj + hj+1)

(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α−1 |x0 − a(cid:48)|2

k(k − 1)
(1 − r)3 rk

Adaptive FEM for FDEs using H-Matrices

7

Note that r =

diam(τ )+2dist(τ,σ) and k ≥ 2, we have

diam(τ )

|Aij − ˜Aij|
≤ 1

8c(α)

k(k − 1)(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α−1 |x0 − a(cid:48)|2

(cid:20) diam(τ ) + 2dist(τ, σ)

(cid:21)3(cid:20)

2dist(τ, σ)

1 + 2

dist(τ, σ)
diam(τ )

(cid:21)−k

,

which gives (3.16).

If dist(τ,σ)

diam(τ ) ≥ 1, we have diam(τ )+2dist(τ,σ)

2dist(τ,σ)

≤ 3

2 , 1 + 2 dist(τ,σ)

diam(τ ) ≥ 3, and then

|Aij − ˜Aij| ≤ 27
64

1

c(α)

k(k − 1)(hi + hi+1)(hj + hj+1)
(|x0 − a(cid:48)| + |c(cid:48) − b(cid:48)|)α−1 |x0 − a(cid:48)|2

−k ,

(3)

which completes the proof.

In the error estimate (3.16), we can see that the dominating term is

(cid:104)

1 + 2 dist(τ,σ)
diam(τ )

(cid:105)−k

,

which determines the decaying rate and, thus, the quality of the approximation. If
dist(τ, σ) → 0, the approximation will degenerate. However, if we require diam(τ ) ≤
dist(τ, σ) as in the Theorem 3.2, we can have a nearly uniform bound

|Aij − ˜Aij| = O(3−k),

where c depends on the intervals and α weakly since it is dominated by 3−k. Moreover,
diam(τ ) if we assume diam(τ ) ≤
the element-wise error mainly depends on the ratio dist(τ,σ)
dist(τ, σ), and the bigger the ratio the better the approximation. This is equivalent
to stating that the bigger the distance dist(τ, σ) compared to diam(τ ) is, the faster
the approximation error decays. The error decays exponentially with respect to the
order k. Figure 3.1 shows how the error decays with respect to k when we vary the
ratio or α; we can see clearly that the error depends strongly on the ratio rather than
α, which supports our error estimates.

Fig. 3.1. Error in the Frobenius norm ((cid:107)A − ˜A(cid:107)F , where (cid:107)M(cid:107)F :=

j |Mij|) mainly
depends on the ratio rather than on α. Left: ration := dist(τ,σ)
diam(τ ) with diam(τ ) the diameter of the
interval τ and dist(τ, σ) the distance between the intervals τ and σ; Right: α ∈ (1, 2) is the order of
the fractional derivative.

i

(cid:113)(cid:80)

(cid:80)

8

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

4. Geometric Multigrid Method based on H-Matrices. In this section, we
discuss how we solve the linear system of equations in the H-Matrix format. Although
many existing fast linear solvers based on the H-Matrix format can be applied directly,
for example, Hierarchical inversion and H-Matrix LU decomposition (see, e.g. [2]), we
will design the geometric multigrid (GMG) method based on the H-matrix format
and use GMG method to solve the linear system. The reason is the following. Firstly,
since we are solving discrete systems resulting from diﬀerential equations, the GMG
method is known to be one of the optimal methods and suitable for large-scale prob-
lems. In [17], GMG methods have been introduced to FDEs discretized on uniform
grids. Therefore, it is natural to take advantage of the H-matrices and generalize
GMG methods for FDEs in higher dimensions discretized on non-uniform grids. Sec-
ondly, our ultimate goal is to design adaptive ﬁnite element methods for solving FDEs,
therefore, hierarchical grids are available due to the adaptive reﬁnement procedure
(which will be made clear in Section 5); hence, we can use those nested unstruc-
tured grids and design GMG methods accordingly. Next, we will present the GMG
algorithms.
As usual, the multigrid method is built upon the subspaces that are deﬁned on
nested sequences of triangulations. We assume that we start with an initial grid T0
and a nested sequence of grids {T(cid:96)}J
(cid:96)=0, where T(cid:96) is obtained by certain reﬁnement
procedure of T(cid:96)−1 for (cid:96) > 0, i.e.,

T0 ≤ T1 ≤ ··· ≤ TJ = T .

Let V(cid:96) denote the corresponding linear ﬁnite element space based on T(cid:96). We thus get
a sequence of multilevel spaces

Note that, a natural space decomposition of V is V =(cid:80)J

V0 ⊂ V1 ⊂ ··· ⊂ VJ = V.

(cid:96)=0 V(cid:96) and this is not a direct
sum. Based on these ﬁnite element spaces, we have the following linear system of
equations on each level:

Correspondingly, we also have their H-Matrix approximation on each level

A(cid:96)u(cid:96) = f(cid:96),

(cid:96) = 0, 1,··· , J.

˜A(cid:96) ˜u(cid:96) = f(cid:96),

(cid:96) = 0, 1,··· , J,

(4.1)

(4.2)

where ˜A(cid:96) is the H-Matrix representation of A as deﬁned entry-wise by (3.10).

In practice, we will solve (4.2) based on the GMG method. Because ˜A(cid:96) provides
a good approximation to A(cid:96) on each level (cid:96), we can expect that ˜u(cid:96) provides a good
approximation to u(cid:96) on each level (cid:96) based on the standard perturbation theory of
solving linear systems of equations [12]. In order to deﬁne the GMG method, we need
to introduce the standard prolongation I(cid:96) on level (cid:96), which is the matrix representation
} to V(cid:96) =
of the standard inclusion operator from V(cid:96)−1 = span{ϕ(cid:96)−1
span{ϕ(cid:96)

} since V(cid:96)−1 ⊂ V(cid:96), e.g., I(cid:96) ∈ RN(cid:96)×N(cid:96)−1 such that,

,··· , ϕ(cid:96)−1

, ϕ(cid:96)−1

N(cid:96)−1

1

2,··· , ϕ(cid:96)

1, ϕ(cid:96)

N(cid:96)

2

N(cid:96)(cid:88)

(I(cid:96))ij = βij, where ϕ(cid:96)−1

j =

βijϕ(cid:96)

i , j = 1,··· , N(cid:96)−1.

(4.3)

Now we can deﬁne the standard V -cycle GMG method for solving (4.2) by the fol-
lowing recursive (Algorithm 1).

i=1

Adaptive FEM for FDEs using H-Matrices

9

Algorithm 1 V-cycle multigrid method for H-Matrix ˜A(cid:96)
˜u(cid:96) = Vcycle(˜u(cid:96), ˜A(cid:96), f(cid:96), (cid:96))
1: if (cid:96) = 0 then
˜u0 = ˜A−1
0 f0
2:
3: else
4:
5:
6:
7:

˜u(cid:96) = FGSsmoother(˜u(cid:96), ˜A(cid:96), f(cid:96))
r(cid:96) = f(cid:96) − Hmatvec( ˜A(cid:96), ˜u(cid:96))
r(cid:96)−1 = I T
e(cid:96)−1 = 0 and e(cid:96)−1 = Vcycle(e(cid:96)−1, H(cid:96)−1, r(cid:96)−1, (cid:96) − 1)
˜u(cid:96) = ˜u(cid:96) + I(cid:96)e(cid:96)−1
˜u(cid:96) = BGSsmoother(˜u(cid:96), ˜A(cid:96), f(cid:96))

(cid:96) r(cid:96)

8:
9:
10: end if

We ﬁrst want to point out that on the the coarsest level (cid:96) = 0, we need to solve
the linear system exactly because the size of the problem is very small compared
with the size on the ﬁnest level. This involves inverting the H-Matrix ˜A0 and can be
done eﬃciently by Hierarchical inversion and H-Matrix LU decomposition methods.
However, in order to keep our implementation simple, we choose a very coarse grid T0
to start with and the size of the problem is small enough so that the computational
cost can be ignored and, therefore, the H-Matrix approach is not needed, i.e., ˜A0 = A0
in our implementation. Standard Gaussian Elimination or LU decomposition for a
dense matrix is used to solve the linear system on the coarsest grid exactly.

Secondly, Algorithm 1 uses matrix-vector multiplication based on the H-Matrix
format, i.e. the subroutine Hmatvec. Such a matrix-vector multiplication has been
widely discussed in the H-Matrix literature, for example [2]. We also adopt the
standard implementation here. We assume that matrix H is stored using the H-
Matrix format and we want to compute y = Hx. The algorithm is presented in
Algorithm 2.

Algorithm 2 Matrix-vector multiplication in H-Matrix format
y = Hmatvec(H, x)

y = Hx

1: if H is full matrix then
2:
3: end if
4: if H is low rank approximation, i.e.

it is stored in factorized form H = CRT

(cid:18)H11 H12

(cid:19)

H21 H22

then

then

y = C(RT x)

5:
6: end if

8:

9:
10:

11:

set y =

12: end if

(cid:18)x1

(cid:19)

x2

7: if H is stored in 2 by 2 block form, i.e., H =

partition x as x =

y1 = Hmatvec(H11, x1) + Hmatvec(H12, x2)
y2 = Hmatvec(H21, x1) + Hmatvec(H22, x2)

(cid:18)y1

(cid:19)

y2

10

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

Finally, we discuss the smoothers used in the GMG Algorithm 1. We use Gauss-
Seidel smoothers in our implementation. The Subroutine FGSsmoother is the imple-
mentation of forward Gauss-Seidel method and the subroutine BGSsmoother is the
implementation of backward Gauss-Seidel method. Their implementations are given
by Algorithm 3 and 4, respectively.
Algorithm 3 Forward Gauss-Seidel smoother in H-Matrix format
x = FGSsmoother(H, b, x)
1: r = b − Hmatvec(H, x)
2: if H is full matrix then
3:
4:
5:
6: end if

get the lower triangular part L of H
z = L−1r
x = x + z

7: if H is stored in 2 by 2 block form, i.e., H =

then

(cid:18)H11 H12

(cid:19)

H21 H22

(cid:18)r1

(cid:19)

r2

8:

9:
10:
11:

12:

partition r as r =

z1 = FGSsmoother(H11, r1, 0)
r2 = r2 − Hmatvec(H21, z1)
z2 = FGSsmoother(H22, r2, 0)

(cid:18)z1

(cid:19)

z2

set z =

x = x + z

13:
14: end if

Algorithm 4 Backward Gauss-Seidel smoother in H-Matrix format
x = BGSsmoother(H, b, x)
1: r = b − Hmatvec(H, x)
2: if H is full matrix then
3:
4:

get the upper triangular part U of H
z = U−1r
x = x + z

5:
6: end if

7: if H is stored in 2 by 2 block form, i.e., H =

then

(cid:18)H11 H12

(cid:19)

H21 H22

(cid:18)r1

(cid:19)

r2

8:

9:
10:
11:

12:

partition r as r =

z2 = BGSsmoother(H22, r2, 0)
r1 = r1 − Hmatvec(H12, z2)
z1 = BGSsmoother(H11, r1, 0)

(cid:18)z1

(cid:19)

z2

set z =

x = x + z

13:
14: end if

Note that in the Gauss-Seidel smoother algorithms, we do not consider the case
that H is a low rank approximation and is stored in factorized form H = CRT . This

Adaptive FEM for FDEs using H-Matrices

11

is because in the Gauss-Seidel algorithm, only the diagonal entries will be inverted
and, in our H-Matrix representation for the FDEs, the diagonal entries are deﬁnitely
stored explicitly in the full matrix format. Therefore, we consider the cases where
H is stored in either full matrix format or 2 by 2 block format, where the diagonal
entries need to be accessed recursively.

Based on Algorithm 2, 3, and 4, the V-cycle multigrid Algorithm 1 is well-
deﬁned. It is easy to check that the overall computational complexity of one V-cycle
is O(kN(cid:96) log N(cid:96)) where N(cid:96) is the number of degrees of freedom on the level (cid:96) and k is
the upper bound of the rank used in the low rank approximation for the H-Matrix.
This is because the computational cost of matrix-vector multiplication for H-Matrix
is O(kN(cid:96) log N(cid:96)) and it is well-known that the Gauss-Seidel method has roughly the
same computational cost as the matrix-vector multiplication. In practice, k (cid:28) N(cid:96)
usually is a small number and does not depends on N(cid:96). Therefore, we can say that
the computational cost of V-cycle multigrid on level (cid:96) is roughly O(N(cid:96) log N(cid:96)). Note
that the computational complexity for solving the linear system of equations in the
H-Matrix format, such as Hierarchical inversion and H-Matrix LU decomposition
methods, is O(k2N(cid:96) log2 N(cid:96)) ≈ O(N(cid:96) log2 N(cid:96)) [2]. Therefore, the GMG approach is
slightly better in terms of computational cost, especially for large-scale problems.

5. Adaptive Finite Element Method for Fractional PDEs. In this section,
we discuss the adaptive ﬁnite element method (AFEM) for solving FDEs. We follow
the idea of standard AFEM, which is characterized by the following iteration

SOLVE −→ ESTIMATE −→ MARK −→ REFINE.

Such iteration generates a sequence of discrete solutions converging to the exact one.
We want to emphasize that one of the main diﬃculties of applying the AFEM to the
FDEs is the SOLVE step. The AFEM iteration usually generates non-uniform grids,
which makes the resulting linear system diﬃcult to solve by existing fast linear solvers.
This is because usually the traditional approaches take advantage of the uniform grid
and the Toeplitz structure of the resulting stiﬀness matrices, which is not true for the
non-uniform grid. However, in this paper, by introducing the H-Matrix approach and
GMG method, we can eﬃciently solve the linear system obtained on the non-uniform
grid and, therefore, design an AFEM method for FDEs so that each AFEM iteration
has computational complexity O(kN log N ), suitable for practice applications. Next,
we will introduce the four modules in the AFEM iterations.

5.1. SOLVE Module. As usual, the SOLVE module should take the current grid
as the input and output the corresponding ﬁnite element approximation. Note here
that the current grid in general is obtained by adaptive reﬁnement and, therefore,
it is an unstructured grid. So, our SOLVE module will use the hierarchical matrix
representation mentioned in Section 3 to assemble the linear system of equations
stored in H-Matrix format and solve it by the GMG method discussed in Section 4.
The detailed description is listed below.
Let N(cid:96) denote the number of degrees of freedoms on grid T(cid:96). As discussed in
Section 3, assembling the H-Matrix on grid T(cid:96) costs O(kN(cid:96) log N(cid:96)) operations and
solving U(cid:96) by the GMG method also costs O(kN(cid:96) log N(cid:96)) operations. Therefore, the
overall cost of the SOLVE module is O(kN(cid:96) log N(cid:96)) or O(N(cid:96) log N(cid:96)) when k (cid:28) N(cid:96).

5.2. ESTIMATE Module. Given a grid T(cid:96) and ﬁnite element approximation ˜u(cid:96) ∈
V(cid:96), the ESTIMATE module computes a posteriori error estimators {η(cid:96)(˜u(cid:96), τ )}τ∈T(cid:96), which
should be computable on each element τ ∈ T(cid:96) and indicate the true error. Such a

12

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

Algorithm 5 SOLVE module: solve FDES using FEM
˜u(cid:96) = SOLVE(T(cid:96))
1: On current grid T(cid:96), assemble the linear system of equation ˜A(cid:96) ˜u(cid:96) = f(cid:96) and stored

it in H-Matrix format

2: Solve ˜u(cid:96) by V-cycle GMG method (Algorithm 1) directly or preconditioned Con-

jugate Gradient method with V-cycle GMG as a preconditioner

posteriori error estimators have been widely discussed in the AFEM literature for
second order elliptic PDEs discretized by FEM [6, 23]. There are three major error
estimators: residual based error estimator, gradient recovery based error estimator,
and objective-oriented error estimator. For FDES, to the best of our knowledge,
studies on such a posteriori error estimators are very limited. In this work, we will
adopt the gradient recovery based error estimators due to its simplicity and problem-
independence. A more detailed investigation on such an error estimator will be a
subject of our future work. The detailed description of the ESTIMATE module is listed
below.

Algorithm 6 ESTIMATE Module: gradient recovery type a posteriori error estimator
{η(cid:96)(˜u(cid:96), τ )}τ∈T(cid:96) = ESTIMATE(˜u(cid:96),T(cid:96))
1: Compute ∇˜u(cid:96).
2: Compute the recovery gradient G ˜u(cid:96) ∈ V(cid:96) = span{ϕ(cid:96)

1,··· , ϕ(cid:96)

}

N(cid:96)

G ˜u(cid:96) :=

(G ˜u(cid:96))iϕ(cid:96)
i ,

(G ˜u(cid:96))i :=

i∇˜u(cid:96)|[x(cid:96)
h(cid:96)

i+1∇˜u(cid:96)|[x(cid:96)

i ,x(cid:96)

i+1]

,

N(cid:96)(cid:88)

i

i ] + h(cid:96)
i−1,x(cid:96)
h(cid:96)
i + h(cid:96)
i − x(cid:96)

i−1.

i+1

where x(cid:96)

i are the nodes in the grid T(cid:96) and h(cid:96)

3: Compute the error estimator on each element τ ∈ T(cid:96)

i = x(cid:96)

η(cid:96)(˜u(cid:96), τ ) := (cid:107)∇˜u(cid:96) − G ˜u(cid:96)(cid:107)τ ,

τ ∈ T(cid:96).

It is easy to check that the computational complexity of ESTIMATE module is
O(N(cid:96)) because all the computations are done locally on the elements τ and on each
element τ , the operations are ﬁnite and independent of N(cid:96).
tor η(cid:96)(˜u(cid:96),T(cid:96)) can be computed by

After computing the error estimators on each element τ , the overall error estima-

(cid:33) 1

2

(cid:32)(cid:88)

τ∈T(cid:96)

η(cid:96)(˜u(cid:96),T(cid:96)) :=

η(cid:96)(˜u(cid:96), τ )

,

and η(cid:96)(˜u(cid:96),T(cid:96)) will be used as the stopping criterion for the overall AFEM algorithm.
Once it is smaller than a given tolerance, the AFEM algorithm will terminate. In
general, by the triangular inequality, we have

(cid:107)∇u − ∇˜u(cid:96)(cid:107) ≤ (cid:107)∇˜u(cid:96) − G ˜u(cid:96)(cid:107) + (cid:107)∇u − G ˜u(cid:96)(cid:107) = η(cid:96)(˜u(cid:96),T(cid:96)) + (cid:107)∇u − G ˜u(cid:96)(cid:107).

If the last term (cid:107)∇u−G ˜u(cid:96)(cid:107) is a high order term (which can be shown for second elliptic
PDEs [41]) compared with η(cid:96)(˜u(cid:96),T(cid:96)), then we can expect that η(cid:96)(˜u(cid:96),T(cid:96)) provides a

Adaptive FEM for FDEs using H-Matrices

13
good estimation of the true error (cid:107)∇u−∇˜u(cid:96)(cid:107) and, therefore, guarantees the eﬃciency
of the overall AFEM algorithm. For FDES, numerical experiments presented below
suggest that (cid:107)∇u − G ˜u(cid:96)(cid:107) is indeed a high order term. A more rigorous analysis on
this topic will be our future work.

5.3. MARK Module. The MARK module selects elements τ ∈ T(cid:96) whose local error
η(cid:96)(U(cid:96), τ ) is relatively large and needs to be reﬁned in the reﬁnement. This module is
independent of the model problems and we can directly use the strategies developed
for second order elliptic PDEs for FDES here.
In this work, we use the so-called
D¨oﬂers marking strategy [23] with the detailed algorithm listed below (Algorithm 7).

Algorithm 7 MARK Module: D´oﬂer’s marking strategy
M(cid:96) = MARK(T(cid:96), η(cid:96)(˜u(cid:96), τ ), θ)
1: Choose a subset M(cid:96) ⊂ T(cid:96) such that

where η(cid:96)(˜u(cid:96),M(cid:96)) :=(cid:0)(cid:80)

τ∈M(cid:96)

η(cid:96)(˜u(cid:96),M(cid:96)) ≤ θη(cid:96)(˜u(cid:96),T(cid:96)),

η(cid:96)(˜u(cid:96), τ )(cid:1) 1

2 .

(5.1)

Here we require that the parameter θ ∈ (0, 1]. Obviously, the choice of M(cid:96) is not
unique. In practice, in order to reduce the computational cost, we prefer the size of the
subset M(cid:96) to be as small as possible. Therefore, we typically use the greedy approach
in the implementation of ESTIMATE module. We ﬁrst order the elements τ according
to the error indicators η(cid:96)(U(cid:96), τ ) from large to small and then pick the element τ in
a greedy way so that condition (5.1) will be satisﬁed with minimal number of the
elements.
Based on the above discussion, the ordering could be done in O(N(cid:96) log N(cid:96)) opera-
tions and picking the elements can be done in O(N(cid:96)) operations, therefore, the overall
computational complexity of the ESTIMATE module is O(N(cid:96) log N(cid:96)).

5.4. REFINE Module. The REFINE module is also problem independent. It takes
the marked elements M(cid:96) and current grid Tk as inputs and outputs a reﬁned grid T(cid:96)+1,
which will be used as a new grid. In this work, because we are only considering the 1D
i ] ∈ T(cid:96) is
case, the reﬁnement procedure is just bisection. Namely, if an element [x(cid:96)
marked, it will be divided into two subintervals [x(cid:96)
i ] by the midpoint
¯x(cid:96)
i = (x(cid:96)

i )/2. The detailed algorithm is listed below (Algorithm 8).

i−1 + x(cid:96)

i−1, x(cid:96)

i−1, ¯x(cid:96)

i ] and [¯x(cid:96)

i , x(cid:96)

Algorithm 8 REFINE Module: bisection reﬁnement
T(cid:96)+1 = REFINE(T(cid:96),M(cid:96))
1: for τ ∈ M(cid:96) do

reﬁne τ using bisection and generate two new elements.

2:
3: end for
4: Combine all new elements and subset T(cid:96)\Ml to generate the new grid T(cid:96)+1.
Obviously, the computational cost of the REFINE module is at most O(N(cid:96)).
5.5. AFEM Algorithm. After discussing each module, now we can summarize
our AFEM algorithm for solving FDES. We assume that an initial grid T0, a parameter
θ ∈ (0, 1], and a targeted tolerance ε are given. The AFEM algorithm is listed in
Algorithm 9.

14

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

Algorithm 9 Adaptive Finite Element Method for Solving FDES
˜uJ = AFEM(T0, θ, ε)
1: Set (cid:96) = 0
2: loop
3:
4:

˜u(cid:96) = SOLVE(T(cid:96))
{η(cid:96)(˜u(cid:96), τ )}τ∈T(cid:96) = ESTIMATE(˜u(cid:96),T(cid:96))
if η(cid:96)(˜u(cid:96),T(cid:96)) ≤ ε then
J = (cid:96) and ˜uJ := ˜u(cid:96).
return

5:
6:
7:
8:

9: M(cid:96) = MARK(T(cid:96), η(cid:96)(˜u(cid:96), τ ), θ)

end if
T(cid:96)+1 = REFINE(T(cid:96),M(cid:96))
(cid:96) = (cid:96) + 1

10:

11:
12: end loop

Obviously, the overall computational cost of each iteration of the AFEM method

is O(kN(cid:96) log N(cid:96)) or O(N(cid:96) log N(cid:96)) when k (cid:28) N(cid:96).

6. Numerical Examples. In this section, we present some numerical experi-
ments to demonstrate the eﬃciency and robustness of the proposed H-Matrix repre-
sentation, GMG method, and AFEM algorithm for solving the FDES. All the codes
are written in MATLAB and the tests are performed on a Macbook Pro Laptop with
Inter Core i7 (3 GHz) CPU and 16G RAM.
Example 6.1. Solving problem (3.1) with exact solution u(x) = 10x2(1− x2) on

[b,c]=[0,1]. The right hand side can be computed as

(cid:2)x2−α + (1 − x)2−α(cid:3) −

(cid:26)
(cid:2)x4−α + (1 − x)4−α(cid:3)(cid:27)

Γ(3 − α)

2

.

f (x) = −

10

2 cos(απ/2)

+

24

Γ(5 − α)

(cid:2)x3−α + (1 − x)3−α(cid:3)

12

Γ(4 − α)

It is easy to see that for Example 6.1, the solution u(x) is smooth. Therefore, the
adaptive method is unnecessary for this example and we mainly use uniform grid
and uniform reﬁnement. The purpose of this example is to show the accuracy of the
H-Matrix representation, the eﬃciency of the GMG method, and the overall optimal
computational complexity of the proposed approach.
Figures 6.1 and 6.2 present the convergence behavior of the ﬁnite element ap-
proximations based on full matrix approach and H-Matrix representation for diﬀerent
values of α. For the full matrix approach, we use a direct solver (LU decomposition)
to solve the linear system of equations (command “\” in MATLAB) and, for the
H-Matrix, we solve the linear system of equations iteratively by the GMG method
presented in Section 4. The stopping criterion is the relative residual to be less than
10−10. The convergence rate of absolute error and L2 error are presented. In all our
experiments, we use the fact that log E = −r log N + log C which is derived from
E = CN−r, where E denotes error, and then compute the convergence rate r by
the linear polynomial ﬁtting between log E and log N . In all cases, we can see that
using the H-Matrix representation, the convergence orders are still around 2 which
is optimal as expected. Moreover, in all cases, the errors obtained by the H-Matrix
representation are also comparable with the errors obtained by using the full matrix.

Adaptive FEM for FDEs using H-Matrices

15

Fig. 6.1. Example 6.1 (α = 1.2). Convergence comparison between full matrix approach and

H-Matrix representation.

Fig. 6.2. Example 6.1 (α = 1.5). Convergence comparison between full matrix approach and

H-Matrix representation.

The results show that using the H-Matrix representation can still achieve the optimal
convergence order and the accuracy of ﬁnite element approximations is still reliable.
As mentioned before, the advantages of using H-Matrix are not only the accuracy
but also the fact that it signiﬁcantly reduces the computational cost compared with
the full matrix, especially when the GMG method is applied. In Table 6.1, the number
of iterations for GMG method is shown for diﬀerent mesh size h and fractional index α.
We can see that the number of iterations is quite stable for wide ranges of parameters
h and α, which demonstrates the optimal convergence and robustness of the proposed
GMG method in H-Matrix format. Moreover, in Figure 6.3, we compare the CPU time
of the LU decomposition for the full matrix and the GMG method for the H-Matrix
representation. We can see that the computational cost of the GMG method behaves
like O(N 0.92), which is signiﬁcantly better than the computational cost of the LU
decomposition for full matrix (O(N 2.68)). Theoretically, the GMG method based on
the H-Matrix representation costs O(N log N ). Therefore, we can expect even bigger
speedup when the problem size N is increased. We want to comment that, in Figure
6.3, for relative small N , LU decomposition for the full matrix seems to be faster than
the GMG method for the H-Matrix. This is because of the diﬀerent implementations
of LU decomposition and the GMG methods. For LU decomposition, Matlab build-in
command “\” is used which is based on the UMFPack package implemented in the
Matlab. Our GMG method for the H-Matrix is completely implemented in Matlab.
Our Matlab implementation actually outperforms the build-in command “\” for large

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

16
size N , which is a strong evidence of the eﬃciency of the GMG method for the H-
Matrix.

Example 6.1: number of iterations of GMG method (stopping criterion: relative residual less

than or equal to 10−10)

Table 6.1

h = 1/256

h = 1/512

h = 1/1024

h = 1/2048

h = 1/4095

α = 1.1
α = 1.3
α = 1.5
α = 1.7
α = 1.9

9
10
11
12
13

9
10
11
12
13

9
10
11
12
13

9
10
12
12
13

9
11
12
13
14

Fig. 6.3. Example 6.1 (α = 1.5) CPU time comparison between full matrix (LU decomposition)

and the H-Matrix (multigrid)

Example 6.2. Solving model problem (3.1) with right hand side f (x) = 1 +

sin(x).

The second example we consider here does not have exact solution. However, due
to the property of the FDES, we expect the solution to have singularities near the
boundaries, which leads to degenerated convergence rate in the errors of ﬁnite element
approximations on uniform grids. This is conﬁrmed by the numerical results as shown
in Figure 6.4. The convergence rates of the L2 errors for both full matrix and H-
Matrix approaches are about 1.2, which reﬂects the singularity of the solution and the
necessity for the AFEM method. These comparisons show that the AFEM algorithm
can achieve better accuracy with less computational cost, which demonstrates the
eﬀectiveness of the AFEM algorithm for FDES.

Next we apply the AFEM algorithm (Algorithm 9) to solve Example 6.2. The
results are shown in Figures 6.5 and 6.6. We can see that, using the AFEM method,
the optimal convergence rates of both L2 error and L∞ have been recovered for both
α = 1.3 and α = 1.5. This demonstrates the eﬀectiveness and robustness of the
In Figure 6.7, we plot the numerical solutions on adaptive
our AFEM methods.

Adaptive FEM for FDEs using H-Matrices

17

Fig. 6.4. Example 6.2 (α = 1.2): Convergence rate comparison between full matrix and H-

Matrix representation on uniform grids.

meshes for both α = 1.3 and α = 1.5. The adaptive reﬁnement near the boundary
points demonstrates that our error estimates captures the singularities well and overall
robustness of our AFEM algorithm.

Fig. 6.5. Example 6.2: Convergence rate of L2 errors comparison between FEM on uniform

grid and AFEM (Left: α = 1.3; Right: α = 1.5).

As mentioned in Section 5, one distinct feature of our proposed AFEM method
is that in the SOLVE module, the H-Matrix representation and the multigrid method
are used, hence providing nearly optimal computational complexity O(N log N ). In
Figure 6.8, we show the CPU time of the GMG method for the H-Matrix used in
the SOLVE module for diﬀerent fractional orders. We can see that, for all cases, the
computational complexity is optimal, which conﬁrms our expectation.

Next we compare the computational costs of FEM on uniform grids and AFEM.
The results are shown in Table 6.2. Here “DoFs” means the degrees of freedom. For
AFEM, we start the adaptive reﬁnement from a coarse grid of size 32. For AFEM,
“Total DoFs” means the sum of the DoFs of all the adaptive grids starting from the
coarse grid to current adaptive grid and “Total Time” means the total CPU time of
the whole AFEM algorithm while “Time” means the CPU time of solving the FDES
on the current adaptive grid. For FEM on a uniform grid of size 16, 383, the L2 error

18

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

Fig. 6.6. Example 6.2: Convergence rate of L∞ errors comparison between FEM on uniform

grid and AFEM (Left: α = 1.3; Right: α = 1.5).

Fig. 6.7. Example 6.2: Numerical solutions on adaptive meshes (Left: α = 1.3; Right: α = 1.5).

is 1.89 × 10−6 and the CPU time is about 49.31 seconds. However, if we use AFEM,
solving the problem on an adaptive grid of size 1, 059 leads to accuracy 7.07 × 10−7
in the L2 norm. This means that the AFEM achieves about 2.7 times better results
using a 15.5 times smaller grid. Even the total DoFs, which is 6, 382, is about 2.6
times smaller than the size of the uniform grid. The speed up is about 18.3 if we
only consider the ﬁnal adaptive grid and is about 3.2 if we consider the whole AFEM
procedure.

Example 6.2 (α = 1.5): Computational cost comparison between FEM on uniform grids and

AFEM. (The time unit is second)

Table 6.2

Uniform

Adaptive

L2 error
5.84 × 10−5
1.30 × 10−5
1.89 × 10−6

DoFs
1, 023
4, 095
16, 383

Time
3.55
13.57
49.31

L2 error
3.40 × 10−5
9.86 × 10−6
7.07 × 10−7

0.28
0.59
2.70

DoFs Time Total DoFs Total Time
116
272
1, 059

490
1, 312
6, 382

1.03
2.82
15.52

In Figure 6.9, we report the breakdown of computational cost of the AFEM on
the ﬁnest adaptive grid. As we can see, the SOLVE module (Assembling and H-Matrix
& MG Solve) dominates the whole AFEM algorithm. The computational cost of

Adaptive FEM for FDEs using H-Matrices

19

Fig. 6.8. Example 6.2: CPU time of GMG method for H-Matrix on nonuniform grid (diﬀerent

fractional index α)

Fig. 6.9. Example 6.2 (α = 1.5): Breakdown of CPU time of AFEM

the other three modules, ESTIMATE module (Estimate Error), MARK module (Mark),
and REFINE module (Adaptive Reﬁne), are roughly the same and could be ignored
compared with the SOLVE module. This is mainly because our experiments are in
1D in the current paper. We can expect those three modules to become more and
more time consuming in 2D and 3D cases. However, the SOLVE module should still
be the dominant module in terms of computational cost and that is why we introduce
the H-Matrix and the GMG method together to make sure that we achieve optimal
computational complexity.

7. Conclusion. In this paper, we presented an adaptive FEM (AFEM) method
for a fractional diﬀerential equation with Riesz derivative, targeting in particular
non-smooth solutions that they may arise even in the presence of smooth right-hand-

20

X. Zhao, X. Hu, W. Cai, G.E. Karniadakis

sides in the equation. To this end, uniform grids result in suboptimal and in fact
sub-linear convergence rate, while the AFEM yields optimal second-order accuracy.
The demonstrated eﬃciency of the method is based on combining two eﬀective ideas,
which act synergistically. First, we approximated the singular kernel in the fractional
derivative using an H-matrix representation, and second, we employed a geometric
multigrid method with linear overall computational complexity. In the current paper,
we developed these ideas for the one-dimensional case but the greater challenge is to
consider higher dimensions, where adaptive reﬁnement has to resolve both solution
singularities and geometric singularities around the boundaries.

REFERENCES

[1] M. Bebendorf. Approximation of boundary element matrices. Numerische Mathematik,

86(4):565–589, 2000.

[2] M. Bebendorf. Hierarchical matrices. Springer, 2008.
[3] S. B¨orm and L. Grasedyck. Hybrid cross approximation of integral operators. Numerische

Mathematik, 101(2):221–249, 2005.

[4] W. Bu, Y. Tang, and J. Yang. Galerkin ﬁnite element method for two-dimensional Riesz space

fractional diﬀusion equations. Journal of Computational Physics, 276:26–38, 2014.

[5] A. Carpinteri and F. Mainardi. Fractals and fractional calculus in continuum mechanics,

volume 378. Springer, 2014.

[6] J. M. Cascon, C. Kreuzer, R. H. Nochetto, and K. G. Siebert. Quasi-optimal convergence rate

for an adaptive ﬁnite element method. SIAM J. Numer. Anal., 46(5):2524–2550, 2008.

[7] M. Chen, Y. Wang, X. Cheng, and W. Deng. Second-order LOD multigrid method for multidi-
mensional riesz fractional diﬀusion equation. BIT Numerical Mathematics, 54(3):623–647,
2014.

[8] S. Chen, J. Shen, and L.-L. Wang. Generalized Jacobi functions and their applications to

fractional diﬀerential equations. Preprint on arXiv, 2015.

[9] W. Deng. Finite element method for the space and time fractional Fokker-Planck equation.

SIAM Journal on Numerical Analysis, 47(1):204–226, 2008.

[10] V. J. Ervin and J. P. Roop. Variational formulation for the stationary fractional advection
dispersion equation. Numerical Methods for Partial Diﬀerential Equations, 22(3):558–576,
2006.

[11] V. J. Ervin and J. P. Roop. Variational solution of fractional advection dispersion equations

on bounded domains in Rd. Numer. Methods Partial Diﬀer. Eq., 23:256–281, 2007.

[12] G. Golub and C. Van Loan. Matrix computations. Johns Hopkins Univ Pr, 1996.
[13] W. Hackbusch. A sparse matrix arithmetic based on H-matrices. Part I: Introduction to H-

matrices. Computing, 62(2):89–108, 1999.

[14] K. L. Ho and L. Ying. Hierarchical interpolative factorization for elliptic operators: diﬀerential

equations. Communications on Pure and Applied Mathematics, 2015.

[15] J. Jia and H. Wang. A preconditioned fast ﬁnite volume scheme for a fractional diﬀeren-
tial equation discretized on a locally reﬁned composite mesh. Journal of Computational
Physics, 299:842–862, 2015.

[16] J. Jia and H. Wang. A fast ﬁnite volume method for conservative space-fractional diﬀusion

equations in convex domains. Journal of Computational Physics, 2016.

[17] Y. Jiang and X. Xu. Multigrid methods for space fractional partial diﬀerential equations.

Journal of Computational Physics, 302:374–392, 2015.

[18] S.-L. Lei and H.-W. Sun. A circulant preconditioner for fractional diﬀusion equations. Journal

of Computational Physics, 242:715–725, 2013.

[19] F.-R. Lin, S.-W. Yang, and X.-Q. Jin. Preconditioned iterative methods for fractional diﬀusion

equation. Journal of Computational Physics, 256:109–117, 2014.

[20] L. Lin, J. Lu, and L. Ying. Fast construction of hierarchical matrix representation from matrix–

vector multiplication. Journal of Computational Physics, 230(10):4071–4087, 2011.

[21] T. Moroney and Q. Yang. A banded preconditioner for the two-sided, nonlinear space-fractional

diﬀusion equation. Computers & Mathematics with Applications, 66(5):659–667, 2013.

[22] S. I. Muslih and O. P. Agrawal. Riesz fractional derivatives and fractional dimensional space.

International Journal of Theoretical Physics, 49(2):270–275, 2010.

[23] R. H. Nochetto, K. G. Siebert, and A. Veeser. Theory of adaptive ﬁnite element methods:
In Multiscale, nonlinear and adaptive approximation, pages 409–542.

an introduction.

Adaptive FEM for FDEs using H-Matrices

21

Springer, Berlin, 2009.

[24] J. Pan, R. Ke, M. K. Ng, and H.-W. Sun. Preconditioning techniques for diagonal-times-
toeplitz matrices in fractional diﬀusion equations. SIAM Journal on Scientiﬁc Computing,
36(6):A2698–A2719, 2014.

[25] G. Pang, W. Chen, and Z. Fu. Space-fractional advection–dispersion equations by the Kansa

method. Journal of Computational Physics, 293:280–296, 2015.

[26] H.-K. Pang and H.-W. Sun. Multigrid method for fractional diﬀusion equations. Journal of

Computational Physics, 231(2):693–703, 2012.

[27] I. Podlubny. Fractional diﬀerential equations: an introduction to fractional derivatives, frac-
tional diﬀerential equations, to methods of their solution and some of their applications,
volume 198. Academic press, 1998.

[28] A. Rebenshtok, S. Denisov, P. H¨anggi, and E. Barkai. Non-normalizable densities in
strong anomalous diﬀusion: beyond the central limit theorem. Physical review letters,
112(11):110601, 2014.

[29] J. P. Roop. Computational aspects of FEM approximation of fractional advection dispersion
equations on bounded domains in R2. Journal of Computational and Applied Mathematics,
193(1):243–268, 2006.

[30] L. Sabatelli, S. Keating, J. Dudley, and P. Richmond. Waiting time distributions in ﬁnancial
markets. The European Physical Journal B-Condensed Matter and Complex Systems,
27(2):273–275, 2002.

[31] S. Samko, A. Kilbas, and O. Marichev. Fractional integrals and derivatives; theory and appli-

cations. Gordon and Breach. Lon don, 1993.

[32] P. G. Schmitz and L. Ying. A fast nested dissection solver for cartesian 3d elliptic problems

using hierarchical matrices. Journal of Computational Physics, 258:227–245, 2014.

[33] M. Shlesinger, B. West, and J. Klafter. L´evy dynamics of enhanced diﬀusion: Application to

turbulence. Physical Review Letters, 58(11):1100, 1987.

[34] H. Sun, W. Chen, and Y. Chen. Variable-order fractional diﬀerential operators in anomalous
diﬀusion modeling. Physica A: Statistical Mechanics and its Applications, 388(21):4586–
4592, 2009.

[35] W. Tian, H. Zhou, and W. Deng. A class of second order diﬀerence approximations for solving
space fractional diﬀusion equations. Mathematics of Computation, 84(294):1703–1727,
2015.

[36] H. Wang and T. S. Basu. A fast ﬁnite diﬀerence method for two-dimensional space-fractional

diﬀusion equations. SIAM Journal on Scientiﬁc Computing, 34(5):A2444–A2458, 2012.

[37] H. Wang and N. Du. A fast ﬁnite diﬀerence method for three-dimensional time-dependent space-
fractional diﬀusion equations and its eﬃcient implementation. Journal of Computational
Physics, 253:50–63, 2013.

fractional diﬀusion equations. Journal of Computational Physics, 240:49–57, 2013.

[38] H. Wang and N. Du. A superfast-preconditioned iterative method for steady-state space-
[39] H. Wang and K. Wang. An O(n log 2n) alternating-direction ﬁnite diﬀerence method
for two-dimensional fractional diﬀusion equations. Journal of Computational Physics,
230(21):7830–7839, 2011.
[40] H. Wang, K. Wang, and T. Sircar. A direct O(n log 2n) ﬁnite diﬀerence method for fractional

diﬀusion equations. Journal of Computational Physics, 229(21):8095–8104, 2010.

[41] J. Xu and Z. Zhang. Analysis of recovery type a posteriori error estimators for mildly structured

grids. Math. Comp., 73(247):1139–1152 (electronic), 2004.

[42] Q. Yang, F. Liu, and I. Turner. Numerical methods for fractional partial diﬀerential equations
with riesz space fractional derivatives. Applied Mathematical Modelling, 34(1):200–218,
2010.

[43] M. Zayernouri and G. E. Karniadakis. Fractional spectral collocation method. SIAM Journal

on Scientiﬁc Computing, 36(1):A40–A62, 2014.

[44] F. Zeng, Z. Zhang, and G. E. Karniadakis. A generalized spectral collocation method with
tunable accuracy for variable-order fractional diﬀerential equations. SIAM Journal on
Scientiﬁc Computing, 37(6):A2710–A2732, 2015.

[45] X. Zhao and Z. Zhang. Superconvergence points of fractional spectral interpolation. arXiv

preprint arXiv:1503.06888, 2015.

[46] Z. Zhou and H. Wu. Finite element multigrid method for the boundary value problem of

fractional advection dispersion equation. Journal of Applied Mathematics, 2013, 2013.

