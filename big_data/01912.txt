Partition Functions from

Rao-Blackwellized Tempered Sampling

6
1
0
2

 
r
a

M
7

 

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
2
1
9
1
0

.

3
0
6
1
:
v
i
X
r
a

David Carlson*
Patrick Stinson*
Ari Pakman*
Liam Paninski
Columbia University, New York, NY

DAVID.EDWIN.CARLSON@GMAIL.COM
PATRICKSTINSON@GMAIL.COM
ARIPAKMAN@GMAIL.COM
LIAM@STAT.COLUMBIA.EDU

Abstract

Partition functions of probability distributions
are important quantities for model evaluation
and comparisons. We present a new method
to compute partition functions of complex and
multimodal distributions. Such distributions
are often sampled using simulated tempering,
which augments the target space with an auxil-
iary inverse temperature variable. Our method
exploits the multinomial probability law of the
inverse temperatures, and provides estimates
of the partition function in terms of a simple
quotient of Rao-Blackwellized marginal in-
verse temperature probability estimates, which
are updated while sampling. We show that
the method has interesting connections with
several alternative popular methods, and offers
some signiﬁcant advantages. In particular, we
empirically ﬁnd that the new method provides
more accurate estimates than Annealed Im-
portance Sampling when calculating partition
functions of large Restricted Boltzmann Ma-
chines (RBM); moreover, the method is suf-
ﬁciently accurate to track training and valida-
tion log-likelihoods during learning of RBMs,
at minimal computational cost.

1. Introduction
The computation of partition functions (or equivalently,
normalizing constants) and marginal likelihoods is an
important problem in machine learning, statistics and
statistical physics, and is necessary in tasks such as eval-
uating the test likelihood of complex generative mod-

∗These authors contributed equally to this work. The order of the
names was randomized.

els, calculating Bayes factors, or computing differences
in free energies. There exists a vast literature exploring
methods to perform such computations, and the popu-
larity and usefulness of different methods change across
different communities and domain applications. Clas-
sic and recent reviews include (Gelman & Meng, 1998;
Vyshemirsky & Girolami, 2008; Marin & Robert, 2009;
Friel & Wyse, 2012).
In this paper we are interested in the particularly
challenging case of highly multimodal distributions,
such as those common in machine learning applica-
tions (Salakhutdinov & Murray, 2008). Our major novel
insight is that simulated tempering, a popular approach
for sampling from such distributions, also provides an es-
sentially cost-free way to estimate the partition function.
Simulated tempering allows sampling of multimodal dis-
tributions by augmenting the target space with a random
inverse temperature variable and introducing a series of
tempered distributions. The idea is that the fast MCMC
mixing at low inverse temperatures allows the Markov
chain to land in different modes of the low-temperature
distribution of interest (Marinari & Parisi, 1992; Geyer
& Thompson, 1995).
As it turns out, (ratios of) partition functions have a sim-
ple expression in terms of ratios of the parameters of the
multinomial probability law of the inverse temperatures.
These parameters can be estimated efﬁciently by aver-
aging the conditional probabilities of the inverse tem-
peratures along the Markov chain. This simple method
matches state-of-the-art performance with minimal com-
putational and storage overhead. Since our estimator is
based on Rao-Blackwellized marginal probability esti-
mates of the inverse temperature variable, we denote it
Rao-Blackwellized Tempered Sampling (RTS).
In Section 2 we review the simulated tempering tech-
nique and introduce the new RTS estimation method.
In Section 3, we compare RTS to Annealed Importance

Partition Functions from Rao-Blackwellized Tempered Sampling

Sampling (AIS) and Reverse Annealed Importance Sam-
pling (RAISE) (Neal, 2001; Burda et al., 2015), two
popular methods in the machine learning community.
We also show that RTS has a close relationship with
Multistate Bennett Acceptance Ratio (MBAR) (Shirts &
Chodera, 2008; Liu et al., 2015) and Thermodynamic
Integration (TI) (Gelman & Meng, 1998), two meth-
ods popular in the chemical physics and statistics com-
munities, respectively.
In Section 4, we illustrate our
method in a simple Gaussian example and in a Restricted
Boltzmann Machine (RBM), where it is shown that RTS
clearly dominates over the AIS/RAISE approach. We
also show that RTS is sufﬁciently accurate to track train-
ing and validation log-likelihoods of RBMs during learn-
ing, at minimal computational cost. We conclude in Sec-
tion 5.

2. Partition Functions from Tempered

Samples

In this section, we start by reviewing the tempered sam-
pling approach. We then introduce our procedure to es-
timate partition functions by tempered sampling. We
note here that our approach is useful not only as a stand-
alone method for estimating partition functions, but is
also essentially free in any application using tempered
sampling.

2.1. Simulated Tempering

Consider an unnormalized, possibly multimodal distri-
bution proportional to f (x), whose partition function we
want to compute. Our method is based on simulated tem-
pering, a well known approach to sampling multimodal
distributions (Marinari & Parisi, 1992; Geyer & Thomp-
son, 1995). Simulated tempering begins with a normal-
ized and easy-to-sample distribution p1(x) and augments
the target distribution with a set of discrete inverse tem-
peratures {0 = β1 < β2 < ... < βK = 1} to create
a series of intermediate distributions between f (x) and
p1(x), given by

However, our method does not depend on this assump-
tion. When performing model comparison through like-
lihood ratios or Bayes factors, both distributions f (x)
and p1(x) can be unnormalized, and one is interested
in the ratio of their partition functions. For the sake of
simplicity, we consider here only the interpolating family
given in (2); other possibilities can be used for particular
distributions, such as moment averaging (Grosse et al.,
2013) or tempering by subsampling (van de Meent et al.,
2014).
When β ∈ {βk}K
k=1 is treated as a random variable, one
can introduce a prior distribution r(βk) = rk, and deﬁne
the joint distribution

p(x, βk) = p(x|βk)rk ,

=

fk(x)rk

Zk

.

(4)

(5)

Unfortunately, Zk is unknown.
know approximate values ˆZk. Then we can deﬁne

Instead, suppose we

q(x, βk) ∝ fk(x)rk

ˆZk

,

(6)

which approximates p(x, βk). We note that the distribu-
tion q depends explicitly on the parameters ˆZk. A Gibbs
sampler is run on this distribution by alternating between
samples from x|β and β|x.
In particular, the latter is
given by

q(βk|x) =

(cid:80)K

fk(x)rk/ ˆZk

k(cid:48)=1 fk(cid:48)(x)rk(cid:48)/ ˆZk(cid:48)

.

(7)

Sampling as such enables the chain to traverse the inverse
temperature ladder stochastically, escaping local modes
under low β and collecting samples from the target dis-
tribution f (x) when β = 1 (Marinari & Parisi, 1992).
When K is large, few samples will have β = 1. Instead,
an improved strategy to estimate expectations of func-
tions over the target distribution is to Rao-Blackwellize,
or importance sample, based on (7) to use all sample in-
formation (Geyer & Thompson, 1995).

where

and

p(x|βk) =

fk(x)

Zk

,

fk(x) = f (x)βk p1(x)1−βk ,

(cid:90)

Zk =

fk(x)dx .

(1)

(2)

(3)

2.2. Estimating Partition Functions
Letting ˆZ1 ≡ Z1 = 1, we ﬁrst note that by integrating
out x in (6) and normalizing, the marginal distribution
over the βk’s is

q(βk) =

.

(8)

(cid:80)K

rkZk/ ˆZk

k(cid:48)=1 rk(cid:48)Zk(cid:48)/ ˆZk(cid:48)

ZK is the normalizing constant that we want to compute.
Note that we assume Z1 = 1 and p(x|β1) = p1(x).

Note that if ˆZk is not close to Zk for all k, the marginal
probability q(βk) will differ from the prior rk, possi-
bly by orders of magnitude for some k’s, and the βk’s

Partition Functions from Rao-Blackwellized Tempered Sampling

and sometimes inﬁnite, for demonstration purposes only, we deﬁne ˆck ∝ 0.1 +(cid:80)N

Figure 1. Comparison of log ˆZk and log ˆck estimates, in some of the ﬁrst eight iterations of the initialization procedure described
in Section 2.4, with and without Rao-Blackwellization, with K = 100. The initial values were ˆZk = 1 for all k, and the prior
was uniform, rk = 1/K. The model is a RBM with 784 visible and 10 hidden units, trained on the MNIST dataset. Each iteration
consists of 50 Gibbs sweeps, on each of 100 parallel chains. Since in the non-Rao-Blackwellized case, the updates are unstable
i=1 δk,k(i) and normalize. Note that in the
Rao-Blackwellized case, the values of ˆck in the ﬁnal iteration are very close to those of rk, signaling that the ˆZk’s are good enough
for a last, long MCMC run to obtain the ﬁnal ˆZk estimates.

will not be efﬁciently sampled. One approach to com-
pute approximate ˆZk values is the Wang-Landau algo-
rithm (Wang & Landau, 2001; Atchade & Liu, 2010).
We use an iterative strategy, discussed in Section 2.4.
Given samples {x(i), βk(i)} generated from q(x, βk), the
marginal probabilities above can simply be estimated by
the normalized counts for each bin βk, 1
i=1 δk,k(i).
N
But a lower variance estimator can be obtained by the
Rao-Blackwellized form (Robert & Casella, 2013)

(cid:80)N

q(βk|x(i)) .

(9)

Note that our estimates in (9) are unbiased estimators
of (8), since

N(cid:88)

i=1

ˆck =

1
N

(cid:90)

Our main idea is that the exact partition function can be
expressed by ratios of the marginal distribution in (8),

Zk = ˆZk

r1
rk

q(βk)
q(β1)

k = 2, . . . , K .

(11)

Plugging our estimates ˆck of q(βk) into (11) immediately
gives us the consistent estimator

ˆZRTS
k = ˆZk

r1
rk

ˆck
ˆc1

k = 2, . . . , K .

(12)

The resulting procedure is outlined in Algorithm 1.

the log-likelihood of the {βk(i)} samples is

log q({βk(i)}N

i=1) =

N(cid:88)

i=1

− N log

log(Zk(i) )

(cid:32) K(cid:88)

k=1

(13)

(cid:33)

rkZk/ ˆZk

+ const.

Because βk(i) was sampled from q(β|x(i)), we can re-
duce variance by Rao-Blackwellizing the ﬁrst sum in
(13), resulting in

LRB[Z] =

log(Zk)q(βk|x(i))

(cid:33)

− N log

rkZk/ ˆZk

+ const,

(14)

(cid:33)

− N log

rkZk/ ˆZk

+ const .

The normalizing constants are estimated by maximizing
(14) subject to a ﬁxed Z1, which is known. Setting the
derivatives of (14) w.r.t. Zk’s to zero gives a system of
linear equations

Zk(cid:48) = r1

k = 2, . . . , K

(cid:18) δk(cid:48),k

(cid:19)

− 1

K(cid:88)

rk(cid:48)
ˆZk(cid:48)

ˆck

k(cid:48)=2
whose solution is (12).

q(βk) =

q(βk|x)q(x)dx .

(10)

= N

log(Zk)ˆck

N(cid:88)

i=1

k=2

K(cid:88)
(cid:32) K(cid:88)
K(cid:88)
(cid:32) K(cid:88)

k=2

k=1

k=1

2.3. Rao-Blackwellized Likelihood Interpretation

We can alternatively derive (12) by optimizing a Rao-
Blackwellized form of the marginal likelihood. From (8),

2.4. Initial Iterations
As mentioned above, the chain with initial ˆZk’s may mix
slowly and provide a poor estimator (i.e. small q(βk)’s

k1102030405060708090100120130140150160170logˆZkwithRao-BlackwellizationExactIteration 8Iteration 6Iteration 4Iteration 2Iteration 1k1102030405060708090100-12-10-8-6-4-20logˆckwithRao-Blackwellizationlogrkk1102030405060708090100100110120130140150160170logˆZkExactIteration 8Iteration 6Iteration 4Iteration 2Iteration 1k1102030405060708090100-12-10-8-6-4-20logˆcklogrkPartition Functions from Rao-Blackwellized Tempered Sampling

Algorithm 1 Rao-Blackwellized Tempered Sampling

Input: {βk, rk}k=1,...,K, N
Initialize log ˆZk, k = 2, ..., K
Initialize β ∈ {β1, ..., βK}
Initialize ˆck = 0, k = 1, ..., K
for i = 1 to N do

Transition in x leaving q(x|β) invariant.
Sample β|x ∼ (β|x)
Update ˆck ← ˆck + 1

N q(βk|x)

end for
Update ˆZRTS

k ← ˆZk

r1 ˆck
rk ˆc1

, k = 2, ..., K

k

are rarely sampled). Therefore, when the ˆZk’s are far
from the Zk’s (or equivalently, the rk’s are far from the
ˆck’s), the ˆZk’s estimates should be updated.
Our estimator in (12) does not directly handle the case
where ˆZk is sequentially updated. We note that the like-
lihood approach of (14) is straightforwardly adapted to
this case and is straightforwardly numerically optimized
(see Appendix A for details). A simpler, less compu-
tationally intensive, and equally effective strategy is as
follows: start with ˆZk = 1 for all k (or a better esti-
mate, if known), and iterate between estimating ˆck with
few MCMC samples and updating ˆZk with the estimated
ˆZRTS
using (12). In our experiments using many parallel
Markov chains, this procedure worked best when the up-
dated Markov chains started from the previous last x’s,
and fresh, uniformly random sampled βk’s.
Once the ˆZk’s estimates are close enough to the Zk’s
to facilitate mixing, a long MCMC chain can be run to
provide samples for the estimator. Because ˆck estimates
q(βk), and q(βk) (cid:39) rk when ˆZk (cid:39) Zk, a simple stop-
ping criterion for the initial iterations is to check the sim-
ilarity between ˆck and rk. For example, if we use a uni-
form prior rk = 1/K, a practical rule is to iterate the
few-samples chains until maxk |rk − ˆck| < 0.1/K.
Figure 1 shows the values taken by ˆZk and ˆck in these
initial iterations in a simple example. The ﬁgure also il-
lustrates the importance of using the Rao-Blackwellized
form (9) for ˆck, which dramatically reduces the noise in
the estimator 1
N

i=1 δk,k(i) for q(βk).

(cid:80)N

2.5. Bias and Variance

In Appendix B, we show that the bias and variance of
log ˆZk using Eqn. (12) can be approximated by

E(cid:104)

log ˆZRTS

k

(cid:105) − log Zk ≈ 1

2

(cid:20) σ2

1
ˆc2
1

(cid:21)

− σ2
k
ˆc2
k

,

(15)

and

k

+

(16)

σ2
k
ˆc2
k

Var[log ˆZRTS

− 2σ1k
ˆckˆc1

] ≈ σ2
1
ˆc2
1
1 = Var[ˆc1], σ2
k = Var[ˆck], and σ1k =
where σ2
Cov[ˆc1, ˆck]. This shows that the bias of log ˆZk has no
deﬁnite sign. This is in contrast to many popular meth-
ods, such as AIS, which underestimates log Zk (Neal,
2001), and RAISE, which overestimates log Zk (Burda
et al., 2015).

3. Related Work
In this section, we brieﬂy review some popular estima-
tors and explore their relationship to the proposed RTS
estimator (12).

3.1. Wang-Landau

A well-known approach to obtain approximate values of
the Zk’s is the Wang-Landau algorithm (Wang & Lan-
dau, 2001; Atchade & Liu, 2010). The setting is similar
to ours, but the algorithm constantly modiﬁes the ˆZk’s
along the Markov chain as different βk’s are sampled.
The factors that change the ˆZk’s asymptotically con-
verge to 1. The resulting ˆZk estimates are usually good
enough to allow mixing in the (x, β) space (Salakhutdi-
nov, 2010), but are too noisy for purposes such as likeli-
hood estimation (Tan, 2015).

3.2. AIS/RAISE

Annealed Importance Sampling (AIS) (Neal, 2001) is
perhaps the most popular method in the machine learn-
ing literature to estimate log ZK. Here, one starts from
a sample x1 from p1(x), and samples a point x2, using
a transition function K2(x2|x1) that leaves f2(x) invari-
ant. The process is repeated until one has sampled xK
using a transition function that leaves f (x) invariant. The
vector (x1, x2, ..., xK) is interpreted as a sample from an
importance distribution on an extended space, while the
original distribution p(xK) can be similarly augmented
into an extended space. The resulting importance weight
can be computed in terms of quotients of the fk’s, and
provides an unbiased estimator for ZK/Z1, whose vari-
ance decreases linearly with K. Note that the inverse
temperatures in this approach are not random variables.
The variance of the AIS estimator can be reduced by
averaging over several runs, but the resulting value of
log( ˆZK) has a negative bias due to Jensen’s inequality.
This in turn results in a positive bias when estimating
data log-likelihoods.
Recently, a related method, called Reverse Annealed Im-
portance Sampling (RAISE) was proposed to estimate

Partition Functions from Rao-Blackwellized Tempered Sampling

(cid:18) ˆck

rk

(cid:19)

− ˆc1
r1

is less general than MBAR, RTS has an analytic solu-
tion and only requires the storage of the ˆck statistics. We
note that this objective function is very similar to the one
discussed in Appendix A for combining different ˆZk’s.
Recent work has proposed a stochastic learning algo-
rithm based on MBAR/UWHAM (Tan et al., 2016). This
algorithm gives updates based on the sufﬁcient statistics
ˆck with

log ˆZ (t+1)

k

= log ˆZ (t)

k + γt

.

(19)

r1

rk

(cid:16)

(cid:17)(cid:17)

(cid:16) ˆc1

(cid:16) ˆck

(cid:17) − log

γt is a step size that is recommended to be set to
γt = t−1. We note that our estimator from (12)
in log space may be written in a similar form, as
, which is very related in form
log
to (19). We empirically found that when the partition
function estimates are far away from the truth, our up-
date (12) dominates over (19). Because the ﬁrst order
Taylor series approximation to our estimator is the same
as the term in (19), the updates will essentially only differ
by the selection of the step size γt when ˆck (cid:39) rk.
We also note that there is a particularly interesting rela-
tionships between the the cost function for MBAR and
the cost function for RTS. Note that Eq[ nk
N ] is equal to
q(βk) for tempered sampling. If the values of nk
N in (18)
are replaced by their expectation, the maximizer of (18)
is equal to the RTS estimator given in (12). We detail
this equivalency in Appendix D. Hence, the similarity of
MBAR and RTS will depend on how far the empirical
counts vary from their expectation.

3.4. Thermodynamic Integration

Thermodynamic Integration (Gelman & Meng, 1998)
is derived from basic calculus identities. Let us ﬁrst
assume that β is a continuous variable in [0, 1]. We
again deﬁne ∆x = log f (x) − log p1(x), and fβ(x) =
f (x)βp1(x)1−β. We note that

(cid:90)

the data log-likelihood in models with latent variables,
giving negatively biased estimates (Burda et al., 2015;
Grosse et al., 2015). The method performs a similar sam-
pling as AIS, but starts from a sample of the latent vari-
ables at βK = 1 and proceeds then to lower inverse tem-
peratures. In certain cases, such as in the RBM examples
we consider in Section 4.2, one can obtain from these es-
timates of the data log-likelihood an estimate of the par-
tition function, which will have a positive bias. The com-
bination of the expectations of these AIS and RAISE es-
timators thus ‘sandwiches’ the exact value (Burda et al.,
2015; Grosse et al., 2015).

3.3. BAR/MBAR

Bennett’s acceptance ratio (BAR) (Bennett, 1976), also
called bridge sampling (Meng & Wong, 1996), is based
on the identity

(17)

Zk
Z1

=

Ep(x|β1)[α(x)fk(x)]
Ep(x|βk)[α(x)f1(x)]

,

(cid:82) f1(x)fk(x)α(x)dx < ∞, which can be chosen to

where α(x) is an arbitrary function such that 0 <

minimize the asymptotic variance. BAR has been gen-
eralized to estimate partition functions when sampling
among multiple distributions, a method termed the mul-
tistate BAR (MBAR) (Shirts & Chodera, 2008).
Assuming that there are nk i.i.d. samples for each in-
verse temperature βk (N samples {xi}i=1,...,N in total),
and ∆x = log f (x) − log p1(x), the MBAR partition
function estimates can be obtained by maximizing the
log-likelihood function (Tan et al., 2012):

exp(− log Zk + βk∆xi)

nk
N

(cid:32) K(cid:88)

log

k=1

log Zr

N(cid:88)
K(cid:88)

1
N

i=1

nr
N

r=1

L[Z] =

+

(cid:33)

(18)

This method was recently rediscovered and shown to
compare favorably against AIS/RAISE in (Liu et al.,
2015). MBAR has many different names in different
literatures, e.g. unbinned weighted histogram analysis
method (UWHAM) (Tan et al., 2012) and reverse logis-
tic regression (Geyer, 1994).
Unlike RTS, MBAR does not use the form of q(β) when
estimating the partition function. As a price associated
with this increased generality, MBAR requires the stor-
age of all collected samples, and the estimator is calcu-
lated by ﬁnding the minimum of (18). This likelihood
function does not have an analytic solution, and Newton-
Raphson was proposed to iteratively solve this problem,
which requires O(N K 2 + K 3) per iteration. While RTS

d
dβ

log Z(β) =

fβ(x)dx

1

d
Z(β)
dβ
= Ex|β[∆x],

From calculus, we have

(cid:18) ZK

(cid:19)

Z1

(cid:90) 1

0

log

=

Ex|β[∆x]dβ = Ep(x|β)p(β)

(20)

(cid:20) ∆x

(cid:21)

p(β)

This equation holds for any p(β) that is positive over
the range [0, 1], and provides an unbiased estimator for
log Zk if unbiased samples from p(x|β) are available.
This is in contrast to AIS, which is unbiased on Zk, and
biased on log Zk. Given samples {x(i), β(i)}i=1,...,N ,

Partition Functions from Rao-Blackwellized Tempered Sampling

the estimator for log ZK is

(cid:92)log ZK = log Z1 +

N(cid:88)

i=1

1
N

∆x(i)
p(β(i))

log

RTS can be written as:

(cid:32) ˆZK

Z1

(cid:33)(RT S)
(cid:90) 1
(cid:90) 1

=

0

=

0

d
dβ

(cid:16)
log ˆcβ − log rβ + log ˆZβ
(cid:80)
(cid:80)
i q(β|xi)∆xi
j q(β|xj)

dβ .

(cid:17)

dβ,

(22)

There are two distinct approaches for generating sam-
ples and performing this calculation in TI. First, β can
be sampled from a prior p(β), and samples are generated
from fβ(x) to estimate the gradient at the current point in
β space. A second approach is to use samples generated
from simulated tempering, which can facilitate mixing.
However, the effective marginal distribution q(β) must
be estimated in this case.
When β consists of a discrete set of inverse temperatures,
the integral can be approximated by the trapezoidal or
Simpson’s rule.
In essence, this uses the formulation
in (20), and uses standard numerical integration tech-
niques. Recently, higher order moments were used to
improve this integration, which can help in some cases
(Friel et al., 2014). As noted by (Calderhead & Giro-
lami, 2009), this discretization error can be expressed
as a sum of KL-divergences between neighboring inter-
mediate distributions. If the KL-divergences are known,
an optimal discretization strategy can be used. However,
this is unknown in general.
While the point of this paper is not to improve the TI ap-
proach, we note that the Rao-Blackwellization technique
we propose also applies to TI when using tempered sam-
ples. This gives that the Monte Carlo approximation of
the gradient (20) is

(cid:12)(cid:12)(cid:12)(cid:12)β=βk

(cid:39) N(cid:88)

i=1

(cid:80)N
q(βk|xi)∆xi
j=1 q(βk|xj)

.

(21)

d
dβ

log Z(β)

This reduces the noise on the gradient estimates, and im-
proves performance when the number of bins is relatively
high compared to the number of collected samples. We
refer to this technique as TI-Rao-Blackwell (TI-RB).
TI-RB is further interesting in the context of RTS, be-
cause of a surprising relationship: in the continuous β
limit, RTS and TI-RB are equivalent estimators. How-
ever, when using discrete inverse temperatures, RTS does
not suffer from the discretization error that TI and TI-RB
do.
We show the derivation of this relationship in Appendix
C, but we give a quick description here. First, let the
inverse temperature β take continuous values. Replacing
the index k by β in (12), we note that the estimator for

K(cid:88)

Note that the integrand of (22) is exactly identical to the
TI-RB gradient estimate from the samples given in (21).
After integration, the estimators will be identical.
We stress that while the continuous formulation of RTS
and TI-RB are equivalent in the continuous limit, in the
discrete case RTS does not suffer from discretization er-
ror. And we reiterate that RTS is of course limited to the
case when samples are generated by the joint tempered
distribution q(x, β).
Parallels between other methods and Thermodynamic In-
tegration can be drawn as well. As noted in (Neal, 2005),
the log importance weight for AIS can be written as

log w =

(βk − βk−1)∆xk

(23)

k=2

and thus can be thought of as a Riemann sum approxima-
tion to the numerical integral under a particular sampling
approach.

4. Examples
In this section, we study the ability of RTS to estimate
partition functions in a Gaussian mixture model and in
Restricted Boltzmann Machines and compare to esti-
mates from popular existing methods. We also study
the dependence of several methods on the number K
of inverse temperatures, and show that RTS can provide
estimates of train- and validation-set likelihoods during
RBM training at minimal cost. The MBAR estimates
used for comparison in this section were calculated with
the pymbar package1.

4.1. Gaussian Mixture Example and Comparisons

Figure 2 compares the performance of RTS to several
methods, including MBAR and TI and its variants, in a
mixture of two 10-dimensional Gaussians (see Appendix
E.1 for speciﬁc details). The sampling was performed
using a novel adaptive Hamiltonian Monte Carlo method
for tempered distributions of continuous variables, in-
troduced in Appendix E. In this case the exact partition
function can be numerically estimated to high precision.

1Code

available

from https://github.com/

choderalab/pymbar

Partition Functions from Rao-Blackwellized Tempered Sampling

Figure 3. Mean and root mean squared error (RMSE) of competing estimators of log ZK evaluated on RBMs with 784 visible units
trained on the MNIST dataset. The numbers of hidden units were 500 (Left and Middle Left) and 100 (Middle Right and Right).
In both cases, the bias from RTS decreases quicker than that of AIS and RAISE, and the RMSE of AIS does not approach that of
RTS at 1000 Gibbs sweeps until over an order of magnitude later. Each method is run on 100 parallel Gibbs chains, but the Gibbs
sweeps in the horizontal axis corresponds to each individual chain.

timate “truth,” we estimate the true mean as the average
of estimates from AIS and RTS with 106 samples from
100 parallel chains. We note the variance of these esti-
mates was very low (≈ 0.006).
Figure 3 shows a comparison of RTS versus AIS/RAISE
on two RBMs trained on the binarized MNIST dataset
(M=784, N=60000), with 500 and 100 hidden units.
The former was taken from (Salakhutdinov & Mur-
ray, 2008),2 while the latter was trained with the method
of (Carlson et al., 2015b).
In all the cases we used for p1 a product of Bernoulli
distributions over the v variables which matches the
marginal statistics of
follow-
ing (Salakhutdinov & Murray, 2008). We run each
method (RTS, AIS, RAISE) with 100 parallel Gibbs
chains.
In RTS, the number of inverse temperatures
was ﬁxed at K=100, and we performed 10 initial itera-
tions of 50 Gibbs sweeps each, following Section 2.4.
In AIS/RAISE, the number of inverse temperatures K
was set to match in each case the total number of Gibbs
sweeps in RTS, so the comparisons in Figure 3 corre-
spond to matched computational costs. We note that the
performance of RAISE is similar to the plots shown in
(Burda et al., 2015) for these parameters.

the training dataset,

4.3. Number of Temperatures

An advantage of the Rao-Blackwellization of tempera-
ture information is that there is no need to pick a pre-
cise number of inverse temperatures, as long as K is
big enough to allow for good mixing of the Markov
chain. As shown in Figure 4, RTS’s performance is not
greatly affected by adding more temperatures once there
are enough temperatures to give good mixing.
Also note that as the number of temperatures increases
RTS and the Rao-Blackwellized version of TI (TI-RB)

2Code and parameters available from: http://www.cs.

toronto.edu/˜rsalakhu/rbm_ais.html

Figure 2. Comparison of log Z estimation performance on a
toy Gaussian Mixture Model using an RMSE from 10 repeats.
TI Riemann approximates the discrete integral as a right Rie-
mann sum, TI trap uses the trapezoidal method, TI trap cor-
rected uses a variance correction technique developed in (Friel
et al., 2014), TI RB uses a Rao-Blackwellized version of TI
discussed in Appendix C.

Note that the estimators essentially give identical perfor-
mance; however, our method is the simplest to imple-
ment and use for tempered samples, with minimal mem-
ory and computation requirements.

4.2. Partition Functions of RBMs

The Restricted Boltzmann Machine (RBM) is a bipar-
tite Markov Random Field model popular in the machine
learning community (Smolensky, 1986). For the binary
case, this is a generative model over visible observations
v ∈ {0, 1}M and latent features h ∈ {0, 1}J deﬁned
by log f (v, h) = vT c + vT W h + hT b, for parameters
c ∈ RM , b ∈ RJ, and W ∈ RM×J. A fundamental per-
formance measure of this model is the log-likelihood of a
test set, which requires the estimation of the log partition
function. Both AIS (Salakhutdinov & Murray, 2008) and
RAISE (Burda et al., 2015) were proposed to address this
issue. We will evaluate performance on the bias and the
root mean squared error (RMSE) of the estimator. To es-

103104105GibbsSweeps450451452453454EstimatorMeanRTSAISRAISETrue103104105GibbsSweeps00.511.522.5EstimatorRMSERTSAISRAISE103104105106GibbsSweeps283284285286287EstimatorMeanRTSAISRAISETrue103104105106GibbsSweeps00.511.52EstimatorRMSERTSAISRAISE1000150020002500300035004000−10123Number of sampleslog RMSE  RTSMBARTI RiemannTI trapTI trap correctedTI RBPartition Functions from Rao-Blackwellized Tempered Sampling

timates of the mean of training and validation log-
likelihoods on the dna dataset3, with 180 observed binary
features, trained on a RBM with 500 hidden units.
We ﬁrst pretrain the RBM with CD-1 to get initial values
for the RBM parameters. We then run initial RTS iter-
ations with K = 100, as in Section 2.4, in order to get
starting log ˆZk estimates.
For the main training effort we used the RMSspectral
gradient method, with stepsize of 1e-5 and parameter
λ = .99 (see (Carlson et al., 2015b) for details). We
considered a tempered space with K = 100 and sam-
pled 25 Gibbs sweeps on 2000 parallel chains between
gradient updates. The latter is a large number compared
to older learning approaches (Salakhutdinov & Murray,
2008), but is similar to that used both in (Carlson et al.,
2015b) and (Grosse & Salakhudinov, 2015) that provide
state-of-the-art learning techniques.
With the samples collected after each 25 Gibbs sweeps,
we can estimate the ˆck’s to compute the running partition
function. To smooth the noise from such a small number
of samples, we consider partial updates of ˆZK given by

(cid:32)

(cid:33)α

ˆZ (t+1)

K

= ˆZ (t)
K

r1
rK

ˆc(t)
K
ˆc(t)
1

(24)

with α = 0.2, and t an index on the gradient update.
Similar results were obtained with .05 < α < .5. This
smoothing is also justiﬁed by the slowly changing na-
ture of the parameters. Figure 5 also shows the corre-
sponding value from AIS with 100 parallel samples and
10,000 inverse temperatures. Such AIS runs have been
shown to give accurate estimates of the partition func-
tion for RBMs with even more hidden units (Salakhut-
dinov & Murray, 2008), but involve a major computa-
tional cost that our method avoids. Using the settings
from (Salakhutdinov & Murray, 2008) adds a cost of 106
additional samples.

5. Discussion
In this paper, we have developed a new partition func-
tion estimation method that we called Rao-Blackwellized
Tempered Sampling (RTS). Our experiments show RTS
has equal or superior performance to existing methods
popular in the machine learning and physical chemistry
communities, while only requiring sufﬁcient statistics
collected during simulated tempering.
An important free parameter is the prior over inverse
temperatures, rk, and its optimal selection is a natural

3Available from: https://www.csie.ntu.edu.tw/

˜cjlin/libsvmtools/datasets/multiclass.
html

Figure 4. RMSE as a function of the number of inverse temper-
atures K for various estimators. The model is the same RBM
with 500 hidden units studied in Figure 3. Each point was ob-
tained by averaging over 200 estimates (20 for MBAR due to
computational costs) made from 10,000 bootstrapped samples
from a long MCMC run of 3 million samples.

become increasingly similar. We show explicitly in Ap-
pendix C that they are equivalent in the inﬁnite limit
of the number of temperatures. Due to computational
costs, running MBAR on a large number of temperatures
is computationally prohibitive. An issue when estimates
are non-Rao-Blackwellized is that the estimates eventu-
ally become unstable as we do not have positive counts
for each bin. This is addressed heuristically in the non-
Rao-Blackwellized version of RTS (TS) by adding a con-
stant of .1 to each bin. For TI, empty bins are imputed
by linear interpolation.

4.4. Tracking Partition Functions While Training

There are many approaches to training RBMs, includ-
ing recent methods that do not require sampling (Sohl-
Dickstein et al., 2010; Im et al., 2015; Gabri´e et al.,
2015). However, most learning algorithms are based
on Monte Carlo Integration with persistent Contrastive
Divergence (Tieleman & Hinton, 2009). This includes
proposals based on tempered sampling (Salakhutdinov,
2009; Desjardins et al., 2010). In these cases, the slow
speed of change of the parameters and the relatively low
number of samples required by RTS, allow us to track
the value of a train- and validation-set likelihoods during
RBM training at minimal additional cost. This allows us
to avoid overﬁtting by early stopping of the training. We
note that there are previous more involved efforts to track
RBM partition functions, which involve additional com-
putational and implementation efforts (Desjardins et al.,
2011).
This idea is illustrated in Figure 5, which shows es-

101102103NumberofTemperatures0.215EstimatorRMSERTSTSMBARTITI-RBPartition Functions from Rao-Blackwellized Tempered Sampling

References
Atchade, Y. and Liu, J. The Wang-Landau algorithm
in general state spaces: Applications and convergence
analysis. Statistica Sinica, 2010.

Bennett, C. Efﬁcient estimation of free energy differ-
ences from Monte Carlo data. Journal of Computa-
tional Physics, 1976.

Beskos, A., Pillai, N., Roberts, G., Sanz-Serna, J.-M.,
and Stuart, A. Optimal tuning of the hybrid Monte
Carlo algorithm. Bernoulli, 2013.

Burda, Y., Grosse, R., and R, S. Accurate and conser-
vative estimates of MRF log-likelihood using reverse
annealing. AISTATS, 2015.

Calderhead, B. and Girolami, M. Estimating Bayes
factors via thermodynamic integration and population
MCMC. Computational Statistics & Data Analysis,
53(12):4028–4045, 2009.

Carlson, D., Cevher, V., and Carin, L. Stochastic spectral
descent for Restricted Boltzmann Machines. AISTATS,
2015a.

Carlson, D., Hsieh, Y.-P., Collins, E., Carin, L., and
Cevher, V. Stochastic spectral descent for discrete
graphical models. IEEE J. Special Topics Signal Pro-
cessing, 2016.

Carlson, D. E., Collins, E., Hsieh, Y.-P., Carin, L., and
Cevher, V. Preconditioned spectral descent for deep
learning. In Advances in Neural Information Process-
ing Systems, pp. 2953–2961, 2015b.

Dellaportas, P. and Kontoyiannis, I. Control variates for
estimation based on reversible Markov Chain Monte
Carlo samplers. Journal of the Royal Statistical So-
ciety: Series B (Statistical Methodology), 74(1):133–
161, 2012.

Desjardins, G., Courville, A. C., Bengio, Y., Vincent,
P., and Delalleau, O. Tempered Markov Chain Monte
Carlo for training of Restricted Boltzmann Machines.
In International Conference on Artiﬁcial Intelligence
and Statistics, pp. 145–152, 2010.

Desjardins, G., Bengio, Y., and Courville, A. C. On
tracking the partition function. In Advances in Neu-
ral Information Processing Systems, pp. 2501–2509,
2011.

Friel, N., Hurn, M., and Wyse, J. Improving power pos-
terior estimation of statistical evidence. Statistics and
Computing, 2014.

Figure 5. A demonstration of the ability to track with mini-
mal cost the mean train and validation log-likelihood during the
training of a RBM on the dna 180-dimensional binary dataset,
with 500 latent features.

question. We explored several parametrized proposals
for rk, but in our experiments no distribution consistently
performed signiﬁcantly better than the uniform. We also
explored a continuous β formulation, but the resulting
estimates were less accurate. Additionally, we tried sub-
tracting off estimates of the bias, but this did not im-
prove the results. Finally, we tried incorporating a va-
riety of control variates, such as those in (Dellaportas &
Kontoyiannis, 2012), but did not ﬁnd them to reduce the
variance of our estimates in the examples we considered.
Other control variates methods, such as those in (Oates
et al., 2015), could potentially be combined with RTS in
continuous distributions. We also brieﬂy considered esti-
mating p(βk) via the stationary distribution of a Markov
process, which we discuss in Appendix F. This approach
did not consistently yield performance improvements.

Acknowledgements
We thank Ryan Adams for helpful conversations. Fund-
ing for this research was provided by DARPA N66001-
15-C-4032 (SIMPLEX), a Google Faculty Research
award, and ONR N00014-14-1-0243; in addition, this
work was supported by the Intelligence Advanced Re-
search Projects Activity (IARPA) via Department of In-
terior/ Interior Business Center (DoI/IBC) contract num-
ber D16PC00003. The U.S. Government is authorized to
reproduce and distribute reprints for Governmental pur-
poses notwithstanding any copyright annotation thereon.
Disclaimer: The views and conclusions contained herein
are those of the authors and should not be interpreted as
necessarily representing the ofﬁcial policies or endorse-
ments, either expressed or implied, of IARPA, DoI/IBC,
or the U.S. Government.

02000400060008000Iteration-100-90-80-70-60-50hlogp(v)iTrain-RTSValidation-RTSTrain-AISValidation-AISPartition Functions from Rao-Blackwellized Tempered Sampling

Friel, N. and Wyse, J. Estimating the evidence–a review.

Statistica Neerlandica, 66(3):288–308, 2012.

Gabri´e, M., Tramel, E. W., and Krzakala, F. Train-
ing Restricted Boltzmann Machines via the Thouless-
Anderson-Palmer free energy. In Advances in Neural
Information Processing Systems, pp. 640–648, 2015.

Gelman, A. and Meng, X.-L. Simulating normalizing
constants: From importance sampling to bridge sam-
pling to path sampling. Statistical science, pp. 163–
185, 1998.

Geyer, C. J.

Estimating normalizing constants and

reweighting mixtures. 1994.

Geyer, C. J. and Thompson, E. A. Annealing Markov
chain Monte Carlo with applications to ancestral infer-
ence. Journal of the American Statistical Association,
90(431):909–920, 1995.

Grosse, R. and Salakhudinov, R. Scaling up natural gra-
dient by sparsely factorizing the inverse Fisher ma-
In Proceedings of the 32nd International Con-
trix.
ference on Machine Learning (ICML-15), pp. 2304–
2313, 2015.

Grosse, R. B., Maddison, C. J., and Salakhutdinov, R. R.
Annealing between distributions by averaging mo-
ments. In Advances in Neural Information Processing
Systems, pp. 2769–2777, 2013.

Grosse, R. B., Ghahramani, Z., and Adams, R. P. Sand-
wiching the marginal likelihood using bidirectional
Monte Carlo. arXiv preprint arXiv:1511.02543, 2015.

Im, D. J., Buchman, E., and Taylor, G. Understanding
minimum probability ﬂow for RBMs under various
kinds of dynamics. ICLR Workshop Track, 2015.

Li, Y., Protopopescu, V., and Gorin, A. Accelerated sim-

ulated tempering. Physics Letters A, 2004.

Liu, Q., Peng, J., Ihler, A., and III, J. F. Estimating the
partition function by discriminance sampling. UAI,
2015.

Marin, J.-M. and Robert, C. P.

Importance sampling
methods for Bayesian discrimination between embed-
ded models. arXiv preprint arXiv:0910.2325, 2009.

Marinari, E. and Parisi, G. Simulated tempering: a new
monte carlo scheme. EPL (Europhysics Letters), 19
(6):451, 1992.

Meng, X.-L. and Wong, W. H. Simulating ratios of nor-
malizing constants via a simple identity: a theoretical
exploration. Statistica Sinica, 6(4):831–860, 1996.

Neal, R. M. Estimating ratios of normalizing constants
arXiv preprint

using linked importance sampling.
math/0511216, 2005.

Neal, R. Annealed importance sampling. Statistics and

Computing, 2001.

Neal, R. Handbook of Markov Chain Monte Carlo, chap-
ter MCMC using Hamiltonian dynamics. Chapman &
Hall / CRC Press, 2011.

Oates, C. J., Papamarkou, T., and Girolami, M. The con-
trolled thermodynamic integral for Bayesian model
evidence evaluation. Journal of the American Statisti-
cal Association, 2015.

Robert, C. and Casella, G. Monte Carlo statistical meth-

ods. Springer Science & Business Media, 2013.

Salakhutdinov, R. Learning deep Boltzmann machines
using adaptive MCMC. In Proceedings of the 27th In-
ternational Conference on Machine Learning (ICML-
10), pp. 943–950, 2010.

Salakhutdinov, R. and Murray, I. On the quantitative
analysis of Deep Belief Networks. In Proceedings of
the 25th International Conference on Machine Learn-
ing, pp. 872–879, 2008.

Salakhutdinov, R. R. Learning in markov random ﬁelds
using tempered transitions. In Advances in neural in-
formation processing systems, pp. 1598–1606, 2009.

Shirts, M. R. and Chodera, J. D. Statistically optimal
analysis of samples from multiple equilibrium states.
The Journal of Chemical Physics, 129(12):124105,
2008.

Smolensky, P. Information processing in dynamical sys-
tems: Foundations of harmony theory. Technical re-
port, DTIC Document, 1986.

Sohl-Dickstein, J., Battaglino, P., and DeWeese, M. R.

Minimum probability ﬂow learning. ICML, 2010.

Tan, Z. Optimally adjusted mixture sampling and locally
Journal of Computa-
weighted histogram analysis.
tional and Graphical Statistics, (just-accepted), 2015.

Tan, Z., Gallicchio, E., Lapelosa, M., and Levy, R. M.
Theory of binless multi-state free energy estimation
with applications to protein-ligand binding. The Jour-
nal of Chemical Physics, 136(14):144102, 2012.

Tan, Z., Xia, J., Zhang, B. W., and Levy, R. M. Locally
weighted histogram analysis and stochastic solution
for large-scale multi-state free energy estimation. The
Journal of Chemical Physics, 144(3):034107, 2016.

Partition Functions from Rao-Blackwellized Tempered Sampling

Tieleman, T. and Hinton, G. Using fast weights to im-
In Proceed-
prove persistent contrastive divergence.
ings of the 26th Annual International Conference on
Machine Learning, pp. 1033–1040. ACM, 2009.

van de Meent, J.-W., Paige, B., and Wood, F. Temper-
ing by subsampling. arXiv preprint arXiv:1401.7145,
2014.

Vyshemirsky, V. and Girolami, M. A. Bayesian ranking
of biochemical system models. Bioinformatics, 24(6):
833–839, 2008.

Wang, F. and Landau, D. P. Efﬁcient multiple-range ran-
dom walk algorithm to calculate the density of states.
Phys. Rev. Let. E, 2001.

Rao-Blackwellized Tempered Sampling: Supplemental Material

Partition Functions from

A. Mixed ˆZ Updates
We can generalize our Rao-Blackwellized maximum
likelihood interpretation in Section 2.3 to situations in
which ˆZ is not a ﬁxed set of quantities for all sam-
ples. Under these conditions, we can no longer use the
update in (12). However, we can easily ﬁnd the Rao-
Blackwellized log-likelihood, assuming i.i.d. βk sam-
ples. Approximately i.i.d. samples can be obtained by
sub-sampling with a rate determined by the autocorrela-
tion of sampled β. We empirically found that varying ˆZ
at late stages did not have a large effect on estimates.
Assume we have samples {x(i), β(i)}, with β|x(i) sam-
pled using estimates ˆZ(i)
k=1. Then our Rao-
Blackwellized log-likelihood is the following

= ( ˆZ (i)

k )K

Z;{ˆZ(i)}N

i=1

L

log Zkq(βk|x(i); ˆZ(i)

(cid:105)

=

N(cid:88)
− N(cid:88)

i=1

K(cid:88)
(cid:32) K(cid:88)

k=2

log

i=1

k(cid:48)=1

(cid:33)

)

,

rk(cid:48)Zk(cid:48)/ ˆZ (i)
k(cid:48)

(cid:104)

where

q(βk|x; ˆZ(i)

) =

(cid:80)K

fk(x)rk/ ˆZ (i)
k
k(cid:48)=1 fk(cid:48)(x)rk(cid:48)/ ˆZ (i)
k(cid:48)

.

Note that this expression is concave in log Z and can
be solved efﬁciently using the generalized gradient de-
scent methods of (Carlson et al., 2015a; 2016). The
total computational time of this approach will scale
O(K), whereas the Newton-Raphson method proposed
in MBAR would scale O(K 3) per-iteration.
It is not
clear how the number of iterations required in Newton-
Raphson will scale, and could potentially have a worse
dependence on K.

where qk = q(βk) and ∆ck = ˆck − qk. Taking expecta-
tions, and replacing qk by its estimate ˆck, gives

(cid:105) − log Zk ≈ 1

2

(cid:20) σ2

1
ˆc2
1

(cid:21)

− σ2
k
ˆc2
k

E(cid:104)

log ˆZRTS

k

,

(25)

and

k

Var[log ˆZRTS

] ≈ σ2
1
ˆc2
1
k = Var[ˆck], and σ1k =
1 = Var[ˆc1], σ2

− 2σ1k
ˆckˆc1

σ2
k
ˆc2
k

(26)

+

where σ2
Cov[ˆc1, ˆck].
From the CLT, the asymptotic variance of ˆck is

(cid:105)

(27)

(28)

V arq(q(βk|x))ak

,

N

where the factor

V ar(ˆck) =

∞(cid:88)

(cid:104)

ak = 1 + 2

corr

q(βk|x(0)), q(βk|x(i))

i=1

takes into account the autocorrelation of the Markov
chain. But estimates of this sum from the MCMC sam-
ples are generally too noisy to be useful. A more practi-
cal approach is to estimate V ar[ˆck] from ˆck estimates of
many parallel MCMC chains.

C. RTS and TI-RB Continuous β

Equivalence

(cid:32) ˆZK

Z1

log

We want to show the relationship mentioned in (22),
which we repeat here:

(cid:33)(RT S)
(cid:90) 1
(cid:90) 1

=

0

=

0

(cid:17)

d
dβ

(cid:16)
log ˆcβ − log rβ + log ˆZβ
(cid:80)
(cid:80)
i q(β|xi)∆xi
j q(β|xj)

dβ .

dβ,

Note that we can write the statistics ck as

B. Bias and Variance derivations
A Taylor expansion of log ˆZRTS
log(1 + x) (cid:39) x − x2/2, gives

k

, using (11)-(12) and

log ˆZRTS

k ≈ log Zk +

∆ck
qk

− ∆c1
q1

− (∆ck)2
2q2
k

+

(∆c1)2

2q2
1

ck =

=

q(βk|xi)

(cid:16)

(cid:17)
βk(cid:48)∆xi + log rk(cid:48) − log ˆZk(cid:48)

(cid:16)
βk∆xi + log rk − log ˆZk

(cid:17)

exp

(cid:80)K

k(cid:48)=0 exp

N(cid:88)
N(cid:88)

i=1

i=1

Partition Functions from Rao-Blackwellized Tempered Sampling

The continuous version of this replaces the index k by β,
and

the the likelihood of MBAR given in (18):

N(cid:88)
N(cid:88)

i=1

i=1

cβ =

=

q(β|xi)

(cid:82) 1

exp

0 exp

(cid:16)
(cid:16)
β∆xi + log rβ − log ˆZβ
α∆xi + log rα − log ˆZα

(cid:17)
(cid:17)

dα

The continuous form of the CTS estimator can be written
as an integral:

log

ZK
Z1

log cβ − log rβ + log ˆZβ
log cβ − log rβ + log ˆZβ

=

(cid:16)
−(cid:16)
(cid:90) 1

=

0

(cid:16)

d
dβ

(cid:17)(cid:12)(cid:12)(cid:12)β=1
(cid:17)(cid:12)(cid:12)(cid:12)β=0

(cid:17)

log cβ − log rβ + log ˆZβ

dβ

(29)

∂L[Z]
∂ log Zk

(cid:33)
exp(− log Zk + βk∆xi )

(cid:32) K(cid:88)

log

k=1

log Zk

N(cid:88)
N(cid:88)

1
N

i=1

nk
N

k=1

nk
N

L[Z] =

+

The partial derivative of this likelihood with respect to
log Zk is given by:

∂L[Z]
∂ log Zk

=

nk
N
− 1
N

N(cid:88)

i=1

(31)

nk

K(cid:88)
N exp(− log Zk + βk∆xi)
exp(− log Zj + βj∆xi)
nj
N

j=1

Replacing nk

N with its expectation for all k gives

= q(βk)

− 1
N

N(cid:88)

i=1

(32)

K(cid:88)
q(βk) exp(− log Zk + βk∆xi )
q(βj) exp(− log Zj + βj∆xi)

j=1

Noting that q(βk) ∝ Zk/ ˆZkrk, we have
∂L[Z]
∂ log Zk

= q(βk)

N(cid:88)
N(cid:88)

i=1

i=1

− 1
N

= q(βk)
− 1
N

,

j=1

Zj
ˆZj

Zk
ˆZk

rj exp(− log Zj + βj∆xi)

rk exp(− log Zk + βk∆xi)

(cid:80)K
(cid:80)K
exp(− log ˆZk + βk∆xi)
j=1 exp(− log ˆZj + βj∆xi)
N(cid:88)

q(βk|xi),

,

(33)

= q(βk) − 1
N
= q(βk) − ˆck .

i=1

Setting the partial derivative to 0 and substituting the def-
inition of q(β) into (33) gives a solution of

(cid:80)K

Zk/ ˆZkrk
j=1 Zj/ ˆZjrj

= ˆck,

(34)

which is identical to the RTS update in (12).

We ﬁrst analyze the derivative of cβ, which is

=

log

d
dβ

d
dβ

log cβ

N(cid:88)

exp

(cid:16)

β∆xi + log rk − log ˆZk

(cid:17)
(cid:82) 1
0 exp (α∆xi + log rα − log zα) dα
(cid:17)

(cid:17) d

1

β∆xi + log rβ
ˆZβ

dβ

=

i=1

i=1

i=1

exp

(cid:16)

β∆xi + log rβ
ˆZβ

0 exp
q(β|xi) d

(cid:82) 1
(cid:16)
exp(β∆xi +log rβ−log ˆZβ)
0 exp(α∆xi +log rα−log ˆZα)dα
(cid:82) 1

(cid:80)N
× N(cid:88)
(cid:88)
(cid:34)(cid:88)
The last line follows since(cid:80)N

(cid:16)
(cid:16)
α∆xi + log rα − log ˆZα
(cid:80)
β∆xi + log rβ − log ˆZβ
(cid:35)
j q(β|xj)
d
dβ

(cid:80)
q(β|xi)
j q(β|xj)

∆xi

(cid:80)

=

=

+

dβ

i

i

(log rβ − log ˆZβ)

(cid:17)
(cid:17)

dα

q(β|xi)
j q(β|xj ) = 1. The
dβ (log rβ − log ˆZβ) term in (29) and (30) simply cancel.

i=1

d

(30)

D. Similarity of RTS and MBAR
In this section, we elaborate on the similarity of the like-
lihood of MBAR and RTS. To prove this, we ﬁrst restate

E. Adaptive HMC for tempering
Here we consider sampling from a continuous distri-
bution using Hamiltonian Monte Carlo (HMC) (Neal,

Partition Functions from Rao-Blackwellized Tempered Sampling

2011). Brieﬂy, HMC simulates Hamiltonian dynamics
as a proposal distribution for Metropolis-Hastings (MH)
sampling. In general, one cannot simulate exact Hamil-
tonian dynamics, so usually one uses the leapfrog al-
gorithm, a ﬁrst order discrete integration scheme which
maintains the time-reversibility and volume preservation
properties of Hamiltonian dynamics.
(Li et al., 2004) found using different step sizes improved
sampling various multimodal distributions using random
walk Metropolis proposal distributions. However, un-
der their scheme, besides step sizes being monotoni-
cally decreasing in β, it is unclear how to set these step
sizes. Additionally, in target distributions that are high-
dimensional or have highly correlated variables, random
walk Metropolis will work badly.
For most distributions of interest, as β decreases, p(x|β)
becomes ﬂatter; thus, for HMC, we can expect the MH
acceptance probability to decrease as a function of β, en-
abling us to take larger jumps in the target distribution
when the temperature is high. As the stepsize of the
leapfrog integrator gets smaller, the linear approxima-
tion of the solution to the continuous differential equa-
tions becomes more accurate, and the MH acceptance
probability increases (for an inﬁnitely small stepsize, the
simulation is exact, and under Hamiltonian dynamics,
the acceptance probability is 1). Thus, p(accept|) de-
creases with . Putting this idea together, we model
p(accept|β, ) as a logistic function for each β ∈ {0 =
β1, ..., βJ = 1}

logit(p(accept|β, )) = w(j)

(35)
Given some data {(β(i), s(i), y(i))}i=1,...,N (y(i) = 1 if
proposed sample i was accepted, and y(i) = 0 if it was
rejected), we ﬁnd

0 + w(j)
1 

(36)

h(w(j))

J(cid:88)
j=1
1 ≤ 0
w(j)
g(βj, ) ≤ g(βj−1, ) ∀ 
(cid:88)

y(i) log(g(β(i), (i)))

max
{w(j)}

s.t.

where

h(w(j)) =

i:β(i)=βj

+(1 − y(i)) log(1 − g(β(i), (i)))

and
g(βj, ) = p(accept|βj, ) =

1 + exp(−(w(j)

1
0 + w(j)

1 ))
The last constraint can be satisﬁed by enforcing
g(βj, min) ≤ g(βj−1, min) and g(βj, max) ≤

g(βj−1, max), as doing so will ensure g(βj, ) ≤
g(βj−1, ) for all  ∈ [min, max]. Before solving (36),
we ﬁrst run chains at ﬁxed β = 0 and β = 1, running a
basic stochastic optimization method to adapt each step-
size until the acceptance rate is close to the target accep-
tance rate, which we take to be 0.651, which is suggested
by (Beskos et al., 2013). We take these stepsizes to be
max and min, respectively. Once we have approximated
p(accept|β, ), choosing the appropriate proposal distri-
bution given β is simple:

ˆopt(βj) =

logit(p(acc)) − w(j)

0

w(j)
1

If ˆopt is outside [min, max], we project it into the interval.

E.1. Example

Here we consider a target distribution of a mixture of
two 10-dimensional Gaussians, each having a covariance
of 0.5I separated in the ﬁrst dimension by 5. Our prior
distribution for the interpolating scheme is a zero mean
Gaussian with covariance 30I. The prior was chosen by
looking at a one-dimensional projection of the target dis-
tribution and picking a zero-mean prior whose variance,
σ2 adequately covered both of the modes. The variance
of the multidimensional prior was taken to be σ2I, and
the mean to be 0. Our prior on temperatures was taken
to be uniform. We compare the adaptive method above
to simulation with a ﬁxed step size, which is determined
by averaging all of the step sizes, in an effort to pick the
optimal ﬁxed step size. The below ﬁgures show an im-
provement over the ﬁxed step size in mixing and partition
function estimation using our adaptive scheme.
We obtained similar improvements using random walk
Metropolis by varying the covariance of an isotropic
Gaussian proposal distribution. We note another scheme
for discrete binary data may be used, where the number
of variables in the target distribution to “ﬂip”, as a func-
tion of temperature, is a parameter.

F. Estimating q(βk) from a transition matrix
Instead of estimating q(βk) by Rao-Blackwellizing via
ck in (9), it is possible to estimate q(βk) from the sta-
tionary distribution of a transition matrix. The key idea
here is that the transition matrix accounts for the sam-
pling structure used in MCMC algorithms, whereas ck
is derived using i.i.d. samples. Suppose that we have
a Gibbs sampler sequence x1 → β1 → x2 ··· → βN .
For a Gibbs sampler, this sequence can be collapsed to

Partition Functions from Rao-Blackwellized Tempered Sampling

Figure 6. (Left) Mixing in β under the ﬁxed step size. (Center) Mixing in β under the adaptive scheme. (Right) Partition function
estimates under the ﬁxed step size and adaptive scheme after 10000 samples. Mixing in β using a ﬁxed step size is visibly slower
than mixing using the adaptive step size, which is reﬂected by the error in the partition function estimate.

Figure 7. An illustration of the effect of estimating the stationary distribution from the transition matrix. Both plots show the RMSE
on RBMs averaged over 20 repeats. Experimental procedure is the same as the main text. (Left) RTS, TM, and RTM compared on a
784-10 RBM. Because the latent dimensionality is small, mixing is very effective and accounting for the transition matrix improves
performance consistently by about 10%. (Right) For an 784-200 RBM, the approximation as a Markov transition is inaccurate, and
we observe no performance improvements.

Markov transitions over βk with

to Rao-Blackwellize over the samples, where

p(βn+1 = βk|βn = βj),

(cid:88)

=

x

= Pjk.

p(βn+1 = βk|x)p(x|βn = βj),

The top eigenvector of P gives the stationary distribu-
tion over βk, which is q(βk). We brieﬂy mention two
importance sampling strategies to estimate this transition
matrix. First, this matrix can simply be estimated with
empirical samples, with

Pjk ∝(cid:88)

1{βn+1=βk,βn=βj},

where 1{·} is the identity function. Then q(βk) is es-
timated from the top eigenvector. We denote this strat-
egy Stationary Distribution (SD). A second approach is

Pjk ∝(cid:88)

p(βn + 1 = βk|xn)1{βn=βj}.

We denote this strategy as Rao-Blackwellized Stationary
Distribution (RSD).
The major drawback of this approach is that it is rare
to have exact Gibbs samples over p(x|β), but instead
we have a transition operation T (xn|β, xn−1).
In this
case, it is unclear whether this approach is useful. We
note that in simple cases, such as a RBM with 10 hidden
nodes, RSD can sizably reduce the RMSE over RTS, as
shown in Figure 7(Left). However, in more complicated
cases when the assumption that we have a Gibbs sam-
pler over p(x|beta) breaks down, there is essentially no
change between RTS and RSD, as shown in a 200 hidden
node RBM in Figure 7 (Right). Our efforts to correct the
transition matrix for the transition operator instead of a
Gibbs sampler did not yield performance improvements.

20004000600080001000000.20.40.60.81Sample numberβ20004000600080001000000.20.40.60.81Sample numberβ−0.200.20.40.60.811.20510152025βlogZ(β)  adaptiveaveragedtrue103104105Gibbs Sweeps10-210-1RMSERTSSDRSD103104105Gibbs Sweeps0.150.20.250.30.350.40.450.50.550.6RMSERTSSDRSD