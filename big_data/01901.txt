SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

1

Conﬁdence-Constrained Maximum Entropy

Framework for Learning from Multi-Instance Data

Behrouz Behmardi, Forrest Briggs, Xiaoli Z. Fern, and Raviv Raich
School of EECS, Oregon State University, Corvallis, OR, 97331-5501

{behmardb,briggsf,xfern,raich}@eecs.oregonstate.edu

Abstract—Multi-instance data, in which each object (bag) con-
tains a collection of instances, are widespread in machine learning,
computer vision, bioinformatics, signal processing, and social
sciences. We present a maximum entropy (ME) framework for
learning from multi-instance data. In this approach each bag
is represented as a distribution using the principle of ME. We
introduce the concept of conﬁdence-constrained ME (CME) to
simultaneously learn the structure of distribution space and infer
each distribution. The shared structure underlying each density
is used to learn from instances inside each bag. The proposed
CME is free of tuning parameters. We devise a fast optimization
algorithm capable of handling large scale multi-instance data.
In the experimental section, we evaluate the performance of the
proposed approach in terms of exact rank recovery in the space of
distributions and compare it with the regularized ME approach.
Moreover, we compare the performance of CME with Multi-
Instance Learning (MIL) state-of-the-art algorithms and show
a comparable performance in terms of accuracy with reduced
computational complexity.

Index Terms—Maximum entropy, Multi-Instance Learning, Den-

sity estimation, Nuclear norm minimization, Topic models.

6
1
0
2

 
r
a

M
7

 

 
 
]

G
L
.
s
c
[
 
 

1
v
1
0
9
1
0

.

3
0
6
1
:
v
i
X
r
a

I. INTRODUCTION

In the multi-instance data representation, objects are viewed
as bags of instances. For example, a document can be viewed
as a bag of words, an image can be viewed as bag of segments,
and a webpage can be viewed as a bag of links (see Fig. 1).
Multi-instance data representation has been used in many areas

(a)

(b)

Fig. 1. Multi-instance representation for (a) text documents and (b) images.

in machine learning and signal processing, e.g., drug activity
detection [1], multi-task learning [2],
text classiﬁcation [3],

This work was partially supported by the National Science Foundation grant

CCF-1254218.

music analysis [4], object detection in image [5], and content-
based image categorization [6]. Machine learning algorithms are
described as either supervised or unsupervised. Multi-Instance
Learning (MIL) refers to the prediction or supervised learning
problem [3], [7] in which the main goal is to predict the label of
an unseen bag, given the label information of the training bags.
On the other hand, unsupervised learning (also referred to as
grouped data modeling [8]) can be applied to unlabeled multi-
instance data with the goal of uncovering an underlying structure
and a representation for each bag in a collection of multiple
instance bags. In supervised MIL, each bag is associated with
a class label and the goal is to predict the label for an unseen
bag given all the instances inside the bag. Due to the ambiguity
of the label information related to instances, supervised MIL is
a challenging task. Since the introduction of the MIL approach
in machine learning and signal processing, numerous algorithms
have been proposed either by extending traditional algorithms to
MIL, e.g., citation kNN [7], MI-SVM and mi-SVM [3], neural
network MIL [9], or devising a new algorithm speciﬁcally for
MIL, e.g., axis-parallel rectangles (APR) [1], diverse density
(DD) [10], EM-DD [11], and MIBoosting [12]. MIL has been
studied in an unsupervised setting in [13].

the bag level and it

Many of the aforementioned algorithms may compute bag-
level similarly metrics (e.g., Haussdoff distance or Mahalanobis
distance) based on instance-level similarity [14]. Instance-level
metrics can become computationally expensive. Computation
of pairwise similarities between of pairs of instance from two
given bags involves a computational complexity that increases
quadratically in the number of instances in each bag. Moreover,
instance level metrics may not reﬂect the structure similarity
deﬁned at
to identify the
characteristics of each bag using instance-level similarities [15].
Some kernel approaches have been proposed to measure the
similarity at the bag-level [15]. This approach enables the use
of kernel based methods for single instance representation to
be extened to the bag-level. However, the kernel computation is
quadratic in the number of instances per bag. The problem of
computational complexity associated with instance-level metrics
has been alleviated by representing each bag with few samples in
a very high dimension, e.g., single-blob-with-neighbors (SBN)
representation for each image [16].

is difﬁcult

In this paper, we consider the problem of associating each
bag with a probability distribution obtained by the principle
of maximum entropy. Assuming that each instance in a bag
is generated i.i.d. from an unknown distribution, we ﬁt to each
bag a distribution while maintaining a common shared structure
among bags (see Fig. 2). This approach has several advantages
over existing approaches. First, the problem can be solved in a
convex framework. Second, it maps each bag of instances into

2

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

Fig. 2. Maximum entropy framework used to ﬁt a density to instances (e.g., words) extracted from documents.

a point in the probability distribution space providing a summa-
rized representation to the data. In this framework, each bag is
parametrized by a vector that carries all the information about
the instances inside each bag. Third, a meaningful metric can be
deﬁned over the space of distributions to measure the similarity
among bags. Moreover, the computational complexity signiﬁ-
cantly drops from quadratic to linear in the number of instances
inside each bag. The joint density estimation framework with
regularization facilitates dimension reduction in the distribution
space and introduces a sparse representation of bases which span
the space of distributions. Using sparse representations of basis
functions to learn the space of distributions in a non-parametric
framework has been studied in [17].

Our contributions in this paper are: 1) we introduce a new
framework for learning from multi-instance data using the prin-
ciple of maximum entropy, 2) a metric deﬁned over the space of
the distributions is introduced to measure the similarities among
bags in multi-instance data, 3) we propose the conﬁdence-
constrained maximum entropy (CME) method to learn the space
of distributions jointly, 4) an accelerated proximal gradient
approach is proposed to solve the resulting convex optimization
problem, 5) the performance of the proposed approach is evalu-
ated in terms of exact rank recovery in the space of distributions
and compared with regularized ME, and 6) we examine the
classiﬁcation accuracy of CME on four real world datasets and
compared the results with MIL state-of-the-art algorithms.

II. PROBLEM STATEMENT

We are given N bags X1, X2, . . . , XN . The ith bag Xi
given by Xi = {xi1, xi2, . . . , xini},
is a set of ni feature
vectors. Each feature vector xij ∈ X and X ⊂ Rd. In
addition, we assume that the bags are statistically independent
and that instances within the same bag are independent and
identically distributed (i.i.d.). More speciﬁcally, for the ith bag
we assume that xij for j = 1, 2, . . . , ni are drawn i.i.d. from
a probability density function pi(x). We consider the problem
of unsupervised learning of distribution for each bag using the
maximum entropy framework. The goals are to 1) provide a
latent representation for each bag Xi using a generative model
pi(x) obtained by maximum entropy and 2) provide a joint
probability framework with a regularization which takes into
account the model complexity and limited number of samples.

III. MAXIMUM ENTROPY FRAMEWORK FOR LEARNING

FROM MULTI-INSTANCE DATA

We consider the maximum entropy framework for modeling
multi-instance data by associating multi-instance bags with

probability distributions. We are interested in a framework that
will allow convenient incorporation of structure (e.g., geometric,
low-dimension) in the distribution space. The problem of density
estimation can be deﬁne as follows. Given an i.i.d. set of
samples X = {x1, x2, . . . , xn} from an unknown density
function p(x), ﬁnd an estimator for p(x). We use the frame-
work of maximum entropy to estimate p(x) [18], [19]. In the
maximum entropy framework one is interested in identifying
a unique distribution given a set of constraints on generalized
moments of the distributions: Ep[φ(x)] = α where φ(x) =
[φ1(x), φ2(x), . . . , φm(x)]T is an m-dimensional vector of basis
functions deﬁned over instance space X , i.e., φi : X → R and
α ∈ Rm. Note that the basis function φi(x), i = {1, 2, . . . , m},
can be any real valued function such as polynomials, splines
or trigonometric series. For example, in a Gaussian distribution,
φ1(x) = x and φ2(x) = x2. Additionally, αi is the expected
value of the ith feature function. For example, in a Gaussian
distribution, α1 = µ and α2 = σ2 + µ2. This framework has
the advantage of not restricting the class of the distribution
to a speciﬁc density and considers a wide range of density
functions in the class of exponential family hence, has a good
approximation capability. In fact, it is shown that with a rich
set of basis function φ(x), the approximation error decreases
in order of O(1/m) where m is the number of basis [20]. We
explain the maximum entropy approach below.

A. Single density estimation (SDE)

ME framework for density estimation was ﬁrst proposed by
Janes [21] and has been applied in many areas of computer
science and signal processing including natural language pro-
cessing [22], species distribution modeling [23], text classiﬁca-
tion [24], and image processing [25]. ME framework ﬁnds a
unique probability density function p(x) over X that satisﬁes
the constraints Ep[φ(x)] = α. In principle, many density
functions can satisfy the constraints. The maximum entropy
approach selects a unique distribution among them that has the
maximum entropy. The problem of single density estimation in
the maximum entropy framework can be formulated as:

maximize H(p)
subject to Ep[φ] = α

(1)

p(x)dx = 1,

ZX

where H(p) = −R p(x) log p(x)dx is the entropy of p(x)
and Ep[φ(x)] = R p(x)φ(x)dx. For now, we ignore the non-

negativity constraints and later show that the optimal solution,

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

3

despite the exclusion of these constraints, is non-negative. Note
that the objective function in (1) is strictly convcave (Hessian
− 1
p(x) < 0) therefore, it has a unique global optimum solution.
To ﬁnd the optimum solution to (1) p∗(x), we ﬁrst construct
the Lagrangian L(p(x), λ, γ) = H (p(x)) + λT (Ep[φ] − α) −
γ(R p(x)dx − 1), where λ ∈ Rm and γ ∈ R are dual variables
corresponding to m + 1 constraints imposed on the solution.
Then, we hold λ and γ constant and maximize the Lagrangian
w.r.t. p(x). This yields an expression for p∗(x) in terms of
the dual variables. Finally, we substitute p∗(x) back into the
Lagrangian, solving for the optimal value of λ and γ (λ∗ and
γ∗, respectively).

The derivative of the Lagrangian w.r.t. to p(x) given λ and γ

are ﬁxed is given by

∂L
∂p(x)

= −(log p(x) + 1) + λT φ(x) − γ.

Equating (2) to zero and solving for p(x), we obtain

(2)

(3)

p∗(x; λ, γ) = exp(cid:0)λT φ(x)(cid:1) exp (−γ − 1).

Equation (3) represents p∗(x) w.r.t. the dual variables λ and
it to one to obtain γ∗.
γ. We can integrate p∗(x) and set
exp{λT φ(x)}dx.

Therefore, p∗(x) can be written as

Hence, γ∗ = Z(λ)− 1, where Z(λ) = logRX
p∗λ(x) = exp(cid:0)λT φ(x) − Z(λ)(cid:1).

Note that
the maximum entropy distribution given in (4),
satisﬁes the non-negativity, since the exponential function is
always non-negative. If we substitute p∗λ(x) and γ∗ back into
the Lagrangian, we obtain the dual function g(λ) as

(4)

Therefore,

g(λ) = L(p∗λ(x), λ, γ∗)

= Z(λ) − λT α

λ∗ = arg min
λ

g(λ)

(5)

(6)

∂λ∗

Since g(λ) is a smooth convex function, setting g(λ) = 0
yeilds optimum solution λ∗. Note that for λ∗, α = ∂Z(λ∗)
.
Based on the fundamental principle in the theory of Lagrangian
multiplier called, Karush-Kuhn-Tucker theorem, which asserts
under the conditions that the cost function is convex and all
the equality constraints are afﬁne (both holds for (1)),
the
optimal solution for dual is equal to the primal optimal solution
[26]. In other words, p∗λ(x) of (3) with λ = λ∗ given by
(6) is in fact the optimum solution to (1). There is a one-
to-one mapping between α in (1) and λ in (6). Therefore,
{p(x|α)|α ∈ Rm} = {p(x|λ)|λ ∈ Rm}. For example,
consider X = R and φ(x) = [x x2]T . By (4), p(x) =
exp(cid:0)λ1x + λ2x2 − Z(λ)(cid:1), where Z(λ) = − λ2
+ logq π
,
1
−λ2
4λ2
) (cid:19). Given
(x−(− λ1
λ2 ≤ 0 or p(x) =
q2π 1
p(x; λ1, λ2), E[φ(x)] = [− λ1
]T = [α1 α2]T .
We will now derive the maximum-likelihood (ML) estima-
tor for the parameter λ in pλ(x) given n i.i.d. observations
x1, . . . , xn. The log likelihood for (4) can be written as

exp(cid:18)−
2(
+ λ2
1
4λ2
2

−2λ2

2λ2
1

−2λ2

−2λ2

1

2λ2

))2

1

n

L(λ) = log p(x1, x2, . . . , xn) =
= n(λT Eˆp[φ(x)] − Z(λ)),

Xi=1

(λT φ(xi) − Z(λ))
(7)

where Eˆp[g(x)] denotes the empirical average of g(x) given by
n Pn
1
i=1 g(xi). Thus, we can write the negative log-likelihood
function as follows:
− L(λ) = −nEˆp[λT φ(x) − Z(λ)]

= nEˆp[log ˆp] − nEˆp[λT φ(x) − Z(λ)] − nEˆp[log ˆp]
(8)
= nD(ˆpkpλ) + Υ,
where Υ = −nEˆp[log ˆp] is a constant w.r.t. λ and D(pkq) =
Ep[log p − log q]. Therefore, maximizing the log-likelihood in
(7) w.r.t. λ is equivalent to minimizing the KL-divergence in (8)
w.r.t. λ. Thus, ˆλ can be obtained as a result of the following
optimization problem:

ˆλ = arg min
λ

= arg min

λ

nD(ˆpkpλ)
n(Z(λ) − λT Eˆp[φ(x)]).

(9)

There are several algorithms for solving ME, e.g., iterative
scaling [27] and its variants [23], gradient descent, Newton, and
quasi-Newton approach [28]. The ML optimization problem is
convex in terms of λ and can be solved efﬁciently using New-
ton’s method. Newton’s method requires the ﬁrst and second
derivative of the objective function w.r.t. λ. The derivatives of
nD(ˆpkpλ) are:

∇λ = n(Epλ [φ] − Eˆp[φ])

∇2
λ = n(Epλ[φ]Epλ [φ]T − Epλ [φφT ]).

Algorithm 1 provides the details for Newton’s method imple-
mentation. ME can overﬁt data due to low number of samples

Algorithm 1 Single density estimation algorithm

Input: X = {x1, x2, . . . , xn} samples from bag X, K, φ ∈
Rm, λ0 ∈ Rm.
Output: ˆλ ∈ Rm
for k = 1 to K do
λk−1∇k
∆λk = −∇2
Find tk using backtracking
λk+1 = λk + tk∆λk

λ

end for
ˆλ = λK

or large number of basis functions φ(x) [23]. Regularized ME
(RME) is proposed to overcome the issue of overﬁtting in ME
[29], [30]. RME can be either formulated as relaxing the equality
in (1) or putting a prior on the p.d.f. in (1) [31] (Laplace prior
yields l1 regularization and Gaussian prior yields l2 regulariza-
tion). Algorithms for solving RME are proposed in [23], [31].
Convergence analysis for RME is provided in [20], [23]. The
problem of single density estimation is presented to introduce
the maximum entropy framework for density estimation. In the
next section, the principle of maximum entropy is applied to
multiple density estimation.

B. Multiple density estimation (MDE)

Multiple density estimation (MDE) for multi-instance data
can be done following the same principle as explained for
single density estimation in the previous section. In MDE each
bag is represented by one distribution, i.e., pi(x) = pλi(x) =
i φ(x) − Z(λi)(cid:1) and the cost function for MDE, due to
exp(cid:0)λT

4

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

bag independence, is the sum of the individual bags negative
log-likelihood. MDE can be solved using the following mini-
mization:

where Λ = [λ1, λ2, . . . , λN ] and λi ∈ Rm, which results in
Λ = Aβ such that A ∈ Rm×k and β ∈ Rk×N . Hence Λ = Aβ
is a low-rank matrix.

niD( ˆpikpλi)

B. Regularized MDE (RMDE) using maximum entropy

To obtain a low-rank solution for Λ, we can solve a reg-
ularized nuclear norm MDE. The nuclear norm of a matrix
kXk∗ is deﬁned as the sum of the singular values of matrix
X. The nuclear norm is a special class of Schatten norm which
is deﬁned as kXkp = (Pi σp
p . When p = 1,kXkp is equal to
the nuclear norm. Nuclear norm enforces sparsity on the singular
values of matrix X, which results in a low-rank structure.
The heuristic replacement of rank with nuclear norm has been
proposed for various applications such as matrix completion
[33], [34], collaborative ﬁltering [35], and multi-task learning
[36].

i )

1

In RMDE, a regularized nuclear norm is added to the objec-

tive function in (10) yielding:

N

Xi=1

minimize

ni(Z(λi) − λT

i Eˆp[φi]) + ηkΛk∗,(11)
where η is the regularization parameter. RMDE can be viewed as
maximum a posteriori (MAP) criterion using a prior distribution
over matrix Λ of the form Ce−ηkΛk∗. This is similar to the
interpretation of l1-regularization for sparse recovery as MAP
with a Laplacian prior. Recently, We proposed a quasi-Newton
approach to solve RMDE [37]. RMDE can also be formulated
as a constrained MDE as follows:

N

ni(Z(λi) − λT

i Eˆp[φi]),

minimize

Xi=1
kΛk∗ ≤ ν,

subject to

(12)
where ν ≥ 0 is a tuning parameter. For each value of η in
(11) there is a value of ν in (12) which produces the same
solution [38]. One of the main challenges in regularized and
constrained MDE is the choice of regularization parameters
η and ν. Often, the regularization parameter is chosen based
on cross-validation which is computationally demanding and
is always biased toward the noise in the validation set. There
is an extensive discussion in [39] for model selection in topic
model. We propose the concept of conﬁdence-constrained rank
minimization for jointly learning the space of distributions
which overcome the issues of parameter tuning with regularized
and constrained MDE.

V. CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY (CME)

We propose the framework of conﬁdence-constrained maxi-
mum entropy (CME) for learning from multi-instance data. The
difﬁculties in tuning the regularization parameters in regularized
MDE will be addressed in CME by solving a constrained
optimization problem where the constraint only depends to the
dimension of the data (i.e., number of instances and number of
bags). Using the properties of the maximum entropy framework,
an in-probability bound on the objective function in (10) can be
obtained. The probability bound on the log-likelihood function
allows us to deﬁne a conﬁdence set. A conﬁdence set is a high-
dimensional generalization of the conﬁdence interval that we use

ˆΛ = arg min
Λ

= arg min

Λ

N

Xi=1
Xi=1

N

ni(Z(λi) − λT

i Eˆp[φi]),

(10)

where ˆΛ = [ˆλ1, . . . , ˆλN ], Λ = [λ1, . . . , λN ], N is total number
of bags, and ni is total number of instances in the ith bag.
The objective function in (10) is expressed as the sum of
the functions of individual variables λi which only depends
on the parameters of single density. Hence, MDE formulation
proposed in (10) considers the density estimation for each bag
individually. This individual estimate addresses the nature of
each dataset separately and ignores the fact that the underlying
structure of the data can be shared among all datasets. This
might cause a poor generalization performance due to the low
number of samples for some bags [32]. To address this, we use
a joint regularization on the parameter space to simultaneously
learn the structure of the distribution space and infer each
distribution while keep the origin of each data uninﬂuenced.
Hierarchical density estimation [30] formulates the problem of
MDE using l1 regularization. The regularization deﬁned on
each data separately and on the group of the data deﬁned
in the hierarchy. Note that the hierarchical structure of the
data is a prior information. However, in most cases in real
world applications the relations among the datasets are unknown
beforehand, e.g., in text or image datasets. In the following,
we proposed a framework for learning jointly in the space of
distributions using the principle of maximum entropy.

IV. STRUCTURED MULTIPLE DENSITY ESTIMATION

To improve the power of estimation in maximum entropy
framework, we choose a large number of basis functions φ. This
results in a large dimensional space for the parameter λ which
cause overﬁtting and poor generalization performance. To reduce
the effect of overﬁtting for density estimation, an efﬁcient way is
to reduce the dimensionality of the parameter space. This low di-
mensional space corresponds to the hidden structure of the data.
Rank minimization is an approach in dimension reduction which
ﬁnds a linear subspace of the observed data by constraining the
dimension of the given matrix. Rank minimization introduces
structures in the parameter space. In the following we ﬁrst deﬁne
rank recovery in the space of distributions and then show how
it can be formulated in the maximum entropy framework.

A. Rank recovery in the space of distributions

The dimension of the space of distributions is controlled by
the size of the basis φ = [φ1, φ2, . . . , φm]T . Often the size of
φ is large to allow accurate approximation of the distribution
space. Hence, we are interested in ﬁnding a smaller basis that
provides a fairly accurate replacement to the original basis φ.
We consider the problem of ﬁnding a new basis in the span of φ.
Suppose a smaller basis ψ can be obtained by ψ = AT φ, where
ψ = [ψ1, ψ2, . . . , ψk]T and A is a m× k matrix, where k < m.
Instead of using λT
i Φ involving m terms, one can use βT
i ψ
involving only k terms. In this case, φT Λ = ψT β = φT Aβ,

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

5

to restrict the search space of the problem. Search for a low-
rank Λ inside the conﬁdence set guarantees a low-rank solution
with high probability. Hence, in this approach the roles of ML
objective and rank constraint are reversed. We consider rank
minimization subject to ML objective constraint. The CME is
given by:

Pj ujsjvT

j , then

λT
i φ(x) =

=

k

Xj=1
Xj=1

k

sj(eT

i vj)(uT

j φ(x))

sj(eT

i vj)ψj(x) = βT

i ψ(x)

minimize

Rank(Λ)

subject to

N

Xi=1

niD(pˆλikpλi) ≤ ǫ(ωa),

(13)

2

where ǫ(ωa) = aN m
is an in-probability bound for the estima-
tion error. N is total number of bags and m is total number of
feature functions φ. Note in this formulation the tuning param-
eter ǫ(ωa) can be obtained by bounding PN
i=1 niD(pˆλikpλi)
Theorem 1: Let ˆλ = arg minλ nD(ˆpkpλ) deﬁned in (9).
With probability at least 1 − ωa:

using the following theorem.

p(cid:18) N
Xi=1

niD(pˆλikpλi) ≥ ǫ(ωa)(cid:19)≤

1
a

.

(For proof, see Appendix A). This theorem suggests that the
original low-rank representation distributions associated with the
N bags pλ1, pλ2, and pλN can be found within an ǫ(ωa)-ball
,
, pˆλ2
(as in (13)) around the rank-unrestricted ML estimates pˆλ1
with high probability. Additionally, ǫ(ωa) is free of
and pˆλN
any tuning parameters. It only depends on the dimensions of
dataset which is available prior to observing the data. Since (13)
involves rank minimization which is non-convex, we provide an
alternative convex relaxation to (13) in the following.

A. Conﬁdence-constrained maximum entropy nuclear norm
minimization (CMEN)

Constrained rank recovery of an unknown matrix has been
studied extensively in the literature in the communities of signal
processing, control system, and machine learning in problems
such as matrix completion and matrix decomposition [40]. In
general, rank minimization problems are NP hard [41]. Vari-
ous algorithms have been proposed to solve the general rank
minimization problem locally (e.g., see [42]). To solve the rank
minimization problem proposed in (13), we propose to apply
the widely adopted approach of replacing the rank minimization
with the tractable convex optimization problem of nuclear norm
minimization. In the following, CME nuclear norm minimization
is proposed as a convex alternative to (13):

minimize

subject to

N

kΛk∗
Xi=1

niD(pˆλikpλi) ≤ ǫ.

(14)

We denote the solution to (14) by ˆΛ∗. Since the nuclear norm
is a convex function, and the set of the inequality and equality
constraints construct a convex set, (14) is a convex optimization
problem. This nuclear norm regularization encourages a low-
rank representation to feature space, i.e., all features can be
represented as a linear combination of a few alternative features.
Consider the singular value decomposition of Λ = U SV T =

where k is the rank of matrix Λ. Similar to principle component
analysis, where each data point can be approximated as a linear
combination of a few principle components, each bag can be
represented as a distribution using a linear combination of only a
few basis functions [ψ1(x), . . . , ψk(x)]. This method facilitates a
dimension reduction in the space of distributions by representing
each distribution with a lower number of basis functions ψ (k ≪
m).

VI. CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY
NUCLEAR NORM MINIMIZATION ALGORITHM (CMENA)
The optimization problem in (14) can be written as follows:

minimize
subject to

f (Λ)
g(Λ) ≤ ǫ,

where f (Λ) = kΛk∗ and g(Λ) = PN

Lagrangian of (15) is

(15)
i=1 niD(pˆλikpλi). The

L(Λ, z) = f (Λ) + z(g(Λ) − ǫ),

(16)
where z ≥ 0 is the Lagrangian multiplier. The next step is to
minimize the Lagrangian (16) with respect to the primal variable
Λ. Deﬁne Λ∗(z) as:

Λ∗(z) = arg min

Λ L(Λ, z).

(17)

By replacing Λ∗(z) in the Lagrangian (16), we obtain the dual:

y(z) = L(Λ∗(z), z).

The dual formulation is given by the following optimization

maximize
y(z)
subject to z ≥ 0.

To optimize the Lagrangian with respect to the primal variable
Λ, we propose to use the proximal gradient approach. In the
following, we introduce the proximal gradient algorithm and
then show how it can be applied to solve (17).

A. Proximal gradient algorithm

Consider a general unconstrained nonsmooth convex opti-

mization problem in the form of the following:

minimize P (X) := f (X) + g(X),

(18)
where f : Rm×n → R is a convex, lower semicontinuous (lsc)
[43] function and g : Rm×n → R is a smooth convex function
(i.e., continuously differentiable). Assume ∇g(X) is Lipschitz
continuous on the domain of g, i.e.,
k∇g(X) − ∇g(Y )kF ≤ τgkX − Y kF , ∀X, Y ∈ Rm×n,
where τg > 0 is some positive scalar. Therefore, a quadratic
approximation of g at point X0 can be provided as follows:
τg
2 kX − X0k2
g(X) ≤ g(X0) + hX − X0,∇g(X0)i +
F .

6

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

Instead of minimizing P (X) in (18), we minimize an upper
bound on P (X), i.e.,

P (X) ≤ f (X) + g(X0) + hX − X0,∇g(X0)i
+

τg
2 kX − X0k2

F

= Q(X, X0),

where Q(X, X0) is f (X) plus a simple quadratic local model
of g(X) around X0.

To proceed further, we need to deﬁne the proximal mapping
(operator). A proximal mapping is an operator deﬁned for a
convex function h as proxh(x) = arg minu h(u) + 1
2.
2kx − uk2
For example, if h(x) is the indicator function of set C the
proximal mapping is the projection into set C and if h(x) is
k · k1 the proximal mapping is the soft thresholding operator
[43].

Since Q(X, X0) can be reformulated as

C. step size

In the proximal gradient approach, Λ will be updated in each
iteration based on 1/τg. In fact, 1/τg plays the role of step
size. However, in practice it is usually very conservative to set
a constant step size τg [44]. As long as the inequality L(Λ, z) ≤
Q(Λ, Λ0) is hold, the step size can be increased. Therefore, a
linesearch-like algorithm is proposed to ﬁnd a smaller value for
τg which satisﬁes the inequality (see Algorithm 2). The pseudo
code for CMENA is proposed in Algorithm 2.

Algorithm 2 CMENA

Input: Xi = {xi1, xi2, . . . , xini} sample from bag Xi, i =
1, . . . , N , K, φ ∈ Rm, Λ1, Λ0 ∈ Rm×N ,a1 = a0 = 1, z1
,
−
+, and α ∈ (0, 1).
z1
Output: λ∗i ∈ Rm and Z(λ∗i )
for j = 1 to . . . do

Q(X, X0) = f (X) +

τg
2 kX − (X0 −

1
τg ∇g(X0))k2

F + g(X0)

1
2τg k∇g(X0)k2
F ,

−

then X∗ the minimum of Q is
X∗ = arg min Q(X, X0)
τg
2 kX − (X0 −

= arg min f (X) +

1
τg ∇g(X0))k2

F

2kX − Y k2

= Π(X′).
where X′ = X0 − 1
τg ∇g(X0). The proximal operator Π(X) is
given by Π(X) = arg minY f (Y ) + 1
F . Moreover,
it can be found in closed form for some nonsmooth convex
functions (e.g., nuclear norm) which is an advantage of al-
gorithm to solve large scale optimization problem [44]. Note
τ ∇g(X old), i.e., the
that if f (X) = 0 then X new = X old + 1
proximal gradient algorithm reduces to the standard gradient
algorithm. The convergence rate for the proximal gradient
algorithm is O(1/k) where k is the number of iterations (i.e.,
see [44] Theorem 2.1).

B. Proximal gradient algorithm to solve CMEN

Given ∇g(Λ) is Lipschitz continuous with parameter τg =
N m (see Appendix B), where N is total number of bags and
m is total number of feature functions, a quadratic upper bound
for (16) can be written as:

τg
2 kΛ − Λ′k2

F + g(Λ0)

L(Λ, z) ≤ kΛk∗ + z(
1
2τg k∇g(Λ0)k2
F − ǫ)
−
= Q(Λ, Λ0)

where Λ′ = Λ0 − 1
of Q(Λ, Λ0) w.r.t. Λ is

τg ∇g(Λ0). The solution to the minimization

ˆΛ∗(z) = arg min Q(Λ, Λ0)

= D 1

τg z

(Λ′)

where Dα(X) is the soft-thresholding operator on the singular
values of matrix X (for proof see [45]) deﬁned by Dα(X) =
U (S − αI)+V T , where X = U SV T is the SVD of X. To ﬁnd
z∗ we have to maximize Q(ˆΛ∗(z), Λ0) w.r.t. z. Since parameter
z is a scalar, we propose a greedy search approach to ﬁnd the
optimum z (see Algorithm 2).

(Λk − Λk−1){Acceleration}

zk
−+zk

+

zk =
for k = 1 to K do

{Dual variable update}

2

g

ak

τ k

g = ατ k−1
τ k

{Line search}
g ∇g(¯Λk) {Variable update}

¯Λk = Λk + ak−1−1
while L(¯Λk, zk) ≤ Q(¯Λk, ¯Λk−1) do
end while
Gk = Λk − 1
Compute Λk+1 = D 1
ak+1 = 1+√1+4ak 2
end for
{Line search for dual variable z}
if g(Λ) − ǫ ≥ 0 then
else

zk τ k
g

2

zk+1
− = zk
zk+1
+ = zk
end if

(Gk) {proximal operator}

if Pi D(pˆλikpλi)ni − ǫ < consTol then

break

end if
end for

D. Acceleration

The convergence rate for the proximal gradient approach is
O(1/k) where k is the number of iteration [43], [44]. The
convergence rate of the gradient approach can be speed up to
O(1/k2) using the extrapolation technique proposed in [46]
given the fact that the ∇g(Λ) is Lipschitz continuous with
τg = N m (see Appendix B). We deﬁne the extrapolated solution
as follows:

¯Λk = Λk +
where ak = 1+√1+4a2k

ak−1 − 1

ak

(Λk − Λk−1),

2

. The only costly part of the proximal
algorithm is the evaluation of the singular values in each
iteration. Note that in each iteration of soft-thresholding operator
we need to know the number of singular values greater than a
threshold. As in [39], [44], [45], [47], we use the PROPACK
package to compute a partial SVD. Because PROPACK can not
automatically calculate the singular values which are greater
than speciﬁc value ζ, we use the following procedure. To

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

7

facilitate the computation of singular value 5 at a time, we set
b0 = 5 and update bl+1 for l = 0, 1, . . . as follows:

bl+1 = (cid:26) Rank(Λk+1)

if Rank(Λk+1) < bk
Rank(Λk+1) + 5 if Rank(Λk+1) ≥ bk.

This procedure stops when bl+1 = bl. Partial SVD calculation
reduces the cost of the computation signiﬁcantly, especially in
the low-rank setting. The pseudo code for calculating SVD is
in Algorithm 3.

Algorithm 3 SVD calculation using PROPACK

Choose r0 = 0, and i = 5
in step l
bl = rk−1 + 1
repeat

[U SV ]bl = SVD(Λk)
bl = bl + i

until sk
bl−i ≤ 1
rk = max{j : sk
Λk+1 = Prk
j=1(sk

zkτ k
g
j > 1
g }
zkτ k
j − 1

zk τ k
g

)uk

j vk
j

VII. EXPERIMENTS

In this section, we evaluate both theoretical and computational
aspect of CMEN ans compare to RMDE for rank recovery in
the space of distributions. For the theoretical part, we provide
a phase diagram analysis to evaluate the performance of both
CMEN and RMDE in exact rank recovery. We then provide
an illustration of distribution space dimension reduction using
CMEN. Moreover, we show that CMEN introduces a metric
which can be used in object similarity recognition in image
processing.

A. Phase diagram analysis

k x) and φ2k−1 = sin(gT

We use the notion of phase diagram [48] to evaluate probabil-
ity of exact rank recovery using CMEN and RMDE for a wide
range of matrices Λ of different dimensions (i.e., features size
× number of bags) and different values for the rank of matrix
Λ. We construct distributions using low-rank matrix Λ and
draw i.i.d samples using rejection sampling (data are generated
in 2D space). For the basis functions used in constructing
the maximum entropy distribution space, we propose φ2k =
k x), where gk ∼ N (0, I) i.i.d
cos(gT
for k = 1, 2, . . . , m/2. In [49], a similar transformation is used
to approximate Gaussian kernels. Figure 3 shows the contour
plot of the ﬁrst 4 distributions used in our experiments. For
the random samples drawn from the constructed distributions,
we obtain ˆΛ by maximum likelihood estimation (10). Note
that ˆΛ is a noisy version of matrix Λ and is full rank. We
consider two different setups for number of bags: N = 50
and N = 500. We would like to illustrate the performance of
CMEN and RMDE in small (N = 50) and large (N = 500)
scale problems in terms of exact rank recovery. For N = 50
bags, we vary the number of features and rank of matrix Λ
over a grid of (m, T ) with m (number of features) ranging
through 7 equispaced points in the interval [20, 50] and T (rank
of matrix Λ) ranging through 10 equispaced points in the interval
[2, 20] (see Fig. 4). Each pixel intensity in the phase diagram

Fig. 3. Contour plot of the ﬁrst 4 distributions used in our experiment

corresponds to the empirical evaluation of the probability of
exact rank recovery. For each pixel in the phase diagram we
produce 10 realization of ˆΛ. We run CMEN and RMDE for
each of 10 realization of ˆΛ and compare the rank of the obtained
matrix Λ∗ with the rank of the true Λ. The rank evaluation is
done by counting the number of singular values of matrix Λ∗
exceeding a threshold. The threshold is deﬁned based on the
empirical distribution of the smallest nonzero singular values
of the true matrix Λ (i.e., mean minus three times the standard
deviation). To ﬁnd the regularization parameter η in RMDE (11),
we consider both a cross-validation approach and a continuation
technique [44], [50]. The continuation technique in nuclear
norm minimization is similar to the path following algorithm
in solving l1 regularized regression (LASSO) proposed in [51].
Convergence analysis of the continuation technique is shown in
[52]. For cross-validation, we consider a range of regularization
parameter η = {10−4, 10−3, . . . , 103, 104}. For each value of
η, we separate data into training and test sets (70% training
and 30% test), and evaluate the test error using the objective
function in (11), then select η∗ as the value corresponding to
the lowest test error. For the continuation technique, we set
η to a large value (η0 = k ˆΛk2
F ) and repeatedly solve the
optimization problem (11) with a decreasing sequence of ηk
until we reach the target value ¯η (ηk = max(10−1ηk−1, ¯η))
where ¯η = 10−3η0. Due to large value of η in the beginning
of the algorithm, matrix Λ∗ is low-rank and in each iteration
we increase the rank of Λ∗. Note that the value of constant
10−3 in ¯η = 10−3η0 and 10−1 in ηk = max(10−1ηk−1, ¯η)
is set manually based on preliminary experiments. The stopping
criterion for CMEN is the combination of MaxIter ≤ 100, objTol
< 10−2, and consTol < 10−1 where MaxIter is the maximum
number of iteration of main algorithm, objTol is the tolerance of
objective function kfk−1
mink1, and consTol is the tolerance
for violating the conﬁdence constraint kPi D(pˆλikpλi)ni − ǫk.
The stopping criteria for RMDE is the same as for CMEN
except that consTol is not used. Figure 4(a), 4(b), and 4(c) show
the phase diagram results for exact rank recovery with CMEN,
RMDE (cross-validation), and RMDE (continuation technique)
for N = 50. The white region in Fig. 4(a) and Fig. 4(b)
correspond to the probability of exact rank recovery obtained
by CMEN and RMDE, respectively. The white area in Fig. 4(a)
is wider than the white areas in Fig. 4(b) and Fig. 4(c) which
means that CMEN is more successful in exact rank recovery
compare to RMDE. This is due to the fact that in RMDE, η∗ is
obtained based on the generalization performance (minimum test

min − fk

8

5

10

T

15

20

 

 

1

0.8

0.6

0.4

0.2

0

5

10

T

15

20

 

20

30

40

50

m

(a)

0.8

0.6

0.4

0.2

0

20

30

40

50

m

(b)

 

1

0.8

0.6

0.4

0.2

0

5

10

T

15

20

 

20

30

40

50

m

(c)

Fig. 4.
Comparison of probability of exact rank recovery obtained by (a)
CMEN, (b) RMDE with cross-validation and (c) RMDE with continuation
technique for N = 50.

error) which does not necessarily guarantees exact rank recovery.
Moreover, in CMENA we use a quadratic bound on the main
objective function which results in a closed-form expression
for the proximal operator. Based on Eckart-Young [53] a low-
rank matrix has the lower error in terms of quadratic cost
function. Another observation is that the white area in RMDE
with continuation technique is slightly wider than RMDE with
cross-validation technique. This could be due to the fact that in
the continuation technique we start with a very low-rank matrix
Λ and increase the rank gradually until we reach a targeted
value, whereas in the cross-validation technique we keep the
regularization parameter constant throughout the optimization.
For N = 500, we scan the number of features and rank of
matrix Λ over a grid of (m, T ) with m ranging through 19 equi-
spaced points in the interval [100, 1000] and T ranging through
20 equispaced points in the interval [5, 100]. Due to the high
computational complexity of scanning through different values
of η in RMDE with cross-validation, and better result in terms
of exact rank recovery in RMDE with continuation technique on
small scale data (N = 50), we compare rank recovery between
CMEN and RMDE with continuation technique in this case.
Figure 5(a) and 5(b) show the phase diagram results for exact
rank recovery with CMEN and RMDE (continuation technique)
for N = 500. We observe that
the white area in CMEN
approach is wider than the white areas in RMDE approach
(better performance in terms of exact rank recovery for CMEN
compare to RMDE).

0

20

40

60

80

T

100

 

200

400

800 1000

600
m

(a)

 

1

0.8

0.6

0.4

0.2

0

0

20

40

60

80

T

 

0.8

0.6

0.4

0.2

100

 

200

400

800 1000

600
m

(b)

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

 

1

B. Parameter estimation error

Pi Z(λi) − λT

We compare the test error vs. runtime for both CMEN and
RMDE on a synthetic dataset. We construct a low-rank matrix Λ
and generate i.i.d. samples from the low-rank distribution and
estimate matrix ˆΛ using maximum likelihood estimation. Then
we obtain matrix Λ∗ using CMEN and RMDE. We consider
N = 50, m = 100, T = 5, and T = 20. We randomly choose
70% of the data as a training set and test on the rest of the
data over 10 different realizations. The test error is evaluated as
i Eˆp[φ], where i indexes all bags in the test set.
Figure 6 shows the results of test error vs. runtime 1. Figure 6(a)
shows the result for T = 5. Since initially ﬁnding the true
model with correct rank in CMEN is computationally expensive
(due to dual variable update), we observe that RMDE has lower
generalization test error than CMEN in the beginning. However,
we observe that overall the generalization test error in CMEN
decreases faster than RMDE. In Fig. 6(b), the result is shown
for T = 20. We see that by increasing the complexity of the
model, it takes longer for CMEN and RMDE to ﬁnd the correct
model.

300

250

200

150

r
o
r
r
E

 
t
s
e
T

100

 

550

600

 

CMEN
RMDE (CT)
RMDE (CV)

800

850

550

500

450

400

350

300

250

200

r
o
r
r
E

 
t
s
e
T

150

 

200

400

 

CMEN
RMDE (CT)
RMDE (CV)

1200

1400

600

800

1000

Runtime (seconds)

650

700

750

Runtime (seconds)

(a)

(b)

Fig. 6. Comparison of generalization test error (Pi Z(λi) − λT
runtime for N = 50, m = 100, and (a) T = 5, (b) T = 20.

i E ˆp[φ]) vs.

C. Dimension reduction

The purpose of this section is to illustrate how dimension
reduction can be achieved using the ψ obtained by CME. Since
all the datasets are high dimensional, we use PCA as a prepro-
cessing step. Figure 8 depicts the whole process of implementing
our approach for one image in the Corel1000 dataset [54]. We
use the block representation of the image followed by PCA to
reduce the dimension. The image is represented as a bag of
instances where each instance corresponds to a small rectangular
patch of pixels. The feature vector describing each patch is
the raw pixel intensities (RGB) with PCA applied to reduce
the dimension. We perform the CMEN approach to learn a
p.d.f. over the block representation of the image.

After performing the nuclear norm minimization in (14) on
the Corel1000 dataset, we select one image as an example.
Then, we choose the ﬁrst few bases of matrix ψ obtained by
(15) to represent the image as a linear combination of these
basis functions. Figure 7 shows that the contour plots of these
basis functions. To provide intuitive understanding, we name
each basis ψ following the content of the image corresponding
to instances near the peaks of ψ (concentration of data points).
The ﬁrst column of Fig. 7 is an image and its corresponding
estimated density. The other columns show each ψi and the
part of the image that corresponds to that ψi.

Fig. 5.
CMEN and (b) RMDE with continuation technique for N = 500.

Comparison of probability of exact rank recovery obtained by (a)

1We run all algorithms on a standard desktop computer with 2.5 GHz CPU

(dual core) and 4 GB of memory implemented in MATLAB.

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

9

"Sky"

"Building"

"Grass"

50

100

150

200

250

300

350

!

"

#

50

100

150

200

250

300

350

!

"

#

50

100

150

200

250

300

350

!

"

#

=   β

×

$

i1 

+  β

×

$

i2 

+  β

×

$

i3 

!"

!#

$

#

"

!

!#

!"

!!

!!

!"

!#

$

#

"

!

!#

!"

!!

!!

!"

!#

$

#

"

!

!#

!"

!!

50

100

150

200

250

300

350

!

"

#

$

!#

!"

!!

!!

TABLE I
DATASETS

+  ...

Dataset

Corel1000 (4class)

Musk1
Musk2

Flowcytometry

bags
200
92
102
43

no. of class

Ave. inst/bag

4
2
2
2

950
4.5
64.7
5664

dim
300
166
166

5

Fig. 7. Dimension reduction in the space of the distribution obtained by the
bases ψ. The ﬁrst column shows the image and corresponding density estimation.
The other columns show each ψ and part of the image that corresponds to that
ψ.

D. KL-divergence similarity

[Φ] − (Z(λi) − Z(λj)).

For classiﬁcation and retrieval, it is useful to have a similarity
measure between bags. The Kullback-Leibler (KL) divergence
between two estimated distributions provides such a similarity
measures [5]. The KL divergence between two distributions
obtained by the maximum entropy approach has a closed form:
D(pλikpλj ) = (λi − λj)T Epλi
We symmetrize the divergence by adding D(pλikpλj ) +
D(pλjkpλi).
D(pλikpλj ) + D(pλjkpλi) = (λi − λj)T (Epλi
Figure 9 shows a set of images and their nearest images identi-
ﬁed by KL-divergence similarity. We observe that by using the
KL-divergence similarity, the nearest neighbor images resemble
the main images which validates the efﬁcacy of the proposed
similarity measure. Figure 10 shows failure examples in which
the nearest neighbor image comes from a different class than the
original image. We hypothesis that this is due to the dominance
of the color features.

[Φ] − Epλj

[Φ]).

Blocks

Instance PCA Features

Distribution

!

"

#

$

!#

!"

!

"

#

$

%

!$

!#

50

100

150

200

250

300

350

50

100

150

200

!!

250

!!

!"

!#

$

#

"

!"

!
!"

!

!#

!$

%

$

#

"

Fig. 8. The whole ME process from bag representation to ﬁtting a distribution.
The ﬁgures from left to right shows the following: (1) how an images is
represented as a bag of instances (blocks), (2) The 2D PCA features of each
instance (3) the density ﬁtted to the data using the maximum entropy principle.

E. Datasets

We also evaluate the classiﬁcation accuracy of the proposed
KL-divergence based similarity measure when used in distance-
based multi-instance algorithms such as Citation-kNN [7] and
bag-level kernel SVM [15]. We compare KL-divergence to bag-
level distance measures that rely on pairwise instance-level
comparisons, namely average Hausdorff distance [7] and the
RBF set kernel [15], both in terms of accuracy and runtime. The
comparison is conducted over four datasets, i.e., the Corel1000
image dataset [54] Musk1, Musk2 [1], and Flowcytometry [55].
The Corel1000 [54] image dataset consists of 10 different
classes each containing 100 images. We use 50 randomly sub-
sampled images from 4 classes: ‘buildings’, ‘buses’, ‘ﬂowers’,
and ‘elephants’. We represent each image (bag) as a collection
of instances, each of which corresponds to a 10×10 pixel block,

and is described by a feature vector of all pixel intensities in
3 color channels (RGB). The Musk1 dataset [1] describes a
set of 92 molecules of which 47 are judged by human expert
to be musks and the remaining 45 molecules are judged to be
non-musk. The Musk2 dataset [1] is a set of 102 molecules
of which 39 are judged by human experts to be musks and
the remaining 63 molecules are judged to be non-musks. Each
instance corresponds to a possible conﬁguration of a molecule.
The Flowcytometry dataset consists of 5d vector reading of
multiple blood cell samples for each one of 43 patients. For each
patient, we have two similar cell characteristics with respect to
the antigens surface which are called 1) chronic lymphocytic
leukemia (CLL) or 2) mantle cell lymphoma (MCL). Each
patient is associated with one bag of multiple cells (instances).
Table I summarizes the properties of each dataset.

F. Experimental setup

We use classiﬁcation accuracy as an evaluation metric. In
all experiments, we use the preprocessed datasets obtained by
PCA. We perform 10-fold cross-validation over all datasets. As
baselines, we implement a modiﬁed version of Citation-kNN
[7] replacing the Hausdorff distance with KL-divergence, and a
bag-level SVM with the kernel for two bags X and X′ deﬁned
as K(X, X′) = e−γDKL(X,X ′), K(X, X′) = e−γDHaus(X,X ′),
and the RBF set kernel used by [15]. Below we state the
ranges of all
tunning parameters for these algorithms used
in our experiments. We compared CMEN with RMDE with
cross-validation and RMDE with continuation technique. We
use a grid of {10−4, 10−3, . . . , 103, 104} for the regularization
parameter η. All of the datasets use features with dimension
reduced by PCA. We use a grid of {2, 3, 4, 5, 6, 7} for the feature
dimension after applying PCA. The Citation-kNN algorithm has
two parameters- the number of nearest neighbors k, and the
number of “citers” k′. We use a grid of {1, 5, 10, 15, 20} for k
and {5, 10, 15, 20, 25} for k′. The SVM has two parameters-
the bandwith of RBF kernel γ, and the penalty factor C.
We use a grid of {2−9, 2−8, . . . , 20} for γ, and a grid of
{20, 21, . . . , 29} for C. For the basis functions used in con-
structing the maximum entropy distribution space, we propose
k x), where gk ∼ N (0, I)
k x) and φ2k−1 = sin(gT
φ2k = cos(gT
i.i.d for k = 1, 2, . . . , m/2. In [49], a similar transformation is
used to approximate Gaussian kernels.

Fig. 9. Top: Query image. Bottom: Nearest-neighbor based on KL-divergence.
This ﬁgure shows success in retrieving the corresponding image.

10

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

100

95

90

85

80

75

70

65

)

%

(
 
y
c
a
r
u
c
c
a
 

n
o
i
t
a
c
i
f
i
s
s
a
l
C

60
 
1

2

3

 

100

 

)

%

(
 
y
c
a
r
u
c
c
a
 

n
o
i
t
a
c
i
f
i
s
s
a
l
C

95

90

85

80

75

70

65

Hausdorff
KL RMDE (CV)
KL CMEN
Set level RBF Kernel
KL RMDE (CT)

Hausdorff
KL RMDE (CV)
KL CMEN
Set level RBF Kernel
KL RMDE (CT)

4

5

Dimension of dataset

6

7

8

60
 
1

2

3

4

5

6

7

8

Dimension of dataset

(a) SVM, Corel1000

(b) SVM, Musk1

100

95

90

85

80

75

70

65

60

)

%

(
 
y
c
a
r
u
c
c
a
 

n
o
i
t
a
c
i
f
i
s
s
a
l
C

55
 
1

2

3

 

100

 

)

%

(
 
y
c
a
r
u
c
c
a
 

n
o
i
t
a
c
i
f
i
s
s
a
l
C

95

90

85

80

75
 
1

Hausdorff
KL RMDE (CV)
KL CMEN
Set level RBF Kernel
KL RMDE (CT)

2

3

Dimension of dataset

4

5

Hausdorff
KL RMDE (CV)
KL CMEN
Set level RBF Kernel
KL RMDE (CT)

4

5

6

7

8

Dimension of dataset

(c) SVM, Musk2

(d) SVM, Flowcytometry

Fig. 12.
Classiﬁcation accuracy results for (a) Corel1000, (b) Musk2 (c)
Musk1 and (d) Flowcytometry. Set level RBF kernel accuracy is provided for
reference.

1√|2πΣ|

exp(cid:0)− 1

2 xT Σ−1x(cid:1) where Σ is a covariance

where ni is the number of sample in bag i, K is a kernel
function, and h is the bandwidth. We select the Gaussian kernel
K(x) =
matrix. We use the maximal smoothing principle [56] for
determining the bandwidth parameter h and Σ = I. We use
the two mentioned classiﬁcation techniques, citation k-NN and
bag-level SVM to compare the accuracy performance of KDE
vs. CMEN. For both approaches, we use KL-divergence as a
similarity measure. All experimental setup is as described in
Section VII-F. Figure 13 shows the classiﬁcation accuracy for

95

90

85

80

75

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

 

CMEN
KDE

95

90

85

80

75

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

6

7

8

70
 
1

2

3

 

CMEN
KDE

6

7

8

4

5

Dimension of dataset

Fig. 10. Top: Query image. Bottom: Nearest-neighbor based on KL-divergence.
This ﬁgure shows failure in retrieving the corresponding image.

G. Classiﬁcation

The results of classiﬁcation accuracy for citation-kNN for four
datasets are shown in Fig. 11. We compared the classiﬁcation
accuracy with Citation-kNN using KL-divergence and Hausdorff
distance. The KL divergence is computed from 3 different distri-
bution estimates: 1) RMDE (CV): RMDE with cross-validation,
2) RMDE (CT): RMDE with continuation technique, and 3)
CMEN. We observe that CMEN has slightly better classiﬁcation
performance than RMDE in musk and image datasets, where
in Flowcytometry dataset RMDE (CT) is performing better.
However, the difference is not very signiﬁcant. Figure 12 shows

100

95

90

85

80

75

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

70
 
1

2

3

 

100

 

Hausdroff
KL RMDE (CV)
KL CMEN
KL RMDE (CT)

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

95

90

85

80

75

Hausdroff
KL RMDE (CV)
KL CMEN
KL RMDE (CT)

4

5

Dimension of dataset

6

7

8

70
 
1

2

3

4

5

6

7

8

Dimension of dataset

(a) Citation-kNN, Corel1000

(b) Citation-kNN, Musk1

Hausdroff
KL RMDE (CV)
KL CMEN
KL RMDE (CT)

100

95

90

85

80

75

70

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

65
 
1

2

3

4

5

Dimension of dataset

 

100

 

)

%

(
 
y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

95

90

85

80

75

70
 
1

Hausdroff
KL RMDE (CV)
KL CMEN
KL RMDE (CT)

2

3

Dimension of dataset

4

5

6

7

8

(c) Citation-kNN, Musk2

(d) Citation-kNN, Flowcytometry

70
 
1

2

3

4

5

Dimension of dataset

Fig. 11.
Musk2 and (d) Flowcytometry.

Classiﬁcation accuracy results for (a) Corel1000, (b) Musk1 (c)

the results for bag-level SVM with the RBF set kernel, the
average Hausdorff distance kernel, and the KL divergence kernel
obtained by RMDE and CMEN. KL divergence has better
classiﬁcation performance than Hausdorff distance in musk1,
musk2, and ﬂowcytomery datasets. In Corel1000 image dataset,
Hausdorff distance is performing better than KL divergence. Ac-
curacy results are very close to all methods using KL divergence.

H. Comparison CMEN vs. Kernel Density Estimation

We compare CMEN to a nonparametric kernel density esti-
mation (KDE) in classiﬁcation application for two real world
datasets, namely: Corel1000 and Musk1. The KDE of pi(x) is
deﬁned as

pi(x) =

1
ni · h

ni

Xj=1

K(cid:18) x − xj

h (cid:19) ,

(19)

(a) Citation-kNN, Corel1000

(b) Citation-kNN, Musk1

95

90

85

80

75

)

%

(
 

y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

70
 
1

2

3

 

CMEN
KDE

95

90

85

80

75

)

%

(
 

y
c
a
r
u
c
c
a
 
n
o
i
t
a
c
i
f
i
s
s
a
l
C

6

7

8

70
 
1

2

3

 

CMEN
KDE

6

7

8

4

5

Dimension of dataset

4

5

Dimension of dataset

(c) SVM, Corel1000

(d) SVM, Musk1

Fig. 13.
accuracy results.

Comparison between CMEN and KDE in terms of classiﬁcation

both CMEN and KDE. The results are comparable for image
Corel1000 dataset, but for Musk1 dataset CMEN outperforms
KDE in terms of prediction accuracy (maximum accuracy value
for CMEN=93% where for KDE=86%). The reason that CMEN
performs better compare to KDE for Musk1 dataset is due
to the lack of enough samples in each bag. Lack of enough

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

11

samples in each bag causes the individual density estimated
by KDE to be inaccurate and therefore, the similarity metric
used in the classiﬁcation algorithms is not discriminative. But,
CMEN uses the shared structure of the data by enforcing the
low-rank structure on parameter Λ. Standard deviation for both
approaches is equal and is in order of 4%.

I. Runtime

To compare the computational complexity of our algorithm
with standard MIL algorithms, we run Citation-kNN and MI-
SVM using the MIL toolkit2 on the Corel1000 image dataset
for different numbers of instances in each bag. To evaluate
how the runtime of each algorithm depends on the number of
instances in the dataset, we randomly sample varying number
of instance from each bag. In Fig. 14, the x-axis shows the
number of samples in each bag and the y-axis shows the
elapsed CPU time in seconds. We compare the time complexity
of standard MIL algorithm with RMDE (CV), RMDE (CT),
and CMENA. The runtime of Citation-kNN and SVM is sig-
niﬁcantly longer than RMDE and CMENA by several orders
of magnitude. Hence our proposed approach achieves superior
runtime and similar accuracy to two standard MIL algorithms.
The computational complexity of RMDE and CMENA during

105

104

103

e
m

i
t
n
u
r
 

U
P
C

102

 
101

 

Citation−kNN
MI−SVM
RMDE (CV)
CMENA
RMDE (CT)

102

number of instances

103

Fig. 14.
CMENA.

Time comparison among Citation-kNN, MI-SVM, RMED, and

training is O(N ndm), where n is average number of instance
per bag, d is the dimension of instances, and m is the number of
basis functions φ and during test is O(N m). The computational
complexity of Hausdorff distance during test is O(n2N ). The
Hausdorff distance based approach requires no training.

J. Discussion

The RMDE and CMEN approaches for MIL are signiﬁcantly
faster than other algorithms when there are a large number of
instances in each bag. RMDE and CMEN achieve this speedup
by summarizing the instances in each bag, thereby avoiding
instance-level processing in later steps.

VIII. CONCLUSION

In this paper, we proposed a conﬁdence-constrained maxi-
mum entropy approach for learning from multi-instance data.
The proposed approach used the idea of representing each bag
in the space of distribution using the principle of maximum
entropy. This approach summarizes the high volume data in

2http://www.cs.cmu.edu/ juny/MILL/

multi-instance data capturing the statistical properties of each
bag using the m-dimensional sufﬁcient statistics Eˆp[φ]. The
computational complexity reduces signiﬁcantly from quadratic
to linear in number of instances inside each bag. We evaluated
the performance of the CME in terms of rank recovery in the
parameter space using the phase diagram analysis and showed
accuracy of this approach in exact rank recovery (true number of
parameters to model distributions). A convenient optimization
framework was proposed using proximal gradient approach
which is efﬁciently scaled to a large dataset. We used the
advantage of the Lipschitz boundedness of the gradient of the
maximum likelihood in the maximum entropy framework in
developing the optimization algorithm.

As future research direction, one can consider the following.
The rank function in CME was heuristically replaced with
nuclear norm in CMEN. Nuclear norm minimization produces a
low-rank solution in practice, but a theoretical characterization
of when CMEN can produce the minimum rank solution was
not investigated. The mathematical characterization of minimum
rank solution was provided in the case where the constraints
were afﬁne [33]. The extension of theoretical guarantees to the
nonlinear set of inequalities is an open research direction. Our
approach is an unsupervised technique in dimension reduction.
Developing a new model which accounts for the useful dis-
criminative information in the dataset is another future research
direction.

APPENDIX A

PROOF OF PROBABILITY BOUND FOR PN
To bound PN

i=1 niD(p ˆλikpλi)
i=1 niD(p ˆλikpλi ), we make the following as-
a) Assumption 1: Z(λ) is strongly convex. There exists a

sumptions.

constant c > 0 such that

Z(ξ) ≥ Z(λ) + (ξ − λ)T ˙Z(λ) +

c
2kξ − λk2,

for any ξ and λ. The strong convexity of Z(λ) corresponds
to the fact that Cov[φ] (cid:23) cI. In other words, the smallest
eigenvalue of the Hessian of Z(λ) is uniformly lower bounded
everywhere by c. If the sufﬁcient statistics φ is minimal (linearly
independent) and λ indexes a regular exponential family, then
Z(λ) is strictly convex [18]. The constant c depends on both
the sufﬁcient statistics φ and the class of the distributions.

b) Assumption 2: ¨Z(λ) is Lipschitz continuous with con-

stant C, i.e.,

our

d3Z

dλkdλldλm

,

then

1
2

ξ

and λ. We

(ξ − λ)T ¨Z(λ)(ξ − λ))|

C
6 kξ − λk3,

|Z(ξ) − (Z(λ) + (ξ − λ)T ˙Z(λ) +
≤
can
assumption
any
for
problem given
1. Let
holds
in
...
...
Zklm = Epλ [φkφlφm] −
Zklm =
Epλ[φkφl]Epλ [φm]−Epλ [φkφm]Epλ [φl]−Epλ[φlφm]Epλ [φk]+
Epλ[φk]Epλ [φm]Epλ [φl] + Epλ[φm]Epλ [φl]Epλ[φk]. Since each
φ is bounded by 1, therefore k
Let ˆλ = ˆλM L = arg min Z(ξ)−ξT Eˆp[φ] be the ML estimator
of λ as in (9), where Eˆp[φ] = ¯φ. The KL-divergence between
pˆλ = exp(cid:16)ˆλT φ − Z(ˆλ)(cid:17) and pλ = exp(cid:0)λT φ − Z(λ)(cid:1) is given

...
Zklmk1 ≤ 6.

prove
kφk∞

this
≤

12

by:

D(pˆλkpλ) = Epˆλ (cid:20)log
Note that Epˆλ

pˆλ
pλ(cid:21) = (ˆλ − λ)T ¯φ − (Z(ˆλ) − Z(λ))
[φ] = Eˆp[φ] = ¯φ. Consequently, we can relate

D(pˆλkpλ) to δ = ¯φ − Epλ [φ] using

D(pˆλkpλ) = −(min
Proof: Using the deﬁnition of ˆλ:

ξ

D(pλkpξ) − (ξ − λ)T δ)

(20)

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

A. relation between D(pˆλkpλ) and δ
follows:

We ﬁrst consider the quantity D(pˆλkpλ) and expand it as

D(pˆλkpλ) = (ˆλ − λ)T Eˆp[φ] − (Z(ˆλ) − Z(λ)).

Recall the Z(λ) = logR eλT φ(x)dx is convex in λ. In our
analysis, we make the following assumptions. The solution to
the minimization ξ = ˆλ satisﬁes ˙Z(ˆλ) − ˙Z(λ) = δ. First we
analyze the term kξ − λk. Using Assumption 1, we have

(ξ − λ)T ( ˙Z(ξ) − ˙Z(λ)) ≥ ckξ − λk2.

c

This is obtained by adding Z(ξ) ≥ Z(λ) + (ξ − λ)T ˙Z(λ) +
2kξ− λk2 and Z(λ) ≥ Z(ξ)− (ξ− λ)T ˙Z(ξ) + c
2kξ− λk2. Next,
using Cauchy-Schwartz inequality: (ξ − λ)T ( ˙Z(ξ) − ˙Z(λ)) ≤
kξ − λkk ˙Z(ξ) − ˙Z(λ)k and simplifying, we obtain

kξ − λk ≤

1
ck ˙Z(ξ) − ˙Z(λ)k.

(21)

Finally, substituting ξ = ˆλ into (21) and using the result
˙Z(λ) = δ, we obtain

˙Z(ˆλ)−

= max

D(pˆλkpλ) = ˆλT Eˆp[φ] − Z(ˆλ) + Z(λ) − λT Eˆp[φ]
(ξ − λ)T Eˆp[φ] − (Z(ξ) − Z(λ))
(ξ − λ)T Epˆλ
[φ] − (Z(ξ) − Z(λ))
(ξ − λ)T Epλ[φ] − (Z(ξ) − Z(λ))

= max

ξ

ξ

[φ] − Epλ [φ])

(ξ − λ)T Epλ[φ] − (Z(ξ) − Z(λ))

ξ

= max
+ (ξ − λ)T (Epˆλ
= max
+ (ξ − λ)T (Epˆλ
= max

ξ

[φ] − Epλ [φ])

ξ −D(pλkpξ) + (ξ − λ)T (Epˆλ
D(pλkpξ) − (ξ − λ)T δ).

= −(min

ξ

[φ] − Epλ [φ])

kˆλ − λk ≤
1
ck

=

1
ckδk

1
ck ˙Z(ˆλ) − ˙Z(λ)k =
1
Xj=1
N

ni

φ(xij ) − Epλ [φ(x)]k.

(22)

Theorem 2: Let ˆλ = arg minλ nD(ˆpkpλ) deﬁned in (9).
Given assumptions (A-0a) and (A-0b), with probability at least
1 − ωa:

p(cid:18) N
Xi=1

niD(pˆλikpλi) ≥ ǫ(ωa)(cid:19)≤

1
a

.

is an in-probability bound for the estima-
where ǫ(ωa) = aN m
tion error. N is total number of bags and m is total number of
feature functions φ.

2

To ﬁnd the probability bound for
the random quantity
PN
i=1 niD(p ˆλikpλi), we use Markov’s inequality. Markov’s
inequality for a non-negative random variable X (i.e., p(X ≥
0) = 1) and a positive scalar a is deﬁned as follows:

p(X ≥ a) ≤

E(X)

a

.

Markov’s inequality relates the probability of random variable
i=1 niD(pˆλikpλi) is a non-
negative value, we propose the following bound for the random

X to its expectation. Since PN
quantity PN
i=1 niD(pˆλikpλi)
p(cid:18) N
Xi=1

niD(pˆλikpλi) ≥ ǫ(ωa)(cid:19)≤

1
a

,

2

, N is the number of datasets, and m
where ǫ(ωa) = aN m
is the number of feature functions. To do so, we need to

compute the E(cid:20)PN

i=1 niD(pˆλikpλi)(cid:21). For ease of notation, we
drop subscript i for λi and ˆλi. While the proof is somewhat
elaborated, the outline is as follows.

• relate D(pˆλkpλ) to δ = Eˆp[φ] − Epλ [φ]
• express E(cid:20)D(pˆλkpλ)(cid:21) in terms of moments of δ

In the following, we explain each parts in details.

Because p(−1 ≤ φ(x) ≤ 1) = 1, the Hoeffding inequality is
applied. Since the probability is geometric in n, by the Borel-
Cantelli Lemma the term on the RHS of (22) converges to zero
in the strong sense. This result guarantees that kˆλ− λk strongly
convergence to 0 as ni → ∞ consequently making O(kˆλ−λk3)
asymptotically negligible when compared to O(kˆλ−λk2) terms.
B. express E(cid:20)D(pˆλkpλ)(cid:21) in terms of moments of δ

Next, we exploit Assumption 2. Note that the relation of (20)
suggests that D(pˆλkpλ) is a function of the random vector δ =
Eˆp[φ] − Epλ [φ] = 1
We examine a tight approximation to the relation between
D(pˆλkpλ) and δ:

n P[φ(xi) − E[φ(xi)]].

D(pˆλkpλ) ≤

1
2

δT ¨Z(λ)−1δ +

Ckδk3
6c3

(23)

Proof: Since D(pλkpξ) is given by Z(ξ) plus afﬁne terms
in ξ the Lipschitz continuity of the second derivative of Z(ξ)
holds also for the second derivative of D(pλkpξ) w.r.t. ξ for any
ξ and λ:

|D(pλkpξ) −

1
2

(ξ − λ)T ¨Z(λ)(ξ − λ)| ≤

C
6 kξ − λk3.

Using the lower bound, we have

D(pλkpξ) ≥

1
2

(ξ − λ)T ¨Z(λ)(ξ − λ) −

C
6 kξ − λk3.

Using this bound we can bound minξ D(pλkpξ)− (ξ − λ)T δ as
follows

min

ξ

≥
=

1
2
1
2

D(pλkpξ) − (ξ − λ)T δ = D(pλkpˆλ) − (ˆλ − λ)T δ (24)
(ˆλ − λ)T ¨Z(λ)(ˆλ − λ) − (ˆλ − λ)T δ −
(ˆλ − λ′)T ¨Z(λ)(ˆλ − λ′) −

C
6 kˆλ − λk3,

δT ¨Z(λ)−1δ −

C
6 kˆλ − λk3

1
2

BEHMARDI AND RAICH: CONFIDENCE-CONSTRAINED MAXIMUM ENTROPY FRAMEWORK FOR LEARNING FROM MULTI-INSTANCE DATA

13

where λ′ = λ− ¨Z−1δ. Substituting (21) in (24) yields the lower
bound:

1
≥
2
≥ −(

(ˆλ − λ′)T ¨Z(λ)(ˆλ − λ′) −
Ckδk3
1
),
6c3
2

δT ¨Z(λ)−1δ +

1
2

δT ¨Z(λ)−1δ −

Ckδk3
6c3

where the last step is since ¨Z is PSD. Finally, we can bound
D(pˆλkpλ) by:

D(pˆλkpλ) = − min

ξ

D(pλkpξ) − (ξ − λ)T δ

Ckδk3
≤
6c3
2 δT ¨Z(λ)−1δ + niCkδk3
Hence, D(pˆλkpλ) ≤ 1

δT ¨Z(λ)−1δ +

1
2

6c3

.

.

Next, taking the expectation on both sides of (25), we obtain:

E[D(pˆλkpλ)] ≤
=

1
2
1
2

E[δT ¨Z(λ)−1δ] +
trh ¨Z(λ)−1E[δδT ]i +

C
6c3 E[kδk3]

C
6c3 E[kδk3](25)
Note that (25) requires only the second and third moments of
δ. For the moments of δ, we have the following result:

E[δ] = 0,

E[δδT ] = Cov[δ] =

¨Z(λ)

1
n

Proof: The proof of E[δ] = 0 is as follows:

Therefore, using the Markov’s inequality with probability ωa
where ωa = 1

a we have
Xi=1

N D(pˆλikpλi)ni ≥ ǫ(ωa),

where ǫ(ωa) = aN m

2

.

APPENDIX B

PROOF OF LIPSCHITZ CONTINUITY FOR ∇g(ˆΛ, Λ)

In this section, we want to show that ∇g(ˆΛ, Λ) is Lipschitz
continuous with constant τg = N m where N is total number of
bags and m is total number of feature functions. We prove that
the Hessian matrix ∇2g(ˆΛ, Λ) is bounded which is stronger than
Lipschitz continuity of the gradient ∇g(ˆΛ, Λ). The Hessian of
g(ˆΛ, Λ) is equivalent to the covariance of the feature functions
φ. Thus,

∇2g(ˆΛ, Λ) =

=

N

Xi=1
Xi=1

N

Epλi

(φφT ) −(cid:18)Epλi

(φ)Epλi

(φ)T(cid:19)

Covpλi

(φ).

We show that the covariance of φ is bounded as follows.

V T Covpλi
V T V

max

V

(φ)V

V (cid:18) Epλi
Epλi

[(V T φ)2]
V T V
[(V T φ)2]
V T V

.

= max

≤ max

V

[Epλi

(V T φ)]2
V T V

(cid:19)

−

(26)

E[δ] = E[

1

n X(φ(xi)−E[φ(xi)])] =

n X(E[φ(xi)]−E[φ(xi)]) = 0.

¨Z(λ), we ﬁrst show E[δδT ] =

1

To show that E[δδT ] = 1
n
1
n Cov[φ]:

E[δδT ] =

=

=

1

1
n

Cov[φ]

n2 E[X(φ(xi) − E[φ(xi)])X(φ(xi) − E[φ(xi)])T ]
n2 X E[φ(xi)φ(xi)T ] − E[φ(xi)]E[φ(xi)]T

1

Next, we show ¨Z(λ) = Cov[φ]:

¨Z(λ) = R φ(x)φ(x)T eλT φ(x)dx

(R eλT φ(x)dx)

(R φ(x)eλT φ(x)dx)(R φ(x)eλT φ(x)dx)T

−
= E[φ(x)φ(x)T ] − E[φ(x)]E[φ(x)]T
= Cov[φ].

(R eλT φ(x)dx)

Moreover, using Hoeffding’s inequality, we have kδk ≤
q2 log 2m
√n

w.p. at least 1 − η [20].

η

To obtain E[PN

i=1 niD(pˆλikpλi)] we can write

E(cid:20) N
Xi=1

niD(pˆλikpλi)(cid:21) =

N

Xi=1
Xi=1

N

E(cid:20)niD(pˆλikpλi )(cid:21)

m
2

N m

2

.

≤

=

Note that ∀V,
ity, we have

[Epλi

(V T φ)]2

V T V

≥ 0. By Cauchy-Schwartz inequal-

(V T φ)2 ≤ V T V φT φ.
i=1 φ2

Since φT φ = Pm

i and kφik∞ = 1, φT φ ≤ m. Hence,
(V T φ)2 ≤ V T V m.
Substituting (27) into (26), we obtain

(27)

N

Xi=1

V T Covpλi
V T V

max

V

(φ)V

N

Xi=1

≤

Epλi

[V T V m]
V T V

max

V

= N m.

REFERENCES

[1] T.G. Dietterich, R.H. Lathrop, and T. Lozano-P´erez, “Solving the multiple
instance problem with axis-parallel rectangles,” Artiﬁcial Intelligence, vol.
89, no. 1-2, pp. 31–71, 1997.

[2] K. Ni, J. Paisley, L. Carin, and D. Dunson, “Multi-task learning for ana-
lyzing and sorting large databases of sequential data,” IEEE Transactions
on Signal Processing, vol. 56, no. 8, pp. 3918–3931, 2008.

[3] S. Andrews, I. Tsochantaridis, and T. Hofmann, “Support vector machines
Proceedings of Advances in Neural

for multiple-instance learning,”
Information Processing Systems, vol. 15, pp. 561–568, 2002.

[4] Y. Qi, J.W. Paisley, and L. Carin, “Music analysis using hidden markov
mixture models,” IEEE Transactions on Signal Processing, vol. 55, no.
11, pp. 5209–5224, 2007.

[5] P. Viola, J. Platt, and C. Zhang, “Multiple instance boosting for object
detection,” in Proceedings of Advances in Neural Information Processing
Systems, 2006, vol. 18, pp. 1417–1426.

[6] Q. Zhang, S.A. Goldman, W. Yu, and J.E. Fritts, “Content-based image
retrieval using multiple-instance learning,” in Proceedings of International
Workshop on Machine Learning, 2002, pp. 682–689.

[7] Jun Wang, Zucker, and Jean-Daniel, “Solving multiple-instance problem:
A lazy learning approach,” in Proceedings of International Conference on
Machine Learning, Pat Langley, Ed., 2000, pp. 1119–1125.

[8] D.M. Blei, A.Y. Ng, and M.I. Jordan,

“Latent Dirichlet Allocation,”

Journal of Machine Learning Research, vol. 3, pp. 993–1022, 2003.

14

SUBMITTED TO THE IEEE TRANSACTION ON SIGNAL PROCESSING

[35] N. Srebro, J.D.M. Rennie, and T. Jaakkola, “Maximum-margin matrix
in Proceedings of Conference on Advances in Neural

factorization,”
Information Processing Systems, 2005, vol. 17, pp. 1329–1336.

[36] T.K. Pong, P. Tseng, S. Ji, and J. Ye,

“Trace norm regularization:
Reformulations, algorithms, and multi-task learning,” Submitted to SIAM
Journal on Optimization, 2009.

[37] B. Behmardi, F. Briggs, X. Fern, and R. Raich,

“Regularized joint
density estimation for multi-instance learning,” in Proceedings of IEEE
International Workshop on Statistical Signal Processing, 2012, pp. 740–
743.

[38] P.E. Gill, W. Murray, and M.H. Wright, Practical optimization, vol. 1,

Academic press, 1981.

[39] B. Behmardi and R. Raich, “On conﬁndence-constrained rank recovery in
topic models,” IEEE Transactions on Signal Processing, vol. 60, no. 10,
pp. 5146–5162, 2012.

[40] E.J. Candes, X. Li, Y. Ma, and J. Wright, “Robust principal component

analysis,” Journal of ACM, vol. 58, no. 1, pp. 1–37, 2009.

[41] R. Meka, P. Jain, C. Caramanis, and I.S. Dhillon, “Rank minimization via
online learning,” in Proceedings of the 25th International Conference on
Machine learning. ACM, 2008, pp. 656–663.

[42] J.P. Haldar and D. Hernando, “Rank-constrained solutions to linear matrix
equations using powerfactorization,” Signal Processing Letters, vol. 16,
no. 7, pp. 584–587, 2009.

[43] Y.J. Liu, D. Sun, and K.C. Toh,

“An implementable proximal point
algorithmic framework for nuclear norm minimization,” Mathematical
Programming, pp. 1–38, 2009.

[44] K.C. Toh and S. Yun, “An accelerated proximal gradient algorithm for
nuclear norm regularized linear least squares problems,” Paciﬁc Journal
of Optimization, vol. 6, pp. 615–640, 2010.

[45] J.F. Cai, E.J. Candes, and Z. Shen,

“A singular value thresholding
algorithm for matrix completion,” Journal on Optimization, vol. 20, pp.
615–640, 2008.

[46] Y. Nesterov, “A method of solving a convex programming problem with
convergence rate O (1/k2),” Soviet Mathematics Doklady, vol. 27, pp.
372–376, 1983.

[47] Z. Lin, M. Chen, L. Wu, and Y. Ma, “The augmented Lagrange multiplier
method for exact recovery of corrupted low-rank matrices,” Mathematical
Programming, 2009.

[48] D.L. Donoho, I. Drori, Y. Tsaig, and J.L. Starck,

“Sparse solution
of underdetermined linear equations by stagewise orthogonal matching
pursuit,” Citeseer, 2006.

[49] A. Rahimi and B. Recht,

“Random features for large-scale kernel
machines,” Proceedings of Advances in Neural Information Processing
Systems, vol. 20, pp. 1177–1184, 2007.

[50] S. Ma, D. Goldfarb, and L. Chen, “Fixed point and bregman iterative
methods for matrix rank minimization,” Mathematical Programming, vol.
128, no. 1, pp. 321–353, 2011.

[51] B. Efron, T. Hastie, I. Johnstone, and R. Tibshirani,

“Least angle

regression,” The Annals of statistics, vol. 32, no. 2, pp. 407–499, 2004.

[52] E.T. Hale, W. Yin, and Y. Zhang, “A ﬁxed-point continuation method
for l1-regularized minimization with applications to compressed sensing,”
CAAM TR07-07, Rice University, 2007.

[53] G.W. Stewart, “On the early history of the singular value decomposition,”

SIAM review, vol. 35, no. 4, pp. 551–566, 1993.

[54] P. Duygulu, K. Barnard, J. De Freitas, and D. Forsyth, “Object recognition
as machine translation: Learning a lexicon for a ﬁxed image vocabulary,”
Proceedigs of European Conference on Computer Vision, pp. 349–354,
2006.

[55] K.M. Carter, R. Raich, W.G. Finn, and A.O. Hero, “Information preserv-
ing component analysis: Data projections for ﬂow cytometry analysis,”
Selected Topics in Signal Processing, IEEE Journal of, vol. 3, no. 1, pp.
148–158, 2009.

[56] George R Terrell, “The maximal smoothing principle in density estima-
tion,” Journal of the American Statistical Association, vol. 85, no. 410,
pp. 470–477, 1990.

[9] J. Ramon and L. De Raedt,

in
Proceedings of ICML-2000, Workshop on Attribute-Value and Relational
Learning, 2000, pp. 53–60.

instance neural networks,”

“Multi

[10] O. Maron and T. Lozano-P´erez,

“A framework for multiple-instance
learning,” in Proceedings of Advances in Neural Information Processing
Systems, 1998, pp. 570–576.

[11] Q. Zhang and S.A. Goldman, “Em-dd: An improved multiple-instance
learning technique,” in Proceedings of Advances in Neural Information
Processing Systems. 2001, vol. 14, pp. 1073–1080, Cambridge, MA: MIT
Press.

[12] X. Xu and E. Frank, “Logistic regression and boosting for labeled bags
of instances,” Advances in Knowledge Discovery and Data Mining, pp.
272–281, 2004.

[13] M.L. Zhang and Z.H. Zhou, “Multi-instance clustering with applications to
multi-instance prediction,” Applied Intelligence, vol. 31, no. 1, pp. 47–68,
2009.

[14] Y. Xu, W. Ping, and A.T. Campbell, “Multi-instance metric learning,” in
Proceedings of IEEE International Conference on Data Mining, 2011, pp.
874–883.

[15] T. G¨artner, P.A. Flach, A. Kowalczyk, and A.J. Smola, “Multi-instance
kernels,” in Proceedings of International Conference on Machine Learn-
ing, 2002, pp. 179–186.

[16] O. Maron and A.L. Ratan, “Multiple-instance learning for natural scene
classiﬁcation,” in Proceedings of International Conference on Machine
Learning, 1998, vol. 15, pp. 341–349.

[17] J. Paisley, X. Liao, and L. Carin, “Active learning and basis selection for
kernel-based linear models: a bayesian perspective,” IEEE Transactions
on Signal Processing, vol. 58, no. 5, pp. 2686–2700, 2010.

[18] S.I. Amari,

“Differential geometry of curved exponential

families-
curvatures and information loss,” The Annals of Statistics, pp. 357–385,
1982.

[19] I. Csisz´ar and P.C. Shields, Information theory and statistics: A tutorial,

vol. 1, Communication and information theroy, 2004.

[20] B. Behmardi, R. Raich, and A.O. Hero, “Entropy estimation using the
principle of maximum entropy,” in Proceedings of IEEE International
Conference on Acoustics, Speech and Signal Processing. IEEE, 2011, pp.
2008–2011.
[21] E.T. Jaynes,

“Information theory and statistical mechanics,” Physical

review, vol. 106, no. 4, pp. 620, 1957.

[22] A.L. Berger, V.J.D. Pietra, and S.A.D. Pietra,

“A maximum entropy
approach to natural language processing,” Computational linguistics, vol.
22, no. 1, pp. 39–71, 1996.

[23] M. Dudık, S.J. Phillips, and R.E. Schapire, “Maximum entropy density
estimation with generalized regularization and an application to species
distribution modeling,” Journal of Machine Learning Research, vol. 8,
pp. 1217–1260, 2007.

[24] S. Zhu, X. Ji, W. Xu, and Y. Gong,

“Multi-labelled classiﬁcation
using maximum entropy method,”
in Proceedings of the 28th annual
international ACM SIGIR conference on Research and development in
information retrieval. ACM, 2005, pp. 274–281.

[25] J. Skilling and RK Bryan,

“Maximum entropy image reconstruction-
general algorithm,” Monthly Notices of the Royal Astronomical Society,
vol. 211, pp. 111, 1984.

[26] S.P. Boyd and L. Vandenberghe, Convex optimization, Cambridge

University Press, 2004.

[27] S. Della Pietra, V. Della Pietra, and J. Lafferty, “Inducing features of
IEEE Transactions on Pattern Analysis and Machine

random ﬁelds,”
Intelligence, vol. 19, no. 4, pp. 380–393, 1997.

[28] R. Salakhutdinov, S.T. Roweis, Z. Ghahramani, et al., “On the convergence
of bound optimization algorithms,” in Uncertainty in Artiﬁcial Intelligence,
2003, vol. 19, pp. 509–516.

[29] B. Krishnapuram, L. Carin, M.A.T. Figueiredo, and A.J. Hartemink,
“Sparse multinomial logistic regression: Fast algorithms and generalization
bounds,” IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 27, no. 6, pp. 957–968, 2005.

[30] M. Dudik, S. Phillips, and R. Schapire,

“Performance guarantees for
regularized maximum entropy density estimation,” Learning Theory, pp.
472–486, 2004.

[31] S.F. Chen and R. Rosenfeld, “A survey of smoothing techniques for me
models,” IEEE Transactions on Speech and Audio Processing, vol. 8, no.
1, pp. 37–50, 2000.

[32] M. Dudik, D.M. Blei, and R.E. Schapire, “Hierarchical maximum entropy
density estimation,” in Proceedings of the 24th international conference
on Machine learning. ACM, 2007, pp. 249–256.

[33] B. Recht, M. Fazel, and P.A. Parrilo, “Guaranteed minimum-rank solutions
of linear matrix equations via nuclear norm minimization, 2007,” SIAM
Review, vol. 52, pp. 471–501, 2010.

[34] E.J. Candes and Y. Plan, “Matrix completion with noise,” Proceedings of

the IEEE, vol. 98, no. 6, pp. 925–936, 2010.

