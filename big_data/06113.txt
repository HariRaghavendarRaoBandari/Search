6
1
0
2

 
r
a

 

M
9
1

 
 
]

R
C
.
s
c
[
 
 

1
v
3
1
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Improved Protocols and Hardness Results for the

Two-Player Cryptogenography Problem

Benjamin Doerr∗

Marvin K¨unnemann†

Abstract

The cryptogenography problem, introduced by Brody, Jakobsen, Scheder, and
Winkler (ITCS 2014), is to collaboratively leak a piece of information known
to only one member of a group (i) without revealing who was the origin of this
information and (ii) without any private communication, neither during the
process nor before. Despite several deep structural results, even the smallest
case of leaking one bit of information present at one of two players is not well
understood. Brody et al. gave a 2-round protocol enabling the two players to
succeed with probability 1/3 and showed the hardness result that no protocol
can give a success probability of more than 3/8.

In this work, we show that neither bound is tight. Our new hardness result,
obtained by a diﬀerent application of the concavity method used also in the
previous work, states that a success probability better than 0.3672 is not possible.
Using both theoretical and numerical approaches, we improve the lower bound to
0.3384, that is, give a protocol leading to this success probability. To ease the
design of new protocols, we prove an equivalent formulation of the cryptogeno-
graphy problem as solitaire vector splitting game. Via an automated game tree
search, we ﬁnd good strategies for this game. We then translate the splits that
occurred in this strategy into inequalities relating position values and use an LP
solver to ﬁnd an optimal solution for these inequalities. This gives slightly better
game values, but more importantly, it gives a more compact representation of
the protocol and a way to easily verify the claimed quality of the protocol.

Unfortunately, already the smallest protocol we found that beats the previous
1/3 success probability takes up 16 rounds of communication. The protocol
leading to the bound of 0.3384 even in a compact representation consists of
18248 game states. These numbers suggest that ﬁnding good protocols for the
cryptogenography problem as well as understanding their structure are harder
than what the simple problem formulation suggests.

∗LIX, ´Ecole Polytechnique, Palaiseau, France
†Max Planck Institute for Informatics, Saarbr¨ucken, Germany

1

1

Introduction

Motivated by a number of recent inﬂuential cases of whistle-blowing, Brody, Jakobsen,
Scheder, and Winkler [2] proposed the following cryptogenography problem as model for
anonymous information disclosure in public networks. We have k players (potential
information leakers). A random one of them holds a secret, namely a random bit.
All other players only know that they are not the secret holder. Now without any
non-public communication, the players aim at both making the secret public and hiding
the identity of the secret holder. More precisely, we are looking for a (fully public)
communication protocol in which the players as only form of communication broadcast
bits, which may depend on public information (including all previous communication),
private knowledge (with respect to the secret), and a private source of randomness.
After this phase of communication, the protocol outputs a single bit depending solely
on all data sent in the communication phase. The complete protocol (regulating the
communication and the output function) and all communication is public, and is
monitored by an eavesdropper who aims at identifying the secret owner. We say that
a run of the protocol is a success for the players, if the protocol output is the secret
bit and the eavesdropper fails to identify the secret owner; otherwise it is a success for
the eavesdropper. Since everything is public, optimal strategies for the eavesdropper
are easy to ﬁnd (see below). We shall therefore always assume that the eavesdropper
plays an optimal strategy. The players’ success probability (for a given protocol) then is
the probability (taken over the random decisions of the players and the random initial
secret distribution) that simultaneously (i) the protocol outputs the true secret and
(ii) an optimal eavesdropper does not blame the secret holder.

2 − 1

It is immediately clear that some positive (players’) success probability is easy to
obtain. A protocol without any communication and outputting a random bit achieves
a success probability of 1
2k (the eavesdropper has no strictly better alternative than
guessing a random player). Surprisingly, Brody et al. could show that the players,
despite the complete absence of private communication, can do better. For two players,
they present a protocol having a success probability of 1
4). For
k suﬃciently large, they present a protocol with success probability 0.5644. They also
show two hardness results, namely that a success probability of more than 3
4 cannot
be obtained, regardless of the number of players, and that 3
8 is an upper bound for
the two-player case. While all these results are easy to state, they build on deep
analyses of the cryptogenography problem, in particular, on clever reformulations of
the problem in terms of certain convex combinations of secret distributions (protocol
design) and functions that are concave on a certain inﬁnite set of two-dimensional
subspaces (“allowed planes”) of the set of secret distributions (hardness results).

3 (instead of the trivial 1

The starting point for our work is the incomplete understanding of the two-player

3 ≈ 0.04167 is small, our
8 − 1
case. While the gap between upper and lower bound of 3
impression is that the current-best protocol achieving the 1
3 success probability in two
rounds together with the abstract hardness result do not give us much understanding
of the structure of the cryptogenography problem. We therefore imagine that a better

2

understanding of this smallest-possible problem of leaking one bit from two players,
ideally by determining an optimal protocol (that is, matching a hardness result), could
greatly improve the situation.

Our Results. We shall be partially successful in achieving these goals. On the positive
side, we ﬁnd protocols with strictly larger success probability than 1
3 (namely 0.3384)
and we prove a stricter hardness result of 0.3672. Our new protocols look very diﬀerent
from the 2-round protocol given by Brody et al., in particular, they use inﬁnite protocol
trees (but have an expected ﬁnite number of communication rounds). These ﬁndings
motivate and give new starting points for further research on the cryptogenography
problem.

On the not so positive side, our work on better protocols indicates that good
cryptogenographic protocols can be very complicated. The simplest protocol we found
that beats the 1
3 barrier already has a protocol tree of depth 16, that is, the two players
need to communicate for 16 rounds in the worst case. While we still manage to give a
human-readable description and performance proof for this protocol, it is not surprising
that previous works not incorporating a computer-assisted search did not ﬁnd such a
protocol. Our best protocol, giving a success probability of 0.3384, already uses 18248
non-equivalent states.

Technical contributions. To ﬁnd the improved protocols, we use a number of
theoretical and experimental tools. We ﬁrst reformulate the cryptogenography problem
as a solitaire vector splitting game over vectors in R2×k≥0 . Both for human researchers
and for automated protocol searches, this reformulation seems to be easier to work
with than the previous reformulation via convex combinations of distributions lying
in a common allowed plane [2]. It also proved to be beneﬁcial for improving upon the
hardness result.
Restrictions of the vector splitting game to a ﬁnite subset of R2×k≥0 , e.g., {0, . . . , T}2×k,
can easily be solved via dynamic programming, giving (due to the restriction possibly
sub-optimal) cryptogenographic protocols. Unfortunately, for k = 2 even discretizations
as ﬁne as T = 40 are not suﬃcient to ﬁnd protocols beating the 1/3 barrier and memory
usage quickly becomes a bottleneck issue. However, exploiting the simple fact that the
game values are homogeneous (that is, multiplying a game position by a non-negative
scalar changes the game value by this factor), we can (partially) simulate a much ﬁner
discretization in a coarse one. This extended dynamic programming approach easily gives
cryptogenographic success probabilities larger than 1/3. Reading oﬀ the corresponding
protocols, due to the reuse of the same position in diﬀerent contexts, needs more care,
but in the end gives without greater diﬃculties also the improved protocols.

When a cryptogenographic protocol reuses a state a second time (with a non-trivial
split in between), then there is no reason to re-iterate this part of the protocol whenever
this position occurs. Such a protocol allows inﬁnite paths, while still needing only an
expected ﬁnite number of rounds. Since the extended dynamic programming approach
in ﬁnite time cannot ﬁnd such protocols, we use a linear programming based post-
processing stage. We translate each splitting operation used in the extended dynamic
programming search into an inequality relating game values. By exporting these into

3

an LP-solver, we do not only obtain better game values (possibly corresponding to
cryptogenographic protocols with inﬁnite paths, for which we would get a compact
representation by making the cycles explicit), but also a way to easily certify these
values using an optimality check for a linear program instead of having to trust the
ad-hoc dynamic programming implementation.

Related work. Despite a visible interest of the research community in the crypto-
genography problem, the only relevant follow-up work is Jakobsen’s paper [3], which
analyses the cryptogenography problem for the case that several of the players know
the secret. This allows to leak a much larger amount of information as made precise
in [3]. Due to the asymptotic nature of these results, unfortunately, they do not give
new insights in the 2-player case. Other work on anonymous broadcasting typically
assumes bounded computational power of the adversary (see, e.g., [4]).

In [2], the cryptogenography problem was reformulated to the problem of ﬁnding the
point-wise minimal function f on the set of secret distributions that is point-wise not
smaller than some given function g and that is concave on an inﬁnite set of 2-dimensional
planes. Such restricted notions of concavity (or, equivalently, convexity) seem to be less
understood. We found work by Matouˇsek [5] for a similar convexity problem, however,
with only a ﬁnite number of one-dimensional directions in which convexity is required.
We do not see how to extend these results to our needs.

2 Finding Better Cryptogenography Protocols

This section is devoted to the design of stronger cryptogenographic protocols.
In
particular, we demonstrate that a success probability of more than 1/3 can be achieved.
We start by making the cryptogenography problem precise (Section 2.1 and Section 2.2)
and introduce an equivalent formulation as solitaire vector splitting game (Section 2.3).
We illustrate both formulations using the best known protocol for the 2-player case
(Section 2.4).
In Section 2.5, we state basic properties that simplify the analysis
of protocols and aid our automated search for better protocols, which is detailed
in Section 2.7. In Section 2.6, we give a simple, human-readable proof that 1/3 is
not the optimal success probability by analyzing a protocol with success probability
449

1334 ≈ 0.3341. We describe how to post-optimize and certify the results obtained by the

automated search using linear programming in Section 2.8 and summarize our ﬁndings
(in particular, the best lower bound we have found) in Section 2.9.

2.1 The Cryptogenography Problem

Let us ﬁx an arbitrary number k of players called 1, . . . , k for simplicity. We write
[k] := {1, . . . , k} for the set of players. We assume that a random one of the them, the
“secret owner” J ∈ [k], initially has a secret, namely a random bit X ∈ {0, 1}. The task
of the players is, using public communication only, to make this random bit public
without revealing the identity of the secret owner. More precisely, we assume that the

4

players, before looking at the secret distribution, (publicly) decide on a communication
protocol π. This is again public, that is, all bits sent are broadcast to all players,
and they may depend only on previous communication, the private knowledge of the
sender (whether he is the secret owner or not, and if so, the secret), and private random
numbers of the sender. At the end of the communication phase, the protocol speciﬁes
an output bit Y (depending on all communication).

The aspect of not disclosing the identity of the secret owner is modeled by an
adversary, who knows the protocol (because it was discussed in public) and who gets
to see all communication (and consequently also knows the protocol output Y ). The
adversary, based on all this data, blames one player K. The players win this game
if the protocol outputs the true secret (that is, Y = X) and the adversary does not
blame the secret owner (that is, K (cid:54)= J), otherwise the adversary wins. It is easy to
see (see Section 2.2), what the best strategy for the adversary is (given the protocol
and the communication), so the interesting part of the cryptogenography problem is
ﬁnding strategies that maximize the probability that the players win assuming that the
adversary plays optimal. We call this the (players’) success probability of the protocol.
While the game starts with a uniform secret distribution, it will be useful to regard
arbitrary secret distributions. In general, a secret distribution is a distribution D over
{0, 1} × [k], where Dij is the probability that player j ∈ [k] is the secret owner and
the secret is i ∈ {0, 1}. Modulo a trivial isomorphism, D is just a vector in R2×k≥0 with
(cid:107)D(cid:107)1 = 1. We denote by ∆ = ∆k the set of all these distributions (this was denoted by
∆({0, 1} × [k]) in [2]).

Brody et al. [2] observe that any cryptogenographic protocol can be viewed as
successive rounds of one-bit communication, where in each step some (a priori) secret
distribution probabilistically leads to one of two follow-up (a posteriori) distributions
(depending on the bit transmitted) such that the a priori distribution is a convex
combination of these and a certain proportionality condition is fulﬁlled (all three distri-
butions lie in the same “allowed plane”). Conversely, whenever the initial distribution
can be written as such a convex combination of certain distributions, then there is a
round of a cryptogenographic protocol leading to these two distributions (with certain
probabilities). Consequently, the problem of ﬁnding a good cryptogenographic protocol
is equivalent to iteratively rewriting the initial equidistribution as certain convex com-
binations of other secret distributions in such a way that the success probability, which
can be expressed in terms of this rewriting tree, is large. Instead of directly working
with this formulation, we propose a slightly diﬀerent reformulation in Section 2.3. To
prepare readers that are unfamiliar with the work of Brody et al. [2], we give a high-level
introduction in the following section.

2.2 The Convex Combination Formulation

For readers’ convenience, we give a high-level description of the convex combination
formulation of Brody et al. For proofs and a more formal treatment, we refer the reader
to [2].

5

Optimal strategy of the adversary. Recall that X denotes the secret bit and J
the identity of the secret owner. Fix a protocol π of the players, which for every state
of the protocol execution, i.e., every possible history of communication, determines
(1) which player’s turn it is to communicate (or whether communication has ended) and
(2) probability distributions over the next message this player sends (two for the case
that this player is the secret owner, i.e., one for each value of the secret bit, and one for
the other case). Both (1) and (2) may depend on all previous communication and, if
the active player is the secret owner, also on the value of the secret bit. Additionally, π
ﬁxes a protocol output function Out that given the transcript τ of all communication
returns the players’ guess Out(τ ) on the secret bit. Without loss of generality, we may
assume that the protocol proceeds in rounds, where in each round a message consisting
of a single bit is sent.

Let Com(π) denote the transcript of all communication of the protocol π. Note
that this is a random variable, since we assume a random player to be the owner of
a random bit as secret.
It is not diﬃcult to see what the optimal strategy of the
adversary is, given the knowledge of the protocol π. He may assume that the players’
guess is correct, i.e., Out(Com(π)) = X, as otherwise the players have already lost
and therefore his guess is irrelevant. After the protocol execution has ﬁnished with a
transcript τ , the adversary maximizes his winning probability by blaming the player
argmaxj∈[k] Pr[J = j | Com(π) = τ, X = Out(τ )] (breaking ties arbitrarily), i.e., the
player who is most likely to own the secret given the communication described by τ .
From this reasoning, it becomes clear that the decisive information in the game is,
for any partial transcript τ(cid:48), the distribution D = ((D0,1, D1,1), . . . , (D0,k, D1,k)), where

Dx,j = Pr[J = j, X = x | Com(π) starts with τ(cid:48)]

is the probability an outside observer (knowing only public information, i.e., all previous
communication) assigns to the event (J = j, X = x). As a simple consequence,
assume that some ﬁxed transcript τ(cid:48) transforms the initial uniform distribution into
the distribution D and no further communication is allowed. Then the optimal choice
for the protocol output is the guess

(cid:88)

j∈[k]

 ,

argmaxx∈{0,1}

Dx,j − max
j∈[k]

Dx,j

as for any ﬁxed choice Out(τ(cid:48)) = x, the adversary blames the player ¯ := argmaxj∈[k]Dx,j
and hence the players win in all cases with X = x except when J = ¯. We call the
strategy applied here the zero-bit strategy (since no further communication is done).

Convex combination formulation. Brody et al. prove that it is not only suﬃcient, but
in fact equivalent to represent the cryptogenography game using only the distributions
D described above and how the protocol aﬀects these distributions. More precisely,
one can model the game starting from any initial distribution D on {0, 1} × {1, . . . , k}.
Then the ﬁrst bit sent by some player j splits D into the distributions D0 (for the

6

case that the 0-bit is sent) and D1 (for the case that the 1-bit is sent), i.e., Di is the
distribution an outside observer assigns to (J, X) after bit i has been sent. By this
abstraction, one can recursively consider the distributions D0 and D1 (i.e., their optimal
protocols and success probabilities).
To determine the properties of possible splits in a protocol, let p be the probability
that player j transmits a 0-bit. By a simple calculation, we have that D = pD0+(1−p)D1
(cf. [2, Lemma 4.1]). Additionally, since a player may only use the information whether
or not he has the secret bit (and if so, the value of the secret bit), player j may
never leak new information about whether another player j(cid:48) ∈ [k] \ {j} is more likely
to have secret 0 or 1 (i.e., the ratio of D0,j(cid:48) and D1,j(cid:48) is maintained in the resulting
(cid:54)= j is more likely to have the secret
distributions D0 and D1) or whether player j(cid:48)
than another player j(cid:48)(cid:48) ∈ [k] \ {j, j(cid:48)}. This transfers to a proportionality condition
that (D0)|{0,1}×([k]\{j}) = λD|{0,1}×([k]\{j}) for some λ ∈ [0, 1]. In fact, any split of D
into D0 and D1 satisfying these conditions can be realized by a cryptogenographic
protocol. Thus, the cryptogenography game is equivalent to, starting from the uniform
distribution, recursively apply splits satisfying these conditions (i.e., allowed splits),
using the zero-bit strategy at the leaves, in such a way that the resulting success
probability is maximized. We argue that this view is equivalent to our vector splitting
formulation in Lemma 2.6.

2.3 The Solitaire Vector Splitting Game

Instead of directly using the “convex combination” formulation of Brody et al., we
propose a slightly diﬀerent reformulation as solitaire vector splitting game. This
formulation seems to ease ﬁnding good cryptogenographic protocols (lower bounds
for the success probability), both for human researchers and via automated search
(Section 2.6). The main advantage of our formulation is that it takes as positions
all 2k-dimensional vectors with non-negative entries, whereas the cryptogenographic
protocols are only deﬁned on distributions over {0, 1} × [k]. In this way, we avoid
arguing about probabilities and convex combinations and instead simply split a vector
(resembling a secret distribution) into a sum of two other vectors. Furthermore, a
simple monotonicity property (Proposition 2.5) eases the analyses. Still, there is an
easy translation between the two formulations, so that we can re-use whatever results
were found in [2].
Deﬁnition 2.1. Let D ∈ R2×k≥0 . We say that (D0, D1) is a j-allowed split of D if
D = D0 + D1 and D0 (and thus also D1) is proportional to D on {0, 1}× ([k]\{j}), that
is, there is a λ ∈ [0, 1] such that (D0)|{0,1}×([k]\{j}) = λD|{0,1}×([k]\{j}). We call (D0, D1)
an allowed split of D if it is a j-allowed split of D for some j ∈ [k].

The objective of the vector splitting game is to recursively apply allowed splits to a

7

given vector D ∈ R2×k≥0 with the target of maximizing the sum of the

(cid:18)(cid:88)

j∈[k]

p(D(cid:48)) := max
x∈{0,1}

x,j − max
D(cid:48)
j∈[k]

D(cid:48)

x,j

(cid:19)

split of the label of v. The payoﬀ of such a play is(cid:80)

values of the resulting vectors (note that when D(cid:48) is a distribution, then p(D(cid:48)) is the
0-bit success probability of D(cid:48) as argued in Section 2.2). More precisely, an n-round
play of the vector splitting game is described by a binary tree of height at most n,
where the nodes are labeled with game positions in R2×k≥0 . The root is labeled with the
initial position D. For each non-leaf v, the labels of the two children form an allowed
D(cid:48) p(D(cid:48)), where D(cid:48) runs over all
leaves of the game tree. The aim is to maximize the payoﬀ. Right from this deﬁnition,
it is clear that the maximum payoﬀ achievable in an n-round game started in position
D, the value of this game, is succn(D) as deﬁned below.
Deﬁnition 2.2. For all n ∈ N and for all D ∈ R2×k≥0 , we recursively deﬁne

(cid:18) (cid:80)
(cid:18)

j∈[k]

(i) succ0(D) := max
x∈{0,1}

(ii) succn(D) := max
(D0,D1)

(cid:19)

Dx,j − max
j∈[k]

Dx,j

;

(cid:19)

succn−1(D0)+succn−1(D1)

, if n ≥ 1. Here the maximum

is taken over all allowed splits (D0, D1) of D.

For an example of an admissible game, we refer to Figure 1 in Section 2.4.
It is easy to see that the game values are non-decreasing in the number of rounds,

but bounded. The limiting value is thus well-deﬁned.
Lemma 2.3. Let D ∈ R2×k≥0 and n ∈ N. Then succn(D) ≤ (cid:107)D(cid:107)1 and succn+1(D) ≥
succn(D). Consequently, succ(D) := limn→∞ succn(D) is well-deﬁned and is equal
to supn∈N succn(D).
Proof. The previous deﬁnition and an elementary induction shows succn(D) ≤ (cid:107)D(cid:107)1.
Since (D, 0) is an allowed split of D and succn(0) = 0 by the previous observation, we
have succn+1(D) ≥ succn(D) + succn(0) = succn(D).
Proposition 2.4 (scalability). Let D ∈ R2×k≥0 and λ ≥ 0. Then succn(λD) =
λ succn(D) for all n ∈ N. Consequently, succ(λD) = λ succ(D).
Proof. The statements follow right from the deﬁnition of succn and succ via induction.

Proposition 2.5 (monotonicity). Let D, E ∈ R2×k≥0 with E ≥ D (component-wise).
Then succn(E) ≥ succn(D) for all n ∈ N. Consequently, succ(E) ≥ succ(D).

8

Proof. Clearly succ0(E) ≥ succ0(D). Hence assume that for some n ∈ N, we have
succn(E) ≥ succn(D) for all E ≥ D. Let (D0, D1) with D0 = (d0
ij) and D1 = D−D0 =
ij) be an allowed split of D = (dij). Building on these, deﬁne E0 := E0(D0, D) = (e0
(d1
ij)
with e0
. Then (E0, E1) is
an allowed split of E satisfying E0 ≥ D0 and E1 ≥ D1. Hence

and E1 := E1(D1, D) := E − E0, hence e1

ij := d0
ij

eij
dij

ij = d1
ij

eij
dij

succn+1(E) ≥ max
≥ max

(D0,D1)

(D0,D1)

(succn(E0) + succn(E1))

(succn(D0) + succn(D1)) = succn+1(D),

where the maxima range over all allowed splits (D0, D1) of D.

From the previous deﬁnitions and observations, we derive that the game values for
games starting with a distribution D, that is, (cid:107)D(cid:107)1 = 1, and the success probabilities
of the optimal cryptogenographic protocols for D, are equal.
Lemma 2.6. Let D ∈ R2×k≥0 with (cid:107)D(cid:107)1 = 1. Then for all n ∈ N, our deﬁnitions of
succn coincide with the ones of Brody et al., which are the success probabilities of the
best n-round cryptogenographic protocols for the distribution D. Consequently, also the
deﬁnition of succ(D) coincides.

Proof. Let us for the moment denote the success probabilities deﬁned by Brody et
al. by sn(D) and s(D) and then show that succn(D) = sn(D) and consequently
succ(D) = s(D) for all distributions D.

By deﬁnition, we have succ0(D) = s0(D) for all distributions D. Lemma 4.1 and 4.2
of [2] establish that the ﬁrst round of any cryptogenographic protocol for the distribution
D with some probability λ leads to a distribution D0 and with probability ¯λ := 1 − λ
leads to a position D1 such that D = λD0 + ¯λD1 and D0, D1 are proportional to D on
{0, 1}×([k]\{j}) for some j ∈ [k]. Conversely, for any such λ, D0, D1 there is a one-round
cryptogenographic protocol leading to the distribution D0 with probability λ and to D1
with probability ¯λ. Hence for any n ≥ 1, the success probability sn(D) of the optimal
n-round protocol for the distribution D is sn(D) = maxλ,D0,D1(λsn−1(D0) + ¯λsn−1(D1)),
where λ, D0, D1 run over all values as above. Note that these are exactly those values
which make (λD0, ¯λD1) an allowed split of D. By induction and scalability, we obtain

sn(D) = max
λ,D0,D1
= max
λ,D0,D1
= max
( ¯D0, ¯D1)

(λ succn−1(D0) + ¯λ succn−1(D1))

(succn−1(λD0) + succn−1(¯λD1))

(succn−1( ¯D0) + succn−1( ¯D1)) = succn(D),

where the last maximum is taken over all allowed splits ( ¯D0, ¯D1) of D.

9

2.4 Example: The Best-so-far 2-Player Protocol

We now turn to the case of two players. We use this subsection to describe the best
known protocol for two players in the diﬀerent languages. We also use this mini-example
to sketch the approaches used in the following subsections to design superior protocols.
For two players, we usually write a game position D = (d01, d11, d02, d12) ∈ R2×2≥0 as
D = (a, b, c, d). The 0-round game value (equaling the success probability of the 0-bit
protocol) then is

succ0(D) = max{min{a, c}, min{b, d}}.

6, 1

6, 1

3, 1

3, 1

3, 0, 1

3, 1

3, 1

6, 1

4, 1

4, 1

4, 1

6) and ( 1

3, 0) and ( 1

4) with probability 1

As a warmup, let us describe the best known 2-player protocol TwoBit in the two
languages. In the language of Brody et al., the ﬁrst player can send a (randomized)
bit that transforms the initial distribution ( 1
2 each into the
distributions ( 1
3). In the ﬁrst case, the second player can send
3, 1
a bit leading to each of the distributions ( 1
3, 1
3) with probability
2, both having a 0-bit success probability of 1
1
3. In the second possible result of the
ﬁrst move, the ﬁrst player can lead to an analogous situation. Consequently, after two
rounds of the protocol we end up with four equally likely distributions all having a 0-bit
3. Hence the protocol TwoBit has a success probability of 1
success probability of 1
3.
In the language of the splitting games, we can forget about the probabilities and
simply split up the initial distribution. Using the scaling invariance, to ease reading we
scaled up all numbers by a factor of 12. Figure 1 shows the game tree corresponding to
the TwoBit protocol. It shows that succ2(3, 3, 3, 3) ≥ 4, proving again the existence
of a cryptogenographic protocol for the distribution ( 1
12(3, 3, 3, 3) with
success probability 4
Note that each allowed split (D0, D1) of D implies the inequality succ(D) ≥
succ(D0) + succ(D1), which follows from clause (ii) of Deﬁnition 2.2 and taking the
limit n → ∞. Hence the game tree giving the 1
3 lower bound for the success probability
equivalently gives the following proof via inequalities.

4) = 1

4, 1

4, 1

4, 1

12 = 1
3.

succ(3, 3, 3, 3) ≥ succ(2, 2, 1, 1) + succ(1, 1, 2, 2),
succ(2, 2, 1, 1) = succ(1, 1, 2, 2) ≥ succ(1, 0, 1, 1) + succ(0, 1, 1, 1),
succ(1, 0, 1, 1) = succ(0, 1, 1, 1) ≥ succ0(0, 1, 1, 1) = 1.

The splitting game and the inequality view will in the following be used to design
stronger protocols (better lower bounds for the optimal success probability). We shall
compute good game trees by computing lower bounds for the game values of a discrete
set of positions via repeatedly trying allowed splits. For example, the above game tree
for the starting position (3, 3, 3, 3) could have easily be found by recursively computing
the game values for all positions in {0, 1, 2, 3}4.

It turns out that such an automated search leads to better results when we also allow
scaling moves (referring to Proposition 2.4). For example, in the above mini-example of
computing optimal game values for all positions {0, 1, 2, 3}4, we could try to exploit
the fact that succ(1, 1, 1, 1) = 1
succ(3, 3, 3, 3). Such scaling moves are a cheap way of
3

10

Figure 1: Game tree corresponding to TwoBit

working in {0, 1, 2, 3}4, but trying to gain the power of working in {0, 1, . . . , 9}4, which
is computationally more costly, especially with regard to memory usage. Scaling moves
may lead to repeated visits of the same position, resulting in cyclic structures. Here
translating the allowed splits used in the tree into the inequality formulation and then
using an LP-solver is an interesting approach (detailed in Section 2.8). It allows to
post-optimize the game trees found, in particular, by solving cyclic dependencies. This
leads to slightly better game values and compacter representations of game trees.

2.5 Useful Facts

For some positions of the vector splitting game, the true value is easy to determine. We
do this here to later ease the presentation of the protocols.
Proposition 2.7. We have succ(a, b, c, d) ≤ min{a, c} + min{b, d}.

This statement is a simple corollary of the concavity method detailed in Section 3.1,

hence at this point, we only state the proposition and postpone the proof.
Proposition 2.8. Let D = (a, b, c, 0). Then succ(D) = succ0(D) = min{a, c}.
Proof. Clearly, succ(D) ≥ succ0(D) = min{a, c}. By Proposition 2.7, we obtain
succ(D) ≤ min{a, c}, proving the claim.
Proposition 2.9. If D = (a, b, c, d) is such that a + b ≤ min{c, d}, then succ(D) =
a + b.
Proof. We have D ≥ D(cid:48) := (a, b, a + b, a + b) and (D0, D1) with D0 = (a, 0, a, a) and
D1 = (0, b, b, b) is an allowed split of D(cid:48). Hence succ(D) ≥ succ(D(cid:48)) ≥ succ(D0) +
succ(D1) = a + b. The upper bound follows immediately from Proposition 2.7.

2.6 Small Protocols Beating the 1/3 Barrier

We now present a sequence of protocols showing that there are cryptogenographic
protocols having a success probability strictly larger than 1
3. These protocols are still
relatively simple, so we also obtain a human-readable proof of the following result.

11

(3, 3, 3, 3)(2, 2, 1, 1)(1, 1, 2, 2)(1, 1, 1, 0)(1, 1, 0, 1)(1, 0, 1, 1)(0, 1, 1, 1)Theorem 2.10. succ( 1

4, 1

4, 1

4) ≥ 449
4, 1

1334 ≈ 0.3341.

Proof. To be able to give a readable mathematical proof, we argue via inequalities for
game values succ(·). We later discuss how the corresponding protocols (game trees)
look like.

We ﬁrst observe the following inequalities, always stemming from allowed splits
(the underlined entries are proportional). Whenever Proposition 2.8 or 2.9 determine a
value, we exploit this without further notice.

succ(12, 12, 12, 12) ≥ succ(7, 7, 6, 4) + succ(5, 5, 6, 8),

succ(5, 5, 6, 8) ≥ succ(2, 2, 0, 2) + succ(3, 3, 6, 6) = 2 + 6 = 8.

This proves succ(12, 12, 12, 12) ≥ 8 + succ(7, 7, 6, 4). To analyze succ(7, 7, 6, 4), we
use the allowed split

succ(7, 7, 6, 4) ≥ succ(4, 5, 3, 2) + succ(3, 2, 3, 2)

(1)

and regard the two positions (4, 5, 3, 2) and (3, 2, 3, 2) separately in some detail.

Claim 1: The value of (4, 5, 3, 2) satisﬁes succ(4, 5, 3, 2) ≥ 55
succ(8, 10, 6, 4). We present the allowed splits

succ(4, 5, 3, 2) = 1
2

12. By scaling, we have

succ(8, 10, 6, 4) ≥ succ(4, 5, 2, 4) + succ(4, 5, 4, 0) = succ(4, 5, 2, 4) + 4,
succ(4, 5, 2, 4) ≥ succ(1, 2, 1, 2) + succ(3, 3, 1, 2) = succ(1, 2, 1, 2) + 3,

hence succ(8, 10, 6, 4) ≥ succ(1, 2, 1, 2) + 7. To bound the latter term, we use the
scaling succ(1, 2, 1, 2) = 1
6

succ(6, 12, 6, 12) and consider the allowed splits

succ(6, 12, 6, 12) ≥ succ(5, 10, 3, 9) + succ(1, 2, 3, 3) = succ(5, 10, 3, 9) + 3,
succ(5, 10, 3, 9) ≥ succ(0, 6, 2, 6) + succ(5, 4, 1, 3) = 6 + 4 = 10.

Thus succ(6, 12, 6, 12) = 13 and succ(1, 2, 1, 2) = 13
2 (succ(1, 2, 1, 2) + 7) = 55
1
12.

Claim 2: We have succ(3, 2, 3, 2) ≥ 5

3 + 2
9
succ(9, 6, 9, 6) and compute

succ(3, 2, 3, 2) = 1
3

6 . This shows succ(4, 5, 3, 2) =

succ(7, 7, 6, 4). By scaling, we obtain

succ(9, 6, 9, 6) ≥ succ(6, 3, 6, 4) + succ(3, 3, 3, 2),
succ(6, 3, 6, 4) ≥ succ(3, 0, 3, 2) + succ(3, 3, 3, 2) = 3 + succ(3, 3, 3, 2),

and hence succ(9, 6, 9, 6) ≥ 3 + 2 succ(3, 3, 3, 2). To bound the latter term, we scale
succ(3, 3, 3, 2) = 1
3

succ(9, 9, 9, 6) and present the allowed splits
succ(9, 9, 9, 6) ≥ succ(7, 7, 6, 4) + succ(2, 2, 3, 2),
succ(2, 2, 3, 2) ≥ succ(1, 1, 1, 0) + succ(1, 1, 2, 2) = 1 + 2 = 3.

Thus succ(3, 3, 3, 2) ≥ 1+ 1

3

succ(7, 7, 6, 4), implying succ(3, 2, 3, 2) = 5

3+ 2

9

succ(7, 7, 6, 4).

12

Putting things together. Claims 1 and 2 together with (1) give

succ(7, 7, 6, 4) ≥ 75

12 + 2

9

succ(7, 7, 6, 4).

Solving this elementary equation, we obtain succ(7, 7, 6, 4) ≥ 225
succ(12, 12, 12, 12) ≥ 225
succ( 1
3 + 1

28 + 8 = 449
1344 = 449

1344 = 0.33407738 . . . .

28 , and consequently,
28. Scaling leads to the claim of the theorem

28 = 16 + 1

4, 1

4, 1

4, 1

4) = 1

Figure 2: Game tree representation of the protocols of Theorem 2.10

When translating the inequalities into a game tree (see Figure 2 for the result), we
ﬁrst observe that in Claim 2 we obtained two diﬀerent nodes labeled with the position
(3, 3, 3, 2). Since there is no reason to treat them diﬀerently, we can identify these two

13

(12, 12, 12, 12)(7, 7, 6, 4)(5, 5, 6, 8)(4, 5, 3, 2)(3, 2, 3, 2)(2, 2, 0, 2)(3, 3, 6, 6)(3, 0, 3, 3)(0, 3, 3, 3)(2, 2, 0, 2)(8, 10, 6, 4)· 2(9, 6, 9, 6)· 3(4, 5, 2, 4)(4, 5, 4, 0)(1, 2, 1, 2)(3, 3, 1, 2)(6, 12, 6, 12)· 6(1, 1, 1, 0)(1, 1, 1, 0)(1, 1, 1, 0)(5, 10, 3, 9)(1, 2, 3, 3)(0, 6, 2, 6)(5, 4, 1, 3)(1, 0, 1, 1)(0, 2, 2, 2)(1, 0, 1, 1)(1, 0, 0, 0)(4, 4, 1, 3)(3, 3, 0, 3)(6, 3, 6, 4)(3, 3, 3, 2)(3, 0, 3, 2)(9, 9, 9, 6)· 3(7, 7, 6, 4)(2, 2, 3, 2)(1, 1, 2, 2)(0, 1, 1, 1)nodes and thus obtain a more compact representation of the game tree. This is the
reason why the node labeled (3, 3, 3, 2) in Figure 2 has two incoming edges.

Interestingly, such identiﬁcations can lead to cycles.

If we translate the equa-
tions for position (7, 7, 6, 4) and its children into a graph, then we observe that the
node for (7, 7, 6, 4) has a descendant also labeled (7, 7, 6, 4) (this is what led to the
inequality succ(7, 7, 6, 4) ≥ 75
succ(7, 7, 6, 4)). By transforming this inequality to
succ(7, 7, 6, 4) ≥ 225
28 , we obtain a statement that is true, but that does not anymore
refer to an actual (ﬁnite) game tree. However, there is a sequence of game trees with
values converging to the value we determined. These trees are obtained from recursively
applying the above splitting procedure for (7, 7, 6, 4) a certain number (cid:96) of times and
then using the 0-round tree for the lowest node labeled (7, 7, 6, 4). The value of this
28 ( 2
9)(cid:96).
Hence for (cid:96) ≥ 3, this is more than 16 (which represents a success probability of 1
3),
corresponding to a game tree of height 4 + 4(cid:96) ≥ 16.

game tree is 8+(cid:80)(cid:96)−1

28 − 57

9)(cid:96) succ0(7, 7, 6, 4) = 8+ 75

12

i=0( 2

9)i 75

12 +( 2

9)(cid:96) = 449

12 + 2

9

1−( 2
9 )(cid:96)
1− 2
9

+6·( 2

2.7 Automated Search

The vector splitting game formulation enables us to search for good cryptogenographic
protocols as follows. We try to determine the game values of all positions from a
discrete set D := {0, . . . , T}2×k by repeatedly applying allowed splits. More precisely,
we store a function s : D → R that gives a lower bound on the game value succ(D) of
each position D ∈ D. We initialize this function with s ≡ succ0 and then in order of
ascending (cid:107)D(cid:107)1 try all allowed splits D = D0 + D1 and update s(D) ← s(D0) + s(D1)
in case we ﬁnd that s(D) was smaller.

Recall that for any secret distribution D, the game value succ(D) is the supre-
mum success probability of cryptogenographic protocols for D. Hence, e.g., the value
s(T, . . . , T )/(2T k) ≤ succ(1/(2k), . . . , 1/(2k)) is a lower bound for this success proba-
bility. As we will discuss later, by keeping track of the update operations performed,
we can not only compute such a lower bound, but also concrete protocols.
Since even for k = 2, the size of the position space D and the number of allowed
splits increase quickly with T , only moderate choices of T are computationally feasible,
limiting the power of this approach drastically. Surprisingly, introducing a simple
scaling step is suﬃcient to overcome this problem and enables us to ﬁnd protocols that
are better than the previous-best protocol TwoBit. Algorithm 1 outlines our basic
search procedure.
Instead of restricting to optimize only over all allowed splits (D0, D1) ∈ D2 of D ∈ D,
however, we use monotonicity of the discretization to exploit even more reasonable
splits. For ease of presentation, we focus here on the 2-player case (the generalization
to larger values of k is straightforward).
Deﬁnition 2.11. We call distributions D0 = (a0, b0, c0, d0) ∈ D and D1 = (a1, b1, c1, d1) ∈
D a relaxed split of D = (a, b, c, d) ∈ D, if a = a0 + a1, b = b0 + b1, c = c0 + c1,
d0 = (cid:98)(d/c) · c0(cid:99) and d1 = (cid:98)(d/c) · c1(cid:99).

14

Algorithm 1 Computing a lower bound on succ for the discrete set of positions
D = {0, . . . , T}2×k.
1: Initialize s ≡ succ0
2: repeat
3:
4:
5:
6:
7:

Splitting Step:
for all D ∈ D in ascending order of (cid:107)D(cid:107)1 do

for all relaxed splits (D0, D1) ∈ D2 of D do

if s(D) < s(D0) + s(D1) then

Update s(D) ← s(D0) + s(D1)

8:
9:
10:

11:

Scaling Step:
for all D ∈ D and all λ ∈ N with λD ∈ D do

if s(D) < s(λD)

then

Update s(D) ← s(λD)

λ

λ

12: until termination criterion is met

Observation 2.12. Any relaxed split (D0, D1) ∈ D2 of D ∈ D yields a feasible lower
bound succ(D) ≥ succ(D0) + succ(D1).
Proof. The statement follows from noting that ¯D0 := (a0, b0, c0, (d/c) · c0) and ¯D1 :=
(a1, b1, c1, (d/c) · c1) yield an allowed split of D. Thus succ(D) ≥ succ( ¯D0) +
succ( ¯D1) ≥ succ(D0) + succ(D1), where the last inequality follows from monotonicity
(Proposition 2.5).

Note that while the deﬁnition relaxes an allowed split only at coordinate d, by
symmetry of succ, we obtain the same lower bound when relaxing at other coordinates.
This allows us to even split distributions D = (a, b, c, d) ∈ D where neither of the
ratios a/b and c/d occur “perfectly” in another distribution D(cid:48) ∈ D by dismissing some
“vector mass”, i.e., rounding down from d/c· ci to (cid:98)d/c· ci(cid:99). Although these splits might
appear inherently wasteful (as this loss can never be regained), the best protocols that
we ﬁnd do indeed make use of (a small number of) such relaxed splits.

Implementation Details. Since succ is symmetric in both the secret and the
player dimension, we may assume the following standard form for distributions D =
((D[0, 1], D[1, 1]), . . . , (D[0, k], D[1, k])) ∈ D to speed up computation and reduce mem-
ory usage: D[0, 1] ≥ D[1, 1] and D[0, i] ≥ D[0, i + 1]
for i = 1, . . . , k − 1. More
speciﬁcally, for k = 2, we can without loss of generality even assume that a ≥ b, c, d.
In principle, an implementation should take care to avoid propagation of ﬂoating-
point rounding errors, since previously computed entries are reused heavily and identical
values are regularly recalculated in a number of diﬀerent ways. Instead of using interval
arithmetic, however, we chose to use a simple, fast implementation ignoring potential
rounding errors: This is justiﬁed by (i) our LP-based post-optimization which gives a
proof of the obtained lower bound (that can be checked using an exact LP solver), hence

15

15

T
Automated search 0.3369432925
Iterations
Constraints
Game Positions

119
535
394

20
0.3376146092
129
1756
1326

25
0.3379027186
141
4217
2956

30
0.3381689066
146
13958
9646

Table 1: Lower bounds s(T, . . . , T )/(4T ) on succ( 1
4) stemming from the auto-
mated search (line 1). Given are also the number of iterations until the automated
search procedure converged, i.e., stopped ﬁnding improvements using relaxed splits or
scalings, and the number of game positions and constraints that had an inﬂuence on
the value of s(T, . . . , T ).

4, 1

4, 1

4, 1

correctness of the output remains certiﬁed, and (ii) the fact that our discretization
of the search space introduces an inherent imprecision that very likely dominates the
ﬂoating-point rounding errors.

The probably most desirable termination criterion is to run the search until no
improvements can be found. However, when the running time becomes a bottleneck
issue, we can restrict the search to a small ﬁxed number of iterations. This is especially
useful in combination with the post-optimization (as the gain in the result per iteration
is decreasing for later iterations of the process, which intuitively give increasingly
accurate approximations of inﬁnite “ideal” protocols – the post-optimization could
potentially resolve these cyclic structures earlier in the process).

Results. The success probabilities of the protocols computed following the above
approach, using diﬀerent values for T , are given in the ﬁrst line of Table 1. Further
results exploiting the post-optimization are given in Table 2 in Section 2.9.

2.8 Post-Optimization via Linear Programming

When letting Algorithm 1 also keep track of at what time which update operation
was performed, this data can be used to extract strategies for the splitting game
(and cryptogenographic protocols). Some care has to be taken to only extract those
intermediate positions that had an inﬂuence on the ﬁnal game value for the position we
are interested in (see below).

While this approach does deliver good cryptogenographic protocols, manually verify-
ing the correctness of the updates or analyzing the structure of the underlying protocol
quickly becomes a diﬃcult task, as the size of the protocol grows rapidly.

Fortunately, it is possible to output a compact, machine-veriﬁable certiﬁcate for the
lower bound obtained by the automated search that might even prove a better lower
bound than computed: Each update step in the automated search corresponds to a
valid inequality of the form succ(D) ≥ succ(D0) + succ(D1), succ(D) ≥ succ0(D)
or λ · succ(D) = succ(λ · D). We can extract the (sparse) set ineq(T, T, T, T ) of those
inequalities that lead to the computed lower bound on succ(T, T, T, T ).

16

Reconstructing the Strategy. Memorizing the best splits found by the dynamic
programming updates, it is straightforward to reconstruct the best strategy found by
the automated search. For preciseness, we deﬁne the i-th update step for i = 2k − 1 as
the k-th splitting step (during the execution of Algorithm 1) and for i = 2k as the k-th
scaling step, i.e., each update step is alternatingly a splitting and a scaling step. For
every distribution D and update step i, we maintain an index L(D, i) deﬁned as the last
update step before and including i in which s(D) has been updated to a better value,
or 0 if s(D) has never been updated. Moreover, for every D and update step i in which
s(D) has been updated, we keep a constraint I(D, i) which represents the inequality or
equality used to update s(D) to its best value in update step i. More speciﬁcally, I(D, i)
stores the inequality succ(D) ≥ succ(D0) + succ(D1) if the update step i represents
a splitting step of D into (D0, D1) and λsucc(D) = succ(λD) if the update step i
represents a scaling of D by λ. Furthermore, we let I(D, 0) represent the inequality
succ(D) ≥ succ0(D). This gives rise to the procedure ineq(D, i) (see Algorithm 2)
that returns a (sparse) list of inequalities proving the lower bound computed by the
automated search (after letting it run for i iterations).

Algorithm 2 Computing the proof ineq(D, I) of the lower bound on succ(D) obtained
by running the automated search for I iterations.

1: function ineq(D, i)
2:
3:

if L(D, i) < i then

return ineq(D, L(D, i))

4:
5:
6:
7:
8:
9:

if i is a splitting step with I(D, i) = ”succ(D) ≥ succ(D0) + succ(D1)” then

return I(D, i) ∪ ineq(D0, i) ∪ ineq(D1, i)
return I(D, i) ∪ ineq(λD, i − 1)

else if i is a scaling step with I(D, i) = ”λsucc(D) = succ(λD)” then
else if i = 0 with I(D, 0) = ”succ(D) ≥ succ0(D)” then

return I(D, 0)

The Linear Program. Consider replacing each occurrence of succ(D(cid:48)) in the set
of inequalities ineq(T, T, T, T ) found by the automated search by a variable sD(cid:48). We
obtain a system of linear inequalities S that has the feasible solution sD(cid:48) = succ(D(cid:48))
(for every occurring vector D(cid:48)). Hence in particular, the optimal solution of the linear
program of minimizing sD subject to S is a lower bound on succ(D). It is easy to see
that this solution is at least as good as the solution stemming from the automated
search alone. It can, however, even be better, in particular when a game strategy yields
cyclic visits to certain positions. Table 2 contains, for diﬀerent values of T , the success
probabilities found by automated search (run with a bounded iteration number of 20)
and by this above linear programming approach. The table also contains the number
of linear inequalities (and game positions) that were extracted from the automated
search run. We observe that consistently the LP-based solution is minimally better.

17

30

T
Automated search 0.3381086510
LP solution
0.3381527322
20
Iterations
5373
Constraints
Game Positions
4126

35
0.3381937725
0.3382301900
20
8882
6789

40
0.3383218072
0.3383547901
20
12410
9396

45
0.3383946540
0.3384303130
20
18659
13992

50
0.3384414508
0.3384736461
20
24483
18248

Table 2: Lower bounds s(T, . . . , T )/(4T ) on succ( 1
4) stemming from the auto-
mated search only (line 1) and from the LP solution of the linear system extracted from
the automated search data, when the number of iterations is restricted to 20.

4, 1

4, 1

4, 1

We also observe that the number of constraints is still moderate, posing no diﬃculties
for ordinary LP solvers (which stands in stark contrast to feeding all relaxed splits
and scalings over the complete discretization to the LP solver, which quickly becomes
infeasible).

Hence the advantage of our approach of extracting the constraints from the auto-
mated search stage is that it generates a much sparser sets of constraints that still
are suﬃciently meaningful. After solving the LP, we can further sparsify this set of
inequalities by deleting all inequalities that are not tight in the optimal solution of
the LP, since these cannot correspond to the best splits found for the corresponding
vector D, yielding a smaller set of relevant inequalities, which might help to analyze
the structure of strong protocols.

2.9 Our Best Protocol

We report the best protocol we have found using the approach outlined in the previous
sections.

4, 1

4, 1

Theorem 2.13. In the 2-player cryptogenography problem, succ( 1

4) ≥ 0.3384736.
4, 1
Proof. On http://people.mpi-inf.mpg.de/~marvin/verify.html, we provide a lin-
ear program based on feasible inequalities on the discretization D with T = 50. To
verify the result, one only has to (1) check validity of each inequality, i.e., checking
whether each constraints encodes a feasible scaling, relaxed split or zero-bit success
probability and (2) solve the linear program. Since we represent the distributions
D = (a, b, c, d) using a normal form a ≥ b, c, d (to break symmetries), checking validity
of each splitting constraint is not completely trivial, but easy. We provide a simple
checker program to verify validity of the constraints. The LP is output in a format
compatible with the LP solver lp solve1.

1lpsolve.sourceforge.net

18

3 A Stronger Hardness Result

In this section, we prove that any 2-player cryptogenographic protocol has a success
probability of at most 0.3672. This improves over the previous 0.375 bound of [2].

Theorem 3.1. We have succ( 1

4, 1

4, 1

4) ≤ 47
4, 1

128 = 0.367188.

To prove the result, we apply the concavity method used by Brody et al. [2] which con-
sists of ﬁnding a function s that (i) is lower bounded by succ0 for all distributions and (ii)
satisﬁes a certain concavity condition. We ﬁrst relax the lower bound requirement to hold
only for six particular simple distributions (namely (1, 0, 0, 0), . . . , (0, 0, 0, 1), ( 1
2, 0)
and (0, 1
2)) instead of all distributions. This simpliﬁes the search for a suitable
stronger candidate function satisfying (i) - it remains to verify condition (ii) for the
thus found candidate function.

2, 0, 1

2, 0, 1

We ﬁrst describe the previously used concavity method in Section 3.1 and apply it

to our new upper bound function in Section 3.2.

3.1 Revisiting the concavity method

We revisit the original result of Brody et al. [2, Theorem 4.4] establishing the con-
cavity method for the cryptogenography problem. Similar concavity arguments have
appeared earlier in diﬀerent settings in information complexity and information theory
(e.g., [1]). In what follows, we mostly use the language of convex combinations of
secret distributions in allowed planes. To this aim, let ∆ := {D ∈ R2×2≥0 | (cid:107)D(cid:107)1 = 1}
denote the set of these distributions. For a given distribution D = (a, b, c, d) ∈ ∆,
there are two allowed planes through D, namely {(a(cid:48), b(cid:48), δc, δd) | a(cid:48), b(cid:48), δ ∈ R} ∩ ∆ and
{(δa, δb, c(cid:48), d(cid:48)) | c(cid:48), d(cid:48), δ ∈ R} ∩ ∆.
Lemma 3.2 (Concavity Method, [2, Theorem 4.4]). Let s : ∆ → R satisfy
(C1) s(D) ≥ λs(D0) + (1 − λ)s(D1) for all λ ∈ [0, 1] and all D0, D1 such that D =

λD0 + (1 − λ)D1 and D0, D1 lie in the same allowed plane through D.

(C2) s(D) ≥ succ0(D) for all D ∈ ∆.
Then succ(D) ≤ s(D) holds for all D ∈ ∆.

To transfer this method to the vector splitting formulation, consider an s(cid:48) : R2×2≥0 → R,
which is scalable (i.e., s(cid:48)(λD) = λs(cid:48)(D) for all λ ∈ R≥0, D ∈ R2×2≥0 ) and when restricted
to ∆ equals s. Then condition (C1) is equivalent to s(cid:48)(D) ≥ s(cid:48)(D0) + s(cid:48)(D1) for all
allowed splits (D0, D1) of D, i.e., superadditivity of s(cid:48) for all allowed splits. Condition
(C2) remains eﬀectively the same: s(cid:48)(D) ≥ succ0(D) for all D ∈ R2×2≥0 .
If these
conditions hold, we obtain succ(D) ≤ s(cid:48)(D) for all D ∈ R2×2≥0 , which is equivalent to
succ(D) ≤ s(D) for all D ∈ ∆.

As a simple application of the concavity method, we can now give the simple proof

of Proposition 2.7 stated in Section 2.5.

19

Proposition 2.7. We have succ(a, b, c, d) ≤ min{a, c} + min{b, d}.
Proof. We make use of the vector splitting formulation. Deﬁne sU B(a, b, c, d) :=
min{a, c} + min{b, d}. We have
succ0(a, b, c, d) = max{min{a, c}, min{b, d}} ≤ min{a, c} + min{b, d} = sU B(a, b, c, d),
which proves condition (C2) of Lemma 3.3. Note that f : (x, y) (cid:55)→ min{x, y} is
superadditive and hence sU B, as a sum of superadditive functions, is superadditive as
well. This proves sU B(D) ≥ sU B(D0) + sU B(D1) even for all splits D = D0 + D1 (not
only allowed splits).

The following lemma is an extension of the concavity theorem. We relax the
condition that s is lower bounded by succ0 on all distributions to now on only six
particular, very simple distributions.
Lemma 3.3 (Concavity Method, adapted). Let s : ∆ → R satisfy
(C1) s(D) ≥ λs(D0) + (1 − λ)s(D1) for all λ ∈ [0, 1] and all D0, D1 such that D =

λD0 + (1 − λ)D1 and D0, D1 lie in the same allowed plane through D.

(C2’)

• s(1/2, 0, 1/2, 0), s(0, 1/2, 0, 1/2) ≥ 1/2, and
• s(1, 0, 0, 0), s(0, 1, 0, 0), s(0, 0, 1, 0), s(0, 0, 0, 1) ≥ 0.

Then succ(D) ≤ s(D) holds for all D ∈ ∆.
Proof. To appeal to Lemma 3.2, we need to show that (C1) and (C2’) imply (C2), i.e.,
for all D = (a, b, c, d) ∈ ∆, we have s(D) ≥ succ0(D) = max{min{a, c}, min{b, d}}.
To prove this statement, we again ﬁnd it more convenient to use the vector splitting
formulation. To this aim, we extend s to s(cid:48) : R2×2≥0 → R by deﬁning s(cid:48)(D) := (cid:107)D(cid:107)1 ·
). Recall that in this view (C1) is equivalent to s(cid:48)(D) ≥ s(cid:48)(D0) + s(cid:48)(D1) for all
s( D(cid:107)D(cid:107)1
allowed splits (D0, D1) of D. Assume that min{a, c} ≥ min{b, d} (the other case is
symmetric). Consider D0 := (a, 0, c, d), D1 := (0, b, 0, 0), which is a 1-allowed split
of D. By scaling and (C2’), we have s(cid:48)(D1) = b · s(0, 1, 0, 0) ≥ 0. We split D0 into
E0 := (a, 0, c, 0) and E1 := (0, 0, 0, d), which is a 2-allowed split. Again, by scaling and
(C2’), we obtain s(cid:48)(E1) ≥ 0. Assuming that a ≥ b (since the other case is symmetric),
we ﬁnally split E0 into F0 := (b, 0, b, 0) and F1 := (a − b, 0, 0, 0), which is a 1-allowed
split that satisﬁes, by scaling and (C2’), s(cid:48)(F1) ≥ 0 and s(cid:48)(F0) = 2b · s( 1
2, 0) ≥ b.
Thus, s(D) = s(cid:48)(D) ≥ b = succ0(D).

2, 0, 1

3.2 The adapted upper bound function

Motivated by our relaxation of the condition of the concavity method, we adapt the
upper bound function of Brody et al. [2] and set
1 − f (a, b, c, d)

s(a, b, c, d)

f (a, b, c, d)

:=
:= a2 + b2 + c2 + d2 − 6(ac + bd) + 8abcd.

4

,

20

(cid:18)

(cid:19)

Note that we have changed the upper bound function by introducing an additional term
of 8abcd, which attains a value of zero on the distributions ( 1
2, 0), (1, 0, 0, 0), etc.,
thus not aﬀecting the zero-bit success probability condition of the concavity method.
Additionally, this function also satisﬁes the concavity condition, which we will prove
later.

2, 0, 1

Lemma 3.4. The thus deﬁned s satisﬁes the concavity condition (C1) of Lemma 3.3.

As an immediate consequence of the concavity method of Lemma 3.3, we obtain the

upper bound of succ( 1

4, 1

4, 1

4) ≤ 47
4, 1

128 of Theorem 3.1.

Proof of Theorem 3.1. Simple calculations show that s satisﬁes s(1, 0, 0, 0) = 0 and
s(1/2, 0, 1/2, 0) = 1/2, which by symmetry implies that s satisﬁes condition (C2’).
Since additionally condition (C1) is satisﬁed by Lemma 3.4, the concavity method
(Lemma 3.3) is applicable and yields succ( 1

4) ≤ s( 1
4, 1
4, 1

4) = 47
128.

4, 1

4, 1

4, 1

4, 1

In the remainder of this section, we will show that s does not violate concavity on
allowed planes (condition (C1)), i.e., prove Lemma 3.4. To this end, we exclusively use
the convex combination view, in which (cid:107)D0(cid:107)1 = (cid:107)D1(cid:107)1 = (cid:107)D(cid:107) = 1.

For q ≥ 0, we deﬁne fq : S → R, where S := {(a, b) | 0 ≤ a, b ≤ 1, a + b ≤ 1}, by

fq(a, b) := f

a, b,

1

1 + q

(1 − a − b),

q

1 + q

(1 − a − b)

,

i.e., for ﬁxed q ≥ 0, this function maps each pair (a, b) ∈ S to the value of f at the
unique distribution (a(cid:48), b(cid:48), c(cid:48), d(cid:48)) with a(cid:48) = a, b(cid:48) = b and d(cid:48)/c(cid:48) = q.
Lemma 3.5. If fq is convex for all q ≥ 0, then s satisﬁes the concavity condition (C1)
of Lemma 3.3.

Proof. Let D = (a, b, c, d) be an arbitrary distribution and let D0 = (a0, b0, c0, d0), D1 =
(a1, b1, c1, d1) be such that D = λD0 + (1 − λ)D1 for some λ ∈ [0, 1] and D0, D1 lie in
the same allowed plane through D. By the symmetry s(a, b, c, d) = s(c, d, a, b), we can
without loss of generality assume that D0, D1 and D are proportional on the entries of
player 2 (i.e., a 1-allowed split).
Assume ﬁrst that c = d = 0, then any D0 and D1 lie on the line (t, 1−t, 0, 0) with t ∈
R. Deﬁne the restriction of s to this line as ˜s(t) := s(t, 1− t, 0, 0) = 1
4 (1 − (1 − t)2 − t2)
and note that ˜s(t) is concave by d2 ˜s

dt2 = −1. Thus (C1) is satisﬁed for c = d = 0.
c and observe that q = d0
c0

Hence we may assume c > 0 or d > 0 and more speciﬁcally, by the symmetry
= d1
s(a, b, c, d) = s(b, a, d, c), that c > 0. We set q := d
,
since (D0, D1) is a 1-allowed split of D. Then by (cid:107)D(cid:107)1 = (cid:107)Di(cid:107)1 = 1, we have
c1
1+q (1− a− b)) and Di = (ai, bi,
1+q (1− ai− bi))
D = (a, b,
(for i ∈ {0, 1}). Recall that D = λD0 + (1 − λ)D1. The claim now follows from the

1+q (1− ai− bi),

1+q (1− a− b),

1

1

q

q

21

simple calculation

1+q (1 − a − b),

1

1 − f (a, b,
1 − fq(a0, b0)

s(D) =
+ (1 − λ)
≥ λ
= λs(D0) + (1 − λ)s(D1).

4

4

q

1+q (1 − a − b))
1 − fq(a1, b1)

1 − fq(a, b)

4

=

[by convexity of fq]

4

It remains to analyze the concavity of fq.

Lemma 3.6. For all q ≥ 0, fq is concave on S.
Proof. We use the fact that fq has continuous second partial derivatives and thus
is convex if the Hessian H := H(fq) is positive semideﬁnite. By straight-forward
calculations, we obtain

H(fq) =

4(q2+4(2b2+(3a−2)b+1)q+4)

4(2q2+(6a2+8(2b−1)a+6b2−8b+5)q+2)

4(2q2+(6a2+8(2b−1)a+6b2−8b+5)q+2)

(q+1)2

(q+1)2

4(4q2+4(2a2+(3b−2)a+1)q+1)

(q+1)2

(q+1)2



 .

To verify positive semideﬁniteness, we exploit the criterion that H(fq) is positive
semideﬁnite if its principal minors are non-negative, i.e.,

4 (4 + 4 (1 + (−2 + 3a)b + 2b2) q + q2)

(1 + q)2

≥ 0,
Det[H] ≥ 0.

and

(2)

(3)
Verifying (2) is equivalent to showing that 4 + 4p1(a, b)q + q2 ≥ 0, where p1(a, b) := 1 +
(−2+3a)b+2b2. Note that by 0 ≤ a, b ≤ 1, we have p1(a, b) ≥ 1−2b+2b2 ≥ 1−2b ≥ −1.
Thus,

4 + 4p1(a, b)q + q2 ≥ 4 − 4q + q2 = (q − 2)2 ≥ 0,

proving (2).

Regarding (3), straight-forward calculations reveal that

(cid:0)p2(a, b) + p3(a, b)q + p4(a, b)q2(cid:1) ,

Det[H] =

64q

(1 + q)4

where

p2(a, b) = 2a2 + 6b − ab − 4b2,
p3(a, b) = 12(a + b) − 23(a2 + b2) − 32ab + 24(a3(1 − b) + b3(1 − a))

+48(ab2 + a2b) − 30a2b2 − 9(a4 + b4),

p4(a, b) = 6a − 4a2 − ab + 2b2.

22

Claim 3.7. For all 0 ≤ a, b ≤ 1 with a + b ≤ 1 we have
p2(a, b), p3(a, b), p4(a, b) ≥ 0.

Proof. Note that by a, b ≤ 1, we have p2(a, b) = 2a2 + 6b− ab− 4b2 ≥ 2a2 + 6b− b− 4b =
2a2 + b ≥ 0. Since p4(a, b) = p2(b, a), it directly follows that p4(a, b) ≥ 0.
To prove the remaining statement p3(a, b) ≥ 0, we will exploit the following basic

inequalities

a4 + b4 ≤ a3(1 − b) + b3(1 − a),

(4)

(5)
which directly follow from plugging in a ≤ 1 − b and b ≤ 1 − a into the left-hand sides.
We compute

a2b2 ≤ 1
2

(ab2 + a2b − ab3 − a3b),

p3(a, b) = 12(a + b) − 23(a2 + b2) − 32ab + 24(a3(1 − b) + b3(1 − a))

+ 48(ab2 + a2b) − 30a2b2 − 9(a4 + b4),

≥ 12(a + b) − 23(a2 + b2) − 32ab + 15(a3(1 − b) + b3(1 − a))

+ 48(ab2 + a2b) − 30a2b2

≥ 12(a + b) − 23(a2 + b2) − 32ab + 15(a3 + b3)

+ 33(ab2 + a2b)

= 12(a + b) − 23(a + b)2 + 14ab + 4(a3 + b3)

+ 11(a + b)3

≥ 12(a + b) − 23(a + b)2 + 11(a + b)3,

[by (4)]

[by (5)]

Basic calculus shows that t : [0, 1] → R, s (cid:55)→ 12s − 23s2 + 11s3 has global minima
t(0) = t(1) = 0 and thus p3(a, b) ≥ t(a + b) ≥ 0.

Thus p2(a, b) + p3(a, b)q + p4(a, b)q2 ≥ 0 follows from q ≥ 0, which implies that
Det[H] ≥ 0. Hence, we have veriﬁed (2) and (3), which proves that fq is convex for all
q ≥ 0.

Proof of Lemma 3.4. Combining Lemmas 3.5 and 3.6 yields that s is concave on all
allowed planes.

4 Conclusion

Despite the fundamental understanding of the cryptogenography problem obtained by
Brody et al. [2], determining the success probability even of the 2-player case remains
an intriguing open problem. The previous best protocol with success probability 1/3,
while surprising and unexpected at ﬁrst, is natural and very symmetric (in particular
when viewed in the convex combination or vector splitting game formulation). We

23

disprove the hope that it is an optimal protocol by exhibiting less intuitive and less
symmetric protocols having success probabilities up to 0.3384. Concerning hardness
results, our upper bound of 0.3671875 shows that also the previous upper bound of 3/8
was not the ﬁnal answer. These ﬁndings add to the impression that the cryptography
problem oﬀers a more complex nature than its simple description might suggest and
that understanding the structure of good protocols is highly non-trivial.

We are optimistic that our methods support a further development of improved
protocols and bounds. (1) Trivially, investing more computational power or optimizing
the automated search might lead to ﬁnding better protocols. (2) Our improved protocols
might motivate to (manually) ﬁnd inﬁnite protocol families exploiting implicit properties
and structure of these protocols. (3) Our reformulations, e.g., as vector splitting game,
might ease further searches for better protocols and for better candidate functions for a
hardness proof.

References

[1] Mark Braverman, Ankit Garg, Denis Pankratov, and Omri Weinstein. From
In Symposium on Theory of Computing

information to exact communication.
(STOC’13), pages 151–160. ACM, 2013.

[2] Joshua Brody, Sune K. Jakobsen, Dominik Scheder, and Peter Winkler. Cryptogeno-
graphy. In Innovations in Theoretical Computer Science (ITCS’14), pages 13–22.
ACM, 2014.

[3] Sune K. Jakobsen. Information theoretical cryptogenography. In 41st International
Colloquium on Automata, Languages, and Programming (ICALP’14), volume 8572
of Lecture Notes in Computer Science, pages 676–688. Springer, 2014.

[4] Sune K. Jakobsen and Claudio Orlandi. How to bootstrap anonymous communica-
tion. In Innovations in Theoretical Computer Science (ITCS’16), pages 333–344,
2016.

[5] Jiˇr´ı Matouˇsek. On directional convexity. Discrete & Computational Geometry,

25:389–403, 2001.

24

