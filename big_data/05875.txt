Approximated Robust Principal Component Analysis for

Improved General Scene Background Subtraction

Salehe Erfanian Ebadi, Student Member, IEEE, Valia Guerra Ones, and Ebroul Izquierdo, Senior Member, IEEE

1

6
1
0
2

 
r
a

 

M
8
1

 
 
]

V
C
.
s
c
[
 
 

1
v
5
7
8
5
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—The research reported in this paper addresses the fun-
damental task of separation of locally moving or deforming image
areas from a static or globally moving background. It builds on the
latest developments in the ﬁeld of robust principal component analysis,
speciﬁcally, the recently reported practical solutions for the long-standing
problem of recovering the low-rank and sparse parts of a large matrix
made up of the sum of these two components. This article addresses
issues including: embedding global motion parameters
a few critical
in the matrix decomposition model,
i.e., estimation of global motion
parameters simultaneously with the foreground/background separation
task; considering matrix block-sparsity rather than generic matrix
sparsity as natural feature in video processing applications; attenuating
background ghosting effects when foreground is subtracted; and more
critically providing an extremely efﬁcient algorithm to solve the low-
rank/sparse matrix decomposition task. The ﬁrst aspect is important for
background/foreground separation in generic video sequences where the
background usually obeys global displacements originated by the camera
motion in the capturing process. The second aspect exploits the fact that
in video processing applications the sparse matrix has a very particular
structure, where the non-zero matrix entries are not randomly distributed
but they build small blocks within the sparse matrix. The next feature of
the proposed approach addresses removal of ghosting effects originated
from foreground silhouettes and the lack of information in the occluded
background regions of the image. Finally, the proposed model also tackles
algorithmic complexity by introducing an extremely efﬁcient “SVD-free”
technique that can be applied in most background/foreground separation
tasks for conventional video processing.

Index Terms—Background subtraction, robust principal component

analysis, low-rank, sparse, foreground detection, moving camera.

I. INTRODUCTION

T HE SEPARATION of locally moving or deforming image

areas from a static or globally moving background is a basic
video processing task with manifold applications including automated
anomaly detection in video surveillance, face alignment for recogni-
tion and authentication, human motion analysis, action recognition,
object tracking, video summarization retrieval and editing, and object
based video coding. A plethora of algorithms and techniques to
achieve this task has been developed since the early days of digital
image processing with varied degrees of performance and complexity.
The research presented in this paper also addresses this fundamental
task by leveraging and building on recent developments in the ﬁeld
of Robust Principal Component Analysis (RPCA). Speciﬁcally, the
work reported here has been inspired by the critical breakthrough
accomplished by Cand`es et al. [1], where the authors provided
a practical and feasible solution for the long-standing problem of
recovering the low-rank and sparse parts of a large matrix made
up of the sum of these two components. In other words, assuming
that a given matrix A consists of the sum of a low-rank and a
sparse component, there exists a feasible solution, by which the
exact recovery of the original matrix from its decomposed parts
becomes possible [1]. In the particular context of video processing,
the 2-dimensional matrix A stores pixel
information of a video
sequence or a set of images by concatenating each frame or image
as columns in A. Then, the background part of the video sequence is
modeled by the low-rank matrix, while the locally deforming parts
constitute the sparse matrix component. Cand`es et al. [1] showed
that under certain assumptions, the low-rank/sparse decomposition

problem can be solved by means of a convex optimization. In that
seminal paper the authors referred to their proposed approach as
Principal Component Pursuit (PCP).

PCP has led to impressive results in background modeling, fore-
ground detection, removal of shadows and specularities in images,
and face alignment for recognition. More importantly,
it shows
a high potential for improving the performance of RPCA based
solutions, motivating the work presented in this paper. An approx-
imated RPCA method for general scene background subtraction is
proposed here, that endeavors to overcome some of the limitations
of related algorithms and techniques reported over the last few years.
In particular, this approach addresses a number of critical issues of
RPCA including the following four main aspects: embedding global
motion parameters in the model, i.e., estimation of global motion pa-
rameters simultaneously with the foreground/background separation
task; considering matrix block sparsity rather than generic matrix
sparsity as natural feature in video processing applications; attenuat-
ing background ghosting effects when foreground is subtracted; and
more critically providing an extremely efﬁcient algorithm to solve the
low-rank/sparse decomposition task. The ﬁrst aspect is very important
for background/foreground separation in general video sequences
where the background usually obeys a global motion originated by
the camera motion in the capturing process. Here the proposed model
aims at also estimating the global motion parameters while perform-
ing the targeted background/foreground separation task. The second
aspect exploits the fact that in video processing applications the sparse
matrix has a very particular structure; i.e., the non-zero matrix entries
are not randomly distributed but they build small blocks within the
sparse matrix. The next feature of the proposed approach addresses
removal of ghosting effects originated by foreground silhouettes and
the lack of information in the occluded regions of the background in
the image. Another important aspect relates to the fact that RPCA
approaches are computationally expensive involving many Singular
Value Decompositions (SVD) of large matrices. The proposed model
also addresses this issue by introducing an extremely efﬁcient “SVD-
free” technique that can be applied in most background/foreground
separation tasks for conventional video processing.

The rest of this paper is organized as follows. In Section I-A
a brief survey of related works as well as their limitations is
provided. The main contributions and fundamentals of the research
reported here are outlined in Section I-B. Section II-A introduces
notation and deﬁnitions used in this paper. The RPCA framework
is presented in Section II-B. Next, a thorough discussion on the
proposed method is presented in section III. More speciﬁcally, a
technique called τ-Decomposition is described in III-A, and III-B dis-
cusses the proposed foreground detection algorithm assuming block
sparsity. Sections III-C and III-D introduce a strategy for removal
of unwanted absorption of foreground pixels into background, i.e.,
ghost-attenuation, and a SVD-free algorithm for fast decomposition
respectively. At the end selected results from a comprehensive eval-
uation of the proposed techniques is presented in Section IV which
are used to validate the introduced approaches. The paper concludes
with few remarks and possibilities for future work.

The preliminary work of this article has appeared in [2].

A. Review of Related Work

During the past decades many methods have been developed to ad-
dress and solve the problems in background modeling and foreground
detection. Several surveys are also dedicated to this topic [3], [4].
Here in a short survey a few noteworthy methods are acknowledged.
A well-studied approach is optical ﬂow estimation and object-based
motion segmentation, which was addressed in an early work by [5].
Another popular approach is the Markov Random Fields (MRF) based
methods in which the background is modeled and then subtracted
using region-level and motion-based information as in [6] and [7].
Nevertheless, these methods are heavily dependent on the motion
estimation algorithm. The segmentation may become unsatisfactory
when the foreground objects undergo large displacement. Moreover,
if part of the object contour is obscured, the detection result around
this part may not be very accurate. A work based on classiﬁcation
algorithms [8] used a self-organizing neural network for learning
background model motion patterns in videos from stationary cameras
in surveillance applications. The work by Wang et al. [9] proposed
an iterative method to achieve layered motion segmentation, with
each layer describing a region’s motion, intensity, shape, and opacity.
A method named ViBe [10] provided a non-parametric background
segmentation with feedback and dynamic controllers that achieved
higher processing speeds compared to previous works. Efforts have
been made to achieve real-time background subtraction as in [11]
where a GPU implementation with SVMs is reported. The problem of
bootstrapping in heavily cluttered videos has been addressed by a pro-
gressive model in [12] based on an incremental, patch-based method
for background initialization. Another popular approach the Bayesian
formalism for statistical modeling of background has been studied
extensively [13]. A recent work [14] built on the success of the robust
PCA with introducing a Bayesian framework for classiﬁcation of
foreground and background pixels. However, Bayesian approaches
do not fully solve the problem of absorption of a still foreground
region into the background. Independent Component Analysis (ICA)
of serialized images from a training sequence, is described in [15]
in which the resulting demixing vector is computed and compared
to that of a new image in order to separate the foreground from a
reference background image. In [16] a model for separating images
into texture and piecewise smooth parts, exploiting variational and
sparsity mechanisms was proposed.

In 1999, Oliver et al. [17] proposed to model the background by
Principal Component Analysis (PCA). They developed the theory of
Robust Subspace Learning (RSL) for making linear learning methods
robust to outliers which are common in realistic training sets. An issue
is that PCA provides a robust model of the probability distribution
function, but not of the moving objects since they do not have a
signiﬁcant contribution to the model. The limitations arising from
this problem are ﬁrstly the size of the foreground object must be
small and do not appear in the same location for a long period of
time; and secondly the outliers of the foreground objects may be
absorbed into the background mode without a mechanism of robust
analysis. Although there are several PCA improvements [18] that
addressed the limitations of classical PCA with respect to outlier and
noise – yielding the ﬁeld of robust PCA – these methods may not
achieve sufﬁcient performances for applications such as surveillance
or general video processing that require fast and very accurate results
where the input data might contain corruptions. Recent advances in
rank minimization [1], [19] have shown that it is indeed possible to
efﬁciently and exactly recover low-rank matrices despite signiﬁcant
corruption, using tools from convex programming. Thus paving the
way for the development of truly robust PCA based techniques.

In a related context, Zhou et al. [20] proposed a method called

2

DECOLOR in which they segmented moving objects from an image
sequence. They contributed to the ﬁeld of RPCA by formulating the
problem as outlier detection and making use of low-rank modeling
to deal with complex and moving background. They incorporated a
Markov Random Fields framework to obtain a prior knowledge of
the spatial distribution of the outliers (foreground objects). Compared
with PCP, DECOLOR uses a non-convex penalty and MRFs for the
optimization, which is more greedy to detect outlier regions that are
relatively dense and contiguous. However, since DECOLOR mini-
mizes a non-convex energy via alternating optimization, it converges
to a local optimum with results depending on initialization of the
foreground support, while PCP always minimizes its energy globally.
Recently Liu et al. [21] proposed a structured sparsity based method
in which a motion-saliency measurement for norm minimization has
been used, to extend the Augmented Lagrange Multiplier method
for solving the RPCA. This method obtains promising results in
foreground detection for scaled-down low resolution video sequences
captured by static cameras in speciﬁc environments.

Another important related work, this time addressing the complex-
ity issue, was reported by Zhou and Tao [22]. The proposed technique
aims at providing an approximate solution of the low-rank/sparse
decomposition problem in a noisy case.

B. Contributions of This Paper

This paper addresses some of the issues of previous research in the
ﬁeld of RPCA, to better adapt this algorithm to a problem of generic
scene background subtraction. The main contributions of this work
can be summarized as follows.

1) A novel algorithm is proposed which is capable of addressing
the background separation problem for globally moving back-
ground. Our approximated RPCA optimization problem called
τ-Decomposition includes parameters modeling global motion
of background regions and also entails a Gaussian additive noise
part. This model’s robustness to camera movement and dynamic
backgrounds has been tested and demonstrated in this paper.

2) Enforcing structured (block) sparsity via a (cid:96)2,1-norm minimiza-
tion based on the fact that in real-world scenes the non-zero
elements of the sparse component generally appear in blocks.
The method adds robustness to the model making it less prone
to illumination changes, variations of object size, and noise while
achieving enhances in overall segmentation performance.

3) An efﬁcient initialization method for the low-rank and sparse
matrices is proposed. It improves the separation of the moving
objects from the background by attenuating the effect of locally
moving image areas that usually leak through and remain within
the background. This problem is known as ghosting effect.
The strategy involves the exploitation of statistical leverages for
measuring the contribution of each column to the non-uniformity
of the structure of the sparse matrix. In other words, a pseudo-
motion saliency map generated from the video frames is used to
improve the classiﬁcation of foreground and background parts
during the iterative process.

4) A SVD-free approximated RPCA algorithm is proposed for
solving the optimization problem. This strategy not only delivers
similarly accurate results as its counterpart using SVD, but is
much faster, since the most expensive computation in RPCA-
based methods is the SVD calculation. In this model the low-
rank matrix is assumed to be of rank 1. That is the columns
of the low-rank part are assumed to be linearly dependent up
to a global transformation, naturally modeling what happens
in real world sequences in which background undergoes global
transformations only. Here the objective is the reconstruction

of the original video sequence calculating the “global” frame
that describes the globally moving part (background), the n
frames (or columns of a sparse matrix S) containing only the
locally deforming or moving objects, and the parameter vector
τ describing the global motion of the scene usually reﬂecting
camera displacements or zooming.

A. Notation

II. FUNDAMENTALS

Throughout this document the following notation is used. Consider
a video sequence Ij, j = 1, . . . , n of n frames of size w × h. For
the sake of consistency the same notation Ij is used to represent
both the video frame and the matrix containing it. Let Aj ∈ Rm
(m = w × h) be the m-vector whose entries are the elements of
matrix Ij. Aj is produced by concatenating all elements of Ij in
row-order in a single column or vector containing m elements. Then
the matrix A = [A1, . . . , An] ∈ Rm×n contains n frames of a video
sequence with m (cid:29) n. Then, aij refers to a single element (pixel)
i in the frame j of matrix A. Here i = 1, . . . , m and j = 1, . . . , n.
Deﬁne mat(·) a mapping operation from the m-dimensional space
into the w × h matrix as Rm −→ Rw×h, i.e., mat(Aj) is equal to
video frame Ij. The following matrix norms are utilized in this paper:

(cid:113)(cid:80)

i,j A2
ij

i,j |Aij|

• Frobenius Norm: (cid:107)A(cid:107)F =

• (cid:96)1-norm: (cid:107)A(cid:107)1 =(cid:80)
j((cid:80)
(cid:107)A(cid:107)α,β = ((cid:80)
• (cid:96)2,1-norm: (cid:107)A(cid:107)2,1 = (cid:80)
• Nuclear norm: (cid:107)A(cid:107)∗ = (cid:80)

largest singular value of A)

• Adapted dissymmetric norm ((cid:96)α,β-norm):

1
β

i Aα
ij)

β
α )
j (cid:107)Aj(cid:107)2 (which is the (cid:96)1-norm of the
vector formed by taking the (cid:96)2-norms of the columns of the
underlying matrix)

i σi(A) (where σi(A) is the i-th

In this paper for practical reasons, we assume that the matrix A
is decomposable; i.e., the matrix A is close to a matrix that can be
written as the sum of a low-rank matrix L with singular vectors that
are not spiky and a sparse matrix S with a uniform and random
pattern of sparsity.

B. RPCA Framework

The work on RPCA-PCP developed in [1], and later used by [23],
exploits convex optimization to address the robust PCA problem.
Under some assumptions, this approach called Principal Component
Pursuit (PCP) recovers the low-rank and the sparse matrices in
synthetic and real data. Given a large data matrix A the decomposition
is deﬁned as A = L + S with:

min(cid:107)A − L(cid:107) subject to rank(L) ≤ k

(1)

where L is low-rank and S is sparse. The most valid formulation in
(1) uses the (cid:96)0-norm to minimize the energy function:

arg min Rank(L) + λ(cid:107)S(cid:107)0

subject to A = L + S

(2)

Here λ is an arbitrary balancing parameter. The above problem is
NP-hard and thus unfeasible for practical applications. To provide a
feasible solution, the authors in [1] proposed to minimize a surrogate
, and the (cid:96)1 and nuclear norms instead.
model using λ =
This leads to the convex problem:
arg min(cid:107)L(cid:107)∗ + λ(cid:107)S(cid:107)1

subject to A = L + S

1√

max(m,n)

(3)

Although this formulation leads to a computationally feasible solu-
tion, the complexity is still high involving the calculation of many
SVDs for a very large matrix. Existing RPCA algorithms often

3

concentrate on ﬁnding exact and meaningful decompositions. How-
ever, their complexity is often uncontrollable due to their automatic
and iterative solving procedure, which makes them unsuitable for
computer vision applications. In order to reduce complexity of the
algorithm,
the approximated RPCA (GoDec) was proposed [22].
This simpliﬁed version aims at decomposing a particular matrix into
its low-rank and sparse components in the presence of noise. The
algorithm estimates the low-rank part L and the sparse part S of a
large matrix containing an additive noise part G as:

A = L + S + G

(4)
GoDec alternatively assigns the low-rank approximation of A − S
to L and the sparse approximation of A − L to S. The authors also
proved that the objective value below converges to a local minimum,
while L and S linearly converge to local optimums.

F

such that

(cid:107)A − L − S(cid:107)2

rank(L) ≤ k, card(S) ≤ κ (5)

min
L,S
The model A = L + S + G, can handle approximated de-
composition in more realistic situations when the exact and unique
decomposition does not exist. In the optimization process the rank
of L and cardinality of S are ﬁxed. This imposes limitations to
decomposition of unconstrained real-world video sequences, because
usually the cardinality of S varies and thus must remain ﬂexible.
Moreover, the hard-thresholding towards S requires sorting all its
entries’ magnitudes and thus is computationally expensive. Later a
similar method was proposed in [24] by introducing a Lagrange
formulation as below:
(cid:107)A − L − S(cid:107)2

rank(L) ≤ k

F + λ(cid:107)S(cid:107)1

such that

(6)

min
L,S

The tuning Lagrangian parameter λ, which acts as a soft-threshold
value is much more convenient
than determining the cardinality
of S, because the resulting decomposition error is more robust to
the change of the Lagrangian parameter. To solve (6) the authors
decompose the sparse part as the sum of several low-rank matrices,
each one corresponding to objects in the scene sharing the same
motion trajectory. However this method does not handle cases with
moving cameras (in which parts of the scene move uniformly with
the camera motion) or cases where part of the background undergoes
a global motion trajectory.

III. MATRIX DECOMPOSITION FOR VIDEO ANALYSIS

A. τ-Decomposition, An Approximated RPCA for Handling Non-
Static Backgrounds

[23], and

In this section building on [1],

[22], an approxi-
mated RPCA model for handling non-static backgrounds is proposed.
First, a transformation τ modeling potential global motion that the
foreground region undergoes,
is introduced into the optimization
task. Basically, it is assumed that the columns of the matrix L are
linearly dependent up to a certain parametric transformation. Given
a data matrix A whose columns are the frames of a video sequence,
captured by a moving camera, the decomposition of matrix A is in
the following form:

A ◦ τ = L + S + G

(7)

where L is a low-rank matrix, S is a sparse matrix, and G is a matrix
that contains the incomplete information and corruption by outliers
in the original video sequence e.g. Gaussian noise. Aj ◦ τj denotes
the j-th frame after transformation parameterized by the vector τj ∈
Rρ where ρ is the number of parameters fully describing the global
motion model. Therefore ρ = 4 corresponds to similarity, ρ = 6 to
afﬁne, and ρ = 8 to projective transformation. The i-th geometric

transformation is comprised of a parameter vector τi, i = 1, . . . , n
where different spatial transformations can be considered. We use
the 2D parametric transforms to model the translation, rotation, and
planar deformation of the background. In particular, we also use an
afﬁne transformation where each parameter τi is a vector with six
coefﬁcients (ρ = 6). Finally, we use the multi-resolution incremental
reﬁnement described in [25], to estimate these motion parameters.

Peng et al. [23] proposed a mathematical formulation for equation
(7) that guarantees a unique solution under some conditions. They
presented an algorithm for calculating the matrices L, S, and G and
the motion model parameters τ1, . . . , τn. The main limitation of this
algorithm is its computation cost. Here, a computationally-cheaper
algorithm is proposed based on an approximated RPCA formulation.
Given the data matrix A and the soft-thresholding parameter λ the
following convex optimization function recovers a low-rank matrix
L, a sparse matrix S, and the motion parameter vector τ such that
A ◦ τ ≈ L + S:

(cid:107)A ◦ τ − L − S(cid:107)F + λ(cid:107)S(cid:107)1

(8)

arg min
rank(L)≤k

L,S,τ

The ﬁrst summand guarantees the approximations of the decom-
position (minimizing the residual) and the second favors the sparse
matrix solution S with many zero elements (i.e. sparse enough).
The parameter λ controls the contribution of each summand to the
function to be minimized. λ needs to be manually set depending
on the problem to be solved and increases the model’s ﬂexibility
and generalizability to different scenarios. The model is tested using
variations of this parameter in our experiments with the Receiver
Operating Characteristic (ROC) performance evaluation. We use
the following alternating strategy minimizing the function for three
parameters L, S, and τ one at a time with t = 1, 2, . . . , p until
the solution reaches convergence. Observe that the solution of this
strategy leads to solving (8) by minimizing three reduced problems,
each being minimized independently from one another. This kind of
iterative linearization has a long history in gradient algorithms. Al-
gorithm 1 below describes the iterative process for the minimization
process of the following three sub-problems.

τ t = arg min

τ

Lt = arg min
rank(L)≤k

(cid:107)A ◦ τ − Lt−1 − St−1(cid:107)2
(cid:107)A ◦ τ t − L − St−1(cid:107)2

F

F

St = arg min

S

(cid:107)A ◦ τ t − Lt − S(cid:107)2

F + λ(cid:107)S(cid:107)1

(9)

(10)

(11)

i

i −St−1

Solving the ﬁrst optimization problem – equation (9).
In the
ﬁrst optimization problem the parameters τi, i = 1, . . . , n transform
each of the columns of A individually. Therefore n minimization
problems must be solved. The i-th problem consists of inferring the
transformation parameters that transform the i-th frame Ai to the
image corresponding to the matrix Lt−1
. This problem can be
written as a weighted least squares minimization where the solutions
τi have a closed-form. It is well known that the solution of minimum
norm of a least squares problem is unique and has a simple closed-
form solution in terms of the Singular Value Decomposition of the
system matrix. However, the obtained solution is highly unstable with
respect to small changes in the data because the rows of the system
matrix corresponding to nearby pixels in adjacent frames tend to
be quite similar and the system matrix is generally ill-conditioned.
There are different strategies for regularizing the solution of an ill-
conditioned linear system. Here, the incremental reﬁnement described
in [23] is used, where a local linearization is applied on Ai ◦ τi
as function of the parameters. The main idea is using an initial
approximation for the parameters τi, i = 1, . . . , n that is iteratively

4

improved applying a reﬁnement process and assuming a linear local
behavior of Ai ◦ τi around the initial approximation. For t = 1 the
initial approximation of the parameters is obtained using the robust
multiresolution method for prealignment described in [26].
Solving the second optimization problem – equation (10). Next
step is to calculate the rank-k matrix that is the nearest estimate to
the matrix A◦τ t−St−1 with respect to Lt under the current estimate
of the parameters A◦τ t and St−1. The singular value decomposition
(SVD) gives a closed-form solution to this problem:

k(cid:88)

Lt =

σiUiV T
i

(12)

i=1

where the coefﬁcients σi and the vectors Ui and Vi (i = 1, . . . , n)
are the singular values, and the left and right singular vectors of the
matrix A ◦ τ t − St−1, respectively.
Solving the third optimization problem – equation (11). Finally
the matrix St is updated using the parameter λ acting as a tuning
parameter in the matrix A ◦ τ t − Lt; i.e., the elements of the matrix
A ◦ τ t − Lt ≤ λ are considered to be zero.

Algorithm 1 Approximated RPCA with moving camera
1: Input: A, k, λ, tol, maxIter
2: Output: S, L, τ
3: Standard initialization: τ 0 = 0, L0 = A, S0 = 0
4: while (cid:107)A ◦ τ t − Lt − St(cid:107)2

F /(cid:107)A(cid:107)2

F > tol or

t < maxIter do

1) Form the matrix A ◦ τ calculating the parameters τ t

2) Calculate Lt = (cid:80)k

i that infer the
mapping that transforms the column vector Ai to the i-th column vector
of the matrix Lt−1 + St−1.
svd(A ◦ τ t − St−1) =
3) Calculate St = Pλ(A ◦ τ t − Lt) where Pλ(x) =

i=1 σiUiV T
i

U ΣV T .
sign(x) max(|x| − λ, 0).

where

5: end while

Convergence of the iterative process. The sequence of values of the
F + λ(cid:107)St(cid:107)1, t = 1, 2, . . . , p
objective function (cid:107)A ◦ τ t − Lt − St(cid:107)2
produced by the iterative process is monotonically decreasing for
a ﬁxed λ converging to a local minimum. The proof is similar to
the convergence arguments used by theorem 1 in [22]. The main
difference is the addition of a third optimization problem (which
involves the parameters of the motion model) that also has a closed-
form solution and the values of the sequence keep decreasing in each
step.

B. Foreground Detection with (cid:96)2,1-Norm Block-Sparsity

The formulation of the background modeling/foreground detection
problem using the optimization function (8), favors solutions where
the matrix S is sufﬁciently sparse. But, this formulation does not
take into account the structure of sparsity in S, and it does not yield
good results when the sparse pattern involves for example clutters of
non-zero entries representing foreground objects. Strictly speaking,
in real-world video sequences the foreground pixels do not appear as
in a sparse matrix at random and scattered; but rather, they appear in
regions corresponding to foreground objects in the scene, in groups
of pixels that have a structure.

In this section, we propose a mathematical formulation of the
problem that favors solutions where the non-zero elements of the
matrix S are structured; in other words the non-zero elements appear
in non-overlapping blocks (with no pre-speciﬁed sizes), where each
block can represent the natural shape of a foreground object. In our
algorithm the background sequence is again modeled by a low-rank
subspace that can gradually change over time; while the moving

is noteworthy that methods that

foreground objects constitute the correlated and contiguous sparse
outliers. It
involve a structured
sparsity solution such as [21], usually impose a block structure by
pre-deﬁning a block size for a group of pixels and then perform
the norm minimization using a motion-saliency check, that would
yield a block structured foreground detection. As a result, the output
is always dependent on the tweaked pre-deﬁned block size and
as the objects in the video sequence change sizes the foreground
support detection becomes more and more unreliable. Here, unlike
other block/group/structured sparsity methods our formulation in-
volves solving a (cid:96)2,1-norm minimization for the matrix mat(Sj) that
corresponds to the sparse part for video frame Ij, and the structured
sparsity is guaranteed by the norm itself.

In other algorithms exploiting the block-sparsity [27], [28] the
matrix S contains mostly zero columns, with several non-zero ones
corresponding to foreground elements. In image processing appli-
cations this assumption cannot be made (since we assume that the
columns of the matrix S correspond to foreground objects in the
frames of a video sequence). Assuming that most columns are zero
contradicts the deﬁnition of sparse matrix. When a whole column in
the sparse matrix is zero it means the information in that column is
assigned to the low-rank subspace. Moreover, if the video sequence
contains foreground objects in all the frames then this assumption
does not help. Instead, it would make sense if the block-sparsity
was imposed on the pixels of each video frame rather than a
whole column (whole frame) in the matrix S. Hence, we solve the
minimization problem for block-sparse matrices mat(Sj). In order
to rule out ambiguity, in our model the columns of the low-rank
matrix L corresponding to the sparse columns are ensured to be zeros.
Therefore,
this algorithm achieves more robustness than RPCA-
PCP [1] and RPCA-LBD [27], [28] with dynamic backgrounds,
varying foreground object sizes, and illumination changes.

Given a data matrix A whose columns are the frames of a video
sequence captured by a moving camera and a soft-thresholding
parameter λ, we minimize the following optimization problem that
recovers the background and the structured block foreground of the
sequence with the matrices L and S, respectively.

Other models that involve the (cid:96)2,1-norm minimization of the matrix
S have been explored in the literature [27]. Here the (cid:96)2,1-norm of
the matrix created by the columns of the matrix S is minimized,
so that one can use the additional information derived from the
spatial positions of the non-zero elements and introduce zero blocks
to strategically enforce sparsity.

In the proposed formulation, the ﬁrst summand guarantees the
approximation of the decomposition (minimizing the residual) and
the second favors solutions where the zero elements of S appear in
blocks corresponding to some columns of mat(Sj). The problem
(13) is solved by alternatively solving three optimization problems
below for t = 1, 2, . . . , p until convergence. Algorithm 2 describes
the iterative process for the following minimization process.

τ t = arg min

τ

Lt = arg min
rank(L)≤k

(cid:107)A ◦ τ − Lt−1 − St−1(cid:107)2
(cid:107)A ◦ τ t − L − St−1(cid:107)2

F

F

(14)

(15)

St = arg min

S

(cid:107)A ◦ τ t − Lt − S(cid:107)2

F + λ

(cid:107)mat(Sj)(cid:107)2,1

(16)

The ﬁrst and second optimization problems are similar to the
optimization problems solved in the previous section. The solution

n(cid:88)

j=1

(cid:107)A ◦ τ − L − S(cid:107)2

F + λ

arg min
rank(L)≤k

S,τ

(cid:107)mat(Sj)(cid:107)2,1

(13)

U ΣV T .

3) Let H = A ◦ τ t − Lt

for j = 1, . . . , n do

n(cid:88)

j=1

5

of the third problem is obtained applying the following lemma to the
matrix H = A ◦ τ t − Lt:
Lemma 1. The i-th column of the matrix mat(Ej) that solves the
minimization problem

(cid:107)H − S(cid:107)2

F + λ

(cid:107)mat(Sj)(cid:107)2,1

E = arg min

S

is given by:

n(cid:88)

j=1

(cid:18)

0, 1 −

(mat (Ej))i = (mat (Hj))i max

j = 1, . . . , n and i = 1, . . . , q

Proof. The function to be minimized can be written as:

n(cid:88)
n(cid:88)

j=1

j=1

min

S

= min

S

(cid:107)mat(Hj) − mat(Sj)(cid:107)2

F + λ

(cid:0)(cid:107)mat(Hj) − mat(Sj)(cid:107)2

(cid:19)

(cid:1)

λ

(cid:107)(mat (Hj))i(cid:107)2
n(cid:88)

(cid:107)mat(Sj)(cid:107)2,1

j=1

F + λ(cid:107)mat(Sj)(cid:107)2,1

Applying the lemma 1 in [23] in each summand of this expression,
we have the closed-from for the i-th column of the matrix mat(Ej)
(cid:4)
given by the lemma.

Lemma 1 states that the solution matrix St for the third opti-
mization problem has non-overlapping zero blocks in the positions
corresponding to the columns of the matrices mat(Sj), j = 1, . . . , n
with (cid:96)2-norm less than λ.

Algorithm 2 Block-sparse extension
1: Input: A, k, λ, tol, maxIter
2: Output: S, L, τ
3: Standard initialization: τ 0 = 0, L0 = A, S0 = 0
4: while (cid:107)A ◦ τ t − Lt − St(cid:107)2

F /(cid:107)A(cid:107)2

F > tol or

1) Form the matrix A ◦ τ calculating the parameters τ t

i that infer the
mapping that transforms the column vector Ai to the i-th column vector
of the matrix Lt−1 + St−1.
svd(A ◦ τ t − St−1) =

2) Calculate Lt = (cid:80)k

where

i=1 σiUiV T
i

t < maxIter do

for l = 1, . . . , q do
if (cid:107) (mat(Hj ))i (cid:107)2 < λ then
(mat(Sj ))i := 0
else
(mat(Sj ))i := 1 − λ(mat(Hj ))i
(cid:107)(mat(Hj ))i
(cid:107)2
end if
end for

5:
6:
7:
8:
9:
10:
11:
12:
end for
13:
14: end while

C. Ghost-Removal: Statistical Leverage Scores for Nearest Estima-
tion of the Low-Rank and the Sparse Components

The optimization problems described in Sections III-A and III-B
are solved by iterative procedures that need to be initialized using
starting values of the matrices L, S and τ. Algorithms 1 and 2 start
the iterative process with a standard (na¨ıve) initialization of L0 = A,
S0 = 0, and τ 0 = 0. However, a better separation of the static
part and moving objects of the frames is obtained when the matrices
are strategically initialized. In this section, a novel strategy for the
initialization in algorithms 1 and 2 is proposed.

The rank-k matrix that is the nearest to the matrix A is a low-rank
matrix that gives a good ﬁrst approximation for the static part of the

D. Special Case: SVD-Free Algorithm for Fast Decomposition

6

In this section, a particular case is considered, where the back-
ground does not change throughout the sequence. It means, the back-
ground can be described by a rank-1 matrix. This is particularly useful
for applications such as video coding, or surveillance background
subtraction in indoor environments, where the background does not
change for prolonged periods or a duration of time. Henceforth, the
optimization problem to be solved using the approximated RPCA is:
(19)

(cid:107)A ◦ τ − L − S(cid:107)F

arg min

S,L,τ

rank(L)=1
card(S)≤κ

Note that the soft-thresholding parameter λ is left out, and instead
the cardinality (number of non-zero elements) card(S) is being ﬁxed.
The cardinality κ acts as a hard-thresholding parameter that controls
the quality of the reconstruction of A using the matrices L and S.
The rank-1 restriction for L imposed in the optimization problem
yields to solutions where the columns of the matrix L can be written
as Lj ← αL1, j = 1, . . . , n, where L1 is the ﬁrst column of L and
α is a scalar.

Based on this fact, we assume a particular rank-1 matrix L where
all the column vectors are equal; i.e. L = l1T where l is a vector
of size m and 1T = (1, . . . , 1). Note that any matrix in the form
l1T is a rank-1 matrix but not all rank-1 matrices can be written by
repeating the same vector in all the columns.

The main advantage of this special rank-1 matrix is that we
prove the vector l can be calculated without computing a SVD;
therefore, this algorithm converges much faster as a result, since the
most expensive computation in the described algorithms is in SVD
calculation step. The optimization model is as below:

(cid:107)A ◦ τ − l1T − S(cid:107)F

(20)

arg min
card(S)≤κ

S,l,τ

Solving the optimization problem. Applying the alternating strategy
three optimization problems must be solved for t = 1, 2, . . . , p until
convergence.

(cid:107)A ◦ τ − lt−11T − St−1(cid:107)2
(cid:107)A ◦ τ t − l1T − St−1(cid:107)2
(cid:107)A ◦ τ t − lt1T − S(cid:107)2

F

F

F

lt = arg min

l

St = arg min
card(S)≤κ

(21)

(22)

(23)

Algorithm 3 describes the iterative process for the SVD-free
algorithm. The ﬁrst optimization problem is solved as described in
section III-A. The matrix St that solves the third optimization prob-
lem is the matrix with zero elements in the positions corresponding
to the ﬁrst κ smallest elements of the matrix |A ◦ τ t − lt1T|.
Solving the second optimization problem – equation (22). Let E
be the matrix A◦τ t−St−1; the following lemma gives a closed-form
solution for the solution vector l of the second optimization problem.
Lemma 2. The solution l of the optimization problem arg minl (cid:107)E−
l1T(cid:107)2

F is given by:

sequence but some parts of the moving objects remain in this rank-
k matrix (for instance when they move slowly, remain inactive for
some period of time, or obscure part of the background during the
training period). With current RPCA-based optimizations these parts
that are called “ghost” (ﬁgure 1 (b) and (d)) usually persist during the
iterative process and are not removed completely. In order to reduce
the inﬂuence of the ghosting effect during the iterative process one
needs to have a prior knowledge of distribution of outliers (which
usually appear in clusters of pixels). Hence in this work it is proposed
to construct a matrix S0 whose columns contain only the more salient
part of the matrices mat(Aj − L0
j ), j = 1, . . . , n where L0 is the
rank-k matrix approximation of the matrix A. In other words, as
each matrix mat(Aj − L0
j ) contains a sketch of the moving objects
in the j-th frame, the idea is forming the initial approximations
S0 using the columns of the mat(Aj − L0
j ) that contribute to the
the non-uniformity of the structure of the matrix. Here the leverage
scores are used to measure the importance of the columns of the
matrix mat(Aj − L0
j ) (the leverage scores can be regarded as a
pseudo-motion saliency map). Let the i-th column of the matrix to
be a linear combination of the orthonormal basis given by the left
k ,
k=1 σkUkV i
i = 1, . . . , h where Uk is the k-th left singular vector, V i
k is the
i-th coordinate of the k-th right singular vector, and rank is the
j ). As the matrices mat(Aj − L0
rank of matrix mat(Aj − L0
j ) are
approximations of the frames containing the moving objects, they can
be considered as approximations to low-rank matrices. It implies that
one can assume:

singular vectors of the matrix(cid:0)mat(Aj − L0
j )(cid:1)

=(cid:80)rank

i

≈ p(cid:88)

k=1

(cid:0)mat(Aj − L0
j )(cid:1)
k and(cid:80)p

k=1 V i2

i

(cid:80)p

k=1 V i1

Note that any two columns i1 and i2 differ only in the terms
k . Then these terms can be used to measure
the importance or contribution of each column to the matrix. The
normalized statistical leverage scores [29] of the i-th column of the
matrix mat(Aj − L0

j ) is deﬁned as:

σkUkV i
k

,

p (cid:28) rank

(17)

p(cid:88)

k=1

πi =

1
p

the image. The vector πi is a probability vector, i.e. (cid:80)h

where h is the number of columns of each frame of the sequence.
The sub-index j is removed to help understanding of this expression.
Leverages have been used historically for outlier detection in statis-
tical regression but recently they have been used to give a column
(or row) order of the amount of motion saliency in a speciﬁc part of
i=1 πi = 1.
Therefore, the columns of each matrix mat(Aj − L0
j ) with leverages
greater than 1/h are the more important columns. So the columns of
the initial approximation S0 contain only the more important columns
of the matrices mat(Aj − L0
j ), j = 1, . . . , n. Consequently, the
less salient (more static) parts of the image are not included in the
initialization of the sparse part, making the iterative process less prone
to converge to the wrong local optimum, yielding more stable results,
and increasing the segmentation accuracy.

(cid:0)mat(S0
j )(cid:1)

=

i

0

(cid:40)(cid:0)mat(Aj − L0
j )(cid:1)

i

it

Initial values for the parameter vector τ. To initialize the motion
parameter vector,
is a feasible practice to apply the strategy
proposed in [20] where the parameters align each frame Aj, j =
1, . . . , n to the middle frame of the sequence (An/2). Then these
initial values of τ are optimized in the iterative process along with
the other parameters.

V i
k

,

i = 1, . . . , h

(18)

τ t = arg min

τ

lev((mat(Aj − L0
otherwise

j ))i) ≥ 1

h

li =

1
n

Eij

,

i = 1, . . . , m

Proof. Expanding the objective function we have:

n(cid:88)

j=1

n(cid:88)

(cid:107)E − l1T(cid:107)2

(cid:107)Ek − l1T(cid:107)2

F =
(E11 − l1)2 + ··· + (Em1 − lm)2 + ··· + (E1n − l2)2
+··· + (Emn − lm)2

F =

k=1

Grouping terms together,

and we can conclude:

7

(cid:18) ψ2

(cid:19)

ψ1

+··· + (Emn − lm)2 =

= (E11 − l1)2 + ··· + (E1n − l1)2 + ··· + (Em1 − lm)2
(Eij − li)2

n(cid:88)
m(cid:88)
Setting the derivatives of each i-th term (cid:80)m
j=1 (Eij − li)2 to zero
n(cid:88)

with respect to li yields:

(Eij − li)2 =
−2 (Ei1 − li) − 2 (Ei2 − li) − ··· − 2 (Ein − li) = 0
= −2 (Ei1 + ··· + Ein) + 2nli = 0

j=1

j=1

i=1

We have from there that:

li =

1
n

n(cid:88)

Eij

j=1

(cid:4)

F

In

the

general

(cid:80)n

arg minl (cid:107)E − l1T(cid:107)2

problems

and
arg minrank(L)=1 (cid:107)E − L(cid:107)2
F have different solutions. The optimal
solution of the ﬁrst problem is the vector l = 1
j=1 Ej and the
n
solution of the second one is the matrix L = σ1V1U T
1 where V1
and U1 are the largest right and left singular vectors and σ1 is the
largest singular value. Since l1T is a particular rank-1 matrix, we
know the value of the objective function of the second problem in
the optimal solution is less than or equal to the minimum value of
the ﬁrst problem. The following lemma characterizes this difference
in terms of the distance of the one-dimensional
linear subspace
spanned by the columns of the matrices l1T and L.
Lemma 3. Suppose that E is a full rank matrix. Let l and L be
the optimal solutions of the problems arg minl (cid:107)E − l1T(cid:107)2
F and
arg minrank(L)=1 (cid:107)E − L(cid:107)2

F respectively; then:
dist (span{l} , span{L}) = O

(cid:18) σ2

(cid:19)

σ1

where span{l} and span{L} denote the one-dimensional subspaces
spanned by l and L respectively, and σ1 and σ2 are the two largest
singular values of E.

Proof. It is based on the proof of the convergence of the power
method for computing the eigenvectors of a matrix in [30]. Consider
the spectral decomposition of the matrix EET which is EET =
W ΨW T . Suppose that q is a vector of size m that can be written
as a linear combination of the eigenvectors of EET :

dist (span{l} , span{W1}) = O

Finally, the thesis of the lemma is obtained using the known rela-
tion between the eigenvectors/eigenvalues of EET and the singular
(cid:4)
vectors and singular values of E.

This lemma asserts that the distance between both subspaces and
the quotient σ2/σ1 are functions with similar growth rates. In other
words, the distance between the minimum value of (cid:107)E − l1T(cid:107)2
F as a
function of l and (cid:107)E − L(cid:107)2
F as a function of L, depends on the gap
between the largest and second largest singular values of the matrix
E. It is clear that the main advantage of the proposed optimization
function (20) is that the calculation of the expensive SVD is avoided.

Algorithm 3 SVD-free solution
1: Input: A, k, κ, tol, maxIter
2: Output: S, l, τ
3: Standard initialization: τ 0 = 0, l = 1
F /(cid:107)A(cid:107)2
4: while (cid:107)A ◦ τ t − l1T − St(cid:107)2
n
F > tol or

j=1 Aj, S0 = 0
1) Form the matrix A ◦ τ calculating the parameters τ t

(cid:80)n

t < maxIter do

i that infer the
mapping that transforms the column vector Ai to the i-th column vector
of the matrix lt−11T + St−1.
2) Calculate E = A ◦ τ t − St−1
3) Form St = PΩκ

(cid:0)A ◦ τ t − Lt(cid:1) where Ωκ is the non-zero subset of

lt = 1
n
the ﬁrst κ largest entities of |A ◦ τ − lt1T |

(cid:80)n

j=1 Ej

,

5: end while

*The initialization strategy described in section III-C can be used in this
algorithm.

IV. EXPERIMENTS AND RESULTS

The proposed algorithms in section III were implemented and
tested in MATLAB 8.3.0.532 (R2014a) on a 64-bit PC with Intel
Core i7-4770 CPU @3.40GHz (single core) and 32GB of RAM. A
C++ implementation has also been developed. For the evaluations,
7 challenging background subtraction datasets ([31], [32], [33], [34],
[35], [36], [37]) are tested with our models. They vary in resolution,
quality, frame number, and general scene scenarios which guarantee
an unbiased and rigorous evaluation. Please refer to table I for the
details and the challenges present in each sequence. A complete
description of challenges is available in [38].

q = α1W1 + ··· + αmWm

A. Evaluating the Ghost-Removal Algorithm

We have:

EET q = EET α1W1 + ··· + EET αmWm

EET q = α1ψ1W1 + ··· + αmψmWm

EET q = α1ψ1

W1 +

αj
α1

ψj
ψ1

Wj

(24)

This expression is satisﬁed in particular for a vector of size m, q
such that ET q = (1, . . . , 1)T ≡ 1 and q = (q1, . . . , qn, 0, . . . , 0).
The existence of this vector q is supported by E being a full rank
n E1 and substituting in equation (24), we have:
matrix. Since l = 1

l =

1
n

α1ψ1

W1 +

αj
α1

ψj
ψ1

Wj

(cid:32)

(cid:32)

m(cid:88)

j=2

m(cid:88)

j=2

(cid:33)

(cid:33)

Figure 1 (b)-(e) shows a comparison between the background
and foreground parts calculated with the model introduced in sec-
tion III-A with and without the ghost-removal algorithm introduced
in section III-C. Notice the absorption of some foreground parts
in the background when the initialization algorithm is not used in
columns (b) and (d). This in turn corrupts the calculated foreground as
well. The ghost-removal method signiﬁcantly reduces the unwanted
effect and noise in the results. The results from our algorithm shown
in this ﬁgure are without any further reﬁnement or morphological
operations and solely the raw output of the algorithms. The param-
eters used to obtain these results are rank(L) = 1, λ = 0.1, and
maxIterations = 10. Table II shows computing time for different
sequences with and without the ghost removal initialization. Note that
the initialization process is computationally cheap and the algorithm
keeps the same order in time consumption.

TABLE I: Information of the sequences used in experiments.

8

Description of challenges

Sequence Name size × #frames
Highway
Ofﬁce
Pedestrian
PETS2006
Video001
Video002
Video003
Video004
Video005
Video006
Video007
Video008

Noise, illumination changes, bootstrapping, dynamic background, shadows
Noise, inserted background object, large foreground objects
Dynamic background, beginning moving object
Illumination changes, dynamic background, inserted background object, shadows

[240 × 320] × 1700 Dynamic background, crowded scene, camouﬂage, shadows, foreground aperture
[240 × 360] × 2050 Sleeping foreground, foreground aperture
[240 × 360] × 1099 Shadows, foreground aperture
[576 × 720] × 1200 Shadows, inserted background object, sleeping foreground object
[240 × 320] × 63
[288 × 352] × 73
[240 × 320] × 15
[240 × 320] × 59
[240 × 320] × 79 Moved background object, inserted background object, dynamic background, bootstrapping
[240 × 320] × 84
[240 × 320] × 109
[240 × 320] × 54
[288 × 352] × 49
[240 × 360] × 500 Camera jitter, dynamic background, camouﬂage
[600 × 800] × 600 Camouﬂage, shadows, dynamic background
[144 × 176] × 3584 Sleeping foreground object, shadows, inserted background object
[120 × 160] × 3055 Bootstrapping, shadows, camouﬂage, foreground aperture
[218 × 180] × 2964 Dynamic background, camouﬂage, illumination changes
[130 × 160] × 3417 Dynamic background, noise, illumination changes
[128 × 160] × 523 Dynamic background, camouﬂage
[256 × 320] × 1286 Sleeping foreground object, shadows, inserted background object
[128 × 160] × 633 Dynamic background, foreground aperture, camouﬂage

Noise, illumination changes, camouﬂage
Illumination changes, noise
Camera jitter, camera automatic adjustments, dynamic background, illumination changes, shad-
ows, noise
Illumination changes, shadows

Camouﬂage
Hall
Bootstrap
Curtain
Escalator
Fountain
Shopping Mall
Water Surface
Walk Turn Back [576 × 720] × 466 Camera jitter, camouﬂage, moved background object

Video009
CM Data

Dataset

Change Detection
Workshop 2014 [31]

Background Models
Challenge 2012 [32]

Carnegie Mellon
2005 [33]
Stuttgart 2011 [34]
Perception 2004
(i2R) [35]

MuHAVi-MAS [36]

TABLE II: Time consumption for model in III-A with and without
ghost removal algorithm in III-C. CPU times are in seconds and for
15 iterations.

Sequence
Water Surface [35]
Pedestrian [31]
QMUL Junction

size×#frames
[128 × 160] × 48
[158 × 238] × 24
[288 × 360] × 300

Original
2.88
2.77
73.65

GR
2.98
2.83
73.74

B. Comparison of the RPCA-LBD and our Proposed Block-Sparse
Algorithm

In this experiment the performance of a model named RPCA-
LBD [27] that involves a (cid:96)2,1-norm minimization, and the proposed
block-sparse model in this paper is evaluated and compared. Figure 1
shows the results for both algorithms. Columns (b) and (d) correspond
to the low-rank and sparse parts obtained by the RPCA-LBD for
λ = 0.6710 (as tuned by authors in their original paper). Notice the
ghosting effect present in both L and S along with unwanted noise
and parts from the dynamic background absorbed into the foreground.
Columns (c) and (e) show the results for the same frames obtained
by our block-sparse solution with the ghost-removal initialization
intact. Notice the ghosting effect which is eliminated and less of
the unwanted noise and dynamic background has leaked into the
foreground. Finally the columns (f) and (g) show the foreground
masks obtained from the sparse parts of both algorithms. The
foreground mask for RPCA-LBD in column (f) has been reﬁned with
a thresholding strategy explained in section IV-D, and the foreground
mask of our method in column (g) is unreﬁned. The parameters
used to obtain these results are rank(L) = 1, λ = 0.03, and
maxIterations = 10.

C. Decomposition and Reconstruction of Video Sequences with SVD-
Free Algorithm

Figure 2 shows the visual results for video reconstruction for the
proposed SVD-free algorithm which can handle moving cameras.
In this example only the vector l (corresponding to background),
a cardinality of 15% of the pixels of the matrix S (corresponding
to moving objects in foreground), and the parameter vector τ were

used for reconstructing the original video sequence. Notice that with
a small amount of information the sequence is well constructed in
the output on column (b). The evaluation of compression ratio gained
with this method is out of scope of this work and must be studied
further. This sequence has been captured with a moving camera,
and therefore the frames are accordingly aligned during the iterative
process. Table IV lists the CPU time for computation of a foreground
from the sequence that obtains the maximal performance (in terms of
accuracy of foreground detection) for all the videos in six datasets.
Notice targeting the same performance, the speed-up in computation
time using our SVD-free algorithm.

D. Foreground Segmentation Evaluation

For quantitative evaluation, the accuracy of foreground detection
is measured by comparing the calculated foreground support F ∈
{0, 1}m,n with the binary ground truth images.

(cid:40)

Fij =

0,
1,

if Sij
if Sij

is background
is foreground

(25)

This performance measure is regarded as a classiﬁcation problem
and evaluate the results using Precision and Recall values which are
deﬁned as:

P recision =

tp

tp + f p

Recall =

tp

tp + f n

=

#correctly classiﬁed foreground pixels

#foreground pixels in GT

The Precision and Recall values are calculated with the number
of pixels that are assigned True-Positive tp, True-Negative tn, False-
Positive f p, and False-Negative f n. Precision and Recall are widely
used when the class distribution is skewed [39]. In addition a single
measurement named F1 score is provided, which is the harmonic
mean of the Precision and Recall values as:

F1 = 2 × P recision × Recall

P recision + Recall

The higher the F1 score, the better the detection accuracy. Also

the False-Positive Rate is deﬁned as F P R = f p

f p+tn .

Figure 3 shows the unreﬁned segmentation results for a general
surveillance sequence. Notice the accuracy and coherence of the
segmentation in our results as compared to that of GoDec. The
proposed algorithm can handle objects that occupy large portions of
the frame as well as small objects (such as pedestrians in this scene)
equally well simultaneously. Table III lists the accuracy measures for
foreground segmentation in six datasets for our method, RPCA solved
via inexact Augmented Lagrange Multipliers1 [40], and GoDec2 [22].
The results for our method are obtained by comparing the obtained
foreground (without any further reﬁnement) to the ground truth.
For RPCA-PCP method the unreﬁned support of the sparse matrix
would produce a lot of false positives. Therefore, to obtain a more
fair comparison for the RPCA-PCP method, a threshold criterion is
required to get the ﬁnal foreground mask, and the same threshold
strategy as in [41] is adopted. It is assumed that the distribution of
the difference values between the A and L at the tentatively identiﬁed
background locations, can be an estimation of the expected level of
noise; i.e. they satisfy the Gaussian distribution (µ, σ). Thereafter,
the threshold is set at the mean of those difference values plus
three standard deviations of difference values, and is then applied
to S to obtain the foreground support. This is known as the 99.7 or
alternatively, the three-σ rule of thumb in statistics, which states that
even for non-normally distributed variables, at least 98% of cases
should fall within properly-calculated three-σ intervals. Given an
observation of difference values δ the probability distribution can
be expressed as:

P r(µ − 3σ ≤ δ ≤ µ + 3σ) ≈ 0.9973

The Receiver Operating Characteristic (ROC) curves obtained
with precision-recall values in ﬁgure 4 show the performance of
our method against GoDec for varying thresholds. ROC curves are
a good tool to graphically illustrate the performance of a binary
classiﬁer system as its discrimination threshold is varied. The results
here guarantee superior performance for all datasets in foreground
segmentation accuracy.

E. Removing Shadows and Specularities and Aligning Face Images
Our model can be extended to applications such as piece-wise face
image alignment. Given n images I1, . . . , In of an object which are
misaligned the optimization problem is solved in such a way that the
resulting images I1◦τ1, . . . , In◦τn are well-aligned. This application
has been proposed in a work by Peng et al. [23] where they used
the original RPCA formulation. Due to the limitations demonstrated
previously, and time consuming convergence of RPCA-PCP,
the
algorithm is not suitable for real-time performance. Following the
proposed optimization problem the individual images are regarded
as frames of a video sequence concatenated in the data matrix A.
The results will yield a decomposition in which A ◦ τ describes
the aligned faces in a canonical frame, the low-rank matrix L that
describes an eigen representation of a face of a person clear of
corruptions and misalignment, and the matrix S +G that contains the
collective corruptions, specularities, shadows and noise. Figures 5, 6,
and 7 demonstrate the results for a set of face images taken from the
Labeled Faces in the Wild (LFW) dataset [42].

V. DISCUSSION AND FUTURE WORK

In this article an improved approximated RPCA algorithm was
proposed that aims to solve general scene background subtraction, as
well as a novel SVD-free solution to the optimization problem for fast

1http://perception.csl.illinois.edu/matrix-rank/sample code.html
2https://sites.google.com/site/godecomposition/code

9

(a) Original images A

(b) Aligned images A ◦ τ

(c) Low-rank component L

(d) Sparse specularities S + G

(e)

(f)

(g)

(h)

Fig. 5: Robust alignment by sparse and low-rank decomposition in
LFW dataset [42]. Figures (e), (f), (g), and (h) correspond to the
average of (a), (b), (c), and (d) respectively.

(a)

(b)

(c)

(d)

Fig. 6: Removing shadows and corruptions on faces from LFW
dataset [42]. (a), (b), (c), and (d) correspond to average of: original
images, aligned images, low-rank component, and sparse specularities
respectively.

computation. The solutions presented in this paper aim to simulta-
neously solve some of the persistent issues that arise with RPCA-
based methods in foreground/background segmentation of general
video sequences. The proposed method can handle camera movement,
various foreground object sizes, and slow-moving foreground pixels
as well as sudden and gradual illumination changes in a scene. The
qualitative and quantitative segmentation results outperform current
state-of-the-art methods. The proposed SVD-free solution achieves
more than double the amount of speed-up in computation time for the
same performance target compared to its counterparts. In future the
authors would like to move towards more unconstrained cases where
the captured video could have any motion, parametric transformation,
quality, motion blur, or deformation of scene elements. There is an
ongoing work to compose a background library from the sequences

Input imagesAligned imagesLow rank partSparse corruptions in the aligned imagesTABLE III: F1 scores comparison for foreground detection accuracy. Results from our method are obtained with unreﬁned raw outputs. RPCA
via IALM and GoDec results are reﬁned with a thresholding strategy for a fairer comparison. (Best: bold-face, Second best: underlined).

10

Recall (TPR)

Fallout (FPR)

Change Detection Workshop
2014 [31]

Background Models Challenge
2012 [32]

Carnegie Mellon 2005 [33]
Stuttgart 2011 [34]
Perception 2004 (i2R) [35]

MuHAVi-MAS [36]

Average

Ours

GoDec

RPCA
0.9136 0.7690 0.1724
Highway
0.7405 0.8631 0.0796
Ofﬁce
0.9489 0.7123 0.7550
Pedestrian
0.9892 0.7197 0.1579
PETS2006
0.8426 0.4021 0.9182
Video001
0.8224 0.6526 0.8790
Video002
0.9710 0.7816 0.9308
Video003
0.7305 0.6870 0.9397
Video004
0.9347 0.3995 0.9627
Video005
0.7613 0.6118 0.9016
Video006
0.3010 0.5410 0.8170
Video007
0.8030 0.3650 0.8946
Video008
0.9157 0.6052 0.9193
Video009
0.7861 0.7271 0.7232
CM Data
0.8653 0.6123 0.1310
Camouﬂage
0.9036 0.6516 0.3656
Hall
0.5501 0.6386 0.3142
Bootstrap
0.9736 0.8353 0.8634
Curtain
0.7506 0.5238 0.4873
Escalator
0.9578 0.5803 0.8706
Fountain
0.9773 0.6973 0.2287
Shopping Mall
Water Surface
0.9880 0.7967 0.9468
Walk Turn Back 0.9655 0.8617 0.9203
0.8431 0.6537 0.6600

Ours

GoDec

RPCA
0.3438 0.0088 0.0000
0.0637 0.0359 0.0030
0.5067 0.0015 0.0044
0.8416 0.0028 0.0000
0.2112 0.0141 0.3647
0.3380 0.0246 0.1917
0.1174 0.0023 0.4575
0.5969 0.0028 0.3905
0.4031 0.0141 0.2921
0.1135 0.0206 0.2543
0.3027 0.0111 0.1735
0.3179 0.0067 0.4234
0.8348 0.0004 0.3600
0.3076 0.0050 0.0281
0.0696 0.0204 0.0026
0.2042 0.0160 0.0009
0.0949 0.0257 0.0021
0.7900 0.0139 0.0159
0.1234 0.0108 0.0080
0.4864 0.0071 0.1647
0.7038 0.0167 0.0010
0.6781 0.0026 0.1249
0.1852 0.0030 0.0277
0.3754 0.0116 0.1431

Ours

Precision (PPV)
GoDec

RPCA
0.2026 0.8929 0.9975
0.5325 0.7020 0.7254
0.0415 0.9186 0.7977
0.0218 0.8278 0.9996
0.0506 0.2763 0.0325
0.1648 0.6825 0.2710
0.1517 0.8805 0.0421
0.0135 0.7367 0.0263
0.0156 0.1622 0.0220
0.2102 0.5411 0.1233
0.0642 0.7704 0.2452
0.0549 0.5575 0.0464
0.0046 0.8485 0.0106
0.0485 0.7428 0.3394
0.2621 0.4620 0.5856
0.2315 0.7347 0.9667
0.3562 0.7035 0.9349
0.1081 0.8555 0.8422
0.2170 0.6883 0.7354
0.0654 0.7439 0.1581
0.0831 0.7318 0.9343
0.1125 0.9644 0.3973
0.0681 0.8007 0.3177
0.1340 0.7054 0.4587

F1 Score
Ours

GoDec

RPCA
0.3316 0.8264 0.2940
0.6195 0.7743 0.1435
0.0796 0.8024 0.7758
0.0426 0.7700 0.2728
0.0955 0.3275 0.0629
0.2746 0.6672 0.4143
0.2625 0.8281 0.0806
0.0266 0.7110 0.0511
0.0307 0.2307 0.0430
0.3294 0.5743 0.2169
0.1058 0.6356 0.3772
0.1028 0.4412 0.0882
0.0091 0.7065 0.0210
0.0913 0.7349 0.4620
0.4023 0.5266 0.2141
0.3686 0.6907 0.5305
0.4324 0.6695 0.4703
0.1946 0.8452 0.8526
0.3367 0.5949 0.5862
0.1224 0.6520 0.2675
0.1531 0.7142 0.3675
0.2020 0.8726 0.5598
0.1272 0.8301 0.4724
0.2061 0.6707 0.3315

TABLE IV: Time performance comparison of the RPCA via IALM, the approximated RPCA GoDec, and our SVD-Free approximated RPCA
for processing the whole dataset videos. All algorithms were run with 5 iterations and the parameter λ was chosen to obtain maximal F1
measure performance.

Number of Frames
RPCA (CPU sec.)
GoDec (CPU sec.)
Our Model (CPU sec.)

CDW [31]
6049
1931.12
1874.82
358.91

BMC [32]
591
116.94
49.67
20.82

CM [33]
500
65.67
44.26
17.38

SAI [34]
600
454.59
376.91
117.69

i2R [35] MuHAVi-MAS [36]
15462
646.52
480.33
209.84

466
380.85
203.17
70.27

Fig. 1: Effect of initialization (b)-(e) and RPCA-LBD algorithm vs. our block-sparse model (d)-(g), comparison for a complex video sequence
with dynamic background (water rippling) and camouﬂage. (a) Original video for frames 24 and 48. (b) Corresponding background extracted
by RPCA-LBD. (c) Background with our block-sparse method. (d) Foreground by RPCA-LBD. (e) Foreground with our block-sparse method.
(f) Reﬁned foreground mask obtained by RPCA-LBD. (g) Unreﬁned foreground mask obtained by our block-sparse method.

solely for reconstruction purposes in video coding applications. In
addition, the authors are currently studying the possibility of a multi-
variable minimization problem based on the proposed original model,
in order to incorporate more features for more robust detection and
better reconstruction.

REFERENCES

[1] E. J. Cand`es, X. Li, Y. Ma, and J. Wright, “Robust principal component
analysis?” J. ACM, vol. 58, no. 3, pp. 11:1–11:37, Jun. 2011. 1, 2, 3, 5

[2] S. Erfanian Ebadi, V. Guerra Ones, and E. Izquierdo, “Efﬁcient back-
ground subtraction with low-rank and sparse matrix decomposition,”
in Image Processing (ICIP), 2015 IEEE International Conference on,
September 2015. 1

[3] T. Bouwmans, “Recent advanced statistical background modeling for
foreground detection: A systematic survey,” Recent Patents on Computer
Science, vol. 4, no. 3, 2011. 2

[4] T. Bouwmans and E. Zahzah, “Robust PCA via principal component
pursuit: A review for a comparative evaluation in video surveillance,”
Special Isssue on Background Models Challenge , Computer Vision and
Image Understanding, 2014. 2

[5] E. M`emin and P. P`erez, “Dense estimation and object-based segmenta-

(a) (b) (c) (d) (e) (f) (g) 11

Fig. 2: Video reconstruction of SVD-free algorithm, a sequence with moving camera [37]. (a) Original video for frames 1, 20, and 40. (b)
Reconstruction results with L + S. The marked green region corresponds to the recovered rank-1 background across the whole sequence
with the alignment procedure described (i.e. transformed images) with motion parameters. (c) Motion-compensated extracted background L.
(d) Motion-compensated extracted foreground S.

Fig. 3: Segmentation results comparison. Sequence from QMUL Junction dataset. (a) Original frames, (b) Low-rank GoDec, (c) Low-rank
ours, (d) Sparse GoDec, (e) Sparse ours. Notice the quality of segmentation and details recovered by our model.

tion of the optical ﬂow with robust techniques.” IEEE Transactions on
Image Processing, vol. 7, no. 5, pp. 703–719, 1998. 2

[6] S. S. Huang, L. C. Fu, and P. Y. Hsiao, “A region-level motion-based
IEEE

background modeling and subtraction using MRFs.” in ICRA.
Transactions on Image Processing, 2005, pp. 2179–2184. 2

[7] Z. Liu, K. Huang, and T. Tan, “Foreground object detection using top-
down information based on em framework.” IEEE Transactions on Image
Processing, vol. 21, no. 9, pp. 4204–4217, 2012. 2

[8] L. Maddalena and A. Petrosino, “A self-organizing approach to
background subtraction for visual surveillance applications,” IEEE
Transations on Image Processing, vol. 17, no. 7, pp. 1168–1177, July
2008. [Online]. Available: http://dx.doi.org/10.1109/TIP.2008.924285 2
[9] J. Y. A. Wang and E. H. Adelson, “Representing moving images with

layers.” IEEE Transactions on Image Processing, vol. 3, no. 5, pp. 625–
638, 1994. 2

[10] O. Barnich and M. V. Droogenbroeck, “Vibe: A universal background
subtraction algorithm for video sequences,” IEEE Transactions on Image
Processing, pp. 1709–1724, 2011. 2

[11] L. Cheng, M. Gong, D. Schuurmans, and T. Caelli, “Real-time discrimi-
native background subtraction,” IEEE Transactions on Image Processing,
2010. 2

[12] A. Colombari and A. Fusiello, “Patch-based background initialization
in heavily cluttered video.” IEEE Transactions on Image Processing,
vol. 19, no. 4, pp. 926–933, 2010. 2

[13] L. Li, W. Huang, I. Y.-H. Gu, and Q. Tian, “Statistical modeling of com-
plex backgrounds for foreground object detection,” IEEE Transactions

(a) (b) (c) (d)  (a) (b) (c) (d) (e) 12

(a) BMC

(b) CDW, CM, SAI, and MuHAVi-MAS

(c) i2R

Fig. 4: Receiver Operating Characteristic (ROC) curves for the performance of our method vs. GoDec with varying thresholds.

Conference on Machine Learning (ICML-11), ser. ICML ’11, L. Getoor
and T. Scheffer, Eds. ACM, June 2011, pp. 33–40. 2, 3, 4, 9

[23] Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma, “RASL: robust
alignment by sparse and low-rank decomposition for linearly correlated
images,” IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, vol. 34, no. 11, pp. 2233–2246, 2012. 3, 4, 5, 9

[24] T. Zhou and D. Tao, “Shifted subspaces tracking on sparse outlier
for motion segmentation,” in IJCAI 2013, Proceedings of
the 23rd
International Joint Conference on Artiﬁcial Intelligence, Beijing, China,
August 3-9, 2013. 3

[25] R. Szeliski, Computer Vision: Algorithms and Applications, 1st ed. New

York, NY, USA: Springer-Verlag New York, Inc., 2010. 4

[26] J.-M. Odobez and P. Bouthemy, “Robust multiresolution estimation of
parametric motion models,” Journal of visual communication and image
representation, vol. 6, no. 4, pp. 348–365, 1995. 4

[27] G. Tang and A. Nehorai, “Robust principal component analysis based
on low-rank and block-sparse matrix decomposition,” in 45th Annual
Conference on Information Sciences and Systems, CISS, The John
Hopkins University, Baltimore, MD, USA, 23-25 March 2011, 2011, pp.
1–5. 5, 8

[28] C. Guyon, T. Bouwmans, and E. Zahzah, “Foreground detection based
on low-rank and block-sparse matrix decomposition,” in International
Conference on Image Processing, ICIP 2012, 2012. 5

[29] M. W. Mahoney and P. Drineas, “CUR matrix decompositions for im-
proved data analysis,” Proceedings of the National Academy of Sciences,
vol. 106, no. 3, pp. 697–702, 2009. 6

[30] G. G. Golub and C. F. V. Loan, Matrix Computations, 3rd ed.

The

Johns Hopkins University Press, 1996. 7

[31] Y. Wang, P.-M. Jodoin, F. Porikli, J. Konrad, Y. Benezeth, and P. Ishwar,
“CDnet 2014: An Expanded Change Detection Benchmark Dataset,” in
IEEE CVPR Change Detection workshop, United States, Jun. 2014, p.
8 p., https://hal-univ-bourgogne.archives-ouvertes.fr/hal-01018757. 7, 8,
10

[32] A. Vacavant, L. Tougne, T. Chateau, and L. Robinault, “Background
Models Challenge, Workshop of ACCV 2012,” Springer, Nov. 2012,
http://liris.cnrs.fr/publis/?id=5905. 7, 8, 10

[33] Y. Sheikh and M. Shah, “Bayesian modeling of dynamic scenes for

object detection,” PAMI, vol. 27, pp. 1778–1792, 2005. 7, 8, 10

[34] S. Brutzer, B. H¨oferlin, and G. Heidemann, “Evaluation of background
subtraction techniques for video surveillance,” in Computer Vision and
Pattern Recognition (CVPR) IEEE, 2011, pp. 1937–1944. 7, 8, 10

[35] L. Li, W. Huang, I. Y.-H. Gu, and Q. Tian, “Statistical modeling of com-
plex backgrounds for foreground object detection,” IEEE Transactions
on Image Processing, vol. 13, no. 11, pp. 1459–1472, 2004. 7, 8, 10

[36] S. Singh, S. A. Velastin, and H. Ragheb, “MuHAVi: A multicamera
human action video dataset for the evaluation of action recognition
methods,” in Proceedings of
the 2010 7th IEEE International
Conference on Advanced Video and Signal Based Surveillance, ser.
AVSS ’10. Washington, DC, USA: IEEE Computer Society, 2010, pp.
48–55. [Online]. Available: http://dx.doi.org/10.1109/AVSS.2010.63 7,
8, 10

[37] T.Brox and J.Malik, “Object segmentation by long term analysis
trajectories,” in European Conference on Computer Vision

of point

(a)

(b)

Fig. 7: Face alignment in large datasets. Average faces (a) before and
(b) after alignment in LFW dataset [42] for 35 images per subject.

on Image Processing, vol. 13, no. 11, pp. 1459–1472, 2004. 2

[14] X. Ding, L. He, and L. Carin, “Bayesian robust principal component
analysis.” IEEE Transactions on Image Processing, vol. 20, no. 12, pp.
3419–3430, 2011. 2

[15] D. M. Tsai and S. C. Lai, “Independent component analysis-based
background subtraction for indoor surveillance.” IEEE Transactions on
Image Processing, vol. 18, no. 1, pp. 158–167, 2009. 2

[16] J. L. Starck, M. Elad, and D. L. Donoho, “Image decomposition via
the combination of sparse representations and a variational approach.”
IEEE Transactions on Image Processing, vol. 14, no. 10, pp. 1570–1582,
2005. 2

[17] N. M. Oliver, B. Rosario, and A. P. Pentland, “A Bayesian computer
vision system for modeling human interactions,” IEEE Transactions on
Pattern Analysis and Machine Intelligence, vol. 22, no. 8, pp. 831–843,
2000. 2

[18] F. D. L. Torre and M. J. Black, “A framework for robust subspace
learning,” International Journal of Computer Vision, vol. 54, p. 2003,
2003. 2

[19] J. Wright, A. Ganesh, S. Rao, Y. Peng, and Y. Ma, “Robust principal
component analysis: Exact recovery of corrupted low-rank matrices via
convex optimization,” in Advances in Neural Information Processing
Systems 22: 23rd Annual Conference on Neural Information Processing
Systems 2009. Proceedings of a meeting held 7-10 December 2009,
Vancouver, British Columbia, Canada., 2009, pp. 2080–2088. 2

[20] X. Zhou, C. Yang, and W. Yu, “DECOLOR: Moving object detection
by detecting contiguous outliers in the low-rank representation.” IEEE
Transactions on Pattern Analysis and Machine Intelligence, vol. 35,
no. 3, pp. 597–610, 2013. 2, 6

[21] X. Liu, G. Zhao, J. Yao, and C. Qi, “Background subtraction based on

low-rank and structured sparse decomposition,” 2015. 2, 5

[22] T. Zhou and D. Tao, “GoDec: Randomized low-rank and sparse matrix
decomposition in noisy case,” in Proceedings of the 28th International

00.10.20.30.40.50.60.70.80.910.80.820.840.860.880.90.920.940.960.981RecallPrecision1Ours1GoDec2Ours2GoDec3Ours3GoDec4Ours4GoDec5Ours5GoDec6Ours6GoDec7Ours7GoDec8Ours8GoDec9Ours9GoDec00.10.20.30.40.50.60.70.80.910.880.890.90.910.920.930.940.950.960.970.980.991RecallPrecisionHighwayOursHighwayGoDecPedestrianOursPedestrianGoDecPETS2006OursPETS2006GoDecCarnegieMellonOursCarnegieMellonGoDecSAIOursSAIGoDecMuHAVi-MASOursMuHAVi-MASGoDec00.10.20.30.40.50.60.70.80.910.80.820.840.860.880.90.920.940.960.981RecallPrecisionBootstrapOursBootstrapGoDecCurtainOursCurtainGoDecEscalatorOursEscalatorGoDecFountainOursFountainGoDecHallOursHallGoDecShoppingMallOursShoppingMallGoDecWaterSurfaceOursWaterSurfaceGoDecAverage face before alignemnt (D)Average face after alignemnt (Do)(ECCV), ser. Lecture Notes in Computer Science. Springer, Sept. 2010.
[Online]. Available: http://lmb.informatik.uni-freiburg.de//Publications/
2010/Bro10c 7, 11

[38] D. D. Bloisi, Background Modeling and Foreground Detection for Video
Surveillance, T. Bouwmans, F. Porikli, B. Hrferlin, and A. Vacavant,
Eds. CRC Press, Taylor and Francis Group, July 2014. 7

[39] J. Davis and M. Goadrich, “The relationship between precision-
the 23rd International
ICML ’06. New York,
[Online]. Available: http:

recall and roc curves,” in Proceedings of
Conference on Machine Learning, ser.
NY, USA: ACM, 2006, pp. 233–240.
//doi.acm.org/10.1145/1143844.1143874 8

[40] Z. Lin, M. Chen, and Y. Ma, “The augmented lagrange multiplier method
for exact recovery of corrupted low-rank matrices,” arXiv preprint
arXiv:1009.5055, 2010. 9

[41] Z. Gao, L.-F. Cheong, and M. Shan, “Block-sparse rpca for consistent
foreground detection,” in Computer Vision–ECCV 2012. Springer, 2012,
pp. 690–703. 9

[42] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller, “Labeled faces
in the wild: A database for studying face recognition in unconstrained
environments,” University of Massachusetts, Amherst, Tech. Rep. 07-49,
October 2007. 9, 12

Salehe Erfanian Ebadi received her B.Sc. degree
in Telecommunications Electrical Engineering from
Sadjad University of Technology, Mashhad, Iran
in 2011, and her M.Sc. degree in Digital Signal
Processing from Queen Mary University of London,
London, U.K. in 2012. She is currently pursuing
a Ph.D. degree in Electronic Engineering at
the
Multimedia and Vision Group, School of Electronic
Engineering and Computer Science, Queen Mary
University of London. Her research interests include
Image and Video Processing, Matrix Decomposition

Techniques for Computer Vision, and Machine Learning.

13

Valia Guerra Ones Valia Guerra Ones received
the M.S. and Ph.D. degrees in applied mathematics
from the University of Havana, Havana, Cuba, in
1995 and 1998, respectively. Currently, she is with
the Department of Electronic Engineering, Queen
Mary University of London, London, U.K., and she
is visiting professor in the Department of Applied
Mathematics, Delft University of Technology, Delft,
The Netherlands. Her research interest include nu-
merical linear algebra and its applications in Image
Processing, randomized matrix algorithms and ill-

posed problems, and regularization methods.

Ebroul Izquierdo (SM’03) received the M.Sc. de-
gree in 1988 from Berlin, Germany, the C.Eng. de-
gree in 1999 from London, U.K., and the Dr. Rerum
Naturalium (Ph.D.) from the Humboldt University,
Berlin, Germany, in the ﬁeld of numerical approx-
imation of algebraic-differential equations. He is a
Chair of Multimedia and Computer Vision and the
Head of the Multimedia and Vision Group in the
School of Electronic Engineering and Computer Sci-
ence at Queen Mary, University of London, London,
U.K. He was a Senior Researcher at the Heinrich-
Hertz Institute for Communication Technology, Berlin, Germany, and the
Department of Electronic Systems Engineering of the University of Essex.
He holds several patents in the area of multimedia signal processing and has
published more than 500 technical papers including chapters in books. Prof.
Izquierdo is a Chartered Engineer, a Fellow of The Institution of Engineering
and Technology (IET), a member of the British Machine Vision Association,
Past Chairman of the IET professional network on Information Engineering,
a member of the Visual Signal Processing and Communication Technical
Committee of the IEEE Circuits and Systems Society and a member of
the Multimedia Signal Processing technical committee of the IEEE. He is
or has been associated and Guest Editor of several relevant journals in the
ﬁeld including the IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS
FOR VIDEO TECHNOLOGY, the EURASIP Journal on Image and Video
processing, the Elsevier Journal Signal Processing: Image Communication,
The EURASIP Journal on Applied Signal Processing, the IEEE Proceedings
on Vision, Image and Signal Processing, the Journal of Multimedia Tools and
Applications and the Journal of Multimedia. He has been a member of the
organizing committee of several conferences and workshops in the ﬁeld and
has chaired special sessions and workshops in International Conference on
Image Processing, International Conference on Acoustics, Speech, and Signal
Processing, and International Symposium on Circuits and Systems.

