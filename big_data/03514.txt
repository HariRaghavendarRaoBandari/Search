6
1
0
2

 
r
a

 

M
1
1

 
 
]

.

A
N
h
t
a
m

[
 
 

1
v
4
1
5
3
0

.

3
0
6
1
:
v
i
X
r
a

STRUCTURE-PRESERVING MODEL REDUCTION OF FORCED

HAMILTONIAN SYSTEMS∗

LIQIAN PENG† AND KAMRAN MOHSENI‡

Abstract. This paper reports a development in the proper symplectic decomposition (PSD)
for model reduction of forced Hamiltonian systems. As an analogy to the proper orthogonal decom-
position (POD), PSD is designed to build a symplectic subspace to ﬁt empirical data. Our aim is
two-fold. First, to achieve computational savings for large-scale Hamiltonian systems with external
forces. Second, to simultaneously preserve the symplectic structure and the forced structure of the
original system. We ﬁrst reformulate d’Alembert’s principle in the Hamiltonian form. Corresponding
to the integral and local forms of d’Alembert’s principle, we propose two diﬀerent structure-preserving
model reduction approaches to reconstruct low-dimensional systems, based on the variational prin-
ciple and on the structure-preserving projection, respectively. These two approaches are proven to
yield the same reduced system. Moreover, by incorporating the vector ﬁeld into the data ensemble,
we provided several algorithms for energy preservation. In a special case when the external force
is described by the Rayleigh dissipative function, the proposed method automatically preserves the
dissipativity, boundedness, and stability of the original system. The stability, accuracy, and eﬃciency
of the proposed method are illustrated through numerical simulations of a dissipative wave equation.

Key words. Structure-preserving, forced Hamiltonian systems, proper symplectic decompo-
sition, d’Alembert’s principle, variational principle, structure-preserving projection, dissipativity
preservation

AMS subject classiﬁcations. 65P10, 37M15, 34C20, 93A15, 37J25

1. Introduction. For several centuries, physical models have been used in the
natural sciences to describe and predict the world we live in. Physical models are
anchored in venerated physical laws, such as Newton’s laws of motion, Hamilton’s
principle, and conservation laws, to name but a few. Compared with data-based
empirical models, physical models are more comprehensive and interpretable.
In
most cases, physical models derived from these laws are simple in the sense that
they are typically expressed in terms of a few elegant equations. Nevertheless, for
many practical problems, physical models become computational expensive, and even
intractable, when they have high dimensions.

In recent years, the revolution in data sciences has opened a new window for un-
derstanding our would. Rather than discovering new physical laws, empirical models
have led to powerful tools for extracting patterns and trends from the data directly.
Although empirical models are phenomenological, they are predictive as well. When
facing the curse of dimensionality in empirical models, dimensionality reduction tech-
niques in data sciences provide low-cost solutions by pre-processing the data into a
lower-dimensional form.

Can we couple tools from the data sciences–tools that are capable of dealing
with high dimensions–with physical models? How can we combine the advantages of
physical models with the information contained in the data? Model reduction is a
technique for reducing the computational complexity of physical models in numeri-
cal simulations. Using empirical data, model reduction can provide low-dimensional

∗ The authors acknowledge partial support from the Air Force Oﬃce of Scientiﬁc Research

(AFOSR).

†Department of Mechanical and Aerospace Engineering, University of Florida, Gainesville, FL

32611-6250 (liqianpeng@uﬂ.edu).

‡Department of Mechanical and Aerospace Engineering, and Department of Electrical and Com-

puter Engineering, University of Florida, Gainesville, FL 32611-6250 (mohseni@uﬂ.edu).

1

2

LIQIAN PENG AND KAMRAN MOHSENI

models that adequately predict the dynamics and allow for real-time analysis and
control. The need for model reduction arises because, in many cases, direct numerical
simulations are so computationally intensive that they either cannot be performed as
often as needed or are only performed in special circumstances. See [1] for a survey
on the classical model reduction methods.

Among these methods, the proper orthogonal decomposition (POD, also known
as Karhunen-Lo`eve decomposition or principle component analysis) with Galerkin
projection, which was ﬁrst introduced by Moore [16], has wide applications in many
ﬁelds of science and engineering. As an empirical model reduction technique, the
POD-Galerkin method (or POD for short) involves an oﬄine-online splitting method-
ology. In the oﬄine stage, empirical data is generated by experiments or direct nu-
merical simulations. A reduced model (or reduced system) is then constructed by
projecting the full model to a subspace where empirical data approximately resides.
In the online stage, the reduced model is solved in the low-dimensional subspace.

However, the classical POD method is not guaranteed to yield a stable reduced
model in general, even if the full model is stable [21, 20, 18]. The instability of
a reduced model is often accompanied by blowup of system energy. Thus, a POD
reduced model often fails to represent a physical system even if it is conservative or
dissipative. More generally, POD can always yield a reduced model with a signiﬁcantly
lower dimension, but the reduced model might be merely a numerical model, rather
than a physical model, since a POD reduced model may not yield to the underlying
physical law that exists in the full model. Our primary motivation in this paper is to
develop a model reduction technique such that the reduced model is guaranteed to be
physical and as stable as the full model.

In the context of classical mechanics, d’Alembert’s principle is the fundamen-
tal law of motion. Thus, if a reduced model remains physical, it should respect
d’Alembert’s principle. In section 2, we shall see that forced Hamiltonian equations
satisfy d’Alembert’s principle; conversely, if a system satisﬁes d’Alembert’s princi-
ple, it can be represented by a forced Hamiltonian equation when choosing canonical
coordinates. Thus, this paper focuses on developing a structure-preserving model
reduction method for forced Hamiltonian systems, where the structure refers to the
forced Hamiltonian structure and the systems are represented by ordinary diﬀerential
equations (ODEs).

The proposed method in this paper extends our previous work on the symplectic
model reduction of Hamiltonian systems to the structure-preserving model reduction
of forced and dissipative systems. The symplectic model reduction is based on proper
symplectic decomposition (PSD)-symplectic projection method [18]. Analogous to the
POD-Galerkin method, PSD builds a symplectic subspace to ﬁt empirical data, while
the symplectic projection constructs a reduced Hamiltonian system on the symplectic
subspace. Because the PSD reduced system preserves the symplectic structure, it
automatically preserves the system energy and stability. Owing to these properties,
the symplectic method outperforms the POD for model reduction of Hamiltonian
systems, especially when stability is taken into consideration for long-time integra-
tion. Since many physical and engineering systems have external forces, this paper
applies symplectic algorithms for model reduction of more general dynamical systems
with external forces. Besides PSD, there are also other structure-preserving model
reduction methods in the context of classical mechanics, including the Lagrangian
approach [11, 4] and the port-Hamiltonian approach [7, 19, 5]. Compared with these
methods, PSD is directly related to symplectic geometry, and provides more ﬂexibility

STRUCTURE-PRESERVING MODEL REDUCTION

3

to construct an optimal subspace to ﬁt empirical data.

The remainder of this paper is organized as follows. Since forced Hamiltonian
equations are anchored in d’Alembert’s principle, we reformulate d’Alembert’s prin-
ciple in the Hamiltonian form in section 2. Corresponding to the integral and local
forms of d’Alembert’s principle, section 3 presents two diﬀerent structure-preserving
approaches for model reduction of forced Hamiltonian equations based on the vari-
ational principle and on the structure-preserving projection, respectively. We also
prove that the two approaches are equal in the sense that they yield the same reduced
equation and provide a PSD algorithm to construct the reduced basis function. In
section 4, we discuss dissipative Hamiltonian systems, and prove that the proposed
method automatically preserves the dissipativity. In section 5, the stability, accuracy,
and eﬃciency of the proposed technique are illustrated through numerical simulations
of a dissipative wave equation. Finally, conclusions are oﬀered in section 6.

2. Forced Hamiltonian equations. In Hamiltonian mechanics, a mechanical
system with external forces can be represented by a forced Hamiltonian equation. In
this section, we ﬁrst represent the forced Hamiltonian equation, and then derive it by
d’Alembert’s principle.

Let Q be an n-dimensional vector space over R, Q∗ be its dual space, and h·, ·i :
Q∗ ×Q → R be a nondegenerate duality paring. With V = Q⊕Q∗, the pair (V, Ω) is a
symplectic vector space, where V is the phase space and Ω is a closed non-degenerate
two-form on V. Assigning a symplectic form Ω to V is referred to as giving V a
symplectic structure. With uq, vq ∈ Q and up, vp ∈ Q∗, we have

(2.1)

Ω((uq, up), (vq, vp)) = hvp, uqi − hup, vpi.

Using canonical coordinates, Ω is represented by the Poisson matrix

J2n = (cid:20) 0n

−In

In

0n(cid:21) .

Let H : V → R denote a smooth Hamiltonian function. The time evolution of

forced Hamiltonian systems are deﬁned by

(2.2)

˙q = ∇pH(q, p),

˙p = −∇qH(q, p) + fH (q, p),

where q ∈ Q denotes the generalized coordinate, p ∈ Q∗ denotes the generalized
momentum, and fH (q, p) ∈ Q∗ is a force ﬁeld. We abstract this formulation by
introducing a variable x = (q, p) in the phase space V. Then, (2.2) becomes

(2.3)

˙x = XH (x) + XF (x),

where XH (x) = J2n∇xH(x) denotes a Hamiltonian vector ﬁeld, and XF (x) = (0, fH(x))
denotes a vertical vector ﬁeld with zero in its ﬁrst component. The state variable x(t)
can also be considered as a function of t, which gives a trajectory as t varies over R+
with a ﬁxed initial condition x0. The trajectory x(R+) contains a sequence of states
that follow from x0.

Dissipative Hamiltonian systems are special forced Hamiltonian systems, where
the system energy is decreasing with time. As an example, consider a one-dimensional
harmonic oscillator with undamped angular frequency ω0 and damping ratio ζ. New-
ton’s second law takes the form

(2.4)

¨x + 2ζω0 ˙x + ω2

0x = 0.

4

LIQIAN PENG AND KAMRAN MOHSENI

2 ω2

2 p2 + 1

With q = x and p = ˙x, the Hamiltonian function is given by H(q, p) = 1
0q2,
and the force ﬁeld is given by fH(q, p) = −2ζω0p. Plugging H(q, p) and fH (q, p) into
(2.2), we can get the Hamiltonian representation of the harmonic oscillator, which is
exactly the same as (2.4). The system energy is given by E(t) := H(q(t), p(t)). The
time derivative of E(t) is given by ˙E(t) = −2ζω0p(t)2, which is negative for every t.
Forced Hamiltonian equations can be derived from the Legendre transformation
of Euler–Lagrange equations with generalized forces. Alternatively, they can be di-
rectly obtained from the reformulation of d’Alembert’s principle in the Hamiltonian
coordinates.
In this paper, we take the second approach, since this approach also
gives us insight on reconstructing structure-preserving reduced models. Our deriva-
tion closely follows reference [14] (pp. 205–210), where generalized Euler–Lagrangian
equations are obtained from d’Alembert’s principle in the Lagrangian coordinates.
We shall begin with the structure of the vertical vector ﬁeld.

2.1. Force ﬁelds. Let H : V → R be a Hamiltonian function, XH : V → V
be the Hamiltonian vector ﬁeld associated to H, and πQ : V → Q, (q, p) 7→ q be the
canonical projection. A vector ﬁeld XF : V → V is called vertical if the projection of
XF is zero, i.e., πQ(XF ) = 0. Such a vector ﬁeld XF deﬁnes a one-form ∆F : V → V∗
by contraction with Ω: ∆F = −iXF Ω. For any vertical vector ﬁeld u on V, if the
duality paring ∆F · u = 0, then we say ∆F is horizontal. Here, we use the dot product
to represent the duality paring of V∗ and V.

Proposition 2.1.

If XF is vertical, then the corresponding one-form ∆F is
horizontal. Conversely, given a horizontal one-form ∆F on V, the vector ﬁeld XF on
V, given by ∆F = −iXF Ω, is vertical.

Proof. Let XF = (fq, fp) and u = (uq, up), where fq, uq, ∈ Q and fp, up ∈ Q∗.

Using the deﬁnition of Ω, we have

(2.5)

∆F · u = −iXF Ω(u) = −Ω((fq, fp), (uq, up)) = −hup, fqi + hfp, uqi.

If u is vertical, uq = 0. Thus, ∆F ·u = 0 for every vertical u is equivalent to hup, fqi = 0
for every up, which holds if and only if fq = 0, i.e., the vector ﬁeld XF is vertical.

Proposition 2.2. A force ﬁeld fH : V → Q∗ induces a horizontal one-form ∆F

on V by

(2.6)

∆F · u = hfH , πQ(u)i,

where u is a vector ﬁeld on V. Conversely, formula (2.6) deﬁnes a map fH for any
horizontal one-form ∆F .

Proof. Given fH , (2.6) deﬁnes a smooth one-form ∆F on V. If u is vertical, then
the right-hand side of (2.6) vanishes, and so ∆F is horizontal. Conversely, if ∆F is
a horizontal one-form on V, ∆F · (uq, up) = ∆F · (uq, 0) + ∆F · (0, up) = ∆F · (uq, 0)
for any vector ﬁeld u = (uq, up). Thus, (2.6) is equivalent to hfH , uqi = ∆F · (uq, 0).
Since h·, ·i is nondegenerate, fH is well-deﬁned and smooth.

Propositions 2.1 and 2.2 imply that a force ﬁeld fH introduces a horizontal one-
form ∆F , which in turn determines a vertical vector ﬁeld XF . Using canonical co-
ordinates, if fH (q, p) ∈ Rn denotes a force ﬁeld, then a horizontal one-form is given
by ∆F (q, p) = (fH (q, p), 0). By contraction with Ω, the corresponding vertical ﬁeld is
given by XF (q, p) = −J2n∆F (q, p) = (0, fH (q, p)). Treating ∆F (q, p) as the external
force term on a mechanical system with a Hamiltonian H, we will next derive the
equation of motion by d’Alembert’s principle.

STRUCTURE-PRESERVING MODEL REDUCTION

5

2.2. D’Alembert’s principle. D’Alembert’s principle is a statement of the
fundamental law of motion in classical mechanics. It is more general than Hamilton’s
principle since it considers both internal and external forces. In Newton’s coordinates,
the principle can be written as

(2.7)

Σi(Fi − ˙pi) · ri = 0,

where Fi is the total applied force (excluding constraint forces) on the i-th particle,
pi is the momentum of the i-th particle, and δri is the virtual displacement of the i-th
particle which is consistent with the constraints. We shall reformulate d’Alembert’s
principle by Hamiltonian coordinates.

Definition 2.3. Given a Hamiltonian function H(q, p) and a horizontal one-
form ∆F (q, p), the integral d’Alembert’s principle for a trajectory (q(t), p(t)) in V
is

(2.8)

δZ b

a

L(q(t), p(t))dt +Z b

a

∆F (q(t), p(t)) · (δq, δp)dt = 0,

where (δq, δp) is a variation on V, and L : V → R is the Lagrangian function deﬁned
by L(q, p) = hp, ˙qi − H(q, p).

The variation of the ﬁrst term is given by the usual expression

δZ b

a

L(q, p)dt = Z b
= Z b
= Z b

a

a

a

hp, δ ˙qi + hδp, ˙qi − (∇qH(q, p), ∇pH(q, p)) · (δq, δp)dt

hp, δ ˙qi + hδp, ˙qi − h∇qH(q, p), δqi − hδp, ∇pH(q, p)idt

h− ˙p − ∇qH(q, p), δqi + hδp, ˙q − ∇pH(q, p)idt

for a given variation (δq, δp), which vanishes at the endpoints. Since the external
force ∆F (q, p) is horizontal, Proposition (2.6), implies that

∆F (q, p) · (δq, δp) = hfH(q, p), δqi,

where fH is the force ﬁeld corresponding to ∆F . Thus, (2.8) gives

(2.9)

Z b

a

h− ˙p − ∇qH(q, p) + fH (q, p), δqi + h ˙q − ∇pH(q, p), δpidt = 0.

Therefore, the trajectory of the integral d’Alembert’s principle is given by the forced
Hamiltonian equation (2.2).

We can also formulate an equivalent principle in terms of one-forms.

Definition 2.4. Given a Hamiltonian function H(x) and a horizontal one-
form ∆F (x), the local d’Alembert’s principle for the ultimate equation of motion,
˙x(t) = X(x(t)), is determined by

(2.10)

iX Ω(x) = dH(x) − ∆F (x),

where X denotes the forced Hamiltonian vector ﬁeld on V .

6

LIQIAN PENG AND KAMRAN MOHSENI

Proposition 2.5. The two forms of d’Alembert’s principle are equivalent, i.e.,

they give the same equation of motion.

Proof. Let XF denote the vector ﬁeld associated to ∆F , i.e., ∆F = −iXF Ω. Since

∆F is horizontal, XF is vertical. Since dH = iXH Ω,

(2.11)

X(x) = XH (x) + XF (x)

satisﬁes the local d’Alembert’s principle. Conversely, the only vector ﬁeld X satisfying
the local d’Alembert’s principle is given by (2.11), and uniqueness is guaranteed by
nondegeneracy of Ω. Therefore, both the integral and local forms of d’Alembert’s
principle give the same vector ﬁeld for the equation of motion ˙x(t) = X(x(t)).

From now on, we will refer to both (2.8) and (2.10) as simply d’Alembert’s prin-
ciple. By the above analysis, if a system satisﬁes d’Alembert’s principle, the equation
of motion is given by the forced Hamiltonian equation. Conversely, if a system is
represented by a forced Hamiltonian equation, it automatically satisﬁes d’Alembert’s
principle. Since d’Alembert’s principle is the ﬁrst principle in classical mechanics, any
mechanical system can be represented by a forced Hamiltonian equation. If a vector
ﬁeld X can be represented by the sum of a Hamiltonian vector ﬁeld XH and a verti-
cal vector ﬁeld XF , we say X has forced Hamiltonian structure. In the next section,
we develop a new model reduction method which preserves the forced Hamiltonian
structure.

3. Reduction and reconstruction of dynamics. In this section, we propose
two methods to construct reduced dynamics in a low-dimensional subspace. The ﬁrst
approach is based on the variational principle, which is closely related to the inte-
gral d’Alembert’s principle; the second approach is based on the structure-preserving
projection, which is closely related to the local d’Alembert’s principle. Both methods
take advantage of empirical data to construct a reduced system, while simultaneously
preserving the underlying forced Hamiltonian structure. In other words, if the orig-
inal system is a forced Hamiltonian equation, the reduced system remains a forced
Hamiltonian equation, but with signiﬁcantly fewer dimensions.

3.1. Variational principle. In the context of Lagrangian mechanics, the vari-
ational principle was used to yield reduced systems while preserving the Lagrangian
structure [11, 4]. The idea is to insert q = Φr into the Lagrangian to obtain a reduced
system in terms of r. Here, Φ ∈ Rn×k denotes a POD basis matrix and r ∈ Rk denotes
the reduced coordinates. Since ˙q is the time derivative of q, it is ﬁxed by ˙q = Φ ˙r. The
Hamiltonian approach provides more ﬂexibility, since q and p have the same status in
the phase space.

Let (V, Ω) and (W, ω) be two symplectic vector spaces; dim(V) = 2n, dim(W) =
2k, and k ≤ n. Using canonical coordinates, a lift σ : V → W, z 7→ x can be written
as

(3.1)

x = Az,

where A ∈ R2n×2k. Using the block form, z = (r, s), x = (q, p), and

(3.2)

Apq App(cid:21) .
A = (cid:20)Aqq Aqp

Then, the map x = σ(z) is represented by

(cid:20)q
p(cid:21) = (cid:20)Aqq Aqp

Apq App(cid:21)(cid:20)r

s(cid:21) = (cid:20)Aqqr + Aqps
Apqr + Apps(cid:21) .

STRUCTURE-PRESERVING MODEL REDUCTION

7

In order to construct a reduced equation, we can plug q = Aqqr + Aqps and p =
Apqr + Apps into (2.8) and take the variation on (δr, δs). This yields

M (cid:20) ˙r

˙s(cid:21) = (cid:20)∇r ˜H(r, s)

∇s ˜H(r, s)(cid:21) −(cid:20)AT

qq
AT
qp

˜fH (r, s)
˜fH (r, s)(cid:21) ,

where ˜H(r, s) = H(Aqqr+Aqps, Apqr+Apps), ˜fH (r, s) = fH (Aqqr+Aqps, Apqr+Apps),
and

M = (cid:20)AT

AT

pqAqq − AT
ppAqq − AT

qqApq AT
qpApq AT

pqAqp − AT
ppAqp − AT

qqApp

qpApp(cid:21) .

Suppose M is invertible, we obtain

(3.3)

˙s(cid:21) = M −1(cid:20)∇r ˜H(r, s)
(cid:20) ˙r

∇s ˜H(r, s)(cid:21) − M −1(cid:20)AT

qq
AT
qp

˜fH (r, s)
˜fH(r, s)(cid:21) .

Equation (3.3) is the reduced system constructed by the variational principle. Next,
we add some constraints to A such that (3.3) preserves the forced Hamiltonian struc-
ture.

Definition 3.1. Let (V, Ω) and (W, ω) be two symplectic vector spaces; dim(V) =
2n, dim(W) = 2k, and k ≤ n. A lift σ : W → V is called symplectic if it preserves
the symplectic structure:

(3.4)

ω(z, w) = Ω(σ(z), σ(w)),

for every z, w ∈ W.

Let A denote the matrix form of σ in canonical coordinates, then (3.4) implies

(3.5)

AT J2nA = J2k.

In this case, we say the matrix A is symplectic, written as A ∈ Sp(2k, R2n), where

(3.6)

Sp(2k, R2n) := {A ∈ R2n×2k|AT J2nA = J2k}

denotes the symplectic Stiefel manifold.

The symplectic condition can also be represented in block form by plugging (3.2)

into (3.5).

Proposition 3.2. The matrix A = [Aqq, Aqp; Apq, App] is symplectic if and only
qqApq and AT

qpApp are symmetric and AT

qqApp − AT

pqAqp = Ik.

if AT

The next lemma gives a suﬃcient and necessary condition such that the variational

approach is structure-preserving for any forced Hamiltonian equations.

Lemma 3.3. The reduced equation (3.3) constructed by the variational principle
preserves the forced Hamiltonian structure for any Hamiltonian functions H(q, p) and
force ﬁelds fH(q, p) if and only if A ∈ Sp(2k, R2n) and Aqp = 0.

Proof. If A ∈ Sp(2k, R2n) and Aqp = 0, then (3.3) reduces to

(3.7)

˙s(cid:21) = J2n(cid:20)∇r ˜H(r, s)
(cid:20) ˙r

∇s ˜H(r, s)(cid:21) +(cid:20)

0

˜fH (r, s)(cid:21) .

AT
qq

8

LIQIAN PENG AND KAMRAN MOHSENI

where ˜H(r, s) represents the reduced Hamiltonian function and AT
qq
the reduced force ﬁeld.

˜fH(r, s) represents

Conversely, suppose that the reduced equation (3.3) preserves the forced Hamil-
tonian structure for any high-dimensional systems of the form (2.2). Let fH(q, p) = 0,
then (3.3) reduces to

(3.8)

˙s(cid:21) = M −1(cid:20)∇r ˜H(r, s)
∇s ˜H(r, s)(cid:21) .
(cid:20) ˙r

If this equation is Hamiltonian for any ˜H(r, s), we must have M −1 = J2k. By Propo-
sition 3.2, M −1 = J2k is equivalent to A ∈ Sp(2k, R2n). Now we plug M −1 = J2k
into (3.3).
If the second term on the right-hand side of (3.3) is a vertical, then
AT
qp

˜fH (q, p) = 0. Since ˜fH (q, p) can be arbitrary, this implies that Aqp = 0.

3.2. Structure-preserving projection. In [18], the symplectic projection was
proposed to construct reduced models for Hamiltonian equations while preserving
the symplectic structure.
In this section, we extend the symplectic projection to
structure-preserving projection of forced Hamiltonian systems. The idea is to add
some constraints to the symplectic projection so that the new projection also preserves
the structure of the vertical vector ﬁeld.

3.2.1. Symplectic projection. We begin with the basic deﬁnition of the sym-

plectic projection.

Definition 3.4. Suppose σ : W → V is a symplectic lift. Then the adjoint of σ

is the linear mapping π : V → W satisfying

(3.9)

ω(w, π(x)) = Ω(σ(w), x),

for every w ∈ W and x ∈ V. We say π is the symplectic projection induced by σ.

Using canonical coordinates, σ can be represented by a symplectic matrix A.

Then, the symplectic projection π : x 7→ z can be written as

(3.10)

z = A+x,

where A+ ∈ R2k×2n. Equation (3.9) implies that J2kA+ = AT J2n. Since J2k is
invertible, it follows that

(3.11)

A+ = J T

2kAT J2n.

Since AT J2nA = J2k, A+ is a left inverse of A, i.e.,

(3.12)

A+A = I2k.

In general, A+ is not equal to the Moore–Penrose pseudoinverse (AT A)−1AT , and the
left inverse of A is not unique. However, since Ω and ω are nondegenerate, A+ is the
unique adjoint matrix of A with respect to the Poisson matrices J2n and J2k.

Equation (3.12) implies that π◦σ = idW. Since (σ◦π)◦(σ◦π) = σ◦(π◦σ)◦π = σ◦π,

σ ◦ π deﬁnes a projection operator on V.

Proposition 3.5. Suppose σ : W → V is a symplectic lift and π : V → W is a

symplectic projection introduced by σ. Then

(3.13) Ω(u, (σ ◦ π)(v)) = Ω((σ ◦ π)(u), v) = Ω((σ ◦ π)(u), (σ ◦ π)(v)) = ω(π(u), π(v)),

STRUCTURE-PRESERVING MODEL REDUCTION

9

for every u, v ∈ V.

Proof. Using canonical coordinates, (3.13) can be rewritten as

(3.14) uT J2nAA+v = (AA+u)T J2nv = (AA+u)T J2n(AA+v) = (A+u)T J2k(A+v),

which can be veriﬁed by replacing A+ with (3.11).

Since Ω is skew-symmetric, Proposition 3.5 implies that

Ω(u, (σ ◦ π)(u)) = Ω((σ ◦ π)(u), u) = 0.

As a consequence, for every u, v ∈ V,

(3.15)

Ω(u, (σ ◦ π)(u + v)) = Ω(u, (σ ◦ π)(v)).

The symplectic projection deﬁnes a mapping from a high-dimensional space to a
low-dimensional space. The same projection can also be applied a high-dimensional
Hamiltonian system to obtain a reduced system while preserving the symplectic struc-
ture.

To see this, suppose the original system is Hamiltonian, i.e., ˙x = XH (x). Suppose
x = Az. Using the chain rule, we obtain ∇zH(Az) = AT ∇xH(x). Using A+J2n =
J2kAT , we obtain the symplecitc projection of the tangent vector at x,
(3.16)

π(XH (x)) = A+J2n∇xH(x) = J2kAT ∇xH(x) = J2k∇zH(Az) = J2k∇z ˜H(z),

where ˜H(z) := H(Az) deﬁnes a Hamiltonian function on W. Since X ˜H (z) :=
J2k∇z ˜H(z) gives a Hamiltonian vector ﬁled on W, the reduced system ˙z = X ˜H(z) is
a well-deﬁned and preserves the symplectic structure.

With some extra constraints, the next section shows that the symplectic projec-
tion can also be applied to a forced Hamiltonian system to construct a reduced system
while preserving the structure of the vertical vector ﬁeld.

3.2.2. Structure-preserving projection. For a forced Hamiltonian system,
the corresponding vector ﬁeld is given by X(x) = XH (x) + XF (x) at each x ∈ V.
Then, we can deﬁne a reduced vector ﬁeld by

(3.17)

π(X(σ(z))) = π(XH (σ(z))) + π(XF (σ(z))),

at each z ∈ W. If σ and π respectively represent the symplectic lift and symplectic
projection, the last section shows that π(XH (σ(z))) gives a Hamiltonian vector ﬁeld
on W. Thus, if the reduced system preserves the forced Hamiltonian structure, we
only need π(XF (σ(z))) to be a vertical vector ﬁeld on W.

In block form, A+ can be written as

(3.18)

A+ = (cid:20) AT

−AT

pp −AT
qp
pq AT

qq (cid:21) .

It follows that the projection X ˜F (z) of the vertical vector ﬁeld XF at Az is given by

(3.19)

X ˜F (z) = A+XF (Az) = (cid:20) AT

−AT

pp −AT
qp
pq AT

qq (cid:21)(cid:20)

0

fH(Az)(cid:21) = (cid:20)−AT

qpfH (Az)

qqfH (Az) (cid:21) .

AT

Thus, the symplectic projection preserves the forced structure, i.e., πXF (Az) is ver-
tical if and only if AT

qpfH (Az) = 0 for any fH (Az). This is equivalent to Aqp = 0.

10

LIQIAN PENG AND KAMRAN MOHSENI

Definition 3.6. Let z ∈ W and x ∈ V. Using the canonical coordinates, a linear
mapping π : x 7→ z is a structure-preserving projection if there exists a symplectic
matrix A ∈ Sp(2k, R2n) with Aqp = 0, such that

(3.20)

z = A+x.

Now, suppose A ∈ Sp(2k, R2n), Aqp = 0, and x(t) ∈ Range(A) for every t. Then,
x(t) = Az(t). Taking the time derivative of z = A+x and using (2.3), the time
evolution of z(t) is given by

(3.21)

˙z = π ˙x = πXH (x) + πXF (x) = X ˜H(z) + X ˜F (z).

Even if x(t) /∈ Range(A) for some t, the last expression is still well-deﬁned forced
Hamiltonian vector ﬁeld. Thus, the reduced system constructed by the structure-
preserving projection preserves the forced Hamiltonian structure.

Remark 3.7. Both the variational principle and the structure-preserving pro-
jection methods requires that A ∈ Sp(2k, R2n) and Aqp = 0, which means that the
two methods can share the same basis matrix A. Let z = (r, s), then (3.7) and (3.21)
deﬁne the same system on the subspace spanned by the column vectors of A. Thus,
two methods construct the same reduced system. From now on, we do not distinguish
the variational principle and the structure-preserving projection when we mention a
structure-preserving reduced model.

Definition 3.8. Given a 2n-dimensional forced Hamiltonian system (2.3) with

an initial condition x0 ∈ R2n, the structure-preserving reduced model is a 2k-dimensional
(k ≤ n) system

(3.22)

˙z = X ˜H (z) + X ˜F (z),

with the initial condition z0 = A+x0 ∈ R2k, where A ∈ Sp(2k, R2n), Aqp = 0, X ˜H (z)
and X ˜F (z) respectively represent the Hamiltonian vector ﬁeld and the vertical vector
on R2k.

Remark 3.9. The vertical vector ﬁeld X ˜F deﬁnes a horizonal one-form ∆ ˜F by

contraction with ω, i.e., ∆ ˜F = −iX ˜F ω. It follows that

(3.23)

iZω = d ˜H − ∆

˜F .

This veriﬁes that the reduced system constructed by the structure-preserving projec-
tion also satisﬁes the local d’Alembert’s principle.

Remark 3.10. Suppose π is a structure-preserving projection. Then, there exists
a symplectic matrix A ∈ Sp(2k, R2n) with Aqp = 0. In the block form, this implies
that

(3.24)

A = (cid:20)Aqq

Apq App(cid:21) ,

0

qqApq is symmetric, and AT

AT
has the form

qqApp = Ik. Using (3.24), the projection operator σ ◦ π

(3.25)

AA+ = (cid:20)

AqqAT
pp
pp − AppAT

ApqAT

0

qq(cid:21) ,

pq AppAT

STRUCTURE-PRESERVING MODEL REDUCTION

11

which gives an invariant subspace, 0 ⊕ Q∗, of V. Thus, all vectors u ∈ 0 ⊕ Q∗ are
transformed by σ ◦ π into vectors that are also contained in 0 ⊕ Q∗. This can be stated
as

(3.26)

u ∈ 0 ⊕ Q∗ ⇒ (σ ◦ π)(u) ∈ 0 ⊕ Q∗.

3.3. Proper symplectic decomposition (PSD). PSD is an empirical model
reduction technique, where the empirical data is used to construct a symplectic basis
matrix A. Let q(ti), p(ti) ∈ Rn (i = 1, . . . , N ) denote the empirical data. Assume
n ≥ 2N . Rewriting the state variable in the form x(ti) = [q(ti); p(ti)], we can deﬁne
a snapshot matrix in R2n×N ,

(3.27)

Mx := [x(t1), . . . , x(tN )].

The structure-preserving projection of Mx onto a low dimensional subspace is given
by Mz = A+Mx, where A ∈ Sp(2k, R2n), Mz = [z(t1), . . . , z(tN )] ∈ R2k×N , and
z(ti) = A+x(ti). The same projection of Mx in the original coordinates is given by
AMz, or AA+Mx.

The Frobenius norm k · kF can be used to measure the error between Mx and its
projection AMz. Suppose a symplectic matrix A minimizes the projection error in a
least squares sense. Then, A is a solution of the following optimization problem:

(3.28)

kMx − AA+MxkF

minimize
subject to AT J2nA = J2k

and Aqp = 0.

Let Mq = [q(t1), . . . , q(tN )] and Mp = [p(t1), . . . , p(tN )]. Using (3.25), the cost

function in (3.28) can be expanded as

kMq − AqqAT

ppMqkF + kMp − (ApqAT

pp − AppAT

pq)Mq − AppAT

qqMpkF .

By Remark 3.7, the constraint in (3.28) holds if and only if AT
AT
(3.29)

qqApp = Ik. Thus, (3.28) is equivalent to

qqApq is symmetric and

minimize
subject to AT

kMq − AqqAT
qqApq = AT

ppMqkF + kMp − (ApqAT
pqAqq

and AT

qqApp = Ik.

pp − AppAT

pq)Mq − AppAT

qqMpkF

Since matrices Aqq, Apq and Aqq all have n × k elements and the constraint
region is nonconvex, it is expected to be quite expensive to solve (3.29) by nonconvex
nonlinear programming. To this eﬀect, we use a singular value decomposition (SVD)-
based method, cotangent lift, to construct a near optimal symplectic matrix in a
subset of Sp(2k, R2n) with Aqp = 0. The idea is to search for the optimal matrix, A1,
in a subset of Sp(2k, R2n) with Aqp = 0, such that all the empirical data lies near
Range(A1). In particular, we assume that

(3.30)

Aqp = Apq = 0

and Aqq = Aqq = Φ.

Then, A1 = diag(Φ, Φ) for some Φ ∈ Rn×k.
AT

It is straightforward to verify that
1 J2nA1 = J2k if and only if ΦT Φ = Ik. Under these assumptions, (3.29) reduces to

(3.31)

kMq − ΦΦT MqkF + kP − ΦΦT P kF

minimize
subject to ΦT Φ = Ik.

12

LIQIAN PENG AND KAMRAN MOHSENI

The cost function in (3.31) equals kMq,p − ΦΦT Mq,pkF , where

(3.32)

Mq,p := [q(t1), . . . , q(tN ), p(t1), . . . , p(tN )]

deﬁnes an extended snapshot matrix Mq,p ∈ Rn×2N .

Algorithm 1 Cotangent Lift
Require: An empirical data ensemble {q(ti), p(ti)}N
Ensure: A symplectic matrix A1 in block-diagonal form.

i=1.

1: Construct an extended snapshot matrix Mq,p as (3.32).
2: Compute the SVD of Mq,p to obtain a POD basis matrix Φ.
3: Construct the symplectic matrix A1 = diag(Φ, Φ).

If Φ∗ denotes the optimal value of Φ in (3.31), Φ∗ can be directly solved by the
SVD of Mq,p. Thus, the cotangent lift method simpliﬁes the optimization problem
(3.28) to an SVD problem. Algorithm 1 lists the detailed procedure of the cotangent
lift method. Since the SVD of a n×m (n ≥ m) matrix requires 2nm2 +2m3 operations
[22], the computational cost of Algorithm (1) is 8nN 2 + 16N 3, which is linearly
dependent on n.

The cost function in (3.31) is also equal to the projection error of the empirical
data in the Frobenius norm kMx − AA+MxkF . Let λ1 ≥ λ2 ≥ . . . ≥ λ2N ≥ 0 denote
the singular values of Mq,p in decreasing order. Then, the projection error of the
cotangent lift method is determined by the truncated singular values of Mq,p,

(3.33)

E(2k)

COT = (cid:13)(cid:13)(cid:13)

(I − Φ∗Φ∗T )Mq,p(cid:13)(cid:13)(cid:13)F

= vuut

2N

Xi=k+1

λ2
i ,

where we use the superscript 2k to emphasize that the symplectic subspace spanned
by the column vectors of A1 = (diag(Φ, Φ) has dimension 2k.

Proposition 3.11. Let E(2k)

OPT denote the projection error
by the cotangent lift method, POD, and the nonlinear programming method to solve
(3.28), respectively. Then,

POD, and E(2k)

COT, E(2k)

(3.34)

1
2

E(4k)

cot ≤ E(2k)

POD ≤ E(2k)

OPT ≤ E(2k)
COT.

Proof. The cotangent lift method yields an optimal symplectic matrix in M1 :=
{A ∈ R2n×2k : A = diag(Φ, Φ), Φ = Rn×k, and ΦT Φ = Ik}. The feasible set of the
optimization problem (3.28) is given by M := {A ∈ R2n×2k : AJ2nA = J2k and Aqp =
0}. POD can ﬁnd the most optimal matrix in R2n×2k to minimize the projection
error. Thus, corresponding to M1 ⊂ M ⊂ R2n×2k, we have E(2k)

OPT ≤ E(2k)
COT.
i=2k+1 λ2
i .
Similar, if σ1 ≥ σ2 ≥ . . . ≥ σN ≥ 0 denotes all the singular values of Mx in descending
order, then (E2k

POD. According to (3.33), (E(4k)

cot )2 = P2N

Next we will prove 1

POD ≤ E(2k)

cot ≤ E(2k)

Since Mq,p = (cid:20)Q
i }2N
i=1. Since Mx = (cid:2)Q P(cid:3), M T
i=1. By the construction, both M T
i }N

P T Q P T P(cid:21) ∈ R2N ×2N , with eigenvalues
x Mx = QT Q + P T P ∈ RN ×N , with eigenvalues
x Mx are positive-semideﬁnite.

q,pMq,p and M T

{λ2
{σ2

2 E(4k)
POD)2 = PN
P(cid:21), M T

i=k+1 σ2
i .
q,pMq,p = (cid:20)QT Q QT P

STRUCTURE-PRESERVING MODEL REDUCTION

13

x Mx}, then S is also positive-semideﬁnite, and the ith largest

Let S = diag{M T
eigenvalue of S is (σ⌈ i

x Mx, M T

2 ⌉)2. Moreover,
q,pMq,p = (cid:20)2M T

2S − M T

0
2M T

x Mx
0

x Mx(cid:21) −(cid:20)QT Q QT P
P T Q P T P(cid:21)
P T P(cid:21)
P T P(cid:21) .

= (cid:20) QT Q −QT P
= (cid:20) QT

−P T Q P T P (cid:21) + 2(cid:20)P T P
−P T(cid:21)(cid:2)Q −P(cid:3) + 2(cid:20)P T P

0

0

0

0

The last equation implies that 2S ≥ M T
largest eigenvalue of 2S is greater than the ith largest eigenvalue of M T
implies that 2(σ⌈ i

q,pMq,p ≥ 0. By the min-max theorem, the ith
q,pMq,p. This

i . It follows that

2 ⌉)2 ≥ λ2

(E(4k)

cot )2 =

2N

Xi=2k+1

λ2
i ≤ 2

2N

Xi=2k+1

(σ⌈ i

2 ⌉)2 = 4

N

Xi=k+1

i = 4(E(2k)
σ2

POD)2.

This completes the proof.

3.4. Energy preservation. Let x(t) be the solution of (2.3) with x(0) = x0, and
E(t) = H(x(t)) be the corresponding system energy at time t. Since dH(x) · XH (x) =
Ω(XH (x), XH (x)) = 0, the time derivative of E(t) equals

(3.35)

˙E(t) = dH · X|x(t) = dH · XF |x(t).

Thus, the time derivative of system energy is completely determined by the Hamilto-
nian function H(x) and the vertical vector ﬁeld XF (x).

Proposition 3.12. The time derivative of E(t) can also be represented in terms

of the force ﬁeld, i.e.

(3.36)

dH · XF |x = hfH , ˙qi|x,

where ˙q(x) = πQ(XH (x)) = ∇pH(q, p).

Proof. Let XF be a vertical vector ﬁeld. By Proposition 2.1, XF induces a
horizontal one-form ∆F = −iXF Ω on V; by Proposition 2.2, ∆F in turn induces a
force ﬁeld fH, which is given by

(3.37)

hfH , πQ(u)i = ∆F · u = −Ω(XF , u),

where u is a vector ﬁeld on V. Let XH denote the Hamiltonian vector ﬁeld. Then,

dH · XF = (iXH Ω) · XF = Ω(XH , XF ) = −Ω(XF , XH ) = hfH , πQ(XH ))i,

which gives (3.36).

Let ˜E(t) = ˜H(z(t)) denote the system energy of the forced Hamiltonian system
(3.22) in reduced coordinates. Similar to (3.35), the time derivative of ˜E(t) is given
by

(3.38)

˙˜E(t) = d ˜H · X ˜F |z(t).

Theorem 3.13. The reduced forced Hamiltonian system exactly preserves the
time derivative of system energy at z ∈ W, i.e. d ˜H · X ˜F |z = dH · XF |σ(z), if any one
of the following conditions is satisﬁed at σ(z):

14

LIQIAN PENG AND KAMRAN MOHSENI

(a) (σ ◦ π)(XF ) = XF .

(b) (σ ◦ π)(XH ) = XH.

(c) (σ ◦ π)(XH ) = X.

(d) (πP ◦ σ ◦ π)(XF ) = πP (XF ).

(e) (πQ ◦ σ ◦ π)(XH ) = πQ(XH ).
Proof. Using (3.13), we obtain

d ˜H · X ˜F |z = ω(X ˜H , X ˜F )|z = ω(π(XH (σ(z))), π(XF (σ(z))))

(3.39)

= Ω(XH , (σ ◦ π)XF )|σ(z)
= Ω((σ ◦ π)XH , XF )|σ(z).

If (a) or (b) holds, the second or third line of (3.39) would imply that d ˜H · X ˜F |z =
Ω(XH , XF )|σ(z), which equals dH · XF |σ(z).

Using (3.15), the time derivative of system energy for the reduced system can be

represented by

(3.40)

d ˜H · X ˜F |z = Ω(XH , (σ ◦ π)(XH + XF ))|σ(z) = Ω(XH , (σ ◦ π)(X))|σ(z).

This implies that (c) is a suﬃcient condition to preserves the time derivative of system
energy.

Since both XF and (σ ◦ π)XF are vertical vector ﬁelds, we have πQ((σ ◦ π)XF ) =

πQ(XF ) = 0. Thus, (a) is equivalent to (d).
Finally, by (3.39) and (3.37), we obtain

d ˜H · X ˜F |z = Ω((σ ◦ π)(XH ), XF )|σ(z) = −Ω(XF , (σ ◦ π)(XH ))|σ(z)

= hfH , πQ((σ ◦ π)(XH ))i|σ(z).

Thus, if (e) is satisﬁed, the time derivative of system energy is preserved as well.

3.4.1. Optimization of the basis matrix. Theorem 3.13 implies that the time
derivative of system energy is exactly preserved when the vector ﬁelds XH, XF , X,
or their vertical/horizontal components are invariant under the projection operator
σ ◦ π. Motivated by this, we formulate ﬁve optimization problems corresponding to
each individual condition in Theorem 3.13. All the optimization problems seek to
construct a symplectic basis matrix A such that one of the aforementioned vector
ﬁelds (or their vertical/horizontal components) can lie near the subspace spanned by
the column vectors of A.

Condition (a). The condition (a) can be written as AA+XF = XF in canonical
coordinates, which requires that XF (Az) ∈ Range(A) for each z. To satisfy this
condition approximately, we can construct an extended data ensemble,

(3.41)

Mx,XF := [x(t1), . . . , x(tN ), XF (x(t1)), . . . , XF (x(tN ))],

and then construct a symplectic matrix A to ﬁt each column vector of Mx,XF by
solving the following optimization problem:

(3.42)

kMx,XF − AA+Mx,XF kF

minimize
subject to AT J2nA = J2k

and Aqp = 0.

STRUCTURE-PRESERVING MODEL REDUCTION

15

Condition (b). Replacing XF (resp., Mx,XF ) with XH (resp., Mx,XH ) in (3.41)
and solving (3.42) to minimize Mx,XH will yield a symplectic matrix A to satisfy (b)
approximately.

Condition (c). If we replace XF with X in (3.41), then (c) will be approximately
satisﬁed by the similar procedure. In this case, the symplectic matrix A is constructed
to ﬁt both the solution snapshots x and time derivative X of x simultaneously to
preserve the time derivative of system energy. In previous literature, the analogous
idea of incorporating time derivative snapshots [3, 17] or diﬀerence quotients [9, 10, 8],
into the data ensemble has been widely used to enhance the performance (such as
convergence and accuracy) of POD reduced models.

Condition (d). In order to approximately satisfy (d), we ﬁrst construct a data

ensemble in Rn×N for the force ﬁeld

(3.43)

MfH := [fH (x(t1)), . . . , fH(x(tN ))].

Since the vertical vector ﬁeld XF (x) can be represented by XF (x) = [0; fH(x)], the
corresponding data ensemble for the vertical vector ﬁeld is given by

(3.44)

MXF := (cid:20) 0

MfH(cid:21) ,

where MXF ∈ R2n×N . Thus, an optimal value of A can be obtained by minimizing a
cost function that is related to the projection error of x and πP (XF (x)). In particular,
the cost function can be formulated as

(3.45)

kMx − AA+MxkF + γkIP MXF − IP AA+MXF kF ,

where Ip = [0, In] ∈ Rn×2n is the matrix representation of πP , and γ is a weighting
coeﬃcient to balance the truncation of Mx and IP MXF . Replacing AA+ by (3.25)
simpliﬁes the cost function (3.45) to

(3.46)

kMx − AA+MxkF + γkMfH − AppAT

qqMfH kF .

When γ = 1, the cost functions in (3.42) and (3.46) are exactly the same.

Condition (e). In order to satisfy (e) approximately, one can construct a data
ensemble that contains ∇pH(x), and form an optimization function in terms of IQ =
[In, 0] ∈ Rn×2n.

While nonconvex nonlinear programming can result in the most optimal subspace
to ﬁt an extended data ensemble, considering A is a matrix with 2n × 2k elements,
the programming problem can be very expensive and even intractable. Thus, we shall
propose a cotangent lift method to obtain a near optimal value of A at a relatively
lower cost while simultaneously preserving the time derivative of system energy.

3.4.2. Cotangent lift with energy preservation. The cotangent lift method
can simplify all the optimization problems mentioned in the previous section. As an
example, we shall give a cotangent lift algorithm to minimize the cost function (3.46)
with γ = 1, such that (a) and (d) can be satisﬁed.

The cotangent lift methods requires that Aqp = Apq = Φ and Aqq = App = Φ,
where Φ is an orthonormal matrix. Then, q, p, and fH have the same status in the
cost function, and all the data of q, p, and fH should lie near the Range of A. As
a result, the k columns of Φ can be obtained from the left singular vectors of the
following data ensemble

(3.47) Mq,p,fH := [q(t1), . . . , q(tN ), p(t1), . . . , p(tN ), fH (x(t1)), . . . , fH (x(tN ))].

16

LIQIAN PENG AND KAMRAN MOHSENI

Algorithm 2 Cotangent lift with energy preservation
Require: An empirical data ensemble {q(ti), p(ti), fH (x(ti))}N
Ensure: A symplectic matrix A1 in block-diagonal form.

i=1.

1: Construct an extended snapshot matrix Mq,p,fH as (3.47).
2: Compute the SVD of Mq,p,fH to obtain a POD basis matrix Φ.
3: Construct the symplectic matrix A1 = diag(Φ, Φ).

Algorithm 2 lists the detailed procedure for the cotangent lift method for the
preservation of the time derivative of system energy. Since this algorithm is based on
SVD, the reconstruction error of the time derivative of system energy at x = σ(z) can
be estimated by the following:

kdH · XF |x − d ˜H · X ˜F |zk = kΩ(XH, XF )|x − Ω(XH , (σ ◦ π)(XF ))|xk

≤ kXH(x)k · kXF (x) − AA+XF (x)k
= kXH(x)k · kfH(x) − AppAT

qqfH (x)k.

In a compact subset M of V, we can assume kXH(x)k to be uniformly bounded. If the
data set of fH(x) is representative at the solution trajectory, kfH (x) − AppAT
qqfH(x)k
is bounded by a constant multiplied by the truncated singular values of (3.47).

4. Reduction of dissipative Hamiltonian systems. In this section, we dis-
cuss a special form of forced Hamiltonian systems where the vertical vector ﬁeld is
dissipative. We also prove that the proposed model reduction method preserves the
stability of the dissipative Hamiltonian system.

4.1. Dissipative Hamiltonian systems. We begin with the deﬁnition of a

dissipative vector ﬁeld.

Definition 4.1. A vertical vector ﬁeld XF on V is called dissipative if dH ·

XF |x ≤ 0 for every x ∈ V.

Proposition 3.12 implies that a vertical vector ﬁeld XF is dissipative if and only

if the corresponding force ﬁeld fH satisﬁes hfH, ˙qi|(q,p) ≤ 0 at all (q, p) ∈ V.

Definition 4.2. A forced Hamiltonian system (2.3) is dissipative if the vector
ﬁeld can be decomposed as X = XH + XF , where XH is a Hamiltonian vector ﬁeld
and XF is a dissipative vector ﬁeld.

By (3.35), if the vertical vector ﬁeld XF is dissipative, then ˙E(t) ≤ 0, which

means that the system energy is nonincreasing in time.

In the last section, based on the empirical data of XF , XH, X, or fH, we have
discussed several approaches to extend the snapshot matrix such that the reduced
model can quantitatively preserve the rate of energy dissipation.
In the absence
of the empirical data of vector ﬁelds, it is still desired for the reduced model to
qualitatively preserve the dissipativity. This implies that if the original system is
dissipative, then the reduced system should remain dissipative. Fortunately, when the
dissipation is Rayleigh dissipation, the aforementioned structure-preserving projection
automatically preserves the dissipativity, and this property is independent from the
data that is used to construct the basis matrix A.

The dissipative force often arises from Rayleigh dissipation function, which can

be written as

(4.1)

F (q, ˙q) =

1
2

˙qT R(q) ˙q

STRUCTURE-PRESERVING MODEL REDUCTION

17

in Lagrangian coordinates, where R(q) ∈ Rn×n is a symmetric positive-semideﬁnite
matrix. The force ﬁeld is then given by fL(q, ˙q) = −∇ ˙qF (q, ˙q) = −R(q) ˙q. Using the
Legendre transformation, we obtain fH(q, p) = −R(q) ˙q(q, p) in Hamiltonian coordi-
nates. Since

hfH , ˙qi|(q,p) = − ˙qT R ˙q|(q,p) ≤ 0,

this veriﬁes that the corresponding vertical vector ﬁeld XF is dissipative.

If the reduced system is constructed by the structure-preserving reduction, then
Aqp = 0 and q = Aqqr + Aqps = Aqqr. If follows that ˙q = Aqq ˙r. Using (3.7), the
reduced force ﬁeld is given by AT
qqR(Aqqr)Aqq ˙r. Thus, the rate of
qq
energy variation of the reduced system at (r, s) is given by

˜fH (r, s) = −AT

hAT
qq

˜fH, ˙ri|(r,s) = −hAT

qqR(Aqqr)Aqq ˙r, ˙ri|(r,s) = −(Aqq ˙r)T R(Aqqr)(Aqq ˙r)|(q,p) ≤ 0.

This veriﬁes that the reduced system preserves the dissipativity.

Dissipativity preservation often is a strong indicator for stability preservation, as

discussed in the next section.

4.2. Stability preservation. Let V = R2n be a conﬁguration space with the
standard topology induced by the Euclidean norm k · k. Let M be a subset of V.
Then the subspace topology in M is the same as the metric topology obtained by
restricting the Euclidean norm k · k to M . Since the Hamiltonian function H : V → R
is continuous, the restriction of H to M gives a continuous function HM : M → R.
Throughout this section, we assume that the forced Hamiltonian system is dissipative,
and the solution x(t) of the system lie in M for every t ≥ 0. We use E0 := H(x0) to
denote the system energy at t = 0.

Let x(R+) = {x(t) : t ≥ 0} denote the solution trajectory of a dissipative Hamil-
tonian system. We say the system is uniformly bounded if there exists a closed r-ball
Br := {x ∈ M : kxk ≤ r} centered at 0 such that x(R+) ⊂ Br. Under certain
conditions, the dissipative Hamiltonian system is uniformly bounded, as the following
three lemmas indicate.

Lemma 4.3. Let D := H −1

M ((−∞, E0]) = {x ∈ M : HM (x) ≤ E0} denote a
sublevel set of the Hamiltonian function HM : M → R. Let D0 be the connected
component of D that contains x0. If D0 is bounded, then the dissipative Hamiltonian
system is uniformly bounded.

Proof. Since H ◦ x : t 7→ HM (x(t)) gives a continuous function of t, the set
x(R+) = {x(t) : t ≥ 0} is path connected, hence it is connected. Since the forced
Hamiltonian system is dissipative, HM (x(t)) ≤ E0 for any t ≥ 0. This implies that
x(R+) ⊂ D. Since D0 is a connected component of D and D0 ∩ x(R+) contains x0,
the connected set x(R+) lies entirely within D0. Hence, if D0 is bounded, so is x(R+).

Lemma 4.4.

If there exists a bounded neighborhood U of x0 in M such that
E0 < HM (x) for every x on the boundary of U , then the dissipative Hamiltonian
system is uniformly bounded.

Proof. Let bdM (U ) denote the boundary of U in M , and clM (U ) denote the
closure of U in M . Since HM (x) > E0 for every x ∈ bdM (U ), we have D ⊂ M −
bdM (U ). Since U and M − clM (U ) form a separation of M − bdM (U ), as a connected
set, D0 must lie entirely within either U or M − clM (U ). Since x0 ∈ D0 ∩ U , the only
possible case is that D0 ⊂ U . Because U is bounded, so is D0. By Lemma 4.3, the
dissipative Hamiltonian system is uniformly bounded.

18

LIQIAN PENG AND KAMRAN MOHSENI

Lemma 4.5. If lim
x→∞

is uniformly bounded.

HM (x) = +∞ in M , then the dissipative Hamiltonian system

Proof. Suppose the system is not uniformly bounded. Then there exists an
increasing sequence of time {t1, t2, . . .} such that kx(ti)k > i for each i ∈ N+. By
assumption, HM (x) → +∞ as x → ∞. Thus, for any E0 ∈ R, there exists an n ∈ N+
such that as long as kxk > n, HM (x) > E0. This implies that HM (x(ti)) > E0 for
every i ≥ n. But if the system is dissipative, we must have HM (x(ti)) ≤ E0, which is
a contradiction.

Remark 4.6. If E0 is a regular value of HM : M → R, then the level set H −1

M (E0)
is an embedded codimension-1 submanifold in M by the regular value theorem, and
the sublevel set D is an embedded codimension-0 submanifold with boundary in M [12]
(pp. 120–121).

Let M = V. Then, Lemmas 4.3, 4.4, and 4.5 imply that under certain conditions,
the original dissipative Hamiltonian system is bounded. Moreover, if we respectively
replace x0 and E0 by x(t1) and H(x(t1)) for some t1 ∈ R, these lemmas still hold.

Next, we consider boundedness of the structure-preserving reduced model. Sup-
pose that the reduced system remains dissipative, x0 ∈ Range(A), and the initial
condition of the reduced system is given by z0 = A+x0. Let M = Range(A). Then,
Lemmas 4.3, 4.4, and 4.5 imply that under the same conditions, the reduced dissipa-
tive Hamiltonian system preserves the boundedness. In particular, in Lemma 4.3, if
the connected component D0 of H −1((−∞, E0]) in V is bounded, then the connected
component of D0 ∩M that contains x0 is bounded in M . In Lemma 4.4, if there exists
a bounded neighborhood U of x0 in V such that E0 < H(x) for every x ∈ bdV(U ),
then UM := U ∩ M is a neighborhood of x0 in M and is bounded in M . Moreover,
since bdM (UM ) ⊂ bdV(U ) ∩ M , E0 < H(x) for every x ∈ bdM (UM ). In Lemma 4.5,
if

HM (x) = +∞ in M .

lim
x→∞

H(x) = +∞ in V, then lim
x→∞

Under the assumptions of Lemmas 4.3, 4.4, and 4.5, we have proved that the
boundedness of the original and the reduced systems is consistent.
In dynamical
systems, boundedness is often accompanied with stability. An equilibrium point x∗
of a dynamical system is Lyapunov stable if for every neighbourhood U of x∗, there
exists a neighbourhood V ⊂ U such that if x0 ∈ V , then x(t) ∈ U for every t ≥ 0.
When the sysetem is linear and uniformly bounded, it is marginally stable in the sense
of Lyapunov. If the original forced Hamiltonian system is linear, then the reduced
system constructed by the structure-preserving projection is also linear. Thus, if any
assumption in the previous lemmas holds, both the original and reduced systems are
Lyapunov stable.

Theorem 4.7. Let M be a closed subset of V. If x∗ is a strict local minimum of

HM in M , then x∗ is a stable equilibrium for the dissipative Hamiltonian system.

Proof. Since x∗ is a strict local minimum of HM , then there exits a neighbourhood
W of x∗ such that HM (x) > HM (x∗) for every x ∈ clM (W ) − {x∗}. Assume W is
bounded in M , otherwise, replace W by W ∩Br(x∗) for an open r-ball Br(x∗) centered
at x∗. Let U be an arbitrary neighborhood of x∗ in M . Since both W and U are open,
so is W ∩ U . Let U0 = W ∩ U . Since bdM (U0) ⊂ clM (W ), bdM (U0) is bounded in M ,
and hence also bounded in V. Since M is closed in V, bdM (U0) is also closed in V. As a
bounded and closed subset of V, bdM (U0) is compact. By the extreme value theorem,
there exits x1 ∈ bdM (U0) such that HM (x1) ≤ HM (x) for every x ∈ bdM (U0).
Since HM is continuous, the preimage D := H −1
M ((−∞, HM (x1))) of (−∞, H(x1))

STRUCTURE-PRESERVING MODEL REDUCTION

19

The POD-Galerkin method vs. the structure-preserving model reduction method.

Table 4.1

Original system

Physical laws of

the original system

Reduced state

Reduced system

POD-Galerkin

General ODE system:
˙x = f (x) with x ∈ Rn

Newton’s Law

Orthogonal projection:

z = ΦT x ∈ Rk

Reduced ODE system:

˙z = ΦT f (Φz)

Structure-preserving model reduction

Forced Hamiltonian system:

˙x = XH (x) + XF (x) with x ∈ R2n

Integral d’Alembert’s

Local d’Alembert’s

principle

principle

Symplectic projection:

z = A+x ∈ R2k

Reduced forced Hamiltonian system:

˙z = X ˜H (z) + X ˜F (z)

Reduction approach

Galerkin projection

Physical laws of

the reduced system

Basis matrix
Basis matrix

construction method

Dissipativity

Stability

N/A

Orthonormal: ΦT Φ = Ik

POD: SVD

N/A
N/A

Variational principle
Integral d’Alembert’s

Structure-preserving projection

Local d’Alembert’s

principle
Symplectic: AT J2nA = J2k and Aqp = 0

principle

PSD: Cotangent lift

Dissipativity preservation

Stability preservation

is open in M . Since x1 ∈ clM (W ) and x1 6= x∗, we have HM (x∗) < HM (x1),
which implies that x∗ ∈ D. Thus, V := U0 ∩ D is a neighbourhood of x∗ in M . If
x0 ∈ V , then HM (x0) < HM (x1) ≤ HM (x) for every x ∈ bdM (U0). This implies
that x(R+) ⊂ U0 ⊂ U , by Lemma 4.4. Therefore, x∗ is a stable equilibrium for the
dissipative Hamiltonian system.

Let M = V. Suppose U is a neighborhood of x∗ in V, and x∗ is the minimum
of H in U . Then, Theorem 4.7 implies that the full model is stable at x∗. Now,
let M = Range(A).
It immediately follows that x∗ is also the minimum of HM
in UM , where UM = U ∩ M .
It follows that x∗ is also the stable equilibrium of
the reduced Hamiltonian system on Range(A). Therefore, the stability of the full and
reduced dissipative Hamiltonian systems is consistent. For both the full model and the
structure-preserving reduced model, HM can be considered a Lyapunov function for
the system. Nevertheless, a POD reduced system is not guaranteed to be dissipative
and stable, and therefore, there is no corresponding Lyapunov function.

While both the structure-preserving method and the POD-Galerkin method con-
struct reduced equations in some low dimensional subspaces, only the structure-
preserving method can preserve the forced-Hamiltonian structure. The PSD algo-
rithm can be used to construct a symplectic matrix A, which is an analogous to POD
that constructs an orthonormal basis matrix Φ. Evolving a PSD reduced system by
a symplectic integrator can capture the energy variation and preserve the stability.
By contrast, even if a POD subspace can ﬁt the empirical data with good accuracy,
a POD reduced system can be unstable. To this end, one can distinguish between
a numerically reduced system and a physically reduced system. Table 4.1 compares
the POD-Galerkin method with the proposed structure-preserving model reduction
method; it serves as a short summary of sections 3–4.

5. Numerical validation. In this section, the performance of the proposed
structure-preserving model reduction method is illustrated in numerical simulation of
a linear dissipative wave equation. Our goal is to demonstrate that PSD can deliver a
low-dimensional reduced system while preserving the stability of the original system.

20

LIQIAN PENG AND KAMRAN MOHSENI

5.1. Hamiltonian formulation of dissipative wave equations. Let u =
u(t, x). Consider a one-dimensional linear wave equation with constant damping co-
eﬃcient β, undamped angular frequency ω0, and moving speed c,

(5.1)

utt + βut − c2uxx + ω2

0u = 0,

on space x ∈ [0, l]. With the generalized coordinates q = u and the generalized
momenta p = ut, the Hamiltonian PDE associated with (5.1) is given by

(5.2)

˙q =

δH
δp

,

˙p = −

δH
δq

− βp,

where the Hamiltonian is deﬁned as

(5.3)

H(q, p) = Z l

0

dx(cid:20) 1

2

p2 +

1
2

ω2
0q2 +

1
2

c2q2

x(cid:21).

A fully resolved model of (5.2) can be constructed by a structure-preserving ﬁnite
In particular, with n equally spaced grid points, the

diﬀerence discretization [2].
spatially discretized Hamiltonian with periodic boundary conditions is given by

(5.4)

Hd(y) =

∆x
2

n

Xi=1

p2
i +

ω2
0∆x
2

n

Xi=1

q2
i +

c2
2∆x

n

Xi=1

(qi − qi−1)2,

where xi = i∆x, qi = u(t, xi), q0 = qn, pi = ut(t, xi), and y = [q1; . . . ; qn; p1; . . . ; pn].
With n∆x = l, (5.4) converges to (5.3) in the limit ∆x → 0. Now, we have a
Hamiltonian ODE system,

(5.5)

dy
dt

= Jd∇yHd + XF ,

where Jd = J2n/∆x, and XF = [0; . . . ; 0; −βp1; . . . ; −βpn]. Let Dxx ∈ Rn×n denote
the three-point central diﬀerence approximation for the spatial derivative ∂xx. We
deﬁne a Hamiltonian matrix K and a dissipative matrix L by

(5.6)

K = (cid:20)

0n

c2Dxx − ω2

0In

Then, (5.5) can be written in the form

In

0n(cid:21) , L = (cid:20)0n

0n −βIn(cid:21) .

0n

(5.7)

˙y = Ky + Ly.

Time discretization of (5.7) can be achieved by using an implicit symplectic integrator
scheme based on mid-point rule [6, 15].

5.2. Numerical results. For our numerical experiments, we study the one-
dimensional dissipative wave equation with periodic boundary conditions deﬁned in
(5.1). Let s(x) = 10 × |x − 1

2 |; and let h(s) be a cubic spline function:

1 − 3

2 s2 + 3
4 (2 − s)3

1

0

4 s3

if

if
if

0 ≤ s ≤ 1

1 < s ≤ 2
s > 2

.

h(s) = 


STRUCTURE-PRESERVING MODEL REDUCTION

21

The initial condition is provided by

(5.8)

q(0) = [h(s(x1)); . . . ; h(s(xn))],

p(0) = 0n×1,

which gives rise to a dissipative system with wave propagating in both directions of x
and then bouncing back. The full model is computed using the following parameter
set:

Size of the space domain
Number of grid points

l = 1
n = 500

Space discretization step ∆x = l/n = 0.002

Final time
Time discretization step
Damping coeﬃcient
Undamped angular frequency
Wave speed

T = 50
δt = 0.01
β = 0.1
ω0 = 0.05
c = 0.1

The reduced PSD model is constructed through the cotangent lift method based on
the extended snapshot matrix (3.32) that contains snapshots of q(t) and p(t). Since
fH = −βp, this extended snapshot matrix can also discover the dominant modes of
fH , and therefore approximately preserves the system energy. Since (5.1) is linear, we
can also obtain the analytical solution by the eigenfunction expansion method. The
analytical solution is used as the reference benchmark solver to measure the error of
the full model as well as POD and PSD reduced models.

Figure 5.1(a) plots several snapshots of the solution proﬁle from t = 0 to t = 10.
The empirical data ensemble takes 101 snapshots from the full model with uniform
interval (∆t = 0.5). We ﬁrst compare PSD with the full model. The lines show the
results from the full model and the symbols show the results from the PSD reduced
model with 20 modes. For all snapshots, the PSD reduced system obtains good
results that match the full model very well. Figure 5.1(b) shows the singular values
corresponding to the ﬁrst 80 POD and PSD modes. A fast decay of singular values
indicates a fast convergence of low-dimensional data to ﬁt the original data with
respectic to the L2 norm. Since POD is designed to minimize the projection error
of the data snapshots in least-squares sense, for a ﬁxed dimension, no other linear
projection method can provide better data approximation with the L2 norm. With
the symplectic constraint, we do observe that the cotangent lift requires more modes
to ﬁt the empirical data than POD in order to obtain the same accuracy.

However, preserving the data does not necessarily imply preserving the dynamics.
With more modes, there is no guarantee that the POD reduced system will yield more
accurate solutions. As Figure 5.2 indicates, the L2 error norm of the POD reduced
system increases exponentially when it has 20, 30, or 40 modes. In addition, the POD
reduced system with 40 modes blows up faster than the POD system with 20 modes.
This result veriﬁes that POD can yield unstable reduced systems, even though the
original system is dissipative and stable. By contrast, PSD reduced systems have
small numerical errors in the L2 norm for all the tested cases. Figure 5.3 shows that
PSD reduced models accurately capture the evolution of the system energy E of the
dissipative wave equation, while the energy of POD reduced systems quickly grows to
inﬁnity. In this example, increasing the number of POD modes actually causes the
system energy to increase at a faster rate. Here, E equals the discretized Hamiltonian
Hd(y).

Figure 5.4(a) plots the L2 norm of the total error of diﬀerent systems over the
whole time domain [0, 50]. We compare the full model (with k = 1000), coarse model,

22

LIQIAN PENG AND KAMRAN MOHSENI

u

1

0.8

0.6

0.4

0.2

0

 
0

 

t=0
t=2.5
t=5
t=7.5
t=10

0.2

0.4

x
(a)

0.6

0.8

1

102

101

100

k

λ

10−1

10−2

10−3

10−4
 
0

 

POD
PSD

20

40
k
(b)

60

80

Figure 5.1. (Color online.) (a) The solution u(t, x) at t = 0, 2.5, 5, 7.5, 10 of the dissipative
wave equation. The lines represent the results from the full model based on 500 grid points and the
symbols represent the results from the PSD reduced model with 20 modes. (b) The singular values
λk corresponding to the ﬁrst k = 1, 2, . . . , 80 POD and PSD modes.

0.1

0.08

k
)
t
(
e
k

0.06

0.04

0.02

POD (k=20)
POD (k=30)
POD (k=40)
PSD (k=20)
PSD (k=40)

 

 

POD (k=20)
POD (k=30)
POD (k=40)
PSD (k=20)
PSD (k=40)

1

0.8

0.6

0.4

0.2

k
)
t
(
e
k

0
 
0

10

20

t
(a)

30

40

50

0
 
0

0.1

0.3

0.4

0.5

0.2

t
(b)

Figure 5.2.

(Color online.) Comparison between POD and PSD (cotangent lift) reduced
systems of the dissipative wave equation. (a) The evolution of the L2 error norm, ke(t)k := kˆu(t) −
u(t)k, between the benchmark solution u(t) and approximating solutions ˆu(t) for the time domain
t ∈ [0, 50]. (b) The L2 error norm ke(t)k for the zoomed in time interval t ∈ [0, 0.5].

0.1

0.08

0.06

0.04

0.02

)
t
(

E

POD (k=20)
POD (k=30)
POD (k=40)
PSD (k=20)
PSD (k=40)

 

 

POD (k=20)
POD (k=30)
POD (k=40)
PSD (k=20)
PSD (k=40)
full model

1

0.8

0.6

0.4

0.2

)
t
(

E

0
 
0

10

20

t
(a)

30

40

50

0
 
0

0.1

0.3

0.4

0.5

0.2

t
(b)

Figure 5.3. (Color online.) Comparison between full model, POD reduced system, and PSD
(cotangent lift) reduced system of the dissipative wave equation. (a) The evolution of the system
energy E(t) for the time domain t ∈ [0, 50]. (b) The system energy E(t) for the zoomed in time
interval t ∈ [0, 0.5].

STRUCTURE-PRESERVING MODEL REDUCTION

23

 

101

100

2
k
e
k

10−1

10−2

10−3

 
10

 

POD
PSD
coarse model
full model

50

60

70

80

20

30

40

k
(a)

103

102

101

100

)
s
(
 

e
m

i
t

10−1

10−2

 
10

POD
PSD
coarse model
full model

50

60

70

80

20

30

40

k
(b)

of the total error kek2 := qR T

Figure 5.4. (Color online.) Comparison between the full model, coarse model, POD reduced
system, and PSD (cotangent lift) reduced system for the dissipative wave equation. (a) The L2 norm
0 ke(t)k2dt of diﬀerent systems. For the POD reduced system, we only
compute kek2 with 10 modes; when the subspace dimension k is greater than 10, the POD reduced
system blows up in the whole time domain [0, 50] and kek2 becomes inﬁnite. (b) The running time of
diﬀerent systems corresponding to diﬀerent subspace dimensions k. All data comes from the average
value of 10 independent runs.

as well as POD and PSD reduced model. The subspace dimension k of the coarse
model and reduced models ranges from 10 to 80. The L2 norm of the total error of the
POD reduced system is bounded only when k equals 10 for all the tested cases . While
the PSD reduced system show some numerical error, this error quickly converges to
the error of the full model. The coarse model also preserves the forced Hamiltonian
structure and remains stable, but the numerical error of the coarse model reduces at
a low rate with increased modes. Figure 5.4(b) shows the running time of diﬀerent
methods. We ﬁnd coarse model and POD/PSD reduced model have similar running
speed. With 80 modes, both the coarse model and the reduced model can signiﬁcantly
improve the computational eﬃciency and reduce the running time by more than two
orders of magnitude.

5.3. Stability analysis. Using the numerical results, we further analyze the
stability for the linear system in (5.1). Using (5.4), we know lim
Hd(x) = +∞;
x→∞
Lemma 4.5 implies that the full model is uniformly bounded. Since the origin is the
strict minimum of Hd, Theorem 4.7 implies that the origin is a stable equilibrium for
the dissipative wave equation. Since the external force of (5.1) is a Rayleigh dissipative
force, where F (q, ˙q) = 1
2 ˙qT ˙q, the reduced PSD system is also dissipative. By the same
argument, the reduced PSD system is uniformly bounded, and also has the origin as
a stable equilibrium.

To explain why the POD reduced system is unstable, we study the eigenvalues of
the linear wave equation. According to [13], the eigenvalues βi (i = 1, . . . , n) of the
discretized spatial derivative Dxx with periodic boundary conditions are given by

βi = −

2

∆x2 (cid:20)1 − cos(cid:18) 2πi

n (cid:19)(cid:21) .

It follows that the eigenvalues of the full model K + L in (5.7) are given by 2n
complex numbers {λi}2n
0 = 0 for
i = 1, . . . , n. It can be veriﬁed that all the eigenvalues of the full model have negative
real parts, which means the full model is stable.

i=1, where λi, λi+n are solutions of λ2 + βλ − c2βi + ω2

24

LIQIAN PENG AND KAMRAN MOHSENI

Since POD does not preserve the system energy, there are no mechanisms to
conﬁne the solution in a bounded region. As a result, the reduced system may blow
up with time evolution. To corroborate this claim, let Φ denote a POD basis matrix,
λ∗ denote the eigenvalue of ΦT (K + L)Φ with the maximal real part, and ξ∗ denote
the corresponding eigenvector with unit length. Then, a∗ = ξT
∗ y0 gives the projection
coeﬃcient of y0 onto ξ∗. Since the solution of a linear system has an exponential term
a∗ exp(λ∗t)ξ∗, the POD reduced system is unstable when a∗ 6= 0 and Re(λ∗) > 0.

Table 5.1 lists Re(λ∗) with a wide range of diﬀusion coeﬃcients β and subspace
dimensions k. Numerical results show that a∗ 6= 0 for all the tested cases. When
β = 102, the diﬀusion term becomes dominant in (5.7). The POD reduced system
is stable when k = 10 and k = 20 for the tested cases. When 10−2 ≤ β ≤ 101, The
POD reduced system is stable only when k = 10. When β = 10−3, the diﬀusion term
becomes negligible in (5.7) and the POD reduced system is unstable for all the tested
cases. Table 5.1 also shows that when β = 10−1, Re(λ∗) with 40 modes is much larger
than Re(λ∗) with 20 modes, which explains why the POD reduced system with 40
modes blows up faster than the system with 20 modes in Figure 5.2.

The real part Re(λ∗) of the eigenvalue corresponding to the most unstable POD mode for

diﬀerent diﬀusion coeﬃcients β and subspace dimensions k.

Table 5.1

β

10

20

10−3
5.17 × 10−3
10−2 −3.71 × 10−3
10−1 −2.09 × 10−2
−2.51 × 10−3
100
−2.50 × 10−4
101
102
−1.07 × 10−3 −2.50 × 10−5

0.304
0.252
1.26
1.43
1.08

k
30
15.1
15.6
12.3
31.4
18.7
3.66

40
19.9
20.2
18.0
37.2
26.7
32.8

50
16.7
17.0
21.8
26.3
38.0
33.6

60
17.4
17.9
20.5
60.3
43.1
43.8

70
19.6
19.7
22.3
44.6
47.8
54.7

80
111
113
129
139
50.0
64.2

6. Conclusion. This paper proposed a PSD model reduction method to simplify
large-scale forced Hamiltonian systems, which can achieve signiﬁcant computational
savings. Since the PSD reduced system preserves the forced Hamiltonian structure,
it automatically satisﬁes the d’Alembert’s principle. Since d’Alembert’s principle is
the ﬁrst principle in classical mechanics, the PSD reduced system is a physical model,
rather than merely a numerical model. In contrast, although POD can always reduce
the dimensionality of a dynamical system, a POD reduced system may be or may not
be physical, since there is no guarantee that the system can satisfy any fundamental
physical laws.

Two structure-preserving approaches are developed in order to reconstruct re-
duced systems in a low-dimensional subspace, one based on the variational principle
and the other on the structure-preserving projection. Both approaches can yield the
same structure-preserving reduced system. By incorporating the vector ﬁeld into the
data ensemble, the PSD method also preserve the time derivative of system energy.
In a special case when the external force represents the Rayleigh dissipation, PSD
automatically preserves the dissipativity. As a consequence, PSD also preserves the
boundedness and Lyapunov stability under some conditions.

The stability, accuracy, and eﬃciency of the proposed method are illustrated
through numerical simulations of the one dimensional dissipative wave equation. How-
ever, PSD can have much more general applications. Once we choose canonical coor-

STRUCTURE-PRESERVING MODEL REDUCTION

25

dinates, all the systems that satisfy d’Alembert’s principle can be written as the forced
Hamiltonian equation. As a result, PSD can be applied to any large-scale mechanical
system in principle. Finally, we should mention that the computational complexity
and implementation complexity of PSD are almost identical to the complexity of POD.
Since the POD reduced system can be unstable and produces unpredictable results,
we believe that PSD is more suited for model reduction of large-scale mechanical
systems, especially when long-time integration is required.

REFERENCES

[1] A. C. Antoulas, D. C. Sorensen, and S. Gugercin, A survey of model reduction methods

for large-scale systems, Contemp. Math., 280 (2001), pp. 193–219.

[2] T. J. Bridges and S. Reich, Numerical methods for Hamiltonian PDEs, J. Phys. A, 39 (2006),

pp. 5287–5320.

[3] K. Carlberg and C. Farhat, A low-cost, goal-oriented ‘compact proper orthogonal decompo-
sition’ basis for model reduction of static systems, Internat. J. Numer. Methods Engrg., 86
(2011), pp. 381–402.

[4] K. Carlberg, R. Tuminaro, and P. Boggs, Preserving Lagrangian structure in nonlinear
model reduction with application to structural dynamics, SIAM J. Sci. Comput., 37 (2015),
pp. B153–B184.

[5] S. Gugercin, R. V. Polyuga, C. Beattie, and A. J. van der Schaft, Structure-preserving
tangential interpolation for model reduction of port-Hamiltonian systems, Automatica, 48
(2012), pp. 1963–1974.

[6] E. Hairer, C. Lubich, and G. Wanner, Geometric Numerical Integration: Structure-
Preserving Algorithms for Ordinary Diﬀerential Equations, Springer Ser. Comput. Math.
31, Springer-Verlag, Berlin, 2006.

[7] C. Hartmann, V.-M. Vulcanov, and C. Sch¨utte, Balanced truncation of linear second-
order systems: A Hamiltonian approach, SIAM J. Multiscale Model. and Simul., 8 (2010),
pp. 1348–1367.

[8] T. Iliescu and Z. Wang, Are the snapshot diﬀerence quotients needed in the proper orthogonal

decomposition?, SIAM J. Sci. Comput., 36 (2014), pp. A1221–A1250.

[9] K. Kunisch and S. Volkwein, Galerkin proper orthogonal decomposition methods for parabolic

problems, Numer. Math., 90 (2001), pp. 117–148.

[10]

, Galerkin proper orthogonal decomposition methods for a general equation in ﬂuid dy-

namics, SIAM J. Numer. Anal., 40 (2002), pp. 492–515.

[11] S. Lall, P. Krysl, and J. E. Marsden, Structure-preserving model reduction for mechanical

systems, Phys. D, 184 (2003), pp. 304–318.

[12] J. M. Lee, Introduction to Smooth Manifolds, Graduate Texts in Mathematics (Book 218),

Springer, 2nd ed., 2012.

[13] R. J. LeVeque, Finite Diﬀerence Methods for Ordinary and Partial Diﬀerential Equations:

Steady-State and Time-Dependent Problems, SIAM, Philadelphia, 2007.

[14] J. E. Marsden and T. Ratiu, Introduction to Mechanics and Symmetry, 2nd ed., Texts in

Appl. Math. 17, Springer-Verlag, New York, 2003.

[15] R. I. McLachlan and G. R. W. Quispel, Geometric integrators for ODEs, J. Phys. A, 39

(2006), pp. 5251–5285.

[16] B. C. Moore, Principal component analysis in linear systems: Controllability, observability,

and model reduction, IEEE Trans. Automat. Control, 26 (1981), pp. 17–32.

[17] L. Peng and K. Mohseni, An online manifold learning approach for model reduction of dy-

namical systems, SIAM J. Numer. Anal., 52 (2014), pp. 1928–1952.

[18]

, Symplectic model reduction of Hamiltonian systems, SIAM J. Sci. Comput., 38 (2016),

pp. A1–A27.

[19] R. V. Polyuga and A. J. van der Schaft, Structure preserving model reduction of port-
Hamiltonian systems by moment matching at inﬁnity, Automatica, 46 (2010), pp. 665–672.
[20] S. Prajna, POD model reduction with stability guarantee, in Proceedings of the 42nd IEEE

Conference on Decision and Control, vol. 5, Maui, HI, 2003, pp. 5254–5258.

[21] M. Rathinam and L. R. Petzold, A new look at proper orthogonal decomposition, SIAM J.

Numer. Anal., 41 (2003), pp. 1893–1925.

[22] L. N. Trefethen and D. Bau, Numerical Linear Algebra, SIAM, Philadelphia, 1997.

