6
1
0
2

 
r
a

M
3

 

 
 
]

.

M
R
n
i
f
-
q
[
 
 

1
v
1
4
0
1
0

.

3
0
6
1
:
v
i
X
r
a

Estimating Quantile Families of Loss Distributions for Non-Life

Insurance Modelling via L-moments

Gareth W. Peters1,2,3, Wilson Y. Chen4, and Richard H. Gerlach4

1Department of Statistical Science, University College London, UK

2Oxford-Man Institute, Oxford University, UK

3System Risk Center, London School of Economics, UK
4Discipline of Business Analytics, University of Sydney

February, 2016

Abstract

This paper discusses diﬀerent classes of loss models in non-life insurance settings.

It then
overviews the class Tukey transform loss models that have not yet been widely considered in non-
life insurance modelling, but oﬀer opportunities to produce ﬂexible skewness and kurtosis features
often required in loss modelling. In addition, these loss models admit explicit quantile speciﬁcations
which make them directly relevant for quantile based risk measure calculations. We detail various
parameterizations and sub-families of the Tukey transform based models, such as the g-and-h,
g-and-k and g-and-j models, including their properties of relevance to loss modelling.

One of the challenges with such models is to perform robust estimation for the loss model
In this paper we
parameters that will be amenable to practitioners when ﬁtting such models.
develop a novel, eﬃcient and robust estimation procedure for estimation of model parameters in
this family Tukey transform models, based on L-moments.
It is shown to be more robust and
eﬃcient than current state of the art methods of estimation for such families of loss models and is
simple to implement for practical purposes.

1 Introduction: context of modelling losses in general insurance

In general, one can consider insurance to be principally a data-driven industry in which the primary
cash out-ﬂows comprise of claim payments.
Insurance companies therefore employ large numbers
of analysts which include actuaries, to understand the claims data. There are many categories of
insurance business lines from which claims payment ﬂows arise. The types of insurance business lines
considered in this manuscript will be the area of general insurance and non-life insurance, which is
probably one of the most active areas of research in actuarial science. General insurance is typically
deﬁned as any insurance that is not determined to be life insurance. It is called property and casualty
insurance in the U.S. and Canada and Non-Life Insurance in Continental Europe. Non-Life insurance
typically includes modelling lines of business such as health insurance, personal/property insurance
such as home and motor insurance as well as large commercial risks and liability insurance.

When considering the claim payments in non-life lines of business, traditionally the claim actuaries
are concerned with the amount the insurance company will have to pay. Therefore, the general
insurance actuary needs to have an understanding of the various models for the risk consisting of the
total or aggregate amount of claims payable by an insurance company over a ﬁxed period of time.
Insurance data that they may consider ﬁtting statistical models to contains relatively large claim
amounts, which may be infrequent. Therefore, an important aspect of actuarial science involves the
development of statistical models that can be utilised to describe the claims process accurately so that
reserves and liability management can be accurately performed. The models such non-life insurance

1

actuaries develop should enable them to accurately make decisions on things such as: premium loading,
expected proﬁts, reserves necessary to ensure (with high probability) proﬁtability and the impact
of reinsurance and deductibles.
In particular, a core role for a non-life insurance actuary involves
preserving the insurance companys ﬁnancial security by accurately estimating future claims liabilities.
Reserving for the amount of future claims payments involves a large degree of uncertainty, especially
for long tail class business where tail behaviors can be largely diﬀerent. Hence, it can be diﬃcult to
estimate the loss reserve precisely. Fortunately, there are now numerous classes of models that have
been developed for modelling claims in non-life insurance settings, for excellent reviews see W¨uthrich
and Merz (2008), Klugman et al. (2012), Denuit et al. (2006), McNeil et al. (2015) and models
discussed in a similar context for heavy tailed, lepto-kurtic and plato-kurtic loss models in Peters and
Shevchenko (2015).

In particular, many studies have pointed to the importance of ﬂexible models with a variety of skew
and kurtosis properties to be considered in modelling non-life insurance loss processes. In practice, it
is popular too consider two parameter shape and scale models such as log-normal, gamma, Weibull
and Pareto models, see Taylor (2012) for discussions. Primarily, these models have been popular due
to simplicity in parameter estimation and model selection. However, it has been observed that making
these distributional assumptions, actuaries may underestimate the risk inherited in the long tail which
is aﬀected by large claim liabilities because these distributions do not possess ﬂexible tails to describe
the features of large claims. Failure to estimate the large claim liabilities adequately can cause ﬁnancial
instability of the company and eventually lead to insolvency. In order to improve modeling accuracy
and reliability, a number of more sophisticated models have been studied for such loss modelling.
These include the Poisson-Tweedie family of models in the additive exponential dispersion class, see
discussion in Peters et al. (2009), the GB2 models studied in Cummins et al. (1990) and Dong and
Chan (2013), the generalized-t (GT) Chan et al. (2008), the Stable family Paulson and Faris (1985)
and Peters et al. (2011) and the Pearson family Aiuppa (1988). In this manuscript, we aim to raise
awareness in the actuarial community of another alternative class of models that can be considered
for such loss modelling based on diﬀerent variations of the Tukey family.

We note that, in practice, many practitioners are reluctant to utilise such ﬂexible models due to
complications that can arise in real applications relating to ease of parameter estimation and model
selection. These can play important practical limitations for utilisation of such models. In this paper,
we will therefore focus on two aspects, ﬁrst the introduction of an under utilised family of ﬂexible
skew and kurtosis models for such non-life insurance modelling applications and then secondly a novel
accurate and robust estimation procedure that we have developed to ﬁt such models in practice. This
will allow the general Tukey transform models such as g-and-h, g-and-k and g-and-j models considered
in this paper to be easily implemented in practice. We show that our proposed estimation method
is robust and more accurate than all current competing methods. The novel approach we develop is
based around L-moments based estimation. We will discuss in detail the family of models we present,
introducing the actuarial literature general forms of the Tukey families follows by developing our
estimation procedure before presenting applications of the model and the new estimation approach.

2 General Families of Quantile Transform Distributions For Insur-

ance Modelling

Here we discuss several distributional families relevant to loss modeling in insurance which can only
be speciﬁed via the transformation of another standard random variable, for example a Gaussian.
Examples of such models which are typically deﬁned through their quantile functions include the
Johnson family with base distribution given by Gaussian or logisitic and the Tukey family with base
distribution typically given by a Gaussian or logistic. The concept of constructing skew and heavy-
tailed distributions through the use of a transformation of a Gaussian random variable was originally
proposed in the work of Tukey (1977) and is therefore aptly named the family of Tukey distributions.
This family of distributions was then extended by Hoaglin (1985), Jorge and Boris (1984), Azzalini

2

(1985) and Fischer et al. (2007). The multivariate versions of these models have been discussed by
Field and Genton (2012).

Within this family of distributions, two particular subfamilies have received the most attention
in the literature; these correspond to the g-and-h and the g-and-k distributions. The ﬁrst of these
families the g-and-h has been studied in a several contexts, see for instance the developments in the
areas of risk and insurance modelling in Dutta and Perry (2006), Peters and Sisson (2006), Degen et al.
(2007), Jim´enez and Arunachalam (2011) and the detailed discussion in (Cruz et al., 2015, Chapter
9). The second family of g-and-k model has been looked at in works such as Haynes et al. (1997) and
Hossain and Hossain (2009).

The advantage of models such as the g-and-h family for modeling losses in a non-life insurance
setting is the fact that they provide a very ﬂexible range of skew, kurtosis, and heavy-tailed features
while also being speciﬁed as a rather simple transformation of standard Gaussian random variates,
making simulation under such a models eﬃcient and simple. It is important to note that the support of
the g-and-h density includes the entire real line, in some cases this is appropriate in non-life insurance
modelling such as under logarithmic transfoms of the loss or claim amounts. In other cases it may
be more appropriate to consider loss models with strictly positive supports, in general this can be
achieved either by truncation or by restriction of the parameter values. In some subfamily members,
the g-and-h family automatically takes a positive support such as the Double h–h subfamily.

2.1 Tukey’s Elongation Transform Family of Loss Models

We begin by discussing the general family of Tukey distributions. Basically, Tukey suggested several
nonlinear transformations of a standard Gaussian random variable, denoted below throughout by
W ∼ Normal(0, 1). The g-and-h transformations involve a skewness transformation g and a kurtosis
transformation h.
If one replaces the kurtosis transformation of the type h with the type k, one
obtains the g-and-k family of distributions discussed by Rayner and MacGillivray (2002a). If the h
transformation is replaced by the j transformation, one obtains the g-and-j transformations of Fischer
and Klein (2004).

The generic speciﬁcation of the Tukey transformation is provided in Deﬁnition 2.1. These types of
transformations were labelled elongation transformations, where the notion of elongation was noted
to be closely related to tail properties such as heavy-tailedness (see discussions by Hoaglin (1985)).
In considering such a class of elongation transformations to obtain a distribution, one is comparing
the tail strength of the new distribution with that of the base distribution (such as a Gaussian or
logistic). In this regard, one can think of tail strength or heavy-tailedness as an absolute concept,
whereas the notion of elongation strength is a relative concept. In the following, we will ﬁrst consider
relative elongation compared to a base distribution for a generic random variable W .
It should
be clear that such a measure of relative tail behavior is independent of location and scale. Other
properties, that such an elongation transform T (·), should satisfy are that it should preserve symmetry
T (w) = T (−w), and the base distribution should not be signiﬁcantly transformed in the center, such
that T (w) = w + O(w2) for w around the mode. Then, to increase the tails of the resulting distribution
relative to the base, it is important to assume that T is strictly monotonically increasing transform that
is convex, that is, one has the transform satisfying for positive w > 0 that T (cid:48)(w) > 0 and T (cid:48)(cid:48)(w) > 0.
One such transformation family satisfying these properties includes the Tukey transformations.

Deﬁnition 2.1 (Tukey transformations) Consider
variable
W ∼ Normal(0, 1) and transformation X = r(w) then the resultant transformed loss random variable
X will be from a Tukey law if the corresponding transform r(W ) is given by

Gaussian

a

random

(1)
for a parameter θ ∈ R. Under this transformation we also have directly in closed form the quantile
function of the loss random variable X in terms of the quantile function of the based random variable

X = r(W ) = W T (W )θ,

3

W as follows

QX (α; ) = a + bQW (α)T (QW (α))θ

(2)

with scaling and translation constants a, b.

Typically, in several application settings, it will be desirable when working with such severity
models to enforce a constraint that the tails of the resulting distribution after transformation are
heavier than the Gaussian distribution.
In this case, one should consider a transformation T (w),
which is positive, symmetric, and strictly monotonically increasing for positive values of w ≥ 0. In
addition, it will be desirable to obtain this property of heavy tails relative to the Gaussian to also
consider setting the parameter θ ≥ 0. As discussed, a series of kurtosis transformations were proposed
in the literature. The Tukey h, k, and j transforms are provided in Deﬁnition 2.2.

Deﬁnition 2.2 (Tukey’s kurtosis transformations, h, k and j types) The h-type of transfor-
mation, denoted by Th(w), is given by

Th(w) = exp(cid:0)w2(cid:1) .

The k-type of transformation, denoted by Tk(w), is given by
Tk(w) = 1 + w2.

The j-type of transformation, denoted by Tj(w), is given by

Tj(w) =

1
2

[exp(w) + exp(−w)] .

(3)

(4)

(5)

In addition to kurtosis transformations, there are skewness transforms that have been developed

in the Tukey family, such as the g-transform.

Deﬁnition 2.3 (Tukey’s skewness transformation) The g-type of transformation, denoted by Tg(w),
is given by

Tg(w) =
The generalized g-type transform, denoted by T ∗

exp(w) − 1

w

(cid:20)

g (w), is given by
1 − exp (−gW )
1 + exp (−gW )

1 + c

T ∗
g (w) =

(cid:21)

(6)

(7)

To nest all these transformations within one class of transformations, the work of Fischer (2010)
proposed a power series representation denoted by the subscript a given in Equation (8). This sug-
gestion, though it nested the other families of distributions, is not practical for use as it involves the
requirement of estimating a very large (inﬁnite) number of parameters ai to obtain the data-generating
mechanism:

∞(cid:88)

i=0

Ta(w) =

aiw2i.

(8)

It was further observed in Fischer (2010) that this nesting structure may be replaced with a diﬀerent
form, given by the general transformation taking the form given in Equation (9):

(cid:32)

(cid:0)w2 + γ(cid:1)α − γα

(cid:33)β

Thjk(w; α, β, γ) =

1 +

β

, α > 0, β ≥ 1, γ > 0.

(9)

Then it is clear that the original h, k, and j transformations are recovered with Th(w) = Thjk(w; 1,∞, γ),
Tk(w) = Thjk(w; 1, 1, γ), and Tj(w) ≈ Thjk(w; 0.5,∞, 0.5). Next, we explain the properties of speciﬁc
subfamilies of distributions, showing how these results are derived for the basic g-and-h family and
the g-and-k family.

4

2.2 Examples of the g-and-h, g, h, and h–h Loss Models

The g-and-h family can be considered as composed of three transformations that can produce sub-
families of non-Gaussian distributions for loss amount severity based on the g-distributions, the h-
distributions, and the g-and-h distributional families. The basic speciﬁcations in which g and h com-
ponents are treated as constants are given in Deﬁnition 2.4 in terms of transformations of a random
variable W , typically Gaussian.
Deﬁnition 2.4 (g-and-h Distributional family) Let W ∼ Normal(0, 1) be a standard Gaussian
random variable. Then the loss random variable X has severity distribution given by the g-and-h
distribution with parameters a, b, g, h ∈ R, denoted X ∼ GH(a, b, g, h), if X is given by (for g (cid:54)= 0)

X = a + bW Tg,h (W ; g, h)θ := a + bG(W )H(W )W,

where θ = 1 and

and

G(w) =

exp(gw) − 1

H(w) = exp

gw

(cid:18) hw2

2

(cid:19)

.

(10)

(11)

(12)

One can observe that a and b account for location and scale, respectively. It can be checked from
(11) that the reshaping function G is bounded from below by zero, that it is either monotonically
increasing or monotonically decreasing for g being, respectively, positive or negative, and that by
rewriting it as its series expansion,

G(w) = 1 +

gw
2!

+

(gw)2

3!

+

(gw)3

4!

+ ··· ,

(13)

G is equal to one at zero for all g. Thus G generates asymmetry by scaling w diﬀerently for diﬀerent
side of zero via the parameter g. Furthermore, as G(w; g) = G(−w;−g), the sign of g aﬀects only
the direction of skewness. For g = 0, by equation (13), the constant function G(w) = 1 is obtained,
and thus the symmetry remains unmodiﬁed. For h > 0, H is a strictly convex even function with
H(0) = 1, and thus it generates heavy tails by scaling upward the tails of z while preserving the
symmetry. When h = 0, the transformation given by Equation (10) generates the subfamily of g-
distributions, which coincides with the family of shifted log-normal distributions for g > 0. When
g = 0, the transformation generates the subfamily of h-distributions, which is symmetric and has
heavier tails than normal distributions. The parameters a and b are linear transformations whereas
the parameters g and h can be signiﬁcantly extended to polynomials as discussed later, and play an
important role in the skewness and kurtosis properties of the g-and-h family.

Remark 2.1 In general, one may consider the constants g and h to be more ﬂexibly selected as
polynomials, which would include higher orders of W 2. These polynomials could take the form, for
example, of any integers p and q :

g(w) := α0 + α1w + ··· + αpw p,
h(w) := β0 + β1w + ··· + βqwq.

(14)

The addition of these polynomial terms can provide additional degrees of freedom to improve the
ability to ﬁt data. These have been shown to be signiﬁcant when modeling certain types of loss data,
as demonstrated by Dutta and Perry (2006) and Peters and Sisson (2006).

Within this family of g-and-h distributions, one can also deﬁne the subfamilies of distributions
given by the g and the h families. Again, we present these models in their simplest form, with
constant g or h, though in practice one may include polynomials in W for such models.

5

Deﬁnition 2.5 (g Distributional Family) Let W ∼ Normal(0, 1) be a standard Gaussian random
variable. Then the loss random variable X has severity distribution given by the g distribution with
parameters a, b, g ∈ R, denoted X ∼ G(a, b, g), if X is given by (for g (cid:54)= 0)

X = a + bTg (W ; g) := a + b

exp (gW ) − 1

g

.

(15)

Remark 2.2 Note that the g-distribution subfamily corresponds (in the case that g is a constant) to
a scaled LogNormal distribution.
Deﬁnition 2.6 (h Distributional Family) Let W ∼ Normal(0, 1) be a standard Gaussian random
variable. Then the loss random variable X has severity distribution given by the h distribution with
parameters a, b, h ∈ R, denoted X ∼ H(a, b, h), if X is given by

X = a + bW Th (W ; a, b, h) := a + bW exp

.

(16)

(cid:18) hW 2

(cid:19)

2

In addition, one may obtain an asymmetric class of h–h distributions studied by (Morgenthaler
and Tukey, 2000, section 2.2), Headrick and Pant (2012a) and Headrick and Pant (2012b). The
asymmetric h–h distribution transformation is given in Deﬁnition 2.7.
Deﬁnition 2.7 (Double h–h Distributional Family) Let W ∼ Normal(0, 1) be a standard Gaus-
sian random variable. Then the loss random variable X has severity distribution given by the unit h–h
distribution with parameters hl, hr ∈ R, denoted X ∼ HH(hl, hr), if X is given by



(cid:19)
(cid:19)

(cid:18) 1
(cid:18) 1

2

2

a + bW exp

hlW 2

a + bW exp

hrW 2

, W ≤ 0,

, W ≥ 0,

(17)

X = a + bW Th,h (W ; hl, hr) :=

for hr ≥ 0 and hl ≥ 0.

To conclude this section, there is also a generalized g-and-h family that is given in Deﬁnition 2.8,

see discussions in Rayner and MacGillivray (2002a).
Deﬁnition 2.8 (Generalized g-and-h Distributional family) Let W ∼ Normal(0, 1) be a stan-
dard Gaussian random variable. Then the loss random variable X has severity distribution given by
the g-and-h distribution with parameters a, b, g, h ∈ R, denoted X ∼ Generalized − GH(a, b, g, h), if
X is given by (for g (cid:54)= 0)

X = a + bW T ∗

g,h (W ; g, h)θ := a + bG∗(W )H(W )W,

where θ = 1 and

and

G∗(w) =

(18)

(19)

(20)

(cid:20)

1 + c

(cid:21)

1 − exp (−gW )
1 + exp (−gW )

(cid:18) hw2

(cid:19)

.

2

H(w) = exp

6

2.3 Examples of the g-and-k and g-and-j Loss Models

The g-and-k family of loss models, as parameterized in Haynes and Mengersen (2005) is given by
combining the g and the k transforms as given in Deﬁnition 2.9.
Deﬁnition 2.9 (g-and-k Distributional family) Let W ∼ Normal(0, 1) be a standard Gaussian
random variable. Then the loss random variable X has severity distribution given by the g-and-k
distribution with parameters a, b, g, k ∈ R, denoted X ∼ GK(a, b, g, k), if X is given by (for g (cid:54)= 0)

where θ = 1 and

and

X = a + bW Tg,k (W ; a, b, g, k)θ := a + bG∗(W )K(W )W

G∗(w) =

(cid:21)

(cid:20)
K(w) =(cid:0)1 + W 2(cid:1)k

1 + c

1 − exp (−gW )
1 + exp (−gW )

(23)
with a ∈ R is location, b > 0 is scale, g ∈ R is the skewness measure, k > −0.5 is a measure of kurtosis
and c is a constant.

.

Similarly, the g-and-j family of loss models is obtained by combining the g and the j transforms

as given in Deﬁnition 2.10.
Deﬁnition 2.10 (g-and-j Distributional family) Let W ∼ Normal(0, 1) be a standard Gaussian
random variable. Then the loss random variable X has severity distribution given by the g-and-k
distribution with parameters a, b, g, j ∈ R, denoted X ∼ GJ(a, b, g, k), if X is given by (for g (cid:54)= 0)

(21)

(22)

(24)

(25)

where θ = 1 and

and

X = a + bW Tg,j (W ; a, b, g, j)θ := a + bG∗(W )J(W )W

G∗(w) =

1 + c

1 − exp (−gW )
1 + exp (−gW )

(cid:21)

(cid:20)

1
2

(26)
with a ∈ R is location, b > 0 is scale, g ∈ R is the skewness measure, and in this case one can set
j = 1.

J(w) =

[exp(W ) + exp(−W )] .

In the following sections we will explore properties of the two more widely used families of models

the g-and-h, and its sub-families, as well as the g-and-k claims severity models.

3

g-and-h, g, h, h–h, and g-and-k Family Distribution and Density
Functions

In this section we discuss properties of the Tukey sub-families of loss models and in particular diﬀerent
ways that people have sought to evaluate and present the distribution and density functions for the
popular sub-families such as the g-and-h, generalized g-and-h and g-and-k families. In general, it will
be informative for this section to remind the reader of the following basic property.
Proposition 3.1 If X is a continuous random variable distributed according to distribution X ∼ F (x),
which is monotonically increasing on support Supp{F (x)} = {x : 0 < F (x) < 1}, then, in this general

7

case, one can show that the quantile function QX (α) = F −1(α) for α ∈ [0, 1] determines the relation-
ship between the random variable X and any other continuous random variable with monotonically
increasing distribution, say W ∼ G(w), through the relationship given as follows

QX (α) = F −1 (G (QW (α))) .

(27)

Furthermore, the following relationship between the quantile function of a random variable X and its
density cab be obtained by using the identity for diﬀerentiation of an inverse function given by

g(cid:0)g−1(x)(cid:1)(cid:21)−1

(cid:20) 1

dx

g−1(x) =

d
dx

(28)

this result when applied to the quantile function of random variable X produces the following relation-
ship

dQX (α)

1

(29)
where QX (α) is the quantile function for random variable X at quantile level α and fX (·) represents
the density for random variable X. One can then also apply this to the relationship in Equation 27 to
obtain

fX (QX (α))

dα

=

dQX (α)

dα

=

=

d
du

QX (u)

du
dα

g (QW (α))

fX (F −1 (G (QW (α))))

.

(30)

In the remainder of this paper we will consider to utilise the most popular choice of reference
distribution in the literature which refers to the standard Gaussian base distribution, i.e.
W ∼ G(w) = Φ(w; 0, 1). We note that it is however trivial to modify the results below for other
choices of distribution. In this Gaussian case, one can show that for any continously diﬀerentiable
transformation X = T (W ), X will have a density given in Equation (31) with respect to the standard
Gaussian density φ(·).

φ(cid:0)T −1(x)(cid:1)

(31)
In this case, one can also observe that when the transform T (·) increases rapidly, the resulting density
is heavy-tailed. For instance, conversely a slower linear growth in the function T (·) results in tail
behavior for the distribution of random variable X being equivalent to a Gaussian

T (cid:48) (T −1(x))

fX (x) =

.

These two general results in Proposition 3.1 can then been used to characterized the distribution
and density functions for diﬀerent members of the Tukey family of quantile speciﬁed loss models. In
the following results we basically apply the same methodology to obtain the density and distribution
for each of the diﬀerent Tukey classes of loss model. We begin with the density of the superclass of
transformations presented previously according to the quantile transformation Thjk.

Deﬁnition 3.1 (Super Class Thjk Density) One can state the following basic properties for the
loss random variable X = r(W ) = W Thjk(W )θ, the loss density fX (·) and quantile functions QX (·),
for loss random variable X, are given by

inf {x : x ∈ S} < x < sup{x : x ∈ S}

(32)

fX (x; h, j, k) =

=

1

(cid:0)Q−1
X (x)(cid:1)
φ(cid:0)r−1(x)(cid:1)

Q(cid:48)

X

r(cid:48) (r−1(x))

,

with S the appropriate support of the random variable X and

QX (α) = r (QW (α)) , α ∈ [0, 1],

r(cid:48)(w) = Thjk(w)θ−1(cid:0)Thjk(w) + θwT (cid:48)

hjk(w)(cid:1) .

8

Clearly, this density representation is a composition of two functions, one of which can only be evalu-
ated typically numerically due to general non-closed from expressions for the inversion.

In an analogous manner one can ofcourse then ﬁnd the distribution and density for the other Tukey
families of loss model. The ﬁrst observation one can make for the g-and-h family is that since the
transformations are monotonically increasing as long as h > 0, the quantile function of the g-and-h
distribution is readily available. Let xu denoted the level u ∈ [0, 1] quantile function of a g-and-h
distribution,

a + b exp(gzu)−1
(cid:16) hz2

g
a + bzu exp

u

2

(cid:17)

exp

(cid:16) hz2

u

(cid:17)

2

if g (cid:54)= 0
if g = 0

x(u; a, b, g, h) =

where zu is the u-level quantile of the standard normal distribution, a ∈ R, b ∈ (0,∞), g ∈ R, and h ∈
[0,∞) are parameters responsible for location, scale, asymmetry, and heavy-tailedness, respectively.
This result was utilised in Degen et al. (2007) and Headrick et al. (2008a) to obtain expressions for
the density as such a composite function.

Deﬁnition 3.2 (g-and-h Distribution Function (constant g and h with h > 0)) Consider the
g-and-h distributed random variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g and h > 0.
The distribution function can be speciﬁed according to the following composite function:

where Φ(·) is the standard Gaussian distribution and the function r(x) is speciﬁed by

(33)

(34)

(35)

(36)

(37)

,

1

=

Q(cid:48)

X

fX (x; g, h) =

r(cid:48) (r−1(x))

FX (x; g, h) = Φ(cid:0)r−1(x)(cid:1) ,
(cid:0)Q−1
X (x)(cid:1) ,
φ(cid:0)r−1(x)(cid:1)
(cid:18) hx2
(cid:19)(cid:21)
(cid:18) hx2

(cid:18) hx2

exp (gx) − 1

(cid:20) exp (gx) − 1
(cid:18)
(cid:19)

r(x) =

(cid:19)

exp

exp

2

2

g

g
hx2
2

h
g

(cid:19)

.

where the derivative is then given by

r(cid:48)(x) =

d
dx

= exp

gx +

+

x exp

(exp(gx) − 1) .

2

In this parametrization, the parameter g will control the skew of the distribution both in terms of
the sign and the magnitude, while the parameter h will control heaviness of the tails and is related
directly to the kurtosis. This will be discussed further when the regular variation properties of this
model are explored. As demonstrated previously, the original Tukey h-type transformation had θ = 1
and an addition scaling of 1

2 . This transformation has the property that its derivative

r(x) =(cid:0)1 + hx2(cid:1) exp

d
dx

(cid:18) 1

2

(cid:19)

hx2

≥ 1

(38)

for all h ≥ 0. In addition, in the following discussions, it will be useful to recall the following properties
of the g-and-h family of distributions:

1. The g-and-h transformation can be shown to be strictly monotonically increasing in its argument,

that is, for all w1 ≤ w2 one has Tgh(w1) ≤ Tgh(w2);

2. If a = 0, then the g-and-h transformation satisﬁes the condition T−g,h(W ) = − Tg,h(−W ).

9

In the case of the generalized g-and-h distribution one has the Tukey quantile transform producing

loss random variable X according to based random variable W given by

(cid:20)

T ∗
gh(W ) =

1 + c

1 − exp (−gW )
1 + exp (−gW )

(cid:21)

(cid:18) hW 2

(cid:19)

2

exp

,

(39)

with r(W ) = W T (W )θ and typically in this family we also consider θ = 1. This then produces the
following density and distributions.

Deﬁnition 3.3 (Generalized g-and-h Distribution and Density Functions) Consider the gen-
eralized g-and-h distributed random variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g
and h > 0. The distribution function can be speciﬁed according to the following composite function:

X

1

Q(cid:48)

fX (x; g, h) =

FX (x; g, h) = Φ(cid:0)r−1(x)(cid:1) ,
(cid:0)Q−1
X (x)(cid:1) ,
φ(cid:0)r−1(x)(cid:1)
(cid:18) hx2
(cid:21)
(cid:19)(cid:27)

1 − exp (−gx)
1 + exp (−gx)

r(cid:48) (r−1(x))

x exp

1 + c

=

(cid:20)

2

,

(cid:19)

,

where Φ(·) is the standard Gaussian distribution and the function r(x) is speciﬁed by

where the derivative is then given by

r(x) =

(cid:26)(cid:20)
exp(hx2/2) (1 + exp(gx))2 (1 + hx2) + 2c exp(gx)(cid:0)gx + (1 + hx2) sinh(gx)(cid:1)

1 − exp (−gx)
1 + exp (−gx)

(cid:18) hx2

d
dx

x exp

1 + c

(cid:21)

2

r(cid:48)(x) :=

=

In the case of the g-and-k distribution family one has the quantile function given by

b(W ) = W Tgk(W )θ =

1 + c

.

(44)

(cid:20)

(1 + exp(gx))2

1 − exp (−gW )
1 + exp (−gW )

(cid:21)

W(cid:0)1 + W 2(cid:1)k

Deﬁnition 3.4 (g-and-k Distribution and Density Functions) Consider the generalized g-and-
k distributed random variable X ∼ GH(a = 0, b = 1, g, k) with constant parameters g and k > −0.5.
The distribution function can be speciﬁed according to the following composite function:

(40)

(41)

(42)

(43)

.

(45)

(46)

(47)

1

fX (x; g, k) =

FX (x; g, k) = Φ(cid:0)k−1(x)(cid:1) ,
X (x)(cid:1) ,
(cid:0)Q−1
φ(cid:0)r−1(x)(cid:1)
(cid:21)

r(cid:48) (r−1(x))

(cid:20)

Q(cid:48)

=

X

,

1 − exp (−gw)
1 + exp (−gw)

w(cid:0)1 + w2(cid:1)k

,

where Φ(·) is the standard Gaussian distribution and the function r(x) is speciﬁed by

r(x) =

1 + c

where the derivative is then given by
r(cid:48)(w; g, k) :=

(cid:26)(cid:20)
2 exp(gw) exp(1 + w2)k(cid:0)1 + cgw + 2kw2 + (1 + 2kw2)Cosh(gw) + c(1 + 2kw2)Sinh(gw)(cid:1)

w(cid:0)1 + w2(cid:1)k(cid:27)

1 − exp (−gw)
1 + exp (−gw)

d
dw

1 + c

(cid:21)

=

(1 + exp(gw))2

10

(48)

.

4 g-and-h, g, h, h–h, and g-and-k Family Statistical Properties of

Relevance to Claims Modelling

One advantage of the speciﬁcations presented above, of the distribution and density functions with
regard to a particular quantile function, is that the statistical properties of these distributions can
now be easily studied. For instance, the mode and moments of the distribution can be characterized.
The result in Proposition 4.1 provides the mode for the g-and-h, generalized g-and-h and the g-and-k
distributions.

Proposition 4.1 (Mode of the g-and-h, generalized g-and-h and g-and-k Densities) Consider
the g-and-h distributed random variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g and
h > 0, the generalized g-and-h given by X ∼ Generalized − GH(a = 0, b = 1, g, h, c) and the g-and-k
distribution X ∼ GK(a = 0, b = 1, g, k) with constant parameters g and k > −0.5. In each of these
models, which will be generically denoted here by transform X = r(W ), the mode of the density is

located at the value (cid:101)w = Mode [W ], which produces a maximum value of the densities at fr(W )((cid:101)w), de-
when w = (cid:101)w, which is selected to satisfy

pending on the transform r(w) in each case, and can be found as the solution to the following equations

(cid:20) fW (w)

(cid:21)

r(cid:48)(w)

d
dw

= 0,

(49)

Analogously the medians can also be obtained.

Proposition 4.2 (Median of the g-and-h, generalized g-and-h and g-and-k Densities) Consider
the g-and-h distributed random variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g and
h > 0, the generalized g-and-h given by X ∼ Generalized − GH(a = 0, b = 1, g, h, c) and the g-and-
k distribution X ∼ GK(a = 0, b = 1, g, k) with constant parameters g and k > −0.5. In each of
these models, which will be generically denoted here by transform X = r(W ), the median of the den-
sity is located at the value w0.5 = Median [W ] and will correspond to the median being the limit of
limw→0 r(w) = 0.

Remark 4.1 Therefore, one sees that in each of the g-and-h, generalized g-and-h and g-and-k distri-
butions the median of the data set will be the parameter a. Furthermore, in the case of the h-type and
double h-type Tukey distributions, the median and mode are at the origin (for a = 0).

One can also obtain the moments of Tukey family of distributions, with generically denoted Tukey
quantile transform given by r(W ) = W T (W )θ, as the solution to the following integrals, where the
n-th moment is given with respect to the transformed moments of the base density as follows:

∞(cid:90)

E [X n] = E [r(W )n] =

r(w)nfW (w)dw,

(50)

−∞

From such a result, one may now express the moments of the g-and-h, generalized g-and-h and
g-and-k distributed random variables according to the results in Proposition 4.3, Proposition 4.4 and
Proposition 4.5.

Before presenting these we note the following from Dutta and Babbel (2002) that since the g-
distribution is a horizontally shifted LogNormal distribution, then the moments of the g-distribution
take the same form as those of a LogNormal model with appropriate adjustment for the translation.
The h-distributional family is symmetric (except the double h–h family); consequently, all odd-order
moments for the h-subfamily are zero.

11

Proposition 4.3 (Moments of the g-and-h Density) Consider the g-and-h distributed random
variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g and h > 0. The n-th integer moment
is given with respect to the standard Normal distribution and the n-th power of the transformed quantile
function given by

(cid:18) hW 2

(cid:19)

2

.

(51)

r(W ) = a + b

exp (gW ) − 1

g

exp

to produce moments according to the relationship

which will exist if h ∈(cid:2)0, 1

(cid:1). One can also observe more generally that under the g-and-h transform

E [X n] = E [r(W )n]

(52)

the following identity holds with regard to powers of the standard Gaussian, W ∼ Normal(0, 1), such
that

n

X n = r(W )n = Tg,h(W ; a, b, g, h)n

= (a + bTg,h(W ; a = 0, b = 1, g, h))n

n!

(n − i)!i!

an−ibiTg,h(W ; a = 0, b = 1, g, h)i,

n(cid:88)

i=0

=

n(cid:88)

i=0

=

which will produce moments given by

E [X n] = E [(a + bTg,h(W ; a = 0, b = 1, g, h))n]

an−ibiE(cid:2)Tg,h(W ; a = 0, b = 1, g, h)i(cid:3) .

n!

(n − i)!i!

(53)

(54)

Furthermore, it was shown by Dutta and Babbel (2002) that when it exists one can obtain the general
expression

E(cid:2)Tg,h(W ; a = 0, b = 1, g, h)i(cid:3) =

(cid:80)i
r=0(−1)r

i!

(i−r)!r! exp

(cid:112)(1 − ih)gi

(cid:16) (i−r)2g2

2(1−ih)

(cid:17)

,

(55)

The results in Proposition 4.3 then produce the following four population moments for the basic

g-and-h loss model in closed form for a = 0 and b = 1:

− 1

exp

2 − 4h

2 − 2h

(cid:20)
(cid:20)
(cid:20)

E [X] =

1 − 2 exp

(cid:19)
(cid:18) g2
(cid:18) g2
E(cid:2)X 2(cid:3) =
(cid:18) g2
(cid:19)
E(cid:2)X 3(cid:3) =
(cid:18) 8g2
E(cid:2)X 4(cid:3) = s(g, h) exp
(cid:19)
(cid:18) 6g2

2 − 6h

1 − 4h

(cid:18)

3 exp

s(g, h) =

1 + 6 exp

4h − 1

(cid:21)(cid:104)
(cid:19)
(cid:19)(cid:104)

√

g

+ exp

1 − h

1 − 2h

(cid:105)−1
(cid:18) 2g2
(cid:19)(cid:21)(cid:104)
(cid:19)
(cid:18) 9g2
(cid:105)−1
(cid:19)

2 − 6h
√
1 − 4h

(cid:18) 8g2

.

− 3 exp

+ exp

g4

+ exp

4h − 1

with the function s(g, h) being given by

(cid:105)−1
(cid:19)

− 1

(cid:21)(cid:104)

g3

√

(cid:105)−1

1 − 3h

g2

√

1 − 2h

(cid:18) 2g2

1 − 3h

(cid:19)

(cid:18) 7g2

8h − 2

(cid:19)(cid:19)

(cid:18) 15g2

8h − 2

.

− 4 exp

− 4 exp

Analagously then we can also ﬁnd the n-th order integer moments for the generalized g-and-h and

the g-and-k models as follows.

12

Proposition 4.4 (Moments of the Generalized g-and-h Density) Consider the Generalized g-
and-h distributed random variable X ∼ GH(a = 0, b = 1, g, h) with constant parameters g and h > 0.
The n-th integer moment is given with respect to the standard Normal distribution and the n-th power
of the transformed quantile function

(cid:20)

(cid:21)

(cid:18) hW 2

(cid:19)

.

2

1 − exp (−gW )
1 + exp (−gW )

W exp

r(W ) = a + b

1 + c

given by

which will exist if h ∈(cid:2)0, 1

r

E [X n] = E [r(W )n]

E [X n] = E(cid:2)(cid:0)a + bT ∗

(cid:1). Hence, one obtains moments given by
g,h(W ; a = 0, b = 1, g, h)(cid:1)n(cid:3)
n(cid:88)
an−ibiE(cid:2)T ∗

n!

=

g,h(W ; a = 0, b = 1, g, h)i(cid:3) .

(n − i)!i!

i=0

(56)

(57)

(58)

(cid:19)

(59)

(60)

The moments of the generalized transform can not in general be obtained in closed form except
in some special cases. However, one make the following McClaren series expansion of the term
[G∗(W )H(W )/W ]i and then approximate the moments as follows at say pth order. We provide the
result for 3rd order series expansion of the transform below

(cid:0)T ∗
g,h(W ; a = 0, b = 1, g, h)(cid:1)i
(cid:18) ih
(cid:18)

= W i

1 +

icgW +

1
2

(cid:19)

(cid:18) 1

c2g2(i − 1)i

1
8

+

2

W 2 +

i2cgh − 1
24

icg3 +

1
48

c3g3(i − 2)(i − 1)i

4

x3 + O(x4)

.

(cid:19)

This can then be integrated to produce the approximate i-th order moments given by

3π25− i

g,h(W ; a = 0, b = 1, g, h)i(cid:3)
2 E(cid:2)T ∗
2(cid:2)c2g2i(−1 + i2) + 4(2 + hi(1 + i))(cid:3) Γ

= cgi(cid:2)12(2 + hi(2 + i)) + g2(2 + i)(−2 + c2(2 − 3i + i2))(cid:3) Γ
+ (−1)i(cid:2)−cgi(12(2 + hi(2 + i)) + g2(2 + i)(−2 + c2(2 − 3i + i2)))(cid:3) Γ
+ (−1)i(cid:104)

(cid:19)
(cid:18) 1 + i

(cid:18) 1 + i
(cid:105)

2(c2g2i(−1 + i2) + 4(2 + hi(1 + i)))

√
3

(cid:18)

(cid:19)

(cid:19)

+ 3

1 +

√

i
2

Γ

2

+ O(x4+i+1)

2

(cid:19)

(cid:18)

1 +

i
2

Similarly to the results obtained above we can obtain the moments of the g-and-k as follows.

Proposition 4.5 (Moments of the g-and-k Density) Consider the g-and-k distributed random
variable X ∼ GK(a = 0, b = 1, g, k) with constant parameters g and k > −0.5. The n-th integer
moment of the distribution is given with respect to the standard Normal distribution and the n-th
power of the transformed quantile function

(cid:20)

(cid:21)

W(cid:0)1 + W 2(cid:1)k

1 − exp (−gW )
1 + exp (−gW )

r(W ) =

1 + c

given by

,

(61)

(62)

E [X n] = E [r(W )n] .

13

Hence, one obtains moments given by

E [X n] = E(cid:2)(cid:0)a + bT ∗

n(cid:88)

i=0

=

n!

(n − i)!i!

g,k(W ; a = 0, b = 1, g, k)(cid:1)n(cid:3)
an−ibiE(cid:2)T ∗

g,k(W ; a = 0, b = 1, g, k)i(cid:3) .

(63)

The moments of the G-and-K transform can not in general be obtained in closed form except in some
special cases. However, one may make the following McClaren series expansion and then approximate
the moments as follows at say p-th order. We provide the result for 3rd order series below

g,k(W ; a = 0, b = 1, g, k)(cid:1)i
(cid:0)T ∗
(cid:18) 1
(cid:19)
23+i (6 + g2i − 12k)

= W i(gW )i

− 1
3π

2i+1π

(cid:20)

1

(cid:21)

W 2 + O(W 4)

.

(64)

This can then be integrated to produce the approximate i-th order moments given by

(cid:2)Γ (1/2 + i)(cid:0)(−1)i(−g)i + gi(cid:1)(cid:0)(g2 − 12k)i(1 + 2i) − 12(cid:1)(cid:3)

E(cid:2)T ∗
g,h(W ; a = 0, b = 1, g, h)i(cid:3) ≈ −

√
24

2π

.

(65)

Remark 4.2 These results allow one to perform model estimation via moment matching of model
moments to empirical moments of the loss data.

Furthermore, using these moment identities one can easily then ﬁnd the skew, kurtosis, and coef-
ﬁcient of variations for the g-and-h, generalized g-and-h and g-and-k loss distribution models as well
as the subfamilies for the g-distributions and h-distributions.

In addition, there are numerous authors who have studied the generalized properties of quantile-
based functionals of asymmetry and kurtosis (see examples in Deﬁnition 4.1; also see Balanda and
MacGillivray (1990), Rayner and MacGillivray (2002b), and Balanda and MacGillivray (1988)).

Deﬁnition 4.1 (Generalized Skewness and Kurtosis Functionals) In considering the general-
izations of the skewness and kurtosis for transformation-based quantile function severity models, one
can utilize the generalized speciﬁcations given for the skewness functional, for a given distribution
FX (x) with respect to its quantile function QX (x) by

(66)

(67)

γF =

QX (α) + QX (1 − α) − 2QX
QX (α) − QX (1 − α)

, α ∈ (0, 1).

(cid:1)

(cid:0) 1

2

In addition, there is the spread functional given by

SF = QX (α) − QX (1 − α), α ∈ (0, 1).

Such measures were discussed by Balanda and MacGillivray (1990) and it can be shown that
|γF (α)| ≤ 1. In the case of the g-and-h family of severity models, one would obtain the forms given in
Deﬁnition 4.2.

Deﬁnition 4.2 (Generalized Skewness and Kurtosis for g-and-h and generalized g-and-h Families)
Consider the g-and-h distributed random varaible X ∼ GH(a = 0, b = 1, g, h) with constant parameters
g and h > 0 then the generalized skewness and kurtosis are given for the g-and-h model according to

14

expressions

SF = QX (α) − QX (1 − α)

=

γF =

=

g

2

(cid:19)

exp

hΦ−1(α)2

exp(cid:0)gΦ−1(α)(cid:1) − 1
(cid:18) 1
− exp(cid:0)gΦ−1(1 − α)(cid:1) − 1
(cid:18) 1
(cid:0) 1
(cid:1)
exp(cid:0) 1
2 hΦ−1(α)2(cid:1)
2 hΦ−1(0.5)2(cid:1)
exp(cid:0) 1

exp
QX (α) + QX (1 − α) − 2QX
QX (α) − QX (1 − α)

SF
exp(gΦ−1(0.5))−1

exp(gΦ−1(α))−1

+

2

g

2

g

g

− 2

SF

(cid:19)

,

hΦ−1(1 − α)2

exp(gΦ−1(1−α))−1

g

.

exp(cid:0) 1

2 hΦ−1(1 − α)2(cid:1)

SF

In the case of the generalized g-and-h model they are given according to expressions
F = QX (α) − QX (1 − α)
S∗

Φ−1(α) exp

1 + c

(cid:34)

(cid:34)

1 + exp (−gΦ−1(α))

(cid:35)
1 − exp(cid:0)−gΦ−1(α)(cid:1)
1 − exp(cid:0)−gΦ−1(1 − α)(cid:1)
(cid:0) 1
(cid:1)

1 + exp (−gΦ−1(1 − α))

−
QX (α) + QX (1 − α) − 2QX
QX (α) − QX (1 − α)
1−exp(−gΦ−1(α))
1+exp(−gΦ−1(α))

1 + c

1 + c

(cid:20)

(cid:21)

2

Φ−1(α) exp

(cid:35)

=

γ∗
F =

=

Φ−1(1 − α) exp

(cid:16) hΦ−1(α)2

(cid:19)

,

2

(cid:18) hΦ−1(α)2

(cid:19)
(cid:18) hΦ−1(1 − α)2
(cid:20)
(cid:17)
(cid:16) hΦ−1(1/2)2

(cid:17)

1 + c

+

2

2

2

.

1−exp(−gΦ−1(1−α))
1+exp(−gΦ−1(1−α))

(cid:20)

1 + c

− 2

SF

1−exp(−gΦ−1(1/2))
1+exp(−gΦ−1(1/2))

Φ−1(1/2) exp

(cid:21)

SF

(cid:21)

Φ−1(1 − α) exp

SF

(cid:16) hΦ−1(1−α)2

(cid:17)

2

Analogously one can trivially ﬁnd the generalized skewness and kurtosis for the g-and-k and g-and-j

families.

4.1 Tail Properties of the g-and-h and g-and-k Loss Models

In terms of the tail behavior of the g-and-h family of distributions, the properties of such severity
models have been studied by numerous authors such as Morgenthaler and Tukey (2000) and Degen
et al. (2007). In particular, the tail property (index of regular variation) for the g-and-h family of
distributions was ﬁrst studied for the h-distribution by Morgenthaler and Tukey (2000) and later for
the g-and-h distribution by Degen et al. (2007) (see Proposition 4.6). In addition, the second-order
regular variation properties of the g-and-h family of distributions was studied by Degen et al. (2007).
In order to study the properties of regular variation of the g-and-h family of loss distribution models
it is ﬁrst important to recall some basic deﬁnitions. First, we note that a postive measurable function
f (·) is regularly varying if it satisﬁes the conditions in Deﬁnition 4.3, see discussion in Karatzas and
Shreve (1991).
Deﬁnition 4.3 (Regularly Varying Function) A positive measurable function f (·) is regularly
varying (at inﬁnity) with an index α ∈ R if it satisﬁes:

• It is deﬁned on some neighbourhood [x0,∞) of inﬁnity; and

15

• It satisﬁes the following limiting relationship

lim
x→∞

f (λx)
f (x)

= λα, ∀λ > 0.

(68)

We note that when α = 0, then the function f (·) is said to be slowly varying (at inﬁnity). From this
deﬁnition one can show that a random variable has a regularly varying distribution if it satisﬁes the
condition in Deﬁnition 4.4.

Deﬁnition 4.4 (Regularly Varying Random Variable) A loss random variable X with distribu-
tion FX (x) taking positive support is said to be regularly varying with index α ≥ 0 if the right tail
distribution F X (x) = 1 − FX (x) is regularly varying with index −α.

The following important features can be noted about regularly varying distributions as shown in

Theorem 4.1, see detailed discussion in Bingham et al. (1989).

Theorem 4.1 (Properties of Regularly Varying Distributions) Given a loss distribution FX (x)
satisfying FX (x) < 1 for all x ≥ 0, the following conditions on FX (x) can be used to verify that it is
regularly varying such that FX (x) ∈ RVα:

• If FX (x) is absolutely continuous with density fX (x) such that for some α > 0 one has the

limit

lim
x→∞

xfX (x)
F X (x)

= α.

(69)

Then fX (x) is regularly varying with index −(1 + α) and consequently F X (x) is regularly varying
with index −α;

• If the density fX (x) for loss distribution FX (x) is assumed to be regularly varying with index

−(1 + α) for some α > 0. Then the following limit,

lim
x→∞

xfX (x)
F X (x)

= α,

(70)

will also be satisﬁed if F X (x) is regularly varying with index −α for some α > 0 and the density
fX (x) will be ultimately monotone.

Many additional properties are described for such heavy tailed distribution and density functions.
Here we will utilise the above stated conditions to assess the regular variation properties of the right
tail of the g-and-h family of loss models. In particular we will see if a single distributional parameter
characterizes the heavy tailed feature as captured by the notion of regular variation index, or if the
relationship is more complex.

Proposition 4.6 (Index of Regular Variation of g-and-h Distribution) Consider the random
variable W ∼ Normal(0, 1) and a loss random variable X, which has severity distribution given by the
g-and-h distribution with parameters a, b, g, h ∈ R, denoted X ∼ GH(a, b, g, h), with h > 0 and density
(distribution) f (x) (and F (x)) . Then the index of regular variation is obtained by considering the
following limit

lim
x→∞

xf (x)
F (x)

= lim
x→∞

φ(u) (exp(gu) − 1)

(1 − Φ(u)) (g exp(gu) + hu(exp(gu) − 1))

=

1
h

(71)

16

for u = k−1(x) where the function k(x) is given by

k(x) =

exp (gx) − 1

g

exp

(cid:18) hx2

(cid:19)

2

.

(72)

Hence, one can state that F ∈ RV− 1

h

.

The asymptotic tail behavior of the h-family of Tukey distributions was studied by Morgenthaler

and Tukey (2000) and is given in Proposition 4.7.
Proposition 4.7 (h-Type Tail Behaviour) Consider the h-type transformation, where W ∼ Normal(0, 1)
is a standard Gaussian random variable and the loss random variable X has severity distribution given
by the h-distribution with parameters a, b, h ∈ R, denoted X ∼ H(a, b, h) according to

X = Th (W ; a, b, h) := a + bW exp

.

(73)

(cid:18) hW 2

(cid:19)

2

Then the asymptotic tail index of the h-type distribution is then given by 1/h. This is equivalent to
the g-and-h family for g (cid:54)= 0.

This shows that the h-type family has a Pareto heavy-tailed property, hence the restriction that
moments will only exist on the order of less than 1/h. The g-family of distributions can be shown to
be subexponential in the tail behavior but not regularly varying. It was shown (Degen et al., 2007,
theorem 2.2) that one can obtain an explicit form for the function of slow variation in the g-and-h
family as detailed in Theorem 4.2.

Theorem 4.2 (Slow Variation Representation of g-and-h Severity Models) Consider
the
random variable W ∼ Normal(0, 1) and a loss random variable X, which has severity distribution
given by the g-and-h distribution with parameters a, b, g, h ∈ R, denoted X ∼ GH(a, b, g, h), with g > 0
and h > 0 and density (distribution) f (x) (and F (x)) . Then F (x) = x−1/hL(x) for some slowly
varying function L(x) given as x → ∞ by

(cid:104)

exp

(cid:16) g

h

(cid:112)g2 + 2h ln(gx) − g2
(cid:112)g2 + 2h ln(gx) − g

h

(cid:17) − 1
(cid:105)1/h

(cid:18)

(cid:18) 1

(cid:19)(cid:19)

ln x

1 + O

.

(74)

L(x) =

h√
2πg1/h

From this explicit Karamata representation developed by Degen et al. (2007), it was also shown

that one can obtain the second-order regular variation properites of the g-and-h family.

The implications of these ﬁndings are that the g-and-h distribution, under the parameter restric-
tions g > 0 and h > 0, belongs to the domain of attraction of an Extreme Value Distribution, such
that X ∼ GH(a, b, g, h) with distribution F satisfying F ∈ M DA (Hγ) where γ = h > 0. As a con-
sequence, by the Pickands–Balkema–de Haan Theorem, discussed in detail in companion book Cruz
et al. (2015), one can state that there exists an Extreme Value Index (EVI) constant γ and a positive
measurable function β(·) such that the following result between the excess distribution of the g-and-h
(denoted by Fu(x) = Pr (X − u ≤ x|X > u) and the generalized Pareto distribution (GPD) is satisﬁed
in the tails

(cid:12)(cid:12)Fu(x) − Gγ,β(u)(x)(cid:12)(cid:12) = 0.

lim
u↑∞ sup
x∈(0,∞)

(75)

17

For discussion on the rate of convergence in the tails, see Raoult and Worms (2003) and the application
of this theorem to the g-and-h case by Degen et al. (2007) where it is shown that the order of covergence

is given by O(cid:0)A exp(cid:0)V −1(u)(cid:1)(cid:1) for functions

V (x) := F

(exp(−x)) ,

A(x) :=

− γ.

(76)

Hence, the conclusion from this analysis regarding the tail convergence of the excess distribution of
the g-and-h family toward the GPD Gγ,β(u)(x) is given explicitly by

ln L(x)

ln x

√

∼

2

g
3
2

h

1(cid:112)ln(x)

= O

1(cid:112)ln (k−1(x))

(cid:33)

, x → ∞.

(77)

Remark 4.3 The implications of this slow rate of convergence are that when data for severities are
obatained from a loss process, if a goodness-of-ﬁt test suggests that one may not reject the null hypoth-
esis that these data came from a g-and-h distribution, then one should avoid performing estimation
of the extreme quantiles, such as those used to measure the capital via the Value-at-Risk, via methods
based on Peaks Over Threshold (POT) or Extreme Value Theory (EVT) based penultimate approxi-
mations.

−1
V (cid:48)(cid:48)(ln x)
V (cid:48)(ln x)

(cid:32)

Proposition 4.8 (Index of Regular Variation of the generalized g-and-h Distribution) Consider
the random variable W ∼ Normal(0, 1) and a loss random variable X, which has severity distribution
given by the g-and-h distribution with parameters a, b, g, h ∈ R, denoted X ∼ GH(a, b, g, h), with k > 0
and density (distribution) f (x) (and F (x)) . Recall that we had for the generalized g-and-h loss model
the function r(x) with a = 0 and b = 1 given by

(78)
Using this, we can then ﬁnd the index of regular variation at x → ∞ as obtained by considering the
following limit

r(x) =

1 + c

2

.

(cid:20)

1 − exp (−gx)
1 + exp (−gx)

(cid:19)

(cid:21)

x exp

(cid:18) hx2
xφ(cid:0)r−1(x)(cid:1)

lim
x→∞

xf (x)
F (x)

= lim
x→∞

r(cid:48) (r−1(x)) [1 − Φ (r−1(x))]

(80)
which by deﬁning u = r−1(x) and further noting that u(1 − Φ(u))/φ(u) → 1 as x → ∞ one can
rewrite as follows using the reciprocal law of limits that states that if limx→c g(x) = M and M (cid:54)= 0
then limx→c

M as well as the product law of limits that

g(x) = 1

1

lim
u→∞

φ(u)r(u)

(1 − Φ(u))r(cid:48)(u)
φ(u)r(u)

(1 − Φ(u))r(cid:48)(u)
ur(u)
r(cid:48)(u)

= lim
u→∞

= lim
u→∞

= lim
u→∞

(1 + exp(gu)) u2

1 + gu + hu2 + exp(gu)(1 + hu2)

Now in the case that g < 0 then one has that exp(gu) → 0 as u → ∞ and hence one obtains

lim
u→∞

φ(u)r(u)

(1 − Φ(u))r(cid:48)(u)

= lim
u→∞

(1 + exp(gu)) u2

1 + gu + hu2 + exp(gu)(1 + hu2)

= 1/h

18

(79)

(81)

(82)

Where, as expected we again see that in the geralized g-and-h model it produces a distribution that
satisﬁes F ∈ RV− 1

.

h

This is not unexpected since the G transform in each case drives the skewness and not the kurtosis.
We can also obtain this analysis for the g-and-k model, this yields that the g-and-k does not admit a
ﬁnite limit in either sign of the parameter g, showing that such a model is not regularly varying, as
we see in the case of the g-and-h models. However, even though this is the case we can still assess the
relative heavy tailedness of the g-and-k models compared to the base distribution under the Tukey
k-transform.

5 Estimating the General Tukey Family Loss Model Parameters

Several studies in the statistics literature have been performed on the estimation of these types of quan-
tile function speciﬁed models, see likelihood based estimation in Rayner and MacGillivray (2002a) and
Hossain and Hossain (2009) or the Bayesian approaches such as in Haynes and Mengersen (2005),Pe-
ters and Sisson (2006) and Allingham et al. (2009). In this section we propose and develop a class of
novel estimation methods based on L-moments for a range of Tukey families which shows favorable
properties compared to previously proposed methods. Before presenting this new approach developed
in this paper we ﬁrst comment on a few approaches previously proposed for instance in the g-and-h
family.

5.1 Estimating the g-and-h Loss Model Parameters

As the g-and-h family does not admit a closed-form density function, the likelihood function can only
be expressed in terms of the inverse quantile function;

fgh(x1, . . . , xn; θgh) =

X−1(xi; θgh),

d
dxi

(83)

where x1, . . . , xn are observations, θgh = (a, b, g, h)(cid:48) is the parameter vector, and X−1 is the inverse
quantile function. The high computational cost of evaluating the likelihood function comes from the
fact that X−1 can not be expressed in closed-form, and thus the quantile function must be inverted
using an iterative root-search algorithm. The maximum likelihood (ML) estimates of the g-and-h
parameters can be found by iteratively searching over the parameter space. The quality of the ML
estimates is investigated via simulations by Rayner and MacGillivray (2002a) for quantile distribution
families generated using skewness and spread functionals, where the authors ﬁnd that the ML method
can be unstable for small samples.
exists if and only if h ∈ [0, 1
and Iglewicz (); for a = 0, b = 1, and g (cid:54)= 0, the k-th raw moment is given by

Another method of ﬁtting the g-and-h distributions is by matching moments. The k-th moment
k ). The expression of the k-th raw moment can be found in 351984Martinez

n(cid:89)

i=1

(cid:40)

m∗

=

k = E(cid:16)
xk(cid:17)
k = E(cid:16)
xk(cid:17)
mk = E(cid:104)

m∗

(cid:18)k

(cid:19)

i

(cid:18) [(k − i)g]2

2(1 − kh)

(cid:19)

√
1
1 − kh

gk

(−1)i

exp

k(cid:88)

i=0

k!

=

2k/2[(k/2)!]
0

(1 − kh)−(n+1)/2

if k is even

if k is odd.

1)k(cid:105)

(x − m∗

=

(cid:18)k

(cid:19)

k(cid:88)

i

i=0

19

(−1)k−im∗

i mk−i

1

.

,

(84)

(85)

(86)

and for g = 0,

Given the k-th raw moment, the k-th central moment can be computed by,

From the central moments, the skewness ζ3 and kurtosis ζ4 are given by

ζ3 = m3/m3/2
2
ζ4 = m4/m2
2.

,

(87)

As the skewness and kurtosis are location and scale invariant shape measures, g and h can be simul-
taneously found by minimising the objective,

(ζ3 − ˆζ3)2 + (ζ4 − ˆζ4)2,

(88)

subject to 0 ≤ h < 1
estimates of g and h, b and a can be solved straightforwardly as follows.

4 , where ˆζ3 is the sample skewness and ˆζ4 is the sample kurtosis. Given the

b =(cid:112) ˆm2/m2,

a = ˆm1 − bm1,

where ˆm1 is the sample mean and ˆm2 is the sample variance. The moment matching estimator is
proposed by 232008bHeadrick et al. (), however the quality of such estimator is not investigated in
depth by the authors.
Instead of matching moments, the g-and-h parameters can be estimated by matching quantiles,
as proposed by Xu et al. (2014). Let 0 < u1 < ··· < uq < 1 denote a set of quantile levels chosen
a priori, X(u1), . . . , X(uq) denote the set of g-and-h quantiles, and ˆχu1, . . . , ˆχuq denote the set of
sample quantiles. The estimate of θgh is found by minimising the objective,

q(cid:88)

i=1

[X(ui) − ˆχui]2,

(90)

subject to b > 0 and h ≥ 0. The quality of the quantile matching estimator is determined by the
selection of u1, . . . , uq. Xu et al. (2014) choose equally spaced quantiles given by ui = i−1/3
q+1/3 , for i ∈
{1, . . . , q}. By treating u1, . . . , uq as auxiliary parameters, the number of quantiles q ∈ {4, . . . , 20}
is then selected by minimising the Akaike information criterion (AIC) given by

(89)

(91)

(92)

(93)

where

and

AIC = n log

+ 2(q + 1),

(cid:19)

(cid:18) SSE
n(cid:88)
[X(pi) − ˆχpi]2

n

SSE =

i=1

i − 1/3
n + 1/3

.

pi =

Notice that, for each q, the corresponding SSE is computed using the same number of quantiles as the
number of observations, thus making use of the full sample.

5.1.1 New Robust Estimation Approach for g-and-h Loss Models Based on Method of

L-moments

We propose a method for ﬁtting Tukey transform distributions such as the g-and-h family using L-
moments, this is a general extension of previous speciﬁc modiﬁed Tukey family models of Headrick and
Pant (2012b) as there is no assumption here on the choice of base line distribution for W . Some of the
advantages that L-moments have over conventional moments are that they exist whenever the mean of
the distribution exists and in addition they are nearly unbiased for all sample sizes and distributions,

20

and they have been noted to be more robust in the presence of outliers, see discussions in Hosking
and Wallis (2005) and Hodis et al. (2012).
L-moments are deﬁned by 281990Hosking () to be certain linear combinations of expectations of
order statistics. Speciﬁcally, let x(1) ≤ x(2) ≤ ··· ≤ x(n) denote a sample of ordered observations. For
k ∈ {1, 2, . . .}, the k-th L-moment is deﬁned as

(cid:19)
(cid:18)k − 1

i

E(cid:2)x(k−i)

(cid:3) .

lk =

1
k

(−1)i

The connection between L-moments and a quantile function becomes apparent when L-moments are
expressed as projections of a quantile function onto a sequence of orthogonal polynomials that forms
a basis of L2;

k−1(cid:88)

i=0

(cid:90) 1

0

where Lk is the k-th shifted Legendre polynomial in the sequence given generically by

(94)

(95)

(96)

lk =

F −1
X (u)Lk−1(u) du,

Lk−1(u) =

(−1)k−j(k + j)!
(j!)2(k − j)!

uj

k−1(cid:88)

j=0

Compared to classical moments, L-moments are able to characterise a wider range of distributions as
all L-moments of a distribution exist if and only if the mean exits. Furthermore, a distribution with
ﬁnite mean is uniquely characterised by its sequence L-moments. Using the representation of (95),
the ﬁrst four L-moments are given by

0

(cid:90) 1
(cid:90) 1
(cid:90) 1
(cid:90) 1

0

0

0

l1 =

l2 =

l3 =

l4 =

F −1
X (u) du,
F −1
X (u)(2u − 1) du,
F −1
X (u)(6u2 − 6u + 1) du,
F −1
X (u)(20u3 − 30u2 + 12u − 1) du.

(97)

Remark 5.1 In the above notation, the F −1
X (u) is understood to be the quantile function of the random
variable X at quantile level u. Hence, for the Tukey family of models the L-moments are to be
considered with respect to the integral of the transform of the quantile function of the base distribution,
which is implicitly included above when we write F −1
X (u) and could be considered with respect to the
base distribution quantile function as follows F −1

X (u) := r(cid:0)F −1
W (u)(cid:1).

The location and scale invariant L-moment ratios, τ3 and τ4, analogous to the classical skewness

and kurtosis, respectively termed L-skewness and L-kurtosis in 281990Hosking (), are deﬁned as

(98)
Unlike the classical skewness and kurtosis, L-skewness and L-kurtosis are bounded, with τ3 ∈ (−1, 1)
and τ4 ∈ [ 1
3 − 1), 1) for continous based distributions. The boundedness of L-moment ratios makes
them easy to interpret.

4 (5τ 2

τ3 = l3/l2,
τ4 = l4/l2.

The sample L-moments, also known as L-statistics, are unbiased estimates of L-moments based on
the order statistics of an observed sample. In particular, the ﬁrst four sample L-moments are given by

ˆl1 = ˆM0,
ˆl2 = 2 ˆM1 − ˆM0,
ˆl3 = 6 ˆM2 − 6 ˆM1 + ˆM0,
ˆl4 = 20 ˆM3 − 30 ˆM2 + 12 ˆM1 − ˆM0,

21

(99)

(cid:40) 1

n
1
n

(cid:80)n
(cid:80)n

where ˆMk is the k-th sample probability weighted moment Greenwood et al. (1979), given by

ˆMk =

i=1 x(i)

(i−1)(i−2)···(i−k)
(n−1)(n−2)···(n−k) x(i)

i=1

if k = 0
if k > 0.

(100)

An alternative, but numerically equivalent, method of computing the sample L-moments is by following
closely the deﬁnition in (94). See 501996Wang () for details.

The most general approach to performing Method of L-Moments that will be applicable for any base
distribution W and any Tukey sub-family of models involves matching L-moments of the population
to the sample L-moments. We note that in general, the integrals in (97) for the Tukey families of
models may be obtained accurately via an one-dimensional numerical integration algorithm such as
the adaptive quadrature. However, in some cases we can also obtain closed form expressions for these
L-Moments as detailed below where we derive these moments in closed form for the Gaussian based
distribution most commonly used in practice. To achieve the L-moment expressions we will work with
the quantile of the Gaussian base function for W given for the standard normal by

√

F −1
W (u) =

2erf−1 (2u − 1) .

(101)

In the case of the ﬁrst L-moment we can ﬁnd a closed form expression for the Tukey families
of models and in the case of higher order L-moments we will utilise the series expansion to ﬁnd a
result for the L-moments to any desired accuracy by truncation of the series expansion and explicit
integrations as follows. We will ﬁrst consider to make a change of variable given by

√

R =

2erf−1 (2u − 1) ,

(102)

which means that we have the n-th L-moment for the general Tukey family of models which can be
written according to the expression

ln =

=

n−1(cid:88)
n−1(cid:88)

j=0

j=0

0

(−1)n−j(n + j)!
(j!)2(n − j)!
√
2(−1)n−j(n + j)!
(j!)2(n − j)!

(cid:90) 1
W (u)(cid:1) uj du,
r(cid:0)F −1
(cid:19)j
(cid:18) 1
(cid:90) ∞
(cid:104)(cid:0)erf−1 (u)(cid:1)2(cid:105)
(cid:2)erf−1 (u)(cid:3) =

(Φ(R) + 1)

r (R)

−∞

√

2

d
du

1
2

(cid:16)√

φ

2R

(cid:17)

dR

(103)

where we used the fact that

(104)
and erf−1 (−1) = −∞ and erf−1 (1) = ∞. Furthermore, for the ﬁrst for L-Moments we can identify
the Legendre polynomials for this change of variable as follows

π exp

,

which means we can write the ﬁrst four L-Moments as follows

L0(R) = 1,
L1(R) = Φ(R),
L2(R) = 3Φ(R)2 + 3Φ(R) + 1,
L4(R) = 10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6,

(cid:16)√

(cid:17)
(cid:16)√

(cid:17)

r (R) φ

2R

dR,

2R

dR,

r (R) Φ(R)φ

r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ

dR,

2R

(cid:16)√

(cid:17)

(105)

(106)

(cid:16)√

(cid:17)

2R

dR.

−∞

(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞

−∞

−∞

−∞

√

√

√

√

2

2

2

2

l1 =

l2 =

l3 =

l4 =

22

These representations under the change of variable will now be used in the following propositions to
obtain the L-Moments for each of the diﬀerent Tukey sub-families considered.

Proposition 5.1 (g-Family Loss Model Population L-Moments) The ﬁrst four population L-
Moments of the g-family of Tukey transform Loss models is given for a = 0, b = 1 by considering

r(R) =

exp(gR) − 1

g

,

giving:

l1 =

l2 =

(cid:16) g2
(cid:17) − 1
exp(cid:0)g2(cid:1) − 1
(cid:18)

2
g

,

2g

exp
√

2π
2g
√
3

g

1,

ψ1

l3 =

3
1
2
2
l4 = 5l3 + 27l2 − 1l1 +

1
2

π

,

,

+

ψ1

(cid:18)
(cid:19)
45Arctan(cid:0)√
3(cid:1)

2√
2π
g2
4
√
π

;− 1
2

gπ

+

3

,

,

3
2

,

1
2

1
1,
2
√

2π

,

;− 1
2

(cid:18) g2

g2
4

(cid:19)

4g

+

exp
√
2√
30
3π

4

Arctan

,

(cid:19)
− 3Arctan(cid:0)√
(cid:19)
(cid:18) 1√

+ O

√

gπ

π

15

3(cid:1)
(cid:18)(cid:90) ∞

0

+ 3l2 + l1,

R3Φ(R)3φ

(cid:16)√

(cid:17)

2R

(cid:19)

dR

.

(107)

The proof of this result can be obtained in Appendix A. Similarly, one may obtain the ﬁrst four l-
moments for the h-family, the g-and-h family and the g-and-k-family of Tukey elongation loss models
are given respectively as follows.

Proposition 5.2 (h-Family Loss Model Population L-Skewness and L-Kurtosis) The ﬁrst four
population L-Moments of the h-family of Tukey transform Loss models is given for a = 0, b = 1 by
considering

(cid:18) hR2

(cid:19)

,

2

r(R) = R exp

(cid:90) ∞

−∞
1√
π

(cid:32)

R exp(cid:0)−(1 − h)R2(cid:1) dR = 0, h < 1,
(cid:16)√

1(cid:112)1 + 2(1 − h)
(cid:16)√

dR = 3l2 + l1,

(cid:33)

(cid:17)

1 +

2R

1

,

2R

dR

(cid:16)√

r (R) φ

(cid:17)
(cid:16)√

2R

dR =

1√
π

(cid:17)

2R

−∞

−∞

dR =

r (R) Φ(R)φ

(1 − h)

r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ
8π(1 − h)(cid:112)π[1 + 2(1 − h)]

−∞
l3 + 12l2 − 6l1 +

30

(cid:17)


giving:

l1 =

l2 =

l3 =

l4 =

=

−∞

(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞

√

√

√

√

2

2

2

2

√
10
8

2π

Arctan

(cid:113)

1

[2 + 4(1 − h)][ 3

2 + (1 − h)]

 .

(108)

The proof of this result can be obtained in Appendix A.

Proposition 5.3 (k-family loss model population L-skewness and L-kurtosis) The ﬁrst four
population L-Moments of the h-family of Tukey transform Loss models is given for a = 0, b = 1 by
considering

r(R) = R (1 + R)k ,

23

2R

−∞

−∞

(cid:17)

(cid:111)

2R

dR

r (R) φ

dR = 0,

r (R) Φ(R)φ

(cid:16)√

(cid:17)
(cid:16)√

(cid:18)(cid:90) ∞

(cid:90) ∞
(cid:90) ∞
(cid:110)
R9Φ(R) exp(cid:0)−R2(cid:1) dR
I1 +(cid:101)I1 + 2kI3 + (k − 1)kI5 + 1/3(k − 2)(k − 1)kI7
(cid:90) ∞
r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
(cid:110)
(cid:111)
(G1 + (cid:101)G1) + k(G3 + (cid:101)G3) + 1/2(k − 1)k(G5 + (cid:101)G5) + 1/6(k − 2)(k − 1)k(G7 + (cid:101)G7)
(cid:19)
(cid:18) 3
R9Φ(R) exp(cid:0)−R2(cid:1) dR
(cid:90) ∞
(cid:16)√
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ
(cid:19)
(cid:18) 1

(cid:17)
(cid:18)(cid:90) ∞

R9Φ(R) exp(cid:0)−R2(cid:1) dR

−∞
[l3 − 3l2 − l1] + 12l2 − 6l1 +

(cid:18)(cid:90) ∞

(cid:16)√

√
4

l1 + O

Arctan

2R

dR

2R

dR

(cid:19)

(cid:19)

(cid:17)

+ O

+ O

−∞

−∞

+ 1

π

−∞

,

,

√
30

8π

3π

−∞

(cid:19)

,

giving:
√

l1 =

√

2

2

1√
2π
√

2

l2 =

=

l3 =

√
3
2π

=

2

+ 3l2 +

√

2

5√
2

l4 =

=

with

4

(cid:32)

(cid:18)

I1 =

1
2

(cid:18)

I2m+1 =

(cid:101)I1 =

1
2

G2n+1 =

(cid:101)G2n+1 =

(cid:19)

(cid:19)

,

1√
3

1 +
(−1)mm!

2
1 − 1√
3
(−1)n√
(−1)n+1√

2π

2π

∂m
∂pm

2

− (−1)m
(cid:32)

,

1

p(cid:112)1/2 + p
(cid:32)
p(cid:112)1/2 + p

1

∂n
∂pn

∂n
∂pn

1

p(cid:112)p + 1/2
(cid:18)

,

(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=1
(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=1
(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=1

1 + 2p

,

1√
1 + 2p

(cid:18) −1√

Arctan

Arctan

(109)

(110)

.

Finally, one can also ﬁnd the g-and-h family Population L-moments in closed form as follows.

Proposition 5.4 (g-and-h-Family Loss Model Population L-Skewness and L-Kurtosis) The
ﬁrst four population L-Moments of the g-and-h family of Tukey transform Loss models is given for
a = 0, b = 1 by considering

giving:

√

2

l1 =

(cid:18) hR2

(cid:19)

,

2

exp(gR) − 1

r(R) =

(cid:16)√

exp

(cid:17)

(cid:90) ∞
(cid:16) g2

−∞

g

(cid:17)√

r (R) φ

2R

dR

exp

=

g

4−2h
√
2 − h

2

−

√

2
4 − 2h

,

g

h < 2,

(111)

24

1
2

,

3
2

,

1
2

;−

1

2(1 − h/2)

,

g2

4(1 − h/2)

(cid:19)

√

2π
2

,

√
− 1
g

π

(cid:90) ∞

−∞

√

2

l2 =

=

l3 =

exp

√
1
2g
π
√

(cid:90) ∞

2

−∞

(cid:17)

(cid:16)√
(cid:17)√

2π

2R

dR

r (R) Φ(R)φ

(4−2h)
√
2 − h

(cid:16) g2
r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
∞(cid:88)

(cid:26) 1

√

gπ

+

1

(cid:18)
(cid:17)

2(1 − h/2)

ψ1

1,

(cid:16)√

2R

dR

= 3l2 + l1 +
21+n(2 − h)−(3/2)−nΓ(3/2 + n)2F1 [1/2, 3/2 + n, 3/2, 1/(−2 + h)]

πn!

n=0

4

2n(2 − h)−1−nΓ(1 + n)

√
2

π

(cid:18)

6(g)n−1√
(cid:32)

1

p(cid:112)1/2 + p
∞(cid:88)

∂n
∂pn

Arctan

r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ

1√
1 + 2p

(g)2n+1
(2n + 1)!

(−1)n√

2π

∂n
∂pn

 ,
(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=(1−h/2)
(cid:17)
(cid:16)√
(cid:32)
p(cid:112)1/2 + p

2R

1

dR

Arctan

+

+1/4
√

l4 =

2

√

(−1)n1
2
π

(cid:90) ∞

−∞

= 12l2 − 6l1 +

√
1

+

+

+

15

g

g

π

π

π

n=0

n=0

√
45

(g)n
n!

2g
√
5

(g)2n+1
(2n + 1)!

∞(cid:88)
∞(cid:88)
∞(cid:88)
(cid:18)(cid:90) ∞
with (cid:52) =(cid:112)3/2 + (1 − h/2).

√
Rn erf(R/

π(1 − h/2)

√
5
4g

(g)n
n!

−∞

n=1

n=1

π

1

+ O

(cid:18)

1√
1 + 2p

(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=(1−h/2)

21+n(2 − h)−(3/2)−nΓ(3/2 + n)2F1 [1/2, 3/2 + n, 3/2, 1/(−2 + h)]

√

π

(cid:32)

2(cid:52)(cid:112)1/2 + (1 − h/2)

1

(cid:33)

,

21/2(−1+n)(1 + exp(nπ))(2 − h)−(1/2)−n/2Γ[(1 + n)/2]

3

(cid:112)1 + 2(1 − h/2)
2)3 exp(cid:0)−(1 − h/2)R2(cid:1) dR

(cid:19)

Arctan

,

(112)

Then, given the L-Moments, for instance in the case of the g-and-h subfamily, the estimates of g

and h are simultaneously found by iteratively minimising the objective

(τ3 − ˆτ3)2 + (τ4 − ˆτ4)2,

(113)
subject to 0 ≤ h < 1, where ˆτ3 = ˆl3/ˆl2 is the sample L-skewness and ˆτ4 = ˆl4/ˆl2 is the sample L-kurtosis.
The estimates of a and b can be obtained using the following properties of L-moments.
Proposition 5.5 (L-moments of aﬃne functions of random variables) Let Lk(·) denote the k-
th L-moment operator. Consider random variables X and Y such that Y = a + bX, where a and b are
constants. The ﬁrst and second L-moments of Y can be expressed as

L1(Y ) = a + bL1(X),
L2(Y ) = bL2(X).

Given the estimates of g and h, using (114), one can estimate the values of b and a by

b = ˆl2/l2,
a = ˆl1 − bl1.

25

(114)

(115)

An alternative L-moment based approach can also be considered, where we consider a special
choice of base distribution for W given by the logistic model. If one modiﬁes the Tukey transform
family in the g-and-h case as follows it is also possible to obtain a re-parameterized form which admits
closed form expressions for the L-moments. This particular sub-family case is known as the L-moment
Tukey transformation families and it was ﬁrst developed by Headrick and Pant (2012b). The choice
of logistic distribution for W means that it will take a density, distribution, and quantile functions
given by

f (w) =

F (w) =

exp (−(w − µ)/s)

s (1 + exp (−(w − µ)/s))2 ,
1 + exp (−(w − µ)/s)

,

(cid:19)

1

(cid:18) α

1 − α

QW (α) = µ + s ln

, α ∈ [0, 1],

(116)

for all w ∈ R, µ ∈ R, and s ∈ R+. The motivation for modifying the distribution transformed under
the Tukey structure was related to the fact that inference on the parameters can then be performed
more readily via L-moments and L-correlation. The resulting four basic classes of modiﬁed Tukey
quantile function transformations are then given in Deﬁnition 5.1.
Deﬁnition 5.1 (L-Moment Tukey Transforms) Let W ∼ Logistic(µ = 0, s = 1) be a standard
logistic distributed random variable. Then the loss random variable X has severity distribution given
by the L-moment Tukey family as follows:

1. The γ−κ Tukey family transformation is given by

X = Tγ,κ(W ) = γ−1 (exp(γW ) − 1) exp(κ|W|).

(117)
This is the analog of the g-and-h Tukey transform for the logistic distribution case for γ (cid:54)= 0 and
κ ≥ 0;

2. The κL−κR Tukey family transformation is given by

W exp (κL|W|) , W ≤ 0

W exp (κR|W|) , W ≥ 0.

X = TκL,κR(W ) =

(118)

This is the analog of the double h–h Tukey transform for the logistic distribution case for κL ≥ 0,
κR ≥ 0, and κL (cid:54)= κR.

These modiﬁed transformations then allow one to obtain the population L-moments in terms of the
parameters of the L-moment γ − κ Tukey family as well as the asymmetric L-moment κL − κR Tukey
family, which can be matched to the sample-estimated L-moments and then utilized as a system of
nonlinear equations to be solve numerically via root search for the resulting L-moment parameter
estimates.
Proposition 5.6 (L-Moment Estimators for the L-Moment γ−κ Tukey Family) Consider a
γ-and-κ distributed random variable X ∼ F (γ, κ) and a sample of n loss data points with order statis-
that will be used to ﬁt the γ-and-κ distribution. Then under the restrictions that
γ + κ < 1, κ < 1, and 1 + γ > κ, which allow the ﬁrst two L-moments to be ﬁnite, one obtains the
following two equations for the population’s ﬁrst two L-moments λ1 and λ2 given by:
(−γ − κ)h1 + (γ − κ)h2 + (−γ + κ)h3 + 2κh4 + (γ + κ)h5 − 2κh6

tics (cid:8)X(i,n)

(cid:9)n

i=1

λ1 =

λ2 =

2γ − (γ + κ)2h1 + (γ − κ)2 (h1 − h3) + (γ + κ)2h5

2γ

2γ

26

,

(119)

where h1, h2, . . . , h6 are deﬁned with respect to the Harmonic number functions with the following
arguments according to

(cid:21)

(−1 − γ − κ)

,

h2 = H

(−1 + γ − κ)

(cid:21)

(cid:20) 1
(cid:20) 1
(cid:20)

2

2
− 1
2

h1 = H

h3 = H

h5 = H

(cid:21)

(γ − κ)

h4 = H

,

(cid:21)

(γ + κ)

,

h6 = H

(cid:21)

(cid:20) 1

2

(cid:21)

(−1 − κ)

− 1
2

κ

,

(cid:20) 1
(cid:20)

2

(120)

(123)

(124)

with the harmonic number functions deﬁned for any x > 0 by

∞(cid:88)

1

k(x + k)

k=1

H[x] := x

.

(121)

One can then estimate sample L-moments that can be matched to the population moments to solve
numerically for the parameters.

Remark 5.2 As noted by Headrick and Pant (2012b), expressions are also developed for the popula-
tion L-skewness τ3 and L-kurtosis τ4 should one wish to utilize these for L-moment matching parameter
estimation.

Analogously, the solutions for the ﬁrst two population L-moments for the class of κL−κR Tukey
transformations were detailed by Headrick and Pant (2012b) and can be used to perform parameter
estimation, as detailed in Proposition 5.7.
Proposition 5.7 (L-Moment Estimators for the L-Moment κL − κR Tukey Family) Consider
the asymmetric κL-and-κR distributed random variable X ∼ F (κL, κR) and a sample of n loss data
that will be used to ﬁt theκL-and-κR distribution. Then under
the restrictions that κL < 1 and κR < 1, which allow the ﬁrst two L-moments to be ﬁnite, one obtains
the following two equations for the population’s ﬁrst two L-moments λ1 and λ2 given by

points with order statistics (cid:8)X(i,n

(cid:9)n

i=1

λ1 =

λ2 =

1
4
1
4

[2p5 − 2p6 − 2p7 + 2p8 − κLp9 + κLp10 + κRp11 − κRp12]
[4 + κL (−4p5 + 4p6 + κL (p9 − p10)) + 4 + κR (−4p7 + 4p8 + κR (p11 − p12))] ,

(122)

where p5, p6, . . . , p12 are deﬁned with respect to the polygamma functions with the following arguments
according to

(cid:20)
(cid:104)
(cid:20)

p5 = P

p8 = P

p11 = P

0,

1
2

− κL
2
0, 1 − κR
2
− κR
2

1
2

1,

(cid:21)
(cid:105)
(cid:21)

(cid:104)
(cid:20)
(cid:104)

1,

0, 1 − κL
2
− κL
1
2
2
1, 1 − κR
2

(cid:105)
(cid:21)
(cid:105)

,

, p6 = P

, p7 = P

0,

, p9 = P

, p10 = P

, p12 = P

(cid:20)
(cid:104)

(cid:21)
(cid:105)

− κR
1
2
2
1, 1 − κL
2

with the polygamma functions deﬁned by

P [m, x] := (−1)m+1m!

∞(cid:88)

k=0

1

(x + k)m+1 .

One can then estimate sample L-moments that can be matched to the population L-moments to solve
numerically for the parameters.

27

6 Simulation study: Comparison of Estimation Procedures for Tukey

Elongation Family Claims Models

Independent samples are generated from two g-and-h distributions whose parameters are (0, 1, 0.1, 0.1)(cid:48)

To investigate the quality of the various parameter estimation methods, including the approach we
have developed in this manuscript based on L-moments, in ﬁtting the g-and-h distributions, we conduct
a simulation study, focusing on bias, variability, and computational cost of each method. The methods
under comparison are moment matching (MoM), maximum likelihood (ML), quantile matching (QM),
and method of L-moments (MoLM).
and (0, 1, 0.5, 0.2)(cid:48), with the second one being more skewed and heavier tailed than the ﬁrst. Notice
that the ﬁrst four moments are ﬁnite for both distributions as h < 1
4 in both cases, and thus the
MoM estimator is not being disadvantaged by design. Independent observations from a g-and-h dis-
tribution are generated by ﬁrst generating ui from an uniform distribution on the interval (0, 1) for
i ∈ {1, . . . , n}. A sample from the g-and-h distribution is then obtained by applying the transfor-
mation, xi = X(ui), given by (33). We use the Mersenne Twister (MT) pseudo-random number
generator Matsumoto and Nishimura (1998) to generate the uniform observations. Samples of sizes
n = 50, n = 100, and n = 1000 are considered. We generate 1000 samples of each sample size from
each g-and-h distribution.

Summaries of the estimates by the studied methods are reported in Table 1. For each parameter,
we report the Monte Carlo mean (Mean), standard deviation (SD), and mean squared error (MSE).
We also report the mean and standard deviation of the per-estimation-time in seconds (Time) of each
method, which allows us to assess the feasibility and scalability of the method.

It can be seen that for both g-and-h distributions, all sample sizes, and all four parameters, the
MoLM has either lowest or equally lowest MSE amongst all considered estimators. The MoM has the
highest MSE in most cases. As the sample size increases, the MSE is reduced for all estimators of all
parameters, except for the MoM of the h parameter. Comparing the Monte Carlo means, the MoM
is particularly poor at estimating the h parameter; the value of h is signiﬁcantly underestimated even
for n = 1000. The MoLM slightly underestimates the g and the h parameters, however the bias is
reducing with an increasing sample size. Comparing between the QM and the MoLM for the g and
the h parameters, the mean of QM estimates is closer to the true value, however the MoLM has a
lower standard deviation, especially for n = 50 and n = 100.

Comparing the mean per-estimation-time amongst the estimators, the MoLM is the fastest for the
ﬁrst g-and-h distribution, and is sometimes slightly slower than MoM for the second one. The ML
estimator is the slowest in each case and scales poorly with sample size.

The conclusion of the results in this study demonstrate that the estimation of the g-and-h family
of claims severity models is accurately and eﬃciently estimated using the proposed approach we
have developed based around L-moments based estimation which was based on equating our derived
population L-moments to the sample estimated L-moments and solving this system of non-linear
equations. Importantly, the method was accurate for the h-parameter which dictates the kurtosis of
the resulting claims severity distribution and will be important to be accurately and robustly estimated
in practical settings. Furthermore, our proposed L-moments based approach was signiﬁcantly more
eﬃcient computationally compared to other procedures, especially with increasing sample size.

28

n = 50

n = 100

n = 1000

(a, b, g, h)

(0, 1, 0.1, 0.1)

(0, 1, 0.5, 0.2)

MoM

ML

QM MoLM MoM

ML

QM MoLM

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD
MSE

Mean

SD

0.002
0.167
0.028

1.104
0.142
0.031

0.090
0.176
0.031

0.022
0.028
0.007

0.177
0.104

0.001
0.124
0.015

1.082
0.105
0.018

0.102
0.153
0.023

0.040
0.033
0.005

0.175
0.107

-0.001
0.043
0.002

1.028
0.042
0.003

0.103
0.058
0.003

0.082
0.022
0.001

0.152
0.090

-0.002
0.160
0.026

-0.001
0.160
0.026

-0.001
0.159
0.025

1.008
0.151
0.023

0.100
0.166
0.028

0.075
0.086
0.008

18.749
3.229

0.003
0.112
0.013

1.007
0.113
0.013

0.099
0.115
0.013

0.085
0.065
0.004

38.064
5.837

0.001
0.037
0.001

1.002
0.038
0.001

0.099
0.036
0.001

0.098
0.021
0.000

390.220
76.362

0.994
0.153
0.023

0.100
0.175
0.031

0.101
0.103
0.011

0.607
0.040

0.003
0.113
0.013

0.996
0.117
0.014

0.102
0.123
0.015

0.100
0.076
0.006

0.600
0.046

0.001
0.036
0.001

0.999
0.036
0.001

0.099
0.038
0.001

0.100
0.024
0.001

0.607
0.057

0.994
0.148
0.022

0.095
0.156
0.024

0.096
0.081
0.007

0.142
0.027

0.003
0.112
0.013

0.996
0.112
0.013

0.098
0.113
0.013

0.098
0.061
0.004

0.141
0.021

0.001
0.036
0.001

0.999
0.035
0.001

0.100
0.036
0.001

0.099
0.020
0.000

0.130
0.021

0.001
0.222
0.049

1.446
0.382
0.345

0.425
0.217
0.053

0.008
0.023
0.037

0.142
0.038

-0.051
0.194
0.040

1.413
0.307
0.264

0.529
0.207
0.044

0.008
0.023
0.037

0.155
0.043

-0.180
0.107
0.044

1.188
0.130
0.052

0.791
0.142
0.105

0.005
0.015
0.038

0.267
0.132

0.007
0.180
0.032

1.024
0.190
0.037

0.470
0.208
0.044

0.159
0.122
0.017

21.192
5.309

0.024
0.343
0.119

1.032
0.226
0.052

0.489
0.171
0.029

0.175
0.087
0.008

50.968
188.407

-0.185
2.590
6.744

1.424
3.606
13.183

0.474
0.190
0.037

0.182
0.055
0.003

539.302
206.724

0.005
0.165
0.027

1.007
0.208
0.043

0.480
0.222
0.050

0.195
0.170
0.029

0.631
0.057

0.008
0.114
0.013

1.015
0.157
0.025

0.502
0.170
0.029

0.192
0.127
0.016

0.616
0.044

0.001
0.036
0.001

1.003
0.049
0.002

0.502
0.053
0.003

0.199
0.046
0.002

0.599
0.036

-0.001
0.163
0.027

1.007
0.193
0.037

0.463
0.204
0.043

0.173
0.111
0.013

0.193
0.051

0.006
0.114
0.013

1.017
0.144
0.021

0.487
0.157
0.025

0.178
0.086
0.008

0.192
0.044

0.001
0.036
0.001

1.003
0.045
0.002

0.500
0.052
0.003

0.197
0.031
0.001

0.188
0.039

a

b

g

h

Time
(sec)

a

b

g

h

Time
(sec)

a

b

g

h

Time
(sec)

Table 1: Summaries of g-and-h parameter estimates by various methods on simulated data.

29

7 Real Data Empirical Application

In this section we consider a real data study involving a very large data set of claims records from
Australia. In this study we consider ﬁtting the g, h, g-and-h, and g-and-k distributions which are
employed to model the total gross payment of individual claims of the Compulsory Third Party
(CTP) insurance from an insurance company based in Queensland, Australia. The data contains
115,300 accident records from September 1994 to December 2008. Unlike most models in non-life
insurance where the annual aggregate amounts of claims are modelled, in this paper, we are interested
in modelling the distributions of individual claim payment amounts, not the aggregate for a claims
development year. In this way we resolve to a better degree the actual claims distribution, which we
can achieve through use of a ﬂexible severity loss model. Two key challenges of modelling such data
are: the computational burden associated with the large number of observations, and the models for
aggregate amounts may not be ﬂexible enough to adequately model the losses at the claim level.

In undertaking this study, we are also interested in studying the time varying skewness and kurtosis
of the claims records over time, to achieve this we consider to split the records into monthly time
series and study the distributional properties each month, allowing us to study temporal variation in
skewness and kurtosis of such claims annualy.

a

b

g

g
h

g-and-h
g-and-k

9.571
9.355
9.566
9.568

1.794
1.717
1.717
1.665

-0.238

-

-0.230
-0.293

h

-

0.053
0.035

k

-
-
-

-

0.088

RMSE

0.143
0.307
0.179
0.138

Table 2: MoLM parameter estimates using all claims.

Table 2 reports the parameters of the g, h, g-and-h, and g-and-k distributions ﬁtted to the log
total gross payment of all the claims in the sample. All models are estimated using the method of L-
moment. To compare the goodness-of-ﬁt between the models, we compute the root-mean-square-error
(RMSE) between the model quantiles and the sample quantiles. Speciﬁcally

(cid:34)

n(cid:88)

1

1
n

(cid:35)1/2

RMSE =

[X(ui) − ˆχui]2

,

(125)

where n is the number of observations, X(ui) is the model quantile, ˆχui is the sample quantile, and
the quantile level ui is given by

i − 0.5

.

n

ui =

The estimates of the g indicates that the log payments are negatively skewed. From the estimates of
h and k, we see that the ﬁtted distributions have tails that are only slightly heavier than the Gaussian
tails. The values of the RMSE show that, for the entire sample, the g-and-k distribution provides the
best ﬁt, followed by the g distribution, while the h distribution ﬁts the data the least well. The fact
that the g and the g-and-k distributions show a similar ﬁt indicates that for this type of data it tends
to be more important to model the asymmetry than the heavy-tailedness. A Q-Q plot of the sample
quantiles vs. the quantiles of the ﬁtted model is shown for each of the models in Figure 1.

30

Figure 1: Q-Q plot sample quantiles vs. model quantiles.

Figure 2

31

Year9496980002040608a567891011(a)Year9496980002040608b11.21.41.61.822.2(b)Year9496980002040608g-0.4-0.3-0.2-0.100.10.2(c)Year9496980002040608h00.050.10.150.2(d)Figure 3

We are also interested in how the parameters of the g-and-h and g-and-k distributions evolve over
time. For this purpose, we estimate the two models using log payments from each month of the year.
In Figure 2, each line is created by plotting the parameter estimate of a speciﬁc month over the years
covered by the sample (1994 to 2008). A similar plot for the g-and-k distribution is shown in Figure 2.
It seems that there was a structural change after 2002, where both distributions increased in scale but
became less heavy-tailed. The locations of the distributions also started to shift downward.

32

Year9496980002040608a567891011(a)Year9496980002040608b11.522.53(b)Year9496980002040608g-0.6-0.4-0.200.20.4(c)Year9496980002040608k-0.4-0.200.20.4(d)Figure 4

To compare the goodness-of-ﬁt between the models for each year, we compute RMSE in Equation
(125) for each month of the year and then plot the average of the 12 monthly RMSE values for each
year in the sample. The plot of the average RMSE values for each model in shown Figure 4. Once
again, the g-and-k distribution provides the best ﬁt in every year and the h distribution is worst for
most of the years.

8 Conclusion

In this paper we have proposed a new family of claims reserving models for non-life insurance severity
modelling corresponding to a ﬂexible class of Tukey elongation transform models. We have outlined
the characterization of the sub-families of g, h, k, j, h-h, g-and-h, g-and-k, g-and-j and generalized
g variants. Furthermore, we have studied the properties of such models, including deriving novel
relationships for the tail behaviour and the population L-moments for such models. Furthermore, we
have demonstrated the estimation of these claims model parameters can accurately and eﬃciently be
performed using L-method of moment matching, which can often be more accurate and eﬃcient that
alternative procedures based on moment-matching or maximum likelihood. Finally, we have applied
the methods and models to calibration of claims severity models for a large insurance database based
on CTP automotive claims data from Australia.

References

Aiuppa, T. A. (1988). Evaluation of pearson curves as an approximation of the maximum probable

annual aggregate loss. Journal of Risk and Insurance, pages 425–441.

Allingham, D., King, R., and Mengersen, K. L. (2009). Bayesian estimation of quantile distributions.

Statistics and Computing, 19(2):189–201.

Azzalini, A. (1985). A class of distributions which includes the normal ones. Scandinavian journal of

statistics, pages 171–178.

33

Year949596979899000102030405060708MeanRMSE(of12months)0.10.150.20.250.30.350.4ghg-and-hg-and-kBalanda, K. P. and MacGillivray, H. (1988). Kurtosis: a critical review. The American Statistician,

42(2):111–119.

Balanda, K. P. and MacGillivray, H. (1990). Kurtosis and spread. Canadian Journal of Statistics,

18(1):17–30.

Bingham, N. H., Goldie, C. M., and Teugels, J. L. (1989). Regular variation, volume 27. Cambridge

university press.

Chan, J. S., Choy, S. B., and Makov, U. E. (2008). Robust bayesian analysis of loss reserves data

using the generalized-t distribution. Astin Bulletin, 38(01):207–230.

Cruz, M. G., Peters, G. W., and Shevchenko, P. V. (2015). Fundamental Aspects of Operational Risk

and Insurance Analytics: A Handbook of Operational Risk. John Wiley & Sons.

Cummins, J. D., Dionne, G., McDonald, J. B., and Pritchett, B. M. (1990). Applications of the gb2
family of distributions in modeling insurance loss processes. Insurance: Mathematics and Economics,
9(4):257–272.

Degen, M., Embrechts, P., and Lambrigger, D. D. (2007). The quantitative modeling of operational

risk: between g-and-h and evt. Astin Bulletin, 37(02):265–291.

Denuit, M., Dhaene, J., Goovaerts, M., and Kaas, R. (2006). Actuarial theory for dependent risks:

measures, orders and models. John Wiley & Sons.

Dong, A. and Chan, J. (2013). Bayesian analysis of loss reserving using dynamic models with gener-

alized beta distribution. Insurance: Mathematics and Economics, 53(2):355–365.

Dutta, K. and Perry, J. (2006). A tale of tails: an empirical analysis of loss distribution models for

estimating operational risk capital. FRB of Boston Working Paper.

Dutta, K. K. and Babbel, D. F. (2002). On measuring skewness and kurtosis in short rate distributions:
The case of the us dollar london inter bank oﬀer rates. Center for Financial Institutions Working
Papers 02, 25.

Field, C. and Genton, M. G. (2012). The multivariate g-and-h distribution. Technometrics.

Fischer, M. (2010). Generalized tukey-type distributions with application to ﬁnancial and teletraﬃc

data. Statistical Papers, 51(1):41–56.

Fischer, M., Horn, A., and Klein, I. (2007). Tukey-type distributions in the context of ﬁnancial data.

Communications in StatisticsTheory and Methods, 36(1):23–35.

Fischer, M. and Klein, I. (2004). Kurtosis modelling by means of the j-transformation. Allgemeines

Statistisches Archiv, 88(1):35–50.

Greenwood, J. A., Landwehr, J. M., Matalas, N. C., and Wallis, J. R. (1979). Probability weighted
moments: deﬁnition and relation to parameters of several distributions expressable in inverse form.
Water Resources Research, 15(5):1049–1054.

Haynes, M. and Mengersen, K. (2005). Bayesian estimation ofg-and-k distributions using mcmc.

Computational Statistics, 20(1):7–30.

Haynes, M. A., MacGillivray, H., and Mengersen, K. (1997). Robustness of ranking and selection rules
using generalised g-and-k distributions. Journal of Statistical Planning and Inference, 65(1):45–66.

Headrick, T. C., Kowalchuk, R. K., and Sheng, Y. (2008a). Parametric probability densities and
distribution functions for tukey g-and-h transformations and their use for ﬁtting data. Educational
Psychology and Special Education at OpenSIUC.

34

Headrick, T. C., Kowalchuk, R. K., and Sheng, Y. (2008b). Parametric probability densities and
distribution functions for tukey g-and-h transformations and their use for ﬁtting data. Applied
Mathematical Sciences, 2(9):449–462.

Headrick, T. C. and Pant, M. D. (2012a). Characterizing tukey h and hh-distributions through l-

moments and the l-correlation. ISRN Applied Mathematics, 2012.

Headrick, T. C. and Pant, M. D. (2012b). A logistic-moment-based analog for the tukey-, and-system

of distributions. ISRN Probability and Statistics, 2012.

Hoaglin, D. C. (1985). Summarizing Shape Numerically: The g-and-h Distributions. Wiley Online

Library.

Hodis, F. A., Headrick, T. C., and Sheng, Y. (2012). Power method distributions through conventional

moments and l-moments. Educational Psychology and Special Education at OpenSIUC.

Hosking, J. R. (1990). L-moments: analysis and estimation of distributions using linear combinations
of order statistics. Journal of the Royal Statistical Society. Series B (Methodological), 52(1):105–124.

Hosking, J. R. M. and Wallis, J. R. (2005). Regional frequency analysis: an approach based on L-

moments. Cambridge University Press.

Hossain, M. A. and Hossain, S. S. (2009). Numerical maximum likelihood estimation for the g-and-k

distribution using ranked set sample. Journal of Statistics, 16(1).

Jim´enez, J. A. and Arunachalam, V. (2011). Using tukeys g and h family of distributions to calculate

value-at-risk and conditional value-at-risk. Journal of Risk, 13(4):95–116.

Jorge, M. and Boris, I. (1984). Some properties of the tukey g and h family of distributions. Commu-

nications in Statistics-Theory and Methods, 13(3):353–369.

Karatzas, I. and Shreve, S. E. (1991). Brownian motion and stochastic calculus, vol. 113 of. Graduate

texts in mathematics.

Klugman, S. A., Panjer, H. H., and Willmot, G. E. (2012). Loss models:

from data to decisions,

volume 715. John Wiley & Sons.

Martinez, J. and Iglewicz, B. (1984). Some properties of the tukey g and h family of distributions.

Communications in Statistics-Theory and Methods, 13(3):353–369.

Matsumoto, M. and Nishimura, T. (1998). Mersenne twister: a 623-dimensionally equidistributed uni-
form pseudo-random number generator. ACM Transactions on Modeling and Computer Simulation
(TOMACS), 8(1):3–30.

McNeil, A. J., Frey, R., and Embrechts, P. (2015). Quantitative risk management: Concepts, techniques

and tools. Princeton university press.

Morgenthaler, S. and Tukey, J. W. (2000). Fitting quantiles: Doubling, hr, hq, and hhh distributions.

Journal of Computational and Graphical Statistics, 9(1):180–195.

Paulson, A. S. and Faris, N. (1985). A practical approach to measuring the distribution of total
annual claims. In Strategic Planning and Modeling in Property-Liability Insurance, pages 205–223.
Springer.

Peters, G. and Sisson, S. (2006). Bayesian inference, monte carlo sampling and operational risk.

Journal of Operational Risk, 1(3):27–50.

35

Peters, G. W. and Shevchenko, P. V. (2015). Advances in Heavy Tailed Risk Modeling: A Handbook

of Operational Risk. John Wiley & Sons.

Peters, G. W., Shevchenko, P. V., and W¨uthrich, M. V. (2009). Model uncertainty in claims reserving

within tweedie’s compound poisson models. Astin Bulletin, 39(01):1–33.

Peters, G. W., Shevchenko, P. V., Young, M., and Yip, W. (2011). Analytic loss distributional
approach models for operational risk from the α-stable doubly stochastic compound processes and
implications for capital allocation. Insurance: Mathematics and Economics, 49(3):565–579.

Prudnikov, Anatoli, P. and Marichev, O. I. (1998). Integrals and series: special functions, volume 2.

CRC Press.

Raoult, J.-P. and Worms, R. (2003). Rate of convergence for the generalized pareto approximation of

the excesses. Advances in Applied Probability, pages 1007–1027.

Rayner, G. and MacGillivray, H. (2002a). Numerical maximum likelihood estimation for the g-and-k

and generalized g-and-h distributions. Statistics and Computing, 12(1):57–75.

Rayner, G. D. and MacGillivray, H. L. (2002b). Numerical maximum likelihood estimation for the

g-and-k and generalized g-and-h distributions. Statistics and Computing, 12(1):57–75.

Taylor, G. (2012). Loss reserving: an actuarial perspective, volume 21. Springer Science & Business

Media.

Tukey, J. W. (1977). Modern techniques in data analysis.

In Proceedings of the NSF-Sponsored

Regional Research Conference.

Wang, Q. (1996). Direct sample estimators of l moments. Water Resources Research, 32(12):3617–

3619.

W¨uthrich, M. V. and Merz, M. (2008). Stochastic claims reserving methods in insurance, volume 435.

John Wiley & Sons.

Xu, Y., Iglewicz, B., and Chervoneva, I. (2014). Robust estimation of the parameters of -and- distri-
butions, with applications to outlier detection. Computational Statistics & Data Analysis, 75(0):66
– 80.

A Appendix A

The following integral identities from Prudnikov and Marichev (1998) are useful for the following
derivations of the population L-moments.

36

Φ(x) =

(cid:18)

1
2

erfc

(cid:19)

− x√
2
√

2π

−∞

−∞

−∞

(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
(cid:90) 0
(cid:90) 0
(cid:90) ∞
(cid:90) ∞

0

−∞

−∞

0

3

2

1
π

√

2π exp

Arctan

Φ(x)dx =

Φ(x)2φ(x)dx =

exp(cx − x2/2)dx =

(cid:17)
(cid:16)√
(cid:18) c2
(cid:16) c2
(cid:17)
b(cid:112)n(2π)n−1
(cid:18) π
(cid:18) π

(cid:19)
(cid:18) b2xn − c
(cid:19)(cid:19)
(cid:18) b
(cid:18) b
(cid:19)(cid:19)
erfc(cx) exp(cid:0)−px2(cid:1) xndx = In, R(cid:8)c2 + p(cid:9) > 0

1
2π|a|
1
2π|a|

exp(cx)φ(bx)ndx =

Φ(bx)φ (ax) dx =

Φ(bx)φ (ax) dx =

− arctan

+ arctan

|a|

|a|

exp

√

2nb2

(cid:19)

Φ

n

2

2

b

I1 =

I2m =

,

1
2p

(cid:32)

(cid:33)
c(cid:112)c2 + p
1 −
(cid:18) 1√
(−1)m√
∂m
∂pm
π
2pm+1 − (−1)m
(−1)mm!
(cid:18) a
(cid:16) a

(cid:18)√
(cid:32)
xa−1erf(cx) exp(cid:0)−px − bx2(cid:1) dx =

∂m
∂pm

Arctan

(cid:17)

p

2

p
c

+ 1

ψ1

2

+ 1,

1
2

2

cp√
πba/2+1

Γ

I2m+1 =

(cid:90) ∞

0

−

(cid:19)(cid:19)
p(cid:112)p + c2

1

(cid:33)

c√
πb(a+1)/2
;− c2
3
b
2

3
2

,

,

,

(cid:90) ∞
(cid:90) ∞

0

0

=

1
πp
(cid:52) =

(−1)nc

erf2(cx) exp(cid:0)−px2(cid:1) x2n+1dx =
erf(ax)erf(bx)erf(cx) exp(cid:0)−px2(cid:1) xdx
(cid:33)
(cid:34)
(cid:52)(cid:112)a2 + p
a(cid:112)a2 + p
(cid:112)

a2 + b2 + c2 + p, R{p > 0}

Arctan

(cid:32)

bc

π

+

(cid:32)

∂n
∂pn

b(cid:112)b2 + p

1

p(cid:112)c2 + p
(cid:32)

Arctan

A.1 Proof of Proposition 5.1

+ C

(126)

(cid:19)

ψ1

(cid:18) a + 1

2

,

1
2

,

3
2

,

1
2

;− c2
b

,

p2
4b

(cid:19)

(cid:18) a + 1
(cid:19)

2

Γ

p2
4b

(cid:32)

Arctan

(cid:33)(cid:33)

, R{p > 0}

c(cid:112)c2 + p
(cid:33)

+

(cid:52)(cid:112)b2 + p

ac

c(cid:112)c2 + p

(cid:32)

(cid:33)(cid:35)

,

(cid:52)(cid:112)c2 + p

ab

Arctan

(127)

Proof A.1 It will also be useful to recall the integral identities from Prudnikov and Marichev (1998)
which are given in Appendix A which are used to make these proofs for each of the ﬁrst four L-moments
as follows:

(cid:90) ∞

−∞

√

2

l1 =

(cid:16)√

(cid:17)

√

2
g

dR =

(cid:90) ∞

−∞

r (R) φ

2R

(cid:16)√

(cid:17)

exp

dR =

2R

(cid:16) g2

(cid:17) − 1

2
g

,

(128)

(exp(gR) − 1) φ

37

l2 =

=

=

l3 =

= 3

√
2
√

2
g
√
3
2
4g
√
3

π

4g
√
3
g
√
3
2
4g
√
3

g

π

√

=

+

=

+

=

−∞

−∞

−∞

dR +

−∞

−∞

√
2
√

2
√
2g
−
√

0
2
g

(cid:18)

0

g2
4

√

gπ

π

ψ1

1,

2R

dR

2R

dR

0
3
2

,

1
2

,

+

2g

Φ(R)φ

2R

Φ(R)φ

2R

dR

2π
2g

dR −

√

2
2g

+ 3l2 + l1

2√
2π

r (R) Φ(R)φ

(cid:16)√

1
2

;− 1
2

,

− R√
√
2
2
g

(cid:19)
(cid:90) ∞

(cid:90) ∞
(cid:16)√
(cid:19)

exp(cid:0)−gR − R2(cid:1) erfc
(cid:17)

(cid:90) ∞
(cid:16)√
(cid:17)
(cid:18)
(cid:90) ∞
exp(cid:0)gR − R2(cid:1) erfc
(cid:90) 0
(cid:16)√
(cid:17)
(cid:18)
exp(cid:0)g2(cid:1) − 1
(cid:90) ∞
(cid:17)
r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
exp(cid:0)gR − R2(cid:1) Φ(R)2dR − 3Arctan(cid:0)√
3(cid:1)
(cid:90) ∞
(cid:40)(cid:90) ∞
(cid:19)2
(cid:18) R√
(cid:90) ∞
exp(cid:0)gR − R2(cid:1) erf
exp(cid:0)gR − R2(cid:1) erf
− 3Arctan(cid:0)√
3(cid:1)
(cid:19)
(cid:18) g2
3(cid:1)
− 3Arctan(cid:0)√
(cid:19)
(cid:18)
(cid:40) ∞(cid:88)
(cid:90) ∞
(cid:90) ∞
exp(cid:0)−gR − R2(cid:1) erf
exp(cid:0)−R2(cid:1) erf
3(cid:1)
− 3Arctan(cid:0)√
(cid:18)
(cid:90) ∞
(cid:16)√
(cid:17)
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ
3(cid:1)
45Arctan(cid:0)√
(cid:90) ∞
45Arctan(cid:0)√
(cid:90) ∞
∞(cid:88)
45Arctan(cid:0)√
(cid:19)
(cid:18) 1√

(cid:18) g2
(cid:19)2
(cid:18) g2

+ 3l2 + l1
√
3

2π

gπ
π
(g)2n+1
(2n + 1)!

,

;− 1
2

1
2

3
2
(gR)n

+ 27l2 − 1l1 +

(cid:18)(cid:90) ∞

+ 27l2 − 1l1

(cid:18) R√

(cid:18) R√

R2n+1Φ(R)3φ

3(cid:1)
3(cid:1)

+ 27l2 − 1l1 +

gπ
π
(gR)n

1
2

;− 1
2

,

r (R) Φ(R)3φ

gπ
g2
4

,

R3Φ(R)3φ

(cid:16)√

(cid:16)√

dR + 5l3 +

1
2

,

3
2

,

+ 3l2 + l1

+ 3l2 + l1

n!
√

4

1
2

,

√

√

√
π

√
3

2R

dR

(cid:19)

(cid:19)

2π

4g

ψ1

1,

ψ1

1,

4

4

dR + 2

+

4g

exp

+

exp

dR

2

(cid:41)

dR +

0

2

Arctan

+ O

n=0

0

n!

(cid:19)

g2
4

(cid:19)

gπ

π

(cid:17)

2R

n=1

0

2π

exp

−∞

2

−∞

√

√

√

2

20
g
√
2√
30
3π

15

0

= 5l3 +

= 5l3 +

gπ

π

gπ

π

−∞

l4 =

2
√
= 10

2

(cid:19)

dR

(129)

− R√
2

(cid:19)2

(cid:18) R√

2

(cid:41)

dR

(130)

(cid:19)

dR

(131)

(cid:17)
(cid:16)√

2R

dR

(cid:17)

2R

A.2 Proof of Proposition 5.2

Proof A.2 The ﬁrst four population L-Moments of the h-family of Tukey transform Loss models is
given for a = 0, b = 1 by considering

(cid:18) hR2

(cid:19)

2

r(R) = R exp

38

giving:

√

2

l3 =

(cid:16)√

(cid:17)

√

−∞

(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞

2

2

=

2R

2R

dR

dR

−∞

−∞

l2 =

l1 =

(cid:17)

r (R) φ

r (R) Φ(R)φ

1√
π
√

R exp(cid:0)−(1 − h)R2(cid:1) dR = 0, h < 1
RΦ(R) exp(cid:0)−(1 − h)R2(cid:1) dR
(cid:33)
(cid:32)
r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ

(cid:16)√
(cid:19)
1(cid:112)1 + 2(1 − h)
(cid:16)√
(cid:17)

exp(cid:0)−(1 − h)R2(cid:1) dR

1√
π
1√
π
1√
π

− R√
2

(1 − h)

(cid:18)

Rerfc

−∞

1 +

=

=

=

1

0

Rerfc2

3√
π

Rerf2

− R√
2

(cid:18)
(cid:26)(cid:90) ∞
(cid:18)
(cid:90) ∞

−∞
− R√
2

2R

dR

(cid:19)
exp(cid:0)−(1 − h)R2(cid:1) dR + 3l2 + l1
(cid:90) ∞
R exp(cid:0)−(1 − h)R2(cid:1) dR − 2
(cid:19)
exp(cid:0)−(1 − h)R2(cid:1) dR
(cid:18)

exp(cid:0)−(1 − h)R2(cid:1) dR

(cid:19)

−∞

Rerf2

Rerf

− R√
2

−∞

(cid:90) ∞
(cid:90) ∞
(cid:90) ∞

−∞

−∞

=

3√
π

+

6√
π

= 3l2 + l1 +

6√
π

= 3l2 + l1 +

= 3l2 + l1

−∞

(132)

(133)

(cid:18)

− R√
2

(cid:19)

exp(cid:0)−(1 − h)R2(cid:1) dR

(cid:27)

(cid:90) ∞

−∞

√

2

l4 =

= 12l2 − 6l1 +

(cid:20)

(cid:17)

(cid:90) ∞

(cid:16)√
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ
(cid:19)(cid:21)3
exp(cid:0)−(1 − h)R2(cid:1) dR
(cid:19)
exp(cid:0)−(1 − h)R2(cid:1) dR
8π(1 − h)(cid:112)π[1 + 2(1 − h)]

(cid:18) R
(cid:18) R

−∞
l3 + 12l2 − 6l1 +

l3 + 12l2 − 6l1 +

(cid:90) ∞

1/2 + 1/2erf



√
10
8
π

(cid:113)

10√
π

Arctan

Rerf3

sqrt2

sqrt2

−∞

dR

2R

30

R

=

=

√
10

2π

√
10

2π

8

8

1

[2 + 4(1 − h)][ 3

2 + (1 − h)]

(134)



(135)

A.3 Proof of Proposition 5.3

Proof A.3 The ﬁrst four population L-Moments of the k-family of Tukey transform Loss models is
given for a = 0, b = 1 by considering

r(R) = R(cid:0)1 + R2(cid:1)k

39

giving:
√

l1 =

√

√

=

l2 =

2

2

2

=

=

1√
2π

+ O

1√
2π

√

l3 =

2
√
= 3

2

−∞

√
3
2π

(cid:90) ∞

2

=

+

0

+ 3l2 +
√
3
2π

=

2

+ 3l2 +

√

l4 =

2
√
= 10

2

−∞

=

5√
2

(cid:19)

(136)

−∞

+ O

(cid:17)

(cid:17)

(cid:111)

−∞

−∞

(cid:19)

(cid:19)

−∞

−∞

−∞

2R

dR = 0

r (R) Φ(R)φ

2R

dR

r (R) φ

2R

dR

(cid:16)√

− R√
2

(cid:17)
(cid:16)√
(cid:16)√

φ

exp(cid:0)−R2(cid:1) dR
R9Φ(R) exp(cid:0)−R2(cid:1) dR

(cid:90) ∞
(cid:16)√
(cid:90) ∞
R(cid:0)1 + R2(cid:1)k
(cid:90) ∞
(cid:18)
(cid:90) ∞
(cid:8)R + kR3 + 1/2(k − 1)kR5 + 1/6(k − 2)(k − 1)kR7(cid:9) erfc
(cid:18)(cid:90) ∞
R9Φ(R) exp(cid:0)−R2(cid:1) dR
(cid:18)(cid:90) ∞
(cid:110)
I1 +(cid:101)I1 + 2kI3 + (k − 1)kI5 + 1/3(k − 2)(k − 1)kI7
(cid:90) ∞
r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
(cid:90) ∞
R9Φ(R) exp(cid:0)−R2(cid:1) dR
(cid:19)
(cid:18) R√
(cid:90) ∞
(cid:8)R + kR3 + 1/2(k − 1)kR5 + 1/6(k − 2)(k − 1)kR7(cid:9) erf2
(cid:19)
(cid:18)
exp(cid:0)−R2(cid:1) dR
(cid:8)R + kR3 + 1/2(k − 1)kR5 + 1/6(k − 2)(k − 1)kR7(cid:9) erf2
(cid:19)
(cid:18) 3
R9Φ(R) exp(cid:0)−R2(cid:1) dR
(cid:110)
(cid:111)
(G1 + (cid:101)G1) + k(G3 + (cid:101)G3) + 1/2(k − 1)k(G5 + (cid:101)G5) + 1/6(k − 2)(k − 1)k(G7 + (cid:101)G7)
(cid:19)
(cid:18) 3
R9Φ(R) exp(cid:0)−R2(cid:1) dR
(cid:90) ∞
(cid:16)√
r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ
(cid:90) ∞
(cid:17)
(cid:19)
(cid:18) 1

(cid:19)
exp(cid:0)−R2(cid:1) dR

(cid:18)(cid:90) ∞
(cid:18)(cid:90) ∞

dR

(cid:17)
(cid:18)(cid:90) ∞

[l3 − 3l2 − l1] + 12l2 − 6l1

R9Φ(R) exp(cid:0)−R2(cid:1) dR

[l3 − 3l2 − l1] + 12l2 − 6l1 +

(cid:18)(cid:90) ∞

dR + 3l2 + l1 + O

r (R) Φ(R)3φ

r (R) Φ(R)2φ

(cid:19)
(cid:19)

− R√
2

(cid:16)√

+ 1

l1 + O

+ 1

l1 + O

(cid:16)√

√
4

π

√
4

π

2R

dR +

5√
2

2R

dR

Arctan

+ O

(cid:19)

,

2R

−∞

0

(cid:17)

(cid:17)

2R

−∞

−∞

−∞

−∞

2

√
30

8π

3π

4

−∞

(137)

40

with

I1 =

1
2

(cid:18)

(cid:18)

(cid:19)

(cid:19)

,

1√
3

1 +
(−1)mm!

I2m+1 =

(cid:101)I1 =

1
2

G2n+1 =

(cid:101)G2n+1 =

,

2

∂m
∂pm

− (−1)m
(cid:32)
p(cid:112)1/2 + p
(cid:32)
p(cid:112)1/2 + p

1

1

∂n
∂pn

∂n
∂pn

2
1 − 1√
3
(−1)n√
(−1)n+1√

2π

2π

(cid:32)

1

(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=1
(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=1
(cid:19)(cid:33)

p(cid:112)p + 1/2
(cid:18)
(cid:18) −1√

1√
1 + 2p

Arctan

1 + 2p

Arctan

A.4 Proof of Proposition 5.4

(138)

Proof A.4 The ﬁrst four population L-Moments of the g-and-h family of Tukey transform Loss models
is given for a = 0, b = 1 by considering

(cid:18) hR2

(cid:19)

2

exp(gR) − 1

r(R) =

(cid:90) ∞
(cid:16) g2

−∞

g

(cid:16)√

exp

(cid:17)

r (R) φ

2R

(cid:17)√

√

2

l1 =

dR

(139)

= 3l2 + l1 +
21+n(2 − h)−(3/2)−nΓ(3/2 + n)2F1 [1/2, 3/2 + n, 3/2, 1/(−2 + h)]

n=0

4

2n(2 − h)−1−nΓ(1 + n)

(141)

πn!

6(g)n−1√
(cid:32)

+

+1/4

(−1)n1
2
π

√

∂n
∂pn

p(cid:112)1/2 + p

1

(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=(1−h/2)



1√
1 + 2p

√

2

π

(cid:18)

Arctan

41

giving:

√

2

l2 =

=

=

+

=

h < 2

exp

4−2h
√
2 − h

2

−

√

2
4 − 2h

,

=

g

g

2R

dR

−∞

r (R) Φ(R)φ

(cid:90) ∞
(cid:90) ∞
Φ(R)(cid:2)exp(cid:0)−(1 − h/2)R2 + gR(cid:1) − exp(cid:0)−R2(cid:1)(cid:3) dR
(cid:20)
(cid:90) ∞
exp(cid:0)−(1 − h/2)R2 + gR(cid:1) dR
(cid:20)
(cid:90) ∞
exp(cid:0)−(1 − h/2)R2 − gR(cid:1) dR − 1
(cid:16) g2

(cid:17)
(cid:19)(cid:21)
(cid:19)(cid:21)

1 + erf

1 + erf

−∞

2

2

g

0

0

√

√
1

g

π
√
1
2g
π
√
1
2g

π

(cid:18)

√

2π
2

π

exp

√
1
π
2g

(4−2h)
√
2 − h

√

l3 =

2

√

1

+

gπ

2(1 − h/2)

ψ1

1,

r (R)(cid:2)3Φ(R)2 + 3Φ(R) + 1(cid:3) φ
∞(cid:88)

(cid:26) 1

1
2

,

3
2

,

1
2

;−

1

2(1 − h/2)

(cid:16)√

(cid:17)

2R

dR

(cid:16)√
(cid:18) R√
(cid:18) R√
(cid:17)√
(cid:90) ∞

2π

−∞

,

g2

4(1 − h/2)

(cid:19)

√

2π
2

√
− 1
g

π

(140)

r (R)(cid:2)10Φ(R)3 + 15Φ(R)2 + 12Φ(R) − 6(cid:3) φ

= 12l2 − 6l1 +

√
1

g

15

π

(g)2n+1
(2n + 1)!

(−1)n√

2π

∂n
∂pn

∞(cid:88)

n=0

(cid:17)

dR

(cid:16)√
p(cid:112)1/2 + p

1

2R

(cid:32)

Arctan

(cid:18)

1√
1 + 2p

(cid:19)(cid:33)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)p=(1−h/2)

21+n(2 − h)−(3/2)−nΓ(3/2 + n)2F1 [1/2, 3/2 + n, 3/2, 1/(−2 + h)]

(cid:90) ∞

−∞

√

2

l4 =

2g
√
5

g

√
45

π

n=0

∞(cid:88)
∞(cid:88)
∞(cid:88)
(cid:18)(cid:90) ∞

n=1

n=1

π

π

√
5
4g

+

+

+

(g)2n+1
(2n + 1)!

(g)n
n!

√
Rn erf(R/

+ O

with (cid:52) =(cid:112)3/2 + (1 − h/2).

−∞

√

π

(cid:32)

21/2(−1+n)(1 + exp(nπ))(2 − h)−(1/2)−n/2Γ[(1 + n)/2]

(g)n
n!

π(1 − h/2)

1

3

(cid:112)1 + 2(1 − h/2)
2)3 exp(cid:0)−(1 − h/2)R2(cid:1) dR

(cid:19)

Arctan

2(cid:52)(cid:112)1/2 + (1 − h/2)

1

(142)

(cid:33)

,

42

