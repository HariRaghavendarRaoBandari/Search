6
1
0
2

 
r
a

 

M
7
1

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
9
9
4
5
0

.

3
0
6
1
:
v
i
X
r
a

Integral control on nonlinear spaces:

two extensions

Zhifei Zhang∗, Zhihao Ling† & Alain Sarlette‡

March 18, 2016

Abstract

This paper applies the recently developed framework for integral control on nonlinear
spaces to two non-standard cases. First, we show that the property of perfect target
stabilization in presence of actuation bias holds also if this bias is state dependent. This
might not be surprising, but for practical purposes it provides an easy way to robustly
cancel nonlinear dynamics of the uncontrolled plant. We speciﬁcally illustrate this for
robust stabilization of a pendulum at arbitrary angle, a problem posed as non-trivial by
some colleagues. Second, as previous work has been restricted to systems with as many
control inputs as conﬁguration dimensions, we here provide results for integral control of
a non-holonomic system. More precisely, we design robust steering control of a rigid body
under velocity bias.

1 Introduction

Integral control, i.e. adding a feedback term that is proportional to the time-integral of the
deviation between actual and target values, is a basic disturbance rejection tool [1]. It lowers
the sensitivity to low-frequency disturbances and in particular for a constant disturbance
input, it allows the system to stabilize perfectly on the target value. Integral control requires
minimal knowledge about the system dynamics — just enough to tune the integral gain —
and thereby is inherently robust to model uncertainties.

On a nonlinear state space like the circle, the torus or the set of rotations, the deﬁnition of
integral control must be revised. Indeed, integration is canonically deﬁned only for arguments
belonging to vector spaces: the integral (or even the sum) of e.g. diﬀerent rotation matrices
is not a standard deﬁned thing. In general, when coordinates like the Euler angles are used
to describe the position on the nonlinear space, the result depends on the parametrization
and can only be valid locally. Whereas when the manifold is embedded in a vector space,
i.e. integrating component-wise the n× n rotation matrices, the result does not belong to the
original space.

∗Key Laboratory of Advanced Control and Optimization for Chemical Processes, Ministry of Education,
East China University of Science and Technology, No.130, Meilong Road, Shanghai 200237, China; and De-
partment of Electronics & Information Systems, Ghent University, Belgium (e-mail: zhifei.zhang@ugent.be).

†Key Laboratory of Advanced Control and Optimization for Chemical Processes, ECUST Shanghai.
‡QUANTIC lab, INRIA Paris. 2 rue Simone Iﬀ, 75012 Paris, France; and Data Science Lab, Ghent

University. Technologiepark 914, 9052 Zwijnaarde, Belgium. tel: +33 1 80 49 43 59; alain.sarlette@inria.fr

1

Recently, in [5, 4] and [8], a canonical deﬁnition of integral control has been given for
systems evolving on Lie groups, to which the above examples belong. It consists in integrating
the input command, instead of the output. Indeed the inputs at diﬀerent times usually belong
to a tangent bundle, and thanks to Lie group properties these can be mapped uniquely into a
reference vector space — the Lie algebra — to deﬁne integration in an inherent way. Typically
the input command contains something “like proportional action”, and integrating it gives
rise to term precisely equivalent to the standard integral control for linear systems. The above
papers establish the beneﬁts of such integral control on Lie groups for fully actuated systems
(number of inputs equals dimension of the Lie group). They show that it perfectly rejects an
input bias that is constant (when mapped back to the Lie algebra) and give estimations of
the basin of attraction of the target equilibrium, which for topological reasons on manifolds
can mostly not be the full state space.

The present paper considers two extensions of this framework with regard to its practical
use.
• First, we rigorously establish robustness of this integral control on Lie groups to a state-
dependent bias. I.e. if the disturbance to be rejected is constant in time at every point of the
conﬁguration space, but varies continuously from point to point in the conﬁguration space
(e.g. on the circle), then integral control can still perfectly reject it. This is not big news
in the traditional linear setting, yet it is worth establishing for the Lie group case as well.
Moreover it highlights the ability of integral control to reject the eﬀect of unknown nonlinear
plant dynamics on the steady state. This complements the control approach by cancellation
of open-loop dynamics, which requires perfect plant knowledge.
• Second, we investigate integral control on Lie groups for so-called under-actuated or non-
holonomic systems, i.e. where the number of control inputs is strictly lower than the dimension
of the Lie group. We do this on a benchmark model, namely a vehicle under steering con-
trol [3]. We propose a new viewpoint on the constant input bias in this case, and a related
adaptation of integral control, for which we establish convergence properties. Although our
paper may suggest a framework towards a general solution, those results are still weaker than
in the case of full actuation and a full treatment of under-actuated systems remains an open
question at this point.

The paper is organized as follows. In Section 2 we analyze the beneﬁt of integral control
for state-dependent bias. In Section 2.2 we apply this to the stabilization of the nonlinear
pendulum at an arbitrary angle; this is a problem of “simple, robust” control suggested to us
by prof. R.Sepulchre [2]. In Section 3 we analyze the eﬀect of a bias in translation velocity
on the steering controlled vehicle. We observe that a problem appears only if the velocity
direction is not correctly estimated.
In Section 4 we propose and analyze an appropriate
integral controller to mitigate this eﬀect.

2 State-dependent bias

Let us ﬁrst consider a linear system

where F v is a constant input disturbance, and controlled with a PID controller u = −kP y −
kD

(cid:82) y(t) dt. It is well-known that under appropriate stability conditions, the presence

d

dt y−kI

d
dt x = Ax + Bu + F v ,

y = Cx

2

of the integral control term makes the system converge to y = 0 despite the disturbance v [1].
It is maybe less known that this can still hold if F depends on y. Indeed, if F = F0 + F1 y
we have equivalently

d

dt x = A(cid:48)x + Bu + F0v ,

y = Cx

with A(cid:48) = A + F1Cv. Thus as long as the PID controller keeps A(cid:48) stable as well, the
system will converge perfectly to y = 0 as with A. This is especially interesting for practical
control design, since state-dependent terms are harder to estimate with an observer than just
constants, especially if one allows arbitrary forms of F (y) (as we show still works). Bias
introduced by systematic model errors (e.g. due to linearization around non-exact solution)
is also countered by such integral action. This section reports on the analog property for
integral control on Lie groups.

2.1 Convergence on compact Lie group

For deﬁniteness consider a simple second-order system:

Lg−1

d

dt g = ξl

,

d

dt ξl = b ξl + ul + ul

B

(1)

where g is the position on the Lie group G (think of a rotation matrix); Lg is the left-invariant
translation from the tangent space at group identity, that is the Lie algebra, to the tangent
space at g; ξl is the left-invariant velocity and belongs to the Lie algebra (think of a vector
of rotation velocities, expressed in body frame); b ξl is velocity damping for b < 0, or a term
making the open-loop system unstable if b > 0; ul is a control input and ul
B a bias on this
input (think of torques in the case of rotations, again expressed in body frame). The PID
controller for this system, as introduced in e.g. [5, 4] and [8], writes

ul = −kP gradl
I = −kP gradl

gφ − kDξl + kI ul
gφ − kDξl

I

d

dt ul

(2)

where kP , kD, kI are constant gains to be tuned. The function φ : G (cid:55)→ R is some potential
with a minimum at the target gtarget, and whose gradient is used as the equivalent of propor-
tional action to push the system towards gtarget. Finally ul
I is the integral of the other control
inputs, which belong to the Lie algebra i.e. a vector space, unlike the error g−1gtarget which
belongs to the Lie group and hence cannot be integrated in a standard way.

The novelty in this section is simply that we allow ul

B to depend on g. We then get the

following extension of our result in [8].
Proposition 1: Consider the system (1) with PID controller (2). If the bias ul
B(g) has a
bounded gradient w.r.t. g, then at least for kI > 0 and kD − kI > 0 both large enough the
I = −ul
conﬁguration g converges to the set of critical points of φ, with ξl = 0 and kI ul
B(g).
Only the minima of φ are stable equilibria.
Proof: Consider the Lyapunov function candidate

V = φ + α

2 (cid:107)ξl(cid:107)2 + β

2(cid:107)kI (ul

I − ξl) + ul

B(cid:107)2 .

Its time derivative along trajectories writes

d

dt V = gradl

gφ · ξl + αξl · ˙ξl +

β(kI (ul

I − ξl) + ul

B) · (kI ( ˙ul

I − ˙ξl) + gradl

gul

B · ξl)

3

d

(cid:16)

where we have used the notation ˙x = d
dt V = −βkI (cid:107)kI (ul
(cid:16)
I − ξl) + ul
( 1
kP
(cid:21)T (cid:20) −a1I

(cid:20) x

kI (ul

+

B

with I the identity matrix. This is a form of the type

dt x. Taking α = 1/kP and grouping terms, we get
I − ξl) + ul

(cid:107)ξl(cid:107)2

B(cid:107)2 − (kD − kI − b)
(cid:17) ·
(cid:17) · ξl ,

kP

gul
B

− (b + kI )βkI )I + βgradl

(cid:21) (cid:20) x

(cid:21)

y

y

A
AT −a2I
− (b+kI )βkI

with

(3)

kP

, A = ( 1
2kP

a1 = βkI , a2 = kD−(b+kI )
B , y =
˙ξl . Now any condition ensuring the matrix in (3) to be negative deﬁnite would be suﬃcient
to conclude our proof. To show that the controller can always be tuned in this way, we here
derive (loose) bounds using the Gershgorin disk theorem. Let dr (resp. dc) be a bound on the
sum of absolute values on any row (resp. column) of the matrix gradl
B. Then for Gershgorin
we need

B and x = kI (ul

I −ξl)+ul

2 gradl

) I + β

gul

gul

2

kI > f + dr/2 and
kD > b + kI + kP f + βkP dc/2

with

f = |

1

2kP β − (b+kI )kI

2

| .

(4)

Take any kI satisfying kI > dr and kI + b > 0. By adjusting β, we can make f = 0. Then the
ﬁrst condition of (4) is satisﬁed, and the second one is easy to satisfy with kD large enough.
Note that β must be known exactly only to deﬁne the corresponding Lyapunov function, not
to tune the controller gains.

With these conditions, the matrix form (3) is negative deﬁnite. Hence V is a true Lya-
punov function, that stops decreasing only when ξl = 0 and kI (ul
B = 0.
To keep these conditions invariant, as requested by the LaSalle invariance principle, we see
from (2) that we need gradl
gφ = 0. Thus the system converges towards the set of critical
points of φ, with zero velocity and ul
B compensated by the integral controller. If there is a
point (˜g, ˜ul
B(˜g) = 0 and φ(˜g) < φ(g),
then we have V (˜g, ˜ul
I , 0), with decreasing V , can
never converge back to g; i.e. the equilibrium is unstable as soon as g is not a minimum of φ. (cid:3)

I + ul
I , 0) < φ(g) and the system starting at (˜g, ˜ul

I , 0) in the neighborhood of (g, ul

I , 0) where kI ˜ul

I − ξl) + ul

B = kI ul

I + ul

Nota Bene: The convergence towards the set of critical points of φ is the same as the basic
result obtained without bias nor integral control. In that case already, it is unavoidable that
some initial conditions, “launched with the right speed and in the right direction”, converge
towards critical points that are not minima of φ; but only the minima of φ are stable. The
sets of initial conditions converging to the unstable equilibria however might diﬀer in the
“bias and integral control” case, with respect to the nominal case.
The conditions on kI and kD are only suﬃcient.

For completeness, note that for a ﬁrst-order system

Lg−1

d
dt
dt ul
d

g = −kP gradl
I = −kP gradl
gφ

gφ + ul

B(g) + kI uI
l

4

(5)

we have the following suﬃcient result.
Proposition 2: Denote R a compact region of the state space containing a minimum gtarget
of φ, for which φ(g) = φ∂R is constant for all g ∈ ∂R the boundary of R, and where inside
R we have φ(g) < φ∂R and Hessl
gφ positive deﬁnite. Take kP suﬃciently large such that
B. For a set S ⊂ R,
kP Hessl
select kI large enough such that

B remains positive deﬁnite inside R, for all expected ul

gφ− gradl

gul

gφ(g) + ul

B(g)(cid:107)2 < kI kP φ∂R ,

2(cid:107) − kP gradl

kI kP φ(g) + 1

for all expected ul
converge towards gtarget.

max
g∈S
B. Then the system (5) starting at any g(0) ∈ S will never leave R, and
I(cid:107)2.
A diﬀerent Lyapunov function might allow to weaken the conditions of the Proposition. Note
that for stability of the corresponding linear system, a similar condition on the Hessian would
be necessary, whereas the sets R, S can be all RN .

The proof is based on the Lyapunov function V = kI kP φ(g)+ 1

2(cid:107)−kP gradl

gφ+ul

B(g)+ul

2.2 Example: nonlinear pendulum

The following problem was mentioned to us in [2] as a stumbling point for standard passivity-
based stabilization. Consider the pendulum in a vertical plane whose motion is governed
by

d2
dt2 θ = b d

dt θ − w sin(θ) + u

(6)

where θ is the angular position of the pendulum, with θ = 0 pointing downwards; w is
the ratio between gravitational acceleration and moment of inertia of the pendulum; b < 0
represents some friction; and u is the control torque, in appropriately normalized units. The
task is to robustly stabilize the pendulum at some angle θtarget (cid:54)= 0, despite the gravitational
potential attracting it towards θ = 0. Due to the latter, proportional-derivative action is
not enough. Of course with perfect knowledge of the parameters one can easily reshape the
gravitational potential to have a minimum at θtarget, but any error in parameters will then
imply a mismatch in θtarget. We next show that with PID control, stabilization perfectly at
θtarget can be achieved even with only approximate knowledge of the system parameters —
in fact we only use bounds on w and b.

Due to the fact that after moving by 2π one is back at the original location, the circle is
a nonlinear space, and in fact a Lie group. This can be highlighted by deﬁning g = eiθ, such
that indeed g1g2 = ei(θ1+θ2) is another point on the circle, θ = 0 corresponds to the identity
for multiplication, and g−1 = e−iθ exists for all g and satisﬁes all smoothness requirements.
We can then further deﬁne ω = d

dt θ and rewrite (6) as:

e−iθ d

dt eiθ = ω ,

d
dt ω = bω + u + uB

where we view uB = −w sin(θ) as an undesired state-dependent bias. Here we have just
dropped the superscript l and replaced ξ by ω compared to the general notation. To stabilize
θtarget we can select the potential φ = sin( θ−θtarget
)2 whose only extrema are a minimum at
θtarget and a maximum at θtarget + π. Note that φ is equivalent to the gravitational potential,
but turned as if the center of the Earth was in the direction θtarget. Proposition 1 then readily
ensures that PID control, with appropriate tuning, will make the system converge to either

2

5

θ = θtarget or θ = θtarget + π, of which only θtarget is stable. The tuning requirements (4) only
require the bound w on d

dθ uB, and possibly a bound on b.

Figure 1 shows a simulation of this example with initial conditions θ(0) = ω(0) = uI = 0,
perfectly stabilizing the state θref = π/2. Admittedly, the circle is not the most challenging
Lie group. However, we believe that this example illustrates how also on nonlinear spaces,
integral control can be a standard method to solve stabilization problems.

3 The steering-controlled vehicle, 1:

without integral action

Consider a planar rigid body, with position p ∈ R2 and orientation given by a 2 × 2 rotation
matrix Q. The dynamics for its steering control writes [3, 7]:

d

dt Q = Q · Q π

· ω ,

d
dt p = Q v

2

(7)
is a π/2 rotation in the plane; ω ∈ R is the angular velocity, to be controlled ; and
where Q π
v ∈ R2 is the translation velocity expressed in body frame, which is ﬁxed both in direction
2
and in magnitude. The ﬁxed direction of v can be interpreted as a vehicle which cannot
translate sidewards. The ﬁxed magnitude can be for technological simpliﬁcation (on-oﬀ motor,
propulsion system) or follow from ﬂoating constraints (airplane, buoyancy-driven underwater
vehicle).

In motion tracking of the non-holonomic vehicle, references pr(t) and Qr(t) are given
which satisfy (7) for some ωr(t) and the nominal v, which we denote vr = e1 = [1, 0] without
loss of generality. For simplicity we consider ωr(t) = ω0 > 0 constant, in which case the
reference is moving at rate ω0 on a circle of radius v/ω0.
Deﬁnition 1: We say that the vehicle follows the reference motion if and only if, in a frame
that moves and turns with the reference, the position and orientation of the controlled vehicle
are constant. In other words, the reference and the vehicle together form a virtual rigid body,
of unimposed shape. For a reference with constant ωr = ω0 and a vehicle model perfectly
matching the reference one, this means that the vehicle follows the same circular path as the
reference, with a constant phase delay.

We call this “motion tracking” to distinguish it from the traditional tracking problem,
where the vehicle would have to reach the exact same position at time t as the reference
at time t. The advantage of just motion tracking is that in fact the unimposed shape can
be controlled independently by another controller [3, 7, 6]. Practical motivation for this is
the possibility to independently optimize the shape of the virtual rigid body according to
objectives like formation ﬂying/navigation/platooning, or the carrying of a heavy rigid load
by a team of vehicles.

To steer the vehicle towards motion tracking and stabilize it there, we can follow the
geometric control design of [7, 6]. Indeed, applying this motion coordination approach to the
particular case of a network of two agents we get ω = ω0 + ωP with

ωP = kP eT
1

ω0QT (p − pr) − QT QrQ π

2

e1

(8)

(cid:16)

(cid:17)

where kP > 0 is a proportional gain. Note that this controller follows as the vehicle measures
QT (p − pr) its relative position to the reference, expressed in body frame, and QT Qr its
If the vehicle perfectly ﬁts the nominal
relative orientation with respect to the reference.

6

Figure 1: Perfect stabilization by PID control of θref = π/2, despite the action of the grav-
itational potential considered as a priori unknown. The parameters are w = 1, and we take
b = 100, kP = 1000, kI = 1, kD = 600 to satisfy (4). The Lyapunov function is shown with
α = 1/kP = 0.001 and β = 1/(kP ∗ (b + kI ) ∗ kI ) = 1/101000.

7

model, with v = e1, then the results of [7, 6] imply that it will almost globally converge
towards the reference motion. Our goal here is to ensure similar tracking performance when
v (cid:54)= e1 is not perfectly known.

A central object in our analysis, as in [7, 6], is the point

c(t) = p(t) +

Q π
2

ω0

Q(t)v .

This is the center of the circle around which the vehicle would rotate if it just applied ω = ω0
from its current position and orientation. Note that the exact c is in fact unknown to the
vehicle if it does not know its v exactly. The convergence proof in [7, 6] is based on the distance
between c(t) and the center cr of the reference circle. The combination of c(t) converging to
cr and ω converging to ω0, as the need for position correction ωP asymptotically vanishes,
eventually implies that the ﬁnal behavior satisﬁes motion tracking.

3.1 Magnitude bias

When v = (1 + )e1 diﬀers from vr but is still parallel to it, the system with just the nominal
controller (8) in fact behaves very well. The proof is based on the same Lyapunov function
as for the nominal case.

Proposition 3: Consider the system (7) with v = (1+)e1 and steering control ω = ω0 +ωP ,
where ωP is deﬁned by (8). Then the vehicle will converge towards motion tracking of the
reference. I.e. it will rotate at rate ω0 on a circle of center cr, but of radius v/ω0 possibly
diﬀerent from the reference radius.

Proof: Consider the candidate Lyapunov function

V (Q, p) = 1

2 (cid:107) c(t) − cr (cid:107)2
2 (cid:107) p(t) − pr(t) +

= 1

Q π
2
ω0

(Q(t)v − Qr(t)e1) (cid:107)2 .

Since cr is constant, when computing d

dt V one only needs

d

dt c = dp

dt +
−ωP
ω0

=

Q π
2
ω0

dQ
dt v = Qv +

Q π
2
ω0

Q Q π
2

(ω0 + ωP )v

Qv ,

where we have used the fact that all planar rotations commute and Q π
Rewriting ωP in terms of c − cr instead of p − pr, see (9), we get
2

v = Qπv = −v.

Q π
2

(9)

(10)

(11)

(12)

The last term drops when v is parallel to e1. Replacing this in (10) yields

ωP = kP ω0

1 Q π

(cid:0)eT
1 QT (c − cr)(cid:1) − kP eT
(cid:0)eT
1 QT (c − cr)(cid:1) (c − cr)T Qv
1 QT (c − cr)(cid:1)2 ≤ 0 .
= − kP|v|(cid:0)eT

dt (c − cr) = (c − cr)T d
dt c

= − kP

v.

2

d

dt V = (c − cr)T d

Now let us apply the LaSalle invariance principle. The set characterized by d
dt V = 0 is
S = {(p, Q)|ωP = 0} = {(p, Q)|c = cr or cos θ = 0}, where θ is the angle between the

8

vectors QT (c − cr) and e1. The subset S1 = {(p, Q)|c = cr} is invariant since ωP = 0
implies dc/dt = 0 from (10). On the other hand, starting from any point in the subset
S2 = {(p, Q)|c (cid:54)= cr and cos θ = 0}, we will have
dt cos θ = −ω0eT

QT (c − cr) .

1 Q π

d

2

But Q π
QT (c − cr). Thus when eT
2
such that a situation where cos θ = 0 cannot be invariant. This concludes the proof.

QT (c − cr) belongs to the same plane as QT (c − cr) and e1, and it is orthogonal to
QT (c − cr) (cid:54)= 0,
(cid:3)

1 QT (c − cr) = 0 and (c − cr) (cid:54)= 0 we have eT

1 Q π

2

Proposition 3 thus implies that, even if the actual translation velocities of diﬀerent vehicles
are unknown, then just applying the same proportional feedback (8) ensures that they will
naturally converge towards circles of the same center, and of radii exactly matched such that
they move as a rigid formation.

3.2 Velocity misalignment: eﬀect with nominal controller

We now investigate what happens under nominal control when v is not parallel to e1, i.e. there
is some misalignment by a rotation Qφ in the constant propulsion direction of the vehicle. The
ideal control would then simply apply (8) after correcting the misalignment in the deﬁnition
of the body frame of the vehicle, i.e.

(cid:16)

ωideal

P

1 QT QT
φ

= kP eT
= kP ω0vT QT (c − cr) .

ω0(p − pr) − QrQ π

e1

2

(cid:17)

(cid:17)

From the previous section, a possible remaining diﬀerence in velocity magnitude has no detri-
mental eﬀect. The diﬀerence

ωB = ωP − ωideal

P

= kP eT

1 QT (I − QT
φ )

(cid:16)

ω0(p − pr) − QrQ π

2

e1

can be viewed as a state-dependent actuation bias.

Simulations, see Fig.2, show that when ωP is applied while φ (cid:54)= 0, the center c(t) converges
to a circular limit cycle around cr. Moreover, ω converges towards a constant value ˆω =
ω0 + ˆωP with ˆωP (cid:54)= 0. This is another viewpoint about ˆωP as an input bias on ω0.

Although a proof of convergence towards this situation is beyond the scope of the present
paper, we can easily compute the value of ˆωP by examining the conditions for the equilibrium
observed in simulations. Note that the center around which the vehicle is turning is given by
ˆc = p(t) +
dt ωP = 0 and
dˆc/dt = 0. Expressing ωP in terms of ˆc and cr instead of p, pr and imposing ˆc = cr, we get
the condition

Q(t)v. Constant rotation on a circle of ﬁxed center ˆc requires d

ω0+ˆωP

Q π
2

Solving this, we get

ˆωP = −ω0

2 ±

4 + ω0kP|v| sin φ .

0

ωP = ω0

kP|v| sin φ .

ω0+ωP

(cid:113) ω2

(13)

One checks (see captions) that the solution with the plus sign ﬁts the value observed in
simulations.

9

Figure 2: Vehicle motion under steering control, with nominal proportional-like controller
ω = ω0 + ωP (taking ω0 = kP = 1) and with translation velocity misalignment v = [1, 0.1].
The left plot shows the trajectories of position p(t), circle center c(t) computed as if rotating
with ω = ω0 (ideal ﬁnal value), and circle center ˆc(t) computed as if rotating with ω = ω0 + ˆωP
(actual ﬁnal value); the initial values are marked by the green line. The right plot shows ωp
0/4 + ω0kP · 0.1 = 0.0916 instead of towards 0, and

converging towards ˆωP = −ω0/2 +(cid:112)ω2

the corresponding distance between c(t) and the target center cr = 0.

10

This is a somewhat strange and undesirable “steady state”, as the rotation speed is not
the reference one and thus QT Qr is time varying, as well as the position of the vehicle with
respect to the reference! Then the reference and following vehicle will not move at all like a
rigid body. Instead, in a frame attached to the reference, the follower will move on a circle
of radius ¯v/¯ω, thus periodically coming possibly very close and getting very far from the
reference. In other words, the result of the bias is a small, constant but thus accumulating
drift. This might be easily counteracted by the formation shape controller. Our goal now
however is to counteract this eﬀect directly, without imposing a shape to the formation, by
introducing appropriate integral action.

4 The steering-controlled vehicle, 2: adapted integral action

P

We now consider the integral action to counteract the velocity misalignment. The diﬀerence
ωP − ωideal
induced by φ (cid:54)= 0 is equivalent to a state-dependent actuation bias, i.e. we actually
apply some u(x) + uB(x) (here ωP ) while we want to apply some u(x) (here ωideal
). However,
towards applying additional corrective actions, there is an important diﬀerence: in an input
bias situation we know u(x), while here what we know is u(x) + uB(x). This corresponds
more to the eﬀect of an output bias, e.g. in a linear system:

P

d

dt x = Ax + Bu , y = (C + CB)x , u = −K y
⇒

dt x = (A − BKC)x − BKCBx .

d

The presence of CB has an eﬀect equivalent to a state-dependent input bias KCBx; but what
we can use for further feedback control, thus y, is related to (C + CB) x, thus the command
including the bias.

It turns out that an integral-like action does help reject the eﬀect of this output bias, at

least in the present application (where it is equivalent to an actuation misalignment).

4.1 Integral action design and convergence analysis

We make two changes in the integral control.

1. We reverse the sign of integral control, such that the integral action does not reinforce
but rather damp the eﬀect of the actuation. This can be understood by remembering
indeed that this actuation includes the bias.

2. We integrate all input commands, including the integral correction itself:

d

dt ωI = ωP − kI ωI

ω = ω0 + ωP − kI ωI with

= ωideal

P + ωB − kI ωI .

(14)

Note that with this notation, as soon as d

dt ωI = 0, we have the desired situation ω = ω0;
all such situations are not necessarily invariant, and this is fortunate. Indeed, to completely
reach our target, we must also get to the correct circle center. The situation c = cr (thus
ωideal
= 0) and kI ωI = ωB is invariant. We can give the following convergence property
towards it.

P

11

Proposition 4: For any |v| and any misalignment φ ∈ (− π
2 ), there exist kI and kP small
enough such that the target situation, with ω = ω0 and c = cr, is locally asymptotically stable
with controller (14).
Proof: The system becomes simpler in a frame rotating at ω. Hence we deﬁne x = QT c and
we get

2 , π

(cid:104)

(cid:105) − ωQ π

x

2

v − kI ωI

1 x − kP eT

d

(cid:104)
dt x = −v
d
dt ωI =

kP ω0eT

2

1 x − kP eT

ω0
kP ω0eT

1 Q π
v − kI ωI
This system features an equilibrium at x = 0, ωI = −kP
nonlinear only through the term ωQ π
2
The linearized system then has the characteristic polynomial
P (λ) = λ3 + (kI + |v|kP cos φ)λ2

1 Q π

kI

2

(cid:105)

.

+(ω2

0 + ω0|v|kP sin φ) λ + kI ω2
0 ,

x, which close to the equilibrium linearizes to ω0Q π

eT
1 Q π

2

v = kP
kI

|v| sin φ =: ˆωI . It is
x.

2

which according to the Routh-Hurwitz criterion is positive for φ ∈ (− π

2 , π

2 ) whenever

ω0 > kP|v|| sin φ| and

ω0 cos φ > kI| sin φ| + |v|kP| sin φ cos φ| .

(15)

For any given φ strictly inside ( π
2 ) the left hand sides are ﬁxed positive constants, so it
suﬃces to take kI and kP small enough on the right hand sides, to ensure that the linearized
(cid:3)
system is stable.

2 , π

Figure 3 shows a simulation with the same parameters as on Fig. 2, but adding our integral

control with kI = 0.1. It conﬁrms the improved behavior of the system.
Remark: From the presence of ω0 in (15), one clearly sees the key role played by the fact
that in steady state the vehicle is rotating with a constant drift input, suﬃciently fast with
respect to the feedback. This makes the strategy look much like an averaging scheme.

5 Concluding remarks

The aim of this paper is to revive the use of integral control to robustly reject biases on sys-
tem dynamics. This idea has recently been formalized for constant biases on Lie groups, and
we provide two extensions. First, we show that a state-dependent bias can also be perfectly
rejected. This makes a strong case for using integral control in systems where natural dy-
namics must be cancelled, complementing the often-used open-loop model-based cancellation.
Second, we treat a case of input bias on an underactuated system, namely steering control of
a vehicle moving at constant speed. When the bias is on the speed magnitude, it seems to
have no detrimental eﬀect on keeping the vehicle in a formation with fellows. When the bias
is on the direction however, it has an eﬀect and must be compensated. We had to modify
the integral controller to cope with this case, which in fact appears closer to a bias in the
measurement output than in the control input.

This last point suggests, for future research, to explore further links between systems
with output bias and systems with underactuated input bias, to possibly solve one case with

12

Figure 3: Same plots as on Fig.2, now including the adapted integral control (14) with
kI = 0.1. Since |v sin φ| = 0.1 = tan φ, one easily checks that the conditions (15) are satisﬁed.
The vehicle now converges perfectly to the target trajectory, while the bias eﬀect is countered
by the integral control input.

13

tools from the other. E.g. one might want to investigate in which cases integral control can
help to eﬃciently and simply reject an output bias. The conditions for local asymptotic
stability (Proposition 4) are analog to those of averaging schemes, and in fact there is hope to
prove global convergence using a combination of the exact local stability proved here, with an
approximate but global trajectory characterization using the averaging theorems of nonlinear
dynamical systems. This averaging behavior also gives indications as to how the integral
controller is “averaging out” the bias, a viewpoint which might be useful for the design of
other bias-rejecting controllers on nonlinear spaces.

To conclude, we must note that velocity bias cannot always be exactly compensated, see
e.g. our benchmark model with ω0 = 0 and a wrong magnitude of v; hence the full treatment
of bias rejection for underactuated systems on Lie groups remains an open question to our
knowledge.

Acknowledgments

This paper presents research results of the Belgian Network DYSCO (Dynamical Systems,
Control, and Optimization), funded by the Interuniversity Attraction Poles Programme, ini-
tiated by the Belgian State, Science Policy Oﬃce. The ﬁrst author’s visit to Ghent University
has been supported by a CSC scholarship, initiated by the China Scholarship Council. The
authors want to thank prof.R.Sepulchre for suggesting the pendulum example.

References

[1] Karl Johan Astr¨om and Richard M Murray. Feedback systems: an introduction for

scientists and engineers. Princeton university press, 2010.

[2] F. Forni and R. Sepulchre. Diﬀerential analysis of nonlinear systems: revisiting the
pendulum example (tutorial session). In IEEE 53rd Conference on Decision and Control
(CDC), 2014.

[3] E.W. Justh and P.S. Krishnaprasad. Equilibria and steering laws for planar formations.

Systems & Control Letters, 52:25 – 38, 2004.

[4] D.H.S. Maithripala and J.M. Berg. An intrinsic robust PID controller on Lie groups. In
Decision and Control (CDC), 2014 IEEE 53rd Annual Conference on, pages 5606–5611.
IEEE, 2014.

[5] D.H.S. Maithripala and J.M. Berg. An intrinsic pid controller for mechanical systems on

Lie groups. Automatica, 54:189–200, 2015.

[6] A. Sarlette, S. Bonnabel, and R. Sepulchre. Coordinated motion design on lie groups.

IEEE Transactions on Automatic Control, 55(5):1047–1058, 2010.

[7] R. Sepulchre, D. Paley, and N.E. Leonard. Stabilization of planar collective motion: All-

to-all communication. IEEE Transactions on Automatic Control, 52(5):811–824, 2007.

[8] Zhifei. Zhang, A. Sarlette, and Z. Ling. Integral control on Lie groups. Systems & Control

Letters, 80:9–15, 2015.

14

