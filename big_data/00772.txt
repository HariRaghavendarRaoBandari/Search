Filter based Taxonomy Modiﬁcation for Improving

Hierarchical Classiﬁcation

Azad Naik

Department of Computer Science

George Mason University

Fairfax, Virginia (USA)
anaik3@gmu.edu

Huzefa Rangwala

Department of Computer Science

George Mason University

Fairfax, Virginia (USA)

rangwala@cs.gmu.edu

6
1
0
2

 
r
a

M
2

 

 
 
]
I

A
.
s
c
[
 
 

1
v
2
7
7
0
0

.

3
0
6
1
:
v
i
X
r
a

ABSTRACT
Large scale classiﬁcation of data organized as a hierarchy
of classes has received signiﬁcant attention in the literature.
Top-Down (TD) Hierarchical Classiﬁcation (HC), which ex-
ploits the hierarchical structure during the learning process
is an eﬀective method for dealing with problems at scale
due to its computational beneﬁts. However, its accuracy
suﬀers due to error propagation i.e., prediction errors made
at higher levels in the hierarchy cannot be corrected at lower
levels. One of the main reasons behind errors at the higher
levels is the presence of inconsistent nodes and links that
are introduced due to the arbitrary process of creating these
hierarchies by domain experts.
In this paper, we propose
two eﬃcient data driven ﬁlter based approaches for hier-
archical structure modiﬁcation:
(i) Flattening (local and
global) approach that identiﬁes and removes inconsistent
nodes present within the hierarchy and (ii) Rewiring ap-
proach modiﬁes parent-child relationships to improve the
classiﬁcation performance of learned models. Our extensive
empirical evaluation of the proposed approaches on several
image and text datasets shows improved performance over
competing approaches.

Keywords
Top-down Hierarchical Classiﬁcation, Inconsistency, Error
Propagation, Flattening, Rewiring

1.

INTRODUCTION

Taxonomy (hierarchy) is used widely to store large vol-
umes of data.
It provides a structured view of the do-
main where classes (categories) are organized from the most
generic to the most speciﬁc in a top-down order.
It has
been used as a data representation in various application
domains such as bioinformatics1, patent2 databases, com-
puter vision3 and web-taxonomy4.

Hierarchies provide useful structural relationships (such as
parent-child and siblings) among diﬀerent classes that can
be exploited for learning generalized classiﬁcation models.
In the past, researchers have demonstrated the usefulness
of hierarchies for classiﬁcation and have obtained promising
results [4, 11, 15, 8, 19]. However, in many situations the
hierarchy used for learning classiﬁers is not consistent for

1http://geneontology.org/
2http://www.wipo.int/patentscope/en/
3http://www.image-net.org/
4http://lshtc.iit.demokritos.gr/

classiﬁcation and HC approaches are outperformed by ﬂat
classiﬁers that ignore the hierarchy [10, 22, 25].

In majority of the cases, the hierarchy available for train-
ing classiﬁers is manually designed by the experts based on
domain knowledge. This manual process of hierarchy cre-
ation suﬀers from various issues that makes it inconsistent
for achieving good classiﬁcation performance. Speciﬁcally,
(i) Hierarchies are designed for easy search and navigation.
(ii) Hierarchies are generated by grouping semantically sim-
ilar categories under a common parent category. Moreover,
many diﬀerent semantically sound hierarchies may exist for
same set of classes. For e.g., in categorizing products, the
experts may generate a hierarchy by ﬁrst separating prod-
ucts based on the company name (e.g., apple, microsoft) and
then the product type (e.g., phone, tablet) or vice-versa.
Both hierarchies are equally good from the perspective of
an expert. However, these hierarchies may lead to signiﬁ-
cantly diﬀerent classiﬁcation results. (iii) A-priori it is not
clear to domain experts when to generate new nodes (hierar-
chy expansion) or merge two or more nodes (link creation),
while creating hierarchies; resulting in a certain degree of
arbitrariness. (iv) Large number of categories also pose a
challenge for the manual design of a consistent hierarchy.

In this paper, our main focus is on generating an improved
representation from the expert-deﬁned hierarchy. Speciﬁ-
cally, we propose scalable data driven taxonomy modiﬁca-
tion approaches which are suitable for HC, leading to better
generalization capabilities of learned models. To summarize,
our major contributions include:

1. We propose local and global ﬂattening approaches that
are able to better identify the set of inconsistent nodes
that exists within the hierarchy, thereby improving the
classiﬁcation performance in comparison to the previ-
ous ﬂattening approaches [2, 21].

2. We propose an eﬃcient ﬁlter based taxonomy modiﬁ-
cation approach which unlike previous wrapper based
approaches [20, 18, 12] does not require multiple, ex-
pensive computations. Our approach is scalable and
can be applied to the HC problems with high-dimensional
features, large number of classes and examples.

With these taxonomy modiﬁcations, TD HC methods are
signiﬁcantly better than the ﬂat methods in classiﬁcation
performance and prediction eﬃciency. Taxonomy obtained
using our proposed methods can also be used with various
existing state-of-the-art HC approaches [10, 13, 23] for im-
proving the classiﬁcation performance.

Rest of the paper is organized as follows: In Section 2,
we discuss the existing methods for taxonomy modiﬁcation

(a) Original Hierarchy (H)

(b) Flat Hierarchy

(c) Top Level Flattened (TLF) Hierarchy

(d) Bottom Level Flattened (BLF) Hierarchy (e) Multiple Level Flattened (MLF) Hierarchy (f) Inconsistent Node Removed (INR) Hierarchy
Figure 1: Various hierarchical structures (b)-(e) obtained after ﬂattening some of the node/level(s) from original hierarchy
(a). ‘IN’ denotes the internal node and ‘LN’ denotes the leaf node.

Method

Strategy ModiﬁcationScalable

Method
Flattening Wrapper
Flattening
Flattening Wrapper
Rewiring
Clustering
Rewiring
Clustering
Rewiring Wrapper
Rewiring Wrapper

Margin-based modiﬁcation [2]
Level ﬂattening [21]
Learning based algorithm [3]
Agglomerative clustering [12]
Divisive clustering [17]
Optimal hierarchy search [20]
Genetic based algorithm [18]
Our proposed approaches:
Inconsistent node removal
Flattening
Filter-based taxonomy adaptation Rewiring
Table 1: Summary review of existing taxonomy modiﬁcation
methods and their characteristics.

(cid:88)
(cid:88)
×
×
×
×
×
(cid:88)
(cid:88)

Filter

Filter
Filter

followed by our proposed methods in Section 3. Experimen-
tal results are discussed in Section 4 and ﬁnally we conclude
and provide various future research directions in Section 5.

2. LITERATURE REVIEW

HC approaches rely on the hierarchical structure for learn-
ing models [4, 8, 10, 11, 15, 19].
In most cases, domain
experts deﬁne the hierarchical structure where semantically
similar categories are grouped together into a parent cate-
gory. Hierarchies generated using this method are indepen-
dent of the data. Various approaches for hierarchy mod-
iﬁcation have been proposed in the literature. These ap-
proaches can be broadly categorized into two classes: (i)
Flattening strategy where some identiﬁed inconsistent nodes
(based on error rate, classiﬁcation margins) are ﬂattened
and (ii) Rewiring strategy where parent-child relationships
within the hierarchy is modiﬁed to improve the classiﬁcation
performance of learned models. Summary of the various ex-
isting methods for taxonomy modiﬁcation and their inherent
characteristics are shown in Table 1.
2.1 Flattening Strategy

Flattening refers to the removal of certain nodes or en-
tire levels of hierarchies; is one of the early approaches used
for hierarchy modiﬁcation [3, 14, 21]. The main intuition
behind ﬂattening is to selectively remove the problematic
nodes that cause deterioration in classiﬁcation performance.
Based on levels that are ﬂattened (removed), various meth-
ods of ﬂattening exist. One of the simplest method is to
remove (ﬂatten) all the internal nodes. This is referred as
ﬂat hierarchy and is shown in Figure 1 (b). Flat hierar-
chy ignores the hierarchical structure completely which may

contain some valuable information for improving the perfor-
mance results of learned classiﬁcation models (especially for
rare categories). Top Level Flattening (TLF) as shown in
Figure 1 (c) modiﬁes the hierarchy by removing the top level
in the original hierarchy. Bottom Level Flattening (BLF)
and Multiple Level Flattening (MLF), shown in Figures 1
(d) and (e) are similar methods of hierarchy modiﬁcation
where bottom and multiple levels are removed, respectively.
Recently, learning based approaches [3] for hierarchy mod-
iﬁcation are proposed, where each node in the hierarchy is
recursively ﬂattened and evaluated for performance improve-
ment over the original (predeﬁned) hierarchy. If there is a
signiﬁcant improvement then the node is marked as inconsis-
tent and removed, otherwise the node is retained in the ﬁnal
hierarchy. This approach although useful for small datasets,
is not scalable due to the expensive evaluation process af-
ter each node removal and is a wrapper approach. In other
work [2], maximum margin-based approach for taxonomy
adaptation (MTA) was proposed where some nodes are in-
telligently ﬂattened based on a deﬁned threshold and margin
scores obtained for each node. Hierarchy modiﬁcation using
this approach (see Figure 1 (f)), is scalable and beneﬁcial
for classiﬁcation and has been theoretically justiﬁed [9]. We
followed a similar ﬁlter approach for hierarchy modiﬁcation.
However, we deﬁne a systematic approach for determining
threshold criterion to identify the set of inconsistent nodes,
based on deviation from mean.
2.2 Rewiring Strategy

Although, the ﬂattening strategy shows performance im-
provement, it suﬀers from limitations. Figure 2 (a) shows
the original expert-deﬁned hierarchy where leaf nodes (cate-
gories) with higher similarities are marked by the same color
and shape. In Figure 2 (a), node C.1 is incorrectly linked
to node C instead of A, which makes learning a discrimi-
native model diﬃcult at higher level i.e., between nodes A
and C. Flattening strategy (shown in Figure 2 (b)) modiﬁes
this hierarchy by ﬂattening (removing) the inconsistent node
C that contains leaf categories with varying similarities be-
tween siblings. In spite of the fact that ﬂattened hierarchy
is comparatively better than the original hierarchy in terms
of classiﬁcation performance, it can be improved further to
better leverage the hierarchy information by rewiring node
C.1 as a child of node A as done in Figure 2 (c) (a rewiring
strategy). To summarize, ﬂattening strategy cannot deal
with inconsistencies that occurs in diﬀerent branches (sub-

RootINININLNLNINLNLNININLNLNINLNLNINININLNLNINLNLNININLNLNINLNLNRootLNLNLNLNLNLNLNLNLNLNLNLNLNLNRootININLNLNINLNLNININLNLNINLNLNININLNLNINLNLNININLNLNINLNLNRootININLNLNLNLNINLNLNLNLNININLNLNLNLNINLNLNLNLNRootINLNLNLNLNINLNLNLNLNINLNLNLNLNINLNLNLNLNRootININLNLNINLNLNININLNLNLNLNININLNLNINLNLNINLNLNINLNLN(a) Original Hierarchy (H)

(b) Flattened Hierarchy

(c) Rewired Hierarchy

Figure 2: Original hierarchy (a) modiﬁed using: (b) Flattening strategy and (c) Rewiring strategy. Leaf nodes with higher
degree of similarities are represented by the same color and shape.

trees) of the hierarchy. Rewiring strategy can be broadly
categorized into two class of approaches: (i) Automated hi-
erarchy generation and (ii) Predeﬁned (original) hierarchy
modiﬁcation.

2.2.1 Automated Hierarchy Generation
In this approach, the hierarchy is generated from scratch
ignoring the expert deﬁned hierarchy. Most of the work
in this category exploits hierarchical clustering algorithms
for generating the hierarchy [1, 5, 12, 17].
In [12], a two
step method for constructing hierarchy is proposed. This
method uses a linear discriminant for projecting the data
into a lower dimensional space followed by the hierarchical
agglomerative clustering to generate a binary tree. For clas-
siﬁcation, the binary tree is converted to a two-level tree
according to cluster coherence. In other work proposed in
[17], a divisive clustering approach is followed where the cat-
egories assigned to each cluster are recursively divided into
sub-clusters using spherical K-means.

Constructing hierarchy using automated approaches is not
popular due to predeﬁned parameter requirements, making
these approaches very ad-hoc. Moreover, these approaches
generate binary trees which are not scalable for large datasets.
In this paper we do not focus on automated hierarchy gen-
eration approaches.

2.2.2 Predeﬁned (original) Hierarchy Modiﬁcation
In the existing rewiring approaches [18, 20, 16], the prede-
ﬁned expert hierarchy is modiﬁed in steps to make it better
suited (aligned) for the classiﬁcation task. In [20], at each
step the subset of the hierarchy is modiﬁed and evaluated for
classiﬁcation performance improvement using the HC learn-
ing algorithm. Modiﬁed changes are retained if the perfor-
mance results improve; otherwise the changes are discarded
and the process is repeated. This repeated procedure of hi-
erarchy modiﬁcation continues until the optimal hierarchy
that satisﬁes certain criteria is reached.

In [20], modiﬁcations are performed using three elemen-
tary operations – promote, demote and merge. Starting from
the predeﬁned (original) hierarchy, the current best hierar-
chy is modiﬁed by applying one of the three elementary op-
erations at each iteration, until an optimal hierarchy with
best classiﬁcation performance is obtained. This approach
produces signiﬁcant performance improvement in compari-
son to a clustering based approach [12]. However, expensive
evaluation at each step makes this approach intractable for
large-scale datasets. Another drawback of this approach is
deciding which branch of the hierarchy to explore ﬁrst (for
modiﬁcation) and which elementary operation to apply at
each step. Similarly, hierarchy modiﬁcation using genetic
algorithms [18], requires many candidate hierarchies to be
evaluated at each subsequent step. Other approaches focus

Symbol Description

H original given hierarchy
L set of leaf categories (classes)
xi
yi ∈ L true label for i-th training example
i ∈ ±1
yn
binary label used for i-th training example to learn
weight vector for n-th node in H, yn
i = 1 iﬀ yi =n,
-1 otherwise

input vector for i-th training example

N total number of training examples
Θn weight vector for n-th node
f∗

n

optimal objective function value for n-th node
obtained using validation dataset. We have dropped
the subscript n at some places for ease of description

HM modiﬁed hierarchy after ﬂattening/rewiring
N set of nodes (except root) in H
Nk
set of nodes at k-th level in H
IL
set of inconsistent nodes using Level-INR method
IG
set of inconsistent nodes using Global-INR method
µ(S) mean of samples in set S
standard deviation of samples in set S
σ(S)
Sk
set of f∗ values for node at k-th level in H
threshold for nodes ﬂattening at k-th level in H
τk
global threshold for nodes ﬂattening or threshold for
τ
grouping similar classes in rewiring method
parent of the n-th node
siblings of the n-th node

π(n)
ζ(n)

Table 2: Notation description.

on improving the runtime performance (apart from classiﬁ-
cation performance) [16], where the hierarchy is only evalu-
ated in the modiﬁed sub-branches. Some improvements in
results over the expert deﬁned hierarchy have been reported.
However, this approach is heuristic by nature and requires
parameter tuning.

We propose a ﬁlter-based data-driven rewiring approach,
where the taxonomy is modiﬁed based on certain relevance
criterion (such as pairwise siblings similarities) between the
diﬀerent classes within the hierarchy. In contrast, wrapper
based methods [18, 20, 16] iteratively modify the hierarchy
by making one or few changes, which are then evaluated by
training a classiﬁcation model on a validation set to identify
if the modiﬁed hierarchy has improved performance. As
such, ﬁlter methods are scalable for large datasets as they
are single step and do not require experimental evaluation
for multiple iterations. In Table 1 we succinctly capture the
diﬀerences amongst the previously proposed approaches and
our proposed method along these dimensions.

3. PROPOSED METHODS

Table 2 summarizes the common notations used in this

paper. We use bold letters to indicate vector variables.
3.1 Hierarchical Classiﬁcation
Given, a hierarchy H = (V,E), where V denotes the set of
nodes and E denotes the set of edges. We train one-vs-rest
classiﬁers for each of the nodes n ∈ N — where N is the set
of all nodes excluding the root node — to discriminate its
examples from other node examples in the hierarchy. In this

paper, we have used logistic regression (LR) as the underly-
ing base model for training. The LR objective uses logistic
loss to minimize the empirical risk and l2-norm term (de-
noted by || · ||2
2) to control model complexity and prevent
overﬁtting. The objective function fn for training a model
corresponding to node n is provided in ??.

(cid:16)−yn

(cid:17)(cid:17)

log

1 + exp

i Θn

T xi

+

1
2

(cid:107)Θn(cid:107)2

2

(1)

(cid:34)

N(cid:88)

i=1

min
Θn

C

(cid:16)

(cid:35)

For each node n within the hierarchy, we solve ?? to obtain
the optimal weight vector denoted by Θn. The complete set
of parameters for all the nodes {Θn}n∈N constitutes the
learned model for the hierarchical TD classiﬁer. For LR
i ∈ ±1 given its
models the conditional probability for ˆyn
feature vector xi and the weight vector Θn is given by ??
and the decision function is given by ??.
(1 + exp (−yn

i | xi, Θn) =

P (ˆyn

(2)

1

n xi))

ˆyn
i =

+1 fn(xi) = ΘT
−1 otherwise

i ΘT
n xi ≥ 0

For a test example with feature vector xi, the TD clas-
siﬁer predicts the class label ˆyi ∈ L as shown in ??, where
C (p) denotes the set of children of node p. Essentially, the
algorithm starts at the root nodes and recursively selects the
best child nodes till it reaches a terminal node belonging to
the set of leaf nodes L.

(3)

(4)

(cid:40)



ˆyi =

initialize p := root
while p /∈ L

p := argmaxq∈C(p) fq(xi)

return p



(cid:35)

(cid:34) (cid:88)

n∈D

δr2
m

3.2 Flattening Approach
It has been shown [9] that for any classiﬁer that correctly
classiﬁes m random input-output pairs using a set of D deci-
sion nodes, the generalization error bound with probability
greater than 1 - ∆ is less than the expression shown in ??.

(

1
γ2
n

) log(4em) log(4m) + |D| log(2m) − log(

2
∆

)

,

(5)

where γn denotes the margin at node n ∈ D, δ is a con-
stant term and r is the radius of the ball containing the
distribution’s support.

This provides two signiﬁcant strategies in designing our
approach to reduce the generalization error: (i) increasing
the margin γn for nodes in the hierarchy or (ii) decreasing
the number of decision nodes |D| involved in prediction. For
learning the optimal model we need to balance the trade-oﬀ
between the margin γn and the number of decision nodes |D|.
Two of the extreme cases for learning hierarchical classiﬁers
are ﬂat and TD methods. For ﬂat classiﬁers, we have to
make a single decision (i.e., |D| = 1) but margin width γn is
presumably small due to the large number of leaf categories,
which makes it diﬃcult to obtain larger margin. For TD
hierarchical classiﬁers, we have to make a series of decisions
from root to leaf nodes (i.e., |D| ≥ 1 ) but margin γn is
larger due to the fewer number of categories that need to be
distinguished at each of the decision nodes. In this paper,
we propose a method that removes some of the inconsistent
nodes in the hierarchy H, thereby, increasing the value of

Algorithm 1 Level-wise Inconsistent Node Removal
Data: Original Hierarchy H, input-output (xi, yi)
Result: Modiﬁed Hierarchy HM
Train l2-regularized LR model in a top-down order
/* Set of inconsistent node, initially empty */
IL := Φ;
for k := 1 . . . end level do

/* Set of all nodes f∗ values in the level */
Sk := Φ;
for n ∈ Nk do

Sk := Sk ∪ {f∗
n}
end
τk := µ(Sk) + σ(Sk);
/* Identify inconsistent node in level */
for n ∈ Nk do

if (f∗

n > τk & n /∈ L) then
IL := IL ∪ {n}

end

end

end
/* New hierarchy with inconsistent node(s) removed */
HM = H - {IL};
return HM

margin γn for nodes in the hierarchy, while minimizing the
number of decision nodes.

In order to improve the eﬀectiveness of classiﬁcation we
need to identify inconsistent nodes and prune them. We
mark a node n within the hierarchy as inconsistent if the
optimal value of the objective function f∗
n becomes greater
than a chosen threshold value. To get a more reliable es-
timate of the f∗
n, we ﬁrst train the regularized LR models
on a training set locally for each node and then compute
the objective function on a separate validation set, which
is diﬀerent from the training set. The objective value on
validation set for node n is denoted by f∗
n. We develop the
following approaches for setting the threshold for pruning.
Level-wise (local) Inconsistent Node Removal - In
this approach, referred as Level-INR, we select a diﬀerent
threshold τk for each level k of the hierarchy. Algorithm
1 presents the level-wise approach that selects inconsistent
nodes at each level in a top-down manner. The threshold
τk for level k is computed as the sum of mean and standard
deviation of the set of values {f∗
, where Nk repre-
sents the set of nodes in level k. All nodes n ∈ Nk that
satisfy f∗
n > τk are marked as inconsistent and added to the
set of inconsistent nodes denoted by IL. This procedure is
repeated for all levels of the hierarchy. Finally, we ﬂatten
the nodes in set IL — remove n ∈ IL and corresponding
edges, and add edges from children of n to n’s parent node.
The modiﬁed hierarchy HM obtained by ﬂattening is used
to re-train a top-down classiﬁer.

n}n∈Nk

Global Inconsistent Node Removal - Diﬀerent from
the Level-INR approach, which sets diﬀerent thresholds for
each level, the global method computes a single threshold
value for all levels. The threshold τ is computed as the sum
of mean and standard deviation of the set of value {f∗
n}n∈N ,
where N represents the set of all nodes except the root node.
τ is used to identify the set of inconsistent nodes IG in the
hierarchy (i.e., all nodes n with f∗
n > τ ). The modiﬁed
hierarchy HM obtained by ﬂattening the nodes present in
IG is used to re-train a top-down classiﬁer. In this paper we
refer to this approach as Global-INR.
3.3 Rewiring Approach

To overcome the drawback associated with ﬂattening ap-
proach (discussed in Section 2.2), we propose an eﬃcient ﬁl-

(a) Original Hierarchy (H)

(b) Node Creation (D)

(c) Parent-child Rewiring (6)

(d) Node Deletion (B)

Figure 3: Modiﬁed hierarchical structures (b)-(d) obtained
after applying elementary operation to original hierarchy
(H). Leaf nodes are marked with ‘rectangle’ and structural
changes are shown by blue color.

ter based data driven rewiring approach for taxonomy mod-
iﬁcation.

Filter based Taxonomy Modiﬁcation - Algorithm 2
describes our proposed approach for taxonomy modiﬁcation.
It consist of two steps:

(i) Grouping Similar Classes - To ensure similar classes
are grouped together to the same parent node in the modi-
ﬁed taxonomy; this step identiﬁes and groups the most sim-
ilar classes that exists within the predeﬁned experts hierar-
chy.

Pairwise similarity computation between diﬀerent classes
is one of the major bottlenecks of this step. To make it scal-
able, we distribute the similarity computation across multi-
ple compute nodes. Cosine similarity is used as the similar-
ity metric in our experiments and we use a separate valida-
tion dataset for computing similarities. Once the similarity
scores are computed, we determine the set S of most similar
pairs of classes using an empirically deﬁned cut-oﬀ threshold
for a dataset.

(ii) Inconsistency Identiﬁcation and Correction -
Similar classes determined in the previous stage are used as
an input for this step. To obtain the consistent hierarchy,
we need to group together each of the similar class pairs to
a common parent node. Iteratively, starting from the most
similar class pairs we check for potential inconsistency i.e.,
if the pairs of classes are in diﬀerent branches (sub-trees).
In order to resolve the identiﬁed inconsistencies, we take
the corrective measures using three elementary operation:
node creation, parent-child rewiring and node deletion. Fig-
ure 3 illustrates the various hierarchical structures that are
obtained after the execution of elementary operation on pre-
deﬁned (original) hierarchy, Figure 3 (a).

Node Creation (NC) - This helps to group together the
identiﬁed similar class pairs in diﬀerent branches (sub-trees)
of the hierarchy using a newly created node, with parent as
the lowest common ancestors of similar classes. Figure 3(b)
illustrate this operation where the similar class pairs 5 and
6 are grouped together by the newly created node D. This
operation is used only when a proper subset of the leaf nodes
from diﬀerent branches are similar (i.e., not similar to all leaf

Algorithm 2 Filter based Taxonomy Modiﬁcation
Data: Original Hierarchy H, input-output (xi, yi)
Result: Modiﬁed Hierarchy HM
/* Initialization */
HM = H;
/* First step: Grouping Similar Classes */
/* similarity computation */
Compute the similarity between all possible class pairs using cosine
similarity.
/* similar class grouping */
Group the most similar class pair based on empirically deﬁned thresh-
old parameter τ . Let |c| denotes the number of similar class pair
represented by the set S = {s1, s2, . . . , s|c|}, where i-th pair si is
represented using (s(1)
/* Second step: Inconsistency Identiﬁcation and Correction
*/
for i = 1 to |c| do

, s(2)

).

i

i

rewire[1] = yes; /* default value */
rewire[2] = yes; /* default value */
/* Inconsistent pair check */
if π(s(1)

) (cid:54)= π(s(2)

) then

/* check similarity to all siblings */
foreach j ∈ ζ(s(1)

, j)(cid:1) /∈ S then

i

i

if (cid:0)(j, s(2)

i

) do
) or (s(2)
rewire[2] = no;
break;

i

i

end

end
foreach j ∈ ζ(s(2)

if (cid:0)(j, s(1)

i

) do
) or (s(1)
rewire[1] = no;
break;

i

i

, j)(cid:1) /∈ S then

end

end
if (rewire[1] == no) and (rewire[2] == no) then

/* perform node creation */
Nnew = φ /* create new node */
[HM ] =nodeCreation(Nnew→lca(si), si→Nnew, HM );
/* lca denotes lowest common ancestor */

else

if (rewire[1] == yes) then

else

[HM ] = parent-childRewiring(s(1)
[HM ] = parent-childRewiring(s(2)

i →π(s(2)
i →π(s(1)

i

i

), HM );
), HM );

end

end

end

end
/* perform node deletion */
[HM ] = nodeDeletion(HM );
return HM

nodes in the branch; otherwise the parent-child rewiring op-
eration is used).

Parent-child Rewiring (PCRewire) - As shown in Fig-
ure 3(c), this operation simply assigns (rewires) the leaf node
from one parent to another parent node in the hierarchy. It
is useful when the leaf node is identiﬁed as similar to all
sibling leaf nodes within the given hierarchy branch. For
example, in Figure 3(c) if the computed similarity score de-
termines the leaf node 6 to be more similar to nodes 3, 4
and 5 in comparison to its current siblings 7 and 8, than it
is more desirable from classiﬁcation perspective to assign 6
as node B child rather than C.

Node Deletion (ND) - This refers to deletion of internal
node in the hierarchy that does not have any associated leaf
node as its descendant. As shown in Figure 3(d), internal
node B is deleted because it does not helps in classiﬁcation
as there are no leaf nodes that can be classiﬁed by node B.
This operation is used as a post-processing step in our al-
gorithm to reﬁne the hierarchy, where irrelevant nodes are

CLEF
DIATOMS
IPC
DMOZ-SMALL
DMOZ-2010
DMOZ-2012

# Total Node # Leaf Node Height # Training # Testing # Features
80
371
1,123,497
51,033
381,580
348,548

10,000
1,940
46,324
6,323
128,710
383,408

1,006
993
28,926
1,858
34,880
103,435

88
399
553
2,388
17,222
13,963

63
311
451
1,139
12,294
11,947

4
4
4
6
6
6

Table 3: Dataset statistics.

removed from the modiﬁed hierarchy.

For resolving inconsistency, our algorithm determines (outer

for loop) the best corrective measures (node creation or
parent-child rewiring) that needs to be taken. Once all the
inconsistencies have been addressed, algorithm calls the node
deletion procedure as a ﬁnal modiﬁcation step where unnec-
essary internal nodes with 0 or 1 child are deleted.

4. EXPERIMENTS AND RESULTS
4.1 Datasets

We have used an extensive set of text and image datasets
for evaluating the performance of our proposed approaches.
Various statistics of the datasets used are listed in Table
3. All these datasets are single labeled and the examples
are assigned to the leaf nodes in the hierarchy. For all text
datasets, we have applied the tf-idf transformation with l2-
norm normalization on the word-frequency feature vector.
Description of the dataset used for experiments are:
Image Datasets

CLEF [7] - Medical images represented by 80 features that

are extracted using local distribution of edges.

DIATOMS [6] - Diatom images where features are cre-
ated using various feature extraction techniques [6]. We have
preprocessed the original dataset by removing the examples
that belongs to the internal nodes.
Text Datasets

IPC5 - Collection of patent documents organized in Inter-

national Patent Classiﬁcation (IPC) hierarchy.

DMOZ-SMALL, DMOZ-2010 and 20126 - Multiple
web documents organized in various classes using the hierar-
chical structure. Dataset has been released as the part of the
LSHTC7 challenge in the year 2010 and 2012. For evaluat-
ing the DMOZ-2010 and DMOZ-2012 datasets we have used
the provided test split. The results reported for these two
benchmarks are blind prediction obtained from web-portal
interface8,9.
4.2 Evaluation Metrics

Flat Measures - We have used the standard metrics
micro-F1 (µF1) and macro-F1 (MF1) for evaluating the per-
formance of various methods. To compute µF1, we sum
up the category speciﬁc true positives (T Pc), false positives
(F Pc) and false negatives (F Nc) for diﬀerent categories and
compute the score as:

c∈L T Pc

, R =

c∈L T Pc

c∈L(T Pc + F Pc)

c∈L(T Pc + F Nc)

, µF1 =

2P R
P + R

(6)

(cid:80)

(cid:80)

P =

(cid:80)

(cid:80)

5http://www.wipo.int/classiﬁcations/ipc/en/
6http://dmoz.org
7http://lshtc.iit.demokritos.gr/
8http://lshtc.iit.demokritos.gr/node/81
9 http://lshtc.iit.demokritos.gr/LSHTC3 oracleUpload

(cid:88)

Unlike µF1, MF1 gives equal weight to all the categories
so that the average score is not skewed in favor of the larger
categories. It is deﬁned as follows:

Pc =

, Rc =

T Pc

T Pc

T Pc + F Pc

c∈L
where, |L| is the number of categories (classes).

T Pc + F Nc

, M F1 =

1
|L|

2PcRc
Pc + Rc

(7)

Hierarchical Measures - This metrics incorporate hier-
archy for evaluating the classiﬁer performance. The hierar-
chy based measures include hierarchical F1 (hF1) (harmonic
mean of hierarchical precision (hP ), hierarchical recall (hR))
are deﬁned as follows,

(cid:80)N
(cid:80)N
i=1 |A( ˆyi) ∩ A(yi)|
i=1 |A( ˆyi)|

hP =

(cid:80)N
(cid:80)N
i=1 |A( ˆyi) ∩ A(yi)|
i=1 |A(yi)|

, hR =

2 ∗ hP ∗ hR
hP + hR

hF1 =

(8)

Note that for consistent evaluation of hierarchical mea-
sures we have used the original hierarchy for all methods
unless noted.
4.3 Methods for Comparison

4.3.1 Flat Method
For the ﬂat classiﬁers we train one-versus-rest regularized
logistic regression (LR) classiﬁers for each of the leaf cate-
gories, ignoring the hierarchical structure. The prediction
decision is based on the maximum prediction score achieved
when compared across the one-versus-rest classiﬁers. This
method is referred as LR.

4.3.2 Top-Down Hierarchical Methods
For all TD hierarchical baselines we train one-vs-rest clas-
siﬁers for each of the nodes (except root) in the hierarchy and
predictions are made starting from the root node and recur-
sively selecting the best scoring child nodes until a leaf node
is reached (See eq. (??)). We choose one-vs-rest over one-vs-
sibling for learning models because our preliminary experi-
ments showed better performance with one-vs-rest method.
Depending upon the hierarchy that we use during the train-
ing process, we use the following TD HC methods for com-
parison purpose.

Top-Down Logistic Regression (TD-LR): We use orig-
inal hierarchy provided by domain experts for training the
classiﬁers.

Level Flattening Approach [21]: Modiﬁed hierarchy
obtained by ﬂattening level(s) is used for classiﬁers train-
ing. Depending on level(s) ﬂattened we have TLF, BLF and
MLF as discussed in Section 2.1. For MLF, we ﬂatten the
ﬁrst and third level nodes as proposed in [21].

Margin based Taxonomy Adaptation (MTA) [2]: Hi-
erarchy is modiﬁed using the computed margin value and
threshold deﬁned at each node in the hierarchy.

Optimal Hierarchy Search [20]: Optimal hierarchy is

(a) Original Hierarchy (H)

(b) Flattened Hierarchy

(c) Rewired Hierarchy

Figure 4: (a) Original hierarchy with inconsistent nodes (marked with diﬀerent symbol) modiﬁed using our proposed: (b)
Flattening strategy (Global-INR) and (c) Rewiring strategy. Modiﬁed hierarchical structure changes are marked in blue.

searched in the hierarchical space by modifying the prede-
ﬁned hierarchy using elementary operation – promote, de-
mote and merge. For reducing the number of hierarchy eval-
uation, we have restricted the modiﬁcation to the hierarchy
branches where we encountered the maximum errors. This
modiﬁed approach is referred as T-Easy.
In the original
paper largest evaluated dataset has 244 classes and 15795
instances.
4.4 Experimental Protocol

To make the experimental evaluation results comparable
to previously published results, we have used the same train-
test split as provided by the benchmarks.
In all the ex-
periments, we have divided the training dataset into train
and small validation dataset in the ratio 90:10. Each ex-
periment was run ﬁve times with diﬀerent sets of train and
validation split chosen randomly. Testing is done on an inde-
pendent held-out dataset as provided by these benchmarks.
The model is trained by choosing mis-classiﬁcation penalty
parameter (C) in the set {0.001, 0.01, 0.1, 1, 10, 100, 1000}.
The best parameter is selected using a validation set. The
best parameters are used to retrain the models on the entire
training set and the performance is measured on a held out
test set. All experiments were conducted using a modiﬁed
version of liblinear10 software and were run on a compute
cluster with Dell C8220 compute nodes, each with dual Intel
Xeon E5-2670 (2.60GHz) 8 core CPUs.
4.5 Evaluation Results
4.5.1 Case Study
To understand the qualitative diﬀerence of our proposed
approaches, we present results on the newsgroup dataset
containing 20 classes and 10,000 training examples. Fig-
ure 4 (b) and (c) shows the modiﬁed hierarchical struc-
ture obtained using our best proposed ﬂattening approach
(Global-INR) and rewiring approach, respectively. Perfor-
mance evaluation on these hierarchy shows improved clas-
siﬁcation results in comparison to the original (predeﬁned)
hierarchy shown in Figure 4 (a). On comparing ﬂattened and
10http://www.csie.ntu.edu.tw/∼cjlin/liblinear/

rewired hierarchy, performance of rewired hierarchy (µF1 =
81.24) is found to be signiﬁcantly better than the ﬂattened
hierarchy (µF1 = 79.42) because of the ﬂattening approach
limitation that it cannot group together the classes from dif-
ferent hierarchical branches (for e.g, soc.religion.christian
and religion.misc or electronics and graphics), limiting the
performance improvement. On the contrary, rewiring ap-
proach has the ﬂexibility of grouping classes from any hi-
erarchical branches which helps in leveraging the hierarchy
better for learning models.

4.5.2 Flattening Approaches
Performance based on Flat Metrics - Table 4 shows
the µF1 and M F1 performance comparison of our proposed
ﬂattening methods with diﬀerent TD hierarchical baselines.
We can see that our proposed method, Global-INR, consis-
tently outperforms other TD HC methods for all the datasets
across all metrics. In fact, for image dataset we see a rel-
ative performance improvement of ∼6% in MF1 on com-
paring Global-INR with the best TD hierarchical baseline
method. Signiﬁcance test between models is performed to
access the performance improvement. We perform sign-test
for µF1 [24] and non-parametric wilcoxon rank test for MF1.
The results of the signiﬁcance test shows that our proposed
method, Global-INR signiﬁcantly outperforms the best TD
hierarchical baseline model for the diﬀerent datasets.

On comparing our two proposed ﬂattening approaches,
Global-INR has better performance than Level-INR because
the Level-INR method strictly enforces some of the nodes to
be removed from each levels although their f∗
n value may be
much lower than the other nodes at diﬀerent levels in the
hierarchy and vice-versa. In contrast, Global-INR method
takes all nodes into consideration while making a decision
to identify the inconsistent nodes and hence it determines
a better set of inconsistent nodes. Maximum margin based
approach, MTA has poor performance due to the similar
issues as with Level-INR approach. Level ﬂattening methods
such as TLF, BLF and MLF, have poor performance because
these methods remove the entire level in the hierarchy and do
not take into consideration whether any node in that level
is important or not, resulting in poor performance. The

CLEF

DIATOMS

IPC

DMOZ-SMALL

DMOZ-2010

DMOZ-2012

µF1(↑)
M F1(↑)
µF1(↑)
M F1(↑)
µF1(↑)
M F1(↑)
µF1(↑)
M F1(↑)
µF1(↑)
M F1(↑)
µF1(↑)
M F1(↑)

TD-LR

72.74 (0.43)
35.92 (0.01)
53.27 (0.32)
44.46 (0.24)
49.32 (0.32)
42.51 (0.94)
45.10 (0.23)
30.65 (0.43)
40.22 (0.55)
28.37 (0.46)
50.13 (0.28)
29.89 (0.23)

Top-down Hierarchical Baselines
TLF

BLF

MLF

75.84 (0.32)
38.45 (0.65)
56.93 (0.28)
45.17 (0.62)
51.28 (0.61)
44.99 (0.43)
45.48 (0.19)
30.60 (0.54)
41.32 (0.32)
29.05 (0.84)
50.32 (0.42)
29.89 (0.23)

73.76 (0.32)
40.93 (0.19)
53.27 (0.24)
44.30 (0.64)
50.36 (0.64)
43.74 (0.81)
44.34 (0.32)
30.94 (0.53)
40.34 (0.24)
28.41 (0.57)
50.11 (0.32)
29.73 (0.14)

X
X
X
X
X
X

45.80 (0.64)
30.62 (0.32)
41.77 (0.56)
29.11 (0.13)
48.05 (0.39)
27.65 (0.48)

MTA

74.48 (0.42)
39.53 (0.74)
58.36 (0.64)
45.21 (0.65)
51.36 (0.32)
42.80 (0.94)
46.01 (0.74)
30.82 (0.63)
41.82 (0.42)
29.18 (0.54)
50.31 (0.48)
30.04 (0.57)

Proposed Flattening Models
Level-INR
Global-INR
77.14† (0.01)
75.25 (0.55)
46.54‡ (0.06)
39.89 (0.24)
61.31‡ (0.53)
58.32 (0.64)
51.85‡ (0.23)
48.77 (0.12)
52.30† (0.12)
50.40 (0.32)
45.65† (0.11)
43.26 (0.43)
46.61† (0.28)
45.43 (0.21)
31.26‡ (0.64)
30.34 (0.12)
42.37 (0.27)
40.71 (0.83)
30.11 (0.64)
28.66 (0.53)
50.64 (0.22)
49.90 (0.92)
30.58 (0.28)
30.52 (0.74)

Table 4: µF1 and M F1 performance comparison of various TD hierarchical baseline models against our proposed ﬂattening
INR models. Table shows mean and (standard deviation) in bracket across ﬁve runs.
’X’ denotes MLF not possible. The
signiﬁcance-test results are denoted as † for a p-value less than 5% and ‡ for p-value less than 1%. Signiﬁcance test are
between best proposed, Global-INR model and best hierarchical baseline model. Test cannot be performed on DMOZ-2010
and DMOZ-2012 dataset because we don’t have access to true labels.

H

MTA

IPC

CLEF

DIATOMS

Best TD Proposed Flattening Models
Global-INR
79.06 (0.01)
80.87 (0.13)
62.80 (0.04)
63.88 (0.13)
64.73 (0.12)
66.29 (0.28)
63.37 (0.44)
64.97 (0.75)
73.19 (0.02)

Level-INR
Original76.01 (0.74) 76.81 (0.59)
New 77.50 (0.23) 78.28 (0.24)
Original59.60 (0.28) 60.03 (0.24)
New 59.70 (0.14) 59.98 (0.28)
Original63.42 (0.54) 63.26 (0.34)
New 63.14 (0.54) 62.52 (0.38)
DMOZ-
Original63.20 (0.54) 61.98 (0.56)
SMALL
New 63.82 (0.42) 58.02 (0.14)
DMOZ-2012Original73.03 (0.11) 71.41 (0.38)
Table 5: hF1 performance comparison of best TD hierarchi-
cal baseline model and proposed ﬂattening models over orig-
inal and new modiﬁed hierarchy. hF1 score for DMOZ-2010
dataset is not available from online evaluation and DMOZ-
2012 dataset hF1 score cannot be computed on new hierachy.

baseline method, TD-LR has worst performance because of
the presence of inconsistent nodes in the hierarchy which
leads to the error propogation.

Performance based on Hierarchical Metrics - Table
5 shows the hF1 score for the best TD model, MTA and
the proposed ﬂattening models evaluated over the original
and the new hierarchy (obtained by modiﬁcation) for all
datasets. We can see that our proposed method, Global-
INR has the best performance over all the datasets because
it is able to identify better set of inconsistent nodes resulting
in performance improvement over other models. Moreover,
new hierarchy has better performance over original hierarchy
because ﬂattening of hierarchies results in the reduction of
hierarchical path length for misclassiﬁed examples, resulting
in hF1 score improvement.

Empirical Study for Threshold (τ ) Selection - Fig-
ure 5 shows the M F1 performance comparison of ﬂat (LR)
and best TD classiﬁer, Global-INR, with varying selection of
threshold (τ ) in the interval [µ, µ+3σ] (performance deterio-
rates after µ+3σ) with step-size 0.1σ for CLEF and DMOZ-
SMALL dataset. We choose these datasets for evaluation be-
cause they have diﬀerent characteristics. The CLEF dataset
is well-balanced and does not suﬀer from the rare categories
problem, whereas, DMOZ-SMALL dataset is highly unbal-
anced and more than 80% of the classes belong to rare cat-
egories i.e., have less than 10 examples. In order to identify
the set of inconsistent nodes in the hierarchy, we compare
the computed f∗ value of each internal node with the cho-
sen threshold (τ ) and mark these node as inconsistent iﬀ

Figure 5: M F1 performance comparison of Flat (marked in
dotted red) and best TD classiﬁer, Global-INR (marked in
solid blue) after varying threshold (τ ) for CLEF and DMOZ-
SMALL dataset.

f∗ > τ .
It can be observed that for CLEF dataset, per-
formance improves as the threshold (τ ) decreases giving in-
tuition that τ should be kept smaller i.e., removing more
internal nodes from the hierarchy (enforcing ﬂat structure)
is better and hence reducing the threshold value τ can possi-
bly lead to better results. However, for the DMOZ-SMALL
dataset, performance ﬁrst increases and than decreases with
maximum performance achieved around τ = µ + 2σ. This
behaviour explains that for unbalanced distribution and cat-
egories with few training examples, we should generally keep
the threshold higher and allow minimal changes in the hi-
erarchy by removing fewer inconsistent nodes. The best
threshold for a speciﬁc dataset can be chosen empirically
using a small validation set as done in this study.

4.5.3 Rewiring Approach
Classiﬁcation Performance - Table 6 shows the per-
formance comparison of our proposed ﬁlter based rewiring
approach with best ﬂattening approach, Global-INR and
competing rewiring approach, T-Easy. We can make fol-
lowing observation from the Table 6: (i) The rewiring ap-
proaches signiﬁcantly outperforms the best ﬂattening ap-
proach, Global-INR (ii) Our proposed ﬁlter based model
achieves competitive performance results in comparison to
T-Easy model. However, for most of the smaller datasets
T-Easy model has better performance because it searches
for the optimal hierarchy in the hierarchical space which
can gradually reach the performance improvement (or even

Figure 6: Sorted cosine similarity scores for DMOZ-SMALL
dataset.

better) that is achieved by our model. Nevertheless, main
drawback of T-Easy approach is that it needs a lot of compu-
tationally expensive hierarchy evaluations for reaching the
optimal hierarchy, which makes this approach intractable for
larger datasets (DMOZ).

Runtime Comparison - In Table 7 we compare the
training times of diﬀerent models. For training, we learn
the models in parallel for diﬀerent classes using multiple
compute nodes which is then combined to obtain the ﬁnal
runtime. For our proposed rewiring approach we also com-
pute the similarity between diﬀerent classes in parallel. We
can see from Table 7 that TD-LR takes the least time as
there is no extra hierarchy modiﬁcation overhead; followed
by the Global-INR model which requires models re-training
after hierarchy ﬂattening. Rewiring approaches are most ex-
pensive because of the compute intensive task of either simi-
larity computation using our proposed approach or multiple
hierarchy evaluations using the T-Easy approach. Compar-
atively, the T-Easy method takes the longest time due to
large number of expensive hierarchy evaluation after each
elementary operation until the optimal hierarchy is reached.
Table 8 shows the number of elementary operations executed
using the T-Easy and our proposed approach. We can see
that T-Easy approach executes extremely large number of
operations even for smaller datasets (for e.g., 412 operations
for IPC datasets), making it expensive.

Empirical Study for Threshold (τ ) Selection to
Group Similar Classes - Figure 6 shows the sorted (de-
scending order) class pairs cosine similarity scores for DMOZ-
SMALL dataset. We can see that similarity scores becomes
nearly constant after 1000 pairs (and drops further after
6000, not shown in the Figure) that does not provides any
interesting similar classes grouping information for taxon-
omy modiﬁcation. So for this dataset choosing threshold τ
as the similarity score of the 1000-th class pair is a reason-
able choice. Similar approach to determine the threshold
can be applied for other datasets as well.

Eﬀect of Varying the Training Size - Figure 7 shows
the M F1 comparison of best ﬂattening, Global-INR and
rewiring approaches on CLEF and DMOZ-SMALL datasets
with varying percentage of training size. For both datasets
we can see that rewiring approaches outperforms the ﬂatten-
ing approach. Interestingly, for CLEF dataset with smaller
training percentage our proposed rewiring approach has bet-
ter performance. Reason for this behaviour might be the
over-ﬁtting of the optimal hierarchy with the training data
in case of the T-Easy approach, which results in poor per-
formance on unseen examples. For training dataset with
enough examples as expected, T-Easy method gives the best
performance but at the cost of expensive runtime. We can-
not run T-Easy on DMOZ datasets.

4.5.4 Comparison to Flat method

Rewiring

Flattening
Best Model
(Global-INR)

[20]

IPC

CLEF

T-Easy

DIATOMS

DMOZ-SMALL

Proposed
Filter Model
µF1(↑) 77.14 (0.01) 78.12 (0.16) 78.00 (0.22)
M F1(↑) 46.54 (0.06) 48.83‡ (0.08) 47.10 (0.03)
hF1(↑) 79.06 (0.01) 81.43 (0.03) 80.14 (0.02)
µF1(↑) 61.31 (0.53) 62.34‡ (0.28) 62.05‡ (0.10)
M F1(↑) 51.85 (0.23) 53.81‡ (0.11) 52.14‡ (0.14)
hF1(↑) 62.80 (0.04) 64.28 (0.22) 63.24 (0.13)
µF1(↑) 52.30 (0.12) 53.94† (0.24) 54.28† (0.18)
M F1(↑) 45.65 (0.11) 46.10† (0.21) 46.04† (0.22)
hF1(↑) 64.73 (0.12)
67.23 (0.24) 68.34 (0.18)
µF1(↑) 46.61 (0.28)
48.25‡ (0.13)
M F1(↑) 31.26 (0.64)
33.92‡ (0.22)
hF1(↑) 63.37 (0.44)
66.18 (0.15)
µF1(↑) 42.37 (0.27)
43.10 (0.28)
M F1(↑) 30.11 (0.64)
31.21 (0.34)
µF1(↑) 50.64 (0.22)
51.82 (0.02)
M F1(↑) 30.58 (0.28)
31.24 (0.12)
hF1(↑) 73.19 (0.02)
74.21 (0.03)
Table 6: µF1, M F1 and hF1 performance comparison of
rewiring approaches against best ﬂattening model. ’NS’ de-
notes not scalable. The signiﬁcance-test results are denoted
as † for a p-value less than 5% and ‡ for p-value less than
1%. Test are between rewiring and ﬂattening approach.
Test cannot be performed on DMOZ-2010 and DMOZ-2012
dataset because we do not have access to true labels.

DMOZ-2010

DMOZ-2012

NS

NS

NS

Figure 7: M F1 performance comparison of rewiring ap-
proaches with best ﬂattening, Global-INR model with vary-
ing % of training size. T-Easy approach is not scalable for
DMOZ-SMALL dataset.

Hierarchical

Baseline
(TD-LR)

Flattening
Best Model T-Easy

Rewiring

(Global-INR)

Proposed

Filter Model

[20]
59
268

2.5
8.5
607
52

CLEF
DIATOMS
IPC
DMOZ-SMALL
DMOZ-2010
DMOZ-2012
Table 7: Total training runtimes (in mins). ’NS’ denotes not
scalable.

3.5
10
830
65

42000
94800

25600
63000

20190
50040

1284
168

NS
NS
NS

7.5
24

26432

# elementary operation executed CLEF DIATOMS

IPC

T-Easy[20]

(promote, demote, merge)

Proposed Rewiring Filter Model

(NC, PCRewire, ND)

52

25

156

34

412

42

Table 8: Number of elementary operation executed for
rewiring approaches.

Table 9 shows the M F1 and hF1 performance compari-
son of our proposed best ﬂattening, Global-INR model and
the ﬁlter based rewiring model against the ﬂat one-vs-rest
LR model on larger DMOZ datasets broken by varying dis-

train

Flat

example

LR Model

Flattening
Best Model
(Global-INR)

Rewiring
Proposed

per
class M F1
≤5
27.02
DMOZ- 6-10
54.76
72.60
SMALL 11-50
71.44
>50
avg.
30.80
≤5
8.57
DMOZ- 6-10
22.62
43.26
2010
11-50
73.20
>50
avg.
29.06
≤5
7.31
DMOZ- 6-10
18.84
2012
37.98
11-50
64.08
>50
avg.
27.22

Filter Model
hF1
54.34
69.15
79.93
87.18
66.18
56.15
57.32
63.21
78.14
57.43
52.14
52.34
54.42
53.20
53.21
Table 9: M F1 and hF1 comparison of our proposed ap-
proaches against ﬂat LR model for DMOZ datasets with
varying distribution of training examples per class.

hF1 M F1
51.86 29.84
67.47 56.16
73.42
78.74
86.70
69.92
63.37 33.92
52.59 12.02
55.76 25.13
43.12
62.39
77.51
71.28
55.17 31.21
51.95 11.34
50.71 21.43
53.16
38.01
51.03
62.32
52.19 31.24

hF1 M F1
46.81 28.77
65.40 55.55
80.12 72.26
88.95 69.43
60.87 31.26
46.13
8.96
51.84 23.03
61.85 42.56
81.51 70.74
58.10 30.11
48.41
8.04
48.82 20.37
53.24 37.19
55.72 58.92
50.10 30.58

tribution of training size. For evaluating DMOZ-2010 and
DMOZ-2012 datasets we have used a separate held out dataset
because we don’t know the actual labels of test dataset from
online evaluation. We use M F1 for comparison because it
gives equal importance to all classes while evaluation. For
hF1, we have used the original hierarchy for consistent eval-
uation. We can see that for rare categories (few training ex-
amples per class) our proposed ﬁlter based and Global-INR
model outperforms the ﬂat LR model. The hierarchy pro-
vides useful information in categorizing these classes with
less training examples. However, for classes with enough
training examples ﬂat LR model gives better results due to
better generalized models learning. It should be noted that
ﬂat models have very expensive predicition time in compar-
ison to our proposed TD models because it invokes all the
models while making prediction. For DMOZ-2010 dataset,
ﬂat model takes ∼90 mins for predicting the labels of test in-
stances whereas our models takes ∼20 mins. On comparing,
our proposed ﬁlter based rewiring model with the Global-
INR model, we can see that rewiring model has better per-
formance because the modiﬁed hierarchy using rewiring ap-
proach is based on the similarity score which leverages the
hierarchy better in comparison to ﬂattened hierarchy.

5. CONCLUSION AND FUTURE WORKS
In this paper, we proposed two diﬀerent ﬁlter-based data-
driven approaches for taxonomy modiﬁcation. We derived
a ﬂattening based approach, that selectively removes the
inconsistent nodes from the hierarchy based on the devia-
tion from mean, and rewiring approach, that modiﬁes the
existing parent-child relationships based on the similarities
between the classes. Our proposed global ﬂattening method
exclusively outperform the existing ﬂattening methods in the
literature, whereas our proposed rewiring method gives com-
petitive results with much better runtime performance that
allow HC on signiﬁcantly larger datasets (DMOZ). Extensive
analysis with varying training percentage and distribution
per class is done to better understand the behaviour of our
proposed approaches with existing methods. In future, we
plan to extend our proposed methods for hierarchical multi-
label datasets where instances can belong to more than one
class. We also plan to study the eﬀect of our methods in
conjunction with feature selection.

6. ACKNOWLEDGEMENTS

NSF grant # 1447489 and 1252318.

7. REFERENCES
[1] C. C. Aggarwal, S. C. Gates, and P. S. Yu. On the merits

of building categorization systems by supervised clustering.
In SIGKDD, pages 352–356, 1999.

[2] R. Babbar, I. Partalas, E. Gaussier, and M.-R. Amini.

Maximum-margin framework for training data
synchronization in large-scale hierarchical classiﬁcation. In
Neural Information Processing, pages 336–343, 2013.

[3] R. Babbar, I. Partalas, E. Gaussier, and M.-R. Amini. On

ﬂat versus hierarchical classiﬁcation in large-scale
taxonomies. In NIPS, pages 1824–1832, 2013.

[4] L. Cai and T. Hofmann. Hierarchical document

categorization with svms. In CIKM, pages 78–87, 2004.

[5] S.-L. Chuang and L.-F. Chien. A practical web-based

approach to generating topic hierarchy for text segments.
In CIKM, pages 127–136, 2004.

[6] I. Dimitrovski, D. Kocev, S. Loskovska, and S. Dˇzeroski.

Hierarchical classiﬁcation of diatom images using predictive
clustering trees. Ecological Informatics, 7:19–29, 2012.

[7] I. Dimitrovski, D. Kocev, S. Loskovska, and S. Dˇzeroski.

Hierarchical annotation of medical images. Pattern
Recognition, 44(10):2436–2449, 2011.

[8] S. Dumais and H. Chen. Hierarchical classiﬁcation of web

content. In SIGIR, pages 256–263, 2000.

[9] T. Gao and D. Koller. Discriminative learning of relaxed

hierarchy for large-scale visual recognition. In ICCV, pages
2072–2079, 2011.

[10] S. Gopal and Y. Yang. Recursive regularization for

large-scale classiﬁcation with hierarchical and graphical
dependencies. In SIGKDD, pages 257–265, 2013.

[11] D. Koller and M. Sahami. Hierarchically classifying docs

using very few words. In ICML, pages 170–178, 1997.
[12] T. Li, S. Zhu, and M. Ogihara. Hierarchical document

classiﬁcation using automatically generated hierarchy. J. of
Intelligent Information Systems, 29(2):211–230, 2007.
[13] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and

W.-Y. Ma. Support vector machines classiﬁcation with a
very large-scale taxonomy. SIGKDD, 7(1):36–43, 2005.

[14] H. Malik. Improving hierarchical svms by hierarchy

ﬂattening and lazy classiﬁcation. In Large-Scale
Hierarchical Classiﬁcation Workshop of ECIR, 2010.

[15] A. McCallum, R. Rosenfeld, T. M. Mitchell, and A. Y. Ng.
Improving text classiﬁcation by shrinkage in a hierarchy of
classes. In ICML, pages 359–367, 1998.

[16] K. Nitta. Improving taxonomies for large-scale hierarchical

classiﬁers of web docs. In CIKM, pages 1649–1652, 2010.

[17] K. Punera, S. Rajan, and J. Ghosh. Automatically learning

document taxonomies for hierarchical classiﬁcation. In
WWW: Special interest tracks and posters, 2005.

[18] X. Qi and B. D. Davison. Hierarchy evolution for improved

classiﬁcation. In CIKM, pages 2193–2196, 2011.

[19] A. Sun and E.-P. Lim. Hierarchical text classiﬁcation and

evaluation. In ICDM, pages 521–528, 2001.

[20] L. Tang, J. Zhang, and H. Liu. Acclimatizing taxonomic

semantics for hierarchical content classiﬁcation. In
SIGKDD, pages 384–393, 2006.

[21] X.-L. Wang and B.-L. Lu. Flatten hierarchies for large-scale
hierarchical text category. In ICDIM, pages 139–144, 2010.

[22] L. Xiao, D. Zhou, and M. Wu. Hierarchical classiﬁcation

via orthogonal transfer. In ICML, pages 801–808, 2011.

[23] G.-R. Xue, D. Xing, Q. Yang, and Y. Yu. Deep

classiﬁcation in large-scale text hierarchies. In SIGIR,
pages 619–626, 2008.

[24] Y. Yang and X. Liu. A re-examination of text

categorization methods. In SIGIR, pages 42–49, 1999.

[25] A. Zimek, F. Buchwald, E. Frank, and S. Kramer. A study

of hierarchical and ﬂat classiﬁcation of proteins. TCBB,
7(3):563–571, 2010.

