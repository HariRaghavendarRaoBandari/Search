Optimizing Data Freshness, Throughput, and Delay

in Multi-Server Information-Update Systems

Ahmed M. Bedewy, Yin Sun, and Ness B. Shroff

Dept. of ECE, The Ohio State University, Columbus, OH.

6
1
0
2

 
r
a

M
 
0
2

 
 
]
T
I
.
s
c
[
 
 

1
v
5
8
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—In this work, we consider an information-update
system where a source sends update packets to a remote monitor
via multiple network servers. An important metric of data
freshness at the monitor is the age-of-information, or simply age,
which is deﬁned as the time elapsed since the freshest packet
at the monitor was generated. Recent studies on information-
update systems have shown that the age-of-information can be
reduced by intelligently dropping stale packets. However, packet
dropping may not be appropriate in many systems (such as
news and social networks), where users are interested in not
just the latest updates, but also past news. Therefore, all packets
may need to be successfully delivered. In this paper, we study
how to optimize the age-of-information without throughput loss.
We show that the preemptive Last-Come First-Served (LCFS)
policy simultaneous optimizes the age, throughput, and delay
performance in inﬁnite buffer systems, and hence is appropriate
for practical
information-update systems. We also show age-
optimality regardless of the buffer size. Numerical results are
provided to validate our theoretical results.

I. INTRODUCTION

With the ever prevalence of mobile devices and applications,
the demand has increased on real-time information updates,
such as news, weather reports, email notiﬁcations, stock
quotes, social updates, mobile ads, etc. Also, in network-
based monitoring and control systems, timely status updates
are crucial. These include, but are not
limited to, sensor
networks used in temperature or other physical phenomenon,
and autonomous vehicle systems.

A common objective in these applications is to keep the
monitor updated with the latest
information. To identify
the timeliness of the update, a metric called the age-of-
information, or simply age, was deﬁned in [1]–[4]. At time
t, if the freshest update at the monitor has a time stamp U (t),
the status update age is ∆(t) = t − U (t). Hence, the age is
the time elapsed since the freshest packet was generated.

Most works try to analytically characterize the time-average
age of different information-update policies under Poisson
arrival process, and ﬁnd a policy with a smaller time-average
age [4]–[10]. In [4]–[6], the update generation rate was op-
timized to improve data freshness in First-Come First-Served
(FCFS) information-update systems. To improve the age, these
studies reduce the update generation rate from the maximum
achievable rate, which in turn degrades system throughput.
In [7], [8], it was found that the age can be improved by
discarding old packets waiting in the queue if a new sample
arrives, which can greatly reduce the impact of queueing delay
on data freshness. However, discarding packets may not be

server m

Source

Queue

Destination

server 2

server 1

Figure 1: System model.

appropriate for applications where the users are interested
in not just the latest updates, but also past news, where all
packets may need to be successfully delivered. In [9], [10], the
time-average age was characterized for several information-
update policies under Poisson arrival process. Applications
of information updates in channel information feedback and
sensor networks were considered in [11], [12].

One important problem is how to achieve the optimal
age performance in information-update systems. Recently, the
joint control of the generation and transmission of update
packets was studied in [12]–[14]. An information update
policy was developed in [14], which was proven to minimize
the time-average age and time-average age penalty among all
causally feasible policies. A counter-intuitive phenomenon was
revealed in this study: While a zero-wait or work-conserving
policy, that submits a fresh update once the server becomes
idle, achieves the maximum throughput and the minimum
average delay, surprisingly, this zero-wait policy does not
always optimize the age. It was shown that in many scenarios
the age-optimal policy is to insert waiting times between
updates, which is, however, not throughput-optimal. Therefore,
how to jointly optimize data freshness, throughput, and delay
performance in information-update systems remains an open
problem.

In this paper, we consider an information-update system
with multiple servers, which is illustrated in Fig. 1. We aim
to answer the following questions: How to minimize the age-
of-information without throughput loss? How to establish age-
optimality in a general policy space and under arbitrary arrival
process? Is it possible to simultaneously optimize multiple
performance metrics, such as age, throughput, and delay? To
that end, the following are the key contributions of this paper:
if the packet service times are i.i.d.
exponentially distributed, then for an arbitrary arrival

• We prove that,

process and any buffer size, the preemptive Last-Come
First-Served (LCFS) policy achieves an age that
is
stochastically smaller than any causally feasible policies
(Theorem 1). This implies that the preemptive LCFS
policy minimizes many data freshness metrics, including
time-average age, average peak age, and time-average
age penalty (Corollary 5). The intuition behind this age-
optimality result is that new update packets with the
freshest information are served as early as possible in
the preemptive LCFS policy.

• In addition, we show that if the queue has an inﬁnite
buffer size,
then the preemptive LCFS policy is also
throughput-optimal and delay-optimal among all causally
feasible policies (Theorem 6). Numerical results are pro-
vided to validate our theoretical results.

The closest study to our work is [9], which analyzed the
time-average age of preemptive and non-preemptive LCFS
policies for a single-server system with Poisson arrival process
and a buffer size of one packet. In our paper, we prove that
the preemptive LCFS policy is age-optimal for multi-server
systems with an arbitrary arrival process and any buffer size.
Hence, our study complements that of [9]. To the best of our
knowledge, this is the ﬁrst study which simultaneously opti-
mizes data freshness, throughput, and delay in information-
update systems.

This paper is motivated by the applications that require all
the updates to be sent not only the latest one. For instance, it
was shown that the completely stale channel state information
(CSI) is still very useful in a MIMO broadcast channel in
[15]. Particularly, by using not only the latest CSI but also the
outdated CSI, one can achieve non-trivial multiplexing gains.
Another example is stock predictions. In [16], a base stock
policy was introduced such that it uses stale or old forecasts
beside the current forecast to set base stock levels at the manu-
facturer. It was found that, in case of a non-stationary demand
process, the proposed policy can decrease the expected supply
chain inventory and shortage costs; and signiﬁcantly reduce
the ﬂuctuations in production levels compared to that of using
current information.

Another important application for our model is the rein-
forcement learning. The reinforcement learning is learning
what action should be performed in order to maximize a nu-
merical reward signal [17]. The reinforcement learning agent
is not told which action to take, but instead it must ﬁgure out
which actions that leads to maximum reward by trying them.
If the learning agent takes action depending on the updates
received from a certain source,
then its decision requires
the knowledge of all updates in addition to the latest one.
Another application is dynamic-content distribution service.
For example, a group of wireless users receives frequent
content updates from a common source such as news feeds.
In this case, the user is interested in not only the latest news,
but also the previous news-feeds.

Figure 2: Evolution of the age-of-information ∆(t).

II. SYSTEM MODEL

We consider an information-update system depicted in Fig.
1, where a source sends an inﬁnite sequence of update packets
to a destination through m identical servers. Each server could
be a wireless channel, a TCP connection, etc. The update pack-
ets are generated at time s1, s2, . . ., where s1 = 0 ≤ s2 ≤ . . .
are deterministic and arbitrarily given. After generation, each
update packet is stored in a queue, waiting to be assigned
to one of the servers. Let B denote the buffer size of the
queue which can be inﬁnite, ﬁnite, or even zero. If B is ﬁnite,
the queue buffer may overﬂow under bursty trafﬁc and some
packets are dropped, which would incur a throughput loss. The
packet service times are exponentially distributed with rate µ,
which are i.i.d. across time and servers. Let Ti denote the i-th
packet delivery time instant.

The system starts to operate at time t = 0. Deﬁne U (t) as
the time stamp of the freshest update at the destination at time
t, where we set U (t) = 0 at t = 0. The age-of-information,
or simply the age, is deﬁned as

∆(t) = t − U (t).

(1)

From this deﬁnition, we can deduce that the age increases
linearly with t but is reset to a smaller value with each update
delivery that contains newer information, as shown in Fig. 2.
Deﬁne Ak as the k-th peak value of ∆(t) since time t = 0.

Following [14], we deﬁne an age penalty function g(∆(t))
to represent the level of “dissatisfaction” for data staleness
or the “need” for new information update, where g(·) is a
general non-decreasing function. A practical example of the
age penalty function can be found in [11].

A. Scheduling Policy

A scheduling policy, denoted by π, assigns update packets
to the servers over time. A scheduling policy can be either
preemptive or non-preemptive.

Deﬁnition 1. Service Preemption: In a preemptive policy,
a server can switch to send an incoming packet with a higher
priority at any time; the preempted packets will be stored back
to the queue if there is enough buffer space and sent at a later
time when the servers are available again. In contrast, in a
non-preemptive policy, a server must complete delivering the
current packet before starting to send another packet.

Deﬁnition 2. Work Conservation: A policy is said to be
work-conserving, if no server is idle when there are packets
waiting in the queue.

We use Π to denote the set of all causal policies. Let Πwc ⊆
Π be the set of work-conserving feasible policies, and Πnwc ⊆
Π be the set of non-work-conserving feasible policies.

B. Age Optimality

We will need the following deﬁnitions: Let ~x =
(x1, x2, . . . , xn) and ~y = (y1, y2, . . . , yn) be two vectors in
Rn, then we denote ~x ≤ ~y if xi ≤ yi for i = 1, 2, . . . , n.

Deﬁnition 3. Stochastic Ordering: [18] Let X and Y be
two random variables. Then, X is said to be stochastically
smaller than Y (denoted as X ≤st Y ), if

P {X > x} ≤ P {Y > x},

∀x ∈ R.

Deﬁnition 4. Multivariate Stochastic Ordering: [18] A
set U ⊆ Rn is called upper if ~y ∈ U whenever ~y ≥ ~x and
~x ∈ U . Let ~X and ~Y be two random vectors. Then, ~X is said
to be stochastically smaller than ~Y (denoted as ~X ≤st ~Y ), if

P { ~X ∈ U } ≤ P {~Y ∈ U },

for all upper sets U ⊆ Rn.

Deﬁnition 5. Stochastic Ordering of Stochastic Pro-
cesses: [18] Let {X(t), t ∈ [0, ∞)} and {Y (t), t ∈ [0, ∞)} be
two stochastic processes. Then, {X(t), t ∈ [0, ∞)} is said to
be stochastically smaller than {Y (t), t ∈ [0, ∞)} (denoted by
{X(t), t ∈ [0, ∞)} ≤st {Y (t), t ∈ [0, ∞)}), if, for all choices
of an integer n and t1 < t2 < . . . < tn in [0, ∞), it holds that

(X(t1), X(t2), . . . , X(tn)) ≤st (Y (t1), Y (t2), . . . , Y (tn)), (2)

where the multivariate stochastic ordering in (2) was deﬁned
in Deﬁnition 4.

Deﬁnition 6. Age Optimality: A policy P ∈ Π is said to

be age-optimal, if for all π ∈ Π

{∆p(t), t ∈ [0, ∞)} ≤st {∆π(t), t ∈ [0, ∞)}.

(3)

As we will see in Corollary 5, this deﬁnition of age optimality
is stronger than many deﬁnitions proposed in prior studies.

III. OPTIMALITY ANALYSIS

In this section, we study the preemptive LCFS policy
depicted in Algorithm 1, where αi is the i-th smallest time
stamp of the packets under service. We will show that the
preemptive LCFS policy is age-optimal, which is stated in the
following theorem.

Theorem 1. If the packet service times are exponentially
distributed and i.i.d. across time and servers, then for any
given arrival time sequence s1, s2, . . . and buffer size B, the
preemptive LCFS policy is age-optimal.

Algorithm 1: Preemptive Last Come First Served policy.
1 αi := 0, i = 1, . . . m;
2 while the system is ON do
3
4
5

if a new packet with time stamp s arrives then

if all servers are busy then

The new packet is assigned to a server by
preempting the packet with time stamp α1;
αi := αi+1, i = 1, . . . m − 1;
αm := s;
if the buffer is not full then

The preempted packet is stored back to
the queue;

else

// the buffer is full

The preempted packet is dropped;

end

else

// At least one of the servers is idle

Assign the new packet to one idle server;

end

end
if a packet is delivered then

if

the buffer is not empty then
Pick any packet in the buffer and assign it to
the idle server;

end

6
7
8
9

10
11
12
13
14
15
16
17
18
19

20
21
22 end

end

smallest time stamp of the packets being processed by the
servers. Without loss of generality, if k servers are sending
stale packets such that α1,π(t) ≤ . . . ≤ αk,π(t) ≤ Uπ(t) or k
servers are idle, then we set α1,π(t) = . . . = αk,π(t) = Uπ(t).
Hence,

Uπ(t) ≤ α1,π(t) ≤ . . . ≤ αm,π(t).

(4)

Let {Vπ(t), t ∈ [0, ∞)} be the state process of policy π, which
is assumed to be right-continuous.

For notational simplicity, let policy P denote the preemp-
tive LCFS policy. Then, in policy P , α1,P (t), α2,P (t), . . . ,
αm,P (t) are the time stamps of m freshest packets among all
packets generated during [0, t].

The key step in the proof of Theorem 1 is the following
lemma, where we compare policy P with any work-conserving
policy π ∈ Πwc.
Lemma 2. For any given arrival time sequence s1, s2, . . . and
buffer size B, suppose that VP (0−) = Vπ(0−) for all work
conserving policies π ∈ Πwc, then

{VP (t), t ∈ [0, ∞)} ≥st {Vπ(t), t ∈ [0, ∞)}.

(5)

We need to deﬁne the system state of any policy π:
Deﬁnition 7. At any time t, the system state of policy π
is speciﬁed by Vπ(t) = (Uπ(t), α1,π(t), . . . , αm,π(t)), where
Uπ(t) is the largest time stamp of the packets that have already
been delivered to the destination. Deﬁne αi,π(t) as the i-th

We use coupling and forward induction to prove Lemma
2. For any work-conserving policy π, suppose that stochastic
processes ˆVP (t) and ˆVπ(t) have the same stochastic laws as
VP (t) and ˆVπ(t). The state processes ˆVP (t) and ˆVπ(t) are
coupled in the following manner: Consider the packet delivery

events during the evolutions of ˆVP (t) and ˆVπ(t). If the packet
with time stamp ˆαi,P (t) is completed at time t as ˆVP (t)
evolves, then the packet with time stamp ˆαi,π(t) is completed
at time t as ˆVP (t) evolves. Such a coupling is valid since the
service time is exponentially distributed and thus memoryless.
According to Theorem 6.B.30 in [18], if we can show

P h ˆVP (t) ≥ ˆVπ(t), t ∈ [0, ∞)i = 1,

(6)

then (5) is proven. Next, we use the following two lemmas to
prove (6):

3.

that

under

policy

1,P , . . . , ˆα′

Lemma
Suppose
P ,
{ ˆU ′
m,P } is obtained by delivering a packet
P , ˆα′
with time stamp ˆαl,P to the destination in the system whose
state is { ˆUP , ˆα1,P , . . . , ˆαm,P }. Further, suppose that under
policy π, { ˆU ′
m,π} is obtained by delivering a
packet with time stamp ˆαl,π to the destination in the system
whose state is { ˆUπ, ˆα1,π, . . . , ˆαm,π}. If

1,π, . . . , ˆα′

π, ˆα′

ˆUP ≥ ˆUπ, ˆαi,P ≥ ˆαi,π,

∀i = 1, . . . , m,

Finally, since the service times are i.i.d. across time and
servers, service idling only increases the waiting time of the
packet in the system. Therefore, the age under non-work-
conserving policies will be greater. As a result, we have

{∆P (t), t ∈ [0, ∞)} ≤st {∆π(t), t ∈ [0, ∞)}, ∀π ∈ Π.

This completes the proof.

As a result of Theorem 1, we can deduce the following

corollary:

Corollary 5. If the packet service times are i.i.d. exponentially
distributed across time and servers, then for all arrival time
sequence s1, s2, . . ., buffer size B, π ∈ Π, and non-decreasing
function g,

lim
T →∞

1

T Z T

0

∆prmp-LCFS(t)dt ≤st

lim
T →∞

lim
K→∞

1
K

K

Xk=1

Ak,prmp-LCFS ≤st

lim
K→∞

1

T Z T

0

K

1
K

Xk=1
T Z T

1

0

∆π(t)dt,

Ak,π,

g(∆π(t))dt,

then,

ˆU ′
P ≥ ˆU ′

π, ˆα′

i,P ≥ ˆα′

i,π,

∀i = 1, . . . , m.

lim
T →∞

(7)

1

T Z T

0

g(∆prmp-LCFS(t))dt ≤st

lim
T →∞

Proof: See Appendix A.

4.

that

under

1,P , . . . , ˆα′

Suppose
policy
m,P } is obtained by adding a

Lemma
P ,
{ ˆU ′
fresh
P , ˆα′
packet with time stamp s to the system whose state is
{ ˆUP , ˆα1,P , . . . , ˆαm,P }. Further, suppose that under policy
π, { ˆU ′
m,π} is obtained by adding a fresh
packet with time stamp s to the system whose state is
{ ˆUπ, ˆα1,π, . . . , ˆαm,π}. If

1,π, . . . , ˆα′

π, ˆα′

ˆUP ≥ ˆUπ, ˆαi,P ≥ ˆαi,π,

∀i = 1, . . . , m,

then

ˆU ′
P ≥ ˆU ′

π, ˆα′

i,P ≥ ˆα′

i,π,

∀i = 1, . . . , m.

(8)

Proof: See Appendix B.
Proof of Lemma 2: For any sample path, we have
that ˆUP (0−) = ˆUπ(0−) and ˆαi,P (0−) = ˆαi,π(0−) for
i = 1, . . . , m. This, together with Lemma 3 and 4, implies
that

ˆUP (t) ≥ ˆUπ(t), ˆαi,P (t) ≥ ˆαi,π(t)

holds for all t ∈ [0, ∞) and i = 1, . . . , m. Hence, (6) follows.
Because { ˆVP (t), t ∈ [0, ∞)} and {VP (t), t ∈ [0, ∞)} are
of the same distribution, { ˆVπ(t), t ∈ [0, ∞)} and {Vπ(t), t ∈
[0, ∞)} are of the same distribution, by Theorem 6.B.30 in
[18] we get (5). This completes the proof.

Proof of Theorem 1: As a result of Lemma 2, we have

{UP (t), t ∈ [0, ∞)} ≥st {Uπ(t), t ∈ [0, ∞)}, ∀π ∈ Πwc,

which implies

where the limits are assumed to exist.1

Hence, the preemptive LCFS policy minimizes time-average
age, average peak age, and time-average age penalty for any
non-decreasing penalty function g. Finally,
the delay and
throughput optimality of the preemptive LCFS policy is stated
as follows:

Theorem 6. If the packet service times are i.i.d. exponentially
distributed across time and servers, then for any arrival time
sequence s1, s2, . . . and inﬁnite buffer size B = ∞,
the
preemptive LCFS policy is throughput-optimal and mean-
delay-optimal among all policies in Π.

In particular, any work-conserving policy is throughput op-
timal and mean-delay-optimal. The proof details are provided
in Appendix C.

IV. NUMERICAL RESULTS

We present some numerical results to illustrate the age and
throughput performance of different policies. The packet ser-
vice times are experientially distributed with mean 1/µ = 1,
which is i.i.d. across time and servers. The inter-arrival times
are i.i.d. Erlang-2 distribution with mean 1/λ. The number of
servers is m. Hence, the trafﬁc intensity is ρ = λ/mµ. The
queue buffer size is denoted as B, which is a non-negative
integer.

Figure 3 illustrates the time-average age versus ρ for an
information-update system with m = 1 server. One can
observe that the preemptive LCFS policy achieves a better
age performance than the FCFS policy analyzed in [4], and
the non-preemptive LCFS policy with buffer size B = 1 [9]
which was also named “M/M/1/2*” in [7]. Note that in these

{∆P (t), t ∈ [0, ∞)}≤st{∆π(t), t ∈ [0, ∞)}, ∀π ∈ Πwc.

1Please refer to Fig. 2 and Section II for the peak age Ak,π.

Preemptive LCFS, Any B ≥ 0
Non-preemptive LCFS, B = 1
FCFS, B = 1
FCFS, B = ∞

8

7

6

5

4

3

2

1

 

e
g
a
e
g
a
r
e
v
A

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

ρ

t

u
p
h
g
u
o
r
h
T

2.1

2

1.9

1.8

1.7

1.6

1.5

1.4

1.3

1.2

Preemptive LCFS, B=∞
preemptive LCFS, varying B
Non-preemptive LCFS, B=1

0

20

40
60
Buffer size B

80

100

Figure 3: Average age versus trafﬁc intensity ρ for an update

Figure 5: Throughput versus buffer size B for an update

system with m = 1 server and buffer size B.

system with m = 2 servers.

Preemptive LCFS, Any B ≥ 0
Non-preemptive LCFS, B = 1
FCFS, B = 1
FCFS, B = 10
FCFS, B = ∞

5

4

3

2

1

e
g
a
 
e
g
a
r
e
v
A

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

ρ

Figure 4: Average age versus trafﬁc intensity ρ for an update

system with m = 2 servers and buffer size B.

prior studies, the time-average age was characterized only for
the special case of Poisson arrival process.

Figure 4 plots the time-average age versus ρ for an
information-update system with m = 2 servers. We found that
the age performance of each policy is better than that in Fig. 3,
because of the diversity provided by two servers. In addition,
the preemptive LCFS policy achieves the best age performance
among all plotted policies. It is important to emphasize that the
age performance of the preemptive LCFS policy remains the
same for any buffer size B ≥ 0. However, the age performance
of the non-preemptive LCFS policy and FCFS policy varies
with the buffer size B when there are multiple servers. These
numerical results validate Theorem 1.

Figure 5 depicts the throughput versus buffer size B for
an information-update system with m = 2 servers. From
the ﬁgure, we can deduce that the preemptive LCFS policy
with an inﬁnite buffer achieves the maximum throughput of
2, and it is better than the other policies. This is because
other policies have a ﬁnite buffer which leads to packet
dropping and throughput loss. This result is in accordance with
Theorem 6 which shows that the preemptive LCFS policy can
simultaneously maintain age and throughput optimality. The
delay performance is omitted because any work-conserving

policy is mean-delay-optimal.

V. CONCLUSIONS

In this paper, we considered an information-update system,
in which a source sends update packets to a destination
through multiple network servers. It was showed that, if the
packet service times are i.i.d. exponentially distributed, then
for any given arrival process and buffer size, the preemptive
LCFS policy simultaneously optimizes the data freshness,
throughput, and delay performance among all causally feasible
policies. We plan to extend these results to more general
system settings with general service time distribution.

APPENDIX A

PROOF OF LEMMA 3

Since a packet with time stamp ˆαl,P is delivered in policy
P and a packet with time stamp ˆαl,π is delivered in policy π,
we have

P = ˆαl,P ≥ ˆαl,π = ˆU ′
ˆU ′
π.

(9)

In policy P , if the queue is empty, then one server will
be idle after the packet delivery. Otherwise, if there exist
packets in the queue, one of these packets will be assigned to
the available server. Because policy P follows a preemptive
LCFS principle, the time stamp of this assigned packet must
be smaller than ˆαl,P , and hence the packet is stale. In both
cases, we will have

i,P = ˆU ′
ˆα′
P ,
ˆα′
i,P = ˆαi,P ,

i = 1, . . . , l,

i = l + 1, . . . , m.

(10)

We consider two cases for policy π.
Case 1: The queue is empty or the packet which will be

served is outdated. In this case, we have

for
for

i,π,

(11)

P ≥ ˆU ′

π = ˆα′

i = 1, . . . , l,

i,P = ˆU ′
ˆα′
i,π,
i,P = ˆαi,P ≥ ˆαi,π = ˆα′
ˆα′
Case 2: The packet which will be served is not outdated.
Assume this packet has a time stamp s. Since policy P is a
preemptive LCFS policy, ˆα′
m,P are the freshest

i = l + 1, . . . , m.

1,p, ˆα′

2,P , . . . , ˆα′

packets among all packets which have arrived. As a result we
have

APPENDIX C

PROOF OF THEOREM 6

ˆα′
ˆα′

i,π,

i,P ≥ ˆα′
m,P ≥ s = ˆα′

i = 1, . . . , m − 1,
m,π.

(12)

Hence, (7) holds, which complete the proof.

APPENDIX B

PROOF OF LEMMA 4

Since policy P is a preemptive policy, this packet will be
immediately assigned to a server. If one server is idle, then
the new packet will be assigned to an idle server; otherwise,
if all servers are busy, then the new packet will preempt the
packet with minimum time stamp α1,P . The preempted packet
will be stored back to the queue if the queue is not full, and
will be discarded if the queue is full. In both cases, the system
state will not be affected. Since s ≥ ˆαi,P for i = 1, . . . , m,
we have

ˆα′
ˆα′

i,P = ˆαi+1,P
m,P = s.

i = 1,. . .,m − 1,

(13)

For policy π, we consider two cases:
Case 1: One of the servers is idle, then the new packet
will be assigned to an idle server. Since s ≥ ˆαi,π for all
i = 1, . . . , m, after the assignment we will have

We follow the same proof technique of Theorem 1. First,
we will compare policy P with any work-conserving policy
π ∈ Πwc. For this, we need to deﬁne the system state of any
policy π:

Deﬁnition 8. At any time t, the system state of policy π is
speciﬁed by Hπ(t) = (Nπ(t), γπ(t)), where Nπ(t) is the total
number of packets in the system at time t. Deﬁne γπ(t) as the
total number of packets that are delivered to the destination at
time t. Let {Hπ(t), t ∈ [0, ∞)} be the state process of policy
π, which is assumed to be right-continuous.

To prove Theorem 6, we will need the following lemma.

Lemma 7. Suppose that HP (0−) = Hπ(0−) for all work
conserving policies π ∈ Πwc, then {HP (t), t ∈ [0, ∞)} and
{Hπ(t), t ∈ [0, ∞)} are of the same distribution.

Suppose that { ˆHP (t), t ∈ [0, ∞)} and { ˆHπ(t), t ∈ [0, ∞)}
are stochastic processes having the same stochastic laws as
{HP (t), t ∈ [0, ∞)} and {Hπ(t), t ∈ [0, ∞)}, where π is
some arbitrary policy in Πwc. Now, we couple the packet
delivery times during the evolution of ˆHP (t) to be identical
with the packet delivery times during the evolution of ˆHπ(t).
The following two lemmas are needed to prove Lemma 7:
Lemma 8. Suppose that under policy P , { ˆN ′
P } is obtained
by delivering a packet to the destination in the system whose
state is { ˆNP , ˆγP }. Further, suppose that under policy π,
{ ˆN ′
π} is obtained by delivering a packet to the destination
in the system whose state is { ˆNπ, ˆγπ}. If

P , ˆγ ′

π, ˆγ ′

ˆα′
ˆα′

m,P = s = ˆα′
i,P = ˆαi+1,P ≥ ˆαi+1,π = ˆα′

m,π,

i,π,

i = 1, . . . , m − 1,

(14)

ˆNP = ˆNπ, ˆγP = ˆγπ,

Case 2: All servers are busy. If policy π is non-preemptive
policy, then the new packet will be stored in the queue if the
queue is not full. Otherwise, the new packet will either be
discarded or replace one of the existed packets in the queue.
As a result, ˆαi,π = ˆα′

i,π for all i. Using (13), we get

then

ˆα′
ˆα′

i,P = ˆαi+1,P ≥ ˆαi+1,π ≥ ˆαi,π = ˆα′
m,P = s > ˆαm,π = ˆα′

m,π.

i,π,

i = 1,. . .,m − 1,

(15)

On the other hand, if policy π is a preemptive policy, then
this fresh packet preempts one packet under service. Suppose
that the preempted packet has a time stamp ˆαl,π, then we have

ˆα′
ˆα′
ˆα′

i,P = ˆαi+1,P ≥ ˆαi+1,π ≥ ˆαi,π = ˆα′
i,P = ˆαi+1,P ≥ ˆαi+1,π = ˆα′
m,P = s = ˆα′

m,π.

i,π,

i,π,

i = 1, . . . , l − 1,

i = l, . . . , m − 1,

ˆN ′

P = ˆN ′

π, ˆγ ′

P = ˆγ ′
π.

(17)

Proof: Since there is a packet delivery, we have

ˆN ′
P = ˆNP − 1 = ˆNπ − 1 = ˆN ′
π,
P = ˆγP + 1 = ˆγπ + 1 = ˆγ ′
ˆγ ′
π.

Hence, (17) holds, which complete the proof.
Lemma 9. Suppose that under policy P , { ˆN ′
P } is obtained
by adding a new packet to the system whose state is { ˆNP , ˆγP }.
Further, suppose that under policy π, { ˆN ′
π} is obtained by
adding a new packet to the system whose state is { ˆNπ, ˆγπ}.
If

P , ˆγ ′

π, ˆγ ′

ˆNP = ˆNπ, ˆγP = ˆγπ,

then

ˆN ′

P = ˆN ′

π, ˆγ ′

P = ˆγ ′
π.

(18)

Since there is no packet delivery, we have

P = ˆUP ≥ ˆUπ = ˆU ′
ˆU ′
π.

Proof: Because B = ∞, no packet is dropped in policy P
and policy π. Since there is a new added packet to the system,
we have

(16)

Hence, (8) holds, which complete the proof.

ˆN ′

P = ˆNP + 1 = ˆNπ + 1 = ˆN ′
π.

[11] M. Costa, S. Valentin, and A. Ephremides, “On the age of channel
information for a ﬁnite-state markov model,” in Proc. IEEE ICC, June
2015, pp. 4101–4106.

[12] T. Bacinoglu, E. T. Ceran, and E. Uysal-Biyikoglu, “Age of information
under energy replenishment constraints,” in Proc. Info. Theory and Appl.
Workshop, Feb. 2015.

[13] R. Yates,

“Lazy is timely: Status updates by an energy harvesting

source,” in Proc. IEEE Int. Symp. Inform. Theory, 2015.

[14] Y. Sun, E. Uysal-Biyikoglu, R. Yates, C. E. Koksal, and N. B. Shroff,
in Proc. IEEE

“Update or wait: How to keep your data fresh,”
INFOCOM, April 2016.

[15] M. A. Maddah-Ali and D. Tse, “Completely stale transmitter channel
state information is still very useful,” in Communication, Control, and
Computing (Allerton), 2010 48th Annual Allerton Conference on, Sept
2010, pp. 1188–1195.

[16] J. Miyaoka and W. Hausman, “How a base stock policy using” stale”
forecasts provides supply chain beneﬁts,” Manufacturing & Service
Operations Management, vol. 6, no. 2, pp. 149–162, 2004.

[17] R. S. Sutton and A. G. Barto, Reinforcement learning: An introduction,

MIT press, 1998.

[18] M. Shaked and J. G. Shanthikumar, Stochastic orders, Springer Science

& Business Media, 2007.

Also, there is no packet delivery, hence

ˆγ ′
P = ˆγP = ˆγπ = ˆγ ′
π.

Thus, (18) holds, which complete the proof.

Proof of Lemma 7: Consider a given sample path of
update delivery times (T1, T2, . . .). We have that ˆNP (0−) =
ˆNπ(0−) and ˆγP (0−) = ˆγπ(0−). This fact, and Lemma 8 and
9, together imply that

ˆNP (t) = ˆNπ(t), ˆγP (t) = ˆγπ(t)

holds for all t ∈ [0, ∞). Hence, we have

P h ˆHP (t) = ˆHπ(t), t ∈ [0, ∞)i = 1.

Because { ˆHP (t), t ∈ [0, ∞)} and {HP (t), t ∈ [0, ∞)} are
of the same distribution, { ˆHπ(t), t ∈ [0, ∞)} and {Hπ(t), t ∈
[0, ∞)} are of the same distribution, we get that {HP (t), t ∈
[0, ∞)} and {Hπ(t), t ∈ [0, ∞)} are of the same distribution.
This completes the proof.

Proof of Theorem 6: As a result of Lemma 7, {γP (t), t ∈
[0, ∞)} and {γπ(t), t ∈ [0, ∞)} are of the same distribution
for all π ∈ Πwc. This implies that all policies π ∈ Πwc have
the same throughput performance. Also, from Lemma 7, we
have that {NP (t), t ∈ [0, ∞)} and {Nπ(t), t ∈ [0, ∞)} are
of the same distribution for all π ∈ Πwc. Hence, all policies
π ∈ Πwc have the same mean-delay performance.

Finally, since the service times are i.i.d. across time and
servers, service idling only increases the waiting time of the
packet in the system. Therefore, the throughput and mean-
delay performance under non-work-conserving policies will be
worse. As a result, the preemptive LCFS policy is throughput-
optimal and mean-delay-optimal among all policies in Π
(indeed, any work-conserving policy with inﬁnite buffer size
B = ∞ is throughput optimal and mean-delay-optimal).

REFERENCES

[1] B. Adelberg, H. Garcia-Molina, and B. Kao, “Applying update streams
in a soft real-time database system,” in ACM SIGMOD Record. ACM,
1995, vol. 24, pp. 245–256.

[2] J. Cho and H. Garcia-Molina, “Synchronizing a database to improve
freshness,” in Acm Sigmod Record. ACM, 2000, vol. 29, pp. 117–128.
[3] L. Golab, T. Johnson, and V. Shkapenyuk, “Scheduling updates in a real-
time stream warehouse,” in Data Engineering, 2009. ICDE’09. IEEE
25th International Conference on. IEEE, 2009, pp. 1207–1210.

[4] S. Kaul, R. Yates, and M. Gruteser, “Real-time status: How often should

one update?,” in Proc. IEEE INFOCOM, 2012, pp. 2731–2735.

[5] R. Yates and S. Kaul, “Real-time status updating: Multiple sources,” in

Proc. IEEE Int. Symp. Inform. Theory, July 2012.

[6] L. Huang and E. Modiano, “Optimizing age-of-information in a multi-
class queueing system,” in Proc. IEEE Int. Symp. Inform. Theory, 2015.
[7] M. Costa, M. Codreanu, and A. Ephremides, “Age of information with
packet management,” in Proc. IEEE Int. Symp. Inform. Theory, June
2014, pp. 1583–1587.

[8] N. Pappas, J. Gunnarsson, L. Kratz, M. Kountouris, and V. Angelakis,
“Age of information of multiple sources with queue management,” in
Proc. IEEE ICC, June 2015, pp. 5935–5940.

[9] S. Kaul, R. Yates, and M. Gruteser, “Status updates through queues,”

in Conf. on Info. Sciences and Systems, Mar. 2012.

[10] C. Kam, S. Kompella, and A. Ephremides, “Effect of message transmis-
sion diversity on status age,” in Proc. IEEE Int. Symp. Inform. Theory,
June 2014, pp. 2411–2415.

