6
1
0
2

 
r
a

M
1

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
0
9
3
0
0

.

3
0
6
1
:
v
i
X
r
a

Parameter Estimation for the Langevin Equation

with Stationary-Increment Gaussian Noise

Tommi Sottinen∗ and Lauri Viitasaari†

March 2, 2016

Abstract

We study the Langevin equation with stationary-increment Gaussian
noise. We show the strong consistency and the asymptotic normality
with Berry–Esseen bound of the so-called alternative estimator of the
mean reversion parameter. The conditions and results are stated in
terms of the variance function of the noise. We consider both the
case of continuous and discrete observations. As examples we consider
fractional and bifractional Ornstein–Uhlenbeck processes. Finally, we
discuss the maximum likelihood and the least squares estimators.

2010 Mathematics Subject Classiﬁcation: 60G15, 62M09, 62F12.

Keywords: Gaussian processes, Langevin equation, Ornstein–Uhlenbeck processes,
parameter estimation.

1

Introduction

We consider statistical parameter estimation for the unknown parameter
θ > 0 in the (generalized) Langevin equation

dU θ,ξ

t = −θU θ,ξ

t dt + dGt,

t ≥ 0.

(1.1)

Here the noise G is Gaussian, centered, and has stationary increments. The
initial condition U θ,ξ
0 = ξ can be any centered Gaussian random variable.
We consider the so-called Alternative Estimator (AE) and show its strong
consistency and asymptotic normality, and provide Berry–Esseen bound for

∗Department of Mathematics and Statistics, University of Vaasa, P.O.Box 700, FIN-

65101 Vaasa, Finland, tommi.sottinen@iki.fi.

T. Sottinen was partially funded by the Finnish Cultural Foundation (National Foun-

dations’ Professor Pool).

†Department of Mathematics and System Analysis, Aalto University School of Science,

Helsinki P.O. Box 11100, FIN-00076 Aalto, Finland, lauri.viitasaari@aalto.fi

L.Viitasaari was partially funded by the Emil Aaltonen Foundation.

1

the normal approximation. The AE was named thus by Hu and Nualart [15].
A more apt name for the estimator could be the Ergodic Estimator, as it
uses the ergodicity of the solution directly. We kept the name AE, though.
The Langevin equation is named thus by the pioneering work of Langevin
[22]. Sometimes the solutions to the Langevin equation are called Ornstein–
Uhlenbeck processes, due to the pioneering work of Ornstein and Uhlen-
beck [36]. In these works the noise was the Brownian motion, and in this
case the equation has been studied extensively since; see, e.g., Liptser and
Shiryaev [23] and the references therein. Recently, the Langevin equation
with fractional Brownian noise, i.e., the fractional Ornstein–Uhlenbeck pro-
cesses, have been studied extensively in, e.g., [3, 10, 11, 19, 20, 29, 30, 34, 35],
just to mention a few very recent ones.

The rest of the paper is organized as follows: In Section 2 we consider
the Langevin equation is a general setting and provide some general results.
Section 3 is the main section of the paper. There we introduce the AE and
provide assumptions ensuring its strong consistency and asymptotic normal-
ity, or the central limit theorem. We also provide Berry–Esseen bounds for
the central limit theorem, and consider the estimation based on discrete ob-
servations. In Section 4 we provide examples. We show how some recent
results concerning the fractional Ornstein–Uhlenbeck processes follow in a
straightforward manner from our results, and extend the previous results.
We also study the bifractional Ornstein–Uhlenbeck processes of the second
kind. In Section 5 we discuss Least Squares Estimators (LSE) and Maximum
Likelihood Estimators (MLE). We argue that the AE is, under the ergodic
hypothesis, the most general estimator one could hope for. Moreover, we
argue that the LSE is not appropriate in many cases. For the MLE, we point
out how it could be used in the general Gaussian setting. In Section 6 we
draw some conclusions. Finally, the proofs of all the lemmas of the paper
are given in Appendix A.

2 Preliminaries

2.1 General Setting

Let us ﬁrst consider the Langevin equation (1.1) in a general setting, where
G is simply a stochastic process, and the initial condition ξ is any random
variable. The solution of (1.1) is

U θ,ξ

t = e−θtξ +Z t

0

e−θ(t−s) dGs.

(2.1)

Indeed, nothing is needed here, except the ﬁniteness of the noise: (2.1) is the
unique solution to (1.1) in the pathwise sense, and the stochastic integral in

2

(2.1) can be deﬁned pathwise by using the integration by parts as

Z t

0

e−θ(t−s) dGs = Gt − θZ t

0

e−θ(t−s)Gs ds.

Any two solutions U θ,ξ and U θ,ζ with the same noise are connected by the
relation

U θ,ζ
t = U θ,ξ

t + e−θt(cid:0)ζ − ξ(cid:1).

Since our estimation is be based on the solution that starts from zero, we
introduce the notation X θ = U θ,0.

For the existence of the stationary solution, the noise G must have sta-
tionary increments. Then, by extending G to the negative half-line with an
independent copy running backwards in time, the stationary solution is

U θ

t =Z t

−∞

e−θ(t−s) dGs,

t ≥ 0.

(2.2)

In other words, the stationary solution is U θ = U θ,ξstat, with

ξstat =Z 0

−∞

e−θt dGt.

In particular, the stationary solution exists if and only if the integral above
converges (almost surely), and in this case

X θ

t = U θ

t − e−θtU θ
0 .

(2.3)

Remark 2.1. By [37, Theorem 3.1] all stationary processes are the sta-
tionary solutions (2.2) of (1.1) with suitable stationary-increment noise G
and parameter θ. Also, by Barndorﬀ and Basse-O’Connor [4, Theorem 2.1]
the stationary solution of (1.1) exists for all integrable stationary-increment
noises.

2.2 Second Order Stationary-Increment Setting

Assume that the noise G is centered square-integrable process with station-
ary increments.

Remark 2.2 (Some notation). By v we denote variance of G, by rθ the
autocovariance of U θ, and by γθ the covariance of X θ. By Φ and ¯Φ we de-
note the cumulative and complementary cumulative distribution functions of
the N (0, 1)-distributed variable, respectively; N (0, 1) denotes the standard
normal distribution. By C we will denote a universal constant depending
only on v; Cθ and Cθ,K, and so on, are universal constants depending ad-
ditionally on θ, and θ and K, and so on.
In proofs, the constants may

3

change from line to line and sometimes the dependence on the parameters
are suppressed. We use the asymptotic notation f (T ) ∼ g(T ) for

lim
T →∞

f (T )
g(T )

= 1.

The existence of the stationary covariance rθ, given by Proposition 2.1,

is ensured by the following elementary lemma.
Lemma 2.1. Let v : R → R be a variance function of a process having
stationary increments. Then, for all t > 0,
v(t) ≤ C t2.
eθsg(t, s) ds − θ2e−θtZ t

rθ(t) = θZ 0

−∞Z 0

eθ(s+u)g(s, u) dsdu,

Proposition 2.1.

−∞

−∞

where

In particular,

θ

1

g(t, s) =

rθ(0) =

2hv(t) + v(s) − v(t − s)i.
2Z ∞
θeθsGtGs ds −Z t
−∞Z 0

e−θtv(t) dt.

−∞

0

θ2e−θ(t−s−u)GsGu dsdu(cid:21) .

(2.4)

Proof. By integrating by parts, we obtain

rθ(t) = E(cid:20)Z 0

−∞

The claim follows from this by the Fubini’s theorem, if the integrals above
converge. To this end, it is necessary and suﬃcient that rθ(0) is ﬁnite. Now,

eθteθshv(t) + v(s) − v(t − s)i dtds

θ2

2 Z 0

−∞

eθt(cid:20)Z −t

−∞

eθ(t+s)v(s) ds(cid:21) dt.

For the latter term we have

rθ(0) =

−∞

−∞

−∞

θ2

2 Z 0
−∞Z 0
= θZ 0
eθtv(t) dt −
eθ(t+s) ds(cid:21) dt
eθt(cid:20)Z −t
v(s)eθs"Z min(−s,0)
2 Z ∞
v(s)eθs(cid:20)Z 0
2 (cid:20)Z 0
4(cid:20)Z 0
v(s)eθs ds +Z ∞
2Z ∞

e−θsv(s) ds.

θ2

−∞

−∞

−∞

−∞

−∞

θ

θ

0

0

θ2

2 Z 0

−∞
θ2

=

=

=

=

e2θt dt# ds
e2θt dt(cid:21) ds +Z ∞
v(s)eθse−2θs ds(cid:21)

0

4

v(s)eθs(cid:20)Z −t

−∞

e2θt dt(cid:21) ds(cid:21)

Consequently, we have shown (2.4). Since, by Lemma 2.1, v(t) ≤ Ct2, the
ﬁniteness of rθ follows from the representation above.

Proposition 2.2.

γθ(t, s) = rθ(t − s) + e−θ(t+s)rθ(0) − e−θtrθ(s) − e−θsrθ(t).

In particular,

kθ(t, s) =(cid:12)(cid:12)γθ(t, s) − rθ(t − s)(cid:12)(cid:12) ≤ Cθe−θ min(t,s).

Proof. The formula for γθ is immediate from (2.3). As for the estimate,
note that |rθ(t)| ≤ rθ(0) by the Cauchy–Schwarz inequality. Consequently,
assuming s ≤ t,

kθ(t, s) ≤ e−θ(t+s)rθ(0) + e−θtrθ(0) + e−θsrθ(0)

= rθ(0)he−θt + e−θ(t−s) + 1i e−θs,

from which the estimate follows.

2.3 Gaussian Setting

Assume that the stationary-increment noise G in the Langevin equation
(1.1) is centered, continuous and Gaussian. Then (and only then) the con-
tinuous stationary Gaussian solution exists and can be characterized by its
autocovariance function rθ given by Proposition 2.1.

Remark 2.3 (Continuity). In the Gaussian realm the assumption that G is
continuous is essential. Indeed, if G were discontinuous at any point, then
U θ would be discontinuous at every point, and also unbounded on every
interval by the Belyaev’s alternative [5]. Parameter estimation for such a
U θ would be a fools errand, indeed.

Remark 2.4 (Gaussian assumption). The assumption of Gaussianity is
not needed in construction of the AE in Deﬁnition 3.1. Also, the strong
consistency result of Theorem 3.1 does not rely on Gaussianity. However,
Assumption 3.2 expresses ergodicity in terms of the autocovariance func-
tion rθ and this is essentially a Gaussian characterization. Theorem 3.1
will remain true for any square-integrable continuous stationary-increment
centered noise once Assumption 3.2 is replaced by a suitable assumption
that ensures the ergodicity of the stationary solution. On the contrary, the
proof of Theorem 3.2 concerning the asymptotic normality of the AE relies
heavily on the assumption of Gaussianity, and cannot be generalized in any
straightforward manner to non-Gaussian noises.

5

3 Alternative Estimator

For the AE of Deﬁnition 3.1 below to be well-deﬁned we need the invertibility
of ψ(θ) = rθ(0), which is ensured by the following assumption:

Assumption 3.1 (Invertibility). v is strictly increasing.

Lemma 3.1 (Invertibility). Suppose Assumption 3.1 holds. Then ψ : R+ →
(0, ψ(0+)) is strictly decreasing inﬁnitely diﬀerentiable convex bijection.

Deﬁnition 3.1 (AE). The alternative estimator is

where

˜θT = ψ−1(cid:18) 1
T Z T
2Z ∞

ψ(θ) =

θ

0

0

(X θ

t )2 dt(cid:19) ,

e−θtv(t) dt

is the variance of the stationary solution.

Remark 3.1. The idea of the AE is to use the ergodicity of the stationary
solution directly. Therefore, it would have been more natural to base it on
the stationary solution U θ instead of the zero-initial solution X θ. However,
from the practical point of view, using the solution X θ makes more sense,
since it does not assume that the Ornstein–Uhlenbeck process has reached
its stationary state. Moreover, the use of the zero-initial solution instead of
the stationary solution makes no diﬀerence (except when bias is concerned;
see Remark 3.3). Indeed, by virtue of Proposition 3.1 below, we could have
used any solution U θ,ξ with any initial condition ξ.

Proposition 3.1. Suppose the stationary solution U θ is ergodic. Then, for
all initial distributions ξ

lim
T →∞

Proof. Let us write

1

T Z T

0

(U θ,ξ

t

)2 dt = ψ(θ) a.s.

1

T Z T

0

=

=

(U θ,ξ

t

)2 dt

0

1

T Z T
T Z T

1

0

(U θ

(U θ

0 ))2 dt

t + e−θt(ξ − U θ
2(ξ − U θ
0 )
t )2 dt +

T

e−θtU θ

t dt +

0 )2
(ξ − U θ

T

Z T

0

e−2θt dt.

Z T

0

6

By ergodicity, the ﬁrst term converges to ψ(θ) almost surely. Also, it is clear
that the third term converges to zero almost surely. As for the second term,
note that U θ is ergodic and centered, which implies that

1

T Z T

0

U θ
t dt → 0 a.s..

Consequently, the second term converges to zero almost surely.

3.1 Strong Consistency

The strong consistency of the AE will follow directly from the ergodicity. For
Gaussian processes, the necessary and suﬃcient conditions for ergodicity are
well known and date back to Grenander [13] and Maruyama [24]. We use
the following characterization for ergodicity:

Assumption 3.2 (Ergodicity). The autocovariance rθ satisﬁes

lim
T →∞

1

T Z T

0

|rθ(t)| dt = 0.

Remark 3.2 (Gaussian Ergodicity). In addition to Assumption 3.2, other
well-known equivalent characterizations for the ergodicity in the Gaussian
realm are

(i)

(ii) The spectral measure µθ deﬁned by the Bochner’s theorem

rθ(t)2 dt = 0.

0

1

lim
T →∞

T Z T
rθ(t) =Z ∞

e−iλt µθ(dλ)

−∞

has no atoms.

Theorem 3.1 (Strong Consistency). Suppose Assumption 3.2 and Assump-
tion 3.1 hold. Then

˜θT → θ

almost surely as T → ∞.
Proof. By Assumption 3.2, the stationary solution U θ is ergodic. Conse-
quently, by Proposition 3.1

lim
T →∞

1

T Z T

0

(X θ

t )2 dt = ψ(θ).

Since, by Lemma 3.1, ψ is a continuous bijection, the claim follows from the
continuous mapping theorem.

7

Remark 3.3 (Bias). Unbiasedness is a fragile property, as it is not preserved
in non-linear transformations. Thus, it is not surprising that the AE is
biased. Indeed, suppose we use the stationary solution U θ instead of X θ in
the AE. Let us call this Stationary Alternative Estimator (SAE), and denote
it by ¨θT . Then

E[ψ(¨θT )] =

1

T Z T

0

E[(U θ

t )2] dt =

1

T Z T

0

ψ(θ) dt = ψ(θ).

So, the SAE is unbiased for ψ(θ). However, ψ is strictly convex, with makes
ψ−1 strictly concave. Consequently, E[¨θT ] < θ. For the estimation based
on the zero-initial solution X θ, even ψ(˜θT ) is biased, but asymptotically
unbiased. Indeed, straightforward calculation shows that

E[ψ(˜θT )] = ψ(θ) +

1

T (cid:20)Z T

0

e−θtrθ(t) dt +

ψ(θ)

2θ h1 − e−2θTi(cid:21) .

In principle, since the distribution of ˜θT and the function ψ are known, it
is possible to construct an unbiased alternative estimator. However, the
formula would be very complicated and, moreover, it would depend on the
unknown parameter θ.

3.2 Asymptotic Normality

It turns out that the rate of convergence and the corresponding Berry–Esseen
bound for the AE are given by

2

wθ(T ) =

T 2Z T
0Z T
Rθ(T ) = R T
Tpwθ(T )

0 |rθ(t)| dt

0

rθ(t − s)2 dsdt,

.

This leads to the following assumption for the asymptotic normality:

Assumption 3.3 (Normality). Rθ(T ) → 0 as T → ∞.

Our main result, Theorem 3.2 below, shows that the AE satisﬁes asymp-
totic normality with asymptotic variance wθ(T )/ψ′(θ)2 and the Berry–Esseen
bound for the normal approximation is governed by Rθ(T ).

Theorem 3.2 (Asymptotic Normality with Berry–Esseen Bound). Suppose
Assumption 3.2 and Assumption 3.1 hold. Then for all K > 0 there exists
a constant Cθ,K such that

sup

P" |ψ′(θ)|pwθ(T )(cid:16)˜θT − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ Cθ,KRθ(T ).
|x|≤K(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

8

In particular, if Assumption 3.3 holds, then

|ψ′(θ)|pwθ(T )(cid:16)˜θT − θ(cid:17) d

→ N (0, 1).

The proof of Theorem 3.2 uses the fourth moment Berry–Esseen bound
due to Peccati and Taqqu [27, Theorem 11.4.3] that is stated below as Propo-
sition 3.2. The setting of Proposition 3.2 is as follows: Let W = (Wt)t∈R+
be the Brownian motion, and let PW be its distribution on L2(R+). The
qth Wiener chaos is the closed linear subspace of L2(Ω, FW , PW ) generated
by the random variables Hq(ξ), where Hq is the qth Hermite polynomial

Hq(x) =

(−1)q
q!

ex2/2 dq

dxqhe−x2/2i ,

0 f (t) dWt for some f ∈ L2(R+).

and ξ =R ∞
Proposition 3.2 (Fourth Moment Berry–Esseen Bound). Let F belong to
the qth Wiener chaos with some q ≥ 2. Suppose E[F 2] = 1. Then

sup

x∈R(cid:12)(cid:12)(cid:12)P[F ≤ x] − Φ(x)(cid:12)(cid:12)(cid:12) ≤ 2r q − 1

3q pE[F 4] − 3.

The following series of elementary lemmas deal with Gaussian processes
in general, not the Gaussian solutions to the Langevin equation in particular.
To emphasize this, we drop the parameter θ in the notation. In this gen-
eral setting, X = (Xt)t∈R+ is a centered Gaussian process with continuous
covariance function γ : R2

+ → R and

1

T Z T
0 hX 2

QT =

t − E[X 2

t ]i dt

Lemma 3.2. QT belongs to the 2nd Wiener chaos.

Lemma 3.3.

2

T 2Z[0,T ]2
E(cid:2)Q2
T(cid:3) =
T(cid:3) = 12" 1
T 2Z[0,T ]2
E(cid:2)Q4
T 4Z[0,T ]4

24

+

γ(t1, t2)2 dt1dt2

γ(t1, t2)2 dt1dt2#2

γ(t1, t2)γ(t2, t3)γ(t3, t4)γ(t4, t1) dt1dt2dt3dt4.

Lemma 3.4. All continuous covariance functions γ satisfy

Z[0,T ]4
≤ " sup

t∈[0,T ]Z T

0

γ(t1, t2)γ(t2, t3)γ(t3, t4)γ(t4, t1) dt1dt2dt3dt4

|γ(t, t1)| dt1#2Z[0,T ]2

γ(t1, t2)2 dt1dt2.

9

Lemma 3.5. There exists a constant C such that

sup

x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
T ] ≤ x − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P QTqE[Q2
T Z T

(X θ

1

0

this end, we decompose

≤ C

supt∈[0,T ]R T
qR T
0R T

0 |γ(t, s)| ds
0 γ(t, s)2 dtds

.

Let us then turn back to the special case of the Langevin equation. To

t )2 dt − ψ(θ) = Qθ

T + εθ(T ),

where

Qθ

T =

εθ(T ) =

1

T Z T
0 h(X θ
T Z T
0 hE[(X θ

t )2]i dt,
t )2 − E[(X θ
t )2] − ψ(θ)i dt.

1

T belongs to the 2nd Wiener chaos, and
Now, the quadratic functional Qθ
the idea is to show that Qθ
T converges to a Gaussian limit with asymptotic
variance wθ(T )/ψ′(θ)2 and the associated Berry–Esseen bound CθRθ(T ),
while the remainder εθ(T ) is negligible.

Lemma 3.6 (Asymptotic Variance).

Lemma 3.7 (Equivalence of Variance). In general,

E[(Qθ

T )2] ∼ wθ(T ) =

rθ(t)2(T − t) dt.

0 rθ(t)2 dt < ∞, we obtain the best possible asymptotic

In particular, if R ∞

rate

Cθ

,

T wθ(T )

(cid:12)(cid:12)(cid:12)(cid:12)

E[(Qθ

T )2]

wθ(T ) − 1(cid:12)(cid:12)(cid:12)(cid:12) ≤
T Z T
4R ∞

T )2] ∼

4

0

E[(Qθ

0 rθ(t)2 dt

.

T

Lemma 3.8 (Berry–Esseen Bound). There exists a constant Cθ such that

sup

Tpwθ(T ) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ CθRθ(T ).
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" Qθ

10

Proof of Theorem 3.2. Since ψ is strictly decreasing and continuous, we have

|ψ′(θ)|

P" |ψ′(θ)|pwθ(T )(cid:16)˜θT − θ(cid:17) ≤ x#
x + θ#
= P"˜θT ≤ pwθ(T )
= P"ψ(˜θT ) ≥ ψ pwθ(T )
x + θ!#
= P"ψ(˜θT ) − ψ(θ) ≥ ψ pwθ(T )
= P"Qθ

T ≥ ψ pwθ(T )

|ψ′(θ)|

|ψ′(θ)|

T + εθ

|ψ′(θ)|

x + θ! − ψ(θ)#

x + θ! − ψ(θ)#

Let us then introduce the short-hand notation

By using the calculation and the short-hand notation above, we split

.

ν =

T + εθ
T

T + εθ(T )

ψ(cid:18)√wθ(T )

|ψ′(θ)| x + θ(cid:19) − ψ(θ)
pwθ(T )
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" |ψ′(θ)|pwθ(T )(cid:16)˜θT − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
= (cid:12)(cid:12)(cid:12)(cid:12)P" Qθ
pwθ(T ) ≥ ν# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)
pwθ(T ) ≥ ν# − ¯Φ (ν)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
≤ (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" Qθ
A1 = (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pwθ(T ) ≥ ν# − ¯Φ (ν)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" Qθ
≤ (cid:12)(cid:12)(cid:12)(cid:12)P" Qθ
Tpwθ(T ) ≥ ν −
¯Φ ν −
pwθ(T )! − ¯Φ(cid:0)ν(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)
+(cid:12)(cid:12)(cid:12)(cid:12)

= A1,1 + A1,2.

= A1 + A2.

T + εθ(T )

εθ(T )

For the term A1, we split again

+(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
¯Φ (ν) − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

εθ(T )

pwθ(T )# − ¯Φ ν −

εθ(T )

pwθ(T )!(cid:12)(cid:12)(cid:12)(cid:12)

11

By the Berry–Esseen bound of Lemma 3.8, A1,1 ≤ CRθ(T ). Consider then
A1,2. Since | ¯Φ(x) − ¯Φ(y)| ≤ |x − y|, we have
εθ(T )
pwθ(T )

By the Cauchy–Schwarz inequality |rθ(t)| ≤ rθ(0) = ψ(θ). Consequently,

A1,2 ≤

.

εθ(T ) = ψ(θ)

≤ ψ(θ)
Cθ
T

≤

.

Therefore,

A1,2 ≤

=

e−θtrθ(t) dt

0

2

1

T Z T
T Z T
e2θt dt −
T Z T
0 he−2θt + e−θti dt

1

0

Cθ/T
0 rθ(t − s)2 dsdt
Cθ

q1/T 2R T
0 R T
qR T
0 R T
R T
qR T
0 R T

≤ Cθ

0 rθ(t − s)2 dsdt

0 |rθ(t)| dt
0 rθ(t − s)2 dsdt

,

where the last inequality follows from the fact that rθ(0) > 0 and we can
assume that T is greater than some absolute constant.

Finally, it remains to consider the term A2. For this, recall that ψ is
smooth. Therefore, by the mean value theorem, there exists some number
η ∈ [θ, θ +

√wθ(T )
|ψ′(θ)| x] such that

ν =

=

=

1

|ψ′(θ)|

pwθ(T ) "ψ pwθ(T )
ψ′(η)"pwθ(T )
pwθ(T )

|ψ′(θ)|

1

ψ′(η)
|ψ′(θ)|

x.

x + θ! − ψ(θ)#
x#

Furthermore, since ψ is decreasing, we have

ψ′(η)
|ψ′(θ)|

ψ′(η)
ψ′(θ)

.

= −

12

Consequently,

Suppose then that x ∈ [−K, K]. Then

K

≤

ψ′(θ)

ψ′(θ)

ψ′(η)
ψ′(θ)

x(cid:19) .
¯Φ(cid:0)ν(cid:1) = Φ(cid:18) ψ′(η)
A2 = (cid:12)(cid:12) ¯Φ(ν) − Φ(x)(cid:12)(cid:12)
= (cid:12)(cid:12)(cid:12)(cid:12)Φ(cid:18) ψ′(η)
x(cid:19) − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)
x − x(cid:12)(cid:12)(cid:12)(cid:12)
≤ (cid:12)(cid:12)(cid:12)(cid:12)
|ψ′(θ)|(cid:12)(cid:12)ψ′(η) − ψ′(θ)(cid:12)(cid:12) .
|ψ′(θ)||ψ′′(˜η)|pwθ(T )
≤ Cθ,Kpwθ(T ).
pwθ(T ) ≤ CθRθ(T ),
rθ(t − s)2 dsdt ≤ CθZ T

|ψ′(θ)|

A2 ≤

K

By using the mean value theorem again, we ﬁnd some ˜η ∈ [θ, η] such that

Therefore, it remains to show that

which translates into showing that

2

T Z T
0Z t

0

|rθ(t)| dt.

0

Since rθ(t)2 ≤ ψ(θ)|rθ(t)|, the inequality above follows by applying l’Hˆopital’s
rule to it. This ﬁnishes the proof of Theorem 3.2

We end this section with corollaries that makes Theorem 3.2 somewhat
easier to use in applications. Corollary 3.1 deals with the classical √T rate
of convergence and Corollary 3.2 deals with mixed models.

Corollary 3.1 (Classical Rate). Suppose Assumption 3.1 holds. Assume
R ∞
0 rθ(t)2 dt < ∞. Denote

Then for each K > 0 there exists a constant Cθ,K such that

0 rθ(t)2 dt
|ψ′(θ)|

.

σ2(θ) = 4R ∞
σ(θ)(cid:16)˜θT − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" √T
≤ Cθ,K 1
|rθ(t)| dt +sZ ∞
√T Z T

sup

T

0

13

rθ(t)2 dt +s 1
T Z T

0

rθ(t)2t dt .

σ(θ)

≤

0 rθ(t)2 dt

Proof. First note that Assumption 3.2 is implied by the assumption that
R ∞
0 rθ(t)2 dt < ∞. Then, let us split
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P"√T (˜θT − θ)
x2qR ∞
≤ (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P|ψ′(θ)|(˜θT − θ)
pT wθ(T )
pwθ(T )
x2qR ∞
pT wθ(T )  − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
+(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Φ
T wT (θ) ∼ 4Z T

x2qR ∞
pT wθ(T ) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

rθ(t)2 dt ∼ 4Z ∞

 − Φ

0 rθ(t)2 dt

0 rθ(t)2 dt

= A1 + A2.

0

0

rθ(t)2 dt,

Now

i.e., T wT (θ) is asymptotically a positive constant. Consequently, we can
take the supremum over x on a compact interval, and Theorem 3.2 implies
that the term A1 is dominated by

Cθ,KRθ(T ) ≤ Cθ,K R T
qTR T

0 |rθ(t)| dt
0 rθ(t)2 dt ≤ Cθ,K

1

√T Z T

0

For the second term, we use the estimate

sup
x∈R |Φ(ρx) − Φ(x)| ≤ |ρ − 1|.

Setting

ρ =

0 rθ(t)2 dt

2qR ∞
pT wθ(T )

= qR ∞
q 1
T R T
0R t

0 rθ(t)2 dt

0 rθ(s)2 dsdt

|rθ(t)| dt.

,

14

we obtain for the term A2 the upper bound

0

1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

0 rθ(s)2 dsdt

0 rθ(s)2 dsdt

rθ(t)2 dt −

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
0 rθ(t)2 dt −q 1
qR ∞
T R T
0R t
q 1
0R t
T R T
≤ Cθs(cid:12)(cid:12)(cid:12)(cid:12)Z ∞
rθ(s)2 dsdt(cid:12)(cid:12)(cid:12)(cid:12)
T Z T
0Z t
= Cθs(cid:12)(cid:12)(cid:12)(cid:12)Z ∞
rθ(t)2(T − t) dt(cid:12)(cid:12)(cid:12)(cid:12)
T Z T
= Cθs(cid:12)(cid:12)(cid:12)(cid:12)Z ∞
rθ(t)2t dt(cid:12)(cid:12)(cid:12)(cid:12)
T Z T
≤ CθsZ ∞
rθ(t)2t dt ,
rθ(t)2 dt +s 1
T Z T
√b| ≤p|a − b| and √a + b ≤ √a + √b.

rθ(t)2 dt −

rθ(t)2 dt +

1

0

0

1

0

0

T

T

0

since |√a −

Corollary 3.2 (Mixed Models). Let Gi, i = 1, . . . , n, be independent con-
tinuous stationary-increment Gaussian processes with zero mean each sat-
isfying Assumption 3.2 and Assumption 3.1. Let rθ,i be the autocovariance
of the stationary solution corresponding the noise Gi. Assume that rθ,i ≥ 0
for all i. Then, for the noise G =Pn
i=1 Gi, there exists, for any K > 0, a
constant Cθ,K such that

sup

x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

P" |ψ′(θ)|pwθ(T )(cid:16)˜θT − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

.

≤ Cθ,K max

i=1,...,n

0 rθ,i(t) dt
0 rθ,i(t − s)2 dsdt

R T
qR T
0R T

Proof. Since the Gi’s are independent, the autocovariance for the mixed
i=1 rθ,i. Consequently, Assumption 3.2 and

model with noise G is rθ = Pn

Assumption 3.1 hold. It remains to show that

i=1 rθ,i(t) dt

R T
0 Pn
qR T
i=1 rθ,i(t − s))2 dsdt ≤ max
0R T
0 (Pn

i=1,...,n

nR T
qR T
0R T

0 rθ,i(t) dt
0 rθ,i(t − s)2 dsdt

The case for the nominator is clear. For the denominator, we use the fact
that the rθ,i’s are non-negative. Indeed, then

  nXi=1

rθ,i(t − s)!2

15

≥ rθ,i(t − s)2

for any i, as the cross-terms rθ,i(t − s)rθ,j(t − s) are positive.
Remark 3.4. It seems challenging to obtain a Berry–Esseen type bound
for supx∈R instead of supx∈[−K,K] in Theorem 3.2 and its corollaries. Indeed,
the same problem was present in Hu and Song [16], where the Berry–Esseen
bound was provided in the case of fractional Ornstein–Uhlenbeck process of
the ﬁrst kind. The reason for this is that by using the second order Taylor
expansion we obtain that the essential factor we are estimating is

where η is a number between θ and θ + x/wθ(T ). Now, since ψ′′ is not
bounded, and

ψ′′(η)
wθ(T )

x2# − Φ(x),

P" Qθ
Tpwθ(T ) ≤ x + C
Tpwθ(T ) ≤ x# ≈ Φ(x),
P" Qθ
x2#
P" Qθ
Tpwθ(T ) ≤ x + C

ψ′′(η)
wθ(T )

the probability

increases much faster than Φ(x) due to the term involving x2.

3.3 Discrete Observations

In practice continuous observations are rarely available. Therefore, it is
important to consider the case of discrete observations. To control the er-
ror introduced by the unobserved time-points, we assume that the driving
noise G is H¨older continuous with some index H ∈ (0, 1), i.e., G is H¨older
continuous with parameter γ for all γ < H. The general idea is, that the
smaller the H the more care must be taken in choosing the time-mesh of
the observations. This gives rise to the condition (3.1) in Theorem 3.3.

Note that from the form of the Langevin equation it is immediate that
any solution is H¨older continuous with index H if and only if the driving
noise is H¨older continuous with the same index H. Due to [2, Corollary 1],
the following assumption is not only suﬃcient, but also necessary, for the
H¨older continuity with index H:

Assumption 3.4 (H¨older continuity). Let H ∈ (0, 1). For all ε > 0 there
exists a constant Cε such that

v(t) ≤ Cε t2H−ε.

16

For notational simplicity, we assume equidistant observation times tk =
k∆N , k = 0, . . . , N . Denote TN = N ∆N and assume that ∆N → 0 with
TN → ∞. The AE based on the discrete observations is

˜θN = ψ−1  1

TN

k∆N )2∆N! .

(X θ

NXk=1

Theorem 3.3 (Discrete Observations). Suppose Assumption 3.2, Assump-
tion 3.1 and Assumption 3.4 hold. Assume further that

where

for some δ > 0. Then,

N ∆β

N → 0,

β = β(H) =

2H + 1
2
H + 1

2 − δ

˜θN → θ a.s.

Moreover, if Assumption 3.3 holds, then

(3.1)

Proof. Following the proof of [3, Theorem 3.2], it is enough to show that

t )2 dt! → 0

(X θ

a.s.

(3.2)

→ N (0, 1) .

|ψ′(θ)|

pwθ(TN )(cid:16)˜θN − θ(cid:17) d
TN Z TN
NXk=1
|X θ
t − X θ
s|
|t − s|H−ε

k∆N )2∆N −

t,s∈[tk−1,tk]

Yk =

(X θ

sup

1

0

1

pwθ(TN )  1

TN

Let

be the (H−ε)-H¨older constant of the process X θ on the subinterval [tk−1, tk].
Similarly, let (with slight abuse of notation) YN be the (H − ε)-H¨older con-
stant of the process X θ on the entire interval [0, TN ] Then, by the identity
a2 − b2 = (a + b)(a − b), the H¨older continuity of X θ, and the triangle

17

inequality,

1

1

2

≤

≤

1
TN

pwθ(TN )(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
NXk=1
TNpwθ(TN )
TNpwθ(TN )
TNpwθ(TN )
TNpwθ(TN )
NXk=1

C∆H−ε+1

≤

=

2

N

Note that

(X θ

0

1

(X θ

tk )2∆N −

TN Z TN
tk )2 − (X θ

t )2 dt(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
NXk=1Z tk
tk−1(cid:12)(cid:12)(X θ
t )2(cid:12)(cid:12) dt
t(cid:12)(cid:12)Z tk
NXk=1
t∈[tk−1,tk](cid:12)(cid:12)X θ
t(cid:12)(cid:12) dt
tk−1(cid:12)(cid:12)X θ
t(cid:12)(cid:12) YkZ tk
NXk=1
t∈[tk−1,tk](cid:12)(cid:12)X θ
tk−1(cid:12)(cid:12)t − tk−1(cid:12)(cid:12)H−ε dt
NXk=1
t∈[tk−1,tk](cid:12)(cid:12)X θ
t(cid:12)(cid:12) Yk.

tk − X θ

sup

sup

sup

YN ,

N

sup

t | ≤ T H−ε

t∈[tk−1,tk]|X θ
NXk=1
k ≤ N Y 2
Y 2
N ,
wθ(T ) ≥ CT −1,

where the last estimate follows, e.g., from Lemma 3.7. Consequently, it
remains to show that

N H−ε+ 1

2 ∆

2H−2ε+ 1
2
N

Y 2
N → 0 a.s.

(3.3)

By [2, Theorem 1 and Lemma 2] (see also [3, Remark 2.3]) we have for all
p ≥ 1 a constant C = Cθ,H,ε,p such that

From this estimate and from the Markov’s inequality it follows that for all
y > 0 and p ≥ 1,

Now, by choosing p large enough, we obtain

N

N .

N i ≤ CT 2εp

EhY 2p
P(cid:20) Y 2
N ε > y(cid:21) ≤
yp(cid:0)∆2ε
N N ε(cid:1)p
P(cid:20) Y 2
N ε > y(cid:21) < ∞

∞XN =1

C

N

.

18

if

∆2ε
N N ε ≤ N −α

for some α > 0. By (3.1), we may choose α = 2ε/β − ε. Indeed, since
β < 2, it follows that α > 0. Consequently, by the Borel–Cantelli lemma
N −εY 2
N → 0 almost surely. By applying this to (3.3) it remains to show that

N H+ 1

2 ∆

2H−2ε+ 1
2
N

→ 0.

But this follows from (3.1) by choosing ε < min{H + 1/4, δ(H + 1/2)/2}.
The details are left to the reader.

Remark 3.5. The Berry–Esseen bound for Theorem 3.3 can be obtained
as in the proof above by analyzing the speed of convergence in (3.2). We
leave the details for the reader.

4 Examples

4.1 Fractional Ornstein–Uhlenbeck Process of the First Kind

The fractional Brownian motion BH with Hurst index H ∈ (0, 1) is the
stationary-increment Gaussian process with variance function vH(t) = t2H.
Actually, it is the (upto a multiplicative constant) unique stationary-increment
Gaussian process that is H-self-similar meaning that

BH d

= a−HBH
a ·

for all a > 0. For the fractional Brownian motion the Hurst index H is
both the index of self-similarity and the H¨older index. We refer to Biagini
et al. [6] and Mishura [25] for more information on the fractional Brownian
motion. The fractional Ornstein–Uhlenbeck process (of the ﬁrst kind) is the
stationary solution to the Langevin equation

dU H,θ

t = −θU H,θ

t

dt + dBH
t ,

t ≥ 0.

(4.1)

The fractional Ornstein–Uhlenbeck processes (of diﬀerent kinds) and re-
lated parameter estimations have been studied extensively recently, see, e.g.,
[3, 8, 15, 16, 17, 18, 31]. By Cheridito et al. [8, Theorem 2.3] the autocovari-
ance rH,θ of the stationary solution satisﬁes, for H 6= 1/2, the asymptotic
expansion

θ2
as t → ∞. Also, by Hu and Nualart [15],

rH,θ(t) ∼

H(2H − 1)

t2H−2

(4.2)

ψH (θ) =

HΓ(2H)
θ2H ,

19

where Γ is the Gamma function. Consequently, Assumption 3.2 and Assump-
tion 3.1 are satisﬁed for all H, and Assumption 3.3 is satisﬁed for H ≤ 3/4.
Also, Assumption 3.4, required for discrete observations, is satisﬁed for all
H. Finally, we observe that Corollary 3.1 is applicable for H ∈ (0, 3/4), and
by using the self-similarity of the fractional Brownian motion it is clear that

where we have denoted

rH,θ(t)2 dt = θ−2Hσ2
H,

0

Z ∞
H =Z ∞

σ2

0

rH,1(t)2 dt.

(4.3)

Let ˜θH
T be the AE associated with the equation (4.1). Proposition 4.1 below
extends the result of Hu and Nualart [15, Theorem 4.1] both by extending
the range of H and by providing the Berry–Esseen bounds.

Proposition 4.1 (Fractional Ornstein–Uhlenbeck Process of the First Kind).
Let K > 0 arbitrary. Let σH be given by (4.3).

(i) Let H ∈ (0, 1/2]. Then

(ii) Let H ∈ (1/2, 3/4). Then

sup

sup

θσ2

P"s T

P"s T

x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P"s T
x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

T − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤
H(cid:16)˜θH
T − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤
H(cid:16)˜θH
T − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤

θσ2 log T (cid:16)˜θ3/4

θσ2

sup

where σ is an absolute constant.

CH,θ,K√T

.

CH,θ,K
√T 3−4H

.

C3/4,θ,K√log T

,

(iii) Let H = 3/4. Then

Proof. Consider ﬁrst the case H ∈ (0, 1/2). By Corollary 3.1, it is enough
to show that

1

√T Z T

0

|rH,θ(t)| dt +sZ ∞

T

rH,θ(t)2 dt +s 1
T Z T

0

rH,θ(t)2t dt ≤

CH,θ√T

.

20

Here the ﬁrst term is the dominating one. Indeed, by (4.2),

1

√T Z ∞

0

|rH,θ(t)| dt ∼

≤

CH,θZ ∞
1
√T
Cθ,H√T

1

,

t2H−2 dt

T

sZ ∞
s 1
T Z T

0

T

rH,θ(t)2 dt ∼ CH,θsZ ∞
= CH,θ√T 4H−3,
rH,θ(t)2t dt ∼ CH,θs 1
T Z T
= CH,θ√T 4H−3

1

t4H−4 dt

t4H−3 dt

The case H = 1/2 is classical and well-known, and stated here only for

the sake of completeness.

The case H ∈ (1/2, 3/4) can be analyzed exactly the same way as the
case H ∈ (0, 1/2), except now it is the second and third terms that dominate.
Consider then the case H = 3/4. Now Corollary 3.1 is not applicable.
Consequently, we have to use Theorem 3.2 directly. Let us ﬁrst calculate the
asymptotic rate. By applying l’Hˆopital’s rule twice and then the asymptotic
expansion (4.2), we obtain

w3/4,θ(T ) =

∼

∼

=

Consequently,

2

T 2Z T
0Z T
r3/4,θ(t − s)2 dsdt
log T Z T
1
r3/4,θ(t)2 dt

2 log T

T

0

2(3/8)2

log T

0
1/T
1/T

θ4

T

2(3/8)2

log T

θ4

T

,

by setting σ2 appropriately. For the Berry–Esseen upper bound, we estimate

3

4 Γ( 3
2 ) 3
√2 3

|ψ′
3/4(θ)|
qw3/4,θ(T ) ∼
R T
Tqw3/4,θ(T ) ≤ CθR T

0 |r3/4,θ(t)| dt

2 θ−5/2

8 θ−2 s T

log T

=s T

θσ2 log T

,

0 t−1/2 dt
√T√log T ≤ Cθ

√T

√T√log T

The claim follows.

21

Remark 4.1. In the case H > 3/4 our method does not provide asymptotic
normality. Indeed, due to the results in Breton and Nourdin [7] it is expected
that asymptotic normality cannot hold in this case.

4.2 Noises Arising from Self-Similar Processes

The examples in the next two subsections deal with self-similar processes.
The motivation comes from the result of Doob [9] stating that the classical
Ornstein–Uhlenbeck process can be viewed as the inverse Lamperti trans-
form of the Brownian motion that is 1/2-self-similar. Therefore, let us start
with an H-self-similar Gaussian process Y H. (For a representation of such
processes in terms of the Brownian motion see Yazigi [38]). The inverse
Lamperti transform with self-similarity parameters H and scale parameter
θ is

(L −1

H,θY H )t = e−θtY H

a(t),

where

a(t) = aH,θ(t) =

θ

H t.

e

H
θ

If Y H is H-self-similar, then L −1
H,θY H is stationary, and vice versa. Further-
more, and all stationary solutions U θ = U H,θ of the Langevin equation are
inverse Lamperti transforms of some H-self-similar Y H , see [21, 37]. There-
fore we have, on the one hand,

for some H-self-similar Y H , and, on the other hand,

U H,θ
t = e−θtY H
a(t)

U H,θ

t =Z t

−∞

e−θ(t−s) dGH,θ

s

for some stationary-increment noise GH,θ arising from the H-self-similar
process Y H. Actually, we have

GH,θ

t =Z t

0

e−θs dY H

a(t).

Moreover, the family {GH,θ ; θ > 0} satisﬁes the scaling property

θHGH,θ
· /θ

d= GH,

where we have denoted GH = GH,1. This motivates the study of the follow-
ing Langevin equation where the noise arises from the H-self-similar process
Y H that depends on θ, but with a noise GH that is independent of θ:

dU H,θ

t = −θU H,θ

t dt + dGH
t .

(4.4)

The solutions of these Langevin equations are called Ornstein–Uhlenbeck
processes of the second kind.

22

4.3 Fractional Ornstein–Uhlenbeck Process of the Second

Kind

The fractional Ornstein–Uhlenbeck process of the second kind arises from
(4.4) by setting GH = BH, the fractional Brownian motion. This process has
been studied e.g. in [1, 3, 17]. By Kaarakka and Salminen [17, Proposition
3.11] the autocovariance rH,θ of the fractional Ornstein–Uhlenbeck process of
the second kind has exponential decay. Consequently, Corollary 3.1 implies
the following:

Proposition 4.2. For the fractional Ornstein–Uhlenbeck processes of the
second ﬁnd

where

sup

x∈[−K,K](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

T − θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤

P" √T
σH,θ(θ)(cid:16)˜θH
σH,θ(θ) =s4Z ∞

rH,θ(t)2 dt.

0

CH,θ,K√T

,

4.4 Bifractional Ornstein–Uhlenbeck Process of the Second

Kind

The bifractional Brownian motion BH,K, introduced by Houdr´e and Villa
[14], with parameters H ∈ (0, 1) and K ∈ (0, 1] is the Gaussian process with
covariance

EhBH,K

t BH,K

t

i =

1

2K (cid:2)(t2H + s2H)K − |t − s|2HK(cid:3) .

The bifractional Brownian motion is a generalization of the fractional Brow-
nian motion, but it does not have stationary increments, except in the frac-
tional case K = 1. Consequently, there does not seem to be a natural
way to deﬁne the bifractional Ornstein–Uhlenbeck process of the ﬁrst kind
that would have a stationary version. The bifractional Brownian motion is,
however, HK-self-similar, see Russo and Tudor [28]. Consequently, we can
deﬁne the bifractional Ornstein–Uhlenbeck process by setting Y HK = BH,K
in equation (4.4).

Lemma 4.1. The autocovariance rH,K,θ of the bifractional Ornstein–Uhlenbeck
process of the second kind has exponential decay.

Lemma 4.1 combined with Corollary 3.1 immediately yields:

Proposition 4.3. For the bifractional Ornstein–Uhlenbeck processes of the
second ﬁnd

P" √T
σH,K,θ(θ)(cid:16)˜θH,K,θ

T

sup

x∈[−L,L](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

− θ(cid:17) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤

23

CH,K,θ,L√T

,

where

σH,K,θ(θ) =s4Z ∞

0

rH,K,θ(t)2 dt.

5 Discussion on Other Estimators

It is a celebrated result by Gauss [12] that for multivariate Gaussian distri-
butions the Least Squares Estimator (LSE) and the Maximum Likelihood
Estimator (MLE) coincide, and this is a characterizing property of the Gaus-
sian distribution. Indeed, this is why Gaussian distributions are named thus.
In the inﬁnite-dimensional case of Gaussian processes, the situation is more
delicate, as the following discussion shows. The discussion is based on Hu
and Nualart [15] in the case of the LSE and on Kleptsyna and Le Breton
[18] in the case of the MLE. To make the discussion short, we do not present
explicit assumptions in terms of the variance v, although this would be
possible. Instead, we conﬁne ourselves in presenting the general ideas and
implicit assumptions.

5.1 Least Squares Estimator

In this subsection, δ denotes the Skorohod integral. We refer to Nualart [26]
for details on Skorohod integrals.

One the one hand, the LSE

ˆθT = −R T
R T

0 X θ
0 (X θ

t δX θ
t
t )2 dt

arises heuristically by minimizing

(5.1)

Z T

0

| ˙X θ

t + θX θ

t |2 dt.

On the other hand, by using the Langevin equation of the solution X θ, one
would hope that

Z T

0

X θ

t δX θ

This would lead to the LSE

Unfortunately, the Skorohod integral is not (bi)linear.
In particular, the
equation (5.2) does not hold. Indeed, this is obvious from the fact that Sko-
rohod integrals have zero mean. Consequently, the LSE’s deﬁned by (5.1)

X θ

t δGt.

(5.2)

.

(5.3)

0

t = −θZ T
bθT = θ − R T
R T

(X θ

t )2 dt +Z T

0

0 X θ
0 (X θ

t δGt
t )2 dt

24

and (5.3), respectively, are not the same. The LSE deﬁned by (5.3) has
been shown to be consistent for some fractional Ornstein–Uhlenbeck pro-
cesses, see [1, 15]. However, the LSE (5.3) depends on θ, the parameter we
want to estimate! Therefore, the LSE (5.3) does not seem to be particu-
larly convenient. Moreover, to show that the LSE (5.3) is consistent, one
t )2 dt converges to zero. This
suggest that it would be more natural to deﬁne the LSE by (5.1). However,
Proposition 5.1 below shows that the LSE (5.1) will fail under rather general
assumptions.

has to show that the term R T

t δGt/R T

0 (X θ

0 X θ

Proposition 5.1. Assume that U θ is ergodic, and that the Skorohod integral
T )2/T → 0 in L1(Ω) and
0 X θ
almost surely, then

t exists. Let ˆθT be deﬁned by (5.1). If (X θ

t δX θ

R T

ˆθT → 0 a.s.

Proof. By the Itˆo formula in [32],

Since U θ is ergodic, Proposition 3.1 implies that

0

X θ

Z T
T Z T

1

0

t δX θ

t =

1
2

(X θ

T )2 −

1
2

E[(X θ

T )2].

(X θ

t )2 dt → ψ(θ) > 0

a.s.

Consequently,

ˆθT =

1
2

and the claim follows.

T )2/T ]

(X θ

1

T )2/T − E[(X θ
T R T
t )2 dt

0 (X θ

→ 0 a.s,

5.2 Maximum Likelihood Estimator

In this subsection, the integrals are abstract Wiener integral as deﬁned in
e.g. [33], or, equivalently, Skorohod integrals as deﬁned e.g. in [32].

To construct the MLE, we assume the following Volterra representation
for the noise G: There exists a Gaussian martingale M with bracket hMi
and a kernel k ∈ L2

+, dhMi × dhMi) such that

loc(R2

Furthermore, we assume the following inverse Volterra representation:

0

Gt =Z t
Mt =Z t

0

k(t, s) dMs.

k∗(t, s) dGt.

25

(5.4)

(5.5)

Next, we deﬁne

M θ

t = Z t

0

Ξθ

t =

k∗(t, s)X θ

s ds,

k∗(t, s) dX θ
t ,

d

dhMitZ t

0

implicitly assuming their existence.

Proposition 5.2 (MLE). Assume representations (5.4)–(5.5) and assume
that Ξθ ∈ L2(Ω×[0, T ], dP×dhMi). Then the MLE based on the observations
X θ
t , t ∈ [0, T ], is

¯θT = − R T
R T

0 Ξθ
0 (Ξθ

t dM θ
t
t )2 dhMit

.

Moreover, if R T

consistent.

0 (Ξθ

t )2 dhMit → ∞ almost surely, then the MLE is strongly

Proof. By integrating the Langevin equation (1.1) against the kernel k∗ on
both sides, we obtain

M θ

t = −θZ t

0

k∗(t, s)X θ

s ds + Mt.

By plugging in Ξθ, this translates into

dM θ

t = −θΞθ

t dhMit + dMt.

Consequently, we can use the Girsanov theorem for Gaussian martingales,
which states that the log-likelihood ℓT (θ) = log dPθ
T /dPT can be written as

ℓT (θ) = −θZ T

0

Ξt dM θ

t −

θ2

2 Z T

0

(Ξθ

t )2 dhMit.

The MLE ¯θT follows from this by maximizing with respect to θ.

The strong consistency follows from the equation

¯θT − θ = − R T
R T

0 (Ξθ

0 Ξθ
t dMt
t )2 dhMit

by using the martingale convergence theorem.

26

6 Conclusions

We have considered the Langevin equation with general stationary-increment
continuous centered Gaussian noise. We have stated mild conditions on
the variance function of the noise ensuring strong consistency and asymp-
totic normality of the so-called alternative estimator of the mean-reversion
parameter. We have also provided Berry–Esseen bounds for the normal
approximation. We have shown that the alternative estimator works for
discrete observations provided that the noise is H¨older continuous and the
observation-mesh is dense enough with respect to the H¨older index of the
noise. We have also shown that our results work in examples rising from frac-
tional and bifractional Brownian noises, thus extending some recent results.
Finally, we discussed least squares estimators and maximum likelihood esti-
mators. We argue that the alternative estimator is, under the stationarity
assumption, the most general estimator, i.e., it works under the mildest
assumptions.

A Proofs of Lemmas

Proof of Lemma 2.1. Let t > 0 and let ⌊t⌋ be the greatest integer not ex-
ceeding t. Then

By the Minkowski’s inequality and stationary of the increments,

|Gt| ≤ |Gt − G⌊t⌋| +

|Gk − Gk−1|.

⌊t⌋Xk=1
t−⌊t⌋] + ⌊t⌋qE[G2

1].

qE[G2

t ] ≤qE[G2

The claim follows from this.

Proof of Lemma 3.1. By changing the variable in (2.4) we obtain

ψ(θ) =

1

2Z ∞

0

e−t v(cid:18) t

θ(cid:19) dt.

(A.1)

Since v is strictly increasing, this shows that ψ is also strictly decreasing.
Furthermore, ψ(θ) → 0 as θ → ∞ by the monotone convergence theorem.

By the Lebesgue’s dominated convergence theorem, the function

θ 7→Z ∞

0

e−θtv(t) dt

is smooth. Consequently, ψ is smooth.

27

Finally, let us show that ψ is convex. Let us ﬁrst assume that v is
diﬀerentiable. Then, by applying the Lebesgue’s dominated convergence to
the representation (A.1) together with the change-of-variable s = t/θ we
obtain

e−t t

θ2 v′(cid:18) t

θ(cid:19) dt

e−θs s v′(s) ds.

ψ′(θ) = −

= −

0

0

1

1

2Z ∞
2Z ∞
2Z ∞

1

0

Diﬀerentiating again we obtain, by using the Lebesgue’s dominated conver-
gence theorem,

ψ′′(θ) =

e−θs s2v′(s) ds ≥ 0.

Consequently, ψ is convex if v is diﬀerentiable. To conclude, the general
case follows by approximating the continuous increasing function v by dif-
ferentiable increasing functions vn, n ∈ N, from below.
Proof of Lemma 3.2. Let t ≥ 0 be ﬁxed. Then we can represent Xt =
depends on t a priori. To see how to represent the entire process X on
any compact interval with a single Brownian motion see [32, Theorem 3.1].)
Consequently Xt belongs to the 1st Wiener chaos for all t > 0. Then note
that

pγ(t, t)W1, where W is a Brownian motion. (Here the Brownian motion

X 2
t − E[X 2

t ] = 2H2(Xt).

Consequently, it belongs to the 2nd Wiener chaos. Finally, note that, because
γ is continuous, the integral

1

T Z T

0

2H2(Xt) dt

can be deﬁned as a limit in L2(Ω) in the 2nd Wiener chaos. The claim follows
from this.

Proof of Lemma 3.3. The claim follows exactly like in [37, Lemma 2.2] once
the sums are replaced by integrals.

Proof of Lemma 3.4. Let Γ be the operator associated with γ by

Γf (t) =Z[0,T ]

f (t1) γ(t, t1) dt1.

Since γ is a continuous covariance function, the operator Γ is trace-class.
Consequently, the kernel γ admits the Mercer’s expansion

γ(t1, t2) =

∞Xn=1

λnφn(t1)φn(t2)

28

with real eigenvalues λn and continuous orthonormal eigenfunctions φn. Let
δk,ℓ denote the Kronecker delta. Then, straightforward calculations with the
Mercer’s expansion by using the orthonormality of the φn’s yield

γ(t1, t2)γ(t2, t3)γ(t3, t4)γ(t4, t1) dt1dt2dt3dt4

λn1φn1(t1)φn1(t2)λn2φn2(t2)φn2(t3)

Z[0,T ]4

=

=

=

∞Xn1,n2,n3,n4=1Z[0,T ]4
∞Xn1,n2,n3,n4=1
∞Xn=1

λ4
n.

λn3φn3(t3)φn3(t4)λn4φn4(t4)φn4(t1) dt1dt2dt3dt4

λn1λn2λn3λn4δn1,n4δn1,n2δn2,n3δn3,n4

Similar straightforward calculations also yield

λn1λn2φn1(t1)φn2 (t1)φn1(t2)φn2(t2) dt1dt2

Z[0,T ]2

=

=

=

γ(t1, t2)2 dt1dt2

∞Xn1,n2=1Z[0,T ]2
∞Xn1,n2=1
∞Xn=1

λ2
n.

λn1λn2δn1,n2

Now, the operator Γ, being trace-class, admits maximal eigenvalue λ∗ =

maxn |λn|. Consequently, by using the elementary bound

the claim follows, if we can show that

λ2
n,

∞Xn=1

λ4
n ≤ (λ∗)2

∞Xn=1
t∈[0,T ]Z T

λ∗ ≤ max

|γ(t, s)| ds.

0

To show this, let φ∗ be the eigenfunction corresponding to the maximal

29

eigenvalue λ∗ and let f ∗ = φ∗/kφ∗k∞. Then
kΓk∞ ≥ kΓf ∗k∞

kφ∗k∞(cid:21)(cid:13)(cid:13)(cid:13)(cid:13)∞
= (cid:13)(cid:13)(cid:13)(cid:13)Γ(cid:20) φ∗
= (cid:13)(cid:13)(cid:13)(cid:13)
φ∗(cid:13)(cid:13)(cid:13)(cid:13)∞

kφ∗k∞

= λ∗

λ∗

Finally, note that

kΓk∞ =

kf k∞=1kΓfk∞
sup

=

sup

kf k∞=1

≤

sup

kf k∞=1

sup

t∈[0,T ](cid:12)(cid:12)(cid:12)(cid:12)Z T
t∈[0,T ]Z T

sup

0

0

f (t1)γ(t, t1) dt1(cid:12)(cid:12)(cid:12)(cid:12)

|f (t1)| |γ(t, t1)| dt1.

Now, the maximizing element in the sphere {f ; kfk∞ = 1} is simply the
constant function f ≡ 1, and the claim follows.

Proof of Lemma 3.5. Note that QT /qE[Q2

T ] belongs to the 2nd Wiener
chaos and has unit variance. Consequently, by the fourth-moment Proposi-
tion 3.2, it suﬃces to show that

Denote

T(cid:3)2 − 3 ≤ C(cid:16)supt∈[0,T ]R[0,T ] |γ(t, s)| ds(cid:17)2
E(cid:2)Q4
T(cid:3)
R[0,T ]2 γ(t, s)2 dsdt
E(cid:2)Q2
I2(T ) = Z[0,T ]2
I4(T ) = Z[0,T ]4

γ(t1, ts)2 dt1dt2,

.

γ(t1, t2)γ(t2, t3)γ(t3, t4)γ(t4, t1) dt1dt2dt3dt4.

Then, by Lemma 3.3,

E[Q4

T ] =

E[Q2

T ]2 =

12
T 4 I2(T )2 +
4
T 4 I2(T )2,

24
T 4 I4(T ),

and, by Lemma 3.4

I4(T ) ≤" sup

t∈[0,T ]Z T

0

|γ(t, s)| ds#2

I2(T ).

30

Consequently,

E(cid:2)Q4
T(cid:3)
T(cid:3)(cid:1)2 − 3 =
(cid:0)E(cid:2)Q2

12I2(T )2 + 24I4(T ) − 12I2(T )2

4I2(T )2

= 6

I4(T )
I2(T )2

≤ 6hsupt∈[0,T ]R T

0 |γ(t, s)| dsi2

I2(T )

.

The claim follows from this.

Proof of Lemma 3.6. By Lemma 3.3, Proposition 2.2, symmetry and esti-
mate |rθ(t)| ≤ rθ(0),

(cid:12)(cid:12)(cid:12)E[(Qθ

≤

0 |rθ(t − s)|kθ(t, s) dsdt +

4

T )2] − wθ(T )(cid:12)(cid:12)(cid:12)
T 2Z T
0Z t
T 2Z T
0Z t
T 2Z T
0 h1 − e−θti dt +

Cθ

Cθ

0

rθ(0)e−θs dsdt +

0

2

Cθ

T 2Z T
0Z t
T 2Z T
0Z t
T 2Z T
0 h1 − e−2θti dt

Cθ

0

e−2θs dsdt

≤

=

≤

Cθ
T

.

kθ(t, s)2 dsdt

This shows the estimate.

Proof of Lemma 3.7. The equivalence E[(Qθ
T )2] ∼ wθ(T ) follows from Lemma
3.6, if T wθ(T ) does not converge to zero. Now, by symmetry, change-of-
variables and the Fubini theorem

Z T
0Z T

0

rθ(t − s)2 dsdt = 2Z T
0Z T

t

rθ(s)2 dtds = 2Z T

0

rθ(t)2(T − t) dt.

Consequently, by assuming that T > 1,

Z T

0

rθ(t)2(T − t) dt ≥Z 1

0

rθ(t)2(T − t) dt ≥ C(T − 1)

This shows T wθ(T ) ≥ C. Also, we have shown the equality

wθ(T ) =

rθ(t)2(T − t) dt

4

T Z T

0

31

E[(Qθ

Consider then the best-rate caseR ∞
T R T
T )2] ∼ 4
0 rθ(t)2(T − t) dt, it is enough to show that

0 rθ(t)2 dt < ∞. By the equivalence

But this is immediate from the facts that the nominator converges to zero
and the denominator is bounded from below by C(T − 1).
Proof of Lemma 3.8. Let us ﬁrst split

lim

T →∞ R ∞
R T

T rθ(t)2 dt

0 r(t)2(T − t) dt

= 0.

x − Φ s wθ(T )

E[(Qθ

T )2]

sup

Qθ

T )2]

+ sup

E[(Qθ

≤ sup

Tpwθ(T ) ≤ x# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P" Qθ
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P
T )2] ≤s wθ(T )
TqE[(Qθ
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x!# − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P"Φ s wθ(T )
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
T )2] ≤ x − Φ (x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
P
TqE[(Qθ
x! − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Φ s wθ(T )

= A1 + A2.

≤ sup

E[(Qθ

E[(Qθ

+ sup

T )2]

T )2]

Qθ

x!(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

For the term A1, let us ﬁrst estimate

|γθ(t, s)| ds

0

0

Z T
= Z T
≤ Z T
≤ Z T
≤ Z T

0

0

0

|rθ(t − s)| ds +

(cid:12)(cid:12)(cid:12)rθ(t − s) + e−θ(t+s)rθ(0) − e−θtrθ(s) − e−θsrθ(t)(cid:12)(cid:12)(cid:12) ds
+ e−θtZ T
e−θt|rθ(0)|
|rθ(s)| ds + |rθ(t)|
|rθ(s)| ds +(cid:0)e−θt + 1(cid:1) |rθ(0)|
|rθ(t − s)| ds + e−θtZ T
|rθ(t − s)| ds +Z T

|rθ(s)| ds + C,

θ

θ

θ

0

0

0

32

Consequently,

t∈[0,T ]Z T

sup

0

|γθ(t, s)| ds ≤ 2 sup

|rθ(t − s)| ds + C

0

t∈[0,T ]Z T
t∈[0,T ]Z T −t

−t

= 2 sup

≤ 2Z T
= 4Z T

0

−T |rθ(u)| du + C

|rθ(u)| du + C.

|rθ(u)| du + C

Since we are interested in the case T → ∞, we can assume that T is bigger
than some absolute positive constant. Consequently, since rθ continuous
with rθ(0) > 0, it follows from the estimate above that

t∈[0,T ]Z T

sup

0

|γθ(t, s)| ds ≤ CZ T

0

|rθ(u)| du.

Therefore, by applying Lemma 3.5 and Lemma 3.7, it follows that A1 ≤
CθRθ(T ).

Let us then consider the term A2. Now, by the mean value theorem,

A2 = sup

≤

where

T )2]

E[(Qθ

1
√2π

x∈R(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
x! − Φ(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Φ s wθ(T )
T )2] − 1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
|x|(cid:17)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
s wθ(T, x)
x∈R(cid:16)e−1/2ηθ(T,x)2
ηθ(T, x) ∈"x, x +s wθ(T )
x# .

E[(Qθ

E[(Qθ

T )2]

sup

,

E[(Qθ

T )2] ∼ 1, it follows that

Sincer wθ(T )
T )2(cid:3) − 1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
A2 ≤(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
s wθ(T )
E(cid:2)(Qθ
T(cid:12)(cid:12)(cid:12)(cid:12)pwθ(T ) −qE[(Qθ

.

= (cid:12)(cid:12)(cid:12)pwθ(T, x) −qE(cid:2)(Qθ
T )2(cid:3)(cid:12)(cid:12)(cid:12)
qE(cid:2)(Qθ
T )2(cid:3)
T )2](cid:12)(cid:12)(cid:12)(cid:12) ≤ CθZ T

|rθ(t)| dt.

0

33

Consequently, by the asymptotic equivalence of wθ(T ) ∼ E[(Qθ
mains to show that

T )2], it re-

0

0

0

≤

(Actually, we show that the left hand side is bounded.) For this purpose,

we estimate, by using the inequality |√a −
a2 − b2 = (a + b)(a − b), that

√b| ≤p|a − b| and the identity
T(cid:12)(cid:12)(cid:12)(cid:12)pwθ(T ) −qE[(Qθ
T )2](cid:12)(cid:12)(cid:12)(cid:12)
= √2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
γθ(t, s)2 dsdt(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
sZ T
rθ(t − s)2 dsdt −sZ T
0Z T
0Z T
√2s(cid:12)(cid:12)(cid:12)(cid:12)Z T
[rθ(t − s)2 − γθ(t, s)2 ] dsdt(cid:12)(cid:12)(cid:12)(cid:12)
0Z T
= √2s(cid:12)(cid:12)(cid:12)(cid:12)Z T
0 (cid:0)rθ(t − s) + γθ(t, s)(cid:1)(cid:0)rθ(t − s) − γθ(t, s)(cid:1)dsdt(cid:12)(cid:12)(cid:12)(cid:12).
0Z T
T(cid:12)(cid:12)(cid:12)(cid:12)pwθ(T ) −qE[(Qθ
T )2](cid:12)(cid:12)(cid:12)(cid:12)
≤ Cθs(cid:12)(cid:12)(cid:12)(cid:12)Z T
0 (cid:0)rθ(t − s) + γθ(t, s)(cid:1)e−θ min(s,t) dsdt(cid:12)(cid:12)(cid:12)(cid:12).
0Z T

Now, |rθ(t − s)| ≤ rθ(0) and |γθ(t, s)| ≤ rθ(0) + 1, by Proposition 2.2. Con-
sequently, the integral above is bounded, and the proof is ﬁnished.

By applying Proposition 2.2 to the estimate above, we obtain

Proof of Lemma 4.1. Let

a(t) = aH,1(t) = Het/H .

Then

rH,K,θ(t) =

By the Taylor’s theorem

1

2K e−θth(cid:0)a(t)2H + 1(cid:1)K −(cid:0)a(t) − 1(cid:1)2HKi .

for some ξ(t) ∈ [a(t), a(t) + 1] and η(t) ∈ [a(t) − 1, a(t)]. Consequently,

(cid:0)a(t)2H + 1(cid:1)K = a(t)2HK + Kξ(t)K−1,
(cid:0)a(t) − 1(cid:1)2HK = a(t)2HK − 2HKη(t)2HK−1,
rH,K,θ(t) ∼ CH,K,θe−θt(cid:2)a(t)K−1 + a(t)2HK−1(cid:3)

∼ CH,K,θe−θt max{ 1

HK −1,1+ 1

H},

HK − 1

which shows the exponential decay.

34

References

[1] E. Azmoodeh and J. I. Morlanes, Drift parameter estimation for
fractional Ornstein-Uhlenbeck process of the second kind, Statistics, 49
(2015), pp. 1–18.

[2] E. Azmoodeh, T. Sottinen, L. Viitasaari, and A. Yazigi, Nec-
essary and suﬃcient conditions for H¨older continuity of Gaussian pro-
cesses, Statist. Probab. Lett., 94 (2014), pp. 230–235.

[3] E. Azmoodeh and L. Viitasaari, Parameter estimation based on dis-
crete observations of fractional Ornstein-Uhlenbeck process of the sec-
ond kind, Stat. Inference Stoch. Process., 18 (2015), pp. 205–227.

[4] O. E. Barndorff-Nielsen and A. Basse-O’Connor, Quasi

Ornstein-Uhlenbeck processes, Bernoulli, 17 (2011), pp. 916–941.

[5] Y. Belyaev, Local properties of the sample functions of stationary

Gaussian processes., Teor. Veroyatn. Primen., 5 (1960), pp. 128–131.

[6] F. Biagini, Y. Hu, B. Øksendal, and T. Zhang, Stochastic calculus
for fractional Brownian motion and applications, Probability and its
Applications (New York), Springer-Verlag London, Ltd., London, 2008.

[7] J.-C. Breton and I. Nourdin, Error bounds on the non-normal ap-
proximation of Hermite power variations of fractional Brownian motion,
Electron. Commun. Probab., 13 (2008), pp. 482–493.

[8] P. Cheridito, H. Kawaguchi, and M. Maejima, Fractional
Ornstein-Uhlenbeck processes, Electron. J. Probab., 8 (2003), pp. no.
3, 14 pp. (electronic).

[9] J. L. Doob, The Brownian movement and stochastic equations, Ann.

of Math. (2), 43 (1942), pp. 351–369.

[10] K. Es-Sebaiy and D. Ndiaye, On drift estimation for non-ergodic
fractional Ornstein-Uhlenbeck process with discrete observations, Afr.
Stat., 9 (2014), pp. 615–625.

[11] K. Es-Sebaiy and C. A. Tudor, Fractional Ornstein-Uhlenbeck
processes mixed with a gamma distribution, Fractals, 23 (2015),
pp. 1550032, 10.

[12] C. F. Gauss, Theoria motus corporum coelestium in sectionibus conicis
solem ambientium, Cambridge Library Collection, Cambridge Univer-
sity Press, Cambridge, 2011. Reprint of the 1809 original.

[13] U. Grenander, Stochastic processes and statistical inference, Ark.

Mat., 1 (1950), pp. 195–277.

35

[14] C. Houdr´e and J. Villa, An example of inﬁnite dimensional quasi-
helix, in Stochastic models (Mexico City, 2002), vol. 336 of Contemp.
Math., Amer. Math. Soc., Providence, RI, 2003, pp. 195–201.

[15] Y. Hu and D. Nualart, Parameter estimation for fractional
Ornstein-Uhlenbeck processes, Statist. Probab. Lett., 80 (2010),
pp. 1030–1038.

[16] Y. Hu and J. Song, Parameter estimation for fractional Ornstein-
Uhlenbeck processes with discrete observations,
in Malliavin calculus
and stochastic analysis, vol. 34 of Springer Proc. Math. Stat., Springer,
New York, 2013, pp. 427–442.

[17] T. Kaarakka and P. Salminen, On fractional Ornstein-Uhlenbeck

processes, Commun. Stoch. Anal., 5 (2011), pp. 121–133.

[18] M. L. Kleptsyna and A. Le Breton, Statistical analysis of the frac-
tional Ornstein-Uhlenbeck type process, Stat. Inference Stoch. Process.,
5 (2002), pp. 229–248.

[19] Y. Kozachenko, A. Melnikov, and Y. Mishura, On drift param-
eter estimation in models with fractional Brownian motion, Statistics,
49 (2015), pp. 35–62.

[20] K. Kubilius, Y. Mishura, K. Ralchenko, and O. Seleznjev,
Consistency of the drift parameter estimator for the discretized frac-
2 ), Elec-

tional Ornstein-Uhlenbeck process with Hurst index H ∈ (0, 1
tron. J. Stat., 9 (2015), pp. 1799–1825.

[21] J. Lamperti, Semi-stable stochastic processes, Trans. Amer. Math.

Soc., 104 (1962), pp. 62–78.

[22] P. Langevin, Sur la th´eorie du mouvement brownien, C. R. Acad. Sci.

Paris, 146 (1908), pp. 530–533.

[23] R. S. Liptser and A. N. Shiryaev, Statistics of random processes.
II, vol. 6 of Applications of Mathematics (New York), Springer-Verlag,
Berlin, expanded ed., 2001. Applications, Translated from the 1974
Russian original by A. B. Aries, Stochastic Modelling and Applied Prob-
ability.

[24] G. Maruyama, The harmonic analysis of stationary stochastic pro-

cesses, Mem. Fac. Sci. Ky¯usy¯u Univ. A., 4 (1949), pp. 45–106.

[25] Y. S. Mishura, Stochastic calculus for fractional Brownian motion and
related processes, vol. 1929 of Lecture Notes in Mathematics, Springer-
Verlag, Berlin, 2008.

36

[26] D. Nualart, The Malliavin calculus and related topics, Probability
and its Applications (New York), Springer-Verlag, Berlin, second ed.,
2006.

[27] G. Peccati and M. S. Taqqu, Wiener chaos: moments, cumulants
and diagrams, vol. 1 of Bocconi & Springer Series, Springer, Milan;
Bocconi University Press, Milan, 2011. A survey with computer imple-
mentation, Supplementary material available online.

[28] F. Russo and C. A. Tudor, On bifractional Brownian motion,

Stochastic Process. Appl., 116 (2006), pp. 830–856.

[29] G. Shen, X. Yin, and L. Yan, Least squares estimation for Ornstein–
Uhlenbeck processes driven by the weighted fractional Brownian motion,
Acta Math. Sci. Ser. B Engl. Ed., 36 (2016), pp. 394–408.

[30] L. Shen and Q. Xu, Asymptotic law of limit distribution for fractional
Ornstein-Uhlenbeck process, Adv. Diﬀerence Equ., (2014), pp. 2014:75,
7.

[31] T. Sottinen and C. A. Tudor, Parameter estimation for stochastic
equations with additive fractional Brownian sheet, Stat. Inference Stoch.
Process., 11 (2008), pp. 221–236.

[32] T. Sottinen and L. Viitasaari, Stochastic analysis of Gaussian
processes via Fredholm representation, submitted, arXiv: 1410.2230
(2014).

[33] T. Sottinen and A. Yazigi, Generalized Gaussian bridges, Stochastic

Process. Appl., 124 (2014), pp. 3084–3105.

[34] X. Sun and F. Guo, On integration by parts formula and characteri-
zation of fractional Ornstein–Uhlenbeck process, Statist. Probab. Lett.,
107 (2015), pp. 170–177.

[35] K. Tanaka, Maximum likelihood estimation for the non-ergodic frac-
tional Ornstein-Uhlenbeck process, Stat. Inference Stoch. Process., 18
(2015), pp. 315–332.

[36] G. E. Uhlenbeck and L. S. Ornstein, On the theory of the brownian

motion, Phys. Rev., 36 (1930), pp. 823–841.

[37] L. Viitasaari, Representation of stationary and stationary increment
processes via Langevin equation and self-similar processes, ArXiv e-
prints, (2014).

[38] A. Yazigi, Representation of self-similar Gaussian processes, Statist.

Probab. Lett., 99 (2015), pp. 94–100.

37

