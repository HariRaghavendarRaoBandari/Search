Local Partial Clique Covers for Index Coding

1

Abhishek Agarwal and Arya Mazumdar

Abstract

Index coding, or broadcasting with side information, is a network coding problem of most fundamental
importance. In this problem, given a directed graph, each vertex represents a user with a need of information,
and the neighborhood of each vertex represents the side information availability to that user. The aim is
to ﬁnd an encoding to minimum number of bits (optimal rate) that, when broadcasted, will be sufﬁcient
to the need of every user. Not only the optimal rate is intractable, but it is also very hard to characterize
with some other well-studied graph parameter or with a simpler formulation, such as a linear program.
Recently there have been a series of works that address this question and provide explicit schemes for
index coding as the optimal value of a linear program with rate given by well-studied properties such as
local chromatic number or partial clique-covering number. There has been a recent attempt to combine
these existing notions of local chromatic number and partial clique covering into a uniﬁed notion denoted
as the local partial clique cover (Arbabjolfaei and Kim, 2014).

We present a generalized novel upper-bound (encoding scheme) - in the form of the minimum
value of a linear program - for optimal index coding. Our bound also combines the notions of local
chromatic number and partial clique covering into a new deﬁnition of the local partial clique cover, which
outperforms both the previous bounds, as well as beats the previous attempt to combination.

Further, we look at the upper bound derived recently by Thapa et al., 2015, and extend their n-GIC
(Generalized Interlinked Cycle) construction to (k, n)-GIC graphs, which are a generalization of k-partial
cliques.

I. INTRODUCTION

Index coding is a multiuser communication problem in which the broadcaster reduces the total number
of transmissions by taking advantage of the fact that a user may have side information about other user’s
data. We consider the index coding problem formulation of [3]. Suppose, a set of users are assigned
bijectively to a set of vectors that they want to know. However, instead of knowing the assigned vector,
each knows a subset of other vectors. This scenario can be depicted by a so-called side-information graph
where each vertex represents a user and there is an edge from user A to user B, if A knows the vector
assigned to B. Given this graph, how much information should a broadcaster transmit, such that each
vertex can deduce its assigned vector?
Consider a group of n users with the side information represented by the directed graph G, such that
the out-neighbors of vertex vi ∈ V (G) = {v1, v2, . . . , vn} denote the nodes whose data is available to
q. Let N (v,G) ⊆ V (G) \ {v}
vi. The data corresponding to node vi is represented by a vector xi ∈ F(cid:96)
denote the out-neighbors of vertex v (v ∈ N (v,G)). For example, an index coding scenario has been
depicted in ﬁg. 1. The side information graph for this scenario is given in ﬁg. 2. In the graph G of

Abhishek Agarwal is with the Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis,
MN 55455. Arya Mazumdar is with the Computer Science Department of University of Massachusetts, Amherst, MA 01003,
and was with the University of Minnesota. email: abhiag@umn.edu, arya@cs.umass.edu. Research supported by NSF
grants CCF 1318093 and CAREER CCF 1453121.

6
1
0
2

 
r
a

M
8

 

 
 
]
T
I
.
s
c
[
 
 

1
v
6
6
3
2
0

.

3
0
6
1
:
v
i
X
r
a

2

Fig. 1: Example of an Index Coding problem. The corresponding side-information graph is depicted in
ﬁg. 2

ﬁg. 2, N (A,G) = {C, E, F}, N (B,G) = {A, E}, N (C,G) = {B}, N (D,G) = {C, F}, N (E,G) =
{A, D, F}, N (F,G) = {D, E}. The aim is to broadcast the minimum amount of data (in-terms of F(cid:96)
q-
symbols) such that vertex vi is able to reconstruct xi from xN (vi,G) (vectors assigned to the neighbors)
and the broadcast for all i ∈ {1, . . . , n}. The amount of broadcasted data is referred to as the broadcast
rate of the index coding problem.

This simple formulation attracted substantial attention recently [1], [5], [12]. In particular, it has been
shown that any network coding problem can be cast as an index coding problem [6], [7]. Furthermore,
index coding has been identiﬁed as the hardest instance of all of network coding [11]. For up to n = 5,
the optimal broadcast rates of all index coding problems have been tabulated in [10].

If the recovery functions for the nodes, as well as the encoding function at the broadcaster are all
linear over Fq, then the optimal (minimum) broadcasting rate is given by a quantity called the minrank of
the graph [3], [9]. In general, minrank is hard to compute for arbitrary graphs, and also does not give an
achievable scheme in terms of simpler well known graph parameters.

There have been a series of works that aim to characterize the index coding broadcast rate in terms
of other possibly intractable graph parameters or cast the index coding rate as the optimal solution to
a linear program. To start with, an immediate achievable scheme in terms of the clique cover number
the graph or the chromatic number of the complementary graph was provided in [4]. Their simple idea
is to partition the graph into minimum number of vertex-disjoint cliques. And then for each clique, the
broadcaster transmits only once, that is the sum (as Fq-vectors) of the data in all the vertices of the clique.
This provides an index coding solution equal to the chromatic number of the complementary graph.

The above approach then was extended in [13]. In particular, in [13] an interference alignment perspective
of the linear index coding problem was given. It was shown that, it is possible to achieve an index coding
solution with number of transmissions equal to the local chromatic number [8] of the graph. There also
exists an orthogonal approach to generalize the clique covering bound (or the chromatic number bound).
In this approach, appearing as early as in [4], one ﬁnds a partial clique cover (covering with subgraphs
instead of cliques) and uses maximum-distance separable (MDS) codes for each of the partial cliques.
More recently, in [2], the above two approaches were merged and a combined linear program solution
was proposed that we discuss later. In this paper, we show that these two orthogonal approaches can be
merged more effectively, and provide a modiﬁed deﬁnition of local partial clique cover. This lead to
better achievability bound for linear index codes than any previous approaches.

User	  A	  Wants	  xA	  Has	  xC,	  xE,	  xF	  User	  B	  Wants	  xB	  Has	  xA,	  xE	  User	  E	  Wants	  xE	  Has	  xA,	  xD,	  xF	  User	  F	  Wants	  xF	  Has	  xD,	  xE	  User	  C	  Wants	  xC	  Has	  xB	  User	  D	  Wants	  xD	  Has	  xC,	  xF	  3

Fig. 2: Example of an Index Coding problem where the fractional local chromatic number and the
fractional partial clique number based index codes are strictly larger than the proposed scheme for the
fractional case. The undirected edges denote bidirectional edges.

In addition, recently another approach to provide achievable index coding schemes is shown in [14],
where the graph is covered by structures called generalized interlinked cycles (GIC). We are also able to
generalize this method in the way of partial clique covers.

The paper is organized as follows. In section II we deﬁne the necessary graph parameters, describe the
previous schemes and narrate our main theorems. In this section we also give some concrete examples to
show the better performance of our solution. In section III we provide some further results by showing a
generalization of the GIC scheme of [14]. In section IV we describe our main achievability scheme (and
hence the proof of the main result) that outperforms the previous results. This is followed up in section V
where we provide a linear programming (LP) relaxation. Proofs and the example have been shortened for
space constraints.

A. Notations

II. PRELIMINARIES AND MAIN RESULT

The following set of notations will be useful throughout the paper, and we provide it at the outset for

easy reference.

• [n] ≡ {1, 2, . . . , n}
• [m, n] ≡ {m, m + 1, . . . , n}, m ≤ n
• Complement of set A, is denoted by A
• For a graph G, V (G) and E(G) denote the vertex and the edge set of the graph, respectively. G
denotes the directed complement of G
• For any set A = {i1, i2, . . . , ir} ⊆ [n] and set of vectors {vi}i∈[n], vAdenotes the set {vj}j∈A and
v[A] denotes the matrix [vi1 vi2 . . . vir ]. For a matrix G ∈ Fk×n, G[B] denotes the sub-matrix of G
constructed from the columns of G corresponding to B ⊆ [n].

• For a graph G(V, E) and a set S ⊆ V , G|S denotes the subgraph induced by S.

• For a graph G(V, E), N (v,G) ⊆ V (G) \ {v} denotes the set of out-neighbors of v ∈ V .
• I(expr) denotes the indicator function for expr.
• An m × n matrix, m ≤ n is MDS if any m columns of the matrix are linearly independent.
• A linear code is called MDS code, if the generator (or the parity-check) matrix of the code is MDS.

An [n, k]-MDS code implies the code is of length n and dimension k.
• For a matrix M, M (i, j) denotes the entry at ith row and jth column.
We will need the following deﬁnitions.

4

Deﬁnition 1. For a directed graph G, a coloring of indices is proper if for every vertex v of G the color
any of its out-neighbors, N (v,G), is different from the color of vertex v. The minimum number of colors
in a proper coloring is the chromatic number χ.
Deﬁnition 2. The local chromatic number χl of a directed graph G is the maximum number of colors in
any out-neighborhood (including itself) of a vertex, minimized over all proper colorings of the undirected
graph obtained from G by ignoring the orientation of edges in G.
The following deﬁnition of index coding and the optimal broadcast rate will be used throughout the
paper. In the index coding problem, a directed side information graph G(V, E) is given. Each vertex
vi ∈ V represents a receiver that is interested in knowing a uniform random vector xi ∈ F(cid:96)
q. The receiver
at v knows the values of the variables xu, u ∈ N (v,G).
Deﬁnition 3 (Index coding). An index code C for F(cid:96)×n
{v1, v2, . . . , vn}, is a set of codewords (vectors) in F(cid:96)·n0
1) An encoding function f mapping inputs in F(cid:96)×n
2) A set of deterministic decoding functions g1, . . . , gn such that gi

with side information graph G(V, E), V =

f (x1, . . . , xn),{xj

to codewords, and

together with:

q

q

q

(cid:16)

: j ∈

N (vi,G)}(cid:17)

= xi for every i = 1, . . . , n.

The encoding and decoding functions depend on G. The number n0 is called the broadcast rate of the
index code C and (cid:96) is called the size of a node. Note that n0 can be a non-integer as long as n0 · (cid:96) is
integer. The minimum value of n0 over all possible index codes and all possible (cid:96) is called the optimal
broadcast rate.

B. Prior work

An interference alignment perspective to the graph coloring approach described in the introduction was

presented in [13] by assigning a vector vi to vi such that,

vi (cid:54)∈ span(vN (vi,G)\{vi}).

(1)
From the interference alignment perspective, N (v,G)\{v} are the interfering set of indices for user v. Let
G = [v1v2 . . . vn]. Then, the index code (the broadcaster transmission) is given by G· [x1 x2 . . . xn]T
(cid:96)×n ∈
F(cid:96)×rank(G)
. It can be seen that each node vi can recover xi from the index code because of eq. (1). We
also sometime denote the vector assigned to node v ∈ V (G) as v(v).

q

It is possible to satisfy the requirements in eq. (1) if span(v[n]) = n. The goal is to minimize the
dimension of span(v[n]). One solution to this problem is to ﬁnd a proper coloring (see, deﬁnition 1) of
the vertices in G and assign orthonormal vectors to each color (the same vector is assigned to all vertices
with the same color). Thus, an achievable solution is given by the chromatic number of G, χ(G).

generator matrix of a [(cid:80)S∈K0

where K0 denotes the set of cliques in the directed graph G. Denote ρ∗
S as the optimal solution to the
above IP. Note that there exists a proper coloring of ¯G corresponding to the IP in eq. (2). We use the
S, χl(G)]-MDS code to assign a column vector to each color in the proper
ρ∗
coloring. In [13], it was shown that this scheme works for every directed graph by assigning each vertex
a vector corresponding to its color in the proper coloring of eq. (2).
Theorem 1 (Shanmugam et al. [13]). The minimum broadcast rate of an index coding problem is upper
bounded by the optimal value of the integer program of eq. (2).

Note that, a coloring of G is equivalent to a clique covering of G. Thus, another approach to ﬁnding an

index code is to ﬁnd a partial clique (deﬁnition 4) cover of G [4].
Deﬁnition 4. A directed graph G on n vertices is a k-partial clique if every vertex has at least n − 1 − k
out-neighbors and there is at least one vertex in G with exactly n − k − 1 out-neighbors.
In each of the kS-partial clique S, one might use a parity check matrix of a Reed-Solomon code that
can correct kS + 1 erasures. The broadcaster ﬁnds the syndrome of the symbols at the vertices. The
dimension of the syndrome is kS + 1. Thus, the broadcast rate of the index coding problem is given by
the following integer program,

minimize (cid:88)
subject to (cid:88)

S∈K

(kS + 1)ρS

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ {0, 1}, S ∈ K

5

(2)

(3)

(4)

One way to improve the upper-bound χ(G) above is to use an [n, k]-MDS code with k = χl(G).
The local chromatic number of G can be given by the following integer program (IP),

subject to (cid:80)S∈K0:S(cid:54)⊆N (v,G) ρS ≤ t, v ∈ V (G)

minimize

t

(cid:88)

ρS ≥ 1, v ∈ V (G)

and

S∈K0:v∈S
ρS ∈ {0, 1}, S ∈ K0

where K denotes the power set of vertices in G and S ∈ K is a kS-partial clique.

Subsequently in this paper we combine the schemes in [13] and [4] to derive an achievability scheme
that would give better results than both of these existing schemes. Recently, in an effort to combination,
Arbabjolfaei and Kim [2] proposes the following result.
Theorem 2 (Arbabjolfaei and Kim [2]). The minimum broadcast rate of an index coding problem on the
side information graph G is upper bounded by the optimal value of the following integer program,

subject to (cid:80)S∈K:S(cid:54)⊆N (v,G)(kS + 1)ρS ≤ t, v ∈ V (G)

minimize

t

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ {0, 1}, S ∈ K.

We provide a stronger bound than eq. (4) (see theorem 3 below). Our bound requires a signiﬁcantly

involved achievability scheme.

Very recently another technique for index coding achievability was proposed in [14]. We refrain from
separately describing the scheme here. Instead in section III, we provide a generalization of their scheme.
The generalization is similar in spirit to that of k-partial clique covering from clique covering.

6

C. Our main results

Our main result is given by the following theorem.

Theorem 3. The minimum broadcast rate of an index coding problem on the side information graph G is
upper bounded by the optimum value of the following integer program.

subject to (cid:80)S∈K min{|S ∩ N (v,G)|, (kS + 1)}ρS ≤ t,

minimize

t

v ∈ V (G)

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ {0, 1}, S ∈ K.

The change in eq. (5) from eq. (4) is introduction of the term |S ∩ N (v,G)| in the optimization under
the summation. Although the set over which the summation is performed seemed to have expanded, it is
not the case. Notice that, if S ⊆ N (v,G) then |S ∩ N (v,G)| = 0. This also shows that our scheme is at
least as good as eq. (4). However the achievability scheme becomes signiﬁcantly complicated because of
the introduction of the term under the summation.

In comparison, for the linear program in eq. (4), a simpler achievability scheme is possible and we
describe it in Appendix A for completeness. Note that, this simple achievability scheme was not mentioned
in [2].

ﬁnds a partition of G into partial cliques. Here,(cid:80)S∈K min{|S ∩ N (v,G)|, (kS + 1)}ρS denotes the number

Furthermore, any vertex subgraph of a k-partial clique is also a k-partial clique. Thus, the IP in eq. (5)

of non-neighbors of vertex v among the the selected partial cliques, while counting at most (kS + 1)
non-neighbors in a kS-partial clique. We call the optimal solution to eq. (5) the local partial clique cover
number.

Since a clique cover is the special case of a k-partial cover (a clique is a 0-partial clique), eq. (5)
trivially outperforms both the optimizations of eqs. (2) and (3). Moreover, the optimization in eq. (5)
clearly results a value smaller than that of eq. (4). What remains is to show that there exists an index
coding encoding scheme that achieve the optimal point of eq. (5). We provide that is section IV.

We can consider the fractional relaxation of the IP in eq. (5) and provide an even better upper-bound.

subject to (cid:80)S∈K min{|S ∩ N (v,G)|, (kS + 1)}ρS ≤ t,

minimize

t

v ∈ V (G)

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ [0, 1], S ∈ K.

(5)

(6)

Theorem 4 (Linear programming relaxation). The minimum broadcast rate of an index coding problem
on the side information graph G is at the most the optimum value of the linear programming of eq. (6).

The necessary adjustments required for the proof of this theorem is provided in section V.
Following the ideas of [2], we can further tighten the achievability bounds by considering recursive

7

linear program.
Theorem 5 (Recursive LP). Let ICF LP (G) denote the optimizated value of the linear program below for
graph G:

subject to (cid:80)S∈K min{|S ∩ N (v,G)|, ICF LP (G|S)}ρS ≤ t,

minimize

t

v ∈ V (G)

(7)

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ [0, 1], S ∈ K.

Also deﬁne ICF LP to be equal to 1 for singleton sets. The minimum broadcast rate of an index coding
problem on the side information graph G is bounded from above by ICF LP (G).

The proof of this theorem is going to be evident at the end of section IV and section V.

1) Examples of better performance for our scheme: While it had been evident that our proposed bounds
are at least as good as the previous bounds, we now give explicit example of graphs where our upper
bounds are strictly smaller than all previous upper bounds. Consider the index coding problem described
by the graph in ﬁg. 2. For this graph, the index coding based on the fractional local chromatic number
(LP relaxation of theorem 1) has broadcast rate 4, the index coding based on the fractional partial clique
clique covering (LP relaxation of eq. (3)) has broadcast rate 11/3 and our proposed scheme (theorem 4)
has broadcast rate 7/2.

The proposed scheme of theorem 5 is also better than the corresponding recursive scheme proposed in
[2, theorem 4]. For the graph in ﬁg. 3 our scheme is strictly better than their scheme. The index coding
broadcast rates for the graph are 3 and 7/2 for our proposed scheme and the scheme in [2, theorem 4],
respectively.

Remark (Codes with small alphabet size): Consider the construction of linear index codes using local
chromatic number of the complement graph in [13]. Assume that the local chromatic number χl corresponds
to a coloring with m colors. Then, we require an [m, χl + 1]-MDS code. Using a Reed-Solomon code
we can construct a [m, χl + 1]-MDS code on a ﬁeld of size m. Here, we note that, instead of using
the generator matrix of a [m, χl + 1]-MDS code the parity check matrix of any linear code of size m
and minimum distance χl + 2 would work. Thus, when restricted to using a small alphabet size (say
q), we have the following upper-bound on the size of the code using the Gilbert-Varshamov bound,
m − logq Aq(m, χl + 2) = m − logq

(cid:1)(q − 1)j(cid:17)
(cid:0)m

(cid:16)(cid:80)χl+1

(cid:80)χl+1

= logq

(cid:18)

(cid:19)

qm
j )(q−1)j
j=0 (m

j=0

j

.

III. FURTHER RESULTS: EXTENSION TO K-GIC GRAPHS

In the previous section, we modiﬁed the scheme in [13] by substituting a 0-partial clique cover of G
with a k-partial clique cover for any k > 0. We can further extend this procedure to include the n-GIC

8

Fig. 3: Example of an Index Coding problem where the scheme in [2, theorem 4] are strictly larger than
the proposed scheme for the fractional case.

graphs deﬁned in [14]. To that end, we extend the deﬁnition of n-GIC graphs to (k, n)-GIC, described
below (n-GIC of [14] is (0, n)-GIC of our deﬁnition).

Consider a directed graph with N vertices having the following properties:
1. A set of n vertices, denoted by VI, such that for any vertex vi and at least n− k − 1 vertices vj ∈ VI
there is a path from vi to vj which does not include any other vertex of VI. We call VI the inner vertex
set, and let VI = {v1, v2, . . . , vn}. The vertices of VI are referred to as inner vertices.
2. Due to the above property, we can always ﬁnd a directed rooted tree, (denoted by Ti) with maximum
number of leaves in VI and root vertex vi, having at least n − k − 1 other vertices in VI \ {vi} as leaves.
The trees may be non-unique.

Denote the union of all selected n trees as Dn (cid:44)(cid:83)∀i∈VI

Ti. If Dn satisﬁes two conditions (to be deﬁned
shortly), we call it a (k, n)-GIC structure (denoted as a (k, n)-GIC sub-digraph: Dn = (V (Dn), E(Dn)),
where |V (Dn)| = N). Now we deﬁne a type of cycle and a type of path.
Deﬁnition 5 (I-cycle). A cycle that includes only one inner vertex i ∈ VI is an I-cycle.
Deﬁnition 6 (P-path). A path in which only the ﬁrst and the last vertices are from VI, and they are
distinct, is a P-path.

The conditions for Dn to be qualiﬁed as a (k, n)-GIC are as follows:
1) Condition 1: There is no I-cycle.
2) Condition 2: For all ordered pairs of inner vertices (vi, vj), i (cid:54)= j, there is only one P-path from i

to j.

A. Code Construction

The following theorem allows us to construct an index coding scheme.

Theorem 6. If a vertex v ∈ V \ VI belongs to trees Ti and Tj, i (cid:54)= j, then all the non-inner nodes on the
subtree of Ti rooted at v also belong to Tj.

1. wI =(cid:80)

proof in [14, Lemma 3] still applies for the (k, n)-GIC.

The proof of this theorem is deferred to Appendix 26. In particular in Appendix 26, we show that the
Denote the non-inner vertices of the subtree rooted at vertex v ∈ V \ VI as Dn(v). Let [v1 v2 . . . vn]

vji∈VI

vixi .

be the generator matrix of a [n, k + 1]-MDS code. Then the index code is deﬁned below:
2. Let xN (vj,Dn) ∈ F|N (vj,Dn)|
N (vj, Dn). A vector wj ∈ Fmin{|N (vj,Dn)|,k+1}
(cid:80)
vl∈{N (vj,Dn)∩VI} vl(xj + xl) +(cid:80)
where,

denote the vector consisting of the data corresponding to the nodes in
corresponding to all vertices vj ∈ V \ VI is transmitted,

q

q

wj =

ul(xj + xl)
1xj + xN (vj,Dn)

vl∈{N (vj,Dn)\VI}
if |N (vj, Dn)| ≥ k + 1
if |N (vj, Dn)| < k + 1



9

(8)

q

where ul ∈ Fmin{|N (vj,Dn)|,k+1}
are chosen as described in algorithm 1. Algorithm 1 ﬁrst assigns a vector
ul to all non-inner nodes vl ∈ Dn starting from the nodes at the bottom of a tree Ti ∈ Dn. The vector ul
corresponding to the vertex vl depends on its children {ul : vl ∈ Dn(vl)}. To show that the algorithm
works, we need to ﬁnd a vertex for which all out-neighbors are outside S. It is easy to see from theorem 6
that this always holds.

for vj ∈ V \ VI and uj ∈ Fk+1 for vj ∈ VI

q

Data: trees T1, T2, . . . , Tn
Result: uj ∈ Fmin{|N (vj,Dn)|,k+1}
1 ui = vi for all vi ∈ VI
2 S = V \ VI
3 while |S| > 0 do
4
5

ui = − (cid:88)

uj

Find a vertex in vi ∈ S : N (vi, Dn) ⊆ S

j:vj∈N (vi,Dn)

S = S \ {vi}

6
7 end

Algorithm 1: Selecting the vectors uj, j ∈ V \ VI

B. Decoding

It is easy to see that all the non-inner vertices j ∈ V \ VI can recover their data xj. We show that
(cid:48) corresponding to the transmitted vector wj for vj ∈ V \ VI as

vi ∈ VI can also recover xi. Deﬁne wj
follows,

(cid:48) =

wj

(9)
where {vc1, vc1, . . . , vcr} = N (vj, Dn). Denote by T (v) the subtree rooted at vertex v in tree T . For the
non-inner child v of vertex vi compute the following,

wj
[uc1 uc2 . . . ucr ]wj

if |N (vj, Dn)| ≥ k + 1
if |N (vj, Dn)| < k + 1

(cid:40)

w(cid:48)

l

(10)

(cid:88)

w(v) =

vl∈Ti(v)\VI

wI −(cid:80)

Note that, w(v) only contains terms of the form ulxl for {l : vl ∈ VI or vl ∈ Dn(vi)}. Now, consider
v∈Dn(vi) w(v). The only terms left in this are ulxl for {l : vl ∈ VI \ Ti}. Since there are at most k
such terms and [v1 v2 . . . vn] is the generator matrix of a [n, k + 1]-MDS code, vertex vi can decode xi.

10

IV. ACHIEVABILITY SCHEME (PROOF OF THEOREM 3)

the program in eq. (5).

We now describe an index coding scheme to achieve a broadcast rate equal to the optimal solution of

j∈[t−1] nj +
j∈[t] nj] be the partial cliques selected in eq. (5). Let kj := kSj. Assume that the optimum value of
j(kj + 1). We construct [nj, kj + 1]-MDS codes for each

Assume without loss of generality that S1 = [n1], S2 = [n1 + 1, n1 + n2], . . . ,St = [(cid:80)
1,(cid:80)
eq. (5) is m. Then maxj(kj + 1) ≤ m ≤(cid:80)


j ∈ [t]. Let Gj denote the generator matrices for these codes. Thus,

1
αj,1 αj,2



Gj =

(11)

1

1

. . .
. . . αj,nj
...
. . . αkj
j,nj

αkj
j,1 αkj
where αj,1, αj,2, . . . , αj,n1 ∈ Fq for all j ∈ [t].

j,2

Let kj =(cid:80)j

Φ[kj−1+1,kj]. Denote, xi

Finally we construct the following matrix G,

l=1(kl + 1). Assume that Φ is the generator matrix of an [kt, m]-MDS code. Let Φj =

j = min{|Sj ∩ N (vi,G)|, (kSj + 1)},

i ∈ [n], j ∈ [t].

G = [u1 u2 . . . un] = [Φ1G1 Φ2G2 . . . ΦtGt]m×n

(12)

where n =(cid:80)

j nj is the number of vertices in G.

Now assigning the vector ui to vertex i, we show that this assignment satisﬁes the interference alignment
condition in eq. (1). Note that this scheme is a natural generalization of the localized coloring scheme
where the matrix Gj is the generator matrix of a repetition code and kt = m.
Lemma 7. Let Hj be a (kj + 1) × (kj + 1) submatrix of Gj. Then for a large enough ﬁeld Fq there
exist αj,i ∈ Fq, j ∈ [t], i ∈ [nj] such that ˆG = [Φ1H1 Φ2H2 . . . ΦtHt] is an MDS matrix for any set of
sub-matrices Hj.
Proof: Let Φ = [v1 v2 . . . vkt] and let U (s) denote any m × s sub-matrix of Φ≥2 := [Φ2 . . . Φt].
Since Φ is MDS, [vi1 vi2 vir U (m − r)] must be full-rank for all {i1, . . . , ir} ⊆ [k1 + 1]. Consider any
vector w ∈ Fm
q ,

where ar ∈ Fr
represented as a linear combination of column vectors in G(cid:48) := [Φ1H1 U (m − r)] where,

q and ar+1 ∈ F(m−r)

w = [vi1 vi2 vir U (m − r)]
. We show that there exist α1,i ∈ Fq, i ∈ [n1] such that w can also be

ar+1

(13)

(cid:20) ar

q

(cid:21)


 1

α1,i1

H1 =

1

α1,i2

α1,ir

1

. . .
. . .
...
. . . α1,ir

k1

α1,i1

k1 α1,i2

k1

for any {i1, i2, . . . , ir} ⊆ [nj], i.e.

w = G(cid:48) (cid:20) dr

dr+1

(cid:21)

11

(14)

for some dr ∈ Fr

q and dr+1 ∈ Fm−r

q

Since, [vi1 vi2 vir U (m − r)] is full-rank, we have,

.

k1+1−r

1 vi(cid:48)
2 . . . vi(cid:48)
[vi(cid:48)
and Br+1 ∈ F(m−r)×(k1+1−r)
where Br ∈ Fr×(k1+1−r)
{i1, i2, . . . , ir}. Thus, combining eqs. (13) to (15), we have,
(cid:21)

] = [vi1 vi2 vir U (m − r)]
and {i(cid:48)
1, i(cid:48)
(cid:21)(cid:19)

[vi1 vi2 . . . vir U (m − r)]·

q

q

(cid:20) Br

(cid:21)

Br+1
2, . . . , i(cid:48)

,

(15)
k1+1−r} = [k1 + 1] \

(16)

where,

1dr + dr+1

Br+1H(cid:48)

(cid:18)(cid:20) [Ir Br] Pσ H1dr


αr+1
1,i1
αr+2
1,i1

αr+1
1,i2
αr+2
1,i2

α1,i1

k1 α1,i2

k1

H(cid:48)
1 =

(cid:20) ar

ar+1

−

. . . αr+1
1,ir
. . . αr+2
1,ir
...
. . . α1,ir

k1

= 0



α1,i1

α1,i1

det

and Pσ is the permutation matrix for σ = (1 → i1, 2 → i2, . . . , r → ir, (r + 1) → i(cid:48)
q, ar+1 ∈ Fk−r+1
2, . . . , (k + 1) → i(cid:48)
i(cid:48)
have, det([Ir Br]PσH1) (cid:54)= 0 i.e.,

k+1−r). For the solution in eq. (16) to exist for all ar ∈ Fr

q

1, r + 2 →
we must

i1−1 + g(α1,i1)b1 α1,i2
i2−1 + g(α1,i1)b2 α1,i2

i1−1 + g(α1,i2)b1
i2−1 + g(α1,i2)b2

...

i1−1 + g(α1,ir )b1
i2−1 + g(α1,ir )b2

...

. . . α1,ir
. . . α1,ir
...
. . . α1,ir

2−1 . . . αi(cid:48)

ir−1 + g(α1,i2)br

ir−1 + g(α1,i1)br α1,i2
1−1αi(cid:48)

k1+1−r−1] and Br =(cid:2)b1 b2 . . . br

α1,i1
where g(α) = [αi(cid:48)
The polynomial in the RHS of eq. (17) has degree at most k1 for all the variables α1,i1, α1,i2, . . . , α1,ir.
Thus, by increasing the size of the ﬁeld Fq we can make sure that there exist αj,i for all j ∈ [t] and
i ∈ [nj] such that eq. (17) holds.
all sets of Hj ∈ F(kj+1)×(kj+1)

Now, repeating the above argument t times we can say that [Φ1H1Φ2H2 Φ3H3 . . . ΦtHt] is MDS for

ir−1 + g(α1,ir )br

submatrices of Gj.

(cid:3)T .

qr

Whereas a loose upper-bound (sufﬁcient) on the ﬁeld size becomes,

 (cid:54)= 0

(17)

(cid:18)n − nj

m − r

kj

kj+1(cid:88)

r=1

(cid:19)(cid:18) nj

(cid:19)

r − 1

q ≤ max
j∈[t]

Now our main theorem is evident.
Theorem 8. For any vertex vi ∈ V (G) we have,

ui (cid:54)∈ span(uN (vi,G)\vi

)

+ nj

(18)

(19)

j

j| = kj + 1 and span(cid:0)uPj

Proof: Consider a vertex vi in graph G, with non-neighbors P1, P2, . . . , Pt such that Pj ⊆ {i : vi ∈ Sj}.
Assume, wlog that vi ∈ S1. Then, |P1| ≤ k1. Note that, for any Pj : |Pj| ≥ kj + 1 there exists a set
(cid:17)
j = Pj for Pj : |Pj| ≤ kj + 1, j (cid:54)= 1
j ⊆ Pj : |P (cid:48)
of P (cid:48)
}j is full-rank
1 = P1 ∪ i. Therefore, we have span
}j
and P (cid:48)
(lemma 7) its easy to see that eq. (19) follows.

(cid:16)
(cid:1) = span
(cid:16){uPj}j
(cid:17)

. Now, since {uP (cid:48)

= span

. Let P (cid:48)

(cid:16){uP (cid:48)

(cid:17)

uP (cid:48)

Note that, in the proof of theorem 8 we do not need the matrix ˆG in lemma 7 to be MDS. Instead we
only need a class of n different subsets of column vectors of G, each of size at most m, to be linearly
independent. Thus the upper bound on the size of the alphabet in eq. (18) is very loose and we can show
that an alphabet of size O(n) should sufﬁce (details omitted).
The optimal index coding solution in eq. (5) uses at most 2 levels of MDS codes Φ and Gj, j ∈ [t]. If
we recursively use the above method on the k-partial cliques corresponding to Gj then we can further
reduce the index coding broadcast rate in eq. (5). The achievement scheme for the recursive linear program
can be easily obtained by replacing Gj in eq. (12) with the matrix obtained for ICLP (G|S). The matrix
for ICLP (G|S) can be obtained recursively in a similar manner. The integer program corresponding to
the recursive scheme is,

j

j

subject to (cid:80)S∈K min{|S ∩ N (v,G)|, ICLP (G|S)}ρS ≤ t,

minimize

t

v ∈ V (G)

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ {0, 1}, S ∈ K

12

(20)

(21)

where ICLP (G) denotes the optimum of the above integer program for the graph G and G|S denotes the
graph G restricted to the subset S. Note that ICLP (G|{i}) := 1, i ∈ [n] and the proof in lemma 7 and
theorem 8 apply to the scheme for eq. (20) as well.

V. FRACTIONAL LOCAL PARTIAL CLIQUE COVER (PROOF OF THEOREM 4)

In this section we show how to design an encoding scheme to achieve the rate given by the linear

programming optimal solution of eq. (6).
Since all the coefﬁcients of the LP in eq. (6) are integers, the optimal solution ρ(cid:63)S must be rational.
Assume that in optimal solution to eq. (6) all partial cliques S for which ρS > 0 are S1 S2, . . . ,St
and |Sj| = nj. Let kj := kSj. Also assume that all ρSj , j ∈ [t] have a common denominator ∆ such
that ρSj = Nj/∆. Assume that the optimum value to the optimization of eq. (6) is m(cid:63). Construct a
[nj, kj + 1]-MDS code for each j. Let Gj, j ∈ [t] be the generator matrix for these codes. Thus,



Gj =



1

1
αj,1 αj,2

αkj
j,1 αkj

j,2

1

. . .
. . . αj,nj
...
. . . αkj
j,nj

j := (cid:80)Nj

where αj,1, αj,2, . . . , αj,n1 ∈ F for all j ∈ [t]. Let G(cid:48)
l=1 Qll ⊗ Gj, where Qrs is a Nj × Nj
matrix with the only non-zero entry being Qrs(r, s) = 1 and ⊗ denotes the matrix tensor product. Let

kj =(cid:80)j

l=1 Nj(kl +1) and let Φ be the generator matrix of an [kt, m(cid:63)∆]-MDS code. Let Φj = Φ[kj−1+1,kj].

Finally we construct a matrix G:

= [Φ1G(cid:48)

G = [u1,1 . . . u1,(N1nj) ··· ut,1 . . . ut,Ntnt]

Note that(cid:80)t

(22)
(23)
j=1 njNj = ∆n. Now each vertex has to be assigned ∆ column vectors from G. Assume
wlog that a vertex belongs to partial cliques S1, S2, . . . , Sr, r ≤ t. Assume that the column vector in
Gj, j ∈ [r] corresponding to the vertex is
, cj ∈ [nj]. Then the vectors assigned to
the vertex are uj,cj , uj,cj+nj , uj,cj+2nj , . . . , uj,cj+(Nj−1)nj for j ∈ [r].

1 Φ2G(cid:48)
(cid:104)

2 . . . ΦtG(cid:48)

t](∆m(cid:63))×(∆n)

Now using arguments similar to lemma 7, the interference alignment condition can be satisﬁed for this

. . . αkj
j,cj

(cid:105)T

1 αj,cj

case too.

To construct an achievability for the fractional relaxation of the recursive scheme (eq. (24)), we can

recursively use the scheme for eq. (6).

13

(24)

subject to (cid:80)S∈K min{|S ∩ N (v,G)|, ICF LP (G|S)}ρS ≤ t,

minimize

t

v ∈ V (G)

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ [0, 1], S ∈ K

where ICF LP (G) denotes the optimum value of the above linear program for graph G. Let a vertex
i ∈ [n] belong to r recursive index coding problems ICLP (G), ICLP (G|S1), . . . , ICLP (G|Sr ), G ⊃ S1 ⊃
S2 . . . ⊃ Sr. Thus, for the achievability scheme above, it is assigned r coefﬁcients corresponding to the r
problems, ρ1 = N 1/∆1, . . . , ρr = N r/∆r and assigned ∆1 × . . . × ∆r column vectors.

Note that, we need the size of the node, (cid:96), to be at least ∆1 × . . . × ∆r, for the scheme to work.

REFERENCES

[1] Noga Alon, Eyal Lubetzky, Uri Stav, Amit Weinstein, and Avinatan Hassidim. Broadcasting with side information. In

Foundations of Computer Science, 2008 (FOCS’08), 49th Annual Symposium on, pages 823–832. IEEE, 2008.

[2] Fatemeh Arbabjolfaei and Young-Han Kim. Local time sharing for index coding. In Information Theory (ISIT), 2014 IEEE

International Symposium on, pages 286–290. IEEE, 2014.

[3] Ziv Bar-Yossef, Yitzhak Birk, TS Jayram, and Tomer Kol. Index coding with side information. Information Theory, IEEE

Transactions on, 57(3):1479–1494, 2011. Preliminary version in FOCS 2006.

[4] Yitzhak Birk and Tomer Kol. Informed-source coding-on-demand (iscod) over broadcast channels. In INFOCOM’98.
Seventeenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE, volume 3,
pages 1257–1264. IEEE, 1998.

[5] Anna Blasiak, Robert Kleinberg, and Eyal Lubetzky. Lexicographic products and the power of non-linear network coding.

In Foundations of Computer Science (FOCS), 2011 IEEE 52nd Annual Symposium on, pages 609–618. IEEE, 2011.

[6] Michelle Effros, Salim El Rouayheb, and Michael Langberg. An equivalence between network coding and index coding.

Information Theory, IEEE Transactions on, 61(5):2478–2487, 2015.

[7] Salim El Rouayheb, Alex Sprintson, and Costas Georghiades. On the index coding problem and its relation to network

coding and matroid theory. Information Theory, IEEE Transactions on, 56(7):3187–3195, 2010.

[8] Paul Erd¨os, Zolt´an F¨uredi, Andr´as Hajnal, P´eter Komj´ath, Vojtech R¨odl, and ´Akos Seress. Coloring graphs with locally

few colors. Discrete mathematics, 59(1):21–34, 1986.

[9] W. Haemers. An upper bound on the shannon capacity of a graph. Algebraic methods in Graph Theory, 25:267–272, 1978.
[10] Young-Han Kim. All index coding problems up to n=5 messages. http://circuit.ucsd.edu/∼yhk/indexcoding.html. Accessed:

2016-02-17.

[11] Michael Langberg and Alex Sprintson. On the hardness of approximating the network coding capacity. In Information

Theory, 2008. ISIT 2008. IEEE International Symposium on, pages 315–319. IEEE, 2008.

[12] Eyal Lubetzky and Uri Stav. Nonlinear index coding outperforming the linear optimum.

Information Theory, IEEE

Transactions on, 55(8):3544–3551, 2009.

[13] Karthikeyan Shanmugam, Alexandros G Dimakis, and Michael Langberg. Local graph coloring and index coding. In

Information Theory Proceedings (ISIT), 2013 IEEE International Symposium on, pages 1152–1156. IEEE, 2013.

[14] Chandra Thapa, Lawrence Ong, and Sarah J Johnson. Generalized interlinked cycle cover for index coding. arXiv preprint

arXiv:1504.04806, 2015.

14

APPENDIX
Consider the following integer program proposed in [2],

subject to (cid:80)S∈K(kS + 1)ρS ≤ t,

minimize

t

(cid:88)

and

ρS ≥ 1, v ∈ V (G)

S∈K:v∈S
ρS ∈ [0, 1], S ∈ K.

v ∈ V (G)

(25)

We propose a simple scheme corresponding to the integer program in eq. (25). Assume that the optima
corresponding to the integer program is m, the partial cliques selected are S1,S2, . . . ,St. Let nj := |Sj|
and kj := kSj. Let the cliques selected corresponding to the vertex vi have indices {ci
} ⊆ [t].

2, . . . , ci
ti

1, ci

We construct the following matrix G,

where n =(cid:80)

G = [u1 u2 . . . un] = [Φ1G1 Φ2G2 . . . ΦtGt]m×n

(26)
j nj is the number of vertices in G, Gj, j ∈ [t] are [nj, kj + 1]-MDS matrices, and Φj are

m × (kj + 1) matrices deﬁned as follows.

Let Φ denote a set of m linearly independent vectors of dimension m. We construct the matrix Φj
are

such that its column vectors are vectors in Φ and the column vectors for the matrices Φci
full rank for all i. Note that such an assignment is possible because m = maxi
j=1(kci

, . . . , Φci
ti
+ 1).

Note that, in this case, the upper bound on the alphabet size is maxj∈[t]nj corresponding to the largest

1

j

(cid:80)ti

alphabet size needed for constructing Gj.

The achievability scheme for the recursive scheme in [2, theorem 4] can be constructed from eq. (25)
analogous to the way for which we construct the scheme for eq. (20) from eq. (5). And the extension to
linear programs is also done in an analogous manner.
Denote the leaves of subtree of the tree T rooted at vertex v ∈ V (T ) as L(v, T ) and the leaves of the

tree T as L(T ).
Lemma 9. If a vertex v ∈ V (Ti) and v ∈ V (Tj), i (cid:54)= j and v ∈ VI then L(v, Tj), L(v, Ti) ⊆ VI\{vi, vj}
Proof: If the vertex vj ∈ L(v, Ti), then there exists a path from vertex v to vj in the tree Ti. However,
in the tree Tj, there is a path from vertex vj to v. Thus in the sub-digraph Dn, we obtain a path from vertex
v to vj (via Ti) and vice versa (via Tj). As a result, an I-cycle containing vj is present. This contradicts
the condition 1 (i.e., no I-cycle) for a Dn. Hence, vj /∈ L(v, Ti). In other words, L(v, Ti) ⊆ VI \ {vi, vj}.
Similarly, L(v, Tj) ⊆ VI \ {vi, vj}.
Lemma 10. If a vertex v ∈ V (Ti) and v ∈ V (Tj), i (cid:54)= j and v ∈ VI then L(v, Ti) = L(v, Tj)

15

Proof: From lemma 9, L(v, Ti) is a subset of VI\{vi, vj}. Now pick a vertex vc belongs to VI\{vi, vj}
such that vc ∈ L(v, Ti) but vc /∈ L(v, Tj) (such vc exists since we suppose that L(v, Ti) (cid:54)= L(v, Tj)). In
tree Ti, there exists a directed path from the vertex vi which includes the vertex v, and ends at the leaf
vertex vc. Let this path be Pvi→vc(Ti).
Now, suppose that in tree Tj, there exists a directed path from the vertex vj, which doesn’t include the
vertex v (since vc /∈ L(v, Tj)), and ends at the leaf vertex vc. Let this path be Pvj→vc(Tj). However, in
the digraph Dn, we can also obtain a directed path from the vertex vj which passes through the vertex v
(via Tj), and ends at the leaf vertex vc (via Ti). Let this path be Pvj→c(Dn). The paths Pvj→vc(Tj) and
Pvj→vc(DK) are different which indicates the existence of multiple P -paths from the vertex vj to vc in
Dn, this contradict the condition 2 for a Dn. Consequently, L(v, Ti) = L(v, Tj).
Therefore, the only case left is vc (cid:54)∈ L(Tj). But since, the tree Tj must be such that it has the maximum

number of leaves in VI and there exists a tree that has more leaves than Tj this leads to a contradiction.
Lemma 11. If a vertex v ∈ V (Ti) and v ∈ V (Tj), i (cid:54)= j and v ∈ VI then the out-neighborhood of the
vertex v must be same in both the trees i.e. N (v, Ti) = N (v, Tj)
Proof: Now we pick a vertex vb such that, without loss of generality, vb ∈ N (v, Ti) but vb (cid:54)∈ N (v, Tj)
(such vb exists since we assumed that N (v, Ti) (cid:54)= N (v, Tj)). Furthermore, we have two cases for vb,
which are (case 1) vb ∈ L(v, Ti), and (case 2) vb /∈ L(v, Ti). Case 1 is addressed in lemma 10. On the
other hand, for case 2, we pick a leaf vertex vd ∈ L(vb, Ti) such that there exists a path that starts from
v followed by vb, and ends at vd, i.e., (cid:104)v, vb, . . . , vd(cid:105) exists in Ti. A path (cid:104)vj, . . . , v(cid:105) exists in Tj. Thus a
path (cid:104)vj, . . . , v, vb, . . . , vd(cid:105) exists in Dn. From the ﬁrst part of the proof, we have L(v, Ti) = L(v, Tj),
so vd ∈ L(v, Tj). Now in Tj, there exists a path from vj to vd, which includes vertex v followed by
a vertex ve such that ve ∈ N (v, Tj) and ve (cid:54)= vb (as vb /∈ N (v, Tj)), and the path ends at vd, i.e.,
(cid:104)vj, . . . , v, ve, . . . , vd(cid:105) which is different from (cid:104)vj, . . . , v, vb, . . . , vd(cid:105). So multiple P -paths are observed
at vd from vj. This contradicts condition 2 for a Dn. Consequently, N (v, Ti) = N (v, Tj).

