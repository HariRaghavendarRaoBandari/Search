6
1
0
2

 
r
a

M
6

 

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
9
3
8
1
0

.

3
0
6
1
:
v
i
X
r
a

Singular Inﬁnite Horizon Quadratic Control of

Linear Systems with Known Disturbances:

A Regularization Approach

ORT Braude College of Engineering, Karmiel, Israel

Valery Y. Glizer

valery48@braude.ac.il

Oleg Kelis

ORT Braude College of Engineering, Karmiel Israel

Haifa University, Haifa, Israel,

olegkelis@braude.ac.il

March 8, 2016

Abstract

An optimal control problem with an inﬁnite horizon quadratic cost
functional for a linear system with a known additive disturbance is con-
sidered. The feature of this problem is that a weight matrix of the control
cost in the cost functional is singular. Due to this singularity, the problem
can be solved neither by application of the Pontriagin’s Maximum Princi-
ple, nor using the Hamilton-Jacobi-Bellman equation approach, i.e. this
problem is singular. Since the weight matrix of the control cost, being
singular, is not in general zero, only a part of the control coordinates is
singular, while the others are regular. This problem is solved by a reg-
ularization method. Namely, it is associated with a new optimal control
problem for the same equation of dynamics. The cost functional in this
new problem is the sum of the original cost functional and an inﬁnite hori-
zon integral of the squares of the singular control coordinates with a small
positive weight. Due to a smallness of this coeﬃcient, the new problem
is a partial cheap control problem. Using a perturbation technique, an
asymptotic analysis of this partial cheap control problem is carried out.
Based on this analysis, the inﬁmum of the cost functional in the original
problem is derived, and a minimizing sequence of state-feedback controls
is designed. An illustrative example of a singular trajectory tracking is
presented.

1

1 Introduction

In this paper, an optimal control of a linear diﬀerential equation with constant
coeﬃcients for the state and the control, and with a known additive disturbance
is considered. The control process is evaluated by an inﬁnite horizon quadratic
cost functional to be minimized by a proper choice of the control. A weight
matrix of the control cost in this cost functional is singular, meaning that the
optimal control problem is singular. Namely, the considered problem can be
solved neither by application of the Pontriagin’s Maximum Principle [1], nor
using the Hamilton-Jacobi-Bellman equation approach (Dynamic Programming
approach) [2]. This occurs because the problem of maximization of the cor-
responding variational Hamiltonian with respect to the control either has no
solution, or has inﬁnitely many solutions. To the best of our knowledge, ﬁve
main methods of solution of singular optimal control problems can be distin-
guished in the literature. Thus, higher order necessary or suﬃcient optimality
conditions can be helpful in solving a singular optimal control problem (see e.g.
[3, 4, 5, 6, 7, 8] and references therein). However, such conditions fail to yield
a candidate optimal control (an optimal control) for the problem, having no
solution (an optimal control) in the class of regular functions, even if the cost
functional has a ﬁnite inﬁmum in this class of functions. The second method
propose to derive a singular optimal control as a minimizing sequence of regular
open-loop controls, i.e., a sequence of regular control functions of time, along
which the cost functional tends to its inﬁmum (see e.g. [7, 9, 10] and references
therein). The derivation of the minimizing sequence is based on the Krotov’s
suﬃcient optimality conditions [7] and theory of linear ﬁrst order partial dif-
ferential equations. A generalization of this method is the extension approach
[11, 12, 13]. The third method combines geometric and analytic approaches.
Namely, this method is based on a decomposition of the state space into ”reg-
ular” and ”singular” subspaces, and a design an optimal open loop control as a
sum of impulsive and regular functions (see e.g. [14, 15, 16, 17] and references
therein). The fourth method consists in searching a solution of a singular op-
timal control problem in a properly deﬁned class of generalized functions (see
e.g.
[18]). Finally, the ﬁfth method based on a regularization of the original
singular problem by a ”small” correction of its ”singular” cost functional (see
e.g.
[19, 20, 21] and references therein). Such a regularization is a kind of
the Tikhonov’s regularization of ill-posed problems [22]. This method yields
the solution of the original problem in the form of a minimizing sequence of
state-feedback controls.

In the present paper, a singular inﬁnite horizon linear-quadratic optimal con-
trol problem with a known additive time-varying disturbance in the dynamics is
considered. To the best of our knowledge, such a problem has not yet been con-
sidered in the literature. This problem is treated by the regularization, which
yields an auxiliary partial cheap control problem. Using perturbation tech-
niques, an asymptotic behavior of the solution to the auxiliary control problem
is analyzed. Based on this analysis, the existence of the ﬁnite inﬁmum of the
cost functional in the original (singular) control problem is established. The ex-

2

pression for this inﬁmum is derived. The minimizing sequence of state-feedback
controls in the original problem also is designed. The theoretical results are
applied to solution of a singular tracking problem.

The paper is organized as follows. In Section 2, the rigorous formulation of
the problem is presented. Objectives of the paper are stated. In Section 3, a
regularization of the original singular optimal control problem is made, yielding
a partial cheap control problem. An asymptotic analysis of this problem is
carried out in Section 4. The solution of the original singular optimal control
problem is derived in Section 5. Section 6 deals with an illustrative example.
Section 7 contains some concluding remarks. Proofs of some technical lemmas
and of one of the main theorems are placed in Appendices.

2 Problem Statement

2.1

Initial control problem and main assumptions

Consider the following controlled diﬀerential equation:

dZ(t)

dt

= AZ(t) + BU (t) + F (t),

t ≥ 0, Z(0) = Z0,

(1)

where Z(t) ∈ En is the state vector; U (t) ∈ Er, (r ≤ n) is the control; A and B
are given constant matrices of corresponding dimensions; F (t), t ≥ 0 is a given
vector-valued function; Z0 ∈ En is a given vector; for any integer m > 0, Em
denotes the real Euclidean space of the dimension m.

The cost functional, to be minimized by U , is

=

J(cid:0)U(cid:1) △

+∞Z0
(cid:2)Z T (t)DZ(t) + U T (t)GU (t)(cid:3) dt,

(2)

where D is a given constant symmetric matrix of corresponding dimension; the
given constant r × r-matrix G has the form

0 ≤ q < r,

(3)

G = diag(cid:0)g1, ..., gq, 0, ..., 0
r−q (cid:1),
| {z }

the superscript ”T ” denotes the transposition.

In what follows, we assume:
(A1) The matrix B has full rank r;
(A2) the matrix D is positive semi-deﬁnite (D ≥ 0);
(A3) gk > 0, k = 1, ..., q;
(A4) the function F (t) satisﬁes the inequality kF (t)k ≤ a exp(−γt), t ≥ 0,
Since the matrix G is singular, the optimal control problem (1)-(2) is singu-

where a > 0 and γ > 0 are some constants.

lar.

Consider the set P of all functions p(w, t) : En × [0, +∞) → Er, which are
measurable w.r.t. t ≥ 0 for any ﬁxed w ∈ En and satisfy the local Lipschitz
condition w.r.t. w ∈ En uniformly in t ≥ 0.

3

Deﬁnition 1 Let U (Z, t), (Z, t) ∈ En × [0, +∞), be a function belonging to
the set P. The function U (Z, t) is called an admissible state-feedback control
in the problem (1)-(2) if the following conditions hold: (a) the initial-value
problem (1) for U (t) = U (Z, t) has the unique locally absolutely continuous
solution Z(t) on the entire interval [0, +∞); (b) Z(t) ∈ L2 [0, +∞; En]; (c)
U(cid:0)Z(t), t(cid:1) ∈ L2 [0, +∞; Er]. The set of all such U (Z, t) is denoted by MU .

Denote

J ∗ △

=

inf

U(Z,t)∈MU J(cid:0)U (Z, t)(cid:1).

Remark 2 Since D ≥ 0 and G ≥ 0, then the inﬁmum (4) is nonnegative.
Moreover, if MU 6= ∅, this inﬁmum is ﬁnite.

Deﬁnition 3 The control sequence (cid:8)Uk(Z, t)(cid:9), Uk(Z, t) ∈ MU , (k = 1, 2, ...),

is called minimizing in the problem (1)-(2) if

(4)

(5)

(6)

(7)

If there exists U ∗(Z, t) ∈ MU , for which

lim

k→+∞ J(cid:0)Uk(Z, t)(cid:1) = J ∗.
J(cid:0)U ∗(Z, t)(cid:1) = J ∗,

this control is called optimal in the problem (1)-(2). In this case there exists a
minimizing control sequence, point-wise convergent to U ∗(Z, t) for a. a. (Z, t) ∈
En × [0, +∞).

2.2 Transformation of the problem (1)-(2)

We assumed that:

and B2 are of dimensions n × q and n × (r − q), respectively.

Let us partition the matrix B into blocks as B =(cid:16)B1,B2(cid:17), where the blocks B1
(A5) det(cid:0)BT
Hence, the block matrix eBc = (Bc,B1) is a complement matrix to B2.

By Bc, we denote a complement matrix to the matrix B, i.e., the matrix of
dimension n × (n − r), and such that the block matrix (Bc,B) is nonsingular.

2 DB2(cid:1) 6= 0.

Consider the following matrices:

H = (BT

2 DB2)−1BT

2 DeBc,

L = eBc − B2H.

Now, using the block matrix (L,B2), we transform the state in the control

problem (1)-(2) as follows:

Z(t) = (L,B2) z(t),

(8)

where z(t) ∈ En is a new state.

By virtue of the results of [23], the transformation (8) is nonsingular.

4

Remark 4 In what follows, we use the notation On1×n2 for the zero matrix of
dimension n1 × n2, excepting the cases where the dimension of zero matrix is
obvious. In such cases, we use the notation 0 for the zero matrix. By Im, we
denote the identity matrix of dimension m.

Based on the results of [24] (Lemma 1), we have the following lemma.

Lemma 5 Let the assumptions (A1), (A2), (A4), (A5) be valid. Then, trans-
forming the state variable of the problem (1)-(2) in accordance with (8), and
redenoting the control as u(t), we obtain the control problem with the dynamics

dz(t)

dt

= Az(t) + Bu(t) + f (t),

z(0) = z0,

t ≥ 0,

(9)

and the cost functional

where

J(u) =

+∞Z0
(cid:2)zT (t)Dz(t) + uT (t)Gu(t)(cid:3) dt,
A = (L,B2)−1 A (L,B2) ,
B2 (cid:19) ,
B = (L,B2)−1 B =(cid:18) B1
(cid:19) ,
B1 =(cid:18) O(n−r)×r
eI1 =(cid:0) Iq , Oq×(r−q)
eI1
eI2 =(cid:0) O(r−q)×q , Ir−q
B2 = HB1 +eI2,
D = (L,B2)T D (L,B2) =(cid:18) D1
D1 = LTDL, D2 = BT

O(r−q)×(n−r+q) D2

(cid:1) ,
(cid:1) ,

O(n−r+q)×(r−q)

(10)

(11)

(12)

(13)

(14)

(15)

(16)

(cid:19) ,

2 DB2,
f (t) = (L,B2)−1 F (t),
z0 = (L,B2)−1 Z0,

(17)
the matrices D1 and D2 are symmetric, and D1 is positive semi-deﬁnite (D1 ≥
0), D2 is positive deﬁnite (D2 > 0). Moreover, the function f (t) satisﬁes the
inequality

where a > 0 is some constant.

kf (t)k ≤ a exp(−γt),

t ≥ 0,

(18)

Remark 6 In the optimal control problem (9)-(10), the cost functional J(u) is
minimized by the control u(t). Since the weight matrix of the control cost in
the cost functional J(u) is singular, the solution (if any) of this game can be

5

obtained neither by the Pontriagin’s Maximum Principle nor by the Hamilton-
Jacobi-Bellman equation method, meaning that the problem (9)-(10) is singular.
The set Mu of admissible state-feedback controls u(z, t) in the problem (9)-(10)
is deﬁned similarly to such a set MU in the problem (1)-(2). The inﬁmum

J ∗ △
=

inf

u(z,t)∈Mu

J(cid:0)u(z, t)(cid:1)

(19)

is nonnegative. Moreover, if Mu 6= ∅, this inﬁmum is ﬁnite. The minimizing
control sequence {uk(z, t)} and the optimal state-feedback control u∗(z, t) in this
problem are deﬁned similarly to those in the problem (1)-(2), (see (5) and (6),
respectively).

2.3 Equivalence of the problems (1)-(2) and (9)-(10)

Lemma 7 Let the assumptions (A1), (A2), (A5) be valid. Then, the sets Mu
and MU of the admissible state-feedback controls in the problems (9)-(10) and
(1)-(2), respectively, are either both nonempty or both empty.

Proof. The statement of the lemma directly follows from Lemma 5, the invert-
ibility of the transformation (8), and the deﬁnitions of the sets MU and Mu.

Lemma 8 Let the assumptions (A1), (A2), (A5) be valid. Let Mu 6= ∅. Then,
the inﬁmum values J ∗ and J ∗ of the cost functionals in the problems (9)-(10)
and (1)-(2), respectively, are ﬁnite and equal to each other.

Proof. The ﬁniteness of J ∗ and J ∗ follows immediately from the condition
Mu 6= ∅, Lemma 7, and Remarks 2 and 6.

Proceed to the proof of the equality

Due to the deﬁnition of J ∗, there exists a control sequence {uk(z, t)}, uk(z, t) ∈
Mu, (k = 1, 2, ...), such that

J ∗ = J ∗.

(20)

lim

k→+∞

J(cid:0)uk(z, t)(cid:1) = J ∗.

(21)

Similarly, due to the deﬁnition of J ∗, there exists a control sequence {bUk(Z, t)},
bUk(Z, t) ∈ MU , (k = 1, 2, ...), such that

(22)

lim

k→+∞ J(cid:0)bUk(Z, t)(cid:1) = J ∗.

Let us deﬁne the controls

Uk(Z, t)

△

= uk(cid:0)(L,B2)−1Z, t(cid:1),

ˆuk(z, t)

△

= bUk(cid:0)(L,B2)z, t(cid:1),

k = 1, 2, ... . (23)

6

Using Lemma 5, the invertibility of the transformation (8) and the deﬁnitions
of the sets MU and Mu, one directly obtains that
ˆuk(z, t) ∈ Mu,

Uk(Z, t) ∈ MU ,

k = 1, 2, ... ,

(24)

and

J(cid:0)Uk(Z, t)(cid:1) = J(cid:0)uk(z, t)(cid:1),

J(cid:0)ˆuk(z, t)(cid:1) = J(cid:0)bUk(Z, t)(cid:1),

The equations (21)-(22) and (25), as well as the facts that J ∗ is the inﬁmum
of the cost functional in the problem (1)-(2) and J ∗ is the inﬁmum of the cost
functional in the problem (9)-(10), imply the inequalities

k = 1, 2, ... .

(25)

J ∗ ≤ J ∗,

J ∗ ≤ J ∗,

(26)

which yield the equality (20). Thus, the lemma is proven.

In the sequel of this paper, we deal with the optimal control problem (9)-
(10). We call this problem the Original Optimal Control Problem (OOCP). As
it was mentioned above, the OOCP is singular. Moreover, this problem does
not have, in general, an optimal control among regular functions.

2.4 Objectives of the paper

The objectives of this paper are:
(I) to establish ﬁniteness of the inﬁmum of the cost functional in the OOCP;
(II) to derive an expression for this inﬁmum;
(III) to design a minimizing sequence of state-feedback controls in the OOCP.

3 Regularization of the OOCP

3.1 Partial cheap control problem

Consider the optimal control problem with the dynamics (9) and the perfor-
mance index

Jε(u)

△
=

where

+∞Z0
(cid:2)zT (t)Dz(t) + uT (t)(G + E)u(t)(cid:3) dt → min
E = diag(cid:16) 0, ..., 0
| {z }q

| {z }

, ε2, ..., ε2

(cid:17),

r−q

u

,

(27)

(28)

and ε > 0 is a small parameter.

Remark 9 Since the parameter ε > 0 is small, the problem (9), (27) is a
partial cheap control problem, i.e., an optimal control problem where a cost of
some control coordinates in the cost functional is much smaller than costs of the

7

state and the other control coordinates. In what follows, we call this problem
the Partial Cheap Control Problem (PCCP). The case of the completely cheap
control was widely studied in the literature for various control problems (see e.g.
[21, 25, 26, 27, 28, 29, 30] and references therein). However, to the best of
the authors’ knowledge, the partial cheap control case was analyzed only in two
works. Namely, in [31] a two-time-scale decomposition of the time-invariant
regulator problem with partial cheap control was carried out, yielding a near-
optimal composite control. In [24], a ﬁnite-horizon zero-sum linear-quadratic
diﬀerential game with partial cheap control of the minimizing player was studied.

3.2 Optimal state-feedback control of the PCCP

We look for such a control in the same set of the admissible controls as was
introduced earlier for the OOCP, i.e., in the set Mu.

Consider the algebraic matrix Riccati equation

where

P A + AT P − P S(ε)P + D = 0,

S(ε) = B(G + E)−1BT .

(29)

(30)

By virtue of the inequality (18) and the results of [32], if for a given ε > 0

the equation (29) has a symmetric solution P ∗(ε) ≥ 0 such that the matrix

A(ε)

△

= A − S(ε)P ∗(ε)

(31)

is a Hurwitz one, then the optimal control of the PCCP exists in the set of the
admissible state-feedback controls Mu. This control is unique and it has the
form

ε(z, t) = −(G + E)−1BT P ∗(ε)z − (G + E)−1BT h(t),
u∗

(32)
where the n-dimensional vector-valued function h(t), t ∈ [0, +∞) is the unique
solution of the terminal-value problem

dh(t)

dt

= −AT (ε)h(t) − P ∗(ε)f (t),

h(+∞) = 0.

The optimal value of the cost functional in the PCCP has the form

ε = zT
J ∗

0 P ∗(ε)z0 + 2hT (0)z0 + s(0),

(33)

(34)

where the scalar function s(t), t ∈ [0, +∞) is the unique solution of the terminal-
value problem

ds(t)

dt

= −2hT (t)f (t) + hT (t)S(ε)h(t),

s(+∞) = 0.

(35)

8

4 Asymptotic Analysis of the PCCP

4.1 Asymptotic solution of the equation (29)

First of all, let as note that the matrix S(ε), appearing in this equation, can be
represented (similarly to the results of [24]) in the following block form:

where

S1

ST
2

S(ε) =
S1 =(cid:18) O(n−r)×(n−r) O(n−r)×q
eG−1

Oq×(n−r)

S2

(1/ε2)S3(ε)  ,
(cid:19) , S2 =(cid:18) O(n−r)×(r−q)

H1

(36)

(cid:19) ,

S3(ε) = ε2H2 + Ir−q,

(37)

(cid:19) ,
eG = diag(cid:0)g1, ..., gq(cid:1), H1 = H3HT , H2 = H(cid:18) O(n−r)×(r−q)
H3 =(cid:16)Oq×(n−r),eG−1(cid:17),

H1

H is deﬁned in (7).
Due to (36)-(38), the left-hand side of the equation (29) has a singularity at
ε = 0. To remove this singularity, we seek the symmetric solution P (ε) of the
equation (29) in the block form

(38)

P (ε) =

P1(ε)

εP T

2 (ε)

εP2(ε)

εP3(ε)  ,

where the blocks P1(ε), P2(ε) and P3(ε) have the dimensions (n − r + q) × (n −
r + q), (n − r + q) × (r − q) and (r − q) × (r − q), respectively; and

P T
1 (ε) = P1(ε), P T

3 (ε) = P3(ε).

We also partition the matrix A into blocks as follows:

(39)

(40)

(41)

where the blocks A1, A2, A3 and A4 have the dimensions (n− r + q)× (n− r + q),
(n − r + q) × (r − q), (r − q) × (n − r + q) and (r − q) × (r − q), respectively.
Substitution of the block representations for the matrices D, S(ε), P (ε),
and A (see (15), (36), (39), and (41)) into the equation (29) yields after a rou-
tine rearrangement the following equivalent set of Riccati-type algebraic matrix

A =

A1

A3

A2

A4

 ,

9

equations with respect to P1(ε), P2(ε) and P3(ε):

P1(ε)A1 + εP2(ε)A3 + AT
2 P1(ε) − εP1(ε)S2P T

−εP2(ε)ST

3 P T

1 P1(ε) + εAT
2 (ε) − P2(ε)S3(ε)P T

2 (ε) − P1(ε)S1P1(ε)
2 (ε) + D1 = 0,

P1(ε)A2 + εP2(ε)A4 + εAT

−ε2P2(ε)ST

1 P2(ε) + εAT

3 P3(ε) − εP1(ε)S1P2(ε)
2 P2(ε) − εP1(ε)S2P3(ε) − P2(ε)S3(ε)P3(ε) = 0,

2 (ε)A2 + εP3(ε)A4 + εAT

εP T
−ε2P3(ε)ST
We seek the asymptotic solution P as

2 P2(ε) − ε2P T

2 P2(ε) + εAT

2 (ε)S1P2(ε)
2 (ε)S2P3(ε) − P3(ε)S3(ε)P3(ε) + D2 = 0.

4 P3(ε) − ε2P T

i,m(ε), (i = 1, 2, 3) of the system (42)-(44)
i,m(ε) = Pi0 +εPi1 +...+εmPi,m, where m ≥ 0 is a given integer. In
in the form P as
what follows, we restrict ourselves to the case of zero-order asymptotic solution,
i.e., m = 0 and

P as

i,0(ε) = Pi0,

i = 1, 2, 3.

(45)

Equations for the zero-order asymptotic solution terms are obtained by substitu-
tion of (45) into (42)-(44) instead of Pi(ε), (i = 1, 2, 3), and equating coeﬃcients
for the zero power of ε on both sides of the resulting equations. Thus, we have
the following system:

P10A1 + AT

1 P10 − P10S1P10 − P20P T

20 + D1 = 0,

(42)

(43)

(44)

(46)

(47)

(48)

P10A2 − P20P30 = 0,
− D2 = 0.

(cid:0)P30(cid:1)2
=(cid:0)D2(cid:1)1/2

△

,

Solving the equations (48) and (47) with respect to P30 and P20, we obtain

P30 = P ∗
30

P20 = P10A2(cid:0)D2(cid:1)−1/2

,

(49)

where the superscript ”1/2” denotes the unique symmetric positive deﬁnite
square root of the corresponding symmetric positive deﬁnite matrix, while the
superscript ” − 1/2” denotes the inverse matrix for such a square root.

is positive deﬁnite, then there exists a positive number β such

Since(cid:0)D2(cid:1)1/2
that all eigenvalues λ(cid:16)−(cid:0)D2(cid:1)1/2(cid:17) of the matrix −(cid:0)D2(cid:1)1/2

satisfy the inequality

(50)

Reλ(cid:16) −(cid:0)D2(cid:1)1/2(cid:17) < −β.

Substitution of the expression for P20 from (49) into (46) yields the algebraic

matrix Riccati equation with respect to P10

P10A1 + AT

1 P10 − P10S0P10 + D1 = 0,

where

S0 = A2D−1

2 AT

2 + S1.

10

(51)

(52)

Based on the results of [24], we can represent the matrix S0 in the form

S0 = ¯BΘ−1 ¯BT ,

where

¯B =(cid:16) eB , A2 (cid:17) ,
eG

Θ =(cid:18)

O(r−q)×q

(cid:19) ,

Iq

eB =(cid:18) O(n−r)×q
(cid:19) .

Oq×(r−q)

D2

Let F1 be a matrix such that

D1 = F T

1 F1.

In what follows, we assume:

(A6) The pair (A1, ¯B) is stabilizable;
(A7) the pair (A1, F1) is detectable.

Using the equation (53), the assumptions (A6), (A7), and the results of [33],
one directly obtains that the algebraic matrix Riccati equation (51) has the
unique symmetric solution P ∗

10 ≥ 0. Moreover, the matrix

A0

△

= A1 − S0P ∗

10

(57)

is a Hurwitz one. Therefore, there exists a positive number α, (α 6= γ), such

that all eigenvalues λ(cid:16)A10(cid:17) of this matrix satisfy the inequality

Reλ(cid:16)A0(cid:17) < −α.

(53)

(54)

(55)

(56)

(58)

(59)

Now, using Lemma 5 (the positive deﬁniteness of the matrix D2), the above
mentioned features of the equation (51), and the results of [34] (Sections 3.4
and 3.6.1), we can state the following:

Lemma 10 Let the assumptions (A1)-(A3), (A5)-(A7) be valid. Then, there
exists a positive number ε0 such that for all ε ∈ [0, ε0] the equation (29) has the
unique symmetric solution P ∗(ε) ≥ 0. This solution has the block form

P ∗(ε) =(cid:18)

P ∗

1 (ε)

ε(cid:0)P ∗
2 (ε)(cid:1)T

ε P ∗
εP ∗

2(ε)

3 (ε) (cid:19) ,

1 (ε), P ∗

where the blocks P ∗
3 (ε) are of dimensions (n− r + q)× (n− r + q),
(n − r + q) × (r − q), (r − q) × (r − q), respectively. These blocks satisfy the
inequalities
(60)

2 (ε), P ∗

i = 1, 2, 3,

i0k ≤ aε,
; a > 0 is some constant independent of ε; k · k

ε ∈ [0, ε0],

20 = P ∗

where P ∗
denotes the Euclidean norm either of a matrix, or of a vector.
Moreover, the matrix A(ε), given by (31), is a Hurwitz one.

kP ∗
i (ε) − P ∗
10A2(cid:0)D2(cid:1)−1/2

11

4.2 Asymptotic solution of the problem (33)
Using the equations (31) and (36), (41), (59), we can represent the matrix A(ε)
in the block form

where

A2(ε)

(1/ε)A4(ε) (cid:19) ,
1 (ε) − εS2(cid:0)P ∗
2 (ε)(cid:1)T
2 (ε) − εS2P ∗
1 (ε) − S3(ε)(cid:0)P ∗
2 (ε)(cid:1)T
2 (ε) − S3(ε)P ∗

3 (ε).

3 (ε),

,

(1/ε)A3(ε)

A(ε) =(cid:18) A1(ε)
A1(ε) = A1 − S1P ∗
A2(ε) = A2 − εS1P ∗
A3(ε) = εA3 − εS2P ∗
A4(ε) = εA4 − ε2ST
f (t) =(cid:18) f1(t)
f2(t) (cid:19) ,

2 P ∗

(61)

(62)

(63)

(64)

(65)

,

t ≥ 0,

(66)

Also, let us partition the vector-valued function f (t) into blocks as follows:

where the blocks f1(t) and f2(t) are of the dimensions n − r + q and r − q,
respectively.

We look for the solution of the problem (33) in the block form

h(t, ε) =(cid:18) h1(t, ε)

εh2(t, ε) (cid:19) ,

t ≥ 0,

(67)

where the blocks h1(t, ε) and h2(t, ε) are of the dimensions n − r + q and r − q,
respectively.
Substitution of the block representations for A(ε), P ∗(ε), f (t) and h(t, ε)
into the problem (33) yields the following initial-value problem, equivalent to
(33):

dh1(t, ε)

dt

dh2(t, ε)

2 (ε)f2(t),

(68)

= −AT

1 (ε)h1(t, ε) − AT

3 (ε)h2(t, ε) − P ∗
4 (ε)h2(t, ε) − ε(cid:0)P ∗

1 (ε)f1(t) − εP ∗
2 (ε)(cid:1)T

ε

dt

= −AT

2 (ε)h1(t, ε) − AT

3 (ε)f2(t),
(69)
(70)
Let us construct the zero-order asymptotic solutions {h10(t), h20(t)} of the prob-
lem (68)-(70). The equations for this asymptotic solution are obtained from the
system (68)-(69) by setting there formally ε = 0 and using Lemma 10. Thus,
we have

h2(+∞, ε) = 0.

h1(+∞, ε) = 0,

f1(t) − εP ∗

dh10(t)

dt

= −AT
0 = −AT

1 (0)h10(t) − AT

3 (0)h20(t) − P ∗

10f1(t),

2 (0)h10(t) − AT

4 (0)h20(t).

(71)

(72)

12

The terminal condition for h10(t) is obtained from the condition for h1(t, ε) (see
(70)) by formal replacing there h1(+∞, ε) with h10(+∞), i.e.,

h10(+∞) = 0.

(73)

Solving the equation (72) with respect to h20(t), and taking into account

that A4(0) = −P ∗

and A2(0) = A2, we obtain

AT

2 h10(t).

(74)

30 = −(cid:0)D2(cid:1)1/2

h20(t) =(cid:0)D2(cid:1)−1/2

Substitution of (74) into (71) and using the expressions A1(0) = A1 − S1P ∗
10,
, as well as the equations (52), (57) and the expression for P ∗
20

(see Lemma 10), yield the diﬀerential equation for h10(t)

20(cid:1)T
A3(0) = −(cid:0)P ∗

dh10(t)

dt

= −AT

0 h10(t) − P ∗

10f1(t).

(75)

Due to the inequalities (18) and (58), this equation, subject to the condition
(73), has the unique solution

satisfying the inequality

h10(t) =Z +∞

0

exp(cid:0)AT

0 ζ(cid:1)P ∗
(cid:13)(cid:13)h10(t)(cid:13)(cid:13) ≤ a exp(−γt),

10f1(ζ + t)dζ,

t ≥ 0,

t ≥ 0

(76)

(77)

where a > 0 is some constant.

yields

The equation (74), along with the condition (73) and the inequality (77),

h20(+∞) = 0,

(cid:13)(cid:13)h20(t)(cid:13)(cid:13) ≤ a exp(−γt),

t ≥ 0,

(78)

(79)

This completes the formal construction of the zero-order asymptotic solution

where a > 0 is some constant.

of the problem (68)-(70).

Lemma 11 Let the assumptions (A1)-(A7) be valid. Then, there exists a posi-

tive number ε1, (ε1 ≤ ε0), such that for all ε ∈ (0, ε1] the solution(cid:8)h1(t, ε), h2(t, ε)(cid:9)

of the terminal-value problem (68)-(70) satisﬁes the inequalities

(cid:13)(cid:13)hi(t, ε) − hi0(t)(cid:13)(cid:13) ≤ cε exp (−µt) ,

µ = min{α, γ},

i = 1, 2,

t ≥ 0,

(80)

(81)

where

c > 0 is some constant independent of ε.

The proof of the lemma is presented in Appendix A.

13

4.3 Asymptotic solution of the problem (35)

Using the block form of the matrix S(ε), and the vectors f (t) and h(t, ε) (see
(36), (66), (67)), we can rewrite equivalently the problem (35) as follows:

ds(t, ε)

= −2(cid:0)hT

dt
+2εhT

1 (t, ε)S2h2(t, ε) + hT

1 (t, ε)f1(t) + εhT

2 (t, ε)f2(t)(cid:1) + hT

2 (t, ε)S3(ε)h2(t, ε),

1 (t, ε)S1h1(t, ε)
s(+∞, ε) = 0.

(82)

Let us construct the zero-order asymptotic solutions s0(t) of the problem
(82). The equation for this asymptotic solution is obtained from the diﬀerential
equation in (82) by setting there formally ε = 0 and using Lemma 11. Thus, we
have

ds0(t)

dt

= −2hT

10(t)f1(t) + hT

10(t)S1h10(t) + hT

20(t)h20(t).

(83)

Substituting the expression for h20(t) (see (74)) into the right-hand side of (83),
and using (52), we obtain

ds0(t)

dt

= −2hT

10(t)f1(t) + hT

10(t)S0h10(t).

(84)

The terminal condition for s0(t) is obtained from the condition for s(t, ε) in (82)
by formal replacing there s(+∞, ε) with s0(+∞), i.e.,

s0(+∞) = 0.

(85)

The solution of the problem (84)-(85) has the form

s0(t) =Z +∞

t

(cid:16)2hT
10(σ)f1(σ) − hT

10(σ)S0h10(σ)(cid:17)dσ,

t ≥ 0.

(86)

Due to the inequalities (18) and (77), the integral in (86) converges. This
completes the formal construction of the zero-order asymptotic solution of the
problem (82). Similarly to Lemma 11, we obtain the following lemma:

Lemma 12 Let the assumptions (A1)-(A7) be valid. Then, there exists a pos-
itive number ε2, (ε2 ≤ ε1), such that for all ε ∈ (0, ε2] the solution s(t, ε) of the
terminal-value problem (82) satisﬁes the inequality

where c > 0 is some constant independent of ε.

(cid:13)(cid:13)s(t, ε) − s0(t)(cid:13)(cid:13) ≤ cε,

t ≥ 0,

(87)

4.4 Asymptotic expansion of the optimal value of the cost

functional

Let us partition the vector z0 into blocks as:

y0 (cid:19) ,
z0 =(cid:18) x0

x0 ∈ En−r+q,

y0 ∈ Er−q.

(88)

14

Let us introduce the value

¯J ∗ △

= xT

0 P ∗

10x0 + 2h10(0)x0 + s0(0).

(89)

Lemma 13 Let the assumptions (A1)-(A7) be valid.Then, the following in-
equality is satisﬁed:

(cid:12)(cid:12)J ∗
ε − ¯J ∗(cid:12)(cid:12) ≤ cε,

where J ∗
constant independent of ε.

ε is the optimal value of the cost functional in the PCCP; c > 0 is some

ε ∈ (0, ε2],

(90)

Proof. The statement of the lemma is a direct consequence of the equation
(34) and Lemmas 10, 11, 12.

4.5 Reduced optimal control problem

Consider the following controlled diﬀerential equation:

d¯x(t)

dt

= A1x(t) + ¯B ¯u(t) + f1(t), t ≥ 0, x(0) = x0,

(91)

where x(t) ∈ En−r+q is the state vector, ¯u(t) ∈ Er is the control, the matrix ¯B
is given in (54).

The cost functional, to be minimized by ¯u(t), has the form

¯J(¯u) =Z +∞

0

(cid:0)¯xT (t)D1 ¯x(t) + ¯uT (t)Θ¯u(t)(cid:1)dt,

where the matrix Θ is given by (55).

(92)

We call the problem (91)-(92) the Reduced Optimal Control Problem (ROCP).
Consider the set ¯P of all functions ¯p( ¯w, t) : En−r+q × [0, +∞) → Er, which
t ≥ 0 for any ﬁxed ¯w ∈ En−r+q and satisfy the local

are measurable w.r.t.
Lipschitz condition w.r.t. ¯w ∈ En−r+q uniformly in t ≥ 0.
Deﬁnition 14 Let ¯u(¯x, t), (¯x, t) ∈ En−r+q × [0, +∞), be a function belong-
ing to the set ¯P. The function ¯u(¯x, t) is called an admissible state-feedback
control in the ROCP if the following conditions hold: (a) the initial-value prob-
lem (91) for ¯u(t) = ¯u(¯x, t) has the unique locally absolutely continuous solu-
tion ¯x(t) on the entire interval [0, +∞); (b) ¯x(t) ∈ L2 [0, +∞; En−r+q]; (c)

¯u(cid:0)¯x(t), t(cid:1) ∈ L2 [0, +∞; Er]. The set of all such ¯u(¯x, t) is denoted by ¯Mu.

Lemma 15 Let the assumptions (A1)-(A7) be valid. Then, the optimal control
of the ROCP exists in the set ¯Mu. This control is unique and it has the form

¯u∗(¯x, t) = −Θ−1 ¯BT P ∗

10 ¯x − Θ−1 ¯BT h10(t).

(93)

The optimal value of the cost functional in the ROCP is ¯J ∗, having the form
(89).

15

Proof. Based on Lemmas 10, 11, 12, the statements of the lemma directly
follow from the results of [32].

Remark 16 Based on the block form of the matrices ¯B and Θ (see (54) and
(55)), the optimal state-feedback control ¯u∗(¯x, t) of the ROCP can be represented
as follows:

where

1(¯x, t)
¯u∗

¯u∗(¯x, t) =(cid:18) ¯u∗
1(¯x, t) = −eG−1eBT P ∗
¯u∗
2(¯x, t) = −D−1
¯u∗

2(¯x, t) (cid:19) ,
10 ¯x − eG−1eBT h10(t),
10 ¯x − D−1

2 h10(t).

2 AT

2 P ∗

2 AT

(94)

(95)

(96)

5 Main Results

For any ε ∈ (0, ε2], consider two state-feedback controls in the OOCP. The ﬁrst
control uε,1(z, t) is obtained from the optimal control in the PCCP (see (32)) by
replacing the matrix P ∗(ε) and the vector h(t) with the following matrix and
vector, respectively:

P ∗

10

0 (ε) =(cid:18) P ∗
20(cid:1)T
ε(cid:0)P ∗

Thus, we have

εP ∗
20
εP ∗

30 (cid:19) ,

h0(t, ε) =(cid:18) h10(t)

εh20(t) (cid:19) .

(97)

uε,1 (z, t) = − (Gu + E)−1 BT P ∗

0 (ε) − (Gu + E)−1 BT h0(t, ε).

(98)

In (97) and (98), {P ∗

30} and {h10(t), h20(t)} are the asymptotic so-
lutions of the system (42)-(44) and the terminal-value problem (68)-(70), re-
spectively.

20, P ∗

10, P ∗

Lemma 17 Subject to the assumptions (A1)-(A7), the state-feedback control
uε,1(z, t) can be represented in the block form as:

uε,1(z, t) = −

K1(ε)x + εK2(ε)y + H3h10(t) + εH1h20(t)

(1/ε)h (P ∗

20)T x + P ∗

30y + h20(t)i

△

K1(ε)

= H3P ∗

10 + εH1 (P ∗

20)T , K2(ε)

△

= H3P ∗

20 + H1P ∗
30;

where

H1 and H3 are deﬁned in (38);

z = col(cid:0)x, y(cid:1),

x ∈ En−r+q,

y ∈ Er−q.

16



(99)

(100)

(101)

Proof. Using the results of [24] (proof of Lemma 8), we can transform the
matrix (Gu + E)−1BT into the following block-form one:
H1

(102)

(Gu + E)−1BT =(cid:18) H3

O(r−q)×(n−r+q)

(1/ε2)Ir−q (cid:19) .

Now, the substitution of (97), (101) and (102) into (98) yields immediately the
equation (99).

By calculation of the point-wise (with respect to (z, t) ∈ En × [0, +∞)) limit
of the upper block in (99) for ε → 0+ we obtain the second state-feedback
control in the OOCP

uε,2(z, t) =

¯u∗
1(x, t)

−(1/ε)h(cid:0)P ∗
20(cid:1)T

where ¯u∗

1(·,·) is given by (95).

x + P ∗

30y + h20(t)i

 ,

(103)

Lemma 18 Let the assumptions (A1)-(A7) be valid. Then, there exists a pos-
itive number ˆε, (ˆε ≤ ε2), such that for all ε ∈ (0, ˆε] the state feedback controls
uε,i(z, t), (i = 1, 2) are admissible in the OOCP.

The proof is presented in Appendix B.

Remark 19 Due to Lemma 18, the set Mu of admissible state-feedback controls
in the OOCP in nonempty. Therefore, due to Remark 6, the inﬁmum J ∗ of the
cost functional in the OOCP (see (19)) is ﬁnite.

Theorem 20 Let the assumptions (A1)-(A7) be valid. Then, the following
equality is satisﬁed:

(104)
where ¯J ∗ is the optimal value of the cost functional in the ROCP given by (89).

J ∗ = ¯J ∗,

Proof. We prove the theorem by contradiction. Namely, let us assume that
(104) is wrong. This means the fulﬁlment of the inequality

J ∗ 6= ¯J ∗.

Let us show that the inequality (105) yields the inequality

J ∗ < ¯J ∗.

(105)

(106)

First of all note, that the control u∗

ε(z, t) (see (32)), being optimal in the
PCCP for all ε ∈ (0, ˆε], belongs to the set Mu for these values of ε. Now,
using the equations (10), (19), (27), we directly obtain the following chain of
inequalities and equalities:

J ∗ ≤ J(cid:0)u∗

ε(z, t)(cid:1) ≤ Jε(cid:0)u∗

ε(z, t)(cid:1) = J ∗

ε ,

17

ε ∈ (0, ˆε].

(107)

where

(111)

(112)

Moreover, from the inequality (90), we have for all ε ∈ (0, ˆε]

¯J ∗ − cε ≤ J ∗
Remember that c > 0 is independent of ε.

ε ≤ ¯J ∗ + cε.

The inequalities (107)-(108) imply the inequality

J ∗ ≤ ¯J ∗ + cε,

ε ∈ (0, ˆε].

(108)

(109)

The inequalities (105) and (109), yield immediately the inequality (106).

such that

Since (106) is valid, then there exists a state-feedback control ˜u(z, t) ∈ Mu
(110)

Since u∗

ε(z, t) is the optimal control in the PCCP, then the following inequal-

J ∗ ≤ J(cid:0)˜u(z, t)(cid:1) < ¯J ∗.
ε(z, t)(cid:1) ≤ Jε(cid:0)˜u(z, t)(cid:1) = J(cid:0)˜u(z, t)(cid:1) + bε2,
2(cid:0)˜z(t), t(cid:1)˜u2(cid:0)˜z(t), t(cid:1)dt < +∞;

˜uT

J ∗

ε = Jε(cid:0)u∗
0 ≤ b =Z ∞

0

ity is satisﬁed for any ε ∈ (0, ˆε]:

˜u2(z, t) is the lower block of the dimension r − q of the vector ˜u(z, t); ˜z(t), t ≥ 0
is the solution of (9) generated by ˜u(z, t).

The inequalities (108) and (111) directly lead to the inequality

¯J ∗ ≤ J(cid:0)˜u(z, t)(cid:1) + cε + bε2,

ε ∈ (0, ˆε],

(113)

which yields immediately ¯J ∗ ≤ J(cid:0)˜u(z, t)(cid:1). The latter contradicts to the right-

hand side of the inequality (110). This contradiction proves the equality (104).
Thus, the theorem is proven.

Consider a numerical sequence {εk} such that

0 < εk ≤ ˆε,

k = 1, 2, ...;

lim

k→+∞

εk = 0.

(114)

For the system (9), consider the following two sequences of state-feedback

controls: {uεk,i(z, t)}, (i = 1, 2), (k = 1, 2, ...).
Theorem 21 Let the assumptions (A1)-(A7) be valid. Then, the following
limit equations are satisﬁed:

lim

k→+∞

J(cid:0)uεk,i(z, t)(cid:1) = J ∗,

i = 1, 2,

(115)

meaning that the sequences of state-feedback controls {uεk,i(z, t)}, (i = 1, 2),
(k = 1, 2, ...) are minimizing in the OOCP (9)-(10).

The proof of the theorem is presented in Appendix C.

18

Remark 22 Note that the upper block of the OOCP minimizing control se-
quence {uεk,2(z, t)}, (k = 1, 2, ...) and the inﬁmum of the cost functional in the
OOCP coincide with the upper block of the optimal state-feedback control and
the optimal value of the cost functional, respectively, in the ROCP (91)-(92).
The latter control problem is regular and is of a smaller dimension than the
OOCP. Thus, in order to solve the singular OOCP, one has to solve the smaller
dimension regular ROCP, construct two gain matrices P ∗
30, using the
equations (49), and construct the vector-valued function h20(t), using the equa-
tion (74).

20 and P ∗

6 Example: Inﬁnite Horizon Tracking

Consider a body of the unit mass subject to an actuator force u(t). Let ˜x(t) be
the inertial position of the body. This dynamics is described by the following
diﬀerential equation and initial conditions

d2 ˜x(t)
dt2 = u(t),

t ≥ 0,

˜x(0) = ˜x0,

d˜x(0)

dt

= ˜x

′

0.

Let us denote

t ≥ 0,
Thus, the problem (116) can be rewritten as:

˜y(t)

dt

,

d˜x(t)

△
=

˜y0

△
= ˜x

′

0.

d˜x(t)

dt

d˜y(t)

dt

= ˜y(t),

= u(t),

t ≥ 0,

t ≥ 0,

˜x(0) = ˜x0,

˜y(0) = ˜y0,

(116)

(117)

(118)

(119)

where ˜x(t) and ˜y(t) are the scalar state variables, u(t) is the scalar control.

The objective of the control of the system (118)-(119) is a trajectory track-
ing. Let ˜xnom(t) = ˜f1(t) and ˜ynom(t) = ˜f2(t), t ∈ [0, +∞), be given nominal
trajectories of the body position and the velocity, respectively. Thus, the per-
formance index for the system’s control can be chosen as:

˜J(u)

△

=Z +∞

0

(cid:16)d1(cid:0)˜x(t) − ˜f1(t)(cid:1)2

+ d2(cid:0)˜y(t) − ˜f2(t)(cid:1)2(cid:17)dt → min

u(t)

where d1 > 0 and d2 > 0 are given constants.

,

(120)

Remark 23 Since the control u(t) does not appear in the cost functional J(u),
the optimal control problem (118)-(120) is singular.

Also, let us choose ˜f1(t) and ˜f2(t) as:

˜f1(t) = ˜a1 exp(−γt),

˜f2(t) = ˜a2 exp(−γt),

(121)

where ˜a1 > 0, ˜a2 > 0 and γ > 0 are given constants.

19

Now, we make the following transformation of the state variables in the

problem (118)-(120):

x(t) = ˜x(t) − ˜f1(t),

y(t) = ˜y(t) − ˜f2(t).

(122)

Due to this transformation, we obtain a new optimal control problem, equivalent
to (118)-(120). Namely,

dx(t)

dt

dy(t)

dt

= y(t) + f1(t),

= u(t) + f2(t),

t ≥ 0,

t ≥ 0,

x(0) = x0,

y(0) = y0,

△

=Z +∞

0

(cid:16)d1(cid:0)x(t)(cid:1)2

+ d2(cid:0)y(t)(cid:1)2(cid:17)dt → min

u(t)

,

J(u)

where

f1(t) = a1 exp(−γt),

f2(t) = a2 exp(−γt),

t ≥ 0,

a1 = ˜a1γ + ˜a2,
x0 = ˜x0 − ˜a1,

a2 = ˜a2γ,
y0 = ˜x0 − ˜a2.

(128)
In the problem (123)-(125), the nominal trajectory is {xnom(t) ≡ 0, ynom(t) ≡
0}.
Based on the results of the previous sections, proceed to solution of (123)-
(125). First of all, let us note that this problem is a particular case of the OOCP
(9)-(10) for n = 2, r = 1, q = 0, and

(123)

(124)

(125)

(126)

(127)

A1 = 0, A2 = 1, A3 = 0, A4 = 0, B1 = 0, B2 = 1,

(129)

D1 = d1, D2 = d2, G = 0.

(130)

For the problem (123)-(125), S0 =(cid:16) 1
+ 1(cid:19)(cid:0)P10(cid:1)2

−(cid:18) 1

d2

d2

+ 1(cid:17), and the equation (51) becomes

+ d1 = 0.

(131)

The matrices ¯B and F1 (see (54) and (56)) are the scalars ¯B = A2 = 1 and
F1 = 1/√d1 > 0, meaning that the assumptions (A6) and (A7) are valid. The
equation (131) has two solutions, positive and negative. We choose the positive
solution of this equation, i.e.,

P ∗

10 =r d1d2

1 + d2

.

Due to this equation and the equation (49), we have

P ∗

20 =r d1

1 + d2

,

P ∗

30 =pd2.

20

(132)

(133)

Using (57), we obtain

A0 = −s d1(1 + d2)

d2

< 0.

(134)

Now, let us obtain h10(t), h20(t) and s0(t). Using the equations (74), (76)

and (86), as well as the data of the example (126), (129-(130), we obtain

exp(−γt),

exp(−γt),

t ≥ 0,

t ≥ 0,

h10(t) =

h20(t) =

a1P ∗
10
γ − A0
a1P ∗
20
γ − A0
a2
1P ∗
10(2γ − A0)
2γ(γ − A0)2

(135)

(136)

(137)

s0(t) =

exp(−2γt),

t ≥ 0.

Due to Theorem 20, and the equations (89), (135) and (137), the inﬁmum

of the cost functional J(u) in the optimal control problem (123)-(125) is

J(u) = P ∗

10"(cid:18)x0 +

a1

γ − A0(cid:19)2

−

2γ(γ − A0)2# > 0.

a2
1A0

inf
u

(138)

Finally, using Theorem 21, as well as the equation (99) and the fact that q = 0,
yields the minimizing sequence in the optimal control problem (123)-(125)

uεk (z, t) = −

20x + P ∗

1

εk(cid:0)P ∗

30y + h20(t)(cid:1),

z = col(x, y),

k = 1, 2, ....

(139)

21

Figure 1: x-component of the trajectory of the system (123)-(124)

22

Figure 2: y-component of the trajectory of the system (123)-(124)

23

Figure 3: Time realization of uεk (z, t)

In Figs. 1 and 2, the x- and y-components of the trajectory of the system
(123)-(124), generated by the control (139) with diﬀerent values of εk, are de-
picted for the following numerical data: a1 = 4, a2 = 2, γ = 1, x0 = 2, y0 = 1,
d1 = 2, d2 = 1. It is seen that both components tend to the components of
the nominal trajectory for t → +∞. Moreover, for the smaller εk, the rate of
this convergence is larger. In Fig. 3, the time realization of the control (139)
along the trajectory of the system (123)-(124), depicted in Figs. 1–2, is pre-
sented. It is seen that for εk approaching zero, this time realization tends to an
impulse-like function with the impulse at t = 0.

7 Concluding Remarks

CRI. In this paper, an inﬁnite horizon linear-quadratic optimal control prob-
lem for a system with known time-varying additive disturbance is considered.
A weight matrix of the control cost in the cost functional of this problem is

24

singular but, in general, non-zero. Due to this singularity of the weight matrix,
the optimal control problem itself is singular. However, if the weight matrix
is non-zero, only a part of the coordinates of the control is singular, while the
others are regular.
CRII. Subject to proper assumptions, the linear system of the control problem
is transformed equivalently to a new system consisting of three modes. The ﬁrst
mode is uncontrolled directly (i.e.
it does not contain the control at all), the
second mode is controlled directly only by the regular coordinates of the control,
while the third mode is controlled directly by the entire control. Due to this
transformation, a new control problem, equivalent to the initially formulated
one, is obtained. This new singular optimal control problem is considered as an
original one in the paper.
CRIII. The original control problem is solved by a regularization approach,
i.e., by its approximate transformation to an auxiliary regular optimal control
problem. The latter has the same equation of dynamics and a similar cost func-
tional augmented by an inﬁnite horizon integral of the squares of the singular
control coordinates with a small positive weight. Hence, the auxiliary problem is
an inﬁnite horizon linear-quadratic optimal control problem with partial cheap
control. An asymptotic analysis of this problem is carried out.
CRIV. Based on this asymptotic analysis, it is shown that the inﬁmum of the
cost functional in the original (singular) optimal control problem is ﬁnite. The
explicit expression of this inﬁmum is derived. The minimizing state-feedback
control sequence in the original problem also is designed. Some coordinates
of the minimizing sequence are convergent in the class of regular functions.
Namely, the coordinates of the minimizing sequence, corresponding to the regu-
lar control coordinates, are point-wise convergent in this class of functions. The
corresponding limits constitute the regular part of the optimal state-feedback
control in the original problem.
CRV. It is shown that the inﬁmum of the cost functional and the regular part
of the optimal state-feedback control in the original singular problem coincide
with the optimal value of the cost functional and the upper block of the optimal
state-feedback control, respectively, in a reduced dimension regular optimal con-
trol problem (reduced control problem). The dimension of the upper block of
the optimal state-feedback control in the reduced control problem equals to the
number of the regular coordinates of the control in the original problem. The
reduced control problem is connected with the zero-order asymptotic solutions
of the equations, arising in the optimality conditions of the auxiliary partial
cheap control problem.
CRVI. Using the obtained theoretical results, the problem of singular inﬁnite
horizon trajectory tracking with two scalar state variables and a scalar control
is solved. Numerical simulation shows that the state-feedback controls of the
minimizing sequence generate trajectories, approaching well enough the nom-
inal ones. The time-realizations of these state-feedback controls tend to an
impulse-like function with the impulse at t = 0.

25

8 Appendix A: Proof of Lemma 11

8.1 Auxiliary results
Let for a given ε > 0, the matrix-valued function Ψ(t, ε), t ≥ 0 of the dimension
(m1 + m2) be the solution of the following initial-value problem:

dΨ(t, ε)

dt

= C(ε)Ψ(t, ε), Ψ(0, ε) = Im1+m2 ,

(140)

where a given (m1 + m2)-matrix C(ε) has the block form

C(ε) =(cid:18) C1(ε)

(1/ε)C3(ε)

C2(ε)

(1/ε)C4(ε) (cid:19) ,

(141)

the blocks C1(ε), C2(ε), C3(ε) and C4(ε) are of the dimensions m1×m1, m1×m2,
m2 × m1 and m2 × m2, respectively.

Represent the matrix Ψ(t, ε) in the block form

Ψ(t, ε) =(cid:18) Ψ1(t, ε) Ψ2(t, ε)
Ψ3(t, ε) Ψ4(t, ε) (cid:19) ,

(142)

where the blocks Ψ1(t, ε), Ψ2(t, ε), Ψ3(t, ε), and Ψ4(t, ε) are of the dimensions
m1 × m1, m1 × m2, m2 × m1 and m2 × m2, respectively.
Proposition 24 Let there exists a positive number ˇε such that the matrices
Cj(ε), (j = 1, ..4) are continuous with respect to ε ∈ [0, ˇε]. Let, there exists a

positive number ω such that all the eigenvalues λ(cid:16)C4(ε)(cid:17) of the matrix C4(ε)

satisfy the inequality

Let, there exists a positive number κ such that all the eigenvalues λ(cid:16) ¯C(ε)(cid:17) of

△

4 (ε)C3(ε) satisfy the inequality

the matrix ¯C(ε)

= C1(ε) − C2(ε)C −1

ε ∈ [0, ˇε].

(143)

Reλ(cid:16)C4(ε)(cid:17) < −ω,

Reλ(cid:16) ¯C(ε)(cid:17) < −κ,

ε ∈ [0, ˇε].

(144)

Then, there exists a positive number ¯ε, (¯ε ≤ ˇε), such that for all ε ∈ (0, ¯ε], the
following inequalities are satisﬁed:

(cid:13)(cid:13)Ψi(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ a exp(cid:0) − κt(cid:1),

(cid:13)(cid:13)Ψ2(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ aε exp(cid:0) − κt(cid:1),

(cid:13)(cid:13)Ψ4(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ a(cid:16)ε exp(cid:0) − κt(cid:1) + exp(cid:0) − ωt/ε(cid:1)(cid:17),

where a > 0 is some constant independent of ε.

i = 1, 3,

0 ≤ t < +∞,

0 ≤ t < +∞,

0 ≤ t < +∞,

(145)

(146)

(147)

26

Proof. The statement of the proposition directly follows from the results of
[35] (Theorem 2.3).

Now, let us set m1 = n − r + q, m2 = r − q and
C1(ε) = AT
3 (ε), C3(ε) = AT

1 (ε), C2(ε) = AT

2 (ε), C4(ε) = AT

4 (ε).

(148)

Corollary 25 Let the assumptions (A1)-(A3), (A5)-(A7) be valid. Then, there
exists a positive number ¯ε0, (¯ε0 ≤ ε0), such that for all ε ∈ (0, ¯ε0] the following
inequalities are satisﬁed:

(cid:13)(cid:13)Ψi(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ a exp(cid:0) − αt(cid:1),

(cid:13)(cid:13)Ψ2(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ aε exp(cid:0) − αt(cid:1),

(cid:13)(cid:13)Ψ4(cid:0)t, ε(cid:1)(cid:13)(cid:13) ≤ a(cid:16)ε exp(cid:0) − αt(cid:1) + exp(cid:0) − βt/ε(cid:1)(cid:17),

where a > 0 is some constant independent of ε.

i = 1, 3,

0 ≤ t < +∞,

0 ≤ t < +∞,

0 ≤ t < +∞,

(149)

(150)

(151)

Proof. First of all note that, due to the equations (62)-(65) and Lemma 10,
the matrices Cj (ε), (j = 1, ..4), given by (148), are continuous with respect to
ε ∈ [0, ε0].

Using the equations (37), (49), (62)-(65), (148) and Lemma 10, we obtain

10S1 + ∆C1(ε),

C1(ε) = AT

1 − P ∗
10A2(cid:0)D2(cid:1)−1/2
C2(ε) = −P ∗
C4(ε) = −(cid:0)D2(cid:1)1/2

C3(ε) = AT

2 + ∆C3(ε),

+ ∆C4(ε),

+ ∆C2(ε),

where ∆Cj(ε), (j = 1, ..., 4) are some matrices satisfying the inequalities

(152)

(153)

(154)

(155)

(156)

(cid:13)(cid:13)∆Cj (ε)(cid:13)(cid:13) ≤ aε,

j = 1, ..., 4.

ε ∈ [0, ε0],

a > 0 is some constant independent of ε.

The equation (155) and the inequalities (50), (156) directly yield the exis-

tence of a positive number ¯ε1, (¯ε1 ≤ ε0), such that all the eigenvalues λ(cid:16)C4(ε)(cid:17)

of the matrix C4(ε) satisfy the inequality

Reλ(cid:16)C4(ε)(cid:17) < −β,

ε ∈ [0, ¯ε1].

(157)

Now, based on (152)-(157) and (57), we immediately obtain that the matrix
¯C(ε) = C1(ε) − C2(ε)C −1

4 (ε)C3(ε) can be represented as:

where ∆C(ε) is some matrix satisfying the inequality

¯C(ε) = AT

0 + ∆C(ε),

(cid:13)(cid:13)∆C(ε)(cid:13)(cid:13) ≤ aε,

27

ε ∈ [0, ¯ε1].

(158)

(159)

From the equation (158), and the inequalities (58) and (159), we directly
obtain the existence of a positive number ¯ε2, (¯ε2 ≤ ¯ε1), such that all the eigen-

values λ(cid:16) ¯C(ε)(cid:17) of the matrix ¯C(ε) satisfy the inequality

Reλ(cid:16) ¯C(ε)(cid:17) < −α,

ε ∈ [0, ¯ε2].

(160)

Thus, we have shown that the blocks (148) of the matrix C(ε) satisfy all the
conditions of Proposition 24, which completes the proof of the corollary.

8.2 Main part of the proof

Let ∆1(t, ε) and ∆2(t, ε) be vectors, deﬁned as follows:

∆1(t, ε)

△

= h1(t, ε) − h10(t), ∆2(t, ε)

△

= h2(t, ε) − h20(t),

t ≥ 0.

(161)

Substitution of (161) into (68)-(70), and using (71)-(72), (73) and (78) yield

the problem for ∆1(t, ε) and ∆2(t, ε)

d∆1(t, ε)

dt

ε

d∆2(t, ε)

dt

where

= −AT

1 (ε)∆1(t, ε) − AT

3 (ε)∆2(t, ε) + Γ1(t, ε),

2 (ε)∆1(t, ε) − AT

= −AT
∆1(+∞, ε) = 0,

∆2(+∞, ε) = 0,

4 (ε)∆2(t, ε) + Γ2(t, ε),

Γ1(t, ε) =(cid:0)AT
Γ2(t, ε) =(cid:0)AT

1 (0) − AT

2 (0) − AT

10 − P ∗

1 (ε)(cid:1)h10(t) +(cid:0)AT
3 (0) − AT
+(cid:0)P ∗
1 (ε)(cid:1)f1(t) − εP ∗
2 (ε)(cid:1)h10(t) +(cid:0)AT
4 (0) − AT
−ε(cid:0)P ∗
2 (ε)(cid:1)T
f1(t) − εP ∗

2 (ε)f2(t),

3 (ε)(cid:1)h20(t)
4 (ε)(cid:1)h20(t)

3 (ε)f2(t).

(162)

(163)

(164)

(165)

(166)

Using the equations (37)-(38), (62)-(65), Lemma 10 (the inequalities (60)),

and the inequalities (18), (77), (79), we directly have

(cid:13)(cid:13)Γi(t, ε)(cid:13)(cid:13) ≤ aε exp(−γt),

△

i = 1, 2,

t ≥ 0,

ε ∈ (0, ˜ε0],

(167)

where ˜ε0

= min{1, ε0}; a > 0 is some constant independent of ε.

Using the equations (140)-(142) and (148), we can represent the solution of

the problem (162)-(164) as follows:

∆1(t, ε) =Z +∞

0

(cid:16)Ψ1(σ, ε)Γ1(σ + t, ε) + (1/ε)Ψ2(σ, ε)Γ2(σ + t, ε)(cid:17)dσ, t ≥ 0,

(168)

28

∆2(t, ε) =Z +∞

0

(cid:16)Ψ3(σ, ε)Γ1(σ + t, ε) + (1/ε)Ψ4(σ, ε)Γ2(σ + t, ε)(cid:17)dσ, t ≥ 0.

(169)
These equations, along with the inequalities (149)-(151) and (167), directly yield
the inequalities

(cid:13)(cid:13)∆i(t, ε)(cid:13)(cid:13) ≤ cε exp(−µt),

where ε1 = min{¯ε0, ˜ε0}, c > 0 is some constant independent of ε.
equalities (80). This completes the proof of the lemma.

The equation (161) and the inequalities (170) immediately imply the in-

i = 1, 2,

t ≥ 0,

ε ∈ (0, ε1],

(170)

9 Appendix B: Proof of Lemma 18

We prove the lemma for uε,1(z, t). The admissibility of uε,2(z, t) is shown simi-
larly.

Substitution of uε,1 (z, t) into (9), and using the equations (30), (36)-(38),
(41), (66), (88) and (101) yield the following initial-value problem in the interval
t ∈ [0, +∞):
dx(t)

= A10(ε)x(t) + A20(ε)y(t) − S1h10(t) − εS2h20(t) + f1(t),

x(0) = x0,
(171)

ε

dy(t)

dt

= A30(ε)x(t) + A40(ε)y(t)
y(0) = y0,

−εST

2 h10(t) − S3(ε)h20(t) + εf2(t),

A10(ε) = A1 − S1P ∗
A20(ε) = A2 − εS1P ∗
A30(ε) = εA3 − εS2P ∗
A40(ε) = εA4 − ε2ST

10 − εS2(cid:0)P ∗
20(cid:1)T
20 − εS2P ∗
30,
20(cid:1)T
10 − S3(ε)(cid:0)P ∗
20 − S3(ε)P ∗
30.

2 P ∗

,

,

(172)

(173)

(174)

(175)

dt

where

(176)
For any ε ∈ (0, ε0], the problem (171)-(172) has the unique locally absolutely
Using the inequalities (18), (77), (79), one can obtain (similarly to the in-

continuous solution z(t, ε) = {x(t, ε), y(t, ε)}, t ∈ [0, +∞).
equalities (170)) the following inequalities:
kx(t, ε)k ≤ a exp(−µt),
ε ∈ (0, ˇε1], (177)
where ˇε1 > 0, (ˇε1 ≤ ε2) is some constant; a > 0 is some constant independent
of ε; the constant µ is given by (81).
Due to (177), z(t, ε) ∈ L2[0, +∞; En] for all ε ∈ (0, ˇε1]. The latter inclusion,
for all ε ∈ (0, ˇε1]. Thus, the state-feedback control uε,1(z, t) satisﬁes all the
conditions of the admissibility in the OOCP, which completes the proof of the
lemma.

along with the equation (98), yields the inclusion uε,1(cid:0)z(t, ε), t(cid:1) ∈ L2[0, +∞; Er]

ky(t, ε)k ≤ a exp(−µt),

t ≥ 0,

29

10 Appendix C: Proof of Theorem 21

We prove the theorem for the sequence {uεk,1(z, t)}, (k = 1, 2, ...). The state-
ment of the theorem with respect to the sequence {uεk,2(z, t)}, (k = 1, 2, ...) is
proven similarly.

10.1 Auxiliary results

Similarly to proof of Lemma 18 (see Section 9), the substitution of uε,1 (z, t)
into (9) yields the initial-value problem (171)-(172) in the interval t ∈ [0, +∞).
Let us construct the zero-order asymptotic solution to this problem. Following
the Boundary Function Method [36], we look for this asymptotic solution in the
form

xas
0 (t, ε) = xo

0(τ ),

0(t) + xb

yas
0 (t, ε) = yo

0(τ ),
0(t)} is the so-called outer solution, xb

0(t) + yb

where {xo
boundary correction terms.

0(t), yo

τ = t/ε,

(178)

0(τ ) and yb

0(τ ) are the

Equations and conditions for obtaining the asymptotic solution (178) are
derived by substitution of xas
0 (t, ε) into the problem (171)-(172)
instead of x(t) and y(t), respectively, and equating the coeﬃcients for the same
powers of ε on both sides of the resulting equations, separately for the outer
solution terms and the boundary correction terms.

0 (t, ε) and yas

10.1.1 Obtaining xb

0(τ )

For obtaining this term, we derive the equation

dxb
0(τ )
dτ

= 0,

τ ≥ 0.

(179)

Due to the Boundary Function Method, we require that xb
Subject to this requirement, the equation (179) yields the unique solution

0(τ ) → 0 for τ → +∞.

xb
0(τ ) ≡ 0,

τ ≥ 0.

(180)

10.1.2 Obtaining the outer solution

Using the equations (37)-(38), (49), (74) and (173)-(176), we have the system
for {xo

0(t), yo

0(t)}
dxo
0(t)
dt

0 = −(cid:0)D2(cid:1)−1/2

Solving the equation (182) with respect to yo

0(t) + A2yo

0(t) − S1h10(t) + f1(t),

(181)

10(cid:1)xo
=(cid:0)A1 − S1P ∗
0(t) −(cid:0)D2(cid:1)1/2

10xo

2 P ∗

AT

0(t) = −D−1
yo

2 AT

2 P ∗

10xo

yo

0(t) −(cid:0)D2(cid:1)−1/2
0(t) − D−1

0(t), we obtain

2 AT

2 h10(t).

AT

2 h10(t).

(182)

(183)

30

Then, substituting (183) into (181), and using (52) and (57) yields the diﬀeren-
tial equation with respect to xo

0(t)

dxo
0(t)
dt

= A0xo

0(t) − S0h10(t) + f1(t).

(184)

Moreover, using (180), we directly have the initial condition for this equation

The solution of the problem (184)-(185) is

xo
0(0) = x0.

−Z t

0

exp(cid:0)A0(t − σ)(cid:1)(cid:16)S0h10(σ) − f1(σ)(cid:17)dσ,

xo

0(t) = exp(cid:0)A0t(cid:1)x0

t ≥ 0.

Due to (18), (58), (77) and (81), this solution satisﬁes the inequality

where a > 0 is some constant.

The equations (81), (183), and the inequalities (77), (187) yield

(cid:13)(cid:13)xo
0(t)(cid:13)(cid:13) ≤ a exp(−µt),
(cid:13)(cid:13)yo
0(t)(cid:13)(cid:13) ≤ a exp(−µt),

t ≥ 0,

t ≥ 0,

where a > 0 is some constant.

10.1.3 Obtaining yb

0(τ )

(185)

(186)

(187)

(188)

Using (37)-(38), (49), (176), we have the following equation for this boundary
correction term:

Moreover, the initial condition for this equation is

dyb
0(τ )
dτ

yb
0(τ ),

= −(cid:0)D2(cid:1)1/2
yb
0(0) = y0 − yo

0(0).

τ ≥ 0.

The solution of the problem (189)-(190) has the form

Due to (50), this solution satisﬁes the inequality

yb

0(τ ) = exp(cid:16) −(cid:0)D2(cid:1)1/2

t(cid:17)(cid:0)y0 − yo
(cid:13)(cid:13)yb
0(τ )(cid:13)(cid:13) ≤ a exp(−βτ ),

0(0)(cid:1),

τ ≥ 0,

totic solution to the problem (171)-(172).

31

where a > 0 is some constant.

Thus, we have completed the formal construction of the zero-order asymp-

(189)

(190)

(191)

(192)

τ ≥ 0.

Lemma 26 Let the assumptions (A1)-(A7) be valid. Then, there exists a posi-
tive constant ˜ε1, (˜ε1 ≤ ε2), such that for all ε ∈ (0, ˜ε1] the solution {x(t, ε), y(t, ε)}
of the initial-value problem (171)-(172) satisﬁes the inequalities

(cid:13)(cid:13)x(t, ε) − xo
(cid:13)(cid:13)y(t, ε) − yo

0(t)(cid:13)(cid:13) ≤ cε exp(−µt),
0(t/ε)(cid:13)(cid:13) ≤ cε exp(−µt),

0(t) − yb

t ≥ 0,

t ≥ 0,

where c > 0 is some constant independent of ε.

Proof. The lemma is proven similarly to Lemma 11.

Let us denote

J0

0

△

=Z +∞
S0(cid:16)P ∗

10xo

0(t)

D1xo

h(cid:0)xo
0(t)(cid:1)T
0(t) + h10(t)(cid:17)idt.

+(cid:16)P ∗

10xo

0(t) + h10(t)(cid:17)T

(193)

(194)

(195)

(196)

Corollary 27 Let the assumptions (A1)-(A7) be valid. Then, for all ε ∈ (0, ˜ε1]
the following inequality is satisﬁed:

Proof. Substitution of z(t, ε) = col(cid:0)x(t, ε), x(t, ε)(cid:1) and uε,1(cid:0)z(t, ε), t(cid:1) (see (99))

into (10), and using (3) and (15) yields

(cid:12)(cid:12)J(cid:0)uε,1(z, t)(cid:1) − J0(cid:12)(cid:12) ≤ cε.
hxT (t, ε)D1x(t, ε) + yT (t, ε)D2y(t, ε)
+(cid:0)K1(ε)x + εK2(ε)y + H3h10(t) + εH1h20(t)(cid:1)TeG
×(cid:0)K1(ε)x + εK2(ε)y + H3h10(t) + εH1h20(t)(cid:1)idt,

0

J(cid:0)uε,1(z, t)(cid:1) =Z +∞

(197)

where eG is given in (38).

Now, using the equations (100), Lemma 26 and the inequalities (187), (188),

(192), we can represent the expression (197) as follows:

J(cid:0)uε,1(z, t)(cid:1) =Z +∞
0(t) + h10(t)(cid:1)T
+(cid:0)P10xo

0

D1xo

h(cid:0)xo
0(t)(cid:1)T
3 eGH3(cid:0)P10xo

H T

0(t)

D2yo

0(t)(cid:1)T

0(t) +(cid:0)yo
0(t) + h10(t)(cid:1)(cid:3)dt + l(ε),

where l(ε) is some function of ε satisfying the inequality

kl(ε)k ≤ cε,

ε ∈ (0, ˜ε1],

c > 0 is some constant independent of ε.

Now, using (183), we have

(cid:0)yo
0(t)(cid:1)T

D2yo

0(t) =(cid:0)P10xo

0(t) + h10(t)(cid:1)T

32

A2D−1

2 AT

2(cid:0)P10xo

0(t) + h10(t)(cid:1).

(198)

(199)

(200)

Also, using (37)-(38), we obtain

Finally, the substitution of (200)-(201) into (198), and using the equation (52)
and the inequality (199) lead immediately to the inequality (194). Thus, the
corollary is proven.

H T

3 eGH3 = S1.

(201)

10.2 Main part of the proof

Substitution of the optimal control (93) of the ROCP into the dynamics (91) of
this problem, and using the equations (53), (57) yields after some rearrangement
the following initial-value problem for the optimal trajectory ¯x∗(t), t ≥ 0 in the
ROCP:

= A0 ¯x∗(t) − S0h10(t) + f1(t),

¯x∗(0) = x0.

(202)

d¯x∗(t)

dt

Comparison of this problem with the problem (184)-(185) yields

¯x∗(t) ≡ xo

0(t),

t ≥ 0.

(203)

Replacing ¯x with xo
optimal state-feedback control in the ROCP

0(t) in (93), we obtain the time realization ¯u∗(t) of the

¯u∗(t) = −Θ−1 ¯BT P ∗

10xo

0(t) − Θ−1 ¯BT h10(t),

t ≥ 0.

(204)

Now, substituting (203) and (204) into (92) instead of ¯x(t) and ¯u(t), respectively,
and using (53) yield the equality

¯J ∗ = J0,

(205)

where ¯J ∗ is the optimal value of the cost functional in the ROCP, while the
value J0 is given by (195). Finally, the equalities (104), (205) and the inequality
(196) directly imply the statement of the theorem.

References

[1] Pontriagin, L.S., Boltyanskii, V.G., Gamkrelidze, R.V., Mischenko, E.F.:
The Mathematical Theory of Optimal Processes, Gordon & Breach, New
York (1986)

[2] Bellman, R.: Dynamic Programming, Princeton University Press, Prince-

ton, NJ (1957)

[3] Kelly, H. J.: A second variation test for singular extremals. AIAA Journal

2, 26–29 (1964)

[4] Bell, D.J., Jacobson, D.H.: Singular Optimal Control Problems, Academic

Press, New York (1975)

33

[5] Gabasov, R., Kirillova, F.M.: High order necessary conditions for optimal-

ity. SIAM J. Control 10, 127–168 (1972)

[6] Mehrmann, V.: Existence, uniqueness, and stability of solutions to singular
linear quadratic optimal control problems. Linear Algebra Appl. 121, 291–
331 (1989)

[7] Krotov, V.F.: Global Methods in Optimal Control Theory, Marsel Dekker,

New York (1996)

[8] Ferrante, A., Ntogramatzidis, L,: Continuous-time singular linear-
quadratic control: necessary and suﬃcient conditions for the existence of
regular solutions. arXiv:1404.1667v1 [math.OC], 12 p (2014)

[9] Gurman, V.I.: Optimal processes of singular control. Autom. Remote Con-

trol 26, 783—792 (1965)

[10] Gurman, V.I., Dykhta, V.A.: Singular problems of optimal control and the
method of multiple maxima. Autom. Remote Control 38, 343—350 (1977)

[11] Gurman, V.I., Ni Ming Kang: Degenerate problems of optimal control. I.

Autom. Remote Control 72, 497–511 (2011)

[12] Gurman, V.I., Ni Ming Kang: Degenerate problems of optimal control. II.

Autom. Remote Control 72, 727—739 (2011)

[13] Gurman, V.I., Ni Ming Kang: Degenerate problems of optimal control. III.

Autom. Remote Control 72, 929—-943 (2011)

[14] Hautus, M.L.J., Silverman, L.M.: System structure and singular control.

Linear Algebra Appl. 50, 369–402 (1983)

[15] Willems, J.C., Kitapci, A., Silverman, L.M.: Singular optimal oontrol: a

geometric approach. SIAM J. Control Optim. 24, 323—337 (1986)

[16] Geerts, T.: All optimal controls for the singular linear-quadratic problem
without stability; a new interpretation of the optimial cost. Linear Algebra
Appl. 116, 135-181 (1989)

[17] Geerts, T.: Linear-quadratic control with and without stability subject to
general implicit continuous-time systems: coordinate-free interpretations
of the optimal costs in terms of dissipation inequality and linear matrix
inequality; existence and uniqueness of optimal controls and state trajec-
tories. Linear Algebra Appl. 203-204, 607-658 (1994)

[18] Zavalishchin, S.T., Sesekin, A.N.: Dynamic Impulse Systems: Theory and

Applications, Kluwer Academic Publishers, Dordrecht (1997)

34

[19] Glizer, V.Y.: Solution of a singular optimal control problem with state
delays: a cheap control approach. In: Reich, S., Zaslavski, A.J. (eds.):
Optimization Theory and Related Topics, Contemporary Mathematics Se-
ries, vol. 568, pp. 77–107. American Mathematical Society, Providence, RI
(2012)

[20] Glizer, V.Y.: Stochastic singular optimal control problem with state delays:
regularization, singular perturbation, and minimizing sequence. SIAM J.
Control Optim. 50, 2862–2888 (2012)

[21] Glizer, V.Y. Singular solution of an inﬁnite horizon linear-quadratic opti-
mal control problem with state delays. In: Wolansky, G., Zaslavski, A.J.
(eds.): Variational and Optimal Control Problems on Unbounded Domains,
Contemporary Mathematics Series, vol. 619, pp. 59–98. American Mathe-
matical Society, Providence, RI (2014)

[22] Tikhonov, A.N., Arsenin, V.Y.: Solutions of Ill-Posed Problems, Halsted

Press, New York (1977)

[23] Glizer, V.Y., Fridman, L.M., Turetsky, V.: Cheap suboptimal control of an
integral sliding mode for uncertain systems with state delays. IEEE Trans.
Automat. Control, 52, 1892–1898 (2007)

[24] Glizer, V.Y., Kelis, O.: Solution of a zero-sum linear quadratic diﬀeren-
tial game with singular control cost of minimizer. Journal of Control and
Decision, 2, 155–184 (2015)

[25] O’Malley, R.E., Jameson, A.: Singular perturbations and singular arcs, II.

IEEE Trans. Automat. Control 22, 328–337 (1977)

[26] Sabery, A., Sannuti, P.: Cheap and singular controls for linear quadratic

regulators. IEEE Trans. Automat. Control 32, 208–219 (1987)

[27] Seron, M.M., Braslavsky, J.H., Kokotovic, P.V., Mayne, D.Q.: Feedback
from Bode integrals to cheap control.

limitations in nonlinear systems:
IEEE Trans. Automat. Control 44, 829-833 (1999)

[28] Glizer, V.Y.: Asymptotic solution of a cheap control problem with state

delay. Dynam. Control, 9, 339–357 (1999)

[29] Smetannikova, E.N., Sobolev, V.A.: Regularization of cheap periodic con-

trol problems. Automat. Remote Control 66, 903–916 (2005)

[30] Glizer, V.Y.: Inﬁnite horizon cheap control problem for a class of systems

with state delays. J. Nonlinear Convex Anal. 10, 199–233 (2009)

[31] O’Reilly, J.: Partial cheap control of the time-invariant regulator. Internat.

J. Control 37, 909–927 (1983)

35

[32] Salukvadze, M.E.: The analytical design of an optimal control in the case
of constantly acting disturbances. Automat. Remote Control 23, 657–667
(1962)

[33] Anderson, B.O.D, Moore, J.B.: Linear Optimal Control, Prentice-Hall,

Englewood, NJ (1971)

[34] Kokotovic, P.V., Khalil, H.K., O’ Reilly, J.: Singular Perturbation Methods

in Control: Analysis and Design, Academic Press, London, UK (1986)

[35] Glizer, V.Y.: Blockwise estimate of the fundamental matrix of linear sin-
gularly perturbed diﬀerential systems with small delay and its application
to uniform asymptotic solution. J. Math. Anal. Appl. 278, 409-433 (2003)

[36] Vasil’eva, A.B., Butuzov, V.F., Kalachev, L.V.: The Boundary Function
Method for Singular Perturbation Problems, SIAM Books, Philadelphia,
PA: (1995)

36

