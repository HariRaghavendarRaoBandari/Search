Testing Interestingness Measures in Practice:

A Large-Scale Analysis of Buying Patterns

Martin Kirchgessner, Vincent Leroy,
Sihem Amer-Yahia, Shashwat Mishra

Univ. Grenoble Alpes, CNRS, LIG

Grenoble, France

6
1
0
2

 
r
a

 

M
5
1

 
 
]

B
D
.
s
c
[
 
 

1
v
2
9
7
4
0

.

3
0
6
1
:
v
i
X
r
a

ﬁrstname.lastname@imag.fr

ABSTRACT
Understanding customer buying patterns is of great interest
to the retail industry and has shown to beneﬁt a wide vari-
ety of goals ranging from managing stocks to implementing
loyalty programs. Association rule mining is a common tech-
nique for extracting correlations such as people in the South
of France buy rosé wine or customers who buy paté also buy
salted butter and sour bread. Unfortunately, sifting through
a high number of buying patterns is not useful in practice,
because of the predominance of popular products in the top
rules. As a result, a number of “interestingness” measures
(over 30) have been proposed to rank rules. However, there
is no agreement on which measures are more appropriate
for retail data. Moreover, since pattern mining algorithms
output thousands of association rules for each product, the
ability for an analyst to rely on ranking measures to iden-
tify the most interesting ones is crucial. In this paper, we
develop capa (Comparative Analysis of PAtterns), a frame-
work that provides analysts with the ability to compare the
outcome of interestingness measures applied to buying pat-
terns in the retail industry. We report on how we used capa
to compare 34 measures applied to over 1,800 stores of In-
termarché, one of the largest food retailers in France.

1.

INTRODUCTION

Ever since databases have been able to store basket data,
many techniques have been proposed to extract useful in-
sights for analysts. One of the ﬁrst, association rule min-
ing [1], also remains one of the most intuitive. Associa-
tion rules are often used to summarize consumer trends in
a transaction1 set or as input to a classiﬁer [4]. The prob-
lem is the very high number of rules, typically in the order
of millions. That is exacerbated by the lack of thorough
studies of which of the many interestingness measures for

1In this paper, a transaction is an entry in the dataset con-
taining information about the activity of a customer.
It
never refers to a database transaction.

1

Intermarché Alimentaire International

STIME

17 Allée des Mousquetaires

91078 Bondouﬂe cedex, France
contact@mousquetaires.fr

ranking rules [5] is most appropriate for which application
domain. We present capa, a framework to compare the
outcome of diﬀerent interestingness measures applied to as-
sociation rules generated in the food retail domain. capa
relies on a ﬂexible architecture and on j LCM [9], our par-
allel and distributed pattern mining algorithm that runs on
MapReduce. The use of real datasets and a close collabo-
ration with experienced domain experts from Intermarché,
one of the largest retailers in France, has led us to selecting
the most relevant measures to rank association rules in the
food retail domain.

Our dataset contains 290 million receipts from 1,884 stores
in all of France, gathered over one year, 2013. Mining this
data results in a huge number of rules. For example, using a
minimum support of 1,000 j LCM mines 2,746,418 frequent
rules of the form customer segment → product category. Out
of these, 15,063 have a conﬁdence of 50% or higher. Table 1
shows a ranking of the top-10 rules according to 3 diﬀerent
interestingness measures proposed in [5]. If we denote rules
as A → B, conﬁdence is the probability to observe B given
that we observed A, i.e., P (B|A). Piatetsky-Shapiro [16]
combines how A and B occur together with how they would
if they were independent, i.e., P (AB) − P (A)P (B). Pear-
son’s χ2, measures how unlikely observations of A and B are
independent. This very small example already shows that
these measures result in diﬀerent rule rankings.

The question we ask ourselves is how diﬀerent are the
rule rankings produced by existing interestingness
measures in the retail domain? To address this ques-
tion, we examine the rankings produced by 34 measures [5,
11]. This eﬀort was conducted for three mining scenar-
ios designed by experienced analysts from the marketing
studies department of Intermarché.
In the ﬁrst scenario,
demo_assoc, the analyst provides a target product category
and expects rules of the form customer segment → category,
i.e. customers who belong to the described segment purchase
products in the target category. In the other two scenarios,
the analyst provides a target product p and expects rules
of the form set of products → p. Such rules are either ex-
tracted based on a receipt-centric view, where products are
grouped by receipt (prod_assoc_t scenario), or based on a
customer-centric view, where products are grouped by cus-
tomer across several receipts (prod_assoc_c scenario). Our
ﬁrst ﬁnding is that existing interestingness measures can be
automatically grouped into 6 families of similar measures,
regardless of the mining scenario.

We then conducted a user study with two experienced
domain experts from Intermarché in order to address the

by conﬁdence
by Piatetsky-Shapiro [16]
{> 65, F, Aube} → Dairy
{∗,∗, N ord} → Liquids
{> 65, F, Aveyron} → Dairy
{∗,∗, N ord} → Soft drinks
{> 65, F, Val de Marne} → Dairy
{∗,∗, N ord} → Beers
{> 65, F, Seine St Denis} → Dairy
{∗,∗, N ord} → Spreads
{> 65, F, Haute Saone} → Dairy
{∗, F, N ord} → Soft drinks
(cid:48)
{> 65, F, Mause} → Dairy
{∗,∗, N ord} → Imported beers {∗,∗, Cotes d
{> 65,∗, Aube} → Dairy
{∗, F, N ord} → Liquids
{> 65, F, Haute Vienne} → Dairy
{∗, F, N ord} → Beers
{> 65, F, Maine et Loire} → Dairy {∗,∗, F inistere} → Butters
{> 65,∗, Val de Marne} → Dairy {∗, F, Garonne} → Drugstore

{∗,∗, Somme} → Cut cheese
{∗, F, Somme} → Cut cheese
{> 65,∗, M orbihan} → Fresh milk
{> 65,∗, Somme} → Cut cheese
{∗,∗, F inistere} → Canned pork
Armor} → Canned pork
{> 65, F, M orbihan} → Fresh milk

by Pearson’s χ2

{∗,∗, N ord} → Beer
{∗,∗, N ord} → Sparkling liquors
{∗,∗, V ienne} → Breakfast biscuits

Table 1: Top-10 demographics association rules, according to diﬀerent interestingness measures. Rules are
denoted {age, gender, department} → product category. Product categories were translated to English for
clarity. French departments were left unchanged. Product brands were removed for conﬁdentiality.

following question: out of the 6 families of interest-
ingness measures, which ones are meaningful? Our
study lets analysts choose one of 3 mining scenarios along
with target products or categories. Analysts also choose an
interestingness measure without knowing which one it is.
Their interactions with the resulting list of association rules
were observed and their feedback recorded in a free-text
form. Overall, ranking rules by decreasing conﬁdence was
preferred. Combined with the minimum support threshold
used in the mining phase, this ranking promotes rules that
are considered reliable. However, the preference of the ana-
lysts changes when ﬁlters are available to narrow down the
set of rules to speciﬁc product categories. In this case, they
favor the compromise between conﬁdence and support of-
fered, for instance, by the Piatetsky-Shapiro’s measure [16],
as it promotes rules that are observed more frequently.

capa is made possible with j LCM, our distributed pattern
mining algorithm that is able to mine millions of patterns
in a few minutes [9]. j LCM can be constrained to focus on
diﬀerent customer demographics and product taxonomies.
Thus, in addition to typical associations between products,
it ﬁnds associations between customer segments and prod-
ucts and between products and categories.

In summary, this paper presents capa, a joint eﬀort be-
tween researchers in Academia and business experts in In-
termarché. capa is a framework that lets analysts com-
pare and contrast diﬀerent interestingness measures (over
30 measures described in [5]). The context and goals of the
work are provided in Section 2. The architecture of capa is
overviewed in Section 3. In Section 4, capa is deployed to
perform an empirical evaluation of interestingness measures
and identify 6 groups of measures. These groups are then
evaluated by retail experts in Section 5. The related work is
summarized in Section 6. Planned and possible evolutions
are ﬁnally discussed in Section 7.

2. CONTEXT
2.1 Dataset
We represent a dataset D as a set of records of the form
(cid:104)t, c, p(cid:105), where t is a unique receipt identiﬁer, c is a customer,
and p is a product purchased by c. When a customer pur-
chases multiple products at the same time, several records
with the same receipt identiﬁer t are generated. The set of
receipt identiﬁers is denoted as T . Each receipt identiﬁer
is associated with a unique customer, and multiple receipt

2

identiﬁers can be associated with the same customer. We
do not use product price or product cardinality in this work.
The complete dataset contains over 290 million unique re-
ceipts, spanning 3.5 billion records, generated at a retail
chain consisting of 1,884 stores over the whole year of 2013.
Table 2 summarizes notations and cardinalities of the data.
The set of customers, C, contains over 9 millions cus-
tomers. Each customer has demographic attributes. In this
study, we focus on 3 attributes: age, gender and location.
The attribute age takes values in {<35, 35-49, 50-65, >65}
and the attribute location admits French departments as val-
ues. Each customer segment is described by a set of user at-
tribute values that are interpreted in the usual conjunctive
manner. For example, the segment {< 35 , Paris} refers to
young Parisian customers.
We use demo(c) to refer to the set of attribute values of
a customer c. For example, {35-49, female, Calvados} rep-
resents a 48 year old female from the Calvados department,
whom we will refer to as Mary.
The set of products P contains over 200,000 entries, out
of which 55,786 have been sold more than a thousand times.
Products are organized in a taxonomy with 19,557 nodes
over 4 levels. Figure 1 shows a sample from our taxonomy.
Products are leaf nodes, and belong to all their ancestor
categories. The set of categories a product p belongs to is
denoted as cat(p). For example, chocolate cream belongs to
the categories Fresh food, Dairy, Ultra fresh and Desserts.
2.2 Mining Customer Receipts

2.2.1 Dataset Preparation
Our analysts are interested in studying two kinds of buy-
ing patterns: those representing associations between cus-
tomer segments and a product category (e.g. young people
in the north of France consume sodas), and those associat-
ing a set of products to a single product (e.g. people who
purchase pork sausage and mustard also buy dry Riesling).
In all cases the analyst speciﬁes B, the set of association
rules’ targets.
In the ﬁrst case, coined demo_assoc, B contains one or
more categories. The analyst expects rules of the form cus-
tomer segment → category, i.e.
customers who purchase
products in the target category. The second case comes in
two variants: prod_assoc_t, a receipt-centric view where
products are found in the same receipt, and prod_assoc_c,
a customer-centric view where products are purchased by

Term

D
T
C
P
T

Description

Raw records (cid:104)t, c, p(cid:105)
Set of receipts
Set of customers
Set of products

Set of transactions

Cardinalities
3,502,834,638
290,734,163

9,267,961
222,228

demo_assoc: 9,267,961

prod_assoc_t: 290,734,163
prod_assoc_c: 9,267,961

Table 2: Notations and cardinalities

the same customer over time. In these variants, B only con-
tains products (as opposed to categories in the ﬁrst senario)
and the analyst expects rules of the form set of products →
target product p ∈ B.
The dataset D is transformed into a collection of trans-
actions T that is given as input to the mining process, as
summarized in Table 3. The set T is constructed diﬀerently
for each scenario.
In demo_assoc, a transaction is a tuple built for each re-
ceipt (cid:104)t, c, p(cid:105) by associating demo(c) with cat(p). For exam-
ple, for Mary, the record (cid:104)234567, Mary, chocolate cream(cid:105) is
mapped to the transaction (cid:104) 35-49, female, Calvados, choco-
late cream, Fresh food, Dairy, Ultra fresh, Desserts(cid:105). Thus,
the number of transactions is equal to |D|, and each trans-
action contains both, the segments a customer belongs to,
and the categories of the product purchased.
In prod_assoc_t, T is built by grouping the records in
D by receipt identiﬁer, t. Hence, for each t, we generate a
transaction as the set of products bought in a single visit to
the store {p|(cid:104)t, c, p(cid:105) ∈ D}. For example, if our user Mary has
a store receipt containing the products cream, yoghurt, cola,
a transaction containing the 3 products is generated. This
leads to a total of |T| transactions, where each transaction
is a subset of the set of products, P.
In prod_assoc_c, we generate the set of transactions T
by grouping records in D by customer. For each customer
c , we generate a single transaction containing all products
ever purchased by her {p|(cid:104)t, c, p(cid:105) ∈ D}. We obtain |C| trans-
actions, each of which is a subset of P. This use case enables
the discovery of patterns occurring over several visits to a
store.

Table 2 contains the number of transactions in each sce-
nario. In prod_assoc_c, the number of transactions is less
important than in prod_assoc_t, but each transaction con-
tains more products: 214, on average, whereas the average
receipt contains 12 products.

2.2.2 Mining Scenarios
Given a frequency threshold ε ∈ [1, n], an itemset P is said
to be frequent in a transactions set T iﬀ supportT (P ) ≥ ε
where supportT (P ) is the number of transactions in T that
contain all items in P . As indicated in Table 3, we set the
frequency threshold to diﬀerent values in diﬀerent scenar-
ios because they diﬀer in the cardinalities of their transac-
tions. Moreover, because marketing actions are decided and
applied nation-wide, they are expected to concern at least
1,000 customers, and preferably more than 10,000.

An itemset P is said to be closed iﬀ there exists no itemset
(cid:48)
) [14]. The
⊃ P such that supportT (P ) = supportT (P
P
number of closed frequent itemsets can be orders of magni-
tude less important than the number of frequent itemsets,

(cid:48)

[all]

Vegetables

Grocery

Beverages

Organic Chocolate bars Breakfast

Stuﬀed

Family sized

Desserts

...

...

...

[...] products [...]

Figure 1: Extract from our products taxonomy.

while providing the same amount of information on T . Sev-
eral algorithms, including ours, focus on extracting frequent
closed itemsets, increasing performance and avoiding redun-
dancy in results [15, 20].

We consider our mining scenarios described in Section 2.2.1.
Each scenario leads to the construction of a collection of
transactions T , where a transaction is a set of items. Given
T , a frequency threshold ε, we ﬁnd all closed frequent item-
sets, and use them to derive association rules [18]. Each
itemset P implies an association rule of the form A → B
where A, B is a partition of P . A is the antecedent of
In demo_assoc, A is a
the rule, and B its consequent.
customer segment and B is a single product category.
In
prod_assoc_t and prod_assoc_c, A is a set of products
(A ⊆ P) and B is a single product. Analysts generally fo-
cus on particular products or product categories. This is
why they specify the list of targets B in each scenario. Ta-
ble 3 contains example association rules extracted from our
dataset, for each scenario.
2.3

Interestingness Measures

Large datasets often contain millions of frequent closed
itemsets, and each of them may lead to several association
rules. The ability to identify valuable association rules is
therefore of the utmost importance to avoid drowning ana-
lysts in useless information. Association rules A → B were
originally selected using thresholds for support (supportT (A∪
B)) and conﬁdence ( supportT (A∪B)
supportT (A) ) [1]. However using two
separate values, and guessing the right threshold is not nat-
ural. Furthermore, support and conﬁdence do not always
coincide with the interest of analysts. Hence, a number of
interestingness measures that serve diﬀerent analyses needs
were proposed in the literature [5, 6, 12]. Table 4 summa-
rizes the interestingness measures we use in this work. The
ﬁrst column contains the name of the measure, the second
its expression. The last column will be referred to later.
2.4 Goal

Our goal is to help analysts test and compare diﬀerent in-
terestingness measures on association rules extracted from
from D. An analyst can specify one of 3 mining scenarios,
demo_assoc, prod_assoc_t, and prod_assoc_c, and one or
several targets (categories in the case of demo_assoc, prod-
ucts in the case of the other two), and capa generates a
ranked list of association rules sorted using diﬀerent inter-
estingness measures.

3

{demo(c) ∪ cat(p)|(cid:104)t, c, p(cid:105) ∈ D} A segment tends to purchase products in a category.

Target Associations

demo_assoc:

segment → category

Input transactions T
min support is 1,000

prod_assoc_t:

prod_assoc_c:

product(s) → product
product(s) → product

{∪(cid:104)t,cj ,pi(cid:105)∈Dpi|t ∈ T}
min support is 1,000
{∪(cid:104)tj ,c,pi(cid:105)∈Dpi|c ∈ C}
min support is 10,000

Desired association rules

{< 35, F,∗} → Baby food
{∗,∗, N ord} → Sodas

{> 65,∗, Gironde} → Bordeaux wine
Products purchased simultaneously.
{vanilla cream}→ chocolate cream

Customers’ product associations over time.
{Pork sausage, mustard}→ dry Riesling

Table 3: Our mining scenarios and example association rules.

Measure
One-Way Support
Relative Risk
Odd Multiplier
Zhang
Yule’s Q 3

Yule’s Y 3

Odds Ratio 3
Information Gain ∗(cid:9)
Lift ∗(cid:9)
Added Value ∗
Certainty Factor ∗
Conﬁdence / Precision ∗⊗
Laplace Correction ∗⊗
Loevinger †
Conviction †
Example and Counter-example Rate
Sebag-Schoenauer
Leverage
Least Contradiction
Accuracy
Pearson’s χ2 (cid:46)

Gini Index (cid:46)

J-measure
Φ Linear Correlation Coeﬃcient

Two-Way Support Variation

Fisher’s exact test

Jaccard
Cosine

Two-Way Support
Piatetsky-Shapiro
Klosgen
Speciﬁcity
Recall
Collective Strength

P (AB)

P (A)P (B)

P (AB)−P (A)P (B)

Formula
P (B|A) × log2
P (B|A)/P (B|¬A)
P (AB)P (¬B)
P (B)P (A¬B)
max(P (AB)P (¬B),P (B)P (A¬B))
P (AB)P (¬A¬B)−P (A¬B)P (B¬A)
P (AB)P (¬A¬B)−√
√
P (AB)P (¬A¬B)+P (A¬B)P (B¬A)
√
√
P (AB)P (¬A¬B)+
P (AB)P (¬A¬B)
P (A¬B)P (B¬A)
log(P (AB)/(P (A)P (B)))
P (AB)/(P (A)P (B))
P (B|A) − P (B)
(P (B|A) − P (B))/(1 − P (B))
P (B|A)

P (A¬B)P (B¬A)
P (A¬B)P (B¬A)

support(AB)+1
support(A)+2
1 − P (A)P (¬B)
P (A¬B)
P (A)P (¬B)
P (A¬B)
1 − P (A¬B)
P (AB)
P (A¬B)
P (B|A) − P (A)P (B)
P (AB)−P (A¬B)
P (AB) + P (¬A¬B)

P (AB)

P (B)

|T | ×(cid:16) (P (AB)−P (A)P (B))2
+|T | ×(cid:16) (P (A¬B)−P (A)P (¬B))2

P (A)P (B)

P (A)P (B)

(cid:17)

+ (P (¬AB)−P (¬A)P (B))2
P (¬A)P (¬B)

+ (P (¬A¬B)−P (¬A)P (¬B))2

P (¬A)P (B)

)

+

P (¬A¬B)

P (¬A)P (¬B)

(cid:17)

P (B)

P (A¬B)

|T |×P (A¬B)

P (A)P (¬B)

P (¬A)P (B)

P (A)P (B)
P (¬AB)

+ P (¬A¬B) × log2

(cid:17)(cid:16) |T |×P (¬B)

) + P (A¬B)log( P (¬B|A)
P (¬B)

P (AB)−P (A)P (B)
P (A)P (B)P (¬A)P (¬B)
P (AB)

+ P (A¬B) × log2
(cid:17)

P (A) × (P (B|A)2 + P (¬B|A)2) + P (¬A) × (P (B|¬A)2+
P (¬B|¬A)2) − P (B)2 − P (¬B)2
P (AB)log( P (B|A)
√
P (AB) × log2
(cid:16) |T |×P (B)
P (¬AB) × log2
(cid:16)
|T |×P (AB)
P (AB)/(P (A) + P (B) − P (AB))
√
P (AB) × log2
P (AB) − P (A)P (B)
P (¬B|¬A)
P (A|B)
P (A)P (B)+P (¬A)P (¬B)

(cid:112)P (AB)max (P (B|A) − P (B), P (A|B) − P (A))

× 1−P (A)P (B)−P (¬A)P (¬B)

1−P (AB)−P (¬B|¬A)

P (AB)+P (¬B|¬A)

P (AB)
P (A)P (B)

|T |

|T |×P (A)

P (AB)

P (A)P (B)

Group

Ga
1

Gb
1

G2

G3

G4

G5

G6

(cid:17)

Table 4: Interestingness measures of a rule A → B. ∗, (cid:46) indicate measures that produce the same rule ranking
when a single target is selected. 3, †, (cid:9), ⊗ indicate measures that always produce the same rule ranking. |T |
is the number of transactions. P (A) = support(A)/|T |.

4

Figure 2: Overview of the architecture

3. ARCHITECTURE

Figure 2 contains the main components of capa and their
interactions. The ﬁrst module is acquisition and stor-
age. Sales records are produced locally at each store, and
are loaded daily into a data center 1 . Records are stored
in a sales table, and are augmented with customer segments
coming from the customers table 2 . capa’s curation mod-
ule is used to build transactions. The analysts selects a min-
ing scenario and a set of input targets 3 , which are used
to generate the appropriate collection of transactions T 4 .
capa’s mining component relies on j LCM, an open-source
pattern mining library that we developed [9], to compute
a set of association rules matching the input targets 5 .
capa’s exploitation component computes the quality of
produced rules according to each interestingness measure
6 , and loads them into a database. Results are presented
to the analyst through a web application 7 . We now de-
scribe the details of each component of capa.
3.1 Acquisition and storage

Each of the 1,884 stores locally maintains a log of all cus-
tomer transactions completed during the day. Whenever
a customer checks out, a receipt is generated, indicating
the list of products purchased, their price, as well as poten-
tial discounts. These receipts are logged under the form of
(cid:104)r, c, p(cid:105) triples and stored in a write-ahead log. Once a day,
during the store’s closing time, this log is transmitted to the
main data center that centralizes all sales records.

We rely on Hadoop YARN [21] to administer the clus-
ter dedicated to storing sales records. All data is stored in
an HBase database [19], and processing is performed using
the Hadoop MapReduce framework [3]. Sales records are
stored in the sales table. To avoid redundancy and ease
data processing, records are grouped by receipt before be-
ing stored in sales. Thus, each receipt is a line in the table,
and the content of the receipt is stored in the meta col-
umn family. We leverage HBase’s ﬂexibility on columns by
recording each product identiﬁer as a column qualiﬁer, with
information such as the cardinality and the unit-price as a
value. The row key of each receipt is deﬁned as storeId-
day-customerId-receiptId. The sales table is conﬁgured to
be sorted by row key. This allows operations such as select-
ing the sales records of a given store to be eﬃciently per-

formed in a single scan, while selecting a speciﬁc time period
can also be done by combining 1,884 ranges (one per store
identiﬁer). Given that customer purchases may vary signiﬁ-
cantly between geographical areas [13] and over time, these
two operations are frequently used by analysts. This data
layout is optimized to perform these selections eﬃciently,
without incurring unnecessary reads. That allows to store
large amounts of data without increasing the cost of analyz-
ing a ﬁxed number of records. Sales logs transferred from
the stores are initially stored on the distributed ﬁle system
HDFS, and then loaded into HBase using MapReduce, as a
daily batch job.

Each customer constitutes an entry in the customers ta-
ble, which records the segments she belongs to. After load-
ing the sales records into the database, we enrich the sales
table using another MapReduce job. For each new record,
the receipt is augmented with the user segments by querying
the customers table and copying these segments to the meta
column family in sales. Hence, each sales record is assigned
a snapshot of the user information at the time the receipt
was generated.

3.2 Curation

As described in Section 2.2.1, mining customer receipts
begins with the construction of a transactions dataset T
following the requirements of the analyst. This operation
is performed using MapReduce jobs executed on the sales
table.
In the case of demo_assoc, a single map operation
is suﬃcient. The product taxonomy is loaded in memory
by all mappers through the distributed cache, and, given
a row, for each product registered in the products column
family, a transaction containing its categories is generated.
Customer segments are directly available in the meta col-
umn family thanks to the enrichment phase and are added
to the transactions. As described in Section 3.1, records are
already grouped by receipt when stored in sales, thus no fur-
ther processing is necessary for an analysis in prod_assoc_t.
Each line of sales generates one transaction containing the
set of products. In prod_assoc_c, the products bought by
a given customer are grouped using a reduce operation with
the customer identiﬁer as a key to generate a transaction.
In all cases, at the end of this phase the dataset T is stored
on HDFS as a text ﬁle, with one line per transaction.

5

demoassocprodassoctprodassoccPreparationcustomerssalestaxonomy1Acquisition/StoragestorereceiptsBatchTransferEnrichment2T4CurationjLCM5A→Bsup(A)sup(B)sup(A,B)........................MiningA→Bsup(A)sup(B)sup(A,B)m1(A,B)m2(A,B).............................................67ExploitationEnrichmentwithmeasuresAnalystScenario+Targets3Algorithm 1: Extracting itemsets with j LCM
Data: dataset T , minimum support threshold ε, target
Result: Output all closed itemsets in T containing an item

items B
from B

1 Function map(E ∈ T )
foreach b ∈ B do
2
if b ∈ E then
3
4
5 Function reduce(b ∈ B, T{b} ⊆ T , ε)

output (b, E)

Data: target b, ﬁltered dataset T{b}, freq. threshold ε
Result: Output all closed itemsets containing e
j LCM (∅, b, T{b}, ε)

6
7 Function jLCM (P, e, TP , ε)

transactions TP , freq. threshold ε

Data: Base itemset P , extension item e, supporting
Result: Output all closed itemsets containing {e} ∪ P
Q ← clo({e} ∪ P )
// Closure computation
if max (Q \ P ) = e then
// Unicity check

8
9
10
11
12
13

if |Q| ≥ 2 then
(Q))
foreach i ∈ freq ε(TQ) | i < e do

output (Q, supportTP
j LCM (Q, i, TQ, ε)

{a, b, x}, 2

(cid:104){b, x}, a(cid:105)

{b, x}, 3

(cid:104){x}, b(cid:105)

{a, b, y}, 2

(cid:104){b, y}, a(cid:105)

{b, c, y}, 2

{b, y}, 3

(cid:104){y}, b(cid:105)

(cid:104){c, y}, b(cid:105)

{a, b, x}, 2
(cid:104){x}, a(cid:105)

{b, c, x}, 2
(cid:104){x}, c(cid:105)

{c, y}, 3
(cid:104){y}, c(cid:105)
Te = {{a, b, c, x, y},{a, c, y},{a, b, x, y},{b, c, x, y}}

{a, y}, 3
(cid:104){y}, a(cid:105)

{x}, 4

{y}, 3

Figure 3: j LCM enumeration trees over an example
dataset Te, with ε = 2 and B = {x, y}. An edge (cid:104)P, e(cid:105)
represents an invocation of j LCM, a node is a closed
itemset Q (Algorithm 1, Line 8). Only boxed nodes
are returned.

3.3 Mining

3.3.1 Extracting itemsets using jLCM
Generating association rules, presented in Section 2.2.2,
ﬁrstly requires the extraction of frequent itemsets from T .
We rely on j LCM, our Java implementation of the LCM
algorithm [20] available as an open-source library [9].

j LCM is integrated in a MapReduce job, as detailed in
Algorithm 1. The itemset extraction job scans the input T
once in the map function, and builds for each target item
b in B, a ﬁltered dataset limited to transactions containing
b: T{b} = {E ∈ T , b ∈ E} (Lines 1–4). This is done using
the target items from B as intermediate keys for the reduce
function. For each target, reduce executes j LCM on its ﬁl-
tered dataset (Lines 5–6).
j LCM is a recursive algorithm
that enumerates itemsets and computes their frequency fol-
lowing a depth-ﬁrst tree-shaped traversal (Lines 7–13).

As proposed by Uno et al. [20], Line 8 ensures that only
closed itemsets are enumerated, and Line 9 avoids duplicat-
ing enumerations. Closed itemsets are returned along with

their support (Line 11), with the exception of singletons that
cannot produce association rules. In demo_assoc, itemsets
should contain a single category only, so all categories except
the target one are removed from transactions.

Figure 3 depicts an example of j LCM execution with two
targets B = {x, y}. This leads to 2 separate enumeration
trees, explored in parallel by two reducers. In the case of the
target x, on the left, j LCM starts with the singleton item-
set {x} and recursively builds larger itemsets. The closed
itemset {a, b, x} is encountered several times throughout the
enumeration, but is only outputted once thanks to the test
of Line 9. This technique allows us quickly obtain itemsets
that satisfy our constraint, i.e. all itemsets contain one of
the targets from B. The job’s run-time is dominated by the
scan of T in the map phase, which can be accelerated by
the addition of worker nodes. On average, each reduce task
completes in 10 seconds.

3.3.2 Evaluating relevant association rules
Analysts aim at uncovering interesting association rules
expressed as A → B. Evaluating the interestingness of an
association rule requires computing the support of itemsets
A, B and A ∪ B in T . The standard method for mining
association rules consists in ﬁnding all frequent itemsets in
the dataset, and then generating the rules. Given that our
analysts have speciﬁed a restricted set of targets B, this
approach would be wasteful. This motivates our distribution
of the itemsets extraction, presented in the previous sub-
section. Our itemsets extraction job gives the support of B
and A ∪ B for all association rules we are interested in (ie.
all B satisfy B = {e}, e ∈ B). This job also materializes, as
a preﬁx tree in a side-output ﬁle, the set A of all antecedent
itemsets, whose support needs to be evaluated.
An second MapReduce job completes the evaluation of
association rules. Each map operation reads a transaction of
T and counts the support all association rules’ antecedents.
The reduce phase uses itemsets in A as intermediate keys
and sums partial counts to obtain the total support. This
two-step approach avoids the computation of many itemsets
that never appear as a rule antecedent.
3.4 Exploitation

The quality measures selected require at most P (A), P (B)
and P (A ∪ B) to be computed, because, given |T |, other
probabilities like P (B|A) or P (A¬B) can be derived from
them. Therefore, we denormalize the results of the mining
phase in order to store those 3 probabilities with each A and
B. The supports of all rules’ antecedents (providing P (A))
are centralized and joined to the results of j LCM (which pro-
vides P (AB) and P (B)). After this denormalization, each
row represents an association rule and has enough informa-
tion to compute its score. This table is then augmented with
34 columns, one for each measure implemented in capa, and
listed in Table 4. Because large numbers are involved, for
Fisher’s exact test we actually use the logarithm of the bi-
nomial coeﬃcients, which are computed as logarithms of the
gamma function. This makes the calculation feasible, but
requires long iterations so we do it in parallel again (this
is easy to implement thanks to the denormalization). The
complete table is stored in a relational database.

The ﬁnal component of capa is a web application allowing
the analyst to explore this augmented table. In any scenario,
the analyst picks a measure and selects a target product or

6

category, or a set of target products or categories. Associa-
tion rules are then returned in a table and sorted according
to the selected measure.
A rule like yoghurt → cheese is displayed with 3 values:
support (number of customers who bought both cheese and
yoghurt), conﬁdence (fraction of yoghurt buyers who also
bought cheese), recall (fraction of cheese buyers who also
bought yoghurt). During the user study these ﬁgures help
the analyst quickly judge the volume of sales for each rule.

4. EMPIRICAL EVALUATION

We present an empirical evaluation of the 34 measures for
association rules introduced in Section 2.3. Recall that our
goal, stated in Section 2.4, is to assist the analyst in select-
ing measures. Our evaluation consists in comparing rankings
produced by these measures on retail data to discover which
measures diﬀer signiﬁcantly in practice. We then use that
similarity to classify ranking measures into groups. We an-
notate these groups based on the properties common to the
group. We discuss key insights obtained from rigorous ex-
perimentation on each group. The goal of this evaluation is
to automatically detect similarities between interestingness
measures and reduce the number of candidate measures to
present to analysts the user study (Section 5).

We ﬁrst present in Section 4.1 methods used to compare
ranked list. Then, we compare measures in two diﬀerent
cases: rules having the same target (Section 4.2) and rules
having diﬀerent targets (Section 4.3). We conclude the em-
pirical evaluation with the selection of representative mea-
sures in Section 4.4.
4.1 Ranking similarity measures

In this section, we discuss some methods for comparison
of ranked lists. The ﬁrst three methods are taken from the
literature. We then introduce NDCC, a new parameter-free
ranking similarity designed to emphasize diﬀerences at the
top of the ranking.
We are given of a set of association rules R to rank. We
interpret each measure, m, as a function that receives a rule
and generates a score, m : R → R. We use LmR to denote
an ordered list composed of rules in R, sorted by decreasing
(cid:48)
score. Thus, LmR =< r1, r2, . . . > s.t. ∀i > i
m(ri) < m(ri(cid:48) ).
We generate multiple lists, one for each measure m, from the
same set R. LmR denotes a ranked list of association rules
according to measure m where the rank of rule r is given as
) ≥ m(r)}|. To assess the
rank(r, LmR) = |{r
(cid:48), we compute
dissimilarity between two measures, m and m
the dissimilarity between their ranked lists, LmR and Lm(cid:48)
R .
We use rm as a shorthand notation for rank(r, LmR).
4.1.1
Spearman’s rank correlation coefﬁcient
Given two ranked lists LmR and Lm(cid:48)
R , Spearman’s rank cor-
relation [2] computes a linear correlation coeﬃcient that
varies between 1 (identical lists) and −1 (opposite rankings)
as shown below.

∈ R, m(r

|r

(cid:48)

(cid:48)

(cid:48)

Spearman(LmR, Lm(cid:48)

R ) = 1 −

This coeﬃcient depends only on the diﬀerence in ranks of
the element (rule) in the two lists, and not on the ranks
themselves. Hence, the penalization is the same for diﬀer-
ences occurring at the beginning or at the end of the lists.

6 (cid:80)

(rm − rm(cid:48)
r∈R
|R|(|R|2 − 1)

4.1.2 Kendall’s τ rank correlation coefﬁcient
Kendall’s τ rank correlation coeﬃcient [8] is based on the
idea of agreement among element (rule) pairs. A rule pair
is said to be concordant if their order is the same in LmR and
Lm(cid:48)
R , and discordant otherwise. τ computes the diﬀerence
between the number of concordant and discordant pairs and
divides by the total number of pairs as shown below.

τ (LmR, Lm(cid:48)

R ) = |C| − |D|

1

2|R|(|R| − 1)

C = {(ri, rj)|ri, rj ∈ R ∧ i < j∧

sgn(rm

i − rm

j ) = sgn(rm(cid:48)

i − rm(cid:48)
j )}

D = {(ri, rj)|ri, rj ∈ R ∧ i < j∧

sgn(rm

i − rm

j ) (cid:54)= sgn(rm(cid:48)

i − rm(cid:48)
j )}

≤ k}|

Similar to Spearman’s, τ varies between 1 and −1, and pe-
nalizes uniformly across all positions.
4.1.3 Overlap@k
Overlap@k is another method for ranked lists compari-
son widely used in Information Retrieval.
It is based on
the premise that in long ranked lists, the analyst is only ex-
pected to look at the top few results that are highly ranked.
While Spearman and τ account for all elements uniformly,
Overlap@k compares two rankings by computing the overlap
between their top-k elements only.
Overlap@k (LmR, Lm(cid:48)
4.1.4 Normalized Discounted Correlation Coefﬁcient
Overlap@k, Spearman’s and τ sit at two diﬀerent extremes.
The former is conservative in that it takes into considera-
tion only the top k elements of the list whereas the latter
two take too liberal an approach by penalizing all parts of
the lists uniformly. In practice, we aim for a good tradeoﬀ
between these extremes.

R ) = |{r ∈ R|r m ≤ k} ∩ {r ∈ R|r m(cid:48)

k

log rm .

To bridge this gap, we propose a new ranking correlation
measure coined Normalized Discounted Correlation Coeﬃ-
cient or NDCC. NDCC draws inspiration from NDCG, Nor-
malized Discounted Cumulative Gain [7], a ranking measure
commonly used in Information Retrieval. The core idea in
NDCG is to reward a ranked list LmR for placing an element
r of relevance relr by relr

The logarithmic part acts as a smoothing discount rate
representing the fact that as the rank increases, the analyst
is less likely to observe r. In our setting, there is no ground
truth to properly assess relr . Instead, we use the ranking
(cid:48) as a relevance measure for r, with an identi-
assigned by m
cal logarithmic discount. When summing over all of R, we
obtain DCC , which presents the advantage of being a sym-
metric correlation measure between two rankings LmR and
Lm(cid:48)
R .

)2

DCC (LmR, Lm(cid:48)

R ) =

log (1 + rm(cid:48)

1
) log (1 + rm)

(cid:88)

r∈R

We compute NDCC by normalizing DCC between 1 (iden-
tical rankings) and −1 (reversed rankings).
dcc − avg
max − avg

NDCC (LmR, Lm(cid:48)

R ) =

7

0.42

-0.27

0.82

0.78
G5

(a) NDCC

0.49

0.85

0.84
G3

G1
G2

G3

Jaccard
Jaccard

G4

Piatetsky-Shapiro

Speciﬁcity

Klosgen

G6

0.60

0.50

-0.16

0.70

0.63
G6

G1
G2

G3

Jaccard
Jaccard
Klosgen

0.86

Piatetsky-Shapiro

Speciﬁcity

G4
Collective strength
Recall

0.75
G3

0.77

(b) τ

Figure 4: Hierarchical clustering of interestingness measures for a single target

where dcc = DCC (LmR, Lm(cid:48)
min = DCC (L∗, Lm(cid:48)

R ), max = DCC (Lm(cid:48)
R ), L∗ = rev (Lm(cid:48)

R )

R , Lm(cid:48)
R )

avg = (max + min)/2

4.1.5 Ranking comparison by example
We illustrate the diﬀerence between all ranking correlation
measures with an example in Table 5. This shows correlation
of a ranking L1 with 3 others, according to each measure.
NDCC does indeed penalize diﬀerences at higher ranks, and
is more tolerant at lower ranks.
4.2 Ranking rules with identical targets
We ﬁrst consider the case of ranking association rules A →
B where B is a product, i.e., all rules have the same B.
We perform a comparative analysis of ranking measures on
our 3 mining scenarios summarized in Table 3. Our ﬁrst
observation is that the results we obtain for all scenarios lead
to the same conclusions. Therefore, we only report numbers
for prod_assoc_c. We use as targets for this comparison
64 products previously studied by analysts that lead to the
discovery of 1,651,024 association rules. We compute one
rule ranking per interestingness measure.

While all measures are computed diﬀerently, we notice
that some of them always return the same ranking for asso-
ciation rules of a given target. We identify them in Table 4
using symbols. Other notable similarities include Sebag-
Schoenauer and lift (89% of rankings are equal), as well
as Loevinger and lift (87%). This diﬀerence between the
number of interestingness measures considered (34) and the
number of diﬀerent rankings obtained (25) can easily be ex-
plained analytically in the case of a ﬁxed target. Indeed, for
a given ranking, P (B) is constant, which eliminates some of
the diﬀerences between interestingness measures. In addi-
tion, some measures only have subtle diﬀerences which only
appear when selecting extreme values for P (A), P (B) and
P (AB), which do not occur in practice in our retail dataset.

4.2.1 Comparative analysis
We now evaluate similarity between interestingness mea-
sures that do not return the same rankings. We compute
a 34 × 34 correlation matrix of all rankings according to

8

Ranking

Content

L1
L2
L3
L4

Spearman

L2
L3
L4

0.80
0.80
0.40

τ

0.67
0.67
0.33

r1, r2, r3, r4
r2, r1, r3, r4
r1, r2, r4, r3
r2, r3, r1, r4

Overlap@2 NDCC
0.20
0.97
−0.18

1
1
0.5

Table 5: Example rankings and correlations

each correlation measure described in Section 4.1, and av-
erage them over the 64 target products. This gives us a
ranking similarity between all pairs of measures We then
rely on hierarchical clustering with average linkage [17] to
obtain a dendrogram of interestingness measures and ana-
lyze their similarities. The dendrograms for NDCC and τ
are presented in Figure 4. For better readability, we merge
sub-trees when correlation is above 0.9. To describe the re-
sults more easily, we partition interestingness measures into
6 groups, as indicated in the third column in Table 4.

G1 is by far the largest group: in addition to 4 measures
that always generate the same rankings, 14 other measures
output similar results. A second group, G2, comprising 2
measures, is quite similar to G1 according to NDCC . τ also
discovers this similarity, but considers it lower, which shows
that it is mostly caused by high ranks. Jaccard is as a slight
outlier in G3 according to NDCC . Indeed, when focusing
on the ﬁrst 20 elements (Overlap@20), only an average of
71% are shared between Jaccard and the rest of G3. This
situation also occurs between Klosgen and the rest of G5.
Interestingly, we observe that, according to NDCC , G5 is
closest to G6 and is negatively correlated with the other
groups. However, according to τ, G5 is very similar to G4
and is negatively correlated with G6. This diﬀerence of be-
havior between ranking measures illustrates the importance
of accounting for rank positions. When the top of the rank-
ing is considered more important, some similarities emerge.
We illustrate this behavior in Figure 5 by displaying corre-

Figure 5: Rank correlations

Figure 6: Average recall/conﬁdence of the top-20
results of interestingness measures

lation between rankings obtained with diﬀerent interesting-
ness measures. This experiment clearly shows that overall,
cosine (G4) is closer to speciﬁcity (G5) than Gini (G3), as
the rank diﬀerence observed in the results is overall smaller.
However, when focusing on the top-10 results of cosine, Gini
assigns closer ranks than speciﬁcity. This explains the diﬀer-
ence in clustering between NDCC /overlap and τ/Spearman.

4.2.2 Annotating groups
While using hierarchical clustering on interestingness mea-
sures allows the discovery of families of measures, and their
relative similarity, it does not fully explain which types of
results are favored by each of them. We propose to com-
pare their outputs according to the two most basic and in-
tuitive interestingness measures employed in data mining:
recall and conﬁdence. recall represents the proportion of tar-
get items that can be retrieved by a rule, that is, P (A|B).
Its counterpart, conﬁdence, represents how often the conse-
quent is present when the antecedent is, that is, P (B|A).
We present, in Figure 6, the average recall and conﬁdence
of the top-20 rules ranked according to each interestingness
measure. G1 contains conﬁdence, so it is expected to score
the highest on this dimension. G2 is extremely close to G1,
but obtains slightly lower conﬁdence and recall. We then
have, in order of increasing recall and decreasing conﬁdence
G3, G4 and G5. Finally, G6, which contains recall, obtains
the highest recall but the lowest conﬁdence. Figure 6 also
shows that executing a Euclidean distance-based clustering,
such as k-means, with recall/conﬁdence coordinates would
lead to groups similar to the ones obtained with hierarchi-
cal clustering. Hence, this analysis is consistent with the
hierarchical grouping and the correlation with NDCC .

While we believe that NDCC reﬂects better the interpre-
tation of analysts browsing rules, it is important to note that
the grouping of interestingness measures created through
this evaluation is stable across all 4 correlation measures
and for all 3 scenarios. Correlation between diﬀerent fam-
ilies of measures may vary, but measures within a single
family always have a high similarity. Thus, we can safely
state that the obtained results are true in the general case
of food retailers and we can rely on these groups to reduce
the number of options presented to analysts.
4.3 Ranking rules with different targets

We now consider the problem of ranking association rules
when many targets are provided as input, i.e. association

rules A → B can have diﬀerent targets B. Compared to hav-
ing a single target, this setting introduces one more degree
of freedom in the quality measure of the association rules,
as P (B) varies. We rely on the same set of (64) products
as in the identical target experiment, but instead of gener-
ating rankings for each target, we rank all association rules
together. The dendrogram of quality measures obtained for
NDCC and τ is presented in Figure 7.

1 and Gb

We observe a much wider variety in rankings. The group
G1, observed previously, splits into two diﬀerent sub-groups,
1. A large fraction of G3 remains similar, and the
Ga
two measures that constitute G4 and G6 remain highly cor-
related. G2 and G5 are not preserved when ranking diﬀerent
targets simultaneously.

We observe a stronger agreement between NDCC and τ.
The only notable diﬀerences are (i) Klosgen and Gini, which
are highly correlated with G4 when focusing on the top re-
sults, while they are more similar to Ga
1 globally, and (ii)
Jaccard, which switches from a similarity with Piatetsky-
Shapiro to a similarity with G6.

Measures that prioritize high values of P (B), i.e.

favor
targets that are more frequent, are Ga
1, Piatetsky-Shapiro,
Klosgen and Gini. Indeed, in the case of conﬁdence (Ga
1),
an association rule A → B that has a very frequent B can
easily score highly by selecting a very speciﬁc A. Conversely,
speciﬁcity, collective strength, accuracy, Gb
1 and recall tend
to rank less frequent targets highly. A similar explanation
applies to recall, as a low frequency of B makes it easier to
ﬁnd association rules that capture most of its appearances
in the data.
4.4 Selecting representative measures

We summarize the ﬁndings of the comparative evaluation
in Table 6. When the analyst selects a single target, we iden-
tify 6 families of measures that behave similarly. When mul-
tiple targets are selected, G1 splits into 2 sub-groups. Each
family oﬀers a diﬀerent trade-oﬀ in terms of conﬁdence and
recall, and thus ranks association rules diﬀerently. When
ranking rules with diﬀerent targets, some families are sensi-
tive to the frequency of the target.

We select the quality measure that most represents each
family of measures (i.e. with highest average similarity) in
order to confront the results of this analysis with the opinion
of domain experts in our user study. Taking a general data
mining perspective leads us to considering G3 and G4 as the
most promising families for ﬁnding interesting association
rules.
Indeed, it is important to achieve a good trade-oﬀ

9

−100−50 0 50 100 1 10 100Average rank differenceRank for Cosine (G4)Specificity (G5)Gini (G3) 0 0.05 0.1 0.15 0.2 0.25 0.3 0.05 0.1 0.15 0.2 0.25 0.3 0.35confidencerecallG1G2G3G4G5G60.65

Gb
1

0.82

Ga
1
Least Contradiction

0.59

0.75

0.69

Gb
1

Ga
1

0.87

Klosgen
Gini

Least contradiction

0.27

0.53

0.87

0.74

G3

Jaccard

Gini

G4
Klosgen

Gini

-0.45

-0.01

0.78

Piatetsky-Shapiro
Jaccard

Accuracy

Speciﬁcity

G6

0.73

(a) NDCC

0.47

-0.14

0.67

0.82

0.35

0.62

0.68

(b) τ

G3

Jaccard

Gini

G4

Piatetsky-Shapiro

Accuracy

Speciﬁcity
Jaccard
G6

Figure 7: Hierarchical clustering of interestingness measures for multiple targets

Group
Representative

Ga
1
Lift

Gb
1
Added value

G2
Accuracy

G3
Fisher’s exact test

G4
Cosine

G5
Piatetsky-Shapiro

G6
Collective strength

Description
Highest conﬁdence
Very low recall
Favors frequent targets
Highest conﬁdence
Very low recall
Favors rare targets
Very high conﬁdence
Very low recall
High conﬁdence
Low recall
Low sensitivity to target freq.
Average conﬁdence
Average recall
Low sensitivity to target freq.
Low conﬁdence
High recall
Lowest conﬁdence
Highest recall
Favors rare targets

Table 6: Summary of quality measure groups

between recall and conﬁdence in order to ﬁnd reliable asso-
ciation rules that can be applied in a signiﬁcant number of
cases. Hence, F1 score, that combines recall and conﬁdence,
would prefer G3 and G4 to others.

5. USER STUDY

We now report the results of a user study with domain
experts from Intermarché. The goal of this study is to assess
the ability of interestingness measures to rank association
rules according to the needs of an analyst. As explained in
Section 4, we identiﬁed 6 families of measures, and selected a

representative of each group for the user study (Table 6). We
rely on the expertise of our industrial partner to determine,
for each analysis scenario, which family produces the most
interesting results. This experiment involved 2 experienced
analysts from the marketing department of Intermarché. We
setup capa and let analysts select targets multiple times
in order to populate the web application’s database with
association rules (Section 3.4). We let our analysts interact
with capa without any time restriction, and collect their
feedback in a free text form.

Each analyst ﬁrstly has to pick a mining scenario among
demo_assoc, prod_assoc_t, or prod_assoc_c. Then she
picks a target category or a target product in the taxonomy.
In prod_assoc_t and prod_assoc_c, she also has the option
to ﬁlter out rules whose antecedent products are not from
the same category as the target. Finally, she chooses one of
our 6 ranking measures to sort association rules. Neither the
name of the measure nor its computed values for association
rules are revealed, because we wanted analysts to evaluate
rankings without knowing how they were produced.

Resulting association rules are ranked according to a se-
lected measure. Each rule is displayed with its support,
conﬁdence and recall, such that analysts can evaluate it at a
glance. For each scenario, our analysts are asked which rep-
resentative measure highlights the most interesting results
(as detailed below, in all cases a few of them were chosen).

5.1 Scrolling behavior

Once the analyst selects a target, all matching rules are
returned. The initial motivation of this choice was to deter-
mine how many results are worth displaying and are actually
examined by the analysts. According to the follow-up inter-
view with the analysts, they carefully considered the ﬁrst
ten results, and screened up to a hundred more. Interest-
ingly, analysts mentioned that they also scrolled down to
the bottom of the list in order to see which customer seg-

10

ments are not akin to buying the selected category. For ex-
ample, when browsing demographic association rules, they
expected to ﬁnd {50-64} → pet food among top results, but
also expected {<35, Paris} → pet food among bottom re-
sults. This conﬁrms that all rules should remain accessible.
This also indicates that while interestingness measures favor
strong associations, it would also be interesting to highlight
anti-rules, as those can also convey useful information.
5.2 Feedback on ranking measures

We let marketing experts explore all 3 scenarios and ex-

press their preference towards groups of measures.

In the demo_assoc case, G1 and G3 were both highly ap-
preciated. G1 favors rules such as {< 35, M, Oise} → Flat
and Carbonated drinks. These rules are very speciﬁc and
thus have a very high conﬁdence (31,58 % in this particu-
lar case). However, this comes at the cost of recall (0,08
%). Experts value conﬁdence much more than recall, as
their priority is ﬁnding rules that they consider reliable.
A low support is not necessarily an issue, and can lead to
the discovery of surprising niche rules that can be exploited
nonetheless. As discussed in Section 4.2.2, G3 oﬀers a more
balanced trade-oﬀ between conﬁdence and recall, and pri-
oritizes rules such as {< 35, *, *} → Baby food (conﬁdence
8,57 %, recall 37,61%). These rules are interesting because
they capture a large fraction of the sales of a given category,
but are less reliable and generally less surprising. G2 and G4
were considered as less interesting than G1 and G3 respec-
tively. Their results oﬀer similar trade-oﬀs, but with lower
conﬁdence each time. G5 and G6 were considered unusable
because of their very low conﬁdence.

When experimenting with prod_assoc, we observed a slightly

diﬀerent behavior. By default, the analysts favored G1 and
G2 because of the conﬁdence of their results. Then, we
oﬀered the analysts the possibility of ﬁltering the rules to
only keep the ones in which the antecedent contains products
from the same category as the target. This led to analysts
favoring G3 and G5. This diﬀerence is caused by an impor-
tant but implicit criterion: the ability of a measure to ﬁlter
out very popular products. For example, the rule {vanilla
cream, emmental}→ chocolate cream usually appears just
above its shorter version {vanilla cream}→ chocolate cream,
because the ﬁrst one has a conﬁdence of 32% and the sec-
ond 31%. However, experts prefer the second one, because
emmental (cheese) is among the heavy hitters in stores. Its
addition to the rule is hence considered insigniﬁcant. This
“noise” generally increases with recall. Hence, when no ﬁlter-
ing is available, G1 is selected, but analysts prefer the recall
and conﬁdence trade-oﬀ provided by G3 and G5. Again,
G4 suﬀered from its proximity to G3 with lower conﬁdence,
while G6’s conﬁdence was too low.
5.3 Summary of user study

In all cases, analysts mentioned G6 as uninteresting over-
all because it selects rules of low conﬁdence. In general, sort-
ing by decreasing lift (which is close to sorting by decreas-
ing conﬁdence) is the preferred choice. Combined with the
minimum support threshold used in the mining phase, this
ranking promotes rules that are considered reliable. How-
ever, the preference of the analysts changes when ﬁlters are
available to narrow down the set of rules to speciﬁc prod-
uct categories. In this case, they favor the compromise be-
tween conﬁdence and support oﬀered, for instance, by the

11

Piatetsky-Shapiro’s measure [16].

6. RELATED WORK

To the best of our knowledge, capa targets datasets which
are orders of magnitude bigger (and sparser) than those
tested in existing work on ranking association rules. This
paper is also the ﬁrst to complement an algorithmic compar-
ative analysis with a user study involving domain experts.
The deﬁnition of quality of association rules is a well-
studied topic in statistics and data mining, summarized in [5].
In this survey, Geng et al. review as many as 38 measures
for association and classiﬁcation rules. They also discuss 4
sets of properties like symmetry or monotony, and how each
of them highlights diﬀerent meanings of “rule quality”, such
as novelty and generality. However, we observe no correla-
tion between these properties and the groups of measures
discovered using capa.

These 38 measures are compared in [10]. Authors consider
the case of extracting and ranking temporal rules (event
A→event B) from the execution traces of Java programs.
Each measure is evaluated in its ability to rank highly rules
known from a ground truth (Java library speciﬁcation). We
observe that the measures scoring the highest are all from
the groups identiﬁed in this work as G1 and G3, which were
also favored by our analysts. There are however some coun-
terexamples, with measures from G1 scoring poorly. The
authors then use a statistical approach to build a partial or-
dering of measures quality. This results in the formation of
measure equivalence classes. However, the semantic of these
classes is based on the principle of dominance in the evalua-
tion, and not on the comparison of the rankings themselves.
Hence, the equivalence classes obtained do not match our
groups. The main diﬀerence between capa and [10] is the
absence of a ground truth of interesting rules for our dataset.
Consequently, our evaluation of measures is ﬁrst compara-
tive, with 4 correlations measures covering both the top of
the ranking and the entire ranked list. We then build groups
of measures to reduce the number of options presented to
expert analysts in the user study. The diﬀerences in the re-
sults obtained also highlight the importance of performing
domain-speciﬁc studies, as the properties of data and the
expectations of analysts vary signiﬁcantly.

The closest work to ours is Herbs [11]. Herbs relies on a
diﬀerent and smaller set of measures to cluster rule rankings.
Authors perform an analysis of the properties of measures,
in addition to an experimental study. The datasets used are
from the health and astronomy domains. Each of them con-
tains at most 1,728 transactions and leads to the extraction
of 49 to 6,312 rules. Rankings are then compared between
all pairs of measures using Kendall’s τ correlation measure
averaged over all datasets. The largest group of measures
identiﬁed, which includes conﬁdence, is quite similar to G1.
However, there are also signiﬁcant diﬀerences. For instance,
we ﬁnd G2 and G6 to be very diﬀerent, while [11] considers
the measures of this group similar. The authors observe a
weak resemblance between the theoretical and experimental
analysis of the measures. The main similarity between [11]
and capa is the reliance on a pairwise correlation measure
followed by a hierarchical clustering to detect groups of mea-
sures. capa is entirely focused on retail data, which has dif-
ferent properties and contains millions of transactions and
rules. capa is also more exhaustive in the analysis of mea-
sures: we consider more interestingness measures, and 4 dif-

ferent ranking correlation measures instead of 1. This allows
us to discover more subtle diﬀerences in a more speciﬁc do-
main. Finally, we perform a user study to assess the quality
of each group according to experts from the retail industry.
Our use of the p-value (via Pearson’s χ2 test) in the eval-
uation of rule interestingness is borrowed from [12]. A low
p-value shows a correlation between a rule’s antecedent and
consequent. The use of Fisher’s exact test on association
rules is inspired by [6]. Both of these works aim at ﬁnd-
ing highly-correlated itemsets, which requires the analyst to
set a threshold on the p-value. This is common practice in
biology, but less meaningful in the retail industry.

In [12], Liu et al. also propose an exploration framework
where rules are grouped by consequent, then traversed by
progressively adding items to the antecedent. The frame-
work provides hints to help guess how each additional item
would make a diﬀerence. Such a framework is suitable to
some of the scenarios we consider and could be integrated
in a future version of capa.

7. SUMMARY AND EVOLUTIONS

In this paper, we present capa, a framework for mining
association rules from large-scale retail data. We deﬁned
3 mining scenarios allowing analysts to extract associations
between user segments and product categories, or products
themselves. Given a scenario, capa builds a dataset of
transactions and mines in parallel association rules contain-
ing targets selected by the analysts. Our main contribu-
tion is the study of 34 interestingness measures for associa-
tion rules. We ﬁrst performed an analytical and an empiri-
cal comparison between diﬀerent rule rankings and grouped
measures into 6 families. Resulting groups were then evalu-
ated in a user study involving retail experts. We concluded
that lift and Piatetsky-Shapiro best ﬁt the needs of the an-
alysts, as they ensure a high conﬁdence.

We foresee 3 directions of improvement for capa. The ﬁrst
one is related to the architecture. capa is currently imple-
mented using batch processing and on-disk storage. While
mining is already fast, I/O operations introduces some la-
tency between the deﬁnition of a mining scenario and the
display of results. We are currently migrating to an in-
memory dataset representation, using Spark [22], to allow
faster target selection and lower response time. A second im-
provement is the extraction of negative results (anti-rules).
That is particularly true for rules containing customer seg-
ments. We hence need to determine how negative rules
should be ranked in order to properly adjust their propor-
tion in the outcome. Finally, while quality measures are
crucial to select the most interesting results for the analysts,
we would like to introduce diversity in displaying rules and
study its impact on analysts’ satisfaction.

8. REFERENCES
[1] R. Agrawal, T. Imieliński, and A. Swami. Mining
Association Rules between Sets of Items in Large
Databases. In Proc. SIGMOD, pages 207–216, 1993.

[2] W. Daniel. Applied Nonparametric Statistics.

Houghton Miﬄin, 1978.

[3] J. Dean and S. Ghemawat. Mapreduce: Simpliﬁed

Data Processing on Large Clusters. Commun. ACM,
51(1):107–113, 2008.

12

[4] P. Suganthan G.C., C. Sun, K. Gayatri K., H. Zhang,

F. Yang, N. Rampalli, S. Prasad, E. Arcaute, G.
Krishnan, R. Deep, V. Raghavendra, A. Doan Why
Big Data Industrial Systems Need Rules and What
We Can Do About It. In Proc. SIGMOD, pages
265–276, 2015.

[5] L. Geng and H. J. Hamilton. Interestingness Measures

for Data Mining: A Survey. ACM Comput. Surv.,
38(3), 2006.

[6] S.i. Minato, T. Uno, K. Tsuda, A. Terada, and J. Sese.

A Fast Method of Statistical Assessment for
Combinatorial Hypotheses based on Frequent Itemset
Enumeration. Lect. Notes Artif. Int., 8725:422–436,
2014.

[7] K. Järvelin and J. Kekäläinen. Cumulated Gain-based
Evaluation of IR Techniques. ACM Trans. Inf. Syst.,
20(4):422–446, 2002.

[8] M. G. Kendall. A New Measure of Rank Correlation.

Biometrika, 30(1/2):81–93, 1938.

[9] M. Kirchgessner, V. Leroy, A. Termier,

S. Amer-Yahia, and M.-C. Rousset. jLCM.
http://slide-lig.github.io/jlcm/. [Online;
accessed 29-Feb-2016].

[10] T.-D. Le and D. Lo. Beyond Support and Conﬁdence:

Exploring Interestingness Measures for Rule-Based
Speciﬁcation Mining. In Proc. SANER, pages 331–340,
2015.

[11] P. Lenca, B. Vaillant, P. Meyer, and S. Lallich.

Association Rule Interestingness Measures:
Experimental and Theoretical Studies. In Quality
Measures in Data Mining, pages 51–76. Springer, 2007.

[12] G. Liu, M. Feng, Y. Wang, L. Wong, S.-K. Ng, T. L.

Mah, and E. J. D. Lee. Towards Exploratory
Hypothesis Testing and Analysis. In Proc. ICDE,
pages 745–756, 2011.

[13] S. Mishra, V. Leroy, and S. Amer-Yahia. Discovering

Characterizing Regions for Consumer Products. In
Proc. DSAA, 2015.

[14] N. Pasquier, Y. Bastide, R. Taouil, and L. Lakhal.

Discovering Frequent Closed Itemsets for Association
Rules. In Proc. ICDT, pages 398–416, 1999.

[15] J. Pei, J. Han, and R. Mao. Closet: An Eﬃcient

Algorithm for Mining Frequent Closed Itemsets. In
Proc. SIGMOD, pages 21–30, 2000.

[16] G. Piatetsky-Shapiro. Knowledge Discovery in
Databases. Menlo Park, CA: AAI/MIT, 1991.

[17] R. R. Sokal and C. D. Michener. A Statistical Method
for Evaluating Systematic Relationships. Univ. Kans.
Sci. Bull., 38:1409–1438, 1958.

[18] P.-N. Tan, M. Steinbach, and V. Kumar. Introduction

to Data Mining, (First Edition). W. W. Norton &
Company, 2007.

[19] The Apache Software Foundation. HBase.

http://hbase.apache.org. [Online; accessed
29-Feb-2016].

[20] T. Uno, M. Kiyomi, and H. Arimura. LCM ver. 2:

Eﬃcient Mining Algorithms for
Frequent/Closed/Maximal Itemsets. In Proc. ICDM
Workshop FIMI, 2004.

[21] V. K. Vavilapalli, A. C. Murthy, C. Douglas,

S. Agarwal, M. Konar, R. Evans, T. Graves, J. Lowe,

H. Shah, S. Seth, B. Saha, C. Curino, O. O’Malley,
S. Radia, B. Reed, and E. Baldeschwieler. Apache
Hadoop YARN: Yet Another Resource Negotiator. In
Proc. SOCC, pages 5:1–5:16, 2013.

[22] M. Zaharia, M. Chowdhury, M. J. Franklin,

S. Shenker, and I. Stoica. Spark: Cluster Computing
with Working Sets. In Proc. HotCloud, pages 10–10,
2010.

13

