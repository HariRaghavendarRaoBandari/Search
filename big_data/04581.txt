6
1
0
2

 
r
a

 

M
5
1

 
 
]

C
H
.
s
c
[
 
 

1
v
1
8
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Introspectibles: Tangible Interaction to Foster Introspection

Renaud Gervais

Inria, France

renaud.gervais@inria.fr

Joan Sol Roo
Inria, France

joan-sol.roo@inria.fr

J´er´emy Frey
Univ. Bordeaux,

France

jeremy.frey@inria.fr

Martin Hachet
Inria, France

martin.hachet@inria.fr

Figure 1: (Left) Tobe is a toolkit enabling the creation of tangible augmented customized bio- and neurofeedback. Here, two users are relaxing together
by using Tobe to reach cardiac coherence. (Middle) Teegi is an augmented tangible avatar that displays the user’s brain activity in real time. (Right)
Inner Garden is an augmented sandbox, linked to the user’s inner states via physiological sensors, designed for contemplative play.

ABSTRACT
Digital devices are now ubiquitous and have the potential to be
used to support positive changes in human lives and promote
psychological well-being. This paper presents three interactive
systems that we created focusing on introspection activities,
leveraging tangible interaction and spatial augmented reality.
More speciﬁcally, we describe anthropomorphic augmented
avatars that display the users’ inner states using physiological
sensors. We also present a ﬁrst prototype of an augmented
sandbox speciﬁcally dedicated to promoting mindfulness ac-
tivities.

Author Keywords
Mindfulness; Tangible Interaction; Spatial Augmented
Reality; Physiological Computing; Virtual Reality

ACM Classiﬁcation Keywords
H.5.1 Multimedia Information Systems: Artiﬁcial, augmented,
and virtual realities; H.5.2 User Interfaces: Prototyping

INTRODUCTION
Seeing the rise and ubiquitousness of the digital devices in
recent years, many Human-Computer Interaction (HCI) re-
searchers, designers and technologists have started looking
at computers not merely as devices to interact with, but as a
support of positive changes in their users’ lives. Examples of
this can be seen in the recent combination of positive psychol-
ogy [19] and the ﬁelds of design [3] and HCI [1]. There are
a multitude of factors that have been shown to contribute to
subjective well-being and Calvo and Peters [1] have made an
extensive inventory of them. In this paper, we present different
interactive systems that we created to foster introspection –
i.e. to reﬂect on our own selves. More speciﬁcally, we focused
on interoception – the ability to sense one’s internal bodily
signals [4] –, contemplation and ultimately mindfulness – a
broad and nonjudgmental present-moment awareness.
Traditional HCI is often focused on manipulating digital infor-
mation through devices. The vision of Ubiquitous Computing,
as proposed by Weiser [22], instead envisioned digital tech-
nology fused in the environment itself, only intervening when
necessary. One of the underlying goal was to create calm
experiences [23]. We present systems that are rooted in this
philosophy of infusing the real world with a digital overlay
so as to keep user’s awareness of the environment and create
such experiences. For this purpose, we are mostly leveraging
tools from Spatial Augmented Reality [17] and Tangible User
Interfaces [13].

CHI’16, May 07 - 12, 2016, San Jose, CA, USA
Copyright is held by the owner/author(s).

Notably, for interoception, we proposed two different aug-
mented tangible avatars (Figure 1, left and middle) represent-
ing real-time physiological measures – ElectroEncephaloG-
raphy (EEG), ElectroCardioGraphy (ECG), ElectroDermal
Activity (EDA), breathing. Also, we developed tools to craft
tailored representations of such signals. Then, based on the
toolkit we created, we target contemplative and mindfulness
practices. We built a ﬁrst prototype of an augmented physical
toy that took the form of an augmented sandbox hosting a digi-
tal world, which properties are mapped to the user’s breathing
and heart rate (Figure 1, right).

EXPOSING INNER STATES
We developed tools to let people discover and learn about their
inner selves. We got interested in tangible interaction, notably
because of pedagogical principles; learners better become
conscious of complex phenomena through self-investigation
and manipulations [21, 5]. Hence, we have been using tangible
augmented objects as a medium to grasp the complexity of
physiological activity and human minds.
Teegi [6] is a “puppet” that displays the users’ brain activity
in real time – recorded by the mean of EEG. Teegi proved to
be an appealing form factor, that favored the understanding of
how the brain works, even for novices with little or no prior
knowledge. The fact that Teegi is anthropomorphic encour-
ages users to “connect” with their avatars, as the combination
of anthropomorphism and tangibility foster social presence
and likability [18, 12, 11]. Moreover, this bond helps them
comprehend rather abstract information – i.e. brain activity –
that they could not directly sense otherwise. Indeed, cognitive
processes are difﬁcult to assimilate [15].
Teegi was a dedicated support for visualizing brain activity but
did not propose any high-level constructs such as workload or
attention. We went beyond this interface with the Tobe project
[9], which gave access to mental states alongside low level
signals (e.g. heartbeats, breathing). Moreover, we designed
wearable sensors, that could be equipped easily (Figure 2).
Because the dynamic representation of physiological signals
is still an open question at the moment [2], we conducted
surveys during a pilot study to gain more insight about the
knowledge and the representation people had. In particular,
we asked participants to express with drawings and text how
they would represent various metrics. We were surprised
by how creative people were; we found little resemblance
between participants for a given signal, even where we would
have expected a consensus to emerge – e.g. some people drew
a physiologically accurate heart instead of a simple sketch.
Therefore, the toolkit we built around Tobe also enables people
to tailor their own dynamic feedback, animated using their
real-time physiological measurements.
Not only does customized bio- and neurofeedbacks create
meaningful representations, but the very act of taking part
in the creation of the avatar, through 3D printing, increases
the involvement of users in the process. But far from gaining
simple knowledge, such emphasis on the body has immediate
beneﬁts. For instance, improving interoception could sufﬁce
to favor a better health [4]. Since interoception is also associ-

ated with empathy, it could affect how we feel toward others
[8]. By exposing overtly inner states – as we propose to do
with the tools we present – we sharpen human senses toward
themselves and others, for the better good of both.

SUPPORTING MINDFULNESS
One of our overarching goals was to eventually go beyond
“simple” feedback and interoception, and also directly support
mindfulness activities.
As a ﬁrst step in this direction, we put into practice the Tobe
system to create a multiuser relaxation experience, where pairs
of users had to synchronize their heart rates through breathing
exercises (Figure 1, left). From there, it encouraged us to go
further and to build a dedicated application and form factor
for mindful practices.
Inner Garden [20] is an augmented sandbox: a world in minia-
ture that slowly evolves according to the users’ inner state. The
system is inspired by both the reﬂective and metaphoric nature
of zen gardens as well as the playful and experimental nature
of sandboxes. Zen gardens are all about careful placement of
elements and are often used for contemplative and meditative
purposes. On the other hand, sandboxes call for interaction
and experimentation. Our main goal was to create an ambient
and meditative toy that could both include playful physical
creation and contemplation.
We designed Inner Garden as a toy: it can be played with,
without any inherent goal or rules. Since our objective was
to create a self-reﬂective and slow experience, mainly driven
by self-motivation and curiosity, a toy seemed the best sup-
port. Using this approach, Paulos et al. [16] created toys to
encourage children to explore their physical environment. An-
other example is the work of Karlesky et al. [14] who created
seemingly meaningless tangible toys in order to explore the
interaction that happens in the margins of creative work. The
sandbox itself can be made of any size. We built one that
is small enough to live on the side of the desk, acting as an
ambient display during the user’s daily activities, while the
user can also decide to interact directly. Alternatively, a bigger
one could support more users in a shared environment, such
as a living room at home or a break area at work.
Whenever the user alters the terrain, the modiﬁed section of
the simulation is restarted, living on its own. Grass grows,
trees starts appearing and water ﬂows. However, this process
takes place slowly. The growth speed and overall health of
the world, in combination with atmospheric effects (day-night
time-lapse, clouds and sea) are linked to the user’s inner state,
measured with EEG and a breathing belt.
The main objective of the system is to foster contemplative and
reﬂective activities. The small living world is a peaceful, slow
display, while also motivating the users to practice relaxing
breathing exercises whenever they want to take a moment for
themselves.

DISCUSSION
In our undergoing Inner Garden project, we are interested both
in social interactions and in individual user experience. We
would like to install the Inner Garden in shared spaces, such

(a)

(b)

(c)

(d)

Figure 2: Wearables. a: coat embedding ECG sensors; b: ﬁngerless glove measuring EDA; c: breathing belt; d: EEG headband.

as break rooms or living rooms. Different colleagues or family
members could work together onto shaping the world, and then
the world would evolve according to their states – monitored
using wearable sensors such as smartwatches – e.g. Empat-
ica’s E41. This could lead to interpersonal interactions, both
in working together to improve the garden and cultivating
empathy between participants.
We envision the inclusion of Virtual Reality (VR) using a
Head Mounted Display (HMD) – such as the Oculus Rift2
– enabling a user to have a private session inside the garden.
While immersed, the world evolution would be slowed down,
and the user could experience the biofeedback directly (e.g. his
or her breath controlling the sea waves or the wind). Another
advantage of the use of VR is that, since the user is already
being equipped with the HMD, the addition of physiological
sensors could be done seamlessly, such as EEG electrodes
embedded in the HMD’s elastic strap – see also [10] for an
example on how to use head mounted devices to measure
breathing and heart rate.

What we want to measure
As we propose to make available a shared space that people
could interact with and contemplate, we want to learn how
such ambient system could alter how we relate to one an-
other. We believe that, by itself, an augmented sandbox left at
disposal in a working environment or at home could prompt
direct interactions between passersby, improving connected-
ness – e.g. “team building”. We envision to test the system
for a prolonged period of time (several weeks), so we could
measure potential changes in interpersonal relationships. No-
tably, it will be important to assess if these changes are due to
a novelty effect and if they eventually will settle back to the
previous dynamics.
We also plan to use the Inner Garden to propose mindfulness
experiences and familiarize people with introspection. We
will let users immerse themselves in the Inner Garden using
a HMD, and we will augment their sensing capabilities by
the mean of physiological sensors. Hence, we are curious to
know if people will seize these technologies as an opportunity
for self-empowerment and we wonder how much the system
could guide them toward healthier habits.
The technology we developed is a mean, not an end. The Inner
Garden is a stand for raising awareness toward others and our

1https://www.empatica.com/
2https://www.oculus.com/

own selves. We seek to measure how the beneﬁcial effects,
such as a mindful routine, induced by the Inner Garden (if
any) echoes beyond its direct usage. Ultimately, it would be
desirable that these effects persist months after the system is
removed.

How to Measure
Inquiries shall be the principal evaluation method to gather
insights about how people welcome the system. Beside sur-
veys, we plan to conduct regular interviews; freely discussing
with several users will notably help to assess the social impact
of the system and gauge which aspects of the Inner Garden
should be reﬁned.
However, the very hardware that we employ to run the sys-
tem is an opportunity to also collect exocentric measures, as
deﬁned in [7]. Indeed, the cameras that we use for augment-
ing the sandbox can also record how users interact with the
system and in the surrounding space. Such video feed could
then be processed to observe peoples’ behavior – e.g. number
and duration of the interactions, if they rather play with the
sandbox or use the virtual reality modality, to what or whom
they look at, how much they move, and so on.
Moreover, the physiological signals that are used to give an
online biofeedback to users could be recorded and further
analyzed ofﬂine. Features such as breathing patterns, heart
rate variability or synchronization between brain areas could
give metrics about relaxation or meditative state – see [9].
Such metrics could be investigated over weeks to sense how
users evolve.
Finally, being able to bring altogether inquiries, behavioral
data and physiological sensors – varying from qualitative to
quantitative measures – will help to contextualize our ﬁndings
so we could iterate over our system, aiming to support mind-
fulness practices, especially mindfulness meditation sessions.

CONCLUSION
We have presented three different interactive systems based on
tangible interaction to foster introspection. More speciﬁcally,
we described how anthropomorphic avatars could raise aware-
ness on the inner working of our bodies and minds and support
interoception. We also presented a ﬁrst prototype of another
form factor of our toolkit, an augmented sandbox speciﬁcally
dedicated to promoting mindfulness activities. We believe that
tangible ambient installations, as opposed to regular displays,
have great potential for these purposes since they are anchored
in reality, which mindfulness is all about.

REFERENCES
1. Rafael A Calvo and Dorian Peters. 2014. Positive
Computing: Technology for wellbeing and human
potential. MIT Press.

2. G. Chanel and C. Muhl. 2015. Connecting Brains and
Bodies: Applying Physiological Computing to Support
Social Interaction. Interacting with Computers (2015).

3. Pieter Desmet and Marc Hassenzahl. 2012. Towards

happiness: Possibility-driven design. In Human-computer
interaction: The agency perspective. Springer, 3–27.

4. Norman Farb, Jennifer J Daubenmier, Cynthia J Price,
Tim Gard, Catherine Kerr, Barney Dunn, Anne Carolyn
KLein, Martin P Paulus, and Wolf E Mehling. 2015.
Interoception, Contemplative Practice, and Health. Name:
Frontiers in Psychology 6 (2015), 763.

5. St´ephanie Fleck and Gilles Simon. 2013. An Augmented

Reality Environment for Astronomy Learning in
Elementary Grades: An Exploratory Study. In IHM ’13.
9.

6. J´er´emy Frey, Renaud Gervais, St´ephanie Fleck, Fabien
Lotte, and Martin Hachet. 2014a. Teegi: Tangible EEG
Interface. In Proceedings of the 27th Annual ACM
Symposium on User Interface Software and Technology
(UIST ’14). ACM, 301–308.

7. J´er´emy Frey, Christian M¨uhl, Fabien Lotte, and Martin

Hachet. 2014b. Review of the use of
electroencephalography as an evaluation method for
human-computer interaction. In PhyCS - International
Conference on Physiological Computing Systems.

8. Hirokata Fukushima, Yuri Terasawa, and Satoshi Umeda.

2011. Association between interoception and empathy:
evidence from heartbeat-evoked brain potential.
International journal of psychophysiology : ofﬁcial
journal of the International Organization of
Psychophysiology 79, 2 (feb 2011), 259–65.

9. Renaud Gervais, J´er´emy Frey, Alexis Gay, Fabien Lotte,
and Martin Hachet. 2016. TOBE: Tangible Out-of-Body
Experience. In Proceedings of the 10th International
Conference on Tangible, Embedded and Embodied
Interaction (TEI ’16). ACM, Eindhoven, Netherlands.

10. Javier Hernandez, Yin Li, James M. Rehg, and

Rosalind W. Picard. 2015. Cardiac and Respiratory
Parameter Estimation Using Head-mounted
Motion-sensitive Sensors. EAI Endorsed Transactions on
Pervasive Health and Technology 1, 1 (may 2015), e2.

11. Michael S Horn, Erin Treacy Solovey, R Jordan Crouser,

and Robert J K Jacob. 2009. Comparing the use of
tangible and graphical programming languages for
informal science education. In CHI ’09, Vol. 32. 975.

12. Eva Hornecker. 2011. The role of physicality in tangible
and embodied interactions. Interactions 18, 2 (2011), 19.

13. Hiroshi Ishii and Brygg Ullmer. 1997. Tangible Bits:

Towards Seamless Interfaces Between People, Bits and
Atoms. In CHI. ACM, 234–241.

14. Michael Karlesky and Katherine Isbister. 2014.

Designing for the Physical Margins of Digital
Workspaces: Fidget Widgets in Support of Productivity
and Creativity. In TEI ’14.

15. Richard E. Nisbett and Timothy DeCamp Wilson. 1977.
Telling more than we can know: Verbal reports on mental
processes. Psychological Review 84, 3 (1977), 231–260.

16. Eric Paulos, Chris Myers, Rundong Tian, and Paxton

Paulos. 2014. Sensory triptych: here, near, out there. In
Proceedings of the 27th annual ACM symposium on User
interface software and technology. ACM, 491–496.

17. Ramesh Raskar, Greg Welch, and Henry Fuchs. 1998.
Spatially augmented reality. In IWAR. Citeseer, 11–20.

18. Michael Schmitz. 2010. Tangible Interaction with
Anthropomorphic Smart Objects in Instrumented
Environments. Ph.D. Dissertation.

19. Martin EP Seligman and Mihaly Csikszentmihalyi. 2000.
Positive psychology: An introduction. Vol. 55. American
Psychological Association.

20. Joan Sol Roo, Renaud Gervais, and Martin Hachet. 2016.

Inner Garden: an Augmented Sandbox Designed for
Self-Reﬂection. In Proceedings of the 10th International
Conference on Tangible, Embedded and Embodied
Interaction (TEI ’16). ACM, Eindhoven, Netherlands.
Work-in-Progress.

21. S. Vosniadou, C. Ioannides, A. Dimitrakopoulou, and E.
Papademetriou. 2001. Designing learning environments
to promote conceptual change in science. Learn Instr 11
(2001), 381–419.

22. Mark Weiser. 1991. The computer for the 21st century.

Scientiﬁc american 265, 3 (1991), 94–104.

23. Mark Weiser and John Seely Brown. 1996. Designing

calm technology, 1995. PowerGrid Journal 1, 1 (1996),
75–85.

