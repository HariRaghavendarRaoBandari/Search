6
1
0
2

 
r
a

M
8

 

 
 
]
S
D
h
t
a
m

.

[
 
 

1
v
6
0
4
2
0

.

3
0
6
1
:
v
i
X
r
a

Weakly Coupled Oscillators in a Slowly Varying

World

Youngmin Park∗& Bard Ermentrout

Department of Mathematics

University of Pittsburgh

Pittsburgh PA 15260

March 9, 2016

Abstract

We extend the theory of weakly coupled oscillators to incorporate
slowly varying inputs and parameters. We employ a combination of
regular perturbation and an adiabatic approximation to derive equa-
tions for the phase-diﬀerence between a pair of oscillators. We apply
this to the simple Hopf oscillator and then to a biophysical model.
The latter represents the behavior of a neuron that is subject to slow
modulation of a muscarinic current such as would occur during tran-
sient attention through cholinergic activation. Our method extends
and simpliﬁes the recent work of Kurebayashi [17] to include coupling.
We apply the method to an all-to-all network and show that there is
a waxing and waning of synchrony of modulated neurons.

Keywords Modulation - weak coupling - oscillators - Traub model - slowly
varying parameters

1

Introduction

The theory of weakly coupled oscillators [8, 9, 16] has served very well as
a predictor of the dynamics in networks of coupled neural oscillators (for a
comprehensive review, see [24]). In the application of this theory, one gener-
ally assumes that, while the oscillators may have diﬀerent intrinsic frequen-
cies, these frequencies are ﬁxed as are the uncoupled limit-cycle oscillators.
However, more generally, local regions of the nervous system are constantly
modulated by extrinsic inputs and by slow processes such as the accumu-
lation of extracellular ions. Thus, synchronization and other properties are

∗Corresponding author. Email yop6@pitt.edu

1

likely to change due to this modulation which can change the frequency,
conductances, and even the synapses within an oscillatory network [21].

Neuronal modulators such as acetylcholine, norepinephrine [20], and
dopamine [11] are known to alter the ﬁring properties of neurons. These
properties, in turn, could alter the synchronization behavior of neurons and
more formally, the form that the weak coupling equations take. One of
the key components to understanding synchronization of neuronal oscilla-
tors is the phase response curve (PRC) which describes how the phase of
an oscillator is shifted by the timing of inputs. The PRC plays the key
role in determining whether or not a pair of coupled neuronal oscillators
will synchronize or not. In [26, 27], the authors directly demonstrated that
cholinergic modulation of a cortical pyramidal neuron had a profound eﬀect
on the shape of the PRC. Acetylcholine is known to directly act on the so-
called M-type potassium current and in [5], they showed how changing the
strength of this current made a huge diﬀerence on the shape of the PRC as
well as in the ability of synaptically coupled neurons to synchronize. Neu-
ronal properties are also aﬀected by the extracellular milieu, notably, con-
centration of extracellular potassium which can profoundly alter excitability
of neurons [2]. Rubin et al [23] showed that the synchronization between
two coupled neurons was strongly dependent on the mean concentration of
extracellular potassium. Jeong and Gutkin [13] showed the changes in the
reversal potential of GABAergic conductances changed the ability of neu-
rons to synchronize; the reversal potential is mainly driven by extracellular
chloride. Thus, since many neuromodulators as well as the ionic concentra-
tions are constantly changing, it is important to see how this time varying
environment alters the ability of neurons to synchronize.

In two recent papers Kurebayashi et al [17, 18], extended the notion of
phase reduction to oscillators that are subject to large slowly varying pa-
rameters. They demonstrated that the evolution of the phase depended, not
just on the instantaneous frequency of the oscillator, but, also on the rate of
change of the slowly varying parameter. In this paper, we re-derive the phase
equation in [17] by using the method of adiabatic invariance [14] (Chapter
12.1.2) and incorporate the slow variation of parameters into weak coupling
of oscillators using the Fredholm alternative. Thus we have a theory to pre-
dict synchrony and antiphase along with stability, in the presence of a slowly
varying parameter. Moreover, because we only assume the parameter to be
slowly varying, our theory is shown to accurately predict phase diﬀerences
with periodic, quasi-periodic, and stochastic slowly varying parameters.

We ﬁrst derive the equations for the phases and the phase-diﬀerences
for a pair of coupled oscillators that are subject to slow changes in a pa-
rameter. Next, we apply the theory to the Hopf oscillator (so-called λ − ω
system, [15]) where all of the required functions for our analysis can be ex-
actly derived. We then consider a biophysical Hodgkin-Huxley model for
pyramidal neurons (the simpliﬁed “Traub” model [5]). This model includes

2

an M-type potassium current, so in our analysis and simulations, we allow
the conductance to slowly change as a model for cholinergic modulation. We
conclude with a discussion and contrast the results with fast modulation.

2 Methods

2.1 Weakly Coupled Oscillators With a Slowly Varying Pa-

rameter

We consider a pair of weakly coupled slowly-varying oscillators:

dX a
dt
dX b
dt

= F (X a, q(t)) + Ga(X b, X a)

(1)

= F (X b, q(t)) + Gb(X a, X b)

where 0 <  (cid:28) 1 is a small parameter. We assume that the slowly varying
parameter, q, lies in an interval Q := [q−, q+] such that for each q ∈ Q, the
system:

dX
dt

= F (X, q)

has an asymptotically stable limit cycle with frequency ω(q). The period
of the oscillators is just T (q) = 2π/ω(q). Thus, each of the two oscillators
is modulated by a common slowly varying signal, q(t) that can alter the
shape and frequency of the rhythm but does not destroy its existence. The
functions Ga,b represent the weak coupling between the two oscillators. If
there is no modulation of the oscillations, then, we can regard equation (1) as
a standard weakly coupled system. However, the slow modulation changes
the dynamics and interactions in a way that we will now demonstrate. We
point out that [17] derived the phase modulation for a single slowly varying
oscillator using successive changes of variables and showed that the “naive”
phase approximation was not valid. More precisely, the term β(τ ) deﬁned
in equation (9) accounts for possibly large variations in the slowly varying
parameter. Therefore, omitting this term (the “naive” approximation) from
equations (7)–(8) results in a poor phase approximation in the case of a
single forced oscillator. Here, we introduce a simpler way to derive the same
equations using a standard adiabatic approximation [14], and extend the
results to coupled oscillators.
In the coupled oscillator case, the “naive”
phase approximation is valid.

Clearly, there are two time scales in this problem, a slow time scale,
τ = t and a fast time scale, s that is related to t. To put everything on a
similar fast time scale, we generally allow that

ds
dt

= g(τ, )

3

and expand to get a relationship between s and t that is τ−dependent.
However, we need only terms in the lowest order in the fast time scale, so
we will simply cut to the chase and write s = ω(q)t, so that the oscillators are
all 2π−periodic in s. (For the time being, we have suppressed the implicit
τ dependence of the fast time scale, by just putting the parameter q in the
frequency, but, in fact, q is just shorthand notation for q(τ ).)

Before continuing with the perturbation, we introduce some additional

notation. Let U0(s, q) be the limit cycle solution to the uncoupled system

ω(q)∂U/∂s = F (U, q),

(2)

and let A(s, q) := DU F (U0, q) be the linearization of the uncoupled system
evaluated at the limit cycle. By taking the derivative with respect to s on
both sides of equation (2), we see that the linear equation

L(s, q)Y := ω(q)

− A(s, q)Y = 0

∂Y
∂s

(3)

has a periodic solution given by ∂sU0(s, q) where the notation, ∂s means
diﬀerentiation with respect to the ﬁrst component in U0. Associated with
the set of 2π−periodic functions is an inner product deﬁned as

(cid:90) 2π

(cid:104)Y1(s), Y2(s)(cid:105) =

Y1(s) · Y2(s) ds,

where Y1·Y2 is the standard Euclidean dot product. With this inner product,
the linearized equation has a well-deﬁned adjoint operator:

0

L∗(s, q)Y := ω(q)

∂Y
∂s

+ AT (s, q)Y,

(4)

from which we attain the adjoint equation,

ω(q)

∂Y ∗
∂s

= −AT (s, q)Y ∗

where AT is the transpose. There is a unique 2π−periodic solution to the
adjoint equation, which we call Z(s, q) such that

Z(s, q) · ∂U0(s, q)

∂s

= 1.

Finally, the linearization has the Fredholm alternative property [14]. That
is, there is a 2π−periodic solution to:

L(s, q)Y = b(s)

(5)

where b(s) is 2π−periodic and L is deﬁned in (3) if and only if

(cid:90) 2π

Z(s, q) · b(s) ds = 0.

0

4

With these preliminaries deﬁned, we are now ready to analyze weak coupling
of slowly varying oscillators.

We assume that the solutions to equation (1) can be expressed in a series

in  and have the form

X a(t, ) = X a
X b(t, ) = X b

0 (s, τ ) + X a
0(s, τ ) + X b

1 (s, τ ) + . . .
1(s, τ ) + . . . .

To lowest order, we must have

ω(q(τ ))

∂X a,b
0 (s, τ )
∂s

= F (X a,b

0 (s, τ ), q(τ )).

The 2π−periodic limit cycle solution to this problem is

X a,b

0 (s, τ ) = U0(s + θa,b(τ ), q(τ ))

where θa,b(τ ) are slowly varying arbitrary phase shifts due to the time-
translation invariance of the limit cycle. Our goal is to now derive equations
for the slow evolution of the phase. Using the chain rule, we see that d/dt =
ω∂/∂s + ∂/∂τ. Thus, after a bit of rearranging, the next order equations
are:

L(s, q(τ ))X a

1 (s, τ ) = −∂sU0(s + θa(τ ), q(τ ))
−∂qU0(s + θa(τ ), q(τ ))
+Ga[U0(s + θb(τ ), q(τ )), U0(s + θa(τ ), q(τ ))],

∂θa
∂τ
dq
∂τ

(6)

where L(s, q(τ )) is deﬁned by (3). There is a similar equation for X b
1(s, τ ).
Finally, we see that this equation has the form of (5), so that there is a
2π−periodic solution if and only if the right-hand side is orthogonal to the
adjoint. This leads to the following equations for the phases:

= −β(τ ) + ha(θb − θa, τ )
= −β(τ ) + hb(θa − θb, τ ),

Z(s, q(τ )) · ∂qU0(s, q(τ ))

∂q
∂τ

ds

(7)

(8)

(9)

∂θa
∂τ
∂θb
∂τ

(cid:90) 2π
(cid:90) 2π

0

where,

β(τ ) =

ha,b(φ, τ ) =

Z(s, q(τ )) · Ga,b[U0(s + φ, q(τ )), U0(s, q(τ ))] ds. (10)

0

The extra β(τ ) term arises due to the fact that the parameter q is slowly
varying. Notice in its deﬁnition through equation (9), that it is proportional

5

to the time derivative of q(τ ). This is the term that [17] emphasized in their
analysis. That is, we recover their results if we ignore coupling. We remark
that the phase-interaction functions, ha,b(·) are exactly those that would
be obtained from standard weak-coupling theory with all parameters held
ﬁxed. In absence of coupling, the total phase evolves as

(cid:90) t

θ(t) = θ(0) + ω(q(τ ))t − 

β(t(cid:48)) dt(cid:48).

0

If both oscillators are subject to the exact same slowly varying inputs, then
the β term becomes irrelevant to their phase diﬀerence, φ := θb − θa which
satisﬁes the simple scalar slowly varying equation [24]:
= hb(−φ, τ ) − ha(φ, τ ) := G(φ, τ )

(11)

dφ
dτ

Equation (11) will be our main tool for comparing the phase reduced model
to the full model. We remark that the interaction functions are τ−dependent,
so that the reduced system for the phase-diﬀerence is no longer autonomous
and we will not be able to write exact solutions. However, if ha = hb,
then the right-hand side of equation (11) is, for each τ , an odd periodic
function of φ, so that φ = 0, π will always be equilibrium points. That is
G(0, τ ) = G(π, τ ) = 0 for all τ. In this symmetric case, we deﬁne Hodd to be
the odd part of the function ha.

2.2 Mode Truncation

In order to study the phase-reduced equations, we need to get formulae for
the τ−dependent interaction functions, ha,b. For our ﬁrst application of
the method, these functions are explicitly computable since the oscillation
and the adjoint are simple sine and cosine functions. However, for the
neural model that we also study (and which gives more interesting results),
we need to somehow approximate the required slowly varying functions.
To this end, we use XPPAUT [4] to numerically compute the adjoint and
interaction functions. For each interaction function we perform a mode
truncation (that is, we keep just a few of the Fourier terms). We ﬁnish
the approximation by deriving a q-dependent equation for the coeﬃcients of
the Fourier series expansion; generally piecewise-linear. This approximation
serves particularly well for our problem because only two sine coeﬃcients are
required to preserve the change in synchrony, bistability between synchrony
and antiphase (π−phase diﬀerence), and other interesting phenomena.

3 Results

We apply our theory to the Lambda-Omega system and a modiﬁed Traub
model with adaptation. For each model, we consider three types of slowly

6

varying parameters, which we brieﬂy discuss before delving into the details
of each model. We remark that all ﬁgure code and relevant data ﬁles are
available on github at https://github.com/youngmp/park and ermentrout
2016

3.1 Slowly Varying Parameters

The slowly varying parameter, q(τ ), is explicitly written as three types of
slowly varying parameters: periodic (qp), quasi-periodic (qqp), and stochastic
(qs):

qp(τ ) := q0 + q1 cos(f τ ),

qqp(τ ) := q0 + (q1/2)(cos(f τ ) + cos(f τ
qs(τ ) := q0 + q1z(τ ).

√

2)),

(12)

The terms qi, f , and ε depend on the system. For the Lambda-Omega
system, we choose f = 1 and various combinations of q0 and q1 because the
choice of qi aﬀects the asymptotic dynamics. Surveying multiple values of qi
provides a more complete demonstration of the dynamics and the accuracy
of our theory. For the Traub model, we chose by default q0 = 0.3, q1 = 0.2,
and f = 5 unless otherwise stated (as in ﬁgure 8). The default choice of
parameters represents a biophysically realistic parameter range, while the
slightly diﬀerent parameter choice in ﬁgure 8 demonstrates the accuracy of
our theory when we avoid slow stability changes.

The noisy parameter, z, is an Ornstein-Uhlenbeck (OU) process satisfy-

ing the stochastic diﬀerential equation

µdz = −zdt +

√

µdW,

where µ = 1000. The raw random noise data is normalized so that

z(τ ) ∈ [−1, 1],

∀τ,

and this data is used in all noisy simulations. The OU data may be repro-
duced by using XPP seeds 1–4.

3.2 Lambda-Omega System
We ﬁrst apply our result to the λ−ω system [15] with weak diﬀusive coupling,

(cid:19)(cid:18)xj

(cid:19)

yj

(cid:18)1 −κ

(cid:19)(cid:18)xk − xj

(cid:19)

+ ε

κ

1

yk − yj

(13)

(cid:18) ˙xj

(cid:19)

=

(cid:18) λ(rj)

˙yj

ω(rj, q(τ ))

λ(rj)
where j, k = 1, 2 and k (cid:54)= j; rj :=

−ω(rj, q(τ ))

(cid:113)

j + y2
x2
λ(r) = 1 − r2

j ; and

ω(r, q) = 1 + q(r2 − 1).

7

When ε = 0, equation (13) is equivalent to the Hopf oscillator in polar

coordinates,

˙rj = rjλ(rj)
˙θj = ω(rj, q(τ )).

One can verify the limit cycle for uncoupled system is

U0(s, τ ) = [cos(s), sin(s)]T ,

and the solution to the adjoint equation (the iPRC) is

Z(t) = [q(τ ) cos(t) − sin(t), q(τ ) sin(t) + cos(t)]T .

Finally, Equation (11) for the λ − ω system is

= 2 (κq(τ ) − 1) sin(φ).

dφ
dτ

(14)

Note that synchrony (φ = 0) is indeed a ﬁxed point of Eq. 14. For a brief
stability analysis, we note that equation (14) is a separable equation and
solve for an implicit solution the diﬀerential equation:

(cid:20)(cid:90) τ

(cid:21)

We can write the inside of the exponential as τ Q(τ ) where Q(τ ) = (1/τ )(cid:82) τ

tan(φ/2) = c exp

0

(κq(s) − 1)ds

.

(15)

0 [κq(s)−

1] ds. Q(τ ) is the running average of the integrand. Since the integrand is
bounded and continuous, the limit of Q(τ ) exists as τ → ∞. If this limit
is positive then the exponential diverges to +∞ and the phase φ → ±π.
Similarly, if the limit is negative, then the exponential goes to zero and φ
converges to 0 as well.

Figure 1 shows the result of simulating equation (13) for diﬀerent func-
tions of q(τ ). In the left column (labeled a,c,e) the mean value of q(τ ) is less
than 1, so that we expect that the phase diﬀerences will go to synchrony. In
the right panels, the mean value of q(τ ) > 1 so that the theory predicts that
phase-diﬀerences will go to π. This is clearly evident from the simulations
of the full model. Furthermore, the approach to equilibrium predicted by
the phase model is almost identical to that of the full simulations. There
is very little error even in the stochastic cases (panels e,f). Even though
this is a highly nonlinear system, the system goes to the stable state that
is appropriate for the average of the slowly varying parameter. If we break
the homogeneity, then the dynamics is more complex and interesting.

8

Figure 1: Periodic ((a),(b)), quasi-periodic ((c),(d)) and stochastic ((e),(f))
slowly varying parameters. The phase diﬀerence φ = θ2 − θ1 theory (light
blue dashed line) is plotted on top of experiment (black solid line). The
slow periodic parameter is shown as a dashed red line. The horizontal line
represents the parameter value q at which there is onset or oﬀset of syn-
chrony. For all subﬁgures, ε = 0.0025, f = κ = q1 = 1.
(a) Periodic,
q0 = 0.9, E[q] < 1. (b) Periodic, q0 = 1.1, E[q] > 1. (c) Quasi-periodic,
q0 = 0.9, E[q] < 1. (d) Quasi-periodic, q0 = 1.1, E[q] > 1. (e) Stochastic
(OU), q0 = 0.85, E[q] = 0.913, XPP seed 2. (f) Stochastic (OU), q0 = 0.9,
E[q] = 1.145, XPP seed 1.

Heterogeneities.

So far, the model derivation assumes that both oscillators are identical.
However, in general, this will not necessarily be the case. If the diﬀerences
are O() (that is, small) then we will get some additional terms in the phase
equations. To account for this, in general, we add terms to equation (1) of
the form:

fa,b(X a,b, τ )

(16)

9

where we could also include some τ -dependence in the heterogeneity. For
example, in the λ − ω system, we could set

ωa,b(r, q) = 1 + q(τ )(r2 − 1) + [da,b + ca,b(τ )(r2 − 1)]

where the subscripts refer again to the two oscillators. Here, the parameters
da,b are just constants that aﬀect the baseline frequency and ca,b(τ ) are
modulatory. With the addition of the terms (16), the phase equations we
get are like equations (7-8) but have additional terms:

= −β(τ ) + ηa(τ ) + ha(θb − θa, τ )
= −β(τ ) + ηb(τ ) + hb(θa − θb, τ ),

∂θa
∂τ
∂θb
∂τ

where

ηa,b(τ ) =

(cid:90) 2π

Z(s, q(τ )) · fa,b(U0(s, q(τ )), τ ) ds.

0

Subtracting the two equations yields the more general phase equation with
heterogeneities:

= ηb(τ ) − ηa(τ ) + hb(−φ, τ ) − ha(φ, τ ) := G(φ, τ ).

(17)

dφ
dτ

We have still eliminated the commmon O(1) slow variation β(τ ), but the
explicit heterogeneities appear threough the diﬀerences ηb(τ ) − ηa(τ ).

With this extension, we now alter the simple model by introducing a
small frequency diﬀerence in the oscillators. For oscillator 2, we replace
ω(r, q) = 1 + q(1 − r2) with ω(r, q) = 1 + d + q(1 − r2), so that in absence
of coupling, there is an order  frequency diﬀerence, d. In this case the
equation for φ becomes

= d + 2 (κq(τ ) − 1) sin(φ).

dφ
dτ

(18)

This means that φ(τ ) will no longer generally approach a steady state. In
ﬁgure 2 we show two simulations with diﬀerent values of  when there is a
slight diﬀerence in frequency. For  = 0.025, the solutions match for most
of the time, but there are places in each segment, where the solutions are
about π out of phase. On the other hand, when we reduce  by factor of 10,
the solutions to the full model and the phase model are indistinguishable.

As the eﬀects of heterogeneities are rather interesting, even in this simple
case, we will now examine equation (18) in more detail in order to explain
the behavior in ﬁgure 2. We can rewrite equation (18) as a system with the
time rescaled:

φ(cid:48) = (d + 2(q(s) − 1) sin φ)/f
s(cid:48) = 1.

10

Figure 2: The eﬀects of inhomogeneity on slowly modulated solutions. The
slowly varying parameter is chosen to be periodic with q0 = 1.1, q1 = 2, f =
1.3, d = 0.05, κ = 1.
(a)  = 0.025 (b)  = 0.0025. Black is the full
model and blue dashed is the phase-reduced model. The solid gray lines at
φ(t) = 0 ≡ 2π (φ(t) = π) represent synchrony (anti-phase).

11

0200040006000t0π2π3π22πφ(t)0200004000060000t0π2π3π22πφ(t)This is an equation on the torus and so the behavior is fairly restricted;
in particular, the ratio ρ = limτ→∞ φ/s, called the rotation number is a
continuous function of the parameters. We ﬁnd three diﬀerent behaviors as
the inhomogeneity d and the frequency f vary. Figure 3 shows the behavior
as these parameters are varied. In the upper left part of the diagram (high
frequency), above the red curve, φ(τ ) has a winding number of 0. That is,
φ(τ + 2π) = φ(τ ). This means that the phase-diﬀerence, φ between the two
oscillators is bounded between two values and one oscillator is consistently
ahead of the other. In the lower right part of the diagram (low frequency),
φ(τ +2π) = φ(τ )+2π, that is, φ has winding number 1. This means that the
phase-diﬀerence between the two neurons stays close to 0 for about half a
cycle and close to π for the other half and makes these switches rapidly and
periodically; it does not get “stuck” at synchrony or anti-phase. Finally, the
middle region (and also the choice used in ﬁgure 2) shows that the the phase
makes rapid transition, ﬁrst between π and 2π and then between π and 0.
This explains the switching back and forth observed in ﬁgure 2. In sum,
heterogeneity (even in the simplest form) can add good deal of complexity
to the dynamics.

3.3 Traub Model with Adaptation

The membrane potential dynamics of the Traub model, V , satisﬁes
C ˙V = −gN am3h(V − EN a) − (gkn4 + q(τ )w)(V − Ek) − gl(V − El) + I

≡ f (V, q(τ )),

(19)
where q(τ ) is the slowly varying parameter with q ∈ [0.1, 0.5], q0 = 0.3,
q1 = 0.2, and gating variables n, m, h, w satisfying
˙n = an(V )(1 − n) − bn(V )n,
˙m = am(V )(1 − m) − bm(V )m,
˙h = ah(V )(1 − h) − bh(V )h,
˙w = (w∞(V ) − w)/tw(V ).

We introduce weak coupling by adding a synaptic conductance

= f (V1, q(τ )) + εgs2(Esyn − V1),
= f (V2, q(τ )) + εgs1(Esyn − V2),

dV1
dt
dV2
dt

where si is the synaptic conductance of Vi and satisﬁes

˙si = α(Vi)(1 − si) − si/τs.

12

Figure 3: The behavior of equation (18) for periodic modulation as a func-
tion of the homogeneity, d and the modulation frequency, f . Green points
show the border for 1 : 1 locking; red points show the border for 0 : 1 locking
and between these are mixed solutions. Typical phase-planes are shown in
each region.

13

 0 0.5 1 1.5 2 0 0.02 0.04 0.06 0.08 0.1 0.12 0.140123456012345601234560123456012345601234562(cid:47)2(cid:47)000dfs02(cid:47)s(cid:113)(cid:113)s(cid:113)02(cid:47)2(cid:47)02(cid:47)Figure 4: The Traub model (equation (19) for two ﬁxed values of q, the
M-type potassium current. (a) the adjoints for q = 0.1 and q = 0.5; (b)
The odd part of the interaction functions for q = 0.1, 0.5 (thick lines) and
two-term sine ﬁt (thin dashed lines) of Hodd(φ). Zero crossings in (b) are
denoted by black circles.

Here α(V ) = 4/(1 + exp(−v/5)) [29]. Adaptation in this model is con-
trolled by the magnitude of the M−type potassium current. This low-
threshold, slow current can drastically aﬀect the dynamics of the Traub
model [5] changing it from Class I excitable (oscillation arises via a saddle-
node inﬁnite cycle or SNIC) to class II excitable (oscillation arises via a
sub-critical Hopf bifurcation). Because of that change, the adjoint, Z(t)
can also drastically change [1, 6] and thus, the interaction function will also
be strongly aﬀected. Biologically, this current is quite important since it is
altered by acetylcholine, a neuromodulator. Thus, since neuromodulators
tend to operate at much slower time scales than the ﬁring rates of neurons,
the slow alteration of the M−type potassium current is an ideal example of
the methods we have developed in this paper.

Figure 4 shows the results of a numerical computation of the adjoint and
the odd part of the interaction function. For small values of the M-current
(q = 0.1) the adjoint (a) is almost strictly positive which is typical for so-
called Class I excitable systems where the periodic orbit arises as a SNIC.

14

0π2π3π22πφ0.00.51.01.5Zq=0.5q=0.10π2π3π22πφ−15−10−5051015Hodd(φ)q=0.1q=0.5On the lower panel (b) we see that the Hodd(φ) is small and that synchrony
is unstable. (Recall that the phase model satisﬁes, φ(cid:48) = −2Hodd(φ), so that
a negative (positive) slope at an equilibrium is unstable (stable).) Anti-
phase (φ = π) is also unstable, but there are two stable ﬁxed points that are
near anti-phase. When there is suﬃcient M-current (q = 0.5), the adjoint
has a large negative lobe right after the spike. This qualitative change
in the shape of the adjoint leads to the stabilization of the synchronous
state (panel b). Thus, as q is varied from a low to high value, we expect
that the phase-diﬀerence will move toward synchrony (at high values) and
away from synchrony (at lower values). Panel b also shows that a two-
term sine approximation is reasonable and captures the qualitative (and to
some extent, quantitative) shape of the functions.
In particular, the full
Hodd(φ) and the two-term sine approximation have the same equilibrium
point properties. For this reason, we make a simple linear interpolation
using a two term sine expansion of the interaction as q slowly varies. The
approximation is thus:

−2Hodd ≈ 2(b1(q(τ )) sin(φ) + b2(q(τ )) sin(2φ)),

where a linear approximation to bi(q) passing through the points (0.1, bi(0.1))
and (0.3, bi(0.3)) predicts onset and oﬀset of synchrony suﬃciently well:

bi(q) = 5(ˆbi(0.3) − ˆbi(0.1))q + 1.5ˆbi(0.1) − 0.5ˆbi(0.3),

i = 1, 2.

The number represented by ˆbi(x) is the actual coeﬃcient value at q = x (see
section 6.1).

In order to compare the slowly varying phase model to the full model,
we need a way to extract the phase from the full model. For the simple
λ− ω model, we could get the exact phase since the limit cycle is circle with
a constant angular velocity. One method that is commonly used is to apply
a Hilbert transform to the voltage and then extract the phase from this.
However, for the Traub model (and, in fact, any model), we have more than
just the voltage, so we can extract an approximate phase by picking a point
on the unperturbed limit cycle that is closest to the point whose phase we
wish to determine. (This is a fairly crude approximation; ideally, we would
determine which isochron the point lies on by integrating the initial data
forward for several periods and then matching the point. This method is
very time consuming [3], so we have opted for the simpler approximation.)
Figure 5 shows how this is done. We take the (V, n) coordinates of the
simulation and ﬁnd the value of (V, n) on the projected limit cycle that is
closest in distance to the point on the actual trajectory. Since the voltage
(V ) spans a region of about 150 and the recovery (n) spans values between 0
and 1, we scale the distance metric accordingly. We compute the variance of
V0(t), n0(t) over one cycle of the unperturbed limit cycle, call these (σ2
n).
Thus the distance is:

V , σ2

(cid:113)

dist(∆V, ∆n) :=

(∆V )2/σ2

V + (∆n)2/σ2
n.

15

Figure 5: How the phase is extracted. A trajectory in green is shown near
the limit cycle (red, for q = 0.1). The point (asterisk) on the trajectory is
closest to the magenta point on the limit cycle which has phase φ, so we
assign this phase. The black curve is the projection of the limit cycle for
q = 0.5.

We deﬁne the phase of a point (V (t), n(t)) to be the value φ that minimizes:

dist(V (t) − V0(φT /(2π)), n(t) − n0(φT /(2π))),

where T is the natural period of the unperturbed limit cycle. We pick
the comparison limit cycle (V0, n0) for a ﬁxed value of the slowly varying
parameter that is the mean value. However, as the ﬁgure shows, the phase
portrait is very similar for two diﬀerent values of q. As we will see later, this
method produces a very reasonable approximation of the phase.

The next three ﬁgures compare the approximated phase model with the
approximated phase extracted from the full model. That is, there are sev-
eral levels of approximation to compare the theory to the full model. As
described above, we approximate the function G(φ, τ ) in equation (11) by
two sine terms whose coeﬃcients are τ−dependent (cf Figure 4b). We ap-
ply the same slowly varying function for the conductance of the adaptation
current to get the τ−dependence for the phase model. We extract the ap-
proximate phase-diﬀerence from the full model and compare the result with

16

00.10.20.30.40.50.60.7-100-80-60-40-2002040θ=0Vnθ=φ*the phase-diﬀerence derived from equation (11). Figure 6 shows the result
of letting q vary periodically in time; the period is 5 seconds. The dashed
red curves show the modulation and the red line shows the mean value.
The light blue curve is the phase-diﬀerence as predicted by equation (11)
and the black dots are the instantaneous approximate phase-diﬀerences from
the model equations. Each dot represnts the phase value at approximately
1/300 of one period. Because the period of the oscillation varies from 12.65s
to 24.6s as a function of the slowly varying parameter, we can not give a pre-
cise total number of cycles. However, based on the total times one oscillator
passes through zero phase, we estimate that there are 245 total cycles.
On the falling phase of the modulation (say, t = 2.5 − 5, t = 8 − 10,
etc) the phase model and the full model agree very closely, On the rising
phase, the reduced system lags the full system by quite a bit. Since both the
rising and falling parts of the stimulus include all ranges of q, this diﬀerence
cannot be due to a bad approximation of the interaction functions. As we
noted above, the synchronous solution is a ﬁxed point and for a range of q, it
is attracting. Because synchrony is a ﬁxed point and we are slowly changing
from stable to unstable, there is great sensitivity at the transition. Small
changes (such as ignoring small higher order terms in the perturbation) can
have drastic eﬀects on the “jump-up” time as synchrony loses stability. This
is an example of a slow passage through a bifurcation [19]. To see what we
mean here, we simulate the phase-model with the periodic stimulus and
perturb the phase-diﬀerence, φ by slightly increasing it when it is close to 0.
Figure 7 shows the result of such a manipulation. By increasing φ(t = 164)
from, say, 10−14 to 10−4 (this is still an order of magnitude smaller than the
 used in the simulations), we can advance the “jump-up” time by almost an
eighth of the cycle. The inset of the ﬁgure shows that dφ/dt is very small at
this point. For this reason, we can expect that the main error will be on the
up-jump since φ has to escape from the equilibrium point at zero. We will
see similar, although less drastic, eﬀects in the subsequent comparisons. By
reducing the range of the slow parameter so that it is never close to the value
for which synchrony is an attractor, we can do a much better job of tracking
the phase-diﬀerence through the reduced model. Figure 8 shows an example
where the modulated adaptation never gets to a region where synchrony is
stable. In this case, the phase-diﬀerence for the phase-reduced model never
gets close to 0 and the modulation stays away from any bifurcation points.
Figure 9 is similar to ﬁgure 6, except that the modulation is quasi-
periodic. As with the periodic modulation, the phase model follows the
full model quite closely once the system jumps away from the synchronous
equilibrium. However, like the periodic case, the phase model has a delayed
jump-up from synchrony relative to the full model; this is especially evident
at t ≈ 25.

Finally, in Figure 10, we use a slowly varying stochastic signal that is
generated by an Ornstein-Uhlenbeck process and then rescaled so that the

17

Figure 6: Periodic slowly varying parameter. Absolute value of phase dif-
ference |φ| = |θ2 − θ1|∈ [0, 2π) theory (light blue) vs numerics (black dots).
The slow periodic parameter is shown as a dashed red line. The horizontal
line represents the parameter value q at which there is onset or oﬀset of
synchrony. ε = 0.0025, f = 5. 245 cycles.

range is [−1, 1]. As in ﬁgures 6 and 9, the phase model does a fairly good
job of tracking the full model. Similarly, the jump up from synchrony is
often delayed (especially evident for t ∈ [2.5, 4] ) as was the case in all the
previous simulations.

The slowly modulated interaction function works well in spite of the

many approximations that we have made in the biophysical model.

3.4 Networks and synchrony

The methods we have described have, so far, been applied only to two cou-
pled oscillators. There is no reason why we cannot apply them to networks
as well. In this case, it is interesting to consider the idea of global synchro-
nization in the presence of modulation. Here we consider (for simplicity) a
population of N (we take N = 51, here) globally coupled neurons that are
subject to slow modulation of the M−current as in the previous sections.
We weakly couple the Traub model neurons with excitatory coupling and
slow periodic modulation of the adaptation. Coupling is all-all and divided
by the total number of neurons. Thus, each includes the synaptic current,
Isyn = gsynstot(t)(V − Esyn), where

stot(t) =

1
51

(t)sj(t)

(20)

50(cid:88)

j=0

18

Figure 7: Small perturbations of the phase model near the transition.
At t = 164, the value of φ is increased for 10−14 to 10−10, 10−8, 10−4
(red,green,blue), leading to an earlier jump-up time.
Inset shows the log
of dφ/dt.

Figure 8: Periodic slowly varying parameter. Absolute value of phase diﬀer-
ence |φ| = |θ2−θ1|∈ [0, 2π) theory (light blue) vs numerics (black dots). The
slow periodic parameter is shown as a dashed red line. The slowly varying
parameter constants are q0 = 0.175, q1 = 0.125. ε = 0.0025, f = 5. 219
cycles.

19

0.050.10.150.20.250.3166166.5167167.5168168.5169169.51701084-22-20-18-16-14-12-10-8-6-4163164165166167168timetimelog(| d   /dt |)φ03π/102π/10π/10Figure 9: Quasi-periodic slowly varying parameter. The absolute value of
phase diﬀerence |φ| = |θ2 − θ1|∈ [0, 2π) in theory (light blue) vs numerics
(black dots). The quasi-periodic parameter is shown as a dashed red line.
ε = 0.0025, f = 5. 444 cycles.

(1/N )(cid:80)

larger variance means greater synchrony.

and sj(t) are the individual synaptic gating variables for each neuron. Figure
11 shows the result of the simulation. As a surrogate for, say, the local
ﬁeld potential, we look at the total voltage of all the oscillators, Vtot =
j Vj(t). Panel A shows the full picture of Vtot(t) over 12 seconds. It
is diﬃcult to see the synchronization, but can be roughly judged by looking
at the variance of Vtot:
(If the
oscillators were completely asynchronous, their sum would be close to a
constant and so the variance of the sum will be small. If they are completely
synchronized, then the variance of the sum will be large as the voltage
swings over a 150 mV range.) To better illustrate this point, we have also
computed the spectrogram (panel B) over this period of time. Notice the
large red band that starts at the peak of q(t) and tails oﬀ as q(t) tends to
zero. Higher bands represent harmonics of the oscillations. This panel also
illustrates the dramatic eﬀect that adaptation has on the frequency of the
rhythm which ranges between 40 and 100 Hz. Higher frequencies correspond
to lower adaptation and weaker synchrony. We can apply the same phase
reduction methods to this model to get a system of phase equations:

θ(cid:48)
i =

1

N + 1

j=0

N(cid:88)

H(θj − θi, τ ) + σξj

20

Figure 10: Noisy slowly varying parameter. Absolute value of phase dif-
ference |φ| = |θ2 − θ1|∈ [0, 2π) theory (light blue) vs numerics (black dots).
The noisy parameter is shown as a dashed red line. XPP seed 4. ε = 0.0025,
f = 5. 404 cycles.

where we have added some weak noise, σ to push oﬀ the invariant synchrony
manifold. To quantify the synchronization, we look at the order parameter:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) N(cid:88)

j=0

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) .

OP =

1

N + 1

eiθj

Figure 11c shows the clear periodic waxing and waning of OP as the slowly
varying potassium conductance goes from large to small. When q(t) is close
to zero (no adaptation), the OP is also near zero and as q(t) tends to its
maximum value of 0.5, OP gets very close to 1. Thus, we see that slow mod-
ulation of this type of network shows transitions in and out of synchrony. We
expect similar eﬀects for non-periodic modulation as long as it is suﬃciently
slow.

4 Discussion

We have shown that it is possible to still accurately apply weak coupling
theory and phase reduction to oscillators even in a changing environment

21

(a) Summed voltage Vtot = (cid:80)

Figure 11: Network of 51 Traub oscillators all-all coupled as in previous
ﬁgures.
j Vj(t) along with the modulation
of the potassium conductance; (b) Spectrogram showing greatly increased
power when the conductance is high; (c) Order parameter from the phase
reduction showing a similar increase

when the changes are occurring at a suﬃciently slow time scale. In a previous
paper [23], we showed that slow coupling between oscillators was equivalent
to weak coupling and that when the slow parameters were frozen, then

22

−85−80−75−70−65−60−55−50−45−40MembranePotential(a)0.00.10.20.30.40.5q(t)024681012Time(Seconds)20406080100120Frequency(b)−80−70−60−50−40−30−20−100Intensity10152025Time(Seconds)0.00.20.40.60.81.0OrderParameterq(t)(c)the spike-to-spike synchrony in some moderate interval of time could be
predicted by the corresponding interaction function. Here, we formalize this
notion and demonstrate that the interaction functions are time-dependent
(with respect to the slowly varying parameter) and thus, we do not need to
freeze any parameters. In the present theory, the slow forcing was exogenous
and imposed on the system.
In contrast, in bursting systems, the slow
modulation is internally generated as the slow variable goes through various
bifurcations between quiescence and oscillations. In [25], Sherman studied
two weakly coupled bursters and observed that during the spiking phase
(when the fast system is periodic), spikes did not synchronize but were
driven to asymmetric and out-of-phase oscillations. The methods we have
developed here require the existence of a limit cycle, so they cannot be
applied globally to the spike synchronization during autonomous bursting.
However, if we make the reasonable assumption that during the quiescent
stage of the burst, the two cells are drawn to the slowly changing equilibrium,
then, when they jump up, they will be nearly synchronous (but, not quite;
if they were precisely synchronous, then they would stay that way for all
time). We can then use the theory developed here to study the dynamics of
the spike-to-spike synchrony during the active period of the burst and thus
explain in a more formal matter Sherman’s results.

Gutkin et al [12] looked at how spiking neural oscillators subjected to a
slowly varying input responded to brief perturbations given between spikes.
They measured the inter-spike interval (ISI) without the perturbation and
then ﬁxed the input so the oscillator had the same period as the ISI. With
this ﬁxed oscillator, they computed the phase response curve (the function
Z(t) solving the adjoint problem) and used this to predict how the perturba-
tion would aﬀect the spike time in the slowly varying system. The method
developed here, could be used to improve this estimate since we know both
the slowly varying frequency and the slowly varying function Z(t; τ ). This
type of correction was, in fact, the goal of [17].

Slowly varying inputs diﬀer in ways both quantitative and, more im-
portantly, qualitative from faster inputs. For example, suppose that two
oscillators receive identical periodic inputs that have a frequency close to
the unforced frequency of the oscillators. Then for some range of input am-
plitudes, we can expect the oscillators to lock in a 1:1 manner with each other
and thus be completely synchronized even in absence of coupling. Similarly,
weak identical noise applied to two uncoupled oscillators will also synchro-
nize them [7, 22, 28], but the noise has to be suﬃciently fast; synchrony falls
oﬀ rapidly as the time constant of the noise slows down [10]. Thus, fast
common rapidly changing inputs will tend to synchronize uncoupled oscil-
lators. But the slow modulations we study here have no such properties.
Indeed, looking at equations (7-8), the common slow input cannot move the
phase-diﬀerence without direct coupling.
It would be interesting to look
at the synchronization between two slowly varying oscillators that are sub-

23

jected to fast correlated noise and derive some equations for the expected
phase-diﬀerence.

5 Conclusion

The Fredholm alternative provides a useful proof method to re-derive the
phase equation in Kurebayashi et al. After obtaining the phase equation, we
use the theory of weakly coupled oscillators to derive the interaction func-
tion, from which we can study the stability of synchrony and anti-synchrony.
Despite the phase estimation and the mode truncation, our theory accu-
rately predicts the phase of the Traub model with periodic, quasi-periodic,
and stochastic slowly varying parameters (we have similar positive results
for the λ−ω system). Because the mode truncation depends on the accuracy
of the numerically derived interaction functions, and because the interaction
functions in turn depend only on the coupling terms and the iPRC, we can
apply the mode truncation method (and subsequently our result) to any
autonomous system for which the iPRC and coupling terms are known. The
methods here show that we can extend the notion of weak coupling and
synchronization of nonlinear neural oscillators to the more realistic scenario
in which the environment is changing.

Acknowledgments BE and YMP were partially supported by NSF DMS
1219753

6 Traub Model With Adaptation

All other equations for the Traub model are deﬁned as follows

tw(V ) = τw/(3.3 exp((V − Vwt)/20) + exp(−(V − Vwt)/20))
w∞(V ) = 1/(1 + exp(−(V − Vwt)/10))
am(V ) = 0.32(54 + V )/(1 − exp(−(V + 54)/4))
bm(V ) = 0.28(V + 27)/(exp((V + 27)/5) − 1)
ah(V ) = 0.128 exp(−(V − Vhn)/18)
bh(V ) = 4/(1 + exp(−(V + 27)/5))
an(V ) = 0.032(V + 52)/(1 − exp(−(V + 52)/5))
bn(V ) = 0.5 exp(−(57 + V )/40)
α(V ) = a0/(1 + exp(−(V − Vt)/Vs))

6.1 Fourier Coeﬃcients

The Fourier coeﬃcients used in the approximation are shown in Table 2

24

Table 1: Traub parameter values

2π Hz)

Parameter Value
C
g
ε
f
I
Vwt
τw
Ek
EN a
El
gl
gk
gN a
Vhn
a0
τ
Vt
Vs
Esyn
q0
q1

1µF/cm2
5mS/cm2
0.0025
0.5( 1000ε
3µA/cm2
−35mV
100ms
−100mV
50mV
−67mV
0.2mS/cm2
80mS/cm2
100mS/cm2
−50mV
4
4ms
0mV
5mV
0mV
0.3mS/cm2
0.2mS/cm2

25

Table 2: Traub Fourier Coeﬃcients

Cosine
a0(0.1) = 19.6011939665
a0(0.3) = 17.4255017198
a1(0.1) = −3.32476526025
a1(0.3) = −6.97305767558
a2(0.1) = −0.255371105623
a2(0.3) − 0.83690237427

Sine
-
-
b1(0.1) = 0.721387113706
b1(0.3) = −1.5028098729
b2(0.1) = 0.738312597998
b2(0.3) = 1.03494013487

References

[1] Eric Brown, Jeﬀ Moehlis, and Philip Holmes. On the phase reduction
and response dynamics of neural oscillator populations. Neural Com-
putation, 16(4):673–715, 2004.

[2] John R Cressman Jr, Ghanim Ullah, Jokubas Ziburkus, Steven J Schiﬀ,
and Ernest Barreto. The inﬂuence of sodium and potassium dynamics
on excitability, seizures, and the stability of persistent states: I. single
neuron dynamics. Journal of Computational Neuroscience, 26(2):159–
170, 2009.

[3] Per Danzl, Robert Hansen, Guillaume Bonnet, and Jeﬀ Moehlis. Partial
phase synchronization of neural populations due to random Poisson
inputs. Journal of Computational Neuroscience, 25(1):141–157, 2008.

[4] Bard Ermentrout. Simulating, analyzing, and animating dynamical sys-
tems: a guide to XPPAUT for researchers and students, volume 14.
SIAM, 2002.

[5] Bard Ermentrout, Matthew Pascal, and Boris Gutkin. The eﬀects of
spike frequency adaptation and negative feedback on the synchroniza-
tion of neural oscillators. Neural Computation, 13(6):1285–1310, 2001.

[6] G Bard Ermentrout, Bryce Beverlin II, and Theoden Netoﬀ. Phase
response curves to measure ion channel eﬀects on neurons. In Phase
response curves in neuroscience, pages 207–236. Springer, 2012.

[7] G Bard Ermentrout, Roberto F Gal´an, and Nathaniel N Urban. Reli-
ability, synchrony and noise. Trends in neurosciences, 31(8):428–434,
2008.

[8] G.Bard Ermentrout. n:m phase-locking of weakly coupled oscillators.

Journal of Mathematical Biology, 12(3):327–342, 1981.

26

[9] George Bard Ermentrout and Nancy Kopell. Frequency plateaus in a
chain of weakly coupled oscillators, I. SIAM Journal on Mathematical
Analysis, 15(2):215–237, 1984.

[10] Roberto F Gal´an, G Bard Ermentrout, and Nathaniel N Urban. Op-
timal time scale for spike-time reliability: theory, simulations, and ex-
periments. Journal of Neurophysiology, 99(1):277–283, 2008.

[11] Natalia Gorelova, Jeremy K Seamans, and Charles R Yang. Mechanisms
of dopamine activation of fast-spiking interneurons that exert inhibition
in rat prefrontal cortex. Journal of Neurophysiology, 88(6):3150–3166,
2002.

[12] Boris S Gutkin, G Bard Ermentrout, and Alex D Reyes. Phase-response
curves give the responses of neurons to transient inputs. Journal of
Neurophysiology, 94(2):1623–1635, 2005.

[13] Ho Young Jeong and Boris Gutkin. Synchrony of neuronal oscilla-
tions controlled by GABAergic reversal potentials. Neural Computa-
tion, 19(3):706–729, 2007.

[14] James P Keener. Principles of applied mathematics. Addison-Wesley,

1988.

[15] N. Kopell and L.N. Howard. Plane wave solutions to reaction diﬀusion

equations. 52:291–328, 1973.

[16] Y. Kuramoto. Chemical oscillations, waves, and turbulence. Springer–

Verlag, New York, 1984.

[17] Wataru Kurebayashi, Sho Shirasaka, and Hiroya Nakao. Phase reduc-
tion method for strongly perturbed limit cycle oscillators. Physical
Review Letters, 111:214101, Nov 2013.

[18] Wataru Kurebayashi, Sho Shirasaka, and Hiroya Nakao. A criterion for
timescale decomposition of external inputs for generalized phase reduc-
tion of limit-cycle oscillators. Nonlinear Theory and Its Applications,
IEICE, 6(2):171–180, 2015.

[19] GJM Mar´ee. Slow passage through a pitchfork bifurcation. SIAM

Journal on Applied Mathematics, 56(3):889–918, 1996.

[20] David A McCormick. Cellular mechanisms underlying cholinergic and
noradrenergic modulation of neuronal ﬁring mode in the cat and guinea
pig dorsal lateral geniculate nucleus. The Journal of Neuroscience,
12(1):278–289, 1992.

27

[21] Benjamin Pfeuty, Germ´an Mato, David Golomb, and David Hansel.
Electrical synapses and synchrony: the role of intrinsic currents. The
Journal of Neuroscience, 23(15):6280–6294, 2003.

[22] Arkady Pikovsky, Michael Rosenblum, and J¨urgen Kurths. Synchro-
nization: a universal concept in nonlinear sciences, volume 12. Cam-
bridge University Press, 2003.

[23] Jonathan J. Rubin, Jonathan E. Rubin, and G. Bard Ermentrout.
Analysis of synchronization in a slowly changing environment: How
slow coupling becomes fast weak coupling. Physical Review Letters,
110:204101, May 2013.

[24] Michael A Schwemmer and Timothy J Lewis. The theory of weakly
coupled oscillators. In Phase Response Curves in Neuroscience, pages
3–31. Springer, 2012.

[25] Arthur Sherman. Anti-phase, asymmetric and aperiodic oscillations in
excitable cells—I. coupled bursters. Bulletin of Mathematical Biology,
56(5):811–835, 1994.

[26] Klaus M Stiefel, Boris S Gutkin, and Terrence J Sejnowski. Choliner-
gic neuromodulation changes phase response curve shape and type in
cortical pyramidal neurons. PloS One, 3(12):e3947–e3947, 2008.

[27] Klaus M Stiefel, Boris S Gutkin, and Terrence J Sejnowski. The ef-
fects of cholinergic neuromodulation on neuronal phase-response curves
of modeled cortical neurons. Journal of Computational Neuroscience,
26(2):289–301, 2009.

[28] Jun-nosuke Teramae and Dan Tanaka. Robustness of the noise-induced
phase synchronization in a general class of limit cycle oscillators. Phys-
ical Review Letters, 93(20):204103, 2004.

[29] Xiao-Jing Wang and Gy¨orgy Buzs´aki. Gamma oscillation by synaptic
inhibition in a hippocampal interneuronal network model. The Journal
of Neuroscience, 16(20):6402–6413, 1996.

28

