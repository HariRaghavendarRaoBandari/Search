Enabling Correct Interest Forwarding and Retransmissions

in a Content Centric Network

J. J. Garcia-Luna-Aceves1,2 and Maziar Mirzazad-Barijough1

1Computer Engineering Department, University of California, Santa Cruz, CA 95064

2PARC, Palo Alto, CA 94304
{jj,maziar}@soe.ucsc.edu

6
1
0
2

 
r
a

 

M
8
1

 
 
]
I

N
.
s
c
[
 
 

1
v
2
1
0
6
0

.

3
0
6
1
:
v
i
X
r
a

ABSTRACT
We show that the mechanisms used in the name data net-
working (NDN) and the original content centric networking
(CCN) architectures may not detect Interest loops, even if
the network in which they operate is static and no faults oc-
cur. Furthermore, we show that no correct Interest forward-
ing strategy can be deﬁned that allows Interest aggregation
and attempts to detect Interest looping by identifying In-
terests uniquely. We introduce SIFAH (Strategy for Interest
Forwarding and Aggregation with Hop-Counts), the ﬁrst In-
terest forwarding strategy shown to be correct under any op-
erational conditions of a content centric network. SIFAH op-
erates by having forwarding information bases (FIBs) store
the next hops and number of hops to named content, and
by having each Interest state the name of the requested con-
tent and the hop count from the router forwarding an In-
terest to the content. We present the results of simulation
experiments using the ndnSIM simulator comparing CCN
and NDN with SIFAH. The results of these experiments il-
lustrate the negative impact of undetected Interest looping
when Interests are aggregated in CCN and NDN, and the
performance advantages of using SIFAH.
Categories and Subject Descriptors
C.2.6 [Internetworking]: Routers
General Terms
Theory, Design, Performance
Keywords
Information-centric networks, Interest forwarding strategies

1.

INTRODUCTION

A number of information-centric networking (ICN) archi-
tectures have been proposed to improve the performance and
the end-user experience of the Internet [2, 20]. ICN archi-
tectures focus on (1) enabling access to content and services
by name, rather than by original location; (2) protecting
content rather than links or connections; and (3) exploiting
in-network storage of content.

A leading approach in ICN architectures can be charac-
terized as Interest-based content-centric networking and is
the focus of this paper. Directed Diﬀusion [12] is one of the
ﬁrst examples of this approach. Requests for named content
(called Interests) are diﬀused throughout a sensor network,
and data matching the Interests are sent back to the issuers
of Interests. Subsequent proposals (e.g., DIRECT [18]) use

a similar approach in MANETs subject to connectivity dis-
ruption. Nodes use opportunistic caching of content and
ﬂood Interests persistently. The limitation of Directed Dif-
fusion and other similar approaches is the need to ﬂood the
network with Interests, an approach that cannot be applied
at Internet scale.

The original CCN proposal [13] was the ﬁrst example of
an Interest-based content-centric architecture applicable to
wired networks in which Interests do not state the iden-
tity of the sender. Today, NDN [16] and CCN [4] are the
leading proposals for content-centric networking based on
Interest forwarding. In general, an Interest-based forward-
ing strategy consists of: populating forwarding information
bases (FIB) of routers with routes to name preﬁxes denot-
ing content, sending content requests (called Interests) for
speciﬁc named data objects (NDO) over paths implied by
the FIBs, and delivering content along the reverse paths tra-
versed by Interests.

Section 2 summarizes the operation of the forwarding strate-

gies of NDN and CCN. The designers of NDN and CCN
have argued [13, 16, 21, 22] that an Interest stating a name
of requested content and a nonce or unique identiﬁer can be
forwarded correctly towards an intended node advertising
the content name, that routers can aggregate Interests so
that a router can forward an Interest for the same content
only once, and that Interest loops can be detected when-
ever they occur. However, no prior work has been reported
proving these claims.

Section 3 demonstrates that the forwarding strategies of
the original CCN and NDN architectures [13, 21, 25] do not
work correctly, in that some Interests may never return data
objects to the consumers who issued the Interests, even if the
content does exist in the network, the network topology and
routing are stable, and all transmissions are successful. More
importantly, it is also shown that there is no correct forward-
ing strategy with Interest aggregation and Interest-loop de-
tection based on the matching of Interest-identiﬁcation data
carried in Interests. In this context, Interest-identiﬁcation
data can be names of requested content, nonces, unique
identiﬁers, or the path traversed by an Interest.

Section 4 introduces the Strategy for Interest Forward-
ing and Aggregation with Hop-counts (SIFAH), which is the
ﬁrst Interest-based forwarding strategy shown to be correct.
SIFAH operates by having FIBs store the next hops and
number of hops to named content, and by forwarding each
Interest based on the name of the requested content and a
hop count from the forwarding router to the requested con-
tent. A router accepts to forward an Interest only if the hop

count stated in the Interest is larger than the hop count from
the router to the content as stated in its FIB. Similarly, a
router that has forwarded an Interest for a given NDO ac-
cepts to aggregate an Interest it receives while waiting for
the requested NDO only if the hop count stated in the In-
terest is larger than the hop count of the Interest sent by
the router.

Section 5 proves that SIFAH works correctly when Interest

loops occur and Interests are aggregated.

Section 6 analyzes the storage requirements of SIFAH and
NDN and shows that SIFAH is a more desirable approach
than using nonces to attempt to detect Interest loops. Fur-
thermore, it presents simulation results based on the un-
modiﬁed implementation of the NDN forwarding strategy
and our implementation of SIFAH in ndnSIM. The simula-
tion results help to illustrate that consumers submitting In-
terests must receive NDO messages or negative acknowledg-
ments (NACK) when SIFAH is used, while some Interests
may go unanswered in NDN and the original CCN design
due to undetected Interest loops, even in stable topologies
with correct entries in FIBs. Furthermore, the results indi-
cate that Interest loops increase the number of PIT entries
and end-to-end delays experienced by consumers even when
Interest loops are rare.

2. EXISTING INTEREST FORWARDING

STRATEGIES

In NDN and CCN, a given router r uses three primary
data structures to implement any of the forwarding strate-
gies deﬁned for Interest-based content-centric architectures:
a forwarding information base (F IBr), a pending Interest
table (P IT r), and a content store (CSr).

The forwarding strategy determines the interaction among
F IBr, P IT r, and CSr needed to forward Interests towards
nodes advertising having copies of requested content, send
NDOs back to consumers who requested them over reverse
paths traversed by Interests, and send any other signal in-
dicating the inability to satisfy an Interest.

F IBr is used to route incoming Interests to the appropri-
ate next hops towards the desired content producer adver-
tising a content preﬁx name n(j)∗.

F IBr is populated using content routing protocols or static
routes and matches Interest names stating a speciﬁc NDO
n(j) to F IBr entries of preﬁx names using longest preﬁx
match.

P IT r serves as a cache of Interest state, such that content
objects that satisfy Interests may follow the reverse Inter-
est path back to the original requester. CSr is a cache for
content objects.

In the rest of this paper, we use the term name data object
(NDO) or content object interchangeably, and use the term
neighbor instead of interface or face. We denote the name of
NDO j by n(j), and the name preﬁx that includes that NDO
name by n(j)∗. We denote the existence of an entry for a
preﬁx n(j)∗ or NDO with name n(j) in the FIB, PIT or CS
of router i by n(j)∗ ∈ F IBi, n(j) ∈ P IT i, and n(j) ∈ CSi,
respectively.

Two Interest-based forwarding strategies proposed to date
are the original CCN strategy [13] and the NDN forwarding
strategy [21, 25]. In both strategies, an Interest created by
source s for NDO j states n(j) and a nonce idj(s). The pair
(n(j), idj(s)) is used to denote an Interest uniquely with

a large-enough probability. Furthermore, the same pair is
used to detect whether an Interest is traversing a loop.

In the context of NDN and the original CCN, we use
I[n(j), idj(s)] to denote an Interest that requests NDO with
name n(j) and that is originated by consumer s, who assigns
nonce idj(s) to the Interest. A content-object message (or
NDO message) sent in response to an Interest I[n(j), idj(s)],
denoted D[n(j), idj(s), sig(j)], states the name and nonce of
the Interest, a signature payload sig(j) used to validate the
content object, and the object itself.

Algorithm 1 NDN Processing of Interest at router i
1: function Process Interest
2: INPUT: P IT i, CSi, F IBi;
3: INPUT: I[n(j), idj (s)] received from k;
4: if n(j) ∈ CSi then
5:
6: else
7:
8:

send D[n(j), idj (s), sig(j)] to k
if n(j) (cid:54)∈ P IT i then

create P I i
call Forwarding Strategy(P I i

n(j)[idj (s), in : k, out : ∅];
n(j))

9:
10:
11:
12:

13:
14:

else

% There is a PIT entry for n(j)
if ∃ P I i

n(j)[idj (x)] with idj (x) = idj (s) then

% A duplicate Interest is detected
[NDN] send N I[n(j), idj (s), duplicate] to k;
drop I[n(j), idj (s)]

else

% Interest can be aggregated
create P I i
if RTi(I[n(j), idj (s)]) is exprired then

n(j)[idj (s), in : k, out : ∅];

call Forwarding Strategy(P I i

n(j));

15:
16:
17:
18:
19:
20: end if

end if

end if

end if

Algorithm 2 NDN forwarding of Interest at router i
1: function Forwarding Strategy
2: INPUT: P IT i, CSi, F IBi;
3: INPUT: P I i
4: if n(j)∗ ∈ F IBi then
5:
6:

if m (cid:54)= in : k for all in : k ∈ P I i

n(j)[idj (s), in : k, out : OU T SET ]

for each neighbor m in F IBi

n(j)∗ by rank do

n(j)∧
m (cid:54)∈ SET for all out : SET ∈ P I i
if m is available then

n(j) then

n(j)) = OU T SET (P I i

OU T SET (P I i
start RTi(I[n(j), idj (s)]);
forward I[n(j), idj (s)] to neighbor m;
return

n(j)) ∪ m;

end if

end if
end for
[NDN] send N I[n(j), idj (s), congestion] to k;
drop I[n(j), idj (s)]; delete P I i

n(j)

7:
8:

9:
10:
11:
12:

13: else
14:

15: end if

send N I[n(j), idj (s), no data] to k;
drop I[n(j), idj (s)]; delete P I i

n(j)

The entry in F IBi for name preﬁx n(j)∗ is denoted by
n(j)∗ and consists of n(j)∗ and the list of neighbors
F IBi
that can be used to reach the NDO. If neighbor k is listed
in F IBi
In NDN [22],
the FIB entry for an NDO also contains a stale time af-
ter which the entry could be deleted; the round-trip time
through the neighbor; a rate limit; and status information

n(j)∗ , then we state k ∈ F IBi

n(j)∗ .

stating whether it is known or unknown that the neighbor
can bring data back, or is known that the neighbor cannot
bring data back.

The entry in P IT i for NDO with name n(j) is denoted
by P I i
n(j) and consists of a vector of one or multiple tuples,
one for each nonce processed for the same NDO name. The
tuple for a given NDO states the nonce used, the incom-
ing and the outgoing neighbor(s). The tuple created as a
result of processing Interest I[n(j), idj(s)] received from k
and forwarded to a set of neighbors OU T SET is denoted by
P I i
n(j)[idj(s), in : k, out : OU T SET ], and the set of outgo-
ing neighbors in P I i

n(j) is denoted by OU T SET (P I i

n(j)).

Each PIT entry P I i

n(j)[idj(s), in : k, out : OU T SET ] has
a lifetime, which should be larger than the estimated round-
trip time to a site where the requested NDO can be found.
We denote by N I[n(j), idj(s), CODE] the NACK sent in
response to I[n(j), idj(s)], where CODE states the reason
why the NACK is sent.

Algorithms 1 and 2 illustrate the NDN Interest processing
approach [21, 22] using the notation we have introduced, and
correspond to Interest-processing and forwarding-strategy
algorithms in [22]. Algorithm 2 does not include the prob-
ing of neighbors proposed in NDN, given that this aspect
of NDN is still being deﬁned [22]. Routers forward NACKs
received from those neighbors to whom they sent Interests,
unless the PIT entries have expired or do not match the
information provided in the NACKs. The NDN forwarding
strategy augments the original CCN strategy by introduc-
ing negative acknowledgements (NACK) sent in response to
Interests for a number of reasons, including: routers iden-
tifying congestion, routers not having routes in their FIBs
to the requested content, or Interest loops being detected.
Algorithms 1 and 2 indicate the use of NACKs that is not
part of the original CCN design by “[NDN].”

3. UNDETECTED INTEREST LOOPS

IN CCN AN NDN

The use of nonces in NDN and the original CCN ap-
proach can be extrapolated to include the case in which an
Interest states a nonce and the path traversed by the Inter-
est by assuming that idj(s) equals the tuple (idj(s)[nonce],
If a nonce and path traversed by the In-
idj(s)[path]).
terest are used, deciding whether an Interest has not tra-
(cid:54)=
versed a loop can be based on whether idj(x)[nonce]
idj(s)[nonce] ∨ i (cid:54)∈ idj(s)[path]. However, including path
information in Interests reveals the identity of originators of
Interests.

The key aspect of the forwarding strategies that have been
proposed for NDN and CCN is that a router determines
whether or not an Interest is a duplicate Interest based solely
on the content name and Interest-identiﬁcation data for the
Interest (a nonce in NDN’s case). To discuss the correctness
of the forwarding strategy and other strategies, we deﬁne an
Interest loop as follows.

Interest Loop: An Interest loop of h hops for NDO with
name n(j) occurs when one or more Interests asking for n(j)
are forwarded and aggregated by routers along a cycle L =
{v1, v2, ..., vh, v1} such that router vk receives an Interest
for NDO n(j) from vk−1 while waiting for a response to the
Interest it has forwarded to vk+1 for the same NDO, with
1 ≤ k ≤ h, vh+1 = v1, and v0 = vh. (cid:3)

According to the NDN forwarding strategy, a router can
select a neighbor to forward an Interest if it is known that it
can bring content and its performance is ranked higher than
other neighbors that can also bring content. The ranking of
neighbors is done by a router independently of other routers,
which can result in long-term routing loops implied by the
FIBs if the routing protocol used in the control plane does
not guarantee instantaneous loop freedom (e.g., NLSR [14]).

Figure 1: Undetected Interest loops in NDN and
CCN

Figure 1 illustrates Interest looping in NDN. Arrowheads
in the ﬁgure indicate the next hops to content advertised by
router j according to the FIB entries stored in routers. Thick
lines indicate that the perceived performance of a neighbor
is better than neighbors shown with thinner lines. Dashed
lines indicate the traversal of Interests over links and paths.
The time when an event is processed at a router is indicated
by ti. Figure 1(a) shows the case of a long-term Interest
loop formed because the multi-paths implied in FIBs are
not loop-free, even though all routing tables are consistent.
Figure 1(b) shows the case of a temporary Interest loop when
single-path routing is used and FIBs are inconsistent due
to a topology change at time t1 (link (b, q) fails). In both
cases, router a aggregates the Interest from x at time t3,
router x aggregates the Interest from c at time t4, and the
combined steps preclude the detection of Interest looping.
This results in x and y having to wait for their Interests to
time out, before they can retransmit. Furthermore, there is
no guarantee that their retransmissions will elicit a response
(content or NACK).

As Theorem 1 proves, the CCN and NDN forwarding
strategies speciﬁed in [13, 22, 25] cannot ensure that Inter-
est loops are detected when Interests are aggregated, even
if nonces were to denote Interests uniquely. The theorem
assumes that all messages are sent correctly and that no
routing-table changes occur to show that the NDN forward-
ing strategy can fail to return any content or NACK in
response to Interests independently of network dynamics.
Furthermore, Theorem 2 shows that no forwarding strat-
egy can be correct if it allows Interest aggregation and at-
tempts Interest-loop detection by the matching of Interest-
identiﬁcation data.

Theorem 1. Interest loops can go undetected in a stable,
error-free network in which NDN or CCN is used, even if
nonces were to denote Interests uniquely.

Proof. Consider the NDN or CCN forwarding strategy
running in a network in which no two nonces created by
diﬀerent nodes for the same content are equal, all transmis-
sions are received correctly, and no topology or routing-table
changes occur after time t0. Let LT vk (I[n(j), idj(s)]) denote
the lifetime of I[n(j), idj(s)] at router vk.

Assume that Interests may traverse loops when they are
forwarded according to the forwarding strategy, and let a

loop L = {v1, v2, ..., vh, v1} exist for NDO j, and let Interest
I[n(j), idj(x)] start traversing the chain of nodes {v1, v2, ...,
vk} ∈ L (with 1 < k < h) at time t1 > t0.

Assume that I[n(j), idj(x)] reaches router vk at time t3 >
t1 and that router vk forwards Interest I[n(j), idj(y)] to its
next hop vk+1 ∈ L at time t2, where t1 ≤ t2 < t3, idj(x) (cid:54)=
idj(y), and vk+1 may be v1.

According to the Interest processing strategy in NDN and
CCN, router vk creates an entry in its PIT for I[n(j), idj(y)]
at time t2, and perceives any Interest for name n(j) and a
nonce diﬀerent than idj(y) received after time t2, and before
its PIT entry for I[n(j), idj(y)] is erased, as a subsequent
Interest.
Let |t2 − t3| < LT vk (I[n(j), idj(y)]) when router vk re-
ceives I[n(j), idj(x)] from router vk−1 ∈ L at time t3, where
1 < k − 1. According to the Interest processing strategy
in NDN and CCN, router vk must treat I[n(j), idj(x)] as
a subsequent Interest for content n(j) that is aggregated,
because vk is waiting for D[n(j), idj(y)] at time t3.

Because of the existence of L, Interest I[n(j), idj(y)] must
be forwarded from vk to v1. Let t4 denote the time when
I[n(j), idj(y)] reaches v1, where t4 > t2 ≥ t1, and assume
that |t1 − t4| < LT v1 (I[n(j), idj(x)]). According to NDN’s
Interest processing strategy, v1 must treat I[n(j), idj(y)] as a
subsequent Interest, because it is waiting for D[n(j), idj(x)]
at time t4.
Given the Interest aggregation carried out by nodes vk
and v1, nodes in the chain {v1, v2, ..., vk−1} ∈ L process only
I[n(j), idj(x)], nodes in the chain {vk+1, vk+2, ..., vh} ∈ L
process only I[n(j), idj(y)], and no Interest loop detection
can take place. Therefore, no content can be submitted in
response to I[n(j), idj(x)] and I[n(j), idj(y)].

Similar results to Theorem 1 can be proven for NDN and
the original CCN operating in a network in which routing
tables are inconsistent as a result of network or content dy-
namics. In this case, Interest loops can go undetected even
if the control plane supports only single-path forwarding of
Interests.

Theorem 2. No correct forwarding strategy exists with
Interest aggregation and Interest loop detection based on the
matching of Interest-identiﬁcation data.

Proof. Assume any forwarding strategy in which a router
remembers an Interest it has forwarded as long as necessary
to detect Interest loops, and detects the occurrence of an In-
terest loop by matching the Interest-identiﬁcation data car-
ried in an Interest it receives with the Interest-identiﬁcation
data used in the Interest it forwarded previously asking for
the same content. Let I[n(j), idj(s)] denote the Interest ask-
ing for n(j) with Interest-identiﬁcation data idj(s) created
by router s.
Assume that an Interest loop L = {v1, v2, ..., vh, v1} for
NDO with name n(j) exists in a network using the forward-
ing strategy. Let Interest I[n(j), idj(x)] start traversing the
chain of nodes {v1, v2, ..., vk} ∈ L (with 1 < k < h) at time
t1.

Assume that I[n(j), idj(x)] reaches router vk at time t3 >
t1 and that router vk forwards Interest I[n(j), idj(y)] to its
next hop vk+1 ∈ L at time t2, where t1 ≤ t2 < t3, idj(x) (cid:54)=
idj(y). Let I[n(j), idj(y)] traverse the chain of nodes {vk,
vk+1, ..., v1} ∈ L, reaching v1 at time t4, where t4 > t2 ≥ t1.
By assumption, Interest aggregation occurs, and hence
vk aggregates I[n(j), idj(x)] at time t3, and v1 aggregates

I[n(j), idj(y)] at time t4. Therefore, independently of the
amount of information contained in idj(x) and idj(y), v1
cannot receive I[n(j), idj(x)] from vh and vk cannot receive
I[n(j), idj(y)] from vk−1. It thus follows that no node in L
can successfully use the matching of Interest-identiﬁcation
data to detect that Interests for n(j) are being sent and
aggregated along L and the theorem is true.

The results in Theorems 1 and 2 can also be proven by
mapping the Interest processing strategy of NDN, and any
forwarding strategy that attempts to detect Interest loops by
matching Interest-identiﬁcation data, to the problem of dis-
tributed termination detection over a cycle, where Interests
serve as the tokens of the algorithm [7, 15]. Because Inter-
est aggregation erases a token traversing the ring (Interest
loop) when any node in the ring has previously created a
diﬀerent token, correct termination detection over the ring
(i.e., Interest loop detection) cannot be guaranteed in the
presence of Interest aggregation.

Obviously, a loop traversed by an Interest can be detected
easily if each Interest is identiﬁed with the route it should
traverse. This is easy to implement but requires routers in
the network to have complete topology information (e.g.,
[14, 17, 19]) or at least path information or partial topol-
ogy information (e.g., [3, 17]). Similarly, carrying the path
traversed by an Interest in its header also ensures that an
Interest loop is detected if it occurs.
In these two cases,
however, there is no need for using nonces to detect Inter-
est loops. More importantly, path information reveals the
identity of the source router requesting content and hence
defeats one of the key objectives of the NDN and CCN for-
warding strategies.

Another view of the problem would be to say that Interest
aggregation is not common and hence undetected Interest
loops should be too rare to cause major performance prob-
lems. However, if Interests need not be aggregated, then
very diﬀerent architectures could be designed for content-
centric networking that do not require using PITs.

4. SIFAH
4.1 Design Rationale

It is clear from the results in the previous section that
using nonces or identifying Interests uniquely is useless for
Interest-loop detection when Interests are aggregated, and
that source routing of Interests or including the path tra-
versed by an Interest are not desirable. Accordingly, for an
Interest forwarding strategy to be correct in the presence of
Interest aggregation, it must be the case that, independently
of the identity of an Interest or how Interests for the same
content are aggregated, at least one router detects that it is
traversing a path that is not getting the Interest closer to a
node that has advertised the requested content.

Ensuring that at least one router in an Interest loop de-
tects the incorrect forwarding of the Interest can be attained
if Interests were to carry any type of ordering information
that cannot be erased by the use of Interest aggregation.
Fortunately, distance information for advertised name pre-
ﬁxes is exactly this type of ordering information.

Given that forwarding information bases (FIB) are pop-
ulated from the routing tables maintained in the control
plane of a network, they constitute a readily-available tool
to establish the proper interaction between the forwarding

strategy operating in the data plane and the distances to
advertised content preﬁxes maintained by the routing pro-
tocol operating in the control plane. This is the basis of
the Strategy for Interest Forwarding and Aggregation with
Hop-Counts (SIFAH).
4.2

Information Stored and Exchanged

A router maintains a FIB, a PIT, and an optional content
store. F IBi is indexed using content name preﬁxes. The
FIB entry for preﬁx n(j)∗ is denoted by F IBi
n(j)∗ , and con-
sists of a list of one or more tuples. Each tuple states a next
hop to n(j)∗ and a hop count to the preﬁx. The set of next
hops to n(j)∗ listed in F IBi
n(j)∗ . The
hop count to n(j)∗ through neighbor q ∈ Si
n(j)∗ is denoted
by h(i, n(j)∗, q).

n(j)∗ is denoted by Si

An Interest sent by node k requesting NDO n(j) is de-
noted by I[n(j), hI (k)], and states the name n(j), and the
hop count (hI (k)) from node k to the name preﬁx n(j)∗ that
is the best match for NDO name n(j) when k forwards the
Interest.

An NDO message sent in response to the Interest I[n(j),
hI (k)] is denoted by D[n(j), sig(j)], and states the name of
the Interest, a signature payload sig(j) used to validate the
content object, and the object itself.

The NACK sent by router i in response to an Interest is
denoted by N I[n(j), CODE] where CODE states the reason
why the NACK is sent. Possible reasons for sending a NACK
include: (a) an Interest loop is detected, (b) a route failed
towards the requested content, (c) no content is found, and
(d) the PIT entry expired.

P IT i is indexed using NDO names. P I i

n(j) denotes the
entry created in P IT i for NDO with name n(j), and spec-
iﬁes: the name of the NDO; the hop count hI (i) assumed
by router i when it forwards Interest I[n(j), hI (i)]; the set
of incoming neighbors from which Interests for n(j) are re-
ceived (IN SET (P I i
n(j))); the set of outgoing neighbor(s)
(OU T SET (P I i
n(j))) to whom router i forwards its Interest;
and the remaining lifetime for the Interest (RT (P I i

n(j))).

4.3

Interest Loop Detection

To deﬁne a correct forwarding strategy, special attention
must be paid to the fact that updates made to the FIBs
stored at routers occur independently of and concurrently
with the updates made to their PITs. For example, once
a router has forwarded an Interest that assumed a given
distance to content preﬁx n(i)∗ and waits for its Interest
to return a data object, its distance to the same content
may change based on updated to its FIB. Hence, simply
comparing the minimum distance from a router to content
against a distance to content stated in an Interest is not
enough to ensure that Interests are not incorrectly forwarded
to routers that are farther away form the requested content.
SIFAH takes into account the fact that FIBs and PITs
are updated independently by requiring that a router that
forwards an Interest for a given piece of content remembers
in its PIT entry the value of the distance to content assumed
when it issues its Interest. The following rule is then used
for a given router to determine whether an Interest may be
propagating over an Interest loop.

The number of hops to requested content is used as the
metric for the invariant condition. This is done for two rea-
sons, storing hop-count distances in the FIB incurs less stor-

age overhead than storing complex distance values, and the
next hops to a preﬁx stored in the FIB can be ranked based
on the actual distances to content.

HFAR–Hop-Count Forwarding with Aggregation
Rule: Router i can accept I[n(j), hI (k)] from router k if
one of the following two conditions is satisﬁed:

n(j)∗ ∧ hI (k) > h(i, n(j)∗, v) )

1. n(j) (cid:54)∈ P IT i ∧∃ v( v ∈ Si
2. n(j) ∈ P IT i ∧ hI (k) > hI (i)
The ﬁrst condition ensures that router i accepts an In-
terest from neighbor k only if i determines that is closer
to n(j)∗ through at least one neighbor than k was when it
sent its Interest. The second condition ensures that router
i accepts an Interest from neighbor k only if i was closer to
n(j)∗ than k when i and k sent their Interests.

Section 5 proves that using HFAR is suﬃcient to ensure
that an Interest loop cannot occur without a router in the
loop detecting that the Interest has been forwarded incor-
rectly. This result is independent of whether Interests are
aggregated or sent over one or multiple paths, or how Inter-
ests are retransmitted.

Similar forwarding rules based on more sophisticated lex-
icographic orderings could be deﬁned based on the same
general approach stated in HFAR. The requirement for such
forwarding rules is that more information needs to be main-
tained in the FIBs, such as distance values to name preﬁxes
that take into account such factors as end-to-end delay, re-
liability, cost, or bandwidth available.

HFAR is very similar to suﬃcient conditions for loop-free
routing introduced in the past, in particular suﬃcient condi-
tions for loop-free routing based on diﬀusing computations
[8, 19, 24]. Indeed, the approach we introduce for Interest-
loop detection in SIFAH can be viewed as a case of termi-
nation detection based on diﬀusing computations [6].

It should be pointed out that, because HFAR is not nec-
essary to detect loops, there are cases in which HFAR is
not satisﬁed even though no Interest loops exist. However,
prior results on multi-path routing based on diﬀusing com-
putations [23] indicate that this does not constitute a per-
formance problem. Given that FIBs are updated to reﬂect
correct hop counts, or correct complex distance values in
general, a suﬃcient condition for loop detection operating
with multi-path routing is a good baseline for an Interest-
based forwarding strategy.
4.4 SIFAH Operation

Algorithms 3 to 8 specify the steps taken by routers to
process Interests, forward Interests, return NDOs, process
perceived link failures, handle Interest-lifetime expirations,
and send NACKs according to SIFAH. Optional steps and
data in algorithms are indicated by “[o]”.

The algorithms used to describe SIFAH were not designed
to take into account such issues as load balancing of avail-
able paths, congestion-control, or the forwarding of an In-
terest over multiple concurrent paths. For simplicity, it is
assumed that all Interest retransmissions are carried out on
an end-to-end basis (i.e., by the consumers of content) rather
than routers. Hence, routers do not attempt to provide any
“local repair” when a neighbor fails or a NACK to an In-
terest is received; the origin of an Interest is in charge of
retransmitting it after receiving a NACK for any reason.
Interest retransmissions could also be done by routers. The

design and analysis of Interest retransmission strategies im-
plemented by routers or by content consumers is a topic
deserving further study.

Algorithm 3 implements HFAR. Router i determines
that an Interest can be forwarded because Condition 1 in
HFAR is satisﬁed (Line 9 of Algorithm 3), or an Interest
can be aggregated because Condition 2 of HFAR is satisﬁed
(Line 17 of Algorithm 3). Content requests from local con-
tent consumers are sent to the router in the form of Interests
stating inﬁnite hop counts to content, and each router knows
which neighbors are remote and which are local.

Algorithm 3 SIFAH Processing of Interest at router i
1: function Process Interest
2: INPUT: P IT i, CSi, F IBi, I[n(j), hI (k)];
3: if n(j) ∈ CSi then send D[n(j), sig(j)] to k
4: if n(j) (cid:54)∈ CSi then
5:
6:
7:

if n(j)∗ (cid:54)∈ F IBi then

% Route failed for n(j)∗:
send N I[n(j), no route] to k; drop I[n(j), hI (k)]
if ∃ v ∈ Si

n(j)∗ ( hI (k) > h(i, n(j)∗, v) ) then

if n(j) (cid:54)∈ P IT i then

else

% Interest can be forwarded:
call Forwarding Strategy(P I i

n(j))

% Interest may be traversing a loop:
send N I[n(j), loop] to k; drop I[n(j), hI (k)]

% There is a PIT entry for n(j):
if hI (k) > hI (i) then

% Interest can be aggregated:
IN SET (P I i

n(j)) = IN SET (P I i

n(j)) ∪ k

else

% Interest may be traversing a loop:
send N I[n(j), loop] to k; drop I[n(j), hI (k)]

8:
9:
10:

11:
12:

13:
14:
15:
16:
17:
18:

19:
20:

else

end if

end if

else

end if

21:
22:
23: end if
24: end function

end if

The Maximum Interest Life-time (M IL) assumed by a
router before it deletes an Interest from its PIT should be
large enough to preclude an excessive number of retrans-
missions. On the other hand, M IL should not be too large
to cause the PITs to store too many Interests for which
no NDO messages or NACKs will be sent due to failures
or transmission errors. A few seconds would be a viable
value for M IL. In practice, however, the consumer submit-
ting an Interest to its local router could provide an initial
value for the Interest lifetime estimated over a number of
Interests submitted for NDOs in the same NDO group cor-
responding to a large piece of content (e.g., a movie). This
is specially the case given our assumption that Interest re-
transmissions are carried out by content consumers, rather
than by routers.

Algorithm 4 describes a simple forwarding strategy in
which router i simply selects the ﬁrst neighbor v in the
ranked list of neighbors stored in the FIB for preﬁx n(j)∗
that satisﬁes the ﬁrst condition in HFAR (Line 4 of the al-
gorithm). More sophisticated strategies can be devised that
attain load balancing among multiple available routes to-
wards content and can be close to optimum (e.g., [19]). In
addition, the same Interest could be forwarded over multiple
paths concurrently, in which case content could be sent back

over some or all the paths that the Interest traversed suc-
cessfully. To be eﬀective, however, these approaches should
require the adoption of a loop-free multi-path routing pro-
tocol in the control plane (e.g., [9, 11]). In this context, the
control plane establishes valid multi-paths to content pre-
ﬁxes using long-term performance measures, and the data
plane exploits those paths using HFAR and short-term per-
formance measurements, without risking the long delays as-
sociated with backtracking due to looping.

Algorithm 4 SIFAH Interest forwarding at router i
1: function Forwarding Strategy
2: INPUT: P IT i, F IBi, M IL, I[n(j), hI (k)];
3: for each v ∈ Si
4:
5:

n(j)∗ by rank do
if hI (k) > h(i, n(j)∗, v) then

create P I i
n(j);
IN SET (P I i
RT (P I i
forward I[n(j), hI (i)] to v; return

n(j)) = {k}; OU T SET (P I i

n(j)) = M IL; hI (i) = h(i, n(j)∗, v);

n(j)) = {v};

6:
end if
7: end for
8: % No neighbor can be used in Si

for each k ∈ IN SET (P I i

n(j)∗ :

9: end function

n(j)) send N I[n(j), no route] to k

Algorithm 5 outlines the processing of NDO messages
received in response to Interests. A router accepts an NDO
received from a neighbor if it has a PIT entry waiting for
the content and the NDO message came from one of the
neighbors over which the Interest was sent (Line 5 of the al-
gorithm). The router forwards the valid NDO to any neigh-
bor that requested it and deletes the corresponding PIT en-
try. A router stores an NDO it receives optionally (Step 7
of Algorithm 5). The caching of NDOs is done according
to the caching strategy used in the network, which can be
path-based or edge-based [5], for example. However, SIFAH
works independently of the caching strategy adopted in the
network.

Algorithm 5 Process NDO message from q at router i
1: function Process NDO message
2: INPUT: P IT i, CSi, F IBi, D[n(j), sig(j)] received from q;

3: [o] verify sig(j);
4: [o] if veriﬁcation fails then drop D[n(j), sig(j)]
5: if n(j) ∈ P IT i ∧ q ∈ OU T SET (P I i
6:
n(j)) do

for each p ∈ IN SET (P I i
send D[n(j), sig(j)] to p;
[o] store the content with name n(j) in CSi;
delete P I i

n(j)) then

7:
8:
9: else
10:
11: end if
12: end function

n(j)

drop D[n(j), sig(j)]

Algorithm 6 shows a simple approach to handle the case
when a PIT entry expires with no NDO or NACK being re-
ceived. Given that routers do not initiate Interest retrans-
missions, router i simply sends NACKs to all neighbors from
which it received Interests for n(j). A more sophisticated
approach would be needed for the case in which routers
must provide Interest retransmissions in a way similar to
on-demand routing protocols that support local repair of
route requests.

Algorithm 6 Process Interest life-time expiration
1: function Process Interest Life-time Expiration
2: INPUT: P IT i, RT (P i
3: for each p ∈ IN SET (P I i

n(j)) = 0;

n(j)) do

send N I[n(j), Interest expired]

4: delete P I i
5: end function

n(j)

Algorithm 7 states the steps taken to handle NACKs.
Router i forwards the NACK it receives for n(j) to all those
neighbors from whom it received Interests for n(j) and deletes
the Interest entry after that. Supporting Interest retrans-
missions by routers would require a more complex approach
for the handling of NACKs.

Algorithm 7 Process NACK at router i
1: function Process NACK
2: INPUT: P IT i, N I[n(j), CODE];
3: if n(j) (cid:54)∈ P IT i then
4:
5: else
6:
7:
8:

drop N I[n(j), CODE]
if k (cid:54)∈ OU T SET (P I i
if k ∈ OU T SET (P I i

for each p ∈ IN SET (P I i
send N I[n(j), CODE];
delete P I i

n(j)) do

9:
10:
11: end if
12: end function

end if

n(j)

n(j)) then drop N I[n(j), CODE];
n(j)) then

Algorithm 8 Process failure of link (i, k) at router i
1: function Process Link Failure
2: INPUT: P IT i;
3: for each n(j) ∈ P IT (i) do
4:
5:

if k ∈ IN SET (P I i

n(j)) then
n(j)) = ∅ then delete P I i

n(j)) − {k};
n(j);

IN SET (P I i
if IN SET (P I i

n(j)) = IN SET (P I i

end if
if k ∈ OU T SET (P I i

n(j)) = OU T SET (P I i

OU T SET (P I i
if OU T SET (P I i

n(j)) then
n(j)) = ∅ then
for each p ∈ IN SET (P I i
send N I[n(j), route failed]

n(j)) do

n(j)) − {k};

6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
end if
16: end for
17: end function

end if

end for
delete P I i

n(j)

Algorithm 8 lists the steps taken by a router in response
to the failure of connectivity with a neighbor. Reacting to
the failure of perceived connectivity with a neighbor over
which Interests have been forwarded could be simply to wait
for the life-times of those Interests to expire. However, such
an approach can be very slow reacting to link failures com-
pared to using Algorithm 8. The algorithm assumes that
the control plane updates F IBi to reﬂect any changes in
hop counts to name preﬁxes resulting from the loss of con-
nectivity to one or more neighbors. For each Interest that
was forwarded over the failed link, router i sends a NACK
to all neighbors whose Interests were aggregated.

4.5 Examples of SIFAH Operation

Figures 2(a) to (d) illustrate how SIFAH operates using
the same example used in Figure 1. Figures 2(a) and (b) ad-
dress the case in which the control plane establishes multiple
paths to each name preﬁx but does not guarantee loop-free
routing tables. Figures 2(c) and (d) illustrate how SIFAH
operates when single-path routing is used.

The pair of numbers next to each link outgoing from a
node in Figure 2(a) indicates the hop count to n(j) through
a neighbor and the ranking of the neighbor in the FIB. The
example assumes that: (a) routers execute a routing proto-
col that does not enforce loop-free FIBs; and (b) the rank-
ing of neighbors is determined independently at each router
using some data-plane strategy based on the perceived per-
formance of each path and interface.
It should be noted
that the distance value of a path need not be directly pro-
portional to the hop-count value of the path shown in the
ﬁgure.

Let the tuple (v: h, r) indicate a neighbor, its hop count
and its ranking. In Figure 2(a), F IBa lists (b: 7, 1), (p: 7,
2), and (x: 9, 3), which is shown in green font. Similarly,
F IBy states (a: 8, 1); F IBb states (c: 10, 2), (a: 8, 1), and
(q: 6, 3); F IBc states (b: 7, 1), (x: 9, 2), and (r: 9, 3); and
F IBx states (a: 8, 1) and (c: 8, 2). Some of the FIB entries
for p, q and r are shown in black font.

Figure 2:
with SIFAH

Interest looping is avoided or detected

In Figure 2(b), router y originates an Interest for n(j) and
sends I[n(j), hI (y) = 8] to a. Router a receives the Inter-
est from router y at time t1 and, given that 8 = hI (y) >
h(a, n(j)∗, b) = 7,
it accepts the Interest because it has
at least one neighbor that satisﬁes HFAR. Router a sends
I[n(j), hI (a) = 7] to b because it is the highest-ranked neigh-
bor satisfying HFAR. Router a aggregates I[n(j), hI (x) = 8]
at time t3 > t1, because it sent I[n(j), hI (a) = 7] at time t1
and 8 = hI (x) > hI (a) = 7. Router b receives the Interest
from a at time t2 > t1; accepts it because it has at least one
neighbor that satisﬁes HFAR (7 = hI (a) > h(b, n(j)∗, q) =
6); and sends I[n(j), hI (b) = 6] to q because q is the highest-
ranked neighbor of b that satisﬁes HFAR. This is an example
that Interests are forwarded along loop-free paths if SIFAH
is used and the FIBs maintained by routers have consistent
information, even if some of the multi-paths implied in the
FIBs involve loops. The next section proves this result in
the general case.

Figure 2(c) shows the hop count values stored in the FIBs
for name preﬁx n(j) when single-path routing is used. Each
router has a single next hop and one hop count for each
preﬁx listed in its FIB. Router b updates its FIB to reﬂect
the failure of link (b, q) at time t1, while router y sends an
Interest to router a requesting n(j). Routers have incon-
sistent FIB states for n(j) while routing updates propagate
and Interests are being forwarded.
As shown in Figure 2(d), router b must send N I[n(j), loop]
to a, because 7 = hI (a) (cid:54)> h(b, n(j)∗, c) = 10 and HFAR is
not satisﬁed. In turn, when a receives the NACK from b, it
must forward N I[n(j), loop] to y and to x. Eventually, the
routing protocol running in the control plane makes routers
a and y change the hop count to n(j)∗ in their FIBs to reﬂect
the failure of link (b, q). At that point, a retransmission of
the Interest from y would state hI (y) = 9 and would make
a forward I[n(j), hI (a) = 8] to p.

5. CORRECTNESS OF SIFAH

The following theorems show that SIFAH enforces correct
Interest forwarding and aggregation, and constitutes a safe
Interest forwarding strategy. The results are independent
of whether the network is static or dynamic, the speciﬁc
caching strategy used in the network (e.g., at the edge or
along paths traversed by NDO messages [5]), or the retrans-
mission strategy used by content consumers after experienc-
ing g a timeout or receiving a NACK from attached routers.
SIFAH ensures that Interests cannot be incorrectly propa-
gated and aggregated along loops without meeting routers
that detect the incorrect forwarding and hence send NACKs
in return.

Theorem 3. Interest loops cannot occur and be unde-

tected in a network in which SIFAH is used.

Proof. Consider a network in which SIFAH is used. As-
sume for the sake of contradiction that nodes in a loop L
of h hops {v1, v2, ..., vh, v1} send and possibly aggregate In-
terests for n(j) along L, with no node in L detecting the
incorrect forwarding of any of the Interests sent over the
loop.
Given that L exists by assumption, vk ∈ L must send
I[n(j), hI (vk)] to node vk+1 ∈ L for 1 ≤ k ≤ h− 1, and vh ∈
L must send I[n(j), hI (vh)] to node v1 ∈ L. For 1 ≤ k ≤
h−1, let h(vk, n(j)∗)L denote the value of hI (vk) when node
vk sends I[n(j), hI (vk)] to node vk+1, with h(vk, n(j)∗)L =
h(vk, n(j)∗, vk+1). Let h(vh, n(j)∗)L denote the value of
hI (vh) when when node vh sends I[n(j), hI (vh)] to node
v1 ∈ L, with h(vh, n(j)∗)L = h(vh, n(j)∗, v1).

Because no node in L detects the incorrect forwarding
of an Interest, each node in L must aggregate the Interest
it receives from the previous hop in L or it must send its
own Interest as a result of the Interest it receives from the
previous hop in L. This implies that vk ∈ L must accept
n(j)) expires for 1 ≤ k < h,
I[n(j), hI (vk−1)] before RT (P I vk
and v1 ∈ L must accept I[n(j), hI (vh)] before RT (P I v1
n(j))
expires.

According to SIFAH, if vk aggregates I[n(j), hI (vk−1)],
then it must be true that hI (vk−1) > hI (vk). Similarly, if
v1 aggregates I[n(j), hI (vh)], then it must be the case that
hI (vh) > hI (v1).

On the other hand, if vk sends I[n(j), hI (vk)] to vk+1
as a result of receiving I[n(j), hI (vk−1)] from vk−1, then

it must be true that hI (vk−1) > h(vk, n(j)∗)L = hI (vk) for
1 < k ≤ h. Similarly, if v1 sends I[n(j), hI (v1)] to v2 as
a result of receiving I[n(j), hI (vh)] from vh, then hI (vh) >
h(v1, n(j)∗)L = hI (v1).

It follows from the above argument that, for L to exist
when each node in the loop follows SIFAH to send Inter-
ests asking for n(j), it must be true that hI (vh) > hI (v1)
and hI (vk−1) > hI (vk) for 1 < k ≤ h. However, this is a
contradiction, because it implies that hI (vk) > hI (vk) for
1 ≤ k ≤ h. Therefore, the theorem is true.

The proof of Theorem 3 can be augmented to account
for Interest forwarding strategies based on complex distance
values rather than hop counts.

To be safe, an Interest forwarding strategy must ensure
that either an NDO message with the requested content or
a NACK is received within a ﬁnite time by the consumer
who issues an Interest. The following theorem shows that
this is the case for SIFAH, independently of the state of the
topology or the fate of messages.

Theorem 4. SIFAH ensures that an NDO message for
name n(j) or a NACK is received within a ﬁnite time by
any consumer who issues an Interest for NDO with name
n(j).

Proof. Consider I[n(j), hI (s)] being issued by consumer
s at time t1. The forwarding of Interests assumed in SIFAH
is based on the best match of the requested NDO name with
the preﬁxes advertised in the network. Furthermore, accord-
ing to Algorithm 3, a router sends back an NDO message to
a neighbor that sent an Interest for NDO n(j) only if has an
exact match of the name n(j) in its content store. According
to Algorithm 5, a router that receives an NDO message in
response to an Interest it forwarded must forward the same
NDO message. Hence, the wrong NDO message cannot be
sent in response to an Interest. There are three cases to con-
sider next: (a) there are no routes to the name preﬁx n(j)∗
of the requested NDO, (b) the Interest traverses an Interest
loop, or (c) the Interest traverses a simple path towards a
router d that can reply to the Interest.
Case 1: If there is no route to n(j)∗, then it follows from
the operation of SIFAH (Algorithm 4) that a router issues a
NACK stating that there is no route. That NACK is either
forwarded successfully back to s or is lost due to errors or
faults. In the latter case, it follows from Algorithms 6 and
8 that a router must send a NACK back towards s stating
that the Interest expired or the route failed.

Case 2: If I[n(j), hI (s)] is forwarded along an Interest
loop and does not reach any node with a copy of n(j), then
it follows from Theorem 3 that the Interest must either reach
some router k that detects the incorrect forwarding of the
Interest and must issue a NACK N I[n(j), loop] in response,
or the Interest is dropped due to faults or transmission errors
before reaching such router k.

If N I[n(j), loop] reaches a router k that detects the loop
and issues N I[n(j), loop], then according to SIFAH (Algo-
rithm 7), every router receiving the NACK N I[n(j), loop]
originated by router k from the neighbor to whom the In-
terest was sent must relay the NACK towards s. Hence, if
no errors or faults prevent the NACK from reaching s, the
consumer receives a NACK stating that an Interest loop was
found.

On the other hand, if either the Interest traversing an
Interest loop or the NACK it induces at some router k is lost,

it follows from Algorithms 6 and 8 that a router between s
and router k must send a NACK towards s indicating that
the Interest expired or that the route failed. Accordingly,
consumer s must receive a NACK within a ﬁnite time after
issuing its Interest in this case.
Case 3: If the Interest traverses a simple path towards a
router d that advertises n(j)∗ or has a content store con-
taining n(j), then the Interest must either reach d or not.

If the Interest is lost and does not reach d, then it follows
from Algorithms 6 and 8 that a router between s and router
d must send a NACK towards s indicating that the Interest
expired or that the route failed. As a result, s must receive
a NACK originated by some router between s and d.

If the Interest reaches d, then that router must either send
the requested NDO back, or (in the case that d advertises
n(j)∗ and n(j) does not exist) issue a NACK stating that
n(j) does not exist. According to Algorithms 5 and 7, the
NDO message or NACK originated by d is forwarded back
towards s along the reversed simple path traversed by the
Interest. If no fault or errors occur between d and s, it fol-
lows that the theorem is true for this case. Alternatively,
if the NDO or NACK originated by d is lost due to faults
or errors, it follows from Algorithms 6 and 8 that a router
between s and router d must send a NACK towards s indi-
cating that the Interest expired or that the route failed.

6. PERFORMANCE COMPARISON

We compare SIFAH with NDN and the original CCN for-
warding strategy in terms of the storage complexity of the
approaches; the average time that a PIT entry remains in
the PIT waiting for an NDO message or a NACK to be re-
ceived in response, which we call PIT entry pending time;
the end-to-end delay experienced by content consumers in
receiving either the content they request or negative feed-
back; and the number of entries in the PITs maintained by
content routers.

The storage complexity of each approach provides an in-
dication of the storage overhead induced by the type of in-
formation required for routers to detect Interests loops. The
simulation results we present on PIT entry pending times,
end-to-end delays, and PIT sizes should be viewed simply as
indications of the negative eﬀects that undetected Interest
loops have on the performance of NDN and CCN, and the
fact that they can be completely avoided using SIFAH.
6.1 Storage Complexity

There is a large diﬀerence in the storage overhead incurred

with the NDN forwarding strategy compared to SIFAH.

In SIFAH, router i uses only the value of hI (i) to deter-
mine whether the Interest it receives from k may be travers-
ing an Interest loop, and does not store hI (k). Hence, the
PIT storage size for SIFAH is

SSSIF AH = O((IN T + |mh|)|P IT i|SIF AH )

where |P IT i|SIF AH is the number of pending Interests in
P IT i when SIFAH is used, |mh| is the number of bits used
to store hI (i), and IN T is the average storage required
to maintain information about the incoming and outgoing
neighbors for a given Interest. For a given NDO with name
n(j), the amount of storage needed to maintain the incoming
and outgoing neighbors is

IN SET (P I i

n(j)) + OU T SET (P I i

n(j)).

The NDN forwarding strategy requires each router to store
the list of diﬀerent nonces used to denote valid Interests for
a given NDO name n(j). With each nonce being of size
|id| and router i having up to I neighbors that send valid
Interests for an NDO, the PIT storage size for NDN is

SSN DN = O((IN T + |id|I) |P IT i|N DN )

where |P IT i|N DN is the number of pending Interests in
P IT i when NDN is used. Hence, even if |P IT i|N DN is the
same as |P IT i|SIF AH , the amount of additional PIT storage
needed in NDN over SIFAH is

SSN DN − SSSIF AH ≥
(|id|I)(|P IT i|N DN ) − (|mh|)(|P IT i|N DN ).

A maximum hop count of 255 for an Interest is more
than enough. Hence, with the size of a nonce in NDN of
four bytes, the savings in PIT storage obtained with SIFAH
compared to NDN is (32I − 8) |P IT i|N DN . This represents
enormous savings of RAM in large networks. Furthermore,
because the NDN forwarding strategy may not detect loops
when Interests are aggregated, many Interest entries in PITs
may have to be stored until their lifetimes expire. Accord-
ingly, |P IT i|SIF AH can be much smaller than |P IT i|N DN .
This is conﬁrmed by the simulation results presented subse-
quently.

The additional FIB storage overhead in SIFAH compared
to the NDN forwarding strategy consists of storing the hop
count information for each preﬁx n(j)∗ from each neighbor.
This amounts to (|mh|)(|F IBi|)Di at router i, where Di is
the number of neighbors of router i and |F IBi| is the number
of entries in F IBi. Given that Di and I are of the same
order and O(|F IBi|) < O(|P IT i|), this is far smaller than
the additional PIT storage needed by the NDN forwarding
strategy compared to SIFAH.
6.2 Performance Impact of

Undetected Interest Loops

6.2.1

Implementation of Forwarding Strategies
in ndnSIM

We implemented SIFAH in ndnSIM, an open-source NS-
3 based simulator for Named Data Networks and Informa-
tion Centric Networks [1]. Following the NDN architec-
ture, ndnSIM is implemented as a new network-layer pro-
tocol model, which can run on top of any available link-
layer protocol model, as well as on top of network-layer and
transport-layer protocols.

We used the NDN implementation of its data plane from
ndnSIM without any modiﬁcations. The ndnSIM NDN im-
plementation is capable of detecting simple loops by match-
ing nonces. The PIT entry expiration time for NDN is set
to the default of one second. It should be pointed out that,
in the default NDN implementation, a router that receives a
duplicate Interest simply drops the Interest without sending
a NACK back. This corresponds to the original CCN for-
warding strategy. The ndnSIM NDN implementation also
allows the use of NACKs after Interest loop detection. The
results presented in this section for “CCN” correspond to
the ndnSIM implementation of NDN without NACKs, and
the results presented for “NDN” correspond to the ndnSIM
implementation of NDN with NACKs enabled.

To implement Algorithms 3 to 8 deﬁning SIFAH in ndnSIM,

we had to make some modiﬁcations on the basic structures

of ndnSIM, namely: the FIBs, Interest packets, NACKs,
and the forwarding strategy. A new ﬁeld “rank” is added
to every entry of the FIB. Unlike ndnSIM in which the next
hop selection for requested preﬁxes is based on hop count,
in SIFAH next hops are sorted based on rank of each FIB
entry. The ﬁeld h(k) was added to each Interest message,
which determines the hop count from forwarding node k to
the preﬁx requested by the Interest. A new type of NACK
for loop detection is added and the behavior of forwarding
strategy for NACKs is modiﬁed based on SIFAH deﬁnitions.
Furthermore, a new class of forwarding strategy is added to
ndnSIM that implements SIFAH functions.
6.2.2
To isolate the operation of the data plane from the perfor-
mance of diﬀerent routing protocols operating in the control
plane, we used static routes and manually conﬁgured routing
loops for speciﬁc preﬁxes.

Simulation Scenarios

Given the use of static routes and conﬁgured loops, we
used a simple grid topology of sixteen nodes with two con-
sumers producing Interests with diﬀerent preﬁxes and one
producer announcing the content requested in the Interests.
Interest traﬃc is generated at a constant bit rate with a fre-
quency of 2000 Interests per second. The delay over each
link of the topology is set t to 10 msec and PIT entry expira-
tion time is set to only 1000 msec, which is too short for real
networks but is large enough to illustrate the consequences
of undetected Interest loops.

Five diﬀerent scenarios, each lasting 90 seconds of simu-
lation time, were used to compare SIFAH with NDN and
CCN. Each scenario is deﬁned by the percentage of Inter-
ests traversing loops, which was set to equal 0%, 10%, 20%,
50%, and 100% of the Interests generated by consumers. In
practice, it should be the case that only a small fraction of
Interests traverse loops, assuming a correct routing protocol
is used in the control plane and sensible policies are used
to rank the available routes in the FIBs. The scenarios we
present illustrate that just a few Interests traversing unde-
tected loops cause performance degradation, and that net-
work performance is determined by the PIT entry expiration
times as the fraction of Interests traveling loops increases.

requesting pref ix2 use alternate paths from node A to node
B and from node B to node C2, which causes the looping of
such Interests.

Interests for pref ix2 generated by C1 and C2, request the
same content at approximately the same time, so that ag-
gregation can take place at routers along the paths traversed
by Interests. This results in the aggregation of Interests at
node C1 for Interests generated by C2, and the aggregation
of Interests at node C2 for Interests generated by C1. Our
simple scenarios provide enough insight on the negative im-
pact of undetected Interest loops in the presence of Interest
aggregation using NDN and the original CCN design.

Simulation results are shown for three diﬀerent forwarding
strategies: The original CCN, NDN, and SIFAH. The dif-
ference between CCN and NDN is that CCN does not send
NACKs when duplicate Interests are detected. On the other
hand, NDN sends NACK when simple loops are detected by
receiving duplicate Interests.

Impact on PIT Entry Duration

6.2.3
Figure 4 shows the average value of the PIT entry pend-
ing time for all PIT entries. When no Interest loops are
present, NDN, CCN and SIFAH exhibit the same perfor-
mance, with each having an average PIT entry pending time
of 60 msec. This should be expected, given that Interests
and NDO messages traverse shortest paths between con-
sumers and producers or caches.

The average PIT entry pending time in SIFAH does not
increase as he percentage of Interests that encounter Interest
loops increases. The reason for this is that SIFAH ensures
that an Interest must elicit either an NDO message or a
NACK to be sent back from some router along the route it
traverses back to the consumer that originates the Interest.
Hence, the average amount of time an Interest entry spends
in the PIT is a function of the round-trip time it takes for
either an NDO message or a NACK to evict it from the
PIT. This is proportional to a round-trip time between a
consumer and a router with the content or a router at which
HFAR is not satisﬁed, which is a few milliseconds in the grid
topology.

Figure 3: Initial Routes and Custom Loop Scenario

Figure 4: Average PIT entry pending time for CCN,
NDN, and SIFAH

Figure 3 shows the topology and scenario we used in our
simulations. Consumer C1, produces Interests for pref ix1
and pref ix2, and consumer C2 produces Interests only for
pref ix2. Blue arrows and green arrows shows initial routes
for pref ix1 and pref ix2, respectively. We assume that the
route between nodes A and D, and the route between nodes
B and E for pref ix2 are disconnected. Therefore, Interests

By contrast, the average PIT entry pending time in CCN
and NDN increases dramatically with the percentage of In-
terests that encounter Interest loops. The percentage of In-
terests that traverse loops need not be large to have negative
performance consequences. For the scenario in which 10%
of the Interests encounter Interest loops, we observe that
the average PIT entry pending time increases dramatically

in NDN and CCN, with the average PIT entry pending time
being 113 msec, which is about twice the average PIT entry
pending time in SIFAH.

The results for NDN and CCN can be easily explained.
CCN simply deletes and drops duplicate Interests, each In-
terest that encounters an Interest loop is discarded by the
router that detects a duplicate Interest, and this action
forces the corresponding PIT entries in the routers traversed
by the Interest to remain in those PITs, until their PIT en-
try expiration timers expire. In NDN, Interest loops can go
undetected with aggregation and therefore no NACKs are
sent in those cases. As a result, the time an Interest entry
spends in the PIT equals the PIT entry expiration time if
the Interest traverses an undetected loop. The results are
almost the same for CCN and NDN. The reason for observ-
ing slightly lower values for NDN compared to CCN, is that
some of the Interests for content in pref ix2 are not gener-
ated by C1 and C2 with suﬃcient time correlation to enable
Interest aggregation, which results in detection of Interest
loops in NDN and Interests being discarded in CCN.

Impact on PIT Size

The PIT entry pending times in NDN and CCN are many
orders of magnitude larger for Interests that traverse unde-
tected Interest loops. This is unavoidable, given that the
PIT entry pending time is proportional to a PIT entry ex-
piration time, which by design must be set conservatively
to values that are far longer than average round-trip times
between consumers and producers. In the simulations, the
PIT entry expiration time is just one second.
6.2.4
Figure 5 shows the average size of PIT tables in terms of
number of entries for a router included in Interest ﬂows for
ﬁve diﬀerent scenarios comparing CCN, NDN, and SIFAH.
CCN, NDN and SIFAH have exactly the same PIT size in
the absence of Interest loops, which is expected. As the
percentage of Interests that encounter loops increases, the
average number of entries in the PITs increases dramatically
for CCN and NDN. For the case in which only 10% of Inter-
ests encounter loops, the number of entries doubles in NDN
and CCN compared to SIFAH. For the case in which 100%
of Interests encounter loops, the average number of PIT en-
tries in CCN and NDN is 1889 and 1884, respectively, while
the number of PIT entries in SIFAH actually decreases.

Figure 5: Average PIT table size for CCN, NDN,
and SIFAH

Impact on Round-Trip Times

routers sending NACKs compared to the round-trip times
of paths to the producers of requested content.
6.2.5
Figure 6 shows the average round-trip time (RTT) for all
ﬁve scenarios for CCN, NDN and SIFAH. In the simulation
experiments, the round-trip time is considered to be the time
elapsed from the instant when an Interest is ﬁrst sent to the
instant when an NDO message or a NACK is received by
the consumer who created the Interest.

For the case of no loops, CCN, NDN, and SIFAH have
the same average RTT. When the percentage of Interests
traversing loops is 10%, the average RTT in CCN and NDN
increases to almost two times the average RTT in SIFAH,
and some Interests have much larger RTTs than the aver-
age. As the percentage of Interests that loop increases, the
average RTT becomes proportional to the PIT entry expi-
ration time, which is to be expected. The average RTT in
SIFAH decreases as more Interests traverse loops, which is
a result of the shorter RTTs between consumers and routers
sending the NACKs.

Figure 6: Average round trip time (RTT) for CCN,
NDN, and SIFAH

6.3 Design Implications

The simulation experiments we have presented are meant
only to help illustrate the negative impact of undetected
Interest loops when they occur, rather than to provide rep-
resentative scenarios of the performance of Interest-based
forwarding strategies in large networks. Our results illus-
trate that loops in FIBs need not be long lasting or impact
a large percentage of Interest to cause the number of stored
PIT entries and end-to-end delays to increase quickly.

As we have shown, the PIT storage requirements for SIFAH
are smaller than those for the original CCN and NDN for-
warding strategies. Thus, SIFAH is more eﬃcient than CCN
and NDN even in the absence of Interest loops. Given that
SIFAH is so easy to implement in the context of CCN and
NDN, it makes practical sense to eliminate the current prac-
tice in NDN and CCN of attempting to detect Interest loops
by the matching of nonces and Interest names, which does
not work.

7. CONCLUSIONS

The reason for the decrease in average number of PIT en-
tries for SIFAH as the percentage of Interests that encounter
loops increases is a consequence of the shorter round-trip
times between the consumers submitting Interests and the

We showed that the forwarding strategies in NDN and the
original CCN architectures may fail to detect Interest loops
when they occur, and that a correct forwarding strategy that
supports Interest aggregation cannot be designed simply by

identifying each Interest uniquely and deciding that there
is an Interest loop based on the matching of Interest names
and nonces.

We introduced the Strategy for Interest Forwarding and
Aggregation with Hop-counts (SIFAH). It is the ﬁrst Interest-
based forwarding strategy shown to be correct in the pres-
ence of Interest loops, Interest aggregation, faults, and the
forwarding of Interests over multiple paths. SIFAH oper-
ates by requiring that FIBs store the next hops and the hop
count through such hops to named content, and by having
each Interest state the name of the content requested and
the hop count from the relaying router to the content.

We showed that SIFAH incurs less storage overhead than
using nonces to identify Interests. We also showed that, if
NDN or the original CCN design is used in a network, the
number of PIT entries and end-to-end delays perceived by
consumers can increase substantially with just a fraction of
Interests traversing undetected loops. Although our simula-
tion experiments assumed a very small network, our results
provide suﬃcient insight on the negative eﬀects of unde-
tected Interest loops in NDN and the original CCN design.
This work is just a ﬁrst step in the deﬁnition of correct
Interest-based forwarding strategies, and it is applicable to
any Interest retransmission approach. For simplicity, we
assumed that content consumers are in charge of Interest
retransmissions and that routers do not provide local re-
pair of Interests after receiving NACKs or detecting link
failures. The design of an eﬃcient Interest retransmission
strategy and determining whether Interest retransmissions
by routers improves performance are arguably the most im-
portant next steps. However, SIFAH provides the necessary
foundation to deﬁne a correct retransmission strategy, be-
cause it guarantees that each Interest results in an NDO
message or a NACK being sent to the consumer who origi-
nated the Interest.

More work is also needed to understand the performance
of SIFAH in large networks, the eﬀect of PIT entry expi-
ration timers on performance, the eﬀect of load balancing
of Interests over multiple available routes to content, the
impact of local repairs in Interest forwarding, and the per-
formance implications of the interaction between SIFAH and
a routing protocol that guarantees loop-free routing tables
(and hence FIBs) at all times [9, 10, 11] compared to one
that does not [14].

8. REFERENCES

[1] A. Afanasyev, I. Moiseenko, and L. Zhang, “ndnSIM:

NDN Simulator for ns-3”, University of California,
Los Angeles, Tech. Rep, 2012.

[2] B. Ahlgren et al., “A Survey of Information-centric
Networking,” IEEE Commun. Magazine, July 2012,
pp. 26–36.

[3] J. Behrens and J.J. Garcia-Luna-Aceves, “Hierarchical
Routing Using Link Vectors,” Proc. IEEE INFOCOM
‘98, April 1998.

[4] Content Centric Networking Project (CCN) [online].
http://www.ccnx.org/releases/latest/doc/technical/
[5] A. Dabirmoghaddam et al., “Understanding Optimal
Caching and Opportunistic Caching at ”The Edge” of
Information-Centric Networks,” Proc. ACM ICN ‘14,
Sept. 2014.

[6] E.W. Dijkstra and C.S. Scholten “Termination

Detection for Diﬀusing Computations,” Information
Processing Letters, Vol. 11, No. 1, 1980.

[7] E.W. Dijkstra, W. Feijen, and A.J.M. van Gasteren,

“Derivation of a Termination Detection Algorithm for
Distributed Computations,” Information Processing
Letters, Vol. 16, No. 5, 1983.

[8] J.J. Garcia-Luna-Aceves, “A Uniﬁed Approach to
Loop-Free Routing Using Distance Vectors or Link
States,” Proc. ACM SIGCOMM ‘89, Aug. 1989.
[9] J.J. Garcia-Luna-Aceves, “Name-Based Content
Routing in Information Centric Networks Using
Distance Information,” Proc. ACM ICN ‘14, Sept.
2014.

[10] J.J. Garcia-Luna-Aceves, “Routing to

Multi-Instantiated Destinations: Principles and
Applications,” IEEE ICNP ‘14, Oct. 2014.

[11] J.J. Garcia-Luna-Aceves, “Eﬃcient Multi-Source

Multicasting in Information Centric Networks,” Proc.
IEEE CCNC ‘15, Jan. 2015.

[12] C. Intanagonwiwat, R. Govindan, and D. Estrin,

“Directed Diﬀusion: A Scalable and Robust
Communication Paradigm for Sensor Networks,” Proc.
ACM MobiCom ‘00, 2000.

[13] V. Jacobson et al., “Networking Named Content,”

Proc. IEEE CoNEXT ‘09, Dec. 2009.

[14] A.K.M. Mahmudul-Hoque et al., “NSLR: Named-Data

Link State Routing Protocol,” Proc. ACM ICN ‘13,
2013.

[15] J. Matocha and T. Camp, “A Taxonomy of

Distributed Termination Detection Algorithms,”
Journal of Systems and Software, 1998.

[16] NDN Project [online]. http://www.named-data.net/
[17] M. Spohn and J.J. Garcia-Luna-Aceves, “Scalable

Link-State Internet Routing,” Proc. IEEE ICNP ‘98,
Oct. 1998.

[18] I. Solis and J.J. Garcia-Luna-Aceves, “Robust

Content Dissemination in Disrupted Environments,”
Proc. ACM CHANTS ‘08, Sept. 2008.

[19] S. Vutukury and J.J. Garcia-Luna-Aceves, “A Simple

Approximation to Minimum-Delay Routing,” Proc.
ACM SIGCOMM ‘99, Aug. 1999.

[20] G. Xylomenos et al., “A Survey of Information-centric
Networking Research,” IEEE Communication Surveys
and Tutorials, July 2013.

[21] C. Yi et al., “Adaptive Forwarding in Named Data
Networking,” ACM CCR, Vol. 42, No. 3, July 2012.

[22] C. Yi et al., “A Case for Stateful Forwarding Plane,”

Computer Communications, pp. 779-791, 2013.

[23] W.T. Zaumen and J.J. Garcia-Luna-Aceves,

“Dynamics of Distributed Shortest-Path Routing
Algorithms,” Proc. ACM SIGCOMM ‘91, Sept. 1991.
[24] W.T. Zaumen and J.J. Garcia-Luna-Aceves, “System

for Maintaining Multiple Loop-free Paths between
Source Node and Destination Node in Computer
Network,” US Patent 5,881,243, 1999.

[25] L. Zhang et al., “Named Data Networking,” ACM

SIGCOMM Computer Communication Review, Vol.
44, No. 3, July 2014.

