6
1
0
2

 
r
a

M
9

 

 
 
]

.

A
N
h
t
a
m

[
 
 

1
v
6
0
9
2
0

.

3
0
6
1
:
v
i
X
r
a

A Sparse Grid Discretization with Variable

Coefﬁcient in High Dimensions

Rainer Hartmann and Christoph Pﬂaum

March 10, 2016

Abstract

We present a Ritz-Galerkin discretization on sparse grids using pre-wavelets,
which allows to solve elliptic differential equations with variable coefﬁcients for
dimension d = 2, 3 and higher dimensions d > 3. The method applies multilinear
ﬁnite elements. We introduce an efﬁcient algorithm for matrix vector multiplica-
tion using a Ritz-Galerkin discretization and semi-orthogonality.

This algorithm is based on standard 1-dimensional restrictions and prolonga-
tions, a simple pre-wavelet stencil, and the classical operator dependent stencil
for multilinear ﬁnite elements. Numerical simulation results are presented for a
3-dimensional problem on a curvilinear bounded domain and for a 6-dimensional
problem with variable coefﬁcients.

Simulation results show a convergence of the discretization according to the
approximation properties of the ﬁnite element space. The condition number of the
stiffness matrix can be bounded below 10 using a standard diagonal preconditioner.

Introduction

1
A ﬁnite element discretization of an elliptic symmetric PDE calculates the best approx-
imation with respect to the energy norm. Since ﬁnite element method uses polynomials
to construct a ﬁnite element space, the convergence of such a method can be proven
using Strang’s lemma or Lax-Milgram theorem. However, difﬁculties arise in the ap-
plication to high dimensional problems. Then the computational amount increases by
O(N d), where N is the number of grid points in one direction and d is the dimension
of the space. This exponential growth of the computational amount restricts the appli-
cation of the ﬁnite element method to dimensions d ≤ 3. A suggestion to solve this
problem is to use sparse grids (see [1]). With sparse grids, one can construct a subspace
of the classical ﬁnite element spaces on full grids. The dimension of this subspace re-
duces to O(N (log N )d−1). However, solving the resulting linear equation efﬁciently
is a difﬁcult task. Suitable algorithms were constructed for constant coefﬁcients and
cubical domains (see [2] and [3]). Those algorithms evaluate the matrix vector multipli-
cation in an efﬁcient way. Therefore, using a Ritz-Galerkin discretization, one matrix
vector-multiplication can be performed by O(N (log N )d−1) operations. However, a
variable coefﬁcient in the operator leads to O(N d) operations. So far, sparse grids

1

have had very limited range of applications since most partial differential equations in
natural science or engineering science include variable coefﬁcients.

The ﬁrst sparse grid discretization with variable coefﬁcients, using a Ritz-Galerkin
approach, is presented in [4]. This discretization applies the semi-orthogonality prop-
erty of standard hierarchical basis functions (see Section 2). A complete convergence
theory is given in [5] for a 2-dimensional case. The discretization leads to a sym-
metric stiffness matrix in case of a symmetric bilinear form. Nevertheless, an exten-
sion to higher dimension problems is not possible for standard hierarchical basis func-
tions since hierarchical basis functions do not satisfy a semi-orthogonality property for
d ≥ 3.

Other discretizations of PDEs with variable coefﬁcients are presented in [6] and
[7]. The discretization in [6] can be treated as a ﬁnite element discretization, while
the discretization in [7] is a ﬁnite difference discretization. Both discretizations lead
to a non-symmetric linear equation system for symmetric problems, which is an unde-
sired property. Additionally, a convergence proof is missing for both discretizations.
Therefore, convergence of these methods is not guaranteed in higher dimensions. Fur-
thermore, the discretization in [6] requires high order interpolation operators, which in-
creases the computational amount. However, simulation results presented in literature
show an optimal convergence for certain 2-dimensional and 3-dimensional problems.
In this paper, we present a new method to discretize partial elliptic differential equa-
tions on sparse grids (see Section 2). This discretization uses pre-wavelets and their
semi-orthogonality property (see [4]). It is well-known that pre-wavelets and wavelets
can be used to discretize partial differential equations (see [8], [9], [10], and [11]).
In the context of sparse grids, they can even lead to natural discretizations of elliptic
partial differential equations with variable coefﬁcients. The elementary convergence
theory of such discretizations is presented for a Helmholtz problem in [12]. In Section
6, we present an algorithm that efﬁciently evaluates the matrix vector multiplication
with the discretization matrix. The algorithm applies only standard 1-dimensional re-
striction and prolongation operators, a simple pre-wavelet stencil of size 5, and the
classical stencil operator for multilinear ﬁnite elements. This operator dependent sten-
cil is a well-known 9-point stencil for bilinear elements and a 27-point stencil for tri-
linear elements. However, in the 6-dimensional case the size of this stencil increases
to 729 = 36. The difﬁculty of the algorithm is to apply all operators in the correct
sequential ordering.

In Section 8 simulation results are presented for the 3-dimensional Poisson’s prob-
lem on a curvilinear bounded domain and for a 6-dimensional Helmholtz problem with
a variable coefﬁcient. The simulation result for Poisson’s problem implies that sparse
grids are not restricted to cubical domains. To our knowledge, the numerical result for
the 6-dimensional Helmholtz equation is the ﬁrst simulation result for an 6-dimensional
Ritz-Galerkin ﬁnite element discretization of a elliptic PDE with variable coefﬁcients.
This paper is restricted to non-adaptive grids. However, it is clear that the algorithm

can be extended to adaptive sparse grids as shown in [4].

2

(cid:90)

(cid:90)

2 Sparse Grid Discretization
Let d ≥ 2 be the dimension of space and Ω = [0, 1]d. Consider the following elliptic
differential equation:
Problem 1 Let f ∈ L2(Ω), A ∈ (L∞(Ω))d×d and κ ∈ L∞(Ω), κ ≥ 0 be given.
Furthermore, assume that A is symmetric and uniformly positive deﬁnite. This means
that there is a α > 0 such that vT A(x)v > αvT v for almost every x ∈ Ω and every
vector v ∈ Rd. Find u ∈ H 1

0 (Ω) such that

(∇u)T A(x)∇v + κ(x)uv dx =

f vh dx ∀v ∈ H 1

0 (Ω).

Ω

Ω

Our aim is to ﬁnd an efﬁcient sparse grid ﬁnite element discretization that can be used
even for large dimension d. A typical 2-dimensional sparse grid is depicted in Figure
1 and a 3-dimensional sparse grid in Figure 11(a).

Figure 1: Example of a 2-dimensional sparse grid Dn.

Finite elements on sparse grids are constructed by tensor products of 1-dimensional
ﬁnite elements. Here, we apply piecewise linear elements in 1D. Let us explain the
construction of the sparse grid ﬁnite element space in more detail. To this end, deﬁne
the 1-dimensional grid

Ωk = {2−k−1i | i ∈ Ik},
Ik = {i | i = 1, ..., 2k+1 − 1},

for k ∈ N0, where Ik is the index set of Ωk. Observe that Ω0 ⊂ Ω1 ⊂ Ω2 ⊂ ... . The
complementary index set is deﬁned by

Ξt = It\It−1.

Now, let Vk be the space of piecewise linear functions of mesh size 2−k−1 and vlin
corresponding nodal basis function at point 2−k−1i ∈ Ωk (see Figure 2).

k,i the

3

Figure 2: 1-dimensional nodal basis
functions.

Figure 3: 1-dimensional pre-wavelet
function.

Using these functions, we deﬁne pre-wavelets ϕt,i, i ∈ Ξt by (see Figure 3)



9

9

t,i+2

ϕt,i =

10 vlin
t,i − 3
vlin
10 vlin

t,i − 3
5 vlin
t,i+1 + 1
t,i+1 + vlin
5 (vlin
k,i − 3
5 vlin
for t ∈ N and ϕ0,1 = vlin
orthogonality for pre-wavelets of different levels

10 vlin
t,i−1) + 1
10 vlin

t,i−1 + 1

t,i−2

(cid:90) 1

10 (vlin

t,i+2 + vlin

t,i−2)

if

if

if

1 = i
3 ≤ i ≤ 2t − 3
i = 2t − 1

,

0,1. An important property of these functions is the L2-

ϕt,i ϕt(cid:48),i(cid:48) dx = 0

if t (cid:54)= t(cid:48).

(1)

Let us introduce the following abbreviations for a multi-index t = (t1, ..., td) ∈

0

Nd
0:

d(cid:88)

|t|
t ≤ t(cid:48)
max(t, t(cid:48))
max(t)

:=

|ti|,
ti ≤ t(cid:48)
i ∀i = 1, ..., d,

i=1

if
:= (max(t1, t(cid:48)
:= max(t1, ..., td).

1), ..., max(td, t(cid:48)

d)),

and

Using these abbreviations, the sets of tensor product indices are deﬁned

(cid:110)
(cid:110)

It =

Ξt =

(i1, ..., id)

(ξ1, ..., ξd)

(cid:12)(cid:12)(cid:12) is ∈ Its, s = 1, ..., d
(cid:111)
(cid:12)(cid:12)(cid:12) ξs ∈ Ξts , s = 1, ..., d
(cid:111)

,

4

Figure 4: Example of spaces Wt = W1,1, V full

t = V full

2,1 , and V prewDn

= V prewD3

.

Figure 5: Example of the support of two basis functions that satisfy | max(t, t(cid:48))| > n
and | max(t1, t2)| = |t| ≤ n | max(t(cid:48)

1, t(cid:48)

and the tensor product functions

vlin
t,i(x)

:=

ϕt,i(x)

:=

2)| = |t(cid:48)| ≤ n.
d(cid:89)
d(cid:89)

vlin
ts,is

(xs),

ϕts,is (xs),

s=1

s=1

i ∈ It,

i ∈ Ξ,

where x = (x1, ..., xd). These constructions allow us to deﬁne the tensor product
vector spaces (see Figure 4)

V full
n,d
Vt
Wt
V linDn
V prewDn

(cid:9),

t(cid:48),i

t,i

:= span(cid:8)vlin
:= span(cid:8)vlin
:= span(cid:8)ϕt,i
:= span(cid:8)vlin
:= span(cid:8)ϕt,i
n,d = span(cid:8)vlin

t,i

(cid:9),

(cid:12)(cid:12) max(t) ≤ n, i ∈ Ξt
(cid:12)(cid:12) t(cid:48) ≤ t, i ∈ Ξt(cid:48)(cid:9),
(cid:12)(cid:12) i ∈ Ξt
(cid:12)(cid:12) |t| ≤ n, i ∈ Ξt
(cid:9),
(cid:12)(cid:12) |t| ≤ n, i ∈ Ξt
(cid:9).
(cid:12)(cid:12) i ∈ I(n,...,n)
(cid:9).

Obviously, this results in Wt ⊂ Vt.

can be written as

V full
n,d is the well-known standard space of multilinear ﬁnite element functions which

V full
(n,...,n),i
The sparse grid spaces V linDn
are equal (see [12]). However, the adaptive ver-
sions of these spaces are not equal. For reasons of simplicity, only the non-adaptive

and V prewDn

5

case is dealt with. In case of smooth functions, sparse and full grid have similar ap-
proximation properties

min
v∈V full

n,d

min
prew
Dn

v∈V

(cid:107)u − v(cid:107)H 1 ≤ C2−n(cid:107)u(cid:107)H 2

and

(cid:107)u − v(cid:107)H 1 ≤ C n 2−n

∂2du
1...∂x2
d

∂x2

(cid:13)(cid:13)(cid:13)(cid:13)

(cid:13)(cid:13)(cid:13)(cid:13)L2

,

where C is a constant independent of n and u. However, the dimension of the corre-
sponding spaces is completely different:

dim(V full

n,d) = O(2nd)

and

dim(V prewDn

) = O(nd−12n).

Therefore, the aim of this paper is to ﬁnd an efﬁcient Galerkin discretization of Problem
(1) using the sparse grid space V prewDn
. To this end, the following lemma is an important
observation:
Lemma 1 (Semi-Orthogonality Property) Let κ be constant and A = diag(α1, ..., αd)
a constant diagonal matrix. Then for all indices t, t(cid:48), i ∈ Ξt, and i(cid:48) ∈ Ξt(cid:48) such that
(2)

| max(t, t(cid:48))| > n and |t| ≤ n,

|t(cid:48)| ≤ n

the following equation holds

(cid:90)

Ω

(∇ϕt,i)T A∇ϕt(cid:48),i(cid:48) + κϕt,iϕt(cid:48),i(cid:48) dx = 0.

The consequence of this lemma is that pre-wavelet basis functions with overlapping
support are orthogonal to each other (see Figure 5). This orthogonality property is the
motivation of the following discretization:
Discretization 1 (Semi-Orthogonality) Let f ∈ L2(Ω) and κ ∈ L∞(Ω), κ ≥ 0 be
given. Then, let us deﬁne

a(u, v) :=

(∇u)T A(x)∇v + κ(x)uv dx

(cid:90)

Ω

| max(t, t(cid:48))| ≤ n
| max(t, t(cid:48))| > n

.

if
if

and

asemi-ortho
n

: V prewDn

× V prewDn
(ϕt,i, ϕt(cid:48),i(cid:48))

→ R

:=

asemi-ortho
n
∈ V prewDn

Find uprewDn

such that

(cid:26) a(ϕt,i, ϕt(cid:48),i(cid:48))
(cid:90)

0

Ω

asemi-ortho
n

(uprewDn

, vh) =

f vh dx ∀vh ∈ V prewDn

.

(3)

In [12] we analyzed the convergence of this discretization for the Helmholtz problem
with variable coefﬁcients with respect to the H 1-norm. This paper shows how to obtain
an efﬁcient algorithm for solving the corresponding linear equation.

6

3 Basic Notation
The difﬁculty in explaining sparse grid algorithms is that the matrices in these algo-
rithms are applied to vectors with varying sizes. Thus, describing these matrices in a
mathematical correct form leads to a non-trivial notation. A second problem appears in
the case of adaptive grids. All sparse grid algorithms have a recursive structure using a
tree data structure. Explaining such algorithms in a mathematical and clear notation is
difﬁcult. Therefore, we restrict ourselves to non adaptive sparse grids and assume that
a sparse grid is a union of semi-coarsened full grids.
Furthermore, we introduce a notation that is based on operators on vector spaces
and its dual space. Assume that the ﬁnite element solution ut ∈ Vt ids searched such
that

asemi-ortho
n

(ut, vt) =

f vt dx ∀vt ∈ Vt.

Then ut is contained in the vector space Vt, but the mappings

(cid:90)

Ω

(cid:90)

Ω

v (cid:55)→

f v dx,

v ∈ Vt

v (cid:55)→ asemi-ortho

(w, v),

v ∈ Vt

n

and

are contained in the dual space V (cid:48)
vector, assume that nt is the number of grid points on level t

t . To store elements of Vt or functionals of V (cid:48)

t as a

nt = dim(Vt)

Moreover, assume that the data of a sparse grid algorithm is stored on various suitable
full grids. A corresponding global array is:

:= (Ut)|t|≤n

(cid:126)Un
Ut ∈ Rnt

The vector Ut is used to store data of different mathematical objects. One possibility
is to describe a function in Vt by the vector Ut. Another possibility is to describe a
functional of V (cid:48)

t by Ut. The notation for a corresponding assignment operator is:

and

Some examples are:

Example 1 Let u =(cid:80)
(cid:16)

(cid:16)
(cid:16)

Ut

set←− u

Ut

set←− f

for u ∈ Vt

for f ∈ V (cid:48)

t

(cid:17)
t,i ∈ Vt. Then,

i∈It

ct,ivlin

Ut

set←− u

:⇔ Ut = (ct,i)i∈It.

(cid:17)
(cid:17)

7

Example 2 Let u =(cid:80)

i∈Ξt

(cid:16)

Ut

set←− u

(cid:17)

ct,iϕt,i ∈ Wt ⊂ Vt. Then, we write
if i ∈ Ξt
else.

(cid:18) ct,i

:⇔ Ut =

0

(cid:19)

.

Example 3 Let f ∈ V (cid:48)

t Then, we write

(cid:16)

(cid:17)

Ut

set←− f

:⇔ Ut = (f (vt,i))i∈It.

For describing our algorithms, we introduce a special operator B, which will be
called back construction operator. This operator reconstructs the mathematical object
u which was used to set values in a vector Ut. This implies the following property of
the back construction operator B:

(cid:16)

Ut

set←− u

(cid:17) ⇒ u = B (Ut) .

(cid:16)

(cid:17)

during execution of
Therefore, if Ut was set by u in an assignment
an algorithm, then B reconstructs u in a later execution of this algorithm. Using this
notation, one can describe algorithms without knowing how information on u were
stored in Ut.

Ut

set←− u

4 Basic Operators
The algorithms in this paper are mainly based on well-known one-dimensional opera-
tors. Brieﬂy recall these operators:
1. Prolongation
A prolongation in direction s can be described by

Wt

set←− It (B(Wt−es)) ,

where B(Wt−es) ∈ Vt−es is given and es is the unit vector in direction s. This operator
is described in matrix form

(cco

i )i∈It−es

∈ R|It−es|,

(ci)i∈It ∈ R|It|,

(cid:88)

B(Wt−es ) =
(cid:88)

B(Wt) =

i∈It−es
civt,i.

i∈It

cco
i vt−es,i,

The prolongation in direction s acts on these vectors as follows

(ci)i∈It = M prol

s

(cco

i )i∈It−es

,

M prol

s = ⊗s−1

i=1 Id ⊗ M prol ⊗ ⊗d

i=s+1Id,

(4)

8

where Id is the identity matrix and M prol is the matrix



1

1
2

1
2
1

...

1

1
2

1
2
1



.

M prol =

2. Restriction of the right hand side
A restriction of the right hand side in direction s can be described by

set←− (cid:0)v (cid:55)→ B(Gt)(v), v ∈ Vt−es

(cid:1),

Gt−es

where B(Gt) ∈ V (cid:48)

t is given. To describe the matrix form of this operator let
(gi)i∈It ∈ R|It|,
∈ R|It−es|,

gi = B(Gt)(vt,i), i ∈ It,
gi = B(Gt−es)(vt−es,i), i ∈ It−es,

(gco

i )i∈It−es

The restriction in direction s acts on these vectors as follows

(gco

i )i∈It−es

= M res

s (gi)i∈It,

M res

s = ⊗s−1

i=1 Id ⊗ M res ⊗ ⊗d

i=s+1Id,

(5)

where Id is the identity matrix and M res is the matrix



M res =

1
2

1

1
2

...

1
2

1

1
2
1
2

1

1
2

...

1
2

1

1
2

 .

3. Transformation to pre-wavelets
Let s be a direction such that 1 ≤ s ≤ d. Furthermore, assume that Ut is given such
that B(Ut) ∈ Vt and

• Ut stores the coefﬁcients of B(Ut) in pre-wavelet form or nodal basis form in
the directions ˜d (cid:54)= s, and
• Ut stores the coefﬁcients of B(Ut) in nodal basis form in the direction s.

Now assume that the pre-wavelet coefﬁcients are calculated in direction s with respect
to level ts of B(Ut) and the resulting vector is stored in Ht. The corresponding assign-
ment can be written as

Ht

set←− Qs

t(B(Ut)).

(6)

9

Here Qs

t is the L2 projection operator onto the space

⊗s−1
i=1 Vti ⊗ Wts ⊗ ⊗d
In matrix form, assignment (6) can be written as

i=s+1Vti .

⊗s−1
i=1 Id ⊗ M prew ⊗ ⊗d

i=s+1Id,

where Id are suitable identity matrices and M prew is the matrix of the 1-dimensional
case. To describe the matrix M prew of the 1-dimensional case, let

(ui)i∈It ∈ R|It|,

ui = B(Ut) =

(hi)i∈Ξt ∈ R|Ξt|,

hi = B(Ht) =

(cid:88)
(cid:88)

i∈It

i∈Ξt

vt,i,

ϕt,i,

where t = ts. The matrix M prew performs the following mapping

(hi)i∈Ξt = M prew(ui)i∈It.

Let Rprew be the following restriction operator which takes only the pre-wavelet coef-
ﬁcients:

Rprew ((hi)i∈It)

:= (hi)i∈Ξt.

Then

where M is the matrix

M =



M prew = RprewM−1,

9
10

− 3

5

1
2

1
10

1 − 3

5

1
10

1
2

...
...
...

1
− 3

5

1
10

1 − 3

1
10

5

9
10

1
2

1
2



.

(7)

This means that the assignment (6) has to be implemented by inverting the matrix (7)
in direction s and taking only the resulting pre-wavelet coefﬁcients.
4. Discretization stencil
Let Ut be a given vector on a semi-coarsened full subgrid such that B(Ut) ∈ Vt. Then
an assignment involving the bilinear form of the operator is:

set←− (cid:0)v (cid:55)→ a(B(Ut), v), v ∈ Vt

(cid:1).

Zt

10

Obviously, the computation corresponding to this assignment requires a 9-point-stencil
in the 2-dimensional case and a 27-point-stencil in the 3-dimensional case. As an
example, for meshsize h = hx = hy in x-direction and y-direction this stencil is

1
h2

where

 ,

 −1 −1 −1
(cid:90)

−1
8 −1
−1 −1 −1

a(u, v) =

Ω

∇u∇v d(x, y).

5 Calculation of pre-wavelet coefﬁcients
Let (Ft)|t ≤n be a function evaluated on the sparse grid of depth n such that Ft =
where xt,i is the grid point on level t with index i. Algorithm ?? cal-
(f (xt,i))i∈It
culates the pre-wavelet decomposition with coefﬁcients (Ct)|t|≤n = (ct,i)|t|≤n,i∈It
given by

f (xt,i) =

ct,iϕt,i (xt,i)

(8)

(cid:88)

|t|≤n,i∈It

for every sparse grid point xt,i ∈ Dn, where Dn is the sparse grid of depth n.

The calculation of the wavelet coefﬁcients works recursively through all the dimen-
sions. For this purpose, the coefﬁcients of the highest dimension are calculated ﬁrst,
starting from the grid with maximum depth down to the coarsest grid. After this, the
algorithm continues with lower dimensions.
The calculation of the pre-wavelet coefﬁcients on depth t in one dimension requires
to solve a system of linear equations with 2t+1 +1 unknowns. The inverse matrix M−1
can efﬁciently be computed using an LU decomposition since M is a band matrix with
bandwidth 3 (see Equation (7)).
Now, let us explain the basic idea of the algorithm for dimension 0 ≤ ˜d < d on
level t ˜d. First, it calculates the pre-wavelet decomposition. Then, the local hierarchical
surplus is subtracted from all low order levels ˜t ˜d < t ˜d. In the case of sparse grids, this
requires the interpolation of the the hierarchical surplus for grids which have no direct
predecessor. To this end, the combination technique is applied to all direct neighbors
in directions with the dimension larger than ˜d.

The same algorithm is used in reverse order to calculate a point-wise evaluation
for a given set of pre-wavelet coefﬁcients (Ct)|t|≤n. Algorithm
Ft = (f (xt,i))i∈It
?? starts on the coarsest level of the smallest dimension and accumulates the surpluses
over all dimensions.

Observe that in Algorithm ?? and Algorithm ?? U ¯d(t) is the upper part of t:

U ¯d(t) = (t ¯d+1, t ¯d+2, ..., td).

11

Input: Let (cid:126)Un = (Ut)|t|≤n be given in nodal format.

Call PRE-WAVELET ALGORITHM ( (cid:126)Un, d).

Output: (cid:126)Un in pre-wavelet format until dimension ¯d.

Function PRE-WAVELET ALGORITHM ( (cid:126)Um := (Ut)|t| ¯d≤m,U ¯d(t)=tu

iterate for ¯t = m, ..., 0 {

, ¯d) {

1. Calculate pre-wavelet coefﬁcients in direction ¯d:
for every t with t ¯d = ¯t and U ¯d(t) = tu do:

set←− Q ¯d

t (B(Ut))

Ut
Wt = Ut

2. Subtract interpolated pre-wavelets on coarse grid
iterate for t(cid:48) = ¯t, ..., 1 {
2.1 for every t with t ¯d = t(cid:48) and U ¯d(t) = tu do:

(B(Wt))

t−e ¯d

set←− I ¯d
set←− B(Ut−e ¯d ) − (B(Wt−e ¯d ))

Wt−e ¯d
Ut−e ¯d
for every t with |t| ¯d = m and t ¯d = t(cid:48) − 1 and U ¯d(t) = tu do:

2.2 if ¯d > 1 then {

set←− (cid:80)

(−1)|α|+1It(B(Wt−α))

)∈{0,1} ¯d−1∧

(α1 ,...,α ¯d−1
,...,αd )=(0,...,0)∧α(cid:54)=(0,...,0)

set←− B(Ut) − B(Wt)

(α ¯d

Deﬁne mlow := m − ¯t. Deﬁne (cid:126)U low
If mlow > 0 call PRE-WAVELET ALGORITHM ( (cid:126)U low

mlow := (Ut)|t| ¯d−1≤mlow,t ¯d=¯t,U ¯d(t)=tu

mlow, ¯d − 1)

Wt

Ut

}

}
3. Recursion
if ¯d > 1 then {

}

}

}
End of Algorithm.

12

Input: Let (cid:126)Un = (Ut)|t|≤n be given in pre-wavelet format.

Call BACK PRE-WAVELET ALGORITHM ( (cid:126)Un, d).

Output: (cid:126)Un in nodal format until dimension ¯d.

Function BACK PRE-WAVELET ALGORITHM ( (cid:126)Um := (Ut)|t| ¯d≤m,U ¯d(t)=tu

, ¯d) {

iterate for ¯t = 0, ..., m {

1. Recursion
if ¯d > 1 then {

Deﬁne mlow := m − ¯t. Deﬁne (cid:126)U low
If mlow > 0 call BACK PRE-WAVELET ALGORITHM ( (cid:126)U low

mlow := (Ut)|t| ¯d−1≤mlow,t ¯d=¯t,U ¯d(t)=tu
mlow, ¯d − 1)

}
2. Transform back in direction ¯d:
if ¯t > 0 then {

for every t with t ¯d = ¯t and U ¯d(t) = tu do:

Wt
Ut

set←− It(B(Ut))
set←− B(Wt) + I ¯d

t (B(Ut−e ¯d ))

}
3. Add interpolated pre-wavelets on coarse grid
iterate for t(cid:48) = ¯t, ..., 1 {

3.1. for every t with t ¯d = t(cid:48) and U ¯d(t) = tu do:

(B(Wt))

t−e ¯d

set←− I ¯d
set←− B(Ut−e ¯d ) + (B(Wt−e ¯d ))
3.2. if ¯d > 1 then {

Wt−e ¯d
Ut−e ¯d
for every t with |t| ¯d = m and t ¯d = t(cid:48) − 1 and U ¯d(t) = tu do:

set←− (cid:80)

(−1)|α|+1It(B(Wt−α))

(α1,...,α ¯d−1)∈{0,1} ¯d−1∧

(α ¯d ,...,αd )=(0,...,0)∧α(cid:54)=(0,...,0)

set←− B(Ut) + B(Wt)

Wt

Ut

}

}

}

}
End of Algorithm.

13

(a) (pro, pro)

(b) (pro, res)

(c) (res, pro)

(d) (res, res)

(e) Splitting

Figure 6: Matrix vector multiplication on sparse grids in the 2-dimensional case. a) -
d) Calculation of part P = {1, 2}, P = {1}, P = {2}, P = ∅. e) Summation of the
result of the 4 parts.

6 Matrix multiplication
Let

(cid:16)

An =

asemi-ortho
n

(cid:17)

(ϕt,i, ϕt(cid:48),i(cid:48))

.

|t|≤n,i∈Ξt
|t(cid:48)|≤n,i(cid:48)∈Ξ
t(cid:48)

(9)

be the stiffness matrix of Discretization 1. The main difﬁculty is to construct an al-
gorithm that efﬁciently evaluates a matrix vector multiplication with matrix An. To
construct such an algorithm, the notation introduced in Section 3 is applied. The fol-
lowing recursive algorithm is obtained:

To explain the concept of this algorithm, start with a 1-dimensional observation.

Assume that the following pre-wavelet decomposition is given:

n(cid:88)

t(cid:48)=1

(cid:88)

t(cid:48)>t

(cid:88)
(cid:88)

i∈Ξt(cid:48)

t(cid:48)≤t

u =

wt(cid:48) where wt(cid:48) =

ct(cid:48),iϕt(cid:48),i.

Then, we can split the matrix vector multiplication in two parts:

a(u, vt) =

a(wt(cid:48), vt) + a(

wt(cid:48), vt).

Algorithm ?? calculates these two parts separately. We call these two parts restriction
part and prolongation part.

t(cid:48)>t a(wt(cid:48), vt) is calculated in the function SPARSE GRID
MATRIX MULTIPLICATION with input parameter D = 1. The essential calculations
are done in Step 3.2 and Step 1. The recursive call of the algorithm applies the dis-
cretization stencil on Ht (see Step 1) ﬁrst and then performs several restrictions (see
Step 3.2).

The restriction part(cid:80)
The prolongation part a((cid:80)

t(cid:48)≤t wt(cid:48), vt) is calculated in the function SPARSE GRID
MATRIX MULTIPLICATION with input parameter D = 0. Here the essential calcula-
tions are done in Step 2.2 and Step 1. First Ht is prolongated on ﬁner grids (see Step
2.2) and then the discretization stencil is applied (see Step 1).
The d-dimensional case is a combination of these two cases in all dimensional
directions. In each direction 1 ≤ ¯d ≤ d, we either can perform a restriction or prolon-
gation. All directions corresponding to restrictions are denoted by

R ⊂ {1, ..., d}.

14

Input: Let (cid:126)Un = (Ut)|t|≤n be given in pre-wavelet format.

Ft
for every R ⊂ {1, 2, ..., d} do {

set←− 0 ∀t
Reorder the directions 1, ..., d such that R = {1, 2, ..., D},
(cid:126)Hn := (Ht)|t|≤n = (cid:126)Un
Call SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)Hn, d,D).

}

0 ≤ D ≤ d.

Output: (cid:126)Fn in complete pre-wavelet format.
Function SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)Hm := (Ht)|t| ¯d≤m,U ¯d(t)=tu
if ( ¯d == 0) { // 1. Deepest point of recursion

set←− (cid:0)v (cid:55)→ a(B(Ht), v), v ∈ Vt

(cid:1)

if (D == d) doZt
else
Zt
Ft

set←− B(Ft) +(cid:0)ϕ (cid:55)→ B(Zt)(ϕ), ϕ ∈ Wt

set←− B(Gt)

} else if ¯d > D { // 2. Interpolate from coarser grids

(cid:1)

2.1. Recursive call on coarsest grid.

, ¯d , D)

Deﬁne (cid:126)H low
call SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)H low

m := (Ht)|t| ¯d−1≤m,t ¯d=0,U ¯d(t)=tu

m , ¯d − 1, D)

iterate for ¯t = 1, ..., m {

Ht

set←− I ¯d

2.2. Prolongate in direction ¯d
for every t with t ¯d = ¯t and U ¯d(t) = tu do
t (B(Ht−e ¯d ))
t (B(Ht)) + I ¯d
2.3. Recursive call on ﬁner grids.
Deﬁne mlow := m − ¯t. Deﬁne (cid:126)H low
if mlow > 0 call SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)H low

mlow := (Ht)|t| ¯d−1≤m,t ¯d=¯t,U ¯d(t)=tu

mlow, ¯d − 1, D)

}

} else if ¯d ≤ D { // 3. Restrict ﬁne pre-wavelet functions

3.1. Recursive call on ﬁnest grid.

set←− 0 ∀t, t ¯d = m,U ¯d(t) = tu

Gt
Deﬁne (cid:126)H low
call SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)H low

:= (Ht)|t| ¯d−1=0,t ¯d=m,U ¯d(t)=tu

0

iterate for ¯t = m − 1, ..., 0 {
3.2. Restrict right hand side.
for every t with t ¯d = ¯t + 1 and U ¯d(t) = tu do:

set←− It(B(Ht))

set←− (cid:0)v (cid:55)→ B(Gt)(v) + a(B(Qt), v), v ∈ Vt−e ¯d

Qt
Gt−e ¯d

0

(cid:1)

, ¯d − 1, D)

Deﬁne mlow := m − ¯t. Deﬁne (cid:126)H low
if mlow > 0 call SPARSE GRID MATRIX MULTIPLICATION ( (cid:126)H low

mlow := (Ht)|t| ¯d−1≤mlow,t ¯d=¯t,U ¯d(t)=tu

mlow, ¯d − 1, D)

} }
End of Algorithm.

15

Now, the recursive structure of Algorithm ?? can be explained. Assume that u is given
in the following form

u =

wt(cid:48),

where wt(cid:48) =

ϕt,ict,i.

(cid:88)

i∈Ξt

This form corresponds to a decomposition of u in its pre-wavelets. Then a short calcu-
lation shows:

(cid:88)

(cid:88)

(cid:88)

a

(cid:88)

 .

a(u, ϕt,i) =

wt(cid:48), ϕt,i

(10)

R⊂{1,2,...,d}

s∈R

t(cid:48)
s>ts

s(cid:54)∈R

s≤ts
t(cid:48)

(cid:88)

|t(cid:48)|≤n

(cid:88)

In the 2-dimensional case this sum leads to 4 parts:

a(u, ϕ(t1,t2),(i1,i2)) =

1,t(cid:48)

2), ϕ(t1,t2),(i1,i2)

(cid:88)

a(cid:0)w(t(cid:48)

t(cid:48)
1>t1, t(cid:48)

2>t2

(cid:88)
(cid:88)
 (cid:88)

a

2≤t2
t(cid:48)

t(cid:48)
1>t1

1≤t1, t(cid:48)
t(cid:48)

2≤t2

+

w(t(cid:48)

1,t(cid:48)

2), ϕ(t1,t2),(i1,i2)

+ a

w(t(cid:48)

1,t(cid:48)

2), ϕ(t1,t2),(i1,i2)

(cid:1)
(cid:88)

1≤t1
t(cid:48)

(cid:88)

t(cid:48)
2>t2

a

 +
 .



w(t(cid:48)

1,t(cid:48)

2), ϕ(t1,t2),(i1,i2)

Figure 6 depicts the calculation of these four parts.

The d-dimensional case (10) consists of 2d cases. Each is calculated by calling
the function SPARSE GRID MATRIX MULTIPLICATION with input parameter d and D.
Here D is the number of restriction directions. In order to simplify the notation, the
restriction directions are reordered such that

R = {1, . . . , D}.

However, this is only a notational trick. An actual implementation of the algorithm
should not perform such a reordering.

Observe that the recursive structure of Algorithm ?? leads to the following sequen-

tial calculations

1. Prolongation in directions D + 1, . . . , d. This is depicted in Figure 7.

2. Application of discretization stencil on level t in Step 1.

3. Restriction in direction 1, . . . , D.

Now, two important question are:

Does Algorithm ?? correctly calculate a matrix vector multiplication?

How is semi-orthogonality involved in this algorithm?

16

(a) 2D

(b) 3D

Figure 7: Prolongation step. 7(a): 2-dimensional case. 7(b): 3-dimensional case.

To answer this question, restrict to the 2-dimensional case and the computation of the
part

 .

w(t(cid:48)

1,t(cid:48)

2), ϕ(t1,t2),(i1,i2)

(cid:88)

2≤t2
t(cid:48)

a

(cid:88)

t(cid:48)
1>t1

This means that D = 1 and d = 2. Obviously, the whole algorithm would be cor-
rect, if we would prolongate all data to a full grid, apply the discretization stencil
and then perform restrictions. Such a prolongation restriction scheme is depicted in
Figure 8(a). Yet, this would lead to a computational inefﬁcient algorithm since it re-
quires to perform computations on the complete full grid. Instead all computations
are omitted which are not needed due to the semi-orthogonality property. To explain
this in more detail, consider two overlapping basis functions as in Figure 8(d). Com-
putations along the algorithmic path depicted in Figure 8(c) are needed to take into
account the corresponding value in the stiffness matrix asemi-ortho
(ϕt,i, ϕt(cid:48),i(cid:48)). How-
ever, by using semi-orthogonality property the result of these computations is zero.
Therefore, this algorithmic path can be omitted. This shows that the remaining algo-
rithmic paths depicted in Figure 8(b) are enough for obtaining a correct computation.
This proves that Algorithm ?? correctly calculates a matrix vector multiplication using
semi-orthogonality.

n

7 The complete iterative solver
Discretization 1 leads to the linear equation system
An (cid:126)U = M (cid:126)F ,

(11)

17

(a) full grid

(b) sparse grid

(c) missing path

(d) semi-orthogonality

Figure 8: Prolongation-restriction in 2d on a sparse grid ignores the overlapping of t
and t(cid:48). Calculation would require a path over the full grid but can be ignored due to
semi-orthogonality.

18

Figure 9: Preconditioned CG-solver using pre-wavelet decomposition.

where An is the stiffness matrix (9), M the mass matrix, (cid:126)F the right hand side in
pre-wavelet format, and (cid:126)U the solution vector in pre-wavelet format. By using the
orthogonality property (1), M is reduced to a diagonal matrix.
For solving (11), the conjugate gradient with a simple diagonal Jacobi precoditioner
is applied. The condition number of An, including this simple preconditioner, is O(1).
This follows from the multilevel theory in [8] and the following equivalence of norms:

(cid:88)

|t|≤n,i∈Ξt

|ct,i|2 a(ϕt,i, ϕt,i),

(cid:107)u(cid:107)2

H 1 ∼=

where u =(cid:80)|t|≤n,i∈Ξt

ct,iϕt,i

Algorithm ?? is used to calculate the right hand side vector (cid:126)F for a given right hand
side vector (f (p))p∈Dn. The conjugate gradient algorithm requires the application
the stiffness matrix multiplication Algorithm ??. The resulting vector (cid:126)U applied to
Algorithm ?? leads to an approximation of the ﬁnite element solution uprewDn
of
Discretization 1. The total algorithm is depicted in Figure 9.

∈ V prewDn

8 Numerical results

To show the efﬁciency of the discretization in this paper, two numerical results are
presented. The ﬁrst example shows that sparse grids can be used to discretize elliptic
partial differential equations on curvilinear bounded domains in 3D. The second exam-
ple is a 6-dimensional Helmholtz problem with a variable coefﬁcient. To our knowl-
edge, this is the ﬁrst Ritz-Galerkin ﬁnite element discretization of an elliptic PDE with
variable coefﬁcients in a high dimensional space.

In this paper the discretization stencils were obtained by analytic calculations. If
this is not possible, then one has to interpolate the variable coefﬁcients by a piecewise
constant interpolation of the variable coefﬁcients on the sparse grid as in [13]. How-
ever, this paper was restricted to analytic calculation of the 27-stencils and 729-stencils.
The simulation results were obtained on a workstation without parallel computing.

The algorithms were implemented in C++ programming language.

19

(a) error in L2-norm

(b) error in L∞-norm

Figure 10: Convergence of the error norm measured by L2 (a) and L∞ (b).

8.1 Poisson’s equation
We want to show that sparse grids can be applied to discretize partial differential equa-
tions on curvilinear bounded domains. To this end consider Poisson’s equation

− ∆u = f in Ω ⊂ R3

u = g on ∂Ω.

(12)

In order to discretize this problem on a curvilinear bounded domain, one has to subdi-
vide the domain Ω into several blocks, such that each of these blocks can smoothly be
transformed to a unit cube. By these transformations to a unit cube, one obtains partial
differential equations with variable coefﬁcients on the unit cube. The basic idea of this
concept is explained in [13, 14] for 2-dimensional domains. To show that this concept
can be extended to a 3-dimensional domain, it is applied to the curvilinear bounded
domain depicted in Figure 11(b). Simulation results are compared with simulations
obtained on a simple cubical domain [0, 1]3 (see Figure 11(a)). Right hand side f and
inhomogeneous Dirichlet boundary condition g are chosen such that

u = sin (xπ) sin (yπ) sin (zπ)

is the exact solution of (12). The curvilinear bounded domain is obtained by the trans-
formation of the x-coordinate according:

˜x = x + sin (yπ) − 1
2

.

This analytic transformation allows an analytic calculation of the 27-stencils on each
subgrid of the sparse grid.
the ﬁnite el-
ement discretization (3) on the sparse grid Dn of depth n. Furthermore, let en,∞ =

Now, let u be the exact solution of Poisson’s problem (12) and uprewDn

20

 1e-05 0.0001 0.001 0.01 0.1 10 100 1000 10000 100000degrees of freedomunit cubecurved domain 1e-05 0.0001 0.001 0.01 0.1 1 10 100 1000 10000 100000degrees of freedomunit cubecurved domain(cid:107)∞ be the error in the maximum norm and en,2 = (cid:107)u − uprewDn

(cid:107)u − uprewDn
(cid:107)2 the error
in a suitable weighted discrete L2-norm such that a constant error has an equally error
norm with respect to the discrete L2-norm. Table 1, Table 2, and Figure 10 show that
the discretization with semi-orthogonality and prewavelets leads to an optimal conver-
gence according the approximation properties of sparse grids. Moreover, the condition
number of the stiffness matrix using a simple diagonal preconditioner stays below 10
for n = 2, ..., 9 (see Table 3). Therefore, only a few cg-iterations are needed to obtain
a small algebraic error.

curved domain
en,∞

en,∞

en−1,∞

tmax
2
3
4
5
6
7
8
9

DOF
7
31
111
351
1023
2815
7423
18943

unit cube

en,∞

1.4131 × 10−1
7.8379 × 10−2
3.0813 × 10−2
1.0418 × 10−2
3.2704 × 10−3
9.8289 × 10−4
2.9844 × 10−4
8.8898 × 10−5

en,∞

en−1,∞

1.80
2.54
2.96
3.19
3.33
3.29
3.36

1.4131 × 10−1
1.3066 × 10−1
8.2763 × 10−2
2.6655 × 10−2
8.9742 × 10−3
2.6322 × 10−3
7.9659 × 10−4
2.3461 × 10−4

Table 1: L∞-norm of discretization error.

2.06
1.58
3.10
2.97
3.41
3.31
3.40

1.78
2.02
2.68
3.03
3.16
3.23
3.29

curved domain
en,2

en,2

en−1,2

tmax
2
3
4
5
6
7
8
9

DOF
7
31
111
351
1023
2815
7423
18943

en,2

unit cube
2.0150 × 10−2
1.1328 × 10−2
5.0768 × 10−3
1.9677 × 10−3
6.9732 × 10−4
2.3303 × 10−4
7.4714 × 10−5
2.3233 × 10−5

en,2

en−1,2

1.78
2.23
2.58
2.82
3.00
3.12
3.22

4.8651 × 10−2
2.7337 × 10−2
1.3524 × 10−2
5.0468 × 10−3
1.6640 × 10−3
5.2647 × 10−4
1.6289 × 10−4
4.9463 × 10−5

Table 2: L2-norm of discretization error.

8.2 Helmholtz equation with variable coefﬁcients in high dimen-

sions

Consider the 6-dimensional Helmholtz problem

− ∆u + cu = f in Ω := [0, 1]6

u = 0 on ∂Ω

(13)

21

κ(cid:0)C T AC(cid:1)

unit cube

curved domain

κ(cid:0)C T AC(cid:1)

tmax
2
3
4
5
6
7
8
9

DOF
7
31
111
351
1023
2815
7423
18943

κ (A)
2.96
8.48
18.82
48.57
126.90
207.40
267.92
283.70

κ (A)
4.47
23.54
64.25
121.38
179.78
232.33
270.43
306.03

1.62
2.42
3.87
4.40
4.59
5.05
5.10
5.46

2.18
3.25
3.91
4.49
4.99
5.06
5.43
5.95

Table 3: Condition number of pre-wavelet discretization and diagonal preconditioning.

with variable coefﬁcient

c (x, y, z, u, v, w) :=

(cid:0)1 − x2(cid:1)(cid:0)1 − y2(cid:1)(cid:0)1 − z2(cid:1)(cid:0)1 − u2(cid:1)(cid:0)1 − v2(cid:1)(cid:0)1 − w2(cid:1) .

(14)

The right hand side f is chosen such that

u = sin (xπ) sin (yπ) sin (zπ) sin (uπ) sin (vπ) sin (wπ)

is a solution of (13).

Table 4 shows the discretization error for constant coefﬁcients (c = 1) as well as for
the variable coefﬁcient (14). The convergence rate for the problem with constant coef-
ﬁcients is similar to the reported convergence behavior in [1]. In addition, the solution
of the discretization with semi-orthogonality and prewavelets convergences in case of
variable coefﬁcients is as fast as in case of constant coefﬁcients. This shows that the
discretization with semi-orthogonality does not introduce any remarkable additional
errors.

constant coefﬁcient

en,∞

en−1,∞

variable coefﬁcient
en,∞

en−1,∞

tmax
2
3
4
5
6

DOF
13
97
545
2561
10625

en,∞
0.40427
0.28396
0.10686
0.04028
0.01533

en,∞
0.391625
0.282802
0.106861
0.040046
0.015328

1.42
2.65
2.65
2.62

1.38
2.64
2.66
2.61

Table 4: Error convergence for a 6-dimensional Helmholtz problem.

9 Acknowledgment
The authors gratefully acknowledge funding of the Erlangen Graduate School in Ad-
vanced Optical Technologies (SAOT) by the German Research Foundation (DFG) in
the framework of the German excellence initiative.

22

(a) unit cube

(b) curved edges

Figure 11: Sparse grid with depth n = 7 on 3-dimensional unit cube (a) and domain
with curved edges (b).

References
[1] Zenger C. Sparse grids. Parallel Algorithms for Partial Differential Equations,
Proceedings of the Sixth GAMM-Seminar, Kiel, 1990, Notes on Num. Fluid
Mech., vol. 31, Hackbusch W (ed.), Vieweg, 1991.

[2] Bungartz HJ. D¨unne Gitter und deren Anwendung bei der adaptiven L¨osung
der dreidimensionalen Poisson-Gleichung. Dissertation, Fakult¨at f¨ur Informatik,
Technische Universit¨at M¨unchen Nov 1992. URL http://www5.in.tum.
de/pub/bungartz92duenne.pdf.

[3] Balder R, Zenger C. The Solution of Multidimensional Real Helmholtz Equations

of Sparse Grids. SIAM J. Sci. Comp. 1996; 17(3):631–646.

[4] Pﬂaum C. A Multilevel Algorithm for the Solution of Second Order Elliptic Dif-

ferential Equations on Sparse Grids. Numer. Math. 1998; 79:141–155.

[5] Pﬂaum C. Diskretisierung elliptischer Differentialgleichungen mit d¨unnen Git-

tern. Dissertation, Technische Universit¨at M¨unchen 1995.

23

[6] Achatz S. Higher Order Sparse Grid Methods for Elliptic Partial Differential

Equations with Variable Coefﬁcients. Computing 2003; 71(1):1–15.

[7] Griebel M. Adaptive Sparse Grid Multilevel Methods for Elliptic PDEs Based on

Finite Differences. Computing 1998; 61:151–179.

[8] Oswald P. Multilevel Finite Element Approximation. Teubner Skripten zur Nu-

merik, Teubner, Stuttgart, 1994.

[9] Barinka A, Barsch T, Charton P, Cohen A, Dahlke S, Dahmen W, Urban K. Adap-
tive Wavelet Schemes for Elliptic Problems—Implementation and Numerical Ex-
periments. SIAM J. Sci. Comput. 2002; 23(3):910–939.

[10] Vassilevski PS, Wang J. Stabilizing the Hierarchical Basis by Approximate
Wavelets II: Implementation and Numerical Results. SIAM J. Sci. Comput. 1998;
20(2):490–514.

[11] Pﬂaum C. Robust Convergence of Multilevel Algorithms for Convection-

Diffusion Equations. SIAM J. Numer. Anal. 2000; 37(2):443–469.

[12] Pﬂaum C, Hartmann R. A Sparse Grid Discretization of Helmholtz Equation with
Variable Coefﬁcient in High Dimensions. SIAM J. Numer. Anal. 2015; Submitted.

[13] Dornseifer T, Pﬂaum C. Discretization of Elliptic Differential Equations on
Curvilinear Bounded Domains with Sparse Grids. Computing 1996; 56(3):197–
213.

[14] Gordon WJ, Hall CA. Construction of curvilinear co-ordinate systems and ap-
plications to mesh generation. International Journal for Numerical Methods in
Engineering 1973; 7(4):461–477, doi:10.1002/nme.1620070405. URL http:
//dx.doi.org/10.1002/nme.1620070405.

24

