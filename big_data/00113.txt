6
1
0
2

 
r
a

M
1

 

 
 
]
S
D
h
t
a
m

.

[
 
 

1
v
3
1
1
0
0

.

3
0
6
1
:
v
i
X
r
a

Directed Self-Assembly of Linear Nanostructures
by Optimal Control of External Electrical Fields

Arash Komaee and Paul I. Barton

1

Abstract—An optimal control strategy is developed to construct
nanostructures of desired geometry along line segments by means
of directed self-assembly of charged particles. Such a control
strategy determines the electric potentials of a set of electrodes
located at ﬁxed points in the line segment. The particles move
under the electric forces generated by these electrodes and by the
interactions between the particles themselves to form a desired
pattern eventually. Due to technology limitations, the particle
positions cannot be measured during the course of control, so
that the control is open-loop in nature. Such an open-loop control
optimally changes the electrode potentials in time in order to
create a desired pattern with the highest probability, despite the
inherent uncertainty in the initial positions and the dynamical
behaviors of the particles. Two models are proposed to describe
the uncertain dynamics of the particles: a continuous model
relying on a set of nonlinear stochastic differential equations,
and a discrete Ising model consisting of a large dimensional
continuous-time Markov chain. While the ﬁrst model is more
mathematically tractable, the second one more precisely describes
particles at the nanometer scale. The control design procedure
begins with the continuous model and identiﬁes the structure of
its stable equilibria, which is used later to propose a piecewise
constant structure for the control and to demonstrate that the
optimal value of each piece is independently obtained from a
certain static optimization problem. It is shown next that the
design procedure can be applied to the discrete model with only
minor modiﬁcations. A numerical example of control design is
presented.

Index Terms—Directed self-assembly, Fokker-Planck equation,

Ising model, nanostructure, optimal control.

I. INTRODUCTION

Self-assembly is the process of forming an ordered structure
from initially disordered components that only interact locally,
without external direction. At the molecular level, this process
is a common technique for fabrication of nanostructures with
periodic patterns [1]–[10]. Due to the important role of this
fabrication technique in nanotechnology, several researchers
have studied self-assembly phenomena at a theoretical level
based on abstract models [11]–[18].

Self-assembled nanostructures usually demonstrate periodic
patterns that only depend on the nature of their components
and the environmental conditions under which the patterns are
formed. However, several applications require fabrication of
nanostructures with certain non-periodic geometries [19]–[24].
Given the major role of molecular self-assembly in fabrication

This work was supported by the National Science Foundation under Grant

No. CBET-1033533.

A. Komaee was with the Department of Chemical Engineering, Mas-
sachusetts Institute of Technology, Cambridge, MA 02139, USA. He is now
with the Department of Electrical and Computer Engineering, Southern Illinois
University, Carbondale, IL 62901, USA (e-mail: akomaee@siu.edu).

P. I. Barton is with the Department of Chemical Engineering, Massachusetts
Institute of Technology, Cambridge, MA 02139, USA (e-mail: pib@mit.edu).

of periodic nanostructures, it is reasonable to ask if this process
can be externally directed to fabricate nanostructures of desired
geometry which are not necessarily periodic. Such a directed
self-assembly process is the focus of this paper.

In directed self-assembly, a number of charged nanoparticles
(e.g., DNA tiles) are manipulated by external electrical ﬁelds
to form a nanostructure of desired geometry. The directing
electrical ﬁelds are generated and controlled by relatively small
number of electrodes (compared to the number of particles)
located at ﬁxed locations on the substrate containing the parti-
cles. The dynamics of the particles are primarily governed by
the interactions between them (self-assembly), and is modiﬁed
to some extent by manipulation of the electrical potentials of
these electrodes (external direction). The particles are initially
distributed randomly on the substrate and are perturbed by
random disturbances during the assembly process. Since the
particle positions cannot be measured during the course of con-
trol, a feedback loop cannot be established and the electrodes
are actuated only by open-loop controls.

The control objective is to direct

the particles towards
formation of a desired pattern despite the uncertainty in their
dynamics and initial positions. Under an optimal design, this
control must maximize the probability of forming the desired
pattern by the end of the assembly process, and maintain the
formed structure under a static control afterward. Such a con-
stant static control creates a stable equilibrium representing the
desired pattern. In addition to this intended stable equilibrium,
the static control inherently creates multiple undesired stable
equilibria, and a major challenge of an optimal control is to
prevent the system falling into such kinetic traps. Given the
large number of these kinetic traps and the inherent uncertainty
in the initial distribution and dynamics of the particles, the
system will most likely be trapped by an undesired stable
equilibrium (formation of a wrong pattern), unless a phase
of dynamic control (time-dependent) is applied prior to the
static control.

This paper intends to develop an analytic framework for
study of directed self-assembly, including a systematic method
for control design. Rather than focusing on a detailed model
of the physical process, the main emphasis is on providing a
clear understanding of the fundamental concepts such as static
control, kinetic traps, and dynamic control. To be consistent
with this approach, the models and control problem considered
in this paper are abstractions of real-world directed self-
assembly: they capture the essence of this phenomenon but
do not reﬂect all its details. In particular, the paper focuses on
directed self-assembly of linear structures (one-dimensional
patterns along straight lines), a simpliﬁed model also adopted
in [12], [17] to study “undirected” self-assembly. This special

case of the more general planar patterns demonstrates certain
properties that facilitate exact characterization of the stable
equilibria of the system, which in turn, allows for a rigorous
analysis and control design methodology. The concepts and
methods developed here for linear patterns are equally valid in
two dimensions, while generalization of some computational
procedures might not be immediate. Such a generalization, at
least approximately, is the subject of our future work.

This paper adopts two different but closely related models
to describe directed self-assembly. A continuous model is
presented in Section II which allows the particles to position
continuously at any arbitrary point in a line segment. This
model is precise for larger particles of micrometer diameter
and its continuous nature facilitates our analysis in Section III.
Later in Section IV, a discrete model is presented for nano-
scale particles, and it is shown how the results of Section III,
originally developed for the continuous model, can be tailored
to this discrete model only with minor modiﬁcations. Our main
results on the structure of the kinetic traps, control design, and
optimization of the electrodes are presented in Section III.

II. MODEL AND PROBLEM STATEMENT

The system of particles considered in this paper is described
at the nano-scale (∼ 10nm) by a discrete Ising model and a
master equation [25]–[27]. In this model, the particles can
occupy only a ﬁnite set of positions along a line segment,
in contrast to a continuous model used for larger particles
(∼ 1µm) in which the particles can position continuously at
any arbitrary point along the line segment. The latter model
is directly derived from the classical Newton’s second law
of motion, and Coulomb’s law that governs the interactions
between the particles and the forces applied to the particles
by the electrodes. Such a continuous model is more intuitive
and mathematically more tractable, thus it is a convenient
point of departure to explain the concepts and control design
methodology developed in this paper. We begin with this
continuous model and construct our control design method
on this basis. Later in Section IV, we present the discrete
model and show that for the purpose of control design using
our proposed method, the two models are mathematically
equivalent and can be interchanged with minor modiﬁcations.
In particular, our control design relies on the steady-state
behaviors of these models which match closely despite their
different dynamical behaviors. It is emphasized that the two
models describe different physical phenomena and they are
not necessarily interchangeable for other purposes such as
simulations.

Throughout this paper, the time-dependent state and control
vectors are shown by the boldface letters x and u, so that
x and u are mappings from time into the state space and the
control set, respectively. The values of the state and the control
vectors at time t are denoted by x (t) and u (t) or simply by x
and u as a shorthand. All constant vectors and other functions
of time or other variables are shown in plain letters.

Referring to Fig. 1, consider a line segment and assume that

c + 1 electrodes are located at the ﬁxed points

0 = q0 < q1 < ··· < qc

2

in this line segment. Suppose that n identical charged particles
are located between q0 and qc at the points x1, x2, . . . , xn. The
particle positions specify the state vector x = (x1, x2, . . . , xn)
in Rn. The control vector u = (u0, u1, u2, . . . , uc) is deﬁned
in such a manner that its kth component uk represents the
electric charge of the electrode k = 0, 1, , . . . , c normalized to
the charge of a single particle. It is assumed that at any time,
the value of the control vector u can be arbitrarily chosen
within the control set U ⊂ Rc+1.

q0

x1

x2 x3

q1

x4

x5

q2

. . . . . .

qc−1

xn−1

xn

qc

Fig. 1. Geometry of the charged particles and the control electrodes along a
line segment. The disks represent the particles while the boxes stand for the
electrodes.

The total energy associated with the state x of the particles
and the control value u is given by κV (x, u), where the
normalized energy function V : Rn × Rc+1 → R is given by
(1)

V (x, u) =

uj

+

1

n

.

c

Xi=1

Xj=0

|xi − qj|

1
2

n

n

Xi=1

Xj=1

j6=i

|xi − xj|

Here, κ > 0 is a constant deﬁned as

κ =

e2

4πε0ε

,

where e denotes the charge of a single particle, ε0 stands for
the permittivity of free space, and the dimensionless constant ε
is the relative permittivity of the environment containing the
particles. The negative gradient −κ∇xV (x, u) of the total
energy (∇x denotes the gradient operator with respect to the
ﬁrst argument) is a vector in Rn whose kth component is the
total force applied to the kth particle by the remaining n − 1
particles (ﬁrst term on the right-hand side of (1)) and by the
c + 1 electrodes (second term on the right-hand side of (1)).
Assume that the particles start from the initial state x0 at
time t = 0 and their state x (t) ∈ Rn evolves in time under a
time-varying control u (t) ∈ U. The dynamics of the particles
is determined by three factors: the Coulomb forces caused by
the interactions between the particles and the electrodes and
the interactions between the particles themselves, the friction
between the particles and their surrounding ﬂuid (drag), and
the Brownian motion. In the absence of the Brownian motion,
the particles accelerate under the Coulomb forces and the
opposing resistance of the surrounding ﬂuid. By Stokes’ drag
law [28], such resistive forces are negatively proportional to
the velocity of the particles with a proportionality constant
µ > 0. In response to a sudden change in the control Coulomb
forces,
the particles accelerate for a short period of time
before the opposing drag forces balance this change in the
control forces. In a large friction regime, this acceleration
period is short and negligible [29], so that it is a reasonable
approximation to take the drag and the Coulomb forces as
equal. Then the velocity of each particle will be proportional
to its applied Coulomb force (Smoluchowski approximation).
By normalizing time to µ/κ, the proportionality constant is
unit and the equation of motion of the particles can be simply

written as

˙x (t) = −∇xV (x (t) , u (t)) .

(2)

The contribution of the Brownian motion is incorporated
into the equation of motion using a n-dimensional standard
Wiener process {w (t)} as described by the Itˆo stochastic
differential equation [30]

dx (t) = −∇xV (x (t) , u (t)) dt + σdw (t).

(3)
Here, σ = √2κkBT is a constant depending on the Boltzmann
constant kB, the temperature T in Kelvin, and the normalizing
factor κ of the energy function. It is assumed that the initial
state x (0) = x0 is a random vector with the known probability
density function p0 (x) satisfying

p0 (x) = 0,

x /∈ [q0, qc]n .

The stochastic differential equation (3) represents the Langevin
equation for the particle positions [31], [32].

[q0, qc]

the interval

Suppose that

is partitioned into N
subintervals I1, I2, . . . , IN of the equal length d0. It is
assumed that the number N of these subintervals is larger than
the number n of the particles. Further, assume that the distance
qk − qk−1 between the electrodes is an integer multiple of the
grid size d0.
A pattern P ∈ {0, 1}N is deﬁned as a binary vector of
dimension N with exactly n ones (1’s) and N − n zeros
(0’s). The total number of patterns is given by the combination
n). Each binary component of a pattern represents one of
S = (N
the subintervals Ik. It is said that a pattern P is formed by the
particles, if exactly one particle is inside the subintervals asso-
ciated with the components of value 1 in P. Notice that every
state of the particles does not necessarily deﬁne a pattern since
it is possible that more than one particle belong to a certain
subinterval. Fig. 2 illustrates a nanostructure created by n = 8
particles in a grid of N = 16 cells with c + 1 = 5 electrodes.
The binary vector P = (0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1)
represents this nanostructure (pattern) in such a manner that
each occupied cell corresponds to a 1 in this vector.

q0

q1

q2

q3

q4

Fig. 2. Nano-structure created by n = 8 particles in a grid of N = 16
cells with c + 1 = 5 electrodes. The pattern is represented by the binary
vector P = (0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1), where each ﬁlled cell
is corresponding to a 1 in this vector. The boxes mark the locations of the
electrodes and the disks show the locations that the particles can occupy in
the discrete model of Section IV.

Each pattern P is uniquely mapped into a subset P0 (P) of
the state space [q0, qc]n such that the formation of that pattern
at time t occurs if x (t) ∈ P0 (P). Let ιk, k = 1, 2, . . . , n
denote the indices of the kth 1 in the binary vector (pattern) P.
Then the value of the mapping P0 (P) is deﬁned as the union

P0 (P) =[ Ii1 × Ii2 × ··· × Iin

taken over the set of all n! permutations of (ι1, ι2, . . . , ιn).

The control goal is to move the particles in such a manner
that they form a desired pattern Pd with the highest probability

3

at a ﬁnal time tf . This must be achieved despite the inherent
uncertainty in the system dynamics and the initial state and
by means of an open-loop control since the particle positions
(components of the state vector) cannot be measured during
the course of control due to technology limitations. Therefore,
the objective is to obtain an open-loop control u (t) ∈ U on
t ∈ [0, tf ] to form a desired pattern Pd at the ﬁnal time tf with
the highest possible probability, and to maintain this maximum
probability under the constant control uss , u (tf ) afterward
(t > tf ). These requirements are mathematically expressed by
maximizing the payoff function

J = Pr{x (tf ) ∈ P0 (Pd)}

(4)

under the inequality constraint

(cid:12)(cid:12)(cid:12)(cid:12)

Pr{x (t) ∈ P0 (Pd)} − lim

6 ǫ
(5)
for all t > tf and some small 0 < ǫ < 1. The ﬁnal time tf > 0
is a free parameter that is preferred but not constrained to be
reasonably short.

Pr{x (t′) ∈ P0 (Pd)}(cid:12)(cid:12)(cid:12)(cid:12)

t′→+∞

This optimization problem can be formulated as an optimal
control problem with deterministic but inﬁnite-dimensional
dynamics. It is well known that the probability density function
p (x, t) of x (t) solves the Fokker-Planck equation [33]

1
2

(x, t) = ∇x ·(cid:18)∇xV (x, u (t)) p (x, t) +

σ2∇xp (x, t)(cid:19)
∂p
∂t
with the initial condition p (x, 0) = p0 (x), where ∇x· denotes
the divergence operator with respect to the ﬁrst argument.
Then, subject to this inﬁnite-dimensional dynamics, an admis-
sible control u (t) ∈ U is sought on t ∈ [0, tf ] to maximize
the payoff function

J =ZP0(Pd)

p (x, tf ) dx

while maintaining the terminal condition

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

6 ǫ

p (x, t) dx(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ZP0(Pd)

p (x, tf ) dx − lim

t→+∞ZP0(Pd)

under the constant control u (tf ) for t > tf .

This new formulation represents a standard optimal control
problem1 although its solution is complicated by the inﬁnite
dimensions of the Fokker-Planck equation. In Section III,
we obtain a solution to this optimal control problem within
a certain class of piecewise constant controls. This solution
exploits a certain structure of the nonlinear system (3) to
convert the optimal control problem above to a sequence
of static optimization problems with tractable computational
complexity.

III. CONTROL DESIGN

Our control design procedure consists of two steps: design
of a static control, and design of a dynamic control. The static
control uss ∈ U is a constant control intended to create a stable
1The payoff function consists of only a terminal payoff and does not include

an integral over time of the state.

equilibrium xss ∈ P0 (Pd) inside the subset P0 (Pd) of the
state space that represents a desired pattern Pd. In the absence
of the Brownian motion, a stable equilibrium is a point of the
state space with a sustainable balance of forces under which
the particles are at rest, i.e., the state vector x (t) settles at this
point in the steady-state so that ˙x (t) = 0. In the presence of
the Brownian motion, the state vector moves towards the stable
equilibrium and eventually reaches a stationary regime under
which it randomly jitters in the vicinity of xss. The desired
pattern is formed in this regime as xss is inside P0 (Pd) and
the state vector remains close to this point. The optimal design
of the static control uss is discussed in Section III-B.

The static control uss and the corresponding equilibrium xss

must jointly satisfy the conditions2

−∇xV (xss, uss) = 0
H (xss, uss) ≻ 0
xss ∈ P0 (Pd)
uss ∈ U,

(6a)
(6b)
(6c)
(6d)

where H (xss, uss) ∈ Rn×n is the Hessian matrix
(xss, uss) .

H (xss, uss) =

∂2V
∂xT∂x

For a ﬁxed uss, the solution xss of the algebraic equation (6a)
is a stationary point of the energy function V (· , uss), and if
this stationary point is a strict local minimum of V (· , uss),
it is a stable equilibrium of the deterministic dynamical sys-
tem (2). As noted in (6b), if the Hessian matrix H (xss, uss) is
positive deﬁnite, the stationary point is a strict local minimum.
For any given static control uss, the algebraic equation (6a)
can have multiple stable solutions for xss, not necessarily
inside P0 (Pd) to form a desired pattern. This is caused by
the fact that the energy function V (· , uss) can have multiple
strict local minima (see Fig. 3(a)) that allow for the formation
of multiple stable patterns. As shown in Fig. 3(a), the energy
function consists of several potential wells with a single stable
equilibrium (a strict local minimum) at the bottom of each one.
Each potential well speciﬁes a region of attraction (ROA)—an
open subset of the state space containing exactly one stable
equilibrium and marked by the property that if the state x (t)
of the dynamical system (2) is initially inside a certain ROA,
it remains inside that ROA and moves towards its equilibrium.
This property is demonstrated by the inequality

d
dt

V (x (t) , uss) = ˙xT (t) ∇xV (x (t) , uss)
= − k∇xV (x (t) , uss)k2
6 0,

where the equality holds if and only if x (t) is an equilib-
rium. This implies that the total energy inside a single ROA
monotonically decreases before the system settles at the stable
equilibrium at the bottom of the potential well. Since the
energy level inside a ROA can never exceed its initial value,
the state vector cannot escape its initial ROA.

For a static control with multiple stable equilibria, the state

2The notation H ≻ 0 indicates that H is a positive deﬁnite matrix.

4

(b)

(a)

ROA

h
t
p
e
d

potential well

state-space

Fig. 3. Multiple equilibria, regions of attraction, and potential wells: (a)
multiple potential wells of a dynamical system of one dimension; (b) the state
space is partitioned by the ROAs. The depth of a potential well is marked
in (a) as the energy difference between the deepest point of that well and
the lowest energy level on its boundary. In (b), each ROA contains a single
stable equilibrium represented by a dot and the shaded region speciﬁes the
ROA containing the desired equilibrium. Without a dynamic control, only the
initial states inside this ROA lead to a desired pattern.

space is partitioned3 by the set of ROAs as illustrated schemat-
ically in Fig. 3(b). However, only a certain equilibrium forms
the desired pattern, and only those initial states belonging to
the ROA of that equilibrium end up with the desired pattern
(see Fig. 3(b)). Thus, before starting the phase of static control,
it is necessary to bring the initial state inside the desired ROA.
This task is performed by a dynamic control, a time-varying
open-loop control that drives the state vector x (t) towards
the desired ROA regardless of the inherent uncertainty in the
initial state. Notice that the state vector—particle locations—
is not known to the controller during the course of control.
It is shown in Section III-D that the dynamic control can
be decomposed into a sequence of static controls, so that a
piecewise constant structure is proposed for this control.

Before proceeding with the control design in Sections III-B
and III-D, the structure of the ROAs and their stable equilibria
is studied in Section III-A.

A. Structure of the Regions of Attraction

In the deterministic system (2) under the constant control
u (t) = uss, the state vector remains in the same ROA that
it takes its initial value. This property does not generally
hold for stochastic systems perturbed by a Wiener process.
For such stochastic systems, the random disturbance causes
the state vector to jitter around one of the equilibria, often
inside the same ROA. Occasionally, the deviations from the
equilibrium are large enough to drive the state vector outside
that ROA, allowing other stable equilibria to attract it. This
migration from one potential well to another can be viewed
as being caused by a high level of energy absorbed from a
disturbance that exceeds the depth of the departure potential
well. As illustrated in Fig. 3(a), the depth of a potential well is
deﬁned as the energy difference between its deepest point and
the lowest energy on its boundary. In the stochastic system (3),
however, the state vector cannot leave its initial ROA (almost
surely), even though the system is disturbed by a Wiener

3This means that the ROAs are disjoint subsets of the state space whose

union is the entire state space excluding the boundaries of the ROAs.

process. This unusual property is a consequence of the inﬁnite
depth of the potential wells in this system.

To show this property, consider an electrode charged with
the same polarity as the particles (assumed positive), and a
particle that is pushed towards the electrode by an external
force. For example, in Fig. 1 suppose that the particle located
at x1 is pushed left towards the electrode at q0 = 0. The
external force required to maintain the particle at the distance
x1 from the electrode is proportional to 1/x2
1 which increases
unboundedly as x1 tends to 0. This implies that the particle
cannot reach the electrode using a bounded external force, and
clearly cannot pass through it. With a similar argument, two
particles cannot hit each other under bounded external forces
that squeeze them together.

Assume that all electrodes have constant positive charges
(same polarity as the particles), i.e., u (t) = uss is a vector of
positive components. Let νk, k = 1, 2, . . . , c be the number of
particles in the interval (qk−1, qk) so that ν1+ν2+···+νc = n.
Based on the above argument, the integers νk remain constant
over time, i.e., at any time after applying the constant control
u (t) = uss, the number of particles in the interval (qk−1, qk)
is equal to its value just before application of this control. In
addition, the order of the particles is preserved over time as
the particles cannot jump over each other.

Since the particles are identical and their order does not
change over the course of control, it can be assumed without
loss of generality that they are labeled by 1, 2, . . . , n from left
to right, as shown in Fig. 1. This requires the initial distribution
of the state vector to satisfy

p0 (x) = 0,

x /∈ S0

where the simpliﬁed state space S0 is deﬁned as

S0 = {x| q0 < x1 < x2 < ··· < xn < qc} .

In addition, the ﬁxed order of the particles allows the mapping
P0 (P) to be simpliﬁed to P (P) deﬁned as
P (P) = Iι1 × Iι2 × ··· × Iιn ,

Let ν = (ν1, ν2, . . . , νc) be a vector in Nc

where ιk, k = 1, 2, . . . , n denote the indices of the kth 1 in
the pattern P.
0 whose kth
component is the number of particles in the interval (qk−1, qk).
Since the total number of particles is n, this vector must satisfy
the constraint kνk1 = n. The total number of such vectors is
the “weak compositions of n into c parts” [34, Thm. 5.2] and
is given by the combination

Each instance of ν uniquely speciﬁes a convex subset of S0
deﬁned as4

S (ν) =(cid:8)x| qk−1 < xik+1 < ··· < xik+νk < qk,

j=1 νj, k ∈ {l = 1, 2, . . . , c|νl 6= 0}(cid:9).

The convexity of this set is straightforward to show.

ik =Pk−1

4For k = 1, the sum Pk−1

j=1 νj is taken equal to 0.

R =(cid:18)n + c − 1

c − 1 (cid:19) =

(n + c − 1)!
n! (c − 1)!

.

(7)

5

These subsets are disjoint and their union is equal to the
state space S0 excluding a zero-measure set B0 containing
the boundaries of the open sets S (ν) in S0, i.e.,

[kνk1=n

S (ν) = S0\B0.

Theorem 1 in this section states that each subset S (ν) of the
state space S0 contains exactly one stable equilibrium of (2)
and that the energy function is convex over S (ν), concluding
that each S (ν) is a ROA of the dynamical system (2).

Theorem 1: For any constant control u (t) = uss with
positive components, the energy function V (· , uss) is strictly
convex over each convex subset S (ν) (with ν satisfying
kνk1 = n), the dynamical system (2) has exactly one equilib-
rium in S (ν), and that equilibrium is stable.

Proof: See Appendix.

Formation of a pattern P at time t is conﬁrmed if the state
vector x (t) is in the subset P (P) of the state space S0. On
the other hand, the deﬁnition of P (P) and the structure of the
ROAs imply that each P (P) is entirely inside a single ROA.
That speciﬁc ROA is characterized as follows. Assume that
the pattern P has νk (P) particles in the interval (qk−1, qk)
and let ν (P) denote a vector in Nc
0 containing the integers
νk (P), k = 1, 2, . . . , c. Then P (P) is a subset of S (ν (P))
as deﬁned in (8). Thus, to form a pattern P, it is necessary
to ﬁrst bring the state vector inside the ROA S (ν (P)). For
simplicity of notation in the rest of the paper, S (ν (P)) is
abbreviated into S (P) to represent the ROA containing the
pattern P.
B. Optimal Static Control

Suppose that a dynamic control has been applied to the
stochastic system (3) during the time interval t ∈ [0, td) to
bring its state inside the ROA S (Pd) that contains the desired
pattern Pd. In Section III-D, it is shown how to design such
a dynamic control to maximize the probability of hitting the
target set S (Pd). At t = td, the constant static control uss
is applied to the system and the system gradually reaches
the steady-state as t → +∞. In the steady-state regime, the
probability of forming the desired pattern remains constant,
i.e., the event of x (t) ∈ P (Pd) has a constant probability.
The objective of the static control is to maximize this constant
probability assuming that at t = td the state vector is
inside the desired ROA, i.e., x (td) ∈ S (Pd). This goal is
mathematically represented by the optimization problem

lim

t→+∞

Pr{x (t) ∈ P (Pd)| x (td) ∈ S (Pd)} .

max
uss∈Uss
In practice, the system can get arbitrarily close to the steady-
state within a bounded but long enough settling time tf − td.
Since the problem statement in Section II does not constrain
the ﬁnal time tf , this quantity can be chosen sufﬁciently large
to ensure that the conditional probability

(9)

(8)

Pr{x (tf ) ∈ P (Pd)| x (td) ∈ S (Pd)}

is close enough to its ﬁnal value in (9). Under this value of
the ﬁnal time, the static control that solves the optimization
problem (9), nearly maximizes this conditional probability.

Here and in the rest of this paper, the static control uss is
chosen from the control set Uss deﬁned as a subset of Rc+1
with positive control charges at two end points q0 and qc, and
nonnegative charges for the rest of the electrodes, so that

Uss = {u|u0 > 0, u1 > 0, . . . , uc−1 > 0, uc > 0} .

(10)

Under this assumption, Theorem 1 is applied to the ROAs of
the system. Notice that in the statement of Theorem 1, all
control charges are assumed positive, while (10) allows some
electrodes to be inactive with zero charges. This provides more
ﬂexibility to the control vector without jeopardizing the use
of Theorem 1: when some electrodes are inactive, still this
theorem is applied, albeit to a system with smaller number
of electrodes (with a control vector of smaller dimension).
In (10), only the electrodes at two end points q0 and qc are
constrained to be active to ensure that the particles cannot
escape the line segment.

For t > td, deﬁne ρ (x, t) as the conditional probability
density function of x (t) given x (td) ∈ S (Pd). The evolution
of this function for t > td is governed by the Fokker-Planck
equation

1
2

(x, t) = ∇x ·(cid:18)∇xV (x, uss) ρ (x, t) +

σ2∇xρ (x, t)(cid:19) .
∂ρ
∂t
The deﬁnition of ρ implies that at t = td this function is
identically 0 for every x /∈ S (Pd). Since the state vector
is almost surely inside S (Pd) at t = td and almost surely
cannot leave this ROA, it stays in S (Pd) for every t > td with
probability 1. This implies ρ (x, t) = 0 for every x /∈ S (Pd)
and every t > td. Based on this analysis, the steady-state
solution of this Fokker-Planck equation is given by [33]

ρ (x, +∞) =

exp(cid:0)−2σ−2V (x, uss)(cid:1)
exp(cid:0)−2σ−2V (ξ, uss)(cid:1) dξ

ZS (Pd)

(11)

for x ∈ S (Pd) and by ρ (x, +∞) = 0 for x /∈ S (Pd). Note
that the normalizing factor in the denominator is an integral
over S (Pd) rather than the entire state space following the
fact that the conditional probability distribution is identically 0
outside this ROA.

Using the conditional density function (11), the conditional

probability

Pss (uss) , lim
t→+∞

Pr{x (t) ∈ P (Pd)| x (td) ∈ S (Pd)}

(12)

is expressed as

Pss (uss) = ZP(Pd)
ZS (Pd)

The condition Pss (uss) 6 1 on probabilities is reﬂected in
this expression by the fact that P (Pd) ⊂ S (Pd). Using the
explicit form (13), the optimal static control u∗
ss is obtained
from the optimization problem

exp(cid:0)−2σ−2V (ξ, uss)(cid:1) dξ
exp(cid:0)−2σ−2V (ξ, uss)(cid:1) dξ

.

(13)

6

it

In this optimization problem,

is computationally ex-
pensive to determine Pss (uss) from (13), since numerical
approximation of this expression requires computation of
the energy function V (ξ, uss) at a large number of points.
The computational complexity can be signiﬁcantly reduced
by saddle point approximation [35], [36] of the integrals
in (13). This approximation relies on the fact that the negative
exponential integrands in (13) take their signiﬁcant values in
the ROA S (Pd) only around the unique minimizer xss (uss)
of the energy function. Hence, without signiﬁcant loss of
accuracy, V (ξ, uss) can be replaced with a simpler function
that approximates it well only around xss (uss). A reasonable
choice for such an approximation is the truncated Taylor series
(ξ − xss)TH (xss, uss) (ξ − xss)
V (ξ, uss) ≃ V (xss, uss) +
in which the dependence of xss on uss is not explicitly shown
for the sake of simplicity.

1
2

Substituting this approximate expression into (13) and mul-
tiplying both its numerator and denominator by an appropriate
constant, Pss (uss) is approximated by

Pss (uss) ≃ ˜Pss (xss (uss) , uss)

(15)

in terms of the mapping ˜Pss : Rn × Rc+1 → R deﬁned as
˜Pss (x, u) = ZP(Pd)
ZS (Pd)

2 σ2H −1 (x, u)(cid:1) dξ
2 σ2H −1 (x, u)(cid:1) dξ

Φ(cid:0)ξ; x, 1
Φ(cid:0)ξ; x, 1

Here, Φ (· ; m, Σ) denotes a multivariate normal distribution
with the mean vector m and the covariance matrix Σ. Using
the payoff function (15)-(16), the optimization problem (14)
can be reformulated as the constrained optimization problem

(16)

.

max

(xss,uss)∈S (Pd)×Uss

˜Pss (xss, uss)

s.t.

− ∇xV (xss, uss) = 0.

(17a)

(17b)

It is shown next that the approximate formula (16) can be
directly derived from a linearized model around the unique
stable equilibrium of the ROA S (Pd). Such a linear model
is later used to provide an intuitive explanation for the static
control design. Let uss ∈ Uss be a ﬁxed control and assume
that xss is its associated equilibrium in S (Pd). If the distur-
bance strength σ is small compared to the norm of the Hessian
matrix H (xss, uss), the dynamical system (3) can be linearized
around (xss, uss) to approximate the state vector as

x (t) ≃ xss + δx (t)

(18)

in which the small deviation δx (t) is the solution of the linear
stochastic differential equation

dδx (t) = −H (xss, uss) δx (t) dt + σdw (t) .

(19)

The linearity of this equation indicates that δx (t) is a zero-
mean Gaussian random vector with the steady-state covariance
matrix

u∗
ss ∈ arg max

uss∈Uss

Pss (uss) .

(14)

Σss =

σ2H −1 (xss, uss)

(20)

1
2

that solves the algebraic Lyapunov equation [37]

−H (xss, uss) Σss − ΣssH (xss, uss) + σ2I = 0.

It is concluded that x (t) is approximately a Gaussian random
vector with the mean vector xss and the covariance matrix Σss.
For this approximation, ˜Pss (xss, uss) deﬁned in (16) represents
the conditional probability on the right-hand side of (12).

Based on the linear model (18)-(19), an approximate design
method is introduced below to provide further intuition on the
optimal static control. To facilitate the discussion, Pss (uss) is
expressed as the ratio

Pss (uss) =

A (uss)

A (uss) + B (uss)

(21)

with A (uss) and B (uss) deﬁned as

A (uss) =ZP(Pd)
B (uss) =ZS (Pd)\P(Pd)

exp(cid:0)−2σ−2V (ξ, uss)(cid:1) dξ

exp(cid:0)−2σ−2V (ξ, uss)(cid:1) dξ.

To achieve the maximum of Pss, the value A (uss) must be
kept as large as possible compared to B (uss). This requires to
shift the concentration of probability towards the central point
of the desired set P (Pd) and push it away from the forbidden
set S (Pd) \P (Pd). Let ξd ∈ Rn be a vector containing the
mid points of the intervals Ik corresponding to 1’s in the
desired pattern Pd. Then the problem is to keep the state vector
x (t) at steady-state as close as possible to ξd with respect to
some appropriate norm.

Since the desired set P (Pd) is a hypercube, a reasonable

choice of the distance measure is

lim

t→+∞

E [kx (t) − ξdk∞] ≃ lim

E [kxss − ξd + δx (t)k∞] .
t→+∞
However, this measure is not mathematically tractable unless
the disturbance power 1
2 σ2 is small enough to justify the
approximation δx (t) ≃ 0. In this case, an approximation for
the optimal static control is given by the optimization problem

(xss,uss)∈S (Pd)×Uss kxss − ξdk∞

min

s.t.

− ∇xV (xss, uss) = 0.

Such a suboptimal static control places the stable equilibrium
xss as close as possible to ξd that represents the desired pattern.
When 1
2 σ2 is not negligible, one can alternatively adopt the
mean squared distance measure

lim

t→+∞

Ehkx (t) − ξdk2i ≃ kxss − ξdk2 + tr{Σss}

which leads to the optimization problem
(xss,uss)∈S (Pd)×Uss kxss − ξdk2 + 1
s.t. − ∇xV (xss, uss) = 0.

min

2 σ2tr(cid:8)H −1 (xss, uss)(cid:9)

It is reasonable at this point to ask whether the optimization
problem (14) has always a bounded solution or it is possible
for the optimal static control to be unbounded. An informal
treatment of this problem comes below. Let uss be a constant
control in Uss with a stable equilibrium xss (uss) ∈ S (Pd).

7

For every ξ ∈ S (Pd), the value V (ξ, uss) of the energy
function tends to +∞ as kussk → +∞ since the components
of uss are nonnegative. Under this limit, the ratio (21) tends to
either 0 or 1, depending on which of the sets S (Pd)\P (Pd)
or P (Pd) contain xss (uss). In particular, the limiting value
of Pss (uss) is explicitly given by

lim

kussk→+∞

Pss (uss) =( 1 xss (uss) ∈ P (Pd)

0 xss (uss) ∈ S (Pd)\P (Pd) .

ss in (14) can be unbounded if under this

This implies that u∗
control the equilibrium xss (u∗

ss) remains inside P (Pd).

Assume that the desired pattern Pd at least in one of the
intervals (qk−1, qk) has two or more particles. Any unbounded
control, necessarily squeezes these particles together, and two
particles closer than a grid length cannot form a valid pattern,
i.e., the probability of forming Pd under an unbounded control
is identically 0. It is concluded that the optimal control u∗
ss can
be potentially unbounded only for the sparse patterns with at
most one particle in each interval (qk−1, qk). Thus, except for
such sparse patterns (that are not of much practical interest),
it is not necessary to impose an upper bound on the control
set Uss to secure a well deﬁned solution for the optimization
problem (14).
In theory, an unbounded control can achieve the probability
ss) = 1 for a sparse pattern. In this degenerate case,
Pss (u∗
the number of particles is smaller than the number of controls
(n < c+1) so that the algebraic equation −∇xV (ξd; uss) = 0
can have multiple solutions for uss, including a solution with
an inﬁnite magnitude. Such an unbounded control leads to a
Hessian matrix H (ξd, uss) with an unbounded norm, which
in turn, results in a zero covariance matrix according to (20).
1) Numerical Computation of a Stable Equilibrium: Two
numerical techniques are proposed here to compute the stable
equilibrium inside each ROA. The ﬁrst method relies on the
numerical solution of the ordinary differential equation (2).
Starting from any arbitrary initial state inside the desired ROA,
the solution to (2) asymptotically approaches the unique stable
equilibrium of that ROA. Although the exact equilibrium is
approached only as t → +∞, after a bounded but long enough
time, the solution of (2) will be close enough to the equilibrium
to provide an acceptable approximation for it.

The second method makes use of the proof of Theorem 1
(see Appendix). This method starts from an initial vector x0 ∈
S (ν) and generates the sequence of vectors x1, x2, x3, . . .
from the recursive equation xk+1 = g(cid:0)xk(cid:1), k = 0, 1, 2, . . .

until the distance between two successive vectors drops below
a given threshold. Then the last vector in this sequence is taken
as an approximation for the equilibrium. At each step k, the

ith component of g(cid:0)xk(cid:1) is computed by numerically solving

(e.g. using Newton’s method) the algebraic equation

1 , xk

i−1, y, xk
for y, as explained in Theorem 1.

fi(cid:0)xk

2, . . . , xk

i+1, . . . , xk

n, uss(cid:1) = 0

2) Approximate Settling Time: Determining an estimate for
the settling time tf−td is the last step to complete the design of
the static control. This quantity closely depends on the second
smallest eigenvalue (in absolute value) of the Fokker-Planck

operator [38]

L (·) = ∇x ·(cid:18)∇xV (x, uss) (·) +

1
2

σ2∇x (·)(cid:19) .

Note that the ﬁrst eigenvalue of this operator (smallest in the
absolute value) is 0 associated with the steady-state solution
of the Fokker-Planck equation. Let l2 (L) < 0 be the second
smallest eigenvalue of L (·) in the absolute value. Then a rule
of thumb for computation of the settling time is given by

tf − td ≃ 5 |l2 (L)|−1 .

Direct computation of l2 (L) is generally a difﬁcult task. In
the case of this paper, the settling time can be approximated
using an alternative method. This approximation is based on
the observation that the settling time tf−td is the time required
for the state vector x (t) to reach a stationary regime starting
from an initial state inside the ROA S (Pd). The temporal
evolution of the state vector is governed by the stochastic
differential equation (3) under the constant control u (t) = uss.
The sample trajectories of x (t) almost surely remain inside the
same ROA S (Pd) and tend towards the equilibrium xss. The
large energy gradient near the boundary (large repulsive forces
between closely placed point charges) of the ROA strongly
pushes the trajectories towards the equilibrium so that they
rapidly move away from the boundary and spend most of their
transition time near the equilibrium. This justiﬁes linearizing
the nonlinear dynamics (3) around the equilibrium xss and
computing the settling time from the linear model (19) rather
than the original nonlinear model (3). Then the approximate
settling time is expressed in terms of the smallest eigenvalue
l1 (·) of the positive deﬁnite Hessian matrix H (xss, uss) as
(22)

(H (xss, uss)) .

tf − td ≃ 5l−1

1

C. Optimal Electrode Positions

In the procedure proposed in Section III-B for design of
the static control, the positions q0, q1, . . . , qc of the electrodes
are assumed ﬁxed and given in advance. However, the speciﬁc
choice of these positions, that are directly involved in the shape
of the energy function (1), can affect the performance of the
static control for better or worse. To maximize the probability
of forming a desired pattern, the electrode positions can be
optimized simultaneously with the static control, of course
within certain physical constraints.

As mentioned before, the electrode positions are integer
multiples of the grid size d0. Let Nk be an integer quantifying
the distance between the electrodes k and k − 1 as

qk − qk−1 = d0Nk.

Then, in terms of N1, N2, . . . , Nc, the electrode positions are
given by

k

qk = q0 + d0

Nj,

k = 1, 2, . . . , c.

(23)

Xj=1

Since the length qc − q0 of the line segment is ﬁxed and
includes exactly N grid cells, the integers N1, N2, . . . , Nc
must satisfy the equality constraint N1 + N2 +··· + Nc = N .

8

Moreover, technology limitations do not allow to fabricate
the electrodes closer than d0Nmin, imposing the inequality
constraints N1, N2, . . . , Nc > Nmin for some integer Nmin.

Substituting (23) into the energy function (1), the depen-
dence of the probability (13) on the energy function (1) results
in an explicit expression Pss (uss, N1, N2, . . . , Nc) for this
probability. Then the joint optimization of the static control
and the electrode positions can be formulated as the mixed
integer nonlinear program (MINLP) [39], [40]

max

uss,N1,N2,...,Nc

s.t.

Pss (uss, N1, N2, . . . , Nc)
uss ∈ Uss
N1 + N2 + ··· + Nc = N
N1, N2, . . . , Nc > Nmin.

D. Dynamic Control

At the initial time t = 0, the state vector x (0) is randomly
distributed in the state space S0 according to some probability
density function p0. The dynamic control is an open-loop
control applied to the system of particles during [0, td) to
bring the random initial state inside the desired ROA S (Pd)
with the highest probability. The dynamic control proposed in
this paper consists of a sequence of static controls, each one
designed through a procedure similar to Section III-B. The
concept of a multistage control for directed self-assembly has
been established in [26] and is illustrated in Fig. 4.

d. The optimal value of u1

Consider a constant control vector u1

d whose ﬁrst and last
components are positive and the rest of its components are 0
(only the electrodes at q0 and qc are active). Under this control,
all particles are distributed inside a single large interval (q0, qc)
and the system has a single ROA S 1
d covering the entire
state space S0. Application of this constant control at t = 0
drives the state vector towards the unique equilibrium of S 1
d
regardless of its initial value. After a settling time of t1
d, the
constant control u1
d is switched to another constant control u2
d
with more than two positive components (e.g. the electrode in
the middle is activated). Under this new control, the system
has more than one ROA while a speciﬁc one of these multiple
d ) is the target set of the state vector at
ROAs (denoted by S 2
d at the ﬁrst stage is determined
t = t1
to maximize the probability of the state vector being inside this
target ROA at t = t1
d . This procedure is
repeated in D stages by activating more controls at each stage
while getting closer to the ﬁnal desired equilibrium. The target
set S D+1
of the last stage is the ROA containing the desired
pattern in the static control problem, i.e., S D+1
= S (Pd).
At the end of the last stage of the dynamic control, the static
control uss activates all electrodes to create the desired pattern.
is explained
below by an example using Fig. 2. In this ﬁgure, a system
of n = 8 particles with c + 1 = 5 controls and N = 16
grid cells is illustrated. The dynamic control is designed with
D = 2 stages and the following sequence of controls: in the
ﬁrst stage, only the electrodes at q0 and q4 are active, while
in the second and last stage the electrode at q2 is turned on.
The electrodes at q1 and q3 are simultaneously activated in the

d, i.e., x(cid:0)t1

Design of the target ROAs S 2

d(cid:1) ∈ S 2

d , S 3

d , . . . , S D

d

d

d

(a)

(b)

9

deﬁned as
U 1
d = {u|u0 > 0, u1 = 0, . . . , uc−1 = 0, uc > 0} ,

and with the property that the controls in U i+1
can possess
d. It
at least one more nonzero component than those in U i
is assumed that at each stage i = 1, 2, . . . , D, the constant
control ui
d, while the static control uss
belongs to Uss.

d is in the control set U i

d

(c)

(d)

The goal is to obtain within the class of controls (24), the
one that solves the optimal control problem of Section II. The
controls in this class consist of a static part applied for t > td
and a dynamic part during 0 6 t < td. Optimization of the
static part was discussed in Section III-B and the procedure
for optimizing the dynamic part is presented below.

Fig. 4. Multistage dynamic control consisting of a sequence of static controls.
The large squares represent the entire state space and the solid lines inside
these squares show the boundary of the ROAs. In the ﬁrst stage (a), the entire
state space is a single ROA with a unique stable equilibrium marked by a small
disk. The state vector can be initially any point in this single ROA (marked
by the asterisks), which moves towards the stable equilibrium and eventually
stays near this point (shown as a circular region) with a high probability. The
stable equilibrium is designed to be inside the desired ROA (shaded region)
of the next stage (b) so that the state vector will be inside this desired ROA at
the end of the ﬁrst stage. This procedure is repeated in transition from (b) to
(c) and from (c) to (d). The static control in (d) eventually creates the desired
pattern.

static control phase. According to this sequence, the controls
d, u2
u1

d, and uss have the structure

u1
d = (⊕, 0, 0, 0,⊕)
u2
d = (⊕, 0, ⋆, 0,⊕)
uss = (⊕, ⋆, ⋆, ⋆,⊕) ,

where ⊕ and ⋆ denote positive and nonnegative components,
respectively. The target ROA S 2
d is a subset of the state space
with 5 particles on the left side of q2 and 3 particles on its
right side, and is explicitly given by

S 2

d = {x| q0 < x1 < ··· < x5 < q2 < x6 < x7 < x8 < q4} .
d is a subset with 3, 2, 1, and 2 particles in the
Similarly, S 3
intervals (q0, q1), (q1, q2), (q2, q3), and (q3, q4), respectively.

Consider the family of piecewise constant controls

i = 1, 2, . . . , D

(24)

u (t) =( ui

d ,
uss ,

d

, ti

t ∈(cid:2)ti−1
d(cid:1) ,
t ∈ [tf , +∞) ,
d < t1

where the constants 0 = t0
d = td < tf
are the switching times of the control and tf is the ﬁnal time.
For i = 1, 2, . . . , D, deﬁne the increasing sequence of control
d ⊂ Uss with Uss given by (10), U 1
sets U 1

d ⊂ ··· ⊂ U D

d < ··· < tD

d ⊂ U 2

d < t2

d

P i

d , . . . , S D

Consider the sequence S 2
d , S 3
ated with the sequence U 1
d ,U 2
d , . . . ,U D
for i = 1, 2, . . . , D deﬁne the conditional probabilities
Pr(cid:8)x (t) ∈ S i+1
d(cid:0)ui

d(cid:1) = lim

|x(cid:0)ti−1

(cid:1) ∈ S i
d(cid:9) ,

d of ROAs associ-
d of control sets, and

where x (t) is the state of (3) under the constant control ui
d
applied at t = ti−1
. As discussed in Section III-B, these
probabilities are explicitly expressed as

t→+∞

(25)

d

d

d

P i

d(cid:1) = ZS i+1
d(cid:0)ui
ZS i

d

d

exp(cid:0)−2σ−2V (cid:0)ξ, ui
d(cid:1)(cid:1) dξ
exp(cid:0)−2σ−2V (cid:0)ξ, ui
d(cid:1)(cid:1) dξ
d − ti−1

d

.

It is assumed that the time durations ti
between the
switching times are long enough for the system to reach the
steady-state before application of a new segment of the control
(as discussed in Section III-B2). Under this condition, the
following approximation holds:

Pr(cid:8)x(cid:0)ti

d(cid:1) ∈ S i+1

d

d

|x(cid:0)ti−1

(cid:1) ∈ S i

d(cid:9) ≃ P i

d(cid:0)ui
d(cid:1) .

At the initial time t = 0, the state vector belongs to S 1
d = S0
with probability 1. Thus, the probability of formation of a
desired pattern Pd under the control (24) at t = tf is given in
terms of the conditional probabilities Pss (uss) and P i
d(cid:1),
d(cid:0)ui
i = 1, 2, . . . , D by the product

Pr{x (tf ) ∈ P (Pd)} ≃ Pss (uss)

D

Yi=1

P i

d(cid:0)ui
d(cid:1) .

(26)

Note that this approximation tends to exact as tf − td → +∞
and ti

d → +∞, i = 1, 2, . . . , D.

d − ti−1

To maximize the probability (26), each multiplicative term
must be maximized independently with respect to its argument.
For the static control term, the optimization problem (14) was
already discussed in Section III-B. For the rest of the terms, the
optimal controls ui∗
d , i = 1, 2, . . . , D are obtained by solving
the optimization problems

ui∗
d ∈ arg max

d∈U i

ui

d

P i

d(cid:0)ui
d(cid:1) .

(27)

In terms of these optimal controls, the maximum probability of
forming a desired pattern Pd at a large ﬁnal time tf achieved

by a control in the class of controls (24) is given by

D

P i

(28)

Yi=1

d(cid:0)ui∗
d (cid:1) .

max Pr{x (tf ) ∈ P (Pd)} ≃ Pss (u∗
ss)
The activation sequence of the electrodes is not unique and
can be regarded as an additional optimization variable. For
any speciﬁc activation sequence, the maximum probability to
form a desired pattern is obtained from (28). Then in a higher
level of the optimization process, the maximum of these opti-
mized probabilities is determined over all possible activation
sequences. For the small size problem of Fig. 2 with only
13 possible activation sequences, this level of optimization
can be performed by simply enumerating all sequences. For
a problem of larger size, more advanced techniques can be
developed based on the outer approximation [39] or branch
and bound [40] methods.

E. Numerical Results

We applied the design procedure developed in this section
to the example of Fig. 2. In this ﬁgure, self-assembly of n = 8
particles using c + 1 = 5 electrodes is considered along a line
segment. The line segment is partitioned into N = 16 cells
and the distance between the electrodes is assumed to be 1 unit
of length. Throughout the design procedure and its following
simulations the disturbance power is set at σ = 0.45. The goal
is to generate a desired pattern of

Pd = (0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1).

For design of both static and dynamic controls, the con-
strained optimization problem (17) was utilized to approximate
the original problems (14) and (27). This constrained opti-
mization problem, was converted to an unconstrained problem
by solving the constraint (17b) for xss using the second
numerical procedure proposed in Section III-B1. The resulting
unconstrained problem was solved using the fminsearch
function of MATLABr.

The designed optimal control consists of a static control
and a two-stage dynamic control as illustrated in Fig. 5. The
optimal values of the control vector are shown for the two
stages of the dynamic control and for the static control in
Figs. 5(a), 5(b), and 5(c), respectively. Further, the most likely
patterns formed at the end of each stage are illustrated in
these ﬁgures. The small boxes in these ﬁgures represent the
locations of the electrodes, while the disks mark the optimal
equilibrium of each stage. Using the approximation method
of Section III-B2, the switching times of the control were
computed as t1
d = 0.98, and tf = 1.13. Also,
the highest probability of success at each stage was obtained
as P 1
ss) = 0.94, which
lead to the total probability of success

d = 0.67, t2

d (cid:0)u1∗

d (cid:1) ≃ 1, P 2
d (cid:0)u1∗

d (cid:0)u2∗
d (cid:1) P 2

d (cid:1) ≃ 1, and Pss (u∗
d (cid:0)u1∗

d (cid:1) Pss (u∗

P 1

ss) ≃ 0.94.

Under this control, the deterministic dynamical system (2)
and its stochastic version (3) were numerically simulated. The
results of these simulations are shown in Fig. 6 for both
deterministic (thick line) and stochastic (thin line) models.

0.77

0.00

(a)

0.00

(b)
1.91

0.00

10

5.93

0.70

0.47

7.53

0.00

0.00

(c)

0.02

1.95

0.46

0.29

Fig. 5. Designed optimal control: (a) ﬁrst stage of the dynamic control; (b)
second stage of the dynamic control; (c) static control. The vertical lines with
a number on their top represent the components of the control vector. The
illustrated pattern at each stage represent the most likely pattern generated at
the end of that stage. The small boxes mark the locations of the electrodes
and the disks show the equilibrium of each stage.

The trajectory of the particles start at random positions (small
boxes) and end at the optimal ﬁnal equilibrium (small disks)
that represents the desired pattern shown on the top. The
vertical axis in this ﬁgure shows progress in time while the
horizontal axis stands for the line segment on which the
particles move. The heavy vertical lines represent the energy
barriers created by the electrodes which cannot be crossed by
the particles. Note that the speciﬁc sample path illustrated in
Fig. 6 succeeds to create the desired pattern; however, not all
sample paths of the stochastic system end up with the desired
pattern. For example, the sample path of Fig. 6 could fail if the
deviation marked by the dashed ellipse would occur shortly
later. With the probability of success estimated as 0.94, the
sample paths fail to form the desired pattern at an average
rate of 6%.

IV. CONTROL DESIGN FOR A DISCRETE ISING MODEL
In the prior work on directed self-assembly, the system of
particles has been described by a discrete Ising model [41]
rather than the continuous model of this paper [25]–[27]. In
such a discrete model, the particles can occupy only a ﬁnite
set of positions along the line—at most one particle in each
position. As shown in Fig. 2, these positions are located at
the centers of the intervals Ik. In this model, the discrete
state of the particles is a vector ˆx (t) in Rn taking its value
in the discrete state space {ξ1, ξ2, . . . , ξS} ⊂ Rn at any time
t > 0. Each vector ξk in this discrete state space corresponds
to a pattern Pk and its n components represent the discrete

11

tf

t2
d

t1
d

where Λ (u (t)) is a S × S matrix with off-diagonal elements
λij (u (t)) and diagonal elements

λii (u (t)) = −

λji (u (t)) .

S

Xj=1

j6=i

For any ﬁxed t > 0, the transition rate λij (u (t)) from a
pattern j to another pattern i exponentially decreases with the
difference between the energy V (ξj, u (t)) of the pattern j
and the energy barrier Eij (u (t)) between the two patterns.
The mapping λij : Rc+1 → R+ that maps the instantaneous
value of the control vector into the instantaneous value of the
transition rate has the form of [43]

λij (u) = exp(cid:0)−2σ−2 (Eij (u) − V (ξj , u))(cid:1) ,

where 1
2σ2 = κkBT is a constant increasing with the absolute
temperature T , and the energy barrier satisﬁes the conditions

i 6= j,

Eij (u) = Eji (u) > V (ξj, u) ,

u ∈ U .

For the explicit form of Eij (u),

the reader is referred
to [27]. For the analysis of this paper, it is enough to know
that the energy barrier between two patterns is positive, and
it is of inﬁnite magnitude if in transition from one pattern to
another a particle has to jump over an active electrode. This
latter property is caused by the unbounded level of energy
at a point charge that represents an active electrode. Due to
this property, the transition rates between two such patterns
are identically 0 which parallels the property observed in the
continuous model that a particle cannot jump over an active
electrode.

Because of this property, the central role of the ROAs in the
continuous model has an analogue in the discrete model. Each
ROA contains a certain subset of the patterns ξ1, ξ2, . . . , ξS,
and similar to the continuous model, the ROAs partition the
discrete state space {ξ1, ξ2, . . . , ξS} into R subsets (R is the
number of ROAs given by (7)). The ROAs are marked by
unbounded energy barriers encircling them, and such inﬁnite
energy barriers block the transition of a pattern inside a ROA
to any pattern outside it. This implies that for any pair of
patterns i and j inside two different ROAs, both othe transition
rates λij (u (t)) and λji (u (t)) are identically 0. As a result,
the state-space equation (29) is decomposed into R decoupled
smaller state-space equations

i

(t) is a column vector containing the probabilities
where πROA
of the patterns belonging to the ith ROA and ΛROA
(u (t)) is
its corresponding square block of Λ (u (t)). Equivalently, the
Markov chain z (t) is reducible into R smaller Markov chains
z1 (t) , z2 (t) , . . . , zR (t) which are statistically independent
conditioned on the initial value z (0). Each of the R decoupled
state-space equations has a steady-state solution which follows
a Gibbs probability distribution.

i

This property helps to determine a simple expression for the
discrete counterpart of the conditional probability (12). Let Pd
be a desired pattern inside the ROA S (Pd) and assume that
it is represented in the discrete state space by the vector ξd.

λij (u (t)) πj (t)

˙πROA
i

(t) = ΛROA

i

(u (t)) πROA

i

(t) ,

i = 1, 2, . . . , R,

1

0.8

t

0.6

0.4

0.2

0
q0

q1

q2

q3

q4

Fig. 6. Simulation results for deterministic (thick line) and stochastic (thin
line) models. The vertical axis represents time while the horizontal axis stands
for the line segment on which the particles move. The heavy vertical lines
represent the energy barriers created by the electrodes which cannot be crossed
by the particles. Not all sample paths of the stochastic system end up with
the desired pattern; on average, 6% of them fail to form this speciﬁc pattern.
The sample path of Fig. 6 could fail if the deviation marked by the dashed
ellipse would occur shortly later.

locations of n particles along the line. The number S of the
elements in the discrete state space is the same as the number
of patterns that can be formed by placement of n particles in
N > n positions and is given by the combination S = (N
n ).
Equivalently, the discrete state of the particles at time t can
be described by an integer z (t) ∈ {1, 2, . . . , S} such that
ˆx (t) = ξz(t).

Similar to the continuous model (3), the discrete state z (t) is
characterized by a stochastic process, namely by a continuous-
time Markov chain [42]. For a continuous-time Markov chain,
the evolution of probability is described by a master equation,
the analogue of the Fokker-Planck equation in the continuous
model. For i = 1, 2, . . . , S deﬁne the probabilities
πi (t) = Pr{ˆx (t) = ξi} = Pr{z (t) = i} .

These probabilities evolve in time according to the set of linear
differential equations

˙πi (t) = −

S

Xj=1

j6=i

λji (u (t)) πi (t) +

S

Xj=1

j6=i

deﬁned for i = 1, 2, . . . , S. The initial state of these equations
(the initial probability distribution) is assumed known and the
nonnegative scalars λij (u (t)), i 6= j = 1, 2, . . . , S describe
the transition rates from pattern j to pattern i. The contribution
of the control to the system dynamics is reﬂected in the model
through the dependence of the transition rates on the control
vector u (t). By collecting the probabilities πi (t) in a single
vector π (t) = [π1 (t) π2 (t) ··· πS (t)]T, the master equation
can be written in the compact form

˙π (t) = Λ (u (t)) π (t) ,

(29)

Similar to (12), deﬁne the conditional probability

Πss (uss) = lim

t→+∞

Pr{ˆx (t) = ξd| ˆx (td) ∈ S (Pd)}

under the constant control u (t) = uss applied at t = td.
Using the analysis above, this conditional probability can be
explicitly expressed as

Πss (uss) =

exp(cid:0)−2σ−2V (ξd, uss)(cid:1)

exp(cid:0)−2σ−2V (ξk, uss)(cid:1)

Xξk∈S (Pd)

.

Similarly, the discrete counterpart of (25) is deﬁned as

Pr(cid:8)ˆx (t) ∈ S i+1

d

d

| ˆx(cid:0)ti−1

(cid:1) ∈ S i
d(cid:9)

d for t > ti−1

d

, and is

under the constant control u (t) = ui
explicitly expressed as

Πi

d(cid:0)ui

t→+∞

d(cid:1) = lim
d(cid:1) = Xξk∈S i+1
d(cid:0)ui
Xξk∈S i

d

d

Πi

exp(cid:0)−2σ−2V (cid:0)ξk, ui
d(cid:1)(cid:1)
exp(cid:0)−2σ−2V (cid:0)ξk, ui
d(cid:1)(cid:1)

.

12

the assembly process. Two models have been proposed to
describe the uncertain dynamics of the particles. The ﬁrst
model which is mathematically more tractable consists of a
set of nonlinear stochastic differential equations and is suitable
for larger particles of micrometer scale. The second model is
a discrete Ising model consisting of a continuous-time Markov
chain and is more accurate for nanometer scale particles. A
class of piecewise constant controls has been proposed for
these models and the optimal values of the constant pieces
have been determined as the solutions to certain optimization
problems.

APPENDIX

PROOF OF THEOREM 1

Consider S (ν) with kνk1 = n. The goal is to show that

the algebraic equation

f (x, uss) , −∇xV (x, uss) = 0

(31)

has exactly one solution xss in S (ν) and that the Jacobian
matrix of the vector ﬁeld f (· , uss) is negative deﬁnite over the
set S (ν). To that end, denote the kth component of f (x, uss)
ss be the jth component of uss, where
by fk (x, uss) and let uj
ss > 0. Then using (1), fk (x, uss) can be
by hypothesis uj
written as

Finally, the probability of successful formation of a pattern Pd
at time t = tf under the control (24) is approximately given as

Pr{ˆx (tf ) = ξd} ≃ Πss (uss)

D

Yi=1

Πi

d(cid:0)ui
d(cid:1) .

Evidently, the procedure of control design for the discrete
model parallels the one proposed for the continuous model: it
is enough to maximize the payoff function (30) instead of (26).
Further, each of these payoff functions closely approximates
the other one as the sums in (30) are discrete approximations
of the integrals in (26). The only major difference in the
control design procedure is in computation of the practical
values of the settling times tf − td and ti+1
d. For the
continuous model, these quantities are determined in terms of
the eigenvalues of the Fokker-Planck operator as explained in
Section III-B2. For the discrete model, the settling time tf −td
is determined in terms of the smallest nonzero eigenvalue
of the matrix ΛROA
(uss) (smallest in the absolute value),
where the subscript d refers to the ROA containing the desired
pattern.

d − ti

d

V. CONCLUSION

Directed self-assembly of charged particles along line seg-
ments has been considered. In the assembly process, a number
of particles move in one dimension along a line segment
under the repulsive forces experienced from interactions with
other particles, and the process is directed towards forma-
tion of a desired pattern by external forces applied from
charged electrodes located at ﬁxed points in the line segment.
The potentials of these electrodes are precisely controlled in
time so that the formation of a desired pattern is secured
with the highest probability despite the inherent uncertainty
in the initial position and the dynamical behaviors of the
particles. A challenging aspect of such a control is that the
actual positions of the particles are not measurable during

(30)

fk (x, uss) = −

V (x, uss) ,

∂
∂xk
∂
∂xk

n

1

j6=k

Xj=1
sign (xk − xj)
(xk − xj )2 +

|xk − xj| −
Xj=0

c

∂
∂xk

c

uj
ss

,

|xk − qj|

Xj=0
uj
sssign (xk − qj)
(xk − qj)2

,

= −

=

n

Xj=1

j6=k

n

∂fk
∂xk

(32)
where sign (·) denotes the signum function. Further, for x ∈
S (ν), the partial derivatives of fk (· , uss) with respect to xk
and xi, i 6= k exist and are given by
Xj=0
|xk − xj|3 −
i 6= k.

∂fk
∂xi
Given x ∈ S (ν), for each k = 1, 2, . . . , n, let k′ denote

Xj=1
|xk − xi|3 ,

|xk − qj|3 ,

the smallest integer satisfying xk < qk′ and deﬁne

(x, uss) = −

(x, uss) =

j6=k
2

(33b)

(33a)

2uj
ss

2

c

xL
1 = q0,
xL
k = max (xk−1, qk′−1) ,
xU
k = min (xk+1, qk′ ) ,
xU
n = qc.

k = 2, 3, . . . , n,
k = 1, 2, . . . , n − 1,

Fix all components of x ∈ S (ν) except for xk which
is allowed to vary in the segment (cid:0)xL
k(cid:1). The negative
derivative (33a) implies that fk (· , uss) is strictly decreasing in
k(cid:1) with all other variables ﬁxed. In addition, (32)
k , xU
xk ∈(cid:0)xL
this function tends to +∞ and −∞ as xk
implies that
tends to xL
k , respectively. Thus, it is concluded that

k and xU

k , xU

fk (x, uss) = 0 has one and only one solution for xk in

the interval xk ∈ (cid:0)xL

This solution depends on x1, . . . , xk−1, xk+1, . . . , xn and is
denoted by

k(cid:1), with all other variables ﬁxed.

k , xU

gk (x) = gk (x1, . . . , xk−1, xk+1, . . . , xn) .

Let g : Rn → Rn be a vector-valued function with the
components gk, k = 1, 2, . . . , n. Then, xss is a solution to (31),
if and only if it is a ﬁxed point of the mapping g, i.e., if it
solves

x = g (x) .

It is proven next that (31) has exactly one solution in S (ν)
by showing that g is a contraction map on S (ν), and thereby
it has exactly one ﬁxed point in this set.

The gradient ∇xgk of the scalar function gk is obtained as

follows. Based on the deﬁnition of gk, the identity

fk (x, uss)(cid:12)(cid:12)xk=gk(x1,...,xk−1,xk+1,...,xn) = 0

holds true for any (x1, . . . , xk−1, xk+1, . . . , xn) ∈ S (ν ′),
where the components of ν ′ are similar to ν except for ν ′
k
which is equal to νk − 1. Differentiating this identity with
respect to xi 6= xk leads to
∂fk
∂xk

(x, uss) +

∂fk
∂xi

∂gk
∂xi

(x) = 0.

(x, uss)

Solving this equation for ∂gk/∂xi results in

∂gk
∂xi

(x) = −(cid:18) ∂fk

∂xk

(x, uss)(cid:19)−1 ∂fk

∂xi

(x, uss) .

(34)

Since gk does not depend on xk, its partial derivative with
respect to xk is identically 0 so that

∂gk
∂xk

(x) = 0.

Substituting the explicit expressions (33) into (34) and noting
that uj

ss > 0, it is straightforward to verify that

k∇xgk (x)k1 =

< 1,

k = 1, 2, . . . , n.

∂gk
∂xi

n

Xi=1(cid:12)(cid:12)(cid:12)(cid:12)

(x)(cid:12)(cid:12)(cid:12)(cid:12)

Let x, y ∈ S (ν) and consider the line segment
s ∈ [0, 1] .

ℓ (s) = sx + (1 − s) y,

Since S (ν) is a convex set, all points on this line segment
are inside the set. Applying the mean value theorem [44] to
the scalar function gk ◦ ℓ implies that there exists s∗
k ∈ (0, 1)
such that

gk ◦ ℓ (1) − gk ◦ ℓ (0) =

dgk ◦ ℓ

ds

(s∗
k)
k)))T ℓ′ (s∗
= (∇xgk (ℓ (s∗

k) .

Substituting gk ◦ ℓ (1) = gk (x), gk ◦ ℓ (0) = gk (y), and
k) = x − y into this equality and taking absolute values
ℓ′ (s∗
of its sides lead to

|gk (x) − gk (y)| =(cid:12)(cid:12)(cid:12)

(∇xgk (ℓ (s∗
6 k∇xgk (ℓ (s∗

k)))T (x − y)(cid:12)(cid:12)(cid:12)

k))k1 kx − yk∞ .

13

Because this inequality holds for every k = 1, 2, . . . , n, it is
concluded that

kg (x) − g (y)k∞ 6 K kx − yk∞ ,

where

K = max

k=1,2,...,nk∇xgk (ℓ (s∗
This veriﬁes that g is a contraction map.

k))k1 < 1.

Finally, it is shown that V (· , uss) is strictly convex on
S (ν), and thereby the solution xss
to (31) is a stable
equilibrium. The Gerˇsgorin circle theorem [45] applied to the
Jacobian matrix of the vector ﬁeld f (· , uss) implies that the
eigenvalues ̺ of this matrix are inside the circles of the form

∂fk
∂xk

̺ −

(cid:12)(cid:12)(cid:12)(cid:12)

(x, uss)(cid:12)(cid:12)(cid:12)(cid:12)

6

n

Xi=1

i6=k

(cid:12)(cid:12)(cid:12)(cid:12)

∂fk
∂xi

.

(x, uss)(cid:12)(cid:12)(cid:12)(cid:12)

Since ∂fk/∂xk < 0 according to (33) and the right-hand side
of the inequality is smaller than |∂fk/∂xk|, the eigenvalues
of the Jacobian matrix have negative values.

REFERENCES

[1] G. M. Whitesides and B. Grzybowski, “Self-assembly at all scales,”

Science, vol. 295, no. 5564, pp. 2418–2421, 2002.

[2] G. M. Whitesides and M. Boncheva, “Beyond molecules: Self-assembly
of mesoscopic and macroscopic components,” Proceedings of the Na-
tional Academy of Sciences, vol. 99, no. 8, pp. 4769–4774, 2002.

[3] B. Amir Parviz, D. Ryan, and G. M. Whitesides, “Using self-assembly
for the fabrication of nano-scale electronic and photonic devices,” Trans.
Adv. Packag., vol. 26, no. 3, pp. 233–241, 2003.

[4] S. Zhang, “Fabrication of novel biomaterials through molecular self-
assembly,” Nature Biotechnology, vol. 21, no. 10, pp. 1171–1178, 2003.
[5] S. Ouk Kim, H. H. Solak, M. P. Stoykovich, N. J. Ferrier, J. J. de Pablo,
and P. F. Nealey, “Epitaxial self-assembly of block copolymers on
lithographically deﬁned nanopatterned substrates,” Nature, vol. 424,
no. 6947, pp. 411–414, 2003.

[6] C. Park, J. Yoon, and E. L. Thomas, “Enabling nanotechnology with
self assembled block copolymer patterns,” Polymer, vol. 44, no. 22,
pp. 6725–6760, 2003.

[7] J. Y. Cheng, A. M. Mayes, and C. A. Ross, “Nanostructure engineering
by templated self-assembly of block copolymers,” Nature Materials,
vol. 3, no. 11, pp. 823–828, 2004.

[8] J. C. Love, L. A. Estroff, J. K. Kriebel, R. G. Nuzzo, and G. M.
Whitesides, “Self-assembled monolayers of thiolates on metals as a form
of nanotechnology,” Chem. Rev., vol. 105, no. 4, pp. 1103–1170, 2005.
[9] A. Khaled, S. Guo, F. Li, and P. Guo, “Controllable self-assembly of
nanoparticles for speciﬁc delivery of multiple therapeutic molecules to
cancer cells using RNA nanotechnology,” Nano Letters, vol. 5, no. 9,
pp. 1797–1808, 2005.

[10] G. A. Ozin, K. Hou, B. V. Lotsch, L. Cademartiri, D. P. Puzzo,
F. Scotognella, A. Ghadimi, and J. Thomson, “Nanofabrication by self-
assembly,” Materials Today, vol. 12, no. 5, pp. 12–23, 2009.

[11] L. M. Adleman, “Towards a mathematical

theory of self-assembly,”

Technical Report 00-722, University of Southern California, 2000.

[12] L. Adleman, Q. Cheng, A. Goel, M. Huang, and H. Wasserman,
“Linear self-assemblies: Equilibria, entropy, and convergence rates,” in
Proc. of the 6th International Conference on Difference Equations and
Applications, ICDEA 2001, (Augsburg, Germany), Jun. 2001.

[13] A. Carbone and N. C. Seeman, “Molecular tiling and DNA self-
assembly,” in Molecular Computing, pp. 61–83, Berlin Heidelberg:
Springer-Verlag, 2004.

[14] D. Soloveichik and E. Winfree, “Complexity of self-assembled shapes,”

SIAM Journal on Computing, vol. 36, no. 6, pp. 1544–1569, 2007.

[15] U. Majumder, S. Sahu, and J. H. Reif, “Stochastic analysis of reversible
self-assembly,” Journal of Computational and Theoretical Nanoscience,
vol. 5, no. 7, pp. 1289–1305, 2008.

[16] S. Hormoz and M. P. Brenner, “Design principles for self-assembly
with short-range interactions,” Proceedings of the National Academy
of Sciences, vol. 108, no. 13, pp. 5193–5198, 2011.

[17] H. Chandran, N. Gopalkrishnan, and J. H. Reif, “Tile complexity
of linear assemblies,” SIAM Journal on Computing, vol. 41, no. 4,
pp. 1051–1073, 2012.

[18] M. J. Patitz, “An introduction to tile-based self-assembly and a survey

of recent results,” Natural Computing, pp. 1–30, 2013.

[43] H. Kang and W. Weinberg, “Dynamic Monte Carlo simulations of
surface-rate processes,” Acc. Chem. Res., vol. 25, no. 6, pp. 253–259,
1992.

[44] T. M. Apostol, Calculus, vol. 1. New York: Wiley, 2nd ed., 1967.
[45] R. S. Varga, Gerˇsgorin and His Circles. Berlin; New York: Springer,

[19] N. L. Rosi and C. A. Mirkin, “Nanostructures in biodiagnostics,”

2004.

14

Chemical Reviews, vol. 105, no. 4, pp. 1547–1562, 2005.

[20] N. Stephanopoulos, E. O. P. Solis, and G. Stephanopoulos, “Nanoscale
process systems engineering: Toward molecular factories, synthetic cells,
and adaptive devices,” AIChE Journal, vol. 51, no. 7, pp. 1858–1869,
2005.

[21] A. Winkleman, B. D. Gates, L. S. McCarty, and G. M. Whitesides,
“Directed self-assembly of spherical particles on patterned electrodes by
an applied electric ﬁeld,” Advanced Materials, vol. 17, no. 12, pp. 1507–
1511, 2005.

[22] M. P. Stoykovich, H. Kang, K. C. Daoulas, G. Liu, C.-C. Liu, J. J.
de Pablo, M. M¨uller, and P. F. Nealey, “Directed self-assembly of block
copolymers for nanolithography: Fabrication of isolated features and
essential integrated circuit geometries,” ACS Nano, vol. 1, no. 3, pp. 168–
175, 2007.

[23] R. A. Kiehl, “DNA-directed assembly of nanocomponents for nanoelec-
tronics, nanophotonics and nanosensing,” in Proc. of SPIE, vol. 6768,
pp. 67680Z–1–67680Z–7, 2007.

[24] C. H. Lalander, Y. Zheng, S. Dhuey, S. Cabrini, and U. Bach, “DNA-
directed self-assembly of gold nanoparticles onto nanopatterned sur-
faces: Controlled placement of individual nanoparticles into regular
arrays,” ACS Nano, vol. 4, no. 10, pp. 6153–6161, 2010.

[25] E. O. P. Solis, P. I. Barton, and G. Stephanopoulos, “Controlled
formation of nanostructures with desired geometries. 1. robust static
structures,” Ind. Eng. Chem. Res., vol. 49, no. 17, pp. 7728–7745, 2010.
[26] E. O. P. Solis, P. I. Barton, and G. Stephanopoulos, “Controlled
formation of nanostructures with desired geometries. 2. robust dynamic
paths,” Ind. Eng. Chem. Res., vol. 49, no. 17, pp. 7746–7757, 2010.

[27] R. Lakerveld, G. Stephanopoulos, and P. I. Barton, “A master-equation
approach to simulate kinetic traps during directed self-assembly,” J.
Chem. Phys., vol. 136, no. 184109, 2012.

[28] R. F. Probstein, Physicochemical Hydrodynamics: An Introduction. New

York: John Wiley & Sons, 2nd ed., 1994.

[29] B. U. Felderhof, “Brownian motion and creeping ﬂow on the Smolu-
chowski time scale,” Physica A: Statistical Mechanics and its Applica-
tions, vol. 147, no. 1, pp. 203–218, 1987.

[30] B. Øksendal, Stochastic Differential Equations. Berlin; New York:

Springer, 6th ed., 2003.

[31] G. E. Uhlenbeck and L. S. Ornstein, “On the theory of the Brownian

motion,” Physical Review, vol. 36, no. 5, pp. 823–841, 1930.

[32] J.-N. Roux, “Brownian particles at different times scales: a new deriva-
tion of the Smoluchowski equation,” Physica A: Statistical Mechanics
and its Applications, vol. 188, no. 4, pp. 526–552, 1992.

[33] C. Soize, The Fokker-Planck Equation for Stochastic Dynamical Systems
and Its Explicit Steady State Solutions. Singapore; Teaneck, NJ: World
Scientiﬁc, 1994.

[34] M. B´ona, A Walk Through Combinatorics: An Introduction to Enumera-
tion and Graph Theory. Hackensack, NJ: World Scientiﬁc Pub., 2nd ed.,
2006.

[35] J. E. Kolassa, Series Approximation Methods in Statistics. New York:

Springer-Verlag, 1994.

[36] J. L. Jensen, Saddlepoint Approximations. Oxford: Clarendon Press,

1995.

[37] Z. Gaji´c and M. T. J. Qureshi, The Lyapunov Matrix Equation in System

Stability and Control. San Diego, CA: Academic Press, 1995.

[38] D. Liberzon and R. W. Brockett, “Spectral analysis of Fokker-Planck and
related operators arising from linear stochastic differential equations,”
SIAM Journal on Control and Optimization, vol. 38, no. 5, pp. 1453–
1467, 2000.

[39] P. Kesavan, R. J. Allgor, E. P. Gatzke, and P. I. Barton, “Outer ap-
proximation algorithms for separable nonconvex mixed-integer nonlinear
programs,” Mathematical Programming, vol. 100, no. 3, pp. 517–535,
2004.

[40] M. Tawarmalani and N. V. Sahinidis, Convexiﬁcation and Global Op-
timization in Continuous and Mixed-Integer Nonlinear Programming:
Theory, Algorithms, Software, and Applications. Dordrecht; Boston:
Kluwer Academic Publishers, 2002.

[41] B. A. Cipra, “An introduction to the Ising model,” American Mathemat-

ical Monthly, vol. 94, no. 10, pp. 937–959, 1987.

[42] X. Guo and O. Hern´andez-Lerma, Continuous-Time Markov Decision
Processes: Theory and Applications. Heidelberg; New York: Springer
Verlag, 2009.

