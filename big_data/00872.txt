6
1
0
2

 
r
a

M
2

 

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
2
7
8
0
0

.

3
0
6
1
:
v
i
X
r
a

Principal Component Analysis

of Quantum Correlation

Renzo Mosetti∗

University of Trieste

Department of Mathematics and Geoscience, Via Weiss, 4, 34127, Trieste, ITALY

March 4, 2016

Abstract.The concept of quantum correlation matrix for observables
leads to the application of the PCA (Principal Component Analysis) also
for quantum system in Hilbert space. It is shown that, in the case of a 2x2
spin system where the observables are the Pauli matrices and a polarization
vector is acting on the density matrix, meaningful results can be obtained
by the PCA in terms of qubit properties. In particular, it is shown that by
choosing, for example, the (x,z) spinors, the axes of the principal components
(PC) coincide with the circular polarization basis on the Block Sphere.

1

Introduction

The interest in quantum computation has raised a huge number of papers
concerning the statistical properties of quantum systems. In particular the
concept of quantum Principal Component Analysis (qPCA) has been deﬁned
[1] . However, in the context of this paper, the qPCA is introduced as an
algorithm for quantum tomography. Quantum tomography is the process of
obtaining features of an unknown quantum state deﬁned by a density matrix
̺. The authors make use of the standard PCA on multiple copies of an
unknown density matrix to construct the eigenstates corresponding to the
large eigenvalues of the state. In practice, the qPCA is a method to derive,
in a eﬃcient computational way , the eigenvalues and eigenvectorrs of ̺.
Actually, in analogy of what happens in the classical correlation analysis, no
deﬁnition of PCA in terms of quantum correlation among observables has
been derived. The aim of this paper is to show that it is possible, starting

∗rmosetti@ogs.trieste.it

1

from a possible deﬁnition of a quantum correlation function, to derive a PCA
following the classical development of the standard correlation analysis.

2 Quantum Correlation Matrix and PCA

A proposed deﬁnition of a quantum mechanical correlation function has been
developed in the framework of the classical limit of quantum mechanics [2].
By diﬀerent considerations, the same correlation function has been suggested
by Andersen in an interesting lecture note [3]. The deﬁnition is based on the
well known concept of average and variance of quantum observables within
the Heisenberg picture. It is a reasonable deﬁnition for quantum mechanical
correlation and has many of the properties of classical equilibrium correlation
functions. In this paper the deﬁnition by Andersen is accepted and, as will
be more clear later, this choice give rise to interesting developments in terms
of application also to quantum computing. In this paper we are considering
for our purposes only the correlation at zero time lag yielding the usual
correlation matrix.

Let O1; O2; ....; On a set of observables. Giving the density matrix ̺ de-
scribing the quantum system under consideration, the variance of an observ-
able (assumed or reduced to a zero average value) Oi is given by:

var(Oi) = tr(ρO2
i )

(1)

In a similar way, the quantum correlation SOiOj between two observable Oi
and Oj is deﬁned as:

Now, it is possible to construct the Correlation Matrix S in the same way as
for the classical correlation analysis:

SOiOj ≡ tr(ρOiOj)

(2)

tr(ρO2
1)

tr(ρO1O2)

tr(ρO2O1)

tr(ρO2
2)

S ≡




....

tr(ρOnO1)

....
....

....
....
....
.....

tr(ρO1On)
tr(ρO2On)

....

tr(ρO2
n)




(3)

Remark. The matrix S could be non-Hermitian since, contrary of what
happens in the ordinary correlation, the elements tr(ρOiOj), tr(ρOjOi) could
be not the same due to the fact that operators do not in general commute.
However, it is possible to deﬁne: φAB = 1/2(SAB + SBA) then the function
φ has the same properties of the classical correlation function.

At this point a question could be raised. Is it possible to extend in a formal
way the Principal Components Analysis (PCA) to the quantum correlation

2

matrix so deﬁned? If the answer is yes, what is the meaning of the Principal
Components for a quantum system. As a ﬁrst insight, the ﬁrst PC constitutes
a new coordinate axis in the variable space which is oriented in order to
maximize the variations of the projections of the data points on this axis. It
is clear that, within the quantum mechanics context, the projection is the
process of measuring an observable and then, the ﬁrst PC may represent the
measurement of an observable along the axis of the maximum of the variance
of the measurements. So, this seems to be reasonable and potentially useful
also for quantum systems.

2.1 The PCA theorem

We recall that the PCA [4] are deﬁned within an Euclidean space Rn as the
problem to ﬁnd the maximum of the function var(z) = aT Sa ≡ V (a) where:
a ∈ Rn; z = aT x; and being S the covariance (correlation) matrix of the n
dimensional vectors of variables x. In the case, where observables are matrices
(let’s consider only the ﬁnite dimensional case), one has to move to the space:
M(n, C) being n the order of the matrix. The problem becomes : ﬁnd the
maximal variance, as deﬁned in (1), of a matrix P expressed as a linear
combination of observable matrices where the elements of the combination
are complex parameters ai subjected to the constraint: Σia∗

i ai = 1

2.1.1 THEOREM: Principal Components on a Matrix Space

The maximum of the variance of a Matrix P expressed as:
P = a1O1 + a2O2 + .... + anOn with the constraint Σia∗

i ai = 1 is equal to
the maximum of the eigenvalues λ1 of the covariance matrix S and the n coef-
ﬁcients ai are the components of the complex vector which is the eigenvector
a1 of λ1.

PROOF. Let’s deﬁne the function F (a) = tr[(̺(a1O1 + a2O2 + .. +
1 − a2
anOn)2] + λ(1− a2
n) whereλ are the Lagrange multipliers related
to the constraint for the maximization problem. The necessary conditions
for the maximum are;

1− ...− a2

∂F/∂a1 = 0; ∂F/∂a2 = 0; ..∂F/∂an = 0;

By using the properties of the trace, we obtain:

∂F/∂ai = 2aitr(ρO2

1) + 2Σj=1,i6=jajtr(ρOiOj) − 2λai = 0

By rearranging the above expression we get:

3

aitr(ρO2

1) + Σj=1,i6=jajtr(ρOiOj) = λai

For i = 1, n the following eigenvalue problem is obtained in compact form:

Sa = λa

where:

tr(ρO2
1)

tr(ρO1O2)

tr(ρO2O1)

tr(ρO2
2)

S =




....

tr(ρOnO1)

....
....

....
....
....
.....

tr(ρO1On)
tr(ρO2On)

....

tr(ρO2
n)




Note that S is exactly the quantum covariance matrix as deﬁned in (3).

This gives the proof of the theorem.

3 Application to a 2x2 spin system

In order to show in a speciﬁc case what could be the potentialities of the
extension of the PCA to a set of observables by using the quantum correlation
matrix, an application will be given for a 2x2 spin system. This leads to
interesting implications to quantum computing, being the 2x2 spin system
the usual qubit representation space. Let’s start from the observables that
in this case are the Pauli matrices:

σx = (cid:18)0 1

1 0(cid:19) ; σy = (cid:18)0 −i

0 (cid:19) ; σz = (cid:18)1

i

0

0 −1(cid:19)

The general form of the density matrix ρ where a polarization vector

P = (P x, P y, P z) is acting on the system, is:

P x + iP y

ρ = 1/2(cid:18) 1 + P z
For pure state |P| = 1 while for mixed states |P| < 1. Now, for any pairs

1 − P z (cid:19)
P x − iP y

of Pauli matrices, the elements of the correlation matrix are:

Si,j = tr(ρσiσj)

(4)

Consider, for instance :

4

1 (cid:19)
Sx,z = (cid:18) 1 −iP y

iP y

The PCA are obtained by solving the eigenvalue problem:
S |φi = λ |φi .
Explicit computation for Sx,z gives:

λ1 = 1 + P y;

λ2 = 1 − P y

The corresponding eigenvectors are (after a normalization) :

|φ1i = (−i√2, 1/√2)T ; |φ2i = (i√2, 1/√2)T

(5)

This process is equivalent to ﬁnd the coordinate system in which the corre-
lation matrix is diagonal. The eigenvector with the largest eigenvalue (λ1)
is along the direction of the highest variance, the second eigenvalue (λ2)
corresponds to the lowest variance and the relative eigenvector lies in an
orthogonal direction. Now, let us express the eigenvectors in the so called
standard computational basis on the Bloch Sphere:

|0i = (1, 0)T ;

|1i = (0, 1)T

The new basis vectors that can be derived from (5) are:

|0′i = 1/√2(|0i + i|1i)

|1′i = 1/√2(|0i − i|1i)

The principal axes obtained by PCA analysis in this case correspond to
the choice of the circular polarization basis for qubits which is well known
basis and which is used for quantum gates. The PCA are :

P1 = −i/√2(cid:18)0 −i

0 (cid:19) + 1/√2(cid:18)0 −i
0 (cid:19)

i

i

P2 = i/√2(cid:18)0 −i

0 (cid:19) + 1/√2(cid:18)0 −i
0 (cid:19)

i

i

It is easy to show that P1 and P2 are uncorrelated according to deﬁnition
(2). The meaning of the PCA matrices follows from the computation of the
variance as deﬁned in (1). Explicit computation gives:

var(P1) = 1 + Py;

var(P2) = 1 − Py

This is fully consistent with the PCA since the variances correspond to the
eigenvalues λ1 and λ2 obtained by the eigenvalue problem. The maximum
of the variance (by assuming Py > 0) is contained in the ﬁrst Principal
Component P1 and the value is that of the corresponding eigenvalue λ1.

5

4 Conclusions

The idea behind this paper was to investigate the possibility to prove that
a deﬁnition of quantum correlation between observables leads to further im-
provements in quantum statistical properties. In particular it has been shown
that the Principal Component Analysis can be performed on the quantum
correlation matrix. The obtained results seem to be very fruitful and open
the door to some applications to quantum computing. The fact to project
quantum states on axes of maximal variance may be used for instance in
quantum data compression. In a very interesting paper on this subject [5]
the application of the Schur-Weyl transform is used to compress an ensamble
of identically prepared qubits.It is well known, from a mathematical point of
view, that relationships exist between Singular Value Decomposition, PCA
[6] and the Schur-Weyl theory [7]. These aspects have to be investigated in
more detail in the framework of quantum statistics and quantum computing.

References

[1] S. Lloyd, M. Mohseni and P. Rebentrost: arXiv:1307.0401v2 [quant-ph]

2013.

[2] C. Anastopoulos: arXiv:gr-qc/0011111v2, 2008.

[3] H.C. Andersen: Stanford University, Lecture Notes 12. Quantum Corre-

lation functions, 2009.

[4] I.T. Jolliﬀe: Principal Component Analysis, 2002: Springer series in

Statistics.

[5] L.A. Rozema, D.H. Mahler, A. Hayat, P.S. Turner and A.M Steimberg:

arXiv:1410.3941v1 [quant-ph], 2014.

[6] M.E. Wall, A. Rechtsteiner and L.M. Rocha: Singular value decomposi-
tion and principal component analysis. In A Practical Approach to Mi-
croarray Data Analysis. Kluwer: Norwell, MA. pp. 91-109 , 2003.

[7] L. Zhang: arXiv:1408.3782v5 [quant-ph], 2015.

6

