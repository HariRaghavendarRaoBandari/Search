Self-stabilizing Balls & Bins in Batches

The Power of Leaky Bins

Petra Berenbrink∗1, Tom Friedetzky†2, Peter Kling‡1,

Frederik Mallmann-Trenn§1,3, Lars Nagel¶4, and Chris Wastell(cid:107)2
1Simon Fraser University, Burnaby, B.C., V5A 1S6, Canada

2Durham University, Durham DH1 3LE, U.K.
3École normale supérieure, 75005 Paris, France

4Johannes Gutenberg-Universität Mainz, 55128 Mainz, Germany

Abstract

A fundamental problem in distributed computing is the distribution of requests to a set of uniform
servers without a centralized controller. Classically, such problems are modelled as static balls into
bins processes, where m balls (tasks) are to be distributed to n bins (servers). In a seminal work,
Azar et al. [4] proposed the sequential strategy Greedy[d] for n = m. When thrown, a ball queries
the load of d random bins and is allocated to a least loaded of these. Azar et al. showed that d = 2
yields an exponential improvement compared to d = 1. Berenbrink et al. [7] extended this to m (cid:29) n,
showing that the maximal load diﬀerence is independent of m for d = 2 (in contrast to d = 1).

We propose a new variant of an inﬁnite balls into bins process. Each round an expected number
of λn new balls arrive and are distributed (in parallel) to the bins. Each non-empty bin deletes one
of its balls. This setting models a set of servers processing incoming requests, where clients can query
a server’s current load but receive no information about parallel requests. We study the Greedy[d]
distribution scheme in this setting and show a strong self-stabilizing property: For any arrival rate
λ = λ(n) < 1, the system load is time-invariant. Moreover, for any (even super-exponential) round

t, the maximum system load is (w.h.p.) O(cid:0) 1

(cid:1) for d = 1 and O(cid:0)log n

(cid:1) for d = 2. In

1−λ

particular, Greedy[2] has an exponentially smaller system load for high arrival rates.

1−λ · log n
1−λ

6
1
0
2

 
r
a

M
7

 

 
 
]

C
D
.
s
c
[
 
 

1
v
8
8
1
2
0

.

3
0
6
1
:
v
i
X
r
a

∗petra@cs.sfu.ca.
†tom.friedetzky@dur.ac.uk.
‡pkling@sfu.ca. Supported in part by the Paciﬁc Institute for the Mathematical Sciences.
§mallmann@di.ens.fr
¶nagell@uni-mainz.de. Supported by the German Ministry of Education and Research under Grant 01IH13004.
(cid:107)christopher.wastell@dur.ac.uk. Supported in part by EPSRC.

1

Introduction

1
One of the fundamental problems in distributed computing is the distribution of requests, tasks, or data
items to a set of uniform servers. In order to simplify this process and to avoid a single point of failure,
it is often advisable to use a simple, randomized strategy instead of a complex, centralized controller
to allocate the requests to the servers. In the most naïve strategy (1-choice), each client chooses the
server where to send its request uniformly at random. A more elaborate scheme (2-choice) chooses two
(or more) servers, queries their current loads, and sends the request to a least loaded of these. Both
approaches are typically modelled as balls-into-bins processes [2, 4, 5, 7, 13, 20, 22], where requests are
represented as balls and servers as bins. While the latter approach leads to considerably better load
distributions [4, 7], it loses some of its power in parallel settings, where requests arrive in parallel and
cannot take each other into account [2, 22].

We propose and study a new inﬁnite and batchwise balls-into-bins process to model the client-server
scenario. In a round, each server (bin) consumes one of its current tasks (balls). Afterward, (expectedly)
λn tasks arrive and are allocated using a given distribution scheme. The arrival rate λ is allowed to be
a function of n (e.g., λ = 1 − 1/poly(n)). Standard balls-into-bins results imply that, for high arrival
rates, with high probability1 (w.h.p.) each round there is a bin that receives Θ(log n) balls.
Most other inﬁnite processes limit the total number of concurrent balls in the system by n [4, 5] and
show a fast recovery. Since we do not limit the number of balls, our process can, in principle, result in an
arbitrarily high system load. In particular, if starting in a high-load situation (e.g., exponentially many
balls), we cannot recover in a polynomial number of steps. Instead, we adapt the following notion of
self-stabilization: The system is positive recurrent (expected return time to a low-load situation is ﬁnite)
and taking a snapshot of the load situation at an arbitrary (even super-exponential large) time yields
(w.h.p.) a low maximum load. Positive recurrence is a standard notion for stability and basically states
that the system load is time-invariant. For irreducible, aperiodic Markov chains it implies the existence
of a unique stationary distribution (cf. Section 1.2). While this alone does not guarantee a good load
in the stationary distribution, together with the snapshot property we can look at an arbitrarily time
window of polynomial size (even if it is exponentially far away from the start situation) and give strong
load guarantees. In particular, we give the following bounds on the load in addition to showing positive
recurrence:

(cid:1).
1-choice Process: The maximum load at an arbitrary time is (w.h.p.) bounded by O(cid:0) 1
1−λ · log n
1−λ
We also provide a lower bound which is asymptotically tight for λ ≤ 1 − 1/poly(n). While this
2-choice Process: The maximum load at an arbitrary time is (w.h.p.) bounded by O(cid:0)log n
(cid:1). This
implies that already the simple 1-choice process is self-stabilizing, the load properties in a “typical”
state are poor: even an arrival rate of only λ = 1 − 1/n yields a superlinear maximum load.
1−λ
allows to maintain an exponentially better system load compared to the 1-choice process; for any
λ = 1 − 1/poly(n) the maximum load remains logarithmic.

1.1 Related Work
Let us continue with an overview of related work. We start with classical results for sequential and ﬁnite
balls-into-bins processes, go over to parallel settings, and give an overview over inﬁnite and batch-based
processes similar to ours. We also brieﬂy mention some results from queuing theory (which is related
but studies slightly diﬀerent quality of service measures and system models).

m · ln(n)/n(cid:1) [20] and m/n + ln ln(n)/ ln d + Θ(1) [7], respectively.

Sequential Setting. There are many strong, well-known results for the classical, sequential balls-into-
bins process. In the sequential setting, m balls are thrown one after another and allocated to n bins. For
maximum load increases to m/n + Θ(cid:0)(cid:112)
m = n, the maximum load of any bin is known to be (w.h.p.) (1 + o(1)) · ln(n)/ ln ln n for the 1-choice
process [13, 20] and ln ln(n)/ ln d + Θ(1) for the d-choice process with d ≥ 2 [4]. If m ≥ n · ln n, the
In particular, note that the number of balls above the average grows with m for d = 1 but is independent
of m for d ≥ 2. This fundamental diﬀerence is known as the power of two choices. A similar (if slightly
weaker) result was shown by Talwar and Wieder [24] using a quite elegant proof technique (which we
also employ and generalize for our analysis in Section 3). Czumaj and Stemann [11] study adaptive
allocation processes where the number of a ball’s choices depends on the load of queried bins. The
authors subsequently analyze a scenario that allows reallocations.
1An event E occurs with high probability (w.h.p.) if Pr(E) = 1 − n−Ω(1).

2

Berenbrink et al. [9] adapt the threshold protocol from [2] (see below) to a sequential setting and
m ≥ n bins. Here, ball i randomly choose a bin until it sees a load smaller than 1 + i/n. While this is
a relatively strong assumption on the balls, this protocol needs only O(m) choices in total (allocation
time) and achieves an almost optimal maximum load of (cid:100)m/n(cid:101) + 1.
Parallel Setting. Several papers (e.g. [2, 22]) investigated parallel settings of multiple-choice games
for the case m = n. Here, all m balls have to be allocated in parallel, but balls and bins might employ
some (limited) communication. Adler et al. [2] consider a trade-oﬀ between the maximum load and the
number of communication rounds r the balls need to decide for a target bin. Basically, bounds that are
close to the classical (sequential) processes can only be achieved if r is close to the maximum load [2].
The authors also give a lower bound on the maximum load if r communication rounds are allowed, and
Stemann [22] provides a matching upper bound via a collision-based protocol.

In inﬁnite processes, the number of balls to be thrown is not ﬁxed. Instead, in
Inﬁnite Processes.
each of inﬁnitely many rounds, balls are thrown or reallocated while and bins possibly delete old balls.
Azar et al. [4] consider an inﬁnite, sequential process starting with n balls arbitrarily assigned to n bins.
In each round one random ball is reallocated using the d-choice process. For any t > cn2 log log n, the
maximum load at time t is (w.h.p.) ln ln(n)/ ln d + O(1).
Adler et al. [1] consider a system where in each round m ≤ n/9 balls are allocated. Bins have a
FIFO-queue, and each arriving ball is stored in the queue of two random bins. After each round, every
non-empty bin deletes its frontmost ball (which automatically removes its copy from the second random
bin). It is shown that the expected waiting time is constant and the maximum waiting time is (w.h.p.)
ln ln(n)/ ln d + O(1). The restriction m ≤ n/9 is the major drawback of this process. A diﬀerential
and experimental study of this process was conducted in [6]. The balls’ arrival times are binomially
distributed with parameters n and λ = m/n. Their results indicate a stable behaviour for λ ≤ 0.86. A
similar model was considered by Mitzenmacher [18], who considers ball arrivals as a Poisson stream of
rate λn for λ < 1. It is shown that the 2-choice process reduces the waiting time exponentially compared
to the 1-choice process.

Czumaj [10] presents a framework to study the recovery time of discrete-time dynamic allocation
processes.
In each round one of n balls is reallocated using the d-choice process. The ball is chosen
either by selecting a random bin or by selecting a random ball. From an arbitrary initial assignment, the

system is shown to recover to the maximum load from [4] within O(cid:0)n2 ln n(cid:1) rounds in the former and

O(n ln n) rounds in the latter case. Becchetti et al. [5] consider a similar process with only one random
choice per ball, also starting from an arbitrary initial assignment of n balls. In each round, one ball is
chosen from every non-empty bin and reallocated randomly. The authors deﬁne a conﬁguration to be
legitimate if the maximum load is O(log n). They show that (w.h.p.) any state recovers in linear time
to a legitimate state and maintain such a state for poly(n) rounds.

Batch-Processes. Batch-based processes allocate m balls to n bins in batches of (usually) n balls
each, where each batch is allocated in parallel. They lie between (pure) parallel and sequential processes.
For m = τ · n, Stemann [22] investigates a scenario with n players each having m/n balls. To allocate a
ball, every player independently chooses two bins and allocates copies of the ball to both of them. Every
bin has two queues (one for ﬁrst copies, one for second copies) and processes one ball from each queue
per round. When a ball is processed, its copy is removed from the system and the player is allowed to
initiate the allocation of the next ball. If τ = ln n, all balls are processed in O(ln n) rounds and the
waiting time is (w.h.p.) O(ln ln n). Berenbrink et al. [8] study the d-choice process in a scenario where
m balls are allocated to n bins in batches of size n each. The authors show that the load of every bin is
(w.h.p.) m/n ± O(log n). As noted in Lemma 3.5, our analysis can be used to derive the same result by
easier means.

Queuing Processes. Batch arrival processes have also been considered in the context of queuing
systems. A key motivation for such models stems from the asynchronous transfer mode (ATM) in
telecommunication systems. Tasks arrive in batches and are stored in a FIFO queue. Several papers [3,
15, 16, 21] consider scenarios where the number of arriving tasks is determined by a ﬁnite state Markov
chain. Results study steady state properties of the system to determine properties of interest (e.g.,
waiting times or queue lengths). Sohraby and Zhang [21] use spectral techniques to study a multi-server
scenario with an inﬁnite queue. Alfa [3] considers a discrete-time process for n identical servers and tasks
with constant service time s ≥ 1. To ensure a stable system, the arrival rate λ is assumed to be ≤ n/s

3

and tasks are assigned cyclical, allowing to study an arbitrary server (instead of the complete system).
Kamal [15] and Kim et al. [16] study a system with a ﬁnite capacity. Tasks arriving when the buﬀer is
full are lost. The authors study the steady state probability and give empirical results to show the decay
of waiting times as n increases.

1.2 Model & Preliminaries
We model our load balancing problem as an inﬁnite, parallel balls-into-bins processes. Time is divided
into discrete, synchronous rounds. There are n bins and n generators, and the initial system is assumed to
be empty. At the start of each round, every non-empty bins deletes one ball. Afterward, every generator
generates a ball with a probability of λ = λ(n) ∈ [0, 1] (the arrival rate). This generation scheme allows
us to consider arrival rates that are arbitrarily close to one (like 1 − 1/poly(n)). Generated balls are
distributed in the system using a distribution process. In this paper we analyze two speciﬁc distribution
processes: (a) The 1-choice process Greedy[1] assigns every ball to a randomly chosen bin. (b) The
2-choice process Greedy[2] assigns every ball to a least loaded among two randomly chosen bins.

(cid:80)n

n

of empty bins after round t. It will be useful to deﬁne 1i(t) := min(cid:0)1, Xi(t)(cid:1) and ηi(t) := 1i(t) − ν(t)

Notation. The random variable Xi(t) denotes the load (number of balls) of the i-th fullest bin at the
end of round t. Thus, the load situation (conﬁguration) after round t can be described by the load vector
X(t) = (Xi(t))i∈[n] ∈ Nn. We deﬁne ∅(t) := 1
i=1 Xi(t) as the average load at the end of round t.
The value ν(t) denotes the fraction of non-empty bins after round t and η(t) := 1 − ν(t) the fraction
(which equals η(t) if i is a non-empty bin and −ν(t) otherwise).
Markov Chain Preliminaries. The evolution of the load vector over time can be interpreted as
a Markov chain, since X(t) depends only on X(t − 1) and the random choices during round t. We
refer to this Markov chain as X. Note that X is time-homogeneous (transition probabilities are time-
independent), irreducible (every state is reachable from every other state), and aperiodic (path lengths
have no period; in fact, our chain is lazy). Recall that such a Markov chain is positive recurrent (or
ergodic) if the probability to return to the start state is 1 and the expected return time is ﬁnite. In
particular, this implies the existence of a unique stationary distribution. Positive recurrence is a standard
formalization of the intuitive concept of stability. See [17] for an excellent introduction into Markov chains
and the involved terminology.

2 The 1-Choice Process
We present two main results for the 1-choice process: Theorem 2.1 states the stability of the system under
the 1-choice process for an arbitrary λ, using the standard notion of positive recurrence (cf. Section 1).
In particular, this implies the existence of a stationary distribution for the 1-choice process. Theorem 2.2
strengthens this by giving a high probability bound on the maximum load for an arbitrary round t ∈ N.
Together, both results imply that the 1-choice process is self-stabilizing.
Theorem 2.1 (Stability). Let λ = λ(n) < 1. The Markov chain X of the 1-choice process is positive
recurrent.
Theorem 2.2 (Maximum Load). Let λ = λ(n) < 1. Fix an arbitrary round t of the 1-choice process.

The maximum load of all bins is (w.h.p.) bounded by O(cid:0) 1
Note that for high arrival rates of the form λ(n) = 1 − ε(n), the bound given in Theorem 2.2 is
inversely proportional to ε(n). For example, for ε(n) = 1/n the maximal load is O(n log n). Theorem 2.3
shows that this dependence is unavoidable: the bound given in Theorem 2.2 is tight for large values of
λ. In Section 3, we will see that the 2-choice process features an exponentially better behaviour for large
λ.
Theorem 2.3. Let λ = λ(n) ≥ 0.5 and deﬁne t := 9λ log(n)/(64(1 − λ)2). With probability 1 − o(1)
The proofs of these results can be found in the following subsections. We ﬁrst prove a bound on the
maximum load (Theorem 2.2), afterwards we prove stability of the system (Theorem 2.1), and ﬁnally we
prove the lower bound (Theorem 2.3).

there is a bin i in step t with load Ω(cid:0) 1

1−λ · log n(cid:1).

(cid:1).

1−λ · log n
1−λ

4

2.1 Maximum Load – Proof of Theorem 2.2
Proof of Theorem 2.2 (Maximum Load). We prove Theorem 2.2 using a (slightly simpliﬁed) drift theo-
rem from Hajek [14] (cf. Theorem A.2 in Appendix A). Remember that, as mentioned in Section 1.2,
our process is a Markov chain, such that we need to condition only on the previous state (instead of
the full ﬁltration from Theorem (A.2)). Our goal is to bound the load of a ﬁxed bin i at time t using
Theorem A.2 and, subsequently, to use this with a union bound to bound the maximum load over all
bins. To apply Theorem A.2, we have to prove that the maximum load diﬀerence of bin i between two
rounds is is exponentially bounded (Majorization) and that, given a high enough load, the system tends
to loose load (Negative Bias). We start with the majorization. The load diﬀerence |Xi(t + 1) − Xi(t)|
is bounded by max(1, Bi(t)) ≤ 1 + Bi(t), where Bi(t) is the number of tokens resource i receives during
round t + 1. In particular, we have (|Xi(t + 1)− Xi(t)|| X(t)) ≺ 1 + Bi(t). Note that Bi(t) is binomially
distributed with parameters n and λ/n (each of the n balls has probability of λ · 1/n to end up in i).
Using standard inequalities we bound

Pr(Bi(t) = k) ≤

and calculate

eBi(t)+1(cid:105)
E(cid:104)

n(cid:88)

k=0

ek ·

= e ·

(cid:17)k

(cid:18) 1

(cid:19)k

·

n

=

ek
kk

(cid:19)k

≤

(cid:19)

(cid:18) λ
(cid:18)n
(cid:100)e3−1(cid:101)(cid:88)

k

n

·

(cid:16) e · n
∞(cid:88)

k

ek
kk ≤ e ·

e2k
kk + e ·

k=0

k=e3

∞(cid:88)

k=1

e2k
kk ≤ Θ(1) +

e−k = Θ(1).

(1)

(2)

This shows that the Majorization condition from Theorem A.2 holds (with λ(cid:48) = 1 and D = Θ(1)). To see
that the Negative Bias condition is also given, note that if bin i has non-zero load, it is guaranteed to delete
one ball and receives in expectation n·λ/n = λ balls. We get E[Xi(t + 1) − Xi(t) | Xi(t) > 0] ≤ λ−1 < 0,
establishing the Negative Bias condition (with ε0 = 1 − λ). We ﬁnally can apply Theorem A.2 with
η := min(1, (1 − λ)/2D, 1/(2 − 2λ)) = (1 − λ)/(2D) and get for b ≥ 0
ln(cid:0) c·na+1

(1 − λ)2 · e− b·(1−λ)
(cid:18) n
(cid:19)(cid:19)
≤ n−a. The theorem’s statement now follows from
c · (a + 1) + 1

η · (1 − λ) · eη·(1−b) ≤
(cid:1) yields Pr(cid:0)maxi∈[n] Xi(t) ≥ b(cid:1)
(cid:19)

where c denotes a suitable constant. Applying a union bound to all n bins and choosing b := c

2 · (2D)2
(1 − λ)2 · e
(cid:18) n
(cid:19)

(cid:18) c · na+1

Pr(Xi(t) ≥ b) ≤ e−b·η +

1−λ ·

(1−λ)·(1−b)

(1−λ)2

= O

(4)

(3)

c

,

b =

2D

=

2D

c

.

c

1 − λ · ln

(1 − λ)2

≤

1 − λ

· ln

1 − λ

(cid:18) 1
1 − λ · ln

1 − λ

2.2 Stability – Proof of Theorem 2.1
In the following, we provide an auxiliary lemma that will prove useful to derive the stability of the
1-choice process.

Lemma 2.4. Let λ = λ(n) < 1. Fix an arbitrary round t of the 1-choice process and a bin i. There is
a constant c > 0 such that the expected load of bin i is bounded by 6c
Proof. To get a bound on the expected load of bin i, note that the probability in Equation (3) (see proof
of Theorem 2.2) is 1 for b ≤ γ := c

1−λ · ln(cid:0) e·c

Considering time windows of γ rounds each, we calculate

(1−λ)2

1−λ

1−λ · ln(cid:0) e·c

(cid:1).

(cid:1).
∞(cid:88)

(k+1)γ(cid:88)

k=1

b=k·γ

5

γ(cid:88)

b=1

≤ γ +

∞(cid:88)

k=1

E[Xi(t)] ≤

b · Pr(Xi(t) = b) +

b · Pr(Xi(t) = b)

≤ 3γ ≤

This ﬁnishes the proof.

1 − λ · ln

(k + 1) · γ · Pr(Xi(t) ≥ k · γ) ≤ γ +
6c

(cid:19)

.

(cid:18) e · c

1 − λ

∞(cid:88)

k=1

(k + 1) · γ · e−k

(5)

state space. For a conﬁguration x we deﬁne the auxiliary potential Ψ(x) :=(cid:80)n
Proof of Theorem 2.1 (Stability). We prove Theorem 2.1 using a result from Fayolle et al. [12] (cf. Theo-
rem A.1 in Appendix A). Note that X is a time-homogenous irreducible Markov chain with a countable
i=1 xi as the total system
load of conﬁguration x. Consider the (ﬁnite) set C := { x | Ψ(x) ≤ n4/(1 − λ)2 } of all conﬁgurations
with not too much load. To prove positive recurrence, it remains to show that Condition (a) (expected
potential drop if not in a high-load conﬁguration) and Condition (b) (ﬁnite potential) of Theorem A.1
hold. In the following, let ∆ := n3
Let us start with Condition (a). So ﬁx a round t and let x = X(t) (cid:54)∈ C. By deﬁnition of C, we
have Ψ(x) > n4/(1 − λ)3, such that there is at least one bin i with load xi ≥ Ψ(x)/n > n3/(1 − λ)2. In
particular, note that xi ≥ ∆, such that during each of the next ∆ rounds exactly one ball is deleted. On
n = λ∆ balls during the next ∆ rounds. We get
the other hand, bin i receives in expectation ∆ · λn · 1
E[Xi(t + ∆) − xi | X(t) = x] = λ∆ − ∆ = −(1 − λ) · ∆. For any bin j (cid:54)= i, we assume pessimistically
that no ball is deleted. Note that the expected load increase of each of these bins can be majorized by
the load increase in an empty system running for ∆ rounds. Thus, we can use Lemma 2.4 to bound the
expected load increase in each of these bins by 6c

(1−λ)2 .

(cid:1)

1−λ · ln(cid:0) e·c

1−λ
E[Ψ(X(t + ∆)) | X(t) = x] ≤ −(1 − λ) · ∆ + (n − 1) ·

≤ 6e·c2

(cid:19)
(1−λ)2 ≤ ∆/n2. We get

(cid:18)

∆
n2 = −∆ ·

1 − λ −

1
n

≤ −∆ ·

1 − λ

2

.

This proves Condition (a) of Theorem A.1. For Condition (b), assume x = X(t) ∈ C. We bounds the
system load after ∆ rounds trivially by

E[Ψ(X(t + ∆)) | X(t) = x] ≤ Ψ(x) + ∆ · n ≤

n4

(1 − λ)2 + ∆ · n < ∞

(note that the ﬁniteness in Theorem A.1 is with respect to time, not n). This ﬁnishes the proof.

(6)

2.3 Lower Bound on Maximum Load – Proof of Theorem 2.3
Proof of Theorem 2.3 (Lower Bound). To show this result we will use the bound of Theorem A.3 which
lower bounds the the maximum number of balls a bin receives when m balls are allocated into m bins.
The idea of the proof is as follows. We assume that we start at an empty system and apply Theorem A.3
on m = λtn many balls. The theorem says that one of the bins is likely to get much more than λt many
balls, which allows us to show that the load of this bin is large, even if the bin was able to delete a ball
during each of the t observed time steps.
Let m(t(cid:48)) the the number of balls allocated during the ﬁrst t(cid:48) steps and let bu(t(cid:48)) the number of
these balls that are allocated to bin u. Set t = 9λ log(n)/(64(1 − λ)2), assume λ > 0.5 and assume
λnt ≤ n · (log n)c for a constant c. Since the expected number of balls is λnt ≥ n log n we can use
Chernoﬀ bounds to show that w.h.p. at least (1 − ) · m(t) balls are generated for very small .

Then

Using Chernoﬀ’s inequality we can show that w.h.p. m(t) ≥ (1 − ) · 9λ log n
constant . By Theorem A.3 (Case 3) with α =

8/9 we get (w.h.p.)

64(1−λ)2 · λn for an arbitrary small

E[m(t(cid:48))] = 9λ log n

64(1−λ)2 · λn.

(cid:112)

(cid:115)

(1 − ) ·

16 · 9λ(log n)2
9 · 64(1 − λ)2 · λ.

(7)

bu(t) ≥ (1 − ) ·

9λ log n

64(1 − λ)2 · λ +

6

We derive

Xu(t) ≥ (1 − ) ·

9
64

λ2 log n

(1 − λ)2 +

(cid:115)

(1 − ) ·

(cid:114)

(1 − )

4

9λ log n
64(1 − λ)2

16 · 9λ2 · (log n)2
9 · 64(1 − λ)2 −
(1 − λ) −
·

λ log n

9λ log n
64(1 − λ)2

4

=

= λ · (1 − ) ·
(1 − )

(cid:114)
(cid:114)
(cid:114)
(cid:18) λ log n

(1 − )

(1 − )

≥

≥

4

4

·

= Ω

1 − λ

9
64

λ log n

(1 − λ)2 +

·

·

λ log n
(1 − λ)
λ log n
(1 − λ)
(cid:19)
λ log n
(1 − λ) − (cid:48) ·

.

9λ log n
64(1 − λ)2
9λ log n
64(1 − λ)2

+ (λ · (1 − ) − 1) ·

+ ((1 − (cid:48)) − 1) ·
λ log n
(1 − λ)

9
64

3 The 2-Choice Process
We continue with the study of the 2-choice process. Here, new balls are distributed according to
Greedy[2] (cf. description in Section 1.2). Our main results are the following theorems, which are
equivalents to the corresponding theorems for the 1-choice process.
Theorem 3.1 (Stability). Let λ = λ(n) ∈ [1/4, 1). The Markov chain X of the 2-choice process is
positive recurrent.
process. The maximum load of all bins is (w.h.p.) bounded by O(cid:0)log n
Theorem 3.2 (Maximum Load). Let λ = λ(n) ∈ [1/4, 1). Fix an arbitrary round t of the 2-choice
Note that Theorem 3.2 implies a much better behaved system than we saw in Theorem 2.2 for the
1-choice process. In particular, it allows for an exponentially higher arrival rate: for λ(n) = 1− 1/poly(n)
the 2-choice process maintains a maximal load of O(log n). In contrast, for the same arrival rate the
1-choice process results in a system with maximal load Ω(poly(n)).

Our analysis of the 2-choice process relies to a large part on a good bound on the smoothness (the
maximum load diﬀerence between any two bins). This is stated in the following lemma. This result is of
independent interest, showing that even if the arrival rate is 1 − e−n, where we get a polynomial system
load, the maximum load diﬀerence is still logarithmic.
Lemma 3.3 (Smoothness). Let λ = λ(n) ∈ [1/4, 1]. Fix an arbitrary round t of the 2-choice process.
The load diﬀerence of all bins is (w.h.p.) bounded by O(ln n).

(cid:1).

1−λ

(cid:88)

i∈[n]

Analysis Overview. To prove these results, we combine three diﬀerent potential functions: For a
conﬁguration x with average load ∅ and for a suitable constant α (to be ﬁxed later), we deﬁne

Φ(x) :=

eα·(xi−∅) +

eα·(∅−xi),

Ψ(x) :=

and

xi,

(8)

(cid:88)

i∈[n]

(cid:88)

Γ(x) := Φ(x) + n

i∈[n]
1−λ · Ψ(x).

The potential Φ measures the smoothness (basically the maximum load diﬀerence to the average) of a
conﬁguration and is used to prove Lemma 3.3 (Section 3.1). The proof is based on the observation that
whenever the load of a bin is far from the average load, it decreases in expectation. The potential Ψ
measures the total load of a conﬁguration and is used, in combination with our results on the smoothness,
to prove Theorem 3.2 (Section 3.2). The potential Γ entangles the smoothness and total load, allowing
us to prove Theorem 3.1 (Section 3.3). The proof is based on the fact that whenever Γ is large (i.e., the
conﬁguration is not smooth or it has a huge total load) it decreases in expectation.

Before we continue with our analysis, let us make a simple but useful observation concerning the
smoothness: For any conﬁguration x and value b ≥ 0, the inequality Φ(x) ≤ eα·b implies (by deﬁnition
of Φ) maxi|xi − ∅| ≤ b. That is, the load diﬀerence of any bin to the average is at most b and, thus, the
load diﬀerence between any two bins is at most 2b. We capture this in the following observation.

7

Observation 3.4. Let b ≥ 0 and consider a conﬁguration x with average load ∅. If Φ(x) ≤ eα·b, then
|xi − ∅| ≤ b for all i ∈ [n]. In particular, maxi(xi) − mini(xi) ≤ 2b.
3.1 Bounding the Smoothness
The goal of this section is to prove Lemma 3.3. To do so, we show the following bound on the expected
smoothness (potential Φ) at an arbitrary time t:
Lemma 3.5. Let λ ∈ [1/4, 1]. Fix an arbitrary round t of the 2-choice process. There is a constant
ε > 0 such that2
(9)

E[Φ(X(t))] ≤

n
ε

.

ε

i

i

Note that Lemma 3.5 together with Observation 3.4 immediately implies Lemma 3.3 by a simple

n2
ε2

(cid:19)

(cid:18)

Pr

max

(cid:16) n

(cid:17)(cid:19)

≤ Pr

4
α · ln

application of Markov’s inequality to bound the probability that Φ(X(t)) ≥ n2/ε.
Our proof of Lemma 3.5 follows the lines of [19, 24], who used the same potential function to analyze
variants of the sequential d-choice process without deletions. While the basic idea of showing a relative
drop when the potential is high combined with a bounded absolute increase in the general case is the
same, our analysis turns out much more involved. In particular, not only do we have to deal with deletions
and throwing balls in batches but the size of each batch is also a random variable. Once Lemma 3.5
is proven, Lemma 3.3 emerges by combining Observation 3.4, Lemma 3.5, and Markov’s inequality as
follows:

(cid:18)
potential in two parts Φ(x) := Φ+(x) + Φ−(x). Here, Φ+(x) := (cid:80)
tential of x and Φ−(x) := (cid:80)

It remains to prove Lemma 3.5. Remember the deﬁnition of Φ(x) from Equation (8). We split the
i eα·(xi−∅)) denotes the upper po-
i eα·(∅−xi)) denotes the lower potential of x. For a ﬁxed bin i, we use
Φi,+(x) := eα·(xi−∅) and Φi,−(x) := eα·(∅−xi) to denote i’s contribution to the upper and lower po-
tential, respectively. When we consider the eﬀect of a ﬁxed round t + 1, we will sometimes omit the
time parameter and use prime notation to denote the value of a parameter at the end of round t + 1.
for the load of bin i at the beginning and at the end of round t + 1,
For example, we write Xi and X(cid:48)i
respectively.
We start with two simple but useful identities regarding the potential drop ∆i,+(t+1) (and ∆i,−(t+1))

ε
n

.

≤

(10)

Xi(t) − min

Φ(X(t)) ≥

Xi(t) ≥

(cid:0)eα·(k−ηi(t)−K/n) − 1(cid:1) and
(cid:0)e−α·(k−ηi(t)−K/n) − 1(cid:1).

due to a ﬁxed bin i during round t + 1.
Observation 3.6. Fix a bin i, let K denote the number of balls that are placed during round t + 1 and
let k ≤ K be the number of these balls that fall into bin i. Then
(a) ∆i,+(t + 1) = Φi,+(X(t)) ·
(b) ∆i,−(t + 1) = Φi,−(X(t)) ·
We now derive the main technical lemma that states general bounds on the expected upper and
lower potential change during a single round. This will be used to derive bounds on the potential
change in diﬀerent situations. For this, let pi := ( i
(the probability that a ball
thrown with Greedy[2] falls into the i-th fullest bin). We also deﬁne ˆα := eα − 1 and ˇα := 1 − e−α.
Note that ˆα ∈ (α, α + α2) and ˇα ∈ (α − α2, α) for α ∈ (0, 1.7). This follows easily from the Taylor
approximation ex ≤ 1 + x + x2, which holds for any x ∈ (−∞, 1.7] (we will use this approximation several
times in the analysis). Finally, let ˆδi := λn · (1/n · ˇ1 − pi · ˆα/α) and ˇδi := λn · (1/n · ˆ1 − pi · ˇα/α), where
ˇ1 := 1− α/n < 1 < ˆ1 := 1 + α/n. These ˆδi and ˇδi values can be thought of as upper/lower bounds on the
expected diﬀerence in the number of balls that fall into bin i under the 1-choice and 2-choice process,
respectively (note that ˆ1, ˇ1, ˆα/α, and ˇα/α are all constants close to 1).
Lemma 3.7. Consider a bin i after round t and a constant α ≤ 1.
(cid:17)
(a) For the expected change of i’s upper potential during round t + 1 we have

n )2 − ( i−1

n )2 = 2i−1
n2

(cid:17)2

(cid:16)

(cid:16)

E[∆i,+(t + 1) | X(t)]

Φi,+(X(t))

≤ −α ·

ηi + ˆδi

+ α2 ·

ηi + ˆδi

.

(11)

2For Φ, the condition λ ≥ 1/4 can be substituted with λ = Ω(1) and only minor changes in the analysis. Moreover, the
analysis can be easily adapted for a process that (deterministically) throws λ · n balls in each round, even for λ > 1 as long
as it is a constant. Finally, one can easily adapt the analysis to cover the process without deletions by setting ηi(t) = 0
(see Observation 3.6). Using Markov’s inequality, this yields the same result as [8] using a simpler analysis.

8

(b) For the expected change of i’s lower potential during round t + 1 we have

E[∆i,−(t + 1) | X(t)]

Φi,−(X(t))

≤ α ·

.

(12)

(cid:0)ηi + ˇδi

(cid:0)ηi + ˇδi

(cid:1)2

(cid:1) + α2 ·
(cid:16)

=

=

K

k

K=0

k=0

(cid:19)

(cid:19)(cid:18)K

Proof. For the ﬁrst statement, we use Observation 3.6 to calculate E[∆i,+(t) | X]/Φi,+
(cid:17)
eα·(k−ηi−K/n) − 1
(cid:17)
eα·(k−ηi−K/n) − 1
(cid:17)
e−α(ηi+K/n) · (1 + ˆα · pi)K − 1

(cid:0)(1 − pi)λ(cid:1)K−k
(cid:19)
(cid:18)K
· (piλ)k ·
K(cid:88)
(cid:32)
(cid:19)
i · (1 − pi)K−k ·
K(cid:88)
(cid:16)

(cid:33)
· (eα · pi)k · (1 − pi)K−k − 1

· (1 − λ)n−K ·
(cid:16)

K(cid:88)
(cid:18) n
(cid:18) n
(cid:18) n

n(cid:88)
n(cid:88)
n(cid:88)
n(cid:88)

(cid:18) n
(cid:19)
(cid:19)
(cid:19)

(1 − λ)n−K · λK ·

(1 − λ)n−K · λK ·

(1 − λ)n−K · λK

(cid:18)K

e−α(ηi+K/n)

· pk

K=0

K=0

k=0

k=0

=

=

K

K

K

k

k

,

K=0

where we ﬁrst apply the law of total expectation together with Observation 3.6 and, afterward, twice
the binomial theorem. Continuing the calculation using the aforementioned Taylor approximation ex ≤
1 + x + x2 (which holds for any x ∈ (−∞, 1.7]), and the deﬁnition of ˆδi yields
(cid:17)n

(cid:0)1 − λ + λe−α/n · (1 + ˆα · pi)(cid:1)n
(cid:18)

(cid:0)1 − λ(1 − e−α/n) + λ · ˆα · pi
(cid:16)

(cid:19)n
− 1 ≤ e−αηi ·

(cid:1)n

− 1

λ · α
n · (1 − α/n) + λ · ˆα · pi

1 −

− 1 ≤ e−αηi ·

α
n · ˆδi

1 −

− 1 ≤ e−α·(ηi+ˆδi) − 1.

= e−αηi ·
≤ e−αηi ·

Now, the claim follows by another application of the Taylor approximation. The second statement follows
similarly.

Using Lemma 3.7, we derive diﬀerent bounds on the potential drop that will be used in the various

situations. The proofs for the following statements can all be found in Appendix C.

We start with a result that will be used when the potential is relatively high.

Lemma 3.8. Consider a round t and a constant α ≤ ln(10/9) (< 1/8). Let R ∈ { +,−} and λ ∈ [1/4, 1].
For the expected upper and lower potential drop during round t + 1 we have

E[∆R(t + 1) | X(t)] < 2αλ · ΦR(X(t)).

(13)

The next lemma derives a bound that is used to bound the upper potential change in reasonably

balanced conﬁgurations.
Lemma 3.9. Consider a round t and the constants ε (from Claim B.2) and α ≤ min(ln(10/9), ε/4).
4 n(t) ≤ ∅(t). For the expected upper potential drop during round t + 1 we
Let λ ∈ [1/4, 1] and assume X 3
have
(14)

E[∆+(t + 1) | X(t)] ≤ −εαλ · Φ+(X(t)) + 2αλn.

The next lemma derives a bound that is used to bound the lower potential drop in reasonably balanced

conﬁgurations.
Lemma 3.10. Consider a round t and the constants ε (from Claim B.2) and α ≤ min(ln(10/9), ε/8).
4 (t) ≥ ∅(t). For the expected lower potential drop during round t we have
Let λ ∈ [1/4, 1] and assume X n
E[∆−(t + 1) | X(t)] ≤ −εαλ · Φ−(X(t)) +
(15)

αλn

2

.

The next lemma derives a bound that will be used to bound the potential drop in conﬁgurations with

many balls far below the average to the right.
Lemma 3.11. Consider a round t and constants α ≤ 1/46 (< ln(10/9)) and ε ≤ 1/3. Let λ ∈ [1/4, 1] and
assume X 3
· Φ+(X(t)). Then we have either Φ+(X(t)) ≤
4 · Φ−(X(t)) or Φ(X(t)) = ε−8 · O(n).
ε

4 n(t) ≥ ∅(t) and E[∆+(t + 1) | X(t)] ≥ − εαλ

4

9

The next lemma derives a bound that will be used to bound the potential drop in conﬁgurations with

many balls far above the average to the left.
Lemma 3.12. Consider a round t and constants α ≤ 1/32 (< ln(10/9)) and ε ≤ 1. Let λ ∈ [1/4, 1] and
assume X n
· Φ−(X(t)). Then we have either Φ−(X(t)) ≤
4 · Φ+(X(t)) or Φ(X(t)) = ε−8 · O(n).
ε
a single round.

Putting all these lemmas together, we can derive the following bound on the potential change during

4 (t) ≤ ∅(t) and E[∆−(t + 1) | X(t)] ≥ − εαλ

4

Lemma 3.13. Consider an arbitrary round t + 1 of the 2-choice process and the constants ε (from
Claim B.2) and α ≤ min(ln(10/9), ε/8). For λ ∈ [1/4, 1] we have

(cid:18)

(cid:19)

E[Φ(X(t + 1)) | X(t)] ≤

εαλ

4

1 −

· Φ(X(t)) + ε−8 · O(n).

(16)

We can use this result in a simple induction to prove Lemma 3.5.

Proof of Lemma 3.5. Lemma 3.13 gives us a γ < 1 and c > 0 such that E[Φ(X(t + 1)) | X(t)] ≤ γ ·
Φ(X(t)) + c holds for all rounds t ≥ 0. Taking the expected value on both sides yields E[Φ(X(t + 1))] ≤
γ · E[Φ(X(t))] + c. Using induction and the linearity of the expected value, it is easy to check that
E[Φ(X(t))] ≤ c
solves this recursion. Using the values from Lemma 3.13 for γ and c (substituting ε(cid:48) for
1−γ
ε) we get E[Φ(X(t))] ≤ 4ε

ε(cid:48)αλ · O(n). The lemma’s statement follows for the constant ε = O(cid:0)ε(cid:48)−9/(αλ)(cid:1).

(cid:48)−8

3.2 Bounding the Maximum Load
The goal of this section is to prove Theorem 3.2. Remember the deﬁnitions of Φ(x) and Ψ(x) from
Equation (8). For any ﬁxed round t, we will prove that (w.h.p.) Ψ(X(t)) = O(n · ln n), so that the
average load is ∅ = O(ln n). Using a union bound and Lemma 3.3, we see that (w.h.p.)
the the
maximum load at the end of round t is bounded by ∅ + O(ln n) = O(ln n).
It remains to prove a high probability bound on Ψ(X(t)) for arbitrary t. To get an intuition for
our analysis, consider the toy case t = poly(n) and assume that exactly λ · n ≤ n balls are thrown each
round. Here, we can combine Observation 3.4 and Lemma 3.5 to bound (w.h.p.) the load diﬀerence
between any pair of bins and for all t(cid:48) < t by O(ln n) (via a union bound over poly(n) rounds). Using
the combinatorial observation that, while the load distance to the average is bounded by some b ≥ 0,
the bound Ψ ≤ 2b · n is invariant under the 2-choice process (Lemma 3.14), we get for b = O(ln n) that
Ψ(X(t)) ≤ 2b· n = O(n · ln n), as required. The case for t = ω(poly(n)) is considerably more involved. In
particular, the fact that the number of balls in the system is only guaranteed to decrease when the total
load is high and the load distance to the average is low makes it challenging to design a suitable potential
function that drops fast enough when it is high. Thus, we deviate from this standard technique and
elaborate on the idea of the toy case: Instead of bounding (w.h.p.) the load diﬀerence between any pair
of bins by O(ln n) for all t(cid:48) < t (which is not possible for t (cid:29) poly(n)), we prove (w.h.p.) an adaptive bound
of O(ln(t − t(cid:48)) · f (λ)) for all t(cid:48) < t, where f is a suitable function (Lemma 3.15). Then we consider the last
round t(cid:48)(cid:48) < t with an empty bin. Observation 3.4 yields a bound of Ψ(X(t(cid:48)(cid:48))) = 2· O(ln(t − t(cid:48)(cid:48)) · f (λ))· n
on the total load at time t(cid:48)(cid:48). Using the same combinatorial observation as in the toy case, we get that
(w.h.p.) Ψ(X(t)) ≤ Ψ(X(t(cid:48)(cid:48))) = 2 · O(ln(t − t(cid:48)(cid:48)) · f (λ)) · n. The ﬁnal step is to show that the load at
time t(cid:48)(cid:48) (which is logarithmic in t − t(cid:48)(cid:48)) decreases linearly in t − t(cid:48)(cid:48), showing that the time interval t − t(cid:48)(cid:48)
cannot be too large (or we would get a negative load at time t). See Figure 1for an illustration.
Lemma 3.14. Let b ≥ 0 and consider a conﬁguration x with Ψ(x) ≤ 2b · n and Φ(x) ≤ eα·b. Let x(cid:48)
denote the conﬁguration after one step of the 2-choice process. Then Ψ(x(cid:48)) ≤ 2b · n.
Proof. We distinguish two cases: If there is no empty bin, then all n bins delete one ball. Since the
maximum number of new balls is n, the number of balls cannot increase. That is, we have Ψ(x(cid:48)) ≤
Ψ(x) ≤ 2b · n. Now consider the case that there is at least one empty bin. Let η ∈ (0, 1] denote the
fraction of empty bins (i.e., there are exactly η · n > 0 empty bins). Since the minimal load is zero,
Observation 3.4 implies maxi xi ≤ 2b. Thus, the total number of balls in conﬁguration x is at most
(1 − η)n · 2b. Exactly (1 − η)n balls are deleted (one from each non-empty bin) and at most n new balls
enter the system. We get Ψ(x(cid:48)) ≤ (1 − η)n · 2b − (1 − η)n + n = (1 − η)n · (2b − 1) + n ≤ 2b · n.

10

Figure 1: To bound the system load at time t, consider the minimum load and our bound on the load diﬀerence over time. There
(cid:48)(cid:48) when there was an empty bin. The system load can only increase if there is an empty bin, and this increase is
was a last time t
bounded by our bound on the load diﬀerence. Exploiting that the system load decreases linearly in time while every increase is
(cid:48)
bounded by our logarithmic bound on the load diﬀerence, we ﬁnd a small interval [t

, t] containing t

(cid:48)(cid:48).

Lemma 3.15. Let λ ∈ [1/4, 1). Fix a round t. For i ∈ N with t− i· 8 log n
Let Yi be the number of balls which spawn in Ii.
t(cid:48)<t

(a) Deﬁne the (good) smooth event St :=(cid:84)
(b) Deﬁne the (good) bounded balls event Bt :=(cid:84)
Φ(t(cid:48)) ≥ |t − t(cid:48)|2 · n2(cid:17)

Pr(cid:0) ¯St

1−λ , t].

1−λ ≥ 0 deﬁne Ii := [t− i· 8 ln n

(cid:0)Φ(X(t(cid:48))) ≤ |t − t(cid:48)|2 · n2(cid:1). Then Pr(St) = 1 − O(cid:0)n−1(cid:1).
· |Ii| · n(cid:1). Then Pr(Bt) = 1 − O(cid:0)n−1(cid:1).
(cid:0)Yi ≤ 1+λ
(cid:88)

Proof. Consider an arbitrary time t(cid:48) < t. By Lemma 3.5 we have E[Φ(t(cid:48))] ≤ n/ε. Using Markov’s
inequality, this implies Pr(Φ(t(cid:48)) ≥ |t − t(cid:48)|2 · n2) ≤ 1/(ε·|t− t(cid:48)|2 · n). Using the union bound over all t(cid:48) < t
we calculate

= O(cid:0)n−1(cid:1),

(cid:88)

1
εn ·

(17)

(cid:16)

(cid:1)

≤

≤

Pr

1

2

i

t(cid:48)<t

|t − t(cid:48)|2 ≤

π2
6ε · n

t(cid:48)<t

where the last inequality applies the solution to the Basel problem. This proves the ﬁrst statement.
For the second statement, let Zi := |Ii| · n − Yi be number of balls that did not spawn during Ii.
Note that Zi is a sum of |Ii| · n independent indicator variables with E[Zi] = (1 − λ) · |Ii| · n = 8i · ln n.
Chernoﬀ yields Pr(Zi ≤ (1 − λ) · |Ii| · n/2) ≤ e−8i·ln n/8 = n−i. The desired statement follows by applying
(cid:1).
the identity Zi = |Ii| · n − Yi and taking the union bound.
Lemma 3.16. Fix a round t and assume that both St and Bt hold. Then Ψ(X(t)) ≤ 9n
exp(cid:0)ln(∆2 · n2)(cid:1). By choice of t(cid:48) we have mini Xi(t(cid:48)) = 0. Together with Observation 3.4 we get
Proof. Let t(cid:48) < t be the last time when there was an empty bin and set ∆ := t − t(cid:48). Note that t(cid:48)
maxi Xi(t(cid:48))) ≤ 2 ln(cid:0)∆2 · n2(cid:1)/α. Summing up over all bins (and pulling out the square), this implies
is well deﬁned, as we have Xi(0) = 0 for all i ∈ [n]. Since St holds, we have Φ(X(t(cid:48))) ≤ ∆2 · n2 =
Ψ(X(t(cid:48))) ≤ 4n · ln(cid:0)∆ · n(cid:1)/α. Applying Lemma 3.14 yields Ψ(X(t(cid:48) + 1)) ≤ 4n · ln(cid:0)∆ · n(cid:1)/α. By choice

of t(cid:48), there is no empty bin in X(t(cid:48)(cid:48)) for all t(cid:48)(cid:48) ∈ { t(cid:48) + 1, t(cid:48) + 2, . . . , t − 1}. Thus, during each of these
rounds exactly n balls are deleted. To bound the number of deleted balls, let i be maximal with Ii ⊆ [t(cid:48), t]
(as deﬁned in Lemma 3.15). Since Bt holds and using the maximality of i, the number of balls Y that
spawn during [t(cid:48), t] is at most (1 + λ)|Ii| · n/2 + 8 ln n
Ψ(X(t)) ≤ Ψ(X(t(cid:48) + 1)) − ∆ · n + Y ≤

1−λ · n. We calculate
∆ · n +

1−λ · n ≤ (1 + λ)∆ · n/2 + 8 ln n

α · ln(cid:0) n

4n
α · ln(∆ · n) −

1 − λ

8 ln n

1−λ

2

(cid:19)

1 − λ · n

(cid:18)

=

1 − λ

2

· n ·

1 − λ

8

(cid:18)
α(1 − λ) · ln(∆ · n) − ∆ +
ln(∆ · n)
− 1

24

16 ln n
(1 − λ)2

(cid:19)

2

≤

· ∆ · n ·

With f = f (λ) := 24/(cid:0)α(1 − λ)2(cid:1) the last factor becomes f · ln(∆ · n)/∆ − 1.

It is negative if and
only if ∆ > f · ln(∆ · n). This inequality holds for any ∆ > −f · W−1(− 1
f·n ), where W−1 denotes the
lower branch of the Lambert W function3. This implies that ∆ ≤ −f · W−1(−1/f n), since otherwise we

α(1 − λ)2 ·

∆

.

3Note that − 1

f·n ≥ −1/e, so that W−1(− 1

f·n ) is well deﬁned.

(18)

11

timetboundonloaddiﬀerence(Φ(t))minloadmini{Xi(t)}t0t00would have Ψ(X(t)) < 0, which is clearly a contradiction. Using the Taylor approximation W−1(x) =

(19)

ln(−x) − ln(cid:0)ln(−1/x)(cid:1)

− o(1) as x → −0, we get

(cid:18)

(cid:19)

1
f · n

∆ ≤ −f · W−1

−

Finally, we use this bound on ∆ to get

≤ f · ln(f · n) + f · ln(cid:0)ln(f · n)(cid:1) + f ≤ 2f · ln(f · n).
(cid:19)
(cid:18) 48n
α(1 − λ)2 · ln

α · ln(cid:0)2f n · ln(f n)(cid:1)
(cid:19)(cid:19)
(cid:18) n

4n
α · ln(∆ · n) ≤

(cid:18) 24n

α(1 − λ)2

9n
α · ln

1 − λ

≤

4n

.

Ψ(X(t)) ≤ Ψ(X(t(cid:48) + 1) ≤

4n
α · ln

≤

Now, by combining Lemma 3.16 with the fact that the events St and Bt hold with high probability
(Lemma 3.15), we immediately get that (w.h.p.) Ψ(X(t)) = O(n · ln n). As described at the beginning
of this section, combining this with Lemma 3.3 proves Theorem 3.2.

3.3 Stability
This section proves Theorem 3.1. The ﬁrst auxiliary lemma states that for suﬃciently high value of Γ,
this potential decreases.4
Lemma 3.17 (Negative Bias Γ). Let λ ∈ [1/4, 1). If Γ(X(t)) ≥ 2

(1−λ)2λ, then

E[Γ(X(t + 1)) − Γ(X(t)) | X(t)] ≤ −1.
Proof. Assume X(t) = x is ﬁxed. By deﬁnition of Γ(·), we have Φ(x) ≥ Γ(x)/2 or Ψ(x) ≥ Γ(x)/2. We
now show that in both cases E[Γ(X(t + 1)) − Γ(x) | X(t) = x] ≤ −1.
(a) If Φ(x) ≥ Γ(x)/2, then we have, by Lemma 3.13, a potential drop of

n4

E[Φ(X(t + 1)) − Φ(x) | X(t) = x] ≤ −(εαλ/4) · Φ(x) + n log n ≤ −(εαλ/8) · Γ(x) + n log n.
Note that, by deﬁnition of Ψ, Ψ(X(t + 1))− Ψ(x) ≤ n. Together with Γ(x) ≥ 8(n log n+n2/(1−λ)+1)

eαλ

,

E[Γ(X(t + 1)) − Γ(x) | X(t) = x] ≤ −(εαλ/8) · Γ(x) + n log n + (n/(1 − λ)) · n ≤ −1.

(b) Otherwise, i.e., if Φ(x) < Γ(x)/2, we have that

(i) the load diﬀerence is, by Observation 3.4, bounded by 2 ln(Γ(x)/2)/α, and
(ii) Ψ(x) ≥ Γ(x)/2 must hold. This implies that ∅ ≥ 1
.
2n2
From (i) and (ii) we have that the minimum load is at least (1−λ)·Γ(x)
− ln(Γ(x)/2)/α. From
, it follows that every bin has load at least load 1. Thus
Lemma 3.18 and Γ(x) ≥ 2
each bin will delete one ball and the number of balls arriving is λn in expectation. Hence,
E[Ψ(X(t + 1)) − Ψ(x) | X(t) = x] = − n

1−λ (1 − λ)n. Now,

= (1−λ)·Γ(x)

(1−λ)2λ

n
1−λ

2n2

n4

n

(cid:16) Γ(x)/2

(cid:17)

E[Γ(X(t + 1)) − Γ(x) | X(t) = x] = E[Φ(X(t + 1)) − Φ(x) | X(t) = x] −

n
1 − λ

(1 − λ)n

(20)

≤ n log n −

(1 − λ)n ≤ −1.

n
1 − λ

Thus, E[Γ(X(t + 1)) − Γ(x) | X(t) = x] ≤ −1, which yields the claim.
(cid:17)
(cid:17)
Lemma 3.18. For all x ≥ 2
Proof. Deﬁne f (x) = (1−λ)·x
(1−λ)2λ
the last inequality holds for large enough of n since α is a constant. Moreover, for all x ≥ 2
have f(cid:48)(x) = 1−λ

(cid:16)
(1−λ)2λ it holds that (1−λ)·x
2n2 − 2 ln(x/2)/α ≥ 1.
2n2 − 2 ln(x/2)/α. We have f
αx ≥ 0. Thus, the claim follows.

(cid:16) n4

(1−λ)λ − 2

n2 − 2

≥ n2

(1−λ)2λ

α ln

n4

n4

2

≥ 1, where
we
(1−λ)2λ

n4

4It might look tempting to use Γ together with Hajek’s theorem to derive a bound on the maximum load of system.

However, this would require (exponentially) sharper bounds on Φ.

12

We are ready to prove Theorem 3.1.

Proof of Theorem 3.1. The proof proceeds by applying Theorem A.1. We now deﬁne the parameters of
Theorem A.1. Let ζ(t) = X(t) and hence Ω is the state space of X. First we observe that Ω is countable
since there are a constant number of bins (n is consider a constant in this matter) each having a load
which is a natural number. We deﬁne φ(X(t)) to be Γ(X(t)). We deﬁne C = {x : Γ(x) ≤ 2
(1−λ)2λ}.
Deﬁne β(x) = 1 and η = 1. We now show that the preconditions (a) and (b) of Theorem A.1 are fulﬁlled.

n4

• Let x (cid:54)∈ C. By deﬁnition of C and φ(X(t)), and from Lemma 3.17 we have

E[φ(X(t + 1)) − φ(x)|X(t) = x] ≤ E[Γ(X(t + 1)) − Γ(x)|X(t) = x] ≤ −1.

(21)
• Let x ∈ C. Recall that Γ(X(t)) = Φ(X(t)) + Ψ(X(t)). By Lemma 3.12 and the fact the the
number of balls arriving in one round is bounded by n, we derive,

(cid:18)(cid:18)

(cid:19)

(cid:19)

E[φ(X(t + 1))|X(t) = x] = E[Φ(X(t + 1))|X(t) = x] + E[Ψ(X(t + 1))|X(t) = x]

n
1 − λ
The claim follows by applying Theorem A.1 with Equations (21) and (22).

(1−λ)2λ

1 −

εαλ

4

≤

n4

2

+

n < ∞.

(22)

References
[1] M. Adler, P. Berenbrink, and K. Schröder. Analyzing an inﬁnite parallel job allocation process. In
Proceedings of the 6th Annual European Symposium on Algorithms, ESA ’98, pages 417–428, London,
UK, UK, 1998. Springer-Verlag. ISBN 3-540-64848-8. URL http://dl.acm.org/citation.cfm?
id=647908.740138.

[2] M. Adler, S. Chakrabarti, M. Mitzenmacher, and L. Rasmussen. Parallel randomized load balanc-
ing. Random Structures & Algorithms, 13(2):159–188, 1998. ISSN 1098-2418. doi: 10.1002/(SICI)
1098-2418(199809)13:2<159::AID-RSA3>3.0.CO;2-Q. URL http://dx.doi.org/10.1002/(SICI)
1098-2418(199809)13:2<159::AID-RSA3>3.0.CO;2-Q.

[3] A. S. Alfa. Algorithmic analysis of the bmap/d/k system in discrete time. Adv. in Appl. Probab.,
35(4):1131–1152, 12 2003. doi: 10.1239/aap/1067436338. URL http://dx.doi.org/10.1239/aap/
1067436338.

[4] Y. Azar, A. Z. Broder, A. R. Karlin, and E. Upfal. Balanced allocations. SIAM Journal on

Computing, 29(1):180–200, 1999. doi: 10.1137/S0097539795288490.

[5] L. Becchetti, A. E. F. Clementi, E. Natale, F. Pasquale, and G. Posta. Self-stabilizing repeated balls-
into-bins. In G. E. Blelloch and K. Agrawal, editors, Proceedings of the 27th ACM on Symposium
on Parallelism in Algorithms and Architectures, SPAA 2015, Portland, OR, USA, June 13-15,
2015, pages 332–339. ACM, 2015. ISBN 978-1-4503-3588-1. doi: 10.1145/2755573.2755584. URL
http://doi.acm.org/10.1145/2755573.2755584.

[6] P. Berenbrink, A. Czumaj, T. Friedetzky, and N. D. Vvedenskaya. Inﬁnite parallel job allocation
(extended abstract). In Proceedings of the Twelfth Annual ACM Symposium on Parallel Algorithms
and Architectures, SPAA ’00, pages 99–108, New York, NY, USA, 2000. ACM. ISBN 1-58113-185-2.
doi: 10.1145/341800.341813. URL http://doi.acm.org/10.1145/341800.341813.

[7] P. Berenbrink, A. Czumaj, A. Steger, and B. Vöcking. Balanced allocations: The heavily loaded

case. SIAM Journal on Computing, 35(6):1350–1385, 2006. doi: 10.1137/S009753970444435X.

[8] P. Berenbrink, A. Czumaj, M. Englert, T. Friedetzky, and L. Nagel. Multiple-choice balanced
allocation in (almost) parallel. In A. Gupta, K. Jansen, J. Rolim, and R. Servedio, editors, Ap-
proximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques, vol-
ume 7408 of Lecture Notes in Computer Science, pages 411–422. Springer Berlin Heidelberg, 2012.
ISBN 978-3-642-32511-3. doi: 10.1007/978-3-642-32512-0_35. URL http://dx.doi.org/10.1007/
978-3-642-32512-0_35.

13

[9] P. Berenbrink, K. Khodamoradi, T. Sauerwald, and A. Stauﬀer. Balls-into-bins with nearly optimal
load distribution. In Proceedings of the Twenty-ﬁfth Annual ACM Symposium on Parallelism in
Algorithms and Architectures, SPAA ’13, pages 326–335, New York, NY, USA, 2013. ACM. ISBN
978-1-4503-1572-2. doi: 10.1145/2486159.2486191. URL http://doi.acm.org/10.1145/2486159.
2486191.

[10] A. Czumaj. Recovery time of dynamic allocation processes. In Proceedings of the Tenth Annual
ACM Symposium on Parallel Algorithms and Architectures, SPAA ’98, pages 202–211, New York,
NY, USA, 1998. ACM. ISBN 0-89791-989-0. doi: 10.1145/277651.277686. URL http://doi.acm.
org/10.1145/277651.277686.

[11] A. Czumaj and V. Stemann. Randomized allocation processes. In Foundations of Computer Science,
1997. Proceedings., 38th Annual Symposium on, pages 194–203, Oct 1997. doi: 10.1109/SFCS.1997.
646108.

[12] G. Fayolle, V. Malyshev, and M. Menshikov. Topics in the Constructive Theory of Countable Markov
Chains. Cambridge University Press, 1995. ISBN 9780521461979. URL https://books.google.
ca/books?id=lTJltFEnnHcC.

[13] G. H. Gonnet. Expected length of the longest probe sequence in hash code searching. J. ACM, 28
(2):289–304, Apr. 1981. ISSN 0004-5411. doi: 10.1145/322248.322254. URL http://doi.acm.org/
10.1145/322248.322254.

[14] B. Hajek. Hitting-time and occupation-time bounds implied by drift analysis with applications.

Advances in Applied Probability, 14(3):502–525.

[15] A. Kamal. Eﬃcient solution of multiple server queues with application to the modeling of atm con-
centrators. In INFOCOM ’96. Fifteenth Annual Joint Conference of the IEEE Computer Societies.
Networking the Next Generation. Proceedings IEEE, volume 1, pages 248–254 vol.1, Mar 1996. doi:
10.1109/INFCOM.1996.497900.

[16] N. K. Kim, M. L. Chaudhry, B. K. Yoon, and K. Kim. A complete and simple solution to a

discrete-time ﬁnite-capacity bmap/d/c queue. 2012.

[17] D. A. Levin and Y. Perres. Markov Chains and Mixing Times. American Mathematical Society,

December 2008. ISBN 978-0-8218-4739-8.

[18] M. Mitzenmacher. The power of two choices in randomized load balancing.

IEEE Trans.
doi: 10.1109/71.963420. URL http://doi.

Parallel Distrib. Syst., 12(10):1094–1104, 2001.
ieeecomputersociety.org/10.1109/71.963420.

[19] Y. Peres, K. Talwar, and U. Wieder. The (1 + β)-choice process and weighted balls-into-bins. In
Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), SODA ’10,
pages 1613–1619, Philadelphia, PA, USA, 2010. Society for Industrial and Applied Mathematics.
ISBN 978-0-898716-98-6.

[20] M. Raab and A. Steger. "balls into bins" - A simple and tight analysis. In M. Luby, J. D. P. Rolim,
and M. J. Serna, editors, Randomization and Approximation Techniques in Computer Science, Sec-
ond International Workshop, RANDOM’98, Barcelona, Spain, October 8-10, 1998, Proceedings,
volume 1518 of Lecture Notes in Computer Science, pages 159–170. Springer, 1998. ISBN 3-540-
65142-X. doi: 10.1007/3-540-49543-6_13. URL http://dx.doi.org/10.1007/3-540-49543-6_13.
[21] K. Sohraby and J. Zhang. Spectral decomposition approach for transient analysis of multi-server
discrete-time queues. In INFOCOM’92. Eleventh Annual Joint Conference of the IEEE Computer
and Communications Societies, IEEE, pages 395–404. IEEE, 1992.

[22] V. Stemann. Parallel balanced allocations. In Proceedings of the Eighth Annual ACM Symposium
on Parallel Algorithms and Architectures, SPAA ’96, pages 261–269, New York, NY, USA, 1996.
ACM.
ISBN 0-89791-809-6. doi: 10.1145/237502.237565. URL http://doi.acm.org/10.1145/
237502.237565.

[23] K. Talwar and U. Wieder. Balanced allocations: A simple proof for the heavily loaded case. CoRR,

abs/1310.5367, 2013. URL http://arxiv.org/abs/1310.5367.

14

[24] K. Talwar and U. Wieder. Balanced allocations: A simple proof for the heavily loaded case. In
J. Esparza, P. Fraigniaud, T. Husfeldt, and E. Koutsoupias, editors, Automata, Languages, and
Programming, volume 8572 of Lecture Notes in Computer Science, pages 979–990. Springer Berlin
Heidelberg, 2014. ISBN 978-3-662-43947-0. doi: 10.1007/978-3-662-43948-7_81. URL http://dx.
doi.org/10.1007/978-3-662-43948-7_81.

15

A Auxiliary Results
Theorem A.1 (Fayolle et al. [12, Theorem 2.2.4]). A time-homogeneous irreducible aperiodic Markov
chain ζ with a countable state space Ω is positive recurrent if and only if there exists a positive function
φ(x), x ∈ Ω, a number η > 0, a positive integer-valued function β(x), x ∈ Ω, and a ﬁnite set C ⊆ Ω such
that the following inequalities hold:
(a) E[φ(ζ(t + β(x))) − φ(x)|ζ(t) = x] ≤ −ηβ(x), x (cid:54)∈ C
(b) E[φ(ζ(t + β(x)))|ζ(t) = x] < ∞, x ∈ C
Theorem A.2 (Simpliﬁed version of Hajek [14, Theorem 2.3]). Let (Y (t))t≥0 be a sequence of random
variables on a probability space (Ω,F, P ) with respect to the ﬁltration (F(t))t≥0. Assume the following
two conditions hold:
(i) (Majorization) There exists a random variable Z and a constant λ(cid:48) > 0, such that E[eλ

(cid:48)

Z] ≤ D for

(cid:12)(cid:12)F(t)) ≺ Z for all t ≥ 0; and

some ﬁnite D, and (|Y (t + 1) − Y (t)|

(ii) (Negative Bias) There exist a, ε0 > 0, such for all t we have

Let η = min{λ(cid:48), ε0 · λ(cid:48)2/(2D), 1/(2ε0)}. Then, for all b and t we have

E[Y (t + 1) − Y (t) | F(t), Y (t) > a] ≤ −ε0.

Pr(Y (t) ≥ b | F(0)) ≤ eη(Y (0)−b) +

ε0 · η · eη(a−b).
E(cid:2)Z k(cid:3). With these requirements it then holds that for all b and t

Proof. The statement of the theorem provided in [14] requires besides (i) and (ii) to choose constants
(cid:80)∞k=2
η, and ρ such that 0 < ρ ≤ λ(cid:48), η < ε0/c and ρ = 1 − ε0 · η + cη2 where c =

E(cid:104)
eλ(cid:48) Z(cid:105)

−(1+λ
λ(cid:48)2

(cid:48)E[Z])

(cid:48)k−2
k!

=

λ

2D

Pr(Y (t) ≥ b | F(0)) ≤ ρteη(Y (0)−b) +

1 − ρt
1 − ρ · D · eη(a−b).

(23)

and lower bound on ρ follow.

In the following we bound (23) by setting η = min{λ(cid:48), ε0 · λ(cid:48)2/(2D), 1/(2ε0)}. The following upper
• ρ = 1 − ε0 · η + cη2 ≤ 1 − ε0 · η + ε0 · η · c · λ(cid:48)2/(2D) ≤ 1 − ε0 · η + ε0 · η/2 = 1 − ε0 · η/2, where we
used c ≤ D/λ(cid:48)2.
• ρ = 1 − ε0 · η + cη2 ≥ 1 − ε0/(2ε0) ≥ 0.
We derive, from (23) using that for any t ≥ 0 we have 0 ≤ ρt ≤ 1

Pr(Y (t) ≥ b | F(0)) ≤ ρteη(Y (0)−b) +
≤ eη(Y (0)−b) +
. This yields the claim.

1

since

(1−ρ) ≤ 2
ε0·η

1 − ρt
1 − ρ · D · eη(a−b) ≤ eη(Y (0)−b) +
ε0 · η · eη(a−b),

2D

1

1 − ρ · D · eη(a−b)

(24)

Theorem A.3 (Raab and Steger [20, Theorem 1]). Let M be the random variable that counts the
maximum number of balls in any bin, if we throw m balls independently and uniformly at random into n
bins. Then Pr(M > kα) = o(1) if α > 1 and Pr(M > kα) = 1 − o(1) if 0 < α < 1, where

(cid:33)

log log

log

n log n

m
n log n

m

log n
n log n

(cid:32)
n + α(cid:112)2 m
(cid:114)

m

log

(dc − 1 + α) log n
n log n

m

1 + α

(cid:16)



kα =

m
n +

2 m

n log n

1 − 1

α

log log n
2 log n

if

n

polylog(n) ≤ m (cid:28) n log n

(cid:17)

if m = c · n log n for some constant c
if n log n (cid:28) m ≤ npolylog(n)
if m (cid:29) n(log n)3,

where dc is largest solution of 1 + x(log c − log x + 1) − c = 0. We have d1 = e and d1.00001 = 2.7183.

16

4 λ.

B Auxiliary Tools for the 2-Choice Process
Claim B.1. Consider a bin i and the values ˆδi and ˇδi as deﬁned before Lemma 3.7. If α ≤ ln(10/9),
then max(|ˆδi|,|ˇδi|) ≤ 5
Proof. Remember that ˆδi := λn · (1/n · ˇ1 − pi · ˆα/α) and ˇδi := λn · (1/n · ˆ1 − pi · ˇα/α), where ˇ1 = 1 − α/n <
1 < 1 + α/n = ˆ1 (see proof of Lemma 3.7). Note that if α ≤ ln(10/9), we have ˆ1 < 5/4 and ˇ1 > 8/9.
The claims hold trivially for i = 1, since then pi = (2i − 1)/n2 = 1/n2 and both |1/n · ˇ1 − pi · ˆα/α| ≤ 1/n
and |1/n· ˆ1− pi · ˇα/α| ≤ ˆ1/n. For the other extreme, i = n, we have pn ≤ 2/n. The ﬁrst statement follows
. Similarly, the
from this and the deﬁnition of ˆα = eα − 1 since 2
second statement follows together with 2
n

n · ˇ1 ≤ 2
(which holds for any α > 0).

10/9−1
ln(10/9) − 1

n · ˇ1 < 5

α − 1

4n

ˇα

n

n

n · ˆα
n · ˆ1 < 1

α − 1
Claim B.2. There is a constant ε > 0 such that

(cid:88)

i≤ 3
4 n

(cid:88)

pi · Φi,+ ≤ (1 − 2ε) ·

Φ+
n

.

(cid:80)

and

pi · Φi,− ≥ (1 + 2ε) ·

Proof. The claim follows from comments in [24]. For Equation 25 recall that (cid:80)

i<3n/4 Φi,+ ≤ Φ+ (by
deﬁnition). Since Φi,+ for i = 1, . . . , n is non-increasing where i is the i-th loaded bin, the above equation
is maximized where all Φi,+ = 4Φ+

. The following observation that can be found in [23]

i∈[n]

.

Φ− −

Φi,−

4

i≤ n
n

(25)

(26)

(27)

(28)

(29)

The result follows from combining these two facts.

(cid:88)
(cid:18)

i≤3n/4

pi ≥

1
4

+ ε =⇒

pi ≤ 1 −

1
4 − ε =

3
4 − ε

(cid:18) 3

(cid:19) 4Φ+

pi · Φi,+ ≤

4 − ε

=

1 −

3n

(cid:19)

4ε
3n

· Φ+ ≤ (1 − 2ε) ·

Φ+
n

.

(cid:88)

3n

i≥3n/4

(cid:88)

i≤ 3
4 n

Equation (26) follows similarly.
Claim B.3. Consider a round t and a constant α ≥ 0. The following inequalities hold:

i∈[n]

αηi(αηi − 1) · Φi,+(X(t)) ≤ α2ην · min(cid:0)n, Φ+(X(t))(cid:1).

(a) (cid:88)
(b) (cid:88)
Proof. For the ﬁrst statement, we calculate(cid:80)

αηi(αηi + 1) · Φi,−(X(t)) ≤ α2ην · Φ−(X(t)).
(cid:88)

i∈[n]

=

i≤νn

(cid:88)

αηi(αηi − 1) · Φi,+(X(t)) +

i∈[n] αηi(αηi − 1) · Φi,+(X(t))

(cid:88)
≤ αη(αη − 1) · ν · Φ+(X(t)) + αν(1 + αν) · η · min(cid:0)n, Φ+(X(t))(cid:1)
≤ α2ην · min(cid:0)n, Φ+(X(t))(cid:1),

Φi,+(X(t)) + αν(1 + αν) ·

αηi(αηi − 1) · Φi,+(X(t))

= αη(αη − 1) ·

Φi,+(X(t))

(cid:88)

i≤νn

i>νn

i>νn

decreasing in i (note that we cannot apply the same trick as above to get min(cid:0)n, Φ−(X(t))(cid:1) instead of

where the ﬁrst inequality uses that Φi,+(X(t)) is non-increasing in i and that Φi,+(X(t)) ≤ 1 for all
i > νn. The claim’s second statement follows by a similar calculation, using that Φi,−(X(t)) is non-
Φ−(X(t))).

17

C Missing Proofs for the 2-Choice Process
Proof of Observation 3.6. Remember that 1i is an indicator value which equals 1 if and only if the i-th
bin is non-empty in conﬁguration X. Bin i looses exactly 1i balls and receives exactly k balls, such that
X(cid:48)i − Xi = −1i + k. Similarly, we have ∅(cid:48) − ∅ = −ν + K/n for the change of the average load. With
the identity ηi = 1i − ν (see Section 1.2), this yields

∆i,+(t) = eα·

Xi−∅(cid:1)

(cid:0)
(cid:0)

i−∅(cid:48)(cid:1)
Xi−∅(cid:1)

X

(cid:48)

(cid:0)
(cid:18)
(cid:0)
− eα·
eα·

(cid:1)

(cid:19)

= eα·

−1i+k+ν−K/n

·

= Φi,+ ·
proving the ﬁrst statement. The second statement follows similarly.
Proof of Lemma 3.8. We prove the statement for R = +. The case R = − follows similarly. Using
Lemma 3.7 and summing up over all i ∈ [n] we get

− 1

,

(cid:16)

(cid:17)
eα·(k−ηi−K/n) − 1

(30)

E[∆+(t + 1) | X] ≤

=

≤

−α · (ηi + ˆδi) + α2 · (ηi + ˆδi)2(cid:17)
(cid:16)
(cid:16)
(cid:18)
(cid:19)
ηiα(ηiα − 1) + α2 · (2ηiˆδi + ˆδ2
i ) − α · ˆδi

· Φi,+

5
4

αλ

· Φi,+.

(cid:88)
(cid:88)
(cid:88)

i∈[n]

i∈[n]

i∈[n]

ηiα(ηiα − 1) + 5α2λ +
(cid:19)

(cid:18)

α2λ + 5α2λ +

5
4

E[∆+(t) | X] ≤

αλ

· Φ+ < 2αλ · Φ+.

Here, the last inequality uses λ ≤ 1 and |ˆδi| ≤ 5
and α < 1/8 to get

4 λ (Claim B.1). We now apply Claim B.3, νη ≤ 1/4 ≤ λ,

Proof of Lemma 3.9. To calculate the expected upper potential change, we use Lemma 3.7 and sum up
over all i ∈ [n] (using similar inequalities as in the proof of Lemma 3.8 and the deﬁnition of ˆδi):

E[∆+(t + 1) | X] ≤ 6α2λ · Φ+ −

(cid:17)

· Φi,+

(31)

(32)

(33)

pi · Φi,+.

(cid:88)

i∈[n]

i∈[n]

· Φ+ + ˆαλn

α · ˆδi · Φi,+

(cid:88)
=(cid:0)6α2λ − αλ · ˇ1(cid:1)
(cid:88)
(cid:0)6α2λ − αλ · ˇ1(cid:1)
(cid:0)6α2λ − αλ · ˇ1 + (1 − 2ε) · ˆαλ(cid:1)
(cid:0)4α2λ − 2ε · αλ(cid:1)

· Φ+ + ˆαλn

i≤ 3
4 n

We now use that Φi,+ = eα·(Xi−∅) ≤ 1 for all i > 3

4 n (by our assumption on X 3

4 n

). This yields

E[∆+(t + 1) | X] ≤

pi · Φi,+ + 2αλn.

Finally, we apply Claim B.2 and the deﬁnition of ˇ1 and ˆα to get

E[∆+(t + 1) | X] ≤
≤
Using α ≤ ε/4 yields the desired result.
Proof of Lemma 3.10. To calculate the expected lower potential change, we use Lemma 3.7 and sum up
over all i ∈ [n] (as in the proof of Lemma 3.9):

· Φ+ + 2αλn.

· Φ+ + 2αλn

(34)

E[∆−(t + 1) | X] ≤ 6α2λ · Φ− +

α · ˇδi · Φi,−

· Φ− − ˇαλn

pi · Φi,−.

(35)

(cid:88)

i∈[n]

(cid:88)
=(cid:0)6α2λ + αλ · ˆ1(cid:1)

i∈[n]

18

We now use that Φi,− = eα·(∅−Xi) ≤ 1 for all i ≤ n
get

4

(by our assumption on X n

4

) and apply Claim B.2 to

E[∆−(t) | X] ≤

· Φ− − (1 + 2ε) · ˇαλn ·

Φ− − n

4

n

· Φ− + (1 + 2ε) ·

ˇαλn

4

(36)

(cid:0)6α2λ + αλ · ˆ1(cid:1)
=(cid:0)6α2λ + αλ · ˆ1 − (1 + 2ε) · ˇαλ(cid:1)
(cid:0)8α2λ − 2ε · αλ(cid:1)
i∈[n] max(Xi − ∅, 0) = (cid:80)

· Φ− +

αλn

≤

2

,

where the last inequality used the deﬁnitions of ˆ1, ˇα, as well as ˇα > α − α2. Using α ≤ ε/8 yields the
Proof of Lemma 3.11. Let L := (cid:80)
desired result.
i∈[n] max(∅ − Xi, 0) be the “excess load”
4 n ≥ ∅ implies Φ− ≥ n
n/4 ) (using
above and below the average. First note that the assumption X 3
4 · exp( αL
Jensen’s inequality). On the other hand, we can use the assumption E[∆+(t + 1) | X] ≥ − εαλ
· Φ+ to
show an upper bound on Φ+. To this end, we use Lemma 3.7 and sum up over all i ∈ [n] (as in the proof
of Lemma 3.9):

4

E[∆+(t + 1) | X] ≤ 6α2λ · Φ+ −
= 6α2λ · Φ+ −

α · ˆδi · Φi,+

(cid:88)

i> n
3

3n

For i ≤ n/3 we have pi = 2i−1
yields

(1− 5α)λ/3. Setting Φ≤n/3,+ :=(cid:80)
n2 ≤ 2
(cid:18)
6α2λ −
εαλ
2 · Φ+ + 2αλ · Φ>n/3,+,

i≤n/3 Φi,+ and Φ>n/3,+ :=(cid:80)
(cid:18) 5

and, using the deﬁnition of ˇ1 and ˆα, ˆδi = λn ·
(cid:19)

E[∆+(t + 1) | X] ≤ 6α2λ · Φ+ −

· Φ≤n/3,+ +
· Φ+ +

αλ · Φ>n/3,+
α(1 − 5α)λ

3
α(1 − 5α)λ

α(1 − 5α)λ

≤ −

(cid:19)

αλ +

5
4

=

3

4

3

(37)

α · ˆδi · Φi,+ −

α · ˆδi · Φi,+.

(cid:0)1/n · ˇ1 − pi · ˆα/α
(cid:1)

≥
i>n/3 Φi,+, together with Claim B.1 this

· Φ>n/3,+

(38)

n

4

αL

3αL

· Φ+ implies Φ+ ≤ 8

46 ε. With this, the assumption E[∆+(t + 1) | X] ≥
where the last inequality uses α ≤ 1/46 ≤ 1
23 − 3
(the last inequality uses that none of the
n/3 = 16n
ε · 2n
− εαλ
3ε e
3 e
2n/3 remaining bins can have a load higher than L/(n/3)). To ﬁnish the proof, assume Φ+ > ε
4 · Φ−
(otherwise the lemma holds). Combining this with the upper bound on Φ+ and with the lower bound
on Φ−

ε · Φ>n/3,+ ≤ 8

, we get

εn
16 · e

(cid:1). Now, the lemma’s statement follows from

ε
4 · Φ− ≥

α · ln(cid:0) 256
i∈[n] max(Xi − ∅, 0) = (cid:80)

n ≥ Φ+ >
Thus, the excess load can be bounded by L < n
n = ε−8 · O(n).
Φ = Φ+ + Φ− < 5

ε · Φ+ ≤ 80n
3ε2 e

Proof of Lemma 3.12. Let L := (cid:80)
above and below the average. First note that the assumption X n
4 · e
Jensen’s inequality). On the other hand, we can use the assumption E[∆−(t + 1) | X] ≥ − εαλ
show an upper bound on Φ−
of Lemma 3.10):

i∈[n] max(∅ − Xi, 0) be the “excess load”
n/4 (using
to
. To this end, we use Lemma 3.7 and sum up over all i ∈ [n] (as in the proof

4 ≤ ∅ implies Φ+ ≥ n

16n
3ε

· Φ−

4αL
n .

(39)

3ε2

3αL

3αL

αL

e

4

E[∆−(t + 1) | X] ≤ 6α2λ · Φ− +
= 6α2λ · Φ− +

α · ˇδi · Φi,−

α · ˇδi · Φi,− +

(cid:88)

i> 2n
3

α · ˇδi · Φi,−.

(40)

(cid:0)1/n · ˆ1 − pi · ˇα/α
(cid:1)
For i ≥ 2n/3 we have pi = 2i−1
ˇδi = λn ·

3n − 1

n2 ≥ 4
≤ λ · (−1/3 + 1+α

n ) + 2αλ ≤ −λ/6 + 2αλ. Setting Φ≤2n/3,− :=(cid:80)

n2 . Using this with pi ≤ pn ≤ 2/n and ˇα ≥ α− α2, we can bound
i≤2n/3 Φi,−

(cid:88)
(cid:88)

i∈[n]

i≤ n

3

(cid:88)
(cid:88)

i∈[n]

i≤ 2n

3

19

and Φ>2n/3,− :=(cid:80)

i>2n/3 Φi,−

, together with Claim B.1 this yields

E[∆−(t + 1) | X] ≤ 6α2λ · Φ− +

5
4

(cid:0)8α2λ − αλ/6(cid:1)

(cid:18) 5

αλ · Φ≤2n/3,− −
· Φ− +

4

≤

εαλ
2 · Φ− + 2αλ · Φ≤2n/3,−,

≤ −

αλ
6 · Φ>2n/3,− + 2α2λ · Φ>2n/3,−

(cid:19)

αλ + αλ/6

· Φ≤2n/3,−

(41)

4

where the last inequality uses α ≤ 1/32 ≤ 1
ε · Φ≤2n/3,− ≤ 8
− εαλ
the 2n/3 remaining bins can have a load higher than L/(n/3)). To ﬁnish the proof, assume Φ− > ε
(otherwise the lemma holds). Combining this with the upper bound on Φ−
on Φ+, we get

48 ε. With this, the assumption E[∆−(t + 1) | X] ≥
16 − 1
(the last inequality uses that none of
n/3 = 16n
ε · 2n
3 e
3ε e
4 · Φ+
and with the lower bound

implies that Φ− ≤ 8

· Φ−

3αL

αL

n

3αL

16n
3ε

e

n ≥ Φ− >
Thus, the excess load can be bounded by L < n
n = ε−8 · O(n).
Φ = Φ+ + Φ− < 5
Proof of lemma 3.13. The proof is via case analysis

ε · Φ− ≤ 80n
3ε2 e

3αL

ε
4 · Φ+ ≥

α · ln(cid:0) 256

3ε2

4αL
n .

εn
16 · e

(cid:1). Now, the lemma’s statement follows from

(42)

Case 1: x n

4 ≥ ∅ and x 3n
4 ≥ x 3n

4 ≤ ∅ In this case the desired bound follows from lemma 3.9 and lemma 3.10.

Case 2: x n

4 ≥ ∅ For E[∆+(t + 1) | X(t)] ≤ −εα

Recall E[∆(t + 1) | X(t)] = E[∆+(t + 1) | X(t)] + E[∆−(t + 1) | X(t)]
By lemma 3.10 we can derive the following

4 Φ+ the results follows from lemma 3.10.

E[∆(t + 1) | X(t)] ≤ E[∆+(t + 1) | X(t)] − εαλ · Φ−(X(t)) +

αλn

2

We now show that the RHS can be bounded by the RHS of lemma 3.13. The result holds when

E[∆+(t + 1) | X(t)] ≤ −
≤ −
≤ −
≤ −

αλn

2

εαλ
4 · Φ(X(t)) + ε−8 · O(n) + εαλ · Φ−(X(t)) −
εαλ
4 · Φ(X(t)) + εαλ · Φ−(X(t))
εαλ
4 · (Φ+(X(t)) + Φ−(X(t))) + εαλ · Φ−(X(t))
εαλ
4 · Φ+(X(t))

For E[∆+(t + 1) | X(t)] ≥ −εα
Case 2.1 Φ+(X(t)) ≤ ε

4 Φ+ lemma 3.11 gives two subcases

4 · Φ−(X(t)) Using lemma 3.8 and lemma 3.10 we obtain the following

E[∆(t + 1) | X(t)] ≤ 2αλ · Φ+(X(t)) − εαλ · Φ−(X(t)) +
· Φ−(X(t)) − εαλ · Φ−(X(t)) +

2αλε

2
αλn

2

αλn

≤
= −
≤ −

αλn

4
εαλ
2 · Φ−(X(t)) +
εαλ
4 · Φ(X(t)) + ε−8 · O(n)

2

20

(43)

(44)

(45)

Case 2.2 Φ(X(t)) = ε−8 · O(n) Using lemma 3.8 we get that E[∆(t + 1) | X(t)] ≤ 2αλε−8 · O(n)

It remains to show that

2αλε−8 · O(n) ≤ −

Since Φ(X(t)) = ε−8 · O(n)

εαλ
4 · Φ(X(t)) + ε−8 · O(n)
(cid:18)

(cid:19)

4

This holds where 2αλ ≤

(cid:0)1 − εαλ

4

εαλ

2αλε−8 · O(n) ≤

(cid:1). By deﬁnition α ≤ 1/8 and λ < 1. The result follows.

· ε−8 · O(n)

1 −

(46)

(47)

the results

4 ≤ ∅ This case is similar to case 2. For E[∆−(t + 1) | X(t)] ≤ −εαn

4 Φ−

two subcases are given by lemma 3.12.

4 ≤ x n

Case 3: x 3n
follows from lemma 3.9. For E[∆−(t + 1) | X(t)] ≥ −εαn
Case 3.1 Φ−(X(t)) ≤ ε
Case 3.2 Φ(X(t)) = ε−8 · O(n) This result follows from lemma 3.8.

4 Φ−

4 · Φ+(X(t)) The result follows from applying lemma 3.12 and lemma 3.8.

21

