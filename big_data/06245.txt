6
1
0
2

 
r
a

 

M
0
2

 
 
]

.

A
N
h
t
a
m

[
 
 

1
v
5
4
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Semi-Analytical Minimum Time Solution for the Optimal Control

of a Vehicle subject to Limited Acceleration

Enrico Bertolazzia, Marco Fregob

aDII - Dipartimento di Ingegneria Industriale

bDISI - Dipartimento di Ingegneria e Scienza dell’Informazione

Abstract

The basic module for the solution of the minimum time optimal control of a car-like vehicle is herein presented.
The vehicle is subject to the eﬀect of laminar (linear) and aerodynamic (quadratic) drag, taking into account the
asymmetric bounded longitudinal accelerations. This module is studied and designed to be fast and robust in sight
to be the fundamental building block of a more extended optimal control problem that considers a given clothoid as
the trajectory and the presence of a constraint on the lateral acceleration of the vehicle. The nonlinear dynamics and
the diﬀerent possible boundary conditions yield diﬀerent analytical solutions of the diﬀerential equations, hence they
by themselves a particular attention. The study of the numeric stability of the computation for limit values of the
parameters is essential as showed in the numerical tests.

Keywords: Nonlinear Dynamic, Optimal Control, Semi-analytic solution, Riccati ODE, Clothoid, Friction.

1. Introduction and Motivation

An important objective in the ﬁeld of mobile robotics since the ﬁrst papers of Dubins [10] is to ﬁnd the optimal
trajectory between two points with speciﬁed tangents vectors and velocities. Moreover, other non dynamic constraints
are considered, such as the geometric continuity of the path, the restrictions on the maximum curvature, the avoidance
of obstacles [2, 4, 5, 9, 15, 17, 20]. There are mainly two global views of this problem: the ﬁrst tries to solve in one
shot the generation of the path and the optimal law to travel it, the second splits the problem into two separate parts:
path generation and optimisation of the dynamics. The ﬁrst approach is done essentially numerically, considering very
complex vehicle models, geometric constraints, and various other characteristics which approximate the real world
in a very satisfactory way. The numeric solution obtained in this way is a formidable task by itself and it requires a
deep knowledge of the physical problem and an eﬃcient optimal control solver [4, 7, 11, 16, 19]. It is not possible
to solve those problems analytically (and thus precisely and quickly) because they are too complex or simply they do
not possess a closed form solution. Even when the analytic solution exists, it can be of impractical use. The obtained
numerical solutions are in general very good and accurate, but at the price of a very high computational cost, which
implies that these methods are not suitable for online simulation. Another important consequence is the lack of a
quick feedback in the case of an unexpected situation such as a sudden event.
On the other hand, splitting the problem in two sub-problems allows us to consider them separately, with the reason-
able expectation that they become easier to tackle and admit an analytical solution. This is not usually the case, unless
the problem is simpliﬁed via assumptions on the hypotheses and via linearisation of the diﬀerential equations of the
dynamics. The advantage of such an approximate but analytic solution is that it is of quick evaluation and therefore
suitable for real time applications. Complete analytic solutions are seldom obtained and almost only on toy problems
of limited application, however, semi-analytical solutions are often a good trade-oﬀ between low computational times
and usefulness.
With this second framework in mind, in [12] we solved the problem of a car-like vehicle travelling on a given clothoid,

Email address: enrico.bertolazzi@unitn.it (Enrico Bertolazzi)

Preprint submitted to Elsevier

March 22, 2016

with assigned initial and ﬁnal position, tangent and velocity. The curve is traversed in minimum time, controlling the
limited longitudinal acceleration and considering the bound on the maximum lateral acceleration of the vehicle, a
quantity that connects the curvature of the path with the velocity of the vehicle, [12]. The complete problem is made
up of several blocks: the algorithm for solving the G1 Hermite Interpolation Problem with a clothoid [6], necessary
to compute the path; the description of the car-like model and its simpliﬁcation in order to ﬁnd analytical useful so-
lutions [12], the development of a fast and reliable tool that solves the ODEs of the basic optimal control (which is
the aim of the present work), and a solution method for the optimal control problem with the constraint on the lateral
acceleration. All these blocks are used inside a high level optimiser that constructs the trajectory of the car-like vehicle
along a sequence of given points [21, 14, 13]. In this work, we focus on the solution of the optimal control problem
without the bound on the lateral acceleration, because it is the basic part of the complete optimal control problem.
We remark, since the limit of the lateral acceleration is a function of the state only (and not of the control variable),
that we can solve the problem in two phases. In the ﬁrst phase, we solve the OCP accounting for the longitudinal
constraint only. The problem turns out to be classically Bang-Bang, yielding a switched hybrid system. We obtain
analytic expressions for the optimal state variables as well as robust numerical routines to evaluate them in all cases,
e.g., when the input parameters rise computational instabilities. Moreover, the various combinations of possible initial
and ﬁnal conditions produce many diﬀerent analytic solution that are worth being studied independently because it is
possible to synthesize them with only two stable expressions, even when the parameters of the problem lead to nu-
merical instabilities. In the second phase, which is not scope of this work, we combine the obtained solutions together
with the bound on the lateral acceleration in order to synthesize the optimal control as it is sketched in [12].

In Section 2 we present the Optimal Control Problem (OCP) with the description of the Riccati diﬀerential equa-
tion formulated with the time as the independent variable, we show the Bang-Bang nature of the solution and how to
ﬁnd the single switching point and the ﬁnal total time of the manoeuvre, assuming that the analytic solutions of the
ODEs of problem are available. The derivation of such analytic solutions is devoted to Section sec:solution, where
we give also the deﬁnitions domains of the functions v and s. The aim of Section 4 is to provide numerically stable
versions of the solutions previously obtained. In Section 5 we introduce the change of variable from time t to space
s for the velocity. In Section 6 we reformulate and solve the OCP presented in Section 2 but reformulated with the
space as independent variable. Its solution is one nonlinear equation that we solve with the application of Newton’s
method. Section 7 shows the practical implementation of the stable equations presented in four diﬀerent test cases
for diﬀerent variations of the parameters. The last section are the conclusions with some insights in application of the
present work as a building block for more complex computations and OCP problems.

2. The Optimal Control Problem

The minimum time optimal control problem of a car-like vehicle that follows any smooth path, neglecting for the

moment any constraints on the lateral acceleration, is [12]:

Find a(t) ∈ [−abrake, apush] that minimizes the total time T subject to:

s′(t) = v(t),
v′(t) = a(t) − c0v(t) − c1v2(t),
s(0) = 0,

s(T ) = L,

v(0) = vi,

−abrake ≤ a(t) ≤ apush,
v(T ) = v f ,

(1)

where T is the ﬁnal time to be optimised, s(t) represents the space variable in curvilinear coordinates, v(t) is the veloc-
ity of the vehicle, a(t) is the controlled acceleration asymmetrically bounded for positive abrake and apush, the laminar
friction is given by the nonnegative coeﬃcient c0, the aerodynamic drag is modelled by the nonnegative coeﬃcient
c1. All the boundary conditions are ﬁxed: without loss of generality the initial position is 0, the ﬁnal position is L (the
length of the curve), the initial and ﬁnal velocities are vi and v f , respectively, both assumed nonnegative.
The Hamiltonian of the minimum time optimal control problem (1) is

H(s, v, λ1, λ2, a) = 1 + λ1v + λ2(a − c0v − c1v2)

2

and the control a appears linearly. Its optimal synthesis is obtained from Pontryagin’s Maximum (minimum) Principle
(PMP), and is

a(t) = arg min

a∈[−abrake,apush]

H(s(t), v(t), λ1(t), λ2(t), a) = 

apush
−abrake
asing

if λ2(t) < 0,
if λ2(t) > 0,
if λ2(t) = 0.

Hence the solution of the PMP produces a typical Bang-Bang controller. The term asing represents a possible singular
control when λ2 is identically zero on an interval. The equations for the adjoint variables are

λ′1 = 0,

λ′2 = λ1(c0 + 2c1v) − λ1.

As the state variables have complete boundary conditions, no initial or ﬁnal conditions are required for the two
multipliers. The singular control asing is derived by using the above expressions for the multipliers, but according to
a well known result in Optimal Control Theory [3], the solution of problem (1), if it exists, has at most one switching
instant (denoted as tσ) when the control value changes.
Lemma 1. The optimal control for problem (1), if exists, has at most one switching point and the control law is
Bang-Bang.

Proof. See [3]. The idea is that the multiplier λ2, in absence of bounds on the state variables, is strictly monotone
increasing, hence there is at most one isolated zero and no singular arcs can exist.

(cid:3)

This implies that the optimal control has to be chosen from a family of four candidate controls. The ﬁrst and
second correspond to pure acceleration (i.e., a(t) ≡ apush) or braking manoeuvre (i.e., a(t) ≡ −abrake), the third and
fourth are a combination of the two. Having explicit expressions for the optimal states, with the complete boundary
conditions, the solution of each case is obtained by the solution of a nonlinear system in two unknowns: the switching
time tσ and the ﬁnal time T . It is possible to rule out the case of a braking manoeuvre followed by an acceleration
because it is not optimal. Moreover, the cases of pure acceleration or braking are very unlikely, because the boundary
conditions should exactly satisfy the boundary value problem (1). Hence, only the case of acceleration and braking
with a switching time (possibly degenerate zero length interval at the extrema of the time interval) is herein considered.
It follows that the solution is given by the intersection at the switching point tσ of the two curves of the velocity and the
space v(t) and s(t). The closed form solution of v(t) and s(t) and its accurate computation is a diﬃcult and important
part, therefore it is postponed to Section 3.
We are here interested to ﬁnd the existence conditions for the optimal control of problem (1). They must depend on
the assigned initial and ﬁnal positions and velocities. We have to ensure that there is enough acceleration (respectively
deceleration) together with the initial and ﬁnal velocities to travel the curve. Those values should be compatible with
the extremal manoeuvres of pure acceleration and pure braking.

If the ﬁnal velocity v f is greater than the reference velocity vmax

obtained starting from vi with maximum acceler-
ation, then the problem does not have solution. Reference velocity vmin
is the ﬁnal velocity obtained starting from vi
with maximum deceleration and vmin
f = 0 if the maximum deceleration produces a solution with v(t) = 0 for s(t) < L,
i.e., the vehicle is stopped before to reach the ﬁnal distance L. If the ﬁnal velocity v f is lower than the reference
velocity vmin

the problem is not solvable.

f

f

In the other cases a solution exists. Those limits values are discussed in the next section, together with the analytic

expression of the integration of the diﬀerential equations.

The complete solution of the Optimal Control Problem 1 is reduced to ﬁnding the optimal switching instant tσ
and the ﬁnal minimum time T . This is done equating the arcs of positive acceleration of velocity and space with the
corresponding arcs of negative acceleration. It results a system of two nonlinear equations in the unknowns tσ and T :

vL(tσ) = vR(tσ − T ),

sL(tσ) = sR(tσ − T ).

(2)

Where sL(t) and vL(t) are the solutions of the ODE

( s′(t) = v(t),
v′(t) = apush − c0v(t) − c1v2(t),

3

s(0) = 0
v(0) = vi

f

whereas sR(t) and vR(t) are the solutions of the ODE

( s′(t) = v(t),
v′(t) =−abrake − c0v(t) − c1v2(t),

s(T ) = L
v(T ) = v f

The next parts of the present work are devoted to the computation of the analytic expressions of s(t), v(t) and to the
study their numeric stable implementation. The nonlinear system (2) can be further reduced to the computation of
the zero of a single nonlinear equation. From this reduction it is possible to show that there is a unique solution and
that the Newton method always converges. However this reduction is possible at the price of an involved change of
variable, hence we prefer to solve directly system (2) which is well behaved with a small computational cost.

3. Analytic Solution of Riccati ODE

From the analysis of the optimal control problem in the previous section, we conclude that the second diﬀerential

equation of (1), i.e.,

v′(t) = a(t) − c0v(t) − c1v(t)2,

v(0) = v◦ ≥ 0,

(3)

should be considered only for piecewise constant values of the control a(t). This simpliﬁes a lot the integration
of the ODE, which is a diﬀerential equation of Riccati that can be solved only for a small class of functions a(t),
[1, 18, 22]. The constant functions are in this class and allow to solve the ODE by means of separation of variables
or transforming the Riccati into a Bernoulli and then with standard techniques into a linear ODE. The shape of the
solution varies according to the value of the initial condition, see Figure 1 for a graphic reference.

For negative accelerations a < 0, the situation is slightly diﬀerent, and the sign of the quantity c2

For constant positive accelerations a > 0 and positive c1 > 0, the threshold is given by the asymptotic value v∞.
For initial conditions v◦ < v∞, the velocity is monotone increasing towards the asymptote v∞, for v◦ > v∞ the velocity
is monotone decreasing towards the asymptotic value v∞, lastly, if v◦ = v∞ the velocity is constant.
0 + 4ac1 must be
considered: this leads to two cases. Also the cases of a = 0, c0 ≈ 0 and/or c1 ≈ 0 should be analysed, because they
originate numerical diﬃculties when evaluating the analytic expression of v(t). Once the explicit expression for v(t)
is given, the integration of the ODE for the space variable s′ = v is possible in closed form. We have collected the
various events in diﬀerent cases, that we will discuss next.
A straightforward integration of (3) with a general initial condition v◦ yields a long expression, which involves inverse
trigonometric functions and their hyperbolic analogue according to the sign of the acceleration, the integration of the
velocity has those functions nested inside a logarithm, making v(t) and s(t) diﬃcult to accurately evaluate. Thus, in
some of the cases presented next, the solution of equation (3) is manipulated in order to use a more compact and stable
formula with some auxiliary constants that are here introduced:

0 + 4ac1,

α :=

w + c0

2

=

,

a
α

,

:=

v∞

β
c1

w := qc2
γ := c1v◦ + α,
θ := arctan |w|
c0

β :=

w − c0

2

,

a0 := (c1v◦ + c0)v◦

(4)

,

θ0 := arctan

v◦ |w|

v◦c0 + 2 |a|

,

θ1 := θ − θ0 = arctan

|w|

2c1v◦ + c0

Notice that according to the values of c0, c1 and a, the value w can be real (w.l.o.g. assumed positive) or complex. The
constants in the ﬁrst two lines of (4) are used to simplify expressions when w is real, the last line is used in the cases
of w complex. We are now able to state the main result of this section.
Lemma 2. The analytic solution of (3) with initial velocity v◦ takes the following forms:
√|a|√c1

, w ∈ C \ R

v(t) = v◦ +

w ≥ 0;

v(t) =

(5)

(a0 − a) E(t, w)
1 − γ E(t, w)

sin(cid:16)θ0 − 1
sin(cid:16)θ1 + 1

2 t |w|(cid:17)
2 t |w|(cid:17)

4

80

70

60

50

40

30

20

10

]
s
/

m

[
v

0
−10

200

v∞

]
s
/
m

[
v

100

50

0
−5

(a) v∞
(b) vo

(c) vo

< v∞
> v∞

20
t [s]

(d) w real

(e) w complex

0

5

t [s]

1.1 Velocity plot for a ≥ 0. Cases (a), (b) and (c). Case (a) is the
horizontal line of constant velocity v(t) = v∞. The lower curve rep-
resents case (b), when v◦ is lower than the asymptotic velocity v∞;
case (c) is the upper curve, when v◦ is higher than v∞.

1.2 Velocity plot for a < 0. Cases (d) and (e). Arcs indicate negative
constant acceleration a = −abrake. There are two cases according to
w. When w is real, we fall in case (d), when w is complex we fall in
case (e).

Figure 1: The ﬁve cases of velocity and travelled space as listed in Lemma 3. In all cases, the acceleration is constant and positive. The green arcs
indicate positive constant control a = apush, red arcs have negative constant acceleration a = −abrake.

where E(t, w) := (1 − ewt)/w and θ, θ0 and θ1 are deﬁned in (4). The solution v(t) is meaniningful only for ﬁnite
nonnegative values.

Proof. It is straightforward to check that (5) satisﬁes the Riccati ODE (3).

(cid:3)

As remarked before, the sign of the argument of the square root in w is fundamental for determining the shape of
the solution of the ODE. With this notation, the asymptotic velocity, when there is one, can be written for a = apush as
v∞ = apush/α ≥ 0.
The following lemma states the interval where the solution is deﬁned.

Lemma 3. The solution v(t) of the problem (3) is ﬁnite and nonnegative for t in the interval summarised in Table 1
and plotted in Figure 1. The values of t◦, t∞, tv◦

are the following:

and tv∞
v◦
a + v◦β(cid:19),
log(cid:18)1 − w
γ(cid:19)
log(cid:18)1 −
tv∞
= −

w

,

,

2θ1
|w|

t◦ =

1
w

t∞ =

tv◦

=

1
w
2θ0
|w|

v◦ < v∞ or a < 0

v◦ > v∞ or a < 0

w complex

(6)

the value of θ0 and θ1 are given in (4).
Proof. We have 5 cases (summarized in Table 1) that are function of the parameters a, v◦, c0 and c1:
(case a) This case corresponds to have αv◦ = a, the constant solution, i.e. when the r.h.s. of ODE (3) vanishes, i.e.

a = c0v◦ + c1v2
◦

. Its nonnegative solution is v◦ = a/α;

(case b) This case happens for αv◦ < a when the numerator of (5) is zero for some t. A simple computation shows
that the numerator has a single real root for αv◦ < a or a < 0. For αv◦ < a the value of the root is t◦ of
equation (6).

5

Table 1: Interval of existence and where the solution of (3) is ﬁnite and nonnegative.

case
(a)
(b)
(c)
(d)
(e)

condition
w ≥ 0 and v◦ = v∞
w ≥ 0 and v◦ < v∞
w ≥ 0 and v◦ > v∞
w ≥ 0 and a < 0
w complex

(tmin, tmax)
(−∞, ∞)
[t◦, ∞)
(t∞, ∞)
(t∞, t◦]
(tv∞
, tv◦

]

(smin, smax)
(−∞, ∞)
[s◦, ∞)
(−∞, ∞)
(−∞, s◦]
]
(−∞, sv◦

v′(t)
= 0
> 0
< 0
< 0
< 0

(case c) This case happens for αv◦ > a ≥ 0 when the denominator of (5) is zero for some t. A simple computation
shows that the denominator has a single real root only if a < αv◦ and the value of the root is t∞ of equation (6).
(case d) This case happens when the denominator of (5) is zero for some t∞ and the numerator of (5) is zero for some

t◦. This can happen only when a < 0.

(case e) Equation (5) has denominator zero for some tv∞

of the interval.

and numerator zero for some tv◦

. This zeros are the border

The remaining part of the proof is a simple computation of the zeros of numerators and denominators.

(cid:3)

The velocity has to be positive, but this is true on some intervals only. Table 1 summarises the intervals of nonnegative
velocity in terms of time and also of travelled space. We focus now on the other state variable, the space s. The
integration of (5) permits to deﬁne the travelled space and the explicit expression is contained in the next Lemma.

Lemma 4. Let s(t) = R t

0 v(ζ) dζ be the space travelled with velocity v(t), then

1 log (1 − c1(v∞ − v◦) E(−t, w)) ,

v∞t + c−1
1   log  sin(cid:16)θ1 + 1
c−1

sin θ1

2 t |w|(cid:17)

! −

c0
2

t!,

for w ≥ 0
for w complex

(7)

s(t) = 

the value of θ0 and θ1 are deﬁned in equation (4).

Proof. As with Lemma 3, the expressions for s(t) are obtained by standard integration techniques, it is an exercise to
check that they satisfy s′(t) = v(t). Integrating (5) and noticing that αβ = ac1:

s(t) =

=

αv◦ − a
β − c1v◦
αv◦ − a
β − c1v◦

t +

a0 − a
γ(γ − w)

log (1 − γ E(t, w))

1 log (1 − (c1v◦ + α) E(t, w))

t + c−1

α + c1v◦
α + c1v◦
1 log (1 − (c1v◦ + α) E(t, w)) .

= −c−1
Then using the equality v∞c1 = β, we have

1 αt + c−1

s(t) = v∞t − c−1
= v∞t + c−1
= v∞t + c−1
= v∞t + c−1
= v∞t + c−1

1 log (1 − (c1v◦ + α) E(t, w))

1 (α + β)t + c−1
1 log(cid:16)e−tw − (c1v◦ + α)e−tw E(t, w)(cid:17)
1 log (1 − wE(−t, w) + (c1v◦ + α) E(−t, w))
1 log (1 + (c1v◦ − β) E(−t, w))
1 log (1 + (c1v◦ − c1v∞) E(−t, w)) .

6

Now from the next equality, for constant a, b, c and d,

d
dt

(c t − a) cos(a + b) − log(sin(c t + b)) sin(a + b)

c

=

sin(c t − a)
sin(c t + b)

and by posing a = θ0, b = θ1, c = |w| /2 with the angle deﬁnitions of (4), we obtain (7).
As a corollary, it is possible to determine the special values s◦ and sv◦
Corollary 5. The values of s◦ and sv◦
log 1 − v◦

2c1 "log 1 +

of Table 1 are:

w " β

β ! +

s◦ =

log(cid:18)1 + v◦

α (cid:19)# ,

α
c1

sv◦

c1

c1

c1

1

1

=

.

(cid:3)

(8)

a0

|a|! − c0tv◦# ,

is deﬁned in (6).

where tv◦
Proof. We use the relations

1 −

E(−t◦, w) =

=

s(t◦) =

v∞
w
v∞
w

and (6) in (7), the two values s(t◦) and s(tv◦
w
log 1 −
γ
log 1 −
log 1 − c1
log 1 − c1
log 1 −

w " β

β
wc1

β
wc1

w
γ

1

=

=

=

c1

1
c1

1
c1

v◦
v∞! +
v◦
v∞! +
v◦
β ! +
v◦
β ! +
v◦! +

c1
β

w
γ

w
γ

and

s(tv◦

) +

c0
2c1

tv◦

=

1
c1

2 tv◦ |w|)

sin(θ − θ0 + 1
sin(θ − θ0)
sin θ0

log
log cos θ0 −


tan θ ! = −

1
c1

=

1
c1

= −

Now bringing

c0
2c1

tv◦

to the r.h.s. completes the proof.

γv∞

γv∞ − wv◦

=

v◦

w

wv◦ − γv∞
) become respectively:

=

v◦

wv◦ − v◦β − a

=

v◦

αv◦ − αv∞

log (1 − c1(v∞ − v◦) E(−t◦, w))
log(cid:18)1 + c1

α + β
wc1

β
wc1

v◦
α(cid:19)
v◦
α(cid:19)
log(cid:18)1 + c1
v◦
α (cid:19) +
log(cid:18)1 + c1
v◦(cid:19)# ,
log(cid:18)1 +

c1
α

α
c1

α
wc1

log(cid:18)1 + c1

v◦
α (cid:19)

1
c1

log 

sin θ

1
c1

sin(θ − θ0)! = −
sin θ0! = −

c0
|w|

log cos θ0 −

log  sin θ cos θ0 − cos θ sin θ0

sin θ

1
2c1

log 

|a|
a0 + |a|! .

!

(cid:3)

Lemma 6. The acceleration v′(t) of Equation (3) is identically 0 or is of constant sign in the interval where v(t) ≥ 0,
the corresponding signs are collected in Table 1. Moreover, the space s(t) is monotone increasing where v(t) ≥ 0 and
thus the inverse function t( ˆs), i.e. the solution of the problem s(t, v◦) = ˆs, is well deﬁned.
Proof. From equation (3) with constant acceleration a, suppose that for a certain t = τ the velocity is v′(τ) = 0. If we
consider the shifted function ˜v′(t) = v′(t − τ), we have 0 = a − (c0 − c1 ˜v(0))˜v(0) and from equation (5) of Lemma 2 the
solution ˜v(t) is constant.

(cid:3)

7

Corollary 7. The function ˜v(s) = v(t(s)) satisﬁes the following ODE:

˜v′(s) =

a(s)
˜v(s) − c0 − c1 ˜v(s),

˜v(0) = v◦ ≥ 0,

that is, the ODE (3) in the new independent variable s. This change of variable will be used in next sections.

4. Stable Computation of the Analytic Solutions

Expressions (5) and (7) may be unstable or numerically inaccurate for c0 ≈ 0, c1 ≈ 0 or w ≈ 0 or for t ≈ t∞ or
t ≈ t◦ . Numerically accurate reformulation for expressions (5) and (7) are derived in this section. We deﬁne some
auxiliary functions:

L(t, c) := c−1 log(1 − ct),
S(x, w) := w−1 sin(wx),

E(t, w) := w−1(cid:16)1 − ewt(cid:17),
A(x, w) := w−1 arctan(wx),

and

F (t, w, c0) := etc0/2 G(t, w, c0),

G(t, w, c0) :=

1

w(cid:20)E(cid:18) − t,

w + c0

2

(cid:19) + E(cid:18)t,

w − c0

2

(cid:19)(cid:21),

(9)

(10)

Lemma 8. The functions (9) and (10) are smooth in their deﬁnition domain and have the following Taylor expansions:

L(t, c) = −t

S(x, w) = x

,

∞

(ct)n
n + 1

Xn=0
(−(wx2))n
(2n + 1)!

∞

Xn=0

,

,

(11)

E(t, w) = −t

A(x, w) = x

,

∞

(wt)n
(n + 1)!

Xn=0
(−(wx)2)n
2n + 1

∞

0

Xn=0
w2n − c2n
w2 − c2
log |t|
Xj=1

2n

0

,

F (t, w, c0) = −

G(t, w, c0) = −

∞

Xn=1

∞

Xn=1

fnt2n
22n(2n)! "4 +

2c0t

2n + 1# ,

fnehn(t)"4 +

2c0t

2n + 1# ,

fn =

hn(t) =

tc0
2

,

2 j −

and fn is computed by the following recurrence:

Initial value:

( g1 = 1,

f1 = 1,

Recurrence:

( gn+1 = gnc2

fn+1 = fnw2 + gn+1.

0,

w2 − c2

Proof. The Taylor series for L, E, sinc1, A are straightforward. Some eﬀort is necessary to derive the expansion for
F (t, w, c0) and G(t, w, c0). To compute (10), we multiply it by (w2 − c2
w (cid:16)e−tw/2 − etw/2(cid:17)
Xn=3,5,7,...

F (t, w, c0) = 2etc0/2 − e−tw/2 − etw/2 +
∞

0)/2 so that we obtain:

0 − 2c0wn−1(cid:17)

0 − 2wn(cid:17)

Xn=2,4,5,...

tn(cid:16)2cn

tn(cid:16)2cn

Xn=1

2nn!

2nn!

c0
w

c0

tn

∞

∞

2

+

=

0

2nn! (cid:18)2cn
t2n+1c0(cid:16)c2n

0 − ((−w)n + wn) +
0 − w2n(cid:17)

22n(2n + 1)!

((−w)n − wn)(cid:19) =
0 − w2n(cid:17)
t2n(cid:16)c2n
22n−1(2n)!

∞

∞

+

=

Xn=1

=

∞

Xn=1

t2n

22n(2n)! (cid:20)2 +

Xn=1

c0t

2n + 1(cid:21)(cid:16)c2n

0 − w2n(cid:17) .

1Notice that we use the unnormalised sinc function, deﬁned, for x , 0 and extended for x = 0 with its limit.

8

If we deﬁne the general term fn := (w2n − c2n
0) then (11) is readily obtained. Those functions are smooth
and numerically stable even when the arguments w and c0 approach zero. Notice that an eﬃcient computation of the
series (10) uses the recurrence for fn. The use of the recurrence is mandatory to avoid cancellation errors or numerical
overﬂows, hence the stable and eﬃcient algorithm to evaluate (11) is summarised in the next equation:

0 )/(w2 − c2

G(t, w, c0) = −

∞

Xn=1

ehn(t)"4 +

2c0t

2n + 1# ,

hn(t) = 2n log |t|

2 −

tc0
2 − log((2n)!),

where

hn(t) = 2n log |t|

2 −

tc0
2 −

2n

Xj=1

log j =

2n

Xj=1  log |t|

2 − log j! −

tc0
2

=

2n

Xj=1

log |t|

2 j −

tc0
2

.

and the remaining part follows easily.

(cid:3)

The computation of the special values t◦, t∞, tv◦

, v∞ of Table 1 and corresponding values of s(t, v) is critical and
must be accurate, otherwise complex arguments or logarithms of negative values are very likely. Using Lemma 8, the
stable computation of the ranges in (6) is written in terms of the smooth functions introduced in (11):

t◦ = L(cid:18)
= 2 A(cid:18)
tv◦

v◦

, w(cid:19),
a + v◦β
v◦

v◦c0 + 2 |a|

γ

t∞ = L(cid:18) 1
, w(cid:19),
= tv◦ − 2 A(cid:18) 1
tv∞

c0

w ≥ 0

w complex.

, |w|(cid:19),

(12)

, |w|(cid:19),

An algorithmic version of the computation of the necessary constants for the semi-analytic solution of the OCP (1) is
given in Algorithm 1.

4.1. Stable speed computation

With the previously introduced formulas, the expressions of Lemma 2 are rewritten in the numerically stable

version in the next Proposition.

Proposition 9. The speed v(t) is numerically stable for parameters w ≈ 0 or t ≈ t◦ or t ≈ t∞ if computed as follows
(An algorithmic version for computing v(t) is presented in Algorithm 3). For w real, the velocity is rewritten as:

v(t) =

p(t)
q(t)

+( 0
v◦

if |t − t◦| ≤ ǫ,
otherwise,

When w is complex, a stable computation is:



p(t) = 
q(t) = 

(αv◦ − a) E(t − t◦, w)
(a0 − a) E(t, w)
(a − a0) E(−t, w)
(w − γ) E(t − t∞, w)
1 − γ E(t, w)
1 + (γ − w) E(−t, w)

if |t − t◦| ≤ ǫ,
t > 0,
t ≤ 0,
if |t − t∞| ≤ ǫ,
t > 0,
t ≤ 0.

2 t |w|) − (c0v◦ + 2 |a|) S( 1
2 t |w|) + (2c1v◦ + c0) S( 1
Proof. Case w ≥ 0 real. Notice that from (5) it is possible to write for v,

v◦ cos( 1
cos( 1

v(t) =

2 t, |w|)
2 t, |w|)

(13)

v◦ +

(a0 − a) E(t, w)
1 − γ E(t, w)

=

v◦ − (a + v◦β) E(t, w)

1 − γ E(t, w)

= v◦ +

(a − a0) E(−t, w)
1 + (γ − w) E(−t, w)

,

9

therefore for the numerator, we have:

v◦ − (a + v◦β) E(t, w) = v◦ − (a + v◦β)w−1(cid:16)e−t◦w − e(t−t◦)w(cid:17)et◦w

= v◦ − (a + v◦β) (− E(−t◦, w) + E(t − t◦, w)) et◦w
w
v◦
= v◦ − (a + v◦β)(cid:18)E(t◦, w) + E(t − t◦, w)(cid:18)1 −
v∞(cid:19)(cid:19)
γ
= v◦ − (a + v◦β)(cid:18) 1
v◦
+ E(t − t◦, w)(cid:18)1 −
v∞(cid:19)(cid:19)
= E(t − t◦, w) (a + v◦β − wv◦)
[a + v◦β = γv∞]
= E(t − t◦, w) (a − αv◦)

v◦
v∞

w
γ

γ

And for the denominator,

1 − γ E(t, w) = 1 − γw−1(cid:16)e−t∞w − e(t−t∞)w(cid:17)et∞w = 1 − γ (− E(−t∞, w) + E(t − t∞, w)) et∞w

= 1 − γ(cid:16) E(t∞, w) + E(t − t∞, w)(cid:16)1 − wγ−1(cid:17)(cid:17) = 1 − γ(cid:16)γ−1 + E(t − t∞, w)(cid:16)1 − wγ−1(cid:17)(cid:17)
= E(t − t∞, w) (w − γ) .

Case w complex. The standard expansion of the trigonometric functions in (5) yields immediately (13).

(cid:3)

4.2. Stable space computation

We restate here the numerically stable formulas of Lemma 4.

Lemma 10. The space s(t) of formula (7) is numerically stable for parameters w ≈ 0, or t ≈ t◦ or t ≈ t∞, if computed
as follows. For w real, s(t) can be rewritten as:

s(t) = v∞t + L ((v∞ − v◦) E(−t, w), c1) = L(cid:16)a G(t, w, c0) − v◦ E(−t, w)eβt, c1(cid:17) ,

where we use the second equation when v∞ ≫ v◦. For w complex and c1 ≫ 0 a stable computation is:

s(t) =

1
c1

log(cid:18)(2c1v◦ + c0) S(cid:18) t

2

, |w|(cid:19) + cos

t |w|
2 (cid:19) −

c0t
2c1

the case c1 ≈ 0 is considered in the next lemma.
Proof. Case w ≥ 0 real. In this case equation (5) becomes, after some manipulations:

(14)

(15)

s(t) = v∞t + c−1

1 log (1 − c1(v∞ − v◦) E(−t, w)) ,

1 βt + c−1
1 log(cid:16)1 − β E(t, β) − c1(v∞ − v◦) E(−t, w)eβt(cid:17) ,

1 log (1 − c1(v∞ − v◦) E(−t, w)) = c−1
1 log(cid:16)eβt − c1(v∞ − v◦) E(−t, w)eβt(cid:17) = c−1
1 log(cid:16)1 − c1v∞(cid:16)E(t, β) + w−1(cid:16)eβt − e−αt(cid:17)(cid:17) + c1v◦ E(−t, w)eβt(cid:17) ,
1 log(cid:16)1 − c1aw−1(cid:16)E(t, β) + E(−t, α)(cid:17) + c1v◦ E(−t, w)eβt(cid:17) .

= c−1

= c−1

= c−1

Case w complex. Follows easily using (7) and the angle deﬁnitions in (5).

(cid:3)

10

Lemma 11. Computation of s(t) when w is complex and c1 ≈ 0:

s(t) = ( (a0 + |a|)t2Q(tℓ1, cos θ1) + v◦t

use (15)

|tℓ1| ≤ 0.001
|tℓ1| > 0.001

where

ℓ1 := pc1(a0 + |a|),

cos θ1 :=

2c1v◦ + c0

2ℓ1

,

sin θ1 := |w|
2ℓ1

,

(16)

(17)

and Q(τ, c) can be approximated (when tℓ1 ≈ 0) with
c2 + 2

2c2 + 1

Q(τ, c) = −

1
2

+

cτ
3 −

τ2 +

12

cτ3 −

2c4 + 11c2 + 2

90

τ4 +

2c4 + 26c2 + 17

315

cτ5 − ε(τ, c).

15

The remainder is |ε(τ, c)| ≤ 10−18.
Proof. Using (7), the deﬁnitions of the constants (17) and the angles c0/2 = ℓ1 cos θ1 − c1v◦ we have

s(t) =

a0 + |a|

ℓ2
1

 log  sin (tℓ1 sin θ1)

tan θ1

+ cos (tℓ1 sin θ1)! − tℓ1 cos θ! + v◦t.

By posing τ = tℓ1 and expanding with Taylor around τ:

Q(τ, c) =
The remainder can be estimated with

1

τ2 log(cid:18) c

s

sin (τs) + cos (τs)(cid:19) −

c
τ

,

s = √1 − c2.

ǫ(τ, c) =

4c6 + 114c4 + 180c2 + 17

2520

τ6
⋆,

π

2 ≤ τ ≤ τ⋆ ≤ 0.

−

From the interval of deﬁnition |τ| ≤ 0.001, we have that |ǫ(τ, c)| ≤ 0.125τ6
|ǫ(τ, c)| ≤ 1.25 × 10−19.
Remark 1. The stable computation of (8) in Corollary 5 for w ≈ 0 can be done using (14) or (16) with (12). An
algorithmic version of the stable computation of the function s(t) is given in Algorithm 4.

⋆ for |τ| ≤ 0.001, thus the error satisﬁes

(cid:3)

5. Velocity as a function of the space s

It is useful in the applications of this work, to have the velocity expressed as a function of the space and not of
the time. This is the case for example when we want to add to the pure Bang-Bang problem a limitation on the lateral
acceleration or constrain the problem with the friction ellipse. Those constraints are tipically functions of the space
(e.g. the curvature of the trajectory). From Corollary 7, the function ˜v(s) and its derivatives can be computed via t(s)
with the relation ˜v(s) = v(t(s)). The point of the problem is to invert the monotone function s(t), or, in other words, to
solve the following equation:

t(ζ) solution of the problem s(t) = ζ .

(18)

The following well-known theorem gives enough conditions for the global convergence of Newtons method.

Theorem 12. Let f (x) be twice continuously diﬀerentiable on the closed ﬁnite interval [a, b] and let the following
conditions be satisﬁed:

1.

f (a) f (b) < 0 ;

11

case (b)

case (c)

1000

500

]

m

[

s

0

−10

50

0

−50

]

m

[

s

0

10

t [s]

20

case (d)

2000

1000

0

]

m

[

s

−1000
−2000
−3000
−4000

−50

50

0

−50

]

m

[

s

0

50

100

t [s]

case (e)

−100

−3

−2

−1

0

t [s]

1

2

3

−100

−5

0

t [s]

5

Figure 2: The ﬁve cases of the velocity and travelled space as listed in Lemma 3. In all those case the acceleration is constant and positive with
constant control a = apush.

f ′(x) , 0 for all x ∈ [a, b]
f ′′(x) either ≥ 0 or ≤ 0 for all x ∈ [a, b]

2.
3.
4. At the endpoint a, b both | f (a)| / | f ′(a)| < b − a and | f (b)| / | f ′(b)| < b − a are satisﬁed;

Then Newton’s method converges to the unique solution in [a, b] for any choice of the initial guess in [a, b].

Proof. See reference [8], Theorem 3.2 of page 104.

(cid:3)

Corollary 13. Let f (x) be twice continuously diﬀerentiable on the closed ﬁnite interval [a, b] with

1.
2.
3.

f (a) f (b) < 0 ;
f ′(x) , 0 for all x ∈ [a, b]
f ′′(x) ≥ 0 for all x ∈ [a, b]

if x0 ∈ [a, b] satisﬁes f (x0) ≥ 0 then the sequence generated by Newton’s method converges monotonically to the
unique solution in [a, b]. Analogously if f ′′(x) ≤ 0 for all x ∈ [a, b] and f (x0) ≤ 0.
Proof. Omitted

(cid:3)

12

From problem (18) the evaluation of the inverse function t(ζ) is the solution of the problem f (t) = 0 where
f (t) = s(t) − ζ. The function f (t) has the following properties depending on the 5 cases (summarized in Table 1) that
are function of the parameters a, v◦, c0 and c1:
case (a) f (t) is linear and not constant;
case (b) up to case (e) f ′(t) , 0 and f ′′(t) ≥ 0 or f ′′(t) ≤ 0 for all t ∈ (tmin, tmax). Moreover for ǫ small enough

f (tmin + ǫ) f (tmax − ǫ) < 0.

Remark 2. The function f (t) = s(t) − ζ in all cases (a) up to (e) has a unique t that satisﬁes f (t) = 0. Moreover,
Newton’s method converges monotonically to the solution provided that initial guess tguess is chosen accordingly to
Corollary 13.

A special initial guess for Newton iteration applied to the problem f (t) = 0 in case (b) is provided using the solution
of the Riccati diﬀerential equation with parameters c0 = c1 = 0 when ζa > 0:

2ζ

v◦ + p4ζa + v2

◦

0

ζa > 0

otherwise.

tguess = 

Because f (t) is convex, f (tguess) ≥ 0 and using Corollary 13 the convergence is monotone. In the cases (c) (d) and (e)
a direct application of the Newton method with tguess = 0 can cause the iterations to exit the interval of deﬁnition of
the function, (tmin, tmax). To avoid this dangerous behaviour, without using a damped Newton method, we construct
the iterations as follows. From the fact that limt→tmin f (t) = −∞, we can approximate the function f (t) with a sequence
of model functions gk(t):

gk(t) = ak −

bk

t − tmin

,

ak = f ′(tk)(tk − tmin) + f (tk),

bk = f ′(tk)(tk − tmin)2,

where ak and bk were computed imposing gk(tk) = f (tk) and g′k(tk) = f ′(tk). The step tk+1 is obtained solving
gk(tk+1) = 0:

tk+1 = tmin +

bk
ak

= tmin +

f ′(tk)(tk − tmin)2

f ′(tk)(tk − tmin) + f (tk)

= tk −

f (tk)

f ′(tk) +

f (tk)
tk − tmin

.

From this construction, if f (tk) > 0 and tk > tmin then tmin < tk+1 < tk, if f (tk) < 0, then we are in the hypotheses of
Corollary 13 and we can safely employ Newton’s method that gives monotone convergence. In conclusion we model
the iterations as stated in Algorithm 2.

Lemma 14 (c-d-e). In the cases (c)–(d)–(e) Algorithm 2 converges to the solution f (t⋆) = 0 with quadratic conver-
gence.

Proof. If f (tk0) < 0 for a certain k0, then the hypotheses of Corollary 13 are respected, hence the quadratic monotone
convergence follows from the convergence of Newton’s method. Otherwise, let t⋆ be the root of f (t⋆), because the
steps are negative, we have a monotone decreasing sequence bounded from below, which admits the limit ¯t. This limit
cannot be ¯t > t⋆ because f (¯t) > 0, hence the step remains diﬀerent from zero. Therefore let εk = tk − t⋆, then we have

εk+1 = εk −

=

1
2

ε2
k

f (tk) − f (t⋆)

k ( f (tk) − f (t⋆))/(tk − tmin)

f ′(tk) + δ+
f ′′(ωk)(tk − tmin) + 2δ+
f ′(tk)(tk − tmin) + εkδ+

k f ′(ζk)
k f ′(ζk)

,

13

= εk −

f (t⋆) + εk f ′(tk) + 1

2 ε2

k f ′′(ωk) − f (t⋆)

f ′(tk) + εkδ+

k f ′(ζk)/(tk − tmin)

that is,

lim
k→∞

εk+1
ε2
k

=

1
2

f ′′(t⋆)(t⋆ − tmin) + 2δ+
f ′(t⋆)(t⋆ − tmin)

k f ′(t⋆)

=

1
2

f ′′(t⋆)
f ′(t⋆)

+

δ

t⋆ − tmin

= C,

Hence the convergence is quadratic with constant C, which is bigger if the covergence is from the right side.

(cid:3)

6. The Optimal Control Problem in the curvilinear abscissa s

With the change of coordinates from time t to space s as independent variable, it is possible to reformulate the
OCP (1), passing from free time to a ﬁxed domain. The change of variable is possible in practice using the results of
the Section 5. Let ˜v(s) = v(t(s)) be the transformed function of the velocity parametrised as a function of s as showed in
Corollary 7, then the minimum time optimal control problem (1) can be reformulated as ﬁnding a(s) ∈ [−abrake, apush]
that minimises

Minimise

T = Z L

ds
|˜v(s)|

subject to:

˜v′(s) =

0
a(s)
˜v(s) − c0 − c1 ˜v(s),

˜v(0) = vi,

˜v(L) = v f ,

−abrake ≤ a(s) ≤ apush,

(19)

The complete solution of the Optimal Control Problem (19) is reduced to ﬁnding the optimal switching point sσ such
that the solution is written as

where ˜vL(s) and ˜vR(s) are the solutions of the ODE

˜v(s) = ( ˜vL(s)

˜vR(s)

s < sσ
s ≥ sσ,

˜v′L(s) =

˜v′R(s) = −

apush
˜vL(s) − c0 − c1 ˜vL(s),
abrake
˜vR(s) − c0 − c1˜vR(s),

˜vL(0) = vi,

˜vR(L) = v f .

(20)

Remark 3. Indeed we notice that while it is possible to solve the dynamic system of (1) as explicit functions of v(t)
and s(t), the diﬀerential equation (19) for ˜v(s) admits only an implicit solution that is impractical to subsolve with
respect to s. Therefore we employ the knowledge of the analytic solutions presented in the previous sections for v(t)
and s(t) together with the numeric change of variable of Section 5.

The computation of the switching point sσ is done equating the arcs of positive acceleration with the corresponding

arcs of negative acceleration. It results a single nonlinear equation g(sσ) = 0 where:

g(s) = ˜vL(s) − ˜vR(s),

To solve g(sσ) = 0 we simply use the Newton method: the derivative of g(s) is readily given by

g′(s) = ˜v′L(s) − ˜v′R(s) =

apush
˜vL(s)

+

abrake
˜vR(s)

+ c1 (˜vR(s) − ˜vL(s))

and the latter is deduced from (20).

14

Table 2: Table of ﬁxed and varying parameters

Fixed Parameters

v(0) [m/s]
6

v(L) [m/s]
5

L[m]
100

apush [m/s2]
2

abrake [m/s2]
2

c0 [1/m]
0.01

c1 [1/s]
0.01

c0 [1/m]
c1 [1/s]

apush [m/s2]
abrake [m/s2]

0
0
10−6
10−6

10−5
0.005
0.01
0.01

Varying Parameters
0.1
0.03
0.25
0.25

0.01
0.01
0.05
0.05

0.05
0.02
0.1
0.1

0.2

0.3

0.4

0.5

1
1

2
2

10
10

7. Numerical Tests

We present herein four numerical tests for various choices of the parameters of the problem, namely we consider
the parameters c0, c1, apush and abrake. The tests are done with the stable formulas for velocity and space of Section 4
with the change of variable from t to s explained in Section 5.
It is worth noticing and pointing out that although the solutions of the Riccati diﬀerential equation derived in Sec-
tion 3 are analytic, a direct na¨ıve implementation of such equations leads to numerical instabilities, which is the main
motivation that led to this study. In particular, things go wrong when the friction parameters c0 and c1 are near to zero,
producing a large error in the division by (near) zero coeﬃcients, or, even if they are far from being zero, but w results
zero or almost zero, for example when the acceleration is negative (braking phase) and c2
0 − 4ac1 ≈ 0. The instabilities
are also evident in the computation of the time and space domains of the equations.

In the ﬁrst test we ﬁx the initial/ﬁnal positions with their speeds and we compute the time optimal control problem
with diﬀerent values of the friction coeﬃcient c0. The ﬁxed parameters and the coeﬃcients for the aerodynamic drag
are resumed in Table 2. The result is showed in Figure 3.1, the curves are ordered from top to bottom according to the
increasing value of c0: the top most curve is for c0 = 0 and the last curve on the bottom is the one for c0 = 0.5. Starting
from above, the ﬁrst ﬁve curves represent a typical situation of a positive acceleration that produces an increment in
the velocity, followed by a braking phase. The ﬂat zones indicate that the asymptotic speed v∞ has been reached.
The sixth curve shows a case where the friction is too intense and a positive acceleration produces a reduction of the
speed that settles at v∞; the ﬁnal condition is then met by a rapid braking phase. The last two curves (dashed lines)
at the bottom of Figure 3.1 show two infeasible manoeuvres, which means the friction is too high (or equivalently the
acceleration apush is too weak) to reach the ﬁnal point. Also here the ﬂat zones indicate the asymptotic velocity v∞.
The second example shows the behaviour of changing the aerodynamic coeﬃcient c1. We keep the parameters previ-
ously ﬁxed in Table 2 and consider the values for c1 from c1 = 0 to c1 = 0.03 as in Table 2. The result is showed in
Figure 3.2, where the curves are ordered from top to bottom according to increasing values of c1, e.g. the higher the
friction, the slower the velocity.
The third experiment makes the value of apush change from apush = 10−6 to apush = 10. The other values are kept as
in the previous tests. The curves of Figure 3.3 are ordered from top to bottom according to the decreasing values of
apush. The ﬁrst four are admissible manoeuvres that share a common deceleration curve, the last four curves (dashed)
are non admissible solutions because the acceleration apush is not strong enough to reach the ﬁnal position.
The fourth test makes the value of abrake change from abrake = 10−6 to abrake = 10. The curves of Figure 3.4 are ordered
from top to bottom according to the increasing values of abrake, that is, the stronger is the braking, the shorter is the
braking phase. The curves are admissible manoeuvres that share a common acceleration curve and meet in the ﬁnal
point.

15

16

14

12

10

8

6

4

)
s
(
v

2

0

10

20

30

40

25

20

15

10

5

)
s
(
v

0

0

10

20

30

40

16

14

12

)
s
(
v

10

8

6

4

0

16

14

12

)
s
(
v

10

8

6

4

0

50
s

3.1 Test 1, variation of c0.

50
s

3.2 Test 2, variation of c1.

60

70

80

90

100

10

20

30

40

60

70

80

90

100

50
s

3.3 Test 3, variation of apush.

50
s

3.4 Test 4, variation of abrake.

60

70

80

90

100

10

20

30

40

60

70

80

90

100

Figure 3: The four pictures show the graphical result of the numerical tests. Solid lines are feasible manoeuvres while dashed lines are unfeasible
manoeuvres. Parameters of the computed solutions are taken from Table 2

8. Conclusions, Future Work and Applications

In this paper we explained and proved the basic module that consists in steering a car-like model from an initial
position and velocity to a ﬁnal state and velocity. The novelty of the OCP is the presence of the quadratic term in
the ODE for the velocity, which yields a nonlinear diﬀerential equation of Riccati kind. The nature of the OCP being
Bang-Bang allows the analytic solution of the ODEs and thus the reduction of the problem to the numeric solution of
a curve intersection. An immediate consequence is the avoidance of the complete numeric integration of the dynamic
system and hence a very low computational time. A rough estimate of the computational cost for the present semi-
analytic solution of the OCP is around 1 microsecond with a C++ implementation, against a pure numerical solution
with Pins or GPOPS-II of around 1 second.
We successfully used it in the solution of the more general optimal control problem of steering a car-like model
with the additional constraint on the maximum lateral acceleration and a given trajectory expressed as clothoid curve,
see [12]. The eﬀectiveness of the algorithm presented in this paper was mandatory in the construction of the tool,
because during the optimisation process, many instances of the Bang-Bang algorithm were required, most of them with
parameters that came from other computational processes, yielding non standard situations. The na¨ıve implementation
of the analytic solution was found to be insuﬃcient for that purpose, therefore we developed the stable formulas.
As a future work based on the present building block, we want to solve the optimal control herein presented with the
limitation on the lateral acceleration and with a trajectory given by ﬁxed sequence of clothoids, not just one. Another
future study is the design of a tool that gives the time optimal trajectory on a road, in terms of clothoids, combining
the present module with a planning algorithm.

16

Acknowledgements

The research activity described in this paper has received funding from the University of Trento within the project

“OptHySYS - Optimisation techniques for Hybrid dynamical SYStems: from theory to applications”.

References

References

[1] M. Abramowitz and I. Stegun, Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables, no. 55 in National

Bureau of Standards Applied Mathematics Series, U.S. Government Printing Oﬃce, Washington, D.C., 1964.

[2] A. Amditis, E. Bertolazzi, M. Bimpas, F. Biral, P. Bosetti, M. Da Lio, L. Danielsson, A. Gallione, H. Lind, A. Saroldi, and A. Sj¨ogren, A
holistic approach to the integration of safety applications: The insafes subproject within the european framework programme 6 integrating
project prevent, IEEE Transactions on Intelligent Transportation Systems, 11 (2010), pp. 554–566.

[3] M. Athans and P. Falb, Optimal Control: An Introduction to the Theory and Its Applications, Lincoln Laboratory publications, McGraw-Hill,

1966.

[4] E. Bertolazzi, F. Biral, and M. Da Lio, Symbolic-numeric eﬃcient solution of optimal control problems for multibody systems, Journal of

Computational and Applied Mathematics, 185 (2006), pp. 404–421.

[5] E. Bertolazzi, F. Biral, M. Da Lio, A. Saroldi, and F. Tango, Supporting drivers in keeping safe speed and safe distance: The saspence
subproject within the european framework programme 6 integrating project prevent, IEEE Transactions on Intelligent Transportation Systems,
11 (2010), pp. 525–538.

[6] E. Bertolazzi and M. Frego, G1 ﬁtting with clothoids, Mathematical Methods in the Applied Sciences, 38 (2015), pp. 881–897.
[7] C. B¨uskens and D. Wassel, The ESA NLP solver WORHP, in Modeling and Optimization in Space Engineering, G. Fasano and J. D. Pint´er,

eds., vol. 73 of Springer Optimization and Its Applications, Springer New York, 2013, pp. 85–110.

[8] S. D. Conte and C. W. D. Boor, Elementary Numerical Analysis: An Algorithmic Approach, McGraw-Hill Higher Education, 3rd ed., 1980.
[9] M. Da Lio, F. Biral, E. Bertolazzi, M. Galvani, P. Bosetti, D. Windridge, A. Saroldi, and F. Tango, Artiﬁcial co-drivers as a universal
enabling technology for future intelligent vehicles and transportation systems, IEEE Intelligent Transportation Systems Magazine, 00 (2014),
pp. 1–20. Article in Press.

[10] L. E. Dubins, On curves of minimal length with a constraint on average curvature, and with prescribed initial and terminal positions and

tangents, American Journal of mathematics, (1957), pp. 497–516.

[11] J. V. W. E, F. P, and C. K. E, ICLOCS, 2010.
[12] M. Frego, E. Bertolazzi, F. Biral, D. Fontanelli, and L. Palopoli, Semi-analytical minimum time solutions for a vehicle following clothoid-

based trajectory subject to velocity constraints, in European Control Conference (ECC), 2016, p. 7.

[13]

, Semi-Analytical Minimum Time Solutions with Velocity Constrainst for Trajectory Following of Vehicles, Automatica, (2016). Sub-

mitted.

[14] M. Frego, P. Bevilacqua, E. Bertolazzi, F. Biral, D. Fontanelli, and L. Palopoli, Trajectory Planning for car–like vehicles: a modular

approach, Conference on Decision and Control (CDC 2016), (2016). Submitted.

[15] M. Gerdts and I. Xausa, Avoidance trajectories using reachable sets and parametric sensitivity analysis, IFIP Advances in Information and

Communication Technology, 391 AICT (2013), pp. 491–500.

[16] B. Houska, H. Ferreau, and M. Diehl, ACADO Toolkit – An Open Source Framework for Automatic Control and Dynamic Optimization,

Optimal Control Applications and Methods, 32 (2011), pp. 298–312.

[17] C. Landry, M. Gerdts, R. Henrion, and D. H¨omberg, Path-planning with collision avoidance in automotive industry, IFIP Advances in

Information and Communication Technology, 391 AICT (2013), pp. 102–111.

[18] F. J. Olver, D. Lozier, R. Boisvert, and C. Clark, eds., NIST handbook of mathematical functions, U.S. Department of Commerce National

Institute of Standards and Technology, Washington, DC, 2010. With CD-ROM.

[19] M. A. Patterson and A. V. Rao, GPOPS-II: A MATLAB software for solving multiple-phase optimal control problems using hp-adaptive

gaussian quadrature collocation methods and sparse nonlinear programming, ACM Trans. Math. Softw., 41 (2014), pp. 1:1–1:37.

[20] A. Rao, Trajectory optimization: A survey, Lecture Notes in Control and Information Sciences, 455 LNCIS (2014), pp. 3–21.
[21] T. Rizano, D. Fontanelli, L. Palopoli, L. Pallottino, and P. Salaris, Global path planning for competitive robotic cars, in Decision and

Control (CDC), 2013 IEEE 52nd Annual Conference on, IEEE, 2013, pp. 4510–4516.

[22] V. Zaitsev and A. Polyanin, Handbook of Exact Solutions for Ordinary Diﬀerential Equations, CRC Press, 2002.

17

Appendix A. Algorithms collected

Algorithm 1: Setup constants for forward computation
of v(t; c0, c1, v◦, a) and s(t; c0, c1, v◦, a)
procedure setup
Data: c0,c1,v
,a
◦
Result: Computation of constants for cases (a)–(e)
if c2

∞

else if v

, a0 with equation (4);

∞
◦ ← L (v

with equation (6) using expansion (9);
// case (d)
◦/(a + v

0 + 4ac1 ≥ 0 then
Compute w, α, β, γ, v
, t
Compute t
◦
if a < 0 then
◦β), w);
tmax ← t
∞ ← L(cid:16)γ−1, w(cid:17);
if γ > w then tmin ← t
else
∞ ← −∞;
tmin ← t
smin ← −∞ ;
) − v
smax ← L(a G(t
◦ E(−t
◦
◦ < v
∞
smax ← ∞;
smin ← −∞;
if γ > w then tmin ← t
else
tmin ← t
else if v

// Equation (14) with t = t
◦, w) exp(−βt
tmax ← ∞;
∞ ← L(cid:16)γ−1, w(cid:17);
∞ ← −∞;
then // case (b)
◦β), w);

then // case (c)

◦ > v
∞
◦ ← L (v
tmin ← t
tmax ← ∞;
if w > 0.1 then
smin ← (L(v
smin ← L(aG(t

◦/(a + v
smax ← ∞;
// Equation (8) with t = t
◦, α/a) + L(−v
◦ E(−t

◦, c1/α))/w;
◦, w) exp(−βt

// Equation (14) with t = t

) − v

◦

), c1);

else

), c1);

◦

◦

◦

end

Algorithm 3: Compute v(t) := v(t; c0, c1, v◦, a)
procedure velocity
Data: t and constant computed with setup (c0,c1,v
◦
Result: Computation of v(t)
switch which computational case? do

,a)

case case (a)-(b)-(c)-(d) do
if t ≤ 0 or t > 1 then

q ← 1 + (γ − w)E(−t, w);
if |t − t
◦ − a) E(t − t
else

◦| < 100ǫ then

p ← (αv
p ← (a − a0) E(−t, w); return v

◦, w); return p/q;
◦ + p/q;

◦

end

else

∞, w);

if |t − t
else
if |t − t
else

∞| < 100ǫ then q ← (w − γ)E(t − t
q ← 1 − γ E(t, w);
◦| < 100ǫ then

◦ − a) E(t − t

p ← (αv
p ← (a0 − a) E(t, w); return v

◦, w); return p/q;

◦ + p/q

end

end

◦

end
case case (e) do

c ← cos(t |w| /2);
c − (c0v
p ← v
◦
return p/q

s ← S(t/2,|w|);

◦ − 2a)s;

q ← c + (2c1v

◦ + c0)s;

else

// case (a)

end

tmax ← ∞;

smin ← −∞;

smax ← ∞;

end

tmin ← −∞;
else // case (e)

end

Compute |w|, θ, θ0, θ1, a0, ℓ1 with equation (4) and (17);
Compute tv◦

with equation (6);

end

Algorithm 2: Modiﬁed Newton for the computation
f (t) = 0 when tmin > −∞
procedure Modiﬁed Newton
Data: tguess
Result: Computation of t such that f (t) = 0
t ← tguess;
repeat
if

f (t) > 0 then

else

δt ← f (t).(cid:16) f ′(t) + f (t)/(t − tmin)(cid:17);
δt ← f (t)/ f ′(t);

end
t ← t − δt ;
until |δt| < ǫ;
return t;

Algorithm 4: Compute s(t) := s(t; c0, c1, v◦, a)
procedure space
Data: t and constant computed with setup (c0,c1,v
◦
Result: Computation of s(t)
switch which computational case? do

,a)

case case (a)-(b)-(c)-(d) do

if t ≥ tmax then return smax;
else if t ≤ tmin then return smin;
else returnL(a G(t) − v

◦ E(−t, w) exp(−βt), c1);

end
case case (e) do

if |tℓ1| ≤ 0.001 then
else

)t

return ((|a| + a0) Q(tℓ1, cos(θ1))t + v
◦
arg ← (2c1v
if arg ≤ 0 then return −∞;
else return (log(arg) − c0t/2)/c1;

◦ + c0)S(t/2,|w|) + cos(t |w| /2);

end

end

end

18

