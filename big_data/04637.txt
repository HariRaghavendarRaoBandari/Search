Friedrich-Schiller-Universität Jena

On the Randomization of Frolov’s Algorithm for

Multivariate Integration

M A S T E R A R B E I T

zur Erlangung des akademischen Grades

Master of Science (M. Sc.)

im Studiengang Mathematik

FRIEDRICH-SCHILLER-UNIVERSITÄT JENA

Fakultät für Mathematik und Informatik

eingereicht von David Krieg

geboren am 08.07.1991 in Würzburg

Betreuer: Prof. Dr. Erich Novak

Jena, 04.02.2016

6
1
0
2

 
r
a

M
 
6
1

 
 
]

.

A
N
h
t
a
m

[
 
 

2
v
7
3
6
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

We are concerned with the numerical integration of functions from
the Sobolev space H r,mix([0, 1]d) of dominating mixed smoothness r ∈ N
over the d-dimensional unit cube.

In [F76], K. K. Frolov introduced a deterministic quadrature rule
whose worst case error has the order n−r (log n)(d−1)/2 with respect to
the number n of function evaluations. This is known to be optimal. In
[KN16], 39 years later, Erich Novak and me introduced a randomized
version of this algorithm using d random dilations. We showed that its
error is bounded above by a constant multiple of n−r−1/2 (log n)(d−1)/2
in expectation and by n−r (log n)(d−1)/2 almost surely. The main term
n−r−1/2 is again optimal and it turns out that the very same algorithm
is also optimal for the isotropic Sobolev space H s([0, 1]d) of smoothness
s > d/2. We also added a random shift to this algorithm to make it un-
biased. Just recently, Mario Ullrich proved in [U16] that the expected
error of the resulting algorithm on H r,mix([0, 1]d) is even bounded above
by n−r−1/2. This thesis is a review of the mentioned upper bounds and
their proofs.

Contents

1 Introduction

2 The Function Spaces

3 The Basic Quadrature Rule

4 Frolov’s Deterministic Algorithm on ˚H r,mix([0, 1]d)

4

6

8

10

5 The Eﬀect of Random Dilations

12
5.1 Worst Case Errors
. . . . . . . . . . . . . . . . . . . . . . . . . . . 12
5.2 Expected Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

6 Further Improvements through Random Shifts

7 Transformations to H r,mix([0, 1]d)

References

21

26

31

3

1

Introduction

Many applications deal with multivariate functions f which are smooth in the
sense that certain weak derivatives Dαf exist and are square-integrable, functions
from a Sobolev space.

Which derivatives Dαf of f are known to be existent and square-integrable
highly depends on the actual problem. Classically, α covers the range of all vectors
0 with (cid:107)α(cid:107)1 ≤ s for some s ∈ N. The corresponding Sobolev space is called
in Nd
isotropic Sobolev space of smoothness s ∈ N. For instance, the solutions of elliptic
partial diﬀerential equations in general and Poisson’s equation in particular, have
this form. They typically appear in electrostatics or continuum mechanics.

But often f is known to satisfy a stronger smoothness condition: Derivatives
Dαf for each α ∈ Nd
0 with (cid:107)α(cid:107)∞ ≤ s exist and are square-integrable. This is
typically the case, if f is a tensor product of s-times diﬀerentiable functions of
one variable: f (x1, . . . , xd) = f1(x1) · . . . · fd(xd). We say that f is from a Sobolev
space of dominating mixed smoothness s. For example, solutions of the electronic
Schrödinger equation are of this form.

We are concerned with the numerical integration of such functions and refer
to [HT08] and [GN01] for a treatise on elliptic partial diﬀerential equations and
their connection with Sobolev spaces and to [Y10] for further information about
electronic wave functions.

More precisely, we want to use linear quadrature rules to approximate the
integral Id(f ) of integrable, real valued functions f in d real variables, with a
particular interest in functions with dominating mixed smoothness s. A linear
quadrature rule, algorithm or method An is given by a ﬁnite number n of weights
a1, . . . , an ∈ R and nodes x(1), . . . , x(n) ∈ Rd, and the rule

n(cid:88)

aj f(cid:0)x(j)(cid:1) .

An(f ) =

j=1

All these numbers and vectors can be deterministic or random variables. Since n
counts the number of function values computed by An, it is a measure for the cost
of An, commonly referred to as information cost of the algorithm.

The error of An associated with the integration of f is |An(f ) − Id(f )|. We
are interested in sequences (An)n∈N of quadrature rules whose error decreases fast
with respect to growing information cost n. In this sense, numerical integration

4

of functions with dominating mixed smoothness s is signiﬁcantly easier than the
integration of functions with isotropic smoothness s, especially if the number d of
variables is large: It turns out that the convergence order n−s−1/2 can be achieved
for the expected error, while n−s/d−1/2 is the best possible rate in the isotropic case.

From now on, for the sake of distinction, we will use s as a parameter for
isotropic smoothness and r as a parameter for dominating mixed smoothness.
The smoothness parameters r and s and the dimension d are arbitrary natural
numbers, with the single condition that s > d/2. But they are considered to be
ﬁxed in the sense that any constant in this thesis is merely a constant with respect
to the information cost n and may depend on r, s and d.

Let us end this introductory section with an outline of the thesis.
We start with a brief compilation of the deﬁnitions and fundamental properties
of the above mentioned Sobolev spaces. In Section 3, we will present a familiy of
deterministic quadrature rules for the integration of compactly supported, contin-
uous functions. Among those rules is Frolov’s algorithm, which will be examined
in Section 4. With respect to the information cost n, its integration error for func-
tions f with dominating mixed smoothness r and compact support in the open unit
cube (0, 1)d is bounded above by a constant multiple of n−r (log n)(d−1)/2 times the
corresponding norm of f. The order n−r (log n)(d−1)/2 is optimal. For functions
with support in (0, 1)d and isotropic smoothness s the order n−s/d is achieved,
which is also optimal.

In Section 5, we will add random dilations to Frolov’s algorithm and examine
the integration error of the resulting algorithm for the same types of functions. We
will see that in both cases the random dilations improve the order of the algorithm’s
error by 1/2 in expectation, while not changing it in the worst case. The additional
random shift introduced in Section 6 makes the algorithm unbiased and, in case
of functions with dominating mixed smoothness r and compact support in (0, 1)d,
further improves the order of its expected error by a logarithmic term.

Section 7 shows that the condition of having support in (0, 1)d can be dropped
by applying a suitable change of variables to the above algorithms. The resulting
algorithms satisfy the error bounds from above for any function on [0, 1]d with
dominating mixed smoothness r or isotropic smoothness s. Beyond that, the
change of variables preserves unbiasedness.

5

2 The Function Spaces
For natural numbers r and d the Sobolev space H r,mix(Rd) of dominating mixed
smoothness r is the real vector space

of d-variate, real valued functions, equipped with the scalar product

H r,mix(Rd) =

(cid:104)f, g(cid:105)H r,mix(Rd) =

(cid:110)
f ∈ L2(Rd) | Dαf ∈ L2(Rd) for every α ∈ {0, . . . , r}d(cid:111)
(cid:88)
 (cid:88)

(cid:104)Dαf, Dαg(cid:105)L2(Rd) .

1/2

(cid:107)Dαf(cid:107)2

α∈{0,...,r}d

L2(Rd)

.

The scalar product induces the norm

(cid:107)f(cid:107)H r,mix(Rd) =

α∈{0,...,r}d

It is known that H r,mix(Rd) is a Hilbert space and its elements can be considered
In this thesis, the Fourier transform is the unique

to be continuous functions.
continuous linear operator F : L2(Rd) → L2(Rd) satisfying

(cid:90)

Rd

Ff (y) =

f (x) e−2πi(cid:104)x,y(cid:105) dx

for integrable f : Rd → R and y ∈ Rd. The space H r,mix(Rd) contains exactly
those functions f ∈ L2(Rd) with Ff · h1/2
r ∈ L2(Rd) for the Fourier transform Ff
of f and the weight function

hr : Rd → R+,

hr(x) =

|2πxj|2αj =

|2πxj|2k.

(cid:88)

d(cid:89)

α∈{0,...,r}d

j=1

d(cid:89)

r(cid:88)

j=1

k=0

In terms of its Fourier transform, the norm of f ∈ H r,mix(Rd) is given by

(cid:90)

(cid:107)f(cid:107)2

H r,mix(Rd) =

|Ff (x)|2 · hr(x) dx.

Rd

Analogously, the isotropic Sobolev space H s(Rd) of smoothness s ∈ N is

H s(Rd) =(cid:8)f ∈ L2(Rd) | Dαf ∈ L2(Rd) for every α ∈ Nd

0 with (cid:107)α(cid:107)1 ≤ s(cid:9) ,

6

equipped with the scalar product

(cid:104)f, g(cid:105)H s(Rd) =

(cid:88)
tion |α| = (cid:107)α(cid:107)1 =(cid:80)d

(cid:107)α(cid:107)1≤s

j=1 |αj|.

(cid:104)Dαf, Dαg(cid:105)L2(Rd)

and its induced norm (cid:107)f(cid:107)H s(Rd). For α ∈ Nd

0, we will frequently use the abbrevia-

The space H s(Rd) is a Hilbert space, too. In the following, we will assume that
s is greater than d/2. Then H s(Rd) also consists of continuous functions, exactly
those functions f ∈ L2(Rd) with Ff · v1/2
s ∈ L2(Rd) for the Fourier transform Ff
of f and the weight function

vs : Rd → R+,

vs(x) =

(cid:88)

d(cid:89)

|α|≤s

j=1

|2πxj|2αj (cid:16)(cid:0)1 + (cid:107)x(cid:107)2

(cid:1)s .

2

In terms of its Fourier transform, the norm of f ∈ H s(Rd) is given by

(cid:90)

(cid:107)f(cid:107)2

H s(Rd) =

|Ff (x)|2 · vs(x) dx.

Rd

Furthermore, let Cc(Rd) be the real vector space of all continuous real valued
functions with compact support in Rd. The spaces ˚H r,mix([0, 1]d) and ˚H s([0, 1]d)
of functions in H r,mix(Rd) or H s(Rd) with compact support in the unit cube are
subspaces of Cc(Rd). They can also be considered as subspaces of the Hilbert space

f ∈ L2([0, 1]d) | Dαf ∈ L2([0, 1]d) for every α ∈ {0, . . . , r}d(cid:111)
(cid:110)

H r,mix([0, 1]d) =

,

equipped with the scalar product

(cid:104)f, g(cid:105)H r,mix([0,1]d) =

(cid:104)Dαf, Dαg(cid:105)L2([0,1]d) ,

(cid:88)

α∈{0,...,r}d

or the Hilbert space

H s([0, 1]d) =(cid:8)f ∈ L2([0, 1]d) | Dαf ∈ L2([0, 1]d) for α ∈ Nd

0 with |α| ≤ s(cid:9) ,

with the scalar product

(cid:104)f, g(cid:105)H s([0,1]d) =

(cid:88)

|α|≤s

(cid:104)Dαf, Dαg(cid:105)L2([0,1]d) .

7

3 The Basic Quadrature Rule

We introduce a family of deterministic and linear quadrature rules. This family is
fundamental to our studies. All the algorithms to be presented are based on the
following deﬁnition.
Algorithm. Let S ∈ Rd×d be invertible and v be a vector in Rd. We deﬁne

f(cid:0)S−(cid:62)(m + v)(cid:1)

Qv

S(f ) =

1

| det S|

(cid:88)

m∈Zd

for any admissible input function f : Rd → R. We call v shift parameter and
denote by QS the algorithm Qv

S for shift parameter v = 0.

The matrix S−(cid:62) is the transpose of the inverse of S. For now, S can be any in-
vertible matrix. But later on, it will be a ﬁxed matrix B multiplied with a number
n1/d and a dilation matrix ˆu = diag(u1, . . . , ud) for a dilation parameter u ∈ Rd.
The dilation parameter u ∈ Rd and shift parameter v ∈ Rd are also arbitrary. As
we go along, they will be chosen as independent random variables U and V that
are uniformly distributed in [1, 21/d]d and [0, 1]d, respectively.

S adds up the values of f at the lattice points (cid:0)S−(cid:62) (m + v)(cid:1),
m ∈ Zd, in the corner of each parallelepiped (cid:0)S−(cid:62)(cid:0)m + v + [0, 1]d(cid:1)(cid:1) weighted
(cid:8)S−(cid:62)(cid:0)m + v + [0, 1]d(cid:1) | m ∈ Zd(cid:9).

with the volume |det S|−1 of this parallelepiped. The value Qv
S(f ) hence can
be thought of as a Riemann sum of f over Rd with respect to the partition

The rule Qv

Admissible input functions are, for instance, functions f with compact support.
For such functions the above sum is a ﬁnite sum. To integrate f, the algorithm
S uses the nodes S−(cid:62)(m + v), where m ∈ Zd is a lattice point in the compact
Qv

set (cid:0)S(cid:62) (supp f ) − v(cid:1) of volume (cid:0)det(S) · λd (supp f )(cid:1). Here, λd is the Lebesgue

S. In particular, the number of nodes of Qv

measure in Rd. The indicated volume is the approximate number of function values
aS for growing a ≥ 1 is
computed by Qv
of order ad. The following simple lemma gives an exact upper bound, see [S94] for
other bounds.
Lemma 1. Suppose f : Rd → R is supported in an axis-parallel cube of edge length
l > 0. For any invertible matrix S ∈ Rd×d, v ∈ Rd and a ≥ 1 the quadrature rule
aS uses at most (l · (cid:107)S(cid:107)1 + 1)d · ad function values of f.
Qv

8

2

(cid:1) ∈ al
(cid:20)

(cid:1) ∈

2 · [−1, 1]d + x0 for some x0 ∈ Rd.
Proof. By assumption, f has compact support in l
The number of computed function values is the number of points m ∈ Zd for which
(aS)−(cid:62)(m + v) is in supp f and hence bounded by the size of

(cid:26)
(cid:26)
m ∈ Zd | m +(cid:0)v − aS(cid:62)x0

m ∈ Zd | (aS)−(cid:62)(m + v) ∈ l
2

M =

=

(cid:27)
(cid:27)

· [−1, 1]d + x0

· S(cid:62)[−1, 1]d

.

Since (cid:107)S(cid:62)x(cid:107)∞ ≤ (cid:107)S(cid:62)(cid:107)∞ = (cid:107)S(cid:107)1 for x ∈ [−1, 1]d,

(cid:40)
m ∈ Zd | m +(cid:0)v − aS(cid:62)x0

M ⊆

−al
2

(cid:107)S(cid:107)1,

(cid:107)S(cid:107)1

al
2

(cid:21)d(cid:41)

and |M| ≤ (al(cid:107)S(cid:107)1 + 1)d. With 1 ≤ a we get the estimate of Lemma 1.

The error of this algorithm for integration on Cc(Rd) can be expressed in terms

of the Fourier transform.
Lemma 2. For any invertible matrix S ∈ Rd×d, v ∈ Rd and f ∈ Cc(Rd)

S(f ) − Id(f )| ≤ (cid:88)

|Qv

m∈Zd\{0}

|Ff (Sm)| .

Proof. The function g = f◦S−(cid:62)(·+v) is continuous with compact support. Hence,
the Poisson summation formula and an aﬃne linear substitution x = S(cid:62)y− v yield

(cid:88)

(cid:88)
(cid:88)

m∈Zd

(cid:90)

Qv

S(f ) =

1

|det S|

1

Fg(m)

g(m) =

|det S|

f(cid:0)S−(cid:62)(x + v)(cid:1) · e−2πi(cid:104)x,m(cid:105) dx

m∈Zd

(cid:90)

|det S|

1

(cid:88)
(cid:88)

m∈Zd

=

=

=

Rd

m∈Zd
f (y) · e−2πi(cid:104)S(cid:62)y−v,m(cid:105) dy

Rd
Ff (Sm) · e2πi(cid:104)v,m(cid:105),

m∈Zd

If not, the stated
if the latter series converges absolutely, see [K00, pp. 356].
inequality is obvious. This proves the statement, since Id(f ) = Ff (S · 0) · e2πi(cid:104)v,0(cid:105).

9

4 Frolov’s Deterministic Algorithm on ˚H r,mix([0, 1]d)

(b)

j=1

It is known how to choose the matrix S in the rule Qv
S to get a good deterministic
quadrature rule on ˚H r,mix([0, 1]d). Let the matrix B ∈ Rd×d satisfy the following
three conditions:

(Bm)j

(a) B is invertible,

(c) For any x, y ∈ Rd the box [x, y] with volume V =

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 1, for any m ∈ Zd \ {0},

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) d(cid:81)
where [x, y] =(cid:8)z ∈ Rd | zj is inbetween of xj and yj for j = 1, . . . , d(cid:9). Such a ma-
trix shall be called a Frolov matrix. Property (b) says that for n > 0 every point
(cid:81)d
of the lattice n1/dBZd but zero lies in the set Dn of all vectors x ∈ Rd with
j=1 |xj| ≥ n, the complement of a hyperbolic cross.

most V + 1 lattice points Bm, m ∈ Zd,

|xj − yj| contains at

d(cid:81)

j=1

This graphic shows the lat-
tice n1/dBZd for d = 2, n = 9
and the Frolov matrix

(cid:33)

(cid:32)
1 2 − √
√

1 2 +

2
2

.

B =

Except zero, every lattice
point lies inside D9.

It is known that one can construct such a matrix B in the following way. Let
p ∈ Z[x] be a polynomial of degree d with leading coeﬃcient 1 which is irreducible
over Q and has d diﬀerent real roots ζ1, . . . , ζd. Then the matrix

B =(cid:0)ζ j−1

(cid:1)d

i

i,j=1

has the desired properties, as shown in [T93, p. 364] and [U14]. In arbitrary dimen-
sion d we can choose p(x) = (x− 1)(x− 3)· . . .· (x− 2d + 1)− 1, see [F76] or [U14],
but there are many other possible choices. For example, if d is a power of two,
we can set p(x) = 2 cos (d · arccos(x/2)) = 2 Td(x/2), where Td is the Chebyshev

10

-20-1001020-1001020polynomial of degree d, see [T93, p. 365]. Then the roots of p are explicitly given

by ζj = 2 cos(cid:0) 2j−1

2d π(cid:1) for j = 1, . . . , d.

From now on, let B be an arbitrary but ﬁxed, d-dimensional Frolov matrix.

Constants may depend on the choice of B.

Algorithm. For any natural number n, we consider the quadrature rule Qn1/dB
from Section 3 with shift parameter zero. This deterministic algorithm is usually
referred to as Frolov’s algorithm.

For input functions f with support in [0, 1]d the number of function values
computed by Qn1/dB is of order n. To be precise, Lemma 1 says that Qn1/dB uses
at most ((cid:107)B(cid:107)1 + 1)d · n function values of f.

K. K. Frolov has already seen in 1976 that the algorithm Qn1/dB is optimal on
˚H r,mix([0, 1]d) in the sense of order of convergence. It satisﬁes the following error
bound.
Theorem 1. There is some c > 0 such that for every n ≥ 2 and f ∈ ˚H r,mix([0, 1]d)

|Qn1/dB(f ) − Id(f )| ≤ c n−r (log n)

d−1

2 (cid:107)f(cid:107)H r,mix([0,1]d) .

See also [F76] and [U14] or my Bachelor thesis for a proof of this error bound
n1/d ˆuB for any
and its optimality. In fact, this error bound holds uniformly for Qv
u ∈ [1, 21/d]d and v ∈ [0, 1]d, which is the statement of Theorem 3 in Section 5.1.
Theorem 1 is only a special case.

But Frolov’s algorithm is also optimal among deterministic quadrature rules

on ˚H s([0, 1]d) in the sense of order of convergence. It satisﬁes:
Theorem 2. There is some c > 0 such that for every n ≥ 2 and f ∈ ˚H s([0, 1]d)

|Qn1/dB(f ) − Id(f )| ≤ c n−s/d (cid:107)f(cid:107)H s([0,1]d) .

This is a special case of Theorem 4 in Section 5.1. See [N88] for a proof of the

optimality of this order.

11

5 The Eﬀect of Random Dilations

We study the impact of random dilations on Frolov’s algorithm Qn1/dB.
Algorithm. For any natural number n and shift parameter v ∈ Rd we consider
the method Qv
from Section 3 with a dilation parameter U that is uniformly
distributed in the box [1, 21/d]d.

n1/d ˆU B

For input functions f from ˚H s([0, 1]d) or ˚H r,mix([0, 1]d) the information cost of
is roughly between det(B) · n and 2 · det(B) · n. More precisely, it uses at

n1/d ˆU B

Qv
most 2 · ((cid:107)B(cid:107)1 + 1)d · n function values of f.

5.1 Worst Case Errors

In the worst case, the error of this method has the same order of convergence like
Frolov’s algorithm, both for ˚H r,mix([0, 1]d) and ˚H s([0, 1]d).
Theorem 3. There is a constant c > 0 such that for any shift parameter v ∈ Rd,
n ≥ 2 and f ∈ ˚H r,mix([0, 1]d)

(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12) ≤ c n−r (log n)

d−1

2 (cid:107)f(cid:107)H r,mix([0,1]d) .

sup

u∈[1,21/d]d

Proof. Let Qv
consideration. By Lemma 2 and Hölder’s inequality,

n1/d ˆuB be an arbitrary realization of the algorithm Qv

under

n1/d ˆU B

(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12)2 ≤
 (cid:88)

≤

hr(n1/d ˆuBm)−1

 (cid:88)
 ·

(cid:12)(cid:12)Ff (n1/d ˆuBm)(cid:12)(cid:12)2
 (cid:88)

m∈Zd\{0}

m∈Zd\{0}

m∈Zd\{0}

hr(n1/d ˆuBm) ·(cid:12)(cid:12)Ff (n1/d ˆuBm)(cid:12)(cid:12)2

 .

We ﬁrst prove that the ﬁrst factor in this product is bounded above by a constant
multiple of n−2r (log n)d−1.
Consider the auxiliary set N (β) = {x ∈ Rd | (cid:98)2βj−1(cid:99) ≤ |xj| < 2βj , 1 ≤ j ≤ d}
for β ∈ Nd
summation is the disjoint union of all Gβ

n =(cid:8)m ∈ Zd \ {0} | n1/d ˆuBm ∈ N (β)(cid:9). The domain Zd \ {0} of
(cid:12)(cid:12) ≥ n for any

For |β| ≤ log2 n, the points x in N (β) satisfy (cid:81)d
second property of the Frolov matrix B yields (cid:81)d

n over β ∈ Nd
0.
j=1 |xj| < 2|β| ≤ n. But the

(cid:12)(cid:12)n1/duj(Bm)j

0 and Gβ

j=1

12

n is empty for |β| ≤ log2 n. For |β| > log2 n, any m ∈ Gβ

n

m ∈ Zd \ {0}. Hence, Gβ
satisﬁes

hr(n1/d ˆuBm) ≥ d(cid:89)

(cid:0)1 + (cid:98)2βj−1(cid:99)2r(cid:1) ≥ d(cid:89)

22r(βj−1) = 22r(|β|−d)

j=1

j=1

and hence hr(n1/d ˆuBm)−1 ≤ 22r(d−|β|). Because of the third property of the Frolov
matrix, we obtain

m ∈ Zd \ {0} | |(Bm)j| <

2βj
n1/d

(cid:27)(cid:12)(cid:12)(cid:12)(cid:12) ≤ 2d+|β|n−1 + 1 ≤ 2d+1+|β|n−1.

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)

(cid:12)(cid:12) ≤
(cid:12)(cid:12)Gβ
That yields(cid:88)

n

m∈Zd\{0}

hr

=

β∈Nd

(cid:0)n1/d ˆuBm(cid:1)−1
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:63)≤ (cid:88)
∞(cid:88)

|β|>log2 n

|β|>log2 n

m∈Gβ

=

0

n

=

k=(cid:100)log2 n(cid:101)

≤ 22rd+d+1 · n−1

= 22rd+d+1 · n−1

hr(n1/d ˆuBm)−1

hr(n1/d ˆuBm)−1

n

m∈Gβ
22r(d−|β|) · n−1 · 2d+1+|β|

22r(d−k) · n−1 · 2d+1+k ·(cid:12)(cid:12)(cid:8)β ∈ Nd

0 | |β| = k(cid:9)(cid:12)(cid:12)

2(1−2r)k · (k + 1)d−1

2(1−2r)(k+(cid:100)log2 n(cid:101)) · (k + 1 + (cid:100)log2 n(cid:101))d−1

∞(cid:88)
∞(cid:88)

k=(cid:100)log2 n(cid:101)

k=0

∞(cid:88)

∞(cid:88)

k=0

≤ 22rd+d+1 · n−1 · n1−2r ·

2(1−2r)k · 2d−1 · (k + 1)d−1 · (cid:100)log2 n(cid:101)d−1

(cid:18)

(cid:19)d−1

(cid:32)

≤ 22rd+2d · n−2r ·

k=0

22rd+3d−1 (log 2)1−d

=

2(1−2r)k(k + 1)d−1

2 · log n
log 2

(cid:33)

(cid:0)21−2r(cid:1)k (k + 1)d−1

∞(cid:88)

· n−2r (log n)d−1.

This is the desired estimate, since 21−2r < 1.

k=0

13

We now show that the second factor in the above inequality is bounded above

by a constant multiple of (cid:107)f(cid:107)2

For x ∈ Rd we have

H r,mix([0,1]d). This proves the theorem.

hr(x) · |Ff (x)|2 =

|FDαf (x)|2 .

(cid:88)

α∈{0,...,r}d

The function gα = Dαf ◦ (n1/d ˆuB)−(cid:62) has compact support in the parallelepiped

(n1/d ˆuB)(cid:62)[0, 1]d. Consider the set Jn of all k ∈ Zd for which (cid:0)k + [0, 1]d(cid:1) has a

nonempty intersection with (n1/d ˆuB)(cid:62)[0, 1]d. Then

(cid:12)(cid:12)FDαf(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2

(cid:12)(cid:12)(cid:12)(cid:12)2

Thus we obtain(cid:88)

m∈Zd\{0}

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)
(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Rd

Rd

1

1

=

=

=

≤

det(n1/d ˆuB)

det(n1/d ˆuB)

gα(x) · e−2πi(cid:104)m,x(cid:105)dx

Dαf (y) · e−2πi(cid:104)n1/d ˆuBm,y(cid:105)dy

(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)(cid:104)gα, e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)

(cid:90)
(cid:88)
(cid:104)gα(x), e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)
(cid:88)
hr(n1/d ˆuBm) ·(cid:12)(cid:12)Ff (n1/d ˆuBm)(cid:12)(cid:12)2 ≤ (cid:88)
(cid:88)

(cid:88)
(cid:12)(cid:12)(cid:12)(cid:104)gα, e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)

|det(n1/d ˆuB)|2

m∈Zd

α∈{0,...,r}d

|Jn|

|Jn|

k∈Jn

k∈Jn

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)2

.

(cid:12)(cid:12)(cid:12)2

(cid:12)(cid:12)FDαf (n1/d ˆuBm)(cid:12)(cid:12)2

≤

=

=

=

|det(n1/d ˆuB)|2

|Jn|

|det(n1/d ˆuB)|2

|Jn|

|det(n1/d ˆuB)|2

|Jn|

m∈Zd

α∈{0,...,r}d

(cid:88)
(cid:88)

k∈Jn
(cid:107)gα(cid:107)2

k∈Jn
(cid:107)gα(cid:107)2

L2(Rd)

(cid:88)
(cid:88)
(cid:88)
(cid:88)

α∈{0,...,r}d

α∈{0,...,r}d

(cid:107)Dαf(cid:107)2

L2(Rd)

|det(n1/d ˆuB)|
|det(n1/d ˆuB)| (cid:107)f(cid:107)2

|Jn|

α∈{0,...,r}d

L2(k+[0,1]d)

=

Since both |Jn| and (cid:12)(cid:12)det(n1/d ˆuB)(cid:12)(cid:12) are of order n, their ratio is bounded by a

H r,mix([0,1]d) .

constant and the above inequality yields the statement.

14

Theorem 4. There is a constant c > 0 such that for any shift parameter v ∈ Rd,
n ∈ N and f ∈ ˚H s([0, 1]d)

(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12) ≤ c n−s/d (cid:107)f(cid:107)H s([0,1]d) .

sup

u∈[1,21/d]d

Proof. Let Qv
consideration. By Lemma 2 and Hölder’s inequality,

n1/d ˆuB be an arbitrary realization of the algorithm Qv

under

n1/d ˆU B

 (cid:88)
(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12)2 ≤
 (cid:88)
 ·
(cid:0)n1/d ˆuBm(cid:1)−1

≤

vs

(cid:12)(cid:12)Ff(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2
 (cid:88)

vs

m∈Zd\{0}

m∈Zd\{0}

m∈Zd\{0}

(cid:0)n1/d ˆuBm(cid:1) ·(cid:12)(cid:12)Ff(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2

 .

The ﬁrst factor in this product is bounded above by a constant multiple of n−2s/d:
Since

(cid:0)n1/d ˆuBm(cid:1) ≥ (cid:107)n1/d ˆuBm(cid:107)2s

vs

2 ≥ n2s/d · (cid:107)Bm(cid:107)2s

2 ≥ n2s/d · (cid:107)B−1(cid:107)−2s

2

· (cid:107)m(cid:107)2s
2 ,

we have(cid:88)

m∈Zd\{0}

vs

(cid:0)n1/d ˆuBm(cid:1)−1 ≤ n−2s/d · (cid:107)B−1(cid:107)2s

2 · (cid:88)

m∈Zd\{0}

(cid:107)m(cid:107)−2s

2

,

where this last series converges for 2s > d.

We show that the second factor in the above inequality is bounded above by a

constant multiple of (cid:107)f(cid:107)2
For any x ∈ Rd we have

H s([0,1]d). This proves the theorem.

vs(x) · |Ff (x)|2 =

|FDαf (x)|2 .

(cid:88)

|α|≤s

The function gα = Dαf◦(n1/d ˆuB)−(cid:62) has compact support in the parallelepiped

(n1/d ˆuB)(cid:62)[0, 1]d. Again consider the set Jn of all k ∈ Zd for which(cid:0)k + [0, 1]d(cid:1) has

a nonempty intersection with (n1/d ˆuB)(cid:62)[0, 1]d.

15

(cid:12)(cid:12)(cid:12)(cid:12)2

We have the estimate

(cid:12)(cid:12)FDαf(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2

=

=

=

≤

Rd

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)
(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Dαf (y) · e−2πi(cid:104)n1/d ˆuBm,y(cid:105)dy

Rd

gα(x) · e−2πi(cid:104)m,x(cid:105)dx

(cid:90)
(cid:88)
(cid:104)gα(x), e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)
(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)(cid:104)gα, e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)

k∈Jn

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)2

.

det(n1/d ˆuB)

1

1

det(n1/d ˆuB)

|Jn|

|det(n1/d ˆuB)|2

k∈Jn

Thus we obtain(cid:88)

(cid:0)n1/d ˆuBm(cid:1) ·(cid:12)(cid:12)Ff(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2 ≤ (cid:88)

(cid:88)
(cid:12)(cid:12)(cid:12)(cid:104)gα, e2πi(cid:104)m,·(cid:105)(cid:105)L2(k+[0,1]d)

(cid:12)(cid:12)FDαf(cid:0)n1/d ˆuBm(cid:1)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)2

m∈Zd

|α|≤s

(cid:88)

m∈Zd\{0}
≤

|det(n1/d ˆuB)|2

=

|det(n1/d ˆuB)|2

vs
|Jn|

|Jn|

|Jn|

(cid:88)
(cid:88)

|α|≤s

m∈Zd

(cid:88)
(cid:88)
(cid:88)

|α|≤s

k∈Jn
(cid:107)Dαf(cid:107)2

k∈Jn
(cid:107)gα(cid:107)2

|Jn|

|det(n1/d ˆuB)|2

(cid:107)gα(cid:107)2

L2(Rd)

(cid:88)

|α|≤s

L2(k+[0,1]d) =
|Jn|

=

|det(n1/d ˆuB)|

L2(Rd) =

|det(n1/d ˆuB)| (cid:107)f(cid:107)2

H s([0,1]d) .

Since both |Jn| and (cid:12)(cid:12)det(n1/d ˆuB)(cid:12)(cid:12) are of order n, their ratio is bounded by a

|α|≤s

constant and the above inequality yields the statement.

5.2 Expected Errors

In expectation, the random dilations improve the order of the error of Frolov’s
algorithm by 1/2 for both ˚H r,mix([0, 1]d) and ˚H s([0, 1]d). These results are based on
the following general error bound for continuous functions with compact support.

Recall that Dn is the set of all x ∈ Rd with(cid:81)d

j=1 |xj| ≥ n.

Theorem 5. There is a constant c > 0 such that for every n ∈ N, shift parameter
v ∈ Rd and f ∈ Cc(Rd)

E(cid:12)(cid:12)Qv
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤ c n−1 ·

|Ff (x)| dx.

(cid:90)

Dn

16

(cid:16)

(cid:90)

m∈Zd\{0}

m∈Zd\{0}

n1/d ˆU Bm



n1/d ˆU Bm

|Ff (x)|

=

(cid:90)

1

(21/d − 1)d

j=1 n1/d(Bm)j

(cid:17)(cid:12)(cid:12)(cid:12)
(cid:17)(cid:12)(cid:12)(cid:12) .

Proof. Thanks to Lemma 2 and the monotone convergence theorem we have

Since each n1/d ˆU Bm is uniformly distributed in the box [n1/dBm, (2n)1/dBm] with

E(cid:12)(cid:12)Qv
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤ E

 (cid:88)
(cid:12)(cid:12)(cid:12)Ff
E(cid:12)(cid:12)(cid:12)Ff
(cid:16)
(cid:88)
(cid:12)(cid:12)(cid:12), this series equals
volume(cid:0)21/d − 1(cid:1)d ·(cid:12)(cid:12)(cid:12)(cid:81)d
(cid:88)
(cid:81)d
j=1 |n1/d(Bm)j| dx
(cid:88)
(cid:81)d
|Ff (x)|
(cid:90)
j=1 2−1/d |xj| dx
j=1 |xj| ·(cid:12)(cid:12)(cid:8)m ∈ Zd \ {0} | x ∈ [n1/dBm, (2n)1/dBm](cid:9)(cid:12)(cid:12) dx
(cid:81)d
(cid:21)(cid:27)(cid:12)(cid:12)(cid:12)(cid:12) dx.
(cid:20)
(cid:90)
(cid:81)d
|Ff (x)|
j=1 |xj| ·
(cid:12)(cid:12) + 1 ≤ 2n−1(cid:81)d

Thanks to the properties of the Frolov matrix B, if(cid:81)d
(cid:12)(cid:12) xj
is empty and otherwise contains no more than (cid:81)d
(cid:90)

j=1 |xj| < n, the latter set
j=1 |xj|

m ∈ Zd \ {0} | Bm ∈

(21/d − 1)d
(21/d − 1)d ·

2

points. Thus, we arrive at

E(cid:12)(cid:12)Qv
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤

2

(21/d − 1)d ·

(2n)1/d ,

n1/d

|Ff (x)| dx

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)

≤

=

=

[n1/dBm,(2n)1/dBm]

|Ff (x)|

m∈Zd\{0}

[n1/dBm,(2n)1/dBm]

1

m∈Zd\{0}

j=1

n1/d

4

(21/d − 1)d · n−1

Dn

Rd

Rd

x

x

and the theorem is proven.

(cid:82)

|Ff (x)| dx. Hence, the general upper bound for the error of Qv

Additional diﬀerentiability properties of the function f ∈ Cc(Rd) result in decay
properties of its Fourier transform Ff. This leads to estimates of the integral
(f ) in
Dn
Theorem 5 adjusts to the diﬀerentiability of f. Two such examples are functions
from ˚H r,mix(Rd) and ˚H s(Rd).
Lemma 3. There is some c > 0 such that for each n ≥ 2 and f ∈ ˚H r,mix([0, 1]d)

n1/d ˆU B

(cid:90)

Dn

|Ff (x)| dx ≤ c n−r+1/2 (log n)

d−1

2 (cid:107)f(cid:107)H r,mix([0,1]d) .

17

=

Dn

≤

Dn

(cid:19)

Dn

(cid:107)f(cid:107)2

(cid:19)2

(cid:18)(cid:90)

(cid:18)(cid:90)

hr(x)−1 dx

|Ff (x)| dx

(cid:19)2
(cid:19)

H r,mix(Rd) = n|det B|

hr(x)−1/2 · |Ff (x)| hr(x)1/2 dx

Proof. Applying Hölder’s inequality and a linear substitution x = n1/dBy to the
above integral, we get

(cid:18)(cid:90)
(cid:18)(cid:90)
with G = B−1D1 being the set of all y ∈ Rd with (cid:81)d
suﬃcient to prove that the integral(cid:82)
Again consider the auxiliary set N (β) = {x ∈ Rd |(cid:2)2βj−1(cid:3) ≤ |xj| < 2βj , 1 ≤ j ≤ d}
n = (cid:8)y ∈ G | n1/dBy ∈ N (β)(cid:9). Similar to the proof of

j=1 |(By)j| ≥ 1. It it thus
G hr(n1/dBy)−1 dy is bounded by a constant

for β ∈ Nd
Theorem 3, the domain G of integration is the disjoint union of all Gβ
where Gβ
22r(d−|β|) for y ∈ Gβ

n over β ∈ Nd
0,
n = ∅, if |β| ≤ log2 n, and otherwise the integrand is bounded above by

multiple of n−2r (log n)d−1.

hr(n1/dBy)−1 dy

0 and the set Gβ

H r,mix(Rd)

(cid:107)f(cid:107)2

G

λd(Gβ

n. On the other hand,

n) ≤ λd(cid:0)(n1/dB)−1N (β)(cid:1) = n−1 · | det B|−1 · λd(N (β))
= n−1 · | det B|−1 · 2d · d(cid:89)
(cid:90)
(cid:88)

(cid:0)2βj −(cid:2)2βj−1(cid:3)(cid:1) ≤ n−1 · | det B|−1 · 2d · 2|β|.
(cid:90)

j=1

hr(n1/dBy)−1 dy

Like in the proof of Theorem 3, we obtain

22r(d−|β|) · n−1 · | det B|−1 · 2d+β

22r(d−|β|) · n−1 · 2d+1+|β|

∞(cid:88)

(cid:0)21−2r(cid:1)k (k + 1)d−1

(cid:33)

n−2r (log n)d−1,

β∈Nd

0

Gβ
n

hr(n1/dBy)−1 dy

G

=

Gβ
n

(cid:90)

|β|>log2 n

hr(n1/dBy)−1 dy =

(cid:88)
≤ (cid:88)
= | det B|−1 · 2−1 · (cid:88)
(cid:32)

|β|>log2 n

|β|>log2 n

(cid:63)≤

22rd+3d−2| det B|−1(log 2)1−d

k=0

where the constant is ﬁnite, since 21−2r < 1.

Combining Theorem 5 and Lemma 3 yields:

18

(cid:90)

Dn

(cid:18)(cid:90)
(cid:18)(cid:90)

Dn

≤

|Ff (x)| dx ≤ c n−s/d+1/2 (cid:107)f(cid:107)H s([0,1]d) .

Proof. Like in Lemma 3, we apply Hölder’s inequality and get

(cid:18)(cid:90)

(cid:19)2
(cid:19)

|Ff (x)| dx

=

|Ff (x)| vs(x)1/2 · vs(x)−1/2 dx

vs(x)−1 dx

Dn

Dn

· (cid:107)f(cid:107)2

H s(Rd) ≤ ˜c ·

(cid:19)2
(cid:19)
(cid:1)−s dx

(cid:18)(cid:90)

Dn

(cid:0)1 + (cid:107)x(cid:107)2

2

Theorem 6. There is a constant c > 0 such that for every n ≥ 2, shift parameter
v ∈ Rd and f ∈ ˚H r,mix([0, 1]d)

E(cid:12)(cid:12)Qv
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤ c n−r−1/2 (log n)

d−1

2 (cid:107)f(cid:107)H r,mix([0,1]d) .

If, however, the integrand is from the space ˚H s([0, 1]d) ⊆ Cc(Rd), the following

lemma holds.
Lemma 4. There is some c > 0 such that for each n ∈ N and f ∈ ˚H s([0, 1]d)

· (cid:107)f(cid:107)2

H s([0,1]d) ,

for some ˜c > 0. Since (cid:107)x(cid:107)2 ≥ max{|xj| | j = 1, . . . , n} ≥ n1/d for x ∈ Dn, the

set Dn is a subset of(cid:8)x ∈ Rd : (cid:107)x(cid:107)2 ≥ n1/d(cid:9) and the latter integral in the above

integral is less than

(cid:90)

∞(cid:90)

(cid:90)

(cid:1)−s dx =

(cid:0)1 + (cid:107)x(cid:107)2
(cid:0)1 + R2(cid:1)−s · Rd−1 dR ≤ σ (Sd−1)

Sd−1

n1/d

2

∞(cid:90)

∞(cid:90)

{x∈Rd: (cid:107)x(cid:107)2≥n1/d}

= σ (Sd−1)

(cid:0)1 + R2(cid:1)−s · Rd−1 dσ dR

R−2s+d−1 dR ≤ ˆc · n−2s/d+1,

n1/d

n1/d

for some ˆc > 0, since −2s + d − 1 < −1.

In this case, combining Theorem 5 and Lemma 4 yields:

Theorem 7. There is a constant c > 0 such that for every n ∈ N, shift parameter
v ∈ Rd and f ∈ ˚H s([0, 1]d)

n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤ c n−s/d−1/2 (cid:107)f(cid:107)H s([0,1]d) .
E(cid:12)(cid:12)Qv

We remark that the Frolov properties of the matrix B are not needed to get
this estimate on ˚H s([0, 1]d), although they are essential for the upper bound on

19

˚H r,mix([0, 1]d) from Theorem 6. As seen in the proof of Lemma 4 and contrarily
to Lemma 3, we do not need that the lattice points of n1/dBZd \ {0} lie in Dn,

but only that they lie in the bigger set(cid:8)x ∈ Rd | (cid:107)x(cid:107)2 ≥ n1/d(cid:9). For example, the

identity matrix would do. But if B is a Frolov matrix, Qv
n1/d ˆuB works universally for
˚H r,mix(Rd) and ˚H s(Rd). Furthermore, the Frolov properties of B prevent extremely
large jumps of the number of nodes of Qv
n1/d ˆuB for small changes of the
dilation parameter u ∈ [1, 21/d]d.

n1/d ˆuB = Qv

20

6 Further Improvements through Random Shifts

Now we also choose the shift parameter v in Qv

n1/d ˆU B

at random.

from Sec-
Algorithm. For any natural number n we consider the method QV
tion 3 with independent dilation parameter U, uniformly distributed in [1, 21/d]d,
and shift parameter V , uniformly distributed in [0, 1]d.

n1/d ˆU B

For input functions f from ˚H s([0, 1]d) or ˚H r,mix([0, 1]d) the information cost of

the method QV

n1/d ˆU B

is again of order n.

The ﬁrst advantage of this method is its unbiasedness.

Proposition 1. Let S ∈ Rd×d be an invertible matrix. For any f ∈ L1(cid:0)Rd(cid:1), the

method QV

S satisﬁes

E(cid:0)QV
S (f )(cid:1) = Id(f ).

In particular, the method QV

n1/d ˆU B

is well-deﬁned and unbiased on L1(cid:0)Rd(cid:1).

(cid:18) 1

|det S|

E

(cid:12)(cid:12)f(cid:0)S−(cid:62)(m + V )(cid:1)(cid:12)(cid:12)(cid:19)

Proof. By the monotone convergence theorem,

(cid:12)(cid:12)f(cid:0)S−(cid:62)(m + V )(cid:1)(cid:12)(cid:12)(cid:33)
(cid:88)
(cid:90)
(cid:12)(cid:12)f(cid:0)S−(cid:62)(m + x)(cid:1)(cid:12)(cid:12) dx
(cid:90)

[0,1]d

=

m∈Zd

|f (y)| dy =

E

=

=

1

m∈Zd

|det S|
1

(cid:32)(cid:88)
(cid:88)
(cid:90)
(cid:88)
S (f ) = (cid:80)

|det S|

m∈Zd

m∈Zd

|f (y)| dy < ∞.

S−(cid:62)(m+[0,1]d)

Rd

1|det S| f(cid:0)S−(cid:62)(m + V )(cid:1) hence converges absolutely almost
(cid:12)(cid:12)f(cid:0)S−(cid:62)(m + V )(cid:1)(cid:12)(cid:12).

1|det S|

m∈Zd

The series QV

surely and is dominated by the integrable function (cid:80)
f(cid:0)S−(cid:62)(m + x)(cid:1) dx

E(cid:0)QV
S (f )(cid:1) =

m∈Zd

(cid:90)

1

We can thus apply Lebesgue’s dominated convergence theorem to get

(cid:88)
(cid:88)

m∈Zd

|det S|

(cid:90)

[0,1]d

=

m∈Zd

S−(cid:62)(m+[0,1]d)

(cid:90)

Rd

f (y) dy =

f (y) dy = Id(f ),

for the expected value of the general algorithm at f.

21

For the method QV

n1/d ˆU B

E(cid:0)QV
n1/d ˆU B(f )(cid:1) = EUEV

, Fubini’s theorem yields

(cid:0)QV
n1/d ˆU B(f )(cid:1) = EU (Id(f )) = Id(f ),

as claimed. In particular, QV

n1/d ˆU B

(f ) is almost surely absolutely convergent.

The worst case error of this method, too, has the order n−r (log n)(d−1)/2 on
˚H r,mix([0, 1]d) and n−s/d on ˚H s([0, 1]d). This is a direct consequence of Theorem 3
and Theorem 4.
Corollary 1. There is some c > 0 such that for any n ≥ 2 and f ∈ ˚H r,mix([0, 1]d)

(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12) ≤ c n−r (log n)
(cid:12)(cid:12)Qv
n1/d ˆuB(f ) − Id(f )(cid:12)(cid:12) ≤ c n−s/d (cid:107)f(cid:107)H s([0,1]d) .

d−1

2 (cid:107)f(cid:107)H r,mix([0,1]d) .

sup

(u,v)∈[1,21/d]d×[0,1]d

sup

(u,v)∈[1,21/d]d×[0,1]d

Corollary 2. There is some c > 0 such that for any n ∈ N and f ∈ ˚H s([0, 1]d)

expected error E(cid:12)(cid:12)(cid:12)QV

The second advantage of this method is the slightly better convergence order
of its expected error on ˚H r,mix([0, 1]d). As proven by Mario Ullrich in [U16], the
in f ∈ ˚H r,mix([0, 1]d) is bounded
above by a constant multiple of n−r−1/2 (cid:107)f(cid:107)H r,mix([0,1]d) instead of a constant mul-
tiple of n−r−1/2 (log n) d−1

(f ) − Id(f )

2 (cid:107)f(cid:107)H r,mix([0,1]d).

n1/d ˆU B

n1/d ˆU B

(cid:12)(cid:12)(cid:12) of QV
(cid:18)

The proof even shows that the quantity

(f ) − Id(f )

n1/d ˆU B

satisﬁes

(cid:12)(cid:12)(cid:12)2(cid:19)1/2

E(cid:12)(cid:12)(cid:12)QV

this bound. This is a stronger statement, as implied by Hölder’s inequality.

In Lemma 2, the absolute error of Qv

S for integration on Cc(Rd) was expressed in
terms of the Fourier transform. The same can be done for the expected quadratic
S .
error of QV
Lemma 5. For any invertible matrix S ∈ Rd×d and f ∈ Cc(Rd) we have

(cid:88)

=

m∈Zd\{0}

|Ff (Sm)|2 .

E(cid:12)(cid:12)QV
S (f ) − Id(f )(cid:12)(cid:12)2
E(cid:12)(cid:12)QV
S (f ) − Id(f )(cid:12)(cid:12)2

Proof. Since the expected value of QV

= Var(cid:0)QV

S (f ) is Id(f ), we have

S (f )(cid:1) = E(cid:0)QV

S (f )2(cid:1) − Id(f )2.

22

The algorithm Qv

functions | det S|−1 f(cid:0)S−(cid:62)(k + ·)(cid:1) in L2(cid:0)[0, 1]d(cid:1) and hence itself in L2(cid:0)[0, 1]d(cid:1).

S(f ) considered as a function of v ∈ [0, 1]d is a ﬁnite sum of

Parseval’s identity states

(cid:12)(cid:12)(cid:12)(cid:12)2

.

L2([0,1]d)

Q(·)

S (f ), e2πi(cid:104)m,·(cid:105)(cid:69)
f(cid:0)S−(cid:62)(k + v)(cid:1) e−2πi(cid:104)m,v(cid:105)dv

(cid:90)
f(cid:0)S−(cid:62)v(cid:1) e−2πi(cid:104)m,v(cid:105)dv

[0,1]d

(cid:13)(cid:13)(cid:13)2

S (f )

(cid:13)(cid:13)(cid:13)Q(·)
E(cid:0)QV
S (f )2(cid:1) =
S (f ), e2πi(cid:104)m,·(cid:105)(cid:69)
(cid:68)

Q(·)

L2([0,1]d)

m∈Zd
For each index m ∈ Zd we have the equality

L2([0,1]d)

=

(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:68)
= |det S|−1(cid:88)
(cid:90)
(cid:90)

= |det S|−1

k∈Zd

Rd

Rd

=
= Ff (Sm).

f (v) e−2πi(cid:104)Sm,v(cid:105)dv

We arrive at

E(cid:12)(cid:12)QV
S (f ) − Id(f )(cid:12)(cid:12)2

=

(cid:88)

m∈Zd

which is what had to be proven.

|Ff (Sm)|2 − Id(f )2 =

(cid:88)

m∈Zd\{0}

|Ff (Sm)|2 ,

Now follows an analogue of Theorem 5 for expected quadratic errors. Like
before, the general error bound for continuous functions with compact support
adjusts to additional smoothness properties.
Theorem 8. There is some c > 0 such that for every n ∈ N and f ∈ Cc(Rd)

Proof. By Lemma 5 and the monotone convergence theorem,

L2(Dn).

E(cid:12)(cid:12)QV
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2 ≤ c n−1 (cid:107)Ff(cid:107)2
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2
(cid:12)(cid:12)QV
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2
E(cid:12)(cid:12)QV
 (cid:88)
(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)Ff (n1/d ˆU Bm)
(cid:12)(cid:12)(cid:12)2
(cid:12)(cid:12)(cid:12)Ff (n1/d ˆU Bm)
(cid:88)

= EUEV

m∈Zd\{0}

= EU

EU

=

.



m∈Zd\{0}

23

1

x

(cid:90)

(cid:90)

m∈Zd\{0}

m∈Zd\{0}

[n1/dBm,(2n)1/dBm]

(21/d − 1)d

j=1 n1/d(Bm)j

Since each n1/d ˆU Bm is uniformly distributed in the box [n1/dBm, (2n)1/dBm] with

volume(cid:0)21/d − 1(cid:1)d ·(cid:12)(cid:12)(cid:12)(cid:81)d
(cid:12)(cid:12)(cid:12), this series equals
(cid:88)
(cid:81)d
|Ff (x)|2
j=1 |n1/d(Bm)j| dx
(cid:88)
(cid:81)d
|Ff (x)|2
j=1 2−1/d |xj| dx
(cid:90)
j=1 |xj| ·(cid:12)(cid:12)(cid:8)m ∈ Zd \ {0} | x ∈ [n1/dBm, (2n)1/dBm](cid:9)(cid:12)(cid:12) dx
(cid:81)d
(cid:21)(cid:27)(cid:12)(cid:12)(cid:12)(cid:12) dx.
(cid:20)
(cid:90)
(cid:81)d
|Ff (x)|2
j=1 |xj| ·
(cid:12)(cid:12) + 1 ≤ 2n−1(cid:81)d

Thanks to the properties of the Frolov matrix B, if(cid:81)d
(cid:12)(cid:12) xj
is empty and otherwise contains no more than (cid:81)d
(cid:90)

(21/d − 1)d
(21/d − 1)d ·
(21/d − 1)d ·

j=1 |xj| < n, the latter set
j=1 |xj|

m ∈ Zd \ {0} | Bm ∈

points. Thus, we arrive at

E(cid:12)(cid:12)QV
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12) ≤

|Ff (x)|2 dx

|Ff (x)|2

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)

(2n)1/d ,

[n1/dBm,(2n)1/dBm]

1

2

2

x

n1/d

≤

=

=

Rd

Rd

j=1

n1/d

4

(21/d − 1)d · n−1

Dn

and the theorem is proven.

Finally, we can prove the stated upper bound for the expected quadratic error

of the method QV
Theorem 9. There is some c > 0 such that for every n ≥ 2 and f ∈ ˚H r,mix([0, 1]d)

n1/d ˆU B

.

(cid:16)E(cid:12)(cid:12)QV
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2(cid:17)1/2 ≤ c n−r−1/2 (cid:107)f(cid:107)H r,mix([0,1]d) .
E(cid:12)(cid:12)QV
n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2 ≤ c0 n−1 (cid:107)Ff(cid:107)2
(cid:90)

L2(Dn)

Proof. If c0 is the constant of Theorem 8, we have the upper bound

= c0 n−1
≤ c0 n−1 (cid:107)h−1

hr(x)−1 · |Ff (x)|2 hr(x) dx
r (cid:107)L∞(Dn) ·

|Ff (x)|2 hr(x) dx

Dn

(cid:90)

Rd

for the expected quadratic error.

24

Since hr(x) ≥ n2r for x ∈ Dn, we obtain the estimate

(cid:16)E(cid:12)(cid:12)QV

n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2(cid:17)1/2 ≤ c1/2

0 n−r−1/2 (cid:107)f(cid:107)H r,mix([0,1]d) .

which proves the theorem.

is also optimal for ˚H s([0, 1]d). This can be derived from
Theorem 8 using the same short argument from the proof of Theorem 9. The

(cid:12)(cid:12)(cid:12) is also a direct consequence of Theorem 7.

(f ) − Id(f )

n1/d ˆU B

n1/d ˆU B

The method QV

upper bound for E(cid:12)(cid:12)(cid:12)QV
(cid:16)E(cid:12)(cid:12)QV

Theorem 10. There is some c > 0 such that for every n ∈ N and f ∈ ˚H s([0, 1]d)

n1/d ˆU B(f ) − Id(f )(cid:12)(cid:12)2(cid:17)1/2 ≤ c n−s/d−1/2 (cid:107)f(cid:107)H s([0,1]d) .

See [N88] for a proof of the optimality of this order.

25

7 Transformations to H r,mix([0, 1]d)

n1/d ˆU B

such that their errors
We can transform the above methods Qn1/dB and QV
satisfy the same upper bounds for the full spaces H r,mix([0, 1]d) and H s([0, 1]d),
that the original algorithms satisfy for the subspaces ˚H r,mix([0, 1]d) and ˚H s([0, 1]d).
This is done by a standard method, which was already used in [T03, pp. 359] to
transform Frolov’s deterministic algorithm. It preserves the unbiasedness of the
algorithm QV

To that end let ψ : R → R be an inﬁnitely diﬀerentiable function such that
ψ|(−∞,0) = 0, ψ|(1,∞) = 1 and ψ|(0,1) : (0, 1) → (0, 1) is a diﬀeomorphism. For
example, we can choose

n1/d ˆU B

.

e

0

h(x) =

1

(2x−1)2−1

if x ∈ (0, 1),
else,

ψ(x) =

−∞ h(t) dt
−∞ h(t) dt

(cid:82) x
(cid:82) ∞

for x ∈ R. Like h also ψ is inﬁnitely diﬀerentiable and apparently satisﬁes
ψ|(−∞,0) = 0 and ψ|(1,∞) = 1. Since the derivative of ψ is strictly positive on
(0, 1), it is strictly increasing and a bijection of (0, 1) and its inverse function is
smooth.

Given such ψ, the map Ψ : Rd → Rd with Ψ(x) = (ψ(x1), . . . , ψ(xd))(cid:62) is
a diﬀeomorphism on (0, 1)d with inverse Ψ−1(x) = (ψ−1(x1), . . . , ψ−1(xd))(cid:62) and
|DΨ(x)| ψ(cid:48)≥0= det DΨ(x) =

d(cid:81)

ψ(cid:48)(xi).

i=1

If An is any linear quadrature formula for integration on the unit cube with
nodes x(j) ∈ [0, 1]d and weights aj ∈ R, where j = 1, . . . , n, we deﬁne the trans-

formed quadrature formula (cid:101)An by choosing the nodes and weights to be

˜x(j) = Ψ(x(j))

and

˜aj = aj · |DΨ(x(j))|.

26

x00.20.40.60.81h(x)00.20.40.60.81x00.20.40.60.81ψ(x)00.20.40.60.811

m∈Zd

S(f ) =

|det S|

(cid:88)

any index m ∈ Zd with S−(cid:62)(m + v) (cid:54)∈ [0, 1]d.

f(cid:0)Ψ(cid:0)S−(cid:62)(m + v)(cid:1)(cid:1) ·(cid:12)(cid:12)DΨ(cid:0)S−(cid:62)(m + v)(cid:1)(cid:12)(cid:12)

Thus, (cid:101)Qv
S for v ∈ Rd and invertible S ∈ Rd×d takes the form
(cid:101)Qv
for any input function f : [0, 1]d → R. Note that(cid:12)(cid:12)DΨ(cid:0)S−(cid:62)(m + v)(cid:1)(cid:12)(cid:12) is zero for
Algorithms. For any n ∈ N we consider the transformed versions (cid:101)Qn1/dB and
(cid:101)QV
information costs of (cid:101)Qn1/dB and (cid:101)QV
Proposition 2. The method (cid:101)QV

These algorithms are well deﬁned for any input function f : [0, 1]d → R. The
are of order n. By Lemma 1, they are at

is well-deﬁned and unbiased on L1([0, 1]d).
Proof. Let f ∈ L1([0, 1]d). By the Change of Variables Theorem, f0 = f ◦ Ψ·|DΨ|
is also integrable on [0, 1]d and satisﬁes

of the algorithms Qn1/dB and QV

most 2 · ((cid:107)B(cid:107)1 + 1)d · n.

from Section 4 and Section 6.

n1/d ˆU B

n1/d ˆU B

n1/d ˆU B

n1/d ˆU B

Id(f ) = Id(f0) and

(cid:101)Qv
n1/d ˆuB of (cid:101)QV
for any realization (cid:101)Qv
(cid:17)
= E(cid:0)QV
n1/d ˆU B(f0)(cid:1) = Id(f0) = Id(f )

n1/d ˆuB(f ) = Qv

. This yields

n1/d ˆU B(f )

n1/d ˆuB(f0)

n1/d ˆU B

satisﬁes the following error bounds on H r,mix([0, 1]d).

n1/d ˆU B

Theorem 11. There is some c > 0 such that for every n ≥ 2 and f ∈ H r,mix([0, 1]d)

(cid:12)(cid:12)(cid:12)2(cid:19)1/2 ≤ c n−r−1/2 (cid:107)f(cid:107)H r,mix([0,1]d)
(cid:12)(cid:12)(cid:12) ≤ c n−r (log n)

and
2 (cid:107)f(cid:107)H r,mix([0,1]d) .

d−1

n1/d ˆU B(f ) − Id(f )

n1/d ˆU B(f ) − Id(f )

(cid:12)(cid:12)(cid:12)(cid:101)QV

n1/d ˆuB(f ) = Qv
f ∈ L1(Rd) and f0 = f ◦ Ψ · |DΨ|.

n1/d ˆuB(f0) and Id(f ) = Id(f0) for any function

Since ψ(cid:48)(x) = 0 for x (cid:54)∈ (0, 1), we have Dαf0|∂[0,1]d = 0 for each α ∈ {0, . . . , r}d

and hence f0 ∈ ˚H r,mix([0, 1]d) for any f ∈ H r,mix([0, 1]d).

by Proposition 1.

E(cid:16)(cid:101)QV
Most notably, (cid:101)QV
(cid:18)
E(cid:12)(cid:12)(cid:12)(cid:101)QV
Proof. Recall that (cid:101)Qv

(u,v)∈[1,21/d]d×[0,1]d

sup

27

That implies the estimates

(cid:18)
E(cid:12)(cid:12)(cid:12)(cid:101)QV

n1/d ˆU B(f ) − Id(f )

(cid:12)(cid:12)(cid:12)(cid:101)Qv

sup

(u,v)∈[1,21/d]d×[0,1]d

n1/d ˆuB(f ) − Id(f )

(cid:16)E(cid:12)(cid:12)Qv

n1/d ˆuB(f0) − Id(f0)(cid:12)(cid:12)2(cid:17)1/2

=
≤ c · n−r−1/2 · (cid:107)f0(cid:107)H r,mix([0,1]d) ,

(cid:12)(cid:12)(cid:12)2(cid:19)1/2
(cid:12)(cid:12)(cid:12) =

(cid:12)(cid:12)Qv
n1/d ˆuB(f0) − Id(f0)(cid:12)(cid:12)

· (cid:107)f0(cid:107)H r,mix([0,1]d) ,

sup

(u,v)∈[1,21/d]d×[0,1]d
d−1
2

≤ c · n−r(log n)

if c > 0 is the maximum of the constants of Theorem 9 and Corollary 1. That
proves the statement, since there is some c0 > 0 such that every f ∈ H r,mix([0, 1]d)
satisﬁes (cid:107)f0(cid:107)H r,mix([0,1]d) ≤ c0 (cid:107)f(cid:107)H r,mix([0,1]d). This can be proven as follows.

The partial derivatives of f0 take the form

Dαf0(x) =

∂|α|
1 ··· ∂xαd

d

∂xα1

f (Ψ(x)) · d(cid:89)

ψ(cid:48)(xi) =

α1,...,αd(cid:88)

Dβf (Ψ(x)) · Sα,β(x)

i=1

β1,...,βd=0

for α ∈ {0, 1, . . . , r}d, where Sα,β(x) is a ﬁnite sum of ﬁnite products of terms
ψ(j)(xi) with i ∈ {1, . . . , d}, j ∈ {1, . . . , rd + 1} and does not depend on f. It is
therefore continuous and bounded by some cα,β > 0.

A special case of Cauchy’s inequality says that the square of a sum is at most

the sum of the squares times the number of addends.

Using these facts, we get

|Dβf (Ψ(Ψ−1(x))|2 · |DΨ−1(x)| dx

c2
α,β

Ψ((0,1)d)

|DΨ−1(x)| α1,...,αd(cid:88)

α,β ·(cid:13)(cid:13)Dβf(cid:13)(cid:13)2

c2

L2([0,1]d)

β1,...,βd=0

≤ (r + 1)d

sup
x∈(0,1)d

β1,...,βd=0

28

(cid:107)Dαf0(cid:107)2

L2([0,1]d) ≤

≤

(cid:32) α1,...,αd(cid:88)
(cid:32) α1,...,αd(cid:88)

β1,...,βd=0

β1,...,βd=0

≤ (r + 1)d

= (r + 1)d

= (r + 1)d

(cid:33)2
(cid:13)(cid:13)L2([0,1]d)
(cid:13)(cid:13)(Dβf ◦ Ψ) · Sα,β
(cid:33)2
cα,β ·(cid:13)(cid:13)Dβf ◦ Ψ(cid:13)(cid:13)L2([0,1]d)
α1,...,αd(cid:88)
α,β ·(cid:13)(cid:13)Dβf ◦ Ψ(cid:13)(cid:13)2
(cid:90)
α1,...,αd(cid:88)
(cid:90)
α1,...,αd(cid:88)

c2
α,β

(0,1)d

c2

β1,...,βd=0

β1,...,βd=0

L2([0,1]d)

|Dβf (Ψ(x))|2 dx

≤ cα · (cid:107)f(cid:107)2

H r,mix([0,1]d) ,

for some cα > 0 and

(cid:107)f0(cid:107)2

H r,mix([0,1]d) =

(cid:88)

α∈{0,1,...,r}d

(cid:107)Dαf0(cid:107)2

L2([0,1]d) ≤ ˜c (cid:107)f(cid:107)2

H r,mix([0,1]d) ,

if ˜c is the sum of the constants cα for α ∈ {0, 1, . . . , r}d.

The corresponding error bounds for (cid:101)QV

n1/d ˆU B

on H s([0, 1]d) are proven in the

exact same manner.
Theorem 12. There is some c > 0 such that for every n ∈ N and f ∈ H s([0, 1]d)

(cid:18)
E(cid:12)(cid:12)(cid:12)(cid:101)QV

n1/d ˆU B(f ) − Id(f )

(cid:12)(cid:12)(cid:12)(cid:101)Qv

sup

(u,v)∈[1,21/d]d×[0,1]d

n1/d ˆuB(f ) − Id(f )

(cid:12)(cid:12)(cid:12)2(cid:19)1/2 ≤ c n−s/d−1/2 (cid:107)f(cid:107)H s([0,1]d)
(cid:12)(cid:12)(cid:12) ≤ c n−s/d (cid:107)f(cid:107)H s([0,1]d) .

and

The optimality of this order of convergence of the expected error on H s([0, 1]d)
was already stated by N. S. Bakhvalov in 1962, see [B62]. A proof can be found in
[N88]. The optimality of the upper bound of Theorem 9 for arbitrary dimensions
can be derived from Bakhvalov’s result for the one-dimensional case.

following error bounds.
Corollary 3. There is some c > 0 such that for any n ≥ 2 and f ∈ H r,mix([0, 1]d)

Since the transformed version (cid:101)Qn1/dB of Frolov’s deterministic algorithm is
a particular realization of the method (cid:101)QV
(cid:12)(cid:12)(cid:12) ≤ c n−r (log n)
(cid:12)(cid:12)(cid:12)(cid:101)Qn1/dB(f ) − Id(f )
(cid:12)(cid:12)(cid:12) ≤ c n−s/d (cid:107)f(cid:107)H s([0,1]d) .
(cid:12)(cid:12)(cid:12)(cid:101)Qn1/dB(f ) − Id(f )

and for any n ∈ N and f ∈ H s([0, 1]d)

, Theorem 11 and 12 imply the

2 (cid:107)f(cid:107)H r,mix([0,1]d)

n1/d ˆU B

d−1

It is also not hard to see, that the error bounds for Qv

from Theorem 3,
4, 6 and 7 on the classes ˚H r,mix([0, 1]d) and ˚H s([0, 1]d) are inherited by the method

n1/d ˆU B

(cid:101)Qv

n1/d ˆU B

on the classes H r,mix([0, 1]d) and H s([0, 1]d) in the same way.

29

n1/d ˆU B

To sum up, both the expected error and the worst case error of the method
have an optimal rate of convergence on both H r,mix([0, 1]d) and H s([0, 1]d).
In addition, the method is unbiased. It is also worth stressing that the algorithm
is universal: It does not depend on the smoothness r or s of the input function in
. Nonetheless,
the convergence rate of its error perfectly adjusts to that smoothness. The same

(cid:101)QV
any way and hence no prior knowledge of it is needed to run (cid:101)QV
is valid for the algorithms (cid:101)Qn1/dB and (cid:101)Qv

n1/d ˆU B

.

n1/d ˆU B

30

References

[B62] N. S. Bakhvalov: On a rate of convergence of indeterministic integration pro-
p . Theory of Probability and its Ap-

cesses within the functional classes W (l)
plications 7, p. 227, 1962.

[F76] K. K. Frolov: Upper Error Bounds for Quadrature Formulas on Function

Classes. Soviet Mathematics Doklady 17/6, pp. 1665–1669, 1976.

[GN01] D. Gilbarg and N. Trudinger: Elliptic Partial Diﬀerential Equations of Sec-

ond Order. Springer, Berlin Heidelberg, 2001.

[HT08] D. D. Haroske and H. Triebel: Distributions, Sobolev Spaces, Elliptic Equa-

tions. European Mathematical Society, Zürich, 2008.

[H03] F. J. Hickernell: My dream quadrature rule. Journal of Complexity 19,

pp. 420–427, 2003.

[K00] H. Koch: Number Theory: Algebraic Numbers and Functions. Graduate
Studies in Mathematics. American Mathematical Society, Providence, 2000.

[KN16] D. Krieg and E. Novak: A Universal Algorithm for Multivariate Integra-

tion, Foundations of Computational Mathematics, to appear.

[N88] E. Novak: Deterministic and Stochastic Error Bounds in Numerical Analy-
sis. Lecture Notes in Mathematics 1349. Springer, Berlin Heidelberg, 1988.

[NW10] E. Novak and H. Woźniakowski: Tractability of Multivariate Problems
II: Standard Information for Functionals. European Mathematical Society,
Zürich, 2010.

[S94] M. M. Skriganov: Constructions of uniform distributions in terms of geome-

try of numbers. Algebra i Analiz 6, 200–230, 1994.

[T93] V. N. Temlyakov: Approximation of Periodic Functions. Computational
Mathematics and Analysis Series. Nova Science Publishers, New York, 1993.

[T03] V. N. Temlyakov: Cubature formulas, discrepancy, and nonlinear approxi-

mation. Journal of Complexity 19, pp. 352–391, 2003.

[U14] M. Ullrich: On "Upper error bounds for quadrature formulas on function
classes" by K. K. Frolov. In R. Cools and D. Nuyens: Proceedings of the
MCQMC 2014. Springer, to appear.

31

[U16] M. Ullrich: A Monte Carlo method for integration of multivariate smooth

functions I: Sobolev spaces, in preparation.

[UU15] M. Ullrich and T. Ullrich:
with

mula
http://arxiv.org/abs/1503.08846, 2015.

functions

for

for-
Preprint,

The

role of Frolov’s

cubature

bounded mixed

derivative.

[Y10] H. Yserentant: Regularity and Approximability of Electronic Wave Func-

tions. Lecture Notes in Mathematics. Springer, Berlin Heidelberg, 2010.

32

