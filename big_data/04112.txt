Iterative Methods for Efﬁcient Sampling-Based
Optimal Motion Planning of Nonlinear Systems

Jung-Su Ha, Han-Lim Choi, and Jeong hwan Jeon

1

6
1
0
2

 
r
a

 

M
4
1

 
 
]

O
R
.
s
c
[
 
 

1
v
2
1
1
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—This paper extends the RRT* algorithm, a recently-
developed but widely-used sampling-based optimal motion plan-
ner, in order to effectively handle nonlinear kinodynamic con-
straints. Nonlinearity in kinodynamic differential constraints
often leads to difﬁculties in choosing appropriate distance metric
and in computing optimized trajectory segments in tree con-
struction. To tackle these two difﬁculties, this work adopts the
afﬁne quadratic regulator-based pseudo metric as the distance
measure and utilizes iterative two-point boundary value problem
solvers for computing the optimized segments. The proposed
extension then preserves the inherent asymptotic optimality of
the RRT* framework, while efﬁciently handling a variety of
kinodynamic constraints. Three numerical case studies validate
the applicability of the proposed method.

Index Terms—Sampling-based motion planning, nonlinear op-

timal control, iterative methods.

I. INTRODUCTION

Robotic motion planning designs a trajectory of robot states
from a given initial state to a speciﬁed goal state through
a complex conﬁguration space. While motion planning algo-
rithms can be categorized into two groups: combinatorial and
sampling-based approach [1], the latter (such as Probabilis-
tic Road Map (PRM) and Rapidly-exploring Random Tree
(RRT)) has been successful in practice as their computational
advantage over combinatorial methods allows for handling of
complex planning environments. In particular, the Rapidly-
exploring Random Tree Star (RRT*) algorithm proposed in [2]
is one of the most inﬂuential algorithms of this type, as it guar-
antees probabilistic completeness and asymptotic optimality at
the same time. In other words, RRT* guarantees that if the
planning problem is feasible, the probability of the algorithm
failing to ﬁnd a solution reduces to zero as the number of itera-
tions increase, and that the solution asymptotically approaches
to the optimal solution; it is an “anytime” algorithm which
ﬁnds a feasible trajectory quickly and reﬁnes the solution for
allowed computation time. In addition, RRT* inherits the key
advantage of RRT: it explores the unexplored search space
rapidly [3]. Due to these advantages, the algorithm has been
successfully extended to many applications such as differential
game and stochastic optimal control problems [4]–[6].

The motion planning problem is called an optimal kinody-
namic motion planning when the objective of planning is to
minimize a given cost function deﬁned by the state and control
trajectory under system dynamics constraints. Applications

J.-S. Ha and H.-L. Choi are with the Department of Aerospace Engineering,

KAIST, Daejeon, Korea. {wjdtn1404, hanlimc}@kaist.ac.kr

J.

Jeon is with nuTonomy Inc., Cambridge, MA 02142, USA.

jhjeon@alum.mit.edu

of such problem include the automatic car-parking [7] and the
trajectory planning of underwater vehicles [8] or gantry cranes
[9] in cluttered environment. The problem is challenging be-
cause the resulting trajectory should not only satisﬁes system
dynamics but also lies over highly non-convex state space
because of the obstacle ﬁeld. Due to the aforementioned
properties, RRT* can provide a good framework for an optimal
kinodynamic motion planner, supposed that the following two
issues are appropriately addressed. First, the distance metric
should be able to take into account kinodynamic constraints of
the problem. RRT-based algorithms take advantage of Voronoi
bias for rapid exploration of the state space; with a wrong
distance metric, the conﬁguration space may not be effectively
explored. Second, there should be a way to construct a optimal
trajectory segment under kinodynamic constraints for a given
cost form, because the RRT* algorithm improves the quality
of solution by reﬁning the segments of the trajectory so that
the solution asymptotically converges to the optimal solution.
There have been many attempts to handle the kinodynamic
planning problem in the framework of RRT* by tackling
the aforementioned two issues in some ways. The minimum-
time/length planning for holonomic and non-holonomic vehi-
cles [10]–[12] have ﬁrst been addressed in the RRT* frame-
work; a method tailored to high-speed off-road vehicles taking
tight turns [13] was also proposed. Several recent researches
have been devoted to deal with kinodynamic constraints in
the form of linear differential constraint [14]–[16]; these work
in particular proposed to adopt the optimal control theory for
linear systems for cost functions of some linear- [15,16] or
afﬁne-quadratic regulator [14] (LQR or AQR) type. Despite
these recent progresses,
the question of a systematic and
efﬁcient method to handle generic nonlinear dynamics, which
inevitably involves computation of two-point boundary value
problems (TPBVPs) solutions in the RRT* process remains
unsettled.

This work focuses on presenting methodology that can
effectively handle nonlinear dynamics in the framework RRT*.
The methodology ﬁnds out an optimal trajectory for an afﬁne-
quadratic cost functional under nonlinear differential con-
straints while allowing for rapid exploration of the state space.
The AQR-based pseudo metric is proposed as an approxi-
mation to the optimum distance under nonlinear differential
constraints, and two iterative methods are presented to solve
associated TPBVPs efﬁciently. The proposed extension of
RRT* preserves asymptotic optimality of the original RRT*,
while taking into account a variety of kinodynamic constraints.
Three numerical case studies are presented to demonstrate the
applicability of the proposed methodology.

While one of the two iterative methods in this paper was
ﬁrst introduced in the authors’ earlier work [17], this article
includes more extended description of the methodology, in
particular proposing one more iterative algorithm, as well as
more diverse/extensive numerical case studies.

II. PROBLEM DEFINITION

A kinodynamic motion planning problem is deﬁned for a

dynamical system

˙x(t) = f (x(t), u(t)),

(1)

where x denotes the state of the system deﬁned over the state
space χ ⊂ Rn and u denotes the control input deﬁned over the
control input space U ⊂ Rm. Let χobs ⊂ χ and χgoal ⊂ χ be
the obstacle region and the goal region where the system tries
to avoid and to reach, respectively. Then, the feasible state and
input spaces are given by χf ree ⊂ χ \ χobs and Uf ree ⊂ U,
respectively.
The trajectory is represented as π = (x(·), u(·), τ ), where
τ is the arrival time at the goal region, u : [0, τ ] → U, x :
[0, τ ] → χ are the control input and the corresponding state
along the trajectory. The trajectory, πf ree, for given initial
state xinit is called feasible if it does not cross the obstacle
region and eventually achieves the goal region while satisfying
the system dynamics (1), i.e., πf ree = (x(·), u(·), τ ), where
u : [0, τ ] → Uf ree, x : [0, τ ] → χf ree, x(0) = xinit and
x(τ ) ∈ χgoal.

In order to evaluate a given trajectory π, the below form of

the cost functional is considered in this paper:

(cid:90) τ

(cid:20)

0

1
2

(cid:21)

c(π) =

1 +

u(t)T Ru(t)

dt.

(2)

2

xrand ← SAMPLING(χf ree);
xnearest ← NEAREST(V, xrand);
xnew ← STEER(xnearest, xrand);
πnew ← TPBVPSOLVER(xnearest, xnew);
if OBSTACLEFREE(πnew) then
Xnear b ← NEARBACKWARD(V, xnew);
Xnear f ← NEARFORWARD(V, xnew);
cmin ← COST(xnearest) + c(πnew);
for xnear ∈ Xnear b do

new ← TPBVPSOLVER(xnear, xnew);
π(cid:48)
c(cid:48) ← COST(xnear) + c(π(cid:48)
if OBSTACLEFREE(π(cid:48)
cmin ← c(cid:48); πnew ← π(cid:48)

new) ∧ c(cid:48) < cmin then

new);

new;

end for
V ← V ∪ xnew; E ← E ∪ πnew;
for xnear ∈ Xnear f do

near ← TPBVPSOLVER(xnew, xnear);
π(cid:48)
c(cid:48) ← COST(xnew) + c(π(cid:48)
if OBSTACLEFREE(π(cid:48)

near)∧c(cid:48) < COST(xnear)

near);

E ← (E \ πnear) ∪ π(cid:48)

near;

(cid:46) replace

Algorithm 1 RRT* algorithm
1: (V, E) ← ({xinit},∅);
2: for i = 1, ..., N do
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:

end if

then

23:

existing edge

end if

end for

24:
25:
26:
27: end for
28: return T ← (V, E);

end if

The above cost functional denotes trade-off between arrival
time of a trajectory and the expanded control effort. R is
user-deﬁne value; the cost function penalizes more for the
trajectory spending large control effort than late arrival time
as R is larger. This type of cost functional is widely used for
the kinodynamic planning problems [14,18].

Then ﬁnally, the problem is deﬁned as follows.

Problem 1 (Optimal kinodynamic motion planning): Given
χf ree, xinit and χgoal, ﬁnd a minimum cost trajectory π∗ =
(x∗(·), u∗(·), τ∗) such that π∗ = argminπ∈Πf ree
c(π), where
Πf ree denotes a set of feasible paths.

III. BACKGROUND

A. The RRT* Algorithm

This section summarizes the RRT* algorithm [2] upon
which this paper builds an extension to deal with kinodynamic
constraints. The RRT* is a sampling-based algorithm that
incrementally builds and produces an optimal trajectory from
a speciﬁed initial state xinit to a speciﬁed goal region Xgoal.
The overall structure of the algorithm is summarized in Algo-
rithm 1. It should be pointed out that Algorithm 1 uses more
generic notations/terminologies than the original algorithm to
better describe the proposed kinodynamic extension within the
presented algorithm structure.

At each iteration, the algorithm randomly samples a state
xrand from χf ree; ﬁnds the nearest node xnearest in the tree
to this sampled state (line 3-4). Then, the algorithm steers
the system toward xrand to determine xnew that is closest to
xrand and stays within some speciﬁed distance from xnearest;
then, add xnew to the set of vertices V if the trajectory from
xnearest to xnew is obstacle-free (lines 5 – 7 and 18). Next,
the best parent node for xnew is chosen from near nodes in the
tree so that the trajectory from the parent to xnew is obstacle-
free and of minimum cost (lines 8, 10 – 17). After adding
the trajectory segment from the parent to xnew (line 18), the
algorithm rewires the near nodes in the tree so that the forward
paths from xnew are of minimum cost (lines 9, 19 – 25); Then,
the algorithm proceeds to the next iteration.

To provide more detailed descriptions of the key functions

of the algorithm:

• SAMPLING(χf ree): randomly samples a state from χf ree.
• NEAREST(V, x): ﬁnds the nearest node from x among
nodes in the tree V under a given distance metric
dist(x1, x2) representing distance from x1 to x2.
• STEER(x, y): returns a new state z ∈ χ such that z is

closest to y among candidates:

STEER(x, y) := argmin

z∈B+

x,η

dist(z, y),

x,η ≡ {z ∈ χ|dist(x, z) ≤ η} with η representing
where B+
the maximum length of an one-step trajectory forward.
• TPBVPSOLVER(x0, x1): returns the optimal trajectory

from x0 to x1, without considering the obstacles.

• OBSTACLEFREE(π): returns indication of whether or not
the trajectory π overlaps with the obstacle region χobs.
• NEARBACKWARD(V, x) and NEARFORWARD(V, x): re-
turn the set of nodes in V that are within the distance of
r|V | from/to x, respectively. In other words,

NEARBACKWARD(V, x) := {v ∈ V |v ∈ B−
NEARFORWARD(V, x) := {v ∈ V |v ∈ B+

x,r|V |},
x,r|V |},
x,r|V | ≡ {z ∈ χ|dist(z, x) ≤ r|V |}, B+

x,r|V | ≡
where B−
{z ∈ χ|dist(x, z) ≤ r|V |}, and |V | denotes the number
of nodes in the tree.
Also, r|V | needs to be chosen such that a ball of volume
γ log |V |
x,r|V | with large
x,r|V | and B+
|V |
enough γ. For example, with the Euclidean distance
metric this can be deﬁned as r|V | = min{( γ
n )1/d, η}
with the constant γ [2]; ζd is the volume of the unit ball
in Rd.

is contained by B−

log n

ζd

• COST(x): returns the cost-to-come for node x from the

initial state.

• PARENT(x): returns a pointer to the parent node of x.
• c(π): returns the cost of trajectory π deﬁned by (2).
Note speciﬁcally that when the cost of a trajectory is
given by the path length and no kinodynamic constraint
is involved (as was in the ﬁrst version presented in [2]),
the Euclidean distance can be used as the distance metric
dist(x1, x2). Thus, NEARBACKWARD(V, x) becomes identi-
cal to NearForward(V, x) because dist(x, z) = dist(z, x), and
TPBVPSOLVER(x0, x1) simply returns a straight line from x0
to x1.

The probabilistic completeness and asymptotic optimality
of RRT* algorithm are proven in [2]: if the planning problem
has at least one feasible solution, the probability that the
algorithm cannot ﬁnds the solution goes to zero as the number
of iterations increases, and at the same time, the solution is
being reﬁned to the optimal one asymptotically.

It should be noted that the RRT* structure in Algorithm 1
can be adopted/extended for kinodynamic optimal planning,
supposed that the distance metric takes into account the kin-
odynamic constraints and that the TPBVPSOLVER computes
the optimal trajectory between two states under differential
kinodynamic constraints.

B. Optimal Control with Afﬁne Dynamics

This section presents a procedure to compute the optimal
solution for an afﬁne system with afﬁne-quadratic cost func-
tional, which will be taken advantage of for quantiﬁcation of
the distance metric for generic nonlinear systems later in the
paper. Consider an afﬁne system

with boundary conditions,

x(0) = x0,

x(τ ) = x1

and free ﬁnal time τ.

The Hamiltonian is given by,

3

(5)

H = 1 +

1
2

u(t)T Ru(t) + λ(t)T (Ax(t) + Bu(t) + c).

The minimum principle yields that the optimal control takes
the form of:

u(t) = −R−1BT λ(t),

with a reduced Hamilitonian system [19]:

˙x(t) = Ax(t) − BR−1BT λ(t) + c,
− ˙λ(t) = AT λ(t),

(BVP1)

where x(0) = x0, x(τ ) = x1. The solution of (BVP1) with
the boundary conditions (5) is the optimal trajectory from x0
to x1, supposed that the ﬁnal time τ is given.

Note that for given τ, the terminal values of x(t) and λ(t)

in (BVP1) can be expressed:

x(τ ) = x1, λ(τ ) = −G(τ )−1(x1 − xh(τ )),

(6)

where a homogeneous solution of (3), xh(τ ), and the weighted
continuous reachability Gramian, G(τ ), are the ﬁnal values of
the following initial value problem:

˙xh(t) = Axh(t) + c,
˙G(t) = AG(t) + G(t)AT + BR−1BT ,
xh(0) = x0, G(0) = 0.

(IVP1)

With (6), the optimal trajectory can be obtained by integrating
(BVP1) backward.

For given ﬁnal time τ, the performance index of the optimal

trajectory can be written as

C(τ ) = τ +

1
2

(x1 − xh(τ ))T G(τ )−1(x1 − xh(τ )).

(7)

and the optimal ﬁnal time can be expressed as:

τ∗ = argmin
τ≥0

C(τ ).

(8)

Equation (7) implies that C(τ ) ≥ τ since G(τ ) is positive
(semi-)deﬁnite. Therefore, τ∗ can be computed by calculating
C(τ ) with increasing τ until τ equals to the incumbent best

cost (cid:101)C(τ ) (cid:44) mint∈[0,τ ] C(t). With this optimal ﬁnal time τ∗,

the optimal cost can be obtained as:
C∗ = C(τ∗).

(9)

˙x(t) = Ax(t) + Bu(t) + c,

and the performance index

J(0) =

1 +

u(t)T Ru(t)

(cid:90) τ

(cid:20)

0

1
2

(cid:21)

(3)

(4)

Within the RRT* framework,

if the kinodynamic con-
straints take an afﬁne form, the procedure in this section
can be used to deﬁne/quantify the distance metric and to
compute the optimized trajectory between two nodes in
TBPVPSOLVER(x0, x1).

dt,

IV. EFFICIENT DISTANCE METRIC AND STEERING

METHOD

To take advantage of the explorative property of RRT*, it
is crucial to use an appropriate distance metric in the process.
The Euclidean distance, which cannot consider the system
dynamics,
is certainly not a valid option in kinodynamic
motion planning problem – for example, it would fail to ﬁnd
the nearest node and thus would not be able to steer toward
the sample node. Thus, a distance metric which appropriately
represents the degree of closeness taking into account the
dynamic constraints and the underlying cost measure needs
to be deﬁned/quantiﬁed for kinodynamic version of RRT*.

A. Afﬁne Quadratic Regulator-Based Pseudo Metric

An AQR-based pseudo metric is ﬁrstly proposed in [18] as
a distance metric to kinodynamic planning to consider a ﬁrst-
order linear dynamics. In this work, an AQR-based pseudo
metric is adopted as an approximate distance measure for prob-
lems with nonlinear differential constraints. For kinodynamic
planning with cost functional (2) and dynamic constraint (1),
the distance from x0 to x1 is computed as

dist(x0, x1) = C∗ ≡ min
τ≥0

where C(τ ) is calculated from (7) with

(cid:12)(cid:12)(cid:12)(cid:12)x=ˆx,u=ˆu

A =

∂f
∂x

, B =

∂f
∂u

(10)

C(τ ).

(cid:12)(cid:12)(cid:12)(cid:12)x=ˆx,u=ˆu

,

where ˆx and ˆu indicate the linearization points that are set to
be the initial (or the ﬁnal) state, i.e., ˆx = x0 (or x1), and ˆu = 0,
in the framework of RRT*. In other words, the distance from
x0 to x1 is approximated as the cost of the optimal control
problem for a linearized system with the same cost functional
and boundary conditions.

In this work, an AQR-based pseudo metric is adapted as
a distance metric in the RRT* framework. An exactness of
a metric is related to the property of rapid exploration of the
RRT* algorithm: for a randomly chosen sample, the algorithm
ﬁnds the nearest node by NEAREST procedure and expands the
tree toward the sample in STEER procedure. Calculation of
the exact metric between two states are equivalent to solving
nonlinear optimal control problem which is computationally
expensive; the algorithm needs to solve such optimal control
problems for every pair of states, from the sample state to
the nodes in the tree and vice versa. Although the AQR-
based pseudo metric does not take into account the nonlinear
dynamics, as will be mentioned in next subsection, it can
measure the metric for all pairs of states by integrating only
n (for xh(t)) + n(n + 1)/2 (for G(t) which is symmetric)
ﬁrst order ODEs and produces the much more exact degree of
closeness than Euclidean distance.

B. Implementation of AQR Metric in RRT* Framework

Based on the AQR metric in (10), NEAREST(V, x), NEAR-
BACKWARD(V, x), NEARFORWARD(V, x) and STEER(x, y)
functions can be readily implemented in the RRT* structure.

4

• xnearest ← NEAREST(V, xrand): First, the system dy-
namics is linearized at xrand. Since xrand is ﬁnal state,
xh(t) and G(t) are integrated from t = 0, xh(0) =
xrand, G(0) = 0 in the backward direction, i.e., t < 0.
the cost from ith node vi ∈ V at
With integration,
2 (vi −
the time −t is calculated as Ci(−t) = −t − 1
xh(t))T G(t)−1(vi − xh(t)) while the minimum cost is
saved as a distance, di = mint<0 Ci(−t). The integration
stops when mini di ≥ −t; since G(t) is a negative (semi-
)deﬁnite matrix, cost less than −t cannot be found by
more integration. Finally, the nearest node, xnearest ←
vk, where k = argmini di, is returned.
• Xnear b ← NEARBACKWARD(V, xnew): The procedure
is similar to NEAREST. First, the system dynamics is
linearized at xnew. xh(t) and G(t) are integrated from
t = 0, xh(0) = xnew, G(0) = 0 for backward di-
rection, i.e., t < 0. With integration, the cost for the
time −t and for each vi ∈ V , the corresponding cost
is saved as a
is calculated while the minimum cost
distance, di = mint<0 Ci(−t). The integration stops
when −t ≥ r|V | and the set of backward near nodes,
Xnear b ← {vi ∈ V |di ≤ r|V |}, are returned.
• Xnear f ← NEARFORWARD(V, xnew): The procedure
is exactly same as NEARBACKWARD except for the
direction of integration, t > 0.
• xnew ← STEER(xnearest, xrand): First, the system dy-
namics is linearized at xnearest. Then, the optimal tra-
jectory is calculated by procedure in section III-B for
the linearized system. If the resulting cost is less than η,
xrand is returned as a new node. Otherwise, it returns x(cid:48)
such that x(cid:48) is in the trajectory and the cost to x(cid:48) from
xnearest is η.

V. EFFICIENT SOLVER FOR THE TWO-POINT

BOUNDARY-VALUE PROBLEM

As mentioned previously, the TPBVPSOLVER(x0, x1) func-
tion returns the optimal trajectory from x0 to x1. A straight-
line trajectory, which is optimal for the problem without
dynamic constraints, cannot be a valid solution in general,
because it would be not only suboptimal but also likely to
violate the kinodynamic constraints. Therefore, this section
derives the two-point boundary value problem (TPBVP) in-
volving nonlinear differential constraints and presents methods
to compute the solution of this TPBVP.

Consider the optimal control problem (OCP) with nonlinear
system dynamics in (1) to minimize the cost functional in (4)
where boundary conditions are given as x(0) = x0, x(τ ) = x1
with free ﬁnal time τ. The Hamiltonian of this OCP is deﬁned
as,

H(x(t), u(t), λ(t)) = 1 +

1
2

u(t)T Ru(t) + λ(t)T f (x(t), u(t)).

From the minimum principle:

H T

u = Ru(t) + f T

u λ(t) = 0,

which allows the optimal control to be expressed in terms of
x(t) and λ(t):

u(t) = h(x(t), λ(t)).

(11)

Thus, a system of differential equations for the state x(t) and
the costate λ(t) is obtained:

˙x(t) = f (x(t), h(x(t), λ(t))),
− ˙λ(t) = H T

x = f T

x λ(t)

(BVP2)

with boundary conditions x(0) = x0, x(τ ) = x1. The
system of differential equations in (BVP2) is nonlinear in
general and has boundary conditions at the initial and ﬁnal
time; thus, it is called a nonlinear two-point boundary value
problem (TPBVP). An analytic solution to a nonlinear TPBVP
is generally unavailable because not only it is nonlinear but
also its the boundary conditions are split at two time instances;
numerical solution schemes have often been adopted for this.
In the present work, two types of numerical iterative ap-
proaches are presented: the successive approximation (SA)
and the variation of extremals (VE) based methods. These
two approaches ﬁnd the solution of a nonlinear TPBVP by
successively solving a sequence of more tractable problems:
in the SA based method, a sequence of linear TPBVPs are
solved and in the VE approach, a sequence of nonlinear initial
value problems (IVPs) are iteratively solved, respectively. The
main concept of the methods has already been presented to
solve a free ﬁnal-state & ﬁxed ﬁnal-time problem [20,21] but
this work proposes their variants that can handle a ﬁxed ﬁnal-
state & free ﬁnal-time problem in order to implemented to the
RRT* framework.

In an iterative method, an initial guess of the solution is
necessary and often substantially affects the convergence of
the solution. In the proposed RRT* extension, the optimal
trajectory with the linearized dynamics can be a good choice of
initial condition, particularly because such trajectory is already
available in the RRT* process by calculating the AQR-based
distance metric in NEARBACKWARD or NEARFORWARD.

A. Successive Approximation

Let ˆx be a linearization point, which is set to be the initial or
the ﬁnal value of a trajectory segment in the RRT* implemen-
tation; ˆu = 0 be also the corresponding linearization point. By
splitting the dynamic equation in (1) into the linearized and
remaining parts around ˆx and ˆu,

(cid:12)(cid:12)(cid:12)x=ˆx,u=ˆu

˙x(t) = Ax(t) + Bu(t) + g(x(t), u(t)),

where A (cid:44) ∂f
and
g(x(t), u(t)) (cid:44) f (x(t), u(t)) − Ax(t) − Bu(t), the optimal
control and the reduced Hamiltonian system are expressed as,

, B (cid:44) ∂f

∂u

∂x

u(t) = −R−1BT λ(t) − R−1gT

u λ(t),

(12)

(cid:12)(cid:12)(cid:12)x=ˆx,u=ˆu

and

˙x(t) = Ax(t) − BR−1BT λ(t) − BR−1gT

u λ(t)

− ˙λ(t) = AT λ(t) + gT

+ g(x(t), u(λ(t))),
x λ(t),

respectively. The boundary conditions are given by

x(0) = x0, x(τ ) = x1

5

and the ﬁnal
nonlinear, as gT
w.r.t x or λ.

time τ is free. The TPBVP in (13) is still
x λ in (13) are not necessarily linear
u λ, g and gT

Consider the following sequence of TPBVPs:

˙x(k)(t) = Ax(k)(t) − BR−1BT λ(k)(t)

− BR−1g(k−1)T

λ(k−1)(t) + g(k−1),

u

− ˙λ(k)(t) = AT λ(k)(t) + g(k−1)T

λ(k−1)(t),

x

(14)
(15)

with boundary conditions x(k)(0) = x0, x(k)(τ ) = x1,
where g(k) ≡ g(x(k), u(k)), g(k)
u ≡
gu(x(k), u(k)). Note that this system of differential equations
are linear w.r.t. x(k)(t) and λ(k)(t) for given x(k−1)(t) and
λ(k−1)(t). It can be converted into an initial value problem as
follows. From (15), λ(k)(t) can be expressed as:

x ≡ gx(x(k), u(k)) and g(k)

λ(k)(t) = eAT (τ−t)λ(k)(τ ) + λ(k)

p (t),

(16)

where λ(k)

p (t) is a solution of
p (t) = −AT λ(k)
˙λ(k)
with terminal condition λ(k)
yields

p (t) − g(k−1)T

x

λ(k−1)(t),

(17)

p (τ ) = 0. Plugging (16) into (14)

˙x(k)(t) = Ax(k)(t) + g(k−1) − BR−1BT eAT (T−t)λ(τ )
λ(k−1)(t).

p (t) − BR−1g(k−1)T

− BR−1BT λ(k)

u

Then, the ﬁnal state x(k)(τ ) is expressed as,

x(k)(τ ) = x(k)

h (τ ) − G(τ )λ(k)(τ ),

where xh(τ ) and G(τ ) are the solution of
h (t) − BR−1BT λ(k)

(k)(t) = Ax(k)

˙xh

p (t)

− BR−1g(k−1)T

λ(k−1)(t) + g(k−1)

u

˙G(t) = AG(t) + G(t)AT + BR−1BT ,
x(k)
h (0) = x0, G(0) = 0.

(18)

(19)

(20)
(21)

Using (19) and x(k)(τ ) = x1, the ﬁnal costate value can be
obtained:

λ(k)(τ ) = −G(τ )−1(x1 − x(k)

(22)
Finally, x(k)(t) and λ(k)(t) for t ∈ [0, τ ] are calculated by
backward integration of the following differential equation,

h (τ )).

(cid:21)(cid:20)x(k)(t)

(cid:21)

(cid:20)A −BR−1BT
(cid:34)−BR−1g(k−1)T

−AT

0

u

+

−g(k−1)T

x

λ(k)(t)
λ(k−1)(t) + g(k−1)
λ(k−1)(t)

(23)

(cid:35)

,

(cid:20) ˙x(k)(t)

(cid:21)

˙λ(k)(t)

=

(13)

with given boundary values x(k)(τ ) and λ(k)(τ ). Also, the
optimal control u(k)(t) can also be computed accordingly:

u(k)(t) = −R−1BT λ(k)(t) − R−1g(k−1)T

u

λ(k−1)(t).

(24)

The optimal ﬁnal time can be found numerically by a gra-
dient descent scheme. The derivative of J(0) for the trajectory
at k’th iteration w.r.t ﬁnal time is given as,

The dynamics of the inﬂuence function matrices can be
λ , ˙λ(t) =
x . Taking the partial derivatives of these equations w.r.t

derived from the state and costate equation ˙x(t) = H T
−H T
the initial value of the costate yields

6

(cid:20) dJ(0)

(cid:21)(k)

dτ

λ(k)(τ )T BR−1BT λ(k)(τ )

= 1 − 1
2
λ(k−1)(τ )T g(k−1)

+

u

R−1g(k−1)T

u

1
2

+ λ(k)(τ )T (Ax1 + g(k)).

λ(k−1)(τ )
(25)

Then, a gradient descent-based update rule of the ﬁnal time is
given as,

τ (k+1) = τ (k) − η

.

(26)

(cid:20) dJ(0)

(cid:21)(k)

dτ

With the process described thus far, the TPBVP solver for
nonlinear system based on successive-approximation can be
summarized as Algorithm 2.
Algorithm 2 π ←SA-based TPBVPsolver(x0, x1)
1: Initialize x(0), λ(0), τ (0) and set k = 0 (cid:46) Section III-B
2: repeat
3:
4:
5:
6: until Converge
7: Calculate u(t)
8: return π ← (x(k)(·), u(·), τ (k))

k = k + 1;
Update τ (k)
Get x(k)(t) and λ(k)(t)

(cid:46) Equation (25)-(26)
(cid:46) Equation (16)-(23)

(cid:46) Equation (24)

B. Variation of Extremals

The VE approach is a technique to successively ﬁnd the
initial value of the costate λ(0) using the Newton-Rapson
method [21]. The method has been well established, but its
implementation into a sampling-based planning is not trivial.
Suppose that the initial value of the costate λ(0) and the
ﬁnal value of the state x(τ ) are related via nonlinear function:

x(τ ) = F (λ(0)).

Then, the initial costate λ(0) that leads to x(τ ) = x1 can be
approximated successively as follows:

λ(k+1)(0) = λ(k)(0) − [Px(λ(k)(0), τ )]−1(x(k)(τ ) − x1),

where Px(p(k)(0), t) is called the state inﬂuence function
matrix which is the matrix of partial derivatives of the com-
ponents of x(t), evaluated at p(k)(0),
···
...
. . .

Px(λ(k)(0), t) ≡

∂x1(t)
∂λn(0)

∂λ1(0)

...

...

.

∂xn(t)
∂λn(0)

λ(k)(0)

Similarly, the costate inﬂuence function matrix is deﬁned and
given by,

Pλ(λ(k)(0), t) ≡

···
...
. . .

∂λ1(t)
∂λn(0)

...

∂λn(t)
∂λn(0)

.

λ(k)(0)

(cid:3)
(cid:2)H T
(cid:2)−H T

λ

x

(cid:3) .

(27)

∂

∂λ(0)

∂

∂λ(0)

[ ˙x(t)] =

(cid:104) ˙λ(t)

(cid:105)

=

∂

∂λ(0)

∂

∂λ(0)
∂λ(0) [ ˙x(t)],

∂

∂λ(0) [ ˙λ(t)] are contin-
With the assumption that
uous and by using the chain rule on right had side of (27),
the differential equations of the inﬂuence function matrices are
obtained as

∂

(cid:20) ˙Px(λ(k)(0), t)

(cid:21)

˙Pλ(λ(k)(0), t)

=

(cid:34) ∂2H
∂x2 − ∂2H

− ∂2H

∂2H
∂λ2

∂x∂λ

∂λ∂x

(cid:35)(cid:20)Px(t)

(cid:21)

Pλ(t)

,

(28)

where Px(λ(k)(0), 0) = 0, Pλ(λ(k)(0), 0) = I.

On the other side, since the ﬁnal time of the problem is

free, the Hamilitonian should vanish:

H(x(τ ), λ(τ ), τ ) = 0.

The update rule for the initial costate value and the ﬁnal time
can then be obtained as:

(cid:20)λ(k)(0)
(cid:21)

τ (k)

=

(cid:20)λ(k+1)(0)
(cid:21)
(cid:34)

τ (k+1)

−

Px(λ(k)(0), τ (k))

∂H (k)(τ (k))

∂λ(k)(0)

∂x(k)(τ (k))

∂τ

∂H (k)(τ (k))

∂τ

(cid:35)−1(cid:20)x(k)(τ (k)) − x1

(cid:21)

H (k)(τ (k))

,

(29)
where entries of the matrix on the right hand side can be
obtained from:

∂H(τ (k))

∂λ0

∂H
∂x

dx(τ (k))

dλ(τ (k))

+

=
= − ˙λ(τ (k))T Pλ(τ (k)) + ˙x(τ (k))T Px(τ (k)), (30)

dλ(0)

dλ(0)

∂H
∂λ

∂x(k)(τ (k))

∂τ (k)

= f (x(k)(τ (k)), h(x(k)(τ (k)), λ(k)(τ (k)))),

∂H(τ (k))

∂τ (k)

∂H
∂x

=

= 0.

dx(τ (k))

dτ (k)

+

∂H
∂λ

dλ(τ (k))

dτ (k)

(31)

(32)

Finally, the TPBVP solver with the variation of extremals

based method can be summarized as Algorithm 3.

C. Discussions

Both methods presented in this section ﬁnd the solution to
(BVP2) iteratively. At each iteration, the SA-based method
computes the optimal solution to an linear approximation of
the original problem linearized at the solution of the previous
iteration, while the VE-based method updates the estimate
of the initial costate and the ﬁnal time. It should be pointed
out that these solvers guarantee local (not global) optimality,
because the underlying TPBVP is derived as a necessary

∂xn(t)
∂λ1(0)

 ∂x1(t)
 ∂λ1(t)

∂λ1(0)

...

∂λn(t)
∂λ1(0)




7

(a) SA-based solver, R = 1

(b) Solver for linearized dynamics,
R = 1

(c) SA-based solver, R = 10

(d) Solver for linearized dynamics,
R = 10

Fig. 1.
pendulum swing up example.

State trajectories for different TPBVP solvers with varying R for

(a) SA-based solver, R = 1

(b) Solver for linearized dynamics,
R = 1

Algorithm 3 π ←VE-based TPBVPsolver(x0, x1)
1: Initialize λ(0)(0), τ (0) and set k = 0
2: repeat
3:
4:
5:
6: until Converge
7: Calculate u(t)
8: return π ← (x(k)(·), u(·), τ (k))

k = k + 1;
Integrate x(k), λ(k), Px, Pλ (cid:46) (BVP2), Equation (28)
Calculate λ(k+1)(0), τ (k+1)
(cid:46) Equation (29)-(32)

(cid:46) Equation (11)

(cid:46) Section III-B

(not sufﬁcient) condition for optimality. However, this locality
would not make a signiﬁcant impact on the overall motion
planning, since the TPBVP itself is posed for optimally linking
a small segment of the overall plan.

Compared to an existing approach that treated linearized
dynamics [14] and thus did not require iterative process
for solving a TPBVP, the proposed methods need to solve
additional kiter ﬁrst-order ODEs, where kiter is the number
of iterations for convergence, in computing a single optimal
trajectory segment in the RRT* framework. However, the pro-
posed schemes can take into account nonlinear kinodynamic
constraints, which was not accurately realized in the previous
work.

Note also that the two methods exhibit different character-
istics from the computational point of view. First, the storage
requirement of the VE-based method has an advantage over
that of the SA-based method: at every iteration, the VE solver
only needs to store 2 (n×n) matrices, Px(t) and Pλ(t), while
the SA solver needs to store the trajectories, λ(k)
p (t), x(k)(t)
and λ(k)(t) for t ∈ [0, τ ] and a (n × n) matrix, G(t). On the
other side, the SA solver demands integration of 4n ﬁrst-order
ODEs in (17), (20) and (23) at each iteration (n2 ﬁrst-order
ODEs in (21) needs to be integrated only at ﬁrst iteration
and then reused.), while the VE solver needs to integrate
2n(n + 1) ﬁrst-order ODEs in (28) and (BVP2) in each
iteration. Thus, assuming both methods converge with similar
number of iterations, the VE-based method exhibits better
memory complexity, while the SA-based one gives better
time complexity, in general. However, detailed convergence
characteristics such as convergence time might be problem
dependent.

VI. NUMERICAL EXAMPLES

This section demonstrates the validity of the proposed
optimal kinodynamic planning methods on three numerical
examples: The ﬁrst pendulum swing-up example compares
the proposed scheme with a state-of-the-art method based on
linearized dynamics. The second example on a two-wheeled
mobile robot
in a cluttered environment demonstrates the
asymptotic optimality of the algorithms. The third example
on a SCARA type robot arm investigates the characteristics
of the optimized plans with varying cost functionals.

A. Pendulum Swing-Up

The control objective of the pendulum swing-up problem is
to put the pendulum in an upright position from its downward

(c) SA-based solver, R = 10

(d) Solver for linearized dynamics,
R = 10

Fig. 2.
Planned control input vs. Executed(feedforward+feedback) control
input containing feedback for different TPBVP solvers with varying R for
pendulum swing up example.

stable equilibrium. The dynamics of the system is given as

I ¨θ + b ˙θ + mglc sin θ = u.

(33)
The angular position and velocity, x(t) = [θ(t) ˙θ(t)]T are
the state variables and the torque, u(t) is the control input
to the system. The cost of the trajectory is given by (2). The
initial and goal states are given as xinit = [0 0]T , xgoal =
{[π 0]T , [−π 0]T}. To comparatively investigate the capability
of RRT* variants in handling nonlinearity in dynamics, the

−3−2−10123−10−50510  RRT* TrajectoryOpen−loop TrajectoryClosed−loop Trajectory−3−2−10123−10−50510  RRT* TrajectoryOpen−loop TrajectoryClosed−loop Trajectory−3−2−10123−10−50510  RRT* TrajectoryOpen−loop TrajectoryClosed−loop Trajectory−3−2−10123−10−50510  RRT* TrajectoryOpen−loop TrajectoryClosed−loop Trajectory00.511.522.53−3−2−10123tu  RRT* InputClosed−loop Input00.511.522.5−3−2−1012345tu  RRT* InputClosed−loop Input01234567−4−3−2−10123tu  RRT* InputClosed−loop Input012345−3−2−101234tu  RRT* InputClosed−loop InputAVERAGE COSTS FROM TEN SIMULATIONS

TABLE I

COST OF THE BEST TRAJECTORIES IN THE TREE OUT OF 100 TRIALS.

TABLE II

8

SA-based solver

planned cost

executed cost

Solver for linearized dynamics
executed cost
planned cost

R=1
R=5
R=10
R=15

6.4621
18.9790
33.0323
52.8430

6.4727
18.9929
33.7034
52.9865

4.5122
9.7229
12.9783
15.1409

8.4837
31.2797
55.9197
83.6147

# of nodes
# of feasible

Mean

Variance

300
81
inf
NaN

500
100

21.8125
2.2570

1000
100

20.5124
0.7864

3000
100

19.5235
0.2261

5000
100

19.1839
0.1687

B. Two-Wheeled Mobile Robot

proposed iterative methods are compared with kinodynamic-
RRT* [14] that
the ﬁrst-order Taylor
approximation of the dynamics.

takes into account

Fig. 1 illustrates state trajectories in the phase plane; an
open-loop and a closed-loop trajectories are depicted as well
as the planned trajectory. The open-loop trajectory is gen-
erated by using the planned control input trajectory u(t) as
a feedfoward control term, while the closed-loop trajectory
is produced by adding an LQR trajectory stabilizer
[22]
that utilizes feedback control in the form of u(t) − K ¯x with
LQR gain K where ¯x being the deviation from the planned
trajectory. It was found that both of the proposed iterative
solvers produce very similar results; thus only the result of
the SA-based solver is presented herein.

The blue-solid line represents the planned trajectories from
the algorithm using the SA-based solver (left) and the solver
for linearized dynamics (right); the red-dashed-dot and black-
dashed lines denote the open-loop and closed-loop state trajec-
tories, respectively. Note that as the linearization is only valid
around the nodes of the RRT* tree, the optimized trajectory
segment with using the linearization-based scheme [14] is
dynamically infeasible for the original (nonlinear) system as
the state moves far away from the nodes. As shown in Fig.1
(b) and (d), the system may not follow the planned trajectory
with open-loop control and even with a feedback trajectory
stabilizer; while, as shown in Fig.1 (a) and (c), the planned
trajectories from the algorithm using the iterative TPBVP
solver is followed not only by the feedback control but also
by the open-loop control.

The control input histories are shown in Fig. 2. The blue-
solid line represents the input from the planning algorithm
and the black-dashed line denotes the input with feedback
control
implementation. In case the planned trajectory is
inconsistent with the real dynamics, a large amount of control
effort is required in the feedback controller, which results in
cost increase. This can be observed in the case where the
linearization-based planner is used; note that the control effort
for the proposed method is signiﬁcantly smaller than that
of the linearization-based method. Also, Table I represents
average costs of ten simulations for varying cost functions with
feedback controller; the ‘planned cost’ means the cost returned
from the algorithm, and the ‘executed cost’ represents the cost
which include control effort from the trajectory stabilization
feedback controller. It is shown that the cost achieved by using
proposed method is smaller and more consistent with planned
cost.

The second example addresses design of the trajectory of a
two-wheeled mobile robot. The states and inputs of the system
are x = [px py θ v w]T and u = [F1 F2]T , where px, py and
θ represent robot position and orientation, respectively, v, w
denote the linear and angular velocity of the robot, and F1, F2
are the force from each wheel. The dynamic equation of the

 .

 =
system is given as



˙px
˙py
˙θ
˙v
˙w

v cos θ
v sin θ

w

F1 + F2
F1 − F2

 =



v cos θ
v sin θ

w

u1 + u2
u1 − u2

The initial and the goal states are given as x(0) =
[0.5 0.5 π/4 1 0]T and x(τ ) = {[px py θ v w]T|23 ≤ px ≤
24, 9 ≤ py ≤ 10, 0 ≤ θ ≤ π/2, 0.8 ≤ v ≤ 1.2, −0.2 ≤ w ≤
0.2}, respectively, with free ﬁnal time τ. The cost functional
is given in (2) with R = 20diag(1, 1).

As the two proposed iterative methods have also shown sim-
ilar performances, only the result for the VE-based solver case
is depicted in this example. Fig. 3 represents the progression
of the RRT* tree, by projecting the tree in ﬁve-dimensional
space onto the two-dimensional position space, (px, py) ∈ R2.
The red star and the square represent the initial position and
the goal region; the thick dark-blue line represents the best
trajectory found up to the corresponding progression. Observe
that the resulting trajectories connect the initial and the goal
state smoothly. Also, as the number of nodes in the tree
increases, the tree ﬁlls up the feasible state space and ﬁnds
out a lower-cost trajectory.

Table II reports the result of a Monte-Carlo simulation with
100 trials; it shows the number of trials ﬁnding a feasible
trajectories, the mean and variance of the minimum costs in
each iteration. It is found that the mean and variance of the
cost decreases as the number of nodes increases, implying
convergence to the same solution.

Finally, Fig. 4 depicts the resulting trajectories with VE-
based solver and the same linearization-based solver as the ﬁrst
example [14]. It is observed that with the solver for linearized
dynamics, there is a portion of sideway-skid moving at the
middle of trajectory, which is dynamically infeasible for the
robot. On the contrary, the result of the proposed solver shows
feasible moving in the whole trajectory.

C. SCARA type Robot Arm

The third example is about generating a motion plan of
a three-degree-of-freedom SCARA robot with two rotational
joints (represented by θ1 and θ2), and one prismatic joint (θ3)

9

(a) 200 nodes

(a) Proposed solver

(b) 500 nodes

(b) Solver for linearized dynamics

Fig. 4. Resulting trajectories with proposed solver and solver for linearized
dynamics for two-wheeled mobile robot example.

(c) 1000 nodes

Fig. 5. SCARA Robot

and

α = Iz1 + r2

1m1 + l2
β = Iz2 + Iz3 + l2

1m2 + l2
1m3,
2m3 + m2r2
2,
γ = l1l2m3 + l1m2r2.

m1, m2, m3 and l1, l2 represent mass and length of each link,
respectively. Also, r1, r2 denote length between a joint axis
and the center of mass of each link and Iz1, Iz2, Iz3 represent
the moment of inertia about the rotation axis. The system has
˙θ3]T , and a
a six-dimensional state vector, x = [θ1 θ2 θ3
three-dimensional control inputs, u = [τ1 τ2 f3]T representing
the torques of the two rotational joints and the force of the
prismatic joint.

˙θ2

˙θ1

The problem is to ﬁnd the optimal motion trajectory that
leads to the end-effector of the robot reaching the goal region
(shown as red circle in Figs. 6-8) from its initial state, x(0) =
[π/2 0 3 0 0 0]T (the corresponding end-effector position is
shown as red star in Figs 6–7), while avoiding collision with
obstacles. The cost of the trajectory takes the form of (2).
With other parameters being ﬁxed, the solutions are obtained

 ,
 ,


0
0
m3
0
0
0

 0

0

m3g

(d) 5000 nodes

Fig. 3. Two-dimensional representation of evolution of RRT* tree for mobile
robot example: when the number of nodes are (a) 200, (b) 500, (c) 1000 and
(d) 5000 for two-wheeled mobile robot example.

as shown in Fig. 5. The dynamics of the robot is given as,

where

M (θ) =

C(θ, ˙θ) =

M (θ)¨θ + C(θ, ˙θ) ˙θ + N (θ, ˙θ) = u,

α + β + 2γ cos θ2 β + γ cos θ2
−γ sin θ2

˙θ2 −γ sin θ2( ˙θ1 + ˙θ2)
˙θ1

β + γ cos θ2

γ sin θ2

β
0

0

0

0
0

N (θ, ˙θ) =

05101520024681020005101520024681050005101520024681010000510152002468105000051015200246810051015200246810with varying input penalty matrix, R, to see the effect of cost
functional on the resulting trajectories. Two values of R are
considered:

R = 0.05diag(1, 1, 0.5), 0.05diag(0.5, 0.5, 10).

10

The proposed VE-based method is implemented to solve
nonlinear TPBVPs in the process of RRT*. There are two
homotopy classes for the solutions from the initial state to the
ﬁnal states: the end effector 1) goes over the wall or 2) makes
a detour around the wall.

Figs. 6–7 show the resulting motions of the robot when
5000 nodes are added into the tree for the two cases; the
magenta dashed line and the red circle represent the end-
effector trajectory and the goal region, respectively. For the
ﬁrst case (R = 0.05diag(1, 1, 0.5)), which has smaller control
penalty on joint 3, the resulting trajectory goes over the wall
as shown in Fig. 6; going over the wall by using cheap control
input of joint 3 leads to lower cost in this case. On the other
hand, in the second case (R = 0.05diag(0.5, 0.5, 10)) shown
in Fig. 7, the proposed algorithm generates the trajectory that
makes a detour as the control penalty for the joint 3 is larger;
going over the wall is so expensive in this case that the
detouring trajectory is chosen as the best one.

Considering the control penalty for joint 1 and 2, the penalty
is smaller in the second case than the ﬁrst one; thus, the
duration of the trajectory weighs more in the second case. Fig.
8 shows that the top-views of the SCARA robot motion at each
time step in Figs. 6–7 and the corresponding control inputs;
the motion starts at the position colored in light-green and ends
at the position colored in dark-green. It can be seen that the
trajectory reaches the goal state more quickly in the second
case despite it requires the large amount of input-energy of the
joint 1 and 2 (the arrival time of the minimum-cost trajectory
is 2.15 and 1.25 second, respectively).

VII. CONCLUDING REMARKS

In this work, an extension of RRT* to handle nonlinear
kinodynamic differential constraints was proposed. In order to
tackle two caveats: choosing a valid distance metric and solv-
ing two point boundary value problems to compute an optimal
trajectory segment. An afﬁne quadratic regulator (AQR)-based
pseudo metric was adopted, and two iterative methods were
proposed, respectively. The proposed methods have been tested
on three numerical examples, highlighting their capability of
generating dynamically feasible trajectories in various settings.
Despite the proposed methods have been focused on imple-
menting to the RRT* framework, it is expected to help other
state-of-the-art sampling-based motion planning algorithms,
like RRT# [23], GR-FMTs [24] or FMT* [25] to address
nonlinear dynamical systems.

REFERENCES

[1] S. M. LaValle, “Motion planning,” IEEE Robotics & Automation Mag-

azine, vol. 18, no. 1, pp. 79–89, 2011.

[2] S. Karaman and E. Frazzoli, “Sampling-based algorithms for optimal
motion planning,” International Journal of Robotics Research, vol. 30,
no. 7, pp. 846–894, 2011.

[3] S. M. LaValle, “Rapidly-exploring random trees a new tool for path

planning,” 1998.

(a) t = 0 sec.

(b) t = 0.7 sec.

(c) t = 1.45 sec.

(d) t = 2.15 sec

Fig. 6.
The motion of the SCARA robot corresponding to the result-
ing state trajectory when 5000 nodes are added to the tree with R =
0.05diag(1, 1, 0.5).

(a) t = 0 sec.

(b) t = 0.4 sec.

(c) t = 0.85 sec.

(d) t = 1.25 sec

Fig. 7.
The motion of the SCARA robot corresponding to the result-
ing state trajectory when 5000 nodes are added to the tree with R =
0.05diag(0.5, 0.5, 10).

[4] S. Karaman and E. Frazzoli, “Incremental sampling-based algorithms
for a class of pursuit-evasion games,” in Algorithmic Foundations of
Robotics IX, 2011, pp. 71–87.

[5] V. A. Huynh, S. Karaman, and E. Frazzoli, “An incremental sampling-
based algorithm for stochastic optimal control,” in IEEE International
Conference on Robotics and Automation, 2012, pp. 2865–2872.

[6] V. A. Huynh, L. Kogan, and E. Frazzoli, “A Martingale approach
and time-consistent sampling-based algorithms for risk management
in stochastic optimal control,” in IEEE Conference on Decision and
Control, 2014, pp. 1858–1865.

11

approximation approach,” Systems & Control Letters, vol. 54, no. 5,
pp. 429–434, 2005.

[21] D. E. Kirk, Optimal Control Theory: An Introduction.

Courier

Corporation, 2012.

[22] R. Tedrake, “Underactuated robotics: Learning, planning, and control
for efﬁcient and agile machines course notes for MIT 6.832,” Working
draft edition, 2009.

[23] O. Arslan and P. Tsiotras, “Use of relaxation methods in sampling-
based algorithms for optimal motion planning,” in IEEE International
Conference on Robotics and Automation, 2013, pp. 2421–2428.

[24] J. Jeon, S. Karaman, and E. Frazzoli, “Optimal sampling-based feedback
motion trees among obstacles for controllable linear systems with
linear constraints,” in IEEE International Conference on Robotics and
Automation, 2015, pp. 4195–4201.

[25] L. Janson, E. Schmerling, A. Clark, and M. Pavone, “Fast marching tree:
A fast marching sampling-based method for optimal motion planning
in many dimensions,” The International Journal of Robotics Research,
vol. 34, no. 7, pp. 883–921, 2015.

(a) Case 1, topview

(b) Case 1, input

(c) Case 2, topview

(d) Case 2, input

Fig. 8. The top-views of resulting motion and the corresponding inputs.

[7] D. Kim, W.-H. Chung, and S. Park, “Practical motion planning for
car-parking control in narrow environment,” IET Control Theory &
Applications, vol. 4, no. 1, pp. 129–139, 2010.

[8] H. Yuan and Z. Qu, “Optimal real-time collision-free motion planning
for autonomous underwater vehicles in a 3d underwater space,” IET
Control Theory & Applications, vol. 3, no. 6, pp. 712–721, 2009.

[9] W. Blajer and K. Kotodziejczyk, “Motion planning and control of
gantry cranes in cluttered work environment,” IET Control Theory &
Applications, vol. 1, no. 5, pp. 1370–1379, 2007.

[10] S. Karaman and E. Frazzoli, “Optimal kinodynamic motion planning
using incremental sampling-based methods,” in IEEE Conference on
Decision and Control, 2010, pp. 7681–7687.

[11] S. Karaman, M. R. Walter, A. Perez, E. Frazzoli, and S. Teller, “Anytime
motion planning using the RRT*,” in IEEE International Conference on
Robotics and Automation, 2011, pp. 1478–1483.

[12] S. Karaman and E. Frazzoli, “Sampling-based optimal motion planning
for non-holonomic dynamical systems,” in IEEE International Confer-
ence on Robotics and Automation, 2013, pp. 5041–5047.

[13] J. Jeon, S. Karaman, and E. Frazzoli, “Anytime computation of time-
optimal off-road vehicle maneuvers using the RRT*,” in IEEE Confer-
ence on Decision and Control, 2011, pp. 3276 – 3282.

[14] D. J. Webb and J. van den Berg, “Kinodynamic RRT*: Asymptotically
optimal motion planning for robots with linear dynamics,” Proc. IEEE
Int. Conf. on Robotics and Automation - ICRA, 2013.

[15] A. Perez, R. Platt, G. Konidaris, L. Kaelbling, and T. Lozano-Perez,
“LQR-RRT*: Optimal sampling-based motion planning with automat-
ically derived extension heuristics,” in IEEE International Conference
on Robotics and Automation, 2012, pp. 2537–2542.

[16] G. Goretkin, A. Perez, R. Platt, and G. Konidaris, “Optimal sampling-
based planning for linear-quadratic kinodynamic systems,” in IEEE
International Conference on Robotics and Automation, 2013, pp. 2429–
2436.

[17] J.-S. Ha, J.-J. Lee, and H.-L. Choi, “A successive approximation-based
approach for optimal kinodynamic motion planning with nonlinear
differential constraints,” in IEEE Conference on Decision and Control,
2013, pp. 3623–3628.

[18] E. Glassman and R. Tedrake, “A quadratic regulator-based heuristic for
rapidly exploring state space,” in IEEE International Conference on
Robotics and Automation, 2010, pp. 5021–5028.
[19] F. L. Lewis and V. L. Syrmos, Optimal Control.

John Wiley & Sons,

1995.

[20] G. Tang, “Suboptimal control for nonlinear systems: A successive

−0.500.511.52−1−0.500.511.522.15sec1.45sec0.7sect = 0sec0sec00.511.522.5−6−4−202468t(sec)(Nm)  u1u2−0.500.511.52−1−0.500.511.521.25sec0.85sect = 0sec0.4sec0sec00.20.40.60.811.21.4−20−15−10−505101520t(sec)(Nm)  u1u2