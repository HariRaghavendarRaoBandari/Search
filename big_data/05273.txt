Fast Low-Complexity Decoders

for Low-Rate Polar Codes

Pascal Giard, Alexios Balatsoukas-Stimming, Gabi Sarkis, Claude Thibeault, and Warren J. Gross

1

6
1
0
2

 
r
a

 

M
8
1

 
 
]
T
I
.
s
c
[
 
 

2
v
3
7
2
5
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Polar codes are capacity-achieving error-correcting
codes with an explicit construction that can be decoded with
low-complexity algorithms. In this work, we show how the state-
of-the-art low-complexity decoding algorithm can be improved to
better accommodate low-rate codes. More constituent codes are
recognized in the updated algorithm and dedicated hardware
is added to eﬃciently decode these new constituent codes. We
also alter the polar code construction to further decrease the
latency and increase the throughput with little to no noticeable
eﬀect on error-correction performance. Rate-ﬂexible decoders for
polar codes of length 1024 and 2048 are implemented on FPGA.
Over the previous work, they are shown to have from 22% to
28% lower latency and 26% to 34% greater throughput when
decoding low-rate codes. On 65 nm ASIC CMOS technology,
the proposed decoder for a (1024, 512) polar code is shown to
compare favorably against the state-of-the-art ASIC decoders.
With a clock frequency of 400 MHz and a supply voltage of
0.8 V, it has a latency of 0.41 µs and an area eﬃciency of 1.8
Gbps/mm2 for an energy eﬃciency of 77 pJ/info. bit. At 600 MHz
with a supply of 1 V, the latency is reduced to 0.27 µs and the
area eﬃciency increased to 2.7 Gbps/mm2 at 115 pJ/info. bit.
Index Terms—Polar codes, successive-cancellation decoding

I. Introduction

Polar codes provably achieve the capacity of binary sym-
metric memoryless channels when decoded with the low-
complexity successive-cancellation (SC) algorithm [1]. The
capacity-achieving property and the low-complexity SC decod-
ing have spurred a signiﬁcant interest in the ﬁeld leading to the
implementation of many hardware decoders based on the SC
algorithm. However, the SC decoding algorithm is sequential
in nature and leads to high-latency, low-throughput decoder
implementations.

To increase decoding speed, two new decoding algorithms
derived from SC were introduced [2], [3]. These two algo-
rithms work by using dedicated, parallel decoding algorithms
on parts of a polar code. They exploit the recursive construc-
tion of polar codes and the a priori knowledge of the code
structure.

While the Fast-SSC [3] algorithm represents a signiﬁcant
improvement over the previous decoding algorithms, the work
in [3] and the optimization presented therein targeted high-
rate codes. Modiﬁcations of the Fast-SSC algorithm and

P. Giard, G. Sarkis and W. J. Gross are with the Department of Electrical
and Computer Engineering, McGill University, Montr´eal, Qu´ebec, Canada (e-
mail: {pascal.giard,gabi.sarkis}@mail.mcgill.ca, warren.gross@mcgill.ca).
A. Balatsoukas-Stimming is with the Telecommunications Circuits Lab-
oratory, ´Ecole polytechnique f´ed´erale de Lausanne, Lausanne, Switzerland
(e-mail: alexios.balatsoukas@epﬂ.ch).

C. Thibeault

is with the Department of Electrical Engineering,
´Ecole de technologie sup´erieure, Montr´eal, Qu´ebec, Canada (e-mail:
claude.thibeault@etsmtl.ca).

its hardware implementation targeting low-rate codes were
presented in [4]. In this paper, we formalize and improve
the code construction alteration process used in [4] and we
present more results using the proposed methods, algorithms
and implementation. These results show a 22% to 28% latency
reduction and a 22% to 28% throughput improvement with
little to negligible coding loss for low-rate moderate-length
polar codes.

The rest of this paper is organized as follows. Section II
provides the necessary background on polar coding. Section III
then discusses polar code construction alteration along with
our proposed method leading to improved latency and through-
put of a hardware decoder. In Section IV, modiﬁcations to the
original Fast-SSC algorithms are proposed in order to further
reduce the latency and increase the decoding throughput.
Sections V and VI present the implementation details along
with the detailed results on FPGA. Section VI also provides
ASIC results for our proposed decoder decoding a (1024, 512)
polar code for a comparison against state-of-the-art ASIC
decoders from the literature. Finally, Section VII concludes
this paper.

A. Polar Codes

II. Background

Polar codes are linear block codes with a recursively con-
structed generator matrix. In other words, a polar code of
length N is built from the concatenation of two constituent
polar codes of length Nv = N/2. This recursive construction
is carried out
in a way that polarizes the probability of
correctly estimating bits: some bit estimates become more
reliable and others becomes less reliable. As the blocklength
grows to inﬁnity, some bit estimates become fully reliable
and the rest become completely unreliable. In an (N, k) polar
code, the k most reliable bit are chosen to store information
bits. The remaining bits are called frozen bits and are set to
predetermined values.

1 1

The encoding process can be described as follows. A vector
containing the k information bits is ﬁrst expanded into a vector
of length N by inserting frozen bits at the appropriate frozen
bit locations. The resulting vector is then multiplied by the
generator matrix FN to yield the polar codeword, where FN =
⊗ log2 N
and ⊗ is the Kronecker power [1]. Frozen
F
2
bits are usually set to zero and their optimal locations depend
on the channel type and condition, as discussed in [5].

(cid:104) 1 0

, F2 =

(cid:105)

It was shown in [6] that polar codes can be encoded and
decoded systematically. This leads to an improved bit-error
rate (BER) without aﬀecting the frame-error rate (FER). In
this work, systematic polar codes are used.

B. Successive-Cancellation Decoding

estimates

A successive-cancellation decoder

the bits
u0, ..., ui sequentially using channel information and previ-
ously estimated bits. It utilizes three operations: F, G, and
Combine. The F operation, corresponding to a ⊕ in Fig. 1a,
accepts two log-likelihood ratio (LLR) inputs and provides
an LLR output. G, corresponding to a • in Fig. 1a, accepts
two LLRs and a bit-estimate to generate one LLR. Finally
Combine, which comprises both ⊕ and • in a left-to-right
takes two bit estimates and combines them to
direction,
provide two bit estimates. These operations are discussed in
detail in Section II-D.

C. From Decoder Graph to Decoder Trees

As shown in [2], [3], polar codes can be represented as trees.
Using only the three node types introduced in [2]—rate-0, rate-
1 and rate-R—the graph of Fig. 1a can be represented as the
decoder tree of Fig. 1b. The black and gray ui labels of Fig. 1a
correspond to information and frozen bits, respectively.

u0 +
u1
u2 +
u3
u4 +
u5
u6 +
u7

+

+

+

+

+

+

+

(a) Graph

x0
x1
x2
+ x3
x4
x5
x6
x7

right

left

u3
0

u7
6

u4 u5

(b) Decoder Tree

Fig. 1: Diﬀrent representations of polar codes.

In Fig. 1b, the rate-0 nodes are white and correspond to
a constituent code that contains only frozen bits, while rate-
1 nodes are black and correspond to a constituent code that
contains only information bits. Finally, the gray nodes are of
rate R, where 0 < R < 1, and correspond to a constituent code
that contains both frozen and information bits.

D. Fast-SSC Decoding

The Fast-SSC algorithm presented in [3] further trims the
decoder tree by using diﬀerent, more eﬃcient algorithms to
decode some constituent codes of rate R. The constituent codes
directly decoded in the Fast-SSC algorithm have diﬀerent
maximum lengths Nv depending on the complexity of the cor-
responding decoding algorithm. For example, for a repetition
node, Nv was set to 16 while it was set to 4 for an exhaustive
search maximum-likelihood (ML) node.

The decoder tree node types corresponding to the decoding
algorithm of [3] are summarized in Table I. Note that the
“01” node was called “ML” in [3]. We brieﬂy review the most
important operations and leaf node types below.

1) F Operations: The F operation generates the messages
to be sent to a left child and is performed using the min-sum
approximation as deﬁned in [7]:

2

αl[i] = F(αv[i], αv[i + Nv/2])

= sgn(αv[i])sgn(αv[i + Nv/2]) min(|αv[i]|,|αv[i + Nv/2]|),
(1)
where αv are soft reliability values from the parent node,
represented as LLRs, and Nv is the node input length.

2) G and G 0R Operations: The G operation generates
the messages to be sent to a right child node. It is performed
as deﬁned in [7]:

αr[i] = G(αv[i], αv[i + Nv/2], βl[i])

αv[i + Nv/2] + αv[i], when βl[i] = 0;

αv[i + Nv/2] − αv[i],

otherwise,

=

(2)

where βl is the bit estimate vector generated by the left sibling
in the subtree.

The G 0R operation is a special case of the G operation,
where the left-hand-side sibling in the subtree is a rate-0 node,
i.e. βl is a all-zero vector.

3) Combine and Combine 0R Operations: The Combine
operation corresponds to the concatenation of two bit-estimate
vectors generated from the left and right child nodes. As an
example, going up the tree, the node circled in blue in Fig. 1b
combines the bit-estimate vectors from its children to provide
the root node of the decoder tree with a bit estimate vector
for the right-hand-side subtree. In the graph representation
illustrated in Fig. 1a, the same operation is also circled in
blue and illustrates how the Combine operation calculates the
bit estimate vector βv:

βl[i] ⊕ βr[i], when i < Nv/2;

βr[i − Nv/2],

otherwise,

βv[i] =

(3)

where βl and βr are bit estimates emanating from the left and
right child nodes, respectively.

Similar to the G 0R operation, the Combine 0R operation
is a special case where the left-hand-side sibling in the subtree
is a rate-0 node i.e. βl is a all-zero vector.

4) Repetition Nodes: Repetition nodes provide the bit esti-
mate vector for a repetition code. A repetition code contains
a single information bit that is replicated over the length Nv
of the code. The maximum-likelihood decoding rule for these
codes is to perform threshold detection on the sum of the input
LLRs [3].

5) Single-parity-check Nodes: Single-parity-check (SPC)
nodes provide bit estimates for SPC codes. The bits in an SPC
codeword satisfy the even parity constraint, i.e. they sum to 0
under binary addition. The maximum likelihood algorithm to
decode them consists of ﬁrst verifying that hard decisions on
the input reliability values satisfy the parity contraint. In case
where they do not, the hard decision of the least reliable input
bit is ﬂipped.

6) Other Nodes: The remaining nodes are a concatenation
of the operations and nodes described above, or an extension.
For example, the RepSPC node is the concatenation of a
repetition node with an SPC node with a constant length

TABLE I: Decoder tree node types supported by the original
Fast-SSC polar decoder.

Name

Color

Description

error-correction performance is degraded. Although, as will be
shown in the next section, the impact can be small, especially
if the number of changes is limited.

3

0R
R1

White and gray Left-half side is frozen.
Gray and black Right-half side is all information.
Gray and yellow Right-half side is an SPC code.

RSPC
0SPC White and yellow Left-half side is frozen, right-half side

Rep

Green

is an SPC code.
Repetition code, maximum length Nv of
16.

RepSPC Green and yellow Concatenation of a repetition code on
the left and an SPC code on the right,
Nv = 8.

Black and white Fixed-length pattern Nv = 4 where the
left-half side is frozen and the right-half
side is all information.
Mixed rate node.

Gray

01

rate-R

Fig. 2: Decoder tree for the (1024, 512) polar code built using
[5] and decoded with the nodes and operations of [3].

Nv = 8. Another example is the 0SPC node, which is the
concatenation of a rate-0 node and an SPC node. Thus, it
replaces the execution of three operations: a G 0R operation,
an SPC operation and a Combine 0R operation.

With the specialized nodes and operations of Fast-SSC, the
trimmed decoder tree for the (8, 3) polar code illustrated in
Fig. 1 is made of a single 0SPC node.

III. Altering the Code Construction

A. Original Construction

As mentioned in Section II-A, a good polar code is con-
structed by selecting which bits to freeze, according to the type
of channel and its conditions [1], [5], [8], [9]. Fig. 2 shows
the decoder tree corresponding to the (1024, 512) polar code
constructed using the technique of [5] where only the node
types deﬁned in Table I are used with the same constraints of
[3]. The polar code was optimized for an Eb/N0 of 2.5 dB.
The F, G, G 0R, Combine and Combine 0R blocks are
constrained to a maximum of P = 512 inputs meaning

that, for nodes with a length Nv > P, (cid:6)Nv/P(cid:7) cycles are
RSPC—use pipelining and require(cid:6)Nv/P(cid:7)+4 clock cycles. Thus

required. The Rep, RepSPC and 01 blocks are all executed
in one clock cycle. Finally, the SPC-based nodes—0SPC and

the decoding latency to decode the tree of Fig. 2 using the
algorithm and implementation of [3] is 220 clock cycles (CC)
and the information throughput is 2.33 bits/CC.

Altering a polar code to further trim the decoder tree can
result
latency reduction, without aﬀecting
the code rate. By making these modiﬁcations however, the

in a signiﬁcant

B. Altered Polar Code Construction

In all simpliﬁed SC decoders, the size of the decoder tree
depends on the distribution of frozen and information bit
locations in the code. Arıkan’s original polar code construction
only focuses on maximizing the reliability of the information
bits. Several altered polar-like code constructions have been
proposed in the literature [10]–[12] and their objective is to
trade oﬀ error-correction performance for decoding complexity
by slightly changing the set of information bits, while keeping
the code rate ﬁxed. The main idea behind all the altered code
constructions is to exchange the locations of a few frozen bits
and information bits in order to get more bit patterns that are
favorable in terms of decoding latency. In all cases, care must
be taken in order to avoid using bit locations that are highly
unreliable to transmit information bits.
The method in [10] ﬁrst deﬁnes a small set of bit locations
which contains the ns−h least reliable information bit locations
along with the h most reliable frozen bit locations. Then, in
order to keep the rate ﬁxed, it performs an exhaustive search
possible combinations of the ns elements contain-
over all
ing exactly h frozen bit locations and selects the combination
that leads to the smallest decoding latency. In [11], the altered
construction problem is formalized as a binary integer linear
program. Consequently,
is shown that ﬁnding the polar
code with the lowest decoding complexity under an error-
correction performance constraint is an NP-hard problem. For
this reason, a greedy approximation algorithm is presented
which provides reasonable results at low complexity even for
large code lengths. A similar greedy algorithm is presented in
[12] for polar codes with more general code lengths of the
form N = ln, l ≥ 2.

(cid:16)ns

(cid:17)

it

h

C. Proposed Altered Construction

The methods of [11], [12] only considered rate-0 and rate-
1 nodes. As such, the results can not be directly applied to
Fast-SSC decoding, where several additional types of special
nodes exist. For this reason, in this work we follow the more
general exhaustive search method of [10], augmented with a
human-guided approach.

More speciﬁcally, bit-state alterations that would lead to
smaller latency are identiﬁed by visual
inspection of the
decoder tree for the unaltered polar code. This list of bit
locations is then passed to a program to be added to the
bit locations considered by the technique described in [10].
Hence, two lists are composed: one that contains frozen bit
locations proposed by the user as well as locations that were
almost reliable enough to be used to carry information bits,
and one that contains the information bit locations proposed by
the user and the locations that barely made it into information
bit locations.

The code alteration algorithm then proceeds by gradually
calculating the decoding latency for all possible bit swap

combinations. A constrained-size and ordered list of the com-
binations with the lowest decoding latency is kept. Once that
list needs to be trimmed, only one entry per latency value
is kept by simulating the error-correction performance of the
altered code at an Eb/N0 value of interest. The entry with the
best frame-error rate is kept and the others with the same
latency are removed from the list. That list containing the
best candidates is further trimmed by removing all candidates
that feature both a greater latency and worse error-correction
performance compared to those of their predecessor. Similarly
to the technique of [10], our proposed technique does not alter
the code rate as the total number of information and frozen
bits remains the same.

1) Human-guided Criteria: The suggested bits to swap
are selected to improve the latency and throughput. Thus,
these bit swaps must eliminate constituent codes for which
we do not have an eﬃcient decoding algorithm and create
ones for which we do. We classify the selection criteria
under two categories: the bit swaps that transform frozen bit
locations into information bit locations and bit swaps that do
the opposite. The former increase the coding rate while the
latter reduce it.

In addition to the node type deﬁnitions of Table I, the below
descriptions of criteria use the following types of subtrees or
nodes:

• R1-01: subtree rooted in a R1 node with a 01 leaf node,

may contain a chain of R1 nodes

• Rep1: subtree rooted in a R1 node with a leaf Rep node;
in Section IV, that subtree is made into a node where the
left-half side is a repetition code and the right-half side
is all information

• R1-RepSPC: subtree rooted in a R1 node with a RepSPC

leaf node, may contain a chain of R1 nodes

• Rep-Rep1: subtree where the rate-R node has a left-hand-
side and right-hand-side nodes are Rep and Rep1 nodes,
respectively

• 0-RepSPC: subtree rooted in a 0R node with a leaf
RepSPC node; in Section IV, that subtree is made into a
node where the left-half side is frozen and the the right-
half side is a RepSPC node

Dedicated hardware to eﬃciently decode Rep1 and 0Rep-

SPC nodes are presented in Section IV.
From frozen to information locations:
1) Unfreezing the second bit of a 01 node that is part of a

R1-01 subtree creates an RSPC node.

2) Changing an RepSPC into an RSPC node by adding the

second, third and ﬁfth bit locations.

3) Changing a RSPC node into a R1 node by changing the

SPC code into a rate-1 code.

Criterion 1 is especially beneﬁcial where the R1-01 subtree
contains a chain of R1 nodes, e.g., Pattern 5 in Fig. 3.
Similarly, Criterion 2 has a signiﬁcant impact on R1-RepSPC
subtrees containing a chain of R1 nodes, e.g., Pattern 3 in
Fig. 3.

From information to frozen locations:
4) Changing a 0R-01 subtree into a Repetition node.
5) Freezing the only information bit location of a Rep node

to change it into a rate-0 code.

4

[4]

[6]

[1]

[2]

[5]

[3]

(a) Before

(b) After

Fig. 3: Decoder trees for two diﬀerent (512, 376) polar codes,
where (a) and (b) are before and after construction alteration,
respectively.

6) A specialization of the above, changing a Rep-RepSPC
subtree into a 0-RepSPC subtree by changing the left-
hand-side Rep node into a rate-0 node.

7) Transforming a Rep-Rep1 subtree into a 0-RepSPC
subtree by changing the left-hand-side repetition code
into a rate-0 code and by freezing the ﬁfth bit location
of the Rep1 subtree to change the rate-1 code into an
SPC code.

Consider the decoder tree for a (512, 376) polar code as
illustrated in Fig. 3a, where some frozen bit patterns are circled
in blue and numbered for reference. Its implementation results
in a decoding latency of 106 clock cycles. That latency can be
signiﬁcantly reduced by freezing information bit locations or
by transforming previously frozen locations into information
bits.

Notably, ﬁve of the bit-swapping criteria—leading to latency
reduction—described above are illustrated in Fig. 3a. The
patterns numbered 1 and 2 are repetition nodes meeting the
fourth criterion. Changing both into rate-0 nodes introduces
two new 0R nodes. The patterns 3 to 6 are illustrations of the
fourth, second, sixth and ﬁrst criteria, respectively.

Fig. 3b shows the resulting decoder tree after the alterations
were made. The latency has been reduced from 106 to 82 clock
cycles.

2) Example Results: Applying our proposed altered con-
struction method, we were able to decrease the decoding
latency of the (1024, 512) polar code illustrated in Fig. 2 from
220 to 189 clock cycles, a 14% improvement, with 5 bit swaps.
That increases the information throughput to 2.71 bits/CC, up
from 2.33 bits/CC. The corresponding decoder tree is shown
in Fig. 4.

TABLE II: New functions performed by the proposed decoder.

5

Name
Rep1

Color

Green and black

0RepSPC White and lilac

Description
Repetition code on the left, rate-1
code on the right, maximum length
Nv of 8.
Rate-0 code on the left, RepSPC code
on the right, Nv = 16.

the right, Nv = 8.

001

4 white and 1
3

4 black Rate-0 code on the left, 01 code on

Fig. 4: Decoder tree for the altered (1024, 512) polar code.

100

10−1

R
E
F

10−2

10−3

10−4

10−1

10−2

10−3

R
E
B

10−4

10−5

10−6

1

2

3
Eb/N0 (dB)

4

1

2

3
Eb/N0 (dB)

4

Original:

Altered:

(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)

(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)

Fig. 5: Error-correction performance using binary phase shift
keying over an additive white Gaussian channel of the altered
codes compared to that of the original codes constructed using
the Tal and Vardy method [5].

The error-correction performance of the (1024, 512) altered
code is degraded as illustrated by the markerless black curves
in Fig. 5. The loss amounts to less than 0.25 dB at a FER of
10−4. For wireless applications, which are usually the target
for codes of such lengths and rates, this represents the FER
range of interest.

Fig. 5 also shows the error-correction performance of three
other polar codes altered using our proposed method. In the
case of these other codes, the alterations have a negligible
eﬀect on error-correction performance

IV. New Constituent Decoders

Looking at the decoder tree of Fig. 4, it can be seen that
some frozen bit patterns occur often. Adding support for more
constituent codes to the Fast-SSC algorithm will result in
reduced latency and increased throughput under the constraint
that the corresponding computation nodes do not signiﬁcantly
lengthen the critical path of a hardware implementation. As
a result of an investigation, the constituent codes of Table II
were added. Furthermore, post-place and route timing analysis

Fig. 6: Decoder tree for the altered polar code with the added
nodes.

showed that the maximum length Nv of a repetition node could
be increased from 16 to 32 without aﬀecting the critical path.
The new decoder tree shown in Fig. 6 has a decoding latency
of 165 clock cycles, which is a 13% improvement over the
decoder tree of Fig. 4 decoded with the original Fast-SSC
algorithm. Thus, the information throughput of that polar code
has been improved to 3.103 bits/CC.

To summarize, Table III lists the frozen bit patterns that can
be decoded by leaf nodes. It can be seen that the smallest
possible leaf node has length Nv = 4 while our proposed
decoder tree shown in Fig. 6 has a minimum length Nv = 8.
In other words, Fig. 6 is representative of the patterns listed
in Table III but not comprehensive.

V. Implementation

A. Quantization

Let Qi be the total number of bits used to represent LLRs
internally, Qc be the total number of bits to represent channel
LLRs, and Q f be the number of bits among Qi or Qc used to
represent the fractional part of any LLR. It was found through
simulations that using Qi.Qc.Q f = 6.5.1 quantization led to an
error-correction performance very close to that of the ﬂoating-
point number representation for the codes of interest as can
be seen in Fig. 7.

B. Rep1 Node

The Rep1 node decodes Rep1 codes—the concatenation of
a repetition code and a rate-1 code—of length Nv = 8. Its bit-
estimate vector β 7
0 is calculated using operations described
in the previous sections. However,
instead of performing
the required operations sequentially, the dedicated hardware
preemptively calculates intermediate soft values.

TABLE III: Frozen bit patterns decoded by leaf nodes.

Name
Rep

Rep1
0SPC
RepSPC
0RepSPC

01
001

Pattern
0001
0000 0001
0000 0000 0000 0001
0000 0000 0000 0000 0000 0000 0000 0001
0001 1111
0000 0111
0001 0111
0000 0000 0001 0111
0011
0000 0011

100

10−1

10−2

R
E
F

10−3

10−4

R
E
B

10−1

10−2

10−3

10−4

10−5

10−6

α7
0

F

(cid:12)(cid:12)(cid:12)β = 0
(cid:12)(cid:12)(cid:12)β = 1

G

G

6

β

x
i
M

β 7
0

Rep

Sign

Sign

Fig. 8: Architecture of the Rep1 Node.

α-RAM

α-Router

Channel RAM

Channel Loader

Channel

Processing Unit

Controller

β -Router

β -RAM

Instruction RAM

Instructions

Codeword RAM

Estimate

Fig. 9: High-level architecture of the decoder.

1

2

3
Eb/N0 (dB)

4

1

2

3
Eb/N0 (dB)

4

Floating-point

Fixed-point 6.5.1

Fig. 7: Impact of quantization on the error-correction perfor-
mance of the proposed (1024, 512) polar code.

Fig. 8 shows the architecture of the Rep1 node. It can be
seen that there are two G blocks. One preemptively calculates
soft values assuming that the Rep block will output β = 0
and the other for β = 1. The Rep block provides a single bit
estimate corresponding to the information bit the repetition
code of length Nv = 4 it is decoding. The outputs of the G
blocks go through a Sign block to generate hard decisions. The
correct hard decision vector is then selected using the output
of the Rep block. Finally, the bit estimate vector β 7
0 is built.
The highest part, β 7
4 , is always comprised of the multiplexer
output. The lowest part, β 3
0 , is either a copy of same output
or its binary negation. The negated version is selected when
the output of the Rep block is 1.

Calculations are carried out in one clock cycle. The output
of the F, G and Rep blocks are not stored in memory. Only the
ﬁnal result, the bit-estimate vector β 7
0 , is stored in memory.

C. High-Level Architecture

The high-level architecture of the decoder is presented in
Fig. 9. Instructions representing the polar decoding operations
to be performed are loaded before decoding starts. When the
decoder is started, the controller signals the channel loader
to start storing channel LLRs, 32 LLRs (160 bits) per clock
cycle, into the channel RAM. The controller then starts to
execute functions on the processing unit. The processing unit
reads LLRs from the Channel or α-RAM and writes LLRs to

the α-RAM. It reads or writes hard decisions to the β -RAM.
The last Combine operation writes the estimated codeword
into the Codeword RAM, a memory accessible from outside
the decoder.

The decoder is complete with all input and output buﬀers to
accommodate loading a new frame and reading an estimated
codeword while a frame is being decoded. The required
memory could be made smaller if the nominal throughput
required is lower. The loading or outputting of a full frame
takes fewer clock cycles than the actual decoding, we have
a pipelined operation; under normal operation, the decoder
should not be slowed down by the I/O operations.

D. Processing Unit or Processor

The core of the decoder is the processing unit illustrated
in Fig. 10 and based on the Fast-SSC implementation of [3].
Thus, the processing unit features all the modules required
to implement the nodes and operations described in sections
II-D and IV. Notably, the 01 and RepSPC blocks connected
to the G block implement
the 001 and 0RepSPC nodes,
respectively, where the all-zero vector input is selected at the
multiplexer m0. The critical path of the decoder corresponds
to the 0RepSPC node i.e. goes through G, RepSPC,
the
multiplexer m3, Combine and the multiplexer m2. It is slightly
longer than that of [3].

A. Veriﬁcation Methodology

VI. Results

A software model was used to generate random codewords
for transmission using binary phase shift keying (BPSK)
over an additive white Gaussian noise (AWGN) channel. The
functionality of the designs was veriﬁed both at the RTL level

m1

α(cid:48)

TABLE V: Latency and information throughput comparison
for low-rate moderate-length polar codes.

7

F

Rep1

Rep

m0

G

0

β0

α

01

01

Rep
SPC

m2

β(cid:48)

0

Sign

e
n
i
b
m
o
C

m3

SPC

Rep
SPC

β(cid:48)

1

β1

Fig. 10: Architecture of the processing unit.

TABLE IV: Post-ﬁtting results for rate-ﬂexible decoders for
moderate-length polar codes.

Implementation

N

LUTs

Regs.

[13]
[3]*

this work

1024
1024
2048
1024
2048

1,940
23,020
23,319
23,353
23,331

748
1,024
5,923
5,814
5,923

RAM
(kbits)
7.1
42.8
60.9
43.8
61.2

f

(MHz)

239
103
103
103
103

and at the post-place and route level through simulations.
Finally, the same frames were also decoded on an FPGA using
an FPGA-in-the-loop setup. For all Eb/N0 values, a minimum
of 100 frames in errors were simulated.

B. Comparison with State-of-the-art Decoders

In this section, post-ﬁtting results are presented for the
Altera Stratix IV EP4SGX530KH40C2 FPGA. All results are
worst-case using the slow 900 mV 85◦C timing model. Ta-
ble IV shows the results for two rate-ﬂexible implementations
for polar codes of length 1024 and 2048, respectively. The
decoder of [13] is also included for comparison.

Looking at the results for our proposed decoders, it can
be observed that the number of look-up tables (LUTs) and
registers required are very similar for both code lengths.
However, the RAM usage diﬀers signiﬁcantly where decoding
a longer code requires more memory as expected. Timing
reports show that the critical path corresponds to the 0RepSPC
node.

Table IV also compares the proposed decoders against the
decoder of [13] as well as the original Fast-SSC implemen-
tation [3]. The latter was resynthesized so that the decoder
only has to accommodate polar codes of length N = 1024 or
N = 2048 and is marked with an asterisk (*) in Table IV.

Our work requires at most a 1.4% increase in used LUTs
compared to [3]. The diﬀerence in registers can be mostly

Implementation

[13]

[3]*

altered codes

this work

altered codes

Code
(N, k)

(1024, 342)
(1024, 512)
(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)
(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)
(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)
(1024, 342)
(1024, 512)
(2048, 683)
(2048, 1024)

Latency

(CCs)
2185
2185
201
220
366
389
173
186
289
336
193
204
334
367
157
165
274
308

(µs)
9.14
9.14
1.95
2.14
3.55
3.78
1.68
1.81
2.81
3.26
1.87
1.98
3.24
3.56
1.52
1.60
2.66
2.99

Info. T/P
(Mbps)

37
56
175
240
192
271
204
284
243
314
183
259
211
287
224
320
257
342

attributed to register duplication, a measure taken by the
ﬁtter to shorten the critical path to meet the requested clock
frequency. The SRAM usage was also increased by 2.3%.

Table V shows the latency and information throughput of the
decoders of Table IV when decoding low-rate moderate-length
polar codes. It also shows the eﬀect of using a polar codes
with altered constructions—as described in Section III—with
all Fast-SSC-based decoders. For both [3]* and our work, the
results listed as ‘altered codes’ have the same resource usage
and clock frequency as listed in Table IV since these decoders
can decode any polar code of length N = 1024 or N = 2048
by changing the code description in memory.

Applying the proposed altered construction alone, Table V
shows that decoding these altered codes with the original
decoders of [3] results in a 14% to 21% latency reduction
and a 16% to 27% throughput improvement. From the same
table, it can be seen that decoding the unaltered codes with
the updated hardware decoder integrating the proposed new
constituent decoders, the latency is reduced by 4% to 10%
and the throughput is improved by 4% to 10%.

Combining the contribution of both the altered construc-
tion method and the new dedicated constituent decoders, the
proposed work achieves the best latency among all compared
decoders. For the polar codes of length N = 1024,
the
throughput is 5.7 to 6.1 times greater than that of the two-
phase decoder of [13]. Finally, the latency is reduced by 22%
to 28% and the throughput is increased by 26% to 34% over
the Fast-SSC decoders of [3].

Table VI presents a comparison of this work against the
state-of-the-art ASIC implementations. Our ASIC results are
for the 65 nm CMOS GP technology from TSMC and are ob-
tained with Cadence RTL Compiler. Only registers were used
for memory due to the lack of access to an SRAM compiler.
Normalized results for the decoders from the literature are also
provided. For consistency, only results for a (1024, 512) polar
code are compared to match what was done in the other works.

TABLE VI: Comparison of state-of-the-art ASIC decoders
decoding a (1024, 512) polar code.

[14](cid:5)
BP

[16]

This work
Fast-SSC
Algorithm
65 nm
Technology
1.3
1.0
0.8
Supply (V)
Oper. temp. (◦C)
N/A
25
25
Area (mm2)
3.21
0.69 0.69
Area @65nm (mm2)
1.68
0.69 0.69
2.5
400 600
Frequency (MHz)
Latency (µs)
0.41 0.27
0.39
1.24 1.86 2.4 @ 4dB 1.28
Info. T/P (Gbps)
1.28
Sust. Info. T/P (Gbps) 1.24 1.86
Area Eﬀ. (Gbps/mm2) 1.8
1.6 @ 4dB 0.4
2.7
215
96
Power (mW)
191
Energy (pJ/bit)
115 203 @ 4dB 149
77
(cid:5) Measurement results.

[15]
SC 2-bit SC
65 nm 90 nm 45 nm
N/A
1.0
≈ 25
N/A
N/A
1.48
0.4
1.48
750
300
1.02
50
0.5
0.5
N/A
N/A
N/A

1.0

478

It should be noted that [14] provides measurement results.

From Table VI, it can be seen that both implementations
of our proposed decoder—at diﬀerent supply voltages—are
46% and 42% the size of the BP decoder [14] and the
combinational decoder [15], respectively, when all areas are
normalized to 65nm technology. Our work has two orders of
magnitude lower latency than the BP decoder of [14], and
two to ﬁve times lower latency than [16]. The latency of the
proposed design is 1.05 times and 0.7 times that of [15], when
operating at 400 and 600 MHz, respectively. The BP decoder
[14] employs early termination and its throughput at Eb/N0 = 4
dB is the fastest followed by our proposed design. Since the
area reported in [14] excludes the memory necessary to buﬀer
additional received vectors to sustain the variable decoding
latency due to early termination, we also report the sustained
throughput for that decoder. The sustained throughput is 1.0
Gbps as a maximum of 15 iterations is required for the BP
decoder to match the error-correction performance of the SC-
based decoders. Comparing the information throughput of all
decoders—using the best-case values for BP,— it can be seen
that the area eﬃciency of our decoder is the greatest. Lastly,
the power consumption estimations indicate that our decoders
are more energy eﬃcient than the BP decoder of [14]. Our
proposed decoders are also more energy eﬃcient than that
of [15]. However, due to the diﬀerence in implementation
technology, the results of this latter comparison could change
if [15] were to be implemented in 65nm.

VII. Conclusion

In this work, we showed how the original Fast-SSC algo-
rithm implementation could be improved by adding dedicated
decoders for three new types of constituent codes frequently
appearing in low-rate codes. We also used polar code construc-
tion alterations to signiﬁcantly reduce the latency and increase
the throughput of a Fast-SSC decoder at the cost of a small
error-correction performance loss. Rate-ﬂexible polar decoders
for polar codes of lengths 1024 and 2048 were implemented
on an FPGA. Four low-rate polar codes with competitive error-
correction performance were proposed. Their resulting latency
and throughput represent a 22% to 28% reduction and a 26%
to 34% improvement over the previous work, respectively. The

8

information throughput was shown to be 224, 320, 257, and
342 Mbps at approximately 100 MHz on the Altera Stratix
IV FPGAs for the (1024, 342), (1024, 512), (2048, 683) and
(2048, 1024) polar codes, respectively. On 65 nm ASIC CMOS
technology, the proposed decoder for a (1024, 512) polar code
was shown to compare favorably against the state-of-the-art
ASIC decoders. With a clock frequency of 400 MHz and a
supply voltage of 0.8 V, it has a latency of 0.41 µs and an
area eﬃciency of 1.8 Gbps/mm2 for an energy eﬃciency of
77 pJ/info. bit. At 600 MHz with a supply of 1 V, the latency
is reduced to 0.27 µs and the area eﬃciency increased to 2.7
Gbps/mm2 at 115 pJ/info. bit.

Acknowledgement

This work was supported by the Natural Sciences and
Engineering Research Council of Canada (NSERC). Claude
Thibeault is a member of ReSMiQ. Warren J. Gross is a
member of ReSMiQ and SYTACom.

References

[1] E. Arıkan, “Channel polarization: A method for constructing capacity-
achieving codes for symmetric binary-input memoryless channels,” IEEE
Trans. Inf. Theory, vol. 55, no. 7, pp. 3051–3073, 2009.

[2] A. Alamdar-Yazdi and F. R. Kschischang, “A simpliﬁed successive-
cancellation decoder for polar codes,” IEEE Commun. Lett., vol. 15,
no. 12, pp. 1378–1380, Dec. 2011.

[3] G. Sarkis, P. Giard, A. Vardy, C. Thibeault, and W. J. Gross, “Fast polar
decoders: Algorithm and implementation,” IEEE J. Sel. Areas Commun.,
vol. 32, no. 5, pp. 946–957, May 2014.

[4] P. Giard, G. Sarkis, C. Thibeault, and W. Gross, “A 638 Mbps low-
complexity rate 1/2 polar decoder on FPGAs,” in IEEE Workshop on
Signal Process. Syst. (SiPS), Oct 2015, pp. 1–6.

[5] I. Tal and A. Vardy, “How to construct polar codes,” IEEE Trans. Inf.

Theory, vol. 59, no. 10, pp. 6562–6582, Oct 2013.

[6] E. Arıkan, “Systematic polar coding,” IEEE Commun. Lett., vol. 15,

no. 8, pp. 860–862, 2011.

[7] C. Leroux, I. Tal, A. Vardy, and W. Gross, “Hardware architectures for
successive cancellation decoding of polar codes,” in IEEE Int. Conf. on
Acoust., Speech, and Signal Process. (ICASSP), May 2011, pp. 1665–
1668.

[8] R. Mori and T. Tanaka, “Performance and construction of polar codes
on symmetric binary-input memoryless channels,” in IEEE Int. Symp.
on Inf. Theory (ISIT), 2009, pp. 1496–1500.

[9] P. Trifonov, “Eﬃcient design and decoding of polar codes,” IEEE Trans.

Commun., vol. 60, no. 11, pp. 3221–3227, 2012.

[10] Z. Huang, C. Diao, and M. Chen, “Latency reduced method for modiﬁed
successive cancellation decoding of polar codes,” Electron. Lett., vol. 48,
no. 23, pp. 1505–1506, Nov 2012.

[11] A. Balatsoukas-Stimming, G. Karakonstantis, and A. Burg, “Enabling
complexity-performance trade-oﬀs for successive cancellation decoding
of polar codes,” in IEEE Int. Symp. on Inf. Theory (ISIT), 2014, pp.
2977–2981.

[12] L. Zhang, Z. Zhang, X. Wang, C. Zhong, and L. Ping, “Simpliﬁed
successive-cancellation decoding using information set reselection for
polar codes with arbitrary blocklength,” IET Communications, vol. 9,
no. 11, pp. 1380–1387, Jul. 2015.

[13] A. Pamuk and E. Arıkan, “A two phase successive cancellation decoder
architecture for polar codes,” in IEEE Int. Symp. on Inf. Theory (ISIT),
Jul. 2013, pp. 1–5.

[14] Y. S. Park, Y. Tao, S. Sun, and Z. Zhang, “A 4.68Gb/s belief propagation
polar decoder with bit-splitting register ﬁle,” in Symp. on VLSI Circuits
Dig. of Tech. Papers, Jun 2014, pp. 1–2.

[15] O. Dizdar

and E. Arıkan,

“A high-throughput
implementation of successive-cancellation decoder
using combinational
[Online]. Available: http://arxiv.org/abs/1412.3829

energy-eﬃcient
for polar codes
logic,” CoRR, vol. abs/1412.3829, Mar 2015.

[16] B. Yuan and K. Parhi, “Low-latency successive-cancellation polar de-
coder architectures using 2-bit decoding,” IEEE Trans. Circuits Syst. I,
vol. 61, no. 4, pp. 1241–1254, Apr 2014.

