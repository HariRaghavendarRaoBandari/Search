6
1
0
2

 
r
a

 

M
1
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
5
0
7
3
0

.

3
0
6
1
:
v
i
X
r
a

XIX Escola Brasileira de Probabilidade

3–8 de Agosto de 2015

São Sebastião-SP, Brasil

Probabilistic Models for the (sub)Tree(s) of Life

Amaury Lambert1

Abstract: The goal of these lectures is to review some mathematical aspects of
random tree models used in evolutionary biology to model gene trees or species
trees.

We start with stochastic models of tree shapes (ﬁnite trees without edge lengths),

culminating in the β-family of Aldous’ branching models.

We next introduce real trees (trees as metric spaces) and show how to study

them through their contour, provided they are properly measured and ordered.

We then focus on the reduced tree, or coalescent tree, which is the tree spanned
by individuals/species alive at the same ﬁxed time. We show how reduced trees,
like any compact ultrametric space, can be represented in a simple way via the
so-called comb metric. Beautiful examples of random combs include the Kingman
coalescent and coalescent point processes.

We end up displaying some recent biological applications of coalescent point
processes to the inference of species diversiﬁcation, to conservation biology, to epi-
demiology and to population genetics.

Keywords:
coalescent; comb; phylogenetics; population dynamics; population genetics.

random tree; tree shape; real tree; reduced tree; branching process;

1UPMC Univ Paris 06. Please email your comments to amaury.lambert@upmc.fr and check updates

at http://www.lpma-paris.fr/pageperso/amaury/

Contents

1 Tree shapes

1.3 Random tree shapes

1.2.1 Counting trees
1.2.2 Counting rankings and labellings

1.1 Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Combinatorics warm up . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
1.3.1 Uniform distributions . . . . . . . . . . . . . . . . . . . . . .
1.3.2 The law of your favourite random tree
. . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . .
1.4.1 Deﬁnitions and interval splitting . . . . . . . . . . . . . . . .
1.4.2 ERM, PDA and Aldous’ β-splitting model
. . . . . . . . . .
Sampling consistency . . . . . . . . . . . . . . . . . . . . . .
1.4.3

1.4 Markov branching models

2 Real Trees

2.1 Preliminaries

2.2.1 The real tree
2.2.2 First constructive example: Connecting segments
2.2.3

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.1
Scaling limits . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 Local time . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Deﬁnitions and examples . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . .
Second constructive example: Chronological trees . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
2.3.1 From the R-tree to its contour process
. . . . . . . . . . . .
2.3.2 From the contour to the tree . . . . . . . . . . . . . . . . . .
2.3.3 A few words on topology . . . . . . . . . . . . . . . . . . . .
2.4 Random R-trees . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.1
Splitting trees . . . . . . . . . . . . . . . . . . . . . . . . . .
2.4.2 The continuum random tree . . . . . . . . . . . . . . . . . .

2.3 The contour process

2

4
4
5
5
7
9
9
11
15
15
17
22

26
26
26
27
29
29
30
31
34
34
35
37
39
39
41

3 Reduced Trees

3.1.1 Deﬁnition and examples
3.1.2

3.2.1 The reduced tree of splitting trees, of the Brownian tree
3.2.2 A more general class of models

3.1 The comb metric . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . .
Spheres of R-trees . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Coalescent Point Processes . . . . . . . . . . . . . . . . . . . . . . .
. .
. . . . . . . . . . . . . . . .
3.3 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.1 Bottlenecks and missing tips . . . . . . . . . . . . . . . . . .
3.3.2 Loss of phylogenetic diversity . . . . . . . . . . . . . . . . .
3.3.3 Do species age? . . . . . . . . . . . . . . . . . . . . . . . . .
3.3.4 How long does speciation take? . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . .
3.3.5 Trees with random marks
3.4 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3

44
44
44
46
48
48
52
55
56
59
61
61
63
66

Chapter 1

Tree shapes

Standard references on the topic of this chapter include: Barthélémy and Guénoche
(1991); Stanley (1999); Semple and Steel (2003).

1.1 Deﬁnitions

In these lecture notes, we call tree shape any rooted, ﬁnite tree (no edge lengths,
no plane embedding). A ﬁnite tree τ is an acyclic graph (V,E) where V = V(τ ) is
a ﬁnite set whose elements are called the vertices or nodes of τ, and E = E(τ ) is a
subset of V × V whose elements are (not ordered and) called the edges of τ. The
root of τ is a distinguished vertex of τ.

We will also use the following terminology.

• Degree. The degree of a node u of the tree shape τ is the number of its
neighbors, where a neighbor of u is an element v of τ such that (u, v) is an
edge of τ. We will always assume that the root has degree 1.

• Partial order. If u and v are two nodes of τ, we say that v is descending from
u and we write u (cid:22) v, if v is not in the same connected component of τ \ {u}
as the root. The relation (cid:22) is a (partial) order on the vertex set of τ.

• Tips/leaves. All nodes with degree 1 but the root, are called tips or leaves. All
other nodes (including the root) are called internal nodes (or internal vertices).
• A tree shape is said binary when each of its internal nodes (but the root) has

degree 3.

4

5

In the next chapter, we will introduce a framework not needed at this stage, known
as Ulam–Harris–Neveu coding, in which ﬁnite trees can be embedded into the set
U of ﬁnite words, where a word v descends from a word u if u is a preﬁx of v.

We also mention that in combinatorial phylogenetics, a tree whose tips are la-
belled by some ﬁnite set X is usually identiﬁed as a so-called X-hierarchy (Semple
and Steel 2003). An X-hierarchy is a collection H of subsets of X containing all
singletons and such that for any A, B ∈ H, A ∩ B ∈ {∅, A, B}.
Exercise 1.1.1. Display the labelled tree coded by the {1, 2, 3, 4, 5}-hierarchy H =
{{1},{1, 4},{1, 4, 5},{2},{2, 3},{3},{4},{5}}.

1.2 Combinatorics warm up

1.2.1 Counting trees
Deﬁnition 1.2.1. We let Tn denote the set of all binary tree shapes with n tips,
n the set of binary tree shapes with n tips labelled by {1, . . . , n}. The elements
and T (cid:96)
n are called cladograms or labelled tree shapes (with n tips).
of T (cid:96)

Deﬁnition 1.2.2. For any (labelled or not) tree shape τ, we call radial order any
total order < on the internal nodes of τ respecting the genealogical order. In other
words, < is a radial order if for any internal nodes u and v of τ,

u (cid:22) v ⇒ u < v,

where we recall that u (cid:22) v means that v is descending from u.
Note that the minimal element in a radial order is always the root.

Example 1.2.3. The archetypal example of radial order is the order in which splits
occur through continuous time in a tree produced by a birth–death process. Note that
this is speciﬁc to continuous time, since in discrete time there are always several
nodes with the same generation (i.e., the same graph distance to the root).

Deﬁnition 1.2.4. We let Rn denote the set of all binary tree shapes with n tips
endowed with a radial order. The elements of Rn are called ranked tree shapes
(with n tips).
{1, . . . , n}. The elements of R(cid:96)
tips).

n denote the set of ranked tree shapes with n tips labelled by
n are called labelled, ranked tree shapes (with n

Also, we let R(cid:96)

6
n → Tn mapping each labelled tree shape to
There is a canonical surjection (cid:96) : T (cid:96)
the same tree shape without labels. We use the same notation for the surjection
n → Rn.
(cid:96) : R(cid:96)
Similarly, there is a canonical surjection r : Rn → Tn mapping each ranked tree
shape to the same tree shape without radial order. We use the same notation for
the surjection r : R(cid:96)
The mappings (cid:96) and r are sometimes called the forgetful maps, because they
consist in ‘forgetting’ the labels or the ranks, respectively. It is obvious that (cid:96)◦ r =
r ◦ (cid:96), so that the following diagram commutes.

n → T (cid:96)
n .

R(cid:96)
n

(cid:96)

Rn

r

r

T (cid:96)
n

(cid:96)

Tn

n and R(cid:96)
We now give explicit expressions for the cardinal numbers of T (cid:96)
n.
Proposition 1.2.5 (Murtagh 1984). For each n ≥ 2, set tn := #T (cid:96)
#R(cid:96)

n. Then

tn = (2n − 3)!! := (2n − 3)(2n − 5)··· (3)(1)

n and rn :=

n! (n − 1)!

2n−1

rn =

Remark 1.2.6. No explicit expression is known for #Tn or #Rn.
Proof. We reason by induction. Let pn : T (cid:96)
n denote the projection which
maps each τ with n + 1 labelled tips to the tree spanned by the tips of τ carrying
labels in {1, . . . , n}. Note that

n+1 → T (cid:96)

tn+1 =

#p−1

n ({τ}).

n ({τ}). It is immediate that each tree shape with n labelled
Now let us compute #p−1
n has n external edges, n − 2 internal edges and a root edge. This gives
tips τ ∈ T (cid:96)
2n− 1 distinct locations where to grow a new external edge carrying the label n + 1,
n ({τ}) = 2n − 1. In conclusion, tn+1 = (2n − 1)tn and the
which means that #p−1
ﬁrst result follows, since t2 = 1.

For ranked tree shapes, we can similarly consider the projection (still denoted)

pn : R(cid:96)

n+1 → R(cid:96)

n and use the similar equality

rn+1 =

#p−1

n ({τ}).

(cid:88)

τ∈T (cid:96)

n

(cid:88)

τ∈R(cid:96)

n

7
n ({τ}). Each ranked tree shape with n labelled tips τ ∈ R(cid:96)
Now let us compute #p−1
has n − 1 ordered internal nodes. Growing a new edge with label n + 1 requires
to add a new internal node. There are n distinct locations where to insert it in
the radial order, say between the (k − 1)-st internal node and the k-th internal
node for 1 ≤ k ≤ n. For a given k, there are k distinct edges where to grow the
new edge, which means #p−1
In conclusion,
rn+1 = n(n + 1)rn/2 and the second result follows, since r2 = 1.

n ({τ}) = 1 + ··· + n = n(n + 1)/2.

n

xn
n!

is well deﬁned for |x| < 1

2. By

Exercise 1.2.7. Check that t(x) := (cid:80)
n−1(cid:88)

n≥1 tn
combinatorial arguments, prove that for n ≥ 2

(cid:18)n

(cid:19)

tn =

1
2

ti tn−i

i

i=1

and deduce that t(x) = x + 1

2t (x)2. Conclude that t(x) = 1 − √

1 − 2x.

Exercise 1.2.8. A tree shape is said oriented when each internal vertex has a
left and a right descending subtree. Each orientation gives a tree a unique plane
embedding. Prove that the number of ranked oriented trees with n tips is (n−1)! and
that the number of ranked, oriented trees with n labelled tips is n! (n− 1)!. Also if o
n, o−1({τ}) = 2n−1.
denotes the map forgetting orientation, check that for any τ ∈ R(cid:96)
This gives another proof of the formula rn = n! (n−1)!
2n−1

.

1.2.2 Counting rankings and labellings
Deﬁnition 1.2.9. For any τ ∈ Tn, an internal node u of τ is said symmetric if
the two subtrees descending from u (i.e., the two connected components of τ \ {u}
not containing the root) are identical. A particular case of symmetric node is when
u subtends (i.e., is the most recent common ancestor of) a cherry, that is u only
subtends (two) tips.

We denote by s(τ ) the number of symmetric nodes of τ, and by c(τ ) the number

of cherries of τ.

Assume we were to extend the notion of symmetric node to labelled (resp. ranked)
tree shapes, in the sense that the two descending subtrees of a symmetric node
should have not only the same shape but also the same tip labels (resp. the same
internal node ranks). Then no node would be symmetric in a labelled tree shape
(ranked or not), and in a ranked tree shape, only cherries would be symmetric. This
explains the following convention.

8

Deﬁnition 1.2.10. For any τ ∈ T (cid:96)
c(τ ) the number of cherries of τ.
Exercise 1.2.11. Prove that for any unlabelled tree shape τ with n tips (τ ∈ Tn ∪
Rn), the number of distinct labellings of τ is

n, we denote invariably by s(τ ) or

n ∪ Rn ∪ R(cid:96)

(1.1)
where we recall that if τ is ranked (τ ∈ Rn), s(τ ) is the number of cherries of τ
(see previous discussion).

#(cid:96)−1({τ}) = 2−s(τ ) n!

Deﬁnition 1.2.12. For any tree shape τ (labelled or not, ranked or not), for any
vertex v ∈ V(τ ), if τ(cid:48) denotes the subtree descending from v, we denote invariably
by λ(v) or by λ(τ(cid:48)) the number of leaves subtended by v, which is also the number
of leaves of τ(cid:48).
Note that λ(v) = 1 iﬀ v is a leaf.

Eq (1.1) gives an explicit expression for the number of distinct labellings of a given
tree shape τ. The next statement gives the number of distinct rankings of any given
(either labelled or not labelled) tree shape.

Proposition 1.2.13 (Knuth 1997). For any unranked tree shape τ with n tips
(τ ∈ Tn ∪ T (cid:96)

n ), the number of distinct rankings of τ is
(n − 1)!

#r−1({τ}) = 2c(τ )−s(τ )

(cid:81)

v∈˚V(τ )(λ(v) − 1)

,

(1.2)

n ), s(τ ) = c(τ ).

Now assume that τ ∈ T (cid:96)

where ˚V(τ ) denotes the set of internal vertices of τ. Recall that when τ is labelled
(τ ∈ T (cid:96)
Proof. First note that the total number of internal vertices of τ is #˚V(τ ) = λ(τ )−1.
n and let τ(cid:48) and τ(cid:48)(cid:48) denote the two labelled subtrees
descending from the root of τ (say for example that τ(cid:48) is the subtree containing the
tip with label 1). Let k denote the number of internal vertices of τ(cid:48). Assuming that
the k internal nodes of τ(cid:48) are ordered and that the n − k − 2 internal nodes of τ(cid:48)(cid:48)
are ordered, the number of ways of ordering the internal nodes of τ(cid:48) and τ(cid:48)(cid:48) with

respect to each other is(cid:0)n−2

(cid:1). In conclusion,
(cid:18)n − 2
(cid:19)

k

k

#r−1({τ}) =

#r−1({τ(cid:48)}) #r−1({τ(cid:48)(cid:48)}),

9

#r−1({τ(cid:48)(cid:48)})
(n − 2 − k)!

.

which also reads

#r−1({τ})
(n − 1)!

=

1

n − 1

An immediate induction yields

#r−1({τ(cid:48)})

k!

(cid:89)

v∈˚V(τ )

#r−1({τ})
(n − 1)!

=

1

λ(v) − 1

,

which is the expected result for labelled tree shapes.

Now assume that τ ∈ Tn. The following proof relies on the equality

#(cid:96)−1(r−1({τ})) = #r−1((cid:96)−1({τ})),

due to the fact that (cid:96) and r commute.

First, let ˜τ ∈ Rn such that r(˜τ ) = τ. Recall from Eq (1.1) that the number of

distinct labellings of ˜τ is 2−s(˜τ ) n! = 2−c(τ ) n!, which yields

#(cid:96)−1(r−1({τ})) = #r−1({τ}) 2−c(τ ) n!

Second, let ¯τ ∈ T (cid:96)

n such that (cid:96)(¯τ ) = τ. From what precedes, we know that

#r−1({¯τ}) = (n − 1)!

1

λ(v) − 1

= (n − 1)!

1

λ(v) − 1

,

(cid:89)

v∈˚V(¯τ )

(cid:89)

v∈˚V(τ )

which yields
#r−1((cid:96)−1({τ})) = #(cid:96)−1({τ})(n−1)!

λ(v) − 1
thanks again to Eq (1.1). Equalling the expression for #(cid:96)−1(r−1({τ})) and the
expression for #r−1((cid:96)−1({τ})) provides the ﬁnal result.

λ(v) − 1

v∈˚V(τ )

v∈˚V(τ )

,

1

= 2−s(τ ) n! (n−1)!

(cid:89)

1

(cid:89)

1.3 Random tree shapes

1.3.1 Uniform distributions

Deﬁnition 1.3.1. Let UnifT (cid:96)
and R(cid:96)

n respectively.

n

probabilities on T (cid:96)

n deﬁned as
P pda
n

:= UnifT (cid:96)

n

and UnifR(cid:96)

n

denote the uniform distributions on T (cid:96)
n

We will adopt the following notation. The distributions P pda

and P erm

n

are the

n

and

P erm
n = UnifR(cid:96)

n

◦ r−1.

10

The distribution P urt

n

is the probability on Rn deﬁned as

P urt
n

:= UnifR(cid:96)

n

◦ (cid:96)−1

n

n ◦ r−1 = P erm

◦ (cid:96)−1 is the push forward of UnifR(cid:96)

Note that P urt
Remark 1.3.2. The preceding denominations come from the terminology used in
the phylogenetics literature (Aldous 1996, 2001; Blum and François 2006; Brown
1994; Lambert and Stadler 2013; Semple and Steel 2003), where these three TLAs1
have the following meanings.

by (cid:96) ◦ r.

n

• PDA stands for ‘proportional to distinguishable arrangements’,
• ERM stands for ‘equal rates Markov’,
• URT stands for ‘uniform on ranked (labelled) trees’.

Thanks to Proposition 1.2.5, and to Equations (1.1) and (1.2), here are the prob-
abilities of any given tree τ under various of the previously deﬁned distributions.
For any τ ∈ T (cid:96)
n ,

◦ (cid:96)−1(τ ) =

P pda
n

(cid:18)2k

(cid:19)

1

#(cid:96)−1({τ})

tn

n! 2−s(τ )

tn

2n−1−s(τ )

cn−1

,

=

=

is the k-th Catalan number, and

where ck :=

P erm
n

k

k + 1
◦ (cid:96)−1(τ ) = #(cid:96)−1({τ})

(cid:89)

v∈˚V(τ )

2n−1
n!

1

λ(v) − 1

=

(cid:81)

2n−1−s(τ )

v∈˚V(τ )(λ(v) − 1)

Exercise 1.3.3. We will see that the tree generated by a Yule (pure-birth) process
stopped upon reaching n particles, has the law P urt
of the uniform labelled, ranked
tree shape after ignoring labels. Check the computations shown for the Yule tree
with n tips (n = 4, 5, 6) in Figures 1.1, 1.2 and 1.3.

n

1Three-Letter Acronym

P pda
n

(τ ) =

1
tn
#r−1({τ})

rn

=

=

1

(2n − 3)!!
2n−1
n!

(cid:89)

v∈˚V(τ )

1

λ(v) − 1

P erm
n

(τ ) =

P urt
n (τ ) =

#(cid:96)−1({τ})

rn

2n−1−c(τ )
(n − 1)!

=

and

For any τ ∈ Rn,

For any τ ∈ Tn,

11

Figure 1.1: Probabilities of trees shapes with n = 4 tips under P urt
n . (a) the caterpillar tree
with 4 tips has only one conforming ranked shape, with probability 2/3; (b) the symmetric
tree with 4 tips also has one conforming ranked shape, with probability 1/3.

Figure 1.2: Probabilities of trees shapes with n = 5 tips under P urt
n . (a) is the caterpillar
tree with 5 tips, which has only one conforming ranked shape, with probability 1/3; (b) has
one conforming ranked shape with probability 1/6; (c) has 3 conforming ranked shapes,
each with probability 1/6.

1.3.2 The law of your favourite random tree

The Bienaymé–Galton–Watson tree shape
Let B stand for the law of a binary (unlabelled) Galton–Watson tree with parameter
p ∈ (0, 1), where p is the probability of begetting two oﬀspring, and Bn the law of
the same tree conditioned to have n leaves. Set σn the probability of having n leaves
under B

σn := B(λ = n),

(a)(b)2/31/3(a)(b)(c)1/31/61/212

Figure 1.3: Probabilities of trees shapes with n = 6 tips under P urt
n . (a) is the caterpil-
lar tree with 6 tips, which has only one conforming ranked shape, with probability 2/15;
(b) has one conforming ranked shape with probability 1/15; (c) has 3 conforming ranked
shapes, each with probability 1/15; (d) has 4 conforming ranked shapes, each with prob-
ability 1/30; (e) has 4 conforming ranked shapes, each with probability 1/15; (f) has 3
conforming ranked shapes, each with probability 1/15.

so that for each τ ∈ Tn,

Bn(τ ) =

B(τ )
σn

.

Now I will leave the reader convince herself (by drawing an example, say the two dif-
ferent binary trees with 4 leaves; or more rigorously, proving that the total number
of plane orientations of an unlabelled, unranked tree shape τ is 2n−1−s(τ )) that

B(τ ) = 2n−1−s(τ )

(1 − p)

= 2n−1−s(τ ) pn−1 (1 − p)n.

(1.3)

v∈˚V(τ )

u tip of τ

Now thanks to Eq (1.1), we know that

 (cid:89)

p

(cid:34) (cid:89)
(cid:88)

τ∈Tn

tn =

(cid:96)−1({τ}) =

(cid:35)

(cid:88)

τ∈Tn

2−s(τ ) n!

(a)(b)(c)(d)(e)(f)2/151/151/52/154/151/5so that

σn =

2n−1−s(τ ) pn−1 (1 − p)n =

2n−1 tn

n!

pn−1 (1 − p)n.

13

(1.4)

(cid:88)

τ∈Tn

In conclusion, for each τ ∈ Tn,

Bn(τ ) =

B(τ )
σn

=

n! 2−s(τ )

#(cid:96)−1({τ})

=

= P pda

n

◦ (cid:96)−1(τ ),

tn

tn
which can be recorded in the following statement
Proposition 1.3.4. For each integer n ≥ 2, Bn = P pda
If the reader is not convinced that (1.3) does hold, another proof will be given in
the context of Markov branching models page 18.
Notice that Bn does not depend on p. Also note for the record that the proba-
bility of a given labelled tree shape under the Galton–Watson model with uniform
labelling is 2n−1

n! pn−1(1 − p)n (where n is its number of tips).

◦ (cid:96)−1.

n

The Yule tree shape

◦ r−1 is denoted P erm

n

n

The reason why UnifR(cid:96)
is that it is the law of the (uniformly
labelled) tree shape given by the genealogy of a population where all particles split
independently and at the same rate b, called birth rate, into two new particles (more
details to come in Chapter 3). The process counting the size of the population is
a Markov process jumping from k to k + 1 at rate bk and is usually called pure
birth process, or Yule (sometimes Yule–Furry) process (see Lambert 2008 for an
introduction to stochastic models of population dynamics and genealogies).
More speciﬁcally let Yn denote the probability on Rn deﬁned as the law of the
ranked tree shape generated by a pure-birth process started at 1 and stopped upon
reaching n, where the radial order is the chronological order of node splits. It is
clear that this probability does not depend on the birth rate b.
Proposition 1.3.5. For each integer n ≥ 2, Yn = P urt
Yn ◦ r−1 of a Yule tree whose node ranks are ignored is P erm
Proof. Let us prove the proposition by induction on n (the proposition obviously
holds for n = 2). Let n ≥ 2 and assume the proposition holds for this n. Now let
τ be a ranked tree shape with n + 1 tips. Let v denote the maximal interior node
in the radial order and let v(cid:48) denote the maximal interior node in the genealogical
order of the path from the root to v. Deﬁne ˆτ as the ranked tree shape with n

n . In particular, the law

◦ (cid:96)−1.

n

tips obtained from τ by collapsing the cherry subtended by v into a single terminal
edge. By deﬁnition of the Yule process, if v(cid:48) subtends a cherry in ˆτ, then splitting
any of the two tips of this cherry of ˆτ into a new cherry yields τ. Otherwise, only
one tip of ˆτ can be split to yield τ. This can be expressed as

14

By the induction hypothesis,

Yn+1(τ ) =

21λ(v(cid:48))=3

n

Yn(ˆτ )

Yn+1(ˆτ ) = P urt

n (ˆτ ) =

2n−1−c(ˆτ )
(n − 1)!

,

so that

Yn+1(τ ) =

But now check that c(τ ) = c(ˆτ ) + 1λ(v(cid:48))(cid:54)=3, which yields the result.

21λ(v(cid:48))=3 2n−1−c(ˆτ )

.

n!

The Kingman tree shape

Conversely, consider a population where each pair of particles independently merges
at the same rate c, called coalescence rate (or competition rate) into one single new
particle. The process counting the size of the population is a Markov pure-death
process jumping from k to k − 1 at rate ck(k − 1)/2.
More speciﬁcally, let Kn denote the probability on R(cid:96)
n of the labelled, ranked tree
shape generated by this process started from n labelled particles and naturally
stopped when it reaches 1, usually called Kingman n-coalescent tree (Kingman
1982). Obviously, Kn does not depend on c.
Proposition 1.3.6. For each integer n ≥ 2, Kn = UnifR(cid:96)
Kn ◦ (cid:96)−1 of a Kingman tree whose labels are ignored is the law UnifR(cid:96)
a Yule tree.
Proof. Let us prove the proposition by induction on n (the proposition obviously
holds for n = 2). Let n ≥ 2 and assume the proposition holds for this n. Let τ
be a ranked tree shape with n + 1 labelled tips. Let i and j be the labels of the
cherry subtended by the maximal interior node in the radial order, and as in the
previous proof, let ˆτ be the ranked tree shape with n labelled tips obtained from τ
by collapsing this cherry into one single terminal edge and relabelling the new tip.
By induction Kn(ˆτ ) = 1/rn, so that

. In particular, the law
◦ (cid:96)−1 = Yn of

n

n

Kn+1(τ ) =

2

n(n + 1)

Kn(ˆτ ) =

2

n(n + 1)

1
rn

=

1

rn+1

,

which terminates the proof.

15

Exercise 1.3.7. Explain why the probability distribution P erm
balanced trees than P pda
as the caterpillar tree (see panel (a) in each of Figures 1.1–1.3), prove that

puts more weight on
. If an denotes the most imbalanced tree with n tips, known

n

n

P pda
n

◦ (cid:96)−1(an) =

2n−2
cn−1

and

P erm
n

◦ (cid:96)−1(an) =

2n−2
(n − 1)!

.

n
◦ (cid:96)−1(an)

P pda
n

P erm
n

◦ (cid:96)−1(an)

3

1

1

4

4
5

2
3

5

4
7

1
3

6

8
21

2
15

7

8
33

2
45

Table 1.1: Numerical values of the probability of the caterpillar tree under P erm
Observe the larger weight put on this tree under P pda

than under P erm

.

n

n

n

and P pda

n

.

One can easily see that the probability of the caterpillar tree with n tips, under
either of these two distributions, vanishes as n → ∞. Nevertheless, the probability
that one of the two subtrees incident to the root subtends exactly one tip (i.e., a
long external edge) converges to 1

, as will be seen in Exercise 1.4.5.

4 under P pda

n

n

It is generally observed that none of the random tree shapes generated by P erm
or by P pda
statistically give a good ﬁt to empirical species trees. More speciﬁcally,
real phylogenies are less balanced than random trees under P erm
but more balanced
than random trees under P pda
. In the following section, we introduce more gen-
eral models of random tree shapes, as well as a one-parameter family of tree shape
distributions interpolating in particular P erm

and P pda

.

n

n

n

n

n

1.4 Markov branching models

1.4.1 Deﬁnitions and interval splitting
In what follows, for each τ ∈ Tn∪T (cid:96)
n , we will write τ = τ(cid:48)⊕τ(cid:48)(cid:48) to denote the fact that
τ(cid:48) and τ(cid:48)(cid:48) are the two subtrees descending from the root of τ. It will be convenient
to assume that τ(cid:48) is chosen uniformly at random among the two possible subtrees

16

(except in the case when τ is not labelled and the root is symmetric, since then
τ(cid:48) = τ(cid:48)(cid:48)). Note that it would also have been possible to select τ(cid:48) deterministically
as the subtree containing the tip with label 1 say, or the subtree with the smaller
number of tips.
Deﬁnition 1.4.1 (Aldous 1996). A family of distributions (Pn) on T (cid:96)
n is a Markov
branching model if there is a family of laws (qn) on {1, . . . , n− 1} such that qn(i) =
qn(n − i) for all i, and for any τ ∈ T (cid:96)
n ,
2qn(i)

(cid:0)n
(cid:1) Pi(τ(cid:48)) Pn−i(τ(cid:48)(cid:48)),

Pn(τ ) =

i

where τ = τ(cid:48) ⊕ τ(cid:48)(cid:48) and i = λ(τ(cid:48)) (when n = 3, and i = 2, P2(τ(cid:48)) = 1 = P1(τ(cid:48)(cid:48))).
Note the abuse of notation, since τ(cid:48) is not in general labelled by {1, . . . , i}. It is
implicit that Pn is invariant by permutations of labels (Pn is said exchangeable or
equivariant) and deﬁned independently from the chosen label set.
Remark 1.4.2. If τ(cid:48) was chosen to be the subtree containing the tip with label 1
(instead of being chosen at random), the previous display would become

(cid:0)n−1
(cid:1) Pi(τ(cid:48)) Pn−i(τ(cid:48)(cid:48)).

qn(i)
i−1

Pn(τ ) =

A third possibility would be to choose τ(cid:48) as the subtree with the smaller number of
tips. The details are left to the reader (see also Aldous 2001).
To generate a labelled tree shape with law Pn, proceed recursively.

1. Draw a random variable Kn ∈ {1, . . . , n − 1} with law qn.
2. Conditional on Kn = i, select a subset I of {1, . . . , n} with cardinality i,

uniformly at random.

3. Create two edges joining the root of τ to τ(cid:48) and τ(cid:48)(cid:48) respectively, where τ(cid:48) and τ(cid:48)(cid:48)
are two independent tree shapes labelled respectively by I and its complement,
with respective laws Pi and Pn−i.

Exercise 1.4.3. If τ ∈ Tn, recall that τ = τ(cid:48) ⊕ τ(cid:48)(cid:48) still makes sense, and check that
s(τ ) = s(τ(cid:48)) + s(τ(cid:48)(cid:48)) except when τ(cid:48) = τ(cid:48)(cid:48), where s(τ ) = 1 + s(τ(cid:48)) + s(τ(cid:48)(cid:48)). Deduce
that

Pn ◦ (cid:96)−1(τ ) = 21τ(cid:48)(cid:54)=τ(cid:48)(cid:48) qn(i) Pi ◦ (cid:96)−1(τ(cid:48)) Pn−i ◦ (cid:96)−1(τ(cid:48)(cid:48)),

where again i = λ(τ(cid:48)). Explain why (Pn◦(cid:96)−1) can also be seen as a Markov branching
model (on unlabelled tree shapes).

non-negative function on (0, 1) such that f (x) = f (1− x) and(cid:82) 1

Now we introduce a speciﬁc way of designing Markov branching models. Let f be a
0 x(1− x)f (x) dx <
∞. Set

17

(cid:90) 1

0

(cid:0)1 − xn − (1 − x)n(cid:1) f (x) dx,

(cid:18)n
(cid:19)(cid:90) 1

n−1(cid:88)

i

0

i=1

αn :=

xi(1 − x)n−if (x) dx =

which is ﬁnite by assumption. Then we deﬁne

(cid:18)n

(cid:19)(cid:90) 1

i

0

n(i) := α−1
qf

n

xi(1 − x)n−if (x) dx,

(cid:82) 1

n ) the associated Markov branching model.

as well as (P f
In the case when f is integrable, one can generate a labelled tree shape with law
n by throwing uniformly n points in (0, 1) and performing a recursive interval
P f
splitting procedure, down until each interval contains at most two of the initial
points. Let U1, . . . , Un be i.i.d. random variables uniform in (0, 1). Assume that
0 f (x) dx = 1.
1. Draw some independent r.v. X with density f in (0, 1).
2. Let I be the subset of {1, . . . , n} deﬁned by: i ∈ I ⇔ Ui < X. Then condi-
tional on X = x, proceed as in the general case, by putting the labels of I in
τ(cid:48) and those of its complement in τ(cid:48)(cid:48).

3. Repeat the same procedure to the intervals (0, x) and (x, 1) independently.

It is intuitive from this description that the more f puts weight close to the bound-
aries of (0, 1), the more the associated random tree shape is imbalanced.

1.4.2 ERM, PDA and Aldous’ β-splitting model

Theorem 1.4.4 (Harding 1971; Slowinski 1990; Brown 1994). Both (P erm
(P pda

) are Markov branching models with

n

) and

n

qpda
n (i) =

1
2

and

qerm
n (i) =

1

n − 1

tn
Proof. We know that for any τ ∈ T (cid:96)
n written τ = τ(cid:48) ⊕ τ(cid:48)(cid:48), with i = λ(τ(cid:48)), P pda
n−i (τ(cid:48)(cid:48)) = 1
, so that

(τ(cid:48)) = 1

and P pda

i

, P pda

i

n

1
tn

tn−i

ti

(τ ) =

(cid:18)n
(cid:19) ti tn−i

P pda
n

(τ ) =

1
tn

=

ti tn−i

tn

P pda

i

(τ(cid:48)) P pda

n−i (τ(cid:48)(cid:48)),

18

i

limn qpda

n (i)

1

1
4

2

1
16

3

1
32

4

5

128

Table 1.2: The limiting value, as n → ∞, of a basal split i vs n − i, under P pda

n

.

We now focus on the distribution of λ(τ(cid:48)) =: Jn under P erm

which agrees with the characterization of Markov branching models choosing qpda
as in the theorem.
◦
. Recall that P erm
(cid:96)−1 is the law of the unranked and unlabelled Yule tree. Consider two particles, a
red one and a black one. Give these two particles independent Yule descendances
and stop the process when the total number of particles equals n. By the strong
Markov property of the Yule process (applied at the time it reaches 2), Jn has the
same law as the number of red (say) particles when the process stops. By the strong
Markov property applied at the ﬁrst time when there are n − 1 particles, it is easy
to see that

n

n

n

P(Jn = i) =

P(Jn−1 = i − 1) +

P(Jn−1 = i),

i − 1
n − 1

n − 1 − i
n − 1
1

.

n − 1

An immediate induction shows that P(Jn = i) =

n

Now recall that P erm

is also the law of the unranked Kingman coalescent tree.
Fixing a subset I of {1, . . . , n} with cardinality i and conditioning the Kingman
coalescent tree to have on the one hand all lineages initially labelled by I and on
the other hand all lineages initially labelled by the complement of I, coalesce within
each other before coalescing between each other, yields two independent Kingman
coalescent trees (forbidding a restricted subset of the pairwise exponential clocks to
ring does not alter the independence of the other clocks). Now these two unranked,
labelled subtrees follow respectively P erm

n−i , which yields the result.

and P erm

i

Exercise 1.4.5. Show that limn→∞ qpda
the ﬂat distribution qerm

n ’ (Semple and Steel 2003).

n (i) = ci−14−i, which ‘contrasts sharply with

Back to the Galton–Watson tree

Here, we want to give a proof of Proposition 1.3.4 via Markov branching models,
without using (1.3). Let τ ∈ Tn and write τ = τ(cid:48) ⊕ τ(cid:48)(cid:48), i = λ(τ(cid:48)). Then by the

B(τ ) = p 21τ(cid:48)(cid:54)=τ(cid:48)(cid:48) B(τ(cid:48))B(τ(cid:48)(cid:48)),

19

branching property,

which becomes

Bn(τ ) = p 21τ(cid:48)(cid:54)=τ(cid:48)(cid:48) σi σn−i
σn

Bi(τ(cid:48))Bn−i(τ(cid:48)(cid:48)).

Now recalling Exercise 1.4.3, this shows that Bn = Pn ◦ (cid:96)−1, where (Pn) is the
Markov branching model associated with

Then it remains to show that

σn =

for this will ensure that

qn(i) =

1
2

qn(i) = p

σi σn−i

σn

2n−1 tn

n!

pn−1 (1 − p)n,

(cid:18)n

(cid:19) ti tn−i

,

i

tn

(1.5)

which indeed is the splitting probability of the PDA model. Actually, (1.5) was
already obtained as Eq (1.4), but this equation was derived from (1.3), so we have
to prove (1.5) by other means. This can actually be done in multiple ways, using
for example the Lukasiewicz path associated to the tree and Dwass identity (see for
example Pitman 2006).

Aldous’ β-splitting model

The β-splitting model of Aldous (1996, 2001) is a one-parameter family of interval
splitting branching models. Speciﬁcally, for any β ∈ (−2, +∞), consider

fβ(x) = xβ(1 − x)β

x ∈ (0, 1).

The law qfβ

n associated with fβ will be denoted qβ
n.

Exercise 1.4.6. Prove that

Γ(β + i + 1) Γ(β + n − i + 1)

1

where Γ is the usual Gamma function Γ(x) =(cid:82) ∞

qβ
n(i) =

an(β)

Γ(i + 1) Γ(n − i + 1)

(cid:90) 1

0

tx−1 e−t dt, for x > 0, and

(cid:0)1 − xn − (1 − x)n(cid:1) xβ(1 − x)β dx.

an(β) :=

Γ(2β + n + 2)

Γ(n + 1)

0

,

(1.6)

This family has some interesting special cases. As noticed earlier, the balance of
the tree increases with β. As β → ∞, the intervals are split deterministically in
their middle, while as β → −2, the splitting procedure converges to pure erosion,
that is P β
n puts weight converging to 1 on the caterpillar tree. The three other cases
of interest are β = 0, β = −3/2 and β = −1.

20

• β = 0. Thanks to Eq (1.6), q0

1

n − 1

= qerm

n (i), so that

n(i) does not depend on i, which implies q0

n(i) =

β = 0 =⇒ P β

n = P erm

n

.

• β = −3/2. We are going to prove that

β = −3/2 =⇒ P β

n = P pda

n

.

=

2

,

(cid:1)

tn =

π. Now tedious calculations (note the missing ‘4’ in Aldous 1996, equation

Γ(2n − 2)
2n−2 Γ(n − 1)

√
following Eq 5) show that

First notice that we can write
(2n − 3)!
2n−2 (n − 2)!

= 2n−1 Γ(cid:0)n − 1
Γ(cid:0) 1
(cid:1)
where we used the identities Γ(x) Γ(cid:0)x + 1
(cid:1) = 21−2x √
π Γ(2x) and Γ(cid:0) 1
(cid:1)
(cid:1) Γ(cid:0) 1
4 Γ(cid:0)n − 1
(cid:1)
(cid:1) Γ(cid:0)n − i − 1

(cid:1) =

−3
2

(cid:19)
(cid:18)
(cid:1) Γ(cid:0)i − 1

− 3
n (i) =

so that

Γ(i + 1) Γ(n − i + 1)

4 Γ(cid:0)n − 1

Γ(n + 1)

Γ(n + 1)

2

,

2

q

an

=

2

2

(cid:1) Γ(cid:0) 1

2

2

2

2

2

n (i).
• β = −1. This model is sometimes called AB model for ‘Aldous branching’.

Γ(i + 1) Γ(n − i + 1)

tn

=

Γ(n + 1)

ti tn−i

= qpda

2

1
2

First check thanks to (1.6) that

q−1
n (i) =

1

an(−1)

Γ(i) Γ(n − i)

Γ(i + 1) Γ(n − i + 1)

=

an(−1)

1

i(n − i)

.

Then

an(−1) =

n−1(cid:88)

i=1

1

(cid:19)

(cid:18)1

n−1(cid:88)

i

i=1

1

i(n − i)

=

1
n

+

1
n − i

=

2hn−1

n

,

β

−2

smaller clade size

1

− 3

2

1.5

−1
√

n

0 ∞

n
4

n
2

21

Table 1.3: Median value of the smaller clade size at the basal split as n → ∞, under P β
n .

with the usual notation hn for the harmonic series

hn := 1 +

+ ··· +

1
n

.

1
2

n

In the end, we get

q−1
n (i) =

1

i(n − i)

2hn−1

n

n

and P erm

The remarkable feature of the β-splitting family is that it interpolates between
maximally imbalanced (caterpillar) trees and random (maximally) balanced trees
passing through P pda
. Table 1.3 is taken from Aldous (2001, Table 3) and
n .
provides the median size of the smaller daughter clade at the basal split under P β
Remark 1.4.7. The reason why the name of Aldous is tied to the special case
β = −1 is due to the empirical observation that the trees generated by P −1
give the
best ﬁt to real phylogenies. In Aldous (2001), this was shown by a visual ﬁt to a
linear dependence with slope 1/2 in the log-log scale of the size of the median split
vs n (see previous table). In Blum and François (2006), the MLE of β for species
trees is remarkably centered around −1. The biological reason for this pattern is
still very much debated (Hagen et al. 2015; Manceau et al. 2015).

n

For the record, we ﬁnally provide a closed-form expression for the probability of a
given labelled tree shape τ ∈ T (cid:96)
Proposition 1.4.8. For any β > −2 and τ ∈ T (cid:96)
n ,

n under P β
n .

P β

n (τ ) =

Γ(β + 2)n 2n−1
Γ(β + n + 1)

Γ(β + λ(v) + 1)

Γ(λ(v) + 1) aλ(v)(β)

(1.7)

(cid:89)

v∈˚V(τ )

Proof. Thanks to Deﬁnition 1.4.1 and Eq (1.6), writing τ = τ(cid:48) ⊕ τ(cid:48)(cid:48) and i = λ(τ(cid:48)),

we get by an immediate induction

i (τ(cid:48)) P β

n−i(τ(cid:48)(cid:48))

2qn(i)

(cid:0)n
(cid:1) P β
(cid:89)

2

an(β) n!

i

P β

n (τ ) =

=

=

Γ(β + λ(τ(cid:48)) + 1) Γ(β + λ(τ(cid:48)(cid:48)) + 1) P β

i (τ(cid:48)) P β

n−i(τ(cid:48)(cid:48))

2

aλ(v)(β) λ(v)!

v∈˚V(τ )

Γ(β + λ(v1) + 1) Γ(β + λ(v2) + 1),

where for each internal node v, we have denoted by v1 and v2 its two oﬀspring
vertices. Therefore,

(cid:34) (cid:89)

u tip of τ

22

(cid:35)

 (cid:89)

v∈˚V(τ )

(cid:89)

v∈˚V(τ )

n (τ ) = Γ(β + n + 1)−1
P β

2Γ(β + λ(v) + 1)

aλ(v)(β) λ(v)!

Γ(β + λ(u) + 1)

,

which yields (1.7).
Exercise 1.4.9. By giving the value 0 or −3/2 to β, recover from (1.7) the explicit
expressions

For β = 0 you will need to remember that an(0) = n − 1, and for β = −3/2 that

P erm
n

(τ ) =

2n−1
n!

tn = 2n−1 Γ(cid:0)n − 1
Γ(cid:0) 1
(cid:1)

2

(cid:1)

2

1

λ(v) − 1

and

P pda
n

(τ ) =

1
tn

(cid:18)

(cid:19)

−3
2

=

4 Γ(cid:0)n − 1

2

(cid:1) Γ(cid:0) 1

2

(cid:1)

Γ(n + 1)

.

and

an

1.4.3 Sampling consistency
Following Aldous (1996), we will say that the Markov branching model (Pn) is
sampling consistent if for each n ≥ 2, the random tree shape ˆτ obtained from the
tree τ with law Pn+1, after removing its edge subtending the label n + 1, has law
Pn.

Exercise 1.4.10. Prove that a Markov branching model where q4(2, 2) = 1 cannot
be sampling consistent.

It is obvious that the interval splitting branching models (P f
tent. The converse statement is given in the following theorem.

n ) are sampling consis-

there is a measure µ on [0, 1] invariant by x (cid:55)→ 1− x such that(cid:82)

Theorem 1.4.11. Let (Pn) be a sampling consistent Markov branching model. Then
[0,1] x(1− x) µ(dx) <
(cid:27)
∞ and

µ(dx) xi (1 − x)n−i + nµ({0})1i=1 + nµ({1})1i=n−1

qn(i) = α−1

n

23

(1.8)

(cid:26)(cid:18)n
(cid:19)(cid:90)
(cid:90)

i

αn =

where

(0,1)

µ(dx)(cid:0)1 − xn − (1 − x)n(cid:1) + nµ({0, 1}).

(0,1)

Remark 1.4.12. If µ has a density f w.r.t. Lebesgue measure, then we are left
with the interval splitting models of Aldous. The terms due to atoms at 0 and
1 correspond to single labels separated from the rest of the labels, a phenomenon
called erosion. The theorem states that the only Markov branching models that
are sampling-consistent combine interval splitting with erosion. In the case of pure
erosion (i.e., when µ charges only {0, 1}), all trees are caterpillar trees a.s.
Remark 1.4.13. A more general version of the previous statement (i.e., not re-
stricted to binary trees) is shown in Haas et al. (2008) by identifying the splitting
rules with the transitions of a general fragmentation process (Bertoin 2006). This
also allows the authors to study scaling limits of these random tree shapes. In partic-
ular, when β ∈ (−2,−1), the trees with n tips generated by the β-splitting branching
model, converge as n → ∞ when their edges are given properly scaled lengths, to
some closed set called real tree (weakly in the Gromov–Hausdorﬀ topology, see next
chapter).
Proof of Theorem 1.4.11. Assume that (Pn) form a Markov branching model, by
deﬁnition exchangeable, and by assumption sampling consistent. Let 1 ≤ i ≤ n ≤
m. Consider the tree generated by Pm and let σ be the most recent common ancestor
(mrca, i.e., the ancestor with maximal distance to the root) of all the tips carrying a
label in {1, . . . , n}, let τ denote its descending subtree, and write τ = τ(cid:48) ⊕ τ(cid:48)(cid:48). Now
let Jn,m (resp. J(cid:48)
n,m) denote the set of labels carried by the tips of τ (resp. τ(cid:48),
τ(cid:48)(cid:48)). By construction, {1, . . . , n} is entirely contained in Jn,m, and intersects both
J(cid:48)
n,m and J(cid:48)(cid:48)
Next, by sampling consistency, the triple (Jn,m+1, J(cid:48)
n,m+1) restricted to
{1, . . . , m} has the same law as (Jn,m, J(cid:48)
n,m). By Kolmogorov’s extension theo-
rem, all these triples can be coupled on a same probability space, i.e., there exists a
n) of random subsets of N, such that Jn contains {1, . . . , n},
random triple (Jn, J(cid:48)
n) form a partition of Jn, both intersect {1, . . . , n}, and the restriction of
(J(cid:48)
n, J(cid:48)(cid:48)
(Jn, J(cid:48)
n, J(cid:48)(cid:48)

n,m, which form a partition of Jn,m.
n,m, J(cid:48)(cid:48)

n) to {1, . . . , m} has the same law as (Jn,m, J(cid:48)

n,m+1, J(cid:48)(cid:48)

n,m, J(cid:48)(cid:48)

n,m, J(cid:48)(cid:48)

n, J(cid:48)(cid:48)

n,m).

24

By exchangeability, Jn is a.s. inﬁnite. In addition, J(cid:48)

n are also exchange-
able subsets of Jn so by de Finetti’s theorem they have asymptotic frequencies
denoted respectively X(cid:48)

n and J(cid:48)(cid:48)

n and X(cid:48)(cid:48)

n, that is

2, J(cid:48)(cid:48)

n, J(cid:48)(cid:48)

n and X(cid:48)(cid:48)

n ∈ dx, J(cid:48)

n ∩ {n + 1, . . . , k}
#J(cid:48)(cid:48)
#Jn ∩ {n + 1, . . . , k} ,

n ∩ {n + 1, . . . , k}
#J(cid:48)
#Jn ∩ {n + 1, . . . , k}

X(cid:48)
n := lim
k→∞
n is independent of Jn. Note that X(cid:48)
n and 1 − X(cid:48)

and X(cid:48)(cid:48)
n := lim
k→∞
n = 1. Since X(cid:48)
n + X(cid:48)(cid:48)
n have the same law.

n) or to (Jn, J(cid:48)(cid:48)

2 ) is either equal to (Jn, J(cid:48)

n have the
From here on, we denote {1, . . . , n} by [n]. Let A be a ﬁxed subset of [n] such
n ∩ [n] = A, the triple
n) with probabilities equal

and X(cid:48)
same law, we can record that X(cid:48)
that 1 ∈ A but 2 (cid:54)∈ A. Now observe that on the event J(cid:48)
n, J(cid:48)
(J2, J(cid:48)
to 1/2. So for any x ∈ (0, 1), writing Ac for {1, . . . , n} \ A,
2 ∈ dx, J(cid:48)
P(X(cid:48)
Now by de Finetti’s theorem, conditional on J2 and X(cid:48)
(1{ai∈J(cid:48)
r.v. with success parameter x. So we get
2 ∩ [n] = Ac)
2 ∈ dx, J(cid:48)

2 ∩ [n] = Ac).
2 = x, the indicator variables
2}), where ai is the i-th element of J2, are independent copies of the Bernoulli

2 ∩ [n] = A, J(cid:48)(cid:48)
= P(X(cid:48)

n ∩ [n] = Ac) =

n ∩ [n] = A, J(cid:48)(cid:48)

2 ∈ dx) xi−1 (1 − x)n−i−1,
where we let i denote the cardinality of A. We can rewrite the next-before-last
equality as
P(X(cid:48)

2 ∈ dx) xi−1 (1 − x)n−i−1.

P([n] ⊂ J2) P(X(cid:48)

n ∩ [n] = A) =

2 ∩ [n] = A, [n] ⊂ J2)
= P([n] ⊂ J2) P(X(cid:48)

2 ∩ [n] = A, J(cid:48)(cid:48)

n ∈ dx, J(cid:48)

2 ∈ dx, J(cid:48)

P(X(cid:48)

P(X(cid:48)

1
2

1
2

Summing all these equalities over all possible A’s with cardinality 1 ≤ i ≤ n − 1,
gives by exchangeability
P(X(cid:48)

(cid:18)n − 2
(cid:19)

P([n] ⊂ J2) P(X(cid:48)

n = i, 1 ∈ J(cid:48)

n ∈ dx, #J(cid:48)

n, 2 (cid:54)∈ J(cid:48)

2 ∈ dx) xi−1 (1−x)n−i−1.

n) =

1
2

i − 1

By exchangeability again, the left-hand-side equals
n) = P(X(cid:48)

n = i, 1 ∈ J(cid:48)

n ∈ dx, #J(cid:48)

P(X(cid:48)

n ∈ dx, #J(cid:48)

n = i)

i(n − i)
n(n − 1)

,

so that

P(X(cid:48)

n ∈ dx, #J(cid:48)

n = i) =

P([n] ⊂ J2)

2 ∈ dx)
P(X(cid:48)
2x(1 − x)

xi (1 − x)n−i.

n, 2 (cid:54)∈ J(cid:48)
(cid:19)

(cid:18)n

i

Now let us treat the case when X(cid:48)
exactly the same reasoning as above,

n = 0, that is J(cid:48)

n is reduced to a singleton. By

P(X(cid:48)

n = 0, J(cid:48)

n = {1}) =

P([n] ⊂ J2) P(X(cid:48)

2 = 0),

1
2

so again by exchangeability

25

n = 0, #J(cid:48)
Reasoning symmetrically with X(cid:48)(cid:48)

P(X(cid:48)

P(X(cid:48)

n ∈ dx, #J(cid:48)

n = i) = P([n] ⊂ J2)

i

n
2

P([n] ⊂ J2) P(X(cid:48)

2 = 0).

n = 1) =
n, we ﬁnally get for all x ∈ [0, 1] and i ∈ [n − 1],

(cid:18)n
(cid:19)(cid:0)xi (1 − x)n−i 1x∈(0,1) + 1(x,i)=(0,1) or (1,n−1)

(cid:1) µ(dx),

where µ is the positive measure on [0, 1] deﬁned by

µ(dx) :=

1

2x(1 − x)

P(X(cid:48)

2 ∈ dx)1x∈(0,1) +

P(X(cid:48)

2 = 0) δ0(dx) +

1
2

P(X(cid:48)

2 = 1) δ1(dx).

1
2

Summing on i ∈ [n − 1] yields

n ∈ dx) = P([n] ⊂ J2)(cid:0)(cid:0)1 − xn − (1 − x)n(cid:1) 1x∈(0,1) + n 1x∈{0,1}(cid:1) µ(dx).

P(X(cid:48)

(cid:18)(cid:90)

Integrating w.r.t. x, we have

P([n] ⊂ J2) =

x∈(0,1)

so that
P(X(cid:48)

n ∈ dx, #J(cid:48)

n = i) = α−1

n

(cid:19)−1

=:

(cid:0)1 − xn − (1 − x)n(cid:1) µ(dx) + nµ({0, 1})
(cid:18)(cid:18)n
(cid:19)

xi (1 − x)n−i 1x∈(0,1) + 1(x,i)=(0,1) or (1,n−1)

i

1
αn

(cid:19)

,

µ(dx).

Integrating w.r.t. x gives the result, because qn(i) = P(#J(cid:48)

n = i).

Chapter 2

Real Trees

Textbooks and surveys available on the topic of this chapter include: Duquesne and
Le Gall (2002); Evans (2008); Le Gall (2005).

2.1 Preliminaries

2.1.1 Scaling limits

As seen in the previous chapter, it is tempting to investigate the limiting behaviour
of some marginals of our random tree shapes with n tips, as n → ∞. Typically
interesting marginals include the maximal leaf height (the generation at which the
population becomes extinct), the maximal width (the maximal population size), the
coalescence time (number of generations back to the most common recent ancestor
of a given subpopulation). There are also higher dimensional, natural marginals like
the leaf-height process (the sequence of heights of tip i, i = 1, . . . , n, for some plane
embedding of the tree), or the width process (the process counting the number of
individuals at each successive generation).

If for the same proper rescaling several of these marginals converge in distribution,
it is relevant to ask whether the trees themselves converge in some sense to some
continuous object. Such a limit theorem would have several important implications.
First, if our marginals of interest can be obtained from the tree by a continuous
mapping, then by the continuous mapping theorem, they should converge to the
image of the limiting object by the same mapping (in practice however, it can be
easier to prove the convergence directly than to prove the mapping’s continuity...).
Second, some diﬃcult computations in the ﬁnite case can be smoothened out in
the limiting case, just as solving diﬀerential equations can be simpler than solving

26

27

diﬀerence equations. The limit theorem already provides the scaling, now compu-
tations can provide the constant in front of the scaling. For example the maximal
√
distance achieved by a random walker in n time units scales like
n thanks to
Donsker’s theorem, and when rescaled by
n, it converges in distribution to the
maximum of the reﬂected Brownian motion on [0, 1].

√

Third, exactly as in the case of Donsker’s theorem, we could hope that the limit
theorem is an invariance principle, in the sense that the law of the limiting object
is the same for a wide class of converging random sequences. In practice, this has
the very important consequence that the patterns predicted by the model do not
depend on the details of the model.

It is beyond the scope of these notes to give more details about limit theorems
for random trees, see Le Gall and Miermont (2012). In this chapter, we want to
directly pounce to the continuous objects, only mentioning in passing how they
arise as limits of discrete objects. We end this section recalling some well-known
deﬁnitions in this area. We will then introduce the general framework of real trees
and explain how they can be usefully coded by a real function called the (jumping)
contour process.

2.1.2 Local time
If A is a closed subset of [0,∞), a local time associated to A is a nondecreasing
mapping L : [0,∞) → [0,∞) such that L(0) = 0 and whose points of increase coin-
cide with A. If A is discrete, L can be deﬁned simply, for example as the counting
process Lt = #[0, t] ∩ A. If A is not discrete, the counting process will blow up at
the ﬁrst accumulation point of A, so a diﬀerent strategy is needed.

Assume that A is perfect, i.e., it has empty interior and no isolated point. For any
compact interval, say [0, M ], we can construct a continuous mapping L : [0, M ] →
[0, 1] such that L(0) = 0, L(M ) = 1 and for any 0 ≤ s < t ≤ M

Lt > Ls ⇔ (s, t) ∩ A (cid:54)= ∅.

The construction is recursive, exactly as for the Cantor–Lebesgue function, also
called ‘devil’s staircase’. The reader who already knows this construction may skip
the next paragraph.
First recall that the open set B := (0, M ) \ A can be written as a countable
union of open intervals, say (In)n≥1. Note that for any ε > 0, there can be only
ﬁnitely many of these intervals which have length larger than ε. Therefore, we can

28

assume that the intervals (In) are ranked by decreasing order of their lengths (in
case of equality, in their order of appearance, say). Finally for each n ≥ 1, write
In = (gn, dn).
We are going to construct recursively, for each n ≥ 1, a continuous mapping Ln :
[0, M ] → [0, 1] which is piecewise aﬃne and constant exactly on ∪n
k=1Ik. First, L1 is
the function equal to 1/2 on I1, aﬃne on [0, g1] and on [d1, 1], such that L1(0) = 0
and L1(M ) = 1. Now assume that we are given a continuous function Ln : [0, M ] →
[0, 1] which is piecewise aﬃne and constant exactly on ∪n
k=1Ik. Writing d0 = 0 and
g0 = 1, there is a unique pair 0 ≤ k, j ≤ n such that dj < gn+1 < dn+1 < gk
minimizing gk − dj. Then we can deﬁne Ln+1 as the continuous function equal to
Ln outside (dk, gj), constant to 1
2(Ln(gj)+Ln(dk)) on [gn+1, dn+1], aﬃne on [dj, gn+1]
and on [dn+1, gk]. It is easy to see that Ln+1 satisﬁes the announced properties.
Now for any p ∈ N, let Dp denote the set of dyadic numbers of (0, 1) whose
dyadic expansion has length smaller than p, i.e., Dp = {x ∈ (0, 1) : ∃(x1, . . . , xp) ∈
k=1 xk 2−k}. Also for n ∈ N, let Jn denote the set of values taken
by Ln on its constancy intervals. Because A has no isolated point, for each p ≥ 1
there is an integer N such that for all n ≥ N, Dp ⊂ Jn, so that for any n(cid:48) ≥ N,
(cid:107)Ln − Ln(cid:48)(cid:107) ≤ 2−p, where (cid:107)·(cid:107) is the supremum norm on [0, 1]. This shows that (Ln)
is a Cauchy sequence for the supremum norm, and so converges uniformly on [0, 1]
to a continuous function L. It is not diﬃcult to see, using the stationarity of (Ln)
on B, that L increases exactly on A.

{0, 1} : x =(cid:80)p

In probability, local times are most often used to ‘count’ the visits to a point or
set by a stochastic process, e.g. the visit times of zero by Brownian motion. In
this case, there are alternative ways of constructing the local time which ensure
that it is at the same time adapted and unique up to a multiplicative constant.
This contrasts with the recursive construction given above, where the local time is
measurable, but is certainly neither adapted nor unique.

In the case of the standard Brownian motion B (but also of many other Markov
processes or semi-martingales) there exist several possible such constructions. For
example, if Nε(t) denotes the number of positive excursions of B with height larger
than ε, then a.s. for all t, 2ε Nε(t) converges as ε ↓ 0 to L0
t , which is a local time at
0 for B. Also,

(cid:90) t

0

L0

t = lim
ε↓0

1
2ε

1|Bs|<ε ds,

where the limit again holds a.s. for all t. Even more interestingly, the local times
of B at all levels (not only 0) can be simultaneously constructed in a consistent
manner. Namely, let νt denote the so-called occupation measure of B, that is for

any non-negative Borel function f(cid:90)

f dνt =

R

29

(cid:90) t

0

f (Bs) ds.

for all t, νt has a density (La
Then a.s.
addition, the doubly indexed process (La
t ; t ≥ 0) is a local time for B at level a.
(La

t ; a ∈ R) w.r.t. Lebesgue measure.
In
t ; a ∈ R) is bicontinuous and for each a,

Not the least utility of an adapted local time L (at 0 say) for a stochastic pro-
cess X, is that it provides a way of indexing the excursions of X away from 0 in
their order of appearance. Indeed, if J denotes the inverse J of L, then to each
jump ∆Js of J corresponds an excursion of X away from 0 with length ∆Js, say
es. In particular, if X is a strong Markov process, ((s, ∆Js); s ≥ 0) are the atoms
of a Poisson point process in [0,∞)2. Furthermore, ((s, es); s ≥ 0) are the atoms
of a Poisson point process in [0,∞) × E , where E is the space of paths with ﬁnite
lifetime V visiting 0 at most at 0 and at V . The intensity measure of this Poisson
point process is called Itô’s excursion measure and is the analogue to the common
probability distribution of excursions when the visit times of 0 by X form a discrete
set.

2.2 Deﬁnitions and examples

2.2.1 The real tree
Deﬁnition 2.2.1. A real tree, or R- tree, is a complete metric space satisfying
(A) Uniqueness of geodesics. For any x, y ∈ t, there is a unique isometric map

[0, 1] → t, ψ([0, 1]) =

φx,y : [0, d(x, y)] → t such that φx,y(0) = 0 and φx,y(d(x, y)) = y.

The geodesic φx,y([0, d(x, y)]), also called arc, is denoted(cid:74)x, y(cid:75).
(cid:74)ψ(0), ψ(1)(cid:75).

(B) No loop. For any continuous, injective map ψ :

The root of an R-tree t is a distinguished element of t denoted ρ.

Theorem 2.2.2 (Four points condition). The metric space (t, d) is a real tree if it
is complete, path-connected and satisﬁes for any x1, x2, x3, x4 ∈ t

d(x1, x2) + d(x3, x4) ≤ max [d(x1, x3) + d(x2, x4), d(x1, x4) + d(x2, x3)]

For references on real trees and the paternity of the last theorem, see Dress et al.
(1996) and Duquesne (2006, p.2).
Deﬁnition 2.2.3. For any x ∈ t, the multiplicity, or degree of x denotes the
number of connected components of t \ {x}.

30

• m(x) = 1 : x is called a leaf
• m(x) = 2 : x is an internal vertex
• m(x) ≥ 3 : x is a branching point.

The set of leaves of t is denoted Lf(t) and the set of branching points Br(t). The
skeleton of t is Sk(t) := t \ Lf(t).
Exercise 2.2.4. Prove that for any sequence (xn) dense in the R-tree t,

(cid:91)
n (cid:74)ρ, xn(cid:74).

Sk(t) =

From now on, we will assume that t denotes a binary R-tree, that is,
m(x) ≤ 3 for all x ∈ t. We will also assume that m(ρ) = 1. We will further need
the following notation and terminology.

• Mrca. For any x, y ∈ t the most recent common ancestor (in short mrca) of x

• Partial order. For any x, y ∈ t, y is said to descend from x, and then x is

and y, denoted x ∧ y, is the unique z ∈ t such that(cid:74)ρ, x(cid:75) ∩(cid:74)ρ, y(cid:75) =(cid:74)ρ, z(cid:75).
called an ancestor of y if x ∈(cid:74)ρ, y(cid:75), and this is denoted x (cid:22) y.
that for any x, y ∈ t, (cid:96)((cid:74)x, y(cid:75)) = d(x, y) (see Section 4.3.5 in Evans 2008).

• Lebesgue measure. Whenever t is locally compact, there is a unique measure
(cid:96) on the Borel σ-ﬁeld of t, called Lebesgue measure or length measure, such

• Orientation. For any x ∈ Br(t), t \ {x} has 3 connected components: the
one containing ρ and two others, which are assumed to be labelled as the left
subtree Lx and the right subtree Rx.

2.2.2 First constructive example: Connecting segments
Fix some inﬁnite-dimensional, complete vector space X and let (γn) be a linearly
independent, countable family of X. Then construct a real tree by recursively
connecting segments as follows.

31

1. Start with a segment colinear to γ1;

2. Given a set consisting of the ﬁrst n segments properly connected, draw a
uniform point (according to Lebesgue measure) in this set and glue one of the
extremities of a segment colinear to γn+1 to this point.

3. When all segments are connected, take the closure t of the resulting set.

The (random) set t is obviously path connected and satisﬁes the four points con-
dition. So it is a real tree iﬀ it is complete, which holds iﬀ the sequence ((cid:107)γn(cid:107))
vanishes (see Evans 2008, Lemma 4.33), in which case t is even compact.

2.2.3 Second constructive example: Chronological trees

We start with a well-known coding of discrete, rooted (plane) trees, sometimes
denoted UHN, for Ulam–Harris–Neveu.

Deﬁnition 2.2.5. A (rooted) discrete tree T is a subset of U :=(cid:83)

Nn (ﬁnite
words), with the convention N0 = {∅}, whose elements are called vertices, satisfying
(i) ∅ ∈ T
(ii) if v = uj ∈ T , then u ∈ T
(iii) for any u ∈ T , there is Ku ∈ Z+ ∪ {+∞} such that
uj ∈ T ⇔ j ∈ {1, . . . , Ku}

n∈Z+

The vertex ∅ is called the root of T .

Let us give some further terminology and notation.
• Edge. An edge is any (non-ordered) pair {u, uj} such that u ∈ T , uj ∈ T .
• Partial order. The vertex v is said to descend from u, and then u is called an
ancestor of v if there is a ﬁnite word w such that v = uw, and this is denoted
u (cid:22) v.

• Generation. The number of letters in the word u is called its length, or gener-

ation, and denoted |u|.

• Ancestor. The ancestor of u at generation k is denoted u|k.

32

• Mrca. The most common recent ancestor (mrca) of u and v is

w∈T {|w| : w (cid:22) u, w (cid:22) v}.
• Distance. The graph distance d in T can be written as

u ∧ v := arg max

u, v ∈ T .
• Boundary. We denote by ∂T the boundary of T deﬁned as

d(u, v) = |u| + |v| − 2|u ∧ v|

∂T := {u ∈ NN

: ∀n ∈ N, u|n ∈ T }.

Deﬁnition 2.2.6. Let T be a discrete, rooted tree. Assume that each vertex u ∈ T
is endowed with a date of birth α(u) ∈ [0, +∞), a date of death ω(u) ∈ (α(u), +∞]
and a lifetime duration ζ(u) := ω(u) − α(u), satisfying
(i) α(∅) = 0
(ii) for any u ∈ T , for any j ∈ N,

uj ∈ T ⇒ α(u) < α(uj) ≤ ω(u).

(iii) for any u ∈ ∂T ,

n→∞ ζ(u|n) = 0,

lim

n↑∞ ↑ α(u|n) < ∞ ⇒ lim
{u} × (α(u), ω(u)] ∪ (cid:91)

(cid:91)

u∈T

Then we can deﬁne the chronological tree t as the subset of U := U ×[0,∞] deﬁned
by

n↑∞ ↑ α(u|n)}
The chronological tree is naturally rooted at ρ := (∅, 0). If in addition

{u} × {lim

u∈∂T

t :=

α(ui) (cid:54)= α(uj)

u ∈ T , i (cid:54)= j,

then the tree T is said binary.

We will further need the following notation and terminology. We use (here only)

the notation p2 : U → [0,∞] for the canonical projection p2((u, t)) = t.

• Partial order. The point y = (v, t) ∈ t is said to descend from x = (u, s) ∈ t,
and then x is called an ancestor of y, if either u = v and s ≤ t, or u (cid:54)= v,
u (cid:22) v and s ≤ α(v). This is denoted x (cid:22) y.

33

• Mrca. The most common recent ancestor of x ∈ t and y ∈ t is

x ∧ y := arg max
z∈t

{p2(z) : z (cid:22) x, z (cid:22) y}.

• Distance. We still denote by d the graph distance in t, deﬁned by

d(x, y) = p2(x) + p2(y) − 2p2(x ∧ y)

x, y ∈ t.

Exercise 2.2.7. Prove the following statement.
Theorem 2.2.8. The metric space (t, d) is a locally compact R-tree.

Exercise 2.2.9. Check that the notions of partial order and mrca in the chrono-
logical tree t coincide with the corresponding notions in R-trees. Characterize the
leaves and branching points of t.

Remark 2.2.10. For chronological trees represented in the plane with vertical edges,
there is a natural orientation stemming from the rule that ‘daughters sprout to the
right of their mother’ (see Fig 2.1 and see Lambert 2010 for a rigorous deﬁnition).
We will always assume that chronological trees are endowed with this speciﬁc orien-
tation.

x t

t

z

6

t

y

Figure 2.1: A binary chronological tree, where edges are vertical, time ﬂows upward,
dashed lines represent ﬁliation and daughters sprout to the right of their mother, conferring
a natural orientation to the tree. The three points x, y, z satisfy y (cid:22) x and x ≤ y ≤ z.

2.3 The contour process
2.3.1 From the R-tree to its contour process
Let t be a binary, oriented R-tree.
Deﬁnition 2.3.1. The relation ≤ on t is deﬁned as follows. For any x, y ∈ t,

34

x (cid:22) y ⇒ y ≤ x,

otherwise x ∧ y ∈ Br(t) and(cid:26) x ∈ Lx∧y ⇒ x ≤ y

x ∈ Rx∧y ⇒ y ≤ x.

Exercise 2.3.2. Prove that ≤ is a total order on t, that ρ = max t, and ﬁnd min t
on the example shown in Figure 2.1.
Exercise 2.3.3. Prove that for any x ∈ t,

π(x) := {y ∈ t : y ≤ x}

is a Borel set.

Now we assume that we are given a ﬁnite measure µ on the Borel σ-ﬁeld of t, called
mass measure, satisfying
Mes 1 for any x ≤ y ∈ t,

x (cid:54)= y ⇒ µ(π(x)) < µ(π(y)).

Mes 2 µ is diﬀuse (no atom).

Remark 2.3.4. Whenever (cid:96)(t) < ∞, the length measure (cid:96) is a natural example of
ﬁnite measure which satisﬁes both Mes 1 and Mes 2.
Now deﬁne ϕ : (t,≤, µ) → ([0, µ(t)],≤, Leb) by

ϕ(x) := µ(π(x))

x ∈ t,

which always makes sense, since π(x) is a Borel set of t. It is clear that ϕ is one-to-
one (by Mes 1), preserves the order and the measure. But it is not clear whether
it is onto.

Exercise 2.3.5. Display an example of a real tree that has no minimal element,
and so for which 0 (cid:54)∈ ϕ(t).

35

Lemma 2.3.6. The set D := ϕ(t) is dense in [0, µ(t)].
Proof. Let t ∈ (0, µ(t)). Set Gt := {x ∈ t : ϕ(x) < t} and Dt := {y ∈ t : ϕ(y) ≥ t}.
Also set st := sup{ϕ(x) : x ∈ Gt} and it := inf{ϕ(y) : y ∈ Dt}, so that in particular
st ≤ t ≤ it.
First notice that for any x ∈ Gt, π(x) ⊂ Gt, so that Gt is necessarily of the form
π(x) or π(x) \ {x}, which yields µ(Gt) = st.
Now by deﬁnition of it, there is some ≤-decreasing sequence (yn) of elements
of Dt such that limn ↓ ϕ(yn) = it. Since (yn) is decreasing, the sequence π(yn) is
also decreasing, let L denote its limit. If there were two elements in L \ Gt, say
z1 < z2, we would have t ≤ ϕ(z1) < ϕ(z2) ≤ it by Mes 1. Now this contradicts the
deﬁnition of it, since L\ Gt ⊂ Dt, so L\ Gt contains at most one element. By Mes
2, this shows that µ(L) = µ(Gt). Now recall that µ(Gt) = st, so that
↓ µ(π(yn)) = µ(L) = µ(Gt) = st,

↓ ϕ(yn) = lim

it = lim
n

n

which shows that it = st = t.
In light of the previous lemma, we can deﬁne φ : [0, µ(t)] → t as

φ(t) := lim

s↓t, s∈D

ϕ−1(s),

which we call the exploration process. The existence and the uniqueness of this limit
come from the fact that all monotonic sequences of t do converge (see Lambert and
Uribe Bravo 2016b). Of course, φ does not preserve the order any longer.

Theorem 2.3.7 (Lambert and Uribe Bravo 2016b). The exploration process is
the only càdlàg extension to ϕ−1. The mapping h : [0, µ(t)] → [0,∞) deﬁned by
h(s) := d(ρ, φ(s)) is called the jumping contour process of t. It is càdlàg and has
no negative jumps.

Fig 2.2 shows an example of a real tree and of the jumping contour process of its
truncation below T , when µ is chosen equal to (cid:96). Fig 2.3 shows how to recover a
chronological tree from its contour.

2.3.2 From the contour to the tree
Let h : [0,∞) → [0,∞) be càdlàg with no negative jumps and compact support.
Set σh := sup{t > 0 : h(t) (cid:54)= 0}, as well as

mh(s, t) := inf

[s∧t,s∨t]

h

s, t ≥ 0,

36

a)

6

T

b)

6

T

@

@

@@

@

@

@@

@

@@

@

@

@

@

@

@@

@

@

@

@

-

Figure 2.2: A chronological tree (a) and (b) the jumping contour process of its truncation
below T , where µ is chosen equal to (cid:96).

and

dh(s, t) := h(s) + h(t) − 2mh(s, t).

It is clear that dh is a pseudo-distance on [0,∞). Further let ∼h denote the equiv-
alence relation on [0,∞)

s ∼h t ⇔ dh(s, t) = 0 ⇔ h(s) = h(t) = mh(s, t).

Theorem 2.3.8. Denote by th the quotient space [0, σh]|∼h. Then (th, dh) is a
compact R-tree.

Exercise 2.3.9. Prove the last statement using the four points condition.
From now on, let ph : [0, σh] → th map any element of [0, σh] to its equivalence class
relative to ∼h. We can also endow th with a total order and a mass measure, as
follows.

37

Figure 2.3: The jumping contour process of a chronological tree with ﬁnite length, where
µ is chosen equal to (cid:96): how to recover the tree from the contour. 1) Start with a càdlàg
map with compact support; 2) Draw vertical solid lines in the place of jumps; 3) Report
horizontal dashed lines from each edge bottom left to the rightmost solid point; 4) erase
diagonal lines.

• Total order. We deﬁne ≤h as the order of ﬁrst visits, that is for any x, y ∈ th,

x ≤h y ⇔ inf p−1

h ({x}) ≤ inf p−1

h ({y}).

• Mass measure. The measure µh is deﬁned as the push forward of Lebesgue

measure by ph.

Theorem 2.3.10 (Duquesne 2006; Lambert and Uribe Bravo 2016b). Let (t, d)
be a compact, binary R-tree endowed with an orientation inducing a total order
≤ (as in Deﬁniftion 2.3.1) and with a (ﬁnite) mass measure µ (satisfying Mes 1
and Mes 2). Let h denote the jumping contour process associated with ≤ and µ.
Then h is the unique càdlàg map such that the tree (th, dh,≤h, µh) is isomorphic to
(t, d,≤, µ).

2.3.3 A few words on topology

Real trees are metric spaces. The ‘space’ of real trees only makes sense if one can
imbed all trees into the same metric space, say (X , δ), and if two compact real trees,

1)3)2)4)38
seen as closed subsets of X , are identiﬁed when there is a root-preserving isometry
mapping one tree onto the other.
Rigorously, the space of real trees is then the set of isometry classes of trees which
are closed subsets of X , and it can then be endowed with the usual Hausdorﬀ metric
δH associated with δ (i.e., δH(F1, F2) is the smallest ε such that the ε-enlargement of
Fi is contained in Fj, i (cid:54)= j), called on this occasion the Gromov–Hausdorﬀ distance
and denoted dGH, see e.g., Burago et al. (2001); Paulin (1989).

In other words, this distance is deﬁned for any two R-trees t1 and t2 as

dGH(t1, t2) = inf

fi:ti→X δH(f1(t1), f2(t2)) ∨ δ(f1(ρ1), f2(ρ2)),

where the inﬁmum is taken over all isometries imbedding t1 and t2 into X .
Theorem 2.3.11 (Evans et al. 2005). The Gromov–Hausdorﬀ distance makes the
space of compact real trees a complete, separable space.
Actually, one can avoid resorting to the abstract space X and directly deal with
correspondences between t1 and t2.
Deﬁnition 2.3.12. A correspondence between (t1, d1) and (t2, d2) is a subset R of
t1 × t2 such that

∀x1 ∈ t1 ∃x2 ∈ t2 (x1, x2) ∈ R,
∀y2 ∈ t2 ∃y1 ∈ t1 (y1, y2) ∈ R.

The distortion dis(R) of the correspondence R is deﬁned as

dis(R) = sup{|d1(x1, y1) − d2(x2, y2)| : (x1, x2) ∈ R, (y1, y2) ∈ R}.

Then we have the following useful equality (Burago et al. 2001)

dGH(t1, t2) =

1
2

inf
R

dis(R),

where the inﬁmum is taken over all distortions R between t1 and t2. This equality
has the following consequence (which is a slight improvement of Lemma 2.4 in
Le Gall 2005) .
Proposition 2.3.13. Let h1, h2 : R+ → R+ be two càdlàg functions with compact
support, and let t1 := th1 and t2 := th2 denote the real trees associated with h1 and
h2 respectively. Then

dGH(t1, t2) ≤ 2dS(h1, h2),

where dS denotes the Skorokhod distance.

39

Remark 2.3.14. A very important consequence of this proposition is that whenever
a sequence (Xn) of càdlàg, non-negative stochastic processes with compact support
converges weakly in Skorokhod space to X, the trees coded by Xn converge weakly in
the Gromov–Hausdorﬀ sense to the tree coded by X.

Also note that the separability of the Gromov–Hausdorﬀ tree space stems from

the separability of the Skorokhod space, thanks again to the last statement.
Proof. Let ε > 0 and let λ be a perturbation such that (cid:107)h1◦λ−h2(cid:107) ≤ dS(h1, h2)+ε,
where (cid:107)·(cid:107) denotes the supremum norm. Then let R be the correspondence deﬁned
by

R = {(x1, x2) ∈ t1 × t2 : ∃t ≥ 0, ph1(λ(t)) = x1, ph2(t) = x2}.
Then for any (x1, x2) ∈ R and (y1, y2) ∈ R, there are s, t ≥ 0 such that
x1 = ph1(λ(s)), x2 = ph2(s) and y1 = ph1(λ(t)), y2 = ph2(t).

Now

and

d1(x1, y1) = h1(λ(s)) + h1(λ(t)) − 2mh1(λ(s), λ(t))

d2(x2, y2) = h2(s) + h2(t) − 2mh2(s, t),

so that
|d1(x1, y1) − d2(x2, y2)| ≤ |h1 ◦ λ − h2|(s) + |h1 ◦ λ − h2|(t) + 2| inf

h1 ◦ λ − inf

[s,t]

h2|

[s,t]

≤ 4(cid:107)h1 ◦ λ − h2(cid:107).

Then by deﬁnition of the distortion, dis(R) ≤ 4(cid:107)h1 ◦ λ − h2(cid:107), so the inequality
stated before the proposition yields

dGH(t1, t2) =

1
2

inf
R

dis(R) ≤ 2(cid:107)h1 ◦ λ − h2(cid:107) ≤ 2dS(h1, h2) + 2ε,

which yields the result. Note that we have not needed to control the diﬀerence
between λ and the identity.

2.4 Random R-trees

2.4.1 Splitting trees

Splitting trees (Geiger 1996; Geiger and Kersting 1997; Lambert 2010) are ran-
dom chronological trees satisfying the branching property. More speciﬁcally, let Λ

be a positive measure on (0,∞], called the lifespan measure, such that (cid:82)

40
(0,∞](r ∧
1) Λ(dr) < ∞. A splitting tree is a random chronological tree, where individuals
live and reproduce independently and conditional on the life span (α(u), ω(u)] of a
given individual u, pairs of birth times and lifetimes of the newborns of u form a
Poisson point process on (α(u), ω(u)] × (0,∞] with intensity Leb ⊗ Λ. If Λ is ﬁnite
with mass b = Λ((0,∞]), then individuals give birth at rate b to individuals with
lifetime with distribution b−1 Λ.

Observe that the width process of a splitting tree is not necessarily Markovian.
When Λ is ﬁnite, it is a binary, homogeneous Crump–Mode–Jagers (CMJ) process,
and it is not Markovian unless the lifetime distribution is exponential (or a Dirac
mass at {∞} in the pure-birth case). For modeling purposes, note that splitting
trees with absolutely continuous lifetimes can equivalently be deﬁned via a ‘death
rate’ that can be age-dependent.

Remark 2.4.1. There are two branching processes hidden in a splitting tree other
than its width process. The ﬁrst one is the process tracking the number of indi-
viduals alive at each given (discrete) generation, and the second one is the process
tracking the total sum of lifetimes of individuals of each given generation. Both are
Markovian branching processes in discrete time, the ﬁrst one with integer values (a
Galton–Watson process), and the second one with non-negative real values (a Jirina
process). Note that the Jirina process can take ﬁnite values even when Λ is not
ﬁnite, which is not the case of the Galton–Watson process.

Recall that chronological trees are naturally endowed with the orientation associated
with the rule that ‘daughters sprout to the right of their mother’, so they are given
a natural order ≤ associated with this orientation.

In addition, thanks to our assumption on Λ, the length measure is a.s. locally
ﬁnite. So it is possible to use the length measure to deﬁne the exploration process
and the jumping contour process for the tree truncated under some ﬁxed, ﬁnite
height. The law of the jumping contour process is particularly appealing in this
setting (see also Fig 2.3).
Theorem 2.4.2 (Lambert 2010). Let Xt = Yt− t, where Y is the subordinator with
Lévy measure Λ. Conditional on the lifetime x of the root individual, the jumping
contour process of the splitting tree with lifespan measure Λ truncated below height
a is distributed like the process X started at x, reﬂected below a and killed upon
hitting 0.

41

2.4.2 The continuum random tree

Recall how in Section 2.2.2 we have constructed a (random) real tree t by connecting
together segments colinear to the elements (γn) of a linearly independent family of a
complete vector space X. To deﬁne the Continuum Random Tree (CRT) discovered
by Aldous (1991, 1993), we need the lengths of the segments to be random (X = (cid:96)1
in the original paper).

Deﬁnition 2.4.3. The CRT is the tree t obtained by connecting segments whose
lengths ((cid:107)γn(cid:107)) are distributed as the successive distances between consecutive atoms
of a Poisson point process on the half line with inhomogeneous intensity t dt.

√

Theorem 2.4.4 (Aldous 1991, 1993). Let e stand for the normalized Brownian
excursion, i.e., the positive Brownian excursion conditioned to have lifetime 1. The
R-tree te coded by e is isometric in law to the CRT.
It is standard that the contour process (in some appropriate meaning) of a Galton–
Watson tree with ﬁnite oﬀspring variance conditioned to have n vertices, rescaled by
n, converges weakly in the Skorokhod space to the normalized excursion.
a factor
The results of the last section then imply that the CRT is the scaling limit in
the Gromov–Hausdorﬀ topology of conditioned Galton-Watson trees with ﬁnite
oﬀspring variance (see e.g., Aldous 1993; Le Gall 1993).
Also, since binary trees with n tips have 2n − 1 vertices, binary Galton–Watson
, converge to the tree coded by

trees conditioned to have n tips, which follow P pda
the Brownian excursion with length normalized to 2.

n

This conditioning (on number of vertices or tips) can sometimes be awkward in
some practical situations since it is evanescent in the limit. It can be more con-
venient to consider a forest of n independent critical Galton–Watson trees, whose
contour process (in the same appropriate meaning) is the concatenation of n inde-
pendent contour processes (Le Gall 2005). In the limit, we should get a contour
process which is the concatenation of a ﬁxed amount of excursions. This ﬁxed
amount is measured by the local time at 0 of this process.

Actually, the contour processes of Galton–Watson processes are not in general
Markovian (Duquesne and Le Gall 2002; Le Gall 2005), so it will be more convenient
to display the same kind of result starting with splitting trees, whose contour process
is Markovian, thanks to Theorem 2.4.2. For the sake of generality, we will also allow
the trees to be subcritical (α > 0 in the following statement).

Let ζ > 0. Consider a forest of [Aζ] i.i.d. splitting trees, where A > 0 is a
scaling parameter, characterized by a ﬁnite birth rate bA and a lifetime distribution

42

given by a random variable VA. We make three assumptions.
(H1) bA E(VA) = 1 − α
A

+ o

A

(cid:18) 1

(cid:19)

(cid:1)
A E(cid:0)V 2
A→∞ A bA E(cid:0)V 3

2 E(VA)

A

(H2) lim
A→∞

(H3) lim

= β > 0

A ∧ 1(cid:1) = 0

Remark 2.4.5. Note that if VA is exponentially distributed with parameter dA, then
the assumptions (H1 − H3) hold as soon as dA = A/β = bA + α/β.
Theorem 2.4.6 (Lambert et al. 2013). Let X A denote the jumping contour process
t denote the total number of individuals alive at time t, rescaled
of this forest and Z A
by A. Then the pair (X A, Z A) converges weakly in Skorokhod space.
First, the limit of the sequence (X A) is the process X − X killed when X hits
−ζ, where X t = inf s∈[0,t] Xs, and

Xt = −αt +(cid:112)2βBt,
(cid:115)

dZt = −α
β

Zt dt +

2 Zt
β

dWt.

where B is the standard Brownian motion started at 0. Second, the limit of (Z A)
is a diﬀusion process Z started at Z0 = ζ and solution to an SDE of the form

Note that −X is a local time at 0 for X − X, so the limiting contour process X − X
is indeed killed when its local time hits ζ.

The fact that the width processes Z A converge cannot be deduced from the
convergences of the contours X A, since the local time functional (mapping the tree
to its width process) is not continuous. In this direction, notice that the theorem
does not specify that Z is the local time process of X − X.

Last, the convergence in Skorokhod space of the contours ensures that the split-
ting trees themselves converge in the Gromov–Hausdorﬀ sense to what we could
call Brownian tree, in a wider sense than the CRT (no normalization of the contour
excursion interval, possible subcriticality).
Remark 2.4.7. Actually, the previous theorem only holds if the lifetimes of the
[Aζ] progenitors are (i.i.d. and) distributed as the forward recurrence time V (cid:63)
A of
VA, otherwise the width process is not continuous at 0.

P(V (cid:63)

A ∈ dx) =

P(VA ≥ x)

E(VA)

dx

x > 0.

Note that V (cid:63)

A is distributed like VA if (and only if) VA is exponentially distributed.

43

Chapter 3

Reduced Trees

For a real tree t and a ﬁxed real number T > 0, the so-called reduced tree at height
T is the tree spanned by points at distance T from the root
{y ∈ t : ∃x ∈ t, y (cid:22) x, d(ρ, x) = T}.

It is usually called reconstructed tree in phylogenetics and coalescent tree in popu-
lation genetics. Its topology can be understood from the topology of the sphere of
t with center ρ and radius T > 0

t{T} := {x ∈ t : d(ρ, x) = T},

which will thus be the focus of the present chapter.

3.1 The comb metric

Most of this section is taken from Lambert and Uribe Bravo (2016a).

3.1.1 Deﬁnition and examples
Let I be a compact interval and f : I → R+ such that for any ε > 0, {f ≥ ε} is
ﬁnite.

For any s, t ∈ I, deﬁne ¯df by

¯df (s, t) = 2 sup

(s∧t,s∨t)

f.

It is clear that ¯df is a pseudo-distance on {f = 0}, and more precisely, that it is
ultrametric, in the sense that

¯df (r, t) ≤ max( ¯df (r, s), ¯df (s, t))

r, s, t ∈ I.

44

45
It is a distance on {f = 0} whenever {f (cid:54)= 0} is dense in I for the usual distance.
This may not be the case in general, so we need to consider ˙I the quotient space
{f = 0}|∼ where ∼ is the equivalence relation

s ∼ t ⇔ ¯df (s, t) = 0 ⇔ f = 0 on [s ∧ t, s ∨ t].

Deﬁnition 3.1.1. We call f a comb-like function or comb, and ¯df the comb metric
on ˙I.
Let us give the canonical example of a comb. Let t be an oriented R-tree with ﬁnite
length, total order ≤ and jumping contour process h associated (for example) with
its length measure (i.e., the mass measure µ is taken equal to the length measure
(cid:96)). Let T > 0 such that the sphere

t{T} = {x ∈ t : d(ρ, x) = T}

has ﬁnite cardinality NT ≥ 2. Let x1 ≤ ··· ≤ xNT denote its elements labelled in
the order ≤. Then for any 1 ≤ i < j ≤ NT , writing si := inf p−1
h ({xi}) (each set
h ({x}) is actually a singleton in the case when the sphere is ﬁnite),
p−1

d(xi, xj) = h(si) + h(sj) − 2 inf

[si,sj ]

h = 2(T − inf

[si,sj ]

h) = 2 max(hi, . . . , hj−1),

where

hi := T − inf

[si,si+1]

h.

I = [1, NT ] and f :=(cid:80)NT −1

In conclusion, the metric on t{T} is isomorphic to the comb metric ¯df on ˙I, where
i=1 hi1{i}. We will extend this description to all locally

compact R-trees in Section 3.1.2.

Fig 3.1 shows a comb and how an ultrametric tree can be embedded into it. As
˙I to
in Fig 3.2 the same metric space can be represented by identifying points of
their left-neighbour in I \ ˙I (or to their right-neighbour) and reporting the distances
accordingly.

Remark 3.1.2. The space ( ˙I, ¯df ) is not complete in general. To make it complete,
one has to distinguish for each point t ∈ I between its left face (t, l) and its right
face (t, r). The distance ¯df is extended to the space I × {l, r} by the following
deﬁnitions for s < t ∈ I

¯df ((s, r), (t, l)) = 2 sup

f,

¯df ((s, l), (t, l)) = 2 sup

f,

(s,t)

[s,t)

46

Figure 3.1: a) A comb-like function with ﬁnite support on [0, 1]. The distance between
the black dot and the grey dot is h(cid:48), whereas h is the distance from either of these dots
to the white dot; b) In dashed lines, the ultrametric tree associated to the comb shown in
a).

¯df ((s, r), (t, r)) = 2 sup

f,

¯df ((s, l), (t, r)) = 2 sup

f,

(s,t]

[s,t]

and the symmetrized deﬁnitions for s > t. If s = t, the four last quantities are
respectively deﬁned as f (t), 0, 0, f (t). This extension of ¯df is a pseudo-distance
and it can be shown (Lambert and Uribe Bravo, 2016a) that the associated quotient
space ¯I is a compact, ultrametric space called comb metric space. Actually the
converse is also true, as states the next theorem.
Theorem 3.1.3 (Lambert and Uribe Bravo 2016a). Any compact ultrametric space
is isometric to a comb metric space.

3.1.2 Spheres of R-trees
Here, we consider a locally compact R-tree t and we assume that the sphere

t{T} = {x ∈ t : d(ρ, x) = T}

hha)b)h'h'010147

Figure 3.2: a) A comb with ﬁnite support, and the associated ultrametric tree in dashed
lines; equivalent representations of this ultrametric space can be obtained by reporting all
tips of the comb to the left (b) or to the right (c).

is not empty. Note that by the four-points condition, for any x, y, z ∈ t{T},

T + d(x, z) =

d(ρ, y) + d(x, z) ≤ max [d(ρ, x) + d(y, z), d(ρ, z) + d(y, x)]

= max [T + d(y, z), T + d(y, x)] ,
which yields d(x, z) ≤ max [d(y, z), d(y, x)], that is the metric induced by d on t{T}
is ultrametric.

Since t is locally compact, t{T} is a compact ultrametric space and Theorem
3.1.3 ensures that provided it has no isolated point, it is isometric to a comb metric
space. There is actually an isometry with a comb metric space preserving the order
on t{T} inherited from the order ≤ on t. Let h denote the jumping contour process
of the tree truncated at height T , which is the closed ball with center ρ and radius
T .
Exercise 3.1.4. Assume that t{T} has no isolated point. Prove that {h = T} has
no isolated point and empty interior. Also prove that t{T} has empty interior.

Recall from the paragraph p.27 on local time, that since {h = T} is perfect, we
can construct a local time at level T for h, that is a nondecreasing, continuous map
LT : [0,∞) → [0,∞) such that LT (0) = 0 and for any s < t
s ⇔ (s, t) ∩ {h = T} (cid:54)= ∅.

t > LT

LT

Let I = [0, LT
σh

], and set

48

↑ x+

n = lim
n

↓ x−

n = x},

n

˙t{T} := {x ∈ t{T} : ∃(x+

n ) ↑, (x−

n ) ↓∈ t{T}, lim

where the sequences in the previous deﬁnition are requested to be strictly mono-
tonic.

Theorem 3.1.5 (Lambert and Uribe Bravo 2016a). Assume as previously that t is
a locally compact R-tree such that t{T} is not empty and has no isolated point. Then
there is a comb-like function f on I and two global isometries ˙θ : ( ˙I, ¯df ) → ( ˙t{T}, d)
and ¯θ : ( ¯I, ¯df ) → (t{T}, d) preserving the order and mapping the Lebesgue measure
to the push forward µT of the measure dLT by ph.

3.2 Coalescent Point Processes

3.2.1 The reduced tree of splitting trees, of the Brownian tree

Consider a splitting tree t with lifespan measure Λ satisfying(cid:82)

(0,∞](r∧1) Λ(dr) < ∞.
We have seen in the last chapter that t is an oriented R-tree naturally endowed with
the associated total order ≤, and that it has locally ﬁnite length. Taking the mass
measure equal to the length measure (cid:96), the jumping contour process X of the tree
t truncated below T is well-deﬁned and thanks to Theorem 2.4.2, it has the law
of the process (Yt − t; t ≥ 0), where Y is the subordinator with Lévy measure Λ,
reﬂected below T and killed upon hitting 0.
So t falls under the category of canonical examples given after Deﬁnition 3.1.1
and conditional on NT ≥ 1 (where NT = #t{T}), it is isometric to the comb metric

space ( ˙I, ¯df ), where I = [1, NT ] and f :=(cid:80)NT −1

i=1 Hi1{i}, with

Hi := T − inf

[σi,σi+1]

X,

and σi is the i-th visit of T by X.
Note that Px(NT (cid:54)= 0) = Px(τ +

T < τ0), where the subscript x records the lifetime
of the progenitor, which is also the starting point of the contour process, and τ +
z
(resp. τy) denotes the ﬁrst hitting time by X of [z, +∞) (resp. of {y}).
Also note, thanks to the strong Markov property of X, that conditional on
NT ≥ 1, NT is geometric with failure probability PT (τ +
T > τ0). Furthermore,
conditional on NT = n, the Hi’s are n i.i.d. random variables, all distributed as the
depth of the excursion of X away from T conditioned to be smaller than T . It is
then elementary to get the following result.

comb(cid:80)

Proposition 3.2.1. The sphere tT of the splitting tree t is non empty with proba-
bility Px(τ +
T < τ0). Conditional on being non-empty, it is isometric to the random
i≥1 Hi1{i}, where the Hi’s form a sequence of i.i.d. random variables killed

at its ﬁrst value larger than T , and whose common distribution is given by

49

P(H1 > t) = PT (τT−t < τ +
T ).

(3.1)

We say that t{T} is (isometric to) a coalescent point process (CPP).
Fig 3.3 shows a coalescent point process and how it codes for an ultrametric tree.
By extension, we make the following deﬁnition.

6

T

1

2

3

4

5

6

H1

?

H3

?

H2

?

H4
?

H6
?

H5

?

Figure 3.3: A coalescent point process (upside down compared to previous pictures of
combs) with 6 nonzero values (the 7th one is the ﬁrst one larger than T ). To recover
an oriented ultrametric tree with 7 tips, draw horizontal lines from each tip left to the
rightmost solid point.
Deﬁnition 3.2.2. Let ν be a σ-ﬁnite measure on (0,∞) such that ν([ε,∞)) < ∞
for all ε > 0. Let M be a Poisson point process on (0,∞)2 with intensity Leb ⊗ ν
and denote by (Si, Hi)i its atoms. Finally, let (D, H) denote the ﬁrst atom (in the
ﬁrst dimension) such that H > T . We will say that the random comb metric space
i:Si<D Hi1{Si} is a coalescent point process with height

associated with the comb (cid:80)

T and intensity measure ν.
The term ‘coalescent point process’ has ﬁrst been coined in the setting of the Brow-
nian tree by Popovic (2004). Recall that we called Brownian tree the tree coded by
a positive Brownian excursion (CRT when the excursion length is normalized).

50

The Brownian excursion has a local time at level T , which allows one to construct
as in Theorem 3.1.5 the comb giving the metric of the reduced tree at level T . This
comb is a ‘list’, in the plane order, of the depths of excursions of the contour away
from T .

Theorem 3.2.3 (Popovic 2004; Aldous and Popovic 2005). Conditional on being
non-empty, the sphere t{T} of the Brownian tree t is a coalescent point process with
height T and intensity measure ν, where ν is the push forward of the Brownian
excursion measure by the depth mapping, i.e.

ν0(dh) =

dx
2x2

(3.2)

More generally, as a follow up to Theorem 2.4.6, it can be shown that under suitable
scaling, the coalescent point processes of (sub)critical splitting trees conditioned on
reaching height T converge to the Poisson point process of excursion depths of a
Brownian motion (with negative drift).

then the point processes(cid:80)

More speciﬁcally, under the assumptions (H1–H3) of Theorem 2.4.6, if H A

1 , H A
2 , . . .
denote the coalescence times of the splitting tree conditioned on reaching height T ,
i ) converge as A → ∞ to a CPP with height T

i≥1 δ( i

A ,H A

and intensity measure ν, where

να((x,∞)) =

α

1 − e−αx/β .

(3.3)

Formulae (3.1), (3.2) and (3.3) can actually all be rephrased in terms of the scale
function W of the relevant contour process, as we will now see. We refer the reader
to Bertoin (1996); Kyprianou (2006) for more information about what follows.

Recall that a Lévy process X with no negative jumps is characterized by the

Laplace transform of its one-dimensional marginals
E(exp(−λXt)) = exp(tψ(λ))
where ψ is called the Laplace exponent of X.
subordinator with Lévy measure Λ), the Lévy–Khinchin formula gives

t, λ ≥ 0,

If Xt = Yt − t (where Y is the

(cid:90)

(cid:0)1 − e−λr(cid:1) Λ(dr)

λ ≥ 0.

ψ(λ) = λ −

(0,∞]

If Xt = −αt +

√

2βBt, then ψ(λ) = αλ + βλ2.

Notice that ψ(0) = 0, that ψ is convex and has at most one positive root,
denoted η. Then there is a unique non-negative, increasing function W called the

51

(3.4)

1

ψ(λ)

λ ≥ η.

2βBt, it is not diﬃcult to compute W (x) = x/β

W (x) =

1 − e−αx/β

α

(cid:26)(cid:90) x

x ≥ 0.

(cid:27)

(3.5)

x ≥ 0,

scale function such that(cid:90) ∞

W (x) e−λx dx =

0

In the case when Xt = −αt +
when α = 0 and when α (cid:54)= 0,

√

In general, one can prove (see Bertoin 1996) that

W (x) = exp

N (sup > s) ds

0

where N is the excursion measure of X − X away from 0. When X has ﬁnite
variation, like when Xt = Yt − t, N is merely the birth rate b = Λ((0,∞)) times the
law of X started from a random jump with law b−1Λ.
process of excursions of X − X away from 0 that

In all cases, it is a consequence of the exponential formula for the Poisson point

Px(τ0 < τ +

a ) =

W (a − x)

W (a)

0 ≤ x ≤ a.

(3.6)

In the cases with inﬁnite variation, such as Brownian motion (with or without drift),
W (0) = 0 and

N (− inf > x) =

1

x ≥ 0,

W (x)

(3.7)

where N is the excursion measure of X away from a(ny) point, so that Eqs (3.2) and
(3.3) are a consequence of (3.5) and (3.7). In the case when Xt = Yt − t, W (0) = 1,
and we can be more accurate in Eq (3.1) using Eq (3.6)

P(H1 > t) = PT (τT−t < τ +

T ) =

1

W (t)

,

where W can be identiﬁed inverting the Laplace transform (3.4).

Remark 3.2.4. In Lambert and Popovic (2013), we have expressed the distribution
of the coalescent point process of non binary branching trees, including Galton–
Watson processes and continuous-state branching processes. One of the main dif-
ﬁculties is to cope with the existence of points with arbitrarily large degree in the
tree.

52

3.2.2 A more general class of models

In this section, we seek to investigate population processes which generate trees
whose spheres are (isometric to) CPPs.

Consider a population where all individuals live and reproduce independently,
and each individual is endowed with a trait (some random character living in R
for simplicity) that evolves through time according to independent copies of the
same, possibly time-inhomogeneous, Markov process K with generator Lt = L(t,·).
Further assume what follows.

• This trait is non-heritable, in the sense that any individual born at time t draws
the value of her trait at birth from the same distribution νt, independently of
her mother’s history;

• All individuals give birth at the same, possibly time-inhomogeneous rate b(t);
• An individual holding trait x at time t dies at rate d(t, x).

Theorem 3.2.5 (Lambert and Stadler 2013). Under the previously deﬁned model,
starting with one individual at time 0 and conditional on having at least one alive
individual at time T , the reduced genealogical tree at level T is given by a coalescent
point process with typical depth H whose inverse tail distribution is given by

W (t) :=

1

P(H > t)

= exp

b(s) (1 − q(s)) ds

t ∈ [0, T ],

(cid:18)(cid:90) T

T−t

(cid:19)

(cid:19)

where q(t) denotes the probability that an individual born at time t has no descen-
dants alive by time T .

We will see later why the function W deﬁned in the previous statement becomes
the scale function of the last section when there is no time-inhomogeneity and the
inheritable trait is the age.
In addition, W can be computed from the knowledge of g, where g(t,·) denotes

the density of the death time of an individual born at time t.

Proposition 3.2.6 (Lambert and Stadler 2013). The function W is solution to the
following integro-diﬀerential equation

W (cid:48)(t) = b(T − t)

W (t) −

W (s) g(T − t, T − s)ds

t ≥ 0,

(3.8)

(cid:18)

(cid:90) t

with initial condition W (0) = 1.

0

53

Proof. First observe that

q(t) =

(cid:90) T

t

Recalling that

we get

or equivalently

Now check that

W (t) =

1

P(H > t)

(cid:90) T
(cid:90) t

t

0

q(t) =

q(T − t) =

g(t, s) e−(cid:82) s
(cid:18)(cid:90) T

= exp

T−t

t b(u) (1−q(u))duds.

(cid:19)

b(s) (1 − q(s)) ds

,

g(t, s)

W (T − s)
W (T − t)

ds,

g(T − t, T − s)

W (s)
W (t)

ds.

W (cid:48)(t) = b(T − t) (1 − q(T − t)) W (t).

Equation (3.8) is a consequence of the last two equations.

Remark 3.2.7. In general, g is not given directly in terms of the model ingredients
b, d and the generator Lt of the trait process K. To compute g and then W , one can
proceed as follows. Recall that g(t,·) is the density of the death time of an individual
born at time t, so that

g(t, s) =

νt(dx) us(t, x)

s ≥ t,

(cid:90)
(cid:16)

R

where us(t, x) is that density conditional on the value x of the trait at birth (Kt = x),
that is,

us(t, x) := Et,x

(3.9)
where Et,x denotes the expectation associated to the distribution of K started at time
t in state x. Now the Feynman-Kac formula ensures that us is solution to

d(s, Ks) e−(cid:82) s

s ≥ t,

t d(r,Kr)dr(cid:17)

∂us
∂t

(t, x) + Ltus(t, x) = d(t, x) us(t, x),

(3.10)

with terminal condition us(s, x) = d(s, x). Speciﬁcally, when K is the age, the
initial trait value is x = 0 and the age at s of a species born at t is Ks = s − t so
that

g(t, s) = d(s, s − t) e−(cid:82) s

t d(r,r−t)dr

s ≥ t.

(3.11)

54
Proof of Theorem 3.2.5. Let n ≥ 1 be an integer, and let h1, . . . , hn−1 be elements
of (0, T ). Assume NT ≥ n, and condition on Hi = hi for i = 1, . . . , n − 1. We are
going to prove that the conditional law of Hn is given by

P(Hn > t) = exp

b(s) (1 − q(s)) ds

t ∈ [0, T ],

(3.12)

(cid:19)

(cid:18)

−

(cid:90) T

T−t

which will show that Hn is independent of H1, . . . , Hn−1 and has W as inverse tail
distribution. This result yields the theorem by induction. Note that conditonal on
NT ≥ n, NT exactly equals n iﬀ Hn > T .
Label by 0, 1, . . . , n − 1 the individuals alive at time T in the order induced
by the plane orientation of the tree, where daughters sprout to the right of their
mother. In particular, hi is the coalescence time between individuals i − 1 and i
(1 ≤ i ≤ n − 1).
We denote by k the number of generations separating individuals n− 1 from the
progenitor. We let xk denote the time when individual n − 1 was born, xk−1 < xk
the time when her mother was born, and so on, until x0 = 0 the birth time of the
progenitor. By the orientation of the tree, there are (conditionally) deterministic
indices 0 = i0 < ··· < ik = n − 1, such that xj = T − hij (and hv < hij for all
v ∈ {ij−1 + 1, . . . , ij − 1}), so that conditional on Hi = hi for i = 1, . . . , n − 1, the
times x0, . . . , xk are deterministic.

By the orientation of the tree again, apart from the individuals already labelled,
individuals alive at T descend from births occurring during one of the time intervals
Ij := [xj, xj+1), where xk+1 := T for convenience. On each of these time intervals,
births occur at rate b(t), and so by thinning, successful births, i.e., births with alive
descendance at time T , occur at rate b(t) (1− q(t)). But conditional on the (xj), all
the ancestors of individual n − 1 (including her) independently give birth on their
corresponding interval Ij. Then if A denotes any subset of [0, T ), the number N (A)
of successful births occurring during A is the sum

k(cid:88)

N (A) =

N (A ∩ Ij),

random variable with parameter(cid:82)

where the random numbers N (A∩ Ij) are independent. Now N (A∩ Ij) is a Poisson
b(t) (1 − q(t)) dt. As a consequence, N (A) is

j=0

A∩Ij

a Poisson random variable with parameter

(cid:90)

k(cid:88)

A∩Ij

j=0

(cid:90)

A

b(t) (1 − q(t)) dt =

b(t) (1 − q(t)) dt.

55
The proof ﬁnishes noticing that Hn > t iﬀ N ([T − t, T )) = 0, which occurs with the
probability stated in (3.12).

Exercise 3.2.8. When there is no trait dependence of the death rate, the process
is merely a time-inhomogeneous birth–death process. Prove that in this case W is
given by

(cid:90) T

T−t

(cid:82) T

W (t) = 1 +

b(s) e

s r(u)du ds,

where r(t) := b(t) − d(t). In particular, when rates do not depend on time, the
process is a linear birth–death process with birth rate b and death rate d. The last
formula then boils down to

(cid:40)

(cid:0)ert − 1(cid:1)

W (t) =

1 + b
r
1 + bt

if r (cid:54)= 0
if r = 0.

(3.13)

Fig 3.4 shows the density W (cid:48)/W 2 (recall W (t) = 1/P(H ≥ t)) of coalescence times
in the pure-birth case (d = 0) and in the critical case (b = d).

Exercise 3.2.9. When there is no time-dependence of the birth and death rates,
and the trait is chosen to be the age, we are back to the splitting tree model. Here,
g(t, s) ≡ g(s − t) and Λ(dr) = b g(r) dr. First prove thanks to (3.8) that

W (cid:48) = b (W − W (cid:63) g) ,

and then recover that the Laplace transform of W indeed is 1/ψ (as in Eq 3.4),

(cid:0)1 − e−λr(cid:1) g(r) (dr).
where here ψ can be written as ψ(λ) = λ − b(cid:82) ∞
a 2D integro-diﬀerential equation (Eq 3.14 along with W (t) =(cid:82) t

In passing, Eq (3.14) oﬀers to compute the pair (W, W (cid:48)) by solving numerically
0 W (cid:48)(s) ds) instead

of inverting the Laplace transform of W , which can be computationally tricky.

0

(3.14)

Exercise 3.2.10. Prove that the shape of an ultrametric tree associated with a
coalescent point process conditioned to have n tips is always P erm

.

n

3.3 Applications

In this section, we wish to give a taste of some recent applications of contour pro-
cesses and coalescent point processes in evolutionary biology and in epidemiology.
They rely in particular on the property that the density (or likelihood) of a given
ultrametric tree t with age T and node depths (hi), seen as the reduced tree of a

56

Figure 3.4: The common density function f = W (cid:48)/W 2 of the node depths of the reduced
tree for a birth–death process with constant rates b and d. In blue, the pure birth case
f (t) = b e−bt (b = 0.1 in the ﬁgure); in red, the critical case f (t) = bt/(1+bt)2 (b = d = 0.1
in the ﬁgure). The critical process gives a density with a faster decay initially, but has a
heavier tail than for the pure-birth model. This ﬁgure is taken from Lambert and Steel
(2013).

tree generated under one of the models displayed in the last section, is in product
form

(cid:89)

L (t) = p(T )

f (hi),

where p and f have to be computed in terms of the model ingredients, in particular
f = W (cid:48)/W 2 is the density of a random node depth.

i

3.3.1 Bottlenecks and missing tips
Let t be a rooted R-tree interpreted as the genealogy of some population. We
want to model the fact that at some ﬁxed time point t, a macroscopic proportion
say p of the population, is killed (and its entire descendance as well of course).
In population genetics, such events are called bottlenecks, whereas in phylogenetics
they model mass extinctions. When t = T is present time, this procedure is meant

57

to model incomplete sampling (or contemporary extinctions, see next section).

There are two reduced trees to consider, the reduced tree ex ante, spanned by
individuals alive at time T in the absence of bottleneck, and the reduced tree ex post,
spanned by individuals alive even in the presence of the bottleneck. The second one
is of course included in the ﬁrst one.

Note that the reduced tree ex post is not aﬀected by lineages that do not even
make it to the present in the absence of bottleneck, so we can equally assume that
the bottleneck is only applied to the reduced tree ex ante. See Fig 3.5.

As soon as the reduced tree is compact it is a comb metric space, and if t < T
we can model the bottleneck by simply disconnecting each lineage of the reduced
tree ex ante at distance t from the root, independently with probability p. The
next statement ensures that this operation preserves the CPP property.

Proposition 3.3.1 (Lambert and Stadler 2013). Start with a CPP with inverse
tail distribution W . Add bottlenecks with survival probabilities ε1, . . . , εk at times
T − s1 > . . . > T − sk (where s1 > 0 and sk < T ). Then conditional on survival, the
reduced tree ex post is again a coalescent point process, with inverse tail distribution
Wε given by

Wε(t) = ε1 ··· εm W (t) +

(1− εj) ε1 ··· εj−1 W (sj)

t ∈ [sm, sm+1], 0 ≤ m ≤ k,
(3.15)

m(cid:88)

j=1

m(cid:88)

where s0 := 0 and sk+1 = T (empty sum is zero, empty product is 1).
In the case of a ﬁnite number of tips, this formula can also include sampling with
probability p by adding a bottleneck with s0 = 0 and ε0 = p, resulting in

Wε(t) = ε0 ··· εm W (t) +

(1 − εj) ε0 ··· εj−1 W (sj)

t ∈ [sm, sm+1], 0 ≤ m ≤ k,

j=0

which boils down to Wε = 1 − p + pW when k = 0 (since W (0) = 1).
Proof. We characterize the eﬀect of one bottleneck on a CPP with ﬁnitely many
individuals at height T .
Assume k = 1 and s1 ∈ (0, T ). Recall that a CPP is deﬁned thanks to a
sequence of independent, identically distributed random variables (Hi). We will see
that the tree obtained after thinning is still a coalescent point process, deﬁned from
independent random variables, say (Bi). Let (ei) be the i.i.d. Bernoulli random
variables deﬁned by ei = 1 if lineage i survives the bottleneck (this has a meaning
only if Hi ≥ s1; it happens with probability ε1). By the orientation of the tree, a tip

58

1

6

u

a)

T

T − t

b)

T

T − t

u

3

3

2

e

2

e

7

8

5

4

u

6

u

u

u

10

11

10

11

9

e

9

e

Figure 3.5: Bottleneck at time point T − t, black dots disconnect lineages. a) Coalescent
point process ex ante, in the absence of bottleneck; b) Reduced tree ex post, after passage
of the bottleneck.

terminating a pendant edge with depth smaller than s1 is kept alive iﬀ the rightmost
pending edge on its left with depth larger than s1 survives. As a consequence, if
H1 < s1, then the ﬁrst lineage is trivially still alive and its coalescence time with
the left-hand ancestral lineage is B := H1. Otherwise, deﬁne 1 = J1 < J2 < ···
the indices of consecutive edges with depths larger than s1. Then the ﬁrst lineage
kept alive after thinning is the least Jm such that eJm = 1, and its coalescence
time with the ancestral lineage is B := max(HJ1, . . . , HJm). By the independence
property of coalescent point processes and by the independence of the Bernoulli
random variables (ei), the new genealogy is obtained by a sequence of independent
random variables (Bi) all distributed as B.
Let us specify the law of B. First, with probability P (H < s1), P (B ∈ ·) =

59

P (H ∈ · | H < s1). Second, with probability P (H ≥ s1)

(d)

= max{A1, . . . , AM},

B

where the Ai’s are i.i.d. distributed as H conditional on H ≥ s1 and M is an
independent (modiﬁed) geometric random variable, that is, P (M = j) = ε1(1 −
ε1)j−1. Then for any s ≥ s1

1

P (B ≥ s)

=

1 − ε1

P (H ≥ s1)

+

ε1

P (H ≥ s)

s ≥ s1.

Then if Wε denotes the inverse tail distribution of B, i.e., Wε(s) := 1/P (B ≥ s),
we have

(cid:40)

Wε(s) =

W (s)
(1 − ε1)W (s1) + ε1W (s)

if 0 ≤ s ≤ s1
if s1 ≤ s ≤ t,

where W is the inverse tail distribution of H. Iterating this procedure yields the
result in Proposition 3.3.1.

3.3.2 Loss of phylogenetic diversity

In the context of the contemporary crisis of biodiversity, conservation biologists have
proposed to quantify the loss of evolutionary heritage by the sum of branch lengths
that disappear from the Tree of Life as new extinctions occur, that is, evolutionary
heritage of a clade is quantiﬁed by the sum of its branch lengths, called phylogenetic
diversity (PD). Then a natural question to ask is the following. If a random, say
10% of species from some given clade were to disappear in the next 100 years due
to current high rates of extinction, how much evolutionary heritage would be lost?
‘Not so much’, asserted Nee and May (1997) in a very much debated paper,
where the tree of life was modeled by Kingman coalescent.
‘A lot more’, replied
Mooers et al. (2012), in a paper where the tree of life was modeled by a Yule tree.
In Lambert and Steel (2013), we generalized their calculations to the case of
a splitting tree with age T and typical node depth H, where tips (contemporary
species) are eliminated independently with probability 1−p (‘ﬁeld of bullets’ model).
Let G denote a geometric random variable with success probability p, let (Ai) be a
sequence of independent copies of H conditioned on H ≤ T and set

B := max
i=1,...,G

Ai,

that is B is the typical node depth of the tree after passage of the ﬁeld of bullets
(see previous paragraph on bottlenecks).

Conditional on the number of tips n of the tree ex ante and on the number kn of
the tree ex post, as n → ∞ and kn/n → p, elementary SLLN-type arguments show
that the ratio of the remaining PD to the old PD converges a.s. to

60

πT (p) = p

E(B)
E(A)

The ratio of remaining to old PD is always above the identity, corresponding to
the case when the tree is star-like. This obviously holds also for πT . In addition,
it is not diﬃcult to see that πT is always a concave, increasing function such that
πT (0) = 0 and πT (1) = 1.

Figure 3.6: Remaining fraction π∞ of phylogenetic diversity (PD) as a function of the
probability p of species survival to the mass extinction, for a constant-rate birth–death
process. Observe the slow progression towards the unit step function (from pure birth to
critical): d/b = 0 (the lowest curve) and then d/b = 0.5, 0.9, 0.99, 0.999. This ﬁgure is
taken from Lambert and Steel (2013).

If we take T = ∞, we get

π∞(p) = p

61

(cid:82) ∞
(cid:82) ∞

0

dt

1−p+pW (t)

dt

0

W (t)

In the case of a birth–death tree with rates b and d, with r := b − d > 0, we get



π∞(p) =

ln(bp/r)
ln(b/r) ,

dp
bp−r
− p ln(p)
1−p ,
− 1−p
ln(p) ,

if b > r (cid:54)= bp;
if b = r > bp;
if b > r = bp.

Fig 3.6 shows the graph of π∞ for a range of birth and death rates b > d. Note that
the more concave the better for evolutionary heritage. Also the larger d/b < 1, the
larger the remaining fraction of phylogenetic diversity, converging, but very slowly,
to 1 as d/b → 1.

3.3.3 Do species age?

In Lambert et al. (2014a), we have developed a framework to test the assumption
that the extinction rate of a species remains constant all the way through its life-
time. Speciﬁcally, we have applied a maximal likelihood procedure to the recently
published bird phylogeny (Jetz et al. 2012), to infer the lifetime distribution of
bird species, assuming they are Gamma distributed. We tested the assumption
that the shape parameter k of the Gamma r.v. equals 1 (exponential lifetimes, i.e.,
age-independent extinction rate) vs k (cid:54)= 1 (age-dependence). This study general-
izes previous works on the inference of diversiﬁcation processes from reconstructed
phylogenies (e.g., Nee et al. 1994; Nee 2006; Stadler 2011).

Our estimate of k is much larger than 1, indicating that the extinction rate is
not constant (p < 10−15) but increases with age. For the record, our estimate of
the speciation rate is 0.11 M y−1 and our estimate of the mean species lifetime is
15 M y.

3.3.4 How long does speciation take?

In most models of diversiﬁcation, like the previous one, species are seen as particles
that split instantaneously into two daughter species upon speciation. It is obvious
that on the contrary speciation takes time, but the last assumption would still be
relevant if the time speciation takes was negligible compared to a species lifetime.
There is evidence that this is not the case, and some authors have recently proposed

62

an alternative model of diversiﬁcation, called protracted speciation, meant to take
this eﬀect into account.

In this model, a species is described as an ensemble of populations, and as time
passes, these populations diverge (genetically) gradually from each other. To not
have to record all (phylo)genetic distances between all populations composing each
species, Etienne and Rosindell (2012) have proposed a model where each population
passes through k diﬀerent stages of maturation, after which it becomes a so-called
good species. This model produces quite realistic patterns in terms of phylogenetic
balance and branching tempo, but an inference framework was missing.

Since speciation stage is a non-heritable trait, Theorem 3.2.5 ensures that if
speciation rate does not depend on speciation stage, the phylogeny produced by
this model is a CPP. In Lambert et al. (2014b), we have characterized the common
distribution of node depths in this CPP.

In Etienne et al. (2014) we have developed an inference framework that we tested
against 46 bird clades. Individual parameters are diﬃcult to infer, but the method
is relatively good at inferring a composite parameter of interest, the duration of
speciation. The duration of speciation is deﬁned as the time it takes for a novel
population to have its ﬁrst descending good species. The results are shown in Fig
3.7.

Figure 3.7: Duration of speciation (in My). Distribution inferred from 46 bird clades,
ranging from 10,000 years to 10 My. This ﬁgure is taken from Etienne et al. (2014).

63

3.3.5 Trees with random marks

In this section, trees are endowed with marks to model sampling, detection or
mutation.

The phylogeny of pathogens

In this paragraph, we focus on a population of patients carrying or not an infectious
disease. We stick to the framework of splitting trees, where a birth is a transmission
event and a death is either a real death or the end of the infectious period (exit
from the infective population). The branching property assumption holds in the
case of a well-mixed population where susceptibles are always in excess.

Our setting where lifetime distributions are not exponential is most attractive
for diseases like ﬂu or HIV, where the infectious period is known to be either de-
terministic (ﬂu) or heavy-tailed (HIV).

In addition, we assume that patients are detected to be infective after some
random time D, at which they are tagged by a mark (see ﬁgures). Upon detection
(if D is smaller than the infectious period/lifetime), the patients are assumed to
exit the infective population, because either they change their behaviour to avoid
transmission or they are treated and become non-infectious.

In Lambert et al. (2014a), we have considered the case where the transmis-
sion tree spanned by detected patients has been reconstructed, similarly as Stadler
(2010). Actually, the data is not directly the transmission tree but the phylogenetic
tree of the pathogens carried by patients, reconstructed thanks to biological sam-
ples taken from the patients upon detection. Fig 3.8 shows the oriented tree of the
epidemic, with black dots showing detection events, along with its reduced tree and
contour process. Patients can be labelled in the plane order, so we can deﬁne Si
the detection time of patient i and Ri the coalescence time between patients i − 1
and i.

By considering the jumping contour process of the epidemics, we have shown
that the sequence (Si, Ri) is a killed Markov chain. The likelihood of a tree t with
coalescence times (xi)2≤i≤n and detection times (yi)1≤i≤n can be written in the form

n(cid:89)

L (t) = g(y1) k(yn)

f (yi−1; xi, yi),

where g, k and f can be semi-explicitly expressed in terms of the model ingredients
(law of infectious lifetimes, transmission rate, detection rate).

i=2

1

u

6

S1

a)

u

6

S2

2

6

R2

?

?

?

6
R3
?

u

6

3

S3

?

64

6

S3

?

u

3

6
R3
?

u

1

6

S1

b)

u

2

6

R2

6

S2

0

?

?

?

c)

u

@

@

@

@

u

@

@

@

@

@@

@

@

@

@@

u

@

@

@

@

@

@

@@

@

@

@

@@

@

@

@

@

@

@

@

@

-

t

0

6

t

0

Figure 3.8: The transmission tree. a) Binary tree with marks (detection events); b) its
reduced tree and c) its contour process.

The state of the epidemics at ﬁrst detection

We have considered the same setting in Lambert and Trapman (2013), but for a
diﬀerent question, the structure of the epidemic at the ﬁrst detection time. This
question arises in the case of hospital-borne diseases due for example to bacterial
antibiotics resistances. In this situation, everything can be known about all carriers
of the disease, but only after the ﬁrst detection of a case. At this random time,
denoted T , everybody in the hospital is scanned and infected individuals are iden-
tiﬁed. Here the phylogeny of pathogens is not assumed to be known but patients’
data like entrance dates or durations of stays are precisely known.

We assume that patients have i.i.d lengths of stay in the hospital, all distributed
as some r.v. K. Conditional on infection, the length of stay of a patient is supposed

to be a size-biased version of K. Finally, the transmission rate is b and the detection
rate per patient is denoted δ.

65

For individual i, set
• Ui := time elapsed from entrance of the hospital up to infection
• Ai := time elapsed from infection up to T
• Ri := residual lifetime in the hospital after T .

See Fig 3.9 for an example. Set m := E(K) and let φ denote the inverse of the
convex function

(cid:90)

x (cid:55)→ x − b
m

(0,∞]

(1 − e−xy) P(K > y) dy.

Using Vervaat’s transform applied to the path of the contour process, we were able

6

T

w

transmission

6
R
?
6

A

?
6
U
?

6

K

6

J

?

?

Figure 3.9: The structure of the stay in the hospital of an infected patient. Some (other)
patient is detected at time T (random). The focal patient has total duration of stay
K = U + A + R (see text).

to show that conditional on NT = n, the triples (Ui, Ai, Ri) of the n infectives at
time T are i.i.d. distributed as

E(f (U, A, R)) =
φ(δ)
φ(δ) − δ

b
m

(cid:90) ∞

(cid:90) ∞

(cid:90) ∞

du

da

u=0

a=0

z=u+a

P(K ∈ dz) e−φ(δ)a f (u, a, z − u − a),

66

In particular, the times Ji = Ui + Ai spent in the hospital up to time T are i.i.d.
distributed as the r.v. J

P(K > y)(cid:0)1 − e−φ(δ)y(cid:1) dy.

P(J ∈ dy) =

b/m
φ(δ) − δ

The last formulae will allow us to infer the dynamical characteristics of hospital-
borne disease epidemics from hospital data. This contrasts with the fact that infer-
ence is impossible from the sole numbers of cases found upon detection (Trapman
and Bootsma 2009), due to the geometric distribution of NT (recall however that
here T is random).

Mutations

Marks on a tree can also be used to model mutations. In population genetics, it
is standard to assume that each new mutation occurs at a new site of the DNA
sequence, the inﬁnitely-many-sites assumption. The list of mutated sites of a se-
quence is called allele. One of the fundamental questions in population genetics is
to interpret genetic data such as the number of individuals in a population carrying
a speciﬁc mutation or a speciﬁc allele. Reciprocally, the number of mutations, or of
alleles, carried by k individuals in the population is called frequency spectrum by
sites, or by alleles.

The frequency spectrum of neutral mutations (that is mutations occurring at
a constant rate on lineages independently of the genealogy) has been extensively
studied for random genealogies arising from models with constant population size,
culminating in so-called Ewens’ sampling formula (Ewens 1972).
In a series of
recent papers relying heavily on contour techniques, we have studied the frequency
spectrum in branching genealogies (Lambert 2009, 2011; Champagnat and Lambert
2012, 2013).

3.4 Perspectives

For who has understood how to identify which forward-in-time processes generate
trees whose reduced tree is a coalescent point process, and has learnt the proce-
dure of characterizing W and the coalescent density from the model ingredients,
coalescent point processes are a very convenient tool:

• They arise in a wide class of models;
• They generate robust patterns, that in particular are invariant under incom-

plete sampling and under the action of bottlenecks;

67
• The reconstructed tree has a particularly simple distribution, which is ex-
tremely fast to simulate, in contrast with the entire forward-in-time process,
that may even not be Markovian;

• The inference of model parameters from the knowledge of the reconstructed

tree can be done using low-tech statistical methods.

On the other hand, CPPs also have a number of shortcomings:

• The models in which CPP arise exclude some interesting features from the
modeling point of view, in particular the trait/age-dependence of birth rates;
• Among the robust patterns they generate, the shape of the reduced tree is al-
ways ERM, which is certainly not the rule in empirical genealogies/phylogenies;
• The models that we have considered so far to model phylogenies are lineage-
based, in the sense that they ignore the dynamics of individuals inside the
species, and they are neutral, in the sense that all particles are exchangeable.

Currently, one of our main lines of research (mine but more generally that of the
SMILE group – Stochastic models for the inference of life evolution, UPMC &
Collège de France) is to produce and study models that

1. are grounded on the microscopic description of individuals, either at the eco-

logical scale or at the genetic scale;

2. feature a small number of parameters, which can nevertheless be tuned so as to
generate a wide range of diﬀerent patterns, when the corresponding empirical
patterns vary across data sets (e.g. species abundance distributions);

3. generate robust patterns when the corresponding empirical patterns are well
conserved across data sets (e.g., the MLE of β in phylogenies, that revolves
around −1);

4. produce observable statistics (e.g., reconstructed trees) with computable like-

lihoods.

Criterion 3 is in general diﬃcult to satisfy, especially simultaneously with 2.

Bibliography

Aldous, D. (1991). The Continuum Random Tree. I. The Annals of Probability,

19(1):1–28.

Aldous, D. (1993). The Continuum Random Tree III. The Annals of Probability,

21(1):248–289.

Aldous, D. (1996). Probability Distributions on Cladograms.

In Friedman, A.,
Miller, W., Aldous, D., and Pemantle, R., editors, Random Discrete Structures,
volume 76, pages 1–18. Springer New York, New York, NY.

Aldous, D. and Popovic, L. (2005). A critical branching process model for biodi-

versity. Advances in Applied Probability, 37(4):1094–1115.

Aldous, D. J. (2001). Stochastic models and descriptive statistics for phylogenetic

trees, from Yule to today. Statistical Science, 16(1):23–34.

Barthélémy, J.-P. and Guénoche, A. (1991). Trees and Proximity Representations.

John Wiley & Sons.

Bertoin, J. (1996). Lévy processes, volume 121 of Cambridge Tracts in Mathematics.

Cambridge University Press, Cambridge.

Bertoin, J. (2006). Random fragmentation and coagulation processes, volume 102
of Cambridge Studies in Advanced Mathematics. Cambridge University Press,
Cambridge.

Blum, M. G. and François, O. (2006). Which random processes describe the tree
of life? A large-scale study of phylogenetic tree imbalance. Systematic Biology,
55(4):685–691.

Brown, J. K. M. (1994). Probabilities of evolutionary trees. Systematic Biology,

43(1):78–91.

68

69

Burago, D., Burago, Y., and Ivanov, S. (2001). A Course in Metric Geometry,

volume 33. American Mathematical Society Providence.

Champagnat, N. and Lambert, A. (2012). Splitting trees with neutral Poisso-
nian mutations I: Small families. Stochastic Processes and their Applications,
122(3):1003–1033.

Champagnat, N. and Lambert, A. (2013). Splitting trees with neutral Poissonian
mutations II: Largest and oldest families. Stochastic Processes and their Appli-
cations, 123(4):1368–1414.

Dress, A., Moulton, V., and Terhalle, W. (1996). T-theory: An overview. European

Journal of Combinatorics, 17(2–3):161–175.

Duquesne, T. (2006). The coding of compact real trees by real valued functions.

arXiv:math/0604106. arXiv: math/0604106.

Duquesne, T. and Le Gall, J.-F. (2002). Random trees, Lévy processes and spatial

branching processes, volume 281. Société mathématique de France.

Etienne, R. S., Morlon, H., and Lambert, A. (2014). Estimating the duration of

speciation from phylogenies. Evolution, 68(8):2430–2440.

Etienne, R. S. and Rosindell, J. (2012). Prolonging the past counteracts the pull of
the present: protracted speciation can explain observed slowdowns in diversiﬁca-
tion. Systematic Biology, 61(2):204–213.

Evans, S. N. (2008). Probability and Real Trees: École d’été de Probabilités de

Saint-Flour XXXV-2005. Springer.

Evans, S. N., Pitman, J., and Winter, A. (2005). Rayleigh processes, real trees, and
root growth with re-grafting. Probability Theory and Related Fields, 134(1):81–
126.

Ewens, W. J. (1972). The sampling theory of selectively neutral alleles. Theoret-
ical Population Biology, 3:87–112; erratum, ibid. 3 (1972), 240; erratum, ibid. 3
(1972), 376.

Geiger, J. (1996). Size-biased and conditioned random splitting trees. Stochastic

Processes and their Applications, 65(2):187–207.

Geiger, J. and Kersting, G. (1997). Depth-ﬁrst search of random trees, and Poisson
point processes. In Classical and modern branching processes (Minneapolis, MN,
1994), volume 84 of IMA Vol. Math. Appl., pages 111–126. Springer, New York.

70

Haas, B., Miermont, G., Pitman, J., and Winkel, M. (2008). Continuum tree
asymptotics of discrete fragmentations and applications to phylogenetic models.
The Annals of Probability, 36(5):1790–1837.

Hagen, O., Hartmann, K., Steel, M., and Stadler, T. (2015). Age-dependent
speciation can explain the shape of empirical phylogenies. Systematic Biology,
64(3):432–440.

Harding, E. F. (1971). The probabilities of rooted tree-shapes generated by random

bifurcation. Advances in Applied Probability, 3(1):44–77.

Jetz, W., Thomas, G. H., Joy, J. B., Hartmann, K., and Mooers, A. O. (2012). The

global diversity of birds in space and time. Nature, 491(7424):444–448.

Kingman, J. (1982). The coalescent. Stochastic processes and their applications,

13(3):235–248.

Knuth, D. E. (1997). The Art of Computer Programming. Addison-Wesley.

Kyprianou, A. E. (2006). Introductory lectures on ﬂuctuations of Lévy processes

with applications. Universitext. Springer-Verlag, Berlin.

Lambert, A. (2008). Population Dynamics and Random Genealogies. Stochastic

Models, 24(suppl. 1):45–163.

Lambert, A. (2009). The allelic partition for coalescent point processes. Markov

Processes and Related Fields, 15(3):359–386.

Lambert, A. (2010). The contour of splitting trees is a Lévy process. The Annals

of Probability, 38(1):348–395.

Lambert, A. (2011). Species abundance distributions in neutral models with im-
migration or mutation and general lifetimes. Journal of Mathematical Biology,
63(1):57–72.

Lambert, A., Alexander, H. K., and Stadler, T. (2014a). Phylogenetic analysis
accounting for age-dependent death and sampling with applications to epidemics.
Journal of Theoretical Biology, 352:60–70.

Lambert, A., Morlon, H., and Etienne, R. S. (2014b). The reconstructed tree in the
lineage-based model of protracted speciation. Journal of Mathematical Biology,
70(1-2):367–397.

71

Lambert, A. and Popovic, L. (2013). The coalescent point process of branching

trees. Annals of Applied Probability, 23(1):99–144.

Lambert, A., Simatos, F., and Zwart, B. (2013). Scaling limits via excursion the-
ory: Interplay between Crump-Mode-Jagers branching processes and Processor-
Sharing queues. The Annals of Applied Probability, 23(6):2357–2381.

Lambert, A. and Stadler, T. (2013). Birth–death models and coalescent point
processes: The shape and probability of reconstructed phylogenies. Theoretical
Population Biology, 90:113–128.

Lambert, A. and Steel, M. (2013). Predicting the loss of phylogenetic diversity under
non-stationary diversiﬁcation models. Journal of Theoretical Biology, 337:111–
124.

Lambert, A. and Trapman, P. (2013). Splitting trees stopped when the ﬁrst clock
rings and Vervaat’s transformation. Journal of Applied Probability, 50(1):208–227.

Lambert, A. and Uribe Bravo, G. (2016a). Spheres of real trees and other ultra-

metric spaces. Preprint.

Lambert, A. and Uribe Bravo, G. (2016b). Totally ordered, measured trees and

splitting trees with inﬁnite variation. Preprint.

Le Gall, J.-F. (1993). The uniform random tree in a Brownian excursion. Probability

Theory and Related Fields, 96(3):369–383.

Le Gall, J.-F. (2005). Random trees and applications. Probability Surveys, Vol. 2,

2005.

Le Gall, J.-F. and Miermont, G. (2012). Scaling limits of random trees and planar
maps. In Ellwood, D., editor, Probability and Statistical Physics in Two and More
Dimensions: Proceedings of the Clay Mathematics Institute Summer School and
XIV Brazilian School of Probability, 2010. American Mathematical Society.

Manceau, M., Lambert, A., and Morlon, H. (2015). Phylogenies support out-of-

equilibrium models of biodiversity. Ecology Letters, 18(4):347–356.

Mooers, A., Gascuel, O., Stadler, T., Li, H., and Steel, M. (2012). Branch lengths
on birth–death trees and the expected loss of phylogenetic diversity. Systematic
Biology, 61(2):195–203.

Murtagh, F. (1984). Counting dendrograms: A survey. Discrete Applied Mathe-

matics, 7(2):191–199.

72

Nee, S. (2006). Birth-death models in macroevolution. Annual Review of Ecology,

Evolution and Systematics, 37:1–17.

Nee, S., May, R., and Harvey, P. (1994). The reconstructed evolutionary process.
Philosophical Transactions of the Royal Society of London. Series B: Biological
Sciences, 344(1309):305–311.

Nee, S. and May, R. M. (1997). Extinction and the loss of evolutionary history.

Science, 278(5338):692–694.

Paulin, F. (1989). The Gromov topology on R-trees. Topology and its Applications,

32(3):197–221.

Pitman, J. (2006). Combinatorial Stochastic Processes: École d’été de Probabilités

de Saint-Flour XXXII - 2002. Springer.

Popovic, L. (2004). Asymptotic genealogy of a critical branching process. Annals

of Applied Probability, pages 2120–2148.

Semple, C. and Steel, M. A. (2003). Phylogenetics, volume 24. Oxford University

Press.

Slowinski, J. B. (1990). Probabilities of n-trees under two models: a demonstra-
tion that asymmetrical interior nodes are not improbable. Systematic Biology,
39(1):89–94.

Stadler, T. (2010). Sampling-through-time in birth–death trees. Journal of Theo-

retical Biology, 267(3):396–404.

Stadler, T. (2011). Mammalian phylogeny reveals recent diversiﬁcation rate shifts.

Proceedings of the National Academy of Sciences, 108(15):6187–6192.

Stanley, R. P. (1999). Enumerative Combinatorics. Vol. 2, volume 62 of Cambridge

Studies in Advanced Mathematics. Cambridge University Press, Cambridge.

Trapman, P. and Bootsma, M. C. J. (2009). A useful relationship between epidemi-
ology and queueing theory: The distribution of the number of infectives at the
moment of the ﬁrst detection. Mathematical Biosciences, 219(1):15–22.

