6
1
0
2

 
r
a

 

M
1
2

 
 
]

G
L
.
s
c
[
 
 

1
v
8
1
3
6
0

.

3
0
6
1
:
v
i
X
r
a

Harnessing Deep Neural Networks with Logic Rules

Zhiting Hu

Xuezhe Ma

zhitingh@cs.cmu.edu

xuezhem@cs.cmu.edu

Zhengzhong Liu
liu@cs.cmu.edu

Eduard Hovy
hovy@cmu.edu

Eric P. Xing

epxing@cs.cmu.edu

School of Computer Science, Carnegie Mellon University

Abstract

Combining deep neural networks with structured logic rules is desirable to harness
Ô¨Çexibility and reduce unpredictability of the neural models. We propose a general frame-
work capable of enhancing various types of neural networks (e.g., CNNs and RNNs)
with declarative Ô¨Årst-order logic rules. SpeciÔ¨Åcally, we develop an iterative distilla-
tion method that transfers the structured information of logic rules into the weights of
neural networks. We deploy the framework on a CNN for sentiment analysis, and an
RNN for named entity recognition. With a few highly intuitive rules, we obtain sub-
stantial improvements and achieve state-of-the-art or comparable results to previous
best-performing systems.

1 Introduction

Deep neural networks provide a powerful mechanism for learning patterns from massive
data, achieving new levels of performance on image classiÔ¨Åcation (Krizhevsky et al., 2012),
speech recognition (Hinton et al., 2012), machine translation (Bahdanau et al., 2014), play-
ing strategic board games (Silver et al., 2016), and so forth.

Despite the impressive advances, the widely-used DNN methods still have limitations. The
high predictive accuracy has heavily relied on large amounts of labeled data; and the
purely data-driven learning can lead to uninterpretable and sometimes counter-intuitive
results (Szegedy et al., 2014; Nguyen et al., 2015).
It is also diÔ¨Écult to encode human
intention to guide the models to capture desired patterns, without expensive direct super-
vision or ad-hoc initialization.

On the other hand, the cognitive process of human beings have indicated that people learn
not only from concrete examples (as DNNs do) but also from diÔ¨Äerent forms of general
knowledge and rich experiences (Minksy, 1980; Lake et al., 2015). Logic rules provide a
Ô¨Çexible declarative language for communicating high-level cognition and expressing struc-
tured knowledge. It is therefore desirable to integrate logic rules into DNNs, to transfer
human intention and domain knowledge to neural models, and regulate the learning process.

1

In this paper, we present a framework capable of enhancing general types of neural net-
works, such as convolutional networks (CNNs) and recurrent networks (RNNs), on various
tasks, with logic rule knowledge. Combining symbolic representations with neural methods
have been considered in diÔ¨Äerent contexts. Neural-symbolic systems (Garcez et al., 2012)
construct a network from a given rule set to execute reasoning. To exploit a priori knowl-
edge in general neural architectures, recent work augments each raw data instance with
useful features (Collobert et al., 2011), while network training, however, is still limited to
instance-label supervision and suÔ¨Äers from the same issues mentioned above. Besides, a
large variety of structural knowledge cannot be naturally encoded in the feature-label form.

Our framework enables a neural network to learn simultaneously from labeled instances as
well as logic rules, through an iterative rule knowledge distillation procedure that transfers
the structured information encoded in the logic rules into the network parameters. Since the
general logic rules are complementary to the speciÔ¨Åc data labels, a natural ‚Äúside-product‚Äù
of the integration is the support for semi-supervised learning where unlabeled data can be
used to better absorb the logical knowledge. Methodologically, our approach can be seen as
a combination of the knowledge distillation (Hinton et al., 2015; Bucilu et al., 2006) and the
posterior regularization (PR) method (Ganchev et al., 2010). In particular, at each iteration
we adapt the posterior constraint principle from PR to construct a rule-regularized teacher,
and train the student network of interest to imitate the predictions of the teacher network.
We leverage soft logic to support Ô¨Çexible rule encoding.

We apply the proposed framework on both CNN and RNN, and deploy on the task of
sentiment analysis (SA) and named entity recognition (NER), respectively. With only a
few (one or two) very intuitive rules, the enhanced networks strongly improve over their
basic forms (without rules), and achieve better or comparable performance to state-of-the-
art models which typically have more parameters and complicated architectures.

To the best of our knowledge, this is the Ô¨Årst work to integrate logic rules with the general
workhorse types of deep neural networks in a principled framework. The encouraging results
indicate that our method can be potentially useful for other NLP tasks and application
domains, as well as incorporating richer types of human knowledge.

2 Related Work

Given the intuitive value of combining logic rules and neural networks, various distinct
forms of such combination have been considered in diÔ¨Äerent contexts. Neural-symbolic
systems (Garcez et al., 2012), such as KBANN (Towell et al., 1990) and CILP++ (Fran¬∏ca
et al., 2014), construct network architectures from given rules to perform reasoning and
knowledge acquisition. A related line of research, such as Markov logic networks (Richardson
and Domingos, 2006), derives probabilistic graphical models (rather than neural networks)
from the rule set.

With the recent success of deep neural networks in a vast variety of application domains,
it is increasingly desirable to incorporate structured logic knowledge into general types of
networks to harness Ô¨Çexibility and reduce unpredictability. Recent work that trains on extra

2

features from domain knowledge (Collobert et al., 2011), while producing improved results,
does not go beyond the data-label paradigm. Kulkarni et al. (2015) uses a specialized
training procedure with careful ordering of training instances to obtain an interpretable
neural layer of an image network. Though there do exist general frameworks that allow
encoding structured constraints on latent variable models (Ganchev et al., 2010; Zhu et al.,
2014; Liang et al., 2009), they either are not directly applicable to the NN case, or could
yield inferior performance as in our empirical study.

Our proposed approach is distinct in that we use an iterative rule distillation process to
eÔ¨Äectively transfer rich structured knowledge, expressed in the declarative Ô¨Årst-order logic
language, into parameters of general neural networks. We show that the proposed approach
strongly outperforms an extensive array of other either ad-hoc or general integration meth-
ods.

3 Method

In this section we present our framework which encapsulates the logical structured knowl-
edge into a neural network. This is achieved by forcing the network to emulate the predic-
tions of a rule-regularized teacher, and evolving both models iteratively throughout training
(section 3.2). The process is agnostic to the network architecture, and thus applicable to gen-
eral types of neural models including CNNs and RNNs. We construct the teacher network
in each iteration by adapting the posterior regularization principle in our logical constraint
setting (section 3.3), where our formulation provides a closed-form solution. Figure 1 shows
an overview of the proposed framework.

Figure 1: Framework Overview. At each iteration, the teacher network is obtained by
projecting the student network to a rule-regularized subspace (red dashed arrow); and
the student network is updated to balance between emulating the teacher‚Äôs output and
predicting the true labels (black/blue solid arrows).

3

losslabeled datalogic rulesùëû(ùë¶|ùë•)ùëùùúÉ(ùë¶|ùë•)projectionunlabeled datateacher network constructionrule knowledge distillationback propagationteacherùëû(ùë¶|ùë•)student ùëùùúÉ(ùë¶|ùë•)3.1 Learning Resources: Instances and Rules

Our approach allows neural networks to learn from both speciÔ¨Åc examples and general rules.
Here we give the settings of these ‚Äúlearning resources‚Äù.
Assume we have input variable x ‚àà X and target variable y ‚àà Y. For clarity, we focus
on K-way classiÔ¨Åcation, where Y = ‚àÜK is the K-dimensional probability simplex and
y ‚àà {0, 1}K ‚äÇ Y is a one-hot encoding of the class label. However, our method speciÔ¨Åcation
can straightforwardly be applied to other contexts such as regression and sequence learning
(e.g., NER tagging, which is typically a sequence of classiÔ¨Åcation decisions). The training
data D = {(xn, yn)}N
Further consider a set of Ô¨Årst-order logic (FOL) rules with conÔ¨Ådences R = {(Rl, Œªl)}L
l=1,
where Rl is the lth rule over the above input-target space (X ,Y), and Œªl ‚àà [0,‚àû] is the
conÔ¨Ådence level with Œªl = ‚àû indicating a hard rule, i.e., all groundings are required to be
true (=1). Given a set of examples (X, Y) ‚äÇ (X ,Y) (e.g., a minibatch from D), the set of
groundings of Rl are denoted as {rlg(X, Y)}Gl
g=1. In practice a rule grounding is typically
relevant to only a single or subset of examples, though here we give the most general form
on the entire set.

n=1 is a set of instantiations of (x, y).

We encode the FOL rules using soft logic (Bach et al., 2015) for Ô¨Çexible encoding and stable
optimization. SpeciÔ¨Åcally, soft logic allows continuous truth values from the interval [0, 1]
instead of {0, 1}, and the Boolean logic operators are reformulated as:

A&B = max{A + B ‚àí 1, 0}
A ‚à® B = min{A + B, 1}

¬¨A = 1 ‚àí A

(1)

3.2 Rule Knowledge Distillation
A neural network deÔ¨Ånes a conditional probability pŒ∏(y|x) by using a softmax output layer
that produces a K-dimensional soft prediction vector denoted as œÉŒ∏(x). The network is
parameterized by weights Œ∏. Previous neural network training has been to iteratively up-
date Œ∏ to produce the correct labels of training instances. To integrate the information
encoded in the rules, we propose to train the network to also imitate the outputs of a
rule-regularized projection of pŒ∏(y|x), denoted as q(y|x), which explicitly includes rule con-
straints as regularization terms. In each iteration q is constructed by projecting pŒ∏ into a
subspace constrained by the rules, and thus has desirable properties. We present the con-
struction in the next section. The prediction behavior of q reveals the information of the
regularized subspace and structured rules. Emulating the q outputs serves to transfer this
knowledge into pŒ∏. The new objective is then formulated as a balancing between imitating
the soft predictions of q and predicting the true hard labels:

N(cid:88)

Œ∏(t+1) = arg min
Œ∏‚ààŒò

1
N

(1 ‚àí œÄ)(cid:96)(yn, œÉŒ∏(t) (xn))

+ œÄ(cid:96)(s(t)

n , œÉŒ∏(t)(xn)),

n=1

4

(2)

where (cid:96) denotes the loss function selected according to speciÔ¨Åc applications (e.g., typically
the cross entropy loss for classiÔ¨Åcation); s(t)
n is the soft prediction vector of q on xn at
iteration t; and œÄ is the imitation parameter calibrating the relative importance of the two
objectives.

A similar imitation procedure has been used in other settings such as model compres-
sion (Bucilu et al., 2006; Hinton et al., 2015) where the process is termed distillation.
Following them we call pŒ∏(y|x) the ‚Äústudent‚Äù and q(y|x) the ‚Äúteacher‚Äù, which can be intu-
itively explained in analogous to human education where a teacher is aware of systematic
general rules and she instructs students by providing her solutions to particular questions
(i.e., the soft predictions). Another noticeable diÔ¨Äerence from previous distillation work,
where teacher is obtained beforehand and student is trained thereafter, is that our teacher
and student are learned simultaneously during training.

Though it is possible to combine a network with rule constraints by projecting the network
to the rule-regularized subspace after it is fully trained as before with only data-label in-
stances, or by optimizing projected network directly, we found our iterative teacher-student
distillation approach provides a much superior performance, as shown in the experiments.
Moreover, since pŒ∏ distills the rule information into the weights Œ∏ instead of relying on
explicit rule representations, we can use pŒ∏ for predicting new examples at test time when
the rule assessment is expensive or even unavailable (i.e., the privileged information set-
ting (Lopez-Paz et al., 2016)) while still enjoying the beneÔ¨Åt of integration. Besides, the
second loss term in Eq.(2) can be augmented with rich unlabeled data in addition to the la-
beled examples, which enables semi-supervised learning for better absorbing the rule knowl-
edge.

3.3 Teacher Network Construction

We now proceed to construct the teacher network q(y|x) at each iteration from pŒ∏(y|x).
The iteration index t is omitted for clarity. We adapt the posterior regularization principle
in our logic constraint setting. Our formulation ensures a closed-form solution for q and
thus avoids any signiÔ¨Åcant increases in computational overhead.

Recall the set of FOL rules R = {(Rl, Œªl)}L
l=1. Our goal is to Ô¨Ånd the optimal q that Ô¨Åts the
rules while at the same time staying close to pŒ∏. For the Ô¨Årst property, we apply a commonly-
used strategy that imposes the rule constraints on q through an expectation operator. That
is, for each grounding (indexed by g) of each rule (indexed by l) on (X, Y), we expect
Eq(Y|X)[rlg(X, Y)] = 1 (with conÔ¨Ådence Œªl). The constraints deÔ¨Åne a rule-regularized space
of all valid distributions. For the second property, we measure the closeness between q
and pŒ∏ with KL-divergence, and wish to minimize it. Combining the two factors together
and further allowing slackness for the constraints, we Ô¨Ånally get the following optimization

5

problem:

min
q,Œæ‚â•0

(cid:88)
KL(q(Y|X)(cid:107)pŒ∏(Y|X)) + C
s.t. Œªl(1 ‚àí Eq[rl,gl (X, Y)]) ‚â§ Œæl,gl
l = 1, . . . , L,

gl = 1, . . . , Gl,

l,gl

Œæl,gl

(3)

‚â• 0 is the slack variable for respective logic constraint; and C is the regularization
where Œæl,gl
parameter. The problem can be seen as projecting pŒ∏ into the constrained subspace. The
problem is convex and can be eÔ¨Éciently solved in its dual form with closed-form solutions.
We provide the detailed derivation in the supplementary materials and directly give the
solution here:

q‚àó(Y|X) ‚àù pŒ∏(Y|X) exp

CŒªl(1 ‚àí rl,gl (X, Y))

(4)

Ô£±Ô£≤Ô£≥‚àí(cid:88)

l,gl

Ô£ºÔ£ΩÔ£æ .

Intuitively, a strong rule with large Œªl will lead to low probabilities of predictions that fail
to meet the constraints.

Our framework is related to the posterior regularization (PR) method (Ganchev et al., 2010)
which places constraints over model posterior in unsupervised setting. In classiÔ¨Åcation, our
optimization procedure is analogous to the modiÔ¨Åed EM algorithm for PR, by using cross-
entropy loss in Eq.(2) and evaluating the second loss term on unlabeled data diÔ¨Äering from
D, so that Eq.(4) corresponds to the E-step and Eq.(2) is analogous to the M-step. This
sheds light from another perspective on why our framework would work. However, we found
in our experiments (section 5) that to produce strong performance it is crucial to use the
same labeled data in the two losses of Eq.(2) so as to form a trade-oÔ¨Ä between imitating
soft predictions and predicting correct hard labels.

Inference and Implementation The procedure of iterative distilling optimization of
our framework is summarized in Algorithm 1. During training we need to compute the soft
predictions of q at each iteration, which is straightforward if the rule constraints in Eq.(4) are
factored in the same way as the base neural model pŒ∏. If the constraints introduce additional
dependencies, e.g., bi-gram dependency as the transition rule in the NER task (section 4.2),
we can use dynamic programming for eÔ¨Écient computation; for higher-order constraints
(e.g., the listing rule in NER), we approximate using Gibbs sampling that iteratively samples
from q(yi|y‚àíi, x) for each position i. If the constraints span multiple instances, we group the
relevant instances in minibatches for joint inference (and randomly break some dependencies
when a group is too large).

At test time we can use either the distilled student network pŒ∏, or the teacher network q
after a Ô¨Ånal projection. Our empirical results show that both models substantially improve
over the base network (trained using only data-label instances), while in general q performs
better than pŒ∏. Besides, q is more suitable when the logic rules are over multiple examples,
requiring joint inference. In contrast, as mentioned above, pŒ∏ is useful when rule evaluation
is expensive or impossible at prediction time.

6

Algorithm 1 Harnessing NN with Rules
Input: The training data D = {(xn, yn)}N

The rule set R = {(Rl, Œªl)}L
Parameters: œÄ ‚Äì imitation parameter

n=1,

l=1,

C ‚Äì regularization strength

1: Initialize neural network parameter Œ∏
2: repeat
3:
4:
5:
6: until convergence
Output: Distilled student network pŒ∏ and teacher network q

Sample a minibatch (X, Y) ‚äÇ D
Construct teacher network q with Eq.(4)
Distill knowledge into pŒ∏ by updating Œ∏ with Eq.(2)

4 Applications

We have presented our framework that is general enough to improve various types of neural
networks with rules, and easy to use in that users are allowed to impose their knowledge and
intentions through the declarative Ô¨Årst-order logic. In this section we illustrate the versatil-
ity of our approach by applying it on two workhorse network architectures, i.e., convolutional
network and recurrent network, on two representative applications, i.e., sentence-level sen-
timent analysis which is a classiÔ¨Åcation problem, and named entity recognition which is a
sequence learning problem.

For each task, we Ô¨Årst brieÔ¨Çy describe the base neural network. Since we are not focusing
on tuning network architectures, we largely use the same or similar networks to previous
successful neural models. We then design the linguistically-motivated rules to be integrated.

4.1 Sentiment ClassiÔ¨Åcation

Sentence-level sentiment analysis is to identify the sentiment (e.g., positive or negative)
underlying an individual sentence. The task is crucial for many opinion mining applications.
One challenging point of the task is to capture the contrastive sense (e.g., by conjunction
‚Äúbut‚Äù) within a sentence.

Base Network We use the single-channel convolutional network proposed in (Kim, 2014).
The simple model has achieved compelling performance on various sentiment classiÔ¨Åcation
benchmarks. The network contains a convolutional layer on top of word vectors of a given
sentence, followed by a max-over-time pooling layer and then a fully-connected layer with
softmax output activation. A convolution operation is to apply a Ô¨Ålter to word windows.
Multiple Ô¨Ålters with varying window sizes are used to obtain multiple features. Figure 2,
left panel, shows the network architecture.

Logic Rules One diÔ¨Éculty for the plain neural network is to identify contrastive sense in
order to capture the dominant sentiment precisely. Conjunction ‚Äúbut‚Äù is one of the strong

7

Figure 2: Left: The CNN architecture for sentence-level sentiment analysis. The sentence
representation vector is followed by a fully-connected layer with softmax output activa-
tion, to output sentiment predictions. Right: The architecture of the bidirectional LSTM
recurrent network for NER. The CNN for extracting character representation is omitted.

indicators for such sentiment changes in a sentence, where the sentiment of clauses following
‚Äúbut‚Äù generally dominates. We thus consider sentences S with an ‚ÄúA-but-B‚Äù structure, and
expect the sentiment of the whole sentence to be consistent with the sentiment of clause B.
The logic rule is written as:

has-‚ÄòA-but-B‚Äô-structure(S) ‚áí (cid:107)œÉŒ∏(S) ‚àí œÉŒ∏(B)(cid:107)2,

(5)

where we use the (cid:96)2 distance between the softmax outputs as a measure for the closeness
of the sentiment predictions of S and B. Note that the distance takes value in [0, 1] which
is a proper soft truth value.

4.2 Named Entity Recognition

NER is to locate and classify elements in text into entity categories such as ‚Äúpersons‚Äù
and ‚Äúorganizations‚Äù. It is an essential Ô¨Årst step for downstream language understanding
applications. The task assigns to each word a named entity tag in an ‚ÄúX-Y‚Äù format where
X is one of BIEOS (Beginning, Inside, End, Outside, and Singleton) and Y is the entity
category. A valid tag sequence has to follow certain constraints by the deÔ¨Ånition of the
tagging scheme. Besides, text with structures (e.g., lists) within or across sentences can
usually expose some consistency patterns.

Base Network The base network has a similar architecture with the bi-directional LSTM
recurrent network (called BLSTM-CNN) proposed in (Chiu and Nichols, 2015) for NER
which has outperformed most of previous neural models. The model uses a CNN and pre-
trained word vectors to capture character- and word-level information, respectively. These
features are then fed into a bi-directional RNN with LSTM units for sequence tagging.
Compared to (Chiu and Nichols, 2015) we omit the character type and capitalization fea-
tures, as well as the additive transition matrix in the output layer. Figure 2, right panel,
shows the network architecture.

8

IlikethisbookstorealotPaddingPaddingWord EmbeddingConvolutionMax PoolingSentence RepresentationChar+WordRepresentationBackwardLSTMForwardLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMLSTMOutputRepresentationNYClocatesinUSALogic Rules The base network largely makes independent tagging decisions at each po-
sition, ignoring the constraints on successive labels for a valid tag sequence (e.g., I-ORG
cannot follow B-PER). In contrast to recent work (Lample et al., 2016) which adds a con-
ditional random Ô¨Åeld (CRF) to capture bi-gram dependencies between outputs, we instead
apply logic rules which does not introduce extra parameters to learn. An example rule is:

Equal(yi‚àí1, I-ORG) ‚áí ¬¨ Equal(yi, B-PER)

(6)

The conÔ¨Ådence levels are set to ‚àû to prevent any violation.

We further leverage the list structures within and across sentences of the same documents.
SpeciÔ¨Åcally, named entities at corresponding positions in a list are likely to be in the same
categories. For instance, in ‚Äú1. Juventus, 2. Barcelona, 3. ...‚Äù we know ‚ÄúBarcelona‚Äù must
be an organization rather than a location, since its counterpart entity ‚ÄúJuventus‚Äù is an
organization. We describe our simple procedure for identifying lists and counterparts in the
supplementary materials. The logic rule is encoded as:

is-counterpart(A, B) = (cid:107)c(œÉŒ∏(A)) ‚àí c(œÉŒ∏(B))(cid:107)2,

(7)

where c collapses the probability mass on the labels with the same categories into a single
probability, yielding a vector with length equaling to the number of categories. The list
rule can span multiple sentences (within the same document), thus we use q at test time
for joint prediction.

5 Experiments

We validate the proposed framework by evaluating its applications of sentiment classiÔ¨Åcation
and named entity recognition on a variety of public benchmarks. By integrating the simple
yet eÔ¨Äective rules with the base networks, we obtain substantial improvements on both tasks
and achieve state-of-the-art or comparable results to previous best-performing systems.
Comparison with a diverse set of other rule integration methods demonstrates the unique
eÔ¨Äectiveness of our framework. Our approach also shows promising potentials in the semi-
supervised learning and sparse data context.

Throughout the experiments we set the imitation parameter to œÄ = 0.1, the regularization
parameter to C = 400. These values are chosen on the dev set of the SST2 sentiment data
(see below). The conÔ¨Ådence levels of rules are set to Œªl = 1, except for hard constraints
whose conÔ¨Ådence is ‚àû. For neural network conÔ¨Åguration, we largely followed the reference
work as speciÔ¨Åed in the following respective sections. All experiments were performed on a
Linux machine with eight 4.0GHz CPU cores, one Tesla K40c GPU, and 32GB RAM. We
implemented neural networks using Theano 1, a popular deep learning platform.

1http://deeplearning.net/software/theano

9

5.1 Sentiment ClassiÔ¨Åcation

5.1.1 Setup

We test our method on a number of commonly used benchmarks, including 1) SST2,
Stanford Sentiment Treebank (Socher et al., 2013) which contains 2 classes (negative and
positive), and 6920/872/1821 sentences in the train/dev/test sets respectively. Following
(Kim, 2014) we train models on both sentences and phrases since all labels are provided.
2) MR (Pang and Lee, 2005), a set of 10,662 one-sentence movie reviews with negative
or positive sentiment. 3) CR (Hu and Liu, 2004), customer reviews of various products,
containing 2 classes and 3,775 instances.

For the base neural network we use the ‚Äúnon-static‚Äù version in (Kim, 2014) with the exact
same conÔ¨Ågurations. SpeciÔ¨Åcally, word vectors are initialized using word2vec (Mikolov et al.,
2013) and Ô¨Åne-tuned throughout training, and the neural parameters are trained using SGD
with the Adadelta update rule (Zeiler, 2012).

Model

1 CNN (Kim, 2014)
2 CNN-Rule

3 MGNC-CNN (Zhang et al., 2016)
4 MVCNN (Yin and Schutze, 2015)
5 CNN-multichannel (Kim, 2014)
6 Paragraph-Vec (Le and Mikolov, 2014)
7 CRF-PR (Yang and Cardie, 2014)
8 RNTN (Socher et al., 2013)
9 G-Dropout (Wang and Manning, 2013)

10 NBSVM (Wang and Manning, 2012)

SST2

87.2
89.3

88.4
89.4
88.1
87.8
‚Äì
85.4
‚Äì
‚Äì

MR
81.51¬±0.02
81.76¬±0.01
‚Äì
‚Äì
81.1
‚Äì
‚Äì
‚Äì
79.0
79.4

CR
84.32¬±0.03
85.33¬±0.04
‚Äì
‚Äì
85.0
‚Äì
82.7
‚Äì
82.1
81.8

Table 1: Accuracy (%) of Sentiment ClassiÔ¨Åcation. Row 1, CNN (Kim, 2014) corresponds
to the ‚ÄúCNN-non-static‚Äù model in (Kim, 2014). Row 2, CNN-Rule is the CNN enhanced
by our framework. We use the projected version (i.e., q) here. For MR and CR, we report
the average accuracy¬±one standard deviation using 10-fold cross validation as in previous
work.

5.1.2 Results

Table 1 shows the sentiment classiÔ¨Åcation performance. Row 1 and Row 2 compare the base
network with the one enhanced by our framework with the ‚Äúbut‚Äù-rule (Eq.(5)). We see that
our method provides a strong boost on accuracy over all three datasets. For instance, on the
SST2 dataset we obtain 2.1% absolute improvement. Rows 3-10 show the accuracy of recent
top-performing methods. On the MR and CR datasets, our model achieves the state-of-the-
art performance. On SST2, MVCNN (Yin and Schutze, 2015) (Row 4) is the only system
that shows a slightly better result than ours. Their neural network has combined diverse

10

versions of pre-trained word embeddings (while we use only word2vec) and has contained
more neural layers and parameters than our model.

To further investigate the eÔ¨Äectiveness of our framework in integrating structured rule
knowledge, we compare with an extensive array of other possible integration approaches.
Table 2 lists these methods and their performance on the SST2 sentiment classiÔ¨Åcation
task. We see that: 1) Although all methods lead to diÔ¨Äerent degrees of improvement,
our framework outperforms all other competitors with a large margin. 2) The distilled
student network ‚Äú-Rule-p‚Äù achieves much superior accuracy compared to the base CNN, as
well as ‚Äú-project‚Äù and ‚Äú-opt-project‚Äù which explicitly project the CNN model to the rule-
constrained subspace. We have observed similar results on the MR and CR datasets‚Äîthe
student network achieves an accuracy of 81.59% and 85.22% on MR and CR, respectively,
greatly improving over the base CNN as shown in Row 1 Table 1. This validates that our
knowledge distillation procedure (section 3.2) can indeed transfer the structured knowledge
into the neural parameters eÔ¨Äectively. 3) The teacher network ‚Äú-Rule-q‚Äù further improves
over the student network ‚Äú-Rule-p‚Äù, though the student network is more widely applicable
in certain contexts as discussed in section 3.2.

Model

Accuracy (%)

1 CNN
2
3
4
5

-but-clause
-(cid:96)2-reg
-project
-opt-project

6
7

-Rule-p
-Rule-q

87.2
87.3
87.5
87.9
88.1

88.8
89.3

Table 2: Performance of diÔ¨Äerent rule integration methods on SST2. 1) CNN is the base
network; 2) ‚Äú-but-clause‚Äù takes the clause after ‚Äúbut‚Äù as input 3) ‚Äú-(cid:96)2-reg‚Äù imposes a
regularization term Œ≥(cid:107)œÉŒ∏(S) ‚àí œÉŒ∏(Y )(cid:107)2 to the CNN objective, with the strength Œ≥ selected
on dev set; 4) ‚Äú-project‚Äù projects the trained base CNN to the rule-regularized subspace
as in Eq.(3); 5) ‚Äú-opt-project‚Äù directly optimizes the projected CNN; 6-7) ‚Äú-Rule-p‚Äù and
‚Äú-Rule-q‚Äù are our models with p being the distilled student network and q the teacher
network.

We next explore the performance of our framework with varying numbers of labeled in-
stances as well as the eÔ¨Äect of exploiting unlabeled data.
Intuitively, with less labeled
examples we expect the general rules would contribute more to the performance, and unla-
beled data should help better learn from the rules. This can be a useful property especially
when data are sparse and labels are expensive to obtain. Table 3 shows the results. The
subsampling is conducted on the sentence level. That is, for instance, in ‚Äú5%‚Äù we Ô¨Årst
selected 5% training sentences uniformly at random, then trained the models on these sen-
tences as well as their phrases. The results verify our expectations. 1) Rows 1-3 give the
accuracy of only using data-label subsets for training. In every setting our methods con-
sistently outperform the base CNN. 2) ‚Äú-Rule-q‚Äù provides higher improvement on 5% data

11

(with margin 2.6%) than on larger data (e.g., 2.3% on 10% data, and 2.0% on 30% data),
showing promising potential in the sparse data context. 3) By adding unlabeled instances
for semi-supervised learning, we get further improved accuracy. 4) ‚Äú-semi-PR‚Äù is the pos-
terior regularization (Ganchev et al., 2010) which imposes the rule constraint only through
unlabeled data during training. Our iterative distillation framework consistently provides
substantially better results.

Data size

1 CNN
2
3

-Rule-p
-Rule-q

4
5
6

-semi-PR
-semi-Rule-p
-semi-Rule-q

5%

79.9
81.5
82.5

81.5
81.7
82.7

10% 30% 100%

81.6
83.2
83.9

83.1
83.3
84.2

83.6
84.5
85.6

84.6
84.7
85.7

87.2
88.8
89.3

‚Äì
‚Äì
‚Äì

Table 3: Accuracy (%) on SST2 with varying sizes of labeled data and semi-supervised
learning. The header row is the percentage of labeled examples for training. Rows 1-3
use only the supervised data. Rows 4-6 use semi-supervised learning where the remaining
training data are used as unlabeled examples. For ‚Äú-semi-PR‚Äù we only report its projected
solution (in analogous to q) which performs better than the non-projected one (in analogous
to p).

5.2 Named Entity Recognition

5.2.1 Setup

We evaluate on the well-established CoNLL-2003 NER benchmark (Tjong Kim Sang and
De Meulder, 2003), which contains 14,987/3,466/3,684 sentences and 204,567/51,578/46,666
tokens in train/dev/test sets, respectively. The dataset includes 4 categories, i.e., person,
location, organization, and misc. BIOES tagging scheme is used.

We use the mostly same conÔ¨Ågurations for the BLSTM network as in (Chiu and Nichols,
2015), except that, besides the slight architecture diÔ¨Äerence (section 4.2), we apply Adadelta
for parameter updating. GloVe (Pennington et al., 2014) word vectors are used to initialize
word features.

5.2.2 Results

Table 4 presents the performance on the NER task. By incorporating the bi-gram transition
rules (Row 2), we obtain 1.56 improvement in F1 score that outperforms all previous neural
based methods (Rows 4-8), including the BLSTM-CRF model (Lample et al., 2016) which
applies a conditional random Ô¨Åeld (CRF) on top of a BLSTM model in order to capture
the transition patterns and encourage valid sequences. In contrast, our method implements

12

Model

1 BLSTM
2 BLSTM-Rule-trans
3 BLSTM-Rules

S-LSTM (Lample et al., 2016)

4 BLSTM-CRF1 (Lample et al., 2016)
5
6 BLSTM-lex (Chiu and Nichols, 2015)
7 BLSTM-CRF2 (Huang et al., 2015)
8 NN-lex (Collobert et al., 2011)
9

Joint-NER-EL (Luo et al., 2015)

F1

89.55
91.11
91.18

90.94
90.33
90.77
90.10
89.59
91.20

Table 4: Performance of NER on CoNLL-2003. Row 2, BLSTM-Rule-trans imposes the
transition rules (Eq.(6)) on the base BLSTM. Row 3, BLSTM-Rules further incorporates
the list rule (Eq.(7)). We use the projected version (q) for prediction.

the desired constraints in a more straightforward way by using the declarative logic rule
language, and at the same time does not introduce extra model parameters to learn. Further
integration of the list rule (Row 3) provides a second boost in performance, achieving an
F1 score very close to the best-performing system Joint-NER-EL (Luo et al., 2015) (Row 9)
which is a probabilistic graphical model based method optimizing NER and entity linking
jointly and using large amount of external resources.

6 Discussion

We have developed a framework which combines deep neural networks with Ô¨Årst-order
logic rules to allow integrating human knowledge and intentions into the neural models.
In particular, we proposed an iterative distillation procedure that transfers the structured
information of logic rules into the weights of neural networks. The transferring is done via a
teacher network constructed using the posterior regularization principle. Our framework is
general and applicable to various types of neural architectures. With a few intuitive rules,
our framework signiÔ¨Åcantly improves base networks on sentiment analysis and named entity
recognition, demonstrating the practical signiÔ¨Åcance of our approach.

The encouraging results indicate a strong potential of our approach on improving other NLP
tasks and application domains. We plan to explore more applications and incorporate more
structured knowledge in neural networks. We also would like to improve our framework to
automatically learn the importance of diÔ¨Äerent rules, and derive new rules from data.

13

References

Bach, S. H., Broecheler, M., Huang, B., and Getoor, L. (2015). Hinge-loss markov random

Ô¨Åelds and probabilistic soft logic. arXiv preprint arXiv:1505.04406.

Bahdanau, D., Cho, K., and Bengio, Y. (2014). Neural machine translation by jointly

learning to align and translate. arXiv preprint arXiv:1409.0473.

Bucilu, C., Caruana, R., and Niculescu-Mizil, A. (2006). Model compression. In Proc. of

KDD, pages 535‚Äì541. ACM.

Chiu, J. P. and Nichols, E. (2015). Named entity recognition with bidirectional lstm-cnns.

arXiv preprint arXiv:1511.08308.

Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., and Kuksa, P. (2011).

Natural language processing (almost) from scratch. JMLR, 12:2493‚Äì2537.

Fran¬∏ca, M. V., Zaverucha, G., and Garcez, A. S. d. (2014). Fast relational learning using
bottom clause propositionalization with artiÔ¨Åcial neural networks. Machine learning,
94(1):81‚Äì104.

Ganchev, K., Gra¬∏ca, J., Gillenwater, J., and Taskar, B. (2010). Posterior regularization for

structured latent variable models. JMLR, 11:2001‚Äì2049.

Garcez, A. S. d., Broda, K., and Gabbay, D. M. (2012). Neural-symbolic learning systems:

foundations and applications. Springer Science & Business Media.

Hinton, G., Deng, L., Yu, D., Dahl, G. E., Mohamed, A.-r., Jaitly, N., Senior, A., Van-
houcke, V., Nguyen, P., Sainath, T. N., et al. (2012). Deep neural networks for acoustic
modeling in speech recognition: The shared views of four research groups. Signal Pro-
cessing Magazine, IEEE, 29(6):82‚Äì97.

Hinton, G., Vinyals, O., and Dean, J. (2015). Distilling the knowledge in a neural network.

arXiv preprint arXiv:1503.02531.

Hu, M. and Liu, B. (2004). Mining and summarizing customer reviews. In Proc. of KDD,

pages 168‚Äì177. ACM.

Huang, Z., Xu, W., and Yu, K. (2015). Bidirectional lstm-crf models for sequence tagging.

arXiv preprint arXiv:1508.01991.

Kim, Y. (2014). Convolutional neural networks for sentence classiÔ¨Åcation. Proc. of EMNLP.

Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012). Imagenet classiÔ¨Åcation with deep

convolutional neural networks. In Proc. of NIPS, pages 1097‚Äì1105.

Kulkarni, T. D., Whitney, W. F., Kohli, P., and Tenenbaum, J. (2015). Deep convolutional

inverse graphics network. In Proc. of NIPS, pages 2530‚Äì2538.

Lake, B. M., Salakhutdinov, R., and Tenenbaum, J. B. (2015). Human-level concept learning

through probabilistic program induction. Science, 350(6266):1332‚Äì1338.

14

Lample, G., Ballesteros, M., Subramanian, S., Kawakami, K., and Dyer, C. (2016). Neural

architectures for named entity recognition. In Proc. of NAACL.

Le, Q. V. and Mikolov, T. (2014). Distributed representations of sentences and documents.

Proc. of ICML.

Liang, P., Jordan, M. I., and Klein, D. (2009). Learning from measurements in exponential

families. In Proc. of ICML, pages 641‚Äì648. ACM.

Lopez-Paz, D., Bottou, L., Sch¬®olkopf, B., and Vapnik, V. (2016). Unifying distillation and

privileged information. Prof. of ICLR.

Luo, G., Huang, X., Lin, C.-Y., and Nie, Z. (2015). Joint named entity recognition and

disambiguation. In Proc. of EMNLP.

Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. (2013). Distributed
representations of words and phrases and their compositionality. In Proc. of NIPS, pages
3111‚Äì3119.

Minksy, M. (1980). Learning meaning. Technical Report AI Lab Memo. Project MAC. MIT.

Nguyen, A., Yosinski, J., and Clune, J. (2015). Deep neural networks are easily fooled:
High conÔ¨Ådence predictions for unrecognizable images. In Proc. of CVPR, pages 427‚Äì
436. IEEE.

Pang, B. and Lee, L. (2005). Seeing stars: Exploiting class relationships for sentiment
categorization with respect to rating scales. In Proc. of ACL, pages 115‚Äì124. Association
for Computational Linguistics.

Pennington, J., Socher, R., and Manning, C. D. (2014). Glove: Global vectors for word

representation. In Proc. of EMNLP, volume 14, pages 1532‚Äì1543.

Richardson, M. and Domingos, P. (2006). Markov logic networks. Machine learning, 62(1-

2):107‚Äì136.

Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., van den Driessche, G., Schrit-
twieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., et al. (2016). Mastering
the game of go with deep neural networks and tree search. Nature, 529(7587):484‚Äì489.

Socher, R., Perelygin, A., Wu, J. Y., Chuang, J., Manning, C. D., Ng, A. Y., and Potts, C.
(2013). Recursive deep models for semantic compositionality over a sentiment treebank.
In Proc. of EMNLP, volume 1631, page 1642. Citeseer.

Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., and Fergus,

R. (2014). Intriguing properties of neural networks. Proc. of ICLR.

Tjong Kim Sang, E. F. and De Meulder, F. (2003). Introduction to the conll-2003 shared
task: Language-independent named entity recognition. In Proc. of CoNLL, pages 142‚Äì
147. Association for Computational Linguistics.

15

Towell, G. G., Shavlik, J. W., and Noordewier, M. O. (1990). ReÔ¨Ånement of approxi-
mate domain theories by knowledge-based neural networks. In Proceedings of the eighth
National conference on ArtiÔ¨Åcial intelligence, pages 861‚Äì866. Boston, MA.

Wang, S. and Manning, C. (2013). Fast dropout training. In Proc. of ICML, pages 118‚Äì126.

Wang, S. and Manning, C. D. (2012). Baselines and bigrams: Simple, good sentiment
and topic classiÔ¨Åcation. In Proc. of ACL, pages 90‚Äì94. Association for Computational
Linguistics.

Yang, B. and Cardie, C. (2014). Context-aware learning for sentence-level sentiment analysis

with posterior regularization. In Proc. of ACL, pages 325‚Äì335.

Yin, W. and Schutze, H. (2015). Multichannel variable-size convolution for sentence classi-

Ô¨Åcation. Proc. of CONLL.

Zeiler, M. D. (2012). Adadelta: an adaptive learning rate method.

arXiv preprint

arXiv:1212.5701.

Zhang, Y., Roller, S., and Wallace, B. (2016). Mgnc-cnn: A simple approach to exploiting

multiple word embeddings for sentence classiÔ¨Åcation. Proc. of NAACL.

Zhu, J., Chen, N., and Xing, E. P. (2014). Bayesian inference with posterior regularization

and applications to inÔ¨Ånite latent svms. JMLR, 15(1):1799‚Äì1847.

16

A Appendix

A.1 Solving Problem Eq.(3), Section 3.3

We provide the detailed derivation for solving the problem in Eq.(3), Section 3.3, which we
repeat here:

min
q,Œæ‚â•0

(cid:88)
KL(q(Y|X)(cid:107)pŒ∏(Y|X)) + C
s.t. Œªl(1 ‚àí Eq[rl,gl(X, Y)]) ‚â§ Œæl,gl
l = 1, . . . , L,

gl = 1, . . . , Gl,

l,gl

Œæl,gl

The following derivation is largely adapted from (Ganchev et al., 2010) for the logic rule
constraint setting, with some reformulation that produces closed-form solution.

The Lagrangian is

where

(cid:88)

max

¬µ‚â•0,Œ∑‚â•0,Œ±‚â•0

min

q(y,Œª),Œæ

L,

(A.2)

L = KL(q(Y|X)(cid:107)pŒ∏(Y|X)) +

(cid:88)

(C + ¬µl,gl)Œæl,gl

(cid:88)
Œ∑l,gl (Eq[Œªl(1 ‚àí rl,gl(X, Y))] ‚àí Œæl,gl) + Œ±(

l,gl

+

l,gl

Y

q(Y|X) ‚àí 1)

(A.3)

Solving Eq.(A.2), we obtain

‚àáqL = log q(Y|X) + 1 ‚àí log pŒ∏(Y|X) +

(cid:88)

=‚áí

q(Y|X) =

pŒ∏(Y|X) exp{‚àí(cid:80)

Œ∑l,gl [Œªl(1 ‚àí rl,gl(X, Y))] + Œ± = 0
l Œ∑lŒªl(1 ‚àí rl,gl(X, Y))}

l,gl

e exp(Œ±)

(A.1)

(A.4)

(A.5)

Ô£∂Ô£∏

‚àáŒæl,gl

L = C + ¬µl,gl ‚àí Œ∑l,gl = 0

(cid:88)

Y

‚àáŒ±L =

pŒ∏(Y|X) exp

(cid:110)‚àí(cid:80)

=‚áí

Œ± = log

=‚áí

¬µl,gl = C ‚àí Œ∑l,gl
(cid:111)
Œ∑l,glŒªl(1 ‚àí rl,gl(X, Y))
(cid:110)‚àí(cid:80)

Y p(Y|X) exp

‚àí 1 = 0

(cid:111)
Œ∑l,glŒªl(1 ‚àí rl,gl(X, Y))

l,gl
e exp(Œ±)

Ô£´Ô£≠(cid:80)

l,gl
e

17

(A.6)

Let ZŒ∑ =(cid:80)

Y p(Y|X) exp

(cid:110)‚àí(cid:80)

l,gl

L = ‚àí log ZŒ∑ +

(cid:111)
Œ∑l,glŒªl(1 ‚àí rl,gl(X, Y))
(cid:88)
(C + ¬µl,gl)Œæl,gl ‚àí(cid:88)

Œ∑l,glŒæl,gl

. Plugging Œ± into L

l,gl

l,gl

(A.7)

= ‚àí log ZŒ∑

Since ZŒ∑ monotonically decreases as Œ∑ increases, and from Eq.(A.6) we have Œ∑l,gl ‚â§ C,
therefore:

max
C‚â•Œ∑‚â•0

‚àí log ZŒ∑
=‚áí

Œ∑‚àó

l,gl

= C

(A.8)

Plugging Eqs.(A.6) and (A.8) into Eq.(A.5) we obtain the solution of q as in Eq.(4).

A.2 Identifying Lists for NER

We design a simple pattern-matching based method to identify lists and counterparts in the
NER task. We ensure high precision and do not expect high recall. In particular, we only
retrieve lists that with the pattern ‚Äú1. ... 2. ... 3. ...‚Äù (i.e., indexed by numbers), and ‚Äú- ...
- ... - ...‚Äù (i.e., each item marked with ‚Äú-‚Äù). We require at least 3 items to form a list.

We further require the text of each item follows certain patterns to ensure the text is
highly likely to be named entities, and rule out those lists whose item text is largely free
text. SpeciÔ¨Åcally, we require 1) all words of the item text all start with capital letters; 2)
referring the text between punctuations as ‚Äúblock‚Äù, each block includes no more than 3
words.

We detect both intra-sentence lists and inter-sentence lists in documents. We found the
above patterns are eÔ¨Äective to identify true lists. A better list detection method is expected
to further improve our NER results.

18

