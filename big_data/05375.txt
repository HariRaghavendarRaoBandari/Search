6
1
0
2

 
r
a

 

M
7
1

 
 
]

.

A
R
h
t
a
m

[
 
 

1
v
5
7
3
5
0

.

3
0
6
1
:
v
i
X
r
a

Minimax theorem for the spectral radius of the product of

non-negative matrices$

Victor Kozyakin

Institute for Information Transmission Problems

Russian Academy of Sciences

Bolshoj Karetny lane 19, Moscow 127994 GSP-4, Russia

Abstract

We prove the minimax equality for the spectral radius ρ(AB) of the product of matrices
A ∈ A and B ∈ B, where A and B are compact sets of non-negative matrices of
dimensions N ×M and M ×N , respectively, satisfying the so-called hourglass alternative.

Keywords: Matrix products, Non-negative matrices, Spectral radius, Minimax, Saddle
point
2010 MSC: 15A45, 15B48, 49J35

1. Introduction

In the article, we consider the question about conditions under which, for compact

(closed and bounded) sets of matrices A and B, holds the minimax equality

min
A∈A

max
B∈B

ρ(AB) = max
B∈B

min
A∈A

ρ(AB),

where ρ(·) is the spectral radius of a matrix.

(1)

Clearly, equality (1) is not true, in general, see Example 4 below. However, some
time ago in a private discussion Eugene Asarin conjectured that minimax equality (1)
still might be valid for certain classes of non-negative matrices. This conjecture, based
on the analysis of properties of the matrix multiplication games [1], was supported by
numerous computer experiments indicating that equality (1) holds for the classes of
matrices with the so-called ‘row uncertainty’ (see deﬁnition in Section 3). Unfortunately,
attempts to formally prove the required equality, even for the simplest cases, do not lead
to success for a long time.

The main cause of arising diﬃculties was the fact that the greater part of classical
proofs of theorems on the minimax for functions f (x, y) assume some kind of convexity in
one of the arguments of the function and concavity in the other (see, e.g., rather old but

$Funded by the Russian Science Foundation, Project No. 14-50-00150.

Email address: kozyakin@iitp.ru (Victor Kozyakin)
URL: http://www.iitp.ru/en/users/46.htm (Victor Kozyakin)

Preprint submitted to Elsevier

March 18, 2016

still urgent survey [2]). In the case of spectral radius we were not able to ﬁnd any analogs
of convexity or concavity of the function ρ(AB) with respect to the matrix variables A
and B. Moreover, in view of the identity ρ(AB) ≡ ρ(BA) the matrices A and B in (1)
are in a sense equivalent. Therefore, any kind of ‘convexity’ of the function ρ(AB) with
respect, say, to the variable A would have to involve its ‘concavity’ with respect to the
same variable, which casts doubt on the applicability of the ‘convex-concave’ arguments
in the proof of (1).

Recently, in [1] the author has managed to overcome the indicated diﬃculties and
to prove minimax equality (1) for the classes of matrices arising in the theory of matrix
multiplication games [1], the theory of switching systems [3, 4] and so forth. The relevant
proof, as is often the case, is turned out to be easy enough, and its idea was based on the
so-called hourglass alternative, ﬁrst formulated in [1], and in a more general form later
used in [5] for proving the ﬁniteness conjecture for some classes of non-negative matrices.
The goal of the article is to prove equality (1) for more general classes of matrices,
the so-called classes of non-negative H-sets of matrices resulting from axiomatization of
the statements constituting the hourglass alternative.

The structure of the work is as follows. In Section 2, we recall the formulation of
the so-called hourglass alternative for the sets of positive matrices. Then we outline the
principal properties of the sets of matrices satisfying the hourglass alternative, H-sets of
matrices, among which the most important is that the totality of all H-sets of matrices,
supplemented by the zero and the identity matrices, forms a semiring with respect to
Minkowski set operations. In Section 3 we show in Theorem 1 that the spectral radius
ρ(AB) of a product of two matrices taken from H-sets of matrices has a saddle point,
from which the main result, Theorem 2, asserting the validity of equality (1) immediately
follows. The proof of Theorem 1 is given in Section 4, its idea is heavily based on the
hourglass alternative.

2. Hourglass alternative and H-sets of matrices

Following [5], we recall necessary deﬁnitions and facts. For vectors x, y ∈ RN , we
write x (cid:62) y or x > y, if all coordinates of the vector x are not less or strictly greater,
respectively, than the corresponding coordinates of the vector y.
Denote by M(N, M ) the set of all real (N × M )-matrices. This set of matrices can be
identiﬁed with space RN×M and therefore, depending on the context, it can be interpreted
as topological, metric or normed space. A set of positive matrices A ⊂ M(N, M ) will
be called H-set or hourglass set if every time the equality ˜Au = v is true for some matrix
˜A ∈ A and vectors u, v > 0 there are also true the following assertions:

H1: either Au (cid:62) v for all A ∈ A or there exists a matrix ¯A ∈ A such that
H2: either Au (cid:54) v for all A ∈ A or there exists a matrix ¯A ∈ A such that

¯Au (cid:54) v and ¯Au (cid:54)= v;
¯Au (cid:62) v and ¯Au (cid:54)= v.

These assertions have a simple geometrical interpretation. Imagine that the sets Bl =
{x : x (cid:54) v} and Bu = {x : x (cid:62) v} form the lower and upper bulbs of an hourglass with
the neck at the point v. Then according to assertions H1 and H2 either all the grains Au
ﬁll one of the bulbs (upper or lower), or there remains at least one grain in the other bulb

2

(lower or upper, respectively). Such an interpretation gives reason to call assertions H1
and H2 the hourglass alternative. This alternative will play a key role in what follows.
It was raised up and used by the author in [1] to analyze the minimax relations between
the spectral radii of matrix products, and also in [5] to prove the ﬁniteness conjecture
for non-negative H-sets of matrices.
Failure of the inequality u (cid:62) v for vectors u and v does not imply, in general, the
inverse inequality u (cid:54) v. From this it follows that assertions H1 and H2 are not valid
for arbitrary sets of matrices A : non-fulﬁllment of the inequality Au (cid:62) v for all A ∈ A
does not mean that for some matrix ¯A ∈ A the inverse inequality ¯Au (cid:54) v will be valid.
And similarly, non-fulﬁllment of the inequality Au (cid:54) v for all A ∈ A does not mean that
for some matrix ¯A ∈ A the inverse inequality ¯Au (cid:62) v will be valid.

In what follows, we will need to make various kinds of limit transitions with the
matrices from the sets under consideration as well as with the sets of matrices themselves.
In this connection, it is natural to restrict our considerations to only compact sets of
matrices. By H(N, M ) we denote the set of all compact H-sets of positive (N × M )-
matrices.

Present some examples of H-sets.

Example 1. A trivial example of H-sets are linearly ordered sets of positive matrices
A = {A1, A2, . . . , An}, that is the sets of matrices whose elements satisfy the inequalities
0 < A1 < A2 < ··· < An. Here, for each u > 0, the vectors A1u, A2u, . . . , Anu are strictly
positive and linearly ordered, which yields the validity of assertions H1 and H2 for A . In
particular, any set consisting of a single positive matrix is an H-set. The totality of all
ﬁnite positive linearly ordered sets of (N × M )-matrices will be denoted by L(N, M ).
Example 2. A less trivial and more interesting example of H-sets, as shown in [1,
Lemma 4] and [5, Lemma 1], is the class of sets of positive matrices with independent
row uncertainty. Following [3], a set of matrices A ⊂ M(N, M ) is called an IRU-set
(independent row uncertainty set) if it consists of all the matrices

 ,

···
···
···
···

a1M
a2M
···
aNM

 a11

a12
a22
a21
···
···
aN 1 aN 2

A =

wherein each of the rows ai = (ai1, ai2, . . . , aiM ) belongs to some set of M -rows Ai,
i = 1, 2, . . . , N . The set of all compact sets of positive (N×M )-matrices with independent
row uncertainty will be denoted by U(N, M ). Clearly, a set A ⊂ M(N, M ) is compact
if and only if it is compact each set of rows Ai, i = 1, 2, . . . , N .

To construct another examples of H-sets of matrices introduce the operations of

Minkowski addition and multiplication for sets of matrices:

A + B = {A + B : A ∈ A , B ∈ B}, A B = {AB : A ∈ A , B ∈ B},

and also the operation of multiplication of a set of matrices by a scalar:

tA = A t = {tA : t ∈ R, A ∈ A }.

3

The operation of addition is admissible if and only if the matrices from the sets A and
B are of the same size, while the operation of multiplication is admissible if and only
if the sizes of the matrices from sets A and B are matched: dimension of the rows of
the matrices from A is the same as dimension of the columns of the matrices from B.
Problems with matching of sizes do not arise when one considers the sets consisting of
square matrices of the same size.
Example 3. As shown in [5, Theorem 2], the totality of H-sets of matrices in a sense is
algebraically closed under the operations of Minkowski addition and multiplication:

• A + B ∈ H(N, M ) if A , B ∈ H(N, M );
• A B ∈ H(N, Q) if A ∈ H(N, M ) and B ∈ H(M, Q);
• tA = A t ∈ H(N, M ) if t > 0 and A ∈ H(N, M ).

From here it follows that for any integers n, d (cid:62) 1, the totality H(N, M ) contains all the
polynomial sets of matrices

P (A1, A1, . . . , An) =

pi1,i2,...,ik

Ai1

Ai2 ··· Aik ,

(2)

d(cid:88)

(cid:88)

k=1

i1,i2,...,ik∈{1,2,...,n}

(cid:26)

(cid:27)

where Ai ∈ H(Ni, Mi) for i = 1, 2, . . . , n, and the scalar coeﬃcients pi1,i2,...,ik are pos-
Ai2 ··· Aik would be admissible and
itive. One must only ensure that the products Ai1
determine the sets of matrices of dimension N × M .
2.1. Closure of the set H(N, M )

Given some matrix norm (cid:107) · (cid:107) on the set M(N, M ), denote by K(N, M ) the totality
of all compact subsets of M(N, M ). Then for any two sets of matrices A , B ∈ K(N, M )
there is deﬁned the Hausdorﬀ metric or distance

H(A , B) = max

(cid:107)A − B(cid:107),

sup
A∈A

inf
B∈B

sup
B∈B

inf
A∈A

(cid:107)A − B(cid:107)

,

in which K(N, M ) becomes a full metric space. Then H(N, M ) ⊂ K(N, M ), equipped
with the Hausdorﬀ metric, also becomes a metric space.
As is known, see, e.g., [6, Chapter E, Proposition 5], any mapping F (A ) acting from
K(N, M ) into itself is continuous in the Hausdorﬀ metric at some point A0 if and only
if it is both upper and lower semicontinuous. It is known also [7, Section 1.3] that the
mappings

(A , B) (cid:55)→ A + B,

(A , B) (cid:55)→ A B, A (cid:55)→ A × A × ··· × A , A (cid:55)→ co(A ),

where A and B are compact sets, are both upper and lower semicontinuous. Then these
mappings are continuous in the Hausdorﬀ metric, and the same continuity properties has
any polynomial mapping (2).
Denote by H(N, M ) the closure of the set H(N, M ) in the Hausdorﬀ metric. Since
the Minkowski addition and multiplication of matrix sets are continuous in the Hausdorﬀ
metric, then as follows from Example 3 all the ‘polynomial’ sets of matrices with the

4

arguments from H-sets of matrices with matched dimensions take values again in the H-
set of matrices. However, the answer to the question when, for a speciﬁc A , the inclusion
A ∈ H(N, M ) holds, requires further analysis. We restrict ourselves to the description
of only one case where the answer to this question can be given explicitly [5, Lemma 4]:
the values of any polynomial mapping (2) with the arguments from ﬁnite linearly ordered
sets of non-negative matrices or from IRU-sets of non-negative matrices belong to the
closure in the Hausdorﬀ metric of the totality of positive H-sets of matrices.

3. Main results

In the theory of functions, one of the fundamental criteria of feasibility of the minimax

equality is the following saddle point principle, see [8, Section 13.4].
Lemma 1. Let f (x, y) be a continuous function on the product of compact spaces X ×Y .
Then

min

x

max

y

f (x, y) (cid:62) max

y

min

x

f (x, y).

The exact equality holds if and only if there exists a saddle point, i.e. a point (x0, y0)
satisfying the inequalities

f (x0, y) (cid:54) f (x0, y0) (cid:54) f (x, y0)

for all x ∈ X, y ∈ Y , and then

min

x

max

y

f (x, y) = max

y

min

x

f (x, y) = f (x0, y0).

This criterion explains the importance of the following saddle point theorem for the

study of the question about minimax equality (1).
Theorem 1. Let A ∈ H(N, M ) and B ∈ H(M, N ). Then there exist matrices ˜A ∈ A
and ˜B ∈ B such that

ρ( ˜AB) (cid:54) ρ( ˜A ˜B) (cid:54) ρ(A ˜B)

(3)

for all A ∈ co(A ) and B ∈ co(B), where co(·) denotes the convex hull of a set.

In a ﬁnite-dimensional space the convex hull of a compact set is a compact set.
And since the sets of matrices A and B can be treated as subsets of ﬁnite-dimensional
spaces RN×M and RM×N , respectively, then the sets co(A ) and co(B) in Theorem 1 are
compact. If A is an IRU-set of matrices which is formed by a set of rows A1, A2, . . . , AN ,
then its convex hull co(A ) is the IRU-set formed by the set of rows co(A1), co(A2), . . . ,
If A is an H-set of matrices then the structure of the set co(A ) is more
co(AN ).
complicated.
In Theorem 1 the ‘saddle point’ ( ˜A, ˜B) belongs to the set A × B, while the matrices
A and B, for which the inequality (3) holds, belong to the wider sets: (A, B) ∈ co(A ) ×
co(B). This makes possible to deduce a variety of minimax theorems for the spectral
radius ρ(AB) from Theorem 1.

5

Theorem 2. Let A ∈ H(N, M ) and B ∈ H(M, N ). Then there exists a number ρ∗ (cid:62) 0
such that

min
A∈ ˜A

max
B∈ ˜B

ρ(AB) = max
B∈ ˜B

min
A∈ ˜A

ρ(AB) = ρ∗

for any compact sets of matrices

˜A and ˜B satisfying

A ⊆ ˜A ⊆ co(A ), B ⊆ ˜B ⊆ co(B).

To prove this theorem, it suﬃces to note that, by Theorem 1 inequalities (3) will take

place for all A ∈ ˜A and B ∈ ˜B, and then to apply Lemma 1.

Choosing in Theorem 1 diﬀerent sets ˜A and ˜B, we obtain diﬀerent minimax equali-
˜A = co(A ) and

˜A = A and ˜B = B, we get (1). Putting

ties. For example, putting a
˜B = co(B), we get another minimax equality:

min

A∈co(A )

max

B∈co(B)

ρ(AB) = max

B∈co(B)

min

A∈co(A )

ρ(AB).

It should be emphasized that the value of the minimax spectral radius ρ(AB) in the last
equality, and the value of the corresponding minimax in equality (1) coincide.

The next example demonstrates that Theorem 2 is not valid for general sets of ma-

trices.
Example 4. Consider the sets of matrices A = {A1, A2} and B = {B1, B2}, where

A1 =

, A2 =

, B1 =

(cid:18)3 1
(cid:19)
(cid:18)8 7

2 1

6 5

(cid:19)

(cid:19)
(cid:18)1 1
(cid:18)4

1 3

3

(cid:19)

9
7

(cid:18)2

2

(cid:19)

2
1

(cid:18)1

1

(cid:19)

2
3

.

, B2 =

(cid:18)4

8

(cid:19)

3
5

(cid:18)2

4

(cid:19)

5
11

Then

and

ρ(A1B1) =

ρ(A2B1) =

Therefore,

A1B1 =

, A1B2 =

, A2B1 =

, A2B2 =

√

13 +
√
2

9 +

2

177

= 13.1521, ρ(A1B2) =

97

= 9.4244,

ρ(A2B2) =

11 +

13 +

√

√
2

2

117

161

= 10.9083,

= 12.8443 .

min
A∈A

max
B∈B

ρ(AB) = 12.8443, max
B∈B

min
A∈A

ρ(AB) = 10.9083,

and minimax equality (1) does not hold in this case.

The spectral radius of the product ρ(AB) of (rectangular) matrices A and B is not
changed by permutation of these matrices and their transposition. This implies the
following corollary.

Corollary 1. Theorems 1 and 2 hold if to replace the function ρ(AB) by ρ(BA), as well
as by ρ(ATBT) or ρ(BTAT).

6

4. Proof of Theorem 1

auxiliary facts.

Before proceeding to the proof of Theorem 1, we recall some deﬁnitions and establish
The spectral radius of an (N × N )-matrix A is deﬁned as maximal modulus of its
eigenvalues and denoted by ρ(A). It depends continuously on the matrix, and if A > 0
then by the Perron-Frobenius theorem [9, Theorem 8.2.2], the number ρ(A) is a simple
eigenvalue of the matrix A, and all the other eigenvalues of A are strictly less than ρ(A)
by modulus. The eigenvector v = (v1, v2, . . . , vN )T corresponding to the eigenvalue ρ(A)
(normalized, for example, by the equation v1 + v2 +··· + vN = 1) is uniquely determined
and positive.

For ease of reference, we summarize some of the well-known statements of the theory

of non-negative matrices, see, e.g. [5, Lemma 2] or [1, Lemma 3] for proofs.
Lemma 2. Let A be a non-negative (N × N )-matrix. Then the following properties hold:
(i) if Au (cid:54) ρu for some vector u > 0, then ρ (cid:62) 0 and ρ(A) (cid:54) ρ;
(ii) moreover, if in conditions of (i) A > 0 and Au (cid:54)= ρu, then ρ(A) < ρ;
(iii) if Au (cid:62) ρu for some non-zero vector u (cid:62) 0 and some number ρ (cid:62) 0, then ρ(A) (cid:62) ρ;
(iv) moreover, if in conditions of (iii) A > 0 and Au (cid:54)= ρu, then ρ(A) > ρ.

To analyze the convergence of sequences An → A∞ in the Hausdorﬀ metric, it is

convenient to use the following lemma, see, e.g., [6, Chapter E, Propositions 2, 4].
Lemma 3. Let An ∈ K(N, M ) for n = 1, 2, . . . . Then An → A∞ in the Hausdorﬀ
metric if and only if the following assertions are valid:
(i) for any sequence of indices n1 < n2 < . . . , any sequence of matrices Ani ∈ Ani,
(ii) for any matrix A∞ ∈ A∞ and any sequence of indices n1 < n2 < . . . , there exists

i = 1, 2, . . . , contains a subsequence converging to some element from A∞;
a sequence of matrices Ani ∈ Ani, i = 1, 2, . . . , converging to A∞.
At last, we will need the following simpliﬁed version of Berge’s Maximum Theorem,

see [10, Ch. 6, § 3, Theorems 1, 2] and also [6, Ch. E, Sect. 3].

Lemma 4. If ϕ is a continuous numerical function in the product of topological spaces
X × Y , where Y is compact, then the functions M (x) = maxy∈Y ϕ(x, y) and m(x) =
miny∈Y ϕ(x, y) are continuous.

Note that in the full version of the Maximum Theorem the set over which the maxi-

mum is taken in the deﬁnitions of M (x) and m(x) is allowed to vary with x.

We are now ready to prove Theorem 1.

Proof of Theorem 1. First, let A ∈ H(N, M ) and B ∈ H(M, N ). To construct the
matrices ˜A ∈ A and ˜B ∈ B we proceed as follows. Let us note that for each B ∈ B
there exists a matrix AB ∈ A which minimizes (in A ∈ A ) the quantity ρ(AB). Such a
matrix AB exists by virtue of compactness of the set A and continuity of the function
ρ(AB) in A and B. Then, for each matrix B ∈ B, the relations

ρ(ABB) = min
A∈A

ρ(AB) (cid:54) ρ(AB)

7

will be valid for all A ∈ A . Here, by Lemma 4 the function minA∈A ρ(AB) is continuous
in B, and therefore there exists a matrix ˜B ∈ B that maximizes its value on set B.

Set ˜A = A ˜B. In this case

max
B∈B

ρ(ABB) = max
B∈B

min
A∈A

ρ(AB) = min
A∈A

ρ(A ˜B) = ρ(A ˜B

˜B) = ρ( ˜A ˜B),

(4)

where the ﬁrst equality follows from the deﬁnition of the matrix AB, the second follows
from the deﬁnition of ˜B, the third follows from the deﬁnition of A ˜B, and the fourth
follows from the deﬁnition of ˜A.
Let v = (v1, v2, . . . , vN )T be the positive eigenvector of the (N × N )-matrix ˜A ˜B
corresponding to the eigenvalue ρ( ˜A ˜B). By denoting w = ˜Bv ∈ RM we obtain that
ρ( ˜A ˜B)v = ˜Aw. Let us show that in this case

ρ( ˜A ˜B)v (cid:54) Aw

(5)
for all A ∈ A . Indeed, otherwise by assertion H1 of the hourglass alternative there exists
a matrix ¯A ∈ A such that ρ( ˜A ˜B)v (cid:62) ¯Aw and ρ( ˜A ˜B)v (cid:54)= ¯Aw which implies, by the
deﬁnition of the vector w, that ρ( ˜A ˜B)v (cid:62) ¯A ˜Bv and ρ( ˜A ˜B)v (cid:54)= ¯A ˜Bv. Then by Lemma 2
ρ( ¯A ˜B) < ρ( ˜A ˜B), and therefore minA∈A ρ(A ˜B) < ρ( ˜A ˜B), which contradicts to (4). This
contradiction completes the proof of inequality (5).

Similarly, now we show that

w (cid:62) Bv

(6)
for all B ∈ B. Again, assuming the contrary by assertion H2 of the hourglass alternative
there exists a matrix ¯B ∈ B such that w (cid:54) ¯Bv and w (cid:54)= ¯Bv. This last inequality, together
with (5) applied to the matrix A ¯B, yields ρ( ˜A ˜B)v (cid:54) A ¯B
¯Bv. Then
¯B), and therefore maxB∈B ρ(ABB) > ρ( ˜A ˜B), which again
by Lemma 2 ρ( ˜A ˜B) < ρ(A ¯B
contradicts to (4). This contradiction completes the proof of inequality (6).

¯Bv and ρ( ˜A ˜B)v (cid:54)= A ¯B

Inequality (5) implies, by the deﬁnition of the vector w, that

ρ( ˜A ˜B)v (cid:54) A ˜Bv

for all A ∈ A . Then this inequality holds also for all A ∈ co(A ), which by Lemma 2
yields

ρ( ˜A ˜B) (cid:54) ρ(A ˜B),

A ∈ co(A ).

(7)

Similarly, left-multiplying the inequality (6) to the positive matrix ˜A, and taking into

account the equality ρ( ˜A ˜B)v = ˜Aw, we see that

ρ( ˜A ˜B)v (cid:62) ˜ABv

for all B ∈ B. Then this inequality holds also for all B ∈ co(B), which by Lemma 2
yields

ρ( ˜AB) (cid:54) ρ( ˜A ˜B),

B ∈ co(B).

(8)
Inequalities (7) and (8) complete the proof of the theorem in the case when A ∈

H(N, M ) and B ∈ H(M, N ).

8

We proceed to the ﬁnal stage of the proof. Let now A ∈ H(N, M ) and B ∈ H(M, N ).
Then, for n = 1, 2, . . . , there exist sets of matrices An ∈ H(N, M ) and Bn ∈ H(M, N )
such that

An → A , Bn → B.

(9)

Therefore, as already shown, in virtue of (7) and (8), for each n, there exist matrices
˜An ∈ An and ˜Bn ∈ Bn such that

ρ( ˜An ˜Bn) (cid:54) ρ(A ˜Bn),
ρ( ˜An ˜Bn) (cid:62) ρ( ˜AnB),

A ∈ co(An),
B ∈ co(Bn).

(11)
By (9), in view of the compactness of each of the sets A , B, An and Bn, each
of the sequences of matrices {An} and {Bn} without loss of generality may be treated
convergent: ˜An → ˜A and ˜Bn → ˜B, besides due to assertion (i) of Lemma 3 ˜A ∈ A and
˜B ∈ B, that is

˜An → ˜A ∈ A ,

˜Bn → ˜B ∈ B.

(12)
Finally, let us take an arbitrary matrix A ∈ co(A ). Then, by deﬁnition of the convex

hull of a set, the matrix A is a ﬁnite convex combination of matrices from A , i.e.

(10)

A =

λiA(i),

r(cid:88)

i=1

r(cid:88)

An =

λiA(i)

n ∈ co(An)

where r is some integer, λi are non-negative numbers the sum of which is 1, and A(i) ∈ A
for i = 1, 2, . . . , r. Then by assertion (ii) of Lemma 3 for each i = 1, 2, . . . , r there exist
n → A (i).
sequences of matrices {A(i)
Therefore for the matrices

n ∈ An for all n = 1, 2, . . . , and A(i)

n } such that A(i)

i=1

it is true the limit relation

An → A.

Substituting now the matrices ˜An, ˜Bn and An in (10) we obtain

ρ( ˜An ˜Bn) (cid:54) ρ(An ˜Bn).

(13)

(14)

Taking the limit in (14), due to (12) and (13) we obtain the inequality (7), valid
this time in the case when A ∈ H(N, M ) and B ∈ H(M, N ). Similarly we can prove
inequality (8) in the case when A ∈ H(N, M ) and B ∈ H(M, N ).

The proof of Theorem 1 is completed.

Acknowledgments

The author is genuinely grateful to Eugene Asarin for numerous inspiring discussions

and constructive criticism.

The work was funded by the Russian Science Foundation, Project No. 14-50-00150.

9

References

[1] E. Asarin, J. Cervelle, A. Degorre, C. Dima, F. Horn, V. Kozyakin, Entropy games and matrix
multiplication games, in: N. Ollinger, H. Vollmer (Eds.), 33rd Symposium on Theoretical Aspects
of Computer Science, (STACS 2016), Vol. 47 of Leibniz International Proceedings in Informatics
(LIPIcs), Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik, Dagstuhl, Germany, 2016, pp. 11:1–
11:14. doi:http://dx.doi.org/10.4230/LIPIcs.STACS.2016.11.
URL http://drops.dagstuhl.de/opus/volltexte/2016/5712

[2] S. Simons, Minimax theorems and their proofs, in: Minimax and applications, Vol. 4 of Nonconvex
Optim. Appl., Kluwer Acad. Publ., Dordrecht, 1995, pp. 1–23. doi:10.1007/978-1-4613-3557-3_1.
URL http://link.springer.com/chapter/10.1007%2F978-1-4613-3557-3_1

[3] V. D. Blondel, Y. Nesterov, Polynomial-time computation of the joint spectral radius for some sets of
nonnegative matrices, SIAM J. Matrix Anal. Appl. 31 (3) (2009) 865–876. doi:10.1137/080723764.
URL http://epubs.siam.org/doi/abs/10.1137/080723764

[4] V. Kozyakin, Constructive stability and stabilizability of positive linear discrete-time switching

systems, ArXiv.org e-Print archive (Nov. 2015). arXiv:1511.05665.
URL http://arxiv.org/abs/1511.05665

[5] V. Kozyakin, Hourglass alternative and the ﬁniteness conjecture for the spectral characteristics
of sets of non-negative matrices, Linear Algebra Appl. 489 (2016) 167–185. arXiv:1507.00492,
doi:10.1016/j.laa.2015.10.017.
URL http://www.sciencedirect.com/science/article/pii/S0024379515006126

[6] E. A. Ok, Real analysis with economic applications, Princeton University Press, Princeton, NJ,
[7] Y. G. Borisovich, B. D. Gel(cid:48)man, A. D. Myshkis, V. V. Obukhovskii, Multivalued mappings, Journal

2007.

of Soviet Mathematics 24 (6) (1984) 719–791. doi:10.1007/BF01305758.
URL http://link.springer.com/article/10.1007%2FBF01305758

[8] J. von Neumann, O. Morgenstern, Theory of Games and Economic Behavior, Princeton University

Press, Princeton, N. J., 1947, 2d ed.

[9] R. A. Horn, C. R. Johnson, Matrix analysis, 2nd Edition, Cambridge University Press, Cambridge,

2013.

[10] C. Berge, Topological spaces, Dover Publications, Inc., Mineola, NY, 1997, including a treatment
of multi-valued functions, vector spaces and convexity, Translated from the French original by E.
M. Patterson, Reprint of the 1963 translation.

10

