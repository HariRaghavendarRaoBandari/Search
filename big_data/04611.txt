Stein Type Characterization for G-normal

Distributions

Mingshang Hu ∗

Shige Peng†

Yongsheng Song‡

March 16, 2016

Abstract

In this article, we provide a Stein type characterization for G-normal distributions: Let
N [ϕ] = maxµ∈Θ µ[ϕ], ϕ ∈ Cb,Lip(R), be a sublinear expectation. N is G-normal if and only
if for any ϕ ∈ C 2

b (R), we have(cid:90)

ϕ(cid:48)(x) − G(ϕ(cid:48)(cid:48)(x))]µϕ(dx) = 0,

[

x
2

R

where µϕ is a realization of ϕ associated with N , i.e., µϕ ∈ Θ and µϕ[ϕ] = N [ϕ].

Key words: G-normal distribution, Stein type characterization, G-expectation
MSC-classiﬁcation: 35K55, 60A05, 60E05

6
1
0
2

 
r
a

 

M
5
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
1
1
6
4
0

.

3
0
6
1
:
v
i
X
r
a

1 Introduction

Peng (2007) introduced the notion of G-normal distribution via the viscosity solutions of the
G-heat equation below

∂tu − G(∂2

xu) = 0, (t, x) ∈ (0,∞) × R,

u(0, x) = ϕ(x),

where G(a) = 1
of bounded Lipstchiz functions on R.

2 (σ2x+ − σ2x−), a ∈ R with 0 ≤ σ ≤ σ < ∞, and ϕ ∈ Cb,Lip(R), the collection

Then the one-dimensional G-normal distribution is deﬁned by

NG[ϕ] = uϕ(1, 0),

where uϕ is the viscosity solution to the G-heat equation with the initial value ϕ.

As is well known, the fact that µ = N (0, σ2) if and only if

(cid:90)

R

[xϕ(cid:48)(x) − σ2ϕ(cid:48)(cid:48)(x)]µ(dx), for all ϕ ∈ C2

b (R).

(1.1)

∗Qilu Institute of Finance, Shandong University, Jinan, China. humingshang@sdu.edu.cn. Research supported

by NSF (No.11201262 and 11301068) and Shandong Province (No.BS2013SF020 and ZR2014AP005).

†School of Mathematics and Qilu Institute of Finance, Shandong University, Jinan, China. peng@sdu.edu.cn.

Research supported by NSF (No.11526205 and 11221061) and by the 111 Project (No. B12023).

‡Academy of Mathematics and Systems Science, CAS, Beijing, China, yssong@amss.ac.cn. Research supported
by NCMIS; Key Project of NSF (No. 11231005); Key Lab of Random Complex Structures and Data Science,
CAS (No. 2008DP173182).

1

This is the characterization of the normal distribution presented in Stein (1972), which is the
basis of Stein’s method for normal approximation (see Chen, Goldstein and Shao (2011) and
the references therein for more details).

What is the proper counterpart of (1.1) for G-normal distributions? An immediate conjecture

should be

NG[LGϕ] = 0, for all ϕ ∈ C2

b (R),

where LGϕ(x) = x
pointed in Hu et al (2015) by a counterexample.

2 ϕ(cid:48)(x)− G(ϕ(cid:48)(cid:48)(x)). However, the above equality does not hold generally as was

By calculating some examples, we try to ﬁnd the proper generalization of (1.1) for G-normal

distributions. As a sublinear expectation, the G-normal distribution can be represented as

NG[ϕ] = max
µ∈ΘG

µ[ϕ], for all ϕ ∈ Cb,Lip(R),

where ΘG is a set of probabilities on R. For ϕ ∈ Cb,Lip(R), we call µ ∈ ΘG a realization of ϕ
associated with NG if NG[ϕ] = µ[ϕ].
Example 1.1 Set β = σ
of the trigonometric function cos x (see Figure 1).

2 . Song (2015) deﬁned a periodic function φβ as a variant

σ and σ = σ+σ

(cid:40) 2

1+β cos( 1+β
1+β cos( 1+β

2 x)
2β x + β−1

2β

2β π)

for x ∈ [− π
for x ∈ [ π

1+β , π
1+β );
1+β , (2β+1)π

1+β

).

(1.2)

φβ(x) =

It was proved that

Figure 1: φβ(x)

G(φ(cid:48)(cid:48)

β(x)) = − σ2

2

φβ(x)

and that u(t, x) := e− 1

2 σ2tφβ(x) is a solution to the G-heat equation. Therefore

√

u(t, x) = NG[φβ(x +

t·)] = µt,x[φβ(x +
√

t·). Since µs,x[φβ(x +

√

(1.3)
t·)] considered as a function of s

√

t·)],

where µt,x is a realization of φβ(x +
attains its maximum at s = t, we get
√

(cid:90)

∂tu(t, x) =

φ(cid:48)
β(x +

R

ty)

(cid:90)

∂yφβ(x +

√

ty)

y
2

µt,x(dy)

R

√
y
t

2

µt,x(dy) =

1
t

2

by taking formal derivation on the equality (1.3) with respect to t. On the other hand, noting
u(t, x) = e− 1

2 σ2tφβ(x), we have

σ2u(t, x)

(cid:90)

∂tu(t, x) = − 1
2
= − 1
2
R
G(φ(cid:48)(cid:48)

(cid:90)

σ2

=

φβ(x +
√

√

ty)µt,x(dy)

β(x +

ty))µt,x(dy)

G(∂2

y φβ(x +

√

ty))µt,x(dy).

(cid:90)

R
1
t

R

=

√

(cid:90)

Combing the above arguments, we get the following equality

[

y
2

∂yφβ(x +

R

ty) − G(∂2

y φβ(x +

√

ty))]µt,x(dy) = 0.

Inspired by this example, we guess generally the following result holds.
Proposition 1.2 Let ϕ ∈ C2
distribution NG, we have

b (R).

If µϕ is a realization of ϕ associated with the G-normal

ϕ(cid:48)(x) − G(ϕ(cid:48)(cid:48)(x))]µϕ(dx) = 0.

(cid:90)

[

x
2

R

To convince ourselves, let us calculate another simple example.
Example 1.3 Let φ ∈ C2(R) satisfy, for some ρ ≥ 0,

φ(cid:48)(x) + G(φ(cid:48)(cid:48)(x)) = ρφ(x).

x
2

It is easy to check that u(t, x) = (1 + t)ρφ( x√

) is a solution to the G-heat equation. Therefore

u(t, x) = NG[φ(x +

1+t

√

t·)] = µt,x[φ(x +
√

√

t·)] = (1 + t)ρφ(

x√
1 + t

),

(1.4)

t·). By taking formal derivation on (1.4) with respect to t,

where µt,x is a realization of φ(x +
we get

∂tu(t, x) =

√

R

φ(cid:48)(x +

√
y
ty)
2
x√
= ρ(1 + t)ρ−1φ(
1 + t

t

µt,x(dy)
) − x
2

(1 + t)ρ− 3

2 φ(cid:48)(

x√
1 + t

).

(1.5)

(1.6)

(cid:90)

(cid:90)

).

(1.7)

Similarly, by taking formal derivation on (1.4) with respect to x, we get
x√
1 + t

∂xu(t, x) =

φ(cid:48)(x +

√

R

2 φ(cid:48)(
ty)µt,x(dy) = (1 + t)ρ− 1
2 − (1.4) × ρ = 0, which implies
√
ty) − G(φ(cid:48)(cid:48)(x +

√

ty))]µt,x(dy) = 0.

Note that (1.6) × (1 + t) + (1.7) × x
φ(cid:48)(x +

(cid:90)
More precisely, we have(cid:90)

√
y

R

2

t

[

√

[

y
2

∂yφ(x +

ty) − G(∂2

y φ(x +

√

ty))]µt,x(dy) = 0,

R

which is just the conclusion of Proposition 1.2.

3

Return to the linear case, the closed linear span of the family of functions considered in either
of the above two examples is the space of continuous functions, which makes us conﬁdent that
the conclusion of Proposition 1.2 is correct.

Just like Stein’s characterization of (classical) normal distributions, we are also concerned
about the converse problem:
(Q) Let N [ϕ] = maxµ∈Θ µ[ϕ], ϕ ∈ Cb,Lip(R), be a sublinear expectation. Assuming N satisﬁes
the Stein type formula (SH) below, does it follow that N = NG?

(SH) For ϕ ∈ C2

b (R), we have(cid:90)

[G(ϕ(cid:48)(cid:48)(x)) − x
2

R

ϕ(cid:48)(x)]µϕ(dx) = 0,

where µϕ is a realization of ϕ associated with N , i.e., µϕ ∈ Θ and µϕ[ϕ] = N [ϕ].

Actually, we can also ﬁnd evidences for the converse statement from some simple examples.

Example 1.4 Assume that N is a sublinear expectation on Cb,Lip(R) satisfying the Stein type
t·)]. We shall “prove” that u is the solution to the
formula (SH). Set u(t, x) := N [φβ(x +
G-heat equation. Actually, noting that u(t, x) = N [φβ(x +
t·)] with µt,x a
realization of φβ(x +

t·)] = µt,x[φβ(x +

t·), we get

√

√

√

√

(cid:90)

∂tu(t, x) =

φ(cid:48)
β(x +

√

ty)

√
y

t

2

µt,x(dy).

R

So, from Hypothesis (SH), we get
√

(cid:90)

∂tu(t, x) =

R
Then u(t, x) = e− σ2

G(φ(cid:48)(cid:48)

β(x +

ty))µt,x(dy) = − σ2
2

(cid:90)

R

√

φβ(x +

ty)µt,x(dy) = − σ2
2

u(t, x).

2 tφβ(x), which is the solution to the G-heat equation with u(0, x) = φβ(x).

Our purpose is to prove the Stein type formula for G-normal distributions (Proposition 1.2) and
its converse problem (Q). In order to do so, we ﬁrst prove a weaker version of the Stein type
characterization below.
Theorem 1.5 Let N [ϕ] = maxµ∈Θ µ[ϕ], ϕ ∈ Cb,Lip(R), be a sublinear expectation. N is G-
normal if and only if for any ϕ ∈ C2

(cid:90)

b (R), we have
[G(ϕ(cid:48)(cid:48)(x)) − x
2

R
where Θϕ = {µ ∈ Θ : µ[ϕ] = N [ϕ]}.

sup
µ∈Θϕ

ϕ(cid:48)(x)]µ(dx) = 0,

(SHw)

Since Hypothesis (SHw) is weaker than (SH), the necessity of Theorem 1.5 is weaker than that of
Proposition 1.2. At the same time, the suﬃciency of Theorem 1.5 implies the converse arguments
(Q).

In Section 2 we provide two lemmas to show how the diﬀerentiation penetrates the sublinear
expectations, which makes sense the “formal derivation” in the above examples. In section 3,
we give a proof to Theorem 1.5. We shall prove Proposition 1.2 in Section 5 based on the G-
expectation theory, and as a preparation we list some basic deﬁnitions and notations concerning
G-expectation in Section 4.

4

2 Two Useful Lemmas
Let N [ϕ] = maxµ∈Θ µ[ϕ] be a sublinear expectation on Cb,Lip(R). Throughout this article, we
suppose the following additional properties:

(H1) Θ is weakly compact;
(H2) limN→∞ N [|x|1[|x|>N ]] = 0.
Clearly, the tightness of Θ is already implied by (H2). We emphasize by (H1) that Θ is weakly
closed, which ensures that there exists a realization µϕ for any ϕ ∈ Cb,Lip(R). In addition, it
is easily seen that Θ can always be chosen as weakly closed for a sublinear expectations N on
Cb,Lip(R).
Deﬁne ξ : R → R by ξ(x) = x. Sometimes, we write N [ϕ], µ[ϕ] by E[ϕ(ξ)], Eµ[ϕ(ξ)],
respectively. For ϕ ∈ Cb,Lip(R), set Θϕ = {µ ∈ Θ : Eµ[ϕ(ξ)] = E[ϕ(ξ)]}.
For a sublinear expectation N on Cb,Lip(R) and ϕ ∈ Cb,Lip(R), set

u(t, x) := N [ϕ(x +

√

t·)] = E[ϕ(x +
(respectively, ∂−

√

tξ)].

Deﬁne ∂+

t u(t, x) = limδ↓0

u(t+δ,x)−u(t,x)

δ

the corresponding limits exist. Similarly, we can deﬁne ∂+
Lemma 2.1 For a sublinear expectation N on Cb,Lip(R) and ϕ ∈ C2

∂+
t u(t, x) = sup
µ∈Θt,x

Eµ[

∂+
x u(t, x) = sup
µ∈Θt,x

√
ϕ(cid:48)(x +
ξ
2
Eµ[ϕ(cid:48)(x +

t

√
√

tξ)], ∂−
tξ)], ∂−

t u(t, x) = inf

µ∈Θt,x

x u(t, x) = inf

µ∈Θt,x

where Θt,x = Θϕ(x+

√

t·). Furthermore, we have

∂+
t u(t + δ, x) = lim
δ↓0
t u(t − δ, x) = lim
∂+
δ↓0

∂−
t u(t + δ, x),
∂−
t u(t − δ, x).

∂+
t u(t, x) = lim
δ↓0
∂−
t u(t, x) = lim
δ↓0
x u(t, x), ∂−

Similar relations hold for ∂+

x u(t, x).

t u(t, x) = limδ↓0

x u(t, x) and ∂−

x u(t, x).

u(t−δ,x)−u(t,x)

−δ

b (R), we have
√
ϕ(cid:48)(x +
tξ)],
√

√
ξ

Eµ[
Eµ[ϕ(cid:48)(x +

tξ)],

2

t

) ) if

(2.1)

(2.2)

(2.3)

(2.4)

(2.5)

(2.6)

(2.7)

(2.8)

Proof. We shall only give proof to (2.1) and (2.3). The other conclusions can be proved
similarly.

Step 1. Proof to (2.1).
By the deﬁnition of the function u we have, for any µδ ∈ Θt+δ,x,

u(t + δ, x) − u(t, x)

δ

=

1
δ
1
=
δ
≤ 1
δ

√

E[ϕ(x +

Eµδ [ϕ(x +

Eµδ [ϕ(x +

√

E[ϕ(x +

E[ϕ(x +

tξ)]
√

Eµδ [ϕ(x +

t + δξ)] − 1
δ
√
√

t + δξ)] − 1
δ
t + δξ)] − 1
δ
√
tξ)] + o(1).

tξ)]
√
tξ)]

= Eµδ [

ϕ(cid:48)(x +

√
ξ

t

2

There exists a subsequence (still denoted by µδ) such that µδ weakly−−−−→ µ∗ ∈ Θ.

5

Then, by (2.8), we have

u(t + δ, x) − u(t, x)

δ

≤ lim
δ↓0

Eµδ [

√
ξ
2

t

ϕ(cid:48)(x +

√

tξ)] = Eµ∗[

ϕ(cid:48)(x +

√
ξ
2

t

√

tξ)].

lim sup

δ↓0

Noting that

|Eµδ [ϕ(x +

√

t + δξ)] − Eµδ [ϕ(x +

√

tξ)]| ≤ E[|ϕ(x +

√

t + δξ) − ϕ(x +

√

tξ)|] → 0,

we conclude, from (2.6), that
√

Eµ∗[ϕ(x +
which means that µ∗ ∈ Θt,x.

On the other hand, for any µ ∈ Θt,x we get

tξ)] = lim
δ↓0

Eµδ [ϕ(x +

√

t + δξ)] = E[ϕ(x +

√

tξ)],

u(t + δ, x) − u(t, x)

δ

1
=
δ
≥ 1
δ

E[ϕ(x +

Eµ[ϕ(x +

Eµ[ϕ(x +

√
tξ)]
√

Eµ[ϕ(x +

tξ)]

√
t + δξ)] − 1
δ
√
t + δξ)] − 1
δ
√
tξ)] + o(1).

= Eµ[

Thus, by (2.11), we get

ϕ(cid:48)(x +

√
ξ

t

2

u(t + δ, x) − u(t, x)

δ

lim inf

δ↓0

≥ sup
µ∈Θt,x

Eµ[

√
ξ

t

2

ϕ(cid:48)(x +

√

tξ)].

Combining the above arguments, we have

u(t + δ, x) − u(t, x)

δ

lim
δ↓0

= sup
µ∈Θt,x

Eµ[

ϕ(cid:48)(x +

√
ξ
t

2

√

tξ)] = Eµ∗[

ϕ(cid:48)(x +

√
ξ
2

t

√

tξ)].

(2.9)

(2.10)

(2.11)

Step 2. Proof to (2.4).
By (2.1), there exists µδ ∈ Θt+δ,x such that ∂+

t u(t + δ, x) = Eµδ [

√
ξ
t+δ
2

ϕ(cid:48)(x +

√

t + δξ)].

√

Noting that

√

√

Eµδ [

√

2

√
ξ
2

t

ϕ(cid:48)(x +

ϕ(cid:48)(x +

tξ)] → 0,

t + δξ)] − Eµδ [
tξ)] → ∂+

ξ
t + δ
√
it suﬃces to prove that Eµδ [ ξ
2
there is a sub-subsequence (µδ(cid:48)
√
√
t u(t, x) = Eµ∗[ ξ
∂+
2
ϕ. For a sublinear expectation N on Cb,Lip(R), set wN (s) := E[v(s,
Lemma 2.2 For a sublinear expectation N on Cb,Lip(R), we have, for t ∈ (0, 1)

ϕ(cid:48)(x +
t u(t, x). Actually, for any subsequence of (µδ),
) such that µδ(cid:48) weakly−−−−→ µ∗ ∈ Θ. By Step 1 we have µ∗ ∈ Θt,x and
√
tξ)]. So we conclude that Eµδ(cid:48) [ ξ

For any ϕ ∈ Cb,Lip(R), let v(t, x) be the solution to the G-heat equation with initial value

1 − sξ)], s ∈ [0, 1].

ϕ(cid:48)(x +
√

tξ)] → ∂+

t u(t, x). (cid:3)

ϕ(cid:48)(x +

√

2

t

t

t

∂+
t wN (t) =

∂−
t wN (t) =

sup
µ∈Θv(t,
√

1−t·)

Eµ[∂tv(t,

inf
µ∈Θv(t,
√

1−t·)

Eµ[∂tv(t,

√

1 − tξ) − ∂xv(t,
√

1 − tξ) − ∂xv(t,

6

√

],

1 − tξ)
√

2
1 − tξ)

√

ξ
1 − t
√
ξ
1 − t
2

(2.12)

].

(2.13)

Proof. For any µδ ∈ Θv(t+δ,
√

1−t−δ·), we have

wN (t + δ) − wN (t) = E[v(t + δ,

√

√
1 − t − δξ)] − E[v(t,
1 − tξ)]
√
√
1 − t − δξ)] − E[v(t,
= Eµδ [v(t + δ,
√
1 − t − δξ)] − Eµδ [v(t,
≤ Eµδ [v(t + δ,
√
1 − tξ)δ − ∂xv(t,
1 − tξ)
= Eµδ [∂tv(t,

√

1 − tξ)]
√

1 − tξ)]
√

ξ
1 − t

2

(2.14)

(2.15)

(2.16)

δ] + o(δ).

(2.17)

There exists a subsequence (still denoted by µδ) such that µδ weakly−−−−→ µ∗ ∈ Θ. Noting that

|Eµδ [v(t + δ,
√
≤ E[|v(t + δ,

√
1 − t − δξ)] − Eµδ [v(t,
1 − t − δξ) − v(t,

1 − tξ)]|
1 − tξ)|] → 0,

√

√

we have, by (2.15),

Eµ∗[v(t,

√

1 − tξ)] = lim
δ↓0

Eµδ [v(t + δ,

√

1 − t − δξ)] = E[v(t,

√

1 − tξ)],

i.e., µ∗ belongs to Θv(t,
√

1−t·). Then by (2.17) we have

wN (t + δ) − wN (t)

δ

lim sup

δ↓0

≤ Eµ∗[∂tv(t,

√

1 − tξ) − ∂xv(t,

√

1 − tξ)

√

ξ
1 − t

2

].

On the other hand, for each ﬁxed µ ∈ Θv(t,

√

1−t·), we have

√
√
wN (t + δ) − wN (t) = E[v(t + δ,
1 − tξ)]
1 − t − δξ)] − E[v(t,
√
√
1 − t − δξ)] − Eµ[v(t,
1 − tξ)]
= E[v(t + δ,
√
√
1 − tξ)]
1 − t − δξ)] − Eµ[v(t,
≥ Eµ[v(t + δ,
√
√
1 − tξ)δ − ∂xv(t,
2

= Eµ[∂tv(t,

1 − tξ)

√

ξ
1 − t

(2.18)

(2.19)

(2.20)

(2.21)

δ] + o(δ).

Therefore, we conclude, by (2.21), that

wN (t + δ) − wN (t)

δ

lim inf

δ↓0

≥

sup
µ∈Θv(t,
√

1−t·)

Eµ[∂tv(t,

√

1 − tξ) − ∂xv(t,

√

1 − tξ)

√

ξ
1 − t

2

].

Combining the above arguments, we obtain (2.12). By similar arguments, we can prove (2.13).

(cid:3)

3 Proof to Theorem 1.5

We shall prove Theorem 1.5 based mainly on the two lemmas introduced in Section 2.
Proof. Necessity.

b (R), u(t, x) := N [ϕ(x +

t·)] = E[ϕ(x +

√

√

tξ)]

Assume that N is G-normal. Then, for ϕ ∈ C2
Step 1. For µ ∈ Θϕ,

is the solution to G-heat equation with initial value ϕ.

ϕ(cid:48)(ξ)].

ξ
2

∂tu(1, 0) = Eµ[

7

Actually, by Lemma 2.1, we have
ϕ(cid:48)(ξ)] = ∂+

Eµ[

sup
µ∈Θϕ

ξ
2

t u(1, 0) = ∂tu(1, 0) = ∂−

t u(1, 0) = inf
µ∈Θϕ

Eµ[

ϕ(cid:48)(ξ)].

ξ
2

(cid:48)(cid:48)
Step 2. ∂tu(1, 0) = supµ∈Θϕ Eµ[G(ϕ
Note that u(1 + δ, 0) = E[u(δ, ξ)] and u(δ, x) = E[ϕ(x +

uniformly with respect to x. So, for µδ ∈ Θu(δ,·), we have

(ξ))].

√

δξ)] = ϕ(x) + δG(ϕ(cid:48)(cid:48)(x)) + o(δ)

u(1 + δ, 0) − u(1, 0) = E[u(δ, ξ)] − E[ϕ(ξ)]
= Eµδ [u(δ, ξ)] − E[ϕ(ξ)]
≤ Eµδ [u(δ, ξ)] − Eµδ [ϕ(ξ)]
= δEµδ [G(ϕ(cid:48)(cid:48)(ξ))] + o(δ).

There exists a subsequence (still denoted by µδ) such that µδ weakly−−−−→ µ∗ ∈ Θ. Noting that

|Eµδ [u(δ, ξ)] − Eµδ [ϕ(ξ)]| ≤ E[|u(δ, ξ) − ϕ(ξ)|] → 0,

we have, by (3.2),

i.e., µ∗ belongs to Θϕ.
By (3.4) we obtain

Eµ∗[ϕ(ξ)] = lim
δ↓0

Eµδ [u(δ, ξ)] = E[ϕ(ξ)],

u(1 + δ, 0) − u(1, 0)

δ
On the other hand, for any µ ∈ Θϕ, we have

lim sup

δ↓0

≤ Eµ∗[G(ϕ(cid:48)(cid:48)(ξ))].

u(1 + δ, 0) − u(1, 0) = E[u(δ, ξ)] − E[ϕ(ξ)]
= E[u(δ, ξ)] − Eµ[ϕ(ξ)]
≥ Eµ[u(δ, ξ)] − Eµ[ϕ(ξ)]
= δEµ[G(ϕ(cid:48)(cid:48)(ξ))] + o(δ).

(3.1)

(3.2)

(3.3)

(3.4)

(3.5)

(3.6)

(3.7)

(3.8)

By (3.8), we get lim inf δ↓0
ments, we get the desired result.

δ

u(1+δ,0)−u(1,0)

≥ supµ∈Θϕ Eµ[G(ϕ

(cid:48)(cid:48)

(ξ))]. Combining the above argu-

Suﬃciency.
Assume N is a sublinear expectation on Cb,Lip(R) satisfying Hypothesis (SHw). For any
ϕ ∈ Cb,Lip(R), let v(t, x) be the solution to the G-heat equation with initial value ϕ. For s ∈ [0, 1],
set w(s) := E[v(s,
s w(s) = 0, s ∈ (0, 1). Noting that

1 − sξ)]. To prove the theorem, it suﬃces to show that w(0) = w(1).

By (2.12 ) in Lemma 2.2 and Hypothesis (SHw), we get ∂+

√

w is continuous on [0, 1] and locally Lipschitz continuous on (0, 1), we get w(0) = w(1).

(cid:3)

Corollary 3.1 Let N [ϕ] = maxµ∈Θ µ[ϕ], ϕ ∈ Cb,Lip(R), be a sublinear expectation. Then N is
G-normal if for any ϕ ∈ C2

b (R), we have

(cid:90)

[G(ϕ(cid:48)(cid:48)(x)) − x
2

ϕ(cid:48)(x)]µϕ(dx) = 0,

(SH)

R

where µϕ is a realization of ϕ associated with N , i.e., µϕ ∈ Θ and µϕ[ϕ] = N [ϕ].

8

4 Some Deﬁnitions and Notations about G-expectation

We review some basic notions and deﬁnitions of the related spaces under G-expectation. The
readers may refer to [7], [8], [9], [10], [12] for more details.
Let ΩT = C0([0, T ]; Rd) be the space of all Rd-valued continuous paths ω = (ω(t))t≥0 ∈ Ω

with ω(0) = 0 and let Bt(ω) = ω(t) be the canonical process.

Let us recall the deﬁnitions of G-Brownian motion and its corresponding G-expectation

introduced in [8]. Set

Lip(ΩT ) := {ϕ(ω(t1),··· , ω(tn)) : t1,··· , tn ∈ [0, T ], ϕ ∈ Cb,Lip((Rd)n), n ∈ N},

where Cb,Lip(Rd) is the collection of bounded Lipschitz functions on Rd.

We are given a function

G : Sd (cid:55)→ R

satisfying the following monotonicity, sublinearity and positive homogeneity:

if a, b ∈ Sd and a ≥ b;

A1. G(a) ≥ G(b),
A2. G(a + b) ≤ G(a) + G(b), for each a, b ∈ Sd;
A3. G(λa) = λG(a) for a ∈ Sd and λ ≥ 0.

Remark 4.1 When d = 1, we have G(a) := 1

2 (σ2a+ − σ2a−), for 0 ≤ σ2 ≤ σ2.

For each ξ(ω) ∈ Lip(ΩT ) of the form

ξ(ω) = ϕ(ω(t1), ω(t2),··· , ω(tn)), 0 = t0 < t1 < ··· < tn = T,

we deﬁne the following conditional G-expectation

Et[ξ] := uk(t, ω(t); ω(t1),··· , ω(tk−1))

for each t ∈ [tk−1, tk), k = 1,··· , n. Here, for each k = 1,··· , n, uk = uk(t, x; x1,··· , xk−1)
is a function of (t, x) parameterized by (x1,··· , xk−1) ∈ (Rd)k−1, which is the solution of the
following PDE (G-heat equation) deﬁned on [tk−1, tk) × Rd:

∂tuk + G(∂2

xuk) = 0

with terminal conditions

uk(tk, x; x1,··· , xk−1) = uk+1(tk, x; x1,··· xk−1, x), for k < n

The G-expectation of ξ(ω) is deﬁned by E[ξ] = E0[ξ]. From this construction we obtain a
:= E[|ξ|p]1/p, p ≥ 1. The completion of Lip(ΩT ) under (cid:107)·(cid:107)Lp
is a Banach
G(ΩT ). The canonical process Bt(ω) := ω(t), t ≥ 0, is called a G-Brownian

G

and un(tn, x; x1,··· , xn−1) = ϕ(x1,··· xn−1, x).
natural norm (cid:107)ξ(cid:107)Lp
space, denoted by Lp
motion in this sublinear expectation space (Ω, L1
Deﬁnition 4.2 A process {Mt} with values in L1
for any s ≤ t.
martingale.

G(Ω), E).
G(ΩT ) is called a G-martingale if Es(Mt) = Ms
If {Mt} and {−Mt} are both G-martingales, we call {Mt} a symmetric G-

G

9

Theorem 4.3 ([2]) There exists a weakly compact subset P ⊂ M1(ΩT ), the set of probability
measures on (ΩT ,B(ΩT )), such that

E[ξ] = sup
P∈P

EP [ξ]

for all ξ ∈ Lip(ΩT ).

P is called a set that represents E.
Deﬁnition 4.4 A function η(t, ω) : [0, T ] × ΩT → R is called a step process if there exists a
time partition {ti}n
i=0 with 0 = t0 < t1 < ··· < tn = T , such that for each k = 0, 1,···, n− 1 and
t ∈ (tk, tk+1]

η(t, ω) = ξtk ∈ Lip(Ωtk ).
We denote by M 0(0, T ) the collection of all step processes.

For a step process η ∈ M 0(0, T ), we set the norm

(cid:107)η(cid:107)p
H p
G

:= E[{

|ηs|2ds}p/2], p ≥ 1

and denote by H p

G(0, T ) the completion of M 0(0, T ) with respect to the norms (cid:107) · (cid:107)H p

.

G

Theorem 4.5 ([13]) For ξ ∈ Lβ
decomposition:

G(ΩT ) with some β > 1, Xt = Et(ξ), t ∈ [0, T ] has the following

(cid:90) T

0

(cid:90) t

Xt = X0 +

ZsdBs + Kt, q.s.,

where {Zt} ∈ H 1
the above decomposition is unique and {Zt} ∈ H α

G(0, T ) and {Kt} is a continuous non-increasing G-martingale. Furthermore,

G(0, T ), KT ∈ Lα

G(ΩT ) for any 1 ≤ α < β.

0

5 Proof to Proposition 1.2
Let P be a weakly compact set that represents E. Then the corresponding G-normal distribution
can be represented as

NG[ϕ] = max

P∈P EP [ϕ(B1)], for all ϕ ∈ Cb,Lip(R).

Clearly, NG satisﬁes condition (H2) and Θ := {P ◦ B−1
Proposition 1.2 can be restated in the following form.
Proposition 5.1 Let ϕ ∈ C2

b (R). For P ∈ P such that EP [ϕ(B1) = E[ϕ(B1)], we have

1 | P ∈ P} is weakly compact. Also,

EP [

B1
2

ϕ(cid:48)(B1) − G(ϕ(cid:48)(cid:48)(B1))] = 0.

b (R), set u(t, x) = E[ϕ(x + Bt)]. As a solution to the G-heat equation, we

Proof. For ϕ ∈ C2
know u ∈ C1,2

b (R). Particularly, one has
u(1 + δ, 0) − u(1, 0)

lim
δ↓0

δ

u(1 − δ, 0) − u(1, 0)

−δ

= lim
δ↓0

= ∂tu(1, 0).

10

Set Pϕ = {P ∈ P : EP [ϕ(B1) = E[ϕ(B1)]}. In the proof to Theorem 1.5, we have already proved
that for P ∈ Pϕ, ∂tu(1, 0) = EP [ B1
2 ϕ(cid:48)(B1)] and that ∂tu(1, 0) = supP∈Pϕ EP [G(ϕ(cid:48)(cid:48)(B1))]. We
shall just prove ∂tu(1, 0) = inf P∈Pϕ EP [G(ϕ(cid:48)(cid:48)(B1))].

By the G-martingale representation theorem, we have

u(1 − δ, 0) = ϕ(B1−δ) −(cid:82) 1−δ
u(1, 0) = ϕ(B1) −(cid:82) 1

s dBs − Kδ
zδ
0 zsdBs − K1,
t },{Kt} are non-increasing G-martingales with Kδ

0

where {Kδ

1−δ,

0 = K0 = 0. Thus

u(1 − δ, 0) − u(1, 0) = E[ϕ(B1−δ) − ϕ(B1) + K1]

= E[− 1

2 ϕ(cid:48)(cid:48)(B1−δ)(B1 − B1−δ)2 + K1] + o(δ).

For each P ∈ Pϕ,

u(1−δ,0)−u(1,0)

−δ

E[−ϕ(cid:48)(cid:48)(B1−δ)(B1 − B1−δ)2 + K1] + o(1)

= 1−2δ
≤ 1
≤ EP [G(ϕ(cid:48)(cid:48)(B1−δ))] + o(1).

2δ EP [ϕ(cid:48)(cid:48)(B1−δ)(B1 − B1−δ)2] + o(1)

EP [G(ϕ(cid:48)(cid:48)(B1))] = ∂tu(1, 0) ≤ inf
P∈Pϕ

EP [G(ϕ(cid:48)(cid:48)(B1))].

sup
P∈Pϕ

Consequently, for P ∈ Pϕ, we have ∂tu(1, 0) = EP [G(ϕ(cid:48)(cid:48)(B1))] .

Thus

(cid:3)

Remark 5.2 In [3], the authors used the similar idea to obtain the variation equation for the
cost functional associated with the stochastic recursive optimal control problem.
Corollary 5.3 Let H ∈ C2(R) with polynomial growth satisfy, for some ρ > 0,

Then we have

H(cid:48)(x) − G(H(cid:48)(cid:48)(x)) = ρH(x).

x
2

E[H(B1)] = 0.

The proof is immediate from Proposition 1.2. Actually, for P ∈ P such that EP [H(B1)] =
E[H(B1)], we have

ρE[H(B1)] = ρEP [H(B1)] = EP [

H(cid:48)(B1) − G(H(cid:48)(cid:48)(B1))] = 0.

B1
2

Below we give a direct proof.
Proof. Let X x

2 (t−s)dBs. Applying Itˆo’s formula to eρtH(X x

t ), we have

(cid:90) t
s ) − 1
2
1
2

0

s H(cid:48)(X x
X x
eρsH(cid:48)(cid:48)(X x

(cid:90) t
s ) + G(H(cid:48)(cid:48)(X x
s )d(cid:104)B(cid:105)s −

0

s )))ds

eρsG(H(cid:48)(cid:48)(X x

s ))ds.

2 x +(cid:82) t
(cid:90) t
0 e− 1
t = e− t
(cid:90) t

t ) = H(x) +

0

eρtH(X x

eρs(ρH(X x

+

eρsH(cid:48)(X x

s )dBs +

So E[H(X x

t )] = e−ρtH(x) and

0

(cid:3)

E[H(B1)] = lim
t→∞

E[H(X x

t )] = 0.

11

References

[1] Chen, Goldstein and Shao (2011) Normal Approximation by Steins Method. New York:

Springer.

[2] Denis, L., Hu, M. and Peng S.(2011) Function spaces and capacity related to a sublinear

expectation: application to G-Brownian motion paths, Potential Anal., 34: 139-161.

[3] Hu, M., Ji, S. (2015) Stochastic maximum principle for stochastic recursive optimal control

problem under volatility ambiguity, arXiv:1508.07693v1 [math.PR].

[4] Hu, M., Li, H., Wang, F. Zheng, G. (2015) Invariant and ergodic nonlinear expectations for

G-diﬀusion processes, Electronic communications in probability, 20:1-15.

[5] Peng, S. (2005) Nonlinear expectations and nonlinear Markov chains, Chin. Ann. Math.

26B(2) 159–184.

[6] Peng, S. (2005) Dynamically Consistent Nonlinear Evaluations and Expectations, arXiv:

math.PR/0501415 v1.

[7] Peng, S.(2007) G-expectation, G-Brownian Motion and Related Stochastic Calculus of Itˆo

type, Stochastic analysis and applications, 541-567, Abel Symp., 2, Springer, Berlin.

[8] Peng, S.(2007) G-Brownian Motion and Dynamic Risk Measure under Volatility Uncer-

tainty, arXiv:0711.2834v1 [math.PR].

[9] Peng, S.(2008) Multi-Dimensional G-Brownian Motion and Related Stochastic Calculus

under G-Expectation, Stochastic Processes and their Applications, 118(12): 2223-2253.

[10] Peng,

S.(2008) A New Central Limit Theorem under Sublinear Expectations,

arXiv:0803.2656v1 [math.PR].

[11] Peng, S.(2009) Survey on normal distributions, central limit theorem, Brownian motion
and the related stochastic calculus under sublinear expectations, Science in China Series A:
Mathematics, 52(7): 1391-1411.

[12] Peng, S.(2010) Nonlinear Expectations and Stochastic Calculus under Uncertainty,

arXiv:1002.4546v1 [math.PR].

[13] Song, Y.(2011) Some properties on G-evaluation and its applications to G-martingale de-

composition, Science China Mathematics, 54(2): 287-300.

[14] Song, Y.(2011) Properties of hitting times for G-martingales and their applications, Stochas-

tic Process. Appl. 121(8): 1770-1784.

[15] Song, Y.(2015) A note on G-normal distributions, Statistics and Probability Letters 106:

142-146.

[16] Stein, C. (1972). A bound for the error in the normal approximation to the distribution of
a sum of dependent random variables. In Proceedings of the Sixth Berkeley Symposium
on Mathematical Statistics and Probability (Vol. 2, pp. 586C602). Berkeley: University of
California Press.

12

