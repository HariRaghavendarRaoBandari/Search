6
1
0
2

 
r
a

 

M
7
1

 
 
]

O
L
.
s
c
[
 
 

1
v
5
2
6
5
0

.

3
0
6
1
:
v
i
X
r
a

Two-variable Logic with a Between Predicate
Andreas Krebs1, Kamal Lodaya2, Paritosh Pandya3, and
Howard Straubing4

1 Universität Tübingen, krebs@informatik.uni-tuebingen.de
2 The Institute of Mathematical Sciences, Chennai, kamal@imsc.res.in
3 Tata Institute for Fundamental Research, pandya@tifr.res.in
4 Boston College, straubin@bc.edu

Abstract

We study an extension of F O2[<], ﬁrst-order logic interpreted in ﬁnite words, in which formulas
are restricted to use only two variables. We adjoin to this language two-variable atomic formulas
that say, ‘the letter a appears between positions x and y’. This is, in a sense, the simplest
property that is not expressible using only two variables.

We present several logics, both ﬁrst-order and temporal, that have the same expressive power,
and ﬁnd matching lower and upper bounds for the complexity of satisﬁability for each of these
formulations. We also give an eﬀective necessary condition, in terms of the syntactic monoid of
a regular language, for a property to be expressible in this logic. We show that this condition is
also suﬃcient for words over a two-letter alphabet. This algebraic analysis allows us us to prove,
among other things, that our new logic has strictly less expressive power than full ﬁrst-order
logic F O[<].

Keywords and phrases automata theory, algebra, ﬁnite model theory, modal and temporal logics,
computational complexity, veriﬁcation

Introduction

1
We denote by F O[<] ﬁrst-order logic with the order relation <, interpreted in ﬁnite words
over a ﬁnite alphabet A. Variables in ﬁrst-order formulas are interpreted as positions in a
word, and for each letter a ∈ A there is a unary predicate a(x), interpreted to mean ‘the
letter in position x is a’. Thus sentences in this logic deﬁne properties of words, or, what is
the same thing, languages L ⊆ A∗. The logic F O[<] over words has been extensively studied,
and has many equivalent characterizations in terms of temporal logic, regular languages, and
the algebra of ﬁnite semigroups. (See, for instance, [17, 22] and the many references cited
therein.)

It is well known that every sentence of F O[<] is equivalent to one using only three
variables, but that the family of languages deﬁnable with two-variable sentences is strictly
smaller [6]. The fragment F O2[<], consisting of the two-variable formulas, has also been
very thoroughly investigated, and once again, there are many equivalent characterizations
[20].

The reason F O2[<] is strictly contained in F O[<] is that one cannot express ‘between-

ness’ with only two variables. More precisely, the following predicate

∃z(a(z) ∧ x < z ∧ z < y),

which asserts that there is an occurrence of the letter a strictly between x and y, is not ex-
pressible using only two variables. Let us denote this predicate, which has two free variables,
by a(x, y), and the resulting logic by FO2[<, Bet]. What properties can we express when
we adjoin these new predicates to F O2[<]? The ﬁrst obvious question to ask is whether we

© Andreas Krebs, Kamal Lodaya, Paritosh Pandya, Howard Straubing;
licensed under Creative Commons License CC-BY

Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany

2

Two-variable Logic with a Between Predicate

Complexity/Variety Ap

W

DA∗D

DA

Nonelementary

EXPSPACE

NEXPTIME

FO[<]
CLTL[U, S] FO2[<, Th],
FO2[<, Bet],
BThTL,
ThTL

, Y2n]
LTL[F, P, X2n
(binary notation)

PSPACE

LTL[U, S]

BInvTL,
InvTL

NP

FO2[<, +1]

LTL[F, P, X, Y]

FO2[<]
(unbounded alphabet)

FO2[<]
(bounded alphabet),
LTL[F, P]

Table 1 A summary of the results in this paper, in the context of the complexity and expressive
power of temporal and predicate logics studied in earlier work. The variety W heading the second
column coincides with MeDA for two-generated monoids, and we conjecture that the two varieties
are identical.

recover all of F O[<] in this way. The answer, as we shall see, is ‘no’, but we will give a
much more precise description.

The present article is a study of this extended two-variable logic. Our investigation is
centered around two quite diﬀerent themes. One theme investigates several diﬀerent logics,
based in F O[<] as well as in temporal logic LT L, for expressing this betweenness, and
establishes their expressive equivalence. We explore the complexity of satisﬁability checking
in these logics as a measure of their descriptive succinctness.

The second theme is devoted to determining, in a sense that we will make precise, the
exact expressive power of this logic. Here we draw on tools from the algebraic theory of
semigroups.

Owing to considerations of length, we will for the most part conﬁne ourselves to careful
statements of our main results, and provide only outlines of the proofs, omitting some
technical details.

In Section 2 we will give the precise deﬁnition of our logic FO2[<, Bet] (although there
is not much more to it than what we have written in this Introduction). We introduce a
related logic FO2[<, Th] which enforces quantitative constraints on counts of letters, and
we show that it has the same expressive power, although it can result in formulas that are
considerably more succinct. In addition, we introduce two temporal logics, one qualitative
and one quantitative, but again with the same expressive power as our original formulation.
In Section 3 we determine the complexity of formula satisﬁability for each of these logics.
Section 4 is devoted to a characterization of the expressive power of this logic in terms
of the algebra of ﬁnite semigroups. This builds on earlier algebraic studies of the regular
languages deﬁnable in F O2[<] [20], and makes critical use of the algebraic theory of ﬁnite

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

3

categories, as developed by Tilson [19]. We ﬁnd an eﬀective necessary condition for a
language to be deﬁnable in FO2[<, Bet]. We conjecture that this condition is also suﬃcient,
and prove that it is suﬃcient for languages over a two-letter alphabet. One consequence
is that we are able to determine eﬀectively whether a given formula of F O[<] over a two-
letter alphabet is equivalent to a formula in the new logic. We use these results to show
that FO2[<, Bet] is strictly less expressive than F O[<]. We also provide a detailed study
of the quantiﬁer alternation depth (or, what is more or less the same thing, the so-called
‘dot-depth’) of languages deﬁnable in this logic.

Table 1 gives a map of our results and compares them to those of previous related work.
Etessami et al. [4] as well as Weis and Immerman [21] have explored logics FO2[<] and
FO2[<, +1], as well as matching temporal logics and their decision complexities. Thérien
and Wilke [20] found characterizations of the expressive power of these same logics, using
algebraic methods. We ﬁnd that our new logics are more expressive but this comes at the
cost of some computational power.

Some counting extensions CLTL[U, S] of full LTL[U, S] have been studied by Laroussinie

et al. [7], and by Alur and Henziger as discrete time Metric Temporal logic [2].

Sketches of the proofs of the main results appear in Section 5.

2

Basic Properties

2.1 Deﬁnition
F O[<] is ﬁrst-order logic interpreted in words over a ﬁnite alphabet A, with a unary predicate
a(x) for each a ∈ A, interpreted to mean that the letter in position x is a. If φ is a sentence
of F O[<], then the set of words w ∈ A∗ such that w |= φ is a language in A∗, in fact a
regular language

For each a ∈ A we adjoin to this logic a binary predicate a(x, y) which is interpreted to

mean

∃z(x < z ∧ z < y ∧ a(z)).

This predicate cannot be deﬁned in ordinary ﬁrst-order logic over < without introducing
a third variable. We will investigate the fragment FO2[<, Bet], obtained by restricting to
formulas that use both the unary and binary a predicates, along with <, but use only two
variables.

There is an even simpler predicate that is not expressible in two-variable logic that we
could have adjoined: this is the successor relation y = x+1. The logic F O2[<] supplemented
by successor, which we denote by F O2[<, +1] has also been extensively studied, and the
kinds of questions that we take up here for FO2[<, Bet] have already been answered for
F O2[<, +1]. (See, for example,
Example. The successor relation y = x+1 is itself deﬁnable in FO2[<, Bet], by the formula

[4, 8, 20]).

x < y ∧ ^

a∈A

¬a(x, y).

As a result, we can deﬁne the set L of words over {a, b} in which there is no occurrence of
two consecutive b’s by a sentence of FO2[<, Bet]. We can similarly deﬁne the set of words
without two consecutive a’s. Since we can also say that the ﬁrst letter of a word is a (by
∀x(∀y(x ≤ y) → a(x)) and that the last letter is b, we can deﬁne the language (ab)∗ in

4

Two-variable Logic with a Between Predicate

FO2[<, Bet]. 1 This language is not, however, deﬁnable in FO2[<].
Example. Let L ⊆ {a, b}∗ be the language deﬁned by the regular expression

(a + b)∗bab+ab(a + b)∗.

This language is deﬁnable in FO2[<, Bet]by the sentence

∃x(∃y(x < y ∧ b(x, y) ∧ ¬a(x, y) ∧ α(y)) ∧ β(x)),

where α(y) is

and β(x) is

a(y) ∧ ∃x(x = y + 1 ∧ b(x))

a(x) ∧ ∃y(x = y + 1 ∧ b(y)).

As we shall see further on, this language is not deﬁnable in FO2[<, +1], so our new logic
has strictly more expressive power than FO2[<, +1].
Example. FO2[<, Bet] has the ability to represent an r-bit counter (modulo 2r) in a word
and to assert properties based on the counter value. This is done by having successive
substrings b0 . . . br−1 of length r, with b0 representing the least signiﬁcant bit of the counter,
separated by a marker (denoted here by letter mark). We use two letters 0 and 1 for the
bit values, which the bi will range over. The representation of an r-bit constant is described
by the O(r) size formula:

mark(x) ∧ Sucr(x) = b0 . . . br−1,

where Suci(x) = z is deﬁned by

Suc1(x) = b
Suci+1(x) = bz

def= ∃y. y = x + 1 ∧ b(y),
def= ∃y. y = x + 1 ∧ b(y) ∧ Suci(y) = z, for i > 0.

Clearly each speciﬁc number such as 0, 2r − 1 or a threshold value can be deﬁned by an
O(r) formula. After the number ends we will have a marker symbol again to begin the next
number. The formula mark(x) ∧ ¬mark(x, y) ∧ mark(y) jumps from start of one number
to the next one.

The O(r2) formula EQ below checks equality of two numbers by comparing the r bits in
succession. We use the fact that the bit string always has r bits over the letters {0, 1} and
if we do not have 0 where we expect a bit then we must have 1.

EQ(x, y) def= mark(x) ∧ mark(y) ∧^r

EQi(x, y),

i=1
EQi(x, y) def= Suci(x) = 0 ↔ Suci(y) = 0.
By small variations of this formula, we can deﬁne formulae LT, GT etc, to make
other comparisons. Incrementing the counter modulo 2r is encoded by an O(r3) formula

1 In contrast to the usual practice in model theory, we permit our formulas to be interpreted in the
empty word: every existentially quantiﬁed sentence is taken to be false in the empty word, and thus
every universally quantiﬁed sentence is true.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

5

IN C1(x, y) which converts a least signiﬁcant block of 1s to 0s, using r disjunctions of O(r2)
formulas.

i

Suci(x) = 0 ∧^
(_
(Suci(y) = 1 ∧^
^
∧(^
Suci(x) = 1 →^

k>i

j<i

Sucj(x) = 1 →
Sucj(y) = 0∧
Suck(x) = 0 ↔ Suck(y) = 0))

j<i

i

Sucj(y) = 0)

j

We can also deﬁne IN Cc(x, y) which checks that the number at position y of the word is
obtained by incrementing the number at position x by a constant c.

In contrast, it is quite diﬃcult to ﬁnd examples of languages deﬁnable in F O[<] that
are not deﬁnable in FO2[<, Bet]. Much of this paper is devoted to establishing methods for
generating such examples.

2.2 Two-variable Threshold Logic
We generalize FO2[<, Bet] as follows: Let k ≥ 0 and a ∈ A. We deﬁne (a, k)(x, y) to mean
that x < y, and that there are at least k occurrences of a between x and y. Adding these
(inﬁnitely many) predicates gives a new logic F O2[<, T h].
Examples. The language ST AIRk consists of all words w over {a, b, c} which have a
subword of the form a(a + c)∗a with at least k occurrences of a. This can be speciﬁed by
sentence ∃x∃y(x < y ∧ (a, k)(x, y) ∧ ¬b(x, y)).
Threshold logic is quite useful in specifying quantitative properties of systems. For example,
a bus arbiter circuit may have the property that if req is continuously on for 15 cycles then
there should be at least 3 occurrences of ack. This can be speciﬁed by ∀x∀y((req, 15)(x, y) →
(ack, 3)(x, y)).

Since a(x, y) is equivalent to (a, 1)(x, y), F O2[<, T h] is at least as expressive as FO2[<, Bet].

What is less obvious is that the converse is true, albeit at the cost of a large blowup in the
quantiﬁer complexity of formulas.
(cid:73) Theorem 1. Considered as language classes,

FO2[<, Bet] = F O2[<, T h].

There is a bit more to this than meets the eye: The predicates (a, k)(x, y) for k > 1
are not themselves expressible by single formulas of FO2[<, Bet], and therefore the proof of
Theorem 1 is not completely straightforward.

2.3 Temporal Logic
We denote by TL[F, P] temporal logic with two operators F and P. Atomic formulas are the
letters a ∈ A. Formulas are built from atomic formulas by applying the boolean operations
∧,∨, and ¬, and the modal operators φ 7→ Fφ, φ 7→ Pφ.
We interpret these formulas in marked words (w, i), where w ∈ A∗ and 1 ≤ i ≤ |w|. Thus
(w, i) |= a if w(i) = a, where w(i) denotes the ith letter of w. Boolean operations have the
usual meaning. We deﬁne (w, i) |= Fφ if there is some j > i such that (w, j) |= φ, and
(w, i) |= Pφ if there is some j < i with (w, j) |= φ.
We can also interpret a formula in ordinary, that is, unmarked words, by deﬁning w |= φ
to mean (w, 1) |= φ. Thus temporal formulas, like ﬁrst-order sentences, deﬁne languages

6

Two-variable Logic with a Between Predicate

in A∗. The temporal logic TL[F, P] is known to deﬁne exactly the languages deﬁnable in
F O2[<] [4, 20].

We now deﬁne new temporal logics by modifying the modal operators F and P with
threshold constraints—these are versions of the between predicates a(x, y) and (a, k)(x, y)
that we introduced earlier. Let B ⊆ A. A threshold constraint is an expression of the
form #B ∼ c, where c ≥ 0, and ∼ is one of the symbols {<,≤, >,≥, =}. Let w ∈ A∗ and
1 ≤ i < j ≤ |w|. We say that (w, i, j) satisﬁes the threshold constraint #B ∼ c if

|{k : i < k < j and w(k) ∈ B}| ∼ c.

We can combine threshold constraints with boolean operations ∧,∨,¬. We deﬁne satisfaction
of a boolean combination of threshold constraints in the obvious way–that is, w(i, j) satisﬁes
g1 ∨ g2 if and only if (w, i, j) satisﬁes g1 or g2, and likewise for the other boolean operations.
If g is a boolean combination of threshold constraints, then our new operators Fg and
Pg are deﬁned as follows: (w, i) |= Fgφ if there exists j > i such that (w, i, j) satisﬁes g and
(w, j) |= φ, (w, i) |= Pgφ if and only if there exists j < i such that (w, j, i) satisﬁes g and
(w, j) |= φ.
Examples.
We can express Fφ with threshold constraints as F#∅=0φ.
We use X to denote the ‘next’ operator: (w, i) |= Xφ if and only if (w, i + 1) |= φ. We can
express this with threshold constraints by F#A=0φ.
We can deﬁne the language (ab)+ over the alphabet {a, b} as the conjunction of several
subformulas: a ∧ Xb says that the ﬁrst letter is a and the second b. ¬F(a ∧ Xa) says that
no occurrence of a after the ﬁrst letter is immediately followed by another a, and similarly
we can say that no occurrence of b is followed immediately by another b. The formula
F(b ∧ ¬X(a ∨ b)) says that the last letter is b.
It is useful to have boolean combinations of threshold constraints. The language ST AIRk
given in Section 2.2 can be deﬁned by F(F#a=k∧#b=0 true).

We denote by BThTL[F, P] temporal logic with these modiﬁed operators Fg and Pg, where
g is a boolean combination of threshold constraints. We also deﬁne several fragments of
BThTL[F, P]: In ThTL[F, P] we restrict the constraints g to be atomic threshold constraints,
In InvTL[F, P] we restrict to constraints of the form
rather than boolean combinations.
#B = 0–we call these invariant constraints and in BInvTL[F, P] to boolean combinations of
such constraints.
(cid:73) Theorem 2. The logics ThTL[F, P], BThTL[F, P], InvTL[F, P], BInvTL[F, P], F O2[<
, T h], and FO2[<, Bet] all deﬁne the same family of languages.

Complexity of Satisﬁability

3
Given a formula in one of these logics, what is the computational complexity of determining
whether it has a model, that is, whether the language it deﬁnes is empty or not? This is
the satisﬁability problem for the logic. To determine this, we require some way to measure
the size of the input formula. For formulas containing threshold constraints, we code the
threshold value in binary, so that mention of a threshold constant c contributes dlog2 ce
to the size of the formula. Mention of a subalphabet B contributes |B| to the size of the
formula.

In the veriﬁcation literature ([4] is relevant for this paper) the syntax allows a ﬁnite set of
propositional letters P V which may or may not simultaneously hold at a position of a word.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

7

This allows us to compactly talk about large alphabets. One can think of the alphabet A
as the set of valuations 2P V to get ﬁnite word models over A. Thus the alphabet A is given
a boolean algebra structure and subsets of A are speciﬁed using propositions over P V . Our
results below hold for bounded and unbounded alphabets, which may be explicitly speciﬁed
or symbolically speciﬁed by propositions.
(cid:73) Theorem 3. Satisﬁability of the temporal logics InvTL (with invariant constraints) and
BThTL (with threshold constraints) is complete for PSPACE and EXPSPACE, respectively.
(cid:73) Theorem 4. Satisﬁability of the two-variable logics FO2[<, Bet] and FO2[<, Th] is EXPSPACE-
complete.

Algebraic Characterization

4
4.1 Background on ﬁnite monoids and varieties
For further background on the basic algebraic notions in this section, see Pin [10].

A monoid is a set together with an associative multiplication (that is, it is a semigroup)

and a multiplicative identity 1.

All of the languages deﬁned by sentences of F O[<] are regular languages. Our character-
ization of languages in FO2[<, Bet] is based on properties of the syntactic monoid M(L) of
a regular language L. This is the transition monoid of the minimal deterministic automaton
recognizing L, and therefore a ﬁnite monoid. Equivalently, M(L) is the smallest monoid
M that recognizes L in the following sense: There is a homomorphism φ : A∗ → M and a
subset X ⊆ M such that L = φ−1(X).

Let M be a ﬁnite monoid. An idempotent e ∈ M is an element satisfying e2 = e. If
m ∈ M, then there is some k ≥ 1 such that mk is idempotent. This idempotent power of m
is unique, and we denote it by mω.

A ﬁnite monoid is aperiodic if it contains no nontrivial groups, equivalently, if it satisﬁes
the identity x · xω = xω for all x ∈ M. We denote the class of aperiodic ﬁnite monoids
by Ap. Ap is a variety of ﬁnite monoids: this means that it is closed under ﬁnite direct
products, submonoids, and quotients.

A well-known theorem, an amalgam of results of McNaughton and Papert [9] and of
Schützenberger [12], states that L ⊆ A∗ is deﬁnable in F O[<] if and only if M(L) ∈ Ap. This
situation is typical: Under very general conditions, the languages deﬁnable in fragments of
F O[<] can be characterized as those whose syntactic monoids belong to a particular variety
V of ﬁnite monoids.(See Straubing [18].)
If M is a ﬁnite monoid and m1, m2 ∈ M, we write m1 ≤J m2 if m1 = sm2t for some
s, t ∈ M. This is a preorder, the so-called J -ordering on M. If e ∈ M is idempotent, then
we denote by Me the submonoid of M generated by elements m such that e ≤J m. Observe
that eMee is a subsemigroup of Me, in fact a monoid whose identity element is e.

If V is a variety of ﬁnite monoids, then we can form a new variety MeV as follows:

MeV = {M : eMee ∈ V for all e2 = e ∈ M}.

(cid:73) Proposition 5. MeV is a variety of ﬁnite monoids.

Let I denote the variety consisting of the trivial one-element monoid alone. We deﬁne

the class

DA = MeI.

8

Two-variable Logic with a Between Predicate

That is, DA consists of those ﬁnite monoids M for which eMee = e for all idempotents
e ∈ M. By Proposition 5, DA is a variety of ﬁnite monoids. The variety DA was introduced
by Schützenberger [13] and it ﬁgures importantly in work on two-variable logic. Thérien and
Wilke showed that a language L is deﬁnable in F O2[<] if and only if M(L) ∈ DA [20].
Example. Consider the language L ⊆ {a, b}∗ consisting of all words whose ﬁrst and last
letters are the same. The syntactic monoid of L contains ﬁve elements

M(L) = {1, (a, a), (a, b), (b, a), (b, b)},

with multiplication given by (c, d)(c0, d0) = (c, d0), for all c, d, c0, d0 ∈ {a, b}. Observe that
every element of M(L) is idempotent. For every e 6= 1, eM(L)e = e, and if e = 1, then
M(L)e = 1. Thus, M(L) ∈ DA. The logical characterization then tells us that L is deﬁned
by a sentence of F O2[<]. Indeed, L is deﬁned by

∃x(∀y(x ≤ y) ∧ ∃y(∀x(x ≤ y) ∧ (a(x) ↔ a(y)))).

Example. Consider the language (ab)∗. We claimed earlier that it is not deﬁnable in
F O2[<]. We can prove this using the algebraic characterization of the logic. The elements
of the syntactic monoid M are

1, a, b, ab, ba, 0.

The multiplication is determined by the rules aba = a, bab = b, and a2 = b2 = 0. Then ab
and ba are idempotents, and Mab = Mba = M. Thus ab · Mab · ab = {ab, 0}, which shows
that M /∈ DA, and thus (ab)∗ is not deﬁnable in F O2[<]..
Example. Now consider the language given by the regular expression (a+b)∗bab+ab(a+b)∗.
We saw earlier that it is deﬁnable in FO2[<, Bet], and claimed that it could not be deﬁned in
FO2[<, +1]. Thérien and Wilke [20] also give an algebraic characterization of FO2[<, +1]:
Let S be subsemigroup of the syntactic monoid of L generated by nonempty words (the
syntactic semigroup of L∩A+). L is deﬁnable in FO2[<, +1] if and only if for each idempotent
e ∈ S, the monoid N = eSe is in DA. For the language under discussion, let us denote the
image of a word w in the syntactic monoid by w. Then e = b is idempotent, and f = baab
is an idempotent in N = eSe. Let s = bab. Then s ∈ eSe, and f sf = f, so s ∈ Mf . We now
have f sf = f 6= f ssf, since f ssf = babab is the zero of N. Thus f Mf f contains more than
one element, so eSe /∈ DA. Consequently this language, while deﬁnable in FO2[<, Bet],
cannot be deﬁned in FO2[<, +1].

4.2 The main result
(cid:73) Theorem 6. Let L ⊆ A∗. If L is deﬁnable in FO2[<, Bet] then M(L) ∈ MeDA. Further,
if |A| = 2, and M(L) ∈ MeDA, then L is deﬁnable in FO2[<, Bet].

We conjecture that suﬃciency of the condition holds for all ﬁnite alphabets, not just those
with two letters. We can prove from rather abstract principles that there is some variety
W of ﬁnite monoids that characterizes deﬁnability in FO2[<, Bet] in this way. Our results
imply that W coincides with MeDA for monoids generated by two elements. The theorem
provides an eﬀective method for determining whether a given language over A = {a, b}
(given, say, by a ﬁnite automaton that recognizes it, or by a regular expression) is deﬁnable
in FO2[<, Bet], since we can compute the multiplication table of the syntactic monoid, and
check whether it belongs to MeDA.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

9

Example. In our example above, where L = (ab)∗, all the submonoids eMee are either
trivial, or are two-element monoids isomorphic to {0, 1}, which is in DA. Thus (ab)∗ is
deﬁnable in FO2[<, Bet], as we saw earlier by construction of a deﬁning formula.

The following corollary to our main theorem answers our original question of whether
F O[<] has strictly more expressive power than FO2[<, Bet]. To prove it, we need only
calculate the syntactic monoid of the given language, and verify that it is in Ap but not in
MeDA.
(cid:73) Corollary 7. The language given by the regular expression

is deﬁnable in F O[<] but not in FO2[<, Bet].

(a(ab)∗b)∗

4.3 Alternation depth
We are interested in how FO2[<, Bet] sits inside F O[<]. One way to measure the complexity
of a language in F O[<] is by the smallest number of alternations of quantiﬁers required in
a deﬁning formula, that is the smallest k such that the language is deﬁnable by a boolean
combination of sentences of Σk[<]. We will call this the alternation depth of the language.
(This is closely related to the dot-depth, which can be deﬁned the same way, but with slightly
diﬀerent base of atomic formulas.)
(cid:73) Theorem 8. The alternation depth of languages in FO2[<, Bet] is unbounded. If |A| = 2,
then the alternation depth of languages in A∗ deﬁnable in FO2[<, Bet] is bounded above by
3.

For alphabets of more than two letters, we conjecture that the alternation depth is also

bounded by a linear function of |A|.

We stress that the alternation depth is measured with respect to arbitrary ﬁrst-order

sentences, not the variable-restricted sentences of FO2[<, Bet].

5 Outlines of the proofs
FO2[<, Bet]
5.1 A game characterization of FO2[<, Bet]
FO2[<, Bet].
We write (w1, i1) ≡k (w2, i2) if these two marked words satisfy exactly the same formulas
of FO2[<, Bet] with one free variable of quantiﬁer depth no more than k.
We overload this notation, and also write w1 ≡k w2 if w1 and w2 are ordinary words
Let k ≥ 0. The game is played for k rounds in two marked words (w1, i1) and (w2, i2)
with a single pebble on each word. At the start of the game, the pebbles are on the marks
i1 and i2. In each round, the pebble is moved to a new position in both words, producing
two new marked words.

that satisfy exactly the same sentences of FO2[<, Bet] with quantiﬁer depth ≤ k.

Suppose that at the beginning of a round, the marked words are (w1, j1) and (w2, j2).
Player 1 selects one of the two words and moves the pebble to a diﬀerent position. Let’s say
he picks w1, and moves the pebble to j0
1. Player 2 moves the pebble to a new
position j0
(i) The moves are in the same direction: j1 < j0
(ii) The letters in the destination positions are the same: w1(j0

2 in w2. This response is required to satisfy the following properties:

1, with j1 6= j0

1 iﬀ j2 < j0
2.

1) = w2(j0
2).

10

Two-variable Logic with a Between Predicate

(iii) The set of letters jumped over is the same—that is, assuming j1 < j0
1:

{a ∈ A : w1(k) = a for some j1 < k < j0
1} =
{a ∈ A : w2(k) = a for some j2 < k < j0
2}.

game.

Player 2 wins the 0-round game if w1(i1) = w2(i2). Otherwise, Player 1 wins the 0-round

Player 2 wins the k-round game for k > 0 if she makes a legal response in each of k

successive rounds, otherwise Player 1 wins.

The following theorem is the standard result about Ehrenfeucht-Fraïssé games adapted

to this logic.
(cid:73) Theorem 9. (w1, i1) ≡k (w2, i2) if and only if Player 2 has a winning strategy in the
k-round game in the two marked words.

We now deﬁne the k-round game in ordinary unmarked words w1, w2 ∈ A∗. Player 1
begins in the ﬁrst round by placing a pebble on a position in one of the two words, and
Player 2 must respond on a position in the other word containing the same letter. Thereafter,
they play the game in the two marked words that result for k − 1 rounds. The following is
a direct consequence of the preceding theorem.
(cid:73) Corollary 10. Player 2 has a winning strategy in the k-round game in w1 and w2 if and
only if w1 ≡k w2.

5.2 Proof of Theorem 1
We introduce a game characterizing F O2[<, T h]. Let θ be a function from A to the positive
integers. We consider formulas in F O2[<, T h] in which for all a ∈ A, every occurrence of
the predicate (a, k)(x, y) has k ≤ θ(a). Let’s call these θ-bounded formulas.
The rules of the game are the same as those for the FO2[<, Bet] game, with this diﬀerence:
At each move, for each a ∈ A, the number m1 of a’s jumped by Player 1 must be equivalent,
threshold θ(a), to the number m2 of a’s jumped by Player 2. That is, either m1 and m2 are
both greater than or equal to θ(a), or m1 = m2. Observe that the game for FO2[<, Bet] is
the case θ(a) = 1 for all a ∈ A.

Let us deﬁne, for marked words (w1, i1), (w2, i2), (w1, i1) ≡θ

k (w2, i2) if and only if they
satisfy exactly the same θ-bounded formulas of quantiﬁer depth less than or equal to k. As
with the case of FO2[<, Bet], we also have a version of both the game and the equivalence
relation for ordinary words.

k (w2, i2), and likewise for ordinary words.

k . What we will show precisely is this: ≡θ

It is easy to show that the analogues of Theorem 9 and Corollary 10 hold in this more
general setting: Player 2 has a winning strategy in the k-round game in (w1, i1), (w2, i2) if
and only if (w1, i1) ≡θ
Let θ, θ0 be two functions from A to the natural numbers that diﬀer by one in the following
sense: θ0(b) = θ(b) + 1 for exactly one b ∈ A, and θ0(a) = θ(a) for all a 6= b. Obviously ≡θ0
k is
ﬁner than ≡θ
k . We prove reﬁnement
by a simple game argument, showing that if Player 2 has a winning strategy in the 2k-move
θ game in (w1, w2) then she has a strategy in the k-move θ0 game in the same two words.
This will give the desired result, because any threshold function θ can be built from the
base threshold function that assigns 1 to each letter of the alphabet by a sequence of steps
in which we add 1 to the threshold of each letter. So it follows by induction that for any θ,
≡θ
k-class is deﬁnable
by a FO2[<, Bet] sentence, although the quantiﬁer depth of this sentence is exponential in
the thresholds used.

k is reﬁned by ≡k·2r , where r =P

a∈A θ(a) − 1. In particular, each ≡θ

2k reﬁnes ≡θ0

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

11

So given a ﬁxed F O2[<, T h] sentence φ there is a threshold such that the sentence is
θ-bounded. Let k be the quantiﬁer depth of φ, then the sentence cannot distinguish words
that are in the same equivalence class with respect to ≡θ
k. As there are only ﬁnitely many θ-
bounded sentence of quantiﬁer depth at most k, there are only ﬁnitely many such equivalence
classes. By the argument above we can ﬁnd a FO2[<, Bet] sentence for each equivalence class
accepted by φ and the disjunction of these will be a sentence in FO2[<, Bet] that accepts
the same models as φ.

Observe that this argument applies to both ordinary words and marked words, and thus
each formula of F O2[<, T h] with one free variable can similarly be replaced by an equivalent
formula of FO2[<, Bet].

5.3 Proof of Theorem 2
In terms of language classes, we obviously have

and

InvTL[F, P] ⊆ BInvTL[F, P] ⊆ BThTL[F, P],

InvTL[F, P] ⊆ ThTL[F, P] ⊆ BThTL[F, P].

So it is enough to show that BThTL[F, P] ⊆ InvTL[F, P]. In performing these translations,
we will only discuss the future modalities, since the past modalities can be treated the same
way.

We can directly translate any formula in BThTL[F, P] into an equivalent formula of
F O2[<, T h] with a single free variable x: A formula Fgψ, where g is a boolean combination
of threshold constraints, is replaced by a quantiﬁed formula ∃y(y > x ∧ α ∧ β(y)), where α
is a boolean combination of formulas (a, k)(x, y) and β is the translation of ψ.

We know from Theorem 1 that any formula of F O2[<, T h] can in turn be translated into
an equivalent formula of FO2[<, Bet]. Furthermore, FO2[<, Bet] is equivalent to BInvTL[F, P]:
A simple game argument shows that equivalence of marked words with respect to BInvTL[F, P]
formulas of modal depth k is precisely the relation ≡k of equivalence with respect to
FO2[<, Bet] formulas with quantiﬁer depth k.
So it remains to show that BInvTL[F, P] ⊆ InvTL[F, P]: We do this by translating Fgφ,
where g is a boolean combination of constraints of the form #B = 0, into a formula that
uses only single constraints of this form. We can rewrite the boolean combination as the
disjunction of conjunctions of constraints of the form #{a} = 0 and #{a} > 0. Since, easily,
Fg1∨g2 φ is equivalent to Fg1φ ∨ Fg2 φ, we need only treat the case where g is a conjunction
of such constraints. We illustrate the general procedure for translating such conjunctions
with an example. Suppose A includes the letters a, b, c. How do we express Fgφ, where g is
(#{a} = 0) ∧ (#{b} > 0) ∧ (#{c} > 0)? The letters b and c must appear in the interval
between the current position and the position where φ holds. Suppose that b appears before
c does. We write this as

F#{a,b,c}=0(b ∧ F#{a,c}=0(c ∧ F#{a}=0φ)).

We take the disjunction of this with the same formula in which the roles of b and c are
reversed.

5.4 Proof of Theorem 3
Satisﬁability of InvTL[F, P] is PSPACE-hard [15] since it includes LTL[F, P, X, Y]. We ob-
serve that BInvTL[F, P] can be translated into LTL[U, S] in polynomial time, hence its sat-

12

Two-variable Logic with a Between Predicate

isﬁability is PSPACE-complete [15]. Using a threshold constant 2n, written in binary in the
formula with size n, the 2n-iterated Next operator X(2n) can be expressed in ThTL[F, P],
so we obtain that its satisﬁability is EXPSPACE-hard [2]. By an exponential transla-
tion of BThTL[F, P] into BInvTL[F, P](the proof of Theorem 1 shows that such translation
exists), or alternately by a polynomial translation into CLTL[U, S][7]), its satisﬁability is
EXPSPACE-complete.

5.5 Proof of Theorem 4
We begin by reducing the exponential Corridor Tiling problem to satisﬁability of FO2[<, Bet].
It is well known that this problem is EXPSPACE-complete [5].

5.5.0.1 The exponential Corridor Tiling problem:
An instance M is given by (T, H, V, s, f, n) where T is a ﬁnite set of tile types with s, f ∈ T,
the horizontal and vertical tiling relations H, V ⊆ T × T, and n is a natural number. A
solution of the 2n sized corridor tiling problem is a natural number m and map π from the
grid of points {(i, j) | 0 ≤ i ≤ 2n, 0 ≤ j < m} to T such that:
π(0, 0) = s, π(n − 1, m − 1) = f and for all i, j on the grid,
(π(i, j), π(i, j + 1)) ∈ V and (π(i, j), π(i + 1, j)) ∈ H.
(cid:73) Lemma 11. Satisﬁability of the two-variable logic FO2[<, Bet] is EXPSPACE-hard.
Proof. Given an instance M as above of a Corridor Tiling problem, we encode it as a
sentence φ(M) of size poly(n) with a modulo 2n counter C(x) encoded serially with n + 1
letters as in the example in Section 2.1. The marker now represents a tile and a colour from
red, blue and green (requiring subalphabet size 3|T|). Thus the 2n × m tiling is represented
by a word of length m(n + 1)2n over an alphabet of size 3|T| + 2. The claim is that M has
a solution iﬀ φ(M) is satisﬁable.
The sentence φ(M) ∈ FO2[<, Bet] is a conjunction of the following properties. The key
idea is to cyclically use monadic predicates red(x), green(x), blue(x) for assigning colours to
rows.

Each marker position has exactly one tile and one colour.
The starting tile is s, the initial colour is red, the initial counter bits read 0n, the last
tile is f.
Tile colour remains same in a row and it cycles in order red, green, blue on row change.
The counter increments modulo 2n in consecutive positions.
For horizontal compatibility we check:
∀x∀y. mark(x) ∧ mark(y) ∧ ¬mark(x, y) →

_

t1(x) ∧ t2(y)

(t1,t2)∈H

.

For vertical compatibility, we check that x, y are in adjacent rows by invariance of lack of
one colour. We check that x and y are in the same column by checking that the counter
value (which encodes column number) is the same:

∀x∀y. (x < y)∧(¬red(x, y)∨¬blue(x, y)∨¬green(x, y))∧ EQ(x, y) →_

t1(x)∧

(t1,t2)∈V

t2(y).
It is easy to see that we can eﬀectively translate an instance M of the exponential
corridor tiling problem into φ(M) in time polynomial in n. The translation preserves satisﬁ-
ability. Hence, by reduction, satisﬁability of FO2[<, Bet] over bounded as well as unbounded
(cid:74)
alphabets is EXPSPACE-hard.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

13

(cid:73) Lemma 12. There is a satisﬁability-preserving polynomial time reduction from the logic
FO2[<, Th] to the logic FO2[<, Bet].

give

a

polytime

from

Proof. We
to
FO2[<, Bet] which preserves satisﬁability. We consider in the extended syntax a thresh-
old constraint #a(x, y) = k where a is a letter or a proposition and k is a natural number.
The key idea of the reduction is illustrated by the following example.

reduction

FO2[<, Th]

For each threshold constraint g of the form #a(x, y) = 2r, we specify a global modulo 2r
counter Cg using monadic predicates p1(x), . . . , pr(x). (This requires a symbolic alphabet
where several such predicates may be true at the same position.) By “global” we mean that
the counter Cg has value 0 at the beginning of the word and it increments whenever a(x) is
true. This is achieved using the formula:

∀x, y. y = x + 1 → (a(x) → IN Cg(x, y)) ∧ (¬a(x) → EQg(x, y))

Also, we have three colour predicates redg(x), blueg(x) and greeng(x) where the colour at
the beginning of the word is redg, and we change the colour cyclically each time the counter
Cg resets to zero by overﬂowing. As in the proof of Lemma 11, invariance of lack of one
colour and the fact that x, y have diﬀerent colours ensures that the counter overﬂows at most
once. We replace the constraint g of the form #a(x, y) = 2r by an equisatisﬁable formula:

x < y ∧ EQg(x, y) ∧ #a(x, y) > 0∧
(¬redg(x, y) ∨ ¬blueg(x, y) ∨ ¬greeng(x, y))

More generally, we deﬁne a polynomial sized quantiﬁer free formula IN Cg,c(x, y) for any
given constant c with 2r−1 < c ≤ 2r using propositions p1, . . . , pr and three colour predicates.
The formula asserts that #a(x, y) + c = 2r. Using this we can encode the constraint
#a(x, y) = 2r − c for any c. Similarly to EQg(x, y), we can also deﬁne formulae LTg(x, y) to
denote that its counter Cg(x) < Cg(y), GTg(x, y) to denote that Cg(x) > Cg(y), etc. Hence
any form of threshold counting predicate can be replaced by an equisatisﬁable formula, with
all these global counters running from the beginning of the word to the end. Thus we have
(cid:74)
a polynomially sized equisatisﬁable reduction from FO2[<, Th] to FO2[<, Bet].

To complete the proof of Theorem 4, the upper bound for FO2[<, Th] comes from Lemma
12, an exponential translation from FO2[<, Bet] to BInvTL[F, P] using an order type argu-
ment similar to [4] (our Theorem 2 also points to this equivalence), and the PSPACE upper
bound for BInvTL[F, P] (Theorem 3).

5.6 Proof of necessity in Theorem 6
Here we outline the proof of the direction of Theorem 6 stating that every language deﬁn-
able in FO2[<, Bet] has its syntactic monoid in MeDA. This is all we will need to prove
Corollary 7 and the ﬁrst assertion of Theorem 8.

We ﬁrst use a game argument to prove the following fact:

(cid:73) Lemma 13. Lef k ≥ 0, A, B ﬁnite alphabets, and f : B∗ → A∗ a monoid homomorphism.
Let w1, w2 ∈ B∗. If w1 ≡k w2, then f(w1) ≡k f(w2).

Now let L ⊆ A∗ be deﬁnable by a sentence of FO2[<, Bet]. L is a union of ≡k-classes
for some k, and thus L is recognized by the quotient monoid N = A∗/ ≡k, so M(L) is a
homomorphic image of this monoid. Consequently, it is suﬃcient to show that N itself is

14

Two-variable Logic with a Between Predicate

a member of the variety MeDA. We denote by ψ : A∗ → N the projection morphism onto
this quotient.

Take e = e2 ∈ N and x, y ∈ eNee. We will show

(xy)ωx(xy)ω = (xy)ω.

This identity characterizes the variety DA (see, for example Diekert, et al. [3]), so this will
prove N ∈ MeDA, as required. We can write

where each mi and m0

x = em1 ··· mre, y = em0
j is ≤J -above e. Thus we have

1 ··· m0
se,

e = n2i−1min2i = n2r+2j−1m0

jn2r+2j,

for some n1, . . . n2r+2s ∈ N.

Now let B be the alphabet

{a1, . . . , ar, b1, . . . , bs, c1, . . . , c2r+2s},

We deﬁne a homomorphism φ : B∗ → N by mapping each ai to mi, bj to m0
j, and ck to nk.
Since ψ : A∗ → N is onto, we also have a homomorphism f : B∗ → A∗ satisfying ψ ◦ f = φ.
We deﬁne words v, a, b, XS,T ∈ B∗, where S, T > 0, as follows:

rY

sY

v =

c2i−1aic2i ·

c2i−1bi−rc2i,

i=r+1

i=1
a = a1 ··· ar, b = b1 ··· br,
XS,T = (vSavSbvS)T .

Observe that

φ(v) = e, φ(XS,T ) = (xy)T , φ(a) = m1 ··· mr, φ(b) = m0

1 ··· m0
s.

Since all languages recognized by N are deﬁnable in F O[<], N is aperiodic, and thus for
suﬃciently large values of T, we have φ(XS,T ) = (xy)ω. Thus for suﬃciently large T and all
S we have

φ(XS,T XS,T ) = (xy)ω(xy)ω = (xy)ω,

By Lemma 14 (proved next),

φ(XS,T aXS,T ) = (xy)ωx(xy)ω.

Then by Lemma 13,

XS,T XS,T ≡k XS,T aXS,T .

f(XS,T XS,T ) ≡k f(XS,T aXS,T ).

So

(xy)ω = φ(XS,T XS,T )

= ψ(f(XS,T XS,T ))
= ψ(f(XS,T aXS,T ))
= φ(XS,T aXS,T )
= (xy)ωx(xy)ω,

as claimed.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

15

5.7 Proof of Lemma 14
The essential idea is to show that a certain identity is satisﬁed deﬁning this variety of ﬁnite
monoids, which we do by application of our game characterization of F O2[<, Inv].

We begin by considering an alphabet B of the form

B = {a1, . . . , ar, b1, . . . , bs, c1, . . . , ct},

where t = 2r + 2s. Let v ∈ B∗ be the word

c1a1c2 · c3a2c4 ··· c2r−1arc2r · c2r+1b1c2r+2 ··· c2r+2s−1bsc2r+2s.

Let R > 0. We will build words by concatenating the factors
a = a1 ··· ar, b = b1 ··· br, vR.

For example, with R = 4, two such words are

v4av4bv8av4av12, v4av4bav4av12.

If the ﬁrst and last factors of such a word are vR, and if two consecutive factors always
include at least one vR, then we call it an R-word. The ﬁrst word in the example above is a
4-word, but the second is not, because of the consecutive factors b and a. In what follows,
we will concern ourselves exclusively with R-words. The way in which we have deﬁned the
word v ensures that the factorization of an R-word in the required form is unique.

Let m ≥ 0, and R > 2m. We’ll deﬁne special factors in R-words that we call m-
neighborhoods. One kind of m-neighborhood is a factor of the form vmavm or vmbvm, where
the a or b is one of the original factors used to build the word. In addition, we say that the
preﬁx vm and suﬃx vm are also m-neighborhoods. So, for example, the 1-neighborhoods in
the 4-word in the example above are indicated here by underlining:

v · v2 · vav · v2 · vbv · v6 · vav · v2 · vav · v10 · v.

The condition R > 2m ensures that m-neighborhoods are never directly adjacent, so
that every position belongs to at most one m-neighborhood, and some of the v factors are
contained in no m-neighborhood.
Consider two marked words (w1, i1), (w2, i2) where w1, w2 are R-words. We say these
marked words are ≡m0 -equivalent if w1(i1) = w2(i2), and if either i1 and i2 are in the same
position in identical m-neighborhoods, or if neither i1 nor i2 belongs to a neighborhood. For
instance, if m = 2, and i1 is on the third position of a 2-neighborhood v2av2 in w1, then
i2 will be on the third position of a 2-neighborhood v2av2 of w2. If m = 0, then we only
require w1(i1) = w2(i2), so ≡0

0 equivalence is the same as ≡0-equivalence.

We now play our game in marked words (w1, i1), (w2, i2), where w1, w2 are R-words. We
add the rule that at the end of every round, the two marked words (w1, j1) and (w2, j2) are
≡m0 -equivalent. If Player 2 has a winning strategy in the k-round game with this additional
rule, we say that the starting words (w1, i1) and (w2, i2) are ≡m
k -equivalent. Once again,
the case m = 0 corresponds to ordinary ≡k-equivalence.

We will call this stricter version of the game the m-enhanced game. As with the original
game, we can deﬁne a version of the m-enhanced game for ordinary (that is, unmarked) R-
words: In the ﬁrst round, Player 1 places his pebble on a position in either of the words,
and Player 2 responds so that the resulting marked words are ≡m0 -equivalent. Play then

16

Two-variable Logic with a Between Predicate

proceeds as described above for k − 1 additional rounds. We write w1 ≡m
a winning strategy in this k-round m-enhanced game.

k w2 if Player 2 has

Let S, T > 0, and let XS,T denote the S-word

(vSavSbvS)T .

We claim:

(cid:73) Lemma 14. For each m ≥ 0, k ≥ 1, there exists R such that if S, T ≥ R,

XS,T XS,T ≡m

k XS,T aXS,T .

Proof. We prove this by induction on k, ﬁrst considering the case k = 1 with arbitrary
m ≥ 0. Choose R > 2m, and S, T ≥ R. If Player 1 plays in either word inside one of the
factors XS,T , then Player 2 might try to simply mimic this move in the corresponding factor
XS,T in the other word. This works unless Player 1 moves near the center of one of the two
words. For example, if Player 1 moves in the ﬁnal position of the ﬁrst XS,T in XS,T XS,T , then
this position is contained inside a factor v and does not belong to any m-neighborhood, but
the corresponding position in the other word belongs to a neighborhood of the form vmavm,
so the response is illegal. Of course we can solve this problem: XS,T itself contains factors v
that do not belong to any m-neighborhood (because R > 2m). Conversely, if Player 1 moves
anywhere in the central m-neighborhood vmavm in XS,T aXS,T then Player 2 can ﬁnd an
identical neighborhood inside XS,T and reply there.
Now let k ≥ 1 and suppose that the Proposition is true for this ﬁxed k and all m ≥ 0.
We will show the same holds for k + 1. Let m ≥ 0. Then by the inductive hypothesis, there
exist S, T such that

XS,T XS,T ≡m+1

k XS,T aXS,T .

We will establish the proposition by showing
XS,T +1XS,T +1 ≡m

k+1 XS,T +1aXS,T +1.

Observe that

XS,T +1XS,T +1 = XS,1(XS,T XS,T )XS,1,
XS,T +1aXS,T +1 = XS,1(XS,T aXS,T )XS,1.

We will call the factors XS,1 occurring in these two words the peripheral factors; the remain-
ing letters make up the central regions. We prove the proposition by presenting a winning
strategy for Player 2 in the (k + 1)-round m-enhanced game in these two words.

For the ﬁrst k rounds, Player 2’s strategy is as follows:
If Player 1 moves into either of the peripheral factors in either of the words, Player
2 responds at the corresponding position of the corresponding peripheral factor in the
other word.
If Player 1 moves from a peripheral factor into the central region of one word, Player
2 treats this as the opening move in the k-round (m + 1)-enhanced game in the central
regions, and responds according to her winning strategy in this game.
If Player 1 moves from one position in the central region of a word to another position
in the central region, Player 2 again responds according to her winning strategy in the
k-round (m + 1)-enhanced game in the central regions.

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

17

We need to show that each move in this strategy is actually a legal move in the game—
that in each case the sets of letters jumped by the two players are the same, and that the
m-neighborhoods match up correctly. It is trivial that the m-neighborhoods match up—in
fact, the (m + 1)-neighborhoods do, so we concentrate on showing that the sets of jumped
letters are the same.

This is clearly true for moves that remain within a single peripheral factor or move from
one peripheral factor to another. What about the situation where Player 1 moves from a
peripheral factor to the central region? We can suppose without loss of generality that the
move begins in the ith position of the left peripheral factor in one word, and jumps right to
the jth position of the central region of the the word. If j ≤ |v|, then this move is within
an m-neighborhood of the central factor, namely the preﬁx of the central factor of the form
vm, so Player’s 2 reply will be at the identical position in the corresponding neighborhood,
and thus at position j of the central factor in the other word. Thus the two moves jumped
over precisely the same set of letters. If j > |v|, then Player 1’s move jumps over all the
letters of v. Since Player 2’s response, owing to the condition on neighborhoods, cannot be
within the ﬁrst |v| letters of the central factor of the other word, her move too must jump
over all the letters of v. The same argument applies to moves from the central region into a
peripheral factor.

This shows that Player 2’s strategy is successful for the ﬁrst k rounds, but we must also
show that Player 2 can extend the winning strategy for one additional round. If after the
ﬁrst k rounds, the two pebbles are in peripheral factors, then Player 1’s next move is either
within a single peripheral factor, from one peripheral factor to another, or from a peripheral
factor into the central region. In all these cases Player 2 responds exactly as she would have
during the ﬁrst k rounds. As we argued above, this response is a legal move.

If Player 1 moves from the central region to one of the peripheral factors, Player 2 will
move to the same position in the corresponding peripheral factor in the other word. Again,
we argue as above that this is a legal move.

The crucial case is when Player 1’s move is entirely within one of the central factors. Now
we can no longer use the winning strategy in the game in the central factors to determine
Player 2’s response, because she has run out of moves. We may suppose, without loss of
generality, that Player 1’s move is toward the left. We consider whether or not the set of
letters that Player 1 jumps consists of all the letters in B. If it does, then Player 2 can just
locate a matching neighborhood somewhere in the left peripheral factor in the other word
and move there. In the process, Player 2 also jumps to the left over all the letters of B.

What if Player 1 jumps over a proper subset of the letters of B? Player 2 responds by
moving the same distance in the same direction in the other word. Why does this work?
After k rounds, the pebbles in the two words must be on the same letters and in the same
positions within matching (m + 1)-neighborhoods, or outside of any (m + 1)-neighborhood.
Thus we cannot have the situation where, for example, the pebble in one word is on a letter
bi within a factor b, and in the other word on the same letter bi within a factor v. If Player
1 moves the pebble from a factor v into a factor b or a—let us say b— then the original
position of the pebble was within a 1-neighborhood. Therefore Player 2’s pebble was in the
corresponding position in a matching 1-neighborhood, so the response moves this pebble to b
as well, and thus jumps over the same set of letters. (This is the only potentially problematic
case.) How can we ensure that the m-neighborhoods match up correctly after this move? If
the move takes Player 1’s pebble into an m-neighborhood, then the move stayed within a
single (m + 1)-neighborhood. This means that the original position of Player 2’s pebble was
in the corresponding position of an identical (m + 1)-neighborhood, so that after Player 2’s

18

Two-variable Logic with a Between Predicate

response, the two pebbles are in matching m-neighborhoods.

(cid:74)

5.8 Proof of Corollary 7
Let L = (a(ab)∗b)∗. It is easy to construct a sentence of F O[<] deﬁning L. We can give
a more algebraic proof by working directly with the minimal automaton of L and showing
that its transition monoid is aperiodic. This automaton has three states {0, 1, 2} along with
a dead state. For each state i = 0, 1, 2 we deﬁne i · a = i + 1, i · b = i − 1, where this
transition is understood to lead to the dead state if i + 1 = 3 or i − 1 = −1. The transition
monoid has a zero, which is the transition mapping every state to the dead state. It is then
easy to check that every m ∈ M(L) is either idempotent, or has m3 = 0, and thus M(L)
is aperiodic. We now show that L cannot be expressed in FO2[<, Bet]. By Theorem 6,
if L is expressible then M(L) ∈ MeDA. As before, we will denote the image of a word
w in M(L) by w. Easily, e = ab is an idempotent in M(L), and both m = (ab)a(ab) and
f = (ab)a(ab)b(ab) are elements of e·M(L)e·e with f idempotent and f ≤J m in e·M(L)e·e.
So if e · M(L)e · e ∈ DA we would have f mf = f. Now f is the transition that maps state
0 to 0 and all other states to the dead state, and m is the transition that maps 0 to 1 and
all other states to the dead state. Thus f mf = 0 6= f, so M(L) /∈ MeDA.

5.9 Proof of suﬃciency in Theorem 6 for two-letter alphabets
We sketch the proof that languages over a two-letter alphabet whose syntactic monoids are
in MeDA are deﬁnable in FO2[<, Bet], which will complete the proof of the main theorem.
This relies heavily on an algebraic theory of ﬁnite categories developed by Tilson [19]. The
category C(φ) and the congruence ∼= described below were ﬁrst introduced by Straubing [16]
in the study of languages of dot-depth 2.
In this and the following sections, we assume that A = {a, b}, that M ∈ MeDA and
that φ : A∗ → M is a homomorphism onto M. Our ultimate goal is to show that φ−1(m)
is deﬁnable in FO2[<, Bet] for all m ∈ M. This implies that every language recognized
by a monoid in M ∈ MeDA is deﬁnable in the logic, and thus that L is deﬁnable if
M(L) ∈ MeDA.

5.9.1 Background on ﬁnite categories
A category C consists of a set Obj(C) of objects, and, for each c, d ∈ Obj(C), a set Arr(c, d)
of arrows from c to d. Given a pair of consecutive arrows

there is a product arrow

c u−→ d, d v−→ e,

c uv−→ e.

The product of nonconsecutive arrows is not deﬁned. We will sometimes denote arrows in
this way by showing their start and end objects, and sometimes just write them as u, v,
uv, etc.. For each c ∈ Obj(C) there is an arrow c
1c−→ c that is a right identity for arrows
ending at c and a left identity for arrows starting at c. This is the traditional deﬁnition of
a category, but we are not doing ‘category theory’ in the traditional sense: We will only
consider categories in which both the object set and every arrow set is ﬁnite, and essentially
treat categories as generalized monoids. Note that a monoid is the same thing as a category

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

19

with a single object. Furthermore, for each object c of a category C, the set Arr(c, c) of
arrows that both begin and end at c is a ﬁnite monoid, called the base monoid at c.

There is a preorder on categories called division and denoted ≺ . The ingredients of a
division C ≺ D are an object map τ : Obj(C) → Obj(D), and for each arrow u ∈ Arr(c, d),
a set of arrows in Arr(τ(c), τ(d)) that are said to cover u. The covering relation is required
to satisfy a number of properties:
(i) An arrow in Arr(τ(c), τ(d)) can cover at most one arrow in Arr(c, d). (It might cover

several diﬀerent arrows with diﬀerent starting and ending objects.)

(ii) The covering relation is multiplicative: If ˆu covers u and ˆv covers v, then the product

arrow ˆuˆv covers uv.

(iii) For each c ∈ Obj(C), 1c is covered by 1τ(c).

An important special case occurs when the category D is a monoid, and an even more
special case when C and D are both monoids. In this instance, category division reduces to
monoid division: C is a quotient of a submonoid of D.

We will employ a special property of the monoid variety DA with respect to categories:
It is local. This means that if every base monoid of a category C divides a monoid in DA,
then C itself divides a monoid in DA (see Almeida [1], Place and Segouﬁn [11]).
5.9.2 The category C(φ)
The objects of C(φ) are pairs (e, X), where e ∈ M is idempotent, X ⊆ A, and e = φ(w) for
some word w ∈ A∗ with α(w) = X. (We write α(w) for the set of letters of w.) An arrow
from (e, X) to (f, Y ) is represented by a triple

(e, X) w−→ (f, Y ),

where w ∈ A∗ and Y = X ∪ α(w).
Two such arrows

(e, X) w1,w2−−−−→ (f, Y )

are identiﬁed if

e · φ(w1) · f = e · φ(w2) · f.

(That is, an arrow is actually an equivalence class modulo this identiﬁcation.)

We multiply arrows by the rule

is equal to

(e, X) w1−→ (f, Y ) w2−→ (g, Z)

(e, X) w1uw2−→ (g, Z),

where u ∈ A∗, α(u) = Y, φ(u) = f.

that

It is straightforward to verify that this multiplication is well-deﬁned and associative, and

(e, X) u−→ (e, X),

where α(u) = X and φ(u) = e, represents the identity arrow 1(e,X). Thus C(φ) is indeed a
category.
The base monoid at (e, X) in C(φ) is in eMee. Since M ∈ MeDA, the result about

locality of DA cited above implies that C(φ) divides a monoid in DA.

20

Two-variable Logic with a Between Predicate

5.9.3 A congruence on {a, b}∗
We describe an equivalence relation on {a, b}∗. Since M ∈ MeDA, M is aperiodic, and
therefore if T > |M|, mT = mT +1 for all m ∈ M.
Given a word w ∈ {a, b}∗ we factor it into maximal factors each of which consists entirely

of a’s or entirely of b’s. We call these factors sub-blocks. For example,

w = akr b‘r ··· ak1 b‘1 .

In this example the word begins with a sub-block of a’s and ends with a sub-block of b’s,
but of course any of the four possibilities can occur. We call the factors aki b‘i the blocks
of the factorization.
In case the number of sub-blocks is odd, the leftmost block will be
incomplete, in the sense that it contains only a’s or only b’s. Observe that we number the
blocks from right to left, and call the rightmost block the ﬁrst block.

Let w, w0 ∈ {a, b}∗. We deﬁne w ∼= w0 if the following conditions hold:
The number of blocks in w and the number of blocks in w0 are equivalent threshold T.
The rightmost letters of w, w0 are the same.
Let S be the number of blocks in w. Let 1 ≤ i ≤ min(S, T), and let akib‘i, ak0
i be the
ith blocks of w, w0, respectively. Then ki and k0
i are equivalent threshold T, and ‘i and
‘0
i are equivalent threshold T. (This assumes that the rightmost letter of both words is b,
so that blocks have the form akb‘, but the analogous deﬁnition is made if the rightmost
letter is a.)
We have the following easy lemma.

ib‘0

(cid:73) Lemma 15. The equivalence relation ∼= is a congruence of ﬁnite index on {a, b}∗.

We let K denote the quotient monoid A∗/ ∼= and ψ : A∗ → K the projection homomor-

phism onto this quotient.

5.9.4 The derived category
We deﬁne another category D, called the derived category, that depends on the homomor-
phisms φ : A∗ → M, ψ : A∗ → K. (In Tilson’s formulation, this is called the derived category
of the relational morphism ψφ−1 : M → K.)

The objects of D are elements of K. The arrows are represented by triples

where k ∈ K and v ∈ A∗. Two such triples

k v−→ k · ψ(v),

v1,v2−−−→ k · ψ(v1) = k · ψ(v2)

k

are identiﬁed if for all words u such that ψ(u) = k, φ(uv1) = φ(uv2). Triples are composed
in the obvious way: the product

is represented by the triple

k v1−→ k · ψ(v1) v2−→ kψ(v1v2)

k v1v2−−−→ k · ψ(v1v2).

It is straightforward to verify that this composition law is associative, respects the equiv-
1−→ k is a left and right identity at the object k. So this is
alence of arrows. and that k
indeed a category.

The crucial property of D that we will use is:

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

21

(cid:73) Lemma 16. D divides a monoid in DA.

The proof of this lemma is given in Straubing [16], where both the category C(φ) and

the congruence ∼= are introduced.

5.9.5 Translation into logic
Let w = a1 ··· ak ∈ A∗. Consider the path traced out in the derived category D by this
word, starting at the object 1 = ψ(1):

1 a1−→ ψ(a1) a2−→ ψ(a1a2)··· ak−→ ψ(a1 ··· ak).

We view this sequence of arrows as a word over the alphabet B of all arrows in D. This
deﬁnes a length-preserving function (but not a homomorphism) ξ : A∗ → B∗. By Lemma 16,
D divides a monoid N ∈ DA, so we can map each arrow b ∈ B to an element θ(b) that
covers it.

Let w, w0 ∈ A∗. We claim that if both ψ(w) = ψ(w0), and θξ(w) = θξ(w0), then φ(w) =
φ(w0). This is because the product (1, w, ψ(w)) of the sequence of arrows ξ(w) is covered
by θξ(w), which consequently covers the product (1, w0, ψ(w0)) of the arrows in ξ(w0). As
these products have the same start and end object, they are accordingly equal, which implies
φ(w) = φ(w0).

Thus if m ∈ M, the language φ−1(m) is a ﬁnite union of sets of the form

{w ∈ Σ∗ : ψ(w) = k, θξ(w) = n},

for n ∈ N and k ∈ K. We will show that each of these sets of words is deﬁnable in FO2[<, Th],
and thus, by Theorem 1, by a sentence of FO2[<, Bet]. To express ψ(w) = k, we need to
be able to describe a ∼=-class in FO2[<, Th]. A single example will illustrate the general
procedure. Suppose that T = 3 and we want to write a sentence satisﬁed by a word w if
and only if w is congruent to

a4b2a5ba2b4a.

This word has four blocks, and the leftmost block is incomplete, but only the three rightmost
blocks matter for the congruence class. To describe the class, we ﬁrst say that we jump left
from the right-hand end of of word, over a single a, to the rightmost b:
∃x(b(x) ∧ ∀y(y > x → (a(y) ∧ ¬a(x, y) ∧ ¬b(x, y))).

We now jump from the rightmost b over no a’s and at least one b to the leftmost b of the
ﬁrst block. Observe that the condition is ‘at least one b,’ because we want to express that
the size of this sub-block is at least 3. Thus our sentence has now grown to
∃x(b(x) ∧ ∀y(y > x → (a(y) ∧ ¬a(x, y) ∧ ¬b(x, y))) ∧ γ(x)).

where γ(x) is

∃y(y < x ∧ (b, 1)(y, x) ∧ ¬a(y, x)).

We continue in this manner, now jumping to the rightmost b of the next block, and then the
leftmost b of the same sub-block. Note that we grow the sentence from the outside in, at
each step adding another existential quantiﬁer and atomic formulas of FO2[<, Th]. When
we reach the leftmost letter of the third block we will have to add that either we are on the
leftmost letter of the word, or that the letter immediately to the left is a. The end result

22

Two-variable Logic with a Between Predicate

is a sentence of FO2[<, Th]deﬁning a congruence class of ∼=, and we can treat every class
similarly.
How do we express that θξ(w) = n? Since θ is a morphism into N ∈ DA, the set of
v ∈ B∗ such that θ(v) = n is expressed by a sentence of F O2[<] over the alphabet B. To
convert this into a sentence over A, we have to translate each atomic formula (k, a, k·ψ(a))(x)
into a formula of FO2[<, Th] over A. We write this as a(x) ∧ α(x), where α says that the
word consisting of letters to the left of x belongs to the ∼=-class k. We then proceed to
write α as formula over FO2[<, Th], following the same procedure we used above to obtain
sentences describing ∼=-classes. In fact, this formula is simpler, in terms of alternation depth,
than the one we produced earlier: Using the same ∼=-class as in our example, our formula
construction will begin with

∃y(y < x ∧ (a, 1)(y, x) ∧ ¬(a, 2)(y, x) ∧ ¬(b, 1)(y, x)).

The result is a sentence of FO2[<, Th]deﬁning φ−1(m), as required.

5.10 Proof of Theorem 8
We ﬁrst show that FO2[<, Bet] contains languages of arbitrarily large alternation depth.

Consider an alphabet consisting of the symbols

We deﬁne a sequence of languages by regular expressions as follows:

0, 1,∨1,∧2,∨3,∧4,··· .

C1 = ∨1(0 + 1)+

T1 = ∨1(0 + 1)∗1(0 + 1)∗.

For even m > 1,

For odd m > 1,

Cm = ∧mC+
Tm = ∧mT +

m−1

m−1.

Cm = ∨mC+

m−1

Tm = ∨mC∗

m−1Tm−1C∗

m−1.

Observe that Cm and Tm are languages over a ﬁnite alphabet of m+2 letters. Cm denotes
the set of preﬁx encodings of depth m boolean circuits with 0’s and 1’s at the inputs. In
these circuits the input layer of 0’s and 1’s is followed by a layer of unbounded fan-in OR
gates, then alternating layers of unbounded fan-in AND and OR gates (strictly speaking,
these circuits are trees of AND and OR gates). Tm denotes the set of encodings of those
circuits in Cm that evaluate to True.
We obtain a sentence deﬁning C1 by saying that the ﬁrst symbol is ∨1 and every symbol

after this is either 0 or 1.

∃x(∨1(x) ∧ ∀y(x ≤ y ∧ x < y → (1(y) ∨ 0(y)))).

We obtain a sentence for T1 by taking the conjunction of this sentence with ∃x1(x).
For the inductive step, we suppose that we have a sentence deﬁning Tk for k ≥ 1. Let’s
suppose ﬁrst that k is odd. Thus Tk is a union of ≡r-classes for some r, which we assume to
be at least 2. Consequently, whenever v ∈ Tk and v0 /∈ Tk, Player 1 has a winning strategy in

Andreas Krebs, Kamal Lodaya, Paritosh Pandya, and Howard Straubing

23

the r-round game in v and v0. The proof now proceeds by showing that whenever w ∈ Tk+1
and w0 /∈ Tk+1, Player 1 has a winning strategy in the (r + 1)-round game in these two
words. This implies that the ≡r-class of w is contained within Tk+1, and thus Tk+1 is a
union of such classes, and hence deﬁnable by a sentence in our logic.

The argument for the case where k is even, and for the classes Ck, is identical. Observe

that since T1 is deﬁned by a formula of quantiﬁer depth 2, we can take r = k + 1.

It remains to prove the claim about unbounded alternation depth. It is possible to give
an elementary proof of this using games. However, by deploying some more sophisticated
results from circuit complexity, we can quickly see that the claim is true. Let us suppose
that we have a language L ⊆ {0, 1}∗ recognized by a constant-depth polynomial-size family
of unbounded fan-in boolean circuits; that is, L belongs to the circuit complexity class AC0.
We can encode the pair consisting of a word w of length n and the circuit for length n inputs
by a word p(w) ∈ Cn. We now have w ∈ L if and only if p(w) ∈ Tn.

Now if the alternation depth of all the Tn is bounded above by some ﬁxed integer d, then
we can recognize every Tn by a polynomial-size family of circuits of depth d. We can use
this to obtain a polynomial family of circuits of depth d recognizing L. This contradicts the
fact (see Sipser [14]) that the required circuit depth of languages in AC0 is unbounded.

To prove the claim about bounded alternation depth in the two-letter case, we re-examine
the construction of the formulas in Section 5.9.5. The formula deﬁning the condition θξ(w) =
n is constructed by writing a sentence of F O2[<] over a base that includes the atomic
formulas (k, a, k·ψ(a))(x). The formula α(x) used to express this atomic formula is in Σ2[<].
The F O2[<] sentence itself can be replaced (Thérien and Wilke [20]) by an equivalent Σ2[<]
sentence or a Π2 sentence, so the result is a Π3[<] sentence deﬁning θξ(w) = n. The formula
sentence deﬁning ψ(w) = k can itself be replaced by a Σ2[<] or Π2[<] sentence, because K
is L-trivial and thus itself in DA.

Acknowledgments

Much of this research was carried out while the various authors were guests of the Tata
Institute for Fundamental Research in Mumbai, the Chennai Mathematical Institute and
the Institute of Mathematical Sciences in Chennai, and the University of Montreal, and
participated in the Dagstuhl Seminar ‘Circuits, Logic and Games’ in September, 2015.

1

2

3

References
Jorge Almeida. A syntactical prof of the locality of DA, Int. J. Alg. Comput. 6, 1996,
165–177.
Rajeev Alur and Thomas Henzinger. A really temporal logic, J. ACM 41(1), Jan 1994, 181–
203.
Volker Diekert, Paul Gastin and Manfred Kuﬂeitner. First-order logic over ﬁnite words, Int.
J. Found. Comp. Sci. 19, 2008, 513–548.

4 Kousha Etessami, Moshe Vardi and Thomas Wilke. First-order logic with two variables and

unary temporal logic. Inform. Comput. 179(2), 2002, 279–295.

5 Martin Fürer. The computational complexity of the unconstrained domino problem (with
implications for logical decision problems), Proc. Logic and machines: decision problems
and complexity, Münster (Egon Börger, Gisbert Hasenjaeger and Dieter Rödding, eds.), LNCS
171, 1984, 312–319.

6 Neil Immerman and Dexter Kozen. Deﬁnability with bounded number of bound variables,

Inform. Comput. 83, 1989, 236–244.

24

Two-variable Logic with a Between Predicate

7

François Laroussinie, Antoine Meyer and Eudes Petonnet. Counting LTL, Proc. 17th TIME,
Paris (Nicolas Markey and Jef Wijsen, eds.), 2010, 51–58.

8 Kamal Lodaya, Paritosh Pandya and Simoni Shah. Around dot depth two, Proc. 14th DLT,
London (Canada) (Yuan Gao, Hanlin Lu, Shinnosuke Seki and Sheng Yu, eds.), LNCS 6224,
2010, 303–314.
Robert McNaughton and Seymour Papert. Counter-free automata (MIT Press, 1971).
Jean-Éric Pin. Varieties of Formal Languages, (Plenum, 1986).
Thomas
preprint
, +1)
cachan.fr/∼segouﬁn/Papers/Mypapers/dad.pdf.

F O2(<
http://www.lsv.ens-

Segouﬁn. Decidable

Luc
of DA,

characterization

of

posted

at

Place

and
locality

and

12 Marcel-Paul Schützenberger. On ﬁnite monoids having only trivial subgroups, Inform. Contr.

9
10
11

13 Marcel-Paul Schützenberger. Sur le produit de concaténation non ambigu, Semigroup Forum

8, 1965, 190–194.

13, 1976, 47–75.

14 Michael Sipser. Borel sets and circuit complexity, Proc. 15th STOC, Boston (ACM, 1983),

61–69.
A. Prasad Sistla and Edmund Clarke. The complexity of propositional linear temporal logics,
J. ACM 32(3), 1985, 733–749.

16 Howard Straubing. Semigroups and languages of dot-depth two, Theoret. Comp. Sci. 58,

15

17 Howard Straubing. Finite Automata, Formal Languages, and Circuit Complexity,

1988, 361–378.

(Birkhäuser, 1994).

18 Howard Straubing. On logical descriptions of regular languages, Proc. 5th Latin, Cancun

(Sergio Rajsbaum, ed.), LNCS 2286, 2002, 528–538.
Bret Tilson. Categories as algebra, J. Pure Appl. Alg. 48, 1987, 83–198.

19
20 Denis Thérien and Thomas Wilke. Over words, two variables are as powerful as one quantiﬁer

alternation, Proc. 30th STOC, Dallas (Jeﬀrey Vitter, ed.) (ACM, 1998), 234–240.
Philipp Weis and Neil Immerman. Structure theorem and strict alternation hierarchy for FO2
on words, Log. Meth. Comp. Sci. 5(3:3), 2009, 1–23.
Thomas Wilke. Classifying discrete temporal properties, Proc. 16th STACS, Trier (Christoph
Meinel and Sophie Tison, eds.), LNCS 1563, 1999, 31–46.

21

22

