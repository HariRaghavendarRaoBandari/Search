6
1
0
2

 
r
a

M
6

 

 
 
]
I
S
.
s
c
[
 
 

1
v
5
9
8
1
0

.

3
0
6
1
:
v
i
X
r
a

Bounds on the Voter Model in Dynamic Networks

Petra Berenbrink∗ 1, George Giakkoupis†2, Anne-Marie Kermarrec‡2, and Frederik

Mallmann-Trenn§1,3

1Simon Fraser University

2INRIA Rennes

3École normale supérieure

March 8, 2016

Abstract

In the voter model, each node of a graph has an opinion, and in every round each node chooses
independently a random neighbour and adopts its opinion. We are interested in the consensus time,
which is the ﬁrst point in time where all nodes have the same opinion. We consider dynamic graphs
in which the edges are rewired in every round (by an adversary) giving rise to the graph sequence
G1, G2, . . . , where we assume that Gi has conductance at least φi. We assume that the degrees of
nodes don’t change over time as one can show that the consensus time can become super-exponential
otherwise. In the case of a sequence of d-regular graphs, we obtain asymptotically tight results. Even
for some static graphs, such as the cycle, our results improve the state of the art. Here we show that
the expected number of rounds until all nodes have the same opinion is bounded by O(m/(dmin · φ)),
for any graph with m edges, conductance φ, and degrees at least dmin. In addition, we consider a
biased dynamic voter model, where each opinion i is associated with a probability Pi, and when a
node chooses a neighbour with that opinion, it adopts opinion i with probability Pi (otherwise the
node keeps its current opinion). We show for any regular dynamic graph, that if there is an ǫ > 0
diﬀerence between the highest and second highest opinion probabilities, and at least Ω(log n) nodes
have initially the opinion with the highest probability, then all nodes adopt w.h.p. that opinion. We
obtain a bound on the convergences time, which becomes O(log n/φ) for static graphs.

1 Introduction

In this paper, we investigate the spread of opinions in a connected and undirected graph using the
voter model. The standard voter model works in synchronous rounds and is deﬁned as follows. At the
beginning, every node has one opinion from the set {0, . . . , n− 1}, and in every round, each node chooses
one of its neighbours uniformly at random and adopts its opinion. In this model, one is usually interested
in the consensus time and the ﬁxation probability. The consensus time is the number of rounds it takes
until all nodes have the same opinion. The ﬁxation probability of opinion i is the probability that this
opinion prevails, meaning that all other opinions vanish. This probability is known to be proportional
to the sum of the degrees of the nodes starting with opinion i [16, 27].

The voter model is the dual of the coalescing random walk model which can be described as follows.
Initially, there is a pebble on every node of the graph. In every round, every pebble chooses a neighbour
uniformly at random and moves to that node. Whenever two or more pebbles meet at the same node,
they are merged into a single pebble which continues performing a random walk. The process terminates
when only one pebble remains. The time it takes until only one pebble remains is called coalescing time.
It is known that the coalescing time for a graph G equals the consensus time of the voter model on G
when initially each node has a distinct opinion [2, 22].

In this paper we consider the voter model and a biased variant where the opinions have diﬀerent

popularity. We express the consensus time as a function of the graph conductance φ.

∗petra@sfu.ca
†george.giakkoupis@inria.fr
‡anne-marie.kermarrec@inria.fr
§fmallman@sfu.ca

1

We assume a dynamic graph model where the edges of the graph can be rewired by an adversary
in every round, as long as the adversary respects the given degree sequence and the given conductance
for all generated graphs. We show that consensus is reached with constant probability after τ rounds,
where τ is the ﬁrst round such that the sum of conductances up to round τ at least m/dmin, where m
is the number of edges. For static graphs the above bound simpliﬁes to O(m/(dmin · φ)), where dmin is
the minimum degree.
For the biased model we assume a regular dynamic graph G. Similar to [19, 22] the opinions have
a popularity, which is expressed as a probability with which nodes adopt opinions. Again, every node
chooses one of its neighbours uniformly at random, but this time it adopts the neighbour’s opinion with a
probability that equals the popularity of this opinion (otherwise the node keeps its current opinion). We
assume that the popularity of the most popular opinion is 1, and every other opinion has a popularity
of at most 1 − ǫ (for an arbitrarily small but constant ǫ > 0). We also assume that at least Ω(log n)
nodes start with the most popular opinion. Then we show that the most popular opinion prevails w.h.p.1
after τ rounds, where τ is the ﬁrst round such that the sum of conductances up to round τ is of order
O(log n). For static graphs the above bound simpliﬁes as follows: the most popular opinion prevails
w.h.p. in O(log n/φ) rounds, if at least Ω(log n) nodes start with that opinion.

1.1 Related work

A sequential version of the voter model was introduced in [17] and can be described as follows. In every
round, a single node is chosen uniformly at random and this node changes its opinion to that of a random
neighbour. The authors of [17] study inﬁnite grid graphs. This was generalised to arbitrary graphs in [12]
where it is shown among other things that the probability for opinion i to prevail is proportional to the
sum of the degrees of the nodes having opinion i at the beginning of the process.

The standard voter model was ﬁrst analysed in [16]. The authors of [16] bound the expected coalescing
time (and thus the expected consensus time) in terms of the expected meeting time tmeet of two random
walks and show a bound of O(tmeet · log n) = O(n3 log n). Note that the meeting time is an obvious
lower bound on the coalescing time, and thus a lower bound on the consensus time when all nodes have
(log4 n + ρ)(cid:1)
distinct opinions initially. The authors of [6] provide an improved upper bound of O(cid:0) 1
matrix of a random walk on G, and ρ = (cid:0)Pu∈V (G) d(u)(cid:1)2
/Pu∈V (G) d2(u) is the ratio of the square of

the sum of node degrees over the sum of the squared degrees. The value of ρ ranges from Θ(1), for the
star graph, to n, for regular graphs.

on the expected coalescing time for any graph G, where λ2 is the second eigenvalue of the transition

1−λ2

The authors of [2, 22, 23] investigate coalescing random walks in a continuous setting where the
movement of the pebbles are modelled by independent Poisson processes with a rate of 1. In [2], it is
shown a lower bound of Ω(m/dmax) and an upper bound of O(thit · log n) for the expected coalescing
time. Here m is the number of edges in the graph, dmax is the maximum degree, and thit is the (expected)
hitting time. In [28], it is shown that the expected coalescing time is bounded by O(thit).

In [22] the authors consider the biased voter model in the continuous setting and two opinions. They
show that for d-dimensional lattices the probability for the less popular opinion to prevail is exponentially
small. In [19], it is shown that in this setting the expected consensus time is exponential for the line.

The authors of [7] consider a modiﬁcation of the standard voter model with two opinions, which they
call two-sample voting. In every round, each node chooses two of its neighbours randomly and adopts
their opinion only if they both agree. For regular graphs and random regular graphs, it is shown that
two-sample voting has a consensus time of O(log n) if the initial imbalance between the nodes having
the two opinions is large enough. There are several other works on the setting where every node contact
in every round two or more neighbours before adapting its opinion [1, 8, 9, 13].

There are several other models which are related to the voter model, most notably the Moran process
and rumor spreading in the phone call model. In the case of the Moran process, a population resides
on the vertices of a graph. The initial population consists of one mutant with ﬁtness r and the rest of
the nodes are non-mutants with ﬁtness 1. In every round, a node is chosen at random with probability
proportional to its ﬁtness. This node then reproduces by placing a copy of itself on a randomly chosen
neighbour, replacing the individual that was there. The main quantities of interest are the probability
that the mutant occupies the whole graph (ﬁxation) or vanishes (extinction), together with the time
before either of the two states is reached (absorption time). There are several publications considering
the ﬁxation probabilities [10, 18, 24]. For any graph it is known that the expected absorption time for an
advantageous mutation (r > 1) is O(n4) [10]. The authors of [11] show that for regular directed graphs

1An event happens with high probability (w.h.p.) if its probability is at least 1 − 1/n.

2

the expected absorption time is Ω(n log n) and O(n2), and give improved bounds for other families of
graphs based on the expansion of these graphs.

Rumor spreading in the phone call model works as follows. Every node v opens a channel to a ran-
domly chosen neighbour u. The channel can be used for transmissions in both directions. A transmission
from v to u is called push transmission and a transmission from u to v is called pull. There is a vast
amount of papers analysing rumor spreading on diﬀerent graphs. The result that is most relevant to
ours is that broadcasting of a message in the whole network is completed in O(log n/φ) rounds w.h.p,
where φ is the conductance (see Section 1.2 for a deﬁnition) of the network. In [15], the authors study
rumor spreading in dynamic networks, where the edges in every round are distributed by an adaptive
adversary. They show that broadcasting terminates w.h.p. in a round t if the sum of conductances up
to round t is of order log n. Here, the sequence of graphs G1, G2, . . . have the same vertex set of size n,
but possibly distinct edge sets. In contrast to our work, the authors assume that the degrees and the
conductance change over time. We refer the reader to the next section for a discussion of the diﬀerences.
Dynamic graphs have received ample attention in various areas [4, 20, 21, 29].

1.2 Model and New Results

In this paper we show results for the standard voter model and biased voter model in dynamic graphs.
Our protocols work in synchronous steps. The consensus time T is deﬁned at the ﬁrst time step at which
all nodes have the same opinion.

Dynamic Standard Voter Model. Our ﬁrst result concerns the standard voter model in dynamic
graphs Our protocol works as follows. In every synchronous time step every node chooses a neighbour
u.a.r. and adopts its opinion with probability 1/2.2

We assume that the dynamic graphs G = G1, G2, . . . are generated by an adversary. We assume
that each graph has n nodes and the nodes are numbered from 1 to n. The sequence of conductances
φ1, φ2, . . . is given in advance, as well as a degree sequence d1, d2, . . . , dn. The adversary is now allowed
to create every graph Gi by redistributing the edges of the graph. The constraints are that each graph
Gi has to have conductance φi and node j has to have degree dj (the degrees of the nodes do not change
over time). Note that the sequence of the conductances is ﬁxed and, hence, cannot be regarded as a
random variable in the following. For the redistribution of the edges we assume that the adversary knows
the distribution of all opinions during all previous rounds.

Note that our model for dynamic graphs is motivated by the model presented in [15]. They allow
the adversary to determine the edge set at every round, without having to respect the node degrees and
conductances. We show (Observation 1) that, allowing the adversary to change the node degrees over
time can results in super-exponential voting time. Since this changes the behaviour signiﬁcantly, we
assume that the degrees of nodes are ﬁxed. Furthermore, in contrary to [15], we assume that (bounds
on) the conductance of (the graph at any time step) are ﬁxed/given beforehand. Whether one can obtain
the same results, if the conductance of the graph is determined by an adaptive adversary remains an
open question.

For the dynamic model we show the following result bounding the consensus time T .

Theorem 1.1 (upper bound). Consider the Standard Voter model and in the dynamic graph generation
model. Assume κ ≤ n opinions are arbitrarily distributed over the nodes of G1. Let φt be a lower bound
on the conductance at time step t. Let b > 0 be a suitable chosen constant. Then, with a probability of
1/2 we have that T ≤ min{τ, τ ′}, where
(i) τ is the ﬁrst rounds so that Pτ
(ii) τ ′ is the ﬁrst rounds so that Pτ ′
For static graphs (Gi+1 = Gi for all i), we have T ≤ min{m/(dmin · φ), n log n/φ2}.

t=1 φt ≥ b · m/dmin.
t=1 φ2
t ≥ b · n log n.

For static d-regular graphs, where the graph doesn’t change over time, the above bound bound
becomes O(n/φ), which is tight when either φ or d are constants (see Observation 2). Theorem 1.1 gives
the ﬁrst tight bounds for cycles and circulant graphs Ck
n (node i is adjacent to the nodes i ± 1, . . . , i ± k
mod n) with degree 2k (k constant). For these graphs the consensus time is Θ(n2), which matches our
[6] note that φ2 ≤ 1 − λ2 ≤ 2φ.
upper bound from Theorem 1.13. For a comparison with the results of

2The factor of 1/2 ensures that the process converges on bipartite graphs.
3The lower bound of Ω(n2) follows from the fact that two coalescing random walks starting on opposite sites of a cycle

of Ω(n) require in expectation Ω(n2) to meet.

3

In particular, for the cycle φ = 1/n and 1/(1 − λ2) = Θ(1/n2). Hence, for this graph, our bound is by
a factor of n smaller. Note that, due to the duality between the voter model and coalescing random
walks, the result also holds for the coalescing time. In contrast to [6,7], the above result is shown using a
potential function argument, whereas the authors of [6,7] show their results for coalescing random walks
and ﬁxed graphs. The advantage of analysing the process directly is, that our techniques allow us to
obtain the results for the dynamic setting.

The next result shows that the bound of Theorem 1.1 is asymptotically tight if the adversary is

allowed to change the node degrees over time.

Theorem 1.2 (lower bound). Consider the Standard Voter model in the dynamic graph generation
model. Assume that κ ≤ n opinions are arbitrarily distributed over the nodes of G1. Let φt be an upper
bound on the conductance at time step t. Let b > 0 be a suitable chosen constant and assume τ ′′ is the
ﬁrst rounds such that

τ ′′

Then, with a probability of at least 1/2, there are at still nodes with two diﬀerent opinions in Gτ ′′.

φt ≥ bn.

Xt=1

In the biased voter model we again assume that there are κ ≤ n distinct opinions
Biased Voter Model
initially. For 0 ≤ i ≤ κ − 1 opinion i has popularity αi and we assume that α0 = 1 > α1 ≥ α2 ≥ . . . ≥
ακ−1. We call opinion 0 the preferred opinion. The process works as follows. In every round, every node
chooses a neighbour uniformly at random and adopts its opinion i with probability αi.

We assume that the dynamic d-regular graphs G = G1, G2, . . . are generated by an adversary. We
assume that the sequence of conductance φt is given in advance, where φi is a lower bound on the
conductance of Gi. The adversary is now allowed to create the sequence of graphs by redistributing the
edges of the graph in every step. The constraints are that each graph Gi has n nodes and has to have
conductance at least φi. Note that we assume that the sequence of the conductances is ﬁxed and, hence,
it is not a random variable in the following.

The following result shows that consensus is reached considerably faster in the biased voter model,
as long as the bias 1 − α1 is bounded away from 0, and at least a logarithmic number of nodes have the
preferred opinion initially.

Theorem 1.3. Consider the Biased Voter model in the dynamic regular graph generation model. As-
sume κ ≤ n opinions are arbitrarily distributed over the nodes of G1. Let φt be a lower bound on the
conductance at time step t. Assume that α1 ≤ 1 − ǫ, for an arbitrary small constant ǫ > 0.
Assume the initial number of nodes with the preferred opinion is at least c log n, for some constant
c = c(α1). Then the preferred opinion prevails in at most τ ′′′ steps, where τ ′′′ is the ﬁrst rounds so that
Pτ ′′′
t=1 φt ≥ b log n, for some constant b. For static graphs (Gi+1 = Gi for all i), we have T = O(log n/φ).
In fact, the assumption on the initial size of the preferred opinion is crucial for the time bound T =
O(log n/φ), in the sense that there instances4 where the expected consensus time is at least T = Ω(n/φ)
if the size of the preferred opinion is small.

The biased voter model can be regarded as a generalisation of the rumor spreading process (with two
opinions having popularity 1 and 0). However, the techniques used for the analysis of rumor spreading
do not extend to the voter model. This is due to the fact that rumor spreading is a progressive process,
where nodes can change their opinion only once, from “uninformed” to “informed”, whereas they can
change their opinions over and over again in the case of the voter model. Note that the above bound is
the same as the bound for rumor spreading of [14] (although the latter bound holds for general graphs,
rather than just for regular ones). Hence, our above bound is tight for regular graphs with conductance
φ, since the rumor spreading lower bound of Ω(log n/φ) is also a lower bound for biased voting in our
model.

2 Analysis of the Voter Model

In this section we show the upper and lower bound for the standard voter model. We begin with some
deﬁnitions. For a ﬁxed set S ⊆ V we deﬁne cut(S, V \ S) to be the set of edges between the sets S ⊆ V
4Consider a 3-regular graph and n opinions where all other α1 = α2 = · · · = αn−1 = 1/2. The preferred opinion

vanishes with constant probability and the bound for the standard voter model of Observation 2 applies.

4

and V \ S at time t and let λu be the number of neighbours of u in V \ S. Let vol(S) =Pu∈S du. The

conductance of G is deﬁned as

φ = φ(G) = minn Pu∈U λu

vol(U)

: U ⊂ V with 0 < vol(U ) ≤ mo .

We note 1/n2 ≤ φ ≤ 1. We denote by v(i)
and t ≥ 0. If we refer to the expected number of nodes we use V (i)
a Markov chain Mt≥0 = (V (0)

, V (1)

)t≥0.

t

t

the set of nodes that have opinion i after the ﬁrst t rounds
instead. We model the system with

t

t

2.1 Part 1 of Theorem 1.1.

First we show Theorem 1.1 for κ = 2 (two opinions), which we call 0 and 1 in the following. Then we
generalise the result to an arbitrary number of opinions.

Let st denote the set having the smaller volume, i.e., st = v(0)

otherwise. Note that we use st, v(0)
for the corresponding random variables. For u ∈ v(0)
and for u ∈ v(1)

, λu,t is neighbours of u in V \ v(0)

and v(1)

t

t

t

time).

t

if vol(v(0)

t whenever the state at time t is ﬁxed, and St, V (0)

), and st = v(1)
and V (1)
, λu,t is the number of neighbours of u in V \ v1(t)
t
. du is the degree of u (the degrees do not change over

) ≤ vol(v(1)

t

t

t

t

t

To analyse the process we use a potential function. Simply using the volume of nodes sharing the
same opinion as the potential function will not work. It is easy to calculate that the expected volume
of nodes with a given opinion does not change in one step. Instead, we use a convex function on the
number of nodes with the minority opinion. We deﬁne

In Lemma 2.1 we ﬁrst calculate the one-step potential drop of Ψ(St). Then we show that every
opinion either prevails or vanishes once the sum of conductances is proportional to the volume of nodes
having that opinion (see Lemma 2.2), which we use later to prove Part 1 of Theorem 1.1.

Ψ(St) =pvol(St).

Lemma 2.1. Assume st 6= ∅ and κ = 2. Then

E[Ψ(St+1) | St = st] ≤ Ψ(st) − Pu∈V λu,t · du
32 · (Ψ(st))3 .

Proof. W.l.o.g. we assume that opinion 0 is the minority opinion, i.e. 0 < vol(V (0)
simplify the notation we omit the index t in this proof and write v(0) instead of vt(0), v(1) for V \ v(0)
and λu instead of λu,t. Hence, st = v(0) and Ψ(st) = pvol(v(0)). Note that for t = 0 we have
vol(v(0)) = Ψ(st)2. Furthermore, we ﬁx St = st in the following (and condition on it). We deﬁne m as
the number of edges. Then we have

) ≤ vol(V (1)

). To
,

t

t

t

E[Ψ(St+1) − Ψ(st) | St = st] = E[pvol(St+1) −pvol(st)]

t+1), m − vol(V (0)

t+1)o −pvol(st)#

(1)

= E"rminnvol(V (0)
≤ E(cid:20)qvol(V (0)

t+1) −qvol(v(0))(cid:21)
if u ∈ v(1)
if u ∈ v(0)

w.p. λu
du
2·du
−du w.p. λu
otherwise
0
t+1) − vol(v(0)) and

2·du

Xu =


Now we deﬁne

and ∆ =Pu∈V Xu. Note that we have ∆ = vol(V (0)

E(cid:20)qvol(V (0)

t+1) −qvol(v(0))(cid:21) = E(cid:20)qvol(v(0)) + ∆ −qvol(v(0))(cid:21)
vol(v(0)) − 1(cid:17)(cid:21)

= E(cid:20)qvol(v(0))(cid:16)q1 +

∆

5

Unfortunately we cannot bound Ψ(st) · E[p1 + ∆/Ψ(st)2 − 1] directly. Instead, we deﬁne a family

of random variables which is closely related to Xu.

= Ψ(st) · E[p1 + ∆/Ψ(st)2 − 1].

w.p. 1
λu
2
−du w.p. λu
otherwise
0

2·du

if u ∈ v(1)
if u ∈ v(0)

Yu =


Lemma A.1, we show that

Similarly, we deﬁne ∆′ = Pu∈V Y (u). Note that |E[Yu]| = λu/2 for both u ∈ v(1) and u ∈ v(0). In
which results in E[Ψ(St+1)− Ψ(st) | St = st] ≤ Ψ(st)· E[p1 + ∆′/Ψ(st)2− 1] From the Taylor expansion
√1 + x ≤ 1 + x

E[p1 + ∆/Ψ(st)2] ≤ E[p1 + ∆′/Ψ(st)2].

8 + x3

16 , x ≥ −1 it follows that

2 − x2
E[Ψ(St+1) − Ψ(st) | St = st] ≤ Ψ(st) · E(cid:2) ∆′
2 −Pv∈v(0)

λu

It remains to to bound E[∆′], E[(∆′)2], and E[(∆′)3].

2Ψ(st)2 − (∆′)2

8Ψ(st)4 + (∆′)3
16Ψ(st)6(cid:3).

• E[∆′]: We have E[∆′] =Pu∈V E[Yu] =Pu∈v(1)
sincePu∈v(1) λu andPu∈v(1) λu both count the number of edges crossing the cut between v(0) and
• E[(∆′)2]: since E[(Yu)2] = (λu)2/2 for u ∈ v(1) and E[(Yu)2] = −du · λu/2 for u ∈ v(0) we have

λv
2 = 0, where the last equality holds

v(1).

Var[Yu] + 0 = Xu∈V

(E[(Yu)2] − (E[Yu])2)

E[(∆′)2] = Xu∈V
= Xu∈v(0)
= Xu∈v(0)

Var[Yu] + (E[Yu])2 = Xu∈V
(E[(Yu)2] − (E[Yu])2) + Xu∈v(1)
2 − Xu∈v(0)

+ Xu∈v(1)

λ2
u
4

λudu

λ2
u

(E[(Yu)2] − (E[Yu])2)
4 ≥ Xu∈v(0)

λudu

4

.

• E[∆′3]: In Lemma A.2 we show that

Note that E[(Yu)3] = 1

2 λu · (du)2 for u ∈ v(0). Hence,

E[∆′3] = Xu∈V (cid:0) E[(Yu)3] − 3 E[(Yu)2] · E[Yu] + 2 E[Yu]3(cid:1).
2 (λu)3 for u ∈ v(1) and E[(Yu)3] = − 1
E[∆′3] = Xu∈v(0)(cid:18)−
+ Xu∈v(1)(cid:18) 1

u(cid:19)
(λu)3(cid:19) ≤ 0,

λu · (du)2 +
3
4

(λu)2 · du −

(λu)3 −

(λu)3 +

1
4

1
4

3
4

1
2

λ3

2

Combining all the above estimations we get

where the ﬁrst sum is bounded by 0 because λu ≤ du.
E[Ψ(St+1) − Ψ(st) | St = st] ≤ Ψ(st) · E(cid:20) ∆′

2Ψ(st)2 −

∆′2

8Ψ(st)4 +

∆′3

16Ψ(st)6(cid:21) ≤ −Pu∈v(0) λudu

32Ψ(st)3

(2)

(3)

.

This completes the proof of Lemma 2.1.

Using Lemma 2.1 we show that a given opinion either prevails or vanishes with constant probability

as soon as the sum of φt is proportional to the volume of the nodes having that opinion.
Lemma 2.2. Assume that sˆt is ﬁxed for an arbitrary (ˆt ≥ 0) and κ = 2.
i=ˆt φi ≥ 129 · vol(sˆt)/dmino. Then Pr(cid:0)T ≤ τ ∗ + ˆt(cid:1) ≥ 1/2.
Let τ ∗ = minnt′ :Pt′
In particular, if the graph is static with conductance φ, then Pr(cid:0)T ≤ 129·vol(sˆt)

+ ˆt(cid:1) ≥ 1/2.

φ·dmin

6

Proof. From the deﬁnition of Ψ(st) and φt it follows for all t that Ψ(st)2 = Pu∈v(0) du = vol(v(0)) and
φt ≤Pu∈v(0) λu,t/vol(v(0)). Hence,

Ψ(st)2 · φt · dmin ≤ Xu∈v(0)

λu,t · du.

Together with Lemma 2.1 we derive for st 6= ∅

E[Ψ(St+1) | St = st] ≤ Ψ(st) − Pu∈V λu,t · du

32 · (Ψ(st))3 ≤ Ψ(st) −

dmin · φt
32 · Ψ(st)

.

(4)

Recall that T = mint{St = ∅}. In the following we use the expression T > t to denote the event st 6= ∅.
Using the law of total probability we get

and using Jensen’s inequality we get

dmin · φt

T > t(cid:21)

E[Ψ(St+1)|T > t] = E(cid:20)Ψ(St) −

32 · Ψ(St)(cid:12)(cid:12)(cid:12)
32 · Ψ(St) | T > t(cid:21)
E[Ψ(St+1) | T > t] = E[Ψ(St) | T > t] − E(cid:20) dmin · φt
dmin · φt
32 · E[Ψ(St)· | T > t]

≤ E[Ψ(St) | T > t] −

.

Since E[Ψ(St) | T ≤ t] = 0 we have

E[Ψ(St)] = E[Ψ(St) | T > t] · Pr[T > t] + E[Ψ(St) | T ≤ t] · Pr[T ≤ t]

= E[Ψ(St) | T > t] · Pr[T > t] + 0.

Hence,

and

E[Ψ(St+1)]
Pr (T > t) ≤

E[Ψ(St)]
Pr (T > t) −

dmin · φt · Pr (T > t)

32 E[Ψ(St)]

E[Ψ(St+1)] ≤ E[Ψ(St)] −

dmin · φt · (Pr (T > t))2

32 E[Ψ(St)]

Let t∗ = min{t : Pr(T > t) < 1/2}. In the following we use contradiction to show

t∗ ≤ max{t : Xˆt≤t<t∗

φt ≤ 128 · vol(sˆt)/dmin}.

Assume the inequality is not satisﬁed. With t = t∗ − 1 we get
dmin · φt · (Pr(T > t∗ − 1))2

E[Ψ(St∗ )] ≤ E[Ψ(St∗−1)] −

32 E[Ψ(St∗−1)]

≤ E[Ψ(St∗−1)] −

dmin · φt∗ · (1/4)
32 E[Ψ(St∗−1)]

,

Applying this equation iteratively, we obtain

E[Ψ(St∗)] ≤ E[Ψ(Sˆt)] − Xˆt≤t<t∗

dmin · φt · 1/4
32 E[Ψ(St)] ≤ E[Ψ(Sˆt)] −

dmin ·Pˆt≤t<t∗ φt

128 E[Ψ(Sˆt)]

.

(5)

Using the deﬁnition of E[Ψ(Sˆt)] =pvol(sˆt) and the deﬁnition of t∗ we get
=qvol(sˆt) −

E[Ψ(St∗ )] <qvol(sˆt) −

dmin · 128 · vol(sˆt)
128 · dmin ·pvol(sˆt)

This is a contradiction since E[Ψ(St∗ )] is non-negative.

= 0

vol(sˆt)

pvol(sˆt)

From the deﬁnition of t∗, we obtain Pr(cid:0)T > τ ∗ + ˆt(cid:1) < 1/2 this completes the proof of Lemma 2.2.

Now we are ready to show the ﬁrst part of the theorem.

7

ℓ0 = κ.

Proof of Part 1 of Theorem 1.1. We divide the τ rounds into phases. Phase i starts at time τi = min{t :
Pt
j=1 φj ≥ 2i} for i ≥ 0 and it ends at τi+1 − 1. Since φj ≤ 1 for all j ≥ 0 we have τ0 < τ1 < . . . and
Pτi+1
j=τi φj ≥ 1 for i ≥ 0. Let ℓt be the number of distinct opinions at the beginning of Phase t. Hence,
After this proof we show in Lemma 2.3 that the expected number of phases before the number of
opinions drops by a factor of 5/6 is bounded by 6c · vol(V )/(ℓt · dmin). For i ≥ 1 let Ti be the number of
phases needed so that the number of opinions drops to (5/6)i · ℓ0. Then only one opinion remains after
log6/5 κ many of these meta-phases. Then, for a suitably chosen constant b

E[T ] =

log6/5 κ

log6/5 κ−1

E[Tj] ≤

Xj=1

Xj=1

6c · vol(V )
ℓj · dmin ≤

log6/5 κ

Xj=1

6c vol(V )

(5/6)j · ℓ0 · dmin

=

b · m
4 · dmin

.

By Markov inequality, consensus is reached w.p. at least 1/2 after b · m/(2dmin) phases. By deﬁnition
of τ and the deﬁnition of the phases, we have that the number of phases up to time step τ is at least
b · m/(2dmin). Thus, consensus is reached w.p. at least 1/2 after τ time steps, which ﬁnishes the
proof.

Lemma 2.3. Fix a Phase t and assume c = 129 and ℓt > 1. The expected number of phases before the
number of opinions drops to 5/6 · ℓt is bounded by 6c · vol(V )/(ℓt · dmin).
Proof. Consider a point when there are ℓ′ opinions left, with 5/6 · ℓ < ℓ′ ≤ ℓ. Among those ℓ′ opinions,
there are at least ℓ′ − ℓ/3 opinions i such that the volume of nodes with opinion i is at most 3 · vol(V )/ℓ.
Let S denote the set of these opinions and let Zi be an indicator variable which is 1 if opinion i ∈ S
vanished after s = 3c · vol(V )/(ℓ · dmin) phases and Zi = 0 if it prevails. To estimate Zi we consider
the process where we have two colours only. All nodes with Opinion i retain their opinion and all other
nodes have Opinion 0. It is easy to see that in both processes the set of nodes with Opinion i remains
exactly the same. Hence, we can use Lemma 2.2 to show that with probability at least 1/2, after s phases
opinion i either vanishes or prevails. Hence,

E [Σj∈SZj] = Σj∈S E[Zj] ≥ |S|/2 ≥ (ℓ′ − ℓ/3)/2.

Using Markov’s inequality we get that with probability 1/2 at least (ℓ′−ℓ/3)/4 opinions vanish within
s phases, and the number of opinions remaining is at most ℓ′ − (ℓ′ − ℓ/3)/4 = 3/4 · ℓ′ + ℓ/12 ≤ 5/6 · ℓ.
The expected number of phases until 5/6 · ℓ opinions can be bounded by

∞

2−i · s ≤ 2s =

Xi=1

2.2 Part 2 of Theorem 1.1

6c · vol(V )
ℓ · dmin

.

The following lemma is similar to Lemma 2.2 in the last section: We ﬁrst bound the expected potential
drop in round t + 1, i.e., we bound E[Ψ(St+1) − Ψ(st) | St = st]. This time however, we express the
drop as a function which is linear in Ψ(st). This allows us to bound the expected size of the potential at
time τ ′, i.e., E[Ψ(Sτ ′)], directly. From the expected size of the potential at time τ ′ we derive the desired
bound on P r (T ≤ τ ′).
Lemma 2.4. Assume κ = 2. We have Pr (T ≤ τ ′) ≥ 1/n2. In particular, if the graph is static with
conductance φ, then Pr(cid:0)T ≤ 96·n log n
Proof. In the following we ﬁx a point in time t and use λu instead of λu,t. From Lemma 2.1 and the
observation λu ≤ du we obtain for st 6= ∅

(cid:1) ≥ 1 − 1/n2.

φ2

E[Ψ(St+1) − Ψ(st) | St = st] ≤ −Pu∈V λu · du

32 · (Ψ(st))3 ≤ −Pv∈v(0) (λu)2
32(Ψ(st))3 .
=(cid:0)Pv∈v(0) λu · 1(cid:1)2
We have, by Cauchy-Schwarz inequality, (cid:0)Pv∈v(0) λu(cid:1)2
≤Pv∈v(0) (λu)2 · n. Hence,
(λu)2 ≥ (cid:0)Pv∈v(0) λu(cid:1)2
Ψ(st)4 · (φt)2
(vol(v0))2 · (φt)2
≥
≥

n

n

n

,

Xv∈V

(λu)2 ≥ Xv∈v(0)

8

where the third inequality follows by deﬁnition of φt. Hence, for st 6= ∅ we have

E[Ψ(St+1) − Ψ(st) | St = st] ≤ −

Ψ(st) · (φt)2

32n

.

Note that E[Ψ(St+1) | St = ∅] = 0 = (1 − (φt)2

E[Ψ(St+1)] = E[E[Ψ(St+1) | St = st]] ≤(cid:18)1 −

32n ) · E[Ψ(∅)]. Hence, for all t ≥ 1 we get
32n (cid:19) · E[Ψ(st)].

(φt)2

Applying this recursively yields

E[Ψ(St+1)] ≤ Ψ(S0) ·

(φi)2
32n

(1 −

t

Yi=0

) ≤ Ψ(S0) ·
1 −

1

t + 1Xi≤t

t+1

(φi)2

32n 


≤ Ψ(S0) · exp
Xi≤t

(φi)2

32n 
 ,

where the second inequality follows from the Inequality of arithmetic and geometric means.
By deﬁnition of τ ′, and from the observation Ψ(S0) ≤ n we get that E[Ψ(Sτ ′)] ≤ n−2.
We derive

n−2 ≥ E[Ψ(Sτ ′)] ≥ 0 · Pr(Ψ(Sτ ′) = 0) + 1 · (1 − Pr(Ψ(Sτ ′) = 0)),

(6)

where we used that min{Ψ(S) : S ⊆ V : S 6= ∅} ≥ 1. Solving (6) for Pr(Ψ(Sτ ′) = 0 gives Pr(Ψ(Sτ ′) =
0) ≥ 1 − 1/n2.

Since κ = 2, it follows that Pr(T ≤ τ ′) = Pr(Ψ(Sτ ′) = 0) ≥ 1 − 1/n2, which yields the claim.
We now prove Part 2 of Theorem 1.1 which generalises to κ > 2.

Proof of Part 2 of Theorem 1.1. We deﬁne a parameterized version of the consensus time T . We deﬁne
T (κ) = min{t : Ψ(St) = 0 : the number of diﬀerent opinions at time t is κ} for κ ≤ n. We want to
show that Pr(T (κ) ≤ τ ′) ≥ 1 − 1/n. From Lemma 2.4 we have that, that Pr(T (2) ≤ τ ′) ≥ 1 − 1/n2.
We deﬁne the 0/1 random variable Zi to be one if opinion i vanishes or is the only remaining opinion
after τ ′ rounds and Zi = 0 otherwise. We have that Pr(Zi = 1) ≥ 1 − 1/n2 for all i ≤ κ. We derive
Pr(T (κ) ≤ τ ′) = Pr(∧i≤κZi) ≥ 1 − 1/n, by union bound. This yields the claim.

2.3 Lower Bounds

In this section, we give the intuition behind the proof of Theorem 1.2 and state two additional obser-
vations. Recall that Theorem 1.2 shows that our bound for regular graphs is tight for the adaptive
adversary, even for k = 2. The ﬁrst observation shows that the expected consensus time can be super-
exponential if the adversary is allowed to change the degree sequence. The second observation can be
regarded as a (weaker) counter part of Theorem 1.2 showing a lower bound of Ω(n/φ) for static graphs,
assuming that either d or φ is constant.

We now give the intuition behind the proof of Theorem 1.2. The high level approach is as follows.
For every step t we deﬁne an adaptive adversary that chooses Gt+1 after observing V (0)
. The
adversary chooses Gt+1 such that the cut between V (0)
is of order of Θ(φt · dn). We show that
such a graph exists when the number of nodes in both V (0)
is at least of linear size (in n). By
this choice the adversary ensures that the expected potential drop of Ψ(St+1) at most −cφtd/Ψ(st) for
some constant c. Then we use the expected potential drop, together with the optional stopping theorem,
to derive our lower bound.

t
and V (1)

and V (1)

and V (1)

t

t

t

t

t

We proceed by giving a lower bound on the potential drop assuming a cut-size of Θ(φt · d · n).

Lemma 2.5. Assume |cut(st, V \ st)| ≤ cφt · dn for some constant c. Then we have

E[Ψ(St+1) | St = st] ≥ Ψ(st) −

c · φt · d
Ψ(st)

.

(7)

9

Proof. The proof is similar to the proof of Lemma 2.1.

E [Ψ(St+1) − Ψ(st) | St = st] =
= E[pvol(St+1) −pvol(st)]
= E"rminnvol(V (0)
t+1), m − vol(V (0)
= E(cid:20)min(cid:26)qvol(v(0)
) + ∆,qm − (vol(v(0)
≥ E(cid:20)min(cid:26)qvol(v(0)
) + ∆,qvol(v(0)
= E(cid:20)qvol(v(0)
)(cid:21)
) − |∆| −qvol(v(0)
) − 1(cid:19)(cid:21)
)(cid:18)r1 − |∆|
= E(cid:20)qvol(v(0)
2Ψ(st)2 − |∆|2
Ψ(st)4(cid:21)
≥ Ψ(st) · E(cid:20)
|∆|

vol(v(0)

t

t

t

t

t

t

t

t

t+1)o −pvol(st)#

) + ∆)(cid:27) −qvol(v(0)

t

) − ∆(cid:27) −qvol(v(0)

t

)(cid:21)

)(cid:21)

(8)

where the last inequality comes from the Taylor expansion inequality √1 + x ≥ 1 + x

2 − x2, x ≥ −1.

Similar to (2) we get

E[(∆)2] = Xu∈V
≤ Xu∈V

E[X 2

u] = Xu∈V

λu · d

2

Var[Xu] + (E[Xu])2 = Xu∈V

Var[Xu] + 0 = Xu∈V

(E[X 2

u] − (E[Xu])2)

= d · |cut(st, V \ st)| ≤ c · φt · d · vol(st) = c · φt · dΨ(st)2.

From (8) we derive now

E [Ψ(St+1) − Ψ(st) | St = st] ≥ Ψ(st) ·(cid:18)−

Ψ(st)2 (cid:19) ≥ −
c · φt · d

c · φt · d
Ψ(st)

.

We now describe the adversary for the graphs that we use in our lower bound. We assume that we
have initially two opinions and each of the two opinion is on n/2 nodes.Recall that we can assume that
in round t + 1 the adversary knows the graph Gt as well as the distribution of the opinions over the
nodes. The adversary generates Gt+1 as follows. c is a constant which is deﬁned in Lemma A.3).

• If |st| ≥ γ · n, the adversary creates a d-regular graph Gt+1 with two subsets st and V \ st such
that the conductance of the cut(st, V \ st) is at most c · φt; According to Lemma A.3 such a graph
always exist.

• If |St| = |st| < γ · n, the adversary does not change the graph and sets Gt+1 = Gt.
To show Theorem 1.2 we ﬁrst deﬁne a new potential function g and bound the one step potential
2cd . Since g(·) is convex we obtain from Lemma 2.5, together with by

drop. For x ≥ 0 we deﬁne g(x) = x2

Jensen’s inequality that

E [g (Ψ(St+1)) − g (Ψ(st)) | St = st] ≥ g (E [Ψ(St+1) | St = st]) − g (Ψ(st))

1

2cd · (cid:18)Ψ(st) −
≥
≥ −φt.

Ψ(st) (cid:19)2
c · φt · d

− (Ψ(st))2!

In the following lemma we use some Martingale arguments to show that with a probability of at least
one half vol(Sτ ′′ ) ≥ γd · n/2. This implies that no opinion vanished after τ ′′ w.p. 1/2, which yields
Theorem 1.2.

10

Lemma 2.6. Let |s0| = n/2. Fix some constant γ < 1/4. Assume G1, G2, . . . is s sequence of graphs
generated by the adversary deﬁned above. Then

P(cid:18)g(Ψ(Sτ ′′)) >

4c (cid:19) ≥
2γ · n

1
2

.

Proof. We deﬁne T ′ = min{τ ′′, min{t : vol(St) ≤ 2γdn/2}}, where we recall that τ ′′ is the ﬁrst rounds
so that Pτ ′′

t=1 φt ≥ bn.. We deﬁne

φi

Zt = g(Ψ(St)) +Xi≤t

and show it the following that Zt∧T ′ is a sub-martingale with respect to the sequence S1, S2, . . . , where
t ∧ T ′ = min{t, T ′}.
Case t < T ′: For any t < T ′ we have

E[Zt+1∧T ′ | St, . . . , S1] = E[Zt+1 | St, . . . , S1]

St, . . . , S1


g(Ψ(St+1)) + Xi≤t+1

= E
= E [g(Ψ(St+1)) − g(Ψ(st)) | St, . . . , S1] + g(Ψ(st)) + Xi≤t+1
≥ −φt+1 +

φi (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
φi
g(Ψ(st)) +Xi≤t
 + φt+1

= Zt = Zt∧T ′,

φi

(9)

where the last equality follows since t < T ′.

Case t ≥ T ′: For t ≥ T ′ and we have

E[Z(t+1)∧T ′ | St, . . . , S1] = E[ZT ′ | St, . . . , S1] = ZT ′ = Zt∧T ′,

where the last equality follows since t ≥ T ′. Both cases together show that Zt∧T ′ is a sub-martingale.
According to Theorem 1.2 we have T ′ < ∞. Hence we can apply the optional stopping-time Theorem
(c.f. Theorem A.4), which results in

We deﬁne

E[Zt∧T ′] ≥ E[Z0] =

n
4c

.

p = P (cid:18)g(Ψ(ST ′)) ≤

4c (cid:19) .
2γ · n

By deﬁnition of St, we have |St| ≤ s0 and thus

g(Ψ(ST ′ )) ≤ g(Ψ(s0)) =

n
4c

.

Thus E[Zτ ′′] ≤ n

n
4c

11

n
4c

4c +Pi≤τ ′′ φi. Hence we derive using T ′ ≤ τ ′′ that
= E[Z0] ≤ E[ZT ′ ]
φi
 + (1 − p) ·
≤ p ·
+ Xi≤T ′


+ Xi≤τ ′′
+ (1 − p) ·
≤ 2p · γ ·
+ b · n + 1,

+ (1 − p) ·

≤ 2p · γ ·

2γ · n
4c

n
4c

n
4c

n
4c

φi

n
4c

+ Xi≤τ ′′

φi


i. Hence

which equals

where the last inequality follows from the deﬁnition of τ ′′ together with the fact that φi ≤ 1 for all

0 ≤ 2p · γ ·

n
4c − p ·

n
4c

+ b · n + 1

p · (1 − 2γ) ·

n
4c ≤ b · n + 1.

Thus for γ < 1/4 and b < 1/(18c) we get p ≤ 1/2 and thus we have P (cid:0)g(Ψ(ST ′)) ≤ 2γ·n

which yields the claim.

4c (cid:1) = p ≤ 1/2

In the following we observe that if the adversary is allowed to change the degrees, then the expected

consensus time is super-exponential.

. . . be a sequence of
Observation 1 (super exponential runtime). Let G1 = (V, E1), G2 = (V, E2),
graphs with n nodes, where the edges E1, E2, . . . are distributed by an adaptive adversary, then the
expected consensus time is at least Ω((n/c)n/c) for some constant c.

Proof. The idea is the following. The initial network is a line and there are two opinions 0 and 1
distributed on ﬁrst n/2 and last n/2 nodes respectively. Whenever one opinion i has fewer nodes than
the other, the adversary creates a graph where only one edge is crossing the cut between both opinions
and the smaller opinions forms a clique. Hence, the probability for the smaller opinion to decrease is
O(1/n) and the probability for the bigger opinion to decrease is Ω(1). This can be coupled with a
biased random walk on a line of n/4 nodes with the a transition probability at most 1/(n/4) = 4/n in
one direction and at least 1/2 in the other. Consequently, there exists a constant c such that expected
consensus time is Ω((n/c)n/c).

The following observation shows that the bound of Theorem 1.1 for static regular graphs of O(n/φ)

is tight for regular graphs if either the degree or the conductance is constant.

Observation 2 (lower bound static graph). For every n, d ≥ 3, and constant φ, there exists a d-regular
graph G with n nodes and a constant conductance such that the expected consensus time on G is Ω(n).
Furthermore, for every even n, φ > 1/n, and constant d, there exists a (static) d-regular graph G with
Θ(n) nodes and a conductance of Θ(φ) such that the expected consensus time on G is Ω(n/φ).

Proof. For the ﬁrst part of the claim we argue that the meeting time of a d-regular graphs is Ω(n) [2].
The claim follows from the duality between coalescing random walks and the voter model. For the second
part of the claim we construct a random graph G′ with n′ = Θ(n · φ) nodes and a constant conductance
(See, e.g., [3]). We obtain G by replacing every edge (u, v) of G′ with a path connecting u and v of length
ℓ = Θ(1/φ) and ℓ mod d = 0. Additionally, we make G d-regular by adding ℓ(d − 2)/d nodes to every
path in such away that the distance between u and v is maximised. We note that the obtained graph G
has a conductance of Θ(φ), Θ(n) nodes, and is d-regular. The meeting time of G′ is Ω(n′) [2]. Taking
into account that traversing every path in G takes in expectation ℓ2 = Θ(1/φ2) rounds, the expected
meeting time in G is at least Ω(n′ · ℓ2) = Ω(n/φ). This yields the claim.

3 Analysis of the Biased Voter Model

In this section, we prove Theorem 1.3. We show that the set St of nodes with the preferred opinion
grows roughly at a rate of 1 + Θ(φt), as long as St or S′
t has at least logarithmic size. For the analysis
we break each round down into several steps, where exactly one node which has at least one neighbour
in the opposite set is considered.
Instead of analysing the growth of St for every round we consider
larger time intervals consisting of a suitably chosen number of steps. We change the process slightly
by assuming that there is always one node with the preferred opinion. If in some round the preferred
opinions vanishes totally, Node 1 is set back to the preferred opinion. Symmetrically, if all other opinions
vanishes, then Node 1 is set to Opinion 1. Note that this will only increase the runtime of the process.

The proof unfolds in the following way. First, we deﬁne formally the step sequence S . Second, we
deﬁne (Deﬁnition 1) a step sequence S to be good if, intuitively speaking, the preferred opinion grows
quickly enough in any suﬃciently large subsequence of S . Afterward, we show that if S is a good step
sequence, then the preferred opinion prevails in at most τ ′′′ rounds (Lemma 3.2). Finally, we show that
that S is indeed a good step sequence w.h.p. (Lemma 3.3).

12

We now give some deﬁnitions. Again, we denote by St the random set of nodes that have the preferred
t = V \ St. For a ﬁxed time step t we write st and s′
t.
t which are adjacent to at least one node from st.
t. For each u ∈ V , let λu,t be the number of edges incident with
t), or equivalently, the number of u’s neighbours that have a diﬀerent opinion

opinion right after the ﬁrst t rounds, and let S′
We deﬁne the boundary ∂st as the subset of nodes in s′
We use the symmetric deﬁnition for ∂s′
u crossing the cut cut(st, s′
than u’s before round t.

We divide each round t into |st| + |s′

t| steps, in every step a single node v from either ∂st or ∂s′
t
randomly chooses a neighbour u and adopts its opinion with the corresponding bias. Note that we
assume that v sees u’s opinion referring to beginning of the round, even if was considered before v and
changed its opinion in the meantime. It is convenient to label the steps independently of the round in
which they take place. Hence, step i denotes the i-th step counted from the beginning of the ﬁrst round.
Also ui refers to the node which considered in step i and λi = λui,t. We deﬁne the indicator variable oi
with oi = 1 if ui has the preferred opinion and oi = 0 otherwise. Let

Λ(i) =

i

Xj=1

(1 − oi) · λi

and

Λ′(i) =

i

Xj=1

oi · λi.

Unfortunately, the order in which the nodes are considered in a round is important for our analysis
and cannot be arbitrarily. Intuitively, we order the nodes in st and s′
t such that sum of the degrees of
nodes which are already considered from st and the sum of the degrees of nodes already considered from
s′
t diﬀers by at most d, i.e.,

|Λi − Λ′

i| ≤ d.
The following rule determines the node to be considered in step j + 1:

(10)
if Λ(j) ≤ Λ′(j), then the
(not jet considered) node v ∈ ∂st is with smallest identiﬁer is considered. Otherwise the node v ∈ ∂st
is with smallest identiﬁer is considered. Note that at the ﬁrst step i of any round we have Λi = Λ′
i.
This guarantees that (10) holds. The step sequence S is now deﬁned as a sequence of tuples, i.e.,
S = (u1, Z1), (u2, Z2), . . . , where Zj = 1 if uj changed its opinion in step j and Zj = 0 otherwise for
all j ≥ 1. Observe that when given the initial assignment and the sequence up to step i, then we know
the conﬁguration Ci of the system, i.e., the opinions of all nodes at step i and in which round step i
occurred.

In our analysis we consider the increase in the number of nodes with the preferred opinion in time
intervals which contain a suﬃciently large number of steps, instead of considering one round after the
other. The following deﬁnitions deﬁne these intervals.

For all i, k ≥ 0 where Ci is ﬁxed, we deﬁne the random variable Si,k := min{j : Λj − Λi ≥ k}, which is
the ﬁrst time step such that nodes with a degree-sum of at least k were considered. Let Ii,k = [i + 1, Si,k]
be the corresponding interval where we note that the length is a random variable. We proceed by showing
an easy observation.
Observation 3. The number of steps in the interval Ii,k is at most 2k + 2d, i.e., |Ii,k| ≤ 2k + 2d.
Furthermore, Λ′(Si,k) − Λ′(i) ≤ k + 2d.
Proof. Assume, for the sake of contradiction, that |Ii,k| > 2k + 2d. This implies, by deﬁnition of
Ii,k = [i + 1, Si,k], that the number of edges of the preferred opinion considered in I = [i + 1, 2k + 2d] is
strictly less than k, i.e., Λ(i + 2k + 2d) − Λ(i) < k. We have

Λ′(i + 2k + 2d) − Λ(i + 2k + 2d) > Λ′(i + 2k + 2d) − (Λ(i) + k)

≥ Λ′(i) + 2k + 2d − k − (Λ(i) + k)
= Λ′(i) − Λ(i) + 2d
≥ −d + 2d ≥ d,

(11)

which contradicts (10). Hence |Ii,k| ≤ 2k + 2d.
k + 2d. This implies that

We now prove the second part of the lemma. Assume, for the sake of contradiction, Λ′(Si,k)− Λ′(i) >

Λ′(Si,k) − Λ(Si,k) > Λ′(i) + k + 2d − Λ(Si,k)

≥ Λ′(i) + k + 2d − (Λ(i) + k)
= Λ′(i) − Λ(i) + 2d
≥ −d + 2d ≥ d,

13

(12)

which contradicts (10). Hence Λ′(Si,k) − Λ′(i) ≤ k + 2d.

Fix Ci and let Xi,k be the total number of times during interval Ii,k that a switch from a non-preferred
i,k similarly for the reverse switches. Finally, we deﬁne
i,k; thus Yi,k is the increase in number of nodes that have the preferred opinion during

opinion to the preferred one occurs; and deﬁne X ′
Yi,k = Xi,k − X ′
the time interval Ii,k.
Deﬁne ℓ = 132β log n

(1−α1)2 and β′ =

600d

α1·(1−α1)2 . In the following we deﬁne a good sequence.

Deﬁnition 1. We call the sequence S of steps good if it has all of the following properties for all
i ≤ T ′ = 2β′ · n. Consider the ﬁrst T ′ steps of S (ﬁx CT ′ ). Then,
(a) Y0,T ′ ≥ 2n. (The preferred opinion prevails in at most T ′ steps)
(b) Y0,i + |S0| > 1. (The preferred opinion never vanishes)
(c) For any 1 ≤ k ≤ T ′ we have Yi,k ≥ −ℓ. (# nodes of the pref. opinion never drops by ℓ)
(d) For any ℓ ≤ γ ≤ T ′, we have Yi,k > γ, where k = γ · β′. (# nodes of the pref. opinion increases)

This deﬁnition allows us to prove in a convenient way that a step sequence S is w.h.p. good: For each
property, we simply consider each (suﬃciently large) subsequence S separately and we show that w.h.p.
S has the desired property. We achieve this by using a concentration bound on Yi,k which we establish
in Lemma 3.1. Afterward, we take union bound over all of these subsequences and properties. Using
the union bound allows us to show the desired properties in all subsequences in spite of the emerging
dependencies. This is done in Lemma 3.2.

We now show the concentration bounds on Yi,k. These bounds rely on the Chernoﬀ-type bound
established in Lemma A.5. This Chernoﬀ-type bound shows concentration for variables having the
property that the sum of the conditional probabilities of the variables, given all previous variables, is
always bounded (from above or below) by some b. The bound might be of general interest.

Lemma 3.1. Fix conﬁguration Ci. Then,
(a) For k = γ

α1·(1−α1)2 with γ ≥ 1 it holds that

256d

Pr (Yi,k < γ) ≤ exp (−γ) .
(b) For k ≥ 0, any b′ = α1 · (k + 2d)/d, and any δ > 0 it holds that

Proof. First we show a lower bound for Xi,k and an upper bound for X ′

i,k.

Pr (Yi,k < −(1 + δ)b′) ≤ exp(cid:16)

eδ

(1+δ)1+δ(cid:17)b′

.

For 1 ≤ j ≤ 2k + 2d, let Aj be the event that ui+j switches its opinion from any opinion other than

the preferred opinion to the preferred one. Furthermore, for 1 ≤ j ≤ 2k + 2d, let

Zj =(1

0

if i + j ≤ Si,k and Aj
otherwise

Deﬁne

Pj =(Pr(Zj = 1 | Z1, . . . , Zj−1) = λi+j /d
It follows that Xi,k =Pj Zj. We set B =Pj Pi. We derive

0

i + j ≤ Si,k and Aj
otherwise

B =Xj

Pi = Xs∈Ii,k

(1 − os)λs/d = (Λ(Si,k) − Λ(i))/d ≥ k/d,

by deﬁnition of Ii,k. From Lemma A.5(b) with b∗ = k/d ≤ B we obtain for any 0 < δ < 1, that

Pr(Xi,k < (1 − δ)b∗) < e−b∗·δ2/2

(13)

We now use a similar reasoning to bound X ′

j be the event that ui+j
switches its opinion from the preferred opinion to any other opinion. Deﬁne for 1 ≤ j ≤ 2k + 2d the
variables Z ′
j instead of Aj. And similarly, deﬁne for 1 ≤ j ≤ 2k + 2d the

i,k. For 1 ≤ j ≤ 2k + 2d let A′

j similar to Zj but using A′

14

variables P ′

j similar as Pj but using Z ′

j, . . . , Z ′

1 instead of Zj, . . . , Z1. In the same spirit as before one

can deﬁne B′ =Pj P ′
B′ =Xj

i . We derive

P ′

i ≤ Xs∈Ii,k

os · α1 · λs/d = α1 · (Λ′(Si,k) − Λ′(i))/d ≤ α1 · (k + 2d)/d,

where the last inequality follows from Observation 3.

Using a similar reasoning for X ′

i,k and applying Lemma A.5(a) with b′ = α1·(k+2d)

d

δ > 0,

≥ B′, yields for

i,k > (1 + δ)b′(cid:1) <(cid:16)

Pr(cid:0)X ′
To prove part (a) we now combine (13) and (14) as follows. Since k ≥ 16d/(1 − α1), for δ = (1 − α1)/8,
we have that w.p. at least 1 − e−b∗·δ2/2 −(cid:16)
Yi,k = Xi,k − X ′

(1+δ)1+δ(cid:17)b′

that

(14)

i,k

eδ

eδ

(1+δ)1+δ(cid:17)b′

> γ.

We proceed by bounding 1 − e−b∗·δ2/2 −(cid:16)

eδ

eδ

. Let p = e−b∗·δ2/2 +(cid:16)
(1+δ)1+δ(cid:17)b′

(1+δ)1+δ(cid:17)b′
p ≤ e−b∗·δ2/2 +(cid:16)
≤ e−b∗·δ2/2 + e−b′·δ2/2
= e−b∗·(1−α1)2/128 + e−b′·(1−α1)2/128
≤ 2e−α1·(1−α1)2·k/(128d)
≤ e−α1·(1−α1)2·k/(266d)
= e−γ,

where we used that k ≥

256d

α1·(1−α1)2 . Part (a) follows from (15) and (16).

We now prove part (b). Since we used that Yi,k ≥ −X ′

i,k, the bound from (14) implies

Pr(Yi,k < −(1 + δ)b′) ≤ Pr(X ′

i,k > (1 + δ)b′) <(cid:16)

eδ

(1+δ)1+δ(cid:17)b′

Hence, part (b) of the lemma follows. This completes the proof of Lemma 3.1.

The following two lemmas imply the theorem.

15

k

k

2d

≥

k (cid:19)

≥ (1 − δ)b∗ − (1 + δ)b′
d (cid:18)1 − δ − (1 + δ)α1 − (1 + δ)
≥
d (cid:18)1 − α1 − 2δ − (1 + δ)
k (cid:19)
d (cid:18)1 − α1 − (1 − α1)/4 − (1 + δ)
k (cid:19)
(1 − α1 − (1 − α1)/4 − (1 − α1)/4)

≥

k
d

2d

2d

k

≥
≥ (1 − α1)
= γ

32

α1·(1−α1)

k
2d

(15)

(16)

eδ

(1+δ)1+δ(cid:17)b′

. We have

Lemma 3.2. Let S be a step sequence. Then S is good with high probability.

Proof. We show for every property of Deﬁnition 1 that it holds with high probability. Fix an arbitrary
i ≤ T ′.
(a) We derive from Lemma 3.1(a) with k = 2n · β′ that Pr(Y0,k < 2n) ≤ e−2n ≤ n−β.
(b) Follows from (c).
(c) Fix an arbitrary k ≤ T ′. We distinguish between two cases

(i) Case k ≤ β · log n · β′. We derive from Lemma 3.1(b) the following. For k ≥ 0, any b′ =

α1 · (k + 2d)/d ≤ 300β log n

(1−α1)2 = ℓ/2, and any δ > 0 it holds that

Pr (Yi,k < −(1 + δ)b′) ≤ exp(cid:16)

We distinguish once more between two cases.

eδ

(1+δ)1+δ(cid:17)b′

.

• If q 3β log n

b′ < 1 set δ =q 3β log n

b′ < 1. We have

Pr (Yi,k < −ℓ) ≤ Pr (Yi,k < −2b′) ≤ Pr (Yi,k < −(1 + δ)b′)
≤ exp(cid:0)−δ2b′/3(cid:1) ≤ n−β.

(1+δ)1+δ(cid:17)b′

≤ exp(cid:16)

eδ

• Otherwise, we have b′ ≤ 3β log n < 4β log n. Set δ = 4β log n
(1+δ)1+δ(cid:17)b′

P r (Yi,k < −ℓ) ≤ Pr (Yi,k < −(1 + δ)b′) ≤ exp(cid:16)

eδ

b′ > 1. We have

≤ exp (−δb′/3) ≤ n−β.

Thus, the claim follows.

n−β.

(ii) Case k > β · log n· β′. We derive from Lemma 3.1(a) that Pr(Yi,k < −ℓ) ≤ Pr(Yi,k < β log n) <
Hence, in all cases we have Pr(Yi,k < −ℓ) ≤ n−β.

(d) We derive from Lemma 3.1(a) with k = z · β′ that Pr(Yi,k < z) < exp(−z) ≤ n−β.
Since 0 < α1 < 1, we have that T ′ ≤ n3. The number of events in Deﬁnition 1 is bounded by 5T ′2 ≤ n7.
Thus choosing, β ≥ 8, and taking union bound over all these events yields the claim.
Lemma 3.3. If S is a good step sequence, then in at most T ′ time steps, the preferred opinion prevails
and the T ′ time steps occur before round τ ′′′.

Proof. Recall, that we assume that if in some round the preferred opinions vanishes, then after this
round, the opinion of some ﬁxed node switches spontaneously. Similarly, if in some round the preferred
opinion prevails, then after this round, the opinion of some ﬁxed node switches spontaneously to an
arbitrary other opinion.the preferred opinion never vanishes. This process P ′ diverges from the original
process P only after the ﬁrst step where either the preferred opinion prevails or vanishes. From (a) and
(b) of the deﬁnition of a good sequence it follows that the preferred opinion prevails in P ′ after T ′ steps.
It is easy to couple both process so that the good opinion also prevails in the original process P .

t)| ≥ d· min{|St|,|S′

It remains to argue that the T ′ time steps happen before round τ ′′′. Using the deﬁnition of the
conductance, we can lower bound the number of steps in any round t by |cut(St, S′
i|}·
φt. We then consider intervals of suﬃcient length in which the size of the preferred doubles as long
as its size is below n/2. Afterward, one can argue that size of all the non preferred opinions halves
every interval. We now give some intuition for the remainder of the proof. Consider the following toy
case example of a static graphs with α1 = 0 (rumor spreading). The length of an interval required
for the preferred S with |s| ≤ n/3 to double in expectation is bounded by 1/φ.
In our setting, we
need to handle two main diﬀerence w.r.t. the toy case example. First, the number of nodes with the
preferred opinion can reduce by up to β log n (Deﬁnition 1(c)). Since β is constant, this can be easy
compensated by slightly longer intervals. Second, the graph is dynamic as opposed to static. To address
this we ’discretize’, similarly as before, rounds into consecutive phases which ensure that sum of the φt
for rounds t in this phase is at least 1. Thus, in our toy example one requires 1 phases in expectation.
We proceed by discretizing the rounds into phases. Phase i starts at round τ (i) = min{t :Pt
j=1 φj ≥
2i} for i ≥ 0 and it ends at round τ (i + 1) − 1. Since φj ≤ 1 for all j ≥ 0 we have τ (0) < τ (1) < . . . and

16

φ(j) ≥ 1 for i ≥ 0. We now map the steps of S to rounds. For this we deﬁne the check point tj

j=τi

Pτi+1
to be the following round for j ≤ jmax = 4 log n + 1.

0
τ (3ℓ · β′/d)
τ (3ℓ · β′/d + (j − 1) · 6β′/d)
τ (6ℓ · β′/d + (jmax − 1) · 6β′/d)

if j = 0
if j = 1
if 2 ≤ j ≤ 4 log n
if j = jmax

Given any good sequence S , we show by induction that over j the following lower bounds on the

size of the preferred opinion at these check points. Formally, deﬁne for all j ≤ jmax that

tj =





ζ(j) =

0
2ℓ
min{2ℓ · 2j−2, 2n/3}
min{n − 2log(n/3)−(j−2 log n), n − 2ℓ}
n

if j = 0
if j = 1
if 2 ≤ j ≤ 2 log n
if 2 log n < j ≤ 4 log n
if j = jmax

In the following we show for all j ≤ jmax that

|stj| ≥ ζ(j),

(17)

We consider each of the cases depending of the size of j w.r.t. (17). The induction hypothesis j = 0
holds trivially. Suppose the claim holds for j − 1 for j ≥ 1.
We assume w.l.o.g. the following about S . There is no step t before round tj with |st| ≥ ζ(j) + ℓ
since by Deﬁnition 1(c) this implies that |stj| ≥ ζ(j) which yields the inductive step. This assumption,
implies that for all t ≤ tj we have |st| < ζ(j)| + ℓ. On the other hand, by induction hypothesis and
Deﬁnition 1(c) we have ζ(j − 1) + ℓ ≤ |st|. Thus, we assume in the following

|st| ∈ [ζ(j − 1) − ℓ, ζ(j) + ℓ]

(18)

We now distinguish between the following cases based on j.

• j = 1 : In every step t ∈ (0, t1] we have φt ≥ d and hence the number of time steps in the interval
(0, t1] is at leastPt1
i=1 d ≥ 3ℓ · β′. Let k = 3ℓ · β′. Deﬁnition 1(d) implies that Y1,k > 3ℓ. Hence, by
Deﬁnition 1(c) we have |st1| ≥ ζ(1) as desired.
• 2 ≤ j ≤ 2 log n : In every step t ∈ (tj−1, tj] we have, by (18),
φt ≥ d · (min{|st|,|s′
t|} − ℓ) ≥ d · min{ζ(j − 1) − ℓ, n/3 − ℓ} ≥ d · (ζ(j − 1) − ℓ) ≥ d · ζ(j − 1)/2.
Hence the number of time steps in the interval (tj−1, tj] is at least 3ζ(j−1)·β′. Let k = 3ζ(j−1)·β′.
Deﬁnition 1(d) implies that Ytj−1,k ≥ 3ζ(j − 1) ≥ ζ(j) + ℓ. Hence, by Deﬁnition 1(c) we have
|stj| ≥ ζ(j).

• 2 log n < j ≤ 2 log n : In every step t ∈ (tj−1, tj] we have, by (18),

φt ≥ d · (min{|st|,|s′

t|} − ℓ) ≥ d · (n − ζ(j) − ℓ) ≥ d · (n − ζ(j))/2.

Hence the number of time steps in the interval (tj−1, tj] is at leastPtj
i=tj−1+1 d·(n−ζ(j))/2 ≥ 3(n−
ζ(j))· β′. Let k = 3(n− ζ(j))· β′. Deﬁnition 1(d) implies that Ytj−1,k ≥ 3(n− ζ(j)) ≥ (n− ζ(j)) + ℓ.
Hence, by Deﬁnition 1(c) we have |stj| ≥ min{ζ(j − 1) + (n − ζ(j)), n − 2ℓ} ≥ ζ(j).
• jmax : In every step t ∈ (tj−1, tj] we have, by (18), φt ≥ d · 1 = d. Hence the number of time
steps in the interval (tj−1, tj] is at least d ≥ 3ℓ · β′. Let k = 3ℓ · β′. Deﬁnition 1(d) implies that
Ytjmax−1,k ≥ 3ℓ. Hence, by Deﬁnition 1(c) we have |stjmax| ≥ n = ζ(jmax).

This completes the proof of (17). We have

tjmax = τ (6ℓ · β′ + jmax · 6β′/d) ≤ 4 (6ℓ · β′ + (jmax − 1) · 2β′/d) ≤ τ ′′′,

which yields the proof.

Proof of Theorem 1.3. The claim follows from Lemma 3.2 together with Lemma 3.3.

17

References

[1] M. A. Abdullah and M. Draief. Global majority consensus by local majority polling on graphs of a

given degree sequence. Discrete Applied Mathematics, 180:1–10, 2015.

[2] D. Aldous and J. Fill. Reversible markov chains and random walks on graphs, 2002. Unpublished.

http://www.stat.berkeley.edu/~aldous/RWG/book.html.

[3] N. Alon, O. Schwartz, and A. Shapira. An elementary construction of constant-degree expanders.

Comb. Probab. Comput., 17(3):319–327, May 2008.

[4] C. Avin, M. Koucký, and Z. Lotker. How to explore a fast-changing world (cover time of a simple
random walk on evolving graphs). In Automata, Languages and Programming, 35th International
Colloquium, ICALP 2008, Reykjavik, Iceland, July 7-11, 2008, Proceedings, Part I: Tack A: Algo-
rithms, Automata, Complexity, and Games, pages 121–132, 2008.

[5] Y. Azar, A. Broder, A. Karlin, and E. Upfal. Balanced allocations. SIAM J. Comput., 29(1):180–200,

1999.

[6] C. Cooper, R. Elsässer, H. Ono, and T. Radzik. Coalescing random walks and voting on connected

graphs. SIAM J. Discrete Math., 27(4):1748–1758, 2013.

[7] C. Cooper, R. Elsässer, and T. Radzik. The power of two choices in distributed voting. In ICALP,

pages 435–446, 2014.

[8] C. Cooper, R. Elsässer, T. Radzik, N. Rivera, and T. Shiraga. Fast Consensus for Voting on General

Expander Graphs. In Proc. DISC ’15, pages 248–262, 2015.

[9] J. Cruise and A. Ganesh. Probabilistic consensus via polling and majority rules. Queueing Systems,

78(2):99–120, 2014.

[10] J. Díaz, L. Goldberg, G. Mertzios, D. Richerby, M. Serna, and P. Spirakis. Approximating ﬁxation

probabilities in the generalized moran process. Algorithmica, 69(1):78–91, 2014.

[11] J. Díaz, L. Goldberg, D. Richerby, and M. Serna. Absorption time of the moran process. CoRR,

abs/1311.7631, 2013.

[12] P. Donnelly and D. Welsh. Finite particle systems and infection models. Mathematical Proceedings

of the Cambridge Philosophical Society, 94:167–182, 1983.

[13] R. Elsässer, T. Friedetzky, D. Kaaser, F. Mallmann-Trenn, and H. Trinker. Eﬃcient k-Party Voting

with Two Choices. ArXiv e-prints, Feb. 2016.

[14] G. Giakkoupis. Tight bounds for rumor spreading in graphs of a given conductance. In STACS,

pages 57–68, 2011.

[15] G. Giakkoupis, T. Sauerwald, and A. Stauﬀer. Randomized rumor spreading in dynamic graphs.
In Automata, Languages, and Programming - 41st International Colloquium, ICALP 2014, Copen-
hagen, Denmark, July 8-11, 2014, Proceedings, Part II, pages 495–507, 2014.

[16] Y. Hassin and D. Peleg. Distributed probabilistic polling and applications to proportionate agree-

ment. Information and Computation, 171(2):248–268, 2001.

[17] R. Holley and T. Liggett. Ergodic theorems for weakly interacting inﬁnite systems and the voter

model. The Annals of Probability, 3(4):643–663, 1975.

[18] B. Houchmandzadeh and M. Vallade. The ﬁxation probability of a beneﬁcial mutation in a geo-

graphically structured population. New Journal of Physics, 13(7):073020, 2011.

[19] M. Kearns and J. Tan. Biased voting and the democratic primary problem. In WINE, pages 639–652,

2008.

[20] F. Kuhn, N. Lynch, and R. Oshman. Distributed computation in dynamic networks. In Proceedings
of the 42nd ACM Symposium on Theory of Computing, STOC 2010, Cambridge, Massachusetts,
USA, 5-8 June 2010, pages 513–522, 2010.

18

[21] H. Lam, Z. Liu, M. Mitzenmacher, X. Sun, and Y. Wang. Information dissemination via random
walks in d-dimensional space. In Proceedings of the Twenty-third Annual ACM-SIAM Symposium
on Discrete Algorithms, SODA ’12, pages 1612–1622. SIAM, 2012.

[22] N. Lanchier and C. Neuhauser. Voter model and biased voter model in heterogeneous environments.

Journal of Applied Probability, 44(3):770–787, 2007.

[23] T. Liggett. Interacting Particle Systems. Springer Berlin Heidelberg, 1985.

[24] G. Mertzios and P. Spirakis. Strong bounds for evolution in networks. In ICALP, pages 669–680,

2013.

[25] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomized Algorithms and Proba-

bilistic Analysis. Cambridge Univ. Press, 2005.

[26] R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge University Press, 1995.

[27] T. Nakata, H. Imahayashi, and M. Yamashita. A probabilistic local majority polling game on
weighted directed graphs with an application to the distributed agreement problem. Networks,
35(4):266–273, 2000.

[28] R. Oliveira. On the coalescence time of reversible random walks. Trans. Am. Math. Soc.,

364(4):2109–2128, 2012.

[29] Y. Peres, A. Sinclair, P. Sousi, and A. Stauﬀer. Mobile geometric graphs: detection, coverage and

percolation. Probability Theory and Related Fields, 156(1-2):273–305, 2013.

19

A Auxiliary Claims

Lemma A.1. Let Xi and Yi be the random variables deﬁned in the proof of Lemma 2.1. Let f (·) be a
concave and continuous function. We have
E [f (Pi Xi)] ≤ E [f (Pi Yi)] .

Proof. We show by induction over i that the variables

E[f (Y1 + ··· + Yi−1 + Xi + ··· + Xk)] ≤ E[f (Y1 + ··· + Yi + Xi+1 + ··· + Xk)].

Let Z = Y1 + ··· + Yi−1 + Xi+1 + ··· + Xk. In step i → i + 1 we have

=

λi

λi

λi
di

= E[f (Z + Xi)]

E[f (Y1 + ··· + Yi−1 + Xi + ··· + Xk)]
di(cid:19) E[f (Z)]
E[f (Z + di] +(cid:18)1 −
= λiE(cid:20) f (Z + di)
di(cid:19) E [f (Z)]
(cid:21) +(cid:18)1 −
= λiE(cid:20) f (Z + di) − f (Z)
(cid:21) + E [f (Z)]
(cid:21) + E [f (Z)]
≤ λiE(cid:20) f (Z + λi) − f (Z)
= E[f (Y1 + ··· + Yi + Xi+1 + ··· + Xk)],

di

λi

di

where the last inequality follows from the concavity of f (·).
Lemma A.2. Let Z1, . . . , Zn be independent random variables and Z = Pi Zi.
E[Z 3] =Pi(cid:0) E[Z 3
Proof. In the following we make use of E[Pi Zi] = 0. We derive

i ] · E[Zi] + 2 E[Zi]3(cid:1).

i ] − 3 E[Z 2

If E[Z] = 0, then

E(cid:2)Z 3(cid:3) = E
Xi,j,k
E
ZiXj,k
=Xi
i(cid:3) + 3Xi
=Xi
E(cid:2)Z 3
E [Zi] Xj, j6=i
+Xi
i(cid:3) + 3Xi
=Xi
E(cid:2)Z 3
E [Zi] Xj, j6=i
+Xi
i(cid:3) − 3Xi
=Xi
E(cid:2)Z 3
E [Zi] Xj j6=i
+Xi
i(cid:3) − 3Xi
=Xi
E(cid:2)Z 3
i(cid:3) − 3Xi
=Xi
E(cid:2)Z 3

ZiZjZk

ZjZk

i(cid:3) E
Zj
 Xj, j6=i
E(cid:2)Z 2

E [Zj] E
Zk
 Xk, k6=i,j

E(cid:2)Z 2
i(cid:3) (0 − E[Zi])
E [Zj] (0 − E[Zi] − E[Zj])
E(cid:2)Z 2
E [Zj] (− E[Zj])
E(cid:2)Z 2
E(cid:2)Z 2

i(cid:3) E [Zi] + 2Xi
i(cid:3) E [Zi] + 2Xi

i(cid:3) E [Zi] +Xi

20

E [Zi] (− E[Zi]) Xj j6=i

E [Zj]

E [Zi] (− E[Zi])(− E[Zi])
E[Zi]3.

We now show d-regular graphs with a cut of size Θ(φtdn) exist indeed.

Lemma A.3. Let 1
nd ≤ φ ≤ 1. Let 0 < γ < 1 be some constant. Let d ≥ 6 be an even integer. For any
integer n′ ∈ [γn, n/2] there exists a d-regular graph G = (V, E) with the following property. There is a
set S ⊂ V with |S| = n′ such that |cut(S, V \ S)| = Θ(φdn). Moreover, there are at least n′/2 without
any edges in cut(S, V \ S).
Proof. In the following we create two d-regular graphs G′ and G′′ and connect them to a d-regular graph G
such that the cut size is Θ(φdn). Let G′ = (V ′, E′) be the circulant graph C⌊d/2⌋
n′}.
Let G′′ = (V ′′, E′′) be the circulant graph C⌊d/2⌋
n−n′}. We now connect G′ and
G′′. W.l.o.g. φ ≤ 1/d. The case φ > 1/d is analogue. We choose k such that we have 2 ≤ k < n′/2
and k = Θ(φdn′). Let S′ = {v′
1, , . . . , , v′
i+1)
i+1). Note that G′(G′′ respectively) is still connected. Furthermore, the
with 1 ≤ i ≤ k − 1 and (v′′
i , v′′
k have degree d − 1 and all other vertices of S′ ∪ S′′ have degree d − 2. One can
vertices v′
easily add (2k − 2) edges such that (i) one endpoint of every edge is in V ′ and one in V ′′, and (ii) all
vertices in G′ and G′′ have degree d.
Note that the obtained graph G is connected and the cut |cut(V ′, V \V ′)| contains (2k−2) = Θ(φdn′)

n−n′ with V ′ = {v′′
1 , . . . , v′′

k}. Now we remove all edges (v′

k} and let S′′ = {v′′

with V ′ = {v′

1, v′

k, v′′

1 , and v′′

1, . . . , v′

edges. The claim follows directly.

n′

1 , . . . , v′′

i, v′

Theorem A.4 ( [25, Theorem 12.2]). If Z0, Z1, . . . is a martingale with respect to X1, X2, . . . and if T
is a stopping time for X1, X2, . . . , then

E[Zt] = E[Z0]

whenever one of the following holds:

• The Zi are bounded, so there is a constant for all i, |Zi| ≤ c;
• T is bounded;
• E[T ] ≤ ∞, and there is a constant c such that E[Zt+1 − Zt|X1, . . . Xt] < c;

A.1 A Chernoﬀ-type bound

The following lemma bounds the sum of (dependent) binary random variables, under the assumption that
the sum of the conditional probabilities of the variables, given all previous variables, is always bounded
(from above or below) by some b. The bounds are the same as the ones for independent variables but
use b in place of µ. The bound can be seen as a generalisation of [5]. The proof follows the proof of the
independent case.

Lemma A.5 (Chernoﬀ Bound for Dependent Setting). Let Z1, Z2, . . . , Zℓ be a sequences of binary

random variables, and for each 1 ≤ i ≤ ℓ, let pi = Pr(Zi = 1 | Z1, . . . , Zi−1). Let Z =Pi Zi, B =Pi pi.
(a) For any b ≥ 0 with Pr(B ≤ b) = 1, it holds for any δ > 0 that
eδ

(1 + δ)1+δ(cid:19)b
(b) For any b ≥ 0 with Pr(B ≥ b) = 1, then for any 0 < δ < 1 it holds that

Pr(Z > (1 + δ) · b) <(cid:18)

.

Pr(Z < (1 − δ)b) < e−bδ2/2.

Proof. The proof follows the proof of the Chernoﬀ bound given in [26]. However, the random variables
{Zi : 1 ≤ i ≤ k} are not independent. For any positive real t we have Pr(Z ≥ (1 + δ)b) = Pr(exp(tZ) ≥
exp(t(1 + δ)b)). Thus, by applying Markov inequality we derive

We now bound E[exp(tZ)]. By law of total expectation and p1 = Pr(Z1 = 1) we get

Pr(Z ≥ (1 + δ)b) < E[exp(tZ)]
exp(t(1+δ)b) .

(19)

E[exp(tZ)] = E[exp(tZ)|Z1 = 1] Pr(Z1 = 1) + E[exp(tZ)|Z1 = 0] Pr(Z1 = 0)

= E[exp(tZ)|Z1 = 1]p1 + E[exp(tZ)|Z1 = 0](1 − p1)

21

k

k

Repeating this inductively for the variables Z2, . . . , Zk yields

k

k

Zi!(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Zi!(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z1 = 0# (1 − p1)
Z1 = 1# exp(t)p1 + E"exp t
= E"exp t
Xi=2
Xi=2
Zi!(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Zi)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Z1 = 0#) (p1exp(t) + 1 − p1).
≤ max(E"exp(t
Xi=2
Xi=2
(Piexp(t) + 1 − Pi) =Yi
E[exp(tZ)] <Yi

Z1 = 1# , E"exp t

(1 + Pi(exp(t) − 1)).

Using 1 + x < ex and rearranging gives E[exp(tZ)] < exp((exp(t) − 1)b). Plugging this into Eq. (19)
yields Claim (a). Claim (b) can be proven analogously.

22

