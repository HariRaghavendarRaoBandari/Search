6
1
0
2

 
r
a

M
4

 

 
 
]
T
G
.
s
c
[
 
 

1
v
8
1
3
1
0

.

3
0
6
1
:
v
i
X
r
a

Recovering Games from Perturbed Equilibrium Observations Using

Juba ZIANI∗

Convex Optimization
Venkat CHANDRASEKARAN†

Katrina LIGETT‡

March 7, 2016

Abstract

We study the problem of reconstructing a game that is consistent with observed equilibrium play, a
fundamental problem in econometrics. Our contribution is to develop and analyze a new methodology
based on convex optimization to address this problem for many classes of games and observation models
of interest. Our approach provides the ﬂexibility to solve a number of variants and specializations of this
problem, such as an evaluation of the power of games from a particular class (e.g., zero-sum, potential,
linearly parameterized) to explain player behavior or the extent to which a particular set of observations
tightly constrains the space of consistent explanations; it can also simply provide a compact summary of
observed behavior. The framework underlying the development in this paper also diﬀers from much of
the literature on econometrics, as we do not make strong distributional assumptions on the observations
of player actions.

We illustrate our approach with numerical simulations.

1

Introduction

In this paper, we study the problem of recovering properties and—when possible—payoﬀs of a game, based
on observations of the actions of the players. There are several reasons why one might want to extrapolate
beyond observations of player behavior. Reconstructing a game payoﬀ matrix that explains observed behavior
well (say, assuming observed behavior was generated by equilibrium play under perturbations of an underlying
game) provides a compact, interpretable summary of said behavior. The reconstruction process may also
yield insight into how tightly the observed behavior constrains the space of possible explanatory games—are
there multiple, wildly diﬀering possible explanations for the observed behavior? When the observations tightly
constrain reconstruction of the underlying game, they may also yield predictive power; an observer who
understands the payoﬀ matrix of a game may be able to predict how player behavior will change under
modiﬁcations to the underlying game, and may also be better able to manipulate game outcomes. Even when
observations do not tightly constrain the space of explanatory games, one may wish to verify whether the
observed behavior is consistent with certain assumptions—could the observed behavior have been generated
by a zero-sum game? a potential game? How well is it explained by other models?

These questions are solidly within the domain of econometrics, an area that largely focuses on the
identiﬁcation (i.e., parameter-ﬁtting) of simple models given observational data (data not generated by
controlled experiments). Our approach is to cast the task of reconstructing and understanding games
consistent with player behavior as an optimization problem, where observations of equilibrium play act as
constraints on the space of possible explanatory games. This approach allows us to sidestep issues of model
selection (we need not decide which aspects of the data to include in a model). Our approach may be viewed
as complementary to a model-driven approach, in that the tools we provide here may be used to objectively

∗California Institute of Technology, jziani@caltech.edu
†California Institute of Technology, venkatc@caltech.edu
‡Hebrew University of Jerusalem and California Institute of Technology, katrina.ligett@mail.huji.ac.il

1

evaluate the quality of ﬁt one achieves under certain modeling assumptions. Our approach also allows us to
explore a variety of assumptions about the information that might available to an observer, and the eﬀect
that it has on constraining the space of consistent games.

1.1 Summary of results

We study a setting in which, at each timestep, an observer observes the actions selected by the players in
a ﬁnite, two-player game1. We assume that players play according to some correlated equilibrium (a more
permissive concept than Nash equilibria). In order to justify that the observer sees more than one ﬁxed
equilibrium of the underlying game, we assume that on each timestep, players experience (and play some
equilibrium of) a slightly perturbed version of the underlying game. As discussed in the related work section,
this is a standard approach.2 We assume that the perturbations are “small,” but, unlike in previous literature,
we do not make distributional assumptions on the perturbations. We also make no assumptions on the
selection rule used by the players to decide which equilibrium to play, when multiple equilibria are present.
In this setting, we give a computationally eﬃcient algorithm (Section 3.1), using convex optimization
techniques, to identify the game(s) that best explain the observations. That is, we return a game that
minimizes a measure of the extent of the perturbations necessary for the observed behaviors to correspond to
equilibria of perturbed versions of the game. We can extend our framework (Section 3.2) to ﬁnd the best
explanatory game when we are restricted to recover games with certain linear properties, e.g., zero-sum
games, potential games, and games whose utilities can be parametrized by linear functions; this allows us to
determine to what extent the observed behavior is consistent with such assumptions on the underlying game.
Some sequences of observations may not suﬃciently constrain the set of games that are consistent with
them; in such a case, one may not be able to draw sharp conclusions about the game that generated
them. To this end, we give an eﬃcient algorithm (Section 3.3) that, given a set of observations, determines
whether accurate recovery of the underlying game is impossible, i.e., whether there exist several, quite
diﬀerent, games that are all good explanations for the observations. Additionally (Section 5), we explore an
enriched observation model where the observer also learns the expected payoﬀ of each observed equilibrium
strategy, and we give structural conditions on the sets of observations in this model that allow for accurate
recovery. We also exhibit examples in which said conditions do not hold, and accurate recovery is not possible.
Another source of information one might assume the observer has access to, inspired by approaches taken in
econometrics, is the “payoﬀ shifters” that aﬀect the game payoﬀs from round to round; we see that these also
ﬁt nicely into our approach (Section 4).

If the payoﬀs and shifters of the played equilibria are not observed and no additional properties of
the underlying game are assumed, the all-constant game always provides an optimal explanation for the
observed behavior. However, one presumably wishes to recover a nontrivial consistent game. We provide a
framework (Section 6) that eliminates such games by controlling the level of degeneracy of the explanations,
and provide bounds on the trade-oﬀ between recovering non-trivial games and recovering games for which
the perturbations that need be added in order to explain the observations are small.

Finally, in Section 7, we illustrate our approach with some simple simulations.

1.2 Related work

An important thread of theoretical economics takes an empirical perspective, with the goal of understanding
what properties of agents are consistent with given, observed data on their economic behavior. While part of
this literature focuses on discrete choice in single-agent problems, another signiﬁcant line of research aims to
rationalize the behavior of several agents in game theoretic settings, where their decisions impact each other.
In both the single-agent discrete choice and the multi-agent game theory settings, one important modeling
issue is whether and why one would ever observe multiple, diﬀering agent behaviors. A common approach

1Our framework can be extended to multi-player games with succinct representations; for clarity, we focus here on the

two-payer case.

2This approach can also be used to model multiple observations coming from play of a game in slightly diﬀerent settings, e.g.,

in diﬀerent cities.

2

is to assume that the agents’ behaviors are observed in several perturbed versions of the same game. A
natural, well-established approach models diﬀerent observations found in the data as stemming from random
perturbations to the agents’ utilities, as in [1, 4, 9, 10, 15, 16]. We adopt a similar approach here.

It is common (see [1–3, 5, 7] for example) to assume that the payoﬀ perturbations and covariates have an
observable part that is seen by the observer—usually observable economic parameters like costs or taxes—and
a non-observable part, often assuming the probability distribution is known to him; the data he observes
can be used to estimate the probability of diﬀerent outcomes conditioned on the observed payoﬀ shifters
(perturbations). We demonstrate how a version of such payoﬀ shifter information can be incorporated into
our approach.

Much of the econometric literature on making inferences from observed equilibrium play restricts players’
utility functions to be parametrized, often as a linear function of covariates, and aims to ﬁnd the best value
of the parameter. Additionally, most of the literature does not deal with the possible presence of multiple
equilibria. In an interesting departure from common approaches, [7] use random set theory and convex
optimization to give a tractable representation of the sharp identiﬁcation region—the collection of parameter
values that could generate the same distribution of observations as found in the data—for a wide class of
incomplete information problems with convex predictions; their results encompass ﬁnite games with multiple
equilibria, and rely on information on the payoﬀ shifters, and also on the parametric form of the utility
function. Although their setting is diﬀerent from ours, we use the setting of their simulations as the jumping
oﬀ point for our own experimental section.

Recently, [13] study a dynamic sponsored search auction game, and provide a characterization of the
rationalizable set consisting in the set of private parameters of a parametrized utility function that are
consistent with the observations, under the relaxed assumption that players need not follow equilibrium play,
but rather use some form of no-regret learning. They do so under no assumptions on the distribution of the
non-observable parameters, nor on the selection rule used to choose among several possible no-regret plays.
[8, 14] study a model in which equilibrium behavior can be observed, but in a very concrete network
setting, and study the query complexity of devising a variant of the game to induce desired target ﬂows as
equilibria. [6] adopt a diﬀerent model in which the observer observes what joint strategies are played when
restricting the actions of the players in a complete information game with no perturbations, and show that
data with certain properties can be rationalized by games with low complexity.

2 Model and setting
Consider a ﬁnite two-player game G; we will refer to it as the true or underlying game. Let A1,A2 be the
ﬁnite sets of actions available to players 1 and 2, respectively, and let m1 = |A1| and m2 = |A2| be the
number of actions available to them. For every (i, j) ∈ A1 × A2, we denote by Gp(i, j) the payoﬀ of player
p when player 1 chooses action i and player 2 chooses action j. Gp ∈ Rm1×m2 is the vector representation
of the utility of player p, and we often abuse notation and write G = (G1, G2). The strategies available to
player p are simply the distributions over Ap. A strategy proﬁle is a pair of strategies (distributions over
actions), one for each player. A joint strategy proﬁle is a distribution over pairs of actions (one for each
player); it is not required to be a product distribution. We refer to strategies as pure when they place their
entire probability mass on a single action, and mixed otherwise.
We consider l perturbed versions of the game G, indexed by k ∈ [l] so that the kth perturbed game is
denoted Gk; one can for instance imagine each Gk as a version of the game G played in a diﬀerent location k.
The same notation as for G applies to the Gk’s.

Throughout the paper, we assume that for each k, the players’ strategies are given by a correlated
equilibrium of the complete information game Gk. In the presence of several such equilibria, no assumption
is made on the selection rule the players use to pick which equilibrium to play (though we assume they both
play according to the same equilibrium). Correlated equilibria are deﬁned as follows:

3

Deﬁnition 1. A probability distribution e is a correlated equilibrium of game G = (G1, G2) if and only if

G1(i(cid:48), j)eij ∀i, i(cid:48) ∈ A1

j=1

d(cid:88)
G1(i, j)eij ≥ d(cid:88)
G2(i, j)eij ≥ d(cid:88)
d(cid:88)

j=1

G2(i, j(cid:48))eij ∀j, j(cid:48) ∈ A2

i=1

i=1

One can see a correlated equilibrium as being a joint strategy proﬁle recommended by some coordination
device—think, for example, of a traﬃc light at an intersection; the traﬃc light coordinates the players by
making sure that they never cross the intersection at the same time. The deﬁnition implies that a player
does not gain anything (in expectation) by deviating to a diﬀerent strategy than that recommended to her,
given the conditional distribution this induces on the other player’s actions. In the traﬃc light example,
deviating from the recommended strategy could result in a collision, severely reducing the utilities of the
players. Note that the deﬁnition protects against unilateral deviations but does not consider the case in
which the two players form a coalition and both deviate from their recommended strategies. The notion of
correlated equilibrium extends the classical notion of Nash equilibrium by allowing players to act jointly; as
every Nash equilibrium of a game is a correlated equilibrium of the same game, our results also hold when
player behavior is restricted to Nash plays.
We model an observer as observing the entire correlated equilibrium distribution ek ∈ Rm1×m2 describing
the strategies followed by the players in each perturbed game Gk, where ek(i, j) denotes the joint probability
of player 1 playing action i ∈ A1 while player 2 plays action j ∈ A2. Note that as ek represents a probability
ek
ij = 1. The reader may interpret this assumption as

distribution, we require ek(i, j) ≥ 0 ∀(i, j) and (cid:80)

i,j

describing a situation in which each perturbed game is repeatedly played over time with the two players
repeatedly using the same strategies, allowing the observer to infer the probability distribution over actions
that is followed by the players.

We always assume that the observer does not have access to the payoﬀs of the underlying game G nor of
the perturbed games Gk for all k in [l]. We do assume that the observer has a prior on the order of magnitude
of said perturbations, encoded by a parameter δ, and make no assumption on the distribution of the . In the
paper, we consider three variants of the model of observations:

• In the partial payoﬀ information setting, the observer has access to equilibrium observations e1, ..., el,
and to the expected payoﬀ of equilibrium ek on perturbed games Gk, for all players p and all k ∈ [l];
we denote said payoﬀ vk
p. See Section 5 for a discussion of the “partial payoﬀ
information” setting.

p and note that vk

p = ek (cid:48)Gk

• In the no payoﬀ information setting, the observer only sees e1, ..., el. See Section 6 for a discussion of

the “no payoﬀ information” setting.

• In the payoﬀ shifter information setting, at each step k, a payoﬀ shifter Sk = (Sk

2 ) ∈ Rm1×m2 ×
Rm1×m2 is added to game G = (G1, G2), and the perturbed games Gk result from the further addition
of small perturbations to the G + Sk’s. The observer knows S1, ..., Sl and observes e1, ..., el of perturbed
games G1, ..., Gl. This is derived from a common model in the economics literature: it represents a
situation in which changes in the behavior of agents are observed as a function of changes in observable
economic parameters (taxes, etc.) See Section 4 for a discussion of the “payoﬀ shifter information”
setting.

1 , Sk

Our paper aims to characterize the games that explain observations under the partial payoﬀ, no payoﬀ,
and the payoﬀ shifter information settings when the perturbations are known to be “small” and the perturbed
games are thus “close” to the underlying game. The next two deﬁnitions formalize our notion of closeness:

Deﬁnition 2. A vector G is δ-close to vectors G1, ..., Gl with respect to metric d for δ > 0 if and only if

d(G|G1, ..., Gl) ≤ δ.

4

For the above deﬁnition to make sense in the context of this paper, we need a notion of metric whose
value on a set of payoﬀ vectors Gp, G1
p are close in terms of payoﬀs. With
a model where the Gk’s are obtained from G through small and possibly bounded perturbations in mind, we
consider the following two metrics:

p is small when Gp, G1

P , ..., Gl

p, ..., Gl

Deﬁnition 3. The sum-of-squares distance between vectors G and G1, ..., Gl is given by

l(cid:88)

d2(G1, ..., Gl|G) =

(G − Gk)(cid:48)(G − Gk).

The maximum distance between vectors G and G1, ..., Gl is deﬁned as

k=1

d∞(G1, ..., Gl|G) = max
k∈[l]

(cid:107)G − Gk(cid:107)∞,

where (cid:107).(cid:107)∞ denotes the usual inﬁnity norm.

Both distances are useful, in diﬀerent situations. The sum-of-squares distance is small when the average
perturbation to G is small, but allows for worst-case perturbations to be large. An example is when the Gk’s
are randomly sampled from a distribution with mean G, unbounded support, and small covariance matrix, in
which case some of the perturbations may deviate from the mean with low probability, while the average
squared perturbation remains small. If the distribution of perturbations is known to be i.i.d Gaussian, then
the sum-of-squares norm is a natural choice, as it replicates the log-likelihood of the estimations and follows
a known, Chi-square distribution. The maximum distance is small when it is known that all perturbations
are small or bounded; one example is when the perturbations are known to be uniform in a small interval
[−δ, δ]. While no distributional assumptions on the perturbations will be made anywhere in the paper, the
observer may have a sense of which of the two distance notions best ﬁts the game whose realized plays he is
observing, or he may use our framework to understand how well the observations ﬁt each of the two metrics.
It may be the case that, given a set of equilibrium observations with no additional assumption on the
distribution of perturbations nor on a the rule used to select among multiple equilibria, one cannot recover
the game that generated these observations, as highlighted in the following example:

Example 1. Take any set of observations e1, ..., el under the “no payoﬀ information” observation model, and
let ˆG be the all-constant game, i.e. ˆG1(i, j) = ˆG2(i, j) = c for some c ∈ R and for all (i, j) ∈ A1 × A2. Let
ˆG1 = ... = ˆGl = ˆG. Then for all k ∈ [l], ek is an equilibrium of ˆGk, and d2(G1, ..., Gl|G) = d∞(G1, ..., Gl|G) =
0. That is, ˆG is a trivial game, and it perfectly explains any arbitrary observations. Even when e1, ..., el are
generated by a non-trivial G, without any additional observations, an observer cannot determine whether G
or ˆG is the actual underlying game.

Clearly, while our optimization framework can recover a game that explains observed equilibrium strategies,
the recovered game is not necessarily unique. We thus adopt an observation-driven view that describes a
class of games that are consistent with the observed behavior and bounds on the perturbations; from there, it
is natural to ask what such a class of games looks like, and more speciﬁcally when the class of games that
explain the observations is small and can lead to approximate point identiﬁcation. We propose the following
deﬁnition to formalize whether approximate point identiﬁcation is possible:

Deﬁnition 4. We say a set of observations is (, δ)-non-identiﬁable under a ﬁxed observation model with re-
spect to player p and distance metric d if there exist at least two sets of games ( ˜G, ˜G1, ..., ˜Gl) and ( ˆG, ˆG1, ..., ˆGl)
such that

• For all k, ek is an equilibrium of both ˜Gk and ˆGk.

observations, we additionally require ˆGk (cid:48)

p ek = vk

p and ˜Gk (cid:48)

In the “partial payoﬀ information” model of
p ek = vk

p for all players p.

p, ..., ˜Gl

• In the “partial payoﬀ information” or “no payoﬀ information”models, we require that ˜Gp is δ-close to
p under metric d . In the “payoﬀ shifter information” model,
p, ..., ˜Gl
p under

p and ˆGp is δ-close to ˆG1

˜G1
p and ˆGp is δ-close to ˆG1
we require that ˜Gp is δ-close to ˜G1
metric d.

p, ..., ˆGl
p − S1

p − S1

p − Sl

p − Sl

p, ..., ˆGl

5

• (cid:107) ˜Gp − ˆGp(cid:107)∞ ≥ 
Informally, a set of observations is non-identiﬁable if there exist several games that are δ-good explanations
of the observations, but are -far from each other in terms of payoﬀ. It is then impossible to distinguish
which (if either) of the candidate games is the underlying one, as they are both good explanations of the
observations.

3 A convex optimization framework

In this section, we will see how techniques from convex optimization can be used to recover the best explanation
for a set of observations, determine the extent to which observations are consistent with certain assumptions
on the underlying game, and determine whether a set of observations tightly constrains the set of games that
could explain it well. The results in this section are not tied to a speciﬁc observation model: they apply to all
models considered in this paper, up to addition of linear constraints for the “partial payoﬀ information”and
“no payoﬀ information” settings (see Programs (4) and (5)), and linear shift of the variables in the objective
function for the “payoﬀ shifter information” setting (see Program (3)).

3.1 Optimization program for recovering a compatible underlying game

One of our primary objectives is to recover a game that is a good explanation—according to the chosen
distance metric—for a given set of observations from perturbed games, subject to the constraint that, for
all k, each observation ek is a correlated equilibrium of a perturbed game Gk. Note that the set of games
compatible with equilibrium observation ek is the set of games Gk that satisfy

d(cid:88)
d(cid:88)

j=1

ij ≥ d(cid:88)
ij ≥ d(cid:88)

j=1

Gk

1(i, j)ek

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1

Gk

2(i, j)ek

2(i, j(cid:48))ek
Gk

ij ∀j, j(cid:48) ∈ A2,

i=1

i=1

This set is a convex cone deﬁned by a polynomial (in m1 and m2) number of inequalities that each are linear
in Gk. It is also easy to see that the distance metrics we consider are convex in (G, G1, ..., Gl), thus our
problem can be seen as optimizing a convex function over a convex set3:
2|G2)
d(G1
ek is an equilibrium of Gk ∀k ∈ [l]

1|G1) + d(G1

min
Gk,G
s.t.

1, ..., Gl

2, ..., Gl

This optimization program simply ﬁnds the game ˆG that minimizes the distance d between ˆG1, ˆG2 and the
cones of candidate perturbed games deﬁned by equilibrium observations e1, ..., el. If the objective value of
the above optimization program is small, then we have found a good explanation in the sense that we have
found perturbed games ˆG1, ..., ˆGl that are compatible with the equilibrium observations, along with a game
ˆG such that the distance between ˆG and the ˆGk’s is small.

We dedicate the rest of this subsection to writing the above convex program in an eﬃciently solvable

form for both metrics.

When we choose the metric to be the sum-of-squares distance, we obtain the following optimization

problem:

3This can be extended to multi-player games with succinct representations:

if there are n players with m actions each,
then n · m equilibrium constraints are needed. Thus, a similar optimization problem with a tractable number of variables and
constraints can be formulated for multi-player games so long as its utility function can be represented using a tractable number
of variables.

6

min
Gk,G

s.t.

(Gk

2 − G2)

2 − G2)(cid:48)(Gk

l(cid:88)
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]

k=1

1(i(cid:48), j)ek
Gk
2(i, j(cid:48))ek
Gk

(Gk

1 − G1)(cid:48)(Gk

1 − G1) +

ij ≥ d(cid:80)
ij ≥ d(cid:80)

j=1

i=1

Gk

1(i, j)ek

Gk

2(i, j)ek

l(cid:88)
d(cid:80)
d(cid:80)

k=1

j=1

i=1

k=1

l(cid:88)
d(cid:80)
l(cid:88)
d(cid:80)

k=1

j=1

i=1

max
k∈[l]

d(cid:80)
d(cid:80)

j=1

i=1

max
k∈[l]

d(cid:80)

j=1

(1)

(2)

The objective is separable and no constraint depends on both the G1’s and the G2’s, so the above problem

can be decoupled and written as two problems of the same form:

and

min
Gk,G

s.t.

min
Gk,G

s.t.

(Gk

1 − G1)(cid:48)(Gk

1 − G1)

Gk

1(i, j)ek

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

(Gk

2 − G2)(cid:48)(Gk

2 − G2)

Gk

2(i, j)ek

2(i, j(cid:48))ek
Gk

ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]

ij ≥ d(cid:80)

j=1

ij ≥ d(cid:80)

i=1

Both problems are quadratic optimization problems with a tractable number of constraints, therefore

eﬃcient algorithms to solve them are known.

When we choose our metric to be the maximum norm, the convex optimization program becomes

min
Gk,G

s.t.

min
Gk
1 ,G1

s.t.

(cid:107)G2 − Gk

2(cid:107)∞

(cid:107)G1 − Gk

Gk

1(i, j)ek

Gk

2(i, j)ek

ij ≥ d(cid:80)
ij ≥ d(cid:80)

1(cid:107)∞ + max
k∈[l]
1(i(cid:48), j)ek
Gk
2(i, j(cid:48))ek
Gk

j=1

i=1

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]

(cid:107)G1 − Gk

Gk

1(i, j)ek

1(cid:107)∞

ij ≥ d(cid:80)

j=1

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

This program is again separable and we need only solve two programs of the form

for each player. Note that this program can be written as a LP and therefore solved eﬃciently:

min
Gk
1 ,G1

s.t.

δ

ij ≥ d(cid:80)

d(cid:80)
Gk
1(i, j) − G1(i, j) ≤ δ ∀(i, j) ∈ A1 × A2,∀k ∈ [l]
i=1
Gk
1(i, j) ≤ δ ∀(i, j) ∈ A1 × A2,∀k ∈ [l]
G1(i, j) − Gk

ij ∀j, j(cid:48) ∈ [m],∀k ∈ [l]

1(i, j(cid:48))ek
Gk

1(i, j)ek

i=1

3.2 Can observations be explained by linear properties?

This convex optimization-based approach can be used to determine whether there exists a game that is
compatible with the observations and also has certain properties, as long as these properties can be written
as a tractable number of linear equalities and inequalities. This section contains a non-exhaustive list of
interesting properties that ﬁt this framework:

7

3.2.1 Zero-sum games
Deﬁnition 5. A 2-player game G = (G1, G2) is a zero-sum game if and only if G1 = −G2.

In other words, a zero-sum game is a game in which for each pure strategy (i, j), the sum of the payoﬀ of
player 1 and the payoﬀ of player 2 for (i, j) is 0. One can restrict the set of games we look for to be zero-sum
games, at the cost of separability of Program (1), by solving:
2|G2)
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]

2, ..., Gl
1(i(cid:48), j)ek
Gk
2(i, j(cid:48))ek
Gk

ij ≥ d(cid:80)
ij ≥ d(cid:80)

1|G1) + d(G1

d(cid:80)
d(cid:80)

1(i, j)ek

2(i, j)ek

1, ..., Gl

min
Gk,G

d(G1

Gk

Gk

s.t.

j=1

j=1

i=1

G1(i, j) = −G2(i, j) ∀(i, j) ∈ A1 × A2

i=1

Note that depending on the choice of distance function, this is either a linear or a quadratic program with a
tractable number of linear constraints, and can therefore be solved eﬃciently.

3.2.2 Exact potential games

Deﬁnition 6. A game G is an exact potential game if and only if there exists a function Φ such that for all
players p, all pure strategy proﬁles (ap, a−p) and all deviations a(cid:48)

p ∈ Ap for player p,

Φ(ai, a−i) − Φ(a(cid:48)

i, a−i) = Gp(ap, a−p) − Gp(a(cid:48)

p, a−p).

Φ is called an exact potential function for game G.

In particular, for 2-player games, the deﬁnition translates to the existence of a function Φ such that

Φ(i, j) − Φ(i(cid:48), j) = G1(i, j) − G1(i(cid:48), j) ∀i, i(cid:48) ∈ A1,∀j ∈ A2
Φ(i, j) − Φ(i, j(cid:48)) = G2(i, j) − G2(i, j(cid:48)) ∀i ∈ A1,∀j, j(cid:48) ∈ A2

In order to restrict the set of games we are searching over to the set of potential games, one can introduce

m1m2 variables Φ(i, j) in Program (1) and solve

min

Gk,G,Φ

s.t.

j=1

Gk

d(G1

1, ..., Gl

1(i, j)ek

d(cid:80)
d(cid:80)

1|G1) + d(G1

ij ≥ d(cid:80)
ij ≥ d(cid:80)

2|G2)
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]
Φ(i, j) − Φ(i(cid:48), j) = G1(i, j) − G1(i(cid:48), j) ∀i, i(cid:48) ∈ A1,∀j ∈ A2
Φ(i, j) − Φ(i, j(cid:48)) = G2(i, j) − G2(i, j(cid:48)) ∀i ∈ A1,∀j, j(cid:48) ∈ A2

2, ..., Gl
1(i(cid:48), j)ek
Gk
2(i, j(cid:48))ek
Gk

2(i, j)ek

Gk

j=1

i=1

i=1

Once again, this is—depending on the choice of objective function—either a linear or a quadratic program

with a tractable number of variables and constraints, thus it can be solved eﬃciently.

3.2.3 Games generated through linear parameter ﬁtting

It is common in the economics literature to recover a game with the help of a parametrized function whose
parameters are calibrated using the observations. In many applications, linear functions in the actions of
the players (and in the state variables, when they exist) are considered—entry games come to mind . Our
framework allows one to determine whether there exist parameters for such a linear function that provide
good explanation for the observations. When such parameters exist, one can use it to ﬁnd a set of parameters
that describe a game which is consistent with the observations.

8

ALGORITHM 1: Measuring (ε, δ) non-identiﬁability for player 1
Input: Equilibrium observations e1, ..., el, parameter , metric d
Output: δ such that e1, ..., el is (ε, δ)-non-identiﬁable
δ = +∞;
for (i, j) ∈ A1 × A2 do

P(i, j) =

min

Gk

1 , ˆGk

1 ,G, ˆG

s.t.

if P(i, j) ≤ δ then

δ = P(i, j)

end

end

d(cid:80)
d(cid:80)

d( ˜G1

1, ..., ˜Gl

1| ˜G) + d( ˆG1

1, ..., ˆGl

ij ≥ d(cid:80)
ij ≥ d(cid:80)

j=1

˜Gk

1 (i, j)ek

1 (i(cid:48), j)ek
˜Gk
1 (i(cid:48), j)ek
ˆGk
˜G1(i, j) − ˆG1(i, j) ≥ 

1 (i, j)ek

ˆGk

j=1

j=1

j=1

1| ˆG1)
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

Take a linear function fα that takes pure strategies (i, j) as input and parameters given by vector α, we

can eﬃciently solve for player 1 (a similar program holds for player 2) as

d(G1

1, ..., Gl

min
1 ,G1,α

Gk

s.t.

d(cid:80)

Gk

1(i, j)ek

1|G1)

ij ≥ d(cid:80)

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

j=1

G1(i, j) = fα(i, j) ∀i ∈ A1,∀j ∈ A2

j=1

for d = d2 or d = d∞. Note that unlike in previous work in economics, such a framework allows us to
account for multiple equilibria at the same time, and does not rely on assumptions on the distribution of
perturbations.

3.3 Deciding whether a set of observations is identiﬁable

In this section, we provide an algorithm for characterizing the level of identiﬁability of a set of observations for
a player, Algorithm 1. Algorithm 1 is clearly computationally eﬃcient, as it solves m1m2 linear or quadratic—
depending on the chosen metric—optimization programs with a tractable number of constraints, and has the
following properties:

Lemma 1. Let δ be the output of Algorithm 1 run with inputs ε, e1, ..., el. Then e1, ..., el is (ε, δ)-non-
identiﬁable. Furthermore, suppose that e1, ..., el is (ε, γ)-non-identiﬁable, then γ ≥ δ
2 .

It immediately follows that Algorithm 1 returns a 2-approximation of the minimum value of δ such that

the observations are (, δ)-non-identiﬁable.

Proof. See Appendix A.

Note that while this optimization program is written with respect to player 1, a similar optimization
program can be solved to characterize the level of non-identiﬁability of the observations for player 2. This
algorithm can also be applied when additional constraints are included, as long as they are linear in the
variables of the optimization program, or when the objective value is modiﬁed, as long as it remains linear or
quadratic in the variables; we consider such modiﬁcations in Sections 3.2, 4, 5 and 6.

Remark 1. It is important to note that (, δ)-non-identiﬁability is a property of the observations, not of the
underlying game nor of our framework. On the one hand, if a set of observations is non-identiﬁable, then

9

by deﬁnition there is no way of distinguishing between diﬀerent explanations for the same observations and
accurate point recovery is impossible for any algorithm that does not make additional assumptions on how
the observations are generated; the best one can do in such a situation is to give a characterization of the
games compatible with the observations. On the other hand, if a set of observations is identiﬁable, this paper
provides an algorithm to obtain an approximation of the underlying game that generated the observations.

4 Consistent games with payoﬀ shifter information

In this section, we brieﬂy show how to adapt our framework to the “payoﬀ shifter information” observation
model. Here, our primary objective is to recover a game that is a good explanation—according to the chosen
distance metric—for a given set of observations from perturbed games, subject to the constraint that, for
all k, each observation ek is a correlated equilibrium of a perturbed game Gk. As before, the set of games
compatible with equilibrium observation ek is the set of games Gk that satisfy

d(cid:88)
d(cid:88)

j=1

ij ≥ d(cid:88)
ij ≥ d(cid:88)

j=1

Gk

1(i, j)ek

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1

Gk

2(i, j)ek

i=1

i=1

2(i, j(cid:48))ek
Gk

ij ∀j, j(cid:48) ∈ A2,

However, in the “payoﬀ shifter information” model, we aim to minimize the distance between the game G
and the “unshifted” G1, ..., Gl, as the perturbed games are obtained from G by adding known payoﬀ shifters
S1, ..., Sl and then also small, unknown perturbations. To do so, we simply consider objective function
d(G1

1 − S1

1 , ..., Gl

1 − Sl

1 , ..., Gl

1|G1) + d(G1
d(cid:80)
d(G1
min
Gk,G
d(cid:80)

Gk

s.t.

j=1

2 − S2
1 − S1

1 , ..., Gl

1(i, j)ek

2 − Sl
1 − Sl

2|G2) and solve
1|G1) + d(G1
2 − S2
1(i(cid:48), j)ek
Gk
2(i, j(cid:48))ek
Gk

ij ≥ d(cid:80)
ij ≥ d(cid:80)

j=1

i=1

Gk

2(i, j)ek

i=1

1 , ..., Gl

2 − Sl

2|G2)

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i ∈ A1,∀j, j(cid:48) ∈ A2,∀k ∈ [l]

(3)

5 Consistent games with partial payoﬀ information

This section considers the partial payoﬀ information variant of the observation model described in Section 2.
Recall that in this setting, for an equilibrium ek observed from perturbed game Gk , the observer also
learns the expected payoﬀ vk
p of player p in said equilibrium strategy on game Gk, on top of observing ek.
Similar to the previous sections, we are interested in computing a game ˆG that is close to some perturbed
games ˆG1, ..., ˆGl that (respectively) have equilibria e1, ..., el with payoﬀs v1, ..., vl; to do so, one can solve the
following convex optimization problem for player 1 (a similar optimization problem can be solved for player
2):

P () = min
1 ,G1

Gk

s.t.

d(cid:80)

d(G1

1, ..., Gk

j=1

Gk
ek (cid:48)Gk

1(i, j)ek
1 = vk

1|G1)

ij ≥ d(cid:80)

j=1

1 ∀k ∈ [l]

1(i(cid:48), j)ek
Gk

ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

(4)

The ﬁrst constraint means that ek must be an equilibrium of the recovered ˆGk, while the second constraint
imposes that the expected payoﬀ of strategy ek on game ˆGk is vk. Note that unlike in Example 1, if G is
far from a trivial game, information on the diﬀerence in the payoﬀs of diﬀerent strategies is given by the
vk’s, and the game we recover will not have a trivial structure. All results from Section 3 can be extended to

10

the partial payoﬀ information setting by adding the linear expected payoﬀ constraint to each optimization
program.

5.1 Quantifying identiﬁability of many linearly independent equilibrium obser-

vations

We take l ≥ m1m2 and make the following assumption for the remainder of this subsection, unless otherwise
speciﬁed:
Assumption 1. There exists a subset E ⊂ {e1, ..., el} of size m1m2 such that the vectors in E are linearly
independent.

We abuse notation and denote by E the m1m2× m1m2 matrix in which row i is given by the ith element of
set E, for all i ∈ [m1m2]. For every p ∈ N ∪ {+∞}, let (cid:107).(cid:107)p be the p-norm. We can deﬁne the corresponding
induced matrix norm (cid:107).(cid:107)p that satisﬁes (cid:107)M(cid:107)p = sup
x(cid:54)=0

for any matrix M ∈ Rm1m2×m1m2.

(cid:107)M x(cid:107)p
(cid:107)x(cid:107)p

The following statement highlights that if one has m1m2 linearly independent observations (among the
l equilibrium observations) such that the induced matrix of observations E is well-conditioned, and the
perturbed games are obtained from the underlying game through small perturbations, any optimal solution
of Program (4) necessarily recovers a game whose payoﬀs are close to the payoﬀs of the underlying game.
The statements are given for both metrics introduced in Section 2.

Lemma 2. Let G be the underlying game, and G1, ..., Gl be the games generating observations e1, .., el, where
l = m1m2. Suppose that for player p, d2(G1
p) be an optimal solution
of Program (4) for player p with distance function d2. Then

p|Gp) ≤ δ. Let ( ˆGp, ˆG1

p, ..., ˆGl

p, ..., Gl

(cid:107)Gp − ˆGp(cid:107)2 ≤(cid:112)2(cid:107)E−1(cid:107)2 · δ.

Proof. For simplicity of notation, we drop the p indices. We ﬁrst remark that (G, G1, ..., Gl) is feasible for
Program (4); as ( ˆG, ˆG1, ..., ˆGl) is optimal, it is necessarily the case that

l(cid:88)

k=1

2 ≤ l(cid:88)

k=1

(cid:107) ˆG − ˆGk(cid:107)2

(cid:107)G − Gk(cid:107)2

2 ≤ δ.

Let us write ∆G = G − ˆG. We know that for all k, ek (cid:48)Gk = ek (cid:48) ˆGk = vk, and thus ek (cid:48)(Gk − ˆGk) = 0.

We can write

E∆G = (e(cid:48)
= (e(cid:48)
= (e(cid:48)

Let xk = G − Gk + ˆGk − ˆG. We then have (cid:107)E∆G(cid:107)2
semi-deﬁnite, stochastic matrix, all its eigenvalues are between 0 and 1 and

2 =

l(G − ˆG))(cid:48)

1(G − ˆG) ... e(cid:48)
1(G − G1 + G1 − ˆG1 + ˆG1 − ˆG) ... e(cid:48)
l(G − Gl + Gl − ˆGl + ˆGl − ˆG))(cid:48)
1(G − G1 + ˆG1 − ˆG) ... e(cid:48)
l(cid:80)
l(cid:88)

l(G − Gl + ˆGl − ˆG))(cid:48).
x(cid:48)
keke(cid:48)

kxk, as eke(cid:48)

k=1

x(cid:48)
kxk =

(cid:107)xk(cid:107)2

2 ≤ 2δ.

2 ≤ l(cid:88)
It immediately follows that (cid:107)∆G(cid:107)2 ≤(cid:112)2(cid:107)E−1(cid:107)2 · δ.

(cid:107)E∆G(cid:107)2

k=1

k=1

k is a symmetric, positive

Lemma 3. Let G be the underlying game, and G1, ..., Gl be the games generating observations e1, .., el, where
l = m1m2. Suppose that for player p, d∞(G1
p) be an optimal solution
of Program (4) for player p with distance function d∞. Then

p|Gp) ≤ δ. Let ( ˆGp, ˆG1

p, ..., ˆGl

p, ..., Gl

(cid:107)Gp − ˆGp(cid:107)∞ ≤ 2(cid:107)E−1(cid:107)∞ · δ.

11

Proof. See Appendix B.

When E is far from being singular, as long as the perturbations are small, we can accurately recover the
payoﬀ matrix of each player. An extreme example arises when we take E to be the identity matrix, in which
case we observe every single pure strategy of the game and an approximation of the payoﬀ of each of these
strategies, allowing us to approximately reconstruct the game. It is also the case that there are examples
in which (cid:107)E−1(cid:107)∞ is large and there exist two games that are far from one another, yet both explain the
observations, making our bound essentially tight:
Example 2. Consider the square matrix E ∈ R4×4 with probability 0.25 +  on the diagonal and 0.75+
oﬀ
the diagonal, i.e., we get four equilibrium observations with a diﬀerent action proﬁle that has probability
slightly higher than 0.25 for each equilibrium; the ﬁrst equilibrium has a higher probability on action proﬁle
(1,1), the second on (1,2), the third on (2,1) and the last one on (2,2). Suppose the vector of observed payoﬀs
is v = (δ,−δ, δ,−δ)(cid:48), where v(i) is the payoﬀ for the ith equilibrium. Note that there exists a constant C such
that for all  > 0 small enough, (cid:107)E−1(cid:107)+∞ ≤ C
 .

In the rest of the example, we ﬁx the payoﬀ matrix of player 2 for all considered games to be all zero so
that it is consistent with every equilibrium observation, and describe a game through the payoﬀ matrix of
player 1. Let G be the all-zero game, G1 = G3 be the game with payoﬀ
0.5+2/3 on actions (1,1) and (1,2)
and 0 everywhere else, and G2 = G4 be the game with payoﬀ − δ
0.5+2/3 on actions (2,1) and (2,2) and 0
everywhere else. It is clear that the Gi’s are consistent with the payoﬀ observations as the payoﬀs are constant
across rows on the same column, making no deviation proﬁtable, and that the payoﬀ of each equilibrium is
indeed δ. We have

3

δ

d∞(G1, G2, G3, G4|G) =

δ

≤ 2δ

0.5 + 2/3

and

d∞(G1, G2, G3, G4|G) = 2δ.

lim
→0

Now, take ˆG to be the game that has payoﬀ δ/ for action proﬁles (1,1) and (1,2), and −δ/ for (2,1) and
3−2
3−4 in the second column;
3−4 in the ﬁrst column and − δ
3−2
 in the second column.

(2,2). Take ˆG1 = ˆG3 to be the game with payoﬀs δ
similarly, take ˆG2 = ˆG4 to be the game with payoﬀs δ

It is clear that the observations are equilibria of the ˆGi’s and yield payoﬀ δ. Now, note that for  < 3/4,

 in the ﬁrst column, and − δ



d∞(G1, G2, G3, G4|G) =

δ


(cid:12)(cid:12)(cid:12)(cid:12)1 − 3 − 2

3 − 4

(cid:12)(cid:12)(cid:12)(cid:12) =

2

3 − 4

δ

Therefore, both G and ˆG are good explanations of the equilibrium observations, in the sense that for  ≤ 1/4,
G is δ-close to G1, ..., Gl and ˆG is δ-close to ˆG1, ..., ˆGl that have e1, ..., el as equilibria, respectively. However,

(cid:107)G − ˆG(cid:107)∞ =

−

δ


δ

0.5 + 2/3

≥ δ

which immediately implies

(cid:107)G − ˆG(cid:107)∞ = Ω→0

(cid:18) δ

(cid:19)



= Ω→0

,

− 2

(cid:19)

(cid:18) 1
(cid:0)(cid:107)E−1(cid:107)∞δ(cid:1) .



Remark 2. In the case of sparse games, in which some action proﬁles are never proﬁtable to the players, and
are therefore never played, one can reduce the number of linearly independent, well-conditioned observations
needed for accurate recovery. Under the assumption that the action proﬁles that are never played with
positive probability have payoﬀs strictly worse than the lowest payoﬀ of any action proﬁle played with non-zero
probability, one can solve the optimization problem on the restricted set of action proﬁles that are observed

12

in at least one equilibrium, and set the payoﬀs of the remaining action proﬁles to be lower than the lowest
payoﬀ of the recovered subgame, without aﬀecting the equilibrium structure of the game. While the recovered
game may not be the unique good explanation of the observations when looking at the full payoﬀ matrix, it is
unique with respect to the subgame of non-trivial actions when one has access to suﬃciently many linearly
independent, well-conditioned equilibrium observations.

6 Finding consistent games without additional information

This section focuses on the no payoﬀ information variant of the observation model given in Section 2. Recall
that in this setting, the observer only observes what equilibrium ek is played for each perturbed game Gk.

6.1 Finding non-degenerate games

In this section, we focus on the optimization problem that recovers the payoﬀs of player 1 (by symmetry, all
results can be applied to the optimization program that recovers the payoﬀs player 2), and drop the player
indices for notational simplicity. Since no payoﬀ information is given, throughout this section, we assume
w.l.o.g that the games are normalized to have all payoﬀs between 0 and 1. As mentioned in Example 1, the
all-constant game G = G1 = ... = Gl gives an optimal solution to our optimization problem, as such a game
is compatible with all equilibrium observations and has an objective value d(G1, ..., Gl|G) = 0. It is therefore
the case that solving our optimization problem might output a degenerate game, so in this section, we provide
a framework that allows us to control the degree of degeneracy of the game we recover and to avoid trivial,
all-constant games. To do so, we require some of the equilibria of the games to be “strict,” in the sense that

d(cid:88)

G(i, j)xij ≥ d(cid:88)

G(i(cid:48), j)xij + εii(cid:48) ∀i, i(cid:48)

j=1

j=1

with εii(cid:48) ≥ 0 and with the condition that at least one of the εii(cid:48) is non-zero. All-constant games do not have
strict equilibria, thus this avoids such games. Note that such a technique only aﬀect the payoﬀs of pure
strategies that are played with positive probability, and does not accord any importance to strategies that
are never played. Let us now consider the new problem:

min
Gk,G
s.t.

d(G1, ..., Gl|G)
ek is a “strict” equilibrium of Gk, ∀k
0 ≤ G(i, j) ≤ 1, ∀(i, j)

which can be rewritten as

min
Gk,G

s.t.

d(cid:80)

d(G1, ..., Gl|G)

d(cid:80)

Gk(i, j)ek

ij =

j=1

0 ≤ G(i, j) ≤ 1, ∀(i, j)

j=1

Gk(i(cid:48), j)ek

ij + εk

ii(cid:48) ∀(i, i(cid:48)),∀k

We introduce a positive parameter ε that controls the level of non-degeneracy of the game and let the
ii(cid:48)’s in a way that minimizes the objective. The

optimization program decide how to split ε among the εk

13

This allows us to rewrite the optimization program under the following form:

˜ek
ii(cid:48)(h, j) =

P (ε) = min
Gk,G

if h = i
if h = i(cid:48)
if h (cid:54)= i, i(cid:48)

ek(i, j)
0

−ek(i, j)
s.t. (cid:80)

d(G1, ..., Gl|G)
ii(cid:48) Gk = −ε
˜ek (cid:48)

k,i,i(cid:48)
ii(cid:48) Gk ≤ 0 ∀(i, i(cid:48)),∀k
˜ek (cid:48)
0 ≤ G ≤ 1

optimization program can now be written as

P (ε) = min
Gk,G

s.t.

d(cid:80)

j=1

j=1

ij =

Gk(i, j)ek

d(G1, ..., Gl|G)

d(cid:80)
(cid:80)
l(cid:80)
εk
ii(cid:48) = ε
0 ≤ G ≤ 1
ii(cid:48) ≥ 0 ∀(i, i(cid:48)),∀k
εk

k=1

i,i(cid:48)

Gk(i(cid:48), j)ek

ij + εk

ii(cid:48) ∀(i, i(cid:48)),∀k

For all i, i(cid:48) ∈ A1 such that i (cid:54)= i(cid:48) and k ∈ [l], we introduce vectors ˜ek

ii(cid:48) whose entries are deﬁned as follows:

(5)

This optimization problem is, depending on the chosen metric, either a linear or quadratic optimization

program with a tractable number of constraints, and can therefore be eﬃciently solved.

6.2 A duality framework

In this section, we give a duality framework under distance d2 that oﬀers insight into the solutions to the
optimization program.Throughout the section, we let D(ε) be the dual of Program (5).

6.2.1 Suﬃcient conditions for strong duality

Claim 1. If there exist G1, ..., Gl such that

ii(cid:48) Gk < 0 ∀(i, i(cid:48)) ∈ cA1,∀k ∈ [l] s.t. ˜ek
˜ek (cid:48)

ii(cid:48) (cid:54)= 0,

then strong duality holds and P (ε) = D(ε).

Proof. Slater’s condition holds iﬀ there exists a solution G, G1, ..., Gl such that

(cid:88)
k,i,i(cid:48)
ii(cid:48) Gk < 0 ∀(i, i(cid:48)),∀k s.t. ˜ek
˜ek (cid:48)

ii(cid:48) Gk = −ε
˜ek (cid:48)

ii(cid:48) (cid:54)= 0.

It is enough to ﬁnd G1, ..., Gl such that
ii(cid:48) Gk < 0 ∀(i, i(cid:48)),∀k s.t. ˜ek
˜ek (cid:48)

ii(cid:48) (cid:54)= 0

as we can then renormalize the Gk’s such that

εk
ii(cid:48) = ε.

l(cid:80)

(cid:80)

k=1

i,i(cid:48)

14

Note that the previous suﬃcient condition is not necessarily tractable to check. We give a stronger

suﬃcient condition such that for any ﬁxed k, ˜ek (cid:48)
Lemma 4. Let k ∈ [l]. Let ek(i, :) = (ek(i, 1), ..., (ek(i, m2)) ∀i ∈ A1. If the non-null ek(1, :), ..., ek(m1, :) are
linearly independent, then the non-null ˜ek
ii(cid:48)’s are linearly independent. In particular, there exists Gk such that

ii(cid:48) Gk < 0 ∀(i, i(cid:48)) has a solution:

ii(cid:48) Gk < 0, ∀i, i(cid:48) ∈ A1.
˜ek (cid:48)
If this holds for all k ∈ [l], then P (ε) = D(ε).

Proof. Let α(h, h(cid:48))’s be such that (cid:80)

α(h, h(cid:48))˜ek

hh(cid:48) = 0, and so (cid:80)
(cid:88)

α(i, h(cid:48))˜ek

i,h(cid:48)(i, j) +

h,h(cid:48)

h(cid:48)(cid:54)=i

h,h(cid:48)

(cid:88)
h,h(cid:48)(i,j) (cid:54)= 0 only if h = i or h(cid:48) = i, but not both at the same time. Therefore,

(cid:88)

α(h, h(cid:48))˜ek

hh(cid:48)(i, j) =

α(h, i)˜ek

h,i(cid:48)(i, j).

h(cid:54)=i

h,h(cid:48)

for a ﬁxed (i, j), ˜ek

α(h, h(cid:48))˜ek

hh(cid:48)(i, j) = 0 ∀(i, j). Recall that

As ˜ek

(cid:88)
i,h(cid:48)(i, j) = −ek(i, j) and ˜ek

−ek(i, j)

h(cid:48)(cid:54)=i

h,i(i, j) = ek(h, j), we have for all (i, j) that

α(i, h(cid:48)) +

α(h, i)ek(h, j) =

α(h, h(cid:48))˜ek

hh(cid:48)(i, j) = 0.

Since this holds for all values of j, it immediately follows that for all i,

−ek(i, :)

α(i, h(cid:48)) +

α(h, i)ek(h, :) = 0.

(cid:88)
(cid:88)

h(cid:54)=i

h(cid:48)(cid:54)=i

(cid:88)

(cid:88)

h(cid:54)=i

(cid:88)

h,h(cid:48)

(cid:88)

(cid:88)

h(cid:54)=i(cid:48)

−ek(i(cid:48), :)

α(i(cid:48), h(cid:48)) + α(i, i(cid:48))ek(i, :) +

α(h, i(cid:48))ek(h, :)

h(cid:48)(cid:54)=i(cid:48)
= −ek(i(cid:48), :)

α(i(cid:48), h(cid:48)) +

h(cid:54)=i,i(cid:48)
α(h, i(cid:48))ek(h, :)

(cid:88)

h(cid:48)(cid:54)=i(cid:48)

Take any i, i(cid:48) such that ek

ii(cid:48) (cid:54)= 0. Then ek(i, :) (cid:54)= 0 and ek(i(cid:48), :) (cid:54)= 0. By the previous equation, we have

= 0

and by the linear independence assumption, we necessarily have α(i, i(cid:48)) = 0. Therefore, the ˜ek
linearly independent, completing the proof.

ii(cid:48) (cid:54)= 0’s are

Note that in the worst case, we want m1 ≤ m2, as there can be up to m1 non-null ek(i, :) of size m2, and
by symmetry, we want m2 ≤ m1 for the program that recovers the payoﬀs of player 2. From now on, we
require m1 = m2, which can be obtained by adding dummy actions to Ap of player p with the least available
actions. When the condition does not hold in such a setting, it can be obtained through small perturbations
of the equilibrium observations.

6.2.2 Dual program

The dual of program (5) is given by:

Theorem 1. The dual of optimization problem 5 is given by:

D(ε) = max

µk
ii(cid:48) ,λ0,λ1

s.t.

ii(cid:48) ˜ek
µk

ii(cid:48)) − 1(cid:48)λ1 − µε

(6)

ii(cid:48))(cid:48)((cid:80)

i,i(cid:48)
ii(cid:48) = 0

ii(cid:48) ˜ek
µk

µk
ii(cid:48) ˜ek

k,i,i(cid:48)

k=1((cid:80)
(cid:80)l
λ1 − λ0 + (cid:80)

− 1

i,i(cid:48)

4

ii(cid:48) ≥ 0
µ + µk
λ0, λ1 ≥ 0

15

The KKT conditions imply that if (G1∗, ..., Gl∗, G∗) is a primal optimal solution and (λ∗
dual optimal solution, then

0, λ∗

1, µ∗, µk ∗

ii(cid:48) ) is a

l +(cid:80)

i,i(cid:48)

µk ∗
ii(cid:48) ˜ek

ii(cid:48))

∀k, Gk∗ = A − 1
G∗ = A − 1
2l (λ∗

1−λ∗
2 ( λ∗
1 − λ∗
0)

0

(7)

for some matrix A ∈ Rl×l

Proof. See Appendix C.

This duality framework will allow us to obtain bounds on the trade-oﬀ between degeneracy and accuracy

in the next subsection.

6.3 Properties of the optimization program

6.3.1 Equilibria of the recovered game
Lemma 5. Let ˆG, ˆG1, .., ˆGl be a solution of Program (5). Then for all k, ek is an 2k-approximate equilibrium
of ˆG, where

l(cid:80)
k = ( ˆG− ˆGk)(cid:48)( ˆG− ˆGk). It immediately follows that (cid:107) ˆG− ˆGk(cid:107)∞ ≤ εk. Since ek is an equilibrium

2
k = P (ε).

Proof. Take 2
of ˆGk, it must be a 2k-approximate equilibrium of ˆG.

k=1

Therefore, as long as P (ε) is small, the k’s are small, the observed equilibria are equilibria of the recovered
game G up to small perturbations in average, and G has all of the observed equilibria of the underlying
game and its close-by games. However, the statement does not make sense unless it is possible to obtain a
small value of P (ε) for a non-trivial degree of degeneracy. Otherwise, it is only natural that G has all of the
observed equilibria of the underlying game, as it also has all of the possible equilibria, being a trivial game.
Understanding the trade-oﬀ between degeneracy and accuracy lets us understand whether it is possible to
obtain a non-trivial game that has most of the observations as approximate equilibria.

6.3.2 Trade-oﬀ between degeneracy and objective value
Deﬁnition 7. We deﬁne the degeneracy threshold ε∗ of a set of observations as

ε∗ = sup{ε s.t. P (ε) = 0}

.

Claim 2. The degeneracy threshold is given by

ε∗ = − min
G,εk
ii(cid:48)

s.t.

˜ek (cid:48)
ii(cid:48) G

(cid:88)
k,i,i(cid:48)
ii(cid:48) G ≤ 0 ∀(i, i(cid:48)),∀k
˜ek (cid:48)
0 ≤ G ≤ 1

The claim gives a tractable linear program to solve for the degeneracy threshold.

(8)

16

Proof. Remark that ε∗ solves

ε∗ =

max
Gk,G,εk
ii(cid:48)
s.t.

From the fact that

l(cid:80)

k=1

ε
˜ek (cid:48)
ii(cid:48) Gk + εk

ii(cid:48) = 0 ∀(i, i(cid:48)),∀k
(Gk − G)(cid:48)(Gk − G) = 0
εk
ii(cid:48) = ε

l(cid:80)
(cid:80)
k,i,i(cid:48)
ii(cid:48) ≥ 0 ∀(i, i(cid:48)),∀k
εk
0 ≤ G ≤ 1

k=1

ii(cid:48) = 0 ∀(i, i(cid:48)),∀k

k,i,i(cid:48)
˜ek (cid:48)
ii(cid:48) G + εk
ii(cid:48) ≥ 0 ∀(i, i(cid:48)),∀k
εk
0 ≤ G ≤ 1

(Gk − G)(cid:48)(Gk − G) = 0 implies G1 = ... = Gl = G, we have

(cid:88)

εk
ii(cid:48)

ε∗ = max
G,εk
ii(cid:48)

s.t.

The result follows immediately.
Claim 3. ε∗ is ﬁnite, ∀ε ≤ ε∗, P (ε) = 0, and ∀ε > ε∗, P (ε) > 0.
Proof. The proof follows immediately from claim 8. P (ε∗) = 0 comes from the fact that the feasible set of
Program (8) is bounded: indeed, for any point in its feasible set, 0 ≤ G ≤ 1 and εk
ii(cid:48) G, forcing the
ii(cid:48) to also be bounded. Thus, ε∗ is a solution of a linear program on a bounded polytope and is therefore
εk
ﬁnite, and attained at an extreme point of this polytope.

ii(cid:48) = −˜ek (cid:48)

Note that if we solve optimization Program (8) and ﬁnd that ε∗ is large, then it is possible to ﬁnd a
large value of ε such that P (ε) = 0, and we can therefore recover a non-degenerate game that has all of the
observed equilibria, i.e., we recover a game that has equilibrium properties similar in some sense to those of
the true, underlying game. For smaller values of ε∗, we refer to the following statement:
Theorem 2. For every ε0 > ε∗, and for all ε ≥ ε0, we have f (ε) ≤ P (ε) ≤ g(ε) where f and g are given by

f (ε) = P (ε0)

(cid:16)

ε2
ε2
0

((cid:112)P (ε0) +

g(ε) =

Proof. See Appendix D.

√

lm
2

−

)

ε
ε0

(cid:17)2

√

lm
2

(9)

(10)

7 Simulations for entry games

In this section, we run simulations for a concrete setting, to illustrate the power of our approach. We consider
an entry game, in which each of two players have to decide whether to enter a market. Each player p has two
actions: Ap = {0, 1}; ap = 0 if player p does not enter the market, ap = 1 if he does. The utility of a player is
given by Gp(ap, a−p) = ap((1 − a−p)γp + a−pθp) for some parameters γp ≥ 0 and θp ≤ γp, similarly to [16]: if
player p does not enter the market, his utility is zero; if he enters the game but the other player does not, p
has a monopoly on the market and gets non-negative utility; ﬁnally, if both players enter the game, they
compete against each other and get less utility than if they had a monopoly. In our simulations, we ﬁx values
for the parameters (γp, θp) and generate the perturbed games as follows:

17

(a) Compatible region in the partial payoﬀ information
setting with σ = 0.5

(b) Compatible region in the payoﬀ shifter information
setting σ = 0.5, σs = 10

Figure 1: Plots of the compatible region for the “payoﬀ shifter information ” and “partial payoﬀ information
settings ”

• In the “no payoﬀ information” and the “partial payoﬀ information” settings, we add Gaussian noise with
mean 0 and standard deviation σ (we vary the value of σ) to Gp(ap = 1, a−p) to obtain the perturbed
games G1, ..., Gl.

• In the “payoﬀ shifter information” case, we sample the payoﬀ shifters S1, ..., Sl such that for all k ∈ [l],
p (ap = 1, a−p) follows a normal distribution of mean 0 and standard deviation σs.
for all players p, Sk
We then add Gaussian noise with mean 0 and standard deviation σ to Gp(ap = 1, a−p) to obtain the
perturbed games G1, ..., Gl.

• In all observation models, no observed payoﬀ shifter nor unknown noise is added to the payoﬀ of action
ap = 0 for player p; action ap = 0 is always assumed to yield payoﬀ 0 for player p, independently of a−p.

Once the perturbed games are generated, we ﬁnd the set of equilibria Sk of each of the Gk, and sample a
point ek uniformly at random in Sk. In the payoﬀ information case, we also compute vk = ek (cid:48)Gk.

We assume the observer knows the form of the utility function, i.e., that Gp(0, 0) = 0 and Gp(ap =
0, a−p = 1) = 0, and that he aims to recover the values of γp and θp. Thus, we add linear constraints
Gp(0, 0) = 0 and Gp(ap = 0, a−p = 1) = 0 in each of the optimization programs (3), (4) and (5) that we
solve for player p in the ‘payoﬀ shifters information”, the “partial payoﬀ information” and the “no payoﬀ
information” settings respectively. Furthermore, we assume that the observer knows that perturbations are
p(ap = 0, a−p = 1) = 0
only added to γ and θ, and therefore we add linear constraints Gk
for all k ∈ [l] to the optimization problems for player p in each of the observation models. All optimization
problems are solved in Matlab, using CVX (see [12]).

p(0, 0) = 0 and Gk

Our model for entry-games is similar to the ones presented in [16] and used in simulations in [7], so as to
facilitate informal comparisons of the simulation results of both papers; in particular, the parametrization of
the utility functions of the players in our simulations is inspired from [7], and noise is generated and added in
a similar fashion. However, formal comparison is diﬃcult because of the diﬀerences in the observation models
and distributional information available in both papers, as well as in the parameters we recover.

7.1 Simulation results

We ﬁx l = 150, γ = 5, θ = −10 in all simulations, and vary the values of σ and σs. We solve all
optimization problems with respect to player 1, and drop the player indices for simplicity of notation. In
all plots, the colored region in the plots is the set of parameters (γ, θ), i.e., of the payoﬀs of the recovered

18

game for which there exist G1, ..., Gl such that the metric d2(G1, ..., Gl|G) is at most C times larger than
the optimal value it can reach subject to the constraints on G, G1, ..., Gl presented in the section dealing
with the corresponding observation model; we call this region the “compatible” region. The darker the
region, the smaller the objective value of the best explanation for the corresponding values of γ and θ. The
light-colored center of the region represents the value of (γ, θ) that minimizes d2(G1, ..., Gl|G). We ﬁx C = 5
in all simulations.
First, we take σ = 0.5, σs = 10. In the “no payoﬀ information” setting, we remark that when using
the framework from Section 6 and looking for a game G whose payoﬀs are rescaled between −20 and 20
and ε = 600, we recover γ = 4.8820, θ = −9.9043; however, accurate recovery is highly dependent on the
chosen ratio of ε to scaling constants, and, in general, it may be diﬃcult for an observer to determine a good
value of ε. Figure 1 plots the compatible region in both the “partial payoﬀ information” and “payoﬀ shifter
information” settings. Note that in both cases, the compatible region is centered on the true value of the
parameters, and that the diameter of the black region, which contains the best games given the observations,
is small.

Figure 2 shows the evolution of the compatible region when varying σ and σs in the “payoﬀ shifter
information” setting. The smaller the standard deviation σ of the unknown noise, the tighter the compatible
region. On the other hand, reasonably increasing the value of σs can be beneﬁcial, at least when it come to
centering the compatible region on the true values of the parameters: this comes from the fact that when the
game is suﬃciently perturbed, new equilibria arise and new behavior is observed, while not adding signiﬁcant
additional uncertainty to the payoﬀs of the game

(a) σ = 0.5, σc = 2.5

(b) σ = 0.5, σc = 5

(c) σ = 0.5, σc = 10

(d) σ = 1.5, σc = 2.5

(e) σ = 1.5, σc = 5

(f) σ = 1.5, σc = 10

Figure 2: Plots of the compatible region for diﬀerent values of σ, σs in the “payoﬀ shifter information ”
observation model

Figure 3 shows the evolution of the compatible region when varying σ. The larger the value of σ, the larger
the compatible region, and the further away its center is from the underlying, true value of the parameters.

19

(a) σ = 0.5

(b) σ = 1.0

(c) σ = 1.5

(d) σ = 2.5

Figure 3: Plots of the compatible region for diﬀerent values of σ in the “partial payoﬀ information ” observation
model

Acknowledgements

We thank Federico Echenique and Matt Shum for extremely helpful comments and suggestions.

Bibliography

[1] A. Aradillas-Lopez. Semiparametric estimation of a simultaneous game with incomplete information.

Journal of Econometrics, 157(2):409 – 431, 2010.

[2] A. Aradillas-Lopez. Nonparametric probability bounds for nash equilibrium actions in a simultaneous

discrete game. Quantitative Economics, 2(2):135–171, 2011.

[3] A. Aradillas-Lopez. Pairwise-diﬀerence estimation of incomplete information games. Journal of Econo-

metrics, 168(1):120 – 140, 2012. The Econometrics of Auctions and Games.

[4] P. Bajari, J. Hahn, H. Hong, and G. Ridder. A Note On Semiparametric Estimation Of Finite Mixtures
Of Discrete Choice Models With Application To Game Theoretic Models. International Economic
Review, 52(3):807–824, 08 2011.

[5] P. Bajari, H. Hong, J. Krainer, and D. Nekipelov. Estimating Static Models of Strategic Interactions.

Journal of Business & Economic Statistics, 28(4):469–482, 2010.

[6] S. Barman, U. Bhaskar, F. Echenique, and A. Wierman. The empirical implications of rank in bimatrix
games. In Proceedings of the Fourteenth ACM Conference on Electronic Commerce, EC ’13, pages 55–72,
New York, NY, USA, 2013. ACM.

[7] A. Beresteanu, I. Molchanov, and F. Molinari. Sharp identiﬁcation regions in models with convex moment

predictions. Econometrica, 79(6):1785–1821, 2011.

[8] U. Bhaskar, K. Ligett, L. J. Schulman, and C. Swamy. Achieving target equilibria in network routing

games without knowing the latency functions. CoRR, abs/1408.1429, 2014.

[9] P. A. Bjorn and Q. H. Vuong. Simultaneous equations models for dummy endogenous variables: A game
theoretic formulation with an application to labor force participation. Working Papers 537, California
Institute of Technology, Division of the Humanities and Social Sciences, 1984.

[10] T. Bresnahan and P. C. Reiss. Empirical models of discrete games. Journal of Econometrics, 48(1-2):57–81,

1991.

[11] A. V. Fiacco and J. Kyparisis. Convexity and concavity properties of the optimal value function in
parametric nonlinear programming. Journal of Optimization Theory and Applications, 48(1):95–126,
1986.

20

[12] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming, version 2.1.

http://cvxr.com/cvx, Mar. 2014.

[13] D. Nekipelov, V. Syrgkanis, and ´E. Tardos. Econometrics for learning agents. CoRR, abs/1505.00720,

2015.

[14] R. Rogers, A. Roth, J. Ullman, and Z. S. Wu. Inducing approximately optimal ﬂow using truthful
mediators. In Proceedings of the Sixteenth ACM Conference on Economics and Computation, EC ’15,
pages 471–488, New York, NY, USA, 2015. ACM.

[15] K. Seim. An empirical model of ﬁrm entry with endogenous producttype choices. RAND Journal of

Economics, 37(3):619–640, 2006.

[16] E. Tamer. Incomplete simultaneous discrete response model with multiple equilibria. The Review of

Economic Studies, 70(1):147–165, 2003.

21

APPENDIX

A Proof of performance of the algorithm

Consider the following optimization program:

P =

min

˜Gk, ˆGk, ˜G, ˆG

s.t.

d(cid:80)
d(cid:80)

j=1

d( ˜G1

1, ..., ˜Gl

1| ˜G1) + d( ˆG1

ij ≥ d(cid:80)
ij ≥ d(cid:80)

j=1

j=1

1, ..., ˆGl
1(i(cid:48), j)ek
˜Gk
1(i(cid:48), j)ek
ˆGk

1| ˆG1)
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]
ij ∀i, i(cid:48) ∈ A1,∀j ∈ A2,∀k ∈ [l]

˜Gk

1(i, j)ek

ˆGk

1(i, j)ek

j=1

(cid:107) ˜G1 − ˆG1(cid:107)∞ ≥ 

If P = δ, then clearly the set of observations is (ε, δ)-non-identiﬁable by deﬁnition. Now suppose the
1) such that ˜G1 is γ-close to
set of observations is (, γ)-non-identiﬁable, then there exist ( ˜G1, ˆG1, ˜Gk
1 are compatible with ek ∀k ∈ [l]. Such a
˜G1
1| ˆG1) ≤ 2γ, hence P = δ ≤ 2γ.
( ˜G1, ˆG1, ˜Gk
To conclude, we just make the easy remark that P = min

1, ˆG1 is γ-close to ˆG1
1, ˆGk

1) is feasible for P and satisﬁes d( ˜G1

1, (cid:107) ˜G1 − ˆG1(cid:107)∞ ≥ , and ˆGk

1| ˜G1) + d( ˆG1
P(i, j).

1, ..., ˆGl

1, ..., ˜Gl

1, ..., ˆGl

1, ..., ˜Gl

1, ˜Gk

1, ˆGk

(i,j)∈m1m2

B Proof of recovery lemma under inﬁnite norm and payoﬀ infor-

mation

Proof. For simplicity of notation, we drop the indices p. We ﬁrst remark that (G, G1, ..., Gl) is feasible for
Program (4); as ( ˆG, ˆG1, ..., ˆGl) is optimal, it is necessarily the case that

(cid:107) ˆG − ˆGk(cid:107)∞ ≤ max

k

max

k

(cid:107)G − Gk(cid:107)∞ ≤ δ.

Let us write ∆G = G − ˆG. We know that for all k, ek (cid:48)Gk = ek (cid:48) ˆGk = vk, and thus ek (cid:48)(Gk − ˆGk) = 0.

We can write

E∆G = (e(cid:48)
= (e(cid:48)
= (e(cid:48)

l(G − ˆG))(cid:48)

1(G − ˆG) ... e(cid:48)
1(G − G1 + G1 − ˆG1 + ˆG1 − ˆG) ... e(cid:48)
1(G − G1 + ˆG1 − ˆG) ... e(cid:48)

l(G − Gl + ˆGl − ˆG))(cid:48).

l(G − Gl + Gl − ˆGl + ˆGl − ˆG))(cid:48)

Let xk = G − Gk + ˆGk − ˆG. We then have (cid:107)E∆G(cid:107)∞ ≤ max
Therefore, by the triangle inequality,

k

(cid:107)E∆G(cid:107)∞ ≤ 2δ.

It immediately follows that (cid:107)∆G(cid:107)∞ ≤ 2(cid:107)E−1(cid:107)∞ · δ.

(cid:107)xk(cid:107)∞ as ek has only elements between 0 and 1.

22

C Obtaining the dual program

We have

with

L(Gk, G, λk
ii(cid:48), λ0, λ1, µ)
= d2(G1, ..., Gk|G) +

= d2(G1, ..., Gk|G) +

= d2(G1, ..., Gk|G) +

(cid:88)
(cid:88)
(cid:88)

k,i,i(cid:48)

k,i,i(cid:48)

k,i,i(cid:48)

ii(cid:48) Gk + µ(−(cid:88)

ii(cid:48) ˜ek (cid:48)
λk

k,i,i(cid:48)

ii(cid:48) Gk − ε) + λ(cid:48)
˜ek (cid:48)

1(G − 1) − λ(cid:48)

0G

ii(cid:48) − µ)˜ek (cid:48)

ii(cid:48) Gk + (λ1 − λ0)(cid:48)G − µε − 1(cid:48)λ1

(λk

ii(cid:48) ˜ek (cid:48)
µk

ii(cid:48) Gk + (λ1 − λ0)(cid:48)G − µε − 1(cid:48)λ1

µk
ii(cid:48) + µ = λk
ii(cid:48)

(11)

Our goal is to ﬁnd h(λk

ii(cid:48)) in order to write the dual. Since L
is a convex function of G1, ..., Gl, G, the ﬁrst order condition needs to hold at a minimum in G1, ..., Gl, G,
unless this minimum is −∞. Remark that for all k,

ii(cid:48)) = inf
G,Gk

L(Gk, G, λ0, λ1, µ, µk

ii(cid:48), λ0, λ1, µ, µk

∂L
∂Gk (Gk, G, λ0, λ1, µ, µk

ii(cid:48)) = 2(Gk − G) +

ii(cid:48) ˜ek
µk
ii(cid:48)

(cid:88)

i,i(cid:48)

and

∂L
∂G

(Gk, G, λ0, λ1, µ, µk

ii(cid:48)) = 2

l(cid:88)

(G − Gk) + (λ1 − λ0)

k=1

Therefore, the ﬁrst order condition is given by

(cid:88)

i,i(cid:48)

2(Gk − G) +

µk
ii(cid:48) ˜ek

ii(cid:48) = 0 ∀k

(G − Gj) + (λ1 − λ0) = 0

l(cid:88)

2

that can be rewritten

j=1

(cid:88)

i,i(cid:48)

(

µk
ii(cid:48) ˜ek

ii(cid:48)) ∀k

Gk = G − 1
2

l(cid:88)

j=1

G =

1
l

Gj − 1
2l

(λ1 − λ0)

(12)

(13)

and implies the following system of equalities that must hold whenever the ﬁrst order condition is satisﬁed:

Gj −

l

2(l − 1)

(

λ1 − λ0

l

+

(cid:88)

i,i(cid:48)

l(cid:88)

Gk =

G =

1
l

1
l − 1

l(cid:88)

j=1

j(cid:54)=k
Gj − 1
2l

(λ1 − λ0)

23

ii(cid:48) ˜ek
µk

ii(cid:48)) ∀k

(14)

(15)

l +(cid:80)

2(l−1) ( λ1−λ0

The system has a solution if and only if the system of equations in (14) has a solution. Let us write
x(i, j) = (G1(i, j), ..., Gl(i, j))(cid:48), bk = − l
µk
ii(cid:48)) for all k, b(i, j) = (b1(i, j), ..., bl(i, j)), and
ii(cid:48) ˜ek
i,i(cid:48)
A ∈ Rl×l the matrix that has 1’s on the diagonal and − 1
l−1 for every other coeﬃcient. Furthermore, let R(A)
denote the range of A, and N (A) its nullspace. Then there exists a solution to (14) iﬀ there exists a solution
to Ax(i, j) = b(i, j) for all (i, j), i.e., if and only if b(i, j) ∈ R(A) for all (i, j). The following statements
characterize R(A) and N (A).
Claim 4. rank(A) = l − 1, dimN (A) = 1
Proof. Let us write A = (a1, a2, ..., al) where ak ∈ Rl has 1 as a kth coordinate and has − 1
coordinates. Therefore, for all i,

l−1 for all other

ak(i) = 1 − l(cid:88)

l(cid:88)

k=1

1
l − 1

= 0,

k(cid:54)=i

l(cid:80)

k=1

ak = 0 and, necessarily, rank(A) ≤ l−1. Now rank(A) ≥ l−1 because (−1, 0, .., 0, 1)(cid:48), (−1, 0, ..., 0, 1, 0)(cid:48),
so
(−1, 0, ..., 0, 1, 0, 0)(cid:48),..., (−1, 1, 0, ..., 0)(cid:48) are l − 1 linearly independent vectors that are in the range of A, as
they are eigenvectors for eigenvalue

k−1 . dimN (A) = 1 follows from the rank-nullity theorem.

k

Claim 5. R(A) = {x ∈ Rl/

xk = 0}

Proof. Let x ∈ R(A), x = Ay. Write A = (a1, ..., al)(cid:48), then x = (a(cid:48)
0(cid:48)y = 0. Therefore, R(A) ⊆ {x ∈ Rl/
subspace of R(A) that has dimension l − 1.

l(cid:80)

k=1

xk = 0}. The rest follows from {x ∈ Rl/

1y, a(cid:48)

2y, ..., a(cid:48)

ly)(cid:48), so

l(cid:80)

k=1

Corollary 1. There exists a solution to the ﬁrst order conditions if and only if

bl = −

l

2(l − 1)

λ1 − λ0

l

(

+

l(cid:88)

k=1

(cid:88)

i,i(cid:48)

µk
ii(cid:48) ˜ek

ii(cid:48)) = 0

(16)

l(cid:80)

l(cid:80)

k=1

xk = (

ak)(cid:48)y =
xk = 0} being a linear

k=1

l(cid:80)

k=1

l(cid:88)

k=1

Proof. Follows immediately from claim 5.
Claim 6. N (A) = span(1, ..., 1)(cid:48)
Proof. A(1, ..., 1)(cid:48) = 0 so span(1, ..., 1)(cid:48) ⊆ N (A) and dim span(1, ..., 1)(cid:48) = dimN (A) = 1.

Corollary 2. If equation (16) holds, the set of solutions S(i, j) of Ax(i, j) = b(i, j) is given by

S(i, j) = {(αij + ˜G1(i, j), ..., αij + ˜Gl(i, j))(cid:48)/αij ∈ R}

for any ( ˜G1, ..., ˜Gl) that satisﬁes the ﬁrst order conditions. In particular, the set of solutions S to the ﬁrst
order conditions is given by

S = {(M + ˜G1, ..., M + ˜Gl)/M ∈ Rl×l}

for any ( ˜G1, ..., ˜Gl) that satisﬁes the ﬁrst order conditions.
Claim 7. ∀k, let ˜Gk = l−1

l bk. Then ( ˜G1, ..., ˜Gl) satisfy the ﬁrst order conditions.

24

(cid:80)

j(cid:54)=k

Proof. Take any k,

1
l−1

equation 16.

Gj + bk = 1

l−1 · l−1

l

(cid:80)

j(cid:54)=k

bj + bk = − 1

l bk + bk = l−1

l bk = Gl as (cid:80)

j(cid:54)=k

bj = −bk from

Putting it all together, we obtain the following lemma:

Lemma 6. The ﬁrst order conditions are satisﬁed if and only if

−

l

2(l − 1)

λ1 − λ0

l

+

ii(cid:48) ˜ek
µk

ii(cid:48)) = 0

l(cid:88)

(
k=1

(cid:88)

i,i(cid:48)

in which case the set S of (G1, ..., Gl) satisfying the ﬁrst order conditions is given by

S = {(M − 1
2

(

λ1 − λ0

l

+

ii(cid:48) ˜e1
µ1

ii(cid:48)), ..., M +

λ1 − λ0

l

1
2

(

+

ii(cid:48) ˜el
µl

ii(cid:48))/M ∈ Rl×l}

(cid:88)

i,i(cid:48)

(cid:88)

i,i(cid:48)

We now have, when constraints (11) and (16) are satisﬁed, and recalling that equation (12) must hold,

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48)) +

ii(cid:48) ˜ek (cid:48)
µk

µk
ii(cid:48) ˜ek

ii(cid:48)) + (λ1 − λ0)(cid:48)G − 1(cid:48)λ1 − µε

(cid:88)
ii(cid:48) (G − 1
(cid:88)
2

i,i(cid:48)

(cid:88)
(cid:88)

k,i,i(cid:48)

k,i,i(cid:48)

that

h(µk

ii(cid:48), λk

ii(cid:48), λ0, λ1) =

=

1
4

1
4

i,i(cid:48)

(
k=1

l(cid:88)
(cid:88)
l(cid:88)
(cid:88)
(cid:88)
l(cid:88)

(
k=1

i,i(cid:48)

i,i(cid:48)

(cid:88)
ii(cid:48))(cid:48)(
(cid:88)
ii(cid:48))(cid:48)(
(cid:88)

i,i(cid:48)
ii(cid:48))(cid:48)(

and otherwise, h(µk

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48)) +

ii(cid:48) ˜ek (cid:48)
µk

ii(cid:48) (− 1
2

i,i(cid:48)

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε

ii(cid:48)) − 1(cid:48)λ1 − µε

i,i(cid:48)

i,i(cid:48)

ii(cid:48), λk

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

(
k=1

= − 1
4
(cid:80)l
k=1((cid:80)
ii(cid:48), λ0, λ1) = −∞. Recall λk
λ1 − λ0 + (cid:80)

(D) = max

µk
ii(cid:48) ,λ0,λ1

− 1

s.t.

i,i(cid:48)

4

ii(cid:48), λ0, λ1 ≥ 0 ∀k, i, i(cid:48), and get the following dual:

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε

This can further be rewritten as:

(D) = max

µk
ii(cid:48) ,λ0,λ1

s.t.

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε

ii(cid:48))(cid:48)((cid:80)

i,i(cid:48)
ii(cid:48) = 0

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48))(cid:48)((cid:80)

i,i(cid:48)
ii(cid:48) = 0

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

k,i,i(cid:48)
ii(cid:48) = λk
µ + µk
ii(cid:48)
ii(cid:48), λ0, λ1 ≥ 0
λk
(cid:80)l
k=1((cid:80)
λ1 − λ0 + (cid:80)

− 1

i,i(cid:48)

4

k,i,i(cid:48)

ii(cid:48) ≥ 0
µ + µk
λ0, λ1 ≥ 0

D Proof of the degeneracy-accuracy trade-oﬀ
Claim 8. P (ε) is a non-decreasing function of ε. In particular, if ε2 > ε1 ≥ 0, then ε2
Proof. Since ε1
ε2
multiply all variables by ε1
ε2
( ε1
ε2

G ≤ 1. Therefore, one can take an optimal solution of P (ε2) and
, to get a solution that is feasible for P (ε1); this solution clearly has objective

≤ 1, we have 0 ≤ ε1

P (ε2) ≥ P (ε1).

)2P (ε2).

1
ε2
2

ε2

This immediately gives the ﬁrst part of the theorem.

25

Lemma 7. Let ε2 ≥ ε1 > 0, and suppose P (ε2) > 0. Then:
√
)P (ε2) −

P (ε1) ≥ (1 − 2

ε2 − ε1

(cid:112)P (ε2)

ε2 − ε1

ε2

lm

Proof. Recall that

D(ε) = max

µk
ii(cid:48) ,λ0,λ1

s.t.

ii(cid:48))(cid:48)((cid:80)

i,i(cid:48)
ii(cid:48) = 0

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ε2

(cid:80)l
k=1((cid:80)
λ1 − λ0 + (cid:80)

− 1

i,i(cid:48)

4

ii(cid:48) ≥ 0
µ + µk
λ0, λ1 ≥ 0

k,i,i(cid:48)

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε

(17)

Take any optimal solution (µk
do not depend on the value of ε. Therefore,

ii(cid:48), µ, λ1) of D(ε2), it is clearly feasible for D(ε1) as the constraints in the dual

Note that since strong duality holds, by the KKT conditions,

l(cid:88)

(
k=1

(cid:88)

i,i(cid:48)

− 1
4

(cid:88)

i,i(cid:48)

l(cid:88)

(
k=1

(cid:88)

i,i(cid:48)

1
4

(cid:88)
ii(cid:48))(cid:48)(

i,i(cid:48)

µk
ii(cid:48) ˜ek

ii(cid:48))(cid:48)(

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε1 ≤ D(ε1)

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48)) = P (ε2) = D(ε2)

and therefore

Since

we have

and therefore,

D(ε2) = − 1
4

l(cid:88)

(
k=1

(cid:88)

i,i(cid:48)

−D(ε2) − 1(cid:48)λ1 − µε1 ≤ D(ε1)

(cid:88)
ii(cid:48))(cid:48)(

i,i(cid:48)

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε2 = −D(ε2) − 1(cid:48)λ1 − µε2

2D(ε2) + µε2 = −1(cid:48)λ1

D(ε2) + µ(ε2 − ε1) = −D(ε2) − 1(cid:48)λ1 − µε1 ≤ D(ε1)
Now, let us try to lower bound µ. We ﬁrst remark that necessarily, µ ≤ 0. If not,

l(cid:88)

(
k=1

(cid:88)

i,i(cid:48)

(cid:88)
ii(cid:48))(cid:48)(

i,i(cid:48)

µk
ii(cid:48) ˜ek

D(ε2) = − 1
4

µk
ii(cid:48) ˜ek

ii(cid:48)) − 1(cid:48)λ1 − µε < 0

and strong duality cannot hold as P (ε2) ≥ 0. Since

µ =

1
ε2

(−2D(ε2) − 1(cid:48)λ1)

it is enough to upper-bound 1(cid:48)λ1. Note that since λ1 is always chosen to be as small as possible as a function
of the µk

ii(cid:48) in order to minimize the objective, we have the following coordinate by coordinate inequality:

(cid:88)

k,i,i(cid:48)

ii(cid:48)) ≤ |(cid:88)

k,i,i(cid:48)

ii(cid:48)| ≤(cid:88)

k

|(cid:88)

i,i(cid:48)

λ1 = max(0,

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

ii(cid:48)|
ii(cid:48) ˜ek
µk

26

by the triangle inequality. For simplicity, let us denote Xk = |(cid:80)
(cid:88)
ii(cid:48))(cid:48)(

ii(cid:48)|(cid:48)|(cid:88)
An upper bound on 1(cid:48)λ1 ≤(cid:80)

i,i(cid:48)
1(cid:48)Xk is therefore given by

|(cid:88)

(cid:88)

l(cid:88)

l(cid:88)

ii(cid:48)| =

ii(cid:48) ˜ek
µk

µk
ii(cid:48) ˜ek

µk
ii(cid:48) ˜ek

i,i(cid:48)

i,i(cid:48)

i,i(cid:48)

i,i(cid:48)

k=1

k=1

(

k

µk
ii(cid:48) ˜ek

ii(cid:48)|.

ii(cid:48) ˜ek
µk

ii(cid:48)) =

l(cid:88)

k=1

X(cid:48)
kXk = 4D(ε2)

(cid:80)
s.t. (cid:80)l
1(cid:48)Xk
k=1 X(cid:48)

max
Xk

k

We can ﬁnd an exact solution to this convex optimization problem by looking at its dual (Slater and therefore
kXk + 4λD(ε2) with λ ≥ 0

k=1 X(cid:48)

strong duality hold); the Lagrangian is given by L(Xk, λ) =(cid:80)
l(cid:88)

and the ﬁrst order condition is Xk = 1
2λ

1. Therefore,

k

kXk ≤ 4D(ε2)

1(cid:48)Xk − λ(cid:80)l

h(λ) = inf
Xk

L(Xk, λ) =

1(cid:48)1 + 4λD(ε2)

1
4λ

k=1

(cid:80)

(cid:80)l

min

1
4λ

k=1

1(cid:48)1 + 4λD(ε2)

k

k=1

1(cid:48) 1

λ
s.t.

λ ≥ 0

(cid:113)(cid:80)l
16D(ε2) ≥ 0 by the ﬁrst order condition, as P (ε2) = D(ε2) > 0 and we get
(cid:118)(cid:117)(cid:117)(cid:116) l(cid:88)
lm(cid:112)D(ε2) leading to

lm2(cid:112)D(ε2) =

1(cid:48)1(cid:112)D(ε2) ≤

h(λ∗) =

√

√

k=1

lm(cid:112)D(ε2).
lm(cid:112)D(ε2))

√

1
ε2

(−2D(ε2) − 1(cid:48)λ1) ≥ 1
ε2

(−2D(ε2) −

)D(ε2) −

√

lm

ε2 − ε1

ε2

(cid:112)D(ε2) ≤ D(ε2) + µ(ε2 − ε1) ≤ D(ε1)

and the dual is given by

The solution to the dual is λ∗ =

So, 0 ≤ 1(cid:48)λ1 ≤ √

µ =
and therefore, as ε2 − ε1 ≥ 0,
ε2 − ε1

(1 − 2

ε2

Claim 9. ∀ε ≥ ε∗,

lim
h→0+

P (ε + h) = P (ε)

i.e. P (.) is right-continuous on [ε∗, +∞[.
Proof. Take h > 0. P (ε + h) ≥ ( ε+h
Lemma 7, since P (ε + h) > 0 as ε + h > ε∗, we have

ε )2P (ε) from claim 8, and ( ε+h

ε )2P (ε) → P (ε) when h tends to 0. From

(cid:112)P (ε + h)

P (ε) ≥ (1 − 2

h

ε + h

)P (ε + h) −

√

lm

h

ε + h

27

and so

1

1 − 2 h

ε+h

(P (ε) +

√

lm

h

ε + h

1

1 − 2 h

ε+h

(P (ε) +

√

lm

h

ε + h

(cid:112)P (ε + h)) ≥ P (ε + h)
(cid:112)P (ε + α)) ≥ P (ε + h)

Note that P (ε + h) ≤ P (ε + α) for any constant α and small enough h; ﬁx an α, we have for h small that

As P (ε + α) is ﬁnite (this is clear from the linear program and previous calculations), we have
√

1

1−2 h

ε+h

(P (ε) +

(cid:112)P (ε + α)) → P (ε) when h tends to 0.

lm h
ε+h
Claim 10. ∀ε > ε∗,

i.e. P (.) is left-continuous on ]ε∗, +∞[.

lim
h→0− P (ε + h) = P (ε)

Proof. The proof is similar to the right-continuity one. The main diﬀerence comes from the fact that we
know require P (ε) > 0 to satisfy the condition of lemma 7 (as ε > ε + h hor h < 0), so we cannot include the
ε = ε∗ case.
Claim 11. P(.) is continuous on [0, +∞[.
Proof. It is clear that P(.) is continuous on [0, ε∗[ and ]ε∗, +∞[ by claims 9 and 10. We just need to check
that P (.) is continuous at ε∗; it is right-continuous at ε∗ by claim 9, and the left-continuity follows from the
fact that P (ε) = 0 ∀ε ≤ ε∗.
Claim 12. P(.) is convex on [0, +∞[.

Proof. Let S(ε) be the feasible region of optimization program (5). It is easy to see that the objective function
of (5) is convex, and that the mapping ε → P (ε) is convex according to the deﬁnition of [11]. Therefore, as
seen in [11], the optimal value function P (.) of Program (5) is convex.
Claim 13. Let ε ≥ ε∗, we have for all h > 0
ε2 P (ε) ≤ P (ε + h) − P (ε)

(cid:112)P (ε + h)

P (ε + h) +

≤ 2

h + 2ε

ε + h

ε + h

√

lm

h

1

Proof. From claim 8, for h > 0,

P (ε + h) − P (ε)

h

≥ P (ε)
h

((

ε + h

ε

)2 − 1) =

h + 2ε

ε2 P (ε)

(18)

From Lemma 7,

P (ε + h) − P (ε)

h

≤ 1
h

h

ε + h

(2

2

P (ε + h) +
√

P (ε + h) +

lm

=

ε + h

h

(cid:112)P (ε + h))
(cid:112)P (ε + h).

ε + h

√

lm

1

ε + h

28

Since P (.) is a convex and continuous on [0, +∞[, its right derivative dP (ε)

exists at every point ε ≥ 0.

dε

By Claim 13, we have

where

l(ε) ≤ dP (ε)
dε

≤ L(ε)

l(ε) = lim
h=0+

h + 2ε

ε2 P (ε)
2

L(ε) = lim
h=0+

ε + h

P (ε + h) +

lm

(cid:112)P (ε + h)

1

√

√

if they exist. Clearly, l(ε) = 2
continuous and limh=0+ P (ε + h) = ε. This implies that given an initial condition P (ε0) for some ε0 > ε∗,
P (.) lies between the function f with f (ε0) = P (ε0) and df (ε)
dε = l(ε) and the function g with g(ε0) = P (ε0)
and dg(ε)

dε = L(ε) for all ε ≥ ε0. We can ﬁnd f and g by solving diﬀerential equations

ε P (ε) exists; L(ε) = 2

ε P (ε) +

lm
ε

ε + h

(cid:112)P (ε) exists because by claim 9, P (.) is right

f (ε)

df (ε)

dε

=

dg(ε)

2
ε
2
ε

(cid:112)g(ε)

√

lm
ε

(19)

(20)
for all ε ≥ ε0. It is easy to see that with initial condition f (ε0) = P (ε0), ODE (19) has as a unique solution

g(ε) +

dε

=

To solve ODE (20), let us write g(ε) =(cid:112)f (ε), and note that the diﬀerential equation can be rewritten:

f (ε) = P (ε0)

Noting that by the choice of initial condition, g(ε0) = P (ε0) > 0 and that the solution of the diﬀerential
equation is necessarily increasing as the derivative is always non-negative, we have g(ε) > 0 for all ε ≥ ε0.
Therefore, on [ε0, +∞[,

The initial condition being ﬁxed, this diﬀerential equation has a unique solution. Note that solutions to the
homogeneous ODE dg(ε)
is a particular solution

of the ODE. Therefore, given the initial condition g(ε0) =(cid:112)P (ε0), we have

ε g(ε) are of the form g(ε) = Cε, and that g0(ε) = −√

dε = 1

lm
2

ε2
ε2
0

√

2g(ε)

dg(ε)

dε

=

2
ε

g(ε)2 +

lm
ε

g(ε)

dg(ε)

dε

1
ε

=

g(ε) +

√

lm
ε

g(ε) = ((cid:112)P (ε0) +
((cid:112)P (ε0) +

(cid:16)

f (ε) =

√

√

lm
2

−

)

ε
ε0

lm
2

√

lm
2

−

)

ε
ε0

√

lm
2

(cid:17)2

.

29

and thus

