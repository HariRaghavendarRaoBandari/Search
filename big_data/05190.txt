6
1
0
2

 
r
a

 

M
6
1

 
 
]

M

I
.

h
p
-
o
r
t
s
a
[
 
 

1
v
0
9
1
5
0

.

3
0
6
1
:
v
i
X
r
a

Draft version March 17, 2016
Preprint typeset using LATEX style emulateapj v. 5/2/11

GADFLY: A PANDAS-BASED FRAMEWORK FOR ANALYZING GADGET SIMULATION DATA

Department of Astronomy, The University of Texas at Austin, TX 78712, USA

Jacob Hummel

Draft version March 17, 2016

Abstract

We present the ﬁrst public release (v0.1) of the open-source gadget Dataframe Library: gadfly.
The aim of this package is to leverage the capabilities of the broader python scientiﬁc computing
ecosystem by providing tools for analyzing simulation data from the astrophysical simulation codes
gadget and gizmo using pandas, a thoroughly documented, open-source library providing high-
performance, easy-to-use data structures that is quickly becoming the standard for data analysis in
python. Gadfly is a framework for analyzing particle-based simulation data stored in the HDF5 format
using pandas DataFrames. The package enables eﬃcient memory management, includes utilities
for unit handling, coordinate transformations, and parallel batch processing, and provides highly
optimized routines for visualizing smoothed-particle hydrodynamics (SPH) datasets.

1.

INTRODUCTION

In the past decade, astrophysical simulations have in-
creased dramatically in both scale and sophistication,
and the typical size of the datasets produced has grown
accordingly. However, the software tools for analyzing
such datasets have not kept pace, such that one of the pri-
mary barriers to exploratory investigation is simply ma-
nipulating the data. This problem is particularly acute
for users of the popular smoothed particle hydrodynam-
ics (SPH) code gadget (Springel et al. 2001; Springel
2005). Both gadget and gizmo (Hopkins 2015), which
uses the same data storage format, are widely used to
investigate a range of astrophysical problems; unfortu-
nately this also leads to fractionation of the data storage
format as each research group modiﬁes the output to
suit its needs. This state of aﬀairs has historically forced
signiﬁcant duplication of eﬀort, with individual research
groups separately developing their own unique analysis
scripts to perform similar operations.

Fortunately, the issue of data management and analy-
sis is not endemic to astronomy, and the resulting overlap
with the needs of the broader scientiﬁc community and
the industrial community at large provides a large pool
of scientiﬁc software developers to tackle these common
problems. In recent years, this broader community has
settled on python as its programming language of choice
due to its eﬃcacy as a ‘glue’ language and the rapid speed
of development it allows. This has led to the develop-
ment of a robust scientiﬁc software ecosystem with pack-
ages for numerical data analysis like numpy (van der Walt
et al. 2011), scipy (Jones et al. 2001), pandas (McK-
inney 2010), and scikit-image; matplotlib (Hunter
2007) and seaborn for plotting; scikit-learn for ma-
chine learning, and statistics and modeling packages
like scikits-statsmodels, pymc, and emcee (Foreman-
Mackey et al. 2013).

Python is quickly becoming the language of choice for
astronomers as well, with the Astropy project (Robitaille
et al. 2013) and its aﬃliated packages providing a coor-
dinated set of tools implementing the core astronomy-
speciﬁc functionality needed by researchers. Addition-

jhummel@astro.as.utexas.edu

ally, the development of ﬂexible python packages like yt
(Turk et al. 2011) and pynbody (Pontzen et al. 2013),
capable of analyzing and visualizing astrophysical simu-
lation data from several diﬀerent simulation codes, have
greatly improved the ability of computational researchers
to perform useful,
insight-generating analysis of their
datasets.

Recently, the scientiﬁc python community has begun
to converge on the DataFrame provided by the high-
performance pandas data analysis library as a common
data structure. As a result, once data is loaded into a
DataFrame, it becomes much easier to take advantage
of the powerful analysis tools provided by the broader
scientiﬁc computing ecosystem. With this in mind, we
present a pandas-based framework for analyzing gad-
get simulation data, gadfly: the GAdget DataFrame
LibrarY.

(v0.1)

of

gadfly, which is

In this paper we present

the ﬁrst public
available
The

re-
lease
at
http://github.com/hummel/gadfly.
frame-
work design and organizational structure are outlined in
Section 2, followed by a description of the included SPH
particle rendering in Section 3. Our plans for future
development are outlined in Section 4, and a summary
is provided in Section 5.

2. A FRAMEWORK BUILT ON PANDAS

There are several motivations for building an analysis
framework around the pandas DataFrame. The guiding
principle underlying the design of this framework is to
enable exploratory investigation. This requires both in-
telligent memory management for handling out-of-core
datasets, and a robust indexing system to ensure that
particle properties do not become misaligned in memory.
Using the pandas DataFrame as the primary data con-
tainer rather than separate numpy arrays makes it much
easier to keep diﬀerent particle properties indexed cor-
rectly while still aﬀording the ﬂexibility to load and re-
move data from memory at will.
In addition, pandas
itself is a thoroughly documented, open-source, BSD-
licensed library providing high-performance, easy-to-use
data structures and analysis tools, and has a strong
community of developers working to improve it. More

2

Jacob Hummel

strated in Figure 1. Our approach to ﬁle access and
intelligent memory management (Section 2.2), our han-
dling of unit conversions (Section 2.3) and coordinate
transformations (Section 2.4), and the included utilities
for parallel batch processing (Section 2.5) are also de-
scribed.

Fig. 1.— Initializing a simulation, deﬁning a PartType dataset,

and loading data.

broadly, as pandas is becoming the de-facto standard for
data analysis in python, doing so simpliﬁes interoperabil-
ity with the rest of the available tools.

Gadfly is designed for use with simulation data stored
in the HDF5 format1. While we otherwise aim to keep
gadfly as general as possible, some assumptions about
the storage format are necessary. Each particle type is
expected to be contained in a diﬀerent HDF5 group, la-
beled PartType0, PartType1, etc; a Header group is
also expected, containing metadata for the simulation
snapshot as HDF5 attributes. All particles are expected
to have the following ﬁelds deﬁned: particle IDs, masses,
coordinates, and velocities. SPH particles are addition-
ally expected to have a smoothing length, density, and
internal energy. Additional ﬁelds not included in the
original gadget speciﬁcation, such as chemical abun-
dances, are also supported.

Here, we provide an overview of the design and capabil-
ities of the gadfly framework, including the Simulation,
Snapshot, and PartType DataFrame objects at the core
of gadfly (Section 2.1), the usage of which is demon-

1 http://www.hdfgroup.org/HDF5

Fig. 2.— Loading non-standard particle ﬁelds and deﬁning cus-

tom PartType classes. Within gadfly this is straightforward.

2.1. Organizational Structure

2.1.1. PartType Dataframes

Data for each particle type (e.g., dark matter, gas,
is stored in a separate PartType dataframe
etc.)
and indexed by particle ID number.
Individual ﬁelds
can be loaded into the dataframes and deleted at
will, with coherent slicing across multiple data ﬁelds,
courtesy of pandas.
The base PartType objects,
PartTypeNbody and PartTypeSPH, are standard pandas
dataframes with additional
functionality for loading
standard gadget particle ﬁelds from HDF5, converting
units, and performing coordinate transformations. As
such, PartType dataframes retain all the capabilities of
the pandas.DataFrame from which they inherit, and any
operation that creates a new dataframe instance returns
a standard pandas dataframe.

Nonstandard particle ﬁelds (e.g.,

chemical abun-
dances) can be easily loaded into gadfly as well; ﬁelds
loaded in this manner simply lack automated unit con-
version. Alternatively, a custom dataframe class inher-
iting from PartTypeNbody or PartTypeSPH as appropri-
ate can be deﬁned to provide methods for loading both
nonstandard particle ﬁelds and additional derived prop-
erties (e.g., temperature). An example of such a custom
class—PartTypeCustom.py—is provided in the examples
distributed with gadfly, and the usage of such a custom
class is demonstrated in Figure 2.

Importinggadflyandinitializingthesimulation:>>>importgadflyasgdf>>>sim=gdf.Simulation(’path_to_simulation_directory’)Loadingasnapshot:>>>snap=sim.load_snapshot(100)>>>snap.file_id<HDF5file"snapshot_100.hdf5"(moder)>>>>snap.file_id.keys()[u’Header’,u’PartType0’,u’PartType1’]InspectingtheHeader:>>>snap.header.Redshift26.663827788885538>>>snap.header.BoxSize100.0Loadingaparticledataset:>>>snap.define_ptype(’dm’,1,gdf.nbody.PartTypeNbody)>>>snap.dm.load_masses()>>>snap.dm.info()<class’gadfly.nbody.PartTypeNbody’>Int64Index:13347573entries,25272898to25272897Datacolumns(total1columns):massesfloat64dtypes:float64(1)memoryusage:203.7MB>>>snap.dm.cleanup()>>>snap.dm.load_quantity(’coordinates’,’particleIDs’)>>>snap.dm.info()<class’gadfly.nbody.PartTypeNbody’>Int64Index:13347573entries,25272898to25272897Datacolumns(total4columns):xfloat64yfloat64zfloat64particleIDsuint32dtypes:float64(3),uint32(1)memoryusage:458.3MBLoadinganon-standardparticlefield:>>>snap.define_ptype(’gas’,0,gdf.sph.PartTypeSPH)>>>snap.gas.load_quantity(’Adiabaticindex’)>>>snap.gas.info()<class’gadfly.sph.PartTypeSPH’>Int64Index:13347573entries,23325038to23308525Datacolumns(total1columns):Adiabaticindexfloat64dtypes:float64(1)memoryusage:203.7MBLoadingadatasetusingacustomclass:>>>fromcustom_ptypeimportPartTypeCustom>>>snap.define_ptype(’gas’,0,PartTypeCustom)>>>snap.gas.calculate_temperature()>>>snap.gas.info()<class’custom_ptype.PartTypeCustom’>Int64Index:13347573entries,23325038to23308525Datacolumns(total3columns):adiabatic_indexfloat64internal_energyfloat64temperaturefloat64dtypes:float64(3)memoryusage:407.3MBGADFLY: A pandas-based Framework for Analyzing GADGET Simulation Data

3

2.1.2. Snapshot

Each Snapshot object represents a single HDF5 snap-
shot ﬁle on disk. File access—provided by h5py (Collette
2008)—is handled via the Snapshot object, and the ac-
tual particle data, loaded as needed into the PartType
dataframes described in Section 2.1.1, is gathered here
with each particle type contained in a separate PartType
dataframe. The information contained in the gadget
header is also maintained here in a Header object, along
with access to the additional metadata and unit infor-
mation stored in the relevant Simulation object.

2.1.3. Simulation

Metadata relevant to the simulation as a whole,
such as ﬁlepaths and unit information, are stored in a
Simulation object. Initializing a Simulation object is
the ﬁrst step in any analysis using gadfly as this is where
default values for all subsequent analysis are set, includ-
ing locating all relevant snapshot ﬁles, choosing a coor-
dinate system, and setting the ﬁeld names of the default
particle properties expected by gadfly. Snapshots are
loaded via Simulation.load_snapshot(), and the par-
allel batch processing functionality described in Section
2.5 is implemented at this level as well.

2.2. Memory Management and File Access

One of the primary goals of the gadfly project is to
enable the analysis of large datasets on machines with
limited memory. Enabling this requires intelligent mem-
ory management, loading only the particle data of in-
terest from the disk. Fortunately the HDF5 protocol is
well-suited to such non-contiguous ﬁle access, allowing
not only individual data ﬁelds to be accessed indepen-
dently, but also for loading only select entries from the
ﬁeld in question.

Gadfly employs two complementary approaches to
minimizing the memory footprint. The ﬁrst method re-
quires deﬁnition of an optional reﬁnement criterion, such
as particles above a given density threshold. The result-
ing ‘reﬁned’ index can then be used to select only the
corresponding values from subsequent particle ﬁelds as
they are loaded. While this method eﬃciently minimizes
I/O operations, it is fairly rigid, and attempting to load
additional ﬁelds into a dataframe from which particles
have been manually dropped will fail, as the particle in-
dices will no longer match. As such, this approach is
poorly suited to exploratory analysis where the proper
reﬁnement criterion may not be know a priori and is
best suited for use in scripts where the analysis to be
performed is well deﬁned.

To mitigate the indexing issues that can arise in situ-
ations where data is loaded incrementally, gadfly per-
forms an intermediate step, ﬁrst loading new ﬁelds into
a pandas.Series data structure, using the particle ID
numbers as an index. This allows pandas to properly
align the particle ﬁelds, dropping any particles not in
the existing PartType dataframe from the newly loaded
ﬁeld as it is appended. This approach, which can be used
in tandem with the reﬁnement index, aﬀords gadfly the
ﬂexibility needed to allow incremental manual reﬁnement
of the data stored in memory. Additional cuts can be
made as subsequent ﬁelds are loaded, resulting in the
selection of a precisely targeted primary dataset from

which derived properties (e.g., temperature) may be cal-
culated, which serves to reduce computational overhead
as well.

Fig. 3.— Unit handling in gadfly.

2.3. Units

Gadfly implements a minimal unit-handling system for
converting between the native code units in which gad-
get stores data and the physical units of interest to as-
tronomers. However, gadget’s code units may be mod-
iﬁed to suit the problem at hand, and therefore must
be speciﬁed at initialization if they diﬀer from the de-
faults listed in Table 1. Conversion from code units to

Default code units expected by gadfly.

TABLE 1

Unit
Mass
Length
Velocity

Conversion to cgs
1.989 × 1043 g
3.085678 × 1021 cm
1.0 × 105 cm s−1

the physical units system of choice is handled at load-
ing. The default units for length, time, mass, etc. can
be speciﬁed at initialization, along with whether to use
physical or comoving coordinates (for cosmological simu-
lations) and whether to factor the Hubble constant out of
the reported units (i.e., units of Mpc vs. Mpc/h). While
defaults are set at startup, they can be modiﬁed at any
time, either by calling units.set_length(), which al-
ters the default length unit for all subsequently loaded
ﬁelds, or by calling a particle ﬁeld’s load function with
the optional units keyword argument. Changing the
units of an existing ﬁeld can be done by simply reloading
it; the ﬁeld will remain properly indexed as described in
Section 2.2. Examples of both approaches to unit con-
versions are shown in Figure 3.

Specifyingcodeunitconversions:>>>importgadflyasgdf>>>sim=gdf.Simulation(’path_to_simulation_directory’,UnitMass_in_g=1.989e43,UnitLength_in_cm=3.085678e21,UnitVelocity_in_cm_per_s=1e5)Specifydefaultunits:>>>sim=gdf.Simulation(’path_to_simulation_directory’,length=’kpc’,mass=’solar’,velocity=’kms’,time=’gyr’)Changedefaultunitsonthefly:>>>sim.units.length_unit’kpc’>>>sim.units.set_length(’AU’)>>>sim.units.length_unit’AU’Specifyunitsatloadtime:>>>sim.units.mass_unit’g’>>>snap.gas.load_masses(unit=’solar’)>>>sim.units.mass_unit’solar’4

Jacob Hummel

2.4. Coordinate Transformations

3. VISUALIZATION

A full suite of coordinate transformation utilities is
included in gadfly, with methods for converting be-
tween Cartesian, spherical, and cylindrical coordinates,
performing linear coordinate translations, and rotations
about arbitrary axes. These methods are both directly
accessible as independent library functions, and via the
PartType dataframe object using the .orient_box()
functionality.

2.5. Parallel Batch Processing

Investigating the results of a simulation often requires
running an identical analysis on many snapshots in order
to study how the system changes with time. These op-
erations are typically completely independent, and thus
amenable to parallelization—so long as the machine be-
ing used has suﬃcient memory. To aid in the paralleliza-
tion of such analyses, gadfly includes utilities for per-
forming parallel batch processing jobs by making use of
python’s multiprocessing module.

One issue with doing operations such as this in parallel
is that they are often IO-bound. To mitigate the issues
that arise when multiple processes attempt to read large
amounts of data from disk simultaneously, gadfly’s par-
allelization utilities are designed to load the data needed
for a given analysis serially in a separate thread from the
main execution. As the necessary data from each snap-
shot ﬁle is loaded, execution is passed to a pool of worker
processes which can then perform the remainder of the
analysis in parallel. An example of such a parallel batch
processing script is included in the examples distributed
with gadfly.

Fig. 4.— Example of a visualization produced by gadfly. This
particular image shows the density distribution in a minihalo form-
ing at z = 25 on 1 kpc scales, and is from a simulation run for
Hummel et al. (2015).

W (r, hs) =

(cid:17)2
(cid:17)3

hs

2

0,

1 − r

hs

(cid:16)

(cid:16) r

1 − 6
ρ(r) (cid:39)(cid:88)

Visualization plays a major role in any analysis of sim-
ulation data, and the ability to directly visualize the spa-
tial structure and evolution of a system is often crucial
to generating insight. While the guiding principle of the
gadfly project is to avoid reinventing the wheel, instead
relying on the tools developed by the broader scientiﬁc
python community wherever possible, SPH particle ren-
dering is one critical area where that broader ecosystem
proves insuﬃcient. To mitigate this shortcoming, gadfly
includes a minimal library of visualization tools.

The particles in an SPH simulation are best thought of
as ﬂuid elements sampling the continuum properties of
the gas they represent (Lucy 1977; Gingold & Monaghan
1977; Monaghan 1992; Springel 2010). They accomplish
this by serving as Lagrangian tracers over which the con-
tinuum properties are interpolated using a smoothing
kernel W . While it is possible to use alternative kernels,
most modern SPH implementations (including gadget)
utilize a cubic spline kernel (Springel 2014):

(cid:17)3

(cid:16) r

hs

+ 6

,

2

≤ 1
≤ 1

, 0 ≤ r
hs
2 < r
hs
r
h > 1,

1

(1)

where r is the radius and hs is the characteristic width
of the kernel, otherwise known as the smoothing length.
The physical density at any point, ρ(r), is then repre-
sented by the sum over all particles

mjW (r − rj, hs),

(2)

j

where mj is the mass of particle j, located at rj. As such,
creating visualizations that faithfully reproduce the ac-
tual density distribution requires performing this sum
over all particles of interest; this can be quite computa-
tionally intensive depending on the number of particles
involved and the desired resolution. The SPH particle
rendering algorithm included in gadfly performs this
summation over two dimensions, producing a density-
weighted projection. An example of such a visualization
produced by gadfly is shown in Figure 4.

Gadfly includes three separate implementations of this
algorithm, each of which is best suited to diﬀerent con-
ditions:

1. The primary implementation is derived from
Navratil et al. (2007) and is written in C, paral-
lelized using OpenMP, and wrapped in python us-
ing scipy.weave. This method must be locally
compiled, and will fail if the python interpreter can-
not locate a C compiler, or if the requisite libraries
are not installed. However, it its the most power-
ful implementation, best suited to rendering many
particles, and to machines with many processors
available.

2. A second implementation makes use of numba (Lam
et al. 2015) to perform just-in-time (JIT) compila-
tion of pure python code using the LLVM com-
piler infrastructure (Lattner & Adve 2004). The
resulting serial routine is highly optimized, pro-
viding performance within a factor of two of the

GADFLY: A pandas-based Framework for Analyzing GADGET Simulation Data

5

parallel method on a 16-core machine. As such,
this method is preferable on smaller machines with
fewer processors, and for visualizations including
fewer particles where the additional overhead asso-
ciated with the parallel implementation is signiﬁ-
cant.

3. The ﬁnal implementation is a pure python routine
included only for situations where the other meth-
ods have unmet dependencies. This implementa-
tion is over 500 times slower than the others, and
as such is suitable only to visualizing small num-
bers of particles, or as a last resort.

These methods are all available as independent library
functions, and can be used both with particle data in
a PartType dataframe or independently from the rest of
the gadfly framework, with data stored in numpy arrays.
Future versions of gadfly will greatly simplify the visu-
alization of data stored in a PartType dataframe through
the use of a .visualize() method (see Section 4).

4. FUTURE DEVELOPMENT

The gadfly package is under active development, and
in addition to incremental improvements of the existing
functionality, a few signiﬁcant upgrades are planned for
future releases. First and foremost, the current gadfly
units system is fairly inﬂexible, with limited support for
additional units. For the next release we plan on re-
placing the existing units system, instead employing the
far more versatile astropy.units framework (Robitaille
et al. 2013) as the backend for handling unit conver-
sions. Future releases will also more seamlessly inte-
grate gadfly’s visualization tools with the rest of the
framework. At the moment the user is required to pass
each required ﬁeld to the visualization methods individ-

ually. We intend to integrate this functionality directly
into the PartType dataframe, allowing the user to sim-
ply call PartType.visualize() and be presented with a
default density projection of the SPH particles currently
in the dataframe, similar to the .plot() functionality of
a standard pandas.DataFrame.

In the longer term, the dask2 project presents an
intriguing option for handling very large out-of-core
datasets through the use of blocked algorithms and task
scheduling. Dask manages this by mapping high-level
numpy, pandas, and list operations on large datasets to
many operations on smaller chunked datasets that can ﬁt
in memory. Future releases of gadfly may migrate the
data structure on which the PartType dataframe is built
from the pandas.DataFrame to dask.dataframe to take
advantage of this functionality.

5. SUMMARY

In this paper we have presented the ﬁrst public release
of gadfly. We have described the framework’s struc-
ture, which is designed around three core abstractions:
the PartType dataframe (Section 2.1.1), the Snapshot
object (Section 2.1.2), and the Simulation object (Sec-
tion 2.1.3). Additional functionality includes intelligent
memory management and ﬁle access (Section 2.2), basic
unit handling (Section 2.3), coordinate transformations
(Section 2.4), utilities for parallel batch processing (Sec-
tion 2.5), and SPH particle visualization (Section 3).

Gadfly is fully open-source,

is released under the
MIT License, and can be downloaded and installed from
its repository at http://github.com/hummel/gadfly.
Users can submit bug reports via GitHub, and if they
know how to ﬁx them, are welcome to submit pull re-
quests.

REFERENCES

Collette, A. 2008, HDF5 for Python, http://www.h5py.org/
Foreman-Mackey, D., Hogg, D. W., Lang, D., & Goodman, J.

2013, PASP, 125, 306

Gingold, R. A., & Monaghan, J. J. 1977, MNRAS, 181, 375
Hopkins, P. F. 2015, MNRAS, 450, 53
Hummel, J. A., Stacy, A., Jeon, M., Oliveri, A., & Bromm, V.

2015, MNRAS, 453, 4136

Hunter, J. D. 2007, Computing in Science & Engineering, 9, 90
Jones, E., Oliphant, T., Peterson, P., & Al., E. 2001, SciPy: Open

source scientiﬁc tools for Python, http://www.scipy.org

Lam, S. K., Pitrou, A., & Seibert, S. 2015, in Proceedings of the

Second Workshop on the LLVM Compiler Infrastructure in
HPC - LLVM ’15 (New York, New York, USA: ACM Press)

Lattner, C., & Adve, V. 2004, in LLVM: A Compilation

Framework for Lifelong Program Analysis and Transformation,
San Jose, CA, USA, 75–88

Lucy, L. B. 1977, AJ, 82, 1013
McKinney, W. 2010, in Proceedings of the 9th Python in Science

Conference, ed. S. van der Walt & J. Millman, 51–56

Monaghan, J. J. 1992, ARA&A, 30, 543

Navratil, P., Johnson, J., & Bromm, V. 2007, IEEE Transactions

on Visualization and Computer Graphics, 13, 1712

Oliphant, T. E. 2006, A Guide to NumPy (Trelgol Publishing),

261

Pontzen, A., Roˇskar, R., Stinson, G., & Woods, R. 2013,

Astrophysics Source Code Library, ascl:1305.002

Robitaille, T. P., Tollerud, E. J., Greenﬁeld, P., et al. 2013, A&A,

558, A33

Springel, V. 2005, MNRAS, 364, 1105
—. 2010, ARA&A, 48, 391
Springel, V. 2014, in Lecture notes given at the 43rd Saas Fee

Advanced School, March 11-16, 2013, Villars-sur-Ollon,
Switzerland

Springel, V., Yoshida, N., & White, S. D. 2001, New Astronomy,

6, 79

Turk, M. J., Clark, P. C., Glover, S. C. O., et al. 2011, ApJ, 726,

55

van der Walt, S., Colbert, S. C., & Varoquaux, G. 2011,

Computing in Science & Engineering, 13, 22

2 http://dask.pydata.org

