6
1
0
2

 
r
a

 

M
0
2

 
 
]

G
L
.
s
c
[
 
 

1
v
0
7
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Under review as a workshop paper at ICLR 2016

JOINT STOCHASTIC APPROXIMATION LEARNING OF
HELMHOLTZ MACHINES

Haotian Xu , Zhijian Ou
Department of Electronic Engineering
Tsinghua University
Beijing, 100084, China
xht13@mails.tsinghua.edu.cn,ozj@tsinghua.edu.cn

ABSTRACT

Though with progress, model learning and performing posterior inference still re-
mains a common challenge for using deep generative models, especially for han-
dling discrete hidden variables. This paper is mainly concerned with algorithms
for learning Helmholz machines, which is characterized by pairing the genera-
tive model with an auxiliary inference model. A common drawback of previous
learning algorithms is that they indirectly optimize some bounds of the targeted
marginal log-likelihood. In contrast, we successfully develop a new class of al-
gorithms, based on stochastic approximation (SA) theory of the Robbins-Monro
type, to directly optimize the marginal log-likelihood and simultaneously mini-
mize the inclusive KL-divergence. The resulting learning algorithm is thus called
joint SA (JSA). Moreover, we construct an effective MCMC operator for JSA. Our
results on the MNIST datasets demonstrate that the JSA’s performance is consis-
tently superior to that of competing algorithms like RWS, for learning a range of
difﬁcult models.

1

INTRODUCTION

Deep generative models (DGMs) have the potential to learn representation and capture high-level
abstractions for high-dimensional data(Hinton et al., 2006; Bengio, 2009). DGMs, often involving
multiple layers of hidden variables h in addition to observed variables x, are highly expressive.
However, model learning and performing posterior inference still remains a common challenge for
using those DGMs, especially for handling discrete hidden variables1.
Recently, there are increased interests in pairing the generative model with an auxiliary infer-
ence model which approximates the posterior inference for the generative model. During train-
ing, it is not only to ﬁt the the generative model pθ(x, h) parameterized by θ, to the training
data, but also to simultaneously train the inference model qφ(h|x) parameterized by φ. This
basic idea has been proposed and enhanced many times - initially the Helmholtz machine with
the wake-sleep algorithm (WS)(Hinton et al., 1995; Dayan et al., 1995); and more recently the
variational autoencoder (VAE)(Kingma et al., 2013), the deep latent Gaussian models (DLGM)
with stochastic backpropagation(Rezende et al., 2014), neural variational inference and learning
(NVIL)(Mnih & Gregor, 2014), re-weighted wake-sleep (RWS)(Bornschein & Bengio, 2014), im-
portance weighted auto-encoders (IWAE)(Burda et al., 2015), and so on. While the above basic idea
remains essentially unchanged, there are much progress in inference and learning algorithms for
Helmholtz machines.

Generally speaking, for those models with a pair of generative and inference models, we could
call them Helmholtz machines. This paper is mainly concerned with algorithms for learning such
Helmholz machines. We leave the detailed discussion of various existing algorithms to Related Work
Section, where we review three main classes of learning algorithms, depending on the objective

1since the reparameterization trick (Kingma et al., 2013) already provides an effective method for handling

continuous hidden variables as we discuss below.

1

Under review as a workshop paper at ICLR 2016

functions used in joint training of p and q model. Remarkably, a common drawback of all the
three class of algorithms is that they indirectly optimize some bounds of the targeted marginal log-
likelihood, whether the variational approximated bound or the IS approximated bound. Accordingly,
the role of the auxiliary inference model in training is the approximation distribution in variational
approximation or the proposal distribution in IS.

In contrast to these previous approaches, we propose a new class of algorithms for learning
Helmholtz machines, based on stochastic approximation (SA) theory of the Robbins-Monro type
Robbins & Monro (1951). Basically, the Robbins-Monro algorithm is a methodology for solving a
root ﬁnding problem, where the function is represented as an expected value. The SA algorithm it-
erates Markov move (implemented via Markov Chain Monte Carlo, MCMC) and parameter update.
The convergence of SA has been studied under various conditions (Benveniste et al., 1990; Chen,
2002; Tan, 2015).

We ﬁrst show how to directly optimize the marginal log-likelihood and simultaneously minimize
the inclusive KL-divergence in the framework of SA. The key is to formulate two gradients as
expectations and equate them to zero, then SA is ready to solve the two simultaneous equations. It
can be proved that under mild conditions, the iterative updated parameters converges to the roots of
the equations almost surely. The resulting learning algorithm is thus called joint SA (JSA). Second,
in the SA setting, the role of the inference model becomes the proposal distribution for constructing
MCMC operator. Speciﬁcally, we construct two types of MCMC operators - one is based on the
standard metropolis independence sampler (MIS)(Hastings, 1970) and the other is based on the
multiple-trial metropolis independence sampler (MTMIS)(Liu, 2008), which considerably improve
SA convergence as shown in our experiments.

The JSA learning algorithm can handle both continuous and discrete variables. In this paper, we
mainly present experimental results for training discrete belief networks with discrete Bernoulli and
multinomial variables for unsupervised learning tasks. Our results on the MNIST datasets demon-
strate that the JSA’s performance is consistently superior to that of competing algorithms like RWS,
for learning a range of difﬁcult models.

2

JOINT STOCHASTIC APPROXIMATION (JSA)

2.1 STOCHASTIC APPROXIMATION BACKGROUND

Since Robbins & Monro (1951), a vast theoretical literature has grown up, concerning condi-
tions for convergence, rates of convergence, multivariate, proper choice of step size, and so on
(Benveniste et al., 1990; Chen, 2002). Recently, it has been shown to work surprisingly well when
training complex generative models, including restricted Boltzmann machines (Tieleman, 2008),
deep Boltzmann machines (Salakhutdinov & Hinton, 2009), and trans-dimensional random ﬁelds
(Wang et al.).

Basically, the SA algorithm is a methodology for solving a root ﬁnding problem, where the functions
are represented as expected values. Suppose that the objective is to ﬁnd a solution ϕ∗ to h(ϕ) = 0
with

h(ϕ) = Eϕ [H(Y ; ϕ)]

(1)

where ϕ ∈ Rd is the parameter of dimension d, H(Y ; ϕ) ∈ Rd is the d-dimensional noisy statis-
tics and Eϕ denotes the expectation with respect to Y ∼ f (·; ϕ), a probability density function
depending on ϕ. A general SA algorithm is as follows.

Stochastic Approximation (Tan, 2015):

• Generate Y (t) ∼ Kϕ(t−1) (Y (t−1), ·), a Markov transition kernel admits f (·; ϕ(t−1)) as the

invariant distribution.

• Set ϕ(t) = ϕ(t−1) + αtH(Y (t); ϕ(t−1)).

The convergence of SA has been studied under mild conditions, e.g. the learning rates αt satisfying
t < ∞. In practice, we can use large learning rates at the early
t for convergence.

t=0 αt = ∞ and P∞

t=0 α2

that P∞

stage of learning and switch to 1

2

Under review as a workshop paper at ICLR 2016

2.2 DEVELOP JSA FOR LEARNING HELMHOLTZ MACHINES

The Helmholtz machine is characterized by pairing a generative model pθ(x, h) with an auxiliary
inference model qφ(h|x). Based on SA theory of the Robbins-Monro type (Robbins & Monro,
1951), the proposed JSA algorithm is to estimate the two set of parameters — θ and φ, by directly
optimizing the marginal log-likelihood and simultaneously minimizing the inclusive KL-divergence.

To that end, we need to solve the simultaneous equations:

∂
∂θ

logpθ(x) =

Epθ (h|x)(cid:20) ∂
KL(pθ(h|x)||qφ(h|x)) = −Epθ (h|x)(cid:20) ∂

logpθ(x, h)(cid:21) = 0
logqφ(h|x)(cid:21) = 0

∂θ

∂φ

∂
∂φ

(2)




which exactly follows the form of Equ. 1. Applying the SA algorithm, we obtain the SA recursion
for updating parameters:

θ(t) = θ(t−1) + αt

φ(t) = φ(t−1) + βt

∂
∂θ
∂
∂φ

logpθ(x, h(t))

logqφ(h(t)|x)

(3)




where h(t) is drawn from the MCMC transition kernel that admits pθ(t−1) (h|x) as the invariant
distribution.

For this purpose, we use the inference model as the proposal distribution to construct the MCMC
operator. Note that as during the SA recursions, the inclusive KL-divergence between the target
posteriori distribution pθ(h|x) and the proposal distribution qφ(h|x) is to be minimized. This
means that the quality of the proposal distribution will be optimised. Moreover, the inclusive KL-
divergence tends to ﬁnd proposal distributions that have higher entropy than the original which is
advantageous for sampling (the exclusive KL would be unsuitable for this reason, (MacKay, 2003)).

In the following, we construct two types of MCMC operators - one is based on the standard
metropolis independence sampler (MIS)(Hastings, 1970) and the other is based on the multiple-trial
metropolis independence sampler (MTMIS)(Liu, 2008), which considerably improve SA conver-
gence as shown in our experiments.

2.2.1 METROPOLIS INDEPENDENCE SAMPLER (MIS)

With abuse of notation, suppose the target distribution is π(x). MIS uses a proposal distribution
g(.), independent of the previous state.

The MIS Scheme: given the current state x(t)

• Draw y ∼ g(y).
• Set x(t+1) = y with probability

min(cid:26)1,

w(y)

w(x(t))(cid:27) , w(x) =

π(x)
g(x)

(4)

2.2.2 MULTIPLE-TRIAL METROPOLIS INDEPENDENCE SAMPLER (MTMIS)

While MIS is simple and easy to implement, it may mix slowly. MTMIS can make large-step moves
along the favorable directions which can accelerate the mixing speed.

The MTMIS Scheme: given the current state x(t)

• Generate K i.i.d samples yj ∼ g(y), j = 1, . . . , K, compute w(yj ) = π(yj)/g(yj)

and W = Pk

j=1 w(yj )

• Draw y from the trial set {y1, . . . , yK} with probability proportional to w(yj )

3

Under review as a workshop paper at ICLR 2016

• Set x(t+1) = y with probability

min(cid:26)1,

W

W − w(y) + w(x(t))(cid:27)

(5)

In the case of learning Heltomhltz machines, we use the inference model qφ(h|x) as the trial distri-
bution to propose samples for pθ(h|x). The importance sampling weight is calculated as :

w(h) =

pθ(h|x)
qφ(h|x)

∝

pθ(x, h)
qφ(h|x)

(6)

Algorithm 1 JSA Learning of Helmholtz machines
1: for number of training iterations do
2:

Randomly pick a training sample x along with its cached hidden states of each layer hx;
Generate sample h via MIS or MTMIS;
Update parameters θ and φ based on Equ. 3;
Update cached hidden states hx for x using samples from qφ(h|x);
Adjust the learning rate.

3:
4:
5:
6: end for

3 RELATED WORK

Depending on the objective functions used in joint training of p and q model, there exist three main
classes of algorithms for learning Helmholtz machines, as summerized in Table. 1.

The ﬁrst class (e.g. VAE, stochastic backpropagation, NVIL, MuProp), uses the variational lower
bound of the marginal log-likelihood as the single objective function, which contains the parameters
of both models (θ, φ). While the gradient with respect to generative parameter θ is well-behaved
and does not pose a problem, the gradient with respect to inference parameter φ is known to have
high variance. To address this problem, reparameterization trick Kingma et al. (2013) has been
developed, providing an effective method for handling continuous hidden variables. Exploring vari-
ance reduction techniques, e.g. NVIL and MuProp(Gu et al., 2015), still remains a major challenge
for this class of algorithms, especially for handling discrete hidden variable, such as Bernoulli or
multinomial.

Another class (e.g. WS, RWS), uses two objective functions - the importance sampling (IS) ap-
proximated lower bound of the marginal log-likelihood 2 for optimizing θ and the inclusive KL-
divergence KL(pθ(h|x||qφ(h|x))) for optimizing φ. The motivation is mixed. Learning through
many cycles of sensing and dreaming seems to be biological attractive. In addition, noting that
the optimization of the variational bound with respect to φ amounts to minimize the exclusive KL-
divergence KL(qθ(h|x||pφ(h|x))), which has the undesirable effect of high variance mentioned
before. Technically, update φ by optimizing the inclusive KL-divergence would be better than op-
timizing the exclusive KL-divergence. A shortcoming of this class of algorithms is that both the IS
estimated gradients for θ and φ are biased estimators. Moreover, the heuristic use of the stochastic
gradients derived from two objective functions also does not provide convergence guarantees.

The third class, mainly the IWAE algorithm, also use a single objective function - the IS approx-
imated lower bound (inspired from RWS). So IWAE is much close to the ﬁrst class of learning
algorithms. By use of the reparameterization trick (inspired from VAE), IWAE can only be applied
to DGMs consisting of continuous latent variables.

2The IS approximated bound is slightly different from the variational bound. The difference is that the
former uses importance weighted averaging in Monte Carlo estimation. When using one sample in Monte
Carlo estimation, they two are equivalent.

4

Under review as a workshop paper at ICLR 2016

Table 1: Review of existing algorithms for learning Helmholtz machines. For each algorithm, we
list the objection function optimized to learn the p and q model (ML: maximum likelihood, V-LB :
the variational lower bound, IS-LB : the IS approximated lower bound), and the supported types of
random variables (RV) (C: continuous, D: discrete).

Algorithm

VAE (Kingma et al., 2013)

NVIL (Mnih & Gregor, 2014)

MuProp (Gu et al., 2015)
WS (Hinton et al., 1995)

RWS (Bornschein & Bengio, 2014)

pθ(x, h)

ML V-LB
√
√
√
√

IWAE (Burda et al., 2015)

JSA

√

1

2

3

√
√
√

√
√

√

IS-LB KL(q||p) KL(p||q)

qφ(h|x)

RV type
C
D
√
√ √
√ √
√ √
√ √
√
√ √

√
√

√

4 EXPERIMENTS

4.1 SETTINGS

We conduct the experiments on the MNIST dataset with a standard training, validation and testing
split of 50k, 10k, and 10k samples. We use the MNIST dataset which was binarized according to
Murray & Salakhutdinov (2009). Both the generative and inference models are of the same type -
either sigmoid belief networks (SBNs) (Saul et al., 1996) with discrete Bernoulli variables or cate-
gorical SBNs with multinomial variables.

For training, we use stochastic gradient decent without momentum and set mini-batch size to 100.
The experiments were run with learning rates of {0.0005, 0.001}. From these two we always report
the result with the highest validation log-likelihood.

For estimating marginal log-likelihood, we use the same method in RWS (Bornschein & Bengio,
2014), namely

pθ(x) = Xh

qφ(h|x)

pθ(x, h)
qφ(h|x)

≃

1
M

M

Xm=1

pθ(x, h(m))
qφ(h(m)|x)

, h(m) ∼ qφ(h|x)

(7)

We use 100 samples to monitor log-likelihood on validation set and use 100,000 samples to estimate
log-likelihood on test set based on Equ. 7.

For our own run of RWS (using the authors’ code) for training categorical SBN, we use the same
experimental settings with Bornschein & Bengio (2014) including the learning rate, momentum and
the number of the samples used (i.e. 10) during training. For fair comparison of computational
complexity, we also use 10 trials for each MTMIS markov move.

4.2 RESULTS

As can been seen from Table. 2, the JSA-MTMIS’s performance (in terms of test likelihoods) is
consistently superior to that of RWS, with the same computational cost, for learning a range of
different models. Moreover, as shown in Fig. 1b, JSA-MTMIS has the same convergence speech as
RWS.

From Fig. 1a, we can see that the JSA-MIS is much slower than JSA-MTMIS and RWS. When
they three converge to a similar log-likelihood value, JSA-MIS takes 10 times epoches compared
to the other two algorithms. It is due to the low sampling efﬁciency of MIS, since each Markov
move in MIS just use one sample from the trial distribution q(h|x). In contrast, MTMIS draws 10
trial samples from q(h|x) and randomly chooses one, which could enable larger move and improve
mixing. This can also be seen from the acceptance ratio during training. In JSA-MIS, 40-50%
samples are accepted, while almost 80-90% samples are accepted in JSA-MTMIS.

5

Under review as a workshop paper at ICLR 2016

Table 2: The negative log-likelihoods (NLL) on test dataset using 100,000 samples to estimate
marginal log-likelihood based on Equ. 7 and lower bound. Both the generative and inference mod-
els are of the same type - either SBNs with discrete Bernoulli variables or categorical SBNs with
multinomial variables (denoted by C). The results of * is from Bornschein & Bengio (2014), ⋄ are
cited from Mnih & Gregor (2014), ♦ from Gu et al. (2015).

Model

WS

RWS

JSA-MIS

JSA-MTMIS

NVIL

MuProp

-90

-100

-110

-120

-130

s
t
a
n
/
L
L

-140

-150

-160

-170

-180

-190

-200

100

200

200-200

200-200-200

116.3∗
(120.7∗)
103.1∗

—

103.5
(112.7)
102.3

(116.37)

—

(113.1⋄)

—

106.9∗
(109.4∗)

93.4∗

—

93.33

(101.00)

92.11

(101.88)

—

(99.8⋄)

—

(113.1♦)

(100.4♦)

101.3∗
(104.4∗)

90.1∗
—

89.85
(97.04)
88.92
(98.20)

—

(96.7⋄)

—

(98.6♦)

200-200-10(C)

200-200-200-10(C)

90.35
(99.71)
91.60
(98.04)
89.84
(98.93)

88.43
(96.09)
88.43
(96.09)
87.82
(96.58)

200-10(C)
NLL est.

(NLL bound)

97.65

(109.41)

97.8

(106.83)

97.05

(110.39)

—

(107.8♦)

-90

-100

-110

s
t
a
n
/
L
L

-120

-130

-140

-150

mtmis est.
mtmis bound
rws est.
rws bound
mis est.
mis bound

101

102

epochs
(a)

103

104

mtmis est.
mtmis bound
rws est.
rws bound

0

50

100

150

200

250

300

350

400

450

500

epochs
(b)

Figure 1:
(a) The convergence curves of MTMIS, RWS and MIS for SBN-200-200 over the test
dataset using 100 samples to estimate the marginal log-likelihoods and lower bounds. (b) The curves
for the ﬁrst 500 epochs taken from (a), which give a clear comparision between JSA-MTMIS and
RWS

5 CONCLUSION

We introduce a new class of algorithms for learning Helmholtz machines - JSA. It directly maxi-
mizes the marginal likelihood and simultaneously minimizes the inclusive KL divergence. In the
JSA setting, we treat the inference model as the trial distribution and construct two types of MCMC
operators - MIS and MTMIS to sample from the true posterior. Our experiments demonstrate that
JSA-MTMIS achieves better likelihood results on MINIST when compared to RWS. Besides, we
also shows that MTMIS is more efﬁcient and mixes more quickly than MIS. In the future, we would
apply JSA to semi-supervised learning of Helmholtz machines.

6

Under review as a workshop paper at ICLR 2016

ACKNOWLEDGMENTS

This project is supported by NSFC grant 61473168. We would like to thank Zhiqiang Tan for
helpful discussions and the developers of Theano (Bergstra et al., 2010; Bastien et al., 2012) for
their powerful software.

REFERENCES
Yoshua Bengio. Learning deep architectures for ai. Foundations and trends R(cid:13) in Machine Learning,

2(1):1–127, 2009.

Albert Benveniste, Michel M´etivier, and Pierre Priouret. Adaptive algorithms and stochastic ap-

proximations. New York: Springer, 1990.

J¨org Bornschein and Yoshua Bengio. Reweighted wake-sleep. arXiv preprint arXiv:1406.2751,

2014.

Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv

preprint arXiv:1509.00519, 2015.

Hanfu Chen. Stochastic approximation and its applications. Springer Science & Business Media,

2002.

Peter Dayan, Geoffrey E Hinton, Radford M Neal, and Richard S Zemel. The helmholtz machine.

Neural computation, 7(5):889–904, 1995.

Shixiang Gu, Sergey Levine, Ilya Sutskever, and Andriy Mnih. Muprop unbiased backpropagation

for stochastic neural networks. arXiv preprint arXiv:1511.05176, 2015.

W Keith Hastings. Monte carlo sampling methods using markov chains and their applications.

Biometrika, 57(1):97–109, 1970.

Geoffrey E Hinton, Peter Dayan, Brendan J Frey, and Radford M Neal. The” wake-sleep” algorithm

for unsupervised neural networks. Science, 268(5214):1158–1161, 1995.

Geoffrey E. Hinton, Simon Osindero, and Yee Whye Teh. A fast learning algorithm for deep belief

nets. Neural Computation, 18:1527–1554, 2006.

Kingma, Diederik P, and Welling Max. Auto-encoding variational bayes.

arXiv:1312.6114, 2013.

arXiv preprint

Jun S Liu. Monte Carlo strategies in scientiﬁc computing. Springer Science & Business Media,

2008.

David JC MacKay. Information theory, inference and learning algorithms. Cambridge university

press, 2003.

Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. arXiv

preprint arXiv:1402.0030, 2014.

Iain Murray and Ruslan R Salakhutdinov. Evaluating probabilities under high-dimensional latent

variable models. In Advances in neural information processing systems, pp. 1137–1144, 2009.

Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and

approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.

Herbert Robbins and Sutton Monro. A stochastic approximation method. The annals of mathemati-

cal statistics, pp. 400–407, 1951.

Ruslan Salakhutdinov and Geoffrey E Hinton. Deep boltzmann machines. In International confer-

ence on artiﬁcial intelligence and statistics, pp. 448–455, 2009.

Lawrence K Saul, Tommi Jaakkola, and Michael I Jordan. Mean ﬁeld theory for sigmoid belief

networks. Journal of artiﬁcial intelligence research, 4(1):61–76, 1996.

7

Under review as a workshop paper at ICLR 2016

Zhiqiang Tan. Optimally adjusted mixture sampling and locally weighted histogram analysis. Jour-

nal of Computational and Graphical Statistics, 2015.

Tijmen Tieleman. Training restricted boltzmann machines using approximations to the likelihood
gradient. In Proceedings of the 25th international conference on Machine learning, pp. 1064–
1071. ACM, 2008.

Bin Wang, Zhijian Ou, and Zhiqiang Tan. Trans-dimensional random ﬁelds for language modeling.
In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics,
volume 1, pp. 785–794.

8

