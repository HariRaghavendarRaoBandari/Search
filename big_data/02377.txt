6
1
0
2

 
r
a

M
8

 

 
 
]
T
G
.
s
c
[
 
 

1
v
7
7
3
2
0

.

3
0
6
1
:
v
i
X
r
a

The Mysteries of Security Games: Equilibrium Computation

becomes Combinatorial Algorithm Design

Haifeng Xu

Department of Computer Science
University of Southern California

haifengx@usc.edu

March 9, 2016

Abstract

The security game is a basic model for resource allocation in adversarial environments. One player
(i.e., the defender) allocates limited resources to defend critical targets and an adversary (i.e., the at-
tacker) seeks his most favorable target to attack. In the past decade, there has been a surge of research
interests in computing, analyzing and reﬁning security games that are motivated by applications from
various real domains. Remarkably, these models and their game-theoretic solutions have led to real-
world deployments in use by major security agencies like the LAX airport, US Coast Guard and Federal
Air Marshal Service [31], as well as non-governmental organizations [10]. Among all these research and
applications, equilibrium computation serves as a foundation.

In this paper, we study security games from a theoretical perspective and provide a uniﬁed view of
various security game models. In particular, we show that each security game can be characterized by a
set system E which consists of the defender’s pure strategies; The defender’s best response problem can
be viewed as a combinatorial optimization problem over E. Our framework captures most of the basic
security game models in literature, including all the deployed systems, and beyond; The set system E
arising from various settings encodes standard combinatorial problems like bipartite matching, maximum
coverage, min-cost ﬂow, packing problems, etc. Our main result shows that equilibrium computation in
security games is essentially a combinatorial problem. In particular, we prove that, for any set system E,
the following problems can be reduced to each other in polynomial time: (0) combinatorial optimization
over E; (1) computing the minimax equilibrium for zero-sum security games over E; (2) computing
the Strong Stackelberg equilibrium for security games over E; (3) computing the best or worst (for the
defender) Nash equilibrium for security games over E. Therefore, the hardness [polynomial solvability]
of any of these problems infers the hardness [polynomial solvability] of all the others. Here by “games
over E” we mean the class of security games with any valid payoff structures, but a ﬁxed set E of
defender pure strategies. This shows that, the complexity of a security game is essentially captured by
the set system E. We view drawing these connections as an important conceptual contribution of this
paper.

1 Introduction

Security of critical infrastructures and areas is an important concern around the world, especially given the
increasing threats of terrorism. Limited security resources cannot provide full security coverage at all places
all the time, leaving potential attackers the chance to explore patrolling patterns and attack the weakness.
How can we make use of the limited resources to build the most effective defense against strategic attackers?
The past decade has seen an explosion of research in attempt to address this fundamental question, which has
led to the development of the well-known model of security games. A security game is a two-player game

1

played between a defender and an attacker. The defender allocates (possibly randomly) limited security
resources, subject to various domain constraints, to protect a set of targets; The attacker chooses one target
to attack. This is a basic model for resource allocation in adversarial environments, and naturally captures
the strategic interaction between security agencies and potential adversaries.
Indeed, these models and
their game-theoretic solutions have led to real-world deployments in use today by security agencies. For
example, they are used by LAX airport for checkpoint placement, US Coast Guard for port patrolling and
the Federal Air Marshal Service for scheduling air marshals [31]; Recently, new models and algorithms have
been tested, and in preparation for deployment, by non-governmental organizations in Malaysia for wildlife
protection [10] and by the Transportation Security Administration (TSA) for airport passenger screening
[4].

Among all these research and applications, equilibrium computation is perhaps the most basic problem
in security games. Indeed, there have been numerous algorithms developed for solving various security
games motivated by different real-world applications (we refer the reader to [31] for a review). However,
many of these algorithms are based on integer linear programs, the techniques of column generation and
sometimes, heuristics, which may run in exponential time or output non-optimal solutions. The computa-
tional complexity for solving these games are not well-understood. Moreover, most of the literature has
focused on the computation of the Strong Stackelberg equilibrium (minimax equilibrium when the game is
zero-sum), which may be inappropriate when the players move simultaneously (see Section 3.2 for a more
detailed discussion). In this paper, we aim at a systematic study on the computational complexity of the three
main equilibrium concepts adopted in security games, namely, the minimax equilibrium, Strong Stackelberg
equilibrium and Nash equilibrium. However, instead of examining all the models one by one, we provide a
uniﬁed view of security games that captures most of the basic models in literature, and provide complexity
analysis under this general framework. Interestingly, it turns out that none of these equilibrium concepts is
computationally harder than the others in any security game captured by our framework.

1.1 Our Results
We start with a uniﬁed formulation of security games.
In particular, we show that security games are
essentially bilinear games, in which each player’s payoff has the form xT Ay + α · y; the defender’s mixed
strategy x lies in a polytope P ⊆ Rn and the attacker’s mixed strategy y is in the n-dimensional simplex ∆n.
Moreover, the matrix A is a non-negative diagonal matrix for the defender, while a non-positive diagonal
matrix for the attacker. Interestingly, the vertexes of P, i.e., all the defender pure strategies, form a set
system E, and the defender’s best response problem can be viewed as a combinatorial optimization problem
over E. This general framework captures most of the basic security game models in literature, including
all the deployed security systems, and beyond. We show that, depending on the setting, the set system E
encodes many standard combinatorial problems like bipartite matching, maximum coverage, min-cost ﬂow,
packing problems, etc.
We are interested in solving the class of security games over E, by which we mean all games with
valid payoff structures, but a ﬁxed set E of defender pure strategies. Our main theoretical results build
connections between combinatorial optimization over E and equilibrium computation for security games
over E. In particular, we prove that, for any set system E, the following problems can be reduced to each
other in polynomial time: (0) combinatorial optimization over E; (1) computing the minimax equilibrium
for zero-sum security games over E; (2) computing the Strong Stackelberg equilibrium for security games
over E; (3) computing the best or worst (for the defender) Nash equilibrium for security games over E.
Therefore, the hardness [polynomial solvability] of any of these problems infers the hardness [polynomial
solvability] of all the others. This shows that, the complexity of a security game is essentially captured by
the set system E. As applications of these results, we also show how to use them to easily recover and
strengthen some known complexity results in the literature, as well as to resolve some open problems from

2

former work.

The result of computing the best/worst Nash equilibrium comes as a surprise. As widely known, maxi-
mizing a player’s utility over Nash equilibria is NP-hard even in two-player normal-form games [15, 7]. It is
neat that security games, which capture a broad class of important real-world applications, “escaped” from
the intractability in many settings. For the zero-sum case, it is not surprising that the minimax equilibrium
can be reduced to the defender’s best response problem, i.e., optimization over E. The interesting direction
is the opposite. That is, the best response problem – a general combinatorial optimization problem – can
be reduced to minimax equilibrium computation, i.e., an optimization problem with very speciﬁc objective.
This is surprising since security games have very simple payoff structures, and are far less general than
bilinear games. Nevertheless, the equilibrium objective is still rich enough to capture a general optimiza-
tion problem. As a complement to this result, we show that, if we further restrict the payoff structure of
security games, there exist zero-sum security games in which the minimax equilibrium can be computed in
polynomial time but the best response problem is NP-hard.

To prove these results, one of the main challenges is to propose universal reductions between these prob-
lems, since we are not working on any speciﬁc instance. Therefore, we have to treat all these problems as
abstractly given. Our reductions make use of the polynomial time equivalence between linear optimization,
separation and membership checking for polytopes. We refer the reader to Section 2.2 for a review.

1.2 Related Work
Several papers in the security game literature have examined the complexity of security games in particular
settings. The most related are the following two papers: Korzhyk et al. [19] consider the security settings
where each security resource can be allocated to protect a subset of targets; Letchford and Conitzer [23]
consider security games on graphs where targets are nodes and security resources patrol along paths. They
prove polynomial solvability or NP-hardness under different conditions. To best of our knowledge, there
is no other work which speciﬁcally focuses on a complexity study of security games. Nevertheless, some
hardness results are provided separately in different work for different models, e.g., [13, 4]. We note that our
framework only concerns the basic security game models. There are many reﬁnements of the basic models,
e.g., the Bayesian setting [27], repeated setting [37], stochastic setting [34], etc. Examining the complexity
of these settings is an interesting future work, but is not the focus of the presented work.

Also related to our work is the rich literature on equilibrium computation for succinctly represented
games. The most fundamental problem along this line is to compute one Nash equilibrium for a two-
player general-sum game. This is proven to be PPAD-hard [8, 5]. In the same setting, computing the Nash
equilibrium that maximizes one player’s utility is NP-hard [15, 7], but the Strong Stackelberg equilibrium
can be computed in polynomial time by solving a linear program [6]. Immorlica et al. [17] consider the
computation of bilinear zero-sum games, and show how to compute the minimax equilibrium when both
players’ action polytopes have explicit polynomial-size expressions. They also reduce computing an -
minimax equilibrium to an additive FPTAS of the player’s best response oracle, using the no regret learning
framework. However, they do not consider the other direction, namely, reduction from best response to
equilibrium computation. Garg et al. [14] consider bilinear general-sum games, and show that such games
are general enough to capture many interesting classes of games, hence are hard to solve in general. They
propose polynomial time (approximation) algorithms when the payoff matrices have low rank.

Outline. Section 2 reviews game theory basics and the tools we use from convex optimization literature.
Section 3 formally describes the uniﬁed formulation of security games, equilibrium concepts adopted in
literature and relation to various combinatorial problems. The reduction between minimax equilibrium and
the best response problem is given in Section 4, while the reduction between Strong Stackelberg equilib-
rium [best/worst Nash equilibrium] and the best response problem is provided in Section 5. We discuss

3

implications of our results in Section 6, and conclude in Section 7.

2 Preliminaries
2.1 Game Theory Basics
In this paper, we focus on two-player games. A normal form two-player game is given by two matrices
A, B ∈ Rm×n. Given mixed strategies x ∈ ∆m and y ∈ ∆n played by player 1 and 2 respectively, player 1
[player 2] derives expected utility xT Ay [xT By]. Slightly generalizing the normal form two-player games
are the bilinear games (see, e.g., [17, 14]), in which, instead of simplexes, each player’ mixed strategies
lie in a general polytope. Formally, a bilinear game is given by a pair of matrices (A, B) and polytopes
(P,Q). Given that player 1 plays x ∈ P and player 2 plays y ∈ Q, the utilities for player 1 and 2 are
xT Ay and xT By respectively. As we will show in Section 3, security games are essentially bilinear games
with slightly richer payoff structures of the form xT Ay + α · y and xT By + β · y for some vector α, β.
Note that each vertex of the polytope is a player pure strategy, and a player may have exponentially many
pure strategies in a bilinear game even though her action polytope (e.g., a hypercube) can be compactly
represented. Throughout this paper, we assume all the action polytopes are compact.

Nash Equilibrium (NE). A strategy proﬁle (x, y) is called a Nash Equilibrium (NE), if

xT Ay ≥ x(cid:48)T Ay, ∀x(cid:48) ∈ P

and

xT By ≥ xT By(cid:48), ∀y(cid:48) ∈ Q.

By Nash’s theorem, there exists at least one NE, possibly multiple NEs, in a bilinear game (assuming P,Q
are compact). As observed in [14], bilinear games encode many interesting classes of games including two-
player normal-form games, two-player Bayesian games, polymatrix games, etc., therefore an NE is hard to
compute in general bilinear games.

Strong Stackelberg Equilibrium (SSE). The NE captures the equilibrium outcome of a simultaneous-
move game. However, when a player, say player 1, can move before another player, the NE is not appropriate
any more. In this setting, the Strong Stackelberg Equilibrium (SSE), which was originally introduced by
Heinrich Freiherr von Stackelberg to capture market competition with leader and follower ﬁrms, serves
as a more appropriate solution concept. A two-player Stackelberg game is played between a leader and
a follower. The leader moves ﬁrst, or equivalently, commits to a strategy, and the follower observes the
leader’s strategy and best responds. The leader’s optimal strategy, together with the follower’s best response,
forms an SSE. Formally, let yx = arg maxy(cid:48)∈Q xT By(cid:48) denote the follower’s best response to a leader
strategy x ∈ P. A strategy proﬁle (x, y) is called a Strong Stackelberg Equilibrium (SSE), if

x = arg max

x(cid:48)∈P x(cid:48)T Ayx(cid:48),

and

y = yx.

Without loss of generality, we can assume y is a pure strategy since it is a best response to x.
Zero-Sum Games and the Minimax Equilibrium. When A = −B, the bilinear game is zero-sum
(zero-sum security games also require α = −β). It is well-known that in zero-sum games, all standard
equilibrium concepts, including the NE and SSE, are payoff-equivalent to the minimax equilibrium. A
strategy proﬁle (x, y), where x ∈ P and y ∈ Q, is called a minimax equilibrium if

xT Ay ≥ x(cid:48)T Ay, ∀x(cid:48) ∈ P

and

xT Ay ≤ xT Ay(cid:48), ∀y(cid:48) ∈ Q.

If (x, y) is a minimax equilibrium, x is called player 1’s maximin strategy, y is called player 2’s minimax
strategy and V = xT Ay = maxx(cid:48)∈P miny(cid:48)∈Q x(cid:48)T Ay(cid:48) is called the value of the game. Each zero-sum game
has a unique game value.

4

2.2 Linear Optimization and Convex Decomposition via Oracles
Any linear optimization problem can be implicitly described as maxx∈P cT x where P ⊆ RN is a polytope.
By “(linear) optimization over P” we mean solving the problem maxx∈P cT x for any c ∈ RN . A member-
ship oracle for P is an algorithm that, on input x0 ∈ RN , correctly asserts whether x0 is in P or not. A
separation oracle for P is an algorithm that, on input x0 ∈ RN , either asserts x0 ∈ P or ﬁnds a hyperplane
aT x = b that separates x0 from P in the following sense: aT x0 > b and aT x ≤ b for any x ∈ P. The
membership [separation] problem for polytope P is to compute a membership [separation] oracle for P. In
the following theorems, by “polynomial running time” we mean polynomial in the dimension N and the
description length of the instance; Solving an LP means return the optimal objective as well as a vertex
optimal solution. The following celebrated results are due to Gr¨otschel – Lov´asz – Schrijver [16].
Theorem 2.1. Let P ⊆ RN be a polytope. If there is a polynomial time algorithm to solve the separation
problem for P, then there is a polynomial time algorithm to solve any linear program over P as well as its
dual program.
Theorem 2.2. (Also see [30, P.189]) Let P ⊆ RN be a polytope and x0 ∈ P is given. There is a polynomial
time algorithm to solve the optimization problem over P if and only if there is a polynomial time algorithm
to solve the membership problem for P. Here the running time is polynomial in N, the description length of
both the instance and x0.

To implement a mixed strategy x ∈ P, we need to decompose x into a linear combination of pure
strategies, i.e., vertexes of P. This can also be done efﬁciently given access to an efﬁcient separation oracle.
Theorem 2.3. Let P ⊆ RN be a polytope. If the separation problem for P can be solved in polynomial time,
then there is a polynomial time algorithm that, on any input x ∈ P, computes N + 1 vertexes x1, ..., xN +1 ∈

P and convex coefﬁcients λ1, ..., λN +1 such that x =(cid:80)N +1

i=1 λixi.

3 The Model of Security Games
3.1 Strategies and Payoff Structures
A security game is a two-player game played between a defender and an attacker. The defender aims to
protect n targets (e.g., physical facilities, critical locations, etc.) from the attacker’s attack. We use [n]
to denote the set of these targets. The defender possesses multiple security resources to be allocated. A
defender pure strategy is a subset of targets that is protected (a.k.a., covered) in a feasible allocation of these
resources. For example, the defender may have k(< n) security resources, each of which can be assigned to
protect any target. In this simple example, any subset of [n] with size at most k is a defender pure strategy.
However, in practice, there are usually resource allocation constraints, thus not all such subsets correspond
to feasible allocations. We will provide more (realistic) examples in Section 3.3.
A more convenient representation of a pure strategy, as will be used throughout this paper, is to use a
binary vector e ∈ {0, 1}n, in which the entries of value 1 specify the covered targets. Note that e can also
be interpreted as the marginal coverage probabilities of each target in this pure strategy.1 Let E ⊆ {0, 1}n
denote the set of all defender pure strategies. Notice that E is essentially a set system. The size of E is
very large, and usually exponential in the number of security resources. In the example mentioned above,
|E| = Ω(nk) which is exponential in k. Therefore, computational efﬁciency in security games means
running time polynomial in n, while not in |E|. In fact, for convenience, we will simply call the running
1Throughout this paper, we will assume security forces have perfect protection effectiveness. That is, once a target is covered,
regardless by one or multiple resources, it is fully protected with probability 1. Generalization to nonperfect effectiveness is
standard.

5

time of an algorithm or the size of a program formulation exponential if it is polynomial in |E|. A defender
mixed strategy is a distribution p over the elements in E. The attacker chooses one target to attack, thus an
attacker pure strategy is a target i ∈ [n]. We use y ∈ ∆n to denote an attacker mixed strategy where yi is
the probability of attacking target i.2

The payoff structure of the game is as follows: given that the attacker attacks target i, the defender gets
a reward ri if target i is covered and a cost ci if i is uncovered; while the attacker gets a cost ζi if target i is
covered and a reward ρi if i is uncovered.3 Both players have utility 0 on the other n − 1 unattacked targets.
A crucial structure of security games is summarized in the following assumption: ri > ci and ρi > ζi for
all i ∈ [n]. That is, covering a target is strictly beneﬁcial to the defender than uncovering it; and the attacker
prefers to attack a target when it is uncovered.4 We summarize the model of security games in the following
deﬁnition.
Deﬁnition 3.1. [Security Game] A security game G with n targets is given by the following tuple (r, c, ρ, ζ,E)
and satisﬁes ri > ci and ρi > ζi for all i ∈ [n]. The security game is called zero-sum if ri + ζi = 0 and
ci + ρi = 0 for all i ∈ [n].

We denote a security game by G(r, c, ρ, ζ,E). When the game is zero-sum, we also use G(r, c,E) for
short. We are interested in solving security games over E, by which we mean all games with valid payoff
structures, but a ﬁxed set E of defender pure strategies. The defender’s utility, as a function of the defender
pure strategy e and attacker pure strategy i, can be formally expressed as
U d(e, i) = ri · ei + ci · (1 − ei),

where ei is the i’th entry of e. Given a defender mixed strategy p ∈ ∆|E| and attacker mixed strategy
y ∈ ∆n, we use U d(p, y) to denote the defender’s expected utility, which can be expressed as

i=1 peyiU d(e, i)
i=1 peyi

(cid:18)
e∈E peei + ci · (1 −(cid:80)

ri · ei + ci · (1 − ei)

(cid:19)

(cid:19)

ri · xi + ci · [1 − xi]

e∈E peei)

(cid:19)

(1)

(2)

U d(p, y) = (cid:80)
= (cid:80)
= (cid:80)n
= (cid:80)n

e∈E(cid:80)n
e∈E(cid:80)n
(cid:18)
ri ·(cid:80)
(cid:18)
(cid:88)

i=1 yi

i=1 yi

xi =

peei ∈ [0, 1]

e∈E

where

x and y. We note that the convex hull of E forms a polytope P = {x : x = (cid:80)

is the marginal coverage probability of target i. Let x = (x1, ..., xn)T denote the marginal probabilities
of all targets induced by the mixed strategy p. Notice that the marginal probabilities of a pure strategy e
is precisely e itself. Equation (1) shows that without loss of generality, we can use marginal probabilities
to compactly represent a defender mixed strategy and express the defender utility. Moreover, the expected
defender utility has the form xT Ay + α · y for some non-negative diagonal matrix A, and is bilinear in
e∈E pe · e, ∀p ∈ ∆|E|}
2One particular type of security games that is not captured by this model is the network interdiction game [35, 33] (also called
graphical security game), in which the defender chooses edges to defend and the attacker chooses a path to attack. The task of the
defender is to interdict the attacker at a certain edge. This belongs to the more general class of succinctly represented games with
non-linear payoffs, which is EXP-hard to approximate in general [11].

3To help the reader to remember, the Greek letters ρ, ζ have similar appearances as r, c.
4In practice, the attacker can also choose to not attack. This can be incorporated into the current model by adding a dummy

target. Therefore, we will not explicitly consider the case here.

6

which consists of all the feasible (i.e., implementable by a defender mixed strategy) marginals. For the rest
of this paper, we will simply interpret a point x ∈ P as a mixed strategy, and write the defender’s utility as
U d(x, y).
has the form xT By + β · y for some non-positive diagonal matrix B, and is bilinear in x and y.

Similarly, the attacker’s expected utility can be represented in the following form. We note that U a(x, y)

(cid:18)

n(cid:88)

(cid:19)

U a(x, y) =

yi

ρi · [1 − xi] + ζi · xi

.

(3)

i=1

3.2 Equilibrium Concepts
Many security games, including some deployed security systems [1, 38], are modeled as zero-sum games.
In this case, ri = −ζi and ci = −ρi for all i ∈ [n], i.e., the defender’s reward [cost] is the negative of the
attacker’s cost [reward]. For example, in the deployed security-game system for patrolling proof-of-payment
metro-systems [38], the defender aims to catch fare evaders at metro stations. This game is naturally zero-
sum: the evader’s cost of paying a ﬁne is the defender’s reward of catching the evader, while the ticket price
is the evader’s reward and the defender’s cost when failing to catch the evader. In zero-sum games, all the
standard equilibrium concepts are payoff-equivalent to the well-known minimax equilibrium, and our goal
is to efﬁciently compute the minimax equilibrium in poly(n) time.

When the game is not zero-sum, i.e., the defender and attacker have different values over targets, the
main solution concept adopted in the literature of security games is the Strong Stackelberg Equilibrium
(SSE) [31]. In particular, the defender plays the role of the leader and can commit to a mixed strategy
before the attacker moves. The attacker observes the defender’s mixed strategy and best responds. This is
motivated by the consideration that the attacker usually does surveillance before committing an attack, thus
is able to observe the empirical distribution of the defender’s patrolling strategy. In this case, our goal is
to compute the optimal mixed strategy for the defender to commit to (the attacker’s best response problem
is usually trivial). Notice that, the attacker is not able to observe the defender’s real-time deployment (i.e.,
pure strategy) since he has to plan the attack before the defender pure strategy is sampled.

Strong Stackelberg Equilibrium (SSE) is appropriate only when the attacker does surveillance and can
indeed observe the defender’s past actions. However, in many cases the attacker does little surveillance. In
fact, sometimes even the attacker intends to do surveillance, he cannot observe the defender’s strategies due
to limited attacker resources and, sometimes, conﬁdentiality of the defender’s resource allocation (e.g., plain
cloth police). In these settings, the defender cannot commit to a strategy,5 thus Nash Equilibrium (NE) serves
as a more appropriate solution concept. Simultaneous-move security game models are particularly common
in the economics literature (see, e.g., [24, 28, 29, 3]). In networked information systems, the interaction
between the defender (system protector) and attacker (malware) is usually modeled as a simultaneous-move
security game (since malwares do not analyze system’s history behaviors) and the goal is to compute some
particular (e.g., best or worst) Nash equilibrium [26, 25].

3.3 Security Games & Combinatorial Optimization
One of the main themes of this paper is to build connections between combinatorial optimization and equi-
librium computation in security games. We view drawing these connections as an important conceptual
contribution of this paper. In particular, we consider the following combinatorial problem.

5Technically, the defender can still commit to play some strategy. However, the attacker cannot observe or verify the defender’s

strategy, making the commitment not effective.

7

Problem 3.2 (Defender Best Response (DBR)). For any non-negative weight vector w ∈ Rn

+, compute

e∗ = arg max

e∈E [w · e].

(cid:18)

(cid:19)

i=1 xi

(cid:80)n

yi[ri− ci]

+(cid:80)n
i=1 yici for any x ∈ P. Let wi = yi[ri− ci] ≥ 0. Since the term(cid:80)n

The DBR problem over E is to compute arg maxe∈E [w · e] for any input w ∈ Rn
+.
In other words, the DBR problem is to compute a defender pure strategy that maximizes the total weights
it “collects”. We claim that Problem 3.2 is precisely the defender’s best response problem to an arbi-
trary attacker mixed strategy. To see this, given any attacker mixed strategy y, we have U d(x, y) =
i=1 yici is not
affected by the defender strategy, the defender’s best response to y is arg maxx∈P x·w = arg maxe∈E e·w.
+, it is easy to ﬁnd an attacker mixed strategy y ∈ ∆n such that yi(ri − ci)
Oppositely, given any w ∈ Rn
is proportional to wi for all i ∈ [n], making Problem 3.2 equivalent to the defender’s best response to y.
Notice that the DBR problem is a combinatorial optimization problem over the set system E. The difference
among various security game models is essentially the structure of the set E. In the following context, we
illustrate how some typical DBR problems relate to standard combinatorial problems.

Uniform Matroid. In simple security settings, the defender has a certain number of security resources,
say k resources; each resource can be assigned to protect any (one) target, i.e., no constraints on allocation.
As a result, any subset of [n] of size at most k is a defender pure strategy. In this case, E is a uniform
matroid and the DBR problem is simply to ﬁnd the largest k weights. The LAX airport security game
system deployed in 2007 – one of the earliest applications of security games – is captured by this model
[27].

Bipartite Matching. A natural generalization of the uniform matroid case is that the resource allocation
has constraints. In this case, the defender has k heterogeneous resources, and each resource can only be
allocated to some particular targets associated with that resource. This naturally models several types of
scheduling constraints in practice. For example, due to geographic constraints, policemen from a certain
police station can only patrol the area around that station. Also, different types of security forces specialize
in protecting different types of targets. The feasibility constraints can be modeled as edges of a bipartite
graph with security resources on one side and targets on another side; a resource can be assigned to a
target if and only if there exists an edge between them in the bipartite graph. Any defender pure strategy
corresponds to a bipartite matching and the DBR problem is to compute the maximum weighted bipartite
matching.

Coverage Problem. In some cases, one security resource can cover several targets. One deployed real
example is the scheduling problem of the federal air marshals, where one air marshal is scheduled to protect
several ﬂights, but constrained on that the arrival destination of any former ﬂight should be the starting point
of the next ﬂight [32]. In other words, each security resource (i.e., air marshal) can protect a (constrained)
subset of targets (i.e., ﬂights). As a result, each pure strategy is the union of targets covered by each security
resource. The DBR problem in this case is the maximum weighted coverage problem. Another natural
example is to protect targets distributed on the plane and each security guard can cover a region of a certain
size. The DBR problem is a 2-dimensional geometric maximum coverage problem.6. Other examples
include patrolling on a graph (e.g., street graph of a city or network systems) in which a patroller at a node
can protect all the adjacent edges or a patroller on an edge can protect its two end nodes. The DBR problem
here is the vertex or edge coverage problem.

Min-Cost Flow. Many security games are played out in (continuous) space and time, which is also
referred as spatio-temporal security games. For example, the deployed software system in [9] helps to
schedule US Coast Guard patrol boats to protect the (moving) Staten Island ferries during the day time.

6For more information about geometric coverage, see the thesis [22] by Leeuwen and the references therein.

8

Figure 1: Feasible (blue) and Infeasible (red) Moves in Discretized Spatio-Temporal Games.

Conservation area patrolling for protecting wildlife is another example [10]. One common way to handle
such continuous settings is to discretize both the spatial and temporal space (e.g., [9, 10]), and protect the
discrete (space, time) points (see Figure 1). The constraint here is that starting from a position at time t, the
positions that a security resource can possibly reach at time t + 1 are restricted due to various constraints
like speed limit, terrain barriers, etc. For example, the move highlighted by red in Figure 1 is infeasible
since the patroller can not move to the end within a small time period due to speed limit, while the blue-
colored moves are feasible. This can be modeled by adding edges between time layers to indicate feasible
moves. The patrolling schedule for each security resource corresponds to a path across all time layers, which
speciﬁes the target this resource covers at each time point (see the blue path in Figure 1). The DBR problem
is, for any given non-negative weights at each (space, time) point, computing k paths for the k resources to
maximize the total weights they cover. This can be solved by adding a super source and sink to the graph,
and then computing a k-unit min-cost integer ﬂow with negative costs.

Packing. Our last example is motivated by recent work to optimize the allocation of security resources
for passenger screening for the Transportation Security Administration (TSA) in United States [4]. Consider
an airport with n ﬂights and ﬂight i has mi passengers. The TSA has several screening tools, e.g., x-ray,
walk-through metal detector, chemicals, etc., and each screening tool has a capacity of the maximum number
of passengers it can check. Opposite from the coverage case where each resource can protect several targets,
here several tools are needed to screen one passenger. More precisely, each screening team is a combination
of several screening tools (but not any combination is a team). By attacking ﬂight i we mean the attacker
becomes a passenger for that ﬂight (i.e., bought its ticket), and brings attack equipments with him. By
protecting the ﬂight from a passenger’s attack we mean that passenger is screened, and identiﬁed as an
attacker if he is, by a screening team.7 The DBR problem is to, given any nonegative weight wi of passengers
in ﬂight i for all i ∈ [n], allocate as many passengers as possible to teams for screening, subject to each
screening tool’s capacity constraint, so that the total weights of screened passengers are maximized. This is
a very general packing problem. In fact, the reader may easily check that when wi = 1 and mi = 1 for any
ﬂight i, the problem encodes a vertex packing (i.e., independent set) problem.

Remark 3.3. We note that the examples above do not capture all the settings of security games. For example,
there is also study on budget constraints for acquiring security resources (e.g., [2]), which induces the
budgeted version of the above combinatorial problems (e.g., the uniform matroid case becomes a Knapsack
problem). In fact, real domains are usually more complicated with various types of constraints, involving

7In [4], each screening team has an effectiveness factor denoting the probability a team can identify an attacker. The example
considered here is slightly simpliﬁed with perfect effectiveness factor 1. Nevertheless, it still captures the essence of the problem
structure and its difﬁculty.

9

timespace.	  .	  .	  .	  .	  .	  .	  .	  .	  .	  .	  .	  .	  .	  .	  intersections of these combinatorial structures. Nevertheless, the combinatorial nature of these problems
does not change and the DBR problem still has the same form as in Deﬁnition 3.1.

4 Solving Zero-Sum Security Games is a Combinatorial Problem

In this section, we focus on zero-sum security games. To recall the notation, we use n to denote the total
number of targets, and reward ri [cost ci] to denote the defender’s utility of covering [uncovering] target i
when it is attacked. The defender seeks to maximize her utility while the attacker seeks to minimize the
defender’s utility. We are interested in computing the minimax equilibrium for security games over E in
poly(n) time. More speciﬁcally, we seek to understand how the computational complexity of the minimax
equilibrium relates to the complexity of the DBR problem. By convention, we sometimes call an algorithm
for solving the DBR problem a DBR oracle. We prove the following equivalence theorem.
Theorem 4.1. There is a poly(n) time algorithm to compute the minimax equilibrium for zero-sum security
games over E, if and only if there is a poly(n) time algorithm to solve the DBR problem over E.

Realizing that security games are bilinear games, it is not surprising that the minimax equilibrium can
be computed in polynomial time with access to an efﬁcient DBR oracle. Indeed, our reduction from the
minimax equilibrium to the DBR problem follows a standard primal-dual argument. In fact, it is not hard
to check that even general bilinear zero-sum games can be solved with access to efﬁcient best response
oracles. What is interesting, however, is the other direction – i.e., solving zero-sum security games is as
hard as solving the general DBR problem. The minimax equilibrium, as an optimization problem, has
a special objective function. It is not clear that such a special objective can be as hard as optimizing a
general objective over E. Moreover, security games are bilinear games with very speciﬁc structures: (i) the
attacker’s mixed strategy set is a simplex; (ii) the defender’s payoff matrix is non-negative and diagonal;
(iii) the attacker’s payoff matrix is non-positive and diagonal. There has been a belief in the literature on
the possibility of solving security games without going through the DBR problem. Indeed, various other
techniques have been employed to tackle security games, e.g., generalized Birkhoff-von Neumann theorem
[23], constrain generation [18] as well as many heuristics. However, the message conveyed by Theorem 4.1
is that to solve security games, one cannot avoid, and also only need, the DBR problem, if only polynomial
time efﬁciency is concerned.
To prove that the DBR problem reduces to equilibrium computation, our reduction makes use of the
polynomial time equivalence between optimization and membership checking for a polytope P. To test
whether any given x is in P or not, the natural idea is to construct a zero-sum security game instance in
which the defender’s maximin strategy corresponds to x precisely when x ∈ P. However, unfortunately,
this is not always possible, because some x is entry-wise dominated by other x(cid:48) ∈ P, thus x can never be
a maximin strategy. To overcome this barrier, we instead consider membership checking and optimization

over a “relaxed” polytope (cid:98)P. We show that if there is a zero-sum security game with defender maximin
strategy x∗ ∈ P, then any x that is dominated by x∗ will be in (cid:98)P . Such a (cid:98)P satisﬁes the down-monotone
ability of checking membership for (cid:98)P, we can optimize over (cid:98)P. Finally, we make use of the condition
w ≥ 0 (essentially due to the assumption ri > ci) to show how to transfer an optimization problem over (cid:98)P

property. This resolves the difﬁculty of checking some x that can never be a maximin strategy. Given the

back to optimization over P. We now provide a formal proof of Theorem 4.1.

The Minimax Equilibrium Formulation
It is well-known that the minimax equilibrium consists of the defender’s maximin strategy and the attacker’s
minimax strategy. We mainly focus on computing the defender’s maximin strategy, since the attacker’s min-
imax strategy can be computed in a similar fashion. Let variable p ∈ ∆|E| be the defender’s mixed strategy

10

and variable x ∈ [0, 1]n be the marginal coverage probability determined by p as deﬁned in Equation (2).
Assuming an adversarial attacker, the defender maximizes her worst-case utility, denoted by variable u.
Then p, x and u can be computed by the following linear program.

maximize u
subject to xiri + (1 − xi)ci ≥ u,

(cid:80)
(cid:80)
e∈E pe · e = x
e∈E pe = 1

pe ≥ 0,

for i = 1, 2, ..., n.

for e ∈ E.

(4)

Reducing Minimax Equilibrium to DBR
We show that LP (4) can be computed in poly(n) time if the DBR problem over E admits a poly(n) time
algorithm. LP (4) has exponentially many variables but polynomially many constraints. We consider the
following dual program of LP (4) with variables r and wi, yi for i ∈ [n].

minimize (cid:80)n
(cid:80)n

i=1 ciyi + r
subject to r − e · w ≥ 0,

(ri − ci)yi = wi,
yi ≥ 0,

i=1 yi = 1

for e ∈ E.
for i = 1, 2, ..., n.

for i = 1, 2, ..., n.

(5)

Note that the optimal {yi}i∈[n] of LP (5) is actually the attacker’s minimax strategy. We show that LP (5)
admits a poly(n) time separation oracle. Given any r and wi, yi for i ∈ [n], we can explicitly check the last
three constraints in LP (5) in poly(n) time. To check whether they satisfy the ﬁrst constraint, we run the
DBR oracle which outputs a pure strategy e∗. If r < e∗ · w, then the ﬁrst constraint is violated at e = e∗.
Otherwise, r ≥ e∗ · w = maxe∈E ≥ e · w for any e ∈ E. Therefore, the ﬁrst constraint is satisﬁed. To
sum up, (5) admits a poly(n) time separation oracle. By Theorem 2.1, both LP (5) and its dual, i.e., LP (4),
can be solved in poly(n) time. We note that the optimal solution of LP (4) is guaranteed to have a support
of poly(n) size, i.e., most of pe will be 0. In fact, Theorem (2.3) guarantees that there exists an optimal
solution with at most n + 1 strictly positive pe’s, and they can be computed efﬁciently.

Reducing DBR to Minimax Equilibrium
The main difﬁculty in proving Theorem 4.1 lies at reducing the DBR problem to the computation of the
minimax equilibrium. We start with a simple observation. Recall that all the feasible marginal coverage
probabilities form the polytope P, and the vertexes of P form the set E of defender pure strategies. The
following is a simple fact of linear programing, which states that any linear program achieves optimality at
some vertex of its feasible region (if non-empty).
Fact 4.2. maxe∈E [w · e] = maxx∈P [w · x], where P = conv(E).

By Fact 4.2, the DBR problem is equivalent to solving the linear program maxx∈P [w · x]. Our ﬁrst
attempt is to reduce the membership checking problem for polytope P to the optimization problem of solving
LP (4). Therefore, computing LP (4) in poly(n) time will allow us to ﬁnd a poly(n) time membership oracle
for P. By the equivalence between membership checking and optimization (Theorem 2.2), we conclude
that the DBR problem can also be solved in poly(n) time. Unfortunately, it turns out that the membership
checking problem for polytope P cannot be easily reduced to solving LP (4) because some x ∈ P is entry-
wise dominated by (i.e., smaller than) other x(cid:48) ∈ P, so that x can never be an optimal solution to LP (4). To

11

overcome this barrier, we relax the polytope P and work on a broader set of marginals. Finally, making use
of the non-negativity of weights in the DBR problem, we argue that working on this relaxed set of marginals
is without loss of generality.

We ﬁrst introduce a few notations. We call(cid:98)e ∈ {0, 1}n a sub pure strategy (of e) if there exists a e ∈ E
such that(cid:98)ei ≤ ei for all i ∈ [n]. Equivalently,(cid:98)e is a sub pure strategy if there exists a defender pure strategy
e such that the covered targets in(cid:98)e is a subset of the covered targets in e. For example, the all zero vector

0 is always a sub pure strategy; any pure strategy e ∈ E is also a sub pure strategy (of itself). Notice that
sub pure strategies are not always feasible (i.e., not always in E). For example, in the air marsh scheduling
problem (see the case of coverage problem in Section 3.3), a feasible schedule for an air marshal has to be
a round trip, while not a one-way ﬂight. We now deﬁne the relaxed set of pure strategies

(cid:98)E = { all e ∈ E and all their sub pure strategies }

to be the set of E augmented with all sub pure strategies. The following lemma shows that, when considering

the DBR problem, relaxing E to (cid:98)E is without loss.
Lemma 4.3. maxe∈E [e · w] = max(cid:98)e∈(cid:98)E [(cid:98)e · w] for any w ∈ Rn
Proof. Since E ⊆ (cid:98)E, we have maxe∈E [e · w] ≤ max(cid:98)e∈(cid:98)E [(cid:98)e · w]. To prove another direction, let(cid:98)e∗ =
arg max(cid:98)e∈(cid:98)E [(cid:98)e · w]. There exists e∗ ∈ E such that(cid:98)e∗ is a sub pure strategy of e∗. Since w ∈ Rn
non-negative, we must have e∗ · w ≥(cid:98)e∗ · w. Therefore,

+ is

+.

e∈E [e · w] ≥ e∗ · w ≥(cid:98)e∗ · w = max(cid:98)e∈(cid:98)E

max

[(cid:98)e · w],

which concludes the proof.

Notice that(cid:98)E is still a ﬁnite set. We now deﬁne the relaxed polytope of marginal probabilities as follows.

(cid:98)P = {x : x =

p(cid:98)e ·(cid:98)e, ∀p ∈ ∆|(cid:98)E|}.

(cid:88)
(cid:98)e∈(cid:98)E

to make sure that its optimal vertex solution is always feasible for the DBR problem.

We show that the DBR problem can be reduced to linear optimization (or equivalently, membership checking

w has zero-valued entries. However, on the other hand side, we need to return a feasible optimal solution

by Theorem 2.2) of this relaxed polytope (cid:98)P. It is easy to prove that the optimal objective of the DBR problem
is equal to maxx∈(cid:98)P [x · w]. However, the challenge of the reduction is that the optimal (vertex) solution to
maxx∈(cid:98)P [x·w], i.e., some(cid:98)e∗ ∈ (cid:98)E, is a sub pure strategy, which may not be a real feasible pure strategy, when
for the DBR problem. To overcome this barrier, we properly regularize the linear program maxx∈(cid:98)P [x · w]
Lemma 4.4. The DBR problem reduces to membership checking for polytope (cid:98)P in poly(n) time.
Proof. By Lemma 4.3 and Fact 4.2, we have maxe∈E [e · w] = max(cid:98)e∈(cid:98)E [(cid:98)e · w] = maxx∈(cid:98)P [x · w]. With the
access to an efﬁcient membership oracle for (cid:98)P, we can solve the optimization problem maxx∈(cid:98)P [x · w] and
get a vertex optimal solution, i.e., some(cid:98)e∗ ∈ (cid:98)E, in poly(n) time by Theorem 2.2 (note that (cid:98)P has a trivial
feasible point 0). However, the problem is that(cid:98)e∗ may not be in E, though we know that there exists some
e∗ such that(cid:98)e∗ is a sub pure strategy of e∗ and e∗ is optimal for both maxx∈(cid:98)P [x · w] and maxe∈E [e · w].
Naturally we prefer the returned optimal solution for maxx∈(cid:98)P [x · w] is e∗ instead of(cid:98)e∗, so that we can

directly return e∗ as the optimal solution for the DBR problem, completing our proof.
To achieve this, we slightly modify the optimization problem. In particular, let polynomial q(n) be
the bit complexity of w, and let  = 2−q(n)/2n which is still of polynomial bit length. Now consider

12

the regularized optimization problem maxx∈(cid:98)P [x · w + (x · 1)]. First observe that any vertex optimal
solution to the regularized optimization problem has to be a real pure strategy. Otherwise, substituting a sub
pure strategy by corresponding real pure strategy will not decrease the ﬁrst term x · w but will strictly
increase the second term (1 · x), thus strictly increases the whole objective. We now claim that if a
real pure strategy e∗ is optimal for the regularized linear optimization problem, it is also optimal for the
corresponding DBR problem. Prove by contradiction. Assume e∗ is optimal for the regularized optimization
problem and a different e(cid:48) is optimal for the DBR problem. Note that both e∗, e(cid:48) are real pure strategies.
By deﬁnition, e(cid:48) · w > e∗ · w. In fact, since e∗, e(cid:48) are 0-1 vectors and w has bit complexity q(n), we have
e(cid:48) · w − e∗ · w ≥ 2−q(n). Therefore,

e∗ · w + (1 · e∗) ≤ e(cid:48) · w − 2−q(n) + n = e(cid:48) · w − 2−q(n)/2 < e(cid:48) · w + (1 · e(cid:48)),

our reduction.

which contradicts the fact that e∗ is optimal for the regularized optimization problem. Therefore, e∗ is
optimal for the DBR problem. Moreover, the regularized optimization problem can be solved in poly(n)

time with access to a poly(n) time membership oracle for (cid:98)P, since the input has poly(n) bits. This completes
As we mentioned before, the key reason for introducing the relaxed polytope (cid:98)P is the following property
of down-monotonicity, which turns out to be crucial for our reduction from the membership checking of (cid:98)P
+. That is, for any x ∈ (cid:98)P and 0 ≤ x(cid:48) ≤ x (entry-wise),
Lemma 4.5. Polytope (cid:98)P is down-monotone in Rn
we have x(cid:48) ∈ (cid:98)P.
i ≤ xi for all i ∈ [n]. We show that x(cid:48) ∈ (cid:98)P. In particular, starting from a
Proof. Let x ∈ (cid:98)P and x(cid:48) satisfy x(cid:48)
convex decomposition for x, we will construct a convex decomposition for x(cid:48) over elements in (cid:98)E.
Since x ∈ (cid:98)P, there exists a p ∈ ∆|(cid:98)E|, such that

to solving the original zero-sum games.

p(cid:98)e ·(cid:98)e.

(cid:88)
(cid:98)e∈(cid:98)E
For all the(cid:98)e satisfying(cid:98)e1 = 1, let(cid:98)e(cid:48) ∈ (cid:98)E be the sub pure strategy of(cid:98)e, which is the same as(cid:98)e except that
1 = 0. Then we do the following operation: change the coefﬁcient of(cid:98)e in Equation (6) to p(cid:98)e· x(cid:48)
(cid:98)e(cid:48)
the coefﬁcient of(cid:98)e(cid:48) in Equation 6 to p(cid:98)e(cid:48) + p(cid:98)e · (1 − x(cid:48)
and change
). It is easy to see that these new coefﬁcients still sum
over elements in (cid:98)E, which gives us a new vector x(cid:48)(cid:48) ∈ (cid:98)E. More importantly, x(cid:48)(cid:48) satisﬁes x(cid:48)(cid:48)
up to 1 and are non-negative. Therefore, Equation (6) with the new coefﬁcients is still a convex combination
1 and
convex decomposition of x(cid:48). Therefore, x(cid:48) ∈ (cid:98)E.
i = xi for all i ≥ 2. Inductively continuing this operation for all the other entries in x(cid:48)(cid:48) we will reach a
x(cid:48)(cid:48)
Lemma 4.6. Membership checking for polytope (cid:98)P reduces in poly(n) time to computing the game value of
Proof. Given any x ∈ Rn, we show how to check x ∈ (cid:98)P by solving properly constructed zero-sum security

+. Otherwise it is easy to check that x is not in (cid:98)P since (cid:98)P ⊆ Rn

zero-sum security games (i.e., solving LP (4)).

games. We assume x lies in Rn
x ∈ Rn

+, we construct the following security game instance:

1
x1

1 = x(cid:48)

x =

1
x1

(6)

+. Given any

• For any i ∈ [n] such that xi = 0, let ci = 1 and ri = 2. Therefore, xiri + (1 − xi)ci = 1.
. Therefore, xiri + (1 − xi)ci = 1.
• For any i ∈ [n] such that xi > 0, let ci = 0 and ri = 1

xi

13

i.e., the game value, in the above zero-sum security game is at least 1 if and only if x ∈ (cid:98)P.

Note that in both cases, the condition ri > ci is satisﬁed. We claim that the defender’s optimal utility,
⇒ direction: Let (p∗, x∗, u∗) be the optimal solution to LP (4). If the defender’s optimal utility is at

least 1, i.e., u∗ ≥ 1. We have

i ri + (1 − x∗
x∗

i )ci ≥ u∗ ≥ 1 = xiri + (1 − xi)ci, ∀i ∈ [n].

(7)

as desired.

Since ri > ci, this induces x∗

deﬁnition and P ⊆ (cid:98)P, therefore x∗ ∈ (cid:98)P. However, xi ≤ x∗
i for any i and (cid:98)P is down monotone, so x ∈ (cid:98)P,
i ≥ xi for any i. Notice that the optimal (feasible) marginal x∗ is in P by
⇐ direction: Let x ∈ (cid:98)P. So there exists p ∈ ∆|(cid:98)E| such that
(cid:88)
p(cid:98)e ·(cid:98)e.
(cid:98)e∈(cid:98)E
p(cid:98)e ·(cid:98)e ≤(cid:88)
(cid:98)e∈(cid:98)E

Notice that each(cid:98)e is a sub pure strategy of some “real” pure strategy e((cid:98)e) ∈ E. By substituting the(cid:98)e in
Equation 7 by e((cid:98)e), we have
where “≤” is entry-wise. However, x(cid:48) =(cid:80)(cid:98)e∈(cid:98)E p(cid:98)e · e((cid:98)e) is a convex combination of pure strategies in E,

thus x(cid:48) ∈ P. Moreover, by playing the mixed strategy with marginal x(cid:48), the defender’s expected utility is
i ≥ xi for any i ∈ [n]. As a result, the optimal defender utility in this zero-sum game is at
at least 1 since x(cid:48)
least 1, completing the proof.

p(cid:98)e · e((cid:98)e).

x =

(cid:88)
(cid:98)e∈(cid:98)E

x =

Lemma 4.4 and 4.6 forms a reduction from the DBR problem to the mimimax equilibrium. This together
with the reduction from the minimax equilibrum to the DBR problem conclude our proof of Theorem 4.1.

4.1 When Gaming is Easier than Best Response
Recall that security games are bilinear games with well-structured payoffs. Theorem 4.1 shows that the
particular problem of computing equilibrium for zero-sum security games fully captures the hardness of the
general DBR problem. Therefore, a natural question is whether there are instances such that the hardness
of gaming and best response are strictly separated. Notice, however, that the best response problem is more
general, thus no easier, than solving the game. Therefore, the question really is, whether there are instances
where gaming is easier than best response. We answer this in the afﬁrmative for security games. Notice that
our construction does not contradict Theorem 4.1 since the instance we will construct has further constrained
payoffs, which make solving the game easy but still maintain the hardness of the best response.
Proposition 4.7. There exist zero-sum security games such that the minimax equilibrium can be computed
in polynomial time but the DBR problem is NP-hard.

Proof. Consider a security game played on a complete graph Kn. Each edge is a target. The defender has
k(< n) security resources and each resource can patrol a vertex, by which the n − 1 adjacent edges of this
vertex are covered. An edge is covered if any of its end vertexes is patrolled. If the attacker attacks edge
e, the defender get utility 1 if it is protected and utility 0 otherwise. The attacker seeks to minimize the
defender’s utility. The DBR problem for this security game is, given weight we ≥ 0 for any edge e ∈ Kn,
ﬁnding k vertexes that maximize the total edge weights they covers. This is NP-hard by a trivial reduction
from vertex cover.

We now show that the minimax equilibrium of this game can be computed in poly(n) time. In fact, we
claim that uniformly randomly sampling k vertexes from Kn to patrol is a minimax equilibrium. Observe

14

that any edge in the constructed mixed strategy is covered with equal probability k
n(n−1) where
the last term is the probability that both end vertexes of an edge is patrolled. Moreover, any pure strategy,
represented as a binary vector, has precisely k(n − 1) − k(k − 1)/2 entries of value 1. This is because any
k vertexes in Kn covers those many edges. As a result, for the marginals x of any mixed strategy, the sum
of its entry values is also k(n − 1) − k(k − 1)/2. Since each edge has the same value to the defender, thus
ideally, the best way is to distribute these probability mass evenly to the n(n − 1)/2 edges and each edge
gets probability mass

n + k

n − k(k−1)

k(n − 1) − k(k − 1)/2

n(n − 1)/2

=

2k
n

− k(k − 1)
n(n − 1)

.

However, this is precisely what the constructed mixed strategy is achieving. Therefore, sampling k vertexes
uniformly at random is a minimax equilibrium.

5 General-sum Security Games
In this section, we consider general-sum security games. Recall that such a game G is given by a tuple
(r, c, ρ, ζ,E) where ri [ci] is the defender’s reward [cost] and ρi [ζi] is the attacker’s reward [cost], when
any target i is attacked. We consider the computation of the two mostly adopted equilibrium concepts in
security games, namely, the Strong Stackelberg Equilibrium (SSE) and Nash Equilibrium (NE). For each
equilibrium concept, we prove analogous equivalence theorem as the zero-sum case.

Theorem 5.1. There is a poly(n) time algorithm to compute the Strong Stackelberg equilibrium for security
games over E, if and only if there is a poly(n) time algorithm to solve the DBR problem over E.
Proof. The “only if” direction follows from Theorem 4.1, the fact that the minimax equilibrium is payoff-
equivalent to the Strong Stackelberg Equilibrium (SSE) in zero-sum games and that zero-sum games are
special cases of general-sum games. We prove the “if” direction. Recall the deﬁnition of SSE in Section 2.1,
without loss of generality, we can assume the attacker always plays a pure strategy since he moves after the
defender. Therefore, as observed in [6], to compute the defender’s optimal mixed strategy, we only need to
enumerate all the possibilities of the attacker’s best response choices . In particular, constrained on that the
attacker’s best response is target k, the defender’s optimal strategy can be computed by the following linear
program (denoted as LPk):

maximize xkrk + (1 − xk)ck
(cid:80)
subject to (1 − xk)ρk + xkζk ≥ (1 − xi)ρi + xiζi,
(cid:80)
e∈E pe · e = x
e∈E pe = 1

pe ≥ 0,

for i (cid:54)= k.

for e ∈ E.

where the ﬁrst constrain is to guarantee that the attacker is indeed incentivized to attack target k. Similar to
the reduction from LP (4) to the DBR problem, we can show that LPk can be solved in poly(n) time with
access to a poly(n) time DBR oracle by exploring the dual program. The SSE can be computed by solving
LP1, ..., LPn and then picking the defender mixed strategy (and corresponding attacker best response) from
the LP of the largest objective.

We now turn to the computation of Nash equilibria. As widely known in the literature of algorithmic
game theory, computing one Nash equilibrium for two-player normal-form games is PPAD-hard [8, 5], and
is only harder for general bilinear games [14]. Interestingly, it turns out that computing a Nash equilibrium
in a security game is relatively easy. This is due to the following characterization of Nash equilibrium in
security games by Korzhyk et al. [21].

15

Lemma 5.2. ([21]) Consider a security game G(r, c, ρ, ζ,E). Let G(−ζ,−ρ, ρ, ζ,E) be the corresponding
zero-sum security game by re-setting the defender’s utilities. Then (x, y) is a Nash equilibrium of G if and
only if (x, f (y)) is a minimax equilibrium of the zero-sum game G, where the one-to-one transform function
f : Rn → Rn is deﬁned as follows:

n(cid:88)

i=1

fi(y) =

ri − ci
ρi − ζi

1
λ

yi, ∀i ∈ [n], where λ =

ri − ci
ρi − ζi

yi is the normalization factor.

(8)

Moreover, Nash equilibria of G are interchangeable. That is, if (x, y) and (x(cid:48), y(cid:48)) are both Nash equilibria,
so are (x, y(cid:48)) and (x(cid:48), y). The attacker receives the same utility in any Nash equilibrium of G.

Notice that the transform function deﬁned in Equation (8) is non-linear due to the normalization factor.
We provide an intuitive explanation of Lemma 5.2 here, while refer the reader to [21] for a formal proof.
Note that the mapping f only re-weights those non-zero yi’s whose indexes correspond to attacker best
responses, so f (y) is still a best response to x in G, thus also in G, since the defender strategy and attacker
payoff structure in both games are the same. On the other hand, x is a best response to y in G. From G
to G, the defender’s utility on each target is changed by a rescaling, so the idea is to rescale the attacker’s
attacking probability to compensate for the defender’s utility rescaling so that the defender’s best response
does not change. The transform function f exactly does this. The interchangeability follows from the
interchangeability of minimax equilibria of G. It is easy to see that the attacker’s utility in any NE equals
his (unique) utility in the zero-sum game G.
As a corollary of Lemma 5.2 and Theorem 4.1, one Nash equilibrium of a security game can be computed
in polynomial time if and only if the DBR problem over E admits a polynomial time algorithm. However,
it is widely known that the Nash equilibrium is not unique in games. To predict and analyze the game
outcomes, we usually need to compute some particular Nash equilibria, among which the NE that maximizes
or minimizes the defender’s utility are usually the most desirable ones. Though Lemma 5.2 shows that the
attacker will derive the same utility in any NE, the defender’s utilities are generally different in different
NEs (examples are given in [21]).

It is widely known that maximizing a player’s utility over Nash equilibria is NP-hard even in two-player
normal-form games [15, 7]. It will be appealing if the optimal NE can be efﬁciently computed in the security
game, which is widely recognized as a very successful application of game theory. Our next result shows
that this is indeed the case! We note that the challenge here is, the defender’s equilibrium utility is a convex
function of the attacker’s mixed strategy (as we will show), and it is generally hard to maximize a convex
function. Interestingly, we prove that the defender equilibrium utility becomes linear when restricted to the
domain of the attacker equilibrium strategies.

Theorem 5.3. There is a poly(n) time algorithm to compute the best and worst (for the defender) Nash
equilibrium for security games over E, if and only if there is a poly(n) time algorithm to solve the DBR
problem over E. Here, by “best” [“worst”] we mean the NE that maximizes [minimizes] the defender’s
utility.

Proof. The “only if” direction follows from Theorem 4.1, the fact that all Nash equilibria are payoff equiv-
alent to the minimax equilibrium in zero-sum games and that zero-sum games are special cases of general-
sum games. For the “if” direction, we only prove the case of computing the best Nash equilibrium since
computing the worst Nash equilibrium is similar.

The defender’s equilibrium utility is a function of the attacker’s strategy, which we denote as UN E(y).

16

We ﬁrst derive the function form of UN E(y), as follows:

UN E(y) = max

x∈P U d(x, y)

(cid:20) n(cid:88)
(cid:20) n(cid:88)

i=1

(cid:21)
(cid:21)

n(cid:88)
n(cid:88)

i=1

+

+

yici

yici

xiyi(ri − ci)

eiyi(ri − ci)

= max
x∈P

= max
e∈E

feasible y which is generally difﬁcult to handle. Interestingly, we show that the term maxe∈E(cid:2)(cid:80)n
ci)(cid:3) becomes linear in y when y is restricted to be an attacker equilibrium strategy. Let (x, y) be a NE of G.

which is a convex function. To compute the best equilibrium, we need to maximize this convex function over
i=1 eiyi(ri−
Recall from Lemma 5.2 that (x, f (y)) is the minimax equilibrium of the zero-sum game G(−ζ,−ρ, ρ, ζ,E).
Therefore,

i=1

i=1

fi(y)ei

fi(y)ρi

(9)

is the game value of G. Recalling the transform fi(y) = 1

yi and utilizing Equation (9), we have

(cid:20) n(cid:88)

i=1

max
e∈E

(cid:21)

eiyi(ri − ci)

= max
e∈E

eiλfi(y)(ρi − ζi)

V al(G) = U d(x, f (y))

(cid:0)ρi − ζi

n(cid:88)

=

i=1

= max
e∈E

fi(y)xi

(cid:20) n(cid:88)

i=1

fi(y)ρi

− n(cid:88)

i=1

i=1

(cid:1) − n(cid:88)
(cid:1)(cid:21)
(cid:0)ρi − ζi
(cid:20) n(cid:88)
(cid:20) n(cid:88)

ri−ci
ρi−ζi

i=1

λ

i=1

(cid:21)

(cid:21)

(cid:21)

eifi(y)(ρi − ζi)

= λ · max
e∈E

(cid:20)

= λ ·

V al(G) +

= λ · V al(G) +

n(cid:88)
n(cid:88)

i=1

fi(y)ρi
ri − ci
ρi − ζi

yiρi

i=1

Crucially, V al(G) is a constant and does not depend on y. Since λ = (cid:80)n
maxe∈E(cid:2)(cid:80)n

i=1 eiyi(ri − ci)(cid:3). Therefor, UN E(y) is linear in y. We note again that this is true only when

yi is linear in y, so is

y is an attacker NE strategy since the above derivation is not valid otherwise. Fortunately, we only need
to optimize over Nash equilibria. Notice that V al(G) can be computed in poly(n) time if the DBR admits
a poly(n) time algorithm by Theorem 4.1. As a result, UN E(y) is a linear function of y which can be
evaluated efﬁciently. Therefore, computing the best Nash equilibrium reduces to a linear optimization over
the set of all the attacker’s Nash equilibrium strategies, denoted as YN E. To complete the proof, we now
show that YN E is a polytope, and admits a poly(n) time separation oracle. Therefore, by Theorem 2.1, we
conclude that the best (for the defender) Nash equilibrium can be computed in poly(n) time.
Lemma 5.4. The set of the attacker’s Nash equilibrium strategies YN E is a polytope, and admits a polyn(n)
time separation oracle if the DBR problem over E can be solved in poly(n) time.

ri−ci
ρi−ζi

i=1

17

Proof of Lemma 5.4. First, compute an arbitrary Nash equilibrium ((cid:101)x,(cid:101)y) of G. By Lemma 5.2 and Theorem

4.1, this can be computed in poly(n) time. We claim that the set of attacker’s Nash equilibrium strategies
YN E is characterized precisely by the following three sets of linear constraints on y ∈ Rn:

(cid:19)
(cid:18)
ρi · [1 − (cid:101)xi] + ζi · (cid:101)xi
(cid:19)
(cid:18)
ri · (cid:101)xi + ci · [1 − (cid:101)xi]

yi

yi

i=1

n(cid:88)
n(cid:88)
n(cid:88)

i=1

yi = 1

and

i=1

yi ≥ 0, ∀i ∈ [n].

≥ ρk · [1 −(cid:102)xk] + ζk ·(cid:102)xk,
≥ n(cid:88)

(cid:18)

ri · ei + ci · [1 − ei]

yi

(cid:19)

∀k ∈ [n].

,

∀e ∈ E.

(10)

(11)

(12)

i=1

We ﬁrst show that these constraints are necessary. By Lemma 5.2, Nash equilibria in security games are

Notice that Inequality (10) restricts y to be an attacker best response to the defender equilibrium strategy(cid:101)x;
Inequality (11) means that(cid:101)x should be a defender best response to the attacker mixed strategy y.
interchangeable, thus if y is an attacker equilibrium strategy, then ((cid:101)x, y) is a Nash equilibrium, so y and(cid:101)x
Constraint (12) restricts y to be a valid mixed strategy; Inequality (10) and (11) induce that ((cid:101)x, y) is a Nash

are best responses to each other, as described by Inequality (10) and (11). Since y is a mixed strategy, thus
Constraint (12) holds.

To show that these constraints are also sufﬁcient, let y be any vector that satisﬁes these constraints.

equilibrium. To sum up, Constraints (10) ∼ (12) precisely characterize the set YN E.

We now show that YN E admits a poly(n) time separation oracle. Notice that Constraints (10) and (12)

can be explicitly checked in poly(n) time. Constraint (11) can be simpliﬁed as follows:

(cid:18)
(cid:18)

yi

yi

n(cid:88)
⇔ n(cid:88)

i=1

i=1

yi

(cid:19)

(cid:19)

ri · ei + ci · [1 − ei]

(cid:18)
(cid:19)
≥ n(cid:88)
ri · (cid:101)xi + ci · [1 − (cid:101)xi]
(cid:19)
(cid:18)
· (cid:101)xi ≥ n(cid:88)
(cid:1) into the DBR problem over E and see whether the
(cid:0)ri−ci
(cid:1)·(cid:101)xi, and if not, return the optimal e from the DBR problem as a
(cid:0)ri− ci

∀e ∈ E.

∀e ∈ E.

ri − ci

ri − ci

· ei,

i=1 yi

i=1

i=1

yi

,

optimal objective is at most(cid:80)n

The inequality can be checked by feeding wi = yi

certiﬁcate of the violated constraint. Therefore, a poly(n) time DBR oracle yields a poly(n) time separation
oracle for YN E. This completes our proof of Lemma 5.2, as well as the proof of the theorem.

The following is a simple corollary of Theorem 5.3. It follows from the fact proved in Theorem 5.3 that
computing the best or worst NE is a linear optimization, therefore we can convert the computation of a NE
with particular defender equilibrium utility to a feasibility checking problem.
Corollary 5.5. Let G be any security game, Umax [Umin] be the best [worst] defender utility among all Nash
equilibria. Then for any U ∈ [Umin, Umax], there exists a NE of G with defender utility U. Furthermore,
such a NE can be computed in polynomial time if the DBR problem over E can be solved in polynomial time.

6 Consequences of the Equivalence Theorems

In this section we discuss some implications of these equivalence theorems. The following corollary of
Theorem 4.1, 5.1 and 5.3 shows that the complexity of a security game is fully captured by the set system
E. Therefor, it should only be a modeling choice about which equilibrium concept to choose in concrete
problems, while not the computational concern.

18

Corollary 6.1. For any set system E, the following problems reduce to each other in polynomial time:

(1) Optimization over E for non-negative linear objective;
(2) Solving zero-sum security games over E;
(3) Computing Strong Stackelberg equilibrium for general-sum security games over E;
(4) Computing best/worst (for the defender) Nash equilibrium for general-sum security games over E.
Corollary 6.1 provide a more convenient way for us to understand the computational complexity of se-
curity games, since the complexity of the combinatorial optimization problem over E is much easier to study
and analyze. In fact, Corollary 6.1 simultaneously implies the computational complexity for solving various
types of security games. For example, when E is any matroid set system or when the optimization over E has
a min-cost ﬂow formulation, the equilibrium of the security game can be computed efﬁciently. On the other
hand, when the optimization over E is a coverage problem, even vertex coverage or 2-D geometric coverage
(NP-hardness proved in [12]), a packing problem, or a Knapsack problem, the equilibrium computation of
these security games are NP-hard in general.

Finally, our framework provides a more combinatorial way to think about security games. It can also
be used to easily recover and strengthen some known complexity results in the literature of security games,
as well as to resolve some open problems from former work. For example, Xu et al.
[36] considered
the computation of the minimax equilibrium in zero-sum spatio-temporal security games (see Section 3.3).
They proved that the DBR problem there is NP-hard in general, but the computation of minimax equilibrium
is left open. Theorem 4.1 resolves this open question. The NP-hardness of the Transportation Security
Administration (TSA) problem shown in [4] easily follows from Corollary 6.1 and the fact that independent
set is NP-hard.
In [13], Gan et al. consider security games on graphs where targets are vertexes. The
defender chooses a subset of vertexes to patrol, by which the patrolled vertexes as well as their adjacent
vertexes are covered. The DBR problem is to, given a non-negative weight for each vertex, ﬁnd a subset of
vertexes to patrol so that the total weight of the covered vertexes is maximized. This is NP-hard by a simple
reduction from set cover. Gan et al. show that computing the SSE is NP-hard. Our results indicate that
computing the minimax equilibrium is also NP-hard. Korzhyk et al. [19] consider security games in which
the DBR problem ﬁts the coverage problem discussed in Section 3.3. They show polynomial solvability of
security games when each (homogeneous) resource can protect a subset of at most 2 targets (e.g., a pair of
round-trip ﬂights). This also follows from Theorem 4.1 and the fact that weighted 2-cover is polynomial
time solvable. The NP-hardness for the case with sets of at most 3 targets follows from Theorem 4.1 and
the fact that 3-cover is NP-hard. Finally, Letchford and Conitzer [23] proved complexity results for security
games played on graphs where vertexes are targets and each resource can patrol an edge or path of the
graph. Some results can be easily recovered under our framework as well. For example, the DBR problem
corresponding to the two positive results there can be solved respectively by a greedy algorithm (the case
of Theorem 1 of [23]) and dynamic programming (the case of Theorem 2 in [23]). We omit further details
here.

7 Conclusions and Discussions

In this paper, we provided a systematic study on the computational complexity of equilibrium computa-
tion in security games. Our main result is the polynomial time equivalence between computing the three
mostly adopted equilibrium concepts in security games, namely, the minimax equilibrium, Strong Stackel-
berg equilibrium, best/worst Nash equilibrium, and computing the defender’s best response. We believe that
our results form a theoretical basis for further algorithm design and complexity analysis in security games.
Future research can take a number of directions. First, given that exactly solving the DBR problem is
NP-hard in many cases, it is an important direction to examine the approximate version of all our equivalence
theorems. That is, how an approximate defender best response oracle relates to the approximate computation

19

of an equilibrium. We note that using the no-regret learning framework, one can transfer an FPTAS for the
DBR problem to an algorithm for computing an -minimax equilibrium (see [17]), but the reverse direction
and other generalizations are open. Second, the results of computing the best/worst Nash equilibrium is
surprising. We wonder how general can this hold, and whether there is any other meaningful game classes
where this is true. Finally, there are several ways to generalize our model. For example, the players’ utility
functions may not be linear, but can still by compactly represented and computed (e.g., the interdiction game
[35, 33]). Another generalization is to allow the attacker to attack multiple targets [20]. We wonder how the
computational complexity of the proposed four problems relates to each other in these generalized settings.

Acknowledgement

We thank Shaddin Dughmi, Milind Tambe and Vincent Conitzer for helpful discussions.

References

[1] Bo An, Eric Shieh, Milind Tambe, Rong Yang, Craig Baldwin, Joseph DiRenzo, Ben Maule, and
Garrett Meyer. PROTECT–a deployed game theoretic system for strategic security allocation for the
United States Coast Guard. AI Magazine, 33(4):96, 2012.

[2] Sayan Bhattacharya, Vincent Conitzer, and Kamesh Munagala. Approximation algorithm for security

games with costly resources. In Internet and Network Economics, pages 13–24. Springer, 2011.

[3] Vicki Bier, Santiago Oliveros, and Larry Samuelson. Choosing what to protect: Strategic defensive

allocation against an unknown attacker. Journal of Public Economic Theory, 9(4):563–587, 2007.

[4] Matthew Brown, Arunesh Sinha, Aaron Schlenker, and Milind Tambe. One size does not ﬁt all: A
game-theoretic approach for dynamically and effectively screening for threats. In AAAI conference on
Artiﬁcial Intelligence (AAAI), 2016.

[5] Xi Chen, Xiaotie Deng, and Shang-Hua Teng. Settling the complexity of computing two-player Nash

equilibria. Journal of the ACM (JACM), 56(3):14, 2009.

[6] Vincent Conitzer and Tuomas Sandholm. Computing the optimal strategy to commit to. In Proceedings

of the 7th ACM conference on Electronic commerce, pages 82–90. ACM, 2006.

[7] Vincent Conitzer and Tuomas Sandholm. New complexity results about Nash equilibria. Games and

Economic Behavior, 63(2):621–641, 2008.

[8] Constantinos Daskalakis, Paul W Goldberg, and Christos H Papadimitriou. The complexity of com-

puting a Nash equilibrium. SIAM Journal on Computing, 39(1):195–259, 2009.

[9] Fei Fang, Albert Xin Jiang, and Milind Tambe. Optimal patrol strategy for protecting moving targets
with multiple mobile resources. In Proceedings of the 2013 international conference on Autonomous
agents and multi-agent systems, pages 957–964. International Foundation for Autonomous Agents and
Multiagent Systems, 2013.

[10] Fei Fang, Thanh H. Nguyen, Rob Pickles, Wai Y. Lam, Gopalasamy R. Clements, Bo An, Amandeep
Singh, Milind Tambe, and Andrew Lemieux. Deploying PAWS: Field optimization of the protection
assistant for wildlife security. In Proceedings of the Twenty-Eighth Innovative Applications of Artiﬁcial
Intelligence Conference, 2016.

20

[11] Lance Fortnow, Russell Impagliazzo, Valentine Kabanets, and Christopher Umans. On the complexity

of succinct zero-sum games. computational complexity, 17(3):353–376, 2008.

[12] Robert J Fowler, Michael S Paterson, and Steven L Tanimoto. Optimal packing and covering in the

plane are NP-complete. Information processing letters, 12(3):133–137, 1981.

[13] Jiarui Gan, Bo An, and Yevgeniy Vorobeychik. Security games with protection externalities.

In

Twenty-Ninth AAAI Conference on Artiﬁcial Intelligence, 2015.

[14] Jugal Garg, Albert Xin Jiang, and Ruta Mehta. Bilinear games: Polynomial time algorithms for rank

based subclasses. In Internet and Network Economics, pages 399–407. Springer, 2011.

[15] Itzhak Gilboa and Eitan Zemel. Nash and correlated equilibria: Some complexity considerations.

Games and Economic Behavior, 1(1):80–93, 1989.

[16] Martin Gr¨otschel, L´aszl´o Lov´asz, and Alexander Schrijver. Geometric algorithms and combinatorial

optimization, volume 2. Springer Science & Business Media, 2012.

[17] Nicole Immorlica, Adam Tauman Kalai, Brendan Lucier, Ankur Moitra, Andrew Postlewaite, and
Moshe Tennenholtz. Dueling algorithms. In Proceedings of the forty-third annual ACM symposium
on Theory of computing, pages 215–224. ACM, 2011.

[18] Manish Jain and Erim Kardes. Security games with arbitrary schedules: A branch and price approach.

2010.

[19] Dmytro Korzhyk, Vincent Conitzer, and Ronald Parr. Complexity of computing optimal Stackelberg

strategies in security resource allocation games. 2010.

[20] Dmytro Korzhyk, Vincent Conitzer, and Ronald Parr. Security games with multiple attacker resources.

In IJCAI, 2011.

[21] Dmytro Korzhyk, Zhengyu Yin, Christopher Kiekintveld, Vincent Conitzer, and Milind Tambe. Stack-
elberg vs. Nash in security games: An extended investigation of interchangeability, equivalence, and
uniqueness. J. Artif. Int. Res., 41(2):297–327, May 2011.

[22] Van EJ Leeuwen et al. Optimization and approximation on systems of geometric objects. 2009.

[23] Joshua Letchford and Vincent Conitzer. Solving security games on graphs via marginal probabilities.

In Twenty-Seventh AAAI Conference on Artiﬁcial Intelligence, 2013.

[24] John A Major. Advanced techniques for modeling terrorism risk. The Journal of Risk Finance, 4(1):15–

24, 2002.

[25] Marios Mavronicolas, Loizos Michael, Vicky Papadopoulou, Anna Philippou, and Paul Spirakis. The
price of defense. In Mathematical Foundations of Computer Science 2006, pages 717–728. Springer,
2006.

[26] Marios Mavronicolas, Vicky Papadopoulou, Anna Philippou, and Paul Spirakis. A graph-theoretic

network security game. In Internet and Network Economics, pages 969–978. Springer, 2005.

[27] James Pita, Manish Jain, Janusz Marecki, Fernando Ord´o˜nez, Christopher Portway, Milind Tambe,
Craig Western, Praveen Paruchuri, and Sarit Kraus. Deployed ARMOR protection: the application of
a game theoretic model for security at the los angeles international airport. In Proceedings of the 7th
international joint conference on Autonomous agents and multiagent systems: industrial track, pages
125–132. International Foundation for Autonomous Agents and Multiagent Systems, 2008.

21

[28] Todd Sandler et al. Terrorism & game theory. Simulation & Gaming, 34(3):319–337, 2003.

[29] Todd Sandler et al. Counterterrorism a game-theoretic analysis.

Journal of conﬂict resolution,

49(2):183–200, 2005.

[30] Alexander Schrijver. Theory of linear and integer programming. John Wiley & Sons, 1998.

[31] Milind Tambe. Security and game theory: algorithms, deployed systems, lessons learned. Cambridge

University Press, 2011.

[32] Jason Tsai, Shyamsunder Rathi, Christopher Kiekintveld, Fernando Ordonez, and Milind Tambe. IRIS
- a tool for strategic security allocation in transportation networks. In The Eighth International Con-
ference on Autonomous Agents and Multiagent Systems - Industry Track, 2009.

[33] Jason Tsai, Zhengyu Yin, Jun-young Kwak, David Kempe, Christopher Kiekintveld, and Milind
Tambe. Urban security: Game-theoretic resource allocation in networked physical domains. In AAAI,
2010.

[34] Yevgeniy Vorobeychik and Satinder P Singh. Computing Stackelberg equilibria in discounted stochas-

tic games. In AAAI, 2012.

[35] Alan Washburn and Kevin Wood. Two-person zero-sum games for network interdiction. Operations

Research, 43(2):243–251, 1995.

[36] Haifeng Xu, Fei Fang, Albert Xin Jiang, Vincent Conitzer, Shaddin Dughmi, and Milind Tambe. Solv-
ing zero-sum security games in discretized spatio-temporal domains. In Proceedings of the 28th Con-
ference on Artiﬁcial Intelligence (AAAI 2014), Qubec, Canada, 2014.

[37] Rong Yang, Benjamin Ford, Milind Tambe, and Andrew Lemieux. Adaptive resource allocation for
wildlife protection against illegal poachers. In Proceedings of the 2014 international conference on Au-
tonomous agents and multi-agent systems, pages 453–460. International Foundation for Autonomous
Agents and Multiagent Systems, 2014.

[38] Zhengyu Yin, Albert Xin Jiang, Milind Tambe, Christopher Kiekintveld, Kevin Leyton-Brown, Tuo-
mas Sandholm, and John P Sullivan. TRUSTS: Scheduling randomized patrols for fare inspection in
transit systems using game theory. AI Magazine, 33(4):59, 2012.

22

