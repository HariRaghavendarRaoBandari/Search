Particle-based Gaussian process optimization for input design in

nonlinear dynamical models

Patricio E. Valenzuela, Johan Dahlin, Cristian R. Rojas and Thomas B. Sch¨on

6
1
0
2

 
r
a

 

M
7
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
5
4
4
5
0

.

3
0
6
1
:
v
i
X
r
a

Abstract— We propose a novel approach to input design for
identiﬁcation of nonlinear state space models. The optimal input
sequence is obtained by maximizing a scalar cost function of the
Fisher information matrix. Since the Fisher information matrix
is unavailable in closed form,
it is estimated using particle
methods. In addition, we make use of Gaussian process opti-
mization to ﬁnd the optimal input and to mitigate the problem
of a large computational cost incurred by the particle ﬁlter,
as the method reduces the number of functional evaluations.
Numerical examples are provided to illustrate the performance
of the resulting algorithm.

Index Terms— System identiﬁcation, input design, Gaussian

process optimization.

I. INTRODUCTION

Input design concerns the maximization of the information
retrieved from an experiment. Some of the ﬁrst contributions
in this area have been introduced in [1], [2]. Since then, sev-
eral approaches to experiment design have been developed
(see e.g. [3] and the references therein).

Recently, the problem of input design for the identiﬁcation
of nonlinear dynamical models has gained interest. One
of the main difﬁculties in this case is that a closed form
expression for the Fisher information matrix is typically not
be available. In addition, the frequency domain techniques
employed in the linear case [4] are no longer valid, which
implies that other formulations are required. Contributions
in this ﬁeld consider nonlinear FIR models [5], multilevel
excitation [6], [7], [8], and nonlinear state space models [9],
among others.

As the Fisher information matrix is unavailable in closed
form, we need to rely on estimates. However, such estimates
are always subject to uncertainty, which results in difﬁculties
when implementing traditional optimization methods.

In this work, we explore the reduction of the computational
complexity when calculating the objective function used
in input design for identiﬁcation of nonlinear dynamical
models. To this end, a Gaussian process optimization (GPO)
based algorithm is presented. By assuming that the scalar
function of the Fisher information matrix is a realization

This work was supported by the Swedish Research Council under

contracts 621-2013-5524 and 621-2009-4017.

Patricio E. Valenzuela and Cristian R. Rojas are with the Department
of Automatic Control and ACCESS Linnaeus Center, School of Electrical
Engineering, KTH Royal Institute of Technology, SE-100 44 Stockholm,
Sweden (e-mail: {pva,crro}@kth.se).

Johan Dahlin is with the Department of Electrical Engineer-
ing, Link¨oping University, SE-581 83 Link¨oping, Sweden (e-mail:
johan.dahlin@liu.se).

Thomas B. Sch¨on

and
Control, Uppsala University, SE-751 05 Uppsala, Sweden (e-mail:
thomas.schon@it.uu.se).

the Department

of Systems

is with

from a Gaussian process (GP), we can compute its predictive
posterior distribution given a set of samples over the feasible
set. The predictive posterior distribution acts as a surrogate
of the intractable objective function, and is employed to
compute the next sample over the feasible set by using
an acquisition rule. This technique recursively explores the
feasible set to determine the element maximizing a surrogate
function. The advantage of this approach when compared
with existing techniques is that it can handle uncertainty
in the estimates of the objective function, and it drives the
exploration of the input space towards those regions where
an improvement of the objective function is expected.

As with most approaches in experiment design, we rely on
prior information about the system for computing an optimal
design. This assumption can be overcome by implementing
an adaptive scheme [10], or by using a robust input design
scheme on top of it [11]. However, this is beyond the scope
of this paper.

II. PROBLEM FORMULATION

Consider the discrete time, nonlinear state space model

(SSM) deﬁned for all t ≥ 1 by

xt|xt−1 ∼ fθ(xt|xt−1, ut−1),

yt|xt ∼ gθ(yt|xt, ut),

x0 ∼ µθ(x0),

(1a)
(1b)
(1c)

where fθ, gθ, and µθ are known probability density functions
(pdf) parameterized by the unknown parameter θ ∈ Θ ⊂
Rnθ . Here, ut ∈ C ⊆ Rnu denotes the input signal, xt ∈ Rnx
are the (unobserved/latent) internal states, and yt ∈ Rny are
the measured outputs. In the following, we assume that there
exists a θ0 ∈ Θ such that the pdfs in (1) describe the true pdfs
of the system when θ = θ0, i.e., there is no undermodelling
[3].

The objective is to design u1:T := (u1, . . . , uT ) ∈ C T ,
such that the parameter θ in the model (1) can be identiﬁed
with maximum accuracy as deﬁned by a scalar function of
the Fisher information matrix I θ0

F [2], given by

(2)

(3)

(4)

F (u1:T ) := E(cid:8)S(θ0)S⊤(θ0)| u1:T(cid:9) ,
I θ0

with S(θ0) denoting the score function, i.e.,
.

S(θ0) := ∇ ℓθ(y1:T )|θ=θ0

Here, ℓθ(y1:T ) denotes the log-likelihood function

ℓθ(y1:T ) := log pθ(y1:T|u1:T ) .

We note that the expected value in (2) is with respect to the
stochastic processes in (1).

In the following, we consider u1:T as a realization of a
stationary process. Hence, we will be interested in the per-
sample Fisher information matrix, given by

I θ0,av

F

(u1:T ) :=

1
T

EunI θ0

F (u1:T )o .

(5)

The input u1:T optimizes a scalar function of (5). We
deﬁne this scalar function as h : Rm×m → R, assumed to
be a matrix nondecreasing function [12, p. 108].

The problem presented here can be summarized as
Problem 1: Find an input signal uopt
h(I θ0,av

1:T ∈ C T as
(u1:T )) ,

uopt
1:T := arg max
u1:T ∈CT

F

(6)

F

(cid:4)

(u1:T ) is given in (5).

where h : Rm×m → R is a matrix nondecreasing function,
and I θ0,av
III. GAUSSIAN PROCESS OPTIMIZATION IN INPUT DESIGN
Problem 1 is difﬁcult to solve. One of the main challenges
is the characterization of h(I θ0,av
(u1:T )) for all u1:T ∈ C T .
Unless assumptions on the model structure (1) and the
input properties are made, the expression h(I θ0,av
(u1:T ))
is often unavailable, and we need to rely on approximations.
Moreover, even if an estimate of h(I θ0,av
(u1:T )) is available,
part of the existing optimization methods are difﬁcult to
implement, since the uncertainty of the estimate is not taken
into account.

F

F

F

F

(u(k)

(ii) Given the collection of

1:T )), denoted bybhk.
tuples {u(j)

Instead, we employ the iterative procedure discussed in
[13] to solve Problem 1. The procedure generates a sequence
of iterates {u(k)
1:T}k≥0 for the input excitation. Each iteration
consists of three steps:
(i) Given u(k)
1:T , compute an estimate of the objective func-
tion h(I θ0,av
j=0, cre-
ate a model of the (unavailable) objective function
h(I θ0,av
generate a new iterate u(k+1)

1:T ,bhj}k
(iii) Use the model as a surrogate for h(I θ0,av
The procedure only requires one estimate of h(I θ0,av
(u1:T ))
at each iteration, hence keeping the number of estimates as
low as possible. Moreover, it requires fewer iterations than a
random search, since it focuses on regions of C T where an
improvement is expected.
For step (i), we employ particle methods to estimate

(u1:T )) to

(u1:T )).

1:T

F

F

F

.

(u(k)

1:T )). This is discussed in Section III-A.

h(I θ0,av
F
For steps (ii) and (iii) we use the GPO framework [14],
[15]. We ﬁrst compute a surrogate of the objective function
by modelling it as a Gaussian process, and computing the
predictive posterior distribution based on {u(j)
j=0.
This is discussed in Section III-B.
Then we make use of a heuristic, referred to as the
acquisition rule (presented in Section III-C), to compute
u(k+1)
based on the GP model. The acquisition rule favours
1:T
values of u1:T for which the model predicts a large value of
the objective function and/or where there is high uncertainty.

1:T ,bhj}k

This establishes a trade-off between exploration and exploita-
tion of the input set. Finally, to employ the GPO framework
in input design, we need tractable parameterizations of C T ,
which are discussed in Subsection III-D.

A. Estimating the Fisher information matrix

Given u(k)

1:T ∈ C T , we need to approximate (5). To this
end, we consider the estimator in [16], which is based on
one estimate of S(θ0) (provided a sufﬁciently large T ) to
approximate (5) by [17]

1

T bS(θ0)(bS(θ0))⊤# ,

(7)

:=

F

bI θ0,av

1

T " TXt=1 bSt(θ0)(bSt(θ0))⊤ −
TXt=1

St(θ′) ,

where the Fisher identity [18] can be used to write1

S(θ′) =
St(θ′) :=Z ∇ ξθ(xt−1:t)|θ=θ′pθ′(xt−1:t|y, u) dxt−1:t ,

(8)

with

ξθ(xt−1:t) := log fθ(xt|xt−1, ut−1) + log gθ(yt|xt, ut) ,
and xt−1:t := {xt−1, xt}. As we can see from (7), we require
an estimate for (8), which we obtain from particle methods
[19].

To estimate the score function in (8), we require the
two-step smoothing distribution pθ(xt−1:t|y, u), which is
not available analytically for a general SSM. Instead, we
approximate it using an empirical distribution

w(i)

t δx

NXi=1
bpθ(dxt−1:t|y, u) :=
where x(i)
denote particle i and its normalized
weight at time t. Here, {x(i)
t=1 denotes the particle
system generated by a particle ﬁlter and δx′ denotes the Dirac
measure located at x = x′.

(dxt−1:t),

and w(i)

t }T

, w(i)

(i)
t−1:t

(9)

t

t

t

Following [16], here we use the bootstrap particle ﬁlter
(bPF), see Algorithm 1 [21]. However, the estimator (9)
based only on the bPF often suffers from poor accuracy due
to particle degeneracy, see e.g. [19]. To mitigate this problem,
we use a particle smoother that
introduces a backward
sweep after the forward run of the bPF. Here, we use the
forward-ﬁltering backwards simulator (FFBSi) with rejection
sampling and early stopping [20].

Algorithm 2 presents the pseudo-code for the FFBSi.
i=1) and Uniform([a, b]) denote the multi-
Here, Multi({p(i)}N
nomial distribution over N elements, with p(i) being the
probability of choosing the i-th element, and the uniform
distribution with support [a, b], respectively. We note that
the parameter ρ required by Algorithm 2 is chosen such
that fθ(xt|xt−1, ut−1) ≤ ρ for all t ∈ {1, . . . , T}. The
computational complexity of FFBSi is of order O(N M T ),
1For conciseness, we write v := v1:T for any vector v1:T . In addition,

we remove the dependence on k of the input, state, and measurements.

Algorithm 1 Bootstrap particle ﬁlter (bPF)
INPUTS: An SSM (1), y (observations), u (inputs), N ∈ N (no.
particles).
OUTPUT: {x(i)

i=1, t = 1, . . . , T .

, w(i)

t }N

t

0 ∼ µθ(x0) and set w(i)

0 = 1/N.

1: Sample x(i)
2: for t = 1 to T do
3:
4:

for i, j = 1 to N do

t

(Resampling) Sample a(i)
from a multinomial distribu-
t = j(cid:17) = w(j)
tion with P(cid:16)a(i)
t−1.
t (cid:12)(cid:12)(cid:12)xa
t ∼ fθ(cid:16)x(i)
(Propagation) Sample x(i)
t o.
0:t−1, x(i)
t = gθ(cid:16)yt(cid:12)(cid:12)(cid:12)x(i)
(Weighting) Calculate ew(i)
Normalize ew(i)

(over i) to obtain w(i)

t−1, ut(cid:17).

0:t = nx

, ut(cid:17).

Set x(i)

t
.

(i)
t

(i)
t

a

t

t

5:

6:

7:

8:
9:
10: end for

end for

Algorithm 2 Fast forward-ﬁltering backward-simulator
with early stopping (fFFBSi-ES)
INPUTS: Inputs to Algorithm 1, M ∈ N (no. backward trajectories),
Nlimit ∈ N (limit for when to stop using rejection sampling), ρ > 0.

t oN
, w(i)

i=1

t

T

F

i=1(cid:1).

for t = 1, . . . , T .

(u) (estimate of the Fisher information matrix).

L ← 1, . . . , M.
{Rejection sampling until Nlimit trajectories remain.}
while |L| ≥ Nlimit do

j=1 ∼ Multi(cid:0){w(i)
T }N
for j = 1, . . . , M.

OUTPUT: bI θ0 ,av
1: Run Algorithm 1 to obtain the particle system nx(i)
2: Sample (cid:8)bT (j)(cid:9)M
T = xbT (j)
3: Set ˜x(j)
4: for t = T − 1 to 1 do
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:

i=1(cid:1).
n ← Multi(cid:0){1/|L|}|L|
Sample (cid:8)I(k)(cid:9)n
Sample (cid:8)U (k)(cid:9)n
if U (k) ≤ f(cid:0)˜xL(k)

i=1(cid:1).
k=1 ∼ Multi(cid:0){w(i)
t }N
k=1 ∼ Uniform([0, 1]).
(cid:1)/ρ then
t+1 |xI(k)

end while
{Use standard FFBSi for the remaining trajectories [20].}
for j ∈ L do

bt(L(k)) ← I(k).
δ ← δ ∪ {L(k)}.

end if
end for
L ← L \ δ.

for k = 1 to n do

δ ← ∅.

t|T ∝ w(i)

t|T (cid:9)N

t (cid:1) for i = 1, . . . , N.
t f(cid:0)˜x(j)
t+1|x(i)
Compute ˜w(i,j)
Normalize the smoothing weights (cid:8) ˜w(i,j)
i=1(cid:17).
Draw bt(j) ∼ Multi(cid:16)(cid:8) ˜w(i,j)
t|T (cid:9)N
t:T = nxbt(j)
bS (k)

t+1:To for j = 1, . . . , M.
, ˜x(j)
t:t+1(cid:17).

∇ξθ(cid:16)˜x(j)

MX

(θ) =

1
M

end for
Set ˜x(j)
Calculate

23:

24:
25:
26:
27:

i=1

.

t

t

t

28: end for

29: Compute bI θ0 ,av

F

j=1
(u1:T ) using (7).

where N and M denote the number of ﬁlter and smoother
particles, respectively. We refer to [20] for more details on

200

150

100

50

0

−2

0
ν

2

4

2

0

−2

ν

f
o

s
e
l
i
t
n
a
u
Q

−4
−4
Standard Normal Quantiles

−2

0

2

4

Fig. 1. Left: Histogram of ν and plot of the scaled pdf of an N (0, 12)
distribution (continuous line), Example 1. Right: Quantile-quantile plot of
the samples of ν and the N (0, 12) distribution, Example 1.

the effects of N , M and T in the accuracy of the estimator.

B. Modelling the objective function

F

We explore the use of a GP to model

the objective
function h(I θ0,av
(u1:T )) [22]. GPs can be understood as a
generalization of the multivariate Gaussian distribution and
are commonly used as priors over functions [23]. In this
perspective, the posterior obtained by conditioning on the
observations corresponds to the functions that could have
generated the observations.

In the following, we model the function h(I θ0,av
being a priori distributed according to a GP. That is

F

h(I θ0,av

F

(·)) ∼ GP (m(·), κ(·, ·)) ,

where the process is fully described by the mean function
m(·) and the covariance function κ(·, ·). Examples of these
functions are a constant for m and a Mat´ern s/2 function
for κ [22, p.84].

To simplify the discussion, we will focus on a speciﬁc
iteration k of the proposed procedure. Let Dk := {u(k)
denote a set of iterates, where u(k)
obtained by stacking input realizations and estimates of the
objective function up to iteration k, respectively. In addition,
we will assume that

1:T , bhk}
1:T andbhk denote matrices

(·)) as

(10)

(u(k)

1:T )) + z ,

(11)

F

bhk = h(I θ0,av

z ), and σz > 0. We note that σz is
where z ∼ N (0, σ2
unknown a priori, and it needs to be estimated using Dk. The
assumption (11) seems strict, but the continuous mapping
theorem [24, Theorem 2.7] shows that
limit
theorem also applies to the estimate bhk, as it is satisﬁed

by (4) asymptotically in the number of particles.

Example 1: Consider

the central

(12a)

xt+1|xt ∼ N(cid:16)φ xt + ut, 0.12(cid:17),
yt|xt ∼ N(cid:16)α xt, 0.12(cid:17),
where the parameters are θ = {φ, α}. We generate T = 103
observations from (12) with θ0 = {0.8, 1}.
(u1:T )) =
log det(I θ0,av
(u1:T )), where u1:T is a binary white noise
process with values {−1, 1}.
The estimate of the Fisher information matrix is obtained
using Algorithms 1-2, with N = 2.5·103 particles, M = 100

We are interested in estimating h(I θ0,av

(12b)

F

F

backward trajectories and Nlimit = √N in the fFFBSi
smoother. Figure 1 shows the histogram based on 103
realizations of the random variable

ν :=

,

(13)

√M (bh − h)

σ√M bh

F

are the sam-

(u1:T )), and h, σ2√M bh

where bh := h(bI θ0,av
ple mean of bh and variance of √Mbh, respectively. As a
comparison, we also present the scaled pdf of an N (0, 12)
distribution. We can see that the histogram follows the shape
of the pdf of a N (0, 12) distribution. This is also conﬁrmed
by the quantile-quantile (QQ) plot in Figure 1, where the
quantiles of ν coincides with those given by an N (0, 12)
distribution.
(cid:4)
Based on (11), it follows that the predictive posterior

F

distribution is
z(cid:1) ,
(u1:T ))|Dk ∼ N(cid:0)µ(u1:T|Dk), σ2(u1:T|Dk) + σ2
h(I θ0,av
(14)
where µ(u1:T|Dk) and σ2(u1:T|Dk) denote the posterior
mean and variance given Dk. From standard results for the
Gaussian distribution, we have

µ(u1:T|Dk) = m(u1:T )

+ κ(u1:T , u(k)

1:T )Γ−1nbhk − m(u1:T )o ,

(15a)

1:T )+σ2

1:T , u(k)

σ2(u1:T|Dk) = κ(u1:T , u1:T )
− κ(u1:T , u(k)

In the GP model

with Γ := κ(u(k)
identity matrix.

1:T )Γ−1κ(u(k)
1:T , u1:T ) , (15b)
z Ik, where Ik denotes the k×k-
introduced here, we use mean and
covariance functions that possibly depend on some unknown
hyperparameters. In addition, we also need to estimate σz
characterizing the random variable z in (11). To estimate
these quantities, we adopt the empirical Bayes procedure,
where the marginal likelihood of the data is numerically
optimized with respect to the hyperparameters [25].

C. Acquisition rules

To implement step (iii), we need to generate u(k+1)

1:T ∈ C T .
One option is to perform a random walk over C T , which
works well provided that the parameterization of u1:T is of
small dimension. However, this approach is inefﬁcient as the
dimension of the parameterization for u1:T increases.

Instead, we make use of acquisition rules that balance
exploration and exploitation of the parameter space and
employ the posterior distribution obtained from the GP. Here,
we use the expected improvement (EI) technique [26].

Consider the predicted improvement

I(u1:T ) := maxn0, h(I θ0,av

F

(u1:T )) − µmax − ξo ,

where ξ is a user deﬁned coefﬁcient balancing exploration
and exploitation, and

(16)

µmax := max
u1:T ∈u

(k)
1:T

µ(u1:T|Dk) ,

(17)

By using the posterior distribution obtained from the GP,

(u1:T )) at iteration k.

F

the expected peak of h(I θ0,av
we deﬁne the EI as2
E{I(u1:T )} = σ(u1:T ){Z(u1:T )Φ(Z(u1:T ))

−φ(Z(u1:T ))} ,
Z(u1:T ) := σ−1(u1:T ){µ(u1:T ) − µmax − ξ} ,

(18a)
(18b)

with Φ and φ denoting the cumulative distribution function
and the pdf of the standard Gaussian distribution, respec-
tively. Then, an acquisition rule is

u(k+1)
1:T = arg max
u1:T ∈CT

E{I(u1:T )|Dk } ,

(19)

i.e., the element maximizing the EI. From (18) we see that
the EI assigns a large value when both the variance σ(u1:T )
and the mean difference µ(u1:T ) − µmax are large, in line
with the desired behavior of an acquisition function, as it is
explained at the beginning of Section III.

D. Parameterizing the input

To implement

the GPO for solving the input design
problem, we need a parameterization of C T . Here we brieﬂy
explain two options:
1) Stationary Markov processes: If we restrict C to be
ﬁnite and u1:T to be a realization from an n-dimensional
stationary Markov process of a given order, then the parame-
terization employed in [8] can be used. The parameterization
of the input is given by the stationary distribution of the
Markov process, which is constrained to

PC :=(pu : C n → R(cid:12)(cid:12)(cid:12)(cid:12) pu(x) ≥ 0, ∀x ∈ C n;
pu(z, v) ,∀z ∈ C n−1) .

Xx∈Cn
pu(v, z) =Xv∈C

Xv∈C

pu(x) = 1;

Following [8], we parameterize (20) as the convex hull
of its extreme points, which are computed using graph
theoretical techniques. Therefore, the decision variable in
this case corresponds to the weighting vector of the extreme
points describing an element
in PC. Assuming that PC
has nV extreme points, then the weighting vector α :=
[α1

. . . αnV ]⊤ ∈ RnV is used to compute p ∈ PC as

p =

with α satisfying

αip(i) ,

nVXi=1

(20)

(21)

(22a)

(22b)

αi ≥ 0 , for all i ∈ {1 , . . . , nV} ,
αi = 1 .

nVXi=1

i=1 corresponds to the probability mass

In (21), {p(i)}nV
functions (pmf) that are the extreme points of PC.
2For simplicity, the dependence on Dk is dropped from the notation.

Algorithm 3 GPO for input design
INPUTS: Algorithm 2, K (no. iterations) and u(0)
excitation).
OUTPUT: {x(i)

i=1, t = 1, . . . , T .

, w(i)

t }N

t

1:T ∈ CT (initial

1: Sample u(0)
1:T ∈ CT .
2: for k = 0 to K do
3:
4:
5:
6:
7:

Use Algorithm 2 to compute bhk := h(bI θ0 ,av
Compute (14)-(15) to obtain h(I θ0 ,av
Compute (17) to obtain µmax.
Compute (19) to obtain ˜u(k+1)
Compute u(k+1)
at ˜u(k+1)

1:T

1:T

F

.

.

1:T

(u(k)
(u1:T ))|Dk.

F

1:T )).

8: end for
9: Compute the maximizer of µ(u1:T |DK ) to obtain uopt
1:T .

as a realization of a random walk centered

Once a new sample α ∈ RnV satisfying3 (22) is generated,
we compute the associated pmf p ∈ PC by (21), and we
generate u1:T by running a Markov chain with stationary
distribution p.

2) Stationary AR processes: We can restrict u1:T to be a
ﬁltered white noise process, as it is proposed in [27]. In this
case, the decision variables are the ﬁlter coefﬁcients, and the
properties of the white noise. For example, we can assume
that u1:T is a realization from a stationary AR process

A(q) ut = et ,

(23)

where {et} is Gaussian white noise, with variance σ2

e , and

A(q) :=

ai q−i ,

(24)

naXi=0

with na > 0 given, ai ∈ R for all i ∈ {1, . . . , na}, and
a0 = 1. For this example, the decision variables are σe > 0,
and {ai}na
i=1, such that A(q) has all its zeros strictly inside
the complex unit disc4.

E. The ﬁnal procedure

Algorithm 3 presents the resulting procedure for input
design using Gaussian process optimization. We note that
line 7 introduces a random walk centered at (19) to promote
exploration around the expected improvement. We also note
that only one functional evaluation is required per iteration,
reducing the computational effort when optimizing over C T .

IV. NUMERICAL EXAMPLES

F

Example 2: Consider

the linear Gaussian state space
model
in Example 1. We are interested in maximizing
h(I θ0,av
(u1:T )) = log det(I θ0,av
(u1:T )), where u1:T (T =
103) is a realization of a stationary Markov process (see
Section III-D), with nm = 1 and C = {−1, 1}.
For Algorithm 3, we use K = 500, ξ = 0.01, and a
random walk centered around the current parametrization

F

3This can be achieved by sampling α satisfying (22a), and then normal-

izing the entries of α to satisfy (22b).

4This can be guaranteed by factorizing A(q) into ﬁrst and second order

polynomials in q, and imposing the constraint on each of these factors.

1:T

of ˜u(k+1)
, uniformly distributed on [−0.01, 0.01]. The es-
timate of the Fisher information matrix is obtained using
Algorithms 1-2, which are implemented as in Example 1.
For the prior distribution of h(I θ0,av
(u1:T )), we consider a
constant mean function, and a covariance function composed
of a Mat´ern s/2 structure and a constant. The Mat´ern s/2
structure is chosen in this example as it contains information
about the smoothness of h(I θ0,av
(u1:T )). Other choices for
the covariance function are also possible and we refer to [22,
Chapter 4] for more details.

F

F

F

(u1:T )).

Algorithm 3 is

implemented in Matlab using the
fmincon command for (19) and the GPML toolbox [28]
to infer the hyperparameters and estimate the predictive
posterior distribution of h(I θ0,av
The solution obtained from Algorithm 3 is ut = 1 for all
t ≥ 0. In this example, a nonzero constant input introduces a
nonzero offset in the measurements, which helps to estimate
θ in the presence of process disturbance and measurement
noise. As a reference, we draw u1:T as a realization from a
binary white noise process with values {−1, 1}. The results
are h(I θ0,av
input and
F
h(I θ0,av
(u1:T )) = 10.18 for the binary white noise process.
(cid:4)

1:T )) = 14.57 for the optimal

(uopt

F

Example 3: Consider the system

1

xt+1|xt ∼ N(cid:16)
yt|xt ∼ N(cid:16)βx2

t , 12(cid:17),

γ + x2
t

+ ut, 0.12(cid:17),

(25a)

(25b)

where the parameters are θ = {γ, β}. We generate T = 103
observations from the model with θ0 = {2, 0.8}. We note
that estimating γ in (25) is inherently difﬁcult, since two
different values of xt can explain yt equally well.

We consider the same setting and function h as in Exam-

ple 2, but we consider three cases for C:

• Case 1: C = {−1, 1}.
• Case 2: C = {−1, 0, 1}.
• Case 3: C = {−1,−1/3, 1/3, 1}.
Table I presents the value of hopt

F

F

(uopt

:= h(bI θ0,av

1:T ))
for each case, where uopt
1:T corresponds to the optimal input
obtained from Algorithm 3. As comparison, we also compute
the value of h(bI θ0,av
(u1:T )), with {ut} binary distributed
white noise with values {−1, 1} (Binary in Table I). We
see that the binary white noise process seems to be optimal
when C = {−1, 1}, as it is conﬁrmed by the value of hopt
for Case 1. We also note that adding intermediate values to
the input alphabet increases the amount of information in the
data, as hopt is greater in Cases 2 and 3 than in Case 1.

1

0

t

u

−1
0

20

40

t

60

80

100

Fig. 2. Optimal input uopt

1:T for Case 3 in Example 3.

)
)
T

:
1
u
(

F

v
a
,
0
θ
bI
(
h

5

4

3

2

1

 

0
0

 

20

40
60
Iteration k

µmax
bhk

80

100

Fig. 3. Value of bhk and µmax at iteration k for Case 3 in Example 3.

hopt FOR DIFFERENT INPUT REALIZATIONS, EXAMPLE 3.

TABLE I

Input
hopt

Binary
4.11

opt. Case 1

opt. Case 2

opt. Case 3

4.11

4.15

4.44

Figure 2 presents the optimal input obtained for Case 3.
We note that the optimal input includes a nonzero offset to
improve the accuracy of the parameter estimates.

To illustrate the evolution ofbhk, we present in Figure 3 the
samples {bhk}100
k=1, together with the value of µmax at every
iteration. The ﬁrst 20 samples are drawn at random from
C T to provide an initial estimate of the hyperparameters in
the GP prior. We note that some of the samples in {bhk}20
k=1
are not close to the optimal cost, which is expected due to
random sampling. However, once Algorithm 3 is executed
from iteration 21 onwards, we observe that the samples are
close to µmax, which implies that the space C T is explored
only in those regions where h can only increase with respect
to the current estimates. Hence,
the proposed technique
drives the parameter search towards those regions where an
improvement in the objective function is expected.
(cid:4)

V. CONCLUSIONS

A Gaussian process optimization algorithm for input de-
sign for the identiﬁcation of nonlinear dynamical models
has been introduced. The method maximizes a scalar cost
function of the Fisher information matrix over the parameter
set for the input sequence. Since the objective function is
unavailable in closed form, a Gaussian process approach is
employed to compute a surrogate function. Numerical exam-
ples show that the algorithm can provide a good alternative
to solve the input design problem.

Future work on this subject will consider a better estima-
tor of the Fisher information matrix with a better particle
smoother, and alternative parameterizations of {ut}.

REFERENCES

[1] D.R. Cox, Planning of experiments, New York: Wiley, 1958.
[2] G.C. Goodwin and R.L. Payne, Dynamic System Identiﬁcation:
Experiment Design and Data Analysis, Academic Press, New York,
1977.

[3] L. Ljung, System Identiﬁcation. Theory for the User, 2nd ed., Upper

Saddle River, NJ: Prentice-Hall, 1999.

[4] H. Jansson and H. Hjalmarsson, “Input design via LMIs admitting
frequency-wise model speciﬁcations in conﬁdence regions,”
IEEE
Transactions on Automatic Control, vol. 50, no. 10, pp. 1534–1549,
2005.

[5] C. Larsson, H. Hjalmarsson, and C.R. Rojas, “On optimal input design
for nonlinear FIR-type systems,” in Proceedings of the 49th IEEE
Conference on Decision and Control, Atlanta, USA, December 2010,
pp. 7220–7225.

[6] M. Forgione, X. Bombois, P.M.J. Van den Hof, and H. Hjalmarsson,
“Experiment design for parameter estimation in nonlinear systems
based on multilevel excitation,” in Proceedings of the 13th European
Control Conference, Strasbourg, France, June 2014.

[7] A. De Cock, M. Gevers, and J. Schoukens, “A preliminary study on
optimal input design for nonlinear systems,” in Proceedings of the
IEEE Conference on Decision and Control, Florence, Italy, December
2013, pp. 4931–4936.

[8] P.E. Valenzuela, C.R. Rojas, and H. Hjalmarsson, “A graph theoretical
approach to input design for identiﬁcation of nonlinear dynamical
models,” Automatica, vol. 51, pp. 233–242, 2015.

[9] P.E. Valenzuela, J. Dahlin, C.R. Rojas, and T.B. Sch¨on,

“A
graph/particle-based method for experiment design in nonlinear sys-
tems,” in Proceedings of the 19th IFAC World Congress, Cape Town,
South Africa, August 2014.

[10] L. Gerencs´er, H. Hjalmarsson, and J. M˚artensson, “Identiﬁcation of
ARX systems with non−stationary inputs−asymptotic analysis with
application to adaptive input design,” Automatica, vol. 45, no. 3, pp.
623–633, 2009.

[11] C.R. Rojas, J.S. Welsh, G.C. Goodwin, and A. Feuer, “Robust optimal
experiment design for system identiﬁcation,” Automatica, vol. 43, no.
6, pp. 993–1008, June 2007.

[12] S. Boyd and L. Vandenberghe, Convex Optimization, Cambridge

University Press, 2004.

[13] J. Dahlin and F. Lindsten,

optimisation for parameter inference,”
IFAC World Congress, Cape Town, South Africa, August 2014.

“Particle ﬁlter-based Gaussian process
in Proceedings of the 19th

[14] B. Shahriari, K. Swersky, Z. Wang, R.P. Adams, and N. de Freitas,
“Taking the human out of the loop: A review of Bayesian optimiza-
tion,” Proceedings of the IEEE, vol. 104, no. 1, pp. 148–175, 2016.
[15] M.A. Osborne, R. Garnett, and S.J. Roberts, “Gaussian processes for
global optimization,” in 3rd International Conference on Learning
and Intelligent Optimization, 2009, pp. 1–15.

[16] P.E. Valenzuela, J. Dahlin, C.R. Rojas, and T.B. Sch¨on, “On robust
input design for nonlinear dynamical models,” Automatica, 2016,
(Provisionally accepted).

[17] M. Segal and E. Weinstein, “A new method for evaluating the log-
likelihood gradient, the Hessian, and the Fisher information matrix for
linear dynamic systems,” IEEE Transactions on Information Theory,
vol. 35, no. 3, pp. 682–687, 1989.

[18] O. Capp´e, E. Moulines, and T. Ryd´en, Inference in Hidden Markov

Models, Springer, 2005.

[19] F. Lindsten and T.B. Sch¨on,

“Backward simulation methods for
Monte Carlo statistical inference,” Foundations and Trends in Machine
Learning, vol. 6, no. 1, pp. 1–143, 2013.

[21] A. Doucet and A. Johansen,

[20] R. Douc, A. Garivier, E. Moulines, and J. Olsson, “Sequential Monte
Carlo smoothing for general state space hidden Markov models,”
Annals of Applied Probability, vol. 21, no. 6, pp. 2109–2145, 2011.
“A tutorial on particle ﬁltering and
smoothing: Fifteen years later,” in The Oxford Handbook of Nonlinear
Filtering, D. Crisan and B. Rozovsky, Eds. Oxford University Press,
2011.

[22] C.E. Rasmussen and C.K.I. Williams, Gaussian processes for Machine

Learning, MIT press, 2006.

[23] P. Boyle, Gaussian processes for regression and optimisation, Ph.D.
thesis, Victoria University Wellington, Wellington, New Zealand,
2007.

[24] P. Billingsley, Convergence of probability measures, 2nd ed., John

Wiley & Sons, 1999.

[25] B.P. Carlin and T.A. Louis, Bayes and empirical Bayes methods for

data analysis, London: Chapman and Hall, 1996.

[26] D.R. Jones, “A taxonomy of global optimization methods based on
response surfaces,” Journal of Global Optimization, vol. 21, no. 4,
pp. 345–383, 2001.

[27] R.B. Gopaluni, T.B. Sch¨on, and A.G. Wills,

“Input design for
nonlinear stochastic dynamic systems - A particle ﬁlter approach,” in
Proceedings of the 18th IFAC World Congress, Milano, Italy, August
2011.

[28] C.E. Rasmussen and H. Nickish, Gaussian process regression and

classiﬁcation toolbox, version 3.6, July 2015.

