6
1
0
2

 
r
a

 

M
1
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
3
8
6
3
0

.

3
0
6
1
:
v
i
X
r
a

Submitted to Mathematics of Operations Research
manuscript MOR-2015-241

Nonzero-sum Risk-sensitive Stochastic Games on a

Countable State Space

Arnab Basu

Quantitative Methods and Information Systems Area, Indian Institute of Management Bangalore, Bangalore- 560076, India,

arnab.basu@iimb.ernet.in, http://www.iimb.ernet.in/user/112/basu-arnab

Department of Mathematics, Indian Institute of Science, Bangalore - 560012, India, mkg@math.iisc.ernet.in,

http://math.iisc.ernet.in/ mkg

Mrinal K. Ghosh

The inﬁnite horizon risk-sensitive discounted-cost and ergodic-cost nonzero-sum stochastic games for con-

trolled Markov chains with countably many states are analyzed. For the discounted-cost game, we prove

the existence of Nash equilibrium strategies in the class of Markov strategies under fairly general condi-

tions. Under an additional geometric ergodicity condition and a small cost criterion, the existence of Nash

equilibrium strategies in the class of stationary Markov strategies is proved for the ergodic-cost game.

Key words : Noncooperative Stochastic Games; Risk-sensitive payoﬀ; Bellman equations; Nash equilibria

MSC2000 subject classiﬁcation : Primary: 91A15, 91A25; secondary: 91A10, 91A50

OR/MS subject classiﬁcation : Games/group decisions: Noncooperative, Stochastic; Probability: Stochastic

model applications

History : Submitted September 16, 2015

1. Introduction We study risk-sensitive nonzero-sum stochastic games on the inﬁnite time

horizon on a countable state space. Risk-sensitive cost criterion plays an important role in many

applications including mathematical ﬁnance (see, e.g., Bilelecki and Pliska [8], Nagai [32]). In this

criterion one investigates ‘exponential of integral’ cost which takes into account the attitude of

the controller with respect to risk. The study of this kind of cost criteria was ﬁrst initiated by

Bellman [6], p. 329 for the ﬁnite-state space case. Howard and Matheson [26] did an in-depth

analysis for the ﬁrst time in the ﬁnite-state space case where each controlled chain is irreducible

and aperiodic. Rothblum [33] extended it to the general non-irreducible ﬁnite-state space case.

In the past two decades, there has been a renewed interest in this type of cost criteria as, when

the ‘risk factor’ is strictly positive, i.e., in the risk-averse case, the use of the exponential reduces

the possibility of rare but devastating large excursions of the state process. Though this criterion

has been studied extensively in the literature of Markov decision processes (see, e.g., Borkar and

Meyn [13], Cavazos-Cadena and Fernandez-Gaucherand [14], Di Masi and Stettner [15, 16, 17],

Fleming and Hern´andez-Hern´andez [21], Fleming and McEneaney [22], Hern´andez-Hern´andez and

1

2

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Marcus [24], Whittle [35, 36]), the corresponding results on stochastic games seem to be limited

(see e.g., Basar [3], El-Karoui and Hamadene [18], Jacobson [27], James et. al. [28], and, Klomp-

stra [30]). The general Linear-Exponential-Gaussian (LEG) control problem for discrete time with

perfect state observation is treated in Jacobson [27] where an equivalence of this with determin-

istic zero-sum quadratic-cost games was shown. Whereas this paper addresses the undiscounted

case, the corresponding discounted case was addressed by Hansen and Sargent [23]. This was fur-

ther extended to studying the Nash equilibrium for a two-person discrete-time nonzero-sum game

with quadratic-exponential cost criteria in Klompstra [30], the analogue of the Linear-Exponential-

Quadratic-Gaussian (LEQG) control problem studied in Whittle [34, 35]. The papers of Basar [3]

and El-Karoui et. al. [18] deal with stochastic diﬀerential games on the ﬁnite time horizon. In James

et. al. [28], the ﬁnite-horizon risk-sensitive stochastic optimal control problem for discrete-time

nonlinear systems was studied and its relation to a deterministic partially observed dynamic game

was established. To the best of our knowledge, the general case of inﬁnite-horizon risk-sensitive

stochastic zero-sum games for both discounted as well as ergodic cost criteria was ﬁrst addressed by

the current authors for the diﬀerential games setup in Basu and Ghosh [4] and for the discrete-time

countable state space case in Basu and Ghosh [5]. The case of nonzero-sum games in such setups

still remains open. In this work, we address this novel problem and analyze the generic nonzero-

sum case for the discrete-time countable state space setup using totally diﬀerent mathematical

techniques for its solution as compared to the corresponding zero-sum case. We study this problem

with two players as the analysis can be routinely extended to three or more player case without

introducing any technical novelty but at the cost of further notational complication.

We use the results of Balaji and Meyn [2] to extend the work of Borkar and Meyn [13] from

one-controller case to two-controller case in a fully competitive setup. In other words we study

nonzero-sum risk-sensitive stochastic games on the inﬁnite planning horizon with both discounted

and ergodic cost criteria. We would like to elucidate that both Balaji and Meyn [2] as well as Borkar

and Meyn [13] have obtained the desired results under a “norm-like” or “near-monotone” condition

on the running cost and a Lyapunov-type stability condition. This “norm-like” condition has been

crucially used in the proofs therein as to ensure that the ‘relative value functions’ are bounded from

below. However, for our case, we have performed the analysis without this “norm-like” condition

on the running cost since it would not be suitable for our purpose as it would invariably favour one

of the competing players. This change makes our analysis totally novel and substantially diﬀerent

from those in the existing literature. Also, in most of the existing literature in this domain see, e.g.,

Balaji and Meyn [2], Borkar and Meyn [13], Cavazos-Cadena and Fernandez-Gaucherand [14], Di

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

3

Masi and Stettner [16], and, Hern´andez-Hern´andez and Marcus [24], the ‘risk factor’ is assumed to

be suﬃciently small. We make an assumption, for the ergodic game only, on the smallness of the

cost function as in Basu and Ghosh [4] which essentially implies that the ‘risk factor’ cannot be

too large.

Under certain assumptions, we have established the existence of Nash equilibria for both crite-

ria. We obtain our results by studying the corresponding Bellman equations. Note that if player

I announces that he is using a stationary/Markov strategy then for player II the game problem

reduces to a Markov decision problem (MDP). Then by the results of Borkar and Meyn [13], Di

Masi and Stettner [15] and Hern´andez-Hern´andez and Marcus [24], player II has optimal station-

ary/Markov strategies. Such a strategy of player II is called an ‘optimal response’ of player II

corresponding to the announced strategy of player I. Optimal responses of player I to the announced

strategies of player II are obtained analogously. Thus, for a given pair of strategies of the two play-

ers, there exists a set of optimal responses. This deﬁnes a point-to-set map. Any ﬁxed point of this

map is clearly a Nash equilibrium. In this paper, we establish the existence of such a ﬁxed point

thereby establishing the existence of Nash equilibria for relevant cases. For the sake of notational

simplicity, we consider two-player games only. All our results extends to multi-player games in a

routine manner.

The rest of our paper is structured as follows. Section 2 deals with the description of the problem.

The discounted cost criterion is studied in Section 3. Section 4 deals with the ergodic cost criterion.

We conclude our paper in Section 5 with a summary and possible future directions of work.

2. Problem Description A two-person stochastic game is determined by six objects

(X, U, V, r1, r2, q) where X

def
= {0, 1, 2, . . .} is a countable state space; U and V are action spaces

of players I and II, resp., assumed to be compact metric spaces; r1(resp. r2) : X × U × V 7→ R is

the one-stage cost function for player I (resp. II) assumed to be bounded and jointly continuous

in (u, v) ∈ U × V for each k ∈ X. Let P(X) be the space of probability measures on X endowed

with the Prohorov topology (see, e.g., Borkar [12]). Let q : X × U × V 7→ P(X) be the transition

stochastic kernel which is assumed to be jointly continuous in (u, v) ∈ U × V in the topology of

weak convergence for each k ∈ X. The game is played is as follows: At each stage (time instant)

players observe the current state k ∈ X of the system and then players I and II independently

choose actions u ∈ U , v ∈ V , resp. As a result of this, two things happen:

(i) the player I (resp. II) pays an immediate cost r1(k, u, v)(resp. r2(k, u, v)),

(ii) the system moves to a new state k′ ∈ X with distribution q(·|k, u, v).

4

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

The whole process then repeats from the new state k′. Cost accumulates throughout the course

of the game. The planning horizon or total number of stages is inﬁnite, and each player wants to

minimize his inﬁnite-horizon multiplicative expected cost to be described shortly. At each stage

the players choose their actions independently on the basis of past information. The available

information for decision making at time t ∈ N0

def
= {0, 1, 2 . . .} is given by the history of the process

up to that time

ht

def
= (k0, (u0, v0), k1, (u1, v1), . . . , (ut−1, vt−1), kt) ∈ Ht,

where H0 = X, Ht = Ht−1 × (U × V × X), . . . , H∞ = (U × V × X)∞ are the history spaces. A

strategy for player I is a sequence µ

def
= {µt : Ht 7→ P(U )}t∈N of stochastic kernels. The set of all such

strategies for player I is denoted by Π1. Given any t, T ∈ N0 with T ≥ t + 1, the set of strategies
{µs : Hs 7→ P(U )}t≤s≤T played from time t to time T is denoted by Πt,T

1 . Hence, Π0,∞

1 ≡ Π1.

Definition 1. A strategy µ for player I is called a Markov strategy if

µt(ht−1, u, v, k)(·) = µt(h′

t−1, u′, v′, k)(·)

for all ht−1, h′

t−1 ∈ Ht−1, u, u′ ∈ U , v, v′ ∈ V , k ∈ X, t ∈ N0. Thus a Markov strategy for player I can

be identiﬁed with a sequence of measurable maps, denoted by µ ≡ {µt : X 7→ P(U )}t∈N. A Markov

strategy {µt} is called stationary Markov if µt = µ : X 7→ P(U ) for all t. A stationary Markov

strategy is called pure or deterministic if µ : X 7→ U .

Let M1, S1, D1 denote the set of Markov, stationary Markov and deterministic strategies strate-

gies for player I. The strategy sets Π2, Πt,T

2 , M2, S2, D2 for player II are deﬁned analogously. The

spaces Mi, Si, i = 1, 2 are endowed with the product topologies derived from the Prohorov topology

on the underlying spaces P(U ) (resp. P(V )) respectively. Since U, V are compact metric spaces, it

follows that Mi, Si, i = 1, 2 are also compact metric spaces. Note that going forward we sometimes

use barbarism of notation and denote a stationary strategy {µ, µ, . . .} as {µ} or only µ when the

context is clear.

Given an initial distribution π0 ∈ P(X) and a pair of strategies (µ, ν) ∈ Π1 ×Π2, the corresponding

state and action processes {Xt}, {Ut}, {Vt} are stochastic processes deﬁned on the canonical space

(H∞, B(H∞), P µ,ν

ut, Vt(h∞) = vt, where P µ,ν
π0

π0 ) (B(H∞) = Borel σ-ﬁeld on H∞) via the projections Xt(h∞) = kt, Ut(h∞) =
is uniquely determined by µ, ν and π0 by Ionescu Tulcea’s Theorem

(see, e.g., Proposition 7.28 of Bertsekas and Shreve [10]). When π0 = δk, k ∈ X, we simply write

P µ,ν

.

k
Let (µ, ν) ∈ Π1 × Π2 and let (X (t)

s , U (t)

s , V (t)

s

: s ≥ t) be the corresponding process starting from

X (t)

t = k ∈ X for given t ≥ 0. We omit the superscript when t = 0 for notational convenience.

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

5

Definition 2. The risk-sensitive discounted cost for player I (i = 1) and II (i = 2) is deﬁned

by

ρµ,ν
i

(θ, (k, t)) =

1
θ

(1)

s=t αs−tri(X

(t)
s ,U

(t)
(t)
s ,V
s

ln Eµ,ν

k,t heθP∞

)i ,

where θ ∈ (0, Θ], Θ > 0 is the ‘risk-sensitive’ parameter, α ∈ [0, 1] is the ‘discount factor’ and Eµ,ν
k,t

denotes the expectation with respect to P µ,ν

k,t . When t = 0, we omit this subscript ‘t’ for notational

convenience. The corresponding risk-sensitive ergodic cost for player i, i = 1, 2 is deﬁned by

β µ,ν
i

(θ, k) = lim supT →∞

1
θT

ln Eµ,ν

k heθPT −1

t=0 ri(Xt,Ut,Vs)i .

(2)

Definition 3. Given a (θ, k) ∈ (0, Θ] × X, a pair of strategies (µ∗, ν ∗) ∈ Π1 × Π2 is called a

Nash equilibrium (for the cost criteria above) if

Lµ∗,ν ∗

1

(θ, k) ≤ Lµ,ν ∗

1

(θ, k), µ ∈ Π1,

and
Lµ∗,ν ∗

2

(θ, k) ≤ Lµ∗,ν

2

(θ, k), ν ∈ Π2,

(3)

where for i = 1, 2, Li = ρi or Li = βi as the case may be.

For a given θ ∈ (0, Θ], a pair (µ∗(θ, ·), ν ∗(θ, ·)) of stationary/Markov strategies (depending on θ)

is said to be Nash equilibrium strategies if these measurable maps constitute a Nash equilibrium

for any initial k ∈ X.

We shall ﬁrst establish the existence of Nash equilibria in the class of Markov strategies for

cost criterion (1). Under additional ergodicity and smallness of cost conditions, we establish the

existence of Nash equilibria in the class of stationary Markov strategies for cost criterion (2).

Given a topological space Y , we denote by B(Y ) and Cb(Y ) the Banach spaces of bounded

measurable and bounded continuous functions on Y respectively, each equipped with the sup-norm

metric.

The following result established in Section II.3, Chapter II (pp. 25-30) of Borkar [11] plays a cru-

cial role in Sections 3 and 4. Given any set of stochastic process {Y (1)
driven by (µ, ν) ∈ Π1 × Π2 we denote their joint law by Lµ,ν{(Y (1)

t }, {Y (2)
, Y (2)

t

t

, . . .), t ≥ 0}.

t }, . . . on (H∞, B(H∞))

Proposition 1. For a ﬁxed initial distribution π0 ∈ P(X), and given (µ, ν) ∈ M1 × M2, the

map

M1 × M2 ∋ (µ, ν) 7→ Lµ,ν{(Xt, Ut, Vt), t ≥ 0}

is jointly continuous in (µ, ν), where {Xt, t ≥ 0} denotes the state process with initial law π0 and

{Ut, t ≥ 0}, {Vt, t ≥ 0} are the corresponding control processes.

6

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

3. Discounted Game In this section, we study the cost criterion (1). To this end, we ﬁrst

consider the risk-sensitive exponential cost criterion for player I (i = 1) and II (i = 2) given by:

ζ µ,ν
i

(θ, (k, t))

def

= eθρµ,ν

i

(θ,(k,t)) = Eµ,ν

s=t αs−tri(X

(t)
s ,U

(t)
(t)
s ,V
s

k,t heθP∞

)i ,

(4)

where {X (t)

s

: s ≥ t} is the state process and {(U (t)

s , V (t)

s ) : s ≥ t} are the control processes under

(µ, ν) ∈ Πt,∞

1 × Πt,∞

2

starting from k ∈ X.

Given strategies (µ, ν) ∈ Πt,∞

1 × Πt,∞

2

, consider the following Bellman equations for the exponen-

tial cost (4) for players I and II (resp.):

φ1(θ, (k, t)) = inf

ξ∈P(U)"ZUZV

eθr1(k,u,v) Xj∈X

φ1(θα, (j, t + 1))q(j|k, u, v)! ξ(du)νt[ht](dv)# ,

with

and

lim
θ→0

φ1(θ, (k, t)) = 1, ∀k ∈ X, ∀t,

(5)

(6)

φ2(θ, (k, t)) = inf

χ∈P(V )"ZUZV

eθr2(k,u,v) Xj∈X

with a boundary condition analogous to (6).

φ2(θα, (j, t + 1))q(j|k, u, v)! µt[ht](du)χ(dv))# ,

(7)

Note that under (µ, ν) ∈ Πt,∞

1 × Πt,∞

2

, the corresponding chain {Xt} is inhomogeneous. Hence,

we consider the transformed chain { ˜Xt} on X × N0 with the transition kernel ˜q deﬁned by

˜q((k, t′)|(j, t), u, v) = ˆq(k|j, u, v)δt′,t+1, u ∈ U, v ∈ V,

(8)

where δs′,s = 1 if s′ = s and 0 otherwise. Now, replacing q by ˜q and using the arguments used in

the proof of Proposition 3.1 of Di Masi and Stettner [15], we get the following result. We omit the

routine details.

Proposition 2. Given (µ, ν) ∈ Πt,∞

1 × Πt,∞

2

, there exist unique bounded solutions ˆφ1[ν], ˆφ2[µ]

to (5) and (7) (resp.) satisfying the boundary condition (6) such that

ˆφ1[ν](θ, (k, t)) = inf

˜µ∈Πt,∞

1

and

ˆφ2[µ](θ, (k, t)) = inf

˜ν∈Πt,∞

2

ζ ˜µ,ν
1

(θ, (k, t)),

ζ µ,˜ν
2

(θ, (k, t)).

(9)

(10)

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Moreover, by Remark 3.2 of Di Masi and Stettner [15], given (µ, ν) ∈ Πt,∞

1 × Πt,∞

2

the minimizing strategies {µ∗

t [ν]}, {ν ∗

t [µ]} in (9) and (10) (resp.) are given by

and

µ∗
t [ν] = ˆµ[ν](θαt, (Xt, t)) ∈ M1

ν ∗
t [µ] = ˆν[µ](θαt, (Xt, t)) ∈ M2

7

and θ ∈ (0, Θ],

(11)

(12)

where (ˆµ[ν], ˆν[µ]) : (0, Θ] × (X × N0) 7→ P(U ) × P(V ) are measurable (minimizing) selectors (see

Beneˇs [9]) such that

inf

ξ∈P(U)"ZUZV
eθr1(k,u,v) Xj∈X

=ZUZV

ˆφ1[ν](θα, (j, t + 1))q(j|k, u, v)! ξ(du)νt[ht](dv)#
eθr1(k,u,v) Xj∈X
ˆφ1[ν](θα, (j, t + 1))q(j|k, u, v)! ˆµ[ν](θ, (k, t))(du)νt[ht](dv),

and

inf

χ∈P(V )"ZUZV
eθr2(k,u,v) Xj∈X

=ZUZV

eθr2(k,u,v) Xj∈X

ˆφ2[µ](θα, (j, t + 1))q(j|k, u, v)! µt[ht](du)χ(dv)#
ˆφ2[µ](θα, (j, t + 1))q(j|k, u, v)! µt[ht](du)ˆν[µ](θ, (k, t))(dv).

(13)

(14)

Thus, µ∗

t [ν] ∈ M1 (resp. ν ∗

t [µ] ∈ M2) is an optimal response of player I (resp. player II) corre-

sponding to ν ∈ Πt,∞

2

(resp. µ ∈ Πt,∞

1

). Hence, without loss of generality, we can eﬀectively consider

the strategy pair (µ, ν) ∈ M1 × M2 for further analysis of this game.

Considering the minimizing selectors (ˆµ[ν], ˆν[µ]) in (13) and (14) (resp.), we now deﬁne the

following point-to-set maps Hi : Mj 7→ 2Mi, i, j = 1, 2, i 6= j as follows:

and

H1(ν)

H2(µ)

def
= {{µ∗

t [ν]} : µ∗

t [ν] satisﬁes (11)},

def
= {{ν ∗

t [µ]} : ν ∗

t [µ] satisﬁes (12)}.

Deﬁne the map H ≡ H1 ⊗ H2 : M1 × M2 7→ 2M1×M2 as

H(µ, ν)

def
= {({µ∗

t [ν]}, {ν ∗

t [µ]}) : µ∗

t [ν] satisﬁes (11) and ν ∗

t [µ] satisﬁes (12)}.

(15)

(16)

(17)

We now prove the existence of Nash equilibria in the class of Markov strategies for the exponential

cost criterion (4).

8

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Theorem 1. Given θ ∈ (0, Θ], there exists a pair of Nash equilibrium strategy in M1 × M2 for

the game corresponding to the cost criterion (4).

Proof: Given θ ∈ (0, Θ], (µ, ν) ∈ M1 × M2, both H1(ν) and H2(µ) are non-empty and convex

implying H(µ, ν) is also non-empty and convex. Let {({µ∗

t,k[ν]}t, {ν ∗

t,k[µ]}t)}k∈N be a sequence of

distinct points of H(µ, ν) converging to ({µt,∞[ν]}t, {νt,∞[µ]}t), i.e., ({µt,∞[ν]}t, {νt,∞[µ]}t) is a limit

point of H(µ, ν). Since, for each k ∈ N, µ∗

t,k[ν] = ˆµk[ν](θαt, (Xt, t)) and ν ∗

t,k[µ] = ˆνk[µ](θαt, (Xt, t))

satisfy (13) and (14) resp., it follows (by linearity) that so do µt,∞[ν] and νt,∞[µ] resp. implying that

they satisfy (11) and (12) resp. The closure property of H(µ, ν) thus follows. Hence, H is a map with

non-empty, closed and convex values. Now, by Proposition 1, Lµ,ν{Xt, t ≥ 0} is jointly continuous
in (µ, ν) ∈ M1 × M2. Note that ˆφ1[ν] as obtained in (9) has a minimizing Markov strategy (11)
and ˆφ2[µ] as obtained in (10) has a minimizing Markov strategy (12), i.e., the minimizations in

(9) and (10) can be eﬀectively considered over M1 and M2 (resp.) which are compact sets. Also,

ri, i = 1, 2 are bounded functions. Hence, by Berge Maximum Theorem (see Theorem 17.31 of
Aliprantis and Border [7]), ˆφ1[ν] and ˆφ2[µ] are continuous in ν and µ respectively. Now consider a

sequence {(µk, νk)}k∈N in M1 × M2 converging to (µ∞, ν∞) ∈ M1 × M2. Let H(µk, νk) ∋ (˜µk, ˜νk) →
(˜µ∞, ˜ν∞) ∈ M1 × M2. From the continuity of q(·|·, u, v), ˆφ1[ν] and ˆφ2[µ] in µ, ν, it follows that

(˜µ∞, ˜ν∞) ∈ H(µ∞, ν∞). Hence the map H is upper semi-continuous. Then, by Theorem 1 of Fan

[19], there exists a ﬁxed point (µ∗, ν ∗) : N0 × X 7→ P(U ) × P(V ) of the map H deﬁned as

(µ∗(t, k), ν ∗(t, k))

def
= (ˆµ[ν ∗](θαt, (k, t)), ˆν[µ∗](θαt, (k, t)))

(18)

where ˆµ[ν ∗] (resp. ˆν[µ∗]) is any minimizing selector in (13) (resp. (14)). Then (µ∗, ν ∗) ∈ M1 × M2

is a Nash equilibrium strategy for the cost criterion (4), i.e.,

ˆφ1[ν ∗](θ, (k, t)) = ζ µ∗,ν ∗

1

(θ, (k, t)) ≤ ζ µ,ν ∗

1

(θ, k), ∀µ ∈ Πt,∞

1

,

and

ˆφ2[µ∗](θ, (k, t)) = ζ µ∗,ν ∗

2

(θ, (k, t)) ≤ ζ µ∗,ν

2

(θ, k), ∀ν ∈ Πt,∞

2

.

Now we prove the existence of Nash equilibria in the class of Markov strategies for the cost

✷

criterion (1).

Given deﬁnition (4), the Bellman equations for the discounted cost (1) are:

eθψ1(θ,(k,t)) = inf

ξ∈P(U)"ZUZV

eθr1(k,u,v) Xj∈X

eθαψ1(θα,(j,t+1))q(j|k, u, v)! ξ(du)νt[ht](dv)# ,

(19)

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

for player 1 with the boundary condition

lim
θ→0

ψ1(θ, (k, t)) = inf
1

µ∈Πt,∞

Eµ,ν

k,t " ∞
Xs=t

αs−tr1(X (t)

s , U (t)

s , V (t)

s )# , ∀k ∈ X, ∀t,

and

eθψ2(θ,(k,t)) = inf

χ∈P(V )"ZUZV

eθr2(k,u,v) Xj∈X

for player 2 with the boundary condition

eθαψ2(θα,(j,t+1))q(j|k, u, v)! µt[ht](du)χ(dv)# ,

lim
θ→0

ψ2(θ, (k, t)) = inf
2

ν∈Πt,∞

Eµ,ν

k,t " ∞
Xs=t

αs−tr2(X (t)

s , U (t)

s , V (t)

s )# , ∀k ∈ X, ∀t.

9

(20)

(21)

(22)

Theorem 2. Given θ ∈ (0, Θ], consider the ﬁxed point Markov strategies (µ∗, ν ∗) of H as in

(18) in Theorem 1. Then (µ∗, ν ∗) is also a pair of Nash equilibrium strategy for the cost criterion

(1), i.e.,

and

ˆψ1[ν ∗](θ, (k, t)) = ρµ∗,ν ∗

1

(θ, (k, t)) ≤ ρµ,ν ∗

1

(θ, (k, t)), ∀µ ∈ Πt,∞

1

ˆψ2[µ∗](θ, (k, t)) = ρµ∗,ν ∗

2

(θ, (k, t)) ≤ ρµ∗,ν

2

(θ, (k, t)), ∀ν ∈ Πt,∞

2

,

,

where ˆψ1[ν ∗] and ˆψ2[µ∗] are unique bounded solutions to (19) and (21) (resp.) satisfying the bound-

ary conditions (20) and (22) respectively.

Proof: The result follows directly from (4), Proposition 2, Theorem 1 and the fact that log is an

increasing function.

✷

4. Ergodic Game In this section, we study the cost criterion (2). To this end, we make the

following assumption:

(A1) The process {Xt}t∈N0 is an irreducible, aperiodic Markov chain under any pair of stationary

Markov strategies (µ, ν) ∈ S1 × S2.

We also assume the following condition which guarantees uniform ergodicity of controlled Markov

processes and is used to study additive average cost problems (see, e.g., Hern´andez-Lerma [25],

Section 3.3 or an equivalent assumption (A1) in Di Masi and Stettner [15] or (3.2) in Hern´andez-

Hern´andez and Marcus [24]):

(A2) There exists a number 0 < δ < 1 such that for all i, j ∈ X, u, u′ ∈ U and v, v′ ∈ V ,

||q(·|i, u, v) − q(·|j, u′, v′)||TV ≤ 2δ,

where || · ||TV denotes the total variation norm (see, e.g., Hern´andez-Lerma [25], Appendix B).

10

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

In our further analysis of this problem, the above assumptions always hold.

Under (A1)-(A2), it follows from the Lemma 3.3 of Hern´andez-Lerma [25] that for any (µ, ν) ∈

S1 × S2, the corresponding Markov chain {Xt} is uniformly ergodic with a unique invariant prob-

ability measure η[µ, ν] ∈ P(X), i.e.,

||ˆqt(·|k, µ, ν) − η[µ, ν](·)||TV ≤ 2δt, ∀k ∈ X, ∀t ∈ N,

(23)

where ˆqt(·|k, µ, ν) denotes the t-step transition kernel under (µ, ν) starting from k ∈ X.

Remark 1.

It is important to note here that the quantity δ on the r.h.s. of the above inequality

(23) is independent of the strategy pair (µ, ν) and (23) holds uniformly across all (µ, ν) ∈ S1 ×S2 (see

also condition C4 of Theorem 4(ii) in Federgruen et. al. [20]). Note that an assumption equivalent

to (A2) was also necessary for the corresponding zero-sum case as analyzed in Basu and Ghosh

[5]. Equivalent assumptions are quite common in the corresponding literature for the one-controller

case (see, e.g., Di Masi and Stettner [15],[16] and [17], Hern´andez-Hern´andez and Marcus [24]).

Definition 4. For any B ⊆ X, deﬁne the hitting time of the set B by {Xt} as

τB

def
= inf{t ≥ 0 : Xt ∈ B}.

Denote τB = τj if B = {j}. Similarly, deﬁne the ﬁrst return time to B by {Xt} as

σB

def
= inf{t ≥ 1 : Xt ∈ B}.

(24)

(25)

Denote σB = σj if B = {j}.

Now, Theorem 2.1 of Balaji and Meyn [2], Theorem 16.0.2 of Meyn and Tweedie [31] and Remark

1 together imply the following result:

Proposition 3. Assume (A1)-(A2). Then the following three equivalent statements hold.

(a) For every A ∈ 2X, the chain {Xt} is geometrically recurrent uniformly over all (µ, ν) ∈

S1 × S2, i.e., there exists some RA > 1 such that sup(µ,ν)∈S1×S2 supk∈X Eµ,ν
particular, if A = {j}, j ∈ X we write the constants above as Rj and Bj respectively. Note that

A ] ≤ BA < ∞. In

[RσA

k

BA, Bj > 1 by deﬁnition.

(b) For every A ∈ 2X, there exists some LA > 0 such that sup(µ,ν)∈S1×S2 supk∈X Eµ,ν

k

[σA] ≤ LA <

∞. In particular, if A = {j}, j ∈ X we write the constant above as Lj.

(c) There exist η < 1, b < ∞, a ﬁnite subset C ⊂ X and a bounded function V : X → [1, ∞) such

that

where η, b, C and V are all independent of (µ, ν) ∈ S1 × S2.

V (j)q(j|i, µ(i), ν(i)) ≤ ηV (i) + bIC(i)

Xj

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

11

Remark 2. Note that stochastic Lyapunov-type stability assumptions as in Proposition 3(c)

was also necessary for the corresponding zero-sum stochastic diﬀerential game case as analyzed

in Basu and Ghosh [4]. See also Remark 1 for reference to the corresponding literature where

equivalent assumptions are used. We also refer the reader to Altman et. al. [1] for examples of such

games on countable spaces with additive cost criteria where equivalent stability assumptions were

made.

Henceforth we ﬁx θ ∈ (0, Θ]. Given strategies (µ, ν) ∈ Π1 × Π2, consider the following dynamic

programming (HJB) equations for the ergodic cost (2) for players I and II (resp.):

and

eθλ1+V1(θ,k) = inf

ξ∈P(U)"ZUZV

eθλ2+V2(θ,k) = inf

χ∈P(V )"ZUZV

eθr1(k,u,v) Xj∈X
eθr2(k,u,v) Xj∈X

eV1(θ,j)q(j|k, u, v)! ξ(du)νt[ht](dv)# ,

eV2(θ,j)q(j|k, u, v)! µt[ht](du)χ(dv)# ,

(26)

(27)

where λ1, λ2 are scalars.

Under (A1)-(A2), by Corollary 2.3 of Di Masi and Stettner [15], there exists at most one (up
to an additive constant) bounded function ˆV1[ν] and a unique constant ˆλ1[ν] for which (26) is

satisﬁed. If it does then, by Proposition 1.1 of Di Masi and Stettner [15] (see also Theorem 2.1 of

Hern´andez-Hern´andez and Marcus [24]), we have

ˆλ1[ν] = inf
µ∈Π1

β µ,ν

1

(θ, k) = inf
µ∈S1

lim supT →∞

1
θT

ln Eµ,ν

k heθPT −1

t=0 r1(Xt,Ut,Vt)i

(28)

and similarly, there exists at most one bounded ˆV2[µ] (modulo an additive constant) and a unique
ˆλ2[µ] satisfying (27) such that

ˆλ2[µ] = inf
ν∈Π2

β µ,ν
2

(θ, k) = inf
ν∈S2

lim supT →∞

1
θT

ln Eµ,ν

k heθPT −1

t=0 r2(Xt,Ut,Vt)i .

Hence there exist measurable (minimizing) selectors (see Beneˇs [9])

(ˆµ[ν], ˆν[µ]) : X 7→ P(U ) × P(V )

satisfying

inf

ξ∈P(U)"ZUZV
=ZUZV

eθr1(k,u,v) Xj∈X
eθr1(k,u,v) Xj∈X

e

e

ˆV1[ν](θ,j)q(j|k, u, v)! ξ(du)νt[ht](dv)#
ˆV1[ν](θ,j)q(j|k, u, v)! ˆµ[ν] [du|k] νt[ht](dv),

(29)

(30)

12

and

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

inf

χ∈P(V )"ZUZV
=ZUZV

eθr2(k,u,v) Xj∈X
eθr2(k,u,v) Xj∈X

e

e

ˆV2[µ](θ,j)q(j|k, u, v)! µt[ht](du)χ(dv)#
ˆV2[µ](θ,j)q(j|k, u, v)! µt[ht](du)ˆν[µ] [dv|k] .

(31)

Hence, by Proposition 1.1 of Di Masi and Stettner [15] (see also Theorem 2.1 of Hern´andez-

Hern´andez and Marcus [24]), given (µ, ν) ∈ Π1 × Π2, if there exist bounded solutions to (26) and

(27) then the minimizing selector ˆµ[ν] and ˆν[µ] in (30) and (31) resp. generates stationary (see (28)

and (29)) optimal response strategy of player I (resp. player II) when the other’s strategy ﬁxed.

Hence, without loss of generality, we can eﬀectively consider the strategy pairs (µ, ν) ∈ S1 × S2 for

further analysis of this game. Thus if we consider the minimizing selectors ˆµ[ν] and ˆν[µ] in (30)

and (31) respectively, we can deﬁne the following point-to-set maps Hi : Sj 7→ 2Si, i, j = 1, 2, i 6= j

as follows:

and

H1(ν)

def
= {{µ∗[ν]} : µ∗[ν] satisﬁes (30)},

H2(µ)

def
= {{ν ∗[µ]} : ν ∗[µ] satisﬁes (31)}.

Deﬁne the map H ≡ H1 ⊗ H2 : S1 × S2 7→ 2S1×S2 as

(32)

(33)

H(µ, ν)

def
= {({µ∗[ν]}, {ν ∗[µ]}) : µ∗[ν] satisﬁes (30) and ν ∗[µ] satisﬁes (31)}.

(34)

A priori, it is not clear that the sets H1, H2 and hence H are nonempty. We now proceed to prove

the existence of unique bounded solutions to (26) and (27). Once this result is established, the

nonemptyness of the above sets follow automatically. Then, using arguments similar to Theorem

1, we prove the existence of Nash equilibria by showing that the map H has a ﬁxed point (˜µ, ˜ν). To

this end, we make the following deﬁnitions (see Balaji and Meyn [2] and Borkar and Meyn [13]).

Definition 5. Given an arbitrarily ﬁxed state 0 ∈ X and any strategy (µ, ν) ∈ S1 × S2, let

Λ1[ν](µ)

Λ2[µ](ν)

and

Also deﬁne

def

= infnΛ ∈ R : Eµ,ν
= infnΛ ∈ R : Eµ,ν

0 heθP
0 heθP

def

Λ∗

1[ν]

def
= inf
µ∈S1

Λ1[ν](µ),

σ0−1

t=0 (r1(Xt,Ut,Vt)−Λ)i ≤ 1o ,
t=0 (r2(Xt,Ut,Vt)−Λ)i ≤ 1o .

σ0−1

(35)

(36)

(37)

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

h∗
1[ν](k)

w∗

1[ν](k)

τ0
t=0(r1(Xt,Ut,Vt)−Λ∗

def
= inf
µ∈S1

Eµ,ν

k heθP

def

= arg minξ∈P(U)"ZUZV

1[ν])i ,
eθr1(k,u,v) Xj∈X

where w∗

1[ν] is any minimizer in (39). Similarly, let

Λ∗

2[µ]

h∗
2[µ](k)

w∗

2[µ](k)

def
= inf
ν∈S2
def
= inf
ν∈S2

Λ2[µ](ν),

Eµ,ν

k heθP

def

= arg minχ∈P(V )"ZUZV

τ0
t=0(r2(Xt,Ut,Vt)−Λ∗

2[µ])i ,
eθr2(k,u,v) Xj∈X

h∗

1[ν](j)q(j|k, u, v)! ξ(du)ν [dv|k]# ,

h∗

2[µ](j)q(j|k, u, v)! µ [du|k] χ(dv)#

13

(38)

(39)

(40)

(41)

(42)

where w∗

2[µ] is any minimizer in (42).

Note that since θ is ﬁxed we have suppressed the explicit dependence on θ in these deﬁnitions

for notational convenience. A priori, it is not obvious that the quantities deﬁned above are ﬁnite.

The following Proposition 4 and Lemmata 1 and 2 settle this issue.

First, we make a “small cost” assumption which shall hold for the rest of this paper.

(A3) ||ri||∞ ≤ ln R0

3Θ , i = 1, 2,

where R0 > 1 is as in part (a) of Proposition 3.

Remark 3. Note that a similar assumption was also necessary for the corresponding zero-sum

stochastic diﬀerential game case as analyzed in Basu and Ghosh [4].

Now we state and prove the following important proposition.

Proposition 4. Under (A1)-(A3) and for any (µ, ν) ∈ S1 × S2,

and

||r1||∞ ≥ |Λ∗

1[ν]|,

||r2||∞ ≥ |Λ∗

2[µ]|.

(43)

(44)

Moreover, Λ∗

1[ν] (resp. Λ∗

2[µ]) is continuous in ν (resp. µ).

Proof: We prove it for player I. The result for player II follows analogously. From (35) we obtain,

by Jensen’s inequality

1 ≥ Eµ,ν

0 heθP

σ0−1

t=0 (r1(Xt,Ut,Vt)−Λ1[ν](µ))i ≥ e−θΛ1[ν](µ)E

[σ0]e−θ||r1||∞E

µ,ν
0

µ,ν
0

[σ0]

≥ e−θΛ1[ν](µ)E

µ,ν
0

[σ0]eθE

µ,ν
0

hP

σ0−1

t=0 (r1(Xt,Ut,Vt)i

which implies

eθ||r1||∞E

µ,ν
0

[σ0] ≥ e−θΛ1[ν](µ)E

µ,ν
0

[σ0].

14

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Under (A1)-(A2), 0 < Eµ,ν

0

[σ0] ≤ L0 < ∞ (see part (b) of Proposition 3) and hence, by taking log

on both sides of the last inequality, we get

Now, by (35), for any ǫ > 0, we have

−||r1||∞ ≤ Λ1[ν](µ).

implying

which, in turn, implies

Eµ,ν

0

heθP

σ0−1

t=0 (r1(Xt,Ut,Vt)−Λ1[ν](µ)+ǫ)i > 1

Eµ,ν

0

heθP

σ0−1

t=0 (||r1||∞−Λ1[ν](µ)+ǫ)i > 1

Since this is true for any ǫ > 0, we have in the limit ǫ ↓ 0,

Eµ,ν

0

(cid:2)eθ(||r1||∞−Λ1[ν](µ)+ǫ)σ0(cid:3) > 1.

Eµ,ν

0

(cid:2)eθ(||r1||∞−Λ1[ν](µ))σ0(cid:3) ≥ 1

||r1||∞ − Λ1[ν](µ) ≥ 0.

implying

Hence we have

− ||r1||∞ ≤ Λ1[ν](µ) ≤ ||r1||∞.

(45)

The inequality (43) follows by taking the inf over µ ∈ S1. We now prove the joint continuity in
(µ, ν) of Λ1[ν](µ). Consider a sequence {(µ(n), ν (n))} n→∞−→ (µ(∞), ν (∞)) in S1 × S2. Let {Xt, t ≥ 0}

denote the chain starting at 0. By Proposition 1,

Lµ(n),ν(n)

{Xt, t ≥ 0} n→∞−→ Lµ(∞),ν(∞)

{Xt, t ≥ 0}.

Then, by Skorohod’s Theorem (see Theorem 2.2.2 of Borkar [12]), there exists some augmentation
( ˜H∞, B( ˜H∞), ˜P) of the canonical space (H∞, B(H∞)) on which

{X µ(n),ν(n)

t

, t ≥ 0}

˜P-a.s−→ {X µ(∞),ν(∞)

t

, t ≥ 0}

t

where {X µ(n) ,ν(n)
mented space starting at 0. Following (25), let σ(n)
Then, obviously ˜P -a.s.

0

, t ≥ 0}, n = 1, 2, . . . , ∞ denotes the Markov chain under (µ(n), ν (n)) on this aug-

def

= inf{t ≥ 1 : X µ(n),ν(n)

t

= 0}, n = 1, 2, . . . , ∞.

σ(n)
0

n→∞−→ σ(∞)

0

.

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

15

Hence we get the joint continuity under (µ, ν) of σ0. Hence, for any 0 < ǫ ≤ ||r1||∞ and along

a subsequence {nk} ⊂ {n} with {(µ(nk), ν (nk))}

nk→∞
−→ (µ(∞), ν (∞)), we have by (45) and the joint

continuity of σ0 under (µ, ν)

(nk)
0

σ
t=0

−1

fnk ≡ e

θP

t

(cid:18)r1(Xµ(nk ),ν(nk )
(cid:18)r1(X

σ
t=0

(∞)
0

−1

˜P-a.s.−→ e

θP

,U µ(nk ),ν(nk )

t

,V µ(nk ),ν(nk )

t

µ(∞) ,ν(∞)
t

µ(∞) ,ν(∞)
,U
t

µ(∞) ,ν(∞)
,V
t

)−Λ1[ν(nk )](µ(nk ))+ǫ(cid:19)
)−Λ+ǫ(cid:19) ≡ f∞,

(46)

where |Λ| ≤ ||r1||∞ and U µ(n),ν(n)
(µ(n), ν (n)), n = 1, 2, . . . , ∞ on this augmented space. Then

, V µ(n),ν(n)

t

t

are the corresponding control sequences under

0 < fnk = |fnk | ≤ gnk

def
= eθ(2||r1||∞+ǫ)σ

(nk )
0

˜P -a.s.−→ eθ(2||r1||∞+ǫ)σ

(∞)
0

def
= g∞ ≥ |f∞| = f∞.

(47)

Moreover, by (A3) and part (a) of Proposition 3, we have

sup
nk

˜E(cid:2)gnk(cid:3) ≤ sup

nk

(nk )
0

˜Ehe3Θ||r1||∞σ

i ≤ sup

nk

(nk )
0

σ
0

˜E(cid:20)R

(cid:21) ≤ B0 < ∞,

(48)

which, in particular, implies that {σ(nk )

0

} are uniformly integrable. Given any ε > 0 it follows from

(48) that there exists some large enough constant K ≡ K(ε, B0) > 0 such that

sup
nk

˜Ehgnk

I{gnk ≥K}i ≤ ε

implying {gnk } are uniformly integrable.

It follows by Theorem 6.18(iii) of Klenke [29] and (47) that {fnk } is uniformly integrable.

Also, by (A3) and part (a) of Proposition 3, we have

˜E [g∞] ≤ ˜Ehe3Θ||r1||∞σ

(∞)
0

Hence, by Corollary 1.3.1 of Borkar [12], we get

(∞)
0

i ≤ ˜E(cid:20)R

σ
0

(cid:21) ≤ B0 < ∞.

(49)

(50)

(51)

(nk )
0

σ
t=0

−1

(cid:18)r1(X

µ(nk ),ν(nk )
t

θP

µ(nk ),ν(nk )
,U
t

µ(nk ),ν(nk )
,V
t

e

(∞)
0

σ
t=0

−1

(cid:18)r1(X

µ(∞),ν(∞)
t

µ(∞),ν(∞)
,U
t

µ(∞),ν(∞)
,V
t

Similarly we can show that

(nk )
0

σ
t=0

−1

θP

(cid:18)r1(X

µ(nk ),ν(nk )
t

µ(nk ),ν(nk )
,U
t

e

µ(nk ),ν(nk )
,V
t

lim
nk→∞

˜E

= ˜E
θP


e

lim
nk→∞

˜E

= ˜E
θP


e

)−Λ1[ν(nk )](µ(nk ))+ǫ(cid:19)


.

)−Λ+ǫ(cid:19)

)−Λ1[ν(nk )](µ(nk ))(cid:19)


)−Λ(cid:19)


(∞)
0

σ
t=0

−1

(cid:18)r1(X

µ(∞) ,ν(∞)
t

µ(∞) ,ν(∞)
,U
t

µ(∞) ,ν(∞)
,V
t

.

(52)

16

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Now from (35) we get that for any 0 < ǫ ≤ ||r1||∞,

Hence, taking limnk→∞ on both sides of (53), we have by (52) and (53)

(53)

(54)

e

˜E
θP

≥ ˜E


e

θP

e

˜E
θP

≥ ˜E


e

(n)
0

σ
t=0

−1

(cid:18)r1(X

µ(n),ν(n)
t

µ(n) ,ν(n)
,U
t

µ(n) ,ν(n)
,V
t

(n)
0

σ
t=0

−1

(cid:18)r1(X

µ(n) ,ν(n)
t

µ(n) ,ν(n)
,U
t

µ(n) ,ν(n)
,V
t

)−Λ1[ν(n)](µ(n))+ǫ(cid:19)

)−Λ1[ν(n)](µ(n))(cid:19)


≥ 1

.

(∞)
0

σ
t=0

−1

(cid:18)r1(X

µ(∞),ν(∞)
t

µ(∞) ,ν(∞)
,U
t

µ(∞) ,ν(∞)
,V
t

(∞)
0

σ
t=0

θP

−1

(cid:18)r1(X

µ(∞),ν(∞)
t

µ(∞),ν(∞)
,U
t

µ(∞),ν(∞)
,V
t

≥ 1

,

)−Λ+ǫ(cid:19)

)−Λ(cid:19)


for some Λ satisfying (45) and all 0 < ǫ ≤ ||r1||∞. This implies, by (35), that Λ = Λ1[ν (∞)](µ(∞)).

Hence Λ1[ν](µ) is jointly continuous under (µ, ν). The continuity of Λ∗

1[ν] with respect to ν now

follows from (45) since S1 is compact.

✷

Remark 4. Note that by (45) above the quantities Λ1[ν](µ) and Λ2[µ](ν) deﬁned in (35) and

(36) respectively are uniformly bounded for all θ ∈ (0, Θ]. This fact shall be implicitly used in the

proof of Theorem 3.

Now we state and prove two useful lemmata.

Lemma 1. Under (A1)-(A2) and for any (µ, ν) ∈ S1 × S2,

1. The multiplicative Poisson inequalities holds for all k ∈ X, i.e.,

ZUZV
ZUZV

eθr1(k,u,v) Xj∈X
eθr2(k,u,v) Xj∈X

h∗

h∗

1[ν](j)q(j|k, u, v)! w∗
2[µ](j)q(j|k, u, v)! µ [du|k] w∗

1[ν](k)(du)ν [dv|k] ≤ eθΛ∗

1[ν]h∗

1[ν](k),

2[µ](k)(dv) ≤ eθΛ∗

2[µ]h∗

2[µ](k).

(55)

(56)

2. h∗

1[ν](k) < ∞, h∗

2[µ](k) < ∞, ∀k ∈ X.

Proof: We prove it for player I when player II uses ν ∈ S2. The other case is analogous. For each

k 6= 0,

e−θΛ∗

1[ν]ZV ZU
ξ∈P(U)ZV ZU

inf

= h∗

eθr1(k,u,v) Xj∈X

eθ(r1(k,u,v)−Λ∗

h∗

1[ν](j)q(j|k, u, v)! w∗
q(j|k, u, v)(cid:26) inf

µ∈S1

1 [ν]) Xj∈X

1[ν](k) (by one-step backward recursion),

1[ν](k)(du)ν [dv|k] =

τ0−1
t=0 (r1(Xt,Ut,Vt)−Λ∗

Eµ,ν

j

heθP

1 [ν])i(cid:27)! ξ(du)ν [dv|k]

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

17

while for k = 0, we have

ZV ZU Xj∈X

h∗

1[ν](j)q(j|0, u, v)! w∗

1[ν](0)(du)ν [dv|0] = inf
µ∈S1

Eµ,ν

0 heθP

σ0−1
t=0 (r1(Xt,Ut,Vt)−Λ∗

1[ν])i ≤ 1,

(57)

where the inequality follows from (35). It follows that (55) holds. From (55) it follows exactly as in

the proof of Lemma 15.2.2(i) of Meyn and Tweedie [31] that the set S

def
= {k ∈ X : h∗

1[ν](k) < ∞}

absorbing, i.e., Pj∈SRV RU q(j|k, u, v)w∗

as 0 ∈ S and the chain {Xt} is irreducible under the stationary strategy (w∗

1[ν], ν) by assumption

1[ν](k)(du)ν [dv|k] = 1 for all k ∈ S. Since it is non-empty

(A1), we get by Proposition 4.2.3 of Meyn and Tweedie [31] that it is full, i.e. S = X establishing

part 2.

✷

Note that, under the additional assumption (A3), we can actually show a tighter result than

part 2 of Lemma 1 as given below.

Lemma 2. Under (A1) - (A3) and for any (µ, ν) ∈ S1 × S2,

1

R0B0

≤ h∗

1[ν](k) ≤ R0B0,

1

R0B0

≤ h∗

2[µ](k) ≤ R0B0, ∀k ∈ X.

(58)

Moreover, h∗

1[ν](k) (resp. h∗

2[µ](k)) is continuous in ν (resp. µ) for all k ∈ X.

Proof: We prove it for h∗

1[ν]. The proof is exactly similar for h∗

2[µ]. Under the assumptions of this

lemma, we have by (38) and part (a) of Proposition 3

0 < Eµ,ν

≤ Eµ,ν

τ0
t=0(r1(Xt,Ut,Vt)−Λ∗

k heθP
(cid:2)e2θ||r1||∞(σ0+1)(cid:3) ≤ Eµ,ν

k heθP

1[ν])i = Eµ,ν
(cid:2)e3Θ||r1||∞(σ0+1)(cid:3) ≤ R0 sup

k∈X

k

k

σ0
t=0(r1(Xt,Ut,Vt)−Λ∗

1[ν])i

[Rσ0

Eµ,ν

k

0 ] ≤ R0B0, ∀k 6= 0,

where the equality follows from Proposition 3.4.5(ii) of Meyn and Tweedie [31]. Hence we get

0 < h∗

1[ν](k) = inf
˜µ∈S1

E ˜µ,ν

k heθP

τ0
t=0(r1(Xt,Ut,Vt)−Λ∗

1[ν])i ≤ R0B0, ∀k 6= 0.

(59)

(60)

Let ˜µ[ν] ∈ S1 be any minimizer in (38). Such a minimizer always exists by (59), Proposition 1

and the compactness of S1. Hence, for all k 6= 0, we have using Jensen’s inequality and part (a) of

Proposition 3

1[ν](k) = E ˜µ[ν],ν
h∗

k

τ0
t=0(r1(Xt,Ut,Vt)−Λ∗

(cid:2)e−2θ||r1||∞(σ0+1)(cid:3) ≥ E ˜µ[ν],ν

k

1

≥ E ˜µ[ν],ν

k

≥

1
R0E ˜µ[ν],ν

k

[Rσ0
0 ]

R0 supj∈X E ˜µ[ν],ν

j

[Rσ0
0 ]

k

heθP
1[ν])i = E ˜µ[ν],ν
(cid:2)e−3Θ||r1||∞(σ0+1)(cid:3) ≥

1
R0

1

≥

.

R0B0

σ0
t=0(r1(Xt,Ut,Vt)−Λ∗

1 [ν])i
0 (cid:21) ≥
(cid:20) 1

Rσ0

E
R
0

E ˜µ[ν],ν

k

1
˜µ[ν],ν
k

[σ0]+1

(61)

heθP

≥

18

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Note that h∗

joint continuity of Eµ,ν

1[ν](0) = inf ξ∈P(U)RV RU eθr1(0,u,v)−θΛ∗

τ0
t=0(r1(Xt,Ut,Vt)−Λ∗

Proposition 4. Hence the continuity of h∗

1[ν]ξ(du)ν [dv|0] obviously obeys the bound. The

1 [ν])i under (µ, ν) can be proved as in the proof of

1[ν] in ν follows from (59) and the compactness of S1. ✷

k heθP

Now we state and prove following theorem which is a key step for proving the existence of Nash

equilibria.

Theorem 3. Under (A1) - (A3) and for (µ, ν) ∈ S1 × S2, (ln h∗

1[ν], ˆλ1[ν]) with h∗

1[ν](0) =

RV RU eθr1(0,u,v)−θΛ∗

1[ν]w∗

1[ν](0)(du)ν [dv|0], where w∗
2[µ], ˆλ2[µ]) with h∗

B(X)× R+ to (26). Similarly, (ln h∗

1[ν] is deﬁned in (39), is the unique solution in

2[µ](0) =RURV eθr2(0,u,v)−θΛ∗

2[µ]µ [du|0] w∗

2[µ](0)(dv),

where w∗

2[µ] is deﬁned in (42), is the unique solution to (27) again in B(X) × R+.

Proof: We shall prove this for player I when player II plays the strategy ν. The other case is

proved analogously. We ﬁrst prove that (ln h∗

1[ν], ˆλ1[ν]) is a solution to (26). By Lemma 1, h∗

1[ν] as

deﬁned in (38) is ﬁnite. Consider w∗

1[ν] deﬁned in (39) with this h∗

1[ν]. Let

f ∗
1 [ν](k)

def

= Ew∗

k

1 [ν],ν

τ0
t=0(r1(Xt,Ut,Vt)−Λ1[ν](w∗

heθP

1 [ν]))i

under the stationary strategy w∗

1[ν]. Note that, for k 6= 0, we can get as in (60) of Lemma 2,

0 < f ∗

1 [ν](k) ≤ R0B0 < ∞.

It follows from the Markov property that

ZV ZU Xj∈X
=ZV ZU

f ∗

1 [ν](j)q(j|k, u, v)! w∗

1[ν](k)(du)ν [dv|k] = Ew∗

k

1 [ν],ν

heθP

σ0
t=1(r1(Xt,Ut,Vt)−Λ1[ν](w∗

1 [ν]))i

e−θr1(k,u,v)+θΛ1[ν](w∗

1 [ν])f ∗

1 [ν](k)w∗

1[ν](k)(du)ν [dv|k] , k 6= 0.

(62)

(63)

(64)

Since, f ∗

1 [ν](0) =RV RU eθr1(0,u,v)−θΛ1[ν](w∗

plicative Poisson equation holds:

1 [ν])w∗

1[ν](0)(du)ν [dv|0], it follows that the following multi-

f ∗

1 [ν](j)q(j|k, u, v)! w∗

1[ν](k)(du)ν [dv|k]

ZV ZU Xj∈X
= ZV ZU

e−θr1(k,u,v)+θΛ1[ν](w∗

1 [ν])f ∗

1 [ν](k)w∗

1[ν](k)(du)ν [dv|k] , ∀k.

(65)

Since by (45) in Proposition 4 Λ1[ν]({w∗

1[ν]}) < ∞ and by (63) 0 < f ∗

1 [ν](k) < ∞, under the tran-

sition kernel q(·|k, u, v), we can deﬁne the “twisted kernel” ˘q1(·|k, w∗

1[ν](k), ν(k)) as follows:

˘q1(j|k, w∗

1[ν](k), ν(k))

def

= ZUZV

eθr1(k,u,v)−θΛ1[ν](w∗

1 [ν])

f ∗
1 [ν](k)

f ∗
1 [ν](j)q(j|k, u, v)w∗

1[ν](k)(du)ν [dv|k] , j ∈ X.

(66)

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

19

Note that the kernel ˘q1 is indeed stochastic i.e., Pj∈X ˘q1(j|k, w∗

1[ν](k), ν(k)) = 1, ∀k since (65)
holds. Hence, ˘q1 is the transition kernel for some Markov chain { ˘Xt}. Since, by (45), for any

−||r1||∞ ≤ Λ < Λ1[ν](w∗

1[ν]),

0 < Ew∗

0

1 [ν],ν

heθP

σ0−1

t=0 (r1(Xt,Ut,Vt)−Λ)i ≤ Ew∗

0

1 [ν],ν

(cid:2)e3Θ||r1||∞σ0(cid:3) ≤ sup

k∈X

1 [ν],ν

Ew∗

k

[Rσ0

0 ] ≤ B0 < ∞,

it follows from Theorem 4.1(i)-(ii) of Balaji and Meyn [2] that the chain { ˘Xt} under ˘q1 is

geometrically recurrent. Hence it follows from Theorem 4.2(i) of Balaji and Meyn [2] that

(f ∗

1 [ν], Λ1[ν]({w∗

1[ν]})) is a solution to the multiplicative Poisson equation:

eθλψ(k) =ZUZV

eθr1(k,u,v) Xj∈X

ψ(j)q(j|k, u, v)! w∗

1[ν](k)(du)ν [dv|k] .

(67)

It follows from (39), the fact that h∗

1[ν] > 0 by deﬁnition and (55) in Lemma 1 that, for all k ∈ X,

h∗

1[ν](j)q(j|k, u, v)! ξ(du)ν [dv|k]

inf

ξ∈P(U)ZV ZU
=ZV ZU

eθr1(k,u,v) Xj∈X
eθr1(k,u,v) Xj∈X

h∗

1[ν](k) ≤ eθΛ1[ν](w∗

≤ eθΛ∗

1[ν]h∗

1[ν](j)q(j|k, u, v)! w∗

1 [ν])h∗

1[ν](k),

1[ν](k)(du)ν [dv|k]

(68)

(69)

(70)

as Λ∗

1[ν] ≤ Λ1[ν](w∗

1[ν]) (see (35) and (37)). Hence, by Theorem 4.2(i)-(ii) of Balaji and Meyn [2],

we obtain

and

h∗
1[ν](k)
h∗
1[ν](0)

=

f ∗
1 [ν](k)
f ∗
1 [ν](0)

,

inf

ξ∈P(U)ZUZV

= eθΛ∗

1[ν]h∗

eθr1(k,u,v) Xj∈X

1[ν](k) = eθΛ1[ν](w∗

1 [ν])h∗

1[ν](k), ∀k ∈ X.

h∗

1[ν](j)q(j|k, u, v)! ξ(du)ν [dv|k]

Hence Λ∗

1[ν] = Λ1[ν](w∗

1[ν]). Since, by Lemma 2, 0 < supk∈X | ln h∗

1[ν](k)| ≤ ln(R0B0) < ∞ as by

deﬁnition both R0, B0 > 1, uniqueness follows from Corollary 2.3 of Di Masi and Stettner [15]

and the condition h∗

1[ν](0) = f ∗

1[ν]ξ(du)ν [dv|0]. It follows from

1 [ν](0) = inf ξ∈P(U)RURV eθr1(0,u,v)−θΛ∗

Proposition 1.1 of Di Masi and Stettner [15] (see also Theorem 2.1 of Hern´andez-Hern´andez and

Marcus [24]) that

and hence,

1[ν] = ˆλ1[ν]
Λ∗

1[ν](k) = E{w∗
h∗

k

1 [ν]},ν

heθP

τ0

t=0(r1(Xt,Ut,Vt)−ˆλ1[ν])i , ∀k ∈ X.

(71)

(72)

20

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

Similarly, it can be shown for player II that

2[µ] = ˆλ2[µ]
Λ∗

and

2[µ](k) = Eµ,{w∗
h∗

k

2 [µ]}

heθP

τ0

t=0(r2(Xt,Ut,Vt)−ˆλ2[µ])i , ∀k ∈ X,

under the stationary strategy w∗

2[µ] as deﬁned in (42) with h∗

2[µ] as deﬁned in (41).

(73)

(74)

✷

Hence, by (30) and (31), for any (µ, ν) ∈ S1 × S2, there exists measurable (minimizing) selectors

(see Beneˇs [9])

satisfying

(ˆµ[ν], ˆν[µ]) : X 7→ P(U ) × P(V )

inf

ξ∈P(U)ZV ZU
=ZV ZU

eθr1(k,u,v) Xj∈X
eθr1(k,u,v) Xj∈X

eln h∗

eln h∗

1[ν](j)q(j|k, u, v)! ξ(du)ν [dv|k]
1[ν](j)q(j|k, u, v)! ˆµ[ν](k)(du)ν [dv|k] ,

implying, by Theorem 3 and (26),

eθˆλ1[ν]+ln h∗

1[ν](k) =ZV ZU

eθr1(k,u,v) Xj∈X

eln h∗

1[ν](j)q(j|k, u, v)! ˆµ[ν](k)(du)ν [dv|k] ,

and similarly

inf

χ∈P(V )ZUZV
=ZUZV

eθr2(k,u,v) Xj∈X
eθr2(k,u,v) Xj∈X

eln h∗

eln h∗

2[µ](j)q(j|k, u, v)! µ [du|k] χ(dv)
2[µ](j)! q(j|k, u, v)µ [du|k] ˆν[µ](k)(dv),

implying, by Theorem 3 and (27),

eθˆλ2[µ]+ln h∗

2[µ](k) =ZUZV

eθr2(k,u,v) Xj∈X

eln h∗

2[µ](j)q(j|k, u, v)! µ [du|k] ˆν[µ](k)(dv).

(75)

(76)

(77)

(78)

Using the minimizing selectors ˆµ[ν] and ˆν[µ] in (75) and (77) as our optimal responses for given

(µ, ν) ∈ S1 × S2, we now prove the existence of Nash equilibria in the class of stationary Markov

strategies for the ergodic cost criterion (2).

Theorem 4. Given θ ∈ (0, Θ], there exists a pair of Nash equilibrium strategy in S1 × S2 for

the game corresponding to the cost criterion (2).

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

21

Proof: Given (µ, ν) ∈ S1 × S2, H as deﬁned in (34) can be proved to be a map with non-empty,

closed and convex values as in Theorem 1. Now, by Proposition 1, Lµ,ν{Xt, t ≥ 0} is jointly contin-
uous in (µ, ν) ∈ S1 × S2. Note that ˆλ1[ν] as obtained in (28) has a minimizing stationary strategy
(30) and ˆλ2[µ] as obtained in (29) has a minimizing stationary strategy (31), i.e., the minimiza-

tions in (28) and (29) can be eﬀectively considered over S1 and S2 (resp.) which are compact sets.

Also, ri, i = 1, 2 are bounded functions. Hence, by Berge Maximum Theorem (see Theorem 17.31
of Aliprantis and Border [7]), ˆλ1[ν] and ˆλ2[µ] are continuous in ν and µ respectively. Similarly,
the continuity of h∗

2[µ]) follows from (72) (resp. (74)) and Lemma 2. Now consider

1[ν] (resp. h∗

(˜µ∞, ˜ν∞) ∈ S1 × S2. From the continuity of q(·|·, u, v), (h∗

a sequence {(µk, νk)}k∈N in S1 × S2 converging to (µ∞, ν∞) ∈ S1 × S2. Let H(µk, νk) ∋ (˜µk, ˜νk) →
2[µ], ˆλ2[µ]) in µ, ν, it fol-
lows that (˜µ∞, ˜ν∞) ∈ H(µ∞, ν∞). Hence the map H is upper semi-continuous. Then, by Theorem

1[ν], ˆλ1[ν]) and (h∗

1 of Fan [19], there exists a ﬁxed point (µ∗, ν ∗) : X 7→ P(U ) × P(V ) of the map H deﬁned as

(µ∗(k), ν ∗(k))

def
= (ˆµ[ν ∗](k), ˆν[µ∗](k))

(79)

where ˆµ[ν ∗] (resp. ˆν[µ∗]) is any minimizing selector in (75) (resp. (77)). Then (µ∗, ν ∗) ∈ S1 × S2 is

a Nash equilibrium strategy for the cost criterion (2), i.e., for all k ∈ X

and

ˆλ1[ν ∗] = β µ∗,ν ∗

1

(θ, k) ≤ β µ,ν ∗

1

(θ, k), ∀µ ∈ Π1,

ˆλ2[µ∗] = β µ∗,ν ∗

2

(θ, k) ≤ β µ∗,ν

2

(θ, k), ∀ν ∈ Π2.

✷

5. Conclusions. We have established Nash equilibria for nonzero-sum discrete-time stochas-

tic games on a countable state space with risk-sensitive cost criteria. We have studied both dis-

counted and ergodic cost criteria on the inﬁnite time horizon. For discounted cost criterion, we

have established Nash equilibria under fairly general conditions. For ergodic cost criterion, how-

ever, we have established our results under additional criteria of irreducibility (A1), stability (A2)

and smallness of cost (A3) all of which are standard in the corresponding literature. A natural

continuation of this work is to analyze such discrete-time games on general state spaces. Another

direction is to investigate such games in continuous time in the set-up of stochastic diﬀerential

games.

Acknowledgments. The work of the second author is supported in part by a grant from

UGC Centre for Advanced Study.

22

References

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

[1] Altman, E., A. Hordijk, F. M. Spieksma. 1997. Contraction conditions for average and α-discount opti-

mality in countable state markov games with unbounded rewards, Math. Oper. Res. 22(3), 558-618.

[2] Balaji, S., S. P. Meyn. 2000. Multiplicative ergodicity and large deviations for an irreducible Markov

chain, Stoch. Proc. Appl. 90, 123-144.

[3] Basar, T. 1999. Nash Equilibria of Risk-Sensitive Nonlinear Stochastic Diﬀerential Games, J. Optim.

Theory Appl. 100, 479-498.

[4] Basu, A., M. K. Ghosh. 2012. Zero-sum risk-sensitive stochastic diﬀerential games, Math. Oper. Res.

37(3), 437-449.

[5] Basu, A., M. K. Ghosh. 2014. , Stoch. Proc. Appl. Zero-sum risk-sensitive stochastic games on a countable

state space 124, 961-983.

[6] Bellman, R. 1957. Dynamic Programming, Princeton University Press, Princeton, New Jersey, U.S.A.

[7] Aliprantis, C. D., K. C. Border. 2006. Inﬁnite Dimensional Analysis: A Hitchhiker’s Guide, Third Ed.,

Springer-Verlag, Berlin.

[8] Bielecki, T. R., S. R. Pliska. 2003. Economic properties of the risk-sensitive criterion for portfolio man-

agement, Rev. Acc. Finan. 2(2), 3-17.

[9] Beneˇs, V. E. 1970. Existence of optimal strategies based on speciﬁed information for a class of stochastic

decision problems, SIAM J. Control 8(2), 179-188.

[10] Bertsekas, D. P., S. E. Shreve. 1996. Stochastic Optimal Control: The Discrete-Time Case, Athena

Scientiﬁc, Belmont, Massachusetts.

[11] Borkar, V. S. 1991. Topics in Controlled Markov Chains, Pitman Research Notes in Mathematics Series

240, Longman Scientiﬁc & Technical, Harlow, Essex, UK.

[12] Borkar, V. S. 1995. Probability Theory: An Advanced Course, Springer-Verlag, New York.

[13] Borkar, V. S., S. P. Meyn. 2002. Risk-sensitive optimal control for Markov decision processes with

monotone cost, Math. Oper. Res. 27(1), 192-209.

[14] Cavazos-Cadena, R., E. Fernandez-Gaucherand. 1999. Controlled Markov chains with risk-sensitive cri-

teria: Average cost, optimality equations, and optimal solutions, Math. Methods Oper. Res. 49, 299-324.

[15] Di Masi, G. B., L. Stettner. 1999. Risk-sensitive control of discrete-time Markov processes with inﬁnite

horizon, SIAM J. Control Optim. 38(1), 61-78.

[16] Di Masi, G. B., L. Stettner. 2000. Inﬁnite horizon risk sensitive control of discrete time Markov processes

with small risk, Systems Control Lett. 40, 15-20.

[17] Di Masi, G. B., L. Stettner. 2007. Inﬁnite horizon risk sensitive control of discrete time Markov processes

under minorization property, SIAM J. Control Optim. 46(1), 231-252.

Basu and Ghosh: Nonzero-sum Risk-sensitive Games with Countable States
Article submitted to Mathematics of Operations Research; manuscript no. MOR-2015-241

23

[18] El-Karoui, N., S. Hamadene. 2003. BSDE and risk-sensitive control, zero-sum and nonzero-sum game

problems of stochastic functional diﬀerential equations, Stochastic Proc. Appl., 107, 145-169.

[19] Fan, K. 1952. Fixed-point and minimax theorems in locally convex topological linear spaces, Proc. Nat.

Acad. Sc. 38, 121-126.

[20] Federgruen, A., A. Hordijk, H. C. Tijms. 1978. A note on simultaneous recurrence conditions on a set

of denumerable stochastic matrices, J. Appl. Prob. 15, 842-847.

[21] Fleming, W. H., D. Hern´andez-Hern´andez. 1997. Risk-sensitive control of ﬁnite state machines on an

inﬁnite horizon I, SIAM J. Control Optim. 35(5), 1790-1810.

[22] Fleming, W. H., W. M. McEneaney. 1995. Risk-sensitive Control on an inﬁnite time horizon, SIAM J.

Control Optim. (33)6, 1881-1915.

[23] Hansen, L. P., T. J. Sargent. 1995. Discounted linear exponential quadratic gaussian control, IEEE

Trans. Aut. Cont. 40(5), 968-971.

[24] Hern´andez-Hern´andez, D., S. I. Marcus. 1996. Risk-sensitive control of Markov processes in countable

state space, Systems Control Lett. 29, 147-155. Errata corriege, 1998, ibid, 34(1-2), 105-106.

[25] Hern´andez-Lerma, O. 1989. Adaptive Markov Control Processes, Springer-Verlag (Applied Math. Sc.

79), New York.

[26] Howard, R. A., J. E. Matheson. 1972. Risk-sensitive Markov decision processes, Management Science 8,

356-369.

[27] Jacobson, D. H. 1973. Optimal stochastic linear systems with exponential performance criteria and their

relation to deteministic diﬀerential games, IEEE Trans. Automatic Control AC-18(2), 124-131.

[28] James, M. R., J. Baras, R. J. Elliot. 1994. Risk-sensitive control and dynamic games for partially

observed discrete-time nonlinear systems, IEEE Trans. Automatic Control AC-39(4), 780-792.

[29] Klenke, A. 2008. Probability Theory: A Comprehensive Course, Springer-Verlag, London.

[30] Klompstra, M. B. 2007. Nash equilibria in risk-sensitive dynamic games, IEEE Trans. Autom. Control,

45, 1397-1401.

[31] Meyn, S. P., R. L. Tweedie. 2009. Markov Chains and Stochastic Stability, Second Ed., Cambridge

University Press, Cambridge.

[32] Nagai, H. 2003. Optimal strategies for risk-sensitive portfolio optimization problems for general factor

models, SIAM J. Control Optim., 41, 1779-1800.

[33] Rothblum, U. G. 1984. Multiplicative Markov decision chains, Math. Oper. Res. 9, 6-24.

[34] P. Whittle, P. 1981. Risk-sensitive linear quadratic gaussian control, Adv. Appl. Prob., 13, 764-777,

1981.

[35] Whittle, P. 1990. Risk-sensitive Optimal Control, John Wiley and Sons, Chichester, U.K.

[36] Whittle, P. 1996. Optimisation: Basics and Beyond, John Wiley and Sons, Chichester, U.K.

