A Fractal-based CNN for Detecting Complicated Curves

in AFM Images

6
1
0
2

 
r
a

 

M
9
1

 
 
]

V
C
.
s
c
[
 
 

1
v
6
3
0
6
0

.

3
0
6
1
:
v
i
X
r
a

Hongteng Xu1,2, Junchi Yan3, Nils Persson4, Hongyuan Zha2

1School of Electrical and Computer Engineering, Georgia Tech

2College of Computing, Georgia Tech

3IBM Research, China

4School of Chemical & Biomolecular Engineering, Georgia Tech

Abstract. Convolutional neural networks (CNNs) have been widely used in com-
puter vision, including low-and middle-level vision problems such as contour
detection and image reconstruction. In this paper, we propose a novel fractal-
based CNN model for the problem of complicated curve detection, providing
a geometric interpretation of CNN-based image model leveraging local fractal
analysis. Utilizing the notion of local self-similarity, we develop a local fractal
model for images. A curve detector is designed based on the model, consisting
of an orientation-adaptive ﬁltering process to enhance the local response along a
certain orientation. This is followed by a post-processing step to preserve local
invariance of the fractal dimension of image. We show the iterative framework
of such an adaptive ﬁltering process can be re-instantiated approximately via a
CNN model, the nonlinear processing layer of which preserves fractal dimen-
sion approximately and the convolution layer achieves orientation enhancement.
We demonstrate our fractal-based CNN model on the challenging task for detect-
ing complicated curves from the texture-like images depicting microstructures of
materials obtained by atomic force microscopy (AFM).

Keywords: Fractal analysis, CNN, curve detection, oriented ﬁlters, AFM image

1 Introduction

Human beings can easily identify visually-salient curves in an image. Endowing com-
puters with similar capabilities is a classical problem of low-and middle-level computer
vision. Curve detection is related to, but different from contour (or edge) detection. A
contour detector [1,2] aims to detect discontinuous boundaries between regular objects,
which helps to segment image into semantic objects, as the BSDS [3] dataset shows.
In contrast, a curve detector recognizes slim objects with diverse shapes directly, which
focuses more on ﬁnding 1-D geometries in the image, as shown in Figs. 1(a) and 1(c).
Curve detection is meaningful for many practical applications, such as power line
detection [4], geological measurement [5], and rigid body detection [6,7], etc. More
recently, the curve detection technique is introduced into more interdisciplinary ﬁelds,
e.g., biology, materials, and nanotechnology [8,9,10]. For the speciﬁc problem related
to computational material science as studied in this paper, Fig. 1(a) gives an AFM im-
age of semiconducting polymers constructed via ﬁbers. The ﬁbrillar structure of the

2

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

(a) AFM image

(b) Scheme of iterative adaptive ﬁltering (c) Labels of curves

(d) Scheme of fractal-based CNN

(e) Convolution layer

(f) Nonlinear layer

Fig. 1. Given material AFM images in (a), we apply an iterative adaptive ﬁltering algorithm in
(b) to label curves in (c). We prove that the curve detector can be efﬁciently implemented via a
fractal-based CNN in (d), whose convolution layer and nonlinear layer are shown in (e, f).

material has a huge inﬂuence on its electronic properties, which is represented via the
complex salient curves in the image, as Figs.1(c) shows. Quantiﬁcation of these curves
and structures from imaging tools enables material scientists and engineers to rationally
design the microstructure to achieve the desired properties [11].

The new application above involves many challenges of curve detection. Firstly, the
AFM has been applied to problems in a wide range of disciplines of the natural sciences,
including solid state physics, semiconductor science and technology, polymer chemistry
and physics, surface chemistry, molecular biology and medicine, etc, but the AFM im-
ages often suffer from heavy noise and low contrast, which has negative inﬂuences on
curve detection. Secondly, the curves in the material AFM images are very complicated
— dense curves with different shapes and orientations are distributed in the image ran-
domly and have overlaps with each other, as Fig. 1(a) shows. Currently, detecting such
chaotic curves relies on semi-automatic methods [11], in which key points are selected
manually and curves are estimated via active contour model and A* shortest path algo-
rithm. Complicated human interaction reduces the efﬁciency of curve detection. How
to detect curves in these texture-like images is still an important open problem ignored
by the community of computer vision.

Technically, early works of curve detection mainly rely on simple thresholding [12]
and diverse transformation techniques, e.g., Hough transformation [13], Fourier trans-
formation [14], Gabor transformation [15], and wavelets [16,17], etc. These methods
essentially involve applying handcrafted ﬁlters to extract structural features for curves,
which cannot robustly deal with the challenging texture-like images in our work. The
recent developments of contour detection and image segmentation [3,2] motivate us
to explore learning-based solutions to our problem, especially the deep learning tech-
niques. In fact, deep convolutional neural networks (CNNs), as one of the most popular

Fig1a.grafﬂeOrientation-AdaptiveFilteringFractal Dimension PreservingThresholdingorSigmoidInput ImageDetected CurvesDetected CurvesConvolution LayerNonlinear LayerThresholdingor SigmoidConvolution LayerNonlinear LayerN layersInput ImagesDetected CurvesMax(.)OrientedFilterBankConvolution LayerNonlinear Layer1/xconv(x)multiply2convA Fractal-based CNN for Detecting Complicated Curves in AFM Images

3

data-driven machine learning techniques, have been applied to detect contours from
images [1,18,19], which is also applicable to detect curves.

While having potentials to attain high performance, the CNN-based methods are
more difﬁcult to interpret compared with handcrafted ﬁlter-based methods. Typically,
for a CNN, the interpretations for its nonlinear layer, i.e., the rectiﬁer linear unit (ReLU),
and its output are often mysterious. Although, several efforts have been made to under-
stand CNNs [20,21,22,23,24,25], for the speciﬁc and fundamental vision problem of
curve detection, the physical meanings of different CNN modules are not fully compre-
hended.

Focusing on the challenges in both methodology and application, in this paper, we
1) explore a geometrical interpretation of CNN based on local fractal analysis of im-
age; and 2) propose a fractal-based CNN (FCNN) for complicated curve detection. As
Fig. 1(b) shows, we give a local fractal model of image and propose a curve detector
under an iterative adaptive ﬁltering framework. Speciﬁcally, in each iteration, we take
patches of image as local fractals, and compute their fractal dimensions accordingly. A
directional ﬁlter is designed adaptively for each patch of image according to the anal-
ysis of gradient ﬁeld, and the ﬁltering result is further enhanced via preserving fractal
dimension. Inspired by the iterative ﬁltering strategy in [26], we apply the steps above
repeatedly to obtain the features of curves, and detect curves via unsupervised or super-
vised methods. In particular, we demonstrate that such a pipeline can be implemented
via a convolutional neural network, as shown in Fig. 1(d). The CNN is interpretable
from a geometrical viewpoint — the convolution layer of CNN corresponds to an ori-
ented ﬁlter bank replacing orientation-adaptive ﬁltering while the nonlinear layer ap-
proximately achieves the invariance of local fractal dimension. Their intra-structures
are shown in Figs. 1(e) and 1(f). Applying backpropagation algorithm for supervised
case and predeﬁned parameters (ﬁlters) for unsupervised case, we achieve curve detec-
tion via the fractal-based CNN.

We test our method on a collected material AFM image dataset (will be released
along with the source code) and compare it with existing curve detectors. Experimental
results show that our method is promising in most situations, especially in the noisy and
texture-like cases. Overall, the contributions of our work are mainly in three aspects:

– To the best of our knowledge, our work is the ﬁrst attempt to combine fractal-based
image model with convolutional neural networks. It is also perhaps the ﬁrst time to
interpret CNNs from a (fractal) geometry perspective.

– Our method connects traditional handcrafted ﬁlter-based curve detector with a CNN
architecture. It establishes a bridge on the gap between ﬁlter-based curve detectors
and learning-based especially CNN-based ones. This connection also allows us to
instantiate a new predeﬁned CNN that can work in an unsupervised setting, differ-
ent from most of its peers known for their ravenous appetite for labeled data.

– We demonstrate a meaningful interdisciplinary application of our curve detector
in computational material science. Additionally, a material AFM image dataset is
collected and will be released with this paper for future public research.

4

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

2 Related Work

Curve Detection: As aforementioned, early curve detectors are based on diverse trans-
formations. Besides the classical Hough transformation method [13], the curvelet-based
curve detector is proposed in [16], which takes advantage of the directionality of curvelets.
Similarly, applying another kind of directional wavelets called wave atoms, a scratch de-
tector for movie restoration is proposed in [17]. Besides the directionality, the multiscale
property of curve is considered via applying multiscale Fourier transformation [14] and
Gabor transformation [15], respectively. These methods principally apply the strategy
of structural ﬁltering — constructing a ﬁlter bank with various directional ﬁlters and
detecting the local strong response to certain directions in the ﬁltering results. Focusing
on curve and line segment detection, currently, the parameterless ﬁtting model pro-
posed in [6,7] achieves the state-of-the-art. Beyond these manually designed methods,
the learning-based approaches become popular as a huge amount of labeled images be-
come available [3,27]. Focusing on contour detection, which can be viewed as a prob-
lem related to curve detection, a fast detector based on structured forests is trained
in [2]. More recently, with the help of deep learning techniques, the CNN-based con-
tour detectors are proposed in [19,18,1,28]. These methods learn their parameters on a
large dataset to obtain representative ﬁlters in convolution layers, and thus, have more
powerful generalization ability to deal with challenging cases.

Fractal Analysis: Many complex natural scenes can be modeled as fractals [29,30].
In the ﬁeld of computer vision, fractal analysis has been proven to be a useful tool for
modeling textures. Taking textures as fractals, the work in [31] learns local fractal di-
mensions and lengths as features of textures. Similarly, the work in [32] learns the spec-
trum of fractal dimension as texture features via the box-counting method [33]. Both
methods take advantage of the bi-Lipschitz invariance property of fractal dimension
for texture classiﬁcation, whose features are very robust to the deformation and scale
changing of textures. It should be noted that the fractal model is not limited to analyze
textures. Because the local self-similarity of image is often ubiquitous both within and
across scales [34,35], natural images can also be modeled as fractals locally. Recently,
the fractal model of natural image is applied to image super-resolution [36,37], where
the local fractal analysis is used to enhance image gradient adaptively.

CNNs for Low-and Middle-level Vision: Convolutional neural networks, espe-
cially the deep CNNs, have been widely used to extract visual features from images,
which have many successful applications, e.g., digits recognition [38], texture classiﬁ-
cation [22], object detection [39]. In these years, this useful tool has been introduced
into many low-and middle-level vision problems, e.g., image reconstruction [40,41],
super-resolution [42], dynamic texture synthesis [43], and contour detection mentioned
above, and achieved encouraging results. For comprehending CNNs in depth, many at-
tempts have been made. Many existing feature extraction methods have been proven to
be equivalent to deep CNNs, like deformable part models in [23] and random forests
in [25]. In contrast to the above methods under a probabilistic setting, a pre-trained deep
learning model called scattering convolution network (SCN) is proposed in [21,22,44].
This model consists of hierarchical wavelet transformations and translation-invariant
operators, which explains deep learning from the viewpoint of signal processing.

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

5

Fig. 2. Given a line segment, we transform it into N = 4 analogues with scaling factor s = 1
3 .
Repeating the transformation on each analogue, we obtain a fractal so-called the Von Koch curve
with D = log N− log s = 1.262. It is with 1 topological dimension but inﬁnite length (unmeasurable).

3 Proposed Curve Detector

In this section, we introduce our fractal-based image model and show the derivation
of local fractal dimension. According to the model, we propose an iterative curve de-
tector combining fractal-based enhancement with adaptive ﬁlters, which preserves the
invariance of local fractal dimension in the phase of feature extraction. Applying the
proposed detector, we can obtain robust representation of curves step-by-step.

3.1 Fractal-based Image Model and Fractal Dimension Estimation
As shown in Fig. 2, a typical fractal is set as follows: 1) transforming a geometry G
to N analogues with scaling factor s; 2) applying the transformation inﬁnitely on each
analogue. The union of the analogues is a fractal, denoted as F. The fractal F is a
“Mathematical monster” that is unmeasurable in the measure space of G. Therefore,
the analysis of fractal is mainly based on the Hausdorff measure [29], which gives rise
to the concept of fractal dimension. The fractal dimension is involved by a power law
of measurements across multiple scales. Speciﬁcally, there always exists a power law
between the quantities N (as a measurement) and s, i.e., N ∝ 1
sD . Here D is deﬁned as
fractal dimension, which is larger than the topological dimension of F.
In our work, we focus on detecting curves in the image f (X), where X ⊂ R2 is
the union of the coordinates of pixels. Each coordinate of pixel is denoted as x ∈ X.
We propose a fractal-based model for the image. Speciﬁcally, we model X as a union
of local fractals, and image f (X) as (X, µ), where µ is a measurement supported on
the fractal set X. According to the power law of measurements mentioned above, we
have µ(Br(x)) ∝ (2r)D, where Br(x) is a ball centering at x with radius r and D is
the fractal dimension of X. Here, we use the intensity of pixel f (X) as the measure µ
directly, and the local fractal dimension at x is

(cid:90)

D(x) = lim
r→0

log µ(Br(x))

log 2r

(cid:16) x2

(cid:17)

, µ(Br(x)) =

y∈Br(x)

Gr ∗ f (y)dy.

(1)

1√

r2σ2

2πrσ

exp

is a Gaussian kernel deﬁned as [32,36]. σ is a pre-
where Gr =
deﬁned constant. “∗” indicates the valid convolution. In practice, we estimate the lo-
cal fractal dimension in (1) numerically by linear regression. Speciﬁcally, we calcu-
late sample pairs {log r, log µ(Br(x))}r={1,2,...} by multiscale Gaussian ﬁltering, and
learn a linear model log µ(Br(x)) = D(x) log 2r + L(x) for all x ∈ X according
to (1). Here D(x) is fractal dimension of Br(x) under the measurement µ. exp(L(x))

16

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

is the value of measurement µ in the unit ball (2r = 1), which is interpreted as the D-
dimensional fractal length in [31]. Algorithm 1 gives the scheme of fractal dimension
estimation.

Algorithm 1 Fractal Dimension Estimation
1: Input: f (X), pre-deﬁned σ, the number of scales R.
(cid:80)R
2: Output: Fractal dimension D(X).
3: For r ∈ {1, ..., R}, perform a convolution of f (X) with Gr to get µ(Br(x)) for each x.
r=1 | log µ(Br(x)) − D log 2r − L|2.
4: For x ∈ X, compute D(x), L(x) = arg minD,L
5: D(X) = {D(x)}x∈X.

Fractal dimension contains important structural information of image. For detect-
ing structures, e.g., curves in images, robustly, we should preserve fractal dimension
from changing after feature extraction. A signiﬁcant property of fractal dimension is its
invariance to bi-Lipschitz transform.
Theorem 1 (Bi-Lipschitz Invariance). For a fractal F with fractal dimension D, its
bi-Lipschitz transformation g(F) is still a fractal, whose fractal dimension Dg = D.
The proof is shown in the appendix section. The theorem claims that the fractal dimen-
sion of image should be invariant to geometric transformations and deformations of
image. Unfortunately, the invariance does not hold after ﬁltering processes. According
to (1), we can ﬁnd that the fractal dimension is not unique, whose value depends on the
choice of measurement µ. The ﬁltering processes actually change the measurement µ
of fractal X, rather than the fractal itself. As a result, we cannot ﬁnd a ﬁlter ensuring
the fractal dimension of ﬁltering result to be exactly same with that of original image.
Although ﬁltering processes inevitably change fractal dimension, it is possible to
ﬁnd an adaptive ﬁlter suppressing the expected change between original fractal dimen-
sion and ﬁltered one. Denote the proposed ﬁlter as F , the measurement and the fractal
dimension of ﬁltering result as µF , DF , respectively. According to (1), we have

D(x) − E(DF (x)) = lim
r→0

= lim
r→0

1

log 2r

1

log 2r

log

log

(cid:82)

E(µD(Br(x)))

(cid:82)
µ(Br(x))
y∈Br(x) Gr ∗ f (y)dy
y∈Br(x) Gr ∗ E(F ) ∗ f (y)dy

(2)

,

where E(·) computes the expectation of random variable. Obviously, to minimize the
expected change between D(x) and DF (x), the expectation of the ﬁlter should be as
close to impulse function δ(x) as possible. Motivated by the analysis above, we propose
the following adaptive fractal dimension-preserved ﬁlters, whose algorithmic scheme is
illustrated in Fig. 1(b).

3.2 Curve Detection via Iterative Adaptive Filtering
Orientation-adaptive Filtering: Like existing works, the proposed ﬁlters should have
strong capabilities of describing local orientations of curves. Following [45], we com-

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

7

pute the orientation ﬁeld of image. For each pixel x, we compute the smoothed gradient
in its neighborhood B(x) as G = [vec(∇h(G ∗ f (B(x))), vec(∇v(G ∗ f (B(x)))] ∈
R|B|×2. Here G is a Gaussian ﬁlter, |B| is the cardinality of the neighborhood, ∇h
(∇v) is partial differential operator along horizontal (vertical) direction, and vec(·) for-
mulates input as a vector. The eigenvector corresponding to the largest eigenvalue of
G(cid:62)G, denoted as u = [uh, uv](cid:62) ∈ R2, indicates the orientation information of x.
Speciﬁcally, we propose an oriented ﬁlter corresponding to x in the polar coordinate
is the strongest orientation at x. Its
system, denoted as Fθ, where θ = arctan
element Fθ(r, φ) satisﬁes

(cid:16) uh

(cid:17)

uv

if r = 0, or φ ∈ {θ, θ + π} and 0 < r ≤(cid:112)|B|,

(cid:40) 1|B| ,

(3)

Fθ(r, φ) =

0,

otherwise.

Obviously, the ﬁlter is normalized and only has responses to the pixels along the strongest
orientation. Therefore the ﬁltering result at x is fF (x) = Fθ ∗ f (B(x)).

The proposed oriented ﬁlters satisfy the following proposition:

Proposition 1. If the distribution of pixel’s orientation is uniform, then the expectation
value of the ﬁlters in (3) is an impulse function δ(x), where δ(0) = 1|B| .
The proof is given in the appendix section. Fig. 3 visualizes several typical oriented
ﬁlters and their mean in the right most, which further veriﬁes the proposition. Recalling
(2), we can ﬁnd that the proposition indicates that the proposed adaptive ﬁlters {Fθ}
tend to preserve the expected value of fractal dimension after ﬁltering.

Fig. 3. The ﬁlters Fθ’s with θ = {0, π
average of the ﬁlters. It is an estimation of E(F ), which is close to an impulse function.

30 } are shown from left to right. The last one is the

30 , ..., 29π

Preserving Fractal Dimension: For further suppressing the change of local fractal
dimension, we apply a post-processing after obtaining ﬁltering result fF (X). For each
pixel x, although the fractal dimension DF (x) with the measurement µF (Br(x)) is
not equal to the original D(x) with µ(Br(x)), we can apply a transformation T to
µF (Br(x)), such that the fractal dimension with the new measurement T (µF (Br(x))),
denoted as DT◦F (x), is equal to D(x). According to the deﬁnition of fractal dimension
in (1) and the relationship log µ(Br(x)) = D log 2r + L given by Algorithm 1, the
proposed transformation T = (·)α, where α = D(x)

DF (x), such that

log T (µF (Br(x))) =

D(x)
DF (x)

log µF (Br(x)) =

D(x)
DF (x)

(DF (x) log 2r + LF (x))

(4)

= D(x) log 2r +

LF (x)
DF (x)

= DT◦F (x) log 2r + LT◦F (x).

8

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

According to the deﬁnition of measurement in (1), the transformation is applied to
fF (X) directly when 2r = 1. Therefore, for the ﬁltering result fF (x) at x, we further
transform it as

fT◦F (x) =

(cid:107)fF (B(x))(cid:107)
F (B(x))(cid:107) f α
(cid:107)f α

F (x), α =

D(x)
DF (x)

.

(5)

Here the term (cid:107)fF (B(x))(cid:107)
fractal length.

F (B(x))(cid:107) preserves the energy of ﬁltering result, which merely changes
(cid:107)f α
Proposed Curve Detector: Taking the adaptive fractal dimension-preserved ﬁlter
as a tool for extracting features of curves, we propose an iterative algorithmic frame-
work for detecting curves. As Fig. 1 shows, the orientation-adaptive ﬁltering and the fol-
lowing post-processes are applied iteratively, and the features corresponding to curves
are extracted accordingly. Fig. 4 illustrates the enlarged output in each iteration. We can
ﬁnd that the pixels corresponding to curves are more and more discriminative. When
the labels of curves are available, we learn the curve detector as a binary classiﬁer with
the help of logistic regression. Sampling the ﬁnal ﬁltering result into patches with over-
laps, we learn the parameters of the sigmoid function. On the contrary, if the labels are
unavailable, we simply apply a threshold [12] to convert the ﬁltering result to a binary
image.

(a) Original image

(b) #1 Iteration

(c) #3 Iteration

(d) #5 Iteration

Fig. 4. Illustration of the iterative adaptive ﬁltering process. Best viewed by magniﬁcation.

4 CNN-based Re-instantiation

In this section, we will show that the curve detector introduced in the previous sec-
tion can be re-instantiated via a convolutional neural network, as Fig. 1(d) shows. The
convolution layer can be explained as a structural ﬁlter bank and the nonlinear layer
preserves local fractal dimensions approximately.

4.1 Convolution Layer
Our orientation-adaptive ﬁlters actually can be implemented via an oriented ﬁlter bank.
Speciﬁcally, the ﬁltering process can be rewritten as

fF (x) = Fθ ∗ f (B(x)) = max(F ∗ f (B(x))),

(6)

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

9
where F = {Fθ} is the stack of all oriented ﬁlters. max(·) only preserves the ﬁltering
result having the maximum response.

4.2 Nonlinear Layer
Focusing on curve detection, the proposed fractal dimension preserving process can
also be approximated via the following nonlinear process:

fT◦F (x) ≈

=

(cid:107)fF (B(x))(cid:107)

(cid:107) max(fF (B(x)), 0)2(cid:107) max(fF (x), 0)2
M ∗ max(fF (B(x)), 0)2 max(fF (x), 0)2.

M ∗ fF (B(x))

(7)

D

k=1Xi) = (cid:80)∞

Here the normalization term is implemented via a convolution, where M is an all-one
ﬁlter, which sums the intensities in the neighborhood B(x) for each x.
A rectiﬁed linear unit (ReLU, max(·, 0)) is applied to the ﬁltering result for guaran-
teeing the nonnegativity. This operator is applied when the ﬁlters of the CNN are trained
from data. It is unnecessary when using our pre-trained oriented ﬁlter because the ﬁl-
tering result is always nonnegative. Instead from the viewpoint of neuroscience, we
explain the ReLU operator based on fractal analysis. It ensures the ﬁltering result to be
a valid measurement (as the measurement used in the box-counting method [33,32]): A
valid measurement µ deﬁned on the set X satisﬁes nonnegativity µ(X) ≥ 0, countable
additivity µ(∪∞
k=1 µ(Xi), and null empty set µ(∅) = 0 simultaneously,
where X ⊂ X. The null empty set is satisﬁed by our ﬁltering result naturally while the
ReLU operator guarantees the nonnegativity and countable additivity of ﬁltering result
even if the trained ﬁlter generates negative outputs.
Additionally, the transformation operator (·)

DF is replaced via a square operator.
This approximation is reasonable for the problem of curve detection. On one hand, we
model the coordinates of image X as a set of fractals, whose fractal dimension must
be in the interval [2, 2 + 1], where 2 is the topology dimension of 2D geometry, and
0 ≤ 1 < 1 because the fractal dimension of a fractal generated from a 2D geometry
via 2D transformation cannot reach to 3. On the other hand, the ﬁltering result shown in
Fig. 4 provides us with an explicit representation of curves. Here we can also model the
curves as a set of fractals with fractal dimension in the interval [1, 1 + 2), where 1 is
the topology dimension of curve (1D geometry) and 0 ≤ 2 < 1. Based on the fractal-
, 2 + 1). Therefore, when 1 and 2 are small, we
based model, we have D
DF
can estimate D
DF

As a result, the convolution layer and nonlinear layer of our fractal-based CNN
(FCNN) can be implemented via the architecture shown in Figs. 1(e) and 1(f). When the
labels of curves are available, we can also add a sigmoid layer to the end of the CNN and
train the model via traditional backpropagation algorithm. When the training data is not
available, we just use the predeﬁned oriented ﬁlter bank and set a threshold for the ﬁnal
output. In contrast to many CNN models with a disadvantage of their ravenous appetite
for labeled training, we believe the adaptability for unlabeled data of our method is
perhaps due to the fact that we instantiate our tailored CNN from the fractal-based
geometry perspective. The proposed curve detection algorithm is shown in Algorithm 2.

∈ ( 2

1+2

≈ 2.

10

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

Algorithm 2 Fractal-based CNN for Curve Detection
1: Input: Image f (X), Filter bank F , the number of layer N.
2: Output: Binary map b(X) corresponding to curves.
3: For n = 1, ..., N, obtain fT◦F (X) from f (X) via (6,7), and set f (X) = fT◦F (X).
4: Unsupervised: b(X) = binary(f (X)).
5: Supervised: b(X) = sigmoid(β(cid:62)P ). β is learned parameters, P are patch matrix of f (X).

4.3 Further Comparisons and Analysis

We compare our FCNN model (see Fig. 1(d)) with our iterative adaptive ﬁltering algo-
rithm (see Fig. 1(b)) and existing CNN models:

FCNN v.s. Iterative Adaptive Filter: The proposed FCNN can be viewed as a fast
implementation of the iterative adaptive ﬁltering algorithm in section 3.2. Firstly, the
orientation-adaptive ﬁltering is approximately achieved by an oriented ﬁlter bank. The
orientation of ﬁlter θ is no longer computed from the eigenvector of the local gradient
matrix, but sampled uniformly from the interval [0, π] (as Fig. 3 shows). Although such
an approximation reduces the accuracy of the description of orientation, it accelerates
the ﬁltering process greatly — instead of doing eigen-decomposition for each pixel, we
just need to perform several convolutions of images. Secondly, the ratio between the
fractal dimension and the original one is replaced by a ﬁxed value, such that we do not
need to apply Algorithm 1 to estimate fractal dimension. As a result, the computational
complexity of adaptive ﬁltering is O(|X||B|3 + |X|R3) in each iteration, where the
ﬁrst term corresponds to orientation-adaptive ﬁltering and the second term corresponds
to fractal dimension estimation, while the FCNN is at most O(|X||B|) in each layer.
The acceleration is further veriﬁed in the following experiments.

FCNN v.s. Scattering Convolution Network: To our FCNN model, the most re-
lated work might be the scattering convolution network (SCN) in [22,44,46]. Similar
to our work, SCNs also use predeﬁned ﬁlters, i.e., Morlet wavelets, in the network. It
means that similar to SCN, our FCNN can be used as a predeﬁned model for features
extraction and unsupervised learning when labels are not available. However, there are
several important differences between our FCNN model and SCNs. Firstly, SCNs aim
to extract discriminative features from images for recognition and classiﬁcation, while
our FCNN model focuses on low-and middle-level vision problems, i.e., curve detec-
tion. Secondly, the nonlinear layer of SCN applies multiple nonlinear operators to en-
hance the invariance of feature to geometric transformation. For example, the absolute
operator |·| is applied to achieve translation invariance. In our work, the nonlinear layer
aims to keep the fractal dimension from changing such that the local structural infor-
mation of image will be preserved. The geometric invariance of feature is not our goal.
Finally, different from wavelet transformation, FCNNs do not down-sample ﬁltering
result (i.e., pooling operation).

FCNN v.s. other CNNs: Compared with other CNNs, our FCNN model also has
many distinctions. Firstly, only are 2D convolutions applied in our model. Given the
stacked images generated via our ﬁlter bank, we preserve the maximum response di-
rectly, rather than apply pooling and 3D convolutions. Such a difference implies that our
model contains much fewer parameters than other CNNs and merely occupies limited

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

11

storage. Secondly, our FCNN model is established based on local fractal analysis of im-
age, which is suitable for curve detection. Each of its modules can be well-interpreted.
As a result, the selection of hyper-parameters, e.g., the number of ﬁlters, α in (4), can be
guided according to the fractal-based image model. On the contrary, however, there still
is often an absence of a sound theory behind the traditional CNNs even if focusing on
a speciﬁc vision problem, and the selection of its hyper-parameters is rather empirical.
Limitations: Differing from previous CNNs, our FCNN model is based on local
fractal analysis of image. This fact implies that our model takes more attention to cap-
ture the local structural information of image, rather than the semantic meanings hidden
in the image. As a result, our FCNN model in this paper might has limited capabilities
of learning features for high-level vision problems. In this regard, our approach is suited
to the material AFM images as studied in the paper.

5 Experiments

5.1

Implementation Details

We test our FCNN-based curve detector with the original iterative adaptive ﬁlter-based
detector (IAF) in both unsupervised and supervised cases. Speciﬁcally, we consider
these two detectors with thresholding-based binary processing (BP) and logistic re-
gression (LR) as the last layer, respectively. Therefore, the proposed methods include
IAF+BP, IAF+LR, FCNN+BP, and FCNN+LR. Both IAF and FCNN are imple-
mented via MATLAB. The iteration number of IAF is set to be 7, so the depth of FCNN
is 14. The size of ﬁlters used in IAF and FCNN is 9× 9, and the number of oriented ﬁl-
ters used in FCNN is 30, as shown in Fig. 3. In the supervised case, 40, 000 patches with
size 9×9 are sampled from the output images of IAF or FCNN to training parameters of
the sigmoid layer. A half of training patches whose central pixels correspond to curves
are labeled as positive samples, while the rest patches are negative ones. For further
demonstrating the superiority of our method, we consider the following competitors:

Basic image processing: the direct binary processing via thresholding intensity
(BPI), the binary processing after edge-preserved ﬁltering, e.g., guided ﬁltering [47]
(FBPI), and the state-of-the-art curve and line segment detector (ELSD) in [7]. The
hyperparameters of the ELSD is set as default values.

Learning-based methods: the simple logistic regression LR and the classical CNN
so-called LeNet [38] are trained according to patches of image and labels of curves.
Speciﬁcally, the logistic regression is trained by 40, 000 patches with size 9 × 9 sam-
pled randomly from training images. The training samples of the LeNet is also 40, 000
patches of images, the only difference is that the size of the patches is 28 × 28. In the
testing phase, each patch of testing image will be classiﬁed and its label will be used as
the corresponding pixel value of ﬁnal binary map.

Collected AFM image dataset: The images in this study are 40 atomic force mi-
croscopy (AFM) phase images of nano-ﬁbers. Each image is taken in tapping mode at a
10 µm and with size 512 × 512. Generally, the images are noisy and low-contrast. The
ground truth of curves are extracted by a semi-automatic tool called FiberApp [11].
The tool requires user’s identiﬁcation of ﬁbers’ endpoints and utilizes a combination

12

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

of active contours and the A* shortest path algorithm for backbone ﬁtting. Similar to
contour detection [3,27,2], we use the standard metrics to evaluate results for various
curve detectors, including the optimal F-score with ﬁxed threshold (ODS), the optimal
F-score with per-image best threshold (OIS), and average precision (AP). Additionally,
the speed of our FCNN-based method (runtime per image) is investigated as well.

5.2 Comparison Results

Table 1 gives comparison results for various methods, and Fig. 5 visualizes some typical
results. We can ﬁnd that:

The intensity of the material image provides important information for detecting
curves. The results of BPI shows that purely replying on the intensity of raw data still
achieves reasonable detection results to some degree. However, to our surprise, after
applying edge-preserving ﬁltering, the results based on ﬁltered images degrade a little.
It might due to the heavy noise and low contrast in the images, which leads to unreliable
ﬁltering results — some curves are smoothed and the structural information are lost.

Essentially, ELSD aims to detect line segments and ellipse curves of rigid bodies in
natural images. In our case, however, the curves of nanoﬁbers are much more complex,
which are not ideal lines or curves. As a result, although the precision of ELSD is too
low, which means that lots of curves are not detected, and accordingly, the ODS and
OIS are very low as well. Note that we also test ELSD with various conﬁgurations of
hyperparameters, but the results are not improved. Therefore, ELSD seems unsuitable
for detecting complicated curves in our case.

The learning-based approaches, i.e., LR and LeNet, achieve at least comparable
results to basic image processing methods. Speciﬁcally, the ODS and OIS of LR are
slightly lower than those of BPI and FBPI, but its precision is much better than that
of them. It means that more curves are detected successfully while a little more non-
curve pixels are detected wrongly. The LeNet, on the other hand, obtains better results
than BPI and FBPI on all three measurements. These results prove that learning-based
approaches can improve curve detection results even if the training samples are noisy,
and we believe they can achieve better results with the increase of training samples.

The proposed methods based on iterative adaptive ﬁltering and its FCNN-based im-
plementation achieve the best results on the collected material AFM image dataset. It
should be noted that although FCNN can be viewed as an implementation of IAF, it
outperforms IAF — among these methods, FCNN+LR is the best on ODS and OIS
while the FCNN+BP is the best on AP. A potential explanation for this interesting phe-
nomenon might be that IAF is more sensitive to the noise in the image. Speciﬁcally,
the ﬂexibility of IAF on selecting orientation might be a “double-edged sword”. Heavy
noise in the image would lead to bad estimate of ﬁlter’s orientation and have negative
inﬂuences on ﬁltering results. The FCNN, however, uses a predeﬁned oriented ﬁlter
bank. The limited options of orientations help to suppress the inﬂuence of noise. Ad-
ditionally, without patch-based fractal dimension estimation and eigen-decomposition,
the proposed FCNN method accelerates IAF obviously, which veriﬁes the computa-
tional complexity discussed in previous section.

Compared with BPI and FBPI, our IAF+BP and FCNN+BP use our proposed meth-
ods as a pre-processing of images and obtain more representative representation of

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

13

Table 1. Comparison for various methods.

Method
ODS
OIS
AP

BPI FBPI ELSD LR LeNet
0.656 0.646 0.058 0.637 0.668
0.725 0.724 0.058 0.703 0.710
0.625 0.598 0.030 0.702 0.637
Time (sec) 0.012 0.307 2.981 0.314 3.420

IAF+BP FCNN+BP IAF+LR FCNN+LR
0.712
0.734
0.692
273.8

0.740
0.777
0.709
1.054

0.688
0.716
0.780
0.385

0.726
0.760
0.691
274.9

curves. Similarly, our IAF+LR and FCNN+LR can also be viewed as an extension of
LR. Experimental results show that using proposed methods as a pre-processing or fea-
ture extraction method of images, the performance can be improved greatly.

The visualization results further verify the superiority of our methods. In Fig. 5,
each subﬁgure shows enlarged image, ground truth, and the detection results of various
methods. We can ﬁnd that the basic image processing methods, i.e., BPI, FBPI, ELSD,
cannot deal with these noisy and texture-like images. The detection results of BPI and
FBPI contain may broken segments and isolated points, which cannot represent curves.
What is worse, these methods are not robust to the local change of intensity. When the
mean of intensity in various local regions has large changes, these methods generally
fail, as Figs. 5(a) and 5(b) show. ELSD fails to detect most of curves. Only some line
segments appear in its detection results. In our opinion, it is more suitable for detecting
clear lines and curves of regular rigid bodies. The learning-based approaches achieve
much better results than previous methods and are robust to the changes of local inten-
sity. For LR and LeNet, most of curves are detected correctly. Although some isolated
points and broken segments appear in their results, the number of these artifacts is much
smaller than those in BPI and FBPI. Our method, FCNN+LR, achieves the best visual
effects: fewer artifacts and more complete curves appear in our results.

6 Conclusions

In this paper, we propose a novel curve detector based on a fractal-based CNN. Taking
an image as a union of local fractals with intensity-based measurement, we combine
orientation-adaptive ﬁlters with fractal dimension preserving processes, and propose
an iterative framework to extract local features for curves. We further reinterpret and
implement our model by a CNN architecture, which generates geometric insights to
the CNN based models in general. Our work is the ﬁrst attempt to combining fractal-
based image model with neural networks. It achieves encouraging results of curve de-
tection, especially for texture-like noisy images. Our approach can be utilized as a pre-
processing step or feature extraction method for images. We will combine our work with
other existing models and learning methods in the future. Additionally, focusing on the
limitations of our FCNN model mentioned before, we plan to explore the potentials of
FCNN in high-level vision problems, e.g., object recognition and detection.

14

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

7 Appendix

7.1 Bi-Lipschitz Invariance of Fractal Dimension (Proof of Theorem 1)
Proof. The mapping g : A (cid:55)→ B is bi-Lipschitz transform if and only if g is invertible
and there exists 0 < c1 ≤ c2 ≤ ∞ so that c1(cid:107)x − y(cid:107) ≤ (cid:107)g(x) − g(y)(cid:107) ≤ c2(cid:107)x − y(cid:107)
holds for all x, y ∈ A. According to the deﬁnition, for arbitrary two points x, y ∈ F,
we have

(x) ⊂ Br(g(x)) ⊂ B r

c1

B r
c2

(x), µ(B r
c2

(x)) ≤ µ(Br(g(x))) ≤ µ(B r

c1

(x)). (8)

Recall the relationship that log µ(Br(x)) = D log 2r + L. The following condition
holds for all r’s:

D log

2r
c2

+ L ≤ Dg log 2r + Lg ≤ D log

2r
c1

+ L.

which implies Dg = D and L − D log c2 ≤ Lg ≤ L − D log c1.

(9)

(cid:3)

7.2 Proof of Proposition 1

Proof. According to the assumption, the expectation of the ﬁlters in (3) is

(cid:90) π

0

1
π

0

Eθ(Fθ) =

pθFθdθ,

pθ =

1
π

.

Eθ(Fθ(0, φ)) =

Fθ(0, φ)dθ =

(cid:90) π

0

For each element Fθ(r, φ), when r = 0, we have

(cid:90) π
When 0 < r ≤(cid:112)|B|, we have
When r > (cid:112)|B|, Eθ(Fθ(r, φ)) = 0. In summary, Eθ(Fθ) is the proposed impulse

Fθ(r, φ)dθ = lim
∆→0

1
π|B| dθ = lim
∆→0

2∆
π|B| = 0.

1
π|B| dθ =

1
|B| .

(cid:90) φ+∆

(cid:90) π

0

Eθ(Fθ(r, φ)) =

φ−∆

1
π

function.

(cid:3)

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

15

(a)

(b)

(c)

Fig. 5. Visual comparisons for various methods. Best viewed by magniﬁcation.

OriginalGround truthBPIFBPIELSDLRLeNetFCNN+LROriginalGround truthBPIFBPIELSDLRLeNetFCNN+LROriginalGround truthBPIFBPIELSDLRLeNetFCNN+LR16

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

References

1. Xie, S., Tu, Z.: Holistically-nested edge detection. In: ICCV. (2015)
2. Doll´ar, P., Zitnick, C.L.: Fast edge detection using structured forests. TPAMI 37(8) (2015)

1558–1570

3. Arbelaez, P., Maire, M., Fowlkes, C., Malik, J.: Contour detection and hierarchical image

segmentation. TPAMI 33(5) (2011) 898–916

4. Ma, Q., Goshi, D.S., Shih, Y.C., Sun, M.T.: An algorithm for power line detection and

warning based on a millimeter-wave radar video. TIP 20(12) (2011) 3534–3543

5. Park, J.W., Lee, J.W., Jhang, K.Y.: A lane-curve detection based on an lcf. Pattern Recogni-

tion Letters 24(14) (2003) 2301–2313

6. von Gioi, R.G., Jakubowicz, J., Morel, J.M., Randall, G.: Lsd: A fast line segment detector

with a false detection control. TPAMI (4) (2008) 722–732

7. P˘atr˘aucean, V., Gurdjos, P., Von Gioi, R.G.: A parameterless line segment and elliptical arc

detector with enhanced ellipse ﬁtting. In: ECCV. (2012)

8. Yang, H., Lindquist, W.B.: Three-dimensional image analysis of ﬁbrous materials. In: In-
ternational Symposium on Optical Science and Technology, International Society for Optics
and Photonics (2000) 275–282

9. Takacs, C.J., Treat, N.D., Kramer, S., Chen, Z., Facchetti, A., Chabinyc, M.L., Heeger, A.J.:

Remarkable order of a high-performance polymer. Nano letters 13(6) (2013) 2522–2527

10. Jordens, S., Isa, L., Usov, I., Mezzenga, R.: Non-equilibrium nature of two-dimensional
isotropic and nematic coexistence in amyloid ﬁbrils at liquid interfaces. Nature communica-
tions 4 (2013) 1917

11. Usov, I., Mezzenga, R.: Fiberapp: an open-source software for tracking and analyzing poly-
mers, ﬁlaments, biomacromolecules, and ﬁbrous objects. Macromolecules 48(5) (2015)
1269–1280

12. Otsu, N.: A threshold selection method from gray-level histograms. Automatica 11(285-296)

(1975) 23–27

13. Duda, R.O., Hart, P.E.: Use of the hough transformation to detect lines and curves in pictures.

Communications of the ACM 15(1) (1972) 11–15

14. Calway, A., Wilson, R.: Curve extraction in images using the multiresolution fourier trans-

form. In: ICASSP. (1990)

15. Mehrotra, R., Namuduri, K.R., Ranganathan, N.: Gabor ﬁlter-based edge detection. Pattern

Recognition 25(12) (1992) 1479–1494

16. Starck, J.L., Cand`es, E.J., Donoho, D.L.: The curvelet transform for image denoising. TIP

11(6) (2002) 670–684

17. Xu, H., Zhai, G., Chen, L., Yang, X.: Automatic movie restoration based on wave atom
transform and nonparametric model. EURASIP Journal on Advances in Signal Processing
(1) (2012) 1–19

18. Bertasius, G., Shi, J., Torresani, L.: Deepedge: A multi-scale bifurcated deep network for

top-down contour detection. In: CVPR. (2015)

19. Shen, W., Wang, X., Wang, Y., Bai, X., Zhang, Z.: Deepcontour: A deep convolutional

feature learned by positive-sharing loss for contour detection. In: CVPR. (2015)

20. Lee, H., Ekanadham, C., Ng, A.Y.: Sparse deep belief net model for visual area v2. In: NIPS.

(2008)

21. Mallat, S.: Group invariant scattering. Communications on Pure and Applied Mathematics

22. Bruna, J., Mallat, S.: Invariant scattering convolution networks. TPAMI 35(8) (2013) 1872–

65(10) (2012) 1331–1398

1886

A Fractal-based CNN for Detecting Complicated Curves in AFM Images

17

23. Girshick, R., Iandola, F., Darrell, T., Malik, J.: Deformable part models are convolutional

neural networks. In: CVPR. (2015)

24. Zheng, S., Jayasumana, S., Romera-Paredes, B., Vineet, V., Su, Z., Du, D., Huang, C., Torr,

P.H.: Conditional random ﬁelds as recurrent neural networks. In: ICCV. (2015)

25. Patel, A.B., Nguyen, T., Baraniuk, R.G.: A probabilistic theory of deep learning. arXiv

preprint arXiv:1504.00641 (2015)

26. Milanfar, P.: A tour of modern image ﬁltering: New insights and methods, both practical and

theoretical. Signal Processing Magazine 30(1) (2013) 106–128

27. Zhang, C., Ruan, X., Zhao, Y., Yang, M.H.: Contour detection via random forest. In: ICPR.

(2012)

28. Shen, L., Wee Chua, T., Leman, K.: Shadow optimization from structured deep edge detec-

tion. In: CVPR. (2015)

29. Mandelbrot, B.B.: The fractal geometry of nature. Volume 173. Macmillan (1983)
30. Pentland, A.P.: Fractal-based description of natural scenes. TPAMI (6) (1984) 661–674
31. Varma, M., Garg, R.: Locally invariant fractal features for statistical texture classiﬁcation.

In: ICCV. (2007)

32. Xu, Y., Ji, H., Ferm¨uller, C.: Viewpoint invariant texture description using fractal analysis.

IJCV 83(1) (2009) 85–100

33. Falconer, K.: Fractal geometry: mathematical foundations and applications. John Wiley &

Sons (2004)

34. Glasner, D., Bagon, S., Irani, M.: Super-resolution from a single image. In: ICCV. (2009)
35. Freedman, G., Fattal, R.: Image and video upscaling from local self-examples. TOG 30(2)

(2011) 12

36. Xu, H., Zhai, G., Yang, X.: Single image super-resolution with detail enhancement based on

local fractal analysis of gradient. TCSVT 23(10) (2013) 1740–1754

37. Yu, L., Xu, Y., Xu, H., Yang, X.: Self-example based super-resolution with fractal-based

gradient enhancement. In: ICME Workshops. (2013) 1–6

38. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document

recognition. Proceedings of the IEEE 86(11) (1998) 2278–2324

39. Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object

detection and semantic segmentation. In: CVPR. (2014)

40. Xie, J., Xu, L., Chen, E.: Image denoising and inpainting with deep neural networks. In:

NIPS. (2012)

41. Burger, H.C., Schuler, C.J., Harmeling, S.:

Image denoising: Can plain neural networks

compete with bm3d? In: CVPR. (2012)

42. Dong, C., Loy, C.C., He, K., Tang, X.: Learning a deep convolutional network for image

super-resolution. In: ECCV. (2014)

43. Yan, X., Chang, H., Shan, S., Chen, X.: Modeling video dynamics with deep dynencoder.

In: ECCV. (2014)

44. Oyallon, E., Mallat, S.: Deep roto-translation scattering for object classiﬁcation. In: CVPR.

(2015)

45. Peyr´e, G.: Texture synthesis with grouplets. TPAMI 32(4) (2010) 733–746
46. Sifre, L., Mallat, S.: Rotation, scaling and deformation invariant scattering for texture dis-

crimination. In: CVPR. (2013)

47. He, K., Sun, J., Tang, X.: Guided image ﬁltering. In: ECCV. (2010)

