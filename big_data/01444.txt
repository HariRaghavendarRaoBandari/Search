6
1
0
2

 
r
a

M
4

 

 
 
]
T
G
.
s
c
[
 
 

1
v
4
4
4
1
0

.

3
0
6
1
:
v
i
X
r
a

Computational Aspects of Private Bayesian Persuasion

Yakov Babichenko∗

Siddharth Barman†

Abstract

We study computational questions in a game-theoretic model that, in particular, aims to
capture advertising/persuasion applications such as viral marketing. Speciﬁcally, we consider
a multi-agent Bayesian persuasion model where an informed sender (marketer) tries to per-
suade a group of agents (consumers) to adopt a certain product. The quality of the product is
known to the sender, but it is unknown to the agents. The sender is allowed to commit to a
signaling policy where she sends a private signal—say, a viral marketing ad—to every agent.
This work studies the computation aspects of ﬁnding a signaling policy that maximizes the
sender’s revenue.

We show that if the sender’s utility is a submodular function of the set of agents that adopt
the product, then we can efﬁciently ﬁnd a signaling policy whose revenue is at least (1 − 1/e)
times the optimal. We also prove that for submodular utilities, approximating the sender’s
optimal revenue by a factor better than (1 − 1/e) is NP-hard and, hence, the developed approx-
imation guarantee is essentially tight. When the sender’s utility is a function of the number of
agents that adopt the product (i.e., the utility function is anonymous), we show that an optimal
signaling policy can be computed in polynomial time. Our results are based on an interest-
ing connection between the Bayesian persuasion problem and the evaluation of the concave
closure of a set function.

1 Introduction

The advent of social networks has fundamentally changed the landscape of advertising. In recent
years much attention has been devoted to new forms of advertising such as viral marketing. The
goal of these marketing strategies is to advertise a product by leveraging the spread of inﬂuence
between consumers in a social network. To accomplish this objective, viral marketing aims to
identify “opinion leaders” in the network who can start a cascade of inﬂuence leading to large
adoption of the advertised product.

Motivated by such marketing applications, the notable work [17] addresses the algorithmic
problem of determining opinion leaders (inﬂuential individuals) in a social network; also see [9].
In [17] the process/dynamic via which inﬂuence spreads through a social network—i.e., the ex-
tent to which people in the network inﬂuence each other—is part of the input. More formally,
given a network, a dynamic that spreads inﬂuence in favor of a product through the network,
and a number n, [17] address the following question: which initial set of n consumers (inﬂuenced,
say, by giving free samples) maximize the ﬁnal adoption of the product, after the inﬂuence has
been spread by the underlying dynamic? Note that this model assumes that the marketer always
succeeds in persuading the initial n consumers to adopt the product.

∗Technion - Israel Institute of Technology. yakovbab@tx.technion.ac.il
†Indian Institute of Science. barman@csa.iisc.ernet.in

1

In order to better capture viral marketing, we can complement the work of [17] by considering
the following real-world aspects. The marketer might be unsuccessful in persuading a consumer
to adopt a product; furthermore, some consumers might be harder to persuade than others. An-
other factor that should be taken into account in this scenario is the asymmetry in information;
in particular, it is reasonable to assume that the marketer has more information about product’s
quality than the consumer. In this paper we focus on a model that is motivated by these obser-
vations, and we ask a question complementary to the one addressed in [17]: If a marketer tries to
persuade n consumers to adopt a product, what is her best strategy for doing so?

We consider a situation where a marketer, henceforth sender, tries to persuade potential con-
sumers, henceforth agents, to adopt a certain product. The asymmetry in the information can be
captured by a Bayesian model where the sender knows the state of nature (for instance, whether
the quality of the product is high or low), and agents do not. This state of nature might effect each
agent’s utility. The sender is allowed to commit to a (information) revelation policy regarding the
state of nature1 before the actual state of nature is realized. Agent’s information, that has been
received from sender, may effect her decision on whether to adopt the product. Thus, such partial
revelation of information may increase sender’s proﬁt.

The above described model is called Bayesian persuasion, and has been extensively studied in
recent years in contexts such as voting [2, 22], regulation policies [16, 23], and marketing [6, 3]. A
central thread of research in Bayesian persuasion has been the study of the optimal revenue of the
sender and the optimal policy to persuade agents. Hence, considering Bayesian persuasion with
a computational lens raises the following natural questions: Can we ﬁnd the sender’s optimal
policy in polynomial time? If not, then what fraction of the optimal revenue can be guaranteed by
policies that are efﬁciently computable? These questions form the basis of our work.

Bayesian persuasion and related algorithmic questions can be considered in two broad set-
tings. The ﬁrst setting considers the setup wherein the sender announces a public signal to the
agents, see, e.g., [22, 2]. The other setting models scenarios where the sender has a private commu-
nication channel with each agent, and is allowed to send a private signal—say, a viral marketing
ad—to each agent; see, e.g., [4, 24, 26]. In this paper we focus on latter setting.
Our Results and Techniques: Note that in a multiagent model the sender’s utility is a function of
the subset of agents that adopt the product. It has been observed that for various dynamics—via
which inﬂuence spreads in a network—the utility of the sender (in the ﬁnal adoption state, i.e.,
after the dynamic had been applied) is submodular, see [17] and references therein. Thus, settings
wherein the sender’s utility is submodular is of central interest in multiagent Bayesian persuasion
model. For submodular utility we develop a tight (1 − 1
e ) approximation of the sender’s optimal
policy. In particular, we establish the existence of a polynomial algorithm that ﬁnds a policy whose
revenue is at least (1 − 1
e ) times the optimal. On the negative side, we show that it is NP-hard to
approximate the sender’s optimal revenue by a factor better than (1 − 1

e ).

Anonymous utilities constitute another interesting class of utility functions. Here, the sender’s
utility is a function of the number of agents that adopt the product. We emphasize that agents’
utility functions may different for different agents (i.e., it might be harder to persuade some agents
than others). We show that for a sender with an anonymous utility function, an optimal policy
and the optimal revenue can be computed in polynomial time.

Our proofs are based on an interesting connection between the Bayesian persuasion model and

1Without the possibility to commit to a policy, the described model will correspond to a cheap talk model (see [8]),
wherein it is known that a sender’s messages are not reliable for the case at hand and, therefore, the sender has no
persuasion power.
The assumption that sender is allowed to commit can be motivated by a repeated interaction where agents may detect
deviations of the sender from the committed strategy, see [21] for a discussion on this issue.

2

the concave closer of a set function [19, 10, 25]. In Section 2—speciﬁcally, in Lemma 2.1—we show
that computation (or approximation) of sender’s optimal revenue with utility V : 2[n] → R+ is
(computationally) equivalent to evaluation (or approximation) of the concave closer of the func-
tion V , here [n] is the set of agents. Concave closer has been studied in the context of submodular
maximization, see, e.g., [7, 25], where it is primarily used as a technical tool to obtain approxima-
tion results. Unlike [7, 25], in the Bayesian persuasion problem the concave closer turns out to be
the core object.

We establish a tight approximation bound for computing the concave closer of monotone sub-
modular functions. Speciﬁcally, we develop a (1 − 1
e )-approximation algorithm for computing
the concave closure of monotone submodular functions. Our approximation result rests on an
approximation preserving reduction between computing the concave closure and the problem
of maximizing a monotone submodular function subject to a matroid constraint. Since the latter
problem admits a (1− 1
e ) approximation (see [7]) the desired result follows. For the hardness result,
we use tools from [18] and [12] which were developed to establish the hardness of approximating
the maximum social welfare in combinatorial auctions.

We establish the result for anonymous utility functions (which are not necessarily submodular)
by developing a polynomial-time algorithm for computing the concave closer of anonymous func-
tions. Such a polynomial-time algorithm might be of independent interest (beyond the Bayesian
persuasion framework), since the concave closer is a basic notion in discrete convex analysis (see
e.g., [20]).

Throughout the paper we consider a model wherein there are exactly two possible states of
nature (|Ω| = 2); such cases capture settings where binary distinctions (e.g., the quality of the
product is high or low) sufﬁce. In general, though, we need to address environments where there
are multiple states of nature and extending our results to handle models in which |Ω| > 2 is an
interesting direction for future work.

1.1 Additional Related Work

The current literature on Bayesian persuasion starts with the result of [13] who—building upon
the classical work by [5]—analyze the case of a single sender and a single receiver. Several exten-
sions of this model appear in recent papers, see, e.g., [1, 14, 15]. One natural extension, considers
the scenario where there are multiple receivers. The setting wherein the sender is only allowed
to send a public signal to the receivers is considered in [2, 22]. The complementary setting in
which the sender is allowed to send private signals to the receivers has been studied in [4, 24, 26].
Our result is most closely related to the work of [4] where the optimal policy and the optimal
revenue are characterized for supermodular utilities, supermajority utilities and submodular util-
ities which are also anonymous. In particular, we build upon the work of [4] with a computation
perspective. Speciﬁcally, we show that for every anonymous utility the optimal revenue can be
computed in polynomial time and provide tight approximations for general submodular utilities
(not necessarily anonymous). Our inapproximability result for submodular functions (Theorem
4.5) indicates that a closed-form expression for sender’s revenue that is derived in [4] for the
submodular anonymous case (and also the supermodular case) cannot have an analogous closed
formula for general submodular functions.

A recent, interesting paper by [11] studies the complexity of the Bayesian persuasion problem
in the case of single agent single receiver with n actions to the receiver and exp(n) states of nature.
[11] prove that in the case where payoff proﬁles are i.i.d. distributed (for all receiver’s actions) the
problem can be solved in polynomial time. The same is not true if payoff proﬁles are indepen-
dently distributed (but not identically)– the problem becomes #P-hard. Finally, they show that

3

the general problem (with arbitrary payoff proﬁles) can be approximately solved efﬁciently in the
query model, if we assume that receiver follows the recommended action by the sender in all cases
where no ε-better action (according to his belief) exists.2

2 Notations and Preliminaries

We consider a Bayesian persuasion model with a sender and n agents, [n] = {1, 2, ..., n}. Write
Ω = {ω0, ω1} to denote the two possible states of nature. Each agent i ∈ [n] has two actions, {0, 1},
and a utility function, ui, that depends on the state of nature and its own action, ui : Ω×{0, 1} → R.
All agents share a common prior distribution, where 0 < γ < 1 is the probability of state ω1, and
1 − γ of state ω0. Note that even though the agents’ utilities depend on the realized state of nature
they are a priori unaware of it. Throughout, we will use ∆(A) to denote the set of probability
distributions over set A.

[4] show that without loss of generality we can assume ui(ω0, 0) > ui(ω0, 1) and ui(ω1, 1) >
ui(ω1, 0) for all agents i ∈ [n]. In particular, it is show in [4] that we can efﬁciently reduce an
instance with arbitrary utility function to an instance wherein agents prefer to adopt the product
(i.e., play 1) in state space ω1 and prefer not to adopt it (i.e., play 0) in state ω0. Hence, throughout
the paper we will work with this assumption on agents’ utilities.

As mentioned earlier, the sender’s utility, V , depends on the set of agents that play action 1
(i.e., the set of agents that adopt the product), V : {0, 1}n → R. With a slight abuse of notation, for
a subset S ⊆ [n], we will use V (S) to denote V (1S ), where 1S is the characteristic vector of subset
S. We assume throughout that the sender’s utility monotonically increases with the set of agents
that play action 1: V (S) ≤ V (T ) for every S ⊆ T .

Note that we have restricted our attention to the case wherein the sender’s utility does not
depend on Ω. More generally, the sender’s utility can be deﬁned to be a function of the state space
as well, i.e., we can have V : Ω × {0, 1}n → R. It is shown in [4] that such a general case can always
be efﬁciently reduced to one in which V (ω0, S) = V (ω1, S) for every S. Hence, throughout the
paper we will focus on a utility functions, V , that are state independent.

As is typical is Bayesian persuasion models, we assume that only the sender knows the real-
ized state. The agents remain unaware of it. Furthermore, following the model of Kamenica and
Gentzkow [13] we allow the sender to commit in advance to an information revelation policy. In
this work, however, we allow the sender to reveal the information to every agent privately. This
translates to a state dependent signaling distribution. Formally, a policy of the informed sender
consists of n ﬁnite sets {Θi}i=1,...,n, where Θi is the private signal set of agent i, and a mapping
F : Ω → ∆(Θ1 × · · · × Θn). The sender can commit to a policy F that is known to the agents prior
to stage where the state ω is realized.

The sequence of the interaction between the sender and the agents is as follows. First, the
sender commits to a signaling policy F . Then, a state ω ∈ Ω is realized in accordance with the
prior (γ, 1 − γ). After that a proﬁle of signals θ = (θ1, . . . , θn) is generated according to the distri-
bution F (ω). Every agent i observes her private signal realization θi ∈ Θi and forms a posterior
πF (ω1|θi) = p(θi).

With the posterior in hand, agent i selects an action that maximizes her expected utility. In

other worlds, agent i plays action 1 if and only if

p(θi)ui(ω1, 1) + (1 − p(θi))ui(ω0, 1) ≥ p(θi)ui(ω1, 0) + (1 − p(θi))ui(ω0, 0).

2This notion is called ε-incentive compatibility.

4

We assume that in case of indifference agents plays action 1. Let gi(θi) ∈ {0, 1} denote agent
i’s best-reply action when she observes the signal θi. Also, write g(θ) to be the action proﬁle
of the agents when the realized vector of signals is θ. Write Θ := Θ1 × · · · × Θn. We will use
F1 ∈ ∆(Θ) to denote the signal distribution conditional on state ω1 and F0 ∈ ∆(Θ) to denote the
signal distribution conditional on state ω0.

Let s(F ) be the sender’s utility from the policy (Θ, F ):

s(F ) := γEθ∼F1[V (g(θ))] + (1 − γ)Eθ∼F0[V (g(θ))].

(1)

A signaling policy (Θ, F ) is said to be optimal if it maximizes sender’s utility among all possible

signal sets Θ and all possible signals F : Ω → ∆(Θ).

We begin by stating a result from [4] (see Lemma 1 in [4]) that shows the existence of an optimal

policy with the following useful properties:

• For every agent i, the private signal set Θi is equal to {0, 1} and agent i’s best reply gi(θi) = θi.
In other words, when signal θi is recommended by the sender to agent i it is proﬁtable (after
agent i performs a Bayesian update of her belief on the state of the world) for her to follow
the recommendation. In [13], such policies are called straightforward.

• In the optimal policy F1(1, 1, . . . , 1) = 1, i.e., when state ω1 is realized the sender recom-
mends everyone to adopt the product. Recall that F1 is a distribution over Θ, which (by the
above mentioned property) is {0, 1}n for the optimal policy under consideration.

• When the realized state is ω0, the sender recommends to agent i to adopt the product with

ui(ω1,1)−ui(ω1,0)

probability of at most ai := min( γ
1−γ
We succinctly express this condition as F0(θi = 1) ≤ ai. The number ai can be interpreted as
the maximal probability that the sender can “lie” to the agent, and will be called the persua-
sion level of player i.

ui(ω0,0)−ui(ω0,1) , 1). Write F0(θi = 1) :=Pθ∈{0,1}n: θi=1 F0(θ).

Under such an optimal policy, sender’s utility is given by

s(F ) = γV ([n]) + (1 − γ)Eθ∼F0V (θ)

(2)

It is shown in [4] that the requirements F1(1, 1, . . . , 1) = 1 and F0(θi = 1) ≤ ai in fact ensure
that the best reply of every agent is equal to the sender’s recommendation, gi(θi) = θi. Also,
the above mentioned properties imply that we can restrict our attention to binary signal sets,
Θi = {0, 1} and Θ = {0, 1}n along with a single distribution F0 ∈ ∆({0, 1}n).

Overall, in light of these properties the problem of determining an optimal policy (over general
signal sets Θ and mappings F : Ω → ∆(Θ)) reduces to the following well-structured maximization
problem:

maximize Eθ∼F0V (θ) subject to F0(θi = 1) ≤ ai.

(3)

Note that prior γ and utility V ([n]) are ﬁxed parameters. Hence, an optimal solution of (3)

gives us the optimal value in (2)

For each subset S ⊂ [n], with characteristic vector 1S, write µS to be the probability that exactly
the agents is S will receive the recommendation to adopt the product, µS := F0(1S ). For a given

5

persuasion levels proﬁle a := (a1, ..., an), the maximization problem (3) can be written as

µSV (S)

(4)

V +(a) := max XS⊆[n]
s.t. XS⊂[n]
XS⊂[n]

µS1S ≤ a

µS = 1

µS ≥ 0.

Interestingly, the expression V +(a) exactly deﬁnes the notion of concave closure (see e.g., [9])
of the sender’s utility function V at a ∈ [0, 1]n. We will refer to solving (approximating) the op-
timization problem (4) as computing (approximating) the concave closure. Note that computing
the concave closer corresponds to solving a linear programming with polynomial number of con-
strains, but with an exponential number of variables (the variables are µS for every S ⊂ [n]).

In some cases we will be interested in approximating the optimal revenue of the sender and,
hence, we introduce here the following lemma that states that computing (approximating) the
concave closure is computationally equivalent to computing (approximating) the sender’s optimal
revenue. Note that, for a given parameter α ∈ (0, 1], an α approximation of the concave closure
corresponds to a distribution {µS}S⊆[n] that satisﬁes the feasibility constraints of the optimization

problem (4) and obtains an objective function value, PS⊆[n] µSV (S), that is at least α times the

optimal. The next lemma states that there exists an approximation-preserving, polynomial-time
reduction between computing the concave closure and ﬁnding the optimal revenue of the sender.
Speciﬁcally, the lemma establishes that computing the concave closure of the sender’s utility func-
tion lies at the core of determining a revenue-maximizing policy for the sender.

Lemma 2.1. Given a persuasion proﬁle a ∈ [0, 1]n and utility function V along with an α approximation
of the concave closer V +(a), in polynomial time we can ﬁnd a policy for the sender (with utility function V
and persuasion proﬁle a) that obtains revenue at lest α the optimal.

Furthermore, for every ε > 0, there exists a polynomial-time reduction from the problem of α approx-
imating a sender’s revenue (with utility function V and persuasion proﬁle a) to the problem of computing
an (α + ε) approximation of the concave closer V +(a).

Proof The forward direction is direct: by equation (2), an α approximation of max Eθ∼F0V (θ) is
also an α approximation of γV (N ) + (1 − γ)Eθ∼F0V (θ).

For the other direction, given function V and persuasion a = (ai)i∈[n], we can set the prior γ to

be very small (e.g., γ = ε(V (N ))2

1−α

sufﬁces) and we set agent i utilities to be

ui(ω0, 0) = 1, ui(ω0, 1) = ui(ω1, 0) = 0, ui(ω1, 1) = ai

1 − γ

γ

.

Such a choice guarantees that indeed ai = min( γ
It follows that for such
1−γ
instances an α approximation of the sender’s revenue implies (α+ε) approximation of the concave
closer of V .
⊓⊔

ui(ω1,1)−ui(ω0,1)
ui(ω0,0)−ui(ω0,1) , 1).

In subsequent sections we establish algorithmic and hardness results for the problem of ﬁnding
the optimal policy (and revenue) of the sender. We do so by using the above mentioned lemma
and, in particular, addressing the computation of the concave closure.

6

3 Anonymous Utility

This section considers the case wherein the sender’s utility function is anonymous i.e., it satisﬁes
V (S) = f (|S|) for some monotonically increasing function f : [n] → R. Our main result for
anonymous utilities is as follows.

Theorem 3.1. There exists a polynomial algorithm for computing the maximum revenue and an optimal
signaling policy for a sender that has a monotone, anonymous utility function.

3.1 Proof of Theorem 3.1

We show that the concave closure of anonymous function can be computed in polynomial time.

We use Sk to denote all the size-k subsets of [n], Sk := {S ⊆ [n] | |S| = k}. We denote by

marg(µ)i :=PS⊂[n]:i∈S µ(S) the marginal probability of the ith coordinate to be equal 1. Note that

the constrains of the concave closure V +(a) can be written as marg(µ)i ≤ ai for every i ∈ [n].

The following lemma from [4] characterizes the maximum probability mass that can be as-
signed to subsets of size k under the constraints imposed by the persuasion levels proﬁle a =
(a1, ..., a2).

Lemma 3.2 ([4]). Let 1 ≥ a1 ≥ a2 ≥ . . . ≥ an ≥ 0 be a monotonic sequence. The solution for the
following maximization problem

max XS∈Sk

µ(S)

subject to marg(µ)i ≤ ai

∀i ∈ [n]

(5)

µS ≥ 0

is given by

βk(a1, ..., an) = min
0≤m<k

1

k − m

(am+1 + . . . + an).

Moreover, such a measure µ that maximizes (5) can be computed in polynomial time.

The key idea is to use this lemma to solve the LP corresponding to the concave closure—
which has exponential (in n) number of variables—by another LP that has a polynomial number
of variables. We split the original problem into n problems of ﬁnding a measure µk over Sk for
every k = 1, ..., n (the ﬁnal measure is deﬁned by µ = µ1 + ... + µn). The new maximization
problem has n2 variables (aj
n) represents the marginal constrain vector on
subsets of size k. We denote by αk the measure that is assigned to subsets of size k, then the
original maximization problem can be translated to the following

i )i,j∈[n], where (aj

1, ..., aj

max α1f (1) + α2f (2) + ... + αnf (n)
1, ak

αk = 1, 0 ≤ αk ≤ βk(ak

2, ..., ak

s.t. Xk∈[n]

n) for k ∈ [n], and Xj∈[n]

(6)

aj
i ≤ ai.

and the last constrain uses the fact that marginals preserve additivity, and thus correspond to

where the ﬁrst constrain corresponds to PS⊂[n] µS = 1, the second follows from Lemma 3.2,
PS⊂[n] µS1S ≤ a.

The following Lemma shows that adding the constrains ak

n for every k ∈ [n] to

1 ≥ ak

2 ≥ ... ≥ ak

the maximization problem (6) do not change the maximum value.

7

Lemma 3.3. For (µS)S⊂[n] we denote by ak
satisﬁes ak
n for every k ∈ [n].

2 ≥ ... ≥ ak

1 ≥ ak

i = PS∈Sk: i∈S µ(S). There exists µ that maximizes (4) that

The proof of this Lemma is relegated to Section 3.1.1.
Note that for the case where ak

2 ≥ ... ≥ ak

1 ≥ ak

n the constraint αk ≤ βk(ak

1, ak

2, ..., ak

n) can be

written as

αk ≤ 1
αk ≤ 1
...
αk ≤ 1




k (a1 + a2 + ... + an)
k−1 (a2 + a3... + an)

1 (ak + ak+1 + ... + an)

because βk is deﬁned as the minimum of the right hand side expressions. Therefore the maxi-
mization problem (6) with the additional constrains ak
n is an LP maximization
with poly(n) number of variables, and it solves the original maximization problem. Moreover,
since the proof of Lemma [4] is constructive, after we have computed the values of (aj
i )i,j∈[n] that
maximize (6) we can compute the optimal policy as well.

2 ≥ ... ≥ ak

1 ≥ ak

3.1.1 Proof of Lemma 3.3

The proof builds upon ideas that were used in the proof of Lemma 3.2 in [4].

Let ν be a distribution that satisﬁes the constrains marg(ν)i ≤ ai, and let αk = ν(Sk) be the
weight of ν on subsets of size k. It is sufﬁcient to construct another distribution µ that satisﬁes
µ(Sk) = αk (and thus µ has the same revenue as ν), and in addition ak

2 ≥ ... ≥ ak
n.

1 ≥ ak

The construction is done in n steps, where the steps k = n, n − 1, ..., 1 are done in an decreasing
order. At step k we assign a measure of αk to subsets of size k, and we denote the assigned
measure by µk. Each step k is done in ﬁnite number of stages (at most n stages). Here we describe
the assignment of measure at stage k.m.

During the construction we ”assign mass” and thus, we ”spend marginal constrains”. We take
track of the remaining marginal constrains vector. At the beginning, we set the constrains vector
(an.0

1 , ..., an.0
During the process we preserve the monotonicity of the marginal constrains vector and there-

n ) = (a1, ..., an) to be the original constrains.

fore we can denote the marginal constrains vector at stage k.m by

(ak.m

1

, ..., ak.m

n ) = (b1, ..., bj , c, c, ..., c

, bl+1, ..., bn)

l−j times

| {z }

where bj > c > bl+1 and j < k ≤ l. Note that if ak.j
simplicity of notation we denote bn+1 = 0. Note that if ak.j
simplicity of notation we denote b0 > b1.

k = ak.j

k+1 = ... = ak.j
2 = ... = ak.j

1 = ak.j

k

n then l = n and for
then j = 0, and for

At stage k.m, the idea is to distribute mass equally over the subsets S of size k that satisfy

[j] ⊆ S ⊆ [l] (we have(cid:0) l−j

k−j(cid:1) such sets). If we do so, after we have distributed x units of mass the

remaining marginal constrains vector will be

b(x) = (b1 − x, ..., bj − x, c −

k − j
l − j

x, ..., c −

k − j
l − j

x, bl+1, ..., bn)

(7)

because every element i = j + 1, j + 2, ..., l appears in exactly k−j
Step k.m terminates at the moment when one of the following three happens:

l−j fraction of the above subsets.

8

(1) The total mass that has been assigned during step k reaches αk. In such a case we proceed

to step k − 1.

(2) The jth coordinate becomes equal to the (j + 1)th coordinate. In such a case we proceed to

stage k.(m + 1).

(3) The lth coordinate becomes equal to the (l + 1)th coordinate. In such a case we proceed to

stage k.(m + 1).

We denote by αk.m the amount of mass that has been assigned during step k.m. We denote by
b(αk.m) the marginal constrains vector after step k.m, where b(·) is deﬁned in equation (7). This
marginal constrains serves as the marginal constrain vector for the next step (in case (1) happens)
or the next stage (in case (2) or (3) happens).

We argue the following two statements, which will complete the proof.

1. The described process succeeds to complete all the n steps.

2. The described process at each step k assigns mass in a way that ak

1 ≥ ak

2 ≥ ... ≥ ak
n.

Statement (2) follows from the fact that at each stage k.m the marginals of the assigned mass
, 0, ..., 0) for x = αk.m and c < 1. Moreover, during step k the

is of the form (x, ..., x

, cx, ..., cx

jm times

| {z }

|

lm−jm times

{z

}

coordinate jm is monotonically decreasing, and the coordinate lm is monotonically increasing.
Therefore, the sum of those vectors, which is equal to the vector (ak
n) is monotonically
increasing.

2, ..., ak

1, ak

Assume by way of contradiction that statement (1) is false. The above process cannot as-
sign the required measure only if we are at step k and the marginal constrains vector becomes
(d1, d2, ..., dm, 0, ..., 0) for m < k. In such a case indeed the process cannot proceed, because it will
turn the m + 1 coordinate of the marginal constrain vector negative. We denote by α′
k the measure
at step k that has been assigned up to the moment of termination.

We argue that this is impossible from the fact that αn, αn−1, ..., αk are feasible weights for some
distribution ν. The idea is that the described above process has minimal marginals on the elements
m + 1, ..., n, thus if this process cannot proceed neither could some other distribution ν. Formally,
we denote ν = ν1 + ... + νn, where νj is a measure over Sj. Note that |νj| = αj. We denote (dj
i )i∈[n]
i ≥ (j − m)αj, because every subset of size j contains

i=m+1 dj

the marginals of νj. We argue thatPn

at least j − m elements from the set {m + 1, ..., n}. Therefore we have

am+1 + ... + an ≥

nXj=k

nXi=m+1

dj
i ≥

nXj=k

(j − m)αj

(8)

On the other hand, the constructed measure µn with marginals (aj

i =
(j − m)αj, because this process assigns positive probability only to subsets that contain {1, ..., m}
(because m < k ≤ j and aj
m+1). Since the process spent all the marginal constrains
am+1, ..., an we have

i=m+1 aj

m > aj

i )i∈[n] satisﬁesPn

am+1 + ... + an =

nXj=k

nXi=m+1

aj
i = (k − m)α′

k +

nXj=k+1

(j − m)αj <

nXj=k

(j − m)αj

(9)

Inequalities (8) and (9) yield a contradiction. This completes the proof of the lemma.

9

4 Submodular Utilities

Recall that a function V is submodular if V (S ∪ {i}) − V (S) ≥ V (T ∪ {i}) − V (T ) for every T ⊂
S ⊂ [n] and every i ∈ [n]. This section considers private Bayesian persuasion settings in which the
sender’s utility function is submodular. In particular, we develop a tight (1 − 1/e) approximation
of the optimal signaling policy when the sender’s utility is a monotone submodular function.

It is relevant to note that our algorithmic results require only query access to the submodular

function, i.e., our results hold as long as we have access to V (S), for any subset S ⊆ [n].

We begin by noting that ﬁnding the concave closure of a submodular function is NP-hard:
Given a succinct, monotone, submodular function f : 2[n] → R and a vector a ∈ [0, 1]n, it is
NP-hard to compute the concave closure f +(a); see, e.g. [25, 10].

4.1 Approximation Algorithm for Submodular Utilities

This section provides a (1 − 1/e)-approximation algorithm for computing the concave closure

of a monotone, submodular function V . We obtain the (cid:0)1 − 1

e(cid:1) approximation by reducing the

computation of the concave closure to the problem of maximizing a submodular function subject
to a matroid constraint. The key implication of this approximation result is the following theorem.

Theorem 4.1. If in a private Bayesian persuasion problem the utility of the sender, V , is a monotone
submodular function, then, we can compute in polynomial time a signaling policy that achieves a revenue
of at least (1 − 1/e − ε) times the optimal; here, ε is an arbitrarily small constant.

We present here an outline of the proof of Theorem 4.1, the details appear below in Section

4.1.1.
Proof outline of Theorem 4.1 The idea is to reduce the continuous maximization problem of the con-
cave closure to a discrete optimization problem. One natural way to do so is by rounding the
underlying probabilities to integer multiples of a parameter δ which is equal to
poly(n) ; i.e., to
restrict our attention to the case where µS is an integer multiple of δ for every S ⊂ [n]. An in-
volved part of the proof is to show that by imposing such a restriction we do not loose much in
the approximation ratio.

1

After the reduction to a discrete optimization problem, we show that this new problem corre-
sponds to maximizing a submodular function subject to a matroid constraint (in fact a partition
matroid constraint). Finally, we use the result by [7] to conclude that the discrete problem (and,
hence, the concave closure) admits a polynomial-time algorithm (1− 1
e )- approximation algorithm.

4.1.1 Proof of Theorem 4.1

We show that the concave closure of submodular function V at vector a = (a1, a2, . . . , an) ∈ [0, 1]n

can be approximated within a factor of(cid:0)1 − 1

follows from Lemma 2.1.

e − ε(cid:1) for an arbitrarily small ε > 0, then Theorem 4.1

We split the marginal values ai into two sets: {ai : ai ≥ 1

n2 }
are the low values. Without loss of generality we assume that a1, ..., am are the high values and
am+1, ..., an are the low values, for m ≤ n.

n2 } are the high values and {ai : ai < 1

Every distribution µ over subsets of [n] induces a distribution ν = ν(µ) over subsets of [m]
in the following natural way: the probability mass µS on S ⊂ [n] is moved to the set S ∩ [m],

formally for each subset T ⊆ [m] deﬁne νT := PS⊂[n]:S∩[m]=T µS. The following lemma holds for

the distribution ν = ν(µ).

10

Lemma 4.2. For every distribution µ that satisﬁes the marginal constraints (i.e.,PS⊆[n]:S∋i µS ≤ ai) we

have

XS⊂[n]

µSV (S) ≥ XT ⊂[m]

ν(T )V (T ) +

nXi=m+1

aiV ({i}).

Proof

XS⊂[n]

V ({i})


µSV ({i})

µSV (S) ≤ XS⊂[n]
= XT ⊂[m]
= XT ⊂[m]
≤ XT ⊂[m]

µS 
V (S ∩ [m]) + Xi∈S,i>m
νT V (T ) +XS Xi∈S,i>m
νT V (T ) +Xi>m XS:i∈S
νT V (T ) +Xi>m

aiV ({i}),

µSV ({i})

where the ﬁrst inequality follows from subadditivity of V . The second equation follows from the
deﬁnition of ν = ν(µ). The third equation is obtained by changing the order of summation and
⊓⊔
the last inequality follows from the fact that µ satisﬁes the marginal constraints.

We can consider the optimization problem corresponding to the concave closure restricted to

the set [m]:

V +

m (a) := max XT ⊂[m]

s.t. XT ⊆[m]:T ∋i

νT V (T )

(10)

νT ≤ ai

∀i ∈ [m]

ν is a probability measure.

Given a distribution ν that α-approximates problem (10), we deﬁne distribution µ over [n] as
n )ν. In addition, for every i > m set µ{i} := ai.
n − am+1 −

follows: For each subset T ⊆ [m], set µT := (1 − 1
Finally, to ensure that µ is a probability measure we assign a probability mass of c = 1
... − an > 0 to the empty set, i.e., µφ := c.
Lemma 4.3. If a distribution ν α-approximates problem (10), then µ provides a (1 − 1
of the original concave closure problem (4).

n )α-approximation

Proof

XS⊂[n]

µSV (S) =(cid:18)1 −
≥(cid:18)1 −
≥(cid:18)1 −
≥(cid:18)1 −

aiV ({i})

1

1

1

νT V (T ) +Xi>m
m (a) +Xi>m
m (a) +Xi>m

n(cid:19) XT ⊂[m]
n(cid:19) αV +
n(cid:19) α[V +
n(cid:19) αV +(a)

1

aiV ({i})

aiV ({i})]

11

where the ﬁrst equation is implied by the deﬁnition of µ. The second inequality follows from the
fact that ν α-approximates the concave closure (on the set [m]). The third inequality is trivial and
⊓⊔
the last one follows from Lemma 4.2.

Lemma 4.3 reduces the original concave closure problem to the problem of computing the
concave closure over [m] where (unlike the original problem) we know that ai ≥ 1
n2 for each
i ∈ [m]. In the remainder of the proof, we consider the later problem. The idea is to translate
this problem into a discrete one. A natural way do to so is by rounding the underlying terms to
integer multiples of a parameter δ :=
n4(n+1) and then working with the multiples, instead of the
fractional terms.

1

Since (10) is a linear program (over variables {νT }T ⊆[m]) with at most n + 1 non-trivial con-
straints, without loss of generality we can restrict attention to solutions that have support size of
at most n + 1.

As mentioned previously, we set a grid of size δ :=

1

n4(n+1) , and we consider the maximization

problem of V +

m where we restrict the probabilities {νS} to be integer multiples of δ.

νT V (T )

(11)

V +

m (a) := max XT ⊂[m]

s.t. XT ⊆[m]:T ∋i

νT ≤ ai

∀i ∈ [m]

ν is a probability measure.
νT ∈ {0, δ, 2δ, . . . , 1}.

Lemma 4.4. Let parameter α ∈ [1/2, 1]. If distribution bν is an α-approximate solution of optimization
problem (11) with support size at most n + 1, then bν is a (1 − 2

n )α-approximate solution of the concave

m (a) as well.

closure V +

Proof We prove that by restricting attention to probabilities in the set {0, δ, 2δ, . . . , 1}, we incur
at most a multiplicative loss of (1 − 1
nα ). Given a distribution ν with support size at most n + 1
we round down the probabilities to integer multiples of δ (and put all the remaining probability
mass on the empty set), we denote the resulting distribution by ν′. Formally ν′
T = ℓδ where
k = max{j ∈ Z : jδ ≤ νT }. Note that

XT
νT V (T ) −XT
≤ XT ∈Supp(ν)

1

ν′

T V (T ) =XT

(νT − ν′

n4(n + 1)

V ([m]) ≤

1
n4 V ([m]) ≤

T )V (T ) ≤XT
n4 Xi∈[m]

1

δV (T )

V ({i}) ≤

1

n2 Xi∈[m]

aiV ({i}).

(12)

Since νT − ν′
T ≤ δ for each subset T , we get the ﬁrst inequality. To obtain the second inequality
we use the deﬁnition of δ :=
n4(n+1) and the monotonicity of V . Now, given that the support
size of ν is at most n + 1, we have the third inequality. The fourth inequality follows from the
submodularity (subadditivity) of V and the last inequality follows from the fact that ai ≥ 1
n2 .

n on singleton {i} for all i ∈ [m], and assign the remaining probability mass

nPi∈[m] aiV ({i}), since one feasible solution is to put a

m (a) ≥ 1

It is relevant to note that V +

probability mass of ai

1

to the empty set. This is indeed a feasible solution becausePi

ai

n ≤Pi

1
n ≤ 1.

12

Finally let ν be an α-approximation solution of V +

m (a), and let ν′ be the corresponding rounded-

down distribution . Then

T V (T )

PT ν′
PT νT V (T )

≥ 1 −

= 1 − PT ν T V (T ) −PT ν′
PT ν T V (T )
n2 Pi∈[m] aiV ({i})
PT νT V (T )
n2 Pi∈[m] aiV ({i})
nPi∈[m] aiV ({i})

≥ 1 −

α 1

1

1

T V (T )

= 1 −

1
nα

where the second inequality follows from bound (12), and the third from the fact that V +
1

nPi∈[m] aiV ({i}). Finally, the stated claim follows from the fact that α ≥ 1/2.

Lemma 4.4 allows us to restrict our attention to the discretized problem (11). Note that problem

m (a) ≥
⊓⊔

(11) is in fact equivalent to

max

S 1,...,S k⊆[m]

1
k

kXj=1

V (Sj)

subject to

|{j ∈ [k] | i ∈ Sj}| ≤ ki

∀i ∈ [n]

(13)

where ki = ain4(n + 1) and k = n4(n + 1).

Below we show that (13) admits a (1 − 1/e) approximation. We do so by showing that (13)
corresponds to the problem of maximizing a monotone submodular function subject to a matroid
constraint. Note that a (1 − 1/e)-approximate solution of (13) can be efﬁciently mapped into a
distribution ˆν that (1 − 2
n )(1 − 1/e)-approximates (11) and has support size n + 1. This follows
from the following observations: given a (1−1/e)-approximate solution of (13), S := {S1, . . . , Sk},
the uniform distribution (say, η) over S is a feasible solution of (11) that achieves an approximation
ratio of (1 − 1/e). We can now consider the following linear program that has the same marginal
constraints as (11) but considers probability distributions whose support lie in S:

νT V (T )

maxXT ∈S
s.t. XT ∈S:T ∋i

XT ∈S

νT ≤ ai

∀i ∈ [m]

νT = 1 and νT ≥ 0 ∀T ∈ S

(14)

Linear program (14) has k = n4(n + 1) variables n + 1 non-trivial constraints, hence in poly-
nomial time we can ﬁnd an optimal solution, say x := {xT }T ∈S , of (14) with support size n + 1.
Furthermore, using η (the uniform distribution over S) we can show that the optimal value of

(14) (i.e.,PT ∈S xT V (T )) is at least (1 − 1/e) times the optimal value of (11). Hence, by rounding

the probabilities xT s down to the nearest multiple of δ, and using arguments similar to the ones
presented in Lemma 4.4 we can obtain a distribution ˆν that satisﬁes the constraints of Lemma 4.4
(i.e., has support size of at most n + 1) with α := (1 − 2

n )(1 − 1/e).

To complete the proof we show that (13) corresponds to the problem of maximizing a mono-
tone submodular function subject to a matroid constraint. Consider base set U = [m] × [k]. We get

13

that the size of U is polynomially bounded. For a subset R = {(i1, j1), (i2, j2), . . . , (il, jl)} of U and
j ∈ [k], write Rj to denote the projected subset {i′ ∈ [m] | (i′, j) ∈ R}.

With this notation in hand, deﬁne function F for each subset R = {(i1, j1), (i2, j2), . . . , (il, jl)} ⊂

U as follows

F (R) :=

1
k

kXj=1

V (Rj).

(15)

We claim that F is submodular: consider subsets X ⊂ Y ⊂ U and element (i, j) ∈ U . Note that
F (X + (i, j)) − F (X) = 1
k V (Y j).
Since X j ⊂ Y j, the submodulartiy (monotonicity) of V implies the submodularity (monotonicity)
of F .

k V (X j) and F (Y + (i, j)) − F (Y ) = 1

k V (X j + i) − 1

k V (Y j + i) − 1

Next we consider a partition matroid M over U . Speciﬁcally, we say that a subset R ⊂ U is
independent (with respect to the matroid M) iff |{(i′, j′) ∈ R | i′ = i}| ≤ ki for all i ∈ [n]. Note
that this is a partition matroid where the disjoint partitions are Bi := {(i, 1), (i, 2), . . . , (i, k)} and
the cardinality bounds are kis. In other words, we obtain M by deﬁning R to be an independent
subset iff |R ∩ Bi| ≤ ki for all i.

Note that if a subset R ⊂ U is independent then R1, R2, . . . Rk satisfy the constraints of the

optimization problem (13), i.e., for an independent R we have |{j ∈ [k] | i ∈ Sj}| ≤ ki for all i.

Overall, we get that optimization problem (13) is equivalent to the following problem:

max
R⊂U

F (R)

subject to R ∈ M

(16)

Since this is a submodular maximization problem subject to a matroid constraint, it admits a
e ) approximation; see [7]. This in turn implies that the original problem admits a (1 − 1
n )(1 −
n )) approximation. We can set parameters such instead of a multiplicative
n )2 in the approximation we get a term that is arbitrarily close one. Hence,

e ) = (1 − 1

e − O( 1

(1 − 1
n )2(1 − 1
2
factor of (1 − 1
we get the desired result.

n )(1 − 2

4.2 Hardness of Approximating the Concave Closure

This section shows that the(cid:0)1 − 1

e(cid:1) approximation guarantee obtained in Section 4.1.1 is tight. In

particular, applying the machinery developed by [18] leads us to the following theorem. We note
that [18] establish the hardness of approximating maximum social welfare in combinatorial auc-
tions and similar tools were developed in [12] for studying the inapproximability of the domatic
number.

Theorem 4.5. Given a monotone, submodular fucntion V : 2[n] → R+ and vector a ∈ [0, 1]n, for any

ε > 0, it is NP-hard to approximate the concave closure, V +(a), by a factor better than(cid:0)1 − 1

Proof [Sketch] [18] study the combinatorial auction problem where n goods have to be partitioned
among m agents whose utilities are submodular functions of the goods assigned to them. In this
problem, the objective is to maximize social welfare, i.e., the sum of the utilities of the agents. It is
shown in [18] that for this problem and any ε > 0 there does not exist a polynomial time algorithm

e − ε(cid:1).

that obtains an approximation ratio better than(cid:0)1 − 1

e − ε(cid:1), unless P = NP.

Speciﬁcally, [18] start with a label-cover problem where it is NP-hard to distinguish whether the
optimal value, OP T (L), is one or less than a particular constant, c < 1. From the given label cover
problem they construct a combinatorial auction instance, I, wherein the maximum social welfare,

14

OP T (I) is greater than a threshold, τ if the label cover problem admits a solution of value one.
Furthermore, if the optimal value of the label cover problem is less than c—i.e., OP T (L) ≤ c—

then it must be the case that OP T (I) ≤ (cid:0)1 − 1

e − ε(cid:1) τ . This, overall, establishes a (cid:0)1 − 1

e − ε(cid:1)

hardness-of-approximation bound for the combinatorial auction problem.

Interestingly, in the constructed instance I all of the m agents have the same monotone, sub-
modular utility function, say, f : 2[n] → R+. We claim that approximating the concave closure of
constructed function f at marginal vector a := ( 1
is NP-hard. In particular, if OP T (L) = 1 then f +(a) ≥ τ ′ and, moreover, if OP T (L) ≤ c then

m ) by a factor better than(cid:0)1 − 1

e − ε(cid:1)

m , . . . , 1

m , 1

f +(a) ≤(cid:0)1 − 1

e − ε(cid:1) τ ′; here τ ′ is a ﬁxed parameter.

The proof of this claim can be obtained by considering the subsets in the support of an optimal
solution, µ∗, of problem (4) deﬁned for function f . Note that the proof given in [18] proceeds by
considering the subsets that constitute the partition of goods among agents in I, instead we can
focus on subsets in the support of µ∗ to obtain the result for the concave closure. In particular,
the arguments presented in [18] go through if, instead of cardinalities, we consider measure of
sets and expected values of quantities with respected to µ∗.3 This, overall, establishes the desired
⊓⊔
inapproximability result for the concave closure.

Acknowledgements

The authors thank Uriel Feige for helpful discussions and references.

References

[1] Ricardo Alonso and Odilon Camara. On the value of persuasion by experts. University of

Southern California, Marshall School of Business, 2014.

[2] Ricardo Alonso and Odilon Camara. Persuading voters. Available at SSRN 2688969, 2015.

[3] Simon P Anderson and R´egis Renault. The advertising mix for a search good. Management

Science, 59(1):69–83, 2013.

[4] Itai Arieli and Yakov Babichenko. Private bayesian persuasion. Available at SSRN 2721307,

2016.

[5] Robert J Aumann, Michael Maschler, and Richard E Stearns. Repeated games with incomplete

information. MIT press, 1995.

[6] Fernando Branco, Monic Sun, and J Miguel Villas-Boas. Too much information? information

provision and search costs. Marketing Science, 2015.

[7] Gruia Calinescu, Chandra Chekuri, Martin P´al, and Jan Vondr´ak. Maximizing a monotone

submodular function subject to a matroid constraint. SIAM Journal on Computing, 2011.

3For example, in Lemma 5 in [18], we can redeﬁne sets N e

2 ) to be the collection of subsets—instead of collection
of players—in the support of µ∗ that cover (do not cover) an edge e in the label cover instance. Along these lines,
instead of bounding the cardinalities of N e
2 in [18]), we can bound the
measures PS∈N e
S. The key Lemmas 4 and 5 of [18] have analogous versions in terms of measures.
A central step in Lemma 5 is to bound the gap ∆e (see page 7 in [18]), for us this step follows via Jensen’s inequality.

2 (which are denoted by ne

S and PS∈N e

1 and N e

1 and ne

1 (N e

µ∗

µ∗

1

2

15

[8] Vincent P Crawford and Joel Sobel. Strategic information transmission. Econometrica: Journal

of the Econometric Society, 1982.

[9] Pedro Domingos and Matt Richardson. Mining the network value of customers. In Proceed-
ings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining.
ACM, 2001.

[10] Shaddin Dughmi. Submodular functions: Extensions, distributions, and algorithms. a sur-

vey. arXiv preprint arXiv:0912.0322, 2009.

[11] Shaddin Dughmi and Haifeng Xu. Algorithmic bayesian persuasion.

arXiv preprint

arXiv:1503.05988, To appear in STOC 2016, 2016.

[12] Uriel Feige, Magn ´us M Halld ´orsson, Guy Kortsarz, and Aravind Srinivasan. Approximating

the domatic number. SIAM Journal on computing, 2002.

[13] Matthew Gentzkow and Emir Kamenica. Bayesian persuasion. American Economic Review,

2011.

[14] Matthew Gentzkow and Emir Kamenica. Competition in persuasion. Technical report, Na-

tional Bureau of Economic Research, 2011.

[15] Matthew Gentzkow and Emir Kamenica. Costly persuasion. The American Economic Review,

2014.

[16] Itay Goldstein and Yaron Leitner. Stress tests and information disclosure. 2015.

[17] David Kempe, Jon Kleinberg, and ´Eva Tardos. Maximizing the spread of inﬂuence through a
social network. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge
discovery and data mining. ACM, 2003.

[18] Subhash Khot, Richard J Lipton, Evangelos Markakis, and Aranyak Mehta. Inapproxima-
bility results for combinatorial auctions with submodular utility functions. In Internet and
Network Economics. Springer, 2005.

[19] Kazuo Murota. Convexity and steinitz’s exchange property. In Integer Programming and Com-

binatorial Optimization, pages 260–274. Springer, 1996.

[20] Kazuo Murota. Discrete convex analysis. SIAM, 2003.

[21] Luis Rayo and Ilya Segal. Optimal information disclosure. Journal of political Economy, 2010.

[22] Keith E Schnakenberg. Expert advice to a voting body. Journal of Economic Theory, 2015.

[23] Wataru Tamura. Optimal monetary policy and transparency under informational frictions.

Available at SSRN 2191900, 2014.

[24] Ina A Taneva. Information design. University of Edinburgh, 2015.

[25] Jan Vondr´ak. Submodularity in combinatorial optimization. PhD thesis, PhD thesis, Charles

University, Prague, Czech Republic, 2007.

[26] Yun Wang. Bayesian persuasion with multiple receivers. Available at SSRN 2625399, 2013.

16

