6
1
0
2

 
r
a

M
 
2
2

 
 
]

.

A
N
h
t
a
m

[
 
 

2
v
9
0
8
4
0

.

3
0
6
1
:
v
i
X
r
a

Optimal sampling recovery of mixed order Sobolev embeddings

via discrete Littlewood-Paley type characterizations

Glenn Byrenheida∗, Tino Ullricha

aHausdorﬀ-Center for Mathematics, 53115 Bonn, Germany

March 24, 2016

Abstract

In this paper we aim at approximating d-variate functions f with bounded mixed deriva-
tives in Lp, where the error is measured in Lq. The reconstruction algorithm is supposed to
(linearly) recover the function from function values, sampled on a discrete set of n sampling
nodes. We close a gap in the existing literature and provide optimal bounds for sampling
pW (Td), Lq(Td)) in some of the so far unknown cases
n-widths of Sobolev embeddings n(Sr
via proving new tailored sampling characterizations for Sobolev Sr
pW and more general
Triebel-Lizorkin spaces Sr
p,θF . Here we replace the usual Littlewood-Paley building blocks
(convolutions) by certain discrete convolutions (related to the discrete Fourier transform)
using only ﬁnitely many function values. This technique has been successfully developed by
Ding D˜ung for Besov spaces of mixed smoothness. Sampling characterizations then allow
to optimally bound the error of a Smolyak sampling operator in the mentioned framework
if 0 < p < q ≤ ∞ and r > 1/p. With the extended theory to Triebel-Lizorkin spaces we are
able to strengthen the results for Sobolev spaces and remove the “infamous” smoothness
restriction r > max{1/p, 1/2} in the Sobolev context. In addition, we pay attention to
several optimality questions on the complexity of the sampling recovery problem. We clar-
ify, for instance, under which conditions on p and q optimal sampling algorithms are also
optimal among all linear algorithms with rank less or equal to n (linear n-widths). Both
scenarios can happen in this rather simple framework as already observed by Novak and
Triebel in the isotropic setting. In the non-matching case we quantify the size of the gap
in the main rate. Another comparison to the Gelfand n-widths, which describe the best
possible rate of convergence for arbitrary (not necessarily linear) algorithms using n pieces
of “linear information”, shows that general non-linear methods do not yield a better rate
in case 2 ≤ p < q < ∞ and r > 1/p compared to our linear Smolyak sampling algorithm.

1

Introduction

This paper is concerned with the problem of optimal sampling recovery in classes of multivariate
functions. We aim at approximating d-variate functions f from classes with bounded mixed
derivative in Lp, where the error is measured in Lq (classical mixed Sobolev embeddings). Our
focus is on the asymptotic decay of the so-called sampling n-widths which measure the mininal
In the past 50
worst-case error for the (linear) sampling recovery problem with n points.

∗Corresponding author. Email: byrenheid.glenn@gmail.com

1

years several asymptotic characteristics like, for instance, Kolmogorov, linear and Gelfand n-
widths, have been studied in the context of multivariate function spaces with bounded mixed
derivative. For a detailed historical discussion and a collection of results in this direction
we refer to Temlyakov [39] and the recent survey article [10]. The Kolmogorov n-widths
represent the benchmark (lower bound) when considering the optimal approximation from n-
dimensional subspaces. In case of linear n-widths we add the additional restriction that the
respective subspace is given by a linear operator. From an applied point of view it is natural to
narrow the set of admissible reconstruction algorithms even further. In this paper we focus on
approximation algorithms which are supposed to (linearly) recover the function from function
values, sampled on a discrete set of n sampling nodes, which is ﬁxed for the entire class.

The interest in this topic goes back to 1963 and started with Smolyak [35] who consid-
ered uniform approximation of multivariate functions with mixed smoothness on the basis of
function values. He used an inﬂuential construction which is nowadays known as Smolyak’s
algorithm

Tmf :=

(Lj1 − Lj1−1) ⊗ ... ⊗ (Ljd − Ljd−1)f

, m ∈ N ,

(1.1)

(cid:88)

j∈Nd
|j|1≤m

0

where the (Lj)j∈N0 represent univariate approximation operators (and we replace L0 − L−1
by L0). When applied to a univariate sampling (interpolation) scheme (Ij)j this construction
yields a powerful sampling algorithm for the multivariate case taking points from a so-called
sparse grid. Let us emphasize that in the univariate setting an optimal algorithm in the sense
of sampling widths for the space W r
p consists in the standard equidistant interpolation method.
When measuring the error in Lp such an optimal linear sampling algorithm is also optimal in
the sense of linear widths. However, when considering multivariate functions the notion of
“equidistant” is not clear anymore. In other words, we are looking for optimal point sets Xm
in the d-dimensional cube to sample the function and build optimal sampling algorithms. The
Smolyak algorithm (1.1) represents one powerful method for proving upper bounds which is
still the method of choice, since we so far have not encountered any substantially better (in
the sense of order) algorithm in this framework.

A systematic study in the context of H¨older-Nikol’skij spaces Sr

p,∞B(Td) and Sobolev spaces
pW (Td) of mixed smoothness has been started with the works of Temlyakov [38, 39] and
Sr
Dinh D˜ung [5, 6, 7]. Let us also refer to the more recent papers Sickel, Ullrich [30, 31, 32, 41],
Dinh D˜ung [8, 9], [3], and [10] and the references therein. For a rather complete solution of
the sampling recovery problem for isotropic Besov spaces Br
p,θ(Ω) and Triebel-Lizorkin spaces
F s
p,θ(Ω) in Lq(Ω) (and other smoothness spaces) we refer to Novak, Triebel [19] and Vyb´ıral
[43]. However, after more than 30 years of intense research the sampling recovery problem for
function spaces of mixed smoothness seems to be rather hard and is far from being completely
understood. To be more precise, we are interested in the behavior of the linear sampling
n-widths lin
n (F , Y ) of a space F of multivariate functions when measuring the error in a
(quasi-)Banach space Y . The sampling n-widths denote a minimal worst-case error in the
following sense

(cid:13)(cid:13)(cid:13)f − n(cid:88)

i=1

(cid:13)(cid:13)(cid:13)Y

lin
n (F , Y ) := inf
Xn

inf
Ψn

sup

(cid:107)f|F(cid:107)≤1

f (xi)ψi(·)

, n ∈ N .

(1.2)

The set of sampling nodes Xn := {xi}n
{ψi}n

i=1 is ﬁxed for the space F in advance.

i=1 ⊂ Td and associated (continuous) functions Ψn :=

2

In this paper we investigate sampling n-widths for the classical mixed Sobolev embedding

I : Sr

pW (Td) → Lq(Td) ,

(1.3)
where 1 < p, q < ∞ and r > 1/p. Surprisingly, in contrast to the mentioned Kolmogorov and
linear n-widths, where the picture is rather complete (see Figure 7.15 and [10, Chapt. 5]), the
correct asymptotic decay of the sampling n-widths is unknown in most of the cases. We will
provide the correct order in the situation 1 < p < q < ∞ where p and q are on the same
side of 2 by developing a novel technique which provides new tailored characterizations of the
p,θF (Td) of dominating mixed smoothness. Note
respective Sobolev-Triebel-Lizorkin spaces Sr
pW (Td) as a special
that this scale of function spaces contains the classical Sobolev spaces Sr
case if θ = 2 and 1 < p < ∞. Dinh D˜ung [81, 87] studied such characterizations in the context
of function spaces with bounded mixed diﬀerence. Already in 1991 he was able to prove the
following sharp result

p,∞B(Td), Lq(Td)) (cid:16)(cid:16) (log n)d−1

(cid:17)r−1/p+1/q

lin
n (Sr

(1.4)
in case 1 < p < q ≤ 2 and r > 1/p. For further results on the sampling recovery problem for
mixed Besov space embeddings we refer to his recent papers [8, 9].

n

(log n)(d−1)/q

, n ∈ N ,

We aim for function space characterizations based on the building blocks used in the clas-

sical Smolyak algorithm (see (1.1) above)

qj[f ] = (Lj1 − Lj1−1) ⊗ ... ⊗ (Ljd − Ljd−1)f

,

j ∈ Nd
0 .

(1.5)

Here the univariate operators (Lj)j are speciﬁcally tailored for the sampling recovery problem.
Let us think for the moment on tensor products of the classical univariate trigonometric in-
terpolation. As a ﬁrst step, we will prove the following characterization for Sobolev spaces of
mixed smoothness if r > max{1/p, 1/2} and 1 < p < ∞

p W (Td)(cid:107) (cid:16)(cid:13)(cid:13)(cid:13)(cid:16)(cid:88)

22j·r|qj[f ](·)|2(cid:17)1/2(cid:13)(cid:13)(cid:13)p

(cid:107)f|Sr

j∈Nd

0

.

(1.6)

In a way we replace the usual convolution by a discrete one such that the building blocks qj[f ]
are constructed out of (cid:16) 2|j|1 function values. This result provides a powerful tool to deal with
pW (Td) in Lq(Td) . Analyzing Smolyak’s algorithm in this context has
Sobolev embeddings Sr
been a technical issue in the past. For instance, the bound

lin
n (Sr

, n ∈ N ,

pW (Td), Lp(Td)) (cid:46) n−r(log n)(r+1/2)(d−1)

(1.7)
if 1 < p < ∞ and r > max{1/p, 1/2}, has been ﬁrst observed by Sickel [30] in case d = 2 and
later extended to the d-variate situation in Sickel, Ullrich [32, 34] and Ullrich [41]. Using (1.6)
we are able to recover this bound within a few lines of proof, see Theorem 6.7 below. Note,
that we still do not know whether this upper bound is sharp. However, all the known sharp
bounds are provided by Smolyak’s algorithm which is a strong indication that this is also the
case for the situation in (1.7). In addition, what concerns the recovery of mixed Sobolev spaces
in the uniform norm, we are also able to recover the following important sharp result due to
Temlyakov [38] as a simple consequence of our theory, see Theorem 6.5 below. If r > 1/2 it
holds

n (Sr
lin

2W (Td), L∞(Td)) (cid:16) n−(r−1/2)(log n)r(d−1)

, n ∈ N .

3

However, besides the identiﬁcation of classical results, the main result of this paper is the new
upper bound in case 0 < p < q < ∞, 0 < θ ≤ ∞ and r > 1/p,

(cid:17)r−1/p+1/q

, n ∈ N ,

(1.8)

which is complemented by

n

lin
n (Sr

p,θF (Td), Lq(Td)) (cid:46)(cid:16) (log n)d−1
(cid:17)r

p,θF (Td), Lq(Td)) (cid:46)(cid:16) (log n)d−1
pW (Td), Lq(Td)) (cid:46)(cid:16) (log n)d−1

lin
n (Sr

lin
n (Sr

(1.9)
if 0 < q ≤ p < ∞, 0 < θ ≤ ∞ and r > max{1/p, 1/θ}. The result in (1.8) closes a gap in the
existing literature since it directly implies the same upper bound

n

(log n)(d−1)(1−1/θ)+

, n ∈ N ,

(cid:17)r−1/p+1/q

, n ∈ N ,

(1.10)
if 1 < p < q < ∞ and r > 1/p, for the classical Sobolev embedding (1.3), which has not been
known before. Note, that we have an additional “log-factor” in (1.9) in contrast to (1.8), (1.10).
Furthermore, comparing (1.8) to (1.4) we observe an extra log-term there, which illustrates
(or quantiﬁes) the embedding Sr

p,∞F (Td) (cid:44)→ Sr

p,∞B(Td).

n

In addition, we pay attention to several optimality questions on the complexity of the
sampling recovery problem for the Sobolev embeddings. We clarify, for instance, under which
conditions on p and q optimal sampling algorithms of the above type are also optimal among all
linear algorithms with rank less or equal to n. Due to the deﬁnition of the sampling n-widths
in (1.2) the associated linear n-widths serve as benchmark here and have been determined
(almost) completely by Galeev, Romanyuk [14, 15, 23, 24, 33], see also Edmunds and Triebel
[11, 12]. Restricting to the situation 1 < p < q < ∞ we ﬁnd as a direct consequence of (1.8)
pW (Td), Lq(Td)) decay signiﬁcantly faster than the corresponding
that linear n-widths λn(Sr
sampling n-widths if and only if p < 2 < q, an eﬀect already known for isotropic embeddings,
see [19, 43]. Furthermore, we are able to quantify the size of the gap lin
n /λn, which is asymp-
totically not smaller than max{n1/2−1/q, n1/p−1/2} in the main rate, see Figure 7.15 below. A
further comparison to the Gelfand n-widths, which describe the best possible rate of conver-
gence for arbitrary (not necessarily linear) algorithms using n pieces of “linear information”,
shows that in case 2 ≤ p < q < ∞ nonlinear methods can not do any better than the proposed
linear Smolyak sampling operator. For the remaining cases this is still an open question.

As already outlined above the upper bound in (1.8) is obtained by analyzing Smolyak’s
algorithm (1.1) in the respective situation. The characterization (1.6) (together with sharp non-
compact embeddings) is the crucial ingredient to bound the Lq-error. Note, that we encounter
the well-known (and infamous) condition r > max{1/p, 1/2} also in (1.6), which is relevant if
p > 2, see also (1.7). The recent ﬁndings in [27, 28] indicate that this condition is most likely
necessary for the respective sampling characterization. Interestingly, the bound (1.8) is valid
for all r > 1/p, in particular for the case of “small smoothness”, i.e., 1/p < r ≤ 1/2 if p > 2.
Since in this range the characterization (1.6) does not help we develop a complete theory of
sampling representations also for more general Triebel-Lizorkin spaces in this paper. Compared
to the Besov space situation, studied by Dinh D˜ung, the situation for Triebel-Lizorkin spaces
is much more involved. It requires several non-trivial tools from harmonic analysis like Hardy-
Littlewood maximal functions and corresponding maximal inequalities in order to establish

4

(1.6) and its counterpart for Triebel-Lizorkin spaces of dominating mixed smoothness. Here
we have under the condition r > max{1/p, 1/θ}

p,θF (Td)(cid:107) (cid:16)(cid:13)(cid:13)(cid:13)(cid:16)(cid:88)

2r·jθ|qj[f ](·)|θ(cid:17)1/θ(cid:13)(cid:13)(cid:13)p

(cid:107)f|Sr

j∈Nd

0

.

(1.11)

The striking advantage of this characterization is reﬂected by the following three observations:
(i) growing θ enlarges the space, (ii) if θ ≥ p the additional restriction r > max{1/p, 1/θ}
becomes void, and (iii) the Lq-error analysis shows no dependence on θ in the upper bound,
see (1.8).
Our technique admits to tackle also the quasi-Banach situation 0 < p, q < ∞ and prove
characterizations and corresponding results for sampling widths, see (1.8) and (1.9). The
price to pay is to use a more regular variant of the univariate sampling operator used in (1.5).
Similar to the step from Dirichlet to de-la-Vall´ee Poussin kernels we construct a suitable family
of band-limited sampling kernels providing arbitrary (prescribed) polynomial decay on the time
side. Surprisingly, it is only the target index q that matters. We observe a certain universality
property of the de la Vall´ee Poussin sampling operators which work well also in the quasi-
Banach situation for arbitrary 0 < p < ∞ in the source space. As a consequence, we almost
completely understand the decay of the sampling n-widths for general Sobolev-Triebel-Lizorkin
space embeddings also in the quasi-Banach range of parameters, which is

q,ηF (Td)) (cid:46)(cid:16) (log n)d−1

(cid:17)r1−r2−1/p+1/q

n (Sr1
lin

p,θF (Td), Sr2

n

(1.12)
if 0 < p < q < ∞, 0 < θ, η ≤ ∞, r > 1/p and r1 > r2 + 1/p − 1/q > σp . This represents the
most general version of the main result in this paper reﬁning the results in (1.8) and (1.10)
even further. Indeed, note that the upper bound does not depend on the ﬁne indices θ and η,
in which the respective spaces “grow” and “shrink”, respectively, on a ﬁne scale. We strongly
conjecture its optimality indicated by some of the the above discussed special cases and the
fact that there is no additional log-factor in the upper bound.

, n ∈ N ,

Last but not least, we will comment on the situation of a non-constant smoothness vector
r = (r1, ..., rd) which is sometimes referred to as “anisotropic mixed smoothness” in the liter-
ature (see [10]) and has been studied in the former Soviet Union. Assuming (without loss of
generality) that

1/p < r := r1 = ... = rµ < rµ+1 ≤ ... ≤ rd

the main result in (1.8), similar to (1.9), rephrases to

p,∞F (Td), Lq(Td)) (cid:46)(cid:16) (log n)µ−1

(cid:17)r−1/p+1/q

, n ∈ N .

(1.13)

lin
n (Sr

n

Note, that then the rate does not depend on the underlying dimension d anymore which
indicates a strong potential of this model for high-dimensional approximation problems.

The paper is organized as follows. Section 2 deals with the construction of univariate
sampling operators and corresponding kernels necessary for (1.5). Afterwards we tensorize
these operators in order to treat the multivariate situation. In Section 3 we deﬁne and discuss
Besov-Triebel-Lizorkin spaces. It contains the Fourier analytical deﬁnition, several properties,
and a characterization by ball means of diﬀerences. In Section 4 we provide tools for estimating
the norms of superpositions of dyadic trigonometric polynomials in Besov-Triebel-Lizorkin

5

a+ := max{a, 0}. For 0 < p ≤ ∞ and x ∈ Rd we denote |x|p := ((cid:80)d

spaces. Section 5 gives a proof for the sampling representations for Besov-Triebel-Lizorkin
spaces, see (1.11), which are used in Section 6 to analyze Smolyak’s algorithm in this context.
In the last section we compare these results with linear and Gelfand n-widths. Finally, in
the appendix we recall some basic facts and known results on maximal inequalities, Fourier
transform, Fourier series, exponential sums and n-widths.
Notation. As usual N denotes the natural numbers, N0 := N∪{0}, Z denotes the integers,
Rd the real numbers, and C the complex numbers. The letter d is always reserved for the
underlying dimension in Rd, Zd etc. With Td we denote the torus represented by the interval
[−π, π]d, where opposite points are identiﬁed. Elements x, y, r ∈ Rd are always typesetted in
bold face. We denote with x· y the usual Euclidean inner product in Rd. For a ∈ R we denote
i=1 |xi|p)1/p with the usual
modiﬁcation in the case p = ∞. By x = (x1, . . . , xd) > 0 we mean that each coordinate is
0 we use the notation 2j = (2j1, . . . , 2jd), 2j = 2j1 · . . . · 2jd. If X and Y are
positive. For j ∈ Nd
two (quasi-)normed spaces, the (quasi-)norm of an element x in X will be denoted by (cid:107)x|X(cid:107).
If T : X → Y is a continuous operator we write T ∈ L(X, Y ). The symbol X (cid:44)→ Y indicates
that the identity operator from X to Y is continuous. For two sequences an and bn we will
write an (cid:46) bn if there exists a constant c > 0 such that an ≤ c bn for all n. We will write
an (cid:16) bn if an (cid:46) bn and bn (cid:46) an. In addition, we use the following notations [d] := {1, . . . , d},
i /∈ e}, Nd
Zd(e) := {k ∈ Zd : ki = 0 :
0(e) := {k ∈ Nd
i /∈ e} where e ⊂ [d],
σp := max{0, 1
p − 1, 1
θ − 1}. For (cid:96), j ∈ Zd, s ∈ Rd we use the notations
(cid:96) > a :⇐⇒ (cid:96)i > a for all i ∈ [d] and (cid:96) > j :⇐⇒ (cid:96)i > ji for all i ∈ [d]. For Ω ⊂ Rd the set of
all bounded and continuous functions f : Ω → C is denoted by C(Ω). We denote by Lp(Ω),
(cid:16)(cid:90)
0 < p ≤ ∞, the space of all measurable functions f : Ω → C where

p − 1}, σp,θ := max{0, 1

(cid:17)1/p

0 : ki = 0 :

(cid:107)f(cid:107)p :=

|f (x)|pdx

Ω

is ﬁnite (with the usual modiﬁcation if p = ∞). For f ∈ L1(Rd) we deﬁne the Fourier transform
and its inverse by

Ff (ξ) :=

1

f (x)e−iξ·xdx and F−1f (x) :=

1

f (x)eiξ·xdξ.

(1.14)

(cid:90)

(2π)

d
2

Rd

(cid:90)

(2π)

d
2

Rd

For f ∈ L1(Td) we deﬁne the k-th Fourier coeﬃcient by

(cid:90)

ˆf (k) :=

1

f (x)e−ik·xdx.

(2π)d

Td

2 Bandlimited sampling kernels

2.1 Univariate sampling kernels

In this section we construct univariate sampling operators

N−1(cid:88)

u=0

(cid:16) 2πu

(cid:17)

N

IN [f ] =

f

(cid:16)

Kπ

x − 2πu
N

(cid:17)

,

based on bandlimited kernels K. Here Kπ denotes the periodization of K. The following
construction allows to arrange any prescribed polynomial decay of the kernel K, which is

6

crucial for our analysis. In addition the operator IN is supposed to reproduce trigonometric
polynomials of a degree related to N . The sampling kernels we study are constructed from a
ﬁnite product of dilated sinc functions. As a starting point we deﬁne for L ∈ N,

KL(x) :=

with

sinc (2−(cid:96)x),

x ∈ R,

sinc (x) :=

x

1

x (cid:54)= 0,
otherwise.

:
:

L(cid:89)
(cid:40) sin(x)

(cid:96)=1

∞(cid:88)

A close related kernel was studied in [25, Example 3] for the non-periodic situation. Our next
step is it to periodize dyadic dilation of KL(x) denoted by

KL

π,j(x) :=

KL(2j(x + 2πk)).

(2.1)

k=−∞
For j ∈ N0 we deﬁne the interpolation operator

2j−1−1(cid:88)

u=−2j−1

(cid:16) 2πu

2j

(cid:17)

(cid:16)

KL

π,j(x)

(cid:17)

,

x − 2πu
2j

f

I L
j [f ](x) :=

where in case j = 0 we put

I L
0 [f ](x) := f (0)KL

π,0(x).

The kernel deﬁned in (2.1) consists of a sum with inﬁnitely many summands. For practical
reasons such a deﬁnition is not useful. For every ﬁxed L ∈ N we can compute an explicit
representation of the kernel. Beginning from the deﬁnition we obtain the following identity

∞(cid:88)

L(cid:89)

k=−∞

(cid:96)=1

KL

π,j(x) =

sin(2j−(cid:96)(x + 2πk))

2j−(cid:96)(x + 2πk)

.

sin(2j−(cid:96)x) cos(2(cid:96)+j+1πk) + sin(2(cid:96)+j+1πk) cos(2j−(cid:96)x)

2j−(cid:96)(x + 2πk)

Obviously, in case x mod π = 0 we obtain

KL

π,j(0) = KL(0) = 1

In case 0 < |x| < π an elementary calculation shows

KL

π,j(x) =

=

=

∞(cid:88)
∞(cid:88)

k=−∞

L(cid:89)
L(cid:89)

(cid:96)=1

sin(2j−(cid:96)x)
2j−(cid:96)(x + 2πk)
k=−∞
sin(2j−1x) . . . sin(2j−Lx)

(cid:96)=1

2jL2− (L+1)L

2

7

∞(cid:88)

k=−∞

1

(x + 2πk)L .

(2.2)

(2.3)

Using the so-called Herglotz-trick we ﬁnd

Taking L − 1 derivatives yields

(cid:17)(cid:105)(L−1)

(cid:16) ·
(cid:17)(cid:105)(L−1)

cot

2

(cid:104) 1
(cid:16) ·

2

2

(cid:104) 1

Computing
2 cot
of the kernel KL

(cid:16) x

2

(cid:17)

=

∞(cid:88)

k=−∞

1
2

cot

1

x + 2πk

.

(x) = (−1)L−1(L − 1)!

∞(cid:88)

k=−∞

1

(x + 2πk)L .

(2.4)

(2.5)

8

1

and inserting this identity in (2.3) gives us a closed representation

π,j(x). For L = 2 and L = 3 we obtain the explicit representations

(cid:40) 2 sin(2j−1x) sin(2j−2x)

K2

π,j(x) =

22j sin2( x
2

)

1

x mod 2π (cid:54)= 0,
otherwise,

:

:

and

K3

π,j(x) =

sin(2j−1x) sin(2j−2x) sin(2j−3x) cos( x

23j sin3( x
2

)

2

)

:

:

x mod 2π (cid:54)= 0,
otherwise.

Remark 2.1. KL consists of products of dilated sinc functions. Since χ[−2−j ,2−j ] ∈ L1(R) it
is easy to verify that

Fχ[−2−(cid:96),2−(cid:96)](x) =

1√
2π

2−((cid:96)−1)sinc (2−(cid:96)x)

holds. Therefore the multiplication/convolution property of the Fourier transform (cf. Lemma
A.1, (iv)) yields

2πF(cid:104)

(cid:105)
χ[−2−1,2−1] ∗ . . . ∗ 2L−1χ[−2−L,2−L](·)

(x)

(2.6)

KL(x) =

sinc (2−(cid:96)x) =

√

L(cid:89)

(cid:96)=1

FKL(ξ) = F−1KL(ξ) =

Due to the fact that F,F−1 are unitary operators in L2(R) and symmetry properties we obtain
(2.7)
in the sense of L2(R). Additionally it is easy to see that KL belongs to L1(R) for L ≥ 2.
Applying Lemma A.2 (Riemann-Lebesgue) we obtain that FKL is a continuous function. Since
the right hand side of (2.6) is also continuous we can identify it with FKL. Altogether FKL
is a locally supported L − 2 times continuously diﬀerentiable function fulﬁlling

2πχ[−2−1,2−1] ∗ . . . ∗ 2L−1χ[−2−L,2−L](ξ)

√

(cid:40)√

0

FKL(ξ) =

2π ,|ξ| ≤ 1
2L ,

,|ξ| ≥ 1 − 1
2L .

F KL√

2π

(2.8)

−1 + 1
2L

− 1
2L

1
2L

ξ

1 − 1
2L

8

Lemma 2.2. Let (cid:96) ∈ Z, L ∈ N, j ∈ N0 and f ∈ C(T).

(i) Then

holds.

(ii) If additionally(cid:80)

1√
2π

(cid:91)
I L
j [f ]((cid:96)) =

FKL(cid:16) (cid:96)

(cid:17) 2j−1−1(cid:88)
(cid:96)∈Z |(cid:98)f ((cid:96))| < ∞ is fulﬁlled. Then
FKL(cid:16) (cid:96)

(cid:91)
I L
j [f ]((cid:96)) =

(cid:17)(cid:88)

u=−2j−1

2j

(cid:16) 2πu

(cid:17)

2j

f

− 2πu
2j (cid:96)

e

(cid:98)f ((cid:96) + 2jk)

(2.9)

(2.10)

1√
2π

2j

k∈Z

holds.

Proof . We compute the (cid:96)-th Fourier coeﬃcient of f and obtain by the translation property
(cf. Lemma A.3,(i)) the following identity

(cid:100)I L

j f ((cid:96)) =

2j−1−1(cid:88)
= (cid:100)KL

u=−2j−1

π,j((cid:96))

(cid:17)

(cid:16) 2πu
2j−1−1(cid:88)

2j

(cid:17) (cid:92)
(cid:16) · − 2πu
(cid:16) 2πu
(cid:17)

KL
π,j

−i 2πu

2j

f

e

2j (cid:96).

f

2j

u=−2j−1

((cid:96))

Lemma A.5 together with the dilation property of the Fourier transform (cf. Lemma A.1,(iii))
yields

(cid:100)I L

j f ((cid:96)) =

FKL(cid:16) (cid:96)

2j

(cid:17) 2j−1−1(cid:88)

u=−2j−1

(cid:16) 2πu

(cid:17)

f

2j

1√
2π2j

−i 2πu
e

2j (cid:96).

It is well-known in harmonic analysis that a continuous function with absolute summable
Fourier series can be represented point-wise by its Fourier series, cf. Lemma A.4. Inserting
this implies

(cid:100)I L

j f ((cid:96)) =

1√
2π2j

(cid:100)I L

j f ((cid:96)) =

1√
2π2j

(cid:17) 2j−1−1(cid:88)

(cid:32)(cid:88)

u=−2j−1

k∈Z

(cid:33)

(cid:98)f (k)eik 2πu

2j

−i 2πu

2j (cid:96).

e

(cid:17)(cid:88)

k∈Z

(cid:98)f (k)

2j−1−1(cid:88)

u=−2j−1

2j (k−(cid:96)).

ei 2πu

Interchanging the order of summation yields

The formula for geometric partial sums tells us

2j−1−1(cid:88)

u=−2j−1

2j (k−(cid:96)) =

ei 2πu

2j
0

k − (cid:96) mod 2j = 0
otherwise.

:
:

2j

FKL(cid:16) (cid:96)
FKL(cid:16) (cid:96)
(cid:40)

2j

9

Finally, we obtain

(cid:100)I L

j f ((cid:96)) =

FKL(cid:16) (cid:96)

2j

(cid:17)(cid:88)

k∈Z

1√
2π

(cid:98)f ((cid:96) + 2jk).

Deﬁnition 2.3. We deﬁne for j, L ∈ N0 the dyadic blocks

(cid:110)

P L
j :=

k ∈ Z : |k| ≤ 1

2L 2j(cid:111)

.

Additionally, we denote the set of trigonometric polynomials with frequencies in P L

j by

T L

j

:= span{eikx : k ∈ P L
j }.

(cid:4)

(2.11)

Corollary 2.4. Let L ∈ N and f ∈ C(T).

(i) Then it holds

(ii) If additionally f ∈ T L

j

then

j [f ] ∈ T 0
I L
j .

I L
j [f ] = f.

FKL(cid:16) (cid:96)

(cid:17)

Proof . We consider the formulas obtained in Lemma 2.2. From Remark 2.1 we know that
2L )2j. This yields (i). To show (ii) we prove that the Fourier
j has an

Indeed, a trigonometric polynomial f ∈ T L

= 0 for (cid:96) ≥ (1 − 1

coeﬃcients of f and I L
absolutely summable Fourier series, therefore

j [f ] coincide.

2j

(cid:91)
I L
j [f ]((cid:96)) =

1√
2π

holds. In case |(cid:96)| ≤ 1

2L 2j we obtain that

FKL(cid:16) (cid:96)

2j

(cid:17)(cid:88)

k∈Z

(cid:98)f ((cid:96) + 2jk)

2L 2j
can only hold for k = 0. Therefore, (2.12) breaks down to

|2j(cid:96) + 2j(cid:96)| ≤ 1

FKL(cid:16) (cid:96)

(cid:17)(cid:98)f ((cid:96)) = (cid:98)f ((cid:96))

2j

(cid:91)
I L
j [f ]((cid:96)) =

1√
2π

due to the special form of FKL. Finally, we consider the case 1
yields

2L 2j ≤ |(cid:96)| <

Hence, |(cid:96) + 2jk| ≥ 1

|(cid:96) + 2jk| >

2L 2j which implies (cid:98)f ((cid:96) + 2jk) = 0 for all k ∈ Z and therefore

:
:

k = 0,
|k| > 0.

(cid:40) 1
2L 2j
2L 2j + (|k| − 1)2j

1

(2.12)

(cid:16)

1 − 1

2L

(cid:17)

(2.13)

2j. This

(cid:91)
I L
j [f ]((cid:96)) = 0.

10

(cid:4)

Lemma 2.5. Let j ∈ N0 and 2 ≤ L ∈ N. Then there is a constant C > 0 (independent of x
and j) such that

|KL

π,j(x)| ≤ C min

(cid:110) 1

|2jx|L , 1

(cid:111)

holds for all x ∈ [−π, π].
Proof . We start for x ∈ [−π, π] the estimation with

Clearly the ﬁrst summand is uniformly bounded. Estimating the second summand in (2.14)
we use the fact that |x| ≤ π implies |2πk + x| ≥ |πk| for every integer k ∈ Z and obtain

1

2jL|x + 2πk|L .

(2.14)

|KL

π,j(x)| =

KL(2j(x + 2πk))

(cid:88)

≤ |KL(2jx)| +

|KL(2j(x + 2πk))|

|k|>0
|sinc (2j−(cid:96)x)| +

(cid:46)

k=−∞

(cid:12)(cid:12)(cid:12) ∞(cid:88)
L(cid:89)

(cid:96)=1

(cid:12)(cid:12)(cid:12)

(cid:88)

|k|>0

(cid:88)

|k|>0
which is known to be ﬁnite for L ≥ 2. Using |x| ≤ π yields

|k|>0

2jLπL

1
|k|L ,

1

2jL|x + 2πk|L ≤ 1
(cid:88)

1

2jL|x + 2πk|L

|k|>0

(cid:46)

1

2jL|x|L .

Considering again the ﬁrst summand in (2.14) gives

(cid:88)

L(cid:89)

which ﬁnishes the proof.

(cid:96)=1

|sinc (2j−(cid:96)x)| ≤

1

2(L+1) L

2

1

2jL|x|L ,

(cid:4)

2.2 Multivariate sampling kernels

Based on the univariate sampling scheme from the previous subsection we are now able to
deﬁne the building blocks used for the Smolyak algorithm, cf. (1.1),

qL
j [f ](x1, . . . , xd) :=

ηL
ji[f ](xi)

(2.15)

with

ηL
ji :=

d(cid:89)

(cid:40)

I L
ji
I L
0

i=1

− I L

ji−1

:
:

ji > 0,
ji = 0.

11

Deﬁnition 2.6. For j ∈ Nd

0 and L ∈ N we tensorize the dyadic blocks deﬁned in (2.11) by

P L
j := P L

j1

× . . . × P L

jd

,

(2.16)

and deﬁne the set of trigonometric Polynomials with frequencies in P L

j by

Proposition 2.7. Let L ∈ N and f ∈ T L

(cid:96)

then qL

j [f ] (cid:54)= 0 implies (cid:96) ≥ j.

T L

j

:= span {eikx : k ∈ P L
j }.

Proof . The proof follows immediately from the deﬁnition of qL
reproduction property in Corollary 2.4.

j [f ] in (2.15) and the univariate
(cid:4)

We also need to tensorize our sampling operator

I L
j :=

I L
ji,

j ∈ Nd
0.

(2.17)

Formally this kind of tensor product operators are deﬁned for trigonometric polynomials only.
Since trigonometric polynomials are dense in C(Td) we can uniquely extend this operator to
C(Td) and obtain for j ∈ Nd

0

I L
j [f ] =

f (xj

u)KL

xj

u =

, . . . ,

2j1

πd,j(x − xj
u)
(cid:17)

2πud
2jd

,

(2.18)

(2.19)

u ∈ Aj := {u ∈ Nd

0 : 2ji−1 ≤ ui ≤ 2ji−1 − 1, i = 1, . . . , d},

d(cid:79)

i=1

(cid:88)
(cid:16) 2πu1

u∈Aj

with

where

and

Then(cid:80)

KL

πd,j :=

KL

π,ji(xi).

d(cid:89)

i=1

(cid:91)

j∈∆

Lemma 2.8. Let ∆ ⊂ Nd

0 be a solid ﬁnite set meaning that j ∈ ∆ and k ≤ j implies k ∈ ∆.

j∈∆ qL

j [f ] reproduces trigonometric polynomials with frequencies in

HL
∆ :=

Proof . We refer to [3, Lemma 6.1].

P L
j ,

(2.20)

(cid:4)

3 Besov-Triebel-Lizorkin spaces of mixed smoothness

In this section we give the classical Fourier analytical deﬁnitions for periodic Triebel-Lizorkin
p,θB(Td) with dominating mixed smoothness. We start
spaces Sr
introducing vector-valued Lebesgue spaces.

p,θF (Td) and Besov spaces Sr

12

Deﬁnition 3.1. We deﬁne for 0 < p, θ ≤ ∞ the spaces Lp((cid:96)θ(Nd
space of all sequences of functions (fj)j∈Nd

⊂ Lp(Td) with ﬁnite (quasi)-norm

0)) and (cid:96)θ(Lp(Td)) as the

(cid:107)fj|Lp((cid:96)θ(Nd

0))(cid:107) :=

and

(cid:107)fj|(cid:96)θ(Lp(Td))(cid:107) :=

0

0

j∈Nd


(cid:13)(cid:13)(cid:13)(cid:16)(cid:80)
(cid:13)(cid:13)(cid:13) supj∈Nd

(cid:16)(cid:80)

j∈Nd
supj∈Nd

0

θ(cid:13)(cid:13)(cid:13)p
|fj|θ(cid:17) 1
|fj|(cid:13)(cid:13)(cid:13)p
(cid:17) 1

θ

(cid:107)fj(cid:107)θ
(cid:107)fj(cid:107)p

p

0

0

0 < θ < ∞,
θ = ∞,

:

:

0 < θ < ∞,
θ = ∞,

:

:

respectively.
Lemma 3.2. For 0 < p, θ ≤ ∞ the (quasi-)norms (cid:107) · |Lp((cid:96)θ(Nd
a µ-triangle inequality with µ = min{p, θ, 1}.
Proof . For more information we refer to the ﬁrst chapter in [26].
Deﬁnition 3.3. A system ϕ = (ϕj)∞

j=0 ⊂ C∞

0))(cid:107) and (cid:107) · |(cid:96)θ(Lp(Td))(cid:107) fulﬁll

(cid:4)

0 (R) belongs to the class Φ(R) if and only if

(i) It exists a A > 0 such that supp ϕ0 ⊂ [−A, A].
(ii) There are constants 0 < B < C, such that supp ϕj ⊂ {ξ ∈ R : B2j ≤ |ξ| ≤ C2j}.
(iii) For all r ∈ N0 holds

2jr|Drϕj(ξ)| ≤ cr < ∞ and

sup

ξ∈R,j∈N0

(iv)

∞(cid:88)

j=0

ϕj(ξ) = 1.

Remark 3.4. The class Φ(R) is not empty. Consider the following example. Let E > D > 0
and ϕ0(ξ) ∈ C∞
0 (R) with ϕ0(ξ) = 1 on [−D, D] and ϕ0(ξ) = 0 for |ξ| > E. For j > 0 we deﬁne

ϕj(ξ) = ϕ0(2−jξ) − ϕ0(2−j+1ξ).

Now it is easy to see, that the system ϕ = {ϕj(ξ)}∞
Because of (iv) in Deﬁnition 3.3 we obtain the following decomposition of f ∈ D(cid:48)(Td). Here,
D(cid:48)(Td) denotes the space of distributions on Td. For more details on periodic distributions we
refer to [26, Section 3.2]. Let

j=0 satisﬁes (i) - (iv).

δj[f ](x) :=

ϕj1(k1) · . . . · ϕjd(kd) ˆf (k)eik·x

(3.1)

(cid:88)

k∈Zd

be a trigonometric polynomial. Then it holds

(cid:88)

j∈Nd

0

f =

δj[f ]

with convergence in D(cid:48)(Td). We introduce the function spaces Sr
these Fourier-analytic building blocks.

p,θF (Td) and Sr

p,θB(Td) using

13

Deﬁnition 3.5. Let ϕ = {ϕj(x)}∞

j=0 ∈ Φ(R), and r ∈ Rd. Let further

(i) 0 < p < ∞ and 0 < θ ≤ ∞. Then
p,θF (Td) :=
Sr

(cid:110)

f ∈ D(cid:48)(Td) : (cid:107)f|Sr

,

p,θF (Td)(cid:107) < ∞(cid:111)
θ(cid:13)(cid:13)(cid:13)p
2θr·j|δj[f ](·)|θ(cid:17) 1
2r·j|δj[f ](·)|(cid:13)(cid:13)(cid:13)p
p,qB(Td)(cid:107) < ∞(cid:111)
(cid:17) 1

,

0

θ

2θr·j(cid:107)δj[f ](cid:107)θ
2r·j(cid:107)δj[f ](cid:107)p

p

:

:


(cid:13)(cid:13)(cid:13)(cid:16)(cid:80)
(cid:13)(cid:13)(cid:13) supj∈Nd

j∈Nd

0


(cid:16)(cid:80)

j∈Nd
supj∈Nd

0

0

θ < ∞,
θ = ∞.

:

:

0 < θ < ∞,
θ = ∞.

where

(cid:107)f|Sr

0))(cid:107) =

p,θF (Td)(cid:107) := (cid:107)2r·jδj[f ]|Lp((cid:96)q(Nd
(cid:110)

p,θB(Td) :=
Sr

(ii) 0 < p, θ ≤ ∞. Then

f ∈ D(cid:48)(Td) : (cid:107)f|Sr

where

(cid:107)f|Sr

p,θB(Td)(cid:107) := (cid:107)2r·jδj[f ]|(cid:96)θ(Lp(Nd

0)) =

Remark 3.6.

(i) Diﬀerent resolutions of unity ϕ, ψ ∈ Φ(R) used in (3.1) generate equiva-

lent norms in Sr

p,θF (Td) and Sr

p,θB(Td), respectively.

(ii) In case d = 1 the concepts of dominating mixed smoothness and isotropic smoothness

coincide, therefore we use the notation

p,θ(T) := Sr
F r

p,θF (T) and Br

p,θ(T) := Sr

p,θB(T).

(iii) In case θ = 2 with 1 < p < ∞ the space Sr

of dominating mixed smoothness Sr
classically normed by

p,θF (Td) coincides with the Sobolev space
p W (Td) is

p W (Td) including Lp(Td) if r = 0. Sr

(cid:107)f|Sr

p W (Td)(cid:107)(cid:48) :=

(1 + |ki|2)

.

(3.2)

(cid:13)(cid:13)(cid:13) (cid:88)

k∈Zd

(cid:98)f (k)

d(cid:89)

i=1

2 eik·x(cid:13)(cid:13)(cid:13)p

ri

We state the following embedding results without proof. For a reference see [26, 42] and

[16].

Lemma 3.7.

(i) Let 0 < p ≤ ∞ (F -case: p < ∞), 0 < θ ≤ ∞, r > σp. Then

and

p,θF (Td) (cid:44)→ Lmax{p,1}(Td) ∩ L1(Td)
Sr

p,θB(Td) (cid:44)→ Lmax{p,1}(Td) ∩ L1(Td).
Sr

(ii) Let 0 < p ≤ ∞ (F -case: p < ∞), 0 < θ ≤ ∞, r > 1

p,θF (Td) (cid:44)→ C(Td)
Sr

and Sr

p . Then
p,θB(Td) (cid:44)→ C(Td).

14

(iii) Let 0 < q < p ≤ ∞ (F-case: p < ∞), 0 < θ ≤ ∞ and r ∈ Rd. Then

p,θF (Td) (cid:44)→ Sr
Sr

q,θF (Td)

and Sr

p,θB(Td) (cid:44)→ Sr

q,θB(Td).

(iv) Let 0 < p ≤ ∞ (F-case: p < ∞), 0 < θ1 < θ2 ≤ ∞ and r ∈ Rd. Then

Sr

p,θ1

F (Td) (cid:44)→ Sr

p,θ2

F (Td)

and Sr

p,θ1

B(Td) (cid:44)→ Sr

p,θ2

B(Td).

(v) Let 0 < p < ∞, 0 < θ ≤ ∞ and r ∈ Rd. Then

p,min{p,θ}B(Td) (cid:44)→ Sr
Sr

p,θF (Td) (cid:44)→ Sr

p,max{p,θ}B(Td).

(vi) Let 0 < p < q < ∞, 0 < θ, ν ≤ ∞ and r1, r2 ∈ Rd with r1 > r2 fulﬁlling

Then

r1 − 1
p

= r2 − 1
q

.

p,θF (Td) (cid:44)→ Sr2
Sr1

q,νF (Td).

Lemma 3.8 (Jawerth-Franke embedding). Let 0 < p < q ≤ ∞, 0 < θ ≤ ∞, r1, r2 ∈ Rd such
that

r1 − 1
p

= r2 − 1
q

is fulﬁlled. Then

holds.

p,θF (Td) (cid:44)→ Sr2
Sr1

q,pB(Td)

As an important tool we introduce diﬀerence characterizations of Sr

p,θF (Td) and Sr

p,θB(Td)

in this section.
Deﬁnition 3.9. For a univariate function f : T → C we introduce the following diﬀerence
operator. Let h ∈ R and m ∈ N. Then for x ∈ R

m(cid:88)

k=0

(cid:18)m
(cid:19)

k

∆m

h f (x) :=

(−1)m−k

f (x + kh).

(3.3)

Deﬁnition 3.10. For a multivariate function f : Td → C and m ∈ N, h ∈ R, i ∈ [d] we denote
with ∆m,i
h f (x) the operator from (3.3) applied to the i-th direction. This allows us to deﬁne
for e ⊂ [d], m ∈ Nd and h ∈ Rd the operator

∆m,e

h f (x) :=

i∈e ∆mi,i

hi

f (x),

|e| > 0,
otherwise.

:

:

(cid:40)(cid:16)(cid:81)

(cid:17)

f (x)

15

Theorem 3.11. Let 0 < p < ∞, 0 < θ ≤ ∞, r ∈ Rd and m ∈ Nd such that σp,θ < r < m is
fulﬁlled. Then

(cid:107)f|Sr

p,θF (Td)(cid:107) (cid:16) (cid:107)f(cid:107)p +

(cid:107)f|Sr

p,θF (Td)(cid:107)e,m

holds with

(cid:107)f|Sr

p,θF (Td)(cid:107)e,m :=

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:104) (cid:88)

j∈Nd

0(e)

2θr·j(cid:16)(cid:16)(cid:89)

i∈e

and the usual modiﬁcation in case θ = ∞.

(cid:17)θ(cid:105) 1

θ

|∆m,e

h f (·)|dh

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)p

(cid:26)

2
1

−ji : i ∈ e,
: i /∈ e

2ji

|hi|≤

Proof . We refer to [18, Theorem 3.7]. There the case for constant smoothness vector r =
(cid:4)
(r, . . . , r) has been considered. The necessary modiﬁcations are straight forward.
Theorem 3.12. Let 0 < p, q < ∞, r ∈ Rd and m ∈ Nd such that σp < r < m is fulﬁlled.
Then

(cid:107)f|Sr

p,θB(Td)(cid:107) (cid:16) (cid:107)f(cid:107)p +

(cid:107)f|Sr

p,θB(Td)(cid:107)e,m

holds with

(cid:107)f|Sr

p,θB(Td)(cid:107)e,m :=

(cid:34) (cid:88)

j∈Nd

0(e)

2θr·j(cid:13)(cid:13)(cid:13)(cid:16)(cid:89)

i∈e

2ji

(cid:17)(cid:90)

|hi|≤

(cid:26)

2
1

−ji : i ∈ e,
: i /∈ e

(cid:35) 1

θ

(cid:13)(cid:13)(cid:13)θ

p

|∆m,e

h f (·)|dh

and the usual modiﬁcation in case θ = ∞.

Proof . We refer to [40, Theorem 3.7.1 and Remark 3.7.1]. There the outer sum is an integral.
(cid:4)
By discretizing this into dyadic parts one obtains the form stated above.

4 Sums of trigonometric polynomials

In this section we want to estimate the norm of a superposition of trigonometric polynomials

(cid:88)

j∈Nd

0

f =

fj

where fj are trigonometric polynomials of degree (cid:16) 2j. In contrast to the usual Littlewood-
Paley building blocks δj[f ] which are ‘almost‘ orthogonal we only need to restrict the degree
of the polynomial in the sequel.
Theorem 4.1. Let 0 < p < ∞, 0 < θ ≤ ∞, r ∈ Rd with r > σp,θ and (fj)j∈Nd
fj ∈ T 0

(cid:12)(cid:12)Lp((cid:96)θ)(cid:13)(cid:13) < ∞. Then

such that

0

fj converges unconditionally in Sr

0 < ν ≤ ∞ and ˜r < r.

0

p,θF (Td) if θ < ∞ and in every S˜r

p,νF (Td) with

j and(cid:13)(cid:13)2r·jfj
(i) (cid:80)

j∈Nd

(cid:88)
(cid:17)(cid:90)

e⊂[d]

(cid:88)

e⊂[d]

16

fj

p,θF (Td)

(cid:12)(cid:12)(cid:12)Sr

(cid:12)(cid:12)Lp((cid:96)θ)(cid:13)(cid:13)

(cid:13)(cid:13)(cid:13)(cid:88)

(ii) There is a constant C > 0 (independent of f ) such that

(cid:13)(cid:13)(cid:13) ≤ C(cid:13)(cid:13)2r·jfj
Proof . Step 1. We assume the unconditional convergence of(cid:80)
0))(cid:13)(cid:13).
(cid:12)(cid:12)Lp((cid:96)θ(Nd

p,νF (Td)) and prove the inequality

(cid:13)(cid:13)(cid:13) (cid:46)(cid:13)(cid:13)2r·jfj

θ = ∞ at least in S˜r

(cid:13)(cid:13)(cid:13)(cid:88)

(cid:12)(cid:12)(cid:12)Sr

p,θF (Td)

holds.

j∈Nd

(cid:96)∈Nd

f(cid:96)

0

0

(cid:96)∈Nd

0

(4.1)

f(cid:96) in Sr

p,θF (Td) (or in case

We mimic Step 1 of the proof of [40, Theorem 3.4.1]. This is rather technical in the multivariate
situation.Therefore we give a proof for the univariate situation ﬁrst. Later we explain the
necessary modiﬁcations for the multivariate situation. We prove

(cid:107)f|F r

p,θ(T)(cid:107) (cid:46)(cid:13)(cid:13)2rjfj
(cid:13)(cid:13)(cid:13) (cid:16)(cid:13)(cid:13)(cid:13)(cid:88)
(cid:13)(cid:13)(cid:13)(cid:104) ∞(cid:88)
(cid:13)(cid:13)(cid:13)p
2θjr(cid:16)
(cid:13)(cid:13)(cid:13)(cid:88)
(cid:46)(cid:13)(cid:13)(cid:13)(cid:16)(cid:88)
(cid:13)(cid:13)(cid:13)p

(cid:96)∈N0

(cid:12)(cid:12)Lp((cid:96)θ(N0))(cid:13)(cid:13)
(cid:90) 2−j
(cid:12)(cid:12)(cid:12)∆m
(cid:104)(cid:88)
θ(cid:13)(cid:13)(cid:13)p
2θrj|fj|θ(cid:17) 1

−2−j

j=0

2j

f(cid:96)

f(cid:96)

+

(cid:96)∈N0

h

.

(cid:96)∈N0

j∈N0

by using methods from diﬀerence characterization of Triebel-Lizorkin spaces. We start by
switching to the diﬀerence norm in F r

p,θ(T) with m > r

(cid:105)(cid:12)(cid:12)(cid:12)dh
θ(cid:13)(cid:13)(cid:13)p
(cid:17)θ(cid:105) 1

f(cid:96)

.

(4.2)

(cid:13)(cid:13)(cid:13)(cid:88)

(cid:96)∈N0

(cid:12)(cid:12)(cid:12)F r

f(cid:96)

p,θ(T)

First we estimate the Lp-norm of f and obtain trivially using either H¨older’s inequality (in
case θ ≥ 1) or the embedding (cid:96)θ (cid:44)→ (cid:96)1 (in case 0 < θ < 1) the estimation

Let a > 0 be a positive real number such that a > max{ 1
0 < λ ≤ min{p, q, 1}

θ} is fulﬁlled. Additionally choose

p , 1

(4.3)

(4.4)

such that

This is possible since

(1 − λ)a > σp,θ.

(cid:111)

(cid:110) 1

,

1
θ

p

(1 − λ)a > (1 − λ) max

Fix j ∈ N0 and use the identity

≥ (1 − min{p, θ}) max

f(cid:96) =

fj+(cid:96)

(cid:88)

(cid:96)∈N0

(cid:88)

(cid:96)∈Z

17

(cid:111)

(cid:110) 1

p

,

1
θ

= σp,θ.

with fj+(cid:96) = 0 for j + (cid:96) < 0. The unconditional convergence of(cid:80)

p,θF (Td) implies
(by Lemma 3.7) an unconditional convergence also in L1(Td). Therefore we can estimate the
integral means as follows

(cid:96)∈Z fj+(cid:96) in Sr

(cid:90) 2−j

−2−j

(cid:104)(cid:88)

(cid:12)(cid:12)(cid:12)∆m

h

2j

(cid:90) 2−j

−2−j

2j

fj+(cid:96)

(cid:105)(cid:12)(cid:12)(cid:12)dh ≤(cid:88)
(cid:90) 2−j

(cid:96)∈Z

(cid:96)∈N0

(cid:88)

(cid:96)≥0

2j

|∆m

h fj+(cid:96)(x)|dh.
(cid:90) 2−j
(cid:88)

2j

−2−j

(cid:96)<0

|∆m

h fj+(cid:96)(x)|dh +

−2−j

(cid:40)
2(cid:96)mP2j+(cid:96),afj+(cid:96)
2(1−λ)(cid:96)a[P2j+(cid:96),afj+(cid:96)]1−λM|fj+(cid:96)|λ

|∆m

h fj+(cid:96)(x)|dh. (4.6)

(cid:96) ≥ 0,
(cid:96) < 0.

:
:

(4.7)

(4.5)

We split the sum over (cid:96)

(cid:88)

(cid:96)∈Z

2j

(cid:90) 2−j

−2−j

Now we prove

|∆m

h fj+(cid:96)(x)|dh =
(cid:90) 2−j

|∆m

2j

−2−j

h fj+(cid:96)(x)|dh (cid:46)
(cid:90) 2−j

2j

−2−j

First we prove the case (cid:96) > 0. Applying Lemma A.12 immediately gives

|∆m

h fj+(cid:96)(x)|dh (cid:46) 2(cid:96)mP2j+(cid:96),a(x).

In case (cid:96) < 0 we estimate as follows

|∆m

h fj+(cid:96)(x)|dh (cid:46) 2j

(cid:90) 2−j

−2−j

Applying Lemma A.12 to the second factor yields

(cid:90) 2−j

−2−j

2j

(cid:90) 2−j

−2−j

2j

|∆m

h fj+(cid:96)(x)|1−λdh.
h fj+(cid:96)(x)|λ|∆m
(cid:90) 2−j

|∆m

h fj+(cid:96)(x)|dh (cid:46) 2(cid:96)(1−λ)a[P2j+(cid:96),afj+(cid:96)(x)]1−λ2j

|∆m
(cid:46) 2(cid:96)(1−λ)a[P2j+(cid:96),afj+(cid:96)(x)]1−λM|fj+(cid:96)|λ(x).

−2−j

h fj+(cid:96)(x)|λdh

Inserting the decomposition in (4.6) together with the estimates obtained in (4.7) into the last
term on the right hand side of (4.2). We obtain by µ-triangle inequality in Lp((cid:96)θ(N)) with
µ := min{p, θ, 1}

(cid:105)(cid:12)(cid:12)(cid:12)dh
θ(cid:13)(cid:13)(cid:13)p
(cid:17)θ(cid:105) 1

2j

(cid:90) 2−j

(cid:104)(cid:88)

(cid:12)(cid:12)(cid:12)∆m

(cid:13)(cid:13)(cid:13)(cid:104) ∞(cid:88)
2θjr(cid:16)
(cid:46)(cid:104)(cid:88)
×M|fj+(cid:96)|λ(x)|Lp((cid:96)θ(N0))(cid:107)µ(cid:105) 1

(cid:96)∈N0

−2−j

(cid:96)≥0

j=0

h

µ .

fj+(cid:96)

2µ(cid:96)(m−r)(cid:107)2(j+(cid:96))rP2j+(cid:96),afj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107)µ +

2µ(cid:96)[a(1−λ)−r]a|2(j+(cid:96))r[P2j+(cid:96),af2j+(cid:96)(x)]1−λ(x)

(4.8)

(cid:88)

(cid:96)<0

(4.9)

To estimate the ﬁrst summand we apply Theorem A.14, which gives

(cid:107)2(j+(cid:96))rP2j+(cid:96),afj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107) (cid:46) (cid:107)2(j+(cid:96))rfj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107).

(4.10)

18

An index shift yields

(cid:107)2(j+(cid:96))rP2j+(cid:96),afj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107) (cid:46) (cid:107)2jrfj(x)|Lp((cid:96)θ(N0))(cid:107).

(4.11)

In the norm expression in (4.9) we apply H¨older’s inequality with 1
(cid:107)2(j+(cid:96))r[P2j+(cid:96),afj+(cid:96)(x)]1−λM|fj+(cid:96)|λ(x)|Lp((cid:96)θ(N0))(cid:107) ≤ (cid:107)2(j+(cid:96))rP2j+(cid:96),afj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107)1−λ
λ|Lp((cid:96)θ(N0))(cid:107)λ.
(4.12)

×(cid:107)2(j+(cid:96))r(M|fj+(cid:96)|λ(x))

λ twice and obtain

1−λ , 1

1

Considering the factors in (4.12) separately we obtain by applying Theorem A.14

(cid:107)2(j+(cid:96))rP2j+(cid:96),afj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107) (cid:46) (cid:107)2(j+(cid:96))rfj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107).

(4.13)
(N0))-norm. This allows for

For the second factor we rewrite the Lp((cid:96)θ(N0))-norm as a L p
applying Theorem A.10.

λ

((cid:96) θ
λ

(cid:107)2(j+(cid:96))r(M|fj+(cid:96)|λ(x))

1

λ|Lp((cid:96)θ(N0))(cid:107) = (cid:107)2(j+(cid:96))rλM|fj+(cid:96)|λ(x)|L p

λ

(N0))(cid:107) 1

λ

((cid:96) θ
λ
(N0))(cid:107) 1

λ

(cid:46) (cid:107)2(j+(cid:96))rλ|fj+(cid:96)(x)|λ|L p
= (cid:107)2(j+(cid:96))rfj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107).

((cid:96) θ
λ

λ

Inserting the estimates from (4.13) and (4.14) into (4.12) implies

(cid:107)2(j+(cid:96))r[P2j+(cid:96),afj+(cid:96)(x)]1−λM|fj+(cid:96)|λ(x)|Lp((cid:96)θ(N0))(cid:107) ≤ (cid:107)2(j+(cid:96))rfj+(cid:96)(x)|Lp((cid:96)θ(N0))(cid:107).

(4.14)

A similar index shift as above yields

(cid:107)2(j+(cid:96))r[P2j+(cid:96),afj+(cid:96)(x)]1−λM|fj+(cid:96)|λ(x)|Lp((cid:96)θ(N0))(cid:107) ≤ (cid:107)2jrfj(x)|Lp((cid:96)θ(N0))(cid:107).

(4.16)
Finally, the choice of the parameters m, a, λ in (4.4) yields that the series in (4.16) converge
to a constant. Altogether we obtain the desired bound

Step 2. We explain the modiﬁcations in the multivariate situation. This time we start com-

f(cid:96) ∈ Sr

p,θF (Td) in terms of diﬀerences, cf. Theorem 3.11,

(4.15)

2µ(cid:96)[a(1−λ)−r](cid:105) 1

µ .

(cid:88)

2µ(cid:96)(m−r)+

(cid:96)<0

(4.17)

We continue estimating (4.9) and insert (4.11) and (4.15) to obtain

2θjr(cid:16)

2j

(cid:13)(cid:13)(cid:13)(cid:104) ∞(cid:88)

j=0

(cid:90) 2−j

−2−j

(cid:12)(cid:12)(cid:12)∆m

h

(cid:104)(cid:88)

(cid:96)∈N0

fj+(cid:96)

(cid:96)∈N0

(cid:13)(cid:13)(cid:13)(cid:88)
puting the norm of(cid:80)
(cid:12)(cid:12)(cid:12)Sr
(cid:13)(cid:13)(cid:13)(cid:88)
(cid:13)(cid:13)(cid:13)(cid:88)

(cid:96)∈Nd

(cid:96)∈Nd

f(cid:96)

f(cid:96)

0

0

For each e ⊂ [d] we have to show that

(cid:96)∈Nd

0

f(cid:96)

(cid:96)≥0

p,θ(T)

(cid:105)(cid:12)(cid:12)(cid:12)dh
θ(cid:13)(cid:13)(cid:13)p
(cid:17)θ(cid:105) 1
(cid:46) (cid:107)2jrfj|Lp((cid:96)θ(N0))(cid:107)(cid:104)(cid:88)
(cid:13)(cid:13)(cid:13) (cid:46) (cid:107)2jrfj|Lp((cid:96)θ(N0))(cid:107).
(cid:12)(cid:12)(cid:12)F r
(cid:13)(cid:13)(cid:13) (cid:16) (cid:107)f(cid:107)p +
(cid:13)(cid:13)(cid:13)e,m

(cid:46) (cid:107)2rj|fj||Lp((cid:96)θ(Nd

(cid:88)

(cid:107)f|Sr

0))(cid:107)

e⊂[d]

p,θF (Td)

p,θF (Td)(cid:107)e,m.

(cid:12)(cid:12)(cid:12)Sr

p,θF (Td)

19

(cid:110)E = (En)n∈N : En ⊂ Nd

E :=

of f used there by the representation(cid:80)

holds. A full proof consists basically in applying the arguments from above to every single
direction contained in e. Since this requires an extensive case study in e and (cid:96) we refer to the
proof given in detail in [40, Theorem 3.4.1, Step 1] where we have to replace the decomposition
Step 3. We prove (i) in case θ < ∞. To begin with, we deﬁne the set of sequences with ﬁnite
index sets given by

(cid:96)∈Zd fj+(cid:96).

0, |En| = n, En ⊂ En+1 for all n ∈ N, and

En = Nd

0

(cid:80)
Every sequence in E deﬁnes an order of summation. Furthermore for E ∈ E we deﬁne FEn :=
fj. We take a second sequence A ∈ E and consider FEn − FAm. This diﬀerence can be
written as a sum with ﬁnitely many fj. This fulﬁlls the assumptions necessary in Part 1 and
yields

j∈En

n=1

∞(cid:91)

(cid:111)

.

(cid:107)FEn − FAm|Sr
(cid:16)
(cid:88)

Obviously,

p,θF (Td)(cid:107) (cid:46)(cid:13)(cid:13)(cid:13)(cid:16)
2r·jθ|fj|θ(cid:17) 1

(cid:88)
θ ≤(cid:16)(cid:88)

θ(cid:13)(cid:13)(cid:13)p
2r·jθ|fj|θ(cid:17) 1

.

2r·jθ|fj|θ(cid:17) 1

θ ∈ Lp(Td)

j∈(En∪Am)\(En∩Am)

j∈(En∪Am)\(En∩Am)

j∈Nd

0

holds almost everywhere. Therefore Lebesgue’s dominated convergence theorem yields that we
ﬁnd for every ε > 0 a n0 ∈ N such that

(cid:107)FEn − FAm|Sr

p,θF (Td)(cid:107) ≤ ε

holds for all m, n > n0. Finally this implies unconditional convergence in Sr
θ = ∞ we stress on the embeddings

p,θF (Td). In case

and

p,1F (Td) (cid:44)→ S ˜r
Ss

p,νF (Td)

(cid:107)2s·jfj|Lp((cid:96)1)(cid:107) (cid:46) (cid:107)2r·jfj|Lp((cid:96)∞)(cid:107),

where r > s > σp,ν, s > ˜r and 0 < ν ≤ ∞. Applying the arguments from above to Ss
yields the result for S ˜r

p,1F (Td)
(cid:4)

p,νF (Td).

We will also need the following diagonal embedding relation which is the periodic counter-

part of [26, Prop. 2.4.1], see also the diagonal embedding in Lemma 3.7, (vi) above.
Lemma 4.2. Let 0 < p < q < ∞ and 0 < θ, ν ≤ ∞. Then

(cid:13)(cid:13)(cid:13)(cid:16)(cid:88)

j∈Nd

0

ν(cid:13)(cid:13)(cid:13)q
|fj|ν(cid:17) 1

(cid:46)(cid:13)(cid:13)(cid:13)(cid:16)(cid:88)

j∈Nd

0

θ(cid:13)(cid:13)(cid:13)p
2θ|j|(1/p−1/q)|fj|θ(cid:17) 1

(4.18)

holds for all (fj)j∈Nd

0

such that fj ∈ T 0
j .

Let us ﬁnally state the counterpart of Theorem 4.1 for the B-case. The proof is similar.

We omit the details.

20

Theorem 4.3. Let 0 < p < ∞, 0 < θ ≤ ∞, r ∈ Rd with r > σp and (fj)j∈Nd
fj ∈ T 0

0

such that

j and(cid:13)(cid:13)2r·jfj
(i) (cid:80)

j∈Nd

(ii) it holds

(cid:12)(cid:12)(cid:96)θ(Lp)(cid:13)(cid:13) < ∞. Then
(cid:12)(cid:12)(cid:12)Sr

(cid:13)(cid:13)(cid:13)(cid:88)

fj

j∈Nd

0

fj converges unconditionally in Sr

0 < ν ≤ ∞ and ˜r < r.

0

p,θB(Td) if θ < ∞ and in every S˜r

p,νB(Td) with

(cid:13)(cid:13)(cid:13) (cid:46)(cid:13)(cid:13)2r·jfj

(cid:12)(cid:12)(cid:96)θ(Lp(Td)(cid:13)(cid:13).

(4.19)

p,θB(Td)

Proof . We follow the proof of Theorem 4.1 with the usual modiﬁcations in the B-case.

(cid:4)

5 Sampling representations

In this section we provide theorems that allow for replacing the Fourier analytic building blocks
δj[f ] used to deﬁne the spaces Sr
j [f ], cf. Deﬁnition
3.5.
For the convenience of the reader we prove the following one-dimensional result ﬁrst.
Lemma 5.1. Let (cid:96), j ∈ N0, a > 0 and L > a + 1. Let further f ∈ C(T). Then

p,θB(Td) by building blocks qL

p,θF (Td) and Sr

|I L
2(cid:96)f (x)| (cid:46) 2a(cid:96)P2(cid:96)+j ,af (x)

for all x ∈ T.

Proof . We have
|I L

2j f (x)| ≤ (cid:88)
(cid:88)

|x− 2πu

+

−2j−1≤u≤2j−1−1

2j |<2−j

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

(cid:12)(cid:12)(cid:12)(cid:12)f
(cid:19)
(cid:18) 2πu
(cid:12)(cid:12)(cid:12)(cid:12)f
(cid:19)
(cid:18) 2πu

2j

2j

(cid:18)
(cid:18)

KL

π,j(x)

x − 2πu
2j

KL

π,j(x)

x − 2πu
2j

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) .

Considering the ﬁrst sum we recognize that there is only one index u0 fulﬁlling |x− 2πu0
Together with Lemma 2.5 this yields

2j

(cid:88)

−2j−1≤u≤2j−1−1

|x− 2πu

2j |<2−j

Lemma A.15 (i),(ii) implies(cid:88)

−2j−1≤u≤2j−1−1

|x− 2πu

2j |<2−j

2j

(cid:18) 2πu0

(cid:12)(cid:12)(cid:12)(cid:12)f
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) .
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) (cid:46)
(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) (cid:46) 2(cid:96)aP2j+(cid:96),af (x).

(cid:12)(cid:12)(cid:12)(cid:12)f
(cid:12)(cid:12)(cid:12)(cid:12)f

(cid:18) 2πu

(cid:19)

2j

(cid:18) 2πu

(cid:19)

2j

(cid:18)

KL

π,j(x)

x − 2πu
2j

(cid:18)

x − 2πu
2j

KL

π,j(x)

21

(5.1)

(5.2)

| < 2−j.

(5.3)

We continue estimating the sum in (5.2) by applying Lemma 2.5 and obtain

(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)f

(cid:18) 2πu

(cid:19)

2j

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

KL

π,j(x)

x − 2πu
2j

(cid:12)(cid:12)(cid:12)(cid:12)f

(cid:18) 2πu

2j

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) (cid:46)
(cid:88)
≤ 2a (cid:88)

|x− 2πu

2j |≥2−j

−2j−1≤u≤2j−1−1

−2j−1≤u≤2j−1−1

2j |≥2−j

|x− 2πu
(cid:46) P2j ,af (x)

(cid:88)

1

(2j|x − 2πu

2j |)L

|f ( 2πu
2j )|
(1 + 2j|x − 2πu

2j |)a

1

(|2jx − 2πu|)L−a

1

(|2jx − 2πu|)L−a .

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

(cid:18)

(cid:18)

With the help of Lemma A.15,(ii) we ﬁnd

(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)f

(cid:18) 2πu

(cid:19)

2j

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

KL

π,j(x)

x − 2πu
2j

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12) (cid:46) 2(cid:96)aP2j+(cid:96),af (x)

(cid:88)

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

1

(|2jx − 2πu|)L−a .

(5.4)

Estimating the last sum gives

(cid:88)

−2j−1≤u≤2j−1−1

|x− 2πu

2j |≥2−j

1

(|2jx − 2πu|)L−a ≤ 2 + 2

∞(cid:88)

u=1

1

(2πu)L−a ≤ C < ∞,

(5.5)

for L− a > 1, where C depends only on a and L. Putting (5.3), (5.4) and (5.5) together yields

|I L
2j f (x)| (cid:46) 2(cid:96)aP2j+(cid:96),af (x).

(cid:4)

It turns out that the technique used in the previous Lemma is also applicable for the

multivariate situation.
Lemma 5.2. Let (cid:96), j ∈ N d

0 and a > 0 with L > a + 1. Furthermore let f ∈ C(Td). Then

|qL
j [f ](x)| (cid:46) 2a|(cid:96)|1P2j+(cid:96),af (x)

holds with a constant independent of (cid:96), j, x and f .

Proof . The triangle inequality yields

j [f ](x)| ≤ (cid:88)

|qL

b∈{−1,0}d

|I L
j+b[f ](x)|.

(5.6)

22

j is a tensor product of univariate sampling operators I2ji , we can estimate component

Since I L
wise applying Lemma 5.1.

j f (x)| ≤ 2j1−1−1(cid:88)
2j1−1−1(cid:88)

u1=−2j1−1

|I L

. . .

. . .

(cid:46)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)f
2jd−1−1(cid:88)
2jd−1−1−1(cid:88)

ud=−2jd−1

(cid:18) 2πu1

2j1

u1=−2j1−1

ud−1=−2jd−1−1

(cid:46) . . .
(cid:46) 2a|(cid:96)|1P2j+(cid:96),af (x).

(cid:18)

(cid:19) d(cid:89)
(cid:18) 2πu1

i=1

2j1

, . . . ,

2πud
2jd

KL

π,ji

xi − 2πui
2ji

2a(cid:96)dP2j+(cid:96),a|df

, . . . ,

2πud−1
2jd−1

, xd

(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:19) d−1(cid:89)

i=1

(cid:18)

KL

π,ji

xi − 2πui
2ji

(cid:19)

Inserting this estimate into (5.6) and applying Lemma A.15],(ii) proves the claim.
Theorem 5.3. Let 0 < p, θ ≤ ∞ (p < ∞), L > max{ 1

θ} + 1 and r > max{ 1

θ}.
p , 1

(i) Then every f ∈ Sr

p , 1
p,θF (Td) admits the representation

(cid:88)

j∈Nd

0

f =

qL
j [f ],

(cid:4)

(5.7)

with unconditional convergence in Sr
convergence in S ˜r

p,νF (Td) for every r > ˜r and 0 < ν ≤ ∞ in case θ = ∞.

p,θF (Td) in case 0 < θ < ∞ and with unconditional

(ii) There is a constant C > 0 independent of f such that
j (f )|Lp((cid:96)θ)(cid:107) ≤ C(cid:107)f|Sr

(cid:107)2r·jqL

p,θF (Td)(cid:107)

(5.8)

holds for all f ∈ Sr

p,θF (Td).

Proof . Step 1. We prove (5.8). To begin with we choose a > 0 such that r > a > max{ 1
is fulﬁlled. We start for j ∈ Nd

0 with the Fourier decomposition

q}
p , 1

δj+(cid:96)[f ](x),

(5.9)

cf. (3.1) and obtain the point-wise estimation

For an easier presentation of the proof we assume that the constants A, B, C in Deﬁnition 3.3
are chosen in such a way that δj+(cid:96)[f ] ∈ T L
0. Then Lemma 2.7 implies

is fulﬁlled for all j ∈ Nd

f (x) =

(cid:88)
j [f ]|(x) ≤ (cid:88)

(cid:96)∈Zd

|qL

(cid:96)∈Zd

j

|qL

j [f ]|(x) ≤(cid:88)
j [f ]|(x) (cid:46) (cid:88)

(cid:96)>0

|qL

(cid:96)>0

23

|qL
j [δj+(cid:96)[f ]|(x).

|qL
j [δj+(cid:96)[f ]|(x).

2a|(cid:96)|1P2(cid:96)+j ,aδ(cid:96)+j[f ](x).

Applying Lemma 5.2 we obtain

Multiplying with the weight 2r·j we ﬁnd the point-wise estimate

j [f ]|(x) (cid:46) (cid:88)

2r·j|qL

2(a1−r)·(cid:96)2r·(j+(cid:96))P2(cid:96)+j ,aδ(cid:96)+j[f ](x).

(5.10)

(cid:96)>0

Now we take the Lp((cid:96)θ) (quasi)-norm on both sides. Due to u-triangle inequality in Lp((cid:96)θ)
with u = min{p, q, 1} we obtain

j [f ]|Lp((cid:96)θ)(cid:107) (cid:46) (cid:16)(cid:88)

2(a1−r)·(cid:96)u(cid:107)2r·(j+(cid:96))P2(cid:96)+j ,aδ(cid:96)+j[f ]|Lp((cid:96)θ)(cid:107)u(cid:17) 1

u

(cid:107)2r·jqL

≤ (cid:107)2r·jP2j ,aδj[f ]|Lp((cid:96)θ)(cid:107)(cid:16)(cid:88)

(cid:96)>0

2(a1−r)·(cid:96)u(cid:17) 1

u .

Here we need r > a where a is chosen as a > max{ 1
does not depend any longer on (cid:96). Therefore the sum over (cid:96) converges to a constant depending
only on a, r and the dimension d. This yields

θ}. The term inside the Lp((cid:96)θ) norm

p , 1

(cid:96)>0

(cid:107)2r·jqL

j [f ]|Lp((cid:96)θ)(cid:107) (cid:46) (cid:107)2r·jP2j ,aδj[f ]|Lp((cid:96)θ)(cid:107).

Applying Peetre maximal inequality (Theorem A.14) gives

(cid:107)2r·jqL

j [f ]|Lp((cid:96)θ)(cid:107) (cid:46) (cid:107)2r·jδj[f ]|Lp((cid:96)θ)(cid:107) = (cid:107)f|Sr

p,θF (Td)(cid:107)

Step 2. We prove (i). The equation (5.8) implies

Then Theorem 4.1 yields unconditional convergence of the series (cid:80)

j [f ]|Lp((cid:96)θ)(cid:107) < ∞.

(cid:107)2r·jqL

case 0 < θ < ∞

(cid:13)(cid:13)(cid:13)f − (cid:88)

|j|1<n

(cid:12)(cid:12)(cid:12)Sr

(cid:13)(cid:13)(cid:13) −→ 0

qL
j [f ]

p,θF (Td)

(n → ∞).

j∈Nd

0

qL
j [f ]. We show in

As a consequence of Deﬁnition 3.5 trigonometric polynomials are dense in Sr
For that reason we ﬁnd for every ε > 0 a trigonometric polynomial t such that

p,θF (Td) if θ < ∞.

(cid:13)(cid:13)(cid:13)f − (cid:88)

The u-triangle inequality gives
p,θF (Td)

qL
j [f ]

(cid:12)(cid:12)(cid:12)|Sr

|j|1<n

For n suﬃciently large we obtain by Lemma 2.8

(cid:13)(cid:13)(cid:13)t − (cid:88)

|j|1<n

(cid:12)(cid:12)(cid:12)Sr

p,θF (Td)

(cid:13)(cid:13)(cid:13)u

.

qL
j [f ]

(cid:107)f − t|Sr

p,θF (Td)(cid:107) < ε.

(cid:13)(cid:13)(cid:13)u ≤ (cid:107)f − t|Sr
p,θF (Td)(cid:107)u +
(cid:88)
t − (cid:88)
(cid:13)(cid:13)(cid:13) (cid:46)(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)
(cid:12)(cid:12)(cid:12)Sr

p,θF (Td)

qL
j [f ] =

j (t − f ).
qL

2θr·j|qL

|j|1<n

|j|1<n

|j|1<n

24

Applying Theorem 4.1 we have
j (t − f )
qL

(cid:13)(cid:13)(cid:13) (cid:88)

|j|1<n

θ(cid:13)(cid:13)(cid:13)p
j (t − f )|θ(cid:17) 1

.

Finally, Step 1 yields(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

|j|1<n

(cid:46) (cid:107)t − f|Sr

p,θF (Td)(cid:107)

θ(cid:13)(cid:13)(cid:13)p
j (t − f )|θ(cid:17) 1
(cid:12)(cid:12)(cid:12)Sr

qL
j [f ]

2θr·j|qL

(cid:13)(cid:13)(cid:13)f − (cid:88)

|j|1<n

(cid:13)(cid:13)(cid:13) ≤ C2ε.

p,θF (Td)

and hence, there is a constant C > 0 independent of n, f and t such that

The case θ = ∞ is based on the embedding
p,∞F (Td) (cid:44)→ Ss
Sr

p,pF (Td) (cid:44)→ S ˜r

p,νF (Td)

p , s > ˜r and 0 < ν < ∞ where the density argument from above is applied to
(cid:4)

with r > s > 1
p,pF (Td).
Ss
Theorem 5.4. Let 0 < p, θ ≤ ∞, L > 1

(i) Then every f ∈ Sr

p + 1, r > 1
p .
p,θB(Td) can be represented by

f =

qL
j (f ),

(5.11)

(cid:88)

j∈Nd

0

with unconditional convergence in Sr
convergence in S ˜r

p,νB(Td) for every r > ˜r and 0 < ν ≤ ∞ in case θ = ∞.

p,θB(Td) in case 0 < θ < ∞, and with unconditional

(ii) There is a constant C > 0 independent of f such that
j [f ]|(cid:96)θ(Lp)(cid:107) ≤ C(cid:107)f|Sr

(cid:107)2r·jqL

p,θB(Td)(cid:107)

(5.12)

holds for all f ∈ Sr

p,θB(Td).

Proof . We follow the proof of Theorem 5.3 with the usual modiﬁcation for the B-case.

(cid:4)

6 Sampling on Smolyak grids

In this section we analyze Smolyak’s algorithm, cf. (1.1), for the embedding

I1 : Sr1

p,θF (Td) → Sr2

q,νF (Td)

with the additional condition on the target space, namely r2 > σq,ν if q ≤ p and r2 + 1
max{ 1
we analyze the embeddings

q >
p−1, 0} in case p < q. We need those conditions in order to use Theorem 4.1. In addition,

p − 1

I2 : Sr

p,θF (Td) → Lq(Td).

25

6.1 The case of constant smoothness vectors

In this subsection we restrict our considerations to model spaces Sr
constant smoothness vector r = (r, . . . , r). We study the Smolyak type sampling operator

p,θF (Td) := Sr

p,θF (Td) with

T L
mf =

qL
j [f ]

(6.1)

(cid:88)

|j|1≤m

(cid:91)

H d

m :=

{j: |j|1≤m}

P 0
j .

that maps a continuous function to a trigonometric polynomial with frequencies contained in
a hyperbolic cross

The operator T L

m samples functions on a Smolyak grid

(cid:91)

(cid:110) 2π
(cid:111)
2j u : u ∈ Zd, −2ji−1 ≤ ui < 2ji−1 − 1, i ∈ [d]

,

SGd

m :=

|j|1≤m

which is also referred to as sparse grid. The name comes from the fact, that the number of
grid points (see Lemma 6.1) is much smaller then the number for an according dyadic full grid
(2dm), which heavily depends on the underlying dimension d of the space.

Figure 1: A sparse grid and associated hyperbolic cross in d = 2

Lemma 6.1. It holds

for all m ≥ 1

Proof . We refer to [32, Lemma 2].

|SGd

m| (cid:16) md−12m

(6.2)

(cid:4)

26

0141234101412341The case p < q
Theorem 6.2. Let 0 < p < q < ∞, 0 < θ, ν ≤ ∞ and L > 1
p − 1, 0}. Then
with r1 > 1
−m(r1−r2− 1

p fulﬁlling r1 > r2 + 1
mf|Sr2

p − 1
q > max{ 1
q,νF (Td)(cid:107) (cid:46) 2

(cid:107)f − T L

p + 1

p + 1. Furthermore, let r1, r2 ∈ R

q )(cid:107)f|Sr1

p,θF (Td)(cid:107)

(6.3)

holds for all m > 0.

Proof . First we prove the error estimate for the model space Sr
f into the series (5.7)

p,∞F (Td). We start expanding

(cid:107)f − T L

mf|Sr2

q,νF (Td)(cid:107) =

qL
j [f ]

q,νF (Td)

(cid:12)(cid:12)(cid:12)Sr2
(cid:12)(cid:12)(cid:12)S

|j|1>m

(cid:13)(cid:13)(cid:13) (cid:88)
(cid:13)(cid:13)(cid:13) (cid:46)(cid:13)(cid:13)(cid:13) (cid:88)
(cid:13)(cid:13)(cid:13) (cid:46)(cid:13)(cid:13)(cid:13) sup

|j|1>m

|j|1>m

(cid:13)(cid:13)(cid:13).

(cid:13)(cid:13)(cid:13).
j [f ]|(cid:13)(cid:13)(cid:13)p
j [f ]|(cid:13)(cid:13)(cid:13)p

.

2|j|1r1|qL

.

The embedding S

p− 1

q

F (Td) (cid:44)→ Sr2

q,νF (Td) (see Lemma 3.7) yields
p− 1

q

qL
j [f ]

r2+ 1
p,∞

F (Td)

qL
j [f ]

q,νF (Td)

(cid:12)(cid:12)(cid:12)Sr2
(cid:12)(cid:12)(cid:12)S

r2+ 1
p,∞

|j|1>m

r2+ 1
p,∞

(cid:13)(cid:13)(cid:13) (cid:88)
(cid:13)(cid:13)(cid:13) (cid:88)
(cid:13)(cid:13)(cid:13) sup

|j|1>m

|j|1>m

We apply Theorem 4.1 and obtain

qL
j [f ]

p− 1

q

F (Td)

|j|1(r2+ 1

p− 1

q )|qL

2

We can estimate this from above by
q )|qL

|j|1(r2+ 1

p− 1

2

j [f ]|(cid:13)(cid:13)(cid:13)p

≤ 2

−m(r1−r2− 1

p + 1

q )(cid:13)(cid:13)(cid:13) sup

j∈Nd

0

Applying Theorem 5.3 yields
(cid:107)f − T L

q,νF (Td)(cid:107) (cid:46) 2

mf|Sr2
p,θF (Td) (cid:44)→ Sr1

−m(r1−r2− 1

p + 1

q )(cid:107)f|Sr1

p,∞F (Td)(cid:107).

Finally, the embedding Sr1
Theorem 6.3. Let 0 < p < q < ∞, 0 < θ ≤ ∞, r > 1/p and L > 1/q + 1. Then

p,∞F (Td) (cf. Lemma 3.7) ﬁnishes the proof.

(6.4)
(cid:4)

(cid:107)f − T L

mf(cid:107)q (cid:46) 2

holds for all m > 0.

−(r− 1

p + 1

q )m(cid:107)f|Sr1

p,θF (Td)(cid:107)

Proof . We start expanding f into the series (5.7). This allows us to estimate

mf(cid:107)q ≤ (cid:13)(cid:13)(cid:13) (cid:88)

(cid:107)f − T L

|j|1>m
−(r− 1

p + 1

≤ 2

|qj[f ]|(cid:13)(cid:13)(cid:13)q
q )m(cid:13)(cid:13)(cid:13)(cid:88)

j∈Nd

0

27

q )|j|1|qj[f ]|(cid:13)(cid:13)(cid:13)q

2(r− 1

p + 1

.

We choose some parameters. Since L > 1
is fulﬁlled. Let ˜r := r − 1

q + 1 we ﬁnd ˜q ∈ R with p < ˜q < q such that L > 1

˜q + 1

p + 1
(cid:107)f − T L

˜q . Applying Lemma 4.2 yields
mf(cid:107)q ≤ 2

q )m(cid:13)(cid:13)(cid:13) sup

−(r− 1

p + 1

2˜r|j|1|qj[f ]|(cid:13)(cid:13)(cid:13)˜q

j∈Nd

0

Theorem 5.3 yields

˜q,∞F (Td)(cid:107).
Finally, using the diagonal embedding stated in Lemma 3.7, (vi) gives

mf(cid:107)q ≤ 2

q )m(cid:107)f|S ˜r

(cid:107)f − T L

p + 1

−(r− 1

(cid:107)f − T L

mf(cid:107)q (cid:46) 2

which ﬁnishes the proof.

−(r− 1

p + 1

q )m(cid:107)f|Sr

p,θF (Td)(cid:107),

(6.5)

(6.6)
(cid:4)

Remark 6.4. It is remarkable that Theorem 6.3 allows to deal in case q > 1 for every 0 < p < q
with L = 2. This means we can handle the quasi-Banach situation in the model space by using
de la Vall´ee-Poussin-type kernel.

Estimates for the uniform norm (q = ∞)

For θ = 2 and p > 1 the next result was obtained by Temlyakov in [38]. We extend this result
to the F-scale including the quasi-Banach cases.
Theorem 6.5. Let 0 < p ≤ ∞, 0 < θ ≤ ∞, L > 1 and r > 1

(cid:107)f − T L

mf(cid:107)∞ (cid:46) m(d−1)(1− 1

p )+2

−m(r− 1

p . Then
p )(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m > 0.

Proof . Step 1. We prove

(cid:107)f − T L

mf(cid:107)∞ (cid:46) (cid:107)f|S

r− 1
p∞,p B(Td)(cid:107)

(cid:40)

−m(r− 1
p )
2
m(d−1)(1− 1

p )2

−m(r− 1
p )

0 < p ≤ 1
p > 1.

:

:

(6.7)

We start as usual with expanding into the series (5.7). Triangle inequality yields

(cid:13)(cid:13)(cid:13)∞

≤ (cid:88)

|j|1>m

(cid:107)qL
j [f ](cid:107)∞.

We have to distinguish the cases 0 < p ≤ 1 and the case p > 1. We start with 0 < p ≤ 1. The
elementary embedding (cid:96)p(Nd

(cid:107)f − T L

mf(cid:107)∞ =

0) (cid:44)→ (cid:96)1(Nd
mf(cid:107)∞ ≤ 2

(cid:107)f − T L

qL
j [f ]

|j|1>m

(cid:13)(cid:13)(cid:13) (cid:88)
p ) (cid:88)
p )(cid:16) (cid:88)

0) yields
−m(r− 1

−m(r− 1

|j|1>m

|j|1>m

28

2(r− 1

p )|j|1(cid:107)qL

j [f ](cid:107)∞

(cid:17) 1

p .

≤ 2

2p(r− 1

p )|j|1(cid:107)qL

j [f ](cid:107)p∞

In case p > 1 we apply H¨older’s inequality with 1 = 1

mf(cid:107)∞ ≤ (cid:16) (cid:88)

(cid:107)f − T L

p )|j|1(cid:17) 1

p + 1

p(cid:48)(cid:16) (cid:88)

−p(cid:48)(r− 1

2

|j|1>m

|j|1>m

p(cid:48) and obtain

2p(r− 1

p )|j|1(cid:107)qL

j [f ](cid:107)p∞

(cid:17) 1

p .

Lemma B.1 yields

(cid:107)f − T L

mf(cid:107)∞ ≤ m(d−1)(1−p)2

p )(cid:16) (cid:88)

−m(r− 1

|j|1>m

2p(r− 1

p )|j|1(cid:107)qL

j [f ](cid:107)p∞

In both cases Theorem 5.4 yields (6.7).
Step 2. The Jawerth-Franke type embedding implies
r− 1
p∞,p B(Td)

p,θF (Td) (cid:44)→ S
Sr

(cf. Lemma 3.8). Applying this we obtain

(cid:107)f − T L

mf(cid:107)∞ (cid:46) m(d−1)(1− 1

p )+2

which proves the claim.

−m(r− 1

p )(cid:107)f|Sr

p,θF (Td)(cid:107),

(cid:17) 1

p .

(6.8)

(6.9)
(cid:4)

The case p ≥ q
Theorem 6.6. Let 0 < q ≤ p < ∞, 0 < θ, ν ≤ ∞, r1 > max{r2, 1
L > max{ 1

θ} with r2 > σp,ν and

p , 1

q,νF (Td)(cid:107) (cid:46) 2−m(r1−r2)m(d−1)( 1

ν − 1

θ )+(cid:107)f|Sr

p,θF (Td)(cid:107)

(6.10)

p , 1

θ} + 1. Then
mf|Sr2
(cid:107)f − T L

holds for all m > 0.

Proof . We have by Lemma 3.7 and Theorem 5.3

(cid:107)f − T L

mf|Sr2

q,νF (Td)(cid:107) (cid:46) (cid:107)f − T L

mf|Sr2

p,νF (Td)(cid:107) (cid:46) (cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

|j|1>m

We distinguish the cases θ ≤ ν and θ > ν. In case θ ≤ ν the embedding (cid:96)θ (cid:44)→ (cid:96)ν yields

2r2|j|1ν|qL

ν(cid:13)(cid:13)(cid:13)p
j [f ]|ν(cid:17) 1
θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1

.

2θr1|j|1|qL

.

θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1
θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1

.

(cid:107)f − T L

mf|Sr2

In case θ > ν H¨older’s inequality with θ

q,νF (Td)(cid:107) ≤ (cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

(cid:107)f − T L

mf|Sr2

Lemma B.1 gives

|j|1>m

2r|j|1θ|qL

ν and 1
1− ν

q,νF (Td)(cid:107) (cid:46) 2−m(r1−r2)(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)
(r1−r2)|j|1(cid:17) 1
θ(cid:16) (cid:88)
θ )(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

− ν
1− ν
2
θ

|j|1>m

yields

ν − 1

ν − 1

θ

|j|1>m

29

(cid:107)f − T L

mf|Sr2

q,νF (Td)(cid:107) (cid:46) 2−m(r1−r2)m(d−1)( 1

2θr1|j|1|qL

|j|1>m

Proceeding in both cases by applying Theorem 5.3 yields
q,νF (Td)(cid:107) (cid:46) 2−m(r1−r2)m(d−1)( 1

(cid:107)f − T L

mf|Sr2

ν − 1

θ )+(cid:107)f|Sr1

p,θF (Td)(cid:107),

which ﬁnishes the proof.

Theorem 6.7. Let 0 < q ≤ p < ∞, 0 < θ ≤ ∞, r > max{ 1

(cid:107)f − T L

mf(cid:107)q (cid:46) 2−mrm(d−1)(1− 1

p , 1
θ )+(cid:107)f|Sr

θ} and L > max{ 1
p,θF (Td)(cid:107)

(cid:4)
θ} + 1. Then

p , 1

(6.11)

holds for all m > 0.

Proof . We obtain by Lemma 3.7 and expanding into the series (5.7) the estimation

We distinguish the cases 0 < θ ≤ 1 and 1 < θ < ∞ now. In case 0 < θ ≤ 1 the embedding
(cid:96)θ (cid:44)→ (cid:96)1 yields

(cid:107)f − T L

(cid:107)f − T L

mf(cid:107)q (cid:46) (cid:107)f − T L

mf(cid:107)p =

.

.

qL
j [f ]

|j|1>m

(cid:13)(cid:13)(cid:13)p
(cid:13)(cid:13)(cid:13) (cid:88)
θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1
θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1
θ(cid:13)(cid:13)(cid:13)p
j [f ]|θ(cid:17) 1

2θr|j|1|qL

2θr|j|1|qL

|j|1>m

.

.

θ(cid:48) yields

2θr|j|1|qL

|j|1>m

θ + 1

mf(cid:107)q (cid:46) 2−mr(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)
θ(cid:48)(cid:16) (cid:88)
(cid:17) 1
θ )(cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

2−θ(cid:48)r|j|1

|j|1>m

|j|1>m

(cid:107)f − T L

mf(cid:107)q (cid:46) 2−mrm(d−1)(1− 1

In case 1 < θ < ∞ H¨older’s inequality with 1 = 1

mf(cid:107)q ≤ (cid:13)(cid:13)(cid:13)(cid:16) (cid:88)

(cid:107)f − T L

Lemma B.1 gives

We proceed in both cases by applying Theorem 5.3 and achieve

(cid:107)f − T L

mf(cid:107)q (cid:46) 2−mrm(d−1)(1− 1

θ )+(cid:107)f|Sr

p,θF (Td)(cid:107),

which ﬁnishes the proof.

(cid:4)
p,2F (Td) = Lp(Td) for 1 < p < ∞. Considering
Remark 6.8. We recall the coincidence S0
Theorem 6.2 with r2 going to zero we observe a singularity for the limit of this rate compared to
the rate obtained in Theorem 6.3. In case r2 = 0 Theorem 6.7 yields an additional logarithmic
factor (log(d−1) n)
1
2 . Technically this observation is due to the fact that a trigonometric super-
q,2F (Td) with 1 < p < ∞ and r2 > 0 can be estimated
position (cf. Section 4) in the space Sr2
by Theorem 4.1 whereas in case r2 = 0 this tool is not available and is replaced by applying
H¨olders inequality that yields the additional logarithm.

30

Small smoothness in case p ≥ q

p < r ≤ 1

θ , whenever 0 < θ < p. Here the structure of the spaces Sr

In this subsection we deal with the case of small smoothness. ‘Small smoothness’ refers to the
p,θF (Td)
smoothness range 1
p,θB(Td) seem to diﬀer signiﬁcanlty. Theorem 5.3 is not applicable and for that reason
and Sr
we cannot express functions f ∈ Sr
p,θF (Td) by the series (5.7), directly. Seeger/Ullrich [27, 28]
proved such an eﬀect for in that sense related Haar bases.
Theorem 6.9. Let 0 < q ≤ p < ∞ with 1 < θ < p and r ∈ R which satisﬁes

1
p

< r ≤ 1
θ

,

be given. Additionally, let L > max{ 1
such that

θ} + 1. Then for every ε > 0 there is a constant Cε > 0

p , 1

(cid:107)f − T L

mf(cid:107)q (cid:46) Cεm(d−1)(1−r+ε)2−rm(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m > 0.

p,θF (Td) (cid:44)→ Sr

p,pF (Td) holds, cf. Lemma 3.7, (v).

Proof . In case p > θ the embedding Sr
Therefore, Theorem 6.7 yields
(cid:107)f − T L

mf(cid:107)q (cid:46) m(d−1)(1− 1
(cid:46) m(d−1)(1− 1

p )2−rm(cid:107)f|Sr
p )2−rm(cid:107)f|Sr

p,pF (Td)(cid:107)
p,θF (Td)(cid:107)

(6.12)

for every r > 1
r > 1

p . We interpolate (6.12) with the result obtained in Theorem 6.7 for θ < p and

θ . Let us ﬁx some parameters. Obviously, we ﬁnd an ε > 0 arbitrary small such that

1
p

+ ε < r <

1
θ

+ ε

is fulﬁlled. Deﬁning r0 := 1

p + ε and r1 := 1
p,θF (Td) = [Sr0
Sr

θ + ε, complex interpolation yields
p,θF (Td), Sr1

p,θF (Td)]ν

for ν ∈ (0, 1) chosen such that r = (1 − ν)r0 + νr1 holds. Finally, this gives for the operator
id − T L

m

for all r ∈ R fulﬁlling 1

mf(cid:107)q (cid:46) m(d−1)(1−r+ε)2−rm(cid:107)f|Sr
(cid:107)f − T L
p < r ≤ 1
θ .

p,θF (Td)(cid:107)

(cid:4)

6.2 Anisotropic mixed smoothness

In this chapter we study model spaces Sr
entries, i.e.

p F (Td) where r is a vector with µ smallest smoothness

0 < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞.

(6.13)

To deal with this spaces we study an anisotropic reﬁned version of the operator deﬁned in
(6.1), denoted by

T L,r
m f :=

qL
j [f ].

(6.14)

(cid:88)

r·j≤m

1
r1

31

The sampling operator T L,r
frequencies in an anisotropic hyperbolic cross

m f maps a continuous function to a trigonometric polynomial with

(cid:91)

AH d,r

m :=

P 0
j .

{j: 1
r1

r·j≤m}

The operator T L

m samples functions on an anisotropic sparse grid

(cid:91)

(cid:111)
(cid:110) 2π
2j u : u ∈ Zd, −2ji−1 ≤ ui < 2ji−1 − 1, i ∈ [d]

.

AGd

m :=

r·j≤m

1
r1

Figure 2: Anisotropic hyperbolic cross in d = 2

Lemma 6.10. Let r ∈ Rd with

0 < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞.

Then

(6.15)

(6.16)

(6.17)

(6.18)

holds for all m ≥ 1.
Proof . Due to Deﬁnition 6.16 an upper bound for the cardinality of AGd,r

m is provided by

|AGd,r

m | (cid:16) mµ−12m

m | ≤ (cid:88)

|AGd,r

2|j|1.

r·j≤m

1
r1

Therefore Lemma B.3 in the appendix provides the upper bound in (6.18). A trivial lower
bound of 2m is provided by simply counting the sampling nodes of qj[f ] of the level j =
(m, 0, . . . , 0). A sharp bound can be obtained by using reproduction properties of T L,r
m for
trigonometric polynomials (cf. Lemma 2.8) with frequencies in AH d,r
m . The dimension of
(cid:4)
AH d,r

m is given by(cid:80)

r·j≤m 2|j|1.

1
r1

Remark 6.11. Comparing this estimate to the one for uniformly reﬁned sparse grids in Lemma
6.1 we recognize that the underlying dimension of the space plays no role for the asymptotic
bound. The dimension dependence is replaced by the µ largest reﬁnement directions.

32

The case p < q
Theorem 6.12. Let 0 < p < q < ∞ and 0 < θ ≤ ∞. Additionally let L > 1
q + 1, the
smoothness vector r ∈ Rd and the operator generating vector η ∈ Rd which are supposed to
satisfy

< r1 = η1 = . . . = rµ = ηµ < rµ+1 ≤ . . . ≤ rd

1
p

and

be given. Then

r1 < ηs < rs, s = µ + 1, . . . , d,

(cid:107)f − T L,η

m f(cid:107)q (cid:46) 2−mr1(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m > 0.

Proof . The proof is similar to the proof of Theorem 6.3.
Estimates for the uniform norm (q = ∞)
Theorem 6.13. Let 0 < p ≤ ∞, 0 < θ ≤ ∞. Additionally let L > 1, the smoothness vector
r ∈ Rd and the operator generating vector η ∈ Rd, which are supposed to satisfy

(cid:4)

< r1 = η1 = . . . = rµ = ηµ < rµ+1 ≤ . . . ≤ rd

1
p

(6.19)

and

be given. Then

r1 < ηs < rs, s = µ + 1, . . . , d,

(cid:107)f − T L,η

m f(cid:107)∞ (cid:46) m(µ−1)(1− 1

p )+2

−m(r1− 1

p )(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m ≥ 0.
Proof . We follow the proof of Theorem 6.5, where we insert the estimation from Lemma
(cid:4)
B.2.
The case q ≤ p
Theorem 6.14. Let 0 < q ≤ p < ∞, 0 < θ ≤ ∞ and L > max{ 1
θ} + 1. Additionally let the
smoothness vectors r ∈ Rd and the operator generating vector η ∈ Rd which are supposed to
satisfy

p , 1

< r1 = η1 = . . . = rµ = ηµ < rµ+1 ≤ . . . ≤ rd

(cid:111)

(cid:110) 1

1
θ

,

p

max

and

be given. Then

r1 < ηs < rs, s = µ + 1, . . . , d,

(cid:107)f − T L,η

m f(cid:107)q (cid:46) 2−mr1m(µ−1)(1− 1

θ )+(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m > 0.

33

Proof . We follow the proof of Theorem 6.7, where we insert the estimation from Lemma
(cid:4)
B.2.

In case of small smoothness the anisotropic mixed modiﬁcation of Theorem 6.9 reads as

follows:
Theorem 6.15. Let 0 < q ≤ p < ∞ with 1 < θ < p and L > max{ 1
the smoothness vector r ∈ Rd fulﬁlling

θ} + 1. Furthermore let

p , 1

1
p

< r1 ≤ 1
θ

,

and the operator generating vector η ∈ Rd, be given. Additionally, both are supposed to satisfy
the relation in (6.19). Then for every ε > 0 there is a constant Cε > 0 such that

(cid:107)f − T L,η

m f(cid:107)q ≤ Cεm(µ−1)(1−r1+ε)2−r1m(cid:107)f|Sr

p,θF (Td)(cid:107)

holds for all m > 0.

Proof . We follow the proof of Theorem 6.9 with the usual modiﬁcations.

(cid:4)

7 Linear sampling recovery

In this section we consider the optimality of convergence rates for linear sampling algorithms in
case of Triebel-Lizorkin spaces with mixed smoothness. As a benchmark quantity we introduce
linear sampling widths, cf. (1.2) in the introduction,

lin
n (Sr

p,θF (Td), Lq(Td)) :=

inf
i=1⊂Td
(ξi)n
i=1⊂Lq(Td)

(ψi)n

(cid:107)f|Sr

sup
p,θF (Td)(cid:107)≤1

(cid:13)(cid:13)(cid:13)f − n(cid:88)

i=1

(cid:13)(cid:13)(cid:13)q

f (ξi)ψi

.

This quantity can be interpreted as the minimal worst case error for the approximation of
p,θF (Td) by linear algorithms using n function evaluations and
functions from the unit ball of Sr
where the error is measured in Lq(Td). For θ = 2 and 1 < p < ∞ we have the coincidence
p,θF (Td). This case is of special interest in this section because it denotes the
p W (Td) = Sr
Sr
probably most famous representat of the F -scale. Choosing m in (6.14) such that n (cid:38) mµ−12m
an upper bound for lin

n (Sr
lin
n (Sr

p,θF (Td), Lq(Td)) is provided by
p,θF (Td), Lq(Td)) (cid:46)

(cid:107)f|Sr

sup
p,θF (Td)(cid:107)≤1

(cid:107)f − T L,η

m f(cid:107)q.

Approximation with general linear information in case of mixed order Sobolev spaces Sr
has beeb intensively studied in the past. We recall the concept of linear n-widths:
(cid:107)f − A(f )(cid:107)q.

p,θF (Td), Lq(Td)) :=

λn(Sr

inf

A:Sr

p,θF (Td)→Lq(Td)

rank A≤n

(cid:107)f|Sr

sup
p,θF (Td)(cid:107)≤1

p W (Td)

p,θF (Td), Lq(Td)) this quantity allows to benchmark linwar operators
In comparison to lin
using n pieces of linear information. Function evaluations are also linear information. There-
fore, we have the relation

n (Sr

λn(Sr

p,θF (Td), Lq(Td)) ≤ lin

n (Sr

p,θF (Td), Lq(Td)).

(7.1)

That means linear n-widths can serve as lower bounds for linear sampling n-widths.

34

7.1 The case p < q
Corollary 7.1. Let 0 < p < q < ∞ and 0 < θ, ν ≤ ∞. Furthermore, let r1, r2 ∈ R with r1 > 1
fulﬁlling r1 > r2 + 1

p

p − 1

q > max{ 1
p,θF (Td), Sr2

p − 1, 0}. Then
q,νF (Td)) (cid:46) (n−1 logd−1 n)r1−r2+ 1

p− 1

q

n (Sr1
lin

(7.2)

holds for all n > 0.

Proof . The corollary follows by Theorem 6.2 with the estimate from Lemma 6.1 for the
(cid:4)
number of functions evaluations.
Corollary 7.2. Let 0 < p < q < ∞ and 0 < θ ≤ ∞. Additionally, the smoothness vector
r ∈ Rd is supposed to satisfy
1
p

< r1 = . . . = . . . = rµ < rµ+1 ≤ . . . ≤ rd.

Then

holds for all n > 0.

lin
n (Sr

p,θF (Td), Lq(Td)) (cid:46) (n−1 log(µ−1) n)r1− 1

p + 1

q

Proof . The proof follows by Theorem 6.3 (µ < d: Theorem 6.12) with the estimate from
Lemma 6.1. In case µ < d we use the estimate in 6.10 for the number of function evaluations
(cid:4)
used by T L,η
m .
Corollary 7.3. Let r ∈ Rd fulﬁlling

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.

1
p

(7.3)

Let further 1 < p < q < ∞ with either p < q ≤ 2 or 2 ≤ p < q and 1 ≤ θ ≤ ∞. Then

p,θF (Td), Lq(Td)) (cid:16) lin

n (Sr

p + 1
q )

p,θF (Td), Lq(Td)) (cid:16) (n−1 log(µ−1) n)(r1− 1

λn(Sr
for all n ∈ N.
Proof . The upper bound for lin
follows by Corollary 7.2. The lower bounds for λn are
n
provided in case θ = 2 in Theorem C.1. For more general 1 ≤ θ ≤ ∞ we refer to Theorem
(cid:4)
C.2.
Remark 7.4. The result stated above is not completely new. In case 2 ≤ p, θ < q, (θ = q) and
1 < p, q < 2 with θ < q the upper bound can be obtained with the help of Besov space results
p,max{p,θ}B(Td).
proven by Dinh D˜ung in [8, 9] using the embedding relation Sr
Nevertheless the case 1 < p < q < 2 with θ > q and 2 ≤ p < q < θ is surprisingly new.
Besov spaces suﬀer in this range (and in the range interesting for embeddings) an additional
logarithmic factor. This parameter range includes the situation of Sobolev spaces in case 1 <
p < q < 2.

p,θF (Td) (cid:44)→ Sr

The following result is based on an observation by Novak/Triebel for the univariate situa-

tion, cf. [19].

35

(cid:40) 1

p

1 − 1

q

: 1
: 1

p + 1
p + 1

q ≥ 1, 1 ≤ θ ≤ ∞,
q ≤ 1, 1 ≤ θ ≤ q,

Theorem 7.5. Let 1 < p < 2 < q < ∞ and r >

fulﬁlling

Then

r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.

(7.4)

λn(Sr

p,θF (Td), Lq(Td)) (cid:18) n

holds for all n > 0.

−(r1− 1

p + 1

q ) (cid:46) lin

n (Sr

p,θF (Td), Lq(Td))

p,θF (Td), Lq(Td)) come from Theorem C.2. We prove the

Proof . Step 1. The bounds for λn(Sr
(non-sharp) lower bound for lin

n (Sr

lin
n (Sr

p,θF (Td), Lq(Td)) ≥

p,θF (Td), Lq(Td)). Sampling widths fulﬁll
(cid:107)f(cid:107)q.

inf
k=1⊂Td

(ξk)n

sup
p,θF (Td)(cid:107)≤1
(cid:107)f|Sr
f (ξk)=0, k=1,...,n

It is enough to consider the univariate situation. Let x1, . . . , xn ⊂ T be n arbitrary sampling
points in T. We construct a fooling function f1 ∈ W r

p (T) with

f1(xk) = 0,

k = 1, . . . , n.

For technical reasons we assume that n is a dyadic number, i.e. n = 2j0. It is easy to check
that there is an open box B ⊂ T with |B| ≥ 2−j0 and

B ∩ {x1, . . . , x2j} = ∅.

We consider the function

where

f1(x) := ϕ(2j0(x − x0))

(cid:40)

ϕ(x) :=

xM (1 − x)M :
:
0

x ∈ [0, 1],
else,

and x0 is chosen such that supp f1 ⊂ B. Obviously f1 is getting arbitrarily smooth with
increasing M such that it belongs to F r

p,θ(T) for M big enough.

Step 2. We estimate the norms of f1. We obtain by trivial computations

(cid:107)f1(cid:107)q =

|ϕ(2j0(x − x0))|qdx

q = 2

|ϕ(x)|qdx

q (cid:16)ϕ 2

− j0
q .

(7.5)

(cid:16)(cid:90) π

−π

q

− j0

(cid:16)(cid:90) π
(cid:90) 2−j

−π

(cid:17) 1
2jrθ(cid:16)

(cid:13)(cid:13)(cid:13)(cid:104) ∞(cid:88)

j=0

(cid:17) 1

θ(cid:13)(cid:13)(cid:13)p
(cid:17)θ(cid:105) 1

Additionally, using the characterization by diﬀerences (with m > 2M )

(cid:107)f1|F r

p,θ(T)(cid:107) (cid:16) (cid:107)f1(cid:107)p +

2j

−2−j

|∆m

h f1(x)|dh

it is easy to see that for r > 0 it holds

(cid:107)f1|F r

p,θ(T)(cid:107) (cid:46) 2j0r2

− j0
p .

36

Considering the function

f (x) := f1(x1)

, x ∈ Td,

and tensor norm properties yield

(cid:107)f|Lq(Td)(cid:107)
(cid:107)f|Sr

p,θF (Td)(cid:107) (cid:38) 2

−j0(r1− 1

p + 1

q ) (cid:16) n

−(r1− 1

p + 1

q ).

Finally, a monotonicity argument proves this lower bound for all n ∈ N.

(7.6)

(cid:4)

Remark 7.6. The fact that the exponents of the main rate and the exponent of the logarithm
in the upper bound obtained in Corollary 7.2 coincide and additionally the main rate is sharp
seems to be a strong indication for the conjecture

lin
n (Sr

p,θF (Td), Lq(Td)) (cid:16) (n−1 logµ−1 n)r1− 1

p + 1

q

in case 1 < p < q < ∞, 1 ≤ θ ≤ ∞ and r ∈ Rd with

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd.

1
p

7.2 Results for the uniform norm (q = ∞)
Corollary 7.7. Let 0 < p, θ < ∞ (θ = ∞) and the smoothness vector r ∈ Rd which is supposed
to satisfy

< r1 = . . . = . . . = rµ < rµ+1 ≤ . . . ≤ rd,

1
p

be given. Then

lin
n (Sr

p,θF (Td), L∞(Td)) (cid:46) (n−1 logµ−1 n)r1− 1

p log(µ−1)(1− 1

p )+ n

holds for all n > 0.

Proof . The upper bound follows by Theorem 6.13 (µ = d: Theorem 6.5) with the estimate
from Lemma 6.10 for the number of used function evaluations. In case µ = d this is provided
(cid:4)
by Theorem 6.1.
Theorem 7.8. Let r ∈ Rd fulﬁlling

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.

1
2

(7.7)

and 1 < p < ∞ (or 1 < p = q). Then

λn(Sr

2W (Td), L∞(Td)) (cid:16) lin

n (Sr

2W (Td), L∞(Td)) (cid:16) n−(r1− 1

2

) log(µ−1)r n(cid:107)f|Sr

2W (Td)(cid:107)

Proof . The upper bound was originally obtained by Temlyakov in [38]. In our case it follows
by Theorem 6.5 where we insert the relation from Lemma 6.1 for the number of points used
by T L
m. The lower bound is based on Ismagilov’s duality theorem [17]. Recently, an alternative
proving method was provided in [4]. There, additionally, the authors cared for the (here:
(cid:4)
hidden) d-dependence of the constants.

37

7.3 The case q ≤ p
Corollary 7.9. Let 0 < q ≤ p < ∞, 0 < θ, ν ≤ ∞, r1 > max{r2, 1

θ} with r2 > σp,ν. Then

p , 1

n (Sr1
lin

p,θF (Td), Sr2

q,νF (Td)) (cid:46) (n−1 logd−1 n)r1−r2 log(d−1)( 1

ν − 1

θ )+ n

(7.8)

holds for all n > 0.

Proof . The corollary follows by Theorem 6.6 with the estimate from Lemma 6.1 for the
(cid:4)
number of functions evaluations.
Corollary 7.10. Let 0 < q ≤ p < ∞ and 0 < θ ≤ ∞. Additionally, the smoothness vector
r ∈ Rd is supposed to satisfy

< r1 = . . . = . . . = rµ < rµ+1 ≤ . . . ≤ rd.

(cid:111)

(cid:110) 1

,

1
θ

p

max

Then

(cid:111)

(cid:110) 1

,

1
θ

p

lin
n (Sr

p,θF (Td), Lq(Td)) (cid:46) (n−1 log(µ−1) n)r1 log(µ−1)(1− 1

θ )+ n

holds for all n > 0.

Proof . The proof follows by Theorem 6.7 (µ < d: Theorem 6.14) where we use the estimate
from Lemma 6.1 for the number of function evaluations used by T L
m. In case µ < d we use
(cid:4)
Lemma 6.10.
Corollary 7.11. Let r ∈ Rd fulﬁlling

max

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.

(7.9)

1 ≤ θ ≤ ∞ and 1 < q ≤ p < ∞. Then

n−r1 log(µ−1)(r1+( 1

2

holds for all n > 0.

θ )+) n (cid:16) λn(Sr
− 1
n (Sr

(cid:46) lin

p,θF (Td), Lq(Td))
p,θF (Td), Lq(Td)) (cid:46) n−r1 log(µ−1)(r1+(1− 1

θ )+) n

Proof . The upper bound for lin
λn are provided in Theorem C.2. Finally the relation in (7.1) concludes the proof.

n in case µ = d is obtained in Corollary 7.10. The bounds for
(cid:4)

Remark 7.12. The same or less integrability in the target than in the model space is one of
p W (Td) or
the probably most interesting open problems in connection with sampling widths in Sr
p,θF (Td), θ > 1. Even in the simply looking Hilbert case with p = q = θ = 2 it
more general in Sr
2 W (Td), L2(Td)). This problem was ﬁrst discovered
is not clear what is the exact rate for lin
p,∞B(Td). Later Sickel [29] and Sickel/Ullrich [32, 34] reduced the gap for
by Temlyakov for Sr
spaces Sr

n (Sr

p,θB(Td) and Sr

p,θF (Td).

38

Corollary 7.13. Let 1 < q ≤ p < ∞ and θ > p. Additionally, let the smoothness vector
r ∈ Rd satisfying

r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd

with 1

p < r1 ≤ 1
lin
n (Sr

θ , be given. Then for every ε > 0 there is a constant Cε > 0 such that
p,θF (Td), Lq(Td)) ≤ Cε(n−1 logµ−1 n)r1(logµ−1 n)1−r1+ε(cid:107)f|Sr
p,θF (Td)(cid:107)

holds for all m > 0.

Proof . The proof follows by Theorem 6.9 (µ < d: Theorem 6.15) where we use the estimate
from Lemma 6.1 for the number of function evaluations used by T L
m. In case µ < d we use
(cid:4)
Lemma 6.10.

Remark 7.14. In case of small smoothness 1
θ the structural deﬁciency mentioned
just before Theorem 6.9 yields a worse convergence rate in Corollary 7.13 compared to the
normal situation studied in Corollary 7.11.

p < r1 ≤ 1

Remark 7.15. The following ﬁgures illustrate the known relations between linear sampling
and linear approximation for Sobolev spaces depending on the parameters p and q.

1
q

1

1
2

λn(Sr

p W, Lq)

α = r1 − ( 1

p − 1

q )+

α = r1 − 1

p + 1
2

1
q

1

1
2

lin
n (Sr

p W, Lq)

(cid:46)(cid:18)

logµ−1 n

n

(cid:19)r1

µ−1

2 n

log

α = r1 − 1

p + 1
q

(cid:46)(cid:18)

logµ−1 n

n

(cid:19)r1− 1

p + 1
q

α = r1 − 1

2 + 1
q

1
2

1
p

1

α = r1 − 1

p + 1
q

1
2

1
p

1

Figure 3: The parameter α refers to the sharp rate ( (log n)µ−1

n

)α.

The lower right square in the right picture describes the parameter range, where sampling
recovery behaves signiﬁcantly worse compared to linear approximation. The upper left triangle
in the right picture is the parameter range according to Remark 7.12.

8 Sampling recovery and Gelfand n-widths

The considerations above cover linear algorithms in the classical sense. Last but not least we
consider an extension of that concept, so-called approximation using standard information, cf.

39

[20, 21]. This means we consider algorithms that are deﬁned as a composition of a linear infor-
mation map and a possibly non-linear reconstruction operator. To avoid further technicalities
p W (Td) in this subsection. We introduce general sampling
we restrict to Sobolev Spaces Sr
widths

n(Sr

p W (Td), Lq(Td)) := inf

(cid:107)f|Sr

sup
p W (Td)(cid:107)≤1

ϕ
An

(cid:107)f − ϕ(An(f ))(cid:107)q,

where An denotes linear mappings of the form

An : f ∈ C(Td) (cid:55)→ (f (x1), . . . , f (xn))

(the so called information map) and ϕ : Cn (cid:55)→ Lq(Td) is a (non-linear) approximation mapping.
It is trivial to see that

n(Sr

p W (Td), Lq(Td) ≤ lin

n (Sr

p W (Td), Lq(Td))

(8.1)

holds. Therefore (possibly non-sharp) upper bounds for sampling widths are always provided
by linear sampling widths. To consider questions on optimality of these bounds we consider
Gelfand n-widths

cn(Sr

p W (Td), Lq(Td)) :=

(cid:107)f(cid:107)q.

B: Sr

inf

sup
p W (Td)(cid:107)≤1
f∈ker B

(cid:107)f|Sr

p W (Td)→Cn
linear
p W (Td) → Cn. This quantity can be reformu-

Here B denotes a general linear mapping B : Sr
lated and scaled to

cn(Sr

p W (Td), Lq(Td)) (cid:16)

B: Sr

inf

p W (Td)→Cn
linear

(cid:107)f − g(cid:107)q.

sup

(cid:107)f(cid:107),(cid:107)g(cid:107)≤1
Bf =Bg

This quantity measures the minimal (over all information mappings) worst case distance of
p W (Td) which can not be distinguished by the information
elements in the unit ball of Sr
mapping B. This immediately gives

cn(Sr

p W (Td), Lq(Td)) (cid:46) n(Sr

p W (Td), Lq(Td)).

The following ﬁgure illustrates the exponents of the rates for cn(Sr

p W, Lq) and n(Sr

p W, Lq):

40

1
q

1

1
2

cn(Sr

p W, Lq)

α = r1

α = r1 − 1

2 + 1
q

n(Sr

p W, Lq)

(cid:46)(cid:18)

logµ−1 n

n

(cid:19)r1

µ−1

2 n

log

1
q

1

1
2

(cid:46)(cid:18)

logµ−1 n

n

(cid:19)r1− 1

p + 1
q

α = r1 − 1

p + 1
q

1
2

1
p

1

α = r1 − 1

p + 1
q

1
2

1
p

1

Figure 4: The parameter α refers to the sharp rate ( (log n)µ−1

n

)α.

Interesting for our considerations is the range 2 < p < q < ∞, which the lower left triangle

covers. We obtain the following result for the lower left triangle in Figure 8.
Corollary 8.1. Let 2 ≤ p < q < ∞ and r ∈ Rd fulﬁlling

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.

1
p

(8.2)

Then

n(Sr

p W (Td), Lq(Td)) (cid:16) cn(Sr
(cid:16) λn(Sr

p W (Td), Lq(Td)) (cid:16) lin
p W (Td), Lq(Td)) (cid:16) (n−1 logd−1 n)r− 1

p W (Td), Lq(Td))
q .

n (Sr

p + 1

Remark 8.2. In the parameter range 2 < p < q < ∞ permitting non-linear reconstruction
operators does not help. Optimal rates can be achieved by completely linear sampling algorithms.

Considering this more general algorithms the result in Theorem 7.5 can be strengthened.

Corollary 8.3. Let 1 < p < 2, q > p and r ∈ Rd such that

< r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞

1
p

(8.3)

holds. Then

p W (Td), Lq(Td)) (cid:18) n

cn(Sr
holds for all n ∈ N.
Proof . The proof can be obtained by following the construction of the lower bound in Theorem
7.5, where we recognize that due to [19, Poposition 19] the stronger inequality

p W (Td), Lq(Td)).

q ) (cid:46) n(Sr

p + 1

−(r1− 1

n(Sr

p W (Td), Lq(Td)) ≥

inf
k=1⊂Td

(ξk)n

sup
p W (Td)(cid:107)≤1
(cid:107)f|Sr
f (ξk)=0, k=1,...,n

(cid:107)f(cid:107)q

holds. The estimations for cn(Sr

p W (Td), Lq(Td)) were obtained in Corollary C.6.

(cid:4)

41

p W (Td), Lq(Td)),
Remark 8.4. As a consequence of the lower bound in Corollary 8.3 for n(Sr
we obtain that in the parameter range 1 < p < 2 < q < ∞ even linear approximation behaves
signiﬁcantly better than sampling recovery with a possibly non-linear reconstructing operator.

Remark 8.5. With the help of the results mentioned in Remark C.5 it is possible to formulate
p,θF (Td). For that
analogs to Corollaries 8.3 and 8.1 in case of Triebel-Lizorkin spaces Sr
p,θF (Td) which is
purpose we need the boundedness of the lifting operator (cf.
provided in [26, Section 2.2.6] for 1 ≤ θ ≤ ∞. We leave the details to the reader.

(C.4)) in Sr

A Appendix: Tools from Fourier analysis

The following Lemma collects trivial properties of the Fourier transform and Fourier coeﬃ-
cients, cf. (1.14).
Lemma A.1. Let f, g ∈ L1(R), λ > 0 and h ∈ R. Then

(i) F[f (· − h)](ξ) = e−ihξFf (ξ),
(ii) F[eih·f (·)](ξ) = Ff (ξ − h),
(iii) λF[f (λ·)](ξ) = Ff
(iv) Ff (ξ)Fg(ξ) = 1√
Lemma A.2 (Riemann-Lebesgue). Let f ∈ L1(R). Then

F[f ∗ g](ξ).

(cid:16) ξ

(cid:17)

2π

,

λ

(i) Ff is continuous.
(ii) |Ff (ξ)| −→ 0

(|ξ| −→ ∞)

Close related to the Fourier transform is the theory of Fourier coeﬃcients and Fourier series.

Lemma A.3. Let f, g ∈ L1(T). Then

(i) (cid:92)f (· + h)((cid:96)) = e−i(cid:96)h(cid:98)f ((cid:96)),
(ii) (cid:91)f ∗ g((cid:96)) = 2π(cid:98)f ((cid:96))(cid:98)g((cid:96)).
Lemma A.4. Let f ∈ L1(T) with(cid:80)

(cid:96)∈Z |(cid:98)f ((cid:96))| < ∞. Then
(cid:98)f ((cid:96))ei(cid:96)x

(cid:88)

f (x) =

(cid:96)∈Z

for all x ∈ T.

Lemma A.5 (Poisson summation). Let f ∈ L1(R). Then its periodization (cid:80)

k∈Z f (· + 2πk)
converges absolutely in the norm of L1([−π, π]). Furthermore its formal Fourier series is given
by

(cid:88)

f (· + 2πk) =

1√
2π

Ff ((cid:96))ei(cid:96)·

(cid:88)

(cid:96)∈Z

Proof . We refer to [36, p. 252].

k∈Z

42

(cid:4)

Deﬁnition A.6. Let f ∈ Lloc

1 (Td). Then we deﬁne the Hardy-Littlewood maximal operator as

(cid:90)

M f (x) := sup
Q(cid:51)x

1
|Q|

Q

|f (x)|dx

where the Q are axis parallel squares that are centered in x.
Theorem A.7 (Hardy-Littlewood maximal inequality). Let 1 < p ≤ ∞ and f ∈ Lp(Td).
Then we have

(cid:107)M f|Lp(Td)(cid:107) (cid:46) (cid:107)f|Lp(Td)(cid:107).

Proof . This Theorem can be interpreted as a special case of Theorem A.8. We refer to the
(cid:4)
proof there.
Theorem A.8 (Feﬀerman-Stein maximal inequality). Let 1 < p < ∞, 1 < θ ≤ ∞ and
(fk)k ⊂ Lp((cid:96)θ). Then we have

(cid:107)M fk|Lp((cid:96)θ)(cid:107) (cid:46) (cid:107)fk|Lp((cid:96)θ)(cid:107).

Proof . We refer to [13, Theorem 1].

(cid:4)

For our purpose we need the following component-wise maximal function.

Deﬁnition A.9. Let i ∈ [d] and f ∈ Lloc
operator in the i-th direction as

1 (Td) then we deﬁne the Hardy-Littlewood maximal

Mif (x) := sup
t>0

1
2t

|f (x1, . . . , xi−1, xi + y, xi+1, . . . , xd)|dy.

It is necessary to prove that this operator maps two equivalent representatives of f to the

same equivalence class. Having this in mind, one can show the following theorem:
Theorem A.10. Let 1 < p, q < ∞ and (fk)k ⊂ Lp((cid:96)θ) and i ∈ [d]. Then we have

(cid:107)Mifk|Lp((cid:96)θ)(cid:107) (cid:46) (cid:107)fk|Lp((cid:96)θ)(cid:107).

Proof . The proof is an easy consequence of the fact that the Lp(Td)-norm is a cross norm

|Mifk(x1, . . . , xd)|q(cid:17) p

q dx1 . . . dxd

(cid:17) 1

p

(cid:90) t

−t

(cid:90) π

(cid:16) (cid:88)

−π

k∈Nd

0

. . .

(cid:16)(cid:90) π
(cid:16)(cid:90)

π

Td−1

(cid:107)Mifk|Lp((cid:96)θ)(cid:107) =

=

(cid:16)(cid:90)
(cid:46) (cid:16)(cid:90)

Td−1

Td−1

= (cid:107)fk|Lp((cid:96)θ)(cid:107).

43

. . .(cid:107)Mifk(x1, . . . , xi−1,·, xi+1, . . . , xd)|Lp(T, (cid:96)θ(Nd

0))(cid:107)pdx1 . . . dxi−1dxi+1 . . . dxd

(cid:17) 1

p .

Applying Theorem A.8 with d = 1 yields

. . .(cid:107)Mifk(x1, . . . , xi−1,·, xi+1, . . . , xd)|Lp((cid:96)θ)(cid:107)pdx1 . . . dxi−1dxi+1 . . . dxd

. . .(cid:107)fk(x1, . . . , xi−1,·, xi+1, . . . , xd)|Lp((cid:96)θ)(cid:107)pdx1 . . . dxi−1dxi+1 . . . dxd

(cid:17) 1

p

(cid:17) 1

p

(cid:4)

Deﬁnition A.11 (Peetre maximal operator). Let a > 0 and b > 0 then we deﬁne for f ∈
C(Td)

Additionally we deﬁne for e ⊂ [d] a component wise Peetre maximal operator by

Pb,af (x) := sup
y∈Rd

(1 + b1|y1|)a . . . (1 + bd|yd|)a .

|f (x + y)|

Pb,a|ef (x) := sup

y∈Rd(e)

(cid:81)

|f (x + y)|
i∈e(1 + bi|yi|)a .

Lemma A.12. Let a, b > 0 and

(cid:88)

|k|<b

f =

ˆf (k)eikx :

x ∈ T

be a univariate trigonometric polynomial with frequencies in [−b, b]. Then there exists a con-
stant C > 0 such that

|∆m

h (f, x)| ≤ C min{1,|bh|m} max{1,|bh|a}Pb,af (x)

holds.

Proof . We refer to [40, Lemma 3.3.1].
Theorem A.13. Let 0 < p ≤ ∞ and f be a trigonometric polynomial with

f =

ˆf (k)eik·x

(cid:88)

|ki|≤bi
i=1,...,d

and a > 1

p . Then there is a constant C > 0 (independent of f and b) such that

(cid:107)Pb,af(cid:107)p ≤ C(cid:107)f(cid:107)p

holds.

(A.1)

(cid:4)

(cid:4)

Proof . We refer to [40, Thm. 4.1.3].
Theorem A.14. Let 0 < p < ∞, 0 < θ ≤ ∞ and (fj)j∈Nd
polynomials with

0

(cid:88)

fj =

ˆf (k)eik·x

be a sequence of trigonometric

|ki|≤bj
i
i=1,...,d

and a > max{ 1

θ}. Then there is a constant C > 0 (independent of f and bj) such that

p , 1

(cid:107)Pbj ,afj|Lp((cid:96)θ)(cid:107) ≤ C(cid:107)fj|Lp((cid:96)θ)(cid:107)

holds.

Proof . We refer to [40, Thm. 4.1.3].
Lemma A.15. Let a > 0, b > 0 and f ∈ C(T).

44

(cid:4)

(i) If |x − x0| < 1

b then

holds.

(ii) Furthermore let b(cid:48) > b > 0. Then

|f (x0)| ≤ 2aPb,af (x)

Pb,af (x) ≤(cid:16) b(cid:48)

(cid:17)a

Pb(cid:48),af (x).

b

Proof . The following estimation yields (i)

|f (x0)| ≤

(1 + |x − x0|b)a (1 + |x − x0|b)a ≤ 2a sup
x0∈R

|f (x0)|

|f (x0)|

(1 + |x − x0|b)a = 2aPb,af (x).

We prove (ii). The trivial estimation p+1
|f (y)|

Pb,af (x) = sup
y∈R

≤ (cid:16) b(cid:48)

b

(1 + b|x + y|)a ≤ sup
(cid:17)a
y∈R

Pb(cid:48),af (x).

q+1 ≤ p

q for p > q > 0 yields

|f (y)|

(1 + b(cid:48)|x + y|)a

(1 + b(cid:48)|x + y|)a
(1 + b|x + y|)a

B Appendix: Some multi-indexed exponential sums

Lemma B.1. Let r > 0. Then (cid:88)

2−r|j|1 (cid:46) md−12−rm

|j|1>m

holds for all m ≥ 1.
(cid:4)
Proof . We refer to [37, p. 9, Lemma B].
Lemma B.2. Let r, η ∈ Rd with 0 < r1 = η1 = . . . = rµ = ηµ < rµ+1 ≤ . . . ≤ rd and

(cid:4)

(B.1)

(B.2)

(cid:4)

(B.3)

(B.4)

(cid:4)

r1 < ηs < rs for s = µ + 1, . . . , d. Then(cid:88)

η·j>m

1
r1

holds for all m ≥ 1.
Proof . We refer to [37, p. 9, Lemma B].
Lemma B.3. Let r ∈ Rd with

2−r·j (cid:46) mµ−12−r1m

and µ ≤ d. Then

0 < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞

(cid:88)

holds for all m ≥ 1.
Proof . We refer to [37, p. 10, Lemma D].

r·j≤m

1
r1

2|j|1 (cid:16) mµ−12m

45

C Appendix: Known results on n-widths
Theorem C.1. Let 1 ≤ p, q < ∞, (p > 1) and r ∈ Rd fulﬁlling

(1/p − 1/q)+ < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞

for a µ ≤ d. Then we have

(cid:16) (log n)µ−1
(cid:16) (log n)µ−1
(cid:16) (log n)µ−1

n

n

(cid:17)r1−(1/p−1/q)+
(cid:17)r1−1/p+1/2
(cid:17)r1−1/2+1/q



:

λn(Sr

p W (Td), Lq(Td)) (cid:16)

q ≤ 2, or
1/p + 1/q ≥ 1, q > 2, r > 1/p,
1/p + 1/q ≤ 1, p < 2, r > 1 − 1/q.
(C.1)
Proof . The case 1 < q < ∞ was proven by Galeev[14, 15], see also [11, 12]. The case q = 1 by
(cid:4)
Romanyuk [24]. Additionally we refer to [10, Theorem 4.39] and the comments therein.

p ≥ 2,

n

:

:

The next theorem is a generalization of the previous result to Triebel-Lizorkin spaces

p,θF (Td).
Sr
Theorem C.2. Let r ∈ Rd fulﬁlling

(1/p − 1/q)+ < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞

for a µ ≤ d. Let additionally 1 < p, q < ∞ (p > 1) and 1 ≤ θ ≤ ∞. Then we have

n

(cid:16) (log n)µ−1
(cid:16) (log n)µ−1
(cid:16) (log n)µ−1
(cid:16) (log n)µ−1

n

(cid:17)r1
(cid:17)r1−1/p−1/q
(cid:17)r1− 1
(cid:17)r1− 1

p + 1

+ 1
q



2

n

θ )+

− 1

λn(Sr

log(µ−1)( 1

p,θF (Td), Lq(Td)) (cid:16)

: 1 < q ≤ p < ∞,
: 1 < p < q ≤ 2 or 2 ≤ p < q < ∞,
: 2 ≤ q < ∞, 1/p + 1/q ≥ 1, r > 1
p ,
: p ≤ 2, 1/p + 1/q < 1, r > 1 − 1
(C.2)
(cid:4)
p W (Td) (cid:55)→
Lq(Td) directly. But there is a duality relation to much more familiar Kolmogorov n-widths
deﬁned by

In literature we do not not ﬁnd results for Gelfand widths of embeddings id : Sr

Proof . This results were obtained by Bazarkhanov in [1, 2].

n

2

2

dn(Sr

p W (Td), Lq(Td)) = inf

A⊂Lq(Td)
dim A≤n

(cid:107)f|Sr

sup
p W (Td)(cid:107)≤1

inf
g∈A

(cid:107)f − g(cid:107)q.

q . θ < q.

Lemma C.3. The following duality relation holds true

dn(T : X → Y ) = cn(T (cid:48) : Y (cid:48) → X(cid:48)),

where T (cid:48) denotes the adjoint operator of T and X(cid:48),Y (cid:48) the topological dual spaces of X and Y .
(cid:4)

Proof . We refer to [22, Theorem 6.2].

46

The following is known for Kolmogorov n-widths in case of Sobolev spaces Sr

p W (Td):

Theorem C.4. Let 1 < p, q < ∞ and r >

p − 1
( 1
max{ 1

q )+
p}
2 , 1

1 ≤ p ≤ q ≤ 2 or 1 ≤ q ≤ p < ∞,
otherwise,

:

:

fulﬁlling

for some µ ≤ d. Then

0 < r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞

dn(Sr

p W (Td), Lq(Td)) (cid:16) (m−1 logµ−1 m)r1−( 1

p−max{ 1

2

, 1

q })+.

Proof . The proof with every single case has a history of more than 20 years. For an overview
(cid:4)
we refer to [10, Section 4.3].
p,θF (Td) Bazarkhanov provided in [1, 2] results

Remark C.5. For Triebel-Lizorkin spaces Sr
on Kolmogorov widths.

(cid:40)

(cid:40) 1

(C.3)

This yields the following estimates for Gelfand n-widths:

Corollary C.6. Let 1 < p, q < ∞ and r >

2
p − 1
( 1

:
q )+ :

1 < p < q ≤ 2,
otherwise,
r1 = . . . = rµ < rµ+1 ≤ . . . ≤ rd < ∞, µ ≤ d.
p W (Td), Lq(Td)) (cid:16) (n−1 logµ−1 n)r1−(min{ 1
p , 1

}− 1

q )+

2

cn(Sr

fulﬁlling

Then

for all n ∈ N.
Proof . The proof follows by the duality relation stated in Lemma C.3 and a lifting argument.
p(cid:48) W (Td) and Lq(Td)
The topological dual spaces of Sr
with 1 = 1

p,θF (Td) and Lq(Td) are the spaces S−r

q(cid:48) . Lemma C.3 yields

p + 1

p(cid:48) = 1

q + 1

cn(Sr

p W (Td), Lq(Td)) = dn(Lq(cid:48)(Td), S−r

p(cid:48) W (Td)).

Finally we show the identity

q(cid:48)(Td), Lp(cid:48)(Td)).
For that reason we consider the lifting operator Ir in D(cid:48)(Td) given by

dn(Lq(cid:48)(Td), S−r

p(cid:48) W (Td)) (cid:16) dn(Sr
(cid:16) d(cid:89)
(cid:98)f (k)

(cid:98)f (k)eikx (cid:55)→ (cid:88)

k∈Zd

i=1

(cid:88)

k∈Zd

Ir : f =

(cid:17)

(1 + |ki|2)− ri

2

eikx.

(C.4)

It is easy to check that this is an isometry that maps f ∈ Sα
(Ir)−1 = I−r. Therefore we obtain the commutative diagram,
−r
p(cid:48) W (Td)
S

Lq(cid:48)(Td)

-id1

p W to Irf ∈ Sα+r

p W , α ∈ R with

Ir
?

q(cid:48)W (Td)
Sr

6
I−r

-id2

Lp(cid:48)(Td)

47

which allows to describe the operators id1, id2 by

id1 = I−r ◦ id2 ◦ Ir

and id2 = Ir ◦ id1 ◦ I−r.

Kolmogorov widths are s-numbers and fulﬁll a multiplicativity property that yields

dn(id1) = dn(I−r ◦ id2 ◦ Ir) ≤ (cid:107)I−r(cid:107)dn(id2)(cid:107)Ir(cid:107) (cid:16) dn(id2)

and

dn(id2) = dn(Lr ◦ id1 ◦ L−r) ≤ (cid:107)Lr(cid:107)dn(id1)(cid:107)I−r(cid:107) (cid:16) dn(id1).

Inserting the result from Theorem C.4 ﬁnishes the proof.

(cid:4)

Acknowledgment

The authors acknowledge the fruitful discussions with D.B. Bazarkhanov, Dinh D˜ung, A.
Hinrichs, E. Novak, W. Sickel, V.N. Temlyakov and M. Ullrich on this topic. The authors
especially thank Dinh D˜ung for the hints on [14, 15] and [23, 24]. G.B. and T.U. gratefully
acknowledge support by the German Research Foundation (DFG) and the Emmy-Noether
programme, Ul-403/1-1.

References

[1] D. B. Bazarkhanov. Estimates for the widths of classes of periodic functions of several

variables—I. Eurasian Math. J., 1(3):11–26, 2010.

[2] D. B. Bazarkhanov. Estimates for the widths of classes of periodic functions of several

variables. Dokl. Akad. Nauk, 436(5):583–585, 2011.

[3] G. Byrenheid, D. D˜ung, W. Sickel, and T. Ullrich. Sampling on energy-norm based sparse
grids for the optimal recovery of Sobolev type functions in H . J. Approx. Theory, to
appear.

[4] F. Cobos, T. K¨uhn, and W. Sickel. Optimal approximation of multivariate periodic

Sobolev functions in the sup-norm. ArXiv e-prints, May 2015.

[5] D. D˜ung. On optimal recovery of multivariate periodic functions. In Harmonic analysis

(Sendai, 1990), ICM-90 Satell. Conf. Proc., pages 96–105. Springer, Tokyo, 1991.

[6] D. D˜ung. Optimal recovery of functions of a certain mixed smoothness. Ta. p ch´ı To´an

Ho. c J. Math., 20(2):18–32, 1992.

[7] D. D˜ung. Non-linear approximations using sets of ﬁnite cardinality or ﬁnite pseudo-
dimension. J. Complexity, 17(2):467–492, 2001. 3rd Conference of the Foundations of
Computational Mathematics (Oxford, 1999).

[8] D. D˜ung. B-spline quasi-interpolant representations and sampling recovery of functions

with mixed smoothness. J. Complexity, 27(6):541–567, 2011.

[9] D. D˜ung. Sampling and cubature on sparse grids based on a b-spline quasi-interpolation.

Foundations of Computational Mathematics, pages 1–48, 2015.

48

[10] D. D˜ung, V. Temlyakov, and T. Ullrich. Hyperbolic cross approximation. ArXiv e-prints,

Jan. 2016.

[11] D. E. Edmunds and H. Triebel. Entropy numbers and approximation numbers in function

spaces. Proc. London Math. Soc. (3), 58(1):137–152, 1989.

[12] D. E. Edmunds and H. Triebel. Entropy numbers and approximation numbers in function

spaces. II. Proc. London Math. Soc. (3), 64(1):153–169, 1992.

[13] C. Feﬀerman and E. M. Stein. Some maximal inequalities. Amer. J. Math., 93:107–115,

1971.

[14] `E. M. Galeev. On linear widths of classes of periodic functions of several variables. Vestnik

MGU, Ser.1 Mat.-Mekh., 4:13–16, 1987.

[15] `E. M. Galeev. Linear widths of H¨older-Nikolskij classes of periodic functions of several

variables. Mat. Zametki, 59(2):189–199, 317, 1996.

[16] M. Hansen and J. Vyb´ıral. The Jawerth-Franke embedding of spaces with dominating

mixed smoothness. Georgian Math. J., 16(4):667–682, 2009.

[17] R. S. Ismagilov. Diameters of sets in normed linear spaces and the approximation of
functions by trigonometric polynomials. Russian Mathematical Surveys, 29(3):169, 1974.

[18] V. Kien Nguyen, M. Ullrich, and T. Ullrich. Change of variable in spaces of mixed
smoothness and numerical integration of multivariate functions on the unit cube. ArXiv
e-prints, Nov. 2015.

[19] E. Novak and H. Triebel. Function spaces in lipschitz domains and optimal rates of

convergence for sampling. Constructive Approximation, 23(3):325–350, 2005.

[20] E. Novak and H. Wo´zniakowski. Tractability of multivariate problems. Vol. 1: Linear
information, volume 6 of EMS Tracts in Mathematics. European Mathematical Society
(EMS), Z¨urich, 2008.

[21] E. Novak and H. Wo´zniakowski. Tractability of multivariate problems. Volume II: Stan-
dard information for functionals, volume 12 of EMS Tracts in Mathematics. European
Mathematical Society (EMS), Z¨urich, 2010.

[22] A. Pinkus. N -widths in approximation theory, volume 7 of Ergebnisse der Mathematik und
ihrer Grenzgebiete (3) [Results in Mathematics and Related Areas (3)]. Springer-Verlag,
Berlin, 1985.

[23] A. S. Romanyuk. Linear widths of Besov classes of periodic functions of several variables.

II. Ukra¨ın. Mat. Zh., 53(6):820–829, 2001.

[24] A. S. Romanyuk. Best approximations and widths of classes of periodic functions of several

variables. Sbornik: Mathematics, 199(2):253, 2008.

[25] H.-J. Schmeisser and W. Sickel. Sampling theory and function spaces. In Applied mathe-

matics reviews, Vol. 1, pages 205–284. World Sci. Publ., River Edge, NJ, 2000.

49

[26] H.-J. Schmeisser and H. Triebel. Topics in Fourier analysis and function spaces, vol-
ume 42 of Mathematik und ihre Anwendungen in Physik und Technik [Mathematics and
its Applications in Physics and Technology]. Akademische Verlagsgesellschaft Geest &
Portig K.-G., Leipzig, 1987.

[27] A. Seeger and T. Ullrich. Haar projection numbers and failure of unconditional conver-

gence in Sobolev spaces. ArXiv e-prints, 2015. arXiv:1507.01211 [math.CA].

[28] A. Seeger and T. Ullrich. Lower bounds for haar projections: deterministic examples.

ArXiv e-prints, 2015. arXiv:1511.01470 [math.CA].

[29] W. Sickel. Approximate recovery of functions and Besov spaces of dominating mixed

smoothness. In Constructive theory of functions, pages 404–411. DARBA, Soﬁa, 2003.

[30] W. Sickel. Approximation from sparse grids and function spaces of dominating mixed
smoothness. In Approximation and probability, volume 72 of Banach Center Publ., pages
271–283. Polish Acad. Sci., Warsaw, 2006.

[31] W. Sickel and F. Sprengel. Interpolation on sparse grids and tensor products of Nikolskij-
Besov spaces. J. Comput. Anal. Appl., 1(3):263–288, 1999. Dedicated to Professor Paul
L. Butzer on the occasion of his 70th birthday.

[32] W. Sickel and T. Ullrich. The Smolyak algorithm, sampling on sparse grids and function
spaces of dominating mixed smoothness. East Journal on Approximations, 13(4):387–425,
2007.

[33] W. Sickel and T. Ullrich. Tensor products of Sobolev-Besov spaces and applications to
approximation from the hyperbolic cross. Journal of Approximation Theory, 161:748–786,
2009.

[34] W. Sickel and T. Ullrich. Spline interpolation on sparse grids. Appl. Anal., 90(3-4):337–

383, 2011.

[35] S. Smolyak. Quadrature and interpolation formulas for tensor products of certain classes

of functions. Soviet Mathematics, Doklady, 4:240–243, 1963.

[36] E. M. Stein and G. Weiss. Introduction to Fourier analysis on Euclidean spaces. Princeton

University Press, Princeton, N.J., 1971. Princeton Mathematical Series, No. 32.

[37] V. Temlyakov. Approximation of functions with bounded mixed derivative. Proc. Steklov
Inst. Math., (1(178)):vi+121, 1989. A translation of Trudy Mat. Inst. Steklov 178 (1986),
Translated by H. H. McFaden.

[38] V. Temlyakov. On approximate recovery of functions with bounded mixed derivative. J.

Complex., 9(1):41–59, Mar. 1993.

[39] V. N. Temlyakov. Approximation of periodic functions. Computational Mathematics and

Analysis Series. Nova Science Publishers, Inc., Commack, NY, 1993.

[40] T. Ullrich. Function spaces with dominating mixed smoothness, characterization by dif-
ferences. Technical report, Jenaer Schriften zur Math. und Inform., Math/Inf/05/06,
2006.

50

[41] T. Ullrich. Smolyak’s algorithm, sampling on sparse grids and Sobolev spaces of domi-

nating mixed smoothness. East J. Approx., 14(1):1–38, 2008.

[42] J. Vybiral. Function spaces with dominating mixed smoothness. Dissertationes Math.

(Rozprawy Mat.), 436:73, 2006.

[43] J. Vyb´ıral. Sampling numbers and function spaces. J. Complexity, 23(4-6):773–792, 2007.

51

