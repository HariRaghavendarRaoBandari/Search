Bayesian methods for event analysis of intracellular currents

Josh Merel $a,b,∗, Ben Shababo $c, Alex Nakac, Hillel Adesnikc,d, Liam Paninskia,b,e,f

aNeurobiology and Behavior program, Columbia University
bCenter for Theoretical Neuroscience, Columbia University

cHelen Wills Neuroscience Institute, University of California, Berkeley

dDepartment of Molecular and Cellular Biology, University of California, Berkeley

eDepartment of Statistics, Columbia University

fGrossman Center for the Statistics of Mind, Columbia University

6
1
0
2

 
r
a

 

M
0
2

 
 
]

.

M
Q
o
i
b
-
q
[
 
 

1
v
0
3
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

Background: Investigation of neural circuit functioning often requires statistical interpretation of events

in subthreshold electrophysiological recordings. This problem is non-trivial because recordings may have

moderate levels of structured noise and events may have distinct kinetics. In addition, novel experimental

designs that combine optical and electrophysiological methods will depend upon statistical tools that combine

multimodal data.

New method: We present a Bayesian approach for inferring the timing, strength, and kinetics of post-

synaptic currents (PSCs) from voltage-clamp recordings on a per event basis. The simple generative model

for a single voltage-clamp recording ﬂexibly extends to include network-level structure to enable experiments

designed to probe synaptic connectivity.

Results: We validate the approach on simulated and real data. We also demonstrate that extensions of the

basic PSC detection algorithm can handle recordings contaminated with optically evoked currents, and we

simulate a scenario in which calcium imaging observations, available for a subset of neurons, can be fused

with electrophysiological data to achieve higher temporal resolution.

Comparison with existing methods: We apply this approach to simulated and real ground truth data

to demonstrate its higher sensitivity in detecting small signal-to-noise events and its increased robustness to

noise compared to standard methods for detecting PSCs.

Conclusions: The new Bayesian event analysis approach for electrophysiological recordings should allow

for better estimation of physiological parameters under more variable conditions and help support new

experimental designs for circuit mapping.

Keywords: Event detection; postsynaptic current; calcium imaging; connectivity mapping; Bayesian

methods; MCMC

$These authors contributed equally.
∗corresponding author: jsmerel@gmail.com
website: https://sites.google.com/site/jsmerel/

1

1. Introduction

Subthreshold neuronal activity provides an unsurpassed richness of information about a single cell’s

physiological properities. Access to subthreshold activity allows for inference about intrinsic biophysical

properties (e.g. membrane and ion channel parameters), circuit level properties (e.g. synaptic connectivity),

neural coding (e.g.

receptive ﬁelds), and synaptic properties (e.g. quantal properties & plasticity). At

present, whole-cell patch-clamp stands alone in its ability to reliably access subthreshold activity owing to

excellent signal-to-noise ratio (SNR) and very high temporal precision, as opposed to optical subthreshold

measurements. At the same time, optical technologies have advanced to the point where we can observe the

suprathreshold activity hundreds of individual neurons simultaneously with calcium imaging and stimulate

neurons by subtype or spatial location [1]. However, the limits on temporal resolution and the indirectness

of the observations make inferring ﬁne-scale network and cellular parameters diﬃcult. Approaches which

combine optical tools with electrophysiology oﬀer unique advantages [2]. In this work we present new statis-

tical techniques useful for analyzing whole-cell data as well as extensions demonstrating how our approach

is particularly well-suited to settings where electrophysiology is combined with optical physiology .

1.1. Our setting and approach

Fundamentally, many of the subthreshold-based analyses mentioned above depend on the interpretation

of the recorded time series as a sequence of events. In this setting, events are the successful transmission of

neurotransmitter onto the recorded cell, and when this occurs, a transient current ﬂows into or out of the

cell, known as a postsynaptic current (PSC). The analyses of experiments designed to infer properties of

evoked or spontaneous inputs to a cell (e.g. monosynaptic mapping or quantal/mini-PSC analyses) require

determining when a postsynaptic event happened and describing that event. Estimating PSC properties

is most straightforward when recordings are acquired using the voltage-clamp conﬁguration which employs

a feedback circuit to hold the membrane potential at a constant value thus mitigating variability in PSC

properties due to the intrinsic biophysics of the cell (though see [3])

In this work, we present a Bayesian approach for inferring the timing, strength, and kinetics of postsynap-

tic currents from voltage-clamp recordings, and we demonstrate on simulated and real data that this method

performs better than standard methods for detecting PSCs. The improvement in single-trial accuracy with

our method should allow for better estimation of physiological parameters with less data and under more

variable conditions (e.g. when the exact timings of stimuli or its eﬀects are unknown).

In addition, the

quantiﬁcation of uncertainty over PSC features provided by Bayesian inference enables new experimental

designs (e.g. [4]).

Bayesian approaches are naturally extensible, so the intuitive, generative model and straightforward in-

ference procedure ﬂexibly extend to include structure relevant to the analyses mentioned above. Speciﬁcally,

we extend the core single-trial model to include types of data obtained in monosynaptic mapping experiments

which may involve optical stimulation artifacts or combine voltage-clamp recordings and optical recordings.

2

For this latter extension, we combine the single trace model presented in this work with related work on

calcium imaging [5] to demonstrate a Bayesian approach to analyzing mapping experiments consisting of

simultaneous population calcium imaging and single cell voltage-clamp recordings [6].

1.2. Review of other approaches

To our knowledge, all previous methods for inferring PSCs have relied on ﬁrst inferring the timing of

single events (i.e. event onsets), and then sometimes ﬁtting per-event kinetics given that event time. These

methods have tended to fall into two categories. The superﬁcially simpler of the two approaches is ﬁnd events

by thresholding the trace or its ﬁrst derivative (i.e. ﬁnite diﬀerence). In practice, such methods have extra

parameters for smoothing, computing the appropriate oﬀset, or post-processing. Implementations tend to

over-detect candidate events and then evaluate candidates based on analysis of per event kinetics [7, 8, 9, 10].

For concreteness, consider a two-stage approach wherein a threshold is used to identify initial candidates, and

then a model is ﬁt to the transient dynamics in order to conﬁrm or reject candidate events by comparison of

the parameters of the dynamics against pre-determined criteria [8]. Even with post-processing, such methods

can be non-selective and tend not to exploit all of the available information (i.e. the transient dynamics

aren’t used to detect the events initially).

Threshold methods have been largely superseded by the second class of approaches, template-based

methods [11, 12]. In these methods, templates are usually learned by averaging event-responses collected by

a simpler method (e.g. thresholding and/or hand-curation). While template methods are straightforward,

initial attempts to apply these methods failed when the amplitude of the events varied or where events

overlapped - both common scenarios. The ﬁrst commonly used algorithm for PSC detection that attempted

to avoid issues related to amplitude variability introduced the idea of rescaling a ﬁxed template at each time

step [11]. Following this trend, template-matching approaches have gradually shifted towards deconvolution

methods, which are a more well-founded way to use templates [12]. Deconvolution generally refers to methods

that assume the observed trace is the result of convolving a template with unobserved events (of varying

amplitude), and such methods invert this model to estimate the times from the template. Both of these

template-based methods produce inferred events with diﬀerent amplitudes and a threshold can then be used

to screen out small events (see [13] for a Python implementation of [11] and [12], and see [14] for deconvolution

of current clamp traces).

Methods that rely on ﬁxed-shape templates can work very well when the shape of the event is consistent

across events, but postsynaptic events can vary in shape and amplitude, especially for events from diﬀerent

pre-synaptic sources due to diﬀerent dendritic ﬁltering, issues with space-clamp, or diﬀerent receptor subunit

distributions. Indeed, a core rationale behind the initial preference for threshold based approaches was the

recognition that events may vary too much for a single template. While is possible to use approaches that

employ multiple templates [15, 16], there are still potential issues related to the stage-wise separation between

learning the template and subsequent detection causing a sub-optimal use of information.

3

We take a Bayesian approach, rooted in a probabilistic, generative model. Broadening the taxonomy,

this approach is a type of deconvolution method. However, we do not consider a single template (or a

handful of templates), but instead a distribution over templates through the use of prior distributions on the

kinetics and amplitudes of individual PSCs. Importantly, we also model event timing in continuous time (i.e.

without binning), and we incorporate an autocorrelated, AR(p) noise process [17], which provides a more

accurate description of the data. This leads to more precise detection of event times and inference that is

more robust (i.e. less susceptible to noise). As such, our inference better leverages all available information

(i.e. all events and full timecourse of each event). Given this probabilistic formulation of the noise process

and the inclusion of priors on the PSC features, we can then perform posterior inference in this model using

Markov chain Monte Carlo (MCMC, see methods).

A tradeoﬀ is that the proposed approach is more computationally intensive than previous approaches.

Nevertheless, we believe the ﬂexibility and robustness that this approach aﬀords makes up for this in many

settings. Beyond handling overlapping events and variation in the shape of events, our method inherits

advantages of probabilistic modelling. The method is extensible and amenable to serving as a modular

component of hierarchical models, as we show. Moreover, while existing methods tend to produce all-or-

none results and the precise timing of the event is a secondary consideration, using a probabilistic approach,

it is straightforward to consider posterior uncertainty. We essentially get a level of conﬁdence for detection of

each event and the level of uncertainty in the precise timing of the event. This posterior uncertainty in event

times can translate into posterior uncertainty for other parameters of interest, such as synaptic weights.

1.3. Overview

In the following sections, we will ﬁrst present the details of the model for single-trial voltage-clamp

traces and extensions mentioned previously. We then provide the details of the inference scheme we use

for sampling from the posterior distribution. In the results, we compare our approach with the standard

template-based approach [11] as well as a Wiener Filtering approach [18] (similar to PSC detection in [12]

but more adaptive in how it regularizes its output), since these serve as competitive and robust baselines.

We show inference results from our approach on simulated and real data for spontaneous EPSCs and IPSCs

across several cell types, PSCs evoked via paired-patching as ground-truth validation, and PSCs evoked

optically with one-photon and two-photon stimulation with stimulation artifacts. We also show results on

simulated data for a mapping experiment which combines voltage-clamp recordings with calcium imaging,

illustrating extensibility.

2. Methods

We draw on tools developed in statistics [19] and signal processing [20] to decompose a voltage-clamp

recording into interpretable elements. In this application, our events are unitary synaptic currents and their

4

features describe the strength and kinetics of each event. In previous work, we have found similar methods

useful for inferring spiking events in calcium imaging data [5].

The framework involves (1) specifying a generative model for voltage-clamp recordings, the parameters

of which describe event times, features, the noise model, etc., and (2) performing Bayesian inference on

event times and features and the model parameters jointly. Theoretically, Bayesian estimators have nice

guarantees (under a “true” model, see [21]). However, this approach can fail if the model is inadequate

(i.e. the generative model does not capture the true statistics of voltage-clamp traces) or if the inference

algorithm performs poorly and the true model posterior is not obtained. These concerns are legitimate, so

we demonstrate below that our model captures the statistics of real voltage-clamp data and that inference

performs well on both simulated and real data.

2.1. Model of a single electrophysiological trace

In the simplest version of our model, the observed current trace, yt, is a discrete time series composed of

the sum of a random number n of unitary synaptic currents, a baseline (holding current), b, and observation

noise t (eq. 1).

yt =

aifi(t − ti) + b + t

n(cid:88)
p(cid:88)

i=1

fi(t) = (e−t/τ d

i − e−t/τ r

i )1(t >= 0)

t =

φjt−j + ut

ut ∼ N (0, σ2)

(1)

(2)

(3)

j=1

Each event, indexed by i, is characterized by an event time, ti ∈ R+, which need not be aligned with the
sampling time of yt, its own kinetics determined by fi(·), and a strength which we deﬁne as the amplitude,
or peak current, of the event, ai. For synaptic currents, we use a diﬀerence of exponentials for fi which is

parameterized by a rise time constant, τ r

i . For an example of the model,
see Figure 1B-D. Observe in Figure 1E that recovered kinetics of individual events do vary signiﬁcantly,

i , and a decay time constant, τ d

suggesting that a model which captures this structure should perform better than methods which rely on a

single (or handful of) template(s).

As opposed to an i.i.d. Gaussian noise process, the more general autoregressive, AR(p), process better

captures the noise in voltage-clamp recordings. We have found the noise model to be crucial for robust

inference (see Results). In an AR(p) noise model, the noise has temporal correlations due to direct depen-

dencies between noise values for p timesteps.

In this work, we use an AR noise model with p = 2 (eq.

3). Voltage-clamp recordings exhibit correlated noise whose source can be electrical hardware, changes in

resistance between the electrode and the interior of the neuron, and other biological non-event contributions

to the observation. In practice, it is these forms of temporally correlated noise which lead to many of the

false positives since they are more likely to exhibit a similar shape to true events.

5

Figure 1: This ﬁgure depicts the correspondence between real data and the generative model. A Shows a real voltage-clamp

recording. B Depicts simulated synaptic currents generated from a ﬁt to the data in A (noiseless). C Depicts AR(p) noise

process (p = 2) generated from a ﬁt to the data in A. D Illustrates a model-based voltage-clamp recording simulation (the sum

of the data in B and C), to illustrate that the simulation visually captures core features of the real data. E Shows individual

events estimated from the data in A (with normalized amplitudes), and panel F shows the individual simulated events used in

B (with normalized amplitudes).

With eqs. 1 and 3 we can write down the likelihood of the observed, noisy data given the parameters

(Θ ≡ {σ, ai, ti, τ d

i , b, φj}i=1...n,j=1...p). We begin with the i.i.d, i.e. AR(0), case,

i , τ r

p(Y |Θ) =

(2πσ2)−1/2exp[− 1

2σ2 (yt − ˆyt)2],

T(cid:89)

T(cid:89)

t=1

where ˆyt refer to the predicted noiseless trace:

t=1

ˆyt =

n(cid:88)

i=1

aifi(t − ti) + b

In equation 8 of [17], the likelihood is extended to the AR(p) case

p(Y |Θ) =

(2πσ2)−1/2exp[− 1

2σ2 (yt − ˆyt|t−1)2],

where ˆyt|t−1 is (adapted from equation 11 of [17], ignoring boundary conditions),

p(cid:88)

ˆyt|t−1 = ˆyt +

φj(yt−j − ˆyt−j).

The probabilistic model provides a natural objective function:

j=1

L(Θ|Y ) ∝ ln p(Y |Θ) + ln p(Θ).

6

(4)

(5)

(6)

(7)

(8)

It is possible to optimize this log-posterior directly, or inference can be performed to obtain an estimate

of the posterior distribution. p(Θ) corresponds to the prior probability on the parameters – for simplicity,

we use a set of independent, largely non-informative priors applied to each parameter (enforcing positivity or

bounded support where appropriate), but of course more informative priors could be used. In a probabilistic

formulation, it is worth explicitly keeping in mind that the posterior distribution for a given parameter

can only have support where its prior distribution has support, so hard constraints (e.g. a parameter being

positive or a minimum amplitude size) can be naturally incorporated as prior information. In addition, priors

in a Bayesian model provide intuitive inputs which can be used to extend the core model. For example,

distributions over event features could be modulated by clustering onto presynaptic sources or the rate of

events in each trace could be time-varied based on stimulation of presynaptic cells in mapping experiments.

2.2. Model extensions

2.2.1. Including optical currents

In this extension, we consider an active mapping experiment where we have some level of spatially

structured optical stimulation (via optogenetics [22] or neurotransmitter uncaging [23]) of presynaptic cells

while holding a postsynaptic cell in voltage-clamp [24, 25]. In this setting, detections of PSCs coincident

with stimulations can be used to infer connectivity between neurons. However, in some protocols, the

postsynaptic cell also responds to the stimulation1. If this is the case, we will see a direct optically evoked

current in our voltage-clamp recording when we attempt to stimulate cells near the patched cell. In order

to remove artifacts of this sort, we can incorporate a parameterized, additive term in the generative model

and then perform inference jointly with respect to these parameters. The choice of an additive term is more

reasonable for optogenetic stimulation because the currents are carried through diﬀerent channels whereas

with neurotransmitter uncaging the direct stimulation current and the synaptic current may be competing

for the same channels.

For example, it is straightforward to include a parameterized kernel for the optical response of the neuron,
h(·), and then to convolve that response with the known optical input to the neuron (e.g. the laser or LED
power),

n(cid:88)

yt =

ns(cid:88)

aifi(t − ti) +

ajh(θh) ∗ dj(t) + b + t

(9)

i=1

j

where we have ns optical inputs each with known timecourse dj(t) and the response kinetics are modelled

with a convolution which is parameterized by θh (e.g. a set of time constants). Each stimulation will

have its own gain, as, which depends on the density of the corresponding channels at the location of that

stimulation. We have found this approach to be useful under certain conditions with optogenetics (Figure

1This is seen with glutamate uncaging at locations near the patched cell and could also occur with optogenetics when mapping

connections between cells of the same transcriptional identity in the same location or when mapping many heterogeneous

populations of cells (i.e. when a pan-neuronal promoter is be used).

7

5D). However, for some optogenetic currents, the multi-state kinetics of opsins can make it diﬃcult to design
a parameterized h(·) which can be sampled eﬃciently. In this case, the shape of the optical current could be
measured empirically and then modelled as

n(cid:88)

ns(cid:88)

yt =

aifi(t − ti) +

ajh(t − t(s)

j ) + b + t

(10)

i=1

j=1

where h(·) is now the stereotyped shape of the current and we know the set of times {t(s)
j }j=1...ns at which we
have stimulated. Since the currents are ﬁltered in the dendrites, eq. 10 breaks down slightly when handling

simulations at locations at varying distances from the soma of the patched cell (Figure 5D). Nonetheless,

it still provides a good trade oﬀ between accuracy and computational tractability. In addition, one could

create several optical current templates based on the distance of the stimulation site from the soma [26].

2.2.2. Mapping with calcium imaging and voltage-clamp recordings

Next we extend the model to show how the inferred events could be identiﬁed with presynaptic sources

when the local population is partially observed via calcium imaging [6] (alternatively, a similar approach could

combine information from voltage imaging). In this setting our observations will consist of the ﬂuorescence

traces of the imaged cells and the voltage-clamp recording. Both the presynaptic ﬂuorescence traces, ck
t

where k indexes the neurons observed via imaging, and the postsynaptic electrophysiological recording, yt,

can be interpreted as a sum of events [5],

nk(cid:88)
K(cid:88)

i=1

ck
t =

yt =

nk(cid:88)

akgk(t − tki) + bk + ηk

t

n∅(cid:88)

ajfj(t − tj) + b + t

(11)

(12)

akfk(t − tki) +

k=1

i=1

j=1

k). Like fk(·), gk(·) is also a sum of exponentials but the prior on the
with t as before and ηk
kinetics are much slower. {tj}j=1...n∅ are the times of PSCs with no corresponding imaged, presynaptic cell.
We want to point out that because we model the process in continuous time, the observed calcium traces

t ∼ N (0, ν2

need not have the same sampling rate or observation times as each other or the voltage-clamp recording

(which will be sampled many orders of magnitude faster).

In this demonstration, we have chosen to assume the calcium events for the same cell are all of equal

amplitude – this would be appropriate if the spikes occur sparsely or if calcium transients sum roughly

linearly. If the summation is known to be nonlinear with some biophysically plausible nonlinearity (e.g. see

[27]), this could be straightforwardly accommodated by modifying the model and similar inference methods

may still be applied. Alternatively, it is also straightforward for the calcium event amplitudes to vary across

events.

We have similarly chosen for all postsynaptic events to be of the same amplitude and shape when they

follow from a speciﬁc presynaptic cell, but in practice one can extend the clustering to impose cell-speciﬁc

8

priors on these amplitudes and shapes. Some subset of events observed in the electrophysiological recording

will arise from unobserved presynaptic inputs so we allow these to be explained by events with no observed

presynaptic cause and with independent shape and amplitude per event (second summation term indexed

i = 1...n∅). We could also incorporate a ﬁxed delay between presynaptic events and postsynaptic events (this
would be an additional parameter, pre-speciﬁed or inferred, in the postsynaptic transient response fk(·)).
Since we now observe multiple traces, our new objective function is simply the sum of the log probabilities
of the various traces. The multiple traces are conditionally independent given event times {tki}k=1...K,i=1...nk
and {tj}j=1...n∅ , so we have an overall objective corresponding to the log-posterior:

K(cid:88)

L(Θ|C k, Y ) ∝ ln p(Y |Θ) +

ln p(C k|Θ) + ln p(Θ),

(13)

again with p(Θ) corresponding to the prior probability on the full set of parameters (see Section 3.4 for

k=1

results).

2.3. Inference

For this work, we perform inference using Markov chain Monte Carlo (MCMC) [28, 29]. MCMC tech-

niques allow us to obtain samples from the posterior distribution over all unknown variables in the model

and thereby approximate the posterior by a histogram of such samples. Speciﬁcally, we perform Gibbs sam-

pling over all the parameters [29]. This means that for each parameter, we hold all other parameters ﬁxed

and conditionally update the focal parameter by sampling it from its conditional distribution. A “sweep”

consists of an update of all parameters. While it is possible to compute conditional distributions analytically

for suﬃciently simple models, it is quite simple to use generic sampling methods to update parameters for

any model for which one can compute the likelihood. For example, we use random-walk Metropolis (RWM)

to update many parameters – this consists of updating parameters by proposing updates from a distribution

centered on the current value and accepting or rejecting proposed updates such that the resulting set of

samples are consistent with the conditional distribution [29]. Alternatively, more powerful samplers such as

Hamiltonian Monte Carlo could be used [29] but simple RWM suﬃced here.

In the single-trial, voltage-clamp case, we update {ti, ai, b, τ d

i }i=1...n by RWM. Inclusion of a direct
optical current, in the simplest case, only contributes one additional amplitude parameter for each stimula-

i , τ r

tion, and these can be inferred similarly. We model the number of events in each trace as a Poisson random

variable and note that this could be generalized to an inhomogenous Poisson process prior so that the event

rate can vary based on inputs such as optical stimulation. To add and remove events (i.e. perform inference

over n), we use birth-death moves which consist of the proposal of a new event time and the removal of an

existing event time respectively [19].

The noise process parameters φ1..p are sampled by rejection sampling from the constrained conditional

distribution and σ is sampled from its conditional distribution. Speciﬁcally, we reproduce the updates for

the φ1..p and σ, which are provided in section 4.1 of [17]. φ1..p is shown to be conditionally normal with a

9

mean and posterior that depend on ˆet = yt − ˆyt and σ2, but also with the constraint that the AR(p) process
deﬁned by φ1..p is stable. Ignoring boundary conditions:

E = [ˆet−1...ˆet−p]
Φn = Φ0 + σ−2(E(cid:48)E)
ˆφ = Φ−1
φ ∼ N ( ˆφ, Φ−1

n )1Sφ

n (Φ0φ0 + σ−2E(cid:48)e)

(14)

(15)

(16)

(17)

Where 1Sφ is an indicator over the set of stable φ values and φ0 and Φ0 are set to weakly informative

prior values. Following [17], we place an inverse-gamma prior on σ2, which is the conjugate prior given the

likelihood (eq. 6) so that we can sample directly from the conditional posterior

T(cid:88)

δ1 =

(yt − ˆyt|t−1)2

t=1

σ2 ∼ IG(

1
2

(T + ν0), 1/(

1
2

(δ1 + δ0))),

(18)

(19)

where ν0 and δ0 are also set to weakly informative prior values.

For the full mapping case, inference is similar. However, additional moves need to be incorporated to

improve mixing. That is, in addition to the single-variable updates, additional custom moves are performed

each sweep. The additional moves correspond to proposing a swap for the presynaptic identity for a PSC

event. That is, an MCMC step is proposed wherein an event associated with one presynaptic source is

eliminated and an event at the same time is considered for another source. To implement such moves, we

simply propose to drop an event at a given time for one presynaptic source and an to add an event at

the same time for another presynaptic source and evaluate the combined acceptance or rejection of these

proposed moves using the Metropolis-Hastings ratio [29].

2.4. Speciﬁc implementation details

Code implementing our inference routine will be made available via the corresponding author’s website.

When applying our inference method to data, we can run from a cold start, or we can initialize event times

with those found via a simpler, faster method (e.g. a deconvolution method). In this work, to establish initial

performance of our algorithm, we present results on simulated and real data using cold starts. For small

timeseries (roughly 1 sec length), inference consisting of 1000 sweeps of the sampler tends to be thorough and

requires a few minutes. For longer timeseries or many timeseries, we run smaller sections of the timeseries in

parallel on a computing cluster. We also note that RWM requires a proposal width hyperparameter – this

can be automatically tuned early in the sampling process (during the burn-in) by adjusting the proposal

variance such that the accept rate is reasonable [30]. This automatic tuning can be done in an ad hoc

adaptive fashion, allowing for increases or decreases in proposal variance when either too many or too few

moves are being accepted.

10

We also note that in the implementation, we frequently rely on the log-likelihood, ln(p(Y |Θ)), to determine
In order to minimize redundant operations, it proves useful to store

whether to accept or reject moves.
ˆet = yt − ˆyt and we perform evaluations of yt − ˆyt|t−1 by observing that:

yt − ˆyt|t−1 = yt − (ˆyt +

φj(yt−j − ˆyt−j))

φj(yt−j − ˆyt−j)

p(cid:88)
= yt − ˆyt − p(cid:88)
= ˆet − p(cid:88)

j=1

j=1

φj ˆet−j.

(20)

(21)

(22)

2.5. Experimental methods

j=1

All experiments were performed in accordance with the guidelines and regulations of the Animal Care and

Use Committee of the University of California, Berkeley and the National Institutes of Health guide for the

care and use of Laboratory animals (NIH Publications No. 8023, revised 1978). Mice used for experiments

in this paper were either wild type (ICR white strain, Charles River), som-IRES-Cre (JAX stock #018973);

Ai9 Rosa-LSL-tdTomato (JAX stock #007909), PV-Cre (JAX stock #008069); Ai9 Rosa-LSL-tdTomato, or

emx1-IRES-Cre (JAX stock #005628).

Viral Infection: Neonatal emx1-cre mice were injected with AAV9-CAG-ﬂexed-Chr2-tdTomato (for 1-

photon experiments) or AAV9-syn-ChrimsonR-tdTomato (for 2-photon experiments) at P0-P4. Viruses

were acquired from the University of Pennsylvania Vector Core. Undiluted viral aliquots were loaded into

a Drummond Nanoject injector. Neonates were brieﬂy cryo-anesthetized and placed in a head mold. With

respect to the lambda suture coordinates for S1 were: 2.0 mm AP; 3.0 mm L; 0.3 mm DV.

2-Photon Optogenetic Stimulation: 1040 nm light (femtoTrain, Spectra-Physics) was delivered to the

sample using a VIVO 2-Photon workstation (3i) based on a Sutter Moveable Objective Microscope (Sutter,

Novato, CA) and the hologram was created using a Phasor 2-Photon computer-generated holography system

(3i). Light was delivered for 10 milliseconds at 100 mW power on sample . The hologram for these data was

a disc of radius 15 µm.

For more detailed methods on brain slicing, in vitro and in vivo electrophysiology, and 1-photon optoge-

netic stimulation, see [31].

3. Results

3.1. AR noise model validation

We have found the choice of noise model to be critical when analyzing voltage-clamp data. It is common

to use i.i.d Gaussian noise for neurophysiological time-series ([32], [14]) , but very often the noise can exhibit

temporal correlations. To obtain a recording of a voltage-clamp noise process which contains no events, we

recorded from a neuron exposed to an excitatory synaptic blocker (Kynurenic Acid, 4mM) while holding

11

Figure 2: Validation of the AR(p) noise model and inference. A Top: a real voltage-clamp recording under “event-free”

conditions such that the recording is dominated by noise. Middle: simulated noise from an AR(0) ﬁt to the real example.

Bottom: simulated noise from an AR(2) ﬁt to the real example. The AR(2) example better captures the structure of real noise.

B Grey: periodogram estimate of the PSD of an “event-free” recording. Blue: a parameteric ﬁt to the PSD with an AR(0)

model. Red: a parameteric ﬁt to the PSD with an AR(2) model. C Top: a simulated voltage-clamp recording with AR(2)

noise. Middle, black: The true current for the top trace. Red: The true time-amplitude coordinate for each PSC. Blue: A

bivariate histogram reﬂecting the estimated time-amplitude posterior distribution using an AR(0) noise model (uses a small,

but non-zero minimum event size threshold). Bottom: same as in the middle trace but inference is performed with an AR(2)

noise model. D Curves depict accuracy of inference as a function of SNR level (ranging an order of magnitude, with 1 indicating

low noise relative to size of events and 10 indicating noise that is has marginal variance larger than the signal) for AR(0) vs

AR(2) model-based inference. The measure of accuracy is correlation coeﬃcient between true (simulated) trace and estimate of

posterior mean. The asterisk indicates a biologically realistic SNR level equal to the example in C. For each point on the curve,

we simulate timeseries with random event-times and amplitudes (traces are median and inter-quartile range over 10 repeats).

Both algorithms do very well in the high SNR regime. As soon as noise level begins to make inference diﬃcult, both algorithms

begin to lose accuracy. However the AR(2) model inference degrades much more slowly.

the cell near the inhibitory reversal potential (-70 mV). Under these conditions, the recording should be

relatively event free; nonetheless the recording shows clear temporal correlations (Figure 2A). In the context

of deconvolving these data, it is primarily this correlated noise that drives false positives because it can have

similar features to PSCs.

To better capture the structure of voltage-clamp noise, we used the more general AR process which we

found was suﬃciently ﬂexible and expressive to represent the types of noise we encountered. Speciﬁcally,

12

10 pA5 msElectrophysiological NoiseSimulation From AR(2) FitSimulation From AR(0) FitASimulated Data With an AR(2) Noise ProcessInference With an AR(0) Noise ProcessInference With an AR(2) Noise ProcessCBD2468100.20.30.40.50.60.70.80.91Noise LevelCorrelation With True  AR(0)AR(2)AR(0) vs. AR(2) InferenceFrequency (Hz)10100100010000Power (pA2/Hz)10-910-810-710-610-510-410-310-210-1100Periodogram of Voltage-Clamp Noise and Parameteric Fitsdata periodogramar(2) fit psdar(0) fit psd10 pA20 msan AR(2) model balanced model expressiveness and computational cost. Figures 2A and 2B show that the

extra structure in the AR(2) model does in fact provide a better description of the data.

For a systematic validation, we performed a comparison between the AR(0) and AR(2) inference for

many simulated traces. Speciﬁcally, we can simulate traces with random event times and with various levels

of AR(2) noise added to the traces (i.e., varying SNR). In these simulations, events are naturalistic in that

they have variability in their distribution of amplitudes and time constants, and events may overlap (2C).

For inference with either noise model, performance is similar when there is low levels of noise (or for speciﬁc

AR(2) noise process parameters that result in only weak noise autocorrelation, not shown), but the inference

results diverge dramatically when the noise is larger in magnitude. To summarize inference, we examine

the correlation between the posterior mean trace and the “true” simulated, noiseless event trace (2D). For

biologically realistic AR(2) noise structure and magnitude (indicated by an asterisk in 2D), inference with the

AR(2) model indeed performs considerably better than with the AR(0) model. Note that in the high-SNR

limit, simple methods like template matching algorithms, greedy optimization, or other direct optimization of

the model likelihood can perform well enough, so sample-based inference would be computationally excessive.

However, this validation demonstrates that in the biologically realistic noise regime, noise is suﬃciently large

and structured for proper inference to be useful.

3.2. Comparison with other methods on spontaneous and evoked PSCs

We also compared our method to two common PSC detection algorithms: a standard template-based

approach [11] and a deconvolution approach (a Wiener Filter [18], which we found tended to improve upon

the slightly simpler inverse ﬁlter used in [12]). When testing these algorithms, we attempted to give each its

best chance to perform well. Speciﬁcally, that means that the template-based and deconvolution methods

were given the average of the true underlying events as a template. We gave the Wiener Filter the true noise

power spectral density for simulated data. For real data with high enough spontaneous rates, it was diﬃcult

to ﬁnd a “quiet” section of the trace to estimate the noise PSD; therefore we provided an AR ﬁt to the noise

from Bayesian inference for the Wiener Filter’s noise PSD. For simulated data with Bayesian inference, we

provided the true priors on τ r and τ d that were used to generate the data.

First, we simulated a test set of recordings with realistic levels of noise and with relatively low SNR

PSCs. Each of the three algorithms produces a time series equal in length to the input recording that is

something like a score that an event is happening at that point in time. For the template-based method the

output represents the goodness-of-ﬁt to the event template at that point in time, and for the deconvolution

the output is an estimate of the event amplitude at that point in time. For the Bayesian approach the

output time series is the marginal posterior of an event at each sample. Importantly, in practice the output

for the template-matching and deconvolution methods only have an empirically reasonable interpretation in

the high SNR case. To obtain estimates of event times for each simulated trace, we threshold these time

series for each method as a function of their standard deviations. Figure 3A shows an example of results

for each algorithm on simulated data. The threshold for each method’s output is shown as a horizontal line,

13

Figure 3: Comparison of methods on simulated data. A An example of inference/detection results for each method on a

simulated voltage-clamp recording. For each method we show the output time-series for that method (i.e. the score template

matching, deconvolved trace for deconvolution, and the poseterior of event times for the Bayesian approach), estimated event

times, and the threshold used to determine those event times (for the Bayesian trace the threshold is so low that it can’t be seen

above the baseline posterior). B The number of true positives and false positives across 10 simulated traces for each method.

The highlighted point in each line corresponds the threshold used in A. C Same as in B except showing the true positive count

as a function of the threshold. D same as in C except showing the false positive count.

and inferred events are shown as dots. (The threshold for the Bayesian approach is diﬃcult to see as it is

very close to zero.)

By varying the threshold and counting the number true positives and false positives, we can get a sense

of how noisy the output is from each approach. The Bayesian approach is able to accurately detect more

events while accumulating fewer false positives than the other methods (Figure 3B). Importantly, it also

maintains similar levels of true and false positives as the threshold is varied (Figures 3C & 3D), indicating

that our approach is more robust and produces a less noisy representation of PSC timing. While there exists

a threshold for the template-matching and deconvolution methods that performs quite well, small deviations

from this value lead to vastly more false positives or less true positives (Figures 3C & D). When applying

these methods to real data, it may not be possible to ﬁnely tune the threshold parameter on a per dataset

basis since ground truth information is not available. This can be especially troublesome when online or

closed-loop analysis is desired.

We next compared methods on real voltage-clamp recordings in which we could modulate the SNR of

14

Figure 4: Results on real voltage-clamp recordings. A-F Comparison to other detection methods on real data while modulating

the SNR. A Top: a single trial of the spiking presynaptic cell ﬁring from direct current injection. Middle traces: three example

trials of the connected postsynaptic cell responding with an IPSC. The postsynaptic cell is being clamped at -45 mV. Below the

examples is the mean trace over all 50 trials. Bottom rasters: estimated events for 50 trials for each detection method. B-C

Same as in A except with the postsynaptic cell held at -50 mV (B) and -55 mV (C). The scales for the example traces are all

the same across A-C and likewise for the mean traces. D-F The average number of evoked events counted in a window around

the spike time (1.0 msec before to 5.0 msec after the spike) above a baseline rate of detected events per trial as a function of

threshold for each method. Colors and symbols as in 2C-B. The dotted horizontal line represents perfect performance of one

extra event detected per trial. G-I Examples of results on several types of real data. G Spontaneous EPSCs detected in a layer

II/III pyramidal cell, top, a SOM+ cell, middle, and a PV+ cell, bottom. H Spontaneous IPSCs in a layer II/III pyramidal

cell. I Spontaneous EPSCs and IPSCs detected in an in vivo recording from a FS cell.

an event physiologically. To achieve this, we made paired patch recordings of a PV+ cell and a layer V

pyramidal cell until we found an inhibitory connection from the fast-spiking cell onto the pyramidal cell with

a probability of of a postsyanptic event extremely close to 1.0. We then moved the holding potential for

the postsynaptic cell towards the reversal potential for the inhibitory current. In this way, we could obtain

ground truth data in which we had direct control over the SNR (Figure 4A, B, & C, top traces).

We ran 50 trials each at three holding potentials representing relatively high, medium, and low SNR

regimes and detected events using all three methods. Only the Bayesian approach was sensitive enough to

detect events reliably in the low SNR case (Figure 4A, B, & C, rasters). Similar to the simulated data, the

15

Bayesian approach was also the only method which was robust to the thresholding parameter, indicating

that the posterior over event times is highly peaked. As expected, as the SNR decreases, the ability to

accurately detect the timing of the event decreases.

Any approach will have hyperparameters that must be selected, and the Bayesian approach allows for

tuning of hyperparameters corresponding to prior distributions on model parameters. We show that a single

set of prior distribution hyperparameters can perform well across several cell types by running inference on

traces from diﬀerent cell types and under diﬀerent recording conditions while holding the hyperparameters

constant. In 4G we show that with a single set of prior parameters our method can detect EPSCs across

three diﬀerent cell types: a layer II/III pyramidal cell, a SOM+ interneuron, and PV+ interneuron. Despite

the diﬀering statistics in each of these traces (event features and noise), event detection performs well. In

4H we show results for spontaneous IPSCs in a layer II/III pyramidal cell. For these results, we used the

same prior parameters as in 4G except that we increased the upper bounds for the time constants to account

for the slower kinetcs of IPSCs. Finally, in 4I we show results on an FS cell recorded in vivo. The prior

parameter settings here are the same as in 4G except that we had to increase the rate prior on the number

of events.

3.3. Extension 1: Direct optical stimulation artifact

For certain experiments, it may be productive to actively drive cells to ﬁre in order to study circuit

properties. In particular, we may want to combine voltage-clamp recordings with spatiotemporally structured

optical stimulation of a putative presynaptic population of neurons. This can induce optically evoked artifacts

from direct optical currents in the voltage-clamp recording. As an example, one could express an optogenetic

channel pan-neuronally which would allow the simultaneous mapping EPSCs and IPSCs onto one cell. Under

these conditions, the cell under voltage-clamp will also express opsin and respond to any stimulating light.

Similarly, in neurotransmitter uncaging mapping experiments, there will be a direct stimulation of the

postsynaptic cell at most stimulation sites close to the cell.

We show that our approach is able to decompose a simulated trace with a direct optical current in Figure

5. Speciﬁcally, we simulated a trace consisting of many EPSCs with an additive direct optical stimulation

current, consistent with eqn. 10. On this simulated data, inference performs very well in terms of extracting

events simultaneously with artifact isolation.

16

Figure 5: Removing direct stimulation artifacts from active mapping data. A Top: a simulated voltage-clamp recording that

is contaminated by a large direct, optical current. Top middle: the true direct current (blue) with an estimate of the inferred

direct current (dashed, red). Bottom middle: the true current used in the top trace. Bottom, the inferred amplitude-time

posterior (blue) with true amplitude-time coordinates overlaid (red X’s). B Top: direct optical currents evoked in a single cell

by stimulating diﬀerent locations with one-photon excitation and a DMD. Bottom: same as above but each trace is normalized

to have the same amplitude. C-D PSC detection with direct optical stimulation on real mapping data. C Inference results

for one-photon, DMD-based mapping data with direct stimulation contamination. All three trials are for a single stimulation

site. Red line shows when the stimulating laser is on. Dark blue trace shows the posterior over event times. Light Blue trace

shows the MAP estimate for the synaptic currents. Maroon trace, MAP estimate for the direct stimulation. Black, raw voltage-

clamp observation. D Inference results for two-photon, SLM-based mapping data with direct stimulation contamination. Left,

three trials from a particular stimulation location which shows putative evoked EPSCs riding on top of direct stimulation with

inference. Right, same as the results to the left but for a stimulation location further from the cell.

17

In Figure 5B-D, we present results on real data obtained by combining voltage-clamp recording with one-

photon stimulation via a digital micromirror device (DMD) as well as two-photon, holographic stimulation of

neurons. In 5B, we show direct currents at many diﬀerent stimulation locations with one-photon excitation

via a DMD. Under these conditions, the shape of the current is not well characterized by a parameterized

template function so we must use an empirically derived template. When normalized, all of the currents have

roughly similar shapes, validating our approximation of the artifact as a scaled template. In 5C we show

PSC inference on three trials from a single stimulation location that has putative evoked PSCs overlapping

the direct stimulation artifact. In Figure 5D, we show similar results except the stimulation is performed

using two-photon excitation with a spatial-light modulator (SLM). We found that under these conditions,

we were able to use the model in eqn. 9 and ﬁt two time constants to the optical current. This allowed

for a more ﬂexible ﬁt that could account for the diﬀerences in the direct current shape as the stimulation

location varied. The two sets of traces and results in 5D are for three trials at two diﬀerent locations. These

locations were chosen because they contained putative evoked EPSCs.

3.4. Extension 2: Passive mapping experiment (simulation)

In addition to electrical recordings from a post-synaptic cell, we may also have calcium indicator available

in pre-synaptic cells [6]. This allows for a passive mapping experiment from many pre-synaptic cells (optically

imaged) to a single post-synaptic cell (patched). Here we provide an example of the usage of the joint inference

procedure (Figure 6A). We have simulated a population of presynaptic cells which are observed via calcium

imaging (SNR for these cells is plausible for a well-tuned setting, and bin size is 35ms). These cells drive

post-synaptic events in the simulated patched cell (noise is biologically plausible, and bin size is .05ms). In

6A, 4 of 6 candidate presynaptic neurons are observed. Postsynaptic events evoked by unobserved neurons

are inferred on a per event basis whereas events co-occuring with presynaptic events arise from a single

variable (see model eqns. 12).

We see that we can recover events jointly from the calcium imaging and electrophysiology, with event

identity successfully linked across the two modalities.

In addition, the histogram in the right panel of

Figure 6B indicates that combining electrophysiology and calcium imaging tends to yield increased temporal

precision of event times compared to inference from calcium imaging alone (this intuitively follows from the

fact that the electrophysiology has much higher temporal resolution and the Bayesian inference can combine

information across modalities). This simulation serves as a proof-of-concept that this probabilistic approach

can provide meaningful automatic analysis for passive mapping experiments.

18

Figure 6: Joint inference over simulated calcium and voltage data. A Observed data and true/inferred event times for four

simultaneously observed calcium traces (top) and (for simplicity) just a single voltage trace (bottom). Colored dots indicate

to which trace the algorithm matched each event; gray dots in bottom correspond to voltage events that were detected but

(correctly) not matched to any detected calcium events. In this example the algorithm correctly matched all calcium-observed

events. B Histograms of temporal error in estimated event times. Given calcium only, the variance of inferred event times

is large; incorporating voltage information drastically reduces this variance, indicating signiﬁcant potential gains in temporal

resolution from this Bayesian data fusion approach.

4. Discussion

In this work we have presented a probabilistic formulation of the event detection problem for electrophys-

iological recordings with an emphasis on PSC detection. This method works on simulated and real data and

its performance compares favorably relative to existing methods. We have also shown how the probabilistic

model can be incorporated into two extensions applicable for mapping experiments which make use either

of optical stimulation or multi-modal fusion of electrophysiology with calcium imaging.

While there are other methods that have been proposed for deconvolution for electrophysiology and for

calcium imaging (e.g. see [33] for alternative event-detection methods for calcium imaging), these approaches

lack the clear probabilistic generative semantics which facilitate modularity and extension to hierarchical

models such as those useful for mapping experiments. Our approach also complements related work infer-

ring synaptic inputs in a probabilistic fashion using particle ﬁltering [32] from voltage traces. The present

approach focuses on current traces, is perhaps simpler to implement, and does not require temporal dis-

cretization, but most importantly in the this paper our method does not assume a ﬁxed PSC shape. While

probabilistic methods may be computationally more burdensome (especially when using MCMC), there are

immediate opportunities to speed up the current approach – computation can be parallelized across time,

since temporally separate events can be sampled in a conditionally independent fashion.

Aside from the extensions we considered, other sophisticated prior structure can be incorporated by

making the model hierarchical. For example, in the single trace setting we might expect the events to

cluster by pre-synaptic cell identity or cell type. Even without the additional observed traces employed in

19

1234567calcium imaging traces (a.u.)01234567electrophysiology (a.u.)time (s)−0.0500.050.10.1500.20.40.60.81time offset (s)histogram of posterior samples (norm. count)calcium onlycalcium & ephysABour mapping model, it would be conceivable to specify and infer latent source clusters based on structure

in the distribution of shape or amplitude of post-synaptic events, depending on what were of most interest

scientiﬁcally.

In the simplest case, this would result in a mixture model for the events, with each event

associated with a latent pre-synaptic source. We plan to pursue these model extensions in future work.

Acknowledgements

Funding for this research was provided by Global Brain Research Award 325398 from the Simons Foun-

dation, ARO MURI W911NF-12-1-0594, and DARPA N66001-15-C-4032 (SIMPLEX); in addition, this work

was supported by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Inte-

rior/ Interior Business Center (DoI/IBC) contract number D16PC00003. The U.S. Government is authorized

to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation

thereon. Disclaimer: The views and conclusions contained herein are those of the authors and should not

be interpreted as necessarily representing the oﬃcial policies or endorsements, either expressed or implied,

of IARPA, DoI/IBC, or the U.S. Government. B.S. is supported by a Fannie and John Hertz Foundation

Fellowship and an NSF Graduate Research Fellowship.

5. References

References

[1] J. P. Rickgauer, K. Deisseroth, D. W. Tank, Simultaneous cellular-resolution optical perturbation and

imaging of place cell ﬁring ﬁelds, Nature Neuroscience 17 (12) (2014) 1816–1824.

[2] M. Scanziani, M. H¨ausser, Electrophysiology in the age of light, Nature 461 (7266) (2009) 930–939.

[3] D. Bar-Yehuda, A. Korngreen, Space-clamp problems when voltage clamping neurons expressing voltage-

gated conductances, Journal of Neurophysiology 99 (3) (2008) 1127–1136.

[4] B. Shababo, B. Paige, A. Pakman, L. Paninski, Bayesian inference and online experimental design for

mapping neural microcircuits, 2013, pp. 1304–1312.

[5] E. A. Pnevmatikakis, J. Merel, A. Pakman, L. Paninski, Bayesian spike inference from calcium imaging

data, in: Asilomar Conference on Signals, Systems and Computers, IEEE, 2013, pp. 349–353.

[6] G. Aaron, R. Yuste, Reverse optical probing (roping) of neocortical circuits, Synapse 60 (6) (2006) 437.

[7] P. Jonas, G. Major, B. Sakmann, Quantal components of unitary EPSCs at the mossy ﬁbre synapse on

CA3 pyramidal cells of rat hippocampus., The Journal of Physiology 472 (1) (1993) 615–663.

[8] N. Ankri, P. Legendre, D. Faber, H. Korn, Automatic detection of spontaneous synaptic responses in

central neurons, Journal of Neuroscience Methods 52 (1) (1994) 87–100.

20

[9] T. N. Hwang, D. R. Copenhagen, Automatic detection, characterization, and discrimination of kineti-

cally distinct spontaneous synaptic events, Journal of Neuroscience Methods 92 (1) (1999) 65–73.

[10] S. N. Kudoh, T. Taguchi, A simple exploratory algorithm for the accurate and fast detection of spon-

taneous synaptic events, Biosensors and Bioelectronics 17 (9) (2002) 773–782.

[11] J. Clements, J. Bekkers, Detection of spontaneous synaptic events with an optimally scaled template.,

Biophysical Journal 73 (1) (1997) 220.

[12] A. J. Pern´ıa-Andrade, S. P. Goswami, Y. Stickler, U. Fr¨obe, A. Schl¨ogl, P. Jonas, A deconvolution-based

method with high sensitivity and temporal resolution for detection of spontaneous synaptic currents in

vitro and in vivo, Biophysical Journal 103 (7) (2012) 1429–1439.

[13] S. J. Guzman, A. Schl¨ogl, C. Schmidt-Hieber, Stimﬁt: quantifying electrophysiological data with python,

Frontiers in Neuroinformatics 8.

[14] M. J. Richardson, G. Silberberg, Measurement and analysis of postsynaptic potentials using a novel

voltage-deconvolution method, Journal of Neurophysiology 99 (2) (2008) 1020–1031.

[15] G.-H. Li, M. F. Jackson, J. F. MacDonald, Weighted least squares ﬁtting with multiple templates for

detection of small spontaneous signals, Journal of Neuroscience Methods 164 (1) (2007) 139–148.

[16] Y. Shi, Z. Nenadic, X. Xu, Novel use of matched ﬁltering for synaptic event detection and extraction,

PLoS One 5 (11) (2010) e15517.

[17] S. Chib, E. Greenberg, Bayes inference in regression models with arma (p, q) errors, Journal of Econo-

metrics 64 (1) (1994) 183–206.

[18] N. Wiener, Extrapolation, interpolation, and smoothing of stationary time series: with engineering

applications, Technology press books in science and engineering, Technology Press of the Massachusetts

Institute of Technology, 1949.

[19] J. Moller, R. P. Waagepetersen, Statistical inference and simulation for spatial point processes, CRC

Press, 2004.

[20] V. Tan, V. Goyal, Estimating signals with ﬁnite rate of innovation from noisy samples: A stochastic

algorithm, IEEE Transactions on Signal Processing 56 (10) (2008) 5135–5146.

[21] E. L. Lehmann, G. Casella, Theory of point estimation, Vol. 31, Springer Science & Business Media,

1998.

[22] L. Fenno, O. Yizhar, K. Deisseroth, The development and application of optogenetics, Annual Review

of Neuroscience 34 (1) (2011) 389–412.

21

[23] E. M. Callaway, R. Yuste, Stimulating neurons with light, Current Opinion in Neurobiology 12 (5)

(2002) 587 – 592.

[24] G. M. G. Shepherd, A. Stepanyants, I. Bureau, D. Chklovskii, K. Svoboda, Geometric and functional

organization of cortical circuits, Nature Neuroscience 8 (6) (2005) 782–790.

[25] D. Katzel, B. V. Zemelman, C. Buetfering, M. Wolfel, G. Miesenbock, The columnar and laminar

organization of inhibitory connections to neocortical excitatory cells, Nature Neuroscience 14 (1) (2011)

100–107.

[26] G. Mena, L. Grosberg, F. Kellison-Linn, E. Chichilnisky, L. Paninski, Large-scale multi electrode ar-

ray spike sorting algorithm introducing concurrent recording and stimulation, in: NIPS workshop on

Statistical Methods for Understanding Neural Systems, 2015.

[27] J. T. Vogelstein, B. O. Watson, A. M. Packer, R. Yuste, B. Jedynak, L. Paninski, Spike inference from

calcium imaging using sequential monte carlo methods, Biophysical Journal 97 (2) (2009) 636–655.

[28] R. M. Neal, Probabilistic inference using markov chain monte carlo methods.

[29] A. Gelman, J. B. Carlin, H. S. Stern, D. B. Rubin, Bayesian data analysis, Vol. 2, Taylor & Francis,

2014.

[30] J. S. Rosenthal, Optimal proposal distributions and adaptive mcmc, Handbook of Markov Chain Monte

Carlo (2011) 93–112.

[31] S. Pluta, A. Naka, J. Veit, G. Telian, L. Yao, R. Hakim, D. Taylor, H. Adesnik, A direct translaminar

inhibitory circuit tunes cortical output, Nature Neuroscience 18 (11) (2015) 1631–1640.

[32] L. Paninski, M. Vidne, B. DePasquale, D. G. Ferreira, Inferring synaptic inputs given a noisy voltage

trace via sequential Monte Carlo methods, Journal of Computational Neuroscience 33 (1) (2012) 1–19.

[33] L. Theis, P. Berens, E. Froudarakis, J. Reimer, M. R. Ros´on, T. Baden, T. Euler, A. Tolias, M. Bethge,

Supervised learning sets benchmark for robust spike detection from calcium imaging signals, arXiv

preprint arXiv:1503.00135.

22

