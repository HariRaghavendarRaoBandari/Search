6
1
0
2

 
r
a

 

M
8
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
2
9
7
5
0

.

3
0
6
1
:
v
i
X
r
a

An iterative Bregman regularization method for

optimal control problems with inequality

constraints

Frank P¨orner∗, Daniel Wachsmuth†

Abstract

We study an iterative regularization method of optimal control prob-
lems with control constraints. The regularization method is based on
generalized Bregman distances. We provide convergence results under a
combination of a source condition and a regularity condition on the active
sets. We do not assume attainability of the desired state. Furthermore,
a-priori regularization error estimates are obtained.

Keywords: optimal control, Bregman regularization, source condition, regu-
larization error estimates

AMS Subject Classiﬁcation: 49K20, 49N45, 65K10

1 Introduction

In this article we consider optimization problems of the following form

Minimize

1
2

kSu − zk2
Y

such that ua ≤ u ≤ ub

a.e. in Ω,

(P)

which can be interpreted both as an optimal control problem or as an inverse
problem. Here Ω ⊆ Rn, n ≥ 1 is a bounded, measurable set, Y a Hilbert
space, z ∈ Y a given function. The operator S : L2(Ω) → Y is linear and
continuous. The inequality constraints are prescribed on the set Ω. We assume
ua, ub ∈ L∞(Ω). Here, we have in mind to choose S to be the solution operator

∗Department of Mathematics, University of W¨urzburg, Emil-Fischer-Str. 40, 97074

W¨urzburg, Germany, E-mail: frank.poerner@mathematik.uni-wuerzburg.de

†Department of Mathematics, University of W¨urzburg, Emil-Fischer-Str. 40, 97074

W¨urzburg, Germany, E-mail: daniel.wachsmuth@mathematik.uni-wuerzburg.de

1

of a linear partial diﬀerential equation. In many situations the operator S is
compact or has non-closed range, which makes (P) ill-posed.

In an optimal control setting, the unknown u is the control and the con-
straints are limitations arising from the underlying physical problem, i.e., tem-
perature restriction of a heat source. The function z is the desired state, and we
search for u such that Su is as close to z as possible with respect to the norm in
Y . Here, the interesting situation is, when z cannot be reached due to the pres-
ence of the control constraints (non-attainability). If (P) is interpreted as an
inverse problem, the unknown u represents some data to be reconstructed from
the measurement z. Here the inequality constraints reﬂect a-priori information
of the unknown u.

A well-known regularization method is the Tikhonov regularization with
some positive regularization parameter α > 0. The regularized problem is given
by:

Minimize

1
2

kSu − zk2

Y +

α
2

kuk2

L2(Ω)

such that ua ≤ u ≤ ub

a.e. in Ω.

The additional term can be interpreted as control costs. This method is well
understood in regard to convergence for α → 0, perturbed data, and numerical
approximations, see e.g., [3, 16, 17, 18, 19]. However, for α tending to zero the
Tikhonov regularized problem becomes increasingly ill-conditioned.

An alternative is the proximal point algorithm (PPM) introduced by Mar-
tinez [7] and developed by Rockafellar [12]. Given an iterate uk, the next iterate
uk+1 is determined by solving

Minimize

1
2

kSu − zk2

Y + αk+1ku − ukk2

L2(Ω)

such that ua ≤ u ≤ ub

a.e. in Ω.

Due to the self-canceling eﬀect of the regularization term, there is hope to
obtain a convergent method without the requirement that the regularization
parameters αk tend to zero. However, in general PPM is not strongly convergent
due to the example given by G¨uler [4], which exhibits weakly converging but
not strongly converging iterates, see also [6]. An application of this method to
optimal control problems is investigated in [13]. There exists strongly convergent
modiﬁcations of PPM, see e.g., [10, 11, 15]. Here, it is an open question how to
transfer these methods to our problem while exploiting its particular structure.
In the inverse problems community this method is known under the name
iterated Tikhonov regularization [3, 5]. Under the attainability assumption,
that is, z is in the range of S, convergence can be proven.
If one assumes
in addition a so-called source condition, then convergence rates can be derived.
While the PPM and thus the iterated Tikhonov method allow to proof beautiful
monotonicity properties, we were not able to show strong convergence under
conditions adapted to our situation (control constraints and non-attainability).
In order to overcome this diﬃculty, we investigated the Bregman iterative
regularization technique, where the Hilbert space norm in the regularization

2

term is replaced by a Bregman distance [1]. There, the iterate uk+1 is given by
the solution of

Minimize

1
2

kSu − zk2

Y + αk+1Dλk (u, uk),

where Dλ(u, v) = J(u) − J(v) − (u − v, λ) is called the (generalized) Bregman
distance associated to a regularization function J with subgradient λ ∈ ∂J(v).
This iteration method was used ﬁrst in [2, 9] applied to an image restoration
problem with J being the total variation. Note that for the special choice
J(u) = 1

L2(Ω) the PPM algorithm is obtained.

2 kuk2

We choose to incorporate the control constraint into the regularization func-

tional, resulting in

J(u) :=

1
2

kuk2 + IUad (u),

where Uad = {u ∈ L2(Ω) : ua ≤ u ≤ ub}, and I is the indicator function of
convex analysis. While at ﬁrst sight the incorporation of IUad into the Bregman
regularization functional together with the explicit control constraint u ∈ Uad
seems to be redundant, this choice proved advantageous for the convergence
analysis.

In order to prove convergence, in [2] a source condition is imposed. Moreover,
the analysis there relied heavily on the attainability of z. In this paper, we prove
convergence and convergence rates without the attainability assumption. To do
so, the existing proof techniques had to be considerably extended. Moreover,
as argued in [18] a source condition is unlikely to hold in an optimal control
setting if z is not attainable, i.e., there is no feasible u such that z = Su. In
[17, 19] a regularity assumption on the active set is used as suitable substitution
of the source condition. Here, the active set denotes the subset of Ω, where
the inequality constraints are active in the solution. However this assumption
implies that the control constraints are active everywhere, and situations where
the control constraints are inactive on a large part of Ω are not covered. To
overcome this, in [18] both approaches are combined: A source condition is used
on the part of the domain, where the inequality constraints are inactive, and
a structural assumptions is used on the active sets. We will use this combined
assumption to prove convergence rates of the Bregman iteration.

In order to formulate the method, a recipe to choose the subgradient λ
has to be added. We report on this choice in Section 3. The convergence
of the Bregman method is studied in Section 4. Convergence rates under the
assumption of a source condition are proven in Section 4.2. The main result of
the paper, the convergence under a combined source condition and regularity
condition on the active sets is Theorem 4.13, which can be found in Section 4.3.

Notation. For elements q ∈ L2(Ω), we denote the L2-Norm by kqk := kqkL2(Ω).
Furthermore c is a generic constant, which may change from line to line, but is
independent from the important variables, e.g. k.

3

2 Problem setting and preliminary results

Let Ω ⊆ Rn, n ∈ N, be a bounded, measurable domain, Y a Hilbert space,
S : L2(Ω) → Y linear and continuous. We are interested in computing a solution
to the minimization problem (P). Here, we assume z ∈ Y and ua, ub ∈ L∞(Ω).
The functional to be minimized will be denoted by

H(u) :=

1
2

kSu − zk2
Y

and the set of admissible functions by

Uad := {u ∈ L2(Ω) : ua ≤ u ≤ ub}.

In addition we assume that ua ≤ ub a.e. on Ω, which ensures that Uad is non-
empty.

2.1 Existence of solutions and optimality conditions

Existence of solutions can be proven by classical arguments using the direct
method of the calculus of variations.

Theorem 2.1. Under the assumptions listed above the problem (P) has a so-
lution. If the operator S is injective the solution is unique.

In the following, we denote by u† ∈ Uad a solution of (P). Note that due
to the strict convexity of H with respect to Su the optimal state y† := Su†
is uniquely deﬁned. In addition, we deﬁne the associated adjoint state p† :=
S∗(z − Su†). We then have the following result.

Theorem 2.2. We have the relation

= ua(x)
∈ [ua(x), ub(x)]
= ub

if
if
if

p†(x) < 0
p†(x) = 0
p†(x) > 0

u†(x)


and the following variational inequality holds:

(−p†, u − u†) ≥ 0,

∀u ∈ Uad.

This result shows that the solution u† can be determined from p† if the
set {x : p†(x) 6= 0} has zero measure. As a consequence, the problem (P) is
uniquely solvable in this case.

2.2 Bregman distance

We want to apply the Bregman iteration with the regularization functional

J(u) :=

1
2

kuk2 + IUad (u),

4

where IC denotes the indicator function of the set C. The Bregman distance
for J at u, v ∈ L2(Ω) and λ ∈ ∂J(v) is deﬁned as

Dλ(u, v) := J(u) − J(v) − (u − v, λ).

Note that λ = v + w with w ∈ ∂IUad (v), hence:

Dλ(u, v) =

1
2

ku − vk2 + IUad (u) − IUad (v) − (u − v, w).

(2.1)

Let us summarize the properties of J and D:

Lemma 2.3. Let C ⊆ L2(Ω) be non-empty, closed, and convex. The functional

J : L2(Ω) → R ∪ {+∞},

u 7→

1
2

kuk2 + IC (u)

is convex and nonnegative. Furthermore the Bregman distance

Dλ(u, v) := J(u) − J(v) − (u − v, λ),

λ ∈ ∂J(v)

is nonnegative and convex with respect to u.

The subgradient ∂IUad (v) is the normal cone of Uad at v, which can be

characterized as:

∂IUad (v) =


w ∈ L2(Ω) : w(x)


Hence, we have for the Bregman distance at v ∈ Uad

≤ 0 if v(x) = ua(x)
= 0 if ua(x) < v(x) < ub(x)
≥ 0 if v(x) = ub(x)

.




Dλ(u, v) =

1
2

ku − vk2 + IUad (u)

+ Z{v=ua}

w(ua − u) dx + Z{v=ub}

w(ub − u) dx.

where we abbreviated by {v = ua} the set {x ∈ Ω : v(x) = ua(x)}. We see that
the Bregman distance adds two parts that measures u on sets where the control
constraints are active for v. Due to the properties of w ∈ ∂IUad (v) we obtain

Dλ(u, v) ≥

1
2

ku − vk2 ∀u, v ∈ Uad, λ ∈ ∂J(v).

(2.2)

Since the subgradient ∂IUad (v) is not a singleton in general, the Bregman dis-
tance depends on the choice of the subgradient w ∈ ∂IUad (v). In the algorithm
described below we will derive a suitable choice for the subgradients λ ∈ ∂J(u)
and w ∈ ∂IUad (u).

5

3 Bregman iteration

To start our algorithm we need suitable starting values u0 ∈ Uad and λ0 ∈
∂J(u0). We deﬁne u0 to be the solution of the problem

min

u∈L2(Ω)

J(u) =

1
2

kuk2 + IUad (u),

which yields u0 = PUad (0). Furthermore this choice ensures 0 ∈ ∂J(u0), so
we simply set λ0 = 0. Note that all of the following results can be extended
to arbitrary u0 ∈ Uad and general subgradients λ0 ∈ ∂J(u0) ∩ R(S∗). The
(prototypical) Bregman iteration is now deﬁned as follows:

Algorithm A0. Let u0 = PUad(0) ∈ Uad, λ0 = 0 ∈ ∂J(u0) and k = 1.

1. Solve for uk:

Minimize

1
2

kSu − zk2

Y + αkDλk−1 (u, uk−1).

(3.1)

2. Choose λk ∈ ∂J(uk).

3. Set k := k + 1, go back to 1.

Here (αk)k is a bounded sequence of positive real numbers. If u† is a solution

of (P), it satisﬁes u† = PUad(cid:0)u†−ΘS∗(Su†−z)(cid:1) with Θ > 0 arbitrary. Therefore

a possible stopping criterion is given by (with ε > 0)

We introduce the quantity

(cid:13)(cid:13)uk − PUad(cid:0)uk − ΘS∗(Suk − z)(cid:1)(cid:13)(cid:13) ≤ ε.

k

γk :=

Xj=1

1
αj

.

Since the sequence αj is bounded we obtain

lim
k→∞

γ−1
k = 0.

In algorithm A0 it remains to specify how to choose the subgradient λk for
the next iteration. We will show that we can construct a new subgradient based
on the iterates u1, ..., uk. The following result motivates the construction of the
subgradient. Moreover it shows that algorithm A0 is well-posed.

Lemma 3.1. The problem (3.1) has a unique solution uk ∈ Uad and there exists
wk ∈ ∂IUad (uk) such that

S∗(Suk − z) + αk(uk − λk−1 + wk) = 0.

Moreover, the subgradient ∂J(uk) is non-empty.

6

Proof. The set of admissible functions Uad is nonempty, closed, convex, and
bounded, hence weakly compact. Furthermore, the function Jk deﬁned by

Jk : L2(Ω) → R,

u 7→

1
2

ku − uk−1k2 − (u − uk−1, λk−1)

is continuous and convex, hence it is weakly lower semi-continuous. It is easy
to check that (3.1) is equivalent to

min
u∈Uad

H(u) + αkJk(u).

Since H is convex, the function H + αkJk is convex and by the Weierstraß
theorem (with respect to the weak topology) we get existence of minimizers.
Since αk 6= 0 and Jk is strictly convex, minimizers are also unique. By the
ﬁrst-order optimality condition for (3.1) there exists wk ∈ ∂IUad (uk) such that

S∗(Suk − z) + αk(uk − λk−1 + wk) = 0.

Clearly, it holds ∂J(uk) 6= ∅.

We have ∂J(uk) = uk + ∂IUad (uk), so motivated by Lemma 3.1 we set

λk := uk + wk =

1
αk

S∗(z − Suk) + λk−1 ∈ ∂J(uk)

(3.2)

An induction argument now yields the following result.

Lemma 3.2. Let the subgradients λk ∈ ∂J(uk) be chosen according to (3.2).
Then it holds

λk = S∗µk, µk :=

Xi=1

k

1
αi

(z − Sui).

With this choice of λk, we see that the Bregman iteration A0 can be equiv-

alently formulated as:

Algorithm A. Let u0 = PUad (0) ∈ Uad, µ0 = 0, λ0 = 0 ∈ ∂J(u0) and k = 1.

1. Solve for uk:

Minimize

1
2

kSu − zk2

Y + αkDλk−1 (u, uk−1).

(A1)

2. Set µk :=

1
αi

(z − Sui) and λk := S∗µk.

3. Set k := k + 1, go back to 1.

k

Pi=1

As argued in [2, 9], algorithm A is equivalent to the following algorithm:

Algorithm B. Let µ0 := 0 and k = 1.

7

1. Solve for uk:

Minimize

1
2

kSu − z − αkµk−1k2

Y +

αk
2

kuk2

such that uk ∈ Uad

2. Set µk =

1
αk

(z − Suk) + µk−1.

3. Set k := k + 1, go back to 1.

The equivalence can be seen directly by computing the ﬁrst-order optimality

conditions. For a solution uk given by algorithm A we obtain

while for an iterate ¯uk and resulting ¯µk of algorithm B we get

(cid:0)S∗(Suk − z) + αk(uk − λk−1), v − uk(cid:1) ≥ 0,
(cid:0)S∗(S ¯uk − z − αk ¯µk−1) + αk ¯uk, v − ¯uk(cid:1) ≥ 0,

∀v ∈ Uad,

∀v ∈ Uad.

By adding both inequalities and applying an induction, we obtain

kS(uk − ¯uk)k2

Y + αkkuk − ¯ukk2 ≤ (αkS∗µk−1 − αkλk−1, ¯uk − uk).

By deﬁnition λk−1 = S∗µk−1 and therefore both algorithms coincide.

3.1 A priori error estimates for H(uk)

We want to show ﬁrst error estimates in terms of |H(uk) − H(u†)|, where u†
is a solution of (P). The following result can be proven similar to the proof
presented in [9] and is omitted here.

Lemma 3.3. The iterates of algorithm A satisfy

H(uk) ≤ H(uk−1).

Following the proof of [9, Theorem 3.3] we can formulate a convergence result

on (H(uk))k, together with an a-priori error estimate.

Theorem 3.4. The iterates of algorithm A satisfy

Hence we have convergence, since the αk are uniformly bounded. Furthermore
we have

|H(uk) − H(u†)| = O(cid:0)γ−1
k (cid:1) .

Dλk (u†, uk) ≤ Dλk−1 (u†, uk−1) and

Dλi−1 (ui, ui−1) < ∞.

∞

Xi=1

The monotonicity of Dλk (u†, uk) will play a crucial role in the subsequent
analysis. Together with the lower bound (2.2) it will allow to proof strong
convergence uk → u† under suitable conditions.

8

3.2 Auxiliary estimates

In the sequel, we will denote by (uk)k the sequence of iterates provided by
algorithm A. Let us start with the following result, which will be useful in the
convergence analysis later on.

Lemma 3.5. Let βj ≥ 0, such that βj → 0. We then have

lim
k→∞

γ−1
k

k

Xj=1

α−1

j βj = 0.

Proof. Let ε > 0 be arbitrary. Since βj → 0 we can choose N such that βj ≤ ε
2
holds for all j ≥ N . Since γ−1

k → 0 there is M > N such that

γ−1
k

N

Xj=1

α−1

j βj ≤

ε
2

holds for all k ≥ M . We compute for k ≥ M :

γ−1
k

k

Xj=1

α−1
j βj = γ−1
k

N

Xj=1

α−1
j βj + γ−1
k

k

Xj=N +1

α−1

j βj

≤

ε
2

+

ε
2

γ−1
k

α−1

j ≤

ε
2

+

ε
2

γ−1
k γk ≤ ε,

k

Xj=N +1

which is the claim.

In the case that Suk is equal to the optimal state y† = Su†, the algorithm

gives uk+1 = uk, which is then a solution of (P).

Lemma 3.6. Let y† be the optimal state of (P). If Suk = y† then it holds
uk+1 = uk, and uk solves (P).

Proof. Since uk+1 is the minimizer of

1
2

kSu − zk2

Y + αk+1Dλk (u, uk)

it follows

1
2

kSuk+1 − zk2

Y + αk+1Dλk (uk+1, uk) ≤

=

1
2
1
2

kSuk − zk2

Y + αk+1Dλk (uk, uk)

ky† − zk2
Y .

Since y† is the optimal state of (P), it follows ky† − zkY ≤ kSuk+1 − zkY , and
hence we obtain

0 = Dλk (uk+1, uk) =

1
2

kuk+1 − ukk2 − (wk, uk+1 − uk).

9

By construction we have wk ∈ ∂IUad (uk), so

1
2

kuk+1 − ukk2 = (wk, uk+1 − uk) ≤ 0,

which implies uk+1 = uk. Since Suk = y† it follows that uk = uk+1 solves
(P).

If the algorithm reaches a solution of (P) after a ﬁnite number of steps, we
can show that this solution satisﬁes a source condition. This condition is used
below in Section 4.2 to prove strong convergence of the iterates.

Lemma 3.7. Let uk be a solution of (P) for some k. Then there exists a w ∈ Y
such that uk = PUad (S∗w) holds.

Proof. For k = 0 this is true by the deﬁnition of u0 = PUad (0) = PUad (S∗(0)).
For k ≥ 1 we obtain with the optimality condition

uk = PUad (λk) = PUad (S∗µk),

which is the stated result.

Let us now prove auxiliary results that exploits the choice of the subdif-
ferential λk in (3.2). They will be employed in the convergence rate estimates
below.

Lemma 3.8. Let u† be a solution of (P). Then it holds

1
αk

Dλk (u†, uk) +

1
2 α2
k

kS(u† − uk)k2

Y +

1
2

kvkk2
Y

where vk is deﬁned by

≤

1
αk

(u†, u† − uk) +

γk
αk

(p†, uk − u†) +

1
2

kvk−1k2
Y

(3.3)

vk :=

1
αi

k

Xi=1

S(u† − ui).

(3.4)

Proof. First notice that u† ∈ ∂J(u†) holds, which follows from

u† = u† + 0 ∈ ∂(cid:18) 1

2

k · k2(cid:19) (u†) + ∂IUad (u†) ⊆ ∂J(u†).

As in the proof of [2, Theorem 4.1], we consider the sum of the Bregman dis-
tances

Du†

(uk, u†) =

10

1
αk

Dλk (u†, uk) +

1
αk

1
αk

(u† − λk, u† − uk).

Using the deﬁnitions of vk and p†, we obtain

1
αk

(−λk, u† − uk) =

=

k

k

1

αk 
Xj=1

αk 
Xj=1


1

1
αj

1
αj

(Suj − z), S(u† − uk)

(S(uj − u† + u†) − z), S(u† − uk)


k

= (−vk, vk − vk−1) +

(Su† − z, S(u† − uk))

1
αk

1
αj

Xj=1

= (−vk, vk − vk−1) +

γk
αk

(p†, uk − u†).

We continue with transforming the ﬁrst addend on the right-hand side

(−vk, vk − vk−1) =

=

1
2
1
2

kvk−1k2

Y −

kvk−1k2

Y −

1
2
1
2

kvkk2

Y −

kvkk2

Y −

1
2

kvk − vk−1k2
Y

1
2α2
k

kS(u† − uk)k2
Y .

We obtain the result by using the nonnegativity of Du†

(uk, u†).

Estimate (3.3) will play a key role in the convergence analysis of the algo-
rithm. The principal idea is to sum the inequality (3.3) with respect to k. Using
the monotonicity of the Bregman distance Dλk (u†, uk) and inequality (2.2), we
can then conclude convergence of the iterates if we succeed in estimating the
terms involving the scalar product (u†, u† − uk). Note that due to Theorem 2.2
the term (p†, uk − u†) is non-positive.

4 Convergence of the Bregman iteration

In this section we study convergence of the iterates (uk)k of algorithm A.

4.1 General convergence results

First we present a general convergence result.

Theorem 4.1. Weak limit points of the sequence (uk)k generated by algorithm
A are solutions to the problem (P). Furthermore the iterates satisfy

kui − ui−1k2 < ∞.

∞

Xi=1

Proof. Since L2(Ω) is a Hilbert space and Uad is bounded, closed and convex,
it is weakly relatively compact and weakly closed. Hence we can deduce the

11

existence of a subsequence ukj ⇀ u∗ ∈ Uad. Furthermore H is convex and
continuous, so it is weakly lower semi-continuous. By Theorem 3.4 we know
that the sequence (H(uk))k is converging towards H(u†), hence we obtain

H(u†) = lim inf
j→∞

H(ukj ) ≥ H(u∗),

yielding H(u†) = H(u∗), since u† realizes the minimum of H in Uad. So u∗ is
a solution to the problem (P). To prove the second part we use (2.2) and the
result of Theorem 3.4 to show

1
2

kui − ui−1k2 ≤

∞

Xi=1

which ends the proof.

Dλi−1 (ui, ui−1) < ∞,

∞

Xi=1

Remark 4.2. The above result resembles properties of the iterates generated by

the PPM. There it holds P∞

i=1 kui − ui−1k2 < ∞, see e.g. [15].

As argued in Section 2.1, the optimal state y† of (P) is uniquely determined.
This allows to prove the strong convergence (Suk) under mild conditions on the
parameters αk.

Theorem 4.3. Let the sequence (uk)k be generated by algorithm A. Then it
holds

where y† is the uniquely determined optimal state of (P).

Suk → y†,

Proof. Let (uk′ )k′ be a subsequence of the sequence of iterates. Due to the
boundedness of Uad, this sequence is bounded, and has a weakly converging
subsequence (uk′′ )k′′ , uk′′ → u∗. By Theorem 4.1, the limit u∗ is a solution of
(P). This implies Su∗ = y†. Hence, we proved that each subsequence of (Suk)k
contains a subsequence that weakly converges to y†. This shows Suk ⇀ y†.

Due to Theorem 3.4 and γ−1

k → 0, we have that

H(uk) =

1
2

kSuk − zk2

Y →

1
2

ky† − zk2

Y = H(u†)

for every solution u† of (P). This implies convergence of the norms kSukkY →
ky†kY . Since Y is a Hilbert space, the strong convergence Suk → y† follows
immediately.

If we assume that the problem (P) has a unique solution u† ∈ Uad we can

prove strong convergence of our algorithm.

As argued above, the solution of (P) is uniquely determined if, e.g., the

operator S is injective or p† 6= 0 almost everywhere.

Theorem 4.4. Assume that u† ∈ Uad is the unique solution of (P). Then the
iterates of algorithm A satisfy

lim
k→∞

kuk − u†k = 0 and

min

j=1,...,k

1
αj

kS(uj − u†)k2

Y → 0.

12

Proof. With Theorem 4.1 we know that each weak limit point is a solution to
the problem (P). So let u∗ be such a point which satisfy H(u†) = H(u∗). As u†
is the unique solution we conclude u∗ = u†. From every subsequence of (uk)k
we can extract a weakly converging subsequence and repeat this argumentation.
Hence we can conclude weak convergence uk ⇀ u† of the whole sequence.

With Lemma 3.8 and Theorem 2.2 we obtain

1
2 α2
k

kS(u† − uk)k2

Y +

1
αk

Dλk (u†, uk) +

1
2

kvkk2

Y ≤

1
αk

(u†, u† − uk) +

1
2

kvk−1k2
Y .

Summing up yields

k

Xj=1

1

2 α2
j

kS(u† − uj)k2

Y +

1
αj

k

Xj=1

Dλj (u†, uj) ≤

k

Xj=1

α−1
j (u†, u† − uj).

where we used the convention v0 = 0. We now use the monotonicity of Dλk (u†, uk)
(see Theorem 3.4) and the estimate 1

2 ku† − ukk2 ≤ Dλk (u†, uk) to obtain

min

j=1,...,k

1
αj

kS(u† − uj)k2

Y + ku† − ukk2

Y ≤ 2γ−1
k

α−1
j (u†, u† − uj).

k

Xj=1

We ﬁnally obtain the result by using the weak convergence uk ⇀ u† and
Lemma 3.5.

4.2 Strong convergence for the Source Condition

A common assumption on a solution u† is the following source condition, which
is an abstract smoothness condition (see [2, 8, 18, 19]). We say u† satisﬁes the
source condition SC if the following assumption holds.

Assumption SC (Source Condition). Let u† be a solution of (P). Assume
that there exists an element w ∈ Y such that u† = PUad (S∗w) holds.

The source condition is equivalent to the existence of Lagrange multipliers

for the problem

min
u∈Uad

1
2

kuk2

such that Su = y†,

(4.1)

where y† is the uniquely deﬁned optimal state of (P). To see this, consider the
Lagrange function

L(u, w) :=

kuk2 + (w, y† − Su).

1
2

For every u† satisfying Su† = y† we obtain

∂
∂w

L(u†, w†) = y† − Su† = 0.

13

This means, the function w† is a Lagrange multiplier if and only if:

∂
∂u

L(u†, w†)(v − u†) ≥ 0 ∀v ∈ Uad

⇐⇒ (u† − S∗w†, v − u†) ≥ 0 ∀v ∈ Uad
⇐⇒ u† = PUad (S∗w†)

Hence, if the control u† satisﬁes SC then it is a solution of (4.1). Moreover, as
this optimization problem is uniquely solvable, it follows that there is at most
one control satisfying SC. Note that the existence of Lagrange multipliers is not
guaranteed in general, as in many situations the operator S is compact and has
non-closed range.

Under this assumption we can prove strong convergence of algorithm A.

Theorem 4.6. Assume that Assumption SC holds for u†. Then the iterates of
algorithm A satisfy

kuk − u†k2 = O(γ−1
k )

min

i=1,...,k

kS(ui − u†)k2

Y = O
  k
Xi=1

α−2

i !

−1
 .

Proof. From Lemma 3.8 we know

1
αk

Dλk (u†, uk) +

1
2 α2
k

kS(u† − uk)k2

Y +

1
2

kvkk2

Y ≤

1
αk

(u†, u† − uk) +

1
2

kvk−1k2
Y .

It remains to estimate (u†, u† − uk) with the help of the source condition. By
the deﬁnition of the projection u† = PUad (S∗w) we get

Since uk ∈ Uad we have

1

αk(cid:0)u†, u† − uk(cid:1) ≤

(cid:0)u† − S∗w, v − u†(cid:1) ≥ 0 ∀v ∈ Uad.
αk(cid:0)S∗w, u† − uk(cid:1) =

1
αk

1

(w, S(u† − uk))Y = (w, vk − vk−1).

Plugging this in the estimate above yields

1
αk

Dλk (u†, uk) +

1

2 α2
k

kS(u† − uk)k2

Y +

1
2

kvk − wk2

Y ≤

1
2

kvk−1 − wk2
Y .

Following the lines of Theorem 4.4 we obtain by a summation

1
2

k

Xj=1

1
α2
j

kS(u† − uj)k2

Y +

γk
2

ku† − ukk2 +

1
2

kvk − wk2

Y ≤

1
2

kwk2
Y ,

which yields the result.

14

Under the source condition SC we can improve Lemma 3.6.

Lemma 4.7. Assume that u† satisﬁes Assumption SC. If it holds Suk = y†,
then it follows uk = u†.

Proof. As argued in Lemma 3.7, uk fulﬁlls SC. Hence both uk and u† are
solutions of the minimal norm problem 4.1. This problem is uniquely solvable,
which yields uk = u†.

While the sequence (λk)k is unbounded in general, we can prove convergence

of γ−1

k λk, which is a weighted average of the sequence (cid:0)S∗(z − Suk)(cid:1)k.

Corollary 4.8. Assume that Assumption SC holds for u†. Then it holds

γ−1
k

1
αi

k

Xi=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

2

Y

S(ui − u†)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
k   k
Xi=1

Proof. Due to the deﬁnitions of λk, p†, and vk it holds

γ−1
k λk − p† = γ−1

1
αi

S∗S(u† − ui)! = γ−1

k S∗vk.

2

= O(γ−2

k ).

+(cid:13)(cid:13)γ−1

k λk − p†(cid:13)(cid:13)

Following the lines of the proof of Theorem 4.6, we obtain

kvkkY ≤ kvk − wkY + kwkY ≤ 2kwkY ,

which yields the claim.

When comparing the convergence rates of Theorem 4.6 and Corollary 4.8,
S(ui −u†) converges

one sees that the norm of the weighted average γ−1

1
αi
kS(ui − u†)kY , since it holds γ2

k Pk

i=1

faster to zero than min

i=1,...,k

k = (cid:16)Pk

i=1 α−1

>

i (cid:17)2

i=1 α−2

i

.

Pk

4.3 Convergence results for the Active Set Condition

If z is not attainable, i.e., y† 6= z, a solution u† may be bang-bang, i.e., u† is
a linear combination of characteristic functions, hence discontinuous in general
with u† 6∈ H 1(Ω). But in many examples the range of S∗ contains H 1(Ω) or
C( ¯Ω). Hence, the source condition SC is too restrictive for bang-bang solutions.
We will thus resort to the following condition. We say that u† satisﬁes the active
set condition ASC, if the following assumption holds. Let us recall the deﬁnition
of p† = S∗(z − Su†).

Assumption ASC (Active Set Condition). Let u† be a solution of (P) and
assume that there exists a set I ⊆ Ω, a function w ∈ Y , and positive constants
κ, c such that the following holds

15

1. (source condition) I ⊃ {x ∈ Ω : p†(x) = 0} and
χI u† = χI PUad (S∗w),

2. (structure of active set) A := Ω \ I and for all ε > 0
|{x ∈ A : 0 < |p†(x)| < ε}| ≤ cεκ,

3. (regularity of solution) S∗w ∈ L∞(Ω).

Remark 4.10. Following [18, Remark 3.1], there exists at most one u† ∈ Uad
satisfying Assumption ASC. Furthermore by [18, Remark 3.1] this has to be the
minimal norm solution in Uad, which is unique by [18, Lemma 2.3].

This condition is used in [18]. It was applied for the case κ = 1, I = ∅ and
A = Ω in [19]. The set I contains the set {x ∈ Ω : p†(x) = 0}, which is the
set of points where u†(x) cannot be uniquely determined from p†(x), compare
to Theorem 2.2. On this set, we assume that u† fulﬁlls a local source condition,
which implies that u† has some extra regularity there. The set A contains the
points, where the inequality constraints are active, since it holds by construction
that p†(x) 6= 0 on A, which implies u†(x) ∈ {ua(x), ub(x)}.

In the following we will show convergence results for iterates produced by
algorithm A if we assume ASC. The special case I = Ω is already covered by
Theorem 4.6, since for this choice of I the Assumption ASC reduces to the
Assumption SC.

We now focus on the case I 6= Ω, that is, if the source condition is not

satisﬁed on the whole domain Ω.

At ﬁrst, let us prove a strengthened version of the ﬁrst-order optimality

conditions satisﬁed by u†. We refer to [14, Lemma 1.3] for a diﬀerent proof.
Lemma 4.11. Let u† satisfy Assumption ASC. Then there is cA > 0 such that
for all u ∈ Uad

(−p†, u − u†) ≥ cAku − u†k1+ 1

κ

L1(A)

is satisﬁed.

Proof. Let ε > 0 be given. Let us deﬁne Aε := {x ∈ A :
holds

|p†(x)| ≥ ε}. Then it

−ZΩ

p†(u − u†) ≥ −ZAε

p†(u − u†) − ZA\Aε

p†(u − u†)

≥ ε ku − u†kL1(Aε) − ε ku − u†kL1(A\Aε).

Using Assumption ASC to estimate the measure of the set A \ Aε we proceed
with

ε ku − u†kL1(Aε) − ε ku − u†kL1(A\Aε)

≥ ε ku − u†kL1(A) − 2 ε ku − u†kL1(A\Aε)
≥ ε ku − u†kL1(A) − 2 ε ku − u†kL∞(A) |A \ Aε|
≥ ε ku − u†kL1(A) − c εκ+1,

16

where c > 1 is a constant independent of u. In the last step, we used that the
control bounds are given in L∞(Ω). Setting ε := c−2/κku − u†k1/κ

L1(A) yields

(−p†, u − u†) ≥ cku − u†k1+ 1

κ

L1(A),

which is the claim.

The next step concerns the estimation of (u†, u† − uj) with the help of the

source condition part of ASC.

Lemma 4.12. Let u† satisfy ASC. If I 6= Ω there is a constant c > 0 such that
for all k it holds

(u†, u† − uk) ≤ (S∗w, u† − uk) + c ku† − ukkL1(A).

Proof. Since Uad is deﬁned by pointwise inequalities, the projection onto Uad
can be taken pointwise. This implies

(cid:0)χI (u† − S∗w), v − u†(cid:1) ≥ 0,

∀v ∈ Uad,

(χI u†, u† − uk) ≤ (χI S∗w, u† − uk).

leading to

This gives

(u†, u† − uk) = (χI u† + χAu†, u† − uk)

≤ (χI S∗w + χAu†, u† − uk)

Since χI = 1 − χA we have

=(cid:0)S∗w, χI (u† − uk)(cid:1) + (χAu†, u† − uk).

SχI(u† − uk) = S(1 − χA)(u† − uk) = S(u† − uk) − SχA(u† − uk).

Hence

(u†, u† − uk) ≤(cid:0)w, S(u† − uk) − SχA(u† − uk)(cid:1) +(cid:0)u†, χA(u† − uk)(cid:1)

=(cid:0)w, S(u† − uk)(cid:1) +(cid:0)u† − S∗w, χA(u† − uk)(cid:1).

Since on A we have p† 6= 0 and u† ∈ L∞(A), (recall ua, ub ∈ L∞(A)) so

using the regularity assumption S∗w ∈ L∞(Ω) we can estimate

(cid:0)u† − S∗w, χA(u† − uk)(cid:1) ≤ cku† − ukkL1(A),

which is the claim.

We now have all the tools to prove strong convergence for the iterates of

Algorithm A.

17

Theorem 4.13. Let u† satisfy Assumption ASC. Then the iterates of Algo-
rithm A satisfy

k + γ−1

k

j γ−κ
α−1

k

ku† − ukk2 = O
γ−1
Y = O

Xj=1


L1(A) = O

Xj=1



k

κ

k

1
α2

Xj=1
−1
j
1 +

−1
αj
1 +


γj

j 
 ,
Xj=1

k

k

Xj=1

j γ−κ
α−1

α−1
j γ−κ

,

.


j 



j 



min

j=1,...,k

min

j=1,...,k

kS(u† − uj)k2

ku† − ujk1+ 1

Proof. Using the results of Lemmas 3.8, 4.11, and 4.12 we obtain

1
αk

Dλk (u†, uk) +

1

2 α2
k

kS(u† − uk)k2

Y +

1
2

kvkk2

Y −

1
2

kvk−1k2
Y

≤

≤

1
αk
1
αk

(u†, u† − uk) +

γk
αk
(S∗w, u† − uk) +

(p†, uk − u†)

ku† − ukkL1(A) −

c
αk
ku† − ukkL1(A) −

ku† − ukk1+ 1

cAγk
αk
ku† − ukk1+ 1

L1(A).

κ

κ

L1(A)

cAγk
αk

≤ (w, vk − vk−1) +

c
αk

By Young’s inequality, we ﬁnd

c
αk

ku† − ukkL1(A) ≤

cAγk
2 αk

This implies the estimate

ku† − ukk1+ 1

κ

L1(A) + c

γ−κ
k
αk

.

1
αk

Dλk (u†, uk) +

1
2 α2
k

kS(u† − uk)k2

Y +

cAγk
2 αk

ku† − ukk1+ 1

κ

L1(A) +

1
2

kvk − wk2
Y

Summation of this inequality together with the monotonicity of the Bregman
distance gives

≤

1
2

kvk−1 − wk2

Y + c

γ−κ
k
αk

.

k

Xj=1

1
α2
j

kS(u† − uj)k2

Y +

γj
αj

k

Xj=1

ku† − ujk1+ 1

κ

L1(A)

+ γkDλk (u†, uk) + kvk − wk2

The claim now follows using the lower bound (2.2).

Y ≤ c
1 +

k

Xj=1

α−1
j γ−κ

j 
 .

18

If assumption ASC is satisﬁed with A = Ω, which implies that u† is bang-
bang on Ω, or w = 0, then the estimate of Theorem 4.13 can be improved
to

k

ku† − ukk2 ≤ c γ−1

k

α−1
j γ−κ

j

.

Xj=1

Similar to Corollary 4.8 we can prove convergence of the weighted average

γ−1
k λk.

Corollary 4.14. Let u† satisfy ASC. Then it holds

γ−1
k

1
αi

k

Xi=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

2

Y

S(ui − u†)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

2

+(cid:13)(cid:13)γ−1

k λk − p†(cid:13)(cid:13)

= O
k 
γ−2
1 +

k

Xj=1

α−1
j γ−κ

j 



 .

Proof. Following the lines of theorem 4.13 we obtain

kvkk2

Y ≤ c(kvk − wk2

Y + kwk2

Y ) ≤ c
1 +

k

Xj=1

j γ−κ
α−1

j 
 .

The claim follows with the same arguments as in Corollary 4.8.

Let us derive precise convergence rates, if αk is a polynomial in k.

Corollary 4.15. Let u† satisfy ASC. Suppose that αk is given by αk = cαk−s
with s ≥ 0, cα > 0. Then it holds

ks+1ku† − ukk2 + k2(s+1) min

ku† − ujk1+ 1

κ

L1(A)

+ k2s+1 min

j=1,...,k

j=1,...,k
kS(u† − uj)k2

Y + k2(s+1)kγ−1

k λk − p†k2

Y

k(s+1)(1−κ)
log(k)
1

if κ < 1,
if κ = 1,
if κ > 1.

≤ c


Proof. For this choice of αk, it is easy to see that γ−1
α−1
j γ−κ

j ≤ cjs−(s+1)κ which implies that Pk

j=1 α−1
j ≤ c log(k) if κ = 1.

k ≤ ck−(s+1). Then
j ≤ ck(s+1)(1−κ) if κ 6= 1
If κ ≤ 1 then the term

j=1 α−1

j γ−κ

j γ−κ

is dominating the error estimate, while for κ > 1 this term tends

and otherwise Pk
Pk

j=1 α−1

j γ−κ

to zero.

j

This yields

ku† − ukk2 ≤ c γ−1

k 
1 +

α−1
j γ−κ

j 


k

Xj=1

19

≤ c k−(s+1)sk

with

k(s+1)(1−κ)
log(k)
1

if κ < 1,
if κ = 1,
if κ > 1.

sk :=


j=1 α−1

Using Pk

min

j=1,...,k

j γj ≥ ck2(s+1) andPk
L1(A) ≤ c
Xj=1


ku† − ujk1+ 1

k

κ

≤ ck−2(s+1)sk

j=1 α−2

j ≥ ck2s+1, we obtain the estimates

α−1

−1
j γj
1 +


k

Xj=1

j γ−κ
α−1

j 


and

min

j=1,...,k

kS(u† − uj)k2

k

Y ≤ c
Xj=1


α−2

−1
j 
1 +


≤ ck−(2s+1)sk.

k

Xj=1

α−1
j γ−κ

j 


Similar we obtain with Corollary 4.14

kγ−1

k λk − p†k2

Y ≤ cγ−2

k 
1 +

k

Xj=1

α−1
j γ−κ

j 


≤ ck−2(s+1)sk.

Combining these 4 inequalities yields the claim.

Funding

This work was supported by DFG under grant number Wa 3626/1-1.

References

[1] L.M. Bregman. The relaxation method of ﬁnding the common point of
convex sets and its application to the solution of problems in convex pro-
gramming. Ussr Computational Mathematics and Mathematical Physics,
7:200–217, 1967.

[2] M. Burger, E. Resmerita, and L. He. Error estimation for Bregman iter-
ations and inverse scale space methods in image restoration. Computing,
81(2-3):109–135, 2007.

[3] Heinz W. Engl, Martin Hanke, and Andreas Neubauer. Regularization of
inverse problems, volume 375 of Mathematics and its Applications. Kluwer
Academic Publishers Group, Dordrecht, 1996.

20

[4] Osman G¨uler. On the convergence of the proximal point algorithm for

convex minimization. SIAM J. Control Optim., 29(2):403–419, 1991.

[5] M. Hanke and C. W. Groetsch. Nonstationary iterated Tikhonov regular-

ization. J. Optim. Theory Appl., 98(1):37–53, 1998.

[6] Alexander Kaplan and Rainer Tichatschke. Stable methods for ill-posed
variational problems, volume 3 of Mathematical Topics. Akademie Verlag,
Berlin, 1994. Prox-regularization of elliptic variational inequalities and
semi-inﬁnite problems.

[7] B. Martinet. Br`eve communication. r´egularisation d’in´equations varia-
tionnelles par approximations successives. ESAIM: Mathematical Mod-
elling and Numerical Analysis - Mod´elisation Math´ematique et Analyse
Num´erique, 4(R3):154–158, 1970.

[8] A. Neubauer. Tikhonov-regularization of ill-posed linear operator equations

on closed convex sets. J. Approx. Theory, 53(3):304–320, 1988.

[9] Stanley Osher, Martin Burger, Donald Goldfarb, Jinjun Xu, and Wotao
Yin. An iterative regularization method for total variation-based image
restoration. Multiscale Model. Simul., 4(2):460–489 (electronic), 2005.

[10] Simeon Reich and Shoham Sabach. A strong convergence theorem for a
proximal-type algorithm in reﬂexive Banach spaces. J. Nonlinear Convex
Anal., 10(3):471–485, 2009.

[11] Simeon Reich and Shoham Sabach. Two strong convergence theorems for a
proximal method in reﬂexive Banach spaces. Numer. Funct. Anal. Optim.,
31(1-3):22–44, 2010.

[12] R. Tyrrell Rockafellar. Monotone operators and the proximal point algo-

rithm. SIAM J. Control Optimization, 14(5):877–898, 1976.

[13] S. Rotin. Konvergenz des Proximal-Punkt-Verfahrens f¨ur inkorrekt gestellte
Optimalsteuerprobleme mit partiellen Diﬀerentialgleichungen. PhD thesis,
Universit¨at Trier, 2004.

[14] Martin Seydenschwanz. Convergence results for the discrete regularization
of linear-quadratic control problems with bang-bang solutions. Comput.
Optim. Appl., 61(3):731–760, 2015.

[15] M. V. Solodov and B. F. Svaiter. Forcing strong convergence of proximal
point iterations in a Hilbert space. Math. Program., 87(1, Ser. A):189–202,
2000.

[16] Fredi Tr¨oltzsch. Optimal control of partial diﬀerential equations, volume
112 of Graduate Studies in Mathematics. American Mathematical Society,
Providence, RI, 2010. Theory, methods and applications, Translated from
the 2005 German original by J¨urgen Sprekels.

21

[17] Daniel Wachsmuth. Adaptive regularization and discretization of bang-
bang optimal control problems. Electron. Trans. Numer. Anal., 40:249–267,
2013.

[18] Daniel Wachsmuth and Gerd Wachsmuth. Regularization error estimates
and discrepancy principle for optimal control problems with inequality con-
straints. Control Cybernet., 40(4):1125–1158, 2011.

[19] Gerd Wachsmuth and Daniel Wachsmuth. Convergence and regulariza-
tion results for optimal control problems with sparsity functional. ESAIM
Control Optim. Calc. Var., 17(3):858–886, 2011.

22

