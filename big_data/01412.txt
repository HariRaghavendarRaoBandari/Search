6
1
0
2

 
r
a

M
4

 

 
 
]

C
D
.
s
c
[
 
 

1
v
2
1
4
1
0

.

3
0
6
1
:
v
i
X
r
a

Contextual trace reﬁnement for concurrent objects:

Safety and progress

Brijesh Dongol1 and Lindsay Groves2

1 Department of Computer Science,

Brunel University London, UK
Brijesh.Dongol@brunel.ac.uk

2 School of Engineering and Computer Science, Victoria

University of Wellington, New Zealand

lindsay@ecs.vuw.ac.nz

Abstract. Correctness of concurrent objects is deﬁned in terms of safety properties such as lineariz-
ability, sequential consistency, and quiescent consistency, and progress properties such as wait-, lock-,
and obstruction-freedom. These properties, however, only refer to the behaviours of the object in isola-
tion, which does not tell us what guarantees these correctness conditions on concurrent objects provide
to their client programs. This paper investigates the links between safety and progress properties of con-
current objects and a form of trace reﬁnement for client programs, called contextual trace reﬁnement.
In particular, we show that linearizability together with a minimal notion of progress are suﬃcient
properties of concurrent objects to ensure contextual trace reﬁnement, but sequential consistency and
quiescent consistency are both too weak. Our reasoning is carried out in the action systems framework
with procedure calls, which we extend to cope with non-atomic operations.

1 Introduction

Concurrent objects provide operations that can be executed simultaneously by multiple threads,
and provide a layer of abstraction to programmers by managing thread synchronisation on behalf
of client programs, which in turn improves safety and eﬃciency. Correctness of concurrent objects
is usually deﬁned in terms of the possible histories of invocation and response events generated by
executing the operations of a sequential speciﬁcation object. There are several notions of safety for
concurrent objects [12, 7]: sequential consistency, linearizability, and quiescent consistency being
the most widely used. Similarly, there are many diﬀerent notions of progress [12, 13], e.g., wait-,
lock- and obstruction-freedom are popular non-blocking conditions.

Both safety and progress properties are stated in terms of a concurrent object in isolation, and
disregard their context, i.e., the client programs that use them. Programmers (i.e., client developers)
have therefore relied on informal “folk theorems” to link correctness conditions on concurrent objects
and substitutability of objects within client programs. We seek to provide a formal account of this
relationship, addressing the question: “Provided concurrent object OC is correct with respect to
sequential object OA, how are the behaviours of C[OA] related to those of C[OC ]?”, where C[O ]
denotes a client program C that uses object O , for diﬀerent notions of correctness. One of the ﬁrst
formal answers to this question was given by the abstraction theorems of Filipović et al. [9], who
link safety properties sequential consistency and linearizability to a contextual notion of correctness
called observational reﬁnement, which deﬁnes substitutability with respect to the initial and ﬁnal
state of a system’s execution. For terminating clients, linearizability is shown to be equivalent to
observational reﬁnement, while sequential consistency is shown to be equivalent to observational
reﬁnement provided that clients only communicate via shared concurrent objects.

Since non-termination is common in many concurrent systems, e.g., operating systems and
real-time controllers, our work aims to understand substitutability for potentially non-terminating
clients. Related to this aim is the work of Gotsman and Yang [10] and Liang et al. [15], who link
observational reﬁnement to safety and progress properties of concurrent objects. However, both [10]
and [15] assume that the concurrent objects in question are already linearizable. Furthermore, [10]
aims to understand compositionality of progress properties, while [15] develops characterisations of
progress properties based on the observational guarantees they provide.

The motivation for our work diﬀers from [10, 15] in that we take contextual trace reﬁnement as
the underlying correctness condition when substituting OC for OA in C, then aim to understand the
safety/progress properties on OC that are required to guarantee trace reﬁnement between C[OA]
and C[OC ]. To this end, we develop an action systems framework that integrates and extends exist-
ing work [18, 1] from the literature, building on our preliminary results on this topic [8]. As part of
our contributions we (i) extend Sere and Waldén’s treatment of action systems with procedures [18]
with non-atomic procedures; (ii) develop a theory for contextual trace reﬁnement, adapting Back
and von Wright’s [1] theory for trace reﬁnement of action systems, then reduce system-wide proof
obligations (i.e., properties of the client and object together) to proof obligations on the objects
only; (iii) show that linearizability [14] and minimal progress [13] together are suﬃcient to guarantee
contextual trace reﬁnement; and (iv) show that both sequential consistency and quiescent consis-
tency are too weak for contextual trace reﬁnement, even when client threads only communicate
through the shared object.

2 Concurrent objects and their clients

2.1 Client-object systems

We consider concurrent systems where a client consists of multiple threads which interact with one
or more concurrent objects and shared variables. For example, the following client program consists
of threads 1 and 2 using a shared stack s, and variables x, y and z.

Init x, y, z = 0, 0, 0
Thread 1:

T1: s.push(1);
T2: s.push(2);
T3: s.pop(x);

Thread 2:

U1: s.pop(y);
U2: z := x;

Thread 1 pushes 1 then 2 onto the stack s, then pops the top element of s and stores it in x.
Concurrently, thread 2 pops the top element of s and stores it in y, then reads the value of x and
stores it in z.

The abstract behaviour of a stack is deﬁned in terms of a sequential object, as shown in Fig. 1.
The abstract stack consists of a sequence of elements S together with two operations push and
pop (‘h’ and ‘i’ delimit sequences, ‘h i’ denotes the empty sequence, and ‘a’ denotes sequence
concatenation). Note that when the stack is empty, pop returns a special value empty that cannot
be pushed onto the stack.

If concurrent objects are implemented using ﬁne-grained concurrency, the call statements in their
clients are not necessarily atomic because they may invoke non-atomic operations. Furthermore,
depending on the implementation of s, we will get diﬀerent traces of the client program because
the eﬀects of the concurrent operations on s may take eﬀect in diﬀerent orders. For example,
Fig. 2 presents a simpliﬁed version of a non-blocking stack example due to Treiber [19]. In this
implementation, each line of the push and pop corresponds to a single atomic step, except H1,

2

Init: S = h i

push(v) ==
atomic { S := hviaS }
pop ==
atomic {

if S = h i
then return empty
else

lv := head(S);
S := tail(S);
return lv }

Init: Head = null

push(v) ==
H1: n := new(Node);
H2: n.val := v;

repeat

ss := Head;
n.next := ss;

H3:
H4:
H5: until

CAS(Head,ss,n)

H6: return

pop ==

repeat

P1: ss := Head;
P2: if ss = null
P3: then return empty

else

ssn := ss.next;
lv := ss.val

P4:
P5:
P6: until

CAS(Head,ss,ssn);

P7: return lv

Fig. 1. Abstract stack

Fig. 2. The Treiber stack

which may be regarded as being atomic because a thread can signal to other threads that a node
has been taken in a single atomic step. Synchronisation of push and pop operations is achieved
using a compare-and-swap (CAS) instruction, which takes as input a (shared) variable gv, an expected
value lv and a new value nv:

CAS(gv, lv, nv) b= atomic { if (gv = lv) then gv := nv ; return true

else return false }

With this stack implementation, the executions of, say T1 and U1, in the above client may
overlap, and diﬀerent behaviours may be observed according to the order in which steps of the
diﬀerent threads are executed. Treiber’s stack is linearizable with respect to the abstract stack in
Fig. 1, so the eﬀect of each operation call takes place between its invocation and its response. If
a diﬀerent stack implementation is used which satisﬁes a more permissive correctness condition,
such as sequential consistency or quiescent consistency [12], a wider range of behaviours may be
observed.

2.2 Observability and contextual trace reﬁnement

With an example client-object system in place, we return to the main question for this paper: What
guarantees do correctness conditions on concurrent objects provide to clients that use the objects?
Furthermore, how can one address divergence, termination and reactivity of a client? To address
these, we ﬁrst pin down the aspects of the system being developed that are visible to an external
observer. Following Filipović et al. [9], we take the state of the client variables to be observable, and
the state of the objects they use to be unobservable. Therefore, for the client program in Section 2.1,
variables x, y and z are observable, but none of the variables of the stack implementation s are
observable. This allows us to reason about a client with respect to diﬀerent implementations of
s. Second, we deﬁne when a system may be observed. Unlike Filipović et al. [9] who only observe
the state at the beginning and end of a client’s execution, we assume that the states throughout a
client’s execution are visible. This allows us to accommodate, for example, reactive clients, which
interact with an observer in some way even if they are potentially non-terminating.

Therefore, our notion of correctness for the combined system will be a form of observational
reﬁnement that holds iﬀ every (observable) trace of a client using a concurrent object is equivalent
to some (observable) trace of the same client using the corresponding abstract speciﬁcation of the
object. The end result is that from the perspective of a client program, it will be impossible to tell
whether it is using the concurrent object, or its abstract (sequential) speciﬁcation.

3

Example 1. Let D denote the client program in Section 2.1, TS denote the Treiber stack in Fig. 2,
and AS denote the abstract stack in Fig. 1. Suppose s in D is an instance of TS . Then the following
is a possible observable trace of D[TS ]:
tr b= h(x , y, z ) 7→ (0, 0, 0), (x , y, z ) 7→ (0, 1, 0), (x , y, z ) 7→ (2, 1, 0), (x , y, z ) 7→ (2, 1, 1)i
where (x , y, z ) 7→ (0, 0, 0) is shorthand for the state {x 7→ 0, y 7→ 0, z 7→ 0}, and we ignore stuttering.
Trace tr is obtained by initialising as speciﬁed by Init, then executing T1, T2, U1, T3, then U2 to
completion; i.e. they each execute their operation call without interruption. It is straightforward to
see that tr can also be generated by D[AS ], i.e., when using the abstract stack for s. Thus tr can
be accepted as being correct. Executions can, of course, be much more complicated than tr — TS
consists of non-atomic operations, hence, executions of T1, T2 or T3 may overlap with U1 or U2. 2

We say that TS contextually trace reﬁnes AS with respect to the client program C iﬀ every
trace of C[TS ] is a possible trace of C[AS ]. In this paper, we wish to know whether contextual
reﬁnement holds for every client program. To this end, we say TS contextually trace reﬁnes AS iﬀ
TS contextually trace reﬁnes AS with respect to every client program C.

2.3 Correctness conditions on concurrent objects

There are many notions of correctness for concurrent objects, and these are deﬁned in terms of
histories of invocation and response events corresponding to operation calls on the object [12].

Concurrent histories may consist of both overlapping and non-overlapping operation calls, in-
ducing a partial order on events. Safety properties deﬁne how, if at all, this partial order is preserved
by the corresponding abstract histories generated by the corresponding sequential object [12, 7]. We
will consider three diﬀerent safety properties. Sequential consistency is a simple condition requiring
the order of operation calls in a concrete history for a single process to be preserved. Operation
calls performed by diﬀerent processes may be reordered in the abstract history even if the operation
calls do not overlap in the concrete history. Linearizability strengthens sequential consistency by
requiring the order of non-overlapping operations to be preserved. Operation calls that overlap in
the concrete history may be reordered when mapping to an abstract history. Quiescent consistency
is weaker than linearizability, but is incomparable to sequential consistency. A concurrent object is
said to be quiescent at some point in its history if none of its operations are executing at that point.
Quiescent consistency requires the order of operation calls that are separated by a quiescent point
to be preserved. Operation calls that are not separated by a quiescent point may be reordered,
including operations performed by the same process.

Progress conditions on concurrent objects are necessary to ensure that clients will eventually
be able to continue execution after calling operations on the objects they use. We consider a notion
of progress called minimal progress [13], which guarantees that after some ﬁnite number of steps,
some operation of the concurrent object terminates.

3 Modelling client-object systems

Our formal framework for reasoning about contextual trace reﬁnement is based on existing work
on action systems with procedures [18], extended to cope with potentially non-atomic operations.
We let Var and Val denote the types of variables and values, respectively. A state is a function
ΣV b= V → Val, where V ⊆ Var , and a predicate of type K is of type PK b= K → B, e.g., a state
predicate over V is of type PΣV .

4

The abstract syntax of an action system is of the form:

A : : = |[ varu L; varo G; proc ph1 = P1 . . . proc phn = Pn ; I ; do A od ]|

where L ⊆ Var is a set of unobservable variables and G ⊆ Var a set of observable variables
such that L ∩ G = ∅; each phi = Pi is a (non-recursive) procedure declaration; I is an action
modelling initialisation; and A is the main action. Within each phi = Pi , Pi is an action and phi
is a procedure heading pi (val v , res x ) with procedure name pi and optional call-by-value and
call-by-result parameters v and x . Procedure declarations may additionally be parameterised by
thread identiﬁers.

The abstract syntax of actions is of the form:

A : : = var x | rav x | skip | x :∈ E | x : = e | p(e, x ) | A1; A2 | b → A | A1 ⊓ A2

where x is a variable, E is a set-valued expression, e is an expression, p is a procedure name and
b is a predicate. Actions var x and rav x introduce and remove variable x from the state space,
respectively, skip is an action that leaves the state unchanged, x :∈ E denotes non-deterministic
assignment, x : = e denotes assignment, p(e, x ) is a procedure call with value parameter e and
result parameter x , A1; A2 is sequential composition of A1 and A2, b → A is a guarded action, and
A1 ⊓ A2 is (demonic) choice between A1 and A2.

The meaning of parameterless procedures is given by syntactically replacing each procedure call
p in A by the procedure body, P . Procedure parameters are handled by introducing new local
variables with the same name; for call-by-value, the new variable is initialised with the value of the
actual parameter, while for call-by-results, the ﬁnal value is copied to the variable passed as the
parameter. This can be seen in Examples 2 and 3 below.

Example 2. Consider again the client program D from Section 2.1 and suppose it uses the abstract
stack object AS in Fig. 1. The action system modelling the client-object system is D[AS ], which
is given below. The shared stack is a sequence modelled by an unobservable variable S . The client
uses variables x , y and z , and unobservable program counters pc1 and pc2 are used to model control
ﬂow. Note that all client variables are assumed to be observable, but none of the object’s varaibles
are observable. We assume npct (k ) is an action that sets pct to k when the procedure being called
has terminated. There are many possible ways to detect termination of the procedure being called,
e.g., by checking whether a program counter for the procedure has been declared in the current
state (see Example 3 below).

|[ varu S , pc1, pc2; varo x , y, z ;

proc pusht (val in) = S : = hini a S
proc popt (res out) = S = h i ∧ ¬dec(ret) → var ret; ret : = empty

⊓ S 6= h i ∧ ¬dec(ret) → var ret; ret , S : = head .S , tail .S
⊓ dec(ret) → out : = ret; rav ret ;

S , pc1, pc2 : = h i, T 1, U 1; x , y, z : = 0, 0, 0;
do pc1 = T 1 → push1(1); npc1(T 2)
⊓ pc1 = T 2 → push1(2); npc1(T 3)
⊓ pc1 = T 3 → pop1(x ); npc1(⊥)

⊓ pc2 = U 1 → pop2(y); npc2(U 2)
⊓ pc2 = U 2 → z , pc2 : = x , ⊥

od ]|

Note that because (A1 ⊓ A2); A = (A1; A) ⊓ (A2; A) holds, and b1 → (b2 → S ) = b1 ∧ b2 → S
and b → (A1 ⊓ A2) = (b → A1) ⊓ (b → A2), expanding the action corresponding to U 1 results in
the action

pc2 = U 1 ∧ S = h i → out : = empty; npc2(U 2)

⊓ pc2 = U 1 ∧ S 6= h i → out , S : = head .S , tail .S ; npc2(U 2)

5

Example 3. The pusht operation of the Treiber stack (invoked by thread t) is deﬁned as follows,
where dec(v ) b= λ σ • v ∈ dom σ holds iﬀ v is declared in the domain of the given state and
newNode.n b= n :∈ Nodes ; Nodes : = Nodes\{n} assigns n to be a new node from the available
set of nodes Nodes. For simplicity, we assume Nodes is an inﬁnite set (e.g., the natural numbers),
so a new node is always available. Further note that the object’s program counter is bpc t , which is
distinguished from the client’s program counter pct . Thus we have:

2

proc pusht (val in) = ¬ dec( bpc t ) → var bpc t , vt , nt , sst ; vt : = in

...

⊓ bpc t = H 1 → newNode.nt ; bpc t : = H 2
⊓ bpc t = H 6 → rav bpc t , vt , nt , sst

The pop operation is similar, except that it additionally sets the output variable to the returned
value.

proc popt (res out) = ¬ dec( bpc t ) → var bpc t , sst , ssnt , lvt

...

⊓ bpc t = P 7 → out : = lvt ; rav bpc t , sst , ssnt , lvt

The action system resulting from using the Treiber stack (which we will refer to as TS ) as the
shared concurrent object in Section 2.1 is D[TS ]. It is similar to the action system in Example 2,
except that the unobservable variables are Nodes (the set of all available nodes), Head (a pointer
to a node, or null), val (a partial function of type Nodes
7→ Val), next (a partial function of
type Nodes → Node); the procedure declarations above are used; and initialisation of the object is
Nodes, Head , val , next : = N, null , ∅, ∅.

2

We now make the concept of an object and the notation C[O ] for an object O and client C more
precise. An object is a triple O b= (L, {ph1,t = P1,t , . . . , phn,t = Pn,t }, I ), where L is a set of variables,
{ph1,t = P1,t , . . . , phn,t = Pn,t } is a set of (potentially parameterised) procedure declarations, and
I is an initialisation action. A client is a triple C b= (G, A, J ), where G is a set of variables, and A
and I are the main and initialisation actions, respectively. Then C[O ] is the action system

|[ varu L; varo G; proc ph1,t = P1,t . . . proc phn,t = Pn,t ; I ; J ; do A od ]|.

4 Contextual trace reﬁnement

We now give the semantics for action systems and deﬁne contextual trace reﬁnement, which extends
the existing theory on trace reﬁnement [1]. Note that we only use part of the action systems
framework, foregoing generality in favour of a subset of the theory adequate for handling with
contextual trace reﬁnement. In particular, to develop a more direct link to trace reﬁnement, we
only give a relational semantics for actions, as opposed to the usual predicate transformer semantics.
We assume expressions are functions from states to values. A relation is of type R(K , K ′) b=
K → PK ′, thus a state relation is of type R(ΣV , ΣV ′), where V , V ′ ⊆ Var . Assume r , r1 and r2
are state relations, b is a predicate and S is a set. We let:

– (r1 ◦ r2).γ.γ ′ b= ∃ γ ′′ • r1.γ.γ ′′ ∧ r2.γ ′′.γ ′ denote relational composition,
– (b ⊳ r ).γ.γ ′ b= b.γ ∧ r .γ.γ ′ denote domain restriction, and
– S −⊳ r = {(γ, γ ′) ∈ r | γ 6∈ S } denote domain anti-restriction.

6

For a function f , we let f ⊕ {x 7→ v } b= λ z ∈ dom f • if z = x then v else f .z denote functional
overriding.

Deﬁnition 1. The (relational) semantics of an action A is given by rel .A:

rel .(var x ) b= λ σ • λ σ′ • ({x } −⊳ σ′) = σ ∧ dec(x ).σ′
rel .(rav x ) b= λ σ • λ σ′ • ({x } −⊳ σ) = σ′
rel .(x : = e) b= λ σ • λ σ′ • σ′ = σ ⊕ {x 7→ e.σ}
rel .(x :∈ E ) b= λ σ • λ σ′ • ∃ k : E .σ • σ′ = σ ⊕ {x 7→ k }
Recall that the semantics of a procedure call is given by substitution as described in Section 3.
We let grd .A.γ b= γ ∈ dom(rel .A) denote the guard of A. Because an action system is a loop
with a non-deterministic choice over actions, we frequently use iteration in our reasoning. Formally,
ﬁnite iteration of relation r (denoted r ∗) is deﬁned as follows:

rel .(b → A1) b= b ⊳ rel .A1
rel .(A1; A2) b= rel .A1 ◦ rel .A2
rel .(A1 ⊓ A2) b= rel .A1 ∨ rel .A2

rel .skip b= id

r 0 b= id

r k +1 b= r ◦ r k

r ∗ b= ∃ k ∈ N • r k

The semantics of an iterated action is deﬁned by lifting from iteration deﬁned on relations, namely,
rel .A∗ b= (rel .A)∗. We say an iterated execution of A terminates from state γ iﬀ term.A.γ b= ∃ k •
∀ γ ′ • (rel .A)k .γ.γ ′ ⇒ ¬grd .A.γ ′. Note that ¬grd .A.γ ⇒ term.A.γ holds for all actions A and states
γ.

We use seq X to denote (possibly inﬁnite) sequences of elements of type X , and assume indices

start from 0.

Deﬁnition 2. A possibly inﬁnite sequence of states s is a trace of action system A iﬀ ∃ σ •
rel .I .σ.(s.0) ∧ ∀ i : dom s\{0} • rel .A.(s.(i − 1)).(s.i ) holds.

2

A trace is complete iﬀ either the trace is of inﬁnite length or the guard of A does not hold in the
last state of the trace. The set of all complete traces of an action system A is denoted JA K.
Traces (Deﬁnition 2) provide a conceptually simple model for a system’s execution, and trace
reﬁnement provides a conceptually simple notion of substitutability [1]. Typically, because a con-
crete system is more ﬁne-grained than the abstract, one must remove stuttering from a trace, i.e.,
consecutive states that leave the observable state unchanged. An action system may also exhibit
inﬁnite stuttering by generating a trace that ends with an inﬁnite sequence of consecutive stuttering
steps. After inﬁnite stuttering, one will never be able to observe any state changes, and hence, we
treat inﬁnite stuttering as divergence, which is denoted by a special symbol ‘↑ 6∈ Σ’. For any trace
s ∈ JA K, we deﬁne Tr .s to be the non-stuttering observable sequence of states, possibly followed
by ↑, which is obtained from s as follows. First, we obtain a sequence s ′ by removing all ﬁnite
stuttering in s and replacing any inﬁnite stuttering in s by ↑. Second, for each i ∈ dom s ′, we let
(Tr .s).i = if s ′.i 6= ↑ then L −⊳ s ′.i else ↑. It is straightforward to deﬁne functions that formalise
the steps and above (see for example [6]).

Deﬁnition 3. We say abstract action system A is trace reﬁned by concrete action system C
(denoted A ⊑ C ) iﬀ ∀ s ′ ∈ JCK • ∃ s ∈ JA K • Tr .s = Tr .s ′ holds.
Back and von Wright have developed simulation rules (details elided due to lack of space) for
verifying trace reﬁnement of action systems [1], which we adapt to reason about client-object
systems in Lemmas 1 and 2. First, we formalise the meaning of contextual trace reﬁnement. The
notion is similar to the notion of data reﬁnement given by He et al. [11, 3], but extended to traces,
which enables one to cope with non-terminating reactive systems.

2

7

Deﬁnition 4. An abstract object OA is contextually trace reﬁned by a concrete object OC , denoted
OA b⊑ OC , iﬀ for any client C we have C[OA] ⊑ C[OC ].

2

In this paper, for simplicity, we assume that (atomic) actions do not abort [3], therefore the
proof obligations for aborting actions do not appear in Lemmas 1 and 2 below – it is straightforward
to extend our results to take aborting behaviour into account. However, like Back and von Wright
[1], our notion of reﬁnement ensures total correctness of the systems we develop, i.e., the concrete
system may only deadlock (or diverge) if the abstract system deadlocks (or diverges). Thus, in
addition to the standard step correspondence proof obligations for ensuring safety of the concrete
system, we include Back and von Wright’s proof obligations that ensure progress.

Because the entire state of the client is observable, the proof obligations pertaining to the client
can be trivially discharged, leaving one with proof obligations that only refer to the object. For
procedure declarations P b= {ph1,t = P1,t , . . . , phn,t = Pn,t }, we let

act .P b= dv ,x ,t p1,t (v , x ) ⊓ · · · ⊓ pn,t (v , x )

denote the action corresponding to the potential procedure calls in P , then deﬁne the following
action, where ttt is assumed to be a fresh variable for all threads t.

rem.P b= dv ,x ,t ¬dec( bpc t ) → (p1,t (v , x ) ⊓ · · · ⊓ pn,t (v , x ))
The guard ¬dec( bpc t ) is used to detect whether the procedure being executed by thread t has
terminated. Upon termination of procedure pi ,t for some 1 6 i 6 n, ¬dec( bpc t ) will hold. The
intention is to use rem.P in (4) below, which attempts to execute the remaining steps of the
operation invoked by thread t to completion.

Lemma 1 (Forward simulation). Suppose OA = (LA, PA, IA) and OC = (LC , PC , IC ) are
objects. Then OA b⊑ OC if there exists a relation R and the following hold for any states σ, τ
and τ ′:

rel .IC .τ ′ ⇒ ∃ σ • R.σ.τ ′ ∧ rel .IA.σ

R.σ.τ ∧ rel .(act .PC ).τ.τ ′ ⇒ ∃ σ′ • R.σ′.τ ′ ∧ rel .(act .PA)∗.σ.σ′
R.σ.τ ∧ ¬grd .(act .PC ).τ ⇒ ¬grd .(act .PA).σ
τ ′ = (τ ⊕ St :T {ttt 7→ false}) ⇒ term.(rem.PC ).τ ′

(1)

(2)

(3)

(4)

The ﬁrst three proof obligations are straightforward. Proof obligation (4) requires that the main
action of the concrete object OC terminates if threads do not invoke new operations after the
operation currently being executed has terminated. Note that (4) does not rule out inﬁnite stuttering
within the program C[OC ], but it does ensure that any inﬁnite stuttering is caused by the client as
opposed to the object OC , and hence, this inﬁnite stuttering must also be present within C[OA].
Therefore, if (4) holds, so does Back and von Wright’s non-termination condition.

Dually to forward simulation, there exists a method of backward simulation, which requires
that the abstract action system under consideration is continuous. An action system A with main
action A is continuous iﬀ for all σ, the set {σ′ | rel .A.σ.σ′} is ﬁnite, i.e., A does not exhibit inﬁnite
non-determinism.

Lemma 2 (Backward simulation). Suppose OA = (LA, PA, IA) and OC = (LC , PC , IC ) are
objects and C is a client such that C[OA] is continuous. Then C[OA] ⊑ C[OC ] holds if there exists
a total relation R and for any states σ′ and τ, τ ′ (4) holds and each of the following hold:

8

rel .IC .τ ′ ∧ R.σ′.τ ′ ⇒ rel .IA.σ′

rel .(act .PC ).τ.τ ′ ∧ R.σ′.τ ′ ⇒ ∃ σ • R.σ.τ ∧ rel .(act .PA)∗.σ.σ′

¬grd .(act .PC ).τ ⇒ ∃ σ • R.σ.τ ∧ ¬grd .(act .PA).σ

(5)

(6)

(7)

Lemmas 1 and 2 reduce the proof obligations for trace reﬁnement of client-object systems to the
level of objects only. This provides us with the opportunity to explore properties of objects in
isolation to guarantee contextual trace reﬁnement.

5 Events and histories

This section provides background for deﬁning safety (e.g., linearizability) and progress (e.g., lock-
freedom) properties of concurrent objects [12]. We deﬁne both types of properties in terms of
histories of invocation and response events [14, 12] that record the externally visible interaction
between a client and the object it uses. The type of an event is Event, which is deﬁned as follows [4]:

Event

: : = inv hhN × Op × (Val ∪ {⊥})ii | rethhN × Op × (Val ∪ {⊥})ii

The components of each event are the thread identiﬁer, the operation name and input/output
values. We use ⊥ 6∈ Val to denote an invocation (return) event that has no input (output). Thus,
for example, inv (1, push, 2) denotes an push invocation by thread 1 with value 2, and ret(1, push, ⊥)
denotes a return from this invocation.

The history of an object is a (potentially inﬁnite) sequence of events, i.e., History b= seq Event.
A history of an object is generated by an execution of a most-general client for the object [5]. We
formalise the concept of a most general client in our framework in Deﬁnition 5 below, but ﬁrst we
describe how invocations and responses are recorded in a history. For an object O b= (L, {ph1,t =
P1,t , . . . , phn,t = Pn,t }, I ) assuming H 6∈ L is a history variable, we let P H
i ,t be the history-extended
action derived from Pi ,t by additionally recording invocation and response events in H (also see [4]).
Example 4. The history-extended action for pusht from Example 2 is:

H : = H a hinv (t , push, in)i; S : = hini a S ; H : = H a hret(t , push, ⊥)i

while the history-extended version of pusht procedure from Example 3 is:

...

¬ dec( bpc t ) → var bpc t , vt , nt , sst ; vt : = in; H : = H a hinv (t , push, in)i
⊓ bpc t = H 6 → H : = H a hret(t , push, ⊥)i; rav bpc t , vt , nt , sst

2

Deﬁnition 5. The most general client of O is the action system below, where H 6∈ L is its history
and tt 6∈ L is a fresh variable that models termination.

M[O ] b= |[ varu L ∪ {H , tt}; varo ∅;

n,t ;

proc ph1,t = P H
1,t
I ; H , tt : = h i, false ;
do ¬tt → dv ,x ,t p1t (v , x ) ⊓ · · · ⊓ pNt (v , x ) ⊓ tt : = true od ]|

. . . proc phn,t = P H

Thus, M[O ] includes unobservable variables H (initially h i) and tt (initially false), which model the
history and termination of M[O ], respectively. Provided tt is false, the history-extended procedures
of O are executed, or the system decides to terminate by setting tt to true. The intention of M[O ] is
to model all possible client behaviours, including for instance faults (where a thread stops running)
or a divergence (where a thread repeatedly executes the same operation).

Deﬁnition 6. The set of histories of an object O is given by

{h ∈ seq Event | ∃ s:JM[O ]K • ∃ i : dom s • h = (s.i ).H }.

9

6 Contextual trace reﬁnement: Progress

The progress condition we will consider is minimal progress, which guarantees system-wide progress,
even though there may be individual threads that may not make progress [13]. To formalise minimal
progress, we say event e1 matches e2 iﬀ matches(e1, e2) b= ∃ t , o, u, v • e1 = inv (t , o, u) ∧ e2 =
ret(t , o, v ) holds, i.e., e1 is an invocation of an operation by a thread and e2 is the corresponding
return. We say m ∈ dom h is a pending invocation iﬀ pi (m, h) b= ∀ n ∈ dom h • m < n ⇒
¬matches(h.m, h.n) holds.
An object O satisﬁes minimal progress iﬀ for every trace tr of the M[O ], it is always the case
that in the future, either M[O ] terminates, or there is some pending operation invocation that
completes and returns.
Deﬁnition 7. An object O satisﬁes minimal progress iﬀ for every s ∈ JM[O ]K and i ∈ dom s,
there exists a j ∈ dom s such that i 6 j and

(s.j ).tt ∨ ∃ m • pi (m, (s.j ).H ) ∧ ¬pi (m, (s.(j + 1)).H )

That is, for any trace s of M[O ] and index i ∈ dom s there is a state s.j (where j > i ) from
which some pending operation in s.j completes. There are a variety of objects that satisfy mini-
mal progress, e.g., wait-, lock-free objects under any scheduler, and obstruction-free objects under
isolating schedulers (see [13] for details). Objects that do not satisfy minimal progress include
obstruction free implementations that are executed using a weakly fair scheduler.

The lemma below states that any object that satisﬁes minimal progress does not suﬀer from

deadlock, and is guaranteed to terminate if no additional operations are invoked.
Lemma 3. If O = (L, P , I ) satisﬁes minimal progress, then for any γ ∈ JM[O ]K and i ∈ dom γ,
both grd .(act .P ).(γ.i ) and condition (4) hold.

Using Lemma 3, we simplify and combine Lemmas 1 and 2. In particular, we are left with the proof
obligations for safety only as in the theorem below.

Theorem 1. Suppose OA = (LA, PA, IA) and OC = (LC , PC , IC ) are objects, OC satisﬁes mini-
mal progress, and R ∈ R(ΣLA, ΣLC ). Then
1. OA b⊑ OC if both (1) and (2) hold, and
2. for any client C such that C[OA] is continuous, C[OA] ⊑ C[OC ] holds if R is total and both (5)

and (6) hold.

7 Safety and contextual trace reﬁnement

We give the formal deﬁnition of safety properties using the nomenclature in [7] and [4]. We say
m, n ∈ dom h form a matching pair in h iﬀ mp(m, n, h) holds, where mp(m, n, h) b= m < n ∧
matches(h.m, h.n) ∧ ∀ i • m < i < n ⇒ π1.(h.i ) 6= π1.(h.m) and πi is the projection function
returning the i th element of the given tuple.

Following [7], safety properties are deﬁned in terms of a history h and a mapping function f
between indices. The sequential history corresponding to h and f
is obtained using map(h, f ) b=
{f (k ) 7→ h(k ) | k ∈ dom f }. Diﬀerent safety properties are deﬁned by placing diﬀerent types of
restrictions on f . The most basic restriction is validity of a mapping. We say a function f is a valid
mapping function if, for any history h, (a) the domain of f is contained in the domain of h, (b)

10

the range of f is a consecutive sequence starting from 0, (c) f only maps matching pairs in h, and
(d) matching pairs in h are mapped to consecutive events in the target abstract history. Assuming
[m, n] is the set of integers from m to n inclusive, we formalise validity for mapping functions using
VMF (h, f ), where

VMF (h, f ) b= dom f ⊆ dom h ∧ (∃ n: N • ran f = [0, n − 1]) ∧ injective(f ) ∧
(∀ m, n: dom h • mp(m, n, h) ⇒ (m ∈ dom f ⇔ n ∈ dom f )) ∧
(∀ m, n: dom f • mp(m, n, h) ⇒ f .n = f .m + 1)

When formalising correctness conditions, one must also consider incomplete histories, which
have pending operation invocations that may or may not have taken eﬀect. To cope with these,
like Herlihy and Wing [14], we use history extensions, which are constructed from a history h by
concatenating a sequence of returns corresponding to some of the pending invocations of h.

Deﬁnition 8. A concurrent object OC implementing an abstract object OA is correct with respect
to a correctness condition Z , denoted OC |=OA Z , iﬀ for any history h of OC , there exists an
extension he of h, a valid mapping function f such that Z (he, f ) holds and map(he, f ) is a history
of OA.

2

7.1 Linearizability

We now show that linearizability is a suﬃcient safety condition for discharging the remaining proof
obligations in Theorem 1. Linearizability is a total condition, which means that all completed (i.e.,
returned) operation calls in a given history h must be mapped by f .3 In addition, it must satisfy
an order condition lin, which states that the return of an operation may not be reordered with
an invocation that occurs after it. For an event e, we use inv ?(e) b= ∃ t , o, v • e = inv (t , o, v ) to
determine whether e is an invocation event and ret?(e) b= ∃ t , o, v • e = ret(t , o, v ) to determine
whether e is an response event event.

total(h, f ) b= ∀ m: dom h • ¬pi (m, h) ⇒ m ∈ dom f
lin(h, f ) b= ∀ m, n: dom f • m < n ∧ ret?(h.m) ∧ inv ?(h.n) ⇒ f .m < f .n

Deﬁnition 9. An object OC is linearizable with respect to OA iﬀ OC |=OA lin ∧ total.

First, we show contextual trace reﬁnement for canonical implementation [16, 2, 17], which splits
each sequential abstract operation call into three actions: an invocation, a eﬀect action and a
response.

Deﬁnition 10. For an abstract procedure pt (val in, res out) = Pt , the canonical implementation
of the procedure is:

P ξ
t b= ¬dec(pct ) → var pct ; pct : = 1; H a hinv (t , p, in)i

⊓ pct = 1 → pt (in, out); pct : = 2
⊓ pct = 2 → rav pct ; H a hret(t , p, out)i

Invocation and response actions modify the auxiliary history variable by recording the corre-
sponding event, while the eﬀect action has the same eﬀect as the abstract operation call. Unlike
the abstract object, the histories of a canonical implementation are potentially concurrent.

Theorem 2 (Canonical contextual trace reﬁnement). Suppose OA and OB are objects, where
OB is a canonical implementation of OA. Then OA b⊑ OB .
3 This is in contrast to partial conditions deﬁned for relaxed memory (see [7] for details).

11

Proof. We use Lemma 1 because OB may not satisfy minimal progress. Here, rel .act .OB trivially
satisﬁes (4) because by nature each procedure of a canonical object terminates. The proof of (3)
requires further consideration because rel .act .OB may deadlock. For example, OB may be a stack
with a pop operation that blocks when the stack is empty. In such cases, because no data reﬁnement
is performed, the guard of the canonical object is false when the guard of the abstract object is
false, allowing one to discharge (3). The remaining proof obligations are straightforward.

2

Next, we restate a result by Schellhorn et al. [17], who have shown completeness of backward
simulation for verifying linearizability. In particular, provided OC is a linearizable implementation
of OA, they show that it is always possible to construct a backward simulation relation between
the OC and the canonical implementation of OA.

Lemma 4 (Completeness of backward simulation [17]). Suppose OA, OB and OC are objects
and M[OA] is continuous. If OC |=OA lin ∧ total and OB is a canonical implementation of OA,
then there exists a total relation R such that both (5) and (6) hold between M[OB ] and M[OC ].

Finally, we prove our main result for linearizability, i.e., that linearizability and minimal progress

together preserves contextual trace reﬁnement.

Theorem 3. Suppose object OC is linearizable with respect to OA, OC satisﬁes minimal progress,
and M[OA] is continuous. If C is a client such that C[OA] is continuous then C[OA] ⊑ C[OC ].

Proof. Construct a canonical implementation OB of OA. By transitivity of ⊑, the proof holds if
both (a) C[OA] ⊑ C[OB ] and (b) C[OB ] ⊑ C[OC ]. Condition (a) holds by Theorem 2, and (b) holds
by Theorem 1 (part 2), followed by Lemma 4. Application of Theorem 1 (part 2) is allowed because
if C[OA] is continuous then C[OB ] is continuous, whereas application of Lemma 4 is allowed because
if R satisﬁes (5) and (6) for M[OB ] and M[OC ], then R also satisﬁes (5) and (6) for C[OB ] and
C[OC ].

2

7.2 Sequential and quiescent consistency

We now consider contextual trace reﬁnement for concurrent objects that satisfy sequential consis-
tency and quiescent consistency, both of which are weaker than linearizability. Both conditions are
total [7]. Additionally, sequential consistency disallows reordering of operation calls within a thread
(see sc below), while quiescent consistency (see qc below) disallows reordering across a quiescent
point (deﬁned by qp below).

sc(h, f ) b= ∀ m, n: dom f • m < n ∧ π1.(h.m) = π1.(h.n) ∧
qp(m, h) b= ∀ n: dom h • (n ≤ m ⇒ ¬pi (n, h[0..m]))
qc(h, f ) b= ∀ m, k , n: dom f • m < k < n ∧ qp(k , h) ⇒ f .m < f .n

ret?(h.m) ∧ inv ?(h.n) ⇒ f .m < f .n

Deﬁnition 11. An object OC is sequentially consistent with respect to OA iﬀ OC |=OA sc ∧ total,
and OC quiescent consistent with respect to OA iﬀ OC |=OA qc ∧ total.

Our results for sequential consistency and quiescent consistency are negative — neither condition
guarantees trace reﬁnement of the underlying clients, regardless of whether the client program in
question is data independent, i.e., the state spaces of the client threads outside the shared object
are pairwise disjoint.

12

Init x, y, z = 0;
Thread 1 ==
T1: s.push(1);
T2: s.push(2);
T3: s.pop(x);

Thread 2 ==
U1: z := 1;
U2: s.pop(y);

Init x, y, z = 0;
Thread 1 ==
T1: s.push(1);
T2: s.push(2);
T3: s.pop(x);
T4: s.pop(y);
T5: s.push(3);

Thread 2 ==
U1: s.pop(z)

Fig. 3. Counter example for contextual trace reﬁne-
ment and sequential consistency

Fig. 4. Counter example for contextual trace reﬁne-
ment and quiescent consistency

Theorem 4. Suppose object OC is sequentially consistent with respect to object OA. Then it is
not necessarily the case that OA b⊑ OC holds.
Proof. Consider the program in Fig. 3, where the client threads are data independent — x is local
to thread 1, while y and z are local to thread 2 — and s is assumed to be sequentially consistent.
Suppose thread 1 is executed to completion, and then thread 2 is executed to completion. Because
s is sequentially consistent, the ﬁrst pop (at T3) may set x to 1, the second (at U2) may set y to 2.
This gives the execution:

h(x , y, z ) 7→ (0, 0, 0),

(x , y, z ) 7→ (1, 0, 0),

(x , y, z ) 7→ (1, 0, 1),

(x , y, z ) 7→ (1, 2, 1)i

which cannot be generated when using the abstract stack AS from Fig. 1 for s.

2

Theorem 4 diﬀers from the results of Filipović et al. [9], who show that for data independent
clients, sequential consistency implies observational reﬁnement. In essence, their result holds be-
cause observational reﬁnement only considers the initial and ﬁnal states of a client program — the
intermediate states of a client’s execution are ignored. Thus, internal reorderings due to sequen-
tially consistent objects have no eﬀect when only observing pre/post states. One can develop hiding
conditions so that observational reﬁnement becomes a special case of contextual trace reﬁnement,
allowing one to obtain the result by Filipović et al [9]. Full development of this theory is left for
future work.

We now give our result for quiescent consistency.

Theorem 5. Suppose object OC is quiescent consistent with respect to object OA. Then it is not
necessarily the case that OA b⊑ OC holds.
Proof. Consider the program Fig. 4, where the client threads are data independent — x and y are
local to thread 1, while z is local to thread 2 — and s is a quiescent consistent stack. The concrete
program may generate the following observable trace:

h(x , y, z ) 7→ (0, 0, 0),

(x , y, z ) 7→ (1, 0, 0),

(x , y, z ) 7→ (1, 2, 0),

(x , y, z ) 7→ (1, 2, 3)i

Note that the pop operations at T 3 and T 4 have been reordered, which could happen if the
execution of pop at U 1 overlaps with T 1, T 2, T 3 and T 4. The trace above is not possible when
the client uses the abstract stack AS from Fig. 1.

2

8 Conclusions

In this paper, we have developed a framework, based on action systems with procedures, for studying
the link between the correctness conditions for concurrent objects and contextual trace reﬁnement,
which guarantees substitutability of objects within potentially non-terminating reactive clients.
Thus, we bring together the previously disconnected worlds of correctness for concurrent objects and
trace reﬁnement within action systems. We have shown that linearizability and minimal progress

13

together ensure contextual trace reﬁnement, but sequential consistency and quiescent consistency
are inadequate for guaranteeing contextual trace reﬁnement regardless of whether clients commu-
nicate outside the concurrent object. The sequential consistency result contrasts earlier results for
observational reﬁnement, where sequential consistency is adequate when clients only communicate
through shared objects [9].

We have derived the suﬃcient conditions for contextual trace reﬁnement using the proof obliga-
tions for forwards and backward simulation. However, neither of these conditions have been shown
to be necessary, leaving open the possibility of using weaker correctness conditions on the underly-
ing concurrent objects. Studying this relationship remains part of future work — areas of interest
include the study of how the correctness conditions for safety of concurrent objects under relaxed
memory models [7] can be combined with diﬀerent scheduler implementations for progress (e.g.,
extending [15, 13]) to ensure contextual trace reﬁnement.

Acknowledgements We thank John Derrick and Graeme Smith for helpful discussions. Brijesh
Dongol is supported by EPSRC grant EP/N016661/1 “Veriﬁably correct high-performance concur-
rency libraries for multi-core computing systems”.

References

1. R. J. R. Back and J. von Wright. Trace reﬁnement of action systems.

In CONCUR ’94: Proceedings of the

Concurrency Theory, pages 367–384. Springer-Verlag, 1994.

2. R. Colvin, S. Doherty, and L. Groves. Verifying concurrent data structures by simulation. Electr. Notes Theor.

Comput. Sci., 137(2):93–110, 2005.

3. W. P. de Roever and K. Engelhardt. Data Reﬁnement: Model-oriented proof methods and their comparison.

Cambridge Tracts in Theor. Comp. Sci. Cambridge Univ. Press, 1996.

4. J. Derrick, G. Schellhorn, and H. Wehrheim. Mechanically veriﬁed proof obligations for linearizability. ACM

Trans. Program. Lang. Syst., 33(1):4, 2011.

5. S. Doherty. Modelling and verifying non-blocking algorithms that use dynamically allocated memory. Master’s

thesis, Victoria University of Wellington, 2003.

6. B. Dongol. Progress-based veriﬁcation and derivation of concurrent programs. PhD thesis, The University of

Queensland, 2009.

7. B. Dongol, J. Derrick, G. Smith, and L. Groves. Deﬁning correctness conditions for concurrent objects in multicore

architectures. In J. T. Boyland, editor, ECOOP, volume 37 of LIPIcs, pages 470–494. Dagstuhl, 2015.

8. B. Dongol and L. Groves. Towards linking correctness conditions for concurrent objects and contextual trace

reﬁnement. REFINE workshop, 2015. To appear.

9. I. Filipović, P. W. O’Hearn, N. Rinetzky, and H. Yang. Abstraction for concurrent objects. Theor. Comput. Sci.,

411(51-52):4379–4398, 2010.

10. A. Gotsman and H. Yang. Liveness-preserving atomicity abstraction. In L. Aceto, M. Henzinger, and J. Sgall,

editors, ICALP(2), volume 6756 of LNCS, pages 453–465, 2011.

11. J. He, C. A. R. Hoare, and J. W. Sanders. Data reﬁnement reﬁned. In B. Robinet and R. Wilhelm, editors,

ESOP, volume 213 of LNCS, pages 187–196. Springer, 1986.

12. M. Herlihy and N. Shavit. The Art of Multiprocessor Programming. Morg. Kauf., 2008.
13. M. Herlihy and N. Shavit. On the nature of progress. In A. Fernández Anta, G. Lipari, and M. Roy, editors,

OPODIS, volume 7109 of LNCS, pages 313–328. Springer, 2011.

14. M. P. Herlihy and J. M. Wing. Linearizability: a correctness condition for concurrent objects. ACM Trans.

Program. Lang. Syst., 12(3):463–492, 1990.

15. H. Liang, J. Hoﬀmann, X. Feng, and Z. Shao. Characterizing progress properties of concurrent objects via
contextual reﬁnements. In P. R. D’Argenio and H. C. Melgratti, editors, CONCUR, volume 8052 of LNCS, pages
227–241. Springer, 2013.

16. N. A. Lynch. Distributed Algorithms. Morgan Kaufmann, 1996.
17. G. Schellhorn, J. Derrick, and H. Wehrheim. A sound and complete proof technique for linearizability of concur-

rent data structures. ACM TOCL, 15(4):31:1–31:37, 2014.

14

18. K. Sere and M. A. Waldén. Data reﬁnement of remote procedures. Formal Asp. Comput., 12(4):278–297, 2000.
19. R. K. Treiber. Systems programming: Coping with parallelism. Technical Report RJ 5118, IBM Almaden Res.

Ctr., 1986.

15

