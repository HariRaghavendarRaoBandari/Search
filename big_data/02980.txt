Joint Baseband Signal Quantization and

Transform Coding for High Dynamic Range Video

Chau-Wai Wong, Member, IEEE, Guan-Ming Su, Senior Member, IEEE, and Min Wu, Fellow, IEEE

1

6
1
0
2

 
r
a

 

M
1
1

 
 
]

M
M

.
s
c
[
 
 

2
v
0
8
9
2
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Digitally acquired high dynamic range (HDR) video
baseband signal can take 10 to 12 bits per color channel. It
is of economical importance to be able to reuse the legacy 8
or 10-bit video codecs to efﬁciently compress the HDR video.
Linear or nonlinear mapping on the intensity can be applied
to the baseband signal to reduce the dynamic range before the
signal is sent to the codec, and we refer to this range reduction
step as the baseband quantization. We show analytically and
verify using test sequences that the existence of the baseband
quantizer lowers the coding efﬁciency. Experiment shows that
as the baseband quantizer strengthened by 1.6 bits, the drop
of PSNR at high bitrate is up to 1.60 dB. Our result suggests
that, in order to achieve high coding efﬁciency, video information
reduction in terms of quantization error should be incurred in
the video codec instead of on the baseband signal.

Index Terms—Quantization, High Dynamic Range (HDR),

Bitdepth, Transform Coding, HEVC/H.265

I. INTRODUCTION

The need for more vivid digital videos relies on two main
factors: more pixels, and better pixels [1], [2]. The latter is
more important than the former when nowadays the resolution
goes beyond the high deﬁnition. At the signal level, the need
for better pixels means adopting a wide color gamut (WCG),
and using high dynamic range (HDR) to represent all colors
with small quantization errors [3]–[7].

level

One efﬁcient color coding standard that keeps the visibility
of quantization artifacts to a uniformly small
is the
perceptual quantizer (PQ) [8], [9], but it still takes 12 bits to
represent all luminance levels. It is of economical importance
to be able to reuse the legacy 8 or 10-bit video codecs such as
H.264/AVC [10] and H.265/HEVC [11] to efﬁciently compress
HDR videos. Linear or nonlinear mapping on the intensity can
be applied to the baseband signal to reduce the dynamic range
before the signal is sent to the codec, and we refer to this range
reduction step as the baseband quantization. Even if a codec
supports the dynamic range of a video, range reduction can
also be motivated by the needs of i) saving the running time
of the codec via computing numbers in a smaller range, ii)
handling the event of instantaneous bandwidth shortage as a
coding feature provided in VC-1 [12]–[14], or iii) removing
color precision that cannot be displayed by old screens.

C.-W. Wong and Min Wu are with the Department of Electrical and
Computer Engineering, and the Institute for Advanced Computer Studies,
University of Maryland, College Park, MD 20742, USA. This work was
initiated when C.-W. Wong was a research intern at Dolby Laboratories in
2014. E-mail: (cwwong, minwu)@umd.edu.

G.-M. Su is with Dolby Laboratories, Sunnyvale, CA 94085, USA. E-mail:

guanmingsu@ieee.org.

Manuscript received March 8th, 2016.

Hence, it is important to ask whether reducing bitdepth for
baseband signal is bad for coding efﬁciency measured in HDR.
Practitioners would say “yes”, but if one starts to tackle this
question formally, the answer is not immediately clear as the
change of the rate-distortion (RD) performance is non-trivial:
reducing the bitdepth for baseband signal while maintaining
the compression strength of the codec will lead to a smaller
size of encoded bitstream and a larger error measured in HDR.
We approach this problem by establishing the relationship
between the strength of the baseband quantizer and the coding
efﬁciency measured in (peak) signal-to-noise ratio [(P)SNR]. It
is beneﬁcial to ﬁrst model the problem of quantifying the error
in reconstructed images [15] as the problem of quantifying
the error in reconstructed residues. We then examine the error
of a single quantizer, and arrive at Lemma 2 that serving as
a primitive to facilitate the joint analysis on the effects of
baseband and codec quantizers with a linear transform.

The paper is organized as follows. In Section II, we simplify
the practical HDR video coding pipeline into a theoretically
tractable model before diving into the main derivation in Sec-
tion III-A. Simulation results are presented in Section III-B to
validate the derivation, and experimental results on videos are
presented in Section IV to conﬁrm the theoretical explanation.

II. HDR VIDEO CODING PIPELINE MODELING

A. Quantifying Frame Error by Residue Error

t

t

Block diagram shown in Fig. 1 (a) models the video coding
pipeline with the effect of baseband signal quantization. The
input to the pipeline is the HDR frame at time index t, IHDR
,
with L pixels. The immediate input to the video codec It and
ﬁnal reconstructed output ˆIHDR
are limited by the precision
of the ﬁnite bits container, so pixels take values on the set
q1Z = {nq1|n ∈ Z}. The immediate output pixels from the
codec take integer values due to the rounding operation at
the ﬁnal stage of the codec, and the integer-valued vector
ˆIt−1 is used by intra- and inter-predictors collectively modeled
as pred(·). For simplicity, we deﬁne the quantizer function
Qi(x) = iQi (Qi(x)) before stating the following lemma:
Lemma 1 (frame error by residue error). The problem of
quantifying the error of predictively coded video frames can
be reduced approximately to quantifying the error of non-
predictively coded residues.

The sketch of the proof is described here, the complete proof
is left to Appendix A. We ﬁrst establish the equivalence of the
t −
two pipelines of Figs. 1 (a) and (b), where rHDR
Q1(Jt). Then, the assumption that quantization step of Q1 is

def= IHDR

t

2

Fig. 1: (a) Block diagram for the video coding process with the effect of baseband signal quantization, and (b) equivalent diagram of (a).
Block R is the rounding to the nearest integer operation, round(x). Qi(x) def= round (x/qi) , iQi(x) def= qi · x, i = 1, 2 are quantization and
dequantization, respectively. All operations are applied separately to each entry of x when x is a vector.

0 + y2

where d2 = x2
0 is the squared Euclidean distance to the
geometric center of the region, (0, 0), and 2
3 a2 is related to
the strength of the quantizer. It is straight forward to extend
the result to the N-dimensional (N-d) case shown as follows:
Lemma 2 (quantization error). The mean-squared error for a
point that is uniformly distributed within an N-d hypercube
with an arbitrarily positioned reconstruction centroid and edge
length 2a is d2 + N
3 a2, where d is the Euclidean distance from
the centroid to the geometric center of the hypercube.

This result agrees with two intuitive observations. First, as
the reconstruction centroid departs from the geometric center,
the quantization error increases. Second, as the quantizer
strength quantiﬁed by the edge length 2a increases, the error
increases.

III. EFFECT OF BASEBAND QUANTIZER

ON CODING EFFICIENCY

A. Error of Video Coding With Baseband Quantizer

Lemma 1 allows us in the following analysis to avoid
dealing with the predictive coding loop, and merely to follow
a scheme with transform coding and quantization blocks in
series. In addition, the residue signal that can be more easily
modeled in the probabilistic sense than the frame signal is
used as the input. Lemma 2 converts the derivation of the
reconstruction error of all possible points to that of just a few
reconstruction centriods.

We again use an example with two axes as shown in
Fig. 2 (b) to illustrate the idea behind, and all the derivations
can be easily expanded to the N-d general case.

Assume the input residual signal is a data point (x, y) on
the xy-plane with a joint probability distribution fXY (x, y).
Transform by an orthogonal matrix T can be considered
geometrically as a rotation of the coordinate system, namely,

(x, y) T(cid:55)→ (u, v),

(cid:0) 1 1−1 1

[u v]T = T [x y]T

(cid:1). In this example, (1, 0) T(cid:55)→

(2)

where we choose T = 1√
) and (1, 1) T(cid:55)→ (
,− 1√
( 1√
2
Quantization is equivalent to cutting the plane into squares,
as shown in Fig. 2 (b). We denote the point set containing

2, 0).

√

2

2

(a)

(b)

Fig. 2: Illustration for MSE calculation for the cases that (a) any
point (x, y) located within the 2a-by-2a square is quantized to
the reconstruction centriod (x0, y0) that may or may not located
within the square, and (b) a quantization in xy-plane is followed
by a transform, a quantization in uv-plane, inverse transform, and a
quantization in xy-plane.

much smaller comparing to the range of rHDR
allows us to
remove the predictive branch of Fig. 1 (b), and to declare the
non-predictive coding branch of Fig. 1 (b) is approximately
equivalent to the original pipeline of Fig. 1 (a).

t

B. Quantization Error for a Hypercube

Assume that

the reconstruction centroid for a squared
region of edge length 2a centered at (0, 0)1 as shown in
Fig. 2 (a) is located at (x0, y0) ∈ R2, not limited to be
within the region. We further assume that the point (X, Y )
is uniformly distributed over the square, namely, the joint
4a2 , (x, y) ∈ [−a, a]2. The mean-
distribution fX,Y (x, y) = 1
squared error (MSE) for the random vector (X, Y ) quantized
to/reconstructed at (x0, y0) is

MSE = E(cid:2)(cid:107)(X, Y ) − (x0, y0)(cid:107)2(cid:3)

(cid:90) a
(cid:90) a

−a

(cid:90) a

−a
1
4a2

=

=

= d2 +

(cid:90) a

−a

dy

−a
2
a2
3

(cid:107)(x, y) − (x0, y0)(cid:107)2 fX,Y (x, y) dx dy

(x − x0)2 + (y − y0)2 dx

(1)

1Throughout this paper, column vector [x1 x2 · · · xn]T may be denoted
as (x1, x2, · · · , xn) for the purpose of compact presentation.

Q1iQ1iQ2Q2T T-1Q1iQ1𝐈𝑡HDR𝐉𝑡=pred𝐈 𝑡−1∈ℝ𝐿 𝐈 𝑡HDR∈𝑞1ℤ𝐿R - 𝐈𝑡∈𝑞1ℤ𝐿𝐈 𝑡∈ℤ𝐿video codec Q1iQ1iQ2Q2T T-1Q1iQ1𝐫𝑡HDR𝐉𝑡%𝐪1∈ℝ𝐿 𝐫 𝑡HDR∈𝑞1ℤ𝐿R - video codec (a) (b) frame  signal residual signal xya-a0-aa(x0, y0)x y 1 2 3 5 1 -1u v 𝑅𝑥𝑦0,0𝑅𝑥𝑦0,1𝑅𝑥𝑦0,2𝑅𝑢𝑣1,1(cid:82)

all points belonging to a quantized region in xy-plane with
horizontal index i and vertical index j as Rxy[i, j], where
indices i, j ∈ ZM
def= {−M,··· , 0,··· , M}. Geometric
centers in of Rxy[i, j] are denoted as “•”, and those of Ruv[i, j]
are denoted as “◦”. In this example, Rxy[0, 1] centered at (0, 2)
and Rxy[0, 2] centered at (0, 4) are both quantized to Ruv[1, 1]
by Q2, and ﬁnally quantized to Rxy[0, 1] by Q1.
The overall error D def= E[(cid:107)(x, y) − (ˆx, ˆy)(cid:107)2] due to video
coding with baseband quantizer can be calculated by averaging
MSE over the (2M + 1)2 regions indexed by (i, j), namely,

D = E(cid:104)E(cid:2)(cid:107)(x, y) − (ˆx, ˆy)(cid:107)2|Rxy[I, J](cid:3)(cid:105)

(3)

(cid:17)2

(cid:16) q1

the probability mass

where
x,y∈Rxy[i,j] fXY (x, y) dxdy. For each region Rxy[i, j],
calculation of error is simpliﬁed by Lemma 2 2, namely,

function is pIJ (i, j) =
the

E(cid:2)(cid:107)(x, y) − (ˆx, ˆy)(cid:107)2|Rxy[i, j](cid:3) =

+ d2{Rxy[i, j]} (4)
where d{Rxy[i, j]} is the Euclidean distance from the recon-
struction centroid to the geometric center of Rxy[i, j]. The
geometric center is by deﬁnition m = (iq1, jq1). Passing m
through the whole pipeline shown in Fig. 1 (b) excluding the
predictive branch (aka the main branch), one can obtain the
reconstruction centroid:

2
3

2

(cid:16)

T−1(cid:8)Q2
(cid:20) q2
(cid:16) q1

(cid:2)TQ1

(cid:0)[iq1 jq1]T(cid:1)(cid:3)(cid:9)(cid:17)
(cid:18) q1
(cid:20)i
(cid:21)(cid:19)(cid:21)
+ E(cid:2)d2{Rxy[I, J]}(cid:3).

T−1 round

(cid:17)2

q2

T

2
3

= q1 round

j
Substituting Eqn. (4) into Eqn. (3), we obtain:

q1

D =

for E(cid:2)d2{Rxy[I, J]}(cid:3) to Appendix B. We present the ﬁnal

Due to the space limitation, we leave the detailed derivation

2

result of the derivation for the overall error D for scenarios
that the baseband quantizer is ﬁner than the codec quantizer
(i.e., q1 < q2) as follows:

(6)

ˆm = Q1

(cid:1) ,

2 + 2q2
1

 N

12
N
12

(cid:0)q2
(cid:2)q2

D =

2 , (7)

q1 ≤ q2

(cid:3) , q1 > q2

2 + (1 + γ1)q2

2 , (8)
where N is the length of input signal vectors, and estimates
of γ1 and γ12 are displayed in Fig. 3 (a).

1 + 2γ12q2q1

It can be proved that, using the scheme of the main branch of
Fig. 1 (b), the bitrate is solely controlled by the codec quantizer
Q2. Hence, ﬁxing q2 and thus the bitrate, any increase in q1
leads to a decrease in SNR and therefore in coding efﬁciency.
In comparison, a change in q2, which changes bitrate and SNR
simultaneously, has no impact on the coding efﬁciency.3
Given the scenarios of interest that q1 < q2, we deﬁne q1 =
α , α ≥ 1. The SNR loss with reference to an almost perfectly

q2

2Note that the uniform distribution assumption of Lemma 2 is valid within
region Rxy[i, j] for the high bitrate coding scenario that we are interested in.
3Recall that the comparison of coding efﬁciency between two codecs is via
the comparison of their empirical RD curves. A change in q2 does lead to a
move of the operation point in the bitrate-SNR plane, but both the starting
and the ending locations reside on the same RD curve.

3

(a)

(b)

Fig. 3: (a) Estimated γ1 and γ12, and (b) SNR LOSS as a function
of q2/q1 or α.

(5a)

(5b)

.

SNR LOSS =

ﬁne baseband quantizer, i.e., q1 → 0, can be easily derived:

(cid:19)

 10 log10

10 log10

(cid:18)
(cid:18)

1 +

1 +

,

2
α2
1 + γ1

α2

(cid:19)

α ≥ 2,

(9)

, α < 2.

(10)

+

2γ12

α

To conclude, under the assumption of q1 < q2,

The resulting SNR loss is shown in Fig. 3 (b).
i) the best
case is q1 (cid:28) q2 or α → ∞, and error is solely due to the codec
quantizer and there is no reduction in SNR; and ii) the worst
case is reached when q1 (cid:37) q2 or α (cid:38) 1, and a maximum of
3 dB SNR drop is incurred.

B. Simulation Results

We verify the theoretical result by simulating the change
of SNR as a function of q1
. Speciﬁcally, assume a length-L
Gaussian vector (X1, X2,··· , XL), with a ﬁxed correlation
q2
i.e., corr(Xl, Xl+1) = ρ, for
of neighboring coordinates,
l = 1,··· , L − 1. In image/video coding scenarios, L usually
takes value in {42, 82, 162}. In our simulation, realizations of
random vectors are obtained by choosing disjoint segments
from a realization of an AR(1) process.

We present

two simulation cases, (a) for small blocks
with low neighborhood correlation (L = 42, ρ = 0.4,
σ = std(Xl) = 1.0911), and case (b) for large blocks with high
correlation (L = 162, ρ = 0.9, σ = 2.2942). In both cases,
we check the performance difference between the scenarios
when the baseband quantizer Q1 is negligible, i.e., q1 → 0,
and not. When Q1 is not negligible, we set the quantizer to be
reasonably coarse with respect to the spread of Xl, namely,
q1 = σ
10, and the corresponding q2 for each bitrate value on
RD curve from left to right are q1 × {8, 4, 2, 1}.
Simulation results are shown in Fig. 4. The solid red curves
show the RD performances when the coarse quantizer Q1 is

12345q2/q1 or α-0.500.51estimatesγ1γ1212345q2/q1 or α0123SNR LOSS (dB)4

(a)

(b)

(c)

Fig. 4: RD curves of simulated video data revealing the performance gap between the scenarios that the baseband quantizer Q1 is negligible
(solid blue) and not negligible (dotted red). Case (a): small blocks with low neighborhood correlation (L = 42, ρ = 0.4), and case (b):
large blocks with high correlation (L = 162, ρ = 0.9). (c) Simulated SNR drops for different q1/q2 ratios agree with the theoretical results
[Eqn. (9)].

(a)

(b)

(c)

Fig. 5: RD curves for inter-coded videos with different strength levels of the baseband quantizer Q1: (a) Market and (b) Typewriter. The
PSNR gaps at high bitrate are 0.35 and 1.60 dB. (c) Largest PSNR gaps at both high and low bitrates for intra- and inter-coded videos.

used; whereas the dotted blue curves show the performances
when Q1 is negligible, which is to approximate the scenario
that Q1 is absent. The RD performance drop with respect
to the solid blue curves is consistent with the theoretical
estimates shown in the table of Fig. 4 (c). As expected from
our theoretical result, the above results are independent of
block size L and neighborhood correlation ρ.

IV. EXPERIMENTAL RESULTS ON VIDEOS

We now verify the theoretical results using standard test
sequences. Test sequences stored in the 16-bit TIFF container
are regarded as the reference/baseband signal. They were ﬁrst
linearly mapped to different dynamic ranges to mimic the
effect of the baseband quantizer, the resulting videos were then
encoded using HM 14.0 [16], and ﬁnally the quality in terms
of PSNR and SSIM was measured in the 16-bit precision.

Detailed simulation conditions are as follows. The luma
component of three test sequences BalloonFestival, Market,
and Typewriter in BT.2020 color space [17] of size 1920×1080
are used. The operational bitdepth in the video codec is 10.
Each video is encoded using two structures: the all I-frames
structure for 17 frames (aka intra-coding), and the IBBB···
structure for 64 frames (aka inter-coding). The codec quantizer
takes 6 equally spaced quantization parameters to draw one
piece of RD curve. Videos are baseband-quantized to the
dynamic ranges [0, 300], [0, 500], [0, 700], and [0, 900] with
effective bitdepth 8.2, 9.0, 9.5, and 9.8 bits, respectively.

The experimental results from all sequences with both
PSNR and SSIM measure reveal that the stronger the baseband
quantizer is, the more penalty in coding efﬁciency is incurred.
Due to the space limitation, we show the RD performance

measured in PSNR for Market and Typewriter that are inter-
coded in Figs. 5 (a) and (b). It can be read from the ﬁgures that
the PSNR gaps between the green curve and the red curve at
a high bitrate (the largest rate that 4 curves simultaneously
cover) is 0.35 dB for Market and 1.60 dB for Typewriter.
Table of Figs. 5 (c) reports the largest PSNR gaps at both
high and low bitrates for intra- and inter-coded videos. It
is observed that as the baseband quantizer strengthened by
1.6 (= 9.8 − 8.2) bits, the drop of PSNR at a high bitrate is
up to nearly 1.60 dB.

V. CONCLUSION AND DISCUSSION

In this work, we analyzed the video coding pipeline by
explicitly considering the existence of the baseband quan-
tizer. We arrived at the conclusion via theoretical proof and
experiment
the baseband quantizer lowers the coding
efﬁciency, whereas the codec quantizer does not affect the
coding efﬁciency. Hence, video information reduction in terms
of quantization error should be incurred in the video codec
instead of on the baseband signal.

that

In a more practical scenario, nonlinear mapping is more
often used than linear mapping for baseband signal range
reduction when the bitdepth is insufﬁcient. Although we have
proved that quantizing the baseband signal uniformly leads to a
penalty in coding efﬁciency measured in HDR, it is interesting
to see whether quantizing the baseband signal non-uniformly
can also lead to a penalty in coding efﬁciency.

22.533.544.555.5bitrate (bits/pixel)101520253035SNR (dB)q2=0.11q2=0.22q2=0.44q2=0.87preciseQ1ﬁttedcurve,q1→0coarseQ1ﬁttedcurve,q1=0.1111.522.533.544.5bitrate (bits/pixel)101520253035SNR (dB)q2=0.23q2=0.46q2=0.92q2=1.84preciseQ1ﬁttedcurve,q1→0coarseQ1ﬁttedcurve,q1=0.236q1/q2simulationtheory[Eqn.(9)]case(a)case(b)1/8−0.13−0.16−0.131/4−0.51−0.53−0.511/2−1.74−1.75−1.761/1−3.00−2.95−2.98rate (kbps)0200040006000PSNR (dB)30354045rate (kbps)0200400600PSNR (dB)40455055data pointsrange: 0--300data pointsrange: 0--500data pointsrange: 0--700data pointsrange: 0--900sequenceintra-codinginter-codingPSNRgap(dB)atextremeBRslowhighlowhighBalloonFe.0.130.830.190.83Market0.040.230.030.35Typewriter0.291.120.621.60REFERENCES

[1] D. G. Brooks, “The art of better pixels,” SMPTE Motion Imaging

Journal, vol. 124, no. 4, pp. 42–48, May 2015.

[2] S. Karlin, “New display technology aims to preserve realistic colors and

contrasts,” IEEE Spectrum, Mar. 2014.

[3] G.-M. Su, Q. Chen, H. Koepfer, and S. Qu, “Joint base layer and
enhancement layer quantizer adaptation in EDR video coding,” US
Patent 9,219,916 B2, 2015.

[4] T. Lu, F. Pu, P. Yin, T. Chen, and W. Husak, “Implication of high
dynamic range and wide color gamut content distribution,” in Proc.
SPIE, Applications of Digital Image Processing XXXVIII, San Diego,
CA, Aug. 2015, p. 95990B.

[5] P. Hanhart, M. Rerabek, and T. Ebrahimi, “Towards high dynamic
range extensions of HEVC: subjective evaluation of potential coding
technologies,” in Proc. SPIE, Applications of Digital Image Processing
XXXVIII, San Diego, CA, Aug. 2015, p. 95990G.

[6] A. Luthra, E. Franois, and W. Husak, “Draft call for evidence (CfE)
for HDR and WCG video coding,” ISO/IEC JTC1/SC29/WG11 MPEG,
Strasbourg, France, Tech. Rep. N15028, Oct. 2014.

[7] “Test results of call for evidence (CfE) for HDR and WCG video
coding,” ISO/IEC JTC1/SC29/WG11 MPEG, Warsaw, Poland, Tech.
Rep. N15350, Jun. 2015.

[8] ST 2084:2014, High Dynamic Range Electro-Optical Transfer Function

of Mastering Reference Displays, SMPTE Std., Aug. 2014.

5

[9] S. Miller, M. Nezamabadi, and S. Daly, “Perceptual signal coding for
more efﬁcient usage of bit codes,” SMPTE Motion Imaging Journal, vol.
122, no. 4, pp. 52–59, May 2013.

[10] Recommendation H.264, Advanced video coding for generic audiovisual
services, Series H: Audiovisual and Multimedia Systems, Infrastructure
of audiovisual services – Coding of Moving Video, ITU-T Std., 2014.
[11] Recommendation H.265, High efﬁciency video coding, Series H: Audio-
visual and Multimedia Systems, Infrastructure of audiovisual services –
Coding of Moving Video, ITU-T Std., 2015.

[12] J.-B. Lee and H. Kalva, The VC-1 and H.264 Video Compression
Springer, 2008, ch. 3, pp.

Standards for Broadband Video Services.
192–195.

[13] K. R. Rao, D. N. Kim, and J. J. Hwang, “Video coding standards:
AVS China, H.264/MPEG-4 PART 10, HEVC, VP6, DIRAC and VC-1,”
Springer, 2014.

[14] VC-1 Compressed Video Bitstream Format and Decoding Process,

SMPTE Std., 2006.

[15] V. K. Goyal, “Theoretical foundations of transform coding,” IEEE Signal

Processing Magazine, vol. 18, no. 5, pp. 9–21, Sep. 2001.

14.0.

(HM)

[16] HEVC Test Model

Joint Collaborative Team
on Video Coding (JCT-VC). https://hevc.hhi.fraunhofer.de/svn/svn
HEVCSoftware/tags/HM-14.0/

[17] Recommendation BT.2020-2, Parameter values for ultra-high deﬁni-
tion television systems for production and international programme
exchange, ITU-R Std., Oct. 2015.

APPENDIX A

PROOF OF LEMMA 1

Proof: For simplicity, deﬁne the quantizer

function
Qi(x) = iQi (Qi(x)). Denote the predicted frame pred(ˆIt−1)
as Jt, and it can be decomposed into the residue vector with
the smallest absolute value for each coordinate, and a vector
of integer multiples of q1, namely,

Jt = Jt%q1 + Q1(Jt)

(11)

(cid:16)

Q1

T−1Q2

(cid:0)T−1Q2

Q1

where % is the modulo operation. Following Fig. 1 (a), the
error due to the joint effect of baseband quantization and video
compression ˆIHDR

can be written as:

(12)
Substituting Eqn. (11) into (12) and moving Q1(Jt) ∈ (q1Z)L
into and out of the quantizer with step size q1, we obtain:

.

t

) − Jt

t

t − IHDR

(cid:8)T(cid:2)Q1(IHDR
(cid:8)T(cid:2)Q1(IHDR

(cid:3)(cid:9) + Jt

t

(cid:1) − IHDR
(cid:3)(cid:9)
t − Q1(Jt)(cid:3) .

t − Q1(Jt)) − Jt%q1
+ Jt%q1

(cid:17) −(cid:2)IHDR

(13)
t − Q1(Jt) can be considered as an intra- or inter-
Here, IHDR
prediction residue, and we deﬁne it as rHDR
. In terms of
quantifying error for reconstructed HDR frames, Fig. 1 (a)
is therefore equivalent to Fig. 1 (b) visualized from Eqn. (13),
namely,

t

t − IHDR
ˆIHDR

t = ˆrHDR

t − rHDR

t

.

(14)

Assuming the quantization step of Q1 is much smaller compar-
ing to the range of rHDR
, the predictive branch Jt%q1 can be
removed to obtain a slightly perturbed residue ˜rHDR
. Therefore,
≈
the error of non-predictively coded residues ˜rHDR
t − IHDR
ˆIHDR

t − rHDR

.

t

t

t

t

DERIVATION FOR E(cid:2)d2{Rxy[I, J]}(cid:3)

APPENDIX B

Deﬁne a residue function g(x) = round(x)− x, where g(x) ∈
(− 1
2 ) for any x < 0. Hence,

2 ] for any x > 0, and [− 1

2 , 1

2 , 1

6

q2

(cid:21)(cid:19)
(cid:18) q1
(cid:16) q1
(cid:20)W1

Eqn. (5b) can be simpliﬁed to the sum of three terms:

(cid:21)

(cid:20)i

j

ˆm = q1

+ q2 T−1g

(cid:20)i

T

j
T−1g

(cid:18) q1
(cid:26) q2

q2

q1

(cid:20)i
(cid:21)(cid:19)(cid:27)
(cid:17)

j

+ q1 g

T

.

(15)

(cid:16) q2

Denote the nth row and column of matrix T by vT
respectively. Deﬁne p = (i, j), Yn = g
. The squared distance is

(cid:17)

n p

uT

vT

q2

g

n Y

q1

n and un,
, and Wn =

d2{Rxy[I, J]} = (cid:107)m − ˆm(cid:107)2

(cid:20)Y1

(cid:13)(cid:13)(cid:13)(cid:13)q2 T−1

(cid:21)
+ q1
Y2
1 (cid:107)W(cid:107)2 + 2q2q1YT TW.
2 (cid:107)Y(cid:107)2 + q2

(cid:21)(cid:13)(cid:13)(cid:13)(cid:13)2

W2

(16a)

(16b)

=

= q2

(16c)

M , and the term q1
q2

Since vector p ∈ Z2
vT
n p can take values on
a non-degenerated subset of R, except in very rare cases with
a certain combination of q1, q2, vn the term takes value on a
subset of Z. For the non-degenerated case, it can be proved
that Yn is approximately uniformly distributed on (− 1
2 , 1
2 ).
Therefore, E[(cid:107)Y(cid:107)2] = 2
12.
When q1 < q2
Y is
larger than (−1, 1). It can be proved that, Wn is uniformly
distributed on (− 1
2 , 1
2 ), and W and Y are uncorrelated. There-
12, and E[YT TW] = trace{T E[WYT ]}
fore, E[(cid:107)W(cid:107)2] = 2
= 0.
In the other case, as q1 increases, Wn becomes more
E[(cid:107)W(cid:107)2] and γ12 =
N trace{T E[WYT ]} are empirically mea-

depend on Y. Statistics γ1 = 12
N
12
N
sured, and results are shown in Fig. 3 (a).

2 , the range of every coordinate of q2
q1

E[YT TW] = 12

(cid:1) / 6,

0 < q1 ≤ q2
2 ,
2 < q1 ≤ q2.

q2

(17)

1 + 2γ12q2q1

And it is not difﬁcult to generalize the above result to the N-d
scenario as follows:

Therefore,

E(cid:2)d2{Rxy[I, J]}(cid:3) =
(cid:1) / 6,

(cid:40)(cid:0)q2
(cid:0)q2

2 + q2
1
2 + γ1q2

E(cid:2)d2{Rxy[I1,··· , IN ]}(cid:3) =
(cid:40)
N(cid:0)q2
N(cid:0)q2

(cid:1) / 12,

2 + q2
1
2 + γ1q2

1 + 2γ12q2q1

(cid:1) / 12,

0 < q1 ≤ q2
2 ,
2 < q1 ≤ q2.

q2

(18)

