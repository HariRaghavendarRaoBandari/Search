Draft version March 4, 2016
Preprint typeset using LATEX style emulateapj v. 5/2/11

6
1
0
2

 
r
a

M
 
3

 
 
]

M

I
.

h
p
-
o
r
t
s
a
[
 
 

1
v
7
6
9
0
0

.

3
0
6
1
:
v
i
X
r
a

OF GENES AND MACHINES: APPLICATION OF A COMBINATION OF MACHINE LEARNING TOOLS TO

ASTRONOMY DATASETS

S. Heinis1, S. Kumar1, S. Gezari1, W. S. Burgett2, K. C. Chambers2, P. W. Draper3, H. Flewelling2, N. Kaiser2,

E. A. Magnier2, N. Metcalfe3, C. Waters2

Draft version March 4, 2016

ABSTRACT

We apply a combination of a Genetic Algorithms (GA) and Support Vector Machines (SVM) ma-
chine learning algorithm to solve two important problems faced by the astronomical community:
star/galaxy separation, and photometric redshift estimation of galaxies in survey catalogs. We use
the GA to select the relevant features in the ﬁrst step, followed by optimization of SVM parameters
in the second step to obtain an optimal set of parameters to classify or regress, in process of which
we avoid over-ﬁtting. We apply our method to star/galaxy separation in Pan-STARRS1 data. We
show that our method correctly classiﬁes 98% of objects down to iP1 = 24.5, with a completeness
(or true positive rate) of 99% for galaxies, and 88% for stars. By combining colors with morphology,
our star/classiﬁcation method yields better results than the new SExtractor classiﬁer spread model
in particular at the faint end (iP1 > 22). We also use our method to derive photometric redshifts for
galaxies in the COSMOS bright multi-wavelength dataset down to an error in (1 + z) of σ = 0.013,
which compares well with estimates from SED ﬁtting on the same data (σ = 0.007) while making a
signiﬁcantly smaller number of assumptions.
Subject headings: methods: numerical

1.

INTRODUCTION

Astronomy has witnessed an ever-increasing deluge of
data over the past decade. Future surveys will gather
very large amounts of data daily that will require on-the-
ﬂy analysis to limit the amount of data that can be stored
or analyzed, and allow timely discoveries of candidates to
be followed-up: for instance Euclid (Laureijs et al. 2011,
100 GB per day), WFIRST (Spergel et al. 2015, 1.3TB
per day), or the Large Synoptic Survey Telescope (LSST,
Ivezic et al. 2008, 10 TB per day). The evolution of the
type, volume, cadence of the astronomical data requires
the advent of robust methods that will enable a maximal
rate of extraction of information from the data. This
means that for a given problem, one needs to make sure
all the relevant information has is made available in the
ﬁrst step, followed by the use of a suitable method that
is able to narrow down on the important aspects of the
data. This can be both for feature selection as well as
for noise ﬁltering.

In machine learning parlance, the tasks required can
be designated as classiﬁcation tasks (derive a discrete
value: star vs galaxy for instance) or regression tasks
(derive a continuous value: photometric redshift for in-
stance.) Methods for classiﬁcation or regression usually
are of two kinds: physically motivated, or empirical4.
Physically motivated methods use templates built from
previously observed data, like star or galaxy Spectral
Energy Distributions (SEDs) for instance in the case of
determining photometric redshifts. They also attempt

1 Department of Astronomy, University of Maryland, College

Park, MD, USA

2 Institute for Astronomy, University of Hawaii at Manoa,

Honolulu, HI 96822, USA

3 Department of Physics, Durham University, South Road,

Durham DH1 3LE, UK
4 Formalisms that blend physically motivated and empirical have

been proposed, see e.g. Budav´ari (2009).

at including as much knowledge as we have of the pro-
cesses involved in the problem at stake, such as prior
information. Physically motivated methods seem more
appropriate than empirical, however the very fact that
they require a good knowledge of the physics involved
might be a important limitation. Indeed, our knowledge
of a number of processes involved in shaping the SEDs of
galaxies for instance is still quite limited (e.g. Conroy et
al. 2010, and references therein): whether is it about the
processes driving star formation, dust attenuation laws,
initial mass function, star formation history, AGN con-
tribution etc . . . Hence choices need to be made: either
make a number of assumptions, in order to reduce the
number of free parameters. Or, one can decide to be
more inclusive and add more parameters, but at the cost
of potential degeneracies. Physically motivated methods
are also usually limited in the way they treat the corre-
lation between the properties of the objects, because the
only correlations taken into account are those included
in the models used, and might not reﬂect all of the in-
formation contained in the data.

On the other hand, empirical methods require few or
no assumptions about the physics of the problem. The
goal of an empirical method is to build a decision func-
tion from the data themselves. The quality of the gener-
alization of the results to a full dataset depends of course
on the representativity of the training sample. We note
however that the question of the generalization also ap-
plies to physically motivated methods, as they are also
validated on the training data.

Depending on the methods used, transformations may
need to be eﬀected before the method is applied; for ex-
ample in the case of Support Vector Machines (SVM,
e.g. Boser et al. 1992; Cortes & Vapnik 1995; Vapnik
1995; Smola & Sch¨olkopf 1998; Vapnik 1998; Duda et
al.
2001) linear separability is presumed, thereby re-
quiring non-linearly separable or regressible data to be

2

S. Heinis et al.

kernel transformed to enable this.

A challenge with empirical methods is that with grow-
ing numbers of input parameters, it becomes prohibitive
in terms of CPU time to use all of them.
It can also
be counter-productive to feed the machine learning tool
with all of these parameters, as some of them might either
be too noisy, or not bring any relevant information to the
speciﬁc problem to tackle. Moreover, high dimensional
problems suﬀer from the bane of being over ﬁt by ma-
chine learning methods (Cawley & Talbot 2010), thereby
yielding high-dimensional non-optimal solutions. This
requires sub-selection of relevant variables from a large
N−dimensional space (with N potentially close to 1000).
This task itself can also be achieved using machine learn-
ing tools. Here we present, to our knowledge, the ﬁrst ap-
plication to astronomy of the combination of two machine
learning techniques: Genetic Algorithms (GA, e.g. Steeb
2014) for selecting relevant features followed by SVM to
build a decision/reward function. GA alone have already
been used in astronomy for instance to study the orbits of
exoplanets, and the SEDs of young stellar objects (Cant´o
et al. 2009), the analysis of SNIa data (Nesseris 2011), the
study of star formation and metal enrichment histories
of resolved stellar system (Small et al. 2013), the detec-
tion of globular clusters from HST imaging (Cavuoti et
al. 2014), or photometric redshifts estimation (Hogan et
al. 2015). On the other hand, SVM have been exten-
sively used to solve a number of problems such as object
classiﬁcation (Zhang & Zhao 2004), the identiﬁcation of
red variables sources (Wo´zniak et al. 2004), photomet-
ric redshift estimation (Wadadekar 2005), morphological
classiﬁcation (Huertas-Company et al. 2011), and param-
eters estimation for Gaia spectrophotometry (Liu et al.
2012). We note also that the combination of GA and
SVM has already been used in a number of ﬁelds such
as cancer classiﬁcation (e.g. Huerta et al.
2006; Alba
et al. 2007), chemistry (e.g. Fatemi & Gharaghani 2007),
bankruptcy prediction (e.g. Min et al. 2006) etc . . . We do
not attempt here to provide the most optimized results
from this combination of methods. Rather, we present
a proof-of-concept that shows that GA and SVM yield
remarkable results when combined together as opposed
to using the SVM as a standalone tool.

In this paper, we focus on two tasks frequently seen in
large surveys: star/galaxy separation and determination
of photometric redshifts of distant galaxies. Star/galaxy
separation is a classiﬁcation problem that has been usu-
ally constrained purely from the morphology of the ob-
jects (e.g. Kron 1980; Bertin & Arnouts 1996; Stoughton
et al. 2002). On the other hand, a number of studies
used the color information with template ﬁtting to sep-
arate stars from galaxies (e.g. Fadely et al. 2012). On
top of these two common approaches, good results have
been obtained by feeding morphology and colors to ma-
chine learning techniques (e.g. Vasconcellos et al. 2011;
Saglia et al. 2012; Kov´acs & Szapudi 2015). Our goal
here is to extend the star/galaxy separation to faint mag-
nitudes where morphology is not as reliable. We apply
here the combination of GA with SVM to star/galaxy
separation in the Pan-STARRS1 (PS1) Medium Deep
survey (Kaiser et al. 2010; Tonry et al. 2012; Rest et al.
2014).

On the other hand, determining photometric redshifts
is a well-studied problem of regression that has been dealt

with using a variety of methods, including template ﬁt-
ting (e.g. Arnouts et al. 1999; Ben´ıtez 2000; Brammer et
al. 2008; Ilbert et al. 2009), cross correlation functions
(Rahman et al. 2015), Random Forests (Carliles et al.
2010), Neural Networks (Collister et al. 2007), polyno-
mial ﬁtting (Connolly et al. 1995), symbolic regression
(Krone-Martins et al. 2014). We apply the GA-SVM to
the zCOSMOS bright sample (Lilly et al. 2007).

The outline of this paper is as follows. In Sect. 2 we
present the data we apply our methods to, and also the
training sets we use: PS1, and zCOSMOS bright.
In
Sect. 3 we brieﬂy describe our methods; we include a
more detailed description of SVM in an Appendix. We
present our results in Sect. 4, and ﬁnally list our conclu-
sions.

2. DATA

We perform star/galaxy separation in PS1 Medium
Deep data (see Sect. 2.1), using a training set built from
COSMOS ACS imaging (see Sect. 2.2.1). We then derive
photometric redshifts for the zCOSMOS bright sample
(see Sect. 2.2.2).

2.1. Pan-STARRS1 data

The Pan-STARRS1 survey (Kaiser et al. 2010) sur-
veyed 3/4 of the northern hemisphere (δ > −30 deg), in
5 ﬁlters: gP1, rP1, iP1, zP1, and yP1 (Tonry et al. 2012).
In addition, PS1 has obtained deeper imaging in 10 ﬁelds
(amounting to 80 deg2) called as the Medium Deep Sur-
vey (Tonry et al. 2012; Rest et al. 2014). We use here
data in the MD04 ﬁeld, which overlaps the COSMOS
survey (Scoville et al. 2007).

We use our own reduction of the PS1 data in the
Medium Deep Survey. We use the image stacks gener-
ated by the Image Processing Pipeline (Magnier 2006),
and also the CFHT u band data obtained by E. Magnier
as follow up of the Medium Deep ﬁelds. We have at hand
6 bands: uCFHT, gP1, rP1, iP1, zP1, and yP1. We per-
form photometry using the following steps; we consider
the PS1 skycell as the smallest entity: i) resample (using
SWarp, Bertin et al. 2002) the u band images to the PS1
resolution, and register all images; ii) for each band ﬁt
the PSF to a Moﬀat function, and match that PSF to the
worse PSF in each skycell; iii) using these PSF-matched
images, we derive a χ2 image (Szalay et al. 1999); iv) we
perform photometry using the SExtractor dual mode
(Bertin & Arnouts 1996), detecting objects in the χ2
image and measuring the ﬂuxes in the PSF matched im-
ages: the Kron-like apertures are deﬁned from the χ2
image and hence are the same over all bands ; v) for
each detection we measure spread model in each band
on the original, non PSF-matched images. We consider
here Kron magnitudes, which are designed to contain
∼ 90% of the source light, regardless of being a point
source star or an extended galaxy.

spread model (Soumagnac et al. 2013) is a discrim-
inant between the local PSF, measured with PSFEx
(Bertin 2011) and a circular exponential model of scale
length F W HM/16 convolved with that PSF. This dis-
criminant has been shown to perform better than SEx-
tractor previous morphological classiﬁer, class star.

2.2. COSMOS data

Of Genes and Machines

3

2.2.1. Star/galaxy classiﬁcation training set

We use the star/galaxy classiﬁcation from Leauthaud
et al. (2007) derived from high spatial resolution Hubble
Space Telescope (HST) imaging (in the F 814W band)
as our training set for star/galaxy classiﬁcation. They
separate stars from galaxy based on their SExtractor
mag auto and mu max (peak surface brightness above sur-
face level). By comparing the derived stellar counts with
the models of Robin et al. (2007), Leauthaud et al. (2007)
showed that the stellar counts are in excellent agreement
with the models for 20 < F 814W < 25. We perform here
star/galaxy separation down to iP1 = 24.5.

2.2.2. Spectroscopic redshift training set

We use data taken as part of the COSMOS survey
(Scoville et al. 2007). We focus here on objects with spec-
troscopic redshifts obtained during the zCOSMOS bright
campaign (Lilly et al. 2007, i < 22.5). We use the pho-
tometry obtained in 25 bands by various groups in broad
optical and near-infrared bands: Capak et al. (2007,
u∗,BJ ,VJ ,g+, r+, i+,z+,Ks); narrow bands: Taniguchi et
al. (2007, N B816) and Ilbert et al. (2009, N B711); inter-
mediate bands Ilbert et al. (2009, IA427, IA464, IA505,
IA574, IA709, IA827, IA484, IA527, IA624, IA679,
IA738, IA767). We also use IRAC1 and IRAC2 photom-
etry (Sanders et al. 2007). We consider here only objects
with good redshift determination (conﬁdence class: 3.5
and 4.5),z < 1.5 (which yields 5,807 objects) and mea-
sured magnitudes for all the bands listed above, which
ﬁnally leaves us with 5093 objects. We do not use objects
with other conﬁdence class values, as the spectroscopic
redshifts can be erroneous in at least 15% of cases (Ilbert,
Private communication).

3. METHODS

We present here the two machine learning methods we
use in this work: Genetic Algorithms are used to select
the relevant features, and Support Vector Machines are
used to predict the property of interest using these fea-
tures.

3.1. Genetic Algorithms

Genetic algorithms (GA, e.g. Steeb 2014) apply the
basic premise of genetics to the evolution of solution sets
of a problem, until they reach optimality. The deﬁni-
tion of optimality itself is debateable, however, the gen-
eral idea is to use a reward function to direct the evolu-
tion. That is, we evolve solution sets of parameters (or
genes) known as organisms through several generations,
according to some pre-deﬁned evolutionary reward func-
tion. The reward function may be a goodness of ﬁt, or
a function thereof that may take into account more than
just the goodness of ﬁt. For example, one may choose
to determine subsets of parameters which optimize χ2
or likelihood, Akaike Information criteria, energy func-
tions, entropy, etc. The lengths of the ﬁrst generation of
organisms is chosen to range from the minimum expected
dimensionality of the parameter space (which can be 1)
to the maximum expected dimensionality of the covari-
ance.

The ﬁttest organisms in a particular generation are
then given higher probabilities of being chosen to be the
parents for successive generations using a roulette selec-
tion method based on their ﬁtnesses. Parents are then

cross-bred using a customized procedure - in our method
we ﬁrst choose the lengths of the children to be based
on a tapered distribution where the taper depends on
the ﬁtnesses of the parents. That way the length of the
child is closer to that of the ﬁtter parent. The child is
then populated using the genes of both parents, where
genes that are present in both parents are given twice
the weight as genes that are only present in one parent.
The idea is that the child should, with a greater proba-
bility, contain genes that are present in both parents as
opposed to the ones contained in only one of them. This
process iteratively produces ﬁtter children in successive
generations and is terminated when no further improve-
ment in the average organism quality is seen. Like in
biological genetics, we also introduce a mutation in the
genes with constant probability. The genes which are
chosen to be mutated, are replaced with any of the genes
that are not part of either parent, with uniform probabil-
ity of choosing from the remaining genes. This allows for
genes that are not part of the current gene pool to be ex-
pressed. The conceptual simplicity of genetic algorithms
combined with their evolutionary analogy as applied to
some of the hardest multi-parameter global optimization
problems makes them highly sought after.

3.2. Support Vector Machines

Support vector machines (SVM) (e.g. Boser et al. 1992;
Cortes & Vapnik 1995; Vapnik 1995; Smola & Sch¨olkopf
1998; Vapnik 1998; Duda et al.
2001) is a machine
learning algorithm that constructs a maximum mar-
gin hyperplane to separate linearly separable patterns.
SVM is especially eﬃcient in high dimensional param-
eter spaces,where separating two classes of objects is a
hard problem, and performs with best case complexity
Onparametersn2
samples. Where the data is not linearly
separable, a kernel transformation can be applied to map
the original parameter space to a higher dimensional fea-
ture space where the data becomes linearly separable.
For both problems we attempt to solve in this paper, we
use a Gaussian Radial Basis Function kernel, deﬁned as

K(x, x(cid:48)) = exp(−γ||x − x(cid:48)||2)

(1)

Another advantage of using SVM is that there are es-
tablished guarantees of their performance which has been
well documented in literature. Also, the ﬁnal classiﬁca-
tion plane is not aﬀected by local minima in the classiﬁca-
tion or regression statistic, which other methods based on
least squares, or maximum likelihood may not guarantee.
For a detailed description of SVM please refer to Smola &
Sch¨olkopf (1998); Vapnik (1995, 1998). We use here the
python implementation within the Scikit-learn (Pe-
dregosa et al. 2011) module.

3.3. Optimization procedure

We combine the GA and SVM to select the optimal set
of parameters that enable one to classify objects or de-
rive photometric redshifts. In either case, we ﬁrst gather
all input parameters, and build color combinations from
all available magnitudes. We also consider here transfor-
mations of the parameters, namely their logarithm and
exponential on top of their catalog values that we name
’linear’ afterwards, in order to capture non-linear depen-
dencies on the parameters. Note that any transformation

4

S. Heinis et al.

could be used, we limited ourselves to log and exp for
sake of simplicity for this ﬁrst application. This way, the
rate of change of the dependent parameter as a function
of the independent parameter in question is more accu-
rately captured, and dependencies on multiple transfor-
mations of the same variable can also be captured. To
eliminate scaling issues in transformed spaces, we trans-
form all independent parameters to between -1 and 1.
The optimization is then performed the following two
steps iteratively until the end criterion or convergence
criterion is met: selection of the relevant set of features
in the ﬁrst, and automatic optimization of SVM param-
eters to yield optimal classiﬁcation/regression given the
parameters. For SVM classiﬁcation, the true positive
rate is used as the ﬁtness function. For SVM regression,
a custom ﬁtness function based on the problem at hand
is chosen. For example, for SVM regressions on the pho-
tometric redshift we use

(cid:16) zi

(cid:80)

i

(cid:17)2

1

phot−zi

spec

zi
phot

(2)

Once the ﬁtness of all organisms has been evaluated,
a new generation of same size as that of the parent gen-
eration is created using roulette selection. The GA then
runs until it reaches a pre-deﬁned stopping criterion. We
use here the posterior distribution of the parameters.
We stop the GA when all parameters have been used
at least 10 times. We also use the posterior distribution
to choose the optimal set of parameters. Various schemes
can be deﬁned. For our application, we restrict ourselves
to characterizing the posterior distribution by its mean
µ and standard deviation σ (see Figure 1). We consider
here all parameters that appear more that µ+σ or µ+2σ
times in the posterior distribution, depending on which
our results change signiﬁcantly. For instance, in the case
of photometric redshifts the mean of the posterior distri-
bution is µ = 13.8, and the standard deviation σ = 10.4,
we keep all parameters that occur more than 24 times in
the posterior distribution when using the µ + σ criterion.

3.3.1. SVM parameters optimization

SVM are not ”black boxes”, but come with a well de-
ﬁned formalism, and free parameters to be adjusted. For
this application, we use the νSVM version of the algo-
rithm which allows to control the fractional error and the
lower limit on the fraction of support vectors used. We
use here ν = 0.1. In the case of classiﬁcation (star/galaxy
separation), we are then left with only one free param-
eter, the inverse of the width of the Gaussian Kernel,
γ (eq. 1).
In the case of regression (photometric red-
shifts), we have an additional free parameter, the trade
oﬀ parameter C (see Appendix A).

If not used with caution, machine learning methods
can lead to over-ﬁtting : the decision function is biased
by the training sample and will not perform well on other
samples. In order to avoid over-ﬁtting and optimize the
value of γ and C, we perform 10-fold cross-validation:
we divide the sample in 10 subsets; we then perform
classiﬁcation or regression for each subset after training
on the 9 other subsets. We perform this cross validation
for a grid of γ and C values. In the case of SVM, the

Figure 1. Example of posterior distribution for the parameters
obtained from the GA-SVM. This posterior distribution was de-
rived for the application to photometric redshifts (§4.2). The
red solid line shows the average occurence of the parameters; the
dashed blue line the occurence at the mean plus one standard de-
viation, af the dotted blue line the occurence at the mean plus
two standard deviations. We use here all parameters which ap-
pear more times than the mean plus one standard deviation in the
posterior distribution.

overﬁtting can be measured by the fraction of objects
used as support vectors, fSV. If fSV ∼ 1, most of the
training sample is used as support vectors, will lead to
poor generalization. For each iteration, we also get fSV,
in order to include it on our cost function. For both
applications, we minimize a custom cost function that
optimizes the quality of the classiﬁcation or regression,
and fSV.

4. RESULTS

4.1. Star/Galaxy separation

We use as inputs to the GA feature selection step all
magnitudes available for the PS1 dataset: uCFHT, gP1,
rP1, iP1, zP1, and yP1; the spread model values derived
from each of these bands; the ellipticity measured on the
χ2 image, all colors. We also included a few quantities
determined by running the code lephare on these data:
photometric redshift, and ratios of the minimum χ2 us-
ing galaxy, star, and quasar templates: χ2
star,
χ2
galaxy/χ2
star. Including the trans-
formations of these parameters yields 96 input parame-
ters to the GA-SVM feature selection procedure.

quasar, and χ2

galaxy/χ2

quasar/χ2

The parameters selected by the GA with occurence
larger than µ + σ times in the posterior distribution are
listed in Table 1. We also indicate the parameters whose
occurence is larger than µ+2σ times. The 15 selected pa-
rameters include spread model derived in gP1, rP1 and
iP1, but are dominated by colors (7 of 15). Using the pa-
rameters occuring more than µ+2σ yields similar results,
however with signiﬁcant overﬁtting.

In order to quantify the quality of the star/galaxy sep-
aration, we use following deﬁnitions for the completeness

Of Genes and Machines

5

Star/Galaxy separation: GA output parameters

Table 1

Parameter

Transform Occurence threshold a

uCFHT

rP1
rP1

spread model g
spread model r
spread model r
spread model i
uCFHT − gP1
uCFHT − zP1
uCFHT − yP1
gP1 − yP1
rP1 − yP1
iP1 − yP1
zP1 − yP1

zphot

log
lin
log
exp
lin
log
exp
lin
lin
lin
log
exp
lin
exp
lin

µ + σ
µ + σ
µ + 2σ
µ + σ
µ + 2σ
µ + 2σ
µ + 2σ
µ + σ
µ + σ
µ + 2σ
µ + σ
µ + σ
µ + σ
µ + σ
µ + σ

a µ + σ indicates that the parameter occured at least µ +
σ times in the posterior distribution of the GA, while µ +
2σ indicates that the parameter occured µ + 2σ times.

c and the purity p:

cg =

pg =

ng

ng + mg

ng

ng + ms

(3)

(4)

where nx is the number of objects of class x correctly
classiﬁed, and mx is the number of objects of class x
misclassiﬁed. The same deﬁnition holds for the star com-
pleteness and purity.

Figure 2. SExtractor morphological classiﬁer spread model mea-
sured in PS1 i band as a function of iP1. We also show the result of
our baseline classiﬁcation (training on all objects): red points show
objects classiﬁed as stars by the GA-SVM, and blue points objects
classiﬁed as galaxies. Orange and cyan points show misclassiﬁed
objects: orange are galaxies according to the catalog of Leauthaud
et al. (2007) classiﬁed as stars, and cyan stars classiﬁed as galaxies.

Based on these deﬁnitions, in the case of star/galaxy

separation, we use as cost function:

0.01

(5)

In other words, we choose here to optimize the average
completeness and purity for stars and galaxies, and also
penalize high fSV, which amounts to penalize high frac-
tional errors, and overﬁtting as well. Other optimization
schemes can be adopted. We perform the optimization
over the only SVM free parameter here, the inverse of the
width of the Gaussian Kernel, γ. We use a grid search
using a log-spaced binning for 0.01 < γ < 10.

We show in Fig. 2 the spread model derived in the
PS1 i band, as a function of iP1. Fig. 2 shows that
spread model enables to recover a star sequence down
to iP1 ∼ 22. At fainter magnitudes morphology alone
is not able to separate accurately stars from galaxies at
the PS1 angular resolution. The colors coding shows the
result of the GA-SVM classiﬁcation. We classify objects
down to iP1 = 24.5. We choose this limit because the
completeness of the PS1 data drops signiﬁcantly beyond
24.5, and also because the training set we use is valid
down to F 814W = 25. Fig. 1 suggests that the GA-
SVM is able to recover the classiﬁcation at bright mag-
nitudes, but also to extend it at the faint end. We list

.

Figure 3. Color magnitude diagram g − iP1 as a function of iP1.
The color coding is the same as in Fig. 2

in Table 2 the percentage of objects classiﬁed correctly.
Our method correctly classiﬁes 97% of the objects down
to iP1 = 24.5. We can compare our results to those from
the PS1 photometric classiﬁcation server (Saglia et al.
2012), who used SVM on bright objects using PS1 pho-
tometry. They obtained 84.9% of stars correctly clas-
siﬁed down to iP1 = 21, and 97% of galaxies down to

(cid:18) cg − 1

(cid:19)2

0.005

(cid:18) cs − 1

(cid:19)2

0.005

+

(cid:18) pg − 1

(cid:19)2

0.005

+

J =

(cid:19)2
(cid:18) ps − 1
(cid:19)2
(cid:18) fSV − 0.1

0.005

+

+

6

S. Heinis et al.

Star/Galaxy separation: performance

Table 2

Type

GA-SVM alla GA-SVM bright/faintb

spread modelc

All types
Galaxies

Stars

97.4
99.8
74.5

98.1
99.2
88.5

92.7
94.5
75.9

— Percentage of correctly classiﬁed objects

Note.
method:
a training and prediction on the full sample
b Training and prediction on bright and faint objects separately
c SExtractor spread model method

for each

P1 = 20. Our method enables to improve upon those, as
we get 88.6% of stars correctly classiﬁed, and 99.3% of
galaxies correctly classiﬁed in the same magnitude range.
We examine in more details in Fig. 3 and 4 the colors
of the objects. These ﬁgures show that the bulk of stars
that are misclassiﬁed as galaxies are at the faint end i (cid:38)
22, and that these objects are in regions where the colors
of stars and galaxies are similar. Galaxies misclassiﬁed
as stars are brighter i < 22 but again are in regions
where colors of stars and galaxies overlap. There are also
a handful of very bright stars misclassiﬁed as galaxies,
in a domain where the galaxy sampling is very poor.
Finally, we classify as galaxies a few stars showing colors
at the outskirt of the color distributions. These objects
might be either misclassiﬁed by the ACS photometry, or
the color might be signiﬁcantly impacted by photometric
scatter.

We show in Fig. 5 the completeness (left) and purity

(right) of our classiﬁcations as a function of iP1.

We derive the completeness and purity for each cross-
validation subset, and show in Fig. 5 the average, and as
error bars the standard deviation. Most of the features
of our classiﬁcation seen in Fig. 5 are due to the fact
that the training sample is unbalanced at the bright end
and the faint end: at the bright end, stars outnumber
the galaxies, and the other way around at the faint end.
At the bright end (iP1 < 16, which is also within the
saturation regime), the completeness is higher for stars
than for galaxies, while noisy because of small statistics.
Some bright galaxies are misclassiﬁed as stars. At the
faint end (iP1 > 22), the star completeness decreases,
as some stars are classiﬁed as galaxies. The impression
given by Fig. 5 is striking, as the star completeness de-
creases to 0 at iP1 ∼ 24. Note however that the stars
represent only 3% of the overall population at this ﬂux
level (Leauthaud et al. 2007). The purity shows a similar
behaviour at the bright end. At the faint end however
the stars purity is larger than 0.85 for iP1 (cid:46) 23. For
galaxies, both completeness and purity are lower than
0.8 at the bright end (iP1 < 18), however the number
of galaxies is small at these magnitudes. At iP1 > 18,
completeness and purity are independent of magnitude
down to iP1 = 24.5 and larger than 0.95.

We compare this results to the classiﬁcation obtained
with spread model derived in the iP1 band. We deter-
mine a single cut in spread model i using its distribu-
tion for reference stars and galaxies. Our cut is the value
of spread model i such that p(g|spread model i) =
p(s|spread model i). We show in Fig. 5 the complete-
ness and purity obtained with spread model i as dotted
lines. For iP1 (cid:46) 22, the results from spread model i and

our method are similar, as at the PS1 resolution, point
sources and extended objects are well discriminated in
this magnitude range. At iP1 > 22, our baseline method
performs better, in particular for galaxies, which is ex-
pected as we add color information. While the galaxies’
purity is similar for both methods, the completeness ob-
tained with spread model i drops to 0.75 at iP1 = 24.5,
but our methods yields a completeness consistent with 1
down to this magnitude. For stars, the purity obtained
with the two methods are similar. On the other hand,
the completeness we obtain drops faster than that ob-
tained with spread model i.
In order to see whether
we can improve our baseline method, we optimize the
SVM parameters independently in two magnitude range:
iP1 < 22 and iP1 > 22. As galaxies at the faint end out-
number stars by several orders of magnitude, we add an
extra free parameter for the optimization at iP1 > 22,
which attempts at correcting this sampling issue.
In
practice we use all stars available, but only a fraction
of the galaxies available, from 1 to 10 times the number
of stars. The results obtained are shown in solid lines on
Fig. 5. The results for galaxies are virtually unchanged
compared to our baseline method. For stars, we are able
to improve at the faint end, where the purity is better
than that obtained with spread model i for iP1 < 23.

As a ﬁnal check, we also derive the star/galaxy sepa-
ration by using SVM only, without selecting the inputs
with the GA. The results are only marginally diﬀerent.
We note however that a parameter space with lower di-
mensions is less prone to overﬁtting with machine learn-
ing methods. On the other hand, even with similar re-
sults, a SVM-based star/galaxy separation with smaller
number of inputs parameters is more likely to generalize
properly.

4.2. Photometric redshifts

We used 978 input parameters as inputs for the GA-
SVM optimization procedure: all magnitudes and colors
available from the COSMOS dataset and the transfor-
mations of these parameters, as described in Sect. 3.3.
Hereafter we consider the parameters that appear at least
µ + 1σ times in the posterior distribution, we are left
with 131 parameters. The parameters retained by the
GA-SVM are dominated by colors (82%, 108/131), and
in particular colors involving intermediate and narrow
bands (71%, 93/131). Using the parameters that appear
µ + 2σ times in the GA posterior distribution yields 45
parameters, with similar proportions of colors and inter-
mediate and narrow bands. This is in line with the con-
clusions of studies using SED ﬁtting methods which show
that including narrow and intermediate bands improves
signiﬁcantly the estimation of photometric redshifts (e.g.
Ilbert et al. 2009).
We quantify the errors on photometric redshifts as
err(zspec) = (zphot − zspec)/(1 + zspec), use as a measure
of global accuracy σ the normalized median absolute de-
viation, deﬁned as σ(z) = 1.4826 ∗ median(|err(zspec) −
median(err(zspec))|).
We deﬁne the following cost function for the SVM op-

(cid:18) σ(z) − 0.005

(cid:19)2

(cid:18) fSV − 0.1

(cid:19)2

0.0001

+

0.01

timization:

J =

.

(6)

Of Genes and Machines

7

Figure 4. Color-color diagram u − rP1 as a function of r − iP1. The left panel shows objects with iP1 < 22 and the right panel objects
with iP1 > 22. The color coding is the same as in Fig. 2

We perform the optimization over the 2 SVM free pa-
rameters available here, γ, and the trade oﬀ parameter
C. We use a grid search using a log-spaced binning for
0.01 < γ < 10 and 0.01 < C < 500.

We compare in Fig. 6 spectroscopic and photomet-
ric redshifts. We obtain an overall accuracy of 0.0135.
The percentage of outliers, deﬁned as objects with
|err(zspec)| > 0.15, is below 1%. The average error (bias)
is equivalent to 0; our results do not show any signiﬁcant
bias as a function of redshift. At high redshifts (z > 1)
the spectroscopic sampling is small, and so the model
is less constrained. Using the parameters that appear
µ+2σ times in the GA-SVM posterior distribution yields
similar results (σ(z) = 0.014), which shows that by us-
ing 3 times less parameters, the same accuracy can be
achieved.

On a similar sample6, Ilbert et al. (2009), using a
SED ﬁtting method, obtain an overall accuracy of 0.007.
While our results are slightly worse at face value, we note
that we use here only 2 free parameters for the photo-
metric redshift optimization, and one model to derive the
photometric redshifts (the one from SVM). On the other
hand Ilbert et al. (2009) rely on 21 SED templates, 30
zero point oﬀsets (one per band), and an extra parameter
describing the amount E(B − V ) of internal dust atten-
uation. We also explicitly avoid overﬁtting, and doing
so guarantees the potential for generalization of these
results. Our tests show that we can obtain an overall
accuracy of ∼ 0.01, however this comes at the price of
signiﬁcant overﬁtting (the support vectors are made up
from the whole sample.)

As above, we also derive the photometric redshifts by
5 Using objects with spectroscopic conﬁdence class 3 ≤ CC < 5

yields similar results with an accuracy of σ(z) = 0.015

6 Ilbert et al. (2009) used an earlier version of the catalog we are

using here.

using SVM only, without selecting the inputs with the
GA. In this case the results are much worse, yielding large
errors: σ(z) ∼ 0.5. This shows that the combination of
GA and SVM yields better results than SVM alone.

We also test whether we can derive empirical error
estimates for each objects using SVM. We use a vari-
ant of the k−fold cross validation, so-called “inverse”.
The usual k−fold cross validation consists of dividing the
sample into k subsamples (we use k = 10 here); for each
subsample predictions are made using the SVM trained
on the union of the other k− 1 subsamples. To derive er-
ror estimates, we use the inverse k−fold cross validation
such that we train the SVM on one subsample, and pre-
dict photometric redshifts for the union of the other k−1
subsamples. We have then k − 1 estimates of zphot. We
derive an empirical error estimate ˆσz which is the stan-
dard deviation of these estimates. We show in Fig. 7 the
normalized distribution of the ratio (zspec − zphot)/ˆσz. If
our empirical estimate were an accurate measurement of
the actual error, this distribution should be a Normal
one. The comparison with a Normal distribution shows
that this is indeed the case, which suggests that our error
estimates are accurate.

5. CONCLUSIONS

We present a new combination of two machine learn-
ing methods that we apply to two common problems in
astronomy, star/galaxy separation and photometric red-
shift estimation. We use Genetic Algorithms to select rel-
evant features, and Support Vector Machines to estimate
the quantity of interest using the selected features. We
show that the combination of these two methods yields
remarkable results, and oﬀers an interesting opportunity
for future large surveys which will gather large amount of
data. In the case of star/galaxy separation, the improve-
ments over existing methods are a consequence of adding

8

S. Heinis et al.

Figure 5. Quality of the GA-SVM star/galaxy classiﬁcation. Top: Galaxy and star counts.Middle: completeness as a function of PS1 i
magnitude. Bottom: Purity as a function of PS1 i magnitude. On all panels, Red is for stars, and blue for galaxies. On the middle and
bottom panels, lines show diﬀerent classiﬁcations: the dashed lines show the result of our classiﬁction when training with the full sample;
solid lines when traing on bright (iP1 > 22) and faint (iP1 < 22) objects separately; dotted lines show the classiﬁcation from spread model.

more information, while for photometric redshifts, it is
rather the selection of the input information fed to the
machine learning methods. This shows that the combi-
nation of GA and SVM is very eﬃcient in the case of
problems with large dimensions.

We ﬁrst apply the GA-SVM method to star/galaxy
separation in the PS1 Medium Deep Survey. Our base-
line method correctly classiﬁes 97% of objects, in partic-
ular virtually all galaxies. Our results improve upon the
new SExtractor morphological classiﬁer, spread model,
which is expected as we added color information com-
pared to morphology only. We show how these results
can be further improved for stars by training separately
bright and faint objects, and taking into account the
respective number of stars and galaxies to avoid being
dominated by one population.

We then apply the GA-SVM method to photometric
redshift estimation for the zCOSMOS bright sample. We
obtain an accuracy of 0.013, which compares well with
results from SED ﬁtting, as we are using only 2 free pa-
rameters. We also show that we can derive accurate error
estimates for the photometric redshifts.

We present here a proof-of-concept of a new method
that can be modiﬁed or improved depending on the prob-
lem at stake. For instance, one can substitute another
machine learning tool to SVM (such as Random Forests
for instance) to derive the quantity of interest. Further-
more the criterion used to select the ﬁnal number of fea-
tures from the GA posterior distribution can be also be
optimized beyond the one we use here. All these tools
will enable to use as much information as possible in an
eﬃcient way for future large surveys.

Of Genes and Machines

9

The Pan-STARRS1 Surveys (PS1) have been made
possible through contributions of the Institute for As-
tronomy, the University of Hawaii, the Pan-STARRS
Project Oﬃce, the Max-Planck Society and its partic-
ipating institutes, the Max Planck Institute for Astron-
omy, Heidelberg and the Max Planck Institute for Ex-
traterrestrial Physics, Garching, The Johns Hopkins Uni-
versity, Durham University, the University of Edinburgh,
Queen’s University Belfast, the Harvard-Smithsonian
Center for Astrophysics, the Las Cumbres Observatory
Global Telescope Network Incorporated, the National
Central University of Taiwan, the Space Telescope Sci-
ence Institute, the National Aeronautics and Space Ad-
ministration under Grant No. NNX08AR22G issued
through the Planetary Science Division of the NASA Sci-
ence Mission Directorate, the National Science Founda-
tion under Grant No. AST-1238877, the University of
Maryland, and Eotvos Lorand University (ELTE) and
the Los Alamos National Laboratory.

Figure 6. Top: comparison of spectroscopic redshifts with photo-
metric redshifts obtained with the GA-SVM. The solid line shows
identity; the dotted line an error or 0.05 in 1 + z, and the dashed
line an error of 0.15 in 1 + z. Bottom: error of photometric red-
shifts as a function of spectroscopic redshifts. Lines are the same
as above.

Figure 7. Empirical estimate of photometric redhift errors. The
histogram shows the distribution of the ratio (zspec − zphot)/ˆσz.
The curve is a normal distribution.

SUPPORT VECTOR MACHINES: SHORT DESCRIPTION

APPENDIX

We provide here a short description of the SVM. More detailed presentations of the formalism can be found elsewhere
(e.g. Smola & Sch¨olkopf 1998; Vapnik 1995, 1998). For the sake of brevity, we present here only the equations relevant
to regression with SVM. Equations for classiﬁcation are similar, except a few diﬀerences that we mention whenever
necessary.

The training data usually consists of a number objects with input parameters, (cid:126)x, of any dimension, and the known

10

S. Heinis et al.

values of the quantity of interest, (cid:126)y. The goal of SVM is to ﬁnd a function f such as

which yields (cid:126)y with a maximal error , and such as f is as ﬂat as possible. In other words, the amplitude of the slope
(cid:126)w has to be minimal. One way to achieve this is to minimize the norm 1
The margin in that case is 2|w| . In other words, SVM attempt to regress with the largest possible margin.

2|w|2 with the condition |yi − (cid:126)w. (cid:126)xi − b| ≤ .

f = (cid:126)w.(cid:126)x + b

(A1)

In a number of problems, the data can not be separated using a ﬁx, hard margin. It is then useful to allow some
points to be misclassiﬁed. One uses a ”’soft margin”, which enables to allow some errors in the results. The modiﬁed
minimization reads:

2|w|2 + C(cid:80)
(cid:40) yi − w.xi − b ≤  + ξi

i ξi + ξ∗

i

−yi + w.xi + b ≤ − + ξ∗
ξi,ξ∗

i ≥ 0

i

minimize 1

subject to :

(A2)

(A3)

(A4)

where ξi, ξ∗

the margin: larger error are penalized.

i are ”slack variables”, and C is a free parameter which controls the soft margin. The larger C, the harder

Using Lagrange multiplier analysis, it can be shown that the slope w can be written as:

n(cid:88)
i are the Lagrange multipliers, which satisfy(cid:80)n

w =

i=1

(αi − α∗

i )xi
i=1 αi − α∗

where αi, α∗

i (cid:54)= 0.

Eq. A4 shows that the solution of the minimization problem is a linear combination of a number of input data
points. In other words, the solution is based on a number of support vectors, the number of training samples where
αi − α∗
The above equations use the actual values of the data, assuming that the separation can be performed linearly. For
most high dimension problems, this assumption is not valid any more. The fact that only a scalar product between
the support vectors and the input data is required enables to use the so-called ”kernel trick”. The idea behind the
trick is that one can use functions which satisfy a number of conditions to map the input space to another where the
separation can be performed linearly. Eq. A4 then becomes:

i = 0, and αi, α∗

i ∈ [0, C].

w =

(αi − α∗

i )Φ(xi)

(A5)

n(cid:88)

i=1

where the kernel k(x, x(cid:48)) = (cid:104)Φ(x)Φ(x(cid:48))(cid:105).
Finally, a slightly modiﬁed version of the algorithm (νSVR) allows to determine  and control the number of support

vector. A parameter ν ∈ [0, 1] is introduced such that Eq. A2 becomes

minimize

|w|2 + C(ν +

1
2

ξi + ξ∗
i ).

(A6)

(cid:88)

i

It can be shown that ν is the upper limit on the fraction of errors, and the lower limit of the fraction of support

vectors.

In the regression case described here, the free parameters for νSVR are the trade oﬀ parameter C and all the kernel
parameters (assuming that one ﬁxes ν, which allows control of the error and the fraction of support vectors). In the
classiﬁcation case (νSVC), the free parameters are only those from the kernel which is used, as ν replaces the trade
oﬀ parameter C, and again, one would usually ﬁx ν.

REFERENCES

Albda, E., Garcia-Nieto, J., Jourdan, L., Talbi, E.-G. 2007, Congress on Evolutionary Computation
Arnouts, S., Cristiani, S., Moscardini, L., et al. 1999, MNRAS, 310, 540
Ben´ıtez, N. 2000, ApJ, 536, 571
Bertin, E., & Arnouts, S. 1996, A&AS, 117, 393
Bertin, E., Mellier, Y., Radovich, M., et al. 2002, Astronomical Data Analysis Software and Systems XI, 281, 228
Bertin, E. 2011, Astronomical Data Analysis Software and Systems XX, 442, 435
Boser, B. E., Guyon, I. M., Vapnik, V. N. 1992, Proceedings of the 5th Annual ACM Workshop on Computational Learning Theory, 144
Brammer, G. B., van Dokkum, P. G., & Coppi, P. 2008, ApJ, 686, 1503
Budav´ari, T. 2009, ApJ, 695, 747
Cant´o, J., Curiel, S., & Mart´ınez-G´omez, E. 2009, A&A, 501, 1259
Capak, P., Aussel, H., Ajiki, M., et al. 2007, ApJS, 172, 99
Carliles, S., Budav´ari, T., Heinis, S., Priebe, C., & Szalay, A. S. 2010, ApJ, 712, 511
Cavuoti, S., Garofalo, M., Brescia, M., et al. 2014, New Astronomy, 26, 12

Of Genes and Machines

11

Cawley, G.,& Talbot, N. 2010, Journal of Machine Learning Research, 11, 2079
Collister, A., Lahav, O., Blake, C., et al. 2007, MNRAS, 375, 68
Connolly, A. J., Csabai, I., Szalay, A. S., et al. 1995, AJ, 110, 2655
Conroy, C., White, M., & Gunn, J. E. 2010, ApJ, 708, 58
Cortes, C., Vapnik, V. N. 1995, Machine Learning, 20, 273
Duda, R. O., Hart, P. E., Stork, D. G. 2001, Pattern Classiﬁcation, Wiley
Fadely, R., Hogg, D. W., & Willman, B. 2012, ApJ, 760, 15
Fatemi, M. H., Gharaghani, S. 2007, Bioorganic & Medicinal Chemistry, 15, 24, 7746
Hogan, R., Fairbairn, M., & Seeburn, N. 2015, MNRAS, 449, 2040
Huerta, E. B., Duval, B., Hao, J.-K. 2006, Applications of Evolutionary Computing, 3907, 34
Huertas-Company, M., Aguerri, J. A. L., Bernardi, M., Mei, S., & S´anchez Almeida, J. 2011, A&A, 525, A157
Ilbert, O., Capak, P., Salvato, M., et al. 2009, ApJ, 690, 1236
Ivezic, Z., Tyson, J. A., Abel, B., et al. 2008, arXiv:0805.2366
Kaiser, N., Burgett, W., Chambers, K., et al. 2010, Proc. SPIE, 7733, 77330E
Kron, R. G. 1980, ApJS, 43, 305
Kov´acs, A., & Szapudi, I. 2015, MNRAS, 448, 1305
Krone-Martins, A., Ishida, E. E. O., & de Souza, R. S. 2014, MNRAS, 443, L34
Laureijs, R., Amiaux, J., Arduini, S., et al. 2011, arXiv:1110.3193
Leauthaud, A., Massey, R., Kneib, J.-P., et al. 2007, ApJS, 172, 219
Lilly, S. J., Le F`evre, O., Renzini, A., et al. 2007, ApJS, 172, 70
Liu, C., Bailer-Jones, C. A. L., Sordo, R., et al. 2012, MNRAS, 426, 2463
Magnier, E. 2006, The Advanced Maui Optical and Space Surveillance Technologies Conference, 50
Min, S.-H., Lee, J., Han, I. 2006, Expert Systems with Applications, 31, 3, 652
Nesseris, S. 2011, Journal of Physics Conference Series, 283, 012025
Pedregosa, F., Varoquaux, G., Gramfort, A., et al. 2011, Journal of Machine Learning Research, 12, 2825
Rahman, M., M´enard, B., Scranton, R., Schmidt, S. J., & Morrison, C. B. 2015, MNRAS, 447, 3500
Rest, A., Scolnic, D., Foley, R. J., et al. 2014, ApJ, 795, 44
Robin, A. C., Rich, R. M., Aussel, H., et al. 2007, ApJS, 172, 545
Sanders, D. B., Salvato, M., Aussel, H., et al. 2007, ApJS, 172, 86
Saglia, R. P., Tonry, J. L., Bender, R., et al. 2012, ApJ, 746, 128
Scoville, N., Aussel, H., Brusa, M., et al. 2007, ApJS, 172, 1
Small, E. E., Bersier, D., & Salaris, M. 2013, MNRAS, 428, 763
Smola, A. J., Sch¨olkopf, NeuroCOLT Technical Report NC-TR-98-030
Soumagnac, M. T., Abdalla, F. B., Lahav, O., et al. 2013, arXiv:1306.5236
Spergel, D., Gehrels, N., Baltay, C., et al. 2015, arXiv:1503.03757
Steeb, W. H. 2014, The Nonlinear Workbook, World Scientiﬁc
Stoughton, C., Lupton, R. H., Bernardi, M., et al. 2002, AJ, 123, 485
Szalay, A. S., Connolly, A. J., & Szokoly, G. P. 1999, AJ, 117, 68
Taniguchi, Y., Scoville, N., Murayama, T., et al. 2007, ApJS, 172, 9
Tonry, J. L., Stubbs, C. W., Lykke, K. R., et al. 2012, ApJ, 750, 99
Vapnik V. N. 1995, The Nature of Statistical Learning Theory, Springer-Verlag
Vapnik V. N. 1998, Statistical Learning Theory, Wiley
Vasconcellos, E. C., de Carvalho, R. R., Gal, R. R., et al. 2011, AJ, 141, 189
Wadadekar, Y. 2005, PASP, 117, 79
Wo´zniak, P. R., Williams, S. J., Vestrand, W. T., & Gupta, V. 2004, AJ, 128, 2965
Zhang, Y., & Zhao, Y. 2004, A&A, 422, 1113

