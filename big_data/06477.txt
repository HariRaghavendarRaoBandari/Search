6
1
0
2

 
r
a

M
 
1
2

 
 
]
T
I
.
s
c
[
 
 

1
v
7
7
4
6
0

.

3
0
6
1
:
v
i
X
r
a

Generalized rank weights of reducible codes, optimal cases

and related properties

Umberto Mart´ınez-Pe˜nas ∗

Department of Mathematical Sciences, Aalborg University, Denmark

March 22, 2016

Abstract

Reducible codes for the rank metric were introduced for cryptographic purposes
[7]. They have fast encoding and decoding algorithms, include maximum rank dis-
tance (MRD) codes when Gabidulin codes [6] may not be applied and can correct
many rank errors beyond half of their minimum rank distance, which make them
suitable for network coding [18]. Particular cases constituted by cartesian products
of MRD codes have already been proposed for secure network coding [19]. In this
paper, we give lower and upper bounds on generalized rank weights (GRWs) of gen-
eral reducible codes, which measure information leakage on the network when used
in the form of coset coding [11]. We ﬁnd new parameters for which these codes are
MRD or close to MRD, while having MRD components at the same time. After-
wards we obtain all linear codes with optimal GRWs for all possible ﬁxed packet
and code sizes, up to rank equivalence. We see that all of these optimal codes have
moreover eﬃcient decoding algorithms using any of their bases. Then we see that
the security performance of general reducible codes is better than the threshold
values given by their GRWs. Finally, we study some related properties: We give
conditions for reducible codes to be rank equivalent to cartesian products of linear
codes and conditions to be rank degenerate. We study their duality properties and
MRD ranks, and give new alternative constructions to the classical (u, u + v) con-
struction [16, 2]. A small remark on consequences of the given study on the GPT
cryptosystem is given in the appendix.

Keywords: Cartesian product, generalized rank weight, maximum rank dis-

tance, rank weight, reducible code, secure network coding.

MSC: 94A60, 94B65, 94C99.

1

Introduction

Codes that correct errors with respect to the rank metric (also called rank-metric codes)
have numerous applications, such as network coding [18, 11, 13, 19] or cryptography

∗umberto@math.aau.dk

1

[8, 7]. Among these codes, reducible codes were introduced in [7] as an alternative to
Gabidulin codes [6] to improve the security of the GPT public key cryptosystem [8].

On the other hand, it was shown in [7] that reducible codes have fast encoding and
rank error-correcting algorithms, their minimum rank distance is not worse than the
minimum rank distance of cartesian products of codes, they can correct many rank
errors beyond half of their minimum rank distance, and some of them are maximum
rank distance (MRD) even in the case n > m, where Gabidulin codes [6] may not be
applied as linear codes, and for parameters that they cannot attain. Therefore they are
also suitable codes for error correction in network coding, specially in the case n > m.
On the other hand, coset coding has been traditionally considered for protecting
information from leakage over wire-tap channels [15, 22], and coset coding using rank-
metric codes has been proposed recently for wire-tap networks, ﬁrst in [5] and further
in [11, 19]. In the wire-tap channel of type II, generalized Hamming weights (GHWs)
were introduced in [21] to measure the security performance of coset coding. Similarly,
generalized rank weights (GRWs) have been introduced independently in [14] and [11]
to measure the security performance of coset coding for wire-tap networks.

In this paper, we study GRWs of reducible codes and their security performance.
The idea is to express properties of reducible codes in terms of the smaller codes they
are formed of. GRWs of families of rank-metric codes have been obtained only for the
family of MRD codes for n ≤ m, which are given by the classical Singleton bound [11,
Corollary 2], and cyclic codes with minimal weights [4]. Hence we give for the ﬁrst
time non-trivial bounds and exact values of GRWs for a particular family of rank-metric
codes.

After some preliminaries in Section II, the new results in this paper are organized
as follows: In Section III, we discuss diﬀerent reductions of reducible codes in order
to see which of their components can be modiﬁed in order to improve bounds on their
parameters. In Section IV, we give lower and upper bounds on the GRWs of reducible
codes, extending the lower bound on the minimum rank distance given in [7], and see
that the given upper bound can be reached by some reduction. In Section V, we obtain
new parameters for which reducible codes are MRD (or close to MRD) and with MRD
components, and obtain explicit estimates on their GRWs, including those MRD codes
found in [7] and considered for secure network coding in [19]. In Section VI, we obtain
all linear codes with optimal GRWs for all ﬁxed packet and code sizes, up to rank
equivalence. Moreover, we see that these codes are built using one-dimensional Gabidulin
codes, have the minimum length required by the optimality of GRWs and have eﬃcient
decoding algorithms using any of their bases. In Section VII, we see that the security
performance of general reducible codes is usually better than the threshold values given
by their GRWs. Finally, in Section VIII, we study related properties of reducible codes.
We obtain conditions for them to be rank equivalent to cartesian products and conditions
to be rank degenerate. We study their duality properties and MRD ranks. Finally, we
propose alternative constructions to the classical (u, u+v) construction, since these codes
are rank equivalent to the cartesian products of their components. In the appendix, a
small remark on the GPT cryptosystem is given.

2

2 Deﬁnitions and preliminaries

Fix a prime power q and positive integers m and n, and let Fqs denote the ﬁnite ﬁeld
with qs elements for a positive integer s.

2.1 Rank-metric codes

qm is just a subset C ⊆ Fn

A code in Fn
qm. Unless otherwise stated, all codes in this
paper will be considered linear, meaning Fqm-linear.
In general, linearity will mean
Fqm-linearity. The term “rank-metric code” is used for codes whose rank properties are
considered, which we will now deﬁne.

Consider a basis α1, α2, . . . , αm of Fqm over Fq. For each c ∈ Fn

q , for i = 1, 2, . . . , m, such that c =Pm

qm, there exist unique
ci ∈ Fn
i=1 αici. We represent by M (c) the m × n
matrix over Fq whose i-th row is ci. The rank support of c [11] is the row space (in Fn
q ) of
the matrix M (c), denoted by RSupp(c), and its rank weight [6] is wtR(c) = Rk(M (c)),
the rank of M (c). Both are independent of the basis α1, α2, . . . , αm.

In a similar way, given a linear subspace D ⊆ Fn

Pc∈D RSupp(c) and its rank weight [9] is wtR(D) = dim(RSupp(D)). Observe that

RSupp(hci) = RSupp(c) and wtR(hci) = wtR(c), for all c ∈ Fn

qm.

qm, its rank support [9] is RSupp(D) =

2.2 Generalized rank weights and security in linear network coding

A network is usually considered as a directed graph, whose vertices are called nodes and
whose edges are called links, and are all considered as channels with unit capacity.

qm, which is seen as n packets in Fm

A given source node wants to convey k packets in Fm

q to one or several sink nodes,
and encodes them into a vector c ∈ Fn
q . “Linear
network coding”, ﬁrst considered in [1], is deﬁned as the process by which, in each node
of the network, linear combinations of the received packets are generated and sent (see
[10, Deﬁnition 1]). This means that a given source is assumed to receive a vector of the
form y = cAT ∈ FN
, called transfer matrix. If the sink
receives a vector of the form y = cAT + e, for some e ∈ FN
qm with t = wtR(e), we say
that t errors occurred [18].

qm, for some matrix A ∈ FN ×n

q

In this context, a wiretapping adversary is assumed to obtain µ linear combinations
of the n packets sent. In other words, he or she obtains a vector of the form cBT for
some matrix B ∈ Fµ×n
(see [19, Section V]), or cBT + e′ if errors occurred, which by [11,
Proposition 5] give no extra information than cBT . To protect the original k packets
from leakage to the adversary, the coset coding scheme introduced by Ozarow and Wyner
[15] has been considered ﬁrst in [5] and then in [11, 19].

q

Deﬁnition 1 ([15]). Given a linear code C ⊆ Fn
coding scheme as follows: Fix a generating matrix G ∈ Fk×n
choose at random, with some given distribution, an element c ∈ Fn
Then c is the encoded vector.

qm of dimension k, we deﬁne its coset
qm,
qm such that x = cGT .

qm of C. For each x ∈ Fk

3

We will consider uniform distributions throughout the paper. The information leaked
to a wiretapping adversary when using coset coding was obtained in [19, Lemma 6], and
then generalized in [11, Lemma 7] to the more general nested coset coding schemes from
[22].

codes C, V ⊆ Fn

We will use the description in [11]. Denote [i] = qi for an integer i ≥ 0. Given linear
qm, we say that V is Galois closed if V q ⊆ V [20], and deﬁne the Galois
i=0 C [i] [20], which is the smallest Galois closed linear code
qm is Galois closed if, and only if, it admits a

closure of C as C ∗ = Pm−1

containing C. By [20, Lemma 1], V ⊆ Fn
basis of vectors in Fn
q .

Lemma 1 ([19, Lemma 6], [11, Lemma 7]). Given a linear code C ⊆ Fn
qm and a
matrix B ∈ Fµ×n
qm and
by W the random variable XBT if X is the encoding of S by the coset coding scheme
using C in Deﬁnition 1. It holds that

, represent by S the uniform random variable taking values in Fk

q

I(S; W ) = dim(C ∩ V ),

(1)

where I(S; W ) represents the mutual information of the variables S and W , taking log-
arithms with base qm and V ⊆ Fn
qm denotes the linear Galois closed space generated by
the rows of B ∈ Fµ×n

.

q

This motivates the deﬁnition of generalized rank weights, introduced independently

in [14] for n ≤ m, and in [11] for the general case. We use the description in [11]:

Deﬁnition 2 ([11, Deﬁnition 2]). Given a linear code C ⊆ Fn
deﬁne its r-th generalized rank weight (GRW), for 1 ≤ r ≤ k, as

qm of dimension k, we

dR,r(C) = min{ dim(V ) | V ⊆ Fn

qm linear and

V = V ∗, dim(C ∩ V ) ≥ r}.

We also deﬁne dR,0(C) = 0 for convenience.

In other words, dR,r(C) is the minimum number of linearly independent linear com-
binations of the components of the encoded vector c ∈ Fn
qm that an adversary needs to
obtain in order to be guaranteed to gain at least “r packets in Fqm” of information about
the original ones.

Moreover, as proven in [11, Corollary 1], it holds that dR,1(C) is the minimum rank
distance of the code C (also denoted dR(C)), hence GRWs actually generalize the mini-
mum rank distance. In [9], the following characterization is given:

Lemma 2 ([9, Theorem 16, Corollary 17]). Given a linear code C ⊆ Fn
sion k and 1 ≤ r ≤ k, it holds that

qm of dimen-

dR,r(C) = min{wtR(D) | D ⊆ C, linear and

dim(D) = r}.

Moreover, it holds that wtR(D) = dim(D∗), for a given linear code D ⊆ Fn
also valid for r = 0 deﬁning wtR({0}) = 0.

qm. This is

4

We include the Singleton bound for the minimum rank distance of a code C ⊆ Fn
qm

of dimension k:

dR,1(C) ≤ n − k + 1,

if n ≤ m,

dR,1(C) ≤

m
n

(n − k) + 1,

if n > m.

(2)

(3)

The ﬁrst was obtained in [6] and the second in [12]. As usual in the literature, we will
say that C is maximum rank distance (MRD) if dR,1(C) attains the previous bound.

2.3 Rank equivalences and rank degenerateness

We will also make use of the concept of rank equivalence. If V ⊆ Fn
qm are
linear and Galois closed, we say that a map φ : V −→ V ′ is a rank equivalence if it is
a vector space isomorphism and wtR(φ(c)) = wtR(c), for all c ∈ V . As in [13], we say
that two codes C and C ′ are rank equivalent if there exists a rank equivalence between
linear Galois closed spaces V and V ′ that contain C and C ′, respectively, and mapping
bijectively C to C ′.

qm and V ′ ⊆ Fn′

The following theorem states that rank equivalent codes behave exactly in the same
way regarding not only rank error and erasure correction, but also information leakage
on networks, when used for coset coding, due to Lemma 1:

Lemma 3 ([13, Theorem 5]). Given a linear vector space isomorphism φ : V −→
V ′, where V ⊆ Fn
qm are linear Galois closed spaces, the following are
equivalent:

qm and V ′ ⊆ Fn′

1. φ preserves rank weights, that is, wtR(φ(c)) = wtR(c), for all c ∈ V .

2. For all linear subspaces D ⊆ V , it holds that wtR(φ(D)) = wtR(D).

3. A linear subspace U ⊆ V is Galois closed if, and only if, φ(U ) ⊆ V ′ is Galois

closed.

4. There exists β ∈ F∗

q

qm = Fqm \ {0} and a linear vector space isomorphism φ′ : V −→
V ′ such that φ′(V |Fq ) ⊆ V ′|Fq and φ(c) = βφ′(c), for every c ∈ V . Equivalently,
there exists a matrix A ∈ Fn×n′
qm such that φ(c) = βcA, for every
c ∈ V .

and β ∈ F∗

In particular, if C and C ′ are rank equivalent linear codes, then they have the same

GRWs:

for all r = 1, 2, . . . , k.

dR,r(C) = dR,r(C ′),

Observe that rank equivalent codes may have diﬀerent lengths. In network coding
(following the model in [18, 11]), the length n of a linear code C ⊆ Fn
qm represents the
number of outgoing links from the source or the number of packets that the source needs
to send (per time slot), whereas the value m represents the length of each packet. In
particular, we may deﬁne rank degenerate codes as those that are rank equivalent to a
linear code of smaller length.

5

Deﬁnition 3 ([13, Deﬁnition 9]). A linear code C ⊆ Fn
degenerate if dR,k(C) < n.

qm of dimension k is rank

See [9, 13] for more details on and characterizations of rank degenerate codes.

2.4 Some existing code constructions

We brieﬂy revise two existing code constructions that have already been considered in
the literature:

1. Assume n ≤ m and 1 ≤ k ≤ n: Take elements β1, β2, . . . , βn ∈ Fqm that are linearly

independent over Fq. The linear code C ⊆ Fn

qm generated by the matrix



β1
β[1]
1
...

β2
β[1]
2
...

β[k−1]
1

β[k−1]
2

βn
β[1]
n
...

. . .
. . .
. . .
. . . β[k−1]

n



has dimension k and minimum rank distance dR,1(C) = n − k + 1, and hence is
MRD. These codes are known as Gabidulin codes and were introduced in [6]. Their
GRWs were given in [11, Corollary 2]: dR,r(C) = n − k + r.

2. Assume n = lm and k = lk′, for some positive integers l and k′ ≤ m: The
qm deﬁned as C = C1 × C2 × · · · × Cl, where each Ci ⊆ Fm
linear code C ⊆ Fn
qm
is a k′-dimensional Gabidulin code, has dimension k and minimum rank distance
dR,1(C) = m − k + 1, and hence is also MRD. These codes were introduced in [7,
Corollary 1] and considered in [19, Section VII.C] for secure network coding. In
contrast with Gabidulin codes, although a ﬁrst analysis of these codes is given in
[19], their GRWs are still not known. We will ﬁnd all of them in Section 5.2.

The two previous constructions are particular cases of reducible codes, introduced in

[7], which we will study in the rest of the paper.

3 Reducible codes and reductions

Consider positive integers l, n1, n2, . . . , nl and linear codes C1 ⊆ Fn1
qm, with dimensions k1, k2, . . . , kl, respectively. Let Gi ∈ Fki×ni
Fnl
of Ci, for i = 1, 2, . . . , l, and consider matrices Gi,j ∈ F
i + 1 ≤ j ≤ l.

qm
ki×nj
qm

qm, C2 ⊆ Fn2
qm, . . . , Cl ⊆
be a generator matrix

, for 1 ≤ i ≤ l − 1 and

Deﬁnition 4 ([7, Deﬁnition 2]). We say that a linear code C ⊆ Fn

qm is reducible with

6

reduction R = ((Gi)1≤i≤l, (Gi,j )i+1≤j≤l

1≤i≤l−1) if it has a generator matrix of the form

G =



G1 G1,2 G1,3
0 G2 G2,3
G3
0
...
...
0
0
0
0

0
...
0
0

. . . G1,l−1 G1,l
. . . G2,l−1 G2,l
. . . G3,l−1 G3,l
...
. . .
. . . Gl−1 Gl−1,l
. . .

0

Gl

...

.



The length of the code C is n = n1 + n2 + · · · + nl and its dimension is k =
k1 + k2 + · · · + kl. C is the cartesian product of the codes C1, C2, . . . , Cl if Gi,j = 0, for
all i, j.

Deﬁnition 5. For a given reduction R as in the previous deﬁnition, we deﬁne the main
components as the linear codes C1, C2, . . . , Cl, the row components as the linear codes
C ′

qm with generator matrix

i ⊆ Fn

G′

i = (0, . . . , 0, Gi, Gi,i+1, . . . , Gi,l),

for i = 1, 2, . . . , l, and the column components as the linear codes bCj ⊆ F

by the matrix

for j = 1, 2, . . . , l, which need not be full rank.

(4)

nj
qm generated

(5)

bGj = (G1,j, G2,j , . . . , Gj−1,j)T ,
i), bkj = dim(bCj) ≥ kj, C = C ′

It holds that ki = dim(C ′

1 ⊕ C ′

2 ⊕ · · · ⊕ C ′

l and

We have the following on the uniqueness of reductions of a given reducible code.

C ⊆ bC = bC1 × bC2 × · · · × bCl.
Proposition 1. Given another reduction bR of C with the same row and column block
sizes as R, it holds that the main components and column components of bR and R are

the same, respectively.

Proof. See Appendix A.

Proposition 2. Assume that the main components of the reduction R of C are not rank
degenerate. Let R′ be a reduction of a linear code C ′ that is rank equivalent to C, with
the same row and column block sizes as R, and such that the rank equivalence maps the
generator matrix corresponding to R to that of R′. Then the main components and row
components of R′ and R are rank equivalent, respectively.

Proof. See Appendix A.

Remark 1. The previous two propositions suggest that changing the row components
and column components of a given reducible code may give diﬀerent results, and suggest
how this may happen. This is the case of the bounds on their GRWs, as we will see later
in the paper.

7

4 Bounds

With notation as in the previous section, it is proven in [7, Lemma 2] that

dR,1(C) ≥ min{dR,1(C1), dR,1(C2), . . . , dR,1(Cl)}.

(6)

In the next theorem we generalize this lower bound to higher weights, and give also upper
bounds. We need the following lemma, which will prove to be useful also in Section 7:

Lemma 4. With notation as in Section 3, given a linear subspace D ⊆ C of dimension
r ≤ k = dim(C), there exist (unique) integers 1 ≤ t ≤ l, i1, i2, . . . , it ∈ {1, 2, . . . , l} and
1 ≤ riu ≤ kiu, 1 ≤ u ≤ t, such that r = ri1 + ri2 + · · · + rit and there exists a basis of D
of the form

b(iu)
1

, b(iu)

2

, . . . , b(iu)
riu

,

1 ≤ u ≤ t,

where

c′
i,j ∈ C ′
all u. In particular, D is again reducible.

i, for all i and j, and where c′

b(iu)
j = c′

iu,j + c′
iu,1, c′

iu+1,j + · · · + c′
iu,2, . . . , c′

iu,riu

l,j,

are linearly independent, for

Proof. We will prove it by induction on l. For l = 1, the lemma is trivial. Fix now l > 1
and assume that it is true for all positive integers smaller than l.

Take some basis b1, b2, . . . , br of D. We can write these vectors uniquely in the

following way

bj = c′

1,j + c′

2,j + · · · + c′

l,j,

with c′

i,j ∈ C ′

i, for i = 1, 2, . . . , l and j = 1, 2, . . . , r.

Deﬁne i1 as the minimum index such that there exists a j with c′

ing linear combinations and reordering the indices, we may assume that c′
are linearly independent and c′
i1,j = 0, for some ri1 > 0 and all j > ri1.

i1,j 6= 0. By perform-
i1,2, . . . , c′

i1,1, c′

i1,ri1

Since c′

s,j = 0, for 1 ≤ s ≤ i1 and j > ri1, it holds that D− = hbri1 +1, bri1 +2, . . . , bri
is contained in the code C − = C ′
l, which is again reducible, with
l − i1 < l main components. By induction hypothesis, D− has a basis as wanted, which
together with b1, b2, . . . , bri1 gives the desired basis of D after renaming indices.

i1+2 ⊕ · · · ⊕ C ′

i1+1 ⊕ C ′

Uniqueness of the given integers follows from Proposition 1.

Theorem 1. With notation as in Section 3, for every 1 ≤ r ≤ k, we have that

dR,r(C) ≥ min{dR,r1(C1) + dR,r2(C2) + · · · + dR,rl(Cl)

| r = r1 + r2 + · · · + rl, 0 ≤ ri ≤ ki},

and

dR,r(C) ≤ min{dR,r1(C ′

1) + dR,r2(C ′

2) + · · · + dR,rl(C ′
l)
| r = r1 + r2 + · · · + rl, 0 ≤ ri ≤ ki}.

(7)

(8)

8

Proof. We ﬁrst prove the bound (7) using the deﬁnition of GRWs given in Lemma 2.
Take an r-dimensional linear subspace D ⊆ C and its basis as in the previous lemma.
For all u = 1, 2, . . . , t and j = 1, 2, . . . , l, deﬁne ciu,j ∈ Ciu as the projection of c′
iu,j onto
the coordinates corresponding to Ciu. Computing dim(D∗), it holds that

wtR(D) ≥

≥

tXu=1
tXu=1

wtR(hciu,1, ciu,2, . . . , ciu,riu i)

dR,riu (Ciu),

and the bound follows by Lemma 2.

To prove the bound (8), just take a decomposition r = r1 + r2 + · · · + rl, with
i with dim(Di) = ri and
i). Then deﬁne the linear subspace D = D1 ⊕ D2 ⊕ · · · ⊕ Dl ⊆ C,
l . Hence

0 ≤ ri ≤ ki, for i = 1, 2, . . . , l, and take linear subspaces Di ⊆ C ′
wtR(Di) = dR,ri(C ′
which satisﬁes dim(D) = r. By deﬁnition, it holds that D∗ = D∗

2 + · · · + D∗

1 + D∗

wtR(D) ≤ wtR(D1) + wtR(D2) + · · · + wtR(Dl)
2) + · · · + dR,rl(C ′

1) + dR,r2 (C ′

= dR,r1(C ′

l),

and the result follows by Lemma 2.

Remark 2. Observe that the bound (8) is valid with the same proof for a general linear
2 ⊕ · · · ⊕ C ′
code that can be decomposed as a direct sum of linear subcodes C = C ′
l.
Thus, the bound (7) gives the bound (6) for the minimum rank distance (the case

1 ⊕ C ′

r = 1), and the bound (8) gives the following (immediate) upper bound:

dR,1(C) ≤ min{dR,1(C ′

1), dR,1(C ′

2), . . . , dR,1(C ′

l)}.

(9)

We obtain the following immediate consequence of Theorem 1:

Corollary 1. If C = C1 × C2 × · · · × Cl and 1 ≤ r ≤ k, with notation as before, then

dR,r(C) = min{dR,r1(C1) + dR,r2(C2) + · · · + dR,rl(Cl)

| r = r1 + r2 + · · · + rl}.

(10)

Remark 3. In the general setting of Theorem 1, the same result as in the previous
corollary holds whenever Ci and C ′
i are rank equivalent, for each i = 1, 2, . . . , l, since in
that case it holds that dR,r(Ci) = dR,r(C ′
i) for all i = 1, 2, . . . , l and all r = 1, 2, . . . , ki.

We illustrate Theorem 1 with the following example that includes the MRD linear

codes in Subsection 2.4, item 2, for l = 2:

Example 1. With notation as in Theorem 1, assume that l = 2, n1, n2 ≤ m, k1 ≤ k2
and take C1 and C2 as MRD codes (the matrix G1,2 can be arbitrary). In particular,
dR,ri(Ci) = ni − ki + ri [11] as in Subsection 2.4, 1 ≤ ri ≤ ki, i = 1, 2. We estimate
dR,r(C) considering three cases:

9

1. Assume 1 ≤ r ≤ k1: The bounds (7) and (8) give

min{n1 − k1, n2 − k2} + r ≤ dR,r(C) ≤ n2 − k2 + r.

2. Assume k1 < r ≤ k2 (if k1 < k2): In this case, in both bounds in Theorem 1,
it is necessary that r2 > 0. Hence, these bounds coincide and give the value
dR,r(C) = n2 − k2 + r.

3. Assume k2 < r ≤ k: As in the previous case, now it is necessary that r1 > 0 and
r2 > 0, and thus Theorem 1 gives the value dR,r(C) = n − k + r, which is optimal
by the Singleton bound [11, Proposition 1].

From Proposition 1 and Proposition 2 we see that we may not obtain diﬀerent lower
bounds in (7) by changing the main components of a reduction. However, Proposition 1
suggests that we may obtain diﬀerent upper bounds in (8) by changing the row compo-
nents. Actually, the minimum rank distance always reaches this upper bound for some
particular reduction:

Proposition 3. With notation as in Theorem 1, there exists a reduction bR = ((Gi)1≤i≤l, (bGi,j )i+1≤j≤l

of C such that the bound (9) is an equality.

1≤i≤l−1)

Proof. Assume that the minimum rank distance is attained by wtR(c) = dR,1(C), for
c ∈ C. It holds that c = c′
i (recall (4)), for
some xi ∈ Fki

qm and all i = 1, 2, . . . , l.

2 + · · · + c′

l, with c′

i, and c′

i = xiG′

i ∈ C ′

1 + c′

We may assume without loss of generality that x1 6= 0. We just need to choose
ki×nj
qm , for 1 ≤ i ≤ l − 1 and i + 1 ≤ j ≤ l, such that

k1×kj
qm

matrices A1,j ∈ F
the k × k matrix

and bGi,j ∈ F

A =



I A1,2 A1,3
0
0
...
0
0

I
0
...
0
0

0
I
...
0
0

. . . A1,l−1 A1,l
0
. . .
0
. . .
...
. . .
0
. . .
. . .
I

0
0
...
I
0



satisﬁes that G = AbG, where bG is the generator matrix corresponding to bR = ((Gi)1≤i≤l, (bGi,j )i+1≤j≤l

1≤i≤l−1),

and

x1A1,j = −xj,

for j = 2, . . . , l.

It is possible to choose such matrices A1,j because x1 6= 0. Then

c = (xA)bG lies in the ﬁrst row component of the reduction bR and hence dR,1(C) =

1), implying the result.

wtR(c) ≥ dR,1(C ′

5 MRD reducible codes with MRD main components

In this section we tackle the problem of ﬁnding good reducible linear codes C ⊆ Fn
qm
when n > m, that is, reducible codes with minimum rank distance close to the Singleton

10

bound (3). We will ﬁnd new parameters for which reducible codes are MRD and we will
estimate their GRWs. In the last subsection we will compare the given constructions
with other code constructions in the literature.

5.1 Searching for optimal reducible codes

Assume n > m and ﬁx an integer 1 ≤ k ≤ n. In view of the bound (6), we will consider
a reducible code C ⊆ Fn
qm of dimension k whose main components C1, C2, . . . , Cl (with
notation as in Section 3) have as similar parameters as possible. This will allow to obtain
reducible codes with minimum rank distance close or equal to (3).

We deﬁne the following parameters:

1. There exist unique l > 0 and 0 ≤ t ≤ m − 1 such that

n = lm − t.

2. There exist unique k′ > 0 and 0 ≤ s ≤ l − 1 such that

k = lk′ − s.

3. Deﬁne then

4. Finally, deﬁne

a =(cid:24) km

n (cid:25) − k′,

and b =(cid:24) t

l(cid:25) − 1.

t′ = l(m − b) − n,

which satisﬁes 0 < t′ ≤ l.

We observe the following:

Lemma 5. It holds that k′ ≤ m − b if b ≥ 0, and k′ ≤ m if b = −1.

Proof. For b = −1, we have that t = 0 and k = lk′−s ≤ n = lm implies that k′ ≤ m+s/l.
Since s < l, the result holds in this case.

Now assume that b ≥ 0. We have that k + s ≤ n + l. Writing k and n as above, this

inequality reads

(lk′ − s) + s ≤ (lm − t) + l,

that is, lk′ + t ≤ l(m + 1) and, dividing by l, it is equivalent to

k′ +

t
l

− 1 ≤ m.

The result follows by deﬁnition of b.

For the code construction, we distinguish diﬀerent cases:

11

Deﬁnition 6. Deﬁne the reducible linear code eC ⊆ Fn

components C1, C2, . . . , Cl as follows:

qm of dimension k with MRD main

1. If t = 0 (i.e. b = −1): Choose C1, C2, . . . , Cl such that l − s of them have length
m and dimension k′, and s of them have length m and dimension k′ − 1. By (6),
we have that

dR,1(eC) ≥ m − k′ + 1.

2. If t > 0 and t′ ≤ s: Choose C1, C2, . . . , Cl such that l − s of them have length m − b
and dimension k′, s − t′ of them have length m − b and dimension k′ − 1, and t′ of
them have length m − b − 1 and dimension k′ − 1. By (6), we have that

dR,1(eC) ≥ m − b − k′ + 1.

3. If t > 0 and t′ > s: Choose C1, C2, . . . , Cl such that l − t′ of them have length
m − b and dimension k′, t′ − s of them have length m − b − 1 and dimension k′,
and s of them have length m − b − 1 and dimension k′ − 1. By (6), we have that

Observe that the deﬁnition is consistent by the previous lemma and the choices of

dR,1(eC) ≥ m − b − k′.

parameters. We have the following, which is immediate from the deﬁnitions:

Lemma 6. It holds that

j m

n

(n − k) + 1k = m − a − k′ + 1.

otherwise.

Hence the diﬀerence between (3) and dR,1(eC) is b − a if t > 0 and t′ ≤ s, and is b − a + 1
It is therefore of interest to upper bound the diﬀerence b − a to see how close dR,1(eC)

is to the bound (3). In the following cases, we obtain MRD codes or codes that diﬀer
from the Singleton bound (3) by 1:

Theorem 2. Assume that 0 ≤ t ≤ l or n ≥ m2. The following holds:

1. If t ≤ s or tk′ > ms, then

2. If t > s and tk′ ≤ ms, then

n

dR,1(eC) =j m
dR,1(eC) ≥j m

(n − k) + 1k .
(n − k)k .

n

12

Proof. First assume that n ≥ m2. Since n = lm − t ≥ m2 and t ≥ 0, it holds that l ≥ m.

Therefore t ≤ m − 1 ≤ l − 1 and hence we may assume 0 ≤ t ≤ l. Denote d = dR,1(eC)

Before considering the diﬀerent cases, we will see that a ≥ 0 and a = 0 if, and only

in the rest of the proof.

if, k′t ≤ sm. First it holds that −1 < km/n − k′ if, and only if,

(k′ − 1)n < km.

Using that n = lm − t and k = lk′ − s, and rearranging terms, this inequality reads

sm + (k′ − 1)t < lm + n,

which is always true since s < l and k′t ≤ k ≤ n. Hence a ≥ 0. On the other hand,
km/n − k′ ≤ 0 if, and only if,

nk′ ≥ km.

Using again that n = lm − t and k = lk′ − s, and rearranging terms, this inequality reads
k′t ≤ sm. This is then the case when a = 0.

Assume ﬁrst that t = 0, then d ≥ m − k′ + 1 and a = 0, hence the result follows in

this case.

Now assume that 0 < t ≤ s. Then d ≥ m − k′ + 1 (since b = 0) and k′t ≤ sm holds,

since k′ ≤ m. Then a = 0 and the result follows in this case.

Next assume that tk′ > ms. Then we know that a ≥ 1 and

j m

n

(n − k) + 1k ≤ m − k′.

Since b = 0, we know that d ≥ m − k′, hence the result follows in this case.

Finally, assume that t > s and tk′ ≤ ms. Then we know that a = b = 0 and

d ≥ m − b − k′. Therefore the result follows also in this case and we are done.

Remark 4. Observe that the reducible MRD linear codes in Subsection 2.4, item 2, are

the subfamily of the codes eC obtained by choosing t = s = 0, and hence are particular

cases of the codes in the previous theorem.

Remark 5. Observe that the conditions 0 ≤ t ≤ l and n ≥ m2 only depend on m and
n, but not on k. Hence, for the previous families of values of n and m, we have obtained
MRD or almost MRD linear codes for all dimensions.

Remark 6. In general, the diﬀerence b − a will be big if t is much bigger than l. As

n grows, the fact t > l happens for fewer values of t. Hence the codes eC are far from

optimal when n is small compared to m (still n > m) and t is much bigger than l.

5.2 Estimates on their GRWs

In this subsection, we will estimate the GRWs of the MRD (or almost MRD) linear

reducible codes eC from Theorem 2, using the lower bound (7).

13

Theorem 3. Assume that 0 ≤ t ≤ l or n ≥ m2, as in Theorem 2. Assume ﬁrst t ≤ s,
then:

1. If 1 ≤ j ≤ l − s and (j − 1)k′ < r ≤ jk′, or if l − s < j ≤ l − s + t and

(j − 1)(k′ − 1) + l − s < r ≤ j(k′ − 1) + l − s, then

2. If l − s + t < j ≤ l and (j − 1)(k′ − 1) + l − s < r ≤ j(k′ − 1) + l − s, then

dR,r(eC) ≥ j(m − k′) + r.

Assume now that t > s.

dR,r(eC) ≥ j(m − k′) + r + (j − l + s − t).

1. If 1 ≤ j ≤ t − s and (j − 1)k′ < r ≤ jk′, then

2. If t−s < j ≤ l−s and (j−1)k′ < r ≤ jk′, or if l−s < j ≤ l and (j−1)(k′−1)+l−s <

dR,r(eC) ≥ j(m − k′ − 1) + r.

r ≤ j(k′ − 1) + l − s, then

dR,r(eC) ≥ j(m − k′) + r − t + s.

In all the previous cases, if eC is the cartesian product of its main components C1, C2, . . . , Cl,
then the previous lower bounds are equalities. In particular, eC is not rank degenerate.

Proof. The result follows from Theorem 1. To see it, we just have to use that dR,ri(Ci) =
ni−ki+ri and see in which way we have to choose ri = 0 or ri > 0 to obtain the minimum
in the bound (7). This constitutes a straightforward extension of the calculations in
Example 1.

5.3 Comparison with other code constructions

In this subsection we will compare the codes eC from Deﬁnition 6 with other codes from

For an arbitrary (linear or non-linear) code C ⊆ Fn

the literature.

qm, the Singleton bound can be

written as

or in other words,

#C ≤ qmax{n,m}(min{n,m}−dR(C)+1),

dR(C) ≤ min{n, m} −

logq(#C)
max{n, m}

+ 1.

Codes attaining this bound are called maximum rank distance (MRD), as in the linear
case. If C is linear (meaning Fqm-linear as in the rest of the paper), then this bound
gives the bounds (2) and (3).

14

On the other hand, assume that C ⊆ Fm

qn is Fqn-linear and MRD. Deﬁne the code
qm obtained by transposing the matrix representations of every codeword in C.
qm is Fq-linear, dR(C T ) = dR(C), dimFq (C T ) = dimFq (C) and C T is again

C T ⊆ Fn
Then C T ⊆ Fn
MRD.

Therefore, one could argue that, using the codes C T deﬁned in the previous para-

improvement with respect to the former ones. We now argue the advantages of the codes

graph, one obtains MRD codes for all parameters and the codes eC do not give an essential
eC over the codes C T :

1. Measuring information leakage: When using a rank-metric code for coset coding
to protect information from a wire-tapping adversary on a network, the known
analyses on measuring information leakage from the literature tend to assume that
the used code is linear (meaning Fqm-linear if C ⊆ Fn
qm). See for instance [11, 19].
In particular, the method of generalized rank weights [11, 14, 3, 9, 13] works only
in the linear case. A reﬁnement of these weights has been introduced in [17] for
general Fq-linear codes. However, its connection to information leakage is only
obtained again in the linear case.

Hence, no method seems to be known to formally measure information leakage for

2. Encoding complexity: Since the codes C T are built from C ⊆ Fm

qn, which are Fqn-
linear, its encoding is performed by matrix multiplications with coeﬃcients in Fqn,

the codes C T , whereas generalized rank weights can be applied for the codes eC.
whereas the encoding for eC is performed by matrix multiplications with coeﬃcients
higher than that of eC.
Moreover, since the codes eC can be constructed as cartesian products, they may

in Fqm.
Since we are assuming n > m, the operational complexity of encoding with C T is

have very sparse generator matrices, which reduces the encoding complexity.

3. Possible parameters obtained: Since the codes C T are obtained from Fqn-linear
codes, their sizes are of the form qN , where N is some multiple of n, whereas the

Since we are assuming n > m, in a given interval of positive integers, there are

sizes of the codes eC are of the form qM , where M is some multiple of m.
usually more possible parameters attained by the codes eC than by the codes C T .
codes eC have a stronger performance regarding both information leakage and error

4. Stronger security than threshold values: Although the minimum rank distance
(and GRWs for the linear case) gives a threshold value on information leakage, the

correction, as we will see in Section 7.

15

6 All codes with optimal GRWs for all ﬁxed packet and

code sizes

Fix k and m in the rest of this section. We will obtain, up to rank equivalence, all linear
codes with optimal GRWs for the values k and m, which correspond to the code size
and packet size, respectively. We start with the following lemma given in [13]:

Lemma 7 ([13, Lemma 11]). Given a linear code C ⊆ Fn
1 ≤ r ≤ k − 1, it holds that

qm of dimension k, for each

1 ≤ dR,r+1(C) − dR,r(C) ≤ m.

On the other hand, recall also from [13] the following upper bound for a given linear

code C ⊆ Fn

qm of dimension k, and 1 ≤ r ≤ k:

dR,r(C) ≤ rm.

(11)

Observe that it follows immediately from the previous lemma and the fact that dR,1(C) ≤
m. Observe also that dR,r(C) = rm for all 1 ≤ r ≤ k if, and only if, dR,k(C) = km, also
by the previous lemma.

Observe that this bound only depends on the packet and code sizes, which are mea-

sured by m and k, respectively, and it does not depend on the length n.

We see in the next proposition that GRWs of cartesian products of one-dimensional

Gabidulin codes attain the bound (11):

Proposition 4. Let C ⊆ Fkm
qm be the linear code C = C1 × C2 × · · · × Ck, where all Ci are
equal to the one-dimensional Gabidulin code generated by the vector (α1, α2, . . . , αm), as
in Subsection 2.4, where α1, α2, . . . , αm ∈ Fqm are linearly independent over Fq.

Then dim(C) = k and dR,r(C) = rm, for 1 ≤ r ≤ k.

Proof. It can be proven from Theorem 3, but we can give a direct proof. C has a basis
of the form v1, v2, . . . , vk, where

vi =

mXj=1

αje(i−1)m+j ∈ Fkm
qm ,

for 1 ≤ i ≤ k, and where the vectors ei are the vectors in the canonical basis of Fkm
qm .
Therefore,

RSupp(vi) = he(i−1)m+1, e(i−1)m+2, . . . , e(i−1)m+mi,

from where it follows that RSupp(C) =Pk

and hence, dR,k(C) =
dim(C ∗) = km by Lemma 2. Finally, this implies that dR,r(C) = rm, for every r =
1, 2, . . . , k, by Lemma 7.

i=1 RSupp(vi) = Fkm

q

16

Remark 7. In network coding, following the model in [18, 11] as stated in Subsection
2.2, given a linear code C ⊆ Fn
qm of dimension k, the parameter m represents the packet
length, k represents the number of linearly independent packets that we may send using
C, or its size, and n represents the number of packets the source needs to send.

Hence, if m and k are ﬁxed and n is not restricted, then the code in the previous

proposition behaves optimally regarding information leakage in the network.

Moreover, this is the unique linear code with these optimal parameters up to rank
equivalence, as we will prove now. We introduce some notation. For a given c =
(c1, c2, . . . , cn) ∈ Fn
n ), for all integers i ≥ 0. Then we
deﬁne the trace map Tr : Fn

qm, deﬁne c[i] = (c[i]

q of the extension Fq ⊆ Fqm as follows

2 , . . . , c[i]

qm −→ Fn

1 , c[i]

Tr(c) = c + c[1] + c[2] + · · · + c[m−1],

for all c ∈ Fn

qm. We will need the following two lemmas:

Lemma 8. For a basis α1, α2, . . . , αm ∈ Fqm of Fqm over Fq, the matrix A = (α[j−1]
over Fqm is invertible.

i

)1≤i,j≤m

Proof. Well-known. See for instance [6].

Lemma 9. For a basis α1, α2, . . . , αm ∈ Fqm of Fqm over Fq and the matrix A =
(α[j−1]

)1≤i,j≤m, deﬁne

i

(β1, β2, . . . , βm) = e1A−1,

qm is the ﬁrst vector in the canonical basis. Then β1, β2, . . . , βm ∈ Fqm is

where e1 ∈ Fm
also a basis of Fqm over Fq.
Moreover, if B = (β[j−1]

i

)1≤i,j≤m, then

(α1, α2, . . . , αm) = e1B−1.

Proof. Write β = (β1, β2, . . . , βm). Then βA = e1, which means that Pm
δj,1. By rising to the power [l − 1] = ql−1, we see that Pm

β[l−1]A = el, for l = 1, 2, . . . , m.

i=1 β[l−1]

α[j−1]
i

i

i=1 βiα[j−1]
=
= δj,l, that is,

i

Let λ ∈ Fm

q be such that λ · β = 0. By rising to the power [l − 1], for l = 1, 2, . . . , m,

we see that λ · β[l−1] = 0 or, equivalently, λ · (elA−1) = 0.

Write µ = (µ1, µ2, . . . , µm) = λ(A−1)T . It holds that

0 = λ · (elA−1) = (λ(A−1)T ) · el = µ · el = µl.

Therefore, µ = 0, thus λ = 0. Hence the elements β1, β2, . . . , βm are linearly indepen-
dent over Fq.

Finally, sincePm

i=1 β[l−1]

i

α[j−1]
i

means that (α1, α2, . . . , αm)B = e1, and we are done.

= δj,l, it holds thatPm

i=1 αiβ[j−1]

i

= δ1,j = δj,1, which

17

Theorem 4. Let C ⊆ Fn
every r = 1, 2, . . . , k, which in particular implies that n ≥ km.

qm be a linear code of dimension k such that dR,r(C) = rm, for

Then, for every basis α1, α2, . . . , αm of Fqm over Fq, the code C is rank equivalent to
the cartesian product C1 × C2 × · · · × Ck, where all Ci are as in Proposition 4. Moreover,
the rank equivalence can be explicitly constructed in polynomial time from any basis of
C.

Proof. Choose any basis b1, b2, . . . , bk of C. Since dim(C ∗) = km and C ∗ is generated
by the elements b[j−1]
, for 1 ≤ s ≤ k and 1 ≤ j ≤ m, it follows that these elements are
linearly independent (over Fqm).

s

Deﬁne the vector β = (β1, β2, . . . , βm) = e1A−1, with notation as in the previous
lemma. By that lemma, β1, β2, . . . , βm ∈ Fqm constitute a basis of Fqm over Fq, and
α = (α1, α2, . . . , αm) = e1B−1.

q , for 1 ≤ s ≤ k and 1 ≤ i ≤ m. Assume

Consider the vectors vs,i = Tr(βibs) ∈ Fn

that there exists λs,i ∈ Fq such thatPs,i λs,ivs,i = 0. Therefore,

kXs=1  mXi=1

mXj=1

λs,iβ[j−1]

i

! b[j−1]

s

= 0.

Hence, Pm

i
λs,i = 0, for all s, i.

i=1 λs,iβ[j−1]

= 0, for every 1 ≤ s ≤ k and 1 ≤ j ≤ m, which implies that

Therefore, the elements vs,i constitute a basis of C ∗ and are vectors in Fn

q . Now
qm by sending the vector
q to
, it follows that it is a rank equivalence by Lemma 3. Deﬁne C ′ = ψ(C).

deﬁne the Fqm-linear vector space isomorphism ψ : C ∗ −→ Fkm
vs,i to the vector e(s−1)m+i, for 1 ≤ s ≤ k and 1 ≤ i ≤ m. Since ψ takes vectors in Fn
vectors in Fkm
The vectors vs = ψ(bs), for 1 ≤ s ≤ k, constitute a basis of C ′.

q

On the other hand, we have that

bs =

αiβ[j−1]

i

b[j−1]

s

=

mXj=1

mXi=1

αiTr(βibs) =

mXi=1

αivs,i.

mXi=1

It follows that vs = ψ(bs) =Pm

Proposition 4, for the basis α1, α2, . . . , αm, and we are done.

i=1 αie(s−1)m+i. This means that C ′ is the linear code in

Remark 8. The fact that the rank equivalence can be obtained in polynomial time (last
part of the previous theorem) implies that all of these optimal codes have polynomial-time
decoding algorithms using any of their bases, since cartesian products of Gabidulin codes
have such algorithms [6, 7].

The algorithm would be as follows, where all steps can be done in polynomial time,
as shown in the previous theorem: First ﬁnd the vectors vs,i. Then deﬁne the matrix
M which is the inverse of the matrix with rows vs,i (in lexicographic order). The linear
map ψ consists then in multiplying by M .

If xG+e is the received vector, where the rows of G are the basis vectors b1, b2, . . . , br
and e is the error vector, then x(GM ) + (eM ) is an encoded vector with errors using the

18

code in Proposition 4 with the generator matrix GM , which is the block diagonal matrix
with (α1, α2, . . . , αm) in the diagonal blocks, and wtR(e) = wtR(eM ).

We can now use a fast rank error-correcting algorithm for such code, which is given

in [7], and obtain x.

Remark 9. Observe that the optimal codes C ⊆ Fkm
qm in Proposition 4 do not only have
optimal GRWs, but the diﬀerence between two consecutive weights is optimal, in view of
Lemma 7, that is,

dR,r+1(C) = dR,r(C) + m,

for 1 ≤ r ≤ k − 1. However, for a Gabidulin code C ′ as in Subsection 2.4, item 1,
the diﬀerence between two consecutive weights is the minimum possible, also in view of
Lemma 7, that is,

dR,r+1(C ′) = dR,r(C ′) + 1,

for 1 ≤ r ≤ k − 1.

This means that, when using the code C, an adversary that obtains r packets of
information by listening to the minimum number of links possible needs to listen at least
to m more links in order to obtain one more packet of information. However, when
using C ′, the adversary only needs to listen to one more link to obtain one more packet
of information.

7 Stronger security of reducible codes

It is well-known that reducible codes can correct a substantial amount of rank errors
beyond half of their minimum rank distance [7, Section III.A]. The method in [7] not
only corrects all these errors eﬃciently, but can also partially correct them, that is, it
can correct parts of the error corresponding to those main components where the rank
of the error is less than half of the minimum rank distance of that main component.

In this section we will use and generalize this idea to see that, when using a reducible
code C for coset coding in secure network coding, a wiretapping adversary may in many
cases get less than “r packets of information” even if he or she obtains at least dR,r(C)
linearly independent combinations of the original sent packets.

For r = 1, this would mean that a wiretapping adversary obtains in many cases no
information about the original packets even if he or she wiretaps at least dR,1(C) links
in the network.

In the rest of the section, we ﬁx a reducible code C ⊆ Fn

Section 3 and we denote by πi : Fn
corresponding to the i-th main component Ci ⊆ Fni

qm −→ Fni

qm with notation as in
qm the projection map onto the coordinates

qm, for i = 1, 2, . . . , l.

Lemma 10. Let V ⊆ Fn

qm be a linear Galois closed space. It holds that

dim(C ∩ V ) ≤

lXi=1

dim(Ci ∩ πi(V )).

19

Proof. Let D = C ∩ V ⊆ C and deﬁne r = dim(D). Take a basis of D as in Lemma 4.
If we prove that riu ≤ dim(Ciu ∩ πiu(V )), then we are done, since it would follow that

dim(C ∩ V ) = r =

riu ≤

tXu=1

tXu=1

dim(Ciu ∩ πiu(V )).

Fix then 1 ≤ u ≤ t. Consider the map

ρu : hb(iu)

1

, b(iu)

2

, . . . , b(iu)
riu

i −→ Ciu ∩ πiu(V ),

deﬁned as the projection πiu restricted to the given domain. It is well-deﬁned since the
vectors b(iu)

, 1 ≤ j ≤ riu, are contained in D ⊆ V and in C ′

iu+1 ⊕ · · · ⊕ C ′
l.

iu ⊕ C ′

j

By the description of the elements b(iu)

j

, 1 ≤ j ≤ riu , in Lemma 4, it holds that ρu

is one to one. Therefore, riu ≤ dim(Ciu ∩ πiu(V )) and we are done.

As a consequence, we obtain the following results on information leakage using re-

ducible codes:

Theorem 5. Let V ⊆ Fn
qm be a linear Galois closed space and assume that, for each
i = 1, 2, . . . , l, there exists 0 ≤ ri ≤ ki with dim(πi(V )) ≤ dR,ri(Ci) if ri > 0, or
dim(πi(V )) = 0 if ri = 0. Then it holds that

dim(C ∩ V ) ≤  lXi=1

ri! − #{i | dim(πi(V )) < dR,ri(Ci)}.

In particular, if dim(πi(V )) < dR,1(Ci), for all i = 1, 2, . . . , l, then

dim(C ∩ V ) = 0.

Proof. First of all, observe that πi(V ) ⊆ Fni

qm is again Galois closed.

By deﬁnition of GRWs, if dim(πi(V )) < dR,ri(Ci), then dim(Ci ∩ πi(V )) < ri, for
i = 1, 2, . . . , l such that ri > 0. On the other hand, if dim(πi(V )) ≤ dR,ri(Ci) and ri < ki,
then by monotonicity of GRWs [11, Lemma 4], it holds that dim(πi(V )) < dR,ri+1(Ci),
which implies that dim(Ci ∩ πi(V )) < ri + 1, that is, dim(Ci ∩ πi(V )) ≤ ri. Finally, if
dim(πi(V )) ≤ dR,ki(Ci), then it is trivial that dim(Ci ∩ πi(V )) ≤ dim(Ci) = ki.

The result follows then from the previous lemma.

Remark 10. According to Lemma 1, the previous theorem implies that, if dim(πi(V )) <
dR,1(Ci), for all i = 1, 2, . . . , l, then an eavesdropper that obtains cBT , where B generates
V , gains no information about the original packets. Observe that this would be guaranteed
if dim(V ) < dR,1(C). However, many linear Galois closed spaces V ⊆ Fn
qm satisfy
dim(πi(V )) < dR,1(Ci), for all i, but do not satisfy dim(V ) < dR,1(C).

Take for instance V = V1×V2×· · ·×Vl, where Vi ⊆ Fni

satisfying dim(Vi) < dR,1(Ci), for i = 1, 2, . . . , l, but dim(V ) =Pl

qm are linear Galois closed spaces
i=1 dim(Vi) ≥ dR,1(C).

20

The previous theorem has the following immediate consequence on the optimal codes

from last section:

Corollary 2. Let C ⊆ Fkm
Galois closed space. It holds that

qm be the code in Proposition 4, and let V ⊆ Fkm

qm be a linear

dim(C ∩ V ) < #{i | πi(V ) = Fm

qm}.

In other words, to obtain at least r packets of information, it must hold that πi(V )
is the whole space Fm
qm for all
i = 1, 2, . . . , k, then the adversary obtains no information about the original packets,
even if dim(V ) > dR,1(C).

In particular, if πi(V ) 6= Fm

qm for at least r indices i.

Take for instance V = V1 × V2 × · · · × Vk, where Vi ( Fn

qm satisﬁes dim(Vi) = m − 1,
for i = 1, 2, . . . , k. In that case, dim(V ) = k(m − 1), which is usually much bigger than
dR,1(C) = m. However, the adversary still obtains no information about the original
packets.

Corollary 3. Let 1 ≤ r ≤ k and let V ⊆ Fn

qm be a linear Galois closed space. Assume
i=1 ri, where 1 ≤ ri ≤ ki and dim(πi(V )) ≤ dR,ri(Ci), for i = 1, 2, . . . , l, and

for some j it holds that dim(πj(V )) < dR,rj (Cj). Then

that r =Pl

dim(C ∩ V ) < r.

Remark 11. Now if dim(πi(V )) ≤ dR,ri(Ci), for i = 1, 2, . . . , l and with strict inequality
for some j, then an eavesdropper that obtains cBT , where B generates V , gains less than
r packets of information about the original packets. The previous condition implies that

i=1 dR,si(Ci) for all possible decom-
i=1 si, then dim(C ∩ V ) < r. However, as in the previous remark, many
linear Galois closed spaces may satisfy dim(πi(V )) ≤ dR,ri(Ci), for all i, and a given
i=1 dR,si(Ci) for some

i=1 ri, but may also satisfy that dim(V ) ≥Pl

Take for instance V = V1 × V2 × · · · × Vl, where Vi ⊆ Fni

qm are linear Galois closed
spaces satisfying dim(Vi) ≤ dR,ri(Ci), for i = 1, 2, . . . , l and with strict inequality for

i=1 dR,ri(Ci).

dim(V ) <Pl
We know from the bound (7) that if dim(V ) <Pl
positions r =Pl
decomposition r =Pl
other decomposition r =Pl
some j, but dim(V ) =Pl

i=1 dim(Vi) ≥ dR,r(C).

i=1 si.

8 Related properties of reducible codes

In this section we study some code properties of reducible codes that have consequences
on their GRWs.

8.1 Cartesian product conditions

In this subsection we gather suﬃcient and necessary conditions for reducible codes to be
rank equivalent to cartesian products.

21

We start by using Galois closures and generalized rank weights to see whether a linear
code that can be decomposed as a direct sum of smaller codes is rank equivalent to the
cartesian product of these codes. It can be seen as a converse statement to Corollary 1.

Proposition 5. Given a code C = C ′
i = 1, 2, . . . , l, and k = dim(C), we have that C ∗ = C ′∗
following conditions are equivalent:

2 ⊕ · · · ⊕ C ′

1 ⊕ C ′

l ⊆ Fn
1 + C ′∗

qm, with ki = dim(C ′
2 + · · · + C ′∗

i),
l and the

1. C is rank equivalent to a cartesian product C1 × C2 × · · · × Cl ⊆ Fn

qm, where
i, and the equivalence map from C to the product

qm is rank equivalent to C ′

Ci ⊆ Fni
is the product of the equivalence maps from C ′

i to Ci.

2. C ∗ = C ′∗

1 ⊕ C ′∗

2 ⊕ · · · ⊕ C ′∗
l .

3. dR,k(C) = dR,k1(C ′

1) + dR,k2(C ′

2) + · · · + dR,kl(C ′

l).

4. For all 1 ≤ r ≤ k, it holds that

dR,r(C) = min{dR,r1(C ′

1) + dR,r2(C ′

2) + · · · + dR,rl(C ′
l)
| r = r1 + r2 + · · · + rl, 0 ≤ ri ≤ ki}.

Proof. It is trivial that item 1 implies item 4 by Corollary 1.
It is also trivial that
item 4 implies item 3 and items 2 and 3 are equivalent, since dR,k(C) = dim(C ∗) and
dR,ki(C ′

i ), for i = 1, 2, . . . , l, by Lemma 2.

i) = dim(C ′∗

Now we prove that item 2 implies item 1. Deﬁne Vi = C ′∗

V = C ∗. We may assume that C is not rank degenerate, that is, V = Fn
n = dim(V ), ni = dim(Vi), for i = 1, 2, . . . , l, and n = n1 + n2 + · · · + nl.

On the other hand, deﬁne a vector space isomorphisms ψi : Vi −→ Fni

i , for i = 1, 2, . . . , l, and
qm. Therefore,

q to the canonical basis of Fni

i). Therefore, Ci and C ′

qm, for i =
qm. It is
i are rank

1, 2, . . . , l, by sending a basis of Vi of vectors in Fn
a rank equivalence by Lemma 3. Deﬁne Ci = ψi(C ′
equivalent by deﬁnition.

Finally, deﬁne the map ψ : V = V1 ⊕ V2 ⊕ · · · ⊕ Vl −→ Fn

qm by

ψ(c1 + c2 + · · · + cl) = (ψ1(c1), ψ2(c2), . . . , ψl(cl)),

q to vectors in
q and is a vector space isomorphism. Hence, it is a rank equivalence by Lemma 3 and

where ci ∈ Vi, for all i = 1, 2, . . . , l. It holds that ψ maps vectors in Fn
Fn
veriﬁes the required conditions.

Corollary 4. With notation as in Section 3, if Ci is rank equivalent to C ′
i = 1, 2, . . . , l, then C is rank equivalent to C1 × C2 × · · · × Cl.

i, for all

Observe that the previous corollary states that Remark 3 is actually implied by

Corollary 1.

On the other hand, we may use the column components to see wether C = C1 × C2 ×

· · · × Cl exactly. The proof is straightforward:

22

Proposition 6. With notation as in Section 3, the following conditions are equivalent:

1. C = C1 × C2 × · · · × Cl.

2. C = bC.
3. ki =bki, for all i = 1, 2, . . . , l.

component Cj.

4. For each 2 ≤ j ≤ l, the rows in Gi,j, 1 ≤ i ≤ j − 1, are contained in the main

8.2 Rank degenerate conditions

In this subsection we study suﬃcient and necessary conditions for reducible codes to be
rank degenerate (recall Deﬁnition 3).

Proposition 7. With notation as in Section 3, it holds that:

1. If C is rank degenerate, then there exists an 1 ≤ i ≤ l such that Ci is rank

degenerate.

2. If there exists an 1 ≤ j ≤ l such that bCj is rank degenerate, then C is rank

degenerate.

Proof. We prove each item separatedly:

1. It follows from

dR,k(C) ≥ dR,k1(C1) + dR,k2(C2) + · · · + dR,kl(Cl),

which follows from Theorem 1, and the fact that C has length n and Ci has length
ni, for i = 1, 2, . . . , l.

2. We have that C ⊆ bC. Hence C ∗ ⊆ bC ∗ and

by Lemma 2, and

dR,k(C) = dim(C ∗) ≤ dim(bC ∗) = dR,bk(bC),
dR,bk(bC) = dR,bk1
(bCl),
(bC2) + · · · + dR,bkl

(bC1) + dR,bk2

by Corollary 1, hence the item follows, using now that bCj has length nj, for j =

1, 2, . . . , l.

Corollary 5. If C = C1 × C2 × · · · × Cl, then C is rank degenerate if, and only if, there
exists an 1 ≤ i ≤ l such that Ci is rank degenerate.

23

H =



H1
H2,1
H3,1
...

0
H2
H3,2
...

0
0
H3
...

Hl−1,1 Hl−1,2 Hl−1,3
Hl,3
Hl,1

Hl,2

0
0
0
...

0
. . .
0
. . .
0
. . .
...
. . .
0
. . . Hl−1
. . . Hl,l−1 Hl

,



8.3 Duality and bounds

With notation as in Section 3, it is shown in [7] that the dual of the reducible code C
has a generator matrix of the form

where Hi is a generator matrix of C ⊥

i , for i = 1, 2, . . . , l.

We see that reversing the order of the row blocks does not change the code, and
reversing the order of the column blocks gives a rank equivalent code. Hence, denoting
by (C ⊥)′

i the subcode of C ⊥ generated by the matrix

H ′

i = (Hi,1, . . . , Hi,i−1, Hi, 0, . . . , 0),

for i = 1, 2, . . . , l, we may obtain analogous bounds on the generalized rank weights of
C ⊥ to those in Theorem 1. We leave the details to the reader.

Moreover, similar uniqueness conditions to those in Proposition 1 and Proposition 2

can be stated for C ⊥ using a generator matrix of the previous form.

An upper bound on the GRW of C ⊥ using column components of C that follows

from Corollary 1 is the following:

Proposition 8. With notation as in Section 3, it holds that

l )

(12)

1 ) + dR,br2(bC ⊥

dR,r(C ⊥) ≤ min{dR,br1(bC ⊥

2 ) + · · · + dR,brl(bC ⊥
| r =br1 +br2 + · · · +brl, 0 ≤bri ≤bki},
for 1 ≤ r ≤ n −bk ≤ n − k.
Proof. It holds that C ⊆ bC, hence bC ⊥ ⊆ C ⊥, and the result follows then from Corollary
1 and the fact that bC ⊥ = bC ⊥
1 × bC ⊥
2 × · · · × bC ⊥
In particular, ifbk < n, it holds that
dR,1(C ⊥) ≤ min{dR,1(bC ⊥

8.4 MRD rank

1 ), dR,1(bC ⊥

2 ), . . . , dR,1(bC ⊥

l )}.

(13)

l .

Recall from [11, Proposition 1] the (classical) Singleton bound on GRWs:

dR,r(C) ≤ n − k + r,

(14)

for any linear code C ⊆ Fn
qm, where k = dim(C) and 1 ≤ r ≤ k. By monotonicity of
GRWs [11, Lemma 4], if the r-th weight of C attains the Singleton bound, then the
s-th weight of C also attains it, for all s ≥ r. Thus, it is interesting to see which is the
minimum r with this property:

24

Deﬁnition 7. For a linear code C ⊆ Fn
qm of dimension k, we deﬁne its MRD rank as
the minimum positive integer r such that dR,r(C) = n − k + r, and denote it by r(C).

If dR,k < n, then we deﬁne r(C) = k + 1.

Observe that the last part of the previous deﬁnition is a redeﬁnition of rank degen-

erate codes. We have the next characterization of r(C) given in [3]:
Lemma 11 ([3, Corollary III.3]). For a linear code C ⊆ Fn
that

qm of dimension k, it holds

deﬁning dR,1({0}) = n + 1 for the case C = Fn

qm.

r(C) = k − dR,1(C ⊥) + 2,

In particular, from the bounds obtained so far, we derive the following result on the

MRD rank of a reducible code:

Proposition 9. Let the notation be as in Section 3. It holds that

k − r(C) ≥ min{k1 − r(C1), k2 − r(C2), . . . , kl − r(Cl)}

(15)

(16)

and

Moreover, denote by ki,j and ri,j the dimension and MRD rank of the linear code with
parity check matrix Hi,j, respectively, with notation as in the previous subsection, for
2 ≤ i ≤ l and 1 ≤ j ≤ i − 1. Then

k − r(C) ≤ min{bk1 − r(bC1),bk2 − r(bC2), . . . ,bkl − r(bCl)}.
k − r(C) ≤ min{ki − r(Ci) + XHi,j 6=0

(ki,j − ri,j + 2)

(17)

| i = 1, 2, . . . , l}.

Proof. The bound (15) follows from the previous lemma and the bound (6). The bound
(16) follows from the previous lemma and the bound (13).

Now we prove the bound (17). From the previous lemma and the bound (9), we

obtain that

k − r(C) ≤ min{dR,1((C ⊥)′

1, (C ⊥)′

2, . . . , (C ⊥)′

l)},

with notation as in the previous subsection. Now, if di,j denotes the minimum rank
distance of the linear code with parity check matrix Hi,j, it follows that

dR,1((C ⊥)′

i) ≤ dR,1(C ⊥

i ) + XHi,j 6=0

di,j,

and the result follows again from the previous lemma.

The MRD rank of the code C in Example 1 was obtained directly using Theorem 1.

However, it could be directly obtained using the previous proposition.

Corollary 6. With notation as in the previous proposition, if C = C1 × C2 × · · · × Cl,
it holds that

k − r(C) = min{k1 − r(C1), k2 − r(C2), . . . , kl − r(Cl)},

and all the bounds in the previous proposition are equalities.

25

8.5 Particular constructions

Finally, in this subsection we brieﬂy recall some constructions of reducible codes in the
literature introduced to improve the minimum Hamming distance of cartesian products
of codes, and see when they may give improvements for the rank distance.

Recall the well-known (u, u + v)-construction by Plotkin [16]. Take linear codes

C1, C2 ⊆ Fn

qm, and deﬁne the linear code C ⊆ F2n

qm by

C = {(u, u + v) | u ∈ C1, v ∈ C2}.

Denoting by dH(D) the minimum Hamming distance of a code D, it holds that dH(C1 ×
C2) = min{dH (C1), dH (C2)}, whereas dH(C) = min{2dH (C1), dH (C2)}, hence improv-
ing the minimum Hamming distance of the cartesian product if dH(C1) < dH(C2).

Observe that C is reducible. However, its ﬁrst row component is obviously rank
equivalent to its ﬁrst main component. By Proposition 5, C and C1 × C2 are rank
equivalent. Hence the (u, u + v)-construction gives nothing but cartesian products for
the rank metric.

We may apply the same argument for the so-called matrix-product codes [2], which
are a generalization of the previous construction. Let the notation be as in Section 3,
ﬁx a non-singular matrix A ∈ Fl×l
qm and assume that N = n1 = n2 = . . . = nl. Deﬁne the
code C = (C1, C2, . . . , Cl)A ⊂ Fn
qm with generator matrix

G =

a1,1G1 a1,2G1
a2,1G2 a2,2G2

...

...

al,1Gl

al,2Gl

. . . a1,lG1
. . . a2,lG2
. . .
. . .

al,lGl

...

.



If A is upper triangular, we see that C is a reducible code. Just as before, if A ∈ Fl×l
,
then C is rank equivalent to C1 × C2 × · · · × Cl, and thus this construction gives nothing
but cartesian products.

q

In the following examples we see that, as an alternative, the (u, αu+v)-construction,
for α ∈ Fqm \ Fq, and (u, u[i] + v)-construction, for i ≥ 0, may improve the minimum
rank distance of the cartesian product.

qm generated by (1, 0, 0) and C2 ⊆ F3
Example 2. Consider α ∈ Fqm \Fq, n = 3, C1 ⊆ F3
qm
generated by (0, α, α[1]) and (0, α[1], α[2]). Let C be the (u, αu + v)-construction of the
codes C1 and C2.

It holds that dR,1(C1 × C2) = 1, whereas dR,1(C) = 2.

qm generated by (α, 0, 0) and C2 ⊆ F3
Example 3. Consider α ∈ Fqm \Fq, n = 3, C1 ⊆ F3
qm
generated by (0, α, α[1]) and (0, α[1], α[2]). Let C be the (u, u[1] + v)-construction of the
codes C1 and C2.

Again, it holds that dR,1(C1 × C2) = 1, whereas dR,1(C) = 2.

26

9 Conclusion

In this paper, we have studied generalized rank weights (GRWs) and other properties of
reducible codes related to security in network coding. We have obtained lower bounds
that generalize the known lower bound for their minimum rank distance [7] and which
give the exact values for cartesian products, and obtained upper bounds that are always
reached for some reduction. We have obtained new parameters for which reducible codes
with maximum rank distance (MRD) main components are also MRD, extending the
families of MRD codes for n > m considered in [7] and [19]. To the best of our knowledge,
this is the only known family of MRD Fqm-linear codes for n > m.

We have obtained all codes with optimal GRWs for all ﬁxed packet and code sizes
up to rank equivalence. The given code construction is a cartesian product of full-length
one-dimensional Gabidulin codes and have the minimum possible length required by the
optimality of their GRWs. As we have seen, they do not only have optimal GRWs,
but the diﬀerence between every two consecutive GRWs is the packet lenght, which is
optimal, in constrast with Gabidulin codes, for which this diﬀerence is the minimum
possible. This suggests that, if the length of the code is big enough or not restricted,
then the given construction behaves much better than Gabidulin codes in secure network
coding.

Then we have seen that, when using reducible codes, a wire-tapping adversary obtains
in many cases less information than that described by their GRWs. In particular, for the
previous optimal codes, we have seen that if the adversary obtains non-zero information,
then at least one of the projections of the corresponding linear Galois space needs to be
the whole space.

Finally, we have studied some related properties of reducible codes: We have given
characterizations for them to be rank equivalent to cartesian products of codes and
characterizations to be rank degenerate. We have studied bounds on their dual codes
and their MRD ranks, giving exact results in the case of cartesian products. At the
end, we have discussed which alternative constructions to the well-known (u, u + v)-
construction may increase the minimum rank distance of cartesian products.

A Proofs for Section 3

In this appendix we will give the proofs of Proposition 1 and Proposition 2.

Proof of Proposition 1. Let bR = ((bGi)1≤i≤l, (bGi,j)i+1≤j≤l
1≤i≤l−1) and let bG be the generator
matrix of C given by the reduction bR. Since the matrices Gi are full rank, there exist

ki×kj
qm , for 1 ≤ i ≤ l − 1 and i + 1 ≤ j ≤ l, such that

and Ai,j ∈ F

matrices Ai ∈ Fki×ki

qm

27

the k × k matrix

A =

A1 A1,2 A1,3
A2 A2,3
0
A3
0
0
...
...
...
0
0
0
0
0
0

. . . A1,l−1 A1,l
. . . A2,l−1 A2,l
. . . A3,l−1 A3,l
...
. . .
. . . Al−1 Al−1,l
. . .

0

...

Al







,

satisﬁes that bG = AG. Then it holds that bGi = AiGi and the main components of both

reductions coincide. On the other hand, it holds that



...

bG1,j
bG2,j
bGj

=

A1 A1,2
A2
0
...
...
0
0

. . . A1,j
. . . A2,j
...
. . .
. . . Aj





G1,j
G2,j
...
Gj

hence the column components of both reductions also coincide.

Proof of Proposition 2. Let R′ = ((G′
1≤i≤l−1) and let G′ be the generator
matrix of C ′ given by the reduction R′. By hypothesis and by Lemma 3, we may assume
that the rank equivalence is given by φ(c) = cA, for some n × n matrix

i)1≤i≤l, (G′

i,j)i+1≤j≤l

A =



A1
A2,1
A3,1
...

A1,2
A2
A3,2
...

A1,3
A2,3
A3
...

Al−1,1 Al−1,2 Al−1,3
Al,3
Al,1

Al,2

. . . A1,l−1 A1,l
. . . A2,l−1 A2,l
. . . A3,l−1 A3,l
...
. . .
. . . Al−1 Al−1,l
. . . Al,l−1

Al

...

,



with coeﬃcients in Fq, and such that G′ = GA. Looking at the generator matrices of
the last row components of R and R′, we see that

(0, . . . , 0, G′

l) = (GlAl,1, . . . , GlAl,l−1, GlAl),

which implies that GlAl,j = 0, for 1 ≤ j ≤ l − 1. This means that the rows of Al,j are in
C ⊥
l . However, since their coeﬃcients lie in Fq, these rows have rank weight equal to 1.
On the other hand, we are assuming that the main components of R are not rank
l ) > 1. Therefore, the rows in Al,j are

degenerate, which in particular means that dR(C ⊥
the zero vector, that is, Al,j = 0.

If we now look at the generator matrices of the (l − 1)-th row components of R and

R′, we see that

(0, . . . , 0, G′

l−1, G′

l−1,l) = (Gl−1Al−1,1, . . .

Gl−1Al−1,l−2, Gl−1Al−1, Gl−1Al−1,l + Gl−1,lAl),

28

which implies that Gl−1Al−1,j = 0, for 1 ≤ j ≤ l − 2. In the same way as before, we see
that this implies that Al−1,j = 0, for 1 ≤ j ≤ l − 2.

Continuing like this, we see that Ai,j = 0, for i > j. In other words, we have that A

is again of the form

A =



A1 A1,2 A1,3
A2 A2,3
0
A3
0
0
...
...
...
0
0
0
0
0
0

. . . A1,l−1 A1,l
. . . A2,l−1 A2,l
. . . A3,l−1 A3,l
...
. . .
. . . Al−1 Al−1,l
. . .

0

...

Al

.



As in the proof of Proposition 1, this implies that the main components and row com-
ponents of R and R′ are rank equivalent, respectively.

B Consequences on the GPT public key cryptosystem

Theorem 4 has some non-trivial consequences on the GPT public key cryptosystem,
introduced in [8] using Gabidulin codes, and extended in [7] to general reducible codes.
There are two general settings for these cryptosystems. The ﬁrst [8] is McEliece-type
and uses generator matrices as public keys and information vectors as plaintexts. The
second [7] is Niederreiter-type and uses parity check matrices as public keys and error
vectors as plaintexts. We only treat the ﬁrst type for simplicity, being the essence of the
two similar.

Choose a linear code C ⊆ Fn

qm with dimension k and generator matrix G. Choose
an invertible k × k matrix S over Fqm (row scrambler), an invertible n × n matrix
P over Fq (column scrambler), and a k × n matrix X over Fqm (distortion matrix)
such that every vector in the linear code generated by X has rank weight at most
t1 ≤ t = ⌊(dR,1(C) − 1)/2⌋. This can be achieved for instance if X is as in [7, Section
IV.A] or if it has coeﬃcients in Fq and rank at most t1.

The private key is the tuple (S, G, X, P ), the public key is the k × n matrix Gp =
qm and the cyphertexts are vectors r =

S(G + X)P , the plaintexts are vectors x ∈ Fk
xGp + e, where e ∈ Fn

qm has rank weight at most t − t1 ≥ 0.

The key fact is to choose G such that an eﬃcient algorithm for rank error-correction
using it is known, whereas it is not known for the matrix Gp. The receiver can compute
rP −1 = xSG + (xSX + eP −1), decode this vector using G and obtain xS. Finally, the
original message x may be obtained by solving a system of linear equations, since the
matrix S is known by the receiver.

Theorem 4 can be used to break this cryptosystem in polynomial time in some cases
where the code C need not be a Gabidulin code [6] nor a reducible code [7], but just
have some special parameters. We illustrate this in the following cases, where we denote
by Cp the linear code generated by Gp.

29

If one of the following conditions is satisﬁed, then Theorem 4 gives a polynomial-time

algorithm to obtain x from r = xGp + e and Gp:

1. Assume X = 0 and dR,k(C) = km, which requires n ≥ km.

2. More generally, assume that dim(Cp) = k and dR,k(Cp) = km, which requires
again n ≥ km. Observe that this condition can always be eﬃciently checked using
dR,k(Cp) dim(C ∗

p ).

3. More generally, assume that kp = dim(Cp) and dR,kp(Cp) = kpm, which requires
n ≥ kpm. In this case, Theorem 4 gives a polynomial-time algorithm to obtain a
(k − kp)-dimensional aﬃne space in Fk

qm containing x.

4. Assume X = 0 and let C ′ be the code generated by the ﬁrst k − 1 rows in SG.

Assume also dR,k−1(C ′) = (k − 1)m and the last component in x is zero.

5. More generally, let C ′ be the code generated by the ﬁrst k′ rows in Gp. Assume
that dim(C ′) = k′, dR,k′(C ′) = k′m and the last k − k′ components in x are zero.

Many other combinations of similar conditions may be considered. We leave the

details to the reader.

Therefore, when constructing a public key cryptosystem using linear rank-metric
codes (even if they are not Gabidulin [6] nor reducible [7]), these conditions must be
always checked, since any of them implies that an attacker may obtain the original
message, some of its coordinates or a smaller space containing it in polynomial time.

Observe also that, even if C does not satisfy the conditions in item 1 or item 4, the
distortion matrix X may make Cp satisfy such conditions, hence making the cryptosys-
tem insecure instead of securing it.

Acknowledgement

The author wishes to thank Olav Geil and Diego Ruano for fruitful discussions and
careful reading of the manuscript. The author also gratefully acknowledges the support
from The Danish Council for Independent Research (Grant No. DFF-4002-00367).

References

[1] R. Ahlswede, N. Cai, S. Y. R. Li, and R. W. Yeung. Network information ﬂow.

IEEE Trans. Inf. Theor., 46(4):1204–1216, September 2006.

[2] T. D. Blackmore and G. H. Norton. Matrix-product codes over Fq. Applicable

Algebra in Engineering, Communications and Computing, 12:477–500, 2001.

[3] J. Ducoat. Generalized rank weights: a duality statement. Topics in Finite Fields,

632:101 – 109, 2015.

30

[4] J. Ducoat and F. Oggier. Rank weight hierarchy of some classes of cyclic codes. In

Information Theory Workshop (ITW), 2014 IEEE, pages 142–146, Nov 2014.

[5] S. El Rouayheb, E. Soljanin, and A. Sprintson. Secure network coding for wiretap

networks of type ii. IEEE Trans. Inf. Theory, 58(3):1361–1371, March 2012.

[6] E. M. Gabidulin. Theory of codes with maximum rank distance. Problems Infor-

mormation Transmission, 21, 1985.

[7] E. M. Gabidulin, A. V. Ourivski, B. Honary, and B. Ammar. Reducible rank codes
and their applications to cryptography. IEEE Transactions Information Theory,
49(12):3289–3293, Dec 2003.

[8] E. M. Gabidulin, A. V. Paramonov, and O. V. Tretjakov.

Ideals over a non-
commutative ring and their application in cryptology. In DonaldW. Davies, edi-
tor, Advances in Cryptology — EUROCRYPT ’91, volume 547 of Lecture Notes in
Computer Science, pages 482–489. Springer Berlin Heidelberg, 1991.

[9] R. Jurrius and R. Pellikaan.

On deﬁning generalized rank weights.

arXiv:1506.02865, 2014.

[10] R. K¨otter and M. Medard. An algebraic approach to network coding. Networking,

IEEE/ACM Transactions on, 11(5):782–795, Oct 2003.

[11] J. Kurihara, R. Matsumoto, and T. Uyematsu. Relative generalized rank weight of
linear codes and its applications to network coding. IEEE Transactions Information
Theory, 61(7):3912–3936, July 2015.

[12] Pierre Loidreau. Etude et optimisation de cryptosyst`emes `a cl´e publique fond´es sur

la th´eorie des codes correcteurs. PhD thesis, 5 2001.

[13] U. Mart´ınez-Pe˜nas. On the similarities between generalized rank and Hamming

weights and their applications to network coding. arXiv:1506.04036, 2015.

[14] F. E. Oggier and A. Sboui. On the existence of generalized rank weights. In Proceed-
ings of the International Symposium on Information Theory and its Applications,
ISITA 2012, Honolulu, HI, USA, October 28-31, 2012, pages 406–410, 2012.

[15] L. H. Ozarow and A. D. Wyner. Advances in Cryptology: Proceedings of EU-
ROCRYPT 84 A Workshop on the Theory and Application of Cryptographic Tech-
niques Paris, France, April 9– 11, 1984, chapter Wire-Tap Channel II, pages 33–50.
Springer Berlin Heidelberg, Berlin, Heidelberg, 1985.

[16] M. Plotkin. Binary codes with speciﬁed minimum distance. Information Theory,

IRE Transactions on, 6(4):445–450, September 1960.

[17] Alberto Ravagnani. Generalized weights: An anticode approach. Journal of Pure

and Applied Algebra, 220(5):1946 – 1962, 2016.

31

[18] D. Silva and F. R. Kschischang. On metrics for error correction in network coding.

IEEE Transactions Information Theory, 55(12):5479–5490, 2009.

[19] D. Silva and F. R. Kschischang. Universal secure network coding via rank-metric

codes. IEEE Trans. Inf. Theory, pages 1124–1135, 2011.

[20] H. Stichtenoth. On the dimension of subﬁeld subcodes. IEEE Transactions Infor-

mation Theory, 36(1):90–93, Jan 1990.

[21] V. K. Wei. Generalized Hamming weights for linear codes. IEEE Trans. Inf. Theory,

37(5):1412–1418, 1991.

[22] R. Zamir, S. Shamai, and U. Erez. Nested linear/lattice codes for structured mul-

titerminal binning. IEEE Trans. Inf. Theory, 48(6):1250–1276, Jun 2002.

32

