6
1
0
2

 
r
a

 

M
8
1

 
 
]

V
C
.
s
c
[
 
 

1
v
2
8
7
5
0

.

3
0
6
1
:
v
i
X
r
a

UnsupervisedCross-MediaHashingwithStructurePreservationXiangyuWangInstituteforInfocommResearchAlexYong-SangChiaInstituteforInfocommResearchAbstractRecentyearshaveseentheexponentialgrowthofhet-erogeneousmultimediadata.Theneedforeffectiveandac-curatedataretrievalfromheterogeneousdatasourceshasattractedmuchresearchinterestincross-mediaretrieval.Here,givenaqueryofanymediatype,cross-mediare-trievalseekstoﬁndrelevantresultsofdifferentmediatypesfromheterogeneousdatasources.Tofacilitatelarge-scalecross-mediaretrieval,weproposeanovelunsupervisedcross-mediahashingmethod.Ourmethodincorporateslo-calafﬁnityanddistancerepulsionconstraintsintoamatrixfactorizationframework.Correspondingly,theproposedmethodlearnshashfunctionsthatgeneratesuniﬁedhashcodesfromdifferentmediatypes,whileensuringintrinsicgeometricstructureofthedatadistributionispreserved.Thesehashcodesempowerthesimilaritybetweendataofdifferentmediatypestobeevaluateddirectly.Experimentalresultsontwolarge-scalemultimediadatasetsdemonstratetheeffectivenessoftheproposedmethod,whereweoutper-formthestate-of-the-artmethods.1.IntroductionTheproliferationandpervasivenessofsocialnetworkshavecontributedmuchtotheexponentialgrowthintheamountofuser-generatedmultimediacontent.Forexam-ple,thereareabout500milliontweetssenteachday,ofwhich36%ofthetweetscontainimages1.Giventhatin-formationisoftenpresentedindifferentmediatypes(e.g.textandimages),itisdesirabletohaveacross-mediare-trievalparadigmtosearchlargescaleheterogeneousdatagivenqueriesinanymediatypes.Forexample,suchare-trievalparadigmwouldﬁndrelevanttextualcontentwhenprovidedwithanimagequery,andviceversa.Here,otherthantheissueofretrievalaccuracy,twoimportantconsider-ationsforpracticalusagearethestorageandcomputationalrequirementsoftheretrievalsystem.Hashing-basednearestneighborsearchhasreceivedcon-siderableinterestfortheirgreatefﬁciencygainsinmas-1http://socialtimes.com/is-the-status-update-dead-36-of-tweets-are-photos-infographicb103245sivedata[9].Arecenttrendincross-mediaretrievalisbasedontheconceptoflocality-sensitivehashing(LSH)[10].Speciﬁcally,givendataofdifferentmodalities,suchmethodslearnhashfunctionsfromthedataautomatically.Thesehashfunctionsarethenexploitedtotransformthedatapoints(ofdifferentmodalities)fromdifferentfeaturespaceintoacommonHammingspace.Retrievalofsimilardatathatareofdifferentmodalitiescanthenbeachievedinthiscommonspacevianearestneighborsearch.Suchhashfunctionsareoftenengineeredtostorethehashcodesinbi-narybits,andlinearprojectionhashfunctionsareusuallypreferredbecauseoftheirefﬁciencyinhashingtime.Thisfurtherimprovesthequeryspeed,andaffordsmoreeffec-tivestoragerequirements.Recently,therehavebeenafewworksoncross-mediahashingthathaveachievednotablesuccess[17,23,8,7].Zhenetal.[23]andGongetal.[8]exploitedthere-lationshipsbetweentext-imagepairstocomputethehashfunctions.Thesemethodsconsideronlytheinter-mediastructureofthedata,butignoretheintra-mediastructure2(i.e.relationshipsbetweenimage-imageandtext-textpairs).Dingetal.[7]learneduniﬁedhashcodesforcorre-spondinginstancesofdifferentmodalities(i.e.image-textpairs).Like[23,8],theirmethodminimizesinter-medialoss,butdoesnotexplicitlyconsiderintra-mediastructureofthedata.Toexploitmoredatainformation,Songetal.[17]exploitedbothinter-mediaandintra-mediadatacon-sistencytooptimizethehashfunctions.Whilegoodre-sultswerereportedbythesepreviousworks,wenotethattheyoptimizethehashfunctionsbasedonlocalgeometricalpropertiesofthedatabutneglecttheglobalgeometricaldatastructure,whichneedstoberespectedinmanyapplications[18].Hashingmethodscanbedividedintotwodifferenttypesbasedontheextentofsupervisionrequiredduringthelearn-ingphase.Speciﬁcally,supervisedmethodssuchasCo-RegularizedHashing[23]andSemanticCorrelationMaxi-mizationHashing[22]requirepriorknowledgesuchasse-manticlabelsofthefeatures(i.e.classlabels)tolearnthehashfunctions.Giventhatmostmultimediadatahavelim-2Inthispaper,weusetheterms“datastructure”and“datamanifold”interchangeably.1itedornosemanticlabels,suchmethodsdemandexpensiveandlaboriousworktoobtaincleanannotateddata.Thislim-itsitsuseinpracticalapplications.Unsupervisedhashingmethods,ontheotherhand,donotrequiresuchsemanticlabelsandonlyrequirecorrespondencesbetweenpairsofdata(i.e.knowledgeofimage-textpairs)tobeknowndur-ingthelearningphase.Suchinformationismorereadilyavailable(e.g.,animagetweetwithaccompanyinghash-tags/captions),andhenceunsupervisedmethodsaremorepopularandsuitableforreal-worldapplications.Inthiswork,wepresentanovelunsupervisedcross-mediahashingmethodwhichismotivatedonthefollow-ingkeyconcepts.First,datapointsofdifferentmodalitiesbutwithsimilarsemanticsshouldbeprojectedneartoeachotherinthecommonHammingspace,i.e.,hashfunctionsshouldbetrainedtominimizeinter-medialoss.Thisen-suresmorereliablecross-mediaretrievalabilitywithnear-estneighborsearch.Second,datapointswhicharesimilarintheoriginalfeaturespaceshouldalsobesimilarintheprojectedspace.Inthesameaspect,datapointswhicharefarapartintheoriginalfeaturespaceshouldalsobepro-jectedtobefarapartintheprojectedspace.Thisretainstheintra-mediastructureofdifferentmodalitiesafterpro-jectingintoacommonHammingspace.Bypreservingsuchdistancesbetweendatapoints(intra-mediastructure),infor-mationanddiscriminabilityoftheoriginaldataarealsore-tained.Weareawareofsomeworks[17]thatexploitnear-estneighborcues,whichensuresimilardatatobecloseto-gether,topreservethestructureoftheintra-mediaspace.However,giventhattheyneglectthestructureofdissimilardataintheoptimization,datapointswhicharedissimilarmightbeprojectedclosetoeachotherinthecommonspaceandbeerroneouslyretrievedwithnearestneighborsearch.WeillustratethesekeyconceptsinFig.1.Speciﬁcally,thetopleftandbottomleftaxesrepresenttheimagespaceandtextspacerespectively,andtherightaxesdenotethecommonHammingspace.Dashedcoloredlinesdepictim-agesandtextwithsimilarsemantics.Weformulatethecross-mediahashingmethodasalossfunctionminimiza-tionproblem.Here,weformulatethelossfunctiontoin-corporatelocalafﬁnityanddistantrepulsionconstraintsinamatrixfactorizationframework.Thismaintainstheinter-mediacorrespondenceandpreservesintra-mediastructureofthedata,asshownintherightaxesinFig.1.Toourknowledge,thisistheﬁrstattempttoexplicitlypreservethestructureofthedatainunsupervisedcross-mediahashing.Experimentalresultsontwolarge-scaledatasetsdemon-stratetheeffectivenessofourmethod,whereweoutperformthestate-of-the-artmethodsonthesedatasets.2.RelatedworkHashingmethodsseektolearnbinaryrepresentationofdataandhavebeenstudiedextensively.ThesemethodscanLocal AffinityDistant RepulsionStructure PreservingFigure1:Illustrationofthekeyconceptsintheproposedmethod.Topleftaxesdenotetheimagespace,withexam-pleimages,whilebottomleftaxesdepictthetextspaceandexampletextarticles.RightaxesdepictthecommonHam-mingspace.Dashedcoloredlinesdepictimagesandtextwithsimilarsemantics.Byenforcingdistantrepulsionandlocalafﬁnityconstraints,theproposedmethodaimstopre-servethestructureofthedata.becategorizedbasedonthemodalityofdatausedassingle-mediahashingandcross-mediahashing.Single-mediahashingmethodsfocusonthegenerationofhashfunctionsfordatabelongingtothesamemediatype.Spectralhash-ing[20]isoneofthemostpopularhashingmethods.ItseekscompactbinarycodessothattheHammingdistancebetweenhashingcodescorrelateswithfeaturesimilarity.Wangetal.[19]presentedasequentialprojectionhash-ingmethodwhichlearnsthehashfunctionsbymaximizingtheempiricalaccuracywithaninformation-theoreticregu-larizer.Liuetal.[14]proposedakernel-basedsupervisedhashingmethodwhichsequentiallytrainsthehashfunc-tionsbasedonsimilaranddissimilarpairs.Followingthat,aniterativequantizationalgorithm[8]isusedtotransformtheoriginaldatatotheverticesofazero-centeredbinaryhy-percubebyminimizingthequantizationerrorofthetrans-formation.Recently,therehavebeenafewworksoncross-mediahashing,suchas[17,23,12,2,7],inwhichthedatausedareofdifferentmodalitytypes.Thesemethodscanbedi-videdintosupervisedandunsupervisedhashingmethods.Supervisedmethodsrequiresemanticlabelsofthefeatures.Forexample,Zhenetal.[23]modeledinter-modalitylossbyasmoothlyclippedinvertedsquareddeviationfunction,andintroducedahingelossfunctionsothatthehashfunc-tionshavegoodgeneralizationability.Aboostingproce-dureisthenusedtominimizethebiasintroducedbythehashfunctions.Gongetal.[8]developedacross-mediaretrievalmethodwhichmaximizesthecorrelationbetweenthecorrespondingdatapointsindifferentmodalitiesbasedoncanonicalcorrelationanalysis.Byregardinglabelvec-torsasthethirdmodality,theirmethodincorporatesseman-ticlabelsintothecanonicalcorrelationanalysis.Zhangetal.[22]proposedasupervisedmultimodalhashingmethodwheretheymaximizedthesemanticcorrelationamongdif-ferentmodalities.Similarto[23,8],theirmethoddemandssemanticlabelsofthetrainingdata.Bronsteinetal.[2]pro-posedacross-modalitysimilarity-sensitivehashingwheretheylearnedtwogroupsoflinearhashfunctionstopreservesemanticsimilarityamongheterogeneousdatapairs.Ad-aBoostprocedureisthenusedtogeneratemultiplebitsse-quentially.Whilegoodresultsareobtainedby[2,23,8,22],wenotethatthesemethodsdemandsemantic(i.e.class)la-belsofthetrainingdata,whichmaynotbereadilyavailable.Thislimitsitsapplicability.Unsupervisedcross-mediahashingmethodsdonotre-quiresemanticlabelsduringtraining.Giventhatunlabelleddataaremorecommonlyavailable,suchunsupervisedhash-ingmethodsareoftenmoresuitableforpracticalapplica-tions.Songetal.[17]proposedinter-mediahashingwhichutilizedtheconsistencywithineachmediatypetolearnthehashfunctions.Theiralgorithmmaintainsinter-mediacon-sistencyandintra-mediaconsistency,wheresimilardataindifferentandsamemodalitiesareprojectedclosetoeachotherinHammingspace.Yuetal.[21]extendedthiswithakernelizedhashingmethod.Whileimprovedresultswereobtained,theirmethodislessefﬁcientasthequerycannotbeencodedoff-line.In[7],Dingetal.learneduniﬁedlatentrepresentationforcorrespondingdataindifferentmodali-tiesthroughcollectivematrixfactorization.Theirlatentrep-resentationspreservethesimilaritywithalooseboundthatcanbesigniﬁcantlyaffectedbyreconstructionerrors.Con-sequently,theintra-mediastructureisnotwellpreservedbytheirmethod.Wenotethatcurrentgenerationofcross-mediahashingalgorithmsexploitlocalgeometriesofthedatatolearnthehashfunctions.Speciﬁcally,suchfunctionsaredesignedtoensuresemanticallyrelateddatapointsareprojectedclosetogetherintheHammingspace.However,thesemethodsignoretheextentofdissimilaritybetweendatapoints,andhenceglobaldatastructureisnotpreservedintheoptimiza-tion.Consequently,datapointswhicharedissimilarmaybeprojectedclosetogether,andhencebeerroneouslyre-trieved.Inthispaper,welearnlinearhashfunctionsbyex-plicitlypreservinginter-mediaandintra-mediastructureofthedataandshowthatthisimprovesthecross-mediare-trievalperformance.3.StructurePreservingCollectiveMatrixFac-torizationHashingThissectionpresentsourmethodwhichexploitsthecor-respondenceinformationbetweendataofdifferentmodali-tiestolearntheoptimalhashfunctions.Suchinformationcanbeextractedfromdatapairingse.g.photoanditscap-tion(whicharemorereadilyavailableascomparedtose-mantic,i.e.class,labelsofthedata),andrevealssemanticrelationshipsbetweendatapairings.Here,werequirecor-respondingdataofdifferentmodalitiestohavethesamela-tentrepresentation,andleverageonlocalafﬁnityconstraintanddistantrepulsionconstrainttojointlylearntheoptimalhashfunctions.Theseconstraintsaredesignedtopreservetheglobalstructureofthedata(detailedinSect.3.2).Inthisaspect,theproposedmethodincorporatesglobalstruc-turepreservationandinformativelatentrepresentationintoasingleframework.3.1.NotationsWeﬁrstpresentthenotationsthatwouldbeusedinthispaper.LetxidenoteacolumnvectorextractedfromithdatainstanceofmodalitytypeX(e.g.text),wherexi∈RDxandDxisthenumberofdimensionsofxi.WedeﬁneX=[x1,...,xN]asthedatamatrixextractedfromNdatainstancesofthesamemodality.Similarly,wedeﬁneY=[y1,...,yN]asthedatamatrixofNdatainstances,eachofdimensionDy,thatareextractedfromdataofadif-ferentmodalitytypeY(e.g.image).Here,X∈RDx×N,Y∈RDy×N,andxiispairedwithyi.Withoutlossofgen-erality,weassumexi∈Xandyj∈Yarenormalizedandcentered.Foreachbitofthehashcodes,thehashfunctionformodalityXisdeﬁnedashx(x)=sgn(wTxx+bx),wheresgn(·)denotesthesignfunction,wx∈RDxisprojectionvector,andbxisdeﬁnedasthemeanoftheprojection.Sincethedataiscentered,bx=0.Similarly,thehashfunctionformodalityYisdeﬁnedashy(y)=sgn(wTyy+by).Here,weseektolearnthesetofprojectionmatricesPx=[w(1)x,...,w(H)x]T,Py=[w(1)y,...,w(H)y]Twhichpre-servetheintra-mediastructureandinter-mediacorrespon-denceintheprojectedspace,whereHdenotesthenumberofbitsinahashcode.ForanunseendatainstancexpofmodalityXandypofmodalityY,theirtthhashbitcanbetriviallycomputedassgn(w(t)xTxp)andsgn(w(t)yTyp)respectively.Withaslightabuseofnotationforsgn(·),thehashcodesofxpandypcanthenbecomputedassgn(Pxxp)andsgn(Pyyp)respectively.3.2.StructurePreservingFormulationInspiredbythesuccessof[7]whichassignsthesamela-tentrepresentationtodatapairingsandlearnshashcodesfromsuchrepresentations,weformulateourmethodtolearnthesetofprojectionmatricesPxandPyasfollows.Letvidenotethelatentrepresentationofbothxiandyi.Correspondingly,sgn(vi)isthehashcodesofxiandyi.WedenoteV=[v1,...,vN]asthelatentrepresentationsofXandY.ThelatentrepresentationofXcanthenbeobtainedthroughmatrixfactorizationbyminimizingthefunctionkX−UxVk2F[6].Similarly,thelatentrepresen-tationofYcanbeobtainedbyminimizingthefunctionkY−UyVk2F.WehighlightherethatsinceVisthela-tentrepresentationofbothXandY,weimplicitlyensurethatdata-pairingofdifferentmodalitieswouldbemappedontothesamepointintheprojectedspace,i.e.,theirhashcodeswouldbethesame.Consequently,thisensuresstruc-tureofinter-mediadataiswellpreserved.GivenPxastheprojectionmatrixofXandPyastheprojectionmatrixofY,wecanderivePxbyminimizingkV−PxXk2FandPybyminimizingkV−PyYk2F.GiventhedatapointsofdifferentmodalitiesX,Y,andtheirlatentrepresentationV,weimposetwoadditionalcon-straints[13]whichexploittheintra-mediadistributionofthedatatopreserveoverallstructureofthedata.•LocalAfﬁnity:Iftwodatapointsarecloseintheoriginalspace,theirembeddedlatentrepresentationsshouldalsobeclosetoeachother.•DistantRepulsion:Iftwodatapointsarefarapartintheoriginalspace,theirembeddedlatentrepresenta-tionsshouldalsobefarapartfromeachother.Weadoptthegraphregularizationframework[4]topre-servethelocalafﬁnityconstraint.Speciﬁcally,weminimize12NXi=1NXj=1Waijkvi−vjk2(1)whereWa=[Waij]istheafﬁnitymatrix.WedeﬁneWaij=Waxij+Wayij,whereWaxij=λxexp(−kxi−xjk2)istheafﬁnitybetweendatapointsxiandxj.Similarly,wedeﬁneWayij=λyexp(−kyi−yjk2)tobetheafﬁnitybe-tweendatapointsyiandyj.Accordingtotheinferencein[4],eqn.(1)canberewrittenasTr(VLaVT),whereTr(·)denotesthetraceofamatrix,andLa=Da−WaisthegraphLaplacian.DaisadiagonalmatrixwhoseentriesarecolumnsumsofWaandDaii=PiWaij.Wepreservethedistantrepulsionconstraintasfollows.LetWrij=Wrxij+Wryij,whereWrxij=λxkxi−xjk2isthedistancebetweendatapointsxiandxj,andWryij=λykyi−yjk2isthedistancebetweendatapointsyiandyj.Here,weseektominimize12NXi=1NXj=1Wrijexp(−kvi−vjk2).(2)Eqns.(1)and(2)ensuredatastructureofeachmodalityisretainedintheprojectedspace,andhencepreservetheglobalstructureofthedataintheprojectedspace.Byjointlyconsideringallconstraints,projectionmatricesPxandPycanthenbeobtainedbyminimizingtheobjectivefunctionL,L=λxkX−UxVk2F+λykY−UyVk2F+α2Xi,jWaijkvi−vjk2+β2Xi,jWrijexp(−kvi−vjk2)+µkV−PxXk2F+µkV−PyYk2F+γ(kVk2F+kUxk2F+kUyk2F+kPxk2F+kPyk2F)(3)whereγ(kVk2F+kUxk2F+kUyk2F+kPxk2F+kPyk2F)areregularizersonthematrixvariablestoavoidoverﬁtting.3.3.OptimizationObjectivefunctionineqn.(3)isnon-convexwithrespecttotheﬁvematrixvariablesPx,Py,V,Ux,Uy.However,itistriviallyobservedthatbyﬁxinganyfourofthematrixvariablesasconstants,eqn.(3)isconvexwithrespecttotheremainingvariable.Towardsthisend,welearnPxandPybyoptimizingeqn.(3)inaniterativeframework,whereineachiteration,weﬁxfourvariablesasconstantstolearnavaluefortheremainingvariable.Speciﬁcally,byﬁxingPy,V,Ux,UyasconstantsandPxasvariable,wecanderive∂L∂Px=−2µVXT+2µPxXXT+2γPx.Consequently,bysetting∂L∂Pxtobezero,wecanderivetheupdateruleofPxas:Px=VXT(XXT+γµI)−1(4)Similarly,byﬁxingPx,V,Ux,UyasconstantsandPyasvariable,wecanobtaintheupdateruleofPyas:Py=VYT(YYT+γµI)−1(5)TheupdateruleforUxandUycanthenbederivedasUx=XVT(VVT+γλxI)−1,(6)Uy=YVT(VVT+γλyI)−1(7)WedeﬁnetheafﬁnitybetweenviandvjtobeWrijexp(−kvi−vjk2).ByﬁxingPx,Py,UxandUytobeconstantsandsetting∂L∂V=0,wecanobtain:V(αL+(2µ+γ)I)+(λxUTxUx+λyUTyUy)V=λxUTxX+λyUTyY+µPxX+µPyY(8)whereIisanidentitymatrix,L=La−βαLr,andLristhegraphLaplacianofWrijexp(−kvi−vjk2)(computedusingVobtainedinthepreviousstep).Weshoweqn.(8)hasauniquesolutionasfollows.Weﬁrstsimplifyeqn.(8)tobeaSylvesterequationAV+VB=C,whereA=λxUTxUx+λyUTyUy(9)B=αL+(2µ+γ)I(10)C=λxUTxX+λyUTyY+µPxX+µPyY(11)From[11],eqn.(8)hasauniquesolutionifandonlyiftheeigenvaluesofAandBineqns.(9)and(10)respectivelysatisfypi+qj6=0foralli,j,wherepiandqjareeigenval-uesofAandBrespectively.ConsiderthedeﬁnitionofAineqn.(9).Weobservethatbysettingparametersλxandλyofeqn.(3)tobegreaterthanzero,AisasumofGrammatrixwhichissymmetricpositivesemi-deﬁnite.Assuch,pi≥0foralli.Similarly,wenotethatLineqn.(10)isaLaplacianmatrixofagraph,andhenceisalsosymmetricpositivesemi-deﬁnite.GiventhatIissymmetricpositive,withsufﬁcientlargevalueof2µ+γ,Bineqn.(10)ispos-itivedeﬁnite.Assuch,qj>0forallj.Consequently,piandqjsatisfypi+qj6=0andthuseqn.(8)hasauniquesolution.Here,wesolveeqn.(8)asV=P˜VQ−1,where˜vij=˜cijpi+qj,˜C=P−1CQ,andPandQarematricessuchthatP−1APandQ−1BQarediagonalmatrices.Wesummarizetheproposedcross-mediahashingmethodinAlg.1.ThemaincomputationcostcomesfromupdatingV,whichtakesO(N3)timeperiteration.Inprac-ticetheproposedmethodtypicallyconvergeswithin50to100iterations.Algorithm1StructurePreservingCollectiveMatrixFac-torizationHashingINPUT:Heterogeneousdata:XandYHashcodelength:HOUTPUT:PxandPy:projectionmatricesformodalityXandY1:InitializeUx,Uy,V,Px,Pybyrandommatrices2:repeat3:UpdateVbyEqn.(8)4:UpdatePxbyEqn.(4)5:UpdatePybyEqn.(5)6:UpdateUxbyEqn.(6)7:UpdateUybyEqn.(7)8:untilconvergence3.4.ExtensionsTheabovesectiondetailsourcross-mediahashingmethodfortwomodalities.Itisstraightforwardtoextendthemethodforheterogeneousdataofmultiplemodalitiesas:L=XgλgkX(g)−UgVk2F+XgµkV−PgX(g)k2F+α2Xi,jWaijkvi−vjk2+β2Xi,jWrijexp(−kvi−vjk2)+γ(kVk2F+XgkUgk2F+XgkPgk2F)whereX(g)denotesthedatamatrixformodalityg,Waij=λgexp(−kx(g)i−x(g)jk2),andWrij=λgkx(g)i−x(g)jk2.Wealsonotethatiftheclasslabelsoftrainingdataisavail-able,eqn.(3)canbeextendedtobeasupervisedmethodbycomputingWaijandWrijwithdistancebetweenclasslabels.4.ExperimentsWeevaluateourtechniqueonthechallengingWiki[16]andNUS-WIDEdatasets[5]fortwocross-mediaretrievaltasks:(a)imagequeryversustextdatabase,whichseekstoretrievesemanticallyrelevanttextbasedonaqueryimage,and(b)textqueryversusimagedatabase,whichaimstore-trievesemanticallyrelevantimagebasedonaquerytext.Wecompareourretrievalperformanceagainstthestate-of-the-artmultimodalhashingmethodswhichobtainedthebestpublishedresultsonthebenchmarkdatasets.Speciﬁ-cally,wecomparedagainstunsupervisedmulti-modalhash-ingmethodsofDingetal.[7](termedasCMFH),Songetal.[17](termedasIMH)andGongetal.[8](termedasCCA).CMFHutilizescollectivematrixfactorizationtoob-tainuniﬁedlatentrepresentationforhashcodegeneration,butdoesnotpreserveglobaldatastructureintheirformula-tion,unlikeourmethod.IMHgeneratesintra-mediaconsis-tencypreservinghashcodeswithorthogonalityconstraintsandhasbeenevaluatedagainst[12,2]whereitdemon-stratedsuperiorperformance.CCAmaximizestheinter-mediacorrelationusingcanonicalcorrelationanalysis.Un-supervisedmethods,suchasIMH,CMFH,CCAandourproposedmethod,donotdemandexpensiveclasslabellingofthetrainingdata,unlikesupervisedcross-mediahashingmethods.Correspondingly,giventhatmultimediadataof-tendonothaveclasslabel,unsupervisedmethodsaremorepracticalforrealapplications.Nevertheless,wecompareagainsttherecentsupervisedmultimodalmethodofGongetal.[8](termedasCCA-3V)whichhasachievednotablesuccessonthebenchmarkdatasets.Whilethefocusofthispaperiscross-mediaretrieval,themethodcanbeusedinsingle-mediaretrievalandthuswealsoreportedtheperfor-mancefortwosingle-mediaretrievaltasks:(c)imagequeryversusimagedatabase,whichseekstoretrievesemanticallyrelevantimagebasedonaqueryimage,and(d)textqueryversustextdatabase,whichaimstoretrievesemanticallyrelevanttextbasedonaquerytext.4.1.ExperimentalsettingsForallexperimentsinthispaper,weusethefollowingparametersettings.WecomputethegraphLaplacianwithknearestneighbor,wherekissetas5.Wesettheweightforlocalafﬁnityasα=100,andthatfordistantrepulsionasβ=1.Theweightsformatrixfactorizationofdatamodal-ityXissetasλx=0.5,andfordatamodalityYisassetasλy=0.5.Finally,wedeﬁnetheprojectionmatricesweightasµ=100andtheregularizerweightasγ=0.01.Theseparametersareobtainedthrough3foldcross-validationandweﬁndthemodelperformancetobeonlymildlysensitivetotheparametersettings.Reportedresultsofothermethodsinthispaperareob-tainedbythesameparametersettingsasthoseusedinthemethods.Additionally,giventhatmethodsCMFH[7]andproposedmethodareinitializedwithrandommatricesdur-ingtraining,weconducted20runsforeachmethod,andre-porttheiraverageresultsinthepaper.Forallexperiments,weadheretotheevaluationcriteriaofothermethods,and,ascloselyaspossible,usethesametrainingandtestin-stancesasothermethodsforcomparingperformances.Wereportretrievalperformancebythemeanaverageprecision(MAP)score.TheMAPiscomputedbyaveragingtheav-erageprecision(AP)valuesoverallthequeriesinthequeryset.APiscalculatedasAP=PLk=1P(k)r(k)PLk=1r(k),whereListhetotalnumberofretrieveddocuments,P(k)isthepreci-sionofthetop-kretrieveddocuments,andr(k)istherel-evanceofthekthdocument.r(k)isequalto1ifthekthdocumentisrelevanttothequeryandequalsto0otherwise.LargeMAPvaluesindicatebetterretrievalperformance.4.2.RetrievalResultsonWikidatasetTheWikidataset[16]isgeneratedfromWikipedia’sfeaturedarticlescollection,andcontains2,866image-textpairs.Weused2,000image-textpairsfortraining.Foreachimage-textpair,thetextcorrespondstoanarticledescribinganeventoraperson,andtheimageissemanticallyrelevanttothecontentofthetext.Atextarticleisrepresentedbya10-dimensionaltopicdistributionvectorthatiscomputedfromlatentDirichletallocation(LDA)model[1],andanimageisrepresentedbya128-dimensionalbagofwordsthatiscomputedfromSIFTdescriptors[15].Theseimageandtextfeaturesarethesameasthoseusedbythecompar-isonmethods.Eachimage-textpairislabelledwithoneoftensemanticclasses(e.g.art,history).Wedonotusetheselabelsduringtraining,butinsteadusethemonlyforeval-uation:atestdataiscorrectlyretrievedifithasthesameclasslabelasthequerydata.Weuse80%ofthedataasthedatabaseandtheremaining20%toformthequeryset.Table1reportstheMAPretrievalresultsofthepro-posedmethodwithcomparisontostate-of-the-artmethodsacrossthreehashcodelengthsof16,32and64.Were-portthecorrespondingprecision-recallcurvesofthemeth-odsforcross-mediaretrievaltasksinFig.2.Asobserved,forallretrievaltasks,weobtainslightlybetterretrievalre-sultsthanthestate-of-the-artCMFHmethod[7]andout-performCCA,CCA-3V[8]andIMH[17]acrossalltestedhashcodelengths.WehighlightthatCCAandCCA-3Vignorestheintra-mediastructureofthedatatoderivethemultimodalhashingfunctions.WhileIMHandCMFHcon-siderintra-mediasimilarityconstrainttoderivethehashingfunctions,thesemethodsignorethedissimilaritybetweendatapoints.Giventhatourproposedmethodexploitsbothlocalafﬁnityanddistantrepulsionconstraints(andcoupletheseconstraintswithinformativelatentrepresentations)andmoreeffectivelypreservetheglobalstructureofthedataintheprojectedspace,theperformancedifferenceisthusexpected.Itisnoteworthythatasthelengthofthehashcodesincreases,retrievalperformanceofourmethodimproveswhilethatofCCA,CCA-3VandIMHdegrades.Thisisbe-causeCCA,CCA-3VandIMHimposeorthogonalitycon-straintsonthehashcodesandrequireeachbitinthehashcodetobeindependentofeachother.Corresponding,hashbitsintheinitialbitpositionsexhibitlargestpossiblevari-ance(i.e.accountformuchofthevariabilityofthedata),whereasvarianceofhashbitsfromsucceedingbitpositionsaremonotonicallydecreasing[3].Inthisaspect,asthecodelengthincreases,thehashcodeswillcontainmorebitswithlowvariancewhichcanbenoisy[19],andthusleadtode-gradedperformance.Incontrast,ourmethodwhichisbasedonmatrixfactorizationleveragesonlatentmatricestoem-bedtheoriginaldatainformation.Giventhatlongerhashcodesderivedfromhigherdimensionlatentmatricescanencodegreaterextentofdatainformation,itisthusnotsur-prisingthatretrievalperformanceofourmethodimproveswithincreasinglengthofthehashcodes.4.3.RetrievalResultsonNUS-WIDEdatasetTheNUS-WIDEdataset[5]comprises269,648imagesandtheirassociatedtagswhichareobtainedfromFlickr.Ground-truthclasslabels(e.g.sky,tree)fortheimage-tagpairsarealsoavailableinthedataset.Followingtheproto-colsofthecomparisonmethods(CMFH,IMH),weprunedasubsetof186,577image-tagpairsbelongingtothe10largestclasses.SimilartoSect.4.2,weused2,000image-textpairsfortraining,anddonotexploittheclasslabelstotrainthemodelsbutforevaluationonly.Werepresenteachimagesbya500-dimensionalbagofwordsfeaturethatiscomputedfromSIFTdescriptors,anditsassociatedtagbya1,000-dimensionaltagoccurrencefeaturevectors[5].Theseimageandtextfeaturesarethesameasthoseusedbytheothercomparisonmethods.Wedividethissubsetintotwoparts:99%ofthedataisselectedasthedatabasesetandtheremaining1%asthequeryset.Table1:MAPresultsonWikidataset[16].“X→Y”denotes“XqueryversusYdatabaseretrievaltask”.Thebestresultsareshowninbold.MethodImage→TextText→ImageImage→ImageText→TextCodeLengthCodeLengthCodeLengthCodeLength163264163264163264163264CMFH[7]0.22990.24490.25370.21250.22860.24030.14420.14880.15240.50170.52660.5400IMH[17]0.14360.13690.14430.13020.12450.12860.12620.12510.12780.32210.32790.3604CCA[8]0.19300.18660.17730.16060.14250.13240.12770.12290.12070.38460.34790.3479CCA-3V[8]0.17940.17040.16840.15860.14760.13980.12870.12420.12140.44150.42530.4156Proposedmethod0.24320.25360.25980.21950.23450.24360.14820.15110.15340.52440.54530.55740.00.20.40.60.81.00.100.150.200.250.30PrecisionRecall CMFH IMH CCA CCA-3V Proposed(a)ImageQueryv.s.TextDatabase@16bits0.00.20.40.60.81.00.100.150.200.250.30PrecisionRecall CMFH IMH CCA CCA-3V Proposed(b)ImageQueryv.s.TextDatabase@32bits0.00.20.40.60.81.00.100.150.200.250.30PrecisionRecall CMFH IMH CCA CCA-3V Proposed(c)ImageQueryv.s.TextDatabase@64bits0.00.20.40.60.81.00.100.150.200.250.300.350.40PrecisionRecall CMFH IMH CCA CCA-3V Proposed(d)TextQueryv.s.ImageDatabase@16bits0.00.20.40.60.81.00.100.150.200.250.300.350.400.45PrecisionRecall CMFH IMH CCA CCA-3V Proposed(e)TextQueryv.s.ImageDatabase@32bits0.00.20.40.60.81.00.100.150.200.250.300.350.400.450.50PrecisionRecall CMFH IMH CCA CCA-3V Proposed(f)TextQueryv.s.ImageDatabase@64bitsFigure2:Precision-recallcurvesforcross-mediaretrievaltasksonWikidataset(Bestviewedonscreen).Table2reportstheMAPretrievalresultsofthecompari-sonandproposedmethodsacrossvarioushashcodelengths.Asobserved,weobtainedmuchhigherMAPscoresacrossalltestedhashcodelengthsforbothimage-queryandtext-queryretrievaltasks.Thebetterperformanceofourmethodisalsodepictedbytheprecision-recallcurvesshowninFig.3,whereweobtainedhigherprecisionscoresattheevalu-atedrecallvaluesforcross-mediaretrievaltasks.Wealsoreportedthesingle-mediaretrievalperformanceinTable2.Asobserved,weoutperformexistingmethodsforalltestedcodelengths.Importantly,wenotethatthesettinginthisexperimentissimilarinnaturetorealworldscenario,inwhichthesizeofthetrainingdataiscomparativelymuchsmallerthanthesizeofthetestdata.Correspondingly,re-trievalperformanceoftheproposedandcomparisonmeth-odsonthisdatasetisindicativeoftheiractualperformanceinrealscenarios.5.ConclusionsInthispaper,weproposeanovelunsupervisedhashingmethodforcross-mediaretrieval.Weexploitlocalafﬁnityanddistantrepulsionconstraintstopreserveglobalstructureofthedata.Speciﬁcally,weenforcetheconstraintsthatdatapointswhicharesimilarintheoriginalfeaturespaceshouldbeneareachotherintheprojectedspace,whiledis-similardatapointsshouldbeapartfromeachotherintheprojectedspace.Theseconstraintsareincorporatedwithin-formativelatentrepresentationthroughmatrixfactorizationtolearnthehashingfunctions.AstheobjectivefunctionisTable2:MAPresultsonNUS-WIDEdataset[5].“X→Y”denotes“XqueryversusYdatabaseretrievaltask”.Thebestresultsareshowninbold.MethodImage→TextText→ImageImage→ImageText→TextCodeLengthCodeLengthCodeLengthCodeLength163264163264163264163264CMFH[7]0.36680.36400.36290.36620.36360.36260.36180.35970.35890.38080.37880.3781IMH[17]0.37160.36850.36050.37060.36810.36000.36530.36780.37440.41970.42460.4177CCA[8]0.35590.35270.34950.35980.35520.35120.36860.36280.35760.35410.35240.3518CCA-3V[8]0.35700.35400.35120.36140.35740.35420.36790.36280.35900.35630.35370.3519Proposedmethod0.40050.40580.40930.38690.39110.39380.37550.37820.37990.43880.44690.45230.00.20.40.60.81.00.340.360.380.400.420.44PrecisionRecall CMFH IMH CCA CCA-3V Proposed(a)ImageQueryv.s.TextDatabase@16bits0.00.20.40.60.81.00.340.360.380.400.420.44PrecisionRecall CMFH IMH CCA CCA-3V Proposed(b)ImageQueryv.s.TextDatabase@32bits0.00.20.40.60.81.00.340.360.380.400.420.440.460.48PrecisionRecall CMFH IMH CCA CCA-3V Proposed(c)ImageQueryv.s.TextDatabase@64bits0.00.20.40.60.81.00.340.360.380.400.420.440.460.48PrecisionRecall CMFH IMH CCA CCA-3V Proposed(d)TextQueryv.s.ImageDatabase@16bits0.00.20.40.60.81.00.340.360.380.400.420.440.460.48PrecisionRecall CMFH IMH CCA CCA-3V Proposed(e)TextQueryv.s.ImageDatabase@32bits0.00.20.40.60.81.00.340.360.380.400.420.440.460.48PrecisionRecall CMFH IMH CCA CCA-3V Proposed(f)TextQueryv.s.ImageDatabase@64bitsFigure3:Precision-recallcurvesforcross-mediaretrievaltasksonNUS-WIDEdataset(Bestviewedonscreen).non-convex,welearntheoptimalhashingfunctionsthroughaniterativeframework.Weevaluateourmethodontwopopularmultimediadatasetsandcompareagainstthestate-of-the-arthashingmethods.Itisshownthattheproposedmethodconsistentlyoutperformsthecomparisonmethodsonbothsingle-mediaandcross-mediaretrievaltasks.Asfuturework,wewouldliketodevisemoreeffectiveopti-mizationtechniquestoimprovethescalabilityofthepro-posedmethod.Additionally,wewouldalsoliketoextendthisworktomultimodalimagesegmentationandalignment.References[1]D.M.Blei,A.Y.Ng,andM.I.Jordan.Latentdirichletallocation.JMLR,3:993–1022,2003.6[2]M.M.Bronstein,A.M.Bronstein,F.Michel,andN.Paragios.Datafusionthroughcross-modalitymet-riclearningusingsimilarity-sensitivehashing.InCVPR,pages3594–3601,2010.2,3,5[3]C.J.Burges.DimensionReduction.NowPublishersInc,2010.6[4]D.Cai,X.He,J.Han,andT.S.Huang.Graphregu-larizednonnegativematrixfactorizationfordatarep-resentation.TPAMI,33(8):1548–1560,2011.4[5]T.-S.Chua,J.Tang,R.Hong,H.Li,Z.Luo,andY.Zheng.Nus-wide:areal-worldwebimagedatabasefromnationaluniversityofsingapore.InACMCIVR,page48,2009.5,6,8[6]S.C.Deerwester,S.T.Dumais,T.K.Landauer,G.W.Furnas,andR.A.Harshman.Indexingbylatentse-manticanalysis.JASIS,41(6):391–407,1990.4[7]G.Ding,Y.Guo,andJ.Zhou.Collectivematrixfac-torizationhashingformultimodaldata.InCVPR,pages2083–2090,June2014.1,2,3,5,6,7,8[8]Y.Gong,S.Lazebnik,A.Gordo,andF.Perronnin.Iterativequantization:Aprocrusteanapproachtolearningbinarycodesforlarge-scaleimageretrieval.TPAMI,35(12):2916–2929,2013.1,2,3,5,6,7,8[9]J.He,J.Feng,X.Liu,T.Cheng,T.-H.Lin,H.Chung,andS.-F.Chang.Mobileproductsearchwithbagofhashbitsandboundaryreranking.InCVPR,pages3005–3012,2012.1[10]P.IndykandR.Motwani.Approximatenearestneigh-bors:towardsremovingthecurseofdimensionality.InACMSTOC,pages604–613,1998.1[11]A.Jameson.Solutionoftheequationax+xb=cbyin-versionofanm*morn*nmatrix.SIAMJournalonAppliedMathematics,16(5):1020–1023,1968.5[12]S.KumarandR.Udupa.Learninghashfunctionsforcross-viewsimilaritysearch.InAAAI,pages1360–1365,2011.2,5[13]Z.Li,J.Liu,andH.Lu.Structurepreservingnon-negativematrixfactorizationfordimensionalityre-duction.CVIU,117(9):1175–1189,2013.4[14]W.Liu,J.Wang,R.Ji,Y.-G.Jiang,andS.-F.Chang.Supervisedhashingwithkernels.InCVPR,pages2074–2081,2012.2[15]D.G.Lowe.Distinctiveimagefeaturesfromscale-invariantkeypoints.IJCV,60(2):91–110,2004.6[16]N.Rasiwasia,J.CostaPereira,E.Coviello,G.Doyle,G.R.Lanckriet,R.Levy,andN.Vasconcelos.Anewapproachtocross-modalmultimediaretrieval.InACMMultimedia,pages251–260,2010.5,6,7[17]J.Song,Y.Yang,Y.Yang,Z.Huang,andH.T.Shen.Inter-mediahashingforlarge-scaleretrievalfromhet-erogeneousdatasources.InSIGMOD,pages785–796,2013.1,2,3,5,6,7,8[18]C.WangandS.Mahadevan.Manifoldalignmentpre-servingglobalgeometry.InAAAI,pages1743–1749,2013.1[19]J.Wang,S.Kumar,andS.-F.Chang.Sequentialpro-jectionlearningforhashingwithcompactcodes.InICML,pages1127–1134,2010.2,6[20]Y.Weiss,A.Torralba,andR.Fergus.Spectralhash-ing.InNIPS,page6,2008.2[21]Z.Yu,Y.Zhang,S.Tang,Y.Yang,Q.Tian,andJ.Luo.Cross-mediahashingwithkernelregression.InICME,pages1–6,July2014.3[22]D.ZhangandW.-J.Li.Large-scalesupervisedmul-timodalhashingwithsemanticcorrelationmaximiza-tion.AAAI,2014.1,3[23]Y.ZhenandD.-Y.Yeung.Co-regularizedhashingformultimodaldata.InNIPS,pages1385–1393,2012.1,2,3