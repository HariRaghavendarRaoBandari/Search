6
1
0
2

 
r
a

 

M
5
1

 
 
]
T
O

.
t
a
t
s
[
 
 

1
v
2
1
9
4
0

.

3
0
6
1
:
v
i
X
r
a

Dynamic Data in the Statistics Classroom

Johanna Hardin

March 17, 2016

Abstract

The call for using real data in the classroom has long meant using datasets which are culled,

cleaned, and wrangled prior to any student working with the observations. However, an im-

portant part of teaching statistics should include actually retrieving data. Nowadays, there are

many diﬀerent sources of data that are continually updated by the organization hosting the data

website. The R tools to download such dynamic data have improved in such a way to make

accessing the data possible even in an introductory statistics class. We provide four full analyses

on dynamic data as well as an additional six sources of dynamic data that can be brought into

the classroom.

Keywords: data scraping, data science, data analysis pipeline, authentic data

1 Introduction

There has been a recent push to change the way we - as statisticians - engage pedagogi-

cally with complex real-world data analysis problems. Two parallel forces have directed

us toward embracing more complex-data real-world problems.

The ﬁrst force is a call from educators to make the statistics in the classroom rel-

evant to students’ experiences.

In order to address the perspective of students who

previously “exhibit remarkably little curiosity about the material they are analyzing”,

Brown and Kass (2009) give as one of their four main recommendations to “require

real-world problem solving” to get students engaged in their analyses. Gould (2010)

1

implores us to have our introductory statistics students leave the course with “a set

of ... attitudes about data that are immediately applicable to their lives.” Gould and

C¸ etinkaya Rundel (2013) suggest that we put “data at the center of the curriculum.”

Horton et al. (2015) assert that “statistics students need to develop the capacity to

make sense of the staggering amount of information collected in our increasingly data-

centered world.” And Zhu et al. (2013) remind us that “data pre-processing bridges

the gap from data acquisition to statistical analysis but has not been championed as a

relevant component in statistics curricula.”

The second force is from the students and is harder to document with references.

Certainly my own experience (and that of my colleagues) is that students engage at

the deepest level when they (a) care about the problem, and (b) understand the data

collection, study design, or motivation of the problem. Kuiper and Sturdivant (2015)

reports, “Our student evaluations of these materials support Gould’s (2010) comments

suggesting that previously collected and cleaned data were considered abstract to the

student ... We have found that unless students 1) have collected the data themselves or

2) clearly see where and how the data were collected, they often fail to appreciate it.”

Indeed, even if the work is done for them, as Grimshaw (2015) argues, there is much

beneﬁt in the students seeing how the data were procured.

Using the vocabulary of Wickham (2014), teachers hide the ‘messy data’ as-

pects and provide ‘tidy data’ - even when students possess the data skills

required to work with the messy data. It is valuable for students to not only

have many authentic data experiences but also to have the professor model

the correct application of statistics by showing work with messy data in lec-

tures...What is good for statistics majors can also be applied to introductory

courses. There may be no data skills on the learning outcomes for these

courses, but some examples and homework in an introductory course may be

2

modiﬁed and/or updated to use the original source data instead of a curated

dataset. The data skills required would certainly be modest and need to ﬁt

student backgrounds. The objective would be for students to see that data

skills are required in an analysis. Students may rely on code provided to them

that results in their own copy of the dataset.

Previously and for many years there has been a call for using real data in the class-

room (Cobb, 1991, 1992, 2007, 2011; Workgroup on Undergraduate Statistics, 2000;

GAISE College Group, 2005). We have seen the beneﬁt of using real data sets (as

opposed to made up numbers) in textbooks and in the classroom. Indeed, there are

virtually no textbooks of any kind (AP Statistics, Introductory Statistics, second course

in statistics) being written today without the vast majority of examples taken from ac-

tual studies or databases. Additionally, there has been a push to infuse R with datasets

that are relevant, recent, and sophisticated (e.g., nycﬂights and other mosaic datasets,

(Pruim et al., 2014)).

Unfortunately, by nature, however, all of the data given in a textbook or an R package

is static. Currently, there do not exist mechanisms to continually update any dataset

provided by the course materials. The most comprehensive baseball dataset compiled

and provided to the students will be out of date (and seemingly uninteresting) by next

fall. The good news, however, is that outside of the statistics classroom there is data of

all kinds are being updated in real time publicly and accessibly. And even better news

is that R developers are continually improving interfaces to the vast amounts of public

data. For example, Hadley Wickham of RStudio has written a handful of packages that

make downloading data straightforward (e.g., see Wickham (2014) and more recently

the functions: rvest, readr, and readxl; expect more functions to come).

Grimshaw (2015) provides a clear way of delineating data along two axes as good/better/best:

the ﬁrst axis describes the source and format for the data; the second axis describes the

3

amount of wrangling required on the data. Indeed, Grimshaw gives examples, sources,

and R code for a few examples to be used in all categories, including the “best/best”

category. However, he has only one dataset from the “best/best” category that worked

well in his classroom. Out of the three “best/best” datasets he used, two were not well

received because of excessive time, computing expertise, or domain knowledge needed

to wrangle the data into usable format.

In this manuscript, we provide examples (including full R Markdown ﬁles) for down-

loading and using dynamic data in the classroom. In the next section we discuss helpful

hints for using the ﬁles in a classroom. Section 3 gives summaries of each dataset as

well as a list of other places to look for dynamic data. We conclude the paper in Section

4.

2 Helpful Hints

As part of the supplementary ﬁles, we have provided R Markdown ﬁles giving both

R code and related pedagogical commentary associated with diﬀerent dynamic data

examples for use in a statistics classroom. The data have all been collected directly

from outside sources - websites that are updated periodically (and with information the

students can access on their own).

2.1 What is an API?

An Application Programming Interface (API) is a set of programming instructions

(written in code, giving the appropriate algorithm) for downloading data from a website

that contains - typically - vast amounts of data. For example, Twitter has an API

(https://dev.twitter.com/overview/api) which tells programmers how to access

tweets (and related information) directly from the Twitter website. At an introductory

level, it is recommended to use an R (or other software) package or function that allows

4

R to speak to the API in order to download the data. For example, the R package

twitteR provides an interface to the Twitter API. Though the examples below do not

rely on APIs or a related R interface, it is important to be aware of APIs (and tell your

students!) to greatly increase the sources of data available to you and your students.

2.2 R Markdown

The R Markdown ﬁles provided as supplementary materials give reproducible analyses

on data collection through analysis and synthesis of the results. The students get the

important practice of tracking each and every step of their work. Reproducible analysis

has recently gotten a lot of press (Johnson, 2014; Stodden et al., 2014), and R Studio

(RStudio Team, 2015) has produced a user friendly format for combining R code with

html (or LATEX) word processing.

R Markdown has a short learning curve and will be straightforward for your students

to implement. One of the key considerations is that when running an R Markdown ﬁle,

the ﬁle does not pay attention to anything running locally. R Markdown essentially

restarts R, so the current state of your R session is totally irrelevant. Recall that the

purpose of R Markdown is to create reproducible ﬁles, so the Markdown ﬁle should run

on any computer anywhere (regardless of the local environment). Horton et al. (2015)

discuss the merits of reproducible research as well as the ease of using R Markdown in

the classroom.

Important note: Any package used in an R Markdown ﬁle needs to be installed

prior to compiling the Markdown ﬁle. That is, if there is a line of code which says

library(dplyr), then before running the Markdown ﬁle, you must run install.packages("dplyr")

from within the console one time (ever).

5

2.3 Great R functions

Some important R functions and packages that will help you and your students navigate

importing and using data in R include:

• dplyr package for data wrangling in general

• The glimpse function in dplyr

• tidyr for converting between wide and long formats and for the very useful ex-

tract numeric() function

• ggplot2 for faceted graphing (also, ggvis) (Wickham, 2009)

• openintro (or packages that come with the textbooks you use) which are great for

pulling up any dataset from the text and building on it in class (Diez et al., 2012)

• mosaic for consistent syntax and helpful functions used in introductory statistics

(Pruim et al., 2014)

• googlesheets for loading data directly from Google spreadsheets

• lubridate if you ever need to work with any date ﬁelds

• stringr for text parsing and manipulation

• rvest for scraping data oﬀ the web; readxl for reading excel data

• readr (and fread with data.table) for loading large datasets with default stringsAs-

Factors = FALSE

• tables for nice looking summary tables.

2.4 Using dynamic data within a typical classroom

For each of the projects below, there is an R Markdown ﬁle which scrapes the data from

an outside web source (presumably kept current and public by some other organization).

Using the data, we start by performing two pieces of the analysis: (1) a graphical

6

representation of the data, (2) an inferential analysis of the data. For each example,

we try to prompt the students to think carefully about what the inference actually says

about the underlying mechanisms that led to the data collection. In some cases we feel

like the conclusions are easy to justify and communicate, in other settings they are not.

2.5 Thinking outside the box

Additionally, we add a section for each analysis which is based on analyses which are

not traditionally taught in introductory statistics classes. The additional analysis is

done not only to expand the tool box of the students, but also to teach the students

that they can think about the problem in sophisticated ways even if all their tools come

only from the introductory course.

We try to communicate to the students that there is information in most data sources.

We want to be wary and attentive to issues of experimental design and systematic biases.

However, we do not want to leave our students feeling stuck every time they encounter

a dataset which has not been gathered from a large randomized trial. Instead, we try

to think of the pieces of the analysis which can elicit information which is interesting

or possibly hypothesis generating.

As Notz indicates, students at every level are ready to examine complicated rela-

tionships using tools which are accessible before taking multiple advanced statistics

courses. “Unfortunately, many instructors teach the sections on data analysis as de-

scriptive statistics, perhaps because this is what they experienced in their ﬁrst course.

They emphasize the process of calculating numerical summaries and making graphical

displays, rather than using these as tools to explore what the data are saying.” (Notz,

2015)

To keep our students from getting stuck, “we must ask questions such as whether

the data allow generalization to a larger population, whether their structure can be

7

meaningfully described with the models we wish to ﬁt, and whether important sub-

groups or individuals were excluded from the data. Exceptions, anomalies, outliers,

and subgroups are best recognized and understood in the context of the question being

addressed.” (De Veaux and Velleman, 2015)

3 Authentic Data Analysis Projects

For each project below, we describe where the data come from, what research questions

are of interest, which standard and graphical techniques were used, and how we thought

about and applied a statistical analysis which was post Introductory Statistics.

3.1 Wikipedia

Wikipedia stores most of its tabular data in html tables. The R function readHTMLTable

seamlessly scrapes all HTML tables from any website. As an initial foray into download-

ing data directly from the internet into R, Wikipedia tables provide a nice introduction.

In the R Markdown ﬁle associated with the Wikipedia data analysis, we also walk

through some of the useful aspects of using dplyr to wrangle the data1.

Using dynamic data within a typical classroom

The introductory analysis uses a t-test, a Wilcoxon rank sum test, data transformations,

and boxplots to investigate music retail sales across countries (see Figure 1). The dataset

is not large, and the p-value is not signiﬁcant. The analysis leads to what could be

interesting conversations about the source of the data and the reasons why p-values

are non-signiﬁcant. The analysis extends easily to each student choosing their own

Wikipedia page and data table.

1Original idea for this example provided by Nick Horton, Amherst College.

8

Figure 1: The log of the retail value of music sales broken down by whether or not the sales have
increased or decreased (presumably over the last year, though the documentation does not specify
over what time period the change is measured).

Thinking outside the box

Among the variables are the breakdown (percentages) of how the retail sales are dis-

tributed across physical, digital, performance rights, and synchronization. We might

want to see whether there is a dependency of total retail sales on the breakdown of types

of products. The problem is not well suited to introductory statistics as there is not an

obvious statistic we can use within a sampling distribution (to create a p-value, etc.).

Because there does not seem to be an obvious mechanism for evaluating the breakdown

9

decreaseincrease5678log retail value vs. change in value over 2013 to 2014change in valuelog retail value $ US millionsof products (and how “diﬀerent” they are), we will consider an ad-hoc measure and then

perform a permutation test to assess signiﬁcance. The average breakdown of retail sales

is given in the R Markdown ﬁle in the supplementary materials. One way to measure

a discrepancy between the retail sales and the consistency of product breakdown is to

correlate the retail sales with the sum of squared distances from the average breakdown

of product types. We see that the metric we created to ﬁnd a relationship between retail

sales and breakdown of types of product does not show signiﬁcance. A good student

project would be to think about diﬀerent ways to measure how the breakdowns can be

considered to be diﬀerent.

3.2 NHANES

The NHANES data come from the National Health and Nutrition Examination Survey,

surveys given nationwide by the Center for Disease Controls (CDC). The CDC followed

the following sampling procedure:

1. Selection of primary sampling units (PSUs), which are counties or small groups of

contiguous counties.

2. Selection of segments within PSUs that constitute a block or group of blocks con-

taining a cluster of households.

3. Selection of speciﬁc households within segments.

4. Selection of individuals within a household

About 12,000 persons per 2-year cycle were asked to participate in NHANES. Re-

sponse rates varied by year, but an average of 10,500 persons out of the initial 12,000

agreed to complete a household interview. Of these, about 10,000 then participated in

data collection at the mobile exam center. The persons (observational units) are located

in counties across the country. About 30 selected counties were visited during a 2-year

10

survey cycle out of approximately 3,000 counties in the United States. Each of the four

regions of the United States and metropolitan and non-metropolitan areas are repre-

sented each year. As such, the data collection is ongoing, and the data are updated on

the NHANES website periodically, http://www.cdc.gov/nchs/nhanes.htm. We will

work with the 2011-2012 data, but we expect the data to be updated regularly, and the

URL should simply change to 2013-2014 when available.

Note that the NHANES data are available in the mosaic package (Pruim et al.,

2014), but the mosaic version of the NHANES data is static (from 2011-2012), and the

data has been cleaned with variables already chosen for you. By accessing the data

directly from the website, students become more involved in the data analysis process,

understanding what they can and cannot get from the data.

The variables in the NHANES dataset are virtually limitless. We use a few diﬀerent

datasets, merging them based on an individual identiﬁer in the dataset. The variable

information is all given online, but each at a diﬀerent webpage. For example, the

demographic data is at http://wwwn.cdc.gov/nchs/nhanes/search/variablelist.

aspx?Component=Demographics&CycleBeginYear=2011.

Additionally, the variables can be downloaded directly using the nhanesA package in

R. https://cran.r-project.org/web/packages/nhanesA/vignettes/Introducing_

nhanesA.html.

Using dynamic data within a typical classroom

We start with a comparison of BMI on those in committed relationships and those not

in committed relationships. The graphs of the two BMI distributions look quite similar,

but the t-test shows a statistically signiﬁcant diﬀerence in means. While we might

actually believe the t-test does report accurately on the population, we wonder how

useful the results are given the large amount of variability within the distributions of

11

the individual BMIs. We prompt a discussion about averages versus individual results,

causation, and sample size.

Thinking outside the box

Because of the large sample size, smoothing techniques can be used to assess relation-

ships between quantitative variables. Adding a smooth curve to a standard scatterplot

leads (see Figure 2) to discussions about how smooth curves are created, SE of the

smooth curve, extra variability due to extremes and also due to fewer data points on

the ends, extrapolation (note that the two curves have diﬀerent ranges), and the slopes

of the two curves not seeming substantially diﬀerent (no interaction) though might

warrant further study.

12

Figure 2: A scatterplot of weight and height broken down by gender. A smooth regression is ﬁt
to the points, and the conﬁdence interval for the smooth curve as well as the increase in variability
for large values of height are part of an important discussion in a second level regression course.

3.3 Literacy Rates

The data come from GapMinder http://www.gapminder.org/. Here we work with

literacy rates, but the analysis could easily be extended for students interested in all

sorts of political, social, environmental, or demographic data available. Understanding

political and demographic trends across both time and location can provide very inter-

esting insight into economic or political science questions. The GapMinder data can

also be simply perused in a descriptive manner by curious students.

13

50100150200150170190HeightWeightgenderfemalemaleHeight vs Weight by Gender with Smooth Regression FitUsing dynamic data within a typical classroom

The introductory analysis includes a linear regression on the diﬀerence between female

and male literacy rates across time. We show a graphical representation and discuss

model assumptions including sampling and independence of residuals. We believe that

the data do show that the diﬀerence between male and female literacy rates is shrinking

over time. However, we worry about the eﬀects of other variables and encourage a

more complete analysis. Indeed, there may be large biases in our model if important

explanatory variables have been left out.

The data provided are ideal for a fantastic classroom conversation about causation,

causal mechanisms, and confounding variables.

Thinking outside the box

In the second analysis, we work with the additional variable continent. The trends

observed in the ﬁrst analysis hold up in the second analysis (i.e., the diﬀerence declines

over time in each of the continents). However, there are additional considerations to be

made, for example, the diﬀerences between the slopes across the continents. We suggest

additional explorations into the independence of the residuals and more advanced spatio-

temporal patterns of literacy.

3.4 Weather Day from NOAA Buoys

The National Oceanic and Atmospheric Administration (NOAA) is the American federal

agency in charge of collecting information and making decisions related to the oceans

and the atmosphere. Throughout North America, they supply weather stations which

are located both along the coast as well as in the middle of the ocean (on buoys).

Among other variables, the weather stations collect information on wind, humidity,

temperature, visibility, and atmospheric pressure. The data is all publicly available on

14

NOAA’s website, http://www.ndbc.noaa.gov/.

Using dynamic data within a typical classroom

Although the data do not constitute a random sample, they are very likely to be quite

representative with respect to the diﬀerence in wind and air temperature at that lo-

cation over the year. We used a paired analysis (i.e., subtract the two variables and

treat them as a single variable) to ﬁnd a conﬁdence interval for the true diﬀerence in

temperature between wind and air. Also, we ﬁnd a prediction interval for the diﬀerence

in temperatures across individual measurements.

Thinking outside the box

Although a full analysis of the data would warrant multiple years of data (so as to

understand yearly trends), we can estimate the spectral density of the time series

using a smoothed periodogram.

In the smoothed periodogram (see Figure 3) the

x-axis is the frequency (one over the period) and y-axis represents the correlation

(normalized) between the cosine wave at that frequency and the time series. We

can see that wind speed has strong correlation at period 12 hours and period 24

hours. A more sophisticated analysis or longer project could include collecting data

from multiple buoys, extended years, and/or additional information on storms https:

//www.ncdc.noaa.gov/stormevents/.

15

Figure 3: A smoothed periodogram of Wind Speed for buoy #46025 oﬀ the coast of Santa Monica.
The dashed lines are at 1/12 and 1/24, representing 12-hour and 24-hour periodicity.

3.5 College Scorecard

Data on characteristics of US institutions of higher education was collected in an eﬀort

to make more transparent issues of cost, debt, completion rates, and post-graduation

earning potential. An undertaking of the U.S. Department of Education, the College

Scorecard data represent a compilation of institutional reporting, federal ﬁnancial aid

reports, and tax information. The process of gathering and compiling the data is well

documented on the College Scorecard website https://collegescorecard.ed.gov/

data/documentation/. One caveat is that some of the variables have been collected

16

0.00.10.20.30.40.50.51.02.05.020.050.0Frequency = 1/periodspectrumWind Speed, Smoothed Periodogrambandwidth = 0.00167only on students receiving federal ﬁnancial aid. Biases inherent to analyses done on

data collected from such a subgroup should be considered.

Using dynamic data within a typical classroom

Using the two variables measuring amount of debt of a typical (i.e., median) college

graduate and median earning 10 years after matriculation, we create both conﬁdence

intervals and prediction intervals. The prediction value is for an institution (which is the

observational unit). The analysis lends itself nicely to a conversation about conﬁdence

vs. prediction intervals as well as observational units as institution vs. as individual

student. Additionally, the plot below (see Figure 4) demonstrates the eﬀect of samples

size: consider the comparison of the Military intervals (1 school) to the intervals for all

of the US institutions (about 6000 schools).

17

Figure 4: The x-axis represents the region of the institution. The y-axis represents either the
amount of debt 10 years after graduation (blue) or the amount of income 10 years after graduation
(orange). Conﬁdence intervals for the average values (across region) are given by the solid lines.
Prediction intervals for individual institutions are given by the dashed lines.

Thinking outside the box

The dataset is incredibly rich and can be used for many diﬀerent types of model build-

ing: linear, logistic, machine learning. Indeed, thinking about interaction terms could

be particularly insightful. We give an example of regressing earnings on debt with

the interaction term as whether or not the institution is one of the Historically Black

Colleges and Universities (HBCU).

18

0e+005e+041e+05Far WestGreat LakesMid EastMilitaryNew EnglandOutlyingPlainsRocky MntsSoutheastSouthwestUSRegion$debt or $income 10 years outtypeconfpredcostdebtearn3.6 Other Dynamic Datasets

There are myriad sources of dynamic data which are public and accessible. We list a

few additional resources here.

3.6.1 Baseball Data

Many of our students are interested in sports statistics. In particular, many statisticians

and sabermatricians have worked over the years to compile datasets and to think care-

fully about statistical methods applied to baseball data. Today’s datasets can answer

questions like: What is the probability of a particular event happening given certain

real time situations?

Albert (2010) provides curated seasonal batting data from 1871 to 2009 at http:

//www.amstat.org/publications/jse/v18n3/mlb_batting.dat.txt. With the pas-

sage of time, the examples of Derek Jeter and Alex Rodriguez as current players and

batting trends up to 2009 are less timely to students interested in sports, and what was

once a current research question has become stagnant and ossiﬁed. However, Albert

(2010) provides suﬃcient detail about the collection of ﬁles on the Lahman Baseball

Database (http://www.seanlahman.com/baseball-archive/statistics/ with data

available as a .zip ﬁle which can be read directly into R http://seanlahman.com/

files/database/lahman-csv_2015-01-24.zip) and tasks required to ﬁlter and merge

the master and batting ﬁles that the research questions and teaching notes can updated

to reﬂect current players and trends. Also see Ben Baumer’s blog Exploring Baseball

Data with R, https://baseballwithr.wordpress.com/.

3.6.2 Cherry Blossom Ten Mile Run

Each year in April, The Cherry Blossom Ten Mile Run happens in Washington, DC

(http://www.cherryblossom.org/theraces/tenmile.php). The race results (includ-

19

ing ﬁnishing time, name, age, hometown, and pace) are available from 1999 to the

present (although admittedly, the results after 2012 are more diﬃcult to scrape oﬀ the

web). Kaplan and Nolan (2015) provide step-by-step instructions for scraping the data

and wrangling it into a format which can be used to investigate race results over time,

by age, or by gender.

3.6.3 Fatal Accidents & US Census Data

The National Highway Traﬃc Safety Administration collects data on all fatalities suf-

fered in motor vehicle traﬃc crashes. The data is posted yearly and publicly, http:

//www.nhtsa.gov/FARS. Each year is posted as a separate set of ﬁles, available in diﬀer-

ent formats. For example, to download SAS data (readable into R via the read.sas7bdat

function in the sas7bdat package) or the sasxport.get function in the Hmisc package,

use the data at ftp://ftp.nhtsa.dot.gov/fars/2014/SAS/. Another dataset which

is easily accessible is the census data (http://factfinder2.census.gov/faces/nav/

jsf/pages/index.xhtml. By looking at the Decennial Census data and then to the

Proﬁle of General Population and Housing Characteristics, students can study the ages

and other demographic characteristics of the general population as compared to those

individuals involved in fatal accidents2.

3.6.4 Climate Data

Witt (2013) describes using data in class to reveal important insights on climate for

statistics students. The data and analyses describe both decline of Arctic sea ice

and global temperature increase. The (static) data used in the analyses is available

through The Journal of Statistics Education, http://www.amstat.org/publications/

jse/v21n1/witt.pdf, but the authors also provide links and information about the

original data sources which are dynamic.

2Original idea for this example from Laura Kapitula, Grand Valley State University.

20

In particular, realclimate.org (http://www.realclimate.org/index.php/data-sources/)

provides a catalogue of many diﬀerent types of climate data and relevant source infor-

mation. Witt (2013) also reports:

NASAs Global Change Master Directory is available at http://gcmd.gsfc.

nasa.gov/. NOAAs National Climate Data Center maintains an extensive

data directory available at http://www.ncdc.noaa.gov/oa/ncdc.html. Yet

another good climate data source is the Data Guide maintained by the Na-

tional Center for Atmospheric Research Climate at https://climatedataguide.

ucar.edu/.

3.6.5

Iowa Liquor Sales

Iowa recently released an 800MB+ dataset containing all the weekly liquor sales from

January 1, 2014 to the present https://data.iowa.gov/Economy/Iowa-Liquor-Sales/

m3tr-qhgy. The data seems to be updated monthly. Dan Nguyen has provided some

code (not R code) for downloading and wrangling the data https://gist.github.com/

dannguyen/18ed71d3451d147af414. Because the data are available in a csv format,

they can be read into R directly using read.csv after downloading from the data.iowa.gov

URL. The SQL code from the Nguyen’s github site can be translated directly into R

using the dplyr package.

3.6.6 Medicare Inpatient Charges

Medicare inpatient charge data is available at https://www.cms.gov/Research-Statistics-Data-and-Systems/

Statistics-Trends-and-Reports/Medicare-Provider-Charge-Data/Inpatient2013.

html which links directly to a zipped csv ﬁle. An analysis of the costs for Medicare Sever-

ity Diagnosis Related Group (MS-DRG) (i.e., the procedure) can be done over many

diﬀerent covariates.

21

4 Conclusion

The few examples provided here give a glimpse into how undergraduate statistics and

introductory classrooms can incorporate real and dynamic data. The Guidelines for

Assessment and Instruction in Statistics Education (GAISE) are currently being revised,

and their authors implore us to make one small change in our courses to keep up

with changing technology and data (Everson and Mocko, 2015). In this manuscript we

have provided tools for helping educators seamlessly incorporate dynamic data into a

standard and modern introductory (or beyond) statistics course. We also hope that

statistics students will see the diﬀerent ways of accessing data and feel empowered to

gather more information on their own. Our courses must remain relevant to both the

student experience and the research community or we run the risk of become irrelevant.

Small steps will get us where we need to be.

5 Acknowledgements

This work was supported by Project MOSAIC (NSF grant 0920350, Phase II: Build-

ing a Community around Modeling, Statistics, Computation, and Calculus). Addi-

tionally, the data sources were found with help from many individuals. For exam-

ple, check out Wes Stevenson’s great blog on importing data into R3. Jenny Bryan’s

R package googlesheets is a huge step forward for accessing data4. The guide to

reading baseball data from baseball-reference.com was taken from Jim Albert’s blog

https://baseballwithr.wordpress.com/. Many of the data sets were inspired by

work by or conversations with Nick Horton, Ben Baumer, Scott Grimshaw, Janie Neal,

Gabe Chandler, Ciaran Evans, Samantha Morrison, and Maddi Cowen.

3http://statistical-research.com/importing-data-into-r-from-different-sources/
4http://blog.revolutionanalytics.com/2015/09/using-the-googlesheets-package-to-work-with-google-sheets.

html

22

References

Albert, J. (2010), “Baseball Data at Season, Play-by-Play, and Pitch-by-Pitch Levels,”

Journal of Statistics Education, 18(3).

Brown, E. N., and Kass, R. E. (2009), “What is Statistics?,” The American Statistician,

63(2), 105–110.

Cobb, G. (1991), “Teaching Statistics: More Data, Less Lecturing,” UME Trends,

pp. 3–7.

Cobb, G. (2007), “The Introductory Statistics Course: A Ptolemaic Curriculum?,”

Technology Innovations in Statistics Education, 1(1).
URL: https://escholarship.org/uc/item/6hb3k0nz, last accessed March 7, 2015

Cobb, G. (2011), “Teaching statistics: some important tensions,” Chilean Journal of

Statistics, 2(1), 31–62.

Cobb, G. W. (1992), “Teaching Statistics,” In Lynn A. Steen (ed), Heeding the call for

change: suggestions for curricular action (MAA Notes No. 22), pp. 3–43.

De Veaux, R., and Velleman, P. (2015), “Teaching Statistics Algorithmically or Stochas-
tically Misses the Point: Why not Teach Holistically? (Online discussion of ”Mere
Renovation is Too Little Too Late: We Need to Rethink Our Undergraduate Cur-
riculum From the Ground Up,” by George Cobb, The American Statistician),” The
American Statistician, 69(4).

Diez, D. M., Barr, C. D., and C¸ etinkaya Rundel, M. (2012), openintro: OpenIntro data

sets and supplemental functions. R package version 1.4.
URL: http://CRAN.R-project.org/package=openintro

Everson, M., and Mocko, M. (2015), “Updating the Guidelines for Assessment and

Instruction in Statistics Education (GAISE),”.
URL: https://www.causeweb.org/webinar/teaching/2015-07/index.php

GAISE College Group (2005), Guidelines for Assessment and Instruction in Statistics

Education,, Technical report, American Statistical Association.
URL: http://www.amstat.org/education/gaise, accessed March 7, 2015

Gould, R. (2010), “Statistics and the Modern Student,” International Statistical Review,

78(2), 297–315.

Gould, R., and C¸ etinkaya Rundel, M. (2013), “Using Tools for Learning Statistics and

Mathematics,”.

Grimshaw, S. (2015), “A Framework for Infusing Authentic Data Experiences Within

Statistics Courses,” The American Statistician, 69(4), 307–314.
URL: http://arxiv.org/abs/1507.08934

23

Horton, N. J., Baumer, B., and Wickham, H. (2015), “Setting the stage for data sci-
integration of data management skills in introductory and second courses in

ence:
statistics,” CHANCE, 28(2), 40–50.
URL: http://arxiv.org/abs/1502.00318, last accessed March 7, 2015

Johnson, G. (2014), “New Truths That Only One Can See,”.

URL: http://www.nytimes.com/2014/01/21/science/new-truths-that-only-one-can-
see.html

Kaplan, D., and Nolan, D. (2015), “Data Science in R: A Case Studies Approach to

Computational Reasoning and Problem Solving,”.

Kuiper, S., and Sturdivant, R. X. (2015), “Using Online Game-Based Simulations to
Strengthen Students’ Understanding of Practical Statistical Issues in Real-World Data
Analysis,” The American Statistician, 69(4), 354–361.

Notz, W. (2015), “Vision or Bad Dream? (Online discussion of ”Mere Renovation is
Too Little Too Late: We Need to Rethink Our Undergraduate Curriculum From the
Ground Up,” by George Cobb, The American Statistician),” The American Statisti-
cian, 69(4).

Pruim, R., Kaplan, D., and Horton, N. (2014), mosaic: Project MOSAIC (mosaic-

web.org) Statistics and Mathematics Teaching Utilities. R package version 0.9-1-3.
URL: http://CRAN.R-project.org/package=mosaic

RStudio Team (2015), Studio: Integrated Development Environment for R, RStudio,

Inc., Boston, MA.
URL: http://www.rstudio.com/

Stodden, V., Leisch, F., and Peng, R. D., eds (2014), Implementing Reproducible Re-

search Chapman and Hall / CRC Press.

Wickham, H. (2009), ggplot2: elegant graphics for data analysis Springer New York.

URL: http://had.co.nz/ggplot2/book

Wickham, H. (2014), “Tidy Data,” Journal of Statistical Software, 59(10).

URL: http://www.jstatsoft.org/v59/i10/, last accessed March 7, 2015

Witt, G. (2013), “Using Data from Climate Science to Teach Introductory Statistics,”

Journal of Statistics Education, 21(1).

Workgroup on Undergraduate Statistics (2000), Guidelines for Undergraduate Statis-
tics Programs, http://www.amstat.org/education/curriculumguidelines.cfm,
accessed August 18, 2013,, Technical report, American Statistical Association.

Zhu, Y., Hernandez, L. M., Mueller, P., Dong, Y., and Forman, M. R. (2013), “Data Ac-
quisition and Preprocessing in Studies on Humans: What is Not Taught in Statistics
Classes?,” The American Statistician, 67, 235–241.

24

