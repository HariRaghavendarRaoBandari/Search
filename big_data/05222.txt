6
1
0
2

 
r
a

 

M
6
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
2
2
2
5
0

.

3
0
6
1
:
v
i
X
r
a

Scaling transition for nonlinear random ﬁelds

with long-range dependence

Vytaut˙e Pilipauskait˙e1,2 and Donatas Surgailis1

1 Vilnius University, Akademijos 4, LT-08663 Vilnius, Lithuania

2 Universit´e de Nantes, 1, quai de Tourville BP, Nantes 44313, France

March 17, 2016

Abstract. We obtain a complete description of anisotropic scaling limits and the existence of

scaling transition for nonlinear functions (Appell polynomials) of stationary linear random ﬁelds
on Z2 with moving average coeﬃcients decaying at possibly diﬀerent rate in the horizontal and

vertical direction. The paper extends recent results on scaling transition for linear random ﬁelds

in [30], [31].

Keywords: scaling transition; anisotropic long-range dependence; fractionally integrated random ﬁeld; Appell polyno-

mials; multiple Itˆo-Wiener integral; fractional Brownian sheet

1 Introduction

[30] introduced the notion of scaling transition for stationary random ﬁeld (RF) X = {X(t, s); (t, s) ∈ Z2} on
Z2 in terms of partial sums limits

D−1

λ,γ X(t,s)∈K[λx,λγ y]

X(t, s)

fdd−→ Vγ(x, y),

(x, y) ∈ R2

+, λ → ∞,

γ > 0

(1.1)

where Dλ,γ → ∞ is normalization and K[λx,λγ y] := {(t, s) ∈ Z2 : 1 ≤ t ≤ λx, 1 ≤ s ≤ λγy} is a family of
rectangles whose sides grow at possibly diﬀerent rate O(λ) and O(λγ) and γ > 0 is arbitrary. See the end of

this section for all unexplained notation. RF X is said to exhibit scaling transition at γ0 > 0 if the limit RFs
Vγ ≡ V X
viz.,

in (1.1) do not depend on γ for γ > γ0 and γ < γ0 and are diﬀerent up to a multiplicative constant,

γ

V X
γ

fdd= V X

+ (∀γ > γ0),

V X
γ

fdd= V X

− (∀γ < γ0),

V X
+

fdd

6= aV X

− (∀a > 0).

(1.2)

In such case, RF V X

− the unbalanced scaling limits of X.
It appears that scaling transition is a new and general feature of spatial dependence which occurs for many

γ0 is called the well-balanced while RFs V X

+ and V X

isotropic and anisotropic RF on Z2 with long-range dependence (LRD). It was established for a class of

1

aggregated α-stable autoregressive models [30], a class of Gaussian LRD RFs [31], and some RFs arising by

aggregation of network traﬃc and random-coeﬃcient time series models in telecommunications and economics;
see [11], [22], [26], [27], also ([30], Remark 2.3). The unbalanced limits V± in the these studies have a
very special dependence structure (either independent or invariant rectangular increments along one of the

coordinate axes) and coincide in the Gaussian case with a fractional Brownian sheet (FBS) BH1,H2 with one
of the two parameters H1, H2 ∈ (0, 1] equal to 1/2 or 1.

The above mentioned works deal with linear RF models written as sums (stochastic integrals) w.r.t. i.i.d.

‘noise’. It is well-known that nonlinear RFs can display quite complicated nongaussian scaling behavior. See

Dobrushin and Major [9], also [1], [2], [13], [14], [16], [19], [21], [33], [34] and the references therein.

The present paper establishes the existence of scaling transition for a class of nonlinear subordinated RFs:

X(t, s) = G(Y (t, s)),

(1.3)

where Y = {Y (t, s), (t, s) ∈ Z2} is a stationary linear LRD RF in (1.4) and G(x) = Ak(x), x ∈ R is the Appell
polynomial of degree k ≥ 1 (see Sec. 2 for the deﬁnition) with EG2(Y (0, 0)) < ∞, EG(Y (t, s)) = 0. The
(underlying) RF Y is written as a moving-average

Y (t, s) = X(u,v)∈Z2

a(t − u, s − v)ε(u, v),

(t, s) ∈ Z2,

(1.4)

in a standardized i.i.d. sequence {ε(u, v); (u, v) ∈ Z2} with deterministic moving-average coeﬃcients such
that

a(t, s) ∼ const (|t|2 + |s|2q2/q1)−q1/2,

|t| + |s| → ∞,

where parameters q1, q2 > 0 satisfy

1 < Q :=

1
q1

+

1
q2

< 2.

(1.5)

(1.6)

In Theorems 3.1-3.5 below, the moving-average coeﬃcients a(t, s) may take a more general form in (2.1)

including an ‘angular function’. Condition Q < 2 guarantees that P(t,s)∈Z a(t, s)2 < ∞ or Y in (1.4) is
well-deﬁned, while Q > 1 implies that P(t,s)∈Z |a(t, s)| = ∞ (in other words, that RF Y is LRD). Note
a(t, 0) = O(|t|−q1), a(0, s) = O(|s|−q2) decay at a diﬀerent rate when q1 6= q2 in which case Y exhibits strong
anisotropy. The form of moving-average coeﬃcients in (1.5) implies a similar behavior of the covariance
function rY (t, s) := EY (0, 0)Y (t, s) =P(u,v)∈Z2 a(u, v)a(t + u, s + v), namely

rY (t, s) ∼ const (|t|2 + |s|2p2/p1)−p1/2,

|t| + |s| → ∞,

where

Note p1/p2 = q1/q2 and the 1-1 correspondence between (q1, q2) and (p1, p2):

pi := qi(2 − Q),

i = 1, 2.

qi :=

pi
2

(1 + P ),

i = 1, 2, where P :=

1
p1

+

1
p2

.

2

(1.7)

(1.8)

(1.9)

(1.7) implies that for any integer k ≥ 1 and P 6∈ N

X(t,s)∈Z2 |rY (t, s)|k = ∞

⇐⇒

1 ≤ k < P,

(1.10)

see Proposition 5.1. In the case when Y in (1.4) is Gaussian RF, rk

Y (t, s) coincides with the covariance of
the kth Hermite polynomial Hk(Y (t, s)) of Y and the (nonlinear) subordinated RF X = Hk(Y ) is LRD if

condition (1.10) holds. A similar result is true for nongaussian moving-average RF Y in (1.4) and Hermite

polynomial Hk replaced by Appell polynomial Ak.

The following summary describes the main results of this paper.

(R1) Subordinated RFs X = Ak(Y ), 1 ≤ k < P exhibit scaling transition at the same point γ0 := p1/p2 =

q1/q2 independent of k.

(R2) The well-balanced scaling limit V X

γ0 of X = Ak(Y ) is non-gaussian unless k = 1 and is given by a k-tuple

Itˆo-Wiener integral.

(R3) Unbalanced scaling limits V X

+ = V X

γ , γ > γ0 of X = Ak(Y ) agree with FBS BH +

1k ∈ (1/2, 1) if kp2 > 1, and with a ‘generalized Hermite slide’ V X

1k,1/2 with Hurst
k (y) if
k is a self-similar process written as a k-tuple Itˆo-Wiener integral. A similar fact

+ (x, y) = xZ +

parameter H +
kp2 < 1, where Z +
holds for unbalanced limits V X

− = V X

γ , γ < γ0.

(R4) For k > P , RF X = Ak(Y ) does not exhibit scaling transition and all scaling limits V X

γ , γ > 0 agree

with Brownian sheet B1/2,1/2.

(R5) In the case of Gaussian underlying RF Y in (1.4), the above conclusions hold for general nonlinear

function G in (1.3) and k equal to the Hermite rank of G.

The above list contains several new noncentral and central limit results. (R2), (R4) and (R5) are new in the
‘anisotropic’ case p1 6= p2 while (R3) is new even for linear RF X = A1(Y ) = Y (see Remark 3.1 concerning
the terminology in (R3)). Similarly as in the case of linear models (see [30], [31]), unbalanced limits in (R3)

have either independent or completely dependent increments along one of the coordinate axes. According
to (R3), the sample mean of nonlinear LRD RF X = Ak(Y ), 1 < k < P on rectangles K[λ,λγ ], γ 6= γ0 may
have gaussian or nongaussian limit distribution depending on k, γ and parameters p1, p2, moreover, in both
cases the variance of the sum P(t,s)∈K[λ,λγ ]
X(t, s) grows faster than λ1+γ, or the number of summands. The

dichotomy of the limit distribution in (R3) is related to the presence or absence of the vertical/horizontal

LRD property of X, see Remark 6.1. We also note that our proofs of the central limit results in (R3) and

(R4) use rather simple approximation by m-dependent r.v.’s and do not require a combinatorial argument or

Malliavin’s calculus as in [6], [24] and other papers.

The paper is organized as follows. Sec. 2 provides the precise assumptions on RFs Y and X and some

known properties of Appell polynomials. Sec. 3 contains formulations of the main results (Theorems 3.1-3.5)

3

as described in (R1)-(R5) above. Sec. 4 provides two examples of linear fractionally integrated RFs satisfying

the assumptions in Sec. 2. Sec. 5 discusses some properties of generalized homogeneous functions and their

convolutions used to prove the results. Sec. 6 discusses the asymptotic form of the covariance function and

the asymptotics of the variance of anisotropic partial sums of subordinated RF X = Ak(Y ). All proofs are

collected in Sec. 7 and 8.

Notation. In this paper,

d−→ ,

fdd−→ ,

d
= ,

fdd
= denote the weak convergence and equality of (ﬁnite dimen-

sional) distributions. C stands for a generic positive constant which may assume diﬀerent values at various
0 := R2\{(0, 0)}, Z+ :=
locations and whose precise value has no importance. R+ := (0,∞), R2
{0, 1,··· }, N+ := {1, 2,··· }, Z•2k := {((u1, v1),··· , (uk, vk)) ∈ Z2k : (ui, vi) 6= (uj, vj), 1 ≤ i < j ≤ k}, k ∈
N+, |t|+ := |t| ∨ 1 (t ∈ Z).

+ := (0,∞)2, R2

2 Assumptions and preliminaries

Assumption (A1) {ε, ε(t, s), (t, s) ∈ Z2} is an i.i.d. sequence with Eε = 0, Eε2 = 1
Assumption (A2) Y = {Y (t, s), (t, s) ∈ Z2} is a moving-average RF in (1.4) with coeﬃcients
|t| + |s| → ∞,

(|t|2 + |s|2q2/q1)1/2(cid:1) + o(1)(cid:17),

a(t, s) =

1

(|t|2 + |s|2q2/q1)q1/2(cid:16)L0(cid:0)

t

(2.1)

where qi > 0, i = 1, 2 satisfy Q = P2
piece-wise continuous function on [−1, 1].

i=1 q−1

i ∈ (1, 2) (see (1.6)) and L0(u) ≥ 0, u ∈ [−1, 1] is a bounded

We refer to L0 in (2.1) as the angular function. Particularly, for q1 = q2, ρ = (|t|2 +|s|2)1/2 and arccos(t/ρ)
are the polar coordinates of (t, s) ∈ R2. Assumptions (A1)-(A2) imply EY (0, 0)2 = P(t,s)∈Z2 a(t, s)2 < ∞
and hence RF Y in (1.4) is well-deﬁned and stationary, with zero mean EY (t, s) = 0. Moreover, if E|ε|α < ∞
for some α > 2 then E|Y (t, s)|α < ∞ follows by Rosenthal’s inequality; see e.g. ([14], Corollary 2.5.1).
Given a r.v. ξ with E|ξ|k < ∞, k ∈ Z+, the kth Appell polynomial Ak(x) relative to the distribution of ξ is
deﬁned by Ak(x) := (−i)kdk(eiux/Eeiuξ)/duk(cid:12)(cid:12)u=0. See [2], [14] for various properties of Appell polynomials.
In as follows, Ak(ξ) stands for the r.v. obtained by substituting x = ξ in the Appell polynomial Ak(x) relative
to the distribution of ξ. Particularly, if Eξ = 0 then A1(ξ) = ξ, A2(ξ) = ξ2 − Eξ2, A3(ξ) = ξ3 − 3ξEξ2 − Eξ3
etc. For standard normal ξ ∼ N (0, 1) the Appell polynomials Ak(ξ) = Hk(ξ) = (−i)kdkeiuξ+u2/2/duk(cid:12)(cid:12)u=0
Assumption (A3)k For k ∈ N+, E|ε|2k < ∞ and

agree with the Hermite polynomials.

X = {X(t, s) := Ak(Y (t, s)), (t, s) ∈ Z2},

(2.2)

where Ak is the kth Appell polynomial relative to the (marginal) distribution of Y (t, s) in (1.4).

We also use the representation of (2.2) via Wick products of noise variables (see [14], Ch. 14):

Ak(Y (t, s)) = X(u,v)k∈Z2k

a(t − u1, s − v1)··· a(t − uk, s − vk) : ε(u1, v1)··· ε(uk, vk) : .

(2.3)

4

By deﬁnition, for mutually distinct points (uj, vj) 6= (uj ′, vj ′) (j 6= j′, 1 ≤ j, j′ ≤ i) the Wick product
: ε(u1, v1)k1 ··· ε(ui, vi)ki : = Qi
j=1 Akj (ε(uj , vj)) equals the product of independent r.v.’s Akj (ε(uj, vj)), 1 ≤
j ≤ i. (2.3) leads to the decomposition of (2.2) into the ‘oﬀ-diagonal’ and ‘diagonal’ parts:

where

Ak(Y (t, s)) = Y •k(t, s) + Z(t, s),

Y •k(t, s)

:= X(u,v)k

•a(t − u1, s − v1)··· a(t − uk, s − vk)ε(u1, v1)··· ε(uk, vk)

(2.4)

(2.5)

and the sumP•(u,v)k
is taken over all (u, v)k = ((u1, v1),··· , (uk, vk)) ∈ Z2k such that (ui, vi) 6= (uj, vj) (i 6= j)
(the set of such (u, v)k ∈ Z2k will be denoted by Z•2k). By deﬁnition, the ‘diagonal’ part Z(t, s) in (2.4) is
given by the r.h.s. of (2.3) with (u, v)k ∈ Z2k replaced by (u, v)k ∈ Z2k \ Z•2k. In most of our limit results,
Z(t, s) is negligible and Y •k(t, s) is the main term which is easier to handle compared to Ak(Y (t, s)) in (2.4).
We also note that limit distributions of partial sums of ‘oﬀ-diagonal’ polynomial forms in i.i.d. r.v.’s were

studied in [33], [14], [3] and other works.

d
= Z and Y (0, 0)

d

ε(0, 0)

= Z have standard normal distribution Z ∼ N (0, 1) and
Assumption (A4)k
X(t, s) = G(Y (t, s)), where G = G(x), x ∈ R is a measurable function with EG(Z)2 < ∞, EG(Z) = 0 and
Hermite rank k ≥ 1.

Assumptions (A1), (A2) and (A4)k imply that Y in (1.4) is a Gaussian RF. As noted above, under

Assumption (A4)k Appell polynomials Ak(x) coincide with Hermite polynomials Hk(x). Recall that the
Hermite rank of a measurable function G : R → R with EG(Z)2 < ∞ is deﬁned as the index k of the lowest
nonzero coeﬃcient cj in the Hermite expansion of G, viz., G(x) =P∞j=k cjHj(x)/j! where ck 6= 0.
Let L2(R2k) denote the Hilbert space of real-valued functions h = h((u, v)k), (u, v)k = (u1, v1,··· , uk, vk) ∈
R2k with ﬁnite norm khkk := {RR2k h2((u, v)k)d(u, v)k}1/2, d(u, v)k = du1dv1 ··· dukdvk. Let W = {W (du, dv),
(u, v) ∈ R2} denote a real-valued Gaussian white noise with zero mean and variance EW (du, dv)2 = dudv. For
any h ∈ L2(R2k) the k-tuple Itˆo-Wiener integralRR2k h((u, v)k)dkW =RR2k h(u1, v1,··· , uk, vk)W (du1, dv1)···
W (duk, dvk) is well-deﬁned and satisﬁes ERR2k h((u, v)k)dkW = 0, E(cid:0)RR2k h((u, v)k)dkW(cid:1)2 ≤ k!khk2

k; see e.g.

[14].

3 Main results

Recall the deﬁnitions pi, P in (1.8), (1.9); γ0 = q1/q2 = p1/p2. Denote

Consider a RF

SX

λ,γ(x, y) := X(t,s)∈K[λx,λγ y]
Vk,γ0(x, y) := ZR2k

5

X(t, s),

λ,γ := SX
SX

λ,γ(1, 1).

h(x, y; (u, v)k )dkW,

(x, y) ∈ R2
+,

(3.1)

(3.2)

where (c.f. (2.1))

h(x, y; (u, v)k )

a∞(t, s)

kYℓ=1

:= Z(0,x]×(0,y]
a∞(t − uℓ, s − vℓ)dtds, where
:= (|t|2 + |s|2q2/q1)−q1/2L0(cid:0)t/(|t|2 + |s|2q2/q1)1/2(cid:1),

(t, s) ∈ R2.

(3.3)

Theorem 3.1 (i) The RF Vk,γ0 in (3.2) is well-deﬁned for 1 ≤ k < P as Itˆo-Wiener stochastic integral and
has zero mean EVk,γ0(x, y) = 0 and ﬁnite variance EV 2
k . Moreover, RF Vk,γ0 has
stationary rectangular increments and satisﬁes the OSRF property:

(x, y) = k!kh(x, y;·)k2

k,γ0

{Vk,γ0(λx, λγ0 y), (x, y) ∈ R2

+} fdd= {λH(γ0)Vk,γ0(x, y), (x, y) ∈ R2
+},

∀λ > 0,

(3.4)

where H(γ0) := 1 + γ0 − kp1/2.
(ii) Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1 ≤ k < P . Then

Var(SX

λ,γ0) ∼ c(γ0)λ2H(γ0),

c(γ0) := kh(1, 1;·)k2

k

and

n−H(γ0)SX

λ,γ0(x, y)

fdd−→ Vγ0(x, y).

(3.5)

(3.6)

Next, we discuss the case k < P, γ 6= γ0. This case is split into four subcases: (c1): γ > γ0, k > 1/p2, (c2):
γ > γ0, k < 1/p2, (c3): γ < γ0, k > 1/p1, and (c4): γ < γ0, k < 1/p1 (the ‘boundary’ cases k = 1/pi, i = 1, 2

are more delicate and omitted, see Remark 3.2 below). Cases (c3) and (c4) are symmetric to (c1) and (c2)
k and Z−k with
and essentially follow by exchanging the coordinates t and s. Introduce random processes Z +

one-dimensional time:

Z +

k (y)

:= ZR2k

h+(y; (u, v)k)dkW,

Z−k (x) := ZR2k

h−(x; (u, v)k)dkW,

x, y ≥ 0,

(3.7)

where

h+(y; (u, v)k) := Z y
and a∞(t, s) is deﬁned in (3.3).

0

kYi=1

a∞(ui, s − vi)ds,

h−(y; (u, v)k) := Z x

0

kYi=1

a∞(t − ui, vi)dt,

(3.8)

Theorem 3.2 (i) Processes Z +

k and Z−k in (3.7) are well-deﬁned for 1 ≤ k < 1/p2 and 1 ≤ k < 1/p1,
respectively, as Itˆo-Wiener stochastic integrals. They have zero mean, ﬁnite variance, stationary increments
and are self-similar with respective indices H +

2k := 1 − kp2/2 ∈ (1/2, 1) and H−1k := 1 − kp1/2 ∈ (1/2, 1).

(ii) Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1 ≤ k < 1/p2. Then for any
γ > γ0

where H(γ) := 1 + γH +

2k and c(γ) := kh+(1;·)k2
λ−H(γ)SX

Var(SX

λ,γ) ∼ c(γ)λ2H(γ),
k. Moreover,

λ,γ(x, y)

fdd−→ xZ +

k (y).

6

(3.9)

(3.10)

(iii) Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1 ≤ k < 1/p1. Then for any
γ < γ0

where H(γ) := γ + H−1k and c(γ) := kh−(1;·)k2
λ−H(γ)SX

Var(SX

λ,γ) ∼ c(γ)λ2H(γ),
k > 0. Moreover,

λ,γ(x, y)

fdd−→ yZ−k (x).

(3.11)

(3.12)

Remark 3.1 Processes Z±k in (3.7) have a similar structure and properties to generalized Hermite processes
discussed in [3] except that (3.7) are deﬁned as k-tuple Itˆo-Wiener integrals with respect to white noise in R2
and not in R as in [3]. Following the terminology in [28], RFs xZ +
k (y) and yZ−k (x) may be called a generalized
Hermite slide since they represent a random surface ‘sliding linearly to 0’ along one of the coordinate on the

plane from a generalized Hermite process indexed by the other coordinate. In the Gaussian case k = 1, a

generalized Hermite slide agrees with a FBS BH1,H2 where one of the two parameters H1, H2 equals 1. Recall
that a fractional Brownian sheet (FBS) BH1,H2 = {BH1,H2(x, y), (x, y) ∈ R2
+} with parameters 0 < H1, H2 ≤ 1
is a Gaussian process with zero mean and covariance function

EBH1,H2(x1, y1)BH1,H2(x2, y2) = (1/4)(x2H1

1 + x2H1

2 − |x1 − x2|2H1)(y2H2

1 + y2H2

2 − |y1 − y2|2H2).

(3.13)

Theorem 3.3 (i) Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1/p2 < k < P .

Then for any γ > γ0

Var(SX

λ,γ) ∼ c(γ)λ2H(γ),

1k := 1 + γ0/2 − kp1/2 ∈ (1/2, 1) and c(γ) := R(0,1]2×R(cid:0)(a∞ ⋆ a∞)(t1 −

where H(γ) := H +

1k + γ/2, H +
t2, s)(cid:1)kdt1dt2ds > 0. Moreover,

(3.14)

(3.16)

λ−H(γ)SX

λ,γ(x, y)

fdd−→ c(γ)1/2BH +

1k,1/2(x, y).

(3.15)

(ii) Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1/p1 < k < P . Then for any

γ < γ0

Var(SX

λ,γ) ∼ c(γ)λ2H(γ),

where H(γ) := γH−2k + 1/2, H−2k := 1 + 1/(2γ0) − kp2/2 ∈ (1/2, 1) and c(γ) := RR×(0,1]2(cid:0)(a∞ ⋆ a∞)(t, s1 −
s2)(cid:1)kdtds1ds2 > 0. Moreover,

λ−H(γ)SX

λ,γ(x, y)

fdd−→ c(γ)1/2B1/2,H −

2k

(x, y).

(3.17)

Remark 3.2 Note H +

1k = 1 (kp2 = 1) and H−2k = 1 (kp1 = 1). We expect that the convergences (3.15)
and (3.17) remain true (modulus a logarithmic correction of normalization) in the ‘boundary’ cases kp2 = 1

and kp1 = 1 of Theorem 3.3 (i) and (ii) and the limit RFs in these cases agree with FBS B1,1/2 or B1/2,1,

respectively, having both parameters equal to 1 or 1/2.

The next theorem discusses the case k > P .

7

Theorem 3.4 Let RFs Y and X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k and k > P . Then for

any γ > 0

where σ2

X :=P(t,s)∈Z2 Cov(X(0, 0), X(t, s)) ∈ (0,∞). Moreover,

Var(SX

λ,γ) ∼ σ2

Xλ1+γ,

λ−(1+γ)/2SX

λ,γ(x, y)

fdd−→ σXB1/2,1/2(x, y).

(3.18)

(3.19)

Our last theorem extends the above results to general function G having Hermite rank k and Gaussian

underlying RF Y .

Theorem 3.5 Let X = G(Y ) satisfy Assumption (A4)k. Assume w.l.g.

G(x) = Hk(x) +P∞j=k+1 cjHj(x)/j!.
(i) Let 1 ≤ k < P . Then RF X satisﬁes all statements of Theorems 3.1-3.3.
(ii) Let k > P . Then RF X satisﬁes the statements of Theorem 3.4.

that G has Hermite expansion

According to Theorems 3.2-3.3, the unbalanced scaling limits V X

± of RF X = Ak(Y ) satisfying Assumptions

(A1)-(A3)k are given by

V X

+ (x, y) = 


V X

− (x, y) = 


(3.20)

2k

kp2 < 1,

xZ +

k (y),

c1/2
+ BH +

1k,1/2(x, y), kp2 > 1,

yZ−k (x),
c1/2
− B1/2,H −
where c± ≡ c(γ) > 0 are given constants. The covariance functions of RFs V X
± in (3.20) agree (modulus a
constant) with the covariance of FBS BH1,H2 where at least one of the two parameters H1, H2 equals 1 or 1/2,
namely (H1, H2) = (1, H +
+ , and (H1, H2) = (H−1k, 1)
if kp1 < 1, = (1/2, H−2k) if kp1 > 1 in the case of V X
− . These facts and the explicit form of the covariance of
6= aV− (∀a > 0), for any k, p1, p2 in Theorems 3.2-3.3, yielding the following
FBS, see (3.13), imply that V+

1k, 1/2) if kp2 > 1 in the case of V X

2k) if kp2 < 1, = (H +

(x, y), kp1 > 1,

kp1 < 1,

fdd

corollary.

Corollary 3.1 Let RF X = Ak(Y ) satisfy Assumptions (A1), (A2) and (A3)k, 1 ≤ k < P, kpi 6= 1, i = 1, 2.
Then X exhibits scaling transition at γ0 = p1/p2.

4 Examples: fractionally integrated RFs

In this section we present two examples of linear fractionally integrated random ﬁelds Y in Z2 satisfying

Assumptions (A1) and (A2).

8

Example 1. Isotropic fractionally integrated random ﬁeld.

Introduce the (discrete) Laplace operator

∆Y (t, s) := (1/4)P|u|+|v|=1(Y (t + u, s + v) − Y (t, s)) and a lattice isotropic fractionally integrated random

ﬁeld satisfying the equation:

(−∆)dY (t, s) = ε(t, s),

(4.1)

r.v.’s, 0 < d < 1/2 is the order of fractional integration,

where {ε(t, s), (t, s) ∈ Z2} are standard i.i.d.
(1 − z)d =P∞j=0 ψj(d)zj , ψj(d) := Γ(j − d)/Γ(j + 1)Γ(−d). More explicitly,

(−∆)dY (t, s) =

∞Xj=0

ψj(d)(1 + ∆)jY (t, s) = X(u,v)∈Z2

b(u, v)Y (t − u, s − v),

(4.2)

(4.6)

(4.7)

where b(u, v) := P∞j=0 ψj(d)pj (u, v) and pj(u, v) are j-step transition probabilities of a symmetric nearest-
neighbor random walk {Wk, k = 0, 1,··· } on Z2 with equal 1-step probabilities P (W1 = (u, v)|W0 = (0, 0)) =
1/4,|u| + |v| = 1. Note P(u,v)∈Z2 |b(u, v)| = P∞j=0 |ψj(d)| < ∞, d > 0 and therefore the l.h.s. of (4.2) is
well-deﬁned for any stationary random ﬁeld {Y (t, s)} with E|Y (0, 0)| < ∞. As shown in [18], for 0 < d < 1/2
a stationary solution of (4.2) with zero-mean and ﬁnite variance can be deﬁned as a moving-average random

ﬁeld:

with coeﬃcients

Y (t, s) = (−∆)−dε(t, s) = X(u,v)∈Z2

a(u, v)ε(t − u, s − v),

a(u, v) =

∞Xj=0

ψj(−d)pj(u, v)

(4.3)

(4.4)

satisfying P(u,v)∈Z2 a(u, v)2 < ∞. Moreover, RF Y in (4.3) has an explicit spectral density f (x, y) =
(2π)−22−2d|(1 − cos x) + (1 − cos y)|−2d, (x, y) ∈ [−π, π]2 which behaves as const (x2 + y2)−2d as x2 + y2 → 0.
According to ([18], Proposition 5.1), the moving-average coeﬃcients in (4.4) satisfy the isotropic asymptotics:

a(t, s) = (A + o(1))(t2 + s2)−(1−d),

t2 + s2 → ∞,

where A := π−1Γ(1 − d)/Γ(d) and hence Assumption (A2) with q1 = q2 = 2(1 − d) ∈ (1, 2), Q = 1/(1 − d) ∈
(1, 2) and a constant angular function L0(z) = A, z ∈ [−1, 1].

Example 2. Anisotropic fractionally integrated random ﬁeld. Consider the ‘discrete heat operator’
∆1,2Y (t, s) = Y (t, s) − θY (t − 1, s) − 1−θ
2 (Y (t − 1, s + 1) + Y (t − 1, s − 1)), 0 < θ < 1 and a fractionally
integrated random ﬁeld satisfying

∆d

1,2Y (t, s) = ε(t, s),

(4.5)

where {ε(t, s)} are as in (4.1). Similarly to (4.3), a stationary solution of (4.5) can be written as a moving-
average random ﬁeld:

Y (t, s) = ∆−d

1,2ε(t, s) = X(u,v)∈Z+×Z

a(u, v)ε(t − u, s − v),

with coeﬃcients

a(u, v) = ψu(−d)qu(v)

9

where qu(v) are u-step transition probabilities of a random walk {Wu, u = 0, 1,··· } on Z with 1-step proba-
bilities P (W1 = v|W0 = 0) = θ if v = 0, = (1 − θ)/2 if v = ±1. As shown in [20], P(u,v)∈Z2 a(t, s)2 < ∞ and
the RF in (4.6) is well-deﬁned for any 0 < d < 3/4, θ ∈ [0, 1); moreover, the spectral density f (x, y) of (4.6)
is singular at the origin: f (x, y) ∼ const (x2 + (1 − θ)2y4/4)−d, (x, y) → (0, 0).
Proposition 4.1 For any 0 < d < 3/4, 0 < θ < 1 the coeﬃcients in (4.7) satisfy Assumption (A2) with
q1 = 3/2 − d, q2 = 2q1 and a continuous angular function L0(z), z ∈ [−1, 1] given by
0 < z ≤ 1,
−1 ≤ z ≤ 0.
Remark 4.1 [7], [12] discussed fractionally integrated RFs satisfying the equation

L0(z) = 


√(1/z)2−1
2(1−θ) (cid:9),

zd−3/2

Γ(d)√2π(1−θ)

(4.8)

exp(cid:8) −

0,

∆d1

1 ∆d2

2 Y (t, s) = ε(t, s),

(4.9)

where ∆1Y (t, s) := Y (t, s) − Y (t − 1, s), ∆2Y (t, s) := Y (t, s) − Y (t, s − 1) are diﬀerence operators and
0 < d1, d2 < 1/2 are parameters. Stationary solution of (4.9) is a moving-average RF in Y (t, s) =
P(u,v)∈Z2
a(u, v)ε(t − u, v − s) with coeﬃcients a(u, v) := ψu(−d1)ψv(−d2). Following the proof of Theo-
rem 3.1 one can show that for any γ > 0 the (normalized) partial sums process of RF Y in (4.9) tends to
a FBS depending on d1, d2 only, viz., λ−H1−γH2SY

λ,γ(x, y) fdd−→ c(d1)c(d2)BH1,H2(x, y), where Hi = di + 1/2
and c(di) > 0 are some constants. See ([31], Proposition 3.2) for related result. We conclude that the frac-

+

tionally integrated RF in (4.9) featuring a ‘separation of LRD along coordinate axes’ does not exhibit scaling

transition in contrast to models in (4.1) and (4.5).

5 Properties of convolutions of generalized homogeneous functions

For a given ̟ > 0 denote

ρ(t, s) := (|t|2 + |s|2/̟)1/2,

ρ+(t, s) := 1 ∨ ρ(t, s),

(t, s) ∈ R2.

(5.1)

Let f (t, s) = ρ(t, s)−hL(t/ρ(t, s)), where h ∈ R and L = L(z), z ∈ [−1, 1] is an arbitrary measurable function,
then f (t, s) satisﬁes the scaling property: f (λt, λ̟s) = λ−hρ(t, s), (t, s) ∈ R2
0 for each λ > 0. Such functions
are called generalized homogeneous functions (see [15]).
We use the notation [φ1 ⋆ φ2](t, s) =P(u,v)∈Z2 φ1(u, v)φ2(t + u, s + v) for ‘discrete’ convolution of sequences
φi = {φi(u, v), (u, v) ∈ Z2} ∈ L2(Z2), i = 1, 2 and (ψ1 ⋆ ψ2)(t, s) =RR2 ψ1(u, v)ψ2(t + u, s + v)dudv for ‘usual’
convolution of functions ψi = {ψi(u, v), (u, v) ∈ R2}, i = 1, 2. Note the symmetry φi(t, s) = φi(t,−s), i = 1, 2
implies the symmetry [φ1 ⋆ φ2](t, s) = [φ1 ⋆ φ2](t,−s), (φ1 ⋆ φ2)(t, s) = (φ1 ⋆ φ2)(t,−s) of convolutions.
Let Bδ(t, s) := {(u, v) ∈ R2 : |t − u| + |s − v| ≤ δ}, Bc
Proposition 5.1 (i) For any δ > 0, h > 0,

δ(t, s) := R2 \ Bδ(t, s).

RBδ (0,0) ρ(t, s)−hdtds < ∞ ⇐⇒ h < 1 + ̟

10

(5.2)

and

RBc
δ (0,0) ρ(t, s)−hdtds < ∞
P(t,s)∈Z2 ρ+(t, s)−h < ∞


 ⇐⇒ h > 1 + ̟.

(ii) Let hi > 0, i = 1, 2, h1 + h2 > 1 + ̟. Then there exists C > 0 such that for any (t, s) ∈ R2

0

(ρ−h1 ⋆ ρ−h2)(t, s) ≤ Cρ(t, s)1+̟−h1−h2,
(ρ−h1
+ ⋆ ρ−h2)(t, s) ≤ Cρ+(t, s)−h2,
(ρ−h1
+ ⋆ ρ−h2

+ )(t, s) ≤ Cρ+(t, s)−h1∧h2,

hi < 1 + ̟, i = 1, 2,

h2 < 1 + ̟, h1 > 1 + ̟,

hi > 1 + ̟, i = 1, 2.

(5.3)

(5.4)

(5.5)

(5.6)

ρ(t, s) on the r.h.s. of (5.4) replaced by ρ+(t, s).

Moreover, inequalities (5.4)-(5.6) are also valid for ‘discrete’ convolution [ρ−h1

+ ](t, s), (t, s) ∈ Z2 with
(iii) Let ai = ai(t, s), (t, s) ∈ Z2, i = 1, 2 satisfy ai(t, s) = ρ+(t, s)−hi(cid:0)Li(t/ρ+(t, s)) + o(1)(cid:1),|t| + |s| → ∞,
where 0 < hi < 1 + ̟, h1 + h2 > 1 + ̟, and Li(u) 6≡ 0, u ∈ [−1, 1] are bounded piecewise continuous functions,
i = 1, 2. Let ai∞(u, v) := ρ(u, v)−hiLi(u/ρ(u, v)), (u, v) ∈ R2, i = 1, 2. Then
ρ+(t,s) ) + o(1)(cid:1),

[a1 ⋆ a2](t, s) = ρ+(t, s)1+̟−h1−h2(cid:0)L12(

|t| + |s| → ∞,

+ ⋆ ρ−h2

t

(5.7)

where

L12(z) := (a1∞ ⋆ a2∞)(z, (1 − z2)̟/2) = ZR2

a1∞(u, v)a2∞(u + z, v + (1 − z2)̟/2)dudv

(5.8)

is a bounded continuous function on the interval z ∈ [−1, 1]. Moreover, if L1(z) = L2(z) ≥ 0 then L12(z) in
(5.8) is strictly positive on [−1, 1].
(iv) Let b(t, s) := ρ+(t, s)−h(cid:0)L(t/ρ+(t, s)) + o(1)(cid:1),|t| + |s| → ∞, (t, s) ∈ Z2, b∞(t, s) := ρ(t, s)−hL(t/ρ(t, s)),
(t, s) ∈ R2 where 0 < h < 1 + ̟ and L(u) ≥ 0, u ∈ [−1, 1] is a continuous function. Then for any γ > 0

Bλ(γ) :=

X(ti,si)∈K[λ,λγ ],i=1,2

b(t1 − t2, s1 − s2) ∼ C(γ)λ2H(γ),

λ → ∞,

(5.9)

where

H(γ) :=




1 + ̟ − h
2 ,
1 + γ − γh
2̟ ,
1 + γ
2 − h−̟
1 + γ − h
2 ,
2 + γ − γ(h−1)
2̟ ,

2

1

,

C(γ) :=




R(0,1]4 b∞(t1 − t2, s1 − s2)dt1dt2ds1ds2,
R(0,1]2 b∞(0, s1 − s2)ds1ds2,
R(0,1]2×R b∞(t1 − t2, s)dt1dt2ds,
R(0,1]2 b∞(t1 − t2, 0)dt1dt2,
RR×(0,1]2 b∞(t, s1 − s2)dtds1ds2,

(I)

(II)

(III)

(IV)

(V)

(5.10)

in respective cases (I): γ = ̟, (II): γ > ̟, h < ̟, (III): γ > ̟, h > ̟, (IV): γ < ̟, h < 1 and (V):

γ < ̟, h > 1.

11

6 Covariance structure of subordinated anisotropic RFs

In this section from Proposition 5.1 with ̟ = γ0 we obtain the asymptotic form of the covariance func-
tion of rX(t, s) := EX(0, 0)X(t, s) and the asymptotics of the variance of anisotropic partial sums SX

λ,γ of

subordinated RF X = Ak(Y ).

Proposition 6.1 Let RF X = Ak(Y ) satisfy assumptions (A1), (A2) and (A3)k.
(i) Let 1 ≤ k < P . Then

rX(t, s) = ρ(t, s)−kp1(cid:0)LX (t/ρ(t, s)) + o(1)(cid:1),

|t| + |s| → ∞,

(6.1)

where LX(z) := (a∞ ⋆ a∞)k(z, (1 − z2)γ0/2), z ∈ [−1, 1] is a strictly positive continuous function and a∞ is
deﬁned in (3.3). Moreover, X(t, s) = Y •k(t, s) + Z(t, s), where Z(t, s) is deﬁned in (2.5) and

rZ (t, s) = O(ρ(t, s)−2q1 ) = o(ρ(t, s)−kp1),

|t| + |s| → ∞.

(ii) Let k > P . Then

rX (t, s) = O(cid:0)ρ(t, s)−(kp1)∧(2q1)(cid:1),

|t| + |s| → ∞.

(6.2)

(6.3)

Clearly, (6.1) implies C1ρ(t, s)−kp1 ≤ rX (t, s) ≤ C2ρ(t, s)−kp1 for all |t| + |s| > C3 and some 0 < Ci <

∞, i = 1, 2, 3. The last fact together with Proposition 5.1 (i) implies the following corollary.

Corollary 6.1 Let X = Ak(Y ), 1 ≤ k < P be the subordinated RF deﬁned in Proposition 6.1 and satisfying
the conditions therein.
(i) Let 1 ≤ k < P . Then P(t,s)∈Z2 |rX(t, s)| = ∞. Moreover, Ps∈Z |rX(0, s)| = ∞ ⇐⇒ kp2 ≤ 1 and
Pt∈Z |rX(t, 0)| = ∞ ⇐⇒ kp1 ≤ 1.
(ii) Let k > P . Then P(t,s)∈Z2 |rX (t, s)| < ∞.
Remark 6.1 Following the terminology in [28], we say that a covariance stationary RF X = {X(t, s), (t, s) ∈
Z2} has vertical LRD property (respectively, horizontal LRD property) if Ps∈Z |rX (0, s)| = ∞ (respectively,
Pt∈Z |rX(t, 0)| = ∞). From Corollary 6.1 we see the dichotomy of the limit distribution in Theorems 3.2 -

3.3 at points kp2 = 1 at kp1 = 1 is related to the change of vertical and horizontal LRD properties of the

subordinated RF X = Ak(Y ).

Corollary 6.2 Let X(t, s) = Ak(Y (t, s)) = Y •k(t, s) + Z(t, s), 1 ≤ k < P be the subordinated RF deﬁned in
Proposition 6.1 and satisfying the conditions therein. Then for any γ > 0

Var(cid:0)SX

λ,γ(cid:1) ∼ Var(cid:0)SY •k

λ,γ (cid:1) ∼ c(γ)λ2H(γ),

and

Var(SZλ,γ) = O(λ1+γ),

λ → ∞

(6.4)

(6.5)

where H(γ) ∈ ((1 + γ)/2, 1 + γ) and c(γ) are deﬁned in Theorems 3.1-3.3.

12

7 Proofs of Theorems 3.1-3.5

We use the criterion in Proposition 7.1 for the convergence in distribution of oﬀ-diagonal polygonal forms

towards Itˆo-Wiener integral which is a straightforward extension of ([14], Proposition 14.3.2).

Let L2(Z2k) be the class of all real functions g = g((u, v)k), (u, v)k ∈ Z2k with P(u,v)k∈Z2k g((u, v)k)2 < ∞
and Qk(g) :=P•(u,v)k
g((u, v)k)ε(u1, v1)··· ε(uk, vk), g ∈ L2(Z2k) be a k-tuple oﬀ-diagonal form in i.i.d. r.v.’s
{ε(u, v)} satisfying Assumption (A1). For gλ,γ ∈ L2(Z2k) (λ > 0, γ > 0) deﬁne a step function egλ,γ ∈ L2(R2k)

by

egλ,γ((u, v)k)

:= λkγ(1+γ−1

0 )/2gλ,γ([λγ/γ0 u1], [λγ v1],··· , [λγ/γ0 uk], [λγ vk]),

(u, v)k ∈ R2k.

(7.1)

Proposition 7.1 Assume that there exists hγ ∈ L2(R2k) such that limλ→∞ kegλ,γ − hγkk → 0. Then Qk(gλ,γ)
d−→ RR2k hγ((u, v)k)dkW (λ → ∞).
Proof of Theorem 3.1. Let ρ(t, s) := (|t|2 + |s|2/γ0 )1/2, (t, s) ∈ R2.
(i) Let us show that the stochastic integral Vk,γ0(x, y) is well-deﬁned or kh(x, y;·)kk < ∞. where h(x, y; (u, v)k)
k =R(0,1]4((a∞ ⋆
is deﬁned in (3.3). It suﬃces to consider the case x = y = 1. By Proposition 5.1, kh(1, 1;·)k2
a∞)(t1 − t2, s1 − s2))kdt1dt2ds1ds2 ≤ R(0,1]4 ρ(t1 − t2, s1 − s2)−kp1dt1dt2ds1ds2 < ∞ since kp1 < 1 + γ0 =
1 + p1/p2 or k < P holds. The self-similarity property in (3.4) follows by scaling properties a∞(λt, λγ0 s) =
λq1a∞(t, s), {W (dλu, dλγ0v)} fdd= {λ(1+γ0)/2W (du, dv)} of the integrand and the white noise, and the change

of variables rules for multiple Itˆo-Wiener integral, see [8], also ([14], Proposition 14.3.5).

(ii) Relation (3.5) is proved in Proposition 6.2. Let us prove (3.6). Recall the decomposition X(t, s) =
Y •k(t, s) +Z(t, s) in Corollary 6.2. Using Var(SZλ,γ0
from

) = O(λ1+γ0 ) = o(λ2H(γ0)), see (6.5), relation (3.6) follows

Qk(gλ,γ0 (x, y;·)) = λ−H(γ0) X(t,s)∈K[λx,λγ0 y]

Y •k(t, s)

fdd−→ Vγ0(x, y),

(7.2)

where

gλ,γ0 (x, y; (u, v)k) := λ−H(γ0) X(t,s)∈K[λx,λγ0 y]

a(t − u1, s − v1)··· a(t − uk, s − vk),

(u, v)k ∈ Z2k.

(7.3)

Using Proposition 7.1 and Cram´er-Wold device, relation (7.2) follows from

lim

λ→∞kXm

i=1

θi(cid:0)egλ,γ0 (xi, yi;·) − h(xi, yi;·)(cid:1)kk = 0,

(7.4)

for any m ≥ 1 and any θi ∈ R, (xi, yi) ∈ R2
+, 1 ≤ i ≤ m, where the limit function h(x, y; (u, v)k ) is given in
(3.3). We restrict the subsequent proof of (7.4) to the case m = θ1 = 1, (x1, y1) = (x, y) since the general
case of (7.4) follows analogously. Using (2.1), (7.3), (7.1) and notation aλ(t, s) := (λ−1ρ(t, s))−q1(cid:0)L0(t/λ−1 ∨
ρ(t, s)) + o(1)(cid:1), λ → ∞ and λ′ := λγ0 similarly to (8.24) we get

egλ,γ0(x, y; (u, v)k ) = ZR2

kYi=1

aλ(cid:0) [λt]−[λu]

λ

, [λ′s]−[λ′v]

λ′

(cid:1)1(cid:0)([λt], [λ′s]) ∈ (0, λx] × (0, λ′y](cid:1)

→ h(x, y; (u, v)k)

13

(7.5)

point-wise for any (u, v)k ∈ R2k, (ui, vi) 6= (uj, vj) (i 6= j) ﬁxed. We use a similar bound to (8.20), viz.,

1

λ ∨ ρ(cid:0) [λt]−[λu]

λ

, [λ′s]−[λ′v]

λ′

(cid:1) ≥ cρ(t − u, s − v),

∀ t, u, s, v ∈ R,

∃c > 0,

(7.6)

implying the dominated bound

|egλ,γ0 (x, y; (u, v)k)| ≤ CR(0,2x]×(0,2y]Qk

i=1 ρ(t − ui, s − vi)−q1dtds =: ¯g(x, y : (u, v)k)

with k¯g(x, y;·)kk < ∞ so that (7.4) follows from (7.5) and Proposition 5.1 by the dominated convergence
theorem. Theorem 3.1 is proved.

(cid:3)

Proof of Theorem 3.2. As noted in Sec. 3, part (iii) follows by the same argument as part (ii) by exchanging

the coordinates t and s and we omit the details.

(i) Let us show that the stochastic integral in (3.7) is well-deﬁned or kh+(y;·)kk < ∞, where h+(y; (u, v)k) is
k =R(0,1]2((a∞⋆a∞)(0, s1−s2))kds1ds2 ≤ CR(0,1]2 ρ(0, s1−
deﬁned in (3.8). Indeed by Proposition 5.1 kh+(y;·)k2
s2)−kp1ds1ds2 ≤ CR[−1,1] |s|−kp2ds < ∞ since kp2 < 1. The remaining facts in (i) follow similarly as in the

proof of Theorem 3.1(i).

(ii) Relation (3.9) is proved in Corollary 6.2. Similarly to the proof of (3.6), the weak convergence in (3.10)

follows from

where

Qk(gλ,γ(x, y;·)) = λ−H(γ) X(t,s)∈K[λx,λγ y]

Y •k(t, s)

fdd−→ xZ+(y),

(7.7)

gλ,γ(x, y; (u, v)k) := λ−H(γ) X(t,s)∈K[λx,λγ y]
Again, we restrict the proof of (7.7) to one-dimensional convergence at (x, y) ∈ R2
follows from

a(t − u1, s − v1)··· a(t − uk, s − vk),

(u, v)k ∈ Z2k.

(7.8)

+. By Proposition 7.1 this

lim

where, with λ′ := λγ, λ′′ := λγ/γ0 ≫ λ, aλ′′ (t, s) := ((λ′′)−1 ∨ ρ(t, s))−q1(L0(t/((λ′′)−1 ∨ ρ(t, s))) + o(1)),
(cid:1)1(cid:0)([λt], [λ′s]) ∈ (0, λx] × (0, λ′y](cid:1)dtds

λ→∞kegλ,γ(x, y;·) − xh+(y;·)kk = 0,
kYi=1

aλ′′(cid:0) [λt]−[λ′′ui]

egλ,γ(x, y; (u, v)k) = ZR2

, [λ′s]−[λ′vi]

λ′′

λ′

(7.9)

(7.10)

→ xh+(y; (u, v)k)

point-wise for any (u, v)k ∈ R2k, (ui, vi) 6= (uj, vj) (i 6= j) ﬁxed.

The dominating convergence argument to prove (7.9) from (7.10) uses Pratt’s lemma [29], as follows.

Similarly to (7.6) note that

1

λ′′ ∨ ρ(cid:0) [λt]−[λ′′u]

λ′′

, [λ′s]−[λ′v]

λ′

(cid:1) ≥ cρ((λt/λ′′) − u, s − v),

∀ t, u, s, v ∈ R,

∃c > 0

14

and hence

|egλ,γ(x, y; (u, v)k)| ≤ CZ(0,2x]×(0,2y]

kYi=1

ρ((λt/λ′′) − ui, s − vi)−q1dtds =: CGλ((u, v)k)

with C > 0 independent of λ > 0, (u, v)k ∈ R2k. Clearly, limλ→∞ Gλ((u, v)k) = G((u, v)k) := 2xR(0,2y]Qk
ρ(−ui, s − vi)−q1ds point-wise in R2k and

i=1

kGλk2

k = Z(0,2x]2×(0,2y]2(cid:0)(ρ−q1 ⋆ ρ−q1)((λ/λ′′)(t1 − t2), s1 − s2)(cid:1)kdt1dt2ds1ds2
→ Z(0,2x]2×(0,2y]2(cid:0)(ρ−q1 ⋆ ρ−q1)(0, s1 − s2)(cid:1)kdt1dt2ds1ds2 = kGk2

k < ∞

by Proposition 5.1 and condition 1 ≤ k < 1/p2, or p2 = q2(2 − Q) < 1/k. Thus, application of [29] proves
(7.9). Theorem 3.2 is proved.

(cid:3)

To prove Theorem 3.3 we use approximation by m-dependent variables and the following CLT for triangular

array of m-dependent r.v.’s.

Lemma 7.1 Let {ξni, 1 ≤ i ≤ Nn}, n ≥ 1 be a triangular array of m-dependent r.v.’s with zero mean
and ﬁnite variance. Assume that: (L1) ξin, 1 ≤ i ≤ Nn are identically distributed for any n ≥ 1, (L2)
i=1 ξni) ∼ σ2Nn, σ2 > 0. Then
ξn := ξn1
n PNn
N−1/2

ξ and (L3) Var(PNn

n → Eξ2 < ∞ for some r.v.

d−→ ξ, Eξ2
i=1 ξni

d−→ N (0, σ2).

Proof. W.l.g., we can assume Nn = n in the subsequent proof. We use the CLT due to Orey [25]. Accordingly,
let ξτ

nij := Cov(ξτ

ni, ξτ

ni := Eξτ

ni, στ

ni := ξni1(|ξni| ≤ τ n1/2), ατ

nj).
i=1 ατ

It suﬃces to show that for any τ > 0
nij → σ2, (O3)

ni → 0, (O2) n−1Pn

i,j=1 στ

i,j=1 στ

the following conditions in [25] are satisﬁed: (O1) n−1/2Pn
n−1Pn
i=1 P(|ξni| > τ n1/2) → 0.
n1. We have 0 = n1/2Eξn = n1/2ατ
Consider (O1), or n1/2ατ
τ n1/2)| ≤ τ−1Eξ2

n1(|ξn| > τ n1/2). Therefore, (O1) follows from

nii = O(1), and (O4) Pn

n → 0, ατ

n := ατ

n+κn, where |κn| := n1/2|Eξn1(|ξn| >

Eξ2

n1(|ξn| > τ n1/2) → 0.

(7.11)

Using the Skorohod representation theorem [32] w.l.g. we can assume that r.v.s ξ, ξn, n ≥ 1 are deﬁned
on the same probability space and ξn → ξ almost surely. The latter fact together with (L2) and Pratt’s
n − ξ2| → 0 and hence (7.11) follows due to P(|ξn| > τ n1/2) → 0, see ([23], Ch.2,
lemma [29] implies that E|ξ2
n1(|ξn| > τ n1/2) by
Prop.5.3). The above argument also implies (O4) since P(|ξn| > τ n1/2) ≤ τ−1n−1Eξ2
Markov’s inequality. (O3) is immediate from (L1) and (L2). Finally, (O2) follows from (L3), (O1) and

n−1 X1≤i,j≤n,|i−j|≤m

E(ξniξnj − ξτ

niξτ

nj) → 0.

(7.12)

Let eξτ

ni := ξni − ξτ

ni. Since |E(ξniξnj − ξτ

niξτ

relation (7.12) follows from (7.11). Lemma 7.1 is proved.

nj)| ≤ |E(eξτ

niξτ

nj + ξτ

nj + eξτ
nieξτ
nieξτ
nj)| ≤ CE1/2ξ2

n1(|ξn| > τ n1/2),

(cid:3)

15

Proof of Theorem 3.3. Again, we prove part (i) only since part (ii) follows similarly by exchanging the

coordinates t and s.

Relation (3.11) is proved in Proposition 6.2. Let us prove (3.12). Similarly as in the case of the previous
theorems, we shall restrict ourselves with the proof of one-dimensional convergence at (x, y) ∈ R2
m ≥ 1, λ > 0 deﬁne stationary RFs
Xm(t, s)

:= Ak(Ym(t, s)),

+. For

where

Ym(t, s)

:=

X

(u,v)∈Z2:|s−v|≤[λγ0 ]m

a(t − u, s − v)ε(u, v),

(7.13)

and where Ak stands for the Appell polynomial of degree k relative to the distribution of Ym(t, s). Note
Xm(t1, s1) and Xm(t2, s2) are independent if |s1 − s2| > 2[λγ0 ]m. Then
Xm(t, s) = PN

λ,γ (x, y) := P(t,s)∈K[λx,λγ y]

i=0 Uλ,m(i)

(7.14)

SXm

where N := [[λγy]/[λγ0 ]] = O(λγ−γ0 ) and

Uλ,m(i)

:= X1≤t≤λx

Xi[λγ0 ]<s≤(i+1)[λγ0 ]

Xm(t, s).

(7.15)

Note Uλ,m(i) and Uλ,m(j) are independent provided |i− j| > 2m hence (7.14) is a sum of 2m-dependent r.v.’s.
The one-dimensional convergence in (3.12) follows from standard Slutsky’s argument (see e.g. [14], Lemma

4.2.1) and the following lemma. Theorem 3.3 is proved.

(cid:3)

Lemma 7.2 Under the conditions and notation of Theorem 3.3 (i), for any γ > γ0 and any m = 1, 2,···

Var(SXm

λ,γ (x, y))

λ−H(γ)SXm

λ,γ (x, y)

σ2
m(x, y)λ2H(γ)

∼
d−→ N (0, σ2

m(x, y))

and

as λ → ∞,

where σ2

m(x, y) is deﬁned in (7.19) below. Moreover,

lim
m→∞

lim sup
λ→∞

λ−2H(γ)Var(SX

λ,γ(x, y) − SXm

λ,γ (x, y)) = 0.

(7.16)

(7.17)

(7.18)

Proof. By adapting the argument in the proof of (3.11) and Proposition 5.1 (iv), Case (III), we can show the

limits

and

λ−2H(γ)Var(SXm

λ,γ (x, y)) → yZ(0,x]2×R(cid:0)(a∞,m ⋆ a∞,m)(t1 − t2, s)(cid:1)kdt1dt2ds =: σ2

m(x, y)

λ−2H(γ)Var(SX

= λ−2H(γ)

λ,γ (x, y))

λ,γ(x, y) − SXm
(ti,si)∈K[λx,λγ y],i=1,2(cid:8)Cov(X(t1, s1), X(t2, s2)) − Cov(X(t1, s1), Xm(t2, s2))

X

− Cov(Xm(t1, s1), X(t2, s2)) + Cov(Xm(t1, s1), Xm(t2, s2))(cid:9)

→ yZ(0,x2]×R

Gm(t1 − t2, s)dt1dt2ds,

λ → ∞,

16

(7.19)

(7.20)

where Gm(t, s) := ((a∞ ⋆ a∞)(t, s))k − ((a∞ ⋆ a∞,m)(t, s))k − ((a∞,m ⋆ a∞)(t, s))k + ((a∞,m ⋆ a∞,m)(t, s))k and
(7.21)

a∞,m(t, s) := L0(t/ρ(t, s))ρ(t, s)−q1 1(|s| ≤ m),

(t, s) ∈ R2.

is a ‘truncated’ version of a∞(t, s) in (3.3). Since |Gm(t, s)| ≤ 4(a∞ ⋆ a∞)(t, s))k and Gm(t, s) vanishes with
m → ∞ for any ﬁxed (t, s) 6= (0, 0), (7.18) follows from (7.20) by the dominated convergence theorem.

The proof of (7.17) uses Lemma 7.1. Accordingly, let Nλ := [[λγy]/[λγ0 ]] and ξλi := λ−H(γ0)Uλ,m(i), where
H(γ0) = 1 + γ0 − kp1/2 is the same as in Thm 3.1 and Uλ,m(i) are 2m-dependent r.v.’s deﬁned in (7.15).
Note Uλ,m(i), i = 1,··· , Nλ − 1 are identically distributed and λH(γ0)N 1/2
λ ∼ λH(γ)y1/2. Thus, condition (L1)
of Lemma 7.1 for ξλi, 1 ≤ i ≤ Nλ − 1 is satisﬁed and (L3) follows from Var(PNλ−1
λ,γ(x, y)) ∼

ξλi) ∼ Var(SX

i=1

cm(γ)x2H1k y, see (7.16). Finally, condition (L2), or

ξλ,1 = λ−H(γ0)Uλ,m(1)

d−→ ξ,

Eξ2

λ,1 → Eξ2

(7.22)

follows similarly as in Theorem 3.1 with the limit r.v. ξ given by the k-tuple Itˆo-Wiener integral:

ξ :=ZR2knZ x

0 Z 1

0

kYℓ=1

a∞,m(t − uℓ, s − vℓ) dtdsodkW

and a∞,m(t, s) deﬁned in (7.21). This proves (7.17) and Lemma 7.2, too.
Proof of Theorem 3.4. The proof is an adaptation of the proof of CLT in ([14], Theorem 4.8.1) for sums of

(cid:3)

‘oﬀ-diagonal’ polynomial forms with one-dimensional ‘time’ parameter. Deﬁne

Xm(t, s)

:= Ak(Ym(t, s)),

Ym(t, s) :=

X

(u,v)∈Z2:|t−u|+|s−v|≤m

a(t − u, s − v)ε(u, v),

(7.23)

where Ak stands for the Appell polynomial of degree k relative to the distribution of Ym(t, s). Note the
truncation level m in (7.23) does not depend on λ in contrast to the truncation level m[λγ0] in (7.13).
Similarly to Lemma 7.2 it suﬃces to prove for any γ > 0, m = 1, 2,···
λ,γ (x, y)
λ,γ(x, y) − SXm

λ,γ (x, y)) ∼ xyσ2
limm→∞ lim supλ→∞ λ−(1+γ)Var(SX

Xmλ1+γ, λ−(1+γ)/2SXm

d−→ N (0, xyσ2

λ,γ (x, y)) = 0.

Var(SXm

(7.25)

(7.24)

Xm)

where σ2

Xm := P(t,s)∈Z2 rXm(t, s) and rXm(t, s) := Cov(Xm(0, 0), Xm(t, s)). Note Xm(t1, s1) and Xm(t2, s2)
are independent if |t1 − t2| + |s1 − s2| > 2m. Therefore P(t,s)∈Z2 |rXm (t, s)| < ∞ and (7.24) follows the CLT
λ,γ −
λ,γ ) ≤P(t,s)∈Z2 |φm(t, s)|, where φm(t, s) := Cov(cid:0)X(0, 0)−Xm(0, 0), X(t, s)−Xm(t, s)). From (8.26), (8.27)

for m-dependent RFs, see [5] Consider (7.25), where we can put x = y = 1 w.l.g. We have λ−(1+γ)Var(SX
SXm

and (8.29) we conclude that

|Cov(X(0, 0), X(t, s))| + |Cov(X(0, 0), Xm(t, s))| + |Cov(Xm(0, 0), Xm(t, s))| ≤ Cρ(t, s)−(kp1)∧(2q1)

as in (6.3), with C > 0 independent of m. Therefore, |φm(t, s)| ≤ Cρ(t, s)−(kp1)∧(2q1) =: φ(t, s), where
P(t,s)∈Z2 φ(t, s) < ∞, see Proposition 5.1(i), also Corollary 6.1(ii). Thus, (7.25) follows by the dominated
convergence theorem and the fact that limm→∞ φm(t, s) = 0 for any (t, s) ∈ Z2. Theorem 3.4 is proved. (cid:3)

17

Proof of Theorem 3.5. (i) Split X = Xk + X′k, where X′k := Pj=k+1 cjXj/j!, Xj(t, s) := Hj(Y (t, s)). Since
all statements of Theorems 3.1-3.3 hold for RF Xk = Hk(Y ) and Cov(Xk(t1, s1), X′k(t2, s2)) = 0, ∀(ti, si) ∈
Z2, i = 1, 2, it suﬃces to show that

Var(S

X ′
λ,γ) = o(λ2H(γ)),
k

λ → ∞

(7.26)

j Var(S

Xj
λ,γ)/(j!)2 and Var(S

for H(γ) deﬁned in Theorems 3.1-3.3. By well-known properties of Hermite polynomials, Var(S

X ′
k
λ,γ) =
P∞j=k+1 c2
Y (t1 − t2, s1 − s2) ≤ j!Σk+1(λ), where
Σk+1(λ) :=P(ti,si)∈K[λ,λγ ],i=1,2 |rY (t1 − t2, s1 − s2)|k+1 for j ≥ k + 1 since |rY (t, s)| ≤ 1 according to Assump-
j /j!(cid:1)Σk+1(λ) ≤ EG(Y (0, 0))2Σk+1(λ), where Σk+1(λ) = o(λ2H(γ))

λ,γ) = j!P(ti,si)∈K[λ,λγ ],i=1,2 rj

λ,γ) ≤(cid:0)P∞j=k+1 c2

tion (A4)k. Hence, Var(S

follows by Proposition 5.1. This proves (7.26) and part (i).

X ′
k

Xj

X ′
K

X ′
K

(ii) For large K ∈ N, K > k, split X = XK + X′K , where XK (t, s) = PK
P∞j=K+1 cjHj(Y (t, s))/j!. Then Var(S

λ,γ ) ≤ (cid:0)P∞j=K+1 c2

λ,γ ) ≤ CǫKλ1+λ where ǫK :=P∞j=K+1 c2

Var(S
On the other hand, by Theorem 3.4 λ−(1+γ)/2S
result extends to ﬁnite sums of Hermite polynomials, viz., λ−(1+γ)/2SXK
σ2
XK

j /j!(cid:1)ΣK+1(λ) as in the proof of part (i), implying
j /j! can be made arbitrary small by choosing K large enough.
fdd−→ σXj B1/2,1/2(x, y) for any j ≥ k and the last
fdd−→ σXK B1/2,1/2(x, y), where
X, K → ∞. See e.g. ([14], proof of Thm.4.6.1). The remaining

=P(t,s)∈Z2 Cov(XK (0, 0), XK (t, s)) → σ2

j=k cjHj(Y (t, s))/j! and X′K (t, s) :=

Xj
λ,γ(x, y)

λ,γ (x, y)

details are easy. Theorem 3.4 is proved.

(cid:3)

8 Proofs of Propositions 4.1, 5.1, 6.1 and Corollary 6.2

Proof of Proposition 4.1. The transition probabilities qu(v) in (4.7) can be explicitly written in terms of

binomial probabilities bin(j, k; p) :=(cid:0)k

j(cid:1)pj(1 − p)k−j, k = 0, 1,··· , j = 0, 1,··· , k, 0 ≤ p ≤ 1:

qu(v) =

uXj=0

bin(u − j, u; θ)bin((v + j)/2, j; 1/2),

u ∈ N, |v| ≤ u.

(8.1)

Similarly to ([18], proof of Prop.4.1) we shall use the following version of the Moivre-Laplace theorem (Feller
[10], ch.7, §2, Thm.1): There exists a constant C such when j → ∞ and k → ∞ vary in such a way that

then

(j − kp)3

k2

→ 0,

(cid:12)(cid:12)(cid:12)(cid:12)

bin(j, k; p)

1√2πkp(1−p)

exp{− (j−kp)2
2kp(1−p)}

− 1(cid:12)(cid:12)(cid:12)(cid:12) <

C
k

+

C|j − kp|3

k2

.

(8.2)

(8.3)

Let us ﬁrst explain the idea of the proof. Using (8.1) and replacing the binomial probabilities by Gaussian

18

densities according to (8.3) leads to

a(u, v) ∼

1

1

=

1
2

u−1

Γ(d)u1−d

uXj=0
p2πθ(1 − θ)u
vXj=0
Γ(d)√2πu3/2−d
Γ(d)√2πu3/2−d Z 1
√1 − θ
Γ(d)√2πu3/2−d
∼
= ρ(u, v)d−3/2L0(z)

∼

1

1

1

1

0

p2πθ(1 − θ)/u

e−(v2/u)/2(1−θ)

1

e−(j−(1−θ)u)2/2θ(1−θ)u

e−v2/2j

1

pjπ/2

1

p2πθ(1 − θ)/u

e−u((j/u)−(1−θ))2/2θ(1−θ)

e−(v2/u)/2(j/u)

1

pj/u

e−u(x−(1−θ))2/2θ(1−θ) 1
√x

e−(v2/u)/2xdx

with L0(z) deﬁned in (4.8). Here, factor 1/2 in front of the sum in the ﬁrst line appears since bin((v +

j)/2, j; 1/2) = 0 whenever v + j is odd, in other words, by using Gaussian approximation for all (even and

odd) j we double the sum and therefore must divide it by 2. Note also that in the third line, the Gaussian

kernel

1√2πθ(1−θ)/u

e−u(x−(1−θ))2/2θ(1−θ) acts as a δ-function at x = 1 − θ when u → ∞.

Let us turn to a rigorous proof of the above asymptotics. For (u, v) ∈ Z2, (u, v) 6= (0, 0), denote ̺ :=
(u2 + v4)1/2, z := u/̺ ∈ [−1, 1], then u = z̺, v2 = ̺√1 − z2. It suﬃces to prove
as |u| + |v| → ∞.

̺3/2−da(u, v) − L0(z) → 0

(8.4)

By deﬁnition (see (4.7), (4.8)), (8.4) holds for u ≤ 0, z ≤ 0 hence we can assume u ≥ 1, z > 0 in as follows.
Moreover, for any ǫ > 0 there exists K > 0 such that

̺3/2−da(u, v) < ǫ

and L0(z) < ǫ

(∀ 1 ≤ u < v9/5, ̺ > K).

(8.5)

The second relation in (8.5) is immediate by limz→0 L0(z) = L0(0) = 0 and z = u/̺ ≤ ̺9/10/̺ → 0 (̺ → ∞).
To prove the ﬁrst relation we use Hoeﬀding’s inequality [17]. Let bin(j, k; p) be the binomial distribution.

Then for any τ > 0

X0≤j≤k:|j−kp|>τ√k

bin(j, k; p) ≤ 2e−2τ 2

.

(8.6)

(8.6) implies bin((v + j)/2, j; 1/2) ≤ 2e−2v2/j ≤ 2e−2v2/u for any |v| ≤ u, 0 ≤ j ≤ u. Also note that
1 ≤ u ≤ v9/5 implies v2 ≥ 21/20u̺1/10. Using these facts and (8.1) with Pu
j=0 bin(u − j, u; θ) = 1 for any
1 ≤ u < v8/5 we obtain

̺3/2−da(u, v) ≤ C̺3/2−dqu(v) ≤ C̺3/2−de−2v2/u ≤ C̺3/2−de−̺1/10

→ 0,

̺ → ∞,

proving (8.5). Hence, it suﬃces to prove (8.4) for u → ∞, 0 ≤ v ≤ u5/9. Below, we give the proof for v even,
the proof for v odd being similar. Denote

D+(u, v) := {0 ≤ j ≤ u/2 : |2j − u(1 − θ)| < u3/5 and |v| < j3/5},
D−(u, v) := {0 ≤ j ≤ u/2 : |2j − u(1 − θ)| ≥ u3/5 or |v| ≥ j3/5}.

19

Split a(u, v) = ψu(−d)P0≤j≤u/2 bin(u− 2j, u; θ)bin(v/2 + j, 2j; 1/2) = a+(u, v) + a−(u, v), where a±(u, v) :=
ψu(−d)Pj∈D±(u,v) ··· . It suﬃces to prove that

̺3/2−da−(u, v) → 0
as u → ∞, 0 ≤ v ≤ u5/9. To show the ﬁrst relation in (8.7), let j∗u := [u(1 − θ)/2] and

̺3/2−da+(u, v) − L0(z) → 0

and

(8.7)

a∗(u, v)

:= bin(v/2 + j∗u, 2j∗u; 1/2)ψu(−d) Xj∈D+(u,v)

bin(u − 2j, u; θ),

then

a∗(u, v) − a+(u, v) = ψu(−d) Xj∈D+(u,v)
According to (8.3), for j ∈ D+(u, v), j∗u ∈ D+(u, v)

bin(u − 2j, u; θ)(cid:0)bin(v/2 + j∗u, 2j∗u; 1/2) − bin(v/2 + j, 2j; 1/2)(cid:1).

bin(v/2 + j, 2j; 1/2) =

bin(v/2 + j∗u, 2j∗u; 1/2) =

1
√πj
1
√πj∗u

e−v2/4j(cid:0)1 + O(j−1/5)(cid:1) =
u(cid:0)1 + O(u−1/5)(cid:1).

e−v2/4j ∗

1
√πj

e−v2/4j(cid:0)1 + O(u−1/5)(cid:1),

Using c−u < j < c+u, j ∈ D+(u, v) for some c± > 0, and elementary inequalities we obtain that | 1√πj e−v2/4j −
1√πj ∗

u| ≤ Cu−7/10e−cv2/u for some C, c > 0 and hence the bound

e−v2/4j ∗

u

(cid:12)(cid:12)bin(v/2 + j∗u, 2j∗u; 1/2) − bin(v/2 + j, 2j; 1/2)(cid:12)(cid:12) ≤ Cu−7/10e−cv2/u

for all j ∈ D+(u, v) and all u > 0 large enough. Therefore since Pj∈D+(u,v) bin(u − 2j, u; θ) ≤ 1 we obtain

̺3/2−d|a∗(u, v) − a+(u, v)| ≤ C̺3/2−du−7/10+d−1e−cv2/u = ̺−1/5L∗(z) ≤ C̺−1/5,

where L∗(z) := Czd−17/10e−c√(1/z)2−1, z ∈ (0, 1] is a bounded function. As a consequence, it suﬃces to prove
u ∼

the ﬁrst relation in (8.7) with a+(u, v) replaced by a∗(u, v). This in turn follows from relations
1√πu(1−θ)/2

e−v2/2u(1−θ), ψu(−d) ∼ Γ(d)−1ud−1, and

e−v2/4j ∗

1√πj ∗

u

Xj∈D+(u,v)

bin(u − 2j, u; θ) → 1/2

as

u → ∞,

(8.8)

each of which hold uniformly in 0 ≤ v ≤ u5/9. Let us check (8.8) for instance. Since c−u < j < c+u, j ∈
D+(u, v) for some c± > 0, see above, so u5/9 = o(j3/5) and (8.8) follows from

B′(u) → 1/2

and B′′(u) → 0,

(8.9)

j=0 bin(u− j, u; θ)1(j is even), B′′(u) :=Pu

where B′(u) :=Pu
j=0 bin(u− j, u; θ)1(|j − u(1− θ)| ≥ u3/5). Here,
the ﬁrst relation in (8.9) is obvious by well-known properties of binomial coeﬃcients (??) while the second
one follows from (8.6) according to which B′′(u) ≤ Ce−2u1/5 → 0. This proves the ﬁrst relation in (8.7).

20

The proof of the second relation in (8.7) uses Hoeﬀding’s inequality in (8.6) in a similar way. We have

a−(u, v) ≤ a−1 (u, v)+a−2 (u, v), where a−1 (u, v) := ψu(−d)P0≤j≤u:|j−u(1−θ)|>u3/5 bin(u−j, u; θ) ≤ Cud−1e−2u1/5
implying ̺3/2−dJ−1 (u, v) ≤ Cu(10/9)(3/2−d)+(d−1)e−2u1/5 → 0 (u → ∞) uniformly in |v| ≤ u5/9. Finally,

a−2 (u, v)

:= ψu(−d)

X
≤ Cud−1 Xc1u≤j≤u,v≥j3/5
e−2v2/j ≤ Cude−c2u1/5

0≤j≤u:|j−u(1−θ)|≤u3/5,v≥j3/5

bin(u − j, u; θ)bin((v + j)/2, j; 1/2)

for some positive constants c1, c2 > 0, implying ̺3/2−da−2 (u, v) ≤ Cu(10/9)(3/2−d)+de−c2u1/5 → 0 (u → ∞)
uniformly in |v| ≤ u5/9 as above. This proves (8.7) and Proposition 4.1, too.
Proof of Proposition 5.1. With the notation ̺ := ρ(t, s) we have that {(t, s) ∈ R2, s ≥ 0} ∋ (t, s) 7→ (̺, t/̺) ∈
[0,∞) × [−1, 1] is a 1-1 mapping. Particularly, if ̟ = 1 then (̺, arccos(t/̺)) are the polar coordinates of
(t, s) ∈ R2, s ≥ 0. We use the inequality:

(cid:3)

ρ(ti, si),

(ti, si) ∈ R2, i = 1, 2,

2Xi=1
i=1 ρ(ti, si)1∧̟ with C̟ := 1 ∨ 21/̟−1.

ρ(t1 + t2, s1 + s2) ≤ C̟
which follows from ρ(t1 + t2, s1 + s2)1∧̟ ≤P2
(i) W.l.g., let δ = 1. Then RB1(0,0) ρ(t, s)−hdtds ≤ 4R 1
(1 + v2/̟)−h/2dv, where the inner
integral = O(1) if h > ̟, = O(uh−̟) if h < ̟, = O(| log u|) if h = ̟, as u → 0. This proves (5.2) and (5.3)
follows analogously.
(ii) After the change of variables: u → ̺u, v → ̺̟v, ̺ := ρ(t, s), we get

0 u̟−hduR 1/u̟

(8.10)

0

(ρ−h1 ⋆ ρ−h2)(t, s) = ̺1+̟−h1−h2ZR2

ρ(u, v)−h1 ρ((t/̺) + u, (s/̺̟) + v)−h2dudv,

= ̺1+̟−h1−h2(I1 + I2 + I12),

(8.11)

where

I1

I2

:= ZBδ(0,0)
:= ZBδ(−t/̺,−s/̺̟) ··· dudv,

ρ(u, v)−h1 ρ((t/̺) + u, (s/̺̟) + v)−h2dudv,

I12 := ZBc

δ (0,0)∩Bc

δ (−t/̺,−s/̺̟) ··· dudv

with δ > 0 such that Bδ(0, 0) ∩ Bδ(−t/̺,−s/̺̟) = ∅ for any (t, s) 6= (0, 0). The integrals Ii ≤ C, i = 1, 2 by
(5.2) and 0 < hi < 1 + ̟, i = 1, 2. Next, by H¨older’s inequality with h := h1 + h2,

I12 ≤ ZBc

ρ(u, v)−hdudv ≤ C,
δ (−t/̺,−s/̺̟) ρ((t/̺)+ u, (s/̺̟)+ v)−hdudv =RBc

in view of (5.3) andRBc
δ (0,0) ρ(u, v)−hdudv. This proves (5.4).
Next, consider (5.5), or the case 0 < h2 < 1 + ̟ < h1. By changing the variables as in (8.11), we get
(ρ−h1
+ ⋆ ρ−h2)(t, s) ≤ ̺1+̟−h1−h2(I′1 + I2 + I12), where I2 < C, I12 < C are the same as in (8.11), whereas

(8.12)

δ (0,0)

I′1 := ZBδ(0,0)

(̺−1 ∨ ρ(u, v))−h1 ρ((t/̺) + u, (s/̺̟) + v)−h2dudv.

21

Note that if given small enough δ > 0, then (8.10) implies ρ((t/̺) + u, (s/̺̟) + v)1∧̟ ≥ 1− ρ(u, v)1∧̟ ≥ 1/2
for all (u, v) ∈ Bδ(0, 0), and hence I′1 ≤ C̺h1−1−̟RR2 ρ+(u, v)−h1dudv ≤ C̺h1−1−̟ according to (5.3). Since
ρ(t, s)1+̟−h1−h2 = o(ρ(t, s)−h2 ) as |t| + |s| → ∞, the proof of (5.5) is complete.
+ )(t, s) ≤ ̺1+̟−h1−h2(I′1 + I′2 + I12)

Finally, consider (5.6). We follow the proof of (5.5) and get (ρ−h1

+ ⋆ ρ−h2

with the same I′1 < C, I12 < C, whereas

I′2 := ZBδ(−t/̺,−s/̺̟ )

ρ(u, v)−h1 (̺−1 ∨ ρ((t/̺) + u, (s/̺̟) + v))−h2 dudv.

For small enough δ > 0, we have ρ(u, v)1∧̟ ≥ 1 − ρ((t/̺) + u, (s/̺̟) + v)1∧̟ ≥ 1/2 for all (u, v) ∈
Bδ(−t/̺,−s/̺̟), and hence I′2 ≤ C̺h2−1−̟RR2 ρ+((t/̺) + u, (s/̺̟) + v)−h2dudv ≤ C̺h2−1−̟ by (5.3).
Using ρ(t, s)1+̟−h1−h2 = o(ρ(t, s)−h1∧h2) as |t| + |s| → ∞, we conclude (5.6). Extension of (5.4)-(5.6) to
‘discrete’ convolution [ρ−h1
+ ](t, s) requires minor changes and we omit the details. This proves part (ii).
(iii) It suﬃces to show (5.7) for (t, s) 6= (0, 0), s ≥ 0, in which case ρ+(t, s) = ρ(t, s). We have [a1 ⋆ a2](t, s) =
P1
i (t, s) = o(ρ+(t, s)−hi), i =

i (t, s) := ρ+(t, s)−hiLi(t/ρ+(t, s)), a1

2](t, s), where a0

+ ⋆ ρ−h2

i,j=0[ai

1⋆aj

1, 2. Clearly, (5.7) follows from

lim

|t|+|s|→∞(cid:12)(cid:12)ρ(t, s)h1+h2−1−̟[a0

1 ⋆ a0

i (t, s) := ai(t, s)−a0
2](t, s) − L12(t/ρ(t, s))(cid:12)(cid:12) = 0

and

[ai

1 ⋆ aj

2](t, s) = o(ρ(t, s)1+̟−h1−h2),

(i, j) 6= (0, 0), i, j = 0, 1,

1 ⋆ a0

The proof of (8.14) mimics the proof of (8.13) and is omitted. To prove (8.13), write [a0
2](t, s) as the
integral: [a0
2([u] + t, [v] +
s)dudv. After the same change of variables u → ̺u, v → ̺̟v, ̺ := ρ(t, s) as in the proof of (ii) we obtain
1 ⋆ a0
[a0

2](t, s) = ̺1+̟−h1−h2L̺(t/̺), where

2](t, s) = RR2 a0

2](t, s) = RR2 a0

2([u] + t, [v] + s)dudv. [a0

1([u], [v])a0

1 ⋆ a0

|t| + |s| → ∞.
1 ⋆ a0
1([u], [v])a0

(8.13)

(8.14)

(8.15)

(8.16)

L̺(z) := ZR2

g̺(u, v; z)dudv,

z ∈ [−1, 1]

and where

g̺(u, v; z) := a1̺(cid:0)˜u, ˜v(cid:1)a2̺(cid:0)˜u + z, ˜v + (1 − z2)̟/2(cid:1),

with ˜u := [̺u]/̺, ˜v := [̺̟v]/̺̟ and

ai̺(u, v) := (cid:0)̺−1 ∨ ρ(u, v)(cid:1)−hiLi(cid:0)u/(cid:0)̺−1 ∨ ρ(u, v)(cid:1)(cid:1),

i = 1, 2,

(8.17)

since s/̺̟ = (1 − z2)̟/2 for z = t/̺ ∈ [−1, 1], s ≥ 0. Then with ai∞(u, v), i = 1, 2 deﬁned by the statement
of Prop. 5.1 (iii) we get that

g̺(u, v; z) → g∞(u, v; z) := a1∞(u, v)a2∞(u + z, v + (1 − z2)̟/2)

(8.18)

as ̺ = ρ(t, s) → ∞ (|t| + |s| → ∞) for any ﬁxed (u, v; z) ∈ R2 × [−1, 1] such that (u, v) 6∈ {(0, 0), (−z,−(1 −
z2)̟/2)} and u/ρ(u, v), (u + z)/ρ(u + z, v + (1 − z2)̟/2) being continuity points of L1 and L2 respectively.
Let us prove that

L̺(z) → L12(z)

as ̺ → ∞

22

(8.19)

uniformly in z ∈ [−1, 1], which implies (8.13), viz., |L̺(t/̺) − L12(t/̺)| ≤ supz∈[−1,1] |L̺(z) − L12(z)| = o(1)
as ̺ → ∞. The uniform convergence in (8.19) follows if lim̺→∞ L̺(z̺) = L12(z) holds for any z ∈ [−1, 1]
and every sequence {z̺} ⊂ [−1, 1] tending to z:
lim̺→∞ z̺ = z. Choose δ > 0 and split the diﬀerence
L̺(z̺) − L12(z) = I1 + I2 + I12, where
:= ZBδ(0,0)
:= ZBδ(−z,−z′) ··· dudv,

(g̺(u, v; z̺) − g∞(u, v; z))dudv,
I12 := ZBc

δ (−z,−z′) ··· dudv

δ (0,0)∩Bc

I1

I2

with the notation z′ := (1 − z2)̟/2. Note that ρ(z, z′) = 1 and δ > 0 is chosen small enough so that
Bδ(0, 0) ∩ Bδ(−z,−z′) = ∅. Let us ﬁrst check that |Ii|, i = 1, 2 can be made arbitrary small by taking
suﬃciently small δ. Towards this end, we need the bound

|ai̺(˜u, ˜v)| ≤ Cρ(u, v)−hi,

(u, v) ∈ R2,

i = 1, 2.

(8.20)

Indeed, by (8.10), ρ(u, v) ≤ C̟(ρ(˜u, ˜v) + ρ(u − ˜u, v − ˜v)), where |u − ˜u| ≤ ̺−1,|v − ˜v| ≤ ̺−̟ and hence
ρ(u− ˜u, v − ˜v) ≤ √2̺−1, with C̟ > 0 dependent only on ̟ > 0. Therefore, ρ(u, v) ≤ √2C̟(ρ(˜u, ˜v) + ̺−1) ≤
2√2C̟(ρ(˜u, ˜v)∨ ̺−1) implying ρ(˜u, ˜v)∨ ̺−1 ≥ (2√2C̟)−1ρ(u, v), or (8.20) in view of the deﬁnition of ai̺ in

(8.17). Using (8.20) it follows that Using (8.20) it follows that

|g̺(u, v; z̺) − g∞(u, v; z)| ≤ Cρ(u, v)−h1(cid:0)ρ(u + z̺, v + z′̺)−h2 + ρ(u + z, v + z′)−h2(cid:1).

(8.21)

From (8.21) we obtain |I1| ≤ CRBδ(0,0) ρ(u, v)−h1 dudv ≤ Cδ1+̟−h1 = o(1) and similarly, |I2| ≤ Cδ1+̟−h2 =
o(1). Hence it suﬃces to show that I12 → 0 (z̺ → z), viz., that for each δ > 0

ZBc

δ (0,0)∩Bc

δ (−z,−z′) |g̺(u, v; z̺) − g∞(u, v; z)|dudv → 0 as ̺ → ∞.

(8.22)

δ(0, 0)∩ Bc

δ(0, 0) ∩ Bc

From (8.10), ρ(u + z̺, v + z′̺)1∧̟ ≥ ρ(u + z, v + z′)1∧̟ − δ1∧̟/2 ≥ (1/2)ρ(u + z, v + z′)1∧̟ for all (u, v) ∈
δ(−z,−z′) and ̺ large enough that ρ(z − z̺, z′ − z′̺)1∧̟ ≤ δ1∧̟/2 (in view of z̺ → z). Hence and from
Bc
δ (−z,−z′) by an integrable function
(8.21) we obtain that the integrand in (8.22) is dominated on Bc
independent of ̺, viz., |g̺(u, v; z̺)−g∞(u, v; z)| ≤ Cρ(u, v)−h1ρ(u+z, v+z′)−h2. Since this integrand vanishes
δ(−z,−z′) as ̺ → ∞, see (8.18), relation (8.22) follows by the dominated convergence
a.e. on Bc
theorem, proving (8.19). The continuity of L12 (5.8) follows similarly by the dominated convergence theorem.
It remains to prove the strict positivity of L12 in the case where L1(z) ≡ L2(z) =: L(z) ≥ 0. Under
assumption of piecewise continuity of L and L 6≡ 0 a.e., we can ﬁnd 0 < |z0| < 1 and δ > 0 such that
L(z) > δ for any |z − z0| < δ. We also have |u/ρ(u, v) − (u + z)/ρ(u + z, v + z′)| ≤ ρ(u, v)−1 + |1 −
ρ(u + z, v + z′)/ρ(u, v)| = O(ρ(u, v)−1∧̟) uniformly in z ∈ [−1, 1] for ρ(u, v) ≥ 1. Indeed, this follows from
|1−(ρ(u+z, v+z′)/ρ(u, v))1∧̟| < ρ(u, v)−1∧̟ by (8.10), when combined with |1−x| ≤ ̟−1(1∨x)1−̟|1−x̟|,
x > 0 due to the mean value theorem if 0 < ̟ < 1. Hence for ρ(u, v) ≥ K ≥ 1 large enough, we have
|u/ρ(u, v) − (u + z)/ρ(u + z, v + z′)| < δ/2. Next, we can ﬁnd the interior point (u0, v0) of Bc
K(0, 0) with
u0/ρ(u0, v0) = z0. In view of continuity of u/ρ(u, v), there exists ε > 0 such that |z0 − u/ρ(u, v)| < δ/2 holds

23

K (0, 0). Consequently, L(u/ρ(u, v))L((u + z)/ρ(u + z, v + z′)) ≥ δ2 > 0 for any
for all (u, v) ∈ Bε(u0, v0) ⊂ Bc
z ∈ [−1, 1] and all (u, v) ∈ Bε(u0, v0). By (8.10), we have ρ(u + z, v + z′) ≤ 2C̟ρ(u, v) for ρ(u, v) ≥ 1 and
hence L12(z) > δ2(2C̟)−h2RBε(u0,v0) ρ(u, v)−h1−h2dudv > 0, proving L12(z) > 0, z ∈ [−1, 1] and part (iii).

(iv) Rewrite the l.h.s. of (5.9) as

Bλ(γ) = Z eK 2

[λ,λγ ]

b([t1] − [t2], [s1] − [s2])dt1dt2ds1ds2,

(8.23)

where eK[λ,λγ ] := {(t, s) ∈ R2 : ([t], [s]) ∈ K[λ,λγ ]}.
Case (I): γ = ̟. By changing the variables in (8.23) as ti → λti, si → λ̟si, i = 1, 2, we obtain λ−2H(̟)Bλ(̟) =
RR4ebλ(t1, t2, s1, s2)dt1dt2ds1ds2, where
ebλ(t1, t2, s1, s2)

:= bλ(([λt1] − [λt2])/λ, ([λ̟s1] − [λ̟s2])/λ̟)
×1(([λti], [λ̟si]) ∈ (0, λ] × (0, λ̟], i = 1, 2)

(8.24)

with bλ(t, s) := (λ−1 ∨ ρ(t, s))−h(L(t/(λ−1 ∨ ρ(t, s)) + o(1)) as λ → ∞. Then
ebλ(t1, t2, s1, s2) → b∞(t1 − t2, s1 − s2)1((ti, si) ∈ (0, 1]2, i = 1, 2),

point-wise for any (t1, t2, s1, s2) ∈ R4, (t1, s1) 6= (t2, s2) ﬁxed. The dominating bound

λ → ∞

λ−1 ∨ ρ(cid:0)([λt1] − [λt2])/λ, ([λ̟s1] − [λ̟s2])/λ̟(cid:1) ≥ Cρ(t1 − t2, s1 − s2),

follows by the same arguments as (8.20). These facts and the dominated convergence theorem justify the limit

limλ→∞ λ−2H(̟)Bλ(̟) = C(̟) since the integral C(̟) ≤ CR(−1,1]2 ρ(t, s)−hdtds < ∞ in (5.10) converges by
Prop. 5.1 (i).
Case (II): γ > ̟, h < ̟. By changing the variables in (8.23) as ti → λti, si → λγsi, i = 1, 2, we obtain
λ−2H(γ)Bλ(γ) =RR4ebλ(t1, t2, s1, s2)dt1dt2ds1ds2, where

ebλ(t1, t2, s1, s2)

:= bλ(([λt1] − [λt2])/λγ/̟, ([λγ s1] − [λγs2])/λγ)
×1(([λti], [λγ si]) ∈ (0, λ] × (0, λγ ], i = 1, 2)

with bλ(t, s) := (λ−γ/̟ ∨ ρ(t, s))−h(L(t/(λ−γ/̟ ∨ ρ(t, s))) + o(1)) as λ → ∞. Hence since γ/̟ > 1 it follows
that

ebλ(t1, t2, s1, s2) → b∞(0, s1 − s2)1((ti, si) ∈ (0, 1]2, i = 1, 2),

λ → ∞

point-wise for any (t1, t2, s1, s2) ∈ R4, s1 6= s2 ﬁxed. Note b∞(0, s) = L(0)|s|−h/̟ is integrable on [−1, 1] due
to h < ̟. The limit limλ→∞ λ−2H(̟)Bλ(̟) = C(̟) can be justiﬁed by the dominated convergence theorem
using the bound

λ−γ/̟ ∨ ρ(cid:0)([λt1] − [λt2])/λγ/̟, ([λγs1] − [λγs2])/λγ(cid:1) ≥ λ−γ/̟ ∨ ρ(0, ([λγ s1] − [λγs2])/λγ)

≥ Cρ(0, s1 − s2),

24

which follows by the same arguments as (8.20).
Case (III): γ > ̟, h > ̟. By changing the variables in (8.23) as ti → λti, i = 1, 2, s1 − s2 → λ̟s1, s2 → λγs2,
we obtain λ−2H(γ)Bλ(γ) =RR4ebλ(t1, t2, s1, s2)dt1dt2ds1ds2, where

:= bλ(([λt1] − [λt2])/λ, ([λ̟s1 + λγs2] − [λγs2])/λ̟)

ebλ(t1, t2, s1, s2)

×1([λti] ∈ (0, λ], i = 1, 2, [λ̟s1 + λγs2] ∈ (0, λγ ], [λγs2] ∈ (0, λγ])

with bλ(t, s) := (λ−1 ∨ ρ(t, s))−h(L(t/(λ−1 ∨ ρ(t, s)) + o(1)) as λ → ∞. Then
ebλ(t1, t2, s, u) → b∞(t1 − t2, s1)1((t1, t2, s2) ∈ (0, 1]3),

λ → ∞

for any t1 6= t2, s1 ∈ R \ {0}, s2 ∈ R \ {0, 1} ﬁxed since γ > ̟ implies 1(0 < [λ̟s1 + λγs2] ≤ λγ]) → 1(0 <
s2 < 1). The dominating bound

λ−1 ∨ ρ(cid:0)([λt1] − [λt2])/λ, ([λ̟s1 + λγs2] − [λγs2])/λ̟(cid:1) ≥ Cρ(t1 − t2, s1)
−1RR ρ(t, s)−hdtds < ∞.

follows by the same arguments as (8.20), because |([λ̟s1 + λγs2] − [λγs2])/λ̟ − s1| ≤ 2λ−̟. Then the
dominated convergence in (5.9) is proved in view of C(γ) ≤ CR 1

Cases (IV) and (V) can be treated similarly to Cases (II) and (III) and we omit the details. Proposition 5.1

is proved.

(cid:3)

Proof of Proposition 6.1. (i) We ﬁrst prove (6.2). According to (2.3)

Z(t, s) =

k−1Xi=1 X(D)i X(u,v)i

•a(t − u1, s − v1)|D1| ··· a(t − ui, s − vi)|Di|A|D1|(ε(u1, v1))··· A|Di|(ε(ui, vi)) (8.25)

where the sum P(D)i
is taken over all partitions of {1, 2,··· , k} into i nonempty sets D1,··· , Di having
cardinality |D1| ≥ 1,··· ,|Di| ≥ 1, |D1| + ··· + |Di| = k. Thus, (8.25) is a decomposition of Z(t, s) =
Ak(Y (t, s)) − Y •k(t, s) into a sum of stationary ‘oﬀ-diagonal’ polynomial forms of order i < k in i.i.d. r.v.
A|Dℓ|(ε(uℓ, vℓ)), 1 ≤ ℓ ≤ i with max(|D1|,··· ,|Di|) ≥ 2. From (8.25) it follows that

|EZ(0, 0)Z(t, s)| ≤ C

k−1Xi=1 X(d)i,(d′)i

iYℓ=1
(|a|dℓ ⋆ |a|d′

ℓ )(t, s)

(8.26)

where the second sum is taken over all collections (d)i = (d1,··· , di), (d′)i = (d′1,··· , d′i) of integers dℓ ≥
1, d′ℓ ≥ 1 with Pi
ℓ=1 d′ℓ = k and satisfying max1≤ℓ≤i dℓ ≥ 2, max1≤ℓ≤i d′ℓ ≥ 2. See [14], proof of
Thm 14.2.1. Then a(t, s)dℓ ≤ Cρ(t, s)−βℓ, a(t, s)d′
ℓ where βℓ := dℓq1, β′ℓ := d′ℓq1. By Proposition
5.1 (ii)

ℓ=1 dℓ = Pi

ℓ ≤ Cρ(t, s)−β′

where

wℓ

:=

|EZ(0, 0)Z(t, s)| ≤ C

k−1Xi=1 X(d)i,(d′)i

iYℓ=1

ρ(t, s)−wℓ,

2q1 − 1 − γ0 = p1,
q1,




2q1,

if dℓ = d′ℓ = 1,
if dℓ ≥ 2, d′ℓ = 1 or dℓ = 1, d′ℓ ≥ 2,
if dℓ ≥ 2, d′ℓ ≥ 2.

25

(8.27)

(8.28)

Since 2q1 − 1 − γ0 < q1 < 2q1, we have that, for max1≤ℓ≤i dℓ ≥ 2, max1≤ℓ≤i d′ℓ ≥ 2, the exponents wℓ
in (8.28) satisfy Pi
ℓ=1 wℓ ≥ 2q1, implying (6.2). Since RFs {Y •k(t, s)} and {Z(t, s)} are uncorrelated:
Cov(Y •k(t, s), Z(u, v)) = 0 for any (t, s), (u, v) ∈ Z2, relation (6.1) follows from (6.2) and

Cov(Y •k(t, s), Y •k(0, 0)) = rY (t, s)k(1 + o(1)),

|t| + |s| → ∞.

(8.29)

To show (8.29), note that the diﬀerence |rY (t, s)k − Cov(Y •k(t, s), Y •k(0, 0))| =(cid:12)(cid:12)(a ⋆ a)k(t, s) −P•(u,v)k
u1, s+v1)a(u1, v1)··· a(t+uk, s+vk)a(uk, vk)(cid:12)(cid:12) satisﬁes the same bound as in (8.27) and therefore this diﬀerence
is O(ρ(t, s)−2q1) = o(rY (t, s)k) according to (6.2). This proves (8.29) and part (i). Part (ii) follows similarly
using (6.2) and |Cov(Y •k(t, s), Y •k(0, 0))| ≤ (|a| ⋆ |a|(t, s))k ≤ Cρ+(t, s)−kp1. Proposition 6.1 is proved.
Proof of Corollary 6.2. Relation (6.5) follows from (6.2) and Proposition 5.1 (i) since the l.h.s. of (6.5) does

a(t +

(cid:3)

not exceed P(t1,s1),(t2,s2)∈K[λ,λγ ] |rZ (t1 − t2, s1 − s2)| ≤ λ1+γP(t,s)∈Z2 |rZ (t, s)| ≤ Cλ1+γP(t,s)∈Z2 ρ+(t, s)−2q1
and the last sum converges by Proposition 5.1 (i) due to 2q1 > 1 + γ0.
Relations (6.4) follow from (6.5), the orthogonality of {Y •k(t, s)} and {Z(t, s)} and

Var(cid:0)X(t,s)∈K[λ,λγ ]

Y •k(t, s)(cid:1) ∼ c(γ)λ2H(γ).

In turn, (8.30) follows from

Vλ,γ :=

X(t1,s1),(t2,s2)∈K[λ,λγ ]
and the fact that the diﬀerence (cid:12)(cid:12)Var(cid:0)P(t,s)∈K[λ,λγ ]

Y (t1 − t2, s1 − s2) ∼ c(γ)2λ2H(γ)
rk
Y •k(t, s)(cid:1) −P(t1,s1),(t2,s2)∈K[λ,λγ ]

be estimated as in (8.26)-(8.27) and therefore this diﬀerence is O(λ1+γ) = o(λ2H(γ) as shown in (6.5).

(8.30)

(8.31)

rk

Y (t1 − t2, s1 − s2)(cid:12)(cid:12) can

References

[1] Anh, V.V., Leonenko, N.N. and Ruiz-Medina, M.D. (2013) Macroscaling limit theorems for ﬁltered spatiotemporal random

ﬁelds. Stochastic Anal. Appl. 31, 460–508.

[2] Avram, F. and Taqqu, M.S. (1987) Noncentral limit theorems and Appell polynomials. Ann. Probab. 15, 767–775.

[3] Bai, S. and Taqqu, M.S. (2014) Generalized Hermite processes, discrete chaos and limit theorems. Stochastic Process. Appl.

124, 1710–1739.

[4] Bierm´e, H., Meerschaert, M.M. and Scheﬄer, H.P. (2007) Operator scaling stable random ﬁelds. Stoch. Process. Appl. 117,

312-332.

[5] Bolthausen, E. (1982) On the central limit theorem for stationary mixing random ﬁelds. Ann. Probab. 10, 1047–1050.

[6] Breuer, P. and Major, P. (1983) Central limit theorems for non-linear functionals of Gaussian ﬁelds. J. Multiv. Anal. 13,

425-441.

[7] Boissy, Y., Bhattacharyya, B.B., Li, X. and Richardson, G.D. (2005) Parameter estimates for fractional autoregressive

spatial processes. Ann. Statist. 33, 2533–2567.

[8] Dobrushin, R.L. (1979) Gaussian and their subordinated self-similar random generalized ﬁelds. Ann. Probab. 7, 1–28.

26

[9] Dobrushin, R.L. and Major, P. (1979) Non-central limit theorems for non-linear functionals of Gaussian ﬁelds. Z. Wahrsch.

verw. Geb. 50, 27–52.

[10] Feller, W. (1966) An Introduction to Probability Theory and Its Applications, vol. 2. Wiley, New York.

[11] Gaigalas, R. and Kaj, I. (2003) Convergence of scaled renewal processes and a packet arrival model. Bernoulli 9, 671–703.

[12] Guo, H., Lim, C. and Meerschaert, M. (2009) Local Whittle estimator for anisotropic random ﬁelds. J. Multiv. Anal. 100,

993–1028.

[13] Giraitis, L. and Surgailis, D. (1985) CLT and other limit theorems for functionals of Gaussian processes. Z. Wahrsch. verw.

Geb. 70, 191–212.

[14] Giraitis, L., Koul, H.L. and Surgailis, D. (2012) Large Sample Inference for Long Memory Processes. Imperial College Press,

London.

[15] Hankey, A. and Stanley, H.E. (1972) Systematic application of generalized homogeneous functions to static scaling, dynamic

scaling, and universality. Phys. Review B 6, 3515–3542.

[16] Ho, H.-C. and Hsing, T. (1997) Limit theorems for functionals of moving averages. Ann. Probab. 25, 1636–1669.

[17] Hoeﬀding, W. (1963) Probability inequalities for sums of bounded random variables. J. Amer. Statist. Assoc. 58, 13–30.

[18] Koul, H.L., Mimoto, N. and Surgailis, D. (2016) Goodness-of-ﬁt tests for marginal distribution of linear random ﬁelds with

long memory. Metrika 79, 165–193.

[19] Lavancier, F. (2007) Invariance principles for non-isotropic long memory random ﬁelds. Statist. Inference Stoch. Process.

10, 255–282.

[20] Lavancier, F., Leipus, R. and Surgailis, D. (2014) Anisotropic long-range dependence and aggregation of space-time models.

Preprint.

[21] Leonenko, N.N. (1999) Random Fields with Singular Spectrum. Kluwer, Dordrecht.

[22] Mikosch, T., Resnick, S., Rootz´en, H. and Stegeman, A. (2002) Is network traﬃc approximated by stable L´evy motion or

fractional Brownian motion? Ann. Appl. Probab. 12, 23–68.

[23] Neveu, J. (1964) Bases math´ematiques du calcul de probabilit´es, Mason, Paris.

[24] Nualart, D. and Peccati, G. (2005) Central limit theorems for sequences of multiple stochastic integrals. Ann. Probab. 33,

177–193.

[25] Orey, S. (1958) A central limit theorem for m-dependent random variables. Duke Math. J. 25, 543–546.

[26] Pilipauskait˙e, V. and Surgailis, D. (2014) Joint temporal and contemporaneous aggregation of random-coeﬃcient AR(1)

processes. Stochastic Process. Appl. 124, 1011–1035.

[27] Pilipauskait˙e, V. and Surgailis, D. (2015) Joint aggregation of random-coeﬃcient AR(1) processes with common innovations.

Statist. Probab. Letters 101, 73–82.

[28] Pilipauskait˙e, V. and Surgailis, D. (2016) Anisotropic scaling of random grain model with application to network traﬃc. J.

Appl. Probab. (in press). Available at http://arxiv.org/abs/1510.07423.

[29] Pratt, J.W. (1960) On interchanging limits and integrals. Ann. Math. Statist. 31, 74–77.

[30] Puplinskait˙e, D. and Surgailis, D. (2016) Aggregation of autoregressive random ﬁelds and anisotropic long-range dependence.

Bernoulli (in press), DOI 10.3150/15-BEJ733. Available at http://arxiv.org/abs/1303.2209v3.

[31] Puplinskait˙e, D. and Surgailis, D. (2015) Scaling transition for long-range dependent Gaussian random ﬁelds. Stoch. Process.

Appl. 125, 2256–2271.

[32] Skorokhod, A.V. (1956) Limit theorems for stochastic processes. Th. Probab. Appl. 1, 261–290.

[33] Surgailis, D. (1982) Zones of attraction of self-similar multiple integrals. Lithuanian Math. J. 22, 185–201.

27

[34] Taqqu, M.S. (1979) Convergence of integrated processes of arbitrary Hermite rank. Z. Wahrsch. verw. Geb. 50, 53–83.

Fractional Brownian motion and long-range dependence.

28

