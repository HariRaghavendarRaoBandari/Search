6
1
0
2

 
r
a

M
4

 

 
 
]
T
I
.
s
c
[
 
 

1
v
8
6
4
1
0

.

3
0
6
1
:
v
i
X
r
a

Edge Coloring and Stopping Sets Analysis in

Product Codes with MDS components

1

Fanny Jardel and Joseph J. Boutros

Abstract

We consider non-binary product codes with MDS components and their iterative row-column

algebraic decoding on the erasure channel. Both independent and block erasures are considered in this

paper. A compact graph representation is introduced on which we deﬁne double-diversity edge colorings

via the rootcheck concept. An upper bound of the number of decoding iterations is given as a function of

the graph size and the color palette size M . Stopping sets are deﬁned in the context of MDS components

and a relationship is established with the graph representation. A full characterization of these stopping

sets is given up to a size (d1 + 1)(d2 + 1), where d1 and d2 are the minimum Hamming distances
of the column and row MDS components respectively. Then, we propose a differential evolution edge

coloring algorithm that produces colorings with a large population of minimal rootcheck order symbols.
The complexity of this algorithm per iteration is o(M ℵ), for a given differential evolution parameter ℵ,
where M ℵ itself is small with respect to the huge cardinality of the coloring ensemble. The performance

of MDS-based product codes with and without double-diversity coloring is analyzed in presence of both

block and independent erasures. In the latter case, ML and iterative decoding are proven to coincide

at small channel erasure probability. Furthermore, numerical results show excellent performance in

presence of unequal erasure probability due to double-diversity colorings.

Index Terms

Product codes, MDS codes, iterative decoding, codes on graphs, differential evolution, distributive

storage, edge coloring, diversity, erasure channel, stopping sets.

This manuscript was submitted to the IEEE Transactions on Information Theory, paper IT-15-1104, Dec. 2015. Fanny Jardel is

with Telecom ParisTech, 75013 Paris, France (email: fannjard@gmail.com). She was with CEA, LIST, Communicating Systems

Laboratory BC 94, Gif Sur Yvette, F91191, France. Joseph J. Boutros is with the Dept. of Electrical and Computer Engineering,

Texas A&M University at Qatar, Education City, 23874 Doha, Qatar (email: boutros@tamu.edu).

March 7, 2016

DRAFT

2

I. INTRODUCTION

The colossal amount of data stored or conveyed by network nodes requires a special design of

coding structures to protect information against loss or errors and to facilitate its access. At the

end-user level, coding is essential for transmitting information towards the network whether it

is located in a single node or distributed over many nodes. At the network level, coding should

help nodes to reliably save a big amount of data and to efﬁciently communicate with each others.

Powerful capacity-achieving error-correcting codes developed in the last two decades are mainly

efﬁcient at large or asymptotic block length, e.g. low-density parity-check codes (LDPC) [23]

and their spatially-coupled ensembles [35], parallel-concatenated convolutional (Turbo) codes [6]

[5], and polar codes derived from channel polarization [4]. Data transmission and storage in

many nowadays networks may require short-length packets that are not suitable for capacity-

achieving codes. The current interest in ﬁnite-length channel coding rates [44] put back the light

on code design for short and moderate block length. Many potential candidates are available for

this non-asymptotic length context such as binary and non-binary BCH codes, including Reed-

Solomon (RS) codes, Reed-Muller (RM) codes, and tensor product codes of all these linear

block codes [40] [7] [39].

Product codes, introduced by Peter Elias in 1954 [19], are tensor products of two (or more)

simple codes with a structure that is well-suited to iterative decoding via its graphical description.

In the early decades after their invention, product codes received a great attention due to

their capability of correcting multiple burst errors [70] [64], the availability of erasure-error

bounded-distance decoding algorithms [66], the ability of correcting many errors beyond the

guaranteed correction capacity [1], and their efﬁcient implementation with a variable rate [68].

The pioneering work by Tanner [60] brought new tools to coding theory and put codes on graphs,

including product codes, and their iterative decoding in the heart of modern coding theory [33]

[32] [49]. The graph approach of coding led to new optimal cycle codes on Ramanujan/Cayley

graphs [61] and to Generalizations of LDPC and product codes, known as GLD codes, studied

for the binary symmetric channel (BSC) and the Gaussian channel [9]. The excellent performance

of iterative (turbo) decoding of product codes on the Gaussian channel [45] made them compete

with Turbo codes and LDPC codes for short and moderate block length. The convergence rate and

stability of product codes iterative decoding were studied based on a geometric framework [55].

March 7, 2016

DRAFT

3

Product codes with mixed convolutional and block components were also found efﬁcient in

presence of impulsive noise [22]. In addition, iterated Reed-Muller product codes were shown

to exhibit good decoding thresholds for the binary erasure channel, but at high and low coding

rates only [65].

The class of product codes in which the row and the column code are both Reed-Solomon

codes was extensively used since more than two decades in DVD storage media and in mobile

cellular networks [69]. In these systems, the channel is modeled as a symbol-error channel

without soft information, i.e. suited to algebraic decoding. Improvements were suggested for

these RS-based product codes such as soft information provided by list decoding [52] within

the iterative process in a Reddy-Robinson framework [48]. Also, RS-based product codes were

directly decoded via a Guruswami-Sudan list decoder [28] after being generalized to bivariate

polynomials [3]. For general tensor products of codes and interleaved, a recent efﬁcient list

decoding algorithm was published [24], with an improved list size in the binary case. On channels

with soft information, RS-based product codes may be row-column decoded with soft-decision

constituent decoders [20] [30].

Tolhuizen found the Hamming weight distribution of both binary and non-binary product codes
up to a weight less than d1d2 + max(d1⌈d2/q⌉, d2⌈d1/q⌉) [62]. Enumeration of erasure patterns
up to a weight less than d1d2 + min(d1, d2) was realized by Sendrier for product codes with
MDS components [56]. Rosnes studied stopping sets of binary product codes under iterative

ML-component-wise decoding [51], where the deﬁned stopping sets and their analysis are based

on the generalized Hamming distance [67] [29].

A. Paper content and structure

In this paper, we consider non-binary product codes with MDS components and their iterative

algebraic decoding on the erasure channel. Both independent and block erasures are considered

in our paper. The erasure channel is currently a major area of research in coding theory [36] [37]

because of strong connections with theoretical computer science [37] and its model that easily

allows to understand the behavior of codes such as for LDPC codes [17], for general linear block

codes [54], and for turbo codes [50]. Coding for block erasures was examined by Lapidoth in

the context of convolutional codes [38]. This was a basis to later construct codes for the block-

fading channel with additive white Gaussian noise [27] [13]. The notion of rootcheck introduced

March 7, 2016

DRAFT

4

in [13] [12] for single-parity checknodes was applied to more general checknodes in GLD codes

[11] and product codes [10] to achieve diversity on non-ergodic block-fading channels. The

rootcheck concept is the main tool in this paper, in a way similar to [10], to deﬁne a compact

graph representation and study iterative decoding in presence of block erasures. Edge coloring

is one of the most interesting problems in modern graph theory [8]. In this paper, edge coloring

is a tool, when combined to the rootcheck concept, yields double-diversity product codes. Our

work is valid for ﬁnite-length MDS-based product codes only. Product codes for asymptotic

block length were studied for single-parity codes constituents [46] and for the erasure channel

with a standard regular structure [53] and MDS-based irregular structures [2].

Whether a product code is endowed with an edge coloring or not, the analysis of stopping

sets, their characterization and their enumeration is a fundamental task to be able to design

codes for erasure channels and determine the decoder performance. Our work in this sense is

an improvement to previous works cited above by Tolhuizen, Sendrier, and Rosnes. Besides this

objective of stopping sets characterization which is useful for independent channel erasures and

erasures occurring in blocks of symbols, recent works on locality [25] stimulated us to search for

edge colorings with a large population of edges that admit a minimal rootcheck order. Locality

is a concept encountered in distributive storage [34] [47] where classic coding theory is adapted

to the nature of a network with distributed nodes with its own constraints of load in bandwidth

and storage [18] [42]. Furthermore, product codes with MDS components appear to be suited

to distributive storage [21] owing to their simple and mature techniques of erasure resilience.

In our search for good edge colorings, we provide a new algorithm based on the concept of

differential evolution [59] [43]. We use no crossover in our evolution loop, only a mutation

of the population of bad edges is made to search for a better edge coloring. Our MDS-based

product codes equipped with a double-diversity edge coloring are suited to distributed storage

applications and to wireless networks where diversity is a key parameter.

The paper is structured as follows. Section II gives a list of mathematical notations. The graph

representation of product codes is given in Section III, including compact and non-compact

graphs. Also the rootcheck concept and its consequences are also found in Section III. The

analysis of stopping sets is made in Section IV. Our edge coloring algorithm for bipartite graphs

of product codes is described in Section V. Finally, in Section VI, we study the performance of

March 7, 2016

DRAFT

product codes with MDS components on erasure channels and we give theoretical and numerical

results before the conclusions in the last section.

5

B. Main results

The main results in this paper are:

• Establishing a new compact graph for product codes. The compact graph has many advan-
tages, the main one being its ability to imitate a Tanner graph with parity-check nodes. The

compact graph is also the basis for the differential evolution edge coloring. See Section III-B.
• Iterative decoding analysis of ﬁnite-length product codes, mainly the proof of new bounds

on the number of decoding iterations. See Theorem 1 and Corollary 1.

• Proving new properties of stopping sets for product codes with MDS components. See

Propositions 1&2, Corollaries 2-4, and Lemmas 1&2.

• Complete enumeration and characterization of stopping sets up to a size (d1 + 1)(d2 + 1),
where d1, d2 are the minimum Hamming distances of the component codes. This stopping
set enumeration goes beyond the weight d1d2 + max(d1, d2) of Tolhuizen’s Theorem 3 for
codeword enumeration in the MDS components case. See Lemmas 3&4 and Theorems 2&3.
• A new edge coloring algorithm (DECA) capable of producing double-diversity colorings

despite the huge size of the coloring ensembles. See Section V-B.

• Construction via the DECA algorithm of product codes maximizing the number of edges
with root order 1, i.e. minimizing the locality when the process of repairing nodes is

considered. See Section V-C.

• First numerical results for MDS-based product codes on erasure channels showing how
close iterative decoding is to ML decoding, mainly for small ǫ. We proved that iterative

decoding perform as well as ML decoding (the ratio of error probabilities tends to 1) for

MDS-based product codes at small ǫ. See Proposition 3, Corollary 5, and other performance

results in Section VI-B.

• Great advantage of double-diversity colorings of product codes (with respect to codes with-
out coloring) in presence of unequal probability erasures. Thus, double-diversity colorings

are efﬁcient on both ergodic and non-ergodic erasure channels. See Section VI-C.

March 7, 2016

DRAFT

6

II. MATHEMATICAL NOTATION AND TERMINOLOGY

We start by the notation related to the product code and its row and column components. The

impatient reader may skip this entire section and then refer to it later to clarify any notation

within the text. Basic notions on product codes and fundamental properties are found in main

textbooks [40] [7] [39] and the encyclopedia of telecommunications [32].

The column code C1 is a linear block code over the ﬁnite ﬁeld Fq with parameters [n1, k1, d1]q
which may be summarized by [n1, k1] when no confusion is possible. The integer q is the code
alphabet size, n1 is the code length, k1 is the code dimension as a vector subspace of Fn1
q , and d1
is the minimum Hamming distance of C1. Similarly, the row code C2 is a linear block code with
parameters [n2, k2, d2]q. Let G1 and G2 be two matrices of size k1 × n1 and k2 × n2 containing
in their row a basis for the subspaces C1 and C2 respectively. From the two generator matrices
G1 and G2 a product code CP is constructed as a subspace of FN
q with a generator matrix
GP = G1 ⊗ G2, where N = n1n2 and ⊗ denotes the Kronecker product [40]. CP has dimension
K = k1k2 and minimum Hamming distance dP = d1d2. C1 and C2 are also called component
codes, this is a terminology from concatenated codes. In [60] and [10], vertices associated to

component codes are called subcode nodes.

A linear [n, k, d]q code is said to be MDS, i.e. Maximum Distance Separable, if it satisﬁes
d = n − k + 1. Binary MDS codes are the trivial repetition codes and the single parity-check
codes. In this paper, we only consider non-trivial non-binary MDS codes where q > n > 2. A

linear code over Fq of rate R = k/n is said to be MDS diversity-wise or MDS in the block-
fading/block-erasure sense if it achieves a diversity order L such that L = 1 + ⌊M(1 − R)⌋,
where M is the number of degrees of freedom in the channel. The right term 1 +⌊M(1− R)⌋ is
known as the block-fading Singleton bound [41] [31]. In this paper, M shall denote the number

of colors, i.e. the palette size of an edge coloring. Assume that code symbols are partitioned

into M sub-blocks, a code is said to attain diversity L if it is capable of correct decoding when
L − 1 sub-blocks are erased by the channel. The reader should refer to [63], chapter 3, for an
exact deﬁnition of diversity on fading channels with additive white Gaussian noise.

A product code shall be represented by a non-compact graph G = (V1, V2, E). G is a complete
bipartite graph where V1 is the set of n2 right vertices, V2 is the set of n1 left vertices, and E is
the set of N edges representing the code symbols. A compact graph Gc will also be introduced

March 7, 2016

DRAFT

7

1 , V c

in the next section with Gc = (V c
2 , Ec). The number of edges (also called super-edges) in
the compact graph is |Ec| = N c. A super-edge is equivalent to a super-symbol that represents
(n1 − k1)(n2 − k2) symbols from Fq. The ensemble of edge colorings is denoted Φ(E) and
Φ(Ec) for G and Gc respectively. An edge coloring will be denoted by φ. Given φ, the rootcheck
order of an edge is ρ(e). The greatest ρ(e) among all edges will be referred to as ρmax(φ). The
number of edges e satisfying ρ(e) = 1 is η(φ), this is the number of good edges and will be
processed by the DECA algorithm in Section V. The DECA parameter ℵ shall represent the
number of edges to be mutated, i.e. those edges being chosen in the population of bad edges

satisfying ρ(e) > 1.

Under iterative row-column decoding, the rootcheck order ρ is equal to the number of decoding

iterations required to solve the edge value (or the symbol associated to that edge). In this paper,

one decoding iteration is equivalent to decoding all rows or decoding all columns. A sequence

of n1 row decoders followed by a sequence of n2 column decoders is counted as two decoding
iterations.

We give now a general deﬁnition of a stopping set. A detailed study is found in Section IV.

The notion of a stopping set is useful for iterative decoding in presence of erasures [17].

Deﬁnition 1: Let C[n, k]q be a linear code. Assume that the symbols of a codeword are
transmitted on an erasure channel. The decoder D is using some deterministic decoding method.
Consider a set S of s ﬁxed positions i1, i2, . . . , is where 1 ≤ ij ≤ n. The set S is said to be
a Stopping Set if D fails in retrieving the transmitted codeword when all symbols on the s
positions given by S are erased.

This paper focuses on stopping sets of a product code under iterative algebraic row-column

decoding, i.e. referred to as type II stopping sets. The number of stopping sets of size w is τw.
The rectangular support R(S) of a stopping set S can be seen as the smallest rectangle containing
S. After excluding rows and columns not involved in S, the rectangular support has size ℓ1 × ℓ2
where w = |S| ≤ ℓ1ℓ2. The word error performance of CP shall be estimated on erasure channels,
ew is the word error probability under Maximum Likelihood decoding and P Gew is the word
P M L
error probability under iterative row-column decoding. Three erasure channels are considered:

1- The Symbol Erasure Channel, SEC(q, ǫ), where code symbols are independently erased with

a probability ǫ, 2- The Color Erasure Channel, CEC(q, ǫ), where all symbols associated to the

same color are block-erased with a probability ǫ. On the CEC(q, ǫ), block-erasure events are

March 7, 2016

DRAFT

8

independent from one color to another. 3- The unequal probability Symbol Erasure Channel,
i=1), where symbol erasures are independent but their erasure probability varies
SEC(q,{ǫi}M
from one color to another.

III. GRAPH REPRESENTATIONS FOR DIVERSITY

Efﬁcient graph representation of codes was established by Tanner for different types of coding

structures [60]. Bounds on the code parameters and iterative decoding algorithms were also

proposed for codes on graphs [60]. In this paper, we study the edge coloring of a product code

graph, where edges represent code symbols. As shown below, the original graph for a product

code is too complex, i.e. it leads to a large ensemble of colorings. Hence, we introduce a compact

graph where symbols are grouped together with the same color in order to reduce the size of the

coloring ensemble. The compact graph also has another asset: grouping parity symbols together

renders check nodes similar to parity-check nodes found in standard low-density parity-check

codes [23] [49].

A. Non-compact graph

Consider a product code C1[n1, k1]q ⊗ C2[n2, k2]q where C1 is the column code and C2 is the
row code. The product code is deﬁned over the ﬁnite ﬁeld Fq and has length N and dimension
K given by [40]

N = n1n2, K = k1k2.

(1)

Each code symbol simultaneously belongs to one row and to one column. Product codes studied

in this paper are regular, in the sense that all columns are codewords of C1 and all rows are
codewords of C2. The graph of C1[n1, k1]q ⊗ C2[n2, k2]q is built as follows. We use the same
terminology as in [49]:

• n1 check nodes are drawn on the left. A left check node represents the coding constraint
which states that a row belongs to C2. The n1 left check nodes are referred to as C2 check
nodes, or row check nodes, or equivalently left vertices.

• n2 check nodes are drawn on the right. A right check node represents the coding constraint
which states that a column belongs to C1. The n2 right check nodes are referred to as C1
check nodes, or column check nodes, or equivalently right vertices.

March 7, 2016

DRAFT

• An edge is drawn between a left vertex and right vertex. It represents a code symbol located
on the row of the left vertex and on the column of the right vertex. The code symbol belongs

to Fq.

9

n1 checknodes

V2

C2

C2

C2

C2

E

V1

C1

C1

C1

C1

n2 checknodes

Figure 1: Non-compact bipartite graph G = (V1, V2, E) of a product code [4, 2]⊗2, i.e. n1 = n2 =
4, k1 = k2 = 2, |V1| = |V2| = 4, and |E| = N = n1n2 = 16 edges representing 16 symbols
in Fq.

In summary, the product code graph (V1, V2, E) is a complete biregular bipartite graph built
from n1 left vertices, n2 right vertices, and N = |E| = n1n2 edges representing code symbols.
The left degree is n2 and the right degree is n1. Irregular product codes can be found in [2].
Our paper is restricted to regular product codes. Figure 1 shows the bipartite graph of a square
regular symmetric product code [4, 2]⊗ [4, 2]. The graph structure reveals n1, n2, and N = n1n2.
The dimensions k1 and k2 of the component codes have no effect on the number of vertices and
edges in the product code graph. Indeed, a [4, 3] ⊗ [4, 3] code can also be deﬁned by the graph
in Figure 1. The role of the dimensions k1 and k2 is played within the check constraints inside
left and right vertices. Similarly, the size of the ﬁnite ﬁeld deﬁning the code cannot be revealed

March 7, 2016

DRAFT

10

from the graph structure, i.e. the product code graph does not depend on q.

Deﬁnition 2: The non-compact graph G = (V1, V2, E) for a [n1, k1] ⊗ [n2, k2] product code is

a complete bipartite graph with n1 = |V2| left vertices and n2 = |V1| right vertices.

B. Compact graph

In [10] where the diversity of binary product codes was considered, vertices of the non-

compact graph were grouped together into super-vertices (or supernodes) because the different

channel states lead to multiple classes of check nodes as in root-LDPC codes [13]. To render
a graph-encodable code, supernodes in [10] were made by putting n − k nodes together for a
[n, k] component code. Also, n − k is not necessarily a divisor of n.

Deﬁnition 3: The compact graph Gc = (V c
n1−k1⌉ = |V c

complete bipartite graph with ⌈ n1

1 , V c
2 | left vertices and ⌈ n2

2 , Ec) for a [n1, k1] ⊗ [n2, k2] product code is a

n2−k2⌉ = |V c

1 | right vertices.

From the above deﬁnition, the number of edges in the compact graph Gc is found to be

N c = |Ec| =(cid:24) n1

n1 − k1(cid:25) ×(cid:24) n2

n2 − k2(cid:25) .

(2)

Assuming that (n1−k1) divides n1 and (n2−k2) divides n2, a left check node in Gc is equivalent
to n2−k2 row constraints and a right check node in Gc is equivalent to n1−k1 column constraints.
An edge in the compact graph carries (n1 − k1) × (n2 − k2) code symbols. To avoid confusion
between edges of G and Gc, we may refer to those in Gc as super-edges or equivalently as super-
symbols. If ni is not multiple of ni − ki, then the last row or column supernode will contain
less than ni − ki check nodes. Figure 2 depicts the compact graph of the [4, 2]⊗2 product code.
All [n, n/2]⊗2 product codes have a compact graph identical to that of [4, 2]⊗2, for all n ≥ 2, n
even.

C. Diversity and codes on graphs

From a coding point of view, diversity is the art of creating many replicas of the same

information. From a channel point of view, diversity is the number of degrees of freedom

available while transmitting information. In distributive storage, independent failure of individual

March 7, 2016

DRAFT

V c
2

Ec

V c
1

11

2 supernodes

2 supernodes

Figure 2: Compact bipartite graph Gc = (V c
product code [n, n/2]⊗2, |V c
(i.e. super-edge) contains n2/4 symbols (i.e. edges).

2 , Ec) with two supernodes on each side for the
2 | = 2 and |Ec| = N c = 4 supersymbols. Each super-symbol

1 , V c

1 | = |V c

machines is modeled by independent erasures of code symbols, while the outage of a cluster

of machines is modeled as block erasures of code symbols. Assuming a storage domain with a

large set of machines partitioned into M clusters, diversity of distributed coding is deﬁned as

follows:

Deﬁnition 4: Consider a product code CP deﬁned over Fq. Assume that symbols are given
M different colors. Erasing one color is equivalent to erasing all symbols having this color. The
code is said to achieve a diversity L if it is capable of ﬁlling all erasures after erasing L − 1
colors. The code is full-diversity when L = M.

The integer L may also be called the diversity order. For Gaussian channels with fading, the
diversity order appears as the slope of the error probability, i.e. L = limγ→∞ − log Pe
log γ [13]. In the
above deﬁnition, a cluster has been replaced by a color. We will use this terminology throughout

the paper. Notice that coloring symbols is equivalent to edge coloring of the product code graph.

The number of edges is N in the non-compact graph and N c in the compact graph. In the

sequel, all colorings are supposed to be perfectly balanced, i.e. M divides both N and N c and

the number of edges having the same color is N/M and N c/M for the non-compact graph and

the compact graph respectively. More formally, our edge coloring is deﬁned as follows: an edge

March 7, 2016

DRAFT

coloring φ of G = (V1, V2, E) is a mapping associating one color to every edge in E,

φ : E → {1, 2, . . . , M},

12

(3)

1 , V c

such that |φ−1(i)| = N/M for i = 1 . . . M, where φ−1(i) is the inverse image of i. Similarly,
φ : Ec → {1, 2, . . . , M} for Gc = (V c
2 , Ec) and |φ−1(i)| = N c/M. The set of such mappings
for G and Gc is denoted Φ(E) and Φ(Ec) respectively.
Consider a coloring φ in Φ(Ec). It can be embedded into Φ(E) by copying the color of a super-
edge to its associated (n1 − k1) × (n2 − k2) edges in E. Thus, let Φ(Ec → E) be the subset of
colorings in Φ(E) obtained by embedding all colorings of Φ(Ec) into Φ(E). We have

Φ(Ec → E) ⊂ Φ(E)

and

|Φ(Ec → E)| = |Φ(Ec)|.

(4)

The size of the edge coloring ensembles Φ(E) and Φ(Ec) is obviously not the same when

N c < N, which occurs for both row and column component codes not equal to single parity-

check codes. Indeed, when a palette of size M is used to color edges, the total number of

colorings of E is

|Φ(E)| =

N!

((N/M)!)M .

This number for the compact graph is

|Φ(Ec)| =

N c!

((N c/M)!)M .

(5)

(6)

As an example, for the [12, 10]⊗2 code and M = 4, there are 2· 1083 edge colorings for the non-
compact graph and 2· 1019 edge colorings for the compact graph. It is clear that the construction
of product codes for diversity is much easier when based on Gc = (V c
2 , Ec) because its
edge coloring ensemble is smaller. Furthermore, as described below, vertices in Gc act in a way
similar to standard LDPC check nodes making the design very simple. Furthermore, we will see

1 , V c

in Section IV that edge colorings of the compact graph render larger stopping sets than colorings

of the non-compact graph.

The diversity order L attained by a code can never exceed M, the latter being the diversity

from a channel point of view. A tighter upper bound of L showing the rate-diversity tradeoff

is the block-fading Singleton bound. The Singleton bound for the maximal achievable diversity

March 7, 2016

DRAFT

13

order is valid for all types of non-ergodic channels, including block-erasure and block-fading

channels. The block-fading Singleton bound states that [31] [41]

L ≤ 1 + ⌊M(1 − R)⌋,

(7)

where R = K/N is the coding rate of the product code. Codes satisfying the equality in the

above Singleton bound are referred to as diversity-wise MDS or block-fading MDS codes. From
(7), we deduce that R ≤ 1/M if L = M (full-diversity coding). For example, we get R ≤ 1/2
with an edge coloring using L = M = 2 colors and R ≤ 1/4 for L = M = 4 colors. The
coding rate can exceed 1/M when L < M in applications where full diversity is not mandatory.

An example suited to distributed storage is an edge coloring with a palette of M = 4 colors, a
diversity L = 2, and R ≤ 3/4.

D. Rootcheck nodes and root symbols

In a way similar to root-LDPC codes and product codes built for block-fading channels [10]

[13], we introduce now the notion of root symbols and root-check nodes in product codes to be
designed for distributive storage. A linear [n, k]q code with parity-check matrix H can ﬁll n− k
erasures at positions where the columns of H are independent. These n− k symbols correspond
to n − k separate edges in the non-compact graph and to a unique edge (supersymbol) in the
compact graph. Therefore, for simplicity, we start by deﬁning a root supersymbol in the compact

graph where supernodes are equivalent to standard LDPC parity-check nodes.

Deﬁnition 5: Let Gc be a compact graph of a product code, let φ be a given edge coloring,
and let e ∈ Ec be a supersymbol. e is a root supersymbol with respect to φ(e) if it admits a
2 , such that all adjacent edges f in υ satisfy φ(f ) 6= φ(e).
neighbor vertex υ, υ ∈ V c

1 or υ ∈ V c

In Deﬁnition 5, if υ ∈ V c
1 then e is a root supersymbol thanks to the product code column to
which it belongs, i.e. e can be solved in one iteration by its column component code when the

color φ(e) is erased. Likewise, e is protected against erasures by its row component code if
2 in the previous deﬁnition. Finally, a root supersymbol may be doubly protected by both
υ ∈ V c
2 satisfy the condition
its row and its column if both right and left neighbors υ1 ∈ V c
of Deﬁnition 5.

1 and υ2 ∈ V c

March 7, 2016

DRAFT

14

Deﬁnition 6: Let G be a non-compact graph of a product code, let φ be a given edge coloring,
and let e ∈ E be a symbol. e is a root symbol with respect to φ(e) if it admits a neighbor vertex
υ such that:
φ(f ) = φ(e) for at most n2 − k2 − 1 adjacent edges f if υ ∈ V1, or
φ(f ) = φ(e) for at most n1 − k1 − 1 adjacent edges f if υ ∈ V2.

As mentioned in the paragraph before Deﬁnition 5, Deﬁnition 6 implies that the ni − ki root
symbols with the same color should belong to positions of independent columns in the parity-

check matrix of the component code Ci. This constraint automatically disappears for MDS
component codes since any set of ni − ki columns of Hi has full rank.

E. The rootcheck order in product codes

Not all symbols of a product code are root symbols. Under iterative row-column decoding on

channels with block erasures, some symbols may be solved in two decoding iterations or more.

Some set of symbols may never be solved and are referred to as stopping sets [17] [54] [51]. Our

study is restricted to erasing the symbols of one color out of M. Hence, the rest of this paper is

restricted to double diversity, L = 2. Absence of diversity is equivalent to L = 1. We establish

now the root order ρ of a symbol. For root symbols satisfying deﬁnitions 5 and 6, the root

order is ρ = 1. For symbols that can be solved after two decoding iterations, we set ρ = 2. The
formal deﬁnition of the root order ρ can be written in the following recursive manner (for ρ ≥ 2).

Deﬁnition 7: Let Gc be a compact graph of a product code, let φ ∈ Φ(Ec) be an edge coloring,

1 be the column neighbor vertex of e. ∀f adjacent to e in υ1 and φ(f ) = φ(e),

and let e ∈ Ec be a super-symbol. e has root order ρ(e) = min(ρ1, ρ2) where:
1- Let υ1 ∈ V c
we have ρ(f ) < ρ1.
2- Let υ2 ∈ V c
have ρ(f ) < ρ2.

2 be the row neighbor vertex of e. ∀f adjacent to e in υ2 and φ(f ) = φ(e), we

The previous deﬁnition implies that ρ(e) = 1 if there exists no adjacent edge with the same
color. Also, for an edge e that does not admit a ﬁnite ρ(e), we set ρ(e) = ∞. When color
φ(e) is erased, symbols belonging to the so-called stopping sets can never be solved (even after

March 7, 2016

DRAFT

an inﬁnite number of decoding iterations) and hence their root order is inﬁnite. In the next

section we review stopping sets as known in the literature and we study new stopping sets for

product codes based on MDS components under iterative algebraic decoding. Deﬁnition 7 can
be rephrased to make it suitable for the non-compact graph G. We pursue this section to establish
an upper bound of the largest ﬁnite root order valid for all edge colorings φ.

15

Theorem 1: Let CP be a product code [n1, k1]⊗[n2, k2] with a compact graph Gc = (V c

1 , V c

2 , Ec).

∀φ ∈ Φ(Ec) and ∀e ∈ Ec we have:
Case 1: ∄f ∈ Ec such that φ(f ) = φ(e) and ρ(f ) = ∞, then
2M(cid:25) = ρu.

1 ≤ ρ(e) ≤(cid:24) N c

Deﬁne the minimum number of good edges,

ηmin(φ) = min

i=1...M |{f ∈ Ec : φ(f ) = i, ρ(f ) = 1}|.

Then, in Case 1,

2ρ(e) + ηmin(φ) − 3 ≤(cid:24)N c
M(cid:25) .
Case 2: ∃f ∈ Ec such that φ(f ) = φ(e) and ρ(f ) = ∞, then
1 ≤ ρ(e) ≤(cid:24)N c

ρ(e) = ∞ or

M(cid:25) − 4,

where N c = |Ec| is given by (2).

(8)

Proof: Case 1 corresponds to a product code with diversity L = 2, for a given color φ(e),

which is capable of solving all symbols when that color is erased. The graph has no inﬁnite root

order symbols. ρ is recursively built by starting from ρ = 1 following two paths in the graph
until reaching a common edge e that has two neighboring vertices with edges of order ρ(e)− 1.
There are up to ⌈N c/M⌉ edges, including e, having color equal to φ(e). The largest ρ(e) is
attained in the middle of the longest path of length ⌈N c/M⌉, hence 2ρ(e)− 1 ≤ ⌈N c/M⌉ which
is translated into the stated result for Case 1. An illustrated instance is given for the reader in
Example 1. Back to the path of length 2ρ(e) − 1 ending with edges of order 1 on both sides, if
the population of order 1 edges is η1 for the color φ(e), then the path can only use a maximum
of ⌈N c/M⌉− (η1− 2) edges. We get the inequality 2ρ(e)− 1 ≤ ⌈N c/M⌉− (η1− 2). By plugging
ηmin(φ) instead of η1, this inequality becomes independent from the particular color. The stated

March 7, 2016

DRAFT

inequality in (8) is obtained after grouping ρ(e) and ηmin(φ) on the left side.
Case 2 corresponds to bad edge coloring where the product code does not have double diversity,

i.e. stopping sets do exist for the color φ(e). The order of e may be inﬁnite if e is involved

16

in a stopping set with another edge f having the same color. Otherwise, consider the smallest
stopping set of size four symbols (the smallest cycle in Gc with edges of color φ(e)), then there
remains ⌈N c/M⌉− 4 edges of color φ(e). A path of length ⌈N c/M⌉− 4 starting with ρ = 1 and
ending at ρ = ∞ may exist. The largest ﬁnite order in this path before reaching the stopping
set is ρ = ⌈N c/M⌉ − 4.

Corollary 1: Let CP be a product code [n1, k1] ⊗ [n2, k2] with a compact graph Gc. Let

φ ∈ Φ(Ec) be an edge coloring. We deﬁne

ρmax(φ) = max
e∈Ec

ρ(e).

(9)

CP attains double diversity under iterative row-column decoding if and only if ρmax(φ) < ∞.
In this case, we say that φ is a double-diversity coloring and ∀e ∈ Ec, e can be solved after at
most ρmax decoding iterations where ρmax(φ) ≤ ρu.

For colorings in Φ(E), we extend the same deﬁnition as in Corollary 1 and we say that
φ ∈ Φ(E) is double-diversity if all edges have a ﬁnite rootcheck order. The parameter ρmax is
important in practical applications to bound from above the amount of conveyed information

within a network (whether it is a local-area or a wide-area network). In fact, in coding for
distributed storage, the locality of a product code per decoding iteration is max(n1, n2) in G
under algebraic decoding of its row and column components. Here, the locality is the number

of symbols to be accessed in order to repair an erased symbol [25]. Locality is max(k1, k2) for
MDS components under ML decoding of the product code components. Finally, for a product

code, the information transfer per symbol is bounded from above by

ρmax(φ) × max(n1, n2).

(10)

The exact transfer cost to ﬁll all erasures with iterative decoding can be determined by multiplying

each order ρ with the corresponding edge population size. This exact cost may vary in a wide

range from one coloring to another. The DECA algorithm presented in Section V dramatically

reduces ρmax by enlarging the edge population with root order 1. The interdependence between

March 7, 2016

DRAFT

ρ and the population of order 1 was revealed in inequality (8). This inequality is useful in
intermediate cases where ρmax = 1 is not attained, i.e. outside the case where all edges have
order 1. The inﬂuence of the component decoding method on the performance of a product code

via its stopping sets is discussed in Section IV.

17

Example 1: Consider a [12, 10]⊗2 product code and a coloring φ with M = 4 colors. The
compact graph has |Ec| = 6 × 6 edges. Instead of drawing Gc, we draw the 6 × 6 compact
matrix representation of the product code in Fig. 3. Supersymbols corresponding to a color
φ(e) = 1 are shaded. Fig. 3 also shows a path in Gc such that a maximal order ρmax = ρu = 5 is
attained for φ(e) = 1. If φ has double diversity then ρmax will not exceed ρu = 5 for all colors
φ(e) ∈ {1, 2, . . . , M}. Note that the parameters of this product code are such that N c/M − 4 is
also equal to 5 for a φ with a diversity defect.

ρ = 4

ρ = 3

5

ρ = 1

ρ = 2

ρ = 2

ρ = 3

ρ = 1

ρ = 4

ρ = 5

4

3

2

1

4

3

2

1

Figure 3: Compact matrix (left) and path in compact graph (right) for a product code [12, 10]⊗2
showing a maximal root order of 5.

Example 2: Consider a [14, 12] ⊗ [16, 14] product code and a coloring φ with M = 4 colors.
The compact graph has |Ec| = 7× 8 edges. The compact matrix and a path attaining ρ = 10 are
illustrated in Fig. 4. φ is chosen such that the ﬁrst color has a cycle involving four supersymbols.

Starting from the root supersymbol (ρ = 1) it is possible to create a path in the graph such that
ρ = 10 is reached. Note that a double-diversity φ cannot exceed a root order ρu = 7.

March 7, 2016

DRAFT

18

10

9

8

7

∞

∞

∞

∞

ρ = ∞

ρ = ∞

ρ = ∞

ρ = ∞

ρ = 10

ρ = 9

ρ = 8

ρ = 7

ρ = 6

ρ = 5

ρ = 4

ρ = 3

ρ = 2

ρ = 1

2

1

6

5

4

3

Figure 4: Compact matrix (left) and path in compact graph (right) for a product code [14, 12] ⊗
[16, 14] showing a maximal ﬁnite root order of 10.

The ideal situation is to construct a product code and its edge coloring in order to obtain

ρ(e) = 1 for all edges. We investigate now the conditions on the product code rate and its
components rates in this ideal situation. The analysis based on ρu reveals the existence of a
trade-off between minimizing the number of decoding iterations and the valid range of both

coding rates for the product code components.

Firstly, let us look at the upper bound ρu from Theorem 1. Without loss of generality, assume

that ni − ki divides ni. Then, we have

The total coding rate becomes

Ri = 1 −

ni − ki

ni

= 1 −

.

1
|V c
i |

R = R1R2 =(cid:18)1 −

1 |(cid:19) ·(cid:18)1 −
1
|V c

2 |(cid:19) .
1
|V c

Using N c = |V c

1 | · |V c

2 |, we get

R1R2 = R1 + R2 − 1 +

1
N c .

March 7, 2016

(11)

(12)

(13)

DRAFT

Finally, from (13) and Theorem 1, the upper bound of the root order for double-diversity edge

coloring of the compact graph can be expressed as

19

ρu =(cid:24) N c

2M(cid:25) =(cid:24)

1

2M × (1 + R1R2 − R1 − R2)(cid:25) .

(14)

Fix the product code rate R, force the upper bound to ρu = 1, and take M = 4 colors. Then
1 + (7 + 8R)R1 − 8R > 0.
the denominator in (14) should be less than 1 or equivalently −8R2
This second-degree polynomial in R1 is non-negative if and only if

R <

9
8 −

1
√2 ≈ 0.4178,

and

√64R2 − 144R + 49 < 16R1 − 8R − 7 < +√64R2 − 144R + 49.

−

(15)

(16)

As a result, with a palette of four colors, (15) tells us that ρ(e) = 1 for all edges is feasible

for a product code with a rate less than 0.4178. It is obvious that (15) is a very constraining
condition because ρu is an upper bound of ρmax(φ) for all φ ∈ Φ(Ec). It is worth noting that
, which corresponds to a product
R1 and R2 vary in a smaller range when R approaches 9
code with balanced components.

8 − 1√2

In Section V-A, we will show unbalanced product codes where a sufﬁcient condition on the

component rates imposes order 1 to all edges. The sufﬁcient condition, not based on ρu, is given
by Lemma 5. But before introducing an efﬁcient edge coloring algorithm in Section V, we

analyze stopping sets in product codes with MDS components in the next section, we describe

the relationship between stopping sets and the product code graph representation, and ﬁnally

we enumerate obvious and non-obvious stopping sets. Stopping sets enumeration is useful to

determine the performance of a product code with and without edge coloring.

IV. STOPPING SETS FOR MDS COMPONENTS

The purpose of this section is to prepare the way for determining the performance of iterative

decoding of non-binary product codes. The analysis of stopping sets in a product code will

yield a tight upper bound of its iterative decoding performance over a channel with independent

erasures. The same analysis will be useful to accurately estimate the performance under edge

coloring in presence of block and multiple erasure channels.

March 7, 2016

DRAFT

20

A. Decoding erasures

Deﬁnition 8: An erasure pattern is said to be ML-correctable if the ML decoder is capable

of solving all its erased symbols.

For an erasure pattern which is not correctable under ML or iterative decoding, the decoding

process may ﬁll none or some of the erasures and then stay stuck on the remaining ones. Before

describing the stopping sets of a product code, let us recall some fundamental results regarding

the decoding of its row and column component codes. The ML erasure-ﬁlling capability of a

linear code satisﬁes the following property.

Proposition 1: Let C[n, k, d]q be a linear code with q ≥ 2. Assume that C is not MDS and
the n symbols of a codeword are transmitted on an erasure channel. Then, there exists an erasure
pattern of weight greater than d − 1 that is ML-correctable.

Proof: Let H be an (n − k) × n parity-check matrix of C with rank n − k > d − 1.
For any integer w in the range [d, n − k], there exists a set of w linearly independent columns
in H. Choose an erasure pattern of weight w with erasures located at the positions of the w

independent columns. Then, the ML decoder is capable of solving all these erasures by simple

Gaussian reduction of H.
For MDS codes, based on a proof similar to the proof of Proposition 1, we state a well-known

result in the following corollary.

Corollary 2: Let C[n, k, d]q be an MDS code. All erasure patterns of weight greater than d−1

are not ML-correctable.

We conclude from the previous corollary that an algebraic decoder for an MDS code attains

the word-error performance of its ML decoder. What about symbol-error performance? Indeed,

for general binary and non-binary codes, the ML decoder may outperform an algebraic decoder

since it is capable of ﬁlling some of the erasures when dealing with a pattern which is not

ML-correctable. In the MDS case, the answer comes from the absence of spectral holes for any

MDS code beyond its minimum distance. This basic result is proven via standard tools from

algebraic coding theory [40] [7]:

Proposition 2: Let C[n, k, d]q be a non-binary MDS code (q > n > 2). For any w satisfying
d ≤ w ≤ n and any support X = {i1, i2, . . . , iw}, where 1 ≤ ij ≤ n, there exists a codeword in
C of weight w having X as its own support.

March 7, 2016

DRAFT

21

Proof: By assumption we have w > r = n − k. Let H be a parity-check matrix of C with
rank r = n − k. Recall that the MDS property makes full-rank any set of n − k columns of H
[40]. w is written as w = r + ℓ, where ℓ = 1 . . . k. The w positions of X are anywhere inside the
range [1, n], but for simplicity let us denote h1 . . . hr the r columns of H in the ﬁrst r positions.
The last ℓ columns are denoted ζ1 . . . ζℓ. For any j = 1 . . . ℓ, we have

r

ζj =

ai,jhi,

Xi=1

where ai,j ∈ Fq \{0} otherwise it contradicts d = n− k + 1. Now, select α1 . . . αℓ from Fq \{0}
such that: α1 is arbitrary, α2 is chosen outside the set {−α1ai,1/ai,2}r
i=1, then α3 is chosen
i=1, and so on, up to αℓ which is chosen outside the
outside the set {(−α1ai,1 − α2ai,2)/ai,3}r
set {−Pℓ−1
i=1. Here, the notation a/b in Fq \ {0} is equivalent to the standard

algebraic notation ab−1. The equality

u=1 αuai,u/ai,ℓ}r

ℓ

r

ℓ

Xj=1

αjζj =

αjai,jhi

Xi=1

Xj=1

produces a codeword of Hamming weight w. Hence, there exists a codeword of weight w with
non-zero symbols in all positions given by X .
Now, at the symbol level for an MDS code and an erasure pattern which is not ML-correctable
(w > d − 1), we conclude from Proposition 2 that the ML decoder cannot solve any of the w
erasures because they are covered by a codeword. Consequently, an algebraic decoder for an

MDS code also attains the symbol-error performance of the ML decoder. This behavior will

have a direct consequence on the iterative decoding of a product code with MDS components:

stopping sets are identical when dealing with algebraic and ML-per-component decoders.

A general description of a stopping set was given by Deﬁnition 1. The exact deﬁnition of a

stopping set depends on the iterative decoding type. For product codes, four decoding methods

are known:

• Type I: ML decoder. This is a non-iterative decoder. It is based on a Gaussian reduction of

the parity-check matrix of the product code.

• Type II: Iterative algebraic decoder. At odd decoding iterations, component codes C1 on
each column are decoded via an algebraic decoder (bounded-distance) that ﬁlls up to d −

March 7, 2016

DRAFT

22

1 erasures. Similarly, at even decoding iterations, component codes C2 on each row are
decoded via an algebraic decoder.

• Type III: Iterative ML-per-component decoder. This decoder was considered by Rosnes in
[51] for binary product codes. At odd decoding iterations, column codes C1 are decoded via
an optimal decoder (ML for C1). At even decoding iterations, row codes C2 are decoded
via a similar optimal decoder (ML for C2).

• Type IV: Iterative belief-propagation decoder based on the Tanner graph of CP, as studied
by Schwartz et al. for general linear block codes [54] and by Di et al. for low-density

parity-check codes [17].

The three iterative decoders listed above give rise to three different kinds of stopping sets. As

previously indicated, from Corollary 2 and Propositions 2, we concluded that type-II and type-III

stopping sets are identical if component codes are MDS.

B. Stopping set deﬁnition

Let C be a q-ary linear code of length n, i.e. C is a sub-space of dimension k of Fn

q . The
support of C, denoted by X (C), is the set of ℓ distinct positions {i1, i2, . . . , iℓ} = {ij}ℓ
j=1,
1 ≤ ij ≤ n, such that, for all j, there exists a codeword c = (c1 . . . cn) ∈ C with cij 6= 0.
This notion of support X is applied to rows and columns in a product code.

Now, we deﬁne a rectangular support which is useful to represent a stopping set in a bi-
dimensional product code. Let S ⊆ {1, . . . , n1} × {1, . . . , n2} be a set of symbol positions
in the product code. The set of row positions associated to S is R1(S) = {i1, . . . , iℓ1} where
|R1(S)| = ℓ1 and for all i ∈ R1(S) there exists (i, ℓ) ∈ S. The set of column positions associated
to S is R2(S) = {j1, . . . , jℓ2} where |R2(S)| = ℓ2 and for all j ∈ R2(S) there exists (ℓ, j) ∈ S.
The rectangular support of S is

i.e. the smallest ℓ1 × ℓ2 rectangle including all columns and all rows of S.

R(S) = R1(S) × R2(S),

March 7, 2016

(17)

DRAFT

23

Deﬁnition 9: Consider a product code CP = C1 ⊗ C2. Let S ⊆ {1, . . . , n1} × {1, . . . , n2}
r = {j : (i, j) ∈ S}
c = {i : (i, j) ∈ S}. The set S is a stopping set of type III
and

with |R1(S)| = ℓ1 and |R2(S)| = ℓ2. Consider the ℓ1 rows of S given by S (i)
and the ℓ2 columns of S given by S (j)
for CP if there exist linear subcodes C (j)
X (C (i)

r ) = S (i)
The cardinality |S| is called the size of the stopping set and will also be referred to in the
sequel as the weight of S. Recall that type II and type III stopping sets are identical when both
C1 and C2 are MDS. Stopping sets of type III were studied for binary product codes by Rosnes
[51]. His analysis is based on the generalized Hamming distance [67] [29] because sub-codes

c ⊆ C1 and C (i)
for all i ∈ R1(S) and for all j ∈ R2(S).

r ⊆ C2 such that X (C (j)

c ) = S (j)

c

r

involved in Deﬁnition 9 may have a dimension greater than 1. In the non-binary MDS case,

according to Proposition 2, all these sub-codes have dimension 1, i.e. they are generated by

a single non-zero codeword. Consequently, the generalized Hamming distance is not relevant

when using MDS components. In such a case, the analysis of type II stopping sets is mainly

combinatorial and does not require algebraic tools.

Stopping sets for decoder types II-IV can be characterized by four main properties summarized

as follows.

• Obvious or not obvious sets, also known as rank-1 sets. A stopping set S is obvious if

S = R(S).

• Primitive or non-primitive stopping sets. A stopping set is primitive if it cannot be partitioned
into two or more smaller stopping sets. Notice that all stopping sets, whether they are

primitive or not, are involved in the code performance.

• Codeword or non-codeword. A stopping set S is said to be a codeword stopping set if there

exists a codeword c in CP such that X (c) = S.

• ML-correctable or non-ML-correctable. A stopping set S cannot be corrected via ML

decoding if it includes the support of a non-zero codeword.

In the remaining material of this paper, we restrict our study to type II stopping sets.

March 7, 2016

DRAFT

Example 3: Consider a [n1, n1 − 2, 3]q ⊗ [n2, n2 − 2, 3]q product code. A stopping set S of
size w = 9 is shown as a weight-9 matrix of size n1 × n2, where 1 corresponds to an erased
position:

24

S =

.

(18)





0 0 0 0 0 0

0 0 0 0 0 0

0 1 0 1 1 0

0 0 0 0 0 0

0 1 0 1 1 0

0 1 0 1 1 0

0 0 0 0 0 0





R(S) = 


1 1 1

1 1 1

1 1 1




We took n1 = n2 = 7 for illustration. The rectangular support is shown in a compact represen-
tation as a matrix of size ℓ1 × ℓ2 = 3 × 3,

.

(19)

The stopping set in (18) is obvious, it has the same size as its rectangular support. It corresponds
to a matrix of rank 1. Each row and each column of S has weight 3. Iterative row-column
decoding based on component algebraic decoders fails in decoding rows and columns since the

number of erasures exceeds the erasure-ﬁlling capacity of the MDS components. This stopping

set is not ML-correctable because it is a product-code codeword. In the sequel, all stopping sets
(type II) shall be represented in this compact manner by a smaller rectangle of size ℓ1 × ℓ2.

Example 4: For the same [n1, n1 − 2, 3]q ⊗ [n2, n2 − 2, 3]q product code used in the previous

example, the following stopping sets of size 12 are not obvious.

S1 =





0 0 0 0 0 0 0

0 0 0 0 0 0 0

0 1 1 1 0 0 0

0 0 1 1 1 0 0

0 1 0 1 1 0 0

0 1 1 0 1 0 0

0 0 0 0 0 0 0

,





(20)

DRAFT

March 7, 2016

S2 =

0 0 0 0 0 0 0

0 0 0 0 0 0 0

0 1 0 1 1 0 0

0 0 0 1 1 1 0

0 1 0 0 1 1 0

0 1 0 1 0 1 0

0 0 0 0 0 0 0





In compact form, their rectangular support is

25

(21)

.





R(S1) = R(S2) =

.

(22)

1 1 1 0

0 1 1 1

1 0 1 1

1 1 0 1









These stopping sets have size 12 and a 4× 4 rectangular support. For w = 12, it is also possible
to build an obvious stopping set in a 3 × 4 rectangle or a 4 × 3 rectangle full of 1. S1 is ML-
correctable since it does not cover a product code codeword. S2 covers a codeword hence it is
not ML-correctable.

C. Stopping sets and subgraphs of product codes

A stopping set as deﬁned by Deﬁnition (9) corresponds to erased edges in the non-compact
graph G introduced in Section III-A. Indeed, consider the size-9 stopping set given by (18)
or (19). The nine symbol positions involve nine edges in G, three row checknodes, and three
column checknodes. Each of these six checknodes has three erased symbols making the [12, 10, 3]
decoder fail. This stopping set is equivalent to a subgraph of 9 edges in G as shown in Figure 5.
The subgraph in Figure 5 has three length-4 cycles and two length-6 cycles. The small cycles
of length-4 are associated to an erasure pattern with a 2 × 2 rectangular support which is not a
stopping set (d1 = d2 = 3). Similarly, length-6 cycles are not stopping sets and are associated
to erasure patterns with a 2 × 3 rectangular support. We will see in the next section that the
minimum stopping set size is d1d2 = 9, i.e. it is equal to the minimum Hamming distance of
the product code.

March 7, 2016

DRAFT

26

5

C2

C1

5

6

C2

C1

6

7

C2

C1

7

8

C2

C1

8

Figure 5: A sub-graph of G representing the size-9 obvious stopping set. The graph G has
|E| = 144 edges, |V2| = 12 left (row) checknodes, and |V1| = 12 left (column) checknodes.
Only the stopping set edges are drawn.

A subgraph of Gc can be embedded into G by splitting each super-edge into (n1−k1)×(n2−k1)
edges. The converse is not always true. The subgraph with nine edges in Figure 5 cannot be
compressed into a subgraph of Gc. For the [12, 10, 3]⊗2 product code, a supersymbol in Gc
contains four edges. Hence, a necessary condition for a stopping set in G to become a valid
stopping set in Gc is to erase edges in groups of 4. Knowing that type II and type III stopping
sets are identical when row and column codes C1 and C2 are MDS, Deﬁnition (9) leads to the
following corollaries.

Corollary 3: Let CP = C1 ⊗ C2 be a product code with MDS components C1 and C2 having
minimum Hamming distance d1 and d2 respectively. Assume that symbols (edges) of G =
(V1, V2, E) are sent over an erasure channel. A stopping set for the iterative decoder is a subgraph
of G such that all column vertices in V1 have a degree greater than or equal to d1 and all row
vertices in V2 have a degree greater than or equal to d2.

Corollary 4: Let CP = C1 ⊗ C2 be a product code with MDS components C1 and C2 having

March 7, 2016

DRAFT

27

1 , V c

minimum Hamming distance d1 and d2 respectively. Assume that supersymbols (super-edges)
2 , Ec) are sent over an erasure channel. A stopping set for the iterative decoder
of Gc = (V c
is a subgraph of Gc such that all column vertices in V c
1 have a degree greater than or equal to
2 and all row vertices in V2 have a degree greater than or equal to 2.

The above corollaries suppose a symbol (or a supersymbol) channel with independent erasures.
When G is endowed with an edge coloring φ, we get the same constraint on the validity of a
subgraph embedding from Gc into G. We know from Section III-A that Φ(Ec → E) is a subset
of Φ(E), i.e. some edge colorings of G are not edge colorings of Gc. Consequently, on a block-
erasure channel, if all super-edges of the same color are erased, stopping sets in Gc are a subset
of those in G. The non-compact graph G has a larger ensemble of stopping sets, with or without
edge coloring. As an example, for the [12, 10, 3]⊗2 product code, the smallest stopping set in Gc
has size 2 × 2 when four super-edges are erased which yields a stopping set of size 16 in G.

q

Example 5: Consider the [9, 6, 4]⊗2

product code where d1 = d2 = 4 and q > 9. As-
sume that our palette has M = 3 colors. The non-compact graph admits an ensemble of
|Φ(E)| = 4490186382903298862950669893074864640 edge colorings! The compact graph
has |Φ(Ec)| = 1680 only. In Gc, each color is used N c/M = 3 times. For a channel erasing
all symbols of the same color, the compact graph has no stopping sets (the 2 × 2 rectangular
support cannot be ﬁlled by a single color). A compact matrix representation of Gc attaining
double diversity with all symbols of order 1 is given by the trivial matrix

R G B

B R G

G B R







,

(23)

where the color φ(e) = 1 is replaced by the letter ’R’, φ(e) = 2 is replaced by the letter ’G’, and
φ(e) = 3 is replaced by the letter ’B’. The non-compact graph has 9×9 edges, each color is used
27 times. Double diversity is lost in G if one of the 4 × 4, 4 × 5, or 5 × 5 obvious stopping sets
is covered by a unique color. Clearly, Gc makes the design much easier. This double-diversity
product code has a relatively low coding rate. More challenging product code designs are given

in Section V with higher rates up to the one imposed by the block-fading/block-erasure Singleton

bound.

March 7, 2016

DRAFT

28

D. Enumeration of stopping sets

For a ﬁxed non-zero integer w, the number of stopping sets of size w, denoted as τw, falls
in two different cases. Firstly, τw = 0 if w is small with respect to the minimum Hamming
distance of the product code. Also, τw = 0 for special erasure patterns obtained by adding a small
neighborhood to a smaller obvious set. Secondly, for both obvious and non-obvious stopping

sets, τw is non-zero and the weight w may correspond to many rectangular supports of different
height and width. The code performance over erasure channels is dominated by not-so-large

stopping sets. Non-empty stopping sets of the second case satisfy the general property stated in

the following lemma.

Lemma 1: Given a weight w ≤ (d1 + 1)(d2 + 1) and assuming τw > 0, then ∃S 0 such that

∀S with |S| = w, we have kR(S)k ≤ kR(S 0)k = (ℓ0

1, ℓ0

2), where

ℓ0

ℓ0

d2 (cid:23) ,
1 ≤ d1 + 1 +(cid:22)d1 + 1
2 ≤ d2 + 1 +(cid:22)d2 + 1
d1 (cid:23) .

(24)

(25)

Proof: Let w be equal to (d1 + 1)(d2 + 1). In order to establish an upper bound of the height
ℓ1, we build the highest possible rectangular support for this weight w. Assume the rectangle is
1 × ℓ2, each of its rows should have at least d2 erasures to make the type-II decoder fail. Then
ℓ0
1 ≤ (d1 + 1)(d2 + 1) which becomes the upper bound given by (24). Now, if w is less than
d2ℓ0
(d1 + 1)(d2 + 1), the rectangular support of the stopping set can only shrink in size. The upper
bound of the width in (25) is proven in a similar way.

The above lemma states the existence of a maximal rectangular support for a given stopping set

size. The example given below cites stopping sets with a unique-size rectangular support and

stopping sets with multiple-size rectangular supports.

Example 6: Consider a C1⊗ C2 product code where C1 and C2 are both MDS with minimum
Hamming distance 3. The stopping set given by (19) cannot have a large rectangular support.
In general, all stopping sets of size d1d2 have a rectangular support of ﬁxed dimensions d1 × d2.
Now, let w = 12. As indicated in Example 4, stopping sets of size 12 may be included in
rectangular supports of dimensions 3× 4, 4× 3, and 4× 4. For w = 12, it is impossible to build
a 4 × 5 rectangular support (reductio ad absurdum) making ℓ0
2 = 4. A similar proof
by contradiction yields ℓ0

1 = 4 and ℓ0

1 = 5 and ℓ0

2 = 5 for w = 15.

March 7, 2016

DRAFT

29

The next lemma gives an obvious upper bound of the size of R(S) by stating a simple limit on
the number of zeros (non-erased positions) inside R(S).

Lemma 2: Let R(S) be the ℓ1 × ℓ2 rectangular support of a stopping set S of size w. Let
β = ℓ1ℓ2 − w be the number of zero positions, or equivalently β is the size of the set R(S) \S.
Then

β ≤ min((ℓ1 − d1)ℓ2, ℓ1(ℓ2 − d2)).

(26)

Before stating and proving Theorem 2, we announce two results in Lemma 3 and Lemma 4 on

bipartite graphs enumeration. We saw in the previous section that stopping sets are sub-graphs
of G and Gc, see Corollary 3 and Corollary 4. In other words, the enumeration of stopping sets
represented as matrices of a given distribution of row weight and column weight is equivalent

to enumerating bipartite graphs where left vertices stand for rows and right vertices stand for

columns. An edge should be drawn between a left vertex and a right vertex according to some

rule, e.g. the rule used in the previous section draws an edge in the bipartite graph for each 1

in the stopping set matrix. Stopping sets enumeration in the next theorem is based on β, the

number of zeros or the number of non-erased positions. Hence, we shall use the opposite rule.
A stopping set of weight w and having a ℓ1 × ℓ2 rectangular support shall be represented by a
bipartite graph with ℓ1 left vertices, ℓ2 right vertices, and a total of β = ℓ1ℓ2 − w edges. Notice
that these bipartite graphs have no length-2 cycles because parallel edges are forbidden.

For ﬁnite ℓ1 and ℓ2, given the left degree distribution and the right degree distribution, there
exists no exact formula for counting bipartite graphs. The best recent results are asymptotic in

the graph size for sparse and dense matrices [14] [16] and cannot be applied in our enumeration.

The following two lemmas solve two cases encountered in Theorem 2 for w = d(d + 2) and
w = (d + 1)(d + 1) both inside a (d + 2)× (d + 2) rectangular support. The deﬁnition of special
partitions is required before introducing the two lemmas.

Deﬁnition 10: Let ℓ ≥ 2 be an integer. A special partition of length j of ℓ is a partition

deﬁned by a tuple (ℓ1, ℓ2, . . . , ℓj) such that its integer components satisfy:

• ℓ1 ≤ ℓ2 ≤ . . . ≤ ℓj.
• Pj
i=1 ℓi = ℓ.
• ℓi ≥ 2, ∀j.
• 1 ≤ j ≤ ℓ/2.

March 7, 2016

DRAFT

30

A special partition shall be denoted by ((ℓ1, . . . , ℓj)).

Deﬁnition 11: The group number of a special partition, denoted by κ = κ(ℓ1, ℓ2, . . . , ℓj), is
the number of different integers ℓj, for j = 1 . . . ℓ/2. In other words, following set theory, the
set including the j integers ℓi’s is {ℓi1, ℓi2, . . . , ℓiκ}. The group number divides the partition of
ℓ into κ groups where the mth group includes ℓim repeated gm times, and Pκ
Lemma 3: Consider bipartite graphs deﬁned as follows: ℓ left vertices, ℓ right vertices, all
vertices have degree 2, and no length-2 cycles are allowed. For ℓ ≥ 2, the total number xℓ of
such bipartite graphs is given by the expression

m=1 gm = j.

xℓ = X((ℓ1,...,ℓj))

1

m=1

Qκ(ℓ1,...,ℓj)

j

Yk=1Qℓk−1

u=0 (ℓ −Pk−1

2ℓk

i=1 ℓi − u)2

gm!

(27)

where P((ℓ1,...,ℓj)) is a summation over all special partitions of the integer ℓ, κ(ℓ1, . . . , ℓj) is the

group number of the special partition ((ℓ1, . . . , ℓj)), and gm is the size of the mth group.

Proof: Firstly, let us ﬁnd the number of Hamiltonian bipartite graphs having ℓk left vertices,
ℓk right vertices, all vertices of degree 2, and no length-2 cycles allowed. There are (ℓk!)2 ways
to choose the order of all left and right vertices. If the Hamiltonian cycle is represented by

a sequence of 2ℓk integers corresponding to the 2ℓk vertices of the bipartite graph, then there
are 2ℓk ways to shift the Hamiltonian cycle without changing the graph. Hence, the number of
Hamiltonian bipartite graphs of degree 2 is

(ℓk!)2
2ℓk

.

(28)

Secondly, given the half-size ℓ of the bipartite graph stated in this lemma, all special partitions of
ℓ are considered. For a ﬁxed special partition ((ℓ1, ℓ2, . . . , ℓj)) the bipartite graph is decomposed
into j Hamiltonian graphs each of length ℓk, k = 1 . . . j. The number of choices for selecting
the vertices of the j Hamiltonian graphs is

The above number should be multiplied by the number of Hamiltonian graphs for each selection

i=1 ℓi

j

Yk=1(cid:18)ℓ −Pk−1

ℓk

2

(cid:19)

.

(29)

of vertices to get

March 7, 2016

i=1 ℓi

j

Yk=1(cid:18)ℓ −Pk−1

ℓk

2

(cid:19)

(ℓk!)2
2ℓk

.

(30)

DRAFT

But for a given special partition, each group of size gm is creating gm! identical bipartite graphs.
Hence, the ﬁnal result for a ﬁxed partition becomes

31

Then, xℓ is obtained by summing (31) over all special partitions of the integer ℓ to yield

(31)

(32)

1

gm!

i=1 ℓi

j

Yk=1(cid:18)ℓ −Pk−1

ℓk

2

(cid:19)

(ℓk!)2
2ℓk

.

i=1 ℓi

j

Yk=1(cid:18)ℓ −Pk−1

ℓk

2

(cid:19)

(ℓk!)2
2ℓk

.

gm!

m=1

Qκ(ℓ1,...,ℓj)
xℓ = X((ℓ1,...,ℓj))

1

m=1

Qκ(ℓ1,...,ℓj)

The simpliﬁcation of the factors (ℓk!)2 yields the expression stated by this lemma.

Lemma 4: Consider bipartite graphs deﬁned as follows: ℓ left vertices, ℓ right vertices, all left

vertices have degree 2 except one vertex of degree 1, all right vertices have degree 2 except one
vertex of degree 1, and ﬁnally no length-2 cycles are allowed. For ℓ ≥ 3, the total number yℓ of
such bipartite graphs is

where xℓ is determined via Lemma 3 and x1 = 0.

yℓ = ℓ2 ·(cid:0)(2ℓ − 1) · xℓ−1 + (ℓ − 1)2 · xℓ−2(cid:1) ,

(33)

Proof: Let the ﬁrst ℓ − 1 left vertices and the ﬁrst ℓ − 1 right vertices be of degree 2.
There exists two ways to complete this bipartite graph such that the two remaining vertices have

degree 1.

• Each of the xℓ−1 sub-graphs has 2(ℓ− 1) edges. Break one edge into two edges and connect
them to the remaining left and right vertices, the number of such graphs is 2(ℓ − 1)xℓ−1.
Another set of xℓ−1 bipartite graphs is built by directly connecting the last two vertices
together without breaking any edge in the upper sub-graph. Now, we ﬁnd 2(ℓ − 1)xℓ−1 +
xℓ−1 = (2ℓ − 1)xℓ−1 bipartite graphs.

• Fix a vertex among the ℓ − 1 upper left vertices and ﬁx one among the ℓ − 1 upper right
vertices ((ℓ − 1)2 choices). Consider a length-2 cycle including these two vertices. One
edge of this cycle can be broken into two edges and then attached to the degree-1 vertices
at the bottom. The remaining ℓ − 2 left and right vertices may involve xℓ−2 sub-graphs.
Consequently, the number of graphs in this second case is (ℓ − 1)2xℓ−2.

The total number of bipartite graphs enumerated in the above cases is

March 7, 2016

(2ℓ − 1)xℓ−1 + (ℓ − 1)2xℓ−2.

(34)

DRAFT

32

Finally, the degree-1 left vertex has ℓ choices and so has the degree-1 right vertex. The number

of graphs in (34) should be multiplied by ℓ2.

We make no claims about a possible generalization of Lemma 3 and Lemma 4 to ﬁnite bipartite

graphs with higher vertex degrees. As mentioned before, for general degree distributions, results

on enumeration of asymptotic bipartite graphs were published by Brendan McKay and his co-

authors [14] [16]. Table I shows the number of special partitions for ℓ = 2 . . . 32. The number

of standard partitions (the partition function) can be found by a recursion resulting from the

pentagonal number theorem [15]. To our knowledge, there exists no such recursion for special

partitions. The number of bipartite graphs under the assumptions of Lemma 3 and Lemma 4 is

found in Table II for a graph half-size up to 8. Finally, we are ready to state and prove the ﬁrst

theorem on stopping sets enumeration.

1, 1, 2, 2, 4, 4, 7, 8, 12, 14, 21, 24, 34, 41, 55, 66, 88, 105, 137,

165, 210, 253, 320, 383, 478, 574, 708, 847, 1039, 1238, 1507

Table I: Sequence of the number of special partitions of the integer ℓ, for ℓ = 2 . . . 32. Special

partitions are described in Deﬁnition 10. The sequence for standard partitions can be found

in [57].

ℓ

xℓ

yℓ

2

1

0

3

6

4

90

5

6

7

8

2040

67950

3110940

187530840

45

816

22650

888840

46882710

3199593600

Table II: Number of bipartite graphs not including length-2 cycles from Lemma 3 and Lemma 4.

In the sequel, the open interval between two real numbers a and b will be denoted ]a, b[,

]a, b[ = {x ∈ R : a < x < b}.

Theorem 2: Let CP be a product code [n1, k1, d1]q ⊗ [n2, k2, d2]q built from row and column
MDS component codes, where the alphabet size q is greater than max(n1, n2). Let τw be the
number of stopping sets of size w. We write τw = τ a + τ b, where τ a counts obvious stopping
sets and τ b counts non-obvious stopping sets. Under (type-II) iterative algebraic decoding and
for d1 = d2 = d ≥ 2, stopping sets are characterized as follows:

March 7, 2016

DRAFT

33

• For w < d2,

• For w = d2,

• For w ∈]d2, d(d + 1)[,

• For w = d(d + 1),

τ a = τ b = 0.

τ a =(cid:18)n1

d(cid:19),
d(cid:19)(cid:18)n2

τ b = 0.

τ a = τ b = 0.

d(cid:19)(cid:18) n2
τ a =(cid:18)n1
τ b = (d + 1)!(cid:18) n1

d(cid:19),
d + 1(cid:19)(cid:18)n2
d + 1(cid:19) +(cid:18) n1
d + 1(cid:19).
d + 1(cid:19)(cid:18) n2

• For w ∈ ]d(d + 1), d(d + 2)[.

Let us write w = d2 + d + λ, where λ ∈ [1, d − 1].

τ a = 0,

τ b = (d + 1 − λ)!(cid:18)d + 1

λ (cid:19)2(cid:18) n1

d + 1(cid:19)(cid:18) n2

d + 1(cid:19).

• For w = d(d + 2),
d(cid:19)(cid:18) n2
τ a =(cid:18)n1
τ b = (d + 1)2(cid:18) n1
+ X2r0+r1=d(cid:18)d + 1
d + 2(cid:19)(cid:18) n2
+ xd+2(cid:18) n1

d(cid:19),
d + 2(cid:19)(cid:18)n2
d + 2(cid:19) +(cid:18) n1
d + 1(cid:19)
d + 1(cid:19)(cid:18) n2
r0 (cid:19)(cid:18)d + 1 − r0

d + 2(cid:19),

r1

(cid:19)(d + 2)!

2r2

d + 1(cid:19)(cid:18) n2
(cid:20)(cid:18) n1

d + 2(cid:19) +(cid:18) n1

d + 2(cid:19)(cid:18) n2

d + 1(cid:19)(cid:21)

where P2r0+r1=d is a summation over r0 and r1, both being non-negative and satisfying
2r0 + r1 = d, r2 = d + 1 − r0 − r1, and xd+2 is determined from Lemma 3.

March 7, 2016

DRAFT

34

(cid:19)(d + 2)!

2r0

d + 1(cid:19)(cid:18) n2
(cid:20)(cid:18) n1

d + 2(cid:19) +(cid:18) n1

d + 2(cid:19)(cid:18) n2

d + 1(cid:19)(cid:21)

• For w = (d + 1)(d + 1)
d + 1(cid:19),
d + 1(cid:19)(cid:18) n2
τ a =(cid:18) n1
r0 (cid:19)(cid:18)d + 1 − r0
τ b = X2r0+r1=d+1(cid:18)d + 1
d + 2(cid:19),
d + 2(cid:19)(cid:18) n2
+ yd+2(cid:18) n1

r1

where yd+2 is determined from Lemma 4.
Proof: For w satisfying d2 ≤ w ≤ (d + 1)2, the admissible size of R(S) varies from d2
up to (d + 2)2 as given by Lemma 1. All cases stated in the theorem shall use the following
sequence of R(S) listed in the order of increasing size ℓ1ℓ2: d2, d(d + 1), d(d + 2), (d + 1)2,
(d + 1)(d + 2), and (d + 2)2. For these rectangular supports, the stopping set weight also has

six cases to be considered, where w takes the following values (or ranges) in increasing order:
w = d2, w ∈]d2, d(d + 1)[, w = d(d + 1), w ∈]d(d + 1), d(d + 2)[, w = d(d + 2), and w = (d + 1)2.

• The case w < d2.

Consider a stopping set of size w < d2. Its rectangular support R(S) has size ℓ1ℓ2 ≥ w. All
columns should have a weight greater than or equal to d, we ﬁnd that w ≥ dℓ2. Similarly,
all rows must have a weight greater than or equal to d, then w ≥ dℓ1. By combining the two
inequalities, we ﬁnd w2 ≥ d2ℓ1ℓ2 ≥ d2w, so we get w ≥ d2 which is a contradiction unless
these stopping sets do not exist, i.e. τw = 0 for w < d2 under type II iterative decoding.

• The case w = d2.

We use similar inequalities as in the previous case. We have w = d2 ≥ dℓ2 because column
decoding must fail. We obtain ℓ2 ≤ d. In a symmetric way, w = d2 ≥ dℓ1 because row
decoding must fail. We obtain ℓ1 ≤ d. But R(S) cannot be smaller than S, i.e. we get
ℓ1 = d and ℓ2 = d. We just proved that all stopping set of size d2 are obvious. Their
number is given by choosing d rows out of n1 and d columns out of n2.

• The case d2 < w < d(d + 1).

Given that ℓ1ℓ2 ≥ w > d2, we get ℓ1 ≥ d and ℓ2 ≥ d since the support R(S) is larger than
a d × d rectangle, the latter being the smallest stopping set as proven in the previous case.
Take ℓ1 = d, then ℓ2 ≥ d + 1 because w > d2. The weight of each column must be at least

March 7, 2016

DRAFT

35

d giving us w ≥ dℓ2 ≥ d(d + 1), which is a contradiction unless τw = 0. For ℓ1 > d, the
same arguments hold.

• The case w = d(d + 1).

– The smallest R(S) is d × (d + 1) or (d + 1) × d. According to Lemma 2, we have

β = 0. All these stopping sets are obvious. Their number is

d(cid:19)(cid:18) n2
(cid:18)n1

d + 1(cid:19) +(cid:18) n1

d(cid:19).
d + 1(cid:19)(cid:18)n2

– R(S) has size d(d + 2). Each column must have at least d erasures. Then S can only
be obvious with weight d(d + 2) which contradicts w = d(d + 1). Hence, this size of
rectangular support yields no stopping sets, τw = 0 in this sub-case.

– R(S) has size (d+1)(d+1). Let β be the number of zeros in R(S), β = (d+1)2−w =
d + 1. All these stopping sets are found by considering the (d + 1)! permutations where

a unique 0 is placed per row and per column. Then, the binomial coefﬁcient must be

multiplied by (d + 1)! which yields the τ b announced in the theorem for w = d(d + 1).
– R(S) has size (d + 1)(d + 2). The number of zeros is β = (d + 1)(d + 2)− w = 2d + 2.
Then β > d + 2 = (ℓ1 − d)ℓ2 which contradicts Lemma 2. We get τw = 0 in this
sub-case. The same arguments are valid for larger rectangles.

• The case d(d + 1) < w < d(d + 2).

Let us write w = d2 + d + λ, where λ ∈ [1, d − 1]. We consider below three sub-cases
corresponding to admissible sizes of R(S).
– The smallest R(S) is d× (d + 2) or (d + 2)× d. Take the rectangle of size d× (d + 2).
Each column must have at least d erasures. Then S can only be obvious with weight
d(d+2) which is outside the range for w in this case. Hence, this size of the rectangular

support yields no stopping sets, τw = 0 in this sub-case.

– R(S) has size (d + 1)× (d + 1). The number of zeros is β = (d + 1)2 − w = d + 1− λ,

where β ∈ [2, d].
Put the zeros in R(S) not exceeding one per column and not exceeding one per row.
The enumeration of these stopping sets is given by selecting the β rows and the β
columns, then ﬁlling all β × β permutation matrices in the zero positions. Hence, given

March 7, 2016

DRAFT

36

that (cid:0)d+1

β (cid:1) =(cid:0)d+1

λ (cid:1), we get for this sub-case

τw = β!(cid:18)d + 1

λ (cid:19)2(cid:18) n1

d + 1(cid:19)(cid:18) n2

d + 1(cid:19).

All corresponding stopping sets are not obvious (the rank is greater than 1).

– R(S) has size (d + 1)(d + 2). The number of zeros is β = (d + 1)(d + 2) − w =
2d + 2− λ ∈ [d + 3, 2d + 1]. Then β > d + 2 = (ℓ1 − d)ℓ2 which contradicts Lemma 2.
In a similar way, it can be proven that τw = 0 in the sub-case R(S) with size (d + 2)2.

• The case w = d(d + 2).

The admissible rectangular support can have four sizes: d(d+2), (d+1)(d+1), (d+1)(d+2),

and (d + 2)(d + 2).
– R(S) has size d(d + 2). According to Lemma 2, we have β = 0. All these stopping

sets are obvious. Their number is

– R(S) has size (d + 1)(d + 1). We have β = 1. The number of these stopping sets is

d(cid:19)(cid:18) n2
(cid:18)n1

d + 2(cid:19) +(cid:18) n1

d(cid:19).
d + 2(cid:19)(cid:18)n2

(d + 1)2(cid:18) n1

d + 1(cid:19)(cid:18) n2

d + 1(cid:19).

– R(S) has size (d+1)(d+2). The number of zeros is β = d+2. Each column must have
a unique zero and each row cannot have more than two zeros. Let ri be the number
of rows containing i zeros, i = 0, 1, 2. Then r0 + r1 + r2 = d + 1 and β = 2r2 + r1,
so the constraint is 2r0 + r1 = d. Given a stopping set satisfying this constraint, a
permutation can be applied on the (d + 2) columns to create another stopping set. But

a row with two zeros creates two identical columns, so the number of stopping sets
should be divided by 2r2, where r2 = d + 1 − r0 − r1. The number of stopping sets in
this sub-case is
d + 1(cid:19)(cid:21) .
X2r0+r1=d(cid:18)d + 1
– R(S) has size (d + 2)(d + 2). We have β = 2d + 4 reaching the upper bound in
Lemma 2. R(S) must have two zeros in each column and two zeros in each row. A
ﬁrst group of these stopping sets can be enumerated by building R(S) with two zero
length-(d + 2) diagonals (to be folded if not the main diagonal) and then applying

r0 (cid:19)(cid:18)d + 1 − r0

d + 1(cid:19)(cid:18) n2
(cid:20)(cid:18) n1

d + 2(cid:19) +(cid:18) n1

d + 2(cid:19)(cid:18) n2

(cid:19)(d + 2)!

2r2

r1

March 7, 2016

DRAFT

all row and column permutations. This generates all Hamiltonian bipartite graphs with

d + 2 left vertices and d + 2 right vertices, their number is

37

((d + 2)!)2
2(d + 2)

,

as known from Lemma 3. In fact, the full exact enumeration of stopping sets in this

case is already made by Lemma 3 and its proof, just take ℓ = d + 2. Then, in this

sub-case, the number of stopping sets is given by

• The case w = (d + 1)(d + 1).

xd+2(cid:18) n1

d + 2(cid:19)(cid:18) n2

d + 2(cid:19).

The admissible rectangular support can have three possible sizes (d+1)(d+1), (d+1)(d+2),

and (d + 2)(d + 2).
– R(S) has size (d + 1)(d + 1). We have β = 0, i.e. R(S) = S. The number of these

obvious stopping sets is

d + 1(cid:19)(cid:18) n2
(cid:18) n1

d + 1(cid:19).

– R(S) has size (d + 1)(d + 2). We have β = d + 1. A column of R(S) should contain
at most one zero and a row should contain at most two zeros. Let ri be the number
of rows containing i zeros, i = 0, 1, 2. Then r0 + r1 + r2 = d + 1 and β = 2r2 + r1,
so the constraint is 2r0 + r1 = d + 1. Given a stopping set satisfying this constraint, a
permutation can be applied on the (d + 2) columns to create another stopping set. The

number of stopping sets in this sub-case is

r1

2r2

(cid:19)(d + 2)!

r0 (cid:19)(cid:18)d + 1 − r0

X2r0+r1=d+1(cid:18)d + 1
– R(S) has size (d+2)(d+2). β = 2d+3 which is less than the upper bound in Lemma 2.
These stopping sets are equivalent to bipartite graphs considered in Lemma 4. Then,

d + 1(cid:19)(cid:18) n2
(cid:20)(cid:18) n1

d + 2(cid:19) +(cid:18) n1

d + 2(cid:19)(cid:18) n2

d + 1(cid:19)(cid:21) ,

where r2 = r0.

in this sub-case, the number of stopping sets is given by

yd+2(cid:18) n1

d + 2(cid:19)(cid:18) n2

d + 2(cid:19).

March 7, 2016

DRAFT

38

From the proof of Theorem 2, in the case w = d(d + 2) with a (d + 1) × (d + 2) rectangular
support, the enumeration of stopping sets is directly converted into enumeration of trivial bipartite

graphs deﬁned by: a- ℓ left vertices and a left degree 0, 1, or 2, and b- ℓ + 1 right vertices all
of degree 1. Similarly, the proof for the case w = d(d + 2) with a (d + 1) × (d + 2) rectangular
support is directly related to the enumeration of bipartite graphs with one edge less.

Theorem 3: Let CP be a product code [n1, k1, d1]q ⊗ [n2, k2, d2]q built from row and column
MDS components, where the alphabet size q is greater than max(n1, n2). Let τw be the number
of stopping sets of Hamming weight w. We write τw = τ a + τ b, where τ a counts obvious
stopping sets and τ b counts non-obvious stopping sets. It is assumed that 2 < d1 < d2 < 3d1 − 1
or 2 = d1 < d2 < 4d1 − 1. Under iterative algebraic decoding, stopping sets are characterized
as follows.

• For w < d1d2,

• For w = d1d2,

• For w ∈]d1d2, d1(d2 + 1)[,

• For w = d1(d2 + 1),

τ a = τ b = 0.

τ a =(cid:18)n1

d2(cid:19),
d1(cid:19)(cid:18)n2

τ b = 0.

τ a = τ b = 0.

τ a =(cid:18)n1

d1(cid:19)(cid:18) n2

d2 + 1(cid:19),

τ b = 0.

For larger weights, the enumeration of stopping sets distinguishes three cases: A, B, and C.
Case A: d2 < 2d1.

• For w ∈]d1(d2 + 1), (d1 + 1)d2[.

• For w = (d1 + 1)d2.

τ a = τ b = 0.

d2(cid:19),
d1 + 1(cid:19)(cid:18)n2
τ a =(cid:18) n1
d2 − d1(cid:19)(cid:18) n1
τ b = (d1 + 1)!(cid:18) d2 + 1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

March 7, 2016

DRAFT

• For w ∈](d1 + 1)d2, d1(d2 + 2)[, write w = (d1 + 1)d2 + λ.
λ (cid:19)(cid:18) d2 + 1

τ b = 1{d2<2d1−1} × (d1 + 1 − λ)!(cid:18)d1 + 1

• For w = d1(d2 + 2).

d1 + 1 − λ(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

39

d2 + 2(cid:19),

d1(cid:19)(cid:18) n2

τ a =(cid:18)n1
τ b = (d2 − d1 + 1)!(cid:18) d1 + 1
+ X2r0+r1=2d1−d2(cid:18)d1 + 1

d2 − d1 + 1(cid:19)(cid:18) d2 + 1
r0 (cid:19)(cid:18)d1 + 1 − r0

d2 − d1 + 1(cid:19)(cid:18) n1
(cid:19) (d2 + 2)!
2r0+d2−d1+1(cid:18) n1
• For w ∈]d1(d2 + 2), (d1 + 1)(d2 + 1)[, write w = d1(d2 + 2) + λ.
d1 + λ(cid:19)(cid:18) n1
(cid:19) (d2 + 2)!

τ b = (d2 − d1 + 1 − λ)!(cid:18) d1 + 1
+ X2r0+r1=2d1−d2+λ(cid:18)d1 + 1

2d1 − d2 + λ(cid:19)(cid:18)d2 + 1
r0 (cid:19)(cid:18)d1 + 1 − r0

2r2λ! (cid:18) n1

r1

r1

where r2 = r0 + λ − d1 − 1.
• For w = (d1 + 1)(d2 + 1).

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19)
d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19)
d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19),

d1(cid:19)(cid:18) n2
d2 + 1(cid:19) + 1{d2=2d1−1}(cid:18)n1
d1 + 1(cid:19)(cid:18) n2
τ a =(cid:18) n1
(cid:19)
r0 (cid:19)(cid:18)d1 + 1 − r0
τ b = X2r0+r1=d1+1(cid:18)d1 + 1
2r0(d2 − d1 + 1)!(cid:18) n1
(cid:19)(d1 + 2)!
+ 1{d2=d1+1} × X2r0+r1=d2+1(cid:18)d2 + 1
+ 1{d2=2d1−1} × X3r0+2r1+r2=d1+1(cid:18)d1 + 1

d2(cid:19),
d1 + 2(cid:19)(cid:18)n2
d2 + 3(cid:19) + 1{d2=d1+1}(cid:18) n1
d2 + 2(cid:19)
d1 + 1(cid:19)(cid:18) n2
d2 + 1(cid:19)
d1 + 2(cid:19)(cid:18) n2
2r0 (cid:18) n1
(cid:19)×
(cid:19)(cid:18)d1 + 1 − r0 − r1

r0 (cid:19)(cid:18)d2 + 1 − r0

(d2 + 2)!

r1

r1

r1

r2

(d2 + 3)!

r0 (cid:19)(cid:18)d1 + 1 − r0
d2 + 3(cid:19)
d1 + 1(cid:19)(cid:18) n2
2r26r3 (cid:18) n1
d2 + 2(cid:19)
d1 + 2(cid:19)(cid:18) n2
(cid:19)(cid:18) n1

2

(d2 + 2)yd1+2

+ 1{d2=d1+1}(cid:18)(d2 + 2)xd1+2 +
+ 1{d1=2,d2=3} × 1860(cid:18) n1

d1 + 2(cid:19)(cid:18) n2

d2 + 3(cid:19).

March 7, 2016

DRAFT

where r3 = d1 + 1 − r0 − r1 − r2, and xd1+2 and yd1+2 are determined from Lemma 3 and
Lemma 4 respectively.

40

Case B: d2 = 2d1.

• For w ∈]d1(d2 + 1), (d1 + 1)d2[.

• For w = (d1 + 1)d2 = d1(d2 + 2).

τ a = τ b = 0.

d1 + 1(cid:19)(cid:18)n2
τ a =(cid:18) n1
τ b = (d1 + 1)!(cid:18)d2 + 1

d2(cid:19) +(cid:18)n1
d1 + 1(cid:19)(cid:18) n1

d2 + 2(cid:19),
d1(cid:19)(cid:18) n2
d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19) +

• For w ∈](d1 + 1)d2, d1(d2 + 3)[, write w = (d1 + 1)d2 + λ.

(d2 + 2)!

2d1+1 (cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

τ b = (d1 + 1 − λ)!(cid:18)d1 + 1
+ X2r0+r1=λ(cid:18)d1 + 1

λ (cid:19)(cid:18)d2 + 1
r0 (cid:19)(cid:18)d1 + 1 − r0
where r2 = d1 + 1 − r0 − r1 = d1 + 1 + r0 − λ.

r1

d1 + λ(cid:19)(cid:18) n1
(cid:19)(d2 + 2)!

d1 + 1(cid:19)(cid:18) n2
2r2λ! (cid:18) n1

d2 + 1(cid:19)
d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19),

• For w = d1(d2 + 3).

d2 + 3(cid:19),

d1(cid:19)(cid:18) n2

d1 + 1(cid:19)(cid:18) n2
r0 (cid:19)(cid:18)d1 + 1 − r0

τ a =(cid:18)n1
τ b = (d1 + 1)(d2 + 1)(cid:18) n1
+ X2r0+r1=d1(cid:18)d1 + 1
+ X3r0+2r1+r2=d1(cid:18)d1 + 1
where r3 = d1 + 1 − r0 − r1 − r2 = 2r0 + r1 + 1.

d2 + 1(cid:19)
(cid:19)(d2 + 2)!
d1 + 1(cid:19)(cid:18) n2
2r2d1! (cid:18) n1
(cid:19)(cid:18)d1 + 1 − r0 − r1

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

r1

r2

d2 + 2(cid:19)
(cid:19) (d2 + 3)!
2r26r3 (cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19),

March 7, 2016

DRAFT

• For w = (d1 + 1)(d2 + 1).

41

d2 + 1(cid:19),
d1 + 1(cid:19)(cid:18) n2
τ a =(cid:18) n1
r0 (cid:19)(cid:18)d1 + 1 − r0
τ b = X2r0+r1=d1+1(cid:18)d1 + 1
r0 (cid:19)(cid:18)d1 + 1 − r0
+ X3r0+2r1+r2=d1+1(cid:18)d1 + 1
Case C: 4 < 2d1 < d2 < 3d1 − 1
or 4 = 2d1 < d2 < 4d1 − 1.

r1

r1

d1 + 1(cid:19)(cid:18) n2

(cid:19) (d2 + 2)!
2r0(d1 + 1)!(cid:18) n1
(cid:19)(cid:18)d1 + 1 − r0 − r1

r2

d2 + 2(cid:19)
(cid:19) (d2 + 3)!
2r262r0+r1(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19).

• For w ∈]d1(d2 + 1), d1(d2 + 2)[.

• For w = d1(d2 + 2).

τ a = τ b = 0.

τ a =(cid:18)n1

d1(cid:19)(cid:18) n2

d2 + 2(cid:19).

τ a = τ b = 0.

• For w ∈]d1(d2 + 2), (d1 + 1)d2[.

• For w = (d1 + 1)d2.

d2(cid:19),
d1 + 1(cid:19)(cid:18)n2
τ a =(cid:18) n1
d1 + 1(cid:19)(cid:18) n1
τ b = (d1 + 1)!(cid:18)d2 + 1
+ 1{d1=2,d2=6} × 1680(cid:18) n1

d1 + 1(cid:19)(cid:18) n2
d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19) +
d2 + 3(cid:19).

(d2 + 2)!

2d1+1(d2 − 2d1)!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19)

March 7, 2016

DRAFT

• For w ∈](d1 + 1)d2, d1(d2 + 3)[, write w = (d1 + 1)d2 + λ.

42

τ b = 1{d1>2} ×"(d1 + 1 − λ)!(cid:18) d2 + 1
(cid:19)
+ X2r0+r1=λ(cid:18)d1 + 1
where r2 = d1 + 1 + r0 − λ.

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

d1 + 1 − λ(cid:19)(cid:18)d1 + 1

λ (cid:19)(cid:18) n1
2r2(d2 − 2d1 + λ)!(cid:18) n1

d2 + 1(cid:19)
d1 + 1(cid:19)(cid:18) n2
d2 + 2(cid:19)#.
d1 + 1(cid:19)(cid:18) n2

(d2 + 2)!

• For w = d1(d2 + 3).
d2 + 3(cid:19),
d1(cid:19)(cid:18) n2
τ a =(cid:18)n1
τ b = 1{d1=2,d2=6} S{d1>2} ×"(d2 − 2d1 + 1)!(cid:18) d1 + 1
3d1 − d2(cid:19)(cid:18)d2 + 1
(cid:19)(d2 + 2)!
+ X2r0+r1=3d1−d2(cid:18)d1 + 1
d1 + 1(cid:19)(cid:18) n2
2r2d1! (cid:18) n1
(cid:19)(cid:18)d1 + 1 − r0 − r1
+ X3r0+2r1+r2=3d1−d2(cid:18)d1 + 1
where r2 = d2 − 2d1 + 1 + r0 and r3 = d1 + 1 − r0 − r1 − r2.

r0 (cid:19)(cid:18)d1 + 1 − r0

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

r2

r1

d2 + 1(cid:19)

d1 + 1(cid:19)(cid:18) n2

2d1 (cid:19)(cid:18) n1
d2 + 2(cid:19)
(cid:19) (d2 + 3)!
2r26r3 (cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19)#,

• For w = d1(d2 + 4).

d2 + 4(cid:19).
• For w ∈]d1(d2 + 3), (d1 + 1)(d2 + 1)[, write w = d1(d2 + 3) + λ.

τ a = 1{d1=2} ×(cid:18)n1

d1(cid:19)(cid:18) n2

d2 + 1(cid:19)
d1 + 1(cid:19)(cid:18) n2

d1 + 1(cid:19)(cid:18) n2

3d1 − d2 + λ(cid:19)(cid:18) d2 + 1
r0 (cid:19)(cid:18)d1 + 1 − r0

τ b = (d2 − 2d1 + 1 − λ)!(cid:18) d1 + 1
+ X2r0+r1=3d1−d2+λ(cid:18)d1 + 1
X3r0+2r1+r2=3d1−d2+λ(cid:18)d1 + 1
+ 1{d1=2,d2=6} × 22050(cid:18) n1
where r2 = d1 + 1 − r0 − r1 and r3 = d1 + 1 − r0 − r1 − r2.

2d1 + λ(cid:19)(cid:18) n1
(cid:19) (d2 + 2)!
2r2(d1 + λ)!(cid:18) n1
(cid:19)(cid:18)d1 + 1 − r0 − r1

r0 (cid:19)(cid:18)d1 + 1 − r0
d2 + 4(cid:19),
d1 + 1(cid:19)(cid:18) n2

r1

r2

r1

+

d2 + 2(cid:19)
(cid:19)(d2 + 3)!
2r26r3λ!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19)

March 7, 2016

DRAFT

43

(cid:19)

(d2 + 3)!

2r26r3(d2 − 2d1 + 1)!×

• For w = (d1 + 1)(d2 + 1).

d2 + 1(cid:19),
d1 + 1(cid:19)(cid:18) n2
τ a =(cid:18) n1
d2 + 2(cid:19)
d1 + 1(cid:19)(cid:18) n2
d1 + 1(cid:19)(cid:18) n1
τ b = (d1 + 1)!(cid:18)d2 + 2
r0 (cid:19)(cid:18)d1 + 1 − r0
+ X3r0+2r1+r2=d1+1(cid:18)d1 + 1
d2 + 3(cid:19)
d1 + 1(cid:19)(cid:18) n2
(cid:18) n1
d2 + 4(cid:19)
d1 + 1(cid:19)(cid:18) n2
+ 1{d1=2,d2=5} × 11130(cid:18) n1
d2 + 4(cid:19),
d1 + 1(cid:19)(cid:18) n2
+ 1{d1=2,d2=6} × 111300(cid:18) n1
where r3 = d1 + 1 − r0 − r1 − r2.

r1

(cid:19)(cid:18)d1 + 1 − r0 − r1

r2

The detailed proof of Theorem 3 is found in Appendix A. From a stopping set perspective, both

theorems 2&3 match Tolhuizen’s results on weight distribution for a weight less than d1d2 + d2
[62]. Our theorems found stopping sets that are only obvious for w in the range [d1d2, d1d2 + d2[.
For any weight w, there exists an equivalence in support between codewords and obvious stopping

sets (thanks to Proposition 3). Trivial lower and upper bounds of the number of obvious weight-w

product code codewords are

(q − 1)τw ≤ Aw ≤ 1{τw6=0}Aw.

For non-obvious stopping sets and non-obvious codewords, establishing a clear relationship

is still an open problem. This is directly related to solving the weight enumeration beyond

d1d2 + max(d1, d2). In the special case d1 = d2 = d, Sendrier gave upper bounds of the number
of erasure patterns for a weight up to d2 + 2d − 1 [56].

V. EDGE COLORING ALGORITHM UNDER CONSTRAINTS

In section III, we described graph representations of product codes and we introduced the root

order ρ(e) of an edge with respect to its color φ(e). Our objective is to ﬁnd a coloring φ such

that the maximum diversity order is reached under block erasures. The notion of root order in

March 7, 2016

DRAFT

44

Deﬁnition (7) is for double diversity (L = 2) because it indirectly assumes that all symbols of

one color out of M can be erased by the channel. Given the Singleton bound tradeoff stated in

(7), double diversity is sufﬁcient in distributed storage applications where the required coding

rate should be sufﬁciently high. Deﬁnition (7) may be generalized to take into account two or

more erased colors, e.g. see Figure 11 in [13] for L = 3 with M = 3 colors where an information

symbol is protected by multiple root checknodes. In this paper, we restrict both Deﬁnition (7)

and the design in this section to a double-diversity product code. This double diversity on a

block-erasure channel is achieved if all stopping sets, as deﬁned and counted in the previous

section, can be colored in a way such that at least two distinct colors are found within the
symbols of a stopping set (valid for both G and Gc). This task is intractable. Imagine an edge
coloring φ designed in a way to guarantee that all weight-w stopping sets include at least two

colors. This task is already very hard (or almost impossible) for a ﬁxed w. There is no coloring

design tool for non-trivial product codes to ensure that all stopping sets of all weights incorporate

at least two distinct colors.

A. Hand-made edge coloring and its limitations

The aim of this section is to give more insight on designing edge coloring, before introducing

the differential evolution algorithm.

The compact graph Gc makes the design much simpler, as we saw in Section IV-C. The
number of super-edges with the same color is N c/M. We also know from (11)-(13) that the

size, height, and width of Gc are directly related to the component and total coding rates.

Lemma 5: Let CP = C1 ⊗ C2 be a product code with a column component C1[n1, k1]q and
a row component C2[n2, k2]q whose coding rates are R1 = k1/n1 and R2 = k2/n2 respectively.
Assume that ni − ki divides ni, for i = 1, 2, and assume that M divides N c. Gc admits an edge
coloring φ such that ρmax(φ) = 1 if the coding rates satisfy

Proof: Consider the |V c

min(R1, R2) ≤ 1 −
2 | matrix representation of Gc. A sufﬁcient condition to get
ρmax(φ) = 1 is to assign the N c/M edges having the same color to a single row or a single
column. The sufﬁcient condition for ρmax(φ) = 1 is expressed as N c/M ≤ max(n1/(n1 −

1 | × |V c

1
M

.

(35)

March 7, 2016

DRAFT

45

k1), n2/(n2 − k2)), the max let us select the longest item among a row or a column. Recall also
that |V c
i | = ni/(ni − ki). Using (2), the sufﬁcient condition becomes n1n2 ≤ M · max(n1(n2 −
k2), n2(n1 − k1)). Divide by n1n2 to get the inequality announced in the Lemma statement.

When the palette has M = 4 colors, the sufﬁcient condition in Lemma 5 is written as
min(R1, R2) ≤ 3/4. In order to achieve the block-fading Singleton bound for M = 4, we
should take R1 = 3/4 and R2 = 1, i.e. the product code degenerates to a single component
code. It is possible to approach R = 3/4 by keeping R1 = 3/4 and letting R2 = n2−1
be very
n2
close to 1. In this case, the row code C2 is a single-parity check code over Fq. The product code
is very unbalanced. An example of such an unbalanced product code is

CP = [12, 9, 4]q ⊗ [14, 13, 2]q.

From the proof of Lemma 5, the edge coloring of Gc satisfying ρmax = 1 is given by the
following 4 × 14 matrix:

,

(36)

R R R . . . R R

G G G . . . G G

B B B . . . B B

Y Y Y . . . Y Y









where the colors φ(e) = 1, 2, 3, 4 are replaced by the four letters ’R’, ’G’, ’B’, and ’Y’. The
rate of [12, 9, 4]q ⊗ [14, 13, 2]q is comparable to the rate of [12, 10, 3]⊗2
q , R ≈ 0.69 but it is sill
far from reaching three quarters as the product code [14, 12, 3]q ⊗ [16, 14, 3]q. Of course, if the
practical constraints allow for it, it is possible to consider an extremely unbalanced code such
as [12, 9, 4]q ⊗ [100, 99, 2]q!

Let us build balanced product codes by relaxing the constraint ρmax = 1. We may authorize
a ρmax greater than 1 but not too large in order to limit the number of decoding iterations. On
the other hand, the double diversity condition on the edge coloring is maintained. Firstly, let us
ﬁnd a hand-made edge coloring for the [12, 10, 3]⊗2
product code with M = 4 colors. Gc has
6 left supernodes, 6 right supernodes, and a total of 36 edges. Each color is used N c/M = 9
times. The hint is to place a color on the rows of the matrix representation of Gc, row by row
from the top to the bottom in a way that avoids stopping sets. The smallest stopping set is the
2× 2 square. Other non-obvious stopping sets may not be visible without a tedious row-column

q

March 7, 2016

DRAFT

decoding which is equivalent to determining the root order of all edges. We start with the ﬁrst

color ’R’ and use the following number of letters per row:

46

R R R G B Y

R

R

R

R

R

R

R R R G B Y

R B Y R Y G

B G G G R Y

Y G B Y G R

R G B B B Y

R G B Y Y B

















.

(37)

As seen above, we completed the ﬁrst row with the three other colors. On the second row, we
moved the second ’R’ to the right to avoid a 2 × 2 stopping set. Next, we can start ﬁlling the
second color ’G’ from the third row, then the third color ’B’ from the ﬁfth row. There will be

no choice for the 9 positions of ’Y’. We allow some extra permutations to avoid small stopping

sets. After ﬁlling the 36 positions, we found the following hand-made edge coloring for the

[12, 10, 3]⊗2

q product code:

.

(38)

This coloring φ gives 24 super-edges of order 1 (96 edges in the non-compact graph G) and
ρmax(φ) = 3. Can we ﬁnd a better φ? Yes, in Section V-C, the DECA algorithm outputs an edge
coloring with a population of 32 super-edges of order 1 (128 edges in the non-compact graph
G) and reaching ρmax(φ) = 2 only.

In a similar way, we attempt to build a double-diversity coloring for a well-balanced rate-3/4
product code, e.g. the [14, 12, 3]q ⊗ [16, 14, 3]q product code where R1 = 6/7, R2 = 7/8, and
R = 3/4. The compact graph Gc has 7 left vertices and 8 right vertices. For M = 4 colors, each
color is used N c/M = 56/4 = 14 times. Again, we try to avoid small obvious stopping sets like
2 × 2, 2 × 3, 3 × 3, etc. We start by putting ﬁve ’R’ on the ﬁrst row, three ’R’ on the second

March 7, 2016

DRAFT

















row, two ’R’ on the third row, and one ’R’ on the remaining rows as follows:

47

R R R R R G B Y

R R

R

R

R

R

R

R

R

.

(39)

We repeat the same number of color entries ’G’ starting on the fourth row. The color ’B’ starts

with ﬁve entries on the seventh row. We allow some extra permutations to avoid small stopping

sets. Colors were exchanged within a row or within a column. The coloring process was tedious.

Many permutations had to be applied. Some non-obvious stopping sets appeared, a computer

software was used to reveal those sets (only for this task). We reached the following hand-made
double-diversity edge coloring for the [14, 12, 3]q ⊗ [16, 14, 3]q product code:

Y R R Y R G B R

R Y B G Y R R B

B B B Y Y R G R

R G G G G G B Y

R G Y Y B Y G G

G G R R B Y Y Y

R G B B B B B Y

.

(40)

This coloring gives 30 super-edges of order 1 in Gc (120 edges in the non-compact graph G) and
ρmax(φ) = 5. In Section V-C, for the same rate-3/4 product code, the DECA algorithm outputs
an edge coloring with a population of 40 super-edges of order 1 (160 edges in the non-compact
graph G) and reaching ρmax(φ) = 3 only.

B. The algorithm

We propose in this section an algorithm for product codes that searches for an edge coloring

with a large number of root-order-1 edges (good edges) and achieving double diversity. The

March 7, 2016

DRAFT

48

search is made in the ensemble of edge colorings Φ(Ec) of the compact graph Gc. A necessary
condition on the coding rate R to get double diversity is

R ≤ 1 −

1
M

,

(41)

i.e. those satisfying inequality (7), where M is the color palette size. Codes attaining equality

in (7) are referred to as MDS in the block-fading/block-erasure sense [27] [13]. The main loop

of our algorithm is a differential evolution loop that mutates a fraction of the population of bad

edges. The algorithm will be referred to as the Differential Edge Coloring Algorithm (DECA).

The population of bad edges is deﬁned by the following set

B = {e ∈ Ec : ρ(e) > 1}.

(42)

It should be remembered that B = B(φ) because of Deﬁnition (7), but φ is dropped here for

the sake of simplifying the notations. The number of good edges is given by

η(φ) = |Ec \ B| = |{e ∈ Ec : ρ(e) = 1}| .

(43)

Among the |B| bad edges, colors of a fraction of ℵ edges are modiﬁed in order to maximize
η(φ), ℵ ∈ N. The fraction ℵ/|B| should be large enough to allow for a population evolution but
it should stay small enough in order to limit the algorithm complexity. The DECA algorithm

proceeds as follows.

Initialization. The compact graph (V c
2 , Ec), the number of colors M, the differential evolu-
tion parameter ℵ, a maximum number of rounds MaxIter, and an initial edge coloring φ0 are
made ready as an input to DECA.

1 , V c

Pre-processing. Build all weak compositions of ℵ with M parts, i.e. write ℵ as the some of M
non-negative integers,

the number of weak compositions being

ℵ = γ1 + γ2 + . . . + γM ,

M − 1 (cid:19).
Γ =(cid:18)ℵ − M + 1

March 7, 2016

(44)

(45)

DRAFT

For each weak composition, prepare the Λ permutations that permute colors among the ℵ edges,
the total number of these permutations is

49

This pre-processing step is completed by setting a loop counter to zero.

i=1 γi!

QM

Λ(γ1, . . . , γM ) =

(γ1 + . . . + γM )!

.

(46)

Differential evolution loop. This looping phase of DECA includes three main steps.

• Edge sets initialization. Set φ = φ0 and ηmax = 0. Build B = B(φ) and randomly
select a subset Bℵ. There is a unique weak composition (γ1, . . . , γM ) of ℵ associated to Bℵ
determined by

γi = |{e ∈ Bℵ : φ(e) = i}| .

(47)

• Color permutations. For λ = 1 . . . Λ(γ1, . . . , γM ), replace the image of Bℵ in the mapping
φ by a permutation of φ0(Bℵ). The color permutation is denoted by πλ. This step is a
modiﬁcation of the mapping φ0 at the ℵ bad edges, i.e. φ(Bℵ) ← πλ(φ0(Bℵ)). Record the
mapping with the largest number of good edges, i.e. the edge coloring with the best η(φ),
in φ1 and update ηmax.

• Termination. Increment the counter of evolution loops. Stop and output φ1 if this counter

reaches MaxIter, otherwise set φ0 = φ1 and go back to the edge sets initialization.

A detailed functional ﬂowchart of DECA is drawn in Figure 6. The complexity of DECA is

mainly due to the differential evolution loop. The complexity is proportional to Λ(γ1, . . . , γM )
per round. Hence, the number of operations in DECA behaves as

Λ ≤ Λmax(ℵ, M) =

ℵ!

((ℵ/M)!)M .

(48)

When ℵ is not multiple of M, the denominator in the right term should be rewritten asQi0
QM
i=i0+1⌈ℵ/M⌉, where i0 is chosen such that the sum of all elements involved in both products
is equal to ℵ. All Γ compositions of ℵ are not considered by the algorithm. In fact, the total
number of permutations for all weak compositions is

i=1⌊ℵ/M⌋×

Γ

Xj=1

(γ1(j) + . . . + γM (j))!

i=1 γi(j)!

QM

= Mℵ.

(49)

DRAFT

March 7, 2016

50

(V c

1 , V c

2 , E c)

M, ℵ, M axIter

φ0 ∈ Φ(E c)

Precompute Γ weak compositions

For each composition γ1 + . . . + γM = ℵ
precompute the Λ color permutations

iter = 0

φ = φ0, ηmax = 0, λ = 1

Build B = {e ∈ E c : ρ(e) 6= 1}

Select Bℵ ⊂ B

φ(Bℵ) ← πλ(φ0(Bℵ))

η(φ) > ηmax

YES

φ0 = φ1

NO

ηmax = η(φ)

φ1 = φ

λ < Λ

YES

λ ← λ + 1

NO

Max Diversity

Subroutine
(optional)

YES

iter < M axIter

iter ← iter + 1

NO

φ1

Figure 6: Flowchart of the edge coloring algorithm (DECA) for designing double-diversity

product codes.

March 7, 2016

DRAFT

51

Fortunately, the per-round complexity of DECA given in (48) is much smaller that Mℵ, i.e.
Λmax = o(Mℵ). In practical product code design, we will also have Λmax ≪ Mℵ ≪ M N c.

The proposed edge coloring algorithm aims at maximizing η(φ) but does not guarantee that
∀e ∈ Ec, ρ(e) < ∞. In some cases, the algorithm may terminate all its rounds with some edges
having an inﬁnite order, i.e. the coloring is not double-diversity. This occurs when trying to design
a product code with a coding rate very close or equal to 1−1/M, the block-fading/block-erasure
Singleton bound rate. To remedy for this weakness, DECA is endowed with an extra subroutine

called Max Diversity, as shown in Figure 6. Likewise the second step in the differential evolution
loop, this subroutine applies color permutations to a subset Bℵ1 of edges, |Bℵ1| = ℵ1, Bℵ1 ⊂ B∞,
and

B∞ = {e ∈ Ec : ρ(e) = ∞}.

(50)

C. Applications

Now, let us apply DECA to design two double-diversity product codes with MDS components.

Numerical values are selected to make these codes suitable to distributed storage applications

and to diversity systems in wireless networks. The parameter MaxIter is 100. DECA with its

hundred iterations runs in a small fraction of a second on a standard computer machine.

Example 7: The ﬁrst application of DECA is to color edges in the compact graph of CP 1 =
q , where n = 12, k = 10, d = 3, and the ﬁnite-ﬁeld alphabet size is q > 12. The coding
[n, k, d]⊗2
rate of CP 1 is R(CP 1) = 25/36 < 1 − 1/M = 3/4, i.e. the gap to (7) is 1/18. This small gap
is enough to render an uncomplicated double-diversity design. The coloring in Φ(Ec) can be

easily converted into its counterpart in Φ(E) by replacing each supersymbol with 4 symbols.
From (5) and (6), the total number of edge colorings is |Φ(E)| ≈ 1083 in the non-compact graph
and |Φ(Ec)| ≈ 1019 in the compact graph. The differential evolution parameter ℵ is set to 8.
The diversity subroutine is deactivated. We have

Λmax(8, 4) = 2520 ≪ |Φ(Ec)| ≪ |Φ(E)|.

For almost any choice of the initial coloring φ0 uniformly distributed in Φ(Ec), DECA yields a
double-diversity coloring φ1. For roughly one choice out of three for φ0, the algorithm outputs a

March 7, 2016

DRAFT

coloring φ1 such that η(φ1) ≥ 28. Figure 7a shows the matrix representation of a special φ1 found
by DECA. It has η(φ1) = 32 which corresponds to η = 128 in (V1, V2, E). The corresponding
rootcheck order matrix is shown in Figure 7b. The highest attained order for this coloring is

ρmax(φ) = 2. The maximal order for all colorings in Φ(Ec) from Theorem 1 is ρu = 5. This
coloring satisﬁes equality in (8) since 2ρmax(φ) + ηmin(φ) = 12.

52

G

G

B

G

Y

R

B

B

G

Y

B

R

Y

Y

B

R

G

G

R

G

R

B

Y

B

B

R

G

Y

R

R

B

G

Y

R

Y

Y

(a)

1r

2b

2b

1c

1r

1c

1c

1r

1c

1c

1r

1c

1r

1r

1c

1c

1r

1r

1r

1c

1r

1r

1c

1r

1c

1r

1c

1c

1r

1c

1c

1r

1c

2b

2b

1r

(b)

Figure 7: Compact coloring matrix (ﬁgure a) and the corresponding rootcheck-order matrix

(ﬁgure b) for the [12, 10]⊗2 product code CP 1 found by DECA, η(φ) = 32 and ρmax = 2.

Example 8: The second more challenging application of DECA is the design of a double-

diversity product code attaining the block-fading/block-erasure Singleton bound. Let us consider
CP 2 = [n1, k1, d1]q ⊗ [n2, k2, d2]q, where n1 = 14, k1 = 12, n2 = 16, k2 = 14, d1 = d2 = 3, and
the ﬁnite-ﬁeld alphabet size is q > 16. The coding rate is R(CP 2) = 1 − 1/M = 3/4. From (5)
and (6), the total number of edge colorings is |Φ(E)| ≈ 10131 in the non-compact graph and
|Φ(Ec)| ≈ 1031 in the compact graph. The differential evolution parameter ℵ is set to 7. The
diversity subroutine is activated with ℵ1 = 8. We have

Λmax(7, 4) + Λmax(8, 4) = 3150 ≪ |Φ(Ec)| ≪ |Φ(E)|.

The initial coloring φ0 is taken to be uniformly distributed in Φ(Ec). For almost three φ0 choices
out of four, DECA yields a double-diversity coloring φ1. Roughly one φ0 choice out of two

March 7, 2016

DRAFT

guarantees η(φ1) ≥ 34. Figure 8a shows the matrix representation of a special φ1 found by
DECA. It has η(φ1) = 40 which corresponds to η = 160 in (V1, V2, E). The rootcheck order
matrix is shown in Figure 8b. The highest attained order for this coloring is ρmax(φ) = 3. The
maximal order for all colorings in Φ(Ec) from Theorem 1 is ρu = 7. This coloring satisﬁes
2ρmax(φ) + ηmin(φ) = 16 while the right term in (8) is 17.

53

R

G

B

R

R

R

Y

R

R

R

Y

G

B

R

R

B

G

G

G

B

Y

G

G

B

Y

G

G

R

B

R

Y

B

G

B

B

R

Y

Y

Y

G

B

Y

R

G

B

Y

B

B

G

Y

G

B

Y

Y

Y

R

2c

1c

1c

1r

1r

1r

1c

3b

1c

2r

1r

1c

1c

1c

2r

1r

1r

1r

2c

2c

1c

1r

3r

1c

1c

3r

1r

1c

1r

1c

1c

1r

1c

2c

1r

1c

1r

2r

3b

1c

1c

2r

1c

2c

2r

1c

1r

3b

1r

1r

1c

1c

2c

1r

1r

1c

(a)

(b)

Figure 8: Compact coloring matrix (ﬁgure a) and the corresponding rootcheck-order matrix
(ﬁgure b) for the [14, 12]⊗ [16, 14] product code CP 2 found by DECA, η(φ) = 40 and ρmax = 3.

Example 9: A third example suitable for nowadays distributed storage warehouses is CP 3 =
[10, 8, 3]q ⊗ [10, 9, 2]q. The coding rate is R = 18/25 with a minimum distance d1d2 = 6 and
the locality is n1 = n2 = 10, i.e. this code is an improvement to the standard RS[14, 10]
used by Facebook [47]. The coloring ensembles have sizes |Φ(E)| ≈ 1057 and |Φ(Ec)| ≈
1027 respectively. The DECA algorithm produced double-diversity edge colorings where we
distinguish two classes: a ﬁrst class of colorings with ρmax = 3 and η(φ) = 41, and a second
class with ρmax = 2 and η(φ) = 40. An edge coloring of the second class is shown in Figure 9.
The reader is invited to determine the rootcheck order matrix and verify that 40 super-edges have

root order 1 and 10 super-edges have a root order equal to 2.

March 7, 2016

DRAFT

54

G

R

Y

G

B

Y

R

B

G

B

R

R

Y

G

B

B

Y

R

B

G

Y

G

R

G

B

B

Y

R

R

G

B

Y

R

G

Y

Y

B

R

G

R

Y

R

G

G

B

B

R

Y

Y

G

Figure 9: Compact coloring matrix for the [10, 8]⊗ [10, 9] product code found by DECA, η(φ) =
40 and ρmax = 2.

In ﬁgures of the previous examples, the four colors were also indicated by the ﬁrst letter of the

color name, Red, Green, Blue, and Yellow. The rootcheck order ρ(e) for an edge e in Ec (which

is also the order of the four code symbols associated to that edge) is indicated by an integer in

the right part of each ﬁgure for the ﬁrst two examples. In the rootcheck order matrix, 2r means

that this supersymbol has order 2 and its root checknode is a row. Similarly, 2c designates a

supersymbol with order 2 and a column rootcheck. The letter ’b’ is written when a supersymbol

has both rootchecks, a row and a column rootcheck.

Product codes in Examples 7-9 do not satisfy the ρu condition given in (15) and the sufﬁcient
condition of Lemma 5 either. An interesting question arises. Does an edge coloring with ρmax = 1
exist for a 6 × 6 compact graph? We provide a partial answer in the sequel. A similar answer
is valid for the 7 × 8 compact graph.

The 6×6 compact graph is perfectly balanced. Let us start with the ﬁrst color ’R’. The unique
solution to get ρ(e) = 1 for all edges e with φ(e) = R is to place ’R’ entries separately on the

ﬁrst row and the ﬁrst column. Hence, no row or a column contain the same color twice. The

ﬁrst 9 edges are located as follows:

March 7, 2016

DRAFT

55

(51)

.

R R R R R

R

R

R

R













G R R R R R

R

G G G G

R G

R G

R G

G

G R R R R B

R B G G G G

R G

B B B

R G B

R G B

B G B

R













We start over with the second color ’G’ using the same rule. Given the lack of space on the

second row and the second column, the ninth green edge is placed on the top left corner. We

get

.

(52)

At this point, 18 super-edges have a rootcheck order ρ = 1. Seven edges only can be colored

in blue, three edges on the third row, three edges on the third column, and one edge at the

intersection of the second row and the second column. One color ’R’ can be moved down to

the last row leading to the following coloring:

.

(53)

Finally, we reached an edge coloring where all edges of three colors satisfy ρ(e) = 1. Unfortu-

nately, there is no space left for edges of ’Y’ to achieve ρ(e) = 1. The situation is even worse,
the remaining edges for ’Y’ make ﬁve primitive stopping sets (three 2 × 2, one 2 × 3, and one
3 × 2). This edge coloring has no diversity.

March 7, 2016

DRAFT

56

D. Random edge coloring

The efﬁciency of the DECA algorithm was validated in the previous section in terms of number

of edges of ﬁrst order and the maximal order over all edges. Clearly, while evolving from one

coloring to another in order to get a large η(φ), DECA also produced a very small maximal
order ρmax(φ). Any deterministic construction seems to be destined to fail given the huge size
of the ensembles Φ(E) and Φ(Ec).

In this sub-section, another way to show the efﬁciency of our coloring algorithm is to make

random selections from Φ(E) and Φ(Ec) and get an estimate of the probability distributions
of η(φ) and ρmax(φ). Indeed, a uniformly distributed permutation in the symmetric group of
order N yields a uniformly distributed edge coloring φ in Φ(E). This is also true for Φ(Ec)

when the symmetric group has order N c. Thus, in a uniform manner, we selected 2 billion

edge colorings through our computer application from Φ(E) and Φ(Ec) respectively. For each

coloring, rootcheck orders of all edges were computed, i.e. for the N edges in the non-compact

graph and the N c edges in the compact graph. Only double-diversity colorings are counted in

this comparison, i.e. colorings with at least one edge of inﬁnite rootcheck order are excluded.

As an illustration, the characteristics of double-diversity random coloring for CP 1 are plotted in
Figure 10 where numerical estimations of all probability distributions are compared to colorings

designed via DECA.

Double diversity design is more arduous for the rate-3/4 CP 2 product code than for the rate-
25/36 CP 1 product code because of the rate-diversity tradeoff given by the Singleton bound.
For CP 1, the [12, 10]⊗2 code, 8.97% of uniformly sampled colorings have double diversity in
Φ(Ec), whereas this fraction is 43.6% in Φ(E). For CP 2, the [14, 12] ⊗ [16, 14] code, only
0.00039% of uniformly sampled colorings have double diversity in Φ(Ec), and we found no

double-diversity colorings in Φ(E) despite the 2 billion samples. As expected, compact graphs
exhibit better characteristics than non-compact graphs thanks to their simpler structure, i.e. ni−ki
parity symbols are grouped inside a unique supersymbol: for CP 1, one double-diversity random
coloring has η(φ) = 88, ρmax(φ) = 4 for non-compact graphs, seven double-diversity colorings
have η(φ) = 120, and ρmax(φ) = 2 for compact graphs. There exists a double-diversity coloring
in Φ(E) with ρmax(φ) = 3 but its η is 85. The estimated probability mass functions for CP 1

March 7, 2016

DRAFT

n
o
i
t
c
n
u
F
 
s
s
a
M
 
y
t
i
l
i

b
a
b
o
r
P

0.20

0.18

0.16

0.14

0.12

0.10

0.08

0.06

0.04

0.02

0.00

 20

Compact Graph

DECA, Example 6, eta=128

Non-Compact Graph

0.70

0.60

0.50

0.40

0.30

0.20

0.10

n
o
i
t
c
n
u
F
 
s
s
a
M
 
y
t
i
l
i

b
a
b
o
r
P

57

Compact Graph

DECA, Example 6
Max(rho)=2

Non-Compact Graph

 40

 60

 80

 100

 120

 140

Number of edges of order 1

0.00

 0

 2

 4
 8
Largest rootcheck order in a graph

 6

 10

 12

(a)

(b)

Figure 10: Distribution of η(φ) (ﬁgure a) and ρmax(φ) (ﬁgure b) for double-diversity random
edge colorings uniformly distributed in Φ(E) and Φ(Ec). Product code [12, 10]⊗2.

are plotted in Figures 10a and 10b. For CP 2, one double-diversity random coloring reached
η(φ) = 128 and ρmax(φ) = 4 out of the 2 billion samples from Φ(Ec). In all cases, for both η
and ρ, double-diversity random colorings are not as efﬁcient as colorings designed via the DECA

algorithm. The situation is worse for random colorings if a double-diversity code with maximal
rate 1 − 1/M is to be designed. The DECA algorithm exhibits excellent values, η = 160 and
ρ = 3, for the rate-3/4 [14, 12] ⊗ [16, 14] product code.

VI. CODE PERFORMANCE IN PRESENCE OF ERASURES

Iterative decoding performance of CP = C1 ⊗ C2 is studied in presence of channel erasures,
with and without edge coloring. The iterative decoder makes row and column iterations where
the component decoder of Ci can be an algebraic erasure-ﬁlling decoder (limited by di − 1) or a
maximum-likelihood decoder of Ci. As stated in Section IV-A, type II and type III stopping sets
are identical because the non-binary codes C1 and C2 are MDS. The word error probability of the
iterative decoder is denoted by P Gew. The product code can also be decoded via an ML decoder,
i.e. maximum likelihood decoding of CP based on a Gaussian reduction of its parity-check
matrix. The word error probability under ML decoding of CP is denoted by P M L
ew .

March 7, 2016

DRAFT

58

A. Block erasures

Consider the block-erasure channel CEC(q, ǫ). The N symbols of a codeword are partitioned
into M blocks, each block contains symbols associated to edges in G with the same color. The
CEC(q, ǫ) channel erases a block with a probability ǫ. The block is correctly received with
a probability 1 − ǫ. Erasure events are independent from one block to another. We say that a
color is erased if the associated block of N/M symbols is erased. Assume that G is endowed
with a double-diversity edge coloring φ (i.e. L(φ) = 2) as deﬁned in Corollary 1. Then, on the

block-erasure channel CEC(q, ǫ), for a rate satisfying

2
M

1 −

< R ≤ 1 −

1
M

,

we have

ǫ2 ≤ P M L

ew ≤ P Gew ≤

M

Xi=2 (cid:18)M

i (cid:19)ǫi(1 − ǫ)M−i.

(54)

(55)

Since φ has a double diversity, there exist two colors among the M colors such that the iterative
decoder must fail if both colors are erased. This explains the upper bound of P Gew in (55). The
upper bound is valid for any rate less than the maximal achievable rate for double diversity,
i.e. 1 − 1
M , the ML decoder for CP cannot attain a diversity L = 3
otherwise the block-fading/block-erasure Singleton bound would be violated. Consequently, the

M . Now, since R > 1 − 2

ML decoder of CP can only reach L = 2 and so there exists a pair of erased colors that cannot
be solved by the ML decoder. This explains the lower bound in (55). The reader can easily

verify that

log P M L
ew
log ǫ

lim
ǫ→0

= lim
ǫ→0

log P Gew
log ǫ

= L = 2.

(56)

The slope of Pew versus the erasure probability ǫ in a double-logarithmic scale is equal to 2.
Under the stated constraint on R, the upper bound in (55) is the exact expression of the outage

probability on a block-erasure channel valid for q-ary codes with asymptotic length [26]. For
double-diversity edge colorings found by DECA in Examples 7 and 8, P Gew equals its upper
bound in (55). These examples achieve the outage probability although a code may perform

better than the outage probability at ﬁnite length. For these colorings where M = 4, the error
probability on CEC(q, ǫ) behaves like P Gew = 6ǫ2 + O(ǫ3). One possible interpretation of this
behavior is: the optimization of η(φ) (equivalent in some sense to minimizing ρ(φ)) pushed the

performance of edge colorings found by the DECA algorithm as far as possible from the lower

March 7, 2016

DRAFT

59

bound ǫ2. As can be observed in Figures 7 and 8, all rows and all columns include the four

colors. When any two colors out of four are erased, the iterative decoder will completely fail

without correcting a single supersymbol. A double-diversity edge coloring guarantees that all

stopping sets are covered by at least two colors but it cannot cover all stopping sets with three
M . Fortunately, these product
colors or more otherwise we get L = 3 which contradicts R > 1− 2
codes are diversity-wise MDS and the second code in Example 8 has the maximal coding rate

for double diversity. In the sequel, we will see that these codes also perform well in presence

of independent erasures.

B. Independent erasures

Consider the i.i.d. erasure channel SEC(q, ǫ). The N symbols of a codeword are independently

erased by the channel. A symbol is erased with a probability ǫ and is correctly received with a
probability 1−ǫ. Edge coloring has no effect on the performance of CP on the SEC(q, ǫ) channel.
Before studying the performance on the SEC(q, ǫ), following Examples 3 & 4 and Theorems

2 & 3, we state an obvious result about obvious stopping sets in the following proposition.

Proposition 3: Let CP = C1 ⊗ C2 be a product code with non-binary MDS components. All

obvious stopping sets are supports of product code codewords.

Proof: Consider an ℓ1×ℓ2 obvious stopping set. Its rectangular support is R(S) = R1(S)×
R2(S). We have ℓ1 ≥ d1 and ℓ2 ≥ d2. From Proposition 2, there exists a column codeword
x = (x1, x2, . . . , xn1) ∈ C1 of weight ℓ1 with support R1(S)×{j1}, where j1 ∈ R2(S). Similarly,
there exists a row codeword y = (y1, y2, . . . , yn2) ∈ C2 of weight ℓ2 with support {i1}×R2(S),
where i1 ∈ R1(S). Now, the Kronecker product of x and y satisﬁes X (x ⊗ y) = S.

Corollary 5: Consider a product code CP = C1⊗C2 with non-binary MDS component codes.
Assume the symbols of CP are transmitted over a SEC(q, ǫ) channel. Then, for ǫ ≪ 1, the
error probabilities satisfy P Gew ∼ P M L
ew .

Proof: On the SEC(q, ǫ), the word error probabilities are given by [54],

N

P M L

ew =

Ψi(ML)ǫi(1 − ǫ)N−i,

(57)

Xi=d1d2

N

where Ψi(ML) is the number of weight-i erasure patterns covering a product code codeword,
and

March 7, 2016

P Gew =

Xi=d1d2

Ψi(G)ǫi(1 − ǫ)N−i,

(58)

DRAFT

60

where Ψi(G) is the number of weight-i erasure patterns covering a stopping set. Of course, here
we refer to stopping sets in the non-compact graph G, i.e. in the n1 × n2 product code matrix.
Next, since N is ﬁxed (asymptotic length analysis is not considered in this paper) we write
ew = Ψd1d2(ML)ǫd1 d2 + o(ǫd1d2) and P Gew = Ψd1d2(G)ǫd1d2 + o(ǫd1d2). From Proposition 3, we
P M L
get the equality Ψd1d2(G) = Ψd1d2(ML) and so we obtain limǫ→0 P Gew/P M L
The erasure patterns can be decomposed according to the size of the covered stopping set.
The coefﬁcient Ψi(G) becomes Ψi(G) = Pi
w=d1d2 Ψi,w(G), where Ψi,w(G) is the number of
weight-i patterns covering a stopping set of size w. It is clear that Ψw,w(G) = τw. For small
i − w, Ψi,w(G) can be approximated by PA(cid:0)N−Ai−w(cid:1)τw,A, where τw,A is the number of stopping
sets of size w having |R(S)| = A. For w ≤ d1d2 + d1 + d2 + 1, the area A is bounded from
above by the product ℓ0
2 from Lemma 1. Numerical evaluations of Ψi(G) are tractable for
very short codes (N ≤ 25) and become very difﬁcult for codes of moderate size and beyond,
e.g. N = 144 and N = 224 for the [12, 10]⊗2 and the [14, 12] ⊗ [16, 14] codes respectively. For
this reason, expressions (57) and (58) are not practical to predict the SEC(q, ǫ) performance of

ew = 1.

1 × ℓ0

product codes with signiﬁcant characteristics.

For P Gew, thanks to Theorems 2 and 3, a union bound can be easily established. Indeed, we

have

leading to

P Gew = P rob(∃S covered)

≤Xw

P rob(∃S : |S| = w,S covered),

N

From Theorem 2, the union bound P U (ǫ) for the [12, 10, 3]⊗2

q product code is

P Gew ≤ P U (ǫ) =

Xw=d1d2

τwǫw.

(59)

P U (ǫ) =48400ǫ9 + 6098400ǫ12 + 23522400ǫ13 + 17641800ǫ14

+ 1754335440ǫ15 + 9126691200ǫ16 + o(ǫ16).

The performance of this code on the SEC(q, ǫ) channel is shown in Figure 11. We used the
standard ﬁnite ﬁeld of size q = 256. The union bound for the symbol error probability P Ges
N τwǫw.

is derived by weighting the summation term in (59) with w/N, i.e. P Ges ≤ PN

w=d1d2

w

March 7, 2016

DRAFT

100

10-1

10-2

10-3

10-4

10-5

10-6

i

g
n
d
o
c
e
D

 
r
e

t
f

a

 
r
o
r
r

E

 
f

o

 
y
t
i
l
i

b
a
b
o
r
P

10-7

0.05

61

Pew, Iterative alg. decoding
Pes, Iterative alg. decoding
Pew, ML decoding
Pes, ML decoding
Union bound on Pew (iterative)
Union bound on Pes (iterative)

0.10

0.15

0.20

0.25

0.30

0.35

Channel Erasure Probability

Figure 11: Product code [12, 10]⊗2
for iterative decoding versus its union bound and ML decoding.

q , no edge coloring. Word and symbol error rate performance

As observed in the plot of Figure 11, the union bound is sufﬁciently tight. Furthermore, the

performance of the iterative algebraic row-column decoder is very close to that of ML decoding

in the whole range of ǫ. For small ǫ, the curves are superimposed as predicted by Corollary 5.

The union bound P U (ǫ) for the [14, 12, 3]q ⊗ [16, 14, 3]q product code is

P U (ǫ) =203840ǫ9 + 44946720ǫ12 + 174894720ǫ13 + 131171040ǫ14

+ 17839261440ǫ15 + 126887941180ǫ16 + o(ǫ16).

The performance of this code on the SEC(q, ǫ) channel is shown in Figure 12. Similar to the

previous code, the union bound is tight enough and iterative decoding performs very close to ML

decoding. Finally, let us interpret these results from a ﬁnite-length information theoretical point

March 7, 2016

DRAFT

62

i

g
n
d
o
c
e
D

 
r
e

t
f

a

 
r
o
r
r

E

 
f

o

 
y
t
i
l
i

b
a
b
o
r
P

100

10-1

10-2

10-3

10-4

10-5

10-6

10-7

Pew, Iterative alg. decoding
Pes, Iterative alg. decoding
Pew, ML decoding
Pes, ML decoding
Union bound on Pew (iterative)
Union bound on Pes (iterative)

0.05

0.10

0.15

0.20
Channel Erasure Probability

0.25

0.30

Figure 12: Product code [14, 12]q ⊗ [16, 14]q, no edge coloring. Word and symbol error rate
performance for iterative decoding versus its union bound and ML decoding.

of view [44]. The SEC(q, ǫ) of Shannon capacity log2(q)(1− ǫ) behaves exactly like a BEC(ǫ)
of capacity (1− ǫ) but erasures in the SEC occur at the symbol level instead of the binary digit
level. Finite-regime BEC bounds from [44] are directly applicable to our product codes over
the SEC(q, ǫ). The BEC channel dispersion is V = ǫ(1 − ǫ) and its maximal achievable rate is
given by [44], Theorem 53,

R = (1 − ǫ) −rV

n

Q−1(Pew) + O(

1
n

),

(60)

where n is the code length, Q(x) is the Gaussian tail function, ǫ is the channel erasure probability,
and Pew is the target word error probability. The next table shows how good is the proposed
product code based on MDS components.

March 7, 2016

DRAFT

63

Coding Rate R

Erasure Prob. ǫ

for ǫ = 0.15

for R = 0.75

Polyanskiy-Poor-Verd´u

0.794 : Pew = 1.0 · 10−2

[14, 12]q ⊗ [16, 14]q

0.750 : Pew = 1.0 · 10−2

Regular-(3, 12) LDPC

0.750 : Pew = 2.9 · 10−2

0.189

0.150

0.135

Table III: Finite-length performance of the [14, 12]q ⊗ [16, 14]q product code. The value of ǫ in
the third column is given for Pew = 10−2 at all rows.

C. Unequal probability erasures

In communication and storage systems, erasure events of unequal probabilities may occur.

In order to observe the effect of a double-diversity coloring on the performance in multiple
erasure channels, we deﬁne the SEC(q,{ǫi}M
i=1). On this channel, symbol erasure events are
independent but the probability of erasing a symbol is ǫi if it is associated to an edge in G with
color φ(e) = i. The union bound is easily modiﬁed to get

where

P Gew ≤ P U (ǫ1, . . . , ǫM ),

P U (ǫ1, . . . , ǫM ) =

N

Xw=d1d2 Xw1, . . . , wM

τ (w1, . . . , wM )

ǫwi
i

.

M

Yi=1

: Pi wi = w

(61)

(62)

The coefﬁcient τ (w1, . . . , wM ) is the number of stopping sets of size w = PM
i=1 wi, where
i symbol edges have color i, i = 1 . . . M. Clearly, the coefﬁcients τ (w1, . . . , wM ) depend on
the edge coloring φ. For double-diversity colorings and M ≥ 2, these coefﬁcients satisfy the
following property:
For any stopping set S such that |S| = w, τ (w1, . . . , wM ) does exist for PM

wi > 0 only, i.e. no weak compositions of w are authorized by φ.
Hence, the product code should perform well if one of the ǫi is close to 1 and the remaining ǫi are
small enough. The extreme case is true thanks to double diversity yielding P U (0M−1, 11) = 0,
where (0M−1, 11) represents all vectors with all positions at 0 except for one position set to 1.
i=1) channel with M = 4
Figure 13 shows the performance of [12, 10]⊗2

i=1 wi = w and

q

on the SEC(q,{ǫi}M

March 7, 2016

DRAFT

64

epsilon1=0.002 (Union Bound)
epsilon1=0.010 (Union Bound)
epsilon1=0.050 (Union Bound)
epsilon1=0.050 (Monte Carlo )
epsilon1=0.100 (Union Bound)
No Coloring

100

10-1

10-2

10-3

10-4

10-5

10-6

y
t
i
l
i

b
a
b
o
r
P

 
r
o
r
r

 

E
d
r
o
W

10-7

0.00

0.05

0.10

0.15

0.20

0.25

0.30

0.35

0.40

0.45

0.50

Channel Erasure Probability (epsilon4)

Figure 13: Product code [12, 10]⊗2
performance versus ǫ4, for iterative decoding on the SEC(q,{ǫi}4

q with double-diversity edge coloring. Word error rate
i=1) channel with ǫ1 = ǫ2 = ǫ3.

colors. The edge coloring is the double-diversity coloring produced by the DECA algorithm and

drawn in Figure 7. The expression of P U (ǫ1, . . . , ǫM ) is determined by stopping sets enumeration
as in Theorems 2 and 3. Details are omitted and the very long expression of P U (ǫ1, . . . , ǫM )
is not shown. The special case ǫ1 = ǫ2 = ǫ3 is considered and the performance is plotted as
a function of ǫ4. For a ﬁxed ǫ1, double diversity dramatically improves the performance with
respect to ǫ4.

VII. CONCLUSIONS

Non-binary product codes with MDS components are studied in this paper in the context of

iterative row-column algebraic decoding. Channels with both independent and block erasures are

considered. The rootcheck concept and associated double-diversity edge colorings were described

March 7, 2016

DRAFT

65

after introducing a compact graph representation for product codes. For solving erased symbols,

an upper bound of the number of decoding iterations is given as a function of the graph size

and the color palette size M. Stopping sets are deﬁned in the context of MDS components

and a relationship is established with the graph representation of the product code. A full

characterization of these stopping sets is given up to a weight (d1+1)(d2+1). Then, we proposed
a differential evolution edge coloring algorithm to design colorings with a large population of

minimal rootcheck order symbols. The complexity of this algorithm per iteration is o(Mℵ),
where ℵ is the differential evolution parameter. The performance of MDS-based product codes
with and without double-diversity coloring is analyzed. In addition, ML and iterative decoding

are proven to coincide at small channel erasure probability. Original results found in this paper

are listed in Section I-B.

A complete enumeration of product code codewords is still an open problem in coding theory.

Following the enumeration of bipartite graphs in Section IV-D (see also Table I) and following

the DECA algorithm that aims at improving η(φ) in Section V-B, two open problems can be

stated.
• In number theory. There exists no recursive or closed form expression for the special partition
function, i.e. the number of special partitions of an integer. Also, in a way similar to the Hardy-

Ramanujan formula, the asymptotic behavior is unknown for the number of special partitions.

Special partitions are introduced in Deﬁnition 10.
• In graph theory and combinatorics. Consider a matrix of size H × W and a coloring palette
of size M. For simplicity, assume that H · W is multiple of M. A matrix entry is called edge. A
color is assigned to each edge in the matrix. All M colors are equally used. A matrix edge/entry

(i, j) of color c is said to be good if it is the unique entry with color c either on row i or on

column j. The number of good entries is denoted by η(φ), see also (43). Given the matrix height

H, width W , and the palette size M, ﬁnd the maximum achievable number of good entries η(φ)

over the set of all edge colorings φ. A simpler problem would be to ﬁnd an upper bound of

η(φ).

March 7, 2016

DRAFT

APPENDIX A

PROOF OF THEOREM 3

66

Of course, C1 and C2 are interchangeable which explains why we stated the theorem for
d1 < d2. From Lemma 1, the maximal rectangle height satisﬁes ℓ0
1 ≤ (d1 + 2). Similarly, under
the condition d2 < 3d1 − 1, the maximal rectangle width satisﬁes ℓ0
2 ≤ (d2 + 3). From d1 × d2
up to the maximal size (d1 + 2) × (d2 + 3), there are twelve different sizes listed in Figure 14.
The most right column tells us when sizes located on the same row are equal. Also, the ﬁrst

entries on rows 4 and 5 are equal if d2 = d1 + 1. For these rectangular supports, the stopping set
weight w takes values from rows 1-4 (and the ranges between these values) in the table drawn
in Figure 14, i.e. d1d2 ≤ w ≤ (d1 + 1)(d2 + 1).

d1d2

d1(d2 + 1)

(d1 + 1)d2

d1(d2 + 2)

d2 = 2d1

(d1 + 1)(d2 + 1)

d1(d2 + 3)

(d1 + 2)d2

(d1 + 1)(d2 + 2)

d2 = 2d1 − 1

d2 = 2d1 + 2

(d1 + 2)(d2 + 1)

(d1 + 1)(d2 + 3)

d2 = 2d1 + 1

(d1 + 2)(d2 + 2)

(d1 + 2)(d2 + 3)

Figure 14: Size of the rectangular support R(S) given in the three left columns. The twelve
different sizes are listed in increasing order within each column. The right column of this table

indicates when sizes on the same row are equal.

March 7, 2016

DRAFT

The proof shall consider d2 > 2d1 in its sub-section C. There exists no integer d2 in the range
]2d1, 3d1 − 1[ for d1 = 2. Only for sub-section C and d1 = 2, we consider a rectangular support
with a width up to d2 + 4 which enlarges the range of d2 to 2d1 < d2 < 4d1 − 1 and permits to
keep the case d1 = 2 valid in sub-section C.

67

• The case w < d1d2.

The proof is similar to w < d2 in Theorem 2. Here, we just deduce that w ≥ d1ℓ2 and
w ≥ d1ℓ2 leading to the contradiction w ≥ d1d2. Therefore τw = 0 for w < d1d2 under type
II iterative decoding.

• The case w = d1d2.

We use similar inequalities as in the previous case which resembles the proof in Theorem 2
for w = d2. We get that R(S) = S. All stopping set of size d1d2 are obvious. Their number
is given by choosing d1 rows out of n1 and d2 columns out of n2.

• The case d1d2 < w < d1(d2 + 1).

Given that ℓ1ℓ2 ≥ w > d1d2, we get ℓ1 ≥ d1 and ℓ2 ≥ d2, since d1 × d2 is the smallest
R(S). Take ℓ1 = d1, then ℓ2 ≥ d2 + 1 because w > d1d2. The weight of each column must
be at least d1 giving us w ≥ d1ℓ2 ≥ d1(d2 + 1), which is a contradiction unless τw = 0.
The same arguments hold for ℓ1 > d1.

• The case w = d1(d2 + 1).

The admissible rectangular support can have all sizes ℓ1 × ℓ2 listed in Figure 14 starting
from d1 × (d2 + 1).
– The smallest R(S) is d1 × (d2 + 1). All corresponding stopping sets are obvious. Their

number is

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 1(cid:19).

– The next R(S) has size (d1 + 1)× d2. The number of zeros is β = (d1 + 1)d2− d1(d2 +
1) = d2 − d1 > 0. This result contradicts Lemma 2 where β = 0. Hence, this size of
the rectangular support yields no stopping sets, τw = 0 in this sub-case.

– The next R(S) has size d1 × (d2 + 2). Again, Lemma 2 on the existence of a stopping

set tells us that β = 0, but β = d1(d2 + 2) − d1(d2 + 1) = d1 > 0. Then τw = 0.

March 7, 2016

DRAFT

68

– All rectangle sizes from rows 4−8 in the table in Figure 14 are larger than the previous

case and make a contradiction on β unless τw = 0.

Starting from this point, d2 should be compared to 2d1 in order to sort the values of the stopping
set size as given in the table in Figure 14.

A. Minimum distances satisfying d2 < 2d1

• The case d1(d2 + 1) < w < (d1 + 1)d2.

The smallest R(S) has size (d1 + 1) × d2 and the largest has size (d1 + 2) × (d2 + 3). All
these stopping sets contradict Lemma 2 if β is computed from the size of R(S) and w.
Then τw = 0.

• The case w = (d1 + 1)d2.

– R(S) has size (d1 + 1) × d2. Stopping sets are obvious and their number is

d2(cid:19).
d1 + 1(cid:19)(cid:18)n2
(cid:18) n1

– R(S) has size d1 × (d2 + 2). Lemma 2 gives β = 0 but β = d1(d2 + 2) − (d1 + 1)d2 =

2d1 − d2 ≥ 1. Then τw = 0 in this sub-case.

– R(S) has size (d1 + 1) × (d2 + 1). We have β = d1 + 1 and d2 − d1 columns have no
0. The β zeros should be in a (d1 + 1) × (d1 + 1) permutation matrix in the remaining
β columns. These stopping sets are not obvious and their number is

(d1 + 1)!(cid:18) d2 + 1

d2 − d1(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– All other R(S) greater than the previous case have τw = 0 because of a contradiction

on β.

• The case (d1 + 1)d2 < w < d1(d2 + 2).

Let us write w = (d1 + 1)d2 + λ, where λ belongs to [1, 2d1 − d2 − 1]. If d2 = 2d1 − 1 this
range for λ is empty and we obtain τw = 0. Then, we consider d2 < 2d1 − 1.
– R(S) has size d1 × (d2 + 2). The number of zeros is β = d1(d2 + 2) − w > 0 which

contradicts Lemma 2. There are no stopping sets for this rectangular size.

– R(S) has size (d1 + 1) × (d2 + 1). We have β = d1 + 1 − λ ∈ [d2 − d1 + 2, d1].
The non-obvious stopping sets are built by selecting β columns and β rows and then

March 7, 2016

DRAFT

embedding any 0-permutation matrix, their number is

69

(d1 + 1 − λ)!(cid:18)d1 + 1

λ (cid:19)(cid:18) d2 + 1

d1 + 1 − λ(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– All other R(S) greater than the previous case have τw = 0 because of a contradiction

on β.

• The case w = d1(d2 + 2).

– For R(S) with size d1(d2 + 2), we the following number of obvious stopping sets

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 2(cid:19).

– The next size for R(S) to be considered is (d1 + 1) × (d2 + 1). The number of zeros
is β = d2 − d1 + 1. As usual, these non-obvious stopping sets are constructed by a
0-permutation matrix of size β inside R(S). Their number is
d2 − d1 + 1(cid:19)(cid:18) n1

d2 − d1 + 1(cid:19)(cid:18) d2 + 1

(d2 − d1 + 1)!(cid:18) d1 + 1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– Both d1 × (d2 + 3) and (d1 + 2)× d2 lead to a contradiction on β. Now we consider the
rectangle of size (d1+1)×(d2+2). The number of zeros is β = d2+2. All columns must
have a single 0. Regarding the rows, let r0, r1, and r2 be the number of rows with 0, 1,
and 2 zeros respectively. We have r0 + r1 + r2 = d1 + 1 and β = 2r2 + r1. Combining
the two previous equalities yields 2r0 + r1 = 2d1 − d2. Many similar cases where
encountered in the proof of Theorem 2. The number of these non-obvious stopping

sets becomes

r0 (cid:19)(cid:18)d1 + 1 − r0
• The case d1(d2 + 2) < w < (d1 + 1)(d2 + 1).

X2r0+r1=2d1−d2(cid:18)d1 + 1

r1

2r0+d2−d1+1(cid:18) n1
(cid:19) (d2 + 2)!

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

Let us write w = d1(d2 + 2) + λ, where λ belongs to the interval [1, d2 − d1].
– The smallest rectangle has size (d1 + 1)(d2 + 1). The number of zeros is β = d2 −
d1 + 1 − λ ∈ [1, d2 − d1]. The number of these non-obvious stopping sets is found by
counting all β × β permutation matrices in all positions,
2d1 − d2 + λ(cid:19)(cid:18)d2 + 1

(d2 − d1 + 1 − λ)!(cid:18) d1 + 1

d1 + λ(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– The next R(S) has size (d1 + 1)(d2 + 2) according to the table in Figure 14, since
both sizes d1(d2 + 3) and (d1 + 2)d2 lead to a contradiction on β. The number of

March 7, 2016

DRAFT

70

zeros for this rectangular support is β = d2 + 2 − λ ∈ [d1 + 2, d2 + 1]. The (d2 + 2)
columns satisfy: λ columns have no zero and β columns have a unique zero. As usual,
we solve β = 2r2 + r1 and r0 + r1 + r2 = d1 + 1 to get 2r0 + r1 = 2d1 − d2 + λ and
r2 = r0 + λ − d1 − 1. The number of non-obvious stopping sets in this case is
d2 + 2(cid:19).

r0 (cid:19)(cid:18)d1 + 1 − r0

d1 + 1(cid:19)(cid:18) n2

(cid:19)(d2 + 2)!

2r2λ! (cid:18) n1

X2r0+r1=2d1−d2+λ(cid:18)d1 + 1

r1

– Rectangular supports larger than (d1 + 1)(d2 + 2) do not correspond to stopping sets

for the given range of w, i.e. τw = 0.

• The last case w = (d1 + 1)(d2 + 1) ≤ d1(d2 + 3).

– The number of obvious stopping sets for the smallest R(S) is

d1 + 1(cid:19)(cid:18) n2
(cid:18) n1

d2 + 1(cid:19).

If d2 = 2d1 − 1 then (d1 + 1)(d2 + 1) = d1(d2 + 3) and corresponds to the following
obvious stopping sets

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 3(cid:19).

Similarly, if d2 = d1 + 1 then (d1 + 1)(d2 + 1) = (d1 + 2)d2 and corresponds to the
obvious stopping sets with number

d2(cid:19).
d1 + 2(cid:19)(cid:18)n2
(cid:18) n1

Notice that d1 × (d2 + 3) and (d1 + 2) × d2 have no non-obvious stopping sets (from
Lemma 2).

– The next R(S) is (d1 + 1)(d2 + 2). The corresponding number of zeros is β = d1 + 1.
Similar cases were encountered before. The number of these non-obvious stopping sets

is

X2r0+r1=d1+1(cid:18)d1 + 1

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

(cid:19)

(d2 + 2)!

2r0(d2 − d1 + 1)!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– Consider R(S) with size (d1 + 2)(d2 + 1). We have β = d2 + 1. If d2 > d1 + 1, then
we ﬁnd τw = 0 by contradicting arguments on β. But if d2 = d1 + 1, the number of
non-obvious stopping sets becomes

X2r0+r1=d2+1(cid:18)d2 + 1

r0 (cid:19)(cid:18)d2 + 1 − r0

r1

(cid:19)(d1 + 2)!

2r0 (cid:18) n1

d1 + 2(cid:19)(cid:18) n2

d2 + 1(cid:19).

March 7, 2016

DRAFT

71

r0 (cid:19)(cid:18)d1 + 1 − r0

– Consider R(S) with size (d1 + 1)(d2 + 3). We have β = 2(d1 + 1). If d2 < 2d1 − 1
there are no stopping sets. When d2 = 2d1 − 1, we get β = 2(d1 + 1) = d2 + 3. The
number of non-obvious stopping sets is found to be (method as in previous cases)
X3r0+2r1+r2=d1+1(cid:18)d1 + 1
r1
where r3 = d1 + 1 − r0 − r1 − r2.
– Consider the next R(S) with size (d1 + 2)(d2 + 2) as given in the table in Figure 14.
We have β = d1 + d2 + 3. No stopping sets are found (by contradiction on β) except
for d2 = d1 + 1. In this case, we get β = 2(d1 + 2). The rectangle has two zeros in
each row. This problem is solved in a similar method as in the proofs of Lemma 3 and

(cid:19)(cid:18)d1 + 1 − r0 − r1

(cid:19)(d2 + 3)!
2r26r3 (cid:18) n1

r2

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19),

Lemma 4. Indeed, we have to enumerate bipartite graphs with d1 + 2 left vertices all of
degree 2. These graphs have d1 + 3 right vertices. Two cases should be distinguished:
a- The extra vertex on the right has no edges, b- The extra vertex at the right has one

edge. The number of these stopping sets is

(cid:18)(d2 + 2)xd1+2 +

(d2 + 2)yd1+2

2

(cid:19)(cid:18) n1

d1 + 2(cid:19)(cid:18) n2

d2 + 2(cid:19),

where xd1+2 and yd1+2 are determined from Lemma 3 and Lemma 4.

– The largest rectangular support for w = (d1 +1)(d2 +1) is (d1 +2)(d2 +3). The number
of zeros is β = d2 +2d1 +5. From Lemma 2 we get that β must be less than or equal to
both 2(d2 + 3) and 3(d1 + 2). The ﬁrst condition is satisﬁed if d2 = d1 + 1 and d1 = 2,
also the second condition is satisﬁed if d2 = 2d1 − 1 and d1 = 2. Consequently, for
this w and this size of R(S), non-obvious stopping sets exist only for d1 = 2, d2 = 3,
and β = 12 in a rectangle of size 4 × 6. Their number is
d2 + 3(cid:19).

d1 + 2(cid:19)(cid:18) n2

1860(cid:18) n1

B. Minimum distances satisfying d2 = 2d1

• The case d1(d2 + 1) < w < (d1 + 1)d2 = d1(d2 + 2).

Write w = d1(d2 + 1) + λ, where λ is in the range [1, d1 − 1]. For all sizes of R(S) in the
table in Figure 14, we ﬁnd β = ℓ1ℓ2 − w and we notice that it contradicts Lemma 2. Thus,
there are no stopping sets for w in the range ]d1(d2 + 1), (d1 + 1)d2[.

March 7, 2016

DRAFT

• The case w = (d1 + 1)d2 = d1(d2 + 2).

– Obvious stopping sets do exist and their number is

72

d1 + 1(cid:19)(cid:18)n2
(cid:18) n1

d2(cid:19) +(cid:18)n1

d1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– For rectangles larger than (d1 + 1) × d2 and d1 × (d2 + 2), all sizes yield no stopping
sets (by contradiction on β) except for (d1 + 1) × (d2 + 1) and (d1 + 1) × (d2 + 2)
where the number of non-obvious stopping sets is respectively

and

d1 + 1(cid:19)(cid:18) n1

(d1 + 1)!(cid:18)d2 + 1
2d1+1 (cid:18) n1

(d2 + 2)!

d1 + 1(cid:19)(cid:18) n2
d2 + 2(cid:19).

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19),

• The case (d1 + 1)d2 = d1(d2 + 2) < w < d1(d2 + 3).

Write w = (d1 + 1)d2 + λ, where λ is in the range [1, d1 − 1].
– The smallest rectangular support with a non-zero number of stopping sets is (d1 +
1) × (d2 + 1). We have β = d1 + 1 − λ belonging to the range [2, d1]. The number of
corresponding non-obvious stopping sets is

(d1 + 1 − λ)!(cid:18)d1 + 1

λ (cid:19)(cid:18)d2 + 1

d1 + λ(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– For R(S) with size (d1 + 1) × (d2 + 2), we have β = d2 + 2 − λ varying in the range
[d1+3, d2+1]. The rectangle have λ columns without zeros. Given r2 = d1+1−r0−r1 =
d1 + 1 + r0 − λ, the number of non-obvious stopping sets is
2r2λ! (cid:18) n1

r0 (cid:19)(cid:18)d1 + 1 − r0

d1 + 1(cid:19)(cid:18) n2

(cid:19)(d2 + 2)!

d2 + 2(cid:19).

X2r0+r1=λ(cid:18)d1 + 1

r1

Larger rectangles R(S) lead to a contradiction on β, so they do not create stopping
sets for this given weight w.

• The case w = d1(d2 + 3).

Obvious stopping sets are given by

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 3(cid:19).

March 7, 2016

DRAFT

– Take R(S) with size (d1 + 1)(d2 + 1). Then β = 1 (recall that d2 = 2d1 in this
sub-section). The number of non-obvious stopping sets with a unique zero in their

rectangular support is

73

(d1 + 1)(d2 + 1)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– Take R(S) with size (d1 + 1)(d2 + 2). Then β = d1 + 2. The number of stopping sets

is given by (VII) after setting λ = d1.

– Take R(S) with size (d1 + 1)(d2 + 3). Then β = d2 + 3. In R(S), all columns have
a unique zero. Deﬁne r3 = d1 + 1 − r0 − r1 − r2 = 2r0 + r1 + 1, then the number of
non-obvious stopping sets in this sub-case becomes
d2 + 3(cid:19)
X3r0+2r1+r2=d1(cid:18)d1 + 1

(cid:19)(cid:18)d1 + 1 − r0 − r1

r0 (cid:19)(cid:18)d1 + 1 − r0

2r26r3 (cid:18) n1
(cid:19)(d2 + 3)!

d1 + 1(cid:19)(cid:18) n2

r1

r2

All remaining rectangle sizes (smaller or larger) have no stopping sets.

• For d2 = 2d1 the range ]d1(d2 + 3), (d1 + 1)(d2 + 1)[ is empty. We complete this sub-section

with the last case w = (d1 + 1)(d2 + 1).
– The number of obvious stopping sets for the smallest R(S) is

d2 + 1(cid:19).
The size (d1 + 2) × d2 rectangle has no stopping sets.

d1 + 1(cid:19)(cid:18) n2
(cid:18) n1

– The next R(S) is (d1+1)(d2+2). The corresponding number of zeros is β = d1+1. The
number of non-obvious stopping sets is (expression identical to the case d2 ≤ 2d1 − 1):

X2r0+r1=d1+1(cid:18)d1 + 1

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

(cid:19) (d2 + 2)!
2r0(d1 + 1)!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– Consider R(S) with size (d1 + 2)(d2 + 1). We have β = d2 + 1. For d2 = 2d1 this β

contradicts the upper bound in Lemma 2. Then τw = 0.

– Consider R(S) with size (d1 + 1)(d2 + 3). We have β = 2(d1 + 1) = d2 + 2. In R(S),
all columns must have at most one zero but rows can afford up to three zeros. The

number of non-obvious stopping sets is found to be (method as in previous cases)

r0 (cid:19)(cid:18)d1 + 1 − r0

X3r0+2r1+r2=d1+1(cid:18)d1 + 1
d2 + 3(cid:19).
– Consider the next supports R(S) with size (d1 + 2)(d2 + 2) and (d1 + 2)(d2 + 3) as
given in the table in Figure 14. The β for both sizes contradicts the upper bound in
Lemma 2. We deduce that τw = 0 in these cases.

(cid:19)(cid:18)d1 + 1 − r0 − r1

(cid:19) (d2 + 3)!
2r262r0+r1(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

r1

r2

March 7, 2016

DRAFT

C. Minimum distances satisfying d2 > 2d1

For 2 < d1 < d2 < 3d1 − 1, the width of R(S) cannot exceed d2 + 3. In the special case
d1 = 2, as stated earlier, a width up to d2 + 4 should be considered. Then, for d1 = 2, the
rectangular supports are ordered in increasing size according to Table IV. The ﬁrst and second

rows list the stopping set weight w in increasing order.

74

d1d2 < d1(d2 + 1) < d1(d2 + 2) < (d1 + 1)d2

< d1(d2 + 3) < d1(d2 + 4) ≤ (d1 + 1)(d2 + 1)

< (d1 + 2)d2 ≤ (d1 + 1)(d2 + 2) < (d1 + 1)(d2 + 3)

≤ (d1 + 2)(d2 + 1) < (d1 + 1)(d2 + 4) < (d1 + 2)(d2 + 2)

< (d1 + 2)(d2 + 3) < (d1 + 2)(d2 + 4)

Table IV: Table of rectangular sizes for the special case where the ﬁrst component code has

d1 = 2.

• The case d1(d2 + 1) < w < d1(d2 + 2) < (d1 + 1)d2.

Write w = d1(d2 + 1) + λ, where λ is in the range [1, d1 − 1]. For all sizes of R(S) in the
table in Figure 14, we ﬁnd β = ℓ1ℓ2 − w and we notice that it contradicts Lemma 2. There
are no stopping sets for w in the range ]d1(d2 + 1), d1(d2 + 2)[.

• The case w = d1(d2 + 2).

– Obvious stopping sets do exist and their number is

– For rectangles larger than d1(d2 + 2) we found no other stopping sets, by contradiction

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 2(cid:19).

on β.

• The case d1(d2 + 2) < w < (d1 + 1)d2.

Write w = d1(d2 + 2) + λ, where λ is in the range [1, d2 − 2d1 − 1]. For all rectangular
supports, from β we deduce that τw = 0.

March 7, 2016

DRAFT

• The case w = (d1 + 1)d2.

Obvious stopping sets are given by

75

d2(cid:19).
d1 + 1(cid:19)(cid:18)n2
(cid:18) n1

– Take R(S) with size (d1 + 1)(d2 + 1). Then β = d1 + 1. The number of non-obvious

stopping sets for this sub-case is

(d1 + 1)!(cid:18)d2 + 1

d1 + 1(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– Take R(S) with size (d1 + 1)(d2 + 2). Then β = 2d1 + 2. All rows have two zeros.
Also, d2 − 2d1 columns have no zeros, while the remaining columns include a unique
zero. The number of non-obvious stopping sets in this sub-case is

(d2 + 2)!

2d1+1(d2 − 2d1)!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– Take R(S) with size (d1 + 1)(d2 + 3). From Lemma 2 we ﬁnd that no stopping sets
exist, except for d1 = 2 and d2 = 6. In this case, β = 3d1 + 3 = 9. Each row in the
63 = 1680 for d1 = 2
rectangle have three zeros. The number of stopping sets is τw = 9!
and d2 = 6.

– Take R(S) with size (d1 + 2)(d2 + 1). Then β = d2 + d1 + 2. The reader can easily
check that the bound in Lemma 2 is not satisﬁed. We deduce that τw = 0 for this
rectangle size and this weight w. All remaining rectangle sizes have no stopping sets.

• The case (d1 + 1)d2 < w < d1(d2 + 3).

τw = 0 for d1 = 2. We pursue this case for d1 > 2.
Write w = (d1 + 1)d2 + λ where λ belongs to the non-empty interval [1, 3d1 − d2 − 1].
– The next rectangular support with a non-zero number of stopping sets is (d1+1)(d2+1).
The number of zeros is β = d1 + 1 − λ varying in the range [d2 − 2d1 + 2, d1]. Non-
obvious stopping sets are enumerated by selecting the location and permuting the β
zeros inside R(S). Their number is
(d1 + 1 − λ)!(cid:18) d2 + 1

d1 + 1 − λ(cid:19)(cid:18)d1 + 1

d1 + 1(cid:19)(cid:18) n2

λ (cid:19)(cid:18) n1

d2 + 1(cid:19).

– Take R(S) with size (d1 + 1)(d2 + 2). We have β = 2d1 + 2 − λ inside the interval
[d2 − d1 + 3, 2d1 + 1]. As made before, we ﬁnd 2r0 + r1 = λ and r2 = d1 + 1 + r0 − λ.

March 7, 2016

DRAFT

The columns in R(S) have at most one zero and rows have at most two zeros. The
number of these non-obvious stopping sets is

76

X2r0+r1=λ(cid:18)d1 + 1

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

(cid:19)

(d2 + 2)!

2r2(d2 − 2d1 + λ)!(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– Consider R(S) with size (d1+2)(d2+1). Here β = d2 +d1+2−λ contradicts Lemma 2
because d2 > 2d1. We have τw = 0. All remaining rectangles (smaller or larger) have
no stopping sets.

• The case w = d1(d2 + 3).

– The number of obvious stopping sets in a d1 × (d2 + 3) rectangular support is

d1(cid:19)(cid:18) n2
(cid:18)n1

d2 + 3(cid:19).

– Consider R(S) with size (d1 + 1)(d2 + 1). Here β = d2 − 2d1 + 1 is restricted to the
interval ]1, d1[ given the constraints 2d1 < d2 < 3d1 − 1 for d1 > 2. For d1 = 2, d2 = 6
is the only valid value, with β = 3. The number of non-obvious stopping sets is (for
d1 ≥ 2)

β!(cid:18) d1 + 1

3d1 − d2(cid:19)(cid:18)d2 + 1

2d1 (cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– Consider R(S) with size (d1 + 1)(d2 + 2). The number of zeros is β = d2 − d1 + 2 ∈

]d1 + 2, 2d1 + 1[. The number of non-obvious stopping sets is given by

X2r0+r1=3d1−d2(cid:18)d1 + 1

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

(cid:19) (d2 + 2)!
2r2d1! (cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19),

where r2 = d2 − 2d1 + 1 + r0. For d2 = 2, the above expression is valid for d2 = 6 only.
– Consider R(S) with size (d1 +1)(d2 +3). Here β = d2 +3. All columns in the rectangle
have one zero. Rows can have up to three zeros. The number of non-obvious stopping

sets is

r0 (cid:19)(cid:18)d1 + 1 − r0

d1 + 1(cid:19)(cid:18) n2
X3r0+2r1+r2=3d1−d2(cid:18)d1 + 1
where r3 = d1 +1−r0−r1−r2. The above expression is also valid for (d1, d2) = (2, 6).
– The rectangular support R(S) of size (d1 + 2)(d2 + 1) gives no stopping sets. The
remaining rectangular supports from Figure 14 and Table IV yield no stopping sets for

(cid:19)(cid:18)d1 + 1 − r0 − r1

(cid:19) (d2 + 3)!
2r26r3 (cid:18) n1

r2

r1

d2 + 3(cid:19),

w = d1(d2 + 3).

March 7, 2016

DRAFT

Recall that a maximal rectangle width of d2 + 3 should be considered for d1 > 2 and it
goes up to d2 + 4 for d1 = 2 as shown in Table IV. New obvious stopping sets are found,
they appear for d1 = 2 only with a rectangular width equal to d2 + 4. Their rectangular

77

d1(cid:1)(cid:0) n2
support corresponds to the sizes in boldface in Table IV for w > d1(d2 + 3): (cid:0)n1
d2+4(cid:1)
obvious stopping sets of size d1 × (d2 + 4), (cid:0) n1
d2+4(cid:1) obvious stopping sets of size
d1+2(cid:1)(cid:0) n2
(d1 + 1) × (d2 + 4), and (cid:0) n1
d2+4(cid:1) obvious stopping sets of size (d1 + 2) × (d2 + 4).
Given that this theorem enumerates stopping sets for w ≤ (d1 + 1)(d2 + 1), one should only
count obvious d1 × (d2 + 4) sets.

d1+1(cid:1)(cid:0) n2

• The case d1(d2 + 3) < w < (d1 + 1)(d2 + 1).

Write w = d1(d2 + 3) + λ where λ ∈ [1, d2 − 2d1]. The results for the three rectangles listed
below are valid for d1 ≥ 2.
– Consider R(S) of size (d1 + 1)(d2 + 1). We have β = d2 − 2d1 + 1 − λ varying in the

range [1, d2 − 2d1]. The number of non-obvious stopping sets is
2d1 + λ(cid:19)(cid:18) n1

(d2 − 2d1 + 1 − λ)!(cid:18) d1 + 1

3d1 − d2 + λ(cid:19)(cid:18) d2 + 1

d1 + 1(cid:19)(cid:18) n2

d2 + 1(cid:19).

– Now consider R(S) of size (d1 + 1)(d2 + 2). We have β = d2 − d1 + 2 − λ ∈
[d1 + 2, d2 − d1 + 1]. As done before, the expression of the number of non-obvious
stopping sets involves r0 and r1 as follows.

r0 (cid:19)(cid:18)d1 + 1 − r0

X2r0+r1=3d1−d2+λ(cid:18)d1 + 1
where r2 = d1 + 1 − r0 − r1.
– We consider the next (d1 + 1)(d2 + 3) rectangular support. Now β = d2 + 3 − λ ∈

2r2(d1 + λ)!(cid:18) n1
(cid:19) (d2 + 2)!

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19),

r1

[2d1 + 3, d2 + 2]. The number of non-obvious stopping sets is

X3r0+2r1+r2=3d1−d2+λ(cid:18)d1 + 1
where r3 = d1 + 1 − r0 − r1 − r2.

r0 (cid:19)(cid:18)d1 + 1 − r0

r1

(cid:19)(cid:18)d1 + 1 − r0 − r1

r2

(cid:19) (d2 + 3)!
2r26r3λ! (cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 3(cid:19),

– The remaining larger rectangular supports give no stopping sets, except for (d1+1)(d2+
4) for d1 = 2 and d2 = 6 where τw = 22050. These 22050 rectangles of size 3 × 10,
where β = 10 and w = 20, have one zero in each column but a row may have up to

four zeros.

March 7, 2016

DRAFT

• The last case w = (d1 + 1)(d2 + 1).

– Obvious stopping sets are given by

78

d1 + 1(cid:19)(cid:18) n2
(cid:18) n1

d2 + 1(cid:19).

– The next R(S) from the table is (d1 + 1)× (d2 + 2). We have β = d1 + 1. The number

of stopping sets is

(d1 + 1)!(cid:18)d2 + 2

d1 + 1(cid:19)(cid:18) n1

d1 + 1(cid:19)(cid:18) n2

d2 + 2(cid:19).

– Now consider the (d1 + 1) × (d2 + 3) rectangle. We have β = 2d1 + 2. The number of

stopping sets is

X3r0+2r1+r2=d1+1(cid:18)d1 + 1

r1

r0 (cid:19)(cid:18)d1 + 1 − r0
2r26r3(d2 − 2d1 + 1)!(cid:18) n1

(cid:19)(cid:18)d1 + 1 − r0 − r1
d2 + 3(cid:19),
d1 + 1(cid:19)(cid:18) n2

(d2 + 3)!

r2

(cid:19)

where r3 = d1 + 1 − r0 − r1 − r2, the above expression being valid for d1 ≥ 2.

– No stopping sets are found for the remaining three rectangular supports for d1 > 2. On
the other hand, for d1 = 2, stopping sets are found only with a rectangle (d1+1)(d2+4).
In this case, we have β = 3(d1 + 1). The number of non-obvious stopping sets is
τw = 11130 for (d1, d2) = (2, 5) and τw = 111300 for (d1, d2) = (2, 6).

Q.E.D.

ACKNOWLEDGMENT

The work of Joseph J. Boutros was supported by the Qatar National Research Fund (QNRF),

a member of Qatar Foundation, under NPRP project 5-401-2-161 on layered coding. The authors

would like to thank Dr. Mireille Sarkiss, from CEA-LIST Paris, for her precious support.

March 7, 2016

DRAFT

REFERENCES

79

[1] N. Abramson, “Cascade decoding of cyclic product codes,” IEEE Trans. on Comm. Technology, vol. 16, no. 3, pp. 398-402,

June 1968.

[2] M. Alipour, O. Etesami, G. Maatouk, and A. Shokrollahi, “Irregular product codes,” IEEE Information Theory Workshop,

pp 197-201, Lausanne, Sept. 2012.

[3] D. Augot, M. El-Khamy, R.J. McEliece, F. Parvaresh, M. Stepanov, and A. Vardy, “Algebraic list decoding of Reed-Solomon

product codes,” Algebraic and Combinatorial Coding Workshop, pp. 210-213, Sept. 2006.

[4] E. Arıkan, “Channel polarization: A method for constructing capacity achieving codes for symmetric binary-input

memoryless channels,” IEEE Trans. Inf. Theory, vol. 55, no. 7, pp. 3051-3073, July 2009.

[5] S. Benedetto and G. Montorsi, “Unveiling turbo-codes: some results on parallel concatenated coding schemes,” IEEE Trans.

on Inf. Theory, vol. 42, no. 2, pp. 409-428, March 1996.

[6] C. Berrou and A. Glavieux, “Near optimum error correcting coding and decoding: Turbo-codes,” IEEE Trans. on

Communications, vol. 44, pp. 1261-1271, Oct. 1996.

[7] R.E. Blahut, Algebraic codes for data transmission, Cambridge University Press, 2003.

[8] B. Bollob´as, Modern graph theory, Springer, 1998.

[9] J.J. Boutros, O. Pothier, and G. Z´emor, “Generalized low density (Tanner) codes,” IEEE Intern. Conf. on Comm. (ICC),

vol. 1, pp. 441-445, Vancouver, June 1999.

[10] J.J. Boutros, G. Z´emor, A. Guill´en i F`abregas, and E. Biglieri, “Full-diversity product codes for block erasure and block

fading channels,” Information Theory Workshop, pp. 313-317, Porto, May 2008.

[11] J.J. Boutros, G. Z´emor, A. Guill´en I F`abregas, and E. Biglieri, “Generalized low-density codes with BCH constituents for

full-diversity near-outage performance,” IEEE Intern. Symp. on Inform. Theory (ISIT), pp. 787-791, Toronto, July 2008.

[12] J.J. Boutros, “Diversity and coding gain evolution in graph codes,” Information Theory and Applications Workshop, pp. 34-

43, San Diego, Feb. 2009.

[13] J.J. Boutros, A. Guill´en i F`abregas, E. Biglieri, and G. Z´emor, “Low-density parity-check codes for nonergodic block-fading

channels,” IEEE Trans. Inf. Theory, vol. 56, no. 9, pp. 4286-4300, Sept. 2010.

[14] E.R. Canﬁeld and B.D. McKay, “Asymptotic enumeration of integer matrices with constant row and column sums”,

Combinatorics, arXiv:math/0703600, revised June 2009.

[15] J.H. Conway and R.K. Guy. The Book of Numbers. New York: Springer-Verlag, pp. 94-96, 1996.

[16] C. Greenhill and B.D. McKay, “Asymptotic enumeration of sparse nonnegative integer matrices with speciﬁed row and

column sums,” Advances in Applied Mathematics, vol. 41, pp. 459-481, 2008, revised April 2012.

[17] C. Di, D. Proietti, I.E. Telatar, T.J. Richardson, and R.L. Urbanke, “Finite-length analysis of low-density parity-check

codes on the binary erasure channel,” IEEE Trans. Inf. Theory, vol. 48, no. 6, pp. 1570-1579, Jun. 2002.

[18] A.G. Dimakis, K. Ramchandran, Y. Wu, and C. Suh, “A survey on network codes for distributed storage,” IEEE Proceedings,

vol. 99, pp. 476-489, March 2011.

[19] P. Elias, “Error-free coding,” IRE Trans. Inf. Theory, vol. 4, no. 4, pp. 29-39, Sept. 1954.

[20] M. El-Khamy and R.J. McEliece, “Iterative algebraic soft-decision list decoding of Reed-Solomon codes,” IEEE Journal

on Selected Areas in Communications, vol. 24, no. 3, pp. 481-490, March 2006.

[21] K.S. Esmaili, L. Pamies-Juarez, and A. Datta, “CORE: Cross-object redundancy for efﬁcient data repair in storage systems,”

IEEE Big Data, pp. 246-254, Oct. 2013.

March 7, 2016

DRAFT

80

[22] D.F. Freeman and A.M. Michelson, “A two-dimensional product code with robust soft-decision decoding,” IEEE Trans.

Comm., vol. 44, no. 10, pp. 1222-1226, Oct. 1996.

[23] R.G. Gallager, Low-density parity-check codes, Ph.D. thesis, Massachussets Institute of Technology Press, 1963.

[24] P. Gopalan, V. Guruswami, and P. Raghavendra, “List decoding tensor products and interleaved codes,” SIAM J. Comput.,

vol. 40, no. 5, pp. 1432-1462, Oct. 2011.

[25] P. Gopalan, C. Huang, H. Simitci, and S. Yekhanin, “On the locality of codeword symbols,” IEEE Trans. Inf. Theory,

vol. 58, no. 11, pp. 6925-6934, Nov. 2012.

[26] A. Guill´en i F`abregas, “Coding in the block-erasure channel,” IEEE Trans. Inf. Theory, vol. 52, no. 11, pp. 5116-5121,

Nov. 2006.

[27] A. Guill´en i F`abregas and G. Caire, “Coded modulation in the block-fading channel: Coding theorems and code

construction,” IEEE Trans. Inf. Theory, vol. 52, no. 1, pp. 91-114, Jan. 2006.

[28] V. Guruswami and M. Sudan, “Improved decoding of Reed-Solomon and algebraic-geometry codes,” IEEE Trans. Inf.

Theory, vol. 45, no. 6, pp. 17571767, June 1999.

[29] T. Helleseth, T. Klove, and O. Ytrehus, “Generalized Hamming weights of linear codes,” IEEE Trans. Inf. Theory, vol. 38,

no. 3, pp. 1133-1140, May 1992.

[30] J. Jiang, K.R. Narayanan, “Iterative soft decoding of Reed-Solomon codes,” IEEE Communications Letters, vol. 8, no. 4,

pp. 244-246, April 2004.

[31] R. Knopp and P.A. Humblet, “On coding for block fading channels,” IEEE Trans. Inf. Theory, vol. 46, no. 1, pp. 189-205,

Jan. 2000.

[32] F.R. Kschischang, Product Codes, J.G. Proakis (ed), Wiley encyclopedia of telecommunications, pp. 2007-2012, vol. 4,

Hoboken, NJ, 2003.

[33] F.R. Kschischang, B.J. Frey, and H.-A. Loeliger, “Factor graphs and the sum-product algorithm,” IEEE Trans. Inf. Theory,

vol. 47, pp. 498-519, Feb. 2001.

[34] J. Kubiatowicz, D. Bindel, Y. Chen, S. Czerwinski, P. Eaton, D. Geels, R. Gummadi and S. Rhea, H. Weatherspoon,

W. Weimer, C. Wells, and B. Zhao, “Oceanstore: An architecture for global-scale persistent storage,” 9th Int. Conf. on

Architectural Support Programm, pp. 190-201, Cambridge, Massachusetts, 2000.

[35] S. Kudekar, T. Richardson, and R.L. Urbanke, “Spatially coupled ensembles universally achieve capacity under belief

propagation,” IEEE Trans. Inf. Theory, vol. 59, no. 12, pp. 7761-7813, Dec. 2013.

[36] S. Kudekar, M. Mondelli, E. Sasoglu, and R. Urbanke, “Reed-Muller codes achieve capacity on the binary erasure channel

under MAP decoding,” ArXiv 1505.05831, 2015.

[37] S. Kumar and H.D. Pﬁster, “Reed-Muller codes achieve capacity on erasure channels,” ArXiv 1505.05123, 2015.

[38] A. Lapidoth, “Convolutional codes and ﬁnite interleavers for the block erasure channel,” Mobile Communications Advanced

Systems and Components, Lecture Notes in Computer Science, Springer Berlin Heidelberg, vol. 783, pp. 113-120, May 2005.

[39] S. Lin and D.J. Costello, Error control coding, Prentice Hall, 2nd edition, 2004.

[40] F.J. MacWilliams and N.J.A. Sloane, The theory of error-correcting codes, North-Holland, 1977.

[41] E. Malkamaki and H. Leib, “Evaluating the performance of convolutional codes over block fading channels,” IEEE Trans.

Inf. Theory, vol. 45, no. 5, pp. 1643-1646, July 1999.

[42] F. Oggier and A. Datta, “Coding techniques for repairability in networked distributed storage systems,” Foundations and

Trends in Communications and Information Theory, vol. 9, pp. 383-466, 2013.

March 7, 2016

DRAFT

81

[43] G.C. Onwubolu and D. Davendra, Differential evolution: a handbook for global permutation-based combinatorial

optimization, Springer, 2009.

[44] Y. Polyanskiy, H.V. Poor, and S. Verd´u, “Channel coding rate in the ﬁnite blocklength regime,” IEEE Trans. Inf. Theory,

vol. 56, no. 5, pp. 2307-2359, May 2010.

[45] R. Pyndiah, “Near-optimum decoding of product codes: Block turbo codes,” IEEE Trans. Comm., vol. 46, no. 8, pp. 1003-

1010, Aug. 1998.

[46] D. Rankin and T.A. Gulliver, “Asymptotic performance of product codes,” IEEE International Conference on Communi-

cations, pp. 431-435, Vancouver, June 1999.

[47] K.V. Rashmi, N.B. Shah, D. Gu, H. Kuang, D. Borthakur, and K. Ramchandran, “A solution to the network challenges

of data recovery in erasure-coded distributed storage systems: A study on the Facebook warehouse cluster,” Proc. USENIX

HotStorage, June 2013.

[48] S.R. Reddy and J.P. Robinson, “Random Error and Burst Correction by Iterated Codes,” IEEE Trans. Inf. Theory, vol. 18,

no. 1, pp. 182-185, Jan. 1972.

[49] T.J. Richardson and R.L. Urbanke, Modern coding theory, Cambridge University Press, 2008.

[50] E. Rosnes and O. Ytrehus, “Turbo decoding on the binary erasure channel: Finite-length analysis and turbo stopping sets,”

IEEE Trans. Inf. Theory, vol. 53, no. 11, pp. 4059-4075, Nov. 2007.

[51] E. Rosnes, “Stopping set analysis of iterative row-column decoding of product codes,” IEEE Trans. Inf. Theory, vol. 54,

no. 4, pp. 1551-1560, April 2008.

[52] A. Sarwate, “Soft decision decoding of Reed-Solomon product codes,” EECS 229B Final Project Report, May 2005.

[53] M. Schwartz, P.H. Siegel, and A. Vardy, “On the asymptotic performance of iterative decoders for product codes,” IEEE

International Symposium on Information Theory, pp. 1758-1762, Sept. 2005.

[54] M. Schwartz and A. Vardy, “On the stopping distance and the stopping redundancy of codes,” IEEE Trans. Inf. Theory,

vol. 52, no. 3, pp. 922-932, March 2006.

[55] A. Sella and Y. Be’ery, “Convergence analysis of turbo decoding of product codes,” IEEE Trans. Inf. Theory, vol. 47, no.

2, pp. 723-735, Feb. 2001.

[56] N. Sendrier, “Codes correcteurs d’erreurs `a haut pouvoir de correction,” Th`ese de Doctorat de l’Universit´e Paris 6, in

French, Dec. 1991.

[57] N.J.A Sloane, The On-Line Encyclopedia of Integer Sequences. See sequence A000041 at oeis.org/A000041.

[58] R.P. Stanley, Enumerative combinatorics, Cambridge Univ. Press, vol. 1, 2nd edition, 2012.

[59] R. Storn and K. Price, “Differential evolution - A simple and efﬁcient heuristic for global optimization over continuous

spaces,” Journal of Global Optimization, vol. 11, pp. 341-359, 1997.

[60] R.M. Tanner, “A recursive approach to low complexity codes,” IEEE Trans. Inf. Theory, vol. 27, no. 5, pp. 533-547,

Sept. 1981.

[61] J.-P. Tillich and G. Z´emor, “Optimal cycle codes constructed from Ramanujan graphs,” SIAM J. Discrete Mathematics,

vol. 10, no. 3, pp. 447-459, 1997.

[62] L.M.G.M. Tolhuizen, “More results on the weight enumerator of product codes,” IEEE Trans. Inf. Theory, vol. 48, no. 9,

pp. 2537-2577, Sept. 2002.

[63] D.N.C. Tse and P. Viswanath, Fundamentals of Wireless Communication, Cambridge University Press, 2005.

[64] W.M.C.J. Van Overveld, “Multiple-burst error-correcting cyclic product codes (Corresp.),” IEEE Trans. Inf. Theory, vol. 33,

no. 6, pp. 919-923, Nov. 1987.

March 7, 2016

DRAFT

82

[65] D.P. Varodayan, “Investigation of the Elias product code construction for the binary erasure channel”, B.A.S. Thesis,

University of Toronto, Dec. 2002.

[66] S. Wainberg, “Error-erasure decoding of product codes (Corresp.),” IEEE Trans. on Inf. Theory, vol. 18, no. 6, pp. 821-823,

Nov. 1972.

[67] V.K. Wei, “Generalized Hamming weights for linear codes,” IEEE Trans. Inf. Theory, vol. 37, no. 5, pp. 1412-1418,

Sept. 1991.

[68] L.-J. Weng and G. Sollman, “Variable redundancy product codes,” IEEE Trans. on Comm. Technology, vol. 15, no. 6,

pp. 835-838, Dec. 1967.

[69] S.B. Wicker and V.K. Bhargava, eds., Reed-Solomon Codes and their Applications. New York: IEEE Press, 1994.

[70] J.K. Wolf, “On codes derivable from the tensor product of check matrices,” IEEE Trans. Inf. Theory, vol. 11, no. 2,

pp. 281-284, April 1965.

March 7, 2016

DRAFT

