Dynamic Adaptive Mixture Models

Leopoldo Cataniaa,∗

aDepartment of Economics and Finance, University of Rome, Tor Vergata, Rome, Italy

6
1
0
2

 
r
a

M
3

 

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
8
0
3
1
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

In this paper we propose a new class of Dynamic Mixture Models (DAMMs) being able to sequentially

adapt the mixture components as well as the mixture composition using information coming from

the data. The information driven nature of the proposed class of models allows to exactly compute

the full likelihood and to avoid computer intensive simulation schemes. An extensive Monte Carlo

experiment reveals that the new proposed model can accurately approximate the more complicated

Stochastic Dynamic Mixture Model previously introduced in the literature as well as other kind of

models. The properties of the new proposed class of models are discussed through the paper and an

application in ﬁnancial econometrics is reported.

Keywords: Dynamic mixture models, Score Driven models, adaptive models, density prediction.

1. Introduction

Mixtures of distributions are extremely diﬀused parametric tools used to model non–Gaussian

shapes that usually characterise empirical data. A great level of ﬂexibility can be achieved in

Mixture Models (MM) by appropriate choices of the mixture components distributions. Moreover,

the mixture components can also be adaptive with respect to the new information as usually happens

in linear and generalised Mixture Models, see e.g. Bishop (2006). Within the context of MM, also

the mixture composition can be allowed to evolve over time, this class of models is usually identiﬁed

∗Department

of

of

Rome
“Tor Vergata” , Via Columbia, 2, 00133, Rome, Italy. leopoldo.catania@uniroma2.it, Phone: +39 06 7259 5941,
web page: http://www.economia.uniroma2.it/phd/ef/default.asp?a=216.

Economics

University

and

Finance,

Preprint submitted to Elsevier

March 7, 2016

as Dynamic Mixture Models (DMM), see e.g. Yu (2012). DMM have been successfully applied in

process monitoring (Yu, 2012), intervention detections (Gerlach et al., 2000), insurance losses (Frigessi

et al., 2002) and graphical engineering (KaewTraKulPong and Bowden, 2002; Xie et al., 2005). A

drawback of DMM is that, when nonlinear non–Gaussian speciﬁcations are assumed for the mixture

components and for the evolution of the mixture composition, classical inference cannot be applied

anymore, see e.g. Gerlach et al. (2000). Usual solutions relay on computer intensive Markov Chain

Monte Carlo (MCMC) simulation schemes to carry out Bayesian inference which highly reduce the

attractiveness of such models and their implementation in commercial softwares, see e.g. Gerlach

et al. (2000), Yu (2012) and Billio et al. (2013).

In this paper we follow a diﬀerent approach to model the time evolution of the mixture component

distributions as well as the mixture composition in a fully observation driven framework (Cox et al.,

1981). We build our model starting from recent advances in Score Driven models, see e.g. Harvey

(2013) and Creal et al. (2013). In Score Driven models, the latent dynamic parameters are updated

using an adequate forcing variable based on the score of the conditional distribution. In our context,

the mixture components can be chosen to be any parametric distribution with the possibility of

allowing for time variation in the full set of parameters of each component. We also allow for

the mixture composition to be sequentially updated using the information contained in data. We

call this class of models Dynamic Adaptive Mixture Models (DAMMs) given their high ﬂexibility in

terms of possible dynamic parametric assumptions and their ability to sequentially adapt the mixture

composition. As extensively discussed by Koopman et al. (2015), the use of the conditional score

in order to pool the information coming from the data into new updated parameters, results to be

extremely ﬂexible. Indeed, they found that robust score–based ﬁlters well approximate unobserved

dynamics generated from nonlinear non–Gaussian state space models and other kinds of models.

Usually, in applications that exploit mixture of distributions as parametric tools, one of the main

inferential objective is in terms of clustering results, see e.g. McLachlan and Peel (2000). Also within

the context of Markov Switching (MS) models, empirical results are often given in terms of decoding

for the latent unobservable regimes, see e.g. Hamilton (1989) , Capp´e et al. (2005) and Fr¨uhwirth-

2

Schnatter (2006). However, given the dynamic evolution of each component of the mixture, the use

of DAMM is not limited to this type of applications. Indeed, one of the main scope of DAMM is to

adaptively represent the dynamic composition of the mixture, and not to uniquely identify regimes or

structural changes aﬀecting the data. However, if the underlying data generating process behaves as

usual MS processes, then DAMM can easily accommodate this feature. In order to demonstrate the

ﬂexibility of DAMM we perform an extensive Monte Carlo experiment composed by four parts. In the

ﬁrst part, we aim to approximate the ﬁrst two conditional moments as well as the dynamic mixture

composition generated by a Stochastic DMM (SDMM) similar to that of Yu (2012). In this respect,

our experiment is similar to that performed by Koopman et al. (2015) in the context of ﬁltering state

space models using Generalised Autoregressive Score (GAS) models, a theoretical treatment of this

interesting topic is reported by Harvey (2013). The second and the third parts, similarly to Engle

(2002) and Creal et al. (2013), focus on ﬁltering several artiﬁcial patterns assumed for the correlation

and the mixture composition of conditional random variables. In the last experiment we investigate

the cost, in terms of precision loss in ﬁltering conditional correlations, of model misspeciﬁcation.

Our results suggest that DAMMs are able to adequately approximate the highly nonlinear dynamics

generated by the SDMM and the artiﬁcial correlation and mixture composition patterns better then

competitive models. To further investigate the properties of the proposed DAMMs, we also report

an empirical application in ﬁnancial econometrics. Speciﬁcally, we estimate several univariate and

multivariate DAMM speciﬁcations to a panel of ﬁnancial returns. The speciﬁcations we consider diﬀer

in terms of parametric assumptions and dynamic properties of the conditional distribution. In sample

and out of sample comparative results are given in terms of goodness of ﬁt and predictive ability of

the marginal and joint conditional distributions. We found that DAMMs outperforms competitive

GARCH/DCC models in both cases.

The paper is organised in the following manner. Section 2 describes the DAMM and details the

updating mechanism for the mixture component distributions and the mixture composition. Section

3 reports several univariate and multivariate DAMM speciﬁcations that can be used in relevant

empirical applications. Section 4 reports the Monte Carlo experiments.

3

Sections 5 reports the empirical application in ﬁnancial econometrics. Finally, Section 6 concludes

and reports some suggestions for future research.

2. Dynamic Adaptive Mixture Models

Let yt ∈ (cid:60)d be a d–dimensional random vector conditionally distributed according to
p (yt|Ft−1, θt), with Ft−1 be the ﬁltration generated by the process {ys, s > 0} up to time t − 1,
and θt be a vector of time varying conditional parameters. We will assume p (·) to be a ﬁnite mixture
of J real valued conditional distributions, i.e.

J(cid:88)

p (yt|Ft−1, θt) =

ωj,tpj (yt|Ft−1, θj,t) ,

with ωj,t ∈ (0, 1) and (cid:80)J

j=1 ωj,t = 1 ∀ t = 1, . . . and θt = (cid:0)θ(cid:48)

j=1

j,t, ωj,t, j = 1, . . . , J(cid:1)(cid:48)

(1)

. Within the

class of Dynamic Mixture Models, the mixture component density parameters θj,t, generally follow

a stochastic process. Convenient choices are ﬁrst order nonlinear autoregression (Billio et al., 2012;

Casarin et al., 2015) and Markov Switching processes (Kim, 1994; Kim and Nelson, 1999; Ardia, 2008;

Harrison and West, 1999). The latter are usually estimated by particle ﬁlters in a Bayesian context,

while for the former the Expectation–Maximisation algorithm of Dempster et al. (1977) is frequently

employed. Diﬀerently, in this paper we follow the Score Driven Framework (SDF) of Harvey (2013)

and Creal et al. (2013) by letting the full set of parameters to be updated using the score of the
conditional distribution p (yt|Ft−1, θt).
(cid:48)
Formally, let ωt = (ωj,t, j = 1, . . . , J)
be the vector containing the mixture weights at time t, and
˜ωt ∈ (cid:60)J−1 be a (J − 1)–dimension vector such that Λω ( ˜ωt) = ωt, for a Ft−1 measurable mapping
function Λω : (cid:60)J−1 → S J , such that Λω ∈ C2, with S J representing the standard unit J–simplex, i.e.
∀j}. Similarly, let ˜θj,t ∈ Ωj ⊆ (cid:60)dj be a dj–dimension
= θj,t where Λj : (cid:60)dj → Ωj holds the same
properties stated for Λω (·), for all j = 1, . . . , J. In order to avoid complicated nonlinear constraints
on the parameters dynamic, in this paper, instead of directly modeling the vector θt deﬁned on

S J : {(t1, . . . , tJ ) ∈ (cid:60)J|(cid:80)J
vector such that, for each time t, we have Λj(cid:16)˜θj,t

j=1 tj = 1 ∧ tj ≥ 0,

(cid:17)

4

(cid:17)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ˜θ=

(cid:16)

=

(cid:17)

∂ ln ˜p

yt|˜θt
∂ ˜θ

˜∇(cid:16)˜θt|yt
˜θt+1 = κ + A ˜∇(cid:16)˜θt|yt

(cid:17)

,

˜θt

(2)

S J × Ω1 × ··· × ΩJ , we model the unconstraint vector of parameters ˜θt =
deﬁned on (cid:60)J−1 ×(cid:60)d1 ×···×(cid:60)dJ . To this end, we reparametrise the conditional distribution (1) into
, where henceforth the dependence from Ft−1 has been omitted for notational purposes.
˜p

yt|, ˜θt

˜ω(cid:48)
t, ˜θ

(cid:48)
j, j = 1, . . . , J

(cid:16)

(cid:17)

In the SDF, the quantity of interest is the score of the conditional distribution given by

(cid:16)

(cid:17)(cid:48)

which enters linearly as a forcing variable into the dynamic updating equation of ˜θt, i.e.

(cid:16)

J − 1 +(cid:80)J

(cid:17)

+ B˜θt,

(cid:17)

j=1 dj

{ ˜∇(cid:16)˜θt|ys

(3)
= L–dimension vector and A and B are L×L matrices of coeﬃcients
where κ is a
that need to be estimated. Since we are modeling the unconstraint vector of parameters ˜θt and
, s > 0} forms a Martingale Diﬀerence Sequence, we only need to impose that the
eigenvalues of B lies inside the unit circle to ensure weak stationarity of the process {˜θs, s > 0}.
Constraints on the number of free parameters that are present in κ, A and B can be imposed in

order to avoid problems of parameters proliferation, indeed, throughout the paper we will impose a

diagonal structure for A and B. It is worth noting that, by a simple application of the chain rule,

the conditional score with respect to the unconstraint vector of parameters ˜∇(cid:16)˜θt|yt
represented as the product between the transpose of the jacobian of the full mapping function J(cid:16)˜θt

can be easily

(cid:17)

(cid:17)

and the conditional score evaluated with respect to the constraint vector of parameters ∇ (θt|yt), i.e.,

˜∇(cid:16)˜θt|yt

(cid:17)

= J(cid:16)˜θt

(cid:17)(cid:48) ∇ (θt|yt) ,

(4)
where with “full mapping function” we mean the vector–valued function Λ : (cid:60)J−1×(cid:60)d1 ×···×(cid:60)dJ →
∀t.
S J × Ω1 × ··· × ΩJ that incorporates Λω (·) and Λj (·) ,
is block diagonal,

In our context, since the matrices A and B are diagonal, and the matrix J(cid:16)˜θt

j = 1, . . . , J, such that Λ

(cid:16)˜θt

= θt,

(cid:17)

(cid:17)

the dynamic updating equation (3) can be divided into J + 1 individual dynamics, i.e.

˜ωt+1 = κω + AωJ ω ( ˜ωt)

˜θj,t+1 = κj + AjJ j(cid:16)˜θj,t

(cid:48) ∇ω (ωt|yt) + Bω ˜ωt

(cid:17)(cid:48) ∇j (θj,t|yt) + Bj ˜θj,t,

j = 1, . . . , J,

(5)

(6)

5

where all the symbols have the same interpretation as before, but are now related to each speciﬁc

quantity of the model. The following Proposition will be necessary later.

Proposition 2.1 (Score of a mixture of distributions). Let x ∼ g (x|φ), with g (x|φ) =
. Let di be the dimension

i=1 ωi = 1 and ω = (ωi, i = 1, . . . , K)

i=1 ωigi (x|φi), with ωi ≥ 0, (cid:80)K
(cid:80)K
of φi and let φ =(cid:0)ω(cid:48), φ(cid:48)
i, i = 1, . . . , K(cid:1)(cid:48)

= D–th dimension vector containing all

K +(cid:80)K

(cid:16)

(cid:17)

be a

i=1 di

(cid:48)

(7)
be a vector of dimension D representing the score of g (x|φ), partitioned into ∇ (φ|x) =

∂φ

,

∇ (φ|x) =

∂ ln g (x|φ)

(cid:17)(cid:48)

the distribution parameters. Let

(cid:16)∇ω (ω|x)

(cid:48)

,∇(i) (φi|x)

(cid:48)

, i = 1, . . . , K

, where

∂ ln g (x|φ)
∂ ln g (x|φ)

∂ω

∂φi

,

i = 1, . . . , K.

∇ω (ω|x) =
∇(i) (φi|x) =
(cid:19)(cid:48)

, i = 1, . . . , K

, and

∀ i (cid:54)= l, we have that

Assuming gi (x|φi) ⊥⊥ gl (x|φl) ,
(a) ∇ω (ω|x) =

(cid:18) gi(x|φi)

g(x|φ)
gi(x|φi)
g(x|φ)

(b) ∇(i) (φi|x) = ωi

∇gi (φi|x), i = 1, . . . , K

where ∇gi (φi|x) =

∂ ln gi(x|φi)

∂φi

is the score of the i–th mixture component distribution.

Proof. (a) follows immediately, while for (b) we note that

∇(i) (φi|x) = ωi

1

g (x|φ)

∂gi (x|φi)

∂φi

,

and

∂gi (x|φi)

∂φi

=

∂ exp (ln gi (x|φi))

∂φi

= gi (x|φi)∇gi (φi|x) .

6

(8)

(9)

(10)

(11)

2.1. Update the mixture composition

Several diﬀerent choices are available in order to reparametrise and update the mixture weights

ωt. For example, Billio et al. (2013) use the Logistic–Transformed Gaussian (LTG) weights, i.e.
their mapping function is the vector valued function ΛLTG : (cid:60)J → S J , with j–th component given
, and ˜ωt ∼ NJ ( ˜ωt| ˜ωt−1, Σ), with Σ be a proper covariance matrix.
by ΛLTG
This mapping and updating scheme assumes that the weights do not depend on the observable data.

exp(˜ωj,t)
i=1 exp(˜ωi,t)

(˜ωj,t) =

(cid:80)J

j

Moreover, it results to be somehow overparametrised since it is always possible to ﬁnd a mapping
function deﬁned on (cid:60)J−1 (instead of (cid:60)J ) with J − 1 free parameters, which maps in S J . We propose
a convenient choice for the function Λω (·), given by

Λω ( ˜ωt) :=

h=1 ωh,t,

j = 1, . . . , J − 1

(12)

where bj,t = bj−1,t − ωj−1,t with b1,t = 1 and λ[L,U ] : (cid:60) → [L, U ] ⊂ (cid:60) is a real–valued deterministic
monotone twice diﬀerentiable mapping function such as the modiﬁed logistic λ[L,U ] (x) = L+ (U−L)
1+exp(−x) .
With these choices of Λω (·) and λ[L,U ] (·), the (j, h)–th element of the J ×J −1 jacobian matrix J ω (·)
is given by

ωj,t = λ[0,bj,t] (˜ωj,t) ,
ωJ,t = 1 −(cid:80)J−1


bj,t exp(−˜ωj,t)
−(cid:80)j−1
(1+exp(−˜ωj,t))2 ,
−(cid:80)J−1

k=1 J ω( ˜ωt)(k,h)
1+exp(−˜ωj,t)
k=1 J ω ( ˜ωt)(k,h) ,
(cid:19)(cid:48)

0,

,

J ω ( ˜ωt)(j,h) =

(cid:18) pj(yt|θj,t)

if h = j
if h < j ∧ j (cid:54)= J

if j = J,

if h > j.

(13)

The score of (1) with respect to the mixture weights parameters follows from Proposition 2.1 and
is given by ∇ω (ωt|yt) =
between the mixture distribution and the j–th component distribution.

, i.e. its j–th component is given by the ratio

It is interesting to note

j = 1, . . . , J

p(yt|θt)

,

that, the SDF naturally suggests to update the weights dynamics using the information contained
(cid:48) ∇ω (ωt|yt). This
in the density ratio adjusted for the chosen reparametrisation of ωt, i.e. J ω ( ˜ωt)
mechanism implicitly moves the mixture composition to the region of higher probability mass at each

7

point in time t, and strongly diﬀers from the pure Random Walk assumption implied by Billio et al.

(2013).

2.2. Update the mixture components

If we assume no ordering restriction to the mixture distribution, the matrix J(cid:16)˜θt
be block diagonal with respect the sub–matrices J j(cid:16)˜θj,t

j = 1, . . . , J, and hence, the dynamic
updating equation for ˜θt can be divided into J dynamics for each ˜θj,t plus the dynamic for ˜ωt.
This feature of the model also permits to easily parallelise the update of ˜θt.1 As for the update of
the mixture composition, the reparametrised mixture component parameters ˜θj,t

(cid:17)

turns out to

j = 1, . . . , J are

(cid:17)

,

updated using the conditional score of the reparametrised mixture distribution ˜p

with respect

to the vector ˜θj,t, given by J j(cid:16)˜θj,t

(cid:17)(cid:48) ∇j (θj,t|yt) where,

(cid:16)

yt|˜θt

(cid:17)

∇j (θj,t|yt) = ωj,t

pj (yt|θj,t)
p (yt|θt)

∇pj (yt|θj,t)

, j = 1, . . . , J,

(14)

follows from Proposition 2.1, and ∇pj (yt|θj,t) =
component. The updating equation for the j–th mixture component parameters can be written

is the score of the j–th mixture

∂θj,t

∂ ln pj(yt|θj,t)

as

where

˜θj,t+1 = κj + ξj,tAjJ j(cid:16)˜θj,t

(cid:17)(cid:48) ∇pj (yt|θj,t) + Bj ˜θj,t,

ξj,t = ωj,t

pj (yt|θj,t)
p (yt|θt)

,

(15)

(16)

1Sometimes, In real applications, it can results to be quite restrictive. Indeed, within the context of (Hidden) Mixture

Models, it is often desirable to identify the mixture component parameters using some predeﬁned schemes based on

previous knowledge. For example, in the ﬁnancial markets, during periods of high volatility also the correlations between

ﬁrms tend to be higher and vice versa. This situation would suggest an ordering of the mixture components variances

and correlations. If this is the case, the matrix J(cid:16)˜θt

(cid:17)

is no longer block diagonal and the J dynamics for the mixture

components parameters cannot be divided anymore. Clearly, this kind of assumptions can be easily incorporated in

DAMM imposing a diﬀerent parametrisation. For simplicity, in this paper we will ignore this possibility.

8

is the relative contribution of the j–th component to the mixture density at time t conditionally on

past information. It is worth remarking that, equation (15) is very similar to that usually found in

Score Driven processes. Indeed, if J = 1, we recover the Generalised Autoregressive Score (GAS) and

the Dynamic Conditional Score (DCS) models with identity scaling matrix of Creal et al. (2013) and

Harvey (2013), respectively. However, in our context, the mixture assumption naturally suggests to

scale the score contribution in a way that accounts for the relative importance each mixture component

has at time t. Interestingly, a similar result has been found by Bazzi et al. (2014) in their Time Varying

Hidden Markov Model. Furthermore, thanks to the use of the conditional score, DAMMs share the

same “robustness” properties of classical Score Driven models and can be easily developed starting

from that speciﬁcations, see e.g. Koopman et al. (2015).

It follows that, the DAMM embeds a

rational learning mechanism for updating the mixture components parameters. Indeed, we do not

need to impose any arbitrary learning mechanism such as the one detailed in Billio et al. (2013),

simply because for DAMMs it emerges naturally. This implied learning mechanism ensures that the

new information contained in the data is shared across the mixture components proportionally to its

relative relevance. Indeed, if we are sure that a new observation has been generated from a particular

component of the mixture, DAMM will update the parameters of that particular component leaving

the others unchanged simply due to the lack of relevant information. We believe that this point is

of primary importance and it is quite often neglected especially for Markow Switching models with

dynamic state–dependent densities. For example, in models such as the MS–GARCH of Haas (2006)

,the MS–Copula of Fei et al. (2013), the SGASC of Bernardi and Catania (2015) and the MS–VAR of

Krolzig (1997), past observations are treated equally across the latent markovian states. Two notable

exceptions are the MS–GARCH speciﬁcations of Gray (1996) and Klaassen (2002) where, in order to

solve the “path dependence problem”, the state dependent GARCH speciﬁcation is scaled using the

predicted and ﬁltered state probabilities, respectively. Even if these ad hoc solutions are developed

with a diﬀerent scope, their consequences are quite similar to those naturally implied by DAMMs.

Concerning the estimation of DAMM, it can be easily performed using the Maximum Likelihood

(ML) estimator as detailed in the technical report “Maximum likelihood estimator for generalised

9

autoregressive score models” by F. Blasques, S.J. Koopman and A. Lucas, available at

http://papers.tinbergen.nl/14029.pdf, see also Blasques et al. (2015). However, as usually

happens when mixtures of distributions are employed, problems of multimodality of the likelihood

can arise, hence good starting values and multiple tries are required. We suggest to initialise the

algorithm using the estimates delivered by a static Mixture models estimated by the EM algorithm,

as suggested by Yu (2012) in a similar context. The supplementary material accompanying this

paper reports a simulation study on the ﬁnite sample properties of the ML estimator for the class of

DAMMs.

3. DAMM speciﬁcations

In this Section we report four diﬀerent DAMM speciﬁcations that can be used in empirical works.

Speciﬁcally, we report two univariate speciﬁcations for dynamic mixtures of univariate Gaussian and

Student–t distributions as well as two speciﬁcations for dynamic mixtures of multivariate Gaussian

and multivariate Student–t distributions and their related copulas. It is worth remarking that, the

updating of the mixture composition is not strictly related to the choice of the mixture components,

so the arguments presented in Subsection 2.1 do not account for the speciﬁc model parametric form.

3.1. Univariate DAMM speciﬁcations

Since the dynamic updating equation for each reparametrised mixture component vector of
parameters ˜θj,t, only depends on the chosen mapping functions Λj (·), and the score of the mixture
and the scores vectors

component distribution, we only need to specify the jacobian matrices J j(cid:16)˜θj,t

(cid:17)

∇pj (yt|θj,t), for j = 1, . . . , J, to fully characterise the updating scheme reported in equation (15).
Speciﬁcally, if we assume that the univariate observation yt ∈ (cid:60) is conditionally distributed according
to a mixture of J Gaussian distributions, i.e.

ωj,tpj (yt|θj,t) ,

(17)

yt ∼ J(cid:88)

j=1

10

(cid:16)

µj,t, σ2
j,t

where θj,t =

(cid:17)(cid:48)

one can easily reparametrise the vector θj,t employing the mapping function

j,t, of the j–th Gaussian density pj,

which implies the jacobian matrix

Finally, the score vector for the j–th Gaussian component is given by

0

j,t

˜σ2
j,t

(cid:17)

(cid:16)

Λj :=

0 exp

˜σ2
j,t

σ2
j,t = exp

contains the mean µj,t and variance σ2

µj,t = µj,t
1
 .
J j(cid:0)µj,t, ˜σ2
(cid:1) =
(cid:16)
(cid:17)
 (yt − µj,t) /σ2
(cid:1) =
(cid:0)yt|µj,t, σ2
(cid:21)
(cid:20)
(cid:16)
κµj
 +

µj,t
βµj
(cid:16)
(cid:17)
αµj
(cid:80)J
ωj,tpj
j=1 ωj,tpj (yt|θj,t)

J j(cid:0)µj,t, ˜σ2

yt|µj,t, σ2

j,t

(yt−µj,t)2

µj,t, ˜σ2
j,t

0

βσj

(cid:17)(cid:48)

∇pj

κσj

˜σ2
j,t

0

0

ασj

j,t

0

− 1

j,t

/2σ2
j,t

σ2
j,t

 ,

µj,t+1

 =

˜σ2
j,t+1

+

(18)

(19)

(20)

(21)

(22)

and the dynamic updating equation for ˜θj,t =

, is simply given by

(cid:1)∇pj

(cid:0)yt|µj,t, σ2

j,t

(cid:1) ,

j,t

where, as stated before, a diagonal structure for the matrices Aj and Bj has be imposed.

If we believe that a mixture of Gaussian distributions is not suited for the available time series, we

can consider a DAMM speciﬁcation with Student–t mixture components. In this case, we can assume

pj to be a Student–t distribution with mean µj,t, scale ψj,t and shape νj,t parameters, and deﬁne the

(cid:48)
vector θj,t = (µj,t, ψj,t, νj,t)

, such that Λj(cid:16)˜θj,t

(cid:17)

well deﬁned ﬁrst and second conditional moments, we can deﬁne Λj equals to

= θj,t. In this case, if we want that yt maintains

µj,t = µj,t

Λj :=

ψj,t = exp

(cid:17)

(cid:16) ˜ψj,t

,

(23)



νj,t = exp (˜νj,t) + 2

11

which implies the jacobian matrix

J j(cid:16)

(cid:17)

=

µj,t, ˜ψj,t, ˜νj,t

0 exp

(24)

0

1


(cid:17)

0

(cid:16) ˜ψj,t

0

0

0

exp (˜νj,t)

(νj,t+1)(yt−µj,t)
j,t+(yt−µj,t)2
2ψ2
+ (νj,t+1)(yt−µj,t)
j,t+ψj,t(yt−µj,t)

νj,tψ3

h (yt, µj,t, ψj,t, νj,t)

 .
 ,

Finally, the score vector for the j–th Student–t component is given by

∇pj (yt|µj,t, ψj,t, νj,t) =

− 1

ψj,t

where

h (yt, µj,t, ψj,t, νj,t) =

1
2



(cid:18) νj,t + 1

2
− 1
2

(cid:19)
(cid:32)

− 1
2

log

1 +

(cid:16) νj,t

(cid:17) − π
(cid:33)

2νj,t

2


(yt − µj,t)2

νj,tψ2
j,t

(cid:16)

(νj,t + 1) (yt − µj,t)2

j,tνj,t + (yt − µj,t)2(cid:17) ,

ψ2

2νj,t

+

and  (x) is the digamma function. It is worth noting that, the dynamic features of the model should

be tailored to the statistical properties of the considered time series. Indeed, if we do not believe that

such a rich parametrisation is required by the data, restrictions on the coeﬃcients that determine the

updating of θj,t can be imposed. For example, the coeﬃcients ανj and βνj , for j = 1, . . . , J, may be

constraint to zero in order to avoid time variation in the mixture components shape parameters.

3.2. Multivariate DAMM speciﬁcations

The extension to the multivariate case yt ∈ (cid:60)d is straightforward. Suppose that yt is conditionally
distributed according to a mixture of J multivariate Gaussian distributions, with mean vector µj,t and

covariance matrix Σj,t, for all j = 1, . . . , J. It is convenient to employ the following decomposition

of the covariance matrix

Σj,t = Dj,tRj,tDj,t,

(25)

12

(cid:48)
where Dj,t = diag (σj,t) and σj,t = (σj,i,t, i = 1, . . . , d)

, where σj,i,t is the conditional standard

deviation of yi,t conditionally on pj. Let deﬁne ρj,t = vechd (Rj,t) where vechd (X) is the vech
operator without considering the diagonal elements of X. The (2d + d (d − 1) /2)–valued vector
of time varying parameters for the j–th mixture component is θj,t =
and its
reparametrised version is given by ˜θj,t =

diﬃcult task is to deﬁne a mapping function that maps ˜ρj,t into ρj,t such that Rj,t = vechd−1(cid:0)ρj,t

. Under this parametrisation, the only

j,t, ˜σ(cid:48)
µ(cid:48)

µ(cid:48)
j,t, σ(cid:48)

j,t, ˜ρ(cid:48)

j,t, ρ(cid:48)

(cid:17)(cid:48)

(cid:17)(cid:48)

(cid:16)

(cid:16)

(cid:1)

j,t

j,t

is a symmetric positive deﬁned correlation matrix, since the exponential mapping function can

still be used for the components of ˜σj,t. We suggest to use the hyperspherical coordinates

reparametrisation for the correlation matrices Rj,t, j = 1, . . . , J as in Creal et al. (2012) and Jaeckel
and Rebonato (1999). Speciﬁcally, we deﬁne Λj
where Ωρ = {(ρj,il,t, i = 1, . . . , d, i < l < d) ∈ [−1, 1]d(d−1)/2

ρ : (cid:60)d(d−1)/2 → Ωρ, such that Λj

| (cid:60) (x∗Rj,tx) > 0, for Rj,t =

ρ

(cid:0)˜ρj,t

(cid:1) = ρj,t,

vechb−1(cid:0)ρj,t
where Z(cid:0)˜ρj,t

(cid:1) ∧ ∀x ∈ Cd(d−1)/2}2. The mapping function Λj
(cid:1)(cid:48)
Z(cid:0)˜ρj,t
(cid:1) is a d × d upper—triangular matrix, that is,

(cid:1) = vechd

(cid:0)˜ρj,t

(cid:16)

Λj
ρ

ρ (·) deﬁnes

Z(cid:0)˜ρj,t

(cid:1)(cid:17)

,

(26)



0

0
...
0

0



,

(27)

Z(cid:0)˜ρj,t

(cid:1) =

1 cj,12,t

0 sj,12,t

cj,13,t

cj,23,tsj,13,t

0

0
...
0

0

0

0
...
0

0

. . .

. . .

. . .

. . .
. . .

0

. . .

cj,1d,t

cj,2d,tsj,1k,t

cj,3d,tsj,2k,tsj,1k,t

cj,4d,tsj,3k,tsj,2k,tsj,1k,t

...

(cid:81)d−2
(cid:81)d−1

l=1 sj,ld,t

cj,d−1,d,t

l=1 sj,ld,t

2here x∗ denotes the conjugate transpose of x

13

where cj,lk,t = cos (˜ρj,lk,t) and sj,lk,t = sin (˜ρj,lk,t), where ˜ρj,lk,t is the (l, k)–th element of ˜Rj,t =

vechd−1(cid:0)˜ρj,t

(cid:1). Consequently, the mapping function for ˜θj,t is given by

which implies a jacobian matrix equals to

0
where D ( ˜σj,t) = diag (exp (˜σj,i,t) , i = 1, . . . , d) and J j
The score of the j–th component mixture distribution can be partitioned in ∇pj (θj,t) =
pj (θj,t) =

(cid:0)˜ρj,t
(cid:1) is deﬁned in Creal et al. (2012).
pj (θj,t) , i = 1, . . . , d(cid:1)(cid:48)

0 D ( ˜σj,t)
0

, where ∇µ

(cid:48)
pj (θj,t)

, ∇σ

pj (θj,t)

,∇σ

,∇ρ

J j

(29)

0

ρ

(cid:48)

(cid:16)∇µ
(cid:16)∇σi

(cid:17)(cid:48)

pj (θj,t)
and ∇ρ

pj (θj,t) , i = 1, . . . , d



Λj :=

J j(cid:0)µj,t, ˜σj,t, ˜ρj,t

µj,i,t = µj,i,t,

∀i = 1, . . . , d

ρ

0

0

(cid:1)

(cid:1) ,

(cid:1) =

ρj,t = Λj
ρ

∀i = 1, . . . , d

 ,

σj,i,t = exp (σj,i,t) ,

(cid:0)˜ρj,t
Idd
(cid:0)˜ρj,t
(cid:48)(cid:17)(cid:48)
pj (θj,t) = (cid:0)∇µi
pj (θj,t) , i = 1, . . . , d, i < l < d(cid:1)(cid:48)
pj (θj,t) =(cid:0)∇ρil
(cid:0)yt − µj,t
(cid:1)
(cid:1)(cid:17)
(cid:16)(cid:0)yt − µj,t
(cid:0)yt − µj,t
(cid:0)yt − µj,t

(cid:1)(cid:48)
(cid:17) − R−1

j,t Ui,lR−1
j,t D−1
j,t R−1

j,t vj,t
j,t ιiι(cid:48)

(i,l),j,t,

Kj,i,t

and

j,t

iΣ−1
∇µi
pj (θj,t) = ι(cid:48)
(cid:16)
pj (θj,t) = −σj,i,t − 1
∇σi
j,tR−1
∇ρil
v(cid:48)
pj (θj,t) =
j,t − D−1
j,t D−1
j,t R−1
iD−1

2

(28)

(30)

(31)

(32)

(cid:1), ιi is a vector of

where Kj,i,t = −D−1
zeros with 1 at its i–th element and Ui,l is a matrix of zeros except for its (i, l)–th element which is

j,t , vj,t = D−1

j,t ιiι(cid:48)

iD−1

j,t

one.

In a multivariate context, the role of the tail dependence implied by the joint distribution is of primary

importance, see e.g. McNeil et al. (2015). The multivariate Student–t distribution is usually employed

to deal with the tail dependence and the fat tails that usually characterise the data, especially in the

ﬁnancial literature. In out framework, we can assume that yt is conditionally distributed according

14

to a mixture of multivariate Student–t distributions with j–th component given by

pj (yt|θj,t) =

Γ

(cid:16) ζj,t+d

(cid:17)(cid:104)

2

(cid:1)(cid:48)

(cid:0)yt − µj,t
(cid:16) ζj,t
(cid:17)

(ζj,tπ)

2

1 + 1
ζj,t

Γ

j,t

Σ−1
2 |Σj,t|1/2

d

(cid:0)yt − µj,t

(cid:1)(cid:105)− ζj,t+d

2

,

(33)

where µj,t is a vector of location parameters, ζj,t is the shape parameter and Σj,t is a proper symmetric

positive deﬁnite scale matrix. As for the multivariate Gaussian case, it is convenient to decompose

Σj,t in

(cid:1) is a diagonal matrix containing the individual conditional scale

Σj,t = Ψj,tRj,tΨj,t,

(34)

, and Rj,t

is the correlation matrix associated with the

j–th mixture component. Consequently, the j–th vector of parameters at time t is given by

θj,t =
deﬁne the reparametrised vector of parameters ˜θj,t =

j,t, ζj,t

˜µ(cid:48)
j,t, ˜ψ

(cid:48)
j,t, ˜ρ(cid:48)

j,t, ˜ζj,t

. Following the same arguments of the multivariate Gaussian case, we can

, as well as the mapping

(cid:16)

(cid:17)(cid:48)

where Ψj,t = diag(cid:0)ψ(cid:48)
(cid:17)(cid:48)

(cid:16)

j,t, ψ(cid:48)
µ(cid:48)

j,t, ρ(cid:48)

j,t

(cid:48)
parameters ψj,t = (ψj,i,t, i = 1, . . . , d)

function

Λj :=



with associated jacobian matrix given by

J j(cid:16)

µj,t, ˜ψj,t, ˜ρj,t, ˜ζj,t

(cid:17)

=

∀i = 1, . . . , d

,

c > 0

µj,i,t = µj,i,t,

∀i = 1, . . . , d

ψj,i,t = exp

= Λj
ρ

ρj,t

ζj,t

= exp

+ c,

,

(cid:17)

(cid:16) ˜ψj,i,t
(cid:0)˜ρj,t
(cid:1)
(cid:17)
(cid:16)˜ζj,t
0 D(cid:16)˜θj,t

0

Idd

0

0

0

0



(cid:17)

J j

ρ

0

0

(cid:0)˜ρj,t

(cid:1)

0

exp

0

0

0

(cid:16)˜ζj,t

(35)

(36)

 .

(cid:17)

Note that, the choice of the scalar c may inﬂuences the existence of the moments of the

conditional distribution of yt,

indeed,

if the existence of the second conditional moment is

15

(cid:16)∇µ

(cid:17)(cid:48)

and

(cid:48)

(cid:17)(cid:48)

, where

pj (θj,t)

,∇ρ

pj (θj,t)

pj (θj,t) =

(cid:48)

(cid:16)∇σi

,∇σ

(cid:48)
pj (θj,t)

pj (θj,t) , i = 1, . . . , d

,∇ζ
pj (θj,t)
and ∇ρ

required, the condition c > 2 should be imposed. The score of the j–th component mixture
distribution can be partitioned in ∇pj (θj,t) =
∇µ
, ∇σ

pj (θj,t) = (cid:0)∇µi
pj (θj,t) , i = 1, . . . , d(cid:1)(cid:48)
(cid:0)∇ρil
pj (θj,t) , i = 1, . . . , d, i < l < d(cid:1)(cid:48)
(cid:0)yt − µj,t
(cid:1)
(cid:16)(cid:0)yt − µj,t
(cid:1)(cid:48)
iΣ−1
∇µi
pj (θj,t) = zj,tι(cid:48)
(cid:17) − R−1
(cid:16)
pj (θj,t) = −σi,j,t − zj,t
∇σi
2
(cid:18) ζj,t
(cid:19)
(cid:19)
(cid:18) ζj,t + d
j,t Ui,lR−1
j,tR−1
∇ρil
v(cid:48)
pj (θj,t) = zj,t
∇ζ
− 1
(1+rj,t) , rj,t = (cid:0)yt − µj,t
(cid:1)(cid:48)
pj (θj,t) =
2
2
Σ−1
iΨ−1
j,t ,  (·) is the digamma function and ιi and Ui,l are

(cid:1)(cid:17)
(cid:18)
(cid:1), vj,t = Ψ−1

(cid:0)yt − µj,t
(cid:20)
(cid:0)yt − µj,t

(cid:21)
(cid:1), Ki,j,t =

− (ζj,t + d) rj,t
(ζj,t + rj,t) ζj,t

(cid:0)yt − µj,t

j,t R−1

j,t Ψ−1

j,t ιiι(cid:48)

− d
2ζj,t

pj (θj,t) =

log

1 +

,

(40)

(37)

(38)

(39)

1
2



j,t vj,t



rj,t
ζj,t

j,t

j,t

j,t

2

Ki,j,t

(i,l),j,t

(cid:19)

where zj,t = ζj,t+d
j,t − Ψ−1
−Ψ−1
j,t Ψ−1
deﬁned under equation (30).

j,t R−1

j,t ιiι(cid:48)

iΨ−1

Since the number of parameters for the multivariate DAMM speciﬁcations may became very large

when d growths, resulting in longer estimation time and higher computational eﬀorts, we can

decide to employ a copula speciﬁcation for the conditional distribution of yt, and exploit the two

step estimation procedure for conditional copulas detailed in Patton (2006). Here, we present the

DAMM speciﬁcation with t–copula mixture components and recover the mixture of Gaussian copulas

(cid:48)
speciﬁcation as a special case. Let ut = (ui,t, i = 1, . . . , d)

be the vector collecting the Probability

Integral Transformations (PITs) of yi,t,

i = 1, . . . , d according to their marginal distributions

i = 1, . . . , d. In our context, the marginal distributions are freely deﬁned, for example

(cid:0)yi,t|ηi,t

(cid:1) ,

fi

each fi can be represented by a proper univariate DAMM speciﬁcation. Exploiting the Sklar

(1959)’s Theorem we can deﬁne the conditional density distribution of yt as the product between
the conditional density distribution of the copula c (ut|∆t, ζ) and the conditional marginal density
distributions. Under the DAMM speciﬁcation with t–copula mixture components we assume that

c (ut|∆t, ζc) =

ωj,tcT

(cid:0)ut|Rj,t, ζc

j

(cid:1) ,

J(cid:88)

j=1

16

(41)

where ∆t =(cid:0)vechd (Rj,t)

given by

cT

(cid:48)

, j = 1, . . . , J(cid:1)(cid:48)
(cid:1) =
(cid:0)ut|Rj,t, ζc

j

, ζc =

(cid:16) ζc

Γ

j +d
2

(cid:17)

ζc
j , j = 1, . . . , J

(cid:16)
(cid:17)d−1(cid:18)
(cid:17)
(cid:16) ζc
(cid:16) ζc+1
(cid:17)d(cid:81)d

j
2

Γ

(cid:18)

1 +

j,tR−1
x(cid:48)
j,t xj,t
ζc
j,t

(cid:19)
(cid:19)− ζc

j

and cT (ut|·) is the t–copula density

,

(42)

+d

(cid:48)
where xt = (xj,i,t, i = 1, . . . , d)

1 +
(·) is the cumulative density function
j degree of freedom. It is worth remarking that c (ut|·)
is a mixture of copulas, and that mixture of copulas are copulas themselves, see e.g. Durante and

ζc
j
of a standard Student–t distribution with ζc

(ui,t), where Tζc

i=1

2

|Rj,t|1/2Γ
, and xj,i,t = T −1

x2
j,i,t
ζc
j

2

j

Sempi (2015). Similarly to the previous multivariate cases, we can deﬁne ρj,t = vechd (Rj,t) and,

(cid:16)˜θj,t

since the only mixture component time–varying vector of parameters is ρj,t, we can set θj,t = ρj,t
j (·) deﬁned in equation (26) in order to deﬁne
and consequently employ the mapping function Λρ
θj,t = Λρ
j
∇ρ

(cid:17)
pj (θj,t, ζj) =(cid:0)∇ρil

In this case, the jacobian matrix is given by J j

pj (θj,t, ζj) , i = 1, . . . , d, i < l < d(cid:1)(cid:48)
(cid:16)

, where

(cid:0)˜ρj,t
(cid:1), and the score vector by
(cid:17) − R−1

(43)

j,tR−1
x(cid:48)

j,t Ui,lR−1

∇ρil
pj (θj,t, ζj) =

j,t xj,t

(i,l),j,t,

ρ

.

ζj + x(cid:48)

ζj + d
j,tR−1

j,t xj,t

where we note that, for ζj → ∞ we recover the multivariate Gaussian case. It is worth adding that,
for this DAMM speciﬁcation, the j–th mixture components parameter ζc
j is not allowed to evolve

over time since the score of the t–copula density with respect to ζc

j is not available in closed form
and requires a step of numerical integration. This limitation derives from the way the parameter ζc
j

enters into the conditional t–copula density function reported in equation (42).

4. Simulation studies

To demonstrate the ﬂexibility of DAMMs to represent complicated nonlinear dynamics for the

means, variances and correlations of random variables, we report four simulation studies. In the ﬁrst

experiment we focus on the ability of DAMMs to approximate the ﬁrst two conditional moments as

well as the conditional distribution of a DMM speciﬁcation similar to that of Gerlach et al. (2000). In

17

the second experiment we focus on the correlation dynamic of a bivariate stochastic vector reporting

an experiment similar the study conducted by Engle (2002), while in the third experiment we focus

on the ability of DAMMs to adapt to changes in the conditional mixture composition. Finally, in the

last experiment we focus on the cost, in terms of ﬁltering precision, of misspeciﬁcation within various

DAMM speciﬁcations.

4.1. DAMMs as ﬁlters for Stochastic DMMs

We aim to approximate the ﬁrst two conditional moments as well as the conditional distribution

generated by the model

yt ∼ ω1,tN(cid:0)yt|µ1,t, σ2

1,t

(cid:1) + ω2,tN(cid:0)yt|µ2,t, σ2
(cid:16)

(cid:17)

where ω1,t =

j,t = exp

˜σ2
j,t

, for j = 1, 2, and

2,t

(cid:1)
iid∼ N(cid:0)εω
iid∼ N(cid:0)εµ1
iid∼ N(cid:0)εσ1
iid∼ N(cid:0)εµ2
iid∼ N(cid:0)εσ2

t+1|0, 1.00(cid:1)
t+1|0, 0.02(cid:1)
t+1|0, 0.04(cid:1)
t+1|0, 0.06(cid:1)
t+1|0, 0.08(cid:1) ,

εω
t+1

εµ1
t+1

εσ1
t+1
εµ2
t+1

εσ2
t+1

1

t+1,

1+exp(−˜ωt) , ω2,t = 1 − ω1,t and σ2
˜ωt+1 = −0.003 + 0.99˜ωt + εω
µ1,t+1 = 0.09 + 0.97µ1,t + εµ1
t+1,
1,t+1 = −0.001 + 0.98˜σ2
1,t + εσ1
˜σ2
µ2,t+1 = −0.04 + 0.98µ2,t + εµ2
t+1,
2,t + εσ2
˜σ2
2,t+1 = 0.004 + 0.99˜σ2

t+1,

t+1,

E (yt|θt) = ω1,tµ1,t + ω2,tµ2,t
Var (yt|θt) = ω1,tσ2
1,t + ω2,tσ2

(cid:17)(cid:48)

(cid:16)

(44)

(45)

(47)

where all the innovations are mutually independent for all t. We label this model SDDM. According
to (44) we have that the conditional mean E (yt|θt) and the conditional variance Var (yt|θt) of yt are

2,t + ω1,tµ2

1,t + ω2,tµ2

2,t − (ω1,tµ1,t + ω2,tµ2,t)2 ,

(46)

where θt =

ωj,t, µj,t, σ2

j,t, j = 1, 2

. In order to approximate the ﬁrst two conditional moments of

(44) we specify a DAMM speciﬁcation with J = 2 Gaussian components. Formally, the approximating

model for (44) is

yt ∼ ω1,tN(cid:0)yt|µ1,t, σ2

(cid:1) + ω2,tN(cid:0)yt|µ2,t, σ2

1,t

(cid:1) ,

2,t

18

where ω1,t =

1+exp(−˜ωt) , ω2,t = 1 − ω1,t , and σ2

1

˜ωt+1 = κω + αω

exp (−˜ωt)

(1 + exp (−˜ωt))2

ω1,tp1

(cid:16)

(cid:17)

where pj

yt|µj,t, σ2

j,t

j,t = exp

(cid:16)
(cid:0)yt|µ1,t, σ2
(cid:16)

yt|µ1,t, σ2

p1

1,t

1,t

˜σ2
j,t

(cid:17)
(cid:1) − p2
(cid:17)

, for j = 1, 2, and

(cid:0)yt|µ2,t, σ2
(cid:16)

2,t

(cid:1)

yt|µ2,t, σ2

2,t

+ ω2,tp2

(cid:17) + βω ˜ωt

(48)

is the density of a Gaussian random variable with mean µj,t and variance σ2

j,t,

for j = 1, 2, evaluated at yt. The j–th dynamics for the conditional mean and the reparametrised

conditional variance are the reported in equation (21), setting J = 2.

(cid:16)

(cid:17)

To perform our experiment we simulate a path of length T = 10000 for θt from (45), then, for

each t = 1, . . . , T , we simulate from (44) B = 1000 pseudo–observations. Finally we estimate on each

series of pseudo–observations y(b) =

y(b)
1 , . . . , y(b)

T

, for b = 1, . . . , B the two Gaussian components

DAMM speciﬁcation detailed in Subsection 3.1. Then, for each estimated model, we evaluate the

implied conditional mean and conditional variance at each point in time t = 1, . . . , T .3 We benchmark

the DAMM with two Gaussian components with the Markov Switching AR(1)–GARCH(1,1) of Haas

(2006) (MSARGARCH, henceforth) with two regimes deﬁned by

(cid:12)(cid:12)(cid:12) (St = s,Ft−1) ∼ N (0, 1) ,

yt − µs,t

σs,t

where

µs,t = ¯µs + φsyt−1

σ2
s,t = ωs + αsz2

s,t−1 + βsσ2

s,t−1,

(49)

(50)

(51)

where zs,t = yt − µs,t and |φs| < 1, ωs > 0, αs + βs < 1, αs > 0, βs > 0 for s = 1, 2 are imposed
to preserve weak stationarity of the process and to ensure the positiveness of the second conditional

moment of yt. In equation (49) St represents an integer valued stochastic variable deﬁned on the
discrete space {1, 2} that follows a ﬁrst order Markov chain with transition probability matrix

3The ﬁrst two conditional moments of DAMM have the same formulation of (46). However, contrary to SDMM, in

the context of DAMM conditioning on θt is redundant since θt if fully available at time t − 1 and hence θt ∈ Ft−1.

19

Q = {qlk}, where qlk = P (St = k|St−1 = l) is the probability that state k is visited at time t
(cid:48)
given that at time t − 1 the chain was in state l, and initial probabilities vector δ = (δs, s = 1, 2)
,
δs = P (S1 = s), i.e., the probability of being in state s at time 1, see e.g. Hamilton (1989) and Dueker
(1997). Conditional on Ft−1, the distribution of yt is a mixture of two Gaussian distributions

yt|Ft−1 ∼ P (St = 1|Ft−1)N(cid:0)yt|µ1,t, σ2

(cid:1) + P (St = 2|Ft−1)N(cid:0)yt|µ2,t, σ2

(52)
where P (St = s|Ft−1) for s = 1, 2, are the predicted probabilities evaluated using the Hamilton
ﬁlter, see e.g. Fr¨uhwirth-Schnatter (2006). Further comparative results are reported in terms of a

1,t

2,t

(cid:1) ,

static mixture model with two Gaussian components estimated on the simulated data using a ﬁxed

moving window of K = 100 observations, labelled MMR. Speciﬁcally, at each t = K, . . . , T the

(cid:16)

(cid:17)

static mixture model with two Gaussian components is recursively estimated using the observations
y(b)
t−K+1, . . . , y(b)

, for b = 1, . . . , B. The implied mean, variance and mixture composition delivered

t

from each static mixture model is stored for each t = K, . . . , T and b = 1, . . . , B and compared versus

the true quantities generated from the SDMM speciﬁcation. The ﬁrst K means, variances and mixture

compositions of the MMR speciﬁcation are not available and are excluded from the comparative

analysis. The MMR and the MSARGARCH models are estimated exploiting the Expectation–

Maximisation algorithm of Dempster et al. (1977), where for the MSARGARCH model part of the

E–step is maximised numerically, see e.g. Zucchini and MacDonald (2009). Comparative results are

given in terms of Mean Absolute Error (MAE) and the Mean Square Error (MSE) between the true

conditional mean, variance and mixture composition generated from the SDMM speciﬁcation and

those delivered by the DAMM, MSARGARCH and MMR models. To investigate the performance

of the DAMM speciﬁcation to approximate the conditional distribution implied by the SDMM, we

also compute the Average Kullback Leibler (AKL) divergence between the true conditional density

reported in equation (44) and that estimated by the DAMM, MSARGARCH and MMR models. The
AKL divergence for model m ∈ {DAMM, MSARGARCH, MMR} for the b–th path is given by

AKL(b) = T −1

(cid:90)

T(cid:88)

(cid:60)

t=1

pm(cid:16)

p (yt|θt)
yt|ˆθ

(b)
m,t

(cid:17) p (yt|θt) dyt,

log

20

(53)

time t and pm(cid:16)

(cid:17)

yt|ˆθ

(b)
m,t

where p (yt|θt) represents the true density of the SDMM speciﬁcation reported in equation (44) at

represents the density of model m with estimated ﬁltered parameters ˆθ

(b)
m,t

at time t for the b–th simulated series.
Table B.1 reports the median MSE and MAE for E (yt|θt) and Var (yt|θt) as well as the median AKL
between the true and estimated conditional distributions for the DAMM, MSARGARCH and MMR

models. Comparative results are reported relative to the MSARGARCH. We note that the DAMM

with two Gaussian components reports lower MSE and MAE for the conditional mean variance and

mixture composition conﬁrming its superior ﬁltering ability versus the MSARGARCH and MMR

models. Looking at the last column of Table B.1, we also note that the median AKL divergence

between the true and the estimated conditional densities of the DAMM speciﬁcation is substantially

lower than those evaluated according to the MSARGARCH and MMR models. This result suggests

that the DAMM speciﬁcation is more adequate to approximated the conditional densities implied by

a SDMM speciﬁcation and conﬁrms the previous ﬁndings of Koopman et al. (2015) for the DAMM

speciﬁcation here considered. To conclude our analysis, in Figure A.1 we report the real as well as

the median across the B estimates for the conditional mean, the conditional variance and the mixture

weight at each point in time t. We note that, even if the estimated model is highly misspeciﬁed, the

DAMM is able to accurately represent the dynamic of the ﬁrst two conditional moments generated

from the SDMM reported in the ﬁrst and second panels of Figure A.1, respectively. Furthermore,

also the mixture composition dynamics reported in the third panel of Figure A.1 is accurately

approximated by the DAMM speciﬁcation.

It is worth stressing that, in this MC experiment, DAMM are found to be able to approximate

the conditional mean and the conditional variance reported in equation (46), and not the mixture

components parameters dynamic reported in equation (45). We like to emphasise that the processes
{µj,s, s > 0} and {˜σj,s, s > 0},
mixture composition is highly shifted in favour of a particular component, this because, during those

j = 1, 2 cannot be properly estimated during periods when the

periods, most of the data are generated by the component with higher probability. Consequently, no

relevant information is contained in the new data in order to update the parameters of the component

21

with low weight in the mixture. As stated before, these kind of logical reasonings are quite neglected

in the literature and most of the available models do not consider the possibility that, during some

periods, they cannot update part of the latent processes. On the contrary, as previously detailed,

DAMM naturally incorporates a rationale mechanism that addresses this particular issue.

4.2. Time varying correlations

Our experiment is designed similarly to that of the study conducted by Engle (2002) and Creal

et al. (2012). Speciﬁcally, we simulate B = 500 time series of length T = 1000 from a bivariate

Gaussian distribution with unit variance and time–varying correlation ρt. The dynamics we impose

to the correlation parameter are

• Constant: ρt = 0.9
• Sine: ρt = 0.5 + 0.4 cos (2πt/200)
• Fast Sine: ρt = 0.5 + 0.4 cos (2πt/20)
• Step: ρt = 0.9 − 0.5 (t > 500)
• Ramp: ρt = mod (t/200)/200
• Model1: ρt = exp (˜ρt) / [1 + exp (˜ρt)] where ˜ρt = −0.4 (1 − 0.99) + 0.99˜ρt−1 + 0.14ηρ
t ,

N (0, 1)

t ∼
ηρ

• Model2: ρt = ωtρ1,t + (1 − ωt) ρ2,t where ρi,t = exp (˜ρt) / [1 + exp (˜ρt)], ˜ρi,t = ¯ρi (1 − 0.99) +
−1,

i = 1, 2, and ¯ρ1 = −0.4, ¯ρ2 = 0.4, where ωt = [1 + exp (˜ωt)]

0.99˜ρi,t−1 + 0.14ηρi
t ,
˜ωt = 0.98˜ωt−1 + ηω
t and ηρ1, ηρ2, ηω

t are iid N (0, 1).

We estimate by Maximum Likelihood the DAMM with two bivariate Gaussian mixture components to

each series of simulated data. Consequently, we evaluate the ability of the model to track the dynamic

correlation using the MAE and the MSE between the ﬁltered and the simulated dynamic. We also

specify the two constraint DAMM versions DAMM–¯ρ and DAMM–¯ω. The DAMM–¯ρ speciﬁcation is

22

deﬁned as the DAMM but with constant state dependent correlations, i.e. ρj,t = ρj,

j = 1, 2,

while the DAMM–¯ω is again deﬁned as the DAMM but with static mixture composition,

i.e.
∀t. For comparative purposes we benchmark the DAMM model with the Dynamic
Conditional Correlation (DCC) model of Engle (2002) and to the Exponentially Weighed Moving

ωt = ω,

Average (EWMA) model deﬁned as

Qt = λQt−1 + (1 − λ) yt−1y(cid:48)

t−1

q11,tq22,t,

√
= q12,t/

ρEWMA
t

(54)

(55)

where qij,t is the (i, j)–th element of Qt and λ is set equal to 0.96, Q1 is ﬁxed as the empirical

unconditional correlation of the series. For the DAMM speciﬁcation we impose the mixture means

and variances to be constant and centered at the values µj,t = 0 and σj,t = 1 for j = 1, 2 and

t = 1, . . . , T . Similar constraints are imposed to the DCC model. Table B.2 reports the median

MAE and the median MSE, across the B replications, for the three models and the seven correlation

patterns. The results are presented relative to the DCC model. We note that the DAMM speciﬁcation

is preferred versus the considered alternatives in every case. More precisely, the unrestricted DAMM

speciﬁcation is preferred for the Sine, FastSine, Ramp and Model2 cases, the DAMM–¯ρ for the Const

and Step, while the DAMM–¯ω when the Model1 speciﬁcation is assumed for the evolution of the

conditional correlation. Generally, we found the DAMM speciﬁcations outperform the DCC and the

EWMA models both under the MAE and MSE criterions.

4.3. Time varying mixture composition

Our third simulation experiment focuses on the ability of DAMMs to model the dynamic mixture

composition generated according to several patterns. To this end we specify a mixture of two

univariate Gaussian distributions with ﬁxed means and variances, i.e. our DGP is of the form

yt ∼ ωtN (yt| − 4, 6) + (1 − ωt)N (yt|1, 3)

(56)

where ωt evolves according to one of the following patterns:

23

• Constant: ωt = 0.9
• Sine: ωt = cos (2πt/200)
• Fast Sine: ωt = cos (2πt/20)
• Step: ωt = 0.9 − 0.5 (t > 500)
• Ramp: ωt = mod (t/100)/100
• Model1: ωt = [1 + exp (˜ωt)]
• Model2: ωt = [1 + exp (˜ωt)]

−1 where ˜ωt = −0.015 + 0.98˜ρt−1 + 0.1ηω
t ,
−1 where ˜ωt = −0.015 + 0.98˜ρt−1 + 0.5ηω
t ,

t ∼ N (0, 1)
ηω
t ∼ N (0, 1).
ηω

Model1 and Model2 are nonlinear ﬁrst order autoregression with diﬀerent standard deviations

assumed for the innovations. According to the selected values of the innovation standard deviations,

the ωt process turns out to evolve more smoothly in the interval (0, 1) for Model1, and to display

abrupt changes from 0 to 1 for Model2. We simulate T = 1000 observations from (56) assuming

that ωt evolves according to the seven considered patterns. Then we estimate the DAMM with

two Gaussian components to the simulated observations and we store the ﬁltered series for ωt. The

procedure is repeated B = 500 times. We compare the DAMM ﬁltered dynamics for the mixture

composition parameter ωt with those delivered by a two regime Markov Switching model with time–

invariant Gaussian distributions in each regime (MS), and with the MMR model detailed in the ﬁrst

simulation experiment. For all the considered models, the values of the means and the variances of

each Gaussian component distribution are ﬁxed to the true values, i.e. for the DAMM speciﬁcation
we impose µ1,t = −4, µ2,t = 1, σ2
median MAE and the median MSE, across the B replications, for the three models and the seven

2,t = 3 for all t = 1, . . . , T . Table B.3 reports the

1,t = 6 and σ2

patterns for ωt. The results are presented relative to the MS model. Similarly to the previously

reported correlation study, we found that the DAMM speciﬁcation reports superior results for all the

patterns assumed for the mixture composition parameter ωt. The only exception is when ωt follows

the “FastSine” dynamic where the MS model marginally outperfoms the DAMM.

24

4.4. The costs of a wrong parametrisation for the conditional correlations dynamics

In our last simulation study we investigate the consequences of estimating a misspeciﬁed model

to the dynamic conditional correlation of a four dimension random variable. Speciﬁcally, we specify

four Data Generating Processes which only diﬀers for the implied conditional correlation dynamic.

The experiment proceeds sampling B = 500 series of length T from one of the four considered DGPs,

assuming that it is the true one, and then estimating the four DGPs on the simulated data. The

experiment is repeated four times assuming at each time a diﬀerent true DGP between the ones

considered. We consider the following general parametric assumption for the conditional distribution
of yt ∈ (cid:60)4,

yt ∼ ωtN (0, R1,t) + (1 − ωt)N (0, R2,t) ,

(57)

where Rj,t, j = 1, 2 are full correlation matrices. The four DGPs are deﬁned as

• DGP1: ωt and Rj,t,

∀i = 1, 2 are updated using the score of the conditional distribution of

yt as detailed in Sections 2 and 3.
• DGP2: equal to DGP1 but ωt = ω
• DGP3: equal to DGP1 but Rj,t = Rj,
• DGP4: assumes ωt = ω and Rj,t = Rj,

∀j = 1, 2

∀j = 1, 2.

Since the marginal distribution of the j–th component of the random variable yt

is standard

Gaussian, the model implied conditional correlation of yt is simply the averages across the correlations
of the mixture components with weights ωt and (1 − ωt), and it is indicated with Rh
t , for h ∈
{DGP 1, DGP 2, DGP 3, DGP 4}. We consider three diﬀerent sample sizes: small (T = 500), medium
(T = 1000) and moderately large (T = 2000). Parameters values are ﬁxed similar to that obtained in

the empirical application assuming high persistence for the correlation matrices Ri,t and the mixture

composition parameter ωt. Results are given in terms of the average Frobenius norm of the matrix
ˆRk|h
t − Rh

represents the estimated implied correlation matrix at time t assuming the

t , where ˆRk|h

t

25

DGP k, when the true DPG is h, i.e.

¯fh|k = T −1

(cid:118)(cid:117)(cid:117)(cid:116) 4(cid:88)

T(cid:88)

4(cid:88)

(cid:16)

t=1

l=1

m=1

(cid:17)2

,

ˆρk|h
lm,t − ρh

lm,t

(58)

lm,t and ρh

lm,t are the (l, m)–th element of the matrices ˆRk|h

where ˆρk|h
t , respectively. Table
B.4 reports the median across the B samples for the average Frobenius norm ¯fh|k for all h, k ∈
{DGP 1, DGP 2, DGP 3, DGP 4}. The rows of Table B.4 indicate the estimated models, while the
columns indicate true DGPs from which the series have been generated. In order to facilitate the

and Rh

t

comparison, all the results are reported relative to the true DGP. We note that, when the true DGP

is DGP1, there is no loss in specifying DGP2 when the sample size is small or medium and we have

to pay about 5.5% in terms of estimate precision when the sample size is moderately large. The cost

became of the order of 13% and 21.4% if we specify DGP3 or DGP4, respectively. Diﬀerently, if the

true DGP is DGP2 and we estimate DGP1, for moderately large sample sizes, we do not pay the cost

of the misspeciﬁcation in terms of precision estimate of the conditional correlation dynamics. The

results changes if we assume either DGP3 or DGP4. In these cases the cost of misspeﬁcation increases

with the sample size. Speciﬁcally, if the true model is DGP3, we pay about 30% if we estimate one

of the other considered DGPs. Generally, we found that if the sample size is small, it is better to

not assume a highly parametrised model like DGP1, since the uncertainty in model coeﬃcients will

inﬂuence the resulting ﬁltered correlation dynamics precision. On the contrary, if the sample size is

moderately large, and the true DGP is DGP1 or DGP2, the cost of misspeciﬁcation is low. Finally,

estimating the wrong model when the true DGP is DGP3 or DGP4, has a relatively highly impact

on the precision the ﬁltered correlation dynamic.

5. Empirical application

In this section we adopt several univariate and multivariate DAMM speciﬁcations to estimate and

forecast the conditional distribution of a panel of daily ﬁnancial log returns. We consider four of the

most capitalised US ﬁrms namely: Apple Inc. (AAPL), Exxon Mobil Corp. (XOM), Wells Fargo

26

& Co. (WFC) and the General Electric Co. (GE). The data set is obtained from Datastream and

consists of 4968 observations spanning from 8th January, 1996 to 22th January, 2016 and including

several crisis episodes that aﬀected the US economy like the Savings and Loan (S&L) crisis of the

1990s, the dot–com bubble of 2000–2002 and the Global Finance Crisis (GFC) of 2007-2008. In line

with usual ﬁnancial time series stylised facts, the series display volatility clusters and a heavy tailed

unconditional empirical distribution, see e.g. McNeil et al. (2015) for an exhaustive treatment of

univariate and multivariate ﬁnancial returns stylised facts. Furthermore, evidences of time varying

second conditional moment as well as time varying correlations are found according to the ARCH

LM test and the LMC test (not reported) of Engle (1982) and Tse (2000), respectively.

5.1. In sample analysis

We compare univariate and multivariate DAMM with GARCH/DCC–type of speciﬁcations in an

in sample analysis. Speciﬁcally, we estimate the DAMM with mixtures of J multivariate Gaussian

distributions (DAMM(J)–mG), as well as with mixtures of J multivariate Student–t distributions

(DAMM(J)–mT). We also include two DAMM copula speciﬁcations. The ﬁrst assumes that the

conditional joint distribution of returns at time t is a mixture of J Gaussian copulas (DAMM(J)–

copG), while the second assumes a mixture of J Student–t copula (DAMM(J)–copT). The marginal

speciﬁcations of DAMMs with copula distributions are given by univariate DAMMs with J Student–

t distributions (DAMM(J)–uT) components. For all the considered speciﬁcations we impose that

the mean of each mixture components is constant over time, but changes across the components.

The speciﬁcations that include univariate or multivariate Student–t distributions (DAMM(J)–mT,

DAMM(J)–copT, DAMM(J)–uT) are imposed to have a constant shape parameter that changes

across the mixture components. From an unreported analysis we found that, for the considered

series, J = 2 is preferred for all the DAMM speciﬁcations, consequently, for the rest of the analysis

we only consider these kind of models avoiding to report J = 2 in the model labels. We benchmark the

proposed DAMM speciﬁcations with the GDCC model of Cappiello et al. (2006) which, similarly to

DAMMs, allows for a heterogeneous behaviour of each conditional correlation to past information. As

27

for the DAMMs we consider multivariate Gaussian (GDCC–mG) and Student–t GDCC (GDCC–mT),

as well as GDCC Gaussian copula (GDCC–copG) and Student–t copula (GDCC–copT) speciﬁcations

(Jondeau and Rockinger, 2006). The marginal speciﬁcations of the GDCC–copG and the GDCC–

copT speciﬁcations are given by univariate GARCH–T models of Bollerslev (1987). All the models

are estimated by Maximum Likelihood. The copula models are estimated exploiting the two step

Inference Function for Margins (IFM) estimator detailed in Patton (2006). The GDCC–mG model

is estimated exploiting the two step estimator detailed in Engle (2002), while the GDCC–mT is

estimated maximising the full likelihood. For all the considered models, starting values are chosen by

maximising the likelihood of their time–invariant version, such that, for example, for the DAMM(J)–

uT we estimate a static mixture of J Student–t distributions. Estimated coeﬃcients are omitted to

save space and are reported in the supplementary material accompanying the paper. R and C++

computer codes are available from the author.

5.1.1. Univariate speciﬁcations

Here we assess the adequacy of the considered univariate speciﬁcations in representing the

conditional distribution of the univariate returns series at each point in time. We compare the

DAMM–uT and the GARCH–T models that will be employed for the rest of the analysis as the

marginal speciﬁcations for the copula models, with their analogues Gaussian versions that we label

DAMM–uG and GARCH–G, respectively. In order to investigate the dynamic properties of DAMMs,

we also include in our univariate analysis constraint versions of the DAMM–uT and DAMM–uG.

Speciﬁcally, we consider models with time invariant mixture composition (¯ω), models with time
varying mixture composition and time invariant mixture components (¯θ), and static mixture models
(st). Summarising, our set of univariate models is given by Mu = {DAMM–uG, DAMM–uG–¯θ,
DAMM-uG-¯ω, DAMM-uG–st, DAMM–uT, DAMM–uT–¯θ, DAMM–uT–¯ω, DAMM–uT–st,GARCH–
G, GARCH–T}. Comparative results are given in terms of goodness of ﬁt considering the two
penalised likelihood criteria AIC and BIC and in terms of adequacy of the models speciﬁcations in

representing the dynamic features of the series. Table B.5 reports the two information criteria AIC and

28

BIC and the log likelihood evaluated at its optimum for all the considered univariate speciﬁcations.

We note that the DAMM–uT speciﬁcation reports the highest log likelihood and is preferred according

to the AIC for AAPL and GE, the GARCH–T model is always preferred according to the BIC except

for GE, where the BIC favours the DAMM–uT-¯ω speciﬁcation. We also note that, in almost every
case, static mixture models (st) as well as constraints models (¯ω, ¯θ) are suboptimal compared with

their unrestricted counterparts according to both AIC and BIC. Concerning the adequacy of the

distributional assumption of each model, we employ the same testing procedure of Diebold et al.

(1998), see also Jondeau and Rockinger (2006) and Bernardi and Catania (2015). The procedure

tests if the PITs according to the estimated conditional distributions are iid uniformly distributed

into the interval (0,1). The “iid” part of the test consists of a Lagrange Multiplier (LM) test on

the coeﬃcient of determination of an autoregression of order 20 estimated on the k–th power of the
estimated PITs. This test is labelled DGT − AR(k) for k = 1, 2, 3, 4, and is distributed according
to a χ2 (20) with a critic value of about 31.4 at the 5% conﬁdence level. The test is is useful to

investigate the presence of correlation of the k–th moment of the estimated PITs, see Diebold et al.

(1998). Table B.6 reveals the usefulness of accounting for time variation in the mixture components

and in the mixture composition. Indeed, we note that the DAMM–uT speciﬁcation is always able

to adequately model the serial dependence that characterises the second and the fourth conditional

moments of the considered series. Diﬀerently, the GARCH–G and the GARCH–T speciﬁcations

result to be not able to totally explain the conditional variance of AAPL and WFC. It is interesting

to note that, diﬀerently from the GARCH cases, where the LM test rejections occur under both the

Gaussian and the Student–t assumptions for the conditional distribution of returns, the results of the

DAMM–uG and the DAMM–uT are diﬀerent. Indeed, the LM test for the DAMM–uT speciﬁcation

suggests to accept the null of correct speciﬁcation of the second and fourth conditional moments for

all the considered series. Diﬀerently, the LM tests for the DAMM–uG speciﬁcations are against the

null for the WFC and the GE series. This apparently counterintuitive result is directly linked with

the score updating mechanism that moves the conditional variance. Indeed, as detailed in Section

2 and in Creal et al. (2013), the score updating mechanism uses the information coming from the

29

full conditional distribution, and not only that contained in its expected value as happens in the

GARCH case. This means that, if the conditional distributional assumption is appropriate, it is

more likely that also the dynamic properties of the series are properly accounted for. To conclude
the goodness of ﬁt analysis, the ﬁfth row of table B.6, named DGT − H, reports the test for the
uniform assumption of the unconditional distribution of the PITs. We employ again the same testing
procedure detailed in Diebold et al. (1998) and Jondeau and Rockinger (2006). The DGT − H test
statistic is approximately asymptotically distributed according to a χ2 (19) distribution with a critical

value of about 30.14 at a conﬁdence level of 5%. We note that, the Gaussian distribution performs

poorly in describing the conditional distribution of ﬁnancial returns, while the Student–t is clearly

more appropriate. We also found that, mixtures of Gaussian and mixtures of Student–t distributions

are generally appropriate for ﬁnancial returns if the dynamic feature of the considered series are taken

into account. Speciﬁcally, we found that models with a dynamic mixture composition perform better

than models with static mixture composition as it is possible to note comparing, for example, the

DAMM–uG and the DAMM–uG–¯ω speciﬁcations.

Figure A.2 reports the estimated conditional standard deviation and the estimated conditional

mixture composition implied by the DAMM–uT estimated on each univariate series. The mixture

composition is represented by the weights assigned to the second component of the mixture at each

point in time t. The conditional standard deviations are those implied by the conditional mixture

distribution. We also compare the conditional standard deviations implied by the DAMM–uT with

those delivered by the GARCH–T models. For each marginal model, the second mixture component

reports a higher coeﬃcient associated to the conditional score that updates the j–th Student–t

scale parameter (ψ). Estimated coeﬃcients are not reported to save space and are available in the

supplementary material accompanying this paper. These ﬁnding implies that the second component

scale parameter reacts more to the new information coming from the market. Looking at the time

evolution of the mixtures composition we note several interesting results. For example, we found that

for all the considered series, during the ﬁrst part of the sample, the mixture composition is shifted in

favour of the second component. The mixtures composition starts to change around the begin of 2004

30

that coincides with the end of the turbulent period implied by the dot–com bubble of 2000-2002. We

note that, for AAPL and XOM, the mixture composition changed sharply, while for WFC and GE

the change is more smooth. Concerning the second part of the sample, the mixture composition is

more heterogeneous between the considered series. However, for all the considered series, the begin

of the GFC implies an abrupt change in the mixture composition in favour of the second component.

5.1.2. Multivariate speciﬁcations

Similarly to the univariate analysis we compare multivariate DAMMs with GDCC models. The

in sample comparison between multivariate models is reported in terms of goodness of ﬁt considering
the AIC and the BIC. The eight speciﬁcations we consider are Mm = {DAMM–mG, DAMM–
mT, DAMM–copG, DAMM–copT, GDCC–mG, GDCC–mT, GDCC–copG, GDCC–copT}, where the
DAMM–copG and the DAMM–copT share the same univariate speciﬁcations which are DAMM–uT,

while for the GDCC copula models the univariate speciﬁcations are assumed to be GARCH–T. Table

B.7 reports the AIC and the BIC for the eight multivariate speciﬁcations we consider. Similarly to

the univariate analysis, we found that DAMMs report higher log likelihood values, and are always

preferred according to the AIC versus their GDCC counterparts. According to the rank induced

by the BIC, we found that the DAMM–gCop is preferred versus the GDCC–gCop, and that the

DAMM–mG is preferred versus the GDCC–mG. Turning into a global comparison, we found that

the DAMM–tCop reports the highest log likelihood and is preferred according to the AIC, while the

GDCC-tCop is preferred according to the BIC.

Figure A.3 reports the conditional correlations implied by the DAMM–copT and the GDCC–copT.

Conditional correlation are evaluated empirically based on 100’000 simulated draws from the joint

conditional distribution implied by the DAMM–tCop and the GDCC–copT speciﬁcations as in

Chollete et al. (2009). Similarly to the conditional standard deviations, we found that the conditional

correlations implied by the two models are quite similar. Notable diﬀerences are present in the ﬁrst

part of the sample for the pairs AAPL–WFC, XOM–WFC and AAPL–XOM, and just before the

turbulent periods of 2000–2002 and 2007–2008 for the pair XOM–GE. Generally, we found that

31

correlations between the considered asset have increased during our sample period with a remarkable

upward trend concurrently to the crisis periods experienced by the US economy.

5.2. Out of sample analysis

To verify the ability of DAMMs to accurately predict the one step ahead conditional distribution

of the considered panel of returns, we report an out of sample analysis based on a scoring rule. To this

end, the last H = 1500 observations from the 2nd February, 2010 to the end of the sample are regarded

as a validating sample and used to compare the considered models. We estimate the univariate and

multivariate speciﬁcations detailed in the in sample analysis, then we perform a rolling one step

ahead forecast of the conditional distribution of returns for the whole validating period. Models

parameters are updated each 40 observations (2 months) using a ﬁxed window. Comparative results

are given both in terms of univariate and multivariate speciﬁcations. Speciﬁcally, for each model
m ∈ (Mu,Mm), we report the sum of the predictive log scores, i.e.

log pm(cid:16)
where F is the length of the in sample period and pm(cid:16)

H(cid:88)

LSm =

s=1

(cid:17)

,

(cid:17)

yF +s|ˆθ

m
F +s

yT +s|ˆθ

m
T +s

(59)

is the one step ahead predictive
distribution of model m at time F + s conditional on the information at time F + s − 1. To further
conﬁrm our ﬁndings, we also apply the Model Conﬁdence Set (MCS) procedure of Hansen et al.

(2011) to the series of negative log scores.

4 Table B.8 reports the log scores for the univariate

speciﬁcations. We note that for AAPL and GE the model that reports the highest log score is

the DAMM–uT, for XOM the best model is DAMM-uG, and for WFC the constraints speciﬁcation

DAMM–uT–¯ω. Concerning the SSM delivered by the MCS procedure, we found that for AAPL only

4The MCS procedure is an iterative model selection algorithm that delivers the “Superior Set of Models” (SSM) for

which the null hypothesis of Equal Predictive Ability (EPA) is not rejected at a certain conﬁdence level. In our case

the “predictive ability” at each point in time F + s, for model m, is measured by (cid:96)m
m
vector of “losses” , used to test the null of EPA at each iteration is given by ˜(cid:96)

= (−(cid:96)m

F +s,

F +s = log pm(cid:16)

(cid:17)

yF +s|ˆθ
s = 1, . . . , H)

m
F +s
(cid:48)

, and the

, see Hansen

et al. (2011) for further details.

32

the DAMM-uT speciﬁcation belongs to the set, for XOM it is given by {DAMM-uG, DAMM-uT,
GARCH-T}, for WFC by {DAMM–uT,DAMM–uT-¯ω , GARCH-T} and for GE by {DAMM–uT ,
DAMM–uT-¯θ, DAMM–uT–¯ω}. Table B.9 reports the LS associated to the multivariate speciﬁcations
detailed in Subsection 5.1.2. Also in this case we found that DAMM speciﬁcations outperform

comparative GDCC speciﬁcations in terms of predictive accuracy of the one step ahead joint

conditional distribution of the considered panel of returns. Indeed, the DAMM–tCop speciﬁcation

reports a log score of about -9222, while the LS associated to the best GDCC speciﬁcation is only

-9289.971. Furthermore, according the MCS test, the SSM for the multivariate speciﬁcations is given
by {DAMM–gCop, DAMM–Mt, DAMM–tCop} and do not include any GDCC speciﬁcation. To
conclude our analysis we report an out of sample comparison between the DAMM-tCop speciﬁcation

and two of its restricted versions.

In this way we want to investigate the beneﬁts, in terms of

predictive accuracy of the joint conditional distribution of returns, of having dynamic correlations and

dynamic mixture composition. To this end, we introduce the DAMM–tCop–¯ω and the DAMM–tCop–

¯ρ speciﬁcations, where the ¯ρ and ¯ω labels have the same meaning of Section 4.2. It is worth noting that

all the three speciﬁcations are able to reproduce time variation in the second conditional moment of

yt, but with diﬀerent degree of ﬂexibility. Furthermore, since we are modeling the conditional copula

distribution of our panel of returns, the mixture weights only inﬂuence the dependence structure of

the returns series and not the means and the variances. Indeed, the marginal conditional distributions

of the series are the same for the three models and do not inﬂuence this part of the analysis. The

sum of the predictive log scores for the DAMM–tCop–¯ω and the DAMM–tCop–¯ρ speciﬁcations are

-9281.876 and -9243.246, respectively. Recalling that the sum of the predictive log scores for the

DAMM–tCop speciﬁcation is -9222.006, we found an improvement of about 60 and 21 points in terms

of log scores for the DAMM–tCop versus the DAMM–tCop–¯ω and the DAMM–tCop–¯ρ speciﬁcations.

To further investigate the diﬀerences between the considered models, in Figure A.4 we report the

one step ahead predicted correlations implied by the three DAMM copula speciﬁcations. We note

that the correlations predicted by the DAMM–tCop–¯ω (red lines) are substantially diﬀerent from

those predicted by the DAMM–tCop (black lines) and DAMM–tCop–¯ρ (blue lines) speciﬁcations.

33

Interestingly, we found that the conditional correlations for the pair XOM–GE are very similar

between those implied by the DAMM–tCop and the DAMM–tCop–¯ρ speciﬁcations. This is also true

for the pair AAPL–XOM during the subperiod 2012/01–20013/12 and for the WFC–GE pair during

the last part of the sample. The correlations for the pair XOM–WFC predicted by the DAMM–tCop–¯ρ

speciﬁcation are similar of that implied by the DAMM–tCop but display much lower variability. In all

other cases the two conditional correlations are substantially diﬀerent between the DAMM–tCop and

the DAMM–tCop–¯ρ speciﬁcations. These results suggest that, the beneﬁts of having time–variation

in the mixture composition as well as in the mixture component correlation matrices, are higher

in a fully multivariate framework, where more heterogeneity aﬀects for the dependence structure of

returns.

Indeed, in our analysis with a panel of four returns, we found that for the majority of

the cases, allowing for both time–varying mixture composition and mixture component correlation

matrices, results in diﬀerent predictions in terms of implied conditional correlation of the returns.

Probably, in a bivariate setting, the beneﬁts of having time–varying mixture composition and time–

varying mixture component correlation matrices would be much much lower in terms of ﬂexibility

of the implied conditional correlation dynamics. However, the prediction of other characteristics of

the conditional distribution, as for example the tail dependence of the data during periods of market

turmoil, can still beneﬁt from a richer model parametrisation.

6. Conclusion

In this paper we introduced a new class of Dynamic Mixture Models, named Dynamic Adaptive

Mixture Models (DAMMs). DAMMs are ﬂexible tools for mixtures of distributions that dynamically

update their composition as well as their components. The updating mechanism is based on the

score of the conditional mixture distribution exploiting the recent advances for Score Driven models of

Harvey (2013) and Creal et al. (2013). DAMMs are ﬁrst reparametrised in terms of auxiliary dynamic

parameters using an adequate mapping function, then the processes for the auxiliary parameters are

updated using the score of the reparametrised conditional mixture at each point in time. Finally,

34

the parameters of interest are found by mapping the auxiliary parameters into the proper parameter

space. DAMMs belong to the class of observation driven models (Cox et al., 1981) with the usual

consequence of having the likelihood available in closed form. Hence, DAMMs can be easily estimated

by Maximum Likelihood, see e.g. Blasques et al. (2015). A Monte Carlo experiment revels that,

the new proposed speciﬁcation is able to adequately estimate the ﬁrst two conditional moments

as well as the dynamic mixture composition generated from highly nonlinear Stochastic Dynamic

Mixture Models as well as several processes assumed for the conditional correlation and the mixture

composition of conditional random variables. In the last part of the paper, we report an empirical

application in ﬁnancial econometrics where several univariate and multivariate DAMM speciﬁcations

are estimated using a panel of ﬁnancial returns. We found that DAMMs are usually preferred versus

GARCH/DCC alternatives both in terms of in sample goodness of ﬁt, and out of sample forecast

ability of the marginal and joint conditional distribution. Indeed, we also found that, contrary to the

competing models, the DAMM speciﬁcations always belong to the Superior Set of Models delivered

by the Model Conﬁdence Set of Hansen et al. (2011) under negative Log–Score losses. Furthermore,

this holds for very high conﬁdence levels. To conclude, we found DAMM very ﬂexible and easy

to handle, we believe they could be successfully employed in other relevant scientiﬁc applications

such as graphical engineering, biology and spatio–temporal econometrics, where more complicated

alternatives are usually employed.

Acknowledgments

I would like to express my sincere thanks to Prof. Andrew Harvey, Prof. Tommaso Proietti and Prof.

Siem Jan Koopman, for their constructive comments that greatly contributed to improve the ﬁnal

version of the paper.

Appendix A. Figures

35

d
r
a
d
n
a
t
s

l
a
n
o
i
t
i

d
n
o
c

e
u
r
t

e
h
t

r
o
f

s
h
t
a
p

e
h
t

t
n
e
s
e
r
p
e
r

s
e
n

i
l

d
e
t
t
o
d

k
c
a
l
B

.

M
M
A
D
g
n

i
s
u

n
o
i
t
a
m
i
x
o
r
p
p
a
M
M
D
S

:
1
.
A
e
r
u
g
i
F

0
0
0
1

e
h
t

s
s
o
r
c
a

s
n
a
i

d
e
m

e
h
t

e
r
a

s
e
n

i
l

e
l
p
r
u
P

.
)
”
a
g
e
m
O
“
(

n
o
i
t
i
s
o
p
m
o
c

e
r
u
t
x
i
m

d
n
a

)
”
u
M
“
(

n
a
e
m

,
)
”
a
m
g
i
S
“
(

n
o
i
t
a
i
v
e
d

d
n
a

d
e
R

.
s
h
t
a
p

d
e
t
a
l

u
m

i
s

y
l
s
u
o
i
v
e
r
p

e
h
t

o
t

y
l
g
n

i

d
r
o
c
c
a

)
4
4
(

m
o
r
f

d
e
t
a
l

u
m

i
s

a
t
a
d

g
n

i
s
u
M
M
A
D
e
h
t

y
b

d
e
r
e
v
i
l
e
d

s
e
t
a
m

i
t
s
e

.
y
l
e
v
i
t
c
e
p
s
e
r

,
s
e
t
a
m

i
t
s
e

0
0
0
1

e
h
t

g
n
i
s
u

t

e
m

i
t

n

i

t
n

i
o
p

h
c
a
e

t
a

d
e
t
a
u

l
a
v
e

s
e
l
i
t
n
a
u
q
%
0
9
–
%
0
1

d
n
a
%
0
8
–
%
0
2

e
r
a

s
d
n
a
b
w
o
l
l
e
y

36

RealMedian20%−80% Bands10%−90% Bands050100150Sigma−4−2024Mu02000400060008000100000.00.20.40.60.81.0OmegaFigure A.2: Conditional standard deviations and mixture composition for the DAMM–uT speciﬁcation (black

lines) and conditional standard deviations delivered by the GARCH–T models (red lines) for the considered

panel of returns. The mixture composition is represented by the weight assigned to the second component of

the mixture at each point in time t and it is reported in the bottom ﬁgure relative to each return series. The

conditional standard deviations are those implied from the conditional mixture distribution and are reported

in the top ﬁgures relative to each return series. Blue vertical bands represent periods of recessions according

to the Recession Indicators Series available from the Federal Reserve Bank of St. Louis

37

123456AAPL0.00.20.40.60.81.012345XOM0.00.20.40.60.81.0199619982000200220042006200820102012201420162468WFC0.00.20.40.60.81.0123456GE0.00.20.40.60.81.019961998200020022004200620082010201220142016Figure A.3: Conditional linear correlation implied by the DAMM–tCop speciﬁcation (black lines) and GDCC–

tCop model (red lines) for each pair of returns. For both models the correlations are evaluated empirically

using 100’000 samples from the conditional joint distribution at each point in time t. Blue vertical bands

represent periods of recessions according to the Recession Indicators Series available from the Federal Reserve

Bank of St. Louis

38

0.00.10.20.30.40.5AAPL−XOM0.00.10.20.30.40.50.6AAPL−WFC0.10.20.30.40.50.6XOM−WFC199619982000200220042006200820102012201420160.00.20.40.60.8AAPL−GE0.00.20.40.60.8XOM−GE0.20.30.40.50.60.70.8WFC−GE19961998200020022004200620082010201220142016Figure A.4: Rolling one step ahead prediction of the conditional linear correlation implied by the DAMM–tCop

(black lines) the DAMM–tCop–¯ω (red lines) and DAMM–tCop–¯ρ (blue lines) speciﬁcations. The correlations

are evaluated empirically using 100’000 samples from the predictive conditional joint distribution at each point

in time during the validating period

39

0.20.30.40.5AAPL−XOM0.20.30.40.5AAPL−WFC0.30.40.50.6XOM−WFC20102011201220132014201520160.20.30.40.50.60.70.8AAPL−GE0.30.40.50.60.7XOM−GE0.40.50.60.7WFC−GE2010201120122013201420152016Appendix B. Tables

Spec

MAE

MSE

AKL

ωt

E (yt|θt) Var (yt|θt)

ωt

E (yt|θt) Var (yt|θt)

DAMM

0.196

0.587

0.737

0.038

0.345

0.543

0.637

MSARGARCH 1.000

1.000

1.000

1.000

1.000

MMR

1.277

1.374

1.55

1.631

1.887

1.000

2.401

1.000

1.412

Table B.1: MAE and MSE between the conditional mean, variance and mixture composition generated by the SDMM

speciﬁcation and estimated from the DAMM, MSARGARCH and MMR models. The last column reports the Average

Kullback Leibler (AKL) divergence between the conditional distribution of the SDMM speciﬁcation and the DAMM,

MSARGARCH and MMR models. The reported values are the median across the B replications. Results are presented

relative to the MSARGARCH model.

Const

Sine

FastSine

Step

Ramp Model1 Model2

Spec

MAE

DAMM

0.9278

0.9068

0.9418

0.3481

0.8606

0.9712

0.9214

DAMM–¯ρ

0.8005

0.9734

0.9428

0.2934

1.0859

1.0210

0.9650

DAMM–¯ω

0.8077

0.9884

1.0187

0.7920

1.0184

0.9532

0.9495

DCC

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

EWMA

3.9346

1.2847

1.1871

0.9959

1.1100

1.0633

1.0528

MSE

DAMM

1.1599

0.8353

0.9249

0.2681

0.7543

0.9448

0.8789

DAMM–¯ρ

0.8223

0.9159

0.9224

0.2293

1.0699

1.0090

0.9385

DAMM–¯ω

0.7075

0.9241

1.0211

0.6887

0.9884

0.9106

0.8951

DCC

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

EWMA

15.3404

1.4543

1.4022

1.0287

1.2867

1.1811

1.1754

Table B.2: MAE and MSE for the estimated conditional correlation dynamic for the DAMM, DCC and EWMA

models for seven diﬀerent patterns. The reported values are the median across the B replications. The results are

presented relative to the DCC model.

40

Spec

Const

Sine

FastSine

Step

Ramp Model1 Model2

MAE

DAMM 0.9951

0.84

1.0005

0.2979 0.7094 0.8832

0.6451

MS

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

MMR

2.7178

1.4333

1.317

0.289

1.246

0.9727

1.0816

MSE

DAMM 0.5232 0.7966

1.0037

0.1566 0.6376 0.7966

0.5091

MS

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

1.0000

MMR

4.0257

1.7442

1.5615

0.212

1.4418

0.982

1.2349

Table B.3: MAE and MSE for the estimated ωt dynamic for the DAMM, MS and MMR models for seven diﬀerent

patterns. The reported values are the median across the B replications. The results are presented relative to the MS

model.

41

DGP1

DGP2

T

500

1000

2000

500

1000

2000

DGP1

1.000

1.000

1.000

1.155

1.133

0.965

DGP2

0.916

0.988

1.055

1.000

1.000

1.000

DGP3

1.017

1.085

1.130

1.191

1.292

1.161

DGP4

1.043

1.152

1.214

1.176

1.373

1.290

DGP3

DGP4

T

500

1000

2000

500

1000

2000

DGP1

1.248

1.234

1.292

1.481

1.502

1.486

DGP2

1.116

1.143

1.308

1.322

1.352

1.339

DGP3

1.000

1.000

1.000

1.102

1.127

1.125

DGP4

0.884

0.993

1.309

1.000

1.000

1.000

Table B.4: Medians across the B samples of the average Frobenius norm reported in Equation (58) for diﬀerent sample

sizes T . The rows indicates estimated models while the columns indicate true DGPs. All the results are relative to the

true DGP.

42

DAMM–uG

DAMM–uT

GARCH–G GARCH–T

–

¯θ

¯ω

st

–

¯θ

¯ω

st

AAPL

AIC

22862.76

22854.76

23519.24

23512.53

22712.42

22841.8

22730.53

23487.96

23042.81

22751.54

BIC

22934.38

22900.34

23577.84

LLK -11420.38

-11420.38

-11750.62

23545.08
22797.06
-11751.26 −11343.21

22900.4

22802.15

23533.54

23068.85

22784.09

-11411.9

-11354.27

-11736.98

-11517.4

-11370.77

Np

11

7

9

5

13

9

11

7

4

5

XOM

AIC

17202.44

17421.14

17219.17

17836.84

17182.6

17350.77

17188.73

17797.33

17299.23

17185.27

BIC

17274.06

17466.72

17277.77

17869.4

LLK -8590.22

-8703.57

-8600.58

-8913.42

17267.24
−8578.3

17409.37

17260.35

17842.9

17325.27

17217.82

-8666.39

-8583.37

-8891.66

-8645.62

-8587.63

Np

11

7

9

5

13

9

11

7

4

5

WFC

AIC

18446.19

18955.97

20188.08

20011.81

18398.75

18979.92

18393.5

19942.13

18534.78

18391.85

BIC

18517.81

19001.55

20246.68

20044.36

LLK -9212.09

-9470.99

-10085.04

-10000.9

18496.41
−9184.37

19038.51

18465.12

19987.71

18560.82

18424.41

-9480.96

-9185.75

-9964.06

-9263.39

-9190.93

Np

11

7

9

5

15

9

11

7

4

5

GE

AIC

18305.78

18535.34

19442.95

19434.97

18200.29

18445.04 18198.28

19243.02

18515.85

18246.59

BIC

18377.39

18580.92

19501.55

19467.53

LLK -9141.89

-9260.67

-9712.48

-9712.49

18284.93
−9087.14

18503.64

18269.9

19288.59

18541.9

18279.15

-9213.52

-9088.14

-9614.51

-9253.93

-9118.3

Np

11

7

9

5

13

9

11

7

4

5

Table B.5: AIC, BIC, Log Likelihood (LLK) and number of parameters (Np) for the DAMM-uG, DAMM-uT and

related constrained versions and GARCH-G and GARCH-T speciﬁcations for each returns series.

43

DGT − AR1
DGT − AR2
DGT − AR3
DGT − AR4
DGT-H

DGT − AR1
DGT − AR2
DGT − AR3
DGT − AR4
DGT-H

DGT − AR1
DGT − AR2
DGT − AR3
DGT − AR4
DGT-H

DGT − AR1
DGT − AR2
DGT − AR3
DGT − AR4
DGT-H

24.32

43.25a

24.15

46.91a

41.41a

14.29

28.79c

19.95

52.53a

49.38a

35.82b

35.64b

30.57c

64.49a

22.27

25.73

16.74

28.06

23.87

39.01a

24.5

42.97a

31.77b

41.92a

14.18

30.2c

19.05

16.68

49.35a

29.8c

37.19b

24.54

18.57

22.76

27.29

17.05

28.61c

11.62

DAMM–uG

DAMM–uT

GARCH–G GARCH–T

–

¯θ

¯ω

st

–

¯θ

¯ω

st

23.92

70.4a

23.93

27.31

27.32

24.28

24.25

23.64

27.2

AAPL

70.45a

678.45a

678.77a

27.88

27.91

40.32a

40.37a

79.27a

79.42a

677.19a

677.21a

18.96

23.58

22.93

80.44a

29.15c

94.52a

21.01

23.32

27.73

675.7a

39.91a

676.15a

36.25a

35.94b

29.63c

29.08c

27.56c

28.22c

36.77a

24.04

108.95a

XOM

42.56a

44.03a

41.33a

55.41a

42.16a

45.23a

43.19a

55.21a

14.11

50.59a

29.84c

36.18b

18.77

62.54a

23.82

19.79

16.03

29.45c

20.52

28.67c

459.24a

14.41

59.14a

12.63

457.98a

59.47a

29.31c

37.13b

29.27c

59.55a

511.55a

18.46

85.15a

16.54

515.26a

23.2

17.19

19.62

18.01

10.35

47.92a

51.44a

51.88a

51.61a

48.86a

50.53a

48.73a

51.24a

WFC

38.1a

200.77a

1234.35a

1181.86a

20.61

214.99a

41.22a

59a

53.6a

38.58a

41.45a

20.04

38.4a

1187.31a

53.6a

236.24a

1358.73a

1301.36a

18.46

252.61a

17.34

1311.01a

26.75

35.52b

85.92a

38.3a

19.35

69.89a

20.78

12.98

GE

23.92

22.17

24.21

24.21

24.08

22.12

23.05

24.22

20.61

109.93a

853.52a

853.52a

14.16

105.25a

15.89

829.29a

18.46

17.82

24.64

24.63

19.34

18.09

19.03

24.51

27.24

147.07a

959.28a

959.38a

19.51

154.86a

22.69

926.86a

37.2b

33.3b

22.46

26.25

64.17a

64.04a

18.25

22.95

11.77

14.75

64.23a

Table B.6: In sample Goodness–of–Fit test of Diebold et al. (1998). The apexes “a”, “b” and “c”, denote the rejection

of the null hypothesis of not signiﬁcance of the corresponding parameter, at diﬀerent conﬁdence levels 1%, 5% and 10%.

See also Jondeau and Rockinger (2006).

44

Speciﬁcation

AIC

BIC

LLK

Np

DAMM-tCop

71954.613

DAMM-gCop

71970.805

72560.115 −35884.307
-35894.403
72563.285

DAMM-Mt

72087.972

72563.259

-35970.986

DAMM-Mg

72427.49

72889.754

-36142.745

GDCC-tCop

72069.748

72297.625

-35999.874

GDCC-gCop

72256.073

72477.439

-36094.037

GDCC-Mt

72112.263

72314.097

-36025.131

GDCC-Mg

73310.633

73505.956

-36625.317

93

91

73

71

35

34

31

30

Table B.7: AIC, BIC, Log Likelihood (LLK) and number of parameters (Np) for the multivariate DAMM and the

GDCC speciﬁcations.

Speciﬁcation

AAPL

XOM

WFC

GE

DAMM-uG
DAMM-uG-¯θ

-2866.035

-2949.23

−2275.761∗
-2322.903

-2618.492

-2509.159

-2643.335

-2511.027

DAMM-uG-¯ω

-3052.224

-2364.859

-2689.309

-2577.902

DAMM-uG-st

DAMM-uT
DAMM-uT-¯θ

-3061.479
−2812.251∗
-2862.802

-2419.254
-2276.699∗

-2303.781

DAMM-uT-¯ω

-2833.06

-2281.131

DAMM-uT-st

-3052.207

-2411.813

-2778.797
-2605.368∗

-2654.574
−2603.959∗
-2767.891

GARCH-G

-2899.621

GARCH-T

-2821.322

-2307.692
-2275.877∗

-2635.302
-2606.006∗

-2618.739
−2490.477∗
-2496.078∗
-2492.675∗

-2605.363

-2567.939

-2500.099

Table B.8: Out of sample log score for all the considered univariate speciﬁcations. For each asset, the model that

reports the highest log score is indicated in bold. Asterisks represent models that belong to the Superior Set of Models

delivered by the MCS procedure with a probability higher then 95%.

DAMM-Mg DAMM-gCop DAMM-Mt DAMM-tCop GDCC-gCop GDCC-Mg GDCC-Mt GDCC-tCop

LS

-9321.838

-9228.399∗

-9224.843∗ −9222.006∗

-9289.971

-9512.197

-9346.559

-9350.887

Table B.9: Out of sample log score for all the considered multivariate speciﬁcations. The model that reports the

highest log score is indicated in bold. Asterisks represent models that belong to the Superior Set of Models delivered

by the MCS procedure with a probability higher then 95%

45

References

Ardia, D. (2008). Financial risk management with Bayesian estimation of GARCH models. Springer.

Bazzi, M., Blasques, F., Koopman, S. J., and Lucas, A. (2014). Time varying transition probabilities for

markov regime switching models.

Bernardi, M. and Catania, L. (2015).

Switching–GAS Copula Models for Systemic Risk Assessment.

1504.03733.

Billio, M., Casarin, R., Ravazzolo, F., and van Dijk, H. K. (2012). Combination schemes for turning point

predictions. The Quarterly Review of Economics and Finance, 52(4):402–412.

Billio, M., Casarin, R., Ravazzolo, F., and Van Dijk, H. K. (2013). Time-varying combinations of predictive

densities using nonlinear ﬁltering. Journal of Econometrics, 177(2):213–232.

Bishop, C. M. (2006). Pattern recognition and machine learning. springer.

Blasques, F., Koopman, S. J.,

(cid:32)Lasak, K., and Lucas, A. (2015).

In–sample conﬁdence bounds and out–

of–sample forecast bands for time–varying parameters in observation driven models. Tinbergen Institue

Discussion Paper.

Bollerslev, T. (1987). A conditionally heteroskedastic time series model for speculative prices and rates of

return. The review of economics and statistics, pages 542–547.

Capp´e, O., Moulines, E., and Ryd´en, T. (2005). Inference in hidden Markov models, volume 6. Springer.

Cappiello, L., Engle, R. F., and Sheppard, K. (2006). Asymmetric dynamics in the correlations of global equity

and bond returns. Journal of Financial econometrics, 4(4):537–572.

Casarin, R., Grassi, S., Ravazzolo, F., and van Dijk, H. K. (2015). Dynamic predictive density combinations

for large data sets in economics and ﬁnance.

Chollete, L., Heinen, A., and Valdesogo, A. (2009). Modeling international ﬁnancial returns with a multivariate

regime-switching copula. Journal of Financial Econometrics, 7(4):437–480.

46

Cox, D. R., Gudmundsson, G., Lindgren, G., Bondesson, L., Harsaae, E., Laake, P., Juselius, K., and Lauritzen,

S. L. (1981). Statistical analysis of time series: Some recent developments [with discussion and reply].

Scandinavian Journal of Statistics, pages 93–115.

Creal, D., Koopman, S. J., and Lucas, A. (2012). A dynamic multivariate heavy-tailed model for time-varying

volatilities and correlations. Journal of Business & Economic Statistics.

Creal, D., Koopman, S. J., and Lucas, A. (2013). Generalized autoregressive score models with applications.

Journal of Applied Econometrics, 28(5):777–795.

Dempster, A., Laird, N., and Rubin, D. (1977). Maximum likelihood from incomplete data via the em algorithm.

Journal of the Royal Statistical Society, 39(1):1 – 38.

Diebold, F. X., Gunther, T. A., and Tay, A. a. (1998). Evaluating density forecasts: With applications to

ﬁnancial risk management. International Economic Review, 39(4):863–883.

Dueker, M. J. (1997). Markov switching in garch processes and mean-reverting stock-market volatility. Journal

of Business & Economic Statistics, 15(1):26–34.

Durante, F. and Sempi, C. (2015). Principles of copula theory. CRC Press.

Engle, R. (2002). Dynamic conditional correlation: a simple class of multivariate generalized autoregressive

conditional heteroskedasticity models. Journal of Business & Economic Statistics, 20(3):339–350.

Engle, R. F. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of united

kingdom inﬂation. Econometrica, 50(4):987–1007.

Fei, F., Fuertes, A.-M., and Kalotychou, E. (2013). Modeling dependence in cds and equity markets: Dynamic

copula with markov-switching. Working Paper.

Frigessi, A., Haug, O., and Rue, H. (2002). A dynamic mixture model for unsupervised tail estimation without

threshold selection. Extremes, 5(3):219–235.

Fr¨uhwirth-Schnatter, S. (2006). Finite Mixture and Markov Switching Models: Modeling and Applications to

Random Processes. Springer.

47

Gerlach, R., Carter, C., and Kohn, R. (2000). Eﬃcient bayesian inference for dynamic mixture models. Journal

of the American Statistical Association, 95(451):819–828.

Gray, S. F. (1996). Modeling the conditional distribution of interest rates as a regime-switching process. Journal

of Financial Economics, 42(1):27 – 62.

Haas, M. M. (2006). S. and paolella, m. Modelling and predicting market risk with laplace–Gaussian mixture

distributions, Applied Financial Economics, 16:1145–1162.

Hamilton, J. D. (1989). A new approach to the economic analysis of nonstationary time series and the business

cycle. Econometrica, 77:357–384.

Hansen, P. R., Lunde, A., and Nason, J. M. (2011). The model conﬁdence set. Econometrica, 79(2):453–497.

Harrison, J. and West, M. (1999). Bayesian Forecasting & Dynamic Models. Springer.

Harvey, A. C. (2013). Dynamic Models for Volatility and Heavy Tails: With Applications to Financial and

Economic Time Series. Cambridge University Press.

Jaeckel, P. and Rebonato, R. (1999). The most general methodology for creating a valid correlation matrix for

risk management and option pricing purposes. Journal of risk, 2(2):17–28.

Jondeau, E. and Rockinger, M. (2006). The copula-garch model of conditional dependencies: An international

stock market application. Journal of international money and ﬁnance, 25(5):827–853.

KaewTraKulPong, P. and Bowden, R. (2002). An improved adaptive background mixture model for real-time

tracking with shadow detection. In Video-based surveillance systems, pages 135–144. Springer.

Kim, C.-J. (1994). Dynamic linear models with markov-switching. Journal of Econometrics, 60(1):1 – 22.

Kim, C.-J. and Nelson, C. R. (1999). State-space models with regime switching: classical and Gibbs-sampling

approaches with applications, volume 2. MIT press Cambridge.

Klaassen, F. (2002). Improving garch volatility forecasts with regime-switching garch. In Advances in Markov-

Switching Models, pages 223–254. Springer.

48

Koopman, S. J., Lucas, A., and Scharth, M. (2015). Predicting time-varying parameters with parameter-driven

and observation-driven models. Review of Economics and Statistics, forthcoming.

Krolzig, H.-M. (1997). Markov-switching vector autoregressions–modelling.

Statistical Inference, and

Application to Business Cycle Analysis.

McLachlan, G. and Peel, D. (2000). Finite Mixture Models. Wiley Series in Probability and Statistics, John

Wiley & Sons, New York.

McNeil, A. J., Frey, R., and Embrechts, P. (2015). Quantitative Risk Management: Concepts, Techniques and

Tools: Concepts, Techniques and Tools. Princeton university press.

Patton, A. J. (2006). Estimation of multivariate models for time series of possibly diﬀerent lengths. Journal

of applied econometrics, 21(2):147–173.

Sklar, M. (1959). Fonctions de r´epartition `a n dimensions et leurs marges. Universit´e Paris 8.

Tse, Y. K. (2000). A test for constant correlations in a multivariate garch model. Journal of econometrics,

98(1):107–127.

Xie, L., Kennedy, L., Chang, S.-F., Divakaran, A., Sun, H., and Lin, C.-Y. (2005). Layered dynamic mixture

model for pattern discovery in asynchronous multi-modal streams [video applications]. In Acoustics, Speech,

and Signal Processing, 2005. Proceedings.(ICASSP’05). IEEE International Conference on, volume 2, pages

ii–1053. IEEE.

Yu, J. (2012). A particle ﬁlter driven dynamic gaussian mixture model approach for complex process monitoring

and fault diagnosis. Journal of Process Control, 22(4):778–788.

Zucchini, W. and MacDonald, I. L. (2009). Hidden Markov models for time series: an introduction using R.

CRC press.

49

