6
1
0
2

 
r
a

 

M
6
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
5
1
2
5
0

.

3
0
6
1
:
v
i
X
r
a

Phase Retrieval from 1D Fourier Measurements:

Convexity, Uniqueness, and Algorithms

Kejun Huang, Yonina C. Eldar, and Nicholas D. Sidiropoulos

March 17, 2016

Abstract

This paper considers phase retrieval from the magnitude of 1D over-sampled Fourier mea-
surements, a classical problem that has challenged researchers in various ﬁelds of science and
engineering. It is shown that an optimal vector in a least-squares sense can be found by solving
a convex problem, thus establishing a hidden convexity in Fourier phase retrieval. It is also
shown that the standard semideﬁnite relaxation approach yields the optimal cost function value
(albeit not necessarily an optimal solution) in this case. A method is then derived to retrieve
an optimal minimum phase solution in polynomial time. Using these results, a new measuring
technique is proposed which guarantees uniqueness of the solution, along with an eﬃcient algo-
rithm that can solve large-scale Fourier phase retrieval problems with uniqueness and optimality
guarantees.

Keywords: phase retrieval, over-sampled Fourier measurements, minimum phase, auto-correlation
retrieval, semi-deﬁnite programming, alternating direction method of multipliers, holography.

1

Introduction

Phase retrieval seeks to recover a signal from the magnitudes of linear measurements [22]. This
problem arises in various applications, including crystallography [19], microscopy, and optical imag-
ing [40], due to the limitations of the detectors used in those applications. Diﬀerent types of mea-
surement systems have been proposed, e.g., over-sampled Fourier measurements, short-time Fourier
measurements, and random Gaussian, to name just a few (see [24, 36] for contemporary reviews),
but over-sampled Fourier measurements are most common in practice. Two fundamental questions
in phase retrieval are: i) is the signal uniquely determined by the noiseless magnitude measurements
(up to inherent ambiguities such as global phase); and ii) is there an eﬃcient algorithm that can
provably compute an optimal estimate of the signal according to a suitable criterion?

This paper considers the 1D phase retrieval problem from over-sampled Fourier measurements.
It is well known that there is no uniqueness in 1D Fourier phase retrieval, i.e. there are multiple
1D signals with the same Fourier magnitude. This is true even when we ignore trivial ambiguities
which include a global phase shift, conjugate inversion and spatial shift. Nonuniqueness also holds
when the support of the signal is bounded within a known range [21].
In addition, since the
phase retrieval problem is nonconvex, there are no known algorithms that provably minimize the
least-squares error in recovering the underlying signal [2].

Existing methods that attempt to resolve the identiﬁability issue include introducing sparsity
assumptions on the input signal [11, 25, 29, 31], taking multiple masked Fourier measurements [7],

1

or using the short-time Fourier transform [12,23]. Algorithmically, the most popular techniques for
phase retrieval are based on alternating projections [2, 15, 17], pioneered by Gerchberg and Saxton
[17] and extended by Fienup [15]. More recently, phase retrieval has been treated using semideﬁnite
programming (SDP) and low-rank matrix recovery ideas [6, 37]. Several greedy approaches to
phase retrieval have also been introduced such as GESPAR [3, 35]. Semideﬁnite relaxation for
phase retrieval, referred to as PhaseLift [6], is known to recover the true underlying signal when
the measurement vectors are Gaussian. However, in the case of Fourier measurements, as we are
considering here, there are no known optimality results for this approach.

Despite the apparent diﬃculty in 1D Fourier phase retrieval, we establish in this paper that
under certain conditions this problem can be solved eﬃciently and optimally in polynomial time. In
particular, we ﬁrst show that the least-squares formulation of this problem can always be optimally
solved using semideﬁnite relaxation. Namely, methods such as PhaseLift do in fact optimize the
nonconvex cost even in the case of Fourier measurements. By slightly modifying the basic PhaseLift
program we propose a new semideﬁnite relaxation whose solution is proven to be rank-one and to
minimize the error. However, due to the nonuniqueness in the problem, the solution is not in general
equal to the true underlying vector. To resolve this ambiguity, we propose a semideﬁnite relaxation
that will always return the minimum phase solution which optimizes the least-squares cost. Based
on this result, we suggest a new approach to measure 1D signals by ﬁrst transforming an arbitrary
signal into a minimum phase counterpart by simply adding an impulse, so that identiﬁability is
restored. We can then recover the input using the proposed SDP. The measurement strategy
resembles classic holography used commonly in optics [16]. Finally, we propose a very eﬃcient
iterative algorithm to recover the underlying signal without the need to resort to lifting techniques
as in the SDP approach. Our method is based on the alternating direction method of multipliers
(ADMM) [5] and is able to solve very large scale problems eﬃciently.

Comparing to existing methods that provide identiﬁability, the proposed approach is easy to
implement (both conceptually and practically), requires a minimal number of measurements, and
can always be solved to global optimality using eﬃcient computational methods.

The rest of the paper is organized as follows. We introduce the problem in more detail in
Section 2. In Section 3 we reformulate phase retrieval by changing the variable from the signal
itself to the correlation of the signal, and discuss two ways to characterize a correlation sequence,
leading to convex optimization problems. Extracting signals from a given correlation sequence,
known as spectral factorization, is brieﬂy reviewed in Section 4, where we also review the notion of
minimum phase. We then propose a new measurement system based on transforming an arbitrary
signal into a minimum phase one, via a very simple impulse adding technique, in Section 5. A
highly scalable algorithm is proposed in Section 6 to recover the signal, providing the ability to
optimally solve large-scale 1D Fourier phase retrieval problems very eﬃciently. We summarize the
proposed method in Section 7, with some discussion on how to modify the method if we know that
the sought signal is real. Computer simulations are provided in Section 8 and show superiority of
our proposed techniques both in terms of accuracy and eﬃciency. We ﬁnally conclude the paper in
Section 9.

Throughout the paper, indices for vectors and matrices start at 0, so that the ﬁrst entry of a
vector x is x0, and the upper-left-most entry of a matrix X is X00. The superscript ∗ denotes
element-wise conjugate (without transpose), and H denotes Hermitian transpose of a vector or a
matrix.

2

2 The Phase Retrieval Problem

In the phase retrieval problem, we are interested in estimating a signal x ∈ CN from the squared
magnitude of its Fourier transform. The discrete-time Fourier transform (DTFT) of a vector
x ∈ CN is a trigonometric polynomial in ω deﬁned as
Xn=0

X(ejω) =

xne−jωn,

N −1

which is periodic with period 2π. In practice it is easier to obtain samples from the continuous
function X(ejω), which leads to the M -point discrete Fourier transform (DFT) of x if we sample
at points

ω = 0,

2π
M

, ...,

2π(M − 1)

M

.

This operation is equivalent to the matrix-vector multiplication FM x, where FM is the ﬁrst N
columns of the M -point DFT matrix, i.e.,

1
φ
...

1
1
...
1 φM −1 φ2(M −1)

1
φ2
...

FM =


1

φN −1

···
···
. . .
··· φ(N −1)(M −1)

...

,




where φ = e−j2π/M . The matrix-vector multiplication FM x can be carried out eﬃciently via the
fast Fourier transform (FFT) algorithm with complexity O(M log M ), unlike the general case which
takes O(M N ) ﬂops to compute.

With this notation, our measurements are given by

where w is a noise vector and | · |2 is taken element-wise. To recover x from b we consider a least-
squares cost (which coincides with the maximum likelihood criterion assuming Gaussian noise):

b = |FM x|2 + w,

(1)

minimize

x∈CN

(cid:13)(cid:13)(cid:13)
b − |FM x|2(cid:13)(cid:13)(cid:13)

2

.

(2)

The most popular methods for solving (2) are the Gershburg-Saxton (GS) and Fienup’s algorithms.
Both techniques start with the noiseless scenario b = |FM x|2, and reformulate it as the following
feasibility problem by increasing the dimension of x to M and then imposing an additional compact
support constraint:

ﬁnd x ∈ CM

such that b = |FM x|2

xn = 0,∀n = N, N + 1, ..., M − 1.

It is easy to derive projections onto the two individual sets of equality constraints, but not both.
Therefore, one can apply alternating projections, which leads to the GS algorithm, or Dykstra’s
alternating projections, which results in Fienup’s algorithm when the step size is set to be 1 [13].

3

Due to the non-convexity of the quadratic equations, neither algorithm is guaranteed to ﬁnd a
solution; nonetheless, Fienup’s approach has been observed to work successfully in converging to
a point that satisﬁes both set of constraints. When the measurements are corrupted by noise,
Fienup’s algorithm does not in general converge, whereas an alternative interpretation of the GS
algorithm shows that it monotonically decreases the cost function of the following optimization
problem (which is diﬀerent from (2)),

minimize

x∈CN ,ψ∈CM (cid:13)(cid:13)(cid:13)

subject to |ψm| = 1,∀m = 0, 1, ..., M − 1.

2

diagn√bo ψ − FM x(cid:13)(cid:13)(cid:13)

(3)

More recently, the general phase retrieval problem has been recognized as a non-convex quadrat-
ically constrained quadratic program (QCQP), for which the prevailing approach is to use semidef-
inite relaxation [30] to obtain a lower bound on the optimal value of (2).
In the ﬁeld of phase
retrieval, this procedure is known as PhaseLift [6]. Speciﬁcally, under a Gaussian noise setting,
PhaseLift solves the following problem

minimize

X∈HN
+

M −1

Xm=0(cid:0)bm − tr(cid:8)fmf H

m X(cid:9)(cid:1)2

+ λtr{X} ,

(4)

+ denotes the set of Hermitian positive semideﬁnite matrices of size N × N , f H

where HN
m is the
mth row of FM , and the term λtr{X} is used to encourage the solution to be low-rank. Problem
(4) can be cast as an SDP and solved in polynomial time. If the solution of (4), denoted as X⋆,
turns out to be rank one, then we also obtain the optimal solution of the original problem (2) by
extracting the rank one component of X⋆. However, for general measurement vectors PhaseLift is
not guaranteed to yield a rank one solution, especially when the measurement b is noisy. In that
case PhaseLift resorts to sub-optimal solutions, for example by taking the ﬁrst principal component
of X⋆, possibly reﬁned by a traditional method like the GS algorithm. An SDP relaxation for the
alternative formulation (3) is proposed in [39], and referred to as PhaseCut.

In the next section we will show that despite the nonconvexity of (2), we can ﬁnd an optimal
solution in polynomial time using semideﬁnite relaxation. Since there is no uniqueness in 1D phase
retrieval, there are many possible solutions even in the noise free setting. Among all solutions, we
will extract the minimum phase vector that minimizes the least-squares error. We will also suggest
an alternative to the SDP formulation, based on ADMM, that will enable recovering this vector
very eﬃciently. Next we will show how any vector can be modiﬁed to be minimum phase by adding
a suﬃciently large impulse to it. This will then pave the way to recovery of arbitrary 1D signals
eﬃciently and provably optimally from their Fourier magnitude.

3 Convex reformulation

In this section we show how (2) can be optimally solved in polynomial time, despite its non-convex
formulation. Similar results have been shown in the application of multicast beamforming under far-
ﬁeld line-of-sight propagation conditions [26], and more generally non-convex QCQP with Toeplitz
quadratics [9, 27].

4

3.1 Using the auto-correlation function
Consider the mth entry of |FM x|2:

φnmxn

N −1

N −1

φ−νmx∗
ν

N −1

Xν=0

ν φ(n−ν)m

xnx∗

Xν=0
Xk=n+1−N

n

xnx∗

n−kφkm

|f H
m x|2 =

=

=

=

=

N −1

N −1

Xn=0
Xn=0
Xn=0
Xk=1−N
Xk=1−N

N −1

N −1

min(N −1+k,N −1)

φkm

Xn=max(k,0)

xnx∗

n−k

φkmrk,

where

min(N −1+k,N −1)

xnx∗

n−k,

(5)

rk =

Xn=max(k,0)

k = 1 − N, ...,−1, 0, 1, ..., N − 1,

is the k-lag auto-correlation of x. Let us deﬁne

˜r = [ r1−N ... r−1 r0 r1 ... rN −1 ]T .

We ﬁrst observe that |f H
by deﬁnition rk = r∗

m x|2, originally quadratic with respect to x, is now linear in ˜r. Moreover,

−k. Removing the redundancy, we let

r = [ r0 r1 ... rN −1 ]T ,

and write

where ˜I = diag{[ 1 2 2 ... 2 ]}, and ℜ{·} takes the real part of its argument. We can then rewrite
(2) as

|FM x|2 = ℜnFM ˜Iro ,
b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

2

(cid:13)(cid:13)(cid:13)

minimize

r∈CN

subject to r is a ﬁnite auto-correlation sequence.

The abstract constraint imposed on r in (6) is to ensure that there exists a vector x ∈ CN such
that (5) holds.
The representation in (5) of the auto-correlation sequence is nonconvex. In the next subsection
we consider convex reformulations of this constraint based on [1]. In Section 4 we discuss how to
obtain x from r in a computationally eﬃcient way.

5

(6)

3.2 Approximate characterization of a ﬁnite auto-correlation sequence

Denote the DTFT of ˜r by

R(ejω) =

N −1

Xk=1−N

rke−jωk.

Since ˜r is conjugate symmetric, R(ejω) is real for all ω ∈ [0, 2π]. The sequence ˜r (or equivalently
r) is a ﬁnite auto-correlation sequence if and only if [28]

R(ejω) ≥ 0, ∀ω ∈ [0, 2π],

(7)

which is a collection of inﬁnitely many linear inequalities. A natural way to approximately satisfy
(7) is to sample this inﬁnite set of inequalities, and replace (7) by a ﬁnite (but large) set of L linear
inequalities

In matrix form, these constraints can be written as (similar to the expression for |FM x|2 that we
derived before)

R(ej2πl/L) ≥ 0,

l = 0, 1, ..., L − 1.

where FL is the ﬁrst N columns of the L-point DFT matrix.

ℜnFL ˜Iro ≥ 0,

Using this result, we can approximately formulate problem (6) as

2

r∈CN

minimize

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)
subject to ℜnFL ˜Iro ≥ 0,

(cid:13)(cid:13)(cid:13)

(8)

with a suﬃciently large L. In practice, the approximate formulation works very well for L ≥ 20N ,
a modest (and typically a constant times) increase in the signal dimension. However, it is not
exact—one can satisfy the constraints in (8), yet still have R(ejω) < 0 for some ω.

3.3 Exact parameterization of a ﬁnite auto-correlation sequence

It turns out that it is possible to characterize the inﬁnite set of inequalities (7) through a ﬁnite
representation, via an auxiliary positive semideﬁnite matrix. One way is to use a N × N positive
semideﬁnite matrix to parameterize r [1]

rk = tr{TkX} ,∀k = 0, 1, ..., N − 1,
X (cid:23) 0,

where Tk is the kth elementary Toeplitz matrix of appropriate size, with ones on the kth sub-
diagonal, and zeros elsewhere, and T0 = I. Another way, which can be derived from the Kalman-
Yakubovich-Popov (KYP) lemma [42], uses a (N − 1) × (N − 1) matrix P to characterize r as a
ﬁnite correlation sequence

(cid:20) r0

r1:N −1

rH
1:N −1

P (cid:21) −(cid:20)P 0

0 0(cid:21) (cid:23) 0,

where r1:N −1 = [ r1 r2 ... rN −1 ]T . It can be shown that the two formulations are equivalent [10].

6

Adopting the ﬁrst characterization, we may rewrite (6) as

2

minimize
r∈CN ,X∈HN
+

subject to

(cid:13)(cid:13)(cid:13)

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

rk = tr{TkX} ,∀k = 0, 1, ..., N − 1.

(9)

It is easy to see that we can actually eliminate the variable r from (9), ending up with the PhaseLift
formulation (4) without the trace regularization. This result is proven in Appendix A.

The implication behind the above analysis is that, even though PhaseLift does not produce
a rank one solution in general1, there always exists a point in CN that attains the cost provided
by the SDP relaxation. In other words, the seemingly non-convex problem (2) can be solved in
polynomial time.

The trace parameterization based formulation (9) exactly characterizes (6), with the price that
now the problem dimension is O(N 2), a signiﬁcant increase comparing to that of (8). In Section 6
we will derive an eﬃcient alternative based on ADMM. In the next section we show how to extract
a vector x from the auto-correlation r that solves (9).

4 Spectral factorization

After we solve (6), either approximately via (8) or exactly by (9), we obtain the auto-correlation
of the optimal solution of the original problem (2). The remaining question is how to ﬁnd a vector
x that generates such an auto-correlation, as deﬁned in (5). This is a classical problem known
as spectral factorization (SF) in signal processing and control. There exist extensive surveys on
methods and algorithms that solve this problem, e.g., [34], [43, Appendix], and [9, Appendix B].
In this section, we ﬁrst derive an algebraic solution for SF, which also explains the non-uniqueness
of 1D Fourier phase retrieval, and reviews the notion of minimum phase. We then review two
practical methods for SF, which we will rely on when developing a highly scalable phase-retrieval
algorithm.

4.1 Algebraic solution
The DFT of an arbitrary signal x ∈ CN can be obtained by sampling its z-transform on the unit
circle |z| = 1. Let X(z) be the z-transform of x, which is a polynomial of order N − 1. It can be
written in factored form as

X(z) =

N −1

Xn=0

xnz−n = x0

N −1

Yn=1

(1 − ξnz−1),

(10)

where ξ1, ..., ξN −1 are the zeros (roots) of the polynomial X(z). The quadratic measurements can
similarly be interpreted as sampled from the z-transform of ˜r deﬁned as

R(z) = |X(z)|2 = X(z)X ∗(1/z∗)

N −1

= |x0|2

Yn=1

(1 − ξnz−1)(1 − ξ∗

nz).

1In fact, it has been shown that if the interior-point algorithm is used to solve an SDP, it will always generate a

solution that is of maximal rank [30].

7

As we can see, the zeros of R(z) always come in conjugate reciprocal pairs. Therefore, given R(z),
we cannot determine whether a zero ξ or its conjugate reciprocal (ξ∗)−1 is a root of X(z), which
is the reason that x cannot be reconstructed from R(z). In other words, for a given signal x, we
can ﬁnd the zeros of its z-transform as in (10), take the conjugate reciprocal of some of them, and
then take the inverse z-transform to obtain another signal y. If we re-scale y to have the same ℓ2
norm as x, then it is easy to verify that

|FM x|2 = |FM y|2,

no matter how large M is, even though clearly x and y are not equal.

Traditionally, this problem is often seen in design problems where uniqueness is not important,
e.g., FIR ﬁlter design [43] and far-ﬁeld multicast beamforming [26]. There, it is natural (from the
maximal energy dissipation point of view) to pick the zeros to lie within the unit circle2, yielding
a so-called minimum phase signal.

The above analysis provides a direct method for SF. For a given auto-correlation sequence r,

we ﬁrst calculate the roots of the polynomial

R(z) = r0 +

N −1

Xk=1(cid:16)rkz−k + r∗

kzk(cid:17) .

Because r is a valid correlation sequence, the roots come in conjugate reciprocal pairs. Therefore,
we can pick the N − 1 roots that are inside the unit circle, expand the expression, and then scale
it to have ℓ2 norm equal to √r0.
Numerically, the roots of R(z) can be found by calculating the eigenvalues of the following

companion matrix:

0

0
...
0

− rN −1

r∗
N −1

1

0

···

1

0
...
···
0
··· − r0

r∗
N −1

. . .
0
··· −

0
...
0
1
r∗
N −2
r∗
N −1





.





However, when expanding the factored form to get the coeﬃcients of the polynomial, the procedure
is very sensitive to roundoﬀ error, which quickly becomes signiﬁcant as N approaches 64.

4.2 SDP-based method for SF

To obtain a more stable method numerically, we can use an SDP approach to SF.

For a valid correlation r, it is shown in [9, Chapter 2.6.1] that the solution of the following SDP

maximize

X∈HN
+

X00

subject to

rk = tr{TkX} ,
k = 0, 1, ..., N − 1,

(11)

2If a zero ξ lie exactly on the unit circle, then (ξ ∗)−1 = ξ, meaning R(z) has a double root at that point, so we

simply pick one as the zero for the signal.

8

In addition, its rank one component generates the given correlation and is
is always rank one.
minimum phase. Algorithms for SDP are numerically stable, although the complexity could be
high if we use a general-purpose SDP solver.

The constraints in (11) are the same as the convex reformulation (9), which according to Ap-
pendix A is equivalent to PhaseLift without the trace regularization. Therefore, we may consider
instead solving the problem

minimize

X∈HN
+

M −1

Xm=0(cid:0)bm − tr(cid:8)fmf H

m X(cid:9)(cid:1)2

− λX00.

(12)

In Appendix B we show that for a suitable value of λ, the solution of (12) is guaranteed to be rank
one, and it attains the optimal least-squares error.

The formulation (12) allows to use customized SDP solvers to obtain a solution eﬃciently. For
example, PhaseLift was originally solved using TFOCS [4], which applies various modern ﬁrst-order
methods to minimize convex functions composed of a smooth part and a non-smooth part that has
a simple proximity operator. For problem (12), the cost function is the smooth part, and the
non-smooth part is the indicator function for the cone of semideﬁnite matrices.

It is now widely accepted that the trace of a semideﬁnite matrix, or nuclear norm for a general
matrix, encourages the solution to be low rank [33]. However, interestingly, in our setting, the cor-
rect regularization is in fact −λX00 which guarantees the solution to be rank one for an appropriate
choice of λ.

4.3 Kolmogorov’s method for SF

Kolmogorov proposed the following method for SF that is both eﬃcient and numerically stable [42].
In what follows, we assume that R(z) contains no zeros on the unit circle.

Consider taking the logarithm of the z-transform of x. Every zero (and pole, which we do not
have since x is ﬁnite length) of X(z) then becomes a pole of log X(z). Assuming the roots of X(z)
lie strictly inside the unit circle, this implies that there exists a region of convergence (ROC) for
log X(z) that contains the unit circle |z| = 1 and inﬁnity |z| = ∞. This in turn means that log X(z)
is unilateral

∞

Evaluating log X(z) at z = ejω, yields

log X(z) =

αnz−n.

Xn=0

ℜ(cid:8)log X(ejω)(cid:9) =
ℑ(cid:8)log X(ejω)(cid:9) = −

∞

∞

Xn=0
Xn=0

αn cos ωn,

αn sin ωn,

implying that ℜ(cid:8)log X(ejω)(cid:9) and ℑ(cid:8)log X(ejω)(cid:9) are Hilbert transform pairs. Moreover, since we
are given R(z) = |X(z)|2, we have that

ℜ(cid:8)log X(ejω)(cid:9) =

1
2

log R(ejω).

9

We can therefore calculate ℑ(cid:8)log X(ejω)(cid:9) from the Hilbert transform of ℜ(cid:8)log X(ejω)(cid:9), and re-

versely reconstruct a signal x that generates the given correlation r and is minimum phase.

In practice, all of the aforementioned transforms can be well approximated by a DFT with

suﬃciently large length L. The detailed procedure of Kolmogorov’s method then becomes:

1. compute the real part

γ =

1
2

log ℜnFL ˜Iro ;

2. compute the imaginary part by taking the Hilbert transform of γ, approximated by a DFT

φ = FLγ,

k = 0, L/2

ϕk =
0,
−jφk, k = 1, 2, ..., L/2 − 1

jφk,

k = L/2 + 1, ..., L − 1

,

η =

F H

L ϕ;

1
L

3. compute (1/L)F H

L exp(γ − jη), and take the ﬁrst N elements as the output.

Kolmogorov’s method generates a valid output as long as in the ﬁrst step we have that ℜnFL ˜Iro ≥

0, so that γ is real. This ﬁts well with the approximate formulation (8), since if we choose the
same L for both (8) and Kolmogorov’s method, then it is guaranteed to be able to run without
encountering a syntax error. Obviously, to obtain a solution with high accuracy, we need L to be
suﬃciently large; empirically we found L ≥ 20N to be good enough in practice. Computationally,
this approach requires computing four L-point (inverse-) FFTs with complexity O(L log L), a very
light computation burden even for large L.

5 A new measurement system

So far we have seen that an arbitrary signal cannot be uniquely determined from the magnitude of its
over-sampled 1D Fourier measurements, because there always exists a minimum phase signal that
yields the same measurements. Nonetheless, a least-squares estimate can be eﬃciently calculated
by solving either (8) or (9) followed by spectral factorization, leading to an optimal solution that is
minimum phase. If the true signal x is indeed minimum phase, then we can optimally estimate it
in polynomial-time. However, the minimum phase property is not a natural assumption to impose
on a signal in general.

We propose to resolve this ambiguity by deliberately making the signal minimum phase be-
fore taking the quadratic measurements, so that the augmented signal is uniquely identiﬁed in
polynomial time. The true signal is then recovered easily by reversing this operation.

For an arbitrary complex signal s, we propose to add δ in front of s before taking measurements,
where δ satisﬁes that |δ|≥ksk1. Denote the augmented signal as smin. The following proposition
shows that smin is minimum phase.

Proposition 1. Consider an arbitrary complex signal

s = [ s0 s1 ... sN −1 ]T .

10

Then the augmented signal

smin = [ δ s0 ... sN −1 ]T ,

(13)

where |δ| ≥ ksk1, is minimum phase.
Proof. To establish the result we need to show that the zeros of the z-transform of smin

or equivalently the roots of the polynomial

δ + s0z−1 + ... + sN −1z−N ,

V (z) = zN +

s0
δ

zN −1 + ... +

sN −1

δ

,

all lie inside the unit circle. To this end, we rely on the following lemma.

Lemma 1.

[20, Theorem 1] Let ζ be a zero of the polynomial

zN + cN −1zN −1 + ... + c1z + c0,

where c0, ..., cN −1 ∈ C and N is a positive integer. Then
Xn=0

|ζ| ≤ max(1,

N −1

|cn|) .

Substituting the coeﬃcients of V (z) into the inequality in Lemma 1 establishes the result.

Conceptually, the approach we propose is very simple: all we need is a way to over-estimate
the ℓ1 norm of the target signal, and a mechanism to insert an impulse in front of the signal before
taking quadratic measurements. For example, if we assume each element in s comes from a complex
Gaussian distribution with variance σ2, then we know that the probability that the magnitude of
one element exceeds 3σ is almost negligible; therefore, we can simply construct smin by setting
δ = 3σN , resulting in smin being minimum phase with very high probability.

Our approach can be used with a number of measurements M , as small as 2N . Indeed, consider
the equivalent reformulation (6), in which the measurements b are linear with respect to r. From
elementary linear algebra, we know that N complex numbers can be uniquely determined by as
few as 2N real linearly independent measurements, even without the speciﬁcation that r is a ﬁnite
correlation sequence. From a unique r, a unique minimum phase smin can be determined using SF.
The impulse may also be appended at the end of the signal s, resulting in a maximum phase

signal, meaning all the zeros of its z-transform are outside the unit circle.

Proposition 2. For an arbitrary complex signal

the augmented signal

s = [ s0 s1 ... sN −1 ]T ,

smax = [ s0 ... sN −1 δ ]T ,

where |δ| ≥ ksk1, is maximum phase.

11

Proof. The z-transform of smax is

Let ˜z = z−1. Then

S(z) = s0 + s1z−1 + ... + sN −1z1−N + δz−N .

S(˜z) = s0 + s1 ˜z + ... + sN −1˜zN −1 + δ˜zN ,

which is a polynomial in ˜z and, according to Lemma 1, has all its roots inside the unit circle.
Taking the reciprocal, this means that all the zeros of the z-transform of smax lie outside the unit
circle.

It is easy to show that for a maximum phase signal

smax = [ s0 ... sN −1 δ ]T ,

its equivalent minimum phase signal is

[ δ∗ s∗

N −1 s∗

N −2 ... s∗

0 ]T .

This means that if we measure the intensity of the Fourier transform of smax instead, we can still
uniquely recover s via solving (6) followed by SF, take the conjugate reversal of the solution, and
then delete the ﬁrst element to obtain an estimate.

Furthermore, from the analysis above, we can extend our measuring technique so that the

impulse is added away from the signal:

or

[ δ 0 ... 0 s0 ... sN −1 ]T ,

[ s0 ... sN −1 0 ... 0 δ ]T ,

(14)

(15)

with an arbitrary number of zeros between δ and s. The resulting augmented signal is still mini-
mum/maximum phase, thus can be uniquely identiﬁed from the intensity of its Fourier transform.
However, in this case more measurements are required for identiﬁability.

This concept is very similar to holography, which was invented by Gabor in 1948 [16], and
was awarded the Nobel Prize in Physics in 1971. One form of holography, spectral interferometry,
inserts an impulse exactly in the form of (14) or (15), and then measures the squared magnitude
of the Fourier transform of the combined signal [8, 38]. Despite the similarities in obtaining the
measurements, the theory behind our approach and holography is very diﬀerent, in several ways:

1. Holography constrains the length of the zeros between s and δ to be at least N , the length
of the signal, which is not required in our method; in fact, in terms of the number of mea-
surements needed, the shorter the better.

2. We require |δ| ≥ ksk1, whereas holography does not have any restriction on the energy of the

impulse.

3. We provide an optimization based framework to recover the underlying signal directly in a
robust fashion by exploiting the minimum phase property which is not part of the framework
in holography.

We are currently collaborating with Prof. Moti Segev and Maor Mutzaﬁ from the Technion to
explore extensions of the proposed measuring technique for holography.

12

6 Scalable algorithms

In this section, we ﬁrst brieﬂy describe how to directly use existing PhaseLift solvers to obtain
guaranteed rank one solutions eﬃciently. Due to the huge amount of extra memory required using
SDP-relaxation methods for large-scale problems, we then design a new algorithm that solves the
approximate formulation (8) with high eﬃciency, in terms of both time and memory.

6.1 SDP based algorithms

In the original PhaseLift paper [6], the authors used TFOCS [4] to solve the SDP (4), which is a
relatively eﬃcient way to solve large scale SDPs. As we discussed in Section 4.2, we can ensure a
rank one minimum phase solution by solving (12) with an appropriate choice of λ. An appropriate
value for λ can be found via bisection: ﬁrst we solve (12) with λ = 0 to get the optimal value
of the ﬁtting term; next we solve it with a λ large enough that the solution is guaranteed to be
rank one, but with a possibly larger ﬁtting error; Finally we bisect λ until both criteria are met.
Since TFOCS allows us to specify initializations, after we solve (12) for the ﬁrst time, subsequent
evaluations can be performed much more rapidly via warm start. Moreover, there is a wide range
of λ that result in both a rank one solution and an optimal ﬁtting error, so that the overall increase
in time required is small compared to that of solving a single PhaseLift problem.

The disadvantage of SDP based algorithms is that one cannot avoid lifting the problem dimen-
sion to O(N 2). If N is moderately large, on the order of a few thousand, then it is very diﬃcult to
apply SDP based methods in practice.

6.2 CoRK: An eﬃcient ADMM method

We now propose a new algorithm for solving the approximate formulation (8), which avoids the
dimension lifting, and can easily handle problem sizes up to millions. Since (8) is a convex quadratic
program, there are plenty of algorithms to solve it reliably. For example, a general purpose interior-
point method can solve it with worst case complexity O(N 3.5) without taking any problem structure
into account. Nevertheless, noticing that all of the linear operations in (8) involve DFT matrices,
the complexity can be further reduced by exploiting the FFT operator.

We propose solving (8) using the alternating direction method of multipliers (ADMM) [5]. To

apply ADMM, we ﬁrst rewrite (8) by introducing an auxiliary variable z ∈ RL:

where

2

+ I+(z)

(16)

minimize

r∈CN ,z∈RL (cid:13)(cid:13)(cid:13)
b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)
subject to ℜnFL ˜Iro = z,
I+(z) =(0,
z ≥ 0,

+∞, otherwise,

is the indicator function of the non-negative orthant in RL. Treating r as the ﬁrst block of variables,
z as the second, and ℜnFL ˜Iro = z as the coupling linear equality constraint with scaled Lagrange

13

multiplier u, we arrive at the following iterative updates:

1

L (z − u)(cid:1) ,

M b + ρF H

M + ρL(cid:0)F H

r ←
z ← max(cid:16)0,ℜnFL ˜Iro + u(cid:17) ,
u ← u + ℜnFL ˜Iro − z.

(17)

The derivation of the algorithm is given in Appendix C.

All the operations in (17) are taken element-wise or involve FFT computations of length L.

This leads to a complexity O(L log L), and eﬀectively O(N log N ) if L is chosen as O(N ).

In terms of convergence rate, it is shown in [18, Theorem 3] that our ADMM approach will
converge linearly, for all values of ρ > 0. The same reference provides an optimal choice of ρ that
results in the fastest convergence rate, for the case when there are fewer inequality constraints than
variables in the ﬁrst block. However, this requirement unfortunately is not fulﬁlled for problem (8).
Inspired by the choice of ρ in [18], we found empirically that by setting ρ = M/L, the proposed
iterates (17) converge very fast, and at a rate eﬀectively independent of the problem dimension.

As we explained in Section 4.3, this formulation blends well with Kolmogorov’s method for
spectral factorization. We thus call our preferred approach for solving the 1-D Fourier phase
retrieval problem (2) the auto-correlation retrieval – Kolmogorov factorization (CoRK) method.

7 Summary of the proposed method

Throughout the paper, we divided 1D Fourier phase retrieval into several steps (measurement,
formulation, algorithms, etc.), and for each step discussed several solution methods. For clarity
and practical purposes, we summarize our approach below based on speciﬁc choices we found to be
eﬃcient. Given an arbitrary vector s we propose the following steps:

1. Construct smin by inserting δ in front of s, i.e.,

smin = [ δ s0 s1 ... sN −1 ]T ,

such that |δ| > ksk1. Take the M -point DFT of smin, where M > 2N , and measure its
squared magnitude b = |FM smin|2.

2. Apply CoRK as follows:

(a) Formulate the least-squares problem with respect to the auto-correlation of smin as in

(8),

2

r∈CN +1

minimize

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)
subject to ℜnFL ˜Iro ≥ 0,

(cid:13)(cid:13)(cid:13)

14

by picking L as the smallest power of 2 that is greater than 32N . Solve this problem
using the iterative algorithm (17), repeated here by setting ρ = M/L:

1
L

F H

L (z − u)(cid:19) ,

1

2(cid:18) 1

F H

M

M b +

r ←
z ← max(cid:16)0,ℜnFL ˜Iro + u(cid:17) ,
u ← u + ℜnFL ˜Iro − z.

(b) Extract the minimum phase signal that generates the correlation r by Kolmogorov’s

method, using the same L, as follows (also given in Section 4.3):

γ =

1
2

φ = FLγ,

log ℜnFL ˜Iro ,

k = 0, L/2

ϕk =
0,
−jφk, k = 1, 2, ..., L/2 − 1

jφk,

k = L/2 + 1, ..., L − 1

F H

,

1
L

η =

L ϕ,
x = (1/L)F H

L exp(γ − jη).

3. Obtain an estimate ˆs via

ˆsn = xn+1, n = 0, 1, ..., N − 1.

Often, we have prior information that the signal of interest s is real. This implies that the
auto-correlation is also real so that we need to restrict the domain of r and/or X in problem (8) or
(12) to be real. For the z-transform of a real signal, the zeros are either real or come in conjugate
pairs, which does not help the non-uniqueness of the solution if we directly measure the 1D Fourier
magnitude. In Kolmogorov’s SF method, if the input r is real and a valid correlation, then γ + jη
is conjugate symmetric, so that it is guaranteed to output a real valued signal. As for the new
measurement system, all the claims made for constructing minimum/maximum phase signals still
hold, if the signal is restricted to be real.
In Appendix C we show how to modify the ADMM
method (17) to accommodate real signals by adding an additional projection to the real domain in
the r update.

When x is real, the DFT has conjugate symmetry

X(e−j2πm/M ) = X ∗(e−j2π(M −m)/M ),

meaning for the squared magnitude, bm = bM −m. Therefore, if we take M samples between [0, 2π],
then only the ﬁrst M/2 measurements provide useful information. Consequently, we still need
M > 2N measurements sampled between [0, 2π] to ensure identiﬁability.

8 Simulations

We now demonstrate the algorithms and the new measurement system we proposed via simulations.
We ﬁrst show that both algorithms, iteratively solving (12) while bisecting λ and solving (8) followed

15

by Kolmogorov’s method, are able to solve the original problem (2) optimally, meaning the cost
attains the lower bound given by PhaseLift. Then, we show that using the new measurement system
proposed in Section 5 we can uniquely identify an arbitrary 1D signal, whereas directly measuring
the over-sampled Fourier intensity does not recover the original input, regardless of the algorithms
being used. All simulations are performed in MATLAB on a Linux machine.

8.1 Minimizing the least-squares error

We ﬁrst test the eﬀectiveness of the proposed algorithms on random problem instances. Fixing
N = 128, we randomly set M as an integer between [2N, 8N ], and generate b from an i.i.d.
uniform distribution between [0, 1]. We compare the following algorithms:

• PhaseLift. Using TFOCS [4] to solve problem (4) with λ = 0. This in general does not
give a rank one solution, therefore only serves as a theoretical lower bound on the minimal
least-squares error (2).

• PhaseLift-PC. The leading principal component of the plain PhaseLift solution.
• PhaseLift-SF. Iteratively solving (12) while bisecting λ until an equivalent rank one solution
for (4) is found, again using TFOCS. Each time TFOCS is initialized with the solution from
the previous iteration for faster convergence. As we proved, this method is guaranteed to
achieve the lower bound given by PhaseLift.

• CoRK. Proposed method summarized in the second step of Section 8. For both steps, L is

set to be the smallest power of 2 that is greater than 32N .

• Fienup-GS. Fienup’s algorithm [14] for 1000 iterations, then reﬁned by GS algorithm until

the error deﬁned in (3) converges.

The optimality gaps between the minimal error in (2) obtained by the aforementioned methods
and the theoretical lower bound given by PhaseLift are shown in Fig. 1; The running time of
the diﬀerent methods is provided in Fig. 2, for the 100 Monte-Carlo trials we tested. As we can
see, PhaseLift-SF provides an optimal rank one solution, although it takes more time compared
to solving one single PhaseLift problem; also, since PhaseLift-SF only provides a solution that is
“numerically” rank one, when we take its rank one component and evaluate the actual ﬁtting error
(2), it is still a little bit away from the theoretical PhaseLift lower bound, as shown in the red
circles in Fig. 1. On the other hand, the proposed CoRK method is able to approximately solve the
problem with high accuracy (a lot of times even better than PhaseLift-SF) in a very small amount
of time (shorter than the standard Fienup-GS algorithm). The conventional Fienup-GS method
and the leading principal component of the PhaseLift solution (in general not close to rank one)
do not come close to the PhaseLift lower bound.

8.2 Estimation performance

We now verify that our proposed new measurement technique, as described in Section 5, is able
to recover a signal s up to global phase ambiguity. As we have shown in the previous simulation,
the CoRK method performs similar to those based on PhaseLift, but with much more eﬃciency.
Therefore, we only compare CoRK and Fienup’s algorithm as baselines. In each Monte-Carlo trial,

16

100

*

f
-
f

10-10

0

20

40

60

80

MC trials

PhaseLift-PC
PhaseLift-SF
Fienup
100
CoRK

Figure 1: Optimality gaps from the PhaseLift lower bound in each Monte-Carlo trial, cf. Section 8.1.

102

100

10-2

s
d
n
o
c
e
s
/

e
m

i
t

0

20

40

60

MC trials

80

PhaseLift-PC
PhaseLift-SF
Fienup
100
CoRK

Figure 2: Time consumed in each Monte-Carlo trial, cf. Section 8.1.

we ﬁrst set N as a random integer between [1, 1024], and then set M as the smallest power of 2
that is larger than 4N . A random signal s ∈ CN is then generated with elements drawn from i.i.d.
CN (0, 1). Two kinds of measurements are collected for performance comparison:

• Direct: directly measure |FM s|2;
• Minimum Phase: ﬁrst construct a minimum phase signal smin as in (13) with δ = 3N , and

then measure |FM smin|2.

For the minimum phase measurements, when Fienup’s algorithm is used, we add an additional
step in which we use the solution to generate an auto-correlation sequence and then apply spectral
factorization (Kolmogorov’s method) to obtain a minimum phase signal with the same ﬁtting error.
We denote this approach by Fienup-SF. We also used a simple prior that the added impulse δ
is real and positive to resolve the global phase ambiguity: after obtaining the minimum phase
solution, the result is ﬁrst rotated so that the ﬁrst entry is real and positive, and then the ﬁrst
entry is deleted to obtain an estimate ˆs. For direct measurements, the estimation error is deﬁned
as

|ψ|=1ks − ψ ˆsk2.
min

17

r
o
r
r
e

 

n
o

i
t

a
m

i
t
s
e

100

10-10

10-20

Direct: Fienup
Direct: CoRK
Minimum Phase: Fienup-SF
Minimum Phase: CoRK

0

20

40

60

80

100

MC trials

Figure 3: Estimation error in each Monte-Carlo trial for the ﬁrst simulation in Section 8.2.

102

100

10-2

s
d
n
o
c
e
s
/

e
m

i
t

0

20

40

60

80

100

MC trials

Fienup-SF
CoRK

Figure 4: Computation time in each Monte-Carlo trial (with the new measurement system) for the
ﬁrst simulation in Section 8.2.

The estimation error in each of the 100 Monte-Carlo trials is shown in Fig. 3: we obtain perfect
signal recovery when the new measurement system is used together with the eﬃcient method we
proposed to optimally solve the problem, which is never the case for direct measurements, even
though the ﬁtting error kb − |F H
M x|2k2 is always close to zero. For the new measuring system,
CoRK obtains a solution with much higher accuracy, and much lower computation time (shown in
Fig. 4), compared to the widely used Fienup’s algorithm.

The new measuring system, together with the proposed CoRK method or Fienup’s algorithm
followed by spectral factorization, is also robust to noise, in the sense that the mean squared
error (MSE) Eks − ˆsk2 can essentially attain the Cram´er-Rao bound (CRB). The CRB for the
phase-retrieval problem is derived in [32], and we use that to benchmark the performance of our
new technique, which is the only method that can guarantee perfect signal reconstruction in the
noiseless case. The CRB results in [32] are with respect to the real and imaginary part of the signal
being measured, in our case smin. We therefore sum over the diagonals of the pseudo-inverse of the
Fisher information matrix except for the 1st and n + 1st entries, which correspond to the real and
imaginary parts of δ, and deﬁne that as the CRB for Eks − ˆsk2. Furthermore, since the CRB is
dependent on the true value of smin, we show the results with respect to a ﬁxed signal s in order
to keep the CRB curve consistent with how we change one parameter setting of the simulation.

18

10-0.4

10-0.7

10-1.0

r
o
r
r
e

 

d
e
z

i
l

a
m
r
o
n

SNR = 40dB

M=8N

CRB
CoRK
Fienup-SF

            100

           10-1

           10-2

10-1.3

2N

4N

8N

           10-3
16N

30

number of measurements

40

50

60

SNR

Figure 5: Normalized MSE ks− ˆsk2/ksk2 vs. normalized CRB using the new measurement system,
where we increased the number of measurements on the left, and SNR on the right.

We set N = 1024 and generate a ﬁxed signal s ∈ CN from i.i.d. CN (0, 1). Similar to the
previous simulation, smin is ﬁrst constructed according to (13) with δ = 3N , so that it is mini-
mum phase with very high probability. White Gaussian noise with variance σ2 is added to the
squared magnitude of the Fourier transform of smin, and the signal-to-noise ratio (SNR) is deﬁned

2

as 10 log10(cid:18)(cid:13)(cid:13)(cid:13)|FM smin|2(cid:13)(cid:13)(cid:13)

/M σ2(cid:19) . The performance is plotted in Fig. 4, where we show the nor-
malized error ks − ˆsk2/ksk2 versus the normalized CRB (original CRB divided by ksk2), averaged
over 100 Monte-Carlo trials. On the left, we ﬁx SNR= 40dB, and increase the number of measure-
ments M from 2N to 16N . On the right, we ﬁx M = 8N , and increase the SNR from 30dB to 60dB.
The SNR may seem high here, but notice that most of the signal power is actually concentrated in
the artiﬁcially added impulse δ, so that the actual noise power is much higher comparing to that
of s per se. In all cases the MSE obtained from our proposed method is able to attain the CRB
sharply, even for as few as M = 2N measurements.

9 Conclusion

We studied the phase retrieval problem with 1D Fourier measurements, a classical estimation
problem that has challenged researchers for decades. Our contributions to this challenging problem
are as follows:

• Convexity. We showed that the 1D Fourier phase retrieval problem can be solved by a convex

SDP.

• Uniqueness. We proposed a simple measurement technique that adds an impulse to the signal

before measuring the Fourier intensities, so that any signal can be uniquely identiﬁed.

• Algorithm. We developed CoRK – a highly scalable algorithm to solve this problem, which

was shown in our simulations to outperform all prior art.

19

A Equivalence of PhaseLift and Problem (9)

We show that the exact convex reformulation (9) is in fact equivalent to PhaseLift (4) without the
trace regularization if we eliminate the variable r in (9). A similar claim is given in [27] for the
more general Toeplitz QCQP, but we show this again here in our context for completeness.

Consider the mth entry in the vector ℜnFM ˜Iro, and replace r by its trace parameterization

rk = tr{TkX} ,

∀k = 0, 1, ..., N − 1.

We then have that

ℜnf H

m

N −1

Xk=1

˜Iro = r0 + 2

ℜnφkmrko
k(cid:17)
Xk=1 (cid:16)φkmrk + φ−kmr∗

N −1

N −1

= r0 +

Xk=1 (cid:16)φkmtr{TkX} + φ−kmtr(cid:8)T T

k X(cid:9)(cid:17)

= tr{T0X} +
= tr(cid:8)fmf H
m X(cid:9) ,

where the last step is a result of the fact that

T0 +

N −1

Xk=1(cid:16)φkmTk + φ−kmT T

k (cid:17) = fmf H

m .

We now eliminate r in Problem (9) as follows:

(cid:13)(cid:13)(cid:13)
b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

M −1

=

Xm=0(cid:0)bm − tr(cid:8)fmf H

˜Iro(cid:17)2

M −1

2

=

m

Xm=0(cid:16)bm − ℜnf H
m X(cid:9)(cid:1)2

,

(18)

(19)

which is exactly the cost function for PhaseLift (4) without the trace regularization.

B Combining PhaseLift with spectral factorization

As we explained in the paper, 1D Fourier phase retrieval can be solved exactly using SDP in the
following two steps. First, solve problem (9) (repeated here),

minimize
r∈CN ,X∈HN
+

subject to

2

(cid:13)(cid:13)(cid:13)

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

rk = tr{TkX} ,∀k = 0, 1, ..., N − 1.

(20)

20

Denote r⋆ as the optimal solution of (20), which is the unique solution since the cost of (20) is
strongly convex with respect to r. Next, perform an SDP-based spectral factorization by computing
the solution to

maximize

X∈HN
+

X00

(21)

subject to r⋆k = tr{TkX} ,∀k = 0, 1, ..., N − 1,

and let the optimal solution of (21) be X⋆. Note that X⋆ is the unique solution for (21), and it
is rank one [9]. Here we want to show that these two steps can actually be combined into one, as
shown in the following proposition.

Proposition 3. Consider the following SDP

M −1

minimize

X∈HN
+

Xm=0(cid:0)bm − tr(cid:8)fmf H

m X(cid:9)(cid:1)2

− λX00.

(22)

There exists some λ such that the solution of (22) is guaranteed to be X⋆, which is also the solution
of (21) with r⋆ being the solution of (20).

Proof. Notice that (r⋆, X⋆) is a feasible solution for (20), and in fact r⋆ is the unique solution. On
the other hand, X⋆ is only one solution among a set of solutions for (20), but is the unique solution
for problem (21). Now consider the following problem

minimize
r∈CN ,X∈HN
+

subject to

2

(cid:13)(cid:13)(cid:13)

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

rk = tr{TkX} ,∀k = 0, 1, ..., N − 1.
X00 = X⋆00,

(23)

It is easy to see that (r⋆, X⋆) is its unique solution. From Lagrange duality, the above problem has
the same solution as

minimize
r∈CN ,X∈HN
+

subject to

2

(cid:13)(cid:13)(cid:13)

b − ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)

+ λ(X⋆00 − X00)
rk = tr{TkX} ,∀k = 0, 1, ..., N − 1,

(24)

where λ is the optimal Lagrangian multiplier with respect to the equality constraint X00 = X⋆00
in (23).

Finally, by dropping the constant λX⋆00 in the cost of (24) and eliminating the variable r as
we described in Appendix A, we end up with the formulation (22), or (12) in the main content,
leading to our conclusion that X⋆ is the unique solution to (22).

Proposition 3 allows to solve 1D Fourier phase retrieval via solving (12), to which all methods
provided by TFOCS can still be applied, and by tuning λ we obtain an optimal solution that is
also rank one.

21

C Derivation of Algorithm (17)

We ﬁrst review the alternating direction method of multipliers (ADMM), which is the tool used to
derive Algorithm (17).

Consider the following optimization problem:

minimize

x,z

f (x) + g(z),

subject to Ax + Bz = c.

ADMM solves this problem using the following updates

f (x) + ρkAx + Bz − c + uk2,
g(z) + ρkAx + Bz − c + uk2,

x

x ← arg min
z ← arg min
u ← u + Ax + Bz − c.

z

ADMM converges to an optimal solution as long as the problem is closed, convex, and proper. The
ﬂexible two-block structure of the algorithm often leads to very eﬃcient and/or parallel algorithms
that work well in practice.

We now apply ADMM to problem (16), which leads to the following steps:

2

r (cid:13)(cid:13)(cid:13)
b−ℜnFM ˜Iro(cid:13)(cid:13)(cid:13)
z I+(z) + ρ(cid:13)(cid:13)(cid:13)ℜnFL ˜Iro − z + u(cid:13)(cid:13)(cid:13)

r ← arg min
z ← arg min
u ← u + ℜnFL ˜Iro − z

+ ρ(cid:13)(cid:13)(cid:13)ℜnFL ˜Iro−z+u(cid:13)(cid:13)(cid:13)

2

2

The explicit update for z is very straight forward—it is simply a projection of the point(cid:16)ℜnFL ˜Iro + u(cid:17)

onto the non-negative orthant, leading to the update of z as shown in (17).

We next derive the update for r in detail. First note that r is in general complex, so that the
derivative needs to be taken with care. To this end we treat r and r∗ as independent variables
and take derivatives with respect to them separately. This approach is referred to as the Wirtinger
derivative [41]. Focusing on the ﬁrst term of the r sub-problem, we can rewrite it as

1
2

b −

FM ˜Ir −

1
2

F ∗
M

(cid:13)(cid:13)(cid:13)(cid:13)

2

˜Ir∗(cid:13)(cid:13)(cid:13)(cid:13)

.

(25)

Taking the derivative with respect to r while treating r∗ as an independent variable, we obtain

1
2

˜IF H

M FM

˜Ir +

1
2

˜IF H

M F ∗
M

˜Ir∗ − ˜IF H
M b.

(26)

Recall that FM represents the ﬁrst N columns of the DFT matrix, which are orthogonal to each
other, so that F H
M , except for the ﬁrst one, come
from the last N − 1 columns of the same DFT matrix; if we assume M ≥ 2N , then we have that
all columns of F ∗
M are orthogonal to columns of FM , except for the ﬁrst one, which is equal to 1.

M FM = M I. On the other hand, the columns of F ∗

22

M = M E00, where E00 has only one entry in the upper-left corner that is equal to

M F ∗

Therefore, F H
one, and zeros elsewhere. Since ˜I = diag{[ 1 2 2 ... 2 ]}, (26) simpliﬁes to
M b = M ˜Ir − ˜IF H
M b,

˜IE00 ˜Ir∗ − ˜IF H

˜I ˜Ir +

M
2

1
2

where we used the fact that r0 is real. Similar expressions apply to the second term of the r
sub-problem. By setting the gradient of the r sub-problem equal to zero, we have that

M ˜Ir − ˜IF H

M b + ρ(cid:16)L ˜Ir − ˜IF H

L (z − u)(cid:17) = 0,

which leads to the update for r given in (17). The gradient with respect to r∗ can be shown to be
exactly the conjugate of the gradient of r. Therefore, equating it to zero gives us the same result.

Finally, if we restrict r to be real, then the term (25) can be written as

Its gradient with respect to r is then

1
2

b −

FM ˜Ir −

1
2

F ∗
M

(cid:13)(cid:13)(cid:13)(cid:13)

2

.

˜Ir(cid:13)(cid:13)(cid:13)(cid:13)

1
2

˜IF H

M FM

˜Ir +

1
2
˜Ir +

˜IF H

M F ∗
M

˜Ir − ˜IF H
M b
˜Ir − ˜IF T
M b

=

+

M
2

+

˜IF T

1
2
˜I ˜Ir +

M FM
M
2

M
2

˜IE00 ˜Ir +

1
2

˜IF T

M F ∗
M
˜IE00 ˜Ir − ˜IF H
M b
˜I ˜Ir − ˜IF T
M b
M bo .

M
2

= 2M ˜Ir − 2ℜn ˜IF H

Therefore, it is easy to see that the update of r that is real is

which is simply a projection of the original complex update onto the real domain.

r = ℜ(cid:26)

1

M + ρL(cid:0)F H

M b + ρF H

L (z − u)(cid:1)(cid:27) ,

Acknowledgment

The authors would like to thank Prof. Moti Segev and Maor Mutzaﬁ from the Technion for pointing
out the similarities between our proposed measuring technique and holography.

References

[1] B. Alkire and L. Vandenberghe. Convex optimization problems involving ﬁnite autocorrelation

sequences. Mathematical Programming, 93(3):331–359, 2002.

[2] H. H. Bauschke, P. L. Combettes, and D. R. Luke. Phase retrieval, error reduction algorithm,

and ﬁenup variants: a view from convex optimization. JOSA A, 19(7):1334–1345, 2002.

23

[3] A. Beck and Y. C. Eldar. Sparsity constrained nonlinear optimization: Optimality conditions

and algorithms. SIAM Optimization, 23(3):1480–1509, Oct. 2013.

[4] S. R. Becker, E. J. Cand`es, and M. C. Grant. Templates for convex cone problems with
applications to sparse signal recovery. Mathematical Programming Computation, 3(3):165–
218, 2011.

[5] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed optimization and statis-
tical learning via the alternating direction method of multipliers. Foundations and Trends R(cid:13)
in Machine Learning, 3(1):1–122, 2011.

[6] E. J. Cand`es, Y. C. Eldar, T. Strohmer, and V. Voroninski. Phase retrieval via matrix com-

pletion. SIAM Journal on Imaging Sciences, 6(1):199–225, 2013.

[7] E. J. Cand`es, X. Li, and M. Soltanolkotabi. Phase retrieval from coded diﬀraction patterns.

Applied and Computational Harmonic Analysis, 39(2):277–299, 2015.

[8] J.-C. M. Diels, J. J. Fontaine, I. C. McMichael, and F. Simoni. Control and measurement of
ultrashort pulse shapes (in amplitude and phase) with femtosecond accuracy. Applied Optics,
24(9):1270–1282, 1985.

[9] B. Dumitrescu. Positive Trigonometric Polynomials and Signal Processing Applications.

Springer, 2007.

[10] B. Dumitrescu, I. T˘abu¸c, and P. Stoica. On the parameterization of positive real sequences
and MA parameter estimation. IEEE Transactions on Signal Processing, 49(11):2630–2639,
2001.

[11] Y. C. Eldar and S. Mendelson. Phase retrieval: Stability and recovery guarantees. Applied

and Computational Harmonic Analysis, (0):–, 2013.

[12] Y. C. Eldar, P. Sidorenko, D. G. Mixon, S. Barel, and O. Cohen. Sparse phase retrieval from

short-time fourier measurements. IEEE Signal Processing Letters, 22(5):638–642, 2015.

[13] V. Elser. Direct phasing of nanocrystal diﬀraction. Acta Crystallographica Section A: Foun-

dations of Crystallography, 69(6):559–569, 2013.

[14] J. R. Fienup. Reconstruction of an object from the modulus of its Fourier transform. Optics

Letters, 3(1):27–29, 1978.

[15] J. R. Fienup. Phase retrieval algorithms: a comparison. Applied optics, 21(15):2758–2769,

1982.

[16] D. Gabor. A new microscopic principle. Nature, 161(4098):777–778, 1948.

[17] R. W. Gerchberg. A practical algorithm for the determination of phase from image and

diﬀraction plane pictures. Optik, 35:237, 1972.

[18] E. Ghadimi, A. Teixeira, I. Shames, and M. Johansson. Optimal parameter selection for the
alternating direction method of multipliers (ADMM): quadratic problems. IEEE Transactions
on Automatic Control, 60(3):644–658, 2015.

24

[19] R. W. Harrison. Phase problem in crystallography. JOSA A, 10(5):1046–1055, 1993.

[20] H. P. Hirst and W. T. Macey. Bounding the roots of polynomials. College Mathematics

Journal, pages 292–295, 1997.

[21] E. Hofstetter. Construction of time-limited functions with speciﬁed autocorrelation functions.

IEEE Transactions on Information Theory, 10(2):119–126, 1964.

[22] N. E. Hurt. Phase Retrieval and Zero Crossings: Mathematical Methods in Image Reconstruc-

tion, volume 52. Springer, 2001.

[23] K. Jaganathan, Y. C. Eldar, and B. Hassibi. Recovering signals from the short-time Fourier
In IEEE International Conference on Acoustics, Speech, and Signal

transform magnitude.
Processing (ICASSP), pages 3277–3281, 2015.

[24] K. Jaganathan, Y. C. Eldar, and B. Hassibi. Phase retrieval: An overview of recent develop-

ments. In A. Stern, editor, Optical Compressive Sensing, 2016 (to appear).

[25] K. Jaganathan, S. Oymak, and B. Hassibi. Recovery of sparse 1-D signals from the magnitudes

of their Fourier transform. CoRR, abs/1206.1405, 2012.

[26] E. Karipidis, N. D. Sidiropoulos, and Z.-Q. Luo. Far-ﬁeld multicast beamforming for uniform

linear antenna arrays. IEEE Transactions on Signal Processing, 55(10):4916–4927, 2007.

[27] A. Konar and N. D. Sidiropoulos. Hidden convexity in QCQP with Toeplitz-Hermitian quadrat-

ics. IEEE Signal Processing Letters, 22(10):1623–1627, 2015.

[28] M. G. Krein and A. A. Nudelman. The Markov Moment Problem and Extremal Problems,
volume 50 of Translations of Mathematical Monographs. American Mathematical Society,
Providence, Rhode Island, 1977.

[29] Y. M. Lu and M. Vetterli. Sparse spectral factorization: Unicity and reconstruction algorithms.
In IEEE International Conference on Acoustic, Speech, and Signal Processing (ICASSP), pages
5976–5979, 2011.

[30] Z.-Q. Luo, W.-K. Ma, M.-C. So, Y. Ye, and S. Zhang. Semideﬁnite relaxation of quadratic

optimization problems. IEEE Signal Processing Magazine, 27(3):20–34, 2010.

[31] H. Ohlsson and Y. C. Eldar. On conditions for uniqueness in sparse phase retrieval.

In
IEEE International Conference on Acoustic, Speech, and Signal Processing (ICASSP), pages
1841–1845, 2014.

[32] C. Qian, N. D. Sidiropoulos, K. Huang, L. Huang, and H.-C. So. Phase retrieval using feasible
point pursuit: algorithms and Cram´er-Rao bound.
In IEEE International Conference on
Acoustic, Speech, and Signal Processing (ICASSP), March 20–25, Shanghai, China, 2016 (to
appear).

[33] B. Recht, M. Fazel, and P. A. Parrilo. Guaranteed minimum-rank solutions of linear matrix

equations via nuclear norm minimization. SIAM review, 52(3):471–501, 2010.

25

[34] A. H. Sayed and T. Kailath. A survey of spectral factorization methods. Numerical linear

algebra with applications, 8(6-7):467–496, 2001.

[35] Y. Shechtman, A. Beck, and Y. C. Eldar. GESPAR: eﬃcient phase retrieval of sparse signals.

IEEE Transactions on Signal Processing, 62(4):928–938, Feb. 2014.

[36] Y. Shechtman, Y. C. Eldar, O. Cohen, H. N. Chapman, J. Miao, and M. Segev. Phase
retrieval with application to optical imaging: a contemporary overview. IEEE Signal Processing
Magazine, 32(3):87–109, 2015.

[37] Y. Shechtman, Y. C. Eldar, A. Szameit, and M. Segev. Sparsity based sub-wavelength imaging
with partially incoherent light via quadratic compressed sensing. Optics Express, 19(16):14807–
14822, 2011.

[38] M. Takeda, H. Ina, and S. Kobayashi. Fourier-transform method of fringe-pattern analysis for
computer-based topography and interferometry. Journal of the Optical Society of America,
72(1):156–160, 1982.

[39] I. Waldspurger, A. d’Aspremont, and S. Mallat. Phase recovery, MaxCut and complex semidef-

inite programming. Mathematical Programming, 149(1-2):47–81, 2015.

[40] A. Walther. The question of phase retrieval in optics. Journal of Modern Optics, 10(1):41–49,

1963.

[41] W. Wirtinger. Zur formalen theorie der funktionen von mehr komplexen ver¨anderlichen. Math-

ematische Annalen, 97(1):357–375, 1927.

[42] S.-P. Wu, S. P. Boyd, and L. Vandenberghe. FIR ﬁlter design via semideﬁnite programming
In IEEE Conference on Decision and Control, volume 1, pages

and spectral factorization.
271–276, 1996.

[43] S.-P. Wu, S. P. Boyd, and L. Vandenberghe. FIR ﬁlter design via spectral factorization and
convex optimization. In Applied and Computational Control, Signals and Circuits, pages 215–
245. Springer, 1999.

26

