6
1
0
2

 
r
a

M
9

 

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
0
4
9
2
0

.

3
0
6
1
:
v
i
X
r
a

Quantum algorithms for Gibbs sampling and hitting-time estimation

Center for Quantum Information and Control, University of New Mexico, Albuquerque,

NM 87131, US and New Mexico Consortium, Los Alamos, NM 87545, US.

Anirban Narayan Chowdhury

Theoretical Division, Los Alamos National Laboratory, Los Alamos, NM 87545, US.

(Dated: March 10, 2016)

Rolando D. Somma

We present quantum algorithms for solving two problems regarding stochastic processes. The ﬁrst
algorithm prepares the thermal Gibbs state of a quantum system and runs in time almost linear
in pN β/Z and polynomial in log(1/ǫ), where N is the Hilbert space dimension, β is the inverse
temperature, Z is the partition function, and ǫ is the desired precision of the output state. Our
quantum algorithm exponentially improves the dependence on 1/ǫ and quadratically improves the
dependence on β of known quantum algorithms for this problem. The second algorithm estimates
the hitting time of a Markov chain. For a sparse stochastic matrix P , it runs in time almost linear
in 1/(ǫ∆3/2), where ǫ is the absolute precision in the estimation and ∆ is a parameter determined
by P , and whose inverse is an upper bound of the hitting time. Our quantum algorithm quadrat-
ically improves the dependence on 1/ǫ and 1/∆ of the analog classical algorithm for hitting-time
estimation. Both algorithms use tools recently developed in the context of Hamiltonian simulation,
spectral gap ampliﬁcation, and solving linear systems of equations.

PACS numbers: 03.67.Ac, 89.70.Eg

I.

INTRODUCTION

Two important problems in statistical mechanics and
stochastic processes are sampling from the thermal or
Gibbs distribution of a physical system at a certain tem-
perature and the estimation of hitting times of classical
Markov chains. The ﬁrst such problem has a wide range
of applications as it allows us to compute quantities like
the partition function, energy, or entropy of the system,
and understand its physical properties in thermal equi-
librium [1]. This problem has also applications in many
other scientiﬁc areas including optimization [2]. Hitting
times are also paramount in the study of classical ran-
dom processes and they allow for a characterization of
Markov chains [3]. Roughly, a hitting time is the time
required by a diﬀusive random walk to reach a particular
conﬁguration with high probability. Besides their use in
physics, hitting times are also important in solving search
problems where the goal is to ﬁnd a marked conﬁguration
of the Markov chain [4].

In a classical setting, these two problems are commonly
solved using Monte-Carlo techniques [5]. Each step in a
Monte-Carlo simulation corresponds to applying a partic-
ular probability rule that determines a Markov chain and
an associated stochastic matrix. In the case of sampling
from Gibbs distributions, for example, the ﬁxed point of
the Markov chain (i.e., the eigenvector of the stochastic
matrix with eigenvalue 1) corresponds to the desired dis-
tribution. Such a distribution can then be prepared by
repeated applications of the probability rule. To sam-
ple from probability distributions associated with ther-
mal Gibbs states of quantum systems, quantum Monte-
Carlo techniques may be used [6]. The running time of
a Monte-Carlo simulation is typically dominated by the

number of times the probability rule is applied to prepare
the desired distribution with some given precision. This
running time depends on properties of the Markov chain
such as the spectral gap of the stochastic matrix [3].

In recent years, there has been signiﬁcant interest in
the development of quantum algorithms for simulating
stochastic processes. Quantum algorithms for thermal
Gibbs state preparation were developed in various works
(c.f., [7–12]) and showed to provide polynomial quan-
tum speedups in terms of various parameters, such as the
spectral gap of the stochastic matrix or the dimension of
the Hilbert space. The notion of quantum hitting time
was also introduced in numerous works (c.f., [13–17]). Of-
ten, quantum hitting times of quantum walks on diﬀer-
ent graphs are signiﬁcantly (e.g., polynomially) smaller
than their classical counterparts. There are also vari-
ous quantum algorithms to accelerate classical Monte-
Carlo methods for estimating diﬀerent quantities, such
as expected values or partition functions (c.f., [18, 19]).
Our results advance these areas further by providing new
quantum algorithms with various improvements in the
running time with respect to known classical and quan-
tum algorithms for some of these problems.

In more detail, we present two quantum algorithms for
preparing thermal Gibbs states of quantum systems and
for estimating hitting times, respectively. The ﬁrst algo-

rithm runs in time ˜O(pN β/Z), where N is the Hilbert
space dimension, β is the inverse temperature, and Z
is the partition function of the quantum system. The
˜O notation hides polylogarithmic factors in these quanti-
ties and 1/ǫ, where ǫ is the desired precision of the output
state. This is a quadratic improvement in β and an ex-
ponential improvement in 1/ǫ with respect to a related
algorithm presented in [8, 9]. In fact, the main diﬀerence

between our quantum algorithm and that of [8, 9] is in
the implementation of the operator e−βH/2, where H is
the Hamiltonian of the system. Rather than using phase
estimation, we use a technique introduced in [20–22] to
decompose e−βH/2 as a linear combination of unitary op-
erations and then apply results of spectral gap ampliﬁ-
cation in [23] to implement each such unitary. The same
idea can be used to improve the running time of the algo-
rithm presented in [10]. The second algorithm provides
an estimate of th, the hitting time of a reversible, irre-
ducible, and aperiodic Markov chain.
It runs in time
˜O(1/(ǫ∆3/2)), where ǫ is the absolute precision in the es-
timation and ∆ is a parameter that satisﬁes 1/∆ ≥ th.
The ˜O notation hides factors that are polynomial in
log(1/(ǫ∆)) and log(N ), where N is the dimension of
the conﬁguration space.
In addition to the techniques
used by the ﬁrst algorithm, the second algorithm also
uses recent methods for the quantum linear systems al-
gorithm in [22] and methods to estimate quantities at the
so-called quantum metrology limit described in [18].

The paper is organized as follows.

In Sec. II we de-
scribe the main techniques introduced in [18, 21–24] that
are also used by our algorithms. Then, the quantum al-
gorithm for the preparation of thermal Gibbs states of
quantum systems is described in Sec. III and the quan-
tum algorithm for estimating hitting times of classical
Markov chains is described in Sec. IV. We provide con-
cluding remarks in Sec. V.

II. MAIN TECHNIQUES

Our algorithms are based on techniques developed in
the context of spectral gap ampliﬁcation [23], Hamilto-
nian simulation [21, 24], quantum metrology [18], and
solving linear systems of equations [22]. We ﬁrst consider
an arbitrary ﬁnite-dimensional quantum system modeled
by a Hamiltonian H that satisﬁes

H |ψji = Ej |ψji .

(1)

Ej are the eigenenergies and |ψji are the eigenstates,
j = 0, 1, . . . N − 1, and N is the dimension of the Hilbert
space. We assume that H describes a system of n qubits
and N = 2n [20, 25]. Furthermore, we assume that H
can be decomposed as

H =

hk ,

K

Xk=1

where each hk ≥ 0 is a semideﬁnite positive Hermitian
operator. In some cases, the assumption on hk can be
satisﬁed after a simple rescaling of H depending on its
speciﬁcation.

The results in [23] use the Hamiltonian

2

where a1 refers to an ancillary qubit register of dimension
O(log(K)). The important property is

( ˜H)2 |φi ⊗ |0ia1 = (H |φi) ⊗ |0ia1 ,

(4)

for any |φi. Roughly, ˜H can be thought of as the square
root of H. Our algorithms will require evolving with ˜H
for arbitrary time:
Deﬁnition 1. Let ˜W (t) := exp(−i ˜Ht) be the evolution
operator of ˜H for time t, and ǫ > 0 a precision parameter.
We deﬁne W as a quantum circuit that satisﬁes k ˜W (t)−
Wk ≤ ǫ. The number of two-qubit gates to implement W
(i.e., the gate complexity) is CW (t, ǫ).

When H is a physical Hamiltonian described by lo-
cal operators, ˜H may be eﬃciently obtained with some
classical preprocessing. To obtain CW (t, ǫ) in some in-
stances, we note that the results in [21, 24] provide an ef-
ﬁcient method for simulating Hamiltonians of complexity
polylogarithmic in 1/ǫ. In more detail, we could assume
that we have a presentation of the Hamiltonian as

or

H =

K

Xk=1

αkΠk ,

H =

1
2

K

Xk=1

αkUk ,

(5)

(6)

where the coeﬃcients satisfy αk > 0. The operators Πk
are projectors (i.e., (Πk)2 = Πk) and Uk are unitaries of
eigenvalues ±1 in this case. Many qubit Hamiltonians
can be represented in this way, where the Uk correspond,
for example, to Pauli operators. We note that Eq. (6) can
be reduced to Eq. (5) by a simple rescaling in which Πk =
(Uk + 1lN )/2 and disregarding the factor proportional to
the N×N identity operator 1lN . In either case, we assume
that there is a mechanism available to simulate Πk or Uk;
that is, we assume access to a unitary

K

Q = −

K

eiπΠk ⊗ |kihk|a2

Xk=1
Xk=1
Uk ⊗ |kihk|a2 ,

(2)

=

(7)

where a2 is also an ancillary register of O(log(K)) qubits.
The gate complexity of each Uk is CU , which depends on
the problem, and the gate complexity of the conditional
Uk operation is O(CU log(K)).

Once the Hamiltonian H has been reduced to the form

of Eq. (5), we obtain

K

˜H =

Xk=1phk ⊗(cid:0)|kih0|a1 + |0ihk|a1(cid:1) ,

(3)

˜H =

K

Xk=1

√αkΠk ⊗(cid:0)|kih0|a1 + |0ihk|a1(cid:1) .

(8)

To be able to use the results in [24] for simulating ˜H in
this case, we note that

|kih0|a1 + |0ihk|a1 =

i

2he−i(π/2)(|kih0|a1
−ei(π/2)(|kih0|a1

+|0ihk|a1

(9)

+|0ihk|a1

)−
)i .

This provides a decomposition of ˜H as a linear combina-
tion of ˜K = O(K) unitary operations ˜Uk; that is,

˜H =

˜K

Xk=1

˜αk ˜Uk ,

(10)

and ˜αk > 0. The unitaries in the right hand side of
Eq. (9) can be implemented with O(log(K)) two-qubit
gates using standard techniques. The algorithm in [24]
assumes the ability to implement the unitary

˜Q =

˜K

Xk=1

˜Uk ⊗ |kihk|a2 .

(11)

Since the unitaries ˜Uk are directly related to the Uk, ˜Q
can be simulated with O(1) uses of Q and additional
two-qubit gates that do not contribute signiﬁcantly to
the ﬁnal gate complexity.

The query complexity of the method in [24] is deter-
mined by the number of uses of ˜Q to implement an ap-
proximation of ˜W (t). The gate complexity stated in [24]
is the number of additional two-qubit gates required.
Then, the results in [24] provide a Hamiltonian simula-
tion method W to approximate ˜W (t) for this case, within
precision ǫ, of query complexity

O (τ log(τ /ǫ)/ log log(τ /ǫ)) .

(12)

Here, τ = |t|Pk ˜αk and thus τ = O(|t|Pk √αk). The

additional gate complexity of W obtained in [24] for this
case is

O (Kτ log(τ /ǫ)/ log log(τ /ǫ)) .

(13)

These results also imply that the overall gate complexity
of W is

CW (t, ǫ) = O(cid:18)(log(K)CU + K)τ

log(τ /ǫ)

log log(τ /ǫ)(cid:19) .

(14)

We refer to [24] for more details.

In general, our quantum algorithm to sample from
improve-
Gibbs distributions provides an exponential
ment in terms of 1/ǫ, with respect to other known al-
gorithms [8, 9, 11], whenever CW (t, ǫ) is polylogarithmic
in 1/ǫ. As discussed, this is the case for a large class of
Hamiltonians such as those when the Uk are presented
as Pauli operators, so that CU = O(n).

For the quantum algorithm that computes an estimate
of the hitting time of a Markov chain, we will assume that
we have query access to the Hamiltonian H, and that H

3

can be presented as in Eq. (5). This assumes the exis-
tence of a procedure that outputs the matrix elements
of H. Constructing a quantum circuit W that approx-
imates the evolution with ˜H in this case is technically
involved and we leave that analysis for Appx. A. As in
the previous case, we use the methods in [21, 24] to show
that CW (t, ǫ) is almost linear in |t| and sublogarithmic
in |t|/ǫ.
Another useful technique for our quantum algorithms,
also used in [20, 22, 24, 26], regards the implementation of
linear combinations of unitary operations. More speciﬁ-
l=0 γlVl, where γl > 0 and Vl
are unitary operations, and that there is a mechanism to
implement Vl. That is, we have access to the unitary

cally, assume that X = PL−1

R =

L−1

Xl=0

Vl ⊗ |lihl|a3 ,

(15)

where a3 is an ancillary register of O(log(L)) qubits.
Lemma 6 of [22] implies that we can prepare a normal-
ized version of the state X |φi with O(γ/kX |φik) uses of
R in addition to O(Lγ/kX |φi k) two-qubit gates, where
γ = PL−1
l=0 γl. When Vl = V l, for some unitary V , and
the gate complexity of V is CV , the gate complexity of
R is O(LCV ).
In this case, the overall gate complex-
ity of the algorithm is O(LCV γ/kX |φi k). This result
follows from Lemma 8 of [22]. The implication is that
the overall gate complexity is dominated by the largest
gate complexity of the unitaries in R times the number
of amplitude ampliﬁcation steps.

For completeness, the quantum algorithm to imple-
ment X is built upon O(γ/kX |φi k) amplitude ampli-
ﬁcation steps [27]. The operation for state preparation
starts by preparing the ancillary state

B |0ia3 =

1
√γ

L−1

Xl=0

√γl |lia3 ,

(16)

where B is unitary. Applying B requires O(L) two-qubit
gates and, in those cases where we can exploit the struc-
ture of the coeﬃcients γl, it can be done more eﬃciently.
The state preparation step then applies R followed by
B†. One can show that the ﬁnal state of this step is

(cid:18) X
γ |φi(cid:19) ⊗ |0ia3 + |Θ⊥i ,

(17)

where |Θ⊥i is supported in the subspace orthogonal to
|0ia3. Amplitude ampliﬁcation allows us to amplify the
probability of observing the state |0ia3 to a constant.
This state corresponds to the desired outcome. The num-
ber of amplitude ampliﬁcation steps is linear in the in-
verse of k(X/γ)|φi k.
tion [18]. Let T be a unitary that implements

The third useful technique regards amplitude estima-

T |φi |0i = (A|φi)|0i +(cid:12)(cid:12)Φ⊥(cid:11)|1i ,

(18)

k(cid:12)(cid:12)Φ⊥(cid:11)k ≤ 1. Our goal is to obtain an estimate of

where A is an operator that satisﬁes kAk ≤ 1 and
hφ| A|φi = hφ|h0| T |φi|0i. The results in [18] imply that
there exists a quantum algorithm that outputs an esti-
mate of the expectation value of T within precision ǫ. For
constant conﬁdence level (c ≈ 0.81), the quantum algo-
rithm uses T and other two-qubit gates O(1/ǫ) times. It
also uses the unitary that prepares the initial state |φi,
O(1/ǫ) times. Increasing the conﬁdence level can be done
with an additional overhead that is logarithmic in |1− c|.

III. PREPARATION OF GIBBS STATES

The thermal Gibbs state of a quantum system H at

inverse temperature β ≥ 0 is the density matrix

ρ =

1
Z

e−βH ,

(19)

where Z = Tr[e−βH] = Pj e−βEj is the partition func-
tion. Then, the probability of encountering the sys-
tem in the quantum state |ψji, after measurement, is
pj = e−βEj /Z.
Given a precision parameter ǫ > 0, a quantum algo-
rithm to sample from the Gibbs distribution pj can be
obtained from a unitary ¯V that satisﬁes

Tra(cid:2) ¯V (|0ih0| ⊗ |0ih0|a) ¯V †(cid:3) = ˆρ

and

1
2k ˆρ − ρk1 ≤ ǫ .

(20)

(21)

We use the label a for an ancillary qubit system that will
be discarded at the end of the computation. The dimen-
sion of a depends on the algorithm. The requirement on
the trace distance in Eq. (21) implies that no measure-
ment can distinguish between ρ and ˆρ with probability
greater than ǫ [28].

The main result of this section is:

Theorem 1. There exists a quantum algorithm that pre-
pares an approximation of the Gibbs state. The quantum
algorithm implements a unitary ¯V of gate complexity

O r N
Z

(CW (t, ǫ′) + n + log(J))! ,

(22)

with t = O(pβ log(1/ǫ′)), ǫ′ = O(ǫpZ/N ), and J =
O(pkHkβ log(1/ǫ′)).

When H is presented as in Eq. (5), we can replace
CW (t, ǫ′) by Eq. (14) if we use the best-known Hamil-
tonian simulation algorithm.
In cases of interest, such
as qubit systems given by Hamiltonians that are linear
combinations of Pauli operators, we have αk = O(1),

4

CU = O(n) = O(log(N )), and K = O(n) = O(log(N )).
In this case, the overall gate complexity is

O r N β
Z

polylog r N β
Z

1

ǫ!! .

(23)

The important result is that the complexity of our algo-
rithm is polylogarithmic in 1/ǫ and also improves upon
the complexity in β with respect to the methods in [8, 9].

Our quantum algorithm to sample from Gibbs distri-
butions uses the two techniques discussed in Sec. II. In
this case, we will be interested in implementing an oper-
ator proportional to e−βH/2. To ﬁnd a decomposition as
a linear combination of unitaries, we invoke the so-called
Hubbard-Stratonovich transformation [29]:

e−βH/2 =r 1

2π Z ∞

−∞

dy e−y2/2e−iy√βH .

(24)

(25)

−∞

= r 1

In our case, we do not have a method to simulate the
evolution with √H. Nevertheless, we assume that we
can evolve with ˜H, which satisﬁes Eq. (4). Then,
(e−βH/2 |φi) ⊗ |0ia1 =
2π Z ∞

dy e−y2/2e−iy√β ˜H!|φi|0ia1 ,
for any state |φi. Note that the ancilla a1 remains in
the state |0ia1 and will be discarded at the end of the
computation. Equation (25) implies that the operator
e−βH/2 can be approximated by a linear combination of
evolutions under ˜H. Because y ∈ (−∞,∞), we will need
to ﬁnd an approximation by a ﬁnite, discrete sum of op-
erators e−iyj√β ˜H . We obtain:
Lemma 1. Let

X′ =r 1

2π

J

Xj=−J

δy e−y2

j /2e−iyj√β ˜H ,

(26)

where yj = jδy, for some J = Θ(pkHkβ log(1/ǫ′)) and
δy = Θ(1/pkHkβ log(1/ǫ′)). Then, if kHkβ ≥ 4 and
log(1/ǫ′) ≥ 4,

k(e−βH/2 |φi) ⊗ |0ia1 − X′ |φi|0ia1 k ≤ ǫ′/2 ,

(27)

for all states |φi.
Proof. Consider the real function

f (˜x) =

1
√2π

∞

Xj=−∞

δy e−y2

j /2e−iyj√β ˜x

(28)

where ˜x ∈ R and assume |˜x| ≤ a < ∞. The Poisson sum-
mation formula and the Fourier transform of the Gaus-
sian imply

f (˜x) =

∞

Xk=−∞

e−ω2

k/2 ,

(29)

5

implement

In general, we cannot

the unitaries
e−iyj√β ˜H exactly but we can do so up to an approxi-
mation error. We obtain:
Corollary 1. Let log(1/ǫ′) ≥ 4, kHkβ ≥ 4, and Wj be
a unitary that satisﬁes

kWj − e−iyj√β ˜Hk ≤ ǫ′/4

(37)

for all j = −J,−J + 1, . . . , J. Let

X =r 1

2π

J

Xj=−J

δy e−y2

j /2Wj .

(38)

Then,

k(e−βH/2 |φi) ⊗ |0ia1 − X |φi|0ia1 k ≤ ǫ′ .

(39)

Proof. The coeﬃcients in the decomposition of X′
Lemma 1 satisfy

in

r 1

2π

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

and thus

δy e−y2

J

Xj=−J
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

r 1

2π

j /2 − 1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
j /2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xj=−J

δy e−y2

J

≤ ǫ′/2 ≤ 1/4 ,

(40)

≤ 5/4 .

(41)

This follows from Eq. (27) for the case of H = ˜H = 0.
The triangle inequality and Eq. (37) imply

kX − X′k ≤ (5/16)ǫ′ ,

(42)

and together with Eq. (27) we obtain the desired result.

In Sec. II we described a technique to implement X =
PL−1
l=0 γlVl. In this case, l = j + J and L = 2J + 1. The
coeﬃcients and unitaries are e−y2
j /2 and Wj, respectively.
The quantum algorithm for preparing Gibbs states will
aim at preparing a normalized version of X |φ0i, for a
suitable initial state |φ0i, using the technique of Sec. II.

1

1

(30)

δy = Ω 
such that |f (˜x) − e−ω2
and plog(1/ǫ′) ≥ 2, we can choose

where ωk = −√β ˜x + k/δy. Then, there exists
a√β +plog(1/ǫ′)!
0/2| ≤ ǫ′/4. Note that if a√β ≥ 2
apβ log(1/ǫ′)! .
δy = Θ 
j /2e−iyj√β ˜x(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xj=J
Xj=J
1 − e−yJ δy/2 .

1
√2π

δy
√2π

δy
√2π

δy
√2π

Xj=J

e−yJ yj /2

δy e−y2

e−y2

e−y2

Also,

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(31)

≤

≤

≤

∞

∞

J /2

j /2

∞

It follows that there exists a value for J, which implies

yJ = Θ(plog(1/ǫ′)), such that
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Xj=−J

f (˜x) −

1
√2π

δy e−y2

J

Using the triangle inequality we obtain

e−ω2

0/2 −

1
√2π

J

Xj=−J

δy e−y2

and we can represent

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

j /2e−iyj√β ˜x(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
j /2e−iyj√β ˜x(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

≤ ǫ′/4 .

(32)

≤ ǫ′/2 ,

(33)

e−ω2

0/2 =

1

√2π Z ∞

−∞

dy e−y2/2e−iy√β ˜x .

(34)

To prove the Lemma, it suﬃces to act with X′ on the
eigenstates of ˜H. We can then use the previous bounds if
we assume that ˜x denotes the corresponding eigenvalue
of ˜H. In particular, a = k ˜Hk. Then, if k ˜Hk√β ≥ 2 and
plog(1/ǫ′) ≥ 2, it suﬃces to choose

δy = Θ 

1

k ˜Hkpβ log(1/ǫ′)!
= Θ(cid:16)log(1/ǫ′)k ˜Hkpβ(cid:17) .

and

J =

yJ
δy

The result follows from noticing that k ˜Hk = O(pkHk)
and that X′ then approximates e−β( ˜H)2/2. Since we
act on initial states of the form |φi |0ia1 , the action of
e−β( ˜H)2/2 is the same as that of e−βH/2 on these states.

(35)

(36)

A. Algorithm

We set ǫ′ = O(ǫpZ/N ). Our quantum circuit ¯V is

deﬁned in two basic steps. The ﬁrst step regards the
preparation of a maximally entangled state

|φ0i =

1
√N

N−1

Xj=0

|ψji ⊗(cid:12)(cid:12)ψ∗j(cid:11)a4 ⊗ |0ia1,a2,a3

(43)

where we used an additional ancillary system a4 of n
qubits. a1, a2, a3, and a4 build the ancillary register a

of Eq. (20). Note that |φ0i coincides with the maximally
entangled state

|φ0i =

1
√N

N−1

Xσ=0

|σi |σia4 ⊗ |0ia1,a2,a3 ,

(44)

where |σi is a n-qubit state in the computational basis,
i.e., |σi = |0 . . . 0i ,|0 . . . 1i , . . ..
The second step regards the preparation of a normal-
ized version of X |φ0i. This step uses the algorithm for
implementing linear combinations of unitary operations
described in Sec. II, which also uses amplitude ampliﬁca-
tion. The operator X is deﬁned in Eq. (38) and requires
a Hamiltonian simulation method for implementing Wj.

B. Validity and complexity

As described, our quantum algorithm prepares the nor-

malized state

X |φ0i
kX |φ0ik

,

with constant probability. We also note that

ke−βH/2 |φ0ik =pZ/N

and Eq. (39) implies

for our choice of ǫ′. Then, the prepared state satisﬁes

= O(ǫpZ/N )

(cid:12)(cid:12)(cid:12)kX |φ0ik −pZ/N(cid:12)(cid:12)(cid:12)
(cid:13)(cid:13)(cid:13)(cid:13)
X |φ0i
kX |φ0ik −

e−βH/2 |φ0i

ke−βH/2 |φ0ik(cid:13)(cid:13)(cid:13)(cid:13)

≤ ǫ/2 .

(48)

We note that
e−βH/2 |φ0i =
N−1
Xj=0
=

1
√N

e−βEj/2 |ψji ⊗(cid:12)(cid:12)ψ∗j(cid:11)a4 ⊗ |0ia1,a2,a3 .

(49)

If we disregard the ancillary system a, this is the Gibbs
state: The probability of obtaining |ψji, after measure-
ment, is proportional to e−βEj . Then, the property of
the trace norm being non-increasing under quantum op-
erations and Eq. (48) imply

where

1
2 k ˆρ − ρk ≤ ǫ ,

ˆρ = Tra(cid:20) X |φ0ihφ0| X†
kX |φ0ik2 (cid:21) ;

(50)

(51)

see Eq. (20). That is, ˆρ is the state prepared by our
algorithm after tracing out the ancillary register a.

(45)

(46)

(47)

6

The number of amplitude ampliﬁcation steps

is
O(1/kX |φ0ik) and Eq. (46) implies that this number
is also O(pN/Z). The gate complexity of each step
is the gate complexity of preparing |φ0i in addition to
the gate complexity of implementing X. The former is
O(n) as |φ0i takes the simple form of Eq. (44) and can
be prepared with O(n) controlled operations. X is im-
plemented in three stages as described in Sec. II. The
ﬁrst stage requires the unitary B used in Eq. (16).
In
this case, the coeﬃcients γl are proportional to e−y2
j /2.
Then, the gate complexity of B is O(log(J)) in this case
if we use one of the methods developed in [30, 31]. The
second stage regards the implementation of R. In this ex-
ample, R is the unitary that implements Wj conditional
on the state |jia3 . Since Wj corresponds to a Hamilto-
nian simulation algorithm that approximates evolutions
with ˜H, the gate complexity of R is dominated by the
largest gate complexity of Wj .
In particular, Wj ap-
proximates e−i ˜Ht within precision ǫ′ and for maximum

t = O(pβ log(1/ǫ′)). Then the gate complexity of R is

order CW (t, ǫ′).

The overall gate complexity is then

O r N
Z

(CW (t, ǫ′) + n + log(J))! ,

(52)

with t = O(pβ log(1/ǫ′)) and ǫ′ = O(ǫpZ/N ). This

proves Thm. 1.

IV. ESTIMATION OF HITTING TIMES

We consider a stochastic process that models a Markov
chain. The number of diﬀerent conﬁgurations is N and
P is the N × N stochastic matrix. We label each con-
ﬁguration as σ = 0, 1, . . . , N − 1 and the entries of P
are transition or conditional probabilities Pr(σ′|σ). We
will assume that P is reversible and irreducible, satis-
ﬁes the so-called detailed balance condition [5], and has
nonnegative eigenvalues. The unique ﬁxed point of P is
the N -dimensional probability vector π. It is useful to
use the bra-ket notation, where |νi represents a vector
ν ∈ CN and hv| = (|vi)†. Then, P |πi = |πi,



|πi =Xσ

=


πσ |σi

πN−1

π0
...

(53)

,

.

and πσ is the probability of ﬁnding conﬁguration σ when
sampling from the ﬁxed point of P .

The hitting time of a stochastic process is roughly de-
ﬁned as the ﬁrst time at which the process is encountered
in a particular subset of conﬁgurations. To deﬁne the hit-
ting time in detail, we assume that there is a subset M of
NM conﬁgurations that are “marked” and the remaining
NU conﬁgurations constitute the “unmarked” subset U.

Here, NM + NU = N . With no loss of generality, the
stochastic matrix P takes the form

P =(cid:18) PUU PUM

PMU PMM(cid:19) ,

(54)

where PUU and PMM are matrices (blocks) of dimension
NU × NU and NM × NM, respectively, and PMU and
PUM are rectangular blocks. The entries of the block
PS ′S determine the probability of a conﬁguration being
in the subset S′ given that the previous conﬁguration was
in the subset S. Our assumptions imply U,M 6= {∅} and
PUM, PMU 6= 0. The hitting time is the expected time
to ﬁnd a marked conﬁguration if the initial probability
vector is |πi. That is, as in [17], we deﬁne the hitting
time of P via the following classical algorithm:

1. Set t = 0
2. Sample σ from |πi
3. If σ ∈ M, stop
4. Otherwise, assign t ← t + 1, apply P , and go to 3.
The hitting time th is the expected value of the random
variable t.

We let |πUi and |πMi represent the probability vectors
obtained by conditioning |πi on U and M, respectively.
These are
|πUi = Pσ∈U
π(σ)|σi
πU
with πU = Pσ∈U

, |πMi = Pσ∈M
π(σ)|σi
πM
π(σ) and πM = Pσ∈M
P ′ =(cid:18) PUU

useful to deﬁne the modiﬁed Markov chain

0

PMU 1lNM(cid:19) ,

(56)

, (55)

π(σ).

It is

which refers to an “absorbing wall” for the subset M.
Here, 1lNM is the NM× NM identity matrix. As deﬁned,
P ′ does not allow for transitions from the subset M to
the subset U. We will observe below that P ′, and thus
PUU , play an important role in the determination of th.

Our deﬁnition of hitting time implies

th =

∞

Xt=0

t Pr(t) ,

(57)

where Pr(t) is the probability of t if we use the previous
classical algorithm. In particular, Pr(t = 0) = πM. We
rewrite

7

where |1Ui = Pσ∈U |σi. This is because, conditional on
t > 0, which occurs with probability πU , the initial prob-
ability vector is proportional to (PUU )t′
|πUi. Then, the
probability of having t > t′ is measured by the proba-
bility of remaining in U after PUU was applied t′ times.
Equations (58) and (59) imply

th = πU h1U| (1lNU − PUU )−1 |πUi ,

(60)

where we used (1 − x)−1 = P∞t′=0 xt′
. We note that
1l − PUU is invertible under our assumptions, since the
eigenvalues of PUU are strictly smaller than 1 (see below).
The complexity of a method that estimates th using the
previous classical algorithm also depends on the variance
of the random variable t. This is

σ2 =

∞

Xt=0

t2Pr(t) − (th)2 ,

(61)

and after simple calculations, we can rewrite it as

σ2 = 2πU h1U|

∞

Xt′=0

t′(PUU )t′

|πUi + th − (th)2 .

(62)

For constant conﬁdence level and precision ǫ in the es-
timation of th, Chebyshev’s inequality implies that the
previous classical algorithm must be executed M =
O((σ/ǫ)2) times to obtain t1, . . . , tM and estimate th as
the average of the ti. The expected number of applica-
tions of P is then M th = O(th(σ/ǫ)2).

To bound the classical complexity, we consider the
worst case scenario in which |πUi is an eigenvector of
PUU corresponding to its largest eigenvalue 1 − ∆ < 1.
In that case, th = πU /∆ and σ2 = O(πU /∆2). When
∆ ≪ 1, the expected number of applications of P is then
O(1/(∆3ǫ2)) in this case. This determines the average
complexity of the classical algorithm that estimates th.
The entries of the symmetric discriminant matrix S of

P are

Sσσ′ =q(P ◦ P †)σσ′ ,

(63)

where ◦ is the Hadamard product. The detailed balance
condition implies

π(σ′)Pr(σ|σ′) = Pr(σ′|σ)π(σ)

(64)

and thus

th =

∞

Xt′=0

Pr(t > t′)

(58)

Then,

pPr(σ|σ′)Pr(σ′|σ) = Pr(σ|σ′)s π(σ′)

π(σ)

.

(65)

so that we take into account the factor t in Eq. (57), i.e.,
Pr(t > t′) = Pr(t′ + 1) + Pr(t′ + 2) + . . .. Note that

S = D−1P D ,

(66)

Pr(t > t′) = πU h1U| (P ′)t′
= πU h1U| (PUU )t′

|πUi
|πUi ,

(59)

where D is a diagonal matrix of dimension N with entries

given by pπ(σ). The symmetric matrix or Hamiltonian
¯H = 1lN −S is known to be “frustration free” [32] and can

be represented as in Eq. (5) using a number of techniques.
For example, if P has at most d nonzero entries per row
or column (i.e., P is d-sparse), the number of terms K in
the representation of ¯H can be made linear or quadratic
in d; see Appx. A or [33] for more details.

We now let ΠU be the projector into the subset U and

deﬁne

H = ΠU

¯HΠU .

Note that

H = 1lNU − D−1
U

PUU DU ,

(67)

(68)

where DU is the diagonal matrix obtained by project-
ing D of Eq. (66) into the subspace U. That is, DU =
ΠU DΠU and Eq. (68) implies H > 0. Then, Eqs. (66)
and (60) imply

th = πU h√πU| (1/H)|√πUi ,

(69)

norm. A similar expression for th was obtained in [17].

where we deﬁned |√πUi = Pσ∈Upπ(σ) |σi /√πU so
that |√πUi is normalized according to the Euclidean
In Appx. A we describe how H can be speciﬁed as
H = PK
k=1 αkΠk, where αk > 0 and Πk are projectors.
Then H is of the form of Eq. (5) and we write ˜H for the
associated Hamiltonian according to Eq. (3). CW (t, ǫ)
is the complexity of approximating ˜W (t) = exp(−i ˜Ht),
and we roughly describe a method for simulating ˜W (t)
below.

A quantum algorithm to obtain th can be constructed
from the relation in Eq. (69). That is, th coincides with
πU times the expected value of the operator 1/H in the
assume that there is a unitary procedure (oracle) QU that
allows us to implement the transformation

√πU(cid:11). For our quantum algorithm, we also

pure state (cid:12)(cid:12)

8

In Appx. A we describe a method to simulate the evo-
lution with ˜H. To this end, we also assume that there
exists a procedure QP that computes the locations and
magnitude of the nonzero entries of the matrix P . More
speciﬁcally, QP performs the map
QP |σi →|σi |σ′1, . . . , σ′di⊗

(73)
⊗ |Pr(σ|σ′1), Pr(σ′1|σ), . . . , Pr(σ|σ′d), Pr(σ′d|σ)i ,
where d is the sparsity of P . The conﬁgurations σ′i are
such that Pr(σ|σ′i), Pr(σ′i|σ) 6= 0. We write CP for the
In Appx. A we de-
complexity of implementing QP .
˜K
˜Uk/2 in terms of
scribe a decomposition of ˜H = P
k=1
˜K = O(d2) unitaries, so that we can use the results of [24]
to simulate ˜W (t) = exp(−i ˜Ht). Each ˜Uk can be imple-
mented with O(1) uses of QU and QP , and O(d log(N ))
additional gates. Using the results of [24] and Sec. II,
the complexity for simulating ˜W (t) within precision ǫ′,
obtained in Eq. (A24), is

τ log(τ /ǫ′)

CW (t, ǫ′) = O(cid:18)(d log(N ) + CP + CU )
log log(τ /ǫ′)(cid:19) ,
where τ = |t|d2. Note that CW (t, ǫ′) is almost linear in
|t| and polynomial in d, and the dependence on d may
be improved by using the results in [34]. Then, assuming
access to QP , we obtain:

(74)

Corollary 2. There exists a quantum algorithm to esti-
mate th within precision ǫ and constant conﬁdence level
that implements a unitary ¯V of gate complexity

˜O(cid:18) 1

ǫ∆(cid:18) d2
√∆

(d log(N ) + CP + CU ) + C√π(cid:19)(cid:19) .

(75)

The ˜O notation hides factors that are polylogarithmic in
d/(ǫ∆).

QU |σi = − |σi if σ ∈ U

(70)

The dominant scaling of the complexity in terms of
∆ and ǫ is then ˜O(1/(ǫ∆3/2)), which is a quadratic im-
provement over the classical complexity obtained above.

and QU |σi = |σi otherwise. We also assume access to a
unitary Q√π such that

Q√π |0i =(cid:12)(cid:12)

√π(cid:11) .

(71)

We write CU and C√π for the respective gate complexi-
ties. The main result of this section is:

Theorem 2. There exists a quantum algorithm to esti-
mate th within precision ǫ and constant conﬁdence level
that implements a unitary ¯V of gate complexity

O(cid:18) 1

ǫ′ (cid:0)CW (t, ǫ′) + CU + C√π + CB(cid:1)(cid:19) ,

(72)

where CB = O(log(1/(∆ǫ))), ǫ′ = O(ǫ∆/ log(1/(ǫ∆)),

and t = O(cid:16)log(1/(ǫ∆))/√∆(cid:17).

Our quantum algorithm uses the three techniques de-
scribed in Sec. II and uses some other results in [22]. In
fact, since H > 0, we can improve some results in [22]
that regard the decomposition of the inverse of a ma-
trix as a linear combination of unitaries. That is, for a
positive matrix H, we can use the identity

1
H

=

1

2Z ∞

0

dβ e−βH/2 ,

(76)

and use the Hubbard-Stratonovich transformation of
Eq. (25) to simulate e−βH/2. Roughly, 1/H can be sim-
ulated by a linear combination of unitaries, each corre-
sponding to an evolution with ˜H for time y√β. Since
β ∈ [0,∞) and y ∈ (−∞,∞), we will need to ﬁnd
an approximation by a ﬁnite, discrete sum of operators
e−iyj√βk ˜H . We obtain:

Lemma 2. Let

and

X′ =

1
√2π

δz

K

Xk=0

J

Xj=−J

δy e−y2

j /2e−iyj√zk ˜H ,

(77)

where yj = jδy, zk = kδz, and kHk ≥ ∆ > 0.
Then, there exists J = Θ(p1/∆ log3/2(1/(∆ǫ))), K =
Θ((1/∆) log(1/(∆ǫ))/ǫ), δy = Θ(√∆/ log(1/(∆ǫ))), and
δz = Θ(ǫ) such that

H |φi(cid:19) ⊗ |0ia1 − X′ |φi |0ia1(cid:13)(cid:13)(cid:13)(cid:13)
(cid:13)(cid:13)(cid:13)(cid:13)
(cid:18) 1

for all states |φi.
Proof. We ﬁrst consider the approximation of 1/x by a
ﬁnite sum of e−zkH :

≤ ǫ/2

(78)

1
x − δz

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

K−1

Xk=0

e−zkx(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

=(cid:12)(cid:12)(cid:12)(cid:12)
=(cid:12)(cid:12)(cid:12)(cid:12)

1 − e−zKx

1
x − δz
1
x

1 − e−δzx(cid:12)(cid:12)(cid:12)(cid:12)
O(δzx + e−zK x)(cid:12)(cid:12)(cid:12)(cid:12)

Assuming that 1 ≥ x ≥ 1/κ so that 1/x ≤ κ, we can
upper bound the above quantity by ǫ/4 if we choose
e−zK /κ = Θ(ǫ/κ) and δz = Θ(ǫ). These imply

(79)

(80)

Let

zK = Θ(κ log(κ/ǫ))

Then,

(81)

9

(86)

J = Θ (√zK log(zK/ǫ))
= Θ(cid:16)√κ log3/2(κ/ǫ)(cid:17) .

Thus far, we presented an approximation of 1/x, for
1 ≥ x ≥ 1/κ, as a doubly weighted sum of terms
exp(−iyj√zkx). To obtain the desired result, it suﬃces
to act with X′ on any eigenstate of ˜H and replace √x
by the corresponding eigenvalue, as we did in Lemma 1.
Since H ≥ ∆, we need to replace κ by 1/∆ in the bounds
obtained for δz, δy, K, J, zK, and yJ .

In general, we cannot

the unitaries
e−iyj√2zk ˜H exactly but we can do so up to an approx-
imation error. We obtain:

implement

Corollary 3. Let ǫ > 0 and Wjk be a unitary that sat-
isﬁes

kWjk − e−iyj√2zk ˜Hk ≤

ǫ

4zK

.

(87)

X =

1
√2π

δz

K

Xk=0

J

Xj=−J

δy e−y2

j /2Wjk .

(88)

and

K = zK/δz = Θ(κ log(κ/ǫ)/ǫ) .

(82)

In the next step, we invoke the proof of Lemma 1 and

approximate each e−zkx as

gk(x) =

1
√2π

J

Xj=−J

δy e−y2

j /2e−iyj√zkx ,

(83)

and we need to choose J and δy so that the approxima-
tion error is bounded by ǫ/(4zK). Then,

Lemma 1 then implies

ǫ

δz

K−1

Xk=0

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
δy = Θ 
= Θ 
= Θ(cid:18)

4zK

≤ (δzK)
≤ ǫ/4 .

(e−zkx − gk(x))(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pzK log(zK/ǫ)!
pκ log(κ/ǫ) log(κ log(κ/ǫ)/ǫ)!
√κ log(κ/ǫ)(cid:19) ,

1

1

1

(84)

(85)

(cid:13)(cid:13)(cid:13)(cid:13)

H |φi(cid:19) ⊗ |0ia1 − X |φi|0ia1(cid:13)(cid:13)(cid:13)(cid:13)
(cid:18) 1

Proof. If we replace each e−iyj√zkx by a term that is an
ǫ/(2zK) approximation in the deﬁnition of gk(x), it yields
an approximation of 1/x within precision ǫ/2 plus

≤ ǫ .

(89)

δzK
√2π

J

Xj=−J

δye−y2

j /2(ǫ/(4zK)) =

ǫ

4√2π

J

Xj=−J

δye−y2

j /2 .

(90)

(91)

Our choice of parameters in Lemma 2 implies

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1 −

1
√2π

J

Xj=−J

δye−y2

≤ ǫ/4

j /2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

so that the additional error is bounded by ǫ/2. The proof
follows by replacing √x by the corresponding eigenvalue
of ˜H and gk(x) by the linear combination of the Wjk with
weights δye−y2

j /2.

So far we showed that 1/H can be approximated within
precision ǫ by a linear combination of unitaries that
correspond to evolutions under ˜H for maximum time
yJ√zK = Θ((1/√∆) log(1/(∆ǫ))). Each such evolu-
tion must be implemented by a method for Hamilto-
nian simulation that approximates it within precision
ǫ′ = O(ǫ/zK) = O(ǫ∆/(log(1/(ǫ∆)))).

In Sec. II we described a technique to implement X =
l=0 γlVl. In this case, the coeﬃcients and unitaries are
j /2/√2π and Wjk, respectively. From Lemma 2

δzδye−y2
and Eq. (91), it is simple to show

PL−1

10

unitaries needed to implement X′. Each such uni-
tary requires evolving with ˜H for maximum time t =
O((1/√∆) log(1/(∆ǫ))). In addition, each such unitary
requires preparing a quantum state proportional to

|zK − γ| ≤

1 −

K

δz(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Xk=0
≤ zKǫ/4

1
√2π

J

Xj=−J

δye−y2

j /2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(92)

and thus γ ≈ zK or γ = Θ((1/∆) log(1/(∆ǫ))).

Last, we deﬁne the unitary T = (T2)†T1 such that

T1 |0i|0ia = √πU

X′

γ |√πUi|0ia + |Θ⊥i ,

(93)

and |Θ⊥i is supported in the subspace orthogonal to |0ia.
The ancillary register a includes the ancillary registers
a1, a2, a3 as needed for evolving with ˜H and implement-
ing X′. That is, |0ia = |0ia1,a2,a3. T1 can be implemented
It ﬁrst uses Q√π to prepare the quantum
as follows.
√πU(cid:11)|0ia′ +
√πM(cid:11)|1ia′, where the ancilla qubit a′ is part of
√πM(cid:11) |0⊥ia, where |0⊥ia
is orthogonal to |0ia. Then, if T = (T2)†T1, we obtain

state |√πi. It then uses QU to prepare √πU(cid:12)(cid:12)
√πM(cid:12)(cid:12)
pares √πU(cid:12)(cid:12)

the register a. Then, conditional on |0ia′, it implements
X′/γ as discussed in Sec. II. T2 is the unitary that pre-

√πU(cid:11)|0ia + √πM(cid:12)(cid:12)

h0|h0|a T |0i|0ia =

γ h√πU| X′ |√πUi .
πU

(94)

A. Algorithm

We set ǫ′ = O(ǫ∆/ log(1/(ǫ∆))). The quantum algo-
rithm for estimating the hitting time consists of two basic
steps. The ﬁrst step uses the amplitude estimation algo-
rithm of [18] to provide an estimate of h0|h0|a3 T |0i|0ia3
within precision ǫ′ and constant conﬁdence level (c ≈
0.81). Call that estimate ˜th. The output of the algo-
rithm is ˆth = zK ˜th.

B. Validity and complexity

As described, our quantum algorithm provides a
O(ǫ′zK) estimate of zK h0|h0|a3 T |0i|0ia3 .
Using
Eqs. (69) and (94), the output is an estimate of (zK/γ)th
within precision O((zK /γ)ǫ + zKǫ′). Our choice of ǫ′ im-
plies that this is O((zK /γ)ǫ). Also, using Eq. (92), we
obtain

= O(ǫ).

(95)

1 −

(cid:12)(cid:12)(cid:12)(cid:12)

zK

γ (cid:12)(cid:12)(cid:12)(cid:12)

Then, our quantum algorithm outputs ˆth, an estimate of
th within absolute precision O(ǫ).

Our quantum algorithm uses T , O(1/ǫ′) times. Each
in addition to the

T uses QU and Q√π two times,

1

√γ Xj,k   δyδze−y2

√2π !1/2

j /2

|j, ki .

(96)

The gate complexity for preparing this state using the
results in [30, 31] is CB = O(log(J) + log(K)) and then
CB = O(log(1/(∆ǫ))). The overall gate complexity is

O(cid:18) 1

ǫ′ (cid:0)CW (t, ǫ′) + CU + C√π + CB(cid:1)(cid:19) .

(97)

This proves Thm. 2. Using Eq. (A24) and replacing for
ǫ′ and t, and disregarding terms that are polylogarithmic
in d/(ǫ∆), the gate complexity is

˜O(cid:18) 1

ǫ∆(cid:18) d2
√∆

(d log(N ) + CP + CU ) + C√π(cid:19)(cid:19) .

(98)

V. CONCLUSIONS

We provided quantum algorithms for solving two prob-
lems of stochastic processes, namely the preparation of
a thermal Gibbs state of a quantum system and the es-
timation of the hitting time of a Markov chain. Our
algorithms combine many techniques, including Hamilto-
nian simulation, spectral gap ampliﬁcation, and methods
for the quantum linear systems algorithm. They provide
signiﬁcant speedups with respect to known classical and
quantum algorithms for these problems and are expected
to be relevant to research areas in statistical physics and
computer science, including optimization and the design
of search algorithms.

We ﬁrst showed that, starting from a completely en-
tangled state, we can prepare a state that is ǫ-close (in
trace distance) to a thermal Gibbs state using resources
that scale polylogarithmic in 1/ǫ. This is an exponential
improvement over previously known algorithms that rely
on phase estimation and have complexity that depends
polynomially in 1/ǫ [8, 9]. Our algorithm circumvents
the limitations of phase estimation by approximating the
exponential operator as a ﬁnite linear combination of uni-
tary operations and using techniques developed in [24] to
implement it. We also used techniques developed in the
context of spectral gap ampliﬁcation [23] to improve the
complexity dependence on the inverse temperature, from
almost linear in β to almost linear in √β.

Next, we presented a quantum algorithm to estimate
the hitting time of a Markov chain, initialized in its sta-
tionary distribution, with almost quadratically less re-
sources in all parameters than a classical algorithm (in a
worst-case scenario). This is done by ﬁrst expressing the
hitting time as the expectation value of the inverse of an
operator H, which is obtained by a simple transformation

of the Markov chain stochastic matrix. We then used re-
sults from [22] to apply 1/H; in this particular case, H is
positive and we showed that the implementation of 1/H
can be done more eﬃciently than the algorithm in [22],
in terms of the condition number of H. Such an expected
value can be computed using methods for amplitude esti-
mation. For constant conﬁdence level (c ≈ 0.81), the use
of amplitude estimation limits us to a complexity depen-
dence that is ˜O(1/ǫ), where ǫ is the absolute precision
of our estimate. It is possible to increase the conﬁdence
level towards c with an increase in complexity that is

O(log(|1 − c|)).

11

VI. ACKNOWLEDGEMENTS

AC was supported by a Google research award. RS
acknowledges support of the LDRD program at LANL
and NRO. We thank Sergio Boixo and Ryan Babbush at
Google Quantum A.I. Lab Team for discussions.

[1] K. Huang, Statistical Mechanics (John Wiley and Sons,

Theory of Computing (2014), pp. 283–292.

Inc., 1963).

[22] A. Childs, R. Kothari, and R. D. Somma, preprint

[2] R. Agarwal, Recent Trends in Optimization Theory and

arXiv:1511.02306 (2015).

Applications (World Scientiﬁc, 1995).

[23] R. D. Somma and S. Boixo, SIAM J. Comp 42, 593

[3] D.

A.
Wilmer,
http://pages.uoregon.edu/dlevin/MARKOV/markovmixing.pdf.

Levin,
Markov

Y.
chains

E.

L.
times,

Peres,

and

and mixing

(2013).

[24] D. W. Berry, A. M. Childs, R. Cleve, R. Kothari, and

R. D. Somma, Phys. Rev. Lett. 114, 090502 (2015).

[4] R. Portugal, Quantum Walks and Search Algorithms

[25] G. Ortiz, J. E. Gubernatis, E. Knill, and R. Laﬂamme,

(Springer, New York, 2013).

Phys. Rev. A 64, 022319 (2001).

[5] M. Newman and G. Barkema, Monte Carlo Methods in

[26] A. M. Childs and N. Wiebe, Quantum Information and

Statistical Physics (Oxford University Press, 1998).

Computation 12, 901 (2012).

[6] J. B. Anderson, Quantum Monte Carlo : Origins, De-
velopment, Applications: Origins, Development, Appli-
cations (Oxford University Press, 2007).

[7] R. D. Somma, S. Boixo, H. Barnum, and E. Knill, Phys.

Rev. Lett. 101, 130504 (2008).

[8] D. Poulin and P. Wocjan, Phys. Rev. Lett. 103, 220502

[27] L. K. Grover, in Proceedings of the 28th ACM Symposium

on Theory of Computing (1996), pp. 212–219.

[28] C. W. Helstrom, Quantum Detection and Estimation

Theory (Academic Press, New York, 1976).
[29] J. Hubbard, Phys. Rev. Lett. 3, 77 (1959).
[30] A. Kitaev and W. A. Webb, preprint arXiv:0801.0342

(2009).

(2008).

[9] C. Chiang and P. Wocjan, in Quantum Cryptography and

Computing (2010), pp. 138–147.

[31] R. D. Somma, preprint arXiv:1503.06319 (2015).
[32] R. D. Somma, C. D. Batista, and G. Ortiz, Phys. Rev.

[10] E. Bilgin and S. Boixo, Phys. Rev. Lett. 105, 170405

Lett. 99, 030603 (2007).

(2010).

[33] S. Boixo, G. Ortiz, and R. D. Somma, The European

[11] K. Temme, T. Osborne, K. Vollbrecht, D. Poulin, and

Physical Journal 224, 35 (2015).

F. Verstraete, Nature 471, 87 (2011).

[12] M. Schwarz, K. Temme, and F. Verstraete, Phys. Rev.

Lett. 108, 110502 (2012).

[13] A. Ambainis, J. Kempe, and A. Rivosh, in Proceedings of
the 16th ACM-SIAM Symposium on Discrete Algorithms
(2005), pp. 1099–1108.

[14] M. Szegedy, in Proceedings of the 45th IEEE Symposium
on Foundations of Computer Science (2004), pp. 575–
584.

[15] H. Krovi and T. A. Brun, Phys. Rev. A 73, 032341

(2006).

[16] F. Magniez, A. Nayak, J. Roland, and M. Santha, in
Proceedings of the 39th ACM Symposium on Theory of
Computing (2007), pp. 575–584.

[17] H. Krovi, M. Ozols, and J. Roland, Phys. Rev. A 82,

022333 (2010).

[18] E. Knill, G. Ortiz, and R. D. Somma, Phys. Rev. A 75,

012328 (2007).

[19] A. Montanaro, Proceedings of the Royal Society A 471,

20150301 (2015).

[20] R. D. Somma, G. Ortiz, J. E. Gubernatis, E. Knill, and

R. Laﬂamme, Phys. Rev. A 65, 042323 (2002).

[21] D. W. Berry, A. M. Childs, R. Cleve, R. Kothari, and
R. D. Somma, in Proc. of the 46th ACM Symposium on

[34] D. W. Berry, A. M. Childs, and R. Kothari, in Proceed-
ings of the 56th Symposium on Foundations of Computer
Science (2015), pp. 792–809.

Appendix A: Simulation of ˜H

We provide a method to simulate ˜H in time polylog-
arithmic in 1/ǫ, as required by the algorithm for esti-
mating hitting times of Sec. IV. We assume that there
exists a procedure QP that computes the locations and
magnitude of the nonzero entries of the matrix P . More
precisely, QP performs the map

QP |σi = |σi |σ′1, . . . , σ′di ⊗

(A1)
⊗ |Pr(σ|σ′1), Pr(σ′1|σ), . . . , Pr(σ|σ′d), Pr(σ′d|σ)i ,
where d is the sparsity of P , i.e., the largest number
of nonzero matrix elements per row or column. The
transition probabilities are assumed to be exactly rep-
resented by a constant number of bits and we disregard
any rounding-oﬀ errors. We also assume access to the

oracle QU such that

QU |σi = − |σi if σ ∈ U

(A2)

and QU |σi = |σi otherwise.
The Hamiltonians ¯H and H can be constructed as
follows. For each pair (σ, σ′), such that σ 6= σ′ and
Pr(σ|σ′) 6= 0, we deﬁne an unnormalized state
(pPr(σ|σ′)|σ′i −pPr(σ′|σ)|σi) .

|µσ,σ′i =

1
√2

(A3)

Then, if σf 6= σ0,
hσf|Xσ,σ′ |µσ,σ′ihµσ,σ′| σ0i = −qPr(σf|σ0)Pr(σ0|σf ) ,

(A4)

and if σf = σ0,

12

decomposition of ˜H in terms of simple unitary opera-
tions so that we can use the results of [24] to devise a
method to simulate exp(−i ˜Ht). We begin with the sec-
ond term in the right hand side of Eq. (A10). Its square
root is

Xσ′∈U


sXσ∈M

Pr(σ|σ′)

|σ′ihσ′| .

This term can be simply obtained as a sum of two diag-
onal unitary operations:

1
2

(UD + U†D) .

UD applies a phase to the state |σ′i as
UD |σ′i = eiθσ′ |σ′i

(A11)

(A12)

(A13)

(A14)

hσ0|Xσ,σ′ |µσ,σ′ihµσ,σ′| σ0i = Xσ′6=σ

Pr(σ′|σ)
= 1 − Pr(σ|σ) .

(A5)

with

These are the same matrix entries of ¯H and the implica-
tion is that

¯H =Xσ,σ′ |µσ,σ′ihµσ,σ′| .

(A6)

This is the desired representation of the ¯H as a sum of
positive operators. In particular, we can normalize the
states and deﬁne

,

|¯µσ,σ′i = |µσ,σ′i
k |µσ,σ′ik
p¯ασ,σ′ = k |µσ,σ′ik =r Pr(σ|σ′) + Pr(σ′|σ)

2

Then,

(A7)

.

(A8)

¯H =Xσ,σ′

¯ασ,σ′ |¯µσ,σ′i h¯µσ,σ′| .

(A9)

We let ΠU be the projector into the subspace U. The
¯HΠU , and using Eq. (A6), we
Hamiltonian is H = ΠU
obtain

cos(θσ′ ) =sXσ∈M

Pr(σ|σ′) ,

if σ′ ∈ U. Otherwise, UD |σ′i = i |σ′i. UD can then be
implemented by ﬁrst using QU to detect if σ′ is in U or
not. It next applies QP and computes θσ′ in an additional
register. Conditional on the value of θσ′ , it applies the
corresponding phase to |σ′i. It then applies the inverse of
QP to undo the computation. That is, UD requires O(1)
uses of QU and QP , and the additional gate complexity
is O(d) due to the computation of θσ′ .
The ﬁrst term in the right hand side of Eq. (A10) can
be written as a sum of K′ = O(d2) terms as follows.
Using QP we can implement a coloring of the graph G
with vertex set V (G) = {σ : σ ∈ U} and edge set E(G) =
{(σ, σ′) : σ, σ′ ∈ U, Pr(σ|σ′) 6= 0}. We can use the same
coloring as that described in [21], which uses a bipartite
graph coloring and was used for Hamiltonian simulation.
Each of the K′ terms corresponds to one color and is then
a sum of commuting rank-1 projectors. That is, the ﬁrst
k=1 hk and

term in the right hand side of Eq. (A10) is PK ′
¯ασ,σ′ |¯µσ,σ′ih¯µσ,σ′| ,

(A15)

hk = Xσ,σ′∈ck

H = Xσ,σ′∈U
+Xσ′∈U

¯ασ,σ′ |¯µσ,σ′ih¯µσ,σ′| +

 Xσ∈M

Pr(σ|σ′)!|σ′ihσ′| ,

where ck are those elements of E(G) associated with the
k-th color. By the deﬁnition of coloring, each rank-1
projector in Eq. (A15) is orthogonal and commutes with
each other, and then

(A10)

which is the desired decomposition as a linear combina-
tion of rank-1 projectors.

To build ˜H, we need to take square roots of the pro-
jectors. In principle, the dimension NU is large and we
want to avoid a presentation of ˜H as a sum of polyno-
mially many terms in NU . We are also interested in a

phk = Xσ,σ′∈ckp¯ασ,σ′ |¯µσ,σ′ih¯µσ,σ′| .

We can write

phk = −iZk + iZ†k

2

,

(A16)

(A17)

where Zk is the unitary

In summary, we found a decomposition of ˜H as

13

(A21)

Zk = exp

i Xσ,σ′∈ck

δσ,σ′ |¯µσ,σ′ih¯µσ,σ′|
 .

The coeﬃcients are chosen so that

sin(δσ,σ′ ) =p¯ασ,σ′ ,

and 0 ≤ ¯ασ,σ′ ≤ 1.

We can simulate each Zk as follows. Note that

(A18)

(A19)

Zk |σi = ξσ,σ′ |σi + ξ′σ,σ′ |σ′i

(A20)

where σ′ is such that (σ, σ′) ∈ ck. The complex coef-
ﬁcients ξσ,σ′ and ξ′σ,σ′ can be simply obtained from the
δσ,σ′ , and depend only on Pr(σ|σ′) and Pr(σ′|σ). Then,
on input |σi, we ﬁrst use QU to decide whether |σi ∈ U
or not. We then apply QP once and look for σ′ such
that (σ, σ′) ∈ ck. We use an additional register to write
a classical description of a quantum circuit that imple-
ments the transformation in Eq. (A20). We apply the in-
verse of QP and QU and only keep the last register. This
is suﬃcient information to apply the map in Eq. (A20).
We can then erase all the additional registers by applying
the inverse of the operation that computed the quantum
circuit. This works because the quantum circuit is invari-
ant under the permutation of σ and σ′. To implement Zk
we need to use QU and QP , O(1) times. The additional
gate complexity is O(d log(N )) for searching for σ′ and
describing the quantum circuit.

˜H =

1
2

˜K

Xk=1

˜Uk

where ˜Uk are unitaries. The number of terms is ˜K =
O(d2). Using Eq. (9) and the results above, each ˜Uk can
be implemented with O(1) uses of QU and QP , and at
most O(d log(N )) additional gates.

Using the results of [24] (see Sec. II), the complexity
for simulating exp(−i ˜Ht) within precision ǫ for this case
is as follows. The number of uses of QU and QP is

O (τ log(τ /ǫ)/ log log(τ /ǫ)) ,

(A22)

where τ = |t|d2. The additional gate complexity is

O (d log(N )τ log(τ /ǫ)/ log log(τ /ǫ)) .

(A23)

If we write CU and CP for the gate complexities of QU
and QP , respectively, the overall gate complexity to sim-
ulate the evolution under ˜H is

CW (t, ǫ) = O(cid:18)(d log(N ) + CU + CP )τ

log(τ /ǫ)

log log(τ /ǫ)(cid:19) .

(A24)

