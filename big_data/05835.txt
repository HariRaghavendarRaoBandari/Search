6
1
0
2

 
r
a

 

M
8
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
5
3
8
5
0

.

3
0
6
1
:
v
i
X
r
a

A Flexible Primal-Dual ToolBox

Technical Report

Hendrik Dirks∗

March 21, 2016

Abstract

FlexBox is a ﬂexible MATLAB toolbox for ﬁnite dimensional con-
vex variational problems in image processing and beyond. Such prob-
lems often consist of non-diﬀerentiable parts and involve linear operators.
The toolbox uses a primal-dual scheme to avoid (computationally) inef-
ﬁcient operator inversion and to get reliable error estimates. From the
user-side, FlexBox expects the primal formulation of the problem, auto-
matically decouples operators and dualizes the problem. For large-scale
problems, FlexBox also comes with a C++-module, which can be used
stand-alone or together with MATLAB via MEX-interfaces. Besides vari-
ous pre-implemented data-ﬁdelities and regularization-terms, FlexBox is
able to handle arbitrary operators while being easily extendable, due to
its object-oriented design.
The toolbox is available at http://www.ﬂexbox.im
Keywords: Convex optimization, primal-dual methods, image process-
ing, variational methods, MATLAB toolbox

1 Introduction

Many variational problems in image processing can be written in the form

arg min

G(x) + F (Ax),

x

(1)

where A denotes some linear operator (see A) and both G and F are proper,
convex and lower-semicontinuous functions. Problem (1) refers to the so-called
primal formulation of the minimization problem and x is known as the primal
variable. It can be shown (see [11]) that minimizing (1) is equivalent to solving
the primal-dual or saddle-point formulation

arg min

arg max

G(x) + hy, Axi − F ∗(y).

(2)

x

y

1Institute for Computational and Applied Mathematics and Cells in Motion Cluster
of Excellence, University of M¨unster, Orl´eans-Ring 10, 48149 M¨unster, Germany, Email:
hendrik.dirks@wwu.de

1

Here, F ∗ refers to the convex conjugate (see A) of F and y is denoted as the
dual variable. It the recent years, algorithms like ADMM [8, 14] or primal-dual
[10, 3, 17, 5] for eﬃciently solving these saddle-point problems have become very
popular. FlexBox makes use of the latter, which can be sketched up as follows:
For τ, σ > 0 and a pair (ˆx0, y0) ∈ X × Y we iteratively solve:

yk+1 = proxσF ∗ (yk + σAˆxk)
xk+1 = proxτ G(xk − τ AT yk+1)
ˆxk+1 = 2xk+1 − xk

(3)

(4)

(5)

Here, proxτ G (resp. σF ∗) denotes the proximal or resolvent operator

proxτ G(y) = (I + τ ∂G)−1 (y) := arg min

v ( kv − yk2

2

2

+ τ G(v)) ,

which can be interpreted as a compromise between minimizing G and being
close to the input argument y. The eﬃciency of primal-dual algorithms relies
on the fact that the prox-problems are computationally eﬃcient to solve.

1.1 Contribution

Since primal-dual algorithms have been extensively applied to all classes of con-
vex optimization problems, we found that people are spending a lot of eﬀort
on calculating convex conjugates or solutions for prox-problems repeatingly for
similar problems. Let us consider, for example, the isotropic total variation
k∇uk1,2, where the convex conjugate is an indicator function of the L∞-ball
and the solution of the prox-problem is a point-wise projection onto L2-balls.
These results hold not only for A = ∇, but for arbitrary operators. FlexBox
makes use of this generalization and simply works on the level of terms in the
primal problem. After adding a certain term, FlexBox automatically decou-
ples operators, creates dual variables and calculates step-sizes (τ, σ). FlexBox
already contains a variety of data-ﬁdelity (e.g. L1, L2, Kullback-Leibler) and
regularization terms (e.g. L2, TV, Laplace, curl), but is also compatible with
user-deﬁned operators. Moreover, the class-based structure allows easy exten-
sion and creation of custom terms. A full list of available terms can be found
in Table 4.2.
Core components of FlexBox are written in MATLAB, but there exists an op-
tional C++-module to improve compatibility and runtime. This module can be
compiled and will afterwards be used automatically via a MEX-interface. The
C++-module can also be used without MATLAB (but e.g. with OpenCV [1, 2]),
but does not have the full functionality and whole variety of terms included.

2 Architecture and Features

Basic Idea: To work with FlexBox, the user has to derive the primal formu-
lation of the variational problem ﬁrst. Afterwards, each primal variable includ-

2

ing its dimensions is added to FlexBox. Then, the primal problem is put into
the toolbox term by term, using the implemented functional terms from Table
4.2. Once the computation is ﬁnished, the result stored in the primal variables
can be requested and used.

Design: FlexBox is designed as one core class, which holds a list of functional
terms. For each term the toolbox decides whether it has to be dualized and
creates necessary dual variables. The main object holds the data of primal and
dual variables xi and yi and all parameters. Terms always correspond to at
least one primal variable, whereas dual terms also correspond to at least one
dual variable and contain the involved operators.
In the primal-dual algorithm (5), applications of the operator can be decoupled
deﬁning

˜y := yk + σAˆxk, and ˜x := xk − τ AT yk+1.

Since dual terms bind the operators, calculations of ˜y and ˜x are done inside the
corresponding dual terms, accessing the variables held by the core class. Finally,
primal and dual terms specify prox-methods to solve the arising prox-problems
while again accessing the variables held by the FlexBox core class.

Parameters: To ensure convergence, the parameters τ and σ have to fulﬁll
τ σkAk < 1. A static choice of these parameters might lead to slow convergence
speed, because it is dominated by the smallest possible value along all operators.
A fully automatic strategy for ﬁnding optimal parameters can be extrapolated
from [9]. Summing up the absolute values of row elements (for σi) resp. column
elements (for τi) leads to custom parameters for each term in the functional.
This strategy is inherited by FlexBox.

Stopping Criterion: As a powerful stopping criterion FlexBox uses the
primal-dual residual, proposed by Goldstein, Esser and Baraniuk [6], which can
be calculated after the (k+1)-th iteration as

xk − xk+1

τ

pk :=(cid:12)(cid:12)(cid:12)(cid:12)

− AT (yk − yk+1)(cid:12)(cid:12)(cid:12)(cid:12)

,

dk :=(cid:12)(cid:12)(cid:12)(cid:12)

yk − yk+1

σ

− A(xk − xk+1)(cid:12)(cid:12)(cid:12)(cid:12)

,

with |·| being the sum of absolute values. We denote pk as the primal and dk
as the dual residual. The total residual is then given by the sum of primal-
and dual residual, which is afterwards scaled with the size of the problem and
number of variables. Since evaluating the residual is computationally expensive,
it is regularly computed after a ﬁxed number of iterations (default 100).
Besides evaluating the primal-dual residual, FlexBox automatically stops after
a static number of iterations (default 10000) and can be continued afterwards.

3

3 Examples

3.1 Rudin-Osher-Fatemi

The Rudin-Osher-Fatemi model [12] has very popular applications in image
denoising. The primal formulation reads

arg min

u

1
2

ku − f k2

2 + αk∇uk1,2,

(6)

where the ﬁrst part ﬁts the unknown u to the given input image f and the
second part refers to the isotropic total variation, which penalizes the total sum
of jumps in the solution. Minimizing this problem with FlexBox can be done
with the following lines of code:

1 %Begin: Code example
2 main = flexbox;

3
4 numberU = main.addPrimalVar(size(f));

5
6 main.addTerm(L2dataTerm(1,imageNoisy),numberU);
7 main.addTerm(L1gradientIso(0.08,size(f)),numberU);

8
9 main.runAlgorithm;

10
11 result = main.getPrimal(numberU);
12 %End: Code example

To keep this example short, we omitted parts of the code where the image f is
read. Let us begin in line 2, which initializes a FlexBox object and saves it to
the variable main. Line 4 then adds the primal objective variable u, which has
the same size as the input image f . The toolbox returns the internal number
of this primal variable, which is saved in numberU .
In line 6 and 7, the L2-data-term with weight 1 (the weight is divided by 2
internally for L2 terms) and corresponding image f is added. Moreover, the
isotropic TV-term with weight 0.08 is pushed into the framework. Note that
the function addT erm always requires a functional part and the internal number
of the corresponding primal variable(s).
The function call in line 9 ﬁnally starts the calculation. Once this is ﬁnished we
transfer the solution into the variable result in line 11.

3.2 Optical Flow

Estimating the motion between two consecutive images f1 and f2 based on the
displacement of intensities in both images is called optical-ﬂow estimation. The
unknown velocity ﬁeld v is usually connected to the image by the brightness-
constancy-assumption f2(x + v) − f1(x) = 0. This formulation is non-linear in
terms of v and therefore linearized (see e.g. [16, 4]). A corresponding variational

4

problem incorporating total variation regularization can be written as

arg min
v=(v1,v2)

1
2

kf2 − f1 + ∇f2 · vk1 + α1k∇v1k1,2 + α2k∇v2k1,2.

(7)

Solving this problem with FlexBox can be done in a similar manner as for the
ROF example:

1 %Begin: Code example
2 main = flexbox;

3
4 numberV1 = main.addPrimalVar(size(f1));
5 numberV2 = main.addPrimalVar(size(f2));

6
7 %add optical flow data term
8 main.addTerm(L1opticalFlowTerm(1,f1,f2),[numberV1,numberV2]);

9
10 %add regularizers - one for each component
11 main.addTerm(L1gradientIso(0.05,size(f1)),numberV1);
12 main.addTerm(L1gradientIso(0.05,size(f1)),numberV2);

13
14 main.runAlgorithm;

15
16 resultV1 = main.getPrimal(numberV1);
17 resultV2 = main.getPrimal(numberV2);
18 %End: Code example

In lines 4 and 5 primal variables for both components of the velocity ﬁelds are
added. Afterwards, in lines 8, 11 and 12 the data term and regularizers for both
components are inserted. Please note that the optical ﬂow term now refers to
two primal variables written as the vector [numberV 1, numberV 2]. Afterwards,
the algorithm is started and both results are retrieved.

3.3 Segmentation

Dividing an image into diﬀerent regions is called segmentation. Assuming that
the image f consists of k diﬀerent regions, each of them having a mean in-
tensity ci for i = 1, . . . , k, the segmentation problem including total variation
regularization can be written as

arg min
u=u1,...,uk

ui

1
2

k

Xi=1

kf − cik2

2 + αk∇uik1,2,

s.t. ui ≥ 0,

ui = 1,

k

Xi=1

(8)

(9)

where u is a labeling vector (see [7, 15]). This labeling formulation is a convex
relaxation of the integer assignment ui ∈ {0, 1}. The MATLAB implementation
of this problem is again rather short:

1 %Begin: Code example
2 numberOfLabels = 3;

5

3 dims = size(image);
4 labels = rand(numberOfLabels,1);

5
6 main = flexbox;

7
8 for i=1:numberOfLabels

main.addPrimalVar(size(image));

9
10 end

11
12 %init data term
13 main.addTerm(labelingTerm(1,image,labels),1:numberOfLabels);

14
15 for i=1:numberOfLabels

main.addTerm(L1gradientIso(0.5,size(image)),i);

16
17 end

18
19 main.runAlgorithm;

20
21 for i=1:numberOfLabels

labelMatrix(:,:,i) = main.getPrimal(i);

22
23 end
24 %End: Code example

We begin by choosing a ﬁxed number of regions and choose the mean intensity in
each region as random values in line 4. Afterwards, the main object is initialized
and a primal variable for each ui is created in lines 8-10. In line 13, we create
the labeling term using the previously deﬁned labels and draw a connection
for primal variables 1:numberOfLabels. The loop in line 13-15 generates a total
variation regularizer for each of the primal variables. The problem is solved in
line 19 and we save each labeling function as a layer in a 3d matrix.

4 Features

4.1 General

• FlexBox can be stopped at any time and afterwards continued from the
current state. Due to this feature, we are able to change parameters after
the problem has converged and use the current state as an initial guess
for the next run.

• The toolbox supports arbitrary user-deﬁned operators consisting of blocks
Ai (see General operator regularization in Table 4.2 ) that can be sub-
mitted by deﬁning A as a cell-array of blocks, where each numPrimals
element correspond to one row in the overall operator. An example for a
user-deﬁned operator is provided with the software package.

6

4.2 Available Terms

Term

C++

αku − f k1

αkAu − f k1

α
2

ku − f k2
2

α
2

kAu − f k2
2

R Au − f + f log

s.t. u ≥ 0

f

Au

αk∇f2 · v + f2 − f1 k1

α
2

k∇f2 · v + f2 − f1 k2
2

Pn

i=1 hui , fi i

s.t. ui ≥ 0, P ui = 1
s.t. fi = (f − li)2

αk∇uk1,1

αk∇uk1,2

α
2

k∇uk2
2

αk∇ukHǫ

αk∇ukF

αk∇(u − w)k1,1

αk∇(u − w)k1,2

αk∇u − wk1,1

αk∇u − wk1,2

αkAuk1,1

αkAuk1,2

α
2

kAuk2
2

αkAukF

αhb, Aui

αkcurl(v)k1

α
2

kcurl(v)k2
2

αk∇ · vk1

α
2

k∇ · vk2
2

αkuk1

α
2

kuk2
2

αhb, ∇ui

αhb, ∇(u − w)i

X

X

X

X

X

X

X

×

X

X

X

×

X

X

X

X

X

X

X

X

X

×

X

X

X

X

X

X

×

×

List of implemented terms

Classname

Data-ﬁdelity
L1dataTerm(alpha,f)

L1dataTermOperator(alpha,A,f)

L2dataTerm(alpha,f)

L2dataTermOperator(alpha,A,f)

KLdataTermOperator(alpha,A,f)

L1opticalFlowTerm(alpha,f1 ,f2 )

L2opticalFlowTerm(alpha,f1 ,f2 )

labelingTerm(alpha,f,l)

Gradient regularization

L1gradientAniso(alpha,dims)

L1gradientIso(alpha,dims)

L2gradient(alpha,dims)

huberGradient(alpha,dims,epsi)

frobeniusGradient(alpha,dims)

L1gradientDiffAniso(alpha,dims)

L1gradientDiffIso(alpha,dims)

L1secondOrderGradientAniso(alpha,dims)

L1secondOrderGradientIso(alpha,dims)

General operator regularization

L1operatorAniso(alpha,numPrimals,A)

L1operatorIso(alpha,numPrimals,A)

L2operator(alpha,numPrimals,A)

frobeniusOperator(alpha,numPrimals,A)

innerProductOperator(alpha,A,b)

Vector-ﬁeld regularization

L1curl(alpha,dims)

L2curl(alpha,dims)

L1divergence(alpha,dims)

L2divergence(alpha,dims)

Other regularization

L1identity(alpha,dims)

L2identity(alpha,dims)

innerProductGradient(alpha,dims,b)

innerProductGradientDiff(alpha,dims,b)

Parameters

input data
weight
input data
weight
operator
input data
weight
input data
weight
operator

input data
weight
operator
images
weight
images
weight
image
weight
label vector
dimensions of u

weight
dimensions of u
weight
dimensions of u
weight
dimensions of u
weight
dimensions of u
ǫ for Huber-norm
weight
dimensions of u
weight
dimensions of u
weight
dimensions of u
weight
dimensions of u
weight
dimensions of u

f:
α:
f:
α:
A:
f:
α:
f:
α:
A:

f:
α:
A:
f1,f2 :
α:
f1,f2 :
α:
f:
α:
l:
dims:

α:
dims:
α:
dims:
α:
dims:
α:
dims:
epsi:
α:
dims:
α:
dims:
α:
dims:
α:
dims:
α:
dims:

α:
numPrimals:
A:
α:
numPrimals:
A:
α:
numPrimals:
A:
α:
numPrimals:
A:
α:
A:
b:

weight
# corresp. primals
operator(s)
weight
# corresp. primals
operator(s)
weight
# corresp. primals
operator(s)
weight
# corresp. primals
operator(s)
weight
operator
vector b

α:
dims:
α:
dims:
α:
dims:
α:
dims:

α:
dims:
α:
dims:
α:
dims:
b:
α:
dims:
b:

weight
dimensions of e.g. v1
weight
dimensions of e.g. v1
weight
dimensions of e.g. v1
weight
dimensions of e.g. v1

weight
dimensions of u
weight
dimensions of u
weight
dimensions of u
vector b
weight
dimensions of u
vector b

Table 1: List of terms currently available in FlexBox (incomplete).

7

A General Considerations

• Throughout this report, we consider ﬁnite dimensional optimization prob-

lems with primal variables x ∈ X and y ∈ Y.

• The sets X ⊂ RN and Y ⊂ RM are assumed to be convex.

• We do not explicitly distinguish between a variable xc on a regular carte-
sian grid N1 × . . .× Nd (s.t. N1 · . . . · Nd = N ) and its vectorized equivalent
x ∈ RN , which is gained by concatenating x along the ﬁrst dimension.

• The scalar product of two vectors on X is deﬁned as

hu, vi =Xi

uivi,

u, v ∈ X .

• FlexBox expects the matrix representation of the linear operator A, hence
A ∈ RM ×N and A∗ = AT . Note that the evaluation of a linear operator
can always be written as a matrix-vector multiplication by applying the
Kronecker product (see e.g. [13]).

• The function F ∗ refers to the convex conjugate or Legendre-Fenchel trans-

formation of F and is deﬁned as

F ∗(y∗) := sup
y∈Y

hy∗, yi − F (y).

Acknowledgements

• Thanks to Eva-Maria Brinkmann, Janic F¨ocke, Lena Frerking, Julian
Rasch and Carolin Roßmanith for testing FlexBox and discussing useful
features.

• FlexBox makes use of the primal-dual algorithm working on concrete
functional terms. A MATLAB toolbox consisting of a more general class of
solvers for optimization problems is OOMFIP, developed by Martin Benning.
Thank you for your advices!

8

References

[1] Gary Bradski et al. The opencv library. Doctor Dobbs Journal, 25(11):120–

126, 2000.

[2] Gary Bradski and Adrian Kaehler. Learning OpenCV: Computer vision

with the OpenCV library. ” O’Reilly Media, Inc.”, 2008.

[3] Antonin Chambolle and Thomas Pock. A ﬁrst-order primal-dual algorithm
for convex problems with applications to imaging. Journal of Mathematical
Imaging and Vision, 40(1):120–145, 2011.

[4] Hendrik Dirks. Variational Methods for Joint Motion Estimation and Im-

age Reconstruction. PhD thesis, WWU M¨unster, 2015.

[5] Ernie Esser, Xiaoqun Zhang, and Tony F Chan. A general framework
for a class of ﬁrst order primal-dual algorithms for convex optimization in
imaging science. SIAM Journal on Imaging Sciences, 3(4):1015–1046, 2010.

[6] Tom Goldstein, Min Li, Xiaoming Yuan, Ernie Esser, and Richard Bara-
niuk. Adaptive primal-dual hybrid gradient methods for saddle-point prob-
lems. arXiv preprint arXiv:1305.0546, 2013.

[7] David Mumford and Jayant Shah. Optimal approximations by piecewise
smooth functions and associated variational problems. Communications on
pure and applied mathematics, 42(5):577–685, 1989.

[8] Neal Parikh and Stephen P Boyd. Proximal algorithms. Foundations and

Trends in optimization, 1(3):127–239, 2014.

[9] Thomas Pock and Antonin Chambolle. Diagonal preconditioning for ﬁrst
order primal-dual algorithms in convex optimization. In Computer Vision
(ICCV), 2011 IEEE International Conference on, pages 1762–1769. IEEE,
2011.

[10] Thomas Pock, Daniel Cremers, Horst Bischof, and Antonin Chambolle.
An algorithm for minimizing the mumford-shah functional. In Computer
Vision, 2009 IEEE 12th International Conference on, pages 1133–1140.
IEEE, 2009.

[11] Ralph Tyrell Rockafellar. Convex analysis. Princeton university press,

2015.

[12] Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total vari-
ation based noise removal algorithms. Physica D: Nonlinear Phenomena,
60(1):259–268, 1992.

[13] Willi-Hans Steeb. Kronecker product of matrices and applications. BI-

Wissenschaftsvlg, 1991.

9

[14] Bo Wahlberg, Stephen Boyd, Mariette Annergren, and Yang Wang. An
admm algorithm for a class of total variation regularized estimation prob-
lems. arXiv preprint arXiv:1203.1828, 2012.

[15] Christopher Zach, David Gallup, Jan-Michael Frahm, and Marc Nietham-
mer. Fast global labeling for real-time stereo using multiple plane sweeps.
In VMV, pages 243–252, 2008.

[16] Christopher Zach, Thomas Pock, and Horst Bischof. A duality based ap-
proach for realtime tv-l 1 optical ﬂow. In Pattern Recognition, pages 214–
223. Springer, 2007.

[17] Xiaoqun Zhang, Martin Burger, and Stanley Osher. A uniﬁed primal-dual
algorithm framework based on bregman iteration. Journal of Scientiﬁc
Computing, 46(1):20–46, 2011.

10

