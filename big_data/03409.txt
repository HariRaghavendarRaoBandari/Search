Security, Privacy, and Access Control in
Information-Centric Networking: A Survey

Reza Tourani, Travis Mick, Satyajayant Misra and Gaurav Panwar

Dept. of Computer Science
New Mexico State University

{rtourani, tmick, misra, gpanwar}@cs.nmsu.edu

6
1
0
2

 
r
a

 

M
0
1

 
 
]
I

N
.
s
c
[
 
 

1
v
9
0
4
3
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Information-Centric Networking (ICN) is a new net-
working paradigm, which replaces the widely used host-centric
networking paradigm in communication networks (e.g., Internet,
mobile ad hoc networks) with an information-centric paradigm,
which prioritizes the delivery of named content, oblivious of the
contents origin. Content and client security are more intrinsic in
the ICN paradigm versus the current host centric paradigm where
they have been instrumented as an after thought. By design, the
ICN paradigm inherently supports several security and privacy
features, such as provenance and identity privacy, which are still
not effectively available in the host-centric paradigm. However,
given its nascency, the ICN paradigm has several open security
and privacy concerns, some that existed in the old paradigm,
and some new and unique. In this article, we survey the existing
literature in security and privacy research sub-space in ICN. More
speciﬁcally, we explore three broad areas: security threats, privacy
risks, and access control enforcement mechanisms.

We present the underlying principle of the existing works,
discuss the drawbacks of the proposed approaches, and explore
potential future research directions. In the broad area of security,
we review attack scenarios, such as denial of service, cache
pollution, and content poisoning. In the broad area of privacy,
we discuss user privacy and anonymity, name and signature
privacy, and content privacy. ICN’s feature of ubiquitous caching
introduces a major challenge for access control enforcement that
requires special attention. In this broad area, we review existing
access control mechanisms including encryption-based, attribute-
based, session-based, and proxy re-encryption-based access control
schemes. We conclude the survey with lessons learned and scope
for future work.

Keywords–Information-centric networking, security, privacy, ac-

cess control, architecture, DoS, content poisoning.

1. INTRODUCTION

According to the Cisco Visual Networking Index forecast,
video trafﬁc (including VoD, P2P, Internet, and TV) will com-
prise 90% of all Internet trafﬁc by 2019. The majority of this
trafﬁc is currently served to end users with the help of content
delivery networks (CDNs), with servers that reside close to
the network edge. This has helped reduce core network trafﬁc
and improve delivery latency. Despite the scalability that CDNs
have so far provided, the current host-centric paradigm will
not continue to scale with the proliferation of mobile devices
and the Internet of Things (IoTs) coupled with the rapidly
increasing volume of video trafﬁc. Not only have these trends
been putting pressure on Internet Service Providers (ISPs) and

This work has been submitted to IEEE Communications Surveys & Tutorials
journal and is supported in part by the U.S. NSF grants:1345232 and 1248109
and the U.S. DoD/ARO grant: W911NF-07-2-0027.

content providers, but they have also motivated the research
community to explore designs for a more scalable Internet,
with a primary objective of efﬁcient content delivery. One
of the products of this endeavor is the Information-Centric
Networking (ICN) paradigm.

ICN shifts the networking paradigm from the current host-
centric paradigm, where all requests for content are made to
a host identiﬁed by its IP address(es), to a content-centric
paradigm, which decouples named content objects from the
hosts where they are located. As a result, named content can
be stored anywhere in the network; each content object can be
uniquely addressed and requested. Several ICN architectures
have been proposed, such as Named-data networking/content-
centric networking (NDN/CCN), Publish-Subscribe Internet
Routing Paradigm (PSIRP), Data Oriented Network Architec-
ture (DONA), and Network of Information (NetInf). Though
they differ in their details,
they share several fundamental
properties: unique name for content, name-based routing, perva-
sive caching, and assurance of content integrity. ICN enhances
several facets of user experience as well as security, privacy,
and access control; however, it also gives rise to many new
security challenges. Various concepts and solutions have been
proposed to address these challenges in the literature.

In this article, we explore ICN security, privacy, and ac-
cess control concerns in-depth, and present a comprehensive
study of the proposed mechanisms in the state of the art.
We categorize this survey into three major domains, namely
security, privacy, and access control. In the security section,
we address attacks applicable to both IP-based networks and
ICNs, such as denial of service (DoS and distributed DoS
or DDoS) and vulnerabilities unique to ICN, including cache
pollution, content poisoning, and naming attacks. Despite many
similarities between a classical DoS attack and the DoS attack
in ICN, the latter is novel in that it abuses ICN’s stateful
routing plane;
the attack aims to overload a router’s state
tables, such as the pending interest table (PIT) and forwarding
information base (FIB). The cache pollution attack targets a
router’s content locality with the intention of altering its set
of cached content; this results in an increase in the frequency
of content retransmission, and consequently reduces network
goodput.

In the privacy section, we study the privacy risks in ICN
under four classes: client privacy, content privacy, cache pri-
vacy, and name and signature privacy [32]. We explore the

implications of each of these risk classes and elaborate on
relevant proposed solutions. Due to ICN’s support for pervasive
caching, content objects can be replicated throughout the net-
work. Though this moves content close to the edge and hence
reduces network load and content retrieval latency, it comes at
a cost—publishers lose control over these cached copies and
cannot arbitrate access. Thus, there is need for efﬁcient access
control, which allows reuse of cached content and also prevents
unauthorized accesses. Several mechanisms have been proposed
in which access control is achieved using content encryption,
clients’ identities, content attributes, or authorized sessions. We
review these proposed mechanisms and highlight their beneﬁts
and drawbacks in detail in the access control section. At the end
of each section, we present a summary of the state of the art and
also discuss open research challenges and potential directions
to explore. We conclude the survey with a summary of lessons
learned.

Before we dive into the discussion, we brieﬂy review some
representative ICN architectures in Subsection 1.A. Following
that we identify previous surveys in ICN covering different ICN
architectures, naming and routing, DoS attacks, mobility, and
potential research directions in Subsection 1.B.

A. Overview of the Proposed Information-Centric Networking
Architectures

Based on the nature of communication in the proposed ICN
architectures, we categorize them into two main models, as
shown in Fig. 1: consumer-driven and publish-subscribe. In
the consumer-driven architectures, communication is initiated
when a client requests a content from the network; in response,
the requested data is sent into into the network by a publisher.
The content routers locate and deliver the requested content
without the use of any request-to-content matching service.
CCN [67], [2] and NDN [7] are two popular consumer-driven
ICN architectures.

In contrast, in the publish-subscribe architectures a publisher
ﬁrst advertises its content to the network and interested sub-
scribers establish subscriptions to the content. The content is
then delivered from the publisher to the subscriber with the
help of a matching service provided by a name resolution
service [16], resolution handlers [73], or rendezvous nodes
[105], [8], [9]. DONA [73], PURSUIT [9], PSIRP [105],
[8], NetInf [16], and MobilityFirst [100], [6] fall into this
category. Although this is not an inclusive list of ICN ar-
chitectures, it is largely representative; thus, we will review
these architectures in what follows. We refer interested readers
to two surveys [17], [121] for more details on other ICN
architectures, such as SAIL [10], 4WARD [1], COMET [99],
[3], CONVERGENCE [4], and CONET [43].

The Data Oriented Network Architecture (DONA) [73] was
proposed by Koponen et al. at UC Berkeley in 2007. DONA
uses a ﬂat self-certifying naming scheme. Each name consists
of two parts; the ﬁrst is the cryptographic hash of the publisher’s
public key, and the second is an object identiﬁer, which is
assigned by the publisher and is unique in the publisher’s

domain. To achieve self-certiﬁcation, the authors suggested that
publishers use a cryptographic hash of the object as the object
identiﬁer. A subscriber can then easily verify the integrity of
an object simply by hashing it and comparing the result to
the object’s name. DONA’s resolution service is composed of
a hierarchically interconnected network of resolution handler
(RH) entities, which are tasked with publication and retrieval
of objects.

To publish an object, the owner sends a REGISTER message
including the object name to its local RH. The local RH, keeps
a pointer to the publisher and propagates this message to its
parent and peer RHs, who then store a mapping between the
local RH’s address and the object name. A subscriber interested
in the object sends a FIND message with the object name to
its own local RH. The local RH propagates this request to its
parent RH, and propagation continues until a match is found
somewhere in the hierarchy.

Content routers, equipped with a content store (CS), a
pending interest table (PIT), and a forwarding information base
(FIB), receive the interest and perform a CS lookup on the
content name. If the content is not available in the CS, the router
performs a PIT lookup to check whether there is an existing
entry for the requested content. If the PIT lookup is successful,
the content router adds the incoming interest’s interface to the
PIT entry (interest aggregation) and drops the interest. If no
PIT match is found, the router creates a new PIT entry for the
interest and forwards the interest using information from the
FIB.

An interest can be satisﬁed either by an intermediate forward-
ing router which has cached the corresponding content chunk,
or in the worst case, by the content provider. In both cases, the
content takes the interest’s reverse-path back to the requester.
Upon a router’s receipt of a content chunk, the PIT lookup

the request

After ﬁnding a match,

is forwarded towards
the identiﬁed publisher. The authors proposed two methods of
object delivery from publisher to requester. In the ﬁrst method,
the publisher sends the object using the underlying IP network.
The second method takes advantage of path symmetry: the
request message records the path it takes through the network.
After reaching the publisher, the object traverses the reverse
path from the publisher to the requester. Exploiting this routing
model, RHs on the path can aggregate the request messages for
an object and form a multicast tree for more efﬁcient object
dissemination/delivery.

Content-centric Networking (CCN) [67], [2] was proposed
by researchers at Palo Alto Research Center in 2009. In 2010,
Named Data Networking (NDN) [7], which follows the same
design principles, was selected by the US National Science
Foundation (NSF) as one of four projects to be funded under
NSF’s Future Internet Architecture program. Both CCN and
NDN share the same fundamentals, such as a hierarchical
naming scheme, content caching, and named content routing.
The hierarchical naming allows the provider’s domain name
to be used in making routing decisions. In the client-driven
CCN/NDN, a client sends an interest packet into the network
to request a content by its name.

ICN Architectures

Consumer-Driven

Publish-Subscribe

CCN

NDN

DONA

PSIRP/PURSUIT

NetInf

MobilityFirst

Fig. 1: Categorization of Information-Centric Networking architectures.

identiﬁes the interfaces over which it should be forwarded. The
content router may cache a copy of the content in its CS in
addition to forwarding it through the designated faces.

The Publish Subscribe Internet Technology (PURSUIT) [9]
project and its predecessor Publish Subscribe Internet Routing
Paradigm (PSIRP) [105], [8], were funded by FP7 (European
Union’s research and innovation program) to produce a publish-
subscribe protocol stack. A PURSUIT network is composed
of three core entities, namely Rendezvous Nodes (RNs) which
form the REndezvous NEtwork (RENE), the topology manager,
and forwarders. Similar to DONA, PURSUIT uses a ﬂat naming
scheme composed of a scope ID, which groups related infor-
mation objects, and a rendezvous ID, which ensures that each
object’s identiﬁer is unique in its group. A publisher advertises
its content by sending a PUBLISH message to its local RN,
which routes the message to the RN designated to store the
content deﬁned by the scope. The local RN makes this decision
using a distributed hash table (DHT). A subscriber interested
in the content object sends a SUBSCRIBE message to its local
RN, which will also be routed to the designated RN using the
DHT.

The routing forwarders, after obtaining the data, deliver it

Upon receipt of a SUBSCRIBE message by the designated
RN, the topology manager is instructed to generate a delivery
path between the publisher and the subscriber. The topology
manager then provides the publisher with a path through the
forwarders. In PURSUIT, network links are each assigned a
unique string identiﬁer, which the topology manager uses to
create a routing Bloom ﬁlter for each ﬂow. The generated
Bloom ﬁlter is then added to each packet’s header, and is used
by the intermediate forwarders for content delivery.

Network of Information (NetInf) [16] was initially conceived
in the FP7 project 4WARD [1]. NetInf employs a ﬂat naming
scheme with a binding between names and their locators, which
point to the content’s location. As several nodes can cache
copies of the data, an object may be bound to more than one
locator. Two models of content retrieval are offered by NetInf:
name resolution and name-based routing. In the name resolution
approach, a publisher publishes its data objects to the network
by registering its name/locator binding with the name resolution
service (NRS). An interested client resolves the named data
object into a set of locators and subsequently submits a request
for the object, which will be delivered by the routing forwarders
to the best available cache.

back to the requester. In the name-based routing model, a client
directly sends out a GET message with the name of the data
object. This message is forwarded to an available storage node
using name-based routing, and the data object, once found, is
forwarded back to the client.

MobilityFirst [100], [6] was funded by the NSF’s future
Internet Architecture program in 2010. The main focus of this
architecture is to scale in the face of device mobility, hence
it includes detailed mechanisms for handling mobility, wire-
less links, multicast, multi-homing, security, and in-network
caching. Each network entity, including devices, information
objects, and services, is assigned a globally unique identiﬁer
(GUID), which can be translated into one or more network
addresses. To advertise a content, a publisher requests a GUID
from the naming service and registers this name with a global
name resolution service (GNRS).

The registered GUID is mapped, by a hash function, to a
set of GNRS servers, which are connected through regular
routing. A subscriber can then obtain the content name from
a Name Certiﬁcation Service (NCS) or use a search engine
to resolve a human-readable name into the corresponding
GUID. A subscriber submits a GET message, containing both
the GUID of the desired object and its own GUID, to its
local content router. Since content routers require the network
address, the request will be forwarded to the GNRS to map the
GUID into actual addresses. The result of this query is a set of
partial or complete routes, or a set of addresses.

Upon receiving this information,

the requesting content
router attaches the destination network address to the GET
message and forwards it into the network. Any content router
on the forwarding path may contact the GNRS for an updated
destination address or route, which may have changed due
to the provider’s mobility. The publisher, upon receiving the
GET message, sends the requested object back to the source
GUID following the same procedure. MobilityFirst provides a
combination of IP routing and name-based routing by name
resolution and data routing processes. On-path caching is
employed to satisfy subsequent requests for previously served
GUIDs. This is in contrast to off-path caching, which causes
an update in the GNRS service, where the new caching node’s
network address is added to the GUID’s record.

Survey Organization

Security

Privacy

Access Control

Denial of Service

Timing Attack

Encryption-Based

Content Poisoning

Monitoring Attack

Cache Pollution

Anonymity

Attribute-Based

Session-Based

Secure Naming & Routing

Protocol Attack

Proxy Re-encryption

Application Security

Name & Signature

Miscellaneous

Generic Contributions

Fig. 2: The organization of the survey.

B. Review of Existing ICN Surveys

[17]

Ahlgren et al.

reviewed the different proposed
information-centric architectures. In addition to describing the
architectures in detail, the authors also presented their open
challenges. Following this survey, Xylomenos et al. [121]
surveyed the proposed ICN architectures, comparing their
similarities and differences and discussing their weaknesses.
Tyson et al. focused on mobility in information-centric net-
works in [107]. Several beneﬁts of node mobility were dis-
cussed by the authors, as well as mobility-related challenges
such as provider mobility and cached content discovery.

Zhang, Li and Lin [125] and Zhang et al. [126] explored
proposed caching approaches in information-centric network-
ing. In [27], Bari et al. reviewed the state-of-the-art in naming
and routing for information-centric networks and explored the
requirements for ideal content naming and routing. Future
research directions in information-centric networking were dis-
cussed by Pan et al. [92]. Aamir and Zaidi [11] surveyed denial-
of-service attacks in information-centric networks and identiﬁed
interest ﬂooding, request piling, content poisoning, signature
key retrieval, and cache pollution as DDoS vectors.

AbdAllah et al. [12] recently discussed security attacks in
ICN. The authors classiﬁed attacks into four categories: routing,
naming, caching, and miscellaneous. The paper focused on
discussing the ways an attacker can orchestrate these attacks
as well as the applicability of current IP-based solutions to
information-centric networks.

Novel Contributions of this Survey: All the existing sur-
veys have either not dealt with security, privacy, and access
control or have looked at them to a very limited extent. The
work of AbdAllah et al. [12] is the ﬁrst survey dealing with
security in ICNs, but it is not comprehensive. For instance,
access control in ICNs has not be considered in any survey

to present a comprehensive survey of

and access control is important. To the best of our knowledge,
we are the ﬁrst
the
state-of-the-art in security, privacy, and access control in the
context of ICN. In this survey, we present each of these three
aspects independently, surveying the state of the art, lessons
learned, and the shortcomings of proposed approaches. We also
discuss existing challenges and propose potential directions and
solutions to explore. We believe that a comprehensive review of
the state-of-the-art in ICN security, privacy, and access control
is essential for a reader/researcher to gain deeper understanding
of the open challenges and existing solutions in this domain,
which is quickly becoming popular.

The rest of the paper is organized as it is depicted in the
Fig. 2. In Section 2, we review the security issues of different
ICN architectures, their proposed solutions, and existing open
problems. Different privacy issues, proposed solutions, and
open challenges are presented in Section 3. Access control
enforcement mechanisms, their drawbacks, and existing open
challenges are presented in Section 4.
In Section 5, we
summarize the existing ICN security research and present a
comprehensive discussion of future research directions in ICN
security.

2. SECURITY IN ICN

In this section, we review vulnerabilities in ICN and discuss
the state-of-the-art solutions, then conclude this section with
open problems and potential solutions to be explored. This
section is divided into subsections based upon the particular
types of attacks. First, we discuss the proposed countermeasures
against DoS attacks. Content poisoning and cache pollution
attacks and their countermeasures are discussed in the subse-
quent subsections. Then, we discuss attacks inherent to content
naming and describe proposed mechanisms for secure nam-
ing. We will also explore proposed application-level security

mechanisms. We conclude this section with an overview of
general contributions to ICN security,
including work that
cannot be grouped into any of the categories described above.
Fig. 3 illustrates the classiﬁcation of existing literature on ICN
security.

A. Denial of Service (DoS) Attack

DoS attacks in ICN may target either intermediate routers
or content providers. The most basic type of attack, interest
ﬂooding, involves an attacker sending interests for a variety of
content objects that are not likely to be present in the targeted
routers’ caches. This is mainly a concern in consumer-driven
architectures such as CCN and NDN, where the storage of a
PIT entry for each received interest may result in the exhaustion
of the router’s PIT table memory and prevent it from serving
benign clients’ requests. This scenario is depicted in Fig. 4,
which shows clients and an attacker connected to an edge router
that is also a content router (can cache content). The network
is composed of a content provider at one end (on the right) and
the routing core consisting of routers without content cache and
the content routers with content cache. In this scenario, the edge
router, connected to the attacker as well as legitimate clients,
has its PIT ﬁlled up by the attacker’s interests. The interest
name /attack/C* refers to some undeﬁned content name that
may not exist, is inaccurate, or is a request for dynamic content
to be created on-the-ﬂy.

This attack is more severe when the attacker requests fake
content objects (i.e., names with a valid preﬁx with an invalid
sufﬁx) or dynamic objects, which need to be generated by the
provider. Requests for fake objects will result in the provider
dropping the interest, and subsequently the PIT entries on
the targeted router(s) (e.g., routers on the path) will remain
active until their expiration. On the other hand, dynamic con-
tent requests will be served by the provider. However, these
requests/replies burden the forwarding routers, and may also
cause DoS at the provider.

Fig. 4: Denial of Service (DoS) attack scenario.

Wang et al. [68] investigated the effect of content caching
on DoS attacks, focusing on CCN in particular. They compared
the DoS attacks that
target content providers in IP-based
and content-centric networks, and proposed a queuing theory
based model to model DoS attacks. This model considers the
caching period of content objects as well as queuing delay at
repositories. The authors concluded that DoS attacks in CCN

(also applies to NDN) have limited effectiveness in comparison
to DoS attacks on IP networks due to a reduced request arrival
rate at the content provider. Because intermediate routers can
satisfy interests, interest ﬂooding can be localized signiﬁcantly
by increasing the cache size at routers and the time period for
which content objects are cached.

Despite the correctness of the authors’ models, several un-
realistic assumptions weaken the relevance of the work. The
authors assumed that an attacker only requests content objects
that are available at the content provider(s) and may be cached.
However, this is not a realistic attack scenario; a real attacker
targeting a content provider would request either non-existent
content or dynamically-generated content (which may be un-
popular and hence useless when cached). Also, the analysis
provided does not account for cache replacement policies,
which would affect the content caching period. Furthermore,
intermediate routers would be more vulnerable targets to DoS
than content providers; however, the impact of DoS on routers
was not discussed.

Afanasayev et al. [14] proposed three approaches to coping
with interest ﬂooding attacks in named-data networking (NDN).
Their vanilla approach is a slight modiﬁcation of the well-
known Token Bucket algorithm, in which each router limits
the number of pending interests for each interface proportional
to its link capacity (bandwidth-delay product). This technique
is not very effective, as a router may utilize the entire link
capacity to satisfy an attacker’s interests, hence reducing the
satisfaction rate of legitimate clients’ interests.

The authors augmented this vanilla approach by introducing
a concept of per-interface fairness. In this mechanism, a router
ensures that the outgoing link capacity is shared fairly among
trafﬁc from all incoming interfaces, thus preventing trafﬁc from
a minority of incoming interfaces from consuming an entire
link’s capacity. For this purpose, the PIT is extended with a
new column to denote each interest’s as either forwarded or
in-queue. The router also maintains a queue for each incoming
interface. An interface with a high interest arrival rate is
subject to queuing in favor of service to other interfaces. This
improvement partially solves the problem, as an attacker on
one interface will be unable to consume all of the router’s
resources. However, even with this approach there is no dis-
tinction between an attacker and a legitimate client. Both the
attackers’ and the legitimate clients’ interests are rate-limited
if they are incident on a high-rate interface.

The last proposed algorithm differentiates interest timeout
events from interest satisfaction events. Each router keeps
statistics pertaining to the satisfaction history of its interfaces.
This allows incoming interfaces with higher satisfaction rates
to be given a greater share of the outgoing link capacity. The
drawback of this approach is that the probability of satisfaction
for an interest reduces dramatically as path length increases. A
longer path may be subject to more congestion and packet loss
at the routers and with more routers the probability of rate lim-
iting increases. To address this drawback, the authors suggested
that routers explicitly announce their interest satisfaction ratio
limits to their downstream neighbors, who can then adjust their

/Youtube.com/movie/NMSU.edu/NetworkPIT/attack/C122222/attack/C2/attack/C3/attack/C4/attack/C5/attack/C  *Edge  routerContent  routerContent  routerRouterRouterContent  providerClientClientAttackerSecurity

?

?

?

?

?

DoS/DDoS

[14] [38] [41]
[54] [68] [79]
[91] [109] [111]
[112] [113]

Content
Poisoning

[54] [57] [58]
[59] [72]

Cache Pollution

[39] [69] [86]
[93] [119]

Secure Naming
and Routing

Application
Security

[15] [19] [20]
[21] [22] [42]
[63] [95] [116]
[122] [127]

[23] [26] [30]
[31] [49] [60]
[61] [70] [98]
[108] [117] [123]

?

Other
General
Contribu-
tions

[50] [51] [55]
[81] [83] [110]

Fig. 3: ICN Security sub-categories and the state-of-the-art.

own acceptance thresholds accordingly. This algorithm, despite
being more effective, still applies penalties at the granularity
of interface, not ﬂow. Legitimate users’ ﬂows will still suffer.
Gasti et al. [54] also explored DDoS attack scenarios in
named-data networking, focusing primarily on interest ﬂooding.
The authors divided interest ﬂooding scenarios into classes
depending on whether the attackers request (1) existing or
static, (2) dynamically generated, or (3) non-existent content
objects. The attack target for Types (1) and (3) is the network-
core infrastructure, while the Type (2) attack targets both the
content providers and the network infrastructure. The authors
noted that malicious requests for existing or static content has
limited effect due to content caching at intermediate routers.

In contrast, requesting dynamically generated content not
only consumes intermediate routers’ resources (such as PIT
space and bandwidth), but also keeps the providers busy with
generation of content chunks corresponding to each incoming
interest. It was noted that non-existent content is the type most
likely to be used in attacks against infrastructure. The authors
suggested that routers keep track of the number of pending
interests per outgoing face, as well as the number of unsatisﬁed
interests per incoming face and/or per-name preﬁx. Hence,
rate limiting could be applied when these counters exceed a
predeﬁned threshold. The per-name preﬁx based rate limiting
is a better approach than per-interface rate limiting.

Compagno et al. [38] designed Poseidon, a collaborative
mechanism for interest ﬂooding mitigation. Poseidon involves
two phases: detection and reaction. Detection is performed
individually, with each router monitoring two values: ratio of
incoming interests to outgoing content, and the amount of PIT
state consumed by each interface. These statistics are collected
over a time window, such that old data does not affect detection
of future attacks. When a pre-set
threshold is reached the
router enters reaction mode, wherein collaborative mitigation
takes place. A router rate limits its interfaces with abnormal
interest arrival rates, then sends notiﬁcation to its downstream
routers about the attack. A downstream router receiving such
notiﬁcation can then detect the attack at an earlier stage.

The authors noted that rate-limiting was more effective at

reducing the attacked router’s PIT size than the notiﬁcation
mechanism, however notiﬁcation improved the satisfaction rate
of requests. Unfortunately, the authors did not evaluate the
impact of their mechanism on legitimate clients in detail;
particularly concerning is the potential effect on clients that
are co-located on the same interface as an attacker.

Dai et al. [41] proposed an IP-inspired approach for miti-
gating interest ﬂooding in NDN. The scheme is inspired by
IP-traceback which allows an attack to be “traced back” to the
attacker. The interest traceback procedure is triggered when the
size of the PIT at a router exceeds a predeﬁned threshold. At
this moment, the router generates a spoofed data packet for the
longest-unsatisﬁed interest in the PIT. The spoofed data will be
forwarded to the attacker, causing its edge router to be notiﬁed
of the malicious behavior; in response, the router can rate-limit
the attacker’s interface.

Similar to other rate-limiting approaches, this mechanism
may also have a negative impact on legitimate clients. This
scheme in particular can cause a legitimate client, who has
mistakenly requested a non-existent (or yet-to-be-created) con-
tent, to be unfairly penalized. Additionally, since rate limiting
only occurs at the edge router, this scheme may be ineffective
if an edge router is compromised or is non-cooperative with its
peers. Furthermore, the authors do not discuss the impact of
the router’s decisions on legitimate long-unsatisﬁed interests;
e.g., it is not mentioned whether all unsatisﬁed interests with
long wait times or only a subset of them may be treated as
malicious.

Virgilio et al. [109] analyzed the security of the existing PIT
architectures under DDoS attack. The authors compared three
proposed PIT architectures: (1) SimplePIT, which stores the
entire URL, (2) HashPIT, where only a hash of the URL is
stored, and (3) DiPIT (distributed PIT), where each interface
uses a Bloom ﬁlter to determine which content objects should
be forwarded. The authors concluded that all three proposed
PIT architectures are vulnerable to DDoS attack, and they
all perform the same under normal trafﬁc conditions. While
SimplePIT and HashPIT suffer from memory growth in the
face of DoS, DiPIT does not consume extra memory. DiPIT

will always use a ﬁxed amount of memory, as each face is
assigned a counting Bloom ﬁlter to identify which data should
be forwarded on that face. Unfortunately, the Bloom ﬁlter’s
inherent false positive rate has the potential to cause data to be
forwarded unnecessarily, and therefore waste bandwidth. Al-
though this paper showed the effects of DDoS on different PIT
architectures through simulation, the authors did not propose
any viable solution.

Wang et al. [112] proposed a mechanism which copes with
interest ﬂooding by decoupling malicious interests from the
PIT. The mechanism requires that each router monitor the num-
ber of expired interests for each name preﬁx, then add a preﬁx
to the malicious list (m-list) if this count exceeds a chosen
threshold. To prevent legitimate name preﬁxes from staying in
the m-list, each m-list entry is assigned an expiry time, after
which the preﬁx is removed from the m-list. However, an m-
list entry’s expiry timer is reset if a new interest arrives for the
same preﬁx.

Routers avoid storing PIT state for preﬁxes recorded in
the m-list by modifying an interest
in order to make the
corresponding content object self-routing. Before forwarding
the interest, the interface on which it arrived is appended as the
last component of the content name. When the response arrives,
it can then be routed without a PIT lookup. This procedure
can be applied by several routers on the path, in which case a
list of interfaces will be present at the end of the name. Each
downstream router removes its own interface (which would be
the last in the list) before forwarding the content object to the
next hop. Although this helps routers keep the sizes of their
PITs manageable, they will still be responsible for forwarding
the malicious interests; thus network congestion and starvation
of legitimate clients are still possible. This mechanism also
puts additional processing burden on the routers and increases
packet overhead.

To remedy the shortcomings of this mechanism, the au-
thors [113] later proposed an interest ﬂooding detection and
mitigation mechanism based on fuzzy logic and router coop-
eration. In the detection part, that core routers monitor their
PIT Occupancy Rate (POR) and PIT Expiration Rate (PER),
which represent the rate at which the PIT collects new entries
and the rate of PIT entry expiration, respectively. The real-
time values corresponding to these rates are collected and used
through fuzzy inference rules to identify if they are normal or
abnormal.

If either value is abnormal, it triggers the mitigation mech-
anism. The mitigation mechanism can be triggered by a router
itself or by another router. The targeted preﬁx is determined,
the router identiﬁes an interface on which the most interests for
that preﬁx have arrived; applies rate-limiting to that interface;
and notiﬁes its neighbor (on that same interface) of the targeted
preﬁx.

Simulation results show the effectiveness of this mechanism
in both reducing PIT memory consumption and increasing
interest satisfaction for legitimate clients. However, the authors
assumed that the attackers only target a speciﬁc name preﬁx;
thus the mitigation is effective in dismantling attacks against

speciﬁc publishers, but not those against the network infras-
tructure itself. Moreover, a distributed attack could reach the
network core over several paths; as this approach allows each
router to identify only one malicious interface, its effectiveness
against DDoS is unknown.

Wang et al. [111] modeled the interest ﬂooding attack in
NDN using a symmetric binary tree topology. The model
considers factors, such as routers’ PIT sizes, round trip times,
PIT entries’ TTLs, content popularity distribution, and both
malicious and legitimate interest rates. To analyze the impact of
a DoS attack, the authors derived a DoS probability distribution,
which evaluates the probability that a legitimate interest will
be dropped due to starvation. The authors modeled the events
of PIT entry insertion and removal with a continuous-time
homogeneous Markov chain, where the number of PIT entries
at any time is given by the states of the Markov process. A
simulation result conﬁrms the validity of the theoretical model.
The authors suggested that the effectiveness of DoS could be
reduced by using bigger PITs, bigger content stores, and shorter
TTLs for PIT entries. Unfortunately, these suggestions do not
actually address the problem: an attacker could easily increase
its request rate proportionally.

Li and Bi [79] proposed a countermeasure against DoS
attacks targeting dynamic content. As opposed to static content,
which is signed once when it is generated, dynamic content
is generated and signed upon interest arrival; a high rate
of requests can thus overload the content provider due to
the computational overhead of the signature generation. As a
mitigation, the authors proposed a proof-of-work mechanism,
which requires clients to perform some extra computational task
before requesting a dynamic content object.

Before requesting the content, the client requests a meta-
puzzle from the content provider. Upon receiving the meta-
puzzle, the client generates the actual puzzle and solves it
(similarly to how blocks are mined in Bitcoin). The puzzle
solution and the current timestamp form a part of the interest.
Upon receiving the interest,
the provider checks both the
validity and freshness of the solution. If the solution is valid
and fresh, the provider generates and signs the desired content;
otherwise, the interest is dropped.

The meta-puzzle is updated either after a predeﬁned lifetime
or after a large number of solutions are received. This proposal
does increase the barrier for DoS or DDoS attacks, but also
puts a computational burden on legitimate clients. But more
importantly, the authors stated that a DDoS attack with as few
as 300 attackers can signiﬁcantly degrade the effectiveness of
this scheme.

Nguyen et al. proposed an interest ﬂooding detector based on
statistical hypothesis testing theory [91]. The scheme is based
upon the fact that when under attack, the interest rate on an
interface is greater than that during normal conditions. Mean-
while, the data rate under both hypotheses remains the same;
therefore, the data hit-ratio in attack scenarios is lower than
that in normal conditions. Unlike other solutions, this scheme
takes the desired probability of false alarm as a parameter
and calculates the detection threshold accordingly. Hence, the

TABLE I: Summary of DoS/DDoS Mitigation Approaches

Mechanism
Afanasayev et al. [14]
Compagno et al. [38]
Dai et al. [41]
Gasti et al. [54]
Wang et al. [68]
Li et al. [79]
Nguyen et al. [91]
Wang et al. [112]
Wang et al. [113]

Target
Router
Router
Router
Provider
Router
Provider
Provider
Router
Router
Router

Content Type
Non-Existent
Non-Existent
Non-Existent

Dynamic

Existing
Dynamic

Non-Existent
Non-Existent
Non-Existent

Existing & Non-Existent

Mitigation Approach

Rate Limiting & Per-face Fairness

Per-face Statistic & Priority

Rate Limiting & Per-face Statistics

Rate Limiting & PIT Size Monitoring

Rate Limiting & Per-face Statistics

Caching Period Increase

Client’s Proof-of-Work per Interest
Statistical Hypotheses Testing Theory
Decoupling Malicious Interest from PIT

Fuzzy Logic-based Detection

Router’s Functionality

PIT Extension
Storing Statistics
Storing Statistics
Not Applicable
Storing Statistics
Not Applicable
Not Applicable
Storing Statistics
Additional Queue
Storing Statistics

Scope

Individual Routers
Router Collaboration
Router Collaboration
Router Collaboration
Individual Routers
Individual Routers

Not Applicable

Individual Routers
Individual Routers
Router Collaboration

threshold only depends on the chosen false positive rate and
the inherent trade-off between detection delay and threshold
accuracy. Unfortunately, the ndnSIM evaluation provided by
the authors uses only a simple binary tree graph with eight
clients and one attacker; thus, the effectiveness of the scheme
is currently unknown for large networks or distributed attacks.
In Table I, we summarize all the proposed DoS mitigation
mechanisms in terms of the entity implementing the mech-
anism, whether the attack model involves existent, dynamic,
or non-existent content requests, the nature of the mitigation
approach, the extra functionality needed in the routers, and
the level of collaboration required between routers. We discuss
open problems and scope for future work in the last subsection
to give a comprehensive view to the reader.

B. Content Poisoning Attack

The objective of the content poisoning attack is to ﬁll routers’
caches with invalid content. To mount this attack, an attacker
must control one or more content providers or intermediate
routers, so that it may inject its own content into the network.
The injected content should have a valid name corresponding
to an interest, but a fake payload or an invalid signature. The
poisoning attack is illustrated in Fig. 5, with the attacker (one of
the content routers on the path between the client and provider)
returning an invalid content (oval C1) instead of the genuine
content (rectangular C1) corresponding to the requested name.
The content poisoning attack is typically infeasible on the
IP Internet (without mounting a man-in-the-middle) as a client
connects directly to the provider to establish a ﬂow. The ICN
paradigm however, allows the content to be served by any in-
termediate router or from any one of several content providers.
This attack can have potentially devastating consequences: the
network can be ﬁlled with poisoned content objects that are
useless to the clients, while useful content ﬁnds no place in
the caches. In the following, we review the countermeasures
against content poisoning.

Gasti et al. [54] were the ﬁrst to discuss the content/cache
poisoning attacks. As their ﬁrst countermeasure, the authors
suggested the use of a “self-certifying interest/data packet”
(SCID), which helps forwarding routers validate received con-
tent chunks. Prior to sending an interest, a client is required
to obtain the desired chunk’s hash, name, and signature from
the content provider; this information is then attached to the

interest. On retrieving a content chunk, a router can easily
check its validity by comparing its hash to the hash from
the interest. This method is less computationally intensive
than traditional RSA signature veriﬁcation, however it requires
that the client obtain the hashes for each data chunk/packet
beforehand. This requires the client
to query the provider
directly prior to requesting a content; this dramatically increases
content retrieval latency and limits scalability.

As an alternative solution,

the authors proposed cached
content signature veriﬁcation by routers. In their basic model,
each router randomly selects content chunks to be subject to
veriﬁcation; the router veriﬁes the signatures of the selected
chunks, and drops any that are corrupted. To prevent redundant
veriﬁcation, routers collaboratively select a range of content
chunks to verify; the scope of this collaboration varies, ranging
from a neighborhood to an organization. To reduce collab-
oration overhead, the authors also suggested client feedback
decision-making, in which a client may inform its edge router
about each content chunk’s validity. However,
this type of
feedback can also be used by malicious clients to mislead
routers by reporting legitimate content objects as fake, or vice-
versa.

Ghali et al. [58] proposed a content poisoning mitigation
mechanism while introducing an updated deﬁnition of a fake
content. The authors deﬁned a fake content as one with a valid
signature using the wrong key, or with a malformed signa-
ture ﬁeld. The authors discussed the applicability of existing
solutions such as signature veriﬁcation by intermediate routers,
which is infeasible at line speed. Although self-certifying names
can mitigate the effect of content poisoning, there are problems
which need to be addressed such as how content hashes

Fig. 5: Content poisoning attack scenario.

C1C1C1ClientClientEdge  routerContent  providerRouterRouterContent  routerAttackerContent  routershould be obtained and how dynamic content objects should be
addressed. Hence, the authors proposed a ranking mechanism
for cached content using exclusion-based feedback.

Exclusion is a selector feature in the CCN and NDN archi-
tectures, which allows a client to exclude certain data (either
by hash or name sufﬁx) from matching its interest, effectively
overriding a match on the requested name’s preﬁx. Clients can
use this feature to avoid receiving data objects that are known
to be unwanted, corrupted, or forged. Therefore, it is a useful
feedback mechanism for detection of poisoned content. The
detector’s ranking function takes three factors into account,
namely number of exclusions, exclusion time, and exclusion-
interface ratio. The exclusion time deﬁnes the recency of a
particular data name exclusion (freshness of the exclusion).

In the paper, a content with more exclusions, or a recent
exclusion has a lower rank. A content’s rank is also reduced
if the router receives exclusion feedback for it from multiple
clients on different interfaces. In this approach, whenever there
are multiple cached contents with names that match the name of
an interest, the router returns the content with the highest rank.
The drawbacks of this approach are: it is highly dependent on
client feedback; non-cooperative and/or malicious clients can
undermine its effectiveness; and the exclusion feature is not
present in all ICN architectures.

Ghali et al. [57], [59] also noted that the content poisoning
mitigation is contingent on network-layer trust management.
According to them the cache poisoning attack depends on
two properties of ICN: interest ambiguity and lack of a trust
model. The former arises from the interest packet structure,
which considers the content name as the only compulsory ﬁeld,
while neglecting two other ﬁelds, the content digest and the
publisher public key digest (PPKD). The latter refers to the
lack of a uniﬁed trust model in the network layer. To efﬁciently
solve the content poisoning problem, the authors suggested a
mechanism that clariﬁes this ambiguity in the interests. The
proposed approach is built upon adding a binding between
content name and the provider’s public key, an Interest-Key
Binding (IKB), to the interest packet. The only modiﬁcation
at the content provider is the addition of the provider’s public
key to the content’s KeyLocator ﬁeld. An intermediate router,
upon receiving a content, should match the hash of the public
key present in the KeyLocator ﬁeld with the interest’s PPKD
(available in the PIT). The content will be forwarded if these
match, and will be discarded otherwise.

The client-side complexity of this approach is in obtaining
the provider’s public key in advance. In order to bootstrap
a trust model, the authors proposed three approaches: a pre-
installed public key in the client’s software application, a global
key name service similar to DNS, and a global search-based
service such as Google. To reduce core routers’ workload, the
authors proposed that edge routers perform the IKB check for
all content packets, while core routers randomly verify a subset
of content packets. Unfortunately, this mechanism does not
scale. Signature veriﬁcation, which is a public key infrastructure
(PKI) based veriﬁcation,
is slow and cannot be performed
at line speed, hence even if random routers or edge routers

perform the veriﬁcation, it will result in congestion and po-
tentially undesirable interest timeouts. Some other weaknesses
of the mechanisms proposed by the authors [54], [58], [57],
[59] include the assumption that the verifying router is trusted–
perhaps the router is malicious, then it can verify an incorrect
IKB to be correct. Further, the schemes lacked from detailed
analysis of scalability and overhead.

Kim et al. [72] proposed a mechanism to reduce signature
veriﬁcation cost. The mechanism was inspired by check before
storing (CBS) [29], which probabilistically veriﬁes and checks
content items, and only validated content items can be stored
in the cache. Through simulation analyses, the authors noticed
that in general only a small number of cached contents (10%
of the content set) are requested before expiration of their
lifetimes. Hence, they divided the cached content into serving
content, which will be requested while they are cached, and by-
passing content, which will be dropped from the cache before
subsequent interests.

The authors used a segmented LRU policy for cache replace-
ment: a content is initially put in the unprotected segment of the
cache (content initially assumed to be by-passing content), upon
successful veriﬁcation it is moved to the protected segment. The
proposed countermeasure, taking advantage of this separation,
only veriﬁes the signature of a serving content. A content is
deﬁned as serving when it has a cache hit, at which point
it’s signature is veriﬁed and it
is moved to the protected
cache segment. This prevents resources from being wasted on
verifying by-passing content. To avoid multiple veriﬁcations of
a single content chunk, the veriﬁed chunk will be tagged when
it is stored in the protected cache.

Although simulation results demonstrate that the percentage
of the cache ﬁlled with poisonous content goes down, the
scheme has some drawbacks. It still suffers from latency due
to the veriﬁcation process that occurs for every chunk that is
requested twice. Hence, an attacker can enforce veriﬁcation of
every fake content, by requesting it twice–this at scale could
lead to a DoS/DDoS attack. The authors show that with increase
in the protected segment proportion in the cache the overall
hit rate goes down, but they do not mention if that is for
fake content or for usable serving content, this has signiﬁcant
bearing on the efﬁciency of the mechanism.

Table II summarizes the basic techniques used in the pro-

posed countermeasures and their overheads.

C. Cache Pollution Attack

Caching in ICN is effective due to the premise that the
popularity of the universe of content on the Internet follows
a distribution (e.g., Zipf distribution), where a small number
of popular contents are requested frequently, while the rest of
the contents are requested sparingly. The popular (frequently
requested) content objects or chunks can be stored in caches
at the network edge, thus reducing request latency and reduc-
ing network load. However, an attacker can undermine this
popularity based caching by skewing the content popularity
distribution by requesting less popular content more frequently.

TABLE II: Content Poisoning Countermeasures

Mechanism
Gasti et al. [54]
Ghali et al. [58]
Ghali et al. [57], [59]
Kim et al. [72]

Mitigation Approach

Client Feedback, Content Ranking

Interest-Key Binding & Adding the Provider’s Public key to the Content

Collaborative Signature Veriﬁcation of Serving Content

Self-Certifying Interest & Collaborative Signature Veriﬁcation

Hash Value Comparison & Random Signature Veriﬁcation

Overhead

Content Ranking Calculation

PPKD Comparison & Signature Veriﬁcation

Signature Veriﬁcation on Cache Hit

This will pollute the cache and make caching less effective. This
is the cache pollution attack. In this subsection, we explore
two classes of cache pollution attacks: locality disruption and
false locality. In the locality disruption attack, an attacker
continuously requests new, unpopular contents to disrupt the
locality of the cache by churning the cache regularly with new
content. In the false locality attack, on the other hand, the
attacker’s aim is to change the popularity distribution of the
local cache by repeatedly requesting a set of unpopular contents
from within the universe of contents. That is, this attack creates
a different popularity order for the contents.

Xie et al. [119] proposed CacheShield, a mechanism pro-
viding robustness against the locality disruption attack. It is
composed of two main components: a probabilistic shielding
function, and a vector of content names and their corresponding
request frequencies. When a router receives a request for a
content chunk, if the chunk is in its CS, it replies with the
content. Otherwise, the router forwards the interest towards the
provider. When a chunk arrives at the router, the shielding
p−t
q ), where p and q are pre-
function deﬁned as, 1/(1 + e
deﬁned system-wide constants and t denotes the tth request
for the given chunk, is used to calculate the probability of
placing the content in the CS. If the chunk is not placed in
the CS, then the router either adds the chunk’s name with a
frequency of one in the vector of content names, if it does
not exist; if the name exists, then the number of requests for
the chunk is incremented by one. A router caches a chunk in
the CS when the request frequency of the chunk’s name in the
vector exceeds a pre-deﬁned threshold. This approach suffers
from the fact that the shield function’s parameters p and q are
constants and can be easily deduced (if not known), and hence
an attacker can easily calculate the value of t. Then the attacker
has to just ensure that it requests the unpopular contents more
than t times. Additionally, the portion of the CS that is used to
store the name vector is essentially an overhead.

of

overcome

the

To

shortcomings

CacheShield,
Conti et al. [39] proposed a machine-learning based algorithm.
They evaluated the effect of cache pollution attacks on
different cache replacement policies and network topologies.
They proposed a detection algorithm, which operates as a
sub-routine of the caching policy. The algorithm is composed
of a learning step and an attack-testing step. It starts by
checking the membership of an arrived content in a sample set
chosen from the universe of contents. If the content belongs
to the sample set, the learning step will be triggered with
the goal of identifying an attack threshold (deﬁned as τ) for
evaluating the contents. The value of τ is used by the attack
test sub-routine in the testing step. The attack test sub-routine

simply compares the calculated τ with another value δm,
which is a function with parameters, such as content request
frequency and the size of the measurement interval, of all
contents in the sample set as input. If δm is greater than τ,
then the mechanism detects an attack. The drawback of this
approach is that it only detects the attack, but does not identify
the attack interests, or content chunks. Further, the assumption
that the adversary’s content requests can only follow a uniform
distribution, while legitimate users follow the Zipf distribution
is also not a fair assumption. The adversary can always create
requests, such that the distribution of its requested content
follows a Zipf distribution–true for both locality disruption or
false locality.

√

Park et al. [93] proposed a cache pollution attack detection
scheme based on randomness check. They proposed an iterative
scheme that takes advantage of matrix ranking and sequential
analysis for detecting a low-rate cache pollution attack,
in
which an attacker requests content chunks at a low rate to
bypass any rate ﬁlters. The detection scheme starts with the
routers mapping their cached content onto an n × n binary
matrix M, where n (cid:39) [
Sc] and Sc is the average number
of cached content. The authors employ two cryptographic hash
functions for mapping a content name to the row and column
indices. The rank of matrix M is evaluated using the Gaussian
elimination method. The ranking process is iterated k times,
and the attack alarm is triggered if the matrix-rank reaches
a pre-deﬁned threshold. To increase detection accuracy, the
authors used a cumulative-sum algorithm over the iterations. As
they were interested in low-rate attacks, the scheme does not
consider popular contents. The popular contents are removed
from the matrix over the k iterations by AND and XOR
operations performed on M.

The authors showed the effectiveness of their scheme in
detecting low-rate locality-disruption attacks. However,
this
scheme is not applicable to the harder to detect false local-
ity attack. Furthermore, the caching routers have to perform
computationally intensive operations such as matrix genera-
tion, popular content elimination, cryptographic hashing, and
iterative rank calculations, which may not only undermine
scalability, but also adoptability.

Karami et al. [69] proposed an Adoptive Neuro-Fuzzy Infer-
ence System (ANFIS) based cache replacement policy resilient
to cache pollution. The proposed replacement policy involves
three stages:
input-output data pattern extraction, accuracy
veriﬁcation of the constructed ANFIS structure, and integration
of the constructed model as a cache replacement policy. In the
ﬁrst stage, an ANFIS structure is constructed according to the
properties of the cached content. Longevity (the period that the

TABLE III: Cache Pollution Countermeasures

Detection & Mitigation Approaches

Attack Type

Mechanism
Conti et al. [39]
Karami et al. [69]
Mauri et al. [86]
Park et al. [93]
Xie et al. [119]

Random Content Sampling for Attack Threshold Detection
Adoptive Neuro-Fuzzy Inference System Replacement Policy

Honeypot Installation & Hidden Monitoring

Cached Content Matrix Ranking

Probabilistically Caching Popular Content

Locality Disruption

Locality Disruption & False Locality Moderate
False Locality (by Content Provider) Moderate

Low-rate Locality Disruption

Locality Disruption

Low

Moderate

Router’s Overhead

Storage

Low

Computation

Moderate

High
Low
High
High

content has been cached), content request frequency, standard
deviation of the request frequency, the last content retrieval
time, content hit-ratio, and the variance of the content request
rate over all interfaces, for each cached content, are all fed
to a nonlinear system. The system returns a goodness value
(between 0 and 1) per content, where 0 indicates false-locality,
0.5 indicates locality-disruption, and 1 indicates a valid content.
The system iteratively evaluates the goodness of the cached
contents with longevity higher than a pre-deﬁned threshold.
Eventually, the system selects the contents with goodness values
less than the threshold, ranks the remaining contents, and
applies cache replacement over the content with lower goodness
values.

The authors showed the advantages of their proposed mecha-
nism over CacheShield in terms of hit damage-ratio (proportion
of hits that cannot occur due to the attack), percentage of
honest consumers receiving valid contents, and communication
overhead. However, this mechanism needs to store historical
and statistical information for each cached content, which could
be a signiﬁcant memory overhead, especially for core routers.
Additionally, the routers are required to iteratively compute
statistics and update the cache state–additionally computations
that can undermine scalability.

Mauri et al. [86] discussed a cache pollution scenario in an
NDN network in which the provider is the attacker and its intent
is to maliciously utilize the router’s cache to preferentially
store its own content objects and reduce their delivery latency.
The authors assume that the malicious provider has access to
terminal nodes (bots or zombies), which request the content
items available at the attacker. This allows a greater proportion
of the attacker’s content to move down to the edge of the
network, thus improving its latency of delivery to legitimate
clients, under the assumption of requests being routed to
the nearest replica routing. At the same time, other contents
experience relatively higher delay, even if they are truly popular.
The authors proposed a mitigation mechanism for this attack
that used a honeypot installed close to potential zombies, which
monitors and reports the malicious interests to the upstream
routers. A router gathers these interests into a blacklist; the
interests in this blacklist are routed using the standard NDN
routing protocol, which routes based on the FIB entry not the
CS or nearest replica.

In Table III, we summarize the proposed cache pollution
solutions based on their detection and mitigation approaches,
and the nature of the attack. We also present the nature of
the storage and computation overheads for each solution at the
routers.

D. Secure Naming and Routing

1) Secure Naming: Wong et al. [116] proposed a secure
naming scheme with the objective of establishing trust between
content providers and clients. The proposed scheme is based on
three identiﬁers: authority identiﬁer (ID), which is generated
from the provider’s public key; content identiﬁer, which is the
cryptographic hash of the content; and algorithmic identiﬁer,
which binds the content identiﬁer with a set of the content
fragment/chunk identiﬁers. Based on the URI naming conven-
tion, the authority ﬁeld is mapped to the provider’s public key
and the resource path ﬁeld holds the content identiﬁer. This
is similar to the naming scheme in DONA. In this scheme,
the generated metadata, which includes information, such as
content ID, provider ID, algorithmic ID, digital signature, and
additional content speciﬁc information are disseminated into a
set of network nodes that function as part of a domain name
system and also store metadata in a DHT.

For content retrieval, a client queries the DNS to resolve
the content name into a digital certiﬁcate. By extracting the
authority identiﬁer from the certiﬁcate, the client obtains the
metadata that has to be resolved by the DHT. The query to the
DHT returns the content and algorithmic ID, which the client
uses to request the content. The authors have not evaluated the
scalability of the approach in terms of the header overheads
and the latency due to DNS and DHT queries.

Similar to the previous scheme, Dannewitz et al. [42] pro-
posed a naming scheme for NetInf. The authors deﬁned a
tuple composed of the content ID, the content, and a piece
of metadata called the information object (IO). The content
ID follows a self-certifying ﬂat structure containing type,
authentication, and label ﬁelds. The type ﬁeld speciﬁes the
hashing function used for ID generation. The authentication
ﬁeld is the hash value of the provider’s public key; and the
label ﬁeld contains a number of identiﬁer attributes and is
unique in the provider’s domain. The IO includes ﬁelds, such
as the provider’s complete public key and its certiﬁcate, a
signature over the self-certiﬁed data, the hash function used for
the signature, and any additional information for the owner’s
authentication and identiﬁcation.

One of the drawbacks of this naming scheme is the signiﬁ-
cant overhead of the headers, which includes the public key and
the certiﬁcate. The authors do not discuss what portion of the
metadata is fetched in the beginning and whether the signature
veriﬁcation happens per chunk, or if it happens after the whole
content is downloaded. Veriﬁcation after the whole content is
downloaded is undesirable as it enables cache poisoning and
pollution attacks.

Zhang et al. [127] proposed a name-based mechanism for
efﬁcient trust management in content-centric networks. This
mechanism takes advantage of identity-based cryptography
(IBC), in which either the provider’s identity or the content
name preﬁx is used as the public key. In this mechanism, a
trusted private key generator (PKG) entity is responsible for
generating private keys given an identity (public key). To do
so, the PKG generates a master key, which it keeps secret and
uses it to generate private keys, and a set of public system
parameters. To sign a content, a provider ﬁrst securely acquires
its private key (corresponding to its identity) from the PKG.
After that, it signs the content and publishes it to the network.
A client, using the public system parameters and the identity
of the provider, can easily verify the content signature. This
procedure can also be performed using the content name preﬁx
as the public key; in this case, a name resolution service is
required to register the name preﬁx.

For conﬁdentiality, a provider may encrypt the content with
the client’s public key, which can be obtained using the client’s
identity by using the system parameters. Meanwhile, the client
has to securely communicate with the PKG to receive its private
key. For group based communication, the provider encrypts the
content with a symmetric key and encrypts the symmetric key
using the group members’ public keys. Despite the advantages
of IBC, PKI is still necessary to secure communication between
the PKG and other network entities. Additionally,
the use
of the content name preﬁx as the public key needs to be
investigated more thoroughly. Another signiﬁcant drawback is
that the scheme requires the client to receive its private key from
a trusted third-party, which seriously undermines the usability
of this scheme in the real-world.

Hamdane et al. [63] proposed a hierarchical identity-based
cryptographic (HIBC) naming scheme for NDN. This scheme
ensures a binding between a content name and its publisher’s
public key. Their identity-based content encryption, decryption,
and signature mechanisms follows [127]. Different from the
previous work, the authors proposed a hierarchical model in
which a root PKG is responsible only for generating private
keys for the domain-level PKGs. In this hierarchical model, the
domain-level PKGs perform the clients’ private key generation.
The identity of an entity is represented as a tuple, composed
of its ancestor PKGs’ identities and its own identity. Therefore,
a PKG at level t derives the private keys of it’s child entity
with an ID t+1-tuple of the form (ID1, ID2, ..., IDt, IDt+1),
where IDt+1 refers to the child entity’s ID. In this scheme,
the ID tuple is used as the public key and the cryptographic
operations are similar to classical IBC. This scheme has the
same scalability concerns as the previous scheme on account of
the encryption/decryption costs. In fact, the overhead is higher
as the size of the public key is longer and grows with the depth
of the hierarchy.

Table IV summarizes the existing secure naming schemes
and presents the type of cryptography used, the mechanism
for ensuring provenance, and the nature of the encryption
infrastructure. We note that for most of the proposed naming
schemes, there exist signiﬁcant overhead and there needs to be

more effort in reducing these overheads, or at least amortizing
their cost across the complete set of interests/responses.

2) Secure Routing: Afanasayev et al. [15] proposed a secure
namespace mapping scheme, which allows interest forwarding
for name preﬁxes that are not in the FIB, which is important in
the event of node mobility. The proposed mechanism is built
upon two main concepts: link object and link discovery. The
link object is basically an association between a name preﬁx
and a set of globally routable preﬁxes. By creating and signing
a link object, the content owner maps its own name preﬁx to
those globally routable preﬁxes. The authors designed an NDN
based DNS service (NDNS), where the mapping between the
name preﬁx and the globally routable preﬁxes are stored, and
the service provides this mapping (delegations) to a requesting
entity.

For link discovery, a client queries the NDNS iteratively for
each component of the requested name preﬁx. If a client sends
an interest that a router cannot satisfy using its FIB, that router
returns a NACK. After the NACK reaches the client, its local
forwarder discovers and validates the link object corresponds to
the name preﬁx. After that, the client embeds the link object to
its original interest and forwards it to the network. Although this
scheme is a good initial solution to provider mobility it still has
overheads. When a provider moves, the current routable preﬁx,
which is in the FIB of the routers, will results in interests being
routed to the provider’s former location until the FIB entries
time out, which may waste bandwidth in high trafﬁc scenarios.
Rembarz et al. [95] proposed two approaches to secure the
communication between public and private domains in NetInf.
The ﬁrst approach, gateway-centric approach, places a gateway
between the public and private networks. All communication
between these two networks are routed through this gateway. A
publisher in the private domain publishes a content to a private
name resolver, PNR, which resides in the private domain.
The PNR informs a public name resolver (NR) in the public
domain, about the published content’s identiﬁer along with the
gateway’s location; instead of the actual publisher’s location. A
subscriber in the public domain resolves the content identiﬁer
at the public NR and obtains the gateway address. Upon the
successful authentication of the subscriber at the gateway, the
gateway resolves the content identiﬁer at the PNR and delivers
the content from the publisher to the subscriber.

In the second approach, the publisher in the private domain
publishes its private data identiﬁer to a PNR. The PNR creates
a mapping between the content identiﬁer ID and a generated
alternative identiﬁer ID’ that is sent to the NR. A subscriber,
in the public domain, contacts the NR to resolve ID’ to its
location. The NR redirects the subscriber to the PNR for
authentication and authorization. Upon the successful authen-
tication, the PNR provides a token to the subscriber, which
the subscriber uses for content retrieval from the publisher.
This mechanism solves the drawbacks of the ﬁrst approach, in
which the gateway is a single point of failure and the network
bottleneck, by eliminating the necessity of having a gateway.
However, the PNR’s computation and communication overhead
for subscribers authentication and authorization (especially

Mechanism
Dannewitz et al. [42]
Hamdane et al. [63]
Wong et al. [116]
Zhang et al. [127]

Provenance

TABLE IV: Secure Naming Approaches
Crypto
RSA
HIBC
RSA
IBC

Pub. Key Digest
IBC Signature
Pub. Key Digest
IBC Signature

Drawbacks

Lack of Evaluation & Scalability Issue

Signature Veriﬁcation Overhead

PKG Requirement for Private key Generation

Scalability Issue & Public key Length

when the private network serves large amounts of requests)
undermines the scalability of this approach.

Alzahrani et al. [19], [20] proposed a DoS resistant self-
routing mechanism using Bloom ﬁlters for publish/subscribe
networks. In publish/subscribe networks, each network link is
assigned a unique identiﬁer (LID), which is represented in the
form of a Bloom ﬁlter. When a network entity requests for
a path from the client to a location where the content exists
(may be publisher or a cache), an entity called the topology
manager (TM), which resides in one or more routers, generates
a ﬁlter (z-ﬁlter) that speciﬁes the delivery path from a publisher
to its subscriber by OR-ing the Bloom ﬁlters (LIDs) of the
links on the delivery path. At the intermediate routers, an AND
operation between the z-ﬁlter (in the packet header) and the
routers’ LIDs on the path indicates the delivery links.

This mechanism is vulnerable against DoS attack in which an
attacker, can collect enough z-ﬁlters and reuse them to overload
the delivery path with bogus trafﬁc. The authors suggested the
use of dynamic link identiﬁers to remedy this vulnerability. In
the proposed mechanism, the TM creates a new z-ﬁlter (for each
time interval) considering the incoming/outgoing interfaces of
the routers on the delivery path, a time-based secret (shared
between TM and intermediate edge routers), and the ﬂow ID
(the information item ID). These per-ﬂow, time-sensitive z-
ﬁlters restricts the duration for which the attacker can use them
(after that they become stale).

This updated mechanism introduces two drawbacks; ﬁrst,
the number of z-ﬁlter updates increases with a decrease in
the time interval, thus better attack mitigation requires higher
computational overhead for the TM. Second, the size of the
packet header (includes the z-ﬁlter) increases with the number
of links in the delivery path. For this reason,
the authors
investigated factors that affect the z-ﬁlter’s size in [21]. One
of the factors affecting the Bloom ﬁlter size is its inherent
false positive probability—bigger the ﬁlter’s size smaller the
false positive probability. This false positive probability may
cause more network trafﬁc by selecting additional links that are
not in the delivery path. An attack scenario arising from false-
positives involves an attacker who maliciously turns some 0 bits
in the z-ﬁlter into 1’s to add more links to the delivery path. In
another attack scenario, an attacker can launch a replay attack
using a valid ﬁlter, in order to send a bogus content, which was
not requested.

Alzahrani et al. [22] proposed a key management protocol
for publish-subscribe networks which utilized dynamic link
identiﬁers. Following the proposed mechanism in [19], [20]
the authors proposed an enhancement that prevents a malicious
publisher from generating fake z-ﬁlters by creating a mecha-
nism for the publisher’s edge router to verify the TM generated

z-ﬁlter. For a content of a particular publisher, the TM uses the
symmetric key that it shares with the publisher’s edge router to
cryptographically hash the corresponding z-ﬁlter and the z-ﬁlter
generation timestamp and forwards it to the publisher along
with the z-ﬁlter. The publisher sends the packet including the
received information to its edge router who checks the validity
of the z-ﬁlter by comparing the received hash (generated by
the TM) with the one it generates. Upon successful validation,
the edge router stores the z-ﬁlter in a table for its TTL period,
and forwards all subsequent packets with that z-ﬁlter, without
further validity check.

Due to the vulnerability of the Difﬁe-Hellman protocol
against man-in-the-middle attacks, to achieve mutual authen-
tication between TM and routers,
the authors used Difﬁe-
Hellman-DSA, as proposed in [80]. However, the proposed
mechanism is vulnerable against the malicious publisher collud-
ing with its edge router. In addition, this mechanism requires
stateful routers, which are vulnerable against ﬂooding based
DoS attacks (similar to CCN/NDN DoS-ﬂooding attack).

Yi et al. [122] augmented the NDN forwarding plane to
thwart security problems, such as preﬁx hijacking and PIT
overload. In preﬁx hijacking, an attacker announces the victim’s
preﬁx and drops the packet. The authors suggested the use of
interest NACKs whenever requests are not satisﬁed for reasons,
such as network congestion, non-existent content, and duplicate
content. The interest NACK reduces the chance of PIT overload
by allowing the reduction of the PIT timeout to a value close
to the network RTT, where previously the PIT timeout was
much greater than the RTT. Additionally, it mitigates the preﬁx
hijacking vulnerability, by providing extra time for the router to
query other faces. However, it increases the amount of states
that routers must store: each router has to store information
about the RTT for each interest, for a router that receives
requests at line speed, this can be a large amount of states.
Although a router’s storage can possibly handle this amount
of storage, it opens a new horizon for attackers to pollute
this information-base. Additionally, with the NACK consuming
an interest in the PIT, there is no scope for bogus interest
aggregation, thus an attacker can keep sending the same bogus
interest several times without any adverse action.

E. Application-level Security

Work on ICN application security can be classiﬁed into three
major subtopics: ﬁltering, anomaly detection, and application
security suites. Filtering concerns the identiﬁcation and re-
moval of unwanted content, such as spam, forged content, and
content from untrusted publishers. Anomaly detection involves
the detection of other types of undesired activity, such as

ﬂooding, misbehavior of network elements, and malicious traf-
ﬁc. We have designated application-speciﬁc security measures
as application security suites; these suites combine different
cryptographic techniques to achieve some speciﬁc goal(s).

Fotiou et al. [49] proposed an anti-spam mechanism for
publish/subscribe networks. It is based on an inform-ranking
process, with content ranked based on votes from publishers
and subscribers. Each publisher serving a content implicitly
votes for that content, and the publishers’ votes are weighted
based on the publishers’ own ranks and publication counts.
After the content is published, it can be voted on by subscribers.
Each subscriber’s vote is weighted inversely to the total number
of votes it has cast. After all votes are collected, the information
can be used to rank the content objects and identify content
objects that are likely to be spam.

The simulations demonstrated that this mechanism is better
at ﬁltering spam in comparison to existing schemes, which only
consider the publisher’s vote when ranking content. However,
this scheme’s reliance on user feedback may degrade its ef-
fectiveness in a real deployment; not only are typical users
unlikely to vote on the content, but malicious users can hijack
the process easily to make up the majority. Moreover, the voting
process itself confers non-negligible communication overhead.
Karami et al. [70] proposed a fuzzy anomaly detection
algorithm for content-centric networks. It employs the Particle
Swarm Optimization (PSO) meta-heuristic algorithm, k-means
clustering, and a fuzzy detection algorithm to classify behaviors
as either normal or abnormal. The detector must ﬁrst be trained,
and thereafter can used to identify potentially malicious trafﬁc.
The fuzzy approach is notable for its low false-positive rate.
However, this comes at the cost of an increased false-negative
rate. Therefore, it may be possible for an attacker with sufﬁcient
resources to produce enough trafﬁc such that some of its
malicious packets are not detected. Additionally, a false positive
results in a legitimate user’s quality of service being degraded–
the user may get wrongly punished.

Wong et al. [117] proposed a separate security plane for
publish/subscribe networks, which would be responsible for
assuring content integrity. The security plane takes over the
distribution of authentication materials and associated content
metadata, which would otherwise be the responsibility of the
data plane. The materials distributed by the security plane
would therefore include the content name, the content ID, the
Merkle tree root, the publisher’s public key, and the publisher’s
signature. To prevent the insertion of malicious metadata, pub-
lishers are obligated to identify themselves to the security plane
and submit to challenge-response authentication. We believe
that while it is convenient for data to be separated from its
authentication materials, abstraction of this functionality into a
separate control plane is ultimately unnecessary. The integrity
assurances of the proposed control plane are no more ﬂexible
and no stronger than those provided by simpler content-signing
schemes, such as the manifest-based content authentication
supported by CCN or NDN.

Goergen et al. [61] designed a semantic ﬁrewall for content-
centric networks. Unlike IP ﬁrewalls, which ﬁlter at ﬂow-

level granularity, the CCN ﬁrewall can ﬁlter content based on
provider and/or name. For provider-based ﬁltering, the ﬁrewall
must obtain the provider’s public key, which is then used to
identify disallowed providers and also ﬁlter content objects with
invalid signatures. Content name ﬁltering is a more convenient
ﬁltering paradigm, in which requests with blacklisted keywords
in the name are ﬁltered. Both types of ﬁltering can be performed
on either interests or their corresponding content objects.

Additionally, the ﬁrewall can monitor the behavior on each
of its interfaces and ﬁlter peers that show abnormal behavior,
such as high request volume or high drop rate. A minimalistic
evaluation of the proposed ﬁrewall shows that latency does
not increase dramatically with the number of ﬁltering rules –
retrieval time increased by only 1.75% for a 500MB content.
However,
these delays may become signiﬁcant for bigger
content objects and with the increase in number of content
objects, which has not been addressed. Thus the scalability of
the approach is unknown.

Goergen et al. [60] proposed a security monitoring mecha-
nism for CCN with the objective of detecting attack patterns
based on the activities of the FIB, PIT, and CS. To detect
abnormal behavior, each node periodically evaluates statistical
per-second information such as bytes sent, bytes received,
content
items received, and interests received. In addition,
statistics are stored on the total number of accepted, dropped,
and sent interests. In order to classify a particular time period
as either anomalous or benign, the authors employ support
vector machine (SVM) classiﬁcation. The experimental results
show the efﬁcacy of this method for attack detection; however,
its ability to detect certain low-rate attacks is questionable.
Furthermore, the added responsibility of SVM classiﬁcation,
which is relatively intensive, creates unnecessary load on core
network elements.

Ambrosin et al. [23] identiﬁed two different ways of creating
an ephemeral covert channel in named-data networking. For
both types of covert channel, sender and receiver must have
tight time synchronization and agree on a set of unpopular
content to use for the exploit. To send a “1” bit covertly, the
sender requests an unpopular object during the proscribed time
slot, to send a “0,” no request is sent. In the ﬁrst variation,
the object is assumed to be cached at the edge router if it was
requested. The receiver then requests the same content, and
measures the retrieval time to differentiate a cache hit from a
cache miss, and consequently infers the bit that was sent. This
mechanism is accurate when the sender and receiver are co-
located behind the same edge router; therefore, its applicability
is limited. Furthermore, the covert transmission is very limited
in bandwidth, and imposes a large load on the network.

Burke et al. [30] presented a security framework for a CCN-
based lighting control system. In the ﬁrst variation of the
protocol, control commands required a three-way handshake
and were transmitted in a signed content payload; in the second,
the commands were immediately sent as a signed interest.
The framework uses an authentication manager to manage
the network’s PKI, and employs shared symmetric keys for
communication. To reduce the burden of key storage on the

TABLE V: Application Security Summary

Moderator-controlled information sharing

Publisher signature followed by moderator signature for message publications

Mechanism
Ambrosin et al. [23]
Asami et al. [26]
Burke et al. [30]
Burke et al. [31]
Fotiou et al. [49]
Goergen et al. [60]
Goergen et al. [61]
Karami et al. [70]
Saleem et al. [98]
Vieira et al. [108]
Wong et al. [117]
Yu et al. [123]

Application

Ephemeral covert channel

Lighting control system
Secure sensing in IoT
Anti-spam mechanism

Trafﬁc anomaly detection at routers

Semantic ﬁrewall

Anomaly detection mechanism

Secure email service

Security suite for Smart Grid

Content integrity by security plane

Trusted Data Publication/Consumption

Time difference analysis between cache hit and cache miss

Approach

Submitting commands as signed content or signed interest

Assigning a sensor an ACL for content publishing

Information ranking based on publishers and subscribers votes

Statistical data analyses and SVM classiﬁcation

Filtering by content name, provider’s public key, and anomaly detection

Fuzzy detection algorithm and trafﬁc clustering

Asymmetric crypto with emails as independent objects

Content-based cryptography and access level distribution via security server

Content signature and publisher authentication to security plane by challenge-response

Schematized chain-of-trust

embedded devices, these symmetric keys can be generated on-
demand by a pseudorandom function. These shared symmetric
keys can then be used to enforce encryption-based access
control.

The authors in [31] employ a similar architecture to perform
secure sensing in the Internet of Things (IoT). The system
requires an authorization manager (AM), a trusted third party
which generates root keys, which are then used to sign any
other keys produced. The AM associates a producer with
a namespace, which is listed in the producer’s certiﬁcate.
Each sensor is also assigned an access control
list, which
speciﬁes the permissions of each application with respect to
that node. While this scheme is ﬂexible in providing conﬁ-
dentiality, integrity, authentication, and access control for IoT
networks,
it suffers from a signiﬁcant overhead problem—
power-constrained devices such as sensing nodes are required
to perform asymmetric-key cryptography, which are expensive.
Yu et al. [123] presented a schematized trust model for
named-data networks to automate data authentication, signing,
and access procedures for clients and providers. The proposed
model is composed of two components: a set of trust rules,
and trust anchors. Trust rules deﬁne associations between data
names and the corresponding keys that are used to sign them.
The authors deﬁne a chain of trust, which is discovered by
recursively evaluating trust rules, starting from the KeyLocator
ﬁeld in the content and ending at a trusted anchor. Anchors are
envisioned to serve as trusted entities that help bootstrap the
key discovery process.

For data authentication, the client uses the public key in the
KeyLocator of the packet and according to the trust schema,
recursively retrieves public keys to reach a trust anchor. It
authenticates the data packet by verifying the signatures from
the trust anchor to the received packet (in reverse). For signing
a content a client
identiﬁes the trust rule and if it has a
corresponding key, it signs the content. If the key does not
exist, the client generates the corresponding key according to
the name and the cryptographic requirements. A generated key
needs to be signed according to the trust rule. The chain-of-
trust allows an entity to publish veriﬁable content and another
to verify the veracity of the content following the chain.

The iterative discovery and key veriﬁcation step is inher-
ently inefﬁcient, especially for mobile devices that are power

constrained. Further the trust rules may become complex very
quickly within a few levels,
in inaccurate
conﬁguration during usage. This limits the applicability of the
approach.

this may result

Vieira and Poll [108] proposed a security suite for C-DAX,
an information-centric Smart Grid communication architecture.
The proposed security suite employs content-based cryptog-
raphy, in which content topics are used as public keys, and
the corresponding secret keys are generated by a security
server. For each topic, write-access secrets and read-access
secrets must be distributed to each authorized publisher and
subscriber, respectively. While the scheme provides sufﬁcient
security and ﬂexibility for typical applications, its reliance on
a central security server constitutes a single point of failure. In
a high-impact application such as the Smart Grid, the failure
or compromise of this service could have dire consequences.
Also, requiring cyber-physical devices to store two keys for
each topic also limits scalability.

Saleem et al. [98] proposed a distributed secure email service
for NetInf, based on asymmetric-key cryptography. In line with
the principles of ICN, each email message is treated as an
independent object. A client’s (user’s) public key constitutes
its identiﬁer, and no domain name service is required; there-
fore, the scalability of the proposal is good. However, the
subscription-based nature of the service potentially leaves users
vulnerable to spam, and no mitigation for this has yet been
proposed.

Asami et al. [26] proposed a moderator-controlled informa-
tion sharing (MIS) model for ICN, which provides Usenet-
like functionality for ICNs while leveraging an identity-based
signature scheme. Several message groups are deﬁned, each
of which is assigned a moderator. To publish a message, the
publisher signs with its secret key then sends it to the moderator
of the group to which it wants to publish; the moderator can
then sign the message and relay it to the group’s subscribers,
or reject the message and drop it. To verify a signature, the
subscriber only needs to know the identities of the publisher and
moderator. This is an example of implementation of a secure
legacy application in ICN.

Table V summarizes the proposed application-level mecha-

nisms.

F. Other General Contributions

In this subsection, we review existing work which high-
lighted, classiﬁed, and addressed ICN security problems in
general. In what follows, we discuss security concerns in
NetInf [81], PSIRP [51], and publish/subscribe architectures
in general [50], as well as concerns related to ICN’s stateful
data plane [110].

Loo et al. [81] studied the security challenges faced by NetInf
from the perspectives of both applications and infrastructure.
The authors divided their concerns into eight categories: access
control, authentication, non-repudiation, data conﬁdentiality,
data integrity, communication security, availability, and privacy.
Application-layer concerns included poisoned content injection,
privacy invasion, unauthorized access, and false accusation. At
the infrastructure level, the authors elaborated on the threats
of unauthorized content access, privacy, and cache and route
misuse. Solutions discussed by the authors included provider
authentication and authorization, Tor-like approaches to privacy
preservation, and PKI-based approaches to signature veriﬁca-
tion and content integrity. Unfortunately, the descriptions of
the proposed solutions are shallow, and their generality raises
concerns about their efﬁciency and ﬂexibility for application in
ICN.

Fotiou et al. [51] reviewed a clean-slate PSIRP network-
ing architecture and highlighted its security assurances. The
architecture employs self-certifying names, each composed of
a rendezvous identiﬁer (RID) and a scope identiﬁer (SID).
Content publication and client subscription operations follow
the same general approach as any publish/subscribe network.
To preserve information security, content
transmissions are
encrypted and include packet-level authentication (PLA). Under
PLA, the packet header contains the sender’s signature along
with its public key and certiﬁcate. The forwarding mechanism
utilizes the z-ﬁlter, a Bloom ﬁlter generated by the topology
manager to deﬁne the information delivery path. The z-ﬁlters
protect against DoS attack by using dynamic link identiﬁers,
as explained in [19], [20].

In the previous subsection, we discussed concerns about the
z-ﬁlter, related to scalability and false positives. Apart from
that, the other main drawback of this design is the use of
per-packet cryptographic signatures in PLA. Performing such
operations at line speed is difﬁcult, even for routers equipped
with embedded cryptographic processors.

Fotiou et al. [50] discussed the security requirements and
threats in publish/subscribe networks, and presented some
preliminary solutions towards a secure rendezvous network.
The authors highlighted client privacy, access control, content
integrity, conﬁdentiality, and availability as the most important
security concerns for publish/subscribe networks. Addition-
ally, rendezvous-based networks are required to handle sub-
scriber/publisher authentication, anonymity for user subscrip-
tions and subscription-publication matching, and accounting for
publication dissemination. A lack of attention to these security
concerns would lead to vulnerabilities such as cache poisoning,
denial of service, route hijacking, and attacks where a malicious

The authors broadly discussed a solution which employs a
key management center, role-based and attribute-based access
control, and homomorphic cryptography. This mechanism mit-
igates many of the poisoning and hijacking attacks, however
privacy concerns and denial-of-service attacks have not been
addressed. Attribute-based access control, in general, also has
limited ﬂexibility due to its inherent lack of support for revo-
cation.

Ghali et al. [55] proposed a secure fragmentation mechanism
for content-centric networks. Unlike the chunking procedure
already performed by content providers, content fragmentation
may happen anywhere in the network–necessary if a chunk
larger than a link MTU (maximum transmission unit) must
be forwarded. The authors argued for per-hop reassembly
of fragments, and concluded that support for interest packet
reassembly should be mandated for the sake of routing efﬁ-
ciency. However, such reassembly requires a more sophisticated
content integrity veriﬁcation mechanism. Therefore, the authors
proposed a method of incremental fragment veriﬁcation for out-
of-order fragment delivery. The router assigns a buffer for each
chunk and veriﬁes each incoming fragments using the informa-
tion calculated from the previous fragments. Upon receiving the
last fragment, the router determines the validity of the entire
chunk and forwards the last fragment only if authentication
succeeds. The simulation results show that retrieving a 32KB
content with the proposed fragmentation mechanism is about
2.5 times slower than baseline CCN. Though fragmentation
increases the ﬂexibility of the network, this is a very signiﬁcant
increase in latency.

entity creates multiple fake identities (Sybil attack).

Marias et al. [83] have identiﬁed security and privacy
concerns which should be addressed by a future Internet
architecture. The authors ﬁrst reviewed recent achievements in
physical layer security, network coding security, and network
infrastructure security. Then they identiﬁed authentication and
identity management as core building blocks of a secure
network, and discussed the challenges of implementing them.
Regarding privacy, the authors reviewed some existing work in
Internet of Things (IoT) privacy and highlighted communication
anonymity as a necessity in a future Internet. Additionally,
the authors highlighted the requirements and challenges for
mobile application security and privacy. However, the authors
did not elaborate on the attacks that are inherent to ICN, such
as cache pollution, content poisoning, DoS/ﬂooding, and the
timing attack. Furthermore, a review of existing access control
mechanisms for ICN has been neglected.

Wahlisch et al. [110] discussed the threats and security
problems that arise from stateful data planes in ICN. The
authors categorized these attacks into three classes: resource
exhaustion, state decorrelation, and path and name inﬁltration.
Resource exhaustion attacks include those such as DoS, interest
ﬂooding, and PIT overload. Timeout attacks (orchestrated by
throttling the network to increase latency) and jamming attacks
are examples of state decorrelation attacks. Path and name in-
ﬁltration attacks include route hijacking and route interception.
Despite presenting a thorough attack classiﬁcation, this paper

did not discuss any mitigation to the aforementioned attacks.
As this subsection groups a set of non-related works, we do
not summarize them in a table. We also do not provide any
summary or future research in this category.

G. Summary and Future Research

In this section, we reviewed the state-of-the-art

in ICN
security, speciﬁcally attacks such as denial of service, content
poisoning, cache pollution, and secure naming. Here, we sum-
marize the existing challenges and suggest potential directions
which may be useful directions for exploration.

1) Denial of Service Attack: DoS attacks, in general, either
target the content routers [14], [38], [41], [112], [111], [91]
and/or the content providers [68], [54], [79]. An attacker tries to
exhaust either the routers’ PITs or content providers’ resources
by requesting dynamic or non-existent content with a high
rate, which causes unbounded service delays for legitimate
clients. The majority of the proposed solutions [14], [38],
[41], [54], especially against the interest ﬂooding based DoS
attacks, are variants of a rate limiting mechanism on the
suspicious interfaces or name preﬁxes. The major drawback of
the rate limiting based solutions is the impact they have on the
legitimate clients who are either co-located with the attackers,
or are requesting dynamic content that are not generated yet or
mistakenly requesting a non-existent content. No scheme does
a per-ﬂow based rate-limiting. The closest is the approach by
Gasti et al. [54] where preﬁx based rate-limiting was proposed.
There is need for more ﬁne-grained rate-limiting to better limit
malicious from benign requests.

Other proposed mechanisms including per-interest client’s
proof-of-work [79], fuzzy logic-based detection [111], statis-
tical hypotheses testing theory [91], and increasing the caching
time [68] have also been proposed to solve the problem.
However, these mechanism either require storage of per content
statistics at the routers or are not computationally scalable,
especially in the real time. A better mechanism may be one that
removes the suspicious requests from the PIT [112], similar to
the publish-subscribe Bloom ﬁlter based self-routing [8], [9].
This mechanism can be augmented by taking a self-routing
approach for the suspicious interests and the available stateful
routing for the legitimate interests.

Another potential direction is employing a software-deﬁned
networking (SDN) approach in which a network controller
with an overall aggregated view of the network detects and
mitigates the DoS attack in its earlier stage. It can be achieved
by the collaboration of routers at different levels of the network
hierarchy, speciﬁcally for ﬁltering the communication ﬂows that
share malicious name preﬁxes. Exploiting a more sophisticated
interest aggregation method, which aggregates the malicious
interests with same preﬁx (regardless of their sufﬁxes) into one
PIT entry, can also slow down the PIT exhaustion. We also
believe some of the current IP-based detection and defense
mechanisms [124] might be relevant for ICN DoS mitigation.
This is a signiﬁcant area of interest.

is to ﬁll

the routers’ caches with fake contents,

2) Content Poisoning Attack: In this attack, the attacker’s
goal
that
are either content with valid names and invalid payloads or
content with invalid signatures. All of the proposed mechanisms
require the intermediate routers to verify the data packets’
signatures [54], [72], compare the content hash in interest and
data packets [54], [57], [59], or to rank the contents based
on the clients’ feedback [58]. The signature veriﬁcation based
mechanism [54], [72],
line
speed due to the high cost of cryptographic operations. Content
ranking proposed in [58] solely relies on the clients’ feedback
and hence, is vulnerable to malicious clients.

in general, are not scalable at

To effectively address the content poisoning attack, a detec-
tion mechanism should be employed with negligible cost at the
intermediate routers. We believe that the hash veriﬁcation based
approach is the more promising approach. Perhaps more study
can be done to identify a suitable cryptographic hash function.
Another approach is to trace the fake content back to its
origin by leveraging the history of each interface on the route.
After successfully detection of the attack origin, a mitigation
mechanism can be orchestrated. For instance, a router may
prevent caching the content chunks that arrive from a suspicious
interface or have the same name preﬁxes as the fake content.
We believe that there is still need for more efﬁcient and scalable
mitigation approaches.

3) Cache Pollution Attack: Cache pollution is divided into
false locality attack in which an attacker tries to change the
locality of the cache by requesting a set of unpopular content
objects, or locality disruption attack in which the attacker
creates fake popularity for unpopular contents. The objective of
these attacks is to degrade cache effectiveness and increase the
content retrieval latency. Some of the proposed approaches [69],
[93], [119] incur high computation cost at the intermediate
routers, which undermines their scalability. Other proposed
mechanisms either only detect the cache pollution attack [39] or
address the less severe malicious provider attack scenario [86].
We believe that the key idea for solving cache pollution
attack is in designing a robust caching mechanism, which
not only increases the resiliency of the cache against these
attacks, but also improves the overall network latency and
users quality of experience. One possible direction is to explore
collaborative caching more. A variety of collaborative caching
schemes have been proposed in the literature with the objective
of improving cache utilization and reducing the latency [114],
[35], [120]. However,
the positive impacts of collaborative
caching mechanisms on mitigating cache pollution attack have
not been explored. With collaborative caching and feedback
between the caches, mechanisms can be designed to contain or
root out cache pollution attack attempts.

4) Secure Naming and Routing: Content naming scheme is
an integral component of ICN, especially for the routing and
security functionalities. Lack of a veriﬁable binding between
the content name and its provider simpliﬁes the orchestration
of the content poisoning attack. Even when the provider’s
signature for the content provides this binding, the high cost
of signature veriﬁcation would prevent intermediate routers

from verifying signature of all arriving packets. Despite some
initial efforts [42], [63], [116], [127] to make content naming
secure, there is still a need for more scalable and computa-
tionally efﬁcient approaches. The identity based cryptographic
approaches [63], [127] require the client to trust a third party for
private key generation; a practice that signiﬁcantly undermines
the applicability of these approaches. A secure and efﬁcient
naming scheme is still an open challenge. Any such scheme
should include metadata, such as the content hash and the
provider’s identity and signature to enhance the security of the
system. This is currently an important area of research with
proposal being made to the ICN Research Group, an Internet
Research Task Force [5].

trafﬁc at

5) Application-Level Security: Different ICN applications
and application-level mechanisms, such as content ﬁltering,
anomaly detection, and covert channel have been proposed in
the literature. Mechanisms proposed in [49], [60], [61], [70]
tried to detect abnormal
the intermediate routers,
spam contents based on the subscribers’ and publishers’ votes,
or performed content ﬁltering through the ﬁrewall. In [30],
[31], [108], the authors proposed ICN inspired architectures
for lighting control systems, Internet of things, and smart grid.
In [123], Yu et al. proposed a chain-of-trust based schema for
content publishers and consumers to use to share content. The
authors in [117] suggested the separation of data and security
planes for better content integrity assurance. Other proposed
applications include ephemeral covert channel communica-
tion [23], secure email service [98], and moderator-controlled
information sharing [26]. We have not found an application that
incorporates all the security functionalities available in ICNs
(any architecture) nor did we ﬁnd a comprehensive application-
level security suite (again any architecture). That should be one
of the interests of future researchers in this domain.

3. PRIVACY IN ICN

In this section, we explore privacy risks in information-
centric networks and the proposed mitigation mechanisms. At
the end of this section, we present the open challenges and
some possible directions them. Attacks against privacy in ICN
may target the caching routers, cached contents, content names,
content signatures, as well as client privacy. These privacy
concerns are inherent to all architectures. Additionally, there
are a few attacks that are possible due to the inherent design
choices of speciﬁc architectures, which we will discussed
separately. We will highlight the vulnerable design choices and
discuss their advantages and disadvantages. Fig. 6 presents a
classiﬁcation of privacy attacks in ICNs, along with the related
work aimed at their mitigation.

Before discussing the privacy state of the art based on
categories we mention one work that covers most of the
categories and hence does not fall into any speciﬁc category.
Fotiou et al. reviewed the proposed ICN architectures and
discussed the requirements and design choices for secure con-
tent naming, advertisement, lookup, and forwarding in [47].
The authors classiﬁed each privacy threat as either a monitor-
ing, decisional interference, or invasion attack. The decisional

interference attack either prevents a consumer to access certain
content, prevents the content advertisement and forwarding
of a speciﬁc provider, or allows content ﬁltering based on
content name. In the invasion attack, an attacker tries to acquire
sensitive information from the target. The authors also analyzed
the identiﬁed threats and ranked them according to the DREAD
model [65], and brieﬂy reviewed ongoing research on privacy
concerns in information-centric networking.

In the ICN paradigm, if we assume that the payload is
encrypted, then the information in a chunk does not identify the
user. However, other mechanisms of trafﬁc analysis can be per-
formed. Based on these mechanisms and knowledge available
at with the attacker several other attacks can be orchestrated.
We categorize these attacks into timing attack, communication
monitoring attack, anonymity, protocol attack, and naming-
signature privacy, and discuss them in what follows.

A. Timing Attack

Timing attack has been explored in a large body of litera-
ture [90], [89], [13], [32], [37]. This attack targets the privacy
of caches and clients that are co-located with the attacker. In
a timing attack, an attacker probes content objects which it
believes are cached at the shared router. The attacker leverages
precise time measurements to distinguish cache hits and cache
misses, and thereby can identify which contents are cached. A
cache hit implies that the content had been requested by another
client in the neighborhood, while a cache miss indicates that
the content has not been requested (or has been evicted from
the cache). An informed attacker can also ascertain whether
the request is served by the provider or by a router somewhere
along the path to the provider. As illustrated in Fig. 7, a shorter
latency of retrieving content C1 in comparison to content C2
reveals the availability of C1 in the shared edge router’s cache.

Fig. 7: Timing attack scenario.

Acs et al. [13] investigated cache privacy in named-data
networks in the presence of timing and cache probing attackers.
The authors conﬁrmed the effectiveness of these attacks in
different network topologies, and demonstrated attack feasibil-
ity even in scenarios where the attacker and the victim are
three hops away from the shared router (success rate of 59%).
They discussed two trafﬁc classes: interactive trafﬁc and content
distribution trafﬁc. For interactive content, the authors proposed
the addition of a random number to the content name, to be
agreed upon by the requester and the content provider. This

C1C2C1TC1<<  TC2ClientClientAttackerEdge  routerContent  routerContent  providerRouterContent  routerRouter?

Timing Attack

[13] [32] [37]
[89] [90]

?

Communication
Monitoring Attack

[32] [74] [75]

Privacy

?

Anonymity

[25] [36] [44]
[46] [52] [104]
[106]

?

Protocol Attack

[32] [74] [75]

?

Naming-Signature
Privacy

[28] [32] [71]
[84] [85] [102]

Fig. 6: Privacy Risks and their Countermeasures.

TABLE VI: Summary of Timing Attack Mitigations

Approach
Mitigating Entity

Acs et al. [13]

Delay for the ﬁrst k interests
Edge routers

Chaabane et al. [32]

Delay for the ﬁrst k interests
Edge routers

Mohaisen et al. [90], [89]

Delay for the ﬁrst interest from each client
Edge routers & access points

prevents the attacker from successfully probing the cache for
this content due to the precise content sufﬁx matching approach
that is employed in the majority of ICN architectures. On the
other hand though, another client requesting the same content
does not have its request satisﬁed even if a cached copy of the
content exists, which undermines efﬁciency due to caching.

As an alternative solution, the authors suggested that the
requester and producer mark privacy-sensitive interests and
content as private. The intermediate routers then prevent the
marked content from being cached, subsequently enhancing the
clients’ privacy. The authors also suggested the emulation of a
cache miss at a router, with the router applying a random delay
before satisfying a content chunk request. However, a delay
undermines user’s quality of experience (QoE). The authors
reduced the impact on QoE by using a popularity threshold.
With this addition,
the router applies a random delay for
interests for a content chunk if the number of interests is below
a predeﬁned threshold k (k may be a uniform or exponential
random variable). After the ﬁrst k requests the router satisﬁes
subsequent interests as soon as possible.

Although this model reduces the latency for popular content
objects, clients experience the extra delay for the ﬁrst k
interests. The basic premise of the model is that that privacy-
sensitive content objects are usually unpopular, and that in-
creased content popularity results in reduction in its privacy.
However, this premise is not universal.

In [90], [89], Mohaisen et al. took a similar approach and
proposed three different variations of a mitigation technique
for the timing attack. In the vanilla approach, an edge router
fetches content chunks from the provider and stores the retrieval
times for the corresponding ﬁrst
interests. The router also
tracks the interest frequency of each requested privacy-sensitive
content chunk. Each ﬁrst interest for a cached content chunk
from a new client (one who has not requested that content
before) will be satisﬁed with a delay same as the recorded
retrieval latency for the chunk. Clearly, the amount of state
that needs to be maintained implies that the vanilla approach

does not scale as the number of clients increases. To reduce the
storage requirements, a second approach was proposed in which
the edge router stores only per-interface interest retrieval time
history. Although this approach reduces state requirements, it
also increases the possibility of timing attacks if an attacker
resides on the interface.

The last variation solved the shortcomings of the ﬁrst two
through cooperation between the access points/proxies and their
corresponding connected edge routers. The access point reduces
the amount of state required at the upstream edge router to store
per-client state, instead requiring the router to store only per-
face statistics. The decision to apply random delay is made by
the router with the help of the downstream access point. The
router always applies a delay to the ﬁrst interest received for
cached content on an interface. The access point also sets a ﬂag
in the interest to indicate to the router that a client is a new
client. Then the router applies the delay for the new client. If
the interest ﬂag is not set the router sends the reply chunk as
soon as it can. We believe that despite the strengths of this
scheme, the use of random delays goes against one of the core
concepts of ICN–leverage caching to reduce latency.

In [32], Chaabane et al. presented several privacy threats
in content-oriented networking, as well as potential counter-
measures. For the timing attack, they also proposed applying
a delay – either on all requests for cached content, or on the
ﬁrst k requests only. They also brieﬂy discussed the possible
use of different caching schemes, such as collaborative caching
and random caching, to preserve cache privacy. Collaborative
caching increases the anonymity set of the clients by increasing
the number of clients that share a set of routers;
thus it
implicitly helps to preserve privacy. However, the authors did
not provide any analysis on the beneﬁts of such an approach.
We believe collaborative caching is a good approach that should
be explored further.

In [37], Compagno et al. proposed a method to geograph-
ically localize a client in named-data networking. To mount
this attack, the attacker must control several hosts (zombies

or bots) scattered throughout the network. These hosts request
content objects that they suspect that a victim(s) may request
with the aim of identifying corresponding cache hits or PIT
hits. Similar to the timing attack, precise time measurements
are important in this attack. Further, the attacker is assumed to
have complete knowledge of the network topology and several
other network properties. And the authors noted that this attack
is only effective when the victim requests unpopular content–
popular content is requested by many and it is difﬁcult to
winnow out one entity from the trafﬁc. Although the study
is interesting, the threat model’s assumptions especially about
complete network knowledge is strong and that practical. Also,
the authors present no countermeasure.

Table VI summarizes the proposed solutions to the timing
attack. We present the referenced work, the proposed solution,
and the entity in the network where the mitigation procedure
is executed. We have not mentioned [37] as the authors have
not really presented a mitigation strategy.

B. Communication Monitoring Attack

In the communication monitoring attack [75], [74], [32],
an attacker is co-located (behind the same edge router) as
the victim, similar to the timing attack. Different from the
timing attack, in this attack, an attacker targets a speciﬁc victim
and tries to learn the content(s) the victim has requested. The
attacker is equipped with some knowledge about the victim,
such as the victim’s content consumption habits or speciﬁc
characteristics, which differentiate the victim from other clients
(e.g., language, region, or institutional afﬁliation).

Chaabane et al. explored attacks against content privacy
in [32]. The authors introduced the monitoring and censorship
attacks, caused by information exposure from caching routers.
To cope with content privacy issues, they discussed a solution
inspired by the current IP network, utilizing secure tunneling
with symmetric/asymmetric encryption (like SSL/TLS). De-
spite the wide applicability and effectiveness of secure tunnel-
ing, it undermines the caching capability of intermediate routers
and consequently increases core network load and content re-
trieval latency. As an alternative solution, the authors proposed
broadcast encryption and proxy re-encryption. This solution
on the other hand introduces signiﬁcant communication and
computational overhead. It is common knowledge that even
with data encryption, monitoring of encrypted communication
can leak information through trafﬁc analysis.

Lauinger et al. [74] proposed two types of request monitoring
attacks under the stationary content popularity model with
a constant request rate, employing non-invasive and invasive
cache probing respectively. The stationary popularity assump-
tion states that the content popularity distribution does not
change over large time periods, and the interest for a content
item is independent of previous interests. In the non-invasive
cache probing model, the authors assumed that the attacker’s
request does not change the router’s cache state. Hence, the
attacker (with prior knowledge of the victim’s content interests)
frequently probes the shared router’s cache. The cache probing

frequency is inversely proportional to the characteristic time for
eviction of a content chunk from the cache [33].

The unrealistic assumptions in the non-invasive model that
the cache probing does not change the content popularity lead
to proposal of the invasive cache probing attack model. In the
invasive model, every cache miss at the shared router causes
the requested content to be cached, hence the attacker needs to
differentiate cache hits from cache misses. To do so, the attacker
must ﬁrst request a known non-cached content and subsequently
send several requests for the same content, thereby learning the
difference in satisfaction time between a locally cached object
and an object retrieved from elsewhere.

To measure the characteristic eviction time of a set of
contents, an attacker ﬁlls up the shared router’s cache by
requesting these contents (by requesting each of them). This
allows the attacker to estimate the characteristic eviction time
and then tune its content probe frequency with the characteristic
time of the content. Then the attacker is ready to probe the
cache for the victim’s content of interest.

The approaches to mitigation of monitoring attacks are very
similar to that of the timing attacks. The authors in [75], [74]
proposed the idea of selective caching, in which a content will
be cached only if it reaches a speciﬁc popularity threshold. This
is congruent with the assumption that privacy risk increases
as content popularity decreases. Alternatively, a client can
ensure privacy by establishing a secure tunnel with either
the content provider or a trusted proxy, as in
[44], [106].
Another potential solution relies on the trustworthiness of the
ISP to honor a client’s request by not caching a content that
is marked as privacy-sensitive by a provider. However, these
approaches are applicable only under assumptions about the
ISP’s trustworthiness and the unpopularity of privacy-sensitive
content, which may not always be valid assumptions in practice.

C. Anonymity

information about

Similar to other networks, anonymous communication is an
important requirement in ICN. Lack of anonymity may reveal
critical
the requesters and the requested
contents, which could be used to enable censorship. Unlike
the current IP network, in ICN the packet carries the name
of the content requested. The name in the interest (be it a
human readable name or a hashed string) can be used by an
intermediate router to ﬁlter and drop the interests. The name
can also be used by the ﬁrst-hop router or proxy to identify
and censor the requesting clients. As it is depicted in Fig. 8,
the adversary (on the path to the content provider) monitors
the client’s interest and compares the requested content name
against its contents’ blacklist for censorship. A match results in
the request being dropped–an effective censorship mechanism.
As we will discuss in this section, the exposure of the content
name, and the semantic binding between the name and the
content itself, raise new privacy and censorship concerns. These
concerns necessitate the creation of mechanisms to allow clients
to interact with the network anonymously, in a way suitable for
private or sensitive communication. Several mechanisms have

been proposed in the literature to address the concerns of lack
of anonymity [25], [44], [36], [52], [106], [104].

Fig. 8: Censorship risk due to lack of anonymity.

Arianfar et al. were one of the ﬁrst to study the problem of
this sort of trafﬁc analysis attack [25]. It is especially important
to prevent this attack for contents that are private. To prevent
an attacker from identifying the interests and the corresponding
contents the authors designed a name obfuscation scheme in
which the content provider uses a secret cover ﬁle–a random
ﬁle of the same size as the content. The provider splits the
content and the cover into same sized blocks and runs an
exclusive-or operation on all combinations of k(≥ 2) blocks of
the content and the cover to create all corresponding encoded
content chunks that are then published into the network. The
name of an encoded chunk is the operation of the hash function
on a hash of the names of the corresponding content and cover
blocks.

Utilizing a secure back channel, the provider sends each
veriﬁed requesting client the necessary metadata such as the
content hash, the content’s length in blocks, the corresponding
cover blocks, the names, and the name generation algorithm.
Using this meta-data the client generates the chunk names,
requests them from the network, and deciphers them. Although
the chunks and their names are publicly available for both
the client and adversary, the adversary cannot decipher the
content without the information received from the provider. It
is computationally very expensive for an adversary to break the
scheme to decipher the chunk names.

Considering that each k-tuple chunk is generated from n
content and cover blocks, the attacker possessing a chunk needs
to compute all possible 2n choose k chunk names of a given
chunk to ﬁnd a match and extract its blocks. Unfortunately, the
size overhead of the scheme is signiﬁcant. The cover ﬁle itself
results in a 100% overhead, and the requirement of a secure
back channel for each client undermines the scalability of this
approach. For instance, why not even send the content over the
back channel, given that the channel is used to transmit more
bits than the size of the content? This concern has not been
identiﬁed by the authors.

ANDaNA [44], a tunneling-based anti-censorship protocol,
uses two proxies to create a tunnel with two layers of encryp-
tion: one proxy adjacent to the requester, and another proxy
closer to the destination. By using ANDaNA, a client decouples
its identity from its request. The ﬁrst proxy is only aware of the
client’s identity (but not the content name), while the second
proxy only has knowledge of the requested content (but not

the client’s identity). The interest travels unencrypted between
the second proxy and the provider. The authors proposed an
asymmetric version of the protocol where the client encrypts
the interest packets with the public keys of the two proxies,
and the proxies use their corresponding private keys to decrypt
the content. The content chunk on the way back is encrypted
by a symmetric key shared by each proxy with the client to
create two layers of encryption.

Due to the computational complexity of the PKI operations,
the authors proposed a symmetric key based session-key model
where the PKI encryptions are replaced by ephemeral session
keys in both directions (interest and content chunk propaga-
tion). Despite ANDaNA’s usefulness as an anti-censorship tool,
it induces signiﬁcant delays to content delivery (ref. results
in [44]) in comparison to Tor (the Onion Routing protocol – the
popular anti-censorship tool for IP networks). These delays are
caused, in part, by the process of setting up the secure channel.
In [36], Chung et al. took a similar approach to ANDaNA
and Tor. In this approach,
the client encrypts the interest
packet with two symmetric keys that will be shared with two
Anonymous Routers (ARs). The interest’s encryption order
follows the onion routing model. Different from conventional
onion routing, an identiﬁer (a hash of the content name) is
embedded in the encrypted interest to enable cache utilization
(i.e., CS-lookup) and interest aggregation (PIT lookup) at the
ﬁrst AR. The provider transmits the content to the closest
(second) AR in plaintext. The content response on the way
back may be cached on the ﬁrst AR it hits, which encrypts the
content and forwards it to the AR closer (ﬁrst AR) to the client.
The ﬁrst AR receives the content and decrypts it for caching
before re-encrypting it and forwarding it towards the client.

Similar to ANDaNA, this scheme suffers from the same
high cost of multiple encryptions per-packet. Considering the
number of chunks per content in ICN, the overall cost of
content encryption makes this scheme not scalable. Also, the
use of this scheme will cause signiﬁcant overhead due to the
multiple encryption/decryption operations, which will prevent
communication at line speed.

Fotiou et al. [52] proposed a mechanism to preserve content
lookup privacy by leveraging homomorphic cryptography [45].
The scheme involves cooperation between providers, clients,
and a hierarchical brokering system. The brokering system is
a tree of brokering nodes. A provider publishes its content
identiﬁer to the brokering system, which disseminates the
identiﬁer-provider pair to the leaf brokering nodes. To locate a
content, a client submits an encrypted query to the root broker
node. By employing homomorphic cryptography,
the query
can be resolved by the brokering system without decryption.
When the content is found, the client will be sent an encrypted
response containing a pointer to the desired content provider.
In this scheme, a query includes a vector of sub-queries
corresponding to the nodes in the brokering system. Each
broker uses its sub-query part
to forward the query to its
children;
the leaf node with a
pointer to the content provider is identiﬁed. A big pitfall of the
proposed mechanism is the number of decryption operations

this is done recursively till

Content  Name:  /facebook.comBlacklist:/facebook.com/Youtube.comClientClientContent  routerContent  routerContent  providerRouterRouterAttackerTABLE VII: Anonymous Communication
Approach

Infrastructure
Not Applicable

Requires three new entities

Mechanism
Arianfar et al. [25]
Elabidi et al. [46]
Chung et al. [36]
DiBenedetto et al. [44]
Fotiou et al. [52]
Tao et al. [104]
Tourani et al. [106]

Encoding interest by mixing content and cover ﬁle

Ephemeral identities for users

TOR based model – 2 layers of encryption
TOR based model – 2 layers of encryption
Hierarchical DNS based brokering model
Random linear network encoded interest

Huffman encoded interest

Two Proxies
Two Proxies

One Proxy
One Proxy

Computation Complexity
High (cover & exclusive-or)
High (several interactions)
Moderate (symmetric key)
Moderate (symmetric key)

Moderate (RLNC + PKI)
Low (Huffman coding)

Brokering Network

High (homomorphic cryptography)

that a client needs to perform per query, that is, 2h−1, where
h is the height of the tree hierarchy. In addition, considering
the number of messages transmitted per query, the scalability
of the system in the face of an increasing number of clients
and content objects is difﬁcult.

Tourani et al. [106] addressed the ICN censorship problem,
by proposing a client anonymity framework that
leverages
the preﬁx-free coding technique. In their proposed design,
each client shares a unique Huffman coding table with an
anonymizer, which may be co-located with the content provider
or an intermediate trusted router. The client encodes the content
chunk’s name postﬁx (part of the name after the domain name)
using its Huffman coding table, leaving the domain name in
plaintext, to be used for routing. The authors also proposed
ways to encode the whole name (when the domain is also
censored) by routing the completed encoded name to an an
uncensored entity that serves as a forwarder (anonymizer).
When an encoded interest reaches the anonymizer, the name
is decoded and the interest with the unencrypted name is
forwarded to the content provider. The content provider sends
the content chunk in open to the anonymizer (caching can be
leveraged here). The anonymizer encrypts the received content
chunk and forwards it to the client under the original encoded
name. The encoding of the name and encryption of the payload
prevent the routers between the client and the anonymizer from
inferring any information about the content.

they cannot

Although the routers between the anonymizer and the
provider can identify the content
identify the
requester preserving client privacy. The authors demonstrate
that their approach is three orders of magnitude faster than
AES encryption, is much more efﬁcient than other proposed
approaches, and provides a higher guessing entropy, thereby
making the brute-force attack very hard. The paper did not
have a trade-off analysis between cache utilization and privacy
preservation, and the authors did not discuss the scope of
potential differential cryptanalysis attacks. However, it is one
of the approaches with the least overhead and the requests can
be made at line-speed.

Tao et al. [104] proposed a network coding based mecha-
nism for anonymous communication in named-data networking.
The proposed mechanism leverages ICN’s inherent content
chunking in conjunction with random linear network coding
(RLNC). To request a content chunk,
the client splits the
interest into small chunks and encrypts a linear combination
of the chunks with the public key of an intermediate trusted
proxy. The proxy, after receiving enough interest chunks,

reconstructs the original interest packet and sends it toward
the content provider. The content provider follows the same
approach as the client, splitting the content into small chunks
and forwarding a linear combination of them towards the proxy.
The two major concerns of this proposed scheme are a lack of
cache utilization and the high cost of many asymmetric-key
cryptographic operations.

Elabidi et al. [46] proposed a privacy protection scheme
for CCN which enforces identity expiration. The system in-
volves identity providers, trust veriﬁcation providers, and digital
identity protection authorities in addition to the standard CCN
network elements. The scheme provides users with ephemeral
identiﬁers, which they communicate to the service providers.
The service providers authenticate the users through a trust
veriﬁcation provider. The trust veriﬁcation provider is capable
of informing a digital identity protection authority when an
ephemeral identity is used after its expiration time. Though this
design provides the useful “forgetfulness” property, a malicious
service provider could disable access or ﬁlter requests from
users by corrupting the ephemeral identities and preventing
access to clients. There are several other issues with this
scheme including the requirement of authentication of users by
a third-party service, which raises concerns of overhead and
availability.

Table VII summarizes the existing anonymous communica-
tion mechanisms and presents their infrastructure requirements
and computation complexities.

D. Discovery and Protocol Attacks

Discovery and protocol attacks are a result of intrinsic design
features of particular ICN architectures. Some examples of
these critical features are the interest packet scope ﬁeld and
the preﬁx-based matching paradigm used in NDN and earlier
versions of CCN (latest versions of CCN mandate exact name
lookup). Fig. 9 illustrates a discovery attack,
in which an
attacker probes all caches in a two-hop locality for content with
preﬁxes /ICN and /NDN. In this subsection, we review two of
the articles that addressed the pitfalls of these design features.
The authors in [75], [74] introduced an object-discovery
attack, which abuses NDN’s [2] preﬁx matching and exclusion
pattern features. The attacker employs the preﬁx matching
feature to probe for all cached content objects under a particular
name preﬁx. The attacker can start at the root of a namespace,
say /www.google.com/ and explore the namespace iteratively by
sending out requests with exclusions and forcing intermediate
routers to walk through the namespace with each interest.

To establish a conversation between two entities, each should
be authenticated by their corresponding DTEs. For two parties
to establish a communication channel, the ﬁrst party authen-
ticates to the DTEs and submits a query seeking the other.
The query will be processed by the DTE infrastructure and the
other party’s identiﬁer is returned. This identiﬁer is used to
establish a tunnel through the DTEs, which the two parties can
then use to exchange messages. Although this overlay network
preserves the entities’ identities, the security of the network in
the presence of compromised DTEs needs to be investigated,
and again this requires a core network infrastructure consisting
of DTEs.

Sollins [102] discussed the design issues of ICN naming
systems and proposed an overlay system for content identi-
ﬁcation. The important factors in a naming system include
the scope of the ID space (local, global), the ID syntax (size,
structure, character set), and the ID structure (ﬂat, hierarchical,
composite). In addition, identiﬁer-object mapping requires the
existence of a naming authority and enforcement of ID lifetime
and uniqueness. The choice of the naming system may neces-
sitate a resolution system; if it is required, the resolution scope
and timing also need to be considered.

The authors noted that hash-based naming is only useful
for read-only, cacheable data objects. Additionally,
the use
of the catalog to obtain self-verifying names requires the
establishment of trust between clients and the catalog publisher,
which requires creation of trusted infrastructure in the network
and may result in signiﬁcant maintenance overhead.

Martinez et al. [85], [84] proposed the use of an overlay net-
work for privacy and untraceability in content-centric networks
using digital identities. Each network entity (users, machines,
services, hardware) is associated with a digital identity and
a domain. Each domain is equipped with a special element
called the Domain Trusted Entity (DTE), which manages entity-
identiﬁer associations and identiﬁer authentication, and guaran-
tees that each identiﬁer corresponds to a legitimate entity. The
DTEs interconnect to form an infrastructure which facilitates
identity-based communication among all entities.

Sollins designed an identiﬁcation system, Pervasive Persis-
tent Object ID (PPOID), based on the principles of layering
and modularity. The author suggested that the identiﬁcation
system layer (PPInS) is compatible with any ICN architecture.
In the PPInS layer, a human-readable identiﬁer is mapped to
an ID space and resolved to an ICN identiﬁer from that ID
space. Layering is reﬂected in the use of simple and expressive
user-friendly identiﬁers at the top layer, followed by machine-
readable identiﬁers for real-time resolution and delivery at the
bottom layer. Unfortunately, the author did not present any case
study on the applicability of this naming system to existing
popular ICN architectures; especially from the perspective of
delay incurred in ﬁnding and mapping an object name to an
identiﬁer and vice versa.

Chaabane et al. in [32] discussed the exposure of informa-
tion through content names and signatures. From the authors’
perspective, the semantic correlation between human-readable
names and content/provider raises privacy concerns. They sug-

Fig. 9: Protocol attack scenario.

Using the exclusion feature an attacker can discover the whole
namespace (quickly for small namespaces) and also the names
of cached content (additional monitoring attacks).

Chaabane et al. [32] also deﬁned two protocol attacks,
based on preﬁx-based matching and scoping respectively.
The preﬁx-based matching attack works as described by
Lauinger et al. [74]. In the scoping attack, an attacker probes
all the available content objects in nearby caches by leveraging
the scope ﬁeld in the interest packet. By carefully selecting
the scope value, the attacker can identify the content available
in individual routers, thereby breaching the privacy of other
clients.

Unfortunately, no solution has been proposed for these at-
tacks except for the removal of the enabling features. However,
the preﬁx-matching feature is useful for legitimate clients with
limited knowledge of their desired content name (e.g., when
only a preﬁx of the content name is known). The scope ﬁeld
can also be employed by a legitimate client who would like to
obtain a content only in the case that it is available in a nearby
cache. Therefore,
these features should not be completely
eliminated from ICN, but instead should be redesigned with
these threats in consideration.

E. Name and Signature Privacy

Unlike the current Internet, several ICN architectures require
the content to be explicitly requested by name. In ICN, names
either follow a hierarchical human-readable or a self-certifying
ﬂat-name model. We refer readers to a survey on ICN naming
and routing [27] for more details. In the human-readable nam-
ing convention, the content name exposes information about the
content and the provider due to the inherent semantic binding.
In what follows, we review two different perspectives on this
type of information leakage.

Cryptographic hash based naming in ICN was motivated by
Baugher et al. [28]. The main advantage of such self-verifying
names (names are cryptographic hash of the content) is that they
reduce the cost of content authentication. Such schemes require
that the client obtain the content’s (or chunk’s) self-verifying
name from a catalog that maps contents from their human-
readable names to their hashes. Upon obtaining a response from
the catalog, the client stores the hashed name in a manifest
for future use and submits a request for the hashed name
into the network. The client accepts the retrieved content if
its cryptographic hash matches the self-verifying name from
the catalog. This also preserves the privacy of the provider.

/ICN/C1/ICN/C2/NDN/N1/NDN/N2/CCN/Z1/ICN/C1/ICN/C5/NDN/N2/NDN/N3/CCN/Z4/ICN/C1/ICN/C2/ICN/C5/NDN/N1/NDN/N2/NDN/N3ClientClientAttackerContent  routerContent  routerEdge  routerRouterRouterContent  providergested the use of a Bloom ﬁlter, a probabilistic hash-based
data structure, to represent names without correlation to the
content. Under a hierarchically structured content namespace,
one Bloom ﬁlter is dedicated to each name component.

Digital signatures play an important role in ICN trust models,
as content are not bound to the provider’s location as they are
in IP networks. Despite the beneﬁts of digital signatures, more
attention must be given to their leakage of information about
the content provider. To protect publisher privacy, the authors
proposed different schemes such as conﬁrmer signature, group
signature, ring signature, and ephemeral identity. All of these
solutions, except ephemeral identity, achieve signature privacy
by increasing the cardinality of the anonymity-set of signers.
Under ephemeral identity, different temporary identities used by
a publisher prevent an attacker from identifying the publisher
based on its signature. However, the probabilistic nature of
Bloom ﬁlter and its inherent false-positive probability might
result
in false routing and incorrect content chunk-interest
mapping. This may result in the wrong content being served
for an interest. Furthermore, the size of the Bloom ﬁlters could
be large and the lookup latency increases with the number of
levels in the hierarchy, which in itself is dynamic. These factors
affect scalability.

Katsaros et al. investigated content-name information expo-
sure from a new perspective in [71]. Service type, ownership,
caching properties, service class, scope, and content format are
among the characteristics that can be exposed by content iden-
tiﬁers. However, these exposed characteristics do not reveal any
information about content popularity or access statistics, which
are important to content providers (e.g., Amazon, Google).
A naive solution proposed by the authors suggested the use
of ephemeral names that are controlled by providers. These
ephemeral names change throughout time, forcing clients to
contact the provider; hence, the provider is able to obtain access
statistics about its content.

The authors noted that a content provider must select the
appropriate service type, service class, content format, and
ephemeral names’ lifetime in order to optimize quality-of-
service. Furthermore, a trusted authority or PKI is required
to validate the identity of the provider and authenticate the
ephemeral names. In this scheme, for better client QoE some
metadata information, such as service types, service classes,
content format, need to be added to each packet. This results
in an increase in the header size and also variability in header
size–an overhead that needs to be optimized to reduce process-
ing delay.

Despite the beneﬁts of using ephemeral names for content
providers, temporary naming undermines the network’s caching
capability. Contents with ephemeral names will expire and will
be purged from the caches, hence they will not be available to
meet clients’ requests; this is especially true for popular content.

F. Summary and Future Research

In this section we explored the existing work in ICN privacy,
with focus on content, cache, naming and client privacy. We

conclude by summarizing the shortcomings of the proposed
solutions and giving some hints on potential directions for
further exploration.

1) Timing Attack: The majority of the proposed timing
attack mitigation mechanisms [13], [32], [89], [90] apply an
artiﬁcial delay during content forwarding. Despite the effective-
ness of this approach in misleading the adversary, it undermines
one of the most important advantages of information-centric
networks: low-latency communication based on caching. An-
other negative impact of this approach is degradation in clients’
QoE, especially for the popular content objects. We believe that
there is need for approaching the problem from another angle.
One natural approach of coping with timing attack is design-
ing a sophisticated collaborative caching mechanism, which not
only increases the anonymity set of the clients but also improves
system performance and reduces retrieval latency for content
that are not present in the edge router’s cache. Moreover, this
precludes the need for artiﬁcial delays. Chaabane et al. [32]
have made an initial attempt in this direction. Network coding
techniques can also be leveraged to design a secure and efﬁcient
content dissemination model, where each content chunk is
stored at a different router.

2) Communication Monitoring Attack: Solutions to this at-
tack aim to prevent sensitive content from being cached, either
by creating a secure tunnel [44], [106] or by ﬂagging the re-
quests. We believe that undermining ICN’s caching capabilities
is not a proper solution, as it increases communication com-
plexity and cost. In addition, these client-driven solutions [74],
[75] only depend on the clients’ decisions. Therefore, a greedy
client may ﬂag all its communication as sensitive, or establish
a secure tunnel for each of its ﬂows, and thereby create much
unnecessary load in the network.

Although we agree that secure tunneling is a viable approach,
we believe an efﬁcient tunneling mechanism should be designed
which at least allows partial content caching. Another direction
to research is naming scheme randomization [25], which would
make content-name prediction difﬁcult for attackers. With the
proposal of manifests in NDN and CCN, the manifest for a
name can contain encrypted information on how to request the
random chunks, which only a legitimate client can decrypt. The
requirement of decryption will also serve as an attack deterrent
in general. Strengthening the vulnerable architectural features,
such as scope, exclusion, and preﬁx matching would also help
reduce the attack scenarios for the affected schemes, of course,
at the expense of efﬁciencies resulting from these features.

3) Anonymity: Some of

the existing anonymity solu-
tions [44], [36], [104], [106], have achieved anonymous com-
munication through secure tunneling, where the content
is
encrypted between the providers/proxy and clients. Other ap-
proaches include a name obfuscation scheme [25] and a
hierarchical brokering network [47] for anonymous content
retrieval. Expensive cryptographic operations [25], [44], [36],
requirement for a secure back channel [25], and undermining
of in-network caching [44], [104], [106] are the main pitfalls
of these mechanisms.

There are some potential directions for future research on

cache utilization optimization and reduction in the cost of
cryptographic operations. Applying cryptographic operations
on a subset of content chunks to reduce cost has not yet
been explored. Exploiting low-complexity network coding tech-
niques [104], [106] instead of traditional cryptography would
be a good idea to expand the applicability of tunneling schemes.
This is especially important given that the majority of devices
we use in the future will be resource-constrained devices (e.g.,
mobile devices, Internet of Things, etc.).

4) Discovery and Protocol Attack: The use of preﬁx match-
ing, exclusions, and the scope ﬁeld are examples of some
features that an attacker can exploit in the ICN architectures
to probe for popular content objects and their location in the
network and also to explore the content namespace. We believe
that there is a need for a comprehensive analysis, both analytical
and experimental, of these features to identify the trade-offs of
the advantages and disadvantages from these features.

5) Name and Signature Privacy: The human-readable nam-
ing convention exposes information about the content, due to
the semantical binding between the content and its name, in
contrast to the self-certifying naming model which prevents
this information leakage. The proposed approaches for secure
naming include overlay-based network [85], [84], [102], self-
verifying names [28], and hierarchical Bloom ﬁlter base nam-
ing [32]. The drawbacks of the overlay-based models is their
dependency on trusted entities for identity validation and com-
munication establishment and additional latency for resolving
content names. The proposed hierarchical Bloom ﬁlter naming
approach [32], suffers from false positives, which becomes a
scalability issue when the number of components that make
the name increase. The self-verifying naming approach [28] is
only applicable to read-only content. Furthermore, this scheme
is not applicable to the dynamic contents, which are generated
upon the content requests, as no catalog can be generated for
this type of contents ahead of time.

We believe one efﬁcient approach in this context could be for
the provider and the user to cloak their identities with several
certiﬁcates. This is similar to the k-anonymity mechanism used
to increase the size of the anonymity-set. However, efﬁcient
mechanisms need to be designed for this.

4. ACCESS CONTROL IN ICN

In this section, we explore the proposed access control
enforcement mechanisms for ICNs. Access control manage-
ment assumes more importance in ICN security due to the
unique characteristics of ICN, such as name based routing
and in-network caching. In ICN, content providers run the
risk of losing control over who accesses their content once
it is disseminated into the network. Content objects can be
cached at intermediate routers, and these routers will satisfy
corresponding interests with the objects, irrespective of whether
the request is from an authorized or an unauthorized user.
Access control in ICN has received attention of researchers.
As depicted in Fig. 10, existing works may be categorized into
encryption-based, attribute-based, identity-based, and session-

based approaches. We discuss these categories in more details
in what follows.

A. Encryption-Based Access Control

A secure content delivery framework, which waives the
necessity of an online authentication service was proposed
by Misra et al. [87], [88]. The proposed mechanism takes
advantage of Shamir’s secret sharing and broadcast encryption
to enforce access control for clients. The framework neither
requires an additional authorization entity in the network nor
incurs extra computational overhead at
the routers. In the
initialization phase, a provider generates a degree-t (revocation
threshold) polynomial and evaluates n coordinates (assuming
n clients) on the polynomial. The clients need to perform
a one-time registration process at the provider. At that time,
each client is assigned a unique evaluated coordinate of the
polynomial deﬁned as the client-share. For secure content
delivery, the provider encrypts the content with a symmetric
key (the constant of the polynomial) and disseminates the
content into the network. In addition, the provider generates
and disseminates a pieces of metadata called the enabling block
(EB), which provides partial knowledge of the polynomial (t−1
public shares) to the clients. The EB is requested by the client
along with the content, and is cacheable.

An authorized client uses the information in the EB and its
client-share to perform polynomial interpolation and extract
the symmetric key, which it uses to decrypt
the content.
Unauthorized clients, without a client-share, cannot perform
the interpolation and thus cannot extract the symmetric key.
Client revocation is achieved by updating the EB by the
replacement of one of the public shares with the revoked client’s
share, which disables the revoked client from decrypting the
symmetric key. This prevents signiﬁcant system re-keying in
the event of a revocation. In this mechanism, the EB is an
overhead (minor for large contents, but signiﬁcant for small
ones). The EB update on client revocation also consumes
system bandwidth.

Chen et al. proposed an encryption-based access control
mechanism augmented by a probabilistic structure in [34].
Publishers and clients are equipped with public-private key-
pairs, and each client initially subscribes to a publisher by
sending an interest. The publisher stores a record for each
registered client, noting the client’s credentials such as its public
key and digest. To circumvent the expensive asymmetric cryp-
tography, the authors suggested the use of PKI bootstrapped
symmetric key exchange between the publisher and the client.
When a client requests a content, the content is delivered in
encrypted form. Upon receiving the content, the client needs to
authenticate itself to securely obtain the symmetric decryption
key (encrypted using the client’s public key) from the publisher.
The authors augmented their mechanism by storing the au-
thorized clients’ public keys in the form of a Bloom ﬁlter, which
may be transmitted to network routers to allow them to pre-ﬁlter
invalid requests. The routers ﬁlter clients based on their public
keys; the interest of a client whose public key is not indexable

Access Control

?

?

?

Encryption-Based

Attribute-Based

[24] [34] [87]
[88]

[18] [40] [62]
[64] [66] [76]
[77] [94]

Session-Based

[96] [97] [115]

?

Proxy
Re-Encryption

[82] [118] [128]

?

Miscellaneous

[48] [56] [78]
[101] [103]

Fig. 10: A classiﬁcation of existing access control enforcement mechanisms.

in the content’s Bloom ﬁlter is dropped. This procedure also
reduces network load. The approach has two drawbacks: First,
Bloom ﬁlter’s suffer from false positives, which implies that an
unauthorized client’s request has a ﬁnite probability of being
satisﬁed. Second, is the need for authentication of the client
at the publisher to obtain the symmetric key. This requires an
always-online entity in the network to verify client credentials,
which is difﬁcult to guarantee.

Kurihara et al.

[24] proposed an access control framework
for content-centric networking (CCN). This framework utilizes
CCN’s new manifest feature, and can leverage other proposed
mechanisms, such as group-based and broadcast-based access
control. The entities in the framework are content providers,
clients, an encryption and dissemination server, a key manager,
and an access policy manager. The key manager generates a
symmetric key (nonce key) for content encryption and sends
it to the encryption and dissemination server, which performs
content encryption and dissemination. The nonce key is then
encrypted by another encryption algorithm depending on the
underlying access control structure, e.g., broadcast encryption,
attribute-based encryption, or session-based encryption. Decap-
sulation key, the key that is required to decrypt the nonce
key, is then encrypted by the access policy manager under the
authorized client’s public key and published into the network.
For content retrieval, an authorized client (authorization
happens at the content provider using the client’s credentials)
downloads the encrypted content and use the content manifest
to locate the decapsulation key. This manifest includes the
access control speciﬁcation ﬁeld (ACS), which speciﬁes the
encryption algorithm (such as AES or 3DES) and other nec-
essary access control conﬁguration (e.g., additional parameters
for decryption, or which access control scheme to use). After
obtaining the encrypted key, the client can decrypt it, and
subsequently decrypt the content. The authors suggested using
lazy revocation, which would allow revoked clients access to
previously published content unless it is re-encrypted and re-
disseminated, which requires a signiﬁcant overload.

Other than the scheme proposed by Misra et al. [87], [88], all
other schemes are not amenable to low-cost client revocation,
requiring either an online authority or content re-encryption,
impedes their scalability.

B. Attribute-Based and Identity-Based Access Control

Ion et al. [66] proposed an attributed-based encryption (ABE)
mechanism for access control enforcement. The authors pre-
sented a key-policy and a ciphertext-policy based encryption
models. In the key-policy model, the content is encrypted with
a key derived from the content attributes, and the access policy
is embedded in the decryption key. A key authority grants
different decryption keys to clients, based on their attributes and
access policies. For a client to be able to decrypt the content,
its decryption key needs to have the attributes required by the
embedded access policy.

In the ciphertext-policy model,

the access control policy
contains the required client attributes and is attached to the
encrypted content. The key authority issues a key for each
client,
in this case derived from the client’s attributes. A
client can decrypt the encrypted content if its attributes are
included in the access control policy. Attribute and identity
based encryption mechanisms suffer from elaborate revocation
procedures. The authors did not describe the process of client
revocation, and did not analyzed the performance and efﬁciency
of the proposed scheme, especially in the face of revocation.
Hamdane et al. [64] discussed the NDN access control prob-
lem and proposed an identity-based cryptography access control
system. In this scheme, content names have a hierarchical tree-
based structure in which the entire sub-tree of a parent node
inherits the access control policy of the parent node. In order
to control the access to a sub-tree’s content, the root of the
sub-tree, is assigned an encryption/decryption key pair and
a symmetric content encryption key. The symmetric key is
encrypted under the root node’s encryption key. To give an
entity read access on a content, the root decryption key is
encrypted using the authorized entities’ public keys.

the symmetric key to decrypt

Upon successful authorization, the entity retrieves the sym-
metric key that is encrypted using the root’s encryption key.
By obtaining the root’s decryption key, the authorized entity
can extract
the content. An
entity with write access to a content must also have access
to the root’s encryption key. For this reason, the access control
manager encrypts the root’s encryption key with the authorized
entity’s public key. Following successful authorization,
the
entity retrieves the root’s encryption key, and hence can edit

the content.

The access control list (ACL) functionality has been omitted
from the scheme to reduce its cost. However, a lazy en-
tity revocation is possible which requires the root’s encryp-
tion/decryption key pair to be updated. Although this revocation
prevents a revoked client to access the newly published content,
it still has access to the contents that have been published
before its revocation. The old decryption key needs to be
encrypted with the new key, so that all
legitimate entities
may access previously published content. Considering that this
procedure creates a chain of encrypted keys, each revocation
makes content access more expensive.
To overcome the above drawback,

the authors proposed
a credential and encryption-based access control mechanism
in [62]. The proposed mechanism introduces an access control
manager (ACM), which possesses the root key for a namespace
and deﬁnes and enforces access control policies over it. Clients
are given read and write capabilities so they can publish
content and/or request content from the network. To publish
a content, a node queries the repository to check whether the
target namespace is subject to an access control policy. In
the case that the name is protected, the publisher forwards its
credentials, signed with its private key to the ACM, and requests
an encryption and decryption key pair. The ACM returns the
encryption and decryption keys if the publisher is granted the
required permissions by the namespace’s policy. The publisher
encrypts the content with a generated a symmetric key and
encrypts the symmetric key with the encryption key sent by
the ACM. The publisher sends the encrypted content and the
encrypted key to the repository to be cached.

When a client requests the content, the encrypted data will
then
be delivered along with the access policy. The client
forwards its credentials to the ACM and retrieves the decryption
if its credentials satisfy the access policy. The client
key,
uses the decryption key to extract
the symmetric key and
decrypt the content. Unfortunately, the authors neglected the
client revocation problem. If a client that has access to several
decryption keys is revoked, it can still keep using the keys. To
revoke it, all the corresponding publisher contents need to be re-
keyed. Also, the authors do not mention how the ACM veriﬁes
if a client is revoked or not and who performs the revocation.
Li et al. [76], [77] used attribute-based encryption for ac-
cess control enforcement in ICN. In the proposed scheme, a
trusted third party deﬁnes and manages the subject and object
attributes. This entity speciﬁes an attribute ontology (ontology
in this context is the universe of all attributes), which deﬁnes
the set of attributes that a publisher needs to deﬁne an access
control policy. Due to the fact that cached contents in ICN are
available to all users, to prevent access to unauthorized clients,
the authors proposed a naming scheme, which preserves the
privacy of the access control policy.

To publish a content, the publisher generates a random sym-
metric key with which it encrypts the content. The encrypted
content, along with its corresponding metadata, is disseminated
into the network. The publisher also generates an access control
policy from the attributes deﬁned by the trusted third party;

the access policy then deﬁnes which clients are authorized to
access the content. The publisher uses the access control policy
to encrypt
the symmetric key, which encrypts the content.
This encrypted symmetric key is then used as the content
name. A client needs to retrieve the content name and extract
the symmetric key using its attributes (only possible by an
authorized client).

Despite its low overhead, the applicability of this scheme is
questionable due to the proposed naming scheme; the content
name is generated by encrypting the symmetric key with the
access control policy. This naming scheme is in contrast to
the spirit of immutable naming in ICN. Compromise of the
symmetric key would necessitate re-keying and hence change
the content name. Another concern is that client revocation has
not been discussed.

Aiash et al. [18] proposed an identity-based access control
mechanism for NetInf. This mechanism involves two steps,
namely the registration and the authorization stages. In the
registration stage, all clients and publishers share their public
keys (i.e., identities) with the name resolution service (NRS).
Upon a client’s authentication, the NRS generates a sub-token
(subscriber token) and encrypts it with the client’s public key.
To retrieve a content, a client retrieves both its (encrypted) token
and a pointer to the content object from the NRS. The NRS
replies with the identity of the publisher, and the client may
use its token to request the data from the publisher.

Upon receiving a request from the client, the publisher ﬁrst
queries the NRS to verify the authenticity of the sub-token.
After token authentication, the publisher sends a challenge to
the client to verify its identity. After authenticating the client,
the publisher veriﬁes the client’s token against the content
token, and if the client is authorized to access the content it
returns the content.

The main drawback of the proposed scheme is the commu-
nication overhead introduced by both frequent queries to the
NRS to verify tokens and the challenge-response interaction
between the client and the publisher. Furthermore, the setup
of this mechanism is somewhat strange. The publisher should
ultimately have authority over access to its content, but here
the NRS does access control.

Da Silva et al. [40] proposed an access control mechanism
using attribute-based encryption for instantaneous access re-
vocation. The authors suggested the use of Ciphertext-policy
ABE,
in which the access policy is embedded inside the
encrypted content. The encrypted content is composed of a con-
tent part, encrypted with the required authorization attributes,
which are stored in content routers, and an access policy part,
which is stored at a proxy. The second part of the encrypted
content, access policy, can only be decrypted by the proxy.

When the client registers with the application, it receives a
key (based on its attributes) and an ID. For content retrieval, the
client sends two interests: the ﬁrst one retrieves the encrypted
content (either from the publisher or a cache), and the second,
which includes the client ID and the content name, is sent to the
proxy to decrypt the access policy. The proxy authenticates the
client and decrypts the access policy on the client’s behalf; this

decrypted policy is forwarded back to the client without being
cached in the network. The client can decrypt the content if its
attributes satisfy the access policy retrieved from the proxy.

In order to perform immediate revocation, the publisher noti-
ﬁes its proxy of each revoked client. Because each client should
be authenticated by the proxy for access policy decryption,
the proxy can deny access to the revoked clients. The main
drawback of this mechanism is its requirement for the third-
party authentication and the need for the proxy (a single point
of failure) to be always online.

Raykova et al. [94] proposed an access control mechanism
for publish/subscribe networks, also leveraging attribute-based
encryption. Following ICN’s principle, this mechanism assures
data integrity through owner’s signature of the content. How-
ever, due to the lack of a trusted root server/authority in ICN,
the authors proposed the use of distributed trust authorities,
which play the roles of certiﬁcate and authorization authorities.
Before publishing a content, a publisher protects the payload
using the ciphertext-policy ABE. Only a subscriber with the
required attributes may decrypt
the ciphertext. For content
routing in publish/subscribe networks, broker nodes must match
the published content to the subscriber’s interest. However, this
matching process leaks some information such as the requested
content name and the requester’s subscription.

To limit this information exposure and preserve subscribers’
privacy, the authors suggested using a unique hashing function
to hash interests and content tags. These brokers may then use
these hashed values instead of the raw interests and content
tags. To limit the authorized brokers’ access to these values, the
hashed values are also protected using ABE. Despite the high
level of security provided by this mechanism, the overhead of
interest hashing and the corresponding per-hop hash matching
procedure increase content retrieval latency.

C. Session-Based Access Control

Renault et al. [96], [97] proposed a session-based access
control mechanism for NetInf. This mechanism is built on
the assumptions of no trusted third party, no storage of user
identities, and the reliability of NetInf. In principle, this mecha-
nism requires a security controller, collocated with each content
storage node, to check the access rights of clients. In the key
management step, a client and the security controller establish
a secure channel and exchange public keys. Due to the lack of
a trusted third party, the key exchange procedure is performed
using a technique such as Difﬁe-Hellman.

In the operation step, the client requests a content using the
content ID and its own public key (the public key may be omit-
ted for publicly available content). Upon receiving a client’s
request, the security controller performs a challenge-response
procedure with the client to verify the client’s identity. Upon
veriﬁcation, the controller checks that the client is authorized
to access the content and forwards the data if it is. It is notable
that all these interactions take place in a secure session; the
session ends if either party explicitly requests its termination.
The main drawbacks of this scheme are undermining caching
and the requirement for the security controller to maintain a se-

cure session with each client for the whole duration of activity.
The authors discussed the security of this mechanism against
several well-known attacks, however they did not disclose the
potential for DoS/DDoS attack. A client can open one/more idle
connections and block resources that cannot be used. Also, this
connection-oriented set-up is anti-thetical to the connectionless
ICN paradigm. Furthermore, client revocation has not been
discussed.

Wang et al. [115] designed a session-based access con-
trol mechanism inspired by the session-based access control
schemes presently employed in IP networks. The authors il-
lustrated their design using the example of an online social
network (OSN). The mechanism had four main phases: user
registration, user authentication, content uploading and sharing,
and shared content access control. A user registers in the
OSN (content provider) by sharing a symmetric key and its
credentials. Upon registration, the OSN provides a unique ID
for the user. The client, in order to interact with the OSN, needs
to log into the network. Hence, it generates a new key and sends
it to the OSN along with the login information. The OSN then
assigns a session ID to the client and stores a tuple consisting
of the session ID, the client ID, and the symmetric key.

To upload a content object, a user must be authorized
by the OSN to publish ﬁrst. After authorization, the client
encrypts the content with the previously obtained symmetric
key, then forwards it to the OSN along with its desired access
control policy. The OSN decrypts the content and re-encrypts
the content with a newly generated symmetric key. Other
clients may request the content using its public name (obtained
from a search in the OSN or a search engine). The OSN,
authorizes the client and its access to the content and returns the
content’s secure network addressable name, the symmetric key
to decrypt the content, and the required metadata encrypted
with the requester’s session key. The requesting, authorized
client decrypts the message and requests the content by the
secure name. To prevent persistent correlation between the
public name and the secure name, the OSN changes the secure
name at regular intervals. This prevents a revoked user from
requesting the network for the content in the future.

The disadvantages of this scheme include: It undermines the
potency of in-network caching as renaming a popular content
effectively invalidates the content in the cache. It could cause a
content to exist under several names in the network, which
violates the ICN’s principle of content name immutability.
Before the name change, a revoked client can still access a
content. More importantly, the overhead to access content is
high.

D. Proxy Re-Encryption-Based Access Control

Wood et al. [118] proposed a ﬂexible mechanism for se-
cure end-to-end communication, leveraging a combination of
proxy re-encryption and identity-based encryption. The content
provider encrypts and disseminates content using a symmetric
key. A client may obtain a content from either a cache or the
content provider. Upon receiving the encrypted content, the

client requests the symmetric key from the content provider.
The producer determines whether the client is authorized to
access the content and then sends the symmetric key to the
legitimate client, encrypted with the client’s identity. After
receiving the key, the client extracts the key and decrypts the
content.

The proposed scheme reduces the cost of cryptography
through the encryption of a symmetric key instead of the entire
content; it also allows caching and enables efﬁcient revocation.
However, contact with the content provider is required with
each request, even if the content can be retrieved from a
cache. This undermines content availability in the case of the
provider’s unavailability.

Mangili et al. [82] proposed ConfTrack-CCN, a framework
designed to enforce access control and track-ability in content-
centric networks. In this framework, the provider partitions
the content and further divides each partition into a set of
fragments. This fragmentation allows two layers of encryption–
one at the fragment level and one at the partition level. The
provider encrypts the fragments of each partition into a chunk
using a symmetric key (one key per chunk); these keys are
stored in the encrypted chunk. The second layer of encryption is
used for conﬁdentiality and collusion prevention. In this layer,
a key-chain is generated using the “key-regression” derivation
algorithm [53]. An authenticated consumer needs to use a secret
from the producer to regenerate this second-layer key.

To prevent collusion, the provider encrypts the ﬁrst-layer
encrypted chunks with different second-layer keys; the keys
could be unique per user, group of users, or one key for all
users. With differing overheads, the provider can then ﬁnd
which user(s) gave their keys away to illegitimate users if the
key is used to decrypt the content. Public key cryptography
is used to authenticate the client before sending the material
needed to generate the second key. In order to prevent revoked
client from accessing cached content, the provider generates
a new second-layer key and publishes the re-encrypted data.
The authors suggested re-encrypting only a subset of chunks,
in order to reduce the cost of revocation.

Nonetheless, the framework requires caching routers to pe-
riodically query the provider for updated chunks. The newly
encrypted chunks replace the old ones,
thereby preventing
revoked users from decrypting all
the chunks. Despite the
framework helping leverage in-network caching, clients must
authenticate to the content provider in order to retrieve each
content. Furthermore, legitimate clients may need to compute
several versions of the second-level key, due to possible mis-
match of retrieved chunk versions.

Zheng et al. [128] proposed an access control mechanism
which requires edge routers to perform content encryption.
The process starts with the publisher encrypting the content
with its public key and a random key k1. Upon a client’s
request for a content, the edge router selects a random key
k2, and re-encrypts the encrypted content (as in proxy re-
encryption). The random key k2 is encrypted by the publisher’s
public key and signed by the edge router, and is attached to
the content to be sent to the client. To decrypt the content,

the client sends the encrypted k2, the desired content name,
and its identity to the publisher. The publisher validates the
client’s identity and decides whether the client may access the
content. The publisher then uses its private key, along with
k1 and k2 to generate the content decryption key k for the
client. Upon receiving k, the client may decrypt the content.
Due to the randomness of the k2 generated with each request,
the decryption key k will be different for each client.

The performance analysis in the paper shows that the edge
router’s re-encryption operation takes about 10 seconds for
a small content (256MB). The need to use edge routers’
resources for encryption undermines the scalability of this
solution, especially since the majority of future Internet trafﬁc
is expected to consist of large multimedia content.

E. Miscellaneous Models of Access Control

Several other proposed models in the literature do not con-
form to a particular access control model. We mention them
here.

Fotiou et al. [48] proposed an access control enforcement
method for rendezvous-based ICN architectures. The model
proposes the use of an access control provider (ACP), which
interacts with publishers, rendezvous nodes (RNs), and sub-
scribers to create access control policies and authenticate sub-
scribers against the policy. A publisher ﬁrst provides its access
control policy to the ACP, which assigns a URI to the policy.
The publisher forwards the content, along with the policy URI,
to the RNs. A subscriber who has requested the content will
receive the URI of the access control as well as a nonce from
the RN. Simultaneously, the RN forwards the nonce and the
URI of the relevant access control policy to the ACP. Upon
receiving the subscriber’s credentials, the ACP veriﬁes it against
the policy and informs the RN whether the client is permitted
access. The RN sends the content to the subscriber, if the ACP
has indicated that access is allowed.

This approach has additional overhead at RNs or routers
which might not scale to line speed. Also it requires the
RN to store the access control policy URI for each content.
In addition, there is a need for a trusted authority to act as
the ACP, and content availability will be subverted in the
case of the ACP’s failure. Furthermore, the use of per-request
communication between the ACP and the relaying party creates
unnecessary overhead. Finally, the mechanism for subscriber
revocation has not been discussed.

Singh [101] proposed a trust-based approach for access
control in publish/subscribe networks. In this scheme, a client
has to establish a level of trust with a broker, an intermediate
entity that serves to authenticate clients and publishers. In the
registration phase, a client submits its credentials and attributes
to the broker entity; this information is then stored and trust is
established between the broker and the client. The publishers
follow the same procedure, registering with their own brokers
before publishing content. To apply access control to its content,
the publisher deﬁnes an access policy and submits it to its
broker, where it is stored.

A registered client can then request the published content
from its local broker. If the content
is not stored by the
local broker, it returns the information needed to locate the
correct broker. The broker corresponding to the content, once
found, evaluates the trust level of the client and evaluates the
client against the content’s access control policy. Despite the
theoretically wide applicability of the proposed scheme, the
authors did not discuss how several aspects of the scheme
are going to be implemented. These aspects include client
identiﬁcation and access level identiﬁcation/veriﬁcation, client
revocation, communication overhead, and how the broker net-
work is created.

Tan et al. [103] proposed a solution to copyright protection
problem in form of an access control mechanism. The basic
idea is to divide the protected content into two portions: a large
portion that is cacheable in the network, and a smaller portion
which remains at the publisher. Each client has to retrieve the
small portion from the publisher to be able to reconstruct the
content, thereby the publisher may enforce access control on its
content. In order to provide track-ability of authorized clients,
the authors suggested that the small portion of the content
(stored at the publisher) should be unique to each client. To
achieve this goal, the publisher creates and stores a unique copy
of the stored portion per client.

An authorized client, having retrieved the large portion of
the content, retrieves its unique part from the publisher and
recreates the entire content. Since the smaller portion is unique
per client, the authors state that a publisher can track a client,
and identify who has leaked its unique portion to an illegitimate
user. However,
this veriﬁcation may not be possible. If a
malicious authorized client gives its content to an illegitimate
user and the user downloads the rest of its content from
the publisher, there is no way that the publisher can know,
which user’s small share was used. Another drawback of this
mechanism is also the need of an always online provider.

Li et al. [78] designed a lightweight digital signature and
access control enforcement scheme for named-data networking,
named LIVE. The access control policies are enforced by the
use of tokens, pieces of information which indicate the access
level of its owner. The provider generates a public token for
unauthorized entities to make sure that the content veriﬁcation
process using this token will fail. An unauthorized entity who
failed to verify the content using a public token then considers
it as corrupted or fake content. Two private tokens are generated
for each authorized entity, granting content access and integrity
veriﬁcation respectively. It is noteworthy to mention that only
the provider can distinguish the public and private tokens.

The provider ﬁrst creates three key vectors, one public and
two private, which will be transformed into the aforementioned
tokens by a hash function. Upon an entity’s request for a token,
the provider encrypts the token according to the requester’s
access level before sending it. These tokens have to be refreshed
after they have been used for signature veriﬁcation; hence, the
subsequent tokens will be encrypted with the old token and
embedded in the content to reduce communication overhead.
To create token-based signatures, the content provider uses

the content blocks and the new token to generate a Merkle
hash tree (MHT). It then uses the key vector from the token
creation process to generate a new vector. By combining the
MHT and the new vector, the provider generates its hash-
based signature. For signature veriﬁcation, a client retrieves
the content and the new token, then regenerates the MHT. By
combining the computed MHT with the obtained signature, the
client can extract the original signing token. The signature is
valid if this token matches the token obtained from the content
provider. The new token is used for next signature veriﬁcation
for a content from the same publisher and is stored at the client.
The authors showed that the proposed algorithm is faster than
conventional RSA signing, especially with increased content
size. However, the entities must synchronize with the provider
to ensure that the correct version of the token is used. The
provider also must store, for each content, at least three tokens
and their corresponding key vectors at any time. Finally, client
revocation, one of the most
important concerns of access
control in ICN, has not been discussed in this article.

Ghali et al. [56] tackled the access control problem using an
interest-based model, in contrast to popular encryption-based
approaches. The two major design aspects of this approach are
(1) name obfuscation, and (2) authorized disclosure. While the
former prevents the unauthorized clients from obtaining the
content name, the latter requires each entity with a content
copy to perform the authentication/authorization procedure on
the publisher’s behalf. The authors proposed encryption-based
and hash-based name obfuscation, in which each authorized
client (either individually or as part of a group) encrypts (with
a symmetric key) or hashes a sufﬁx of the content name with
a key shared with the provider.

The interest for a content carries a nonce, a time-stamp, and a
client identiﬁer in its payload, and is signed by the client using
the group’s private key. The provider, upon receiving an interest,
veriﬁes the client’s signature (using the group’s public key) and
fetches the client’s key in order to decrypt the encrypted portion
of the content name. The provider attaches the group’s public
key for signature veriﬁcation to the content and forwards it to
the client. In line with the concept of authorized disclosure, the
on-path routers, upon receiving a content, store the obfuscated
content name and its corresponding public key so that they can
authenticate the subsequent requests for the same content from
the same group of clients. If the request cannot be authenticated
it is dropped.

There are several concerns regarding the proposed approach,
such as obfuscated content names, which may cause several
copies of a content to be stored, which undermines caching
effectiveness. The use of hashing for name obfuscation would
also required that the provider pre-computes the hashed content
names for each individual and group, which is not computation
and storage efﬁcient. In addition, a revoked client from a
group can still request content until the provider revokes its
membership and update the group’s keying material.

Table VIII presents a summary of the proposed access control
mechanisms for ICN. It compares the existing mechanisms
on the basis of their overhead types, communication and

Mechanism

Kurihara et al. [24]
Chen et al. [34]
Misra et al. [87], [88]

Aiash et al. [18]
Da Silva et al. [40]
Hamdane et al. [62]
Hamdane et al. [64]
Ion et al. [66]
Li et al. [76], [77]
Raykova et al. [94]

Renault et al. [96], [97]
Wang et al. [115]

Mangili et al. [82]
Wood et al. [118]
Zheng et al. [128]

Fotiou et al. [48]
Ghali et al. [56]
Li et al. [78]
Singh [101]
Tan et al. [103]

TABLE VIII: Summary of the Access Control Mechanisms

Communication

Overhead

Computation Overhead
Provider Network Client

Additional

Infrastructure

Client

Revocation

Cache

Utilization

Access Control
Enforcement





































































































Required

Not Required
Not Required

Lazy Revocation

Daily Re-encryption

Threshold Based

Limited

Yes

Yes

Provider

Provider/Network

Client

Not Required

Required
Required
Required

Required
Required
Required

Not Considered

Key Update per Revoc.

Not Considered
System Re-key
Not Considered
Not Considered
Not Considered

Required

Not Required

Not Required
Not Required
Not Required

Not Considered
Not Considered

Partial Re-encryption

Not Considered
Not Considered

No
Yes
Yes
Yes
Yes
Yes
No

No
No

Yes
Yes
Yes

Provider
Network
Network
Provider
Client
Client
Client

Network
Provider

Client
Provider
Network

Required

Not Required
Not Required

Required

Not Required

Not Considered
Not Considered
Not Considered
Not Considered

Considered

Limited

Yes

Yes
Yes
Yes

Provider/Network

Network

Provider
Network
Provider

computation, and the entities where the computation overhead
occurs. Client revocation method, ability of cache utilization,
and the entities that enforce access control are other comparison
features of Table VIII.

F. Summary and Future Research

In this section, we reviewed the existing research in ICN ac-
cess control enforcement and speciﬁcally focused on models in-
cluding encryption-based [24], [34], [87], attribute-based [18],
[40], [62], [64], [66], [76], [77], [94],
identity-based [96],
[97], [115], session-based [82], [118], [128], and proxy re-
encryption-based [48], [56], [78], [101], [103] models. Al-
though almost all the proposed mechanisms introduce com-
munication overhead, some of the proposed mechanisms [18],
[48] require extensive interactions between an access control
manager and other network entities in order to enforce access
constraints. These interactions not only increase communica-
tion and computation overhead, but also require additional
infrastructure. The availability of a content in caches is not of
much use if access to the content requires authentication and/or
authorization from an always-online server, which cannot be
guaranteed to be online always. To truly exploit ICN’s intrinsic
provisions for content availability, an access control mechanism
in which the access can be granted without
the need for
immediate access speciﬁcation veriﬁcation is required. The
work by Misra et al. is the ﬁrst attempt in this direction.

Access right revocation is the other major concern of current
proposals for ICN access control management. Attribute-based
mechanisms [18], [40], [62], [64], [66], [76], [77], [94], in
general, either take the costly and inefﬁcient approach of per-
revocation re-keying, or allow clients to continue accessing

the latter approach is more acceptable, as it

cached content even after revocation. Although we believe
that
imposes
less damage and complexity, efﬁcient access revocation is a
key factor for the design of a broadly-applicable and scalable
access control mechanism in ICN. Some of the proposed
mechanisms [34], [40], [62], [96], [128], [48], [56], [101]
require the network (routers) to enforce access control and
authenticate clients. The fact that the intermediate routers have
to perform authentication procedure undermines the scalability
of these mechanisms. There is scope for improvements on all
the noted fronts.

5. CONCLUSIONS AND LESSONS LEARNED

In this survey, we have comprehensively explored the ex-
isting work in the domain of information-centric network
security. We divided the content into three major sub-domains:
security, privacy, and access control enforcement. We reviewed
the existing work in each sub-domain, and highlighted the
drawbacks and beneﬁts of each proposed solution. Additionally,
we provided potential future research directions to explore in
order to overcome the mentioned shortcomings.

In the security risks section, we explored attacks such as
denial of service, content poisoning, and cache pollution, and
also explained the proposed models for secure naming, routing,
and applications. The majority of the existing works in this
sub-domain aim to prevent adversaries from degrading the user
QoS and QoE through malicious behavior, such as interest
ﬂooding, cache pollution, and packet forgery. However, the
negative impacts of these solutions on legitimate clients have
not been studied in depth. Among these attacks, DoS is the most
widespread and the easiest to mount. A simple rate limiting

approach can mitigate the impact of the attack to some extent,
however, it also can starve legitimate clients. Thwarting content
poisoning attack, despite its detection simplicity, requires com-
putational resources at the intermediate routers, which makes
it more severe.

ICN privacy threats can affect content, caches, and the
clients. Timing and monitoring attacks speciﬁcally target
cached content in the router shared between a victim and a
attacker, and hence threaten both client and cache privacy. De-
spite the simplicity of orchestrating these attacks, the proposed
counter-attacks such as applying random delay can protect
the attack targets at the expense of latency. Protocol attacks
caused by ICN protocol design ﬂaws target cache privacy, while
naming and signature privacy attacks target the name and signer
privacy respectively. Among the privacy risks that we have
explored, we believe communication anonymity is of the utmost
importance.

The availability of content replicas at various locations
outside the publisher’s control creates need for more sophis-
ticated access control mechanisms for ICN. The majority of
the access control mechanisms that were studied in this survey
rely on the existence of an online service to authorize each re-
quests. However, per-content online authorization dramatically
increases the communication overhead, and can also undermine
content availability if the authorization service goes down,
regardless of the presence of the desired content in a cache.
Hence, there is a need for an access control mechanism that
guarantees the usability of the content regardless of the content
provider’s availability. This can be achieved through enforcing
access control by network elements that cache the content.
However, the computation and communication overheads of
the authentication and authorization processes can become
excessive overheads at the routers. In what follows, we identify
the lessons we have learned while reviewing the state of the art
in ICN security.

First, the negative impacts of proposed security protocols
on legitimate clients should be further investigated. Approaches
such as rate limiting on suspicious interfaces and name preﬁxes
may mitigate DoS attacks, however they come at the cost of
quality of service degradation for legitimate clients. By prevent-
ing content caching through either tunneling or request ﬂagging
many privacy-focused schemes also inadvertently affect user
QoE and QoS. For example, a selﬁsh client may prevent all of
the content it receives from being cached, simply by ﬂagging
all requests as private/sensitive or by creating tunnels for each
ﬂow. This will result in increased network load, and increased
download latency for other users.

The second lesson learned is that security concerns should be
addressed at the intrinsic level. For example, content poisoning
and cache pollution attacks are enabled by the lack of secure
naming and caching schemes. We believe that these attacks
should be solved intrinsically by employing strong cache
veriﬁcation mechanisms and self-certifying naming schemes,
which would inherently eliminate unpopular content from the
cache and prevent forged content from lingering in the network.
Similarly, a scalable naming scheme would not only eliminate

many opportunities for malicious behavior, but it also improves
the efﬁciency of content routing.

In ICN, the privacy risks emanate from the data interest
traveling in clear in the network. In the era of widespread
consumer proﬁling, in which data consumption information are
invaluable to corporations, service providers, and most impor-
tantly censors, existing ICN architectures have a wide attack
surface for data collection. There have been some attempts
at mitigating these problems, but we believe more needs to
be done to develop an ICN-inspired mechanism, which can
preserve privacy, while still leveraging the inherent beneﬁts of
ICN.

Third, the fundamental principles of ICN should be re-
spected during the design of new security mechanisms. Here,
we speciﬁcally refer to the necessity of an efﬁcient access
control enforcement mechanisms that are in agreement with
ICN principles. ICN,
in principle, promotes content avail-
ability by allowing pervasive caching, and hence requires a
more advanced, service-independent access control mechanism,
which can be enforced in the network. In this survey, we
have identiﬁed some initial attempts towards an independent
access control mechanism that can be enforced by any network
caching entities without using too much of their computational
resources. We believe that the research community must keep
ICN principles in mind, such that future access control schemes
may protect content without undermining features necessary for
the future Internet, such as in-network caching and session-less
communication.

REFERENCES

[1] 4WARD. http://www.4ward-project.eu/.
[2] CCNX. http://www.ccnx.org/.
[3] COMET. http://www.comet-project.org/.
[4] CONVERGENCE. http://www.ict-convergence.eu/.
[5] Information-Centric Networking Research Group. https://irtf.org/icnrg.
[6] MobilityFirst. http://mobilityﬁrst.winlab.rutgers.edu/.
[7] NDN. http://named-data.net/.
[8] PSIRP. http://www.psirp.org/.
[9] PURSUIT. http://www.fp7-pursuit.eu/PursuitWeb/.
[10] SAIL. http://www.sail-project.eu/.
[11] M. Aamir and M. Zaidi. Denial-of-service in content centric (named
data) networking: a tutorial and state-of-the-art survey. Security and
Communication Networks, 8:2037–2059, 2014.

[12] E. AbdAllah, H. Hassanein, and M. Zulkernine. A survey of security at-
tacks in information-centric networking. IEEE Communications Surveys
& Tutorials, 17:1441–1454, 2015.

[13] G. Acs, M. Conti, P. Gasti, C. Ghali, and G. Tsudik. Cache privacy
in named-data networking. In IEEE 33rd International Conference on
Distributed Computing Systems (ICDCS), pages 41–51, 2013.

[14] A. Afanasyev, P. Mahadevan, I. Moiseenko, E. Uzun, and L. Zhang.
Interest ﬂooding attack and countermeasures in named data networking.
In Proceedings of IFIP Networking Conference, pages 1–9. IEEE, 2013.
[15] A. Afanasyev, C. Yi, L. Wang, B. Zhang, and L. Zhang. Snamp: Secure
In Proceedings of 18th

namespace mapping to scale ndn forwarding.
IEEE Global Internet Symposium (GI 2015), 2015.

[16] B. Ahlgren, M. D’Ambrosio, M. Marchisio, I. Marsh, C. Dannewitz,
B. Ohlman, K. Pentikousis, O. Strandberg, R. Rembarz, and V. Ver-
In In
cellone. Design considerations for a network of information.
Proceedings of the ACM CoNEXT Conference, page 66, 2008.

[17] B. Ahlgren, C. Dannewitz, C. Imbrenda, D. Kutscher, and B. Ohlman.
IEEE Communications

A survey of information-centric networking.
Magazine, 50(7):26–36, 2012.

[18] M. Aiash and J. Loo. A formally veriﬁed access control mechanism for
information centric networks. In Proceedings of the 12th International
Conference on Security and Cryptography, pages 377–383, 2015.

[19] B. Alzahrani, M. Reed, V. Vassilakis, et al. Enabling z-ﬁlter updates
for self-routing denial-of-service resistant capabilities. In 4th Computer
Science and Electronic Engineering Conference (CEEC), pages 100–
105. IEEE, 2012.

[20] B. Alzahrani, V. Vassilakis, M. Reed, et al. Securing the forwarding
In Proceedings of 5th IEEE
plane in information centric networks.
Computer Science and Electronic Engineering Conference (CEEC),
pages 174–178, 2013.

[21] B. Alzahrani, V. Vassilakis, M. Reed, et al. Selecting bloom-ﬁlter header
lengths for secure information centric networking. In 9th International
Symposium on Communication Systems, Networks & Digital Signal
Processing (CSNDSP), pages 628–633. IEEE, 2014.

[22] B. A. Alzahrani, V. G. Vassilakis, and M. J. Reed. Key management
in information centric networking. International Journal of Computer
Networks & Communications (IJCNC), 5(6):153–166, 2013.

[23] M. Ambrosin, M. Conti, P. Gasti, and G. Tsudik. Covert ephemeral
the
communication in named data networking.
9th ACM symposium on Information, computer and communications
security, pages 15–26, 2014.

In Proceedings of

[24] J. Kurihara andE. Uzun and C. Wood. An encryption-based access
control framework for content-centric networking. In IFIP Networking
Conference (IFIP Networking), pages 1–9. IEEE, 2015.

[25] S. Arianfar, T. Koponen, B. Raghavan, and S. Shenker. On preserving
the ACM
privacy in content-oriented networks.
SIGCOMM workshop on Information-centric networking, pages 19–24,
2011.

In Proceedings of

[26] T. Asami, B. Namsraijav, Y. Kawahara, K. Sugiyama, A. Tagami,
T. Yagyu, K. Nakamura, and T. Hasegawa. Moderator-controlled infor-
mation sharing by identity-based aggregate signatures for information
centric networking. In Proceedings of the 2nd International Conference
on Information-Centric Networking, pages 157–166. ACM, 2015.

[27] F. Bari, S. Chowdhury, R. Ahmed, R. Boutaba, and B. Mathieu. A
IEEE

survey of naming and routing in information-centric networks.
Communications Magazine, 50(12):44–53, 2012.

[28] M. Baugher, B. Davie, A. Narayanan, and D. Oran. Self-verifying
In IEEE Conference on Computer
names for read-only named data.
Communications Workshops (INFOCOM WKSHPS), volume 12, pages
274–279, 2012.

[29] G. Bianchi, A. Detti, A. Caponi, and N. Melazzi. Check before storing:
What is the performance price of content integrity veriﬁcation in lru
caching? ACM SIGCOMM Computer Communication Review, 43(3):59–
67, 2013.

[30] J. Burke, P. Gasti, N. Nathan, and G. Tsudik. Securing instrumented
the case of lighting
In IEEE Conference on Computer Communications

environments over content-centric networking:
control and ndn.
Workshops (INFOCOM WKSHPS), pages 394–398, 2013.

[31] J. Burke, P. Gasti, N. Nathan, and G. Tsudik. Secure sensing over named
In IEEE 13th International Symposium on Network

data networking.
Computing and Applications (NCA), pages 175–180, 2014.

[32] A. Chaabane, E. De Cristofaro, M. A. Kaafar, and E. Uzun. Privacy
in content-oriented networking: Threats and countermeasures. ACM
SIGCOMM Computer Communication Review, 43(3):25–33, 2013.

[33] H. Che, Y. Tung, and Z. Wang. Hierarchical web caching systems:
Modeling, design and experimental results. IEEE Journal on Selected
Areas in Communications, 20(7):1305–1314, 2002.

[34] T. Chen, K. Lei, and K. Xu. An encryption and probability based
access control model for named data networking. In IEEE International
Performance Computing and Communications Conference (IPCCC),
pages 1–8, 2014.

[35] K. Cho, M. Lee, K. Park, T. Kwon, Y. Choi, and S. Pack. Wave:
Popularity-based and collaborative in-network caching for content-
oriented networks. In IEEE Conference on Computer Communications
Workshops (INFOCOM WKSHPS), pages 316–321, 2012.

[36] S. Chung, T. Kim, and M. Jang. A privacy-preserving approach in
content centric networking. In IEEE 11th Consumer Communications
and Networking Conference (CCNC), pages 866–871, 2014.

[37] A. Compagno, M. Conti, P. Gasti, L. V. Mancini, and G. Tsudik.
Violating consumer anonymity: Geo-locating nodes in named data
In Proceedings of Conference of Applied Cryptography
networking.
and Network Security (ACN), pages 243–262. Springer, 2015.

[38] A. Compagno, M. Conti, P. Gasti, and G. Tsudik. Poseidon: Mitigating
interest ﬂooding ddos attacks in named data networking. In IEEE 38th
Conference on Local Computer Networks (LCN), pages 630–638, 2013.
[39] M. Conti, P. Gasti, and M. Teoli. A lightweight mechanism for
detection of cache pollution attacks in named data networking. Computer
Networks, 57(16):3178–3191, 2013.

[40] R. S. da Silva and S. Zorzo. An access control mechanism to ensure
privacy in named data networking using attribute-based encryption with
In 12th Annual IEEE Consumer
immediate revocation of privileges.
Communications and Networking Conference (CCNC), pages 128–133,
2015.

[41] H. Dai, Y. Wang, J. Fan, and B. Liu. Mitigate ddos attacks in ndn by
interest traceback. In IEEE Conference on Computer Communications
Workshops (INFOCOM WKSHPS), pages 381–386, 2013.

[42] C. Dannewitz, J. Goli´c, B. Ohlman, and B. Ahlgren. Secure naming for
a network of information. In INFOCOM IEEE Conference on Computer
Communications Workshops, pages 1–6, 2010.

[43] A. Detti, N. Belfari Melazzi, S. Salsano, and M. Pomposini. Conet:
In Proceedings of the
a content centric inter-networking architecture.
ACM SIGCOMM workshop on Information-centric networking, pages
50–55, 2011.

[44] S. DiBenedetto, P. Gasti, G. Tsudik, and E. Uzun. Andana: Anonymous
named data networking application. arXiv preprint arXiv:1112.2205,
2011.

[45] M. Van Dijk, C. Gentry, S. Halevi, and V. Vaikuntanathan. Fully
homomorphic encryption over the integers. In Advances in cryptology–
EUROCRYPT 2010, pages 24–43. Springer, 2010.

[46] A. Elabidi, G. Ben Ayed, S. Mettali Gammar, and F. Kamoun. To-
wards hiding federated digital identity: Stop-dissemination mechanism
in content-centric networking. In Proceedings of the 4th international
conference on Security of information and networks, pages 239–242.
ACM, 2011.

[47] N. Fotiou, S. Arianfar, M. S¨arel¨a, and G. C. Polyzos. A framework
for privacy analysis of icn architectures. In Privacy Technologies and
Policy, pages 117–132. Springer, 2014.

[48] N. Fotiou, G. Marias, and G. Polyzos. Access control enforcement
delegation for information-centric networking architectures. In Proceed-
ings of the second edition of the ICN workshop on Information-centric
networking, pages 85–90. ACM, 2012.

[49] N. Fotiou, G. F. Marias, and G. C. Polyzos.

Fighting spam in
In 6th EURO-
publish/subscribe networks using information ranking.
NF Conference on Next Generation Internet (NGI), pages 1–6. IEEE,
2010.

[50] N. Fotiou, G. F. Marias, and G. C. Polyzos. Towards a secure rendezvous
network for future publish/subscribe architectures. In Future Internet-
FIS, pages 49–56. Springer, 2010.

[51] N. Fotiou, G. F. Marias, and G. C. Polyzos. Publish–subscribe internet-
working security aspects. In Trustworthy Internet, pages 3–15. Springer,
2011.

[52] N. Fotiou, D. Trossen, G. F. Marias, A. Kostopoulos, and G. C.
Polyzos. Enhancing information lookup privacy through homomorphic
encryption. Security and Communication Networks, 7(12):2804–2814,
2014.

[53] K. Fu, S. Kamara, and T. Kohno. Key regression: Enabling efﬁcient key
distribution for secure distributed storage. Computer Science Department
Faculty Publication Series, page 149, 2006.

[54] P. Gasti, G. Tsudik, E. Uzun, and L. Zhang. Dos and ddos in
named data networking. In 22nd International Conference on Computer
Communications and Networks (ICCCN), pages 1–7. IEEE, 2013.

[55] C. Ghali, A. Narayanan, D. Oran, G. Tsudik, and C. Wood. Secure frag-
mentation for content-centric networks. arXiv preprint arXiv:1405.2861,
2014.

[56] C. Ghali, M. Schlosberg, G. Tsudik, and C. Wood. Interest-based access
control for content centric networks (extended version). arXiv preprint
arXiv:1505.06258, 2015.

[57] C. Ghali, G. Tsudik, and E. Uzun. Elements of trust in named-data

networking. arXiv preprint arXiv:1402.3332, 2014.

[58] C. Ghali, G. Tsudik, and E. Uzun. Needle in a haystack: Mitigating
content poisoning in named-data networking. In Proceedings of NDSS
Workshop on Security of Emerging Networking Technologies (SENT),
2014.

[59] C. Ghali, G. Tsudik, and E. Uzun. Network-layer trust in named-
data networking. ACM SIGCOMM Computer Communication Review,
44(5):12–19, 2014.

[60] D. Goergen, T. Cholez, J. Franc¸ois, and T. Engel. Security monitoring
In Data privacy management and

for content-centric networking.
autonomous spontaneous security, pages 274–286. Springer, 2013.

[61] D. Goergen, T. Cholez, J. Franc¸ois, and T. Engel. A semantic ﬁrewall
for content-centric networking. In IFIP/IEEE International Symposium
on Integrated Network Management, pages 478–484, 2013.

[62] B. Hamdane and S. G. Fatmi. A credential and encryption based access
control solution for named data networking. In IFIP/IEEE International
Symposium on Integrated Network Management (IM), pages 1234–1237,
2015.

[63] B. Hamdane, A. Serhrouchni, A. Fadlallah, and S.G. El Fatmi. Named-
data security scheme for named data networking. In Third International
Conference on the Network of the Future (NOF), pages 1–6. IEEE, 2012.
[64] B. Hamdane, A. Serhrouchni, and S. Fatmi. Access control enforcement
in named data networking. In 8th International Conference for Internet
Technology and Secured Transactions (ICITST), pages 576–581. IEEE,
2013.

[65] M. Howard and D. LeBlanc. Writing secure code. Pearson Education,

2003.

[66] M. Ion, J. Zhang, and E. M. Schooler. Toward content-centric privacy

in icn: attribute-based encryption and routing. 43(4):513–514, 2013.

[67] V. Jacobson, D. Smetters, J. Thornton, M. Plass, N. Briggs, and
the
R. Braynard. Networking named content.
5th international conference on Emerging networking experiments and
technologies, pages 1–12. ACM, 2009.

In Proceedings of

[68] k. Wang, J. Chen, H. Zhou, and Y. Qin. Content-centric networking:
Effect of content caching on mitigating dos attack. International Journal
of Computer Science Issues, (9):43–52, 2012.

[69] A. Karami and M. Guerrero-Zapata. An anﬁs-based cache replacement
method for mitigating cache pollution attacks in named data networking.
Computer Networks, 80:51–65, 2015.

[70] A. Karami and M. Guerrero-Zapata. A fuzzy anomaly detection system
based on hybrid pso-kmeans algorithm in content-centric networks.
Neurocomputing, 149:1253–1269, 2015.

[71] K. Katsaros, L. Saino, I. Psaras, and G. Pavlou. On information
In 10th International Conference
exposure through named content.
on Heterogeneous Networking for Quality, Reliability, Security and
Robustness (QShine), pages 152–157. IEEE, 2014.

[72] D. Kim, S. Nam, J. Bi, and I. Yeom. Efﬁcient content veriﬁcation
In Proceedings of the 2nd International
in named data networking.
Conference on Information-Centric Networking, pages 109–116. ACM,
2015.

[73] T. Koponen, M. Chawla, B. Chun, A. Ermolinskiy, K. H. Kim,
S. Shenker, and I. Stoica. A data-oriented (and beyond) network archi-
tecture. ACM SIGCOMM Computer Communication Review, 37(4):181–
192, 2007.

[74] T. Lauinger, N. Laoutaris, P. Rodriguez, T. Strufe, E. Biersack, and
E. Kirda. Privacy implications of ubiquitous caching in named data net-
working architectures. Technical report, Technical report, TR-iSecLab-
0812-001, iSecLab, 2012.

[75] T. Lauinger, N. Laoutaris, P. Rodriguez, T. Strufe, E. Biersack, and
E. Kirda. Privacy risks in named data networking: what is the cost
of performance? ACM SIGCOMM Computer Communication Review,
42(5):54–57, 2012.

[76] B. Li, A. Verleker, D. Huang, Z. Wang, and Y. Zhu. Attribute-
based access control for icn naming scheme. In IEEE Conference on
Communications and Network Security (CNS), pages 391–399, 2014.

[77] B. Li, Z. Wang, D. Huang, and Y. Zhu. Toward privacy-preserving
content access control for information centric networking. Technical
report, DTIC Document, 2014.

[78] Q. Li, X. Zhang, Q. Zheng, R. Sandhu, and X. Fu. Live: Lightweight
integrity veriﬁcation and content access control for named data net-
IEEE Transactions on Information Forensics and Security,
working.
10(2):308–320, 2015.

[79] Z. Li and J. Bi.

Interest cash: an application-based countermeasure
against interest ﬂooding for dynamic content in named data networking.
In Proceedings of The Ninth International Conference on Future Internet
Technologies, page 2. ACM, 2014.

[80] J. Liu and J. Li. A better improvement on the integrated Difﬁe-Hellman-
dsa key agreement protocol. International Journal of Network Security,
11(2):114–117, 2010.

[81] J. Loo and M. Aiash. Challenges and solutions for secure information
centric networks: A case study of the netinf architecture. Journal of
Network and Computer Applications, 50:64–72, 2015.

[82] M. Mangili, F. Martignon, and S. Paraboschi. A cache-aware mechanism
to enforce conﬁdentiality, trackability and access policy evolution in
content-centric networks. Computer Networks, 76:126–145, 2015.

[83] G. Marias, J. Barros, M. Fiedler, A. Fischer, H. Hauff, R. Herkenhoener,
A. Grillo, A. Lentini, L. Lima, C. Lorentzen, et al. Security and privacy
Security and Communication
issues for the network of the future.
Networks, 5(9):987–1005, 2012.

[84] P. Martinez-Julia and A. Gomez-Skarmeta. Using identities to achieve
enhanced privacy in future content delivery networks. Computers &
Electrical Engineering, 38(2):346–355, 2012.

[85] P. Martinez-Julia, A. Gomez-Skarmeta, J. Girao, and A. Sarma. Protect-
ing digital identities in future networks. In Future Network & Mobile
Summit (FutureNetw), pages 1–8. IEEE, 2011.

[86] G. Mauri, R. Raspadori, M. Gerlay, and G. Verticale. Exploiting
information centric networking to build an attacker-controlled content
delivery network. In 14th Annual Mediterranean Ad Hoc Networking
Workshop (MED-HOC-NET), pages 1–6. IEEE, 2015.

[87] S. Misra, R. Tourani, and N. Majd.

Secure content delivery in
information-centric networks: design, implementation, and analyses. In
Proceedings of the 3rd ACM SIGCOMM workshop on Information-
centric networking, pages 73–78, 2013.

[88] S. Misra, R. Tourani, F. Natividad, T. Mick, N. Majd, and H. Huang.
AccConF: An access control framework for leveraging in-network
cached data in ICNs. IEEE Transactions on Information Forensics and
Security (T-IFS), xx(xx):1–14, 2016.

[89] A. Mohaisen, H. Mekky, X. Zhang, H. Xie, and Y. Kim. Timing attacks
on access privacy in information centric networks and countermeasures.
IEEE Transactions on Dependable and Secure Computing, 12(6):675–
687, 2015.

[90] A. Mohaisen, X. Zhang, M. Schuchard, H. Xie, and Y. Kim. Protecting
access privacy of cached contents in information centric networks.
In Proceedings of the 8th ACM SIGSAC symposium on Information,
computer and communications security, pages 173–178, 2013.

[91] T. Nguyen, R. Cogranne, and G. Doyen. An optimal statistical test for
robust detection against interest ﬂooding attacks in ccn. In IFIP/IEEE
International Symposium on Integrated Network Management (IM),
pages 252–260. IEEE, 2015.

[92] J. Pan, S. Paul, and R. Jain. A survey of the research on future internet

architectures. IEEE Communications Magazine, 49(7):26–36, 2011.

[93] H. Park, I. Widjaja, and H. Lee. Detection of cache pollution attacks
using randomness checks. In IEEE International Conference on Com-
munications (ICC), pages 1096–1100, 2012.

[94] M. Raykova, H. Kazmi, H. Lakhani, and A. Gehani. Decentralized
authorization and privacy-enhanced routing for information-centric net-
works. In Proceedings of the 31st Annual Computer Security Applica-
tions Conference, pages 31–40. ACM, 2015.

[95] R. Rembarz, D. Catrein, and J. Sachs. Private domains in networks
of information. In IEEE International Conference on Communications
Workshops ICC Workshops, pages 1–5, 2009.

[96] E. Renault, A. Ahmad, and M. Abid. Toward a security model for the
future network of information. In Proceedings of the 4th International
Conference on Ubiquitous Information Technologies & Applications,
pages 1–6. IEEE, 2009.

[97] E. Renault, A. Ahmad, and M. Abid. Access control to objects and their
description in the future network of information. Journal of information
processing systems, 6(3):359–374, 2010.

[98] M. Saleem and E. Renault. Towards a secure email service for the
In 2nd International Conference on Networking and

future internet.
Future Internet. Citeseer, 2012.

[99] R. Salguero. Content mediator architecture for content-aware networks.

COMET EU FP7 Report, 2010.

[100] I. Seskar, K. Nagaraja, S. Nelson, and D. Raychaudhuri. MobilityFirst
In Proceedings of the 7th Asian

future internet architecture project.
Internet Engineering Conference, pages 1–3. ACM, 2011.

[101] S. Singh. A trust based approach for secure access control in information
International Journal of Information and Network

centric network.
Security (IJINS), 1(2):97–104, 2012.

[102] K. R. Sollins. Pervasive persistent identiﬁcation for information centric
networking. In Proceedings of the second edition of the ICN workshop
on Information-centric networking, pages 1–6. ACM, 2012.

[103] X. Tan, Z. Zhou, C. Zou, Y. Niu, and X. Chen. Copyright protection in
named data networking. In Sixth International Conference on Wireless
Communications and Signal Processing (WCSP), pages 1–6. IEEE,
2014.

[104] F. Tao, X. Fei, L. Ye, and F. J. Li. Secure network coding-based
named data network mutual anonymity communication protocol.
In
International Conference on Electrical, Computer Engineering and
Electronics (ICECEE), pages 1107–1114, 2015.

[105] S. Tarkoma, M. Ain, and K. Visala. The publish/subscribe internet
routing paradigm (psirp): Designing the future internet architecture. In
Future Internet Assembly, pages 102–111, 2009.

[106] R. Tourani, S. Misra, J. Kliewer, S. Ortegel, and T. Mick. Catch me
if you can: A practical framework to evade censorship in information-
centric networks. In Proceedings of the 2nd International Conference
on Information-Centric Networking, pages 167–176. ACM, 2015.

[107] G. Tyson, N. Sastry, I. Rimac, R. Cuevas, and A. Mauthe. A survey
of mobility in information-centric networks: challenges and research
In Proceedings of the 1st ACM workshop on Emerging
directions.
Name-Oriented Mobile Networking Design-Architecture, Algorithms,
and Applications, pages 1–6, 2012.

[108] B. Vieira and E. Poll. A security protocol for information-centric
networking in smart grids. In Proceedings of the ﬁrst ACM workshop
on Smart energy grid security, pages 1–10, 2013.

[109] M. Virgilio, G. Marchetto, and R. Sisto. Pit overload analysis in content
centric networks. In Proceedings of the 3rd ACM SIGCOMM workshop
on Information-centric networking, pages 67–72, 2013.

[110] M. W¨ahlisch, T. Schmidt, and M. Vahlenkamp. Backscatter from
the data plane—threats to stability and security in information-centric
networking. arXiv preprint arXiv:1205.4778, 2012.

[111] K. Wang, J. Chen, H. Zhou, Y. Qin, and H. Zhang. Modeling denial-
of-service against pending interest table in named data networking.
International Journal of Communication Systems, 27(12):4355–4368,
2014.

[112] K. Wang, H. Zhou, Y. Qin, J. Chen, and H. Zhang. Decoupling malicious
interests from pending interest table to mitigate interest ﬂooding attacks.
In IEEE Globecom Workshops (GC Wkshps), pages 963–968, 2013.

[113] K. Wang, H. Zhou, Y. Qin, and H. Zhang. Cooperative-ﬁlter: countering
interest ﬂooding attacks in named data networking. Soft Computing,
18(9):1803–1813, 2014.

[114] S. Wang, J. Bi, and J. Wu. Collaborative caching based on hash-
routing for information-centric networking. ACM SIGCOMM Computer
Communication Review, 43(4):535–536, 2013.

[115] Y. Wang, M. Xu, Z. Feng, Q. Li, and Q. Li. Session-based access
control in information-centric networks: Design and analyses. In IEEE
International Performance Computing and Communications Conference
(IPCCC), pages 1–8, 2014.

[116] W. Wong and P. Nikander.

Secure naming in information-centric
networks. In Proceedings of the Re-Architecting the Internet Workshop,
page 12. ACM, 2010.

[117] W. Wong, F. Verdi, and M. F. Magalh˜aes. A security plane for
In Proceedings of

publish/subscribe based content oriented networks.
the 2008 ACM CoNEXT Conference, page 45, 2008.

[118] C. Wood, E. Uzun, et al. Flexible end-to-end content security in ccn.
In IEEE 11th Consumer Communications and Networking Conference
(CCNC), pages 858–865, 2014.

[119] M. Xie, I. Widjaja, and H. Wang. Enhancing cache robustness for
In In Proceedings of IEEE INFOCOM,

content-centric networking.
pages 2426–2434, 2012.

[120] Y. Xu, Y. Li, T. Lin, G. Zhang, Z. Wang, and S. Ci. A dominating-
set-based collaborative caching with request routing in content centric
In IEEE International Conference on Communications
networking.
(ICC), pages 3624–3628, 2013.

[121] G. Xylomenos, C. Ververidis, V. Siris, N. Fotiou, C. Tsilopoulos,
X. Vasilakos, K. Katsaros, G. C. Polyzos, et al. A survey of information-
centric networking research. IEEE Communications Surveys & Tutorials,
16(2):1024–1049, 2014.

[122] C. Yi, A. Afanasyev, I. Moiseenko, L. Wang, B. Zhang, and L. Zhang.
A case for stateful forwarding plane. Computer Communications,
36(7):779–791, 2013.

[123] Y. Yu, A. Afanasyev, D. Clark, V. Jacobson, L. Zhang, et al. Schema-
In Proceedings of the 2nd
tizing trust in named data networking.
International Conference on Information-Centric Networking, pages
177–186. ACM, 2015.

[124] S. T. Zargar, J. Joshi, and D. Tipper. A survey of defense mechanisms
IEEE

against distributed denial of service (ddos) ﬂooding attacks.
Communications Surveys & Tutorials, 15(4):2046–2069, 2013.

[125] G. Zhang, Y. Li, and T. Lin. Caching in information centric networking:

a survey. Computer Networks, 57(16):3128–3141, 2013.

[126] M. Zhang, H. Luo, and H. Zhang. A survey of caching mechanisms
in information-centric networking. IEEE Communications Surveys and
Tutorials, 17(3):1473–1499, 2015.

[127] X. Zhang, K. Chang, H. Xiong, Y. Wen, G. Shi, and G. Wang. Towards
In 19th
name-based trust and security for content-centric network.
IEEE International Conference on Network Protocols (ICNP), pages
1–6, 2011.

[128] Q. Zheng, G. Wang, R. Ravindran, and A. Azgin. Achieving secure and
scalable data access control in information-centric networking. In IEEE
International Conference on Communications (ICC), pages 5367–5373,
2015.

Reza Tourani received his B.S. in computer engi-
neering from IAUT, Tehran, Iran, in 2008, and M.S. in
computer science from New Mexico State University,
Las Cruces, NM, USA,
in 2012. From 2013, he
started his Ph. D. at New Mexico State University. His
research interests include smart grid communication
architecture and protocol, wireless protocols design
and optimization, future Internet architecture, and
privacy and security in wireless networks.

Travis Mick completed his B.S. at New Mexico State
University, Las Cruces, NM, USA in 2014, and is
now pursuing an M.S. in computer science at New
Mexico State University. His research is in smart grid
communication and information-centric networking.

Satyajayant Misra (SM’05, M’09) is an associate
professor in computer science at New Mexico State
University. He completed his M.Sc. in Physics and
Information Systems from BITS, Pilani, India in 2003
and his Ph.D. in Computer Science from Arizona
State University, Tempe, AZ, USA,
in 2009. His
research interests include wireless networks and the
Internet, supercomputing, and smart grid architectures
and protocols. He has served on several IEEE journal
editorial boards and conference executive committees
(Communications on Surveys and Tutorials, Wireless
Communications Magazine, SECON 2010, INFOCOM 2012). He has authored
more than 45 peer-reviewed IEEE/ACM journal articles and conference pro-
ceedings. More information can be obtained at www.cs.nmsu.edu/∼misra.

Gaurav Panwar completed his B.Tech in electronics
and communication engineering at Mahatma Gandhi
Institute of Technology, Hyderabad, AP, India in
2013, and is now pursuing an M.S.
in computer
science at New Mexico State University. His research
is in Wireless Sensor Networks, security, information-
centric networking and smart grid technologies.

