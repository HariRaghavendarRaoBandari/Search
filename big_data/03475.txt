6
1
0
2

 
r
a

 

M
0
1

 
 
]

O
L
.
s
c
[
 
 

1
v
5
7
4
3
0

.

3
0
6
1
:
v
i
X
r
a

Information Flow in Logical Environments

Robert E. Kent

Ontologos

Abstract. This paper describes information ﬂow within logical environ-
ments. The theory of information ﬂow, the logic of distributed systems,
was ﬁrst deﬁned by Barwise and Seligman [1]. Logical environments are
a semantic-oriented version of institutions. The theory of institutions,
which was initiated by Goguen and Burstall [5], is abstract model theory.
Information ﬂow is the ﬂow of information in channels over distributed
systems. The semantic integration of distributed systems, be they ontolo-
gies, databases or other information resources, can be deﬁned in terms of
the channel theory of information ﬂow. As originally deﬁned, the theory
of information ﬂow uses only a speciﬁc logical environment in order to
discuss information ﬂow. This paper shows how information ﬂow can be
deﬁned in an arbitrary logical environment.

Keywords: information ﬂow, logical environment, distributed systems,

channel, core, information integration, structure, theory and logic

1

Introduction

We describe information ﬂow in logical environments. The theory of Information
Flow (IF) is [1] the logic of distributed systems. The theory of Institutions (INS)
is [5] abstract model theory. Both can be regarded as ways to describe, classify,
model, extract, and apply patterns of knowledge in the design and maintenance
of ontologies [6], databases [3] and other knowledge resources. The theory IF and
the theory INS are related in two ways. On the one hand, IF is a special case of
ﬁrst order logic (FOL) (and FOL is just one institution): the types of IF can be
regarded as unary predicates and (then) the instances of IF are to be regarded
as individuals that may satisfy these unary predicates. So IF is both a special
case and a speciﬁc instance of INS. This point of view, advocated in a recent
paper by Goguen [4], has been used for several years in the Information Flow
Framework (IFF), as evidenced by the various documents and ontologies listed
at the IFF website [8]. On the other hand, the IF classiﬁcation relation (between
instances and types) can be regarded as an abstraction of the INS satisfaction
relation (between structures and sentences). As such, anything in the theory of
IF that is treated abstractly can be used to extend the theory of INS. So we
can view IF as an abstraction and extension of INS. This paper argues for this
point of view. We ﬁrst discuss a more semantic form of institutions called logical
environments. Then we demonstrate how the basics of information ﬂow can be
deﬁne in logical environments. We follow the example set by the theory of IF [1]
in the use of principles to codify and structure the discussion.

2

Robert E. Kent

2 Logical Environments

2.1 Structures

World Principle: The world exists a priori and is describable.

We represent the world as a category (mathematical context) Struc of semanti-
cal structures and structure morphisms. We assume the category of structures is
self-referential, in that the structures and their morphisms contain (are indexed
by) linguistic mechanisms for self-description. This index is represented by a
functor (passage between contexts) lang : Struc → Lang from the category of
semantical structures to a category Lang of (logical) languages and language
morphisms. For any structure M , lang (M ) is a language capable of describing
M , and for any structure morphism f : M1 → M2, lang (f ) : lang (M1) →
lang (M2) is a language morphism capable of describing f . Hence, a world con-
sists of a triple Wrld = hStruc, Lang, lang i as discussed above.

The institutional approach assumes that multiple worlds exist and are relat-
able. In general, diﬀerent worlds use diﬀerent languages for description. Worlds
are related through world morphisms. A world morphism wrld = hstruc, lang i :
Wrld1 → Wrld2 consists of a structure functor struc : Struc1 → Struc2 and a
language functor lang : Lang1 → Lang2 that commute with the source/target
world linguistic indexings struc ◦ lang 2 = lang 1 ◦ lang . World morphisms are
composable componentwise. Let World denote the category consisting of worlds
and world morphisms.

Polarity Principle: The linguistic indexing of the world is polar, having
equivalent homogeneous and heterogeneous forms.

We assume the linguistic indexing functor lang : Struc → Lang is a ﬁbration
(Cartesian passage). This gives a homogeneous representation of a world (all
stuctures are in one category). By the equivalence between ﬁbrations and in-
dex categories, we can alternately represent the world as the structure indexed
category struc : Langop → Cat with the category of languages as its index-
ing category. This gives a heterogeneous representation of a world (stuctures
are in many categories, each category indexed by the language of structures in
that category). For any language Σ, struc(Σ) is the category whose objects
are structures with underlying language Σ, and whose morphisms are structure
morphisms whose underlying language morphism is the identity 1Σ. Here the in-
dexed category struc is the heterogenization of the ﬁbration lang , and lang is
(up to equivalence) the homogenization (fusion) of struc. The indexed category
of stuctures models structural heterogeneity, whereas the ﬁbration of stuctures
models structural homogeneity. In summary, a world can be represented as an
indexed category Wrld = hLang, struc : Langop → Cati.

By the equivalence between ﬁbration morphisms and index morphisms, we

can alternately represent a world morphism as an indexed morphism hlang , struci :
hLang1, struc1i → hLang2, struc2i, where lang : Lang1 → Lang2 is the lan-
guage functor and struc : struc1 ⇒ lang op ◦ struc2 : Langop
1 → Cat is a

Information Flow in Logical Environments

3

structure natural transformation (bridge between passages) with Σth component
functor strucΣ : struc1(Σ) → struc2(lang (Σ)) for each language Σ in Lang1,
where the naturality diagram struc1(σ) ◦ strucΣ ∼= strucΣ′ ◦ struc2(lang (σ))
connecting the source/target structure indexes, holds up to isomorphism for each
language morphism σ : Σ → Σ′ in Lang1.

The structure indexed category has an underlying indexed set |struc| =
struc ◦ |-| : Langop → Set obtained by forgetting morphism information; any
language Σ is mapped to the set |struc|(Σ) of all Σ-structures and any lan-
guage morphism σ : Σ1 → Σ2 is mapped to the structure reduct |struc|(σ) :
|struc|(Σ2) → |struc|(Σ1).

2.2 Logical Expression

Logic Principle: The description of the world involves semantics. It is
logically meaningful, being based upon satisfaction.

We assume (syntax) that any structure can be described using logical expres-
sions (sentences) built from its language. In particular, we assume that there is
a sentence functor (dual indexed set) sen : Lang → Set with the category of
languages as its source (indexing category); any language Σ is mapped to the set
sen(Σ) of all sentences built upon it and any language morphism σ : Σ1 → Σ2
is mapped to the sentence translation map sen(σ) : sen(Σ1) → sen (Σ2) built
upon it. Furthermore, we assume (semantics) that the indexed sets of struc-
tures and sentences are linked by satisfaction; any language Σ is mapped to
a satisfaction relation (truth classiﬁcation) |=Σ ⊆ |struc|(Σ)×sen(Σ), where
the symbolism M |=Σ s expressing the assertion that ‘M satisﬁes s’ means
that Σ-sentence M is true when interpreted in Σ-structure M . A Σ-sentence
s ∈ sen (Σ) is a constraint (or theorem) of the Σ-structure M , and is said to be
valid in M , when M satisﬁes s.

We also assume that satisfaction is preserved under sentence translation (info-
morphism condition): |struc|(Σ)(M2) |=Σ1 s1 iﬀ M2 |=Σ2 sen(Σ)(s1) for target
structure M2 ∈ |struc|(Σ2) and source sentence s1 ∈ sen(Σ1). This expresses
the invariance of truth under change of notation. Finally, the structure and sen-
tence indexed sets can be combined with the satisfaction relations into a functor
cls : Lang → Cls from the category of languages to the category of classiﬁca-
tions and infomorphisms [7], whose composition with instance/type component
functors gives the structure/sentence indexed sets cls op ◦ inst = |struc| and
cls ◦ typ = sen . We can think of the classiﬁcation functor cls : Lang →
Cls as a diagram within the ambient category of classiﬁcations and infomor-
phisms, indexed by languages and language morphisms. When composed with
the lift functor (see below) logical expression and semantics extends to theories
cls ◦ lift : Lang → Cls.

Satisfaction Principle: The meaning of the world crucially involves both
types and their particulars in classiﬁcations and infomorphisms. (This is the
transfer to satisfaction of the second principle of Information Flow [1].)

4

Robert E. Kent

This principle motivates the use of structures (via satisfaction) as the interpreta-
tive objects (for the local logics that incorporate the regularities of a distributed
system) and the use of structure morphisms (via truth invariance) as the in-
terpretative morphisms (for the morphisms of local logics that incorporate the
information ﬂow of regularities of a distributed system).

2.3 Core Heterogeneity

Core Principle: The architecture of the world description is concentrated in a
2-dimensional diagram of core indexed categories.

Being a classiﬁcation relation, satisfaction induces order. The intent of a struc-
ture M ∈ |struc|(Σ) is the theory M Σ = {s ∈ sen (Σ) | M |=Σ s}, the set of all
sentences that are satisﬁed by M ; that is, the set of all theorems of M . This is
called the (maximal) theory of the structure M and denoted be max (M ) = M Σ.
Structures are ordered by intent: two structures M1, M2 ∈ |struc|(Σ) are or-
dered M1 ≤Σ M2 when M Σ
2 ; that is, when M2 |=Σ s implies M1 |=Σ s for
all sentences s ∈ sen(Σ). This implies the condition, if M1 ≤Σ M2 and M2 |=Σ s
then M1 |=Σ s, a bimodular condition stating that satisfaction respects the order
on structures. Since preservation of satisfaction forms an infomorphism out of
the structure and sentence maps, the structure map lifts to a monotonic function:
struc(σ) : hstruc(Σ2), ≤Σ2i → hstruc(Σ1), ≤Σ1i for any language morphism
σ : Σ1 → Σ2. This means that the structure functor lifts to an indexed preorder
(hence, category) struc

ˆ♭ : Langop → Pre ⊆ Cat with struc

1 ⊇ M Σ

ˆ♭ ◦ | - | = |struc|.

1 ⊆ T Σ

For any language Σ, a theory is a subset of sentences T ∈ ℘sen(Σ). Satis-
faction lifts to theories: a structure satisﬁes a theory M |=Σ T when it satisﬁes
every sentence in it; then T is said to be valid in M . A theory T entails a sen-
tence s, T ⊢Σ s, when any structure that satisﬁes T also satisﬁes s. The extent
of a theory T Σ is the set of all structures that satisfy it. The closure of a the-
ory is the set of all entailed sentences — the intent of the extent T • = T ΣΣ.
Theories are ordered (entailment) by extent: two theories T1, T2 ∈ ℘sen(Σ) are
ordered T1 ≤Σ T2 when T Σ
2 . This implies the bimodular condition, if
M |=Σ T1 and T1 ≤Σ T2 then M |=Σ T2, which states that satisfaction respects
entailment order. The sentence functor extends to theories in two adjoint ways.
There is a direct image functor (dual indexed preorder) dir : Lang → Pre; any
language Σ is mapped to the entailment preorder th(Σ) = h℘sen(Σ), ≤Σi of
all theories built upon it, and any language morphism σ : Σ1 → Σ2 is mapped
to the theory direct image monotonic function dir (σ) : th(Σ1) → th(Σ2); there
is a related functor lift : Cls → Cls that lifts the direct image functor on Set.
There is an inverse image functor (indexed preorder) inv : Langop → Pre; any
language Σ is mapped to the entailment preorder th(Σ), and any language mor-
phism σ : Σ1 → Σ2 is mapped to the theory inverse image monotonic function
inv (σ) : th(Σ2) → th(Σ1).

Structures and theories can be embedded monotonically as concepts in the
concept lattice of satisfaction [2]. Due to these embeddings, the intent order on

Information Flow in Logical Environments

5

structures and the entailment order on theories are special cases of the lat-
tice order of the satisfaction concept lattice. The concept lattice order is a
generalization-specialization order with the more general concepts above and
the more special concepts below. The ﬁber order of stuctures (theories) is the
opposite of the intent (entailment) order on structures (theories) induced by
the satisfaction concept lattice. Composition with the opposite preorder involu-
tion ∝ : Pre → Pre gives the structure involuted indexed preorder struc♭ =
ˆ♭ ◦ ∝ : Langop → Pre and the theory inverse image involuted indexed
struc
preorder inv ∝ = inv ◦ ∝ : Langop → Pre. The structure involuted indexed
preorder gives a heterogeneous representation of a ﬂat world.

2.4 Flat Structures

Associated (homogenization) with the structure involuted indexed preorder struc♭
is the (ﬂattened) structure ﬁbration lang ♭ : Struc♭ → Lang deﬁne as fol-
lows. Struc♭, the category of (ﬂat) structures and (ﬂat) structure morphisms,
is the Grothendieck construction of struc♭. A (ﬂat) structure hΣ, M i consists
of a language Σ and a Σ-structure M ∈ struc(Σ) (so that lang(M ) = Σ).
A (ﬂat) structure morphism σ : hΣ1, M1i → hΣ2, M2i is a language mor-
phism σ : Σ1 → Σ2 that preserves constraints (theorems): M1 |=Σ1 s1 im-
plies M2 |=Σ2 sen (σ)(s1). Equivalently, a (ﬂat) structure morphism is an lan-
guage morphism whose structure component maps the target structure to a
specialization of the source structure struc(σ)(M2) ≤Σ1 M1 or (intentwise, us-
ing theories) struc(σ)(M2)Σ1 ≤Σ1 M Σ1
1 Equivalently, a (ﬂat) structure mor-
phism is an language morphism whose inverse image sentence component maps
the target structure intent to a specialization of the source structure intent
sen(σ)−1(M Σ2
1 . This gives a homogeneous representation of a ﬂat
world, the ﬁber ﬂattening of the category Struc. The (ﬂattened) language func-
tor lang ♭ is the projection, which maps an object hΣ, M i to its indexing language
Σ and maps a morphism σ : hΣ1, M1i → hΣ2, M2i to its indexing language mor-
phism σ : Σ1 → Σ2. This is a ﬁbration. For any language Σ, the identity language
morphism 1Σ : Σ → Σ is a (ﬂat) structure morphism 1Σ : hΣ, M1i → hΣ, M2i
iﬀ M1 ≥Σ M2.

2 ) ≤Σ1 M Σ1

Bimodular Principle: The description of the world factors through ﬂat
structures. Satisfaction is bimodular; that is, satisfaction respects structure
morphisms.

We assume that the language ﬁbration factors lang = ﬂat ◦ lang ♭ through
the ﬂattened language ﬁbration lang ♭ : Struc♭ → Lang by way of a struc-
ture ﬂattening functor ﬂat : Struc → Struc♭. This means the following: For
any structure M , if lang (M ) = Σ then ﬂat (M ) = hΣ, M i. For any struc-
ture morphism f : M1 → M2, if lang(f : M1 → M2) = σ : Σ1 → Σ2, then
ﬂat (f : M1 → M2) = σ : hΣ1, M1i → hΣ2, M2i. Hence, M1 ≥Σ1 struc(σ)(M2);
equivalently, M1 |=Σ1 s1 implies M2 |=Σ2 sen(σ)(s1) (or struc(σ)(M2) |=Σ1 s1)
for every sentence s1 ∈ sen (Σ1). This implies the condition, if f : M1 → M2 is

6

Robert E. Kent

a structure morphism and M1 |=Σ1 s1 then M2 |=Σ2 sen(σ)(s1), a bimodular
condition stating that satisfaction respects structure morphisms. In particular, if
f : M1 → M2 is a vertical structure morphism over language Σ, then M1 |=Σ s
implies M2 |=Σ s for any sentence s ∈ sen (Σ); that is, M1 ≥Σ M2. Hence, the
(ﬂat) structure ﬁber over Σ is the underlying preorder of the structure ﬁber.

2.5 Theories

Associated (homogenization) with the theory inverse image involuted indexed
preorder inv ∝ is the theory ﬁbration lang : Th → Lang deﬁne as follows.
Th, the category of theories and theory morphisms, is the Grothendieck con-
struction of inv ∝. A theory hΣ, T i consists of a language Σ and a Σ-theory
T ∈ ℘sen(Σ). A theory morphism σ : hΣ1, T1i → hΣ2, T2i is a language mor-
phism σ : Σ1 → Σ2 that maps the target theory to a specialization of the
source theory inv (σ)(T2) = sen(σ)−1(T •
2 ) ⊇ T1 iﬀ
sen(σ)−1(T •
1 ; or that preserves entailment, T1 ⊢Σ1 t1 implies T2 ⊢Σ2
sen(σ)(t1) for any t1 ∈ sen (Σ1). Equivalently, a theory morphism is an lan-
guage morphism that maps the source theory to a generalization of the target
theory T2 ≤Σ2 dir (σ)(T1) = ℘sen (σ)(T1) iﬀ T •
2 ⊇ ℘sen(σ)(T1). The projec-
tion ﬁbration lang : Th → Cls maps a theory hΣ, T i to the language Σ and
maps a theory morphism σ : hΣ1, T1i → hΣ2, T2i to the language morphism
σ : Σ1 → Σ2. For any language Σ, the identity language morphism 1Σ : Σ → Σ
is a (vertical) theory morphism 1Σ : hΣ, T1i → hΣ, T2i iﬀ T1 ≥A T2. Hence, the
theory ﬁber at language Σ is the opposite of the entailment theory preorder.

2 ) ≤Σ1 T1 iﬀ sen (σ)−1(T •

2 ) ⊇ T •

2.6 Logical Environments

In summary, a logical environment (Figure 1) is a more semantic version of
an institution. It has both semantical and logical aspects. The semantical as-
pect is represented by a category of structures Struc (the world) with a ﬁ-
bration lang : Struc → Lang (the world description) from structures into
a category of logical languages Lang; or equivalently, an indexed category of
structures struc : Langop → Cat with underlying indexed set |struc| =
struc ◦ |-| : Langop → Set. The logical aspect is represented by a dual in-
dexed set of sentences sen : Lang → Set. The semantical aspect is connected
to the logical aspect via a functor cls : Lang → Cls, with instance projec-
tion cls op ◦ inst = |struc| and type projection cls ◦ typ = sen. Structures
and sentences are linked by satisfaction M |=Σ s, with truth preserved under
change of notation struc(M2) |=Σ1 s1 iﬀ M2 |=Σ1 sen(s1). The concept or-
der of satisfaction extentionally lifts to the (ﬂat) structure indexed preorder
struc♭ : Langop → Pre and intentionally lifts to the theory direct image dual
indexed preorder dir : Lang → Pre and (adjointly) to the theory inverse image
indexed preorder inv : Langop → Pre. The (ﬂat) structure indexed preorder
is equivalent (homogenization ↔ heterogenization) to the (ﬂattened) structure
ﬁbration (the ﬂattened world) lang ♭ : Struc♭ → Lang, such that description

Information Flow in Logical Environments

7

Log♭
✡
❏
pr 0

max

Log

✲
ﬂat

✡

pr 0
✡
✡✢

✲
ﬂat

Struc

lang

pr 1

✡
✡✢

Struc♭
❏
lang ♭

❏
❏❫

pr 1
❏
❏❫
③
✲

Th

✡
lang

✡
✡✢

③

Lang

| - |

✲
✚❃

✚

sen
✚
✚
cls

Cat
✻

sen

Lang

✲

Cls

Set
✻
typ

Langop

cls op

✲

Clsop

struc

struc

=⇒
◆
✌
Cat

|struc|

❩❩
struc ♭

❩
❩⑦
✲

| - |

inst
❄
Set

ﬁbration

heterogenization✲
✛
homogenization

indexed category

Fig. 1. Logical Environment

factors through ﬂat structures lang = ﬂat ◦ lang ♭. Either the theory direct im-
age dual indexed preorder or the theory inverse image indexed preorder induce
the theory ﬁbration (the logical aspect) lang : Th → Lang. The crucial facts
linking the semantical aspect of structures to the logical aspect of theories via
satisfaction are (1) that the indexed set of structures is the instance projection of
the classiﬁcation functor and (2) that description factors through ﬂat structures.

2.7 Examples

We use the three logical environments of equational logic EQ, ﬁrst order logic FOL
and information ﬂow IFC as running examples. The world (structure category)
of EQ consists of universal algebriac structures, that of FOL consists of ﬁrst order
logical structures, and that of IFC consists of classiﬁcations and infomorphisms.

Example. The logical environment IFC has StrucIFC = Cls as its category of
structures, LangIFC = Set as its category of languages, and the type functor
lang IFC = typ : Cls → Set as its projection. For any set Y , the set struc IFC(Y )
of Y -structures is the set of classiﬁcations with type set Y , the set sen IFC(Y ) of Y -
sentences is the set of Y -sequents, pairs Γ ⊢ ∆ of subsets of types Γ , ∆ ⊆ Y , and
a Y -classication hX, Y, |=i satisﬁes a Y -sequent Γ ⊢ ∆, denoted hX, Y, |=i |=Y
(Γ ⊢ ∆), when for all instances x ∈ X, x |= y for all y ∈ Γ implies x |= y′ for some
y′ ∈ ∆. For each function (language translation) f : Y → Z, sentence translation
along f is direct image squared on types sen IFC(f ) : sen IFC(Y ) → sen IFC(Z) :
(Γ ⊢ ∆) 7→ (℘f (Γ ) ⊢ ℘f (∆)), and structure translation along f , struc IFC(f ) :
struc IFC(Z) → struc IFC(Y ), maps a Z-classiﬁcation C = hX, Z, |=i to the Y -
classiﬁcation struc IFC(f )(C) = hX, Y, |=f i, where x |=f y when x |= f (y). The
classiﬁcation functor cls IFC
: Set → Cls maps a set Y to the classiﬁcation

8

Robert E. Kent

cls IFC(Y ) = hstruc IFC(Y ), sen IFC(Y ), |=Y i, and maps a function f : Y → Z to the
infomorphism cls IFC(f ) = hstruc IFC(f ), sen IFC(f )i : cls IFC(Y ) ⇀↽ cls IFC(Z). The
logical environment IFC is a subenvironment of FOL when types are regarded as
unary relation symbols.

Example. The logical system of equational logic (universal algebra) is repre-
sented by the logical environment EQ. The language category is LangEQ = Setℵ,
the ℵth power of Set. A language Φ is a family Φ = {Φn | n ∈ ℵ} of sets of
function symbols, and a language morphism φ : Φ → Φ′ is a family {φn : Φn →
Φ′
n | n ∈ ℵ} of arity-preserving maps of function symbols. For any language
Φ, the set sen EQ(Φ) is the set of equations between Φ-terms of function sym-
bols. For any language morphism φ : Φ → Φ′, the sentence translation function
sen EQ(φ) : sen EQ(Φ) → sen EQ(Φ′) is deﬁned by function symbol substitution.
A Φ-structure A ∈ struc EQ(Φ) is a Φ-algebra, consisting of a set (universe) A
and a function (operation) fA : An → A for each function symbol f ∈ Φn.
A Φ-structure morphism in struc EQ(Φ) is a Φ-algebra morphism, consisting of a
function (between universes) a : A → A′ that preserves operations fA·a = an·fA′
for each function symbol f ∈ Φn. Structure translation is reduct with symbol
translation. Satisfaction is as usual.

Example. The logical system of unsorted ﬁrst-order logic with equality is repre-
sented by the logical environment FOL. This extends the logical environment of
equational logic by adding relation symbols. The language category is LangFOL =
Setℵ×Setℵ ∼= Setℵ+ℵ ∼= Setℵ, the square of the ℵth power of Set. A language
hΦ, Ψ i is a family Φ as above, plus a family Ψ = {Ψn | n ∈ ℵ} of sets of re-
lation symbols of arity n. A language morphism hφ, ψi : hΦ, Ψ i → hΦ′, Ψ ′i is a
family φ as above, plus a family ψ : Ψ → Ψ ′ of arity-preserving maps of re-
lation symbols. Sentences are the usual ﬁrst order sentences. For any language
hΦ, Ψ i, the set sen FOL(Φ, Ψ ) of hΦ, Ψ i-sentences consists of closed ﬁrst-order for-
mulae using function symbols from Φ and relation symbols from Ψ . For any
language morphism hφ, ψi : hΦ, Ψ i → hΦ′, Ψ ′i, the sentence translation function
sen FOL(φ, ψ) : sen FOL(Φ, Ψ ) → sen FOL(Φ′, Ψ ′) is deﬁned by symbol substitution.
A hΦ, Ψ i-structure A ∈ struc FOL(Φ, Ψ ) is a Φ-algebra A (as above) and a sub-
set RA ⊆ An for each relation symbol R ∈ Ψn. A hΦ, Ψ i-structure morphism
in struc EQ(Φ) is a Φ-algebra morphism (as above), which preserves relations
℘an(RA) ⊆ RA′ for each relation symbol R ∈ Ψn. Structure translation is reduct
with symbol translation. Satisfaction is as usual. The institution FOL can be
extended to the institution FOL∗, which replaces language maps with language
interpretations hφ, ψi : hΦ, Ψ i → hΦ′, Ψ ′i mapping function symbols to terms of
the same arity {φn : Φn → term(Φ′)n | n ∈ ℵ} and mapping relation symbols
to expressions of the same arity {ψn : Ψn → expr (Ψ ′)n | n ∈ ℵ}.

Example. The category Set⊆ has subsets Y ⊆ X as objects and restrictions (g ⊆
f ) : (Y1 ⊆ X1) → (Y2 ⊆ X2) as morphisms, where f : X1 → X2 is a function and
g : Y1 → Y2 is a restriction of f . The category Cls⊆ has Set⊆ as its component
instance category and Set as its component type category. An object hY, Ai

Information Flow in Logical Environments

9

in Cls⊆ consists of a classiﬁcation A and a subset of instances Y ⊆ inst(A).
A morphism hg, f i : hY1, A1i ⇀↽ hY2, A2i in Cls⊆ consists of an infomorphism
f : A1 ⇀↽ A2 and a restriction g : Y2 → Y1 of the instance function inst(f ).
The logical environment IFS has LangIFS = Set as its category of languages,
StrucIFS = Cls⊆ as its category of structures, and lang IFS = typ : Cls⊆ → Set
as its language index functor. This logical environment allows the deﬁnition of
a normal subset of instances.

3

Information Flow

3.1 Distributed Systems

System Principle: Information ﬂow results from regularities in a distributed
system. (This is the ﬁrst principle of Information Flow [1].)

This principle motivates the representation of distributed systems by diagrams
of objects that can incorporate regularities. Eventually, we will argue that these
objects should be local logics.

✛

semantic
alignment
constraint

distributed

✲

system

(alignment

diagram) ✲

✚

r
r

✘

✙

r
r

colimit

refinement

❄

core

category of

theories (or logics)

◗

optimal
channel

◗
✑

✑
◗

❄
✑

channel

✲
✑✸

✑
◗◗s
✲

Fig. 2. Distributed System

The semantic integration of ontologies [7], [4] can be represented by align-
ment and uniﬁcation (Figure 2): aligning a distributed system of ontologies by
building a suitable diagram of logics and unifying the distributed system of on-
tologies along a channel covering the underlying diagram of structures. The logics
in the alignment diagram represent the individual ontologies, and the morphisms
between logics in the alignment diagram represent the semantic alignment con-
straints. An example of semantic alignment constraints is the representation
of an equivalent pair of types in two ontologies being aligned by a single type
in a mediating ontology, with two mappings from this mediating type back to
the equivalent pair of types. The alignment diagram represents a semantically
constrained distributed system of ontologies, with individual logics representing
parts of the system. Any covering channel over the underlying diagram of struc-
tures has a core that represents the whole system in some respect. Uniﬁcation

10

Robert E. Kent

forms a covering channel of logics that connects the distributed system to the
fusion logic — the meet, in the logic ﬁber over the underlying core, of the direct
image of the diagram of logics along the underlying channel of structures.

Structure Principle: Information ﬂow crucially involves structures of the
world. (This is the second principle of Information Flow [1], abstracted from
classiﬁcations to structures. A classiﬁcation is just one example of a structure.)

This principle motivates the use of structures as the indexing objects for the
(local) logics that incorporate the regularities of a distributed system and the use
of structure morphisms as the indexing links for the morphisms of (local) logics
that incorporate the information ﬂow of regularities of a distributed system.

A distributed system A : I → Struc consists of an indexed family {Ai | i ∈
|I|} of structures together with an indexed family {Ae : Ai → Aj | (e : i →
j) ∈ I} of structure morphisms; that is, a distributed system is a diagram in the
structure category Struc. We think of the component structures Ai as being
parts the the system. We would also like to represent the whole system as a
structure, where we might have diﬀerent representative structures for diﬀerent
purposes. The theory of part-whole relations is called mereology. It studies how
parts are related to wholes, and how parts are related to other parts within a
whole. In a distributed system, the part to part relationships are modeled by
the structure morphisms Ae : Ai → Aj. In Information Flow, we can model the
whole as a structure C and model the part-whole relationship between some part
A and the whole with a structure morphism g : A → C.

3.2 Information Channels

g
An information channel C : A
⇒ ∆(C) over a world (category of structures)
Struc consists of an I-indexed family C = {gi : Ai → C}i∈I of structure mor-
phisms with a common target structure C, called the core of the channel. A
g
⇒ ∆(C) covers a distributed system A : I → Struc when
channel C : A
I = |I| and the channel component morphisms commute with the distributed
gj→ C for e : i → j in I. A cover-
system morphisms Ai
g
ing channel C : A
⇒ ∆(C) is essentially a cocone over diagram A. For any
h
two covering channels C : A
⇒ ∆(D) over the same dis-
tributed system A, a reﬁnement (mediating morphism) is a structure morphism
between cores r : C → D that commutes with the channel component mor-

g
⇒ ∆(C) and D : A

gi→ C = Ai

Ae→ Aj

gi→ C

r
→ D = Ai

hj→ C for i ∈ |I|. A channel Copt : A

phisms Ai
a minimal cover of a distributed system A when it covers A and for any other

⇒ ∆(` A) is
covering channel D there is a unique reﬁnement [D] : ` A → D from Copt to

D. A minimal cover is essentially a colimiting cocone over diagram A. Any two
minimal covers are isomorphic.

ι

Information ﬂow has two concerns with respect to channels: (1) given a dis-
tributed system and some viewpoint (scientiﬁc, technological, social, etc.), how
should the whole system be modeled; and (2) how does the natural logic of one

Information Flow in Logical Environments

11

component part of a system aﬀect another component part. The ﬁrst concern,
realizing a channel core, can have several solutions. An optimal solution, the col-
imit, is discussed in the section on cocompleteness and cocontinuity. The second
concern, involving distributed inference rules, local logics and information ﬂow,
is discussed in other succeeding sections.

Connection Principle: It is by virtue of regularities among connections that
information about some components of a distributed system carries information
about other components. (This is the third principle of Information Flow [1].)

gi→ C

This principle motivates the use of logics over structures, which lift theories over
languages, to represent information ﬂow over covering channels of a distributed
system. For a simple example of information ﬂow, consider two component parts
gj← Aj with underlying language morphisms γi and γj that are connected
Ai
to the core structure C by being essentially projections Ai ∼= struc(γi)(C) and
struc(γj)(C) ∼= Aj. Then Ai’s satisfying sentence ai carries the information that
Aj satisﬁes sentence aj, relative to the channel C, if the translation sen (γi)(ai)
entails the translation sen (γj)(aj ) in the theory max (C).

3.3 Inference Rules

In the section we paraphrase the discussion in the ﬁrst part of [1]. To see how
unsound and incomplete logics arise in reasoning about distributed systems, we
consider the diagram

p

−→ C

d

←− D

P

called a binary channel. This consists of a proximal structure P a distal structure
D and a connecting structure C. We think of this binary channel as representing
a distributed system having proximal part P , distal part D and whole (or core)
C.

We are interested in discovering what kind of theory of the distal part is
available to someone with complete knowledge of the proximal part. The diagram
suggests breaking the problem up into two parts, the problem of going directly
along p from proximal component P to core component C, and the problem of
going inversely along d from core component C to distal component D. We can
discuss both steps at once by considering a single structure morphism f : M1 →
M2 (in the above, f can be either p : P → C or d : C → D). Image someone who
wants to reason about one side by using the induced theory of the other side.

Consider the following “rules of inference” along an structure morphism f :
M1 → M2 with underlying language morphism lang (f ) = σ : Σ1 → Σ2. The
ﬁrst says that from any source sentence s1 ∈ sen(Σ1) we can infer the target
sentence sen (σ)(s1) ∈ sen(Σ2). The second is read similarly.

f -Intro:

s1

sen(σ)(s1)

f -Elim:

sen(σ)(s1)

s1

12

Robert E. Kent

The ﬁrst rule allows us to move along the structure morphism f from a source
sentence to a target sentence, whereas the second rule allows us to move in the
opposite direction. These inference rules have very important properties. First
consider the preservation of validity and nonvalidity.

A rule preserves validity when it leads from premise constraints to conclu-
sion constraints. The f -Intro rule preserves validity: if the premise s1 is valid
in M1, M1 |=Σ1 s1, then the conclusion sen (σ)(s1) is valid in M2, M2 |=Σ2
sen(σ)(s1). This follows immediately from the deﬁnition of structure morphism.
The f -Elim rule does not preserve validity. It is possible to have a constraint
sen(σ)(s1) of M2, M2 |=Σ2 sen(σ)(s1), such that s1 has counterexample M1,
M1 6|=Σ1 s1. However, M1 is not a counterexample of s1 if M1 is a specialization
of struc(σ)(M2), M1 ≤Σ1 struc(σ)(M2); that is, the f -Elim rule is sound when
M1 ∼=Σ1 struc(σ)(M2). In particular, the f -Elim rule preserves validity along
structure-isomorphic structure morphisms.

A rule preserves nonvalidity when it leads from premise nonconstraints to
conclusion nonconstraints. The f -Elim rule preserves nonvalidity: if the premise
sen(σ)(s1) is not valid in M2, M2 6|=Σ2 sen(σ)(s1), then the conclusion s1 is
not valid in M1, M1 6|=Σ1 s1. This also follows immediately from the deﬁnition of
structure morphism. The f -Intro rule does not preserve nonvalidity. It is possible
that s1 has counterexample M1, M1 6|=Σ1 s1, where sen(σ)(s1) is a constraint
of M2, M2 |=Σ2 sen (σ)(s1). However, sen(σ)(s1) is not a constraint of M2 if
M1 is a specialization of struc(σ)(M2), M1 ≤Σ1 struc(σ)(M2); that is, the rule
preserves nonvalidity when M1 ∼=Σ1 struc(σ)(M2). In particular, the f -Intro
rule preserves nonvalidity along structure-isomorphic structure morphisms.

Summarizing the above, the rule of f -Intro preserves validity, but not non-
validity; whereas, the rule of f -Elim preserves nonvalidity, but not validity. In
terms of distributed systems, when using the f -Intro rule any constraint that
holds for a component translates directly to a constraint about the whole system,
and when using the f -Elim rule any constraint about the whole system trans-
lates inversely to a constraint of those parts that really are (up to isomorphism)
a component of the system structure. Returning to the binary channel

p

−→ C

d

←− D

P

depicted previously, we wanted to know what happens when we use the sound
and complete theory max (P ) = {s ∈ sen (ΣP ) | P |=ΣP s} of the proximal
structure to reason about the distal structure. On the one hand, we have seen
that p-Intro preserves validity, but not nonvalidity; so that the theory we obtain
at C may be sound (any constraint of P maps to a constraint of C), but not
necessarily complete (we may have no sentence or only nonvalid sentences of P
mapping to a particular constraint of C — there may be constraints of C that are
missed). On the other hand, following p-Intro by d-Elim means that we lose our
guarantee that the resulting distal theory is either sound or complete. A sentence
about the distal structure obtained from a sentence about the proximal structure
in this way is guaranteed to apply when the distal structure is connected (up to
isomorphism) to the proximal structure in the channel.

Information Flow in Logical Environments

13

⊤ = hΣ, M, ∅i = ⊤

r

log (M) = hΣ, M, max (M)i

❏❏

✡✡

sound

❏
✡

r

✡
❏

❏

✡

✡

❏

✡✡

complete

❏❏

r

⊥ = hΣ, M, ℘sen (Σ)i

pr 2
✲

Th

Log
✻

log

struc
= pr 1
❄
✲
Struc
lang

✡

lang
❄
Lang

th

(cid:27) ﬁbrations

✻
homogenization

heterogenization
✲
dir

Pre

❄

(cid:27) indexed categories

✠✻

fbr (M )op

∼=

fbr (Σ)op




Fig. 3. The Logic Context

3.4 Local Logics

Channel Principle: The regularities of a given distributed system are relative
to its analysis in terms of information channels. (This is the fourth principle of
Information Flow [1].)

Paraphrasing and quoting [1] (Lecture 12), when “reasoning about a distributed
system with component” parts of various kinds, the component parts will typ-
ically be describe in quite diﬀerent ways with diﬀerent languages. Along with
these diﬀerent languages “it is natural to think of each of the components as hav-
ing its own logic”, expressed in its own language. “In this way, the distributed
system” of structures “gives rise to a distributed system of local logics. The in-
teractions of the local logics reﬂect the behavior of the system as a whole.” The
concept of a (local) logic represents the regularities of a distributed system and
tracks what happens when we reason at a distance.

A (local) logic L = hΣ, M, T i consists of an indexing language Σ, a Σ-
structure M ∈ struc(Σ) and a Σ-theory T ∈ th(Σ). For any ﬁxed structure
M with underlying language Σ, the set of all logics with that structure is a
preordered set under the theory order: hΣ, M, T1i ≤ hΣ, M, T2i when T1 ≤ T2.
This is the (opposite of the) ﬁber over M with respect to the logic-to-structure
projection functor struc. There are larger ﬁbers. For any ﬁxed language Σ,
the set of all logics with that language is a preordered set under the structure
and theory orders: hΣ, M1, T1i ≤ hΣ, M2, T2i when M1 ≤Σ M2 and T1 ≤Σ T2.
This is the (opposite of the) ﬁber over Σ with respect to the composite functor
struc ◦ lang. Any structure M with underlying language Σ induces the natural
logic log (M ) = hΣ, M, max (M )i = hΣ, M, M Σi. If two structures are ordered
M1 ≤Σ M2, then their logics are ordered log (M1) ≤Σ log(M2), since M1 ≤Σ M2
iﬀ M Σ

1 ⊇ M Σ

2 iﬀ M Σ

1 ≤Σ M Σ
2 .

A logic morphism f : hΣ1, M1, T1i → hΣ2, M2, T2i is a structure morphism
f : M1 → M2, whose underlying language morphism σ : Σ1 → Σ2 is also a theory
morphism σ : hΣ1, T1i → hΣ2, T2i. The category of logics Log has logics as ob-
jects and logic morphisms as morphisms. It is describable (Figure 3) as either the
pullback of the indexing functors for structures and theories, or the Grothendieck

14

Robert E. Kent

2 ⊇ ℘sen (σ)(M Σ1

construction of the dual indexed preorder th = lang ◦ dir : Struc → Pre.
The projection functors struc = pr 1 : Log → Struc and pr 2 : Log → Th
satisfy the pullback condition pr 1 ◦ lang = pr 2 ◦ lang . The ﬁrst pullback
projection is the ﬁbration associated (homogenization) with the dual indexed
preorder th : Struc → Pre. This pullback projection is the structure lift of
the theory indexing functor lang : Th → Lang. The second pullback projec-
tion is the theory lift of the structure indexing functor lang : Struc → Lang.
Any structure morphism f : M1 → M2, with underlying language morphism
σ : Σ1 → Σ2, induces the logic morphism f : log (M1) → log (M2) between
natural logics. This is well-deﬁned, since validity-preservation is equivalent to
M Σ2
1 ). Hence, there is a functor log : Struc → Log (Figure 3)
satisfying log ◦ base = 1Struc. A local logic hΣ, M, T i in the ﬁber over M does
not compare to the natural logic log (M ), unless it is either sound or complete.
In general, logics may be neither sound nor (logically) complete. A logic
hΣ, M, T i is sound when the structure M satisﬁes the theory T (T is valid in
M ), M |=Σ T ; equivalently, when M Σ ⊇ T or M Σ ⊇ T • or M Σ ≤Σ T . A logic
hΣ, M, T i is complete when every sentence satisﬁed by M is entailed by T ; that
is, when M |=Σ t implies T ⊢Σ t for all sentences t ∈ sen(Σ); equivalently,
when T • ⊇ M Σ or T ≤Σ M Σ; equivalently, when T 6⊢Σ t implies M 6|=Σ t for
all sentences t ∈ sen(Σ). A logic hΣ, M, T i is sound (complete) iﬀ the identity
(ﬂat) structure morphism 1M : M → M with underlying identity language mor-
phism 1Σ : Σ → Σ is a logic morphism ηhΣ,M,T i = 1M : hΣ, M, T i → log (M )
(εhΣ,M,T i = 1M : log (M ) → hΣ, M, T i). The only sound and complete logics
are those equivalent to the natural logic log(M ) for some structure M . Sound
logics form a reﬂective subcategory of all logics Snd ⊆ Log with unit natu-
ral transformation η : 1Snd ⇒ struc ◦ log . Complete logics form a coreﬂec-
tive subcategory of all logics Cmp ⊆ Log with counit natural transformation
ε : log ◦ struc ⇒ 1Cmp.

3.5 Colimits

Completeness/continuity Principle: The world is cocomplete and the
description of the world is cocontinuous.

We assume the logical environment (Figure 1) is cocomplete. This means that it
has a cocomplete category of structures Struc, a cocomplete category of logical
languages Lang, and a cocontinuous ﬁbration lang : Struc → Lang. Hence, all
colimits (universal constructions) of structures and languages are possible, and
the underlying language of the colimit of a diagram of structures is the colimit of
the underlying diagram of languages. All the examples of logical environments
(IFC, EQ, FOL) are cocomplete.

In approach advocated here, unpopulated ontologies (no world information
and no semantics) are represented by theories and the optimal semantic inte-
gration of unpopulated ontologies is represented by the colimit construction of
theories, whereas populated ontologies (both world information and semantics)
are represented by logics, and the optimal semantic integration of populated

Information Flow in Logical Environments

15

ontologies is represented by the colimit construction of logics. Colimits in the
category of theories (logics) can be used to fuse together smaller theories (logics)
to form larger ones. The colimit construction in the category of theories (logics)
forms an optimal channel Copt : A
formed by information ﬂow over the optimal channel: direct image ﬂow followed
by meet in the lattices of theories (logics). The colimit construction is based
upon the colimit theorem, a powerful, general criterion for when such colimits of
theories actually exist. It allows us to use for semantic integration, the same ﬂow
and lattice operators on logics-over-models as we do for theories-over-languages.

⇒ ∆(`A). The fusion theory (logic) `A is

ι

Theorem 1. (Cocompleteness/Cocontinuity) [5] For any logical environment,
the projection functors lang : Struc♭ → Lang and lang : Th → Lang reﬂect
colimits. Hence, if the logical environment is cocomplete, then its category Struc♭
of (ﬂat) structures and structure morphisms and its category Th of theories and
theory morphisms are cocomplete and the projection functors are cocontinuous.

When the structure category Struc is cocomplete, information ﬂow in a
g
channel C : A
⇒ ∆(C) covering a distributed system A can be factored through
information ﬂow in the optimal channel followed by direct image along the unique

mediating structure morphism `A

3.6 Information Flow

m
→ C.

Information ﬂow over a channel is deﬁned as a two-step process: direct image
ﬂow along the component structure morphisms of the channel, followed by the
meet operation in the lattice of logics over the core.

Given a structure morphism f : M1 → M2 with underlying language mor-
phism σ : Σ1 → Σ2 and a source logic L1 = hΣ1, M1, T1i, the direct image is
the target logic dir (f )(L1) = hΣ2, M2, ℘sen(σ)(T1)i. The direct image is the
greatest logic L2 on the target structure M2 such that f is a logic morphism from
L1 to L2; that is, f : L1 → dir (f )(L1) is a logic morphism; and if f : L1 → L2
is a logic morphism, then L2 ≤ dir (f )(L1).

Proposition 1. For any structure morphism f : M1 → M2, direct image pre-
serves soundness: if a source logic L1 is sound, then the direct image logic
dir (f )(L1) is also sound.

Proof: Assume the source logic hΣ1, M1, T1i is sound. This means that M Σ1
1 ≤Σ1
T1 (sentences inside the closure T •
1 are valid). Since f : M1 → M2 is an structure
morphism, with the underlying language morphism struc(f ) = σ : Σ1 → Σ2,
struc(σ)(M2)Σ1 ≤Σ1 M Σ1
1 . Thus, struc(σ)(M2)Σ1 ≤Σ1 T1. By satisfaction in-
variance, struc(σ)(M2)Σ1 ≤Σ1 T1 iﬀ M Σ2
2 ≤Σ2 ℘sen(σ)(T1), this means that
the direct image dir (f )(L1) = hΣ2, M2, ℘sen(σ)(T1)i is sound.

Given a structure morphism f : M1 → M2 with underlying language mor-
phism σ : Σ1 → Σ2 and a target logic L2 = hΣ2, M2, T2i, the inverse image is

16

Robert E. Kent

the source logic inv (f )(L2) = hΣ1, M1, sen(σ)−1(T •
2 ) =
{t1 ∈ sen (Σ1) | T2 ⊢Σ2 sen(σ)(t1)}. The inverse image is the least logic L1
on source structure M1 such that f is a logic morphism from L1 to L2; that
is, f : inv (f )(L2) → L2 is a logic morphism; and if f : L1 → L2 is a logic
morphism, then inv (f )(L2) ≤ L1.

2 )i, where sen(σ)−1(T •

Proposition 2. For any structure morphism f : M1 → M2, inverse image
preserves completeness: if a target logic L2 is complete, then the inverse image
logic inv (f )(L2) is also complete.

2 . Hence, sen (σ)−1(T •

2 ) ≤Σ1 sen (σ)−1(M Σ2

Proof. Assume target logic hΣ2, M2, T2i is complete. This means that T •
2 ≤Σ2
M Σ2
2 ). Since f : M1 → M2 is an
structure morphism with language morphism struc(f ) = σ : Σ1 → Σ2, we have
sen(σ)−1(M Σ2
1 . This means that
the inverse image inv (f )(L2) = hΣ1, M1, sen(σ)−1(T •

1 . Hence, sen (σ)−1(T •

2 ) ≤Σ1 M Σ1

2 ) ≤Σ1 M Σ1

2 )i is complete.

4 Conclusion

We have deﬁned logical environments, semantic versions of institutions, and have
demonstrated how important concepts in IF theory, such as distributed systems,
channels and information ﬂow, can be deﬁned within logical environments. Thus,
IF theory abstracts and extends INS theory.

References

1. Barwise, J., Seligman, J.: Information Flow: The Logic of Distributed Systems.

Cambridge University Press, Cambridge (1997)

2. Ganter, B., Wille, R.: Formal Concept Analysis: Mathematical Foundations.

Springer, New York (1999)

3. Goguen, J.A.: Data, schema, ontology and logic integration. Log. Jrnl. IGPL. vol.

13, pp. 685–715. Oxford University Press (2005)

4. Goguen, J.: Information Integration in Institutions. Draft paper for the Jon Barwise

memorial volume edited by Larry Moss (2006).

5. Goguen, J., Burstall, R.: Institutions: Abstract Model Theory for Speciﬁcation and

Programming. J. Assoc. Comp. Mach. 39, 95–146 (1992)

6. Kent,

R.E.:

Semantic

Integration

in

the

IFF.

[http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-82/SI_paper_09.pdf]
In: Doan, A., Halevy, A., Noy, N,, (eds.) Semantic Integration 2003. CEUR Work-
shop Proceedings, vol. 82, Sun SITE Central Europe (CEUR) (2003)

7. Kent, R.E.: Semantic Integration in the Information Flow Framework. In: Kalfoglou,
Y., Schorlemmer, M., Sheth, A., Staab, S., Uschold, M. (eds.) Semantic Interoper-
ability and Integration, Dagstuhl Seminar Proceedings, vol. 04391, Dagstuhl Re-
search Online Publication Server (2005).

8. The Information Flow Framework (IFF), [http://suo.ieee.org/IFF/].

