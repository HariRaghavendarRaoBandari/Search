6
1
0
2

 
r
a

 

M
7
1

 
 
]

M

I
.

h
p
-
o
r
t
s
a
[
 
 

1
v
3
4
4
5
0

.

3
0
6
1
:
v
i
X
r
a

Optimal strategies for observation of active galactic nuclei variability

with Imaging Atmospheric Cherenkov Telescopes

Matteo Giomia, Lucie Gerarda, Gernot Maiera

aDeutsches Elektronen-Synchrotron DESY, D-15738 Zeuthen, Germany

Abstract

Variable emission is one of the deﬁning characteristic of active galactic nuclei (AGN). While pro-
viding precious information on the nature and physics of the sources, variability is often challenging
to observe with time- and ﬁeld-of-view-limited astronomical observatories such as Imaging Atmo-
spheric Cherenkov Telescopes (IACTs). In this work, we address two questions relevant for the
observation of sources characterized by AGN-like variability: what is the most time-eﬃcient way
to detect such sources, and what is the observational bias that can be introduced by the choice of
the observing strategy when conducting blind surveys of the sky. Diﬀerent observing strategies are
evaluated using simulated light curves and realistic instrument response functions of the Cherenkov
Telescope Array (CTA), a future gamma-ray observatory. We show that strategies that makes use
of very small observing windows, spread over large periods of time, allows for a faster detection
of the source, and are less inﬂuenced by the variability properties of the sources, as compared to
strategies that concentrate the observing time in a small number of large observing windows. Al-
though derived using CTA as an example, our conclusions are conceptually valid for any IACTs
facility, and in general, to all observatories with small ﬁeld of view and limited duty cycle.

Keywords: Cherenkov Telescopes, Active Galactic Nuclei, variability, gamma-ray, observation
planning, extragalactic sky survey

1. Introduction

Transient and variable emission has been observed from gamma-ray sources such as binary
systems, active galactic nuclei and gamma-ray bursts. Variability studies shed light on physical
processes responsible for the acceleration of charged particles and the photon emission in these
objects. The determination of the characteristic physical time scales for particle acceleration and
gamma-ray emission mechanisms, and their dependence on the relativistic beaming, allow us to
gain an understanding of the origin of ﬂares, and the size, structure, and location of the emission
region.
The majority of variable gamma-ray sources detected at very-high-energy (VHE, from ∼ 50 GeV
to hundreds of TeV) are active galactic nuclei (AGN), powered by supermassive black holes accreting
matter at the center of some galaxies. Most of the gamma-ray bright AGN are blazars, a subclass of
AGN characterized by the presence of two collimated outﬂows of relativistic plasma (jets), streaming

Email address: matteo.giomi@desy.de (Matteo Giomi)

Preprint submitted to Elsevier

March 18, 2016

away from the central black hole along the line of sight, so that one jet is pointed towards the
Earth [1]. Relativistic beaming of the emission of the jet enhances the luminosity of the source and
shifts it to higher energies, making these sources bright VHE emitters; in fact, blazars account for
∼ 1/3 of all the sources currently detected at these energies. Blazar emission spans through the
entire electromagnetic spectrum and it is characterized by a strong temporal variability, observed
on time scales ranging from years down to minutes.

The observation of variable emission patterns is challenging with IACTs, due to their small ﬁeld
of view and the fact that observations are limited to dark nights and good weather periods. For
these reasons, observing strategies for IACTs must be carefully optimized in order to achieve their
goal in as little time as possible. The common approach to observation planning makes use of the
sensitivity to describe the performance of the instrument and compare it to the mean or low-state
ﬂux of the sources. This approach is not optimized to plan observations of strongly variable sources
as it does not explicitly take into account the variability. In this work, variability is taken into
account by the simulation of light curves similar to those measured for AGN. Various types of
variability properties are considered. Diﬀerent observing strategies are modeled and, for each one,
the probability of detecting the sources is computed. This probability provides a measure of the
performance of the observing strategy and is used to quantitatively compare diﬀerent strategies.
Two questions that are relevant in the context of observation planning are addressed: what is
the fastest way to detect a weak, variable source with given variability characteristics, and which
observing strategies are more suited to conduct variability-unbiased, blind-sky surveys.

Our work is applied here to optimize AGN observations with the Cherenkov Telescope Array
(CTA), a future VHE gamma-ray observatory [2]. CTA will consist of 80-100 of telescopes of
three diﬀerent sizes, resulting in a ten times better sensitivity than any of the current IACT arrays
and a wide, four-orders-of-magnitude, energy range. The observation of AGN will be one of the
major goals for CTA, and simulations show that CTA will detect a large number (∼ 103) of these
objects [3].

This paper is structured as follows: Section 2 presents the simulation of AGN variability. In
Section 3, the model of the observing strategies is illustrated. Section 4 describes the method used
to compute the performance of the observing strategies for a given set of variability properties.
Finally, in Section 5 the optimal strategies to observe known sources and to conduct a blind-sky
survey are identiﬁed.

2. Simulation of VHE AGN variability

The variability of a source is usually presented through its light curve, showing the ﬂux in a
given energy band as a function of time. VHE AGN light curves appear aperiodic. Flux variations
down to the timescale of minutes have been observed for the brightest sources such as Mkn 421 [4],
PKS 2155-304 [5], and Mkn 501 [6].

As of today, little information is available on the temporal properties of VHE AGN light curves.
To attempt a description of the variability characteristics of the whole class of AGN, data collected
at other wavelengths have to be considered. In particular we will refer to results from the Fermi
Large Area Telescope (LAT) [7], observing the sky in the high-energy (HE, from tens of MeV
to hundreds of GeV) band. By doing this we assume that variability properties observed in the
HE band are representative of those in VHE. This working assumption might be supported since
similar physical phenomena could be responsible for the emission in these two adjacent energy
bands. However, it is worth stressing that the light curves we simulate are meant only to give a

2

good representation of the available data; no attempt is made here to a detailed model of VHE
AGN variability.

Fourier analysis is one of the most common and powerful tools used to characterize time series.
Referring to its properties in the frequency domain, AGN variability is often described as power-law
noise, i.e. the Power Spectral Density (PSD) of AGN light curves is well reproduced by a power-law
function of the frequency ν, P (ν) ∝ ν−β, over a wide range of frequencies. Fourier spectral analysis
has been performed on a sample of 156 BL Lacs and 56 Flat Spectrum Radio Quasars (FSRQs) in
the second Fermi LAT AGN catalog (2LAC) [8]. In this case monthly binned light curves of the
integral ﬂux above 100 MeV are used, ﬁnding β ∼ 1.15± 0.1 for both source classes in the frequency
−1. Similar analysis performed on a smaller sample of bright sources (22
range [0.033, 0.5] month
FSRQs and 6 BL Lacs) for which three- and four-days binned light curves could be produced, lead
to values of β of 1.7 and 1.5 for BL Lacs and FSRQs respectively [9]. In the VHE energy domain
the only case in which Fourier analysis of the light curve has been performed is the PKS 2155-304
2006 ﬂare observed by H.E.S.S. The PSD for the 1 minute binned light curve is compatible at 90%
conﬁdence level with a power law of index β = 2 in the frequency range ∼ [10−4, 10−3] Hz [5].

Another important feature of AGN light curves is a linear relation between the root mean
square (RMS) amplitude and the mean ﬂux of groups of contiguous bins of the light curve. This
proportionality implies that ﬂuctuations around the mean value, i.e. variability, are enhanced when
the ﬂux is higher. This has been observed in X-ray for many AGN and other accreting objects, like
binary systems [10, 11]. At VHE such behavior has been detected in the well studied PKS 2155-
304 [12] and Mkn 421 [13]. As observed by Uttley and McHardy [14], and Biteau and Giebels [15],
this RMS-ﬂux proportionality represents a strong constraint on the models that must be used to
reproduce AGN light curves. In particular, these authors have demonstrated that only models in
which the simulated ﬂux is obtained as the exponential of an underlying stochastic process are able
to produce such a relation.

PSD properties and the RMS-ﬂux relation deﬁne the variability proﬁle of the light curves; the
variance of the light curve sets the scale of the ﬂuctuations. This quantity is more commonly
1. Fractional RMS amplitudes
expressed through the use of the fractional RMS amplitude Frms
ranging from 20% to 60% have been observed in the VHE light curve above 200 GeV of PKS 2155-
304 [12]. Values of Frms for most of the Fermi 2LAC sources are found to vary between 20% and
80% [8].

We simulate AGN-like light curves of the ﬂux above 100 GeV, the typical energy threshold for
VHE observatories. To produce time series exhibiting a power-law PSD and a linear RMS-ﬂux
relation, we follow the method proposed by Uttley and McHardy [14]. The light curve φ(ti) is
obtained through an exponential transformation of a linear, aperiodic time series with zero mean,
x(ti):

φ(ti) = exp [x(ti)]

(1)

The Timmer and K¨onig algorithm [16] is used to produce the input time series x(ti). This algorithm
produces linear time series with a power-law PSD of arbitrary slope. It must be noted that, as a
consequence of the exponential transformation, the PSD of the resulting light curve φ(ti) is diﬀerent
from that of the input time series x(ti). However, for the broad continuous PSD observed in AGN,

(cid:113)

1Frms =

φ/(cid:104)φ(cid:105), where (cid:104)φ(cid:105) and σ2
σ2

φ are respectively the mean ﬂux and variance of the light curve. This quantity
expresses, independently from the source strength, the amount of variability in the light curve. When dealing with
real data, the variance σ2

φ is more conveniently replaced by the excess variance [10].

3

this distorting eﬀect is relatively small and can be neglected [14].

The exponential transformation of Eq. 1 enhances points above the mean while reducing points
below the mean. As a consequence, when the variance of the Timmer and K¨onig time series x(ti)
increases, ﬂares in the light curve φ(ti) becomes more prominent compared to the dips. The aspect
of the resulting light curves φ(ti) is thus inﬂuenced by the variance of the input time series x(ti),
a parameter that is inherent to the light curve simulation algorithm but has no clear physical
interpretation2.
In this work this parameter is ﬁxed for all the light curves: the Timmer and
K¨onig series are normalized to Frms = 50% before taking the exponential transformation. Diﬀerent
normalization for the Timmer and K¨onig series have been tested and shown negligible impact on
the conclusion of this work.

The choice of the frequency, i.e. the spacing between two contiguous points, and length, of the
simulated light curves deﬁnes the range of Fourier frequencies that contributes to the signal. These
parameters are chosen in such a way as to include contributions from all the frequency components
that are currently probed by HE and VHE observations. The lowest frequency considered is 0.033
month−1, probed by Fermi -LAT for sources in the second LAT AGN catalog [8]. The highest
frequency will be 1 minute−1, as in the case of PKS 2155-304 2006 ﬂare light curve measured by
H.E.S.S. To cover this frequency range, we generate 30-months-long light curves with one point per
minute. From these long light curves we extract 100-days-long segments at random positions. In
this way the light curves will have a duration that is comparable to the yearly visibility of a source
(see Section 3.1 for details), while still including variability from all the frequency components that
have been observed. This choice does not completely eliminate the problem of ‘red noise leak’ (see
[10] and references therein), as AGN light curves contain variability on time scales longer than 30
months. To mitigate this eﬀect one can generate much longer light curves, extrapolating the PSD
to very low frequencies. Since low frequency behavior of the PSD of VHE AGN light curves is not
known (if β ≥ 1 a ﬂattening must be present at low frequencies to avoid divergence of the power
in the signal), and considering that the eﬀect of red noise leak is negligible for β ≤ 1.5 [10], in this
work it has been chosen not to correct the light curves for this eﬀect.

To simulate diﬀerent kinds of variability we consider variations of β and Frms, assuming a ﬂat
distribution of sources with respect to both of these parameters. We vary the PSD index β between
1 and 2 with an increment of 0.1. Frms will take values between 10% and 100% using steps of 10%.
For each combination of β and Frms, a set of 1000 light curves is produced. All light curves in each
set share the same variability characteristics. The mean ﬂux of all the light curves is set to 1% of
the ﬂux above 100 GeV of the Crab Nebula3, representing the target AGN population for CTA.
Figure 1 shows some examples of the light curves thus produced, illustrating the diﬀerent kinds of
variability considered in this work.

2A possible workaround to this problem would be to assume a log-normal distribution for VHE AGN ﬂuxes.
Under this assumption, the statistical properties of the light curves can be related to the mean and variance of the
input series x(ti), eliminating the need of this additional parameter. However, as of today, log-normal distributions
of AGN ﬂuxes have not been observed in VHE, if the entire light curve of the source is considered (see, for example,
the bi-modal distribution of PKS 2155-304 ﬂux over the 2005-2007 period as observed by H.E.S.S. [12]). Although
log-normality at the highest energies is not ruled out, due to the generally poor sampling ﬂux states of the sources,
biased towards the observation of ﬂares, we still prefer not to use this additional hypothesis.
3φCrab(E > 100GeV) = 9·10−10cm−2s−1, as computed from the pure power-law parametrization of the spectrum

of the Crab Nebula given in [17]

4

Figure 1: Examples of the light curves used in this work: top: low-variability light curve (β = 1.0, Frms = 10%),
middle: medium-variability light curve (β = 1.5, Frms = 50%), bottom: highly-variable light curve (β = 2.0,
Frms = 100%).

5

3. Model of the observing strategies

A model of the observation of a source has been set up. This model includes source visibility,

the pointing scheme used to carry out the observations, and the characteristic of the instrument.

3.1. Source visibility

The visibility of the source is taken into account, using visibility parameters that matches
realistic observing conditions of IACTs. The visibility windows are deﬁned as the time intervals in
which the sun is 15 degrees below the horizon, the moon phase is less than 30%, and the altitude of
the source is greater than 60 degrees. They are computed using the astropy [18], and PyEphem [19]
python packages. To simplify the modeling of the pointing schemes, and to be able to test observing
strategies that makes use of large observing windows, we discard visibility windows that are smaller
than 4 hours. The resulting visibility proﬁle spans 100 days, with 4 blocks of 8 to 12 consecutive
days where the source can be observed for ∼ 4.5 hours, separated by periods of bright moon. It is
computed for a source whose declination (δ) is equal to the latitude (φ) of the observatory, but it
is a good approximation for all the sources for which |δ − φ| ≤ 10◦. In the following, we will refer
to the visibility windows simply as nights.

3.2. Pointing schemes

A pointing scheme speciﬁes the series of time intervals in which the instrument is observing the
source (observing windows). Pointing schemes are deﬁned by specifying the prescription (observing
mode) used to place the observing windows along the light curve, by the total amount of time
available for observation (Tobs), and by the duration of each window (Twin). Two diﬀerent observing
modes are considered: consecutive and random observations. In the case of consecutive observations
the source is observed once in every night, starting from the ﬁrst night. For the random observing
mode, windows are created at random positions inside randomly chosen nights. Although in this
case there could be more than one window inside the same night, no overlap between the windows
is permitted. In both cases, observing windows are constructed so that the summed duration of all
windows is equal to the total observing time Tobs. If necessary the last window is resized in order
not to exceed Tobs.

The main diﬀerence between the two observing modes is that while consecutive observations,
especially when the observing windows are large, tend to be concentrated in a portion of the light
curve, random observation are spread over the entire length of the simulated light curves. This
translates into a diﬀerent coverage of the Fourier spectra of the light curves, with the consecutive
observing mode partially lacking coverage of the lowest frequencies.

3.3. Instrument response functions

The instrument is modeled through the use of its instrument response functions (IRFs) for
eﬀective area and background rate. We make use of the IRFs that are publicly available for the
CTA southern array [20]. These IRFs are computed for a source at 20 degrees zenith angle, and
have been optimized for observing times of 0.5, 5, and 50 hours.

Since the points of the simulated light curves represent the integral ﬂux of the sources above
E0 = 100 GeV, the IRFs are integrated above this energy. In order to convert the points of the
light curves into the rate of signal events above E0, the diﬀerential eﬀective area Aeﬀ(E) is folded

6

with the diﬀerential ﬂux of the simulated sources, here assumed to be a power-law with photon
index Γ = 3, which is a typical shape for AGN VHE spectra4. Deﬁning Aeﬀ as

Aeﬀ(Ei)E−Γ

i

Ei≥E0

Aeﬀ =

,

E−Γ

i

(2)

(cid:88)

(cid:88)

Ei≥E0

(cid:88)

Ei≥E0

where Aeﬀ(Ei) is the eﬀective area at energy Ei, the integral rate of signal events at a time ti can
be written as Rγ(ti) = Aeﬀφ(ti). The expected rate of background events above E0 is simply given
by:

Rbg =

Rbg(Ei),

(3)

with Rbg(Ei) is the expected rate of background events at energy Ei. For the considered IRFs and
photon index, the computed values of Aeﬀ and Rbg are summarized in table 1.

Optimization time [h] Aeﬀ [109 cm2] Rbg [mHz]

0.5
5
50

1.97
1.96
1.50

50
62
37

Table 1: Integrated IRFs for the diﬀerent optimization times.

These IRFs have been computed assuming a ﬁxed zenith angle of 20 degrees, but they are a
good approximation of the performance of the instrument in the range [0, 30] degrees zenith. Having
restricted the visibility windows to period where the source altitude is greater than 60 degrees ensure
a consistent picture.

4. Quantifying observing strategies performance

Using the integrated IRFs described above and the simulated light curves we compute, for each

observing strategy, the probability of detecting a source with given variability characteristics.

For both random and consecutive observing modes, Tobs is varied between a minimum and a
respectively and, for each value of Tobs, the window

maximum observing time, T min
length takes values between T min

obs and T max
obs
win and the minimum between T max

win , and T max
obs .

T min
obs and T max

obs are chosen in such a way as to focus the exploration of the parameter space in
the region in which the probability of detection changes from almost zero to almost unity, the most
interesting in the context of observing strategies optimization. We choose T min
obs = 0.5 hours, and
T max
obs = 10 hours. The maximum allowed length for the observing windows is T max
win = 4 hours; the
shortest windows will be T min

win = 5 min long.

4Although it is known that source spectra are typically harder during ﬂares, time variations of the spectral index
are not considered in this work. The value Γ = 3 is chosen as a compromise between softer spectra observed during
quiescent states and the harder ones during ﬂares.

7

The ranges for the observing time and window length are covered using logarithmic bins. The
bins of the simulation will have the same relative width: δTobs and δTwin. These determine the
precision of the simulation: δTwin = 20%, δTobs = 2%. Smaller values of δTwin can not be achieved,
due to the 1-minute spacing of the points of the light curves.

Taking into account the time lost to re-point the instrument from one position in the sky to
another, the overall time usage of an observing strategy is estimated as Ttot = Tobs + Nwin∆tslew
with Nwin being the number of windows employed and ∆tslew the time it takes to re-point the
telescopes, taken to be 1 minute for CTA medium-size telescopes5.

For each observing strategy and set of light curves we apply the same sequence of observing
windows to all the light curves in the set. Using the simulated ﬂuxes and the integrated IRFs we
compute the number of detected signal and background events as a function of the observing time
along the light curve. At each time step ti we use the IRFs whose optimization time is closer to ti
and compute the statistical signiﬁcance of the gamma-ray excess in the signal region using Equation
17 from Li and Ma [21] taking α, the ratio between signal and background region, to be 1/5, as
customary for IACTs analysis. If the signiﬁcance is greater than 5 and the number of excess signal
events is greater than 10 for any point in the light curve, then the simulated source is ﬂagged as
detected.

For a given set of light curves and observing strategy, the number of light curves for which
the source is detected, Ndet, can be regarded as the number of successes obtained from a series
of NLC = 1000 identical and independent yes/no tests; it therefore follows a binomial distribution
with a probability of success pdet = Ndet/NLC, i.e. the probability of detecting the source with
that particular strategy. We use the method proposed by Feldman and Cousins [22], adapted to
the binomial distribution, to construct conﬁdence intervals that are always physically acceptable,
i.e. that never violate the condition 0 ≤ pdet ≤ 1. For each observing strategy, conﬁdence intervals
at the 3σ conﬁdence level have been computed.

The detection probability describes the performance of an observing strategy with respect to
a given light curve type. For each observing strategy, the values of pdet for the diﬀerent types of
variability are combined together to assess how that strategy behaves with respect to the variability
properties of the sources. For a given observing strategy, let pdet(Frms, β) be the probability of
detecting sources whose variability characteristic are described by Frms and β. The number N95%
of combinations of Frms and β for which pdet ≥ 95% is given by:

(cid:88)

N95% =

H(pdet(Frms, β) − 95%),

(4)

Frms,β

where H(x) is the Heaviside step function and the sum runs through all of the considered values
of Frms and β: ten values of Frms (NFrms = 10), and eleven values of β (Nβ = 11). How well
an observing strategy performs over the whole variability parameter space is estimated with the
parameter Rcover, deﬁned as Rcover = N95%/(NFrms Nβ). For a given observing strategy, Rcover
measures the fraction of the variability parameter space that is covered at high detection probability
by that strategy.

5This is a rather conservative assumption, corresponding to the time it takes to point the telescopes to any

direction in the sky. In a realistic scenario, observations are planned in such a way to minimize these losses.

8

5. Selection of optimal observing strategies

Using the detection probability pdet, and Rcover, the performances of diﬀerent observing strate-
gies are compared and the ones more suited to accomplish a given task are identiﬁed. This method
is applied here to search for optimal observing strategies in two diﬀerent cases: detect a source
with known variability properties in as little time as possible, and conduct variability-unbiased sky
surveys.

5.1. Time-eﬃcient observing strategies

For a given light curve type, studying how pdet varies as a function of Twin, Tobs, and observing
mode, enables the identiﬁcation of the fastest way to detect the source. The method described
here can be used to tailor the observing strategy to individual sources whenever some indications
of their variability properties are available, as for example in the case of pointed observations of
previously detected AGN.

To illustrate the main features of pdet as a function of Twin, Tobs, and observing mode, we
refer to medium variability light curves, characterized by β = 1.5, and Frms = 50%, see Figure 2.
Besides the obvious increase of pdet with Tobs, the detection probability visibly depends on Twin.
Dividing the observing time in many small windows increases the chances of observing the source
during periods of high activity. Such observations have a high signal to noise ratio, increasing the
overall signiﬁcance and leading to a faster detection of the source. This eﬀect is a consequence of
the variability of the source, and becomes more marked as the source variability increase. For low-
variability sources, the length of the observing windows has practically no inﬂuence on the detection
probability, the diﬀerences between the two observing mode vanish, and pdet(Tobs) approaches the
step function expected in the case of constant sources.

Figure 2: pdet(Twin, Tobs) for random (left) and consecutive (right) observations for light curves characterized by
β = 1.5, Frms = 50%. Note the changes of the Twin axis range in the left panel. The empty region visible in the
right panel is due to the fact that, for the consecutive observing mode, the visibility proﬁle does not allow to reach
large values of Tobs when Twin is small.

Time-eﬃcient observing strategies are deﬁned as the ones for which pdet is compatible with one
at 3-sigma conﬁdence level, while having the smallest Ttot and largest Twin possible. With this
deﬁnition, the parameters (T best
obs ) that characterize the best observing strategy are found for
each light curve type and observing mode. The results are presented in Figure 3, showing how

win , T best

9

T best
obs varies as a function of the parameters governing the variability: Frms and PSD index β. For
both observing modes, Frms has the largest inﬂuence on the observing strategies. For low values of
is of the order of ∼ 1.5 h, compatible with the time needed to detect a constant source
Frms, T best
obs
with a ﬂux equal to the mean ﬂux of the simulated light curves. T best
increases with the variance
obs
of the light curves, i.e. sources with large amounts of total variability power are harder to detect.
The PSD index has a weaker inﬂuence on the parameters of the best observing strategies. For the
consecutive observing mode, the fastest way to detect a source almost exclusively uses the smallest
observing windows considered, T best
win = 5 minutes. For random observations, only in the case of low
fractional RMS (Frms (cid:46) 30%), larger windows, of the order of (cid:38) 0.5 h, can be used with success.
Random observations, as opposed to consecutive ones, are slightly faster in detecting the source,
with a resulting time gain, averaged over the entire variability parameter space of 0.4 h. However, for
Frms ≤ 30%, the two observing modes have similar performances. Random observing windows are
distributed along the entire length of the light curve, and variability components at all frequencies
are sampled. Consecutive observations, especially when Twin is large, are concentrated at the
beginning of the light curve, thus partially lacking the coverage of the lowest frequencies. Since
for β > 1 most of the variability power and ﬂuctuations are at low frequencies, for a ﬁxed Tobs
consecutive observations, as compared to random ones, yield lower detection probability and are
more inﬂuenced by the length of the windows.

5.2. Observing strategies for sky surveys

The parameter Rcover is used to evaluate how much the performance of an observing strategy is
inﬂuenced by the variability properties of the source. We use this information to select observing
strategies that are less inﬂuenced by the variability properties of the sources, and are therefore more
suited to conduct blind-sky surveys, where any observation bias, possibly induced by variability
properties, has to be minimized. As we will see, the choice of a particular observing strategy can
favor or disfavor the detection of the source, depending on its variability characteristics. Since there
is evidence that diﬀerent sub-classes of blazars have diﬀerent variability behaviors [8], signiﬁcant
bias can be introduced in the sample of detected sources, if the survey strategy is not chosen
properly.

To illustrate this eﬀect, we refer to a typical observation with observing windows of 30 minutes
and 2 hours observing time, and see how the probability of detection changes for the diﬀerent types
of variability considered. In Figure 4, pdet is presented as a function of Frms and β for this particular
choice of Twin and Tobs for both random and consecutive observing modes. It is apparent that, if
one use these strategies to carry out, for example, a blind survey of the sky, the resulting sample
of detected sources will be biased towards low values of fractional RMS amplitude and harder PSD
of the light curves. Taking random observations, for which Rcover ∼ 14%, will prove more eﬃcient
in reducing this eﬀect as compared to consecutive observations for which Rcover ∼ 5%.

The best observing strategy to conduct a survey is found asking for Rcover = 1 and the smallest
Ttot possible. Such a strategy provides the fastest way to collect a sample of sources, in which the
bias towards any kind of variability is lower than 5%. Figure 5 presents the behavior of Rcover in
the observing strategies parameter space. As can be seen, for both observing modes, the most time-
eﬃcient way to conduct a variability-unbiased blind sky survey makes use of very small observing
windows of ∼ 5 minutes. Using such small windows for each individual pointing of the survey, and
a total time spent on each ﬁeld of view of ≥ 3.5 hours6 there is little diﬀerence between random

6The study presented here is based on the on-source performace of the instrument. The time stated here has to

10

Figure 3: The observing time for the best strategy, T best
as a function of PSD index β and fractional RMS amplitude Frms of the light curves.

obs [h], for random (top) and consecutive (bottom) observations,

11

Figure 4: pdet vs. Frms and β for observation with Tobs = 2 h and Twin = 30 min with random (left) and consecutive
(right) observing mode. The corresponding values of Rcover can be read directly from these plots, dividing the
number of bins for which pdet > 95% by the total number of bins (110).

and consecutive observing modes.

Figure 5: Rcover vs. Twin and Tobs for random (left) and consecutive (right) observing mode.

6. Summary and conclusions

The performance of a time-limited pointing observatory for detection of sources characterized
with AGN-like variability have been studied. Taking CTA as an example of such an instrument,
observing strategies have been optimized for two scenarios: fast detection of sources with known
variability characteristic, and variability-unbiased blind sky survey. We have used the current
knowledge of AGN variability at high and very-high energy to simulate AGN-like light curves
with diﬀerent variability properties. Diﬀerent observing strategies have been modeled and applied

be understood as on-source equivalent time.

12

to these light curves and their performances are quantiﬁed through the probability of detection.
Statistical errors associated with this probability are computed with the appropriate conﬁdence
belt construction.

We have shown that many short observations, spread over long periods of times, have several
advantages over strategies that concentrate the observations in few long windows. In the former
case the observations cover a wider range of variability time scales and have a higher probability of
observing the sources during periods of high activity. For these reasons, such strategies are faster in
detecting the sources. If small observing windows are used, the two observing modes that have been
tested have similar performances. Even taking into account time losses in telescope slewing, for
sources with substantial variability (Frms (cid:39) 50%), observing strategies with ∼5-minute observing
windows enables the savings of up to ∼ 30% of the total observing time, as opposed to observing
strategies with half an hour windows. Observing strategies using very small observing windows are
also less inﬂuenced by the variability properties of the sources, which makes them more appropriate
to conduct blind surveys with the least bias towards a certain source class. We have shown that
an unbiased survey at 1% of the Crab level can be achieved observing each ﬁeld of view for a total
of ∼ 3.5 hours with 5-minute windows. With the same observing time per ﬁeld, but with half an
hour observing windows, only low-variability (Frms (cid:46) 20%) sources will be detected.

Acknowledgments

The authors thank the CTA Speaker And Publication Oﬃce for the courtesy review of this
manuscript, and the CTA Consorium for the input provided. Thanks also to Nathan Kelley-
Hoskins for the kind help and stimulating questions, to Rolf B¨uhler and Jonathan Biteau for the
useful comments, and to Markus Paul Lindhout.

References

[1] C. M. Urry and P. Padovani, “Uniﬁed Scheme for Radio-Loud Active Galactic Nuclei,” Publi-

cations of the Astronomical Society of the Paciﬁc, vol. 107, September 1995.

[2] M. Actis, G. Agnetta, F. Aharonian, A. Akhperjanian, J. Aleksi´c, E. Aliu, D. Allan,
I. Allekotte, F. Antico, L. A. Antonelli, , et al., “Design concepts for the Cherenkov Tele-
scope Array CTA: an advanced facility for ground-based high-energy gamma-ray astronomy,”
Experimental Astronomy, vol. 32, pp. 193–316, Dec. 2011.

[3] H. Sol et al., “Active Galactic Nuclei under the scrutiny of CTA,” Astroparticle Physics, vol. 43,

pp. 215–240, Mar. 2013.

[4] G. Fossati et al., “Multiwavelength Observations of Markarian 421 in 2001 March: An Un-
precedented View on the X-Ray/TeV Correlated Variability,” Astrophysical Journal, vol. 677,
pp. 906–925, Apr. 2008.

[5] F. Aharonian et al., “An Exceptional Very High Energy Gamma-Ray Flare of PKS 2155-304,”

The Astrophysical Journal, Letters, vol. 664, pp. L71–L74, Aug. 2007.

[6] J. Albert et al., “Variable Very High Energy γ-Ray Emission from Markarian 501,” Astrophys-

ical Journal, vol. 669, pp. 862–883, Nov. 2007.

[7] W. B. Atwood et al., “The large area telescope on the fermi gamma-ray space telescope mis-

sion,” The Astrophysical Journal, vol. 697, no. 2, p. 1071, 2009.

[8] M. Ackermann et al., “The Second Catalog of Active Galactic Nuclei Detected by the Fermi

Large Area Telescope,” Astrophysical Journal, vol. 743, p. 171, Dec. 2011.

[9] A. A. Abdo et al., “Gamma-ray Light Curves and Variability of Bright Fermi-detected Blazars,”

Astrophysical Journal, vol. 722, pp. 520–542, Oct. 2010.

[10] S. Vaughan, R. Edelson, R. S. Warwick, and P. Uttley, “On characterizing the variability prop-
erties of X-ray light curves from active galaxies,” Monthly Notices of the Royal Astronomical
Society, vol. 345, pp. 1271–1284, Nov. 2003.

[11] M. Axelsson, S. Larsson, and L. Hjalmarsdotter, “The aperiodic broad-band X-ray variability
of Cygnus X-3,” Monthly Notices of the Royal Astronomical Society, vol. 394, pp. 1544–1550,
Apr. 2009.

[12] H.E.S.S. Collaboration, “VHE γ-ray emission of PKS 2155-304: spectral and temporal vari-

ability,” Astronomy and Astrophysics, vol. 520, p. A83, Sept. 2010.

[13] M. Tluczykont, E. Bernardini, K. Satalecka, R. Clavero, M. Shayduk, and O. Kalekin, “Long-
term lightcurves from combined uniﬁed very high energy γ-ray data,” Astronomy and Astro-
physics, vol. 524, p. A48, Dec. 2010.

[14] P. Uttley, I. M. McHardy, and S. Vaughan, “Non-linear X-ray variability in X-ray binaries and
active galaxies,” Monthly Notices of the Royal Astronomical Society, vol. 359, pp. 345–362,
May 2005.

[15] J. Biteau and B. Giebels, “The minijets-in-a-jet statistical model and the rms-ﬂux correlation,”

Astronomy & Astrophysics, vol. 548, p. A123, Dec. 2012.

[16] J. Timmer and M. Koenig, “On generating power law noise,” Astronomy and Astrophysics,

vol. 300, p. 707, Aug. 1995.

[17] F. Aharonian et al., “Observations of the Crab nebula with HESS,” Astronomy & Astrophysics,

vol. 457, pp. 899–915, Oct. 2006.

[18] ”http://www.astropy.org/”.

[19] ”http://rhodesmill.org/pyephem/”.

[20] ”https://portal.cta observatory.org/”.

[21] T.-P. Li and Y.-Q. Ma, “Analysis methods for results in gamma-ray astronomy,” Astrophysical

Journal, vol. 272, pp. 317–324, Sept. 1983.

[22] G. J. Feldman and R. D. Cousins, “Uniﬁed approach to the classical statistical analysis of

small signals,” Physical Review D (Particles and Fields), vol. 57, pp. 3873–3889, Apr. 1998.

14

