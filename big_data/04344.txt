6
1
0
2

 
r
a

 

M
4
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
4
4
3
4
0

.

3
0
6
1
:
v
i
X
r
a

Necessary and Suﬃcient Conditions

for Convergence of First-Rare-Event Times for

Perturbed Semi-Markov Processes

Dmitrii Silvestrov1

Abstract: Necessary and suﬃcient conditions for convergence in distri-
bution of ﬁrst-rare-event times and convergence in Skorokhod J-topology of
ﬁrst-rare-event-time processes for perturbed semi-Markov processes with ﬁ-
nite phase space are obtained.

Keywords: Semi-Markov process, First-rare-event time, First-rare-event-
time process, Convergence in distribution, Convergence in Skorokhod J-
topology, Necessary and suﬃcient conditions.

2010 Mathematics Subject Classiﬁcation: Primary: 60J10, 60J22, 60J27,

60K15; Secondary: 65C40.

1. Introduction

Random functionals similar with ﬁrst-rare-event times are known under
diﬀerent names such as ﬁrst hitting times, ﬁrst passage times, absorption
times, in theoretical studies, and as lifetimes, ﬁrst failure times, extinction
times, etc., in applications. Limit theorems for such functionals for Markov
type processes have been studied by many researchers.

The case of Markov chains and semi-Markov processes with ﬁnite phase
spaces is the most deeply investigated. We refer here to the works by Simon
and Ando (1961), Kingman (1963), Darroch and Seneta (1965, 1967), Keilson
(1966, 1979), Korolyuk (1969), Korolyuk and Turbin (1970, 1976), Silvestrov
(1970, 1971, 1974, 1980, 2014), Anisimov (1971a, 1971b, 1988, 2008), Turbin
(1971), Masol and Silvestrov (1972), Zakusilo (1972a, 1972b), Kovalenko
(1973), Latouch and Louchard (1978), Shurenkov (1980a, 1980b), Gut and
Holst (1984), Brown and Shao (1987), Alimov and Shurenkov (1990a, 1990b),
Hasin and Haviv (1992), Asmussen (1994, 2003), Ele˘ıko and Shurenkov

1Department of Mathematics, Stockholm University, SE-106 81 Stockholm, Sweden.

Email address: silvestrov@math.su.se

1

(1995), Kalashnikov (1997), Kijima (1997), Stewart (1998, 2001), Gyllen-
berg and Silvestrov (1994, 1999, 2000, 2008), Silvestrov and Drozdenko (2005,
2006a, 2006b), Asmussen and Albrecher (2010), Yin and Zhang (2005, 2013),
Drozdenko (2007a, 2007b, 2009), Benois, Landim and Mourragui (2013).

The case of Markov chains and semi-Markov processes with countable and
an arbitrary phase space was treated in works by Gusak and Korolyuk (1971),
Silvestrov (1974, 1980, 1981, 1995, 2000), Korolyuk and Turbin (1978), Ka-
plan (1979, 1980), Kovalenko and Kuznetsov (1981), Aldous (1982), Ko-
rolyuk D. and Silvestrov (1983, 1984), Kartashov (1987, 1991, 1996, 2013),
Anisimov (1988, 2008), Silvestrov and Velikii (1988), Silvestrov and Abadov
(1991, 1993), Motsa and Silvestrov (1996), Korolyuk and Swishchuk (1992),
Korolyuk V.V. and Korolyuk V.S. (1999), Koroliuk and Limnios (2005),
Kupsa and Lacroix (2005), Glynn (2011), and Serlet (2013).

We also refer to the books by Silvestrov (2004) and Gyllenberg and Silve-
strov (2008) and papers by Kovalenko (1994) and Silvestrov D. and Silvestrov
S. (2015), where one can ﬁnd comprehensive bibliographies of works in the
area.

The main features for the most previous results is that they give suﬃcient
conditions of convergence for such functionals. As a rule, those conditions
involve assumptions, which imply convergence in distribution for sums of i.i.d
random variables distributed as sojourn times for the semi-Markov process
(for every state) to some inﬁnitely divisible laws plus some ergodicity condi-
tion for the imbedded Markov chain plus condition of vanishing probabilities
of occurring a rare event during one transition step for the semi-Markov
process.

In the context of necessary and suﬃcient conditions of convergence in
distribution for ﬁrst-rare-event-time type functionals, we would like to point
out the paper by Kovalenko (1965) and the books by Gnedenko and Korolev
(1996) and Bening and Korolev (2002), where one can ﬁnd some related re-
sults for geometric sums of random variables, and the papers by Korolyuk and
Silvestrov (1983) and Silvestrov and Velikii (1988), where one can ﬁnd some
related results for ﬁrst-rare-event-time type functionals deﬁned on Markov
chains with arbitrary phase space.

The results of the present paper relate to the model of perturbed semi-
Markov processes with a ﬁnite phase space. Instead of conditions based on
“individual” distributions of sojourn times, we use more general and weaker
conditions imposed on distributions sojourn times averaged by stationary
distributions of the corresponding imbedded Markov chains. Moreover, we

2

show that these conditions are not only suﬃcient but also necessary condi-
tions for convergence in distribution of ﬁrst-rare-event times and convergence
in Skorokhod J-topology of ﬁrst-rare-event-time processes. These results give
some kind of a “ﬁnal solution” for limit theorems for ﬁrst-rare-event times
and ﬁrst-rare-event-time processes for perturbed semi-Markov process with
a ﬁnite phase space.

The paper generalize and improve results concerned necessary and suf-
ﬁcient conditions of weak convergence for ﬁrst-rare-event times for semi-
Markov process obtained in papers by Silvestrov and Drozdenko (2005, 2006a,
2006b) and Drozdenko (2007a, 2007b, 2009).

First, weaken model ergodic conditions are imposed on the corresponding
embedded Markov chains. Second, the above results about weak convergence
for ﬁrst-rare-event times are extended, in Theorem 1, to the form of corre-
sponding functional limit theorems for ﬁrst-rare-event-time processes, with
necessary and suﬃcient conditions of convergence. Third, new proofs, based
on general limit theorems for randomly stopped stochastic processes, de-
veloped and extensively presented in Silvestrov (2004), are given, instead
of more traditional proofs based on cyclic representations of ﬁrst-rare-event
times if the form of geometrical type random sums. This actually made it
possible to get more advanced results in the form of functional limit theo-
rems. Fourth, necessary and suﬃcient conditions of convergence for step-sum
reward processes deﬁned on Markov chains are also obtained in the paper.
In the context of the present paper, these results, formulated in Theorem 2,
play an intermediate role. At the same time, they have their own theoreti-
cal and applied values. Finally, we would like to mention results formulated
in Lemmas 1 - 9, which also give some useful supplementary information
about asymptotic properties of ﬁrst-rare-event times and step-sum reward
processes.

We would like to conclude the introduction with the remark that the
present paper is a slightly improved version of the research report by Silve-
strov (2016).

2. First-rare-event times for perturbed semi-Markov processes

Let (ηε,n, κε,n, ζε,n), n = 0, 1, . . . be, for every ε ∈ (0, ε0], a Markov re-
newal process, i.e., a homogenous Markov chain with a phase space Z =
{1, 2, . . . , m} × [0, ∞) × {0, 1}, an initial distribution ¯qε = hqε,i = P{ηε,0 =

3

i, κε,0 = 0, ζε,0 = 0} = P{ηε,0 = i}, i ∈ Xi and transition probabilities,

P{ηε,n+1 = j, κε,n+1 ≤ t, ζε,n+1 = /ηε,n = i, ξε,n = s, ζε,n = ı}

= P{ηε,n+1 = j, κε,n+1 ≤ t, ζε,n+1 = /ηε,n = i}
= Qε,ij(t, ), i, j ∈ X, s, t ≥ 0, ı,  = 0, 1.

(1)

As is known, the ﬁrst component ηε,n of the above Markov renewal process
is also a homogenous Markov chain, with the phase space X = {1, 2, . . . , m},
the initial distribution ¯qε = hqε,i = P{ηε,0 = i}, i ∈ Xi and the transition
probabilities,

pε,ij = Qε,ij(+∞, 0) + Qε,ij(+∞, 1), i, j ∈ X.

(2)

Also, the random sequence (ηε,n, ζε,n), n = 0, 1, . . . is a Markov renewal
process with the phase space X × {0, 1}, the initial distribution ¯qε = hqε,i =
P{ηε,0 = i, ζε,0 = 0} = P{ηε,0 = i}, i ∈ Xi and the transition probabilities,

pε,ij, = Qε,ij(+∞, ), i, j ∈ X,  = 0, 1.

(3)

Random variables κε,n, n = 1, 2, . . . can be interpreted as sojourn times
and random variables τε,n = κε,1 +· · ·+κε,n, n = 1, 2, . . . , τε,0 = 0 as moments
of jumps for a semi-Markov process ηε(t), t ≥ 0 deﬁned by the following
relation,

ηε(t) = ηε,n

for

τε,n ≤ t < τε,n+1, n = 0, 1, . . . ,

(4)

As far as random variables ζε,n, n = 1, 2, . . . are concerned, they are inter-
preted as so-called, “ﬂag variables” and are used to record events {ζε,n = 1}
which we interpret as “rare” events.

Let us introduce random variables,

ξε =

νε

Xn=1

κε,n, where νε = min(n ≥ 1 : ζε,n = 1).

(5)

A random variable νε counts the number of transitions of the imbedded
Markov chain ηε,n up to the ﬁrst occurrence of “rare” event, while a ran-
dom variable ξε can be interpreted as the ﬁrst-rare-event time of the ﬁrst
occurrence of “rare” event for the semi-Markov process ηε(t).

We also consider the ﬁrst-rare-event-time process,

ξε(t) =

[tνε]

Xn=1

κε,n, t ≥ 0.

(6)

4

The objective of this paper is to describe class F of all possible c`adl`ag pro-
cesses ξ0(t), t ≥ 0, which can appear in the corresponding functional limit the-
orem given in the form of the asymptotic relation, ξε(t), t ≥ 0
−→ ξ0(t), t ≥ 0
as ε → 0, and to give necessary and suﬃcient conditions for holding of the
above asymptotic relation with the speciﬁc (by its ﬁnite dimensional distri-
butions) limiting stochastic process ξ0(t), t ≥ 0 from class F.

J

Here and henceforth, we use symbol

d−→ to indicate convergence in distri-
bution for random variables (weak convergence of distribution functions) or
stochastic processes (weak convergence of ﬁnitely dimensional distributions),
symbol
−→ to indicate convergence of random variables in probability, and
symbol
−→ to indicate convergence in Skorokhod J-topology for real-valued
c`adl`ag stochastic processes deﬁned on time interval [0, ∞).

P

J

We refer to books by Gikhman and Skorokhod (1971), Billingsley (1968,
1999) and Silvestrov (2004) for details concerned the above form of functional
convergence.

The problems formulated above are solved under three general model

assumptions.

Let us introduce the probabilities of occurrence of rare event during one

transition step of the semi-Markov process ηε(t),

pε,i = Pi{ζε,1 = 1}, i ∈ X.

Here and henceforth, Pi and Ei denote, respectively, conditional proba-

bility and expectation calculated under condition that ηε,0 = i.

The ﬁrst model assumption A, imposed on probabilities piε, speciﬁes
interpretation of the event {ζε,n = 1} as “rare” and guarantees the possibility
for such event to occur:

A: 0 < max1≤i≤m pε,i → 0 as ε → 0.

Let us introduce random variables,

µε,i(n) =

n

Xk=1

I(ηε,k−1 = i), n = 0, 1, . . . , i ∈ X.

(7)

If, the Markov chain ηε,n is ergodic, i.e., X is one class of communicative
states for this Markov chain, then its stationary distribution is given by the
following ergodic relation,

µε,i(n)

n

P

−→ πε,i as n → ∞, for i ∈ X.

(8)

5

The ergodic relation (8) holds for any initial distribution ¯qε, and the
stationary distribution πε,i, i ∈ X does not depend on the initial distribution.
Also, all stationary probabilities are positive, i.e., πi(ε) > 0, i ∈ X.

As is known, the stationary probabilities πi(ε), i ∈ X are the unique

solution for the system of linear equations,

πε,i = Xj∈X

πε,jpε,ji, i ∈ X, Xi∈X

πε,i = 1.

(9)

The second model assumption is a condition of asymptotically uniform

ergodicity for the embedded Markov chains ηε,n:

B: There exists a ring chain of states i0, i1, . . . , iN = i0 which contains all
states from the phase space X and such that limε→0 pε,ik−1ik > 0, for
k = 1, . . . , N.

As follows from Lemma 1 given below, condition B guarantees that there
exists ε′
0 ∈ (0, ε0] such that the Markov chain ηε,n is ergodic for every
ε ∈ (0, ε′
0]. However, condition B does not require convergence of tran-
sition probabilities and, in sequel, do not imply convergence of stationary
probabilities for the Markov chains ηε,n as ε → 0.

In the case, where the transition probabilities pε,ij = p0,ij, i, j ∈ X do
not depend on parameter ε, condition B reduces to the standard assumption
that the Markov chain η0,n with the matrix of transition probabilities kp0,ijk
is ergodic.

Lemma 1 formulated below gives a more detailed information about con-

dition B.

Finally, the following condition guarantees that the last summand κε,νε

in the random sum ξε is asymptotically negligible:

C: Pi{κε,1 > δ/ζε,1 = 1} → 0 as ε → 0, for δ > 0, i ∈ X.

Let us deﬁne a probability which is the result of averaging of the prob-
abilities of occurrence of rare event in one transition step by the stationary
distribution of the imbedded Markov chain ηε,n,

pε =

m

Xi=1

πε,ipε,i and vε = p−1
ε .

(10)

6

Let us introduce the distribution functions of a sojourn times κε,1 for the

semi-Markov processes ηε(t),

Gε,i(t) = Pi{κε,1 ≤ t}, t ≥ 0, i ∈ X.

Let θε,n, n = 1, 2, . . . be i.i.d. random variables with distribution Gε(t),
which is a result of averaging of distribution functions of sojourn times by
the stationary distribution of the imbedded Markov chain ηε,n,

Gε(t) =

m

Xi=1

πε,iGε,i(t), t ≥ 0.

Now, we can formulate the necessary and suﬃcient condition for conver-

gence in distribution for ﬁrst-rare-event times:

D: θε = P[vε]

n=1 θε,n

variable with distribution not concentrated in zero.

d−→ θ0 as ε → 0, where θ0 is a non-negative random

As well known, (d1) the limiting random variable θ0 penetrating condition
D should be inﬁnitely divisible and, thus, its Laplace transform has the
0 (1 − e−sv)G(dv), s ≥ 0, g is a
non-negative constant and G(dv) is a measure on interval (0, ∞) such that
1+v G(dv) > 0 (this is equivalent to the

form, Ee−sθ0 = e−A(s), where A(s) = gs + R ∞
R(0,∞)

v

1+v G(dv) < ∞; (d2) g +R(0,∞)

assumption that P{ξ0 = 0} < 1).

v

Let also consider the homogeneous step-sum process with independent

increments (summands are i.i.d. random variables),

θε(t) =

[tvε]

Xn=1

θε,n, t ≥ 0.

(11)

As is known (see, for example, Skorokhod (1964, 1986)), condition D is

necessary and suﬃcient for holding of the asymptotic relation,

θε(t) =

[tvε]

Xn=1

θε,n, t ≥ 0

J

−→ θ0(t), t ≥ 0 as ε → 0,

(12)

where θ0(t), t ≥ 0 is a nonnegative L´evy process (a c`adl`ag homogeneous pro-
cess with independent increments) with the Laplace transforms Ee−sθ0(t) =
e−tA(s), s, t ≥ 0.

7

Let us deﬁne the Laplace transforms,

ϕε,i(s) = Eie−sκε,1, i ∈ X, ϕε(s) = Ee−sθε,1 = X∈X

πε,iϕε,i(s), s ≥ 0.

Condition D can be reformulated (see, for example, Feller (1966, 1971))

in the equivalent form, in terms of the above Laplace transforms:

D1: vε(1 − ϕε(s)) → A(s) as ε → 0, for s > 0, where the limiting function

A(s) > 0, for s > 0 and A(s) → 0 as s → 0.

In this case, (d3) A(s) is a cumulant of non-negative random variable
with distribution not concentrated in zero. Moreover, (d4) A(s) should be
the cumulant of inﬁnitely divisible distribution of the form given in the above
conditions (d1) and (d2).

The following condition, which is a variant of the so-called central crite-
rion of convergence (see, for example, Lo`eve (1977)), is equivalent to condi-
tion D, with the Laplace transform of the limiting random variable θ0 given
in the above conditions (d1) and (d2):

D2: (a) vε(1−Gε(u)) → G(u) as ε → 0 for all u > 0, which are points of con-
tinuity of the limiting function, which is nonnegative, non-increasing,
and right continuous function deﬁned on interval (0, ∞), with the limit-
ing value G(+∞) = 0; (a) function G(u) is connected with the measure
G(dv) by the relation G((u′, u′′]) = G(u′) − G(u′′), 0 < u′ ≤ u′′ < ∞;

(b) vεR(0,u] vGε(dv) → g +R(0,u] vG(dv) as ε → 0 for some u > 0 which

is a point of continuity of G(u).

It is useful to note that (d5) the asymptotic relation penetrating condition
D2 (b) holds, under condition D2 (a), for any u > 0 which is a point of
continuity for function G(u).

In what follows, we also always assume that asymptotic relations for
random variables and processes, deﬁned on trajectories of Markov renewal
processes (ηε,n, κε,n, ζε,n), hold for any initial distributions ¯qε, if such distri-
butions are not speciﬁed.

The main result of the paper is the following theorem.
Theorem 1. Let conditions A, B and C hold. Then, (i) condition D
is necessary and suﬃcient for holding (for some or any initial distributions
¯qε, respectively, in statements of necessity and suﬃciency) of the asymptotic

8

d−→ ξ0 as ε → 0, where ξ0 is a non-negative random
relation ξε = ξε(1)
In this case, (ii) the
variable with distribution not concentrated in zero.
limiting random variable ξ0 has the Laplace transform Ee−sξ0 = 1
1+A(s) , where
A(s) is a cumulant of inﬁnitely divisible distribution deﬁned in condition D.
Moreover, (iii) the stochastic processes ξε(t), t ≥ 0
−→ ξ0(t) = θ0(tν0), t ≥ 0
as ε → 0, where (a) ν0 is a random variable, which has the exponential
distribution with parameter 1, (b) θ0(t), t ≥ 0 is a nonnegative L´evy process
with the Laplace transforms Ee−sθ0(t) = e−tA(s), s, t ≥ 0, (c) the random
variable ν0 and the process θ0(t), t ≥ 0 are independent.

J

Remark 1. According Theorem 1, class F of all possible nonnegative,
nondecreasing, c`adl`ag , stochastically continuous processes ξ0(t), t ≥ 0 with
distributions of random variables ξ0(t), t > 0 not concentrated in zero, and
such that the asymptotic relation, ξε(t), t ≥ 0
−→ ξ0(t), t ≥ 0 as ε → 0,
holds, coincides with the class of limiting processes described in proposition
(iii). Condition D is necessary and suﬃcient condition for holding not only
the asymptotic relation given in propositions (i) – (ii) but also for the much
stronger asymptotic relation given in proposition (iii).

J

Remark 2. The statement “for some or any initial distributions ¯qε, re-
spectively, in statements of necessity and suﬃciency” used in the formulation
of Theorem1 should be understood in the sense that the asymptotic relation
penetrating proposition (i) should hold for at least one family of initial dis-
tributions ¯qε, ε ∈ (0, ε0], in the statement of necessity, and for any family of
initial distributions ¯qε, ε ∈ (0, ε0], in the statement of suﬃciency.

3. Asymptotics of step-sum reward processes.

Let us consider, for every ε ∈ (0, ε0], the step-sum stochastic process,

κε(t) =

[tvε]

Xn=1

κε,n, t ≥ 0.

(13)

The random variables κε(t) can be interpreted as rewards accumulated on
trajectories of the Markov chain ηε,n. Respectively, random variables ξε can
be interpreted as rewards accumulated on trajectories of the Markov chain
ηε,n till the ﬁrst occurrence of the “rare” event.

Asymptotics of the step-sum reward processes κε(t), t ≥ 0 have its own
value. At the same, the corresponding result formulated below in Theorem

9

2 plays the key role in the proof of Theorem 1.

It is useful to note that the ﬂag variables ζε,n are not involved in the
deﬁnition of the processes κε(t). This let us replace function vε = p−1
ε by an
arbitrary function 0 < vε → ∞ as ε → 0 in condition D, Theorem 2 and
Lemmas 2 – 6 formulated below.

Theorem 2. Let condition B holds. Then, (i) condition D is necessary
and suﬃcient condition for holding (for some or any initial distributions
¯qε, respectively, in statements of necessity and suﬃciency) of the asymptotic
d−→ θ0 as ε → 0, where θ0 is a non-negative random vari-
relation, κε(1)
able with distribution not concentrated in zero. In this case, (ii) the random
variable θ0 has the inﬁnitely divisible distribution with the Laplace trans-
form Ee−sθ0 = e−A(s), s ≥ 0 with the cumulant A(s) deﬁned in condition D.
Moreover, (iii) stochastic processes κε(t), t ≥ 0
−→ θ0(t), t ≥ 0 as ε → 0,
where θ0(t), t ≥ 0 is a nonnegative L´evy process with the Laplace transforms
Ee−sθ0(t) = e−tA(s), s, t ≥ 0.

J

Remark 3. According Theorem 2, class G of all possible nonnegative,
nondecreasing, c`adl`ag , stochastically continuous processes θ0(t), t ≥ 0 with
distributions of random variables θ0(t), t > 0 not concentrated in zero, and
such that the asymptotic relation, κε(t), t ≥ 0
−→ θ0(t), t ≥ 0 as ε → 0,
holds, coincides with the class of limiting processes described in proposi-
tion (iii). Condition D is necessary and suﬃcient condition for holding the
asymptotic relation given in propositions (i) – (ii) as well as for the much
stronger asymptotic relation given in proposition (iii).

J

We use several useful lemmas in the proof of Theorems 1 and 2.
Let ˜ηε,n be, for every ε ∈ (0, ε0] a Markov chain with the phase space X

and a matrix of transition probabilities k˜pε,ijk.

We shall use the following condition:

E: pε,ij − ˜pε,ij → 0 as ε → 0, for i, j ∈ X.

If transition probabilities ˜pε,ij ≡ p0,ij, i, j ∈ X do not depend on ε, then

condition E reduces to the following condition:

F: pε,ij → p0,ij as ε → 0, for i, j ∈ X.

Lemma 1. Let condition B holds for the Markov chains ηε,n. Then, (i)
0 ∈ (0, ε0] such that the Markov chain ηε,n is ergodic, for every
0] and 0 < limε→0 πε,i ≤ limε→0 πε,i < 1, for i ∈ X. (ii) If, together

There exists ε′
ε ∈ (0, ε′

10

0 ∈ (0, ε′

with B, condition E holds, then, there exists ε′′
0] such that Markov
chain ˜ηε,n is ergodic, for every ε ∈ (0, ε′′
0], and its stationary distribution
˜πε,i, i ∈ X satisfy the asymptotic relation, πε,i − ˜πε,i → 0 as ε → 0, for
i ∈ X. (iii) If condition F holds, then matrix kp0,ijk is stochastic, condition
B is equivalent to the assumption that a Markov chain η0,n, with the matrix of
transition probabilities kp0,ijk, is ergodic and the following asymptotic relation
holds, πε,i → π0,i as ε → 0, for i ∈ X, where π0,i, i ∈ X is the stationary
distribution of the Markov chain η0,n.

Proof. Let us ﬁrst prove proposition (iii). Condition F obviously
implies that matrix kp0,ijk is stochastic. Conditions B and F imply that
limε→0 pε,ik−1ik = p0,ik−1ik > 0, k = 1, . . . , N, for the ring chain penetrating
condition B. Thus, the Markov chain η0,n with the matrix of transition prob-
abilities kp0,ijk is ergodic. Vise versa, the assumption that a Markov chain
η0,n with the matrix of transition probabilities kp0,ijk is ergodic implies that
there exists a ring chain of states i0, . . . , iN = i0 which contains all states
from the phase space X and such that p0,ik−1ik > 0, k = 1, . . . , N. In this
case, condition F implies that limε→0 pε,ik−1ik = p0,ik−1ik > 0, k = 1, . . . , N,
and, thus, condition B holds. Let us assume that the convergence rela-
tion for stationary distributions penetrating proposition (iii) does not hold.
In this case, there exist δ > 0 and a sequence 0 < εn → 0 as n → ∞
such that limn→∞ |πεn,i′ − π0,i′| ≥ δ, for some i′ ∈ X. Since, the sequences
πεn,i, n = 1, 2, . . . , i ∈ X are bounded, there exists a subsequence 0 < εnk → 0
as k → 0 such that πεnk ,i → π′
0,i as k → ∞, for i ∈ X. This relation, condition
F and relation (9) imply that numbers π′
0,i, i ∈ X satisfy the system of linear
equation given in (9). This is impossible, since inequality |π′
0,i′ − π0,i′| ≥ δ
should hold, while the stationary distribution π0,i, i ∈ X is the unique solution
of system (9).

Let us now prove proposition (i). Condition B obviously implies that
there exist ε′
0 ∈ (0, ε0] such that pε,ik−1ik > 0, k = 1, . . . , N, for the ring
chain penetrating condition B, for ε ∈ (0, ε′
0]. Thus, the Markov chain
ηε,n is ergodic, for every ε ∈ (0, ε′
0]. Let now assume that limε→0 πε,i′ = 0,
for some i′ ∈ X.
In this case, there exists a sequence 0 < εn → 0 as
n → ∞ such that πεn,i′ → 0 as n → ∞. Since, the sequences pεn,ij, n =
1, 2, . . . , i, j ∈ X are bounded, there exists a subsequence 0 < εnk → 0 as
k → 0 such that pεnk ,ij → p0,ij as k → ∞, for i, j ∈ X. By proposition
(iii), the matrix kp0,ijk is stochastic, the Markov chain η0,n with the matrix
of transition probabilities kp0,ijk is ergodic and its stationary distribution

11

π0,i, i ∈ X satisﬁes the asymptotic relation, πεnk ,i → π0,i as k → ∞, for
i ∈ X. This is impossible since equality π0,i′ = 0 should hold, while all
stationary probabilities π0,i, i ∈ X are positive. Thus, limε→0 πε,i > 0, for

i ∈ X. This implies that, also, limε→0 πε,i < 1, for i ∈ X, since Pi∈X πε,i = 1,

for ε ∈ (0, ε′

0].

0 ∈ (0, ε′

Finally, let us now prove proposition (ii). Conditions B and E obviously
imply that limε→0 ˜pε,ik−1ik = limε→0 pε,ik−1ik > 0, k = 1, . . . , N, for the ring
chain penetrating condition B. Thus, condition B holds also for the Markov
chains ˜ηε,n and there exist ε′′
0] such that Markov chain ˜ηε,n is ergodic,
for every ε ∈ (0, ε′′
0]. Let assume that the convergence relation for stationary
distributions penetrating proposition (ii) does not hold. In this case, there
exist here exist δ > 0 and a sequence 0 < εn → 0 as n → ∞ such that
limn→∞ |πεn,i′ − ˜πεn,i′| ≥ δ, for some i′ ∈ X. Since, the sequences pεn,ij, n =
1, 2, . . . , i, j ∈ X are bounded, there exists a subsequence 0 < εnk → 0 as
k → 0 such that pεnk ,ij → p0,ij as k → ∞, for i, j ∈ X. This relations and
condition E imply that, also, ˜pεnk ,ij → p0,ij as k → ∞, for i, j ∈ X. By
proposition (iii), the matrix kp0,ijk is stochastic, the Markov chain η0,n with
the matrix of transition probabilities kp0,ijk is ergodic and its stationary
distribution π0,i, i ∈ X satisﬁes the asymptotic relations, πεnk ,i → π0,i as
k → ∞, for i ∈ X and ˜πεnk ,i → π0,i as k → ∞, for i ∈ X. This is impossible,
since relation limk→∞ |πεnk ,i′ − ˜πεnk ,i′| ≥ δ should hold. (cid:3)

Due to Lemma 1, the asymptotic relation penetrating condition D1 can,
under conditions A, B and E, be rewritten in the equivalent form, where the
stationary probabilities πε,i, i ∈ X are replaced by the stationary probabilities
˜πε,i, i ∈ X,

vε(1 − ϕε(s)) = Xi∈X
∼ Xi∈X

πε,ivε(1 − ϕε,i(s))

˜πε,ivε(1 − ϕε,i(s)) → A(s) as ε → 0, for s > 0.

(14)

Here and henceforth relation a(ε) ∼ b(ε) as ε → 0 means that a(ε)/b(ε) →

1 as ε → 0.

Proposition (iii) of Lemma 1 implies that, in the case, where the tran-
sition probabilities pε,ij = p0,ij, i, j ∈ X do not depend on parameter ε or
pε,ij → p0,ij as ε → 0, for i, j ∈ X, condition B reduces to the standard
assumption that the Markov chain η0,n, with the matrix of transition proba-
bilities kp0,ijk, is ergodic.

12

These simpler variants of asymptotic ergodicity condition, based on con-
dition F and the assumption of ergodicity of the Markov chain η0,n combined
with averaging of characteristic in condition D by its stationary distribution
π0,i, i ∈ X, have been used in the mentioned above works by Silvestrov and
Drozdenko (2006a) and Drozdenko (2007a) for proving analogues of propo-
sitions (i) and (ii) of Theorem 1.

In this case, the averaging of characteristics in the necessary and suﬃ-
cient condition D, in fact, relates mainly to distributions of sojourn times.
Condition B, used in the present paper, balances in a natural way averaging
of characteristics in condition D between distributions of sojourn times and
stationary distributions of the corresponding embedded Markov chains.

Let us introduce random variables, which are sequential moments of hit-

ting state i ∈ X by the Markov chain ηε,n,

τε,i,n = (cid:26) min(k ≥ 0, ηε,k = i)

min(k > τε,i,n−1, ηε,k = i)

for n = 1,
for n ≥ 2.

Let also deﬁne random variables,

κε,i,n = κε,τε,i,n+1, n = 1, 2, . . . , i ∈ X.

(15)

(16)

The following simple lemma describe useful properties of the above family

of random variables.

Lemma 2. Let condition B holds. Then, for every ε ∈ (0, ε′

0], (i) the
random variables κε,i,n, n = 1, 2, . . . , i ∈ X are independent; (ii) P{κε,i,n ≤
t} = Gε,i(t), t ≥ 0, for n = 1, 2, . . . , i ∈ X; (iii) the following representation
takes place for process κε(t),

κε(t) =

[tvε]

Xn=1

µε,i([tvε])

κε,n = Xi∈X

Xn=1

κε,i,n, t ≥ 0.

(17)

It should be noted that the families of random variables hµε,i(n), n =

0, 1, . . . , i ∈ Xi and hκε,i,n, n = 1, 2, . . . , i ∈ Xi are not independent.

In what follows, we, for simplicity, indicate convergence of c`adl`ag pro-
cesses in uniform U-topology to continuous processes as convergence in J-
topology, since, in this case, convergence J-topology is equivalent to conver-
gence in uniform U-topology.

13

Lemma 3. Let condition B hold. Then,

µ∗

ε,i(t) =

µε,i([tvε])

πε,ivε

, t ≥ 0

J

−→ µ0,i(t) = t, t ≥ 0 as ε → 0, for i ∈ X.

(18)

exist p ∈ (0, 1) and εp ∈ (0, ε0] such that QN

Proof. Let αε,j = min(n > 0 : ηε,n = j) be the moment of ﬁrst hitting
to the state j ∈ X for the Markov chain ηε,n. Condition B implies that there
k=1 pε,ik−1ik > p, for ε ∈ (0, εp].
The following inequalities are obvious, Pi{αε,j > kN} ≤ (1−p)k, k ≥ 1, i, j ∈
X, for ε ∈ (0, εp]. These inequalities imply that there exists Kp ∈ (0, ∞) such
that maxi,j∈X Eiα2
ε,j ≤ Kp < ∞, i, j ∈ X, for ε ∈ (0, εp]. Also, as well known,
Eiαε,i = π−1

ε,i , i ∈ X, for ε ∈ (0, εp].

Let αε,i,n = min(k > αε,i,n−1 : ηε,k = i), n = 1, 2, . . . be sequential mo-
ments of hitting to state i ∈ X for the Markov chain ηε,n and βε,i,n = αε,i,n −
αε,i,n−1, n = 1, 2, . . ., where αε,i,0 = 0. The random variables βε,i,n, n ≥ 1 are
independent and identically distributed for n ≥ 2. The above relations for
moments of random variables αε,i imply that αε,i,1/vε
−→ 0 as ε → 0, for
i ∈ X. Also, Pi{v−1
ε,i [tvε]| > δ} ≤ tKp/δ2vε, δ > 0, t ≥ 0, i ∈ X,
for ε ∈ (0, εp]. These relations obviously implies that random variables
αε,i,[tvε]/π−1
−→ t as ε → 0, for t ≥ 0. The dual identities P{µε,i(r) ≥
k} = P{αε,i,k ≤ r}, r, k = 0, 1, . . . let one, in standard way, convert the latter
asymptotic relation to the equivalent relation µ∗
−→ t as
ε → 0, for t ≥ 0. Since the processes µ∗
ε,i(t), t ≥ 0 are nondecreasing and the
corresponding limiting function is continuous, the latter asymptotic relation
is (see, for example, Lemma 3.2.2 from Silvestrov (2004)) equivalent to the
asymptotic relation (18) given in Lemma 3. (cid:3)

ε,i(t) = µε,i,[tvε]/πε,ivε

ε,i vε

P

|αε,i,[tvε] − π−1

ε

P

P

Let now introduce step-sum processes with independent increments,

[tπε,ivε]

˜κε(t) = Xi∈X

Xn=1

κε,i,n, t ≥ 0.

(19)

Lemmas 2 and 3 let us presume that processes ˜κε(t) can be good approx-

imations for processes κε(t).

Lemma 4. Let condition B hold. Then, (i) condition D holds if and
d−→ θ0 as ε → 0, where θ0 is a
only if the following relation holds, ˜κε(1)
non-negative random variable with distribution not concentrated in zero. In
this case, (ii) the random variable θ0 has the inﬁnitely divisible distribution

14

with the Laplace transform Ee−sθ0 = e−A(s), s ≥ 0 with the cumulant A(s)
deﬁned in condition D. Moreover, (iii) stochastic processes ˜κε(t), t ≥ 0
−→
θ0(t), t ≥ 0 as ε → 0, where θ0(t), t ≥ 0 is a nonnegative L´evy process with
the Laplace transforms Ee−sθ0(t) = e−tA(s), s, t ≥ 0.

J

Proof of Theorem 2. The proof of Lemma 4 is an integral part of the

proof of Theorem 2.

Let us, ﬁrst, prove that condition D implies holding of the asymptotic

relations penetrating Lemma 4 and Theorem 2.

Let ˆηε,n, n = 1, 2, . . . be, for every ε ∈ (0, ε′

0], a sequence of random
variables such that: (a) it is independent of the Markov chain (ηε,n, κε,n), n =
0, 1, . . . and (b) it is a sequence of i.i.d. random variables taking value i with
probability πε,i, for i ∈ X.

Note that, in this case, the sequence of random variables ˆηε,n, n = 1, 2, . . .
is also independent of the families of random variables hµε,i(n), n = 0, 1, . . . , i ∈
Xi and hκε,i,n, n = 1, 2, . . . , i ∈ Xi.
Let us deﬁne random variables,

ˆµε,i(n) =

n

Xk=1

and stochastic processes

I(ˆηε,n = i), n = 0, 1, . . . , i ∈ X.

(20)

ˆµε,i([tvε])

ˆκε(t) = Xi∈X

Xn=1

κε,i,n, t ≥ 0.

(21)

Let us also consider the sequence of random variables θε,n = κε,ˆηε,n,n, n =
1, 2, . . .. This is the sequence of i.i.d. random variables that follows from the
above deﬁnition of the sequence of random variables ˆηε,n, n = 1, 2, . . . and
the family of random variables κε,i,n, n = 1, 2, . . . , i ∈ X. Also,

P{θε,1 ≤ t} = Xi∈X

πε,iGε,i(t) = Gε(t), t ≥ 0.

(22)

Let us also deﬁne the homogeneous step-sum processes with independent
increments using for them, due to relation (22) the same notation as for
processes introduced in relation (11),

θε(t) =

[tvε]

Xn=1

θε,n, t ≥ 0.

15

(23)

As well known (see, for example, Skorokhod (1964, 1986)), condition D

is equivalent to the following relation,

θε(t), t ≥ 0 d−→ θ0(t), t ≥ 0 as ε → 0.

(24)

By the deﬁnition of the sequence of random variables hˆηε,n, n = 1, 2, . . .i
and the family of random variables hκε,i,n, n = 1, 2, . . . , i ∈ Xi, in particular,
due to independence of the above sequence and family, the following relation
holds,

ˆκε(t), t ≥ 0 d= θε(t), t ≥ 0.

(25)

Relation (25) implies that ˆκε(t), t ≥ 0 also is a homogeneous step-sum
process with independent increments and that condition D is equivalent to
the following relation,

ˆκε(t), t ≥ 0 d−→ θ0(t), t ≥ 0 as ε → 0.

(26)

Random variables I(ˆηε,n = i), n = 1, 2, . . . are, for every i ∈ X, i.i.d.
random variables taking values 1 and 0 with probabilities, respectively, πε,i
and 1 − πε,i. According proposition (i) of Lemma 1, 0 < limε→0 πε,i ≤
limε→0 πε,i < 1, for every i ∈ X. Taking into account the above remarks,
this is easy to prove using the corresponding results from Skorokhod (1964,
1986), that the following relation holds,

ˆµ∗

ε,i(t) =

ˆµε,i([tvε])

πε,ivε

, t ≥ 0

J

−→ µ0,i(t) = t, t ≥ 0 as ε → 0, for i ∈ X.

(27)

Let us choose some 0 < u < 1.
By the deﬁnition, processes ˜κε(t), ˆκε(t), and ˆµ∗

ε,i(t), i ∈ X are non-negative

and non-decreasing. Taking this into account, we get, for x ≥ 0,

P{˜κε(u) > x} ≤ P{˜κε(u) > x, ˆµ∗

ε,i(1) > u, i ∈ X}

P{˜κε(u) > x, ˆµ∗

+Xi∈X
≤ P{ˆκε(1) > x} +Xi∈X

ε,i(1) ≤ u}

P{ˆµ∗

ε,i(1) ≤ u}.

(28)

16

Relations (26), (27) and inequality (28) imply that distributions of ran-

dom variables ˜κε(u) are relatively compact as ε → 0,

lim
x→∞

lim
ε→0

P{˜κε(u) > x} ≤ lim
x→∞

lim
ε→0
ε,i(1) ≤ u}) = lim
x→∞

P{ˆµ∗

+Xi∈X

(P{ˆκε(1) > x}

P{θ0(1) > x} = 0.

(29)

Let also introduce homogeneous step-sum processes with independent

increments, for i ∈ X,

˜κε,i(t) =

[tπε,ivε]

Xn=1

κε,i,n, t ≥ 0.

(30)

Note that, for every ε ∈ (0, ε′

0], processes h˜κε,i(t), t ≥ 0i, i ∈ X are inde-

pendent.

Since, ˜κε,i(u) ≤ ˜κε(u), for i ∈ X, relation (29) imply that distributions
of random variables ˜κε,i(1) are also relatively compact as ε → 0, for every
i ∈ X,

lim
x→∞

lim
ε→0

P{˜κε,i(u) > x} ≤ lim
x→∞

lim
ε→0

P{˜κε(u) > x} = 0.

(31)

This implies that any sequence 0 < εn → 0 as n → ∞ contains a subse-

quence 0 < εnk → 0 as k → ∞ such that random variables,

˜κεnk ,i(u)

d−→ θ0,i,u as k → ∞, for i ∈ X,

(32)

where θ0,i,u, i ∈ X are proper nonnegative random variables, with distribu-
tions possibly dependent of the choice of subsequence εnk.

Moreover, by the central criterion of convergence (see, for example, Lo`eve
(1977)), random variables θ0,i,u, i ∈ X have inﬁnitely divisible distributions.
Let Ee−sθ0,i,u = e−uAi(s), s ≥ 0, i ∈ X be their Laplace transforms.

As well known (see, for example, Skorokhod (1964, 1986)), relation (32)

implies that stochastic processes,

˜κεnk ,i(t), t ≥ 0

J

−→ θ0,i(t), t ≥ 0 as k → ∞, for i ∈ X,

(33)

where θ0,i(t), t ≥ 0, i ∈ X are nonnegative L´evy processes with Laplace trans-
forms Ee−sθ0,i(t) = e−tAi(s), s, t ≥ 0, i ∈ X, possibly dependent of the choice of
subsequence εnk.

17

Moreover, since processes ˜κε,i(t), t ≥ 0, i ∈ X are independent, J-conver-

gence of vector processes (˜κεnk ,1(t), . . . , ˜κεnk ,m(t)), t ≥ 0 also takes place,

(˜κεnk ,1(t), . . . , ˜κεnk ,m(t)), t ≥ 0

J

−→ (θ0,1(t), . . . , θ0,m(t)), t ≥ 0 as k → ∞,

(34)

where θ0,i(t), t ≥ 0, i ∈ X are independent nonnegative L´evy processes with
Laplace transforms Ee−sθ0,i(t) = e−tAi(s), s, t ≥ 0, i ∈ X, possibly dependent
of the choice of subsequence εnk.

Note (see, for example, Theorem 3.8.1,

in Silvestrov (2004)) that J-
compactness of the vector processes (˜κεnk ,1(t), . . . , ˜κεnk ,m(t)) follows from J-
compactness of their components ˜κεnk ,i(t), i ∈ X, since the corresponding
limiting processes θ0,i(t), i ∈ X are stochastically continuous and indepen-
dent and, thus, they have not with probability 1 joint points of discontinuity.

Relation (34) obviously implies the following relation,

˜κεnk

(t) = Xi∈X

˜κεnk ,i(t), t ≥ 0

J

−→ θ′

0(t) = Xi∈X

θ0,i(t), t ≥ 0 as k → ∞,

(35)

where θ0,i(t), t ≥ 0, i ∈ X are independent nonnegative L´evy processes de-
scribed in relation (34).

Since, the limiting processes in (18) and (27) are non-random functions,
relations (18), (27) and (35) imply (see, for example, Subsection 1.2.4 in
Silvestrov (2004)), by Slutsky theorem, that,

(µ∗

εnk ,1(t), . . . , µ∗

εnk ,m(t), ˜κεnk ,1(t), . . . , ˜κεnk ,m(t)), t ≥ 0

d−→ (µ0,1(t), . . . , µ0,m(t), θ0,1(t), . . . , θ0,m(t)), t ≥ 0 as k → ∞,

(36)

and

(ˆµ∗

εnk ,1(t), . . . , ˆµ∗

εnk ,m(t), ˜κεnk ,1(t), . . . , ˜κεnk ,m(t)), t ≥ 0

d−→ (µ0,1(t), . . . , µ0,m(t), θ0,1(t), . . . , θ0,m(t)), t ≥ 0 as k → ∞,

(37)

where µ0,i(t) = t, t ≥ 0, i ∈ X and θ0,i(t), t ≥ 0, i ∈ X are independent
nonnegative L´evy processes deﬁned in relation (34).

We can now apply Theorem 3.8.2, from Silvestrov (2004), which give
conditions of J-convergence for vector compositions of c`adl`ag stochastic pro-

18

cesses, and get the following asymptotic relations,

(˜κεnk ,1(µ∗

εnk ,1(t)), . . . , ˜κεnk ,m(µ∗

εnk ,m(t))), t ≥ 0

J

−→ (θ0,1(µ0,1(t)), . . . , θ0,m(µ0,m(t)))

= (θ0,1(t), . . . , θ0,m(t)), t ≥ 0 as k → ∞,

(38)

and

(˜κεnk ,1(ˆµ∗

εnk ,1(t)), . . . , ˜κεnk ,m(ˆµ∗

εnk ,m(t))), t ≥ 0

J

−→ (θ0,1(µ0,1(t)), . . . , θ0,m(µ0,m(t)))

= (θ0,1(t), . . . , θ0,m(t)), t ≥ 0 as k → ∞,

(39)

where θ0,i(t), t ≥ 0, i ∈ X are independent nonnegative L´evy processes deﬁned
in relation (34).

Relations (38) and (39) obviously imply J-convergence for sum of compo-
nents of the processes in these relations, i.e. that, respectively, the following
relations hold,

κεnk

(t) = Xi∈X

˜κεnk ,i(µ∗

εnk ,i(t)), t ≥ 0

J

−→ θ′

0(t) = Xi∈X

θ0,i(t), t ≥ 0 as k → ∞,

(40)

and

ˆκεnk

(t) = Xi∈X

˜κεnk ,i(ˆµ∗

εnk ,i(t)), t ≥ 0

J

−→ θ′

0(t) = Xi∈X

θ0,i(t), t ≥ 0 as k → ∞,

(41)

where θ0,i(t), t ≥ 0, i ∈ X are independent nonnegative L´evy processes deﬁned
in relation (34).

Relation (26) implies that

0(t), t ≥ 0 d= θ0(t), t ≥ 0,
θ′

(42)

Thus, the limiting process θ′

dimensional distributions for all subsequences εnk described above. Moreover,

0(t) = Pi∈X θ0,i(t), t ≥ 0 has the same ﬁnite

19

the cumulant A(s) of the limiting L´evy process θ0(t) is connected with cu-

mulants Ai(s), i ∈ X of L´evy processes θ0,i(t) by relation, A(s) = Pi∈X Ai(s),

s ≥ 0.

Therefore, relations (35), (40) and (41) imply that, respectively, the fol-

lowing relations hold,

˜κε(t) = Xi∈X

˜κε,i(t), t ≥ 0

J

−→ θ0(t), t ≥ 0 as ε → 0,

(43)

and

as well as,

κε(t) = Xi∈X

ˆκε(t) = Xi∈X

˜κε,i(µ∗

ε,i(t)), t ≥ 0

J

−→ θ0(t), t ≥ 0 as ε → 0,

(44)

˜κε,i(ˆµ∗

ε,i(t)), t ≥ 0

J

−→ θ0(t), t ≥ 0 as ε → 0.

(45)

It is useful to note that relation (45) for homogeneous step-sum processes

ˆκε(t) follows directly from relation (26).

It was obtained in the way described above just in order to prove that
the limiting process in relations (35), (40) and (41) is the same and does
not depend on the choice of subsequences εnk described above. This made it
possible to write down relations (43) and (44).

Let us now prove that the asymptotic relation given in proposition (i) of

Theorem 2 or in proposition (i) of Lemma 4 implies condition D to hold.

In both cases, the ﬁrst step is to prove that distributions of random

variables ˜κε(u) are relatively compact as ε → 0, for some u > 0.

Let us choose some 0 < u < 1.
By the deﬁnition, the processes κε(t), ˜κε(t), and µ∗

ε,i(t), i ∈ X are non-
negative and nondecreasing. Taking this into account, we get, for any x ≥ 0,

P{˜κε(u) > x} ≤ P{˜κε(u) > x, µ∗

ε,i(1) > u, i ∈ X}

P{˜κε(u) > x, µ∗

+Xi∈X
≤ P{κε(1) > x} +Xi∈X

ε,i(1) ≤ u}

P{µ∗

ε,i(1) ≤ u}.

(46)

20

The asymptotic relation given in proposition (i) of Theorem 2, relation

(18) and inequality (46) imply that,

lim
x→∞

lim
ε→0

P{˜κε(u) > x} ≤ lim
x→∞

(P{κε(1) > x}

ε,i(1) ≤ u}) = lim
x→∞

P{θ0 > x} = 0. (47)

lim
ε→0
P{µ∗

+Xi∈X

Note that, in this nessessity case, the asymptotic relation given in propo-
sition (i) of Theorem 2 is required to hold only for at least one family initial
distributions ¯qε, ε ∈ (0, ε0].

The asymptotic relation given in proposition (i) of Lemma 4 implies that,

lim
x→∞

lim
ε→0

P{˜κε(u) > x} ≤ lim
x→∞
= lim
x→∞

P{˜κε(1) > x}

lim
ε→0
P{θ0 > x} = 0.

(48)

Relation (47), as well as relation (48), implies that distributions of random

variables ˜κε(u) are relatively compact as ε → 0.

Now, we can repeat the part of the above prove related to relations (30)

– (41).

Relation (40) and the asymptotic relation given in proposition (i) of The-
orem 2, as well as relation (35) and the asymptotic relation given in propo-
sition (i) of Lemma 4, implies that the random variables θ′(1) and θ0, which
appears in the above asymptotic relations, have the same distribution,

θ′(1) d= θ0.

(49)

Moreover, cumulant A(s) of the limiting L´evy process θ′

0(t) coincides
with the cumulant of the random variable θ0, which, therefore, has inﬁnitely
divisible distribution. Moreover, relation (41) implies that cumulant A(s) is
connected with cumulants Ai(s), i ∈ X of L´evy processes θ′
0,i(t) by relation

A(s) = Pi∈X Ai(s), s ≥ 0.

Thus, the limiting process θ′

ﬁnite dimensional distributions for all subsequences εnk described above.

0(t), t ≥ 0 = Pi∈X θ0,i(t), t ≥ 0 has the same

This let us again to write down relations (43) – (45).
Relation (45) proves, in this case, that condition D holds.
Relation (43) proves proposition (iii) of Lemma 4.
Relation (44) proves proposition (iii) of Theorem 2. (cid:3)

21

Let us consider the particular case of the model with random variables
κε,n = fε,ηε,n−1, n = 1, 2, . . . , i ∈ X, where fε,i ≥ 0, i ∈ X are nonrandom
nonnegative numbers. In this case, stochastic process,

κε(t) =

[tvε]

Xn=1

fε,ηε,n−1, t ≥ 0.

(50)

Also, the Laplace transforms,

ϕε,i(s) = Eie−sfε,ηε,0 = e−sfε,i, s ≥ 0, for i ∈ X.

and,

ϕε(s) = Xi∈X

πε,ie−sfε,i, s ≥ 0.

Condition D1 takes, in this case, the form of the following relation,

vε(1 − ϕε(s)) = Xi∈X

πε,ivε(1 − e−sfε(i))

→ A(s) as ε → 0, for s > 0,

(51)

where the limiting function A(s) > 0, for s > 0 and A(s) → 0 as s → 0.

This condition obviously implies that 1 − ϕε,i(s) → 0 as ε → 0, for
s > 0, i ∈ X that is equivalent to relation fε,i → 0 as ε → 0, for i ∈ X. In
this case, 1 − ϕε,i(s) = sfε,i + o(sfε,i) as ε → 0, for every s > 0, i ∈ X. These
relations let us reformulate condition D1 in terms of functions,

fε = vεXi∈X

πε,ifε,i.

Condition D1 is equivalent to the following condition:

G: fε → f0 ∈ (0, ∞) as ε → 0.

Moreover, in this case the cumulant A(s) = f0s, s ≥ 0.
Theorem 2 takes in this case the following form.
Lemma 5. Let condition B holds. Then, (i) condition G is necessary
and suﬃcient condition for holding (for some or any initial distributions
¯qε, respectively, in statements of necessity and suﬃciency) of the asymptotic
d−→ θ0 as ε → 0, where θ0 is a non-negative random variable
relation, κε(1)

22

with distribution not concentrated in zero.
variable θ0
κε(t), t ≥ 0

In this case, (ii) the random
d= f0, i.e., it is a constant. Moreover, (iii) stochastic processes
−→ f0t, t ≥ 0 as ε → 0.

J

Let us assume that function fε satisfy the following natural assumption:

H: There exists ε′′

0 ∈ (0, ε′

0] such that fε > 0 for ε ∈ (0, ε′′
0].

In this case, we can describe asymptotic behavior of reward step-sum pro-
cesses κε(t) under weaker than G condition, which admits extremal behavior
of functions fε:

I: fε → f0 ∈ [0, ∞] as ε → 0.

J

ε κε(t), t ≥ 0

The following lemma generalizes and supplements Lemma 5.
Lemma 6. Let conditions B and H hold. Then, (i) f −1

−→
g0(t) = t, t ≥ 0 as ε → 0. (ii) Condition I is necessary and suﬃcient
condition for holding (for some or any initial distributions ¯qε, respectively, in
d−→
statements of necessity and suﬃciency) of the asymptotic relation, κε(1)
θ0 as ε → 0, where θ0 is a non-negative proper or improper random variable.
d−→ f0, i.e., it is a constant, and
In this case, (iii) the random variable θ0
−→ f0t as ε → 0, for every t > 0. Moreover, (v) if f0 ∈ [0, ∞)
(iv) κε(t)
−→ f0t, t ≥ 0 as ε → 0; and (vi) if f0 = ∞ then,
then, κε(t), t ≥ 0
min(T, κε(t)), t > 0
−→ hT (t) = T, t > 0 as ε → 0, for every T > 0.

P

J

J

Proof. We can use the following representation,

κε(t) = Xi∈X

µ∗

ε,i(t)vεπε,ifε,i, t ≥ 0.

(52)

For any sequence 0 < εn → 0 as n → ∞, there exists a subsequence

0 < εnk → 0 as k → ∞ such that

vnkπεnk ,ifεnk ,i

fεnk

→ gi ∈ [0, 1] as k → ∞, for i ∈ X.

(53)

Constants gi, i ∈ X can depend on the choice of subsequence εnk, but,

obviously satisfy the following relation,

gi = 1.

Xi∈X

23

(54)

Since the limiting processes in relations (18) given in Lemma 3 are non-

random functions, relations (18) and (53) obviously imply that

f −1
εnk

κεnk

(t), t ≥ 0 d−→ Xi∈X

tgi = t, t ≥ 0 as k → ∞.

(55)

Moreover, since the processes on the left hand side of the above rela-
tion are nondecreasing and the limiting function is continuous, the following
relation (see, for example, Lemma 3.2.2 from Silvestrov (2004)) holds,

f −1
εnk

κεnk

(t), t ≥ 0

J

−→ Xi∈X

tgi = t, t ≥ 0 as k → ∞.

(56)

Since the limiting process is the same for all subsequences εnk described

above, relation (56) implies that the following relation holds,

f −1
ε κε(t), t ≥ 0

J

−→ g0(t) = t, t ≥ 0 as ε → 0.

(57)

Relation (57) implies that random variables f −1

d−→ t as ε → 0, for
every t ≥ 0. This implies that the random variables κε(1) = fε · (f −1
ε κε(1))
can converge in distribution if and only if fε → f0 ∈ [0, ∞] as ε → 0.
Moreover, in this case, the limiting (possibly improper) random variable is
constant f0, and κε(t)

−→ f0t as ε → 0, for every t ≥ 0.

ε κε(t)

P

If f0 ∈ [0, ∞), then the asymptotic relation penetrating propositions
(v) can be obtained by application of Theorem 3.2.1 from Silvestrov (2004)
to processes κε(t) = gε(f −1
ε κε(t)), t ≥ 0, which are compositions processes
f −1
ε κε(t), t ≥ 0 and functions gε(t) = fεt, t ≥ 0.

If f0 = ∞ then the asymptotic relation penetrating proposition (vi)
can be obtained by application of Theorem 3.2.1 from Silvestrov (2004).
to processes min(T, κε(t)) = hε,T (f −1
ε κε(t)), t > 0, which are compositions
processes f −1

ε κε(t), t > 0 and functions hε,T (t) = min(T, fεt), t > 0.

Let us now assume that the asymptotic relation penetrating proposition

(ii) holds but condition I does not hold.

Relation fε 6→ f0 ∈ [0, ∞] as ε → 0 holds if and only if there exist at least
n → f ′
0 ∈ [0, ∞]
0 . In this case,
0 as n → ∞ and, thus, random

two subsequences 0 < ε′
n → f ′′
as n → ∞, (b) fε′′
κε′
variables κε(1) do not converge in distribution. (cid:3)

n, ε′′
0 ∈ [0, ∞] as n → ∞ and (c) f ′

n → 0 as n → ∞ such that (a) fε′
0 6= f ′′

0 as n → ∞ and κε′′

−→ f ′′

n(1)

P

−→ f ′

P

n(1)

24

4. Asymptotics of ﬁrst-rare-event times for Markov chains.

The following lemma describe asymptotics for ﬁrst-rare-event times νε for

Markov chains ηε,n.

Note that in this section, we always use function vε = p−1
ε .
Lemma 7. Let conditions A and B hold. Then, the random variables
d−→ ν0 as ε → 0, where ν0 is a random variable exponentially

ν ∗
ε = pενε
distributed with parameter 1.

Proof. Let us deﬁne probabilities, for ε ∈ (0, ε0],

Pε,ij = Pi{ηε,1 = j, ζε,1 = 0}, ˜pε,ij =

Pε,ij

Pr∈X Pε,ir

=

Pε,ij

1 − pε,i

, i, j ∈ X.

Let also ˜ηε,n, n = 0, 1, . . . be a homogeneous Markov chain with the phase
space X, an initial distribution ¯qε = hqε,i, i ∈ Xi and the matrix of transition
probabilities k˜pε,ijk.

The following relation takes place, for t ≥ 0,

P{ν ∗

ε > t} = Xi∈X

qε,i Xi=i0,i1,...,i[tvε]∈X

= Xi∈X

qε,i Xi=i0,i1,...,i[tvε]∈X

[tvε]

Yk=1

[tvε]

Yk=1

Pε,ik−1ik

˜pε,ik−1ik(1 − pε,ik−1)

= E exp{−

[tvε]

Xk=1

− ln(1 − pε,˜ηε,k−1)}.

(58)

Conditions A and B imply that condition B holds for transition prob-
abilities of the Markov chains ˜ηε,n, since, the following relation holds, for
i, j ∈ X,

|pε,ij − ˜pε,ij| =

|pε,ij(1 − pε,i) − Pε,ij|

1 − pε,i

=

≤

|Pi{ηε,1 = j, ζε,1 = 0} − pε,ijpε,i|

1 − pε,i

2pε,i

1 − pε,i

→ 0 as ε → 0.

(59)

25

Thus, by Lemma 1, there exist ε′′

˜ηε,n is ergodic, for every ε0 ∈ (0, ε′′
satisfy the following relation,

0 ∈ (0, ε′

0] such that the Markov chain
0], and its stationary probabilities ˜πε,i, i ∈ X

˜πε,i − πε,i → 0 as ε → 0, for i ∈ X.

(60)

We can apply Lemma 5, which is a particular case of Theorem 2, to the

nonnegative step-sum process,

κ∗
ε(t) =

[tvε]

Xn=1

− ln(1 − pε,˜ηε,n−1), t ≥ 0.

(61)

To do this, we should check that condition G holds for functions fε(i) =
− ln(1 − pε,i), i ∈ X. Indeed, using condition A, B, Lemma 1 and relation
(60), we get,

fε = −vεXi∈X
∼ vεXi∈X

˜πε,i ln(1 − pε,i) ∼ vεXi∈X

˜πε,i pε,i

πε,i pε,i = vεpε = 1 as ε → 0.

(62)

This relation is a variant of condition G. In this case the corresponding
limiting constant θ0 = 1 and the process θ0(t) = t, t ≥ 0 is a non-random
linear function. By applying suﬃciency proposition of Lemma 5 to the step-
sum process κ∗

ε(t), we get the following relation,

ε(t), t ≥ 0 d−→ θ0(t) = t, t ≥ 0 as ε → 0.
κ∗

(63)

The expression on the right hand side of relation () is, just, the Laplace
transform of the nonnegative random variable κ∗
ε(t) at point 1. Thus, relation
(63) implies, by continuity theorem for Laplace transforms, that the following
relation holds, for every t ≥ 0,

P{ν ∗

ε > t} = Ee−κ∗

ε (t) → e−t as ε → 0.

(64)

The proof is complete. (cid:3)
Let, as in Lemma 8, fε,i, i ∈ X be nonrandom nonnegative numbers and

fε = vεPi∈X πε,ifε,i. Let us introduce stochastic processes,

[tνε]

νε(t) =

Xn=1

fε,ηε,n−1, t ≥ 0.

26

(65)

J

The following lemma generalizes Lemma 7 and is used in what follows.
Lemma 8. Let conditions A, B and H hold. Then, (i) f −1
ε νε(t), t ≥
0
−→ tν0, t ≥ 0 as ε → 0, where ν0 is a random variable exponentially
distributed with parameter 1. (ii) Condition I is necessary and suﬃcient
condition for holding (for some or any initial distributions ¯qε, respectively, in
d−→
statements of necessity and suﬃciency) of the asymptotic relation, νε(1)
ν as ε → 0, where ν is a non-negative random variable with distribution
not concentrated in zero. In this case, (iii) the random variable ν d= f0ν0.
Moreover, (iv) if f0 ∈ [0, ∞) then, νε(t), t ≥ 0
−→ f0ν0t, t ≥ 0 as ε → 0,
−→ hT (t) = T, t > 0 as ε → 0,
and, (v) if f0 = ∞ then, min(T, νε(t)), t > 0
for every T > 0 and, thus, (vi) νε(t)

−→ ∞ as ε → 0, for t > 0.

P

J

J

Proof. The following representation takes place,

νε(t) = κε(tν ∗

ε ), t ≥ 0,

(66)

where κε(t) are processes deﬁned in relation (50).

Relations given in proposition (i) of Lemma 6 and in Lemma 7 imply, by

Slutsky theorem, the following relation,

(tν ∗

ε , f −1

ε κε(t)), t ≥ 0 d−→ (tν0, t), t ≥ 0 as ε → 0.

(67)

The components of the processes on the left hand side of relation (67) are
non-decreasing processes and the process on the right hand side of relation
(67) is continuous. This let us apply Theorem 3.2.1 from Silvestrov (2004)
to processes f −1
ε ), t ≥ 0 and to get the asymptotic relation
penetrating the proposition (i) of Lemma 8.

ε νε(t) = f −1

ε κε(tν ∗

ε νε(1)

Relation penetration proposition (i) of Lemma 8 implies that random
d−→ ν0 as ε → 0. This implies that random variables
variables f −1
νε(1) = fε · (f −1
ε νε(1)) can converge in distribution if and only if fε → f0 ∈
[0, ∞] as ε → 0. Moreover, in this case, the limiting (possibly improper)
random variable ν d= f0ν0.

If f0 ∈ [0, ∞), then relations given in proposition (iv) of Lemma 6 and

in Lemma 7 imply, by Slutsky theorem, the following relation,
ε , κε(t)), t ≥ 0 d−→ (tν0, f0t), t ≥ 0 as ε → 0.

(tν ∗

(68)

The components of the processes on the left hand side of relation (68)
are non-decreasing processes and the process on the right hand side of re-
lation (67) is continuous. This let us apply Theorem 3.2.1 from Silvestrov

27

(2004) to processes νε(t) = κε(tν ∗
penetrating the proposition (iv) of Lemma 8.

ε ), t ≥ 0 and to get the asymptotic relation

If f0 = ∞, then relations given in proposition (v) of Lemma 6 and in

Lemma 7 imply, by Slutsky theorem, the following relation,

(tν ∗

ε , min(T, κε(t))), t > 0 d−→ (tν0, T ), t > 0 as ε → 0, for T > 0.

(69)

The components of the processes on the left hand side of relation (69)
are non-decreasing processes and the process on the right hand side of re-
lation (67) is continuous. Also the limiting random variable tν0 > 0 with
probability 1, for every t > 0. This let us apply Theorem 3.2.1 (and
the remarks made in Subsection 3.2.6) from Silvestrov (2004) to processes
min(T, νε(t)) = min(T, κε(tν ∗
ε )), t > 0 and to get the asymptotic relation
penetrating the proposition (v) of Lemma 8.

Proposition (vi) of this lemma is the direct corollary of proposition (v).
Let us now assume that the asymptotic relation penetrating proposition

(ii) holds but condition I does not hold.

Relation fε 6→ f0 ∈ [0, ∞] as ε → 0 holds if and only if there exist at least
n → f ′
0 ∈ [0, ∞]
0 . In this case,
0 ν0 as n → ∞ and, thus, random

two subsequences 0 < ε′
n → f ′′
as n → ∞, (b) fε′′
νε′
variables νε(1) do not converge in distribution. (cid:3)

0ν0 as n → ∞ and νε′′

n, ε′′
0 ∈ [0, ∞] as n → ∞ and (c) f ′

n → 0 as n → ∞ such that (a) fε′
0 6= f ′′

n(1)

d−→ f ′

n(1)

d−→ f ′′

5. Asymptotics of ﬁrst-rare-event times for semi-Markov

processes.

Proof of Theorem 1. Now we are prepared to complete the proof of
this theorem. Let us, ﬁrst, concentrate attention on propositions (i) and (ii)
of this theorem.

Let us introduce Laplace transforms,

ϕε,ij(ı, s) = EiI(ηε,1 = j, ζε,1 = ı)e−sκε,1, s ≥ 0, for i, j ∈ X, ı = 0, 1,

and

ϕε,i(ı, s) = EiI(ζε,1 = ı)e−sκε,1, s ≥ 0, for i ∈ X, ı = 0, 1.

Let also introduce conditional Laplace transforms,

φε,ij(ı, s) = Ei{I(ηε,1 = j)e−sκε,1/ζε,1 = ı}, s ≥ 0, for i, j ∈ X, ı = 0, 1,

28

and

φε,i(ı, s) = Ei{e−sκε,1/ζε,1 = ı}, s ≥ 0, for i ∈ X, ı = 0, 1.

Now, let us deﬁne probabilities, for s ≥ 0,

pε,s,ij =

=

ϕε,ij(0, s)
ϕε,i(0, s)

, i, j ∈ X.

ϕε,ij(0, s)

Pr∈X ϕε,ij(0, s)

Let (ηε,s,n, ζε,s,n), n = 0, 1, . . . be, for every s ≥ 0, a Markov renewal
process, with the phase space X × {0, 1}, the initial an initial distribution
¯qε = hqε,i = P{ηε,0 = i, ζε,s,0 = 0} = P{ηε,s,0 = i}, i ∈ Xi and transition
probabilities,

P{ηε,s,n+1 = j, ζε,s,n+1 = /ηε,s,n = i, ζε,s,n = ı}

= P{ηε,s,n+1 = j, ζε,s,n+1 = /ηε,s,n = i}
= pε,s,ij(pε,i  + (1 − pε,i)(1 − )), i, j ∈ X, ı,  = 0, 1.

(70)

Note that the ﬁrat component of the Markov renewal process, ηε,s,n, n =
0, 1, . . . is a homogeneous Markov chain with the phase space X, an initial dis-
tribution ¯qε = hqε,i, i ∈ Xi and the matrix of transition probabilities kpε,s,ijk.

Let us also introduce random variables,

νε,s = min(n ≥ 1 : ζε,s,n = 1).

(71)

Let us prove that condition D or conditions A, B and the asymptotic
relation penetrating proposition (i) of Theorem 1 imply that, for every s ≥ 0,
condition B holds for transition probabilities of the Markov chain ηε,s,n.

Condition D obviously, implies that, for i ∈ X,

ϕε,i(s) → 1 as ε → 0, for s ≥ 0,

(72)

Let us show that conditions A, B and the asymptotic relation penetrating

proposition (i) of Theorem 1 also implies that relation (72) holds.

Let us use representation,

µε,i(νε)

[µ∗

ε,i(νε)πε,ivε]

ξε = Xi∈X

Xn=1

κε,i,n = Xi∈X

Xn=1

κε,i,n.

(73)

Let us now assume that relation (72) does not holds. This means that
there exists i ∈ X such that for some δ, p > 0 and εδ,p ∈ (0, ε′
0] probabil-
ity P{κε,i,1 ≥ δ} ≥ p, for ε ∈ (0, εδ,p]. This obviously implies that random

29

P

κε,i,n

variables ˜κε,i(t) = P[tπε,ivε]

n=1

−→ ∞ as ε → 0, for t > 0, and, thus,
d−→ hT (t) = T, t > 0 as ε → 0.
stochastic processes min(T, ˜κε,i(t)), t > 0
Since, the processes ˜κε,i(t), t > 0 are non-decreasing and the limiting func-
tion hT (t) = T, t > 0 is continuous, the latter relation implies (see, for ex-
ample, Theorem 3.2.1 from Silvestrov (2004)) that min(T, ˜κε,i(t)), t > 0
−→
hT (t) = T, t ≥ 0 as ε → 0. Also, by Lemma 8, applied to the model
with functions fε,j = I(j = i)(πε,ivε)−1, j ∈ X, the following relation takes
d−→ ν0 as ε → 0, where ν0 is a random variable exponentially
place, µ∗
distributed with parameter 1. The latter two relations imply, by Slutsky
ε ), min(T, ˜κε,i(t))), t > 0 d−→ (ν0, hT (t)), t > 0 as ε → 0.
theorem, that (µ∗
Now we can apply Theorem 2.2.1 from Silvestrov (2004) that yields the fol-
d−→ T as ε → 0, for any T > 0. This
lowing relation, min(T, ˜κε,i(µ∗
ε )))
ε,i(ν ∗
is possible only if ˜κε,i(µ∗
−→ ∞ as ε → 0. Thus, random variables
˜κε,i(µ∗
−→ ∞ as ε → 0. This relation con-
tradicts to the asymptotic relation penetrating proposition (i) of Theorem 1.

ε ))) = Pn=1 µε,i(νε)κε,i,n ≤ ξε

ε,i(ν ∗
ε )))

P

P

J

ε,i(ν ∗
ε )

ε,i(ν ∗

ε,i(ν ∗

Relation (72) and condition A imply the following relation,

ϕε,i(s, 0) = EiI(ζε,1 = 0)e−sκε,1 → 1 as ε → 0, for s ≥ 0, i, j ∈ X.

(74)

which implies that, for s ≥ 0,

pε,ij − pε,s,ij =

pε,ijϕε,i(0, s) − ϕε,ij(0, s)

ϕε,i(0, s)

≤

≤

≤

|pε,ijϕε,i(0, s) − pε,ij| + |pε,ij − ϕε,ij(0, s)|

ϕε,i(0, s)

pε,ij|ϕε,i(0, s) − 1| + EiI(ηε,1 = j)|1 − I(ζε,1 = 0)e−κε,1)|

ϕε,i(0, s)

2(1 − ϕε,i(0, s))

ϕε,i(0, s)

→ 0 as ε → 0, for i, j ∈ X.

(75)

Thus, for every s ≥ 0, there exist ε′
chain ˜ηε,n,s is ergodic, for every ε ∈ (0, ε′
πε,s,i, i ∈ X satisfy the following relation,

0,s ∈ (0, ε0] such that the Markov
0,s], and its stationary probabilities

πε,s,i − πε,i → 0 as ε → 0, for i ∈ X.

(76)

Let us assume that Markov chains ηε,n and ηε,n,s has the same initial

distribution ¯qε.

30

The following representation takes place for the Laplace transform of the

random variables ξε, for s ≥ 0,

∞

n−1

ϕε,ik−1ik(0, s)ϕε,in−1in(1, s)

ϕε,ik−1ik (0, s) Xin∈X

ϕε,in−1in(1, s)

n−1

n−1

qε,i

qε,i

qε,i

∞

∞

Yk=1
Xn=1 Xi=i0,i1,...,in∈X
Yk=1
Xn=1 Xi=i0,i1,...,in−1∈X
Xn=1 Xi=i0,i1,...,in−1∈X
Yk=1

Ee−sξε = Xi∈X
= Xi∈X
= Xi∈X
× (1 − pε,ik−1)φε,ik−1(0, s)pε,in−1 Xin∈X
= Xi∈X

Xn=1 Xi=i0,i1,...,in−1∈X

n−1

Yk=1

qε,i

∞

pε,s,ik−1ik

pε,s,ik−1ik

ϕε,in−1,in(1, s)

pε,in−1

× (1 − pε,ik−1)φε,ik−1(0, s)pε,in−1φε,in−1(1, s)

= E exp{−

νε,s

Xk=1

− ln φε,ηε,s,k−1(0, s)

− ln φε,ηε,s,νε,s−1(0, s) + ln φε,ηε,s,νε,s−1(1, s)}.

(77)

Relation (74) and condition A imply that the following relation holds,

φε,i(0, s) =

φε,i(0, s)
1 − pε,i

→ 1 as ε → 0, for s ≥ 0, i ∈ X.

(78)

Also condition C is equivalent to the following relation,

φε,i(1, s) = Ei{e−sκε,1/ζε,1 = 1} → 1 as ε → 0, for s ≥ 0, i ∈ X.

(79)

The above two relations obviously imply that,

| ln φε,ηε,s,νε,s−1(0, s)| + | ln φε,ηε,s,νε,s−1(1, s)|

P

−→ 0 as ε → 0, for s ≥ 0. (80)

Representation (77) and relation (80) imply the following relation,

Ee−sξε ∼ Ee−˜νε,s as ε → 0, for s > 0.

(81)

31

where

˜νε,s =

νε,s

Xn=1

− ln φε,ηε,s,k−1(0, s).

(82)

Relations (76), (78) and proposition (i) of Lemma 1 imply that,

πε,s,i ln φε,i(0, s)

πε,s,i(1 − φε,i(0, s))

Aε(s) = −vεXi∈X
∼ vεXi∈X
∼ vεXi∈X

πε,i(1 − φε,i(0, s)) as ε → 0, for s > 0.

(83)

Let us assume that condition D holds additionally to conditions condi-

tions A – C.

Condition D is equivalent to condition D1, and, thus, due to relations
(78) and (79), condition A and proposintion (i) of Lemma 1, to the following
relation,

vε(1 − ϕε(s)) = vεXi∈X
= vεXi∈X
= vεXi∈X
∼ vεXi∈X
∼ vεXi∈X

πε,i(1 − ϕε,i(s))

πε,i(1 − (1 − pε,i)φε,i(0, s) − pε,iφε,i(1, s))

πε,i((1 − pε,i)(1 − φε,i(0, s)) + pε,i(1 − φε,i(1, s))

πε,i(1 − pε,i)(1 − φε,i(0, s))

πε,i(1 − φε,i(0, s)) → A(s) as ε → 0, for s > 0,

(84)

where A(s) > 0, for s > 0 and A(s) → 0 as s → 0.

Relations (83) and (84) imply that, in this case,

Aε(s) = −vεXi∈X

πε,s,i ln φε,i(0, s) → A(s) as ε → 0, for s > 0.

(85)

Now, we can, for every s > 0, apply the suﬃciency statement of propo-
sition (iv) of Lemma 8 to random variables ˜νε,s. This yields, the following
relation,

˜νε,s

d−→ A(s)ν0 as ε → 0, for s > 0,

(86)

32

where ν0 is exponentially distributed random variable with parameter 1.

This relation implies, by continuity theorem for Laplace transforms, the

following relation,

Ee−sξε ∼ Ee−˜νε,s → Ee−A(s)ν0 =

1

1 + A(s)

as ε → 0, for s > 0.

(87)

Relation (87) proves suﬃciency statements of propositions (i) and (ii) of

Theorem 1.

Let now assume that conditions A – C plus proposition (i) of Theorem

1 hold.

The asymptotic relation (in proposition (i) of Theorem 1) expressed in
terms of Laplace transforms takes the form of relation (which should be
assumed to hold for some initial distributions ¯qε),

Ee−sξε → e−A0(s) as ε → 0, for s > 0,

(88)

where A0(s) > 0 for s > 0 and A0(s) → 0 as s → 0.

Let us assume that conditions A – C hold but condition D does not

holds.

The latter assumption means, due to relation (83), that either (a) Aε(s) →
A(s) ∈ (0, ∞) as s → 0, for every s > 0, but A(s) 6→ 0 as ε → 0, or (b)
Aε(s∗) 6→ A(s∗) ∈ (0, ∞) as ε → 0, for some s∗ > 0. The latter relation
holds if and only if there exist at least two subsequences 0 < ε′
n → 0
n(s∗) → A′(s∗) ∈ [0, ∞] as n → ∞, (b2)
as n → ∞ such that (b1) Aε′
Aε′′

n(s∗) → A′′(s∗) ∈ [0, ∞] as n → ∞ and (b3) A′′(s∗) < A′(s∗).
In the case (a), we can repeat the part of the above proof presented in
relations (83) – (91) and, taking into account relation (88), to get relation,
Ee−sξε ∼ Ee−˜νε,s → 1
1+A(s) = e−A0(s) as ε → 0, for s > 0. This relation implies
that A(s) → 0 as ε → 0, i.e., the case (a) is impossible.

n, ε′′

In the case (b), sub-case, A′(s∗) = ∞, is impossible.

Indeed, as was
shown in the proof of Lemma 8, applied to random variables ˜νε,s∗, in this
n ,s∗ → 0 as n → ∞.
case, ˜νε′
This relation contradicts to relation (88).

−→ ∞ as n → ∞, and, thus, Ee−s∗ξε′

n ∼ Ee−˜νε′

n,s∗

P

Sub-case, A′′(s∗) = 0, is also impossible.

proof of Lemma 8, random variables ˜νε,s∗, in this case, ˜νε′′
and, thus, Ee−s∗ξε′′
to relation (88).

n ∼ Ee−˜νε′′

Indeed, as was shown in the
−→ 0 as n → ∞,
n ,s∗ → 1 as n → ∞. This relation also contradicts

n,s∗

P

33

n,s∗

n,s∗

Finally, the remaining sub-case, 0 < A′′(s∗) < A′(s∗) < ∞, is also im-
possible. Indeed, the suﬃciency statement of Lemma 7 applied to random
d−→ A′(s∗)ν0 as n → ∞
variables ˜νε,s∗ yields, in this case, two relations ˜νε′
d−→ A′′(s∗)ν0 as n → ∞, where ν0 is exponentially distributed
and ˜νε′′
random variable with parameter 1. These relations imply that Ee−s∗ξε′
n ∼
Ee−˜νε′
n ∼ Ee−˜νε′′
1+A′′(s∗) as
n → ∞. These relations contradict to relation (88), since
1+A′′(s∗) .
Therefore, condition D should hold. This complete the proof of proposi-

1+A′(s∗) as n → ∞ and Ee−s∗ξε′′

n,s∗ → 1

n,s∗ →
1+A′(s∗) 6=

1

1

1

tions (i) and (ii) of Theorem 1.

The following lemma brings together the asymptotic relations given in
Theorem 2 and Lemma 7. The proposition of this lemma gives the last
intermediate result required for completing the proof of proposition (iii) in
Theorem 1.

ε , κε(t)), t ≥ 0

Lemma 9. Let conditions A, B, C and D hold. Then, the following
d−→ (ν0, θ0(t)), t ≥ 0 as ε →
asymptotic relation holds, (ν ∗
0, (a) ν0 is a random variable, which has the exponential distribution with
parameter 1, (b) θ0(t), t ≥ 0 is a nonnegative L´evy process with the Laplace
transforms Ee−sθ0(t) = e−tA(s), s, t ≥ 0, with the cumulant A(s) deﬁned in
condition D, (c) the random variable ν0 and the process θ0(t), t ≥ 0 are
independent.

Proof. The following representation takes place, for s, t ≥ 0,

EI(ν ∗

ε > t)e−sκε(t) = Xi∈X

qε,i Xi=i0,i1,...,i[tvε]∈X

= Xi∈X

qε,i Xi=i0,i1,...,i[tvε]∈X

[tvε]

Yk=1

[tvε]

Yk=1

ϕε,ik−1ik(0, s)

pε,s,ik−1ik

× (1 − pε,ik−1)φε,ik−1(0, s)

= E exp{−

[tvε]

Xk=1

(− ln(1 − pε,˜ηε,k−1)

− ln φε,˜ηε,k−1(0, s))}.

(89)

Using condition A, B, Lemma 1 and relation (76), we get, for s ≥ 0, the

34

following analogue of relation (62),

˜πε,s,i ln(1 − pε,i) ∼ vεXi∈X

˜πε,s,i pε,i

fε,s = −vεXi∈X
∼ vεXi∈X

πε,i pε,i = vεpε = 1 as ε → 0.

(90)

Relations (85) and (90) and imply that Lemma 5 can, for every s > 0, be

applied to the processes,

κε,s(t) =

[tvε]

Xk=1

(− ln(1 − pε,˜ηε,k−1) − ln φε,˜ηε,k−1(0, s)), t ≥ 0.

(91)

This yields that the following relation holds, for every s > 0,

κε,s(t), t ≥ 0 d−→ t + A(s)t, t ≥ 0 as ε → 0.

(92)

Let us denote, for i, j ∈ X, n = 0, 1, . . . , s ≥ 0,

Ψε,ij(n, s) = EiI(νε > n, ηε,n = j)e−s Pn

k=1 κε,k,

and

Ψε,i(n, s) = EiI(νε > n)e−s Pn

k=1 κε,k = Xj∈X

Ψε,ij(n, s).

Relation (92) implies, by continuity theorem for Laplace transforms, the

following relation, for t ≥ 0,

EI(ν ∗

ε > t)e−sκε(t) = Ψε,i([tvε], s)

= Ee−κε,s(t) → e−t−A(s)t
= e−te−A(s)t as ε → 0, for s > 0.

(93)

Let us also denote, for i, j ∈ X, n = 0, 1, . . . , s ≥ 0,

ψε,ij(n, s) = EiI(ηε,n = j)e−s Pn

k=1 κε,k,

and

ψε,i(n, s) = Eie−s Pn

k=1 κε,k = Xj∈X

ψε,ij(n, s).

35

Relation (93) easily implies that, for s > 0 and 0 ≤ t′′ ≤ t′ < ∞,

Ψε,i([t′vε] − [t′′vε], s) ∼ Ψε,i([(t′ − t′′)vε], s)

→ e−(t′−t′′)e−A(s)(t′−t′′) as ε → 0,

(94)

Also the proposition (iii) of Theorem 2 easily implies that, for s > 0 and

0 ≤ t′′ ≤ t′ < ∞.

ψε,i([t′vε] − [t′′vε], s) ∼ ψε,i([(t′ − t′′)vε], s)

→ e−A(s)(t′ −t′′) as ε → 0.

(95)

Relations (94) and (95) imply that, for s > 0 and 0 ≤ t′′ ≤ t′ < ∞,

Ψε,ij([t′vε] − [t′′vε], s)

Xj∈X

= Ψε,i([t′vε] − [t′′vε], s) → e−(t′−t′′)e−A(s)(t′ −t′′) as ε → 0.

(96)

and

ψε,ij([t′vε] − [t′′vε], s)

Xj∈X

= ψε,i([t′vε] − [t′′vε], s) → e−A(s)(t′ −t′′) as ε → 0.

(97)

Now, we shall use the following representation for multivariate joint dis-
tributions of random variable ν ∗
ε and increments of stochastic process κε(t)
for 0 = t0 ≤ t1 < · · · tk = t ≤ tk+1 ≤ · · · ≤ tn < ∞, 1 ≤ k < n < ∞ and
s1, . . . , sn ≥ 0,

n

EI(ν ∗

ε > tk) exp{−

sr(κε(tr) − κε(tr−1)}

Ψε,ir−1ir ([trvε] − [tr−1vε], sr)

Xr=1
Yr=1

k

n

qε,i0

= Xi0,...,in∈X
Yr=k+1
qε,i0 Xi1∈X

= Xi0∈X

×

ψε,ir−1ir ([trvε] − [tr−1vε], sr)

Ψε,i0i1([t1vε] − [t0vε], s1)

36

Ψε,ik−1ik([tkvε] − [tk−1vε], sk)

ψε,ikik+1([tk+1vε] − [tkvε], sk+1)

· · · × Xik ∈X
× Xik+1∈X
· · · × Xin∈X

ψε,in−1in([tnvε] − [tn−1vε], sn)

(98)

Using relations (96), (97) and representation (98) we get recurrently, for
0 = t0 ≤ t1 < · · · tk = t ≤ tk+1 ≤ · · · ≤ tn < ∞, 1 ≤ k < n < ∞ and
s1, . . . , sn > 0,

EI(ν ∗

ε > tk) exp{−

n

Xr=1

sr(κε(tr) − κε(tr−1))}

∼ EI(ν ∗

ε > tk) exp{−

n−1

Xr=1

sr(κε(tr) − κε(tr−1))}e−A(sn)(tn −tn−1)

· · · ∼ EI(ν ∗

ε > tk) exp{−

k

Xr=1

sr(κε(tr) − κε(tr−1))}

× exp{

n

Xr=k+1

−A(sr)(tr − tr−1)}

∼ EI(ν ∗

ε > tk−1) exp{−

k−1

Xr=1

sr(κε(tr) − κε(tr−1))}

n

× exp{−(tk − tk−1)} exp{

−A(sr)(tr − tr−1)}

Xr=k
Xr=1

n

· · · ∼ exp{−

k

Xr=1

(tr − tr−1)} exp{

−A(sr)(tr − tr−1)}

= exp{−t} exp{

n

Xr=1

−A(sr)(tr − tr−1)} as ε → 0.

(99)

This relation is equivalent an form of the asymptotic relation given in

Lemma 9. (cid:3)

Now, we can complete the proof of Theorem 1.
The asymptotic relation given in Lemma 9 can, obviously, be rewritten

37

in the following equivalent form,

(tν ∗

ε , κε(t)), t ≥ 0 d−→ (tν0, θ0(t)), t ≥ 0 as ε → 0,

(100)

where the random variable ν0 and the stochastic process θ0(t), t ≥ 0 are
described in Lemma 9.

Asymptotic relation given in proposition (iii) of Theorem 2 and relation
(100) let us apply Theorem 3.4.1 from Silvestrov (2004) to the compositions
of stochastic processes κε(t), t ≥ 0 and tν ∗
ε , t ≥ 0 that yield the following
relation,

ξε(t) = κε(tν ∗

ε ), t ≥ 0

J

−→ θ0(tν0), t ≥ 0 as ε → 0.

(101)

The proof of Theorem 1 is complete. (cid:3)

References

[1] Aldous, D.J. (1982). Markov chains with almost exponential hitting times. Stoch.

Proces. Appl., 13, 305–310.

[2] Alimov, D., Shurenkov, V.M. (1990a). Markov renewal theorems in triangular array
model. Ukr. Mat. Zh., 42, 1443–1448 (English translation in Ukr. Math. J., 42,
1283–1288).

[3] Alimov, D., Shurenkov, V.M. (1990b). Asymptotic behavior of terminating Markov
processes that are close to ergodic. Ukr. Mat. Zh., 42, 1701–1703 (English translation
in Ukr. Math. J., 42 1535–1538).

[4] Anisimov, V.V. (1971a). Limit theorems for sums of random variables on a Markov
chain, connected with the exit from a set that forms a single class in the limit. Teor.
Veroyatn. Mat. Stat., 4, 3–17 (English translation in Theory Probab. Math. Statist.,
4, 1–13).

[5] Anisimov, V.V. (1971b). Limit theorems for sums of random variables in array of
sequences deﬁned on a subset of states of a Markov chain up to the exit time. Teor.
Veroyatn. Mat. Stat., 4, 18–26 (English translation in Theory Probab. Math. Statist.,
4, 15–22).

[6] Anisimov, V.V. (1988). Random Processes with Discrete Components. Vysshaya

Shkola and Izdatel’stvo Kievskogo Universiteta, Kiev, 183 pp.

[7] Anisimov, V.V. (2008). Switching Processes in Queueing Models. Applied Stochastic

Methods Series. ISTE, London and Wiley, Hoboken, NJ, 345 pp.

[8] Asmussen, S. (1994). Busy period analysis, rare events and transient behavior in

ﬂuid ﬂow models. J. Appl. Math. Stoch. Anal., 7, no. 3, 269–299.

[9] Asmussen, S. (2003). Applied probability and queues. Second edition. Applications
of Mathematics, 51, Stochastic Modelling and Applied Probability. Springer, New
York, xii+438 pp.

38

[10] Asmussen, S., Albrecher, H. (2010). Ruin probabilities. Second edition. Advanced
Series on Statistical Science & Applied Probability, 14, World Scientiﬁc, Hackensack,
NJ, xviii+602 pp.

[11] Bening, V.E., Korolev, V.Yu. (2002). Generalized Poisson Models and their Appli-
cations in Insurance and Finance. Modern Probability and Statistics, VSP, Utrecht,
432 pp.

[12] Benois, O., Landim, C., Mourragui, M. (2013). Hitting times of rare events in Markov

chains. J. Stat. Phys., 153, no. 6, 967–990.

[13] Billingsley, P. (1968, 1999). Convergence of Probability Measures. Wiley Series in

Probability and Statistics, Wiley, New York, x+277 pp.

[14] Brown, M., Shao, Y. (1987). Identifying coeﬃcients in spectral representation for

ﬁrst passage-time distributions. Prob. Eng. Inf. Sci., 1 69–74.

[15] Darroch, J., Seneta, E. (1965). On quasi-stationary distributions in absorbing

discrete-time ﬁnite Markov chains. J. Appl. Probab., 2, 88–100.

[16] Darroch, J., Seneta, E. (1967). On quasi-stationary distributions in absorbing

continuous-time ﬁnite Markov chains. J. Appl. Probab., 4, 192–196.

[17] Drozdenko, M. (2007a). Weak convergence of ﬁrst-rare-event times for semi-Markov

processes. I. Theory Stoch. Process., 13(29), no. 4, 29–63.

[18] Drozdenko, M. (2007b). Weak Convergence of First-Rare-Event Times for Semi-

Markov Processes. Doctoral dissertation 49, M¨alardalen University, V¨aster˚as.

[19] Drozdenko, M. (2009). Weak convergence of ﬁrst-rare-event times for semi-Markov

processes. II. Theory Stoch. Process., 15(31), no. 2, 99–118.

[20] Ele˘ıko, Ya.I., Shurenkov, V.M. (1995). Transient phenomena in a class of matrix-
valued stochastic evolutions. Teor. ˇImorvirn. Mat. Stat., 52, 72–76 (English transla-
tion in Theory Probab. Math. Statist., 52, 75–79).

[21] Feller, W. (1966, 1971). An Introduction to Probability Theory and Its Applications,

Vol. II. Wiley Series in Probability and Statistics, Wiley, New York, 669 pp.

[22] Gikhman, I.I., Skorokhod, A.V. (1971). Theory of Random Processes. 1. Probability
Theory and Mathematical Statistics, Nauka, Moscow, 664 pp. (English edition: The
Theory of Stochastic Processes. 1. Fundamental Principles of Mathematical Sciences,
210, Springer, New York (1974) and Berlin (1980), viii+574 pp.).

[23] Glynn, P. (2011). On exponential limit laws for hitting times of rare sets for Harris
chains and processes. In: Glynn, P. Mikosch, T. and Rolski, T. (Eds). New Frontiers
in Applied Probability: a Festschrift for Sren Asmussen, J. Appl. Probab. Spec. Vol.
48A, 319–326.

[24] Gnedenko, B.V., Korolev, V.Yu. (1996). Random Summation. Limit Theorems and

Applications. CRC Press, Boca Raton, FL, 288 pp.

[25] Gut, A., Holst, L. (1984). On the waiting time in a generalized roulette game. Statist.

Probab. Lett., 2, no. 4, 229–239.

[26] Gyllenberg, M., Silvestrov, D.S. (1994). Quasi-stationary distributions of a stochastic

metapopulation model. J. Math. Biol., 33, 35–70.

[27] Gyllenberg, M., Silvestrov, D.S. (1999). Quasi-stationary phenomena for semi-
Markov processes. In: Janssen, J., Limnios, N. (Eds). Semi-Markov Models and
Applications. Kluwer, Dordrecht, 33–60.

39

[28] Gyllenberg, M., Silvestrov, D.S. (2000). Nonlinearly perturbed regenerative processes
and pseudo-stationary phenomena for stochastic systems. Stoch. Process. Appl., 86,
1–27.

[29] Gyllenberg, M., Silvestrov, D.S. (2008). Quasi-Stationary Phenomena in Nonlinearly
Perturbed Stochastic Systems. De Gruyter Expositions in Mathematics, 44, Walter
de Gruyter, Berlin, ix+579 pp.

[30] Hassin, R., Haviv, M. (1992) Mean passage times and nearly uncoupled Markov

chains. SIAM J. Disc Math., 5, 386–397.

[31] Kaplan, E.I. (1979). Limit theorems for exit times of random sequences with mixing.
Teor. Veroyatn. Mat. Stat., 21, 53–59 (English translation in Theory Probab. Math.
Statist., 21, 59–65).

[32] Kaplan, E.I. (1980). Limit Theorems for Sum of Switching Random Variables with an
Arbitrary Phase Space of Switching Component. Candidate of Science dissertation,
Kiev State University.

[33] Kalashnikov, V.V. (1997). Geometric Sums: Bounds for Rare Events with Applica-

tions. Mathematics and its Applications, 413, Kluwer, Dordrecht, xviii+265 pp.

[34] Kartashov, N.V. (1987). Estimates for the geometric asymptotics of Markov times
on homogeneous chains. Teor. Veroyatn. Mat. Stat., 37, 66–77 (English translation
in Theory Probab. Math. Statist., 37, 75–88).

[35] Kartashov, N.V. (1991). Inequalities in R´enei’s theorem. Teor. ˇImovirn. Mat. Stat.,

45, 27–33 (English translation in Theory Probab. Math. Statist., 45, 23–28).

[36] Kartashov, N.V. (1996). Strong Stable Markov Chains, VSP, Utrecht and TBiMC,

Kiev, 138 pp.

[37] Kartashov, M.V. (2013). Quantitative and qualitative limits for exponential asymp-
totics of hitting times for birth-and-death chains in a scheme of series. Teor.
ˇImovirn. Mat. Stat., 89, 40–50 (English translation in Theory Probab. Math. Statist.,
89, 45–56).

[38] Keilson, J. (1966). A limit theorem for passage times in ergodic regenerative pro-

cesses. Ann. Math. Statist., 37, 866–870.

[39] Keilson, J. (1979). Markov Chain Models – Rarity and Exponentiality. Applied Math-

ematical Sciences, 28, Springer, New York, xiii+184 pp.

[40] Kijima, M. (1997). Markov Processes for Stochastic Modelling. Stochastic Modeling

Series. Chapman & Hall, London, x+341 pp.

[41] Kingman, J.F. (1963). The exponential decay of Markovian transition probabilities.

Proc. London Math. Soc., 13, 337–358.

[42] Korolyuk, D.V., Silvestrov D.S. (1983). Entry times into asymptotically receding
domains for ergodic Markov chains. Teor. Veroyatn. Primen., 28, 410–420 (English
translation in Theory Probab. Appl., 28, 432–442).

[43] Korolyuk, D.V., Silvestrov D.S. (1984). Entry times into asymptotically receding
regions for processes with semi-Markov switchings. Teor. Veroyatn. Primen., 29,
539–544 (English translation in Theory Probab. Appl., 29, 558–563).

[44] Korolyuk, V.S. (1969). On asymptotical estimate for time of a semi-Markov process

being in the set of states. Ukr. Mat. Zh., 21, 842–845.

40

[45] Korolyuk, V.S., Korolyuk, V.V. (1999). Stochastic Models of Systems. Mathematics

and its Applications, 469, Kluwer, Dordrecht, xii+185 pp.

[46] Koroliuk, V.S., Limnios, N. (2005). Stochastic Systems in Merging Phase Space.

World Scientiﬁc, Singapore, xv+331 pp.

[47] Korolyuk, V., Swishchuk, A. (1992). Semi-Markov Random Evolutions. Naukova
Dumka, Kiev, 254 pp. (English revised edition: Semi-Markov Random Evolutions.
Mathematics and its Applications, 308, Kluwer, Dordrecht, 1995, x+310 pp.).

[48] Korolyuk, V.S., Turbin, A.F. (1970). On the asymptotic behaviour of the occupation
time of a semi-Markov process in a reducible subset of states. Teor. Veroyatn. Mat.
Stat., 2, 133–143 (English translation in Theory Probab. Math. Statist., 2, 133–143).
[49] Korolyuk, V.S., Turbin, A.F. (1976). Semi-Markov Processes and its Applications.

Naukova Dumka, Kiev, 184 pp.

[50] Korolyuk, V.S., Turbin, A.F. (1978). Mathematical Foundations of the State Lump-
ing of Large Systems. Naukova Dumka, Kiev, 218 pp. (English edition: Mathematics
and its Applications, 264, Kluwer, Dordrecht, 1993, x+278 pp.)

[51] Kovalenko, I.N. (1973). An algorithm of asymptotic analysis of a sojourn time of
Markov chain in a set of states. Dokl. Acad. Nauk Ukr. SSR, Ser. A, no. 6, 422–426.
[52] Kovalenko, I.N. (1965) On the class of limit distributions for thinning ﬂows of ho-

mogeneous events. Litov. Mat. Sbornik, 5, 569–573.

[53] Kovalenko, I.N. (1994). Rare events in queuing theory – a survey. Queuing Systems

Theory Appl., 16, no. 1-2, 1–49.

[54] Kovalenko, I.N., Kuznetsov, M.Ju. (1981). Renewal process and rare events limit
theorems for essentially multidimensional queueing processes. Math. Operat. Statist.,
Ser. Statist., 12, no. 2, 211–224.

[55] Kupsa, M., Lacroix, Y. (2005). Asymptotics for hitting times. Ann. Probab., 33 ,

no. 2, 610–619.

[56] Latouch, G., Louchard, G. (1978). Return times in nearly decomposible stochastic

processes. J. Appl. Probab., 15, 251–267.

[57] Lo`eve, M. (1977). Probability Theory. I. Fourth edition. Graduate Texts in Mathe-

matics, 45, Springer, New York, xvii+425 pp.

[58] Masol, V.I., Silvestrov, D.S. (1972). Record values of the occupation time of a semi-

Markov process. Visnik Kiev. Univ., Ser. Mat. Meh., 14, 81–89.

[59] Motsa, A.I., Silvestrov, D.S. (1996). Asymptotics of extremal statistics and
functionals of additive type for Markov chains. In: Klesov, O., Korolyuk, V., Kull-
dorﬀ, G., Silvestrov, D. (Eds). Proceedings of the First Ukrainian–Scandinavian Con-
ference on Stochastic Dynamical Systems, Uzhgorod, 1995. Theory Stoch. Proces.,
2(18), no. 1-2, 217–224.

[60] Serlet, L. (2013). Hitting times for the perturbed reﬂecting random walk. Stoch.

Process. Appl., 123, no. 1, 110–130.

[61] Shurenkov, V.M.

theory in
asymptotical problems of theory of random processes 1. Mat. Sbornik, 112, 115–132
(English translation in Math. USSR: Sbornik, 40, no. 1, 107–123 (1981)).

(1980a). Transition phenomena of

the renewal

[62] Shurenkov, V.M.

theory in
asymptotical problems of theory of random processes 2. Mat. Sbornik, 112, 226–241
(English translation in Math. USSR: Sbornik, 40, no. 2, 211–225 (1981)).

(1980b). Transition phenomena of

the renewal

41

[63] Silvestrov, D.S. (1970). Limit theorems for semi-Markov processes and their applica-
tions. 1, 2. Teor. Veroyatn. Mat. Stat., 3, 155–172, 173–194 (English translation in
Theory Probab. Math. Statist., 3, 159–176, 177–198).

[64] Silvestrov, D.S. (1971). Limit theorems for semi-Markov summation schemes. 1.
Teor. Veroyatn. Mat. Stat., 4, 153–170 (English translation in Theory Probab. Math.
Statist., 4, 141–157).

[65] Silvestrov, D.S. (1974). Limit Theorems for Composite Random Functions. Vysshaya

Shkola and Izdatel’stvo Kievskogo Universiteta, Kiev, 318 pp.

[66] Silvestrov, D.S. (1980). Semi-Markov Processes with a Discrete State Space. Library

for an Engineer in Reliability, Sovetskoe Radio, Moscow, 272 pp.

[67] Silvestrov, D.S. (1981). Theorems of large deviations type for entry times of a se-
quence with mixing. Teor. Veroyatn. Mat. Stat., 24, 129–135 (English translation in
Theory Probab. Math. Statist., 24, 145–151).

[68] Silvestrov, D.S. (1995). Exponential asymptotic for perturbed renewal equations.
Teor. ˇImovirn. Mat. Stat., 52, 143–153 (English translation in Theory Probab. Math.
Statist., 52, 153–162).

[69] Silvestrov, D.S. (2000). Nonlinearly perturbed Markov chains and large deviations
for lifetime functionals. In: Limnios, N., Nikulin, M. (Eds). Recent Advances in Re-
liability Theory: Methodology, Practice and Inference. Birkh¨auser, Boston, 135–144.
[70] Silvestrov D.S. (2004). Limit Theorems for Randomly Stopped Stochastic Processes.

Probability and Its Applications, Springer, London, xvi+398 pp.

[71] Silvestrov D.S. (2014). Improved asymptotics for ruin probabilities. In: Silvestrov,
D., Martin-L¨of, A. (Eds). Modern Problems in Insurance Mathematics, Chapter 5,
EAA series, Springer, Cham, 93–110.

[72] Silvestrov, D. (2016). Necessary and suﬃcient conditions for convergence of ﬁrst-
rare-event times for perturbed semi-Markov processes. Research Report 2016-4, De-
partment of Mathematics, Stockholm University, 39 pp.

[73] Silvestrov, D.S., Abadov, Z.A. (1991). Uniform asymptotic expansions for exponen-
tial moments of sums of random variables deﬁned on a Markov chain and distribu-
tions of entry times. 1. Teor. Veroyatn. Mat. Stat., 45, 108–127 (English translation
in Theory Probab. Math. Statist., 45, 105–120).

[74] Silvestrov, D.S., Abadov, Z.A. (1993). Uniform representations of exponential mo-
ments of sums of random variables deﬁned on a Markov chain, and of distributions
of passage times. 2. Teor. Veroyatn. Mat. Stat., 48, 175–183 (English translation in
Theory Probab. Math. Statist., 48, 125–130).

[75] Silvestrov, D.S., Drozdenko, M.O. (2005). Necessary and suﬃcient conditions for the
weak convergence of the ﬁrst-rare-event times for semi-Markov processes. Dopov.
Nac. Akad. Nauk Ukr., Mat. Prirodozn. Tekh. Nauki, no. 11, 25–28.

[76] Silvestrov, D.S., Drozdenko, M.O. (2006a). Necessary and suﬃcient conditions for
weak convergence of ﬁrst-rare-event times for semi-Markov processes. I. Theory
Stoch. Process., 12(28), no. 3-4, 151–186.

[77] Silvestrov, D.S., Drozdenko, M.O. (2006b). Necessary and suﬃcient conditions for
weak convergence of ﬁrst-rare-event times for semi-Markov processes. II. Theory
Stoch. Process., 12(28), no. 3-4, 187–202.

42

[78] Silvestrov, D., Silvestrov, S. (2015). Asymptotic expansions for stationary distribu-
tions of perturbed semi-Markov processes. Research Report 2015-9, Department of
Mathematics, Stockholm University, 75 pp.

[79] Silvestrov, D.S., Velikii, Yu.A. (1988). Necessary and suﬃcient conditions for conver-
gence of attainment times. In: Zolotarev, V.M., Kalashnikov, V.V. (Eds). Stability
Problems for Stochastic Models. Trudy Seminara, VNIISI, Moscow, 129–137 (English
translation in J. Soviet. Math., 57, (1991), 3317–3324).

[80] Simon, H.A., Ando, A. (1961). Aggregation of variables in dynamic systems.

Econometrica, 29, 111–138.

[81] Skorokhod, A.V. (1964). Random Processes with Independent Increments. Probabil-
ity Theory and Mathematical Statistics, Nauka, Moscow, 278 pp. (English edition:
Nat. Lending Library for Sci. and Tech., Boston Spa, 1971).

[82] Skorokhod, A.V. (1986). Random Processes with Independent Increments. Second
edition, Probability Theory and Mathematical Statistics, Nauka, Moscow, 320 pp.
(English edition: Mathematics and its Applications, 47, Kluwer, Dordrecht, 1991,
xii+279 pp.).

[83] Stewart, G.W. (1998). Matrix Algorithms. Vol. I. Basic Decompositions. SIAM,

Philadelphia, PA, xx+458 pp.

[84] Stewart, G.W. (2001). Matrix Algorithms. Vol. II. Eigensystems. SIAM, Philadel-

phia, PA, xx+469 pp.

[85] Turbin, A.F. (1971). On asymptotic behavior of time of a semi-Markov process being
in a reducible set of states. Linear case. Teor. Verotatn. Mat. Stat., 4, 179–194
(English translation in Theory Probab. Math. Statist., 4, 167–182).

[86] Yin, G.G., Zhang, Q. (2005). Discrete-time Markov chains. Two-time-scale methods
and applications. Stochastic Modelling and Applied Probability, Springer, New York,
xix+348 pp.

[87] Yin, G.G., Zhang, Q. (2013). Continuous-time Markov chains and applications. A
two-time-scale approach. Second edition. Stochastic Modelling and Applied Proba-
bility, 37, Springer, New York, xxii+427 pp.

[88] Zakusilo, O.K. (1972a). Thinning semi-Markov processes. Teor. Veroyatn. Mat. Stat.,

6, 54–59 (English translation in Theory Probab. Math. Statist., 6, 53–58).

[89] Zakusilo, O.K. (1972b). Necessary conditions for convergence of semi-Markov pro-
cesses that thin. Teor. Veroyatn. Mat. Stat., 7, 65–69 (English translation in Theory
Probab. Math. Statist., 7, 63–66).

43

