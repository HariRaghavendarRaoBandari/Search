6
1
0
2

 
r
a

 

M
0
2

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
2
2
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Quantum machine learning over inﬁnite dimensions

Hoi-Kwan Lau,1 Raphael Pooser,2, 3 George Siopsis,3, ∗ and Christian Weedbrook4

1Institute of Theoretical Physics, Ulm University, Albert-Einstein-Allee 11, 89069 Ulm, Germany

2Quantum Information Science Group, Oak Ridge National Laboratory, Oak Ridge, Tennessee 37831, U.S.A

3Department of Physics and Astronomy, The University of Tennessee, Knoxville, Tennessee 37996-1200, U.S.A.

4CipherQ, 10 Dundas St E, Toronto, M5B 2G9, Canada

(Dated: March 22, 2016)

Machine learning is a fascinating and exciting ﬁeld within computer science. Recently, this ex-
citement has been transferred to the quantum information realm. Currently, all proposals for the
quantum version of machine learning utilize the ﬁnite-dimensional substrate of discrete variables.
Here we generalize quantum machine learning to the more complex, but still remarkably practi-
cal, inﬁnite-dimensional systems. We present the critical subroutines of quantum machine learning
algorithms for an all-photonic continuous-variable quantum computer that achieve an exponential
speedup compared to their equivalent classical counterparts. Finally, we also map out an experi-
mental implementation which can be used as a blueprint for future photonic demonstrations.

I.

INTRODUCTION

We are now in the age of big data [1]. An unprece-
dented era in history where the storing, managing and
manipulation of information is no longer eﬀective using
previously used computational tools and techniques. To
compensate for this, one important approach in manip-
ulating such large data sets and extracting worthwhile
inferences, is by utilizing machine learning techniques.
Machine learning [2–6] involves using specially tailored
‘learning algorithms’ to make important predictions in
ﬁelds as varied as ﬁnance, business, fraud detection, and
counter terrorism. Tasks in machine learning can involve
either supervised or unsupervised learning and can solve
such problems as pattern and speech recognition, classi-
ﬁcation, and clustering. Interestingly enough, the over-
whelming rush of big data in the last decade has also been
responsible for the recent advances in the closely related
ﬁeld of artiﬁcial intelligence [7]; with the achievements of
AlphaGo being a remarkable milestone.

Another important ﬁeld in information processing
which has also seen a signiﬁcant increase in interest in
the last decade is that of quantum computing [8]. Quan-
tum computers are expected to be able to perform cer-
tain computations much faster than any classical com-
puter. In fact, quantum algorithms have been developed
which are exponentially faster than their classical coun-
terparts [9–18]. Recently, a new subﬁeld within quantum
information has emerged combining ideas from quantum
computing with artiﬁcial intelligence to form quantum
machine learning. Such discrete-variable schemes have
shown exponential speedup in learning algorithms, such
as supervised and unsupervised learning [19], support
vector machine [20], cluster assignment [21] and oth-
ers [22–25, 70].
Initial proof-of-principle experimental
demonstrations have also been performed [27–30].

In this paper, we have developed learning algorithms

∗ siopsis@tennessee.edu

based on a diﬀerent, but equally important, type of sub-
strate in quantum computing, those of continuous vari-
ables (CVs) [31, 32]. A CV system is characterized by
having an inﬁnite-dimensional Hilbert space described by
measuring variables with a continuous eigenspectra. The
year 1999 saw the ﬁrst important attempt at developing
a CV model of quantum computing [33]. Seven years
later, the cluster state version [34] of CVs [35, 36], ac-
celerated the ﬁeld’s interest due to experimental inter-
est. The result of this were proof-of-principle demonstra-
tions [37–40], which culminated in an ‘on-the-run’ 10, 000
node cluster [41], as well as a 60-node ‘simultaneous’ clus-
ter [42]. Further important theoretical work was also car-
ried out [43–52], including an important CV architecture
that was ﬁnally fault tolerant [53].

Here, we take advantage of the practical beneﬁts of
CVs (high-eﬃciency room-temperature detectors, broad
bandwidths,
large-scale entanglement generation, etc.)
by generalizing quantum machine learning to the inﬁnite
dimension. Speciﬁcally, we develop the important CV
tools and subroutines that form the basis of the exponen-
tial speedup in various machine learning algorithms. This
includes matrix inversion, principle component analysis
and vector distance. Furthermore, each of these crucial
subroutines are given a ﬁnite squeezing analysis for fu-
ture experimental demonstrations along with a suggested
photonic implementation.

This paper is organized as follows. In Sec. II, we be-
gin by introducing the required encoding schemes and
various gates needed for our algorithms. In Sec. III, we
introduce the machine learning algorithms for CVs. In
Sec. IV, we give a photonic experimental implementa-
tion, followed by a discussion and concluding remarks in
Sec. V.

II. QUANTUM MACHINE LEARNING FOR

CONTINUOUS VARIABLES

Encoding — Storing a set of classical data, a ≡
{ax; x = 1, . . . , N}, requires at least N classical mem-

ory cells. On the other hand, only n = logd N quantum
memory cells are required to store the same data in a
quantum state

|˜ai =

N

Xx=1

1
|a|

ax|xi ,

(1)

where d is the number of encoding state in each quan-
tum memory (qudit or qumode - a ‘qumode’ is the CV
version of a qubit); |xi ≡ |x1i ⊗ |x2i ⊗ . . .|xni is a ten-
sor product of states in n modes; x = (x1x2 . . . xn) is a
d-nary representation of x; ˜a ≡ a/|a| is the normalized
a. Although obtaining the classical value of each data
ax requires O(N ) copies of quantum states, in some ap-
plications, particularly machine learning, only the global
behavior of the data set is interesting. Quantum machine
learning algorithms take advantage of this property to re-
duce the amount of memory and operations needed.

In CV systems, in principle each qumode contains in-
ﬁnite orthogonal states that are available for encoding
but not necessarily accessible. For simplicity, we employ
only two coherent states as the logical state in each mode,
i.e., for d = 2, |0Li ≡ |αi and |1Li ≡ | − αi. For a suf-
ﬁciently large α, the two logical states are orthogonal,
i.e., h0L|1Li = e−4α2
≈ 0. The superposition of such
states are known as cat states. Note that our algorithms
also apply to other encoding schemes as well, e.g., Fock
state, superposition of squeezed states [54], but we will
speciﬁcally consider the cat state encoding here.

We show in Appendix A that the encoding state |ai
in Eq. (1) can be eﬃciently created - provided that the
data is suﬃciently homogeneous. The state construc-
tion of general data could be constructed eﬃciently by
extending the discrete-variable quantum RAM [55] to
a suitable CV encoding (i.e., Fock state, superposition
of squeezed states) or by using a hybrid scheme [74].
Now if the data set is uniformly bounded for large N ,

i.e., |ax| < O(1/√N ), following the method in Ref. [56],
|ai can be constructed by using only the Grover’s op-
erators, eiπ|Ψ0ihΨ0| and eiφ|xihx|. These unitaries can be
generated eﬃciently (for details, again see Appendix A).
The construction starts from the initial state |Ψ0i ≡
x |xi/√N = [(|0Li + |1Li)/√2)]⊗n. By using the
PN
method in Ref.
[21], the Grover’s operators can be im-
plemented by repeatedly applying the exponential swap
operation with the states |xi and |Ψ0i. In our encoding,
the states |xi and |Ψ0i are tensor products of coherent
states and cat states, which can be eﬃciently created in
CV experiments [57].

Exponential swap gate — In both the data state con-
struction and the quantum machine learning operation,
the generalized Grover’s operator, eiρ′t, plays the main
role of inducing a phase shift according to an ensemble of
unknown given states ρ′. As suggested in Ref. [21], such
an operation can be implemented by repeatedly apply-
ing the exponential swap operation and tracing out the
auxiliary mode, i.e.,

2

where by deﬁnition the swap operator functions as
S|ψ1i|ψ2i = |ψ2i|ψ1i.
Here we outline the procedure of implementing the ex-
ponential operator with standard CV techniques. First of
all, we need a qubit as control, which can be implemented
by two auxiliary modes, 1 and 2, with one and only one
photon in both modes, i.e., the state of the modes is
cos θ|01i + i sin θ|10i. The rotation angle θ is controllable
by applying the rotation operator R(θ) ≡ eiθ(ˆa1ˆa†
1ˆa2),
which can be implemented by linear optics [57]. In addi-
tion, we need a controlled-swap operation,

2+ˆa†

S ≡ eiπˆa†
Ccc′

1ˆa1ˆa†

c ˆace

π

2 ˆa†

1ˆa1(ˆacˆa†

c′−ˆa†

c ˆac′ ),

(3)

which swaps the modes c and c′ depending on the photon
number of the control qubit. The operations in Ccc′
can
S
be implemented with the quartic gate introduced in [43,
52]. See Appendix B for more detail.

The control qubit is ﬁrst prepared in |+i ≡ (|01i +
|10i)/√2.
By applying the operations in sequence
exp(iθS) = Ccc′
S

, the state becomes

R(θ)Ccc′
S

Ccc′
S R(θ)Ccc′

S |+i|ψic|φic′ = |+ieiθScc′|ψic|φic′

≡ |+i(cos θ|ψic|φic′ + i sin θ|φic|ψic′) .

(4)

The method can be generalized to implement a multi-
mode exponential swap, exp(iθScc′Sdd′ . . .), by applying
Ccc′
. . .. We note that the precious
S
resources of a single photon state is not measured or dis-
carded, so it can be reused in future operations.

. . . R(θ)Ccc′
S

Cdd′

Cdd′

S

S

III. CV QUANTUM MACHINE LEARNING

ALGORITHMS

Now we discuss several key subroutines (matrix inver-
sion, principle component analysis, and vector distance)
that power the quantum machine learning problems us-
ing the tools we have just introduced.

Matrix inversion — Various machine learning appli-
cations involves high-dimensional linear equations, e.g.,
Ay = b. The advantage of some quantum machine learn-
ing algorithms is the ability to solve linear equations eﬃ-

eﬃcient on a quantum computer [22].

ciently. Speciﬁcally, for any vector b = Pi biei, comput-
ing the solution vector y = A−1b = Pi bi/λiei is more
In a CV system, the algorithm starts by preparing the
state |bi and two auxiliary modes in the q quadrature
eigenstates, i.e., |0iq,R and |0iq,S . We apply the opera-
tor exp(iδγAˆpR ˆpS) 1/δ times. Each operator can be im-
plemented based on Eq. (2), and a modiﬁed exponential
swap gate with the rotation operator in Eq. (4) replaced
by the four-mode operator

R(γ ˆpR ˆpS) = eiγ ˆpR ˆpS (ˆa1ˆa†

2+ˆa†

1ˆa2) ,

(5)

trρ′ (eiδtS ρ ⊗ ρ′e−iδtS) = eiδtρ′

ρe−iδtρ′

+ O(δ2) ,

(2)

which can be implemented eﬃciently [43]. The state then

becomes

eiγAˆpR ˆpS|bi|0iq,R|0iq,S = Xi

biZ |eii|pip,R|γλipiq,Sdp,

(6)
where we have neglected a normalization constant. If the
S auxiliary mode is measured in the q quadrature with
outcome qS, then we get

Xi

bi/λi|eii|qS /γλiip,R .

(7)

Up to the normalization, the solution state |yi =
Pi bi/λi|eii is obtained if the R auxiliary mode is mea-
sured in the q quadrature and we get the result qR = 0.
In the inﬁnitely squeezed case, the successful rate of
the last measurement is vanishing. In practice, however,
when squeezed vacuum states are employed as auxiliary
modes, the successful rate of obtaining an answer state
with error ǫ scales as O(ǫ3/2), which is comparable to the
discrete-variable algorithm that has success which scales
as O(ǫ) [20]. The detailed argument is shown in Ap-
pendix C.
Principal component analysis — The next problem is
to ﬁnd the eigenvalue λ corresponding to a unit eigenvec-
tor ei with respect to the matrix A, i.e., Aei = λiei. This
problem is ubiquitous in science and engineering and can
also be used in quantum tomography, supervised learning
and cluster assignment.

The algorithm starts from a data state |eii and an
auxiliary mode R prepared as the zero eigenstate of the
q quadrature, |0iq,R. The idea of the algorithm is to
apply the operator eiγAˆpR that displaces the auxiliary
mode according to the eigenvalue, i.e.,

eiγAˆpR|eii|0iq,R = |eiieiγλi ˆpR|0iq,R = |eii|γλiiq,R ,

(8)
then the eigenvalue can be obtained by measuring the
auxiliary mode with homodyne detection. This opera-
tor can be implemented by preparing an ensemble such
that the density matrix is ρ′ = A/trA, and repeatedly
(2) to implement eiδAˆpR ,
apply the techniques in Eq.
for γtrA/δ times. Here the argument of the exponen-
tial swap operator is not a c-number but an operator
ˆpR. This can be implemented by replacing the rotation
operator in Eq. (4) by the three-mode operator

R(ˆpR) = eiδ ˆpR(ˆa1ˆa†

2+ˆa†

1ˆa2) ,

(9)

which can be eﬃciently implemented by a cubic phase
gate and linear optics [33, 43].

In practice, the success of the algorithm relies on the
distinguishability of |γλiiq, which depends on the spec-
trum of eigenvalues, the degree of squeezing s of the aux-
iliary state, and the magnitude of error. In Appendix D,
we have shown that O(1/ǫ) operations are needed for an
error ǫ . 1/(γ2s).
Vector distance — In supervised machine learning, new
data is categorized into groups by its similarity to the

3

previous data. For example, the belonging category of a
vector u is determined by the distance, D, to the aver-
age value of the previous data {vi}. The objective of a
quantum machine learning algorithm is to compute the
value D2 ≡ |u −PM

i=1 vi/M|2.
an oracle can generate the state

Following the approach given in Ref. [20], we assume

|Ψi =

1

N (cid:16)|u||0iI|˜ui +

1
√M

M

Xi=i

|vi||iiI|˜vii(cid:17) ,

(10)

where the ﬁrst mode is denoted as the index mode I; the

be known. D2 can be obtained by conducting a swap
test on the index mode with a reference mode prepared

normalization N ≡ p|u|2 +Pi |vi|2/M is supposed to
i=1 |iiR/√M )/√2. Various swap
as |ΦiR ≡ (|0iR − PM

tests for CV systems have been proposed where the result
is obtained from a photon number measurement [58, 59].
Here we propose a swap test that employs only homodyne
detection and an exponential swap operation.

We consider two test modes that are prepared in the
coherent states |βi1|0i2. The operator exp(i π
4S12SIR) is
applied to exponential swap the two test modes, as well
as the reference and the index modes. After that, the test
modes pass through a 50/50 beam splitter. The density
operator of the test modes after tracing out the other
modes becomes

ρ12 =

1

β
2(cid:16)|
√2i11h
−iD2|−β

√2i11h

β

β
√2| + iD2|
√2| + |−β

√2i11h−β
√2|
√2i11h−β
√2|(cid:17) ⊗ |

β

(11)

β
√2i22h

β
√2| .

We ﬁnd that if the 1 mode is homodyne detected in the
p quadrature and β & 4, the probability diﬀerence of
measuring a positive and negative outcome scales as D2,
where the scaling constant is at the order of 0.1 for a
wide range of β. See Appendix E for further details.

IV. ALL-PHOTONIC IMPLEMENTATION

In this section, we outline an all-photonic implementa-
tion of the previously mentioned machine learning algo-
rithms. First, one must create an ancillary state for use
in the exponential swap gate. One method is to provide
a heralded ancilla via parametric down conversion (see
for example [57], for background on a lot of the stan-
dard quantum optics methods discussed here). The un-
detected photon is interfered with the vacuum on a 50/50
beam splitter in order to place it in the superposition re-
quired for Eq. (4) (see Fig. 1). This serves as an input to
the phase-dependent gates outlined in [43], which can be
used to construct the exponential swap gate. The rota-
tion gate in Eq. (4) is essentially the interference of the
two modes on a variable reﬂectivity, or programmable
beam splitter, which can be achieved via polarization

4

FIG. 1. All-photonic implementation schematic of the operator exp(iθS) = C cc′
mode |+i = (|01i + |10i)/√2 with two (swap) modes C and C ′ used to implement the operators given in Eq. 4. The method
for generating |+i is one of many possibilities, e.g., preparing a heralded superposition of polarization states is illustrated.
χ(2): nonlinear crystal source; APD: avalanche photodiode detector; 50/50: balanced beam splitter; λ/2: half wave plate; PBS:
polarizing beam splitter; C CC′
: controlled-swap operator; R(θ): rotation operator; see text for explanation of operators. Note
that C cc′
S can be implemented with the quartic gate [43, 52] and R(θ) can also be eﬃciently implemented by a cubic phase gate
and linear optics [33, 43].

S . We initially have an ancillary input

S R(θ)C cc′

S

control and a polarizing beam splitter, or via a collec-
tion of phase or amplitude modulators. Inverse phase-
dependent gate operations are implemented after the ro-
tation.

Each algorithm essentially utilizes a variation of this
conﬁguration, in addition to the possibility of squeezed
ancilla in order to increase the accuracy of the result.
The principle component analysis problem replaces the
variable beam splitter in the swap gate with a two-mode
quantum-non-demolition phase gate.
It can be imple-
mented by treating the auxiliary mode, R, as the ancilla
in the phase-dependent gate. Thus, the principle compo-
nent analysis problem essentially relies on repeated ap-
plication of the ‘repeat-until-success’ phase gate [43]. In
a realistic scenario, R is in a single-mode squeezed state
with ﬁnite squeezing (see Appendix C.2), which is experi-
mentally straightforward using a below-threshold optical
parametric ampliﬁer (OPA). Phase sensitive ampliﬁca-
tion can also be used. The squeezing parameter can be
used to tune the accuracy of the computation. The ﬁnal
homodyne detection is also experimentally straight for-
ward with a local oscillator derived from the pump laser
used in the OPA (via a doubling cavity, for instance).

The matrix inversion algorithm is experimentally very
similar to the eigenvalue problem. The key diﬀerence is
the use of an extra auxiliary mode, which can be prepared
independently with an additional OPA. The four-mode
operator is conceptually similar to the operator in Eq. (6)
used in the previous algorithm. Each auxiliary mode
serves as an ancilla in the phase-dependent gate, and
the algorithm otherwise follows a similar approach to the
previous one, with a ﬁnal homodyne detection step for
the amplitude quadrature of each auxiliary mode, with
the local oscillators derived from the pumps of each OPA.

Finally, the vector distance algorithm requires use of a
swap test, which can be implemented via the application
of the exponential swap gate between two auxiliary states
(which can be coherent states or squeezed states) and the
oracle mode in Eq. (10) [20] and the reference mode. The
required homodyne detection of the phase quadrature of

the ﬁrst test mode in a bright coherent state and is again
experimentally straight forward.

V. DISCUSSION AND CONCLUSION

The previous all-photonic implementations are diﬃcult
to do experimentally but are still within current reach of
the latest technological achievements. For instance, high
rates of squeezing are now achievable [60], along with the
generation of cat states [61]. However, we note that our
scheme is not limited to photonic demonstrations but a
variety of substrates, including spin ensemble systems,
such as trapped atoms and solid state defect centers [62–
66].

We hope that the work presented here will lead to fur-
ther avenues of research. Especially since there has been
a substantial increase of results in discrete-variable ma-
chine learning [67–72]. All of these would be interesting
to be generalized to continuous variables as future work.
Additionally, adapting our current work into the cluster-
state formulism [46] would also be interesting in order
to take advantage of state-of-the-art experimental inter-
est and the scalability that continuous variables can pro-
vide [41]. Furthermore, we note another viable option
that uses a ‘best-of-both-worlds’ approach to quantum
information processing, i.e., hybrid schemes [73, 74]. It
would be interesting to adapt our scheme presented here
to such hybrid architectures.

In conclusion, we have introduced the required
continuous-variable quantum gates and (cat state) en-
coding scheme to create machine learning algorithms that
run on a continuous-variable quantum computer. Specif-
ically, these algorithms are the key pieces that provide
the exponential speedup in the machine learning proto-
cols. They included matrix inversion, principle compo-
nent analysis and vector distance. Unlike all previous
results using discrete variables, our approach can take
advantages of the practical aspects of continuous vari-
ables. Finally, we also gave an explicit experimental im-

5

plementation using Gaussian and non-Gaussian optical
elements which would allow for future proof-of-principle
demonstrations.

where Ul = 1 + γlx, and −1/γl are the (complex) roots
of the kth-order polynomial 1 + i γ
K Pk(x). Each linear
operator Ul (l = 0, 1, . . . , K − 1) can be implemented as
discussed in further detail in Ref. [43].

ACKNOWLEDGMENTS

We thank Kevin Marshall

for helpful discussions.
H. -K. L would like to acknowledge support from the
Croucher Foundation. R. C. P. performed portions of
this work at Oak Ridge National Laboratory, operated
by UT-Battelle for the US Department of Energy under
Contract No. DE-AC05-00OR22725.

Appendix C: Matrix inversion

1.

Ideal implementation

We start with qumodes in the state |bi and two re-
source modes in the state |qR = 0i ⊗ |˜qR = 0i. Thus,
initially,

Appendix A: Encoding eﬃciency

|Ψi ∝ |biZ dpRd˜pR|pRi|˜pRi

Here we discuss the encoding eﬃciency as described in
Sec. II. Of particular interest are the Grover operators,

Next, we apply the unitary

eiγApR ˜pR

(C1)

(C2)

eiπ|Ψ0ihΨ0| = I − 2|Ψ0ihΨ0|

(A1)

and eiφ|xihx| (which implements a phase change eiφ on
the state |xi). A repeated application of these unitaries
can create any state |Ψi from |Ψ0i. The complexity C
(number of resources and oracle calls required) varies
depending on the distribution of data. For probability
distributions which remain uniformly bounded for large
N , the complexity has a polynomial dependence on n.

More precisely, this is the case if |ax| . 1/√N , ∀x (for
example, states close to |Ψ0i). Otherwise, the complex-
ity can be as high as O(√N ). The latter is the case for
any state, such as |xi, in which the probability distribu-
tion is highly peaked (although, it should be noted that
a state |xi is easy to construct, because it is the tensor
product of coherent states). The proof follows the lines
of Ref. [56]. The number 1/ǫ of copies of |Ψ0i and |xi
needed for implementation of eiπ|Ψ0ihΨ0| and eiφ|xihx| are
also polynomial in n. Indeed, if λ is the required ﬁdelity,
we have λ ∼ Cǫ, therefore the number of copies of |Ψ0i
and |xi needed is 1/ǫ ∼ C/λ, which is of polynomial order
in n.

where γ is a parameter that can be adjusted at will. The
unitary is implemented similarly to (D2), except that
we now have two resource qumodes. The algorithm is
unchanged, except for the rotation of the ancillas, which

becomes a four-mode unitary, RAB hγ pR ˜pR

n i, and can be

implemented via the quartic gate constructed in [43].

We obtain

βiZ dpRd˜pReiγλipR ˜pR|eii|pRi|˜pRi

eiγApR ˜pR|Ψi ∝ Xi
(C3)
Next, we measure qR of the ﬁrst resource mode. This
projects the state onto

|qRihqR|eiγApR ˜pR|Ψi ∝ Xi

βiZ d˜pRδ(γλi ˜pR − qR)
βi|eii|qRi(cid:12)(cid:12)(cid:12)(cid:12)

×|eii|qRi|˜pRi
∝ Xi

˜pR =

1
λi

γλi(cid:29)
qR

(C4)

Appendix B: Higher-order CV non-Gaussian gates

Here we discuss the implementation of higher-order
gates using CVs. The discussion generalizes the construc-
tion of cubic phase gate given in Ref. [43]. Non-Gaussian
phase gates of order k are of the form eiγPk(x), where
Pk(x) is a polynomial of order k (k > 2). In this paper,
we make use of cubic (k = 3) and quartic (k = 4) phase
gates. To implement them, we ﬁrst decompose them as

Finally, we measure ˜qR. The ﬁnal state is

e−i˜qRqR/(γλi) 1
λi

Xi

βi|eii|qRi|˜qRi

(C5)

For suﬃciently large γ, this is approximately

1
λi

Xi

βi|eii|qRi|0i = |A−1bi|qRi|˜qRi

(C6)

2. Realistic implementation

eiγPk(x) = (cid:16)1 + i

γ
K

Pk(x)(cid:17)K

+ O(1/K)

and further,

1 + i

γ
K

Pk(x) = U0U1 ···UK−1

(B1)

(B2)

Realistically, we start with qumodes that are squeezed

states. Thus, initially,

|Ψi ∝ |biZ dpRd˜pRe−[(pR)2+( ˜pR)2]/(2s)|pRi|˜pRi

(C7)

Ideally, s → ∞. After we apply the unitary (C2), we
obtain

and we expand

eiγApR ˜pR

|Ψi ∝ Xi

βiZ dpRd˜pRe−[(pR)2+( ˜pR)2]/(2s)

we obtain

|bi = Xi

βi|eii

eiγApR|Ψi = Xi

βiZ dpReiγλipR|eii|pRi

6

(D4)

(D5)

×eiγλipR ˜pR

|eii|pRi|˜pRi

(C8)

After we measure qR, ˜qR of the respective resource
modes, we arrive at the ﬁnal state

eiγApR ˜pR|Ψi ∝ Xi

βiAi(qR, ˜qR)|eii|qRi|˜qRi

(C9)

where

Ai(qR, ˜qR) = Z dpRd˜pRe−[(pR)2+( ˜pR)2]/(2s)

×ei(γλipR ˜pR−pRqR− ˜pR ˜qR)
exph− s[(qR)2+(˜q)2]+2is2γλiqR ˜qR

2(1+γ 2λ2

i s2)

λiq1 + 1

γ 2λ2

i s2

∝

i

(C10)

Notice that in the limit s → ∞, this reduces to
γλi i, in agreement with (C5).
Ai(qR, ˜qR) ∝ 1

exph iqR ˜qR
For γ|λi|s ∼ 1√ǫ , we have

λi

|Ai(qR, ˜qR)|2 ∼

i s i
exph− (qR)2+(˜q)2

2γ 2λ2
λi

(C11)

so both qR and ˜qR have probability distributions of
width ∼ γ|λi|√s ∼ O(1/√sǫ). The width of qR ˜qR
is
∼ γ|λi|s ∼ O(1/√ǫ).
. O(ǫ), for a
normal distribution the success rate is O(ǫ3/2).

If we want qR ˜qR
γλi

γλi

Appendix D: Eigenvalue distinguishing

Given an N × N Hermitian matrix A, and a vector |bi,
ﬁnd out if |bi is an eigenvector, and if so, which eigenvalue
it belongs to. In particular, we are interested in matrices
of the form A = ρ − σ, where ρ, σ are both mixed states.

1.

Ideal implementation

We start with n qumodes in the state |bi and a resource

mode R in the state |qR = 0i. Thus, initially,

|Ψi = |biZ dpR|pRi

Next, we apply the unitary

eiγApR

If the eigenvalue problem of A is

A|eii = λi|eii

(D1)

(D2)

(D3)

Next, we measure qR of the resource mode. This projects
the state onto

hqR|eiγApR|Ψi = Xi
= Xi

βiZ dpRei(γλi−qR)pR|eii
βiδ(γλi − qR)|eii

(D6)

Thus, the measurement outcome is proportional to one of
the eigenvalues, qR = λi/γ, for which βi 6= 0. The most
probable outcome corresponds to the maximum |βi|2. We
obtain that outcome with certainty, if |bi is an eigenstate
of A.
All of the above steps are independent of the size of
the matrix, N . This is evident for all steps, except for
the implementation of the unitary (D2). To implement
(D2), we make 1/ǫ copies of ρ and 1/ǫ copies of σ, where
ǫ is the desired accuracy. Let S be the swap operator.
We have
trP eiǫγSpR ρ ⊗ |bihb|e−iǫγSpR = eiǫγρpR|bihb|e−iǫγρpR

+O(ǫ2)

(D7)

where we took a partial trace over the degrees of freedom
of ρ. Similarly for σ,
trP e−iǫγSpR σ ⊗ |bihb|eiǫγSpR = e−iǫγσpR|bihb|eiǫγσpR
(D8)
The smaller the ǫ, the larger the range of pR over which
there is little distortion. Repeating these two steps with
the rest of the copies, we arrive at an approximation of

+O(ǫ2)

eiγApR|bihb|e−iγApR

(D9)

i.e., an implementation of (D2).

The unitary eiǫγSpR itself can be implemented using

eiǫγSpR = I cos ǫγpR + iS sin ǫγpR

(D10)

To implement (D10), we introduce two ancillary modes
in the logical state |0iL, and rotate it to 1√2
(|0iL + |1iL).
Next, we apply the string of three-mode unitaries S, and
arrive at the state

1
√2

(I ⊗ |0i1|1i2 + S ⊗ |1i1|0i2)

(D11)

We then apply the three-mode unitary RAB(ǫγpR),
which is a rotation on the ancillas and can be imple-
mented using the cubic gate constructed in [43] together
with two-mode operators. The state becomes

1
√2
[I ⊗ (cos ǫγpR|0iL + i sin ǫγpR|1iL)
+S ⊗ (cos ǫγpR|1iL + i sin ǫγpR|0iL)]

(D12)

Once again, we apply S and obtain

n + 1 mode resources state, given by

1
√2

[I cos ǫγpR + iS sin ǫγpR] ⊗ (|0iL + |1iL)

(D13)

|Ψi =

7

(E1)

After applying RAB(− π
original state, and we arrive at

4 ), the ancilla goes back to its

[I cos ǫγpR + iS sin ǫγpR] ⊗ |0iL

(D14)

matching (D10), as desired.

2. Realistic implementation

Realistically, we start with a qumode in the state |bi
and a resource mode in a squeezed state. Thus, initially,

|Ψi ∝ |biZ dpRe−(pR)2/(2s)|pRi

(D15)

After we apply the unitary (D2), and measure qR of the
resource mode, we obtain the projected state

hqR|eiγApR|Ψi ∝ Xi
∝ Xi

βiZ dpRe−(pR)2/(2s)ei(γλi−qR)pR|eii
βie−s(γλi−qR)2/2|eii

(D16)

which yields a probability distribution

P (qR) ∝ Xi

|βi|2e−s(γλi−qR)2

(D17)

consisting of peaks at the eigenvalues. Since we are inter-
ested in eigenvalues ±1, to discriminate between them,
the width of the peaks ought to be O(1), so sγ2 & 1. The
number 1/ǫ of copies needed to simulate (D2) must be
such that ǫsγ2 . 1, therefore by adjusting the arbitrary
parameter γ, even a small integer 1/ǫ will suﬃce.

Appendix E: Distance computation

Let u and vi be two N -dimensional unit vectors. We
are interested in computing the distance D between u to
the average of {vi}, i.e.,

D2 ≡ |u −

1
M

M

Xi=1

vi|2 = |u|2 +

1

M 2 Xi,i′ |vi||vi′|˜vi · ˜vi′

1
M

−

M

Xi=1

|u||vi|(˜u∗ · vi + ˜u · v∗i ) .

The objective of quantum machine learning is to mea-
sure the value of D2 without learning all of the coeﬃ-
cients of each data set. Following [20], we consider a

1

N (cid:16)|u||0iI|˜ui +

1
√M

M

Xi=i

|vi||iiI|˜vii(cid:17) ,

where the normalization N ≡ p|u|2 +Pi |vi|2/M is

supposed to be known. We denote the ﬁrst mode as the
index mode I, while the following n modes are the data
modes. Following our argument in Appendix A, if the
data of u and vi are suﬃciently homogeneous, |Ψi can
also be eﬃciently constructed.
In analogous to the discrete-variable algorithm [19],
the value of D2 can be deduced from the probabil-
ity of measuring the index mode in the |Φi ≡ (|0i −
i=1 |ii/√M )/√2 state,
PM
i.e., khΨ|Φik2 = D2/2N 2.
Such a measurement can be achieved by conducting a
swap test between the index mode with an auxiliary ref-
erence mode that is prepared in |Φir. Here we propose
a swap test that involves only homodyne detection and
the exponential swap operation.

Let’s consider two auxiliary test modes that are pre-
pared in coherent states, |β0i12. Then an exponential
swap exp(i π
4S12SIR ) is applied to transform the state as

1

√2N (cid:16)|β0i12(|u||ΦiR|0iI|˜ui +
1
√M
+i|0βi12(|u||0iR|ΦiI|˜ui +

M

1
√M

M

Xi=i

|vi||ΦiR|iiI|˜vii)

Xi=i
|vi||iiR|ΦiI|˜vii)(cid:17) .

After tracing out the index mode, the reference mode,
and the data modes, the total state of the two test modes
becomes

D2

1

D2

ρ12 =

2(cid:16)|β0ihβ0| − i
N 2 |β0ih0β|
N 2|0βihβ0| + |0βih0β|(cid:17)
forms any coherent state as UBS|αβi = | α−β√2
state of the test mode then becomes

After that, we apply a 50/50 beam splitter that trans-
α+β√2 i, the

(E2)

+i

ρ12 =

1

β
2(cid:16)|
√2i11h
D2
N 2|−β

D2

β

β
√2| − i
β

N 2 |
√2| + |−β

√2i11h−β
√2|
√2i11h−β
√2|(cid:17) ⊗ |

+i

√2i11h

β
√2| .
When measuring the ﬁrst test mode in the P quadra-
ture, the probability of obtaining a value p is proportional
to

β
√2i22h

(E3)

P(p) ∝ e−p2

(2 + iei√2pβ D2

N 2 − ie−i√2pβ D2
N 2 ) .

(E4)

We ﬁnd that the probability diﬀerence between the pos-
itive and negative values of p is

P(p > 0) − P(p < 0) = −e−β 2/2erﬁ(

N 2 ,
where erﬁ is the imaginary error function. For β & 4, the
expression is well approximated by ∼ 0.1D2/N 2.

(E5)

)

D2

β
√2

8

[1] http://www.ibm.com/big-data/us/en/
[2] T. Hastie, R. Tibshirani, J. Friedman, The Elements of
Statistical Learning: Data Mining, Inference, and Pre-
diction, (Springer, Cambridge) (2013).

[3] D. Mackay, Information Theory, Inference and Learning

Algorithms (Cambridge University Press, 2003).

[4] E. Alpaydin, Introduction to Machine Learning (Adap-
tive Computation and Machine Learning) (MIT Press,
2004).

(2006).

[36] N. C. Menicucci, et al., Phys. Rev. Lett. 97, 110501

(2006).

[37] S. Yokoyama, R. Ukai, S. C. Armstrong, J.-i. Yoshikawa,
P. van Loock, and A. Furusawa, Phys. Rev. A 92, 032304
(2014).

[38] K. Miyata, H. Ogawa, P. Marek, R. Filip, H. Yonezawa,
J.-i. Yoshikawa, and A. Furusawa, Phys. Rev. A 90,
060302(R) (2014).

[5] C. M. Bishop, Pattern Recognition and Machine Learn-

[39] M. Pysher, Y. Miwa, R. Shahrokhshahi, R. Bloomer, and

ing (Springer, 2007).

[6] K. P. Murphy, Machine Learning: A Probabilistic Per-

spective (MIT Press, 2012).

[7] Yann LeCun, Yoshua Bengio, and Geoﬀrey Hinton, Na-

ture 521, 436 (2015).

[8] T. D. Ladd et al., Nature 464, 45 (2010).
[9] P. W. Shor, SIAM J. Sci. Statist. Comput. 26, 1484

(1997).

[10] S. Lloyd, Science 273, 1073 (1996).
[11] D. S. Abrams and S. Lloyd, Phys. Rev. Lett. 83, 5162

(1999).

[12] D. A. Lidar and H. Wang, Phys. Rev. E 59, 2429 (1999).
[13] J. P. Dowling, Nature 439, 919 (2006).
[14] I. Buluta and F. Nori, Science 326, 108 (2009).
[15] J. Q. You and F. Nori, Nature 474, 589 (2011).
[16] H. Wang, S. Ashhab, and F. Nori, Phys. Rev. A 85,

O. Pﬁster, Phys. Rev. Lett. 107, 030505 (2011).

[40] S. Takeda, T. Mizuta, M. Fuwa, J.-i. Yoshikawa, H.
Yonezawa, and A. Furusawa, Phys. Rev. A 87, 043803
(2013).

[41] S. Yokoyama, R. Ukai, S. C. Armstrong, C. Sornphiphat-
phong, T. Kaji, S. Suzuki, J.-i. Yoshikawa, H. Yonezawa,
N. C. Menicucci, and A. Furusawa, Nat. Phot. 7, 982
(2013).

[42] M. Chen, N. C. Menicucci, and O. Pﬁster, Phys. Rev.

Lett. 112, 120505 (2014).

[43] K. Marshall, R. Pooser, G. Siopsis, and C. Weedbrook,

Phys. Rev. A 91, 032321 (2015).

[44] H.-K. Lau and C. Weedbrook, Phys. Rev. A 88, 042313

(2013)

[45] P. van Loock, C. Weedbrook, and M. Gu, Phys. Rev. A

76, 032321 (2007).

062304 (2012).

[46] M. Gu, C. Weedbrook, N. Menicucci, T. Ralph, and P.

[17] L. Veis, J. Visnak, T. Fleig, S. Knecht, T. Saue, L. Viss-

van Loock, Phys. Rev. A 79, 062318 (2009).

cher, and J. Pittner, Phys. Rev. A 85, 030304 (2012).

[47] R. N. Alexander, S. C. Armstrong, R. Ukai, and N. C.

[18] A. W. Harrow, A. Hassidim, and S. Lloyd, Phys. Rev.

Menicucci, Phys. Rev. A 90, 062324 (2014).

Lett. 103, 150502 (2009).

[48] T. F. Demarie, T. Linjordet, N. C. Menicucci, and G. K.

[19] S.

Lloyd, M. Mohseni,

and P. Rebentrost,

Brennen, New J. Phys. 16, 085011 (2014).

arXiv:1307.0411 (2013).

[49] N. C. Menicucci, T. F. Demarie, and G. K. Brennen,

[20] P. Rebentrost, M. Mohseni, and S. Lloyd, Phys. Rev.

arXiv:quant-ph/1503.00717 (2015).

Lett. 113, 130503 (2014).

[50] P. Wang, M. Chen, N. C. Menicucci, and O. Pﬁster, Phys.

[21] S. Lloyd, M. Mohseni, and P. Rebentrost, Nat. Phys. 10,

Rev. A 90, 032325 (2014).

631 (2014).

[22] A. W. Harrow, A. Hassidim, and S. Lloyd, Phys. Rev.

Lett. 103, 150502 (2009).

[23] E. Aimeur, G. Brassard, and S. Gambs, Machine Learn-

ing 90, 261 (2013).

[51] N. C. Menicucci, Phys. Rev. A 83, 062314 (2011).
[52] K. Marshall, R. Pooser, G. Siopsis, and C. Weedbrook,

Phys. Rev. A 92, 063825 (2015).

[53] N. C. Menicucci, Phys. Rev. Lett. 112, 120504 (2014).
[54] D. Gottesman, A. Kitaev, and J. Preskill, Phys. Rev. A

[24] K.L. Pudenz and D.A. Lidar, Quant. Inf. Proc. 12, 2027

64, 012310 (2001).

(2013).

[55] V. Giovannetti, S. Lloyd, and L. Maccone, Phys. Rev.

[25] A. Hentschel and B. C. Sanders, Phys. Rev. Lett. 104

Lett. 100, 160501 (2008).

(2010).

[56] A. N. Soklakov and R. Schack, Phys. Rev. A 73, 012307

[26] N. Wiebe, A. Kapoor, and K. Svore, Quant. Info. and

(2006).

Comp. 15, 0318 (2015).

[27] X. -D. Cai, et al., Phys. Rev. Lett. 110, 230501 (2013).
[28] S. Barz, et al., Scientiﬁc Reports 4, 6115 (2014).
[29] X. -D. Cai, et al., Phys. Rev. Lett. 114, 110504 (2015).
[30] Z. Li, et al., Phys. Rev. Lett. 114, 140504 (2015).
[31] S. L. Braunstein and P. van Loock, Rev. Mod. Phys. 77,

513 (2005).

[32] C. Weedbrook,

S. Pirandola, R. Garc´ıa-Patr´on,
N. J. Cerf, T. C. Ralph, J. H. Shapiro, and S. Lloyd,
Rev. Mod. Phys. 84, 621 (2012).

[33] S. Lloyd and S. L. Braunstein, Phys. Rev. Lett. 82, 1784

(1999).

[57] A. Furusawa and P. van Loock, Quantum Teleportation
and Entanglement: A Hybrid Approach to Optical Quan-
tum Information Processing (Wiley-VCH, 2011).
[58] R. Filip, Physical Review A, 65, 062320 (2002).
[59] H. Jeong, C. Noh, S. Bae, D. G. Angelakis, T. C. Ralph,
Journal of the Optical Society of America B, 31, 3057.
(2014)

[60] U. L. Andersen, T. Gehring, C. Marquardt, and

G. Leuchs, arXiv:1511.03250 (2015).

[61] W. -B. Gao, et al., Nat. Phys. 6, 331 (2010).
[62] J. P. Dowling, G. S. Agarwal, and W. P. Schleich, Phys.

Rev. A 49, 4101 (1994).

[34] R. Raussendorf and H. J. Briegel, Phys. Rev. Lett. 86,

[63] K. Tordrup, A. Negretti, and K. Molmer, Phys. Rev.

5188 (2001).

Lett. 101, 040501 (2008).

[35] J. Zhang and S. L. Braunstein, Phys. Rev. A 73, 032318

[64] J. H. Wesenberg, et al., Phys. Rev. Lett. 112, 070502

(2009).

[65] Y. Kubo, et al., Phys. Rev. Lett. 105, 140502 (2010).
[66] Y. Kubo, et al., Phys. Rev. Lett. 107, 220501 (2011).
[67] N. Wiebe, D. Braun, and S. Lloyd, Phys. Rev. Lett. 109,

050505 (2012).

[70] N. Wiebe, A. Kapoor, and K. Svore, Quant. Info. and

Comp., 15 318 (2015).

[71] M. H. Amin, E. Andriyash, J. Rolfe, B. Kulchytskyy, and

R. Melko, arXiv:1601.02036 (2016).

[72] N. Wiebe, A. Kapoor, K. M. Svore, arXiv:1602.04799

[68] N. Wiebe, A. Kapoor, and K. M. Svore, arXiv:1412.3489

(2016).

(2014).

[69] G. D. Paparo, V. Dunjko, A. Makmal, M. A. Martin-
Delgado, and H. J. Briegel, Phys. Rev. X 4, 031002
(2014).

[73] N. Liu, et al., arXiv:1510.04758 (2015).
[74] U. L. Andersen, et al., Nat. Phys. 11, 713 (2015).

9

