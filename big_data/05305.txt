6
1
0
2

 
r
a

 

M
6
1

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
5
0
3
5
0

.

3
0
6
1
:
v
i
X
r
a

Near-OptimalStochasticApproximationforOnlinePrincipalComponentEstimationChrisJ.Li∗MengdiWang∗HanLiu∗TongZhang†March16,2016AbstractPrincipalcomponentanalysis(PCA)hasbeenaprominenttoolforhigh-dimensionaldataanalysis.Onlinealgorithmsthatestimatetheprincipalcomponentbyprocessingstreamingdataareoftremendouspracticalandtheoreticalinterests.Despiteitsrichap-plications,theoreticalconvergenceanalysisremainslargelyopen.Inthispaper,wecastonlinePCAintoastochasticnonconvexoptimizationproblem,andweanalyzetheonlinePCAalgorithmasastochasticapproximationiteration.Thestochasticapproximationiterationprocessesdatapointsincrementallyandmaintainsarunningestimateoftheprincipalcomponent.Weprovefortheﬁrsttimeanearlyoptimalconvergenceratere-sultfortheonlinePCAalgorithm.Weshowthattheﬁnite-sampleerrorcloselymatchestheminimaxinformationlowerbound.Inaddition,wecharacterizetheconvergenceprocessusingordinaryandstochasticdiﬀerentialequationapproximations.Keywords:Principalcomponentanalysis,Stochasticapproximation,Nonconvexoptimiza-tion,Stochasticgradientmethod,High-dimensionaldata,Onlinealgorithm,Finite-sampleanalysis,Diﬀerentialequations.1IntroductionPrincipalcomponentanalysis(PCA)(Pearson,1901;Hotelling,1933)isoneofthemostpopulardimensionreductionmethodsforhigh-dimensionaldataanalysis.Ithaswideappli-cationsinbioinformatics,healthcare,imaging,computervision,artiﬁcialintelligence,socialscience,ﬁnanceandeconomy.LetXbearandomvectorinRdwithmeanzeroandunknowncovariancematrixΣ=E(cid:2)XX>(cid:3)∈Rd×d,∗DepartmentofOperationsResearchandFinancialEngineering,PrincetonUniversity,Princeton,NJ08544,USA;e-mail:{junchil,mengdiw,hanliu}@princeton.edu†DepartmentofStatistics,RutgersUniversity,Piscataway,NJ08854,USA;e-mail:tzhang@stat.rutgers.edu1wheretheeigenvaluesofΣareλ1>λ2≥···≥λd>0.PrincipalcomponentanalysisaimstoﬁndtheprincipaleigenvectorofΣthatcorrespondstothelargesteigenvalueλ1,basedonindependentandidenticallydistributedsamplerealizationsX(1),...,X(n).Thiscanbecastedintoanonconvexstochasticoptimizationproblem,givenbymaximizeu>E(cid:2)XX>(cid:3)u,subjecttokuk=1,u∈Rd,(1.1)wherek·kdenotestheEuclideannorm.WeassumethroughoutthispaperthatthecovariancematrixΣhasauniqueprincipalcomponent,whichwedenotebyu∗.Accordingly,theprincipalcomponentu∗istheuniquesolutiontoproblem(1.1).TheclassicalPCAmethodestimatesu∗usingtheprincipalcomponentoftheempiricalcovariance,i.e.,bu(n)=argmaxkuk=1u>bΣ(n)u,wherebΣ(n)istheempiricalcovariancematrixbasedonnsamplesbΣ(n)=1nnXi=1X(i)(cid:0)X(i)(cid:1)>.Thiscanbeviewedasasampleaverageapproximationmethodforproblem(1.1).AccordingtobothliteraturesofPCAandsampleaverageapproximation,itiswell-knownthatthismethodproducesannon-improvablesolutionbu(n),inthesensethattheestimationerrorbu(n)−u∗achievestheinformationlowerbound.Moreprecisely,weareinterestedintheanglebetweenthetwounitvectorsbu(n)andu∗,givenby∠(bu(n),u∗)=arccos(cid:0)bu(n)>u∗(cid:1),(1.2)whichtakesvaluein[0,π].Ithasbeenshownthattheanglebetweenanyestimatoreu(n)thatusesnsamplesandu∗islowerboundedbyinfeu(n)supX∈Md(Σ,1)E(cid:2)sin2∠(eu(n),u∗)(cid:3)≥c·λ1λ2(λ1−λ2)2·dn,(1.3)wherecissomepositiveconstant(Theorem3.1ofVu&Lei(2013)).Heretheinﬁmumofeu(n)istakenoverallprincipaleigenvectorestimators,andMd(Σ,1)isthecollectionofalld-dimensionalsubgaussiandistributionswithmeanzeroandeigengapλ1−λ2>0.ClassicalPCAmethodhastimecomplexityO(nd2)andspacecomplexityO(d2).Whentherawdatahasahighdimension,storingandcomputingalargeempiricalcovariancematrixcanbeexpensive.Inthispaper,wefocusonincrementaloronlinemethodsforprincipalcomponentanalysis.Thesemethodsupdatetheiteratesincrementallybyprocessingdatapointsone-by-one.The2practicalgoalistobeabletolearntheprincipaleigenvector“ontheﬂy”,withoutexplicitlycomputingandstoringtheempiricalcovariancematrixbΣ.Inparticular,wefocusonaniterationforonlinePCAthatwasﬁrstproposedbyOja(1983)asu(n)=Π(cid:8)u(n−1)+βX(n)(X(n))>u(n−1)(cid:9).(1.4)Hereβissomepositivestepsize,andΠdenotestheEuclideanprojectionoperatorontotheunitsphereSd−1={u∈Rd|kuk=1},i.e.Πu=kuk−1uforallu6=0.Theiteration(1.4)onlyrequiresvectorproductoperations.IthastimecomplexityO(d)periteration,andhasspacecomplexityO(d).Iteration(1.4)isveryeasytoimplementinpracticeandhasbeenusedasaheuristicmethodforfastprincipalcomponentanalysis.IncontrasttoclassicalPCAwhichisasampleaverageapproximationmethod,theonlinePCAiteration(1.4)isessentiallyastochasticapproximationiterationfortheoptimizationproblem(1.1).Surprisingly,theoreticalanalysisofitsconvergenceremainslargelyopen.Thetheoreticalchallengeisduetothespecialnonconvexnatureofsphericalconstraints.Inthispaper,weaimtotakeanimportantstepinanalyzingtheconvergenceofonlinePCAmethods.WewillcharacterizethestochasticalgorithmusingaMarkovprocessanditsdiﬀerentialequationapproximations.Morespeciﬁcally,weareinterestedinﬁnite-sampleanalysisoftheonlinePCAiteration,andweaimtomatchtheconvergenceratewiththeinformationlowerbound.Anintriguingopenquestionis:Canonlineprincipalcomponentanalysisbeoptimal?Ananswer“yes”wouldimplythatprincipalcomponentanalysisisassimpleasestimatingthemeanofadistribution,forwhichaniterativeonlineprocessissuﬃcienttoprovidenon-improvableestimates.Ourresultsprovideapartialanswertothisquestion:almostyes.OuranalysisinvolvestheweakconvergencetheoryforMarkovprocesses(Ethier&Kurtz,1985)whichhasapotentialforabroaderclassofstochasticalgorithmsfornonconvexoptimization.1.1RelatedLiteraturesAlthoughtheonlinePCAiteration(1.4)wasproposedoverthirtyyearsago(Oja,1983;Oja&Karhunen,1985),itsconvergencerateanalysisremainssomewhatlimited.Itwasnotuntilrecently,duetotheneedtohandlemassiveamountsofdata,didonlinePCAgainattention.TworecentworksBalsubramanietal.(2013)andShamir(2015a)studytheconvergenceofonlinePCAfromdiﬀerentperspectives,andobtainsomeusefulrateresults.WeprovideadetailedcomparisonbetweentheirresultsandoursinSection2.3.Inthemathematicalprogrammingandstatisticscommunities,thecomputationalandsta-tisticalaspectsofPCAareoftenstudiedseparately.Fromthestatisticalperspective,recentdevelopmentshavefocusedonestimatingprincipalcomponentsforveryhigh-dimensionaldata.Whenthedatadimensionismuchlargerthanthesamplesize,i.e.,d(cid:29)n,classicalmethodusingdecompositionoftheempiricalconvariancematrixproducesinconsistentes-timates(Johnstone&Lu,2009;Nadler,2008).Sparsity-basedmethodshavebeenstudied,suchasthetruncatedpowermethodstudiedbyYuan&Zhang(2013)andWangetal.(2014b).OthersparsityregularizationmethodsforhighdimensionalPCAhasbeenstudied3inJohnstone&Lu(2009);Vu&Lei(2013,2012);Zou(2006);d’Aspremontetal.(2008);Amini&Wainwright(2009);Ma(2013);Caietal.(2013),etc.Notethatinthispaperwedonotconsiderthehigh-dimensionalregimeandsparsityregularization.Fromthecomputationalperspective,poweriterationsortheLanczosmethodarewellstudied.Theseiterativemethodsrequireperformingmultipleproductsbetweenvectorsandempiricalcovariancematrices.Suchoperationusuallyinvolvesmultiplepassesoverthedata,whosecomplexitymayscalewiththeeigengapanddimensions(Kuczynski&Wozniakowski,1992;Musco&Musco,2015;Geetal.,2015).Recently,randomizedalgorithmshavebeendevelopedtoreducethecomputationcomplexity(Shamir,2015c,b;Garber&Hazan,2015).Acriticaltrendtodayistocombinethecomputationalandstatisticalaspectsandtodevelopalgorithmicestimatorthatadmitsfastcomputationaswellasgoodestimationproperties.Relatedliteraturesinclude(Aroraetal.,2012,2013;Mitliagkasetal.,2013;Hardt&Price,2014;Saetal.,2015).TheideaofusingstochasticapproximationforPCAcanbetracedbacktoOja&Karhunen(1985).Stochasticapproximation(SA)wasﬁrststudiedfortherootﬁndingproblemandlaterextendedtostochasticoptimizationandstochasticvariationalinequali-ties;seee.g.,thetextbooksbyKushnerandYinKushner&Yin(2003),byBenvenisteetal.Benvenisteetal.(2012),byBorkarBorkar(2008),byBertsekasandTsitsiklisBertsekas&Tsitsiklis(1989).Theideaofprocessingonesampleatatimeisalsorelatedtotheclassofincrementalmethods,whicharedevelopedforminimizingthesumofalargenumberofcomponentfunctions.Thesemethodsupdateincrementallybymakinguseofonecompo-nentatatime,throughagradient-typeorproximal-typeiteration[seeforexample,Nedi´cetal.(2001),Nedi´c&Bertsekas(2001),Bertsekas(2011),Nedi´c(2011),Wang&Bertsekas(2014b),Wang&Bertsekas(2014a),Wangetal.(2014a)].However,existingconvergencerateanalysisofincrementalalgorithmsdonotapplytotheoptimizationoverthenonconvexsphereconstraint.Inthecontextofmachinelearningandsignalprocessing,stochasticapproximation(ormorecommonlyreferredtoasstochasticgradientdescent)hasbeenextensivelystudiedforstochasticconvexoptimization.Inmachinelearningapplications,theobjectiveisusuallytheexpectationofaconvexlossfunctionparameterizedbyarandomvariable.Ithasbeenshownthatafternsamples/iterations,theaverageoftheiterateshasO(1/n)optimizationerrorforstronglyconvexobjective,andO(1/√n)errorforgeneralconvexobjective(seeRakhlinetal.Rakhlinetal.(2012),ShamirandZhangShamir&Zhang(2013)).Fornonsmoothprob-lemswithnoisygradients,thereareΘ(1/n)andΘ(1/√n)minimaxinformation-theoreticlowerboundsforconvexandstronglyconvexproblems,respectively(seee.g.,Agarwaletal.Agarwaletal.(2012),andseethebookbyNesterovandYudinNemirovsky&Yudin(1983)foracomprehensivestudyonoptimizationcomplexities).Thematchingbetweenthelowerboundsandtheupperboundssuggeststhatstochasticapproximation(orequivalently,stochasticgradient)isoptimalforconvexoptimizationunderthestochasticﬁrst-orderoracle.Incontrast,tothebestknowledgeoftheauthors,therehasbeennosuchworkforstochasticnonconvexoptimizationproblem(1.1)withsphereconstraint.41.2OurContributionsThecontributionsofthisworkissummarizedasfollows.•WeprovidetheﬁrstconvergencerateresultforonlinePCAthatnearlymatchestheinformationminimaxlowerbound(1.3).Weshowthat,whentheinitialiterateu(0)israndomlychosenaccordingtoauniformdistributionandthestepsizeβischoseninaccordancewiththesamplesizen,thereisahigh-probabilityeventA∗withP(A∗)≥1−δsuchthatE(cid:2)tan2∠(u(n),u∗)|A∗(cid:3)≤C(d,n,δ)·λ1λ22(λ1−λ2)2·dlognn,(1.5)whereδisanarbitraryprobabilitythattakesvaluein[0,1].Wealsoshowthat,whenboththedatadimensiondanddatasizenscaleupwithd/n1−ε→0forsomeconstantε∈(0,1),thefactorC(d,n,δ)approachesto(1−δ)−1.Totheauthors’bestknowledge,thisisthetightestconvergenceresultknownfortheonlinePCAiterationunderthenear-optimalscaling,d/n1−ε→0.AdetailedcomparisonbetweenourresultandexistingonesisgiveninSection2.3.•Ourconvergencerateresultsarenearlyglobal.Inparticular,convergencerateresultsholdaslongastheinitialiteratesatisﬁestan2∠(u(0),u∗)≤c∗d,forsomeconstantc∗>0.Heretheerrortolerancescaleslinearlyasthedimensiondincreases.Thisiscriticalbecause,whendislarge,auniformlydistributedinitialiterateisnearlyperpendiculartotheprincipalcomponentwithhighprobability.Ourinitialconditionallowsonetorandomlysampleu(0)accordingtoauniformdistributionoverthesphere,whilepreservingthenear-optimalconvergencerate.Incontrast,mostexistingresultsonPCA,forinstanceYuan&Zhang(2013),requirethattheinitialconditionbe|sin∠(u(0),u∗)|≤1−c0forsomec0∈(0,1).Suchinitialconditionbecomesincreasinglystringentasthedimensiondincreases(Ball,1997).Ourchoiceofinitialiteratedoesnotrequireanypriorknowledgeabouttheprincipalcomponent.Therefore,ourconvergenceresultsarenearlyglobalinthesensethatarandomlyselectedinitialpointachievesnear-optimalconvergenceratewithhighprobability.•WeprovideaMarkovchaincharacterizationofthestochasticprocess{u(n)}generatedbytheonlinePCAiteration.Weshowthat,uponappropriatescalings,theiteratesasaMarkovprocessweaklyconvergestothesolutionofanordinarydiﬀerentialequationsystem,whichisamulti-dimensionalanaloguetothelogisticequations;uponadiﬀerentscalingtheprocessweaklyconvergestotheOrnstein-Uhlenbeckprocesses.ThisistheﬁrstworkthatstudiesonlinePCAfromtheperspectiveofweakconvergencetheoryofMarkovprocesses.Theinﬁnitesimalanalysistogetherwiththediﬀerentialequationapproximationshedslightonconvergencerateanalysisoftheonlinealgorithm.In5addition,weprovidesnewinsightsintotheconnectionbetweenonlinePCAandthetheoryofproductofrandommatrices.Webelievethatthislineofanalysiscanbegeneralizedtoabroaderclassofstochasticalgorithms.Organization.Section2summarizesthemainconvergenceandrateofconvergenceresults,aswellasaﬁnitesampleerroranalysis.Section3studiestheonlinePCAiterationfromtheMarkovchainperspectiveandpresentsthatitadmitsanordinarydiﬀerentialequationapproximationuponappropriatescaling.Section4analyzesthelocalconvergenceofthestochasticiteration,whichwerefertoasthewarmstartphase,aswellasthenear-globalconvergenceofthestochasticiterationundermilderinitialconditions,andgivesdetailedproofsofthemainresults.Notations.Forasequenceof{xk}andpositive{yk},wewritexk=O(yk)ifthereexistsconstantM<∞suchthat|xk|≤Myk.Alsoletbxcdenotesthelargestinteger≤x,anddxethesmallestinteger≥x.Letx∧y=min(x,y)andx∨y=max(x,y).Lastly,E[X;A]denotestheexpectationofXovereventA,i.e.wehaveE[X;A]=E[X1A].2MainResultsInthissection,wepresentthemainconvergenceresultsfortheonlinePCAalgorithm.Thealgorithmmaintainsarunningestimateu(n)ofthetrueprincipalcomponentu∗,andupdatesitwhileinteractingwithanexternaldatasource.DuetothenatureofPCA,weareinterestedintheconvergenceoftheangleprocess{∠(u(n),u∗)}.AdetaileddescriptionofthealgorithmisgivenbyAlgorithm1.Algorithm1OnlinePCAAlgorithmInitializeu(0)andchoosethestepsizeβundersomecondition(tobespeciﬁed)forn=1,2,...doDrawonesampleX(n)fromthedatasourceUpdatetheiterateu(n)byu(n)=Π(cid:8)u(n−1)+βX(n)(X(n))>u(n−1)(cid:9).endfor2.1DistributionalAssumptionsWesummarizeourassumptionsasthefollowingAssumption1.TherandomvectorsX(1),...,X(n)∈RdareindependentandidenticallydistributedwithXandhavethefollowingproperties:(i)E[X]=0andE(cid:2)XX>(cid:3)=Σ;6(ii)TheeigenvaluesofΣareλ1>λ2≥...≥λd>0;(iii)ThereexistsaconstantB>0suchthatkXk2≤Bwithprobability1.Assumption1isamildcondition.Theeigengapλ1−λ2playsakeyroleintheconvergencerateofthestochasticiteration.Forsimplicityoftheanalysis,weassumethattherandomvariablehasboundedsupport.Infact,itispossibletoadaptouranalysistoobtainanalogousresultsforabroaderclassofdistributions,forexamplethesubgaussiandistributions.Itwouldrequireasubstantiallylengthierargument,whichisbeyondthescopeofthecurrentwork.WeletthediagonaldecompositionofthecovariancematrixbeΣ=E(cid:2)XX>(cid:3)=UΛU>,whereΛ=diag(λ1,λ2,...,λd)isadiagonalmatrixwithdiagonalentriesλ1,λ2,...,λd,andUisanorthogonalmatrixconsistingofcolumneigenvectorsofΣ.ClearlytheﬁrstcolumnofUisequaltotheprincipalcomponentu∗.Notethatthediagonaldecompositionmightnotbeunique,inwhichcaseweworkwithanarbitraryone.WedeﬁnetherescaledsamplesasY(n)=U>X(n),v(n)=U>u(n),v∗=U>u∗.(2.1)OnecaneasilyverifythatE[Y]=0,E(cid:2)YY>(cid:3)=Λ;TheprincipalcomponentoftherescaledrandomvariableY,whichwedenotebyv∗,isequaltoe1,where{e1,...,ed}isthecanonicalbasisofRd.ByapplyingthelineartransformationU>tothestochasticprocess{u(n)},weobtainaniterativeprocess{v(n)=U>u(n)}intherescaledspace:v(n)=Πnv(n−1)+βY(n)(cid:0)Y(n)(cid:1)>v(n−1)o.(2.2)Moreover,theangleprocessesassociatedwith{u(n)}and{v(n)}areequivalent,i.e.,∠(u(n),u∗)=∠(v(n),v∗).Thereforeitwouldbesuﬃcienttostudytherescaledprocessgivenby(2.2).Inwhatfollows,wefocusouranalysisoniteration(2.2).WemakethefollowingassumptionsaboutthedistributionofXunderthenewcoordinates.Assumption2.LetΣ=UΛU>beadiagonaldecompositionofΣ,whereUisanorthogonalmatrixandΛhasλ1,...,λdalongitsdiagonal.Moreover,letY=U>XsatisfythatthereisaconstantM≥0suchthatforany1≤i<j≤d,cov(Y2i,Y2j)=0.(2.3)7NoteEq.(2.3)impliesthatfori6=j,var(YiYj)=cov(Y2i,Y2j)+EY2iEY2j−(EYiYj)2=λiλj.Thereforeonecansummarizetheexpectedfourth-ordermoments(frequentlyembeddedinafourth-ordertensor)ascov(YiYj,YkYl)=var(Y2i)=ψiii=k=j=l,var(YiYj)=λiλji=k6=j=l,cov(Y2i,Y2k)=0i=j6=k=l,0otherwise,(2.4)whereforeachi,j=1,...,d,ψiiisanonnegativescalar.Ourassumptionsandthelaterresultsapplytoareasonablybroadclassofdistribu-tions.WhenYi’sareindependentmean-zerorandomvariableswithPdi=1kYik2∞≤B2andcovariancematrixΛ,onecandirectlyverifythatAssumption2applies.2.2ConvergenceResultsandFiniteSampleAnalysisForeasinessofpresentation,weintroducearescalingoftheiterationnumber/samplenumbern.AssumethatbothBandλ1−λ2areknowninadvance.WedeﬁnetherescaledtimeN∗β,sasN∗β,s=(cid:24)slog(B−2(λ1−λ2)β−1)−log(1−β(λ1−λ2))(cid:25),(2.5)wheres>0isatuningparameter.HeretheﬁxedtimeN∗β,sincreasestoinﬁnityasthestepsizeβdecreasesto0.Inlateranalysis,wewillchoosetheconstantstepsizeβ=O(1/n)asthebudgetsamplesizenincreases.Forc∗>0wedeﬁneNoβ(c∗)=(cid:22)0.5log(2c∗d)−log(1−β(λ1−λ2))(cid:23).(2.6)Westateourﬁrstmainresultasfollows.Itprovidesafoundationtoourﬁnite-sampleconvergencerateanalysis.Theorem1(Convergenceresultwithdeterministicinitialization).LetAssumptions1and2hold,andthereexistssomeconstantc∗>1suchthattan2∠(u(0),u∗)≤c∗d.Furthermore,letthefollowingscalingconditionhold:forsomeε∈(0,1/3)d(cid:0)B2(λ1−λ2)−1β(cid:1)1−3ε≤1.(2.7)Thenthereexistsahigh-probabilityeventH∗withP(H∗)≥1−2dN∗β,2exp(cid:0)−C1(B2(λ1−λ2)−1β)−2ε(cid:1),(2.8)andexistsaconstantb1withb1∈(0,ln22/16),suchthat,forallβ≤(b1/c∗)1/ε(λ1−λ2)B−2(2.9)8theiteratesgeneratedbyAlgorithm1satisfythatforn∈[N∗β,1+Noβ(c∗),N∗β,2]E(cid:2)tan2∠(u(n),u∗);H∗(cid:3)≤2c∗d(1−β(λ1−λ2))2n+dXk=2[1+4(B2(λ1−λ2)−1β)ε]λ1λk+C2B2(B2(λ1−λ2)−1β)1−2ε2(λ1−λk)·β.(2.10)HereC1andC2arepositiveconstants.Theorem1givesaconvergencerateestimateoftheonlinePCAalgorithmwhentheinitialconditionisnearlyglobal.Itcharacterizesthetime/samplesizenneededfortheangleprocesstobecomesuﬃcientlysmall.TheproofofTheorem1isprovidedinSubsection4.1.Nextconsiderthecasewheretheinitialsolutionu(0)issampledfromtheunitsphereaccordingtoauniformdistribution.Inthiscase,wewouldexpectthatcos2∠(u(0),u∗)(cid:16)1/d,tan2∠(u(0),u∗)(cid:16)d−1,w.h.p.ThisimpliestheinitialconditionrequiredbyTheorem1isindeedsatisﬁed.Byfollowingthislineofanalysis,weobtainthesecondmainresultofthispaper.Theorem2(Convergenceresultwithuniformrandomizedinitialization).LetAssumptions1and2hold,letu(0)beuniformlysampledfromtheunitsphere.SupposethescalingconditionEq.(2.7)holdsforsomeε∈(0,1/3).Thenthereexistsapositiveconstantb2suchthat,givenanyδ>0thereexistsaneventA∗withP(A∗)≥1−2δandforallβ≤(b2/c∗)1/ε(λ1−λ2)B−2(2.11)theiteratesgeneratedbyAlgorithm1satisfyE(cid:2)tan2∠(u(n),u∗);A∗(cid:3)≤C3δ−2d(1−β(λ1−λ2))2n+d[1+4(B2(λ1−λ2)−1β)ε]λ1λ2+C4B2(B2(λ1−λ2)−1β)ε2(λ1−λ2)·β(2.12)forn∈[N∗β,1.5,N∗β,2].HereC3andC4arepositiveconstants.Nowletusconsiderthechoiceofstepsizeβ.Supposethattheeigengapλ1−λ2isknownandwearegivenabudgetoftotalNsampledatapoints.Assumethatthesamplesizeissuﬃcientlylargeinthesensethat(λ1−λ2)2N1.5logN>d.(2.13)Ourgoalistochooseanappropriatestepsizeβandminimizetheﬁnite-sampleerrorbound.Welet¯β(N)=1.5logN(λ1−λ2)N(2.14)9whichis(asymptotically)theminimizeroftherighthandofEq.(2.12),andlet¯ε(d,N)=13(cid:18)1−logdlog((λ1−λ2)2N)−log(1.5logN)(cid:19).(2.15)Note¯ε(d,N)∈(0,1/3)underEq.(2.13).Thenweobtainthemainﬁnite-sampleresultasfollows.Theorem3(Finite-sampleanalysiswithuniformrandomizedinitilization).LetAssump-tions1and2hold,letu(0)beuniformlysampledfromtheunitsphere,letEq.(2.13)hold,andletβ=¯β(N)begivenbyEq.(2.14).Thenthereexistsapositiveconstantb3suchthat,givenanyδ>0thereexistsaneventA∗withP(A∗)≥1−2δandforallNwith1.5logNN≤(b3δ2)1/¯ε(d,N)(λ1−λ2)2B−2(2.16)theiteratesgeneratedbyAlgorithm1satisfyE(cid:2)tan2∠(u(N),u∗);A∗(cid:3)≤C(d,N,δ)·λ1λ22(λ1−λ2)2·dlogNN,(2.17)wherethefactorC(d,N,δ)approachesto1asd,N→∞whenthescalingrelationEq.(2.13)holds.Theorem3givesanexplicitestimateoftheconvergenceratewhenaﬁxedsamplesizeisknowninadvance.Noteβ=¯β(N)doesnotinvolvethedimensiond,andtheconstantfactorinEq.(4.17)satisﬁesC(d,N,δ)≈1forsuﬃcientlylargedandN,aslongasε=¯ε(d,N)>0isboundedawayfrom0.Fromanasymptoticpointofview,thisimpliesthataslongasd→∞andN→∞withd/N1−ε→0forsomeε>0,wehaveC(d,N,δ)→1.Inorderwords,thefactorC(d,N,δ)behaveslikeaconstantunderreasonablescalingoftheproblemdimensions.NoteinEq.(1.5)thefactorC(d,N,δ)canbechosen(1−δ)−1timesthefactorheresincetheconditionalexpectationisequaltoexpectationovereventA∗dividedbyP(A∗).Theorem3suggeststhattheonlinePCAisnearlyoptimal,inthesensethatunderourdistributionalassumptions,theexpectedﬁnite-sampleerrormatchestheminimaxinforma-tionlowerboundO(pd/n)withhighprobability.Inotherwords,onlinePCAachievessimilaraccuracyasthatoftheclassicalPCAinthebatchsetting(uptoO(logN)).Moreimportantly,thenear-optimalconvergencerateisattainedundertheuniformlyrandomini-tialization.Tosumup,ourconvergencerateresultisbothnearlyoptimalandnearlyglobal.ProofsofTheorems2and3aredeferredtoSubsection4.2.2.3ComparisonswithExistingResultsWeprovideadetailedcomparisonbetweenourmainresult,Theorem3,andtherecentresultsontheconvergencerateofonlinePCAiteration.10(i)TheworkbyBalsubramanietal.(2013)analyzestwoversionsofincrementalPCAalgorithms.Theirresultsfocusondiminishingstepsizesβnforiteration(1.4)andissummarizedasfollows.Proposition1(Theorem1.1ofBalsubramanietal.(2013)).Letsometheoreticalassumptionshold,andletu(0)beuniformlysampledfromSd−1.Pickanyδ∈(0,1),andanyco>2.Setthestepsizesasβn=co/(2(λ1−λ2)n)whichisdiminishingovern.Withappropriatestartingtimeno≥C0c2o(λ1−λ2)−2B2d2δ−4log(1/δ)thereisaneventAowithP(Ao)≥1−δsuchthatforeachn≥n0E(cid:2)sin2∠(u(n),u∗)|Ao(cid:3)≤c2oeco/no8(co−2)·B2(λ1−λ2)2(n+1)+C1(cid:18)dδ2(cid:19)a(cid:18)no+1n+1(cid:19)co/2,whereC0,C1>0anda∈(1,4)areabsoluteconstants.ThisisoneoftheearliestconvergencerateresultsforonlinePCAiteration.However,theresultofProp.1doesnotalwaysmatchtheminimaxlowerbound(1.3).Thedependenceoftherateonthetopeigenvaluesλ1,λ2remaintobeclariﬁed.Notethattheeigenvaluesλ1,λ2areimportantquantitiesthatmeasuresthehardnessofprincipalcomponentanalysis.However,therateestimategivenbyProp.1doesnotfullycharacterizetheirrole.(ii)AmorerecentworkbyShamir(2015a)studiestheconvergencerateoftheonlinePCAiteration(1.4)fromtheoptimizationperspectively.Inparticular,itprovesaconvergencerateresultintermsoftheobjectivevaluesofproblem(1.1).Werewriteitsmainresultinoursettingasfollows.Proposition2(Corollary1ofShamir(2015a)).Letsometheoreticalassumptionshold,andu(0)beuniformlysampledfromSd−1.Setβ=(C1dn)−1/2.WithprobabilityatleastO(d−1)whendsuﬃcientlylargetheiteratesgeneratedbyAlgorithm1satisfy1−u(n)>Σu(n)kΣk≤C2·Bλ1·logn·√d√n,(2.18)whereC1andC2arepositiveconstant.Inaddition,byinitializethealgorithmusingtheﬁrstO(d)iterates,theyimprovethedependenceondimensionalitydtoadependenceonthenumericalrankofthecovariancematrix.Letustranslatetheresult(2.18)intotheangleconvergencerateasfollowssin2∠(u(n),u∗)≤kΣk−u(n)>Σu(n)λ1−λ2≤C·Bλ1−λ2·logn·√d√n,whereCissomeuniversalconstant.Theﬁrstinequalityistightwhenλ2=···=λd=0.ItisknownthatthesquaredangleerrorshouldconvergetozeroatarateofO(1/n),11assuggestedbythecentrallimittheoremandthePCAlowerboundVu&Lei(2013).Asaresult,therateestimateO(p1/n)1byShamir(2015a)isnottightwithrespecttothesamplesizen.Itmissestheminimaxconvergencerate(1.3)andourrateestimate(1.5)byafactorofO(p1/n).Incontrast,wehaveobtainedrateestimateontheorderofO(1/n),whichisnon-improvablewithrespecttothesamplesize.3MarkovChainCharacterizationandDiﬀerentialEquationAp-proximationInthissection,wecharacterizethestochasticprocess{u(n)}generatedbytheonlinePCAalgorithmasaMarkovchainandanalyzeitsproperties.Accordingtotheiterationweobservethattheiterates{u(n)}∞n=1isacontinuous-spacediscrete-timeMarkovchaintakingvaluesontheunitsphereSd−1.Tobemoreprecise,thereexistsatransitionkernelpsuchthatforanyBorelsetAinSd−1,P(cid:0)u(n+1)∈A(cid:12)(cid:12)u(n),u(n−1)...,u(0)(cid:1)=p(u(n),A).ThisallowsustoanalyzetheprocessusingtheweakconvergencetheoryofMarkovchains.Weshowthat,uponsuitablerescalingoftime,theMarkovchaingloballyconvergesweaklytothesolutionofanordinarydiﬀerentialequation.Wealsoshowthat,uponadiﬀerenttimerescaling,theMarkovchaincanbelocallyapproximatedbythesolutionofastochasticdiﬀerentialequation,aslongasu(n)iswithinaneighborhoodofu∗.3.1ProductofRandomMatricesasaMarkovChainTheonlinePCAiterationisequivalenttou(n)=Π(cid:8)(I+βX(n)(X(n))>)···(I+βX(1)(X(1))>)u(0)(cid:9),andhencetheprocess{u(n)}iscloselyrelatedtotheproductofi.i.d.randommatrices(I+βX(n)(X(n))>)···(I+βX(1)(X(1))>),whichformsacontinuous-spaceMarkovchainuponnormalization.Toanalyzethestochasticalgorithm,weturntothetheoryofproductsofrandommatrices,whichdatedbacktothe1960s;seeCohenetal.(1985);Bougerol&Lacroix(1985)foracomprehensivestudy.ByleveragingtheMarkovnatureofthealgorithmandthetheoryforproductofrandommatrices,weobtainthefollowingpropertiesof{u(n)}:(i)TheMarkovchain{u(n)}admitsauniqueinvariantdistributionνundersomemildcondition.Inparticular,theinvariantdistributionνisuniqueaslongasAssumptions1Hereandinthefollowingbig-O’sinthissectionwehidethelog-polynomialfactorsofnandpolynomialfactorsofdimensiond.121,2holdandthedensityofXisboundedfrombelowonanopenballinRd.Toanalyzetheinvariantdistribution,weusethestandardtechniqueforstochasticgradientdescent.WecanshowthatEu∼ν(cid:2)sin2∠(u,u∗)(cid:3)=O(cid:18)dλ1λ2βλ1−λ2(cid:19).(3.1)Thissuggeststhatthesineanglediﬀerenceisconcentratedaround0whentheMarkovchain{u(n)}reachesitsinvariantdistribution,aslongasthestepsizeβisreasonablysmall.Inparticular,theanglediﬀerenceisatscaleO(√β),whichsuggeststhatwewanttocontrolβtoobtaintheoptimalestimator.Notethattheeigengapquantitiesalsoshowupintheexpectederror(3.1).(ii)TheMarkovchain{u(n)}isgeometricallyergodic,undersomemildcondition.Inotherwords,theMarkovchain,startingfromanyinitialdistribution,convergesexponentiallyfasttoitsinvariantdistribution.ThisallowsustoestimatetheﬁniteexpectederrortobeE(cid:2)sin2∠(u(n),u∗)(cid:3)=O(cid:18)dλ1λ2βλ1−λ2+exp(−αn)(cid:19),whereαisapositiveexponent.(iii)TheexponentofgeometricconvergenceαisrelatedtotheLyapunovexponentsoftheMarkovchain.Whenβissuﬃcientlysmall,weconjecturetheexponentialconvergencerateαisasymptoticallylower-boundedbyβ(λ1−λ2).Moreprecisely,weconjecturethatthereexistsaconstantη>0suchthatasβ→0α≥β(λ1−λ2)+O(β1+η).(3.2)Inthecasewhend=2,theaboveconjecturecanbeshownwithη=1/2usingexistingtheoryforproductofrandommatricesCohenetal.(1985);Bougerol&Lacroix(1985).Thistogetherwiththeinvariantdistributionresultscanbeusedtogiveaheuristicconvergencerateestimate.Totheauthors’bestknowledge,existingtheoryonproductofrandommatricesseemsinadequatetoprovidefullcharacterizationofthestochasticprocess{u(n)}.Inparticular,ouranalysisrequiresanestimateofthesecondLyapunovcomponentoftheproductprocess.However,upperboundonthesecondexponentisonlyavailableforthecasewhered=2Cohenetal.(1985);Bougerol&Lacroix(1985).AcompletecharacterizationoftheonlinePCAalgorithmwouldinvokeadeepconnectionwiththeproductofrandommatricestheory.Weleavethisquestionforfutureresearch.3.2ODEApproximationInwhatfollowsweshowthatthestochasticiteratesgeneratedbytheonlinePCAiterationcanbeapproximatedbythesolutionofanODEsystem,aslongasβissmall.Letusdeﬁneanewprocess,whichisobtainedbyrescalingthetimeindexnaccordingtothestepsizeβeVβk(t)≡v(btβ−1c)k,k=1,...,d.(3.3)13Weaddthesuperscriptβinthenotationtoemphasizethedependenceoftheprocessonβ.WewillshowthateVβk(t)convergesweaklytoadeterministicfunctionVk(t),asβ→0.FurthermorewecanidentifythelimitVk(t)astheclosed-formsolutiontoanODEsystem.Usinganinﬁnitesimalgeneratoranalysisresults,wehave(cid:12)(cid:12)(cid:12)eVβk(t+β)−eVβk(t)(cid:12)(cid:12)(cid:12)=O(β).Itfollowsthat,asβ→0,theinﬁnitesimalconditionalvarianceisβ−1var(cid:20)eVβk(t+β)−eVβk(t)(cid:12)(cid:12)(cid:12)(cid:12)eVβk(t)=v(cid:21)=O(β),andtheinﬁnitesimalconditionalmeanisβ−1EheVβk(t+β)−eVβk(t)(cid:12)(cid:12)eVβk(t)=vi=vkdXd0=1(λk−λd0)v2d0+O(β2).Byusinganinﬁnitesimalgeneratorargument(Ethier&Kurtz,1985,Corollary4.2inSec.7.4),weobtainthefollowingresult.ProofisprovidedinSubsectionA.2.Theorem4.Foreachk=1,...,d,ifeVβk(0)convergesweaklytosomeconstantscalarVokasβ→0thenthestochasticprocesseVβk(t)convergesweaklytothesolutionofthefollowingordinarydiﬀerentialequationdVkdt=VkdXd0=1(λk−λd0)V2d0,k=1,...,d,(3.4)withinitialvaluesVk(0)=Vok.ThesolutiontoEq.(3.4)isVk(t)=(Z(t))−1/2Vk(0)exp(λkt),(3.5)whereZ(t)isthenormalizationfunctionZ(t)=dXd0=1(Vd0(0))2exp(2λd0t).LetustrytounderstandthelimitfunctiongivenbyEq.(3.5).Inthespecialcasewhereλ2=···=λd,wehaveZ(t)=(V1(0))2exp(2λ1t)+(cid:0)1−(V1(0))2(cid:1)exp(2λ2t),and(V1(t))2=(V1(0))2exp(2λ1t)(V1(0))2exp(2λ1t)+(cid:0)1−(V1(0))2(cid:1)exp(2λ2t).(3.6)14Thisistheformulaofthelogisticcurve.Howeverinthegeneralcase,thenormalizingconstantZ(t)ishardtocharacterizeandestimate.Togetabetterunderstanding,weconsiderachangeofvariables.DeﬁnetheratiotobeU(n)k=v(n)kv(n)1,(3.7)whichsatisﬁestan2∠(v(n),v∗)=dXk=2(cid:16)U(n)k(cid:17)2.(3.8)WeseethattheratioU(n)kisthetangentofanglebetweenv(n)andprincipaleigenvectorv∗=e1afterprojectedontothetwo-dimensionalsubspacespannedbye1andek,theﬁrstandkthcanonicalvectors.AccordingtoEq.(3.5),bytakingt=nβ,thetangentanglecanbeapproximatedasfollowsU(n)k≈Vk(t)V1(t)=(Z(t))−1/2Vk(0)exp(λkt)(Z(t))−1/2V1(0)exp(λ1t)=U(0)kexp(−β(λ1−λk)n).(3.9)Inotherwords,U(n)kisapproximatelyadeterministiccurvethatdecaysexponentiallyto0atrateofβ(λ1−λk).ThisprovidesustheinsightofODEapproximationwhichguidesourconvergenceanalysisofalgorithminSubsection4.1.3.3LocalSDEApproximationInthissubsectionweshowthatundersomescaling,theprocessadmitsastochasticdiﬀeren-tialequationapproximationwithinaneighborhoodofu∗.WereferthereaderstoOksendal(2003)formoreonbasicconceptsandrelatestopicsofSDE.UsingtheoryfromEthier&Kurtz(1985),wehaveforeachk=2,...,d,ifβ−0.5v(0)kconvergesweaklytoVok∈(0,∞)asβ→0thenthestochasticprocessβ−0.5v(btβ−1c)kconvergesweaklytothesolutionofthestochasticdiﬀerentialequationssystemdVk(t)=−(λ1−λk)Vkdt+pλ1λkdB(t)(3.10)withinitialvaluesVk(0)=Vok.HereB(t)isastandardBrownianmotion.SolutiontoEq.(3.10)isknownasOrnstein-Uhlenbeckprocesswhichcanbesolvedexplicitly.ThesolutiontoEq.(3.10)isVk(t)=Vokexp(−(λ1−λk)t)+pλ1λkZt0exp((λ1−λk)(s−t))dBk(s).15Fortheinvariantdistribution,rescalingthestochasticprocessalongwithsomecalculationsgivesEv∼νsin2∠(v,v∗)≈limt→∞βdXk=2E(Vk(t))2=dXk=2λ1λk2(λ1−λk)β.TheprecedingapproximationmatchestheerrorboundinTheorem1andinformationlowerboundEq.(3.1).4ProofsofMainResultsThissectionanalyzestheconvergenceofthestochasticiterationgeneratedbyAlgorithm1andprovidesdetailedproofsofthemainresultsinSection2.ArgumentsforconvergenceresultsareseparatelyprovidedinSubsections4.1and4.2,separatelyforthedeterministicinitializationcase(Theorem1)andfortheuniformrandomizedinitializationcase(Theorem2).Subsection4.2alsoprovidestheargumentfortheﬁnite-sampleresultwithuniformrandomizedinitialization(Theorem3).ProofsofallpropositionsinthissectionareprovidedinAppendixB.4.1ProofofTheorem1Thissubsectionaimstoprovetheconvergenceresultforthedeterministicinitializationcase,Theorem1.ConsiderapartitionSd−1=S1]S2whereS1=nv∈Sd−1:|v1|<1/√2o,S2=nv∈Sd−1:|v1|≥1/√2o.(4.1)WerefertoS1andS2asthecoldregionandthewarmregion,respectively.WeﬁrstfocusonAlgorithm1whentheinitialestimatorliesinthewarmregionS2,whichweconvenientlycallwarmstart.SuchanalysisiscrucialinobtainingthecorrectrateofconvergenceintheproofofTheorem1.Intermsoftheangle∠(v(0),v∗)thiswarmstartconditionisequivalentto∠(v(0),v∗)∈[0,π/4]∪[3π/4,π].Toavoiduncontrollablevariancesweneeditsﬁrstcoordinatev(0)1tobeboundedawayfrom0throughoutthealgorithmforNt∗iterates.WeﬁrstlydeﬁneanauxiliaryregionS3=(cid:8)v∈Sd−1:|v1|∈[1/3,1](cid:9),(4.2)andsetthestoppingtimeNw=inf{n≥0:v(n)∈Sc3}.(4.3)Itisconvenienttodeﬁnebβ=B2(λ1−λ2)−1β.(4.4)WeconsidertheiterationsU(n)kwhereU(n)k=v(n)k/v(n)1istheratiowefocusoninthissubsection.Ourﬁrstgoalinthissubsectionistoprovethefollowing16Proposition3.AssumeallconditionsinTheorem1alongwiththewarmstartconditionv(0)∈S2.Thentherearepositiveconstantsb4andC3,Psuchthatwheneverbβε≤b4,(4.5)withprobability≥1−2N∗texp(cid:16)−C3,Pbβ−2ε(cid:17)onehasfork=2,...,dthatsupn≤N∗t∧Nw(cid:12)(cid:12)U(n)k−U(0)k(1−β(λ1−λk))n(cid:12)(cid:12)≤bβ0.5−ε.ProofofProposition3isdeferredtoSubsectionB.1.Proposition3showsthatfromwarmstart,foreachcoordinatek=2,...,d,theU(n)kapproximatelydecaysgeometricallyatrate1−β(λ1−λk).Usingthiswecanobtaintherateofconvergenceundermorecarefulvarianceestimates,asfollows.Proposition4.AssumeallconditionsinTheorem1alongwiththewarmstartconditionv(0)∈S2.Thenthereisapositiveconstantb4suchthatwheneverEq.(4.5)issatisﬁed,thereexistsahigh-probabilityeventH0satisfyingP(Hc0)≤2(d−1)N∗β,2exp(cid:16)−C4,Pbβ−2ε(cid:17),(4.6)suchthatforﬁxedk=2,...,dandn∈[N∗β,1,N∗β,2],E(cid:20)(cid:16)U(n)k(cid:17)2;H0(cid:21)≤(1−β(λ1−λk))2n(cid:16)U(0)k(cid:17)2+(1+4bβε)λ1λk+C04,PB2bβ1−2ε2(λ1−λk)β.(4.7)HereC4,PandC04,Parepositiveconstants.ProofofProposition4isdeferredtoSubsectionB.2.NotefromEq.(4.6)H0occurswithhighprobabilityasβ→0.WithbβdeﬁnedinEq.(4.4)thesecondtermontherighthandofEq.(4.7)matchesthesecondmomentestimatesasinEq.(2.10).Second,wetrytorelaxthewarmstartcondition.DeﬁnethestoppingtimeNc=inf{n≥0:v(n)∈S2}.(4.8)Inwords,Ncistheﬁrstnsuchthattheiterateentersthewarmregion.Inthecaseofwarmstart,Nc=0.Wehavethefollowingboundforthestoppingtime,whoseproofisprovidedinSubsectionB.3.Proposition5.AssumeallconditionsinTheorem1.Thereexistapositiveconstantb5withb5<ln22/16suchthatifbβε≤b5/c∗,(4.9)thenwehaveP(cid:0)Nc∈[0,Noβ(c∗)](cid:1)≥1−2Noβ(c∗)exp(cid:16)−C5,Pbβ−2ε(cid:17),(4.10)whereNoβ(c∗)isdeﬁnedasinEq.(2.6).17WearenowreadyproveTheorem1.NotethatunderthesettingofTheorem1,Algorithm1startsfromv(0)∈Sd−1wheretan2∠(v(0),v∗)≤c∗d.RunningthealgorithmforNc∧Noβ(c∗)iteratesweknowfromProposition5thattheiteratev(cid:0)Nc∧Noβ(c∗)(cid:1)liesinS2withhighprobability.BystrongMarkovproperty,theiteratesgeneratedbyAlgorithm1havethesamelawastheonestartingfromv(cid:0)Nc∧Noβ(c∗)(cid:1),andhenceProposition4canbeapplied.Wefollowthisreasoninganddetailtheproofasinbelow.ProofofTheorem1.Proposition5impliesthatforallβsatisfyingEq.(4.9)P(cid:0)Nc∈[0,Noβ(c∗)](cid:1)≥1−2Noβ(c∗)exp(cid:16)−C5,Pbβ−2ε(cid:17).(4.11)LetH∗,1=(cid:0)Nc∈[0,Noβ(c∗)](cid:1)=(cid:0)Nc=Nc∧Noβ(c∗)(cid:1),H∗,2=supn∈[N∗β,1,N∗β,2](cid:12)(cid:12)(cid:12)U(n+Nc)k(cid:12)(cid:12)(cid:12)≤2bβ0.5−εforallk=2,...,d,H∗=H∗,1∩H∗,2.(4.12)OnH∗∩(Nc=no)whereno∈[0,Noβ(c∗)]isaninteger,fromthedeﬁnitioninEq.(4.8)wehavev(cid:0)Nc∧Noβ(c∗)(cid:1)=v(no)∈S2andhencetan2∠(v(no),v∗)=dXk=2(cid:16)U(no)k(cid:17)2≤1.(4.13)DeﬁnitionofNoβ(c∗)inEq.(2.6)implies(1−β(λ1−λ2))−2no≤(1−β(λ1−λ2))−2Noβ(c∗)≤2c∗d.Thereforeforn∈[N∗β,1+Noβ(c∗),N∗β,2]⊆[N∗β,1+no,N∗β,2+no],andβsatisfyingbothEqs.(4.5)and(4.9),weutilizetheMarkovpropertyandProposition4andconcludethatforβsatisfyingEq.(2.9)whereb1=b4∧b5∈(0,ln22/16)E(cid:2)tan2∠(v(n),v∗)1H∗|Nc=no(cid:3)=dXk=2E(cid:20)(cid:16)U(n)k(cid:17)21H∗(cid:12)(cid:12)(cid:12)(cid:12)Nc=no(cid:21)≤dXk=2(1−β(λ1−λk))2(n−no)(cid:16)U(no)k(cid:17)2+dXk=2(1+4bβε)λ1λk+C04,PB2bβ1−2ε2(λ1−λk)β≤(1−β(λ1−λ2))−2no(1−β(λ1−λ2))2n+dXk=2(1+4bβε)λ1λk+C04,PB2bβ1−2ε2(λ1−λk)β≤2c∗d(1−β(λ1−λ2))2n+dXk=2(1+4bβε)λ1λk+C04,PB2bβ1−2ε2(λ1−λk)β.18Eqs.(3.8),(4.13)havebeenappliedintheaboveestimate.TheboundforE(cid:2)tan2∠(v(n),v∗)1H∗|Nc(cid:3)wasarguedforNc=no∈[0,Noβ(c∗)]butistriviallyvalidon(Nc>Noβ(c∗)),since1H∗=0onthatevent.Furthermore,theboundontherighthandisdeterministicandhenceindependentofNc.TakingexpectationagaingivesE(cid:2)tan2∠(v(n),v∗);H∗(cid:3)≤2c∗d(1−β(λ1−λ2))2n+dXk=2(1+4bβε)λ1λk+C04,PB2bβ1−2ε2(λ1−λk)β.ThereforeEq.(2.10)establisheswithC2=C04,P.ToensurethattheeventH∗deﬁnedinEq.(4.12)satisﬁestheprobabilityestimateinEq.(2.8),noteﬁrstfromEq.(4.9)inProposition5andthescalingconditionEq.(2.7)inTheorem1,onehasbβε≤(2c∗)−1andhence0.5log(2c∗d)≤(0.5−ε)log(bβ−1)CombinedwiththedeﬁnitionsinEqs.(2.5)and(2.6),thisimplies0≤Noβ(c∗)≤N∗β,0.5−ε≤N∗β,2.(4.14)Eqs.(4.6),(4.14)and(4.11)togetherimplyP(H∗)≥h1−2Noβ(c∗)exp(cid:16)−C5,Pbβ−2ε(cid:17)ih1−2(d−1)N∗β,2exp(cid:16)−C3,Pbβ−2ε(cid:17)i≥1−2N∗β,2exp(cid:16)−C5,Pbβ−2ε(cid:17)−2(d−1)N∗β,2exp(cid:16)−C3,Pbβ−2ε(cid:17),LettingC1=C5,P∧C3,PthisimpliesthatEq.(2.8)holds.ProofofTheorem1isaccom-plished.(cid:4)4.2ProofsofTheorem2and3Nextweprovethemainresultsoftheuniformrandomizedinitializationcase,Theorems2and3.ThefollowinglemmabasicallysaysthattheinitialestimatorconditioninTheorem1issatisﬁedwithhighprobability,wherethecoeﬃcientc∗=C∗δ−2blowsupastheerrorprobabilityδtendsto0.Lemma1.Givenanyδ>0,ifu(0)issampleduniformlyatrandomfromSd−1inRdthenthereexistsaconstantC∗>0independentofδanddsuchthatP(cid:0)tan2∠(u(0),u∗)≤C∗δ−2d(cid:1)≥1−δ.ProofofLemma1isprovidedinAppendixC.1.WearereadytoproveTheorem2.19ProofofTheorem2.LetA0∗=(cid:0)tan2∠(u(0),u∗)≤C∗δ−2d(cid:1).andrecallbβisasdeﬁnedinEq.(4.4).Lemma1indicatesP(A0∗)≥1−δsincetheinitialestimatoru(0)issampleduniformlyatrandomfromSd−1.WhenconditioningonA0∗,MarkovpropertyimpliesthatTheorem1applieswithc∗=C∗δ−2,andhencethereexistsahigh-probabilityeventH∗withP(Hc∗|A0∗)≤2dN∗β,2exp(cid:16)−C1bβ−2ε(cid:17)(4.15)suchthatforallβsatisfyingbβε≤(b1(C∗)−1δ2)∧b1,E(cid:2)tan2∠(u(n),u∗);A∗(cid:3)≤E(cid:2)tan2∠(u(n),u∗)1H∗|A0∗(cid:3)≤2C∗δ−2d(1−β(λ1−λ2))2n+dXk=2(1+4bβε)λ1λk+C2B2bβ1−2ε2(λ1−λk)·β≤2C∗δ−2d(1−β(λ1−λ2))2n+d(1+4bβε)λ1λ2+C2B2bβε2(λ1−λ2)·β,whereinthelaststepweusedλk≤λ2anddbβ1−2ε≤bβε.NotetherighthandofEq.(4.15)is≤2bβ3ε−1·2(λ1−λ2)−1β−1log(cid:16)bβ−1(cid:17)·exp(cid:16)−C1bβ−2ε(cid:17)≤4B2(λ1−λ2)−2·bβ3ε−2log(cid:16)bβ−1(cid:17)·exp(cid:16)−C1bβ−2ε(cid:17)whichisexponentiallysmallasbβ→0.Thisenablestheexistenceofpositivefactorb2≤b1(δ2/C∗∧1)suchthatP(Hc∗|A0∗)≤δforallbβ<b2.HenceP(A0∗∩H∗)=P(A0∗)P(H∗|A0∗)≥(1−δ)2≥1−2δ.SettingC3=2C∗andC4=C2concludesTheorem2.(cid:4)Weﬁnalizethispaperbyprovingtheﬁnite-sampleresult,Theorem3.ProofofTheorem3.AsEq.(2.16)holds,bychoosingβasinEq.(2.14)andεasinEq.(2.15)wehaveEq.(2.11)holds.Therefored(cid:0)¯β(N)(cid:1)1−3ε=d(cid:18)1.5logN(λ1−λ2)N(cid:19)1−3ε=d(cid:18)1d(cid:19)=1.20ThereforethescalingconditionEq.(2.7)issatisﬁedandTheorem2applies.Itisnothardtoverifywhenβ=¯β(N)deﬁnedinEq.(2.14)onehasN∈[N∗β,1.5,N∗β,2],whereweusedEq.(4.14).ThereforebyplugginginβasinEq.(2.14),weimmediatelyobtainthatE(cid:2)tan2∠(u(N),u∗);A∗(cid:3)≤C3δ−2·dN3+d(cid:16)1+4(cid:2)B2(λ1−λ2)−1¯β(N)(cid:3)¯ε(d,N)(cid:17)λ1λ2+C4B2(cid:2)B2(λ1−λ2)−1¯β(N)(cid:3)¯ε(d,N)2(λ1−λ2)2·logNN.(4.16)SettingC5=C3andC6=C4,itisstraightforwardtosimplifyEq.(4.16)toEq.(2.17),wherethefactorC(d,N,δ)takestheformC(d,N,δ)=1+4[B2(λ1−λ2)−1¯β(N)]¯ε(d,N)+2(λ1−λ2)2λ1λ2·C5δ−2N2logN+C6B[B2(λ1−λ2)−1¯β(N)]¯ε(d,N)dλ1λ2.(4.17)AlsoitisstraightforwardtoverifythatC(d,N,δ)→1asd,N→∞,whichprovesthetheorem.(cid:4)ReferencesAgarwal,A.,Bartlett,P.,Ravikumar,P.,&Wainwright,M.(2012).Information-theoreticlowerboundsontheoraclecomplexityofstochasticconvexoptimization.IEEETransac-tionsonInformationTheory,58(5),3235–3249.Amini,A.&Wainwright,M.(2009).High-dimensionalanalysisofsemideﬁniterelaxationsforsparseprincipalcomponents.TheAnnalsofStatistics,37(5B),2877–2921.Arora,R.,Cotter,A.,Livescu,K.,&Srebro,N.(2012).StochasticoptimizationforPCAandPLS.In50thAnnualAllertonConferenceonCommunication,Control,andComputing(pp.861–868).Arora,R.,Cotter,A.,&Srebro,N.(2013).StochasticoptimizationofPCAwithcappedmsg.InAdvancesinNeuralInformationProcessingSystems(pp.1815–1823).Ball,K.(1997).Anelementaryintroductiontomodernconvexgeometry.Flavorsofgeom-etry,31,1–58.Balsubramani,A.,Dasgupta,S.,&Freund,Y.(2013).ThefastconvergenceofincrementalPCA.InAdvancesinNeuralInformationProcessingSystems(pp.3174–3182).21Benveniste,A.,M´etivier,M.,&Priouret,P.(2012).AdaptiveAlgorithmsandStochasticApproximations.Springer.Bertsekas,D.(2011).Incrementalproximalmethodsforlargescaleconvexoptimization.MathematicalProgramming,Ser.B,129,163–195.Bertsekas,D.&Tsitsiklis,J.(1989).ParallelandDistributedComputation:NumericalMethods.Belmont,M.A.:AthenaScientiﬁc.Borkar,V.(2008).StochasticApproximation:ADynamicalSystemsViewpoint.M.A.:CambridgeUniversityPress.Bougerol,P.&Lacroix,J.(1985).ProductsofrandommatriceswithapplicationstoSchr¨odingeroperators,volume8.SpringerScience&BusinessMedia.Cai,T.T.,Ma,Z.,&Wu,Y.(2013).SparsePCA:Optimalratesandadaptiveestimation.TheAnnalsofStatistics,41(6),3074–3110.Chung,F.&Lu,L.(2006).Concentrationinequalitiesandmartingaleinequalities:asurvey.InternetMathematics,3(1),79–127.Cohen,J.E.,Kesten,H.,&Newman,C.M.(1985).RandomMatricesandTheirApplica-tions:ProceedingsoftheAMS-IMS-SIAM,volume50.AmericanMathematicalSoc.d’Aspremont,A.,Bach,F.,&ElGhaoui,L.(2008).Optimalsolutionsforsparseprincipalcomponentanalysis.JournalofMachineLearningResearch,9,1269–1294.Durrett,R.(2010).Probability:theoryandexamples(4thed.).Cambridgeuniversitypress.Ethier,S.N.&Kurtz,T.G.(1985).Markovprocesses:characterizationandconvergence(2nded.),volume282.JohnWiley&Sons.Garber,D.&Hazan,E.(2015).FastandsimplePCAviaconvexoptimization.arXivpreprintarXiv:1509.05647.Ge,J.,Wang,Z.,Wang,M.,&Liu,H.(2015).Minimax-optimalprivacy-preservingsparsepcaindistributedsystems.Submitted.Hardt,M.&Price,E.(2014).Thenoisypowermethod:Ametaalgorithmwithapplications.InAdvancesinNeuralInformationProcessingSystems(pp.2861–2869).Hotelling,H.(1933).Analysisofacomplexofstatisticalvariablesintoprincipalcomponents.Journalofeducationalpsychology,24(6),417.Johnstone,I.M.&Lu,A.Y.(2009).OnConsistencyandSparsityforPrincipalComponentsAnalysisinHighDimensions.JournaloftheAmericanStatisticalAssociation,104(486),682–693.22Kuczynski,J.&Wozniakowski,H.(1992).Estimatingthelargesteigenvaluebythepowerandlanczosalgorithmswitharandomstart.SIAMjournalonmatrixanalysisandapplications,13(4),1094–1122.Kushner,H.&Yin,G.(2003).StochasticApproximationandRecursiveAlgorithmsandApplications.N.Y.:Springer.Ma,Z.(2013).Sparseprincipalcomponentanalysisanditerativethresholding.TheAnnalsofStatistics,41(2),772–801.Mitliagkas,I.,Caramanis,C.,&Jain,P.(2013).Memorylimited,streamingPCA.InAdvancesinNeuralInformationProcessingSystems(pp.2886–2894).Muirhead,R.J.(2005).Aspectsofmultivariatestatisticaltheory,volume197.JohnWiley&Sons.Musco,C.&Musco,C.(2015).Strongerapproximatesingularvaluedecompositionviatheblocklanczosandpowermethods.arXivpreprintarXiv:1504.05477.Nadler,B.(2008).Finitesampleapproximationresultsforprincipalcomponentanalysis:Amatrixperturbationapproach.TheAnnalsofStatistics,41(2),2791–2817.Nedi´c,A.(2011).Randomalgorithmsforconvexminimizationproblems.MathematicalProgramming,Ser.B,129,225–253.Nedi´c,A.&Bertsekas,D.(2001).Incrementalsubgradientmethodsfornondiﬀerentiableoptimization.SIAMJournalonOptimization,12,109–138.Nedi´c,A.,Bertsekas,D.,&Borkar,V.(2001).Distributedasynchronousincrementalsub-gradientmethods.StudiesinComputationalMathematics,8,381–407.Nemirovsky,A.&Yudin,D.(1983).ProblemComplexityandMethodEﬃciencyinOpti-mization.Wiley.Oja,E.(1983).Subspacemethodsofpatternrecognition,volume6.ResearchStudiesPress.Oja,E.&Karhunen,J.(1985).Onstochasticapproximationoftheeigenvectorsandeigen-valuesoftheexpectationofarandommatrix.Journalofmathematicalanalysisandapplications,106(1),69–84.Oksendal,B.(2003).Stochasticdiﬀerentialequations.Springer.Pearson,K.(1901).Liii.onlinesandplanesofclosestﬁttosystemsofpointsinspace.TheLondon,Edinburgh,andDublinPhilosophicalMagazineandJournalofScience,2(11),559–572.23Rakhlin,A.,Shamir,O.,&Sridharan,K.(2012).Makinggradientdescentoptimalforstronglyconvexstochasticoptimization.InProceedingsofthe29thInternationalConfer-enceonMachineLearning(pp.449–456).Sa,C.D.,Re,C.,&Olukotun,K.(2015).Globalconvergenceofstochasticgradientdescentforsomenon-convexmatrixproblems.InProceedingsofthe32ndInternationalConferenceonMachineLearning(ICML-15)(pp.2332–2341).Shamir,O.(2015a).ConvergenceofstochasticgradientdescentforPCA.arXivpreprintarXiv:1509.09002.Shamir,O.(2015b).FaststochasticalgorithmsforsvdandPCA:Convergencepropertiesandconvexity.arXivpreprintarXiv:1507.08788.Shamir,O.(2015c).AstochasticPCAandsvdalgorithmwithanexponentialconvergencerate.InProceedingsofthe32ndInternationalConferenceonMachineLearning(ICML-15)(pp.144–152).Shamir,O.&Zhang,T.(2013).Stochasticgradientdescentfornon-smoothoptimization:Convergenceresultsandoptimalaveragingschemes.InProceedingsofThe30thInterna-tionalConferenceonMachineLearning(pp.71–79).Vu,V.Q.&Lei,J.(2012).MinimaxRatesofEstimationforSparsePCAinHighDimensions.AISTATS,(pp.1278–1286).Vu,V.Q.&Lei,J.(2013).Minimaxsparseprincipalsubspaceestimationinhighdimensions.TheAnnalsofStatistics,41(6),2905–2947.Wang,M.&Bertsekas,D.(2014a).Incrementalconstraintprojectionmethodsforvariationalinequalities.MathematicalProgramming,Ser.A,(pp.1–43).Wang,M.&Bertsekas,D.(2014b).Incrementalconstraintprojection-proximalmethodsfornonsmoothconvexoptimization.SIAMJournalonOptimization,toappear.Wang,M.,Fang,E.X.,&Liu,H.(2014a).Stochasticcompositionalgradientdescent:Algorithmsforminimizingcompositionsofexpected-valuefunctions.arXivpreprintarXiv:1411.3803.Wang,Z.,Lu,H.,&Liu,H.(2014b).Nonconvexstatisticaloptimization:Minimax-optimalsparsePCAinpolynomialtime.arXivpreprintarXiv:1408.5352.Yuan,X.-T.&Zhang,T.(2013).Truncatedpowermethodforsparseeigenvalueproblems.TheJournalofMachineLearningResearch,14(1),899–925.Zou,H.(2006).Theadaptivelassoanditsoracleproperties.JournaloftheAmericanstatisticalassociation,101(476),1418–1429.24AAnalysisofAlgorithmIncrementsThroughouttheAppendixofthispaperweusethefollowingnotations:(i)TheC’swithsubscriptsdenotessomepositiveconstants;(ii)TheC,C0,C00’swithoutsubscriptsarepositiveconstantswhosevaluesmaychangebetweenlines;(iii)Wedenoteforshortthatv≡v(n)andY≡Y(n+1);(iv)Forgenericfunctionf(v)denote∆f(v)=f(v(n+1))−f(v(n));ToanalyzethealgorithmfromtheviewofaMarkovchain,weneedtounderstandtheincrementsoneachcoordinateateachstep.Proposition6.UnderAssumptions1and2,foreachk=1,2,...,dandn≥0wehaveforallβ≤(3B)−1thefollowing:(i)ThereexistsarandomvariableQkwith|Qk|≤C6,1B2β2almostsurely,suchthattheincrementv(n+1)k−v(n)kcanberepresentedasv(n+1)k−v(n)k=β(cid:0)(v>Y)Yk−vk(v>Y)2(cid:1)+Qk;(A.1)(ii)Theincrementhasthefollowingbound(cid:12)(cid:12)(cid:12)v(n+1)k−v(n)k(cid:12)(cid:12)(cid:12)≤C6,2Bβ;(A.2)(iii)ThereexistsadeterministicfunctionE1,k(v)withsupv∈Sd−1|E1,k(v)|≤C6,1B2β2,suchthatEhv(n+1)k−v(n)k(cid:12)(cid:12)v(n)=vi=βvk(cid:0)λk−v>Λv(cid:1)+E1,k(v).(A.3)A.1ProofofProposition6ThissubsectionisdevotedtotheproofofProposition6.WeﬁrstcometoshowLemma2.Foreachn≥0(cid:12)(cid:12)(cid:12)(cid:12)kv+β(v>Y)Yk−1−1+β(v>Y)2+12β2(v>Y)2kYk2(cid:12)(cid:12)(cid:12)(cid:12)≤C2β2(v>Y)4.25Proof.Sincekv+β(v>Y)Yk−1=(cid:0)1+2β(v>Y)2+β2(v>Y)2kYk2(cid:1)−1/2,(A.4)Taylorexpansionsuggestsfor|x|<1(1+x)−1/2=∞Xn=0(cid:18)−12n(cid:19)xn=1−12x+38x2−516x3+···whichisanalternatingseriesforx∈[0,1),whereastheabsolutetermsapproachto0monotonically(cid:12)(cid:12)(cid:12)(cid:12)(cid:18)−12n+1(cid:19)xn+1(cid:12)(cid:12)(cid:12)(cid:12)≤(cid:12)(cid:12)(cid:12)(cid:12)(cid:18)−12n(cid:19)xn(cid:12)(cid:12)(cid:12)(cid:12).Hencetheerrorboundgives(cid:12)(cid:12)(cid:12)(cid:12)(1+x)−1/2−1+12x(cid:12)(cid:12)(cid:12)(cid:12)≤38x2,x∈[0,1).(A.5)Noting|v>Y|≤kYkwehaveforallβ2β(v>Y)2+β2(v>Y)2kYk2≤2Bβ+B2β2.Theabovedisplayisstrictlylessthan1whenβ≤(3B)−1,andhenceEq.(A.5)applies.CombinedwithEq.(A.4)wehave(cid:12)(cid:12)(cid:12)(cid:12)kv+β(v>Y)Yk−1−1+12(cid:0)2β(v>Y)2+β2(v>Y)2kYk2(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)≤38(cid:0)3β(v>Y)2(cid:1)2.Noticing|v>Y|≤kYk,triangleinequalitysuggests(cid:12)(cid:12)kv+β(v>Y)Yk−1−1+β(v>Y)2(cid:12)(cid:12)≤Cβ2kYk4≤CB2β2,completingtheproof.(cid:4)ProofofProposition6.SettingQ=kv+β(v>Y)Yk−1−1+β(v>Y)2.Then∆vk=kv+β(v>Y)Yk−1(cid:0)vk+βv>YYk(cid:1)−vk=(cid:0)1−β(v>Y)2+Q(cid:1)(cid:0)vk+βv>YYk(cid:1)−vk=β(cid:0)(v>Y)Yk−vk(v>Y)2(cid:1)+Qk,whereQk=(cid:0)vk+βv>YYk(cid:1)Q−β2(v>Y)3Yk.(A.6)Notethetermβ(cid:2)(v>Y)Yk−vk(v>Y)2(cid:3)26isabsolutelyboundedby2Bβ,andtakingexpectationgivesE(cid:2)(v>Y)Yk−vk(v>Y)2(cid:3)=vkλk−vkE(v>Y)2=vkλk−vkv>E(YY>)v>=vk(cid:0)λk−v>Λv(cid:1).Tothisstage,wehaveveriﬁed∆vk=β(cid:0)(v>Y)Yk−vk(v>Y)2(cid:1)+Qk.(A.7)Eq.(A.1)aslongasEqs.(A.2)and(A.3)inProposition6canbeconcludedif|Qk|≤CB2β2,(A.8)sincethisimpliesforE1,k(v)=EQkwehave|E1,k(v)|≤E|Qk|≤CB2β2.ToconcludeEq.(A.8),notethatβ≤(3B)−1andhence(cid:12)(cid:12)vk+βv>YYk(cid:12)(cid:12)≤1+βB≤43.Lemma2implies|Q|≤C2β2(v>Y)4≤C2B2β2.ThereforetheﬁrsttermonRHSofEq.(A.6)isabsolutelyboundedby2C2B2β2.ForthesecondterminEq.(A.6)wehave|β2(v>Y)3Yk|≤B2β2.WetherebyveriﬁedEq.(A.8)bytakingC=2C2+1,whichcompletesalltheproofofProposition6.(cid:4)A.2ProofofTheorem4Proposition6impliesforeVβk(t)deﬁnedinEq.(3.3),theincrementalquantityregardingtocoordinatekatt=nβiseVβk(t+β)−eVβk(t)=β(cid:0)(v>Y)Yk−vk(v>Y)2(cid:1)+Qk,where|Qk|≤CB2β2.UsingEq.(A.2)wehavetheinﬁnitesimalvarianceβ−1E(cid:20)(cid:16)eVβk(t+β)−eVβk(t)(cid:17)2(cid:12)(cid:12)(cid:12)(cid:12)eVβk(t)=v(cid:21)≤β−1·C26,2B2β2→0.Eq.(A.3)impliesthattheinﬁnitesimalmeanisβ−1EheVβk(t+β)−eVβk(t)(cid:12)(cid:12)eVβk(t)=vi=vk(cid:0)λk−v>Λv(cid:1)+O(β),27LetVk(t)bethesolutiontoODEsystemEq.(3.4)withinitialvaluesVk(0)=v(0)k.Applyingstandardinﬁnitesimalgeneratorargument(Ethier&Kurtz,1985,Corollary4.2inSec.7.4)onecanconcludethatasβ→0,theMarkovprocesseVβk(t)convergesweaklytoVk(t).Mathematically,weakconvergencecanbecharacterizedbythefollowingﬁnite-dimensionalconvergence:foreachcoordinatek=1,...,dandany0≤t1<t2<···<tnthefollowingconvergenceindistributionoccursasβ→0:(cid:16)eVβk(t1),eVβk(t2),...,eVβk(tn)(cid:17)d−→(Vk(t1),Vk(t2),...,Vk(tn)).Moreover,characterizationofweakconvergence(Ethier&Kurtz,1985)convergenceinprob-abilityimpliesweakconvergenceand,inthecasewherethelimitisnonrandom,viceversa.ThereforeeVβk(t)p−→Vk(t)holds.VerifyingthatEq.(3.5)isthesolutionto(3.4)isstraight-forward,andweconcludeTheorem4.(cid:4)BProofofPropositionsinSection4B.1ProofofProposition3TostatethenextresultweletFn=σ(vk:k≤n)betheσ-ﬁeldﬁltrationofourprocess,i.e.theinformationknownbytimen.IncrementalanalysisonU(n)kgivesLemma3.AssumeallconditionsinTheorem1alongwiththewarmstartconditionv(0)∈S2.Foreachk=2,...,dandanyn≥0,on(cid:0)v(n)∈S3(cid:1)(cid:12)(cid:12)(cid:12)U(n+1)k−U(n)k(cid:12)(cid:12)(cid:12)≤C3,1Bβ(B.1)Inadditionon(cid:0)v(n)∈S3(cid:1)EhU(n+1)k−U(n)k|Fni=−β(λ1−λk)U(n)k+E3,k(v(n)),(B.2)wherethedeterministicfunction|E3,k(v)|≤C3,2B2β2holdsforv∈S3.Proof.TostartderivingEq.(B.1),noteforcoordinated0∈[1,d]accordingtoEq.(A.1)∆vd0=β(cid:2)(v>Y)Yd0−vd0(v>Y)2(cid:3)+Qd0,where|Qd0|≤C6,2B2β2.Therefore∆(vk/v1)=v−11(∆vk−(vk/v1)∆v1)·v1v1+∆v1,wherev−11(∆vk−(vk/v1)∆v1)=v−11(cid:2)β(v>Y)Yk+Qk−(vk/v1)(cid:0)β(v>Y)Y1+Q1(cid:1)(cid:3)=βv−11(cid:2)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:3)+v−11Qk−v−21vkQ1.(B.3)28Notev∈S3alongwiththeboundednessofQimplies|v−11Qk−v−21vkQ1|≤CB2β2.UsingEq.(A.2)inProposition6,Eq.(B.3)isboundedby≤βv−11(cid:12)(cid:12)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:12)(cid:12)+CB2β2≤3β(cid:2)(cid:12)(cid:12)v>Y(cid:12)(cid:12)|Yk|+|vk/v1|(cid:12)(cid:12)v>Y(cid:12)(cid:12)|Y1|(cid:3)+CB2β2≤C0Bβ.|∆(vk/v1)|isthusboundedbyaslightlylargerCBβ,andEq.(B.1)isveriﬁed.WithEq.(A.3)athandwetakeexpectationonbothsidesofEq.(B.3)toobtainE[∆(vk/v1)]=βv−11E(cid:2)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:3)+E(cid:2)v−11Qk−v−21vkQ1(cid:3)=βv−11[vkλk−(vk/v1)v1λ1]+E3,k(v)=−β(λ1−λk)(vk/v1)+E3,k(v),whereE3,k(v)=E(cid:2)v−11Qk−v−21vkQ1(cid:3)∈[−CB2β2,CB2β2],concludingEq.(B.2).(cid:4)Deﬁnethenoisetermsgeneratedfromeachincrementasek,n+1=U(n+1)k−E[U(n+1)k|Fn],(B.4)Eq.(B.1)inLemma3imply|ek,n+1|=(cid:12)(cid:12)(cid:12)U(n+1)k−U(n)k−E[U(n+1)k−U(n)k|Fn](cid:12)(cid:12)(cid:12)≤|U(n+1)k−U(n)k|+E[|U(n+1)k−U(n)k||Fn]≤2C3,1Bβ,(B.5)andEq.(B.2)givesfor|E3(v(n))|≤C3,2β2U(n+1)k=ek,n+1+E[U(n+1)k−U(n)k|Fn]+U(n)k=ek,n+1+(1−β(λ1−λk))U(n)k+E3(v(n)).(B.6)Forfurtheranalysis,weintroducetwo-sidedAzuma’sinequalityasfollowsLemma4.LetMnbeamartingalewithregardstoﬁltrationFnwherethemartingaledif-ferencesξk=Mk−Mk−1hasﬁniteL∞normkξkk∞.Thenforanyλ>0andn≥1P(|Mn−M0|≥λ)≤2exp(cid:18)−λ22Pnk=1kξkk2∞(cid:19).Seee.g.Chung&Lu(2006,Section6)fortheproofofLemma4andasurveyofrelatedmartingaleinequalities.29ProofofProposition3.RepeatedlyapplyingEq.(B.6)impliesthatU(n)k=(1−β(λ1−λk))nU(0)k+nXn0=1(1−β(λ1−λk))n−n0en0,k+nXn0=1(1−β(λ1−λk))n−n0E3(v(n)).(B.7)Noteβ(λ1−λk)≤1/2,andhencethesecondsuminEq.(B.7)isabsolutelyboundedby≤nXn0=1(1−β(λ1−λk))n−n0(cid:12)(cid:12)E3(v(n))(cid:12)(cid:12)≤C3,2B2β2nXn0=1(1−β(λ1−λk))n−n0≤C3,2B2β2β(λ1−λk)≤C3,2bβ(B.8)ToboundtheﬁrstsuminEq.(B.7)noteforﬁxedn>0 Mnt=t∧NwXn0=1(1−β(λ1−λk))n−n0en0,k:1≤t≤n!formsamartingale.Herethem.d.s.termisboundedby(1−β(λ1−λk))n−n0≤2C3,1β,andthesumofthesquaredL∞boundsis≤4C23,1B2β2nXn0=1(1−β(λ1−λk))2(n−n0)≤C2B2β22β(λ1−λk)−β2(λ1−λk)2≤C0bβ.ApplyingAzuma’sinequalityintheformofLemma4withMn0=0P(cid:18)|Mnn|≥12bβ0.5−ε(cid:19)=P (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)n∧NwXn0=1(1−β(λ1−λk))n−n0en0,k(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)≥12bβ0.5−ε!≤2exp(cid:18)−(cid:16)2C0bβ(cid:17)−114bβ1−2ε(cid:19).(B.9)Eq.(B.9)isvalidforalln≤N∗t.CombiningEqs.(B.7),(B.9)andEq.(B.8)withbβ0.5+ε≤(2C4,2)−1onehasbytakingC=(8C0)−1P supn≤N∗t∧Nw(cid:12)(cid:12)U(n)k−U(0)k(1−β(λ1−λk))n(cid:12)(cid:12)>bβ0.5−ε!≤2N∗texp(cid:16)−Cbβ−2ε(cid:17),completingtheproofofProposition3.(cid:4)30B.2ProofofProposition4WeﬁrstgiveanupperboundoftheprobabilityofeventHc0,whoseordermatchestheprobabilityestimateinTheorem1.LetJn=(cid:18)supk=2,...,d(cid:12)(cid:12)(cid:12)U(n)k(cid:12)(cid:12)(cid:12)≤2bβ0.5−ε(cid:19),H0=\n∈[N∗0.5−ε,N∗1.5]Jn.(B.10)WeﬁrstgiveanupperboundoftheprobabilityofeventHc0,whoseordermatchestheprobabilityestimateinTheorem1.Lemma5.WehaveP(Hc0)≤2(d−1)N∗1.5exp(cid:16)−C3,Pbβ−2ε(cid:17).(B.11)Proof.LetH1,k= supn≤N∗β,2∧Nw(cid:12)(cid:12)U(n)k−U(0)k(1−β(λ1−λk))n(cid:12)(cid:12)≤bβ0.5−ε!,H2,k= supn∈[N∗β,0.5−ε,N∗β,2](cid:12)(cid:12)(cid:12)U(n)k(cid:12)(cid:12)(cid:12)≤2bβ0.5−ε!.(B.12)ImmediatelywehaveH0=∩2≤k≤dH2,k.Proposition3impliesthatfork=2,...,dP(cid:0)Hc1,k(cid:1)≤2N∗β,2exp(cid:16)−C3,Pbβ−2ε(cid:17).On∩2≤k≤dH1,kbydeﬁnitionofNwinEq.(4.3),wehave(cid:0)N∗β,2>Nw(cid:1)⊆[n≤N∗β,2 dXk=2(cid:12)(cid:12)U(n)k(cid:12)(cid:12)2!1/2>2√2Ontheotherhandsupn≤N∗β,2∧Nw dXk=2(cid:12)(cid:12)U(n)k−U(0)k(1−β(λ1−λk))n(cid:12)(cid:12)2!1/2≤(dbβ1−2ε)1/2≤bβε/2,sobytriangleinequalityforEuclideannormsupn≤N∗β,2∧Nw dXk=2(cid:12)(cid:12)U(n)k(cid:12)(cid:12)2!1/2≤ dXk=2(cid:12)(cid:12)U(0)k(cid:12)(cid:12)2!1/2+bβε≤1+bβε≤2,31implyingthat(cid:0)N∗β,2>Nw(cid:1)∩\2≤k≤dH1,k⊆(cid:0)N∗β,2≤Nw(cid:1).WehavesuccessfullyremovedthestoppingtimeNwandobtain\2≤k≤dH1,k=\2≤k≤d supn≤N∗β,2(cid:12)(cid:12)U(n)k−U(0)k(1−β(λ1−λk))n(cid:12)(cid:12)≤bβ0.5−ε!.Henceon∩2≤k≤dH1,kwehaveforn∈[N∗β,0.5−ε,N∗β,2]andeachk∈[2,d](cid:12)(cid:12)(cid:12)U(n)k(cid:12)(cid:12)(cid:12)≤bβ0.5−ε+|U(0)k|(1−β(λ1−λk))n≤bβ0.5−ε+bβ0.5−ε=2bβ0.5−ε.FromthedeﬁnitionsinEq.(B.12)andEq.(B.10)thisindicates∩2≤k≤dH1,k⊆∩2≤k≤dH2,k=H0.ThereforeP(Hc0)≤dXk=2P(cid:0)Hc1,k(cid:1)≤(d−1)·2N∗β,2exp(cid:16)−C3,Pbβ−2ε(cid:17),completingtheproof.(cid:4)ToproveProposition4weneedaresultfrombasicprobabilityLemma6.ForanyrandomvariablesX,Ywithvar(X)≥var(Y),wehavevar(X+Y)≤var(X)+3pvar(X)var(Y).Proof.Thelemmaistrivialwhenvar(X)=0.Inthecasewherevar(X)=1≥var(Y)wehavevar(Y)≤pvar(Y),andalsocov(X,Y)≤pvar(Y),whichleadtovar(X+Y)=var(X)+var(Y)+2cov(X,Y)≤1+var(Y)+2pvar(Y)≤1+3pvar(Y).Forgeneralvar(X)=σ2X>0wehavevar(σ−1XX)=1,andtheaboveimpliesσ−2Xvar(X+Y)=var(σ−1XX+σ−1XY)≤1+3qvar(σ−1XY)=1+3svar(Y)var(X).Multiplyingbothsidesbyvar(X)=σ2Xcompletestheproof.(cid:4)32Letbek,n+1=ek,n+11Jnwhereek,n+1isasdeﬁnedinEq.(B.4),andletbλ1=(1+4bβε)λ1.Weﬁrstobtainatightestimatefortheerrorterm,ek,n+1.Lemma7.Forn∈[N∗β,0.5−ε,N∗β,2]E(bek,n+1)2≤β2(cid:16)bλ1λk+C7B2bβ1−2ε(cid:17).Proof.WehaveonJnv2k≤(vk/v1)2≤4bβ1−2ε,v−21dXk=2v2k≤4dbβ1−2ε≤4bβε,v−21≤1+4bβε.(B.13)Theseestimateswilllaterbeusedasareference.ForconveniencewewriteEq.(B.3)againas∆(vk/v1)=βv−11(cid:2)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:3)+v−11Qk−v−21vkQ1.(B.14)SinceAssumption2issatisﬁed,wehaveforYcov(cid:0)(v>Y)2,Y2k(cid:1)=cov dXd0=1vd0Yd0!2,Y2k=dXd0=1v2d0cov(cid:0)Y2d0,Y2k(cid:1)+2X1≤l<m≤dvlvmcov(cid:0)YlYm,Y2k(cid:1)=v2kψkk.NotewehaveE(v>Y)2=v>Λv≤λ1.(B.15)Alsoψkk≤EY4k≤BEY2k=Bλk.(B.16)Thereforecov(cid:0)(v>Y)2,Y2k(cid:1)≤v2kBλk.(B.17)UsingEqs.(B.17),(B.15)and(B.16)oneconcludesvar(cid:2)(v>Y)Yk(cid:3)≤E(cid:2)(v>Y)Yk(cid:3)2=cov(cid:0)(v>Y)2,Y2k(cid:1)+E(cid:0)v>Y(cid:1)2EY2k≤v2kBλk+λ1λk.(B.18)Analogouslyfortheﬁrstcoordinatevar(cid:2)(v>Y)Y1(cid:3)≤cov(cid:0)(v>Y)2,Y21(cid:1)+E(cid:0)v>Y(cid:1)2EY21≤(v21B+λ1)λ1≤CB2.(B.19)33Thecovarianceoftwotermsiscov(cid:0)(v>Y)Yk,(vk/v1)(v>Y)Y1(cid:1)=(vk/v1)cov(v1Y1Yk,vkYkY1)=v2kvar(Y1Yk)≥0.ThereforefromEqs.(B.19)and(B.18)var(cid:2)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:3)≤v2kBλk+λ1λk+CB2(vk/v1)2≤λ1λk+CB2bβ1−2ε,whichisboundedbyCB2.NotefromEq.(A.1),var(cid:0)v−11Qk−v−21vkQ1(cid:1)≤C26,2B4β4.LastlywehavefromthedeﬁnitionE(bek,n+1)2≤E(ek,n+1)2=var(∆(vk/v1)).CombinethelastthreedisplaysandEq.(B.14),usingEq.(6)andthefactthatBβ≤bβ≤bβ1−2εweconcludeE(bek,n+1)2≤β2v−21var(cid:2)(v>Y)Yk−(vk/v1)(v>Y)Y1(cid:3)+3Bβ·CB2β2≤β2(1+4bβε)(cid:16)λ1λk+CB2bβ1−2ε(cid:17)+C0B3β3≤β2(cid:16)bλ1λk+CB2bβ1−2ε(cid:17).Thiscompletesproofofthelemma.(cid:4)ProofofProposition4.ProbabilityofH0hasbeenestimatedinEq.(4.6)ofLemma5,whichleavesustoproveEq.(4.7).ApplyEq.(B.6)recursivelyandonecanconcludeforn∈[N∗β,1−2ε,N∗β,2]U(n)k=(1−β(λ1−λk))nU(0)k+nXn0=1(1−β(λ1−λk))n−n0ek,n0.(B.20)Forn>N∗β,0.5−ε,weconsiderasequenceinparallelthatusesslightlydiﬀerentnoisetermsbU(n)k=(1−β(λ1−λk))nU(0)k+N∗β,0.5−εXn0=1(1−β(λ1−λk))n−n0ek,n0+nXn0=N∗β,0.5−ε+1(1−β(λ1−λk))n−n0bek,n0,(B.21)34wherebek,n0termsweredeﬁnedinLemma7.FromthedeﬁnitionofH0inEq.(B.10)weconcludeforeachn∈(cid:2)N∗β,1−2ε,N∗β,2(cid:3)H0⊆\n∈[N∗β,0.5−ε,N∗β,2](en+1=ben+1).CombiningthiswithEqs.(B.20)and(B.21),wehave(U(n)k)21H0=(bU(n)k)2forn∈(cid:2)N∗β,0.5−ε,N∗β,2(cid:3).TakingexpectationE(cid:20)(cid:16)U(n)k(cid:17)2;H0(cid:21)=E(bU(n)k)2.(B.22)Fromanotherperspectivewehave(1−β(λ1−λk))n−n0ek,n0formsanm.d.s.TakingsecondmomentonbothsidesofEq.(B.21)andusingthepropertyofsquareintegrablem.d.s.(Durrett,2010,Chap.5)givesE(cid:16)bU(n)k(cid:17)2=(1−β(λ1−λk))2n(cid:16)U(0)k(cid:17)2+N∗β,0.5−εXn0=1(1−β(λ1−λk))2(n−n0)E(ek,n0)2+nXn0=N∗β,0.5−ε+1(1−β(λ1−λk))2(n−n0)E(bek,n0)2≡I+II+III.(B.23)NoteforII,recallfromthedeﬁnitioninEq.(2.5)thatforeachcoordinatek=2,...,d,(1−β(λ1−λ2))N∗s≤bβs.Henceforn≥N∗β,1−2ε(1−β(λ1−λk))2(n−N∗β,0.5−ε)≤bβ1−2ε,andwefactorthisout.ApplyingProposition6wehaveII≤bβ1−2εN∗β,0.5−εXn0=1(1−β(λ1−λk))2(N∗β,0.5−ε−n0)E(en0,k)2≤bβ1−2ε∞Xn=0(1−β(λ1−λk))2n·CB2β2≤C0B2bβ1−2ελ1−λkβ.(B.24)35ForIII,usingLemma7III≤β2(cid:16)bλ1λk+C7B2bβ1−2ε(cid:17)nXn0=N∗β,0.5−ε+1(1−β(λ1−λk))2(n−n0)≤β2(cid:16)bλ1λk+C7B2bβ1−2ε(cid:17)∞Xn=0(1−β(λ1−λk))2n=bλ1λk+C7B2bβ1−2ε2(λ1−λk)·β·22−(λ1−λk)βNoteusingTaylorexpansion,thethirdfactorinthelastline≤1+C(λ1−λ2)2B−2bβ≤1+Cbβ.ThisindicatesIII≤(cid:16)bλ1λk+C7B2bβ1−2ε(cid:17)(cid:16)1+Cbβ(cid:17)2(λ1−λk)β≤bλ1λk+C00B2bβ1−2ε2(λ1−λk)β.(B.25)CombiningEqs.(B.23),(B.24),(B.25)E(cid:16)bU(n)k(cid:17)2=I+II+III≤(1−β(λ1−λk))2n(cid:16)U(0)k(cid:17)2+bλ1λk+2C0B2bβ1−2ε+C00B2bβ1−2ε2(λ1−λk)β.Setting2C0+C00aboveasthenewCandnotingtherelationinEq.(B.22)completestheproofofEq.(4.7).(cid:4)B.3ProofofProposition5LetAU(v)=λ1−v>Λv1−v21,(B.26)NotethatAU(v)≥λ1−(λ1v21+λ2(1−v21))1−v21≥λ1−λ2.Lemma8.Foreachn≥0,wehaveon(cid:0)v(n)∈S1(cid:1)(cid:12)(cid:12)U(n+1)−U(n)(cid:12)(cid:12)≤C8,1Bβ.(B.27)Inadditionon(cid:0)v(n)∈S1(cid:1)E(cid:2)U(n+1)−U(n)|Fn(cid:3)=βAU(v(n))U(n)+E2(v(n)),(B.28)wherethedeterministicfunction|E2(v)|≤C8,2B2β2holdsforv∈S1.36Proof.Taylor’stheoremforlinearapproximationgivesforf(x)=x(1−x2)−1/2∆(M(v))=∆ v1p1−v21!=f0(v1)∆v1+R(v)=∆v1(1−v21)3/2+R(v),whereduetotheC∞-smoothnessoff(x)onx∈[0,5/6],thereisaconstantCthatboundthesecondderivativef00.Lagrangeformoftheremainderimplies|R(v)|≤C(∆v1)2≤C0B2β2.NoteProposition6impliesfortheboundforv(n)∈S1(cid:12)(cid:12)U(n+1)−U(n)(cid:12)(cid:12)≤|∆v1|(1−v21)3/2≤CBβ(1−v21)3/2≤C0Bβ,whereweusedEq.(A.2)inProposition6,completingtheproofofEq.(B.27).ForthemeanE[∆v1]=βv1(cid:0)λ1−v>Λv(cid:1)+E1,1(v)wehaveon(cid:0)U(n)=u=M(v),v(n)=v(cid:1)E(cid:2)U(n+1)−U(n)|Fn(cid:3)=βv1(cid:0)λ1−v>Λv(cid:1)+E1,1(v)(1−v21)3/2=βAU(v)u+E2(v),whereduetov21≤1/2E2(v)=E1,1(v)(1−v21)3/2∈[−2√2C6,1B2β2,2√2C6,1B2β2].ThisprovesEq.(B.28).(cid:4)Letthenoisetermsgeneratedfromeachincrementbeen+1=U(n+1)−E[U(n+1)|Fn].(B.29)Eq.(B.27)inLemma8imply|en+1|=(cid:12)(cid:12)U(n+1)−U(n)−E[U(n+1)−U(n)|Fn](cid:12)(cid:12)≤|U(n+1)−U(n)|+E[|U(n+1)−U(n)||Fn]≤2C8,1Bβ,(B.30)andEq.(B.28)givesfor|E2(v(n))|≤C8,2B2β2U(n+1)=en+1+E[U(n+1)−U(n)|Fn]+U(n)=en+1+(1+βAU(v(n)))U(n)+E2(v(n)).(B.31)37Lemma9.ThesequencegeneratedbyEq.(B.31)hasrepresentationP−nU(n)=U(0)+nXk=1P−k(cid:0)ek+E2(v(k−1))(cid:1),(B.32)whereP−k∈Fk−1isarandomvariablegivenbyP−k=k−1Yk0=0(cid:16)1+βAU(v(k0))(cid:17)−1.Proof.Wehavebysettingαk=1+βAU(v(k))U(n)=en+E2(v(n−1))+αn−1U(n−1)=en+E2(v(n−1))+αn−1(cid:0)en−1+E2(v(n−2))(cid:1)+αn−1αn−2U(n−2).RepeatedlyapplytheaboverecursionandwehaveU(n)= n−1Yk0=0αk0!U(0)+nXk=1 n−1Yk0=kαk0!(cid:0)ek+E2(v(k−1))(cid:1).SinceP−k=Qk−1k0=0α−1kwemultiplybothsidesbyP−nP−nU(0)=U(0)+nXk=1 k−1Yk0=0αk0!−1(cid:0)ek+E2(v(k−1))(cid:1)=U(0)+nXk=1P−k(cid:0)ek+E2(v(k−1))(cid:1),obtainingEq.(B.32).(cid:4)Lemma10.WehaveforﬁxedNP(cid:18)supn≤Nc∧N(cid:12)(cid:12)P−nU(n)−U(0)(cid:12)(cid:12)≥bβ0.5−ε(cid:19)≤2Nexp(cid:16)−C5,Pbβ−2ε(cid:17).Proof.UsingEq.(B.32)andbasicprobabilityinequalitiesitisenoughtoshowP (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Nc∧nXk=1P−kek+Nc∧nXk=1P−kE2(v(k−1))(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)≥bβ0.5−ε!≤2exp(cid:16)−Cbβ−2ε(cid:17)(B.33)foranyn.FromthedeﬁnitionofAUinEq.(B.26)andP−kinLemma9wehave0<P−k=k−1Yk0=0(cid:16)1+βAU(v(k0))(cid:17)−1≤(1+β(λ1−λ2))−k.(B.34)38Since2β(λ1−λ2)≤1,Lemma8impliesforthesecondsuminsideEq.(B.33)that(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Nc∧nXk=1P−kE2(v(k−1))(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)≤Nc∧nXk=1P−k(cid:12)(cid:12)E2(v(k−1))(cid:12)(cid:12)≤∞Xk=1(1+β(λ1−λ2))−kC8,2B2β2≤2C8,2bβ.Fortheﬁrstsummationthem.d.s.sequencesatisﬁes|P−kek|≤(1+β(λ1−λ2))−kC8,1Bβ.ThesumofthesquaredL∞normisboundedby≤C2B2β2nXk=1(1+β(λ1−λ2))−2k≤C0bβ.ApplyingAzuma’sinequalitywehaveP (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Nc∧nXk=1P−kek(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)≥12bβ0.5−ε!≤2exp(cid:18)−(cid:16)2C0bβ(cid:17)−1bβ1−2ε(cid:19)≤2exp(cid:16)−Cbβ−2ε(cid:17).Sincebβ0.5+ε≤(4C8,2)−1the2C8,2bβ≤0.5bβ0.5−ε.TheaboveanalysisgivesEq.(B.33),concludingthelemma.(cid:4)ProofofProposition5.DeﬁneE1= supn≤Nc∧Noβ(c∗)(cid:12)(cid:12)P−nU(n)−U(0)(cid:12)(cid:12)≤bβ0.5−ε!.ThenontheeventE1∩(cid:0)Nc>Noβ(c∗)(cid:1)wehavebyEqs.(B.34)andtheinitialconditioninTheorem1|U(0)|≥(c∗d)−0.5that|U(Noβ(c∗))|≥(cid:16)P−Noβ(c∗)(cid:17)−1(cid:16)|U(0)|−bβ0.5−ε(cid:17)≥(1+β(λ1−λ2))Noβ(c∗)(cid:16)(c∗d)−0.5−bβ0.5−ε(cid:17).39Takinglogarithminthelastdisplay,wehaveforbβ<1/3log|U(Noβ(c∗))|≥Noβ(c∗)log(1+β(λ1−λ2))+log(cid:16)(c∗d)−0.5−bβ0.5−ε(cid:17)≥0.5log(2c∗d)log(1+β(λ1−λ2))log(1−β(λ1−λ2))−1−0.5log(c∗d)+log(cid:16)1−(c∗bβε)1/2(cid:17)≥0.5log2−0.5log(2c∗d)β(λ1−λ2)−2(c∗bβε)1/2≥0.5log2−0.5log(cid:16)2c∗bβ−1+3ε(cid:17)bβ−2(c∗bβε)1/2.(B.35)Noteweuseddbβ1−3ε≤1,andlog(1+t)log(1−t)−1≥1−t,0≤t≤1/3,andlog(1−t)≥−2t,0≤t≤1/3.TherighthandofEq.(B.35)isnonnegativewheneverc∗bβεislessthansomeabsolute,positiveconstantb5<ln22/16,whichgivesEq.(4.9).ExponentiatingbothsidesofEq.(B.35)weobtain|U(Noβ(c∗))|≥1.BydeﬁnitionofNcinEq.(4.8)weshowedthatE1∩(cid:0)Nc>Noβ(c∗)(cid:1)⊆(cid:0)Nc≤Noβ(c∗)(cid:1),i.e.E1⊆(cid:0)Nc≤Noβ(c∗)(cid:1).ThisalongwithLemma10impliesP(cid:0)Nc∈[0,Noβ(c∗)](cid:1)≥P(E1)≥1−2Noβ(c∗)exp(cid:16)−C5,Pbβ−2ε(cid:17),provingEq.(4.10).(cid:4)CProofsofAuxillaryLemmasC.1ProofofLemma1Weneedtouseaclassicalresultofmultivariatestatistics(Muirhead,2005,pp.147)Lemma11.IfX=(X1,...,Xd)>isuniformlygeneratedfromSd−1inRd,themarginaldensityofX1isf1(x)=ωd−1ωd(1−x2)(d−3)/2·1[−1,1](x),whereωd∗≡2πd∗/2[Γ(d∗/2)]−1istheareaoftheunitsphereinRd∗.40ProofofLemma1.Letθ0=∠(u(0),u∗).Sincecosθ0isdistributedthesameasX1inLemma11weusethedensityformulatheretoconcludeP(cid:0)tan2θ0>C∗δ−2d(cid:1)=P(cid:16)|cosθ0|<(cid:0)1+C∗δ−2d(cid:1)−1/2(cid:17)≤P(cid:16)|X1|<(cid:0)C∗δ−2d(cid:1)−1/2(cid:17)≤4ωd−1ωd(cid:0)C∗δ−2d(cid:1)−1/2≤δ,whereC∗=supd≥116(cid:16)ωd−1ωd(cid:17)2d−1isﬁniteduetothepropertyofgammafunction.ThenumericalvalueofC∗isapproximately2.56.(cid:4)41