Abstract

This paper serves as an introduction to the current book. It provides
the basic notions of long-baseline optical/infrared interferometry prior to
reading all the subsequent chapters, and is not an extended introduction
to the ﬁeld.

6
1
0
2

 
r
a

M
 
4

 
 
]

M

I
.

h
p
-
o
r
t
s
a
[
 
 

1
v
3
6
4
1
0

.

3
0
6
1
:
v
i
X
r
a

1

Interferometry concepts

F. Millour∗

EAS publication series, vol. 69, 2014

1

Introduction

Long-baseline interferometry in the optical and infrared wavelengths is living a
“golden age” which indicates its maturity as an observing technique. I chose here
not to develop the history of interferometry as it has already been extensively
presented in numerous reviews (e.g. Shao & Colavita [1992], Lawson [2000],
Jankov [2010], and including in this book: L´ena [2015]).

I would also suggest reading the excellent book on optical interferometry
from A. Glindemann ([2011]), where all the notions which are rapidly explained
here, are detailed.

I will rather try to get into more details of new ideas and now-commonly
understood aspects which have been developed in the years after the publication
of Millour ([2008]), namely the breakthrough of spectrally-dispersed interferom-
etry and its consequences, how to cope with chromatic datasets, how to make
a model of such data, and imaging techniques. I will also try to present what
makes a good interferometer.

2 Why high-angular resolution?

The resolution power of an optical system, given its optical elements are perfect,
is only related to its size (diameter). This property was noted by Lord Rayleigh,
which gave his name to the so-called empiric Rayleigh criterion θ:

θ = 1.22

λ
D

(1)

with D the telescope diameter, and λ the wavelength of observation. This
relation comes from an approximate estimate of the radius of the ﬁrst zero in
the Airy function, which is involved in the description of the diﬀraction pattern
of a round pupil (see later).

The consequence is that, even making abstraction of all practical problems
aﬀecting an instrument, there is a fundamental limit in its resolution power,
∗Laboratoire Lagrange, UMR7293, Universit´e de Nice Sophia-Antipolis, CNRS, Observa-
toire de la Cˆote d’Azur, Bd. de l’Observatoire, 06304 Nice, France. email: fmillour@oca.eu

2

If one takes
directly linked to its diameter and the wave-properties of light.
the simple example of our Sun, which has an approximate diameter of 30”, an
instrument with a pupil smaller than ≈ 145µm will not be able to resolve it
in the visible (i.e. at λ = 555 nm, see Defr`ere et al. [2014]). As an illustration
of this eﬀect, most insects, whose eyes are composed of tiny ommatidia (≤
50µm) see the Sun as a point source, whereas men, whose pupil is ≈ 1 mm,
can resolve it (with the use of an adequate ﬁlter, of course). To resolve one of
the biggest star in the sky, Betelgeuse with a diameter of 44 mas (Michelson &
Pease, [1921], Haubois et al. [2009]), the needed telescope diameter would be
≈ 3.2 m, i.e. slightly larger than the 100 inches (2.5 m) of the Hooker telescope
used by Michelson & Pease ([1921]) to resolve it (hence the installation of a
boom supporting mirrors to enlarge the available aperture). To resolve a dwarf
star similar to the Sun located at 10 pc (i.e. a star with an angular diameter of
0.9 milli-arcsecond), one would need to build a 150 m diameter telescope, which
is simply unfeasible with the current techniques (see e.g. Monnet & Gilmozzi,
[2006]).

The way to go to get ﬁner details on stars is interferometry, i.e. combin-
ing several telescopes into a “virtual telescope” the diameter of the utmost-
separated apertures.

3 PSF and (u, v) plane

To understand what an interferometer does, one needs to understand what
a Point Spread Function (PSF) is.
I recall here the introduction of Millour
([2008]).

3.1 Single-aperture PSF and U-V patch

The light propagating from the astrophysical source to the observer has come a
long way. Let us represent it by the classical electromagnetic wave:

(cid:126)E((cid:126)z, t) = (cid:126)E0((cid:126)z)eıωt
(cid:126)B((cid:126)z, t) = (cid:126)B0((cid:126)z)eıωt

(2)

Here, (cid:126)E represents the electric ﬁeld, (cid:126)B the magnetic ﬁeld, which form a
plane perpendicular to the propagation direction, (cid:126)z is the position in space, t is
the time and ω the light pulsation, related to the wavelength λ and the speed
of light c by ω = 2πc/λ.

The light intensity at the focus of the instrument (see Fig. 1 for details) is
the result of the superposition of many electromagnetic waves coming from the
pupil of the instrument:

3

Figure 1: Notations used in this paper. The light propagates from the sky to
the detector through the instrument pupil. Each plane of interest has its own
coordinate system.

(cid:13)(cid:13)(cid:13)2(cid:29)

t

(cid:28)(cid:13)(cid:13)(cid:13) (cid:126)E((cid:126)x, t)
(cid:42)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:88)

i

(cid:126)E((cid:126)pi, t − τi)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2(cid:43)

(3)

(4)

t

I((cid:126)x) =

=

The i index represent a number of arbitrarily chosen points in the plane of
interest. (cid:126)x is the 2D coordinate vector onto the focal plane, screen or detector.
For example, (cid:126)pi is the coordinate vector onto the pupil plane. τi represents the
propagation delay between the diﬀerent incoming electromagnetic waves.

When the pupil is split like in Fig. 1, it is convenient to deﬁne (cid:126)B the sepa-
ration vector between the sub-pupils. This vector, or its length, is often called
“baseline”.

If one considers a point-source light emitter (i.e. the wavefront at the en-
trance pupil is a plane), this expression can be integrated onto the pupil, instead
of summed as in eq. 4 to see what the shape of the intensity in the image plane
is.

For example, in the case of a round pupil of diameter D, the light intensity
will follow an Airy pattern (see the demonstration in Perez [1988] page 288),
which writes:

I(ρ) =

(5)

(cid:18) πD2

(cid:19)2(cid:20) 2J1(πρD)

(cid:21)2

4

πρD

4

xSkyPupilDetectorypxpyLight propagationdirectionwith ρ = (cid:107)(cid:126)x(cid:107) and J1 the 1st order Bessel function. An illustration of dif-
ferent pupils and the associated PSF is shown in Figure 2. The consequence
is that a point-source does not appear as a point source through a telescope
or instrument, owing to the Rayleigh criterion (the factor 1.22 comes from the
ﬁrst zero of the Bessel function). An instrument is therefore limited in angular
resolution by the diameter (or maximum baseline) of its aperture.

Figure 2: Top, from left to right: Simulated apertures for diﬀerent instru-
ments with similar angular resolution ; round pupil ; VLT pupil ; Keck pupil ;
3 telescopes interferometer ; 2 telescopes interferometer. Bottom, from left
to right: The corresponding PSF

3.2 Diluted or masked-aperture PSF and U-V plane

An interferometer, or a pupil-masking instrument, is a set of multiple telescopes
(or apertures D) which are combined together to form interference patterns on
a given common source, represented by its sky-brightness distribution Sλ(α, δ).
For convenience, one will always considers that the pupils are inﬁnitely small,
and they are identiﬁed by their indices i or j.

The interferometer is sensitive to the incoming light coherence, measured
by the mutual coherence function. This function is deﬁned as the correlation
between two incident wavefronts (cid:126)E coming from positions (cid:126)pi and (cid:126)pj. The two
beams of light from each positions have a delay τ :

(cid:68) (cid:126)E((cid:126)pi, t − τ ) (cid:126)E∗( (cid:126)pj, t)
(cid:69)
(cid:88)

Γi,j(τj − τi) + Γi,j

t

Γi,j(τ ) =

(cid:88)

I((cid:126)x) =

Γi,i(0) +

i

i,j

5

The light intensity can then be developed as a function of Γ from eq 3:

(6)

(7)

∗(τj − τi)

One can note here that the terms Γi,i(0) are just the light intensity Ii((cid:126)x),
as if there was only one unperturbed source of light. The delays τi are set
as a function of the origin of the two wavefronts, and of the conﬁguration of
the instrument (used optics, focal length, etc.) and, in the focal plane of the
instrument, both depend only on the coordinates in that plane. Let us pose
τj − τi = τ . When dealing with 2 wavefronts, just like in an interferometer, the
equation 7 simpliﬁes in:

I((cid:126)x) = I1((cid:126)x) + I2((cid:126)x) + Γ1,2(τ ) + Γ1,2

∗(τ )

(8)

If one normalises the term Γi,j by the total ﬂux, this deﬁnes the complex

coherence degree γ1,2(τ ):

γ1,2(τ ) =

Γ1,2(τ )

Γ1,1(0) + Γ2,2(0)

(9)

When considering a 1D-interferogram with abscissa x (for example when
one axis is anamorphosed in order to feed it into a spectrograph), equation 8
becomes:

I(x) = [I1(x) + I2(x)] [1 + (cid:60) (γ1,2(τ ))]

= [I1(x) + I2(x)]

1 + µobj

1,2 cos

(cid:20)

(cid:18) 2πx

λ

(cid:19)(cid:21)

+ φobj
1,2

(10)

(11)

µ being the modulus of γ1,2(0) and φ its phase (γ1,2(0) = µeıφ). The cosine
modulation corresponds to the intensity fringes that an optical interferometer
measures. Eq. 11 and its variants is often referred as “the interferometric equa-
tion”, and describes the intensity interference pattern (or interferogram) as seen
on a screen or detector. µ and φ are often called the visibility or contrast, and
phase of the interferogram, respectively. An illustration of this equation can be
seen in Figure 4, left. The x variable is a length corresponding to the delay dif-
ference between the two recombined beams. It can be directly projected on the
detector, as is done in a multiaxial instrument, or a time-modulated variation of
x = vmod × t can be introduced as is often done in a coaxial instrument (see e.g.
Berger et al. [1999], or the paper in this book: Berger [2015] for more details).
This equation, with minor modiﬁcations (due to the ﬂux envelope of the

slits) also drives the well-known Young’s two-slit experiment.

4 Light source and light coherence

With the Young’s experiment, a simple test to do is to change the physical size
of the source by e.g. putting a varying-size diaphragm in front of it. When
the source’s size changes, one can observe that the fringe contrast also changes,
and there are speciﬁc sizes at which the fringes completely wash out. We saw

6

in the previous sections the intensity function of an interferometer in the case
of a point source. Here I will detail a little what happens when the source is
resolved by the instrument or interferometer.

This is where the Zernicke and van Cittert (ZVC) theorem comes into light,
1,2 to the object’s shape projected onto the

1,2 eıφobj

linking the value of γ1,2(0) = µobj
plane of sky:

For a non-coherent and almost monochromatic extended source, the complex
visibility is the normalised Fourier transform (hereafter FT) of the brightness
distribution of the source.

Or written in a mathematical way:

γ1,2(0) = (cid:115) ∞

−∞ S(α, δ)e−2iπ(uα+vδ) dα dδ

(cid:115) ∞
−∞ S(α, δ) dα dδ

=

F T (S)

Stot

(12)

(13)

with here S(α, δ) is the brightness distribution of the source at angular
coordinates α and δ, u and v are the spatial frequencies at which the Fourier
Transform is computed. The demonstration of this theorem can e.g. be found
in Born & Wolf ([1999]). And here is why Fourier-transforms are so important
to interferometry!

The direct consequence of this theorem is that the fringe contrast and phase
are related to Fourier Transforms: the larger the object, the lower will be the
contrast (for a “regular” object). An illustration of this eﬀect is shown in
Figure 3.

4.1 Coherent ﬂux

As has been seen, the interferometer is sensitive in theory to the degree of
1,2 × eıφobj
coherence of light γi,j(0) = µobj
1,2 , or complex visibility, which is given by
the Zernicke and van Cittert theorem.

One needs to calculate the visibility values from the interferogram signal.
As this signal has a cosine modulation, one way to extract its amplitude and
phase is to apply a Fourier Transform and calculate the power at the modulation
frequency fi,j (See Fig. 4). The observed γi,j(0), noted with “(cid:94)γi,j(0)” is:

(cid:94)γi,j(0) =

NbasesFTfi,j [I(x, λ)]

FT0 [I(x, λ)]

(14)

with Nbases = Ntel(Ntel−1)

. This equation contains the approximation that
the two ﬂuxes I1((cid:126)x) and I2((cid:126)x) are equal. The case where I1((cid:126)x) and I2((cid:126)x) are
not equal is treated later in this book (ten Brummelaar [2015]).

2

This method is often called the Fourier method, but note that it has nothing
to do with the ZVC theorem (eq. 13), as it is just a way to actually measure
the visibility.

7

point source

Object
small

large

Image

Interferometer

Full pupil

Figure 3: Top, from left to right: Simulated round objects of diﬀerent di-
ameters. Middle-left: Reproduction of the 2 telescope interferometer pupil.
Middle: Fringe pattern for the diﬀerent object sizes. Note the fringe contrast
change. Bottom-left: Reproduction of the ideal round pupil. Bottom: cor-
responding image. Note the disappearance of the Airy rings when the object is
resolved.

8

Figure 4: Left: A simulated fringe pattern for a typical multiaxial interfer-
ometer, with the representation of where the fringe contrast and phase can be
measured. Right: The Fourier Transform of that fringe pattern exhibits two
peaks: one at zero frequency, representing the total ﬂux, and one at frequency
fi,j representing the fringe contrast. Note that the white noise from the data
appears as “grass” in the Fourier Transform.

Another way is to measure the amplitude of the fringes in the image space,
for example, one can measure one fringe at 4 diﬀerent points A, B, C, D each one
separated to each other in phase by π/2 (see Fig. 5). The visibility amplitude
can be computed this way:

(cid:101)µ =

2(cid:80)
(cid:18) IA − IC
and the visibility phase:(cid:101)φ = arctan

(cid:112)(IA − IC)2 + (IB − ID)2
(cid:19)

j Ij

IB − ID

(15)

(16)

One needs to note here that the ABCD method relies on the knowledge of
the shape of the fringes (a cosine function) and on the fact that the A,B,C and D
samples are exactly oﬀset by π/2. A generalisation of that method, called p2vm
(Millour et al. [2004], Tatulli et al. [2007]), was proposed and implemented on
the amber instrument (Petrov et al. [2007]). The basic idea is to use the a
priori information of the fringes shape to adjust a model to the data in order
to obtain the visibilities. The method is thoroughly described in Tatulli et al.
([2007]).

To get an overview and understanding of how to reduce data for a speciﬁc
instrument, it is always better to read the corresponding paper. For example
Mourard et al. ([2011]) for the chara/vega instrument, Petrov et al. ([2007])
for the vlti/amber instrument, ten Brummelaar ([2015]) for chara/classic,
Perrin ([2003a], [2003b]) for chara/fluor and vlti/vinci, etc.

4.2 The (u, v) problem

One very speciﬁc problem of optical long-baseline interferometry is called the
“(u, v) problem”.
It is related to the sparsity of measurements the interfer-

9

µobjφobj 360 380 400 420 440 0 500 1000PixelsFlux (photons)φobjµobj/2fij1011ReImFigure 5: Principle of the ABCD method: 4 measurements are made onto one
single fringe, dephased by π/2 each, owing to the fringe contrast and phase.

ometers can provide.
Indeed, contrary to classical imaging, a two telescopes
interferometer measurement samples only one point in the frequency domain
of equation 13, usually noted (u, v) plane. More details are given in Millour
([2008]), therefore I will just recall the diﬀerent ways to ﬁll the (u, v) plane:

Supersynthesis: The rotation of Earth relative to the celestial sphere makes
the baseline change with time. The (u, v) tracks are on an arc of ellipse.
The exact expression of the (u, v) tracks is given in Segransan ([2007]) and
recalled in Millour ([2008]).

Add more telescopes: The number of (u, v) points for one measurement is
equal to the number of baselines, roughly proportionnal to the square of
the number of telescopes, following the relation Nbases = Ntel(Ntel−1)

2

Make use of wavelength: The spatial frequencies are proportionnal to the

wave number σ = 1/λ and trace radial lines in the (u, v) plane.

An illustration of these is shown in Table 1 for the future matisse/vlti

instrument (Lopez et al. [2006]) in the L band (3µm).

4.3 The phase problem

So, we have a way to measure the complex visibility. However, the actual
measurement of the fringes is aﬀected by a series of eﬀects we detail here, and
we explain a set of workarounds on how to measure the amplitude µ and phase φ
of the object of interest. The eﬀects can be classiﬁed into visibility attenuation
factors A ≤ 1 and phase factors φ. The following list is ordered by decreasing
magnitude on the observables:

10

OPDIntensityABCDc
o
n
f

4

T

+

4
T

2
T

11

a
n
d

c
h
a
n
g
e

o
f

c
o
n
ﬁ
g
u
r
a
t
i
o
n
s
”
,

i
.
e
.

t
h
e

b
e
s
t

s
i
t
u
a
t
i
o
n

a
t

v
l
t
i

t
o
d
a
y

S

i

n
g
l
e
m
e
a
s
u
r
e
m
e
n
t

W
a
v
e
l
e
n
g
t
h

c
o
v
e
r
a
g
e

S
u
p
e
r
s
y
n
t
h
e
s
i
s

S
u
p
e
r
s
y
n
t
h
e
s
i
s

+
W
a
v
e
l
e
n
g
t
h

c
o
v
e
r
a
g
e

γ
2
V
e
l
o
r
u
m

(
d
e
c
l
i

T
a
b

l
e

1
:

T
h
e

i

d
ﬀ
e
r
e
n
t
w
a
y
s

n
a
t
i
o
n
−
4
7
o
)
.

o
f

ﬁ

“
2
T
”
m
e
a
n
s

“
2
T
e
l
e
s
c
o
p
e
s
”
,

“
4
T
”
m
e
a
n
s

“
4
T
e
l
e
s
c
o
p
e
s
”

a
n
d

“
4
T
+
c
o
n
f
”
m
e
a
n
s

“
4
T
e
l
e
s
c
o
p
e
s

l
l
i

n
g

t
h
e

(
u

,
v
)

p

l
a
n
e
,

i
l
l

u
s
t
r
a
t
e
d

b
y
m
a
t
i
s
s
e

o
b
s
e
r
v
a
t
i
o
n

i

n

t
h
e
L
b
a
n
d

(
3
.
5
–
4
.
1
µ
m

)

o
f

t
h
e

s
t
a
r

NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)NE−200 0 200−200 0 200U (arcseconds−1)V (arcseconds−1)• The atmospheric turbulence adds a phase term φp between the telescopes,
sometimes called “atmospheric piston” because it comes from a change
in the optical path diﬀerence δ(t) between the two telescopes. This term
varies as φp
λ(t) = 2πδ(t)/λ as a ﬁrst approximation (see an example phase
shape in Fig. 6).

• Atmosphere also puts higher-order terms (like the tip/tilt eﬀect) which
will aﬀect the instantaneous ﬂux I1 and I2. It can also aﬀect other terms
due to the speckle pattern (Mourard et al. [1994]) but today most of the
combiners use optical ﬁbers to wash out this eﬀect, so we will not detail
it here.

• A ﬁnite exposure time can also be of trouble, as it transforms the phase
φ (Tatulli et al.

p into contrast variations A(σφ

p) = e−σ2

term variations σφ
[2007]).

• Chromatic longitudinal dispersion makes the optical path delay δ(t) de-
pendent of wavelength δλ(t). This eﬀect is explained in details in Tubbs
et al. ([2004]) and Vannier et al. [2006].

• Polarisation eﬀects, either in the beam feeding or inside the instrument can
make the contrast time-variable and even kill it. The contrast variation
due to polarisation is noted: A(∆π). This is due to a diﬀerence of speed
propagation between the two linear polarisations (birefringence eﬀect) due
to asymmetric setups or birefringent materials in the instruments (e.g.
optical ﬁbres). One can then extinct one of the polarisation to avoid this
eﬀect by using a linear polarizer, or an elegant solution is to introduce
a birefringent plate with relevant properties to compensate for this eﬀect
(Lazareﬀ et al. [2012]).

In addition to these eﬀects, more fundamental eﬀects like photon noise σφ
or detector noise σdet, grouped in additive noises b, need to be taken into ac-
count. To summarize, one can include all these eﬀects into the interferometric
equation 11 and consider an arbitrary number of telescopes N tel, which can be
written as:

Ntel(cid:88)
Ntel−1(cid:88)

j=1

Ij

k=1

j=k+1

+ b

I =

+

Ntel(cid:88)

IjIkA(σφ

p)A(∆π)A(δ)µobj

j,k cos

(cid:18) 2π

λ

(x + δ) + φobj
j,k

(cid:19)

(17)

where j, k are telescope indices; x is a space coordinate; λ is the wavelength;
µobj
j,k and φobj
j,k are the object’s visibility and phase; δ is the atmospheric optical
path diﬀerence (OPD), varying with time (see Fig. 6). All the beam intensity

12

p) is an
terms Ij and Ik depend on space x, wavelength λ, and time t; A(σφ
attenuation factor coming from the ﬁnite exposure time of each frame, and
depends on the atmospheric conditions, or the fringe tracker performances; A(δ)
is an attenuation factor dependent of the spectral resolution of the instrument
and the value of the OPD δ; A(∆j,k) is an attenuation factor depending on the
polarization state of both contributiong beams; ﬁnally, b is a zero-mean noise.

Figure 6: From left to right: example amber spectrally dispersed fringes, the
corresponding phase, and a time-sequence of OPD from Tatulli et al. ([2007]).
Reproduced with permission.

The consequence of the phase problem is that the object phase cannot be
measured directly. The following section provides some guidelines on how to
cope with this fact.

5 Observables

The goal of observables is to extract the relevant information, i.e. µo and φo
from the somewhat perturbed equation 17 compared to eq. 11.

5.1 Squared visibility

One way to minimise the turbulence eﬀect of the phase on the visibility is to take
proﬁt of the developments made for speckle interferometry in the 70’s (Labeyrie
[1970]). Indeed, the modulus of the instantaneously-measured complex visibil-
ity can be computed and averaged over time, minimising the eﬀects of phases
ﬂuctuations. To simplify the calculations, one can remove the square root of the
modulus, hence calculating squared modulus. With the Fourier method, this
gives:

(cid:102)µ2 =

13

(cid:13)(cid:13)(cid:13)(cid:13) NbasesFTfi,j [I(x, λ)]

FT0 [I(x, λ)]

(cid:13)(cid:13)(cid:13)(cid:13)2

(18)

 0 10 20 30 0 50 100 150−100 0 100#pixWavelength (µm)φ (o) 0 50 100 150 200−20 0 20Time (s)Piston (mm)Here one can see that most of the phase eﬀects wipe out from this visibility

estimate, but there are a number of issues related to it:

• Additive noises can lead to biases (see how to treat them in Perrin [2003b],

and also in this book: ten Brummelaar [2015]),

• The multiplicative terms A(σφ

p), A(δ), and A(∆π) in eq. 17 do not wipe
out from the estimator, making calibration a very acute issue for this type
of estimator (See for example Millour et al. [2008]).

In terms of error estimate, the squared visibility method has a well-documented

bibliography and I would suggest reading one of these papers: Tatulli et al.
([2007]), Petrov et al. ([2007]), or ten Brummelaar [2015]).

5.2 Diﬀerential visibility, coherent visibility

p)) is to wipe it out explicitely.

Another way to minimize turbulence on the visibility measurement (the terms
2π
λ δ and A(σφ

“slope”, directly related to OPD. This provides us a way to measure (cid:101)δ. The
In other words, as shown in Fig. 6, the phase as a function of λ exhibits a
coherent ﬂux (cid:94)γi,j(0) of eq. 14 can be corrected from the associated phase term,
and its real part averaged.(cid:101)µ = (cid:60)(cid:104)(cid:94)γi,j(0) × exp− 2ıπ
λ (cid:101)δ(cid:105)

(19)

This estimator of visibility is calculated by the midi pipeline (Koehler et al.
[2008]) and is planned to be implemented in the matisse instrument too. It
is often called “coherent visibility” or “linear visibility”. Many aspects are not
treated here (like e.g. time-averaging) as these are pure signal processing aspects
(you can refer to Papoulis [2002] to see how time-averaging of the quotient of
two random variables can be done) and they would be too long to describe here.
p) term, supposedly wavelength-invariant, it may be
convenient to divide the above estimate of visibility by its wavelength-average.
This provides a visibility measurement whose average value is 1 and whose
variations with respect to wavelengths are kept. It is then called “diﬀerential
visibility” as its variations are only relevant relative to a virtual reference wave-
length (also called “reference channel”).

To overcome the A(σφ

(20)

Two ﬂavors of diﬀerential visibility may be computed:
• normalizing the squared visibility of eq. 18 by its wavelength-average.
• normalizing the linear visibility of eq. 19 along λ.
The ﬁrst method was used in the early times of amber. The second method
is the one proposed today in the amber data reduction software, and also on
vega. It will be proposed also for matisse. I would suggest reading the papers
Millour ([2006]) and Mourard et al. ([2009]) for more information.

(cid:101)µdiﬀ =

(cid:101)µ
<(cid:101)µ >λ

14

5.3 Closure phase
The phase φobj
j,k of the object is usually considered as lost when going through the
atmosphere. However, a phase measurement out of 3 telescopes was invented for
radio-astronomy (Jennison [1958]), called “closure phase”. This closure phase
has extremely interesting properties in that it washes out the atmospheric dis-
turbances from the phases.

Let us call 1, 2, 3 the three telescopes of interest. The object’s phases are,
according to the ZVC theorem, linked with each baselines φobj
2,3 , and φobj
3,1 .
On the other hand, the atmospheric disturbances aﬀect the phase of the wave-
front prior each telescope, hence the atmospheric phases can write φatm
φatm
φatm

. Baseline-wise, the phases can be expressed then:

1,2 , φobj

1

2

3

Φ1,2 = φobj
Φ2,3 = φobj
Φ3,1 = φobj

1,2 + φatm
2,3 + φatm
3,1 + φatm

2 − φatm
3 − φatm
3 − φatm

1

2

1

(21)

(22)

(23)

(24)

When summing the phases from the three baselines, the atmospheric distur-

bances disappear and the summed phase becomes:

Ψ1,2,3 = φobj

1,2 + φobj

2,3 + φobj

3,1

(25)

This is called the closure phase. However, one cannot simply sum the phases,
as the phase noise is usually very large compared to 60o (or 1 rad). The phases
histogram can therefore be very far from a pristine Gaussian distribution, often
close to an uniform distribution. The corresponding phase-wrapping eﬀect is
illustrated in Fig. 7.

The way to compute it as an observable is to compute the bispectrum directly

in the complex plane, average it and then take the phase:

(cid:94)Ψ1,2,3 = arg(cid:10)FTf1,2 [I(x, λ)] × FTf2,3 [I(x, λ)] × FTf3,1 [I(x, λ)](cid:11)

t

(26)

√

When the three visibilities on the three baselines have similar values, the
3 higher than the true phase noise. However, this is
closure phase noise is just
not true at all when the three baselines have very diﬀerent visibility amplitudes
(for example when one baseline is exactly in a zero of visibility). In such a case,
the closure phase noise is approximately equal to the highest phase noise from
the three baselines. One can refer to Chelli et al. ([2009]) for more information.
For details on what means the closure phase, and how to interpret it, please

read section 6.

15

Figure 7: Illustration of the phase wrapping eﬀect, showing the transition of
phases histograms from almost Gaussian to a nearly uniform distribution. The
top part shows the real and imaginary parts of the complex values, while the
lower part shows the corresponding phase histograms. The three ﬁrst panels
are synthetic data, while the last one is actual very high signal-to-noise ratio
amber data.

5.4 Diﬀerential phase

5.4.1 How to get it

“Diﬀerential phase” can mean many things: the phase diﬀerence between the
two telescopes (what has been called “phase” in this paper), the phase diﬀer-
ence between two oﬀset positions (also referred as “phase referencing”), the
phase diﬀerence between two separated beams (Aime et al. [1986]), or the phase
diﬀerence between two adjacent wavelengths, introduced by Beckers ([1982]).
We will not talk about the three ﬁrst phases, but explain here the last one
which had quite some applications in the last decade for optical interferometry.
If we take a look to the phase term in eq.17, we note it is made primarily of

two components:

φi,j(λ) = φobj

i,j (λ) +

2πδ(t)

λ

+ o

(cid:18) 1

(cid:19)

λ

(27)

These two components are the object’s phase φobj

i,j (λ), basically ﬁxed as a
function of time (if there is no baseline smearing) but possibly varying as a
function of wavelength (for example inside an emission line, or as a function of
spatial frequency), and the OPD term 2πδ(t)
strongly varying as a function of
time. All higher-order terms (like the water vapor term) are contained within
the term o( 1

λ

λ ).

If one is able to estimate properly the OPD term, it can be subtracted from

16

σφ = 45o−1.0−0.50.51.0−1.0−0.50.51.0σφ = 90o−1.0−0.50.51.0σφ = 180o−1.0−0.50.51.0AMBER data−1.0−0.50.51.0ImImImImRe−100 0 100−100 0 100−100 0 100−100 0 100φ (o)φ (o)φ (o)φ (o)Densitythe individual phase measurements, and the remaining phase variations as a
function of wavelength can be averaged. To avoid wrapping eﬀects in presence
of noise, this procedure must be done in the complex plane, by computing a
cross-spectrum:

W noP = (cid:94)γi,j(0) × e−2ıπ δ(t)

λ

(28)

We note here that we remove only the achromatic OPD eﬀect, but as men-
tionned in page 12, other eﬀects can also aﬀect the phase. They are present
essentially as a phase oﬀset plus higher order terms. The phase oﬀset can be
removed by computing phase diﬀerences between the current wavelength (called
“work channel”) and another wavelength (called “reference channel”, bearing
many similarities to the one used for diﬀerential visibility), i.e.:

(cid:103)φdiﬀ = arg(cid:10)W noP(λwork)W noP(λref )(cid:11)

t

(29)

One can note here that equations 28 and 29 can be swapped in the process

without any issue.

The reference channel can be computed by taking one wavelength, or by av-
eraging several wavelengths. The most used method is to compute the reference
channel with all but one of the wavelengths (to avoid introducing a quadratic
bias). The diﬀerential phase can be related to the object phase according to the
following equation:

(cid:103)φobj

i,j =

Nλ − 1
Nλ

φdiﬀ

i,j +

α
λ

+ β

(30)

where Nλ is the number of wavelengths in the reference channel, and “1” is
the one wavelength in the work channel. The small multiplicative factor Nλ−1
has to be taken into account due to the deﬁnition of the reference channel, as
detailed in Millour ([2006]) page 91. Usually, this factor is negligible, as most
today spectro-interferometric instruments have 100’s of channels, but it may be
large-enough for wideband instruments to be considered. The two terms α and
β are lost in the process, but may be recovered by using the self-calibration
method (see Sect. 6.4.2).

Nλ

6

Interpreting interferometric data

What has been described in the previous sections is how to obtain interfero-
metric data, but no word has been written about how to interpret these data.
The goal of this section is to see how to compare interferometric measurements
with a model, the image reconstruction part being treated in a separated article
(Young & Thi´ebaut [2015], this book). We divide this section in two sub-
sections: qualitative interpretation of data (“ﬁrst sight” interpretation) and
quantitative interpretation, with a few examples of implementations.

17

6.1 First-sight interpretation

6.1.1 Description of observables

Interferometer data usually come as Optical Interferometry Flexible Image Trans-
port System (OIFITS) data ﬁles, which are based on the FITS format. For more
information on the OIFITS speciﬁcations, see Pauls et al. ([2004, 2005]). Most
of the time, an OIFITS ﬁle contains squared visibilities, plus optionally closure
phases and/or diﬀerential visibilities and diﬀerential phases, depending on the
instrument used.

These diﬀerent observables provide already some information on the object.
Table 2 presents some simple examples of the considerations you can make at
“ﬁrst sight”. For example, a visibility close to 1 is measured with a 130 m
baseline in the near-infrared for an object much smaller than 2 mas, i.e. smaller
than the angular resolution θres (cid:39) λ/B.

More generally,

The visibility value indicates whether the object is resolved (low visibility) or

not (visibility close to 1).

The diﬀerential visibility is a relative measurement of the object size along
wavelengths. A lower diﬀerential visibility in an emission line indicates an
emitting region larger than in the continuum.

The phase is sensitive to astrometric position of a given source. As such, it
provides both information on the asymmetry (skewness of the intensity
distribution) of the object and its photocenter (astrometry).

The closure phase gives the information whether the object is asymmetric
(skewness): a zero or π closure phase may correspond to a symmetric
object (but not in 100% of the cases), whereas a non-zero closure phase
(modulo π) indicates for sure an asymmetric object. The astrometric
position is lost in the closure phase signal.

The diﬀerential phase is sensitive to the astrometric position at one wave-
length relative to another wavelength. Therefore, astrometric shifts in
emission lines can be measured with it, or, if a large chunk of wavelength
is available, it allows one to scan phase across spatial frequencies for an
achromatic object (like a binary star for example). It contains also the
information of the closure phase wavelength-variations, the only relevant
information coming from closure phase being then its wavelength-average
value.

A few example of qualitative features seen on the above observables and

their signiﬁcation are provided in Table 2.

18

D
ﬀ

i

.

p
h
a
s
e

S

i

n
e

s
h
a
p
e

“

W

”

s
h
a
p
e

i

n

a

l
i

n
e

“
V
”

s
h
a
p
e

i

n

“
S
”

s
h
a
p
e

i

n

a

a

l
i

n
e

l
i

n
e

C
l
o
s
.

p
h
a
s
e

D
ﬀ

i

.

v
i
s
.

V
i
s
i

b

i
l
i
t
y

(cid:37)

(cid:38)

(cid:37)

(cid:38)

◦

◦

=
0

o
r

1
8
0

=
0

a
n
d

1
8
0

◦

◦

i

n

i

n

a
n

a
n

a
b
s
o
r
p
t
i
o
n

a
b
s
o
r
p
t
i
o
n

C
o
s
i

n
e

s
h
a
p
e

C
l
o
s
e

C
l
o
s
e

t
o

t
o

1

0

i

n

i

n

a
n

a
n

e
m

i
s
s
i
o
n

e
m

i
s
s
i
o
n

l
i

n
e

l
i

n
e

l
i

n
e

l
i

n
e

C
e
n
t
r
a
l

o
b
j
e
c
t

i

n

a
b
s
o
r
p
t
i
o
n

A
b
s
o
r
b
n
g

i

c
e
n
t
r
a
l

o
b
j
e
c
t

A
s
y
m
m
e
t
r
i
c

o
b
j
e
c
t

S
h
e
l
l

i

n

a
b
s
o
r
p
t
i
o
n

A
d
d

a

p
o
i
n
t

s
o
u
r
c
e

A
b
s
o
r
b
n
g

i

s
h
e
l
l

O
b
j
e
c
t

p
o
s
s
i

b
l
y

s
y
m
m
e
t
r
i
c

-

A
s
y
m
m
e
t
r
i
c

o
b
j
e
c
t

i

n

l
i

n
e

S
e
e

W

e
i
g
e
l
t

e
t

a
l
.

(
[
2
0
0
7
]
)

A
b

i

p
o
l
a
r

o
u
t
ﬂ
o
w
?

S
e
e
C
h
e
s
n
e
a
u

e
t

a
l
.

(
[
2
0
1
1
]
)

O
b
j
e
c
t

i
s

r
o
t
a
t
i
n
g
!

i

B
n
a
r
y

s
t
a
r
!

U
s
e

a

k
i

n
e
m
a
t
i
c
m
o
d
e
l

U
s
e

a

b

i

n
a
r
y
m
o
d
e
l

O
b
s
e
r
v
a
b

l
e

V
a
l

u
e

o
r

f
e
a
t
u
r
e
s

Q
u
a
l
i
t
a
t
i
v
e

i

n
f
o
r
m
a
t
i
o
n

M
o
d
e
l
-
ﬁ
t
t
i
n
g

g
u
i
d
e
l
i
n
e
s

I
l
l
u
s
t
r
a
t
i
o
n

T
a
b

l
e

2
:

Q
u
a
l
i
t
a
t
i
v
e

i

n
f
o
r
m
a
t
i
o
n
w
h

i
c
h

c
a
n

b
e

r
e
t
r
i
e
v
e
d

f
r
o
m

i

n
t
e
r
f
e
r
o
m
e
t
r
i
c

o
b
s
e
r
v
a
b
l
e
s
.

O
b
j
e
c
t

O
b
j
e
c
(cid:31)
t

i

B
n
(cid:31)
a
r
y

(cid:29)

s
t
a
r
!

(cid:28)
λ
/
B

1
.
2
2
λ
/
B

r
a
d

S
m
a
l
l
e
r

e
m

i
s
s
i
o
n

B
i
g
g
e
r

e
m

i
s
s
i
o
n

r
a
d

A
d
d

a

r
e
s
o
l
v
e
d

c
o
m
p
o
n
e
n
t

A
d
d

a
n

i

n
n
e
r

r
e
g
i
o
n
/
d
i
s
k

A
d
d

a
n

e
m

i
t
t
i

n
g

e
n
v
e
l
o
p
e

U
s
e

a

b

i

n
a
r
y
m
o
d
e
l

U
n
i
f
o
r
m
d
i
s
k

s
i
z
e

(
j
)

(
d
)

(
h
)

(
k
)

(
b
)

(
f
)

(
g
)

(
c
)

(
i
)

(
e
)

(
a
)

T
a
b
l
e

3

19

(cid:54)
M

e
i
l
l
a
n
d

e
t

a
l
.

(
[
2
0
1
1
]
)

(
i
)
C
o
s
i

n
e

s
h
a
p
e

C
h
e
s
n
e
a
u

e
t

a
l
.

(
[
2
0
1
1
]
)

M

e
i
l
l
a
n
d

e
t

a
l
.

(
[
2
0
1
1
]
)

(
j
)

“

W

”

s
h
a
p
e

(
k
)

S
i
n
e

s
h
a
p
e

D
e
m
o
r
y

e
t

a
l
.

(
[
2
0
0
9
]
)

(
e
)
U
n
r
e
s
o
l
v
e
d

s
o
u
r
c
e

M
o
n
n
i
e
r

e
t

a
l
.

(
[
2
0
0
6
]
)

K
r
a
u
s

e
t

a
l
.

(
[
2
0
0
8
]
)

M

e
i
l
l
a
n
d

e
t

a
l
.

(
[
2
0
1
2
]
)

(
f
)
N
o
n
-
z
e
r
o

(
g
)

(cid:37)

i

n

e
m

i
s
s
i
o
n

l
i
n
e

(
h
)

“
S
”

s
h
a
p
e

20

s
p
e
c
t
r
o
-
i

n
t
e
r
f
e
r
o
m
e
t
r
i
c

i

n
s
t
r
u
m
e
n
t
s
,

i
l
l

u
s
t
r
a
t
e
d

w
i
t
h

a
c
t
u
a
l

p
u
b

l
i
s
h
e
d

i

n
t
e
r
f
e
r
o
m
e
t
r
i
c

d
a
t
a
.

T
h
e

l
e
t
t
e
r
s

l
i
n
k

t
o

t
h
e

T
a
b
l
e

2
.

T
a
b

l
e

3
:

T
h
e

o
p
t
i
c
a
l

l
o
n
g
-
b
a
s
e
l
i

n
e

i

n
t
e
r
f
e
r
o
m
e
t
r
i
c

“
o
b
s
e
r
v
a
b

l
e
s

z
o
o
”
,

s
h
o
w
n
g

i

a
l
l

t
h
e

i

d
ﬀ
e
r
e
n
t

c
a
s
e
s

o
n
e

c
a
n

f
a
c
e
w
i
t
h

c
u
r
r
e
n
t

R
e
p
r
o
d
u
c
e
d
w
i
t
h

p
e
r
m

i
s
s
i
o
n

.

B
e
n

i
s
t
y

e
t

a
l
.

(
[
2
0
1
0
]
)

(
a
)
R
e
s
o
l
v
e
d

s
o
u
r
c
e

V
i
s
i

b

i
l
i
t
y

M
o
n
n
i
e
r

e
t

a
l
.

(
[
2
0
0
6
]
)

(
b
)

Z
e
r
o

C
l
o
s
u
r
e

p
h
a
s
e

(
c
)

(cid:38)

S
t
e
e

D
ﬀ

i

.

V
i
s
.

e
t

i

n

a
l
.

(
[
2
0
1
2
]
)

e
m

i
s
s
i
o
n

l
i
n
e

W

e
i
g
e
l
t

e
t

a
l
.

(
[
2
0
0
7
]
)

(
d
)

“
V
”

s
h
a
p
e

D
ﬀ

i

.

P
h
a
s
e

6.1.2 What can I do without a model?

Already a signiﬁcant amount of things! The visibility, closure phase and diﬀer-
ential phase provide already a large number of information about the geometry
of an object.

In practice, two quantitative information can be extracted from the visibili-

ties and diﬀerential phases without a model:

• Size estimate with the visibilities (if the visibility is larger than 20%),
using simple ad-hoc models (like uniform disks: Demory et al. [2009]),
Gaussian disks: Tristram et al. [2007], or even rings: Kishimoto et al.
[2011],

• Photocentre p variations with the diﬀerential phase, or spectro-astrometry,

using the simple relation φ = 2πpB/λ when an object is unresolved.

However, one needs to bear in mind that these quantitative estimates are
valid only when the object is barely resolved. For more details, please read
Lachaume ([2003]). In all other cases, on needs to use a model-ﬁtting tool like
LITpro (Tallon-Bosc et al. [2008]), fitOmatic (Millour et al. [2009]), or SIMTOI
(Kloppenborg et al. [2012])

6.2 Quantitative Interpretation: model-ﬁtting

When one has a model mi of an object, with parameters p, and wishes to
compare it with the data acquired, one needs to quantify how the model matches
the data. This match is perfect when the synthetic observables computed from
the model mi(p) are equal to the observations, described by the measurements
xi:

∀i, xi = mi(p)

(31)

However, this never happens due to the presence of noise. One way to best
match the model to the data is to compute squared diﬀerences between mi(p)
and xi, taking into account the noise σi:

(cid:88)

χ2 =

(xi − mi(p))2

i

σ2
i

(32)

Minimizing this quantity by changing the parameters values p provide a
plausible solution to the eq. 31. This minimization is made by an optimization
algorithm, and the whole process is called “model-ﬁtting”.

Speciﬁc aspects of long-baseline interferometry,

like the use of wrapped
phases (see Fig. 7), heterogeneous data noise models (Schutz et al. [2014]),
or highly non-convex χ2, need to be taken into account. This is why speciﬁc
software have been developed to cope with it. They are basically made of an
OIFITS reader combined with a simpliﬁed instrument model, and they make

21

use of diﬀerent optimizers going from simple descent algorithms up to simulated
annealing, or MCMC methods.

The whole process is described for the speciﬁc case of LITpro in Tallon-Bosc
et al. ([2008]). You can also have a look to the practice sessions in this book
using LITpro (Domiciano [2015]).

The model itself mi(p) may be a simple analytic model (“toy” model, de-
scribed in sect. 6.2.1), very fast to compute, or an image coming from a more
advanced model (described in Sect. 6.2.2).

6.2.1 Analytic models

The space distribution of light may be described by simple analytical functions,
as is the associated visibility. Due to the Zernicke & van-Cittert theorem, these
visibility functions are the Fourier transforms of the image functions. The most
common analytical functions are given in table 4 and provide already a quite
complete overview of what is used nowadays to interpret interferometric data.
All these analytical models can be added together to produce combined
models. This is feasible thanks to the linearity of the Fourier Transform, and
other properties described below:

6.2.2 Generic properties of Fourier Transform

Here I describe the generic properties of the Fourier transform, which can be
found in any book treating FT. These properties are widely used to combine or
to modify, stretch, distort, the simple analytical models provided above:
• linearity (addition): F T [f + g] = F T [f ] + F T [g],
• translation (shift): F T [f (x − x0, y − y0)] = F T [f ](u, v) × e2iπ,(ux0+vy0),
• similarity (zoom and shrink): F T [f (αx, βy)] = 1
• convolution (“blurring”): F T [f ⊗ g] = F T [f ] × F T [g],
• ∞ limit (“small” details): F T [f ]
• 0 limit (“large” details): F T [f ]

∞(cid:55)−→ 0,
0(cid:55)−→ 1.

β ),

αβ F T [f ]( u

α , v

These Fourier transform properties can also be used to combine more ad-
vanced models. This was for example the case of Millour et al. ([2009]), where
the authors combined a series of ring models to build the pseudo-3D toy-model
of a spiral nebula.

6.2.3 Advanced models

For more advanced models, which do not have a simple analytical expres-
sion, one can produce a pixellized map of the model and Fourier-transform it.
Most model-ﬁtting software allow, or are planned to allow to Fourier-transform
maps of otherwise computed models. This is for example the case of ASPRO,
fitOmatic, and will be in a near-future in the distributed version of LITpro.

22

Shape

Point source

Background

Binary star

Gaussian

Uniform disk

Ring

Exponential

Any circular
object

Pixel (image
brick)

Limb-
darkened
disk

δ((cid:126)x)

I0

I0

π

I0 [δ((cid:126)x) + Rδ((cid:126)x − (cid:126)x0)]
−4 ln 2 r2
(cid:31)2

(cid:113) 4 ln(2(cid:31))
(cid:40) 4
× e
if r < (cid:31)2
(cid:17)
(cid:16)
π(cid:31)2
r − (cid:31)2
π(cid:31) δ
e−k0r, k0 ≥ 0

otherwise

0

1

if x < l and y < L
otherwise

lL
0

I(r)

(cid:26) 1
(cid:26) I0[1 − uλ(1 − µ)]
µ = cos(2r/(cid:31))

if r < (cid:31)2



(cid:26) 1
(cid:114)

0

Visibility

1

if ρ = 0
otherwise

(cid:16) (cid:126)ρ· (cid:126)x0

(cid:17)

λ

1+R2+2R cos

1+R2

4 ln 2

e− (π(cid:31)ρ)2
2J1(π(cid:31)ρ)
π(cid:31)ρ
J0(π(cid:31)ρ)

k2
0
1+k2
0ρ2

2π(cid:82) ∞
(cid:34)
α J1(x)

0 I(r)J0(2πrρ)rdr

sin(πxl) sin(πyL)

π2xylL

√

x +β

π/2

J3/2(x)
x3/2

(cid:35)2

2 + β

3 )2

( α
α = 1 − uλ
β = ulλ
x = πθLD

B
λ

Table 4: Analytical models of diﬀerent shapes and their associated visibility

function. The following parameters are used: (cid:31) represents either the diameter

for a ring or uniform disk, or FWHM. r or (cid:126)x represent the angles in the image
plane. ρ = B

λ or (cid:126)ρ are the spatial frequencies.
Brightness distribution

with f , g analytical functions like the ones described in table 4, x, y are coor-
dinates in the image plane, u and v are spatial frequencies, and α and β are
zoom & shrink factors.

23

6.3

Image reconstruction

Image reconstruction is treated in details in Young & Thiebaut ([2015]) later in
this book. I invite the reader to take a look to that article.

6.4 The advent of diﬀerential phase

Diﬀerential phase has changed the panorama of possibles in long-baseline in-
terferometry. Millour ([2006]) presented a theoretical approach to explain the
potential of diﬀerential phase to bring new information, independent of a model,
to model-ﬁtting and image reconstruction. As this work in in French, I translate
most of the related content here to the English reader:

6.4.1 potential in model-ﬁtting

I was interested here to quantify the information brought by diﬀerential phases
in addition to the one brought by closure phases.
I took inspiration from
the demonstration of Lachaume ([2003]) and considered ﬁrst a N-point-sources
model, but resolved by the interferometer. These sources are described by
2Ns − 2 parameters for position (global centroid is unknown and all sources
coordinates are described relative to the ﬁrst one), and NλNs ﬂuxes, i.e.

Nparam = 2Ns − 2 + NλNs

(33)

No other hypothesis is done otherwise than observing several sources at many

wavelengths simultaneously. Great.

Accounting for the number of observables will help us quantify the maximum
number of sources that can be modeled Ns max. This maximum is given by
zeroing the degrees of freedom of the model-ﬁtting problem (i.e. modelling
Ns chromatic point-sources and comparing them to the interferometer data).
These degrees of freedom D are simply the diﬀerence between the number of
independent observations Nobs and the number of parameters of the model
Nparam, i.e. D = Nobs − Nparam. Zeroing it is simply writing the equation:

The users of interferometers can face four speciﬁc cases:

Nobs = Nparam

(34)

Full access to the complex visibility: This is for example the case in radio-
astronomy, or the dream of every single optical interferometrist. In this case,
one has access to Ntel(Ntel−1)
Nλ visibilities, the same number of phases, and Nλ
measured ﬂuxes (the spectrum). We therefore have:

2

Nobs = Ntel(Ntel − 1)Nλ + Nλ

Putting equations 33 and 35 into equation 34, we get:

Ns max = Ntel(Ntel − 1)

Nλ

(Nλ + 2)

+ 1

24

(35)

(36)

We see here that the maximum number of sources is roughly proportional to
the number of baselines (i.e. square the number of telescopes), but not to the
number of wavelengths. On the wavelength side, the increase of the number of
sources has an asymptotic behavior.

Visibility only: This is the case with 2-telescopes instruments like vinci,
classic, fluor or midi. In this case, one has access to Ntel(Ntel−1)
Nλ visibilities
2
and Nλ measured ﬂuxes (the spectrum). We therefore have

Nobs =

Ntel(Ntel − 1)

2

Nλ + Nλ

(37)

That number is roughly half the number of eq. 35. This is expected as we
measure only half the information on the object (no phases). Putting equations
33 and 37 into equation 34, we get:

Ns max =

Ntel(Ntel − 1)

Nλ

2

(Nλ + 2)

+ 1

(38)

Visibility and closure phase: This is still today the most common case.
In such a case, one has access to Ntel(Ntel−1)
Nλ
closure phases and still Nλ measured ﬂuxes. Therefore,

Nλ visibilities, (Ntel−1)(Ntel−2)

2

2

Nobs =

Ntel(Ntel − 1)

2

Nλ +

(Ntel − 1)(Ntel − 2)

2

Nλ + Nλ

(39)

We therefore have the following:

(Ntel − 1)2

Nλ

Ns max =

(40)
The same comments as before applies here, except that the term (Ntel − 1)2

grows faster than the term Ntel(Ntel − 1) of the previous paragraph.

(Nλ + 2)

+ 1

2

2

Nλ diﬀerential phases, (Ntel−1)(Ntel−2)

Visibility, closure phase and diﬀerential phase: This is the case of am-
ber, matisse and gravity. The observables are now Ntel(Ntel−1)
Nλ visibilities,
Ntel(Ntel−1)
Nλ closure phases and still Nλ
measured ﬂuxes. However, one has to note that closure phase and diﬀerential
phase are not independent measurements. Indeed, they are both related to the
object phase (see eq. 30 and eq. 25). Therefore, one can write the relation
between the diﬀerential phase and the closure phase using both equations:

2

2

Ψi,j,k = φdiﬀ

i,j + φdiﬀ

j,k + φdiﬀ

k,i + βi,j + βj,k + βk,i +

αi,j
λ

+

αj,k
λ

+

αk,i
λ

(41)

Nλ−1
Nλ
also note that one of the terms βi,j + αi,j

The careful reader should have seen here that I discarded the small term
, which can be neglected for a large number of spectral channels. One can
λ can be ﬁxed to zero in order to set the

25

two other oﬀsets, and therefore ﬁx the global photocenter of the object (which
remains unconstrained by closure phases and diﬀerential phases).

This equation and the above additional constrain provide us with the relevant
information: the closure phase bring only additional data on two oﬀsets βi,j
and wavelength-slopes αi,j
that are missed by diﬀerential phases. All other
λ
information (wavelength variations) are contained both in closure phase and
diﬀerential phases. Therefore, the closure phase provides (Ntel − 1)(Ntel − 2)
independent observables instead of the (Ntel−1)(Ntel−2)
Nλ accounted just before.
Therefore, we get:

2

Nobs =

Ntel(Ntel − 1)

2

Nλ + (Ntel − 1)(Ntel − 2) +

Ntel(Ntel − 1)

2

Nλ + Nλ (42)

and the maximum number of sources that can be modeled is:

Ns max =

(Ntel − 1)(NtelNλ − 2)

(Nλ + 2)

+ 1

(43)

These diﬀerent cases are illustrated in Fig. 8. We see that, typically above 20
spectral channels, the use of diﬀerential phases put us in a case almost similar
as if there was a true phase measurement for model-ﬁtting. This was the main
motivation to develop the model-ﬁtting tool fitOmatic, which can make use of
chromatic parameters.

Figure 8: Illustration of the potential of using the diﬀerential phase in model-
ﬁtting or image reconstruction for 3 nights of 4 telescopes observations (like in
the case of matisse) compared to other cases. Left: modelling Ns max point-
sources, the green dashed line using visibilities and phases, the black solid line is
using visibilities alone, the red dotted line using visibilities and closure phases,
and ﬁnally the blue dash-dotted line using visibilities, closure phases and diﬀer-
ential phases. Right: reconstructing a Np × Np pixels chromatic image. The
colours are the same.

26

 10 20 30 40 50 0 100 200NλNs max 10 20 30 0 100 200NλNp26.4.2

in image reconstruction

The wavelength-diﬀerential phase was not considered in imaging until Millour
([2006]), Schmitt et al. ([2009]) and Millour et al. ([2011]). Indeed, diﬀerential
phase provide a corrugated phase measurement (as described in eq. 30), which,
in theory, can be incorporated into a self-calibration algorithm, in a very similar
way as what is done in radio-interferometry (Pearson & Readhead [1984]).

As early as [2003], J. Monnier anticipated “revived activity [on self-calibration]
as more interferometers with imaging capability begin to produce data.” And in-
deed, the conceptual bases for using diﬀerential phases in image reconstruction
were laid in Millour ([2006]): the same reasoning as in the previous section
can be applied, except that an image is made of pixels whose positions are
pre-deﬁned. The only unknown information is therefore the spectrum of each
pixel. If Np is the image size (Np = 128 for a 128 x 128 image), the number of
unknown Nparam is equal to:

and the maximum number of pixels that can be reconstructed is:

Nparam = N 2

p Nλ

Full access to the complex visibility:

(44)

(45)

(46)

(47)

Visibility only:

Visibility and closure phase:

Np =(cid:112)Ntel(Ntel − 1) + 1

+ 1

2

Np =

Ntel(Ntel − 1)

(cid:114)
Np =(cid:112)(Ntel − 1)2 + 1
(cid:115)

Visibility, closure phase and diﬀerential phase:
(Ntel − 1)(NtelNλ − 2)

Np =

Nλ

+ 1

(48)

Fig. 8 shows the same behavior as for model-ﬁtting: typically above 20
spectral channels, the use of diﬀerential phases put us in a case almost similar
as if there was a true phase measurement, i.e. as if there was no atmosphere in
front of the interferometer, given that one is able to take proﬁt of the information
contained in the diﬀerential phase.

The Schmitt et al. ([2009]) paper was a ﬁrst attempt to use diﬀerential phases
in image reconstruction. They considered that the phase in the continuum was
equal to zero, making it possible to use the diﬀerential phase (then equal to the
phase) in the Hα emission line of the β Lyr system. They were able this way to
image the shock region between the two stars at diﬀerent orbital phases.

27

The paper Millour et al. [2011] went one step further, by using an itera-
tive process similar to radio-interferometry self-calibration (Pearson & Read-
head [1984]) in order to reconstruct the phase of the object from the closure
phases and diﬀerential phases. This way, they could reconstruct the image of
a rotating gas+dust disk around a supergiant star, whose image is asymmet-
ric even in the continuum (non-zero phase). This method was subsequently
used in a few papers to reconstruct images of supergiant stars (Ohnaka et al.
[2011, 2013]). A more recent work (Mourard et al. [2014]) extended the method
to the visibilities, in order to tackle the image reconstruction challenges posed
by visible interferometry, lacking the closure phases and a proper calibration of
spectrally-dispersed visibilities. The image-cube reconstructed with this tech-
nique in Mourard et al. ([2014]) is shown in Fig. 9.

Figure 9: Image from Mourard et al. ([2014]), showing the kinematics of the
φ Per Be star disk through the Hα emission line. The top row shows the
reconstructed images, the middle row a best-ﬁt kinematics model and the lower
row a reconstruction based on the model, for comparison. Reproduced with
permission.

Of interest are also new developments made on the core image reconstruction
algorithms to include the diﬀerential phases into the process (Schutz et al. [2014],
or Soulez et al. [2014]). These new algorithms are very promising and they must
be confronted sooner or later to real datasets.

7

Interferometry hardware

Combining telescopes which are hundreds of meters apart is a diﬃcult matter,
which needs a set of functions described below and shown in Fig. 11:

(a) Telescopes, to collect the light, mostly deﬁned by their diameter D,

(b) Set of periscopes (sometimes grouped in “switchyards”) to shape, collimate,
and feed the beam through light tunnels, deﬁned by a ﬁxed length ∆ﬁxed,

(c) Delay lines to compensate for the variable delay due to pointing the tele-
scope and the atmosphere’s eﬀects, deﬁned by a time-variable optical path

28

length ∆i(t),

(d) Combiner instrument to eﬀectively produce the interference pattern.

We will try not to repeat the numerous descriptions of how to build an

interferometer. We just describe here what makes an interferometer working:

7.1 Telescopes

Interferometry telescopes are, in principle, no diﬀerent from “regular” astro-
nomical telescopes. However they diﬀer on three aspects we will detail in the
following subsections: they must be smart, tough and large.

7.1.1 “smart”

A “smart” telescope is a reliable one. Indeed, a single telescope needs to be
operational (i.e. not undergoing technical failures or maintenance) most of its
time.

For example, if we take the ESO telescope schedule1 for the Unit Telescopes
on the vlti, the Observatory conﬁdence in their telescopes is given by the ratio
of observing nights scheduled by the available clear skies observing nights (Lom-
bardi et al. [2009]: 310 nights/years at Paranal). This is illustrated by Figure 10
where we provide the number of scheduled nights (visitor or service mode) ver-
sus the average number of clear nights at Paranal. ESO usually accounts for
reliable telescopes 89% of the clear sky time.

On the other hand, the vlti scheduling, illustrated in Figure 10 tells us that
the ESO observatory uses 50% of the available clear sky nights, after a learning
curve on the interferometer between 2003 and 2006. This is well explained if we
consider all 4 telescopes are used for interferometry. The probability of having
all 4 telescopes online in a given night is just 0.894 ≡ 63% of the available
time. The diﬀerence between the two numbers (50% and 63%) comes from the
numerous additional sub-systems needed by the vlti to operate (delay lines,
fringe tracker, instrument, etc.).

A word on the “technical” time plotted here: the cumulative time, including
technical one, exceeds the number of clear sky nights, since some technical
activities do not need the telescope open. We also note here that the vlti
technical time was not fully taken into account in the scheduling until 2008,
leaving the impression that the vlti was “idle” most of the time.

7.1.2 “tough”

A “tough” telescope is a stable one. “stable” means the telescope do not trans-
mit vibrations to the instrument. Usual instruments at the focus of telescopes
are sensitive (at ﬁrst order...) to transverse vibrations (i.e. “tip/tilt” vibra-
tions). This puts some requirements on the tip/tilt pointing and stability accu-
racy (See for example a study in Altarac et al. [2001]).

1http://archive.eso.org/wdb/wdb/eso/sched_rep_arc/form

29

Figure 10: Left: VLT scheduling taken from the ESO telescope schedule1,
including all 4 Unit Telescopes (hence # of nights multiplied by 4). Diﬀerent
colours represent diﬀerent times on the telescopes. The dashed line represent
the clear skies night, while the dotted line represent the total number of nights
over one observing period (6 months). Right: The same plot for the vlti.

Unfortunately, an interferometer is sensitive both to transverse and longi-
tudinal vibrations (a.k.a. “OPD” or “piston” vibrations). Both of the large
telescopes interferometers are subject to such vibrations as they were not de-
signed in the ﬁrst time to be used in an interferometer (Hess et al. [2003], Millour
et al. [2008]). To overcome these eﬀects, an active dampening system had to be
integrated into both facilities (Hess et al. [2003], Lizon et al. [2010], Poupar et
al. [2010], Spaleniak et al. [2010]).

On smaller telescopes facilities, vibrations have also been investigated but

this eﬀect has a much smaller amplitude (Merand et al. [2001]).

It is worth to note that the VLT instruments are themselves aﬀected by
vibrations (Sauvage, private communication), and vibrations assessment are a
part of the ELTs design.

7.1.3 “large”

“Large” telescopes means large collecting area, means more sensitive interfer-
ometer. However, one needs to bear in mind that the gain in sensitivity is true
only for a constant strehl ratio of the telescope PSF, simply because the overall
eﬀective transmission of the system, when using optical ﬁbres, is multiplied by
the strehl ratio. This is why very large telescopes interferometers (vlti & Keck)
have been equipped with adaptive optics (Arsenault et al. [2003]).

7.2 Feed through

The light is fed by a series of mirrors from the telescope to the delay lines
building. This is where a large part of the light propagation occurs in the
interferometer and where potentially several issues can happen to the beam.
Three possibilities exist today to transport the beam:

• through air (e.g. in vlti and Keck-I),

30

 2005 2010 0 200 400 600Year#Nights scheduled/period100%50%0%VisitorServiceTechnicalVLT scheduling 2005 2010 0 50 100 150Year#Nights scheduled/period100%50%0%VisitorServiceTechnicalVLTI scheduling• through vacuum (e.g. in iota, chara, npoi),
• through ﬁbers (developed for the OHANA project, Woillez et al. [2014]).

The air transportation is the simplest to setup with just tunnels and relay
optics to be installed (no bulky vacuum tubes and pumps). However, the air in-
troduces chromatic longitudinal dispersion when large delays are compensated,
which aﬀects the fringe signal and is not easy to overcome for high-precision
measurements (Tubbs et al. [2004], Vannier et al. [2006]).

Figure 11: How to combine beams from separated telescopes illustrated with
the vlti. The collected beams are ﬁrst collimated and fed into tunnels by a set
of mirrors in the telescopes, put into delay lines to compensate for the delay in-
troduced by pointing and other eﬀects (in red), then fed into the interferometric
instruments that records the data.

31

7.3 Delay lines

Delay lines are a set of movable mirrors which compensate for the optical delay
induced by the pointing of the telescope. These are supposedly simple at ﬁrst
glance but one needs to consider the required precision (less than 1µm), and
range of motion (half the largest telescope baseline, i.e.
it can be hundreds
of meters). These optical systems are in no way simple to build and operate,
as the mirrors-bearing carriage has to provide sub-micron position accuracy on
hundreds of meters with a continuous motion of a few centimetres per second...
Several technical solutions have been implemented, which all have advan-
tages and drawbacks: the delay lines can be in the air (like on vlti or Keck-I)
or in vacuum (like on iota), or partially in vacuum and partially in air (like
in chara, npoi). They can be one stage (vlti) or two stages (iota, Keck-I,
chara, npoi) with a long-stroke ﬁxed delay (easier to manufacture) and short-
stroke moving delay.

7.4 Combiner

The last element of the interferometer is the Combiner. It is basically a Michel-
son or a Fizeau interferometer plugged-in to a very sophisticated video camera
with some degree of spectral dispersion and a feedback loop to stabilise the
fringes. The fringe combination can be done in diﬀerent ways and we refer the
reader to Berger ([2015], this book) for further details.

All these sub-systems are shown in the illustration Fig. 11.

8 Optical interferometry in 2015

8.1 vlti
The vlti is the only large-aperture interferometer in operation today. With
its four 8-meter class telescopes, supplemented by four movable 2-meter class
telescopes (see Fig 11), it oﬀers versatility and sensitivity at the same time. It
saw its ﬁrst light in 2001 (Glindemann et al. [2001]) with the vinci instrument,
and has since seen its capabilities increasing: 2 recombined telescopes in 2001
(Kervella et al. [2003]), mid-infrared with midi (Leinert et al. [2003]), 3 tele-
scopes and a high spectral resolution in 2004 with amber (Petrov et al. [2007])
and 4 telescopes in 2010 with pionier (Le Bouquin et al. [2011], but lacking
a high or medium spectral resolution, and just open to the general community
since 2015). The vlti is noticeably the most productive interferometric facility
in the world (see Fig. 12). Applying for observing time is open to any profes-
sional astronomer, and its archive is public after typically one year of ownership
by the PI. The next generation instruments matisse and gravity will oﬀer
to the wide community four telescopes and, for the ﬁrst time, real imaging
capabilities.

32

Figure 12: Publications related to long-baseline interferometry per year (Data
from the JMMC http://apps.jmmc.fr/bibdb/). The dash line represent the
total number of publication whereas the colors are per facility (i.e. observations
papers only). We can see a steep increase after 2002 with the advent of vlti,
and a decrease after 2010 due to the closure of several facilities (Keck-I, IOTA,
...).

8.2 chara
chara is a six-1-meter-class telescopes interferometer, which is funded and
operated by the Georgia State University.
It has developed in the 2000s a
collaborative framework allowing teams from all over the world to install and
operate instruments on the facility. As a result, chara is the interferometer
with the most number of currently-operated instruments, with classic, climb,
mirc, pavo, vega. chara has the longest operating baselines (300 m) and
works in the visible range, making it the sharpest telescope on Earth.

8.3 npoi
npoi is a six-telescope interferometer jointly operated by the Lowell Observa-
tory and the US Navy. It consists of small apertures movables siderostats for
imaging as well as ﬁxed siderostats dedicated to astrometry. Its recent devel-
opments include a 6-telescope visible instrument vision and the commissioning
of new longer baselines.
It is currently limited by the small apertures, but
the developement plan includes the installation of meter-class telescopes in the
future.

33

ISIMark IIISUSIIOTALBTNPOIPTI, Keck−ICHARAI2T, GI2TVLTI 1980 1990 2000 2010 0 20 40 60 80Year# papers8.4 The legacy

The long-term durability of the data acquired by the interferometers make it a
goldmine for future astronomers. Therefore some observatories have made an
eﬀort to archive the obtained data and to make it public for future use. This is
e.g. the case for the ESO science archive facility2 which provides raw datasets
from all the open vlti instruments plus, more recently, data from the visitor
instrument pionier.

Since ESO provides only raw datasets, a community eﬀort is being made,
led by JMMC3, to provide a reduced database called OIDB. It will provide in a
near-future reduced datasets which have been published, in order to make them
accessible for future use.

An eﬀort has also been conducted to make the legacy Keck-I and PTI instru-
ments data avilable through the PTI & Keck Public Database4. Future users
can access freely these data and use them in a publication provided they follow
the publishing guidelines available at ESO and NExScI webpages.

9 The future: new instruments, new possibili-

ties

The vlti has been at the leading edge for optical interferometry in the last
decade. However, the two ﬁrst-generation instruments, amber and midi are
now 10 years old, and even though they have unmatched features (high spectral
resolution for amber and N band for midi), they start to show their limits.
Therefore, ESO issued a call for proposals in 2005 to build second genera-
tion instruments. Two projects were selected: gravity5, aiming at performing
micro-arcseconds astrometry on the Galactic Center in the near-infrared, and
matisse6, aiming at opening the L band in addition to bring imaging capabili-
ties to the vlti in the mid-infrared. They both come to the sky in the 5+ years
from now.

The chara array is being ﬁtted with adaptive optics to improve by a large
factor its performances, especially at short wavelengths, oﬀering new possibili-
ties of performant instrumentation in the 5+ years to come.

In the meantime, several projects have emerged to pave the way of future
facilities: a visible interferometry prospective is being conducted today (Stee et
in prep.), to make emerge a new generation instrumentation at vlti and
al.
chara in the 10+ years; a more general prospective is conducted by the Europan
Interferometry Initiative to direct future instruments in the same timeline (Pott,
private communication); the Planet Formation Imager project (Kraus et al.
[2014]) aims at imaging and characterizing an exoplanet in the 20+ coming

2available at http://archive.eso.org
3available at http://www.jmmc.fr/oidb.htm
4available at http://irsa.ipac.caltech.edu/data/NExScI_PTI_KI/
5http://www.mpe.mpg.de/ir/gravity
6https://www.matisse.oca.eu

34

years; ﬁnally several bold prototypes of completely new combination schemes
(le Coroller et al. [2015], Labeyrie et al. [2001], and see also the conclusion of
this book: Labeyrie [2015]), hypertelescopes, are being imagined, developed and
tested to gather the technologies necessary for the 40+ years to come.

Acknowledgements: The author would like to thank R. Petrov, A. Meilland
and G. Dalla Vedova for reading through this paper and for suggesting improve-
ments. Thanks also to J.-F. Sauvage for interesting discussions about technical
aspects on the VLT, and to J.-U. Pott for pushing the prospective on the future
of interferometry.

References

[1921] Michelson, A. A. & Pease, F. G. 1921, ApJ, 53, 249

[1958] Jennison, R. C. 1958, MNRAS, 118, 276

[1970] Labeyrie, A. 1970, A&A, 6, 85

[1982] Beckers, J. M. 1982, Optica Acta, 29, 361

[1984] Pearson, T. J. & Readhead, A. C. S. 1984, A&A Ann. Rev., 22, 97

[1986] Aime, C.; Borgnino, J.; Martin, F. et al. 1986, J. Opt. Soc. Am. A, 3,

1001

[1988] P´erez, J. P. 1988, Optique g´eom´etrique et ondulatoire, Masson

[1992] Shao, M. & Colavita, M. M. 1992, A&A Ann. Rev., 30, 457

[1994] Mourard, D.; Tallon-Bosc, I.; Rigal, F. et al. 1994, A&A, 288, 675

[1999] Berger, J.-P., Schanen-Duport, I., El-Sabban, S., et al. 1999, in ASP

Conf. Ser. 194, 264

[1999] Born, M., Wolf, E. 1999, Principles of optics, Cambridge University Press

[2000] Lawson, P. R. 2000, in Principles of Long Baseline Stellar Interferometry,

ed. P. R. Lawson, 325

[2001] Altarac, S., Berlioz-Arthaud, P., Thi´ebaut, E. et al. 2001, MNRAS, 322,

141

[2001] Glindemann, A., Bauvir, B., Delplancke, F., et al. 2001, The Messenger,

104, 2

[2001] Labeyrie, A. and Arnold, L. and Gillet, S. et al. 2001, SF2A, 505

[2001] Merand, A.; ten Brummelaar, T.; McAlister, H. et al. AAS, 198, 6104

35

[2002] Papoulis, A. and Pillai, S. U., 2002, Probability, Random Variables, and

Stochastic Processes, McGraw-Hill Higher Education

[2003] Arsenault, R. and Alonso, J. and Bonnet et al. 2003, The Messenger,

112, 7

[2003] Hess, M., Nance, C. E., Vause, J. W., et al. 2003, SPIE, 4837, 342

[2003] Kervella, P., Gitton, P. B., Segransan, D., et al. 2003, SPIE, 4838, 858

[2003] Lachaume, R. 2003, A&A, 400, 795

[2003] Leinert, C., Graser, U., Przygodda, F., et al. 2003, ApSS, 286, 73

[2003] Monnier, J. D., Reports on Progress in Physics, 66, 789

[2003a] Perrin, G. 2003a, A&A, 398, 385

[2003b] Perrin, G. 2003b, A&A, 400, 1173

[2004] Millour, F., Tatulli, E., Chelli, A. E., et al. 2004, SPIE, 5491, 1222

[2004] Pauls, T. A., Young, J. S., Cotton, W. D., & Monnier, J. D. 2004, SPIE,

5491, 1231

[2004] Tubbs, R. N., Meisner, J. A., Bakker, E. J., & Albrecht, S. 2004, SPIE,

5491, 588

[2005] Pauls, T. A., Young, J. S., Cotton, W. D., & Monnier, J. D. 2005,

Publications of the ASP, 117, 1255

[2006] Lopez, B., Wolf, S. Lagarde, S. et al. 2006, SPIE, 6268, 31

[2006] Millour, F.; Vannier, M.; Petrov et al. 2006, EAS Publications Series, 22,

379

[2006] Millour, F. 2006, Interf´erom´etrie diﬀ´erentielle avec AMBER, PhD thesis,

Univ. Joseph Fourier

[2006] Monnet, G. & Gilmozzi, R. 2006, in IAU Symposium, Vol. 232, The

Scientiﬁc Requirements for Extremely Large Telescopes, 429

[2006] Monnier, J. D. and Berger, J.-P. and Millan-Gabet, R. et al. 2006, ApJ,

647, 444

[2006] Vannier, M., Petrov, R. G., Lopez, B., & Millour, F. 2006, MNRAS, 367,

825

[2007] Petrov, R. G., Malbet, F., Weigelt, G., et al. 2007, A&A, 464, 1

[2007] Segransan, F. 2007, New Astronomy Review, 51, 597

[2007] Tatulli, E., Millour, F., Chelli, A., et al. 2007, A&A, 464, 29

36

[2007] Tristram, K. R. W.; Meisenheimer, K.; Jaﬀe, W. et al. 2007, A&A, 474,

837

[2007] Weigelt, G. and Kraus, S. and Driebe, T. et al. 2007, A&A, 464, 87

[2008] K¨ohler, R. and Jaﬀe, W., 2008 Power of Optical/IR Interferometry conf.

569

[2008] Kraus, S. and Hofmann, K.-H. and Benisty et al. 2008, A&A, 489, 1157

[2008] Millour, F. 2008, New Astronomy Review, 52, 177

[2008] Millour, F., Petrov, R., Malbet, F., et al. 2008, in 2007 ESO Instrument

Calibration Workshop, 461

[2008] Tallon-Bosc, I.; Tallon, M.; Thibaut, E. et al. 2008, SPIE, 7013

[2009] Chelli, A., Duvert, G., Malbet, F., & Kern, P. 2009, A&A, 498, 321

[2009] Demory, B. O., S´egransan, D., Forveille, T. 2009, A&A, 505, 205

[2009] Haubois, X., Perrin, G., Lacour, S., et al. 2009, A&A, 508, 923

[2009] Lombardi, G., Zitelli, V., & Ortolani, S. 2009, MNRAS, 399, 783

[2009] Millour, F.; Chesneau, O.; Borges Fernandes et al. 2009, A&A507, 317

[2009] Millour, F.; Driebe, T.; Chesneau, O. et al. 2009, A&A, 506, L49

[2009] Mourard, D.; Clausse, J. M.; Marcotto et al., 2009, A&A, 508, 1073

[2009] Schmitt, H. R., Pauls, T. A., Tycner, C., et al. 2009, ApJ, 691, 984

[2010] Benisty, M. and Natta, A. and Isella et al. 2010, A&A, 511, A74

[2010] Jankov, S. 2010, Serbian Astronomical Journal, 181, 1

[2010] Lizon, J. L., Jakob, G., de Marneﬀe, B., & Preumont, A. 2010, SPIE,

7739

[2010] Poupar, S., Haguenauer, P., Merand, A., et al. 2010, SPIE, 7734

[2010] Spaleniak, I., Giessler, F., Geiss, R., et al. 2010, SPIE, 7734

[2011] Chesneau, O., Meilland, A., Banerjee, D. P. K., et al. 2011, A&A, 534,

L11

[2011] Glindemann, A. 2011, Principles of Stellar Interferometry

[2011] Kishimoto, M.; H¨onig, S. F.; Antonucci, R. et al. 2011, A&A, 527, 121

[2011] Le Bouquin, J.-B., Berger, J.-P., Lazareﬀ, B., et al. 2011, A&A, 535, A67

[2011] Meilland, A. and Delaa, O. and Stee, P. et al. 2011, A&A, 532, A80

37

[2011] Millour, F., Meilland, A., Chesneau, O., et al. 2011, A&A, 526, A107

[2011] Mourard, D., B´erio, P., Perraut, K., et al. 2011, A&A, 531, A110

[2011] Ohnaka, K., Weigelt, G., Millour, F., et al. 2011, A&A, 529, A163

[2012] Stee, P. and Delaa, O. and Monnier, J. D. et al. 2012, A&A, 545, A59

[2012] Lazareﬀ, B., Le Bouquin, J.-B., & Berger, J.-P. 2012, A&A, 543, A31

[2012] Meilland, A. and Millour, F. and Kanaan, S. et al. 2012, A&A, 538, A110

[2012] Kloppenborg, B.; Baron, F. 2012, SIMTOI: SImulation and Model-
ing Tool for Optical Interferometry. Available from https://github.com/
bkloppenborg/simtoi

[2013] Ohnaka, K., Hofmann, K.-H., Schertl, D., et al. 2013, A&A, 555, A24

[2014] Defr`ere, D., Absil, O., Hanot, C., et al. 2014, in Improving the Perfor-

mances of Current Optical Interferometers & Future Designs, 87

[2014] Kraus, S. and Monnier, J. and Harries, T. et al. 2014, SPIE, 9146, 120

[2014] Mourard, D., Monnier, J. D., Meilland, A., et al. 2015, A&A, 577,51

[2014] Schutz, A.; Ferrari, A.; Mary et al. ArXiv e-prints, 2014

[2014] Schutz, A.; Vannier, M.; Mary, D. et al. 2014, A&A, 565, A88

[2014] Soulez, F. and Thi´ebaut, ´E. 2014, in Improving the Performances of

Current Optical Interferometers & Future Designs 255

[2014] Woillez, J., Perrin, G., Lai, O., et al. 2014, in Improving the Performances

of Current Optical Interferometers & Future Designs, 175

[2015] Berger, J.-P. 2015, this book

[2015] Domiciano, A., 2015, this book

[2015] Labeyrie, A. 2015, this book

[2015] Le Coroller, H. and Dejonghe, J. and Hespeels, F. et al. 2015, A&A, 573,

A117

[2015] Lena, P. 2015, Some historical insights on optical interferometry, this

book.

[2015] ten Brummelaar, T. 2015, CLASSIC/CLIMB Theory, this book.

[2015] Young, J. and Thi´ebaut, E. 2015, this book

38

