6
1
0
2

 
r
a

M
9

 

 
 
]

.

C
N
o
i
b
-
q
[
 
 

1
v
6
1
9
2
0

.

3
0
6
1
:
v
i
X
r
a

ANALYSIS OF NEURONAL SEQUENCES USING PAIRWISE BIASES

by

Zachary J. Roth

A DISSERTATION

Presented to the Faculty of

The Graduate College at the University of Nebraska

In Partial Fulﬁlment of Requirements

For the Degree of Doctor of Philosophy

Major: Mathematics

Under the Supervision of Professor Vladimir Itskov

Lincoln, Nebraska

December, 2015

ANALYSIS OF NEURONAL SEQUENCES USING PAIRWISE BIASES

Zachary J. Roth, Ph.D.

University of Nebraska, 2015

Advisor: Vladimir Itskov

Sequences of neuronal activation have long been implicated in a variety of brain func-

tions. In particular, these sequences have been tied to memory formation and spatial

navigation in the hippocampus, a region of mammalian brains. Traditionally, neu-

ronal sequences have been interpreted as noisy manifestations of neuronal templates

(i.e., orderings), ignoring much richer structure contained in the sequences. This pa-

per introduces a new tool for understanding neuronal sequences: the bias matrix.

The bias matrix captures the probabilistic tendency of each neuron to ﬁre before or

after each other neuron. Despite considering only pairs of neurons, the bias matrix

captures the best total ordering of neurons for a sequence (Proposition 3.3) and, thus,

generalizes the concept of a neuronal template.

We establish basic mathematical properties of bias matrices, in particular describ-

ing the fundamental polytope in which all biases reside (Theorem 3.25). We show

how the underlying simple digraph of a bias matrix, which we term the bias network,

serves as a combinatorial generalization of neuronal templates. Surprisingly, every

simple digraph is realizable as the bias network of some sequence (Theorem 3.34).

The bias-matrix representation leads us to a natural method for sequence correlation,

which then leads to a probabilistic framework for determining the similarity of one

set of sequences to another. Using data from rat hippocampus, we describe events

of interest and also sequence-detection techniques. Finally, the bias matrix and the

similarity measure are applied to this real-world data using code developed by us.

ii

COPYRIGHT

© 2015, Zachary J. Roth

DEDICATION

iii

To my family, thank you. My mother and father both worked hard and without

complaint in raising me despite not receiving anything in return, and they each strived

to live well as examples for me. Mom, much of my personality and humor stems from

you; that has been key to so much of what I have done and how I have lived. Dad,

I ﬁnd more and more that I share many natural similarities to you; and I ﬁnd more

and more that this is a good thing. Justin, whether you know it or not, you are much

of the reason that I ever cared about doing well in school. Though I know you would

contest it, I am convinced to this day that you are far more intelligent than I. Micah,

Noah, and Samuel, you inﬂuenced me less in these developmental ways since you’re

younger than I; but you deserve recognition for putting up with me all these years.

Rachel, that you are choosing to become part of my family is astounding to me. I

look forward to our life together.

ACKNOWLEDGMENTS

iv

As with any accomplishment, there are many to be acknowledged for their contri-

butions (more or less directly) to this work.

I would be remiss if I did not ﬁrst

acknowledge God (1) for providing me with any abilities I do have and (2) for ﬁlling

in the gaps with support from friends, family, and advisors. His grace and generosity

to me are unfathomable.

During my somewhat extended tenure as a graduate student, many people served

as advisors to me. Judy Walker provided me with much encouragement, direction,

and patience as my ﬁrst advisor. Her support during the early years of my graduate

school experience was invaluable, and the time that we spent laughing during meet-

ings helped to make the experience enjoyable. I am also grateful to Vladimir Itskov

and Carina Curto who took something of a risk in allowing me to work with them

later on. Vladimir taught me that I need to be willing to ﬁght for any worthwhile

idea or approach, and Carina kept me encouraged as I fought some of these ﬁghts.

Vladimir pushed me to try to keep up as he leaped ahead in his thoughts, and Carina

demonstrated that even complex ideas can be crafted and organized in such a way as

to make them seem straightforward. Lastly, in inviting me to visit Janelia Research

Campus, Eva Pastalkova assumed the role of an advisor of sorts. Although Eva never

served as a mathematics advisor, she spent much time advising me as I found myself

ﬂoundering to stay aﬂoat in the foreign world of neuroscience. It was encouraging to

work with such a principled scientist as I found myself questioning so much of what

science seems to have become, and it was good to share with Eva in conversations of

deeper importance than science.

In addition to Vladimir, Carina, and Judy, I would also like to explicitly thank the

remainder of my supervisory committee: Jamie Radcliﬀe and Khalid Sayood. Jamie

v

unhesitatingly agreed to serve as a reader on this committee at the last minute, and

he did this despite having had to read my combinatorics "proofs" during my ﬁrst

semester of graduate school. Khalid always oﬀered a much-appreciated perspective

on work and life. Though not part of my committee, the math department staﬀ made

my life easier during this time. Marilyn Johnson and Liz Youroukos, in particular,

helped me with various things throughout the course of graduate school; and each

slipped me lots of, uh, brain food to help me along.

Those who have known me beyond the walls of academia during graduate school

have also contributed much toward this accomplishment. During this time, these

friendships have kept me sane and grounded. It is, perhaps, unreasonable to try to

mention all of the people who have aided me with their friendship over these years;

but that will not stop me from trying.

To those who started school with me in the Fall of 2007, I appreciated our time

together learning of analysis, algebra, combinatorics, and the such; and, yes, I even

appreciated your jabs at me for being mostly indistinguishable from Orlando Bloom.

To my many oﬃcemates throughout the years, I appreciated our time together and the

many conversations that you each allowed me to thrust upon you while I was avoiding

real work. I wouldn’t have expected my life in a math department to contain so many

thoughtful conversations about theology.

Mark DeBoer, moving to Lincoln was easier because I knew we would be liv-

ing together at ﬁrst; I appreciated our years living together. David Lessor and Joe

LaChance, eating pizza, playing Halo, and climbing with you guys kept me feeling

mostly normal as I fell deeper into the world of math. Mike Janssen and Tanner

Auch, it’s somewhat shocking how much time you were willing to spend with me

outside of the time spent together in both school and church; shared meals, board

games, King of the Hill, and vidya games with you were staples of my time in Lincoln.

vi

Laura Janssen and Amy Auch, you facilitated this time together and became great

friends in the process. Mike Callen, thank you for opening up your house to me while

I was still mostly a stranger; no other close friendship of mine has ever formed quite

so quickly as ours.

My time in Lincoln was truly special in that my school and church communities

overlapped heavily. To my Grace Chapel community, thank you for all of your gen-

erosity. During these years in Lincoln, my close friends the Janssens, Auchs, and

Rawsons probably fed me more than I fed myself. The opportunity to share in life

with the same people in school, in church, and beyond was a blessing that I didn’t

fully appreciate at the time. Grace Fellowship Church, you made being in State

College during my last year of graduate school not just bearable but worthwhile.

So many other people should be mentioned for some reason or another: Ben

Nolting, Brian Kloppenborg, David and Jenny Rawson, Doug Dailey, Warren Wright,

Jon Walker, David Beevers, Brian and Gretchen Bredemeier, Yingxue Wang, and

Brian Lustig, to name a few. To those I have not mentioned, I appreciated our

friendships, too. From others in my joint math/church community to landlords to

friendships continued from times past and to many others, thank you.

Contents

1 Sequential information in the brain

1.1 Phenomenology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.2 Neuronal sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.3 Summary of thesis

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

2 Characterizations of sequences

2.1 A combinatorial characterization . . . . . . . . . . . . . . . . . . . .

2.2 Center-of-mass sequences . . . . . . . . . . . . . . . . . . . . . . . . .

2.3 Pairwise biases

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.4 Higher-order biases . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Bias Matrices

3.1 Relationship to center-of-mass vectors . . . . . . . . . . . . . . . . . .

3.2 Permutations of sequences . . . . . . . . . . . . . . . . . . . . . . . .

3.3 The fundamental polytope . . . . . . . . . . . . . . . . . . . . . . . .

3.4 The bias network of a sequence . . . . . . . . . . . . . . . . . . . . .

4 Comparing sequences

4.1 Correlation between sequences . . . . . . . . . . . . . . . . . . . . . .

4.2 Signiﬁcance of correlation . . . . . . . . . . . . . . . . . . . . . . . .

vii

1
1

4

6

7
7

10

11

17

22
24

28

32

45

51
51

54

4.3 Global signiﬁcance

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.4 Monte-Carlo computation of signiﬁcance . . . . . . . . . . . . . . . .

5 Experimental set-up and data analysis
5.1 The experimental setup and event types

. . . . . . . . . . . . . . . .

5.2 SWR detection and reﬁnement . . . . . . . . . . . . . . . . . . . . . .

5.3 Sequence comparison in in-vivo hippocampus

. . . . . . . . . . . . .

A Data analysis codebase

B Supplementary ﬁgures

Bibliography

viii

56

58

60
60

63

68

74

75

79

1

Chapter 1

Sequential information in the brain

1.1 Phenomenology

The inner workings of the brain are still poorly understood. Study it though we may,

the deep truths of its inner workings—the ways that it both processes and stores

information—elude us. Even in organisms far simpler than humans, this problem

remains. In 1986, White et al. [1] revealed the the entire connectome—the neurons

and their synaptic connections—for the hermaphroditic roundworm C. elegans. Yet

with this map of all 302 neurons and around 7000 connections, we still do not fully

understand how the brains of C. elegans work. Comparing this to the estimated 86

billion neurons in the average adult human nervous system [2], the task of under-

standing our own brains is daunting to say the least. As such, it is not surprising

that the body of literature describing and modeling the observed phenomena of the

brain keeps growing. Here, we develop tools for use in the analysis of neuronal data

that accompanies these phenomena. Though our tools are of general purpose, we

focus on speciﬁc phenomena observed in a particular area of the mammalian brain:

the hippocampus.

2

Figure 1.1: Place ﬁelds and neuronal spiking. The animal here has four place cells
(not pictured) each with a preference for spiking while the animal is at a particular
location within a straight track. The four place ﬁelds are shown as colored regions
on the track (bottom). The traversal of such a track results in the generation of a
neuronal sequence (top) called a place-ﬁeld sequence, which reﬂects the direction of
traversal through the track.

The hippocampus is widely believed to aid in two main functions: episodic memory

and spatial navigation. Episodic memories are, broadly speaking, memories that are

associated with events in one’s life (times, places, emotions, etc.); this type of memory

is in contrast with other types of memory such as semantic memory (knowledge of

facts) and implicit memory (e.g., how to ride a bike). Evidence for the participation

of the hippocampus in the formation of new episodic memories was ﬁrst reported in

[3] in 1957. A man referred to as Patient HM underwent a surgery to remove large

portions of his hippocampal formation in an attempt to be cured of severe epileptic

seizures. Although the surgery was successful in regards to reducing the frequency

and severity of the seizures, there was an unexpected side eﬀect: Patient HM no longer

seemed to be capable of forming new memories about his experiences. Research on

Patient HM and his condition continued until his death in 2008.

The clearest evidence of the participation of the hippocampus in spatial navigation

is the existence of place cells, ﬁrst observed in 1971 in [4]. These neurons have a

preference for spiking when the animal is occupying a certain location in space, as

Spike LocationNeuron12343

illustrated in Figure 1.1. The spatial area in which a place cell has a tendency to spike

is called its place ﬁeld. Traversal of a series of place ﬁelds results in the generation

of a neuronal sequence called a place-ﬁeld sequence, such as pictured in Figure 1.1.

It is believed (e.g., [5], [6], [7]) that generation of place-ﬁeld sequences is intimately

related to, and perhaps dependent upon, a hippocampal oscillation of the local-ﬁeld

potential (LFP) called the theta oscillation, which exists whenever an animal is in

locomotion.

A hippocampal event called a sharp-wave ripple (SWR) has also been tied to the

formation of new episodic memories. Such an event is illustrated in Figure 1.2. As

pictured in this ﬁgure, a SWR is characterized by two main features: (1) a sharp wave,

which is a separation in the local-ﬁeld potential (LFP) across the pyramidal layer

of the hippocampus, and (2) a burst in neuronal activity, often observed as a high-

frequency ripple in the LFP within the pyramidal layer. When SWRs were selectively

eliminated from neural activity during post-training memory-consolidation periods in

[8], animals exhibited reduced performance in spatial memory tasks, indicating that

SWRs are necessary for the consolidation of episodic memories.

4

Figure 1.2: A sharp-wave ripple in the hippocampus. On the left, we see an image
of a rat hippocampus with a probe across the pyramidal layer of the CA1 region of
the hippocampus. In the upper-right section of this ﬁgure, we see a real example of
local-ﬁeld potentials from above and below the pyramidal layer. This separation of
the local-ﬁeld potential is called a sharp wave. Below the sharp wave, the increase in
spiking that accompanies the SWR is showin in a spike raster plot.

1.2 Neuronal sequences

Given that neuronal sequences are important for storage and processing of information

in the brain, it is crucial that we possess a reasonable model of sequences. Similarities

between place-ﬁeld sequences and SWR sequences [9] give reason to believe that

properties such as sequence duration and total number of spikes (and even the precise

timing of spikes) are perhaps less important (or, rather, manifestations of) some

other properties that are less immediately obvious when considering and comparing

sequences. An appropriate sequence model should ideally capture these intrinsic

qualities and, in so doing, address the fundamental question of what a sequence

actually is.

With clean illustrations such as that given in Figure 1.1, the concept of sequence

seems simple: A sequence is intuitively, more or less, just an ordering of neurons.

Though other characteristics stand out, the fact that there seems to be a clear ordering

50 msNeuron #Time (ms)5

(a) SWR

(b) Place-ﬁeld

Figure 1.3: Sequences from rat hippocampus. The SWR sequence in panel (a) and
the place-ﬁeld sequence in panel (b) are very diﬀerent from each other in many ways
including duration and number of spikes. Still, these sequences share a similar trend
in the general order in which neurons seem to spike.

is a large part of what makes a sequence seem to be structured to us. This intuition,

however, breaks down as we start to look noisy, real-world data such as that in

Figure 1.3. How do the two sequences in this ﬁgure compare to each other? These

sequences appear to the eye to have similar trends in their neuronal ﬁring patterns.

How can we characterize and quantify this relationship? This example immediately

reveals that our intuitive notion of a sequence is not broad enough to encapsulate the

sequences observed in real data. The situation becomes even hairier when we think

about asking a computer to tell us which sequences are similar.

In the literature that deals with neuronal sequences, oversimipliﬁed mathematical

models have arisen to describe the concept of a sequence. These models have served

a purpose and pushed the ﬁeld forward, but they are limited in their representation

of such a broad class of events. Chapter 2 introduces a generalized model that more

robustly represents these sequences.

050Neuron #Time (ms)15000Time (ms)Neuron #6

1.3 Summary of thesis

In the ﬁrst half of this thesis (Chapters 2–3), we introduce a novel tool for char-

acterizing and comparing neuronal sequences: the bias matrix. Chapter 2 provides

characterizations of neuronal sequences, including the introduction of the bias matrix

(Section 2.3). In Chapter 3, we investigate mathematical properties of bias matri-

ces, including a description of their relationship to the previously used center-of-mass

representation (Section 3.1), a proof that all bias matrices lie in the fundamental

polytope (Theorem 3.25 in Section 3.3), and a proof that the adjacency matrix of any

simple digraph can be realized as the sign matrix of some bias matrix (Theorem 3.34

in Section 3.4).

The second part of this thesis (Chapters 4–5) describes how we use these tools to

analyze neuronal sequences from the hippocampus of rats. Chapter 4 uses the bias

matrix to introduce a statistical tool for detecting non-random correlations among

sequences of neuronal activation. Chapter 5 introduces the experiment in which the

data was recorded and describes the various types of sequences that are of interest.

In Section 5.3, the techniques developed in Chapter 4 are used to investigate the

similarities between the aforementioned sequence types. Appendix A serves as a

README ﬁle for the code base that was developed for these analyses. Most of the

code used for this analysis was written from scratch for this analysis.

7

Chapter 2

Characterizations of sequences

As discussed in Section 1.2, representation of neuronal sequences as orderings of

neurons is appealing because it makes sequences easy to describe and easy to interpret;

but it falls short in that (1) it does not capture the complex relationships that exist

between neurons, especially as observed in noisy data, and (2) it has no simple,

realistic biological interpretation. In this chapter, we describe a new representation

of sequences that addresses these issues and, as we will see in Chapter 3, generalizes

the concept of a neuronal ordering.

2.1 A combinatorial characterization

Throughout the remainder of this document, we denote the collection of neurons by
N := [n], where n ∈ N. The raw form of a sequence with which we start is called a
spike train:

Deﬁnition 2.1. A spike train is a set of pairs of ﬁring times and neurons, that is, a
set of the form {(t, i) | t ∈ R, i ∈ N}.

8

Figure 2.1: Spike raster plot. To get a sequence from a spike train pictured as
a spike-raster plot (as shown here), we simply list the neuron for each spike in
order of occurrence (left to right). Hence, the corresponding sequence is s =
(1, 2, 4, 4, 4, 4, 3, 3, 1, 3, 1, 1, 2, 4) = 12444433131124.

We have already seen graphical examples of spike trains in Figures 1.2 and 1.3 in

the form of spike raster plots. As seen in the real-world sequences introduced in Chap-

ter 1, neuronal sequences occur on various timescales; but their sequential nature is

independent of the timescales on which they occur. As such, an appropriate sequence

representation will be timescale invariant while still maintaining complex relationships

between the spikes of neurons. Although spike trains maintain complex relationships

between the spikes of neurons, this representation is not timescale-invariant since

each spike has an associated time. If we instead discard this time information and

maintain only the order in which spikes occur, the resultant representation will be

timescale-invariant and also represent complex inter-spike relationships. This brings

us to our formal deﬁnition of a sequence.

Deﬁnition 2.2. A sequence is a ﬁnite list of neurons.

If s = (s1, s2, . . . , s(cid:96)) is a sequence, we will often write s as s = s1s2 ··· s(cid:96). Given
a spike train T = {(t1, i1), . . . , (t(cid:96), i(cid:96))} with t1 ≤ ··· ≤ t(cid:96) and ik < ik+1 if tk = tk+1,
the corresponding sequence is (i1, . . . , i(cid:96)). An example of this process is illustrated in
Figure 2.1.

The set of all sequences on the neuron set N is represented by S(N ) or, if N
is understood, by S. Table 2.1 contains some terminology and notation for working
with a sequence s = (s1, . . . , s(cid:96)) and a neuron i.

TimeNeuron #Table 2.1: The terminology of sequences

9

Notation Terminology
a spike of s
i spikes in s
length of s
support of s
spike set of i
spike count of i number of times that i spikes
ﬁring rate of i

Meaning
an entry of a sequence s
i = sk for some k ∈ [(cid:96)]
the number of spikes in s
collection of neurons that spike in s
collection of indices where i spikes
proportion of spikes that are equal to i

len(s)
supp(s)
Li(s)
ci(s)
ρi(s)

Example 2.3. With s from the previous example, we see that neuron 1 spikes four
times and has spike set L1(s) = {1, 9, 11, 12}; hence, the spike count of 1 in s is
c1(s) = 4. Similarly, c2(s) = 2, c3(s) = 3, c4(s) = 5, and ci(s) = 0 for any other
neuron i ∈ N . Since len(s) = 14, the ﬁring rate of each neuron in s is ρ1(s) = 4
,
ρ2(s) = 2
14

, and ρ4(s) = 5

14

, ρ3(s) = 3

14

.

14

Deﬁnition 2.4. Given a sequence s = (s1, . . . , s(cid:96)) and an index set K = {k1, . . . , k(cid:96)(cid:48)} ⊆
[(cid:96)] with k1 < ··· < k(cid:96)(cid:48), we deﬁne the subsequence of s corresponding to K to be
sK := (sk1, . . . , sk(cid:96)(cid:48) ). We say that a sequence s(cid:48) is a subsequence of s if s(cid:48) = sK for
some index set K ⊆ [(cid:96)].

Example 2.5. Let s = (1, 2, 4, 4, 4, 4, 3, 3, 1, 3, 1, 1, 2, 4) be the sequence from Fig-
ure 2.1, and let K1 = [6] and K2 = {1, 2, 9, 11, 12, 13}. Then the subsequences of
s corresponding to K1 and K2 are sK1 = (1, 2, 4, 4, 4, 4) and sK2 = (1, 2, 1, 1, 1, 2),
respectively.

The following operations will be useful in our discussion of sequences.

Deﬁnition 2.6. Given any two sequences u = (u1, . . . , u(cid:96)) and v = (v1, . . . , vm), de-
ﬁne the concatenation of u with v to be the sequence u·v = uv = (u1, . . . , u(cid:96), v1, . . . , vm).

Notation 2.7. For any neuron i ∈ N and any positive integer m ∈ N, let im denote
the sequence (s1, . . . , sm) with sk = i for all k ∈ [m].

10

2.2 Center-of-mass sequences

A sequence can induce an ordering by many means. One sandard way of performing

this reduction is by considering the average location in which a neuron ﬁres.

Deﬁnition 2.8. For each neuron i ∈ N and sequence s = (s1, . . . , s(cid:96)), we deﬁne the
(unnormalized) center of mass of neuron i in sequence s to be

(cid:80)

 1

ci(s)

centeri(s) :=

k∈Li(s) k,

ci(s) > 0;

len(s)+1

2

,

ci(s) = 0.

Note that centeri(s) ∈ [1, len(s)] for all i ∈ N . Moreover, when a neuron does not
ﬁre in a sequence, the corresponding center-of-mass value is chosen so that it falls in
the middle of the range [1, (cid:96)]. Thus, centeri(s) reduces all spikes from neuron i in
sequence s to a single value; but this value is dependent on the length of s. To allow
for comparison of sequences of diﬀerent lengths, we shift and normalize centeri(s) so
that the resultant value lies in the interval (−1, 1) regardless of the length of s:

Deﬁnition 2.9. For each neuron i ∈ N and sequence s = (s1, . . . , s(cid:96)), we deﬁne the
(normalized) center of mass of neuron i in sequence s to be

γi(s) :=

2 centeri(s) − 1

len(s)

− 1.

Note that with this deﬁnition, neurons that do not ﬁre in the sequence have
γi(s) = 0. If the sequence consists of just one spike, then the corresponding neuron
has centeri(s) = 1 and hence γi(s) = 0. On the other hand, if a neuron ﬁres only once
in the sequence and this corresponds to the ﬁrst or last spike, then γi(s) = −1 + 1
or γi(s) = 1 − 1
, respectively, so that the endpoints of the [−1, 1] range are only

len(s)

len(s)

11

attained in the limit as len(s) → ∞. These centers of mass can now be used to induce
an ordering on the underlying neurons.

Deﬁnition 2.10. We deﬁne the center-of-mass ordering of s to be σ(s) := (i1, . . . , in)
where {i1, . . . , in} = [n] are such that γi1(s) ≤ ··· ≤ γin(s) and, in the case that
γik(s) = γik+1(s), such that ik < ik+1.

Example 2.11. Let s = 12444433131124. Then, as we saw in Example 2.3, L1(s) =
{1, 9, 11, 12} and c1(s) = 4. Now, center1(s) = 1
and γ1(s) =
2(33/4)−1
5 ) and γ(s) =
70). Further, γ4(s) < γ2(s) < γ1(s) < γ3(s) and, hence, σ(s) = (4, 2, 1, 3).

14 − 1 = 3
( 3
28, 0, 5

. Similarly, we ﬁnd that center(s) = ( 33

42,− 11

4 , 15

2 , 25

3 , 32

28

(cid:80) L1(s) = 33

4

c1(s)

It is worth mentioning that when the concept of centers of mass is used in the

literature, the starting point is usually spike trains, not our concept of a neuronal

sequence. When starting with spike trains, the spike times of a neuron are aver-

aged instead of its indices in the sequence; these average ﬁring times then induce an

ordering in the same way that the centers of mass do.

2.3 Pairwise biases

If each neuron active in a sequence spikes only once, then the sequence itself is an

ordering of its active neurons. In such a case, the center-of-mass ordering equals the

original sequence. A broader class of sequences induce an ordering in a similarly un-

ambiguous way. For instance, in the sequence 3311222, every spike of neuron 3 comes
before every spike of neuron 1; further, every spike of neuron 1 occurs before every
spike of neuron 2. Hence, 3311222 induces the unambiguous order 312. Although
this ordering can be computed with centers of mass, the ordering is also immediately

12

obvious upon inspection of the sequence since all of the spikes from each neuron are

grouped together. We give a name to sequences such as this.

Deﬁnition 2.12. Disjoint sets I, J ⊆ N are interlaced if there exist i, i(cid:48) ∈ I and
j, j(cid:48) ∈ J such that i < j and i(cid:48) > j(cid:48).

Deﬁnition 2.13. A sequence s is pure if the spike sets of the active neurons are not
interlaced.

In a pure sequence, all of the spikes from one neuron must follow (or precede) all

of the spikes from any other neuron. In particular, the indices of the spikes of each

individual neuron form a contiguous set of natural numbers. To get a sequence that

is not pure from one that is pure, we could transpose adjacent spikes from diﬀerent

neurons. For example, the pure sequence 111122223333 can be transformed into the
impure sequence 111212223333 by transposing the fourth and ﬁfth spikes in the pure
sequence. In a sense, this new sequence is minimally impure: The spikes from neuron

3 are still contiguous, and only one pair of spikes from neurons 1 and 2 are "out
of order." This perspective suggests that the purity of a sequence (1) is somehow

related to the pairwise relationships between the spikes of diﬀerent neurons and (2)

is dependent on the collection of all such pairs of neurons. In other words, the purity

of a sequence depends on the bias of each pair of neurons to ﬁre in a particular order.

We begin to quantify these biases with the bias-count matrix below.

Deﬁnition 2.14. The bias-count matrix of the sequence s is the matrix C(s) :=
[cij(s)]i,j∈N where cij(s) := |Lij(s)| and Lij(s) := {(k, k(cid:48)) | k < k(cid:48), sk = i, and sk(cid:48) = j}.
In words, cij(s) is the number of length-2 subsequences of s that are equal to (i, j).

Example 2.15. Consider the sequence s = (1, 2, 4, 4, 4, 4, 3, 3, 1, 3, 1, 1, 2, 4) from Fig-

ure 2.1. Note that L1(s) = {1, 9, 11, 12} and L2(s) = {2, 13}. Hence, we see that

13

L12(s) = {(1, 2), (1, 13), (9, 13), (11, 13), (12, 13)}

and

L21(s) = {(2, 9), (2, 11), (2, 12)} ;

so c12(s) = |L12(s)| = 5 and c21(s) = |L21(s)| = 3. In a similar way for the other
entries cij(s), we ﬁnd that the bias-count matrix for s is

 6

5
1
3

4
3
3

8
6
3
8
3
12 4 12 10

 .

C(s) =

A few simple facts about the bias-count matrix are immediate. First, since the

deﬁnition of the bias-count matrix arose out of a discussion of pure sequences, it

is worth noting that the bias-count matrix completely captures whether or not a

sequence is pure.

diagonal entries, with equality if and only if s is pure.

Lemma 2.16. A sequence s with supp(s) = N has at least (cid:0)|N|
Proof. Any C(s) must obviously have at least(cid:0)|N|
each of the(cid:0)|N|

(cid:1) non-zero, oﬀ-
(cid:1) non-zero, oﬀ-diagonal entries since
(cid:1) pairs i, j ∈ N of active neurons must ﬁre in at least one of the two
(cid:1) non-zero, oﬀ-diagonal entries, then, by
(cid:1). If C(s) has more than(cid:0)|N|

possible orderings (i, j) or (j, i). If s is pure, it must be the case that exactly one of
the orderings (i, j) or (j, i) appears in s for each i, j ∈ N with i (cid:54)= j, of which there

are exactly(cid:0)|N|

2

2

the pigeonhole principle, there exist distinct neurons i, j ∈ N such that cij(s) > 0

2

2

2

and cji(s) > 0; so we must have that the spikes of i and j are interlaced, meaning
that s is not pure. This ﬁnishes the proof.

14

Next, one cannot always recover a sequence from its bias-count matrix. Consider,
for example, s1 = 1221 and s2 = 2112. Then C(s1) = C(s2) = [ 1 2
2 1 ]. Hence, thought
of as a map, C : S → N|N|×|N| is not injective. Though we cannot recover s from
C(s), we can recover the spike counts ci(s). To see this, ﬁrst note that

(cid:18)ci(s)
(cid:19)

.

Since f : N → N by f (n) =(cid:0)n

2

cii(s) =

2

(cid:1) is injective, it has an inverse; therefore,

ci(s) = f−1(cii(s)) =

1
2

+

1
2

(cid:112)1 + 8cii(s).

Last, note that cij + cji = cicj. In words, cij + cji is equal to the product of the
number of spikes of i and of j. This is easy to see because we just choose one index
for i and one index for j (which can be done in cicj ways); in each such choice, either
i follows j (counted by cji) or j follows i (counted by cji).

Though C(s) encapsulates the idea of purity, it does so in a somewhat unsatisfac-
tory way. The sequences 123 and 112233, for instance, are both pure sequences with
the same neuronal ordering, yet their bias-count matrices

0 1 1


0 0 1
0 0 0

C(123) =

and

C(112233) =

1 4 4


0 1 4
0 0 1

are quite diﬀerent. The issue is that 112233 has more pairs of spikes than 123 does.
We can correct for this by normalizing each entry by an appropriate value. How likely
is neuron j to follow neuron i? There are cij index pairs in which j follows i out of a

total of cicj possible index pairs. This leads us to the deﬁnition of a second type of
bias matrix.

15

Deﬁnition 2.17. The probability-bias matrix of a sequence s is the matrix Bprob(s) :=
[bij(s)]i,j∈N where bij(s) := cij (s)

.

ci(s)cj (s)

Example 2.18. The probability-bias matrix for the sequence s = 12444433131124
from Figure 2.1 is

 6/16

3/8
8/12
12/20

 =

3/8

3/8
2/3
3/5

5/8
1/4
3/6
4/10

4/12
3/6
3/9
12/15

8/20
6/10
3/15
10/25

 .

5/8
1/4
1/2
2/5

1/3
1/2
1/3
4/5

2/5
3/5
1/5
2/5

Bprob(s) =

The probability-bias matrix maps the set S of sequences into the matrices [0, 1]|N|×|N|,

and it does so in a way that each oﬀ-diagonal entry of the matrix has a natural in-

terpretation in terms of how likely it is to see a pair of spikes in a given order. As
such, it should hold that bij + bji = 1. Recalling that cij + cji = cicj, we see that this
indeed holds:

bij + bji =

cij
cicj

+

cji
cjci

=

cij + cji

cicj

=

cicj
cicj

= 1.

Stated simply, when i and j both spike in a sequence, each pair of spikes must occur
in one order or the other. As deﬁned, this likelihood is global in terms of the sequence,
which gives it a sort of skew-symmetric nature: bij = 1 − bji. As such, it is clear that
not every point in the hypercube [0, 1]|N|×|N| can be obtained as a probability-bias
matrix. Though that much is known simply because no irrational coordinate can

ever be hit by the map, the above relation shows that at least one further relation is

imposed on this image. In a sense, this relation suggests that the bias matrix is still
2−bji = −(bji− 1
not quite in the right form: Since bij +bji = 1, we see that bij− 1
2).
Because the relation comes from the fact that the probability biases are probabilities,

2 = 1

16

the entries are centered at 1
2

, whereas we might more naturally think of a non-bias

(i.e., a maximally unbiased bias) as being equal to 0. Similarly, we might want the
sign of a bias to convey the tendency of neurons to spike in the given order (a positive

bias) or the opposite order (a negative bias). Perhaps we then care more about the
diﬀerence between bij and bji than we do about each of them individually. This leads
us to deﬁne our ﬁnal version of the bias matrix.

Deﬁnition 2.19. The skew-bias matrix of the sequence s is the matrix Bskew(s) :=
Bprob(s) = Bprob(s)T = [βij(s)]i,j∈N with entries βij(s) = bij(s) − bji(s) = cij (s)−cji(s)
.
The skew-bias matrix Bskew(s) is a scaling of the skew-symmetric part of the probability-
bias matrix Bprob(s).

ci(s)cj (s)

Note that when i (cid:54)= j, βij(s) = bij − bji = bij − (1− bij) = 2bij − 1. The skew biases
are now centered at zero and have a sign that indicates the direction of the bias.
Further, the skew-bias matrix is skew-symmetric as a matrix since βij = bij − bji =
−(bji − bij) = −βji.

Example 2.20. The skew-bias matrix for the sequence s = (1, 2, 4, 4, 4, 4, 3, 3, 1, 3, 1, 1, 2, 4)
from Figure 2.1 is

 0

−1/4
1/3
1/5

Bskew(s) =

 .

1/4 −1/3 −1/5
0 −1/5
0
0 −3/5
0
0
3/5
1/5

Here, it is obvious at a glance that, for instance, neuron 2 tends to follow neuron 1
and that neurons 2 and 3 are maximally unbiased toward each other.

17

2.4 Higher-order biases

When creating a mathematical model, it is important to question what information

the model discards. The pairwise biases from the previous section attempt to capture

the tendency of pairs of neurons to ﬁre in a particular order. While this certainly

preserves some information about complex relationships between neurons/spikes, it

may at times discard more information than is desired.

Example 2.21. Consider the sequences s1 = 123321 and s2 = 321123. These se-
quences are indistinguishable by pairwise biases:

1 2 2
 .

2 1 2
2 2 1

C(s1) = C(s2) =

Note that, since the probability- and skew-bias matrices are computed from the bias-
count matrix, these matrices also cannot distinguish between s1 and s2.

We might want, however, for the sequences from the above example to be dis-

tinguishable using some bias-like method. This may or may not be possible for all

pairs of sequences, but we can extend the idea behind the pairwise-bias matrices to

consider more neurons within each individual bias. For instance, we can count the

subsequences that are equal to each permutation of 123 (where, before, we counted
the subsequences equal to each permutation of 12). We call these higher-order biases.

Deﬁnition 2.22. For a list v = (v1, . . . , vk) of k distinct neurons, we deﬁne

Lv(s) := {(i1, . . . , ik) | i1 < ··· < ik and sij = vj for all j ∈ [k]}.

to be the collection of subsequences of s that are equal to v and deﬁne

cv(s) := |Lv(s)|

18

to be the count of those subsequences; we call cv(s) an order-k bias count. Moreover,
analogously to the bias-count matrix, we deﬁne the order-k bias-count vector

(cid:35)

(cid:34) cv1 (s)

...
cvk(cid:48) (s)

Ck(s) :=

where v1, . . . , vk(cid:48)

(cid:0)|N|

(cid:1)k! =

k

(|N|−k)! = |N|(k)
|N|!

.

is the list of length-k biases in lexicographical order and k(cid:48) =

Example 2.23. Continuing the previous example, let s1 = 123321 and s2 = 321123.
Note that L231(s1) = {(2, 3, 6), (2, 4, 6)} and L231(s2) = ∅. In particular, c231(s1) = 2
but c231(s2) = 0. Hence, the order-3 biases can distinguish between the sequences s1
and s2.

Note that cv is a generalization of cij and that cij = c(i,j) = cv for v = (1, 2). This
also uniﬁes the deﬁnitions of the spike-count ci and the bias-count cij; that is, ci and
cij are order-1 and order-2 biases, respectively. But this added information comes at
a cost: The number of order-k biases is O(|N|k). With this increase in the number of
biases, it is valuable to see that a higher-order bias vector contains at least as much

information about a sequence as a lower-order conterpart.

Lemma 2.24. The collection of order-(k − 1) biases can be computed from the col-
lection of order-k biases if the spike counts are also known.

Proof. Let s ∈ S be given, and let v = (v1, . . . , vk−1) ∈ N k−1 be a list of distinct
neurons. We want to compute the order-(k−1) bias cv(s) from the collection of order-

19

k biases. Recall that cv(s) is the number of times that v appears as a subsequence of
s. Let U be the collection of length-k sequences of distinct neurons and of which v
is a subsequence. To make this more precise, deﬁne the sets V = {v1, . . . , vk−1} and
I = N \ V . We can now write U as

U =(cid:8)v[m] · v · v{m+1,...,k} | v ∈ N, m ∈ [k](cid:9) .

We want to double-count the number d of subsequences of s that are equal to some
element of U. First, by deﬁnition of d and the bias count cu(s), we have that d =

(cid:80)

u∈U cu(s).

To count in another way, let B = (cid:83)

v∈N Lv(s) be the collection of indices of s
that are not spikes from the set V . Now, each subsequence of s that is equal to an
element of U has the form sJ∪{m} for some m ∈ B and some J ⊆ [(cid:96)] with sJ = v;
moreover, each such J and m yields such a subsequence. As there are cv(s) such J
v∈N cv(s). Finally, putting together

and(cid:80)

v∈N cv(s) such m, we ﬁnd that d = cv(s)(cid:80)
(cid:33)(cid:46)(cid:32)(cid:88)

(cid:32)(cid:88)

the two expressions for d, we ﬁnd that

(cid:33)

cv(s)

.

cv(s) =

cu(s)

u∈U

v∈N

This completes the proof.

Similarly to the pairwise biases, we may not care about subsequence counts cv
so much as the likelihood that the neurons v1, . . . , vk will appear in the order v =
(v1, . . . , vk) provided that they all appear.

Deﬁnition 2.25. Given a list v = (v1, . . . , vk) of distinct neurons, deﬁne the order-k
. The order-k probability-bias
probability-bias to be the number bv(s) :=

cv(s)

cv1 (s)···cvk (s)

20

vector is the vector

(cid:35)

(cid:34) bv1 (s)

...
bvk(cid:48) (s)

,

Bk(s) :=

where v1, . . . , vk(cid:48) is the list of length-k biases in lexicographical order.

Note that the denominator of bv(s) is the total number of length-k subsequences
of s that contain all neurons v1, . . . , vk; together with the fact that cv(s) is a count of
such sequences, we see that bv(s) is really the proportion of all length-k subsequences
of s containing v1, . . . , vk that are equal to v.

Example 2.26. Let s = 12444433131124. Then L1(s) = {1, 9, 11, 12}, L2(s) =
{2, 13}, and L3(s) = {7, 8, 10}. So we see that L123(s) = {(1, 2, 7), (1, 2, 8), (1, 2, 10)}
and L132(s) = {(1, 7, 13), (1, 8, 13), (1, 10, 13), (9, 10, 13)}; hence,

c123(s) = |L123(s)| = 3

and

c132(s) = |L132(s)| = 4.

Since c1(s) = 4, c2(s) = 2, and c3(s) = 3, we also have that

b123(s) =

c123(s)

c1(s)c2(s)c3(s)

=

1
8

and

b123(s) =

c123(s)

c1(s)c2(s)c3(s)

=

1
6

.

Similarly, we can compute the remainder of the order-3 bias-count and probability-

bias vectors. The vectors are shown as matrices here strictly for formatting purposes:

C3(s) =

c123(s) c213(s) c312(s) c412(s)
c124(s) c214(s) c314(s) c413(s)
c132(s) c231(s) c321(s) c421(s)
c134(s) c234(s) c324(s) c423(s)
c142(s) c241(s) c341(s) c431(s)
c143(s) c243(s) c342(s) c432(s)



 =





8 12
1
3
4
8
3
9
0
0
8
4
3
0
3
4
4
12 0 32
12 12 0 12

21

and



b123(s)
b124(s)
b132(s)
b134(s)
b142(s)
b143(s)

 =

b412(s)
b413(s)
b421(s)
b423(s)
b431(s)
b432(s)



1/8
9/40
1/6
1/15
1/10
1/5

 .

3/10
1/15
0
0
8/15
2/5

1/24
3/40
1/3
1/10
3/10
2/5

1/3
2/15
0
1/10
0
0

b213(s)
b214(s)
b231(s)
b234(s)
b241(s)
b243(s)

b312(s)
b314(s)
b321(s)
b324(s)
b341(s)
b342(s)

B3(s) =

We deﬁne no higher-order version of the skew-bias matrix Bskew because the skew-
nature of Bskew arose from the fact that only two probabilities were involved for each
pair of neurons, that is, from the fact that bij + bji = 1. In the higher-order version,
a more complicated relationship exists, namely

(cid:88)

σ∈Perms({n1,...,nk})

b(nσ(i),...,nσ(n)) = 1

for each set of distinct neurons {n1, . . . , nk} ⊆ N , where Perms(()Ω) is the collection
of permutations of the set Ω.

22

Chapter 3

Bias Matrices

In the previous chapter, we formalized the concept of a neuronal sequence and intro-

duced the pairwise biases associated with those sequences. These pairwise biases—of

which we have three separate formulations—capture the tendency of pairs of neurons

to ﬁre in a particular order. As the main drive of the discussion in the previous

chapter was to motivate and deﬁne these biases, it is worth taking more space here to

investigate further properties of these matrices. Recall that we deﬁned the bias-count
matrix C(s) = [cij]i,j∈N , the probability-bias matrix Bprob(s) = [bij]i,j∈N , and the
skew-bias matrix Bskew(s) = [βij]i,j∈N .

Lemma 3.1. Let s and s(cid:48) be sequences, and consider the following statements:

1. C(s) = C(s(cid:48))

2. Bprob(s) = Bprob(s(cid:48))

3. Bskew(s) = Bskew(s(cid:48))

Then statements (1) and (2) are equivalent. Further, (1) and (2) imply (3).

23

Proof. First, note that that (1) implies (2) since Bprob was deﬁned solely in terms of
C. Similarly, (2) implies (3) since Bskew was deﬁned solely in terms of Bprob. All that
remains to be shown is that (2) implies (1). To see this, note that the spike count
ci(s) can be recovered from the diagonal entry bii(s) of Bprob(s):

(cid:0)ci(s)
(cid:1)

(cid:18)

(cid:19)

bii(s) =

cii(s)

ci(s)ci(s)

=

2

ci(s)ci(s)

=

1
2

1 − 1
ci(s)

=⇒ ci(s) =

1

1 − 2bii(s)

.

Knowing each spike count now allows us to recover any entry of C(s):

bij(s) =

cij(s)

ci(s)cj(s)

=⇒ cij(s) = bij(s)ci(s)cj(s).

Hence, C(s) = C(s(cid:48)) if Bprob(s) = Bprob(s(cid:48)). Therefore, (2) implies (1), as claimed.
This completes the proof.

Note that statement (3) from the above lemma is not equivalent to statements (1)

and (2). This is easily seen, for example, with the pure sequences 12 and 1122:

Bskew(12) = Bskew(1122) =

(cid:21)

(cid:20) 0

1
−1 0

but

(cid:20)0 1

(cid:21)

0 0

(cid:20)1 4

(cid:21)

0 1

(cid:54)=

C(12) =

= C(1122).

The reason for this is that Bskew(s) does not contain suﬃcient information to recover
the spike counts since βii(s) = 0 for all neurons i ∈ N and all sequences s.

24

3.1 Relationship to center-of-mass vectors

Bias matrices were introduced in an attempt to deal with issues associated with

center-of-mass vectors, but these two concepts were reached through very diﬀerent

approaches. Still, a surprising relationship exists between them: The center-of-mass

vector center(s) can be computed from the bias-count matrix C(s).

Lemma 3.2. If s ∈ S is a sequence and i ∈ supp(s) is an active neuron, then

(cid:80)n

centeri(s) = 1 + 1
ci(s)

j=1 cji(s).

Proof. Let (cid:96) = len(s). Also, let c(k)
before the $k$-th spike in the sequence s provided that sk = i:

ji (s) denote the number of times neuron j spikes

ji (s) := |{k(cid:48) < k | sk(cid:48) = j and sk = i}|.
c(k)

Observe that

(cid:96)(cid:88)

k=1

c(k)
ji (s) = cji(s)

and

n(cid:88)

j=1

c(k)
ji (s) =

k − 1,

0,

sk = i;
sk (cid:54)= i.

Further, since we know C(s), we know cii(s) for each i ∈ N . Recalling that cii(s) =

2

(cid:0)ci(s)
(cid:1), we note that ci(s) = 1
i ∈ N allows us to ﬁnd (cid:96) as (cid:96) =(cid:80)
n(cid:88)

2 + 1

2

cji(s) =

j=1

i∈N ci(s). Putting these facts together, we see that

(cid:112)1 + 8cii(s). Moreover, knowing cii(s) for each
n(cid:88)
(cid:96)(cid:88)

c(k)
ji (s)

(cid:96)(cid:88)
n(cid:88)

k=1

j=1

=

c(k)
ji (s)

k=1

j=1

25

(k − 1)

(cid:88)
(cid:88)

k∈Li(s)

=

Li(s) − ci(s)

=
= ci(s)[centeri(s) − 1].

Because ci(s) (cid:54)= 0 by assumption, we can solve for centeri(s) to obtain the desired
result.

In particular, the above lemma says that center(s1) = center(s2) if C(s1) = C(s2).
However, the converse to this statement is not true. That is, the center-of-mass vector

center(s) does not contain enough information to compute the bias-count matrix. For
example, consider the sequences s1 = 123123 and s2 = 211332. Then

center(s1) = center(s2) =

but

1 3 3
 (cid:54)=

1 1 3
1 1 1

C(s1) =

5/2

 = C(s2).
1 2 4

7/2
9/2

2 1 2
0 2 1

As such, the bias-count matrix C(s) is in fact a generalization of the center-of-mass
vector center(s).

One might also suspect that the center-of-mass vector γ(s) can be recovered
from the skew-bias matrix Bskew(s). However, upon closer inspection of the previ-
ous lemma, we notice that the bias-count matrix was used to recover the spike-count

vector, which cannot be done when starting with the skew-bias matrix. As the next

proposition shows, however, we can reconstruct the center-of-mass vector γ(s) from
the skew-bias Bskew(s) if we also know the sequence’s ﬁring-rate vector ρ(s).

26

Proposition 3.3. If s ∈ S is a sequence, then

γ(s) = Bskew(s)T ρ(s).

Proof. Let (cid:96) = len(s), and assume that i ∈ supp(s). Recall that γi(s) = 2 centeri(s)−1
1, from which we see that

(cid:96)

−

centeri(s) =

(cid:96)
2

[γi(s) + 1] +

1
2

.

We now want to rewrite the previous lemma to give us an expression for γi(s) in terms
of the skew-biases βij(s). Dropping the s dependence from the notation, the above
equation and the previous lemma yield the following:

(cid:96)
2

1
2

j(cid:54)=i

= 1 +

cji

j=1

= 1 +

cii +

cji

= centeri

1
ci

1
ci

1
ci

(γi + 1) +

(cid:17)
(cid:88)

n(cid:88)
(cid:16)
(cid:88)
(cid:16) ci(ci − 1)
(cid:16)
(cid:88)
(cid:16)(cid:2)ci +
(cid:88)
(cid:3) − 1 +
(cid:16)
(cid:17)
n(cid:88)
where we have recalled in the last line that βii = 0 and(cid:80)n

j(cid:54)=i
(cid:96) − 1 +

2
ci − 1 +

1
2

1
2

1
2

cicj
2

j(cid:54)=i

cj

cjβji

,

+

j(cid:54)=i

(cid:88)

j(cid:54)=i

= 1 +

= 1 +

= 1 +

= 1 +

cj(βji + 1)

j=1

(cid:17)

(βji + 1)

(cid:17)

(cid:17)

cjβji

j=1 cj = (cid:96). Solving for γi

27

and including the s dependence into our notation, we obtain

n(cid:88)

γi(s) =

βji(s)ρj(s)

j=1

(cid:96)

since ρi(s) = ci(s)
. Note that although we derived this equation using the assumption
that ci(s) > 0, it still holds if ci(s) = 0 because in this case we have γi(s) = 0 and
j=1 βji(s)ρj(s) is the entry in row i of Bskew(s)T ρ(s), this

βij(s) = 0 for all j. Since(cid:80)n

completes the proof.

If we substitute the ﬁring-rate vector ρ(s) in Proposition 3.3 for an arbitrary ﬁring-
rate vector, then the skew-bias matrix can be used to generate other center-of-mass

vectors and orderings.

Deﬁnition 3.4. Given a sequence s and a ﬁring-rate column vector ρ = (ρ1, . . . , ρn),
deﬁne the center of mass of s induced by ρ to be γs(ρ) := Bskew(s)T ρ. Further,
deﬁne the corresponding center-of-mass ordering of s induced by ρ, denoted σs(ρ),
just as with the center-of-mass ordering of a sequence: If γs(ρ) = (g1, . . . , gn), then
σs(ρ) = (i1, . . . , in) where {i1, . . . , in} = [n] are such that gi1(s) ≤ ··· ≤ gin(s) and,
in the case that gik(s) = gik+1(s), such that ik < ik+1.

Example 3.5. Recall that the sequence s = 12444433131124 has skew-bias matrix

 0

−1/4
1/3
1/5

 .

1/4 −1/3 −1/5
0
0
1/5
0 −3/5
0
0
3/5
1/5

Bskew(s) =

The ﬁring-rate vector of s is ρ(s) = 1

14[4, 2, 3, 5] and σ(s) = (4, 2, 1, 3). With ﬁring-rate

vectors ρ1 = 1

4[1, 1, 1, 1] and ρ2 = 1

3[1, 1, 1, 0], we ﬁnd that

 −→ σs(ρ1) =
17/240

1/80

1/15−1/4

4


2
3
1

γs(ρ1) =

and

γs(ρ2) =

28

4
 .

3
1
2

 −→ σs(ρ2) =

 1/36

1/12−1/9−1/3

So, ρ1 and ρ2 induce the orderings (4, 2, 3, 1) and (4, 3, 1, 2), respectively. In particular,
notice that the activation of neuron 4 changed the induced ordering of {1, 2, 3}.

In the case of a pure sequence, this process can result in only one neuronal ordering,

as the following lemma shows.

Lemma 3.6. If s is a pure sequence, then σs(ρ) = σ(s) for each ﬁring-rate vector
ρ = (ρ1, . . . , ρn) satisfying ρi > 0 for each i ∈ N .

Proof. Without loss of generality, we can assume that s = σ(s) since Bskew(s) =
Bskew(σ(s)) whenever s is pure. For each neuron i ∈ [n − 1], we know that βjsi(s) =
βjsi+1(s) for each j ∈ N \ {si, si+1} since s is pure and since si and si+1 are adjacent
spikes (not equal to j); additionally, we know that βsisi(s) = βsi+1si+1(s) = 0 and that
βsisi+1(s) = 1 and βsi+1si(s) = −1. Letting γs(ρ) = (γ1, . . . , γn), these facts tell us
that

n(cid:88)

n(cid:88)

γsi =

βjsi(s)ρj <

βjsi+1(s)ρj = γsi+1.

j=1

j=1

Hence, regardless of the choice of ρ, we always have that γs1 < ··· < γsn
letting ρ = ρ(s), we ﬁnd that σs(ρ(s)) = σ(s), thus completing the proof.

. In particular,

3.2 Permutations of sequences

To understand a bias matrix A, it would be useful to know which sequences give rise
skew(A) ⊆ S.
to that bias matrix; that is, we would like to be able to describe the set B−1

We can "ﬁll in" part of this set if we know a sequence in that set, that is, a sequence
s such that Bskew(s) = A.

29

Consider the sequence s = 12321 and its bias-count matrix

1 2 1
 .

2 1 1
1 1 0

C(s) =

If we ﬂip any two adjacent spikes, the result in the bias-count matrix will be that

exactly two entries are modiﬁed. For instance, if we ﬂip the ﬁrst two spikes, the

bias-count matrix becomes

1 1 1
 .

3 1 1
1 1 0

C(21321) =

Since we want the bias-count matrix to remain unchanged if we are to ﬁnd another
sequence in B−1
skew(Bskew(s)), we can try to undo the eﬀect of the ﬁrst ﬂip by ﬂipping
another pair of spikes; that is, since we made a subsequence of the form 12 into
one of the form 21, we can look for a subsequence of the form 21 to change into
12. Here, the last two spikes are 21; changing these and the ﬁrst two, we get the
sequence s(cid:48) = 21312. Now, C(s(cid:48)) = C(s). So, indeed, it is sometimes possible to ﬁnd
another sequence with the same biases by simply permuting the spikes of the original

sequence. It will be convenient to have some notation and terminology for such an

operation:

Deﬁnition 3.7. For a sequence s = (s1, . . . , s(cid:96)) and a permutation π ∈ Perms([(cid:96)]),
deﬁne the shuﬄing of s by π to be sπ := (sπ(1), . . . , sπ((cid:96))).

Example 3.8. Let s = 1212333. The following table shows permutations of [len(s)] =
[7] along with the corresponding shuﬄed sequence.

30

Permutation
π1 = (1 7)(2 6)(3 5)
π2 = (2 3)
π3 = (1 2)(3 4)
π4 = (1 3)(5 6 7)

Shuﬄed sequence
sπ1 = 3332121
sπ2 = 1122333
sπ3 = 2121333
sπ4 = 1212333

Note that the non-trivial permutation π4 induces a shuﬄed sequence sπ4 that is equal
to the original sequence s.

Deﬁnition 3.9. For a sequence s = (s1, . . . , s(cid:96)) and a collection ω of neurons, deﬁne
the restriction of s to ω to be s|ω := sIω
Example 3.10. Let s = 12444433131124, and let ω1 = {1, 2} and ω2 = {3, 4}. Then
sω1 = 121112 and sω2 = 44443334.

where Iω := ∪i∈ωLi(s).

Lemma 3.11. Let s = (s1, . . . , s(cid:96)) be a sequence, and let π = (k1 k1 + 1)(k2 k2 + 1)
be a permutation such that sk1 = sk2+1 and sk2 = sk1+1. Then C(s) = C(sπ).

Proof. Let s = (s1, . . . , s(cid:96)) be a sequence, and let π = (k1 k1 + 1)(k2 k2 + 1) be
a permutation of [(cid:96)] such that sk1 = sk2+1 and sk2 = sk1+1. Let i1 = sk1 ∈ N
and i2 = sk2 ∈ N , and let N = N \ {i1, i2}. Observe that s|N = sπ|N since π
ﬁxes the indices of the spikes from neurons in N; in particular, this tells us that
cj1j2(s) = cj1j2(s|N ) = cj1j2(sπ|N ) = cj1j2(sπ).

We now want to show that cij(s) = cij(sπ) and cji(s) = cji(sπ) if {i, j}∩{i1, i2} (cid:54)= ∅.
Recalling that cij = |Lij|, we proceed by listing the relationships between index pairs
in the sets Lij and Lji. Suppose that m ∈ [(cid:96)] \ {k1, k1 + 1, k2, k2 + 1} is a spike index
and that j := sm ∈ N. Then the following relationships hold:

(k1, m) ∈ Li1j(s) ⇐⇒ (k1 + 1, m) ∈ Li1j(sπ)

(k2 + 1, m) ∈ Li1j(s) ⇐⇒ (k2, m) ∈ Li1j(sπ)
(k1 + 1, m) ∈ Li2j(s) ⇐⇒ (k1, m) ∈ Li2j(sπ)

31

(k2, m) ∈ Li2j(s) ⇐⇒ (k2 + 1, m) ∈ Li2j(sπ)
(m, k1) ∈ Lji1(s) ⇐⇒ (m, k1 + 1) ∈ Lji1(sπ)

(m, k2 + 1) ∈ Lji1(s) ⇐⇒ (m, k2) ∈ Lji1(sπ)
(m, k1 + 1) ∈ Lji2(s) ⇐⇒ (m, k1) ∈ Lji2(sπ)

(m, k2) ∈ Lji2(s) ⇐⇒ (m, k2 + 1) ∈ Lji2(sπ)

(k1, k1 + 1), (k1, k2) ∈ Li1i2(s) ⇐⇒ (k1 + 1, k2 + 1), (k2, k2 + 1) ∈ Li1i2(sπ)

(k1 + 1, k2 + 1), (k2, k2 + 1) ∈ Li2i1(s) ⇐⇒ (k1, k1 + 1), (k1, k2) ∈ Li2i1(sπ)

This completes the proof since each line above indicates that the corresponding index-

pair sets are of the same size for both s and sπ.

Since a sequence of such permuations can be applied recursively, one might wonder

whether all sequences with equal bias-count matrices can be obtained from a single

sequence by repeated application of such permutations. This is not the case: For
example, if s = 123231 and s(cid:48) = 231123, then C(s) = C(s(cid:48)) but no such permutation
π = (i i + 1)(j j + 1) exists such that s(cid:48) = sπ since there is no pair {i, j} with i (cid:54)= j
such that si = sj+1 and si+1 = sj. More succinctly, if Bprob(s) = Bprob(s(cid:48)), it is not
necessarily the case that s(cid:48) = sπ for some permutation π.

We can also describe a broader class of permutations that ﬁxes the center-of-mass

vectors of a given sequence. Generally speaking, elements of this class will not ﬁx the

corresponding bias matrices.

Lemma 3.12. If s = (s1, . . . , s(cid:96)) is a sequence and π = (k1 k1 + 1)··· (km km + 1) ∈
Perms([l]) with ka+1 > ka + 1 for all a ∈ {1, . . . , m − 1}, then center(s) = center(sπ)
if {sk1, . . . , skm} = {sk1+1, . . . , skm+1} and |{sk1, . . . , skm}| = m.
Proof. Suppose that i ∈ {s1, . . . , sk}. Then i = skb = skd+1 for some b, d ∈ [m].

32

Noting that Li(sπ) = [Li(s) \ {kb, kd + 1}] ∪ {kb + 1, kd}, we see that

centeri(s) = centeri(s) +

= centeri(s) +

= center(sπ).

[kb + (kd + 1)] − [kb + (kd + 1)]
[(kb + 1) + kd] − [kb + (kd + 1)]

ci(s)

ci(sπ)

If i /∈ {s1, . . . , sk}, then centeri(s) = centeri(sπ) since Li(sπ) = Li(s). Hence,
centeri(s) = centeri(sπ) for all i ∈ N , thus completing the proof.

Example 3.13. Let s = 123123 and π = (1 2)(3 4)(5 6). Then s and π meet the
stipulations of the previous lemma since {s1, s3, s5} = {s2, s4, s6} = {1, 2, 3}. Noting
that sπ = 211332, we see that

center(s) = center(sπ) =

 .

7/2

5/2
9/2

3.3 The fundamental polytope

The bias matrix arose in an attempt to capture the tendency of pairs of neurons to

ﬁre in a particular order. These tendencies can be computed from any individual

sequence, but the pairwise nature of the biases hints at an underlying network of

neurons with pairwise preferences for spiking in particular orders. From this per-

spective, a sequence is really just a (noisy) manifestation of the neural network’s

biases. As such, it may be useful to understand the properties that characterize all

bias matrices. By considering the biases that arise from sequences, we aim to derive

a bias-matrix formulation that is independent of any individual sequence.

In this

section, we develop such a formulation and conjecture that each collection of biases

in this formulation is realizable as the collection of biases of an actual sequence.

We begin by consideration of the bias-count matrix C(s) = [cij(s)]i,j∈N . We

already know a few properties that must be satisﬁed:

33

• Its entries are natural numbers: cij ∈ N0 for all i, j ∈ N .

• Its diagonal entries are binomial coeﬃcients: cii =(cid:0)ci

(cid:1) for all i ∈ N .

2

• For all neurons i, j ∈ N with i (cid:54)= j, cij + cji = cicj.

But we moved from the bias-count matrix to the skew-bias matrix because we want

the individual bias entries to have meaning independent of other entries. When the

above properties are translated into the skew-bias matrix, we ﬁnd only two properties:

• It is skew-symmetric: βij = −βji for all i, j ∈ N .

• Its entries are bounded and rational: βij ∈ [−1, 1] ∩ Q for all i, j ∈ N .

Though the properties listed here do not fully characterize the skew-biases in general

(as we will see below), they do provide a convenient starting place from which we can

further restrict as we look for additional properties. The skew nature of the matrices
Bskew(s) allows us to describe the matrix using only the above-diagonal entries of each
matrix.

Deﬁnition 3.14. The bias space B(N ) of the neuron set N = [n] is the (cid:0)n
(cid:1)-

dimensional hypercube [−1, 1](n
2) with coordinates indexed by neuron pairs (i, j) ∈ N 2
with i < j. When s is a sequence, the vector [βij(s)]i<j consisting of the upper-
triangular portion of Bskew(s) is the corresponding point in the bias space. We will
abuse terminology and refer to Bskew(s) as being in the bias space for notational/ter-
minological convenience.

2

34

Deﬁnition 3.15. A point x ∈ B(N ) is obtainable if x is in the closure of the set
{Bskew(s) | s ∈ S}.

Which points in B(N ) are obtainable? Let us ﬁrst consider one of the simplest
classes of sequences: those with exactly two active neurons. In this case—that is,
when N = [2]—the only bias that we consider is β12; further, the bias space is just
the interval [−1, 1]. Here, we ﬁnd that the biases are actually dense in the bias space.

Lemma 3.16. For any x ∈ [−1, 1] and any  > 0, there exists a sequence s ∈ S such
that supp(s) = [2] and |β12(s) − x| < .

Proof. Let x ∈ [−1, 1] and  > 0 be given. Choose (cid:96) ∈ N such that

k ∈ N as k =(cid:4) 1
2(1 + x)((cid:96)− 1) ≤ (cid:96)− 1 and, thus, k ∈ [(cid:96)]. Moreover,(cid:12)(cid:12)k − 1

2(1 + x)((cid:96) − 1) + 1(cid:5). Note that 0 ≤ 1 + x ≤ 2 since −1 ≤ x ≤ 1; so,
2(1 − x)(cid:96)(cid:12)(cid:12) ≤ 1 by choice

0 ≤ 1
of k. Deﬁne the sequence s = (s1, . . . , s(cid:96)) by sk = 2 and sm = 1 for m ∈ [(cid:96)] \ {k}.
Now, c12(s) = k − 1, which implies that b12(s) = c12(s)
and that
β12(s) = 2b12(s) − 1 = 2k−2

c1(s)c2(s) = k−1

(cid:96)−1 < , and pick

((cid:96)−1)·1 = k−1
(cid:96)−1

2

(cid:96)−1 − 1. Now,

|β12(s) − x| =

=

(cid:96) − 1

− 1 − x

(cid:12)(cid:12)(cid:12)(cid:12)2k − 2
(cid:12)(cid:12)(cid:12)(cid:12)2k − 2 − (1 + x)((cid:96) − 1)
(cid:12)(cid:12)k −(cid:0) 1

(cid:12)(cid:12)(cid:12)(cid:12)
2(1 + x)((cid:96) − 1) + 1(cid:1)(cid:12)(cid:12)

(cid:96) − 1

(cid:12)(cid:12)(cid:12)(cid:12)

2
(cid:96) − 1
=
≤ 2
(cid:96) − 1

< ,

thus completing the proof.

But it is not generally the case that every point in the bias space is obtainable.

To get some intuition about why some points are not obtainable, consider the matrix

35

 .

A =

 0

1 −1
−1
1
0
1 −1
0

Suppose that A = Bskew(s) for some sequence s. Because all oﬀ-diagonal entries are
in {1,−1}, we must have that s is a pure sequence. Considering the entries more
closely, we also ﬁnd the following:

• (a12 = 1) All spikes from neuron 1 precede all spikes from neuron 2.

• (a23 = 1) All spikes from neuron 2 precede all spikes from neuron 3.

• (a13 = −1) All spikes from neuron 3 precede all spikes from neuron 1.

The ﬁrst two points (a12 = a23 = 1) tell us that all spikes from neuron 1 must
precede all spikes from neuron 3. But this is a contradiction to the third observation!
Hence, we cannot have that A = Bskew(s) for any sequence s. Indeed, we will see in
Corollary 3.19 that A is not obtainable.

Although we have not yet shown that A is not obtainable, the point is well-taken:
There are non-trivial relationships among the entries βij, βjk, and βik (that is, among
the collection of biases between the neurons i, j, and k). In fact, the above-observed
property holds in a more general case: If s ∈ S is pure, then we must have that
βik = 1 if βij = βjk = 1 for distinct neurons i, j, k ∈ N . The logic for seeing that
this holds is exactly the same as in the motivating example. As seen in the proof

of Lemma 3.16, only one spike from the second neuron was necessary to obtain (in

the sense of density) all possible biases between exactly two neurons. As such, we

begin our investigation of biases among three neurons by considering sequences with

exactly one spike from a third neuron.

Lemma 3.17. For any sequence s ∈ S with distinct neurons i, j, k ∈ supp(s) and
with ck(s) = 1, bik(1 − bjk) ≤ bij ≤ 1 − bjk(1 − bik).

36

= ckj
cj

ckci

Proof. Since neuron k spikes only once, it is easy to construct a sequence that min-
imizes mij for ﬁxed (rational) values of bki and bkj. Since bki = cki
and
, we see that cki = bkici and ckj = bkjcj are proportions of the total
bkj = ckj
ckcj
number of times that neurons i and j spike, respectively. In particular, when consid-
ering the restricted sequences containing k and only one other neuron, we ﬁnd that
there is only one possibility for each restricted sequence:

= cki
ci

s|{i,k} = icik · k · icki

and

s|{j,k} = jcjk · k · jckj ,

where we recall that the symbol · represents concatenation. In joining these restricted
sequences to form the full sequence s, we minimize bij by placing j before i whenever
possible, resulting in the following:

s = jcjk · icik · k · jckj · icki.

It is now straightforward to count cij:

cij = cikckj = (bikci)(bkjcj) = bik(1 − bjk)cicj.

Because s was chosen to minimize cij, dividing by the product cicj yields one of the
desired inequalities: bij ≤ bik(1 − bjk). Similar reasoning allows us to maximize cij
with s(cid:48):

s(cid:48) = icik · jcjk · k · icki · jckj ,

which results in the count

37

cij = cikcj + ckickj

= bikcicj + (bkici)(bkjcj)

= (bik + bkibkj)cicj
= [bik + (1 − bik)(1 − bjk)]cicj
= (1 − bjk + bikbjk)cicj
= [1 − bjk(1 − bik)]cicj,

thus yielding the other desired inequality: bij ≥ 1 − bjk(1 − bik). This completes the
proof.

As it turns out, however, not every point in the bias space B([3]) is obtainable
using only a single spike from the third neuron. Consider, for example, the sequence

s = 3123 and its bias matrix

Bskew(s) =

 0

 .

1 0
−1 0 0
0 0
0

Suppose that there is some sequence s(cid:48) such that c3(s(cid:48)) = 1 and Bskew(s(cid:48)) = Bskew(s).
Since β12(s(cid:48)) = 1, the restricted sequence s(cid:48)|[2] must be pure. But then the single spike
from neuron 3 cannot fall in the middle of the spikes for neuron 1 and in the middle
of the spikes for neuron 2. Hence, no such s(cid:48) can exist. Still, not all points in the bias
space are obtainable even when we consider arbitrary sequences on three neurons.

But this should not come as too much of a surprise: Our intuition for sequences

says that if i follows j and k follows j, then we would expect for k to follow i. The
inequalities in the lemma below are restrictions of such a form.

38

Proposition 3.18. For any sequence s with neurons i, j, k ∈ supp(s) such that i <
j < k, the inequalities 0 ≤ bij + bjk − bik ≤ 1 hold.

Proof. Let s = (s1, . . . , s(cid:96)) be a sequence. First, note that the following equality holds
because every triple (cid:96)i, (cid:96)j, (cid:96)k ∈ [(cid:96)] with s(cid:96)i = i, s(cid:96)j = j, and s(cid:96)k = k (of which there
are cicjck) will produce exactly one of the six orderings ijk, jki, kij, ikj, jik, and
kji:

cijk + cikj + cjik + cjki + ckij + ckji = cicjck

We now show that the following relationships exist between pairwise-bias counts

and third-order bias counts:

ckcij = cijk + cikj + ckij

cicjk = cjki + cjik + cijk

cjcki = ckij + ckji + cjki

To see that these relationships hold, consider the ﬁrst one. For each subsequence of
s that is equal to $(i, j)$—of which there are $cij$—each of the ck occurrences of k
in s can produce only one of the triples (i, j, k), (i, k, j), and (k, i, j); moreover, each
such combination must produce one such triple. Hence, the equality holds. Similar

arguments work for each of the other two equations.

Summing the above equations, we get the following inequality:

ckcij + cicjk + cjcki = 2(cijk + cjki + ckij) + (cikj + cjik + ckji)

= 2(cijk + cjki + ckij + cikj + cjik + ckji)
− (cikj + cjik + ckji)
= 2cicjck − (cikj + cjik + ckji)

≤ 2cicjck.

39

Dividing the resultant inequality by cicjck yields the inequality bij + bjk + bki ≤ 2. By
considering the sum of the same equations again, we ﬁnd another inequality:

ckcij + cicjk + cjcki = 2(cijk + cjki + ckij) + (cikj + cjik + ckji)

= (cijk + cjki + ckij + cikj + cjik + ckji)

+ (cijk + cjki + ckij)

= cicjck + (cikj + cjik + ckji)
≥ cicjck.

Dividing this by cicjck yields the inequality bij + bjk + bki ≥ 1. Putting these two
inequalities together, we have that 1 ≤ bij + bjk + bki ≤ 2. Recalling that bki = 1− bik,
this becomes 0 ≤ bij + bjk − bik ≤ 1, thus completing the proof.

Corollary 3.19. For any sequence s with neurons i, j, k ∈ supp(s) such that i < j <
k, the inequalities −1 ≤ βji + βkj − βik ≤ 1 hold.

As sequences become less pure, our intuition about one neuron "following" another

breaks down, and we run into tendencies that would be contradictory in the case of

a pure sequence.

Example 3.20. Consider the sequence s = 2331112123. The skew-bias matrix of s
is

 0

Bskew(s) =

 .

1/6 −1/3
1/9
0
0

−1/6
1/3 −1/9

Upon inspection, we see that (1) neuron 1 tends to precede neuron 2, (2) neuron 2

tends to precede neuron 3, and (3) neuron 3 tends to precede neuron 1.

40

Inequalities of the form in Corollary 3.19 essentially ensure that the pairwise-

biases among any three neurons are consistent with each other (i.e., if j follows i and
k follows j, then k follows i), a sort of pseudo-transitivity that is guaranteed when
biases arise from an actual sequence. Further, the collection of all such inequalities

carves out a polytope in the bias space, which we will call the consistent-bias polytope.

Because three distinct neurons were required for this corollary, there are (cid:0)|N|
be described by a total of 2(cid:0)|N|

inequalities, each of which is really two distinct inequalities. Since the bias space
itself is deﬁned by inequalities of the form −1 ≤ βij ≤ 1 with i < j, this polytope can

(cid:1) such

3

(cid:1) + 2(cid:0)|N|

2

(cid:1) inequalities:

3

• βij + βjk − βik ≤ 1 for all i < j < k,
• −βij − βjk + βik ≤ 1 for all i < j < k,
• βij ≤ 1 for all i < j,
• −βij ≤ 1 for all i < j.

The inequalities from Corollary 3.19 can be rearranged to bound the bias of i to
ﬁre before k if the other biases are known: βij + βjk − 1 ≤ βik ≤ βij + βjk + 1. This
inequality is the direct equivalent to the intuition that k should follow i if k follows
j and j follows i. But longer chains of this form do not create inequalities that are
more restrictive than those arising from such chains of length three. For considering

possible biases among more than three neurons, we start by looking at the simplest

of such biases: those arising from pure sequences.

Deﬁnition 3.21. A pure-bias matrix is a matrix A such that A = Bskew(s) for some
pure sequence s ∈ S.

For each pure-bias matrix A, there is a sequence s with one spike per neuron such
that Bskew(s) = A. Let us start by considering the sequence s = (1, 2, . . . , n). Here,

we see that i precedes j whenever i < j; as such, the corresponding entries of Bskew(s)
are βij(s) = 1 and βji(s) = −1. For example,

41

 0

1
1
−1
0
1
−1 −1
1
−1 −1 −1 0

1
1
0

 .

Bskew(1234) =

Indeed, up to row and column permutations, the bias matrix of each pure sequence

is of this form, as the following lemma shows.

Lemma 3.22. Suppose that s ∈ S is pure. Then Bskew(s) = P −1AP for A =
Bskew(12··· n) and some permutation matrix P .

Proof. Let s ∈ S be pure. Without loss of generality, we can assume that s =
(s1, . . . , sn) has one spike per neuron since, for a pure sequence, it is clear that
Bskew(s) = Bskew(σ(s)). Note that βsi,sj (s) = βij(12··· n) since si precedes sj in
s if and only if i precedes j in 12··· n. Deﬁne π ∈ Perms(N ) by π(si) = i, and let
P = [pij]i,j∈N be the permutation matrix with entries

1, π(j) = i;

0, otherwise.

pij =

Letting C = P −1AP = [cij]i,j∈N and D = AP = [dij]i,j∈N , we ﬁnd that

k=1

n(cid:88)
n(cid:88)
n(cid:88)

k=1

k=1

csi,sj =

=

=

pk,sidk,sj

(cid:32) n(cid:88)

(cid:33)

ak,(cid:96)p(cid:96),sj

pk,si

(cid:96)=1

pk,siak,π(sj )

42

= aπ(si),π(sj )

= aij
= βij(12··· n)

= βsi,sj (s).

Therefore, Bskew(s) = P −1AP as claimed, completing the proof.

Pure sequences are extreme from the perspective of biases.

Indeed, each bias

corresponding to a pure sequence is a vertex of the the bias space hypercube. As we

have already seen in this section, not all vertices of the bias space are legitimate biases.

We now know exactly which vertices correspond to legitimate biases. Moreover, we

have a simple count for how many vertices are obtainable biases: There is one for
each permutation of the neuron set N = [n]; that is, n! of the 2(n
are obtainable biases.

2) bias-space vertices

But we can glean more from this investigation of pure biases. Consider two pure

sequences with one spike per neuron that are as close to each other as possible, that

is, sequences that diﬀer by a single transposition of spikes. For the sake of example,
we will consider s = 1234··· n and s(cid:48) = s(1 2) = 2134··· n. From the perspective of
the neurons in N \ [2], neurons 1 and 2 both behave exactly the same (since both
1 and 2 precede all other spikes in both s and s(cid:48)). Many other sequences share this
property with s and s(cid:48); in fact, we can completely characterize the collection of all such
sequences as {(s1, . . . , s(cid:96), 3, 4, . . . , n) | (s1, . . . , s(cid:96)) ∈ S([2])}. That is, we can prepend
an arbitrary sequence from the neuron set [2] to the beginning of the sequence 34··· n.
But we know something about the biases arising from the sequences in S([2]): Every
bias is obtainable! This tells us that the entire line joining s to s(cid:48) in the bias space is
obtainable as a bias. This is similarly true for any such pair of "adjacent" sequences

43

Figure 3.1: When N = [3], the fundamental polytope of S is 3-dimensional. Above,
this polytope is shown below from two angles. In this case of only three neurons,
the fundamental polytope is equal to the consistent-bias polytope. Note that n = 3
is a special case: These polytopes are not equal in general. Since they are
equal here, we can easily write down the hyperplanes that serve as its boundaries:
−1 ≤ β12 + β23 − β13 ≤ 1, −1 ≤ β12 ≤ 1, −1 ≤ β13 ≤ 1, and −1 ≤ β23 ≤ 1

with one spike per neuron. More surprisingly, each obtainable bias is in the convex

hull of the collection of pure biases. Before showing this claim to be true, we name

this polytope and show its relationship to the consistent-bias polytope.

Deﬁnition 3.23. The fundamental polytope of S is the convex hull of the set of pure
biases arising from sequences in S.

Lemma 3.24. The consistent-bias polytope contains the fundamental polytope.

Proof. Since the vertices of the fundamental polytope are obtainable biases, they must
satisfy the constraints that specify the consistent-bias polytope; moreoever, since both

polytopes are convex, we must have that the fundamental polytope is contained in

the consistent-bias polytope.

Theorem 3.25. If s ∈ S with supp(s) = N , then the bias corresponding to s is
contained in the fundamental polytope.

44

Proof. Let t = 12··· n, and let Pn = {Bskew(tπ) | π ∈ Sn} be the collection of pure-
bias matrices. Also, let s = (s1, . . . , s(cid:96)) be any sequence with supp(s) = N . We need
only to show that Bskew(s) is a convex combination of the elements of Pn. For each sub-
sequence s(cid:48) of s that is equal to tπ for some π ∈ Perms([n]), we have that Bskew(s(cid:48)) ∈
Pn by deﬁnition of Pn. Let Sub(s) = {I ⊆ [(cid:96)] | sI = tπ for some π ∈ Perms([n])}, and
deﬁne the sum D = [dij] to be

1(cid:81)n

i=1 ci(s)

D =

(cid:88)

I∈Sub(s)

Bskew(sI).

Because Bskew(sI) ∈ Pn, the proof will be ﬁnished if D = Bskew(s) and if the coeﬃ-
cients of its summands sum to 1.

To see that the latter of these requirements holds, ﬁrst note that all coeﬃcients
i=1 ci(s) summands in the deﬁnition of D:
Choosing a subsequence of s that is and ordering of N is the same as choosing one

are equal. Moreover, there are exactly (cid:81)n
index from each of the sets Li(s) for i ∈ N , which can obviously be done in(cid:81)n

i=1 ci(s)

ways since ci(s) = |Li(s)| for each i ∈ N .

To see that D = Bskew(s), consider an arbitrary entry dij:

k=1 ck(s)

I∈Sub(s)

k=1 ck(s)

βij(sI)

(cid:88)
(cid:18) (cid:88)
(cid:88)
(cid:18)
[cij(s) − cji(s)] ·(cid:89)

I∈Sub(s)
cji(sI )=1

I∈Sub(s)
cij (sI )=1

1 +

(cid:19)

−1

(cid:19)

ck(s)

k /∈{i,j}

1(cid:81)n
1(cid:81)n
1(cid:81)n

dij =

=

=

=

k=1 ck(s)

cij(s) − cji(s)
ci(s)cj(s)

= βij(s)

45

Hence, we see that the fundamental polytope contains all biases.

Though all biases are contained in the fundamental polytope, the question of

whether or not the biases are dense in the fundamental polytope is still an open

question.

Question 3.26. Is every point in the fundamental polytope obtainable?

3.4 The bias network of a sequence

Neuronal templates are appealing because they provide a simple combinatorial picture

of neuronal sequences, but this representation is lacking in many aspects. The bias

matrix can be used to deﬁne a more-robust combinatorial representation of these

sequences.

Deﬁnition 3.27. Let A = [aij]i,j∈N be a bias matrix. We deﬁne the bias net-
work of A to be the simple digraph G(A) with vertext set N and edge set E(A) :=
{(i, j) | aij > 0}. The bias network of a sequence s is G(s) := G(Bskew(s)) with edge
set E(s) = E(Bskew(s)).

Deﬁnition 3.28. A tournament is a complete oriented graph.

Deﬁnition 3.29. A digraph D with edge-set E is transitive if (v1, v3) ∈ E whenever
(v1, v2), (v2, v3) ∈ E.

The vertices of a transitive tournament can be totally ordered by reachability

(i.e., vertex v precedes vertex u in the ordering if (v, u) is an edge). The following
lemma shows one way in which bias networks generalize neuronal templates: by

unambiguously inducing a total ordering in the case of a pure sequence.

46

Sequence s

Bskew(s)

γ(s)

Bias matrix

G(s)

Bias network

ρ (cid:55)→ Bskew(s)T ρ

Center-of-mass

σ(s)

Neuronal ordering

Recurrent network model

Network synﬁre chain

Figure 3.2: The bias network model. This diagram represents how the bias net-
work serves as a generalization of neuronal templates. Starting with a sequence s,
the center-of-mass vector and ordering can be computed directly (right side). Alter-
nately, the same vectors can be computed via the bias matrix; this also allows for the
generation of other orderings by varying the ﬁring-rate vector ρ used to generate the
center-of-mass vector. The dashed line across the middle indicates that, in the case
of pure sequences, the center-of-mass ordering is recoverable from the bias network,
as shown in Lemma 3.30. At the bottom level, these two combinatorial objects can
be used to generate sequences using recurrent networks and network synﬁre chains,
topics beyond the scope of this paper.

Lemma 3.30. If A is a pure-bias matrix, then G(A) is a transitive tournament.

Proof. Let N = [n]. If n = 1, then the claim is trivially true. Let s be a sequence
with Bskew(s) = A, and suppose that n > 1. Since s is pure, some neuron i ∈ N must
spike ﬁrst. Then s|N\{i} is a pure sequence on n − 1 neurons. By induction on n, we
have that G(Bskew(s|N\{i})) is a transitive tournament. Because i precedes all other
neurons, we have that βij(s) = 1 for each j ∈ N \ {i}. In particular, this means that
the graph G(Bskew(s)) = A is transitive, completing the proof.

As a result of Lemma 3.30, it is clear that all possible transitive tournaments can

be realized as the bias network of some sequence. But it is not obvious which other

digraphs are realizable, and it would be surprising if a sequence could be constructed

to match an arbitrary list of pairwise orderings (as a simple digraph speciﬁes).

Question 3.31. Which digraphs are realizable as the bias network of some sequence?

The following examples explore this question.

47

Example 3.32. The sequence s = 12444433131124 has skew-bias matrix

 0

−1/4
1/3
1/5

 .

1/4 −1/3 −1/5
0 −1/5
0
0 −3/5
0
0
3/5
1/5

This allows us to easily see that G(s) has adjacency matrix

0 1 0 0
 .

0 0 0 0
1 0 0 0
1 1 1 0

Graphically, we can visualize G(s) as below.

1

3

2

4

Notice that G(s) is not a tournament because it does not contain an edge between
vertices 2 and 3, which happened because β23(s) = β32(s) = 0.

Example 3.33. The sequence s = 2331112123 has bias network G(s) with adjacency
matrix

0 1 0
 .

0 0 1
1 0 0

Graphically, G(s) is shown below.

48

1

2

3

So G(s) is clearly not transitive since (1, 2), (2, 3) ∈ E(s) but (1, 3) /∈ E(s).

The answer to 3.31 is surprising: We have control over each individual tendency

in a bias network.

Theorem 3.34. Every bias network is possible.

To prove this theorem, we ﬁrst need some other results and deﬁnitions.

Deﬁnition 3.35. The reverse of a sequence s = (s1, . . . , s(cid:96)) is the sequence sT =
(s(cid:96), s(cid:96)−1, . . . , s1).

Note that the reverse of the reverse of a sequence is the original sequence; that
is (sT )T = s for any sequence s ∈ S. The reason for the notation sT is seen in the
following lemma.

Lemma 3.36. For any sequence s, Bskew(sT ) = Bskew(s)T .

Proof. Consider neurons i, j ∈ N . For each index pair (k, k(cid:48)) ∈ Lij(s), we must have
that (k(cid:48), k) ∈ Lji(sT ). Similarly, for each index pair (m, m(cid:48)) ∈ Lij(sT ), we must have

that (m(cid:48), m) ∈ Lji(s). Hence, cij(s) = |Lij(s)| = (cid:12)(cid:12)Lji(sT )(cid:12)(cid:12) = cji(sT ) for arbitrary

neuron pairs. Now,

βji(sT ) =

cji(sT ) − cij(sT )
cji(sT ) + cij(sT )

=

cij(s) − cji(s)
cij(s) + cji(s)

= βij(s) = −βji(s).

In particular, Bskew(sT ) = −Bskew(s) = Bskew(s)T since Bskew is skew-symmetric, thus
ﬁnishing the proof.

Lemma 3.37. Given a sequence s, a sign value a ∈ {−1, 1}, and distinct neurons
i, j ∈ N , there is a sequence s(cid:48) such that

49

1. sign(βij(s(cid:48))) = a and

2. sign(βqr(s(cid:48))) = sign(βqr(s)) for {q, r} (cid:54)= {i, j}.

Proof. Recall that, for any distinct neurons i, j ∈ N , βij = cij−cji
. Since cij + cji
is a count of neuron pairs, it is positive; in particular, this tells us that sign(βij) =
sign(cij − cji). Now, let s ∈ S be given and ﬁx i, j ∈ N as distinct neurons.

cij +cji

Since Bskew is skew-symmetric, assume without loss of generality that a = 1 (by
exchanging i and j if a = −1). Pick k ∈ N such that 2k2 > cji(s) − cij(s), and
deﬁne s(cid:48) := ik · jk · s · ik · jk. We will ﬁrst show that βij(s(cid:48)) > 0, implying that
sign(βij(s(cid:48))) = 1 = a. Note that cij(s(cid:48)) = 3k2 + k · cj(s) + ci(s) · k + cij(s) and that
cji(s(cid:48)) = k2 + k· ci(s) + cj(s)· k + cji(s). Now, cij(s)− cji(s) = 2k2 + cij(s)− cji(s) > 0,
as claimed.

Let q, r ∈ N be distinct with {q, r} (cid:54)= {i, j}. Suppose that {q, r} ∩ {i, j} = ∅.
Then βqr(s(cid:48)) = βqr(s(cid:48)|N\{i,j}) = βqr(s|N\{i,j}) = βqr(s). In particular, sign(βqr(s(cid:48))) =
sign(βqr(s)). Now, suppose that q ∈ {i, j} but r /∈ {i, j}. Then cqr(s(cid:48)) = k · cr(s) +
cqr(s) and crq(s(cid:48)) = crq(s) + cr(s) · k; hence, cqr(s(cid:48)) − crq(s(cid:48)) = cqr(s) − crq(s).
In
particular, sign(βqr(s(cid:48))) = sign(cqr(s(cid:48)) − crq(s(cid:48))) = sign(cqr(s) − crq(s)) = sign(βqr(s)).
Therefore, the lemma holds.

Deﬁnition 3.38. A sequence s is a palindrome if sT = s.

Lemma 3.39. If s ∈ S([n]) is a palindrome, then Bskew(s) = 0n, where 0n is the
n × n zero matrix.

Proof. Since s is a palindrome, we have that s = sT . Using Lemma 3.36 and the fact
that the skew-bias matrix is skew-symmetric, we have that Bskew(s) = Bskew(sT ) =

50

Bskew(s)T = −Bskew(s). In particular, βij(s) = −βij for each i, j ∈ N , implying that
βij = 0. This completes the proof.

We are now ready to show that every simple digraph is realizable as a bias network.

Proof of Theorem 3.34. Let D be an arbitrary digraph. Then D has skew-symmetric
adjacency matrix A ∈ {−1, 0, 1}n×n. We want to show that there exists a sequence s
on neuron set N = [n] such that Bskew(s) = A.

Let s0 be a palindrome with supp(s0) = N . By Lemma 3.39, we know that
Bskew(s0) = 0n is the n × n zero matrix. Deﬁne I := {(i, j) ∈ N s | aij > 0} to be
the set of index pairs at which A is positive, and let I = {(i1, j1), . . . , (im, jm)} be an
enumeration of I. We proceed by induction on m. If m = 1, then A has only one
positive entry ai1j1
. Since s0 is the zero matrix, Lemma 3.37 provides a sequence s1
such that βi1j1(s1) = 1 and βqr(s1) = 0 for all q, r ∈ N with {q, r} (cid:54)= {i, j}; that is
Bskew(s1) = A.

Suppose now that m > 1, and assume for induction that there is a sequence
sm−1 such that βimjm(sm−1) = βjm,im(sm−1) = 0 and βqr(sm−1) = aqr for all other
q, r ∈ N . Lemma 3.37 now provides a sequence sm such that βimjm(sm) = 1 and
βqr(sm) = βqr(sm−1) for all other q, r ∈ N . Then Bskew(sm) = A. Hence, by induction,
the lemma holds for any m > 0.

51

Chapter 4

Comparing sequences

4.1 Correlation between sequences

In the brain, it is often the case that signals are very noisy (due to neuronal mis-

ﬁres, improper spike sorting, etc.); as a result, comparing sequences directly to each

other may not be so eﬀective. Additionally, complications arise when one wants, for

instance, to compare relatively long neuronal sequences (e.g., place-ﬁeld sequences)

to relatively short neuronal sequences (e.g., SWR sequences): How does one mean-

ingfully (and generically) compare a sequence with 10 spikes to a sequence with 100

spikes? Even if a meaningful comparison were developed to directly compare the se-

quences, this comparison would likely be computationally expensive since these tech-

niques usually involve modifying one sequence until it becomes the other sequence.

As we attempt to compare sequences in a less direct way, we must ask a natural

question: What does it mean for two sequences to be similar (or even "the same")?

As we will hopefully show, the bias matrix provides a somewhat natural framework

for answering this question and, thus, for comparing sequences.

Recall that the bias matrix arose out of an attempt to generalize our intuitive

52

Figure 4.1: Spike raster plot of an impure sequence that induces an unambiguous
neuronal ordering

notion of a pure neuronal sequence. Even with this representation of sequences as

biases (which are vectors), careful consideration should be given to what method

is employed to compare these vectors.

It is tempting to want to compare biases

using the standard Euclidean distance, but this may not be the most meaningful of

comparisons. To see this, once again consider pure sequences. Recalling Lemma 3.6,

the bias matrix of a pure sequence contains suﬃcient information to determine the

original neuronal ordering. Pure sequences, though, are not the only sequences for

which the bias matrix allows us to unambiguously reconstruct an ordering in the same

manner. Indeed, some of the sequences corresponding to these other bias matrices

even match up well with our original intuition.

Example 4.1. Consider the spike-raster plot in Figure 4.1. Though the spikes of the
neurons are interlaced, it seems obvious to the casual observer that there is only one

neuronal ordering that makes sense: neuron 1 ﬁres, then neuron 2, and ﬁnally neuron
3. This casual observation seems slightly less obvious when considering the sequence
representation s = 123123, but it emerges again upon computing the bias matrix:

 0

Bskew(s) =

 =

1/2
−1/2
0
−1/2 −1/2

1/2
1/2
0

1
2

Bskew(123).

The skew-bias matrix of s is a scaling of that of the pure sequence 123. As such,
Bskew(s) induces the same ordering as Bskew(123), namely the ordering (1, 2, 3).

From this perspective, it seems that the underlying "ordering," if you will, of a

12353

bias matrix is characterized simply by the direction in which the bias matrix points

(when considered as a vector). This further suggests that the magnitude of a bias

vector is not so much an indication of an underlying order as it is an indication of the

purity of a sequence. It is with this perspective that we deﬁne a correlation between

sequences.

Deﬁnition 4.2. We deﬁne the product of sequences s and s(cid:48) to be (cid:104)s, s(cid:48)(cid:105) :=(cid:80)
Bskew(s(cid:48)|ω). Also, we deﬁne the magnitude of a sequence s to be (cid:107)s(cid:107) :=(cid:112)(cid:104)s, s(cid:105). With

for ω = supp(s) ∩ supp(s(cid:48)). Note that (cid:104)s, s(cid:48)(cid:105) = (cid:104)s|ω, s(cid:48)|ω(cid:105) = (cid:104)Bskew(s|ω), Bskew(s(cid:48)|ω)(cid:105),
where the last expression is the standard Euclidean inner product of Bskew(s|ω) and

i,j∈ω βij(s)βij(s(cid:48))

these expressions in hand, we can ﬁnally deﬁne the correlation of sequences s and s(cid:48)
to be

corr(s, s(cid:48)) :=

(cid:13)(cid:13)s|supp(s(cid:48))

(cid:104)s, s(cid:48)(cid:105)

(cid:13)(cid:13) ·(cid:13)(cid:13)s(cid:48)|supp(s)

(cid:13)(cid:13)

In terms of geometry, corr(s, s(cid:48)) is the cosine of the angle between Bskew(s|ω) and
Bskew(s(cid:48)|ω), where again ω = supp(s) ∩ supp(s(cid:48)). In these deﬁnitions, we restrict to
the common set of neurons in part because noise is a major consideration in real

data. A real sequence might contain a spike from a neuron that should not have been

active but not contain a spike from a neuron that should have been active. Though

we cannot know for sure which spikes "should" and "should not" be in a sequence,

we attempt to mitigate this problem slightly by comparing sequences based only on

the collection of neurons that are active in both sequences.

Example 4.3. Let s = 12444433131124 and s(cid:48) = 2431. Then

0 −1 −1 −1
 .

1
1
0 −1
0
1

1
0
1 −1
1 −1

 0

−1/4
1/3
1/5



1/4 −1/3 −1/5
0 −1/5
0
0 −3/5
0
0
3/5
1/5

Bskew(s) =

and

Bskew(s(cid:48)) =

Noting that supp(s) = supp(s(cid:48)) = [4], the correlation between s and s(cid:48) is corr(s, s(cid:48)) =
(cid:104)s,s(cid:48)(cid:105)
(cid:107)s(cid:107)·(cid:107)s(cid:48)(cid:107). Now, each component of this can be computed as follows:

54

(cid:104)s, s(cid:48)(cid:105) =

βij(s)βij(s(cid:48))

4(cid:88)

j=i+1

= 2

i,j∈N

(cid:88)
4−1(cid:88)
= 2(cid:0)− 1
(cid:113)
2(cid:0) 1

41
60

i=1

=

βij(s)βij(s(cid:48))

4 + 1

3 + 1

5 + 0 − 1

5 + 3

5

(cid:1)

(cid:1) =

√
47

2

60

(cid:107)s(cid:107) =
(cid:107)s(cid:48)(cid:107) =

√

16 + 1
9 + 1
√

12 = 2

3

25 + 0 − 1

25 + 9

25

Putting this all together, we ﬁnd that corr(s, s(cid:48)) = 41
√

47

≈ 0.6168.

6

4.2 Signiﬁcance of correlation

While we do now have the ability to compare arbitrary sequences using our correla-

tion measure, there is still an issue to be addressed: How do we interpret a correlation

value? Despite coming to the bias-matrix representation of a sequence and the corre-

lation measure by fairly intuitive means, a correlation value does not seem to have an

intuitive interpretation beyond (1) its sign indicating correlation or anti-correlation

and (2) larger magnitude indicating strength of (anti-)correlation.

In Figure 4.2, we see an example of how a correlation value alone does not nec-

essarily say so much about the similarity of two sequences. Why does something

like this happen? This is partly an issue of angles and dimensionality. Consider the

pure sequences in Figure 4.2b. By moving just a single spike, we modiﬁed a large

55

(a) Arm-run

(b) Pure

Figure 4.2: Both of these pairs of sequences seem to be similar (to the eye), so we
might expect them to have relatively high correlation values. However, neither pair
does: The arm-run sequences have a correlation value of 0.52572, and the pure se-
quences have a correlation value of 0.2. These low values are somewhat unsatisfactory
since maximally uncorrelated sequences have a correlation value of zero.

proportion of the entries in the pairwise-bias matrix. If these short sequences had a

common subsequences prepended to them, then the correlation value would be much

higher even though the same number of spikes are "out of order"; this is because a

much larger percentage of the pairwise-bias matrix entries are unmodiﬁed in this case.

When considering the arm-run sequences in Figure 4.2a, we notice that each of the

neurons has spikes that are interlaced with spikes from many of the other neurons.

When spikes are interlaced in a consistent way like in Example 4.1, bias matrices end

up being scalings of pure biases. These spikes, however, are not interlaced in such

consistent ways; and the result is that the bias matrices end up pointing in fairly

diﬀerent directions. Still, to the eye, these long arm-run sequences could be much

more diﬀerent from each other if we just shifted some of their spikes around.

And here we stumble onto some key intuition: We evaluate the similarity of one

sequence ˆs to another s not just on how close ˆs is to s but also on how much more
diﬀerent they could be from each other. In a sense, we ask the question of where their

similarity falls in relation to the similarities of other pairs of sequences.

Deﬁnition 4.4. Given sequences s and ˆs, the signiﬁcance of correlation of ˆs to s is
the proportion of shuﬄings of ˆs that are more strongly correlated to s than ˆs is to

Neuron #Neuron #56

s. More precisely, letting Π = {π ∈ Perms([(cid:96)(cid:48)]) : |corr(s, ˆs)| ≤ |corr(s, ˆsπ)|}, then the
signiﬁcance of the correlation of ˆs to s is sigs(ˆs) :=

.

|Π|
len(ˆs)!

Example 4.5. We used computational techniques (as will be described in Section 4.4)
to approximate the signiﬁcance values corresponding to the correlations of Figure 4.2.

In our simulations, the signiﬁcance of the correlation values of the arm-run sequences

and of the pure sequences were approximately 0.00 and 0.40, respectively. Using a

standard $p$-value of 0.05, This indicates that the correlation value between the arm-

run sequences is signiﬁcant but that the correlation value between the pure sequences

is not signiﬁcant.

4.3 Global signiﬁcance

The previous section allows us to compare collections of sequences while putting each

correlation on more even footing; i.e., we can set a threshold for signiﬁcance instead of

for (absolute value of) correlation. Now, we are brought to the question of similarity
of one collection of sequences to another. Let U = (u1, . . . , ua) and V = (v1, . . . , vb)
be lists of sequences in S. We want to ask how similar is U to V . One natural place
to start answering this question is to consider all of the correlation values between a

sequence in U and a sequence in V .

Deﬁnition 4.6. We deﬁne the correlation matrix between U and V to be Corr(U, V ) :=
[corr(u, v)]u∈U, v∈V .

Though we can look for commonalities and statistics among the entries of this

matrix (e.g., that it has all positive entries or by considering the distribution of

values), we face a similar problem as when looking at individual correlation values:

Aside from basic properties (such as having only positive entries), we do not have a

57

good interpretation of the magnitude of correlation (as demonstrated in the examples

of the previous section). As such, we will approach the answer to this qeustion in

the same way as for individual correlations: by considering signiﬁcance values. But

we will need to iterate the process, in a sense, because we are comparing collections

instead of just individual sequences.

Deﬁnition 4.7. Deﬁne the signiﬁcance matrix of correlation of U to V to be SigV (U ) :=
[sigv(u)]u∈U, v∈V .

The signiﬁcance matrix allows us to identify how signiﬁcantly correlated each se-

quence in U is to each sequence in V . Still, though, the question remains: How
do we convert this information to some sort of meaningful value to tell us how
similar U is to V ? Given a signiﬁcance parameter p ∈ (0, 1), we can count how
many pairs (u, v) ∈ U × V satisfy sigv(u) < p. Though this gives us, for in-
stance, the percentage of pairs that are signiﬁcantly correlated (as determined by

p), we have still not quite reached a satisfactory measure. What percentage of pairs
is a signiﬁcant percentage? It really depends on the collections U and V . As we
compared corr(s, ˆs) to a distribution in the previous section, we must ﬁnd an ap-
propriate distribution of values to which we can compare the count sigV (U, p) :=
|{(u, v) ∈ U × V | sigv(u) < p}|. Naturally, as before, we want to compare this value
to the counts gotten by comparing a random shuﬄing of the sequenes in U to
If (cid:126)π = (π1, . . . , πa) ∈ Π(U ) := Perms([len(u1)]) × ··· × Perms([len(ua)]), de-
V .
ﬁne U (cid:126)π := (uπ1
a ). Now, the global signiﬁcance of correlation of U to V is
1 , . . . , uπa
|A|

|Π(U )| where A =(cid:8)(cid:126)π ∈ Π(U ) | sigV (U (cid:126)π, p) ≥ sigV (U, p)(cid:9). Hence, we have

gV (U, p) =
a measure telling us how signiﬁcantly correlated the list U is to the list V .

58

4.4 Monte-Carlo computation of signiﬁcance

Mathematically, the signiﬁcance of correlation and global signiﬁcance of correlation

values described in the previous two sections allow us to have conﬁdence that two

sequences or two collections of sequences share (or do not share) similarities.

In

practice, however, the distributions necessary for computation of these values are often

prohibitively large. For instance, if ˆs is a sequence with only ten spikes, calculation of
sigs(ˆs) requires computation of over 3.6 million correlation values. And the situation
gets a lot worse as the length of ˆs grows, not to mention the added complexities when
trying to compute a global signiﬁcance value.

Because of this diﬃculty, we employ a Monte-Carlo method to approximate the

two types of signiﬁcance values.

In the analysis that follows in Section 5.3, each

sequence is a part of some collection of sequences. We leverage this fact by simulta-

neously approximating the distribution for both types of signiﬁcance values. Let T
be some (large) natural number representing the number of trials in our Monte-Carlo
approximations. Further, let U = (u1, . . . , ua) and V be lists of sequences; and let
p ∈ (0, 1) be a signiﬁcance parameter. For each u ∈ U and each v ∈ V , we will
approximate sigv(u) in such a way that the resultant distribution approximations
of all such pairings can also be used to approximate the distributions necessary for
computing gV (U, p).

Let (cid:126)π1, . . . , (cid:126)πT ∈ Π(U ) be T randomly selected lists of permutations. For each
t ∈ [T ], we compute and store the correlation matrix Corr(V, U (cid:126)πk). This list of
correlation matrices will allow us to approximate all signiﬁcance values. First, to
compute sigv(um), note that the list corr(v, uπ1,m
m ) can be extracted

from the list of correlation matrices; hence, we approximate sigv(um) by (cid:99)sigv(um) =

m ), . . . , corr(v, uπT,m

|A|
T

where A = {t ∈ [T ] : | corr(v, um)| < | corr(v, uπt,m

m )|}.

Indeed, this process

produces an approximation (cid:99)SigV (U ) of the signiﬁcance matrix SigV (U ).

59

To approximate gV (U ) using the list of computed correlation matrices, we note
ﬁrst that the list U (cid:126)πk is a shuﬄing not only of the list U but also of the list U (cid:126)πt(cid:48) for each
t(cid:48) ∈ [T ] \ {t}. As such, we can also approximate the signiﬁcance matrices SigV (U (cid:126)πt)
by (cid:99)SigV (U (cid:126)πt) = [(cid:99)sigv(uπt,m
where A = {t(cid:48) ∈ [T ] :
m )|}. With these matrices in hand, the approximation
of gV (U, p) is straightforward: Let(cid:99)sigV (U(cid:48), p) = |{(u, v) ∈ U × V :(cid:99)sigV (U(cid:48), p)}|, from
πt(cid:48),m

m )]v∈V,m∈[a] with (cid:99)sigv(uπt,m

where A = {t ∈ [T ] :(cid:99)sigV (U (cid:126)πt, p) ≥(cid:99)sigV (U, p)}.

which we deﬁne ˆgV (U, p) =

|A|
T

| corr(v, uπt,m

m )| < | corr(v, u

m ) =

|A|
T

60

Chapter 5

Experimental set-up and data

analysis

The tools introduced in the preceding chapters were developed for use in the anal-

ysis of real-world data. The lab of Eva Pastalkova at the Howard Hughes Medical

Institute’s Janelia Research Campus graciously provided all of the data used in this

document. The following section describes the experimental setup from which this

data was collected and the various types of neuronal sequences that are considered in

our analysis. Section 5.2 then describes details of our sequence detection techniques.

Finally, Section 5.3 uses bias matrices to perform some basic analyses of the data.

5.1 The experimental setup and event types

Rats were trained to perform a basic memory task in the U-shaped track pictured in

Figure 5.1. In short, the task of the animal can be described as follows: To receive a

reward, the animal must alternate between running to the left reward port and the

right reward port. The task is complicated for the animal by the delay area, which

61

Figure 5.1: Alternation memory task. The three main areas of interest for this task
are (1) the delay area and running wheel, (2) the left and right arms/corridors, and
(3) the reward area at the end of each arm. The dotted lines surrounding the delay
area represent mechanically movable doors that are used to hold the animals in the
delay area until the wheel-run portion of each trial has been completed.

forces the animal to run in the running wheel for a speciﬁed amount of time before the

doors of the delay area open and allow the animal to proceed toward a reward port.

Each trial of the experiment consists of a run in the wheel, a visit to a reward port,

and a return to the delay area. By requiring the animal to spend time running in the

wheel before choosing to run to the left or right, the animal is forced to remember

the arm to which it should next run instead of being allowed to run immediately from

one arm to the other.

In addition to performing this task under normal conditions, each animal per-

formed the task after the drug muscimol had been injected into the animal’s medial

septum. This injection has the eﬀect of shutting down the medial septum, which is

the area of the brain that serves as the primary drive of the theta oscillations that

are thought to be an integral part of the generation of place-ﬁeld sequences in the

hippocampus during locomotion.

During performance of this task, the rat’s location within the track was recorded.

Further, local-ﬁeld potentials (LFPs) were recorded at various depths across the pyra-

midal layer of the CA1 region of the rat’s hippocampus. Neuronal spiking information

was then extracted from these LFPs via a process called spike sorting. For our pur-

WheelRewardportsLeft ArmRight ArmDelayarea62

poses, we will say that an event is all of the information (LFPs, spike trains, animal
location, etc.) within some time window. The sequence corresponding to an event is

the list of all spikes that occur within that event. The various event/sequence types

that we will be investigating are described below.

Wheel-run events are behavioral events recorded while the animal is running in
the wheel to satisfy the delay requirement. As such, each wheel-run event

is recorded over a period of approximately 10 seconds. These event types are

generally the longest in duration of all of the event types that we consider; thus,

the corresponding wheel-run sequences are usually the longest of our recorded

sequence types. Because the animals are running during these sequences, the

hippocampus exhibits a prominent theta oscillation under normal conditions.

Arm-run events are behavioral events recorded while an animal is running through
either arm of the track in either direction between the delay area and a reward

area. The duration of each arm-run event is the length of time that it takes

the animal to get where it is going, usually around 2 seconds. Though shorter

than wheel-run sequences, arm-run sequences are still usually quite long. The

locomotion of the animal is again accompanied by a prominent theta oscilla-

tion. Because the animals are actually moving through the track during these

sequences, the sequences exhibit place ﬁelds under normal conditions. We di-

vide these sequences into four subtypes based on the trajectory of the animal;

speciﬁcally, the animal can run to (outbound) or from (inbound) either the left

or right reward area.

Sharp-wave ripple (SWR) events usually occur while an animal is not in motion;
hence, they primarily occur in the reward areas and in the delay area outside

of the wheel, though we placed no explicit restrictions on the location or move-

63

ment of the animal in our detection of these events. As described in Section

1.1, these events are characterized by a hyper-polarization in the LFP across

the pyramidal layer in the CA1 region of the hippocampus, which generally

lasts from around 50 to 250 milliseconds. Given the shorter timescale than the

behavioral events, these sequences are generally much shorter than wheel-run

and arm-run sequences.

Reﬁned SWR events are the bursts of neuronal activity that accompany SWRs.
These bursts of activity are not always perfectly aligned with the corresponding

sharp wave, which (as we will see in the next section) is the feature we use to

detect the SWR events. Given that our analysis is performed on sequences of

neuronal spikes, it is important that we strive to ﬁnd the sequences of spikes

that most accurately represent the neuronal activity that accompanies the SWR

events, regardless of whether or not those sequences are aligned with the ac-

companying LFP envelope. This reﬁnement process results in the discarding

of many events that do not contain suﬃcient spiking information. Thus, there

are fewer reﬁned SWR sequences than (unreﬁned) SWR sequences; but the

sequences that remain are often longer.

5.2 SWR detection and reﬁnement

Unlike arm-run and wheel-run events, SWR events are not behavioral in nature.

In particular, no action or activity of an animal will tell us when a SWR event is

occurring. As such, we must ﬁnd a way to determine when these events are occurring.

To do this, we consider one prominent feature of SWR events: the sharp wave. During

a sharp wave, the LFPs across the pyramidal layer of CA1 become hyperpolarized,

resulting in the characteristic shape that has already been observed (see Figure 1.2).

Our method for detecting SWR events can be summarized as follows:

64

1. Select two LFP channels, a lower channel (i.e., one that drops in value during

SWRs) and an upper channel (i.e., one that increases in value during SWRs).

In lieu of an automated method for performing this, all of the LFP channels

were selected by hand. The selection process was done by gaining an inuitive

understanding of what SWR events look like and then by selecting the channels

that most-faithfully represented the desired LFP separation.

2. Center each LFP at zero by computing a local average for each. This is necessary

to account for changes in the LFPs that occur over a longer time scale than

SWRs occur on. To do this, we computed the average output for each channel

over the interval of one second preceding each point in time; we then subtracted

the resultant local averages from the original signals.

3. Create a single sharp-wave signal by subtracting the lower centered-LFP from

the upper centered-LFP, subtracting the overall mean of the resultant signal,

normalizing by the standard deviation of the resultant signal, and smoothing

the resultant signal using a gaussian ﬁlter.

4. Threshold the sharp-wave signal to determine initial estimates for SWR event

windows. We set the base-line threshold at 1.25 standard deviations of the

sharp-wave signal.

5. Filter, combine, and modify the initial event estimates to ensure that each event

satisﬁes properties characteristic of SWRs.

• Split single events into multiple events. Sometimes, SWRs happen close

enough together that the separation in the LFP from the ﬁrst event has

65

not ended before the separation from the second event has begun. As a

result, the detection process up to this point joins those multiple events

into a single event. This process of splitting is done by ﬁnding the peaks of

the second derivative of the smoothed sharp-wave signal; if a large enough

peak occurs within an event, then the event is split at that point in time.

• Remove events that do not last for some minimum amount of time (25

ms).

• Shorten events that last for too long. It is sometimes the case that the

minimum-required LFP separation of a detected event can persist for

longer than the underlying SWR event. To account for this while not

discarding legitimate SWRs, we enforce a maximum SWR duration (250

ms) by taking the event in a 250-ms time window surrounding the highest

point of LFP separation within the event.

• Remove events in which the peak of the sharp-wave signal is not large

enough (4 standard deviations of the sharp-wave signal).

• Remove events that do not contain a sudden LFP separation. Without

this characteristic feature, the event is not a SWR. We enforce this by

ensuring that the absolute value of the ﬁrst derivative of the sharp-wave

signal passes above a minimum value.

• Ensure that enough spikes happen close enough to each other within each

event. This is done by summing up gaussian functions centered at the

spikes within each event and ensuring that the resultant signal passes above

a minimum value.

The parameters used in this detection process were ﬁne-tuned by hand until the

resultant events were largely undeniably SWRs but also while not being so restrictive

66

(a) Normal condition

(b) Muscimol condition

(c) Doublet

(d) Needs reﬁnement

Figure 5.2: SWR events. Panels (a) and (b) show standard examples of SWRs.
Panel (c) shows an example of a doublet, two SWR events that occur so close in time
as to be joined together. Panel (d) shows an example of a SWR for which the burst
of neural activity signiﬁcantly precedes the accompanying sharp wave. Such an event
requires reﬁnement.

as to eliminate many good candidates for SWR events.

Although detection based on the sharp wave gives us a good starting place for

SWR detection, a detection algorithm based solely on the sharp wave is insuﬃcient

for our needs. While the bursts of neural activity in a SWR are (by deﬁnition) accom-

panied by a sharp wave, it is not the case that the two types of activity are perfectly

synchronized in time. See Figure 5.2d for an example of this. Since our analysis is

of neuronal sequences, it is crucial that we have as accurate a set of sequences as

possible. Our attempt to extract the events corresponding to the neuronal-activity

bursts of SWR events consists of four basic steps:

50 ms50 ms50 ms50 ms67

1. Detect the intrinsic sequences of a recording. These are formed by splitting the

spike train of a recording wherever the gap between successive spikes exceeds

some threshold and then by extracting the sequences from each resultant spike

train.

2. Discard all intrinsic sequences that do not overlap with any SWR event.

3. Join together those intrinsic sequences that overlap with a common SWR event.

The idea is that the SWR event should represent a single pice of sequential

information. Any gap that occurs within such a joining of intrinsic sequences

is justiﬁed as being within a single sequence by arguing that other neurons—

neurons that were not detected—were likely spiking within that interval.

4. Of the resulting collection of sequences, keep only those that meet certain re-

quirements. First, we impose a requirement on the minimum number of active

neurons; a sequence does not contain much useful information to us if, for in-

stance, it contains spikes from only one neuron. Next, we impose a duration

condition; there is reason to believe that SWRs have minimum and maximum

duration. Lastly, we require that the sequence is isolated in time from its near-

est intrinsic sequences; this is an attempt to ensure that the activity captured

by the sequence is a burst of activity accompanying a SWR and not due to

increased neural activity in the area for some other reason.

This process generally results in signiﬁcantly fewer events than the sharp-wave detec-

tion process.

68

5.3 Sequence comparison in in-vivo hippocampus

It is believed that theta oscillations are necessary for the generation of hippocam-

pal sequences. Analyses suggesting this result [10] compare observed hippocampal

sequences under normal and theta-inhibited (i.e., muscimol) conditions to neuronal

templates generated, for instance, by considering the order of place ﬁelds in a track

under normal conditions. The introduction of the bias matrix allows for the direct

comparison of observed sequences to each other. In this section, we use the techniques

of Chapter 4 to perform similarity analyses on the hippocampal sequences described

in Section 5.1. In particular, we will attempt to determine whether the sequences

generated under the inﬂuence of muscimol are diﬀerent from those generated under

normal conditions. For reference, brief descriptions of the sequence types are given

in Table 5.1.

Table 5.1: Hippocampal sequence types.

Type
Wheel-run

Subtypes

Arm-run

Reﬁned SWR

Left / outbound
Left / inbound
Right / outbound and a reward area
Right / inbound

Description
Behavioral sequences generated during the
enforced delay period while running in
the wheel
Behavioral sequences generated as an animal
traverses a path between the delay area

Non-behavioral sequences from SWRs

Question 5.1. Are hippocampal sequences the same after elimation of theta oscilla-
tion?

In the end, our analysis suggests that eliminating theta oscillation eliminates (at

least some of) the structure of behavioral hippocampal sequences. We approach this

Question by setting reference sets of sequences to which we can compare normal-
condition sequences and muscimol-condition sequences. Since the question we are

69

trying to answer is about whether there is a change from the normal behavior, these

reference sets should consist of normal-condition sequences. For instance, when com-

paring normal-condition wheel-run sequences to muscimol-condition wheel-run se-

quences, the reference set will be the collection of normal-condition wheel-run se-

quences. The basic tools used in this section are the correlation and signiﬁcance

matrices introduced in Section 4.3. Figure 5.3 provides an example of the correlation

and signiﬁcance matrices for each sequence type. The examples in this ﬁgure illustrate

how the correlation matrix can be a useful tool for observing structure in collections

sequences. In particular, notice the diﬀerence in the matrix structure between wheel,

arm, and SWR correlations. Where the wheel-run correlation matrix displays that all

correlations are positive, the arm-run correlation matrix shows positive and negative

correlations existing in a highly structured manner (switching sign as we go between

comparing subtypes of these sequences); the SWR correlation matrix, on the other

hand, shows that positive and negative correlations exist in a much less structured

way.

The diﬀerences in structure between the correlation matrices shown in Figure 5.3

can be observed over all data sets in Figure 5.4, which shows histograms of the

correlation values for the diﬀerent types. For instance, looking at the distributions

of correlation values for arm-run sequences, the normal-condition correlations tend

to be more positive than the muscimol-condition correlations. This observation is

in line with the intended purpose of the muscimol injections to eliminate the theta

oscillation that is believed to aid in the formation of place-ﬁeld sequences.

In addition to looking for changes in the distributions of correlation values after

injection of muscimol, we also investigate the change in proportion of correlations

that are signiﬁcant after injection of muscimol, as shown in Figure 5.5. For behav-

ioral events, muscimol is accompanied by a reduction in the proportion of correlations

70

that are signiﬁcant. The reduction is somewhat modest for arm-run sequences when

compared to the reduction for wheel-run sequences. This suggests that theta oscilla-

tion is more critical for the formation of normal-condition wheel-run sequences than

for the formation of normal-condition arm-run sequences.

In conclusion, our analysis demonstrates via bias-matrix correlations that behav-

ioral hippocampal sequences lose some of their structure when theta oscillation is

removed by the injection of musimol into an animal’s medial septum.

71

(a) Wheel correlation

(b) Wheel signiﬁcance

(c) Arm correlation

(d) Arm signiﬁcance

(e) SWR correlation

(f) SWR signiﬁcance

Figure 5.3: Correlation and signiﬁcance matrices. Red entries indicate positive corre-
lation, blue entries indicate negative correlation, and white entries indicate incompa-
rable sequences; in signiﬁcance matrices, gray entries indicate insigniﬁcant correlation
values. Panels (a) and (b) show that all wheel sequences are positively correlated to
each other and that a majority of the correlations are signiﬁcant. Panels (c) and (d)
show matrices for arm-run sequences; events are sorted by their subtypes: left/out-
bound, left/inbound, right/outbound, left/inbound. Lines delineate subtypes. The
checkering pattern indicates postitive correlation within a subtype and negative cor-
relations between inbound and outbound events. Few correlations between subtypes
are signiﬁcant. Panels (e) and (f) show the sparsity of correlation matrices for SWR
sequences; additionally, few of the comparable SWR events are signiﬁcantly corre-
lated. The all-red diagonals indicate that each event is positively and signiﬁcantly
correlated to itself. All matrices were generated from the same recording.

72

(a) Wheel correlation

(b) Arm correlation

(c) SWR correlation

Figure 5.4: Histograms of correlation values. For each type of sequence, the corre-
sponding plot above shows the distribution of correlation values for normal-condition
and muscimol-condition correlation values across all data sets.
In panel (a), the
wheel-run histograms show the greater tendency of normal-condition sequences to
be positively correlated (88.75% positive) than their muscimol counterparts (67.86%
positive). Panel (b) illustrates a similar phenomenon for normal-condition arm-run
sequences to exhibit stonger positive correlations than their muscimol counterparts.
Panel (c) shows a much less pronounced diﬀerence when considering SWR sequences,
though the two-sample Kolmogorov-Smirnov test indicates that the distributions are
indeed diﬀerent (p-value of 0.0097).

-1-0.500.5100.020.040.060.080.1NormalMuscimol-1-0.500.5100.010.020.030.040.050.06NormalMuscimol-1-0.500.5100.020.040.060.08NormalMuscimol73

(a) Wheel

(b) Arm

(c) SWR

Figure 5.5: Proportion of correlations that are signiﬁcant. For each recording and
each correlation/signiﬁcance matrix, we consider the proportion of signiﬁcance values
that are below some threshold (0.05); this process results in two values, one for
the normal-condition sequences and one for the muscimol-condition sequences, the
horizontal and vertical axes, respectively, of the plots above. Panels (a) and (b) show
that injection of muscimol is accompanied by a systematic drop in the proportion
signiﬁcant correlations for both sets of behavioral sequences. This universal drop in
signiﬁcance is not observed when considering SWR sequences in panel (c).

00.5100.20.40.60.81NormalMuscimolNormal00.20.4Muscimol00.10.20.30.400.050.100.020.040.060.080.1NormalMuscimol74

Appendix A

Data analysis codebase

Much of the code written for the data analysis performed in this thesis is stored
in a Git repository at https://github.com/zjroth/neural-events along with a
corresponding README ﬁle.

75

Appendix B

Supplementary ﬁgures

(a) Normal condition

(b) Muscimol condition

(c) Increase of occurrence

Figure B.1: SWR occurrence. Panel (a) shows that under normal conditions, SWR
events occur almost exclusively at the reward areas, though some small number occur
within the delay area. Panel (b) shows that injection of muscimol is accompanied by
an increased number of SWRs occurring within the delay area. Panel (c) shows the
ratio of the number of muscimol events to the number of normal-condition events on
a per-recording basis.

Ratio0204076

(a) Wheel

(b) Wheel

(c) Arm

(d) Arm

(e) SWR

(f) SWR

Figure B.2: Sequence length. The left column shows the relationship between the
duration of an event and the corresponding sequence’s length. The right column
shows the relationship between the total number of neurons that are active within an
event and the corresponding sequence’s length. Each plot in the right column shows
that a linear dependence exists between the number of active cells in an event and
the total length of the sequence.

Duration5101520Sequence length050010001500Number of active cells050100150050010001500Sequence lengthDuration010203040Sequence length020040060080010001200Number of active cells050100150020040060080010001200Sequence lengthDuration00.050.10.150.20.25Sequence length020406080100120Number of active cells020406080020406080100120Sequence length77

(a) Wheel-run. Median: 13.30 /
12.94; KS: 0.0046

(b) Arm-run. Median: 1.84 / 2.16;
KS: 1.

(c) Left / outbound. Median: 1.66
/ 1.96; KS: 0.

(d) Left / inbound. Median: 2.25 /
2.74; KS: 1.

(e) Right / outbound. Median: 1.64
/ 1.97; KS: 8.

(f) Right / inbound. Median: 2.65
/ 2.70; KS: 0.

(g) Reﬁned SWR. Median: 0.084 /
0.082; KS: 2.99

Figure B.3: Event duration. For each event type, the distribution of event durations
is shown under normal (solid line) and muscimol (dashed line) conditions. The me-
dian of each distribution is shown as normal / median. In each case, the two-sample
Kolmogorov-Smirnov test (KS) tells us the p-value with with we reject the null hy-
pothesis that the two distributions are the same. For each behavioral event type
(all but SWR), the injection of muscimol tends to create slightly longer events. In
contrast, muscimol tends to create slightly shorter SWR events.

8910111213141500.511.5NormalMuscimol0246800.51NormalMuscimol0246800.511.52NormalMuscimol0246800.20.40.6NormalMuscimol0246800.511.52NormalMuscimol0246800.20.40.6NormalMuscimol00.050.10.150.20.25051015NormalMuscimol78

Figure B.4: Number of active neurons. The vertical axis shows the ratio of the median
number of active neurons in a muscimol event to the median number of active neurons
in an event under normal conditions. After injection of muscimol, the median number
of active cells in wheel-run sequences tends to decrease slightly, whereas the median
number of The median number of active neurons changes after. No change is observed
in the number of active neurons in arm-run sequences.

WheelArmSWR1.610.4Ratio79

Bibliography

[1] J. G. White et al. “The Structure of the Nervous System of the Nematode

Caenorhabditis elegans”. In: Philosophical Transactions of the Royal Society B:
Biological Sciences 314.1165 (1986), pp. 1–340. doi: 10.1098/rstb.1986.0056.
url: http://dx.doi.org/10.1098/rstb.1986.0056.

[2] Frederico A.C. Azevedo et al. “Equal numbers of neuronal and nonneuronal

cells make the human brain an isometrically scaled-up primate brain”. In: J.
Comp. Neurol. 513.5 (2009), pp. 532–541. doi: 10 . 1002 / cne . 21974. url:
http://dx.doi.org/10.1002/cne.21974.

[3] W. B. Scoville and B. Milner. “LOSS OF RECENT MEMORY AFTER BILAT-

ERAL HIPPOCAMPAL LESIONS”. In: Journal of Neurology, Neurosurgery &
Psychiatry 20.1 (1957), pp. 11–21. doi: 10.1136/jnnp.20.1.11. url: http:
//dx.doi.org/10.1136/jnnp.20.1.11.

[4] J. O'Keefe and J. Dostrovsky. “The hippocampus as a spatial map. Preliminary

evidence from unit activity in the freely-moving rat”. In: Brain Research 34.1
(1971), pp. 171–175. doi: 10 . 1016 / 0006 - 8993(71 ) 90358 - 1. url: http :
//dx.doi.org/10.1016/0006-8993(71)90358-1.

[5] W. E. Skaggs et al. “Theta phase precession in hippocampal neuronal popu-

lations and the compression of temporal sequences.” eng. In: Hippocampus 6.2

80

(1996), pp. 149–172. issn: 1050-9631. doi: 10.1002/(SICI)1098-1063(1996)
6:2&lt;149::AID-HIPO6&gt;3.0.CO;2-K. url: http://www.ncbi.nlm.nih.
gov/pubmed/8797016.

[6] George Dragoi and György Buzsáki. “Temporal Encoding of Place Sequences

by Hippocampal Cell Assemblies”. In: Neuron 50.1 (2006), pp. 145–157. doi:
10.1016/j.neuron.2006.02.023. url: http://dx.doi.org/10.1016/j.
neuron.2006.02.023.

[7] George Dragoi and Susumu Tonegawa. “Preplay of future place cell sequences by

hippocampal cellular assemblies”. In: Nature 469.7330 (2010), pp. 397–401. doi:
10.1038/nature09633. url: http://dx.doi.org/10.1038/nature09633.

[8] Gabrielle Girardeau et al. “Selective suppression of hippocampal ripples impairs

spatial memory”. In: Nature Neuroscience 12.10 (2009), pp. 1222–1223. doi:
10.1038/nn.2384. url: http://dx.doi.org/10.1038/nn.2384.

[9] Kamran Diba and György Buzsáki. “Forward and reverse hippocampal place-

cell sequences during ripples”. In: Nature Neuroscience 10.10 (2007), pp. 1241–
1242. doi: 10.1038/nn1961. url: http://dx.doi.org/10.1038/nn1961.

[10] Yingxue Wang et al. “Theta sequences are essential for internally generated

hippocampal ﬁring ﬁelds”. In: Nature Neuroscience 18.2 (2014), pp. 282–288.
doi: 10.1038/nn.3904. url: http://dx.doi.org/10.1038/nn.3904.

[11] Michaël Zugaro. Freely Moving Animal (FMA) Toolbox. 2010. url: http://

fmatoolbox.sourceforge.net/ (visited on 07/06/2015).

[12] Lav R. Varshney et al. “Structural Properties of the Caenorhabditis elegans

Neuronal Network”. In: PLoS Computational Biology 7.2 (2011). Ed. by Olaf
Sporns, e1001066. doi: 10.1371/journal.pcbi.1001066. url: http://dx.
doi.org/10.1371/journal.pcbi.1001066.

[13] Masami Tatsuno, ed. Analysis and Modeling of Coordinated Multi-neuronal Ac-
tivity. Springer New York, 2015. doi: 10.1007/978- 1- 4939- 1969- 7. url:
http://dx.doi.org/10.1007/978-1-4939-1969-7.

81

