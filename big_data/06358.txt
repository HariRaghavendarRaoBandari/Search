6
1
0
2

 
r
a

 

M
1
2

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
8
5
3
6
0

.

3
0
6
1
:
v
i
X
r
a

Multiplicative Prior and Sequential Monte Carlo Methods

for Multiple Gaussian Graphical Models

Linda S. L. Tan∗, Ajay Jasra∗, Maria De Iorio† and Timothy M. D. Ebbels‡

email: statsll@nus.edu.sg; staja@nus.edu.sg; m.deiorio@ucl.ac.uk; t.ebbels@imperial.ac.uk

∗ Department of Statistics and Applied Probability, National University of Singapore

† Department of Statistical Science, University College London
‡ Department of Surgery and Cancer, Imperial College London

Abstract

We propose using the multiplicative (or Chung-Lu random graph) model as a prior

on graphs for Bayesian inference of Gaussian graphical models (GGMs). In the mul-

tiplicative model, each edge is chosen independently with probability equal to the

product of the connectivities of the end nodes. This class of prior is parsimonious yet

highly ﬂexible; it can be used to encourage sparsity or graphs with a pre-speciﬁed

degree distribution when such prior knowledge is available. We further extend the mul-

tiplicative model to multiple GGMs linking the probability of edge inclusion through

logistic regression and demonstrate how this leads to joint Bayesian inference for mul-

tiple GGMs. A sequential Monte Carlo (SMC) algorithm is developed for estimating

the posterior distribution of the graphs. We illustrate the performance of the proposed

methods on simulated data and an application which investigates the eﬀect of cadmium

(a toxic environmental pollutant) on the correlation structure of a number of urinary

metabolites.

Key Words: Gaussian Graphical Models; Prior Speciﬁcation; Sequential Monte Carlo.

1

Introduction

Gaussian graphical models (GGMs, Dempster, 1972) provide an important tool for studying
the dependence structure among a set of random variables. Under the assumption that the
variables have a joint Gaussian distribution, a zero in the precision matrix indicates condi-
tional independence between the associated variables. This corresponds to the absence of an
edge in the underlying graph, where nodes denote variables and edges represent conditional
dependencies (Lauritzen, 1996). GGMs are widely used, for instance, in biological networks
to study the dependence structure among genes from expression data (e.g. Dobra et al., 2004;
Chun et al., 2014) and ﬁnancial time series for forecasting and predictive portfolio analysis

1

(e.g. Carvalho and West, 2007; Wang et al., 2011). In applications where the eﬀect of diﬀer-
ent experimental conditions on the dependence relationships among variables is of interest,
multiple GGMs (one for each condition) have to be estimated. Under such circumstances,
joint inference can encourage sharing of information across graphs and allow for common
structure where appropriate (e.g. Guo et al., 2011; Peterson et al., 2015).

We focus on Bayesian inference for GGMs using the G-Wishart prior (Roverato, 2002;
Atay-Kayis and Massam, 2005). The G-Wishart is the family of conjugate distributions for
the precision matrix, where entries corresponding to missing edges in the underlying graph
are constrained to be zero. The normalizing constant of the G-Wishart can only be computed
in closed form for decomposable graphs. In this work, we consider the unrestricted graph
space where non-decomposable graphs are allowed. Where necessary, we use the Monte Carlo
method of Atay-Kayis and Massam (2005) and the Laplace approximation of Lenkoski and
Dobra (2011) to estimate the normalizing constant eﬃciently.

This article makes two main contributions. First, we propose using the multiplicative
model of Chung and Lu (2002) as a prior on graphs for estimating GGMs. This prior is further
extended to multiple GGMs via logistic regression. Second, we develop a novel sequential
Monte Carlo (SMC) algorithm (Del Moral et al., 2006) which uses tempering techniques to
obtain joint posterior inference for multiple GGMs. The performance of proposed methods
is illustrated on simulated data and an application to urinary metabolic data.

1.1 Background and Structure

In the absence of any prior belief on the graphical structure, a uniform prior over all graphs
is often used in estimating GGMs (e.g. Lenkoski and Dobra, 2011; Wang and Li, 2012). That
is, given p nodes, it is assumed that each of the 2r possible graphs, where r = p(p− 1)/2, has
equal probability of arising. This prior concentrates its mass on graphs with moderately large
number of edges and the expected number of edges as well as the mode is r/2 (see Figure 1).
Thus, this prior may not be appropriate when sparse graphs are desired. Several alternatives
have been developed. To encourage sparse graphs, Dobra et al. (2004) and Jones et al.
(2005) propose a prior where every edge is included independently with a small probability
α so that a graph with x edges has prior probability αx(1 − α)r−x. This prior is known
as the Erd˝os-R´enyi model in random graph theory and it reduces to the uniform prior
when α = 0.5. Jones et al. (2005) recommend taking α = 2/(p − 1) so that the expected
number of edges is p. Carvalho and Scott (2009) treat α as a model parameter rather than
a ﬁxed tuning constant. They place a Beta(a, b) prior on α so that a graph with x edges

2

Figure 1: Plot shows the probability allocated to graphs with x edges by the uniform prior, the Bernoulli
prior (Jones et al., 2005) with probability of inclusion of each edge: α = 2/(p − 1), the size-based prior
(Armstrong et al., 2009) or equivalently the Bernoulli prior with α ∼ Uniform[0, 1] integrated out (Carvalho
and Scott, 2009) and the multiplicative prior (MP) for diﬀerent values of a and b.

(cid:0)r

(cid:1)−1. This prior is equivalent to the

has prior probability B(a + x, r + b − x)/B(a, b), where B(a, b) denotes the Beta function.
When a = b = 1, this probability simpliﬁes to
size-based prior (Armstrong et al., 2009) when the graph space is unrestricted. Under the
size-based prior, every size 0, . . . , r, has equal probability and every graph of the same size
has equal probability. Carvalho and Scott (2009) demonstrate that their proposed prior has
strong control over the number of spurious edges and corrects for multiple hypothesis testing
automatically, where each null hypothesis corresponds to the exclusion of one edge.

1

r+1

x

provided (maxi di)2 <(cid:80)

We propose using the multiplicative or Chung-Lu random graph model as a prior on
the graphical space of GGMs. Given a desired or expected degree sequence {d1, . . . , dp},
where di denotes the degree (number of neighbours) of node i, the multiplicative model
(Chung and Lu, 2002) assumes that the edge between each pair of nodes i and j is formed
independently with probability pij proportional to the product didj. Allowing self-loops and
i di, the expected degree of node i is exactly di. The multiplicative
model is able to capture degree distributions which are more diverse (e.g. right-skewed, U-
shaped) and closer to that of real-world networks than the Erd˝os-R´enyi model. Notably, the
Erd˝os-R´enyi model has a degree distribution that is binomial and can be viewed as a special
case of the multiplicative model with a constant expected degree sequence. We consider
an alternative parametrization of the multiplicative model introduced by Olhede and Wolfe
(2013), which dispenses with self-loops and the normalization constraint by taking pij = πiπj
and 0 < πi < 1 for each i. They derive degree characteristics and large-sample approximations
of this model, which lends insight on the variation attainable in degree structure. Adopting

3

0501001500.000.020.040.060.080.10p=20Number of edges (x)Probability of graphs with x edgeslllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllluniformbernoullisize−basedMP(a=1,b=1)MP(a=1,b=4)MP(a=4,b=1)a Bayesian approach, we treat each πi as a variable with a Beta(a, b) prior. We present
degree and clustering properties of the multiplicative model, showing how they depend on
choices of a and b. In the context of GGMs, we show that the multiplicative model provides
an avenue to encourage sparsity or graphs that exhibit particular degree patterns based on
prior knowledge obtained through expert opinion or past data. We further demonstrate how
the multiplicative model can be extended to include covariates and become a prior on joint
graphs for multiple GGMs.

Several approaches for joint inference of multiple GGMs have been developed recently.
Guo et al. (2011) estimate precision matrices for diﬀerent groups jointly by parameterizing
each entry as a product of two factors: one factor is common across all groups while the
other is group speciﬁc. A hierarchical l1 penalty is imposed and optimization is performed
using graphical lasso (Friedman et al., 2008). Danaher et al. (2014) formulate a more general
framework called joint graphical lasso and introduce two convex penalty functions; the fused
graphical lasso which encourages edge value on top of structural similarity and the group
lasso which only encourages a shared sparsity pattern. Chun et al. (2014) extend the approach
of Guo et al. (2011) to a wider class of nonconvex penalty functions. Yajima et al. (2015)
compare the Gaussian directed acyclic graphs of two subgroups using Bayesian inference via
Gibbs sampling. The strength of association between two variables in the diﬀerential group is
modeled as the strength in the baseline group plus an edge-speciﬁc parameter controlling the
diﬀerence in association between the two subgroups. They deﬁne a prior on the graphical
space by centering on a prior graph constructed from a database (Telesca et al., 2012).
Peterson et al. (2015) consider an alternative Bayesian approach which links graphs from
diﬀerent groups using a Markov Random Field. The probability of inclusion of each edge in
graphs 1, . . . , K, is parameterized in terms of a K × K symmetric matrix which measures the
pairwise similarity of groups and is common across all edges, and an edge-speciﬁc K×1 vector
which controls the inclusion probability in each group independently of group relatedness.
Priors are further placed on these parameters and a block Gibbs sampler is used for inference.
The approach that we use to link multiple graphs is based on the multiplicative model
by expressing the connectivity of each node as a logistic regression function of graph speciﬁc
covariates. As the multiplicative model decouples the inclusion probability of each edge into
the product of the connectivities of the end nodes, the resulting model is parsimonious
and scales linearly in the number of variables and graphs. For inference, we develop an
SMC sampler for estimating the joint posterior distribution of the graphs. Using tempering
techniques (see e.g. Del Moral et al., 2006, and the references therein), we create a sequence

4

of probability distributions from which to sample, moving gradually from a distribution that
is easy to sample from, through artiﬁcial intermediate distributions towards the posterior
distribution of interest.

In Section 2, we introduce the multiplicative model and discuss its degree and clustering
properties. Section 3 speciﬁes the model setup for multiple GGMs. Section 4 describes pos-
terior inference and a Laplace approximation for the prior probabilities of graphs. The SMC
algorithm is outlined in Section 5. Proposed methods are illustrated using simulations and
an application to urinary metabolic data in Section 6. Section 7 concludes.

2 Multiplicative model

Here we deﬁne our notation and present the multiplicative model, followed by a study of
its properties. These properties lend insight on the structure and range of networks that
can be generated from the multiplicative model. They are also useful in the determination
of suitable hyperparameters based on prior understanding of data obtained through expert
opinion or a database.

Let G = (V, E) be a simple graph with vertex set V = {1, 2, . . . , p} and edge set E ⊆
{(i, j) ∈ V × V : i < j}. A simple graph is undirected and does not contain self-loops or
multiple edges. The adjacency matrix A = [Aij] of G is a p × p binary matrix where Aij is 1
if an edge is present between nodes i and j, and 0 otherwise for i, j ∈ V . As G is simple, A
is symmetric and has zeros on its diagonal.

In the multiplicative model, each edge is modeled independently as

Aij ∼ Bernoulli(pij) for 1 ≤ i < j ≤ p,

pij = πiπj, where 0 ≤ πi ≤ 1 for i = 1, . . . , p.

(1)

Thus, every edge Aij is formed independently with probability pij, where pij is a product
of the tendencies of nodes i and j to form edges with other nodes. The parameter πi is
characteristic of node i and reﬂects its activity level. We refer to πi as the connectivity of i.
The Erd˝os-R´enyi random graph model arises as a special case when πi is constant across all
i, that is, every link is formed independently with equal probability.

We adopt a Bayesian approach and place an independent Beta prior on each πi. Let

πi ∼ Beta(a, b) for i = 1, . . . , p,

(2)

5

where a, b > 0. We have p(πi) = πa−1

Γ(a)Γ(b). Let π = (π1, . . . , πp)T and p(π) =(cid:81)p

Γ(a+b)

i

(1 − πi)b−1/B(a, b), where the Beta function B(a, b) =
i=1 p(πi). Networks of highly varying densities

and structures can be formed by choosing diﬀerent hyperparameters a and b.

2.1 Degree and clustering properties

of i, and is given by Di =(cid:80)

The degree Di of a node i is the number of links that involve i or the number of neighbours
j(cid:54)=i Aij. The properties below describe the degree distribution
and cohesiveness of networks generated from the multiplicative model. Their implications
are discussed later in the section. We follow the framework in Rastelli et al. (2015), which is
based on probability generating functions (see Newman et al., 2001). Proofs are given in the
Supplementary Material. We note that some of these results have been discussed in Olhede
and Wolfe (2013) but not with regards to the Beta(a, b) prior. In the following, let µ = a
a+b
and σ2 =
(a+b)2(a+b+1) denote the mean and variance of a Beta(a, b) distribution respectively.

ab

P1: The probability that a randomly chosen node is a neighbour of a node with connectivity

πi is µπi.

P2: The degree of a node with connectivity πi is distributed as Binomial(p− 1, µπi). Hence

its average degree is (p − 1)µπi, which is proportional to πi.

P3: The probability generating function of the degree of a randomly chosen node is given

(cid:90) 1

0

by

GDi(z) =

p−1(cid:88)

d=1

(cid:18) Di!

(cid:19)

E

(Di − k)!

P(Di = d)zd =

(1 − µπi + µπiz)p−1p(πi) dπi.

(3)

The kth factorial moment of Di, E{Di(Di − 1) . . . (Di − k + 1)}, is given by

= G(k)
Di

(1) =

(p − 1)! B(a + k, b)
(p − 1 − k)! B(a, b)

µk for any positive integer k.

P4: The average degree of a randomly chosen node is E(Di) = (p − 1)µ2 and the variance

is Var(Di) = (p − 1)µ2{1 − µ2 + (p − 2)σ2}.

P5: The degree distribution of a randomly chosen node is given by

P (Di = d) =

πa+d−1

i

(1 − µπi)p−1−d(1 − πi)b−1 dπi

(cid:18)p − 1

(cid:19) µd

(cid:90) 1

d

B(a, b)

0

6

P6: The dispersion index of the degree distribution is given by 1 − a{a2+(b+1)a−(p−2)b}

0 ta−1(1 − t)b−1 dt is the incomplete Beta function.

for d ∈ {0, . . . , p − 1}. When b = 1, P (Di = d) =(cid:0)p−1
(cid:1)aB(µ, a + d, p − d)/µa, where
B(x; a, b) =(cid:82) x
• When 0 < a < {(cid:112)b2 + (4p − 6)p + 1 − b − 1}/2, the distribution has dispersion
• When a = {(cid:112)b2 + (4p − 6)p + 1 − b − 1}/2, the distribution has dispersion index 1
• When a > {(cid:112)b2 + (4p − 6)p + 1 − b − 1}/2, the distribution has dispersion index

index greater than 1 and is over-dispersed.

(equal to that of a Poisson distribution).

d

(a+b)2(a+b+1)

.

less than 1 (similar to that of a Binomial distribution) and is under-dispersed.

P7: The skewness index or Pearson’s moment coeﬃcient of skewness of the degree distribu-
i ) =
(a+b+2)(a+b+1)(a+b).

tion can be computed as {E(D3
(p− 1)µ2{1 + 3(p− 2)(µ2 + σ2) + (p− 2)(p− 3)µE(π3

i )−3E(Di)Var(Di)−E(Di)3}/Var(Di)1.5, where E(D3

i )} and E(π3

(a+2)(a+1)a

i ) =

P8: The average degree of the neighbours of a node is independent of the connectivity or

degree of that node, and is given by 1 + (p − 2)(µ2 + σ2).

P9: The global clustering coeﬃcient, which measures the probability that nodes j and k

are linked given that both nodes are linked to i, is given by a+1

a+b+1.

In the Erd˝os-R´enyi model, Di is distributed as Binomial(p − 1, α), where α is the prob-
ability of inclusion of each edge. When α = µ2, the mean degree of a randomly chosen node
in the multiplicative model is equal to that in the Erd˝os-R´enyi model from P4. However,
the variance of the degree distribution in the multiplicative model is greater than that in
the Erd˝os-R´enyi model by (p − 1)(p − 2)σ2. Thus, as the number of nodes increases, the
multiplicative model can accommodate greater variation in the degree distribution than in
the Erd˝os-R´enyi model by O(p2) given the same mean degree.

Figure 2 shows the degree distributions of the multiplicative model for graphs with p =
100 nodes under diﬀerent hyperparameter settings. When the degree distributions cannot
be computed directly using P5, they are estimated via simulation using 105 graphs. Degree
distributions of a variety of shapes (e.g. right-skewed, U-shaped) can be obtained from the
multiplicative model by varying a and b.

The dispersion index measures how clustered a distribution is compared to standard
statistical models. From P6, the degree distribution is over-dispersed when a is small and
under-dispersed when a is large. In fact, as a → ∞ (and/or b → ∞), σ2 → 0 and each πi

7

Figure 2: Beta densities (left) and degree distributions of the multiplicative model (right) corresponding to
diﬀerent hyperparameter settings when p = 100.

reduces to a point mass. The multiplicative model thus degenerates and reduces to the Erd˝os-
R´enyi model with constant probability of inclusion for every edge. As the degree distribution
is over-dispersed for a wide range of hyperparameter values, the multiplicative model is able
to represent well heterogeneity in degree sequences.

The skewness index in P7 is useful for identifying asymmetries in degree distributions.
Generally, the degree distribution is positively skewed when a is small and b is large and
negatively skewed vice versa (plots of the dispersion index and skewness as a function of a
and b can be found in the Supplementary Material Figures S1 and S2). A network exhibiting
power-law behaviour (P (Di = d) ∝ d−γ where γ is a positive constant) tends to have large
positive values for the skewness index. For the multiplicative model, Olhede and Wolfe (2013)
show that taking πi ∝ i−γ for some 0 < γ < 1 leads to networks with degree distributions
that reﬂect power laws when p is large. When πi is given a Beta prior, the skewness is
positive and large for small a and large b (i.e. sparse networks). In Figure 3, we investigate
the relationship between log P (Di = d) and log d, which should be a straight line if the
power-law is satisﬁed. We observe that the multiplicative model (with a Beta prior) comes
close to power-law behaviour for very sparse networks but the right tail is not suﬃciently
heavy.

3 Gaussian Graphical Models

Suppose we have a dataset with p variables and K groups or classes. Let yh = (yh1, . . . , yhp)
denote the hth observation of the p variables for h = 1, . . . , H, and Sk be an index set
containing the indices of observations which belong to group k for k = 1, . . . , K. The number

8

0.00.20.40.60.81.001234Beta densitiespip(pi)a=b=0.1a=b=1a=1,b=2a=2,b=1a=1,b=4a=4,b=10204060801000.000.020.040.060.080.10Degree distributionsDegreeProbabilitya=b=0.1a=b=1a=1,b=2a=2,b=1a=1,b=4a=4,b=1Figure 3: Degree distributions for investigating power-law. Right plot is in log-scale.

of observations in Sk is denoted by |Sk| and H =(cid:80)K

k=1 |Sk|. Without loss of generality, we
assume that the observations in each group are centered at 0 along each variable. We consider

yh|Ωk ∼ N (0, Ω−1

k ) for h ∈ Sk,

(4)

where Ωk is a p × p precision matrix and k ∈ {1, . . . , K}.

Let Gk = (V, Ek) be a simple graph with vertex set V = {1, 2, . . . , p} and edge set Ek ⊆
{(i, j) ∈ V × V : i < j} for k = 1, . . . , K. Node i ∈ V represents the ith variable and each
edge (i, j) ∈ Ek corresponds to Ωk,ij (cid:54)= 0. That is, yhi and yhj are conditionally independent
(in Gk) given the rest of the elements in yh if and only if Ωk,ij = 0, or equivalently (i, j) /∈ Ek.
The conjugate prior for Ωk is the G-Wishart distribution (Atay-Kayis and Massam, 2005),
WGk(δk, Dk), which has density

p(Ωk|Gk) =

1

IGk(δk, Dk)

|Ωk|(δk−2)/2 exp

−1
2

tr(ΩkDk)

.

(cid:26)

(cid:27)

Here, Ωk is constrained to the cone PGk of positive deﬁnite matrices with entries equal to
zero for all (i, j) /∈ Ek and IGk(δk, Dk) is a normalizing constant such that
(cid:27)

(cid:26)

(cid:90)

IGk(δk, Dk) =

|Ωk|(δk−2)/2 exp

−1
2

Ωk∈PGk

tr(ΩkDk)

dK.

k ∈ PGk (Diaconis and
This normalizing constant is guaranteed to be ﬁnite if δk > 2 and D−1
Ylvisaker, 1979). The G-Wishart distribution reduces to the Wishart distribution when Gk

9

llllllllllllllll01234560.00.20.40.60.81.0p=100, b=20DegreeProbabilityllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllla=2a=1a=0.5a=0.25a=0.1lllllllllllll0.00.51.01.52.02.5−15−10−5p=100, b=20log(d)log(P(Di=d))lllllllllllllllllllllllllla=2a=1a=0.5a=0.25a=0.1is complete, and the normalizing constant can then be evaluated in closed form as

IGk(δk, Dk) = 2(δk+p−1)p/2 Γp{(δk + p − 1)/2}|Dk|−(δk+p−1)/2,

(5)

where Γp(a) = πp(p−1)/4(cid:81)p−1

i=0 Γ(a − 1

2) for a > (p − 1)/2.

3.1 Priors over graphs

We use the multiplicative model to assign prior probabilities to graphs. Let Ak = [Ak,ij] be
the adjacency matrix of Gk for k = 1, . . . , K. Consider

Ak,ij|πk,iπk,j ∼ Bernoulli(πk,iπk,j),

(6)

where 0 ≤ πk,i ≤ 1 for i = 1, . . . , p and k = 1, . . . , K. As in Section 2, the probability that an
edge (i, j) is present in Ek is given by πk,iπk,j, the product of the propensities of nodes i and
j to form edges with other nodes in Gk. Priors are further placed on each πk,i. We consider
the cases K = 1 and K > 1 separately.

3.1.1 When K = 1

When K = 1, there is only one group and the subscript k indicating diﬀerent groups may be
dropped so that G1 = G and π1,i = πi for i = 1, . . . , p. We place a Beta(a, b) prior on each
πi as in (2). The prior probability of G with adjacency matrix A is then given by

(cid:90)

p(G|a, b) =

p(G|π)p(π|a, b) dπ

(cid:90) (cid:89)

i,j: i<j

=

1

B(a, b)p

(1 − πiπj)(1−Aij )

p(cid:89)

i=1

π(a+di−1)

i

(1 − πi)(b−1) dπ,

(7)

where di denotes the degree of node i.

3.1.2 When K > 1

We propose a joint prior for G1, . . . , GK, which is allowed to depend on covariates speciﬁc
to each graph. First, we express πk,i in terms of a logistic regression as

πk,i =

exp(βT

i xk)

1 + exp(βT

i xk)

10

for i = 1, . . . , p, and k = 1, . . . , K, where xk = (xk1, . . . , xkQ)T is a vector of covariates for
Gk and βi = (βi1, . . . , βiQ) is a vector of coeﬃcients speciﬁc to node i. Let x = (x1, . . . , xK)
and β = (βT

p )T . We consider a normal prior for each βiq such that

1 , . . . , βT

βiq|σ2

q ∼ N (0, σ2
q )

for i = 1, . . . , p and q = 1, . . . , Q. Let σ2 = (σ2
known. The joint prior probability of G1, . . . , GK, is then given by

1, . . . , σ2

Q) be a hyperparameter assumed to be

(cid:90)
 1(cid:113)

K(cid:89)
(cid:18)

k=1

p(β|σ2)

exp

p(Gk|xk, β)dβ

(cid:19) K(cid:89)

k=1

− β2
iq
2σ2
q

(cid:40) p(cid:89)

(cid:89)

(1 − πk,iπk,j)1−Ak,ij

πdk,i
k,i

(cid:41)

dβ,

(8)

i=1

i<j

p(G1, . . . , GK|x, σ2) =

(cid:90) p(cid:89)

Q(cid:89)

=

i=1

q=1

(2πσ2
q )

where dk,i denotes the degree of node i in Gk for k = 1, . . . , K.

As an example, in the application on urinary metabolic data, we consider K = 2 and
the covariates xk to include an intercept and an indicator for level of exposure to cadmium
(1 if above the median and 0 otherwise). We take x1 = (1, 0) and x2 = (1, 1) so that G1
and G2 represent the correlation structure of the groups with exposure to cadmium below or
equal to the median, and above the median respectively. The connectivity of node i is π1,i =
{1 + exp(−βi1)}−1 in G1 and π2,i = {1 + exp(−βi1 − βi2)}−1 in G2. Thus βi1 determines the
popularity of node i in G1 while βi2 is a diﬀerential parameter which controls the diﬀerence
in popularity of node i between G1 and G2. If βi2 is close to zero, the connectivity of node
i in G1 and G2 is similar. As the magnitude of βi2 increases, the diﬀerence in connectivity
of node i between G1 and G2 becomes greater. See illustration in Supplementary Material
Figure S3.

Figure 4 shows the prior degree distributions of G1 and G2 for p = 50 and diﬀerent values
of σ2. These plots are obtained via simulation of 105 joint pairs of graphs in each case. When
σ2
1 = σ2
2 = 0.1, both βi1 and βi2 are close to zero, and π1,i and π2,i are close to 0.5. Thus
the degree distribution is shaped like a Binomial curve, resembling the Erd˝os-R´enyi model
where each edge is formed independently with constant probability 0.25. As σ2
1 increases,
there is greater variation in the degree sequence of G1. When σ2
1 is large, the connectivity of
each node tends to the extremes of 0 and 1 (each node has a high probability of being either
very connected or isolated). Thus the degree distribution resembles the case where each πi is

11

allocated a U-shaped Beta(0.1,0.1) prior as shown in Figure 2. The distinction between the
degree distribution of G1 and G2 becomes greater as σ2

2 increases.

Figure 4: Prior degree distributions of G1 and G2 for p = 50 and diﬀerent combinations of σ2
Covariates for G1 and G2 are (1,0) and (1,1) respectively.

1 and σ2
2.

We can also add a third covariate say for gender (1 if male and 0 for female) so that
K = 4 and take x1 = (1, 0, 0), x2 = (1, 0, 1), x3 = (1, 1, 0) and x4 = (1, 1, 1). Then G1, for
instance, will represent the correlation structure for the group of females with exposure to
cadmium below or equal to the median level.

4 Posterior distribution

Let y = (y1, . . . , yH). For K > 1, the joint distribution of the model can be written as

p(y, Ω1, . . . , ΩK, G1, . . . , GK, β|x, σ2) = p(β|σ2)

p(Gk|xk, β)p(Ωk|Gk)

p(yh|Ωk)

(cid:40)

K(cid:89)

k=1

(cid:41)

.

(cid:89)

h∈Sk

Integrating out Ωk, the marginal likelihood p({yh|h ∈ Sk}|Gk) can be shown (see, e.g. Atay-
Kayis and Massam, 2005) to be given by

p({yh|h ∈ Sk}|Gk) = (2π)−p|Sk|/2IGk(δk + |Sk|, Dk +

yhyT

h )/IGk(δk, Dk).

(cid:88)

h∈Sk

Integrating out β as well, we have

p(G1, . . . , GK|y, x, σ2) ∝ p(G1, . . . , GK|x, σ2)

K(cid:89)

k=1

IGk(δk + |Sk|, Dk +

(cid:88)

h∈Sk

yhyT

h )/IGk(δk, Dk).

(9)

12

010203040500.000.050.100.150.20s12 = s22 = 0.1DegreeProbabilityG1G2010203040500.000.050.100.150.20s12 = s22 = 1DegreeProbabilityG1G2010203040500.000.050.100.150.20s12 = s22 = 10DegreeProbabilityG1G2010203040500.000.050.100.150.20s12 = 1 , s22 = 10DegreeProbabilityG1G2H(cid:88)

When K = 1, the posterior distribution can be derived similarly. The only diﬀerence is that
the dependence on x and σ2 is replaced by the Beta prior hyperparameters a and b. We have

p(G|y, a, b) ∝ p(G|a, b)IG(δ + H, Dk +

yhyT

h )/IG(δ, D).

(10)

h=1

the corresponding set of separators. Then IG(δ, D) =(cid:81)L

For posterior inference, we propose a SMC algorithm to obtain samples from the posterior
distribution. To compute the right-hand side of 9 and 10, we note that for any graph G (not
necessarily decomposable), normalizing constants of the form IG(δ, D) can be evaluated by
ﬁrst factorizing G into its prime components and their separators (see, e.g. Lauritzen, 1996).
Suppose (P1, . . . ,PL) is a perfect sequence of the prime components of G and (S2, . . . ,SL) is
(δ, D), where
GPl and GSl denote the subgraphs induced by Pl and Sl respectively. As the separators are
(δ, D) for any prime
complete, IGSl
component Pl which is complete. Otherwise, we estimate IGPl
(δ, D) using the Monte Carlo
method of Atay-Kayis and Massam (2005) when δ is small and the Laplace approximation
of Lenkoski and Dobra (2011) when δ is large. The priors on graphs are estimated using
Laplace approximation, which is described next.

(δ, D) can be evaluated as in (5). The same applies to IGPl

(δ, D)/(cid:81)L

l=1 IGPl

l=2 IGSl

4.1 Laplace approximation for prior on graphs
Evaluating p(G|a, b) or p(G1, . . . , GK|x, σ2) via Monte Carlo becomes more computationally
intensive as p increases and we estimate these quantities eﬃciently using Laplace approxi-
mation instead. We consider

exp{f (u)} du ≈ (2π)

n

2 | − H(u0)|− 1

2 exp{f (u0)},

(11)

(cid:90)

where u = (u1, . . . , ud)T , u0 is the mode of f (u) and H(u0) denotes the Hessian of f evaluated
at u0. The mode u0 can be found using numerical methods.

For K = 1, we estimate p(G|a, b) in (7) using (11) by ﬁrst making a change of variable

and letting πi = exp(ui)

1+exp(ui). Then we take

f (u) =

(cid:88)
(cid:88)

i

+

{(a + di)ui − (a + di + 1) log[1 + exp(ui)] + (b − 1) log(1 − πi)}
(1 − Aij) log(1 − πiπj) − p log B(a, b).

i<j

13

For K > 1, we estimate p(G1, . . . , GK|x, σ2) in (8) using (11) by taking u = β and

(cid:40) p(cid:88)

K(cid:88)

(cid:88)

f (β) =

dk,i log πk,i +

(1 − Ak,ij) log(1 − πk,iπk,j)

log(2πσ2

q ) +

k=1

i=1

i<j

i=1

q=1

(cid:41)
− p(cid:88)

Q(cid:88)

(cid:26)1

2

(cid:27)

.

β2
iq
2σ2
q

For simplicity, we have omitted dependence of f on other variables in its expression. The
corresponding gradient and Hessian expressions are given in the Supplementary Material.

5 Sequential Monte Carlo sampler

We use SMC samplers for posterior inference. Suppose we are interested in sampling from
a complex target λ(x). The idea is to start with some distribution λ1 that is easy to sam-
ple from and move via a sequence of intermediate distributions, λ2, . . . , λT−1, towards the
distribution of interest λT = λ. At any time t, a large collection of weighted samples
{W (n)
|n = 1, . . . N} is maintained, and these particles are used to generate samples
from the target distribution at the next time point using sequential importance sampling
(SIS) and resampling methods. The motivation is that it would be easier to move the particles
from one target to the next if λt is close to λt+1.

, X (n)

t

t

5.1 Review of methodology

We ﬁrst review SIS and SMC brieﬂy. Let λ1, . . . , λT , be the target densities and γ1, . . . , γT ,
unnormalized densities such that λt(x1:t) ∝ γt(x1:t) for t = 1, . . . , T . Let φ be some test
function and ηt an arbitrary proposal density. In importance sampling,

φ(x1:t)

λt(x1:t)
ηt(x1:t)

ηt(x1:t) dx1:t =

(cid:82) φ(x1:t)wt(x1:t)ηt(x1:t) dx1:t
(cid:82) wt(x1:t)ηt(x1:t) dx1:t

,

(cid:90)

Eλt[φ(X1:t)] =

where

are the unnormalized weights. If {X (n)

Carlo approximation of Eλt{φ(x1:t)} is(cid:80)N

wt(x1:t) = γt(x1:t)/ηt(x1:t)

(12)
1:t |n = 1, . . . , N} is a sample from ηt(x1:t), then a Monte

n=1 φ(X (n)

1:t )W (n)

t

, where w(n)

t = wt(X (n)

1:t ) and

w(n)

t

(13)

(cid:88)N

n=1

W (n)

t = w(n)
t /

14

are the normalized weights. Given {W (n)
t, samples {X (n)
{X (n)

1:t |n = 1, . . . N} approximating λt(x1:t) at time
1:t+1} approximating λt+1 at time t + 1 are obtained in SIS by sampling from

1:t } using a Markov kernel Kt+1(xt, xt+1). The proposal density is

1:t , X (n)

ηt+1(x1:t+1) = ηt(x1:t)Kt+1(xt, xt+1).

(14)

From (12), the corresponding unnormalized weights can be computed recursively using

wt+1(x1:t+1) =

γt+1(x1:t+1)
ηt+1(x1:t+1)

=

γt+1(x1:t+1)

γt(xt)Kt+1(xt, xt+1)

wt(x1:t).

˜γt(x1:t) = γt(xt)(cid:81)t−1

In SMC, artiﬁcial joint target distributions ˜λt(x1:t) ∝ ˜γt(x1:t) are introduced, where
l=1 Ll(xl+1, xl) and Ll(xl+1, xl) is an artiﬁcial backward in time Markov
1:t |n = 1, . . . N} is a weighted sample approximating ˜λt(x1:t) at
1:t , X (n)
1:t+1} using the Markov

kernel. Assume {W (n)
time t distributed according to η(x1:t). Moving the samples to {X (n)
kernel in (14), the unnormalized importance weights can be computed as

wt+1(x1:t+1) = ˜γt+1(x1:t+1)/ηt+1(x1:t+1) = wt(x1:t) ˜wt+1(xt, xt+1),

(15)

where ˜wt+1(xt, xt+1) = γt+1(xt+1)Lt(xt+1, xt)/{γt(xt)Kt+1(xt, xt+1)} are unnormalized incre-
mental weights. In the proposed algorithm, we take Kt+1 to be an MCMC kernel of invariant
distribution λt+1 and Lt(xt+1, xt) = λt+1(xt)Kt+1(xt, xt+1)/λt+1(xt+1). See Del Moral et al.
(2006) Section 3.3.2.3. The unnormalized incremental weights then simplify to

˜wt+1(xt, xt+1) = γt+1(xt)/γt(xt).

(16)

5.2 Proposed Algorithm
Our aim is to sample from p(G1, . . . , GK|y, x, σ2) in (9) when K > 1 and p(G|y, a, b) in (10)
when K = 1. Let p(G1, . . . , GK|y) denote the posterior density generally omitting dependence
on covariates and hyperparameters. We have p(G1, . . . , GK|y) ∝ γ(G1, . . . , GK|y) where

p(G|a, b)IG(δ + H, D +(cid:80)H
p(G1, . . . , GK|x, σ2)(cid:81)K

k=1

γ(G1, . . . , GK) =

(δk+|Sk|,Dk+(cid:80)

h )/IG(δ, D)
h∈Sk

h=1 yhyT
IGk

IGk

(δk,Dk)

yhyT
h )

if K = 1,

if K > 1.

15

For simplicity, we do not state the dependence of γ on other variables explicitly. To construct
the SMC sampler, we devise the following sequence of intermediate target densities,

p(G1, . . . , GK|y)φ1, p(G1, . . . , GK|y)φ2, . . . , p(G1, . . . , GK|y)φT ,

where 0 < φ1 < φ2 < . . . φT = 1 is a sequence of user-speciﬁed temperatures. For greater
stability, we use tempering to bridge the target densities so that they evolve smoothly. At
each time t, we maintain N weighted samples {W (n)
|n = 1, . . . , N} approx-
imating the target p(G1, . . . , GK|y)φt ∝ γ(G1, . . . , GK)φt and the annealing temperature is
raised gradually from 0 to 1.

, (G1, . . . , GK)(n)

t

t

5.3 Initialization and computation of weights
To generate N samples from the initial target p(G1, . . . , GK|y)φ1 at time t = 1, we sample
(G1, . . . , GK) uniformly from the joint graphical space. This can be accomplished by sampling
each edge in Gk independently with probability 0.5 for each k = 1, . . . , K. This process is
performed N times independently to obtain {(G1, . . . , GK)(n)
1 |n = 1, . . . , N}. The weight of
each sample can be computed using importance sampling. Let r = p(p − 1)/2. From (12),

w(n)
1 = γ((G1, . . . , GK)(n)

1 )φ12rK.

(17)

Suppose we increase the temperature from φt−1 to φt at time t ≥ 2. From (15) and (16),

unnormalized weights for the nth sample can be computed as

w(n)
t = w(n)

(t−1)γ((G1, . . . , GK)(n)

t−1)φt−φt−1,

(18)

Normalized weights may be obtained using (13).

5.4 Resampling

ESS = {(cid:80)N

n=1 W (n)

To prevent degeneracy of the particle approximation, we measure the eﬀective sample size,
t }−1, at each time t and resample when the ESS falls below a threshold, say
Nthreshold = N/3. Resampling is performed by drawing N new particles from the multinomial
distribution with parameters (W (1)
). In this way, particles with high weights will
be duplicated multiple times while particles with low weights will be eliminated. Resampled
particles are then assigned equal weights.

, . . . , W (N )

t

t

16

t−1, (G1, . . . , GK)(n)

5.5 MCMC steps
Suppose we have weighted samples {W (n)
t−1|n = 1, . . . , N}. At time t, these
samples are moved using an MCMC kernel with invariant distribution pt(G1, . . . , GK|y) by
performing a small number of MCMC steps. This improves mixing and helps to restore
the heterogeneity lost during resampling. During this step, candidates for each sample are
generated by selecting a small number, say M , of edges uniformly at random from the set
of all possible edges and proposing to ﬂip each edge (a 1 (present) to 0 (absent) and vice
versa) in turn in each Gk for k = 1, . . . , K. For the selected edge, let (G1, . . . , GK)(n)
c denote
the sample obtained after ﬂipping this edge in one of the K graphs in (G1, . . . , GK)(n)
t−1. As
the proposal is symmetric, the candidate is accepted with probability given by

(cid:104)(cid:110)

(cid:111)φt

(cid:105)

min

γ((G1, . . . , GK)(n)

c )/γ((G1, . . . , GK)(n)

t

)

, 1

.

(19)

t = (G1, . . . , GK)(n)
If the candidate is accepted, we update the nth sample as (G1, . . . , GK)(n)
,
otherwise it remains unchanged. The proposed SMC sampler is summarized in Algorithm
1. Note that Algorithm 1 is easily parallelizable as computation of weights as well as the
MCMC steps can be performed independently for the N samples.

c

Algorithm 1 SMC Algorithm for multiple GGMs
At t = 1,
• draw (G1, . . . , GK)(n)
• Compute weights {w(n)

1 at random uniformly from the joint graphical space for n = 1, . . . , N .

1 } using (17) and obtain normalized weights {W (n)

1 } using (13).

For t = 2, . . . , T ,
• Update weights {w(n)
• If ESS < Nthreshold, resample the particles and set W (n)
• For n = 1, . . . , N ,

t } using (18) and obtain normalized weights {W (n)

t } using (13).

t = 1/N for n = 1, . . . , N .

– Randomly select M edges from the set of all possible edges..
– Set (G1, . . . , GK)(n)
– For m = 1, . . . , M, and k = 1, . . . , K, let (G1, . . . , GK)(n)

t = (G1, . . . , GK)(n)
t−1.

c

be the sample candi-
date obtained from (G1, . . . , GK)(n)
by ﬂipping the mth selected edge in Gk. Ac-
cept sample candidate with probability in (19). If sample candidate is accepted, set
(G1, . . . , GK)(n)

t = (G1, . . . , GK)(n)

.

c

t

17

6 Results

In the following experiments, we take δk = 3 and Dk = Ip for k = 1, . . . , K in the G-Wishart
prior. For the SMC sampler, we set the number of samples N = 500, and the number of
edges ﬂipped at each iteration in the MCMC step M = 5. The sequence {φt} is set as (0.005,
0.01, . . . , 1) with T = 200. This can also be set adaptively (see Jasra et al., 2011). All code
is written in Matlab.

6.1 Simulated data

In this section, we investigate the performance of the multiplicative model as a prior on
graphs for GGMs and compare it with the commonly used uniform prior which assigns
equal prior probability to every graph, and the size-based prior (Armstrong et al., 2009) or
equivalently the prior that corrects for multiple hypothesis testing proposed by Carvalho and
West (2007) (see Section 1.1 for details). We consider p = 20 nodes and simulate a graph
from the multiplicative model in 2 by letting πi = 0.9 for i = 1, . . . , 10, and πi = 0.1 for
i = 11, . . . , 20, so that each node is either highly or poorly connected. The degree sequence
of the simulated graph is {0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 6, 7, 7, 7, 8, 8, 9, 10, 10, 11}. A plot of
the simulated graph and its degree distribution can be found in the Supplementary Material
Figure S4. Using this graph as the “true” graph, we simulate ten data sets from the GGM
in (4) by setting H = 200 and K = 1. The precision matrix Ω is constructed by setting
diagonal entries as one and entries corresponding to missing edges as zero. Upper diagonal
entries corresponding to edges in G are simulated randomly from the uniform distribution
on [−0.4,−0.35] ∪ [0.35, 0.4]. The resulting matrix is averaged with its transpose to obtain
a symmetric matrix that is veriﬁed to be positive deﬁnite.

Using Algorithm 1, weighted samples from the posterior distribution are obtained for
each simulated data set under the uniform prior, size-based prior and multiplicative prior
respectively. For the multiplicative model, we set the Beta hyperparameters as a = b = 0.1
(see Figure 2) so that the shape of the prior degree distribution resembles that of the true
graph. Using the weighted samples, we compute the posterior probability of the occurrence of
each edge, and summarize the results using ROC curves in Figure 5. The mean and standard
deviation of the area under the ROC curves (AUC) over the ten data sets are given in Table 1.
While there is some variation in results over diﬀerent simulated data sets, the multiplicative
prior generally performs as well as and in several cases better than the uniform and size-based
prior, with a higher AUC value on the average. We observe that the multiplicative model

18

Figure 5: ROC curves corresponding to diﬀerent priors. Each color corresponds to one of the ten simulated
data sets.

Uniform Size-based MP(0.1,0.1)
0.96 (0.03)

0.91 (0.04)

AUC 0.92 (0.03)

Table 1: AUC values corresponding to diﬀerent priors averaged over ten simulated data sets. Standard
deviation given in brackets.

demonstrates the ability to encourage sparsity generally and in particular graphs where the
connectivity of each node is close to either 0 or 1.

6.2 Application to urinary metabolic data

We analyze urinary metabolic data for H = 127 individuals acquired using 1H NMR spec-
troscopy (see Ellis et al. (2012) for details). These individuals live close to a lead and zinc
smelter at Avonmouth in Bristol, UK, which produces large quantities of airborne cadmium
(Cd). An extremely toxic metal, cadmium is commonly released through industrial processes
and acute exposure poses numerous health risks. Here, we investigate the correlation struc-
ture of p = 22 urinary metabolites listed in Table 2 in response to cadmium exposure through
GGMs. This dataset has also been studied by Salamanca et al. (2014) using Bayesian hier-
archical models. We perform two analyses. In the ﬁrst case, we consider the individuals as
a homogeneous group. In the second case, we divide the individuals into two groups; S1 (a
control group with level of exposure to cadmium lower than or equal to the median) and S2
(a diseased group with level of cadmium higher than the median). In each case, we ﬁrst use
the R package GeneNet (Schaefer et al., 2015) to obtain fast shrinkage estimators of partial
correlation in the network. The degree distributions obtained (see Supplementary Material
Figure S5) can be used as a basis for determining appropriate hyperparameters for the mul-

19

0.00.20.40.60.81.00.00.20.40.60.81.0UniformFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0Size−basedFalse positive rateTrue positive rate0.00.20.40.60.81.00.00.20.40.60.81.0MP(0.1,0.1)False positive rateTrue positive ratetiplicative model. The observations of each variable are ﬁrst normalized to have zero mean
and standard deviation of one in each group.

Degree
Abbrev M(1, 1) M(0.1, 0.1)
TMAO
PCS
Suc
DMA
Creat
4-DEA
Pyr
Cit
3-HV
Gly
Urea
Ala

Metabolites
Trimethylamine oxide
P-cresol-sulphate
Succinate
Dimethylamine
Creatinine
4-deoxyerythronic acid
Pyruvate
Citrate
3-hydroxyisovalerate
Glycine
Urea
Alanine
Phenylacetylglutamine PAG
AcO
Acetate
Hippurate
Hip
DMG
Dimethylgycine
TMA
Trimethylamine
Lactate
Lac
Proline-betaine
PB
N-methyl-nicotinic acid NMNA
Formate
Creatine

For
Crea

4.52
4.33
3.95
3.81
3.54
3.52
3.21
3.15
2.85
2.70
2.62
2.48
2.24
1.93
1.55
1.49
1.28
1.08
0.64
0.56
0.36
0.12

4.62
3.81
4.07
4.05
3.38
1.56
3.19
2.58
2.87
2.79
3.50
2.01
2.12
0.29
2.98
1.88
1.18
0.62
0.06
0.09
0.03
0.01

Betweenness

UF M(1, 1) M(0.1, 0.1)

SB
4.20 5.33
3.72 6.39
3.79
5.71
5.68
3.47
4.93
3.09
5.23
2.63
3.01
5.41
4.84
2.42
4.58
2.74
4.42
2.41
2.09
6.17
5.45
2.38
4.55
2.16
5.13
1.32
1.76
4.86
4.70
1.44
3.28
1.60
0.96
4.56
2.49
0.84
3.06
1.06
2.85
0.43
0.28
1.94

0.15
0.10
0.10
0.10
0.08
0.09
0.05
0.09
0.10
0.07
0.07
0.06
0.02
0.04
0.02
0.02
0.01
0.02
0.00
0.01
0.00
0.00

0.13
0.07
0.10
0.08
0.05
0.02
0.05
0.07
0.08
0.06
0.07
0.03
0.02
0.00
0.05
0.03
0.01
0.01
0.00
0.00
0.00
0.00

SB
UF
0.20 0.08
0.09
0.11
0.17
0.07
0.07
0.12
0.06
0.09
0.08
0.11
0.06
0.06
0.05
0.12
0.06
0.17
0.05
0.10
0.06
0.09
0.07
0.10
0.04
0.05
0.05
0.04
0.04
0.06
0.06
0.04
0.03
0.04
0.02
0.04
0.01
0.01
0.02
0.01
0.02
0.01
0.00
0.01

Table 2: List of 22 urinary metabolites and their abbreviations. Columns 3–6 and columns 7–10 show the
weighted mean degree and betweenness respectively, under the multiplicative model with a = b = 1 (M(1,
1)) and a = b = 0.1 (M(0.1, 0.1)), the size-based prior (SB) and the uniform prior(UF). The highest value
in each column (3–10) is highlighted in bold.

6.3 Case: K = 1

In this section, we study the correlation structure of the metabolites treating the individuals
as one homogeneous group. We compare the performance of four priors on the graphical
space, namely, the multiplicative model with a = b = 1 and a = b = 0.1, the size-based
prior and the uniform prior. We ﬁt a GGM to the data using Algorithm 1, obtaining N =
500 weighted samples from the posterior distribution in each case. Using these weighted
samples, we compute the posterior probability of occurrence of each edge. Figure 6 shows
the graphs obtained under each prior. Only edges with posterior probability greater than 0.5
and associated nodes are shown and the width of each edge is proportional to its posterior

20

Figure 6: Graphs corresponding to diﬀerent priors. Only edges with posterior weights greater than 0.5 are
shown.

probability. Graphs showing the full set of nodes and all possible edges are given in the
Supplementary Material Figure S6. The graphs obtained under the multiplicative model and
the size-based prior have a high degree of similarity and are much sparser than that of the
uniform prior.

Table 2 shows the weighted mean degree and betweenness centrality measures for each
metabolite. The metabolites have been sorted in terms of weighted mean degree in decreasing
order according to M(1,1), the multiplicative model with a = b = 1. Under the multiplicative
model and size-based prior, TMAO has the highest degree as well as betweenness. Under the
uniform prior, PCS has the highest degree with Urea close behind; these two metabolites
also have the highest betweenness.

For the multiplicative model, we can also obtain uncertainty measures of the tendency of
each node to form connections with other nodes. Figure 7 shows the posterior distributions
of the connectivities πi of each metabolite obtained via simulations. It appears that the
multiplicative model with a = b = 0.1 is too strong and places too much prior weight on
values of πi at the extremes of 0 and 1. The multiplicative model with a = b = 1 provides a

21

0.510.530.540.640.650.810.820.960.971111111113−HVAcOPyrSucDMAPCSTMACreatAlaCitPAGTMAOGlyUrea4−DEAa=1, b=1:0.810.850.890.8911111111111PyrSucDMAPCS3−HVTMACreatAlaCitHipPAGTMAOGlyUrea4−DEAa=0.1, b=0.1:0.570.610.610.970.9911111111111PyrSucDMAPCS3−HVTMACreatAlaCitHipPBPAGTMAOGlyUrea4−DEAsize−based:0.510.520.530.550.550.560.580.670.680.690.710.720.720.750.780.850.870.90.980.990.990.990.9911111111113−HVLacAlaAcOPyrSucDMADMGPCSTMACreatCitHipPBPAGNMNATMAOGlyUreaFor4−DEAuniform prior:Figure 7: Posterior distribution of the connectivity (πi) of diﬀerent metabolites under the multiplicative
model with a = b = 1 (ﬁrst 3 rows) and a = b = 0.1 (last 3 rows).

better ﬁt. The mean and 95% credible interval of the connectivity of each metabolite, and
the mean covariance matrix corresponding to the multiplicative model with a = b = 1 are
given in the Supplementary Material Tables S1 and S2.

6.4 Case: K = 2

Next, we investigate the diﬀerence in correlation structure of the urinary metabolites between
the two groups of individuals S1 (with level of exposure to cadmium lower than or equal to
the median) and S2 (level of exposure higher than the median). We consider the covariates xk
for the kth graph to include an intercept and an indicator for level of exposure to cadmium
(1 if above the median and 0 otherwise) so that x1 = (1, 0) and x2 = (1, 1). The diﬀerence in
graphical structure between G1 and G2 due to exposure to urinary cadmium is of interest.
We ﬁt a GGM with K = 2 to the data using the SMC algorithm under four priors. The ﬁrst
three are the multiplicative model with σ2
2 = 10,

2 = 10 and σ2

1 = 1 and σ2

1 = σ2

2 = 1, σ2

1 = σ2

22

0.00.60.01.5TMAODensity0.00.60.01.5PCSDensity0.00.60.01.0SucDensity0.00.60.01.5DMADensity0.00.60.01.5CreatDensity0.00.60.01.04−DEADensity0.00.60.01.5PyrDensity0.00.60.01.5CitDensity0.00.60.01.53−HVDensity0.00.60.01.5GlyDensity0.00.60.01.0UreaDensity0.00.60.01.5AlaDensity0.00.60.01.5PAGDensity0.00.60.01.5AcODensity0.00.60.02.0HipDensity0.00.60.02.0DMGDensity0.00.602TMADensity0.00.602LacDensity0.00.6024PBDensity0.00.6024NMNADensity0.00.6036ForDensity0.00.6048CreaDensity0.00.60.02.0TMAODensity0.00.60.01.5PCSDensity0.00.60.01.5SucDensity0.00.60.01.5DMADensity0.00.60.01.5CreatDensity0.00.602464−DEADensity0.00.60.52.0PyrDensity0.00.60.01.5CitDensity0.00.60.52.03−HVDensity0.00.60.52.0GlyDensity0.00.60.51.5UreaDensity0.00.60.02.0AlaDensity0.00.60.02.0PAGDensity0.00.601020AcODensity0.00.60.51.5HipDensity0.00.6048DMGDensity0.00.60246TMADensity0.00.6010LacDensity0.00.6010PBDensity0.00.6010NMNADensity0.00.601025ForDensity0.00.601025CreaDensityand the last is the uniform prior. From Figure 4 and the preliminary degree distributions
obtained using GeneNet (see Supplementary Material Figure S5), taking σ2
2 = 1 seems
appropriate but we wish to investigate if there is any beneﬁt to be gained by allowing the
structure of G2 to vary more signiﬁcantly from that of G1 by taking σ2
2 to be 10 and whether
a prior which assumes the tendencies to connect are closer to the extremes of 0 and 1 is more
appropriate (σ2

1 = σ2

1 = σ2

2 = 10).

1 = σ2

Using Algorithm 1, we obtain weighted samples from the posterior distribution under
each of the four priors. The ESS and acceptance rate in the SMC sampler are monitored
at each iteration and these plots are given in the Supplementary Material Figure S7 for the
multiplicative prior with σ2
2 = 1. Typically, the ESS decreases as the algorithm proceeds
until it falls below the threshold, Nthreshold = N/3, and it bounces back after resampling is
performed. Due to bridging of target densities using tempering, the acceptance rate is usually
high at the beginning when the temperature φt is close to zero and proposals have a high
probability of being accepted [see (19)]. As the temperature increases, the samples becomes
more concentrated in the regions of high posterior probability and the acceptance rate falls.
Figure 8 shows the diﬀerential network corresponding to the diﬀerent priors. It highlights
the diﬀerences between G1 and G2 by displaying only edges which have high posterior prob-
ability (e.g. greater than 0.5) of appearing in one graph but not the other (see, e.g. Valcarcel
et al., 2011). Due to space limitations, further detailed results are given in the Supplemen-
tary Material. These include weighted graphs obtained from Algorithm 1 under diﬀerent
priors (Figures S8 and S9), posterior distributions (Figures S10, S11 and S12), betweenness
centrality measures, weighted means and 95% credible intervals of the connectivities (πi,k)
and regression coeﬃcients (βiq) of each metabolite (Tables S4, S5 and S6) and the mean
covariance matrices corresponding to the multiplicative prior with σ2
2 = 1 (Tables S7
and S8).

1 = σ2

The full network in the K = 1 case and the diﬀerential network in the K = 2 case
both show similar topological characteristics corresponding to sub-graphs of metabolites.
For the case of K = 2, the diﬀerent prior hyperparameters only lead to diﬀerent levels
of shrinkage, but there is a high degree of similarity in terms of biological interpretation.
For example, both Figures 6 and 8 show three diﬀerent sub-graphs linking metabolites with
shared metabolic origin. First, a group of organic acids including succinate, pyruvate, acetate
and para-cresol sulphate (PCS) are connected, sometimes also with phenylacetylglutamine
(PAG). Several of these metabolites (PCS and PAG) are known to be of gut bacterial origin,
and Cd stress is known to modulate gut microbiota populations in mice (Liu et al., 2014).

23

Figure 8: Diﬀerential network corresponding to the diﬀerent priors. Blue edges represent edges with posterior
probability more than 0.5 of appearing in G1 but not in G2 and pink edges represent edges with posterior
probability more than 0.5 of appearing in G2 but not in G1.

Increased acetate is a known consequence of renal damage, which could be linked to high Cd
levels in this population. The second group contains trimethylamine (TMA) and its oxidation
product trimethylamine-N-oxide (TMAO), both part of choline metabolism, plus 3-HV and
4-DEA which are products of amino acid catabolism. Choline is an essential nutrient and
is metabolised primarily in the liver. Due to its long biological half-life, Cd accumulates
in human tissues, especially the liver and kidney, so this observation may point towards a
possible mechanistic connection. Moreover, in their original study of this data set, Ellis et al.
(2012) reported a positive correlation between urinary Cd and both 4-DEA and 3-HV, though

24

s12 = 1 , s22 = 10.530.510.980.560.590.970.560.530.540.590.590.990.690.850.92lllllllllllllllAcOPyrSucDMGCreatPCSTMAOFor4−DEAPBAla3−HVTMACitGlys12 = 1 , s22 = 100.980.980.980.510.730.731.000.890.93llllllllllllAcOSucPyrPCSPAGPB4−DEA3−HVCreatTMAOCitGlys12 = 10 , s22 = 100.930.830.540.550.840.580.980.710.680.96lllllllllllAcOSucPyrCitPCS3−HVCreatTMAOTMAGly4−DEAUniform prior0.670.870.860.600.750.910.920.500.850.810.910.740.710.780.810.900.590.540.900.540.530.630.530.620.660.730.720.51lllllllllllllllllllllLacAcOSucPyrAlaCitDMADMGCreatPCSNMNAGlyPBUreaForTMAO4−DEA3−HVTMACreaPAGthis relationship did not survive correction for age and sex. The third group links citrate
and glycine, closely associated via malate and glyoxylate in central carbon metabolism (the
network of metabolic reactions essential to life). A strong correlation between Cd and citrate
was found by Ellis et al. (2012), while Valcarcel et al. (2011) found a signiﬁcant deregulation
of the dependency network associated with dimethylglycine, a biproduct of the synthesis of
glycine from choline. Thus, it is plausible that several of the metabolites found in the networks
of Figures 6 and 8 are involved in pathways disregulated due to Cd exposure. However,
metabolite associations derive from a variety of factors and many may be indirect, and
possibly non-biochemical in origin, e.g. change in expression of membrane transporters. Thus
interpretation of dependency networks, such as those generated here, is diﬃcult. Nonetheless,
they give us a novel view of the data not exposed in conventional analyses, and may serve
to help generate new hypotheses to be investigated by future biochemical experiments.

7 Conclusion

This article proposes using the multiplicative or Chung-Lu random graph model as a prior
on the graphical space of GGMs, where the probability of inclusion of each edge is a product
of the connectivities of the end nodes. This model can be used to encourage sparsity or
particular degree structures, when such prior knowledge is available, say from a database
or based on expert opinion. A Bayesian approach is adopted and priors are further placed
on the connectivity of the nodes. We study the degree and clustering properties of the mul-
tiplicative prior and note that this prior is able to accommodate a wider range of degree
structures than the Erd˝os-R´enyi model. For example, we can use it to encourage shrinkage
towards the extremes of 0 and 1, or degree distributions that are right-skewed by varying
the hyperparameters, We illustrate how this prior can be applied to both single and multiple
GGMs and a SMC sampler is developed for posterior inference. We ﬁnd the performance of
this sampler to be stable and consistent in our experiments and it can also be parallelized
easily. The multiplicative prior also yields rich posterior inference, enabling a study of the
connectivity of each node and how the propensity to connect varies across diﬀerent exper-
imental conditions in the case of multiple GGMs. This allows deeper exploration into the
structure of dependency networks and may aid in the formulation of new scientiﬁc hypothesis
and in opening further lines of investigations.

25

8 Acknowledgments

Linda Tan is supported by the National University of Singapore Overseas Postdoctoral Fel-
lowship. Ajay Jasra is supported by AcRF Tier 1 grant R-155-000-156-112.

References

Armstrong, H., Carter, C. K., Wong, K. F. K. and Kohn, R. (2009). Bayesian covariance matrix estimation

using a mixture of decomposable graphical models. Statistics and Computing, 19, 303–316.

Atay-Kayis, A. and Massam, H. (2005). A Monte Carlo method for computing the marginal likelihood in

nondecomposable Gaussian graphical models. Biometrika, 92, 317–335.

Carvalho C. M. and Scott, J. G. (2009). Objective Bayesian model selection in Gaussian graphical models.

Biometrika, 3, 497–512.

Carvalho, C. M. and West, M. (2007). Dynamic Matrix-Variate Graphical Models. Bayesian Analysis, 2,

69–98.

Chun, H., Zhang, X. and Zhao, H.

regulation network inference with joint
sparse Gaussian graphical models. Journal of Computational and Graphical Statistics, DOI:
10.1080/10618600.2014.956876.

(2014). Gene

Chung, F. and Lu, L. (2002). The average distances in random graphs with given expected degrees. Proceed-

ings of the National Academy of Sciences of the United States of America, 99, 15879–15882.

Danaher, P., Wang, P. and Witten, D. M. (2014). The joint graphical lasso for inverse covariance estimation

across multiple classes. Journal of the Royal Statistical Society: Series B, 76, 373–397.

Del Moral, P., Doucet, A. and Jasra, A. (2006). Sequential Monte Carlo samplers. Journal of the Statistical

Royal Society: Series B, 68, 411–436.

Dempster, A. P. (1972). Covariance selection. Biometrics, 157–175.

Diaconis, P. and Ylvisaker, D. (1979). Conjugate priors for exponential families. The Annals of Statistics, 7,

269–281.

Dobra, A., Hans, C., Jones, B., Nevins, J. R., Yao, G. and West, M. (2004). Sparse graphical models for

exploring gene expression data. Journal of Multivariate Analysis, 90, 196–212.

Ellis, J. K., Athersuch, T. J., Thomas, L. D., Teichert, F., Perez-Trujillo, M., Svendsen, C., Spurgeon,
D. J., Singh, R., Jarup, L., Bundy, J. G. and Keun, H. C. (2012). Metabolic proﬁling detects early
eﬀects of environmental and lifestyle exposure to cadmium in a human population. BMC Medicine, 10:61.
doi:10.1186/1741-7015-10-61.

26

Friedman, J., Hastie, T. and Tibshirani, R. (2008). Sparse inverse covariance estimation with the graphical

lasso. Biostatistics, 9, 432–441.

Guo, J., Levina, E., Michailidis, G., and Zhu, J. (2011). Joint estimation of multiple graphical models.

Biometrika, 98, 1–15.

Jasra, A., Stephens, D. A., Doucet, A. and Tsagaris, T. (2011). Inference for L´evy-Driven Stochastic Volatility

Models via Adaptive Sequential Monte Carlo Scandinavian Journal of Statistics, 38, 1–22.

Jones, B., Carvalho, C., Dobra, A., Hans, C., Carter, C. and West, M. (2005). Experiments in stochastic

computation for high-dimensional graphical models. Statistical Science, 20, 388–400.

Lauritzen, S. L. (1996). Graphical Models. Oxford University Press.

Lenkoski, A. and Dobra, A. (2011). Computational aspects related to inference in Gaussian graphical models

with the G-Wishart prior. Journal of Computational and Graphical Statistics, 20, 140–157.

Liu Y., Li, Y., Liu, K. and Shen J. (2014). Exposing to cadmium stress cause profound toxic eﬀect on

microbiota of the mice intestinal tract. PLoS ONE, 9(2): e85323. doi:10.1371/journal.pone.0085323

Newman, M. E. J., Strogatz, S. H. and Watts, D. J. (2001). Random graphs with arbitrary degree distribu-

tions and their applications. Physical Review E, 64. doi: 10.1103/PhysRevE.64.026118.

Olhede, S. C. and Wolfe, P. J. (2013). Degree-based network models. arXiv:1211.6537

Peterson, C., Stingo, F. C. and Vannucci, M. (2015). Bayesian inference of multiple Gaussian graphical

models. Journal of the American Statistical Association, 110, 159–174.

Rastelli, R., Friel, N. and Raftery, A. E. (2015). Properties of

latent variable network models.

arXiv:1506.07806.

Roverato, A. (2002). Hyper inverse Wishart distribution for non-decomposable graphs and its application to

Bayesian inference for Gaussian graphical models. Scandinavian Journal of Statistics, 29, 391–411.

Salamanca, B. V., Ebbels, T. M. D. and De Iorio, M. (2014). Variance and covariance heterogeneity analysis
for detection of metabolites associated with cadium exposure. Statistical Applications in Genetic and
Molecular Biology

Schaefer, J., Opgen-Rhein, R. and Strimmer, K. (2015). R package: GeneNet version 1.2.13. https://cran.

r-project.org/web/packages/GeneNet/index.html

Telescar, D., M¨uller, P., Parmigiani, G. and Freedman, R. S. (2012). Modeling dependent gene expression.

The Annals of Applied Statistics, 6, 542560.

Valc´arcel, B., W¨urtz, P., Seich al Basatena N.-K., Tukiainen, T., Kangas, A. J., Soininen, P., J¨arvelin,
M.-R., Ala-Korpela, M., Ebbels, T. M. and de Iorio, M. (2011) A diﬀerential network approach to ex-
ploring diﬀerences between biological states: an application to prediabetes. PLoS ONE, 6(9): e24702.
doi:10.1371/journal.pone.0024702

27

Wang, H., Reesony, C. and Carvalhoz, C. M. (2011). Dynamic ﬁnancial index models: modeling conditional

dependencies via graphs. Bayesian Analysis, 6, 639–664.

Wang, H. and Li, S. Z. (2012). Eﬃcient Gaussian graphical model determination under G-Wishart prior

distributions. Electronic Journal of Statistics, 6, 168–198.

Yajima, M., Telesca, D. and M¨uller, P. (2015). Detecting diﬀerential patterns of interaction in molecular

pathways. Biostatistics, 16, 240–251

28

Supplementary Material for “Multiplicative Prior and Sequential Monte

Carlo Methods for Multiple Gaussian Graphical Models”

Linda S. L. Tan∗, Ajay Jasra∗, Maria De Iorio† and Timothy M. D. Ebbels‡

∗ Department of Statistics and Applied Probability, National University of Singapore

† Department of Statistical Science, University College London
‡ Department of Surgery and Cancer, Imperial College London

S1 Properties of multiplicative model

S1.1 Derivations

This section provides the proofs of properties P1 - P9 given in Section 2.1 of the manuscript.
• Proof of P1: The probability of a random node j being connected to a node i with

connectivity πi is given by(cid:82) 1
• Proof of P2: From P1, Aij|πi ∼ Bernoulli(πiµ) for any j (cid:54)= i. Since Di = (cid:80)

0 πiπjp(πj) dπj = πiµ.

Di|πi ∼ Binomial(p−1, πiµ). Therefore E(Di|πi) = (p−1)µπi. We also have E(D2
(p − 1)µπi + (p − 1)(p − 2)µ2π2
i .

j(cid:54)=i Aij,
i |πi) =

G(k)
Di

(z) =

(cid:90) 1
(cid:90) 1
(p−1−k)! µk(cid:82) 1

=

0

0

29

P r(Di = d|πi)zd

• Proof of P3:

E(zDi|πi) =

p−1(cid:88)
(cid:18)p − 1
(cid:19)
p−1(cid:88)
Therefore E(zDi) = E{E(zDi|πi)} =(cid:82) 1

d=0

d=0

=

d

(µπiz)d(1 − µπ)p−1−d

= (1 − µπi + µπiz)p−1.

0 (1 − µπi + µπiz)p−1p(πi) dπi.

p(πi)

∂k
∂kz

(1 − µπi + µπiz)p−1 dπi
(p − 1)!

p(πi)

(p − 1 − k)!

(µπi)k(1 − µπi + µπiz)p−1 dπi.

Hence G(k)
Di

(1) = (p−1)!

0 p(πi)πk

i dπi = (p−1)!B(a+k,b)

(p−1−k)!B(a,b) µk.

• Proof of P4: We have

E(Di) = E{E(Di|πi)} = (p − 1)µ2.
E(D2

i ) = E{E(D2

i |πi)} = (p − 1)µ2 + (p − 1)(p − 2)µ2(µ2 + σ2).

i ) − E(D2

Hence, Var(Di) = E(D2

• Proof of P5: Since P (Di = d|πi) = (cid:0)p−1
(cid:82) 1
0 P (Di = d|πi)p(πi)dπi.

d

i ) = (p − 1)µ2{1 − µ2 + (p − 2)σ2}.

(cid:1)(µπi)d(1 − µπ)p−1−d, we have P (Di = d) =

• Proof of P6: The dispersion index of the degree distribution can be computed as
(a+b)2(a+b+1), we get

E(Di) = 1 − µ2 + (p − 2)σ2. Substituting µ = a

a+b and σ2 =

Var(Di)

ab

the result.
• Proof of P7:

E(D3

i |πi) = (p − 1)(p − 2)(p − 3)(µπi)3 + 3(p − 1)(p − 2)(µπi)2 + (p − 1)µπi.

Hence E(D3

i ) = (p − 1)(p − 2)(p − 3)µ3E(π3

i ) + 3(p − 1)(p − 2)µ2(µ2 + σ2) + (p − 1)µ2,

where E(π3

i ) =

(a+2)(a+1)a

(a+b+2)(a+b+1)(a+b).

• Proof of P8: The average degree of node j given that it is connected to a node with

connectivity πi is given by

d P(Dj = d|Aij = 1, πi)

=

d=1

p−1(cid:88)
(cid:90) p−1(cid:88)
(cid:90) p−1(cid:88)
(cid:90) p−2(cid:88)
(cid:90)

x=0

d=1

d=1

=

=

(cid:18)p − 2

d P(Dj = d|Aij = 1, πi, πj)P(πj|Aij = 1, πi) dπj

(cid:19)
(πjµ)d−1(1 − πjµ)p−2−(d−1) P(Aij = 1|πi, πj)p(πi)p(πj)
(cid:18)p − 2
(cid:19)

P(Aij = 1|πj)p(πi)

d − 1

d

dπj

(x + 1)

(πjµ)x(1 − πjµ)p−2−x πiπj
πiµ

x

p(πj) dπj

{(p − 2)πjµ + 1}πj
=
µ
= (p − 2)(µ2 + σ2) + 1

p(πj) dπj

Therefore the average degree of a neighbour of node i is independent of its connectivity

30

d P(Dj = d|Aij = 1, Di = k)

d=1

p−1(cid:88)
(cid:90) p−1(cid:88)
(cid:90) p−1(cid:88)

d=1

=

d P(Dj = d|Aij = 1, Di = k, πi)P(πi|Aij = 1, Di = k) dπi

(20)

d P(Dj = d|Aij = 1, πi)

P(πi, Aij = 1, Di = k)

P(Aij = 1, Di = k)

dπi.

=

From above, we have(cid:80)p−1

d=1

πi. Similarly, the average degree of node j given that it is connected to a node with
degree k is given by

d=1 d P(Dj = d|Aij = 1, πi) = (p − 2)(µ2 + σ2) + 1 and

P(Di = k|πi, Aij = 1)P(Aij = 1|πi)p(πi)

(cid:82) P(Di = k|πi, Aij = 1)P(Aij = 1|πi)p(πi)dπi
(cid:0)p−2
(cid:1)(πµ)k(1 − πµ)p−1−k p(πi)
(cid:82)(cid:0)p−2
(cid:1)(πµ)k(1 − πµ)p−1−k p(πi)dπi

k−1
k−1

P(Di = k|πi) p(πi)

.

P(Di = k)

P(πi, Aij = 1, Di = k)

P(Aij = 1, Di = k)

=

=

=

Therefore (20) simpliﬁes to (p − 2)(µ2 + σ2) + 1, which is again independent of the
degree of i.

• Proof of P9: The global clustering coeﬃcient can be written as

(cid:82) (πiπk)(πkπj)(πjπi)p(πi)p(πj)p(πk) dπidπjdπk
(cid:82) (πiπk)(πkπj)p(πi)p(πj)p(πk) dπidπjdπk

=

(σ2 + µ2)3
(σ2 + µ2)2µ

=

a + 1

a + b + 1

.

S1.2 Dispersion index and skewness

Figures S1 and S2 show plots of the dispersion index and skewness as a function of a and b
for p = 100. The left plots in Figures S1 and S2 show how the dispersion index and skewness
vary across a wide range of hyperparameter values. The right plot in Figure S1 shows some
cross-sectional plots of the skewness while the right plot in Figure S2 compares the skewness
of the multiplicative prior with the Erd˝os-R´enyi model for the same mean degree when
p = 100 and b = 5. The multiplicatve model tends to be more positively skewed for small
values of a and less so for large values of a as compared to the Erd˝os-R´enyi model.

31

Figure S1: Left: Dispersion index as a function of hyperparameters a and b in the Beta prior for p = 100.
Right: Cross-sectional plots for b = 1, 5, 10, 20.

Figure S2: Left: Skewness as a function of hyperparameters a and b in the Beta prior for p = 100. Right:
Comparison of skewness of multiplicative prior with the Erd˝os-R´enyi model for the same mean degree.

Illustration of connectivity of nodes when K = 2

S2
In our proposed prior for multiple GGMs, the connectivity of node i is π1,i = {1+exp(−βi1)}−1
in G1 and π2,i = {1 + exp(−βi1 − βi2)}−1 in G2 when K = 2, x1 = (1, 0) and x2 = (1, 1). The
relationship between the connectivity of a node and its regression coeﬃcients is illustrated
in Figure S3.

S3 Laplace approximation

The gradients and Hessians required in the Laplace approximation for computing prior prob-
abilities of graphs described in Section 4.1 are given below. They can be derived using vector

32

102030405010203040500123456abDispersion0102030400246810p=100aDispersionb=1b=5b=10b=20246810246810−4−20246810abSkewness020406080100−2−101234n=100, b=5average degreeSkewnessMultiplicative modelErdos−RenyiFigure S3: Connectivity of node i in G2 (π2,i) as a function of βi2 (black line), with βi1 ﬁxed at 1. Red
dotted line marks the value of π1,i.

diﬀerential calculus and a useful reference is Magnus and Neudecker (1988).

=

πi

1+exp(ui), d2πi

du2
i

= dπi
dui

1−exp(ui)
1+exp(ui) and

/(1 − πi) −(cid:80)

= a + di − (a + di + 1)πi − (b − 1) dπi

dui

j(cid:54)=i(1 − Aij)πj

/(1 − πiπj),

dπi
dui

For K = 1, we have dπi
dui
• ∂f
•

∂2f

∂ui

∂ui∂uj

• ∂2f

∂u2
i

For K > 1, we have ∂πk,i
∂βi

/(1 − πiπj)2,

(cid:110) d2πi

du2
i

dui

duj

πj

dπi
dui

d2πi
du2
i

− (b − 1)

= −(1 − Aij) dπj
−(cid:80)
= −(a + di + 1) dπi
j(cid:54)=i(1 − Aij)
(cid:110)
=(cid:80)K
= −(cid:80)K
= −(cid:80)K

(cid:110)
i xk) −(cid:80)
(cid:110) dk,iπk,i
i xk) +(cid:80)

= πk,ixk
1+exp(βT

1+exp(βT

1+exp(βT

j(cid:54)=i

k=1

k=1

dk,i

• ∂f

∂βi

•

•

∂2f

∂βi∂βT
j

∂2f
∂βiβT
i

/(1 − πi) + ( dπi

/(1 − πiπj) + π2

j ( dπi
dui

= πk,i

i xk), ∂2πk,i

∂βi∂βT
i
(1−Ak,ij )πk,iπk,j
(1−πk,iπk,j ){1+exp(βT

dui

)2/(1 − πi)2(cid:111)
)2/(1 − πiπj)2(cid:111)
(cid:111)
(cid:17)T

i xk)
i xk)}2 xkxT
xk − diag( 1

1−exp(βT
{1+exp(βT

.

,

i xk)}

(cid:16) ∂πk,j

∂βj

k and

σ2 )βi,

(1−Ak,ij )πk,iπk,j{1−exp(βT

i xk)(1−πk,iπk,j )}

(1−πk,iπk,j )2{1+exp(βT

i xk)}2

j(cid:54)=i

k=1(1 − Ak,ij)(1 − πk,iπk,j)−2 ∂πk,i

∂βi

(cid:111)

xkxT

k −diag( 1
σ2 ),

where 1

σ2 = ( 1
σ2
1

, . . . , 1
σ2
Q

) is evaluated element-wise.

S4 Simulated data

Figure S4 shows the true graph simulated from the multiplicative model in (2) and its degree
distribution.

33

−6−4−202460.00.20.40.60.81.0bi2p2,ip1,iFigure S4: Left: True graph from which data are simulated. Right: Degree distribution of true graph.

S5 Urinary metabolic data

Figure S5 shows the degree distributions estimated using GeneNet.

Figure S5: Degree distributions estimated using GeneNet for the case where the individuals are treated as
one heterogeneous group (left) and where they are divided into two groups S1 (middle) and S2 (right).

S5.1 Case: K = 1

Figure S6 shows the graphs obtained from Algorithm 1 under each prior. The width of every
edge is proportional to its posterior weight. Table S1 shows the mean and 95% credible
interval of the connectivity of each metabolite. Table S2 shows the mean precision matrix
corresponding to the multiplicative prior with a = b = 1.

S5.2 Case: K = 2

Figure S7 shows a plot of the ESS and mean acceptance rate in the MCMC steps at each
iteration for the multiplicative prior with σ2
2 = 1. Figure S8 shows the graphs of G1
and G2 corresponding to diﬀerent priors. The width of the edges are proportional to their

1 = σ2

34

True graphllllllllllllllllllll12345678910111213141516171819200510150.000.100.200.30Degree distributionDegreeProportion of nodesllllllllllllllllllllll051015200.00.10.20.30.4GDegreeProportion of nodesllllllllllllllllllllll051015200.00.10.20.30.4G1DegreeProportion of nodesllllllllllllllllllllll051015200.00.10.20.30.4G2DegreeProportion of nodesFigure S6: Graphs corresponding to diﬀerent priors. Width of edges are proportional to their posterior
weights.

35

3−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAa=1, b=1:3−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAa=0.1, b=0.1:3−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAsize−based:3−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAuniform prior:M(1, 1)

M(0.1, 0.1)

Abbrev
¯πi
TMAO 0.48
0.46
PCS
Suc
0.43
0.42
DMA
Creat
0.39
4-DEA 0.39
Pyr
0.36
0.36
Cit
0.33
3-HV
0.32
Gly
Urea
0.31
0.30
Ala
0.28
PAG
0.25
AcO
Hip
0.22
0.22
DMG
0.20
TMA
0.18
Lac
PB
0.14
NMNA 0.14
0.12
For
Crea
0.10

CI (πi)

(0.15, 0.84)
(0.11, 0.84)
(0.06, 0.81)
(0.07, 0.80)
(0.07, 0.76)
(0.02, 0.79)
(0.05, 0.73)
(0.05, 0.71)
(0.05, 0.66)
(0.04, 0.66)
(0.00, 0.75)
(0.02, 0.63)
(0.02, 0.60)
(0.00, 0.63)
(0.00, 0.60)
(0.00, 0.58)
(0.00, 0.46)
(0.00, 0.52)
(0.00, 0.47)
(0.00, 0.48)
(0.00, 0.44)
(0.00, 0.43)

¯πi
0.54
0.43
0.46
0.46
0.38
0.18
0.36
0.28
0.32
0.31
0.40
0.22
0.23
0.05
0.33
0.21
0.13
0.08
0.02
0.03
0.02
0.02

CI (πi)

(0.00, 0.90)
(0.06, 0.96)
(0.07, 0.95)
(0.07, 0.96)
(0.06, 0.99)
(0.00, 0.14)
(0.05, 0.99)
(0.00, 0.65)
(0.00, 0.81)
(0.00, 0.76)
(0.01, 1.00)
(0.00, 0.62)
(0.00, 0.68)
(0.00, 0.05)
(0.04, 1.00)
(0.00, 0.19)
(0.00, 0.11)
(0.00, 0.07)
(0.00, 0.03)
(0.00, 0.03)
(0.00, 0.03)
(0.00, 0.03)

Table S1: Mean and 95% credible interval of the connectivity (πi) of each metabolite under the multiplicative
prior with a = b = 1 (M(1, 1)) and a = b = 0.1 (M(0.1, 0.1)).

TMAO PCS Suc DMA Creat 4-DEA Pyr Cit 3-HV Gly Urea Ala PAG AcO Hip DMG TMA Lac PB NMNA For Crea
-0.00 -0.00 -0.00
0.01 0.00 0.00
0.00 -0.01 -0.00
0.00 0.00 -0.00
0.01 0.03 0.00
0.00 0.00 -0.00
0.06 0.00 0.00
0.00 -0.00 0.00
-0.00 0.00 0.00
0.00 -0.00 0.00
0.00 0.00 -0.00
0.00 -0.00 -0.00
0.00 0.00 -0.00
0.00 -0.00 -0.00
-0.01 -0.00 0.00
0.00 -0.00 -0.00
-0.00 -0.00 0.00
0.00 -0.00 -0.00
0.00 -0.00 0.00
1.05 -0.00 0.00
. 1.04 0.00
.
. 1.03

0.00 0.00 0.00 -0.52 -0.00 -0.01 -0.00 -0.00 0.00 0.02 -0.01 -0.43 -0.00 -0.00
0.01 -0.00 0.06 0.00
-0.36 -3.62 -0.00
0.00 0.01 -0.02 -0.00 -2.11 -0.02 0.00
-0.04 0.67 -0.57 -0.00 -0.00 0.05 -0.00 0.05 -0.19 -0.00
0.00
0.00 0.00 -0.00
-0.01 -0.00 -0.00 -0.00 -0.00 0.24 -0.00 -0.00 0.10 0.09 -0.01 -0.02 0.00 -0.00
-0.01 0.02 0.00 -0.00 -0.00 -0.00 0.00 0.00 0.02 0.06 -0.12 -0.00 0.00 0.00
1.34 0.15 0.00 -0.41 -0.00 0.00 -0.00 0.36 -0.00 0.00 -0.00 -0.00 -0.00 -0.13
0.02 -0.00 0.01 0.00
0.00
0.02 0.00 0.00
1.46 -0.00 0.00 -0.15 0.00 0.00 0.00 -0.02 -0.00 -0.00 -0.00
. 1.56 0.03 -0.60 0.00 0.01 0.02 -0.05 -0.00 -0.00 -0.00
. 1.21 0.00 -0.00 -0.04 0.17 -0.03 -0.00 0.06 0.00
.
.
.
. 1.41 0.00 0.00 0.05 -0.07 -0.00 -0.06 0.00
0.00 0.02 0.00
.
.
.
0.00
0.00 -0.02 0.00
.
.
.
0.00
0.01
.
.
.
0.00 0.00 -0.00
1.11 -0.01 -0.00 -0.00
.
.
.
.
.
.
1.21 0.00 0.00
. 1.08 -0.00
.
.
.
. 1.07
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

0.00 -0.00 -0.01 -0.02 -0.08 0.01 0.00
. 1.54 -0.00 -0.52 0.07 -0.01 -0.00 0.11 0.00
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 4.23 -0.00
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

0.82
2.64 0.00 0.00 -1.86
0.00
0.02
0.00 -0.00
3.02 -1.30
1.71
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 5.93 -0.82
. 1.53
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 2.83 0.00 -0.00
. 1.14 0.00
.
. 1.13
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

TMAO
PCS
Suc
DMA
Creat
4-DEA
Pyr
Cit
3-HV
Gly
Urea
Ala
PAG
AcO
Hip
DMG
TMA
Lac
PB
NMNA
For
Crea

Table S2: Mean precision matrix Ω correponding to K = 1 and multiplicative prior with a = b = 1.

36

posterior weights. Figure S9 shows these graphs but displaying only edges with posterior
weights greater than 0.5 and associated nodes. Table S3 shows a list of 10 edges which are
most likely to appear in G1 but not in G2 and vice versa under each prior. Tables S4, S5
and S6 show the mean and 95% credible interval of (1) the connectivity (πik) and (2) the
regression coeﬃcients (βiq) of each metabolite for k = 1, 2, q = 1, 2, and the weighted mean
betweenness centrality measure in each graph under the multplicative priors. Figures S10,
S11 and S12 show the posterior distributions of the connectivity and regression coeﬃcients
of each metabolite under the multplicative priors. Tables S7 and S8 show the mean precision
matrix of G1 and G2 corresponding to the multiplicative prior with σ2

1 = σ2

2 = 1.

Figure S7: Typical plot of ESS (left) and mean acceptance rate (right) of SMC algorithm. This plot is
obtained from ﬁtting the urinary metabolic data using K = 2 for the multiplicative prior with σ2
2 = 1.

1 = σ2

References

Magnus, J. R. and Neudecker, H. (1988). Matrix diﬀerential calculus with applications in statistics and

econometrics. Wiley, Chichester, UK.

37

0501001502000100200300400500IterationESS0501001502000.00.20.40.60.81.0IterationMean acceptance rateFigure S8: Graphs of G1 and G2 corresponding to diﬀerent priors. Width of edges are proportional to their
posterior weights.

38

3−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAs12 = 1 , s22 = 1 :G13−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAG23−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAs12 = 1 , s22 = 10 :G13−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAG23−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAs12 = 10 , s22 = 10 :G13−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAG23−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAUniform prior:G13−HVLacAlaAcOPyrSucCitDMATMADMGCreaCreatPBPCSPAGHipNMNATMAOGlyUreaFor4−DEAG2Figure S9: Plots of G1 and G2 showing edges with weights greater than 0.5 corresponding to diﬀerent priors.

39

0.510.530.540.560.560.580.590.610.620.710.870.970.990.9911111AcOPyrAlaSucDMADMGPCSCreatTMAOPBCitPAGGlyFor4−DEAs12 = 1 , s22 = 1 :G10.50.510.540.590.720.860.931111111SucAlaDMAPyrPCS3−HVTMACreatCitDMGPAGTMAOGlyUrea4−DEAG20.60.670.730.970.981111111AcOPyrSucDMAPCSCreatAlaPBCitPAGTMAOGly4−DEAs12 = 1 , s22 = 10 :G10.530.570.670.740.980.99111111Suc3−HVDMAPyrPCSTMACreatAlaCitPAGTMAOGly4−DEAG20.550.560.590.830.880.930.930.9911111AcOPyrSucDMAPCSCreatAlaCitPAGTMAOGlys12 = 10 , s22 = 10 :G10.570.60.670.730.760.910.940.9911111Suc3−HVDMAPyrPCSTMACreatAlaCitPAGTMAOGly4−DEAG20.510.510.550.560.590.610.610.650.740.860.870.880.890.930.940.950.950.960.960.970.970.981111113−HVLacAcOPyrAlaSucDMADMGCreaPCSCreatCitPBHipTMAOPAGNMNAGlyUreaFor4−DEAUniform prior:G10.50.50.50.550.590.620.630.650.650.670.670.690.740.750.840.860.890.910.920.980.9811111111LacSuc3−HVAlaDMAPyrPCSTMACreatCitPBAcODMGCreaHipPAGNMNATMAOGlyUreaFor4−DEAG2σ2
1 = σ2

2 = 1:

σ2
1 = 1, σ2

2 = 10:

1 = σ2
σ2

2 = 10:

Uniform prior:

In G1 but not in G2

In G2 but not in G1

11

10

11

10

00

01 Edge

Edge
00
01
Pyr – Suc
0.01 0.01 0.98 0.00 3-HV – TMAO 0.00 0.01 0.00 0.99
Suc – PCS
0.00 0.03 0.97 0.00 3-HV – 4-DEA 0.07 0.00 0.00 0.92
AcO – PCS
0.40 0.00 0.59 0.01 Cit – Gly
0.00 0.15 0.00 0.85
PCS – 4-DEA 0.38 0.03 0.59 0.01 TMA – TMAO 0.21 0.03 0.07 0.69
0.41 0.01 0.00 0.59
DMG – Creat 0.43 0.01 0.56 0.00 Ala – DMG
0.43 0.01 0.56 0.01 DMA – Urea
TMAO – For
0.45 0.01 0.05 0.50
0.51 0.01 0.00 0.48
PB – 4-DEA 0.42 0.03 0.54 0.00 3-HV – Creat
0.47 0.00 0.05 0.47
AcO – Pyr
0.45 0.01 0.53 0.01 Crea – Urea
0.65 0.01 0.02 0.32
Pyr – 4-DEA 0.47 0.00 0.53 0.00 Ala – DMA
AcO – Suc
0.49 0.00 0.51 0.00 AcO – DMA
0.32 0.01 0.37 0.31

Suc – PCS
AcO – Suc
Pyr – Suc
PB – 4-DEA 0.27 0.00 0.73 0.00 3-HV – Creat
Pyr – PAG
DMG – Creat 0.49 0.00 0.49 0.02 Ala – DMG
Suc – 4-DEA 0.53 0.00 0.47 0.00 DMA – Urea
Suc – Cit
Ala – Cit
Pyr – DMG

0.00 0.01 0.98 0.00 3-HV – TMAO 0.00 0.00 0.00 1.00
0.02 0.00 0.98 0.00 3-HV – 4-DEA 0.02 0.06 0.00 0.93
0.00 0.10 0.01 0.89
0.00 0.02 0.98 0.00 Cit – Gly
0.26 0.01 0.00 0.73
0.00 0.49 0.51 0.00 TMA – TMAO 0.46 0.03 0.01 0.49
0.54 0.01 0.00 0.45
0.54 0.01 0.04 0.42
0.00 0.54 0.43 0.03 PAG – 4-DEA 0.54 0.04 0.02 0.40
0.57 0.04 0.38 0.01 Creat – TMAO 0.00 0.60 0.00 0.40
0.64 0.00 0.36 0.00 Lac – Ala
0.65 0.00 0.00 0.34

AcO – Suc
Suc – PCS
Pyr – Suc
AcO – PCS
AcO – Cit
Lac – AcO
Pyr – 4-DEA 0.51 0.01 0.45 0.03 PB – TMAO
DMG – Creat 0.54 0.00 0.44 0.02 Ala – Pyr
Suc – Cit
0.00 0.57 0.43 0.00 DMA – Urea
Suc – 4-DEA 0.58 0.00 0.42 0.00 Creat – Gly

0.07 0.00 0.93 0.00 3-HV – TMAO 0.00 0.02 0.00 0.98
0.07 0.08 0.84 0.01 3-HV – 4-DEA 0.01 0.03 0.00 0.96
0.12 0.05 0.83 0.00 TMA – TMAO 0.23 0.05 0.00 0.71
0.00 0.32 0.00 0.68
0.44 0.01 0.55 0.00 Cit – Gly
0.45 0.01 0.54 0.00 3-HV – Creat
0.40 0.01 0.00 0.58
0.53 0.01 0.47 0.00 Creat – TMAO 0.02 0.52 0.08 0.39
0.64 0.00 0.00 0.36
0.63 0.00 0.01 0.35
0.64 0.03 0.01 0.32
0.65 0.00 0.04 0.31

0.03 0.05 0.92 0.01 Ala – DMG
0.02 0.08 0.00 0.90
Suc – PCS
0.07 0.02 0.91 0.00 3-HV – TMAO 0.00 0.10 0.00 0.90
AcO – For
0.07 0.12 0.01 0.81
DMG – Creat 0.05 0.04 0.91 0.00 Lac – Ala
0.03 0.10 0.87 0.00 PB – For
AcO – Suc
0.23 0.02 0.02 0.73
0.04 0.09 0.86 0.01 3-HV – 4-DEA 0.00 0.28 0.00 0.72
Pyr – Suc
DMG – Gly
0.10 0.04 0.85 0.01 Crea – Urea
0.07 0.26 0.01 0.66
0.27 0.04 0.06 0.63
PB – Urea
0.11 0.05 0.81 0.03 AcO – Urea
0.24 0.05 0.09 0.62
PB – 4-DEA 0.02 0.20 0.78 0.00 DMG – Urea
0.19 0.06 0.16 0.59
AcO – DMA 0.11 0.12 0.75 0.02 3-HV – Creat
TMAO – For
0.04 0.22 0.74 0.00 Ala – NMNA
0.42 0.01 0.03 0.54

Table S3: List of 10 edges which are most likely to appear in G1 but not in G2 (left) and in G2 but not in
G1 (right) corresponding to the diﬀerent priors. The posterior probability of each edge to appear in none of
the graphs (‘00’), both graphs (‘11’), in G1 but not in G2 (‘10’) and in G2 but not in G1 (‘01’) are shown.

40

¯βi1
Node i
TMAO -0.44
-0.28
PCS
-0.43
Suc
-0.43
DMA
-0.63
Creat
4-DEA -0.83
-0.23
Pyr
-0.76
Cit
-1.39
3-HV
-0.95
Gly
-1.27
Urea
-0.98
Ala
-0.85
PAG
-0.74
AcO
Hip
-1.65
DMG -1.19
-1.42
TMA
-1.66
Lac
PB
-1.39
NMNA -1.52
-1.40
-1.42

For
Crea

CI (βi1)

(-1.69, 0.81)
(-1.48, 0.94)
(-1.61, 0.75)
(-1.69, 0.84)
(-1.88, 0.61)
(-2.23, 0.55)
(-1.44, 1.00)
(-2.04, 0.52)
(-2.65, -0.14)
(-2.23, 0.32)
(-2.67, 0.11)
(-2.29, 0.32)
(-2.09, 0.38)
(-2.13, 0.65)
(-3.08, -0.24)
(-2.62, 0.21)
(-2.79, -0.06)
(-3.08, -0.24)
(-2.77, -0.03)
(-2.91, -0.14)
(-2.85, -0.01)
(-2.87, 0.03)

¯βi2
0.30
-0.50
-0.91
0.23
0.08
-0.43
-0.67
-0.21
0.28
-0.12
-0.07
-0.19
-0.24
-0.89
-0.62
-0.62
-0.37
-0.61
-0.47
-0.58
-0.70
-0.48

CI (βi2)

(-1.27, 1.87)
(-1.96, 0.99)
(-2.41, 0.60)
(-1.33, 1.81)
(-1.50, 1.66)
(-2.02, 1.16)
(-2.24, 0.90)
(-1.72, 1.31)
(-1.22, 1.79)
(-1.70, 1.46)
(-1.76, 1.59)
(-1.85, 1.46)
(-1.83, 1.33)
(-2.52, 0.75)
(-2.28, 1.05)
(-2.26, 0.99)
(-1.96, 1.20)
(-2.28, 1.05)
(-2.18, 1.18)
(-2.28, 1.09)
(-2.33, 0.92)
(-2.18, 1.16)

¯π1,i
0.40
0.44
0.40
0.40
0.36
0.32
0.45
0.33
0.22
0.30
0.24
0.29
0.31
0.34
0.18
0.25
0.22
0.18
0.22
0.20
0.22
0.22

CI (π1,i)

(0.14, 0.68)
(0.18, 0.71)
(0.15, 0.67)
(0.14, 0.68)
(0.12, 0.62)
(0.07, 0.60)
(0.18, 0.72)
(0.09, 0.60)
(0.05, 0.42)
(0.07, 0.55)
(0.04, 0.48)
(0.07, 0.54)
(0.09, 0.56)
(0.09, 0.62)
(0.02, 0.39)
(0.04, 0.50)
(0.04, 0.43)
(0.02, 0.39)
(0.04, 0.44)
(0.03, 0.41)
(0.03, 0.44)
(0.03, 0.46)

¯π2,i
0.47
0.33
0.23
0.46
0.38
0.25
0.31
0.30
0.27
0.28
0.24
0.27
0.28
0.20
0.12
0.17
0.17
0.13
0.17
0.14
0.14
0.17

CI(π2,i)

(0.14, 0.81)
(0.07, 0.63)
(0.03, 0.49)
(0.12, 0.80)
(0.08, 0.71)
(0.02, 0.53)
(0.05, 0.62)
(0.04, 0.61)
(0.04, 0.55)
(0.03, 0.57)
(0.01, 0.55)
(0.02, 0.59)
(0.03, 0.58)
(0.01, 0.46)
(0.00, 0.32)
(0.00, 0.41)
(0.01, 0.39)
(0.00, 0.35)
(0.00, 0.41)
(0.00, 0.37)
(0.00, 0.34)
(0.00, 0.42)

¯B1,i
0.07
0.10
0.18
0.08
0.06
0.08
0.13
0.09
0.00
0.05
0.02
0.05
0.02
0.12
0.01
0.06
0.02
0.01
0.02
0.01
0.03
0.02

¯B2,i
0.18
0.07
0.02
0.19
0.12
0.04
0.05
0.11
0.08
0.11
0.07
0.10
0.06
0.02
0.01
0.01
0.02
0.01
0.01
0.01
0.01
0.02

Table S4: Weighted mean (¯πk,i) and 95% credible interval (CI) of πk,i, weighted mean ( ¯βiq) and 95% credible
interval (CI) of βiq, and weighted mean betweenness centrality ( ¯Bk,i) for each node i for k = 1, 2 and q = 1, 2
corresponding to the multiplicative prior with σ2

1 = σ2

2 = 1.

41

Figure S10: Posterior distributions of the connectivity πk,i and the regression coeﬃcients βiq for each metabo-
lite for k = 1, 2 and q = 1, 2 corresponding to the multiplicative prior with σ2

1 = σ2

2 = 1.

42

0.00.60.02.0 TMAO p 1,iDensity0.00.60.01.5 TMAO p 2,iDensity−4040.00.4 TMAO b i1Density−4260.00.3 TMAO b i2Density0.00.60.02.0 PCS p 1,iDensity0.00.60.02.0 PCS p 2,iDensity−4040.00.4 PCS b i1Density−4260.00.3 PCS b i2Density0.00.60.02.0 Suc p 1,iDensity0.00.60.02.0 Suc p 2,iDensity−4040.00.4 Suc b i1Density−4260.00.3 Suc b i2Density0.00.60.02.0 DMA p 1,iDensity0.00.60.01.5 DMA p 2,iDensity−4040.00.4 DMA b i1Density−4260.00.3 DMA b i2Density0.00.60.02.0 Creat p 1,iDensity0.00.60.01.5 Creat p 2,iDensity−4040.00.4 Creat b i1Density−4260.00.3 Creat b i2Density0.00.60.02.0 4−DEA p 1,iDensity0.00.60.02.0 4−DEA p 2,iDensity−4040.00.4 4−DEA b i1Density−4260.00.3 4−DEA b i2Density0.00.60.02.0 Pyr p 1,iDensity0.00.60.02.0 Pyr p 2,iDensity−4040.00.4 Pyr b i1Density−4260.00.3 Pyr b i2Density0.00.60.02.0 Cit p 1,iDensity0.00.60.02.0 Cit p 2,iDensity−4040.00.4 Cit b i1Density−4260.00.3 Cit b i2Density0.00.6024 3−HV p 1,iDensity0.00.60.02.0 3−HV p 2,iDensity−4040.00.4 3−HV b i1Density−4260.00.3 3−HV b i2Density0.00.60.02.0 Gly p 1,iDensity0.00.60.02.0 Gly p 2,iDensity−4040.00.4 Gly b i1Density−4260.00.3 Gly b i2Density0.00.602 Urea p 1,iDensity0.00.60.02.0 Urea p 2,iDensity−4040.00.4 Urea b i1Density−4260.00.3 Urea b i2Density0.00.60.02.0 Ala p 1,iDensity0.00.60.01.5 Ala p 2,iDensity−4040.00.4 Ala b i1Density−4260.00.3 Ala b i2Density0.00.60.02.0 PAG p 1,iDensity0.00.60.02.0 PAG p 2,iDensity−4040.00.4 PAG b i1Density−4260.00.3 PAG b i2Density0.00.60.02.0 AcO p 1,iDensity0.00.6024 AcO p 2,iDensity−4040.00.4 AcO b i1Density−4260.00.3 AcO b i2Density0.00.6024 Hip p 1,iDensity0.00.6036 Hip p 2,iDensity−4040.00.4 Hip b i1Density−4260.00.3 Hip b i2Density0.00.60.02.0 DMG p 1,iDensity0.00.6024 DMG p 2,iDensity−4040.00.4 DMG b i1Density−4260.00.3 DMG b i2Density0.00.6024 TMA p 1,iDensity0.00.6024 TMA p 2,iDensity−4040.00.4 TMA b i1Density−4260.00.3 TMA b i2Density0.00.6024 Lac p 1,iDensity0.00.6036 Lac p 2,iDensity−4040.00.4 Lac b i1Density−4260.00.3 Lac b i2Density0.00.6024 PB p 1,iDensity0.00.6024 PB p 2,iDensity−4040.00.4 PB b i1Density−4260.00.3 PB b i2Density0.00.6024 NMNA p 1,iDensity0.00.6024 NMNA p 2,iDensity−4040.00.4 NMNA b i1Density−4260.00.3 NMNA b i2Density0.00.602 For p 1,iDensity0.00.6024 For p 2,iDensity−4040.00.4 For b i1Density−4260.00.3 For b i2Density0.00.602 Crea p 1,iDensity0.00.6024 Crea p 2,iDensity−4040.00.4 Crea b i1Density−4260.00.3 Crea b i2Density¯βi1
Node i
TMAO -0.76
-0.38
PCS
-0.04
Suc
-0.64
DMA
-0.61
Creat
4-DEA -0.80
-0.17
Pyr
-0.83
Cit
-1.39
3-HV
-0.99
Gly
-1.35
Urea
-0.93
Ala
-0.84
PAG
-0.79
AcO
Hip
-1.47
DMG -1.12
-1.55
TMA
-1.35
Lac
PB
-1.23
NMNA -1.33
-1.41
-1.40

For
Crea

CI (βi1)

(-2.16, 0.64)
(-1.73, 1.00)
(-1.37, 1.34)
(-1.97, 0.70)
(-2.03, 0.81)
(-2.24, 0.64)
(-1.56, 1.28)
(-2.24, 0.59)
(-2.82, 0.02)
(-2.37, 0.38)
(-2.82, 0.08)
(-2.31, 0.45)
(-2.20, 0.53)
(-2.24, 0.66)
(-3.01, 0.08)
(-2.63, 0.36)
(-2.97, -0.17)
(-2.80, 0.06)
(-2.65, 0.17)
(-2.86, 0.17)
(-2.84, 0.02)
(-2.86, 0.04)

¯βi2
0.71
-0.55
-2.46
0.48
0.48
-0.50
-1.20
-0.78
0.98
-0.27
-0.98
-0.27
-0.26
-3.25
-2.89
-1.84
-0.74
-1.01
-2.82
-1.96
-1.74
-2.68

CI (βi2)

(-1.96, 3.51)
(-3.01, 1.86)
(-6.03, 0.61)
(-2.35, 3.31)
(-2.28, 3.37)
(-3.14, 1.99)
(-3.80, 1.33)
(-3.53, 1.86)
(-1.69, 3.70)
(-3.07, 2.39)
(-5.71, 2.78)
(-3.73, 2.98)
(-3.21, 2.52)
(-7.22, 0.28)
(-6.96, 0.81)
(-5.84, 1.60)
(-3.86, 2.19)
(-4.92, 2.26)
(-6.89, 0.87)
(-6.03, 1.53)
(-5.84, 1.73)
(-6.82, 1.07)

¯π1,i
0.34
0.41
0.49
0.36
0.37
0.33
0.46
0.32
0.22
0.29
0.23
0.30
0.32
0.33
0.21
0.27
0.20
0.23
0.25
0.23
0.22
0.22

CI (π1,i)

(0.08, 0.62)
(0.14, 0.71)
(0.20, 0.79)
(0.11, 0.64)
(0.09, 0.67)
(0.07, 0.62)
(0.16, 0.77)
(0.07, 0.61)
(0.03, 0.45)
(0.06, 0.56)
(0.03, 0.47)
(0.07, 0.57)
(0.08, 0.59)
(0.07, 0.63)
(0.03, 0.46)
(0.04, 0.54)
(0.03, 0.41)
(0.03, 0.47)
(0.04, 0.49)
(0.03, 0.48)
(0.03, 0.45)
(0.03, 0.46)

¯π2,i
0.47
0.31
0.14
0.45
0.46
0.26
0.25
0.22
0.41
0.27
0.18
0.29
0.30
0.05
0.04
0.12
0.15
0.16
0.06
0.10
0.11
0.06

CI(π2,i)

(0.07, 0.92)
(0.02, 0.69)
(0.00, 0.11)
(0.04, 0.92)
(0.06, 0.94)
(0.00, 0.61)
(0.00, 0.61)
(0.00, 0.56)
(0.04, 0.84)
(0.00, 0.64)
(0.00, 0.15)
(0.00, 0.76)
(0.00, 0.74)
(0.00, 0.05)
(0.00, 0.04)
(0.00, 0.10)
(0.00, 0.52)
(0.00, 0.14)
(0.00, 0.05)
(0.00, 0.08)
(0.00, 0.09)
(0.00, 0.05)

¯B1,i
0.04
0.08
0.24
0.06
0.08
0.06
0.13
0.07
0.00
0.04
0.02
0.05
0.03
0.09
0.02
0.05
0.00
0.01
0.02
0.01
0.01
0.02

¯B2,i
0.10
0.07
0.02
0.12
0.09
0.05
0.03
0.05
0.09
0.08
0.04
0.09
0.06
0.00
0.00
0.01
0.02
0.03
0.00
0.01
0.01
0.00

Table S5: Weighted mean (¯πk,i) and 95% credible interval (CI) of πk,i, weighted mean ( ¯βiq) and 95% credible
interval (CI) of βiq, and weighted mean betweenness centrality ( ¯Bk,i) for each node i for k = 1, 2 and q = 1, 2
corresponding to the multiplicative prior with σ2

1 = 1, σ2

2 = 10.

43

Figure S11: Posterior distributions of the connectivity πk,i and the regression coeﬃcients βiq for each metabo-
lite for k = 1, 2 and q = 1, 2 corresponding to the multiplicative prior with σ2

1 = 1 and σ2

2 = 10.

44

0.00.60.02.0 TMAO p 1,iDensity0.00.60.01.0 TMAO p 2,iDensity−420.00.4 TMAO b i1Density−150150.000.25 TMAO b i2Density0.00.60.01.5 PCS p 1,iDensity0.00.60.01.5 PCS p 2,iDensity−420.00.4 PCS b i1Density−150150.000.25 PCS b i2Density0.00.60.01.5 Suc p 1,iDensity0.00.6036 Suc p 2,iDensity−420.00.4 Suc b i1Density−150150.000.20 Suc b i2Density0.00.60.02.0 DMA p 1,iDensity0.00.60.01.0 DMA p 2,iDensity−420.00.4 DMA b i1Density−150150.000.25 DMA b i2Density0.00.60.01.5 Creat p 1,iDensity0.00.60.01.0 Creat p 2,iDensity−420.00.4 Creat b i1Density−150150.000.25 Creat b i2Density0.00.60.01.5 4−DEA p 1,iDensity0.00.60.01.5 4−DEA p 2,iDensity−420.00.4 4−DEA b i1Density−150150.000.25 4−DEA b i2Density0.00.60.01.5 Pyr p 1,iDensity0.00.60.01.5 Pyr p 2,iDensity−420.00.4 Pyr b i1Density−150150.000.25 Pyr b i2Density0.00.60.02.0 Cit p 1,iDensity0.00.60.02.0 Cit p 2,iDensity−420.00.4 Cit b i1Density−150150.000.25 Cit b i2Density0.00.602 3−HV p 1,iDensity0.00.60.01.5 3−HV p 2,iDensity−420.00.4 3−HV b i1Density−150150.000.25 3−HV b i2Density0.00.60.02.0 Gly p 1,iDensity0.00.60.01.5 Gly p 2,iDensity−420.00.4 Gly b i1Density−150150.000.25 Gly b i2Density0.00.602 Urea p 1,iDensity0.00.6036 Urea p 2,iDensity−420.00.4 Urea b i1Density−150150.000.20 Urea b i2Density0.00.60.02.0 Ala p 1,iDensity0.00.60.52.0 Ala p 2,iDensity−420.00.4 Ala b i1Density−150150.000.25 Ala b i2Density0.00.60.02.0 PAG p 1,iDensity0.00.60.52.0 PAG p 2,iDensity−420.00.4 PAG b i1Density−150150.000.25 PAG b i2Density0.00.60.01.5 AcO p 1,iDensity0.00.6010 AcO p 2,iDensity−420.00.4 AcO b i1Density−150150.000.15 AcO b i2Density0.00.6024 Hip p 1,iDensity0.00.6010 Hip p 2,iDensity−420.00.3 Hip b i1Density−150150.000.15 Hip b i2Density0.00.60.02.0 DMG p 1,iDensity0.00.6048 DMG p 2,iDensity−420.00.3 DMG b i1Density−150150.000.20 DMG b i2Density0.00.6024 TMA p 1,iDensity0.00.6024 TMA p 2,iDensity−420.00.4 TMA b i1Density−150150.000.25 TMA b i2Density0.00.602 Lac p 1,iDensity0.00.6024 Lac p 2,iDensity−420.00.4 Lac b i1Density−150150.000.20 Lac b i2Density0.00.60.02.0 PB p 1,iDensity0.00.6010 PB p 2,iDensity−420.00.4 PB b i1Density−150150.000.15 PB b i2Density0.00.60.02.0 NMNA p 1,iDensity0.00.6048 NMNA p 2,iDensity−420.00.3 NMNA b i1Density−150150.000.20 NMNA b i2Density0.00.602 For p 1,iDensity0.00.6048 For p 2,iDensity−420.00.4 For b i1Density−150150.000.20 For b i2Density0.00.602 Crea p 1,iDensity0.00.6010 Crea p 2,iDensity−420.00.4 Crea b i1Density−150150.000.15 Crea b i2Density¯βi1
Node i
TMAO -1.09
0.16
PCS
-0.07
Suc
-0.97
DMA
-0.91
Creat
4-DEA -1.59
0.12
Pyr
-0.88
Cit
-2.95
3-HV
-1.30
Gly
-3.41
Urea
-1.75
Ala
-1.12
PAG
-0.55
AcO
Hip
-3.75
DMG -2.04
-3.19
TMA
-2.51
Lac
PB
-3.14
NMNA -3.30
-2.87
-3.18

For
Crea

CI (βi1)

(-3.33, 1.02)
(-2.26, 3.02)
(-2.12, 2.09)
(-2.90, 0.88)
(-3.55, 1.74)
(-4.62, 0.95)
(-2.19, 2.74)
(-3.55, 1.66)
(-5.83, -0.33)
(-3.55, 0.81)
(-7.04, -0.33)
(-3.90, 0.24)
(-3.19, 0.88)
(-3.26, 2.09)
(-7.40, -0.62)
(-5.47, 0.67)
(-6.19, -0.55)
(-6.33, 0.52)
(-6.76, -0.12)
(-7.19, -0.12)
(-6.69, 0.17)
(-7.04, 0.31)

¯βi2
1.63
-0.69
-2.48
0.82
0.43
-0.38
-0.45
-0.01
2.14
0.30
0.37
0.69
0.05
-2.70
-0.75
-1.55
0.51
-1.19
0.26
-1.31
-0.74
-0.89

CI (βi2)

(-1.59, 5.13)
(-4.25, 2.86)
(-6.31, 0.87)
(-2.19, 3.86)
(-3.52, 4.39)
(-3.72, 3.00)
(-4.18, 3.20)
(-3.32, 3.26)
(-1.12, 5.59)
(-2.92, 3.40)
(-5.25, 5.06)
(-3.78, 4.73)
(-3.05, 3.13)
(-6.71, 0.94)
(-6.31, 4.33)
(-6.78, 3.40)
(-3.85, 4.73)
(-6.38, 3.46)
(-5.11, 5.06)
(-6.58, 3.46)
(-6.05, 3.99)
(-6.58, 4.46)

¯π1,i
0.29
0.52
0.48
0.30
0.33
0.23
0.51
0.33
0.09
0.26
0.08
0.19
0.28
0.40
0.06
0.19
0.08
0.15
0.09
0.09
0.12
0.11

CI (π1,i)

(0.01, 0.66)
(0.15, 0.99)
(0.11, 0.89)
(0.02, 0.66)
(0.00, 0.78)
(0.00, 0.63)
(0.14, 0.96)
(0.00, 0.76)
(0.00, 0.07)
(0.00, 0.60)
(0.00, 0.06)
(0.00, 0.48)
(0.01, 0.64)
(0.00, 0.83)
(0.00, 0.05)
(0.00, 0.16)
(0.00, 0.06)
(0.00, 0.12)
(0.00, 0.07)
(0.00, 0.07)
(0.00, 0.09)
(0.00, 0.07)

¯π2,i
0.58
0.38
0.14
0.45
0.42
0.18
0.42
0.33
0.34
0.31
0.17
0.35
0.30
0.10
0.07
0.09
0.13
0.10
0.17
0.06
0.12
0.09

CI(π2,i)

(0.00, 0.90)
(0.00, 0.90)
(0.00, 0.12)
(0.03, 0.92)
(0.05, 0.99)
(0.00, 0.53)
(0.02, 0.94)
(0.00, 0.85)
(0.01, 0.75)
(0.00, 0.72)
(0.00, 0.17)
(0.00, 0.32)
(0.00, 0.76)
(0.00, 0.08)
(0.00, 0.06)
(0.00, 0.08)
(0.00, 0.11)
(0.00, 0.08)
(0.00, 0.15)
(0.00, 0.06)
(0.00, 0.10)
(0.00, 0.07)

¯B1,i
0.03
0.10
0.12
0.05
0.07
0.03
0.10
0.08
0.00
0.06
0.00
0.02
0.02
0.10
0.00
0.05
0.00
0.01
0.00
0.00
0.01
0.01

¯B2,i
0.14
0.05
0.01
0.09
0.06
0.01
0.07
0.07
0.08
0.07
0.03
0.09
0.04
0.00
0.00
0.01
0.01
0.01
0.02
0.00
0.01
0.01

Table S6: Weighted mean (¯πk,i) and 95% credible interval (CI) of πk,i, weighted mean ( ¯βiq) and 95% credible
interval (CI) of βiq, and weighted mean betweenness centrality ( ¯Bk,i) for each node i for k = 1, 2 and q = 1, 2
corresponding to the multiplicative prior with σ2

1 = σ2

2 = 10.

45

Figure S12: Posterior distributions of the connectivity πk,i and the regression coeﬃcients βiq for each metabo-
lite for k = 1, 2 and q = 1, 2 corresponding to the multiplicative prior with σ2

1 = σ2

2 = 10.

46

0.00.60.01.5 TMAO p 1,iDensity0.00.60.01.0 TMAO p 2,iDensity−2000.00.3 TMAO b i1Density−150150.000.20 TMAO b i2Density0.00.60.01.0 PCS p 1,iDensity0.00.60.52.0 PCS p 2,iDensity−2000.00.3 PCS b i1Density−150150.000.20 PCS b i2Density0.00.60.01.5 Suc p 1,iDensity0.00.6036 Suc p 2,iDensity−2000.00.3 Suc b i1Density−150150.000.20 Suc b i2Density0.00.60.01.5 DMA p 1,iDensity0.00.60.01.0 DMA p 2,iDensity−2000.00.3 DMA b i1Density−150150.000.25 DMA b i2Density0.00.60.52.0 Creat p 1,iDensity0.00.60.41.2 Creat p 2,iDensity−2000.000.25 Creat b i1Density−150150.000.20 Creat b i2Density0.00.60.01.5 4−DEA p 1,iDensity0.00.6024 4−DEA p 2,iDensity−2000.00.3 4−DEA b i1Density−150150.000.20 4−DEA b i2Density0.00.60.01.0 Pyr p 1,iDensity0.00.60.51.5 Pyr p 2,iDensity−2000.00.3 Pyr b i1Density−150150.000.20 Pyr b i2Density0.00.60.52.0 Cit p 1,iDensity0.00.60.51.5 Cit p 2,iDensity−2000.00.3 Cit b i1Density−150150.000.20 Cit b i2Density0.00.6048 3−HV p 1,iDensity0.00.60.52.0 3−HV p 2,iDensity−2000.000.25 3−HV b i1Density−150150.000.20 3−HV b i2Density0.00.60.02.0 Gly p 1,iDensity0.00.60.52.0 Gly p 2,iDensity−2000.00.3 Gly b i1Density−150150.000.20 Gly b i2Density0.00.6048 Urea p 1,iDensity0.00.6048 Urea p 2,iDensity−2000.000.20 Urea b i1Density−150150.000.15 Urea b i2Density0.00.602 Ala p 1,iDensity0.00.60.52.0 Ala p 2,iDensity−2000.00.3 Ala b i1Density−150150.000.20 Ala b i2Density0.00.60.01.5 PAG p 1,iDensity0.00.60.52.0 PAG p 2,iDensity−2000.00.3 PAG b i1Density−150150.000.20 PAG b i2Density0.00.60.51.5 AcO p 1,iDensity0.00.6048 AcO p 2,iDensity−2000.00.3 AcO b i1Density−150150.000.15 AcO b i2Density0.00.60612 Hip p 1,iDensity0.00.6010 Hip p 2,iDensity−2000.000.20 Hip b i1Density−150150.000.15 Hip b i2Density0.00.6024 DMG p 1,iDensity0.00.6048 DMG p 2,iDensity−2000.000.25 DMG b i1Density−150150.000.15 DMG b i2Density0.00.6048 TMA p 1,iDensity0.00.6036 TMA p 2,iDensity−2000.000.20 TMA b i1Density−150150.000.20 TMA b i2Density0.00.6036 Lac p 1,iDensity0.00.6048 Lac p 2,iDensity−2000.000.20 Lac b i1Density−150150.000.15 Lac b i2Density0.00.6048 PB p 1,iDensity0.00.6048 PB p 2,iDensity−2000.000.20 PB b i1Density−150150.000.15 PB b i2Density0.00.6048 NMNA p 1,iDensity0.00.6010 NMNA p 2,iDensity−2000.000.20 NMNA b i1Density−150150.000.15 NMNA b i2Density0.00.6048 For p 1,iDensity0.00.6048 For p 2,iDensity−2000.000.20 For b i1Density−150150.000.15 For b i2Density0.00.6048 Crea p 1,iDensity0.00.60612 Crea p 2,iDensity−2000.000.20 Crea b i1Density−150150.000.10 Crea b i2Density0.04
0.00

TMAO PCS Suc DMA Creat 4-DEA Pyr Cit 3-HV Gly Urea Ala PAG AcO Hip DMG TMA Lac PB NMNA For Crea
-0.00 -0.24 0.00
0.04 -0.00 0.00
0.01 -0.05 -0.07
0.01 -0.00 0.00
0.01 0.00 -0.02
-0.00 -0.00 -0.08
0.09 0.00 0.05
0.00 -0.00 0.03
-0.00 0.00 0.00
0.00 -0.01 0.00
0.00 0.00 0.01
-0.00 -0.00 0.00
0.01 0.00 0.00
0.01 -0.20 -0.01
-0.02 -0.02 -0.00
-0.00 0.00 -0.01
-0.00 -0.00 0.01
0.03 0.00 0.00
0.00 0.00 0.00
1.12 -0.00 -0.00
. 1.23 -0.00
.
. 1.13

0.01 -0.00 0.00 -0.00 0.00 -0.00 -0.00 0.01 0.06 0.00 -0.00 -0.03 0.00 -0.00
0.00 0.03 0.00
-0.40 -2.54 0.00
0.00 0.00 -0.00 0.00 -0.87 -0.49 0.00
-0.13 1.06 -0.72 -0.00 -0.00 0.00 0.00 0.02 -0.35 -0.00
0.01 0.00 -0.00
0.00 0.00 0.01 0.01 0.00 0.15 0.00 -0.01 -0.02 0.00 -0.00
-0.00 0.00 -0.00
0.00 0.01 0.00 0.00 0.00 0.01 0.01 -0.25 -0.00 0.00 -0.00
0.00 0.00 0.00
0.00 -0.00 0.00 -0.28
1.39 0.36 -0.00 -0.00 -0.00 0.00 0.00 0.01 -0.00 -0.00
0.01 0.01 -0.00
0.11
0.00 -0.00 -0.01 -0.00 -1.40 0.39 0.00
. 1.56 -0.00 -0.05 0.04 -0.27 -0.00 0.12 -0.00
0.02
0.01 0.00 -0.00
1.06 -0.00 -0.00 -0.03 0.00 0.00 0.00 -0.01 -0.00 0.00 0.00
.
. 1.53 0.00 -0.73 -0.00 0.00 0.01 -0.16 -0.00 -0.00 0.00
.
. 1.13 0.00 -0.00 -0.00 0.02 -0.00 -0.02 0.01 0.11
.
.
. 1.57 0.00 0.00 0.02 -0.00 -0.00 -0.00 0.00
.
.
.
.
.
.
.
0.01 0.01 -0.00
0.00
0.00 -0.00 -0.11 0.01
.
.
.
.
0.00
.
.
.
.
0.00 0.00 0.00
1.27 -0.02 0.00 0.00
.
.
.
.
1.09 -0.00 0.01
.
.
.
.
.
.
.
.
. 1.11 0.00
. 1.22
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

0.44
1.74 0.00 0.01 -1.09
0.01
0.00
0.00
0.01
2.34 -1.14
1.80
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 4.14 -1.22
.
. 2.19
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 4.29 -0.01
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 2.74 0.00 0.00
. 1.59 -0.00
.
. 1.08
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

TMAO
PCS
Suc
DMA
Creat
4-DEA
Pyr
Cit
3-HV
Gly
Urea
Ala
PAG
AcO
Hip
DMG
TMA
Lac
PB
NMNA
For
Crea

Table S7: Mean precision matrix Ω1 corresponding to K = 2 and multiplicative prior with σ2

1 = σ2

2 = 1.

0.00 -0.00 -0.01 -0.02 0.84 -0.00 -0.00

0.00 0.00 -0.00 -0.00 -3.53 0.00 -0.00
0.00 -0.01 0.04 -0.00 -0.00 -0.00 0.00

TMAO PCS Suc DMA Creat 4-DEA Pyr Cit 3-HV Gly Urea Ala PAG AcO Hip DMG TMA Lac PB NMNA For Crea
0.01 0.00 -0.03
-0.01 -0.00 0.00
0.00 -0.00 0.00
-0.00 0.04 -0.04
0.00 0.06 0.00
0.00 0.00 0.00
0.06 0.00 0.00
0.00 0.00 -0.00
-0.03 0.00 -0.00
0.00 -0.00 -0.00
0.03 0.00 -0.21
0.02 -0.00 -0.00
0.01 -0.00 -0.00
0.00 0.00 -0.00
-0.00 -0.00 0.00
0.00 -0.00 -0.03
-0.00 0.00 0.00
0.00 -0.00 -0.00
0.00 -0.04 -0.00
1.10 -0.00 0.02
. 1.10 0.01
.
. 1.16

-0.00 0.02 0.00 -1.85 -0.01 0.01 -0.02 -0.01 0.01 0.01 -0.00 -0.45 -0.00 -0.18
0.00 -0.00 0.00 0.00
0.00 -8.09 -0.01
0.00 -0.00 -0.48
0.00 -0.00 -0.00 0.00
-0.06 -0.00 -0.00 -0.03 -0.04 0.22 -0.11 -0.01 0.08 0.06 -0.00 -0.08 -0.00 0.12
0.00 -0.00 0.00 0.03
-0.05 0.00 -0.06 -0.33 -0.03 0.00 -0.00 0.01 0.01 0.04
0.00 -0.01 -0.01
1.57 0.00 -0.00 -0.75 -0.00 0.00 -0.01 0.13 0.00 0.00 -0.00
0.00 -0.00 0.00 0.00
0.00 0.00 0.04
3.03 -0.01 0.02 -0.01 0.00 0.01 0.00 -0.00 -0.05 -0.00 -0.00
0.01 -0.01 -0.04
0.00 0.05 -0.00
. 1.41 0.01 0.01 0.02 -0.30 -0.00 -0.07 0.00
0.00 -0.00 0.00 0.01
.
0.00
.
0.00 -0.00 -0.01
0.00 -0.00 0.00 -0.00
.
1.20 -0.00 -0.00 -0.00
.
.
1.34 0.00 -0.00
. 1.10 -0.00
.
. 1.15
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 1.83 -0.00 -0.87 0.00 -0.04 -0.01 0.01 0.00 -0.02
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 1.74 0.07 -0.27 0.01 0.00 0.00 -0.00
. 1.33 0.03 -0.00 -0.04 0.02 -0.04
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

5.23 -0.01 0.00 -3.27
. 11.46 -0.00 -0.02
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

1.38
0.00
. 1.30 -0.00 -0.03
4.58 -1.56
.
1.86
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 8.02 -0.01
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

. 3.43 0.00 -0.00
. 1.10 0.00
.
. 1.10
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.
.
.
.
.
.
.
.
.

.
.
.
.
.
.

TMAO
PCS
Suc
DMA
Creat
4-DEA
Pyr
Cit
3-HV
Gly
Urea
Ala
PAG
AcO
Hip
DMG
TMA
Lac
PB
NMNA
For
Crea

Table S8: Mean precision matrix Ω2 corresponding to K = 2 and multiplicative prior with σ2

1 = σ2

2 = 1.

47

