6
1
0
2

 
r
a

M
 
5
1

 
 
]

.

G
A
h
t
a
m

[
 
 

1
v
3
1
8
4
0

.

3
0
6
1
:
v
i
X
r
a

Algorithm for computing

µ-bases of univariate polynomials

Hoon Hong, Zachary Hough, Irina A. Kogan

Abstract

We present a new algorithm for computing a µ-basis of the syzygy module of n
polynomials in one variable over an arbitrary ﬁeld K. The algorithm is conceptually
diﬀerent from the previously-developed algorithms by Cox, Sederberg, Chen, Zheng,
and Wang for n = 3, and by Song and Goldman for an arbitrary n.
It involves
computing a “partial” reduced row-echelon form of a (2d + 1)× n(d + 1) matrix over K,
where d is the maximum degree of the input polynomials. The proof of the algorithm
is based on standard linear algebra and is completely self-contained. It includes a proof
of the existence of the µ-basis and as a consequence provides an alternative proof of the
freeness of the syzygy module. The theoretical (worst case asymptotic) computational
complexity of the algorithm is O(d2n + d3 + n2). We have implemented this algorithm
(HHK) and the one developed by Song and Goldman (SG). Experiments on random
inputs indicate that SG gets faster than HHK when d gets suﬃciently large for a ﬁxed
n, and that HHK gets faster than SG when n gets suﬃciently large for a ﬁxed d.

Keywords: µ-basis; syzygy module; polynomial vectors; rational curves.

MSC 2010: 12Y05, 13P10, 14Q05, 68W30.

Introduction

1
Let a[s] = [a1(s), . . . , an(s)] be a vector of univariate polynomials over a ﬁeld K. It is
well known that the syzygy module of a, consisting of linear relations over K[s] among
a1(s), . . . , an(s):

syz(a) = {h ∈ K[s]n | a1 h1 + ··· + an hn = 0}

is free.1 This means that the syzygy module has a basis, and, in fact, inﬁnitely many
bases. A µ-basis is a basis with particularly nice properties, which we describe in more
details in the next section.

The concept of µ-basis ﬁrst appeared in [5], motivated by the search of new, more
eﬃcient methods for solving implicitization problems for rational curves, and as a

1Freeness of the syzygy module in the one-variable case follows, in particular, from the Quillen-Suslin
theorem (see Theorem 5.1.8 in [4]). In the multivariable case, the syzygy module of a polynomial vector is
not always free.

1

further development of the methods of moving lines (and, more generally, moving
curves) proposed in [7]. Since then, a large body of literature on the applications of
µ-bases to various problems involving vectors of univariate polynomials has appeared,
such as [2, 9, 6, 10] .2 The variety of possible applications motivates the development of
algorithms for computing µ-bases. Although a non-constructive proof of the existence
of a µ-basis for arbitrary n appeared already in [5], the algorithms were ﬁrst developed
for n = 3 case only [5, 11, 3]. The ﬁrst algorithm for arbitrary n appeared in [9], as a
generalization of [3].

This paper presents an alternative algorithm for an arbitrary n. The proof of
the algorithm does not rely on previously established theorems about the freeness
of the syzygy module or the existence of a µ-basis, and, therefore, as a by-product,
provides an alternative, self-contained, constructive proof of these facts. In the rest of
the introduction, we informally sketch the main idea underlying this new algorithm,
compare it with previous algorithms, and brieﬂy describe its performance.

Main idea: It is well known that the syzygy module of a, syz(a), is generated by the
set syzd(a) of syzygies of degree at most d = deg(a). The set syzd(a) is obviously
a K-subspace of K[s]n. Under the standard monomial basis, it is easy to see that
this subspace is isomorphic to the kernel of a certain linear map A : Kn(d+1) → K2d+1
(explicitly given by (8) below). Now we come to the key idea: one can systematically
choose a suitable ﬁnite subset of the kernel of A so that the corresponding subset of
syzd(a) forms a µ-basis. We elaborate on how this is done. Recall that a column of
a matrix is called non-pivotal if it is either the ﬁrst column and zero, or it is a linear
combination of the previous columns. Now we observe and prove a remarkable fact
that the set of indices of non-pivotal columns of A splits into exactly n − 1 sets of
modulo-n-equivalent integers. By taking the smallest representative in each set, we
obtain n − 1 integers, which we call basic non-pivotal indices. The set of non-pivotal
indices of A is equal to the set of non-pivotal indices of its reduced row-echelon form
E. From each non-pivotal column of E, an element of ker(A) can be easily read oﬀ,
which, in turn, gives rise to an element of syz(a), which we call a row-echelon syzygy.
We prove that the row-echelon syzygies corresponding to the n − 1 basic non-pivotal
indices comprise a µ-basis. Thus, a µ-basis can be found by computing the reduced
row-echelon form of a single (2d + 1) × n(d + 1) matrix A over K. Actually, it is
suﬃcient to compute only a “partial” reduced row-echelon form containing only the
basic non-pivotal columns and the preceding pivotal columns.

Relation to the previous algorithms: Cox, Sederberg and Chen [5] implicitly suggested
an algorithm for the n = 3 case. Later, it was explicitly described in the Introduction
of [11]. The algorithm relies on the fact that, in the n = 3 case, there are only two
elements in a µ-basis, and their degrees (denoted as µ1 and µ2) can be determined prior
to computing the basis (see Corollary 2 in [5] and p. 621 of [11]). Once the degrees
are determined, two syzygies are constructed from null vectors of two linear maps
A1 : K3(µ1+1) → Kµ1+d+1 and A2 : K3(µ2+1) → Kµ2+d+1 (similar to the one described

2A notion of a µ-basis for vectors of polynomials in two variables also has been developed and applied to
the study of rational surfaces in three-dimensional projective space (see, for instance, [2, 8]). This paper is
devoted solely to the one-variable case.

2

above). Special care is taken to ensure that these syzygies are linearly independent
over K[s]. These two syzygies comprise a µ-basis. It is not clear, however, how this
method can be generalized to arbitrary n. First, as far as we are aware, there is not yet
an eﬃcient way to determine the degrees of µ-basis members a priori. Second, there
is not yet an eﬃcient way for choosing appropriate null vectors so that the resulting
syzygies are linearly independent.

ai

Zheng and Sederberg [11] gave a diﬀerent algorithm for the n = 3 case, based
on Buchberger-type reduction. Its more eﬃcient modiﬁcation was proposed by Chen
and Wang [3], and was subsequently generalized to arbitrary n by Song and Gold-
man [9]. The general algorithm starts by observing that the set of the obvious syzy-
gies {[ −aj
]| 1 ≤ i < j ≤ n} generates syz(a), provided gcd(a) = 1. Then
Buchberger-type reduction is used to reduce the degree of one of the syzygies at a
time. It is proved that when such reduction becomes impossible, one is left with ex-
actly n − 1 non-zero syzygies that comprise a µ-basis. If gcd(a) is non-trivial, then
the output is a µ-basis multiplied by gcd(a). We note that, in contrast, the algorithm
developed in this paper outputs a µ-basis even in the case when gcd(a) is non-trivial.
See Remark 7 below for more details.

Performance: We show that the algorithm in this paper has theoretical complexity
O(d2n + d3 + n2), assuming that the arithmetic takes constant time (which is the case
when the ﬁeld K is ﬁnite). We have implemented our algorithm (HHK), as well as
Song and Goldman’s [9] algorithm (SG) in Maple [1]. Experiments on random inputs
indicate that SG gets faster than HHK when d gets suﬃciently large for a ﬁxed n and
that HHK gets faster than SG when n gets suﬃciently large for a ﬁxed d.

Structure of the paper: In Section 2, we give a rigorous deﬁnition of a µ-basis, describe
its characteristic properties, and formulate the problem we are considering. In Sec-
tion 3, we prove several lemmas about the vector space of syzygies of degree at most
d, and the role they play in generating the syzygy module. In Section 4, we deﬁne the
notion of row-echelon syzygies and explain how they can be computed. This section
contains our main theoretical result, Theorem 1, which explicitly identiﬁes a subset of
row-echelon syzygies that comprise a µ-basis. In Section 5, we present an algorithm for
computing a µ-basis. In Section 6, we analyze the theoretical (worst case asymptotic)
computational complexity of the algorithm. In Section 7, we discuss implementation
and experiments, and compare the performances of the algorithm presented here with
the one described in [9].

2 µ-basis of the syzygy module.
Throughout the paper, K denotes a ﬁeld and K[s] denotes a ring of polynomials in one
indeterminate s. Symbol n will be reserved for the length of the polynomial vector a,
whose syzygy module we are considering, and from now on we assume n > 1, because for
the n = 1 case the problem is trivial. Symbol d is reserved for the degree of a.3 We also

3In several previous papers on µ-bases, n was used for the degree of a and, in [5], d was used to denote

length(a) − 1 (the dimension of the ambient space of the rational curve deﬁned by a).

3

will assume that a is a non-zero vector. All vectors are implicitly assumed to be column
vectors, unless speciﬁcally stated otherwise. Superscript T denotes transposition.
Deﬁnition 1 (Syzygy). Let a = [a1, . . . , an] ∈ K[s]n be a row n-vector of polynomials.
The syzygy set of a is

syz(a) = {h ∈ K[s]n | a h = 0}.4

It is easy to check that syz(a) is a K[s]-module. To deﬁne a µ-basis, we need the
following terminology:
Deﬁnition 2 (Leading vector). For h ∈ K[s]n we deﬁne the degree and the leading
vector of h as follows:
• deg(h) = max
• LV (h) = [coeﬀ(h1, t), . . . , coeﬀ(hn, t)] ∈ Kn, where t = deg(h) and coeﬀ(hi, t)

deg(hi).

i=1,...,n

denotes the coeﬃcient of st in hi.

 1 − 2s − 2s2 − s3

2 + 2s + s2 + s3

. Then deg(h) = 3 and LV (h) =

 .

 −1

1
0

Example 3. Let h =

−3

Deﬁnition 4 (µ-basis). For a non-zero row vector a ∈ K[s]n, a subset u ⊂ K[s]n of
polynomial vectors is called a µ-basis of a if the following three conditions hold

1. u has exactly n − 1 elements
2. LV (u1), . . . , LV (un−1) are independent over K
3. u is a basis of syz(a), the syzygy module of a.5

Remark 5. We could have weakened the third condition into “u is a generator of
the module syz(a)”, because, as it is shown below in Lemma 27, the second condition
implies the linear independence of elements of u over K[s]. Therefore, the second
condition and the generating property imply that u is a basis. However, we decided to
keep the stronger version, because it has the beneﬁt of making the linear independence
requirement explicit, motivating the name µ-“basis”.

As we mentioned in the introduction, a µ-basis has a number of special properties.
Among those we highlight the following three, which are often used both for theoretical
purposes and in applications.

1) [minimality of the degrees] Assume that deg(u1) ≤ ··· ≤ deg(un−1) and h1, . . . , hn−1
is any generating set of syz(a), such that deg(h1) ≤ ··· ≤ deg(hn−1). Then
deg(ui) ≤ deg(hi) for i = 1, . . . , n − 1, and equality holds for all i if and only if
h1, . . . , hn−1 is a µ-basis.6

4 We emphasize that h is by default a column vector and a is explicitly deﬁned to be a row vector, so

that the product a h is well deﬁned.

5Technically we should have said “µ-basis of syz(a)”, but for the sake of simplicity, we will almost always

say “µ-basis of a”.

6It follows that, although a µ-basis itself is not canonical, the degrees of its members are canonical. In

[5], these degrees were denoted by µ1, . . . , µn−1 and the term “µ-basis” was coined.

4

2) [sum of the degrees] deg(u1) + ··· + deg(un−1) = deg(a) − deg(gcd(a)).7
3) [outer product] There exists a non-zero constant α ∈ K such that the outer product

of u1, . . . , un−1 is equal to α a/ gcd(a).

The above properties can easily be derived from Theorems 1 and 2 in [9] and an
observation that syz(a) = syz (1/gcd(a) a). Since we do not use these properties in our
proofs, we omit their derivation.

In the next two sections, through a series of lemmas culminating in Theorem 1, we
give a self-contained constructive proof of the existence of a µ-basis. This, in turn,
leads us to a solution of the following problem:

Problem: Devise an algorithm for

a (cid:54)= 0 ∈ K[s]n, row vector, where n > 1 and K is a computable ﬁeld.8

Input :
Output : M ∈ K[s]n×(n−1) such that its columns form a µ-basis of a.

Example 6 (Running example). We will be using the following simple example through-
out the paper to illustrate the theoretical ideas/ﬁndings and the resulting algorithm.

a =(cid:2) 1 + s2 + s4 1 + s3 + s4 1 + s4 (cid:3) ∈ Q[s]3
 −s

1 − 2s − 2s2 − s3
2 + 2s + s2 + s3



−3

Input

Output

M =

1

−1 + s

The algorithm is presented in Section 5.

Remark 7. In contrast with the algorithm developed by Song and Goldman in [9], the
algorithm presented in this paper produces a µ-basis even when the input vector a has
a non-trivial greatest common divisor. Moreover, once a µ-basis is computed, one can
immediately ﬁnd gcd(a) using Property 3) listed above. Indeed, let h denote the outer
product of a µ-basis u1, . . . , un−1. In other words, if M is the matrix obtained as an
output of the above algorithm, then hi = (−1)i |Mi|, where Mi is an (n − 1) × (n − 1)
submatrix of M obtained by removing the i-th row. By Property 3), there exists a
non-zero α ∈ K such that

a = α gcd(a) h.

Let i ∈ {1, . . . , n} be such that ai is a non-zero polynomial. Then gcd(a) is obtained
by a long division of ai by hi and then dividing the quotient by its leading coeﬃcient
to make it monic. In comparison, the algorithm developed in [9] produces a µ-basis
of a multiplied by gcd(a). From the output of this algorithm and Property 3), one
ﬁnds gcd(a)n−2. Song and Goldman discuss how to recover gcd(a) itself by repeatedly
running their algorithm.

7Here and below gcd(a) denotes the greatest common monic devisor of the polynomials a1, . . . , an.
8 A ﬁeld is computable if there are algorithms for carrying out the arithmetic (+,−,×, /) operations

among the ﬁeld elements.

5

3 Syzygies of bounded degree.
From now on, let (cid:104)(cid:3)(cid:105)K[s] stand for the K[s]-module generated by (cid:3). It is known that
syz(a) is generated by polynomial vectors of degree at most d = deg(a). To keep our
presentation self-contained, we provide a proof of this fact (adapted from Lemma 2 of
[9]).
Lemma 8. Let a ∈ K[s]n be of degree d. Then syz(a) is generated by polynomial
vectors of degree at most d.

Proof. Let ˜a = a/gcd(a) = [˜a1, . . . , ˜an]. For all i < j, let

uij = [ −˜aj

˜ai

]T ,

with −˜aj in i-th position, ˜ai in j-th position and all the other elements equal to zero.
We claim that the uij’s are the desired polynomial vectors. First note that

max

1≤i<j≤n

deg(uij) = max
1≤i≤n

˜ai ≤ deg a = d.

It remains to show that syz(a) = (cid:104)uij | 1 ≤ i < j ≤ n(cid:105)K[s] . Obviously we have

syz(a) = syz(˜a)

Since uij belongs to syz(˜a), we have

syz(˜a) ⊃ (cid:104)uij | 1 ≤ i < j ≤ n(cid:105)K[s] .

Since gcd(˜a) = 1, there exists a polynomial vector f = [f1, . . . , fn]T such that

(1)

(2)

(3)

For any h = [h1, . . . , hn]T ∈ syz(˜a), a direct computation shows that

˜af = 1.

(cid:88)

(fihj − fjhi)uij.

h =

1≤i<j≤n

Therefore

syz(˜a) ⊂ (cid:104)uij | 1 ≤ i < j ≤ n(cid:105)K[s] .

Putting (1), (2) and (3) together, we have

syz(a) = (cid:104)uij | 1 ≤ i < j ≤ n(cid:105)K[s] .

Let K[s]d denote the set of polynomials of degree at most d, let K[s]n

d denote the

set of polynomial vectors of degree at most d, and let

syzd(a) = {h ∈ K[s]n

d | a h = 0}

be the set of all syzygies of degree at most d.

It is obvious that K[s]d is a (d + 1)-dimensional vector space over K. Therefore, the
set K[s]n
d is an n (d + 1)-dimensional vector space over K. It is straightforward to check
that syzd(a) is a vector subspace of K[s]n
d over K and, therefore, is ﬁnite-dimensional.
We show that a K-basis of the vector space syzd(a) generates the K[s]-module syz(a).

6

Lemma 9. Let a ∈ K[s]n be of degree d and h1, . . . hl be a basis of the K-vector space
syzd(a). Then syz(a) = (cid:104)h1, . . . , hl(cid:105)K[s].
Proof. From Lemma 8, it follows that there exist u1, . . . , ur ∈ syzd(a) that generate
the K[s]-module syz(a). Therefore, for any f ∈ syz(a), there exist g1, . . . , gr ∈ K[s],
such that

f =

gi ui.

(4)

Since h1, . . . hl is a basis of the K-vector space syzd(a), there exist αij ∈ K such that

Combining (4) and (5) we get:

r(cid:88)

f =

gi

ui =

j=1

l(cid:88)

αij hj =

(5)

αij hj.

(cid:32) r(cid:88)

l(cid:88)

(cid:33)

αijgj

hj.

i=1

j=1

j=1

i=1

r(cid:88)

i=1

l(cid:88)

The next step is to show that the vector space syzd(a) is isomorphic to the kernel
of a certain linear map A : Kn(d+1) → K2d+1. Before introducing A, let us deﬁne an
t and Km(t+1), where t and m are
explicit isomorphism between vector spaces K[s]m
arbitrary natural numbers. Any polynomial m-vector h of degree at most t can be
written as h = w0 + sw1 + ··· + stwt where wi = [w1i, . . . , wmi]T ∈ Km. It is clear that
the map

: K[s]m

t → Km(t+1)

(cid:93)m
t

h → h(cid:93)m

t =



 w0

...
wt

(6)

(7)

is linear. It is easy to check that the inverse of this map

: Km(t+1) → K[s]m

t

(cid:91)m
t

is given by a linear map:

where

v → v(cid:91)m

t = Sm

t =(cid:2) Im sIm ··· stIm

Sm

t v

(cid:3) ∈ K[s]m×m(t+1).

For the sake of notational simplicity, we will often write (cid:93), (cid:91) and S instead of (cid:93)m
and Sm

t when it is clear from the context what m and t are.

t , (cid:91)m
t

7

Example 10. For

 1 − 2s − 2s2 − s3

2 + 2s + s2 + s3

−3

 =

 1

2
−3

 + s

 −2

2
0

 + s2

 −2

1
0

 + s3

 ,

 −1

1
0

h =

we have

Note that

h(cid:93) = [1, 2, −3, −2, 2, 0, −2, 1, 0, −1, 1, 0]T .

h = (h(cid:93))(cid:91) = S h(cid:93) =(cid:2) I3

(cid:3) h(cid:93).

Lemma 11. For a =

vectors, deﬁne

cjsj ∈ Kn

d [s], where cj = [c1j, . . . , cnj] ∈ Kn are row

(cid:88)

0≤j≤d



A =

c0
...
cd

. . .
...
. . .

c0
...
cd

sI3

s2I3

s3I3

 ∈ K(2d+1)×n(d+1),

(8)

(9)

with the blank spaces ﬁlled by zeros. Then for any v ∈ Kn(d+1):

av(cid:91) = (Av)(cid:91).

Proof. A vector v ∈ Kn(d+1) can be split into (d + 1) blocks

 ,

 w0

...
wd

where wi ∈ Kn are column vectors. For j < 0 and j > d, let us deﬁne cj = 0 ∈ Kn.
Then Av is a (2d + 1)-vector with (k + 1)-th entry

(Av)k+1 = ck w0 + ck−1w1 + ··· + ck−dwd =

ck−iwi,

(cid:88)

0≤i≤d

where k = 0, . . . , 2d. Then

av(cid:91) = a Sn

d v =

cjsj

 (cid:88)
 (cid:88)

0≤j≤d

0≤i≤d

 (cid:88)
 =

0≤i≤d

wi si

(cid:88)

0≤k≤2d

ck−iwi

 =

(cid:88)

0≤i,j≤d

cjwisi+j

sk (Av)k+1 = S1

2d (Av) = (Av)(cid:91).

(cid:88)

=

sk

0≤k≤2d

8

Example 12. For the row vector a in the running example (Example 6), we have
n = 3, d = 4,

c0 = [1, 1, 1], c1 = [0, 0, 0], c2 = [1, 0, 0], c3 = [0, 1, 0], c4 = [1, 1, 1]

and

A =



1 1 1
0 0 0 1 1 1
1 0 0 0 0 0 1 1 1
0 1 0 1 0 0 0 0 0 1 1 1
1 1 1 0 1 0 1 0 0 0 0 0 1 1 1
1 1 1 0 1 0 1 0 0 0 0 0
1 1 1 0 1 0 1 0 0
1 1 1 0 1 0
1 1 1



.

Let v = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]T . Then

Av = [6, 15, 25, 39, 60, 33, 48, 47, 42]T

and so
(Av)(cid:91) = S1

2d(Av) = S1

8 (Av) = 6 + 15s + 25s2 + 39s3 + 60s4 + 33s5 + 48s6 + 47s7 + 42s8.

On the other hand, since

v(cid:91) = Sn

d v = S3

4 v =

 1 + 4s + 7s2 + 10s3 + 13s4

2 + 5s + 8s2 + 11s3 + 14s4
3 + 6s + 9s2 + 12s3 + 15s4

 ,

we have

av(cid:91) =(cid:2) 1 + s2 + s4 1 + s3 + s4 1 + s4 (cid:3) 1 + 4s + 7s2 + 10s3 + 13s4



2 + 5s + 8s2 + 11s3 + 14s4
3 + 6s + 9s2 + 12s3 + 15s4

= 42s8 + 47s7 + 48s6 + 33s5 + 60s4 + 39s3 + 25s2 + 15s + 6.

We observe that

Lemma 13. v ∈ ker(A) if and only if v(cid:91) ∈ syzd(a).
Proof. Follows immediately from (9).

av(cid:91) = (Av)(cid:91).

We conclude this section by describing an explicit generating set for the syzygy

module.

Lemma 14. Let b1, . . . bl comprise a basis of ker(A), then

(cid:68)

(cid:69)

syz(a) =

b(cid:91)
1, . . . , b(cid:91)
l

.

K[s]

Proof. Lemma 13 shows that the isomorphism (7) between vector spaces Kn(d+1) and
K(s)n
d induces an isomorphism between their respective subspaces ker(A) and syzd(a).
Therefore, b(cid:91)
l is a basis of syzd(a). The conclusion then follows from Lemma 9.

1, . . . , b(cid:91)

9

4 “Row-echelon” generators and µ-bases.

In the previous section, we proved that any basis of ker(A) gives rise to a generating
set of syz(a). In this section, we show that a particular basis of ker(A), which can be
“read oﬀ” the reduced row-echelon form of A, contains n− 1 vectors that give rise to a
µ-basis of syz(a). In this and the following sections, quo(i, j) denotes the quotient and
rem(i, j) denotes the remainder obtained by division of an integer i by an integer j.

We start with the following important deﬁnition:

Deﬁnition 15. A column of any matrix N is called pivotal if it is either the ﬁrst
column and is non-zero or it is linearly independent of all previous columns. The rest
of the columns of N are called non-pivotal. The index of a pivotal (non-pivotal) column
is called a pivotal (non-pivotal) index.

From this deﬁnition, using induction, it follows that every non-pivotal column can

be written as a linear combination of the preceding pivotal columns.

We denote the set of pivotal indices of A as p and the set of its non-pivotal indices
as q. In the following two lemmas, we show how the speciﬁc structure of the matrix A
is reﬂected in the structure of the set of non-pivotal indices q.

Lemma 16 (periodicity). If j ∈ q then j + kn ∈ q for 0 ≤ k ≤(cid:106) n(d+1)−j

. Moreover,

(cid:107)

(cid:88)

A∗j =

αr A∗r =⇒ A∗j+kn =

r<j

r<j

αr A∗r+kn,

(10)

where A∗j denotes the j-th column of A.
Proof. To prove the statement, we need to examine the structure of the (2d+1)×n(d+1)
matrix A:

(cid:88)

···
···
···
···

c01
...
...
cd1



n



c0n
...
...
cdn

···
···
···
···

c0n
...
...
cdn

c01
...
...
cd1

. . .
. . .
. . .
. . .

···
···
···
···

c0n
...
...
cdn

c01
...
...
cd1

.

(11)

The j-th column of A has the ﬁrst quo(j − 1, n) and the last (d− quo(j − 1, n)) entries
zero. For 1 ≤ j ≤ nd the (n + j)-th column is obtained by shifting all entries of the
j-th column down by 1 and then putting an extra zero on the top. We consider two
cases:

1. Integer j = 1 is in q if and only if the ﬁrst column of A is zero. From the
structure of A it follows that any column indexed by 1 + kn is zero and therefore,
(1 + kn) ∈ q for

= d ≥ k ≥ 0.

(cid:106) n(d+1)−1

(cid:107)

n

10

2. Let us embed A in the inﬁnite matrix indexed by integers. By inspection of the

structure of A given by (11), we see immediately

Then, for a non pivotal index j > 1 and 0 ≤ k ≤(cid:106) n(d+1)−j

Ai,r+kn = Ai−k,r.

(cid:107)

we have:

(12)

n

(cid:88)

A∗j =

αr A∗r

r<j

⇐⇒ ∀

i∈Z Ai,j =

r=1

αrAi,r

j−1(cid:88)
j−1(cid:88)
j−1(cid:88)
(cid:88)
(cid:106) n(d+1)−j

r=1

r<j

n

⇐⇒ ∀

i∈Z Ai−k,j =

αrAi−k,r

⇐⇒ ∀

i∈Z Ai,j+kn =

=⇒ A∗j+kn =

αrAi,r+kn

r=1
αr A∗r+kn,

(by reindexing the row)

(from (12))

Therefore (j + kn) ∈ q for

(cid:107) ≥ k ≥ 0 and equation (10) holds.

Deﬁnition 17. Let q be the set of non-pivotal indices. Let q/(n) denote the set of
equivalence classes of q modulo n. Then the set ˜q = {min | ∈ q/(n)} will be called
the set of basic non-pivotal indices.
Example 18. For the matrix A in Example 12, we have n = 3 and q = {6, 9, 11, 12, 14, 15}.

Then q/(n) =(cid:8){6, 9, 12, 15}, {11, 14}}(cid:9) and ˜q = {6, 11}.

Lemma 19. There are exactly n − 1 basic non-pivotal indices: |˜q| = n − 1.
Proof. We prove the lemma by showing that |˜q| < n and |˜q| > n − 2.

1. Since there are at most n equivalence classes in q modulo n, it follows from the
deﬁnition of ˜q that |˜q| ≤ n. Moreover, the (2d + 1)-th row of the last block of
n-columns of A is given by the row vector cd = (c1d, . . . , cnd) = LV (a), which
is non-zero. Thus, there exists r ∈ {1, . . . , n}, such that crd (cid:54)= 0. Suppose r is
minimal such that crd (cid:54)= 0. Then the (nd + r)-th column of A is independent from
the ﬁrst nd + r− 1 columns (since each of these columns has a zero in the (2d + 1)-
th position). Hence, there exists r ∈ {1, . . . , n} such that nd+r is a pivotal index.
From the periodicity Lemma 16, it follows that for every k = 0, . . . d, index r + kn
is pivotal and therefore no integer from the class r modulo n belongs to ˜q. Thus
|˜q| < n.

11

2. Assume |˜q| ≤ n − 2. From the periodicity Lemma 16, it follows that the set of
non-pivotal indices is the union of the sets {j + kn|j ∈ ˜q, 0 ≤ k ≤ lj}, where
lj ≤ d is some integer. Therefore

|q| ≤ |˜q| (d + 1) ≤ (n − 2)(d + 1) = nd + n − 2d − 2.

On the other hand, |q| = n(d + 1)−|p|. It is well-known (and easy to check) that
|p| = rank(A). Since rank(A) cannot exceed the number of rows of A, |p| ≤ 2d+1.
Then

|q| ≥ n(d + 1) − (2d + 1) = nd + n − 2d − 1.

Contradiction. Hence |˜q| > n − 2.

From the matrix A we will now construct a square n (d + 1)× n(d + 1) matrix V in
the following way. For i ∈ p, the i-th column of V has 1 in the i-th row and 0’s in all
other rows. For i ∈ q we deﬁne the i-th column from the linear relationship

A∗i =

αjA∗j

(13)

(cid:88)

{j∈p | j<i}

as follows: for j ∈ p such that j < i we set Vji = αj. All the remaining elements of the
column V∗i are zero. For simplicity we will denote the i-th column of V as vi. We note
two important properties of V :

1. Matrix V has the same linear relationships among its columns as A.
2. Vectors {bi = ei − vi | i ∈ q}, where by ei we denote a vector that has 1 in the

i-th position and 0’s in all others, comprise a basis of ker(A).

The corresponding syzygies {b(cid:91)
i | i ∈ q} will be called row-echelon syzygies because the
constants α’s appearing in (13) can be read oﬀ the reduced row-echelon form E of A.
(We remind the reader that the (2d+1)×n(d+1) matrix E has the following property:
for all i ∈ q, the non-zero entries of the i-th column consist of {αj | j ∈ p, j < i} and αj
is located in the row that corresponds to the place of j in the increasingly ordered list
p.) The reduced row-echelon form can be computed using Gauss-Jordan elimination
or some other methods.

12

Example 20. For the matrix A in Example 12, we have n = 3, d = 4, and



V =

0 0 −1

3
2

0 0

0 0 0

1 0
1 0

1
1 0 0 0 0
1
0 1 0 0 0 −1 0 0 −1 0 −2 −1 0 −1
1
0 −2
0 0 1 0 0
0 −1
0 0 0 1 0
0
1
0 0 0 0 1
0 0
0
0 0 0 0 0
0
0 −1
1 0
0 0 0 0 0
0 0 −1 −1 0 −1
0
0 0 0 0 0
0
0
0 0
0 0 0 0 0
0 0 0 0 0
0 1
1
0
0
0
0 0
0 0 0 0 0
0
0
0 0
0 0 0 0 0
1
1
0 0
0 0 0 0 0
0 0 0 0 0
0 0
0
0
0
0
0 0
0 0 0 0 0

1 0 0
1 0
1 0 0
1 0
0 0 0 −1 0 −2 −1 0
0 0
0 0 0
0 1 0
1 0
0 0 1
0 0 0
0 0 0
0 0 0
0 0 0
0 0 0
0 0 0
0 0 0

0 0
1 0
0 0
0 0
0 1
0 0
0 0

0
1
0
0
0
0
0

0
2



.

The non-pivotal indices are q = {6, 9, 11, 12, 14, 15}. We have

b6 = e6 − v6 = [0, 1,−1,−1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]T
b9 = e9 − v9 = [0, 1,−1,−1, 1, 0,−1, 0, 1, 0, 0, 0, 0, 0, 0]T
b11 = e11 − v11 = [1, 2,−3,−2, 2, 0,−2, 1, 0,−1, 1, 0, 0, 0, 0]T
b12 = e12 − v12 = [0, 1,−1,−1, 1, 0,−1, 1, 0,−1, 0, 1, 0, 0, 0]T
b14 = e14 − v14 = [−1, 1, 0, 0, 0, 0, 0, 1, 0,−1, 0, 0,−1, 1, 0]T
b15 = e15 − v15 = [−1,−1, 2, 1,−1, 0, 1, 0, 0, 0, 0, 0,−1, 0, 1]T

and the corresponding row-echelon syzygies are

1

−1 + s


 −s
 1 − 2s − 2s2 − s3
 −1 − s3 − s4


2 + 2s + s2 + s3

1 + s2 + s4

−3

0



b(cid:91)
6 =

b(cid:91)
11 =

b(cid:91)
14 =

1 + s
−1 + s2


 −s − s2
 −s − s2 − s3

 −1 + s + s2 − s4

1 + s + s2
−1 + s3

−1 − s
2 + s4

b(cid:91)
9 =

b(cid:91)
12 =

b(cid:91)
15 =

 .

The following lemma shows a crucial relationship between the row-echelon syzygies.
Note that, in this lemma, we use i to denote a non-pivotal index and ι to denote a
basic non-pivotal index.

13

Lemma 21. Let vr, r ∈ {1, . . . , n(d + 1)} denote columns of the matrix V . For i ∈ q,
let

Then for any ι ∈ ˜q and any integer k such that 0 ≤ k ≤(cid:106) n(d+1)−ι

bi = ei − vi

(cid:107)

(cid:88)

n

αj b(cid:91)

j+kn,

b(cid:91)
ι+kn = sk b(cid:91)

ι +

{j∈p | j<ι, j+kn∈q}

where constants αj appear in the expression of the ι-th column of A as a linear combi-
nation of the previous pivotal columns:

Proof. We start by stating identities, which we use in the proof. By deﬁnition of V ,
we have for any j ∈ p:

and for any ι ∈ ˜q:

vι =

αjvj =

αjej.

property (10). Therefore, for any ι ∈ ˜q and any integer k such that 0 ≤ k ≤(cid:106) n(d+1)−ι

Since V has the same linear relationships among its columns as A, it inherits periodicity
:

{j∈p | j<ι}

{j∈p | j<ι}

(cid:107)

n

(cid:88)

A∗ι =

αjA∗j.

{j∈p | j<ι}

(cid:88)

vj = ej

(cid:88)

(cid:88)

{j∈p | j<ι}

(14)

(15)

(16)

(17)

vι+kn =

αj vj+kn.

(18)

We will also use an obvious relationship for any r ∈ {1, . . . , n(d + 1)} and 0 ≤ k ≤

(cid:106) n(d+1)−r

(cid:107)

n

:

(19)
and the fact that the set {1, . . . , n(d + 1)} is a disjoint union of the sets p and q. Then
ι+kn = (eι+kn − vι+kn)(cid:91) = ske(cid:91)
b(cid:91)

ι − (cid:88)

αj v(cid:91)

j+kn

r+kn = ske(cid:91)
e(cid:91)
r

by (14), (19) and (18)

(cid:88)
(cid:88)

= ske(cid:91)

ι −

= ske(cid:91)

= ske(cid:91)

= ske(cid:91)

ι −

ι − (cid:88)
ι − (cid:88)

{j∈p | j<ι}

{j∈p | j<ι}

{j∈p | j<ι, j+kn∈p}

{j∈p | j<ι, j+kn∈q}

{j∈p | j<ι, j+kn∈p}

{j∈p | j<ι, j+kn∈q}

(cid:88)
(cid:88)

(cid:16)

αj v(cid:91)

αj e(cid:91)

{j∈p | j<ι}
j+kn −
j+kn −
(cid:88)
(cid:88)

{j∈p | j<ι, j+kn∈q}

{j∈p | j<ι, j+kn∈q}

14

αje(cid:91)

j+kn +

sk αj e(cid:91)

j +

αj v(cid:91)

j+kn

αj v(cid:91)

j+kn

(disjoint union)

by (16)

(disjoint union)

(cid:17)

j+kn − v(cid:91)
e(cid:91)

j+kn

αj

αj b(cid:91)

j+kn

by (19) and (14)

eι − (cid:88)
(cid:88)

{j∈p | j<ι}

= sk

= skb(cid:91)

ι +

{j∈p | j<ι, j+kn∈q}

(cid:91)

+

αj ej

(cid:88)

{j∈p | j<ι, j+kn∈q}

αj b(cid:91)

j+kn

αj b(cid:91)

j+kn.

(17) and (14)

Example 22. Continuing with Example 20, where q = {6, 9, 11, 12, 14, 15} and ˜q =
{6, 11} and p = {1, 2, 3, 4, 5, 7, 8, 10, 13}, we have:

b(cid:91)
9 = s b(cid:91)
b(cid:91)
12 = s2 b(cid:91)
b(cid:91)
14 = s b(cid:91)
b(cid:91)
15 = s3 b(cid:91)

6 + 1 b(cid:91)
6,
9 + 0 b(cid:91)
6 + 1 b(cid:91)
11,
6 + (−1) b(cid:91)
11 + 3 b(cid:91)
11
6 + (−1) b(cid:91)
11 + 1 b(cid:91)
12 + 0 b(cid:91)

14.

(20)

In the next lemma, we show that the subset of row-echelon syzygies indexed by the

n − 1 basic non-pivotal indices is suﬃcient to generate syz(a).

Lemma 23. Let ˜q denote the set of basic non-pivotal indices of A. Then

(cid:68)

(cid:69)
r | r ∈ ˜q
b(cid:91)

.

K[s]

syz(a) =

syz(a) =(cid:10)b(cid:91)

i | i ∈ q(cid:11)

Proof. Since {bi | i ∈ q} comprise a basis of ker(A), we know from Lemma 14 that
K[s] . Equation (15) implies that for all i ∈ q, there exist constant

β’s such that

i = sk b(cid:91)
b(cid:91)

ι +

βr b(cid:91)
r,

(21)

(cid:88)

{r∈q | r<i}

where ι ∈ ˜q is equal to i modulo n. It follows that inductively we can express b(cid:91)
K[s]-linear combination of {br|r ∈ ˜q} and the conclusion of the lemma follows.

i as a

Example 24. Continuing with Example 20, we have from (20):

9 = (s + 1) b(cid:91)
b(cid:91)
6,
12 = (s2 + s + 1) b(cid:91)
b(cid:91)
6 + 0 b(cid:91)
6 + (s − 1) b(cid:91)
b(cid:91)
14 = 3 b(cid:91)
11,
b(cid:91)
15 = (s3 + s2 + s + 1) b(cid:91)

11,

6 + (−1) b(cid:91)
11.

We next establish linear independence of the corresponding leading vectors:

15

Lemma 25. The leading vectors LV (b(cid:91)

r), r ∈ ˜q are linearly independent over K.

Proof. The leading vector LV (b(cid:91)
r) is equal to the last non-zero n-block in the n(d + 1)-
vector br. By construction, the last non-zero element of br is equal to 1 and occurs in
the r-th position. Then LV (b(cid:91)
r) has 1 in ¯r = (r mod n) (the reminder of division of r
by n) position. All elements of LV (b(cid:91)
r) positioned after ¯r are zero. Since all integers in
˜q are distinct (modulo n), LV (b(cid:91)

r), r ∈ ˜q are linearly independent over K.

Example 26. The basic non-pivotal columns of the matrix V in Example (20) are
the columns 6 and 11. We previously computed

b6 = e6 − v6 = [0, 1,−1,−1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]T
b11 = e11 − v11 = [1, 2,−3,−2, 2, 0,−2, 1, 0,−1, 1, 0, 0, 0, 0]T .

Their last non-zero n-blocks are [−1, 0, 1] and [−1, 1, 0]. They coincide with LV (b(cid:91)
6)
and LV (b(cid:91)
11) computed in Example 20. We observe that these vectors are linearly
independent, as expected.
Lemma 27. Let polynomial vectors h1, . . . , hl ∈ K[s]n be such that LV (h1), . . . , LV (hl)
are independent over K. Then h1, . . . , hl are independent over K[s].
Proof. Assume that h1, . . . , hl are linearly dependent over K[s], i.e. there exist polyno-
mials g1, . . . , gl ∈ K[s], not all zero, such that

l(cid:88)

i=1

gi hi = 0.

(22)

(deg(gi) + deg(hi)) and let I be the set of indices on which this maxi-

Let m = max
i=1,...,l

mum is achieved. Then (22) implies(cid:88)

LC(gi) LV (hi) = 0,

i∈I

where LC(gi) is the leading coeﬃcient of gi and is non-zero for i ∈ I. This contradicts
our assumption that LV (h1), . . . , LV (hl) are linearly independent over K.
Theorem 1 (Main). The set u = {b(cid:91)

r | r ∈ ˜q} is a µ-basis of a.

Proof. We will check that u satisﬁes the three conditions of a µ-basis in Deﬁnition 4.

1. From Lemma 19, there are exactly n − 1 elements in ˜q. Since br1 (cid:54)= br2

for
r1 (cid:54)= r2 ∈ ˜q and since (cid:91) is an isomorphism, the set u contains exactly n − 1
elements.

2. From Lemma 25, we know that the leading vectors LV (b(cid:91)

independent over K.

r), r ∈ ˜q are linearly

16

3. Lemma 23 asserts that the set u generates syz(a). By combining Lemmas 25 and
27, we see that the elements of this set are independent over K[s]. Therefore u is
a module basis of syz(a).

Remark 28. We note that by construction the last non-zero entry of vector br is in
the r-th position, and therefore

r) =(cid:6) r/n(cid:7) − 1.

deg(b(cid:91)

Thus we can determine the degrees of the µ-basis elements prior to computing the
µ-basis from the set of basic non-pivotal indices.

Example 29. For the row vector a given in the running example (Example 6), we
determined that ˜q = {6, 11}. Therefore, prior to computing a µ-basis, we can determine

the degrees of its members: µ1 =(cid:6) 6/3(cid:7) − 1 = 1 and µ2 =(cid:6) 11/3(cid:7) − 1 = 3. We now

can apply Theorem 1 and the computation we performed in Example 20 to write down
a µ-basis:

 and b(cid:91)

11 =

 1 − 2s − 2s2 − s3

2 + 2s + s2 + s3

 .

 −s

1

−1 + s

b(cid:91)
6 =

−3

We observe that our degree prediction is correct.

5 Algorithm

In this section, we describe an algorithm for computing µ-bases of univariate polynomi-
als. We assume that the reader is familiar with the Gauss-Jordan elimination process
(for computing reduced row-echelon forms and in turn null vectors), which can be
found in any standard linear algebra textbooks. The theory developed in the previous
sections can be recast into the following computational steps:

1. Construct a matrix A ∈ K(2d+1)×n(d+1) whose null space corresponds to syzd(a).
2. Compute the reduced row-echelon form E of A.
3. Construct a matrix M ∈ K[s]n×(n−1) whose columns form a µ-basis of a, as

follows:
(a) Construct the matrix B ∈ Kn(d+1)×(n−1) whose columns are the null vectors

of E corresponding to its basic non-pivot columns:
• B˜qj ,j = 1
• Bpr,j = −Er,˜qj for all r
• All other entries are zero
where p is the list of the pivotal indices and ˜q is the list of the basic non-
pivotal indices of E.

(b) Translate the columns of B into polynomials.

17

However, steps 2 and 3 do some wasteful operations and they can be improved, as
follows:

• Note that step 2 constructs the entire reduced row-echelon form of A, even though
we only need n − 1 null vectors corresponding to its basic non-pivot columns.
Hence, it is natural to optimize this step as follows so that only the n − 1 null
vectors are constructed: instead of using the Gauss-Jordan elimination process to
compute the entire reduced row-echelon form, one performs operations column by
column only on the pivot columns and basic non-pivot columns. One aborts the
elimination process as soon as n− 1 basic non-pivot columns are found, resulting
in a partial reduced row-echelon form of A.

• Note that step 3 constructs the entire matrix B even though many entries are
zero. Hence, it is natural to optimize this step so that we bypass constructing the
matrix B, but instead construct the matrix M directly from the matrix E. This
is possible because the latter contains all the information about the matrix B.

Below, we describe the resulting algorithm in more detail and illustrate its operation
on our running example (Example 6).

µ-Basis Algorithm

a (cid:54)= 0 ∈ K[s]n, row vector, where n > 1 and K is a computable ﬁeld

Input
Output M ∈ K[s]n×(n−1) such that its columns form a µ-basis of a

1. Construct a matrix A ∈ K(2d+1)×n(d+1) whose null space corresponds to syzd(a).

(a) d ←− deg(a)
(b) Identify the row vectors c0, . . . , cd ∈ Kn such that a = c0 + c1s + ··· + cdsd.



c0
...
cd

. . .
...
. . .

c0
...
cd

(c) A ←−



2. Construct the “partial” reduced row-echelon form E of A.

This can be done by using Gauss-Jordan elimination (forward elimination, back-
ward elimination and normalization), with the following optimizations:

• Stop the forward elimination as soon as n − 1 basic non-pivot columns are

detected.

• Skip over periodic non-pivot columns.
• Carry out the row operations only on the columns needed.

3. Construct a matrix M ∈ K[s]n×(n−1) whose columns form a µ-basis of a.

Let p be the list of the pivotal indices and let ˜q be the list of the basic non-pivotal
indices of E.
(a) Initialize an n × n − 1 matrix M with 0 in every entry.

18

(b) For j = 1, . . . , n − 1

(c) For i = 1, . . . ,|p|

r ← rem (˜qj − 1, n) + 1
k ← quo (˜qj − 1, n)
Mr,j ← Mr,j + sk
r ← rem (pi − 1, n) + 1
k ← quo (pi − 1, n)
For j = 1, . . . , n − 1

Mr,j ← Mr,j − Ei,˜qj sk

Theorem 2. Let M be the output of the µ-Basis Algorithm on the input a ∈ K[s]n.
Then the columns of M form a µ-basis for a.

Proof. In step 1, we construct the matrix A whose null space corresponds to syzd(a) as
has been shown in Lemma 13. In step 2, we perform partial Gauss-Jordan operations
on A to identify the n−1 basic non-pivot columns of its reduced row-echelon form E. In
Lemma 19, we showed that there are exactly n− 1 such columns. In step 3, we convert
the basic non-pivot columns of E into polynomial vectors, using the (cid:91)-isomorphism
described in Section 3, and return these polynomial vectors as columns of the matrix
M . From Theorem 1 it follows that the columns of M , indeed, form a µ-basis of a,
because they satisfy the generating, leading vector, and linear independence conditions
of Deﬁnition 4 of a µ-basis.

Example 30. We will trace the algorithm (with partial Gauss-Jordan) on the input
vector from Example 6:

a =(cid:2) 1 + s2 + s4 1 + s3 + s4 1 + s4 (cid:3) ∈ Q[s]3

1. Construct a matrix A ∈ K(2d+1)×n(d+1) whose null space corresponds to syzd(a):

(a) d ←− 4
(b) c0, c1, c2, c3, c4 ←− [ 1 1 1 ] , [ 0 0 0 ] , [ 1 0 0 ] , [ 0 1 0 ] , [ 1 1 1 ]



(c) A ←−

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1



A blank indicates that the entry is zero due to structural reasons.

2. Construct the “partial” reduced row-echelon form E of A:

For this step, we will maintain/update the following data structures.

• E: the matrix initialized with A and updated by the Gauss-Jordan process.

19

• p: the set of the pivotal indices found.
• ˜q: the set of the basic non-pivotal indices found.
• O: the list of the row operations, represented as follows.

: swap Ei,j with Ei(cid:48),j

(i, i(cid:48))
(i, w, i(cid:48)) : Ei,j ←− Ei,j + w · Ei(cid:48),j
where j is the current column index.

We will also indicate the update status of the columns of E using the following
color codings.

gray
blue
red
brown : periodic non-pivot

: not yet updated
: pivot
: basic non-pivot

Now we show the trace.

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1




(a) Initialize.
p ←− { }
˜q ←− { }

E ←−

O ←− [ ]
(b) j ←− 1




Carry out the row operations in O on column 1. (Nothing to do.)

E ←−

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

Identify column 1 as a pivot.
p ←− {1}
˜q ←− { }
Carry out the row operations (3,−1, 1), (5,−1, 1) on column 1.

20





1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
1
1

E ←−

1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

Append (3,−1, 1), (5,−1, 1) to O.
O ←− [(3,−1, 1), (5,−1, 1)]

(c) j ←− 2

Carry out the row operations in O on column 2.

E ←−

1

1
0
−1
1
0

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1





Identify column 2 as a pivot.
p ←− {1, 2}
˜q ←− {}
Carry out the row operations (3, 2), (4, 1, 2) on column 2.

E ←−

1

1
−1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

Append (3, 2), (4, 1, 2) to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2)]

(d) j ←− 3

Carry out the row operations in O on column 3.

21

E ←−

1

1
1
−1 −1
0
−1
0

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1





Identify column 3 as a pivot.
p ←− {1, 2, 3}
˜q ←− { }
Carry out the row operation (4, 3) on column 3.

E ←−

1

1
1
−1 −1
−1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

Append (4, 3) to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3)]

(e) j ←− 4

Carry out the row operations in O on column 4.

E ←−

1

1
1
−1 −1
−1

0
1
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1





1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
1
1

Identify column 4 as a pivot.
p ←− {1, 2, 3, 4}
˜q ←− { }
Carry out the row operation (6,−1, 4) on column 4.

22





1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
1
1

1

1
1
−1 −1
−1

0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

Append (6,−1, 4) to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4)]

Carry out the row operations in O on column 5.

1

1
1
−1 −1
−1

0
1
1

0
0
1
1
0

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

E ←−

(f) j ←− 5

E ←−





1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

Identify column 5 as a pivot.
p ←− {1, 2, 3, 4, 5}
˜q ←− { }
No row operations needed on column 5.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

Nothing to append to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4)]

(g) j ←− 6

Carry out the row operations in O on column 6.

23



E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0
0

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1



1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

Identify column 6 as a basic non-pivot:
it is non-pivotal because it does
not have non-zero entries below the 5-th row and therefore it is a linear
combination of the ﬁve previous pivotal columns: E∗6 = −E∗2 + E∗3 + E∗4.
It is basic because its index is minimal in its equivalence class q/(3).
p ←− {1, 2, 3, 4, 5}
˜q ←− {6}
No row operations needed on column 6.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

Nothing to append to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4)]

Carry out the row operations in O on column 7.

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

0
1
0
1
0
1

Identify column 7 as a pivot.
p ←− {1, 2, 3, 4, 5, 7}
˜q ←− {6}
Carry out the row operations (7, 6) on column 7.

24




(h) j ←− 7

E ←−




1
0
0
1
1

0
1
0
0
1
1

1
0
0
0
1

0
1
0
0
0
1

E ←−

(i) j ←− 8

E ←−









1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
0
0
1

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

Append (7, 6) to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4), (7, 6)]

Carry out the row operations in O on column 8.

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

Identify column 8 as a pivot.
p ←− {1, 2, 3, 4, 5, 7, 8}
˜q ←− {6}
No row operations needed on column 8.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

Nothing to append to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4), (7, 6)]

(j) j ←− 9

Identify column 9 as periodic non-pivot.

25

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

1
0
0
0
1

1
0
1
0
1

1
0
0
1
1

E ←−

(k) j ←− 10

Carry out the row operations in O on column 10.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

1
0
0
0
1





1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
1
1

0
1
0
0
0
1
1

0
1
0
0
0
1
1

1
0
0
1
1

1
0
0
1
1





Identify column 10 as a pivot.
p ←− {1, 2, 3, 4, 5, 7, 8, 10}
˜q ←− {6}
No row operations needed on column 10.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

1
0
0
0
1

Nothing to append to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4), (7, 6)]

(l) j ←− 11

Carry out the row operations in O on column 11.

26

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

1
0
0
0
1

Identify column 11 as a basic non-pivot.
p ←− {1, 2, 3, 4, 5, 7, 8, 10}
˜q ←− {6, 11}
No row operations needed on column 11.

E ←−

1

1
1
−1 −1
−1

0
1
1

0
0
1
1

0
0
1
0

1
1
0
1
1

1
1
0
0
1
1

1
0
0
0
1

0
1
0
0
0
1
1

0
1
0
0
0
1
1

0
1
0
0
1
0
1

0
1
0
0
1
0
1

1
0
0
0
1

1
0
0
0
1

1
0
1
0
1

1
0
1
0
1

1
0
0
1
1

1
0
0
1
1

1
0
0
0
1

1
0
0
0
1









Nothing to append to O.
O ←− [(3,−1, 1), (5,−1, 1), (3, 2), (4, 1, 2), (4, 3), (6,−1, 4), (7, 6)]
We have identiﬁed n − 1 basic non-pivot columns, so we abort the forward
elimination process.

(m) Perform backward elimination on the pivot columns and basic non-pivot

columns.

E ←−

1

−1

−1

0
1
−1
1
0

1

1

−1
2
−3
2
−2
2
−1
1

1

1
0
0
0
1

1
0
0
0
1

1

1

1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

(n) Perform normalization on the pivot columns and basic non-pivot columns.

27



E ←−

1

1

1

0
−1
1
1
0

1

1

−1
−2
3
2
−2
2
−1
1

1

1
0
0
0
1

1
0
0
0
1

1

1



1
0
1
0
1

1
0
0
1
1

1
0
0
0
1

3. Construct a matrix M ∈ K[s]n×(n−1) whose columns form a µ-basis of a:




0 0
0 0

 0 0
 0
 −s

0
0 s3
0
s

1

−1 + s

(a) M ←−

(b) M ←−

(c) M ←−



1 − 2s − 2s2 − s3
2 + 2s + s2 + s3

−3

6 Theoretical Complexity Analysis

In this subsection, we analyze the theoretical (asymptotic worst case) complexity of
the algorithm given in the previous section. We will do so under the assumption that
the time for any arithmetic operation is constant.

Theorem 3. The complexity of the algorithm given in the previous section is

O(d2n + d3 + n2).

Proof. We will trace the theoretical complexity for each step of the algorithm.

1. (a) To determine d, we scan through each of the n polynomials in a to identify
the highest degree term, which is always ≤ d. Thus, the complexity for this
step is O(dn).

(b) We identify n(d + 1) values to make up c0, . . . , cd. Thus, the complexity for

this step is O(dn).

(c) We construct a matrix with (2d + 1)n(d + 1) entries. Thus, the complexity

for this step is O(d2n).

2. With the partial Gauss-Jordan elimination, we only perform row operations on
the (at most) 2d + 1 pivot columns of A and the n− 1 basic non-pivot columns of
A. Thus, we perform Gauss-Jordan elimination on a (2d + 1) × (2d + n) matrix.
In general, for a k × l matrix, Gauss-Jordan has complexity O(k2l). Thus, the
complexity for this step is O(d2(d + n)).

28

3. (a) We ﬁll 0 into the entries of an n × (n − 1) matrix M . Thus, the complexity

of this step is O(n2).

(b) We update entries of the matrix n − 1 times. Thus, the complexity of this

step is O(n).

(c) We update entries of the matrix |p|×(n−1) times. Note that |p| = rank(A) ≤

By summing up, we have

2d + 1. Thus the complexity of this step is O(dn).

O(cid:0)dn + dn + d2n + d2(d + n) + n2 + n + dn(cid:1) = O(cid:0)d2n + d3 + n2(cid:1)

Remark 31. Note that the n2 term in the above complexity is solely due to step 3(a),
where the matrix M is initialized with zeros. If one uses a sparse representation of
the matrix (storing only non-zero elements), then one can skip the initialization of the

matrix M . As a result, the complexity can be improved to O(cid:0)d2n + d3(cid:1).

Remark 32. As far as we are aware, the theoretical complexity of the algorithm by
Song and Goldman [9] has not yet been published. Based on an initial study of the
algorithm, we believe the complexity of this algorithm to be O(dn5 +d2n4), if one uses a
partial Gauss-Jordan process for ﬁnding the null vector in step 4 of the algorithm. The
rough reason is as follows. Finding a null vector requires performing row operations
on (at most) n + 1 columns. Since each column contains n entries, we conclude that
this step has complexity O(n3). Performing the “update” operation in step 5 of the
algorithm has complexity O(dn2). Step 6 implies that, in the worst case, the algorithm
repeats steps 4 and 5 at most
times. The reason is as follows. Since the
obvious syzygies and each has degree ≤ d, the
algorithm starts with the Cn
(worst case) total degree of the syzygies at the beginning of the algorithm is d n(n−1)
.
The algorithm ends only when the total degree is d. If each repetition of steps 4 and 5
times. Thus,
reduces the total degree by 1, then the steps are repeated
the total computational complexity appears to be O(dn5 + d2n4). However, it will
require a more rigorous analysis to prove/refute this apparent complexity, which is
beyond the scope of this paper.

(cid:16)
d n(n−1)
2 = n(n−1)

(cid:17)
2 − d

(cid:16)

2

(cid:17)
2 − d

d n(n−1)

2

7

Implementation, experiments, comparison

We implemented the algorithm presented in this paper and the one described in Song-
Goldman [9]. For the sake of simplicity, from now on, we will call these two algorithms
HHK and SG. In Section 7.1, we discuss our implementation. In Section 7.2, we describe
experimental performance of both algorithms. An experimental timing corresponds to
a point (d, n, t), where d is the degree, n is the length of the input polynomial vector,
and t is the time in seconds it took for our codes to produce the output. For each
algorithm, we ﬁt a surface through the experimental data points. Our ﬁtting models
are based on the theoretical complexities obtained in Section 6.
In Section 7.3, we
compare the performance of the two algorithms.

29

7.1

Implementation

We have implemented both algorithms (HHK and SG) in the computer algebra system
Maple [1]. The codes and examples are available on the web:

http://www.math.ncsu.edu/~zchough/mubasis.html

We post two versions of the code:

program rf : over rational number ﬁeld Q.
program ff : over ﬁnite ﬁeld Fp where p is an arbitrary prime number.

Now we explain how the two algorithms (HHK and SG) have been implemented.

• Although both algorithms could be written in a non-interpreted language such as
the C-language, making the running time signiﬁcantly shorter, we implemented
both algorithms in Maple [1] for the following reasons.

1. Maple allows fast prototyping of the algorithms, making it easier to write

and read the programs written in Maple.

2. It is expected that potential applications of µ-bases will often be written in

computer algebra systems (such as Maple).

• Both algorithms contain a step in which null vectors are computed (step 2 of HHK
and step 4 of SG). Although Maple has a built-in routine for computing a basis
of the null space for the input matrix, we did not use this built-in routine because
we do not need the entire null basis, but only a certain subset of basis vectors
with desired properties, consisting of n − 1 vectors for HHK and a single vector
for SG. For this reason, we implemented the partial Gauss-Jordan elimination
process.

• For the rational ﬁeld implementation of the SG algorithm, we produced the null
vector in step 4 with integer entries in order to avoid rational number arithmetic
(which is expensive due to integer gcd computations) in the subsequent steps of
the algorithm.

• Dense representations of matrices were used for both algorithms. As shown in
Remark 31, it is easy to exploit sparse representations for HHK, but it was not
clear how one could exploit sparse representations for SG. Thus, in order to ensure
fair comparison, we used dense representations for both algorithms.

7.2 Timing and ﬁtting

We explain the setup for our experiments so that the timings reported here can be
reproduced independently.

• The programs were executed using Maple 2015 version running on Apple iMac

(Intel i 7-2600, 3.4 GHz, 16GB).

• The inputs were randomly-generated: for various values of d and n, the coeﬃcients

were randomly taken from F5, with a uniform distribution.

30

• In order to get reliable timings, especially when the computing time is small
relative to the clock resolution, we ran each program several times on the same
input and computed the average of the computing times.

• The execution of a program on an input was cut oﬀ if its computing time exceeded

120 seconds.

Figure 1: HHK algorithm timing

Figure 2: SG algorithm timing

Figure 1 shows the experimental timing for the HHK algorithm, while Figure 2 shows
the experimental timing for the SG algorithm. The algorithms were run on randomly-
generated examples with speciﬁed d and n, and they ran in time t. For each ﬁgure, the
axes represent the range of values d = 3, . . . , 200, n = 3, . . . , 200, and t = 0, . . . , 120,
where t is the timing in seconds. Each dot (d, n, t) represents an experimental timing.
The background gray surfaces are ﬁtted to the experimental data. The ﬁtting
model is based on the theoretical complexities from Section 6. The ﬁtting was obtained
using least squares. For HHK, based on Theorem 3, we chose a model for the timing,
t = α1d2n + α2d3 + α3n2, where α’s are unknown constants to be determined. After
substitution of the experimental values (d, n, t), we obtain an over-determined system
of linear equations on the α’s. We ﬁnd α’s that minimize the sum of squares of errors.
For SG, we used the same procedure with the timing model t = β1dn5 + β2d2n4 based
on Remark 32.

We obtained the following functions:

tHHK ≈ 10−6 · (7.4 d2n + 1.2 d3 + 1.2 n2)

tSG ≈ 10−7 · (2.6 dn5 + 0.6 d2n4)

(23)

(24)

For our experimental data, the residual standard deviation for the HHK-timing model
(23) is 0.686 seconds, while the residual standard deviation for the SG-timing model
(24) is 11.886 seconds.

We observe from Figures 1 and 2 that for a ﬁxed d, the HHK algorithm’s dependence
on n is almost linear, while the SG algorithm’s dependence on n is highly nonlinear.

31

In fact, for the latter, the dependence is so steep that the algorithm was unable to
terminate in under 120 seconds for most values of n, thus explaining the large amount
of blank space in Figure 2. For a ﬁxed n, the HHK algorithm’s dependence on d is
nonlinear, while the SG algorithm’s dependence on d is almost linear.

7.3 Comparison

Two pictures below represent performance comparison.

Figure 3: HHK (red) and SG (blue).

Figure 4: Tradeoﬀ graph

• Figure 3 shows the ﬁtted surfaces from Figures 1 and 2 on the same graph.
The axes represent the range of values n = 3, . . . , 200, d = 3, . . . , 200, and t =
0, . . . , 120, where t is the timing of the algorithms in seconds.

• Figure 4 shows a tradeoﬀ graph for the two algorithms. The curve in the ﬁgure
represents values of d and n for which the two algorithms run with the same
timing. Below the curve, the SG algorithm runs faster, while above the curve,
the HHK algorithm runs faster. The ratio of the dominant terms in the ﬁtted
formulae is d : n4. This ratio manifests itself in the shape of the tradeoﬀ curve
presented in Figure 4.

From Figure 3, we observe that for a ﬁxed d, as n increases the HHK algorithm
vastly outperforms the SG algorithm. On the contrary, for a ﬁxed value of n, as d
increases the SG algorithm outperforms the HHK algorithm. The order by which SG
runs faster is less than the order by which HHK runs faster for ﬁxed d and increasing
n. We underscore this observation by displaying two-dimensional slices of Figure 3.
Figure 5 represents the slice in d-direction with n = 7, while Figure 6 represents the
slice in n-direction with d = 50. As before, HHK is represented by red and SG by blue.

32

Figure 5: n = 7

Figure 6: d = 50

Acknowledgement: We would like to thank Ron Goldman for a careful reading of
our preprint. The research was partially supported by the US NSF CCF-1319632 grant.

References

[1] L. Bernardin, P. Chin, P. DeMarco, K. O. Geddes, D. E. G. Hare, K. M. Heal,
G. Labahn, J. P. May, J. McCarron, M. B. Monagan, D. Ohashi, and S. M.
Vorkoetter. Maple Programming Guide. Maplesoft, 2015.

[2] Falai Chen, David Cox, and Yang Liu. The µ-basis and implicitization of a rational

parametric surface. J. Symbolic Comput., 39(6):689–706, 2005.

[3] Falai Chen and Wenping Wang. The µ-basis of a planar rational curve-properties

and computation. Graphical Models, 64(6):368–381, 2002.

[4] David Cox, John Little, and Donal O’Shea. Using algebraic geometry, volume 185

of Graduate Texts in Mathematics. Springer-Verlag, New York, 1998.

[5] David A. Cox, Thomas W. Sederberg, and Falai Chen. The moving line ideal basis

of planar rational curves. Comput. Aided Geom. Design, 15(8):803–827, 1998.

[6] Xiaohong Jia and Ron Goldman. µ-bases and singularities of rational planar

curves. Comput. Aided Geom. Design, 26(9):970–988, 2009.

[7] Thomas Sederberg and Falai Chen. Implicitization using moving curves and sur-
faces. Computer Graphics Proceedings, Annual Conference Series, 2:301–308,
1995.

[8] Xiaoran Shi, Xuhui Wang, and Ron Goldman. Using µ-bases to implicitize rational
surfaces with a pair of orthogonal directrices. Comput. Aided Geom. Design,
29(7):541–554, 2012.

[9] Ning Song and Ron Goldman. µ-bases for polynomial systems in one variable.

Comput. Aided Geom. Design, 26(2):217–230, 2009.

[10] Mohammed Tesemma and Haohao Wang. Intersections of rational parametrized

plane curves. Eur. J. Pure Appl. Math., 7(2):191–200, 2014.

33

[11] Jianmin Zheng and Thomas W. Sederberg. A direct approach to computing the

µ-basis of planar rational curves. J. Symbolic Comput., 31(5):619–629, 2001.

34

