Authenticating users through their arm movement patterns

Rajesh Kumar, Syracuse University, NY, USA
Vir V Phoha, Syracuse University, NY, USA
Rahul Raina,, Georgia Institute of Technology, GA, USA

6
1
0
2

 
r
a

M
7

 

 
 
]

V
C
.
s
c
[
 
 

1
v
1
1
2
2
0

.

3
0
6
1
:
v
i
X
r
a

In this paper, we propose four continuous authentication designs by using the characteristics of arm movements while individuals

walk. The ﬁrst design uses acceleration of arms captured by a smartwatch’s accelerometer sensor, the second design uses the

rotation of arms captured by a smartwatch’s gyroscope sensor, third uses the fusion of both acceleration and rotation at the feature-

level and fourth uses the fusion at score-level. Each of these designs is implemented by using four classiﬁers, namely, k nearest

neighbors (k-NN) with Euclidean distance, Logistic Regression, Multilayer Perceptrons, and Random Forest resulting in a total of

sixteen authentication mechanisms. These authentication mechanisms are tested under three different environments, namely an

intra-session, inter-session on a dataset of 40 users and an inter-phase on a dataset of 12 users. The sessions of data collection

were separated by at least ten minutes, whereas the phases of data collection were separated by at least three months. Under the

intra-session environment, all of the twelve authentication mechanisms achieve a mean dynamic false accept rate (DFAR) of 0%

and dynamic false reject rate (DFRR) of 0%. For the inter-session environment, feature level fusion-based design with classiﬁer

k-NN achieves the best error rates that are a mean DFAR of 2.2% and DFRR of 4.2%. The DFAR and DFRR increased from 5.68%

and 4.23% to 15.03% and 14.62% respectively when feature level fusion-based design with classiﬁer k-NN was tested under the

inter-phase environment on a dataset of 12 users.

Categories and Subject Descriptors: C.2 [Computer-Communication Networks]: Security and Protection

General Terms: Biometrics Based Security

Additional Key Words and Phrases: Arm movements, Behavioral Biometrics, Biometrics, Authentication, Smartwatch, Security

1. INTRODUCTION

With the emergence of the Internet of Things (IoT), cyber physical objects such as smart vehicles, smart

buildings, smart devices and other things are to be sensed and controlled remotely across existing net-

work infrastructure. The IoT provides an interface for direct integration of the physical world into

computer-based systems. When augmented with sensors and actuators, the IoT also improves the ef-

ﬁciency and accuracy of the objects connected to it [IoT 2016]. However, these beneﬁts come with a high

risk of security and privacy. Individuals with malicious intent can get unauthorized access to IoT devices

and may create havoc. Therefore, developing authentication mechanisms for users who are authorized

to access these devices is essential. Developing a foolproof authentication mechanism is extremely chal-

lenging due to the following. Firstly, users of these devices strive for secure and less time consuming

authentication mechanisms to accommodate the need of their ever quickening lives. Secondly, the most

July 2015.

A:2

R. Kumar et al.

prominent authentication mechanism based on PINs and passwords, are under question as they can

be stolen by utilizing various side channels [Sarkisyan et al. 2015][Shukla et al. 2014]. Finally, despite

being faster and easier to use, the physiological biometric, e.g. ﬁngerprint, face, and iris-based authen-

tication mechanisms suffer from two weaknesses: i) they provide only entry (or one) point authentica-

tion which provides a window for unauthorized access;, and, ii) they are susceptible to spoof attacks

[Charlton 2013]. For instance, if the owners keep their device unlocked and unattended or if they are

sleeping, intoxicated or unconscious, their ﬁngerprint can be obtained easily to unlock the device.

Alternatively, researchers have been exploring the possibility of authenticating users of these devices

continuously based on their behaviometrics1, especially swiping, typing, and gait (walking patterns)

[Frank et al. 2013][Serwadda et al. 2013][Buchoux and Clarke 2008][Derawi et al. 2010]. Of these, gait

captured by a smartphone accelerometer has shown promise and is seen to be a viable means for authen-

ticating users on smartphones [Derawi et al. 2010] as it achieves a signiﬁcantly high accuracy. However,

most studies of gait biometrics assume that the phone is placed at a ﬁxed location e.g. pocket, hand,

or waist. This is a strong assumption because it ignores the variations introduced (due to changes in

the placement of the phone) in the walking pattern as captured by accelerometer. For instance, Primo

et al. [Primo et al. 2014] demonstrated that variations in acceleration caused by changing the position

of the phone from pocket to hand affects the authentication accuracy markedly [Primo et al. 2014]. The

researchers proposed a multi-stage authentication framework in which the system creates different tem-

plates for different locations of the phone. However, to implement the idea in a real scenario, the system

would need to identify the exact location of the phone on the owner’s body. Any error in prediction of the

phone location could result in an incorrect authentication decision. Unfortunately, no proper framework

exists so far, that can locate the exact position of the phone automatically.

In contrast to smartphones, smartwatches are always worn on the wrist by their users, provide a more

consistent source for capturing arm movements while walking and may provide a potential basis for au-

thenticating users. If arm movements can be used as a behaviometric, not only can it be used to authen-

ticate users to access smartwatches, but also smartphones or any other device paired with a smartwatch

[Greyb 2015]. In addition, it is crucial to study security through smartwatches because they are seen

as the potential replacement for smartphones in the near future [Curtis 2014]. Samsung, Apple and

Microsoft have already begun to incorporate novel sensors and features into their smartwatches. For

example, Samsung is planning to add biosensors to their Gear S that would analyze wrist rotations and

heartbeat signals to authenticate users [Charara 2015].

Thus, this paper examines whether acceleration and rotation generated by an individual’s arm move-

ments while walking, as captured through an accelerometer and a gyroscope built into a smartwatch,

1Any human behavioral characteristic that satisﬁes the following requirements: universality, distinctiveness, permanence, col-
lectability, performance, acceptability, and circumvention; for example, typing, swiping, and walking [Jain et al. 2004].

Authenticating users through their arm movement patterns

A:3

can be used to authenticate users. We also explore whether the fusion of these two (i.e. acceleration and

rotation) enhance authentication performance.

Our contributions are as follows:

— Following our university’s institutional review board (IRB) guidelines, we built a dataset of arm move-

ments of individuals walking naturally. The data collection experiment was carried out in two different

phases. A total of 40 individuals participated in the ﬁrst phase. Twelve of them followed up in the

second phase which was carried out after three months. We plan to share our data, application and

supporting code publicly in order to facilitate fellow researchers to reproduce the results for further

investigations or comparative studies. For details, see Section 4.

— We extracted a total of 32 features from accelerometer readings and a total of 44 features from gyro-

scope readings. By using two feature evaluation methods, namely, the information gain based feature

ranking (IGFR) and the correlation based feature subset selection (CFSS) methods, we evaluate the

importance of these features. The IGFR method helped in ranking the features according to their dis-

criminability, whereas the CFSS method helped in selecting the best subset of features for classiﬁcation.

The feature evaluation helped us discard more than 25% of the features. The effect of feature selection

is demonstrated by comparing the performance of the classiﬁers with and without feature selection.

For details, see Section 5.

— An empirical analysis of two important parameters i.e. the window size (Wsize) used for feature ex-

traction and the amount of overlap or sliding interval (Sinterval) among the consecutive windows is

performed. These two parameters are critical for a continuous authentication mechanism as the for-

mer decides the time taken to give the ﬁrst authentication decision, whereas the latter determines the

time taken to give subsequent decisions. We propose optimal settings for these two parameters are

suggested. For more details, see Section 5.1.1.

— We propose three different continuous authentication designs based on the characteristics of arm move-

ments of individuals: ﬁrst, by using only acceleration, second, by utilizing only rotation, and third by

fusing these two at the feature level. Each of these designs are implemented by four classiﬁcation al-

gorithms, namely, k nearest neighbors (kNN) with Euclidean distance, logistic regression, multilayer

perceptrons, and random forest. Consequently, we propose a total of twelve authentication mechanisms.

All of these mechanisms are tested in three different environments, namely, intra-session, inter-session

and inter-phase. The performance of all of them are presented in terms of DFAR, DFRR and dynamic

accuracy. For more details, see Section 6.

The rest of this paper is organized as follows: the related literature is discussed in Section 2; continuous

authentication and threat model is discussed in Section 3; data collection and feature analysis are pre-

A:4

R. Kumar et al.

sented in Sections 4 and 5; the experimental design and performance evaluation methods are described

in Section 6; and, the conclusions and ideas for future work are given in Section 7.

2. RELATED WORK

To the best of our knowledge,

the most closely related work came out by Johnston et al.

[Johnston and Weiss 2015] while our work was in progress. In their paper, Johnston et al. also pro-

pose similar authentication mechanisms as ours. However there are several factors that distinguish our

work apart from theirs.

First, they only test their systems in an intra-session environment. The intra-session environment does

not represent a realistic scenario as we can not carry out the enrollment and veriﬁcation in the same

session. The intra session environment may favor the classiﬁcation process and result in high accuracy.

We also carried out performance evaluation of the intra-session environment, which always resulted in

perfect classiﬁcation accuracies (error rate of 0%). We assume a more realistic scenario in which the

enrollment is carried out by using the data collected in one session and veriﬁcation by using the other.

We refer to this as the inter-session environment. Additionally, we test our system in a far more realistic

scenario in which the veriﬁcation is carried out after three months of the enrollment. Johnston et al.

mention that when they tried to evaluate the performance in the intra-session or inter-phase environ-

ments, the error rates were very high. Contrary to their study, our design of authentication not only

performs well in the inter-session and but also achieves state-of-the-art classiﬁcation error rates in the

inter-phase environment.

Second, the feature set used by Johnston et al. contains mostly statistical features that have mainly

been used for smartphone accelerometers in the past [Kwapisz et al. 2010]. The same set of features

were extracted from gyroscope readings as well. Our feature set consists of features from both a time

and frequency domain. We also deﬁne sixteen novel features dedicated to the rotation (see Table I). Fur-

thermore, Johnston et al. did not carry out any feature analysis in order to ﬁnd out the strength of the

features. However, we carry out an extensive feature analysis by using two prominent methods IGFR

and CFSS (see Section 5.2). Through this process, we were able to discard more than 25% of the total

features which, not only resulted in improved classiﬁcation accuracy but also reduced classiﬁcation time.

Third, we use two different classiﬁcation algorithms, namely, k-NN and Logistic Regression. Interest-

ingly, both of these outperform the other common ones (i.e., multilayer perceptrons and random forest)

in terms of classiﬁcation accuracy (see Figure 6 and Table III).

Finally, and more importantly, we carry out a fusion of acceleration and rotation at the feature level, a

consideration that is stated in their future work. We also provide an empirical evidence that our system

is scalable to a large population of users which is an important aspect that has not been studied by John-

ston et al.

Authenticating users through their arm movement patterns

A:5

In addition, researchers have studied wrist motion while making pre-deﬁned gestures such as geometri-

cal shape (circle, triangle etc.) or any alphabet or word for authentication purposes. The wrist motions

in these studies are captured by either wrist worn sensors or an accelerometer and gyroscope built into

smartwatches. For example, Yang et al. [Junshuang Yang 2015] studied four different types of gestures,

namely, circle, up, down, and rotation that were collected from 30 users for authenticating them. The

authors apply two different methods, namely, histogram and dynamic time warping (DTW), and report

the distribution of equal error rate (EER) across the users. Above 70% of the users hit an EER of ∼

5%, whereas the remaining users’ EER lies between 5 to 25%. Their proposed authentication system

[Junshuang Yang 2015] is an entry point authentication system, which means it does not monitor the

device continuously. Whereas, in our paper, we propose continuous authentication systems based on arm

movements while walking.

Guiry et al. [Guiry et al. 2014], used smartwatches and smartphones to address the activity recognition

problem. They conclude that although acceleration contributes signiﬁcantly in human activity recogni-

tion, rotation helps in improving the overall performance. Additionally, Lorenzo et al. [Porzi et al. 2013]

used smartwatch to develop an assistance mechanism for visually challenged people during their daily

activities. In their paper, they develop a gesture recognition system based on the combination of signals

received from the smartwatch and smartphone together. Moreover, a variety of applications of smart-

watches are being proposed by researchers. For example, smartwatch-based payment [Charara 2015],

smartwatch based authentication of users to access phones or other paired devices [Greyb 2015] and fall

detection in elderly people [Fraccaro et al. 2014].

Although our proposed authentication framework relies solely upon arm movements while walking, we

believe that it can be easily extended to arm movements while running, while cycling, stair ascents and

stair descents or while typing by designing a multi-stage authentication framework. The multi-stage

authentication framework will use different template for different activities similar to the one proposed

by Primo et al. [Primo et al. 2014]. However, the framework will need to identify the activities on the ﬂy.

The error in activity classiﬁcation will only reduce the authentication accuracy.

3. CONTINUOUS AUTHENTICATION

Continuous authentication (CA) is a process of repeatedly verifying the identity of individuals (who are

authorized to use a device or a system) . The veriﬁcation is carried out at predeﬁned or random intervals,

or after the occurrence of speciﬁc events. The predeﬁned interval usually depends upon the availabil-

ity, quality and quantity of data to be used as input for CA. The CA framework mainly consists of four

components: enrollment, repeated veriﬁcation, re-login, and template update [Traore et al. 2011]. Dur-

ing the enrollment, a template (proﬁle) for the genuine user is created. Sometimes multiple templates

are also created to support the multistage authentication framework. Primo et al. suggest creating two

A:6

R. Kumar et al.

separate templates for smartphones, one for use while a phone is placed in a pocket and the other for use

while a phone is in a user’s hand to improve the authentication accuracy of gait-based authentication

systems. Next, the repeated veriﬁcation component receives a stream of data and classiﬁes that into

either a genuine or an impostor categories, by using the template created during the enrollment process.

The re-login component is typically invoked after a certain number of continuous false rejects, prompting

the user to input some other credentials e.g. PIN, password etc. in order to verify their identity again.

Finally, the template update component is responsible for updating template(s) after a certain period of

time or after a drastic change in the environment[Niinuma et al. 2010].

The proposed authentication system in this paper is a type of CA as it contains all of the

above mentioned components. We assume that by using human activity recognition methods (see

[Dernbach et al. 2012][Yan et al. 2012][Kwapisz et al. 2011]), walking patterns can be accurately de-

tected. The segment of data generated during the walking activity can be supplied to the proposed

authentication system. The enrollment component in the proposed system consists of data collection,

preprocessing, sliding window-based feature extraction, classiﬁer training, and the computation of the

user’s speciﬁc equal error rate threshold. We used around two minutes of data for enrollment. Further

investigation needs to be conducted about how the amount of training data affects the performance of the

system and what the optimal size or duration of data for training should be. The repeated veriﬁcation is

done on a speciﬁed interval (2 to 4 seconds) based on the requirements and assuming the data is avail-

able continuously. The re-login authentication component is not integrated into our system; however,

any conventional authentication system can be incorporated. We studied the impact of template updates

by training on Session1 Phase2 data, updating the thresholds, and by testing on Session2 Phase2 data.

We observed that, by updating the template we could maintain the actual performance of the system (i.e.

accuracy of more then 95%). For details, see Section 6.4.2 and Table III. We could not make conclusions

about what frequency (or duration) of update the template should be. We are planning to follow-up the

data collection to investigate this problem further.

3.1. Attack Scenarios

A total of eight basic sources of attack are described in [Ratha et al. 2001] for a generic biometric system.

The sources include, reproduction of biometric at the sensor (also known as mimicry attack), replay of

stored (or stolen) biometric, overriding the feature extractor, snooping and tempering the feature vec-

tors, overriding template matcher, tempering with or replacing stored templates (adopted in the movie

Mission:impossible - Rogue Nation), channel attack, and decision override. The mimicry is an easy, un-

noticeable, and practical method of attack on any biometric based authentication system, as it does not

require any modiﬁcation to the device or the authentication system. Therefore, biometric researchers

focus more on mimicry attacks. Thus far there exists three kinds of mimicry attacks, in behavioral bio-

Authenticating users through their arm movement patterns

A:7

metrics based authentication systems, namely, zero-effort, minimal-effort, and high-effort. In zero-effort

mimicry attack, it is assumed that adversaries do not have access to the details of genuine user. Hence,

imitators are arbitrarily chosen either from or outside of database. On the contrary, in minimal-effort

mimicry attack, it is assumed that adversaries have access to the details of the genuine user. Hence,

the imitators are chosen based on certain criteria such as similar physical characteristics. For example,

to test a gait-based authentication mechanism, imitators who have similar height, weight and ethnicity

should be used. The high-effort mimicry attack involves intensive training imitators to mimic behavior

of the genuine user [Gafurov et al. 2007][Kumar et al. 2015][Serwadda and Phoha 2013]. For example,

if an individual can be trained to type, swipe or walk like other individuals then the security provided

by authentication systems based on these patterns will be of less use. In this paper, we evaluate the per-

formance assuming the zero effort or random attack. However, we have recorded videos of individuals

while collecting the data. We plan to evaluate our system by carrying out the minimal and high effort

mimicry impostor attacks in the future.

4. DATA COLLECTION

4.1. Procedure

Following the approval from our university’s institutional review board (IRB), we requested students,

staff and faculty members of our university to participate in our data collection exercise. The participants

were informed, prior to participation, that participation is completely voluntary and no compensation

will be provided. A consent form, which brieﬂy explained the nature of our study, was signed by each

participant before we started the data collection process. Participants in our study were mostly graduate

and undergraduate students, with the exception of a few faculty members and staff. In addition to

collecting arm movement information through accelerometer and gyroscope sensors, we also collected

age, gender, and WatchHand (left or right) information of the participants (see Figure 1). The data

collection was carried out in two phases (Phase1 and Phase2), each separated by at least three months.

Each phase consists of two sessions (Session1 and Session2) separated by at least a ten minute time

interval. The data collected during Session1 was used for training the classiﬁers, and the Session2 data

was used for testing purposes in the inter-session testing setup. The data collected during Session1

of Phase1 was used to train the classiﬁers and the data collected during the Session1 and Session2

of Phase2 were used for testing under inter-phase testing setup. Forty subjects participated during

Phase1. Twelve of them followed up in Phase2. Of the 40 subjects who participated in Phase1, 34 of

them are between 20 and 30, four of them are between 30 and 35, and two of them are in their 50s. Ten

of the subjects are female, while the rest are male. Of the twelve participants of Phase2, four of them

are female and the rest are male, and all of them are between 20 and 30. No participants were given

A:8

R. Kumar et al.

any speciﬁc instructions during the data collection except to wear the watch and walk as naturally as

possible for around ∼ 2 min.

Fig. 1. Samsung Gear S worn on the wrist of one of our participants.

4.2. Application Development

We developed an application for the smartwatch (Samsung Galaxy Gear S) to record arm movements (ac-

celeration and rotation) through the accelerometer and gyroscope sensors. We used the tizen-sdk version

2.3.63, which provides application programming interfaces (APIs) for accessing the sensor readings on

the Ubuntu-64 bit platform. HTML and Javascript were used to create the graphical user interface. The

user interface consists of four input ﬁelds to input userid, age, gender, and watchhand (left or right). The

interface also had two buttons start and stop to control when data collection was to begin and end. The

sampling rate for both the sensors, accelerometer and gyroscope was kept to 25Hz.

4.3. Data Preprocessing

In order to remove the noise from the data before feature extraction, we used a simple (equally weighted)

moving average technique, which is described as follows. Let T (t) = (x(t1), x(t2), x(t3),...,x(tn)) be the

original data and T ′(t) = (x′(t1), x′(t2), x′(t3),...,x′(tn−p)) be the transformed data. Then x′(ti) are obtained

as 1/p × (x(ti) + x(ti−1) + ... + x(ti−(p−1))), where p is the parameter to control the number of points taken
at a time. We set p to ﬁve in our experiment as it was able to remove the noise from the data without

disturbing its characteristics.

5. FEATURE ANALYSIS

5.1. Feature Extraction

In order to observe whether the accelerometer and gyroscope readings vary signiﬁcantly among the users,

we carried out exploratory data analysis by plotting ﬁve to ten seconds of the data corresponding to each

)

2

s
/
m

(
 
n
o
i
t
a
r
e
l
e
c
c
A

-5

-10

-15

-20

0

)
s
/
d
a
r
(
 
y
t
i
c
o
l
e
V

 
r
a
l
u
g
n
A

200

100

0

-100

-200

0

)

2

s
/
m

(
 

n
o
i
t
a
r
e
l
e
c
c
A

10

5

0

-5

0

)
s
/
d
a
r
(
 

y
t
i
c
o
l
e
V

 
r
a
l
u
g
n
A

200

100

0

-100

-200

0

)

2

s
/
m

(
 
n
o
i
t
a
r
e
l
e
c
c
A

10

5

0

-5

0

)
s
/
d
a
r
(
 

y
t
i
c
o
l
e
V

 
r
a
l
u
g
n
A

200

100

0

-100

-200

0

)

2

s
/
m

(
 
n
o
i
t
a
r
e
l
e
c
c
A

20

15

10

5

0

)
s
/
d
a
r
(
 

y
t
i
c
o
l
e
V

 
r
a
l
u
g
n
A

250

200

150

100

50

0

0

Authenticating users through their arm movement patterns

User 1

User 2

User 1

User 2

User 1

User 2

A:9

User 1

User 2

50
100
Time (s/25)

150

50
100
Time (s/25)

150

(a) Ax along the X-axis.

(b) Ax along the Y-axis.

(c) Ax along the Z-axis.

(d) Am along the M-axis.

50
100
Time (s/25)

150

50
100
Time (s/25)

150

User 1

User 2

User 1

User 2

User 1

User 2

User 1

User 2

50
100
Time (s/25)

150

50
100
Time (s/25)

150

50
100
Time (s/25)

150

50
100
Time (s/25)

150

(e) Rx along the X-axis.

(f) Ry along the Y-axis.

(g) Rz along the Z-axis.

(h) Rm along the M-axis.

Fig. 2. Exploratory data analysis of segments of data taken from two arbitrarily selected users. A distinguishing trend between
two arbitrary users can be observed.

component of the acceleration (ax, ay, az, and am) and each component of the rotation (rx, ry, rz, and rm)

for a few randomly selected users. Where am and rm are deﬁned as

p(ax)2 + (ay)2 + (az)2 and p(rx)2 + (ry)2 + (rz)2 respectively. We observed clearly distinguishable cycles

among each component of distinct users’ data. We used a sliding window-based feature extraction mech-

anism in which the data stream is divided into several parts (windows) and each window overlaps with

the previous one (see. Figure 3). The sliding (overlapping) windows-based segmentation of streaming

data forms the basis for continuous authentication. In the authentication mode, a segment of data is

taken and features are extracted from it to obtain one feature vector. The feature vector is later fed to

the trained classiﬁer that outputs a score (see Section 6). By comparing the obtained score with a pre-

determined user speciﬁc threshold, the system decides whether it should accept or reject. The process

loops for subsequent segments created from the forthcoming data.

Fig. 3. Sliding window based feature extraction

5.1.1. Length of the window and sliding interval. In order to decide what data stream length offers the most

distinctiveness, we extracted a number of features from all eight components. The length of the window

is referred to as the Wsize and the overlap as the Sinterval. Our proposed authentication mechanism

follows a continuous framework in which authentication decisions are given every few seconds. The

Wsize and Sinterval are two critical parameters as they determine the time the system takes to give the

A:10

R. Kumar et al.

ﬁrst authentication decision and the time taken in the subsequent decisions respectively. Therefore,

we performed an empirical analysis in order to ﬁnd out the optimal setting for these parameters. We

evaluated the performance of the acceleration and rotation based systems separately for ten different

settings (2, 4, 6, ..., 10 seconds) of Wsize and for four different settings (Wsize, Wsize/2, 4, and 2 seconds) of

Sinterval. We observed that the performance stabilized for Wsize beyond 250 (10 seconds). Since, we want

to minimize the Wsize, therefore we suggest to use any number of seconds between 8 to 12 as we observed

lowest error rates in this range for majority of the classiﬁers. We used 10 seconds of windows in all of our

experiments. Similarly, we observed that the performance at Sinterval = 4 seconds was relatively better

compared to Sinterval = 2 seconds throughout, so we used Sinterval = 4 throughout the experiment.

With these settings for Wsize and Sinterval, we extracted a total of 32 features ( = 8 unique features ×

4 dimensions) from the data generated by arm acceleration and 44 features ( = 11 unique features × 4

dimensions) from the data generated from arm rotation (see Table I). Let W = (Wx, Wy, Wz, and Wm) be

Table I. A list of features and their abbreviations used in this
paper. We derived a total of 32 ( = 8 (features) × 4 (x, y,
z, and m), from the accelerometer readings and 44 ( = 11
(features) × 4 (x, y, z, and m) from the gyroscope readings.

S.No.
1
2
3
4
5
6
7
8
9
10
11
12

Feature description
Average peak interval
Bandpower
Energy
Median
# of peaks (only acc.)
Range
Median frequency
Spectral entropy
Median stride time (only rot.)
# of mid-swing points (only rot.) NMSP
Mean rotation angle (only rot.)
Mean rotation rate (only rot.)

Abbrev.
API
BAP
ENG
MED
NOP
RNG
MDF
SPE
MST

MRA
MRR

the window, where Wx, Wy, Wz, and Wm are four column vectors representing the rotation or acceleration

along the x, y, z and m directions. As the Wsize is set to 10 seconds, each of the vectors contains 250 values

as the sampling rate is 25 Hz. Let Wx = (xi, xi+1, xi+2,...,xj ). Then the required features can be computed

as described below:

— Average peak interval (API): We identiﬁed the indices of peaks (local maxima) in Wx by using the

ﬁndpeaks function of MATLAB [MATLAB 013a].
Let I = (ij, ij+1, ij+2, ..., in) be a set of indices of peaks found in Wx. Then API = 1

n−1 Pn−1

j=1 (ij+1 − ij).

— Bandpower: The bandpower of a signal is deﬁned as the average power in the given frequency range.

We computed this feature by using the bandpower(Wx, Sf , Fr) function of MATLAB. Where Wx is the sig-

nal vector, Sf is the sampling frequency that is 25 Hz and Fr is the frequency range, which is [0, (Sf )/2]

in our experiments.

Authenticating users through their arm movement patterns

A:11

— Energy: The energy of a signal vector Wx is computed as

Z j

i

Wx(t)ˆ2dt

.

— Median: To compute the median we sort the elements of Wx and then compute 1/2 × (xn/2 + xn/2+1) as

the number of elements in Wx is always 250 in our case and is even.

— Number of peaks (acceleration only): We identiﬁed be the indices of peaks (local maxima) in Wx by

using the ﬁndpeaks function of MATLAB.

Let I = (ij, ij+1, ij+2, ..., in) be a set of indices of peaks found in Wx. Then the length(I) provides the

number of peaks.

— Range: Range of a Wx is computed as max(Wx) − min(Wx).

— Median frequency: A frequency that divides the power spectrum into two regions with equal am-

plitude is known as the median frequency. We compute the median frequency (MDF) by using the

medf req(Wx, Sf ) of MATLAB R2015a, where Sf is the sampling frequency.

— Spectral entropy: Spectral entropy describes the complexity of the signal. It is directly proportional

to the peak of the signal power spectrum and similar to Shannon’s entropy. With the use of the power

spectral density as a probability density. It is computed as

1

log(N ) P Pi log(Pi).

— The number of mid-swing points (rotation only): A mid-swing (MS) point, is deﬁned as the highest

peak within a single stride. A stride or a cycle is deﬁned as the curve formed by data points from one

peak to another. To ﬁnd the peaks, we used the ﬁndpeaks(Wx, ’MinPeakDistance’, p, ’MinPeakHeight’,

q) function of MATLAB. We set p to 10 to avoid the nearby peaks which mostly occurred due to noise.

For the q, we used 40, as we observed that peaks below forty were either noise or not useful (see Figure

2)[Fraccaro et al. 2014].

— Median stride time (rotation only): Initial contact (IC) points are deﬁned as the ﬁrst local minimum

after the MS point in a single stride. Let (c1, c2, c3, ..., cq) be the indices of ICs in Wx then the median

stride time (MST) is deﬁned as median(c2 − c1, c3 − c2, c4 − c3, ..., cq − cq−1).

— Mean rotation rate (rotation only): Let M = (µ1, µ2, µ3, ..., µr) be the vector containing the statisti-

cal mean of the absolute values between a consecutive pair of MS points in Wx. Then the mean rotation

rate (MRR) is deﬁned as mean(M ).

— Mean rotation angle (rotation only): The mean rotation angle is basically a function of MST and

MRR. It is computed as (M RR × M ST ).

A:12

5.2. Feature Selection

R. Kumar et al.

For better classiﬁcation results, it is important to analyze the discriminability of these features as they

directly affect the classiﬁcation results. Therefore, we evaluated all 32 features (see Table I) extracted

from the accelerometer readings and 44 features (see Table I) from the gyroscope readings by using

two different methods, namely IGFR [Hall and Holmes 2003] and CFSS [Hall 1998]. We anticipated a

few features to perform better in comparison to the others. For example, the rotation angle which is

derived from two variables (i.e. mean rotation rate and stride time) that are independent of each other,

believed to be a highly discriminative feature among different users. While the average number of cycles

(or number of peaks) would be relatively less distinguishing as the number of steps taken by different

individuals in 10 seconds of window does not vary much. This hypothesis is validated by using IGFR

method that ranks features by how discriminative they are with respect to the class label. We saw that

MRA Y and MRR Z were ranked among the top ﬁve best features under the ranked rotation feature list

(see Table II). However, classiﬁcation algorithms that we have used in this paper use a set of features at

a time. Therefore, we used CFSS which returns the best subset of features for distinguishing the users.

5.2.1. Correlation Based Feature Subset Selection (CFSS). We used CFSS implemented in Weka, with ﬁve

possible search methods that use slightly different mechanisms to choose the resulting subset. These

search methods included: the best ﬁrst (BF), genetic search (GS), greedy stepwise (GRS), linear forward

selection (LFS), and subset size forward selection (SSFS). For the 32 acceleration based features, the

GS method chose 27 features, whereas the BF, GRS, LFS, and SSFS methods all selected the same 25

features. We computed the correlation among these features and present the results in Figure 4(a).

Similarly, of the 44 rotation-based features, the same 33 were selected by the BF and LFS, but GS, GRS,

and SSFS selected only 31 features. Though the GRS and SSFS selected the same 31 features for their

feature set, the GS method selected two different features. Because the different features that the GS

method selected were ranked higher in the information gain table (see Table II), we chose this as the

best subset of the subsets of the 31 features. In order to see whether the CFSS worked, we computed the

correlation among 25 accelerometer-based features (see Figure 4(a)) and also among 31 rotation-based

features (see Figure 4(b)). We can observe that the correlations among the selected features are very low,

which is seen as a good sign for classiﬁcation purposes [Frank et al. 2013].

For feature-level fusion, we simply took a union of these separately selected accelerometer and rotation-

based features (see Section 6.3.1) which results in a set of 56 features. The set of fused features are

referred to as separately the selected combined set (SSCS). However, one may wonder why we run feature

selection separately, instead of combining the features and running feature selection on all of the features

at once. Since, CFSS does not perform an exhaustive search over all the possible subsets, running the

feature selection on a total of 76 features would be less likely to perform as exhaustively and accurately

Authenticating users through their arm movement patterns

A:13

than feature selection run on the 32 features and the 44 features independently. The results of this would

then be combined for another round of feature selection. To verify this concept, we applied the CFSS on

the entire set of 76. The BF and GRS output the same 59 feature subset, the LFS and SSFS selected

the same subset of 46 features, and the GS method selected 52 features. Next, when we evaluated the

performances of the system built upon these feature subsets (59, 46, and 52), we found that the subset

with 59 features performed slightly better when compared to the other two subsets (i.e. 46 and 52). We

refer to the selected subset of features (59) as the selected set of total features (SSTF). Further, when

we compared the performance of the SSCS and SSTF, the SSCS performed consistently better than the

SSTF for all of the four classiﬁers used in our experiments. Therefore, we chose to use the SSCS in all of

our feature-level fusion experiments. The heat map of the correlations among the SSCS features looks

similar to Figures 4(a) and 4(b).

Table II. List of features ranked using the information gain at-
tribute evaluator with the search method Ranker that ranks at-
tributes by their individual evaluations. The attribute selection
mode was the 10-fold cross validation. Hence, we obtained the
average information gain and the standard deviation.

Rank

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32

Rot. Features
Feature
ENG Z

Acc. Features
Info Gain
Info Gain
Feature
2.50 (0.05)
2.21 (0.03)
MED Y
2.26 (0.05) MED M 2.16 (0.07)
ENG X
2.24 (0.05) MRR M 2.17 (0.09)
ENG M
ENG M
2.21 (0.05)
2.15 (0.06)
MED Z
2.14 (0.08)
2.13 (0.03) MRR Z
MED X
2.12 (0.05)
ENG Y
2.13 (0.08)
ENG Y
1.99 (0.06)
2.11 (0.03)
RNG Y
BAP X
1.99 (0.04)
2.00 (0.08) MRA Z
BAP M
1.96 (0.06)
1.96 (0.06)
BAP M
BAP Y
1.84 (0.14) MRR Y
1.94 (0.05)
ENG Y
1.93 (0.05)
RNG Z
MED M 1.87 (0.02)
1.90 (0.07)
BAP Z
1.64 (0.06)
SPE Y
1.84 (0.03)
1.60 (0.08)
SPE X
BAP Y
1.78 (0.04)
1.52 (0.03) MRA Y
BAP Z
SPE M
1.42 (0.02)
RNG M
1.73 (0.07)
1.36 (0.11) MDF M 1.61 (0.06)
RNG Z
1.32 (0.02) MRR X
RNG M
1.61 (0.13)
1.32 (0.07) MRA M 1.57 (0.1)
MDF Y
1.27 (0.25) MRA X
RNG X
1.28 (0.07) MDF X
NOP Z
MDF X
1.22 (0.01) MST Z
MDF M 1.18 (0.10)
ENG X
1.18 (0.13) MDF Z
NOP X
1.10 (0.03) MST X
API M
API Z
1.05 (0.13)
API X
API Y
RNG Y
1.02 (0.23)
1.01 (0.11)
API Y
BAP X
0.98 (0.16) MST Y
NOP M
0.90 (0.08) MDF Y
MDF Z
API M
0.83 (0.03)
API Z
NOP Y
0.81 (0.01)
RNG X
SPE Z
0.73 (0.04)
SPE Z

1.44 (0.08)
1.42 (0.05)
1.38 (0.05)
1.38 (0.09)
1.29 (0.02)
1.24 (0.06)
1.17 (0.29)
1.22 (0.04)
1.23 (0.09)
1.19 (0.08)
1.05 (0.04)
1.01 (0.16)
0.96 (0.04)
0.86 (0.04)

A:14

R. Kumar et al.

API_M
API_X
API_Y
API_Z
BAP_X
BAP_Y
BAP_Z
ENG_M
ENG_Y
ENG_Z
MED_X
MED_Y
MED_Z
NOP_X
NOP_Y
NOP_Z
RNG_M
RNG_Y
RNG_Z
MDF_X
MDF_Y
MDF_Z
SPE_X
SPE_Y
SPE_Z

API_ M

API_X

API_Y

BAP_X
API_Z

BAP_Z
E N G _ M
BAP_Y

E N G _Y
N O P_Y
M E D_Y
M E D_X
N O P_X
M E D_Z
R N G _ M
E N G _Z
M DF_X
R N G _Y
N O P_Z
R N G _Z

SPE_X
M DF_Z
M DF_Y

SPE_Z
SPE_Y

 

(a) Acceleration based features.

API_M 
API_X 
API_Y 
API_Z 
BAP_M 
ENG_Y 
ENG_Z 
MED_M 
MED_X 
MED_Y 
MED_Z 
RNG_M 
RNG_X 
RNG_Y 
MDF_M 
MDF_X 
MDF_Z 
SPE_X 
SPE_Z 
MST_X 
MST_Y 
MST_Z 
NMSP_M
NMSP_Y
MRA_M 
MRA_X 
MRA_Y 
MRA_Z 
MRR_X 
MRR_Y 
MRR_Z 

M E D_ M 
BAP_ M 
API_Y 
M R A_ M 
N M SP_Y
M D F_ M 
M R A_X 
M E D_Y 
M E D_X 
M R R_Y 
E N G _Z 
M D F_Z 
E N G _Y 
API_ M 
M E D_Z 
API_Z 
N M SP_ M
R N G _ M 
M R A_Y 
R N G _Y 
M R R_Z 
M ST_Z 
M R R_X 
M ST_Y 
SPE_Z 
M R A_Z 
API_X 
SPE_X 
M D F_X 
R N G _X 
M ST_X 

 

(b) Rotation based features.

 

1

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

 

1

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

−0.8

Fig. 4. Correlation among the subset of features selected from the set of acceleration and rotation based features by using CFSS
method. As expected, we can see that most of the features are uncorrelated to each other.

Authenticating users through their arm movement patterns

A:15

5.2.2. Information Gain Feature Ranking Method (IGFR). As mentioned above, the CFSS method selects the

best subset following the philosophy that, the selected features should be highly correlated with the

class attribute in addition to being the least correlated with other features in the subset. The CFSS

method, however, fails to provide any comparison between the features. Therefore, we used IGFR

[Hall and Holmes 2003], which provides a measure of discriminability of each of the features separately

and ranks them accordingly. We evaluated all 32 acceleration-based features by using the IGFR method.

The features and their information gain are presented in Table II. Interestingly, when observed we found

that, of the 25 acceleration-based features that were selected by the CFSS, 20 were ranked in the top 25

features in the information gain table (see Figure 4(a) and Table II). Similarly, we used IGFR methods

on the 44 rotation-based features and ranked them according to their information gain; we found that,

of the 31 rotation-based features selected by the CFSS, 22 were ranked within the top 30 features (see

Figure 4(b) and Table II). It will be interesting to see the tradeoff between the number of features used

for classiﬁcation and the performance. We plan to carry out this analysis in our future work.

6. PERFORMANCE EVALUATION

6.1. Classiﬁcation Algorithms

Different researchers have used different classiﬁcation algorithms for building authentication systems

based on acceleration captured by smartphones. For example, Yang et al. [Junshuang Yang 2015] used

histogram and dynamic time warping methods, Primo et al. [Primo et al. 2014] used Logistic Regression,

Zhong et al. [Zhong and Deng 2014] used gait dynamics images, Nickel et al. [Nickel et al. 2012] used

k-NN, and Kumar et al. [Kumar et al. 2015] used Bayes Network, Logistic Regression, Neural Network,

Random Forest, and SVMs. Along the same line, we chose to use k-NN with Euclidean distance and ten

nearest neighbors [Aha and Kibler 1991], and Random Forest with one thousand trees [Breiman 2001].

These two algorithms are commonly known as weighted neighborhood schemes, and are comparatively

faster in decision-making. We also used Logistic Regression [Witten and Frank 2005] and Neural Net-

work (i.e. Multilayer Perceptrons) [Hassoun 1995], as both are frequently used classiﬁers in this area

[Johnston and Weiss 2015]. The Multilayer Perceptrons was observably slow in training and testing, and

also did not perform better than the other classiﬁers.

6.2. Training and Testing Methods

6.2.1. Training the classiﬁers. We used a total of four state-of-the-art classiﬁers, all of them requiring

knowledge of both genuine and impostor classes in order to be trained. In other words, the training

set consists of both genuine and impostor samples. The genuine and impostor samples consist of a set

of feature vectors that are created by extracting features from overlapping windows. The overlapping

A:16

1

0.8

0.6

0.4

0.2

d
l
o
h
s
e
r
h
T

kNNEuc

LogReg

MulPer

RanFor

 

1

0.8

d
l
o
h
s
e
r
h
T

0.6

0.4

0.2

R. Kumar et al.

kNNEuc

LogReg

MulPer

RanFor

 

0

 
0

4

8

12

16

20

# of users

24

28

32

36

40

0

 
0

4

8

12

16

# of users

20

24

28

32

36

40

(a) Distribution of user-speciﬁc EER thresholds for acceleration
based system.

(b) Distribution of user-speciﬁc EER thresholds for rotation
based system.

Fig. 5. The distribution of user-speciﬁc dynamic equal error rate thresholds. These ﬁgures suggest that a global threshold could
have downgraded the performance of the authentication systems.

windows are obtained by segmenting the raw data (see Figure 3). These samples are created for each

user separately. We refer to the user as the candidate user for which the samples are being created,

whereas the remaining users are referred to as other user. The process of creating feature vectors for

genuine and imposter samples is the same. The only difference is, the raw data used for creating them.

For instance, the feature vectors of genuine samples are created by using the candidate user’s data,

whereas the feature vectors of impostor samples are created by using the other user’s data. To create

impostor samples, we investigated three options. First, we took genuine samples of every other user.

Second, we took a ﬁxed number of genuine samples from every other user. Third, we selected a ﬁxed

number of genuine samples from a ﬁxed number of randomly selected users from the set of other users.

We decided to use the second option, i.e., the ﬁxed number (four consecutive) of samples from every other

user. The main reason behind choosing this option is that it gives relatively more samples for training

and testing compared to the third option. Additionally, it avoids the class imbalance problem to some

extent which would have been worse compared to the ﬁrst option. However, we observed that, even with

the second option we had more feature vectors (39 ( # of other users) * 4 ( # of feature vector taken from

each) = 156 feature vectors) in the impostor samples compared to the genuine samples (15-20) for a user.

One feature vector is created by using ten seconds of window and we had ∼ 2 min of data for each user.

By keeping the overlap of four seconds between the consecutive windows, we had around 15-20 feature

vectors created from ∼ 2 min of data for each user. The difference in the number of feature vectors of the

genuine (15-20) and impostor (156) samples is still big and can potentially pose a class imbalance prob-

lem. To overcome this issue, we again had two alternatives, either over-sampling the genuine users or

under-sampling the impostor samples. We opted to over sample the genuine samples by using bootstrap-

ping (repeating the uniform-randomly picked instances) to make the number of genuine and impostor

samples equal. As a result, the training set contains an equal number (156) of features vectors for both

impostor and genuine classes for each user. The training set is fed to the classiﬁers to create an indepen-

dent model (template or proﬁle) for each user.

For inter-session setup, the training sets were created from data collected during Phase1 Session1 (P1S1)

Authenticating users through their arm movement patterns

A:17

for Phase1 inter-session whereas data collected during Phase2 Session1 (P2S1) was used for Phase2 inter-

session (see Table III). Similarly, for inter-phase setup, the training set was created from data collected

during Phase1 Session1 (P1S1).

6.2.2. Genuine and Impostor Testing. Once the models are created for each user by using the training set,

we test the model by using the genuine and impostor samples separately, created from data designated

for testing. The testing data depends upon the testing setup. For example, for inter-session testing setup,

the testing data comes from either Phase1 Session2 or Phase2 Session2. Whereas, for inter-phase testing

setup, the testing data comes either from Phase2 Session1 or Phase2 Session2. The classiﬁers output

probabilities of belonging to the genuine class for every single vector supplied to them. The probabili-

ties obtained for the feature vectors belonging to the genuine class are referred to as the genuine score,

whereas the probabilities obtained for feature vectors belonging to the impostor class are referred to as

the impostor scores in the rest of this paper. For each user, we obtained separate vectors of genuine

and impostor scores. Let Gs = {g1, g2, g3, ..., gm} and Is = {i1, i2, i3, ..., in} be the vectors of the genuine

and impostor scores, respectively. These scores were obtained for the feature vectors created from the

successive overlapping windows, but are considered as independent scores that make an authentication

decision. Successive authentication decisions are made from these scores by using user-speciﬁc equal

error rate (EER) thresholds. The user-speciﬁc EER thresholds are computed during the training period.

To create the user-speciﬁc threshold, we used the genuine and impostor scores obtained by using the

training data as test data. Figure 5 shows equal error thresholds obtained for each user. We observed

that the threshold for each user varies signiﬁcantly, we opted to use user speciﬁc thresholds instead of

a global threshold. Moreover, other researchers have also suggested that user-speciﬁc thresholds not

only improve the performance, but also increase the robustness of the system against spoof attacks

[Rattani et al. 2012][Jain and Ross 2002].

Since in our system, acceptance or rejection decisions are continuously made over a certain pe-

riod of time we use the continuous authentication metrics DFAR, DFRR and dynamic accuracy

[Ahmed 2008][Monroe ] to evaluate the overall performance of our system. For each user, we computed

the DFAR, DFRR and dynamic accuracy by using the genuine (and imposter scores) and the speciﬁc

equal error rate (EER) threshold computed for each user during the enrollment process. We report the

average DFAR, DFRR, and dynamic accuracy, computed over a total of 40 users (e.g. see Figure 6).

6.3. Fusion of sensor readings

The fusion of acceleration and rotation is feasible at three different levels namely, at the data level,

feature level, and score level. In this paper, we only investigate the feature and score level fusion. We

plan to explore the data level fusion in future. These different levels of fusion proved to have varying

A:18

R. Kumar et al.

levels of success in improving overall performance of the system and adding an extra layer of secu-

rity against imitation attacks on authentication systems which are built by using acceleration only (see

[Kumar et al. 2015]).

)

%

(
 

R
A
F
D
n
a
e

 

M

12
10
8
6
4
2
0

A(32)

A(25)

R(44)

R(31)

F(76)

F(56)

 

 

kNNEuc

LogReg

MulPer

RanFor

Classifiers

(a) Average DFAR.

A(32)

A(25)

R(44)

R(31)

F(76)

F(56)

 

kNNEuc

LogReg

MulPer

RanFor

Classifiers

(c) Average Dynamic Accuracy.

)

%

(
 

R
R
F
D
n
a
e

 

M

16
14
12
10
8
6
4
2
0

A(32)

A(25)

R(44)

R(31)

F(76)

F(56)

 

 

kNNEuc

LogReg

Classifiers

MulPer

(b) Average DFRR.

RanFor

)

%

(
 
y
c
a
r
u
c
c
A
D
n
a
e

 

M

 

100
98
96
94
92
90
88
86
 
0

 

kNNEuc

LogReg

MulPer

RanFor

4

8

12

16

20

# of users

24

28

32

36

40

(d) Scalability of the system built only upon acceleration data
generated from hand movements.

kNNEuc

LogReg

MulPer

RanFor

 

4

8

12

16

20

# of users

24

28

32

36

40

)

%

(
 
y
c
a
r
u
c
c
A
D
n
a
e

 

M

 

100
98
96
94
92
90
88
86
 
0

 

kNNEuc

LogReg

MulPer

RanFor

4

8

12

16

24

28

32

36

40

20

# of users

)

%

(
 
y
c
a
r
u
c
c
A
D
n
a
e

 

M

99
97
95
93
91
89
87
85

 

)

%

(
 
y
c
a
r
u
c
c
A
D
n
a
e

 

M

 

100
98
96
94
92
90
88
86
 
0

(e) Scalability of the system built only upon rotation data gen-
erated from hand movements.

(f) Scalability of the system built upon the fusion of acceleration
and rotation generated from hand movements.

Fig. 6. Figures 6(a), 6(b), and 6(c), show the impact of feature selection and FLF on the average performance (DFAR, DFRR, and
dynamic accuracy) of the authentication system. In this ﬁgure, acceleration, rotation and fusion are abbreviated as A, R and F
respectively. The numbers of features used for corresponding sensors are given inside parentheses. For example, A(32) means
the performance is evaluated by using a total of 32 acceleration-based features. Moreover, Figures 6(d), 6(e), and 6(f) show the
scalability of the systems built upon the acceleration, gyroscope, and fusion of these two respectively.

6.3.1. Feature level fusion. Fusion at the feature level is proven to be effective in multi-modal biometrics

systems. Therefore, we carried out a feature level fusion (FLF) considering acceleration (32) as one and

rotation (44) as the other modality. As mentioned in Subsection 5.2, we evaluated these features sepa-

rately and selected 25 and 31 features respectively. Further, to fuse them we applied the concatenation

method. For example, let A = {f1, f2, ..., f25} be the subset of features selected from the acceleration data

and G = {g1, g2, ..., g31} be the subsets of features selected from the rotation data, then the fused feature

Authenticating users through their arm movement patterns

A:19

)

%

(
 

R
A
F
n
a
e

 

M

k−Star

MulPer

LogReg

k−NNEuc

7
6
5
4
@
3
@@
2
 
0 .05 .1 .15 .2 .25 .3 .35 .4 .45 .5 .55 .6 .65 .7 .75 .8 .85 .9 .95 1

RanFor

@

@

Weights for acc. scores

 

)

%

(
 

R
R
F
n
a
e

 

M

 

k−Star

MulPer

LogReg

k−NNEuc

18
16
14
12
10
8
6
4
@@
2
 
0 .05 .1 .15 .2 .25 .3 .35 .4 .45 .5 .55 .6 .65 .7 .75 .8 .85 .9 .95 1

RanFor

@

@

@

Weights for acc. scores

(a) FAR

(b) FRR

Fig. 7.
Impact of SLF on average FAR and FRR computed over all 40 users of the dataset. The weights along the x-axis are the
weights assigned to the acceleration based scores whereas the weights for rotation-based are computed as (1 − Wa).The at the rate
symbols (@) show the best combination of weights for fusion.

set can be given as S = A ∪ G = {f1, f2, .., f25, g1, g2, ..., g31} [Nagar et al. 2012] [A and B 2005]. In order

to demonstrate the impact of the FLF on the performance, we evaluated three variations of the authen-

tication system: ﬁrst, by using only an acceleration-based system, second, by using only a rotation-based

system, and third, by using the FLF-based system. In addition, to show the effect of feature selection,

we evaluated these three systems with and without feature selection. The performance of all six systems

is presented in Figure 6(a), 6(b), and 6(c). By observing these ﬁgures, we can conclude two things: ﬁrst

the feature selection has a positive impact, as without compromising the accuracy much, we were able

to get rid of more than 25% of the features. Second, a system based on the fusion of the selected features

outperforms the other variations for three out of four classiﬁers.

Is the FLF worth using? This question arises as the FLF almost doubles the number of features used to

build the authentication system. The answer is, it depends. If we take only the performance (accuracy)

into account, it may not be that useful. However, FLF may worth it if we consider minimal or high effort

mimicry threat model as stated in section 3.1. Kumar et al. [Kumar et al. 2015] suggest that authentica-

tion systems based only on acceleration are vulnerable to high effort imitation attack. They also suggest

that the inclusion of other context information e.g., rotation captured through the gyroscope will add

extra dimensions to the feature space. Considering the minimal or high effort mimicry threat models,

we believe that fusing rotation information at the feature level may provide an extra layer of defense,

in addition to improving the overall performance of the system. We do not claim that fusing rotation

information will completely rule out the possibility of attack, but we believe that it will certainly make

an adversary’s job more difﬁcult as fusion of rotation information adds more (31) degrees of freedom in

the feature space.

6.3.2. Score level fusion. As we used the same classiﬁers for both of the modalities, the classiﬁcation

scores were similar in nature (probabilities). The score level fusion (SLF) was one of the feasible and

practical alternatives for fusing acceleration and rotation. Moreover, one of the biggest advantages of

A:20

R. Kumar et al.

SLF is that it requires no knowledge of the underlying features extraction and classiﬁcation methods

[Dass et al. 2005][He et al. 2010]. We used a weighted score fusion technique in order to fuse the classi-

ﬁcation scores obtained from acceleration- and rotation-based systems built on separately on separately

selected features. Let Sa be the acceleration-based classiﬁcation scores and Sr be the rotation-based clas-

siﬁcation scores. The fused scores are computed as Sf = (Wa × Sa) + (Wr × Sr), where Wa is the weight

for acceleration-based scores, Wr is the weight for rotation-based scores (Wa + Wr = 1). In Figure 7(a)

and 7(b), the weights along the x-axis are the weights assigned to the acceleration based scores whereas

the weights for rotation-based are computed as (1 − Wa). The at the rate symbols (@) show the best

combination of weights for fusion. By observing these results, we can see that SLF is not as effective as

the FLF. Therefore, we conclude that feature level fusion shows more promise than the score level fusion

which is not a surprise.

6.4. Discussions

6.4.1. Scalability of the system. How scalable is our proposed system? Since, we tested our system on a

limited number (40) of users, it is important to investigate the scalability of all three authentication

systems for a larger population of users. To show that our method is scalable, we computed the error

rates and accuracy starting from one user, kept on adding other users one by one, and computed the

mean of error rates, and the mean of accuracies [Frank et al. 2013]. The users were added in their order

of participation in our data collection. We repeated the experiment until all 40 users of our database

were added and tested. We can see that the mean accuracy stabilized after a certain number of users

were added. For example, FLF based system achieves 95% or higher for three (kNNEuc, LogReg, and

RandFor) out of four classiﬁers after testing 30% of the users (see Figures 6(d), 6(e), 6(f)). A sharp drop of

2% can be observed for multilayer perceptrons but soon after adding more users, the accuracy stabilized

and stayed up above the 93%. This trend suggests that all three of our systems are scalable to the desired

number of users.

6.4.2. Impact of external phenomenon on the performance. In order to analyze how external phenomenon, e.g.,

physiological changes, shoe type, emotional state, pose and orientation, prior activity, time, etc., affect

the authentication accuracy, we collected the data in two different phases separated by at least three

months. We decided to use a three month period because we assume that most of the mentioned external

phenomenon change signiﬁcantly enough to affect the performance of the authentication system. We

evaluated the performance of each system with all four classiﬁcation algorithms. The performance of

systems based on acceleration, rotation and fusion are presented in Table III. We can observe that the

performance of each system in the inter-phase setting is poor compared to the one in the inter-session

setting. However, the error rates are still acceptable for a continuous authentication system. The P2S1 −

Authenticating users through their arm movement patterns

A:21

Table III. The performance of the acceleration, rotation, and FLF-based authentication systems in intersession and interphase au-
thentication for ONLY TWELVE common users in Phase1 and Phase2. Each sessions were separated by at least a 10 minute of
interval, whereas the phases are separated by at least a three month time period. The acronyms PaSb − PcSd indicate the data
used for training and testing. For example, P1S1 − P1S2 stands for Phase1 Session1 for training and Phase1 Session2 for testing.
The P1S1 − P1S2 and P2S1 − P2S2 are for the inter session, whereas P1S1 − P2S1 and P1S1 − P2S2 are for the inter-phase. DAc
stands for dynamic accuracy.

Class-
iﬁers

kNNEuc
LogReg
MulPer
RanFor

kNNEuc
LogReg
MulPer
RanFor

kNNEuc
LogReg
MulPer
RanFor

Inter-Session

Inter-Phase

P1S1 − P1S2

P2S1 − P2S2

P1S1 − P2S1

P1S1 − P2S2

DFAR DFRR DAc DFAR DFRR DAc DFAR DFRR DAc DFAR DFRR DAc

9.91
16.04
17.45
18.4

8.81
13.05
16.67
15.57

5.68
12.63
12.5
16.29

3.85
3.21
2.08
3.85

8.01
5.61
5.61
2.24

4.23
3.21
2.82
1.03

Performance of acceleration-based authentication system

93.1
90.3
90.2
88.8

91.6
90.6
88.8
91

95
92
92.3
91.3

8.49
12.58
15.57
22.8

3.69
3.85
3.53
4.01

93.9
91.8
90.4
86.5

16.04
17.45
22.48
30.5

22.76
8.81
6.89
3.69

80.6
86.8
85.2
82.8

13.68
21.23
25.16
26.42

Performance of rotation-based authentication system

9.75
12.89
13.99
15.88

4.33
3.69
2.4
4.33

92.9
91.7
91.8
89.8

16.19
16.67
22.01
19.65

17.95
20.67
18.59
10.26

82.9
81.4
79.7
85

Performance of FLF-based authentication system

8.33
11.99
13.64
21.09

3.33
1.28
0.77
0.9

94.1
93.3
92.7
88.9

17.68
18.43
23.61
26.77

12.31
6.03
5.13
2.31

85
87.7
85.6
85.4

15.09
16.35
24.37
20.75

15.03
17.8
22.35
26.39

23.24
11.06
7.37
4.81

26.92
27.72
25.32
17.31

14.62
5.38
3.72
2.31

81.6
83.8
83.7
84.3

79.1
78
75.2
81

85.2
88.4
86.9
85.6

P2S2 column of Table III presents the results of the template update. To show the effect of the template

update we trained the classiﬁer again by using the latest (P2S1) data and updated the thresholds for

every user. The performance is tested by using the data collected later on i.e. in P2S2. We can see that

the accuracy is almost unaltered which means if the template gets updated periodically the performance

(accuracy) of the system will remain above 90 in most of the cases.

6.4.3. Arm movements while walking as a behaviometric. We argue that arm movements while walking qual-

iﬁes as a behaviometric based on these criteria: universality, distinctiveness, permanence, collectability,

performance, acceptability, and circumvention [Jain et al. 2004]. Since arm movements, while a person

walks, are a universal behavior, it satisﬁes the universality criteria. Our experimental results support

the distinctiveness and permanence criteria– distinctiveness is supported by accuracy in authentication

(∼96%) and permanence through the training and testing data used in different time frames. Because

the data collection or the method of interaction with the device for authentication does not pose proce-

dural issues, we claim that arm movements recorded through smartwatches satisfy collectability and

acceptability criteria. We do not expect drastic change in arm movements within the same context thus

our claim of circumvention. Thus we posit that arm movements while walking has a potential to be a

behaviometric.

6.4.4. Application Scenarios. The security of components (cars, mobile, tablets, computers, house, lockers,

ofﬁces, schools, restaurants, airports, weapons, etc.) of the Internet of Things (IoT) has become more

prevalent than ever before. The authenticity or identity of the owner of these devices has to be contin-

A:22

R. Kumar et al.

uously and unobtrusively veriﬁed, instead of the one point authentication offered by PINs, passwords,

patterns, or physiological characteristics such as ﬁnger, palm, iris, face prints etc. The potential channels

to verify the authenticity or identity of the owner are wearable or hand-held devices such as smartphones,

smartwatches, Google glass, key fobs etc. The proposed behaviometric in this paper can be potentially

used to authenticate users for accessing the aforementioned buildings and devices.

For example, consider an organization like Central Intelligence Agency (CIA), where, there are various

levels of security clearance that allow authorized people to access secured resources. The current existing

security mechanisms verify the authenticity of a person at the time of entry. If the security service at the

time of entry is compromised, the CIA does not have any other means to detect the authenticity of the

individual. In this case, our proposed behaviometric can be very helpful because it provides continuous

and unobtrusive veriﬁcation of authorized individuals. The authorized person will have to wear a smart-

watch while they walk up to the secured equipment, weapons, documents, or buildings. The security

system will automatically verify them easily, efﬁciently, and conveniently by using the data generated

by their arm movements. A similar concept can be seen in the movie Mission:Impossible - Rogue Nation,

where a camera based gait authentication system is used to create the most secure and unbreakable

system seen to date.

7. CONCLUSION AND FUTURE WORK

We conclude that arm movements while walking can be used as a viable means for authenticating users.

We designed, implemented, and evaluated four continuous authentication mechanisms, ﬁrst by using

acceleration of arms, second rotation of arms, and third through fusion of these two at the feature level.

We tested all four designs (acceleration, rotation, and fusion) by using four machine learning classiﬁca-

tion algorithms. Our experimental results suggest that, although acceleration and rotation individually

are sufﬁciently discriminative to build an authentication system, the feature-level fusion of these modal-

ities not only improves the overall performance of the system but it also arguably adds an extra layer

of defense against potential high-effort mimicry attacks. We also conclude that the score level fusion

does not improve the performance much. By performing in-depth analysis of features extracted from

each acceleration and rotation, we provide the best suitable subsets of features for classiﬁcation. Our

empirical analysis shows that Wsize between eight to twelve seconds and SInterval of two to four seconds

are effective in general. These settings offer more frequent and reliable authentication decisions.

In future, we plan to investigate the following: investigate the impact of data and score level fusion; ana-

lyze the tradeoffs between the number of features used for classiﬁcation and the performance; statistical

evidence of the robustness of fusion based systems against high effort mimicry attacks; examine how the

proposed biometric can be used to authenticate users on smartphone paired with a smartwatch.

Authenticating users through their arm movement patterns

A:23

8. ACKNOWLEDGEMENTS

We would like to thank all volunteers for participating in our data collection and anonymous reviewers
for their insightful feedback. All ﬁndings, conclusions and recommendations expressed in this paper are
those of the authors and do not necessarily represent the views of any organization.

REFERENCES

A, A. R. AND B, R. G. 2005. Feature level fusion using hand and face biometrics. In Proceedings of SPIE Conference on Biometric

Technology for Human Identiﬁcation II. 196–204.

AHA, D. AND KIBLER, D. 1991. Instance-based learning algorithms. Machine Learning 6, 37–66.

AHMED, A. A. E. S. 2008. Security monitoring through human computer interaction devices. Ph.D. thesis, Victoria, B.C., Canada,

Canada. AAINR60664.

BREIMAN, L. 2001. Random forests. Machine Learning 45, 1, 5–32.

BUCHOUX, A. AND CLARKE, N. L. 2008. Deployment of keystroke analysis on a smartphone. In Australian Information Security

Management Conference. 48.

CHARARA, S. 2015. Samsung’s bet on biometrics for smartwatch payments. http://www.ibtimes.co.uk/apple-iphone-5s-touch-id-fingerprint-sca

[Online; Last accessed in 18 July, 2015].

CHARLTON,

A.

2013.

iphone

5s

ﬁngerprint

security

bypassed

by

german

computer

club.

http://www.ibtimes.co.uk/apple-iphone-5s-touch-id-fingerprint-scanner-508196.

[Online; Last accessed 18 July,

2015].

CURTIS.

2014.

Why

smartwatches

will

replace

smartphones:

biometrics

and

convenience.

http://www.ibtimes.co.uk/apple-iphone-5s-touch-id-fingerprint-scanner-508196.

[Online; Last accessed in 18

July, 2015].

DASS, S. C., N, K., AND JAIN, A. K. 2005. A principled approach to score level fusion in multimodal biometric systems. In

Proceedings of AVBPA. 1049–1058.

DERAWI, M., BOURS, P., AND HOLIEN, K. 2010. Improved cycle detection for accelerometer based gait authentication. In IIH-MSP,

2010 Sixth International Conference on. 312–317.

DERAWI, M. O., NICKEL, C., BOURS, P., AND BUSCH, C. 2010. Unobtrusive user-authentication on mobile phones using biometric

gait recognition. [Online; Last accessed 04 August, 2015].

DERNBACH, S., DAS, B., KRISHNAN, N. C., THOMAS, B., AND COOK, D. 2012. Simple and complex activity recognition through

smart phones. In Intelligent Environments (IE), 2012 8th International Conference on. 214–221.

FRACCARO, P., COYLE, L., DOYLE, J., AND O’SULLIVAN, D. 2014. Real-world gyroscope-based gait event detection and gait feature

extraction.

FRANK, M., BIEDERT, R., MA, E., MARTINOVIC, I., AND SONG, D. 2013. Touchalytics: On the applicability of touchscreen input as

a behavioral biometric for continuous authentication. Information Forensics and Security, IEEE Transactions on 8, 1, 136–148.

GAFUROV, D., SNEKKENES, E., AND BOURS, P. 2007. Spoof attacks on gait authentication system. Information Forensics and

Security, IEEE Transactions on 2, 3, 491–502.

GREYB.

2015.

Samsungs

smartwatch:

Your

heartbeats

will

unlock

your

next

smartphone.

http://www.whatafuture.com/2015/03/17/heartbeat-authentication-in-samsung-smartwatch/#sthash.gWOBeptQ.AbPqCxwm.dpbs .

[Online; Last accessed in 18 July, 2015].

A:24

R. Kumar et al.

GUIRY, J. J., VAN DE VEN, P., AND NELSON, J. 2014. Multi-sensor fusion for enhanced contextual awareness of everyday activities

with ubiquitous devices. Sensors 14, 3, 5687.

HALL, M. AND HOLMES, G. 2003. Benchmarking attribute selection techniques for discrete class data mining. Knowledge and

Data Engineering, IEEE Transactions on 15, 6, 1437–1447.

HALL, M. A. 1998. Correlation-based feature subset selection for machine learning. Ph.D. thesis, University of Waikato, Hamilton,

New Zealand.

HASSOUN, M. H. 1995. Fundamentals of Artiﬁcial Neural Networks 1st Ed. MIT Press, Cambridge, MA, USA.

HE, M., HORNG, S.-J., FAN, P., RUN, R.-S., CHEN, R.-J., LAI, J.-L., KHAN, M. K., AND SENTOSA, K. O. 2010. Performance

evaluation of score level fusion in multimodal biometric systems. Pattern Recogn. 43, 5, 1789–1800.

IOT. 2016. Internet of things. https://en.wikipedia.org/wiki/Internet_of_Things . [Online; Last accessed 9 February, 2016].

JAIN, A. AND ROSS, A. 2002. Learning user-speciﬁc parameters in a multibiometric system. In Image Processing. 2002. Proceed-

ings. 2002 International Conference on. Vol. 1. I–57–I–60 vol.1.

JAIN, A. K., ROSS, A., AND PRABHAKAR, S. 2004. An introduction to biometric recognition. IEEE Trans. on Circuits and Systems

for Video Technology 14, 4–20.

JOHNSTON, A. AND WEISS, G. 2015. Smartwatch-based biometric gait recognition. In Biometrics Theory, Applications and Systems

(BTAS), 2015 IEEE 7th International Conference on. 1–6.

JUNSHUANG YANG, YANYAN LI, M. X. 2015. Motionauth: Motion-based authentication for wrist worn smart devices. In Workshop

on Sensing Systems and Applications Using Wrist Worn Smart Devices. 1049–1058.

KUMAR, R., PHOHA, V., AND JAIN, A. 2015. Treadmill assisted imitation attack on gait-based authentication systems. In Biomet-

rics: Theory, Applications and Systems (BTAS), 2015 IEEE Seventh International Conference on. 1–7.

KWAPISZ, J., WEISS, G., AND MOORE, S. 2010. Cell phone-based biometric identiﬁcation. In Biometrics: Theory Applications and

Systems (BTAS), 2010 Fourth IEEE International Conference on. 1–7.

KWAPISZ, J. R., WEISS, G. M., AND MOORE, S. A. 2011. Activity recognition using cell phone accelerometers. SIGKDD Explor.

Newsl. 12, 2, 74–82.

MATLAB. 2013a. version 8.1.0.604 (R2013a). The MathWorks Inc., Natick, Massachusetts.

MONROE, D. Biometrics metric report. http://www.usma.edu/ietd/docs/BiometricsMetricsReport.pdf. [Online; Last accessed

27 November, 2015].

NAGAR, A., NANDAKUMAR, K., AND JAIN, A. 2012. Multibiometric cryptosystems based on feature-level fusion. Information

Forensics and Security, IEEE Transactions on 7, 1, 255–268.

NICKEL, C., WIRTL, T., AND BUSCH, C. 2012. Authentication of smartphone users based on the way they walk using k-nn algo-

rithm. In Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), 2012 Eighth International Conference

on. 16–20.

NIINUMA, K., PARK, U., AND JAIN, A. 2010. Soft biometric traits for continuous user authentication. Information Forensics and

Security, IEEE Transactions on 5, 4, 771–780.

PORZI, L., MESSELODI, S., MODENA, C. M., AND RICCI, E. 2013. A smart watch-based gesture recognition system for assisting

people with visual impairments. In Proceedings of the 3rd ACM International Workshop on Interactive Multimedia on Mobile

&#38; Portable Devices. IMMPD ’13. ACM, New York, NY, USA, 19–24.

PRIMO, A., PHOHA, V. V., KUMAR, R., AND SERWADDA, A. 2014. Context-aware active authentication using smartphone ac-

celerometer measurements. The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops.

Authenticating users through their arm movement patterns

A:25

RATHA, N. K., CONNELL, J. H., AND BOLLE, R. M. 2001. An analysis of minutiae matching strength. In Proceedings of the Third

International Conference on Audio- and Video-Based Biometric Person Authentication. AVBPA ’01. Springer-Verlag, London,

UK, UK, 223–228.

RATTANI, A., POH, N., AND ROSS, A. 2012. Analysis of user-speciﬁc score characteristics for spoof biometric attacks. In Computer

Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on. 124–129.

SARKISYAN, A., DEBBINY, R., AND NAHAPETIAN, A. 2015. Wristsnoop: Smartphone pins prediction using smartwatch motion

sensors. In Information Forensics and Security (WIFS), 2015 IEEE International Workshop on. 1–6.

SERWADDA, A., PHOHA, V., AND WANG, Z. 2013. Which veriﬁers work?: A benchmark evaluation of touch-based authentication

algorithms. In Biometrics: Theory, Applications and Systems (BTAS), 2013 IEEE Sixth International Conference on. 1–8.

SERWADDA, A. AND PHOHA, V. V. 2013. When kids’ toys breach mobile phone security. In Proceedings of the 2013 ACM SIGSAC

Conference on Computer &#38; Communications Security. CCS ’13. ACM, New York, NY, USA, 599–610.

SHUKLA, D., KUMAR, R., SERWADDA, A., AND PHOHA, V. V. 2014. Beware, your hands reveal your secrets! In Proceedings of the

2014 ACM SIGSAC Conference on Computer and Communications Security. CCS ’14. ACM, New York, NY, USA, 904–917.

TRAORE, I., TRAORE, I., AND AHMED, A. A. E. 2011. Continuous Authentication Using Biometrics: Data, Models, and Metrics 1st

Ed. IGI Global, Hershey, PA, USA.

WITTEN, I. H. AND FRANK, E. 2005. Data Mining: Practical Machine Learning Tools and Techniques, Second Edition (Morgan

Kaufmann Series in Data Management Systems). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.

YAN, Z., SUBBARAJU, V., CHAKRABORTY, D., MISRA, A., AND ABERER, K. 2012. Energy-efﬁcient continuous activity recognition

on mobile phones: An activity-adaptive approach. In Wearable Computers (ISWC), 2012 16th International Symposium on.

17–24.

ZHONG, Y. AND DENG, Y. 2014. Sensor orientation invariant mobile gait biometrics. In Biometrics (IJCB), 2014 IEEE International

Joint Conference on. 1–8.

