6
1
0
2

 
r
a

 

M
3
1

 
 
]

V
C
.
s
c
[
 
 

1
v
2
4
0
4
0

.

3
0
6
1
:
v
i
X
r
a

DeepInteractiveObjectSelectionNingXuUniversityofIllinoisatUrbana-Champaignningxu2@illinois.eduBrianPriceAdobeResearchbprice@adobe.comScottCohenAdobeResearchscohen@adobe.comJimeiYangAdobeResearchjimyang@adobe.comThomasHuangUniversityofIllinoisatUrbana-Champaignt-huang1@illinois.eduAbstractInteractiveobjectselectionisaveryimportantresearchproblemandhasmanyapplications.Previousalgorithmsrequiresubstantialuserinteractionstoestimatethefore-groundandbackgrounddistributions.Inthispaper,wepresentanoveldeep-learning-basedalgorithmwhichhasamuchbetterunderstandingofobjectnessandthuscanre-duceuserinteractionstojustafewclicks.Ouralgorithmtransformsuser-providedpositiveandnegativeclicksintotwoEuclideandistancemapswhicharethenconcatenatedwiththeRGBchannelsofimagestocompose(image,userinteractions)pairs.Wegeneratemanyofsuchpairsbycom-biningseveralrandomsamplingstrategiestomodelusers’clickpatternsandusethemtoﬁnetunedeepFullyConvo-lutionalNetworks(FCNs).FinallytheoutputprobabilitymapsofourFCN-8smodelisintegratedwithgraphcutop-timizationtoreﬁnetheboundarysegments.OurmodelistrainedonthePASCALsegmentationdatasetandevaluatedonotherdatasetswithdifferentobjectclasses.Experimen-talresultsonbothseenandunseenobjectsclearlydemon-stratethatouralgorithmhasagoodgeneralizationabilityandissuperiortoallexistinginteractiveobjectselectionapproaches.1.IntroductionInteractiveobjectselection(alsoknownasinteractivesegmentation)hasbecomeaverypopularresearchareaoverthepastyears.Itenablesuserstoselectobjectsofinterestaccuratelybyinteractivelyprovidinginputssuchasstrokesandboundingboxes.Theselectedresultsareusefulforvar-iousapplicationssuchaslocalizededitingandimage/videocomposition.Therearemanyalgorithmsproposedtosolvethisprob-lem.OneofthemostfamousalgorithmsisproposedbyBoykovandJolly[2]wheretheyformulateinteractiveseg-mentationasthegraphcutoptimizationandsolveitviamax-ﬂow/min-cutenergyminimization.Rotheretal.[19]extendgraphcutbyusingamorepowerful,iterativeversionofoptimization.BaiandSapiro[1]presentanewalgorithmthatcomputesweightedgeodesicdistancestotheuser-providedscribbles.Grady[8]usesthegraphtheorytoesti-matetheprobabilitiesofrandomwalksfromunlabeledpix-elstolabeledpixels.Inordertogetaccuratesegmentation,allthesealgorithmsrequiresubstantialuserinteractionstohaveagoodestimationoftheforeground/backgrounddis-tributions.Incontrast,ourapproachsimpliﬁesuserinterac-tionstoafewclicks,withoneortwoclicksusuallygivingreasonablygoodresults.Theadvantageofourapproachovertheothersisthecapabilitytounderstandobjectnessandsemanticsbyleveragingdeeplearningtechniques.Toourbestknowledge,thisistheﬁrstworkthatsolvesinter-activesegmentationintheframeworkofdeeplearning.Ourapproachisinspiredbyrecentsuccessesofdeepfullyconvolutionalneuralnetworks(FCNs)onthesemanticsegmentationproblem[15,26,3,14,12].Longetal.[15]adaptpopulardeepclassiﬁcationnetworksintoFCNsforsemanticsegmentationandimprovethearchitecturewithmulti-resolutionlayercombinations.Builtuponthis,Chenetal.[3]combinetheoutputsofFCNswithConditionalRandomField(CRF)whileZhengetal.[26]formulatemean-ﬁeldapproximateinferenceasRecurrentNeuralNet-work(RNN)andplugitontopofFCNstogetﬁnerresults.Aseeminglyplausibletransformationofthoseap-proachestointeractivesegmentationisthatweﬁrstperformsemanticsegmentationonthewholeimageandthenselecttheconnectedcomponentswhichcontainuser-providedse-lections.However,thereexistsatleastthreeproblemswiththisapproach.First,itisnotalwaysclearhowtoresponsetouseinputs.Forexample,iftheuserplacesaforegroundclickandbackgroundclickinsidethesameclasslabel,thisapproachcannotresponsetothat.Second,currentseman-ticsegmentationmethodsdonotsupportinstance-levelseg-1mentationwhilethatisoftentheuser’sdesire.Lastbutnottheleast,currentsemanticsegmentationapproachesdonotgeneralizetounseenobjects.Thismeansthatwehavetotrainamodelforeverypossibleobjectintheworld,whichisobviouslyimpractical.Inthispaper,wepresentanovelalgorithmforinterac-tiveobjectselection(Fig.1).Toselectanobjectinanimage,usersprovidepositiveandnegativeclickswhicharethentransformedintoseparateEuclideandistancemapsandconcatenatedwiththeRGBchannelsoftheimagetocom-posea(image,userinteractions)pair.FCNmodelsareﬁnetunedonmanyofthesepairsgeneratedbyrandomsam-pling.Moreover,graphcutoptimizationiscombinedwiththeoutputsofourFCNmodelstogetsatisfactoryboundarylocalization.Thekeycontributionsofthispaperaresum-marizedasfollows:•Weproposeaneffectivetransformationtoincorporateuserinteractionwithcurrentdeeplearningtechniques.•Weproposeseveralsamplingstrategieswhichcanrep-resentusers’clickbehaviorswellandobtainthere-quiredtrainingdatainexpensively.•Ourinteractivesegmentationsystemisrealtimegivenahigh-endgraphicsprocessingunits(GPU).Therestofthepaperisorganizedasfollows.Section2givesabriefreviewofrelatedworks.Theproposedalgo-rithmiselaboratedinSection3.ExperimentalresultsarepresentedinSection4andﬁnallyweconcludethepaperinSection5.2.RelatedworksInteractivesegmentationhasbeenstudiedformanyyears.Therearemanyinteractiveapproaches,suchascontour-basedmethods[17,10]andboundingboxmethods[19].Stroke-basedmethodsarepopular,anduseanumberofunderlyingalgorithms,includingnormalizedcuts[20],graphcut[2,11,23],geodesics[1,4],thecombinationofgraphcutandgeodesics[18,9]andrandomwalks[8].However,allthesepreviousalgorithmsestimatethefore-ground/backgrounddistributionsfromlow-levelfeatures.Unfortunately,low-levelfeaturesareinsufﬁcientatdistin-guishingtheforegroundandbackgroundinmanycases,suchasinimageswithsimilarforegroundandbackgroundappearances,complextexturesandappearances,anddifﬁ-cultlightingconditions.Insuchcases,thesemethodsstrug-gleandrequireexcessiveuserinteractiontoachievedesir-ableresults.Incontrast,ourFCNmodelistrainedend-to-endandhasahighlevelunderstandingofobjectnessandsemantics,thereforesimplifyinguserinteractionstojustafewclicks.Thetaskofsemanticsegmentationiscloselyrelatedtointeractivesegmentation.Manyalgorithmshavebeenpro-posedinthepast[25,21,22].Duetothegreatimprove-mentsonimageclassiﬁcationanddetectionbydeepneu-ralnetworksespeciallytheconvolutionalneuralnetworks(CNNs),manyresearchershaverecentlyappliedCNNstotheproblemofsemanticsegmentation.Farabetetal.[6]useamulti-scaleconvolutionalnetworktrainedfromrawpixelsforscenelabeling.Girshicketal.[7]applyCNNstobottom-upregionsproposalsforobjectdetectionandsegmentationandimproveoverpreviouslow-level-feature-basedapproachesgreatly.Longetal.[15]adapthigh-capacityCNNstoFCNswhichcanbetrainedend-to-end,pixels-to-pixelsandleverageaskiparchitecturewhichcom-binesmodelresponsesatmultiplelayerstogetﬁnerre-sults.However,asexplainedintheintroduction,seman-ticsegmentationisnotdirectableforinteractivesegmen-tation.OurmodelisbasedonFCNsbutdifferentfrom[15]inmainlytwopoints.1)Ourmodelistrainedonran-domlygenerated(image,userinteractions)pairswhicharetheconcatenationsofRGBchannelsandtransformedEu-clideandistancemaps.2)Ourmodelhasonlytwolabels–“object”and“background”.Otherworkhaslookedatimprovingtheboundarylocal-izationofCNNsemanticsegmentationapproaches.Chenetal.[3]combinetheoutputsofFCNswithfullyconnectedCRF.Zhengetal.[26]formulatemean-ﬁeldapproximateinferenceasRNNsandtrainwithFCNsend-to-end.Theyimprovethemeanintersectionoverunion(IU)accuracyofFCNsfrom62.2%to71.6%and72%respectively.Al-thoughourFCNmodelsarequitegeneraltobecombinedwiththeirapproaches,theirsegmentationresultsarefarlessacceptablefortheinteractivesegmentationtask.Therefore,weproposeasimpleyeteffectiveapproachthatcombinegraphcutoptimizationwithourFCNoutputmaps,whichenablesouralgorithmachievehighIUaccuracywithevenasingleclick.3.TheproposedalgorithmWeproposeadeep-learning-basedalgorithmforinterac-tivesegmentation.UserinteractionsareﬁrsttransformedintoEuclideandistancemapsandthenconcatenatedwithimages’RGBchannelstoﬁnetuneFCNmodels.Afterthemodelsaretrained,graphcutoptimizationiscombinedwiththeprobabilitymapsofFCN-8stogettheﬁnalsegmenta-tionresults.Figure1illustratestheframeworkofhowwetrainourFCNmodels.3.1.TransforminguserinteractionsInourapproach,ausercanprovidepositiveandnegativeclicks(orstrokes)sequentiallyinordertosegmentobjectsofinterest.Aclicklabelsaparticularlocationasbeingei-ther“object”or“background”.Asequenceofuserinter-FCNFigure1:TheframeworkoflearningourFCNmodels.Givenaninputimageanduserinteractions,ouralgorithmﬁrsttransformspositiveandnegativeclicks(denotedasgreendotsandredcrossesrespectively)intotwoseparatechannels,whicharethenconcatenated(denotedas⊕)withtheimage’sRGBchannelstocomposeaninputpairtotheFCNmodels.Thecorrespondingoutputisthegroundtruthmaskoftheselectedobject.actionsSincludesapositiveclicksetS1whichcontainsalluser-providedpositiveclicksandanegativeclicksetS0whichcontainsalluser-providednegativeclicks.Oural-gorithmusesaEuclideandistancetransformationtotrans-formS1andS0toseparatechannelsU1andU0respec-tively.Eachchannelisa2Dmatrixwiththesameheightandwidthastheoriginalimage.Tocalculatethepixelvalueutijatthelocation(i,j),t∈{0,1},letusﬁrstde-ﬁneanoperatorfsuchthatgivenasetofpointspij∈Awhere(i,j)isthepointlocation,thenforanypointpmn,f(pmn|A)=min∀pij∈Ap(m−i)2+(n−j)2.Inotherwords,theoperatorfcalculatestheminimumEuclideandistancebetweenapointandasetofpoints.Then,utij=f(pij|St),t∈{0,1}(1)Fortheefﬁciencyofdatastorage,wetruncateutijto255.ItshouldbenotedthatitispossiblethatS0isaemptysetsinceinmanyscenariosouralgorithmhasperfectsegmen-tationresultswithevenonesinglepositiveclick.Inthiscase,allu0ijaresetto255.ThenweconcatenatetheRGBchannelsoftheimagewithU1,U0tocomposea(image,userinteraction)pair.3.2.SimulatinguserinteractionsItshouldbenotedthatdifferentuserstendtohavedif-ferentinteractionsequencesforselectingthesameobject.ThereforeourFCNmodelsneedalotofsuchtrainingpairstolearnthis.However,itistooexpensivetocollectmanyinteractionsequencesfromrealusers.Wethususerandomsamplingtoautomaticallygeneratethosepairs.LetObethesetofgroundtruthpixelsoftheobjectandletusdeﬁneanewsetG={pij|pij∈Oorf(pij|O)≥d}.LetGcdenotethecomplementarysetofG.ItiseasytoseethatthepixelsinGchavetwoproperties:1)theyarebackgroundpixelsand2)theyarewithinacertaindistancerangetotheobject.Tosamplepositiveclicks,werandomlyselectnpixelsinOwheren∈[1,Npos].ThepixelsinOareac-tuallyﬁlteredinthewaythat1)anytwopixelsareatleast(a)Strategy1(b)Strategy2(c)Strategy3Figure2:Avisualexampleofthethreesamplingstrategiesfornegativeclicks.Thepersonistheforegroundobject.dsteppixelsawayfromeachotherand2)anypixelisatleastdmarginpixelsawayfromtheobjectboundaries.Tosamplenegativeclicks,wecombineseveralsamplingstrategiestomodelthecomplexityofusers’clickpatterns.•Strategy1:nnegativeclicksarerandomlysampledinthesetGc,wheren∈[0,Nneg1].GcisﬁlteredinthesamewayasO.•Strategy2:ninegativeclicksarerandomlysampledoneachnegativeobjectOiinthesameimage,whereni∈[0,Nneg2].EachOiisﬁlteredinthesamewayasO.•Strategy3:Nneg3negativeclicksaresampledtocovertheoutsideobjectboundariesasmuchaspossible.Indetail,theﬁrstnegativeclickisrandomlysampledinGc.Thenthefollowingclicksareobtainedsequentiallybypnext=argmaxpij∈Gcf(pij|S0∪G)(2)whereS0includesallpreviouslysamplednegativeclicks.Figure2presentsanexampleofthethreestrategies.ThesamplednegativeclicksfromStrategy1or2alonedonotalwaysfollowusers’typicalclickpatterns,thereforemak-ingthemharderforourmodelstolearn.Thesampledneg-ativeclicksfromStrategy3surroundtheobjectevenly,(a)(b)(c)Figure3:AnexampleofSection3.4.(a)Antestingimageanduserinteractions.(b)TheoutputprobabilitymapfromFCN-8s.(c)Theresultaftergraphcut.whichhasastrongpatternbutiseasytolearn.Weﬁndthatusingallthreestategiesprovidesbetterresultsthanrelyingonanyonestrategy,thereforewecombinethemtogether.Speciﬁcally,foreachobjectinanimagewerandomlysam-pleNpairstrainingpairsof(image,userinteractions).Eachpairisgeneratedbyoneofthesamplingstrategieswithanequalprobability.3.3.FinetuningFCNmodelsWeleverageFCNstolearntheinteractivesegmentationtask.Thetrainingsamplestoourmodelsare(image,userinteractions)pairsandthelabelsarethebinarymasksofcorrespondingobjects.Weﬁrstﬁnetuneastride-32FCNmodel(FCN-32s)fromthestride-32semanticsegmenta-tionmodelof[15].Forthetwoextrachannelsofﬁltersintheﬁrstconvolutionallayer,weusezeroinitialization.Wealsotriedinitializationwiththemeanvalueofthoseﬁl-terweights,butitshowsnodifference.AfterﬁnetuningFCN-32s,wecontinuetoﬁnetuneastride-16FCN(FCN-16s)fromFCN-32swiththesametrainingdata.Finallyweﬁnetuneastride-8FCN(FCN-8s)modelfromFCN-16s.Assuggestedby[15],trainingﬁner-strideFCNsdoesnotprovidefurtherbeneﬁts,whichwealsoobserved.IttakesapproximatelythreedaystoﬁnetuneFCN-32sandﬁvedaystoﬁnetuneFCN-16sandFCN-8s.Bybalanc-ingthetrade-offsbetweentheperformanceandtime,eachFCNmodelistrainedabout20epochs.FCN-32sconvergesfastintheﬁrsttwoepochswhilealongertrainingtimegivesﬁnersegmentationresults.WealsoﬁndthatFCN-16shasobviousimprovementsoverFCN-32sespeciallyinregionsclosetoobjectboundaries,buttheaccuracyofFCN-16sandFCN-8saresimilar.3.4.GraphcutoptimizationFromtheoutputsatthelastlayerofFCN-8swecanob-tainaprobabilitymapQ,ofwhichtheentryqijindicateshowlikelythepixelpijislabeledas“object”(e.g.Figure3b).Directlythresholdingqijat0.5givesusverycoarsesegmentationmasks,whicharenotusefulforinteractivesegmentation.Instead,weintegrateQintothegraphcutoptimization[2]:E(L)=λ·R(L)+B(L)(3)WhereλisacoefﬁcientthatspeciﬁesarelativeimportancebetweenR(L)andB(L).TheﬁrsttermR(L)=Ppij∈PRpij(Lpij),whereRpij(Lpij)estimatesthepenaltyofassigningpixelpijtolabelLpij.OuralgorithmdeﬁnesRpij(Lpij)=(−log(qij),ifLpij=“object”−log(1−qij),otherwise(4)ThesecondtermB(L)=P{pij,pmn}∈NB{pij,pmn}·δ(Lpij,Lpmn),whereB{pij,pmn}comprisesthepropertiesofobjectboundaries.OuralgorithmdeﬁnesB{pij,pmn}∝exp(−(Ipij−Ipmn)22σ2)·1dist(pij,pmn)(5)OuralgorithmsolvesEquation3viamax-ﬂow/min-cuten-ergyminimization.Figure3cillustratestheresultaftergraphcutoptimization.3.5.EvaluationandcomplexityAusercanprovidepositiveandnegativeclickssequen-tiallytoselectobjectsofinterest.Eachtimeanewclickisadded,ouralgorithmrecomputesthetwodistancemapsU1andU0.Thenthenew(image,userinteractions)pairissenttoourFCN-8smodelandanewprobabilitymapQisobtained.GraphcutusesQtoupdatethesegmentationresultswithoutrecomputingeverythingfromscratch.Tocompareouralgorithmwithotherapproaches,wealsode-signamethodtoautomaticallyaddaclickgiventhecurrentsegmentationmaskandthegroundtruthmask.Themethodplacesaseedatthemislabeledpixelthatisfarthestfromtheboundaryofthecurrentselectionandtheimagebound-aries,mimicingauser’sbehaviorundertheassumptionthattheuserclicksinthemiddleoftheregionofgreatesterror.Givenhigh-endGPUslikeNVIDIATitanX,thecompu-tationofQisveryfastandlessthan100millisecond.GraphcutoptimizationisalsoveryefﬁcientonmodernCPUs.Thereforeouralgorithmsatisﬁesthespeedrequirementfortheinteractivesegmentationtask.4.Experiments4.1.SettingsWeﬁnetuneourFCNmodelsonthePASCALVOC2012segmentationdataset[5]whichhas20distinctob-jectcategories.Weuseits1464trainingimageswhichhaveinstance-levelsegmentationmasksandtheirﬂippedversionstosamplethe(image,userinteractions)pairs.Thechoicesofsomesamplinghyper-parametersare:dissettoClicks02468101214161820IU accuracy00.10.20.30.40.50.60.70.80.91(a)PascalClicks02468101214161820IU accuracy00.10.20.30.40.50.60.70.80.91(b)GrabcutClicks02468101214161820IU accuracy00.10.20.30.40.50.60.70.80.91(c)BerkeleyClicks02468101214161820IU accuracy00.10.20.30.40.50.60.70.80.91(d)MSCOCOseencategoriesClicks02468101214161820IU accuracy00.10.20.30.40.50.60.70.80.91(e)MSCOCOunseencategoriesGraph cut [2]Geodesic matting [1]Random walker [8]Euclidean star convexity [9]Geodesic star convexity [9]Growcut [23]Ours(f)LegendFigure4:ThemeanIUaccuracyvs.thenumberofclicksonthe(a)Pascal(b)Grabcut(c)Berkeley(d)MSCOCOseencategoriesand(e)MSCOCOunseencategoriesdatasets.Thelegendoftheseplotsisshownin(f).be40,Nposissettobe5,Nneg1,Nneg2,Nneg3aresettobe10,5and10respectively.Npairsissettobe15.Thetotalnumberofsampledtrainingpairsisabout80k.200valida-tionimagesarerandomlysampledfromthewholetrainingsettocontrolthelearningofourmodels.Wecompareouralgorithmtoseveralpopularinteractivesegmentationalgorithms[2,1,8,9,23].Sincetheotheral-gorithmscannotestimateforeground/backgrounddistribu-tionswithasingleclick,weenlargeeveryclicktoabigdotwitharadius5forthem.WeusesuchbigdotsforourgraphcutreﬁnementbutonlyusesingleclicksforourFCNmod-els.Toevaluate,werecordtheupdatedIUaccuracyofanobjectgivensequentialclickswhichareautomaticallygen-eratedinthewaydescribedinSection3.5.Themaximumnumberofclicksonasingleobjectislimitedto20.Wealsorecordhowmanyclicksarerequiredtoachieveacer-tainIUaccuracyfortheobject.IftheIUaccuracycannotbeachievedin20clicks,wewillthresholditby20.Finally,weaverageeachmetricoverallobjectsinadataset.4.2.ResultsWeevaluateallthealgorithmsonfourpublicdatasets:PascalVOC2012segmentationvalidationset,Grabcut[19],Berkeley[16]andMSCOCO[13].ThequantitativeresultsofthetwometricsondifferentdatasetsareshowninFigure4andTable1respectively.Pascal:Thevalidationsethas1449imagesandmanyofthemcontainmultipleobjects.FromFigure4awecanseethatouralgorithmisbetterthanalltheotheralgorithms.Sincethevalidationsetcontains20objectcategorieswhichhavebeenseeninourtrainingset,wetestouralgorithmonotherdatasetswithdifferentobjectstoprovethegeneraliza-tioncapabilityofouralgorithmtounseenobjectclasses.GrabcutandBerkeley:Thesetwodatasetsarebench-markdatasetsforinteractivesegmentationalgorithms.OntheGrabcutdataset(Figure4b),ouralgorithmachievesbet-terresultswithafewclicksandhasasimilarIUaccu-racywithGeodesic/Euclideanstarconvexity[9]withmoreclicks.SinceGrabcutonlyhas50imagesandmostim-ageshavedistinctforegroundandbackgrounddistributionswhichcanbehandledwellbylow-level-feature-basedalgo-rithms,ouradvantageoverothermethodsissmallerthanitisonmorechallengingdatasets.OntheBerkeleydataset(Figure4c),ouralgorithmachievesbetterIUaccuracyateverystepandincreasestheIUaccuracymuchfasterthantheothersatthebeginningoftheinteractiveselection.SegmentationmodelsPascal(85%IU)Grabcut(90%IU)Berkeley(90%IU)MSCOCOseencategories(85%IU)MSCOCOunseencategories(85%IU)Graphcut[2]15.0611.1014.3318.6717.80Geodesicmatting[1]14.7512.4415.9617.3214.86Randomwalker[8]11.3712.3014.0213.9111.53Euclideanstartconvexity[9]11.798.5212.1113.9011.63Geodesicstartconvexity[9]11.738.3812.5714.3712.45Growcut[23]14.5616.7418.2517.4017.34Ours6.886.048.658.317.82Table1:ThemeannumberofclicksrequiredtoachieveacertainIUaccuracyondifferentdatasetsbyvariousalgorithms.TheIUaccuracyfordifferentdatasetsisindicatedintheparentheses.Thebestresultsareemphasizedinbold.GraphcutGeodesicmattingRandomwalkerEuclideanstarconvexityGeodesicstarconvexityGrowcutOursGroundtruthGrabcutexampleBerkeleyexamplePascalexampleFigure5:Thesegmentationresultsbydifferentalgorithmsgiventhesameuserinteractionsequences.Eachrowisantestingimagefromonedataset.Eachoftheﬁrstsevencolumnsrepresentthesegmentationresultsbyonealgorithmandtherightmostcolumnshowsthegroundtruths.Ineachﬁgure,greendotsindicatepositiveclicks.Backgroundregionsarefadedtoblackandobjectboundariesareoutlinedincyan.MSCOCO:MSCOCOisalarge-scalesegmentationdatasetandhas80objectcategories.60ofthemaredistinctfromthePascaldataset.Werandomlysample10imagespercategoriesandtestallthealgorithmsonthe20seencat-egoriesand60unseencategoriesseparately.Ouralgorithmstillconsistentlyperformsbetterthantheotheralgorithmsbyalargemargininbothcases.OuralgorithmalsorequirestheleastnumberofclickstoachieveacertainIUaccuracyonallthedatasets.Fig-ure4andTable1clearlydemonstratethat1)ouralgorithmachievesmoreaccurateresultswithlessinteractionthanothermethodsand2)ouralgorithmhasagoodgeneraliza-tionabilitytoallkindsofobjects.Giventhesameuserin-teractionsequences,somesegmentationresultsbydifferentalgorithmsareillustratedinFigure5and9.Inmanyexam-ples,ouralgorithmobtainsverygoodresultsinjustonesin-gleclickwhiletheotherseitheronlysegmentapartoftheobjectorcompletelyfail.ThisisbecauseourFCNmodelshaveahigh-levelunderstandingoftheobjectnessandse-mantics,incontrarytotheotherapproachessimplyrelyingonlow-levelfeatures.WealsoshowafailedsegmentationresultbyouralgorithminFigure9.ThefailureisbecauseFCNscannotcapturethinstructuresandﬁnedetailsverywell.ThereforetheoutputprobabilitiesfromourFCN-8sFCNCRF-RNNOursGroundtruthFigure6:Thesegmentationresultsbythesemanticsegmen-tationalgorithms(FCNandCRF-RNN)andouralgorithm.Theﬁrstrowisatestingimagefromseencategories(i.e.“person”).Thesecondrowisatestingimagefromunseencategories(i.e.“banana”).SegmentationmodelsMSCOCOseencategoriesMSCOCOunseencategoriesFCN[15]42.37%16.14%CRFRNN[26]47.01%13.28%Ours48.35%42.94%Table2:ThemeanIUaccuracywithasinglepositiveclickontheMSCOCOseenandunseencategories.Thebestresultsareemphasizedinbold.modelarenotaccurateenoughinthoseareas,whichaffectstheperformanceofgraphcutinproducingourﬁnalresult.4.3.Comparisonstosemanticsegmentationap-proachesSinceallexistinginteractivesegmentationalgorithmsareonlybasedonlow-levelfeatures,weshouldalsocompareouralgorithmtosomemodelsthatunderstandhigh-levelse-mantics,suchasFCNs[15]andCRF-RNN[26].However,theyneithersupportinstance-levelsegmentationnorcanre-spondtousers’interactions.Tomakethemcomparable,wedesignasimplestrategysuchthattheconnectedcomponentofagivenlabelthatcontainstheuserclickisselectedasforegroundandtheotherareasaretreatedasbackground.Itisnotstraightforwardhowtorespondtonegativeclicks,thereforeweonlycompareresultsbyasinglepositiveclick.ThevisualcomparisonresultsareshowninFigure6.Intheﬁrstexample,since“person”isaknowncategorytoFCNandCRF-RNN,theyareabletosegmentalltheper-sonsintheimage.Buttheycannotsegmentthemaninthemiddlewhooverlapswithotherpersons.Inthesecondex-ample,“banana”isanewcategorytoFCNandCRF-RNN.Thereforetheydon’trecognizeitatall.Table2presentsthemeanIUaccuracywithasinglepositiveclickontheMSCOCOdataset,whichdemonstratesthelimitationsofFigure7:ThesegmentationresultsofclothingpartsbyouralgorithmontheFashionistadataset.Theclothingpartsfromtheleftimagetotherightimageare“shirt”,“skirt”and“jacket”.semanticsegmentationapproachesdirectlyappliedtointer-activesegmentation.Forseencategories,sincemanyoftheclassinstancesarenon-overlapping,weonlyhaveamodestimprovement.However,rememberthatouralgorithmwasgivenonlyoneclick,andwithmoreclickswecangreatlyimproveourresults.Forunseenclasses,ouralgorithmper-formssigniﬁcantlybetter,provingbothourabilitytogener-alizetonewclassesandtheeffectivenessofouralgorithmincombininguserinteractionswithdeeplearningtechniques.4.4.SegmentingobjectpartsPreviousresultsdemonstratethatouralgorithmperformsverywellongeneralobjects.Moreover,althoughourFCNmodelsareonlytrainedonwholeobjects,ouralgorithmcanstillselecttheirsubparts.InFigure7weshowsomesegmentationresultsofclothingpartsontheFashionistadataset[24].Thisdemonstratestheﬂexibilityofouralgo-rithmandtheeffectivenessofourlearningframeworkthatenablesourmodelstounderstandusers’intentionswell.Inaddition,comparedwiththeotherinteractivesegmentationapproaches,thereisnodoubtthattheyneedmanyuserin-teractionstoachievetheresults.ComparedwithautomaticsemanticsegmentationmethodslikeFCNs,theyaretrainedtosegmententirepeopleandthuscannotgetthesubparts.Thisagainshowstheadvantagesofouralgorithm.4.5.ReﬁnementbyGraphCutWeillustratethedifferencesofsegmentationresultsbe-foreandafterourgraphcutreﬁnementinFigure8.TheﬁrstrowshowstheoutputprobabilitymapsofourFCN-8smodelthresholdedat0.5.Wecanseeourmodelrespondscorrectlytotheuserinteractionsandselectsmostpartsofthebus.Buttheresultsalongobjectboundariesarenotveryaccurate.Thereforeouralgorithmleveragesgraphcuttore-ﬁnetheresults.Thesecondrowshowstheﬁnalresultsofouralgorithm.Clearlytheresultsaremoresatisfactoryandhavebetterboundarylocalization.1click2clicks3clicksThresholdedGraphCutFigure8:Thesequentialsegmentationresultsbeforeandaf-terourgraphcutreﬁnement.TheﬁrstrowshowstheresultsbythresholdingtheoutputprobabilitymapsofourFCN-8smodelwithoutusinggraphcut.Thesecondrowshowsourﬁnalresultsaftergraphcut.5.ConclusionTheproposedalgorithmistheﬁrstworkthatsolvestheinteractivesegmentationproblembycombininguserinter-actionswithcurrentdeeplearningmodels.OuralgorithmtransformsuserinteractionstoEuclideandistancemapsandtrainsFCNmodelstorecognize“object”and“background”basedonmanysynthesizedtrainingsamples.OuralgorithmalsocombinesgraphcutoptimizationwiththeoutputoftheFCN-8smodeltoreﬁnethesegmentationresultsalongob-jectboundaries.Experimentalresultsclearlydemonstratethesuperiorityoftheproposeddeepalgorithmoverexistinginteractivemethodsusinghanddesigned,lowlevelfeatures.Ourmethodcanachievehighqualitysegmentationswithasmallamountofusereffort,oftenjustafewclicks.References[1]X.BaiandG.Sapiro.Geodesicmatting:Aframeworkforfastinteractiveimageandvideosegmentationandmatting.InternationalJournalofComputerVision,82(2):113–132,2009.1,2,4,6[2]Y.Y.BoykovandM.-P.Jolly.Interactivegraphcutsforop-timalboundary&regionsegmentationofobjectsinndim-ages.InComputerVision,2001.ICCV2001.Proceedings.EighthIEEEInternationalConferenceon,volume1,pages105–112.IEEE,2001.1,2,4,6[3]L.-C.Chen,G.Papandreou,I.Kokkinos,K.Murphy,andA.L.Yuille.Semanticimagesegmentationwithdeepcon-volutionalnetsandfullyconnectedcrfs.arXivpreprintarXiv:1412.7062,2014.1,2[4]A.Criminisi,T.Sharp,andA.Blake.Geos:Geodesicimagesegmentation.InComputerVision–ECCV2008,pages99–112.Springer,2008.2[5]M.Everingham,L.VanGool,C.K.I.Williams,J.Winn,andA.Zisserman.Thepascalvisualobjectclasses(voc)chal-lenge.InternationalJournalofComputerVision,88(2):303–338,June2010.4[6]C.Farabet,C.Couprie,L.Najman,andY.LeCun.Learninghierarchicalfeaturesforscenelabeling.PatternAnalysisandMachineIntelligence,IEEETransactionson,35(8):1915–1929,2013.2[7]R.Girshick,J.Donahue,T.Darrell,andJ.Malik.Richfea-turehierarchiesforaccurateobjectdetectionandsemanticsegmentation.InComputerVisionandPatternRecognition(CVPR),2014IEEEConferenceon,pages580–587.IEEE,2014.2[8]L.Grady.Randomwalksforimagesegmentation.PatternAnalysisandMachineIntelligence,IEEETransactionson,28(11):1768–1783,2006.1,2,4,6[9]V.Gulshan,C.Rother,A.Criminisi,A.Blake,andA.Zisser-man.Geodesicstarconvexityforinteractiveimagesegmen-tation.InComputerVisionandPatternRecognition(CVPR),2010IEEEConferenceon,pages3129–3136.IEEE,2010.2,4,5,6[10]M.Kass,A.Witkin,andD.Terzopoulos.Snakes:Activecontourmodels.Internationaljournalofcomputervision,1(4):321–331,1988.2[11]Y.Li,J.Sun,C.-K.Tang,andH.-Y.Shum.Lazysnapping.InACMTransactionsonGraphics(ToG),volume23,pages303–308.ACM,2004.2[12]G.Lin,C.Shen,I.Reid,etal.Efﬁcientpiecewisetrainingofdeepstructuredmodelsforsemanticsegmentation.arXivpreprintarXiv:1504.01013,2015.1[13]T.-Y.Lin,M.Maire,S.Belongie,J.Hays,P.Perona,D.Ra-manan,P.Doll´ar,andC.L.Zitnick.Microsoftcoco:Com-monobjectsincontext.InComputerVision–ECCV2014,pages740–755.Springer,2014.5[14]Z.Liu,X.Li,P.Luo,C.C.Loy,andX.Tang.Semanticim-agesegmentationviadeepparsingnetwork.arXivpreprintarXiv:1509.02634,2015.1[15]J.Long,E.Shelhamer,andT.Darrell.Fullyconvolu-tionalnetworksforsemanticsegmentation.arXivpreprintarXiv:1411.4038,2014.1,2,4,6,7[16]K.McGuinnessandN.E.O?connor.Acomparativeevalua-tionofinteractivesegmentationalgorithms.PatternRecog-nition,43(2):434–444,2010.5[17]E.N.MortensenandW.A.Barrett.Intelligentscissorsforimagecomposition.InProceedingsofthe22ndannualcon-ferenceonComputergraphicsandinteractivetechniques,pages191–198.ACM,1995.2[18]B.L.Price,B.Morse,andS.Cohen.Geodesicgraphcutforinteractiveimagesegmentation.InComputerVisionandPat-ternRecognition(CVPR),2010IEEEConferenceon,pages3161–3168.IEEE,2010.2[19]C.Rother,V.Kolmogorov,andA.Blake.Grabcut:Interac-tiveforegroundextractionusingiteratedgraphcuts.ACMTransactionsonGraphics(TOG),23(3):309–314,2004.1,2,5[20]J.ShiandJ.Malik.Normalizedcutsandimagesegmen-tation.PatternAnalysisandMachineIntelligence,IEEETransactionson,22(8):888–905,2000.2[21]J.TigheandS.Lazebnik.Superparsing:scalablenonpara-metricimageparsingwithsuperpixels.InComputerVision–ECCV2010,pages352–365.Springer,2010.2GraphcutGeodesicmattingRandomwalkerEuclideanstarconvexityGeodesicstarconvexityGrowcutOursGroundtruthSeencategoriesUnseencategoriesFailurecaseFigure9:ThesegmentationresultsbydifferentalgorithmsgiventhesameuserinteractionsequencesontheMSCOCOdataset.Theﬁrsttothirdrowsaretestingimagesfromseencategories(i.e.“cow”,“dog”,“motorcycle”).Theforthtosixthrowsaretestingimagesfromunseencategories(i.e.“elephant”,“apple”,“teddybear”).Thelastrowisafailureexample(i.e.“bicycle”)byouralgorithm.Eachoftheﬁrstsevencolumnsrepresentthesegmentationresultsbyonealgorithmandtherightmostcolumnshowsthegroundtruths.Ineachﬁgure,greendotsindicatepositiveclicksandredcrossesindicatenegativeclicks.Backgroundregionsarefadedtoblackandobjectboundariesareoutlinedincyan.[22]J.TigheandS.Lazebnik.Findingthings:Imageparsingwithregionsandper-exemplardetectors.InComputerVisionandPatternRecognition(CVPR),2013IEEEConferenceon,pages3001–3008.IEEE,2013.2[23]V.VezhnevetsandV.Konouchine.Growcut:Interactivemulti-labelndimagesegmentationbycellularautomata.Inproc.ofGraphicon,pages150–156.Citeseer,2005.2,4,6[24]K.Yamaguchi,M.H.Kiapour,L.E.Ortiz,andT.L.Berg.Parsingclothinginfashionphotographs.InComputerVisionandPatternRecognition(CVPR),2012IEEEConferenceon,pages3570–3577.IEEE,2012.7[25]J.Yang,B.Price,S.Cohen,andM.-H.Yang.Contextdrivensceneparsingwithattentiontorareclasses.InComputerVisionandPatternRecognition(CVPR),2014IEEEConfer-enceon,pages3294–3301.IEEE,2014.2[26]S.Zheng,S.Jayasumana,B.Romera-Paredes,V.Vineet,Z.Su,D.Du,C.Huang,andP.Torr.Conditionalran-domﬁeldsasrecurrentneuralnetworks.arXivpreprintarXiv:1502.03240,2015.1,2,6,7