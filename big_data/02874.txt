6
1
0
2

 
r
a

M
9

 

.

 
 
]
T
S
n
i
f
-
q
[
 
 

1
v
4
7
8
2
0

.

3
0
6
1
:
v
i
X
r
a

Libor at crossroads: stochastic switching

detection using information theory quantiﬁers

Aurelio Fern´andez Bariviera

Department of Business, Universitat Rovira i Virgili, Av. Universitat 1, 43204 Reus, Spain

aurelio.fernandez@urv.net

M. Bel´en Guercio

Instituto de Investigaciones Econ´omicas y Sociales del Sur, UNS-CONICET.

12 de Octubre y San Juan, B8000CTX Bah´ıa Blanca, Argentina.

Universidad Provincial del Sudoeste (UPSO).

Alvarado 328, B8000CJH Bah´ıa Blanca, Argentina

Lisana B. Martinez

Instituto de Investigaciones Econ´omicas y Sociales del Sur, UNS-CONICET.

12 de Octubre y San Juan, B8000CTX Bah´ıa Blanca, Argentina.

Universidad Provincial del Sudoeste (UPSO).

Alvarado 328, B8000CJH Bah´ıa Blanca, Argentina

Osvaldo A. Rosso

Instituto de F´ısica, Universidade Federal de Alagoas (UFAL).

BR 104 Norte km 97, 57072-970 Macei´o, Alagoas, Brazil.

Instituto Tecnol´ogico de Buenos Aires (ITBA),

Av. Eduardo Madero 399, C1106ACD Ciudad Aut´onoma de Buenos Aires, Argentina.

March 10, 2016

Abstract

This paper studies the 28 time series of Libor rates, classiﬁed in seven
maturities and four currencies), during the last 14 years. The analy-
sis was performed using a novel technique in ﬁnancial economics: the
Complexity-Entropy Causality Plane. This planar representation allows
the discrimination of diﬀerent stochastic and chaotic regimes. Using a
temporal analysis based on moving windows, this paper unveals an ab-
normal movement of Libor time series arround the period of the 2007
ﬁnancial crisis. This alteration in the stochastic dynamics of Libor is con-
temporary of what press called “Libor scandal”, i.e.
the manipulation
of interest rates carried out by several prime banks. We argue that our
methodology is suitable as a market watch mechanism, as it makes visible
the temporal redution in informational eﬃciency of the market.

1

PACS: 89.65.Gh Econophysics; 05.45.Tp Time series analysis; 05.45.Df
Fractals
Keywords: Libor, permutation entropy, permutation statistical com-
plexity, information theory

1 Introduction

Interest rates no only reﬂect the time value of money, but also show the tension
in the ﬁnancial market. From the investors’ point of view they provide a basic
information for making decisions. From the government’s point of view they
are key elements for eﬀective monetary policy transmission. Consequently fair
market conditions in the money market arise as an important issue in political
economy.

Libor stands for London Interbank Oﬀered Rate and was created in 1986
by the British Banking Association (BBA). It is one of the most important
economic benchmarks, followed closely by those who make ﬁnancial decisions.
According to BBA deﬁnition, Libor is “...the rate at which an individual Con-
tributor Panel bank could borrow funds, were it to do so by asking for and then
accepting inter-bank oﬀers in reasonable market size, just prior to 11:00 [a.m.]
London time”. In fact, Libor rate does not necessarily reﬂect the cost or price
of actual transactions. It is a daily survey conducted by BBA among 16 prime
banks, about their fair perception on their own borrowing costs. Every London
business day, each bank in the Contributor Panel (selected banks from BBA)
makes a blind submission such that each banker does not know the quotes of
the other bankers. A compiler, Thomson Reuters, then averages the second and
third quartiles. This average is published and represents the Libor rate on a
given day. In other words, Libor is a trimmed average of the expected borrow-
ing rates of leading banks. Libor rates has been published for ten currencies
and ﬁfteen maturities. As it is deﬁned, Libor is expected to be the best self
estimate of leading banks borrowing cost at diﬀerent maturities. It is calculated
for several currencies and maturities, and the panel composition is not the same
for all currencies.

Until 2008, Libor was an uncontested benchmark. However, this situation
changed due to a journal publication. Mollenkamp and Whitehouse [1] pub-
lished a disruptive article in the Wall Street suggesting that the Libor rate
did not reﬂect what it was expected, i.e., the cost of funding of prime banks.
This, and other publications (e.g. [2, 3]) triggered investigations conducted by
the US Department of Justice, UK Financial Services Authority, EU European
Comission and the Swiss Concurrence Commission. In June 2012 Barclays Bank
pleaded guilty and accepted a ﬁne of about $ 480 millions. Other banks were
also ﬁned by improper ﬁnancial conduct. For a full review of the Libor case
from a regulator’ point of view, please see Hou and Skeie [4].

Only a few papers deal with this topic in academic journals. Most of
them uses basic econometric techniques aiming to detect varying diﬀerences
between the Libor rate and another rate, supposedly not subject to manipula-

2

tion. Among these papers we ﬁnd Taylor and Williams [5], who documented the
detachment of the Libor rate from other market rates such as Overnight Inter-
est Swap (OIS), Eﬀective Federal Fund (EFF), Certiﬁcate of Deposits (CDs),
Credit Default Swaps (CDS), and Repo rates. Snider and Youle [6] studied in-
dividual quotes in the Libor bank panel and found that Libor quotes in the US
were not strongly related to other bank borrowing cost proxies. Abrantes-Metz
[7] analyzed the distribution of the Second Digits (SDs) of daily Libor
et al.
rates between 1987 and 2008 and, compared it with uniform and Benford’s dis-
tributions. If we take into account the whole period, the null hypothesis that
the empirical distribution follows either the uniform or Benford’s distribution
cannot be rejected. However, if we take into account only the period after the
subprime crisis, the null hypothesis is rejected. This result calls into question
the “aseptic” setting of Libor. Monticini and Thornton [8] found evidence of
Libor under-reporting after analyzing the spread between 1-month and 3-month
Libor and the rate of Certiﬁcate of Deposits using the Bai and Perron [9] test
for multiple structural breaks.

Bariviera et al.

[10] unveil strange movements in the stochasticity of the
3-month UK Libor, using the Complexity Entropy Causality Plane (CECP).
More recently Bariviera et al. [11] studied the Libor scandal using the Shannon-
Fisher plane, giving a new perspective under the lens of local-global information
quantiﬁes.

Our approach greatly expands [10], studying the behavior of the Libor for
seven maturities and four currencies using the Complexity Entropy Causality
Plane. This study highlights that Libor manipulation was more extensive as
originally thought and was more subtle for some maturities.

The relevance for studying Libor manipulation is that, as stated in the inde-
pendent study conducted by HM Treasury [12], more than $ 300 trilion valued
contracts uses Libor as benchmark. This means that the value of syndicated
loans, ﬂoating rate notes and interest rate swaps were aﬀected. Even more,
many mortgages have their interests linked to Libor evolution. As a consequence
borrowers (mostly families) were directly aﬀected by this unfair behavior.

The rest of the paper is structured as follows. Section 2 describes the
methodology. Section 3 details the data under analysis. Section 4 comments
the main ﬁndings of our study and, ﬁnally Section 5 concludes.

2 Information theory quantiﬁers

Many economic data are recorded as a sequence of measurements equally spaced
in time. This kind of data, commonly referred as time series, are usually the
starting point for economic analysis. When the data are abundant, the num-
ber of adequate quantitative techniques increases. In particular, econophysics
methods, as the one applied in this article, are innovative and appropriate to
shed light on economic phenomena. In many cases, econophysics complement
the limitations of traditional econometric techniques.

In this line, information-theory-derived quantiﬁers can help to extract rele-

3

vant information from ﬁnancial time series. The use of information quantiﬁers
in economics is not new, but infrequent. The origins can be traced back to Theil
and Leenders [13], who use entropy to predict short-term price ﬂuctuations in
the Amsterdam Stock Exchange. [14] and [15] replicate the same technique for
the New York Stock Exchange and the London Stock Exchange respectively. [16]
analyzes the proportion of securities with positive, negative and null returns on
the American Stock Exchange using information theory methods and conclude
that this proportions are dependent on the previous day and is not signiﬁcantly
inﬂuenced by the proportion of untraded securities.
[17] proposes the average
mutual information or shared entropy as a proxy of systematic risk. This tech-
nique was remained unused until recent years. For example, [18] uses entropy
and symbolic time series analysis in order to relate informational eﬃciency and
the probability of having an economic crash. Later, [19] uses Shannon entropy to
rank the informational eﬃciency of several stock markets around the world. [20]
uses multiscale entropy analysis to analyze the evolution of the informational
eﬃciency of crude oil prices.

2.1 Shannon entropy

When studying dynamical systems, the discrimination of the presence of corre-
lations in time series, emerges as one key task. Given a time series, one of the
most natural measures of disorder, and thus absence of correlation, is Shannon
entropy [21]. Given a discrete probability distribution P = {pi : i = 1, · · · M },
Shannon entropy is deﬁned as:

S[P ] = −

M

X

i=1

pi log(pi)

(1)

This formula measures the information embedded into the physical process de-
cribed by P . It is a bounded function in the interval [0, log(M )]. S[P ] = 0 means
that one of the states pi∗ = 1 and the remaining pi = 0 for i 6= i∗, ∀i ∈ M . In
other words, null entropy means full certainty about the system’s outcome. On
the other extreme, if S[P ] = log(M ), our knowledge about the system is min-
imal, meaning that all states are equally probable. Even though entropy can
describe globally the level of order/disorder of a process, the analysis of time
series using solely Shannon entropy could be incomplete [22]. The reason is that
an entropy measure does not quantify the degree of structure or patterns present
in a process. Consequently, a measure of statistical complexity is necessary in
order to characterize the system.

2.2 Statistical complexity

Although Shannon entropy is a good measure of the order of a physical system, it
has limitations. An additional measure in order to measure the hidden structure
of the process is needed in order to fully characterize dynamical systems: an

4

statistical complexity measure. A family of statistical complexity measures,
based on the functional form developed by [23], is deﬁned in [24, 25] as:

CJ S = QJ [P, Pe] · H[P ]

(2)

where H[P ] = S[P ]/Smax is the normalized Shannon entropy, P is the discrete
probability distribution of the time series under analysis, Pe is the uniform dis-
tribution and QJ [P, Pe] is the so-called disequilibrium. This disequilibrium is
deﬁned in terms of the Jensen-Shannon divergence, which quantiﬁes the dif-
ference between two probability distributions. Mart´ın, Plastino and Rosso [26]
demonstrates the existence of upper and lower bounds for generalized statis-
tical complexity measures such as CJ S . Additionally, as highlighted in [27],
the permutation complexity is not a trivial function of the permutation entropy
because they are based on two probability distributions. A complete discussion
about this measures and details about their calculation is in [28].

2.3 Bandt-Pompe symbolization method

In order to evaluate this quantiﬁers, a symbolic technique should be selected
in order to obtain the appropriate probability distribution function. Following
[28, 29, 30, 31], we use the Bandt and Pompe [32] permutation method, because
it is the single symbolization technique that considers time causality. This
methodology requires only weak stationarity assumptions.

The appropriate symbol sequence arises naturally from the time series. “Par-
titions” are devised by comparing the order of neighboring relative values rather
than by apportioning amplitudes according to diﬀerent levels. No model as-
sumption is needed because Bandt and Pompe method makes partitions of
the time series and orders values within each partition. Given a time series
S(t) = {xt; t = 1, · · · , N }, an embedding dimension D > 1, D ∈ N, and an
embedding delay τ, τ ∈ N, the BP-pattern of order D generated by

s 7→ (cid:0)xs−(D−1)τ , xs−(D−2)τ , · · · , xs−τ , xs(cid:1)

(3)

is the one to be considered. To each time s, BP assign a D-dimensional vector
that results from the evaluation of the time series at times s − (D − 1)τ, s − (D −
2)τ, · · · , s − τ, s. Clearly, the higher the value of D, the more information about
“the past” is incorporated into the ensuing vectors. By the ordinal pattern of
order D related to the time s, BP mean the permutation π = (r0, r1, · · · , rD−1)
of (0, 1, · · · , D − 1) deﬁned by

xs−rD−1 τ ≤ xs−rD−2 τ ≤ · · · ≤ xs−r1 τ ≤ xs−r0 τ .

(4)

In this way the vector deﬁned by Eq. (3) is converted into a deﬁnite symbol π.
So as to get a unique result BP consider that ri < ri−1 if xs−ri τ = xs−ri−1 τ .
This is justiﬁed if the values of xt have a continuous distribution so that equal
values are very unusual.

For all the D! possible orderings (permutations) πi when embedding di-
mension is D, their associated relative frequencies can be naturally computed

5

according to the number of times this particular order sequence is found in the
time series, divided by the total number of sequences,

p(πi) =

♯{s|s ≤ N − (D − 1)τ ; (s) has type πi}

N − (D − 1)τ

(5)

In the last expression the symbol ♯ stands for “number”. Thus, an ordinal
pattern probability distribution P = {p(πi), i = 1, · · · , D!} is obtained from the
time series.

As we mention previously, the ordinal-pattern’s associated PDF is invariant
with respect to nonlinear monotonous transformations. Accordingly, nonlinear
drifts or scalings artiﬁcially introduced by a measurement device will not mod-
ify the quantiﬁers’ estimation, a nice property if one deals with experimental
data (see i.e. [33]). These advantages make the BP approach more convenient
than conventional methods based on range partitioning. Additional advantages
of the method reside in (i) its simplicity (we need few parameters: the pat-
tern length/embedding dimension D and the embedding delay τ ) and (ii) the
extremely fast nature of the pertinent calculation-process [34]. The BP method-
ology can be applied not only to time series representative of low dimensional
dynamical systems but also to any type of time series (regular, chaotic, noisy,
or reality based). In fact, the existence of an attractor in the D-dimensional
phase space in not assumed. The only condition for the applicability of the BP
method is a very weak stationary assumption (that is, for k = D, the probability
for xt < xt+k should not depend on t [32]). The selected pattern length should
fulﬁll N ≫ D! , in order to obtain reliable quantiﬁers .

2.4 The Complexity Entropy Causality Plane

When the Shannon entropy and the statistical complexity measures deﬁned
before are computed using the [32] symbolization technique, the quantiﬁers are
named permutation entropy and permutation statistical complexity. Both quan-
tiﬁers can be represented in a Cartesian plane, forming the Complexity Entropy
Causality Plane (CECP). This planar representation was introduced in eﬃciency
analysis in [28] and was successfully used to rank eﬃciency in stock markets [29],
commodity markets [30], and to link informational eﬃciency with sovereign bond
ratings [35]. Given the power of the CECP for the discrimination of random
and chaotic signals, its application goes across disciplines. For example, [36]
studies the daily stream ﬂow of United States rivers, and [37] reviews the main
biomedical and econphysical applications of this methodology.

3 Data

We analize the Libor rates in British Pounds (GBP), Euro (EUR), Swiss Franc
(CHF) and Japanese Yen (JPY), for the following seven maturities: overnight
(O/N), one week (1W), one month (1M), two months (2M), three months
(3M), six months (6M) and twelve months (12M). The data coverage is from

6

02/01/2001 until 06/10/2015, for a total of 3851 datapoints. All data were
retrieved from Datastream.

We computed the permutation entropy and permutation statistical complex-
ity for D = 4, using daily values (τ = 1). In order to assess the changes in the
dynamical process that generates Libor time series, we used sliding windows.
The sliding window approach works as follows: we compute the information
quantiﬁers for the ﬁrst 300 datapoints, then we move forward 20 datapoints
(δ = 20) and compute again the quantiﬁers for the next 300 datapoints. We
continue in this way until the end of the data. Using this procedure, we obtained
177 windows, each one spanning slightly more than a year (≈ 13 months)

4 Results

The results of the permutation entropy and statistical complexity are displayed
in cartesian planes called Complexity Entropy Causality Planes. This graphical
representation allows the discrimination of stochastic and chaotic dynamics, as
described in [31]. According to the classical ﬁnancial literature, prices in a
competitive market should follow a memoryless stochastic process [38]. Thus,
if Libor is freely set, without exogenous altering forces, it should approximately
follow a random walk. In this situation, permutation entropy is maximized and
permutation statistical complexity is minimized. We can safely say that, the
closer the quantiﬁers to the point (1, 0), the more informational eﬃcient the
market is.

A simple observation of Figures 1 to 8 shows that we are facing a changing
dynamic. The process governing interest rates does not seem to be stable over
time. The reﬂection of this is that the position of the estimators changes radi-
cally in diﬀerent temporal windows. However, this change is not random, but
rather seems to follow a directed path. To make a more visual presentation, we
have grouped the windows in 11 periods of 16 windows each (17 windows in the
last period). So we can diﬀerentiate each period with a color and a diﬀerent
marker. Additionally, we have put a number to each period and we have located
in the average values of entropy and complexity of that period. As a general
rule, we can see that GBP, EUR and CHF Libor behaves very eﬃciently during
the ﬁrst three periods (years 2001-2005). Indeed, entropy is greater than 0.8
and less than 0.2 complexity. Period 4 appears to be a certain transition. En-
tropy decreases and complexity increases. This trend is deepened in subsequent
periods, with periods 6, 7 and 8 being the most ineﬃcient (years 2007-2012).
Periods 9, 10 and 11 (years 2012-2015) show a return to the area of greatest
informational eﬃciency.

A more detailed analysis by currency allows us to discover that not all ma-
turities followed the same pattern. Indeed, the most aﬀected are the maturities
of 1, 2 and 3 months. At the other extreme, the least aﬀected were maturities
of overnight and 12 months. Further analysis should JPY Libor. The behavior
is similar to other currencies, but all maturities have also been aﬀected in the
rate rigging.

7

Probably one of the reasons for the distinct behavior of JPY and the rest of
the currencies is that Libor JPY is less used as a benchmark for pricing other
ﬁnancial instruments. On the other hand, the distinct behavior in the diﬀerent
maturities can be also explained by their use as a reference rate1.

We cannot discard that the ﬁnancial crisis itself produced a disruption in
the Libor market, making it less eﬃcient.
Its inﬂuence seems to depend on
the nature of the ﬁnancial assets under study. For example, [39] report an
asymmetric impact of the crisis in the long memory of corporate and sovereign
bonds. However, it is at least a remarkable coincidence that the changes in
informational eﬃciency is contemporary with the alleged manipulation, specially
in some maturities. Additionally, the informational eﬃciency recovery begins
when banks were ﬁned by improper conduct. Moreover, our results agree with
the ﬁnding in [40], that between 2007 and 2009 the Libor time series was more
predictable than either before or after those years.

In order to observe more clearly the temporal changes in informational eﬃ-

ciency, we compute the metric introduced in [41]:

Ineﬃciency = +p(HS − 1)2 + (CJ S)2.

(6)

This measure represents the Euclidean distance to the point HS = 1 and CJ S = 0
, i.e. the maximal eﬃciency point. The results can be observed in Figure 9.

5 Conclusions

This paper studies the 28 time series of Libor rates during the last 14 years. The
information theory based symbolic analysis is known as Complexity-Entropy
Causality Plane, a novel approach in ﬁnancial economics. The use of the CECP
allows the discrimination of diﬀerent stochastic and chaotic regimes. We used
moving windows in order to introduce temporal dimension into our analysis.
According to our results an abnormal movement of Libor time series arround the
period of the 2007 ﬁnancial crisis is detected. This alteration in the stochastic
dynamics of Libor is contemprary of what press called “Libor scandal”, i.e. the
manipulation of interest rates carried out by several prime banks. We argue that
our methodology is suitable as a market watch mechanism, as it makes visible
the temporal redution in informational eﬃciency of the market. Our results
could be useful for regulatory authorities, since the procedure detailed in this
paper could act as an early warning mechanism to detect unusual dynamics in
the Libor market.

6 Acknowledgements

Lisana B. Martinez, M. Bel´en Guercio and Osvaldo A. Rosso acknowledge ﬁ-
nancial support from Consejo Nacional de Investigaciones Cient´ıﬁcas y T´ecnicas

1see the use of the diﬀerent Libor rate maturities and currencies as a reference rate for

interest rate swaps and ﬂoating rate notes in Table C.2 in [12]

8

Figure 1: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of GBP Libor for diﬀerent maturities: overnight (O/N), one week (1W), one
month (1M), two months (2M). Numbers {1, · · · , 11} are the central points of
each of the clusters. The solid lines represent the upper and lower bounds of
the quantiﬁers as computed by Mart´ın et al. [26]

(CONICET), Argentina.

References

[1] C. Mollenkamp, M. Whitehouse, Study casts doubt on key rate: WSJ
analysis suggests banks may have reported ﬂawed interest data for libor,
The Wall Street Journal, Thursday, 29 May, p.1, 2008.

[2] Reuters, New york federal reserve knew about libor rate-ﬁxing issues as
far back as 2007 and proposed changes but were ignored, The Daily Mail,
July 10, 2012.

[3] L.

Saigol,

The

email

trail,

Libor:

Financial
http://www.ft.com/cms/s/0/cefd67a0-25df-11e3-aee8-
http://www.

Times,
00144feab7de.html#axzz3FNK2XAFe,
ft.com/cms/s/0/cefd67a0-25df-11e3-aee8-00144feab7de.html
#axzz3FNK2XAFe.

2013.

URL:

The

9

Figure 2: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of GBP Libor for diﬀerent maturities (continuation): three months (3M), six
months (6M) and twelve months (12M). Numbers {1, · · · , 11} are the central
points of each of the clusters. The solid lines represent the upper and lower
bounds of the quantiﬁers as computed by Mart´ın et al. [26]

[4] D. Hou, D. R. Skeie, Libor: Origins, economics, crisis, scandal, and reform,

Federal Reserve Bank of New York Staﬀ Report No. 667, 2014.

[5] J. B. Taylor, J. C. Williams, A black swan in the money market, American

Economic Journal: Macroeconomics 1 (2009) 58-83.

[6] C. A. Snider, T. Youle, Does the libor reﬂect banks borrowing
costs?, Available at SSRN: http://ssrn.com/abstract=1569603, 2010.
doi:10.2139/ssrn.1569603.

[7] R. M. Abrantes-Metz, S. B. Villas-Boas, G. Judge, Tracking the libor rate,

Applied Economics Letters 18 (2011) 893-899.

[8] A. Monticini, D. L. Thornton, The eﬀect of underreporting on LIBOR

rates, Journal of Macroeconomics 37 (2013) 345–348.

[9] J. Bai, P. Perron, Estimating and testing linear models with multiple

structural changes, Econometrica 66 (1998) 47-78.

10

Figure 3: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of EUR Libor for diﬀerent maturities: overnight (O/N), one week (1W), one
month (1M), two months (2M). Numbers {1, · · · , 11} are the central points of
each of the clusters. The solid lines represent the upper and lower bounds of
the quantiﬁers as computed by Mart´ın et al. [26]

[10] A. F. Bariviera, M. Guercio, L. Martinez, O. Rosso, The (in)visible hand in
the libor market: an information theory approach, The European Physical
Journal B 88 (2015) 208.

[11] A. F. Bariviera, M. Guercio, L. Martinez, O. Rosso, A permutation in-
formation theory tour through diﬀerent interest rate maturities: the libor
case, Philosophical Transactions of the Royal Society of London A: Math-
ematical, Physical and Engineering Sciences 373 (2015) 20150119.

[12] M. Wheatley, The Wheatley Review of LIBOR: Final Report, Independent

report, H.M. Treasury, 2012.

[13] H. Theil, C. T. Leenders, Tomorrow on the Amsterdam stock exchange,

The Journal of Business 38 (1965) 277-284.

[14] E. F. Fama, Tomorrow on the New York stock exchange, The Journal of

Business 38 (1965) 285-299.

11

Figure 4: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of EUR Libor for diﬀerent maturities (continuation): three months (3M), six
months (6M) and twelve months (12M). Numbers {1, · · · , 11} are the central
points of each of the clusters. The solid lines represent the upper and lower
bounds of the quantiﬁers as computed by Mart´ın et al. [26]

[15] M. M. Dryden, Short-term forecasting of share prices: an Information
Theory approach, Scottish Journal of Political Economy 15 (1968) 227-
249.

[16] G. C. Philippatos, D. N. Nawrocki, The behavior of stock market aggre-
gates: Evidence of dependence on the american stock exchange, Journal
of Business Research 1 (1973) 101-114.

[17] G. C. Philippatos, C. J. Wilson, Information theory and risk in capital

markets, Omega 2 (1974) 523-532.

[18] W. A. Risso, The informational eﬃciency and the ﬁnancial crashes, Re-

search in International Business and Finance 22 (2008) 396-408.

[19] W. A. Risso, The informational eﬃciency: the emerging markets versus

the developed markets, Applied Economics Letters 16 (2009) 485-487.

[20] A. Ortiz-Cruz, E. Rodriguez, C. Ibarra-Valdez, J. Alvarez-Ramirez, Eﬃ-
ciency of crude oil markets: Evidences from informational entropy analy-
sis, Energy Policy 41 (2012) 365-373.

12

Figure 5: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of CHF Libor for diﬀerent maturities: overnight (O/N), one week (1W), one
month (1M), two months (2M). Numbers {1, · · · , 11} are the central points of
each of the clusters. The solid lines represent the upper and lower bounds of
the quantiﬁers as computed by Mart´ın et al. [26]

[21] C. E. Shannon, W. Weaver, The Mathematical Theory of Communication,

University of Illinois Press, Champaign, IL, 1949

[22] D. P. Feldman, J. P. Crutchﬁeld, Measures of statistical complexity:

Why?, Physics Letters A 238 (1998) 244-252.

[23] R. L´opez-Ruiz, H. L. Mancini, X. Calbet, A statistical measure of com-

plexity, Physics Letters A 209 (1995) 321-326.

[24] M. Mart´ın, A. Plastino, O. Rosso, Statistical complexity and disequilib-

rium, Physics Letters A 311 (2003) 126–132.

[25] P. W. Lamberti, M. T. Mart´ın, A. Plastino, O. A. Rosso, Intensive entropic

non-triviality measure, Physica A 334 (2004) 119-131.

[26] M. T. Mart´ın, A. Plastino, O. A. Rosso, Generalized statistical complexity
measures: Geometrical and analytical properties, Physica A 369 (2006)
439-462.

13

Figure 6: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of CHF Libor for diﬀerent maturities (continuation): three months (3M), six
months (6M) and twelve months (12M). Numbers {1, . . . , 11} are the central
points of each of the clusters. The solid lines represent the upper and lower
bounds of the quantiﬁers as computed by Mart´ın et al. [26]

[27] M. C. Soriano, L. Zunino, O. A. Rosso, I. Fischer, C. R. Mirasso, Time
scales of a chaotic semiconductor laser with optical feedback under the
lens of a permutation information analysis, IEEE J. Quantum Electron.
47 (2011) 252-261.

[28] L. Zunino, M. C. Soriano, I. Fischer, O. A. Rosso, C. R. Mirasso,
Permutation-information-theory approach to unveil delay dynamics from
time-series analysis, Physical Review E 82 (2010) 046212.

[29] L. Zunino, M. Zanin, B. M. Tabak, D. G. P´erez, O. A. Rosso, Complexity-
entropy causality plane: A useful approach to quantify the stock market
ineﬃciency, Physica A: Statistical Mechanics and its Applications 389
(2010) 1891-1901.

[30] L. Zunino, B. M. Tabak, F. Serinaldi, M. Zanin, D. G. P´erez, O. A.
Rosso, Commodity predictability analysis with a permutation information
theory approach, Physica A: Statistical Mechanics and its Applications
390 (2011) 876-890.

14

Figure 7: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of JPY Libor for diﬀerent maturities: overnight (O/N), one week (1W), one
month (1M), two months (2M). Numbers {1, . . . , 11} are the central points of
each of the clusters. The solid lines represent the upper and lower bounds of
the quantiﬁers as computed by Mart´ın et al. [26]

[31] O. A. Rosso, H. A. Larrondo, M. T. Mart´ın, A. Plastino, M. A. Fuentes,
Distinguishing noise from chaos, Physical Review Letters 99 (2007)
154102.

[32] C. Bandt, B. Pompe, Permutation entropy: A natural complexity measure

for time series, Physical Review Letters 88 (2002) 174102.

[33] P. M. Saco, L. C. Carpi, A. Figliola, E. Serrano, 330 O. A. Rosso, En-
tropy analysis of the dynamics of el ni˜no southern oscillation during the
holocene, Physica A: Statistical Mechanics and its Applications 389 (2010)
5022–5027.

[34] K. Keller,M. Sinn, Ordinal analysis of time series, Physica A: Statistical

Mechanics and its Applications 356 (2005) 114-120.

[35] L. Zunino, A. F. Bariviera, M. B. Guercio, L. B. Martinez, O. A. Rosso,
On the eﬃciency of sovereign bond markets, Physica A 391 (2012) 4342-
4349.

15

Figure 8: Complexity Entropy Causality Plane, with D = 4, τ = 1, δ = 20
of JPY Libor for diﬀerent maturities (continuation): three months (3M), six
months (6M) and twelve months (12M). Numbers {1, · · · , 11} are the central
points of each of the clusters. The solid lines represent the upper and lower
bounds of the quantiﬁers as computed by Mart´ın et al. [26]

[36] F. Serinaldi, L. Zunino, O. A. Rosso, Complexity-entropy analysis of daily
stream ﬂow time series in the continental united states, Stochastic Envi-
ronmental Research and Risk Assessment 28 (2014) 1685-1708.

[37] M. Zanin, L. Zunino, O. A. Rosso, D. Papo, Permutation entropy and
its main biomedical and econophysics applications: A review, Entropy 14
(2012) 1553-1577.

[38] P. A. Samuelson, Proof that properly anticipated prices ﬂuctuate ran-

domly, Industrial Management Review 6 (1965) 41-49.

[39] A. F. Bariviera, M. B. Guercio, L. B. Martinez, A comparative analysis of
the informational eﬃciency of the ﬁxed income market in seven european
countries, Economics Letters 116 (2012) 426-428.

[40] A. F. Bariviera, M. T. Mart´ıin, A. Plastino, V. Vampa, LIBOR troubles:
Anomalous movements detection based on maximum entropy, Physica A:
Statistical Mechanics and its Applications 449 (2016)401–407.

16

Figure 9: Ineﬃciency evolution for each currency and maturity of Libor rates,
according to equation 6

[41] A. F. Bariviera, L. Zunino, M. B. Guercio, L. B. Martinez, O. A. Rosso,
Revisiting the European sovereign bonds with a permutation information-
theory approach, The European Physical Journal B 86 (2013) 509.

17

