Astronomy & Astrophysics manuscript no. article
March 7, 2016

c(cid:13)ESO 2016

High Resolution Weak Lensing Mass-Mapping Combining Shear

and Flexion

F. Lanusse1, 2(cid:63), J.-L. Starck2, A. Leonard3, S. Pires2

1 McWilliams Center for Cosmology, Department of Physics, Carnegie Mellon University, Pittsburgh, PA 15213, USA.
2 Laboratoire AIM, UMR CEA-CNRS-Paris, Irfu, SAp, CEA Saclay, F-91191 GIF-SUR-YVETTE CEDEX, France.
3 Department of Physics and Astronomy, University College London, Gower Place, London WC1E 6BT, U.K.

March 7, 2016

ABSTRACT

Aims. We propose a new mass-mapping algorithm, speciﬁcally designed to recover small-scale information from a combination of
gravitational shear and ﬂexion. Including ﬂexion allows us to supplement the shear on small scales in order to increase the sensitivity
to substructures and the overall resolution of the convergence map without relying on strong lensing constraints.
Methods. In order to preserve all available small scale information, we avoid any binning of the irregularly sampled input shear
and ﬂexion ﬁelds and treat the mass-mapping problem as a general ill-posed inverse problem, regularised using a robust multi-scale
wavelet sparsity prior. The resulting algorithm incorporates redshift, reduced shear, and reduced ﬂexion measurements for individual
galaxies and is made highly eﬃcient by the use of fast Fourier estimators.
Results. We test our reconstruction method on a set of realistic weak lensing simulations corresponding to typical HST/ACS cluster
observations and demonstrate our ability to recover substructures with the inclusion of ﬂexion which are lost if only shear information
is used. In particular, we can detect substructures at the 15(cid:48)(cid:48) scale well outside of the critical region of the clusters. In addition, ﬂexion
also helps to constrain the shape of the central regions of the main dark matter halos. Our mass-mapping software, called Glimpse2D,
is made freely available at http://www.cosmostat.org/software/glimpse.
Key words. Gravitational lensing: weak – Methods: data analysis – Galaxies: clusters: general – dark matter

1. Introduction
Probing the mass distribution of the various structural compo-
nents of the Universe is a fundamental tool to constrain cosmo-
logical models. Gravitational lensing, which is sensitive to the
total mass content, is particularly well suited for this task. One
of the strengths of gravitational lensing is its ability to probe the
dark matter content from the largest cosmological scales down
to the galaxy scale, providing valuable constraints at all interme-
diary scales.

In particular, at the galaxy cluster scale, gravitational lens-
ing is an established tool for measuring the total mass distribu-
tion and investigating the nature of dark matter (e.g. Clowe et al.
2006; Massey et al. 2015). While the combination of gravita-
tional shear and strong lensing constraints has proven very suc-
cessful to resolve the ﬁne structure of galaxy clusters (Bradac
et al. 2005; Cacciato et al. 2006; Merten et al. 2009), strong
lensing is only eﬀective within the Einstein radius of the cluster
which represents for most clusters only a fraction of their total
area. Outside of this region, constraints from gravitational shear
are generally very poor below the arcminute scale which makes
the detection of substructures extremely unlikely. A promising
avenue to bridge the gap between shear and strong lensing,
and help resolve substructure outside of the innermost regions
of galaxy clusters is gravitational ﬂexion, which has already
been shown to provide valuable constraints at these intermedi-
ate scales (Leonard et al. 2007).

Measuring ﬂexion has proven to be a diﬃcult task in practice
(Viola et al. 2012; Rowe et al. 2013). Originally, ﬂexion estima-

(cid:63) ﬂanusse@andrew.cmu.edu

tors were derived from shapelet coeﬃcients (Goldberg & Bacon
2005; Bacon et al. 2006). Another approach relied on moments
of galaxy images (Okura et al. 2007; Goldberg & Leonard 2007;
Schneider & Er 2008). More recently, a diﬀerent approach to
ﬂexion estimation, called Analytic Image Method (AIM), was
proposed by Cain et al. (2011) based on forward ﬁtting analyti-
cal galaxy image models. Among the beneﬁts of this promising
new method are a complete invariance under the mass-sheet de-
generacy and a better characterisation of the measurement errors.
Very few methods have been developed for mass-mapping
including ﬂexion. The ﬁrst reconstruction technique using ﬂex-
ion has been proposed in Bacon et al. (2006) as an extension of
the Kaiser-Squires Fourier estimator (Kaiser & Squires 1993).
A parametric reconstruction of Abell 1689 was attempted in
Leonard et al. (2007) and Leonard et al. (2009); Leonard & King
(2010) later proposed an extension of aperture mass ﬁlters to the
case of ﬂexion. Joint reconstruction based on maximum likeli-
hood methods combining shear, ﬂexion and strong lensing have
also been proposed by Er et al. (2010) and most recently in Cain
et al. (2015).

Recovering high resolution mass-maps from weak lensing is
a diﬃcult problem for two main reasons: the irregular sampling
of the lensing ﬁeld and the low Signal to Noise Ratio (SNR)
on small scales. While the lensing equations can be most easily
inverted when the ﬁeld is fully sampled on a regular grid, for
instance using a Kaiser-Squires estimator, in practice the shear
and ﬂexion ﬁelds are only sampled at the position of the back-
ground galaxies, which are not regularly distributed. In that case
the lensing equations are no longer directly invertible and mass-
mapping becomes an ill-posed inverse problem i.e. the solution

Article number, page 1 of 19

6
1
0
2

 
r
a

M
4

 

 
 
]

.

O
C
h
p
-
o
r
t
s
a
[
 
 

1
v
9
9
5
1
0

.

3
0
6
1
:
v
i
X
r
a

A&A proofs: manuscript no. article

is not unique and/or extremely unstable to measurement noise.
To avoid this issue, a usual approach is to bin or smooth the in-
put shear or ﬂexion on a regular grid, which not only serves as
a regularisation of the inverse problem but also acts as a denois-
ing step by suppressing smaller scales, where the noise typically
dominates. Although this reasoning holds for shear alone, adding
ﬂexion information greatly increases the SNR of structures on
small scales, in which case binning or smoothing the input data
can destroy relevant information.

The aim of this paper is to propose a new mass-mapping
methodology, speciﬁcally designed to recover small-scale infor-
mation from weak lensing by avoiding any binning or smooth-
ing of the input data and supplementing shear information with
ﬂexion to increase the sensitivity to substructures. We address
the mass-mapping problem as a general ill-posed inverse prob-
lem which we regularise using a wavelet based sparsity prior
on the recovered convergence map. Similar sparse regularisa-
tion methods have already been proposed in the context of weak
lensing mass-mapping in Pires et al. (2009) for inpainting miss-
ing data and Leonard et al. (2012, 2014) for 3D mass-mapping.
In this work, the sparse regularisation framework not only al-
lows us to solve the lensing equations even at very low sampling
rates, it also provides a very robust multi-scale noise regularisa-
tion. Furthermore, despite the irregular sampling of the data, our
algorithm relies on fast Fourier estimators to invert the lensing
equations, by treating the computation of the Fourier transform
(which is ill-posed in this case) as part of the same inverse prob-
lem. This makes our approach far more eﬃcient than the costly
ﬁnite diﬀerencing schemes usually used in maximum likelihood
algorithms. Finally, the proposed algorithm accounts for reduced
shear and ﬂexion and incorporates individual redshift measure-
ments of background sources.

This paper is structured as follows. We present a short
overview of the weak lensing formalism and motivate the interest
of ﬂexion in section 2. In section 3 we introduce and demonstrate
the eﬀectiveness of our sparse regularisation approach in the
simpliﬁed setting of reconstructing the convergence from shear
alone. Then, in section 4, we incorporate the non-linearity in-
duced by the reduced shear, we add redshift information for indi-
vidual galaxies and we extend the framework to include ﬂexion.
Finally, in section 5 we demonstrate on realistic cluster simula-
tions that our method is successful at reconstructing the surface
mass density and illustrate the impact of the additional ﬂexion
information for the recovery of small scale substructures.

2. Weak gravitational lensing formalism
2.1. Weak lensing in the linear regime
Because gravitational lensing is sensitive to the total matter con-
tent of structures, it is an ideal probe to map the dark matter dis-
tribution. The presence of a massive lens along the line of sight
will induce a distortion of the background galaxy images which
can be described by a coordinate transformation (Bartelmann
2010) between the unlensed coordinates β and the observed im-
age coordinates θ:
β = θ − ∇ψ(θ) ,
where ψ is the 2D lensing potential encoding the deﬂection of
light rays by the gravitational lens. The lensing potential can
be seen as generated from a source term, through the following
Poisson equation:

(1)

∆ψ(θ) = 2 κ(θ) ,

Article number, page 2 of 19

(2)

where κ is the convergence, a dimensionless surface density. If
we consider a single thin lens, κ can be derived from the surface
mass density of the lens Σ as:

κ(θ) =

Σ(θ)
Σcritic

,

(3)

where Σcritic is the critical surface density deﬁned by a ratio of
distances between the observer, the lens and the source:

Σcritic =

c2
4πG

DS

DLDLS

.

(4)

In this expression, DS , DL and DLS are respectively the angular
diameter distances to the source, the lens and between the lens
and the source.

If the lensing eﬀect is weak enough, the coordinate trans-
formation can be approximated using a Taylor expansion to ﬁrst
order of Equation 1 as:
βi (cid:39) Ai jθ j ,
(5)
where A is the ampliﬁcation matrix, deﬁned in terms of the
derivatives of the lensing potential and which takes the form:

Ai j(θ) =

A =

(cid:32)
∂βi
∂θ j
1 − κ − γ1

= δi j − ∂i∂ jψ(θ) ,
−γ2

−γ2

1 − κ + γ1

(cid:33)

,

(6)

(7)

where γ is the complex shear, causing anisotropic distortions
whereas κ only produces an isotropic magniﬁcation eﬀect. How-
ever, in practice, when using galaxy ellipticities as a measure-
ment of the lensing eﬀect, neither the convergence nor the shear
are directly observable. Indeed, the net contribution of weak
lensing to the ellipticity of a galaxy is not the shear γ but the
reduced shear g deﬁned as g = γ
1−κ . The ampliﬁcation matrix
can equivalently be expressed as a function of the reduced shear
by factorising a term (1 − κ) which yields:
A = (1 − κ)
(8)
Note that in the weak lensing regime, for κ (cid:28) 1, the reduced
shear can be approximated to the actual shear, γ (cid:39) g. How-
ever, this assumption no longer holds for the purpose of map-
ping galaxy clusters where it is critical to correctly account for
the reduced shear.

−g2
1 + g1

1 − g1
−g2

(cid:32)

(cid:33)

,

2.2. Gravitational ﬂexion
The previous expressions for the coordinate transformations
hold if the convergence and shear ﬁelds are assumed to be con-
stant at the scale of the observed source images. When this as-
sumption is not veriﬁed, the expansion of the coordinate trans-
formation can be pushed to second order (Goldberg & Bacon
2005):
βi (cid:39) Ai jθ j +

Di jkθ jθk ,

(9)

1
2

where the third order lensing tensor Di jk can be derived from
Di jk = ∂kAi j. This additional term gives rise to third order deriva-
tives of the lensing potential which can be summarised as a spin-
1 ﬁeld F = ∇κ and a spin-3 ﬁeld G = ∇γ respectively called ﬁrst
and second ﬂexion.

F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

Similarly to the case of the reduced shear, these two ﬂex-
ion components are not directly observable. Instead, only the re-
duced ﬂexion ﬁelds are measured from galaxy images:

estimator does not have a ﬂat noise power spectrum. Indeed, as-
suming uncorrelated ﬂexion measurements with intrinsic vari-
ance σ2

F, the variance of this estimator is:

F =

F
1 − κ

; G =

G
1 − κ

.

Furthermore, estimating in practice the second ﬂexion G is ex-
tremely delicate and measurements are generally noise domi-
nated and discarded. As a result, in the rest of this work, we
will only include measurements of the reduced ﬁrst ﬂexion F.

Throughout this work, we assume reduced shear and ﬂexion
measurement provided by the AIM method of Cain et al. (2011).
In particular, we will use σF = 0.029 arcsec−1 for the dispersion
of ﬂexion measurements, as reported by Cain et al. (2011) on
HST data.

2.3. Mass-mapping using Fourier estimators
The most well known inversion technique for weak lensing
mass-mapping is the Kaiser-Squires inversion (Kaiser & Squires
1993) which consists in applying a minimum variance ﬁlter in
Fourier space to both components of the shear, yielding one es-
timate of the convergence ﬁeld with minimum noise variance,
given by

ˆ˜κγ =

1 − k2
k2
k2

2

˜γ1 +

2k1k2

k2

˜γ2 ,

(11)

+ k2

2. This estimator is only valid for k2 (cid:44) 0 and as
where k2 = k2
1
a result the mean value of the ﬁeld cannot be recovered, which
corresponds to the well-known mass sheet degeneracy. Assum-
ing white Gaussian noise of variance σ2
γ on the input shear ﬁeld,
the Kaiser-Squires estimator features a simple ﬂat noise power
spectrum:
< ˆ˜κ

ˆ˜κγ >= σ2

(12)

∗
γ

γ

Although this inversion technique has some very desirable prop-
erties including linearity and minimum variance, it has one ma-
jor shortcoming, namely that is not well deﬁned on bounded do-
mains, even less so on domains with complex geometries and
missing data, which occurs in actual surveys. Some alternatives
to the simple Kaiser-Squires have also been developed to mit-
igate some of it shortcomings (Pires et al. 2009; Deriaz et al.
2012) using iterative schemes.

Similarly to the Kaiser-Squires inversion for the shear, Bacon
et al. (2006) proposed a minimum variance ﬁlter for estimating
the convergence from ﬁrst ﬂexion F . As the ﬂexion is only the
gradient of the convergence, these two quantities can be related
in the Fourier domain as:
˜F1 = −ik1˜κ
With the same approach as the Kaiser-Squires inversion, the two
components of the ﬁrst ﬂexion can be combined in order to yield
a minimum variance estimator of the convergence, which takes
the simple expression:

˜F2 = −ik2˜κ .

(13)

;

ˆ˜κF =

ik1 ˜F1 + ik2 ˜F2

k2

.

(14)

Note that, just as with the Kaiser-Squires inversion, this expres-
sion is only valid for k1 (cid:44) 0 and k2 (cid:44) 0, which means that
the ﬂexion reconstruction is still subject to the mass sheet de-
generacy. Contrary to the previous Kaiser-Squires inversion, this

(10)

< ˆ˜κ

∗
F ˆ˜κF > =

k2
2
k4 σ2
F ,

F +

k2
1
k4 σ2
1
k2 σ2
F .

(15)

(16)

=

This makes the reconstruction of mass maps from ﬂexion alone
using this estimator very problematic on large scales where the
noise will always dominate the signal. This means that applying
any low-pass smoothing actually reduces the signal to noise ratio
(SNR) of the reconstruction.

Fig. 1: Noise power spectra of the minimum variance estimators
for shear alone, ﬂexion alone and shear and ﬂexion combined.
The vertical red line indicates the arcminute scale. These noise
power spectra assume σF = 0.029 arcsec−1, σγ = 0.3 and ng =
80 gal/arcmin2 with 14 arcsecs pixels.

Figure 1 shows the noise power spectra of a shear inversion
alone and ﬂexion inversion alone, the arcminute scale is marked
by the vertical line. As can be seen, the ﬂexion noise power-
spectrum is much more favourable than the shear on small scales.
However, it is only worth considering adding ﬂexion information
if the scale at which these two power spectra cross is still rele-
vant. This scale only depends on the ratio of shear and ﬂexion
intrinsic dispersion and we ﬁnd it to be around 65 arcsecs for
σF = 0.029 arcsec−1 and σγ = 0.3. As a result, based solely
on considerations about the relative noise power spectra using
these Fourier estimators, we argue that ﬂexion can be used to
help resolve sub-arcmins structures.

It is clear from Figure 1 that although ﬂexion can help con-
strain small features, it is not competitive with respect to the
shear on scales larger than 1 arcmin. To simultaneously bene-
ﬁt from both shear and ﬂexion, Bacon et al. (2006) proposed
a minimum variance ﬁlter combining both measurements. Al-
though they present reconstructions using this combined ﬁlter,
they do not explicitly provide its expression, which can easily be
derived and takes the form:

ik1 ˜F1 + ik2 ˜F2 +

 k2

1 − k2
k2

2

σ2
F
σ2
γ

 .

˜γ1 +

2k1k2

k2

˜γ2

ˆ˜κγF =

1

k2 + σ2
F
σ2
γ

Article number, page 3 of 19

10-210-1100k [arcsec]−110-410-310-210-1100101102N2Shear aloneFlexion aloneCombinedA&A proofs: manuscript no. article

These Fourier estimators are only valid in the weak lensing
regime and should only be applied when the convergence is weak
(when κ (cid:28) 1) such that the observed reduced shear and ﬂexion
can be approximated to the true shear and ﬂexion:

g =

(cid:39) γ

γ
1 − κ

and

F =

F
1 − κ

(cid:39) F

(19)

(a) Input convergence map

(b) Combined estimator ˆκγF

(c) Shear alone ˆκγ

(d) Flexion alone ˆκF

Fig. 2: Top: Simulated 10 × 10 arcmin2 ﬁeld containing a mas-
sive cluster (a) and its reconstruction using the combined mini-
mum variance estimator (b). Bottom: Reconstructions using the
shear alone Kaiser-Squires estimator (c) and the ﬂexion alone
minimum variance estimator (d).The noise level correspond to
σF = 0.04 arcsec−1, σγ = 0.3 and ng = 50 gal/arcmin2 with 6
arcsecs pixels.

The noise variance of this estimator is now:

< ˆ˜κ

∗
γF ˆ˜κγF >=

σ2
F
k2 + σ2
F
σ2
γ

.

(17)

(18)

As can be seen, on large scales, i.e. for small k we recover
asymptotically the ﬂat shear noise power spectrum while on
small scales we recover the ﬂexion estimator noise power spec-
trum. Figure 1 illustrates the noise power spectrum of this com-
bined estimator (blue line) in realistic conditions. We see that the
combined estimator starts improving over the shear alone around
the arcminute scale.

An example of reconstruction using this combined estima-
tor is shown on Figure 2. The input convergence map is recon-
structed from shear alone, ﬂexion alone and combining shear
and ﬂexion. As expected, the shear alone reconstruction is very
noisy, especially on small scales because of its ﬂat noise power
spectrum. On the contrary, the ﬂexion alone reconstruction is
noise dominated on scales larger than 1 arcmin. However, by
combining both shear and ﬂexion information, the noise is ef-
fectively suppressed on small scales and not ampliﬁed on large
scales which makes the cluster and some of its substructure
clearly identiﬁable without any additional ﬁltering. Note how-
ever that this simple example only illustrates the noise properties
of these estimators but is unrealistic in the sense that it does not
consider the problem of missing data.

Article number, page 4 of 19

Of course this assumption no longer holds at the close vicinity of
galaxy clusters and it is therefore important to properly account
for reduced shear and ﬂexion for the purpose of mapping galaxy
clusters. In those situations, κ is no longer negligible and the re-
construction problem becomes non-linear. As was noted in Seitz
& Schneider (1995), it is still possible to recover the convergence
using the previous linear estimators by iteratively solving the in-
version problem, using at each iteration the previous estimate of
the convergence to correct the measured reduced shear:
κn+1(θ) − κ0 =

(cid:48)))(cid:60)(cid:2)D∗(θ − θ

(cid:48)(1 − κn(θ

(cid:48))(cid:3)

(cid:48))g(θ

(cid:90)

(20)

dθ

1
π

Where D(θ) is the Kaiser-Squires convolution kernel and the
constant κ0 accounts for the fact that the constant of the con-
vergence is not constrained by the data. This iterative process is
generally found to converge quickly to the solution. Of course,
a similar procedure can be implemented to correct the reduced
ﬂexion and we will use the same principle in the reconstruction
algorithm presented in the next section.

2.4. Mass-sheet degeneracy and redshift dependency
One of the most notorious issues in weak lensing mass-mapping
is the so-called mass-sheet degeneracy (Seitz & Schneider
1996). This degeneracy is due to the fact that the shear is left
invariant by the addition of a constant mass-sheet to the lens sur-
face density. As a result, the observed reduced shear is invariant
under the following λ-transformation:
(cid:48) = λκ + (1 − λ)
κ
Indeed, if g(cid:48) is the reduced shear generated by κ(cid:48) then:
(cid:48) =
g

(21)

(22)

= g

λγ

=

1 − λκ − 1 + λ

λγ
λ − λκ

By the same mechanism, the reduced ﬂexion F is also invariant
under the same λ-transformation: adding the ﬂexion information
will not aﬀect the mass-sheet degeneracy.

This issue is particularly problematic for measuring the mass
of galaxy clusters from weak-lensing. Indeed, these measure-
ments are typically performed on small ﬁelds where it cannot
simply be assumed that the convergence goes to zero outside the
ﬁeld without biasing the measurement (Bartelmann 1995).

However, although it is true that from shear alone the mass-
sheet degeneracy can not be lifted, it can nonetheless be miti-
gated when including additional information about the relative
distances between the lens and the diﬀerent sources. Indeed, as
was pointed out in Bradac et al. (2004), knowledge of individ-
ual photometric redshifts of background galaxies is enough to
constrain the mass-sheet for strong enough lenses.

Let us consider γ∞(θ) and κ∞(θ) the shear and convergence
of a given lens at redshift zl, for sources at inﬁnite redshift.
The actual shear and convergence applied to a galaxy at a spe-
ciﬁc redshift zs can be expressed as κ(θ, zs) = Z(zs)κ∞(θ) and
γ(θ, zs) = Z(zs)γ∞(θ) where Z is a cosmological weight, function

4202442024420244202442024420244202442024F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

of the redshifts of the source and lens, which can be expressed
as a ratio of two critical surface densities:

Z(zs) =

Σ∞
crit
Σcrit(zs)

H(zs − zl)

(23)

where H is the Heaviside step function, which only accounts for
the fact that sources located at lower redshift than the lens are
not lensed, and Σ∞
z→∞ Σcrit(z) is the critical surface density
for sources at inﬁnite redshift.

= lim

crit

If we now consider the reduced shear measured on a galaxy
at a speciﬁc redshift zs as a function of κ∞ and γ∞, it takes the
form:

g(θ, zs) =

Z(zs)γ∞(θ)
1 − Z(zs)κ∞(θ)

(24)

This expression alone is just a rewriting of the measured reduced
shear, which makes explicit the dependency on the redshift of the
source. Therefore, the convergence is still subject to the mass-
sheet degeneracy which can now be made explicit in term of zs:

(cid:48) = λκ +

κ

1 − λ
Z(zs)

(25)

It is easily shown that such a transformation leaves the measured
reduced shear invariant. However, it is speciﬁc to a given source
redshift zs and the reduced shear measured on a galaxy at a dif-
ferent redshift z(cid:48)
s (cid:44) zs is not invariant under the same transforma-
tion. As a result, simultaneously constraining the convergence to
ﬁt the reduced shear at diﬀerent redshifts formally leads to λ = 1
and breaks the degeneracy. In practice however, this mechanism
is only eﬀective at lifting the degeneracy in regions where the
convergence is strong enough. Indeed, in the linear regime the
transformation κ(cid:48) = κ + λ has no dependency on the redshift
of the source. Therefore, the mass-sheet degeneracy can only be
lifted in the neighborhood of strong enough lenses, where the
weak lensing approximation no longer holds.

For the rest of this work, we will assume knowledge of the
redshift zL of the lens as well as individual photometric redshifts
for the sources. For a source with a given photo-z distribution
pi(z), we deﬁne the following lensing weight Zi relating the con-
vergence of the source and the convergence at inﬁnite redshift:

(cid:90) ∞

zL

Zi =

Z(z)pi(z)dz =

Σ∞
critic
Σcritic(z)

pi(z)dz

(cid:90) ∞

zL

where Σcritic(z) is the critical density for a lens at redshift zL and
a source at redshift zs = z while Σ∞
critic is the critical density for
sources at inﬁnite redshift. With this deﬁnition, the reduced shear
gi and reduced ﬂexion Fi for a given source can be described as
a function of the shear, ﬂexion and convergence for sources at
inﬁnite redshift γ∞, F∞ and κ∞:

gi =

Ziγ∞
1 − Ziκ∞

; Fi =

ZiF∞
1 − Ziκ∞

(27)

Finally, for convenience in the rest of the paper, we introduce the
diagonal matrix Z = diag(Z1, Z2, . . . , ZN), with N the number of
galaxies in the survey.

3. A new mass-mapping methodology
3.1. Dealing with irregularly sampled data
The global inversion methods presented in the previous section
all assume knowledge of the shear on a grid. However, the shear
is only sampled in practice at randomly distributed galaxy posi-
tions. Therefore a ﬁrst step in all of these methods is to bin the
shear catalogue in order to have a suﬃcient number of galax-
ies per pixel prior to performing the inversion. Even so, some
regions are bound to remain empty because of various masks
applied to the data. The simplest and most common procedure
to handle missing data consists in applying a large Gaussian
smoothing to the binned shear maps with a kernel larger than
the typical size of the masks. Obviously, this strategy is far from
optimal as it irremediably destroys small scale information.

A more sophisticated approach was proposed in Pires et al.
(2009), based on sparse inpainting. This method regularises the
inversion in the case of missing data by imposing on the solu-
tion a sparsity prior in a Discrete Cosine Transform (DCT) dic-
tionary. In eﬀect, the resulting inpainted map features minimal
B-modes leaking and unbiased power spectrum and bispectrum
with respect to the original map. This method as been employed
to map galaxy clusters in Jullo et al. (2014) where the authors
advocate using a very ﬁne binning of the data in order to have on
average one galaxy per pixel.

We propose in this section a new method for reconstruct-
ing the convergence map, based on Fourier estimators, which
does not require any binning or smoothing of the input shear.
Although this approach allows us to preserve small-scale infor-
mation which would otherwise be lost, it does turn the recon-
struction problem into an ill-posed inverse problem, which we
will address using sparse regularisation

3.1.1. Non-equispaced Discrete Fourier Transform
When using Fourier based methods, the fundamental motivation
behind binning or smoothing is to regularise the Discrete Fourier
Transform (DFT) of the shear, which is not well deﬁned for data
sampled on an irregular grid and which is known in this case
as a Non-equispaced Discrete Fourier Transform (NDFT). The
NDFT is of course no longer an orthogonal transform and is
usually not even invertible. We will consider the case where only
the spatial nodes x = (xl)0≤l<M are arbitrary while the frequency
nodes k = (cid:126)0, N(cid:126) are N regularly spaced integers. Computing
the NDFT from a set of Fourier coeﬃcients ˆf =
sim-
0≤k<N
ply amounts to evaluating the trigonometric polynomials:

(cid:16) ˆfk

(cid:17)

(26)

∀l ∈ (cid:126)0, M(cid:126),

fl =

1√
N

ˆfke2πikxl .

(28)

N−1(cid:88)

k=0

This operation can more conveniently be expressed using matrix
notations as:

f = T ˆf with

Tlk =

1√
N

e2πikxl ,

(29)

where T is the NDFT matrix. Note that in the case of equispaced
spatial nodes such that xl = 1
N l, this operation corresponds to the
conventional DFT and T reduces to the Fourier matrix F deﬁned
as:

Flk =

1√
N

e2πikl/N .

(30)

Article number, page 5 of 19

A&A proofs: manuscript no. article

This Fourier matrix is unitary and its inverse is simply its Her-
mitian conjugate: F−1 = F∗. On the contrary, for non-equispaced
spatial nodes x, the operator T is typically neither orthogonal
nor admits an inverse. Still, one can consider the adjoint NDFT
operator T∗:
T∗

e−2πikxl/N .

(31)

=

kl

1√
N

Although this adjoint operation no longer corresponds to the in-
verse of the transform, it can be used in practice to estimate the
inverse when the problem remains over-determined through a
least squares optimisation of the form:
ˆf = arg min

(cid:107) f − T ˆx (cid:107)2
2 .

(32)

ˆx

This problem can be eﬃciently solved using iterative algorithms
(in particular using a conjugate gradient) which involve the com-
putation of both T and T∗.

It is therefore important to have fast algorithms for the com-
putation of the NDFT and its adjoint. Note that a naive eval-
uation of the sum in Equation 28 would scale as O(N × M)
which is prohibitively large for most applications (including for
our mass-mapping problem). In this work, we use a fast approx-
imate algorithm1 to evaluate the NDFT and its adjoint, called
NFFT (Keiner et al. 2009), which only scales as O(N log(N) +
| log()|M) where  is the desired accuracy. For a given sampling
of the frequency space (i.e. for a given N), the NFFT only lin-
early scales with the number M of spatial nodes xl, which in our
case will correspond to the number of galaxies in the survey.

Although the DFT can still be estimated for irregularly sam-
pled data by solving Equation 32 when the problem remains
over-determined, the under-determined problem is ill-posed and
cannot be directly solved using a least-squares but requires an
additional regularisation.

3.1.2. Sparse regularisation of inverse problems
For the speciﬁc application of weak lensing mass-mapping, the
inverse problem of estimating the Fourier transform of the signal
for irregular samples can be severely ill-posed when the galaxy
density is low. In that case, a simple least-squares such as Equa-
tion 32 is not able to recover a satisfying estimate of ˆf without
additional prior. To regularise this inversion, we propose in this
paper to use a so-called analysis-based sparsity prior. We intro-
duce here the concepts of sparse regularisation in a general set-
ting before specialising them to the weak lensing mass-mapping
problem in the next section.

Let us consider a general linear inverse problem of the form:

y = Ax + n
(33)
where A is a linear operator, y are the measurements, contam-
inated by an additive Gaussian noise n, and x is the unknown
signal we wish to recover from the measurements y. Ill-posed
inverse problems typically occur when the operator A is not in-
vertible or extremely badly conditioned, in which case the so-
lution may not be unique and is at least extremely unstable to
measurement noise. In order to recover a meaningful estimate of
the unknown signal some additional prior information is required
to help restrict the space of possible solutions. One particularly

1 The C++ library NFFT 3 is available at https://www-user.
tu-chemnitz.de/~potts/nfft

Article number, page 6 of 19

powerful instance of such a prior is the sparsity prior which as-
sumes that the signal can be represented in an suitable domain
using only a small number of nonzero coeﬃcients (Starck et al.
2015).

More formally, let us consider a signal x, it can be analysed
using a dictionary Φ to yield a set of analysis coeﬃcients α, such
that α = Φ∗x. For instance, in the case of the Fourier dictionary,
Φ would correspond to the DFT matrix F and α would be the
Fourier coeﬃcients of the signal x. A signal is considered sparse
in this analysis framework if only a small number of its coeﬃ-
cients α are non-zero.

Under a sparsity prior, the solution of the inverse problem
stated in Equation 33 can be recovered as the sparsest possible
signal ¯x still compatible with the observations. This can be for-
malised as a convex optimisation problem of the form:

¯x = arg min

x

1
2

(cid:107) y − Ax (cid:107)2

2

+λ (cid:107) Φ∗x (cid:107)1 .

(34)

The ﬁrst term in this expression in this minimisation problem is
a quadratic data ﬁdelity term while the second term promotes the
sparsity of the solution by penalising the (cid:96)1 norm of the analysis
coeﬃcients of x.

Thanks to very recent advances in the ﬁeld of convex opti-
misation and proximal theory, we now have at our disposal very
eﬃcient algorithms for solving this optimisation problem, which
had remained for a long time largely intractable. In the applica-
tion presented in this paper, we chose to implement an adaptation
of the primal-dual algorithms introduced in Condat (2013); Vu
(2013). We direct the interested reader to Appendix A for a few
elements of proximal calculus and details concerning this spe-
ciﬁc algorithm. A more in depth introduction to proximal theory
can be found in Starck et al. (2015).

3.2. Sparse recovery algorithm for weak lensing

mass-mapping

We now consider the speciﬁc case of weak lensing mass-
mapping from irregularly sampled data and we propose a sparse
recovery algorithm to reconstruct the convergence map from
noisy shear data.

Consider a lensing survey with Ng galaxies. We can write
the expression of the shear γ = (γi)i∈(cid:126)0,Ng(cid:126) at the position of each
galaxy given a convergence map κ as
γ = TPF∗
(35)
In this expression, F is the Fourier matrix and T is the NDFT ma-
trix deﬁned for arbitrary spatial nodes x placed at the position of
each galaxy in the survey. The diagonal operator P implements
the transformation from convergence to shear in Fourier space:

κ

 k2

1 − k2
k2

2

 ˆκ

+ i

2k1k2

k2

ˆγ = Pˆκ =

(36)

Of course, this expression is not deﬁned for k1 = k2 = 0, which
corresponds to the well known mass-sheet degeneracy and by
convention we will set the mean to 0. We are using complex
notations for both shear and convergence, with in particular κ =
κE + iκB where κE and κB are respectively E- and B-modes maps.
This expression is only formally correct if the Fourier trans-
form is evaluated on the R2 plane. In practice however, we con-
sider ﬁnite ﬁelds and rely on a DFT to compute the Fourier
transform which imposes artiﬁcial periodic conditions. The re-
sult of Equation 36 is therefore a circular convolution of the con-
vergence ﬁeld and the Kaiser-Squires kernel. In practice, when

F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

2

κ

2

evaluating this expression, we apply suﬃcient zero-padding to
the convergence ﬁeld κ in order to minimize the impact of these
periodic boundary conditions. As the Kaiser-Squires kernel de-
cays to the inverse angular distance squared, the quality of the
approximation due to the circular convolution quickly improves
with the amount of zero-padding.
An important point to stress is that the operator P is unitary,
with P∗ P = Id, just like the Fourier matrix F, and as such is
readily invertible. Solving Equation 35 therefore reduces to the
inversion of the NDFT operator, which is the only diﬃcult step.
As mentioned in the previous section, if the spatial nodes are not
regularly spaced, estimating the inverse NDFT is in the general
case an ill-posed inverse problem.

− 1
(cid:107) Σ
γ

¯κ = arg min

κ(cid:3) (cid:107)2

(cid:2)γ − TPF∗

Our aim is to apply the sparse regularisation framework in-
troduced in subsubsection 3.1.2 to the inversion of the NDFT
operator, thus yielding an estimate of the convergence. We con-
sider the following sparse optimisation problem:
+λ (cid:107) w◦Φ∗

κ (cid:107)1 +i(cid:61)(·)=0(κ) .
(37)
The ﬁrst term is a quadratic data ﬁdelity term, where Σγ is the
covariance matrix of the individual shear measurements, gener-
ally assumed to be diagonal as we are treating galaxies indepen-
dently. The second term is an analysis-based sparsity constraint
where Φ is a dictionary providing a sparse representation of the
signal we want to recover, ◦ is the Hadamard product (term by
term product), and w is a vector of weights allowing us to adap-
tively adjust the (cid:96)1 ball based on the local level of noise (see
subsection 3.4). Finally, the last term imposes the imaginary part
of the solution (i.e. B-modes) to vanish. Remember that the in-
dicator function iC of a set C is deﬁned by

1
2

if x ∈ C
(cid:110)
+∞ otherwise
κ ∈ CN×N

(cid:111)
| (cid:61)(κ) = 0

iC(x) =
(38)
Here, C =
where (cid:61) is the imaginary
part, and N × N is the size of the reconstruction grid. As a re-
sult any solution with a non-zero imaginary part is excluded.
This additional constraint is crucial as the irregular galaxy sam-
pling leads to important leakage between E- and B-modes. As
E-modes are constrained by the sparsity prior, most of the sig-
nal would tend to leak towards B-modes without this additional
term. Vanishing B-modes is of course a completely physically
motivated prior as gravitational lensing only produces E-modes,
but this also means that this method will be sensitive to spuri-
ous B-modes resulting from uncorrected systematics which will
contaminate the recovered signal.

(cid:40)0

We eﬃciently solve this problem by adopting a primal-dual
algorithm following Condat (2013); Vu (2013). The specialisa-
tion of this algorithm to the weak lensing mass-mapping problem
is presented in Appendix A and summarised in algorithm 1.

The solution of this optimisation problem tends to be biased
as a well-known side eﬀect of the (cid:96)1 sparsity constraint. In order
to correct for this bias and improve the quality of the solution,
we implement a two-steps approach.

We ﬁrst apply the reweighted-(cid:96)1 strategy from Candès et al.
(2008) which relies on iteratively solving Equation 37, adjusting
each time the weights w based on the previous estimate of the
solution. This procedure is described below:
1. Set the iteration count (cid:96) = 0 and initialise the weights w(0)

according to the procedure described in subsection 3.4.

Algorithm 1: Analysis-based κ sparse recovery from shear

Require:

2 T (cid:107)2).

Shear of each galaxy in the survey γ.
Sparsity constraint parameter λ > 0.
Weights wi > 0.
τ = 2/((cid:107) Φ (cid:107)2 + (cid:107) Σ− 1
1: κ(0) = 0
γ − TPF∗κ(n)(cid:17)
(cid:16)
2: ∀i,
λ(cid:48)
3: for n = 0 to Nmax − 1 do
i
(cid:16)∇(n) − Φα(n)(cid:17)(cid:105)
(cid:16)
α(n) + Φ∗(cid:16)
4:
5:
6:
7: end for
8: return κ(Nmax).

∇(n) = FP∗T∗Σ−1
κ(n) + τ
α(n+1) = (Id − STλ(cid:48))

κ(n+1) = (cid:60)(cid:104)

= λwi

γ

2κ(n+1) − κ(n)(cid:17)(cid:17)

2. Solve the weighted (cid:96)1 minimisation problem of Equation 37

using algorithm 1, yielding a solution κ((cid:96)).

3. Update the weights based on the wavelet transform of the

solution α((cid:96)) = Φtκ((cid:96)):

w((cid:96)+1)
i

=

|α((cid:96))

i

w(0)
i
|/λw(0)
w(0)
i

i

if |α((cid:96))
if |α((cid:96))

i

i

| ≥ λw(0)
| < λw(0)

i

i

,

(39)



4. Terminate on convergence. Otherwise, increment (cid:96) and go to

step 2.

In practice we ﬁnd that 3 or 5 re-weightings are generally suf-
ﬁcient to reach a satisfying solution. However, despite improv-
ing the quality of the solution, this reweighting scheme does not
completely correct for the (cid:96)1 amplitude bias.

The second correction step involves using this reweighted-(cid:96)1
solution to deﬁne the support Ω of the solution in the analysis
dictionary, which can then be used in place of the (cid:96)1 constraint
to recover an unbiased solution. This support is deﬁned as:

if [Φ∗κ(l)]i > λw(0)
otherwise

i

(40)

(cid:40)1,

0,

Ωi =

Using the support to constrain the solution, the recovery problem
becomes:

¯κ = arg min

κ

− 1
(cid:107) Σ
γ

2

1
2

(cid:2)γ − TPF∗

κ(cid:3) (cid:107)2

2

+iΩ (Φ∗

κ) +i(cid:61)(·)=0(κ) . (41)

where iΩ is the indicator function of the support Ω. This problem
preserves the sparsity of the solution of the reweighted-(cid:96)1 itera-
tive scheme but no longer penalises the amplitude of the analysis
coeﬃcients, which leads to an unbiased solution. This problem
can still be solved using algorithm 1 simply by replacing the
Soft-Thresholding operation on line 6 by a multiplication with
the support Ω.

3.3. Choice of dictionary
For any sparse regularisation method, an appropriate choice of
dictionary is important to the quality of the result. This is espe-
cially true for noise dominated problems where the prior takes
prevalence when the data is not constraining. Previous sparsity
based methods developed for weak lensing mass-mapping either
employed starlets for denoising (Starck et al. 2006) or DCT for

Article number, page 7 of 19

A&A proofs: manuscript no. article

3.4. Adjusting the sparsity constraint

A recurring issue with sparse recovery problems such as the one
stated in Equation 37 is the choice of the regularisation parame-
ter λ. There is unfortunately no general rule indicating how to set
this parameter in practice. For this application, we adopt the ap-
proach that was proposed in Paykari et al. (2014), which consists
in deﬁning this parameter with respect to the noise level.

Formally, the parameter λ scales the (cid:96)1 ball used in the spar-
sity constraint. In practice, it deﬁnes the level of Soft Threshold-
ing applied to the dual variable α (see line 6 in algorithm 1) and
therefore discriminates between signiﬁcant and non-signiﬁcant
coeﬃcients. While this threshold can be set according to a given
sparsity model of the signal to recover, for noise dominated prob-
lems, it is much more crucial to deﬁne this threshold with respect
to the noise level. As the noise statistics vary across the ﬁeld, de-
pending on the speciﬁc galaxy distribution, we introduce a vector
of weights w (found in the (cid:96)1 term in Equation 37) with the pur-
pose of locally scaling the sparsity constraint based on the stan-
dard deviation of the noise propagated to the coeﬃcients α. For
each wavelet coeﬃcient αi we set the weight wi to the estimated
standard deviation σ(αi). As a result, the level of Soft Thresh-
olding applied to each coeﬃcient αi is λ(cid:48)
= λwi and accounts for
noise variations across the ﬁeld. As the threshold is proportional
to the standard deviation of the noise, it can be interpreted as an
hypothesis test to determine if a coeﬃcient is due to signal or
noise, assuming Gaussian statistics for the noise, which adds a
powerful detection aspect to the sparsity constraint.

i

To estimate this noise level, and therefore set the weights w,
it is ﬁrst necessary to understand how the noise in the data prop-
agates to the dual variable α. By considering algorithm 1, it can
be seen that the noise at the level of the shear γN is propagated to
the wavelet coeﬃcients through the operation Φ∗(cid:60) (FP∗T∗γN).
In practice, we estimate the standard deviation of wavelet coef-
ﬁcients by generating Monte-Carlo noise simulations, obtained
by keeping the galaxies at their observed position while ran-
domising their orientation. Note that this step needs only to be
performed once, outside of the main iteration of algorithm 1.
An example of the resulting standard deviation maps for diﬀer-
ent wavelet scales is shown on Figure 4. As can be seen, at the
ﬁnest scales, the noise level has important ﬂuctuations across the
ﬁeld and the contribution of individual galaxies can be seen. On
larger scales, these local ﬂuctuations are smoothed out and the
noise level becomes much more homogeneous. Using this strat-
egy therefore allows us to tune locally the sparsity constraint to
take into account the speciﬁc galaxy distribution of the survey
and leaves only one free parameter λ.

3.5. Numerical experiment on noiseless data

The algorithm presented in this section is only meant to address
the irregular sampling of the shear and the presence of noise,
the complete problem being solved in the next section. In this
simpliﬁed setting, we present a small numerical experiment to
verify the algorithm’s eﬀectiveness at solving the linear inverse
problem.
We simulate a 10 × 10 arcmin2 ﬁeld, containing a group of
galaxy clusters extracted from the Bolshoi N-body simulations
(Klypin et al. 2011) (see subsection 5.1 for more details), as
shown on Figure 5. These clusters are placed at redshift zl = 0.3
and we simulate a lensing catalogue with randomly distributed
sources on a single lens plane at redshift zs = 1.2. Note that we
only simulate shear measurements from the input convergence
map and not the reduced shear.

(a) Starlet dictionary

(b) Starlet + Battle-Lemarié dictio-
nary

Fig. 3: Comparison of reconstruction using starlets or a combi-
nation of starlets and Battle-Lemarié wavelets as the dictionary
Φ. The Battle-Lemarié atoms are very eﬀective at penalising iso-
lated pixels.

inpainting (Pires et al. 2009). Indeed, at small scale, the non-
Gaussian convergence signal essentially generated by isolated
galaxy clusters is well represented using the starlet dictionary
which features isotropic atoms, adapted to the average circular
proﬁle of dark matter halos. On the other hand, on large scales,
the DCT is more eﬃcient at capturing the Gaussian part of the
convergence signal and has proven to be an excellent dictionary
to inpaint missing data due to masks without altering the power
spectrum of the reconstructed maps.

In this work, we aim at reconstructing the convergence map
on small scales and we therefore adopt the starlet dictionary
for the reasons stated above. However, we ﬁnd that when us-
ing the starlet alone, details at the ﬁnest scale are not suﬃ-
ciently constrained, in particular spurious isolated pixels tend to
contaminate the solution, as shown on Figure 3a. To help pe-
nalise this unwanted behaviour, we build a hybrid dictionary by
concatenating to the starlet dictionary the ﬁrst scale of an un-
decimated bi-orthogonal wavelet transform, more speciﬁcally a
Battle-Lemarié wavelet of order 5. Contrary to starlet atoms,
Battle-Lemarié wavelets are much more oscillatory and have a
larger support (formally inﬁnite but with an exponential decay).
This makes them relatively ineﬃcient at sparsely representing
singularities such as isolated pixels, which are therefore more
strongly penalised by the sparsity prior.

To illustrate the beneﬁts of using this hybrid dictionary, we
compare in Figure 3 the results of our reconstruction algorithm
in a simple noiseless case when using starlets alone or the hy-
brid dictionary described above, all other parameters being kept
ﬁxed. As this simple qualitative comparison demonstrates, star-
lets alone tend to create small pixel-sized artefacts, even in the
absence of noise. These are completely eliminated by the inclu-
sion of the Battle-Lemarié wavelets.

We add that although we ﬁnd this dictionary to be eﬀective
at regularising the mass-mapping inversion, it remains generic
and was not speciﬁcally designed for an optimal representation
of convergence maps. More speciﬁc dictionaries could be used
just as well and would potentially improve further our results.
It has for instance been shown that application speciﬁc dictio-
naries built using Dictionary Learning (DL) perform better than
wavelets for the recovery of astronomical images (Beckouche
et al. 2013).

Article number, page 8 of 19

4.04.55.05.56.06.57.04.04.55.05.56.06.57.04.04.55.05.56.06.57.04.04.55.05.56.06.57.0F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

(a) Scale j=0

(b) Scale j=1

(c) Scale j=2

(d) Scale j=3

Fig. 4: Standard deviation maps w used to scale the sparsity constraint, obtained by propagating the shear noise to the wavelet
coeﬃcients. We show here noise maps for four successive starlet scales.

(a) Galaxy distribution

(b) Kaiser-Squires inversion

Fig. 5: Test convergence map generated from an N-body simula-
tion. The clusters are located at zl = 0.3 while the source plane
is placed at zs = 1.2.

We consider here the noiseless inpainting problem where the
input shear is exactly known at the position of the sources. Of
course this problem is unrealistic but does illustrate the impact
of missing data on the mass-mapping inversion using Fourier
estimators.

We generate a shear catalogue with a density of 30 galaxies
per square arcminute which corresponds to a typical Euclid den-
sity. To exacerbate the eﬀects of missing data, we reconstruct
the input convergence map on a grid with 3 arcsecond pixels.
Binning the input catalogue at this resolution corresponds to an
average of 0.075 galaxies per pixels, which means mostly empty
pixels as illustrated by the mask on Figure 6a where empty pix-
els are shown in white. A direct Kaiser-Squires inversion with
such a mask is shown on Figure 6b which corresponds to the so-
lution of the inverse problem in the absence of regularisation. In
order to recover the main structures we also show the result of
a Gaussian smoothing with a kernel of 0.25 arcminute on Fig-
ure 6c. Note that on this last ﬁgure the color scale is adjusted
for better visualisation but the amplitude of the reconstruction
is an order of magnitude below the input signal smoothed with
the same kernel. As illustrated by these plots, small scale infor-

(c) Kaiser-Squires with a 0.25 ar-
cmin Gaussian smoothing

(d) Sparse recovery

Fig. 6: Reconstruction of the input convergence map using 30
galaxies per square arcminute using a Kaiser-Squires estimator
(b-c) and sparse recovery (d). The top left panel shows the mask
applied to the binned shear map with empty pixels marked in
white. In this test, 93% of the pixels are masked.

mation is lost with this approach and although using larger bins
would regularise the inversion these details would still be lost.

We then apply algorithm 1 to the same catalogue. As the
weighting scheme presented in subsection 3.4 is not meant to
be used on noiseless data, we use a noisy version of the shear
data to estimate the weights w and we set the regularisation pa-
rameter λ to a very low value (λ = 0.01) to apply the algorithm
on noiseless data. The solution of the optimisation problem is
shown on Figure 6d. The sparse recovery algorithm constitutes a
major improvement over a simple Kaiser-Squires inversion and
is able to recover pixel scale details despite 93 % of the ﬁeld
being masked. Several reasons can explain these surprising re-
sults. First and foremost, the shear information is non local and
even small structures formally impact the shear across all the
ﬁeld, albeit with an amplitude decaying to the square of the an-

Article number, page 9 of 19

050100150200250050100150200250050100150200250050100150200250050100150200250050100150200250050100150200250050100150200250024681002468100.00.10.20.30.40.50.60.70.80.91.002468100246810024681002468100.000.150.300.450.600.750.90024681002468100.00000.00250.00500.00750.01000.01250.01500.01750.0200024681002468100.000.150.300.450.600.750.90A&A proofs: manuscript no. article

gular distance. The second reason is the use of isotropic wavelets
which provide a sparse representation of the true convergence
map while being morphologically distinct from the response of
individual galaxies, which is quadrupolar. As a result, the spar-
sity constraint greatly favours the true convergence map, which
is smooth with small isotropic features, over anisotropic artefacts
resulting from the irregular shear sampling.

The point of this numerical experiment is to show that al-
though the shear ﬁeld is randomly sampled at a relatively low
rate, high frequency information can still be recovered using our
method. Of course, in practice small-scale details are generally
lost in the considerable amount of noise coming from intrin-
sic galaxy ellipticities, but not necessarily at the close vicinity
of the center of galaxy clusters where the shear signal can be-
come signiﬁcant even on small scales. The ability to reconstruct
small-scale details is even more relevant when including ﬂexion
information as the noise power spectrum of the ﬂexion estimator
drops at small scales.

4. Sparse recovery for the complete problem: the

Glimpse2D algorithm

In the previous section, we have introduced an algorithm based
on sparse regularisation for solving the simpliﬁed linear inver-
sion problem. Although not realistic, this problem is still an im-
portant step towards the complete surface density reconstruction
that we address now in this section. We detail how the algo-
rithm of the previous section can be modiﬁed to take into account
reduced shear, redshift information for individual galaxies, and
ﬂexion information.

4.1. Handling the reduced shear
The problem addressed in the previous section assumed knowl-
edge of the shear, in which case the inverse problem remains
linear. While this assumption can be made in the weak regime,
it breaks down at the vicinity of the structures (galaxy clusters)
we are interested in mapping. Although the method presented in
the previous section no longer directly applies, we present in this
section how it can be extended to take into account the reduced
shear g = γ
Throughout this paper, we will restrict ourselves to the case
|g| ≤ 1 for simplicity, assuming that the sources which do not
verify this condition can be identiﬁed and excluded from the
sample. The method presented here could be extended using an
iterative procedure to identify and thus treat accordingly sources
lying in the region |g| > 1.

1−κ , which makes the inversion problem non-linear.

Replacing the shear by the reduced shear in the inversion

problem stated in Equation 37 yields:

(cid:34)
g − TPF∗κ
1 − TF∗κ

(cid:35)

arg min

κ

(cid:107) Σ− 1

2

1
2

(cid:107)2

2

+λ (cid:107) w ◦ Φtκ (cid:107)1 +i(cid:61)(·)=0(κ) .
(42)

Note that at the denominator the NDFT operator is only used to
evaluate the convergence at the position of each galaxy. In this
form, the full problem cannot be directly addressed using the al-
gorithm presented in the previous section as the operator to invert
is no longer linear. Nonetheless, following a common strategy to
handle this non-linearity, the term C−1
2 /(1 − TF∗κ) can be
Article number, page 10 of 19

= Σ− 1

κ

factored out and be interpreted as a diagonal covariance matrix,
which depends on the signal κ:

(cid:2)(1 − TF∗

arg min

κ

(cid:107) C−1

κ

1
2

κ(cid:3) (cid:107)2

κ)g − TPF∗
+ λ (cid:107) w ◦ Φtκ (cid:107)1 +i(cid:61)(·)=0(κ) .

2

(43)

κ

If the factor C−1
is kept ﬁxed, the problem is now linear and can
be solved once again using the same class of algorithms as in the
previous section. By iteratively solving this linearised problem,
updating each time the matrix C−1
κ with the current estimate of
κ we can recover the solution of the original problem stated in
Equation 42. This is for instance the strategy adopted in Merten
et al. (2009).

4.2. Including redshift information
So far we have not given any consideration to the fact that lens-
ing sources are not located on a single plane but are distributed
in redshift. As was described in subsection 2.4, for a lens at a
given redshift, the amplitude of the lensing eﬀect experienced
by each source will depend on its own redshift. Let us note Z the
diagonal matrix of weights Zi introduced in subsection 2.4, the
reduced shear can be computed from the convergence κ using
the Fourier operators introduced thus far as:

g =

ZTPF∗κ
1 − ZTF∗κ

(44)

where κ is understood to be the convergence at inﬁnite redshift.
With this new operator, the full inversion problem becomes:

(cid:2)(1 − ZTF∗

arg min

κ

(cid:107) C−1

κ

1
2

κ(cid:3) (cid:107)2

κ)g − ZTPF∗
+ λ (cid:107) w ◦ Φtκ (cid:107)1 +i(cid:61)(·)=0(κ) .

2

κ

(45)
where the matrix C−1
2 /(1 − ZTF∗κ).
This is simply a generalisation of Equation 43, which can be
recovered when no redshift information is available by setting
Z = Id, and can be solved exactly in the same way.

κ now becomes C−1

= Σ− 1

(46)

The main advantage of using redshift estimates for individual
galaxies is the proper scaling of the resulting convergence map,
which can be translated into a physical surface mass density map
Σ of the lens plane:
Σ(θ) = κ(θ)Σ∞
The mass of the lens can then be estimated by integrating Σ
within a given radius. The second advantage of using individ-
ual redshifts is that it can help mitigate the mass-sheet degen-
eracy, as was described in Bradac et al. (2004) and presented
in subsection 2.4. We stress however that this degeneracy can-
not be completely lifted using the method presented here as, of
the two terms in the gradient of the χ2 in Equation A.14, we
only retain the one that is insensitive to the mean. Therefore, the
mean value of the ﬁeld remains unconstrained by the data using
our algorithm. Nevertheless, we expect the additional redshift in-
formation to locally break the degeneracy and help recover the
correct amplitude for the most signiﬁcant structures.

crit .

4.3. Improving angular resolution with ﬂexion
We demonstrated in the previous section that our sparse recov-
ery algorithm is capable of reconstructing small scale details in

F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

(cid:34)
where we introduce the application R : RN×N → C2N×N, κ (cid:55)→
FQF∗κ

(cid:35)
, with N × N the size of the reconstruction grid.

κ

the absence of noise despite the irregular galaxy sampling. In
practice however, the shear is noise dominated on those scales,
which makes recovering high frequency information from shear
measurements unlikely.

As was explained in subsection 4.3, while the Kaiser-Squires
estimator for shear has a ﬂat noise power spectrum, the noise
power spectrum of the minimum variance estimator for ﬂexion
has a 1/k2 dependency. As a result, although ﬂexion measure-
ments are generally very noisy, the noise level of the estimated
map eventually drops below that of the shear on suﬃciently
small scales. Flexion can therefore bring useful information but
only below a given scale and is very complementary to shear.

Our aim is therefore to improve the mass-map reconstruction
on small scales by extending our reconstruction method to incor-
porate ﬂexion information. In the interest of simplicity, we con-
sider here only the linear problem without redshift information,
to highlight the diﬃculties inherent to the inclusion of ﬂexion.
The full problem is solved in the next section.

Following the approach developed in the ﬁrst section, we ad-
dress the problem using Fourier estimators. We ﬁrst introduce
the diagonal operator Q implementing the transform from con-
vergence κ to ﬁrst ﬂexion F in Fourier space, deﬁned as:
ˆF = Qˆκ = (k2 − ik1) ˆκ ,
(47)
where we use complex notations for the ﬂexion with F =
F1 + iF2. Contrary to the shear operator P, this operator Q is
not unitary but is still invertible:
ˆκ = Q−1 ˆF =
ˆF .
To extend the algorithm presented in the previous section, a ﬁrst
straightforward approach would be to simply add a ﬂexion term
to the χ2 of Equation 37 and solve the following problem:

k2 + ik1

Q∗
k2

ˆF =

(48)

k2

arg min

κ

1
2

(cid:107) γ − TPF∗

κ (cid:107)2

2

+

κ (cid:107)2

(cid:107) F − TQF∗

1
2
+ λ (cid:107) w ◦ Φtκ (cid:107)1 +i(cid:61)(·)=0(κ) .

2

(49)
Although formally correct, solving this problem using the
primal-dual algorithm presented in the previous section leads to
a number of technical issues linked to the fact that the operator
Q, being not unitary, now contributes to the diﬃculty of the in-
verse problem. In particular, this impacts our ability to robustly
identify signiﬁcant coeﬃcients in the gradient of the data ﬁdelity
term (key to the regularisation strategy presented in the previous
section), which is now aﬀected by a mixture of a ﬂat shear noise
and a ﬂexion noise with a power spectrum in k2. Furthermore,
even without considering the regularisation, the inversion of the
operator Q, which is essentially a 2D gradient, requires a large
number of iterations if solved with a standard gradient descent.
These considerations make the algorithm much slower and far
less robust to noise than when solving the problem from shear
alone.

This needs not be the case however as the inverse of this op-
erator is explicit in Fourier space and these diﬃculties can be
avoided if we make proper use of this explicit inverse. We pro-
pose therefore to address the combined shear and ﬂexion recon-
struction as the following sparse optimisation problem:

arg min

κ, ˜F

1
2

(cid:107) γ − TPF∗

κ (cid:107)2

2

+

(cid:107) F − TF∗ ˜F (cid:107)2

1
2
+ λ (cid:107) w ◦ Φtκ (cid:107)1 +iIm(R)

2

(cid:35)(cid:33)

(cid:32)(cid:34)

κ
˜F

(50)

Thanks to the inclusion of the auxiliary variable ˜F we have
now decoupled the problem of the inversion of the NDFT op-
erator T from the conversion between ﬂexion and convergence
which is now addressed implicitly in the last term. Remember
that the indicator function iC is inﬁnite outside of the set C and
therefore exclude any solution which do not belong to C. In our
case, we require the solution to be in the image of the operator
R:

Im(R) =

∈ C2N×N

| ∃κ ∈ RN×N,

˜F = FQF∗

κ

(51)

(cid:41)

(cid:40)(cid:34)

(cid:35)

κ
˜F

The constraint iIm(R) therefore implies two conditions. First, the
recovered convergence has to be real, which is equivalent to en-
forcing the vanishing B-modes condition already used for the
shear alone inversion problem. The second is that the recovered
ﬂexion ˜F needs to match the ﬂexion derived from the recov-
ered convergence, which makes the connection between the two
variables κ and ˜F . Interestingly, the implementation of this con-
straint in the primal-dual algorithm naturally gives rise to the
minimum variance estimator for shear and ﬂexion introduced in
Equation 17 and therefore will ensure that shear and ﬂexion are
optimally combined at each iteration of the algorithm to maxi-
mize the SNR of features present in the signal on all scales.

4.4. Complete surface density mapping algorithm
We now present the complete reconstruction algorithm, called
Glimpse2D, combining reduced shear g and reduced ﬂexion
F, and taking into account individual redshift estimates for the
sources. The complete problem we aim to solve is the following:

arg min

κ, ˜F

1
2

κg

(cid:107) C−1

(cid:2)(1 − ZTF∗
(cid:104)
1
(1 − ZTF∗
2
+ λ (cid:107) w ◦ Φtκ (cid:107)1 +iIm(R)

κ(cid:3) (cid:107)2
κ)F − ZTF∗ ˜F(cid:105) (cid:107)2
(cid:32)(cid:34)

κ)g − ZTPF∗
(cid:35)(cid:33)

(cid:107) C−1

κF

+

2

2

,

κ
˜F

(52)

κg and C−1

where the non-linear correction matrices C−1
κF incor-
porate the diagonal covariance matrices of the shear and ﬂex-
ion measurement respectively. Note that by separating shear and
ﬂexion terms, we are assuming that these components are inde-
pendent. We use this simplistic assumption as the amplitude of
the correlation between shear and ﬂexion measurements has not
been yet been quantiﬁed in practice for the AIM method. How-
ever, our formalism is trivially extensible to the full non diagonal
covariance between shear and ﬂexion, should it be provided.

As in the previous section, the problem can be solved us-
ing the same primal-dual algorithm derived from Condat (2013);
Vu (2013). The specialisation of this algorithm to the full mass-
mapping problem of Equation 52 is provided in algorithm 2 and
derived in subsection A.3.

Just as with the linear problem, we apply a reweighted-(cid:96)1
strategy to correct for the bias caused by the (cid:96)1 sparsity con-
straint. As the non-linear correction also requires to iteratively
solve this problem we combine the update of the weights w and
the update of the matrix Cκ in the following iterative procedure:
Article number, page 11 of 19

A&A proofs: manuscript no. article

Algorithm 2: Analysis-based surface density mapping al-
gorithm from reduced shear and ﬂexion

Require:

Reduced shear and ﬂexion of each galaxy in the survey g
and F.
Redshift weights for each galaxy in the survey Z.
Reduced shear correction matrix C−1
κ .
Sparsity constraint parameter λ > 0.
Weights wi > 0.
τ = 2/((cid:107) Φ (cid:107)2 + (cid:107) Σ− 1
2 T (cid:107)2).
1: κ(0) = 0 ; ˜F (0) = 0
(cid:16)
(1 − ZTF∗κ(n))g − ZTPF∗κ(n)(cid:17)
2: ∀i,
3: for n = 0 to Nmax − 1 do
(1 − ZTF∗κ(n))F − ZTF∗ ˜F (n)(cid:19)
(cid:18)
4:
(cid:32)(cid:32) κ(n)
(cid:33)
(cid:16)∇(n) − RΦα(n)(cid:17)(cid:33)
2κ(n+1) − κ(n)(cid:17)(cid:17)
α(n) + Φt(cid:16)
(cid:16)

∇(n) = FP∗T∗ZC−2
(cid:33)
FT∗ZC−2

= proxIm(R)
˜F (n+1)
α(n+1) = (Id − STλ(cid:48))

(cid:32) κ(n+1)

˜F (n)

= λwi

+ τ

λ(cid:48)

5:

κF

+

κg

i

6:
7: end for
8: return κ(Nmax).

1. Set the iteration count (cid:96) = 0, C(0)

κ = 1.0 and initialise the
weights w(0) according to the procedure described in subsec-
tion 3.4.

2. Solve the weighted (cid:96)1 minimisation problem of Equation 52
3. Update the matrices C((cid:96))

g (1 − ZTF∗κ(l)) and C((cid:96))

using algorithm 2, yielding a solution κ((cid:96)).
F (1 − ZTF∗κ(l))
Σ−1
solution α((cid:96)) = Φtκ((cid:96)):

4. Update the weights based on the wavelet transform of the

κg = Σ−1

κF

=

w((cid:96)+1)
i

=

|α((cid:96))

i

w(0)
i
|/λw(0)
w(0)
i

i

if |α((cid:96))
if |α((cid:96))

i

i

| ≥ λw(0)
| < λw(0)

i

i

,

(53)



5. Terminate on convergence. Otherwise, increment (cid:96) and go to

step 2.

As for the linear problem we ﬁnd that 3 to 5 iterations of this pro-
cedure are generally suﬃcient to reach a satisfying solution. To
complement the reweighting scheme, the same de-biasing step
based on the support of the reweighted solution is applied to
yield the ﬁnal solution.

5. Results on simulations
In this section we assess the performance of the reconstruc-
tion algorithm on lensing simulations using realistic clusters ex-
tracted from N-body simulations and realistic noise levels for a
space based shear and ﬂexion survey.

5.1. Lensing simulations
In order to assess the performance of the algorithm, we build a
test data set based on N-body simulations. Three massive clus-
ters were extracted at z=0 from the Bolshoi simulations (Klypin
et al. 2011) using the CosmoSim2 interface. These clusters were

2 http://www.cosmosim.org

Article number, page 12 of 19

selected because of their complex geometry with substantial sub-
structure. In each case, at least one halo above 1013h−1M(cid:12) can be
found within the virial radius of the central halo. The masses of
the three clusters we consider in this work can be found in Ta-
ble 1.

Field number Virial mass Virial radius
[h−1Mpc]

[h−1M(cid:12)]
1.09 × 1015
3.02 × 1014
2.70 × 1014

2.14
1.43
1.45

1
2
3

Table 1: Parameters of the three halos extracted from the Bolshoi
simulation

Density maps were obtained for these three clusters by pro-
jecting and binning the particle data with a high resolution, cor-
responding to pixels with an angular size of 0.5 arcsec, for clus-
ters located at redshift zL = 0.3. A multiscale Poisson denoising
was subsequently applied to the binned density maps to remove
the shot noise from the numerical simulation. The resulting sur-
face mass density maps were then scaled to create convergence
maps corresponding to clusters at a redshift zL = 0.3 lensing
background galaxies at inﬁnite redshift. Although we acknowl-
edge that these three particular clusters, selected at z = 0, are
not necessarily representative of clusters at zL = 0.3, for the pur-
pose of testing the mapping algorithm they provide more real-
istic density distributions than simple models based on SIS or
NFW proﬁles. Shear and ﬂexion maps were then derived from
these reference convergence maps and only the center 10 × 10
arcmin central region of each ﬁeld is kept. At the redshift of the
lenses, this corresponds to a physical size of 1.88×1.88 h−1Mpc.
Figure 7 illustrates the convergence maps scaled for sources at
inﬁnite redshift for the 3 ﬁelds we consider.

Finally, 100 mock galaxy catalogues were produced for the
three ﬁelds using for each realisation a uniform spatial distribu-
tion of background galaxies with a density of 80 gal/arcmin2 and
the following redshift distribution:
p(z) ∝ z2
2z3
0

exp(−z/z0)

(54)

with z0 = 2/3. The median redshift of this distribution is zmed =
1.75 and we truncate the distribution at zmax = 5. This particular
distribution has been used in a number of diﬀerent works and in
particular in Cain et al. (2015) to represent the actual galaxy dis-
tribution for a typical HST/ACS ﬁeld. We compute the reduced
shear and ﬂexion for each source galaxy based on their redshift
and on the resdshift of the lens. In the ﬁnal mock catalogues we
assume Gaussian photometric redshifts errors for each sources
with σz = 0.05(1 + z), an intrinsic shape noise of σ = 0.3 for
the reduced shear measurements and σF = 0.029 arcsec−1 for
the reduced ﬂexion measurements. This particular value for the
ﬂexion noise is in accordance with previous works (Rowe et al.
2013) and corresponds to the median dispersion of the ﬂexion
measurements obtained using the AIM method on HST data for
the Abel 1689 cluster (Cain et al. 2011).

Some ﬁnal cuts are applied to the galaxy catalog to exclude
strongly lensed sources by discarding all sources which verify
|g| ≥ 1 or |F| ≥ 1.0 arcsec−1. The ﬂexion cut is based on recom-
mendations from Cain et al. (2015) and constitutes a simple ap-
proximation to the practical limit encountered in real data when
estimating ﬂexion for extremely lensed sources.

F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

Fig. 7: Convergence maps for the three test clusters extracted from the N-body simulation, assuming a lens redshift of zL = 0.3 and
background sources at inﬁnite redshift.

This particular setting was chosen to match the simulations
used in Cain et al. (2015) so that our results can be qualitatively
compared to theirs. However, we stress that contrary to their
work, our reconstruction method relies only on shear and ﬂex-
ion and does not include strong lensing constraints which are
very powerful to map the very center of the clusters.

Finally, throughout this section, we assume a ﬁducial ΛCDM
model for computing distances with Ωm = 0.25, ΩΛ = 0.75
and H0 = 70 km/s/Mpc. Cosmological computations are imple-
mented using the NICAEA library3.

5.2. Results
For each of the mock catalogues generated, we perform the in-
version with and without the ﬂexion information to assess how
much the ﬂexion information can help recover the substructure
of the clusters. The same parameters are used for all the three
diﬀerent ﬁelds and are summarised in Table 2. The pixel size
can in theory be arbitrarily small but we choose 0.05 arcmins as
a good compromise between resolution and computational cost.
The number of wavelet scales is not crucial to the quality of the
reconstruction, we adjust it so that the maximum scale corre-
sponds roughly to the order of the maximum size of the struc-
tures we want to recover. Finally, the number of iterations and
reweighting steps is not crucial either as the algorithm does con-
verge to a solution.

Parameter
Pixel size
Number of wavelet scales
K−sigma threshold
Number of iterations
Number of re-weightings

Value

0.05 arcmin

7
5
500
5

Table 2: Parameters of the reconstruction algorithm

Assessing the quality of the inversion from a single realisa-
tion of the galaxy catalog is diﬃcult as the ability to detect small
structure will depend on the speciﬁc positions of the galaxies
in one realisation. Therefore, we compute the mean and stan-
dard deviation of the reconstructed maps over 100 realisations of
3 http://www.cosmostat.org/software/nicaea

both shape noise and galaxy positions. The mean of the recon-
structions for the 3 ﬁelds with and without ﬂexion is represented
in Figure 8. The most striking diﬀerence between the 2 sets of
reconstructions is the ﬂexion’s ability to detect very small sub-
structures at the 10 arcseconds scale which are not detected from
shear alone. This is clearly visible for the ﬁrst and third ﬁelds.

The errors on the reconstructed mass maps are estimated by
taking the standard deviation of each pixel in the 100 indepen-
dent mock catalogues realisation. It is important to stress that the
observed dispersion of the reconstructions are due to 2 eﬀects:
diﬀerent noise realisations and diﬀerent galaxy distributions in
angular position and redshift. The standard deviation with and
without ﬂexion for all 3 ﬁelds is illustrated in Figure 10. As
can be seen on this ﬁgure, we only observe signiﬁcant disper-
sion on small scales, around detected structures. This is expected
as these scales have the lowest signal to noise ratio in the data
which makes the reconstruction of these features strongly de-
pendent on the speciﬁc noise and galaxy distribution realisation.
Nevertheless, we ﬁnd that the reconstruction is remarkably sta-
ble between realisations. Figure 9 shows reconstructions of the
mass maps for one realisation of the galaxy catalogues. We see
that for a single realisation the reconstructed maps is very close
to the mean maps and mainly diﬀers for small substructure. For
instance, the sub-halo at the bottom of ﬁeld 3 appears stronger
in this particular realisation than in the average maps. Such de-
viations are unavoidable but the shape of the halos can reliably
be reconstructed from a single data set, as would be the case for
actual data.

Flexion does not only enable the detection of very small
structures, it also helps to constrain the small scale shape of the
main halos. Indeed, in shear reconstructions, the noise dominates
the signal at these scales which makes the sparsity prior apparent
on small scales. As we are using isotropic wavelets, without suf-
ﬁcient evidence from the data, the reconstruction will be biased
towards isotropic shape. This is visible for instance at the cen-
ter of the ﬁrst halo, on the top left image of Figure 8, where the
elongation of the very center of the cluster, visible in Figure 7, is
clearly lost. On the contrary, including ﬂexion information helps
to constrain the shape of the center of the cluster.

The same eﬀect can be seen in Figure 11 where we show
the absolute diﬀerence between the mean of the reconstructions
and input convergence maps. The clusters are successfully re-
covered on large scales in both cases, leaving mostly only the

Article number, page 13 of 19

4202442024Field 142024Field 242024Field 30.000.150.300.450.600.750.901.051.20A&A proofs: manuscript no. article

Fig. 8: Mean of 100 independent signal realisations for the three ﬁelds. The top row corresponds to reconstructions using the shear
alone while the bottom row corresponds to reconstructions using shear and ﬂexion.

Fig. 9: Reconstruction of the 3 clusters for a single noise realisa-
tion. The top row corresponds to reconstructions using the shear
alone. The bottom row corresponds to simulations using shear
and ﬂexion.

Fig. 10: Standard deviation of the 100 independent signal real-
isations for the 3 clusters. The top row corresponds to recon-
structions using the shear alone. The bottom row corresponds to
simulations using shear and ﬂexion.

very ﬁne substructure visible in these residual maps. Neverthe-
less, although small, some residuals of the main halos remain
visible near the center of the center ﬁelds but are lower when
combining shear and ﬂexion, indicating better recovery of the
shape of the central part of the cluster when ﬂexion is included.
This is particularly visible for the ﬁrst cluster where the shear
only residuals clearly indicate that the anisotropy of the halo is

Article number, page 14 of 19

not captured as well by the shear alone reconstruction than by
the combined shear and ﬂexion reconstruction.

We also note that on large scales, where the shear dominates,
the two sets of reconstructions agree with each other and the in-
clusion of ﬂexion does not modify the reconstruction. This is il-
lustrated by Table 3 where the integrated mass within a 1(cid:48) radius
is computed on the reconstructions with and without ﬂexion. As
can be seen, tight constraints on the halo masses can be obtained

42024Shear aloneField 1Field 2Field 34202442024Shear and flexion combined42024420240.000.150.300.450.600.750.901.051.2042024Shear aloneField 1Field 2Field 34202442024Shear and flexion combined42024420240.000.150.300.450.600.750.901.051.2042024Shear aloneField 1Field 2Field 34202442024Shear and flexion combined42024420240.000.030.060.090.120.150.180.210.240.270.30F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

Fig. 11: Absolute diﬀerence between the mean of 100 independent signal realisations and the input convergence maps. The top row
corresponds to reconstructions using the shear alone while the bottom row corresponds to reconstructions using shear and ﬂexion.

for the three ﬁelds considered from shear only and the addition
of ﬂexion does not change the mass estimates on scales larger
than the arcminute.

Field

Input M1(cid:48)
1013 h−1M(cid:12)

1
2
3

18.5
9.48
5.88

Shear only M1(cid:48) Combined M1(cid:48)
1013 h−1M(cid:12)
1013 h−1M(cid:12)
19.1 ± 0.53
18.7 ± 0.54
10.5 ± 0.62
10.2 ± 0.62
6.97 ± 0.71
6.89 ± 0.83

Table 3: Integrated mass in the central 1(cid:48) of each ﬁeld, corre-
sponding to a radius of 188 h−1kpc at the redshift of the lens.

To quantify the impact of ﬂexion on the recovery of small-
scale structures, we show in Figure 12 aperture masses for ﬁve
diﬀerent radii (19, 38, 75, 150, and 300 h−1 kpc or 6(cid:48)(cid:48),12(cid:48)(cid:48),24(cid:48)(cid:48),
48(cid:48)(cid:48), 1.6(cid:48)) at the center of the 3 ﬁelds and compare them with
the input aperture masses. As can be seen for all three ﬁelds, the
aperture masses computed for the largest radius, which is above
the arcminute scale coincide between the shear only and com-
bined shear and ﬂexion reconstruction, showing that on large
scales the reconstructions are mostly constrained by the shear
information. Furthermore, above the arcminute scale, the mea-
sured aperture masses are in excellent agreement with the input
masses for all three ﬁelds. The impact of ﬂexion becomes obvi-
ous on small scales where one can see that the aperture masses
are systematically underestimated from the shear only recon-

struction while adding ﬂexion can dramatically improve the re-
covery of small scale details as can be seen for ﬁeld 3.

To illustrate further the impact of ﬂexion on the recovery of
substructure, we also show in Figure 13 the aperture mass at
the same ﬁve radii but for the subhalo visible in the combined
shear and ﬂexion reconstruction of ﬁeld 1. As can be seen in
this ﬁgure, this substructure, which is around the 15(cid:48)(cid:48) scale, is
clearly recovered by the addition of ﬂexion between the 12(cid:48)(cid:48) and
24(cid:48)(cid:48) scale.

6. Conclusion
In this work, we have introduced a new mass-mapping method-
ology, aimed at the recovery of high-resolution convergence
maps from a combination of shear and ﬂexion measurements.
In order to preserve all available small-scale information, our
approach avoids any binning or smoothing of the input lensing
signal and still relies on eﬃcient Fourier estimators despite the
irregular sampling of the shear and ﬂexion ﬁelds. Stating the
mass-mapping problem using Fourier estimators on an irregu-
larly sampled lensing ﬁeld is an ill-posed linear inverse prob-
lem, which we solve using the sparse regularisation framework.
Our full reconstruction algorithm incorporates individual red-
shift, shear and ﬂexion measurements for background galaxies
and accounts for the non-linear reduced shear and ﬂexion. We
deﬁne our sparse regularisation based on a multiscale noise vari-
ance map derived from randomisations of the data which allows
us to tune the regularisation by a single parameter corresponding
to a signiﬁcance level for the detection of structures.

Article number, page 15 of 19

42024Shear aloneField 1Field 2Field 34202442024Shear and flexion combined42024420240.000.060.120.180.240.300.360.420.480.540.60A&A proofs: manuscript no. article

Fig. 12: Aperture masses measured at the centre on the main halo for each ﬁeld and for ﬁve diﬀerent radii: 19, 38, 75, 150, and
300 h−1 kpc or 6(cid:48)(cid:48),12(cid:48)(cid:48),24(cid:48)(cid:48), 48(cid:48)(cid:48), and 1.6(cid:48). The blue circles indicate the masses computed on the shear only reconstructions while
the red triangles indicate the masses computed on the combined shear and ﬂexion reconstructions. Error bars represent the standard
deviation of 100 independent realisations.

We verify that, the shear alone and combined shear and ﬂex-
ion reconstructions agree on scales larger than the arcminute.
This behaviour is expected, by construction, as our algorithm
weighs the shear and ﬂexion information based on their respec-
tive noise levels, promoting shear on large scales and ﬂexion on
small scales. More interestingly, we demonstrate that the inclu-
sion of ﬂexion impacts the recovery of sub-arcminute scales in
two diﬀerent ways. First and foremost, substructures at the 15(cid:48)(cid:48)
scale which are lost when reconstructing from shear alone can
be recovered by the addition of ﬂexion. Second, the inclusion of
ﬂexion allows a much better constraint of the shape of the inner
part of the main halos, in particular we ﬁnd that anisotropies are
more eﬃciently recovered. These results are in good agreement
with the conclusions of Cain et al. (2015), showing the impor-
tance of ﬂexion for the recovery of high resolution maps well
outside of the inner-most regions of clusters where strong lens-
ing prevails.

In the spirit of reproducible research, our C++ implementa-
tion of the mass-mapping algorithm presented in this paper will
be made freely available at:

http://www.cosmostat.org/software/glimpse

The mock catalogues and their corresponding reconstructions as
well as the input convergence maps are available at http://
www.cosmostat.org/product/benchmark_wl.
Acknowledgements. The authors thank Jalal Fadili, Eric Jullo, Fred Ngole,
Chieh-An Lin and Martin Kilbinger for useful comments and discussions.
This work was funded by the Centre Nation d’Etude Spatiale (CNES) and the
DEDALE project, contract no. 665044, within the H2020 Framework Program
of the European Commission.

References
Bacon, D. J., Goldberg, D. M., Rowe, B. T. P., & Taylor, A. N. 2006, Monthly

Notices of the Royal Astronomical Society, 365, 414

Bartelmann, M. 1995, Astronomy and Astrophysics, 303, 643
Bartelmann, M. 2010, Classical and Quantum Gravity, 27, 233001
Beckouche, S., Starck, J. L., & Fadili, J. 2013, Astronomy and Astrophysics,

556, A132

Bradac, M., Lombardi, M., & Schneider, P. 2004, Astronomy and Astrophysics,

424, 13

Fig. 13: Aperture mass for the main subhalo in ﬁeld 1 for ﬁve
diﬀerent radii: 19, 38, 75, 150, and 300 h−1 kpc or 6(cid:48)(cid:48),12(cid:48)(cid:48),24(cid:48)(cid:48),
48(cid:48)(cid:48), and 1.6(cid:48). The blue circles indicate the masses computed on
the shear only reconstructions while the red triangles indicate the
masses computed on the combined shear and ﬂexion reconstruc-
tions. Error bars represent the standard deviation of 100 inde-
pendent realisations.

We demonstrate the eﬀectiveness of this approach for deal-
ing with irregularly sampled data in the simpliﬁed linear case of
reconstructing the convergence from noiseless shear measure-
ment. We show near-perfect recovery of an input convergence
ﬁeld despite 93% of missing data, at a 3(cid:48)(cid:48) resolution with only
30 background galaxies per arcmin2.

In order to test our reconstruction algorithm in a realistic set-
ting and, more importantly, to demonstrate the added value of
ﬂexion, we build a set of mock catalogues corresponding to a
deep HST/ACS survey using as lenses realistic dark matter dis-
tributions extracted from N-Body simulations. We compare the
reconstructions of these simulated ﬁelds with and without the
inclusion of ﬂexion.

Article number, page 16 of 19

1010101110121013Input aperture mass [h−1Mﬂ] 1010101110121013Reconstructed aperture mass [h−1Mﬂ] Field 1Shear onlyShear and Flexion combined1010101110121013Input aperture mass [h−1Mﬂ] 1010101110121013Reconstructed aperture mass [h−1Mﬂ] Field 2Shear onlyShear and Flexion combined1010101110121013Input aperture mass [h−1Mﬂ] 1010101110121013Reconstructed aperture mass [h−1Mﬂ] Field 3Shear onlyShear and Flexion combined1010101110121013Input aperture mass [h−1Mﬂ] 1010101110121013Reconstructed aperture mass [h−1Mﬂ] Shear onlyShear and Flexion combinedF. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

43

40, 120

648, L109

A34

Bradac, M., Schneider, P., Lombardi, M., & Erben, T. 2005, Astronomy and

Cacciato, M., Bartelmann, M., Meneghetti, M., & Moscardini, L. 2006, Astron-

Astrophysics, 437, 39

omy and Astrophysics, 458, 349

Cain, B., Bradac, M., & Levinson, R. 2015, ArXiv e-prints, arXiv:1503.08218
Cain, B., Schechter, P. L., & Bautz, M. W. 2011, The Astrophysical Journal, 736,

Candès, E. J., Wakin, M. B., & Boyd, S. P. 2008, Journal of Fourier Analysis and

Applications, 14, 877

Chambolle, A. & Pock, T. 2011, Journal of Mathematical Imaging and Vision,

Clowe, D., Bradaˇc, M., Gonzalez, A. H., et al. 2006, The Astrophysical Journal,

Condat, L. 2013, Journal of Optimization Theory and Applications, 158, 460
Deriaz, E., Starck, J. L., & Pires, S. 2012, Astronomy and Astrophysics, 540,

Er, X., Li, G., & Schneider, P. 2010, ArXiv e-prints, arXiv:1008.3088
Goldberg, D. M. & Bacon, D. J. 2005, The Astrophysical Journal, 619, 741
Goldberg, D. M. & Leonard, A. 2007, The Astrophysical Journal, 660, 1003
Jullo, E., Pires, S., Jauzac, M., & Kneib, J. P. 2014, Monthly Notices of the Royal

Astronomical Society, 437, 3969

Kaiser, N. & Squires, G. 1993, The Astrophysical Journal, 404, 441
Keiner, J., Kunis, S., & Potts, D. 2009, ACM Transactions on Mathematical Soft-

Klypin, A. A., Trujillo-Gomez, S., & Primack, J. 2011, The Astrophysical Jour-

Leonard, A., Dupé, F.-X., & Starck, J.-L. 2012, Astronomy & Astrophysics, 539,

ware, 36, 1

nal, 740, 102

A85

ical Journal, 666, 17

Society, 405, 1854

Leonard, A., Goldberg, D. M., Haaga, J. L., & Massey, R. 2007, The Astrophys-

Leonard, A. & King, L. J. 2010, Monthly Notices of the Royal Astronomical

Leonard, A., King, L. J., & Wilkins, S. M. 2009, Monthly Notices of the Royal

Leonard, A., Lanusse, F., & Starck, J.-L. 2014, Monthly Notices of the Royal

Astronomical Society, 395, 1438

Astronomical Society, 440, 1281

Astronomical Society, 449, 3393

Massey, R., Williams, L., Smit, R., et al. 2015, Monthly Notices of the Royal

Merten, J., Cacciato, M., Meneghetti, M., Mignone, C., & Bartelmann, M. 2009,

Astronomy and Astrophysics, 500, 681

Moreau, J.-J. 1962, CRAS Sér. A Math., 255, 2897
Okura, Y., Umetsu, K., & Futamase, T. 2007, The Astrophysical Journal, 660,

Paykari, P., Lanusse, F., Starck, J. L., Sureau, F., & Bobin, J. 2014, Astronomy

Pires, S., Starck, J. L., Amara, A., et al. 2009, Monthly Notices of the Royal

Rowe, B., Bacon, D., Massey, R., et al. 2013, Monthly Notices of the Royal

995

and Astrophysics, 566, A77

Astronomical Society, 395, 1265

Astronomical Society, 435, 822

Schneider, P. & Er, X. 2008, Astronomy and Astrophysics, 485, 363
Seitz, C. & Schneider, P. 1995, Astronomy and Astrophysics, 297, 287
Seitz, S. & Schneider, P. 1996, Astronomy and Astrophysics, 305, 383
Starck, J.-l., Murtagh, F., & Fadili, J. 2015, Sparse Image and Signal Processing:
Wavelets and Related Geometric Multiscale Analysis (Cambridge University
Press)

Starck, J. L., Pires, S., & Refregier, A. 2006, Astronomy and Astrophysics, 451,

Viola, M., Melchior, P., & Bartelmann, M. 2012, Monthly Notices of the Royal

Astronomical Society, 419, 2215

Vu, B. C. 2013, Advances in Computational Mathematics, 38, 667

1139

Appendix A: Specialisation of the primal-dual

algorithm

This appendix introduces elements of proximal calculus and de-
scribes the specialisation of the generic primal-dual algorithms
introduced in Condat (2013); Vu (2013) to the speciﬁc weak
lensing mass-mapping problems stated in this paper.

f (x) < +∞} .

Appendix A.1: Elements of proximal calculus
Let H be a ﬁnite-dimensional Hilbert space (in the speciﬁc case
considered in this paper, H = Rn). Let us consider a function
f : H → R ∪ {+∞} and deﬁne the domain of f , noted dom f , as
the subset of H where f does not reach +∞:
dom f = {x ∈ H |
A function f will be said proper if its domain dom f
nonempty. We also deﬁne the epigraph of f , noted epi f :
epi f = {(x, λ) ∈ H × R |
The epigraph is useful to characterise several important proper-
ties, in particular the convexity and lower semicontinuity of f :
epi f is closed ⇔ f is lower semicontinuous
epi f is convex ⇔ f is convex
We will note Γ0 the class of proper lower semicontinuous convex
functions of Rn. Functions in Γ0 are therefore characterised by a
non empty closed convex epigraph.

f (x) ≤ λ} .

(A.3)
(A.4)

(A.2)

(A.1)

is

The proximal operator, introduced by Moreau (1962) is at
the center of the diﬀerent algorithms introduced in the following
sections. This operator, which can be seen as an extension of the
convex projection operator is deﬁned by the following:
Deﬁnition 1. Let F ∈ Γ0. For every x the function y (cid:55)→ 1
2 (cid:107)
x − y (cid:107)2 +F(y) achieves its inﬁmum at a unique point deﬁned as
proxF(x).

Therefore, given a proper lower semicontinuous convex
function F ∈ Γ0, the proximity operator of F is uniquely deﬁned
by:

proxF(x) = arg min

y

(cid:107) y − x (cid:107)2

2

1
2

+F(y) .

(A.5)

In order to illustrate this operator in practice in a simple case,
consider F = iC the indicator function of a closed convex set C.
Then the proximity operator reduces to the orthogonal projector
onto C, noted projC:

proxiC(x) = arg min

y∈C

(cid:107) y − x (cid:107)2

2

1
2

= projC(x) .

(A.6)

Similarly to the simple case of the indicator function, explicit
expressions for the proximity operator exist for a number of dif-
ferent simple functions.

In the context of sparse optimisation, we will be particularly
interested in the proximity operator of the (cid:96)1 norm. Thankfully,
the proximity operator of F(x) = λ (cid:107) x (cid:107)1 is explicit and corre-
sponds to Soft Thresholding:

proxλ(cid:107)·(cid:107)1(x) = STλ(x) ,

(A.7)

Article number, page 17 of 19

A&A proofs: manuscript no. article

where the Soft Thresholding operator STλ is deﬁned for x ∈ RN
as:

∀i ∈ (cid:126)1, N(cid:127),

STλ(x)i =

.

(A.8)

xi − λ

xi + λ

0

if xi ≥ λ
if |xi| ≤ λ
if xi ≤ λ

As previously mentioned, the proximity operator is a key
tool in convex optimisation as it can be used to derive fast con-
vergent algorithms for convex but not necessarily diﬀerentiable
problems. In particular, in this paper we consider optimisation
problems of the following general form:

arg min

x

F(x) + G(W(x)) + H(x)

(A.9)

where F is convex and diﬀerentiable, with a Lipschitzian gradi-
ent of constant β, (H, G) ∈ Γ2
0 and W is a non-zero linear opera-
tor. In our case, F will typically be the χ2 data ﬁdelity term, W
the wavelet transform, and G and H the (cid:96)1 norm and the indica-
tor function respectively, which are convex but not diﬀerentiable.
Proximal algorithm generally rely on an iterative scheme using
the gradient of the ﬁrst term and the proximity operators of the
additional terms. The particular diﬃculty of this problem stems
from the composition of the two operators G and W which does
not possess in the general case an explicit proximity operator
even if proxG has a closed-form expression.

Primal-dual algorithms, such as the one initially proposed in
Chambolle & Pock (2011), avoid this diﬃculty by recasting part
of the problem in a form which allows the separation between
G and W such that a closed-form expression of proxG can be
used if it exists. The main limitation of this algorithm however
is that it does not take advantage of the diﬀerentiability of the
ﬁrst term F. More recently, a variation of this approach was pro-
posed in Condat (2013); Vu (2013), still relying on a primal-dual
formulation for separating G and W but taking full advantage of
the diﬀerentiability of F, thus leading to a much more eﬃcient
algorithm in practice. The main iteration of this minimisation
algorithm for solving Equation A.9 takes the following form:

(cid:16)
(cid:17)
x(k) + τ(∇F(x(k)) − W∗u(k))
u(k) + σW(2x(k+1) − x(k))

(A.10)

proxG∗

u(k+1) =
where τ and σ must verify 1−τσ (cid:107) W (cid:107)2> τβ/2 to ensure conver-
gence and where G∗ is the convex conjugate of the original func-
tion G, deﬁned according to G∗(x) = maxy{< y, x > −G(y)}.
Thankfully, the proximal operator of the convex conjugate is
readily expressible in terms of the proximal operator of the origi-
nal function, with proxG∗(x) = x−proxG(x), so that the proximity
operator of the conjugate can be evaluated at no extra-cost.

x(k+1) = proxτH

(cid:16)

(cid:17)

Appendix A.2: Algorithm specialisation in the simpliﬁed linear

setting

In the simpliﬁed linear setting, deriving the specialisation of
minimisation algorithm introduced in Equation A.10 is straight-
forward. We aim to solve Equation 37, which can be seen as a
specialisation of Equation A.9 for the following choice of oper-
ators:

2

− 1
(cid:107) Σ
γ
κ

1
F(κ) =
2
W(κ) = Φ∗
Applying the Condat (2013); Vu (2013) algorithm introduced
in the previous section is therefore only a matter of computing

=λ (cid:107) w ◦ α (cid:107)1
=i(cid:61)(·)=0(κ)

; G(α)

; H(κ)

2

(cid:2)γ − TPF∗

κ(cid:3) (cid:107)2

Article number, page 18 of 19

F

κ
˜F

(cid:32)(cid:34)
(cid:32)(cid:34)

(cid:35)(cid:33)
(cid:35)(cid:33)

=

+

1
2
1
2

κg

(cid:107) C−1
(cid:107) C−1

(cid:32)(cid:34)

κF

(cid:2)(1 − ZTF∗
(cid:104)
(cid:35)(cid:33)
(1 − ZTF∗
κ
˜F

κ)g − ZTPF∗

κ(cid:3) (cid:107)2
κ)F − ZTF∗ ˜F(cid:105) (cid:107)2

2

2

κ)

γ (γ − TPF∗

the gradient of F and the proximity operators of G∗ and H. The
gradient of the quadratic term F is simply:
∇F(κ) = FP∗T∗Σ−1
while the proximity operators of G and H have a closed-form
expression already introduced in the previous section:
proxG∗(α) = α − STλ◦w(α)
proxH(κ) = (cid:60)(κ)
These expressions for the gradient and proximity operators read-
ily yield algorithm 1 when applied to the iteration introduced in
Equation A.10.

(A.12)
(A.13)

(A.11)

Appendix A.3: Algorithm specialisation for the complete

problem

Contrary to the previous case, solving the full mass-mapping
problem stated in Equation 52 presents a number of diﬃculties.
The specialisation of Equation A.9 diﬀers from the previous case
in the deﬁnition of the diﬀerentiable term F and the convex func-
tion H:

H

= iIm(R)

κ
˜F
Remember that this expression for the quadratic ﬁdelity term
F is a linearisation of the original problem which includes a non-
linear factor due to the reduced shear. However, despite this ﬁrst
simpliﬁcation, the gradient of this expression proves to be prob-
lematic. Since the shear and ﬂexion terms are equivalent and sep-
arable, let us concentrate on the gradient of the shear term of F,
which takes the form:
FP∗T∗ZC−2

(cid:2)(1 − ZTF∗

κg

κ(cid:3)
(cid:2)(1 − ZTF∗

κ)g − ZTPF∗
∗C−2

κg

κ)g − ZTPF∗

(A.14)

+ FT∗Zg

κ(cid:3)

The ﬁrst term of this expression simply corresponds to the same
gradient as in the linear case but corrected for the reduced shear.
In particular, the noise aﬀecting the measured shear still propa-
gates linearly. On the contrary, the second term is new compared
to the linear case and is problematic in the sense that it becomes
a quadratic function of the reduced shear g. If one assumes the
reduced shear noise to be Gaussian, the noise contribution of
this second term becomes χ2 distributed. As explained in sub-
section 3.4, our regularisation scheme is deﬁned in terms of the
standard deviation of the noise propagated to the wavelet coef-
ﬁcients. While this scheme proves very eﬀective for Gaussian
noise, it is not appropriate for χ2 distributed noise.

Therefore, in the approach presented here, we choose to use a
suboptimal gradient for the quadratic data ﬁdelity term by keep-
ing only the ﬁrst term of Equation A.14, which is the price to pay
in order to keep the very eﬀective regularisation scheme intro-
duced in the linear case. Thus, we use the following expression
instead of the exact gradient of F:
(cid:16)
κg ((1 − ZTF∗
∇F = FP∗T∗ZC−2
(1 − ZTF∗

κ)F − ZTF∗ ˜F(cid:17)

κ)g − ZTPF∗

+ FT∗ZC−2

κ)

κF

F. Lanusse , J.-L. Starck , A. Leonard, S. Pires: High Resolution Weak Lensing mass-mapping

Note however that despite this simpliﬁcation, the resulting pro-
cedure still corresponds to the reduced shear correction scheme
suggested in Seitz & Schneider (1995).

The second diﬀerence with the shear only reconstruction
comes from the more complex constraint H based on the indi-
cator function of the image of the linear operator R introduced
in Equation 51. Thankfully, despite the additional complexity,
the proximity operator of this term can still be explicitly from its
deﬁnition:

(cid:32)(cid:34)

(cid:35)(cid:33)

proxiIm(R)

κ
˜F

= arg min
(xκ,xF )

1
2

+iIm(R)

2

(cid:34)
(cid:34)

κ
˜F
κ
˜F

−

xF

(cid:107)2

(cid:35)
(cid:34) xκ
(cid:35)
(cid:34)
(cid:35)
(cid:35)
k2Q−1F∗ ˜F +

FQF∗xκ

−

xκ

(cid:107)

(cid:107)

1

(cid:107)2

2

σ2F
σ2


xF

(cid:32)(cid:34) xκ
(cid:35)(cid:33)
 .


F∗

κ

= R arg min
xκ∈RN×N

= R(cid:60)

F

k2 + σ2F
σ2


In this expression, σ2
 is the variance of the intrinsic ellipticity
and σ2F is the variance of the intrinsic ﬂexion. Let us detail what
is computed by this proximity operator. The ﬁrst step is to rewrite
the proximity operator using its deﬁnition, introduced in Equa-
tion A.5. Then, using the deﬁnition of Im(R), the problem can
be recast in terms of a single real unknown xκ, from which con-
vergence and ﬂexion can be computed by applying the operator
R. Finally, as κ is ﬁtted to the shear and ˜F is ﬁtted to the ﬂex-
ion, solving the minimisation problem for xκ amounts to ﬁnd-
ing the minimum variance ﬁlter combining shear and ﬂexion,
already introduced in Equation 17. To summarise, this operator
computes the optimal combination of the two input variables,
making explicit use of the ﬂexion Fourier operator and its inverse
Q−1 = Q∗/k2, thus eliminating the need to solve this additional
problem as part of the main minimisation problem.
Given these expressions for ∇F and proxiIm(R), the specialisa-

tion of the primal-dual algorithm yields algorithm 2.

Article number, page 19 of 19

