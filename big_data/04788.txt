6
1
0
2

 
r
a

 

M
5
1

 
 
]

M
D
.
s
c
[
 
 

1
v
8
8
7
4
0

.

3
0
6
1
:
v
i
X
r
a

Correspondences between partitions

Roland Glantz, Christian L. Staudt, and Henning Meyerhenke

Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany

1, . . . , P (cid:48)

Abstract. A partition is a subdivision of a set into disjoint subsets
called parts. Partitions are instrumental in tasks such as classiﬁcation,
pattern recognition and network analysis. In the past, a wide spectrum
of similarity measures for pairs of partitions P = {P1, . . . , P|P|} and
P(cid:48) = {P (cid:48)
|P(cid:48)|} of the same set V have been proposed. Such a
measure for the overall similarity of P and P(cid:48), however, does not provide
speciﬁcs on how P and P(cid:48) correspond, e. g. when the union of two parts
in P is similar to that of three parts in P(cid:48).
In this paper, we think of a good correspondence between P and P(cid:48) as a
pair (S,S(cid:48)) with S ⊆ P and S(cid:48) ⊆ P(cid:48) such that the symmetric diﬀerence
between the union of the parts in S and the union of the parts in S(cid:48) has
low cardinality (low total weight if the elements of V are weighted). It
turns out that such an objective function is essentially one for subsets S
of P only, and that it makes sense to call the objective function’s value
for S the fragmentation of S w. r. t. P(cid:48) or the weight of the cut (S,P \S)
w. r. t. P(cid:48).
Thus, we can derive a hierarchy of the |P − 1| best correspondences
from a minimal cut basis of P, i. e. |P − 1| minimal non-crossing Ps-Pt
cuts of P. Since our objective function is symmetric and submodular,
we can compute a minimal Ps-Pt cut in time O(|V |) + |P|4|P(cid:48)|) for all
Ps (cid:54)= Pt ∈ P. To reduce the running time for typical inputs, we present
a branch-and-bound algorithm for ﬁnding minimal Ps-Pt cuts, which
is feasible up to |P|, |P(cid:48)| ≈ 1000 when the entire cut basis is to be
computed. The number of elements in V is practically irrelevant.
Finally, we use correspondences to gain insight into a parallel commu-
nity detection algorithm that is non-deterministic due to race conditions
and that has an optional reﬁnement phase. It turns out that the race
conditions frequently entail unions or break-ups of communities, while
the reﬁnement leaves most communities intact.

Keywords: Correspondences between partitions, symmetric submodular op-
timization, similarity measures for partitions, minimal cuts, branch-and-bound
algorithm

1 Introduction

“One of the most basic abilities of living creatures involves the grouping of sim-
ilar objects . . . ” [4]. Objective and quantitative methods to help humans with

the task of grouping objects in a meaningful way are the subject of cluster anal-
ysis [4], e. g. when organisms are to be grouped according to their genetic simi-
larities, when a classiﬁcation is to be learned, when the pixels/voxels of an image
are to be grouped such that the groups correspond to real-world objects or when
communities in a social network are to be detected. Usually, the parts are non-
overlapping and form a partition of data points into parts/clusters/groups/classes/
cells/regions/communities.
This paper is about a new approach for comparing two partitions P =
{P1, . . . , P|P|} and P(cid:48) = {P (cid:48)
|P(cid:48)|} of the same set. In contrast to similarity
measures for partitions that yield a single number [16,27], we provide speciﬁcs
on how P and P(cid:48) correspond to each other.
More speciﬁcally, a good correspondence is a pair (S,S(cid:48)) with S ⊆ P, S(cid:48) ⊆ P(cid:48)

1, . . . , P (cid:48)

and a low value of

φP,P(cid:48)(S,S(cid:48)) := |US(cid:52)US(cid:48)|,

(1.1)
where US denotes the union of all sets in S, (cid:52) denotes the symmetric diﬀerence,
and | · | denotes cardinality [total weight] if the elements of V are unweighted
[weighted]. Thus, minimizing φP,P(cid:48)(·,·) amounts to ﬁnding similarities between
P and P(cid:48) modulo unions of parts.
If P and P(cid:48) are partitions of sets that are diﬀerent but have a large intersec-
tion, W , it may be appropriate to turn P and P(cid:48) into the two related partitions
|P(cid:48)| ∩ W}. If W is large enough,
{P1 ∩ W, . . . , P|P| ∩ W} and {P (cid:48)
the correspondences between the two new partitions will still reveal speciﬁcs on
similarities between P and P(cid:48).

1 ∩ W, . . . , P (cid:48)

Correspondences in image segmentation. For the sake of graphic power we turn
to applications in which P and P(cid:48) are segmentations, i. e. partitions of a set of
pixels/voxels into regions (actual use of correspondences in this paper will be in
community detection, see Section 5.3).
We assume that P and P(cid:48) are based on the same image or, if they are based
on diﬀerent images, that the latter have the same resolution and picture the
same scene. Ideally, a region corresponds to a real-world object, but ﬁnding such
regions is hindered by noise, under-segmentation, over-segmentation or occlusion.
Scenarios in which it makes sense to compare P and P(cid:48) using correspondences
can be as follows.
1. P is the result of a segmentation algorithm and P(cid:48) describes ground truth,
e. g. if P is a segmented satellite image and if P(cid:48) describes land use that has
been determined in the ﬁeld by experts. Here, the aim of a comparison might
be to identify areas where P suﬀers from over-segmentation (unions of regions
of P that correspond well to single regions of P(cid:48)), from under-segmentation
(single regions of P that correspond well to unions of regions of P(cid:48)) or more
intricate combinations of over-segmentation and under-segmentations, i. e.
good correspondences (S,S(cid:48)) with |S|,|S(cid:48)| > 1. There may also be areas
in which there are no good correspondences, i. e. where the segmentation
algorithm fails completely.

2

Fig. 1. Top: Two segmentations (by hand) of the same image. Poor match between
individual regions left and right. Bottom: A good correspondence.

2. P and P(cid:48) describe ground truth at diﬀerent times. Sticking to land use, a
good correspondence (S,S(cid:48)) with |S|,|S(cid:48)| > 1 may indicate crop rotation.
3. P and P(cid:48) are results of diﬀerent segmentation algorithms applied to the
same image, and/or the two segmentations are based on diﬀerent physical
measurements, e. g. channels in Satellite Imagery or CT vs. MRI in medical
imaging. Then, a good correspondence (S,S(cid:48)) provides strong evidence that
the feature described by S is not an artifact. For an example of correspon-
dences between diﬀerent segmentations see Figure 1.

Contributions. Our ﬁrst contribution is to show that minimizing φP,P(cid:48)(S,S(cid:48)) in
Equation (1.1) under the restriction ∅ (cid:54)= S (cid:40) P essentially amounts to minimiz-
ing a function that does not depend on S(cid:48) anymore. In particular, it turns out
that

φP,P(cid:48)(S) := minS(cid:48)⊆P(cid:48) φP,P(cid:48)(S,S(cid:48))
|P (cid:48)| peak(

=

|US ∩ P (cid:48)|

), where

(1.2)

(1.3)

(1.4)

|P (cid:48)|
if x ≤ 1/2,
if x > 1/2.

(cid:88)
(cid:40)

P (cid:48)∈P(cid:48)

x,
1 − x,

peak(x) =

The value φP,P(cid:48)(S) can be seen as the fragmentation of S w. r. t. P(cid:48) or as the
weight of the cut (S,P \ S) w. r. t. P(cid:48). An optimal partner S(cid:48) of S, see Equa-
tion (1.2), then is

3

S(cid:48) = {P (cid:48) ∈ P(cid:48) : |US ∩ P (cid:48)| >

(1.5)
Thus, we reduce the problem of ﬁnding good correspondences (S,S(cid:48)) to the
problem of ﬁnding ∅ (cid:54)= S (cid:40) P that give rise to small cuts (S,P \S). It turns out
that φP,P(cid:48)(·) is a symmetric submodular function, see Section 3.1.

|P (cid:48)|
2

}.

Using results from symmetric submodular minimization, our second contri-
bution consists in deriving an asymptotic time and space complexity for mini-
mizing fragmentation under the constraint that S is nontrivial. Speciﬁcally, we
show that ∅ (cid:54)= S (cid:40) P minimizing φP,P(cid:48)(·) can be found in time O(|V |+|P|4|P(cid:48)|),
where V is the ground set of P and P(cid:48). This is done in Sections 3.2 and 3.3.
To make the detection of good correspondences practical, our third contri-
bution is an eﬃcient method to compute a basis of minimal Ps-Pt cuts of P
w. r. t. P(cid:48). This cut basis gives rise to the |P|− 1 best correspondences via Equa-
tions (1.2) and (1.5). We ﬁrst show that ﬁnding such a basis requires |P| − 1
computations of certain minimal Ps-Pt cuts. We then present a branch-and-
bound algorithm to compute a minimal Ps-Pt cut for any pair Ps (cid:54)= Pt, see
Section 4.2. We test the performance of our algorithm in Section 5.2. As an ex-
ample, computing the |P| − 1 best correspondences between two partitions with
100 parts each takes only 11 seconds, even if the best correspondence is well
hidden and involves large S, S(cid:48).

Our fourth contribution is to the ﬁeld of community detection. Typically, a
community is a densely connected set of nodes with sparse connections to the
rest of the network (for surveys on methods to ﬁnd communities see [19,5]).
In Section 5.3 we use correspondences to gain insight into the behavior of a
community detection algorithm [3] and an extension thereof [22]. Speciﬁcally, we
compare two eﬀects on the resulting partitions: (i) the eﬀect of race conditions
that occur during the parallel execution of the algorithm and (ii) the eﬀect
of an optional reﬁnement phase. It turns out that the overall quality of the
correspondences due to these eﬀects is on the same order, that the race conditions
lead to many unions and break-ups of communities, but that the reﬁnement
phase leaves most communities intact.

2 Examples of correspondences and cuts

2.1 Correspondences

Figure 2 depicts two partitions of a set V with 31 elements. Speciﬁcally, we have a
5} at the bottom.
partition P = {P1, . . . P6} on top and a partition P(cid:48) = {P (cid:48)
The elements of V are represented by symbols indicating membership to the
parts of P. The four nontrivial subsets of P with minimum fragmentation (value
is 2) are the subsets {P1, P2} and {P5, P6}, as well as the complements of these
subsets. The best partners (see Equation (1.5)) of the former two subsets are the
1})
1} and {P (cid:48)
subsets {P (cid:48)
4, P (cid:48)
5}), respectively (dissimilarity is 2 in both cases). The best
and ({P5, P6},{P (cid:48)
4, P (cid:48)
3}.
partner of {P4} is {P (cid:48)

5}, giving rise to the correspondences ({P1, P2},{P (cid:48)

1, . . . P (cid:48)

4

Fig. 2. Upper [lower] row of six [ﬁve] disks depicts partition P [P(cid:48)]. Upper [lower]
brackets indicate subsets of P [P(cid:48)], and arrows indicate some good correspondences
between subsets of P and those of P(cid:48) (see the text).

Fig. 3. Same scenario as in Figure 2 with the roles of P and P(cid:48) exchanged.

If we reverse the roles of P and P(cid:48) (see Figure 3), the counterparts of the
best nontrivial correspondences from before are the new best nontrivial corre-
5},{P5, P6}). The counterpart of
spondences, e. g. ({P (cid:48)
the correspondence ({P4},{P (cid:48)
3}), however, is gone. Indeed, the best partner of
S(cid:48) = {P (cid:48)
3(cid:52)∅| = 4 < 5 = |P (cid:48)
3(cid:52)P4|. Hence,
we should be aware that reversing the roles of P and P(cid:48) cannot always be com-
pensated by swapping S and S(cid:48) in a correspondence.

4, P (cid:48)
3} is not {P4} but ∅. In particular, |P (cid:48)

1},{P1, P2}), and ({P (cid:48)

2.2 Basis of minimal Ps-Pt cuts
The |P| − 1 best correspondences that we calculate in this paper can be derived
from a basis of minimal Ps-Pt cuts. Speciﬁcally, a minimal Ps-Pt cut (S,P \ S)
from the basis gives rise to the correspondence (S,S(cid:48)), where S(cid:48) is determined
by Equation (1.5).

Such a basis of minimal Ps-Pt cuts, in turn, can be represented by an edge-
weighted tree called Gomory-Hu tree [10]. For an exact deﬁnition of Gomory-Hu
trees and proof of the statements below see Deﬁnition 5 and Proposition 5. For
examples of Gomory-Hu trees see Figures 4a,c. A Gomory-Hu tree is a very
concise representation of all minimal Ps-Pt cuts and, in conjunction with Equa-
tion (1.5), gives rise to the entire hierarchy of the |P| − 1 best correspondences.

5

614352PPPPPPP’P’P’P’P’43215’OP’432P’1563145PPPPPPP’2P’P’’(a)

(b)

(c)

(d)

Fig. 4. P and P(cid:48) are as in Figures 2 and 3. (a) Gomory-Hu tree of best cuts of P
w. r. t. P(cid:48) and (b) hierarchical decomposition of P. (c) Gomory-Hu tree of best cuts of
P(cid:48) w. r. t. P and (d) hierarchical decomposition of P(cid:48).

The nodes of a Gomory-Hu tree TP|P(cid:48) represent the parts of P (see Fig-
ures 4a,c.), and the edges of TP|P(cid:48) represent minimal Ps-Pt cuts in the following
way. Removal of an edge {Ps, Pt} from TP|P(cid:48) results in two subtrees, one span-
ning a subset S of P, and the other spanning P \ S. This deﬁnes the Ps-Pt cut
(S,P\S) that is always a minimal Ps-Pt cut. As an example, removal of the edge
between (cid:78) and (cid:3) in Figure 4a gives rise to the cut that separates the triangles
from the other shapes. This cut is a minimal (cid:78)-(cid:3) cut.
The edge weights of TP|P(cid:48) are such that for any Ps (cid:54)= Pt ∈ P, not necessarily
connected by an edge of TP|P(cid:48), we have that (i) an edge on the unique path from
Ps to Pt with minimal weight w gives rise to a minimal Ps-Pt cut, and (ii) the
weight of this cut is w. As an example, a minimal P1-P4 cut of P, as shown in
Figure 2, is given by the edge between (cid:78) and (cid:3) in Figure 4a, and the weight of
this cut is 2.
The Gomory-Hu tree of the |P|− 1 = 5 best cuts of P is shown in Figure 4a.
A dendrogram of the hierarchical decomposition of P, as determined by the ﬁve
best cuts, is shown in Figure 4b. Figures 4c,d are the corresponding ﬁgures for
P(cid:48) instead of P.

3 Finding an optimal correspondence

3.1 Correspondences from fragmentation minimization
Recall that the union of the parts in some S ⊆ P is denoted by US . We want to
minimize φP,P(cid:48)(S,S(cid:48)) = |US(cid:52)US(cid:48)|, where S ⊆ P and S(cid:48) ⊆ P(cid:48).
The solutions (S,S(cid:48)) with S ∈ {∅,P} ∧ S(cid:48) ∈ {∅,P(cid:48)}, however, are not useful
and should be excluded. We ﬁrst exclude even more solutions, but we will make
up for this below when we exchange the roles of P and P(cid:48).

6

45522Φ 0  1  2  3  4  5 2542 0  1  2  3  4  5 ΦDeﬁnition 1 (Eligible pair (S,S(cid:48)), optimal pair (S,S(cid:48))). A pair (S,S(cid:48))
with S /∈ {∅,P} is called eligible for φP,P(cid:48)(·,·). An eligible pair (S,S(cid:48)) is called
optimal for φP,P(cid:48)(·,·) if φP,P(cid:48)(S,S(cid:48)) is minimal w. r. t. all eligible pairs.

Exchanging the roles of P and P(cid:48) (compare Figures 2 and 3) yields a diﬀe-
rent optimization problem since eligibility is not symmetric. Now, among all
useful pairs, i. e. pairs (S,S(cid:48)) with S /∈ {∅,P} ∨ S(cid:48) /∈ {∅,P(cid:48)}, a pair (S,S(cid:48))
minimizes |US(cid:52)US(cid:48)| if and only if (S,S(cid:48)) is an optimal pair for φP,P(cid:48)(·,·) or
(S(cid:48),S) is an optimal pair for φP(cid:48),P (·,·). The following results on φP,P(cid:48)(S,S(cid:48))
yield corresponding results on φP(cid:48),P (S(cid:48),S).
Proposition 1 (From φP,P(cid:48)(·,·) to φP,P(cid:48)(·)). An optimal pair (S,S(cid:48)) of φP,P(cid:48)(·,·)
can be found by ﬁrst ﬁnding ∅ (cid:54)= S (cid:40) P that minimizes

(cid:88)
(cid:40)

P (cid:48)∈P(cid:48)

φP,P(cid:48)(S) :=

peak(x) :=

x,
1 − x,

if x ≤ 1/2
if x > 1/2

.

|P (cid:48)| peak(

|US ∩ P (cid:48)|

|P (cid:48)|

), where

(3.1)

and then setting

S(cid:48) := {P (cid:48) ∈ P(cid:48) : |US ∩ P (cid:48)| >

|P (cid:48)|
2

}.

Proof: Starting with Equation (1.1), we get

(3.2)

(3.3)

(3.4)

(3.5)

(3.6)

min{|US ∩ P (cid:48)|,|P (cid:48)| − |US ∩ P (cid:48)|}
, 1 − |US ∩ P (cid:48)|
|P (cid:48)| min{|US ∩ P (cid:48)|
|P (cid:48)|
|P (cid:48)|
|US ∩ P (cid:48)|

|P (cid:48)| peak(

|P (cid:48)|

).

}

(3.7)

(3.8)

(3.9)

(cid:117)(cid:116)

7

φP,P(cid:48)(S,S(cid:48)) = |US \ US(cid:48)| + |US(cid:48) \ US|

= |US ∩ (V \ US(cid:48))| +

|P (cid:48) \ US|

|US ∩ P (cid:48)| +

(|P (cid:48)| − |US ∩ P (cid:48)|).

(cid:88)
(cid:88)

P (cid:48)∈S(cid:48)

P (cid:48)∈S(cid:48)

By choosing S(cid:48) as in Equation (3.3), we minimize the contribution (damage)
of each P (cid:48) ∈ P(cid:48) to the right hand side of Equation (3.6), and thus minimize
φP,P(cid:48)(S,·). Insertion of S(cid:48) from Equation (3.3) then yields

(cid:88)

=

P (cid:48) /∈S(cid:48)

P (cid:48)∈P(cid:48)

(cid:88)
(cid:88)
(cid:88)

P (cid:48)∈P(cid:48)

P (cid:48)∈P(cid:48)

minS(cid:48)⊆P(cid:48) φP,P(cid:48)(S,S(cid:48)) =

=

=

Recall that we refer to φP,P(cid:48)(S) as the fragmentation of S w. r. t. P(cid:48) or the
weight of the cut (S,P \ S) w. r. t. P(cid:48).
The function peak(·) in Equation (3.2), called (classiﬁcation) error in [26],
is an example of a generator as deﬁned in [21]: a function f : [0, 1] (cid:55)→ R is a
generator if it is concave and f (0) = f (1) = 0 (hence f (·) is also subadditive). In
addition, peak(·) is symmetric, i. e. peak(p) = peak(1− p) for all p ∈ [0, 1]. Other
examples of symmetric generators are the binary entropy function H(·) [15,26,21]
and the Gini impurity measure G(·) [26,21]. We could have chosen H(·), G(·) or
any other nontrivial symmetric generator (computable in constant time) instead
of peak(·). The minimization of Equation (3.1) would then have the same asymp-
totic time complexity (see Section 3.3). We choose peak(·) because it is in line
with minimizing |US(cid:52)US(cid:48)|.

3.2 Fragmentation minimization and submodularity
Deﬁnition 2 (Symmetric, submodular, modular). Let P be a set. A func-
tion φ : 2P (cid:55)→ R is called symmetric if φ(S) = φ(P \ S) for all S ⊆ P. Further-
more, φ(·) is called submodular if

φP,P(cid:48)(S1 ∪ S2) ≤ φP,P(cid:48)(S1) + φP,P(cid:48)(S2) − φP,P(cid:48)(S1 ∩ S2) ∀S1,S2 ⊆ P.
If φ(·) fulﬁlls the above with “=” instead of “≤”, then φ(·) is called modular.
Proposition 2. φP,P(cid:48)(·) in Equation (3.1) is symmetric and submodular.
Proof: The symmetry of φP,P(cid:48)(·) follows from that of peak(·). Sums and multi-
ples of submodular functions are submodular [20]. Thus, to show that φP,P(cid:48)(·)
is submodular, it suﬃces to show that φi(S) := peak(
) in Equation (3.1)
is submodular for all i.
Indeed, the φi(·) are of the form c(m(·)), where c(·) is concave and m(·) is
(cid:117)(cid:116)

non-negative modular. Any function of this form is submodular [24,2].

|US∩P (cid:48)
i|
|P (cid:48)
i|

3.3 Asymptotic running time for ﬁnding an optimal pair
In order to eﬃciently compute the terms |US ∩ P (cid:48)| in Equations (3.1) and (3.3),
we ﬁrst compute the columns of the contingency table of P and P(cid:48), i. e. the
table (matrix) whose entry at (i, j) equals |Pi ∩ P (cid:48)
j|. We refer to these columns
as distributions over P.
Deﬁnition 3 (Distributions dP (cid:48)[·]). Let P (cid:48) ∈ P(cid:48). The distribution of P (cid:48)
w. r. t. P is the vector dP (cid:48)[·] of length |P| deﬁned by

dP (cid:48)[i] := |Pi ∩ P (cid:48)| for 1 ≤ i ≤ |P|.

(3.10)
Proposition 3. Calculation of all distributions can be done in time O(|P||P(cid:48)|+
|V |) and with space O(|P||P(cid:48)|). Furthermore, given all distributions and S ⊆ P,
the determination of S(cid:48), as deﬁned in Equation (3.3), and the evaluation of
φP,P(cid:48)(S), as deﬁned in Equation (3.1), can both be done in time O(|P||P(cid:48)|) and
with space O(|P(cid:48)|).

8

all |US ∩P (cid:48)|, P (cid:48) ∈ P(cid:48), in time O(|P||P(cid:48)|) (due to |US ∩P (cid:48)| =(cid:80)

Proof: We ﬁrst show that all distributions dP (cid:48)[·] can be computed in time
O(|P||P(cid:48)| +|V |). Indeed, the ﬁrst summand is due to initializing all dP (cid:48)[·] to zero
vectors, and the second summand is due to updating the distributions, which can
be done in one traversal of V (deciding on membership of any v ∈ V to a part in
P and P(cid:48) takes constant time). The asymptotic space requirement for calculating
all distributions equals that for storing the distributions, i. e. O(|P||P(cid:48)|).
Using the distributions we can compute, for any given S ⊆ P, the values of
i:Pi∈S dP (cid:48)[i]). The
space requirement for this step is O(|P(cid:48)|). Based on the values of |US ∩ P (cid:48)|, the
determination of S(cid:48) via Equation 3.3, as well as the evaluation of φP,P(cid:48)(S,S(cid:48))
via Equation (3.6), takes time and space O(|P(cid:48)|).
Recall that φP,P(cid:48)(S,S(cid:48)) in Equation (3.6) equals φP,P(cid:48)(S) in Equation (3.1).
Thus, given the distributions and some S ⊆ P, the total time and space require-
ments for evaluating φP,P(cid:48)(S) are O(|P||P(cid:48)|) and O(|P(cid:48)|), respectively.
(cid:117)(cid:116)
In the proofs of Propositions 4 and 5 we refer to Algorithm OPTIMAL-SET
from [17], where a symmetric submodular function f (·) is minimized by build-
ing the set minimizing f (·) from scratch. OPTIMAL-SET consists of O(|P|3)
evaluations of φP,P(cid:48)(·), see Theorem 3 in [17].
Proposition 4. Finding an optimal pair (S,S(cid:48)) takes time O(|V |) + |P|4|P(cid:48)|)
and space O(|P||P(cid:48)|) + O(|P|2).

Proof: Due to Proposition 2 of this paper, Theorem 3 in [17] (which uses
OPTIMAL-SET) and Proposition 3 of this paper, the asymptotic running time
for minimizing Equation (3.1) with the constraint S /∈ {∅,P} amounts to O(|V |+
|P|3|P||P(cid:48)|) = O(|V | + |P|4|P(cid:48)|). The space requirement in [17] is O(|P|2)
(cid:117)(cid:116)
(needed to store the candidate subsets in Algorithm OPTIMAL-SET).

4 Minimal Ps-Pt cuts
We are not only interested in the best correspondence between P and P(cid:48), but
in a larger set of good correspondences. Proposition 1 says that ﬁnding good
correspondences basically amounts to ﬁnding small cuts of P w. r. t. P(cid:48). A natural
basis of small cuts is formed by the minimal Ps-Pt cuts deﬁned in the following
subsection.

4.1 Basis of minimal Ps-Pt cuts
Deﬁnition 4 ((Minimal) Ps-Pt cut (Ss,St), weight λs,t). Let Ps (cid:54)= Pt ∈ P.
Any pair (Ss,St) with Ps ∈ Ss, Pt ∈ St and St = P \ Ss is called a Ps-Pt cut of
P. A Ps-Pt cut (Ss,St) is minimal if φP,P(cid:48)(Ss), and thus φP,P(cid:48)(St), is minimal
w. r. t. all Ps-Pt cuts. Finally, for any s (cid:54)= t ∈ {1, . . . ,|P|} we set
λs,t := min{φP,P(cid:48)(Ss) : (Ss,P \ Ss) is a Ps-Pt cut}.

(4.1)

9

We are interested in minimal Ps-Pt cuts for all s (cid:54)= t ∈ {1, . . .|P|}. Analo-
gous to graphs, such a set of minimal cuts can be represented by a Gomory-Hu
tree [10].

Deﬁnition 5 (Gomory-Hu tree TP|P(cid:48) = (VT , ET , ωφ)).
TP|P(cid:48) = (VT , ET , ωφ) is an edge weighted tree with vertex set VT = {1, . . .|P|},
edge set ET and a function ωφ : ET (cid:55)→ R≥0 such that for all s (cid:54)= t ∈ VT

λs,t = min{ωφ(e) : e ∈ Πs,t}, where

(4.2)

Πs,t is the set of edges forming the unique path from s to t on TP|P(cid:48).
Proposition 5. There exists at least one Gomory-Hu tree TP|P(cid:48), and such a
Gomory-Hu tree can be computed in O(|V | + |P|5|P(cid:48)|).
Proof: As shown in [8], the existence of TP|P(cid:48) follows from φP,P(cid:48)(·) being sym-
metric and submodular. A Gomory-Hu tree TP|P(cid:48) can be built by computing
|P| − 1 minimal Ps-Pt cuts, and this is also what determines the asymptotic
running time for building a Gomory-Hu tree [9]. To compute a minimal Ps-Pt
cut we may again use Algorithm OPTIMAL-SET [17]. The only diﬀerence is
that we require s in the set and t to be in the complement of the set. This does
not change the asymptotic running time of OPTIMAL-SET.

Recall that the asymptotic running times from Propositions 3 and 4 are based
on the use of OPTIMAL-SET. Thus, considering that we need to compute the
distributions dP (cid:48)[i], 1 ≤ i ≤ |P|, only once, it follows that we can compute TP|P(cid:48)
in O(|V | + (|P| − 1)(|P|4|P(cid:48)|)) = O(|V | + |P|5|P(cid:48)|).
(cid:117)(cid:116)
A Gomory-Hu tree TP|P(cid:48) gives rise to a hierarchical partition of P if edges
from TP|P(cid:48) are removed in ascending order of ωφ(·). For examples of dendrograms
depicting such hierarchical partitions see Figure 4b,d.

4.2 Finding minimal Ps-Pt cuts by branch-and-bound

Using OPTIMAL-SET, the computation of one minimal Ps-Pt cut takes time
O(|V | + |P|4|P(cid:48)|), see Proposition 4. This is problematic for high |P|. The fol-
lowing branch-and-bound algorithm for ﬁnding a minimal Ps-Pt cut turns out
to be practical, although we cannot give guarantees on its running time.
Let Ps (cid:54)= Pt ∈ P. The idea behind our algorithm to ﬁnd a minimal Ps-Pt cut
(Ss,St) is to ﬁrst set Ss := {Ps}, St := {Pt} and then let Ss and St compete
.∪ St = P. We assure that Ss ∩ St = ∅ at
for the remaining parts in P until Ss
all times. To curtail the exponentially growing number of possibilities that arise
when assigning new parts, i. e. parts in P \ (Ss
.∪ St), to either Ss or St, we need
a bound b(Ss
.∪ St) on how low φP,P(cid:48)(S) can possibly get for S with Ss ⊆ S
and S ∩ St = ∅. Proposition 6 below guarantees that the bound deﬁned next is
admissible.
Deﬁnition 6. Let Ss,St ⊆ P with Ps ∈ Ss, Pt ∈ St and Ss ∩ St = ∅. We set

min{|USs ∩ P (cid:48)|,|USt ∩ P (cid:48)|}.

(4.3)

10

b(Ss,St) :=

(cid:88)

P (cid:48)∈P(cid:48)

Proposition 6. Let Ss,St ⊆ P with Ps ∈ Ss, Pt ∈ St and Ss ∩St = ∅. Further-
more, let S ⊇ Ss, S ∩ St = ∅. Then, b(Ss,St) ≤ φP,P(cid:48)(S).
Proof:

φP,P(cid:48)(S) =

=

(cid:88)
(cid:88)
(cid:88)

P (cid:48)∈P(cid:48)

=
≥ b(Ss,St).

P (cid:48)∈P(cid:48)

P (cid:48)∈P(cid:48)

|US ∩ P (cid:48)|

|P (cid:48)| peak(
|P (cid:48)|
|P (cid:48)| min{|US ∩ P (cid:48)|
|P (cid:48)|
|P (cid:48)|
min{|US ∩ P (cid:48)|,|UP\S ∩ P (cid:48)|}

)
|UP\S ∩ P (cid:48)|

,

}

(4.4)

(4.5)
(cid:117)(cid:116)

We still have to make decisions on
1. the choice of the next part P from P \ (Ss
2. whether we assign P to Ss or St.

Ss or St and

.∪ St) that we use to extend either

Our strategy for item 2.) above is to assign P to Ss or St according to
the (optimistic) prospect b(Ss,St), i. e. P is assigned such that the new value
b(Ss,St) is minimal. We prefer minimizing b(Ss,St) over minimizing φP,P(cid:48)(Ss)
and/or φP,P(cid:48)(St) because the latter two numbers can both be high although the
prospect for ﬁnding a good cut of P is still good. Due to the symmetry of φP,P(cid:48)(·),
however, the objectives of minimizing b(Ss,St), φP,P(cid:48)(Ss) and φP,P(cid:48)(St) will
have converged by the time when Ss and St are fully grown, i. e. Ss
.∪ St = P.
Our strategy for item 1.), i. e. the choice of P , aims at shifting the backtrack-
ing phases of our branch-and-bound algorithm to scenarios in which Ss and St
are already large and where chances are that we are close to a new minimum
of φP,P(cid:48)(·). To this end, we pick P from P \ (Ss
.∪ St) such that the alterna-
tive between putting P into Ss or into St matters the most in terms of b(·,·).
Formally,

(4.6)

.∪St) |b(Ss

P = argmaxP∈P\(Ss

.∪ {P},St) − b(Ss,St

Algorithm greedy(Ss,St, bestSoF ar) terminates prematurely, i. e. with Ss

.∪ {P})|
Algorithm 1 summarizes the way in which we extend a pair (Ss,St).
.∪
St (cid:54)= P, if there is no chance to ﬁnd S with φP,P(cid:48)(S) < bestSoF ar. In the
ﬁrst call of greedy(Ss,St, bestSoF ar) we have Ss = {Ps}, Ss = {Ps} and
bestSoF ar = ∞. In particular, greedy({Ps},{Pt},∞) does not end prematurely,
i. e. it delivers a Ps-Pt cut (S,P \ S).
After initializing Ss and St, our branch-and-bound algorithm, see Algo-
rithm 2, calls greedy(Ss,St,∞). In later calls of greedy(Ss,St, bestSoF ar) we
always have (Ss (cid:41) {Ps} ∨ St (cid:41) {Pt}) ∧ Ss ∩ St = ∅, and bestSoF ar amounts to
the minimum weight (φP,P(cid:48) value) of the Ps-Pt cuts found so far (see lines 5-10
of Algorithm 2). Two crucial questions after any call of greedy are

11

Algorithm 1 Algorithm greedy(Ss,St, bestSoF ar) for extending a pair (Ss,St)
with Ss ∩ St = ∅ towards a pair (S,P \ S) with S ⊇ Ss and S ∩ St = ∅ as long
as there is a chance that φP,P(cid:48)(S) < bestSoF ar.
.∪ St (cid:54)= P) ∧ b((Ss,St) < bestSoF ar) do
1: while (Ss
Find P ∈ P \ (Ss
2:
if b(Ss
.∪ {P},St) < b(Ss,St
3:
.∪ {P}
4:
5:
.∪ {P}
6:
end if
7:
8: end while

.∪ St) that fulﬁlls Equation (4.6).

Ss ← Ss
St ← St

.∪ {P}) then

else

greedy(Ss,St, bestSoF ar)
if Ss

Algorithm 2 Branch-and-bound algorithm for ﬁnding a minimal Ps-Pt cut.
1: Ss ← {Ps}, St ← {Pt}
2: bestSoF ar ← ∞
3: do
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:

.∪ St = P then
S ← Ss
bestSoF ar ← b(Ss,St)

if b(Ss,St) < bestSoF ar then

(cid:46) i. e. we have found a Ps-Pt cut
(cid:46) b(Ss,St) = φP,P(cid:48) (Ss) = φP,P(cid:48) (St)

end if
i ← 0
do

(cid:46) Beginning of undo

end if

if ˆP|Ss

else

14:

15:

.∪St|−2−i ∈ Ss then
.∪St|−2−i

Ss ← Ss \ ˆP|Ss
St ← St \ ˆP|Ss

.∪St|−2−i

end if
i ← i + 1

16:
17:
18:
19:
20:
21:
22:
23: while (Ss,St) (cid:54)= ({Ps},{Pt})
24: return (S,P \ S)

(Ss,St) ← A(Ss,St)

end if

while (Ss,St) (cid:54)= ({Ps},{Pt}) ∧ dejaVu(A(Ss,St))
if (Ss,St) (cid:54)= ({Ps},{Pt}) then

(cid:46) i. e. ˆP|Ss

.∪St|−2−i ∈ St

(cid:46) End of undo

1) whether greedy(·,·,·) needs to be invoked again and, if so,

2a) which of the most recent assignments of parts (to Ss or St) should be

undone in a backtracking step and
2b) which alternative line for searching a minimal Ps-Pt cut is taken after
backtracking, i. e. what is the input of greedy(·,·,·) when it is called the
next time.

12

The answer to 1) is “as long as Ss (cid:41) {Ps} or St (cid:41) {Pt}”. In other words, we
stop when (Ss,St) has shrunk to its initialization ({Ps},{Pt}) (see lines 3 and
23 of Algorithm 2). The following notation and deﬁnition will make it easier to
answer the remaining questions.
Notation 4.1 W. l. o. g. the parts in Ss
ˆP1, . . . , ˆP|Ss
to Ss \ {Ps} or St \ {Pt} (the larger an index, the later the part was added).
Deﬁnition 7 (Alternative A(Ss,St) to (Ss,St)).
If ˆP|Ss
(Ss \ { ˆP|Ss
If ˆP|Ss
(Ss

.∪St|−2 is contained in Ss, the alternative to (Ss,St) is

.∪St|−2 is contained in St, the alternative to (Ss,St) is

.∪St|−2, and the indices reﬂect the order in which the parts were added

.∪ St \ {Ps, Pt} are denoted by

.∪St|−2},St \ { ˆP|Ss

.∪ { ˆP|Ss
The answer to 2a) now is “Undo the assignment of ˆP|Ss

.∪St|−2}).

.∪St|−2. Keep un-
.∪St|−2−i, i ≥ 1, is reached such
doing the latest assignments until some ˆP|Ss
that greedy(·,·,·) has not yet been called with the ﬁrst two arguments given
by A(Ss,St).” In the pseudocode of Algorithm 2, a boolean function called
dejaVu(·,·) is used to express whether A(Ss,St) has entered the call of greedy(·,·,·)
before, see line 19 of Algorithm 2. This line guarantees termination of our branch-
and-bound algorithm. The answer to 2b) then is “call greedy(·,·,·) with A(Ss,St)
and the current value of bestSoF ar” (see lines 21 and 4 of Algorithm 2).

.∪St|−2},St

.∪ { ˆP|Ss

.∪St|−2}).

We conclude this section with two implementation details.
– We implement the boolean function dejaVu(·,·) as a boolean vector called
doneW ith[·]. The two arguments Ss, St of dejaVu(·,·) correspond to a single
.∪ St \ {Ps, Pt}
index i of doneW ith. Speciﬁcally, i is the cardinality of Ss
or, equivalently, the highest index, |Ss
.∪ St|− 2, in Notation 4.1. The vector
doneW ith has length |P| − 2, and its entries are initialized to false. Any-
time greedy(·,·,·) is called with (Ss,St) = A( ˆSs, ˆSt) for some ˆSs, ˆSt ⊂ P,
doneW ith[i] is set to true. Furthermore, if backtracking goes back behind an
index j, doneW ith[j] is set to false.
– For eﬃcient updates of b(Ss,St) in Algorithm 2, i. e. when Ss or St grows
or shrinks by one part, we use distributions as in Section 3.3 — this time
the rows of the contingency table of P and P(cid:48). Speciﬁcally, let P ∈ P.
Then dP [·] is a vector of length |P(cid:48)| deﬁned by dP [j] := |P ∩ P (cid:48)
j| for 1 ≤
dP . Now, adding or removing a part P
from Ss corresponds to the command dSs ← dSs + dP and dSs ← dSs − dP ,
respectively. By carrying along dSs and dSt, we can compute the bounds
b(·,·) as follows.

j ≤ |P(cid:48)|. We deﬁne dSs := (cid:80)

P∈Ss

b(Ss,St) =

min{dSs[j], dSt[j]}.

(4.7)

|P(cid:48)|(cid:88)

j=1

13

Such an implementation is also advantageous for parallel processing.

5 Experiments

The purpose of the experiments of Section 5.2 is to test the limits of the branch-
and-bound algorithm described in Section 4.2. In Section 5.3 we use correspon-
dences to gain insight into the behavior of a community detection algorithm and
an extension thereof.

5.1 Settings and implementation

All computations were done on a workstation with two 8-core Intel(R) Xeon(R)
E5-2680 processors at 2.7 GHz. Our C++ code was compiled with GCC 4.7.1,
and we use Python 3.4.1.

We integrated our code into NetworKit, an open-source network analysis
tool suite [23], because NetworKit provides (i) a C++ class for partitions,
(ii) implementations of the community detection algorithm which we want to
study and (iii) a Python frontend which allows us to conveniently include runs
of community detection algorithms into our tests. The C++ sources will be made
publicly available after paper acceptance.

5.2 Running times of branch-and-bound algorithm

1, P (cid:48)

2, . . . , P (cid:48)

The idea behind the experiments of this section is to see how well our branch-
and-bound algorithm can cope with situations in which large subsets S and S(cid:48)
have to be formed to minimize φP,P(cid:48)(·,·).
To this end we ﬁrst generate a partition P = {P1, P2, . . . , P2k} of a set V
where all parts have the same size. Second, we randomly select S ⊂ P with |S| =
2k} with empty parts and randomly
k. Third, we generate P(cid:48) = {P (cid:48)
select S(cid:48) ⊂ P(cid:48) with |S(cid:48)| = k. Finally, we ﬁll the parts of P(cid:48) as follows. The
elements in S [P \ S] are distributed evenly but otherwise randomly over the
parts in S(cid:48) [P(cid:48) \ S(cid:48)]. Thus, (S,S(cid:48)) is a perfect but well-hidden correspondence
with large S,S(cid:48), and the distribution of V over P(cid:48) is random otherwise. For a
small example see Figure 5.
In our experiments we choose 2k ∈ {10, 20, 50, 100, 200, 400, 800, 1000} and
|V | = 107. We then calculate the best 2k − 1 correspondences via a Gomory-Hu
tree of minimal Ps-Pt cuts of P w. r. t. P(cid:48). We use Gusﬁeld’s algorithm for the
computation of the Gomory-Hu tree [11,9]. The running times for calculating the
best 2k−1 correspondences are given in Figure 6. A moderate increase in running
time to about 2k = 100 is followed by a steep increase, which is expected for a
branch-and-bound algorithm. In the experiments described in the next section,
we observe very similar dependencies of the running time on the number of parts,
not only qualitatively but also in terms of absolute running times.

The size of V is not a problem since it enters the running time only as a linear
add-on (when the distributions are computed). Generally, our branch-and-bound

14

Fig. 5. Partitions P and P(cid:48) are such that S = ({P1, P2, P5},{P (cid:48)
correspondence between P and P(cid:48).

4}) is a perfect

2, P (cid:48)

3, P (cid:48)

(a)
Fig. 6. Running times for calculating the 2k − 1 best correspondences. (a) 2k = 10 to
2k = 200. (b) 2k = 10 to 2k = 1000.

(b)

algorithm can deal with partitions P and P(cid:48) of very large data sets as long as the
number of parts in P and P(cid:48) is bounded by about 1000. As we have observed in
additional experiments, the inﬂuence of |P(cid:48)| on the running time is only linear.
This makes sense since |P(cid:48)| equals the length of the distributions, and P(cid:48) aﬀects
our branch-and-bound algorithm only via the distributions.

Finding correspondences may become easier in applications where domain
knowledge can be used to steer the branch-and-bound algorithm. In image seg-
mentation, for example, one can use color, shape, and connectivity to improve
the choice of the next region during the extension of Ss and St in line 2 of
Algorithm 1.

15

P’123456123456PPPPPPP’P’P’P’P’’Table 5.1. Complex networks used for comparing partitions.

Graph ID Name

#vertices #edges

Network Type

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

p2p-Gnutella
PGPgiantcompo
email-EuAll
as-22july06
soc-Slashdot0902
loc-brightkite edges
loc-gowalla edges
coAuthorsCiteseer
wiki-Talk
citationCiteseer
coAuthorsDBLP
web-Google
coPapersCiteseer
coPapersDBLP
as-skitter

6 405
ﬁlesharing network
29 215
10 680
network of PGP users
24 316
16 805
network of connections via email
60 260
22 963
48 436 autonomous systems in the internet
379 445
28 550
news network
212 945
56 739
location-based friendship network
950 327
196 591
location-based friendship network
227 320
814 134
citation network
232 314 1 458 806
user interactions through edits
268 495 1 156 647
citation network
299 067
977 676
citation network
356 648 2 093 324
hyperlink network of web pages
434 102 16 036 720
citation network
540 486 15 245 729
citation network
554 930 5 797 663 network of internet service providers

5.3 Behavior of a parallel implementation of the Louvain method

for community detection in networks: insight through
correspondences

In the ﬁeld of community detection in networks one thinks of communities as
densely connected sets of nodes with sparse connections to the rest of the net-
work. Their detection has received signiﬁcant attention in basic research and
applications. For surveys see [19,5]. Here, we consider only non-overlapping com-
munities that form partitions. One of the most popular methods in community
detection is the method that we describe next.

The Louvain method (LM). LM is a locally greedy, bottom-up multilevel algo-
rithm [3] that forms communities of network nodes. On each level, it assigns
(i. e. moves) nodes to communities (parts) in an iterative way that maximizes
the objective function modularity [7] (not to be confused with Deﬁnition 2). The
communities found on a level are contracted into single nodes, giving rise to the
graph on the next level. The communities of the coarsest graph are then succes-
sively expanded to the next ﬁner level until, on the ﬁnest level, we have the ﬁnal
result.

In [22] a shared-memory parallelization of LM, called PLM, is provided:
among other things, node moves are evaluated and performed in parallel in-
stead of sequentially. We denote the single-thread (sequential) version of PLM
by SLM. Moreover, PLM and thus SLM have been extended by an optional
reﬁnement phase: after each expansion nodes are again moved for modularity
gain. SLM with reﬁnement is denoted by SLMR.

Questions on behavior of PLM, SLM and SLMR. PLM is not deterministic due
to race conditions during the parallel execution of the method. Let P be the

16

partition returned by one run of PLM, and let P(cid:48) be the partition returned by
another run of PLM. We want to know whether the transition from P to P(cid:48) is
best described as (a) communities merely exchanging elements with each other,
but otherwise remaining as they are or (b) involving unions and break-ups of
communities. An analogous question arises when P and P(cid:48) are from SLM and
SLMR, respectively.

Approach. As input for PLM, SLM, and SLMR we choose a collection of 15
diverse and widely used complex networks from two popular archives [1,14].
These networks are listed and described in Table 5.1. For each network and each
comparison, i. e. one run of PLM vs. another run of PLM or SLM vs. SLMR, we
get a pair of partitions P and P(cid:48).
We ﬁrst want to get an idea of the overall dissimilarity of the correspondences
between P and P(cid:48). To this end we add up the φP,P(cid:48)(·,·) values of the |P|−1 best
correspondences (those that are given by the fundamental cuts of the Gomory-
Hu tree) and divide this sum by the total number of vertices in the graph.

(a)

(b)

Fig. 7. (a) Overall dissimilarities and (b) imbalances of correspondences for each graph
in Table 5.1.

We then tackle the question about the occurrence of unions and break-ups
of communities through computing pairs (|S|,|S(cid:48)|): one pair for each of the
|P|−1 best correspondences (S,S(cid:48)), see Figure 8. We distinguish between pairs in
Meq := {(n, n(cid:48)) : n = n(cid:48) ∈ IN} and the remaining pairs in Mneq := IN×IN\Meq.
Let φeq [φneq] denote the sum over all φP,P(cid:48)(·,·) values (overall dissimilarity)
of correspondences with pairs in Meq [Mneq]. We deﬁne the imbalance of the
correspondences between P and P(cid:48) as
. Thus, a low [high] imbalance
indicates that the communities tend to remain intact [unions and break-ups of
communities are frequent].

φeq+φneq

φneq

Results. Figure 7a shows that the overall dissimilarity of the correspondences
between diﬀerent runs of PLM, i. e. the median of overall dissimilarity from 10

17

(a)

(b)

Fig. 8. A data point (n, n(cid:48)) indicates that there are correspondences between partitions
P and P(cid:48), where n communities of P correspond to n(cid:48) communities of P(cid:48). The number
at a data point (n, n(cid:48)) indicates the number of correspondences (S,S(cid:48)) with (|S|,|S(cid:48)|) =
(n, n(cid:48)). PLM, SLM and SLMR are applied to the graph web-Google, see Table 5.1.
(a) Pairs from diﬀerent runs of PLM. The pairs not shown are (37,36) and (94,94) with
one occurrence each. (b) Pairs from SLM vs. SLMR. The pairs not shown are (61,61),
(66,66), (69,69) and (77,77) with one occurrence each.

experiments with two runs each, is on the same order as the overall dissimilarity
of the correspondences between SLM and SLMR.

Figure 7b shows the imbalances. For the comparison PLM vs. PLM, the im-
balances are again medians over 10 experiments with two runs each. We see that,
despite comparable overall dissimilarity of the correspondences, the imbalances
from diﬀerent runs of PLM are much higher than those from SLM vs. SLMR.
In the latter comparison, correspondences from graphs with IDs 2, 4, 5, 12 and
15 have imbalance exactly zero, i. e. all correspondences are between the same
number of communities.

The comparison PLM vs. PLM is characterized by high imbalances with
no exception. Even for the graph web-Google (with ID 12), where the overall
dissimilarity of the correspondences is very small in both comparisons, i. e. 0.0033
in PLM vs. PLM and 0.0065 in SLM vs. SLMR, the latter dissimilarity being
about twice the former, the correspondences in the comparison SLM vs. SLMR
are deﬁnitely much more balanced. See Figures 7b and 8.

To summarize, the imbalances we gathered indicate that the race condi-
tions during PLM disrupt the communities in a more fundamental way (frequent
unions or break-ups of communities) than the reﬁnement phase. The latter de-
serves its name in that it leaves most communities intact. Yet, the impact of the
race conditions is comparable to the impact of the reﬁnement if impact is mea-
sured by φP,P(cid:48)(·,·): communities do unite and break up due to race conditions,
but primarily those communities that are not distinct in the ﬁrst place.

18

6 Related work

1, . . . , P (cid:48)

Similarity measures for partitions. Wagner and Wagner [27] provide a compre-
hensive collection of similarity measures for partitions P = {P1, . . . , P|P|} and
P(cid:48) = {P (cid:48)
|P(cid:48)|} of the same set V . They can all be derived from the contin-
gency table of P and P(cid:48). The correspondences introduced in this paper can also
be derived from the contingency table. Wagner and Wagner group the similarity
measures into three groups:

2. Measures that involve a sum over maximum Pi, P (cid:48)

1. Measures based on considering all unordered pairs (two-element subsets)
{v, w} of V and counting the 4 cases arising from the distinction as to
whether v and w belong to same part or to diﬀerent parts of P and the
analogous distinction with P(cid:48) instead of P. Examples of such measures are
the Rand index [18] and the adjusted Rand index [12].
j overlaps, where the sum is
over the Pi, the maximum is over the P (cid:48)
j, and the overlaps are deﬁned in var-
ious ways. One example is the F-measure [13,6]. Typically, theses measures
yield diﬀerent results if the roles of P and P(cid:48) are exchanged. Fragmentation
deﬁned in this paper, see Equations (1.3) and (1.4), has similar properties
in that it (i) involves a sum over the P (cid:48)
j overlaps over
certain Pi in a nonlinear way, and (iii) may vary if the roles of P and P(cid:48) are
exchanged.

j, (ii) aggregates Pi, P (cid:48)

3. Measures that involve mutual information, e. g. Normalized Mutual Informa-
tion [25]. Here, the common ground with our approach to deﬁning fragmen-
tation and thus correspondences is that we can replace the function peak(·),
see Equations (1.3) and (1.4), by the binary entropy function without alter-
ing the nature of our optimization problem (see also the next paragraph and
Section 3.1).

Impurity measures. The fragmentation of S ⊆ P w. r. t. P(cid:48), i. e. φP,P(cid:48)(S) in the
form of Equations (1.3) and (1.4), indicates how well the parts of P(cid:48) ﬁt into US
or V \US . Impurity measures, as deﬁned in [26,21], seem to be based on a similar
idea. Using our setting and notation, Simovici et al. [21] deﬁne the impurity of
a subset L of the ground set V relative to P and generated by peak(·) as

(L) = |L| (cid:88)

P (cid:48)∈P(cid:48)

IMPpeakP(cid:48)

peak(

|L ∩ P (cid:48)|

|L|

).

(6.1)

We can turn IMPpeakP(cid:48)

(US ) into φP,P(cid:48)(S) by (i) pulling US under the sum
(mathematically correct) and (ii) exchanging the roles of US and P (cid:48) under the
sum (mathematically incorrect). For us it is important to have the roles as they
are in φP,P(cid:48)(S) because this is what makes φP,P(cid:48)(·) a submodular and symmetric
function. These properties, in turn, make it possible to ﬁnd the best nontrivial
S in polynomial time.
(·)

(·) and φP,P(cid:48)(·), studying IMPpeakP(cid:48)

Despite this mismatch between IMPpeakP(cid:48)

helped to develop the intuition behind our approach.

19

The main properties of IMPpeakP(cid:48)

(·) and related measures, as formulated and
proven in [21], are preserved if peak(·) is replaced by another generator, as deﬁned
in [21], i. e. another concave and additive function f : [0, 1] (cid:55)→ R with f (0) =
f (1) = 0. Likewise, if we replace peak(·) in Equation (1.3) by another generator,
we will arrive at similar deﬁnitions of fragmentation and correspondences. This
also does not change the kind and asymptotic complexity of the optimization
problems posed by our approach. Examples of generators are the binary entropy
function and the Gini impurity measure [26,21].

7 Conclusions and outlook

Correspondences and associated dissimilarities provide insight into multiple ways
in which two partitions can be similar and are an instrument to detect, represent
and quantify consensus between partitions. Very often, it is not clear in a certain
application whether two or more parts “belong together” or should be single
parts. Then, correspondences allow us to compare two partitions modulo such
ambiguities.
Since “good” correspondences between two partitions P and P(cid:48) are basically
small cuts of P w. r. t. P(cid:48), a hierarchy of the |P| − 1 best correspondences arises
from a minimal basis of non-crossing Ps-Pt cuts of P w. r. t. P(cid:48). In particular,
a hierarchy of the |P| − 1 best correspondences can readily be derived from a
Gomory-Hu tree, the computation of which requires the determination of only
|P|−1 minimal Ps-Pt cuts. Our branch-and-bound algorithm makes it feasible to
compute these cuts even for |P| and |P(cid:48)| around 1000. The number of elements
in V can be neglected. Within the branch-and-bound algorithm, the most crucial
feature is the choice of the next candidates for extension of either Ss or St, as
speciﬁed in Equation (4.6). The choice of the next candidates may also involve
application-speciﬁc criteria such as color or shape in image segmentation. Such
additional information may help our branch-and-bound algorithm to stay in the
lane, and is expected to accelerate it.
The |P| − 1 best correspondences between P and P(cid:48) give rise to consensus
partitions (clusterings) of P and P(cid:48) (consensus modulo unions of parts). Indeed,
any correspondence (S,S(cid:48)) with φP,P(cid:48)(S,S(cid:48)) = 0 is such that each P (cid:48) ∈ P(cid:48) is
fully contained in S or in P \ S. Thus, removing the edges of the Gomory-Hu
tree with weight zero yields the ﬁnest partition that is a coarsening of P and
P(cid:48). In case of PLM vs. PLM [SLM vs. SLMR] on the network web-Google,
the number of clusters in this “largest common denominator of P and P(cid:48)” is
54% [32%] of the number of clusters from PLM [SLM]. If we consider all corre-
S|
|US∩U(cid:48)
spondences (S,S(cid:48)) whose quality
S| exceeds 0.99, the percentage rises to
|US∪U(cid:48)
96% [68%]. Thus, the exact consensus already contains a considerable amount
of clusters, and a very good consensus contains the majority of clusters. More
generally, the |P| − 1 best correspondences give rise to a hierarchy of consensus
partitions parameterized by quality. Consensus partitions with more parts can
also be obtained by generating ﬁner partitions in the ﬁrst place.

20

Despite the symmetry of φP,P(cid:48)(S,S(cid:48)) = |US(cid:52)US(cid:48)|, ﬁnding the |P| − 1 best
correspondences between P and P(cid:48) is not the same as ﬁnding the |P(cid:48)| − 1 best
correspondences between P(cid:48) and P, even if |P| = |P(cid:48)|. Interestingly, the time
complexity for ﬁnding the |P| − 1 best correspondences between P and P(cid:48), i. e.
O(|V | + |P|5|P(cid:48)|), depends only linearly on |P(cid:48)|. This linear dependence goes
back to using distributions, where each part P of P gives rise to a distribution
of P w. r. t. P(cid:48), analogous to Deﬁnition 3. In the future we would like to ﬁnd out
whether we can use distributions w. r. t. P(cid:48) and P to speed up the computation
of correspondences.

References

[1] D. A. Bader, H. Meyerhenke, P. Sanders, C. Schulz, A. Kappes, and D. Wag-
ner. Benchmarking for graph clustering and partitioning. In Encyclopedia
of Social Network Analysis and Mining, pages 73–82. 2014.

[2] J. Bilmes. Submodularity Functions, Optimization, and Application to Ma-

chine Learning. Lecture at University of Washington, Seattle, 2012.

[3] Vincent D Blondel, Jean-Loup Guillaume, Renaud Lambiotte, and Etienne
Lefebvre. Fast unfolding of communities in large networks. Journal of
Statistical Mechanics: Theory and Experiment, 2008(10):P10008, 2008.

[4] Brian Everitt, editor. Cluster analysis. Wiley series in probability and

statistics. Wiley, Chichester, 5th ed. edition, 2011.

[5] Santo Fortunato. Community detection in graphs. Physics Reports, 486(3-

5):75 – 174, 2010.

[6] B. C. M. Fung, K. Wang, and M. Ester. Hierarchical document clustering
using frequent items. In Proceedings of the SIAM International Conference
on Data Mining, 2003.

[7] M. Girvan and M.E.J. Newman. Community structure in social and bio-
logical networks. Proc. of the National Academy of Sciences, 99(12):7821,
2002.

[8] M. X. Goemans and V. S. Ramakrishnan. Minimizing submodular functions

over families of sets. COMBINATORICA, 15(4):499–513, 1995.

[9] A. V. Goldberg and K. Tsioutsiouliklis. Cut tree algorithms: An experi-

mental study. Journal of Algorithms, 38(1):51–83, 2001.

[10] R. E. Gomory and T. C. Hu. Multi-terminal network ﬂows. Journal of the

Society for Industrial and Applied Mathematics, 9(4):551–570, 1961.

[11] D. Gusﬁeld. Very simple methods for all pairs network ﬂow analysis. SIAM

J. Comput., 19(1):143–155, 1990.

[12] L. Hubert and P. Arabie. Comparing partitions. Journal of classiﬁcation,

2(1):193–218, 1985.

[13] B. Larsen and C. Aone. Fast and eﬀective text mining using linear-time
document clustering.
In Proceedings of the Fifth ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining, KDD ’99,
pages 16–22, New York, NY, USA, 1999. ACM.

21

[14] J. Leskovec. Stanford large network dataset collection. At http://snap.

stanford.edu/data/, October 2011.

[15] D. J. C. MacKay. Information Theory, Inference, and Learning Algorithms.

Cambridge University Press, 2003.

[16] M. Meil˘a. Comparing clusterings. Technical Report 418, University of

Washington, COLT, 2003.

[17] M. Queyranne. Minimizing symmetric submodular functions. Mathematical

Programming, 82(1-2):3–12, 1998.

[18] W. M. Rand. Objective criteria for the evaluation of clustering methods.

Journal of the American Statistical Association, 66(336):846–850, 1971.

[19] Satu Elisa Schaeﬀer. Graph clustering. Computer Science Review, 1(1):27–

64, 2007.

[20] A. Schrijver. Combinatorial Optimization - Polyhedra and Eﬃciency.

Springer, 2003.

[21] D. A. Simovici, D. Cristofor, and L. Cristofor.

Impurity measures in

databases. Acta Informatica, 28:200–2, 2002.

[22] C. Staudt and H. Meyerhenke. Engineering parallel algorithms for commu-
nity detection in massive networks. Parallel and Distributed Systems, IEEE
Transactions on, PP(99):1–1, 2015. Available online, to appear in printed
form.

[23] C. L. Staudt, Sazonovs A., and H. Meyerhenke. Networkit: An interactive
tool suite for high-performance network analysis. CoRR, abs/1403.3005,
2014.

[24] P. Stobbe and A. Krause. Eﬃcient minimization of decomposable submod-
ular functions. In Advances in Neural Information Processing Systems 23:
24th Annual Conference on Neural Information Processing Systems 2010,
Vancouver, British Columbia, Canada., pages 2208–2216, 2010.

[26] P.-N. Tan, M. Steinbach, and V. Kumar.

[25] A. Strehl and J. Ghosh. Cluster ensembles — a knowledge reuse framework
for combining multiple partitions. J. Mach. Learn. Res., 3:583–617, 2003.
Introduction to Data Mining,
(First Edition). Addison-Wesley Longman Publishing Co., Inc., Boston,
MA, USA, 2005.

[27] S. Wagner and D. Wagner. Comparing Clusterings – An Overview. Tech-

nical Report 2006-04, Universit¨at Karlsruhe (TH), 2007.

22

