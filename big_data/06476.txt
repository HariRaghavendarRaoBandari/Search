Dynamic Prediction for Multiple Repeated Measures and
Event Time Data: An Application to Parkinson’s Disease

Jue Wang, Sheng Luo∗, Liang Li

Abstract

In many clinical trials studying neurodegenerative diseases such as Parkinson’s disease (PD),
multiple longitudinal outcomes are collected to fully explore the multidimensional impairment
caused by this disease. If the outcomes deteriorate rapidly, patients may reach a level of func-
tional disability suﬃcient to initiate levodopa therapy for ameliorating disease symptoms. An
accurate prediction of the time to functional disability is helpful for physicians to monitor pa-
tients’ disease progression and make informative medical decisions. In this article, we ﬁrst pro-
pose a joint model that consists of a semiparametric latent trait linear mixed model (LTLMM)
for the multiple longitudinal outcomes, and a survival model for event time. The two submod-
els are linked together by an underlying latent variable. We develop a Bayesian approach for
parameter estimation and a dynamic prediction framework for predicting target patients’ fu-
ture outcome trajectories and risk of a survival event, based on their multivariate longitudinal
measurements. Our proposed model is evaluated by simulation studies and is applied to the
DATATOP study, a motivating clinical trial assessing the eﬀect of deprenyl among patients with
early PD.

Key Words: Area under the ROC curve, clinical trial, failure time, latent trait model.

6
1
0
2

 
r
a

 

M
1
2

 
 
]
P
A

.
t
a
t
s
[
 
 

1
v
6
7
4
6
0

.

3
0
6
1
:
v
i
X
r
a

∗Corresponding author: Sheng Luo is Associate Professor, Department of Biostatistics, The University of Texas
Health Science Center at Houston, 1200 Pressler St, Houston, TX 77030, USA (E-mail: sheng.t.luo@uth.tmc.edu;
Phone: 713-500-9554).

1

1

Introduction

Joint models of longitudinal outcomes and survival data have been an increasingly productive re-
search area in the last two decades (e.g., Tsiatis & Davidian, 2004). The common formulation of joint
models consists of a mixed eﬀects submodel for the longitudinal outcomes and a semiparametric Cox
submodel (Wulfsohn & Tsiatis, 1997) or accelerated failure time (AFT) submodel for the event time
(Tseng et al., 2005). Subject-speciﬁc shared random eﬀects (Vonesh et al., 2006) or latent classes
(Proust-Lima et al., 2014) are adopted to link these two submodels. Many extensions have been pro-
posed, e.g., relaxing the normality assumption of random eﬀects (Brown & Ibrahim, 2003), replacing
random eﬀects by a general latent stochastic Gaussian process (Xu & Zeger, 2001), incorporating
multivariate longitudinal variables (Chi & Ibrahim, 2006), and extending single survival event to
competing risks (Elashoﬀ et al., 2007) or recurrent events (Sun et al., 2005; Liu & Huang, 2009).

Joint models are commonly used to provide an eﬃcient framework to model correlated longitudi-
nal and survival data and to understand their correlation. A novel use of joint models, which gains
increasing interest in recent years, is to obtain dynamic personalized prediction of future longitudinal
outcome trajectories and risks of survival events at any time, given the subject-speciﬁc outcome pro-
ﬁles up to the time of prediction. For example, Rizopoulos (2011) proposed a Monte Carlo approach to
estimate risk of a target event and illustrated how it can be dynamically updated. Taylor et al. (2013)
developed a Bayesian approach using a Markov chain Monte Carlo (MCMC) algorithm to dynami-
cally predict both the continuous longitudinal outcome and survival event probability. Blanche et al.
(2015) extended the survival submodel to account for competing events. Rizopoulos et al. (2013)
compared dynamic prediction using joint models v.s. landmark analysis (van Houwelingen, 2007), an
alternative approach for dynamically updating survival probabilities. A key feature of these dynamic
prediction frameworks is that the predictive measures can be dynamically updated as additional
longitudinal measurements become available for the target subjects, providing instantaneous risk
assessment.

Most dynamic predictions via joint models developed in the literature have been restricted to
one or two longitudinal outcomes. However, impairment caused by the neurodegenerative diseases
such as Parkinson’s disease (PD) aﬀects multiple domains (e.g., motor, cognitive, and behavioral).
The heterogeneous nature of the disease makes it impossible to use a single outcome to reliably
reﬂect disease severity and progression. Consequently, many clinical trials of PD collect multiple
longitudinal outcomes of mixed types (categorical and continuous). To properly analyze these longi-
tudinal data, one has to account for three sources of correlation, i.e., inter-source (diﬀerent measures
at the same visit), longitudinal (same measure at diﬀerent visits), and cross correlation (diﬀerent
measures at diﬀerent visits) (O’Brien & Fitzmaurice, 2004). Hence, a joint modeling framework for
analyzing all longitudinal outcomes simultaneously is essential. There is a large number of joint
modeling approaches for mixed type outcomes. Multivariate marginal models (e.g., likelihood-based
(Molenberghs & Verbeke, 2005), copula-based (Lambert & Vandenhende, 2002), and GEE-based
(O’Brien & Fitzmaurice, 2004)), provide direct inference for marginal treatment eﬀects, but handling
unbalanced data and more than two response variables remain open problems. Multivariate random

2

eﬀects models (Verbeke et al., 2014) have severe computational diﬃculties when the number of ran-
dom eﬀects is large. In comparison, mixed eﬀects models focused on dimensionality reduction (using
latent variables) provide an excellent and balanced approach to modeling multivariate longitudinal
data. To this end, He & Luo (2013) developed a joint model for multiple longitudinal outcomes
of mixed types, subject to an outcome-dependent terminal event. Luo & Wang (2014) proposed a
hierarchical joint model accounting for multiple levels of correlation among multivariate longitudinal
outcomes and survival data. However, these works focus on the statistical inference instead of per-
sonalized dynamic prediction. To the best of our knowledge, there is no studies of dynamic prediction
using joint models based on latent variables to reduce the dimension of multiple outcomes.

In this article, we propose a novel joint model that consists of: (1) a semiparametric latent trait
linear mixed model (LTLMM) for the multiple longitudinal outcomes with a univariate latent variable
representing the underlying disease severity, and (2) a survival submodel for the event time data.
We adopt penalized splines using the truncated power series spline basis expansion in modeling the
eﬀects of some covariates and the baseline hazard function. This spline basis expansion results in
tractable integration in the survival function, which signiﬁcantly improves computational eﬃciency.
We develop a Bayesian approach via Markov chain Monte Carlo (MCMC) algorithm for statistical
inference and a dynamic prediction framework for the predictions of target patients’ future outcome
trajectories and risks of survival event. These important predictive measures oﬀer unique insight into
the dynamic nature of each patient’s disease progression and they are highly relevant for patient tar-
geting, management, prognosis, and treatment selection. Moreover, accurate prediction can advance
design of future studies, experimental trials, and clinical care through improved prognosis and earlier
intervention.

The rest of the article is organized as follows. In Section 2, we describe a motivating clinical trial
and the data structure. In Section 3, we discuss the joint model, Bayesian inference, and subject-
speciﬁc prediction.
In Section 4, we apply the proposed method to the motivating clinical trial
dataset. In Section 5, we conduct simulation studies to assess the prediction accuracy. Concluding
remarks and discussions are given in Section 6.

2 A motivating clinical trial

The methodological development is motivated by the DATATOP study, a double-blind, placebo-
controlled multicenter randomized clinical trial with 800 patients to determine if deprenyl and/or
tocopherol administered to patients with early Parkinson’s disease (PD) will slow the progression of
PD. We refer to as placebo group the patients who did not receive deprenyl and refer to as treatment
group the patients who received deprenyl. The detailed description of the design of the DATATOP
study can be found in Shoulson (1998).

In the DATATOP study, the multiple outcomes collected include Uniﬁed PD Rating Scale (UP-
DRS) total score, modiﬁed Hoehn and Yahr (HY) scale, Schwab and England activities of daily living
(SEADL), measured at 10 visits (baseline, months 1, and every 3 months starting from month 3 to

3

month 24). UPDRS is the sum of 44 questions each measured on a 5-point scale (0-4), and it is
approximated by a continuous variable with integer value from 0 (not aﬀected) to 176 (most severely
aﬀected). HY is a scale describing how the symptoms of PD progresses. It is an ordinal variable
with possible values at 1, 1.5, 2, 2.5, 3, 4, and 5, with higher values being clinically worse outcome.
However, the DATATOP study consists of only patients with early mild PD and the worst observed
HY is 3. SEADL is a measurement of activities of daily living, and it is an ordinal variable with
integer values from 0 to 100 incrementing by 5, with larger values reﬂecting better clinical outcomes.
We have recoded SEADL variable so that higher values in all outcomes correspond to worse clinical
conditions and we have combined some categories with zero or small counts so that SEADL has eight
categories.

Among the 800 patients in the DATATOP study, 44 did not have disease duration recorded and
one had no UPDRS measurements. We exclude them (5.6%) from our analysis and the data analysis
is based on the remaining 755 patients (375 in placebo and 380 in treatment). Before the end of
the study, some patients (207 in placebo and 146 in treatment) were taken out of the study, in
the judgement of the enrolling physicians, because their health deteriorated to a pre-deﬁned level of
functional disability to warrant switching them to standard symptomatic treatment of levodopa. The
initiation of symptomatic treatment of levodopa is considered to be a terminal event because it can
signiﬁcantly change the clinical outcomes. Figure 1 displays the mean UPDRS measurements over
time for DATATOP patients with follow-up time less than 6 months (96 patients, solid line), 6-12
months (215 patients, dotted line), and more than 12 months (444 patients, dashed line). Figure 1
suggests that patients with shorter follow-up had higher UPDRS measurements, manifesting the
strong correlation between the PD symptoms and terminal event. Similar patterns are observed in
HY and SEADL measurements. Such a dependent terminal event time is referred to as “dependent
censoring” or “informative censoring” (Diggle & Kenward, 1994).

Because levodopa is associated with possible motor complications (Brooks, 2008), physicians
tend to provide more targeted interventions to delay their initiation of levodopa use. To this end, in
the context of DATATOP study and similar PD studies, there are two important clinically relevant
prediction questions: (1) For the 402 patients (168 in placebo and 234 in treatment) in the DATATOP
study who did not reach functional disability, what are their most likely future health outcome
trajectories (e.g., UPDRS, HY, and SEADL), and their risks of functional disability within the next
year? (2) for a new patient (not included in the DATATOP study) with one or multiple visits, what
are his/her most likely future outcome trajectories and risk of functional disability within the next
year, given the outcome histories and the covariate information? These important predictive measures
are highly relevant for PD patient targeting, management, prognosis, and treatment selection. In this
article, we propose to develop a Bayesian personalized prediction approach based on a joint modeling
framework consisting of a semiparametric latent trait linear mixed model (LTLMM) for multivariate
longitudinal outcomes and a survival model for the event time data (time to functional disability).

4

)
e
s
r
o
w
 
s
i
 
r
e
h
g
h
(
 

i

S
R
D
P
U

< 6 mos
6~12 mos
> 12 mos

5
4

0
4

5
3

0
3

5
2

0
2

0

6

12

18

24

Follow up time (months)

Figure 1: Mean UPDRS values over time.

3 Methods

3.1 Joint modeling framework

In the context of clinical trials with multiple outcomes, the data structure is often of the type
{yik(tij), ti, δi}, where yik(tij) is the kth (k = 1, . . . , K) outcome, which can be binary, ordinal, or
continuous, for patient i (i = 1, . . . , I) at visit j (j = 1, . . . , Ji) recorded at time tij from the study
onset, ti = min(T ∗
i , Ci) is the observed event time to functional disability, as the minimum between
the true event time T ∗
i and the censoring time Ci, and δi is the censoring indicator (1 if the event
is observed, and 0 otherwise). We propose to use a semiparametric latent trait linear mixed model
(LTLMM) for the multiple longitudinal outcomes and a survival model for the event time.

To start building the semiparametric LTLMM framework, we assume that there is a latent variable
representing the underlying disease severity score and denote it as θi(t) for patient i at time t with
a higher value for more severe status. We introduce the ﬁrst level latent trait model for continuous
outcomes,

yik(t) = ak + bkθi(t) + εik(t),

(1)

where ak and bk (positive) are the outcome-speciﬁc parameters, and the random errors ǫik(t) ∼
N(0, σ2
εk). Note that ak = E[yik(t)|θi(t) = 0] is the mean of the kth outcome if the disease severity
score is 0 and bk is the expected increase in the kth outcome for one unit increase in the disease severity
score. The parameter bk also plays the role of bringing up the disease severity score to the scale of
the kth outcome. The models for outcomes that are binary (e.g., the presence of adverse events)

and ordinal (e.g., HY and SEADL) are logit(cid:8)p(yik(t) = 1|θi(t))} = ak + bkθi(t) and logit(cid:8)p(yik(t) ≤

5

l|θi(t))(cid:9) = akl − bkθi(t), respectively (Fox, 2005), where l = 1, 2, . . . , nk − 1 is the lth level of the kth

random variable, which is ordinal with nk levels. Note that the negative sign for bk in the ordinal
outcome model is to ensure that worse disease severity (higher θi(t)) is associated with a more severe
outcome (higher yik(t)). Interpretation of parameters is similar for continuous outcomes, except that
modeling is on the log-odds, not the native scale, of the data. A major feature of these models is
that they all incorporate θi(t) and explicitly combine longitudinal information from all outcomes.

To model the dependence of severity score θi(t) on covariates, we propose the second level semi-

parametric linear mixed model

θi(t) = fi(t) + ei(t) = X i(t)β + Z i(t)ui + V R(t)ζ + ei(t),

(2)

a smooth time function V R(t)ζ = PR

where fi(t) denotes the true unobserved disease severity score at time t manifested by the longitudinal
outcomes. Vectors X i(t) and Z i(t) are p and q dimensional covariates corresponding to ﬁxed and
random eﬀects, respectively. They can include covariates of interest such as treatment and time.
To allow additional ﬂexibility and smoothness in modeling the eﬀects of some covariates, we adopt
r=1 ζr(t − κr)+ using the truncated power series spline basis
expansion V R(t) = {(t − κ1)+, . . . , (t − κR)+}, where κ = {κ1, . . . , κR} are the knots, and (t − κr)+ =
t − κr if t > κr and 0 otherwise. Following Ruppert (2012), we consider a large number of knots
(typically 5 to 20) that can ensure the desired ﬂexibility and we select the knot location to have
suﬃcient subjects between adjacent knots. To avoid overﬁtting, we explicitly introduce smoothing
by assuming that ζ = (ζ1, . . . , ζR)′ ∼ N(0, σ2
ζ I)(Ruppert et al., 2003; Crainiceanu et al., 2005). For
the ease of illustration, we include the nonparametric smooth function for the time variable, although
our model can be extended to accommodate more nonparametric smooth functions. The vector
ui = (ui1, . . . , uiq)′ contains the random eﬀects for patient i’s latent disease severity score and it is
distributed as N(0, Σ). We also assume that the residuals ei(t) are independent from the random
eﬀects vector ui and are distributed as N(0, σ2
e ). Models (1) and (2) consist of the semiparametric
LTLMM model, which provides a nature framework for deﬁning the overall eﬀects of treatment and
r=1 ζr(t − κr)+ + ui0 + ui1t + ei(t), where
xi is treatment indicator (1 if treatment and 0 otherwise), then β1 is the main treatment eﬀect and
β3 is the time-dependent treatment eﬀect. In this context, the null hypothesis of no overall treatment
eﬀect is H0 : β1 = β3 = 0. Because the number of outcomes (K) has been reduced to one latent
disease severity score, models are quite parsimonious in terms of number of random eﬀects, which
improves computational feasibility and model interpretability.

other covariates. Indeed, if θi(t) = β0 + β1xi + β2t + β3xit +PR

Because the semiparametric LTLMM model is over-parameterized, additional constraints are
required to make it identiﬁable. Speciﬁcally, we set ak1 = 0 and bk = 1 for one ordinal outcome.
For the ordinal outcome k with nk categories, the order constraint ak1 < . . . < akl < . . . < aknk−1
must be satisﬁed, and the probability of being in a particular category is p(Yik(t) = l) = p(Yik(t) ≤
l|θi(t)) − p(Yik(t) ≤ l − 1|θi(t)). With these assumptions, the conditional log-likelihood of observing
k=1 log p(yik(tij)|ui, ζ). For
notational convenience, we let a = (a′
K)′, with ak being numeric for binary and
continuous outcomes and ak = (ak1, . . . , aknk−1)′ for ordinal outcomes. We let b = (b1, . . . , bK)′

the patient i data {yik(tij)} given ui and ζ is ly(Θy; yi, ui, ζ) =PJi

j=1PK

1, . . . , a′

k, . . . , a′

6

and yi(t) = {yik(t), k = 1, . . . , K}′ be the vector of measurements for patient i at time t and let
yi = {yi(tij), j = 1, . . . , Ji} be the outcome vector across Ji visit times. The parameter vector for
the longitudinal process is Θy = (a′, b′, β′, Σ, σεk, σe, σζ)′.

To model the survival process, we use the proportional hazard model

hi(t) = h0(t) exp{W iγ + νfi(t)},

(3)

exp{η0 + η1t +PR

r=1 ξr(t − κr)+} and assume ξ = (ξ1, . . . , ξR)′ ∼ N(0, σ2

where γ is the coeﬃcient for time-independent covariates and h0(·) is the baseline hazard function. For
prediction of subject-speciﬁc survival probabilities, a speciﬁed and smooth baseline hazard function
is desired. To this end, we again adopt a truncated power series spline basis expansion h0(t) =
ξ I) to introduce smoothing.
The knot locations can be the same or diﬀerent from those in model (2). The association parameter ν
quantiﬁes the strength of correlation between fi(t), i.e., the true unobserved disease severity score at
time t, and the hazard for a terminal event at the same time point. Speciﬁcally, positive association
parameter ν indicates that patients with worse disease severity tend to have a terminal event earlier.
In model (3), diﬀerent formulations can be used to postulate how the risk for a terminal event
depends on the true unobserved disease severity score at time t. For example, one can add to model (3)
a time-dependent slope f ′
i (t)), so that the risk depends on both
the current severity score and the slope of the true severity trajectory at time t. Alternatively, one
can account for the cumulative eﬀect of the longitudinal severity score from baseline up to time t by
0 fi(s)ds. Detailed investigation of these various formulations in

i (t) (i.e., νfi(t) becomes ν1fi(t) + ν2f ′

The log-likelihood of observing event outcome ti and δi for patient i is

the joint modeling framework can be found in Rizopoulos et al. (2014) and Yang et al. (2015).

replacing νfi(t) in model (3) by νR t
ls(Θs; ti, δi, ui, ζ, ξ) = log{hi(ti)δiSi(ti)}, where the survival function Si(ti) = exp{−R ti

0 hi(s)ds} and
the parameter vector for the survival process is Θs = (γ′, ν, η0, η1, σξ)′. Note that the truncated power
series spline basis expansion in modeling the smooth time function in model (2) and in modeling the
baseline hazard function is linear function of time, which results in tractable integration in the
survival function Si(ti), and consequently, signiﬁcant gain in computing eﬃciency. Conditional on
the random eﬀect vector ui, yi is assumed to be independent of ti. The penalized log-likelihood of
the joint model for patient i given random eﬀects ui and smoothing parameters σζ , σξ is

l(Θ, ζ, ξ; ·) = ly(Θy; yi, ui, ζ) + ls(Θs; ti, δi, ui, ζ, ξ) −

ζ′ζ −

1
σ2
ζ

ξ′ξ,

1
σ2
ξ

(4)

where the unknown parameter vector Θ = (Θ′

y, Θ′

s)′.

3.2 Bayesian inference

To infer the unknown parameter vector Θ, we use Bayesian inference based on Markov chain Monte
Carlo (MCMC) posterior simulations. We use vague priors on all elements in Θ. Speciﬁcally, the
prior distributions of parameters ν, η0, η1, and all elements in vectors β and γ are N(0, 100). We

7

use the prior distribution bk ∼ Uniform(0, 10), k = 2, . . . , K, to ensure positivity. The prior dis-
tribution for the diﬃculty parameter ak of the continuous outcomes is ak ∼ N(0, 100). To obtain
the prior distributions for the threshold parameters of ordinal outcome k, we let ak1 ∼ N(0, 100),
and akl = ak,l−1 + ∆l for l = 2, . . . , nk − 1, with ∆l ∼ N(0, 100)I(0, ), i.e., normal distribution left
truncated at 0. We use the prior distribution Uniform[−1, 1] for all the correlation coeﬃcients ρ
in the covariance matrix Σ, and Inverse-Gamma(0.01, 0.01) for all variance parameters. We have
investigated other selections of vague prior distributions with various hyper-parameters and obtained
very similar results.

The posterior samples are obtained from the full conditional of each unknown parameter using

Hamiltonian Monte Carlo (HMC) (Duane et al., 1987) and No-U-Turn Sampler (NUTS) (Hoﬀman & Gelman,
2014). Both HMC and NUTS samplers are implemented in Stan, which is a probabilistic program-
ming language implementing statistical inference. The model ﬁtting is performed in Stan (version
2.8.0) (Stan Development Team, 2015) by specifying the full likelihood function and the prior dis-
tributions of all unknown parameters. For large datasets, Stan may be more eﬃcient than BUGS
language (Lunn et al., 2000) in achieving faster convergence and requiring smaller number of sam-
ples (Hoﬀman & Gelman, 2014). To monitor Markov chain convergence, we use the history plots and
view the absence of apparent trends in the plot as evidence of convergence. In addition, we use the

Gelman-Rubin diagnostic to ensure the scale reduction bR of all parameters are smaller than 1.1 as

well as a suite of convergence diagnosis criteria to ensure convergence (Gelman et al., 2013). After
ﬁtting the model to the training dataset (the dataset used to build the model) using Bayesian ap-
proaches via MCMC, we obtain M (e.g., M = 2, 000 after burn-in) samples for the parameter vector
Θ0 = (Θ′, ζ′, ξ′)′ and for the random eﬀects vector ui, denoted by {Θ(m)
, m = 1, . . . , M}. To
facilitate easy reading and implementation of the proposed joint model, a Stan code has been posted
in the Web Supplement. Note that Stan requires variable types to be declared prior to modeling.
The declaration of matrix Σ as a covariance matrix ensures it to be positive-deﬁnite by rejecting the
samples that cannot produce positive-deﬁnite matrix Σ. Please refer to the Stan code in the Web
Supplement for details.

, u(m)

0

i

3.3 Dynamic prediction framework

3.3.1 Prediction for patients in the training dataset

i = {yi(tij); 0 ≤ tij ≤ t} and covariates history X {t}

We ﬁrst illustrate the prediction for the patients in the training dataset. Given PD patient i’s outcome
histories y{t}
i = {X i(tij), Z i(tij), W i; 0 ≤ tij ≤ t}
up to time t, we want to obtain two personalized predictive measures: the longitudinal trajectories
yik(t′), for k = 1, . . . , K, at a future time point t′ > t (e.g., t′ = t + ∆t), and the probability of
functional disability before time t′, denoted by πi(t′|t) = p(T ∗
). Predictions
can be obtained by simply plugging in realizations of the parameter vector and random eﬀects vector
{Θ(m)
, m = 1, . . . , M}, obtained from the MCMC samples. For example, the mth sample of

i > t, y{t}

i ≤ t′|T ∗

, X {t}

i

i

, u(m)

i

0

8

continuous outcome yik(t′) is obtained from models (1) and (2):

y(m)
ik (t′) = a(m)

k + b(m)

i + V R(t′)ζ(m) + e(m)

i

k nX i(t′)β(m) + Z i(t′)u(m)

(t′)o + ε(m)

ik (t′),

where the random errors e(m)
εk
replaced by the corresponding element in the mth MCMC sample {Θ(m)

ik (t′) ∼ N(0, σ2(m)

(t′) ∼ N(0, σ2(m)

) and ε(m)

e

i

), and each parameter is
i }.

, u(m)

0

i

i

0

ik (t′) ≤

(t′|u(m)

) = h(m)

kl −b(m)

i +V R(t′)ζ(m)+e(m)

ik (t′) ≤ l(cid:1) − p(cid:0)y(m)

i at time t′ is h(m)
Thus, the conditional probability of functional disability before time t′ is

(t′) exp(cid:8)W iγ(m) + ν(m)(cid:2)X i(t′)β(m) + Z i(t′)u(m)

(t′)(cid:9). The probability of being in category
ik (t′) ≤ l − 1(cid:1). The mth sample of the hazard of patient
i + V R(t′)ζ(m)(cid:3)(cid:9).

Similarly, the mth sample of ordinal outcome yik(t′) = l with l = 1, 2, . . . , nk is logit(cid:8)p(cid:0)y(m)
k (cid:8)X i(t′)β(m)+Z i(t′)u(m)
l(cid:1)(cid:9) = a(m)
l is p(cid:0)y(m)
ik (t′) = l(cid:1) = p(cid:0)y(m)
bπi(t′|t) = Z p(T ∗
p(cid:16)T ∗
MXm=1
MXm=1(1 −
MXm=1(1 − exp −Z t′

i (cid:17)
))
)ds!) ,

i > t′|y{t}
i > t|y{t}

, X {t}
i
, X {t}

, u(m)
, u(m)

, ui)p(ui|T ∗

i > t, y{t}

i > t, y{t}

i > t, y{t}

p(T ∗
p(T ∗

i ≤ t′|T ∗

i ≤ t′|T ∗

, X {t}

, u(m)

, X {t}

i

, X {t}

i

h(m)
i

(s|u(m)

i

1
M

)dui

1
M

1
M

i

i

i

i

i

i

≈

=

=

)

t

i

i

i

i

where the integration with respect to ui in the ﬁrst equality is approximated using Monte Carlo
method. Note that the truncated power series spline basis expansion in modeling the smooth time
function in model (2) and in modeling the baseline hazard function results in tractable integration
not only in the survival function Si(ti), but also in the integration of hazard function in the last
equality. All prediction results can then be obtained by calculating simple summaries (e.g., mean,

variance, quantiles) of the posterior distributions of M samples(cid:8)y(m)

3.3.2 Predict for a new subject not in the training dataset

ik (t′), m = 1, . . . , M(cid:9).

N = {yN (tN j); 0 ≤ tN j ≤ t} and the covariate vector X {t}

Next we illustrate how to make prediction for a new subject N, based on the available outcome
histories y{t}
N up to time t, and δN = 0 (no
event). We want to predict the outcomes yN k(t′), for k = 1, . . . , K, at time t′ > t and the probability
of functional disability before t′, denoted by πN (t′|t) = p(T ∗
N ). To do this, the
key step is to obtain samples for patient N’s random eﬀects vector uN from its posterior distribution
p(uN |T ∗
, we draw the mth

N , Θ0). Speciﬁcally, conditional on the mth posterior sample Θ(m)

N > t, y{t}

N > t, y{t}

N ≤ t′|T ∗

N , X {t}

0

9

sample of the random eﬀects vector uN from its posterior distribution

p(uN |T ∗

N > t, y{t}

N , Θ(m)

0

) =

)

∝ p(y{t}, T ∗

N > t, uN |Θ(m)

0

)

= p(y{t}|uN , Θ(m)

0

N > t|uN , Θ(m)

0

)p(uN |Θ(m)

0

),

p(y{t}, T ∗

p(y{t}, T ∗

N > t, uN |Θ(m)
0
)

N > t|Θ(m)
)p(T ∗

0

where the ﬁrst equality is from Bayes theorem.

For each of Θ(m)

0

, m = 1, . . . , M, we use adaptive rejection Metropolis sampling (Gilks et al.,
1995) to draw 50 samples of random eﬀects vector uN and retain the ﬁnal sample. This process
is repeated for the M saved values of Θ0. Once the posterior distribution of uN is simulated, all
calculations become straightforward and produce the entire distribution of the future trajectory
(health outcomes and risk) of a new patient. Suppose that patient N does not develop functional
disability by time t′, then the outcome histories are updated to y{t′}
N . We can dynamically update
the posterior distribution to p(uN |T ∗
), draw new samples, and obtain the updated
predictions.

N > t, y{t}

N , Θ(m)

0

3.4 Assessing predictive performance

It is essential to assess the performance of the proposed predictive measures. Here, we focus on
the probability of functional disability π(t′|t). Speciﬁcally, we assess the discrimination (how well
the models discriminate between patients who had the event from patients who did not) using the
receiver operating characteristic (ROC) curve and the area under the ROC curves (AUC) and assess
the validation (how well the models predict the observed data) using the expected Brier score (BS).

3.4.1 Area under the ROC curves

Following the notation in Section 3.3, for any given cut point c ∈ (0, 1), the time-dependent sen-
sitivity and speciﬁcity are deﬁned as sensitivity(c, t, t′) : P {πi(t′|t) > c|Ni(t, t′) = 1, T ∗
i > t} and
speciﬁcity(c, t, t′) : P {πi(t′|t) ≤ c|Ni(t, t′) = 0, T ∗
i ≤ t′),
indicating whether there is an event (case) or no event (control) observed for subject i during the
time interval (t, t′]. In the absence of censoring, sensitivity and speciﬁcity can be simply estimated
from the empirical distribution of the predicted risk among either cases or controls. To handle cen-
sored event times, Heagerty et al. (2000) proposed a nearest neighbor estimation (NNE) method by
estimating the bivariate distribution of the risk π and the true survival time T ∗ using nonparamet-
ric kernel methods, which is now available in the R package survivalROC. We refer to the nearest
neighbor estimation of time-dependent AUC as AUC1.

i > t}, respectively, where Ni(t, t′) = I(t < T ∗

In the NNE method, a bandwidth is needed as a tuning parameter for the kernel. However, a
practical guidance on how to choose the bandwidth is not yet available. Li et al. (2015) showed
that the result of the NNE method was sensitive to the selection of bandwidth and proposed an

10

alternative estimator for the sensitivity and speciﬁcity based on the predictive distribution of the
censored survival time:

bP {πi(t′|t) > c|Ni(t, t′) = 1, T ∗

i > t} = Pn
i=1cWi(t, t′)I{bπi(t′|t) > c}
Pn
i=1cWi(t, t′)
i=1[1 −cWi(t, t′)]I{bπi(t′|t) ≤ c}
Pn
i=1[1 −cWi(t, t′)]
wherecWi(t, t′) is the weight to account for censoring and it is deﬁned as

bP {πi(t′|t) ≤ c|Ni(t, t′) = 0, T ∗
cWi(t, t′) = I(t < ti ≤ t′)δi + I(t < ti ≤ t′)(1 − δi)P {T ∗
= I(t < ti ≤ t′)δi + I(t < ti ≤ t′)(1 − δi)(cid:20)1 −

i > t} = Pn

P {T ∗
P {T ∗

i < t′|T ∗

,

i ≥ ti,bπi(t′|t)}
i ≥ ti|bπi(t′|t)}(cid:21) .
i ≥ t′|bπi(t′|t)}

(5)

Note that the subjects who have the survival event before time t (i.e., ti < t) have their estimated
i ≥

weightcWi(t, t′) = 0 and thus they play no role in (5). The conditional survival distribution P {T ∗
˜t|bπi(t′|t)}, where ˜t can be either t′ or ti, can be estimated using kernel weighted Kaplan-Meier

method with a bandwidth d, which can be easily implemented in standard survival analysis software
accommodating weighted data:

P {T ∗

Pi′6=i Kd{bπi′(t′|t),bπi(t′|t)}I(Ti′ ≥ s) # ,
i ≥ ˜t|bπi(t′|t)} = Ys∈Ω,s≤˜t"1 −Pi′6=i Kd{bπi′(t′|t),bπi(t′|t)}I(Ti′ = s)δi′

where Ω is the set of distinct ti’s with δi = 1 and Kd is the kernel function, e.g., uniform and
Gaussian kernels. Speciﬁcally, we use uniform kernel in this article. Li et al. (2015) compared the
performance of this simple weighted estimator with the NNE method and showed that the results
were less sensitive to the bandwidth choice. Further evaluation of this weighted method in the current
context is presented in Section 5.

With the estimation of sensitivity and speciﬁcity, the time-dependent ROC curve can be con-
structed for all possible cut points c ∈ (0, 1) and the corresponding time-dependent AUC(t, t′) can
be estimated using standard numerical integration methods such as Simpson’s rule. We refer to the
weighted estimator of time-dependent AUC (Li et al., 2015) as AUC2.

3.4.2 Dynamic Brier score

The Brier score (BS) developed in survival models can be extended to joint models for prediction
validation (S`ene et al., 2014; Proust-Lima et al., 2014). The dynamic expected BS is deﬁned as
E[(D(t′|t) − π(t′|t))2], where the observed failure status D(t′|t) equals to 1 if the subject experiences
the terminal event within the time interval (t, t′] and 0 if the subject is event free until t′. An estimator

of BS is cBS(t, t′) = 1

NtPNt

i=1 bGi(t, t′) (Di(t, t′) − πi(t′|t))2, where Nt is the number of subjects at risk

11

at time t, and the weight bGi(t, t′) = I(ti>t′)

the Kaplan-Meier estimate (S`ene et al., 2014).

ˆS0(t′)/ ˆS0(t)

+ I(t<ti≤t′)δi
ˆS0(ti)/ ˆS0(t)

is to account for censoring with ˆS0 denoting

AUC and BS complement each other by assessing diﬀerent aspects of the prediction. AUC has a
simple interpretation as a concordance index, while BS accounts for the bias between the predicted
and true risks.
In general, AUC = 1 indicates perfect discrimination and AUC = 0.5 is random
guess, while BS = 0 indicates perfect prediction and BS = 0.25 is random guess. Blanche et al.
(2015) provides excellent illustration of AUC and BS.

4 Application to the DATATOP study

In this section, we apply the proposed joint model and prediction process to the motivating DATATOP
study. For all results in this section, we run two parallel MCMC chains with overdispersed initial
values and run each chain for 2, 000 iterations. The ﬁrst 1, 000 iterations are discarded as burn-in and
the inference is based on the remaining 1, 000 iterations from each chain. Good mixing properties of

of all parameters are smaller than 1.1.

the MCMC chains for all model parameters are observed in the trace plots. The scale reduction bR

In order to validate the prediction, we randomly select 555 patients in the DATATOP study as
the training dataset for model building and set aside the remaining 200 patients as the validation
dataset. The covariates of interest included in model (2) are baseline disease duration, baseline age,
treatment (active deprenyl only), time, and the interaction term of treatment and time. We allow a
ﬂexible and smooth disease progression along time by using penalized truncated power series splines
with 7 knots at the location κ = (1.2, 3, 6, 9, 12, 15, 18) in months, to ensure suﬃcient patients within
each interval. Speciﬁcally, model (2) is

θi(tij) = fi(tij) + ei(tij) = β0 + β1durationi + β2agei + β3trti + β4tij

+β5(trti × tij) +

7Xr=1

ζr(tij − κr)+ + ui0 + ui1tij + ei(tij),

where the random eﬀects (ui0, ui1)′ ∼ N2(0, Σ) with Σ = {(σ2
to avoid overﬁtting.

ζ I)

1, ρσ1σ2), (ρσ1σ2, σ2

2)} and ζ ∼ N(0, σ2

Model (3) is hi(t) = h0(t) exp(γ1durationi + γ2agei + γ3trti + νfi(t)), where baseline hazard
r=1 ξr(t − κr)+} and
ξ I). Parameter estimates based on the training dataset are presented in Table 1 and Web

h0(t) is similarly approximated by penalized splines h0(t) = exp{η0 + η1t +P7

ξ ∼ N(0, σ2
Table S1 (outcome-speciﬁc parameters only).

For the 200 patients in the validation dataset, we predict their longitudinal trajectories and the
probability of functional disability at a clinically relevant future time point, conditional on their
available measurements. To illustrate the subject-speciﬁc predictions, we select two patients from
the validation dataset, i.e., a more severe Patient 169 with clinically worse longitudinal measures
and earlier initiation of functional disability, as compared with a less severe Patient 718. Patient

12

Table 1: Parameter estimates on the training dataset from DATATOP study.

Mean

SD

95% CI

For latent disease severity
Int
Duration (months)
Age (years)
Trt (deprenyl)
Time (months)
Trt × Time
ρ
σ1
σ2
σe
σε

−1.074
0.021
0.030
−0.157
0.043
−0.095
0.329
1.373
0.122
0.100
4.966

For survival process
Duration (months) −0.015
Age (years)
−0.041
−0.758
Trt (deprenyl)
0.687
ν

0.415 −1.932 −0.289
0.029
0.012
0.004
0.044
0.007
0.018
0.126 −0.401
0.095
0.030 −0.016
0.102
0.013 −0.121 −0.072
0.423
0.049
0.060
1.489
0.136
0.007
0.150
0.025
0.095
5.150

0.233
1.261
0.110
0.058
4.784

0.005 −0.024 −0.006
0.007 −0.054 −0.028
0.140 −1.037 −0.487
0.046
0.782

0.599

13

169 had 8 visits with mean UPDRS 42.6 (SD 7.7), median HY 2, median SEADL 80, and developed
functional disability at month 16.
In contrast, Patient 718 had 9 visits with mean UPDRS 15.6
(SD 3.1), median HY 1, median SEADL 95, and was censored at month 21. Figure 2 displays the
predicted UPDRS trajectories for these two patients, based on diﬀerent amounts of data. When only
baseline measurements are used for prediction, the predicted UPDRS trajectory is biased with wide
uncertainty band. For example, Patient 169 had a relatively low baseline UPDRS value of 33 and
our model based only on baseline measurements tends to underpredict the future UPDRS trajectory
(ti = 0, the ﬁrst plot in upper panels). However, Patient 169’s higher UPDRS values of 41 and 40
at months 1 and 3, respectively, subsequently shift up the prediction and tend to overpredict the
future trajectory (ti = 3 months, the second plot in upper panels). By using more follow-up data,
predictions are closer to the true observed values and the 95% uncertainty band is narrower (ti = 6
or 12 months, the last two plots in upper panels). Patient 169’s predicted UPDRS values after 12
months are above 40 and increase rapidly, indicating a higher risk of functional disability in the near
future.
In comparison, the predicted UPDRS values for Patient 718 are relatively stable because
his/her observed UPDRS values are relatively stable.

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

S
R
D
P
U

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

0
0
1

0
8

0
6

0
4

0
2

0

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

Months

Months

Months

Months

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

S
R
D
P
U

0
0
1

0
8

0
6

0
4

0
2

0

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

Months

Months

Months

Months

Figure 2: Predicted UPDRS for Patient 169 (upper panels) and Patient 718 (lower panels). Solid
line is the mean of 2000 MCMC samples. Dashed lines are the 2.5% and 97.5% percentiles range of
the MCMC samples. The dotted vertical line represents the time of prediction t.

14

The predicted probability being in each category for outcome HY is presented in Figure 3. For
example, Patient 169 had HY measurements equal to 2 at all visits. When only the baseline data
are used for prediction (the ﬁrst plot in upper panels), our model tends to underpredict the disease
progression by assigning sizable probabilities to the less severe HY categories 1 and 1.5 even at
the end of the study, possibly due to low baseline UPDRS value of 33. After month 3 visit (the
second plot in upper panels), our model overpredicts disease progression by assigning abnormally
high probability to the severe category 3, possibly due to higher UPDRS values at months 1 and 3.
However, using the ﬁrst 6 or 12 months’ data (the last two plots in upper panels), our model has good
ﬁt by correctly assigning the largest posterior probability to HY category 2 for all visits from baseline
to month 12. Moreover, our model properly assigns higher probabilities to more severe categories 2.5
and 3 and negligible probabilities to less severe categories 1 and 1.5 for visits after month 12, due to
the deteriorating UPDRS measure. Similar interpretation can be made to the predicted probability
of being in each SEADL category displayed in Web Figure S1.

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

)

Y
H
(
b
o
r
P

)

Y
H
(
b
o
r
P

0
1

.

8

.

0

6
0

.

4

.

0

2

.

0

0
0

.

0

.

1

8
0

.

6

.

0

4

.

0

2
0

.

0

.

0

0

3

6
12
Months

18

24

after baseline visit

)

Y
H
(
b
o
r
P

)

Y
H
(
b
o
r
P

0
1

.

8

.

0

6
0

.

4

.

0

2

.

0

0
0

.

0

.

1

8
0

.

6

.

0

4

.

0

2
0

.

0

.

0

0

3

6
12
Months

18

24

after 3 month visit

)

Y
H
(
b
o
r
P

)

Y
H
(
b
o
r
P

0
1

.

8

.

0

6
0

.

4

.

0

2

.

0

0
0

.

0

.

1

8
0

.

6

.

0

4

.

0

2
0

.

0

.

0

0

3

6
12
Months

18

24

after 6 month visit

)

Y
H
(
b
o
r
P

)

Y
H
(
b
o
r
P

0
1

.

8

.

0

6
0

.

4

.

0

2

.

0

0
0

.

0

.

1

8
0

.

6

.

0

4

.

0

2
0

.

0

.

0

0

3

6
12
Months

18

24

after 12 month visit

0

3

6
12
Months

18

24

0

3

HY=1

6
12
Months

HY=1.5

18

24

0

3

HY=2

6
12
Months

HY=2.5

18

24

0

3

6
12
Months

18

24

HY=3

Figure 3: Predicted probability of being in each HY category for Patient 169 (upper panels) and
Patient 718 (lower panels). Patient 169 had HY measurements equal to 2 at all 8 visits at months
0, 1, 3, 6, 9, 12, 15, and 16, while Patient 718 had HY measurements equal to 1 at all 9 visits at
months 0, 1, 3, 6, 9, 12, 15, and 18.

Besides the predictions of longitudinal trajectories, it is more of clinical interest for patients and

15

physicians to know the probability of functional disability before time t′ > t: πi(t′|t), conditional
on the patient’s longitudinal proﬁles up to time t and the fact that he/she did not have functional
disability up to time t. The predicted probabilities for Patients 169 and 718 based on various amount
of data are presented in Figure 4. A similar pattern is that the prediction becomes more accurate if
more data are used. With such predictions, physicians are able to precisely track the health condition
of each patient and make better informed decisions individually. For example, based on the ﬁrst 12
months’ data, for Patient 169, the predicted probabilities in the next 3, 6, 9 and 12 months are 0.19,
0.44, 0.75 and 0.96 (the last plot of upper panels), while for Patient 718, the probabilities are 0.02,
0.05, 0.12 and 0.29 (the last plot of lower panels). Patient 169 has higher risk of functional disability
in the next few months and physicians may consider more invasive treatments to control the disease
symptoms before the functional disability is developed.

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

y
t
i
l
i

b
a
b
o
r
p

 

e
r
u

l
i

a
F

y
t
i
l
i

b
a
b
o
r
p
e
r
u

 

l
i

a
F

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0
0

.

0
1

.

8

.

0

6

.

0

4
0

.

2

.

0

0

.

0

y
t
i
l
i

b
a
b
o
r
p

 

e
r
u

l
i

a
F

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0
0

.

y
t
i
l
i

b
a
b
o
r
p

 

e
r
u

l
i

a
F

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0
0

.

y
t
i
l
i

b
a
b
o
r
p

 

e
r
u

l
i

a
F

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0
0

.

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

Months

Months

Months

Months

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

y
t
i
l
i

b
a
b
o
r
p
e
r
u

 

l
i

a
F

0
1

.

8

.

0

6

.

0

4
0

.

2

.

0

0

.

0

y
t
i
l
i

b
a
b
o
r
p
e
r
u

 

l
i

a
F

0
1

.

8

.

0

6

.

0

4
0

.

2

.

0

0

.

0

y
t
i
l
i

b
a
b
o
r
p
e
r
u

 

l
i

a
F

0
1

.

8

.

0

6

.

0

4
0

.

2

.

0

0

.

0

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

0

3

6

9

12 15 18 21 24

Months

Months

Months

Months

Figure 4: Predicted conditional failure probability for Patient 169 (upper panels) and Patient 718
(lower panels).

Next we assess our prediction’s performance in terms of discrimination and validation using the
validation dataset (200 patients) and present AUC1, AUC2, and BS score in Table 2. The results sug-
gest that AUC2 is less sensitive to the choices of bandwidth, as compared with AUC1, a phenomenon
discussed in details in Section 5. With increasing amount of data, both the discrimination and
validation of the prediction improve markedly. Conditional on the baseline data only (i.e., t = 0),

16

the prediction is inaccurate with small AUCs and large BS (e.g., when t′ = 15 and span = 0.05,
AUC1(t = 0, t′ = 15) = 0.708, AUC2(t = 0, t′ = 15) = 0.717, BS(0, 15) = 0.265). Using more follow
up measurements, AUCs increase, e.g., AUC1(12, 15) = 0.800 and AUC2(12, 15) = 0.790, indicat-
ing that conditional on the measurement history up to month 12, our model has 0.800 and 0.790
probabilities, respectively, to correctly assign higher probability of functional disability by month 15
to more severe patients (who had functional disability earlier) than less severe patients (who had
functional disability later). Meanwhile, BS decreases to BS(12, 15) = 0.072, i.e., the mean square
error of prediction is 0.072, suggesting good prediction in terms of validation.

Table 2: Area under the ROC curve and Brier score (BS) for the validation dataset of the DATATOP
study. AUC1: nearest neighbor estimator. AUC2: the weighted estimator.

t

0

3

6

12

t′

9
12
15
18

9
12
15
18

9
12
15
18

15
18

span=0.05

AUC1 AUC2
0.658
0.656
0.682
0.676
0.717
0.708
0.679
0.681

0.734
0.744
0.753
0.746

0.732
0.756
0.771
0.751

0.740
0.734
0.746
0.739

0.760
0.751
0.775
0.764

span=0.1

AUC1 AUC2
0.657
0.640
0.680
0.673
0.710
0.706
0.681
0.681

0.703
0.722
0.746
0.732

0.708
0.744
0.776
0.752

0.738
0.732
0.745
0.734

0.761
0.756
0.773
0.752

span=0.2

AUC1 AUC2
0.658
0.624
0.675
0.658
0.706
0.706
0.681
0.679

0.684
0.699
0.737
0.730

0.698
0.715
0.765
0.745

0.737
0.732
0.743
0.731

0.762
0.755
0.770
0.739

0.800
0.752

0.790
0.739

0.782
0.759

0.786
0.730

0.756
0.719

0.790
0.737

BS

0.210
0.261
0.265
0.254

0.184
0.240
0.235
0.177

0.116
0.183
0.188
0.166

0.072
0.125

To facilitate the personalized dynamic predictions in clinical setting, we develop a web-based
calculator available at https://kingjue.shinyapps.io/dynPred_PD_Datatop_alpha. A screenshot
of the user interface is presented in Web Figure S2. The calculator requires as input the PD patients’
baseline characteristics and their longitudinal outcome values up to the present time. The online
calculator will then produce time-dependent predictions of future health outcomes trajectories and the
probability of functional disability, in addition to the 95% uncertainty bands. Moreover, additional
data generated from more follow-up visits can be input to obtain updated predictions. The calculator

17

is a user friendly and easily accessible tool to provide physicians with dynamically-updated patient-
speciﬁc future health outcome trajectories, risk predictions, and the associated uncertainty. Such
a translational tool would be relevant both for physicians to make informed decisions on therapy
selection and for patients to better manage risks.

5 Simulation studies

In this section, we conduct an extensive simulation study to investigate the prediction performance
of the probability π(t′|t) using the proposed joint model. We also compare the performance of
the nearest neighbor estimator AUC1 with the weighted estimator AUC2 under diﬀerent choices of
bandwidth. We generate 200 datasets with samples size n = 800 subjects and six visits, i.e., baseline
and ﬁve follow-up visits (Ji = 6), with the time vector ti = (ti1, ti2, . . . , ti6)′ = (0, 3, 6, 12, 18, 24). The
simulated data structure is similar to the motivating DATATOP study, and it includes one continuous
outcome and two ordinal outcomes (each with 7 categories).

Data are generated from the following models: θi(tij) = fi(tij) + ei(tij) = β0 + β1xi1 + β2tij +
β3xi1tij + ui0 + ui1tij + ei(tij) and hi(t) = h0 exp{γxi2 + νfi(t)}. Covariate xi1 takes value 0 or
1 each with probability 0.5 to mimic treatment assignment and covariate xi2 is randomly sampled
integer from 30 to 80 to mimic age. We set coeﬃcients β = (β0, β1, β2, β3)′ = (−1, −0.2, 0.8, −0.2)′,
σe = 0.5, γ = −0.12 and ν = 0.75. For simplicity, baseline hazard is assumed to be constant with
h0 = 0.1. Parameters for the continuous outcome are a1 = 15, b1 = 7 and σε = 5. Parameters for
the ordinal outcomes are a2 = (0, 1, 2, 4, 5, 6), a3 = (−1, 1, 3, 4, 6, 8), b2 = 1 and b3 = 1.2. We assume
that random eﬀects vector ui = (ui0, ui1)′ follows a multivariate normal distribution N2(0, Σ), where
Σ = {(σ2
2)} with σ1 = 1.5, σ2 = 0.15 and ρ = 0.4. The independent censoring
time is sampled from Uniform(10, 24).

1, ρσ1σ2), (ρσ1σ2, σ2

From each simulated dataset, we randomly select 600 subjects as the training dataset and set
aside the remaining 200 subjects as the validation dataset. Web Table S2 displays bias (the average
of the posterior means minus the true values), standard deviation (SD, the standard deviation of
the posterior means), coverage probabilities (CP) of 95% equal tail credible intervals, and root mean
squared error (RMSE) of model inference based on the training dataset. The results suggest that
the model ﬁtting based on the training dataset provides parameter estimates with very small biases
and RMSE and the CP being close to the nominal level 0.95. Using MCMC samples from the ﬁtted
model and available measurements up to time t, we make prediction of πi(t′|t) for each subject in
the validation dataset.

Web Table S3 presents the two estimators of the time-dependent AUC with diﬀerent bandwidths.
Compared with AUC2, AUC1 is more sensitive to bandwidth selection. For example, AUC1(0, 9)
is equal to 0.896, 0.903, 0.890 with span being 0.05, 0.1, and 0.2, respectively, while AUC2 re-
mains unchanged at 0.905 for all spans. Predictions have high discriminating capability with high
AUC values over 0.9. AUC is increasing when more data are available, e.g., AUC2(0, 9) = 0.905,
AUC2(3, 9) = 0.921 and AUC2(6, 9) = 0.926 at span 0.05.

18

From each of the 200 simulation datasets, we randomly select 20 subjects to plot the bias between
the predicted event probability π(t′|t) and the true event probability with t′ = 9 (upper panels) and
t′ = 12 (lower panels) in Web Figure S3. When more data are available, bias is decreasing as more
bias is within the region of [−0.2, 0.2]. For example, with only baseline data, 7.4% and 22.7% of
bias for the predictions of π(t′ = 9|t = 0) and π(t′ = 12|t = 0), respectively, are outside the range.
With up to three months’ data, 4.5% and 16.4% of bias for the predictions of π(t′ = 9|t = 3) and
π(t′ = 12|t = 3), respectively, are outside the range. With up to six months’ data, the prediction is
precise with only 2.2% and 9.8% of bias for the prediction of π(t′ = 9|t = 6) and π(t′ = 12|t = 6),
respectively, being outside the range.

6 Discussion

Multiple longitudinal outcomes are often collected in clinical trials of complex diseases such as Parkin-
son’s disease (PD) to better measure diﬀerent aspects of disease impairment. However, both the-
oretical and computational complexity in modeling multiple longitudinal outcomes often restrict
researchers to a univariate longitudinal outcome. Without careful analysis of the entire data, pace
of treatment discovery can be dramatically slowed down.

In this article, we ﬁrst propose a joint model that consists of a semiparametric latent trait linear
mixed model (LTLMM) for the multiple longitudinal outcomes by introducing a continuous latent
variable to represent patients’ underlying disease severity, and a survival submodel for the event time
data. The latent variable modeling eﬀectively reduces the number of outcomes and has improved
computational feasibility and model interpretability. Next we develop the process of making per-
sonalized dynamic predictions of future outcome trajectories and risks of target event. Extensive
simulation studies suggest that the predictions are accurate with high AUC and small bias. We
apply the method to the motivating DATATOP study. The proposed joint models can eﬃciently
utilize the multivariate longitudinal outcomes of mixed types, as well as the survival process to make
correct predictions for new subjects. When new measurements are available, predictions can be dy-
namically updated and become more accurate and eﬃcient. A web-based calculator is developed as
a supplemental tool for PD physicians to monitor their patients’ disease progression. For subjects
with high predicted risk of functional disability in the near future, physicians may consider more
targeted treatment to defer the initiation of levodopa therapy because of its association with motor
complications and notable adverse events (Brooks, 2008). Although the dynamic prediction frame-
work has utilized only three longitudinal outcomes in the DATATOP study, it can be broadly applied
to similar studies with more longitudinal outcomes.

There are some limitations in our proposed dynamic prediction framework that we will address in
the future study. First, the semiparametric LTLMM sub-model assumes a univariate latent variable
(unidimensional assumption), which may be reasonable for small number of outcomes. However, for
large number of longitudinal outcomes, multiple latent variables may be required to fully represent
the true disease severity across diﬀerent domains impaired by PD. We will develop a multidimen-

19

sional latent trait linear mixed model (MLTLMM) that allows multiple latent variables. Moreover,
functional forms of joint models that allow a reasonable summary of the whole longitudinal trajecto-
ries have been investigated (Brown, 2009). To this end, Rizopoulos et al. (2014) investigated various
models for the association between the longitudinal and event time responses and used Bayesian
model averaging (BMA) to combine joint models with diﬀerent association structures. However,
functional forms in the context of latent variables deserve more research eﬀort.

Missed visits and missing covariates exist in the DATATOP study. In this article, we assume that
they are missing at random (MAR). However, the missing data issue becomes more complicated in
prediction model framework because it can impact both the model inference (missing data in the
training dataset) and dynamic prediction process (e.g., the new subject only has measurements of
UPDRS and HY, but not SEADL). How to address this issue in the proposed prediction framework
is an important direction of future research. Moreover, the online calculator is based on the training
dataset from the DATATOP study, which may not represent PD patients at all stages and from all
populations. Nonetheless, the large and carefully studied group of patients provides an important
resource to study the clinical expression of PD. We will continue to improve the calculator by including
more heterogeneous PD patients from diﬀerent studies.

Acknowledgements

Sheng Luo’s research was supported by the National Institute of Neurological Disorders and Stroke
under Award Number R01NS091307 and by the National Center for Advancing Translational Sciences
under Award Number KL2-TR000370. The authors acknowledge the Texas Advanced Computing
Center (TACC) for providing high-performing computing resources.

References

Blanche, Paul, Proust-Lima, C´ecile, Loub`ere, Lucie, Berr, Claudine, Dartigues, Jean-Fran¸cois, &
Jacqmin-Gadda, H´el`ene. 2015. Quantifying and comparing dynamic predictive accuracy of joint
models for longitudinal marker and time-to-event in presence of censoring and competing risks.
Biometrics, 71(1), 102–113.

Brooks, David J. 2008.

Optimizing levodopa therapy for Parkinson’s disease with lev-
odopa/carbidopa/entacapone: Implications from a clinical and patient perspective. Neuropsy-
chiatric Disease and Treatment, 4(1), 39.

Brown, Elizabeth R. 2009. Assessing the association between trends in a biomarker and risk of event

with an application in pediatric HIV/AIDS. The Annals of Applied Statistics, 3(3), 1163–1182.

Brown, Elizabeth R, & Ibrahim, Joseph G. 2003. Bayesian Approaches to Joint Cure-Rate and

Longitudinal Models with Applications to Cancer Vaccine Trials. Biometrics, 59(3), 686–693.

20

Chi, Yueh-Yun, & Ibrahim, Joseph G. 2006. Joint models for multivariate longitudinal and multi-

variate survival data. Biometrics, 62(2), 432–445.

Crainiceanu, Ciprian, Ruppert, David, & Wand, Matthew P. 2005. Bayesian analysis for penalized

spline regression using WinBUGS. Journal of Statistical Software, 14(14), 1–24.

Diggle, P., & Kenward, M. G. 1994. Informative drop-out in longitudinal data analysis. Applied

statistics, 49–93.

Duane, S, Kennedy, AD, Pendleton, BJ, & Roweth, D. 1987. Hybrid Monte Carlo. Physics Letters

B, 195(2), 216–222.

Elashoﬀ, Robert M, Li, Gang, & Li, Ning. 2007. An approach to joint analysis of longitudinal

measurements and competing risks failure time data. Statistics in Medicine, 26(14), 2813–2835.

Fox, JP. 2005. Multilevel IRT using dichotomous and polytomous response data. British Journal of

Mathematical and Statistical Psychology, 58(1), 145–172.

Gelman, A, Carlin, JB, Stern, HS, Dunson, DB, Vehtari, A, & Rubin, DB. 2013. Bayesian Data

Analysis. CRC press.

Gilks, Wally R, Best, NG, & Tan, KKC. 1995. Adaptive rejection Metropolis sampling within Gibbs

sampling. Applied Statistics, 44(4), 455–472.

He, B, & Luo, S. 2013. Joint modeling of multivariate longitudinal measurements and survival data

with applications to Parkinson’s disease. Statistical Methods in Medical Research, OnlineFirst.

Heagerty, Patrick J, Lumley, Thomas, & Pepe, Margaret S. 2000. Time-dependent ROC curves for

censored survival data and a diagnostic marker. Biometrics, 56(2), 337–344.

Hoﬀman, Matthew D, & Gelman, Andrew. 2014. The no-U-turn sampler: Adaptively setting path
lengths in Hamiltonian Monte Carlo. The Journal of Machine Learning Research, 15(1), 1593–
1623.

Lambert, P, & Vandenhende, F. 2002. A copula-based model for multivariate non-normal longitudinal
data: analysis of a dose titration safety study on a new antidepressant. Statistics in Medicine,
21(21), 3197–3217.

Li, L, Greene, T, & Hu, B. 2015. A simple method to estimate the time-dependent ROC curve under

right censoring. Working Paper 114. http://biostats.bepress.com/cobra/art114.

Liu, Lei, & Huang, Xuelin. 2009. Joint analysis of correlated repeated measures and recurrent events
processes in the presence of death, with application to a study on acquired immune deﬁciency
syndrome. Journal of the Royal Statistical Society: Series C (Applied Statistics), 58(1), 65–81.

21

Lunn, David J, Thomas, Andrew, Best, Nicky, & Spiegelhalter, David. 2000. WinBUGS-a Bayesian
modelling framework: concepts, structure, and extensibility. Statistics and Computing, 10(4),
325–337.

Luo, Sheng, & Wang, Jue. 2014. Bayesian hierarchical model for multiple repeated measures and

survival data: An application to Parkinson’s disease. Statistics in Medicine, 33(24), 4279–4291.

Molenberghs, G, & Verbeke, G. 2005. Models for discrete longitudinal data. Springer.

O’Brien, Liam M, & Fitzmaurice, Garrett M. 2004. Analysis of longitudinal multiple-source binary
data using generalized estimating equations. Journal of the Royal Statistical Society: Series C,
53(1), 177–193.

Proust-Lima, C´ecile, S´ene, Mb´ery, Taylor, Jeremy MG, & Jacqmin-Gadda, H´el`ene. 2014. Joint latent
class models for longitudinal and time-to-event data: A review. Statistical Methods in Medical
Research, 23(1), 74–90.

Rizopoulos, Dimitris. 2011. Dynamic Predictions and Prospective Accuracy in Joint Models for

Longitudinal and Time-to-Event Data. Biometrics, 67(3), 819–829.

Rizopoulos, Dimitris, Murawska, Magdalena, Andrinopoulou, Eleni-Rosalina, Molenberghs, Geert,
Takkenberg, Johanna JM, & Lesaﬀre, Emmanuel. 2013. Dynamic Predictions with Time-
Dependent Covariates in Survival Analysis using Joint Modeling and Landmarking. arXiv preprint
arXiv:1306.6479.

Rizopoulos, Dimitris, Hatﬁeld, Laura A, Carlin, Bradley P, & Takkenberg, Johanna JM. 2014.
Combining dynamic predictions from joint models for longitudinal and time-to-event data using
Bayesian model averaging. Journal of the American Statistical Association, 109(508), 1385–1397.

Ruppert, David. 2012. Selecting the number of knots for penalized splines. Journal of Computational

and Graphical Statistics.

Ruppert, David, Wand, Matthew P, & Carroll, Raymond J. 2003. Semiparametric Regression. Cam-

bridge University Press.

S`ene, Mb´ery, Taylor, Jeremy MG, Dignam, James J, Jacqmin-Gadda, H´el`ene, & Proust-Lima, C´ecile.
2014. Individualized dynamic prediction of prostate cancer recurrence with and without the initia-
tion of a second treatment: Development and validation. Statistical Methods in Medical Research,
OnlineFirst.

Shoulson, Ira. 1998. DATATOP: A decade of neuroprotective inquiry. Annals of Neurology, 44(S1),

S160–S166.

22

Stan Development Team. 2015. Stan Modeling Language Users Guide and Reference Manual, Version

2.8.0.

Sun, Jianguo, Park, Do-Hwan, Sun, Liuquan, & Zhao, Xingqiu. 2005. Semiparametric regression
analysis of longitudinal data with informative observation times. Journal of the American Statistical
Association, 100(471), 882–889.

Taylor, Jeremy MG, Park, Yongseok, Ankerst, Donna P, Proust-Lima, Cecile, Williams, Scott, Kestin,
Larry, Bae, Kyoungwha, Pickles, Tom, & Sandler, Howard. 2013. Real-time individual predictions
of prostate cancer recurrence using joint models. Biometrics, 69(1), 206–213.

Tseng, Yi-Kuan, Hsieh, Fushing, & Wang, Jane-Ling. 2005. Joint modelling of accelerated failure

time and longitudinal data. Biometrika, 92(3), 587–603.

Tsiatis, A. A., & Davidian, M. 2004. Joint modeling of longitudinal and time-to-event data: An

overview. Statistica Sinica, 14(3), 809–834.

van Houwelingen, Hans C. 2007. Dynamic prediction by landmarking in event history analysis.

Scandinavian Journal of Statistics, 34(1), 70–85.

Verbeke, G, Fieuws, S, Molenberghs, G, & Davidian, M. 2014. The analysis of multivariate longitu-

dinal data: A review. Statistical Methods in Medical Research, 23(1), 42–59.

Vonesh, Edward F, Greene, Tom, & Schluchter, Mark D. 2006. Shared parameter models for the

joint analysis of longitudinal data and event times. Statistics in Medicine, 25(1), 143–163.

Wulfsohn, Michael S, & Tsiatis, Anastasios A. 1997. A joint model for survival and longitudinal data

measured with error. Biometrics, 53(1), 330–339.

Xu, Jane, & Zeger, Scott L. 2001. Joint analysis of longitudinal data comprising repeated measures

and times to events. Journal of the Royal Statistical Society: Series C, 50(3), 375–387.

Yang, Lili, Yu, Menggang, & Gao, Sujuan. 2015. Prediction of coronary artery disease risk based on

multiple longitudinal biomarkers. Statistics in Medicine.

23

Web Supplement

Table S1: The outcome-speciﬁc parameter estimates from the training dataset in the DATATOP
sutdy.

Mean
For UPDRS
17.114
a1
7.334
b1

For HY
a22
a23
a24

0.994
4.170
6.491

For SEADL
a31 −1.395
0.693
a32
3.158
a33
3.965
a34
6.177
a35
7.100
a36
8.919
a37
1.255
b3

SD

95% CI

0.381
0.219

16.330
6.887

17.832
7.765

0.042
0.093
0.155

0.913
3.989
6.194

1.077
4.356
6.786

0.085 −1.571 −1.228
0.080
0.851
3.361
0.104
4.184
0.113
0.159
6.498
7.448
0.182
9.431
0.255
0.048
1.349

0.541
2.965
3.743
5.872
6.746
8.427
1.165

24

after baseline visit

after 3 month visit

after 6 month visit

after 12 month visit

)
L
D
A
E
S
(
b
o
r
P

)
L
D
A
E
S
(
b
o
r
P

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0

.

0

0

.

1

8

.

0

6

.

0

4
0

.

2

.

0

0
0

.

0

3

6
12
Months

18

24

after baseline visit

)
L
D
A
E
S
(
b
o
r
P

)
L
D
A
E
S
(
b
o
r
P

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0

.

0

0

.

1

8

.

0

6

.

0

4
0

.

2

.

0

0
0

.

0

3

6
12
Months

18

24

after 3 month visit

)
L
D
A
E
S
(
b
o
r
P

)
L
D
A
E
S
(
b
o
r
P

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0

.

0

0

.

1

8

.

0

6

.

0

4
0

.

2

.

0

0
0

.

0

3

6
12
Months

18

24

after 6 month visit

)
L
D
A
E
S
(
b
o
r
P

)
L
D
A
E
S
(
b
o
r
P

0

.

1

8

.

0

6

.

0

4

.

0

2
0

.

0

.

0

0

.

1

8

.

0

6

.

0

4
0

.

2

.

0

0
0

.

0

3

6
12
Months

18

24

after 12 month visit

0

3

6
12
Months

18

24

0

3

6
12
Months

18

24

0

3

6
12
Months

18

24

0

3

6
12
Months

18

24

100

95

90

85

80

75

70

£ 65

Figure S1: Predicted probability of SEADL to be observed in a given category for Subject 169
(upper panels) and Subject 718 (lower panels). Observed categories of SEADL for Subject 169 in
the 8 follow-up visits are 90, 80, 80, 90, 80, 80, 80, 80 and for Subject 718 in the 9 visits are 95, 95,
95, 95, 90, 95, 95, 95, 95.

25

Table S2: Simulation results using the training dataset.

BIAS

SD

CP RMSE

For the latent disease severity
−0.000
β0 = −1
β1 = −0.2 −0.005
β2 = 0.8
0.005
β3 = −0.2 −0.002
σ1 = 1.5
0.009
0.000
σ2 = 0.15
−0.001
ρ = 0.4
σe = 0.5
−0.004

0.119
0.119
0.025
0.016
0.071
0.008
0.053
0.039

0.955
0.965
0.935
0.940
0.910
0.920
0.955
0.940

0.119
0.119
0.025
0.016
0.071
0.008
0.053
0.040

For the survival process
γ = −0.12 −0.001
ν = 0.75
0.003

0.008
0.045

0.950
0.945

0.008
0.045

−0.007
−0.036
0.019

0.483
0.194
0.184

0.003
0.008
0.023
0.032
0.034

0.061
0.085
0.128
0.149
0.170

For the ﬁrst outcome (continuous)
a1 = 15
0.950
0.940
b1 = 7
σε = 5
0.925
For the second outcome (ordinal)
a22 = 1
a23 = 2
a24 = 4
a25 = 5
a26 = 6
For the third outcome (ordinal)
a31 = −1
a32 = 1
a33 = 3
a34 = 4
a35 = 6
a36 = 8
b3 = 1.2

−0.004
0.006
0.018
0.024
0.046
0.061
0.004

0.105
0.110
0.130
0.148
0.182
0.244
0.049

0.955
0.950
0.920
0.930
0.940

0.955
0.960
0.940
0.935
0.955
0.925
0.935

0.482
0.197
0.185

0.061
0.085
0.130
0.152
0.173

0.105
0.110
0.131
0.150
0.187
0.251
0.049

26

Figure S2: A screenshot of the web-based calculator for prediction.

27

after baseline visit

after 3 month visit

after 6 month visit

 

)
9
=
 
*
t
(
 
s
a
B

i

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

4.5% outside

 

)
9
=
 
*
t
(
 
s
a
B

i

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

2.2% outside

7.4% outside

0

50

100

150

200

0

50

100

150

200

0

50

100

150

200

Dataset

Dataset

Dataset

after baseline visit

after 3 month visit

after 6 month visit

 

)
2
1
=
 
*
t
(
 
s
a
B

i

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

16.4% outside

 

)
2
1
=
 
*
t
(
 
s
a
B

i

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

9.8% outside

22.7% outside

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

0

.

1

6

.

0

2

.

0

2

.

0
−

6

.

0
−

0

.

1
−

 

)
9
=
 
*
t
(
 
s
a
B

i

 

)
2
1
=
 
*
t
(
 
s
a
B

i

0

50

100

150

200

0

50

100

150

200

0

50

100

150

200

Dataset

Dataset

Dataset

) with true failure probability
when t′ = 9 (upper panels) and t′ = 12 (lower panels) for 20 randomly selected subjects from each
of the 200 simulation datasets.

Figure S3: Bias between the predicted failure probabilitybπi(t′|y{t}

, X {t}

i

i

28

Table S3: Area under the ROC curve for the simulation study. AUC1: nearest neighbor estimator.
AUC2: the weighted estimator.

t

0

3

6

t′

9
12
15
18

9
12
15
18

9
12
15
18

span=0.05

AUC1 AUC2
0.905
0.896
0.893
0.895
0.881
0.878
0.865
0.870

0.914
0.917
0.911
0.905

0.912
0.927
0.929
0.927

0.921
0.914
0.907
0.898

0.926
0.923
0.925
0.919

span=0.1

AUC1 AUC2
0.905
0.903
0.893
0.899
0.884
0.880
0.871
0.870

0.928
0.925
0.916
0.907

0.930
0.937
0.935
0.930

0.921
0.914
0.909
0.903

0.926
0.923
0.927
0.925

span=0.2

AUC1 AUC2
0.905
0.890
0.893
0.892
0.878
0.879
0.869
0.860

0.912
0.918
0.912
0.898

0.910
0.928
0.931
0.921

0.921
0.914
0.909
0.904

0.926
0.923
0.928
0.929

Stan code for the simulation study

data {

int<lower=0> N_train; // Number of subjects in training data
int<lower=0> obs; // Number of observations
int subject[obs]; // Subject ID
int<lower=0> K_ordi; // number of ordinal outcomes
real Y_conti[obs];
int<lower=0> Y_ordi[obs, K_ordi];
int<lower=0> n_ordi; // Number of categories for ordinal outcomes
vector[2] zero;
real<lower=0> time[obs];
int<lower=0> treat[obs];
int<lower=0> treat_pts[N_train];
int<lower=0, upper=100> age_pts[N_train];
real tee[N_train]; // Survival time
int<lower=0> event[N_train]; // Censoring indicator

}
parameters {

vector<lower=-10, upper=10>[2] beta0;
vector<lower=-10, upper=10>[2] beta1;
vector[2] U[N_train];
real<lower=0> var1;
real<lower=0> var2;
real<lower=-1, upper=1> rho;
real e[obs];
real<lower=0> var_e;
real<lower=0> var_conti;
real gamma;

29

real nu;
real h0;
real a_conti;
real<lower=0> b_conti;
real a_ordi_temp;
real<lower=0> b_ordi_temp;
vector<lower=0>[n_ordi-2] delta[K_ordi];

}
transformed parameters {

real<lower=0> sig1;
real<lower=0> sig2;
cov_matrix[2] Sigma_U;
real<lower=0> sd_e;
real<lower=0> sd_conti;
vector[n_ordi-1] a_ordi[K_ordi];
vector<lower=0>[K_ordi] b_ordi;
real theta[obs];
real mu_conti[obs];
real<lower=0, upper=1> psi[obs, K_ordi, n_ordi];
vector<lower=0, upper=1>[n_ordi] prob_y[obs, K_ordi];

// construct the latent variable theta
for (i in 1:obs)

theta[i] <- beta0[1] + beta0[2]*treat[i] + U[subject[i], 1] +

(beta1[1] + beta1[2]*treat[i] + U[subject[i], 2])*time[i] + e[i];

// construct the means for the continuous variables
for (i in 1:obs)

mu_conti[i] <- a_conti + b_conti*theta[i];

// construct the probability vector for the remaining ordinal variables
a_ordi[1, 1] <- 0;
for (l in 2:(n_ordi-1)) a_ordi[1, l] <- a_ordi[1, l-1] + delta[1, l-1] ;
for (k in 2:K_ordi) {

a_ordi[k, 1] <- a_ordi_temp;
for (l in 2:(n_ordi-1)) a_ordi[k, l] <- a_ordi[k, l-1] + delta[k, l-1];

}
b_ordi[1] <- 1;
for (k in 2:K_ordi) b_ordi[k] <- b_ordi_temp;

for (i in 1:obs) {

for (k in 1:K_ordi) {

for (l in 1:(n_ordi-1)) {

psi[i, k, l] <- inv_logit(a_ordi[k, l] - b_ordi[k]*theta[i]);

}
psi[i, k, n_ordi] <- 1;

prob_y[i, k, 1] <- psi[i, k, 1];
for (l in 2:n_ordi) {prob_y[i, k, l] <- psi[i, k, l] - psi[i, k, l-1];}

}

}

sd_e <- sqrt(var_e);
sd_conti <- sqrt(var_conti);
sig1 <- sqrt(var1);
sig2 <- sqrt(var2);

// construct the variance-covariance matrix
Sigma_U[1,1] <- sig1*sig1;
Sigma_U[1,2] <- rho*sig1*sig2;

30

Sigma_U[2,1] <- Sigma_U[1,2];
Sigma_U[2,2] <- sig2*sig2;

}
model {

real h[N_train];
real S[N_train];
real LL[N_train];

Y_conti ~ normal(mu_conti, sd_conti);
for (i in 1:obs) {

for (k in 1:K_ordi) {

Y_ordi[i, k] ~ categorical(prob_y[i, k]);

}

}

// construct random effects
U ~ multi_normal(zero, Sigma_U);
e ~ normal(0, sd_e);

// construct survival part
for (i in 1:N_train) {

h[i] <- exp(gamma*age_pts[i] + nu*(beta0[1] + beta0[2]*treat_pts[i] + U[i, 1] +

S[i] <- exp(-h0*exp(gamma*age_pts[i]+nu*(beta0[1]+beta0[2]*treat_pts[i]+U[i, 1])) *

(beta1[1] + beta1[2]*treat_pts[i] + U[i, 2])*tee[i]))*h0;

LL[i] <- log(pow(h[i],event[i])*S[i]);

// event=1 for event; 0 for censored

(exp(nu*(beta1[1]+beta1[2]*treat_pts[i]+U[i, 2])*tee[i])-1) / (nu*(beta1[1]+beta1[2]*treat_pts[i]+U[i, 2])));

}
increment_log_prob(LL);

// construct the priors
beta0 ~ normal(0, 10);
beta1 ~ normal(0, 10);
var1 ~ inv_gamma(0.01, 0.01);
var2 ~ inv_gamma(0.01, 0.01);
rho ~ uniform(-1, 1);
var_e ~ inv_gamma(0.01, 0.01);
var_conti ~ inv_gamma(0.01, 0.01);

h0 ~ gamma(0.01, 0.01);
nu ~ normal(0, 10);
gamma ~ normal(0, 10);

for (i in 1:(n_ordi-2)) delta[1, i] ~ normal(0, 10) T[0,] ;
for (k in 2:K_ordi) {

b_ordi_temp ~ uniform(0, 10);
a_ordi_temp ~ normal(0, 10);
for (i in 1:(n_ordi-2)) delta[k, i] ~ normal(0, 10) T[0,] ;

}

}

31

