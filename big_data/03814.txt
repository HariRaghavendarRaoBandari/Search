Solving MaxSAT by Successive Calls to a SAT Solver

Mohamed El Halaby
Department of Mathematics

Faculty of Science

Cairo University

Giza, 12613, Egypt

halaby@sci.cu.edu.eg

Abstract

The Maximum Satisﬁability (MaxSAT) problem is the problem of ﬁnding a truth
assignment that maximizes the number of satisﬁed clauses of a given Boolean formula
in Conjunctive Normal Form (CNF). Many exact solvers for MaxSAT have been de-
veloped during recent years, and many of them were presented in the well-known SAT
conference. Algorithms for MaxSAT generally fall into two categories: (1) branch and
bound algorithms and (2) algorithms that use successive calls to a SAT solver (SAT-
based), which this paper in on. In practical problems, SAT-based algorithms have
been shown to be more eﬃcient. This paper provides an experimental investigation
to compare the performance of recent SAT-based and branch and bound algorithms
on the benchmarks of the MaxSAT Evaluations.

6
1
0
2

 
r
a

 

M
1
1

 
 
]
I

A
.
s
c
[
 
 

1
v
4
1
8
3
0

.

3
0
6
1
:
v
i
X
r
a

1

Contents

1 Introduction and Preliminaries

2 Linear Search Algorithms

3 Binary Search-based Algorithms

4

5

7

4 Core-guided Algorithms

12
4.1 Fu and Malik’s algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
4.2 WPM1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
4.3
Improved WPM1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
4.4 WPM2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
4.5 WMSU1-ROR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4.6 WMSU3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
4.7 WMSU4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

5 Core-guided Binary Search Algorithms

6 Portfolio MaxSAT Techniques

26

31

7 Translating Pseudo-Boolean Constraints into CNF

31
7.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
7.2 Encoding method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
7.3 Complexity of the encoding . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
7.3.1 Polynomial cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
7.3.2 Exponential cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
7.4 Other encoding techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

8 Experimental Investigation

35
8.1 Solvers descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
8.2 Benchmarks descriptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
8.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
8.3.1 Random category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
8.3.2 Crafted category . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
8.3.3
Industrial category . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

9 Acknowledgments

42

2

List of Algorithms

1

2
3
4

LinearUNSAT(φ) Linear search UNSAT-based algorithm for solving WP-
MaxSAT.
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
LinearSAT(φ) Linear search SAT-based algorithm for solving WPMaxSAT. .
BinS-WPMaxSAT(φ) Binary search based algorithm for solving WPMaxSAT.
BinLin-WPMaxSAT(φ) Alternating binary and linear searches for solving
WPMaxSAT. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
BitBased-WPMaxSAT(φ) A bit-based algorithm for solving WPMaxSAT. . . 11
5
6
Fu&Malik(φ) Fu and Malik’s algorithm for solving PMaxSAT.
. . . . . . . . 13
7 WPM1(φ) The WPM1 algorithm for WPMaxSAT. . . . . . . . . . . . . . . . 14
8
. . . . . . 16
9 WPM2(φ) The WPM2 algorithm for WPMaxSAT . . . . . . . . . . . . . . . 18
10 NewBound(AL, B) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
11 WMSU1-ROR(φ)
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
12 Hard((Ci, wi), R) Determines if a clause is hard or not . . . . . . . . . . . . . 23
13 ROR((Ci, wi), R) Determines if a clause is hard or not or if its ancestors are

ImprovedWPM1(φ) The stratiﬁed approach for WPM1 algorithm.

5
6
8

used at most once . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
. . . . . . . . . . . . . 24
. . . . . . . . . . . . . 25

14 WMSU3(φ) The WMSU3 algorithm for WPMaxSAT.
15 WMSU4(φ) The WMSU4 algorithm for WPMaxSAT.
16 CoreGuided-BS(φ) Core-guided binary search algorithm for solving WP-

MaxSAT.

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

17 DisjointCoreGuided-BS(φ) Core-guided binary search extended with disjoint

cores for solving WPMaxSAT.

. . . . . . . . . . . . . . . . . . . . . . . . . . 29

3

1

Introduction and Preliminaries

a variable x or its negation ¬x. A clause is a disjunction of literals, i.e.,(cid:87)n
where each clause Ci is composed of mi is deﬁned as F =(cid:86)k

A Boolean variable x can take one of two possible values 0 (false) or 1 (true). A literal l is
i=1 li. A CNF
formula is a conjunction of clauses. Formally, a CNF formula φ composed of k clauses,
j=1 li,j.
In this paper, a set of clauses {C1, C2, . . . , Ck} is referred to as a Boolean formula. A

i=1 Ci where Ci =(cid:87)mi

truth assignment satisﬁes a Boolean formula if it satisﬁes every clause.

Given a CNF formula φ, the satisﬁability problem (SAT) is deciding whether φ has a
satisfying truth assignment (i.e., an assignment to the variables of φ that satisﬁes every
clause). The Maximum Satisﬁability (MaxSAT) problem asks for a truth assignment that
maximizes the number of satisﬁed clauses in φ.

Many theoretical and practical problems can be encoded into SAT and MaxSAT such
as debugging [51], circuits design and scheduling of how an observation satellite captures
photos of Earth [56], course timetabling [11, 45, 41, 34], software package upgrades [24],
routing [58, 46], reasoning [52] and protein structure alignment in bioinformatics [50].
Let φ = {(C1, w2), . . . , (Cs, ws)} ∪ {(Cs+1,∞), . . . , (Cs+h,∞)} be a CNF formula,
where w1, . . . , ws are natural numbers. The Weighted Partial MaxSAT problem asks for
an assignment that satisﬁes all Cs+1, . . . , Cs+h (called hard clauses) and maximizes the
sum of the weights of the satisﬁed clauses in C1, . . . , Cs (called soft clauses).

In general, exact MaxSAT solvers follow one of two approaches: successively calling
a SAT solver (sometimes called the SAT-based approach) and the branch and bound ap-
proach. The former converts each MaxSAT problem with diﬀerent hypothesized maximum
weights into multiple SAT problems and uses a SAT solver to solve these SAT problems to
determine the actual solution. The SAT-based approach converts the WPMaxSAT prob-
lem into a sequence of SAT instances which can be solved using SAT solvers. One way
to do this, given an unweighted MaxSAT instance, is to check if there is an assignment
that falsiﬁes no clauses. If such an assignment can not be found, we check if there is an
assignment that falsiﬁes only one clause. This is repeated and each time we increment the
number of clauses that are allowed to be F alse until the SAT solver returns T rue, meaning
that the minimum number of falsiﬁed clauses has been determined. Recent comprehensive
surveys on SAT-based algorithms can be found in[43, 8].

The second approach utilizes a depth-ﬁrst branch and bound search in the space of
possible assignments. An evaluation function which computes a bound is applied at each
search node to determine any pruning opportunity. This paper surveys the satisﬁability-
based approach and provides an experimental investigation and comparison between the
performances of both approaches on sets of benchmarks.

Because of the numerous calls to a SAT solver this approach makes, any improvement to
SAT algorithms immediately beneﬁts MaxSAT SAT-based methods. Experimental results
from the MaxSAT Evaluations1 have shown that SAT-based solvers are more competent
to handle large MaxSAT instances from industrial applications than branch and bound
methods.

1Web page: http://www.maxsat.udl.cat

4

2 Linear Search Algorithms

from a lower bound LB initialized with the maximum possible cost (i.e. LB =(cid:80)|φS|

A simple way to solve WPMaxSAT is to augment each soft clause Ci with a new variable
(called a blocking variable) bi, then a constraint is added (speciﬁed in CNF) saying that
the sum of the weights of the falsiﬁed soft clauses must be less than a given value k. Next,
the formula (without the weights) together with the constraint is sent to a SAT solver
to check whether or not it is satisﬁable. If so, then the cost of the optimal solution is
found and the algorithm terminates. Otherwise, k is decreased and the process continues
until the SAT solver returns T rue. The algorithm can start searching for the optimal cost
i=1 wi)
and decrease it down to the optimal cost, or it can set LB = 0 and increase it up to the
optimal cost. Solvers that employ the former approach is called satisﬁability-based (not to
be confused with the name of the general method) solvers, while the ones that follow the
latter are called UNSAT-based solvers. A cost of 0 means all the soft clauses are satisﬁed
and a cost of means all the soft clauses are falsiﬁed.

Algorithm 1 employs the ﬁrst method to search for the optimal cost by maintaining

(maintaining a lower bound initialized to 0) (line 1).

Algorithm 1: LinearUNSAT(φ) Linear search UNSAT-based algorithm for solving
WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

1 LB ← 0
2 foreach (Ci, wi) ∈ φS do

let bi be a new blocking variable
φS ← φS \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

(state, I) ← SAT ({C | (C, w) ∈ φ} ∪ CN F ((cid:80)|φS|

5 while T rue do

3

4

6

7

8

9

if state = T rue then

return I

LB ← U pdateBound({w | (C, w) ∈ φS}, LB)

i=1 wibi ≤ LB))

Next, the algorithm relaxes each soft clause with a new variable in lines 2-4. The
formula φ now contains each soft clause augmented with a new blocking variable. The
while loop in lines 5-9 sends the clauses of φ (without the weights) to a SAT solver (line
6). If the SAT solver returns T rue, then LinearUNSAT terminates returning a solution
(lines 7-8). Otherwise, the lower bound is updated and the loop continues until the SAT
solver returns T rue. The function U pdateBound in line 9 updates the lower bound either
by simply increasing it or by other means that depend on the distribution of the weights
of the input formula. Later in this paper we will see how the subset sum problem can be a
possible implementation of U pdateBound. Note that it could be ineﬃcient if U pdateBound
changes LB by one in each iteration. Consider a WPMaxSAT formula with ﬁve soft clauses
having the weights 1, 1, 1, 1 and 100. The cost of the optimal solution can not be anything
else other than 0, 1, 2, 3, 4, 100, 101, 102, 103 and 104. Thus, assigning LB any of the values
5, . . . , 99 is unnecessary and will result in a large number of iterations.

5

Example 2.1. Let φ = φS ∪ φH , where φS = {(x1, 5), (x2, 5), (x3, 10),
(x4, 5), (x5, 10), (x6, 5), (¬x6, 10)} and φH = {¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞), (¬x3 ∨
¬x4,∞), (¬x4 ∨¬x5,∞), (¬x5 ∨¬x1,∞)}. If we run LinearUNSAT on φ, the soft clauses
will be be relaxed {(x1 ∨ b1, 5), (x2 ∨ b2, 5), (x3 ∨ b3, 10), (x4 ∨ b4, 5), (x5 ∨ b5, 10), (x6 ∨
b6, 5), (¬x6 ∨ b7, 10)} and LB is initialized to 0. The sequence of iterations are

1. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 0) is included,

state = F alse, LB = 5.

2. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 5) is included,

state = F alse, LB = 10.

3. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 10) is included,

state = F alse, LB = 15.

4. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 15) is included,

state = F alse, LB = 20.

5. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 20) is included,
state = T rue. The SAT solver returns the assignment I = {x1 = F alse, x2 =
F alse, x3 = T rue, x4 = F alse, x5 = T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 =
F alse, b4 = T rue, b5 = F alse, b6 = T rue, b7 = F alse}, which leads to a WPMaxSAT
solution if we ignore the values of the bi, (1 ≤ i ≤ 7) variables with cost 20.

The next algorithm is describes the SAT-based technique. Algorithm 2 starts by ini-
tializing the upper bound to one plus the the sum of the weights of the soft clauses (line
1).

Algorithm 2: LinearSAT(φ) Linear search SAT-based algorithm for solving WP-
MaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

let bi be a new blocking variable φS ← φS \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

i=1 wibi ≤ U B − 1))

1 U B ← 1 +(cid:80)|φS|

2 foreach (Ci, wi) ∈ φS do

i=1 wi

4 while T rue do

3

5

6

7

8

9

if state = F alse then

(state, I) ← SAT ({C | (C, w) ∈ φ} ∪ CN F ((cid:80)|φS|
U B ←(cid:80)|φS|

i=1 wi(1 − I(Ci \ {bi}))

lastI ← I

return lastI

In each iteration of algorithm 2 except the last, the formula is satisﬁable. The cost of the
optimal solution is found immediately after the transition from satisﬁable to unsatisﬁable
instance. LinearSAT begins by initializing the upper bound to one plus the sum of the
weights of the soft clauses (line 1). The while loop (lines 4-8) continues until the formula
becomes unsatisﬁable (line 6), then the algorithm returns a WPMaxSAT solution and
terminates (line 7). As long as the formula is satisﬁable, the formula is sent to the SAT

6

Note that updating the upper bound to (cid:80)|φS|

solver along with the constraint assuring that the sum of the weights of the falsiﬁed soft
clauses is less than U B − 1 (line 5), and the upper bound is updated to the sum of the
weights of the soft clauses falsiﬁed by the assignment returned by the SAT solver (line 8).
i=1 wi(1 − I(Ci \ {bi})) is more eﬃcient
than simply decreasing the upper bound by one, because uses less iterations and thus the
problem is solved with less SAT calls.

Example 2.2. If we run LinearSAT on φ from the previous example, the soft clauses will
be be relaxed {(x1∨b1, 5), (x2∨b2, 5), (x3∨b3, 10), (x4∨b4, 5), (x5∨b5, 10), (x6∨b6, 5), (¬x6∨
b7, 10)} and U B is initialized to 1 + (5 + 5 + 5 + 5 + 10 + 10 + 10) = 51. The sequence of
iterations are

1. The constraint CN F (5b1+5b2+10b3+5b4+10b5+5b6+10b7 ≤ 50) is included, state =
T rue, I = {x1 = F alse, x2 = F alse, x3 = F alse, x4 = F alse, x5 = F alse, x6 =
F alse, b1 = T rue, b2 = T rue, b3 = T rue, b4 = T rue, b5 = T rue, b6 = T rue, b7 =
F alse}, U B = 5 + 5 + 10 + 5 + 10 + 5 = 40.

2. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 40 − 1) is in-
cluded, state = T rue, I = {x1 = F alse, x2 = F alse, x3 = F alse, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = T rue, b4 = T rue, b5 = F alse, b6 =
T rue, b7 = F alse}, U B = 5 + 5 + 10 + 5 + 5 = 30.

3. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 30 − 1) is in-
cluded, state = T rue, I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 =
T rue, b7 = F alse}, U B = 5 + 5 + 5 + 5 = 20.

4. The constraint CN F (5b1 + 5b2 + 10b3 + 5b4 + 10b5 + 5b6 + 10b7 ≤ 20− 1) is included,
state = F alse. The assignment from the previous step is indeed a solution to φ if
we ignore the values of the bi, (1 ≤ i ≤ 7) variables with cost 20.

3 Binary Search-based Algorithms

WPMaxSAT algorithm can take(cid:80)|φS|
for a value (the optimal cost) among a set of values (from 0 to (cid:80)|φS|

The number of iterations linear search algorithms for WPMaxSAT can take is linear in
the sum of the weights of the soft clauses. Thus, in the worst case the a linear search
i=1 wi calls to the SAT solver. Since we are searching
i=1 wi), then binary
search can be used, which uses less iterations than linear search. Algorithm 3 searches for
the cost of the optimal assignment by using binary search.

7

Algorithm 3: BinS-WPMaxSAT(φ) Binary search based algorithm for solving WP-
MaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

1 state ← SAT ({Ci | (Ci,∞) ∈ φH})
2 if state = F alse then
3

return ∅

4 LB ← −1

5 U B ← 1 +(cid:80)|φS|

6 foreach (Ci, wi) ∈ φS do

i=1 wi

7

8

let bi be a new blocking variable
φS ← φS \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

9 while LB + 1 < U B do

2

(cid:99)

mid ← (cid:98) LB+U B

(state, I) ← SAT ({C | (C, w) ∈ φ} ∪ CN F ((cid:80)|φS|
U B ←(cid:80)|φS|

i=1 wi(1 − I(Ci \ {bi}))

if state = T rue then

lastI ← I

i=1 wibi ≤ mid))

10

11

12

13

14

15

16

else

LB ← U pdateBound({wi | 1 ≤ i ≤ |φS|}, mid) − 1

17 return lastI

BinS-WPMaxSAT begins by checking the satisﬁability of the hard clauses (line 1)
before beginning the search for the solution.
If the SAT solver returns F alse (line 2),
BinS-WPMaxSAT returns the empty assignment and terminates (line 3). The algorithm
updates both a lower bound LB and an upper bound U B initialized respectively to -1
and one plus the sum of the weights of the soft clauses (lines 4-5). The soft clauses are
augmented with blocking variables (lines 6-8). At each iteration of the main loop (lines
9-16), the middle value (mid) is changed to the average of LB and U B and a constraint is
added requiring the sum of the weights of the relaxed soft clauses to be less than or equal
to the middle value. This clauses describing this constraint are sent to the SAT solver
along with the clauses of φ (line 11). If the SAT solver returns T rue (line 12), then the
cost of the optimal solution is less than mid, and U B is updated (line 14). Otherwise,
the algorithm looks for the optimal cost above mid, and so LB is updated (line 16). The
main loop continues until LB + 1 = U B, and the number of iterations BinS-WPMaxSAT
i=1 wi) which is a considerably lower complexity than

executes is proportional to log((cid:80)|φS|

that of linear search methods.

In the following example, U pdateBound assigns mid + 1 to LB.

Example 3.1. Consider φ in example 2.1 with all the weights of the soft clauses set to
1. At the beginning, LB = −1, U B = 8. The following are the sequence of iterations
algorithm 3 executes.
1. mid = (cid:98) 8+(−1)

(cid:99) = 3, the constraint CN F (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 3) is

2

included, state = F alse, LB = 3, U B = 8.

2. mid = (cid:98) 8+3

2 (cid:99) = 5, the constraint CN F (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 5) is

8

included, state = T rue, I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 =
T rue,
b7 = F alse}, U B = 4, LB = 3. The assignment I is indeed an optimal one,
falsifying four clauses.

It is often stated that a binary search algorithm performs better than linear search.
Although this is true most of the time, there are instances for which linear search is
faster than binary search. Let k be the sum of the soft clauses falsiﬁed by the assignment
returned by the SAT solver in the ﬁrst iteration. If k is indeed the optimal solution, linear
search methods would discover this fact in the next iteration, while binary search ones
would take log k iterations to declare k as the optimal cost. In order to beneﬁt from both
search methods, An et al.[3] developed a PMaxSAT algorithm called QMaxSAT (version
0.4) that alternates between linear search and binary search (see algorithm 4).

9

Algorithm 4: BinLin-WPMaxSAT(φ) Alternating binary and linear searches for
solving WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

1 state ← SAT ({Ci | (Ci,∞) ∈ φH})
2 if state = F alse then
3

return ∅

4 foreach (Ci, wi) ∈ φS do

5

let bi be a new blocking variable
φS ← φS \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

6

7 LB ← −1

8 U B ← 1 +(cid:80)|φS|

i=1 wi

9 mode ← binary
10 while LB + 1 < U B do
11
(cid:99)
mid ← (cid:98) LB+U B

if mode = binary then

12

2

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

else

mid ← U B − 1

(state, I) ← SAT ({C | (C, w) ∈ φ} ∪ CN F ((cid:80)|φS|
U B ←(cid:80)|φS|

i=1 wi(1 − I(Ci \ {bi}))

if state = T rue then

lastI ← I

i=1 wibi ≤ mid))

else

if mode = binary then

LB ← U pdateBound({wi | 1 ≤ i ≤ |φS|}, mid) − 1

else

LB ← mid

if mode = binary then

mode ← linear

else

mode ← binary

28 return lastI

on the clauses of φ with the constraint(cid:80)|φS|

Algorithm 4 begins by checking that the set of hard clauses is satisﬁable (line 1). If not,
then the algorithm returns the empty assignment and terminates (line 3). Next, the soft
clauses are relaxed (lines 4-6) and the lower and upper bounds are initialized respectively to
-1 and one plus the sum of the weights of the soft clauses (lines 7-8). BinLin-WPMaxSAT
has two execution modes, binary and linear. The mode of execution is initialized in line 9
to binary search. At each iteration of the main loop (lines 10-27), the SAT solver is called
i=1 wibi bounded by the mid point (line 12), if
the current mode is binary, or by the upper bound if the mode is linear (line 14). If the
formula is satisﬁable (line 16), the upper bound is updated. Otherwise, the lower bound
is updated to the mid point. At the end of each iteration, the mode of execution is ﬂipped
(lines 24-27).

Since the cost of the optimal solution is an integer, it can be represented as an array of

10

bits. Algorithm 5 uses this fact to determine the solution bit by bit. BitBased-WPMaxSAT
starts from the most signiﬁcant bit and at each iteration it moves one bit closer to the
least signiﬁcant bit, at which the optimal cost if found.

Algorithm 5: BitBased-WPMaxSAT(φ) A bit-based algorithm for solving WP-
MaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

1 state ← SAT ({Ci | (Ci,∞) ∈ φH})
2 if state = F alse then
3

return ∅

4 foreach (Ci, wi) ∈ φS do

let bi be a new blocking variable
φS ← φS \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

6

5

7 k ← (cid:98)lg((cid:80)|φS|

i=1 wi)(cid:99)

8 CurrBit ← k
9 cost ← 2k
10 while CurrBit ≥ 0 do

// s0, . . . , sk are the binary

i=1 wibi < cost))

if state = T rue then

lastI ← I
let s0, . . . , sk ∈ {0, 1} be constants such that

(state, I) ← SAT ({C | (C, w) ∈ φ} ∪ CN F ((cid:80)|φS|
i=1 wi(1 − I(Ci \ {bi})) =(cid:80)k
(cid:80)|φS|
cost ←(cid:80)k

j=0 2jsj
representation of the current cost
CurrBit ← max({j | j < CurrBit and sj = 1} ∪ {−1})
if CurrBit ≥ 0 then

j=CurrBit 2jsj

else

CurrBit ← CurrBit − 1
cost ← cost + 2CurrBit

11

12

13

14

15

16

17

18

19

20

21 return lastI

At the beginning of the algorithm as in the previous ones, the satisﬁability of the hard
clauses are checked and the soft clauses are relaxed. The sum of the weights of the soft
clauses k is an upper bound on the cost and thus it is computed to determine the number
of bits needed to represent the optimal solution (line 7). The index of the current bit
being considered is initialized to k (line 7), and the value of the solution being constructed
is initialized (line 8). The main loop (lines 10-20) terminates when it reached the least
signiﬁcant bit (when CurrBit = 0). At each iteration, the SAT solver is called on φ with
constraint saying that the sum of the weights of the falsiﬁed soft clauses must be less than
cost (line 11). If the SAT solver returns T rue (line 12), the sum of the weights of the
soft clauses falsiﬁed by the current assignment is computed and the set of bits needed to
represent that number are determined as well (line 14), the index of the current bit is
decreased to the next j < CurrBit such that sj = 1 (line 15). If such an index does not
exist, then CurrBit becomes -1 and in the following iteration the algorithm terminates.

11

On the other hand, if the SAT solver returns F alse, the search continues to the most
signiﬁcant bit by decrementing CurrBit (line 19) and since the optimal cost is greater
than the current value of cost, it is decreased by 2CurrBit (line 20).

Example 3.2. Consider φ from example 2.1 with all the weights of the soft clauses being
1. At the beginning of the algorithm, the soft clauses are relaxed and the formula becomes
{(x1 ∨ b1, 1), (x2 ∨ b2, 1), (x3 ∨ b3, 1), (x4 ∨ b4, 1), (x5 ∨ b5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)}∪ φH .
Also, the variables k, CurrBit and cost are initialized to 2, 2 and 22 respectively. The
following are the iterations BitBased-WPMaxSAT executes.

1. The constraint CN F (b1 + b2 + b3 + b4 + b5 + b6 + b7 < 22) is included, state = F alse,

CurrBit = 1, cost = 22 + 21 = 6.

2. The constraint CN F (b1 + b2 + b3 + b4 + b5 + b6 + b7 < 22 + 21), state = T rue,
I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 = T rue, x6 = F alse, b1 =
T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 = T rue, b7 = F alse},
CurrBit = −1.

4 Core-guided Algorithms

As in the previous method, UNSAT methods use SAT solvers iteratively to solve MaxSAT.
Here, the purpose of iterative SAT calls is to identify and relax unsatisﬁable formulas
(unsatisﬁable cores) in a MaxSAT instance. This method was ﬁrst proposed in 2006 by
Fu and Malik in[18] (see algorithm 6). The algorithms described in this section are

1. Fu and Malik’s algorithm[18]

2. WPM1[4]

3. Improved WPM1[5]

4. WPM2[7]

5. WMSU1-ROR[21]

6. WMSU3[37]

7. WMSU4[38]

Deﬁnition 4.1 (Unsatisﬁable core). An unsatisﬁable core of a CNF formula φ is a subset
of φ that is unsatisﬁable by itself.

Deﬁnition 4.2 (Minimum unsatisﬁable core). A minimum unsatisﬁable core contains the
smallest number of the original clauses required to still be unsatisﬁable.

Deﬁnition 4.3 (Minimal unsatisﬁable core). A minimal unsatisﬁable core is an unsatis-
ﬁable core such that any proper subset of it is not a core[15].

Modern SAT solvers provide the unsatisﬁable core as a by-product of the proof of
unsatisﬁability. The idea in this paradigm is as follows: Given a WPMaxSAT instance
φ = {(C1, w1), . . . , (Cs, ws)} ∪ {(Cs+1,∞), . . . , (Cs+h,∞)}, let φk be a SAT instance that
is satisﬁable iﬀ φ has an assignment with cost less than or equal to k. To encode φk,

12

(cid:32) s(cid:88)

(cid:33)

conversion of the constraint(cid:80)s

i=1 wibi ≤ k. So, we have

we can extend every soft clause Ci with a new (auxiliary) variable bi and add the CNF

φk = {(Ci ∨ bi), . . . , (Cs ∨ bs), Cs+1, . . . , Cs+h} ∪ CN F

wibi ≤ k

k ≥ kopt, and unsatisﬁable for all k < kopt, where k may range from 0 to(cid:80)s

Let kopt be the cost of the optimal assignment of φ. Thus, φk is satisﬁable for all
i=1 wi. Hence,
the search for the optimal assignment corresponds to the location of the transition between
satisﬁable and unsatisﬁable φk. This encoding guarantees that the all the satisfying as-
signments (if any) to φkopt are the set of optimal assignments to the WPMaxSAT instance
φ.

i=1

4.1 Fu and Malik’s algorithm

Fu and Malik implemented two PMaxSAT solvers, ChaﬀBS (uses binary search to ﬁnd
the optimal cost) and ChaﬀLS (uses linear search to ﬁnd the optimal cost) on top of a
SAT solver called zChaﬀ[44]. Their PMaxSAT solvers participated in the ﬁrst and second
MaxSAT Evaluations[10]. Their method (algorithm 6 basis for many WPMaxSAT solvers
that came later. Notice the input to algorithm 6 is a PMaxSAT instance since all the
weights of the soft clauses are the same.

Algorithm 6: Fu&Malik(φ) Fu and Malik’s algorithm for solving PMaxSAT.
Input: φ = {(C1, 1), . . . , (Cs, 1), (Cs+1,∞), . . . , (Cs+h,∞)}
Output: The cost of the optimal assignment to φ

1 if SAT ({Cs+1, . . . , Cs+h}) = (F alse, ) then

2

return ∞

3 opt ← 0
4 f ← 0
5 while T rue do
6

(state, φC ) ← SAT ({Ci | (Ci, wi) ∈ φ})
if state = T rue then

// The cost of the optimal solution
// The number of clauses falsified

7

8

9

10

11

12

13

14

15

16

return opt

f ← f + 1
B ← ∅
foreach Ci ∈ φC such that wi (cid:54)= ∞ do

let bi be a new blocking variable
φ ← φ \ {(Ci, 1)} ∪ {(Ci ∨ bi, 1)}
B ← B ∪ {i}

φ ← φ ∪ {(C,∞) | C ∈(cid:80)

i∈B bi = 1} // Add the cardinality constraint as hard

clauses
opt ← opt + 1

Fu&Malik (algorithm 6) (also referred to as MSU1) begins by checking if a hard clause
is falsiﬁed (line 1), and if so it terminates returning the cost ∞ (line 2). Next, unsatisﬁable
cores (φC) are identiﬁed by iteratively calling a SAT solver on the soft clauses (line 6).

13

If the working formula is satisﬁable (line 7), the algorithm halts returning the cost of the
optimal assignment (line 8). If not, then the algorithm starts its second phase by relaxing
each soft clause in the unsatisﬁable core obtained earlier by adding to it a fresh variable,
in addition to saving the index of the relaxed clause in B (lines 11-14). Next, the new
working formula constraints are added indicating that exactly one of bi variables should
be T rue (line 15). Finally, the cost is increased by one (line 16) a clause is falsiﬁed. This
procedure continues until the SAT solver declares the formula satisﬁable.

4.2 WPM1

Ans´otegui, Bonet and Levy[4] extended Fu& Malik to WPMaxSAT. The resulting algo-
rithm is called WPM1 and is described in algorithm 7.

Algorithm 7: WPM1(φ) The WPM1 algorithm for WPMaxSAT.
Input: A WPMaxSAT instance φ = {(H1,∞), . . . , (Hh,∞)} ∪ {(S1, w1), . . . , (Ss, ws)}
Output: The optimal cost of the WPMaxSAT solution

1 if SAT ({Hi | 1 ≤ i ≤ h}) = F alse then

2

return ∞

3 cost ← 0
4 while T rue do
5

(state, φC ) ← SAT ({Ci | (Ci, wi) ∈ φ})
if state = T rue then

6

7

8

9

10

11

12

13

14

15

16

17

18

19

return cost

BV ← ∅
wmin ← min{wi | Ci ∈ φC and wi (cid:54)= ∞}
// Compute the minimum weight of all the soft clauses in φC
foreach Ci ∈ φC do
if wi (cid:54)= ∞ then

Let bi be a new blocking variable
φ ← φ \ {(Ci, wi)} ∪ {(Ci, wi − wmin)} ∪ {(Ci ∨ bi, wmin)}
BV ← BV ∪ {bi}

if BV = ∅ then

else

return F alse // φ is unsatisfiable

φ ← φ ∪ CN F(cid:0)(cid:80)

b∈BV b = 1(cid:1) // Add the cardinality constraint as hard

clauses

cost ← cost + wmin

Just as in Fu&Malik, algorithm 7 calls a SAT solver iteratively with the working
formula, but without the weights (line 5). After the SAT solver returns an unsatisﬁable
core, the algorithm terminates if the core contains hard clauses and if it does not, then the
algorithm computes the minimum weight of the clauses in the core, wmin (line 9). Next,
the working formula is transformed by duplicating the core (line 13) with one copy having
the clauses associated with the original weight minus the minimum weight and a second
copy having having the clauses augmented with blocking variables with the original weight.

14

i=1 bi = 1

(cid:16)(cid:80)k

(cid:16)(cid:80)k
(cid:17)
(cid:17) ∪ ··· ∪ CN F

Finally, the cardinality constraint on the blocking variable is added as hard clauses (line
18) and the cost is increased by the minimum weight (line 19).
WPM1 uses blocking variables in an eﬃcient way. That is, if an unsatisﬁable core,
φC = {C1, . . . , Ck}, appears l times, all the copies get the same set of blocking vari-
ables. This is possible because the two formulae φ1 = φ \ φC ∪ {C1 ∨ bi, . . . , Ci ∨ bi |
Ci ∈ φC} ∪ CN F
i | Ci ∈ φC} ∪
CN F
are MaxSAT equivalent, meaning that
i = 1
the minimum number of unsatisﬁable clause of φ1 and φ2 is the same. However, the algo-
rithm does not avoid using more than one blocking variable per clause. This disadvantage
is eliminated by WMSU3 (described later).
Example 4.1. Consider φ = {(x1, 1), (x2, 2), (x3, 3), (¬x1 ∨ ¬x2,∞),
(x1∨¬x3,∞), (x2∨¬x3,∞)}. In the following, bj
Ci at the jth iteration. A possible execution sequence of the algorithm is:

and φ2 = φ \ φC ∪ {Ci ∨ b1

i is the relaxation variable added to clause

i , . . . , Ci ∨ bl

(cid:16)(cid:80)k

i=1 bl

i = 1

i=1 b1

(cid:17)

1. state = F alse, φC = {(¬x3), (¬x1 ∨ ¬x2), (x1 ∨ ¬x3), (x2 ∨ ¬x3)}, wmin = 3,
3 =

3, 3),, (¬x1 ∨ ¬x2,∞), (x1 ∨ ¬x3,∞), (x2 ∨ ¬x3,∞), (b1

φ = {(x1, 1), (x2, 2), (x3 ∨ b1
1,∞)}.

2. state = F alse, φC = {(x1), (x2), (¬x1∨¬x2)}, wmin = 1, φ = {(x1∨b2

1), (x2, 1), (x2∨

2), (x3 ∨ b1
b2
(x2 ∨ ¬x3,∞), (b1

3 = 1,∞), (b2

3), (¬x1 ∨ ¬x2,∞),(x1 ∨ ¬x3,∞),
2 = 1,∞).
(cid:88)

1 + b2

wi = 2

3. state = T rue, A = {x1 = 0, x2 = 1, x3 = 0} is an optimal assignment with

Ci is soft

A satisﬁes Ci

If the SAT solver returns a diﬀerent unsatisﬁable core in the ﬁrst iteration, a diﬀerent
execution sequence is going to take place.

4.3 Improved WPM1

In 2012, Ans´otegui, Bonet and Levy presented a modiﬁcation to WPM1 (algorithm 7)[5].
In WPM1, the clauses of the core are duplicated after computing their minimum weight
wmin. Each clause Ci in the core, the (Ci, wi − wmin) and (Ci ∨ bi, wmin) are added to
the working formula and (Ci, wi) is removed. This process of duplication can be ineﬃcient
because a clause with weight w can be converted into w copies with weight 1. The authors
provided the following example to illustrate this issue: consider φ = {(x1, 1), (x2, w), (¬x2,
∞)}. If the SAT solver always includes the ﬁrst clause in the identiﬁed core, the working
2, 1), (x2, w − 1), (¬x2,∞), (b1
formula after the ﬁrst iteration will be {(x1 ∨ b1
1 +
2 = 1,∞)}.
b1
If at each iteration i, the SAT solver includes the ﬁrst clause and with
{(x2, w − i + 1), (¬x2,∞)} in the unsatisﬁable core, then after i iterations the formula
1∨···∨bi
would be {(x1∨b1
2 =
2 = 1,∞)}. In this case, WPM1 would need w iterations to solve the
1,∞), . . . , (bi
1 + bi
problem.

1, 1), (x2∨b2∗1, 1), . . . , (x2∨bi

2, 1), (x2, w−i), (¬x2,∞), (b1

1, 1), (x2 ∨ b1

1 +b1

15

Algorithm 8: ImprovedWPM1(φ) The stratiﬁed approach for WPM1 algorithm.

Input: A WPMaxSAT instance

φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m(cid:48) , wm+m(cid:48) )}

Output: The cost of the optimal WPMaxSAT solution to φ

1 if SAT ({Ci | wi = ∞}) = (F alse, ) then

return ∞ // cost = ∞ if the hard clauses can not be satisfied

3 cost ← 0
4 wmax ← max{wi | (Ci, wi) ∈ φ and wi < wmax} // Initialize wmax to the largest

2

7

8

9

10

11

12

13

14

15

16

17

18

19

20

weight smaller than ∞

5 while T rue do
6

(state, φC ) ← SAT ({Ci | (Ci, wi) ∈ φ and wi ≥ wmax})
if state = T rue and wmax = 0 then

return cost

else

if state = T rue then

wnax = max{wi | (Ci, wi) ∈ φ and wi < wmax}

else

BV ← ∅ // Set of blocking variables of the unsatisfiable core
wmin ← min{wi | Ci ∈ φC and wi (cid:54)= ∞} // Minimum weight of soft
clauses in the unsatisfiable core
foreach Ci ∈ φC do
if wi (cid:54)= ∞ then

Let b be a new variable
φ ← φ \ {(Ci, wi)} ∪ {(Ci, wi − wmin), (Ci ∨ b, wmin)}
BV ← BV ∪ {b}

φ ← φ ∪ {(C,∞) | C ∈ CN F ((cid:80)

b∈BV b = 1)} // The cardinality

constraint is added as hard clauses
cost ← cost + wmin

Algorithm 8 overcomes this problem by utilizing a stratiﬁed approach. The aim is to
restrict the clauses sent to the SAT solver to force it to concentrate on those with higher
weights, which leads the SAT solver to return unsatisﬁable cores with clauses having larger
weights. Cores with clauses having larger weight are better because they contribute to
increasing the cost faster. Clauses with lower weights are used after the SAT solver returns
T rue. The algorithm starts by initializing wmax to the largest weight smaller than ∞,
then in line 6 only the clauses having weight greater than or equal to wmax are sent to the
SAT solver. The algorithm terminates if the SAT solver returns T rue and wmax is zero
(lines 7-8), but if wmax is not zero and the formula is satisﬁable then wmax is decreased to
the largest weight smaller than wmax (lines 10-11). When the SAT solver returns F alse,
the algorithm proceeds as the regular WPM1.

A potential problem with the stratiﬁed approach is that in the worst case the algorithm
could use more calls to the SAT solver than the regular WPM1. This is because there is
no contribution made to the cost when the SAT solver returns T rue and at the same time
wmax > 0. The authors apply the diversity heuristic which decreases wmax faster when
there is a big variety of distinct weights and assigns wmax to the next value of wi when
there is a low diversity among the weights.

16

4.4 WPM2

In 2007, Marques-Silva and Planes[37] discussed important properties of Fu&Malik that
were not mentioned in[18]. If m is the number of clauses in the input formula, they proved
that the algorithm performs O(m) iterations and the number of relaxation variables used
in the worst case is O(m2). Marques-Silva and Planes also tried to improve the work of Fu
and Malik. Fu&Malik use the pairwise encoding[19] for the constraints on the relaxation
variables, which use a quadratic number of clauses. This becomes impractical when solving
real-world instances. Instead, Marques-Silva and Planes suggested several other encodings
all of which are linear in the number of variables in the constraint[57, 53, 17, 19].

Another drawback of Fu&Malik is that there can be several blocking variables asso-
ciated with a given clause. This is due to the fact that a clause C can participate in
more than one unsatisﬁable core. Each time C is a part of a computed unsatisﬁable core,
a new blocking variable is added to C. Although the number of blocking variables per
clause is possibly large (but still linear), at most one of these variables can be used to
prevent the clause from participating in an unsatisﬁable core. A simple solution to re-
duce the search space associated with blocking variables is to require that at most one
(cid:80)ti
of the blocking variables belonging to a given clause can be assigned T rue. For a clause
Ci, let bi,j, (1 ≤ j ≤ ti) be the blocking variables associated with Ci. The condition
j=1 bi,j ≤ 1 assures that at most one of the blocking variables of Ci is assigned T rue.
This is useful when executing a large number of iterations, and many clauses are involved
in a signiﬁcant number of unsatisﬁable cores. The resulting algorithm that incorporated
these improvements is called MSU2.

Ans´otegui, Bonet and Levy also developed an algorithm for WPMaxSAT in 2010, called
WPM2[7], where every soft clause Ci is extended with a unique fresh blocking variable bi.
Note that a SAT solver will assign bi T rue if Ci is F alse. At every iteration, the algorithm
modiﬁes two sets of at-most and at-least constraints on the blocking variables, called AL
and AM respectively. The algorithm relies of the notion of covers.

Deﬁnition 4.4 (Cover). Given a set of cores L, its set of covers Covers(L) is deﬁned
as the minimal partition of {1, . . . , m} such that for every A ∈ L and B ∈ Covers(L), if
A ∩ B (cid:54)= ∅, then A ⊆ B.

17

Algorithm 9: WPM2(φ) The WPM2 algorithm for WPMaxSAT

Input: A WPMaxSAT instance

φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m(cid:48) ,∞)}

Output: The optimal WPMaxSAT solution to φ

1 if SAT ({Ci ∈ φ | wi = ∞}) = (F alse, ) then

2

return ∞

3 φe ← {C1 ∨ b1, . . . , Cm ∨ bm, Cm+1, . . . , Cm+m(cid:48)}
4 Covers ← {{1}, . . . ,{m}}
5 AL ← ∅
6 AM ← {w1b1 ≤ 0, . . . , wmbm ≤ 0}
7 while T rue do
8

(state, φC , I) ← SAT (φe ∪ CN F (AL ∪ AM ))
if state = T rue then

9

10

11

12

13

14

15

16

17

18

19

20

21

22

return I

return ∅

Remove the hard clauses from φC
if φC = ∅ then

A ← ∅
foreach Ci ∨ bi ∈ φC do

A ← A ∪ {i}

B(cid:48)∈RC B(cid:48)

B ←(cid:83)
AL ← AL ∪ {(cid:80)
AM ← AM \ {(cid:80)

RC ← {B ∈ Covers | B ∩ A (cid:54)= ∅}
k ← N ewBound(AL, B)
Covers ← Covers \ RC ∪ B
i∈B wibi ≥ k}

i∈B(cid:48) wibi ≤ k(cid:48) | B(cid:48) ∈ RC} ∪ {(cid:80)

i∈B wibi ≤ k}

// φ has no solution

The constraints in AL give lower bounds on the optimal cost of φ, while the ones in
AM ensure that all solutions of the set AM ∪ AL are the solutions of AL of minimal cost.
This in turn ensures that any solution of φe ∪ CN F (AL ∪ AM ) (if there is any) is an
optimal assignment of φ.

The authors use the following deﬁnition of cores and introduced a new notion called

covers to show how AM is computed given AL.

Deﬁnition 4.5 (Core). A core is a set of indices A such that

(cid:32)(cid:88)

(cid:33)

wibi ≥ k

∈ AL

. The function Core(cid:0)(cid:80)

i∈A wibi ≥ k(cid:1) returns the core A, and Cores(AL) returns {Core(al) |

i∈A

al ∈ AL}.
Deﬁnition 4.6 (Disjoint cores). Let U = {U1, . . . , Uk} be a set of unsatisﬁable cores,
each with a set of blocking variables Bi, (1 ≤ i ≤ k). A core Ui ∈ U is disjoint if for all
Uj ∈ U we have (Ri ∩ Rj = ∅ and i (cid:54)= j)

Given a set of AL constraints, AM is the set of at-most constraints (cid:80)
such that A ∈ Cover(Cores(AL)) and k is the solution minimizing(cid:80)

i∈A wibi ≤ k
i∈A wibi subject to

18

AL and bi ∈ {T rue, F alse}. At the beginning, AL = {w1b1 ≥ 0, . . . , wmbm ≥ 0} and
the corresponding AM = {w1b1 ≤ 0, . . . , wmbm ≤ 0} which ensures that the solution to
AL ∪ AM is b1 = F alse, . . . , bm = F alse. At every iteration, when an unsatisﬁable core
φC is identiﬁed by the SAT solver, the set of indices of soft clauses in φC A ⊆ {1, . . . , m}
is computed, which is also called a core. Next, the set of covers RC = {B(cid:48) ∈ Covers | B(cid:48)∩
B(cid:48)∈RC B(cid:48). The new
set of covers is Covers = Covers \ RC ∪ B. The set of at-least constraints AL is enlarged
i∈B wibi ≥ N ewBound(AL, B), where N ewBound(AL, B)
wibi≥k}∪ AL where
i∈A(cid:48) wibi ≤ k(cid:48) ∈ AM and A(cid:48) ⊆ A}. Given AL and B, the computation
of N ewBound can be diﬃcult since it can be reduced to the subset sum problem in the
j=1 wjxj > k
and xj ∈ {0, 1}. This is equivalent to N ewBound(AL, B), where the weights are wj,
j=1 wjxj ≥ k}. In the authors’ implementation, N ewBound

A (cid:54)= ∅} that intersect with A is computed, as well as their union B =(cid:83)
by adding a new constraint(cid:80)
i∈A wibi subject to the set of constraints {(cid:80)
correspond to minimize(cid:80)
k = 1 +(cid:80){k(cid:48) |(cid:80)
following way: given {w1, . . . , wn} and k, minimize(cid:80)n
B = {1, . . . , n} and AL = {(cid:80)n

j=1 wjxj subject to(cid:80)n

is computed by algorithm 10.

1 k ←(cid:80)(cid:8)k(cid:48) |(cid:80)
4 until SAT(cid:0)CN F(cid:0)AL ∪ {(cid:80)

2 repeat
3

k ← SubsetSum({wi | i ∈ B}, k)

i∈B wibi = k}(cid:1)(cid:1)

Algorithm 10: NewBound(AL, B)

i∈B(cid:48) wibi ≤ k(cid:48) ∈ AM and B(cid:48) ⊆ B(cid:9)

5 return k

The SubsetSum function (called in line 3) is an optimization version of the decision
subset sum problem. It returns the largest integer d ≤ k such that there is a subset of
{wi | i ∈ B} that sums to d.
Example 4.2. Consider φ in example 2.1 with all the weights of the soft clauses set to
1. Before the main loop of algorithm 9, we have φe = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨
b4), (x5∨b5), (x6∨b6), (¬x6∨b7)}∪φH , Covers = {{1},{2},{3},{4},{5},{6},{7}}, AL =
∅, AM = {b1 ≤ 0, b2 ≤ 0, b3 ≤ 0, b4 ≤ 0, b5 ≤ 0, b6 ≤ 0, b7 ≤ 0}. The following are the
iterations the algorithm executes. The soft clauses in the core φC are denoted by Sof t(φC).
1. state = F alse, Sof t(φC) = {(x6 ∨ b6), (¬x6 ∨ b7)}, A = {6, 7}, RC = {{6},{7}},
B = {6, 7}, k = 1, Covers = {{1},{2},{3},
{4},{5},{6, 7}}, AL = {b6 + b7 ≥ 1}, AM = {b1 ≤ 0, b2 ≤ 0, b3 ≤ 0, b4 ≤ 0, b5 ≤
0, b6 + b7 ≤ 1}.

2. state = F alse, Sof t(φC) = {(x1), (x2)}, A = {1, 2}, RC = {{1},{2}}, B = {1, 2},
k = 1, Covers = {{1, 2},{3},{4},{5},
{6, 7}}, AL = {b6 + b7 ≥ 1, b1 + b2 ≥ 1}, AM = {b3 ≤ 0, b4 ≤ 0, b5 ≤ 0, b6 + b7 ≤
1, b1 + b2 ≤ 1}.

3. state = F alse, Sof t(φC) = {(x3), (x4)}, A = {3, 4}, RC = {{3},{4}}, B = {3, 4},
k = 1, Covers = {{1, 2},{3, 4},{5},{6, 7}}, AL = {b6 + b7 ≥ 1, b1 + b2 ≥ 1, b3 + b4 ≥
1}, AM = {b1 + b2 ≤ 1, b5 ≤ 0, b6 + b7 ≤ 1, b3 + b4 ≤ 1}.

19

4. state = F alse, Sof t(φC) = {(x1), (x2), (x3), (x4), (x5)}, A = {1, 2, 3, 4, 5}, RC =
{{1, 2},{3, 4},{5}}, B = {1, 2, 3, 4, 5}, k = 3, Covers = {{6, 7},{1,
2, 3, 4, 5}}, AL = {b6 + b7 ≥ 1, b1 + b2 ≥ 1, b3 + b4 ≥ 1, b1 + b2 + b3 + b4 + b5 ≥ 3},
AM = {b1 + b2 ≤ 1, b1 + b2 + b3 + b4 + b5 ≤ 3}.

5. state = T rue, I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 =
T rue, b7 = F alse}.

To sum up, the WPM2 algorithm groups the identiﬁed cores in covers, which are a
decomposition of the cores into disjoint sets. Constraints are added so that the relaxation
variables in each cover relax a particular weight of clauses k, which is changed to the next
largest value the weights of the clauses can sum up to. Computing the next k can be
expensive since it relies on the subset sum problem, which is NP-hard.

In[6], Ans´otegui et at.

invented three improvements to WPM2. First, they applied
the stratiﬁcation technique[5]. Second, they introduced a new criteria to decide when
soft clauses can be hardened. Finally, they showed that by focusing search on solving to
optimality subformulae of the original WPMaxSAT instance, they eﬃciency of WPM2 is
increased. This allows to combine the strength of exploiting the information extracted
from unsatisﬁable cores and other optimization approaches. By solving these smaller
optimization problems the authors obtained the most signiﬁcant boost in their new WPM2
version.

4.5 WMSU1-ROR

WMSU1-ROR[21] is a modiﬁcation of WPM1.
It attempts to avoid adding blocking
variables by applying MaxSAT resolution to the clauses of the unsatisﬁable core. Given
an unsatisﬁable core φC, a resolution refutation (a contradiction obtained by performing
resolution) is calculated by a specialized tool. As much of this refutation as possible is
copied by applying MaxSAT resolution steps to the working formula. If the transformation
derived the empty clause, it means that the core is trivial and the sequence of calls to the
SAT solver can continue without adding any relaxation variables for this step. Otherwise,
the transformed core is relaxed as in WPM1. The classical resolution rule can not be
applied in MaxSAT because it does not preserve the equivalence among weighted formulae.
The MaxSAT resolution rule used in WMSU1-ROR is called Max-RES and is described
in[26]. The following deﬁnition extends the resolution rule from SAT to WMaxSAT.
Deﬁnition 4.7 (WPMaxSAT resolution). {(x ∨ A, u), (¬x ∨ B, w)} ≡ {(A ∨ B, m), (x ∨
A, u (cid:127) m), (¬x ∨ B, w (cid:127) m), (x ∨ A ∨ ¬B, m), (¬x ∨ ¬A ∨ B, m)}, where A and B are
disjunctions and (cid:127) is deﬁned on weights u, w ∈ {0, . . . ,(cid:62)}, such that u ≥ w, as

(cid:26) u − w u (cid:54)= (cid:62)

u = (cid:62)

u (cid:127) w =

(cid:62)

and m = min(u, w). The clauses (x∨ A, u) and (¬x∨ B, w) are called the clashing clauses,
(A ∨ B, m) is called the resolvent, (x ∨ A, u (cid:127) m) and (¬x ∨ B, w (cid:127) m) are called posterior
clashing clauses, (x ∨ A ∨ ¬B, m) and (¬x ∨ ¬A ∨ B, m) are the compensation clauses
(which are added to recover an equivalent MaxSAT formula).

For example, if Max-RES is applied on {(x∨y, 3), (¬x∨y∨z, 4)} with (cid:62) > 4, we obtain
{(y ∨ y ∨ z, 3), (x ∨ y, 3 (cid:127) 3), (¬x ∨ y ∨ z, 4 (cid:127) 3), (x ∨ y ∨ ¬(y ∨ z), 3), (¬x ∨ ¬y ∨ y ∨ z, 3)}.

20

The ﬁrst and fourth clauses can be simpliﬁed by observing that (A ∨ C ∨ ¬(C ∨ B), u) ≡
(A∨C∨¬B, u). The second and ﬁfth clauses can be deleted since the former has weight zero
and the latter is a tautology. De Morgan’s laws can not be applied on MaxSAT instance
for not preserving the equivalence among instances[26]. The following rule can be applied
instead (A ∨ ¬(l ∨ C), w) ≡ {(A ∨ ¬C), (A ∨ ¬l ∨ C, w)}. A resolution proof is an ordered
set R = {Ci = (Ci(cid:48) (cid:46)(cid:47) Ci(cid:48)(cid:48) ), Ci+1 = (Ci(cid:48)+1 (cid:46)(cid:47) Ci(cid:48)(cid:48)+1), . . . , Ci+k = (Ci(cid:48)+k (cid:46)(cid:47) Ci(cid:48)(cid:48)+k)},
where (Ci, wi) = (Ci(cid:48), wi(cid:48)) (cid:46)(cid:47) (Ci(cid:48)(cid:48), wi(cid:48)(cid:48) ) is the the resolution step i of a resolution proof,
(Ci, wi) is the resolvent and (Ci(cid:48), wi(cid:48)) and (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48)) are the clashing clauses. The set of
compensation clauses will be denoted [(Ci(cid:48), wi(cid:48)) (cid:46)(cid:47) (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48))].

The ROR approach is captured in lines 12-22 in algorithm 11. WMSU1-ROR handles
WPMaxSAT formulae the same way as[4].
It maintains a working formula φW and a
lower bound LB. The resolution proof RC is obtained in line 12 and MaxSAT resolution
is applied (lines 14-21) for each read-once step.
In detail, the weights of the clashing
clauses (Ci(cid:48), wi(cid:48)) and (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) ) are decreased by the minimum weight of the clauses in the
unsatisﬁable core φC (lines 15-16). If the clashing clauses are soft, they are deleted from
φC (lines 17-18) and if their resolvent is not (cid:3), it is added to φC (lines 21-22). On the
other hand, if the clashing clauses are hard, they are kept in the core because they could
be used in a diﬀerent resolution step. Lastly, the compensation and clashing clauses are
added to φW (lines 19-20).

21

Algorithm 11: WMSU1-ROR(φ)

Input: A WPMaxSAT instance

φ = {(C1, w1), . . . , (Cm, wm), (Cm+1,∞), . . . , (Cm+m(cid:48) , wm+m(cid:48) )}

Output: The cost of the optimal solution to φ

1 if SAT ({Ci | wi = ∞}) = F alse then

2

return ∞

3 φW ← φ
4 LB ← 0
5 while T rue do
6

(state, φC ) ← SAT (φW )
if state = T rue then

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

return LB
φW ← φW \ φC
m ← min ({w | (C, w) ∈ φC and w < (cid:62)})
LB ← LB + m
// Beginning of read-once resolution
RC ← GetP roof (φC )
foreach (Ci, wi) = (Ci(cid:48) , wi(cid:48) ) (cid:46)(cid:47) (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) ) ∈ RC do

if ROR((Ci, wi), RC ) then

(Ci(cid:48) , wi(cid:48) ) ← (Ci(cid:48) , wi(cid:48) (cid:127) m)
(Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) ) ← (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) (cid:127) m)
if wi(cid:48) < (cid:62) and wi(cid:48)(cid:48) < (cid:62) then

φC ← φC \ {(Ci(cid:48) , wi(cid:48) ), (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) )}

φW ← φW ∪ {(Ci(cid:48) , wi(cid:48) ), (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) )}
φW ← φW ∪ {[(Ci(cid:48) , wi(cid:48) ) (cid:46)(cid:47) (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) )]}
if Ci (cid:54)= (cid:3) then

φC ← φC ∪ {(Ci, m)}

// End of read-once resolution
B ← ∅
foreach (Ci, wi) ∈ {(C, w) | (C, w) ∈ φC and w < (cid:62)} do

Let b be a new relaxation variable B ← B ∪ {b} φC ← φC ∪ {(C ∨ b, m)} if w > m
then

(C, w) ← (C, w (cid:127) m)

else

φC ← φC \ {(C, w)}

φc ← φC ∪ CN F(cid:0)(cid:80)

b∈B b = 1(cid:1)

φW ← φW ∪ φC

Hard((Ci, wi), R) (algorithm 12) returns T rue if (Ci, wi) is a hard clause and all its
ancestors are hard, otherwise it returns F alse. Input((Ci, wi), R) (called in line 1) returns
T rue if (Ci, wi) is not a resolvent of any step in R (i.e., an original clause), otherwise it
returns F alse. ancestors((Ci, wi), R) (called in line 5) returns the pair of clauses (Ci(cid:48), wi(cid:48))
and (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48)) from which (Ci, wi) was derived as dictated by R.

22

Algorithm 12: Hard((Ci, wi), R) Determines if a clause is hard or not

Input: A proof R
Output: T rue if (Ci, wi) is hard, or F alse otherwise

1 if Input((Ci, wi), R) and wi = (cid:62) then

return T rue

3 if Input((Ci, wi), R) and wi (cid:54)= (cid:62) then

2

4

return F alse

5 {(Ci(cid:48) , wi(cid:48) ), (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) )} ← ancestors((Ci, wi), R)
6 return Hard((Ci(cid:48) , wi(cid:48) ), R) and Hard((Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) ), R)

The function ROR (algorithm 13) returns T rue if (Ci, wi) is hard or if it and all of
its soft ancestors have been used at most once in the resolution proof R. If (Ck, wk) =
(Ck(cid:48), wk(cid:48)) (cid:46)(cid:47) (Ck(cid:48)(cid:48), wk(cid:48)(cid:48) ), where (Ck, wk) is the last resolvent in a resolution proof R. The
entire proof is read-once if ROR((Ck, wk), R) returns T rue. In this case (when the last step
is ROR), the resolvent of that step is ((cid:3), m). If this situation occurs, the algorithm does
not need to augment clauses with relaxation variables or cardinality constraints, which
improves upon the original algorithm.

Algorithm 13: ROR((Ci, wi), R) Determines if a clause is hard or not or if its
ancestors are used at most once

Input: A proof R
Output: T rue if (Ci, wi) is hard or if its ancestors are used exactly once, F alse otherwise

1 if Hard((Ci, wi), R) then
2

return T rue

3 if Input((Ci, wi), R) and U sed((Ci, wi), R) = 1 then
4

return T rue

5 if U sed((Ci, wi), R) > 1 then
6

return F alse

7 {(Ci(cid:48) , wi(cid:48) ), (Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) )} ← ancestors((Ci, wi), R)
8 return ROR((Ci(cid:48) , wi(cid:48) ), R) and ROR((Ci(cid:48)(cid:48) , wi(cid:48)(cid:48) ), R)

The problem with this approach (applying Max-RES instead of adding blocking vari-
ables and cardinality constraints) is that when soft clauses with weights greater than zero
are resolved more than once, MaxSAT resolution does not ensure to produce resolvents
with weights greater than zero. For this technique to work, the authors restrict the appli-
cation of resolution to the case where each clause is used at most once, which is referred
to as read-once resolution (ROR). Unfortunately, ROR can not generate resolution proofs
for some unsatisﬁable clauses[23].

4.6 WMSU3

WMSU3 is a WPMaxSAT algorithm that adds a single blocking variable per soft clause,
thus limiting the number of variables in the formula sent to the SAT solver in each iteration.

23

Algorithm 14: WMSU3(φ) The WMSU3 algorithm for WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: The cost of the optimal WPMaxSAT solution to φ

1 if SAT ({C | (C,∞) ∈ φH}) = F alse then

// Set of blocking variables
// Working formula initialized to φ
// Lower bound initialized to 0

2

return ∞

3 B ← ∅
4 φW ← φ
5 LB ← 0
6 while T rue do
7

(state, φC ) ← SAT ({C | (C, w) ∈ φW} ∪ CN F ((cid:80)

bi∈B wibi ≤ LB))

8

9

10

11

12

13

14

if state = T rue then

return LB

foreach (Ci, wi) ∈ φC ∩ φS do

if w (cid:54)= ∞ then

B ← B ∪ {bi}
φW ← φW \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

LB ← U pdateBound({wi | bi ∈ B}, LB)

Algorithm 14 begins by initializing the set of blocking variables that will be augmented
later to ∅ (line 3), the working formula to φ (line 4) and the lower bound to zero (line 5).
MSU3 then loops over unsatisﬁable working formulae φW (while loop in lines 6-13) until
it ﬁnds a satisﬁable one in line 8. At each iteration, when an unsatisﬁable core is returned
by the SAT solver, the algorithm adds one blocking variable to each soft clause that has
not been augmented with a blocking variable yet (line 13), unlike WPMaxSAT algorithms
discussed previously such as WPM1 (algorithm 7). Indeed, at most one blocking variable
is added to each clause because if at iteration i Ci was blocked by bi, then at iteration i + 1
the clause Ci ∨ bi will not be in φC ∩ φS. The function U pdateBound in line 14 updates
the lower bound LB, either by simply incrementing it or by the subset sum problem as
in[7]. The following example illustrates how the algorithm works.
Example 4.3. Let φ = {(x1, 1), (x2, 3), (x3, 1)} ∪ {(¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}.

1. state = F alse, φC = {(x1), (x2), (¬x1 ∨ ¬x2)}, φC ∩ φS = {(x1), (x2)}, φW =

{(x1 ∨ b1, 1), (x2 ∨ b2, 2), (x3, 1), (¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}, LB = 1.

2. The constraint CN F (b1 + 3b2 ≤ 1) is included and satisfying it implies that b2
must be falsiﬁed, and thus CN F (b1 + 3b2 ≤ 1) is replaced by (¬b2). state = F alse,
φC = {(x2∨b2), (x3), (¬x2∨¬x3), (¬b2)}, φC ∩φS = {(x3)}, φW = {(x1∨b1, 1), (x2∨
b2, 2), (x3 ∨ b3, 1), (¬x1 ∨ ¬x2,∞), (¬x2 ∨ ¬x3,∞)}, LB = 2. As in the previous
iteration, satisfying the constraint b1 + 3b2 + b3 ≤ 2 implies b2 must be falsiﬁed.

3. The constraint CN F (b1 +3b2 +b3 ≤ 2) is included, state = T rue and the assignment
I = {x1 = F alse, x2 = T rue, x3 = F alse, b1 = T rue, b2 = F alse, b3 = T rue} indeed
satisﬁes φW of the last iteration. By ignoring the values of the blocking variables, I
is indeed an optimal assignment for φ. It falsiﬁes the soft clauses (x1, 1) and (x3, 1)
and satisﬁes (x2, 3).

24

4.7 WMSU4

Like WMSU3, WMSU4[38] (algorithm 15) adds at most one blocking variable to each soft
clause. Thought, it maintains an upper bound (U B) as well as a lower bound (LB). If the
current working formula is satisﬁable (line 9), U B is changed to the sum of the weights
of the falsiﬁed clauses by the solution (I) returned from the SAT solver. On the other
hand, if the working formula is unsatisﬁable, the SAT solver returns an unsatisﬁable core,
and the algorithm adds a blocking variable to each clause that has not yet been relaxed in
that core. If all the soft clauses in the unsatisﬁable core have been relaxed (line 16), then
the algorithm updates the lower bound (line 17) and exists the main loop. The following
example illustrates how the algorithm works.

Algorithm 15: WMSU4(φ) The WMSU4 algorithm for WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: The cost of the optimal WPMaxSAT solution to φ

1 if SAT ({C | (C,∞) ∈ φH}) = F alse then

return ∞

2

3 B ← ∅
4 φW ← φ
5 LB ← −1

6 U B ← 1 +(cid:80)|φS|

// Set of blocking variables
// Working formula initialized to φ
// Lower bound initialized to 0
i=1 wi // Upper bound initialized to the sum of the weights

of the soft clauses plus one

7 while U B > LB + 1 do
8

(state, φC, I) ← SAT ({C | (C, w) ∈ φW} ∪ CN F ((cid:80)
U B ←(cid:80)

bi∈B wi(1 − I(Ci \ bi))

if state = T rue then

bi∈B wibi ≤ U B − 1))

// Update U B to the sum of the

weights of the falsified clauses without the blocking variables

else

foreach (Ci, wi) ∈ φC ∩ φS do

if w (cid:54)= ∞ then

B(cid:48) ← B(cid:48) ∪ {bi}
φW ← φW \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

if B(cid:48) = ∅ then

LB ← U B − 1

else

B ← B ∪ B(cid:48)
LB ← U pdateBound({wi | bi ∈ B}, LB)

9

10

11

12

13

14

15

16

17

18

19

20

21 return U B

Example 4.4. Let φ = φS ∪ φH , where φS = {(x1, 1), (x2, 1), (x3, 1),
(x4, 1)} and φH = {(¬x1∨¬x2,∞), (¬x1∨¬x3,∞), (¬x1∨¬x4,∞), (¬x2∨¬x3∨¬x4,∞)}.
Before the ﬁrst iteration of the while loop, we have LB = −1, U B = 1 + (1 + 1 + 1 + 1) = 5

25

and φW = φ.

1. state = F alse, φC∩φS = {(x2), (x3), (x4)}, LB = 0, φW = {(x1, 1), (x2∨b2, 1), (x3∨

b3, 1), (x4 ∨ b4, 1)} ∪ φH .

2. The constraint CN F (b2 + b3 + b4 ≤ 5 − 1) is included, state = T rue, I = {x1 =
T rue, x2 = F alse, x3 = F alse, x4 = F alse, b2 = T rue, b3 = T rue, b4 = T rue},
U B = 3.

3. The constraint CN F (b2 + b3 + b4 ≤ 3 − 1) is included, state = F alse, φC ∩ φS =
{(x1, 1), (x2 ∨ b2, 1), (x3 ∨ b3, 1), (x − 4 ∨ b4, 1)}, LB = 1, φW = {(x1 ∨ b1), (x2 ∨
b2, 1), (x3 ∨ b3, 1), (x − 4 ∨ b4, 1)} ∪ φH .

4. The constraint CN F (b1 + b2 + b3 + b4 ≤ 2) is included, state = SAT , I = {x1 =
F alse, x2 = F alse, x3 = T rue, x4 = T rue, b1 = T rue, b2 = T rue, b3 = F alse, b4 =
F alse}, U B = 2. The cost of the optimal assignment is indeed 2 (since (x1, 1) and
(x2, 1) are falsiﬁed) by I.

5 Core-guided Binary Search Algorithms

Core-guided binary search algorithms are similar to binary search algorithms described in
the ﬁrst section, except that they do not augment all the soft clauses with blocking variables
before the beginning of the main loop. Heras, Morgado and Marques-Silva proposed this
technique in[22] (see algorithm 16).

26

Algorithm 16: CoreGuided-BS(φ) Core-guided binary search algorithm for solving
WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: The cost of the optimal WPMaxSAT solution to φ

1 state ← SAT ({Ci | (Ci,∞) ∈ φH})
2 if state = F alse then
3

return ∅

4 φW ← φ
5 LB ← −1

6 U B ← 1 +(cid:80)|φS|

i=1 wi

7 B ← ∅
8 while LB + 1 < U B do
9

bi∈B wibi ≤ mid))

(cid:99)

mid ← (cid:98) LB+U B

(state, φC, I) ← SAT ({C | (C, w) ∈ φW} ∪ CN F ((cid:80)
U B ←(cid:80)|φS|

i=1 wi(1 − I(Ci \ {bi}))

if state = T rue then

2

lastI ← I

else

if φC ∩ φS = ∅ then

LB ← U pdateBound({wi | bi ∈ B}, mid) − 1

else

foreach (Ci, wi) ∈ φC ∩ φS do

let bi be a new blocking variable
B ← B ∪ {bi}
φW ← φW \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

return lastI

10

11

12

13

14

15

16

17

18

19

20

21

22

Similar to other algorithms, CoreGuided-BS begins by checking the satisﬁability of the
hard clauses (lines 1-3). Then it initializes the lower bound (line 4), the upper bound (line
5) and the set of blocking variables (line 6) respectively to -1, one plus the sum of the
weights of the soft clauses and ∅. At each iteration of the main loop (lines 7-21) a SAT
solver is called on the working formula with a constraint ensuring that the sum of the
weights of the relaxed soft clauses is less than or equal the middle value (line 9). If the
formula is satisﬁable (line 10), the upper bound is updated to the sum of the falsiﬁed soft
clauses by the current assignment (line 11). Otherwise, if all the soft clauses have been
relaxed (line 14), then the lower bound is updated (line 15), and if not, non-relaxed sot
clauses belonging to the core are relaxed (lines 17-19). The main loop continues as long
as LB + 1 < U B.

Example 5.1. Consider φ in example 2.1 with all the weights of the soft clauses set to 1.
At the beginning of the algorithm LB = −1, U B = 8, B = ∅ and φH is satisﬁable. The
following are the iterations the algorithm executes.

1. mid = (cid:98)−1+8

(cid:99) = 3. Since B = ∅, no constraint is included. state = F alse,

φC ∩ φS = {(x6), (¬x6)}, B = {b6, b7}. φ = {(x1, 1), (x2, 1), (x3, 1),

2

27

(x4, 1), (x5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .

2. mid = 3, the constraint CN F (b6 + b7 ≤ 3) is included. state = F alse, φC ∩ φS =

{(x1), (x2)}, B = {b1, b2, b6, b7}, φ = {(x1∨b1, 1), (x2∨b2, 1), (x3, 1), (x4, 1), (x5, 1), (x6∨
b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .

3. mid = 3, the constraint CN F (b1 + b2 + b6 + b7 ≤ 3) is included. state = F alse,
φC ∩ φS = {(x3), (x4)}, B = {b1, b2, b3, b4, b6, b7}, φ = {(x1 ∨ b1, 1), (x2 ∨ b2, 1), (x3 ∨
b3, 1), (x4 ∨ b4, 1), (x5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .

4. mid = 3, the constraint CN F (b1 + b2 + b3 + b4 + b6 + b7 ≤ 3) is included. state =
F alse, φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x6 ∨ b6), (¬x6 ∨ b7), (x5)},
B = {b1, b2, b3, b4, b5, b6, b7}, φ = {(x1∨b1, 1), (x2∨b2, 1), (x3∨b3, 1), (x4∨b4, 1), (x5∨
b5, 1), (x6 ∨ b6, 1), (¬x6 ∨ b7, 1)} ∪ φH .

5. mid = 3, CN F (b1 + b2 + b3 + b4 + b5 + b6 + b7 ≤ 3) is included. state = F alse,
φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨ b5), (x6 ∨ b6), (¬x6 ∨ b7)},
LB = 3.

6. mid = 5, the constraint CN F (b1+b2+b3+b4+b6+b7 ≤ 5) is included. state = T rue,
I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 = T rue, x6 = F alse, b1 =
T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 = T rue, b7 = F alse},
U B = 4. The values of the xi, (1 ≤ i ≤ 6) variables in I indeed constitute an
optimal assignment.

The core-guided binary search approach was improved by Heras[22] et al. with disjoint

cores (see deﬁnition 4.6).

28

Algorithm 17: DisjointCoreGuided-BS(φ) Core-guided binary search extended with
disjoint cores for solving WPMaxSAT.
Input: A WPMaxSAT instance φ = φS ∪ φH
Output: A WPMaxSAT solution to φ

1 if SAT ({C | (C,∞) ∈ φH}) = F alse then

return ∅

2

3 φW ← φ
4 C ← ∅
5 repeat
6

foreach Ci ∈ C do
midi ← U Bi

if LBi + 1 = U Bi then

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

else

midi ← (cid:98) LBi+U Bi

(state, φC , I) ← SAT ({C | (C, w) ∈ φW} ∪(cid:83)

(cid:99)

2

if state = T rue then
lastI ← I
foreach Ci ∈ C do

U Bi ←(cid:80)

br∈B wr(1 − I(Cr \ {br})))

Ci∈C CN F ((cid:80)

bi∈B wibi ≤ midi))

else

subC ← IntersectingCores(φC ,C)
if φC ∩ φS = ∅ and |subC| = 1 then

LB ← mid // subC = {(B, LB, mid, U B)}

else

foreach (Ci, wi) ∈ φC ∩ φS do

let bi be a new blocking variable
B ← B ∪ {bi}
φW ← φW \ {(Ci, wi)} ∪ {(Ci ∨ bi, wi)}

LB ← 0

U B ← 1 +(cid:80)

foreach (Bi, LBi, midi, U Bi) ∈ subC do

bi∈B wi

B ← B ∪ Bi
LB ← LB + LBi
U B ← U B + U Bi

C ← C \ subC ∪ {(B, LB, 0, U B)}

32 until ∀Ci∈CU Bi ≤ LBi + 1
33 return lastI

Core-guided binary search methods with disjoint unsatisﬁable cores maintains smaller
lower and upper bounds for each disjoint core instead of just one global lower bound
and one global upper bound. Thus, the algorithm will add multiple smaller cardinality
constraints on the sum of the weights of the soft clauses rather than just one global
constraint.
To maintain the smaller constraints, the algorithm keep information about the pre-
vious cores in a set called C initialized to ∅ (line 4) before the main loop. Whenever

29

the SAT solver returns F alse (line 12) it also provides a new core and a new entry
Ci = (Bi, LBi, midi, U Bi) is added in C for Ui, where Bi is the set of blocking variables
associated with the soft clauses in Ui, LBi is a lower bound, midi is the current middle
value and U Bi is an upper bound. The main loop terminates when for each Ci ∈ C,
LBi + 1 ≥ U Bi (line 33). For each entry in C, its middle value is calculated (lines 6-
10) and a constraint for each entry is added to the working formula before calling the
SAT solver on it (line 11). If the working formula is unsatisﬁable (line 16), then, using
IntersectiongCores, every core that intersects the current core is identiﬁed and its corre-
sponding entry is added to subC (line 17). If the core does not contain soft clauses that
need to be relaxed and |subC| = 1 (line 18), then LB is assigned the value of the midpoint
(line 19). On the other hand, if there exists clauses that has not been relaxed yet then
the algorithm relaxes them (lines 21-24) and a new entry for the current core is added to
C which accumulates the information of the previous cores in subC (lines 25-31).

Example 5.2. Consider φ in example 2.1 with all the weights of the soft clauses set to
1. At the beginning of algorithm 17, we have φW = φ and C = ∅. The following are the
iterations the algorithm executes.

1. No constraints to include. state = F alse, φC ∩ φS = {(x6), (¬x6)}, subC = ∅,
B = {b6, b7}, φW = {(x1), (x2), (x3), (x4), (x5), (x6 ∨ b6), (¬x6 ∨ b7)} ∪ φH , LB = 0,
U B = 3, C = {({b6, b7}, 0, 0, 3)}.

2. The constraint CN F (b6 +b7 ≤ 1) is included. state = F alse, φC∩φS = {(x1), (x2)},
subC = ∅, B = {b1, b2}. φW = {(x1 ∨ b1), (x2 ∨ b2), (x3), (x4), (x5), (x6 ∨ b6), (¬x6 ∨
b7)} ∪ φH , LB = 0, U B = 3, C = {({b6, b7}, 0, 0, 3), ({b1,
b2}, 0, 0, 3)}.

3. The constraints {CN F (b6 +b7 ≤ 1), CN F (b1 +b2 ≤ 1)} are included. state = F alse,
φC ∩ φS = {(x3), (x4)}, subC = ∅, B = {b3, b4}, φW = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨
b3), (x4∨b4), (x5), (x6∨b6), (¬x6∨b7)}∪φH , LB = 0, U B = 3, C = {({b6, b7}, 0, 0, 3),
({b1, b2}, 0, 0, 3), ({b3, b4}, 0, 0, 3)}.

4. The constraints {CN F (b6 + b7 ≤ 1), CN F (b1 + b2 ≤ 1), CN F (b3 + b4 ≤ 1)} are
included. state = F alse, φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5)},
subC = {({b1, b2}, 0, 0, 3), ({b3, b4}, 0,
0, 3)}, B = {b1, b2, b3, b4, b5}, φW = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨
b5), (x6∨b6), (¬x6∨b7)}∪φH , LB = 0, U B = 8, C = {({b6, b7}, 0, 0, 3), ({b1, b2, b3, b4, b5}, 0, 0, 8)}.

5. The constraints CN F (b6 + b7 ≤ 1), CN F (b1 + b2 + b3 + b4 + b5 ≤ 4) are in-
cluded. state = T rue, I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = F alse, b3 = T rue, b5 = F alse, b6 =
T rue, b7 = F alse}, C = {({b6, b7}, 0, 0, 1), ({b1, b2, b3, b4, b5}, 0, 0, 2)}.

6. The constraints CN F (b6 + b7 ≤ 1), CN F (b1 + b2 + b3 + b4 + b5 ≤ 1) are included.
state = F alse, φC ∩ φS = {(x1 ∨ b1), (x2 ∨ b2), (x3 ∨ b3), (x4 ∨ b4), (x5 ∨ b5)}, subC =
{({b1, b2, b3, b4, b5}, 0, 0, 2)}, C = {({b6, b7}, 0, 0, 1), ({b1, b2, b3, b4, b5}, 1, 0, 2)}.

7. state = T rue, I = {x1 = F alse, x2 = F alse, x3 = T rue, x4 = F alse, x5 =
T rue, x6 = F alse, b1 = T rue, b2 = T rue, b3 = F alse, b4 = T rue, b5 = F alse, b6 =
T rue, b7 = F alse}.

30

SAT-based WPMaxSAT solvers rely heavily on the hardness of the SAT formulae
returned by the underlying SAT solver used. Obviously, the location of the optimum
solution depends on the structure of the instances returned and the number of iterations
it takes to switch from T rue to F alse (or from F alse to T rue).

6 Portfolio MaxSAT Techniques

The results of the MaxSAT Evaluations suggest there is no absolute best algorithm for
solving MaxSAT. This is because the most eﬃcient solver often depends on the type of
instance. In other words, diﬀerent solution approaches work well on diﬀerent families of
instances[40]. Having an oracle able to predict the most suitable MaxSAT solver for a
given instance would result in the most robust solver. The success of SATzilla[59] for SAT
was due to a regression function which was trained to predict the performance of every
solver in the given set of solvers based on the features of an instance. When faced with a
new instance, the solver with the best predicted runtime is run on the given instance. The
resulting SAT portfolios excelled in the SAT Competitions in 2007 and in 2009 and pushed
the state-of-the-art in SAT solving. When this approach is extended to (WP)MaxSAT, the
resulting portfolio can achieve signiﬁcant performance improvements on a representative
set of instances.

ISAC[9] (Instance-Speciﬁc Algorithm Conﬁguration) is one of the most successful WP-
MaxSAT portfolio algorithms. It works by computing a representative feature vector that
characterizes the given input instance in order to identify clusters of similar instances. The
data is therefore clustered into non-overlapping groups and a single solver is selected for
each group based on some performance characteristic. Given a new instance, its features
are computed and it is assigned to the nearest cluster. The instance is then solved by the
solver assigned to that cluster.

7 Translating Pseudo-Boolean Constraints into CNF

This section discusses translating pseudo-Boolean (PB) constraints into CNF. The proce-
dure is needed in almost every SAT-based WPMaxSAT algorithm and its eﬃciency surely
aﬀects the overall performance of the solver.

7.1 Introduction

A PB constraint is a linear constraint over Boolean variables. PB constraints are inten-
sively used in expressing NP-hard problems. While there are dedicated solvers (such as
Sat4j) for solving PB constraints, there are good reasons to be interested in transforming
the constraints into SAT (CNF formulae), and a number of methods for doing this have
been reported[53, 12, 36, 2, 55, 33, 1, 13].

Deﬁnition 7.1 (PB constraint). A PB constraint is an inequality (equality) on a linear
combination of Boolean literals li

n(cid:88)

aili{<,≥, =,≤, >}K

where a1, . . . , an and K (called the bound) are constant integers and l1, . . . , ln are literals.

i=1

31

There are at least two clear beneﬁts of solving PB constraints by encoding them into
CNF. First, high-performance SAT solvers are being enhanced continuously, and since they
take a standard input format there is always a selection of good solvers to make use of.
Second, solving problems involving Boolean combinations of constraints is straightforward.
This approach is particularly attractive for problems which are naturally represented by
a relatively small number of PB constraints (like the Knapsack problem) together which
a large number of purely Boolean constraints.

7.2 Encoding method

consider (without loss of generality) PB constraints of the form (cid:80)n

In their paper, they
We present the method of Bailleux, Boufkhad and Roussel[13].
i=1 aili ≤ K, where
a1 ≤ a2 ≤ ··· ≤ an. This type of constraint is denoted by the triple (cid:104)An, Ln, K(cid:105), where
An = (a1, . . . , an) and Ln = (l1, . . . , ln). For some bound b, the triple (cid:104)Ai, Li, b(cid:105), for
1 ≤ i ≤ n, represents the PB constraint aili + a2l2 + ··· + aili ≤ b. When the tuples
An and Ln are ﬁxed, a triple (cid:104)Ai, Li, b(cid:105) representing a PB constraint is deﬁned with no
ambiguity by the integer i and the bound b.
For each (cid:104)Ai, Li, b(cid:105), a new variable Di,b is introduced. This new variable represents
the satisfaction of the constraint (cid:104)Ai, Li, b(cid:105), i.e., Di,b = T rue if and only if (cid:104)Ai, Li, b(cid:105) is
satisﬁed. The variable Dn,K represents (cid:104)An, Ln, K(cid:105) and the correctness of the encoding is
conditioned by the fact that an assignment satisﬁes (cid:104)An, Ln, K(cid:105) if and only if it satisﬁes
the encoded CNF formula and ﬁxes Dn,K to T rue.

The variables Di,b such that b ≤ 0 or b ≥(cid:80)i

j=1 aj are called terminal variables.

The encoding starts with a set of variables containing the original variables PB con-
straint and the variable Dn,K. The variables li are marked. At each step, an unmarked
variable Di,b is considered. If Di,b is not terminal the two variables Di−1,b and Di−1,b−ai
are added to the set of variables if they are not already in it and the following four clauses
are added

(¬Di−1,b−ai ∨ Di,b), (Di,b ∨ Di−1,b), (Di,b ∨ li ∨ Di−1,b−ai), (Di−1,b ∨ li ∨ Di,b)

In case that Di,b is a terminal variable, then by deﬁnition either b ≤ 0 or b ≥(cid:80)i

Next, Di,b is marked so it won’t be considered again.

j=1 aj

F alse
T rue

if b < 0. The clause ¬Di,b is added to the formula.

j=1 aj ≤ b. The clause Di,b is added to the formula.

if (cid:80)i

and Di,b is ﬁxed as follows

(cid:40)

Di,b =

When b = F alse, every variable in the constraint must be set to F alse. To achieve this, for
every 1 ≤ j ≤ i, the clauses (Di,0∨lj) are added together with the clause (l1∨l2∨···∨Di,0).
The procedure stops when there are no more unmarked variables.
Example 7.1. This example illustrates the encoding of the PB constraint 2x1+3x2+4x3 ≤
6. The formula φ = {(¬D2,2 ∨ D3,6), (¬D3,6 ∨ ¬x3 ∨ D2,2), (¬D2,6 ∨ x3 ∨ D3,6), (D2,6 ∨
¬D1,−1∨D2,2), (¬D2,2∨D1,2), (¬D2,2∨¬x2∨D1,−1), (¬D1,2∨x2∨D2,2), (D1,2), (¬D1,−1)}.
Thus, D3,6 = T rue only if at least one of x2 or x3 is F alse.

The correctness and the complexity of the encoding are discussed in the same paper[13].

32

7.3 Complexity of the encoding

The complexity of the encoding is measured in terms of the number of variables. The
number of clauses produced is related by a constant factor to the number of variables.
There are cases where the previous procedure produces a polynomial and others that
produce an exponential number of variables.

7.3.1 Polynomial cases

The encoding seems to generate an exponential number of variables: at each step a non-
terminal variable creates two variables that will in turn create two other variables each
and so on. However, this is not true for terminal variables and for variables that have
already been considered by the procedure. When a terminal variable is met, it is said to
be a cut in the procedure and when a variable already in the set of variables is met, it
is said to have merged in the procedure. By the cuts and merges, the size of encodings
can be polynomial in some cases. There are two restrictions on the PB constraint for it to
have a polynomial-size encoding:

where m is at least equal to K −(cid:80)i
diﬀerent values and then it can take at most (cid:80)i

1. The integers ai’s are bounded by a polynomial in n, P (n). In this case, the potential
number of Di,b variables for some i is 2n−i but because of the merges, this number
reduces to a polynomial since the variables Di,b for some i are such that m ≤ b ≤ M
j=0 an−j and M ≤ K, b can take at most M ?m
j=0 an?j diﬀerent values, which is
bounded by (n − i)P (n). Since there are n diﬀerent possible values for i, the total
number of variables is bounded by a polynomial in n. Figure 1 shows an example of
this case.

is a terminal variable. This is true because (cid:80)i?1
then (cid:80)i−1

2. The weights are ai = αi where α ≥ 2. In this case, for every non terminal variable
Di,b considered in the procedure, at least one of the variables Di−1,b or Di−1,b?αi
j=0 αj < αi. Either b ≥ αi and
j=0 αj < b and then Di−1,b is a terminal variable or b < αi and in this
case Di−1,b−αi is a terminal variable. Thus, there is a cut each time a variable is
considered in the procedure. Figure 2 shows an example for this case.

Figure 1: Variables introduced to
encode 3x1 +3x2 +3x3 +3x4 ≤ 6.

Figure 2: Variables introduced to
encode 2x1 + 4x2 + 8x3 + 16x4 ≤
12.

33

Figure 3: Totalizer encoding for the constraint l1 + ··· + l5 ≤ k

7.3.2 Exponential cases

There are possible sequences of ai’s that will give a tree with branches of length Ω(n) and
with no possible merge of nodes (which implies a tree of size Ω(2n)). The idea here is
simply to combine a constant sequence with a geometric sequence. Let n be the length of
the PB constraint Q and let ai = α + bi such that α = bn+2. The key point is that the
i=0 bi < α.
For simplicity, we will choose b = 2. Note that in this case, ai = 2n+2 + 2i which is not
bounded by a polynomial in n. Fix K = α × n

2 = n × 2n+1.

geometric term must be negligible compared to the constant term, that is (cid:80)n
A terminal node is reached when we get a term Di,k such that k ≤ 0 or k ≥(cid:80)i
equal to K. We have(cid:80)i
j=1 aj =(cid:80)i
sponds to(cid:80)i
j=1 ajxj ≤ K −(cid:80)
binary representation of K −(cid:80)

j=1 aj.
Because the constant term is predominant, the ﬁrst condition cannot be met before i =
K
α = n
2 . The earliest case where the second condition can be satisﬁed is when k remains
j=1 bj ≥ α × i. Therefore, the
2 = α × i which means
earliest case where the second condition can be met is when α × n
i = n

2 . We can conclude that each branch is at least of length n
2 .
In addition, in the encoding, each node of the tree holds the term Di,k which corre-
j∈S aj, where S ⊂ [i + 1..n]. One key point is that in the
j∈S aj, the n least signiﬁcant bits directly correspond to
the indices in S. Therefore, these n least signiﬁcant bits of the right term are necessarily
diﬀerent from one node to another. For this reason, no node can be merged. Because of
2 , the size of the tree is at least 2 n
this and since branches are of length at least equal to n
2
and the encoding of this particular constraint is of exponential size.

j=1 α + bj = α × i +(cid:80)i

7.4 Other encoding techniques

Incremental approaches[42, 39, 47] allow the constraint solver to retain knowledge from
previous iterations that may be used in the upcoming iterations. The goal is to retain the
inner state of the constraint solver as well as learned clauses that were discovered during
the solving process of previous iterations. At each iteration, most MaxSAT algorithms
create a new instance of the constraint solver and rebuild the formula losing most if not
all the knowledge that could be derived from previous iterations.

34

8 Experimental Investigation

We conducted an experimental investigation in order to compare the performance of diﬀer-
ent WPMaxSAT solvers to branch and bound solvers on a number of benchmarks instances.
Experimental evaluations of MaxSAT solvers has gained great interest among SAT and
MaxSAT researchers. This is due to the fact that solvers are becoming more and more
eﬃcient and adequate to handle WPMaxSAT instances coming from real-life applications.
Thus, carrying out such an investigation and comparing the eﬃciency of diﬀerent solvers
is critical to knowing which solving technique is suitable for which category of inputs. In
fact, an annual event called the MaxSAT Evaluations is scheduled just for this purpose.
The ﬁrst MaxSAT Evaluation was held in 2006. The objective of the MaxSAT Evaluation
is comparing the performance of state of the art (weighted) (partial) MaxSAT solvers on
a number of benchmarks and declaring a winner for each benchmark category.

The solvers that we investigate participated in the MaxSAT Evaluations of 2013 and
2014. A number of the solvers are available online while some of them were not and we had
to contact the authors to get a copy. The benchmarks we used participated in the 2013
MaxSAT Evaluation and are WPMaxSAT instances of three categories: random, crafted
and industrial.
The solvers were run on a machine with an Intel(cid:114) CoreTM i5 CPU clocked at 2.4GHz,
with 5.7GB of RAM running elementary OS Linux. The timeout is set to 1000 seconds
and running the solvers on the benchmarks took roughly three months. We picked elemen-
taryOS because it does not consume too many resources to run and thus giving enough
room for the solvers to run. In addition, elementaryOS is compatible with popular Ubuntu
distribution which makes it compatible with its repositories and packages.

8.1 Solvers descriptions

The solvers we experimented with are:

1. WMiFuMax is an unsatisﬁability-based WPMaxSAT solver based on the tech-
nique of Fu and Malik[18] and on the algorithm by Manquinho, Marques-Silva,
and Planes[32], which is works by identifying unsatisﬁable sub-formulae. MiFuMax
placed third in the WPMaxSAT industrial category of the 2013 MaxSAT evaluation.
The solver (and the source code) is available online under the GNU General Public
License. The SAT solver used is called MiniSAT[54]. Author: Mikol´aˇs Janota.

2. QWMaxSAT is a weighted version of QMaxSAT developed by Koshimura, Zhang,
Fujita and Hasegawa[25] and is available freely online. This solver is a satisﬁability-
based solver built on top of version 2.0 of the SAT solver MiniSAT[16]. The authors
of QMaxSAT modiﬁed only the top-level part of MiniSat to manipulate cardinal-
ity constraints, and the other parts remain unchanged. Despite originally being a
PMaxSAT solver, the authors developed a version of the solver for WPMaxSAT in
2014. Authors: Miyuki Koshimura, Miyuki Koshimura, Hiroshi Fujita and Ryuzo
Hasegawa.

3. Sat4j[27] is a satisﬁability-based WPMaxSAT solver developed by Le Berre and Par-
rain. The solver works by translating WPMaxSAT instances into pseudo-Boolean
optimization ones. The idea is to add a blocking variable per weighted soft clause
that represents that such clause has been violated, and to translate the maximization

35

tion min :(cid:80)n

problem on those weighted soft clauses into a minimization problem on a linear func-
tion over those variables. Given a WPMaxSAT instance φ = {(C1, w1), . . . , (Cn, wn)}∪
φH , Sat4j translates φ into φ(cid:48) = {(C1 ∨ b1), . . . , (Cn ∨ bn)} plus an objective func-
i=1 wibi. Sat4j avoids adding blocking variables to both hard and unit
clauses. the Sat4j framework includes the pseudo-Boolean solver Sat4j-PB-Res which
is used to solve the encoded WPMaxSAT problem. Authors: Daniel Le Berre and
Emmanuel Lonca.

4. MSUnCore[35] is an unsatisﬁability-based WPMaxSAT solver built on top the
SAT solver PicoSAT[14]. This solver implements a number of algorithms capable
of solving MaxSAT, PMaxSAT and W(P)MaxSAT. MSUnCore uses PicoSAT for
iterative identiﬁcation of unsatisﬁable cores with larger weights. Although ideally a
minimal core would be preferred, any unsatisﬁable core can be considered. Clauses
in identiﬁed core are then relaxed by adding a relaxation variable to each clause.
Cardinality constraints are encoded using several encodings, such as the pairwise and
bitwise encodings[49, 48], the ladder encoding[20], sequential counters[53], sorting
networks[17], and binary decision diagrams (BDDs)[17]. Authors: Ant´onio Morgado,
Joao Marques-Silva, and Federico Heras.

5. Maxsatz2013f is a very successful branch and bound solver that placed ﬁrst in
the WPMaxSAT random category of the 2013 MaxSAT evaluation. It is based on
an earlier solver called Maxsatz[28], which incorporates the technique developed for
the famous SAT solver, Satz[29]. At each node, it transforms the instance into an
equivalent one by applying eﬃcient reﬁnements of unit resolution ((A∨ B) and (¬B)
yield A) which replaces {(x), (y), (¬x∨¬y)} with {(cid:3), (x∨y)} and {(x), (¬x∨y), (¬x∨
z), (¬y∨¬z)} with {(cid:3), (¬x∨y∨z), (x∨¬y∨¬z)}. Also, it implements a lower bound
method (enhanced with failed literal detection) that increments the lower bound by
one for every disjoint inconsistent subset that is detected by unit propagation. The
variable selection heuristics takes into account the number of positive and negative
occurrences in binary and ternary clauses. Maxsatz2013f is available freely online.
Authors: Chu Min Li, Yanli LIU, Felip Many`a, Zhu Zhu and Kun He.

6. WMaxSatz-2009 and WMaxSatz+[31, 30] are branch and bound solvers that
use transformation rules[28] which can be implemented eﬃciently as a by-product
of unit propagation or failed literal detection. This means that the transformation
rules can be applied at each node of the search tree. Authors: Josep Argelich, Chu
Min Li, Jordi Planes and Felip Many`a.

7. ISAC+[9] (Instance-Speciﬁc Algorithm Conﬁguration) is a portfolio of algorithm
which, given a WPMaxSAT instance, selects the solver better suited for that in-
stance. A regression function is trained to predict the performance of every solver in
the given set of solvers based on the features of an instance. When faced with a new
instance, the solver with the best predicted runtime is run on the given instance.
ISAC+ uses a number of branch and bound solvers as well as SAT-based, including
QMaxSAT, WMaxSatz-2009 and WMaxSatz+. Authors: Carlos Ans´otegui, Joel
Gabas, Yuri Malitsky and Meinolf Sellmann.

36

Technique

Satisﬁability-based

Branch and bound

Portfolio

Summary

Solver name
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
Maxsatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

Sub-technique
SAT-based
SAT-based
SAT-based
UNSAT-based

8.2 Benchmarks descriptions

The benchmarks we used are the WPMaxSAT instances of the 2013 MaxSAT Evaluation
and are divided into three categories:

1. Random: This category consists of WPMax-2-SAT and WPMax-3-SAT instances
generated uniformly at random. The WPMax-2-SAT instances are divided into for-
mulae with low (lo), medium (me) and high (hi) numbers of variables and clauses.
The WPMax-3-SAT instances contain three literals per clause and have a high num-
ber of variables and clauses.

2. Crafted: These instances are speciﬁcally designed to give a hard time to the solver.

There is an award for the smallest instance that can not be solved by any solver.

3. Industrial: Consists of instances that come from various applications of practical
interest, such as model checking, planning, encryption, bio-informatics, etc. encoded
into MaxSAT. This category is intended to provide a snapshot of the current strength
of solvers as engines for SAT-based applications.

In the MaxSAT Evaluations, a ﬁrst, second and third place winners are declared for each
of the three categories.

8.3 Results

In this section, the results we obtained are presented and discussed. For each category, we
present the constituting sets of instances and their sizes, the number of instances solved
by each solver and the amount of time it took each solver to work on each set of instances.

8.3.1 Random category

The three sets of instances in the random category are:

Name
wpmax2sat-lo
wpmax2sat-me
wpmax2sat-hi
wpmax3sat-hi

Abbreviation # of instances

30
30
30
30

lo
me
hi
3hi

37

Solver
MiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

lo me hi
0
0
0
0
0
0
0
0
29
30
30
29
29
30
29
1

0
0
0
0
30
30
30
8

3hi

0
0
0
0
30
30
30
10

Table 1: Number of instances solved in the random category.

Solver
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

hi
0%
0%
0%
0%

Total

0%
0%
0%
0%

me
0%
0%
0%
0%

3hi
0%
0%
0%
0%

lo
0%
0%
0%
0%
100% 100% 96.7% 100% 99.2%
100% 100% 96.7% 100% 99.2%
100% 100% 96.7% 100% 99.2%
96.7% 26.7% 3.3% 33.3% 40%

Table 2: Percentages of instances solved in the random category.

Figure 4: Time results for the random category.

38

The branch and bound solvers MaxSatz2013f, WMaxSatz-2009 and WMaxSatz+ per-
formed considerably better than the SAT-based solvers in the random category. In par-
ticular, MaxSatz2013f ﬁnished the four benchmarks under 16 minutes, while WMiFuMax,
MSUnCore and Sat4j timedout on most instances. MaxSatz2013f placed ﬁrst in the ran-
dom category in the 2013 MaxSAT Evaluation, see http://www.maxsat.udl.cat/13/results/
index.html#wpms-random-pc. The top non branch and bound solver is ISAC+, which placed
third in the random category in 2014 (see http://www.maxsat.udl.cat/14/results/index.html#
wpms-random-pc).

8.3.2 Crafted category

The seven sets of instances in the crafted category are:

Name
auctions/auc-paths
auctions/auc-scheduling
CSG
min-enc/planning
min-enc/warehouses
pseudo/miplib
random-net

Abbreviation # of instances

auc/paths

auc/sch

csg

planning

warehouses

miplib
rnd-net

86
84
10
56
18
12
74

Solver
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

auc/paths

auc/sch

csg

planning warehouses miplib

rnd-net

84
84
55
84
81
67
66
84

84
84
55
84
81
67
66
84

5
10
10
6
1
1
1
4

23
56
56
53
41
45
45
53

0
2
1
0
6
6
6
18

1
4
4
0
4
3
2
3

8
1
0
0
1
0
0
55

Table 3: Number of instances solved by each solver.

rnd-net Total
30.1%
57%
48%
38.7%
49.7%
47%
45.6%
76.3%

10.8%
1.4%
0%
0%
1.4%
0%
0%

74.3%

Solver
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

auc/paths

auc/sch

2.3%
52.3%
31.4%
16.3%
100%
100%
100%
100%

100%
100%
65.5%
100%
96.4%
79.8%
78.6%
100%

csg
50%
100%
100%
60%
10%
10%
10%
40%

planning warehouses miplib

41.1%
100%
100%
94.6%
73.2%
80.4%
80.4%
94.6%

0%

11.1%
5.6%
0%

33.3%
33.3%
33.3%
100%

8.3%
33.3%
33.3%

0%

33.3%
25%
16.7%
25%

Table 4: Percentages of instances solved in the crafted category.

39

Figure 5: Time results for the crafted category.

As it can be noticed from the results, ISAC+ is the winner of the crafted cate-
Indeed, the winner of this category in the 2014 MaxSAT Evaluation is ISAC+
gory.
(see http://www.maxsat.udl.cat/14/results/index.html#wpms-crafted), and in the 2013 evalua-
tion it placed second (see http://www.maxsat.udl.cat/13/results/index.html#wpms-crafted-pc).
Generally, SAT-based and branch and bound solvers perform nearly equally on crafted
instances.

8.3.3

Industrial category

The seven sets of instance in the industrial category are:

Name
wcsp/spot5/dir
wcsp/spot5/log
haplotyping-pedigrees
upgradeability-problem
preference planning
packup-wpms
timetabling

Abbreviation # of instances

21
21
100
100
29
99
26

wcsp-dir
wcsp-log

HT
UP
PP

PWPMS

TT

40

Solver
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

wcsp-dir wcsp-log HT UP PP PWPMS TT

6
14
3
14
4
4
4
17

6
13
3
14
4
3
3
7

85
20
15
89
0
0
0
15

100

0
37
100

0
41
41
100

11
29
28
25
5
5
5
9

46
17
2
0
25
12
12
99

0
8
8
0
0
0
0
9

Table 5: Number of instances solved in the industrial category.

Solver
WMiFuMax
QWMaxSAT
Sat4j
MSUnCore
MaxSatz2013f
WMaxSatz-2009
WMaxSatz+
ISAC+

wcsp-dir wcsp-log HT

UP

PP

PWPMS

28.6%
66.7%
14.3%
66.7%
19%
19%
19%
81%

28.6%
61.9%
14.3%
66.7%
19%
14.3%
14.3%
33.3%

0%
37%

85% 100% 15.2%
40%
20%
15%
38.7%
89% 100% 34.5%
6.9%
0%
5%
0%
0%
6.9%
15% 100% 12.4%

0%
41%
41%

46%
17%
2%
0%
25%
12%
12%
100%

TT
0%

Total
43.3%
30.8% 34.5%
30.8% 21.7%
51%
10%
13%
13%
34.6% 53.8%

0%
0%
0%
0%

Table 6: Percentages of instances solved in the industrial category.

Figure 6: Time results for the industrial category.

It is clear that SAT-based solvers outperform branch and bound ones on industrial

41

instances. The winner solver of this category in the 2013 MaxSAT evaluation is ISAC+
(see http://www.maxsat.udl.cat/13/results/index.html#wpms-industrial) and the same solver
placed second in the 2014 evaluation (see http://www.maxsat.udl.cat/14/results/index.html#
wpms-industrial-pc).

Generally, we can notice that on industrial instances, SAT-based solvers are performed
considerably better than branch and bound solvers which performed poorly. On the other
hand, branch and bound solvers outperformed SAT-based ones on random instances.

9 Acknowledgments

This paper is made possible through the help and support from Dr. Hassan Aly (Depart-
ment of Mathematics, Cairo University, Egypt) and Dr. Rasha Shaheen (Department of
Mathematics, Cairo University, Egypt). I would also like to thank Dr. Carlos Ans´otegui
(University of Lleida, Spain) for his advice to include a section on translating pseudo
Boolean constraints and his encouraging review of this work.

References

[1] Amir Aavani. Translating pseudo-boolean constraints into cnf. Theory and Applica-

tions of Satisﬁability Testing-SAT 2011, pages 357–359, 2011.

[2] Amir Aavani, David G Mitchell, and Eugenia Ternovska. New encoding for translating

pseudo-boolean constraints into sat. In SARA, 2013.

[3] Xuanye An, Miyuki Koshimura, Hiroshi Fujita, and Ryuzo Hasegawa. Qmaxsat ver-
sion 0.3 & 0.4. In Proceedings of the International Workshop on First-Order Theorem
Proving, FTP, pages 7–15, 2011.

[4] Carlos Ans´otegui, Mar´ıa Bonet, and Jordi Levy. Solving (weighted) partial maxsat
through satisﬁability testing. Theory and Applications of Satisﬁability Testing-SAT
2009, pages 427–440, 2009.

[5] Carlos Ans´otegui, Maria Luisa Bonet, Joel Gab`as, and Jordi Levy. Improving sat-
based weighted maxsat solvers. In Principles and Practice of Constraint Programming,
pages 86–101. Springer, 2012.

[6] Carlos Ans´otegui, Maria Luisa Bonet, Joel Gab`as, and Jordi Levy. Improving wpm2
for (weighted) partial maxsat. In Principles and Practice of Constraint Programming,
pages 117–132. Springer, 2013.

[7] Carlos Ans´otegui, Maria Luisa Bonet, and Jordi Levy. A new algorithm for weighted

partial maxsat. 2010.

[8] Carlos Ans´otegui, Maria Luisa Bonet, and Jordi Levy. Sat-based maxsat algorithms.

Artiﬁcial Intelligence, 196:77–105, 2013.

[9] Carlos Ans´otegui, Yuri Malitsky, and Meinolf Sellmann. Maxsat by improved

instance-speciﬁc algorithm conﬁguration. 2014.

42

[10] Josep Argelich, Chu Min Li, Felip Manya, and Jordi Planes. The ﬁrst and second

max-sat evaluations. JSAT, 4(2-4):251–278, 2008.

[11] Roberto As´ın Ach´a and Robert Nieuwenhuis. Curriculum-based course timetabling

with sat and maxsat. Annals of Operations Research, pages 1–21, 2012.

[12] Olivier Bailleux and Yacine Boufkhad. Eﬃcient cnf encoding of boolean cardinality
constraints. In Principles and Practice of Constraint Programming–CP 2003, pages
108–122. Springer, 2003.

[13] Olivier Bailleux, Yacine Boufkhad, and Olivier Roussel. A translation of pseudo-
boolean constraints to sat. Journal on Satisﬁability, Boolean Modeling and Compu-
tation, 2:191–200, 2006.

[14] Armin Biere. Picosat essentials. JSAT, 4(2-4):75–97, 2008.

[15] Jessica Davies and Fahiem Bacchus. Postponing optimization to speed up maxsat solv-
ing. In Principles and Practice of Constraint Programming, pages 247–262. Springer,
2013.

[16] Niklas Een and Niklas S¨orensson. Minisat: A sat solver with conﬂict-clause mini-

mization. Sat, 5, 2005.

[17] Niklas E´en and Niklas S¨orensson. Translating pseudo-boolean constraints into sat.

JSAT, 2(1-4):1–26, 2006.

[18] Zhaohui Fu and Sharad Malik. On solving the partial max-sat problem. Theory and

Applications of Satisﬁability Testing-SAT 2006, pages 252–265, 2006.

[19] Ian P Gent. Arc consistency in sat. In ECAI, volume 2, pages 121–125, 2002.

[20] Ian P Gent and Peter Nightingale. A new encoding of alldiﬀerent into sat. In Proc.
3rd International Workshop on Modelling and Reformulating Constraint Satisfaction
Problems, pages 95–110, 2004.

[21] Federico Heras and Joao Marques-Silva. Read-once resolution for unsatisﬁability-
based max-sat algorithms. In Proceedings of the Twenty-Second international joint
conference on Artiﬁcial Intelligence-Volume Volume One, pages 572–577. AAAI Press,
2011.

[22] Federico Heras, Antonio Morgado, and Joao Marques-Silva. Core-guided binary search
algorithms for maximum satisﬁability. In Proceedings of the AAAI National Confer-
ence (AAAI), 2011.

[23] Kazuo Iwama and Eiji Miyano. Intractability of read-once resolution. In Structure
in Complexity Theory Conference, 1995., Proceedings of Tenth Annual IEEE, pages
29–36. IEEE, 1995.

[24] Mikol´aˇs Janota, Inˆes Lynce, Vasco Manquinho, and Joao Marques-Silva. Packup:
Tools for package upgradability solving system description. Journal on Satisﬁability,
Boolean Modeling and Computation, 8:89–94, 2012.

43

[25] Miyuki Koshimura, Tong Zhang, Hiroshi Fujita, and Ryuzo Hasegawa. Qmaxsat: A
partial max-sat solver system description. Journal on Satisﬁability, Boolean Modeling
and Computation, 8:95–100, 2012.

[26] Javier Larrosa, Federico Heras, and Simon de Givry. A logical approach to eﬃcient

max-sat solving. Artiﬁcial Intelligence, 172(2):204–233, 2008.

[27] Daniel Le Berre and Anne Parrain. The sat4j library, release 2.2 system description.

Journal on Satisﬁability, Boolean Modeling and Computation, 7:59–64, 2010.

[28] Chu Li, Felip Many`a, Nouredine Mohamedou, and Jordi Planes. Exploiting cycle
structures in max-sat. Theory and Applications of Satisﬁability Testing-SAT 2009,
pages 467–480, 2009.

[29] Chu Min Li and Anbulagan Anbulagan. Heuristics based on unit propagation for
satisﬁability problems. In Proceedings of the 15th international joint conference on
Artiﬁcal intelligence-Volume 1, pages 366–371. Morgan Kaufmann Publishers Inc.,
1997.

[30] Chu Min Li, Felip Many`a, Nouredine Ould Mohamedou, and Jordi Planes. Resolution-

based lower bounds in maxsat. Constraints, 15(4):456–484, 2010.

[31] Chu Min Li, Felip Many`a, and Jordi Planes. New inference rules for max-sat. Journal

of Artiﬁcial Intelligence Research, 30(1):321–359, 2007.

[32] Vasco Manquinho, Joao Marques-Silva, and Jordi Planes. Algorithms for weighted
boolean optimization. Theory and Applications of Satisﬁability Testing-SAT 2009,
pages 495–508, 2009.

[33] Norbert Manthey, Tobias Philipp, and Peter Steinke. A more compact translation
of pseudo-boolean constraints into cnf such that generalized arc consistency is main-
tained.
In KI 2014: Advances in Artiﬁcial Intelligence, pages 123–134. Springer,
2014.

[34] Filip Maric. Timetabling based on sat encoding: a case study, 2008.

[35] Joao Marques-Silva. The msuncore maxsat solver. SAT 2009 competitive events

booklet: preliminary version, page 151, 2009.

[36] Joao Marques-Silva and Inˆes Lynce. Towards robust cnf encodings of cardinality
constraints. Principles and Practice of Constraint Programming–CP 2007, pages 483–
497, 2007.

[37] Joao Marques-Silva and Jordi Planes. On using unsatisﬁability for solving maximum

satisﬁability. arXiv preprint arXiv:0712.1097, 2007.

[38] Joao Marques-Silva and Jordi Planes. Algorithms for maximum satisﬁability using
unsatisﬁable cores. In Proceedings of the conference on Design, automation and test
in Europe, pages 408–413. ACM, 2008.

[39] Ruben Martins, Saurabh Joshi, Vasco Manquinho, and Inˆes Lynce. Incremental cardi-
nality constraints for maxsat. In Principles and Practice of Constraint Programming,
pages 531–548. Springer, 2014.

44

[40] Paulo Matos, Jordi Planes, Florian Letombe, and Joao Marques-Silva. A max-sat

algorithm portfolio1. 2008.

[41] Elizabeth Montero, Mar´ıa-Cristina Riﬀ, and Leopoldo Altamirano. A pso algorithm
to solve a real course+ exam timetabling problem. In International Conference on
Swarm Intelligence, pages 24–1, 2001.

[42] Antonio Morgado, Carmine Dodaro, and Joao Marques-Silva. Core-guided maxsat
with soft cardinality constraints. In Principles and Practice of Constraint Program-
ming, pages 564–573. Springer, 2014.

[43] Antonio Morgado, Federico Heras, Mark Liﬃton, Jordi Planes, and Joao Marques-
Iterative and core-guided maxsat solving: A survey and assessment. Con-

Silva.
straints, 18(4):478–534, 2013.

[44] Matthew W Moskewicz, Conor F Madigan, Ying Zhao, Lintao Zhang, and Sharad
Malik. Chaﬀ: Engineering an eﬃcient sat solver. In Proceedings of the 38th annual
Design Automation Conference, pages 530–535. ACM, 2001.

[45] Fahima NADER, Mouloud KOUDIL, Karima BENATCHBA, Lotﬁ ADMANE, Said
GHAROUT, and Nacer HAMANI. Application of satisﬁability algorithms to time-
table problems. Rapport Interne LMCS, INI, 2004.

[46] G-J Nam, Fadi Aloul, Karem A. Sakallah, and Rob A. Rutenbar. A comparative
study of two boolean formulations of fpga detailed routing constraints. Computers,
IEEE Transactions on, 53(6):688–696, 2004.

[47] Nina Narodytska and Fahiem Bacchus. Maximum satisﬁability using core-guided

maxsat resolution. In AAAI, pages 2717–2723, 2014.

[48] Steven Prestwich. Variable dependency in local search: Prevention is better than
cure. In Theory and Applications of Satisﬁability Testing–SAT 2007, pages 107–120.
Springer, 2007.

[49] Steven David Prestwich. Cnf encodings. Handbook of satisﬁability, 185:75–97, 2009.

[50] Wayne Pullan. Protein structure alignment using maximum cliques and local search.

In AI 2007: Advances in Artiﬁcial Intelligence, pages 776–780. Springer, 2007.

[51] Sean Safarpour, Hratch Mangassarian, Andreas Veneris, Mark H Liﬃton, Karem
Sakallah, et al. Improved design debugging using maximum satisﬁability. In Formal
Methods in Computer Aided Design, 2007. FMCAD’07, pages 13–19. IEEE, 2007.

[52] Tian Sang, Paul Beame, and Henry Kautz. A dynamic approach to mpe and weighted
max-sat. In Proceedings of the 20th international joint conference on Artiﬁcal intel-
ligence, pages 173–179. Morgan Kaufmann Publishers Inc., 2007.

[53] Carsten Sinz. Towards an optimal cnf encoding of boolean cardinality constraints.

Principles and Practice of Constraint Programming-CP 2005, pages 827–831, 2005.

[54] Niklas Sorensson and Niklas Een. Minisat v1. 13-a sat solver with conﬂict-clause

minimization. SAT, 2005:53, 2005.

45

[55] Peter Steinke and Norbert Manthey. Pbliba c++ toolkit for encoding pseudo–boolean
constraints into cnf. TU Dresden, Dresden, Germany, Technical Report, 1:2014, 2014.

[56] Michel Vasquez and Jin-Kao Hao. A “logic-constrained” knapsack formulation and a
tabu algorithm for the daily photograph scheduling of an earth observation satellite.
Computational Optimization and Applications, 20(2):137–157, 2001.

[57] Joost P Warners. A linear-time transformation of linear inequalities into conjunctive

normal form. Information Processing Letters, 68(2):63–69, 1998.

[58] Hui Xu, Rob A Rutenbar, and Karem Sakallah. sub-sat: A formulation for relaxed
boolean satisﬁability with applications in routing. Computer-Aided Design of Inte-
grated Circuits and Systems, IEEE Transactions on, 22(6):814–820, 2003.

[59] Lin Xu, Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Satzilla: portfolio-
based algorithm selection for sat. Journal of Artiﬁcial Intelligence Research, pages
565–606, 2008.

46

