6
1
0
2

 
r
a

 

M
9
1

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
5
4
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Conditional Screening for Ultra-high Dimensional

Covariates with Survival Outcomes
Hyokyoung Grace Hong∗, Jian Kang† and Yi Li

Abstract

Identifying important biomarkers that are predictive for cancer patients’
prognosis is key in gaining better insights into the biological inﬂuences on
the disease and has become a critical component of precision medicine. The
emergence of large-scale biomedical survival studies, which typically involve
excessive number of biomarkers, has brought high demand in designing eﬃ-
cient screening tools for selecting predictive biomarkers. The vast amount of
biomarkers deﬁes any existing variable selection methods via regularization.
The recently developed variable screening methods, though powerful in many
practical setting, fail to incorporate prior information on the importance of each
biomarker and are less powerful in detecting marginally weak while jointly im-
portant signals. We propose a new conditional screening method for survival
outcome data by computing the marginal contribution of each biomarker given
priorly known biological information. This is based on the premise that some
biomarkers are known to be associated with disease outcomes a priori. Our
method possesses sure screening properties and a vanishing false selection rate.
The utility of the proposal is further conﬁrmed with extensive simulation stud-
ies and analysis of a Diﬀuse large B-cell lymphoma (DLBCL) dataset.

Keywords: Conditional screening, Cox model, Diﬀuse large B-cell lymphoma,
high-dimensional variable screening

∗Hyokyoung Grace Hong is Assistant Professor in the Department of Probability and Statis-
tics, Michigan State University, East Lansing, MI 48823. Jian Kang is Assistant Professor in the
Department of Biostatistics, University of Michigan, Ann Arbor, MI 48019. Yi Li is Professor of
Biostatistics, Director of Kidney Epidemiology and Cost Center, University of Michigan, Ann Arbor,
MI 48019.
†To whom correspondence should be addressed: jiankang@umich.edu. This research was partially
supported by a grant from NSA (H98230-15-1-0260, Hong), an NIH grant (R01MH105561, Kang)
and Chinese Natural Science Foundation (11528102, Li).

1

1

Introduction

Despite much progress made in the past two decades, many cancers do not have a

proven means of prevention or eﬀective treatments. Precision medicine that takes into

account individual susceptibility has become a valid approach to gaining better in-

sights into the biological inﬂuences on cancers, which is expected to beneﬁt millions of

cancer patients. A critical component of precision medicine lies in detecting and iden-

tifying important biomarkers that are predictive for cancer patients’ prognosis. The

emergence of large-scale biomedical survival studies, which typically involve excessive

number of biomarkers, has brought high demand in designing eﬃcient screening tools

for selecting predictive biomarkers. The presented work is motivated by a genomic

study of Diﬀuse large B-cell lymphoma (DLBCL) Rosenwald et al. (2002), with the

goal of identifying gene signatures out of 7399 genes for predicting survival among

240 DLBCL patients. The results may address whether the DLBCL patients’ survival

after chemotherapy could be regulated by the molecular features.

The recently developed variable screening methods, such as the sure independence

screening proposed by Fan and Lv (2008), have emerged as a powerful tool to solve

this problem, but their validity often hinges upon the partial faithfulness assumption,

that is, the jointly important variables are also marginally important. Consequently,

they will fail to identify the hidden variables that are jointly important but have

weak marginal associations with the outcome, resulting in poor understanding of the

molecular mechanism underlying or regulating the disease. To alleviate this problem,

Fan and Lv (2008) further suggested an iterative procedure (ISIS) by repeatedly

using the residuals from the previous iterations, which has gained much popularity.

However, the required iterations have increased the computational burden, and the

statistical properties are elusive.

On the other hand, intensive biomedical research has generated a large body

2

of biological knowledge. For example, several studies have conﬁrmed AA805575, a

Germinal-center B-cell signature gene, is relevant to DLBCL survival (Gui and Li

2005, Liu et al. 2013). Including such prior knowledge for improved accuracy in vari-

able selection has drawn much interest. Barut et al. (2016) proposed a conditional

screening (CS) approach in the framework of a generalized linear model (GLM) when

some prior knowledge on feature selection is known, and showed that the CS approach

provides a powerful means to identify jointly-informative but marginally weak asso-

ciations, and Hong et al. (2016) further proposed to integrate prior information using

data-driven approaches.

Development of high dimensional screening tools with survival outcome has been

fruitful. Some related work includes an (iterative) sure screening procedure for Cox’s

proportional hazards model (Fan et al. 2010), a marginal maximum partial likelihood

estimator (MPLE) based screening procedure (Zhao and Li 2012), a censored rank

independence screening method which is robust to outliers and applicable to a general

class of survival model (Song et al. 2014). But to the best of our knowledge, all these

methods essentially posit the partial faithfulness assumption and do not incorporate

the known prior biological information. As a result, they will be likely to suﬀer the

inability to identify marginally weak but jointly important signals.

To ﬁll the gap, we propose a new conditional screening method for the Cox pro-

portional hazards model by computing the marginal contribution of each covariate

given priorly known information. We refer to it as Cox conditional screening (CoxCS).

As opposed to the conventional marginal screening methods, our method enables the

detection of marginally weak but jointly important signals, which will have important

biological applications as shown in the data example section. Moreover, in contrast

with most screening methods that usually employ subjective thresholds for screening,

we also propose a principled cut-oﬀ to govern the screening and control the false posi-

3

tives in light of Zhao and Li (2012). This will be especially important in the presence

of hidden variables.

To demonstrate the utility of CoxCS in recovering important hidden variables,

we consider an example with 100 subjects and 1,000 covariates, where the survival

times were generated from a Cox model with baseline hazards function being 1, and

the covariates being generated from the multivariate standard normal distribution

with equal correlation 0.5. The true coeﬃcients in the Cox model are set to be
β1 = . . . = β5 = 1 and β6 = −2.5 and βj = 0 for j ∈ {7, . . . , 1000}. By design,

variable 6 is the hidden variable in that it is marginally uncorrelated with survival

times approximately; see Example 1 in Section 4 for more details. Let (cid:98)βC,j denote the

screening statistics by the CoxCS approach (deﬁned in Section 2), where C indexes
variables that are pre-included into the model. When C = ∅, the CoxCS is equivalent

to the marginal screening approach for the Cox proportional hazard model. Figure

1 summarizes the densities of the screening statistics for the hidden variable 6 and

noisy variables 10 to 1,000 for diﬀerent sets of conditional variables based on 400 sim-

ulated datasets. The results show that with a high probability the marginal screening

statistic for hidden variable 6 is much smaller than those of noisy variables. When

the conditioning set includes one truly active variable, the density plots show a clear

separation between the hidden variables and the noisy variables. When we include

more truly active variables, this separation becomes larger. Interestingly, when con-

ditional on noisy variables that are correlated with both active and hidden variables

in the model, the chance of identifying the hidden variable using CoxCS is still higher

than the marginal screening. A similar phenomenon was observed in the GLM setting

(Barut et al. 2016). This is because when such “noisy” variables are correlated with

both marginally important variables and hidden variables, they may eﬀectively func-

tion as surrogates for the active variables and conditioning on them can help detect

4

hidden variables.

Figure 1: Density of the screening statistics |(cid:98)βC,6| (red) for the hidden variable com-
pared with a mixture of densities of screening statistics |(cid:98)βC,11:1000| (blue) for the noise

variables with diﬀerent conditioning sets: (A) C = {∅} which is equivalent to marginal
screening; (B) C = {1} one truly active variables; (C) C = {1, 2} two truly active
variables; (D) C = {7, . . . , 10} four noisy variables.

The theory of conditional screening for GLM has been established by Barut et al.

(2016). But its extension to the survival context is challenging and elusive, calling

for new techniques. To this end, we propose two new functional operators on ran-

dom variables to characterize their linear associations given other random variables:

the conditional linear expectation and the conditional linear covariance. Both are

critical to formulate the regularity conditions for the population level properties of

CoxCS with statistically meaningful interpretations, and facilitate the development

of theory for conditional screening approaches in general settings. A similar concept

of the conditional linear covariance has been introduced by Barut et al. (2016), but

it can not be used for the survival outcome data. In summary, the proposed method

is computationally eﬃcient, adapts to sparse and weak signals, enjoys the good the-

oretical properties under weak regularity conditions, and works robustly in a variety

of settings to identify hidden variables.

The remaining of this paper is organized as follows. In Section 2, we review the Cox

proportional hazard model and present CoxCS approach with some alternatives. In

5

0.00.51.01.52.00123456(A) C={f}b^C, jDensity0.00.51.01.52.00123456(B) C={1}b^C, jDensity0.00.51.01.52.00123456(C) C={1, 2}b^C, jDensity0.00.51.01.52.00123456(D) C={7, …, 10}b^C, jDensity|b^C, 6||b^C, 11:1000|Section 3, we list the regularity conditions and establish the sure screening properties.

In Section 4, we further conduct simulation studies to compare our method with the

major competing methods under under a number of scenarios. In Section 4, we apply

our method to study the DLBCL data. We conclude with a a brief discussion on the

future work in Section 5.

2 Model

2.1 The Cox Proportional Hazard Model

Suppose we have n observations with p covariates. Let i and j respectively in-

dex subjects and covariates. Denote by Zi,j covariate j for subject i, write Zi =

(Zi,1, . . . , Zi,p)T. Let Ti be the underlying survival time and Ci be the censoring time.
We observe Xi = min{Ti, Ci}, and δi = I[Ti ≤ Ci], where I(·) is the indicator func-
tion. Assume that there exists τ > 0, such that P(Xi > τ | Zi) = 0 and assume that

the event time Ti and the censoring time Ci are independent. Suppose Ti follows a

Cox proportional hazards model

λ(t; Zi) = λ0(t) exp(αTZi),

(1)

where λ0(t) is an-unspeciﬁed baseline hazard and α = (α1, . . . , αp)T is the true-

coeﬃcient. Let Λ0(t) =(cid:82) t

0 λ0(s)ds be the cumulative hazard function. Suppose there

is a set of covariates that are known a priori to be related to the survival outcome.
Denote by C the indices of these covariates. Let q = |C| be the number of covariates
in C. Write Zi,C = (Zi,j, j ∈ C)T, Zi,−C = (Zi,j, j /∈ C)T, αC = (αj, j ∈ C)T and
α−C = (αj, j /∈ C)T. Note that in our problem, C is known but both αC and α−C are

unknown. Then the true hazard function in (1) is equivalent to

λ(t; Zi) = λ0(t) exp(αTC Zi,C + αT−CZi,−C),

(2)

To estimate αC and α−C, we introduce the independent counting process Ni(t) =

6

I(Xi ≤ t, δi = 1) and the at-risk process Yi(t) = I[Xi ≥ t]. When p is small, we

can obtain the partial likelihood estimator (cid:98)α = ((cid:98)αTC ,(cid:98)αT−C)T by solving the estimation

equation U(α) = 0p with U(α) = (U1(α), . . . , Up(α))T and

(cid:90) τ

0

(cid:40)
Zi,j − S(1)
j (t, α)
S(0)
j (t, α)

(cid:41)

dNi(t)

,

with

Uj(α) =

S(m)
j

(t, α) =

n(cid:88)
n(cid:88)

i=1

1
n

i=1

(3)

(4)

(6)

(7)

(8)

Z m

i,jYi(t) exp(αTC Zi,C + αT−CZi,−C),

for m ∈ {0, 1, 2, . . . ,}. When p > n, it is computationally and theoretically infeasible

to directly solve the equation (6). By imposing sparsity on the coeﬃcients, one may

maximize the penalized partial likelihood to obtain solutions. However, when p >> n,

we need to employ a variable screening procedure ﬁrst before performing regularized

regression. We propose a new conditional screening procedure in the next section.

2.2 Cox Conditional Screening

We ﬁt the marginal Cox regression by including the known covariates in C. Speciﬁ-
cally, for j /∈ C, we have the following marginal Cox regression model

from which the maximum partial likelihood estimation equation ((cid:98)β

λj(t; Zi) = λj,0(t) exp(βTC Zi,C + βZi,j),

(5)

C,j,(cid:98)βj)T can be

T

obtained. It is given by the solution of the following equation:
Vj(βC, β) = [Vj,k(βC, β), k ∈ C ∪ {j}]T = 0q+1,
(cid:41)

with

(cid:90) τ

n(cid:88)

i=1

0

(cid:40)
Zi,k − R(1)
R(0)

j,k (βC, β, t)
j,k (βC, β, t)

dNi(t)

,

Vj,k(βC, β) =

and

R(m)

j,k (βC, β, t) =

n(cid:88)

i=1

1
n

i,kYi(t) exp(βTC Zi,C + βZi,j),
Z m

7

for k ∈ C ∪ {j} and m ∈ {0, 1, 2, . . .}. For a given threshold γ > 0. The selected
index set in addition to set C is given by

(cid:110)

(cid:111)

(cid:99)M−C =

j /∈ C : |(cid:98)βj| ≥ γ

.

(9)

Namely, we recruit variables with large additional contribution given ZC. We refer to

this method as Cox conditional screening (CoxCS).

3 Theoretical Results

We establish the theoretical properties of the proposed methods by introducing a few

new deﬁnitions along with the basic properties.

3.1 Deﬁnitions and Basic Properties

Let (Ω,F, P) be the probability space for all random variables introduced in this
paper, where Ω is the sample space, F is the σ-algebra as the set of events and P is the
probability measure. Let Rd be a d-dimensional Euclidean vector space, for positive
integer d. Denote by E[•], Var[•] and Cov[•,•] the commonly used expectation,

variance and covariance operator in the probability theory, respectively. For any
d ≥ 1, any random variable ξ : Ω → Rd and any operator A, denote by A[• | ξ]
conditional A of • given ξ. For any vector a = (a1, . . . , ap) ∈ Rp, let aC = (aj, j ∈ C)T
be the sub vector where all its elements are indexed in C. Let (cid:107)a(cid:107)d = d
j be
the L-d norm for any vector a ∈ Rp. For a sequence of random variables indexed by
{ξn}, ξn = op(1) if and only if for any 1 > 0 and 2 > 0, there exists N such that for
any n > N P[|ξn| > 1] < 2.

(cid:113)(cid:80)p

j=1 |a|d

For simplicity, let T , C, X, Y (t), Zj, Z and δ represent Ti, Ci, Xi, Yi(t), Zi,j,
Zi and δi respectively, by removing the subject index i. Let ST (t | Z) and SC(t)

represent the survival functions for the event time T and censored time C. Let
FT (t | Z) = 1 − ST (t | Z).

8

Deﬁnition 1. Let M−C = {j /∈ C, αj (cid:54)= 0} and w = (cid:80)

j /∈C I[αj (cid:54)= 0] be the true
set of non-zero coeﬃcients and its cardinality in model (1), aside from the important

predictors known a priori.

To study the asymptotic property of ((cid:98)β

C,j,(cid:98)βj)T, deﬁne the population level quan-

T

tity as follows:

Deﬁnition 2. Let (βTC,j, βj)T be the solution of the following equations

vj(βC, β) = [vj,k(βC, β), k ∈ C ∪ {j}]T = 0q+1,
(cid:35)

(cid:34)

(cid:90) τ

k (t) − r(1)
j,k (t, βC, β)
s(1)
r(0)
j,k (t, βC, β)

0

vj,k(βC, β) =

s(0)
k (t)

dt,

(t) = E [Z m

k dN (t)] and r(m)

j,k (t, βC, β) = E[R(m)

j,k (t, βC, β)].

with

where s(m)

k

Deﬁnition 3. Let βC,0 be the solution of the following equations

vC(βC) = [vj,k(βC, 0), k ∈ C]T = 0q.

Proposition 1. vj(βC,0, 0) = 0q+1 if and only if vj,j(βC,0, 0) = 0, for all j ∈ C.

(10)

(11)

(12)

To understand the intuition of the population level properties for the Cox con-

ditional screening, we need to deﬁne a conditional linear expectation. A similar

concept has been used to study the conditional sure independence screening (CSIS)

in the GLM setting by Barut et al. (2016). We provide a formal deﬁnition here.

Deﬁnition 4. For two random variables ζ : Ω → Rd and ξ : Ω → Rp. The conditional

linear expectation of ζ given ξ is deﬁned as

E∗(ζ | ξ) = E[ζ] + AT{ξ − E(ξ)},

(13)

where A = argminB∈Rd×Rp E[(ζ − E[ζ] − BT{ξ − E(ξ)})2 | ξ]. Also, deﬁne notation
E∗(ζ) = E(ζ).

9

The basic properties of the conditional linear expectation are listed in the following

proposition.

Proposition 2. Let ζ, ζ1, ζ2 and ξ be any four random variables in the probability
space (Ω,F, P). The following properties hold for the conditional linear expectation
E∗[• | ξ] given ξ:

1. Closed form: E∗(ζ | ξ) = E[ζ] + Cov(ζ, ξ)Var[ξ]−1{ξ − E(ξ)}.

2. Stability: E∗[ξ | ξ] = ξ.

3. Linearity: E∗[A1ζ1 + A2ζ2 | ξ] = A1E∗[ζ1 | ξ] + A2E∗[ζ2 | ξ], where A1 and

A2 are two matrices that are compatible with the equation.

4. Law of total expectation: E∗[E∗(ζ | ξ)] = E[E∗(ζ | ξ)] = E[ζ].

Remark 1. In general, E∗(ζ | ξ) (cid:54)= E(ζ | ξ). Also, ζ and ξ are independent does not
imply E∗(ζ | ξ) = 0, unless ζ and ξ are jointly normally distributed.
Deﬁnition 5. For any random variables ζ1 : Ω → Rd1, ζ2 : Ω → Rd2 and ξ : Ω → Rp.
The conditional linear covariance between ζ1 and ζ2 given ξ is deﬁned as

Cov∗(ζ1, ζ2 | ξ) = E∗[{ζ1 − E∗(ζ1 | ξ)}{ζ2 − E∗(ζ2 | ξ)} | ξ].

(14)

Remark 2. By Proposition 2, we can easily verify the following properties.

Proposition 3. The conditional linear covariance deﬁned in deﬁnition 5 has the

following properties

1. Linear independence and linear zero correlation:

Cov∗(ζ1, ζ2 | ξ) = 0

⇔

E∗(ζ1ζ2 | ξ) = E∗(ζ1 | ξ)E∗(ζ2 | ξ).

2. Expectation of conditional linear covariance:

E[Cov∗(ζ1, ζ2 | ξ)] = Cov(ζ1, ζ2) − Cov(ζ1, ξ)Var(ξ)−1Cov(ξ, ζ2).

10

3. Sign: for any increasing function h(·) : R → R and random variable η : Ω → R,

then

Deﬁnition 6. Deﬁne

Cov∗(h(η), η | ξ) ≥ 0.

(cid:88)

vj(βC, β) = vj,j(βC, β) +

where vector aC = [ak, k ∈ C]T such that E∗[Zj | ZC] =(cid:80)

k∈C

akvj,k(βC, β),

k∈C akZk.

Proposition 4. vj,j(βC,0, 0) = 0 if and only if vj(βC,0, 0) = 0.

3.2 Regularity Conditions

We list all conditions for the theoretical results.

Condition 1. For each j /∈ C and k ∈ C ∪ {j}, there exists a neighborhood of
(βTC,j, βj)T, which is deﬁned as

Bj = {(βTC , β)T : (cid:107)(βTC , βj)T − (βTC,j, βj)T(cid:107)1 < δj},

with

δj > 0,

such that for each τ < ∞,

1. For m = 0, 1,

sup

t∈[0,τ ],(βTC ,β)T∈Bj

in probability as n → ∞.

(cid:107)R(m)

j,k (βC, β) − r(m)

j,k (βC, β)(cid:107)2 → 0,

2. There exists a constant L > 0 such that

(cid:20)

L = min
j /∈C

inf

t∈[0,τ ],(βTC ,β)T∈Bj

(cid:21)
j,k (βC, β, t)}
{r(0)

.

Of note, {r(0)

j,k (βC, β, t)} does not depend on k. Let δ = maxj /∈C δj.

11

Condition 2. The covariates Zj’s satisfy the following conditions

1. For j ∈ {1, . . . , p}, E[Zj] = 0 and there exists a constant K0 such that P(Zj >

K0) = 0.

2. Zj is a time constant variable, for all j.

3. All Zj’s, j ∈ M−C are independent of all Zk’s, k /∈ M−C given ZC.

4. For constant c1 > 0 and κ < 1/2,

|E[Cov∗(Zj, P[δ = 1 | Z] | ZC)])| ≥ c1n−κ.

min
j∈M−C

Condition 3. There exists a constant K1 such that

(cid:107)α(cid:107)1 < K1 and (cid:107)(βTC,j, βj)T(cid:107)1 < K1,

for all p > 0.

Condition 4. For all j /∈ C, there exists a constant M > 0 such that

M(cid:107)((cid:98)β

C,j,(cid:98)βj)T − βTC,j, βj)T(cid:107)2 ≤ (cid:107)Vj((cid:98)βC,j,(cid:98)βj) − Vj(βC,j, βj)(cid:107)2.

T

3.3 Properties on Population Level

Lemma 1. The solution of vj(βC, β) = 0q+1 and the solution of vC(βC) = 0q are
both unique, for any j /∈ C.

Theorem 1. Suppose Condition 2 hold, βj = 0 if and only if αj = 0 for all j /∈ C.

Theorem 2. Suppose Condition 2 holds. There exist constants c2 > 0 and κ < 1/2

such that

|βj| ≥ c2n−κ.

min
j∈M−C

12

3.4 Properties on Sample Level

Theorem 3. Suppose Conditions 1–4 hold. For any 1 > 0 and any 2 > 0, there

exits positive constants c3, c4 and integer N such that for any n > N ,

1. For any 0 < κ < 1/2,

(cid:20)

P

max
j∈M−C

|(cid:98)βj − βj| >

(cid:21)

(n−κ − 1)

c2
2

≤ 2w(q + 1) exp(−c3n1−2κ) + 2.

where w is the size of M−C, q is the size of C and c2 is the same value in

Theorem 2 and c3 does not dependent on 1, 2 and κ, but N depends on 1 and

2.

2. If γn = c4n−κ, where κ is the same number in Condition 2, then

≥ 1 − 2w(q + 1) exp(−c3n1−2κ) − 2.

(15)

(cid:20)

P

min
j∈M−C

(cid:21)

|(cid:98)βj| > γn

where c4 does not depend on 1, 2 and κ, thus

(cid:104)M−C ⊆ (cid:99)M−C

(cid:105)

lim
n→∞ P

= 1.

(16)

3.5 Controlling the False Discover Rate

Deﬁne the information matrix

Ij(βC, βj) = −

,

(17)

k,k(cid:48)∈C∪{j}

which is of q + 1 dimension. Denote(cid:98)σ2
of (cid:98)βj. For a given threshold γ > 0, we can have a diﬀerent way to select the index
(cid:40)

q+1,q+1 be the variance estimate

which is given by

(cid:99)M∗

−C =

(18)

∂βk(cid:48)

(cid:19)
(cid:18) ∂Vj,k(βC, βj)
j = [Ij(βC,j,(cid:98)βj)]−1
(cid:41)
|(cid:98)βj|(cid:98)σj

j /∈ C :

≥ γ

,

as suggested by Zhao and Li (2012). We refer to (18) as “CS-Wald”.

13

Another alternative to construct the screening statistics, which is also scale free,

(cid:90) τ

(cid:96)(βC, β) =

i=1

0

Suppose ((cid:98)β

T

is to utilize the partial log likelihood ratio statistic. Speciﬁcally,

(cid:16)

(cid:110)
βTC Zi,C + βZi,j − log

n(cid:88)
C,j,(cid:98)βj)T maximizes (19) for a given j. Then, for a given threshold

dNi(t)

R(0)

j,k (βC, β, t)

(cid:111)

.

(19)

(cid:17)

γ > 0, the index set can be chosen by considering the following likelihood ratio

statistic.

(cid:110)

(cid:99)M∗

−C =

j /∈ C : (cid:96)( ˆβC,j, ˆβj) − (cid:96)( ˆβC,0, β = 0) ≥ γ

(cid:111)

,

(20)

where ˆβC,0 maximizes (cid:96)(βC, 0). Hereafter (20) will be referred to as “CS-PLIK”.

4 Simulation Studies

The utility of the proposed methods was evaluated via extensive simulations. De-

note by CS-MPLE, a version of CoxCS that is based on the criteria of (9). For

completeness, we considered two other variations of CoxCS, namely, CS-PLIK and

CS-Wald. The ﬁnite sample performance of the proposed methods was compared

with the following marginal screening methods designed for the survival data.

• CRIS: censored rank independence screening proposed by Song et al. (2014).

• CORS: correlation screening, which is an extension of sure independence screen-

ing to the censored outcome data by using inverse probability weighting; see Song

et al. (2014).

• PSIS-Wald: Wald test based on the marginal Cox model ﬁtted on each covariate;

see Zhao and Li (2012).

• PSIS-PLIK: partial likelihood ratio test based on the marginal Cox model ﬁtted

on each covariate, which is asymptotically equivalent to Zhao and Li (2012).

14

We illustrated our methods and compared them with the competing methods on

data simulated as below.

Example 1. The survival time was generated from a Cox model with baseline hazards

function being set to be 1, i.e.,

λ(t | Z) = exp(βTZ),

where Z were generated from the standard normal distribution with equal correlation

0.5 and β = (1T

5 ,−2.5, 0T

p−6)T.

Example 2. The survival time was generated from a Cox model with baseline hazards

function being set to be 1, i.e.,

λ(t | Z) = exp(−1 + βTZ),

where β = (10, 0T

p−2, 1)T and all covariates were generated from the independent

standard normal distribution.
Example 3. The same as Example 2 except that the ﬁrst p − 1 covariates were gen-

erated from the multivariate standard normal distribution with an equal correlation

of 0.9.

The simulated data examples were designed in such a way that variables Z6 in

Example 1 and Zp in Example in 3 possessed marginally weak but conditionally strong

signals, which made marginal screening approaches not ideal for identifying them. For

the GLM, Barut et al. (2016) provided a similar simulation design in the context of

non-censored regression. Figure 3 depicted the distribution of the absolute correlation

between the survival time and the covariate variables, where uncensored data were

used to compute the marginal correlation between the event time and the covariate

using an inverse probability weighting (Song et al. 2014). Clearly, in Example 1

the marginal signal strength of Z6 was weaker than most noisy (inactive) variables

15

Figure 2: Absolute correlation of the survival time and the covariate variables. The
blue short-dashed lines (·····) represents the distribution of the inactive variables; the
green long-dashed (– – –) lines for the active variables with relatively strong signals;
the red solid lines (——) for the hidden active variable.

16

0.00.20.40.60.81.00123456Example 1 (CR=20%)Absolute correlationDensity0.00.20.40.60.81.00123456Example 2 (CR=20%)Absolute correlationDensity0.00.20.40.60.81.00123456Example 3 (CR=20%)Absolute correlationDensity0.00.20.40.60.81.00123456Example 1 (CR=60%)Absolute correlationDensity0.00.20.40.60.81.00123456Example 2 (CR=60%)Absolute correlationDensity0.00.20.40.60.81.00123456Example 3 (CR=60%)Absolute correlationDensity(Z7 − Z1000), while the marginal signal strength of Z1000 in Examples 2 and 3 was

similar or even lower than most noisy variables. The marginal correlation between

the survival time and each variable was getting weaker with heavier censoring.

In all these examples, the censoring times Ci were independently generated from

a uniform distribution U [0, c], with c chosen to give approximately 20% and 60% of

censoring proportions. We set n = 100 and varied p from 1000 (high-dimensional)

to 10000 (ultrahigh-dimensional). For each conﬁguration, a total of 400 simulated

datasets were generated.

We considered two metrics to compare the performance between diﬀerent methods:

the minimum model size (MMS) which is the minimum number of variables that need

to be selected in order to include all active variables, and the true positive rate (TPR)

which is the proportion of active variables that are included in the ﬁrst n selected

variables. Hence, a method with small MMS and large TPR can be more eﬃcient

to discover true signals. To have a fair comparison, we added one (the number of

conditioning variable in our examples) to MMS for the proposed methods (CS-MPLE,

CS-Wald and CS-PLIK). In practice, identifying conditional sets normally requires

some prior biological information. In our simulations, we simply choose the covariate

Z1 as the conditioning variable. In practice, we propose to choose the variable with

the highest marginal signal strength as the conditioning variable, which can be a

practical solution in the absence of prior biological knowledge.
In Examples 1–3,
C = {1} is the true conditioning set, the signal of which was strong enough to be

easily selected by other marginal screening methods.

Table 1 demonstrated the superiority of our proposed methods under the diﬃcult

scenarios as reﬂected in Examples 1–3.

Indeed, the proposed methods drastically

reduced MMS in Examples 1–3 compared to the marginal approaches. Moreover, we

noted that all the marginal screening methods had tremendous diﬃculties in identi-

17

Figure 3: Median number of active variables that are included in the model with
diﬀerent thresholds by diﬀerent methods

18

02004006008001000123456Example 1 (CR = 20%, p = 1000)Number of Variables SelectedNumber of Active VariablesCS−MPLECS−WaldCS−PLIKPSIS−WaldPSIS−PLIKCORSCRIS020040060080010001.01.21.41.61.82.0Example 2 (CR = 20%, p = 1000)Number of Variables SelectedNumber of Active Variables020040060080010001.01.21.41.61.82.0Example 3 (CR = 20%, p = 1000)Number of Variables SelectedNumber of Active Variables02004006008001000123456Example 1 (CR = 60%, p = 1000)Number of Variables SelectedNumber of Active Variables020040060080010001.01.21.41.61.82.0Example 2 (CR = 60%, p = 1000)Number of Variables SelectedNumber of Active Variables020040060080010001.01.21.41.61.82.0Example 3 (CR = 60%, p = 1000)Number of Variables SelectedNumber of Active Variables0200040006000800010000123456Example 1 (CR = 20%, p = 10000)Number of Variables SelectedNumber of Active Variables02000400060008000100001.01.21.41.61.82.0Example 2 (CR = 20%, p = 10000)Number of Variables SelectedNumber of Active Variables02000400060008000100001.01.21.41.61.82.0Example 3 (CR = 20%, p = 10000)Number of Variables SelectedNumber of Active Variables0200040006000800010000123456Example 1 (CR = 60%, p = 10000)Number of Variables SelectedNumber of Active Variables02000400060008000100001.01.21.41.61.82.0Example 2 (CR = 60%, p = 10000)Number of Variables SelectedNumber of Active Variables02000400060008000100001.01.21.41.61.82.0Example 3 (CR = 60%, p = 10000)Number of Variables SelectedNumber of Active Variablesfying Z6 in Example 1 and Z1000 in Examples 2–3. Indeed, these variables had the

lowest priorities to be included by using the competing methods. On the other hand,

the proposed approaches greatly outperformed the marginal approaches, as the condi-

tioning approaches eﬀectively boosted the signal strengths of the “hidden” variables.

The performance by CS-MPLE, CS-Wald and CS-PLIK are quite similar in all the

cases in Examples 1 and 2. In Example 3, there is a very high correlation among the

covariate variables, CS-MPLE has a slightly larger MMS compared to the CS-Wald

and CS-PLIK which well control the false discover rate in this cases.

5 Application

We illustrated the practical utility of the proposed method by applying it to analyze

the diﬀuse large B-cell lymphoma (DLBCL) dataset of Rosenwald et al. (2002). The

dataset, which was originally collected for identifying gene signatures relevant to the

patient survival from time of chemotherapy, included a total of 240 DLBCL patients

with 138 deaths observed during the followup and a median survival time of 2.8 years.

Along with the clinical outcomes, the expression levels of 7,399 genes were available

for analysis. In our subsequent analysis, each gene expression was standardized to

have mean zero and variance 1.

To facilitate the use of our method, we identiﬁed the conditional set by resorting to

the medical literature. As gene AA805575, a Germinal-center B-cell signature gene,

has been known to be predictive to DCBCL patients’ survival in the literature (Liu

et al. 2013, Gui and Li 2005), we used it as the conditional variable in our proposed

procedure. For comparisons, we also analyzed the same data using various compet-

ing methods introduced in the simulation section and computed the corresponding

concordance statistics (C-statistics) (Uno et al. 2011).

Speciﬁcally, we randomly assigned 160 patients to the training set and 80 patients

19

Method

(n, p) = (100, 1000)
MMS

TPR

(n, p) = (100, 10000)
MMS

TPR

1000.0 (3.0)

944.0 (168.2)

CRIS
CORS
Example 1 PSIS-PLIK 1000.0 (0.0)
CR ≈ 20% PSIS-Wald
1000.0 (0.0)
CS-PLIK
CS-Wald
CS-MPLE

152.5 (272.2)
154.5 (274.5)
143.0 (249.0)

926.5 (151.8)
898.0 (152.2)

CRIS
CORS
Example 1 PSIS-PLIK 1000.0 (2.0)
CR ≈ 60% PSIS-Wald
1000.0 (2.0)
CS-PLIK
CS-Wald
CS-MPLE

227.0 (351.2)
227.5 (348.2)
228.5 (320.5)

CRIS
CORS
Example 2 PSIS-PLIK
CR ≈ 20% PSIS-Wald
CS-PLIK
CS-Wald
CS-MPLE

CRIS
CORS
Example 2 PSIS-PLIK
CR ≈ 60% PSIS-Wald
CS-PLIK
CS-Wald
CS-MPLE

262.5 (401.8)
490.5 (510.8)
318.0 (492.8)
318.5 (494.2)

2.0 (0.0)
2.0 (0.0)
2.0 (0.0)

399.5 (478.0)
603.5 (390.5)
325.0 (498.5)
322.0 (501.0)

2.0 (0.0)
2.0 (0.0)
2.0 (0.0)

1000.0 (0.0)
CRIS
1000.0 (0.0)
CORS
Example 3 PSIS-PLIK 1000.0 (0.0)
CR ≈ 20% PSIS-Wald
1000.0 (0.0)
CS-PLIK
2.0 (0.0)
2.0 (0.0)
CS-Wald
CS-MPLE
3.0 (4.0)

783.0 (463.8)

1000.0 (0.0)

CRIS
CORS
Example 3 PSIS-PLIK 1000.0 (0.0)
CR ≈ 60% PSIS-Wald
1000.0 (0.0)
2.0 (0.0)
CS-PLIK
CS-Wald
2.0 (0.0)
20.0 (55.2)
CS-MPLE

0.50 (0.17)
0.33 (0.33)
0.67 (0.17)
0.67 (0.17)
0.83 (0.17)
0.83 (0.17)
0.83 (0.17)

0.33 (0.17)
0.00 (0.17)
0.67 (0.17)
0.67 (0.17)
0.83 (0.17)
0.83 (0.17)
0.83 (0.17)

0.50 (0.00)
0.50 (0.00)
0.50 (0.00)
0.50 (0.00)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.00 (0.00)
0.50 (0.00)
0.50 (0.00)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.50 (0.50)
0.50 (0.00)
0.50 (0.50)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.00 (0.50)
0.50 (0.00)
0.00 (0.00)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

9995.0 (37.0)
9466.0 (1101.8)

10000.0 (2.2)
10000.0 (2.2)

1322.0 (2253.8)
1286.5 (2287.0)
1321.0 (2305.8)

9429.0 (1405.0)
8976.0 (1610.0)
9999.0 (17.0)
9999.0 (17.0)
2383.5 (3331.5)
2403.5 (3233.2)
2229.5 (3046.8)

2871.0 (4314.0)
4878.5 (5099.8)
3777.0 (5690.8)
3786.5 (5707.8)

2.0 (0.0)
2.0 (0.0)
2.0 (0.0)

3601.0 (4894.2)
5988.0 (4353.0)
3942.5 (5679.5)
3915.5 (5679.5)

2.0 (1.0)
2.0 (2.0)
2.0 (4.0)

10000.0 (0.0)
10000.0 (0.0)
10000.0 (0.0)
10000.0 (0.0)
2.0 (0.0)
2.0 (0.0)
7.5 (33.0)

10000.0 (0.0)

7967.0 (4972.2)

10000.0 (0.0)
10000.0 (0.0)
2.0 (0.0)
2.0 (0.0)

161.5 (553.5)

0.17 (0.17)
0.00 (0.17)
0.33 (0.17)
0.33 (0.17)
0.67 (0.17)
0.67 (0.17)
0.50 (0.17)

0.00 (0.17)
0.00 (0.00)
0.33 (0.17)
0.33 (0.17)
0.50 (0.33)
0.50 (0.33)
0.50 (0.17)

0.50 (0.00)
0.50 (0.00)
0.50 (0.00)
0.50 (0.00)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.00 (0.00)
0.50 (0.00)
0.50 (0.00)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.00 (0.00)
0.50 (0.00)
0.00 (0.50)
1.00 (0.00)
1.00 (0.00)
1.00 (0.00)

0.50 (0.00)
0.00 (0.00)
0.50 (0.00)
0.00 (0.00)
1.00 (0.00)
1.00 (0.00)
0.50 (0.50)

Table 1: Median minimum model size (MMS) and median true positive rates (TPR)
along with their corresponding IQRs (in the parentheses) based on 400 simulated
data sets.

20

to the testing set, while maintaining the censoring proportion roughly the same in

each set. For each split, we applied each method to select top 31(= 160/ log(160))

variables using the training set. LASSO was performed subsequently for reﬁned

modeling, with the tuning parameter selected by the 10-fold cross-validation. The

risk score for each subject was obtained by using the ﬁnal model selected by LASSO

in the training dataset and the C-statistics was obtained in the testing dataset. A

total of 100 splits were made and the average C-statistics and the model size (MS)

were reported in Table 2. By the criterion of C-statistics, the proposed method seemed

to have more predictive power.

CRIS

CORS

PSIS-PLIK PSIS-Wald

C-statistics
Model size

0.54 (0.21)
14.41 (3.00)

0.58 (0.20)
6.83 (3.70)

0.58 (0.19)
15.22 (2.93)

0.55 (0.20)
15.65 (2.89)

CS-MPLE

CS-PLIK

CS-Wald

C-statistics
Model size

0.63 (0.18)
16.74 (3.26)

0.63 (0.18)
15.90 (3.01)

0.62 (0.19)
16.28 (3.41)

Table 2: Summary of C-statistics and the model size for diﬀerent methods.

Our further scientiﬁc investigation focused on identifying the relevant genes by

utilizing the full dataset. Applying our proposed method, we selected top 44 (=

240/ log(240)) genes, before using LASSO to reach the ﬁnal list. It follows that CS-

MPLE, CS-PLIK and CS-Wald selected 20, 16 and 16 genes, respectively. Among

the 22 uniquely selected genes by either of them, 14 genes were overlapped and were

reported in Table 3. Twelve genes among these 22 genes belong to Lymph-node sig-

nature group, proliferation signature group, and Germinal-center B-cell group deﬁned

by Rosenwald et al. (2002). We observed that 13 of these 22 genes were chosen by

at least one of CRIS, CORS, PSIS-PLIK, and PSIS-Wald. On the other hand, gene

AB007866, Z50115, S78085, U00238, AL050283, J03040, U50196, and AA830781, and

M81695 were only identiﬁed by using our methods.

21

In fact, only a few studies have suggested an important role of M81695 (Deb and

Reddy 2003, Chow et al. 2001, Mikovits et al. 2001, Stewart and Schuh 2000) or

AA830781 (Li and Luan 2005, Binder and Schumacher 2009, Schifano et al. 2010)

in predicting DLBCL survival. Indeed, as the marginal correlation between M81695

and the survival time and between AA830781 and the survival time are markedly

low at 0.008 and 0.097, respectively. Thus, it is highly likely to be missed by using

the conventional screening approaches. Schifano et al. (2010) also commented their

majorization-minimization algorithm selected AA830781 because of coexpression or

correlation with other relevant genes. A more detailed investigation of its functions

in the context of a broader class of blood cancers, including lymphoma, may shed

light on preventing, treating and controlling the lethal blood cancers.

22

d
l
a

W
-
S
C

K
I
L
P
-
S
C

E
L
P
M
-
S
C

n
o
i
t
p

i
r
c
s
e
D

e
r
u
t
a
n
g
i

S

D

I

k
n
a
B
n
e
G

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

(cid:88)

2

r
o
t
c
a
f

n
o
i
t
a
i
t
i

n

i

n
o
i
t
a
l
s
n
a
r
t

c
i
t
o
y
r
a
k
u
e

e
t
a
h
p
s
o
h
p
o
r
y
p

l
y
s
o
b

i
r
o
h
p
s
o
h
p

e
s
a
r
e
f
s
n
a
r
t
o
d
m
a

i

1

e
m
a
r
f

g
n

i

d
a
e
r

n
e
p
o

4
1

e
m
o
s
o
m
o
r
h
c

2

h
t
a
e
d

l
l
e
c

d
e
m
m
a
r
g
o
r
p

1

e
s
a
d

i
t
p
e
p
o
g
i
l
o

t
e
m
h
t

i

A
N
R
m
n

i
e
t
o
r
p

a
D
k

2
8

c
i

d

i
c
a

7

e
s
a
n

i
k

t
n
e
d
n
e
p
e
d
-
n

i
l
c
y
c

t
c
u
d
o
r
p

e
n
e
g

6
0
4
0
A
A
K

I

1

n

i
t
p
e
s

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

n
o
i
t
a
r
e
f
i
l
o
r
P

4
5
0
5
2
C
L

3
4
7
7
7
X

2
5
5
5
1
U

6
6
8
7
0
0
B
A

1
6
1
2
1
0
C
B

9
5
1
4
3
1
F
A

5
1
1
0
5
Z

5
8
0
8
7
S

6
3
5
9
2
M

8
3
2
0
0
U

e
n
e
g
o
c
n
o

s
i
s
i
r
c

t
s
a
l

b

d

i
o
h
p
m
y
l

e
s
a
n

i
k
-
3
-
e
d

i
t
i
s
o
n

i
o
h
p
s
o
h
p

n

i
e
t
o
r
p

4
8
0
0
A
A
K

I

)
e
k
i
l
-
I

n

i
l
c
i
c
s
a
f
(

2

r
o
t
c
a
f

c
ﬁ

i
c
e
p
s

t
s
a
l
b
o
e
t
s
o

r
o
s
r
u
c
e
r
p

n

i
l

u
b
o
l
g

g
n

i

d
n

i

b
-
e
n

i
x
o
r
y
h
t

X
a
h
p

l
a

,

n

i
r
g
e
t
n

i

n

i
e
t
o
r
p

d
e
t
e
r
c
e
s

e
s
a
n

i
k

e
n

i
s
o
n
e
d
a

e
d
o
n

h
p
m
y
L

e
d
o
n

h
p
m
y
L

3
1

y
t
i
c
i

n
e
g
i
r
o
m
u
t

f
o

n
o
i
s
s
e
r
p
p
u
s

n
o
i
t
a
r
e
f
i
l
o
r
P

s
T
S
E

5
9
6
1
8
M

6
6
6
3
1
D

0
4
0
3
0
J

6
9
1
0
5
U

8
1
9
8
2
U

6
4
7
1
2
7
A
A

1
8
7
0
3
8
A
A

1
8
4
7
2
1
F
A

6
0
9
1
6
M

3
4
0
2
4
D

3

e
s
a
e
t
o
r
p

c
ﬁ

i
c
e
p
s
-
O
M
U
S
/
n

i
r
t
n
e
s

n
o
i
t
a
r
e
f
i
l
o
r
P

4
2
2
7
4
A
o
t

r
a
l
i

m

i
s

y
l
k
a
e

W

,
s
T
S
E

l
l
e
c
-
B
-
r
e
t
n
e
c
-
l
a
n
m
r
e
G

i

3
8
2
0
5
0
L
A

3
4
5
9
2
1
F
B

23

.

d
l
a

W
-
S
C
d
n
a
K
I
L
P
-
S
C

,

E
L
P
M
-
S
C
y
b

d
e
t
c
e
l
e
s

e
r
a

t
a
h
t

s
e
n
e
g

f
o

n
o
s
i
r
a
p
m
o
c
A

:
3

e
l

b
a
T

6 Discussion

In this paper, we have proposed a new conditional variable screening approach for

the Cox proportional hazard model with ultra-high dimensional covariates. The pro-

posed partial likelihood based conditional screening approaches are extremely com-

putationally eﬃcient, with a solid theoretical foundation. Our method and theory

are extensions of the conditional sure independence screening (CSIS) Barut et al.

(2016), which is designed for the GLM. In the development of theory, we introduce

the new concept of the conditional linear covariance for the ﬁrst time, which is useful

to specify the regularity conditions for the model identiﬁability and the sure screening

property. This also provides a solid building block for a general theoretical framework

of conditional variable screening in the context of other semi-parametric models, such

as the partially linear single-index model.

We have mainly focused on studying the theoretical properties of CS-MPLE, which

extends the work of Barut et al. (2016) in the GLM setting, though development of

the inference procedures for the two variants of the proposed method, namely, CS-

PLIK and CS-Wald, will be more involved and out of scope of this paper. However,

as indicated by the simulation studies, these two variants may induce substantial

improvement especially when the variables are highly correlated. More research is

warranted.

Our work also enlightens a few directions that are worth ensuing eﬀort. First, as

our proposal requires the prior information to be known and informative, it remains

statistically challenging to develop eﬃcient screening methods in the absence of such

information. Recently, in the context of GLM, Hong et al. (2016) has proposed a

data-driven alternative when a pre-selected set of variables is unknown. It is thus

of substantial interest to develop a data-driven conditional screening for the survival

model. Second, even with prior knowledge, an open question often lies in how to

24

balance it with the information extracted from the given data. There has been some

recent work on how to incorporate prior information. For example, Wang et al. (2013)

developed a LASSO method by assigning diﬀerent prior distributions to each subset

according to a modiﬁed Bayesian information criterion that incorporates prior knowl-

edge on both the network structure and the pathway information, and Jiang et al.

(2015) proposed “prior lasso” (plasso) to balance between the prior information and

the data. A natural extension of the current work is to develop a variable screen-

ing approach that incorporates more complex prior knowledge, such as the network

structure or the spatial information of the covariates. We will report the progress

elsewhere.

25

References

Barut, E., Fan, J., and Verhasselt, A. (2016), “Conditional sure independence screen-

ing,” Journal of the American Statistical Association, to appear.

Binder, H. and Schumacher, M. (2009), “Incorporating pathway information into

boosting estimation of high-dimensional risk prediction models,” BMC Bioinfor-

matics, 10, 18.

Chow, M. L., Moler, E. J., and Mian, I. S. (2001), “Identifying marker genes in

transcription proﬁling data using a mixture of feature relevance experts,” Physiol

Genomics, 5, 99–111.

Deb, K. and Reddy, A. R. (2003), “Reliable classiﬁcation of two-class cancer data

using evolutionary algorithms,” BioSystems, 72, 111–129.

Fan, J., Feng, Y., and Wu, Y. (2010), “High-dimensional variable selection for Cox’s

proportional hazards model,” IMS Collections Borrowing Strength: Theory Pow-

ering Applications - A Festschrift for Lawrence D. Brown, 6, 70–86.

Fan, J. and Lv, J. (2008), “Sure Independence Screening for Ultrahigh Dimensional

Feature Space (with discussion),” Journal of Royal Statistical Society B, 70, 849–

911.

Gui, J. and Li, H. (2005), “Penalized Cox regression analysis in the high-dimensional

and low-sample size settings, with applications to microarray gene expression data,”

Bioinformatics, 21(13), 3001–8.

Hong, H., Wang, L., and He, X. (2016), “A data-driven approach to conditional

screening of high dimensional variables,” Manuscript.

26

Jiang, Y., He, Y., and Zhang, H. (2015), “Variable Selection with Prior Information

for Generalized Linear Models via the Prior LASSO Method,” JASA, To appear.

Li, H. and Luan, Y. (2005), “Boosting proportional hazards models using smoothing

splines, with applications to high-dimensional microarray data,” Bioinformatics,

21, 2403–2409.

Lin, D. Y. and Wei, L.-J. (1989), “The robust inference for the Cox proportional

hazards model,” Journal of the American Statistical Association, 84, 1074–1078.

Liu, X.-Y., Liang, Y., Xu, Z.-B., Zhang, H., and Leung, K.-S. (2013), “Adaptive

L1/2 Shooting Regularization Method for Survival Analysis Using Gene Expression

Data,” ScientiﬁcWorldJournal. 475702., 2013, 475702.

Mikovits, J., Ruscetti, F., Zhu, W., Bagni, R., Dorjsuren, D., and Shoemaker, R.

(2001), “Potential cellular signatures of viral infections in human hematopoietic

cells,” Dis Markers., 17(3), 173–8.

Rosenwald, A., Wright, G., Chan, W., Connors, J., Campo, E., et al. (2002), “The use

of molecular proﬁling to predict survival after chemotherapy for diﬀuse large-B-cell

lymphoma,” N Engl J Med., 346(25), 1937–47.

Schifano, E. D., Strawderman, R. L., and Wells, M. T. (2010), “MM Algorithms

for Minimizing Nonsmoothly Penalized Objective Functions,” Electronic Journal

of Statistics, 4, 1258–1299.

Song, R., Lu, W., Ma, S., and Jeng, X. J. (2014), “Censored Rank Independence

Screening for High-dimensional Survival Data,” Biometrika, 101 (4), 799–814.

Stewart, A. K. and Schuh, A. C. (2000), “White cells 2: impact of understanding the

molecular basis of haematological malignant disorders on clinical practice,” Lancet,

355(9213), 1447–53.

27

Uno, H., Cai, T., Pencina, M. J., D’Agostino, R. B., and Wei, L. J. (2011), “On the

C-statistics for Evaluating Overall Adequacy of Risk Prediction Procedures with

Censored Survival Data,” Stat Med., 30(10), 1105–1117.

Van Der Vaart, A. W. and Wellner, J. A. (1996), Weak Convergence, Springer.

Wang, Z., Xu, W., San Lucas, F., and Liu, Y. (2013), “Incorporating prior knowledge

into Gene Network Study,” Bioinformatics, 29, 2633–40.

Zhao, S. D. and Li, Y. (2012), “Principled sure independence screening for Cox models

with ultra-high-dimensional covariates,” Journal of Multivariate Analysis, 105(1),

397–411.

7 Appendix

7.1 Proof of Theorem 1

Proof. First we make the connection between βj to the expected conditional linear
covariance between Zj and P[δ = 1 | Z] given ZC, that is
E[Cov∗(Zj, P[δ = 1 | Z] | ZC)],

then by Condition 2, we relate it to αj. For any j /∈ C and k ∈ C, it is straightforward

to see that

and

s(m)
k

(t) = E[Z m

k λ0(t) exp(ZTα)ST (t | Z)SC(t)],

r(m)
j,k (t, βC, β) = E[Z m

k exp(ZTC βC + Zjβ)ST (t | Z)SC(t)],

for m = 0, 1. Then

vj,k(βC, β)

=

(cid:90) τ

0

E(cid:2)Wj,k(t, βC, β) exp(ZTα)ST (t | Z)SC(t)λ0(t)(cid:3) dt,

28

(21)

(22)

(23)

where

By Proposition 2,

.

Wj,k(t, βC, β) = Zk − E[Zk exp(ZTC βC + Zjβ)ST (t | Z)SC(t)]
E[exp(ZTC βC + Zjβ)ST (t | Z)SC(t)]
E(cid:2)Wj,k(t, βC, β) exp(ZTα)ST (t | Z)SC(t)(cid:3)
= E(cid:8)E∗(cid:2)Wj,k(t, βC, β) exp(ZTα)ST (t | Z)SC(t)(cid:3)(cid:9) .
vj(βC, β) = vj,j(βC, β) −(cid:88)

akvj,k(βC, β)

By Deﬁnition 6,

=

E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] − g(βC, β).

k∈C

where

and

(cid:90) τ

E [Cov∗(Zj, P[δ = 1 | Z] | ZC)]

E(cid:2)(Zj − E∗[Zj | ZC]) exp(ZTα)ST (t | Z)SC(t)λ0(t)(cid:3) dt,

=

0

gj(βC, β)

=

(cid:90) τ

0

E[(Zj − E∗[Zj | ZC]) exp(ZTC βC + Zjβ)ST (t | Z)SC(t)]

E[exp(ZTC βC + Zjβ)ST (t | Z)SC(t)]

×E(cid:2)exp(ZTα)ST (t | Z)λ0(t)SC(t)(cid:3) dt.

By Deﬁnition 2, vj(βC,j, βj) = 0q+1,

gj(βC,j, βj) = E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] .

When αj = 0, then E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] = 0. Thus gj(βC,j, βj) = 0.
Also, by Propositions 1 and 2, gj(βC,0, 0) = 0, then vj(βC,0, 0) = 0q+1. By uniqueness

in Lemma 1, βj = 0.

29

When αj (cid:54)= 0, by Condition 2, we have

|gj(βC,j, βj)| = |E [Cov∗(Zj, P[δ = 1 | Z] | ZC)]| > c1n−κ.

This implies that gj(βC,j, βj) and E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] are both nonzero and
have the same signs since they are equal. Next we show for any βC, gj(βC, 0) and
E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] have the opposite signs unless they are equal to zero.
This fact implies that βj (cid:54)= 0. Speciﬁcally, note that P(δ = 1 | Z) is the probability
of occurring the event and ST (t | Z)SC(t) = P(X > t | Z) represents the probability

at risk at time t. Based on Model (1), for any t,

∂P(X > t | Z)

∂Zj

× ∂P(δ = 1 | Z)

∂Zj

≤ 0.

By Proposition 3, Cov∗(Zj, P[δ = 1 | Z] | ZC) and Cov∗[Zj, ST (t | Z)SC(t) | ZC] have

the opposite signs unless they are zero. This further implies that for any βC,

E[exp(ZTC βC)Cov∗[Zj, ST (t | Z)SC(t) | ZC]]

E[exp(ZTC βC)ST (t | Z)SC(t)]

×E(cid:2)exp(ZTα)ST (t | Z)λ0(t)SC(t)(cid:3) dt.

(cid:90) τ

0

gj(βC, 0) =

and E [Cov∗(Zj, P[δ = 1 | Z] | ZC)] have opposite signs unless they are equal to zero.
Therefore, βj (cid:54)= 0.

7.2 Proof of Theorem 2
Proof. For any j ∈ M−C, we have βj (cid:54)= 0 by Theorem 1, by mean value theorem, for

some (cid:101)βj ∈ (0, βj),

|vj(βC,j, 0)| = |vj(βC,j, βj) − vj(βC,j, 0)| =

(cid:12)(cid:12)(cid:12) ∂vj
∂β (βC,j,(cid:101)βj)

(cid:12)(cid:12)(cid:12) is bounded. For given any βC, consider gj(βC, β) as
(cid:20)(cid:90) τ

Hj(t, βC, β)SC(t)dFT (t | Z)

.

Next we show that

a function of β, Then

∂gj
∂β

(cid:12)(cid:12)(cid:12)(cid:12) ∂vj

∂β

(βC,j,(cid:101)βj)

(cid:12)(cid:12)(cid:12)(cid:12)|βj|,
(cid:21)

(βC, β) = E

0

30

where

Hj(t, βC, β) =

E[exp(ZTC βC)Cov∗[Z 2

j exp(Zjβ), ST (t | Z) | ZC]]

E[exp(ZTC βC + Zjβ)ST (t | Z)]

−E[exp(ZTC βC)Cov∗[Zj exp(Zjβ), ST (t | Z) | ZC]]E[Zj exp(ZTC βC + Zjβ)ST (t | Z)]

[E[exp(ZTC βC + Zjβ)ST (t | Z)]]2

By Condition 2.1, P(|Z| < K0) = 1, then supβC,β |Hj(t, βC, β)| ≤ 2K 2

0 . Thus,

(βC, β)

0|E[E[SC(T ) | Z]] ≤ 2K 2
0 .

(cid:12)(cid:12)(cid:12)(cid:12) ∂vj

∂β

(βC,j,(cid:101)βj)

(cid:12)(cid:12)(cid:12)(cid:12) ≤ sup

βC,β

(cid:12)(cid:12)(cid:12)(cid:12) ∂gj

∂β

(cid:12)(cid:12)(cid:12)(cid:12) ≤ 2K 2

By the proof in Theorem 1, g(βC,j, 0) and E [Cov∗(Zj, E{FT (C | Z) | Z} | ZC)] have
the opposite signs, and by Condition 2,

|vj(βC,j, 0)| = |E [Cov∗(Zj, P[δ = 1 | Z] | ZC)]| + |gj(βC,j, 0)| > c1n−κ.

Taking c2 = 0.5K−2

0 c1, βj > 0.5K−2

0 |vj(βC,j, 0)| > c2n−κ. This completes the proof.

7.3 Proof of Theorem 3

Proof. For any j /∈ C and k ∈ C ∪ {j}, by Lin and Wei (1989), we have

Vj(βC, β) = En{Wi,j(βC, β)} + op(1),

where En[·] denotes the empirical measure, which is deﬁned as En[ξi] = n−1(cid:80)n

i=1 ξi

for any random variables ξ1, . . . , ξn, and Wi,j(βC, β) are independent over i, and
write Wi,j(βC, β) = [Wi,j,k(βC, β), k ∈ C ∪ {j}]T with
(cid:40)
Zi,k − r(1)
j,k (βC, β, t)
r(0)
j,k (βC, β, t)

(cid:40)
Zi,k − r(1)
j,k (βC, β, t)
r(0)
j,k (βC, β, t)

Yi(t) exp(Zi,CβTC + Zi,jβ)

(cid:90) τ
(cid:90) τ

r(0)
j,k (βC, β, t)

Wi,j,k(βC, β) =

dE[Ni(t)].

(cid:41)

(cid:41)

dNi(t)

0

0

−

31

Note that given any i, j, k, with probability one |Wi,j,k(βC, β)| are uniformly bounded.
Speciﬁcally, by Conditions 1.2, 2.1 and 3, with probability one, for all t ∈ [0, τ ],
(βTC , β)T ∈ Bj,

j,k (βC, β, t)
r(0)
j,k (βC, β, t)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Zi,k − r(1)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Yi(t) exp(Zi,CβTC + Zi,jβ)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:90) τ

r(0)
j,k (βC, β, t)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ |Zi,k| + K0,
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ exp{K0(K1 + δ) − log(L)},
(cid:12)(cid:12)(cid:12)(cid:12) ≤ Λ0(τ ) exp(K0K1).

dE[Ni(t)]

0

and

Thus, with probability one,

|Wi,j,k(βC, β)| ≤ K2,

where K2 = 2K0(1+Λ0(τ ) exp(2K0K1+K0δ−log L)). By the fact that E[Wi,j,k(βC, β)] =
0,

Var[Wi,j,k(βC, β)] = E[|Wi,j,k(βC, β)|2] < K 2

2

By Lemma 2.2.9 (Bernsterin’s inequality) of Van Der Vaart and Wellner (1996),

for any t > 0, for all j, k, βC and β, we have

(cid:18)
|En(Wi,j,k(βC, β))| >

P

(cid:19)

t
n

≤ 2 exp

(cid:18)

−1
2

t2

nK 2

2 + K2t/3

(cid:19)

.

Note that the above inequality holds for every j /∈ C and k ∈ C ∪ {j}. By Bonferroni

inequality,

(cid:18)
(cid:107)En(Wi,j(βC, β))(cid:107)2 >

P

(cid:19)

t

(q + 1)n

≤ 2(q + 1) exp

(cid:18)

−1
2

t2

nK 2

2 + K2t/3

(cid:19)

.

Since,

(cid:107)Vj(βC, β) − En(Wi,j(βC, β))(cid:107)2 = op(1).

Then for any 1 > 0 and 2 > 0, there exits N1, such that for any n > N1

P((cid:107)Vj(βC, β) − En(Wi,j(βC, β))(cid:107)2 > M 1/2) < 2.

32

P

(cid:18)
(cid:107)Vj(βC, β)(cid:107)2 >
(cid:18)

(cid:19)

(n−κ − 1)

≤ 2(q + 1) exp

M c2

2

(cid:18)

− M 2c2
8(q + 1)2

2

(cid:19)

+ 2.

n1−2κ

2 + K2n−κ/3
K 2

(cid:19)

P

Take N = max{(cid:100)(K2/3)1/κ(cid:101), N1}, then for any n > N , n−κ < 3/K2, and
n1−2κ
K 2
2 + 1

(cid:107)Vj(βC, β)(cid:107)2 >
Note that the above inequality holds for all (βTC , β)T ∈ Bj, particularly for (βTC,j, βj)T,
j /∈ C. Also, we have Vj((cid:98)βC,j,(cid:98)βj) = 0q+1. By Condition 4, we have

− M 2c2
8(q + 1)2

≤ 2(q + 1) exp

(n−κ − 1)

+ 2.

M c2

2

2

(cid:18)

(cid:19)

where M is the same value in Condition 4. By Triangle inequality and Bonferroni

inequality, we have

(cid:19)

(cid:18)
(cid:107)Vj(βC, β)(cid:107)2 >
≤ P

(cid:18)
(cid:107)En(Wi,j(βC, β))(cid:107)2 >

(q + 1)n

P

t

(cid:19)

− M 1/2

t

(q + 1)n

+ P((cid:107)Vj(βC, β) − En(Wi,j(βC, β))(cid:107)2 > M 2/2)

When n → ∞, take t = c2M (q + 1)n1−κ/2 > 0 on both side of the inequality, where

c2 is the same value in Theorem 2, we have

(cid:17)

P

(cid:16)|(cid:98)βj − βj| >
(cid:16)(cid:107)((cid:98)β

T

≤ P
≤ 2(q + 1) exp

(cid:18)

c2
2

(n−κ − 1)

C,j,(cid:98)βj)T − (βTC,j, βj)T(cid:107)2 >

− M 2c2
8(q + 1)2

2

n1−2κ
K 2
2 + 1

(cid:17)

(n−κ − 1)

c2
2

(cid:19)

+ 2.

Taking c3 =

M 2c2
2

8(q+1)2(K2

2 +1) and by Bonferroni completes the proof for part 1.

For part 2, by Theorem 2,

|βj| > c2n−κ.

min
j∈M−C

Note that, for any j ∈ M−C, event

(cid:111)
(cid:110)|(cid:98)βj − βj| ≤ c2n−κ/2 − 1
⊆(cid:110)|(cid:98)βj| ≥ |βj| − c2n−κ/2 + 1
(cid:111)
⊆(cid:110)|(cid:98)βj| ≥ c2n−κ/2 + 1

.

(cid:111)

33

Take γn = c4n−κ with c4 = c2/4,

(cid:26)

(cid:27)
|(cid:98)βj − βj| ≤ c2n−κ/2 − 1
(cid:26)
(cid:27)
|(cid:98)βj| ≥ c2n−κ/2 + 1
(cid:26)
(cid:27)
|(cid:98)βj| ≥ γn + 1

min
j∈M−C

.

min
j∈M−C

max
j∈M−C
⊆

⊆

Thus,

P

(cid:104)M−C ⊆ (cid:99)M−C

(cid:20)
(cid:20)

= P

≥ P

min
j∈M−C

min
j∈M−C

(cid:20)

(cid:105)
(cid:21)
|(cid:98)βj| > γn
|(cid:98)βj| > γn + 1
|(cid:98)βj − βj| ≤ c2n−κ/2 − 1

(cid:21)

(cid:21)

≥ 1 − P
≥ 1 − 2w(q + 1) exp(−c3n1−2κ) − 2.

max
j∈M−C

Let n → ∞, we have for any 2 > 0,

(cid:104)M−C ⊆ (cid:99)M−C

(cid:105) ≥ 1 − 2.

lim
n→∞ P

Note that the left side of the above equation does not depends on n any more. Taking
2 → 0 completes proof.

34

