6
1
0
2

 
r
a

 

M
5
1

 
 
]
S
D
.
s
c
[
 
 

1
v
8
9
7
4
0

.

3
0
6
1
:
v
i
X
r
a

ND-Tree: a Fast Online Algorithm for Updating a Pareto Archive

and its Application in Many-objective Pareto Local Search

Andrzej Jaszkiewicza, Thibaut Lustb

aPoznan University of Technology, Faculty of Computing, Institute of Computing Science, ul. Piotrowo

bSorbonne Universit´es, UPMC, Universit´e Paris 06, CNRS, LIP6, UMR 7606, F-75005, Paris, France

2, 60-965 Poznan

Abstract

In this paper we propose a new method called ND-Tree for fast online update of a Pareto
archive composed of mutually non-dominated solutions. ND-Tree uses a tree structure in
which each node represents a subset of solutions contained in a hypercube deﬁned by its
local approximate ideal and nadir points. A leaf is a subset of solutions organized as a
simple list, and an internal node is subset of solutions composed of the union of all its
sub-nodes. Using heuristic rules we build subsets, either leafs or internal nodes, contain-
ing solutions located close in the objective space. Using basic properties of local ideal and
nadir points we can eﬃciently avoid searching many branches in the tree. ND-Tree may
be used in any multiobjective metaheuristics e.g. in an multiobjective evolutionary algo-
rithm to update the external archive of potentially eﬃcient solutions. We experimentally
compare ND-Tree to simple list, quad-Tree, and M-Front methods using artiﬁcial and
realistic benchmarks. Finally we apply ND-Tree within two-phase Pareto Local Search
for traveling salesperson problems instances with up to 6 objectives. We show that with
this new method substantial reduction of the computational time can be obtained.

Keywords: Multiobjective optimization, Pareto archive, Quad-tree, Pareto local search,
Many-objective optimization

1. Introduction

In this paper we consider the problem of online update of a Pareto archive composed of
mutually non-dominated solutions when a new candidate solution shows up. This problem
is also referred to as dynamic non-dominance problem [27]. Online update of a Pareto
archive is typically used in multiobjective metaheuristics (MOMHs), e.g. multiobjective
evolutionary algorithms, whose goal is to generate a good approximation of the Pareto
front. Most of the nowadays MOMHs use an external archive of potentially eﬃcient
solutions, i.e. Pareto archive containing solutions not dominated by any other solutions

Email addresses: andrzej.jaszkiewicz@put.poznan.pl (Andrzej Jaszkiewicz),

thibaut.lust@lip6.fr (Thibaut Lust)

Preprint submitted to Elsevier

March 16, 2016

generated so far. We consider here MOMHs that generate iteratively new candidate
solutions and use them to immediately update Pareto archive. Updating Pareto archive
with a new solution x means that:

• all solutions dominated by x are removed from Pareto archive,
• x is added to Pareto archive if it was non-dominated w.r.t. to any solution in Pareto

archive.

Online update of a Pareto archive may also be used as an intermediate step of other
methods. For example Drozd´ık et al. [8] propose to use the online updated Pareto archive
to speed-up non-dominated sorting procedure used in many multiobjective evolutionary
algorithms.

The time needed to update Pareto archive generally grows with growing number of
objectives and growing number of solutions. In some cases it may become a crucial part
of the total running time of a MOMH.

The simplest data structure for storing Pareto archive is a plain list. When a new
solution x is added, x is compared to all solutions in Pareto archive until either all solutions
are checked or a solution dominating x was found.

In order to speed-up the process of updating a Pareto archive some authors proposed
the use of specialized data structures and algorithms, e.g. quad-trees. However, the
results of computational experiments reported in the literature are not conclusive and in
some cases such data structures may in fact increase the update time compared to simple
list.

The direct motivation for us to revisit the issue of updating Pareto archive comes from
special properties of Pareto local search (PLS) method [25, 3]. PLS works directly with
the Pareto archive. For each solution in the archive its neighborhood is searched to ﬁnd
new potentially eﬃcient solutions and update the archive. Standalone PLS starting from
random solutions is very ineﬃcient since it spends a lot of time generating large numbers
of solutions being still very far from the Pareto front. PLS, however, is used as a crucial
component in some of the best methods for multiobjective knapsack [20], biobjective
traveling salesperson problem (bTSP) [19, 18, 15] and set covering problem [21]. The
general idea of such methods is to start PLS from a set of high quality solutions generated
by some other methods, e.g. the powerful Lin-Kernighan heuristic for TSP [17].

PLS has also been used in other contexts, e.g. for solving scheduling problems [30, 9, 6],

multi-agent problems [13] or multiobjective Markov decision processes [16].

The importance of PLS may be explained by the fact that unlike most other MOMHs
it is especially good in the search for new solutions along Pareto front. In order to generate
a good approximation of the Pareto front a MOMH has to achieve two diﬀerent goals: the
solutions generated by such method should both approach the Pareto front and cover all
areas along this front. In other words, the MOMH has to search both towards and along
Pareto front [1]. PLS seems to be especially good in search along Pareto front, i.e. when
started from a sample of solutions located very close to the true Pareto front, PLS may
generate a large number of new potentially eﬃcient solutions in a very short time.

2

From the point of view of updating Pareto archive, PLS has some special characteris-

tics:

• PLS generates large number of new candidate solutions in a very short time (as the
neighborhood solutions for many problems may be quickly generated). In particular,
before a neighbor solution is added to the archive only the new values of objectives
are needed. These values may often be eﬃciently calculated using changes of the
objectives. For example, in the case of TSP, the typical two edges exchange move
requires only removing two edges and adding two other edges to the solution. So,
the calculation of change of each objective requires just few arithmetic operations.
This means that the time needed to generate a new solution may be much shorter
than the time needed to update the archive.

• Since the new candidate solutions are neighbors of potentially eﬃcient solutions
they are usually quite good, i.e. even if the new solution is dominated there are
only relatively few dominating solutions.
In this case the plain list is especially
ineﬃcient since the ﬁrst dominating solution will on average be found after checking
large fraction of solutions.

• Pareto archive is a crucial element of PLS. New solutions are accepted or rejected
based on the comparison to the archive. So Pareto archive has to be updated online,
while in some other MOMHs it is at least potentially possible to store all candidate
solutions and only at the end to ﬁlter out the dominated ones.

Based on these motivations, we propose a new method, called ND-Tree, for updating a
Pareto archive. A thorough experimental study will show that we can obtain substantial
computational time reductions comparing to state-of-the-art methods.

The remainder of the paper is organized as follows. Basic deﬁnitions related to multi-
objective optimization are given in Section 2. In Section 3, we present a state of the art
of the methods used for online updating a Pareto archive. The new method ND-Tree is
described in Section 4. Finally, computational experiments are reported and discussed in
Section 5.

2. Basic deﬁnitions

2.1. Multiobjective combinatorial optimization

We consider in this section a general multiobjective combinatorial optimization prob-

lem, deﬁned as follows:

“minimize
”

x∈X

subject to

y(x) = Cx
x : Ax ≤ b
x ∈ {0, 1}n

x ∈ {0, 1}n
C ∈ Np×n

−→ n variables,
−→ p objective functions

A ∈ Nm×n and b ∈ Nm×1 −→ m constraints

3

A combinatorial structure is associated to this problem, which can be path, tree, ﬂow,
tour, etc.
We denote by X the feasible set in decision space, deﬁned by X = {x ∈ {0, 1}n : Ax ≤
b}. The image of the feasible set in objective space is called Y and is deﬁned by Y =
y(X ) = {Cx : x ∈ X} ⊂ Np. Due to the contradictory features of the objectives, there
does not exist a feasible solution simultaneously minimizing each objective (that is why the
word minimize is placed between quotation marks) but a set of feasible solutions called
eﬃcient solutions. We present below some deﬁnitions that characterize these eﬃcient
solutions.

We ﬁrst deﬁne dominance relations:

Deﬁnition 1. Pareto dominance relation: we say that a vector u = (u1, ..., up) dominates
a vector v = (v1, ..., vp) if, and only if, uk ≤ vk ∀ k ∈ {1, . . . , p}∧∃ k ∈ {1, . . . , p} : uk < vk.
We denote this relation by u ≺ v.

We can now deﬁne an eﬃcient solution, a non-dominated point, the eﬃcient set and

the Pareto front.
Deﬁnition 2. Eﬃcient solution: a feasible solution x∗ ∈ X is called eﬃcient if there
does not exist any other feasible solution x ∈ X such that y(x) ≺ y(x∗). For the sake
of simplicity we will use the dominance relation w.r.t. solutions as well, i.e. x ≺ x∗ ⇔
y(x) ≺ y(x∗).
Deﬁnition 3. Non-dominated point: the image y(x∗) in objective space of an eﬃcient
solution x∗ is called a non-dominated point.
Deﬁnition 4. Eﬃcient set: the eﬃcient set denoted by XE contains all eﬃcient solutions.
Deﬁnition 5. Pareto front: the image of the eﬃcient set in Y is called the Pareto front
(or non-dominated frontier/set), and is denoted by YN .

Since in many places we will need dominance or equality relation we deﬁne it as

coverage relation.
Deﬁnition 6. Coverage relation: we say that a point u covers a point v if u ≺ v or
u = v. We denote this relation by u (cid:22) v. We will also use the coverage relation w.r.t.
solutions as well, i.e. x (cid:22) x∗ ⇔ y(x) (cid:22) y(x∗).

Please note that coverage relation is sometimes referred to as weak dominance [5].
The terminology, however, is not consistent and other authors use weak dominance as the
synonym of Pareto dominance [7] (in contrast to strong dominance where a solution is
better on all objectives). Thus to avoid confusion we use the name “coverage”.

To deﬁne a Pareto archive, we need to introduce the mutually non-dominated relation:

4

Deﬁnition 7. Mutually non-dominated relation: we say that two solutions are mutually
non-dominated or non-dominated w.r.t. each other if none of the two solutions covers the
other one.

We can now deﬁne the Pareto archive:

Deﬁnition 8. Pareto archive: set of solutions such that any pair of solutions of the set
are mutually non-dominated.

In the context of MOMHs, the Pareto archive contains thus the mutually non-dominated

solutions generated so far (i.e. at a given iteration of a MOMH). We will denote (cid:98)XE the
Pareto archive generated by a MOMH. In other words (cid:98)XE contains solutions that are

potentially eﬃcient at a given iteration.

The new method ND-Tree is based on local

ideal and nadir points that we deﬁne

below.
Deﬁnition 9. Local ideal point of a subset S ∈ X denoted as z∗(S) is the point in
the objective space composed of the best coordinates of all solutions belonging to S, i.e.
k(S) = min
z∗

x∈S {y(x)k},∀ k ∈ {1, . . . , p}.

Naturally, local ideal point covers all solutions in S.

Deﬁnition 10. Local nadir point of a subset S ∈ X denoted as z∗(S) is the point in
the objective space composed of the worst coordinates of all solutions belonging to S, i.e.
z∗k(S) = max

x∈S {y(x)k},∀ k ∈ {1, . . . , p}.

Naturally, local nadir point is covered by all solutions in S.
Approximations of these two points will be also used in ND-Tree:

Deﬁnition 11. Approximate local ideal point of a subset S ∈ X denoted as (cid:98)z∗(S) is a
point in the objective space such that (cid:98)z∗(S) (cid:22) z∗(S).
Deﬁnition 12. Approximate local nadir point of a subset S ∈ X denoted as (cid:98)z∗(S) is a
point in the objective space such that z∗(S) (cid:22)(cid:98)z∗(S).

Naturally, approximate local ideal point also covers all solutions in S.

Naturally, approximate nadir ideal point is also covered by all solutions in S.

3. State of the art

We present here a number of methods for the online update of Pareto archive presented
in the literature and used in the comparative experiment. This review is not supposed to
be exhaustive. Other methods can be found in [28] and reviews in [2, 23]. We describe
two popular methods: linear list and quad-tree, the composite points method [10] and one
recent method, M-Front [8], when used as a part of the non-dominated sorting procedure
gave excellent performances compared to Jensen-Fortin’s algorithm [14, 11], one of the
fastest non-dominated sorting algorithm.

5

3.1. Linear List
3.1.1. General case

In this structure, a new solution is compared to all solutions of the list until a covering
solution is found or all solutions are checked. The solution is only added if it is non-
dominated w.r.t. all the solutions in the list, that is we need to browse whole list before
adding a solution. The complexity in terms of number of Pareto dominance check is thus
in O(N ) with N the size of the list.

3.1.2. Biobjective case: sorted list

When only two objectives are considered, we can use the following special property:
if we sort the list according to one objective (let’s say the ﬁrst), the non-dominated list
is also sorted according to the second objective.

Therefore, roughly speaking, updating of the list can be eﬃciently done in the following
way. Let us consider two minimized objectives. The list is kept sorted according to the
ﬁrst objective. We ﬁrst determine the potential position of the new candidate solution in
the sorted list according to its value for the ﬁrst objective, with a binary search. Please
note that in this case, it is more eﬃcient to code the list with a dynamic array to get a
constant access to the solutions of the list. Once the place of the new solution is found
and it is not equal to some existing solution, it is enough to use these two procedures:

• We compare the new solution to the preceding one (if there is one) in the sorted
list: this solution has a better value according to the ﬁrst objective compared to the
new solution. Therefore, if the preceding solution has also a better value according
to the second objective, the new solution is dominated and cannot be added.

• If the solution is not dominated by the preceding solution, the solution can be
added since the next solutions have a higher value for the ﬁrst objective and cannot
thus dominated the solution. We then need to check if there are some dominated
solutions: we browse the next solutions of the list, until ﬁnding a solution that
has a better evaluation according to the second objective compared to the new
solution. All the solutions found that have a worse evaluation according to the
second objective have to be removed since there are dominated by the new solution.
The worst-case complexity is still in O(N ) since it can happen that a new solution
has to be compared to all the other solutions (in the special case where we add a new
solution in the ﬁrst position and all the solutions of the sorted list are dominated by this
new solution). But on average, experiments show that the behavior of this structure for
handling two objectives updating problems is much better than a simple list since the
worst-case scenario rarely occurs.

3.2. Quad-tree

The use of Quad-tree for storing potentially eﬃcient solutions was proposed by Habenicht

[12] and further developed by Sun and Steuer [29], and Mostaghim and Teich [22]. In
Quad-tree, solutions are located in both internal nodes and leafs. Each node may have

6

p2 sons corresponding to each possible combination of results of comparisons on each
objective where a solution can either be better or not worse.
In the case of mutually
non-dominated solutions in fact p2 − 2 sons are possible since the combinations corre-
sponding to dominating or covered solutions are not possible. Quad-tree allows for a fast
checking if a new solution is dominated or covered. A weak point of this data structure
is that when an existing solution is removed its whole sub-tree has to be re-inserted to
the structure. Thus, removal of a dominated solution is in general costly. In this paper
we use Quad-tree2 version as described by Mostaghim and Teich [22].

3.3. M-Front

M-Front has been proposed relatively recently by Drozd´ık et al.

[8] as a part of
method for non-dominated sorting problem. The idea of of M-Front is as follows. Assume
that in addition to the new solution x a reference solution ref relatively close to x and

belonging to the Pareto archive (cid:98)XE is known. The authors deﬁne two sets:
RSU (x, ref ) = {y ∈ (cid:98)XE | ∃k ∈ {1, . . . , p} : yk ≥ refk ∧ yk ≤ xk}
RSL(x, ref ) = {y ∈ (cid:98)XE | ∃k ∈ {1, . . . , p} : yk ≥ xk ∧ yk ≤ refk}

(1)

and prove that if a solution y ∈ (cid:98)XE is dominated by x then it belongs to RSL(x, ref ) and

(2)

if y dominates x then it belongs to RSU (x, ref ). Thus, it is suﬃcient to compare the new
solutions to sets RSL(x, ref ) and RSU (x, ref ) only. To ﬁnd all solutions with objective
values in a certain interval M-Front uses additional indexes one for each objective. Each
index sorts the Pareto archive according to one objective.

To ﬁnd a reference solution being close to x M-Front uses the k-d tree data structure.
The k-d tree is a binary tree in which each intermediate node divides the space into two
parts based on a value of one objective. While going down the tree the algorithm cycle
over particular objectives, selecting one objective for each level. Drozd´ık et al. [8] suggest
to store references to solutions in leaf nodes only, while intermediate nodes keep only split
values. To insert a solution k-d tree selects either lower or upper-or-equal half-space.

Please note, that the paper of Drozd´ık et al. [8] does not give the precise algorithm of
k-d tree. In our implementation when a leaf is reached a new division is made using the
average value of the current level objective. The split value is average between the value
for new solution and the solution in the leaf.

Also alike Drozd´ık et al. [8] approximate nearest neighbor is found exactly as in the
standard exact nearest neighbor search, but only four evaluations of the distance are
allowed.

We do not use the rebalancing of the k-d Tree described in [8] since it would never
be activated in the case of all data sets used in this paper and is very unlikely to be used
in the case of solutions generated by PLS.

7

3.4. M-Front-II

While implementing M-Front for the purpose of computational experiment we noticed
that a number of elements can be improved to reduce further the running time. The
improvement is in our opinion signiﬁcant enough to call the new method M-Front-II (see
Algorithm 1). The modiﬁcations we introduced are as follows:

• In original M-Front the sets RSL(x, ref ) and RSU (x, ref ) are built explicitly and
only then the solutions contained in these sets are compared to x. In M-Front-II we
build them only implicitly, i.e. we immediately compare the solutions that would
be added to the sets to x.

• We analyze the objectives such that we start from objectives for which refk ≤ xk. In
other words we start with solutions from set RSU (x, ref ). Since many new solutions
are dominated it allows to stop the search immediately when a solution dominating
x was found. Note that a similar mechanism is in fact used in original M-Front but
only after the sets RSL(x, ref ) and RSU (x, ref ) are explicitly built.

• The last modiﬁcation is more technical. M-Front uses linked lists (std::list in
C++) to store the indexes and a hash-table (std::unordered_map in C++) to link
solutions with their positions in these lists. We observed, however, that even basic
operations like iterating over the list are much slower with linked lists than with
dynamic arrays (like std::vector in C++). Thus we use dynamic arrays for the
indexes. In this case, however, there is no constant iterator that could be used to
link the solutions with their positions in these indexes. So, we use the fast binary
search to locate a position of a solution in the sorted index whenever it is necessary.
The overhead of the binary search is anyway smaller than the savings due to use of
faster hash-table.

3.5. Composite points

The composite points method has been developed by Fieldsend et al

[10] in 2003.
They introduce two new data structures called dominated tree and non-dominated tree.
The dominated tree allows to detect if a new solution should be included into the Pareto
archive (that is the new solution is not covered) and the non-dominated tree allows to
determine which solutions of the Pareto archive are dominated by the new solution. Some
particular points, called composite points, are used to build the trees. These points are
based on the maximal and minimal coordinates of the points of the Pareto archive, and
are built such that a total order between the composite points is obtained, according to
the coverage relation. A binary search among the composite points of each tree allows
then to update the Pareto archive when a new candidate point is added. This method has
been compared to the simple list for standard multiobjective continuous problems (ZDT
test functions [31]) but no signiﬁcant diﬀerence in speed has been achieved.

8

Algorithm 1 M-Front-II Update

Parameter (cid:108): A Pareto archive (cid:98)XE with p indexes Ik, k ∈ {1, . . . , p}, i.e. lists containing

references to all solutions sorted incrementally according to objective k and kd a k-d
tree containing references to all solutions
Parameter ↓: New candidate solution x

if (cid:98)XE = ∅ then

Add x to (cid:98)XE and its reference to all indexes Ik and to kd

else

Find reference solution ref using approximate nearest neighbor search in kd
if ref (cid:22) x then

else

STOP: x is rejected
- -| Comparison to set RSU (x, ref )
for each k ∈ {1, . . . , p} | refk < xk do

Find it, i.e. position of ref in index Ik using binary search
Decrement it to the last position where Ik[it]k = refk
while Ik[it]k ≤ xk do
if Ik[it] (cid:22) x then

STOP: x is dominated

it++

Insert x to Ik right before it
- -| Comparison to set RSL(x, ref )
for each k ∈ {1, . . . , p} | refk > xk do

Find it, i.e. position of ref in index Ik using binary search
Increment it to the last position where Ik[it]k = refk
while Ik[it]k ≥ xk do
if x (cid:22) Ik[it] then

Remove Ik[it] from (cid:98)XE, indexes Ik and kd

it–

if x was not covered by any solution in (cid:98)XE then

Insert x to Ik right after it

(cid:98)XE ← (cid:98)XE + x

add x to kd

4. ND-tree

The new method proposed in this paper is based on the following idea that allows to

reduce the number of comparisons to be made. Consider a subset S ⊆ (cid:98)XE composed of
approximate local ideal (cid:98)z∗(S) and approximate local nadir points (cid:98)z∗(S) are known. We

mutually non-dominated solutions and a new candidate solution x. Assume that some

can deﬁne the following simple properties:

9

Property 1. If x is covered by (cid:98)z∗(S), then x is covered by each solution in S and thus

can be rejected.

Proof 1. This property is a straightforward consequence of the transitivity of the
coverage relation.

Property 2. If x covers(cid:98)z∗(S), then each solution in S is covered by x.

w.r.t. each solution in S.

Proof 2. This property is also a straightforward consequence of the transitivity of
the coverage relation.

Property 3. If x is non-dominated w.r.t. both(cid:98)z∗(S) and(cid:98)z∗(S), then x is non-dominated
Proof 3. If x is non-dominated w.r.t. (cid:98)z∗(S) then there is at least one objective on
which x is worse than (cid:98)z∗(S) and thus worse than each solution in S. If x is non-
dominated w.r.t. (cid:98)z∗(S) then there is at least one objective on which x is better than
(cid:98)z∗(S) and thus better than each solution in S. So, there is at least one objective on
Property 4. If none of the above holds, i.e. x is neither covered by(cid:98)z∗(S), does not cover
(cid:98)z∗(S), nor is non-dominated w.r.t. both (cid:98)z∗(S) and (cid:98)z∗(S), then all situations are

which x is better and at least one objective on which x is worse than each solution
in S.

possible, i.e. x may either be non-dominated w.r.t. all solutions in S, covered by
some solutions in S or dominate some solutions in S.

Proof 4. This property can be proven by showing examples of each of the situation.

Consider for example a set S = {(1, 1, 1), (0, 2, 2), (2, 2, 0)} with (cid:98)z∗(S) = z∗(S) =
(0, 1, 0) and(cid:98)z∗(S) = z∗(S) = (2, 2, 2). A new solution (1, 1, 0) dominates a solution

in S, a new solution (1, 1, 2) is dominated (thus covered) by a solution in S, and
solutions (0, 3, 0) and (2, 0, 1) are non-dominated w.r.t. all solutions in S.

The properties are graphically illustrated for the biobjective case in Figure 1. As

can be seen in this ﬁgure, in the biobjective case, if x is covered by (cid:98)z∗(S) and x is non-
dominated w.r.t. (cid:98)z∗(S) then x is dominated by at least one solution in S. Note, however,
used in the proof - the point (0, 3, 0) is covered by(cid:98)z∗(S) = (0, 1, 0), non-dominated w.r.t.
(cid:98)z∗(S) = (2, 2, 2) and (0, 3, 0) is not dominated by any points in S.

that this does not hold in the case of three and more objectives as shown in the example

In fact it is possible to distinguish more speciﬁc situations if property 4 holds, e.g.
situation when a new solution may be covered but cannot dominate any solution, but since
we do not distinguish them in the proposed algorithm we do not deﬁne them formally.
The above properties allow in some cases to quickly compare a new candidate solution
x to all solutions in a set S without the need for further comparisons to individual solutions

10

Figure 1: Comparison of a new solution to all solutions in set S based on comparisons to(cid:98)z∗(S) and(cid:98)z∗(S)

only.

belonging to S. Such further comparisons are necessary only if the situations described
by Property 4 hold. Intuitively, the closer the approximate local ideal and nadir points
the stronger are these properties, i.e.
it is more likely that the further comparisons can
be avoided. To obtain close approximate local ideal and nadir points we should:

• Split the whole set of potentially eﬃcient solutions into subsets of solutions located

close in the objective space.

• Have good approximations of the exact local ideal and nadir points. On the other
hand calculation of the exact points may be computationally demanding and a
reasonable approximation may assure the best overall eﬃciency.

Based on these properties, we can now deﬁne the ND-Tree structure.

Deﬁnition 13. ND-Tree data structure is a tree with the following properties:

1. With each node n is associated a set of solutions S(n).
2. Each leaf node contains a list L(n) of solutions and S(n) = L(n).
3. For each internal node n, S(n) is the union of sets associated with all sons of n.

4. Each node n stores an approximate ideal point (cid:98)z∗(S(n)) and approximate nadir point
(cid:98)z∗(S(n)).
5. If n(cid:48) is a son of n, then (cid:98)z∗(S(n)) (cid:22) (cid:98)z∗(S(n(cid:48))) and (cid:98)z∗(S(n(cid:48))) (cid:22) (cid:98)z∗(S(n)).

11

through the nodes of ND-Tree and skipping sons (and thus their sub-trees) for which
property 4 does not hold. This procedure is presented in Algorithm 3 (UpdateNode).

The algorithm to update a Pareto archive with ND-Tree is given in Algorithm 2
(Update). The idea of the algorithm is as follows. We start by checking if the new

solution x is dominated, covered or non-dominated w.r.t. all solutions in (cid:98)XE by going
The new solution is ﬁrst compared to the approximate ideal point ((cid:98)z∗(S(n)) and nadir
point ((cid:98)z∗(S(n)) of the current node.
If the new solution is dominated by (cid:98)z∗(S(n) it
If (cid:98)z∗(S(n) is covered, the node is deleted and
its whole sub-tree as well (Property 2). Otherwise if (cid:98)z∗(S(n)) (cid:22) x or x (cid:22) (cid:98)z∗(S(n))

is immediately rejected (Property 1).

(Property 4) and if n is a leaf node, x may be dominated by or dominate some solutions
of n and it is necessary to browse the whole list L(n) of the node n. If a solution dominating
x is found, x is rejected, and if a solution dominated by x is found, the solution is deleted
from L(n).

If after checking ND-Tree the new solution was found to be non-dominated it is inserted
by adding it to a close leaf (Algorithm 4 Insert). To ﬁnd a proper leaf we start from
the root and always select a son with closest distance to x. As a distance measure we use
the Euclidean distance to the middle point between approximate ideal and approximate
nadir points. The middle point is a point with individual coordinates equal to the average
of corresponding coordinates in approximate ideal and approximate nadir points. Such
distance measure is very fast to compute based on the two points only. Since we do not
need the value of the Euclidean distance but just the order induced by this distance, we
used squared Euclidean distance to avoid calculation of the root. Once we have reached a
leaf node, we add the solution x to the list L(n) of the node and possibly update the ideal
and nadir points of the node n (Algorithm 6 UpdateIdealNadir). However, if the size of
L(n) became larger than the maximum allowed size of a leaf set, we need to split the node
into a predeﬁned number of sons (Algorithm 5 Split). We ﬁrst select one solution of L(n)
for each new subnode. The ﬁrst solution selected is the one with the highest Euclidean
distance to all other solutions in L(n). Then we select the solution with the highest
average Euclidean distance to all the solutions contained in all subnodes already created.
We continue this procedure until the required number of subnodes is created. Finally, we
add each remaining solution of L(n) to the closest subnode. We use as distance measure
the Euclidean distance to the middle point between approximate ideal and approximate
nadir points, as done in the Insert algorithm.

The approximate local ideal and nadir points are updated only when a solution is
added. We do not update them when solution(s) are removed since it is a more complex
operation. This is why we deal with approximate (not exact) local ideal and nadir points.
Please note that our goal is to propose a practically fast method. We do not present
any analysis of worst case complexity but we will show that this method performs well in
computational experiments.

12

Algorithm 2 Update

Parameter (cid:108): A Pareto archive (cid:98)XE organized as ND-Tree
if (cid:98)XE = ∅ then

Parameter ↓: New candidate solution x

else

Create a leaf node n with an empty list set L(n) and use it as a root
L(n) ← L(n) + x
n ← root node
UpdateNode(n (cid:108),x ↓)
Insert(n (cid:108),x ↓)

if x was not covered by any solution in (cid:98)XE then

Algorithm 3 UpdateNode
Parameter (cid:108): A node n
Parameter ↓: New candidate solution x

Compare x to (cid:98)z∗(S(n)) and (cid:98)z∗(S(n))
if (cid:98)z∗(S(n)) (cid:22) x then
else if x (cid:22) (cid:98)z∗(S(n)) then
else if (cid:98)z∗(S(n)) (cid:22) x or x (cid:22) (cid:98)z∗(S(n)) then

- -| Property 1
STOP: x is rejected
- -| Property 2
Remove n and its whole sub-tree
- -| Property 4
if n is a leaf node then
if y (cid:22) x then
else if x ≺ y then

for each y ∈ L(n) do

STOP: x is rejected

Remove y

else

for each Subnode n(cid:48) of n do

UpdateNode (n(cid:48) (cid:108),x ↓)
if n(cid:48) became empty then

Remove n(cid:48)

5. Computational experiments

We will show results obtained with ND-Tree and other methods in three diﬀerent

cases:

13

Algorithm 4 Insert

Parameter (cid:108): A node n
Parameter ↓: New candidate solution x

if n is a leaf node then
L(n) ← L(n) + x
UpdateIdealNadir (n (cid:108),x ↓)
if Size of L(n) became larger than maximum size of a leaf set then

Split (n (cid:108))

else

Find subnode n(cid:48) of n being closest to x
Insert(n(cid:48) (cid:108),x ↓)

Algorithm 5 Split

Parameter (cid:108): A node n
Find the solution y ∈ L(n) with the highest average Euclidean distance to all other
solutions in L(n)
Create a new subnode n(cid:48) with an empty list set L(n(cid:48))
L(n(cid:48)) ← L(n(cid:48)) + y
UpdateIdealNadir (n(cid:48) (cid:108),y ↓)
L(n) ← L(n) − y
while The required number of subnodes are not created do

Find the solution y ∈ L(n) with the highest average Euclidean distance to all
solutions in all subnodes of n
Create a new subnode n(cid:48) with an empty list set L(n(cid:48))
L(n(cid:48)) ← L(n(cid:48)) + y
UpdateIdealNadir (n(cid:48) (cid:108),y ↓)
L(n) ← L(n) − y
while L(n) is not empty do
y ← ﬁrst solution in L(n)
Find subnode n(cid:48) of n being closest to y
L(n(cid:48)) ← L(n(cid:48)) + y
UpdateIdealNadir (n(cid:48) (cid:108),y ↓)
L(n) ← L(n) − y

A) Results for sets artiﬁcially generated, which allow us to easily control the number

of solutions of the sets and the quality of the solutions.

B) Results when ND-Tree is integrated into PLS for solving the multiobjective traveling

salesperson problem.

14

Algorithm 6 UpdateIdealNadir

Parameter (cid:108): A node n
Parameter ↓: New candidate solution x

Check in any component of x is lower than corresponding component in (cid:98)z∗(S(n)) or
greater than corresponding component in (cid:98)z∗(S(n)) and update the points if necessary
if (cid:98)z∗(S(n)) or (cid:98)z∗(S(n)) have been changed then

if n is not a root then
np ← parent of n
UpdateIdealNadir (np (cid:108),x ↓)

C) Results for sets coming from solutions generated by PLS for solving the multiobjec-

tive traveling salesperson problem.

To avoid the inﬂuence of implementation details all methods were implemented from
the scratch in C++ and C in as much homogeneous way as possible, i.e. when possible
the same code was used to perform the same operations like Pareto dominance checks.
The code, as well as test instances and data sets, are available from the authors upon
request. Most of the results have been obtained on an Intel Core i7-5500U CPU at 2.4
GHz. The results involving PLS (Section 5.2) were obtained on an i5-450M CPU at 2.4
GHz.

5.1. Artiﬁcial sets

k=1(Vmax − yi

k)2 ≤ V 2

to the point (0, . . . , 0)): (cid:80)p
also add a quality constraint: (cid:80)p

The artiﬁcial sets are composed of n points with p objectives to minimize. The sets
are created as follows. We generate randomly n points yi in {0, . . . , Vmax}p with the
following constraint (otherwise there can be few non-dominated points, all located near
max. With these constraints, all the non-
dominated points will be close to the hypersphere of center (Vmax, . . . , Vmax) and with a
radius of length equal to Vmax. In order to control the quality of the points generated, we
max. With a small , only
high-quality solutions will be generated and this simulates well the behavior of a MOMH.
We have generated data sets composed of 100 000 and 200 000 points, with Vmax =
10000, and for p = 2 to 6. In the main experiment we use data sets with 100 000 points
because for the larger sets running times of some methods became very long.

k)2 ≥ (1 − ) ∗ V 2

i=k(Vmax − yi

For each value of p, ﬁve diﬀerent quality sets are considered:
• Quality = 1,  = 0.5
• Quality = 2,  = 0.25
• Quality = 3,  = 0.1
• Quality = 4,  = 0.05

15

Table 1: Numbers of non-dominated solutions in artiﬁcial sets

p Quality number of non-dominated solutions
2
2
2
2
2
3
3
3
3
3
4
4
4
4
4
5
5
5
5
5
6
6
6
6
6

519
713
1046
1400
2735
4588
6894
12230
19095
53813
14360
21680
39952
64664
98283
28944
42246
77477
96002
99975
45879
65195
96687
99788
100000

1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5
1
2
3
4
5

• Quality = 5,  = 0.01

The fraction of non-dominated solutions grows both with increasing quality and num-
ber of objectives and in extreme cases all solutions may be non-dominated (see table 1).
We compare simple list, sorted list (biobjective case), Quad-tree, M-Front, M-Front-II

and ND-Tree for these sets according to the CPU time (ms).

For ND-Tree we use 20 as the maximum size of leaf and p + 1 as the number of sons.
These values of the parameters were found to perform well in many cases. We analyze
the inﬂuence of these parameters later in this section.

Each method was run 10 times for each set each time processing the solutions in a
diﬀerent random order. The average running times are presented in Figures 2 to 6. Please
note that because of large diﬀerences the running time is presented in logarithmic scale.
In addition, in Figure 7 we illustrate the evolution of the running times according to the

16

Figure 2: CPU time (logarithmic scale) for biobjective data sets

Figure 3: CPU time (logarithmic scale) for three-objective data sets

Figure 4: CPU time (logarithmic scale) for four-objective data sets

17

Figure 5: CPU time (logarithmic scale) for ﬁve-objective data sets

Figure 6: CPU time (logarithmic scale) for six-objective data sets

Figure 7: CPU time (logarithmic scale) vs. number of objectives for data sets of quality 3

18

number of objectives for the data sets of intermediate quality 3.

The main observations from this experiment are:
• ND-Tree performs the best for all test sets with three and more objectives. In some
cases the diﬀerences to other methods are of two orders of magnitude and in some
cases the diﬀerence to the second best method is of one order of magnitude. ND-
Tree behaves also very predictably, its running time grows slowly with increasing
number of objectives and increasing fraction of non-dominated solutions.

• For biobjective instances sorted list is the best choice. In this case, M-Front and

M-Front-II also behave very well since they become very similar to sorted list.

• Simple list obtains its best performances for data sets with many dominated solu-
tions like p = 2 with lowest quality. In this case the new solution is dominated by
many solutions, so the search process is quickly stopped after ﬁnding a dominating
solution.

• Quad-tree performs very bad for data sets with many dominated solutions, e.g. on
biobjective instances where it is worst in all cases.
In this case, many solutions
added to Quad-tree are then removed and the removal of a solution from Quad-tree
is a costly operation as discussed above. On the other hand, it is the second best
method for all data sets with six objectives.

• M-Front-II is much faster than M-Front on data sets with larger fraction of dom-
In this case, M-Front-II may ﬁnd a dominating solution faster

inated solutions.
without building explicitly the whole sets RSL(x, ref ) and RSU (x, ref ).

• The performance of both M-Front and M-Front-II deteriorates with increasing num-
ber of objectives. With six objectives M-Front is the slowest method in all cases.
Intuitively this can be explained by the fact that M-Front (both versions) uses each
objective individually to reduce the search space. In case of two objectives the val-
ues of one objective carry a lot of information since order on one objective induces
also an order on the other one. The more objectives, the less information we get
from an order on one of them. Furthermore, sets RSL(x, ref ) and RSU (x, ref ) are
in fact unions of corresponding sets for particular objectives which also results in
their growth. Finally, M-Front is based on the assumption that a reference solution
close on Euclidean distance is also close on each objective. The more objectives, the
less it is so, since the close solution will rather have a good balance of diﬀerences
on many coordinates, but it does not have to be particularly close on individual
objectives.

In an additional experiment we analyzed also the evolution of the running time of all
methods with increasing number of solutions. We decided to use one intermediate data
set with p = 4 and quality 3. We used 200 000 solutions in this case and 10 runs for
each method. The results are presented in Figure 8. In addition, since the running time

19

Figure 8: CPU time vs. the number of solutions for four-objective data sets of quality 3

Figure 9: CPU time vs. the number of solutions for ND-Tree only (four-objective data sets of quality 3)

is much smaller for ND-Tree its results are presented in Figure 9 separately. We see that
ND-Tree is the fastest method for any number of solutions and its running time grows
almost linearly with the number of solutions.

ND-Tree has two parameters - the maximum size (number of solutions) of a leaf,
and the number of sons, so the question arises how sensitive it is to the setting of these
parameters. To study it we again use the intermediate data set with p = 4 and quality
3 and run ND-Tree with various parameters. The results are presented in Figure 10.
Please note, that number of sons cannot be larger to maximum size of leaf +1 since after
exceeding the maximum size the leaf is split into the given number of sons. We see that
ND-Tree is not very sensitive to the two parameters: the CPU time remains between
about one and three seconds regardless the values of the parameters. The best results are
however obtained with 20 for the maximum size of the list and with 6 for the number of
sons.

In our opinion the results conﬁrm that ND-Tree performs relatively well for a wide
range of the values of the parameters. In fact, it would remain the best method for this
data set with any of the parameters settings tested.

20

Figure 10: ND-Tree CPU time for diﬀerent values of parameters (four-objective data sets of quality 3).
Data series correspond to maximum leaf size.

5.2. Pareto local search

In this section, we solve instances of the multiobjective traveling salesperson problem
(MOTSP) with PLS. We use this problem since state-of-the-art methods for biobjective
TSP use PLS as one of the components (see [19, 15]). We compare the results of ND-
Tree with the simple (sorted) list data structure (commonly used in PLS). We do not
use other methods since we use an existing eﬃcient implementation of PLS for MOTSP
in C1, and full integration of all methods with this implementation would be technically
very complex. However, in the next section we will compare all methods on sets of points
generated by PLS.

There are diﬀerent versions of PLS according to the solutions from which the neigh-
borhood is applied. There are versions where the neighborhood is only applied from
non-dominated solutions [25] and there are versions where it is allowed to apply the
neighborhood from dominated solutions [3, 13].

For experimental reasons explained latter, we will use a version where the neighbor-

hood can be applied from dominated solutions.

Our version of PLS works as follows. The method starts with a population P composed
of potentially eﬃcient solutions given by an initial population P0. Then, all the neighbors
p(cid:48) of each solution p of P are generated. If a neighbor p(cid:48) is not covered by the current
solution p, we update a local list Ln of non-dominated neighbors with p(cid:48). Once all the
neighbors p(cid:48) of p have been generated, we update XE with Ln. We found it more eﬃcient
to use a local list of non-dominated neighbors rather than updating XE each time when
a new neighbor is produced (as commonly done in PLS, see [25, 3, 19]). The neighbors
list Ln is reinitialized after each neighborhood exploration. Finally, we save the neighbors
that have been added to XE, to an auxiliary population Pa. We then start again the
process with P = Pa until P is empty. The pseudo-code of PLS is given by Algorithm 7.

1Available at http://www-desir.lip6.fr/~lustt

21

In the algorithm, N (p) denotes the neighborhood of p and Update() is the procedure
used to update Pareto archive with a new solution (and returns true if the new solution
has been added to this set).

Please note that the Update() procedure is used in two diﬀerent contexts: ﬁrst
Update() is used to update the local list of non-dominated neighbors and secondly to
update the Pareto archive. For the ﬁrst case, we have noticed in our experiments that
the size of the neighbors list was quite small (less than 50). Therefore, in all cases, a
simple linear list has been used to store the non-dominated neighbors. Also, in some
versions of PLS [3, 19, 18], the auxiliary population Pa is also updated to keep only the
non-dominated solutions.
In the version of PLS used in this paper, we simply add a
solution to Pa without any dominance checking. The main reason is that, in this way, the
only diﬀerence between the use of two diﬀerent data structures in PLS comes from the
update of the Pareto archive.

Parameter ↓: An initial population P0 of non-dominated solutions

Algorithm 7 PLS

Parameter ↑: A Pareto archive (cid:98)XE
(cid:98)XE ← P

P ← P0
- -| Initialization of an auxiliary population Pa
Pa ← ∅
while P (cid:54)= ∅ do

- -| Generation of all the neighbors p(cid:48) of all the solutions p ∈ P
for each p ∈ P do

- -| Initialization of a list of neighbors Ln
Ln ← ∅
for each p(cid:48) ∈ N (p) do
if y(p) (cid:14) y(p(cid:48)) then
Update(Ln (cid:108),p(cid:48) ↓)

if Update((cid:98)XE (cid:108),n ↓) then

for each n ∈ Ln do
Pa ← Pa + n

- -| P is composed of the solutions of Pa
P ← Pa
- -| Re-initialization of Pa
Pa ← ∅

We have used Euclidean MOTSP instances with p = 2 to p = 6 objectives. The size
of the instances are given in Table 2. The p costs between the edges correspond to the
Euclidean distance between two points in a plane.

We have considerably reduced the size of the instances according to the number of

22

Table 2: MOTSP instances

p

Size

2
500

3
50

4
25

5
20

6
15

Table 3: Size of the initial population

p

|N DP|

2
836

3
411

4
428

5
489

6
263

objectives. Indeed, when the number of objectives increase, the number of Pareto non-
dominated generally increases also signiﬁcantly.

It is now well-known that PLS needs a good-quality initial population to start [19].
Otherwise, PLS converges very slowly to the Pareto front. We have used as initial pop-
ulation for all the instances, the potentially eﬃcient solutions obtained from 1000 Lin-
Kernighan runs [4] with a linear aggregation of the objectives and random weight sets.
The number of potentially eﬃcient solutions obtained (|N DP|) in this way is given in
Table 3.

We have used for the neighborhood simple 2-opt moves (two edges are removed, and
two new edges are added). However, as generating all the 2-opt moves for each solution
of the population will be very time-consuming ( N (N−3)
neighbors to generate for each
solution, with N cities), we only consider a small proportion of all the possible 2-opt
moves. As done in [18], candidate lists for the 2-opt moves are used: the candidate lists
are created on the basis of the edges used by the solutions of the initial population. More
precisely, we explore the set of candidate edges of the initial population, and for each
candidate edge {vi, vj}, we add the city vj to the candidate list of the city vi. Moreover,
for the instances with at least four objectives, we limit the size of the candidate list to
2 to limit the number of neighbors generated in order to keep reasonable running times
(which can be very high when the list is used to update the Pareto archive).

2

to the Pareto archive (cid:98)XE. That enables to reduce the computational time of PLS since

We also introduce another speed-up technique in PLS for solving the MOTSP: in the
neighbors list Ln, we only save the new objective values and the indexes, in the current
solution, of the two edges to be removed, but we do not modify the whole representation of
the solution. Then the neighbor solution is fully built only if it is non-dominated according
building a new solution from a 2-opt move is in O(N ) and we avoid this operation for
new solutions that are found to be covered.

The result of the comparison between the use of the linear list and ND-Tree for solving

the MOTSP with PLS is given in Table 4.

The results illustrate the substantial beneﬁt of using ND-Tree in comparison to the
simple list: by only changing the method used to update the Pareto archive we obtain

23

Table 4: Comparison between the list and ND-Tree for updating the potentially eﬃcient solutions set in
PLS. *In the biobjective case, the sorted list structure has been used.

Instance

p Size
500
2
3
50
25
4
20
5
6
15

|N DP|
32842
94343
84013
359581
49341

CPU(s)

List

ND-Tree Speed-up

24.26*
3517.52
1299.30
20130.35
257.93

24.82
33.26
18.81
282.14
12.09

0.98
106
69
71
21

speed-up factors that goes to 21 (6 objectives instance) to 106 (3 objectives instance). For
example, for the 5 objectives instance, PLS with the list needs more than 5 hours while
PLS with ND-Tree only needs not more than 5 minutes. On the other hand, for the two
objectives instance, we have used the sorted list, and in this case, ND-Tree does not allow
to improve the running time of PLS.

5.3. Sets generated by PLS

In this section we compare ND-Tree with the list, quad-tree, M-Front and M-Front-II

for sets of points generated by PLS. The points correspond to:
• the initial points obtained from 1000 Lin-Kernighan runs,
• points generated with the application of the neighborhood from the initial points

(i.e. one phase of PLS).

The numbers of all solutions and non-dominated solutions are given in Table 5.
The results are presented in Figure 11. Please note that the results are not directly
comparable between diﬀerent numbers of objectives since the sets diﬀer in total number
of solutions. The results conﬁrm that the observations made for artiﬁcial sets also hold in
the case of real sets. ND-Tree is the fastest method for three and more objectives. Quad-
tree performs particularly bad in biobjective case. Both versions of M-Front relatively
deteriorate with growing number of objectives.

6. Conclusion

According to the results of the computational experiments ND-Tree should be a
method of choice for storing and updating a Pareto archive in the case of three and
more objectives problems. In biobjective case the best choice remains the sorted list.

We believe that with the proposed method for updating a Pareto archive, new state-
of-the art results could be obtained for many MOCO problems (with p > 2) and some
MOMHs could be adapted to this special data structure in order to improve their results.
In fact in this paper we were able to apply PLS to MOTSP instances with up to 6

24

Table 5: Numbers of solutions in sets generated by PLS

p N Number of solutions Number of non-dominated solutions
2
3
4
5
6

593579
199149
133981
105901
45223

500
100
50
35
25

6471
22960
37561
47691
20663

Figure 11: CPU time (logarithmic scale) on sets generated by PLS

objectives while according to our knowledge so far PLS was applied to biobjective and
three-objective instances only.

An interesting direction for further research is to adapt ND-Tree to be able to deal with
archives of a relatively large but limited size. Finally, it would be interesting to study how
ND-tree could be modiﬁed to update archives with stronger dominance relations than the
Pareto dominance (e.g. sorted-Pareto dominance [24] or Lorenz dominance [26]). In this
way, preferences of a decision maker could be integrated and methods such as PLS will not
be limited by the high number of Pareto eﬃcient solutions when solving many-objective
combinatorial optimization problems.

Acknowledgment

The research of Andrzej Jaszkiewicz was funded by the the Polish National Science

Center, grant no. UMO-2013/11/B/ST6/01075.

References

[1] A.Lara, Sanchez, G., Coello, C. C., Sch¨utze, O., Feb 2010. HCS: A new local search
strategy for memetic multiobjective evolutionary algorithms. IEEE Transactions on
Evolutionary Computation 14 (1), 112–132.

25

[2] Altwaijry, N., Bachir Menai, M., 2012. Data structures in multi-objective evolution-

ary algorithms. Journal of Computer Science and Technology 27 (6), 1197–1210.

[3] Angel, E., Bampis, E., Gourv`es, L., 2004. A dynasearch neighborhood for the bi-
criteria traveling salesman problem. In: Gandibleux, X., Sevaux, M., S¨orensen, K.,
T’kindt, V. (Eds.), Metaheuristics for Multiobjective Optimisation. Springer. Lecture
Notes in Economics and Mathematical Systems Vol. 535, Berlin, pp. 153–176.

[4] Applegate, D., 2003. Chained Lin-Kernighan for large traveling salesman problems.

INFORMS Journal on Computing 15, 82–92.

[5] Brockhoﬀ, W., 2010. Theory of Randomized Search Heuristics: Foundations and
Recent Developments. World Scientiﬁc Publishing Company, Ch. Theoretical aspects
of evolutionary multiobjective optimization, pp. 101–139.

[6] Coelho, V. N., Souza, M. J. F., Coelho, I. M., Guimar˜aes, F. G., Lust, T., Cruz,
R. C., 2012. Multi-objective approaches for the open-pit mining operational planning
problem. Electronic Notes in Discrete Mathematics 39, 233–240.

[7] Deb, K., 2001. Multi-objective optimization using evolutionary algorithms. Wiley,

New-York.

[8] Drozd´ık, M., Akimoto, Y., Aguirre, H., Tanaka, K., 2015. Computational cost reduc-
tion of nondominated sorting using the M-front. IEEE Transactions on Evolutionary
Computation 19 (5), 659–678.

[9] Dubois-Lacoste, J., L´opez-Ib´a˜nez, M., St¨utzle, T., 2011. A hybrid TP+PLS algorithm
for bi-objective ﬂow-shop scheduling problems. Computers & Operations Research
38 (8), 1219–1236.

[10] Fieldsend, J. E., Everson, R. M., Singh, S., 2003. Using unconstrained elite archives
for multiobjective optimization. IEEE Transactions on Evolutionary Computation
7 (3), 305–323.

[11] Fortin, F.-A., Grenier, S., Parizeau, M., 2013. Generalizing the improved run-time
complexity algorithm for non-dominated sorting. In: Proceedings of the 15th Annual
Conference on Genetic and Evolutionary Computation. GECCO ’13. ACM, New
York, NY, USA, pp. 615–622.

[12] Habenicht, W., 1983. Essays and Surveys on Multiple Criteria Decision Making: Pro-
ceedings of the Fifth International Conference on Multiple Criteria Decision Making,
Mons, Belgium, August 9–13, 1982. Springer Berlin Heidelberg, Ch. Quad Trees, a
Datastructure for Discrete Vector Optimization Problems, pp. 136–145.

26

[13] Inja, M., Kooijman, C., de Waard, M., Roijers, D., Whiteson, S., September 2014.
Queued Pareto local search for multi-objective optimization. In: PPSN 2014: Pro-
ceedings of the Thirteenth International Conference on Parallel Problem Solving from
Nature. pp. 589–599.

[14] Jensen, M., Oct 2003. Reducing the run-time complexity of multiobjective EAs: The
NSGA-II and other algorithms. IEEE Transactions on Evolutionary Computation
7 (5), 503–515.

[15] Ke, L., Zhang, Q., Battiti, R., Oct 2014. Hybridization of decomposition and local
search for multiobjective optimization. IEEE Transactions on Cybernetics 44 (10),
1808–1820.

[16] Kooijman, C., de Waard, M., Inja, M., Roijers, D., Whiteson, S., April 2015. Pareto
local policy search for MOMDP planning. In: ESANN 2015: Proceedings of the 23rd
European Symposium on Artiﬁcial Neural Networks, Special Session on Emerging
Techniques and Applications in Multi-Objective Reinforcement Learning. pp. 53–58.

[17] Lin, S., Kernighan, B., 1973. An eﬀective heuristic algorithm for the traveling-

salesman problem. Operations Research 21, 498–516.

[18] Lust, T., Jaszkiewicz, A., 2010. Speed-up techniques for solving large-scale biobjec-

tive TSP. Computers & Operations Research 37, 521–533.

[19] Lust, T., Teghem, J., 2010. Two-phase Pareto local search for the biobjective trav-

eling salesman problem. Journal of Heuristics 16 (3), 475–510.

[20] Lust, T., Teghem, J., 2012. The multiobjective multidimensional knapsack problem:
a survey and a new approach. International Transactions in Operational Research
19 (4), 495–520.

[21] Lust, T., Tuyttens, D., 2014. Variable and large neighborhood search to solve the

multiobjective set covering problem. J. Heuristics 20 (2), 165–188.

[22] Mostaghim, S; Teich, J., 2004. Quad-trees: A data structure for storing Pareto sets in
multiobjective evolutionary algorithms with elitism. In: Abraham, A; Jain, L. G. R.
(Ed.), Evolutionary Multiobjective Optimization, Book Series: Advanced Informa-
tion and Knowledge. Springer-Verlag London LTD, pp. 81–104.

[23] Mostaghim, S., Teich, J., Tyagi, A., 2002. Comparison of data structures for storing
Pareto-sets in MOEAs. In: Evolutionary Computation, 2002. CEC ’02. Proceedings
of the 2002 Congress on. Vol. 1. pp. 843–848.

[24] O’Mahony, C., Wilson, N., 2013. Sorted-pareto dominance and qualitative notions
of optimality. In: Gaag, L. C. (Ed.), Symbolic and Quantitative Approaches to Rea-
soning with Uncertainty: 12th European Conference, ECSQARU 2013, Utrecht, The
Netherlands, July 8-10, 2013. Proceedings. Springer Berlin Heidelberg, pp. 449–460.

27

[25] Paquete, L., Chiarandini, M., St¨utzle, T., 2004. Pareto local optimum sets in the
biobjective traveling salesman problem: an experimental study. In: Gandibleux, X.,
Sevaux, M., S¨orensen, K., T’kindt, V. (Eds.), Metaheuristics for Multiobjective Op-
timisation. Springer. Lecture Notes in Economics and Mathematical Systems Vol.
535, Berlin, pp. 177–199.

[26] Perny, P., Spanjaard, O., Storme, L.-X., 2006. A decision-theoretic approach to ro-

bust optimization in multivalued graphs. Annals OR 147 (1), 317–341.

[27] Sch¨utze, O., 2003. A new data structure for the nondominance problem in multi-
objective optimization. In: Proceedings of the 2nd International Conference on Evo-
lutionary Multi-criterion Optimization. EMO’03. Springer-Verlag, Berlin, Heidelberg,
pp. 509–518.

[28] Sch¨utze, O., Mostaghim, S., Dellnitz, M., Teich, J., 2003. Covering Pareto sets by
multi-level evolutionary subdivision techniques. In: Proceedings of the Second Int.
Conf. on Evolutionary Multi-Criterion Optimization. Springer, Berlin, pp. 118–132.

[29] Sun, M., Steuer, R., 1996. Quad trees and linear list for identifying nondominated

criterion vectors. INFORM Journal on Computing 8 (4), 367–375.

[30] Teixeira, C., Covas, J., St¨utzle, T., Gaspar-Cunha, A., 2009. Application of Pareto
local search and multi-objective ant colony algorithms to the optimization of co-
rotating twin screw extruders. In: Viana, A., et al. (Eds.), Proceedings of the
EU/Meeting 2009: Debating the future: new areas of application and innovative
approaches. pp. 115–120.

[31] Zitzler, E., Deb, K., Thiele, L., 2000. Comparison of Multiobjective Evolutionary

Algorithms: Empirical Results. Evolutionary Computation 8 (2), 173–195.

28

