Quantum Dynamics in Phase space using the
Biorthogonal von Neumann bases: Algorithmic

Considerations

Shai Machnesa,∗, Elie Assémata, David Tannora

aDept. of Chemical Physics, Weizmann Institute of Science, 76100 Rehovot, Israel

Abstract

The von Neumann lattice refers to a discrete basis of Gaussians located on a
lattice in phase space. It provides an attractive approach for solving quan-
tum mechanical problems, allowing the pruning of tensor-product basis sets
using phase space considerations. In a series of recent articles Shimshovitz
et al. [Phys. Rev. Lett. 109 7 (2012)], Takemoto et al. [Journal of Chemical
Physics 137 1 (2012)] Machnes et al.
[Journal of Chemical Physics, ac-
cepted (2016)]), we have introduced two key new elements into the method:
a formalism for converging the basis and for eﬃcient pruning by use of the
biorthogonal basis. In this paper we review the key components of the theory
and then present new, eﬃcient and parallelizable iterative algorithms for solv-
ing the time-independent and time-dependent Schrodinger equations. The
algorithms dynamically determine the active reduced basis iteratively with-
out resorting to classical analogs. These algorithmic developments, combined
with the previous formal developments, allow quantum dynamics to be per-
formed directly and economically in phase space. We provide two illustrative
examples: double-well tunneling and double ionization of helium.

∗Corresponding author, shai.machnes@gmail.com

6
1
0
2

 
r
a

 

M
2
1

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
3
6
9
3
0

.

3
0
6
1
:
v
i
X
r
a

Contents
1 Introduction
2 Theory

3
4
4
5

2.1 Review of PvB . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.1 The Fourier grid . . . . . . . . . . . . . . . . . . . . .
2.1.2 The von Neumann lattice and its projection onto the
Fourier grid (PvN) . . . . . . . . . . . . . . . . . . . .
2.1.3 Biorthogonal bases . . . . . . . . . . . . . . . . . . . .
2.1.4 BvN - The basis biorthogonal to PvN . . . . . . . . . .
2.1.5 The Schrödinger equation in PvB . . . . . . . . . . . .

6
7
8
9
2.2 PvB as a similarity transformation . . . . . . . . . . . . . . . 11
2.2.1 PvB expressed entirely in terms of B . . . . . . . . . . 11
2.2.2 Connection to the Husimi and Wigner representations . 12
2.3 The reduced Hilbert space . . . . . . . . . . . . . . . . . . . . 13

2.3.1 Deﬁning the reduced Hilbert space, (cid:101)H . . . . . . . . . 13
2.3.2 Biorthogonal bases for (cid:101)H . . . . . . . . . . . . . . . . . 14
2.3.3 Projecting into (cid:101)H . . . . . . . . . . . . . . . . . . . . . 15

2.4 The Hamiltonian and the Schrödinger equations for the re-

duced state

. . . . . . . . . . . . . . . . . . . . . . . . . . . . 16
20
3.1 Evaluating the reduced Hamiltonian . . . . . . . . . . . . . . . 20

3 Practical considerations and Algorithms

3.1.1 Decomposition of the Hamiltonian into a sum of one

3.1.2 Updating (cid:101)S . . . . . . . . . . . . . . . . . . . . . . . . 22

dimensional products (POTFIT)

. . . . . . . . . . . . 21

3.1.3 Utilizing symmetries in the Hamiltonian and the Gabor

basis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
3.2 Statics: The eigenmode algorithm . . . . . . . . . . . . . . . . 24
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
3.3 Dynamics
3.3.1 Dynamics algorithm . . . . . . . . . . . . . . . . . . . 26
3.3.2 Time propagation . . . . . . . . . . . . . . . . . . . . . 27
3.3.3 Multi-factor determination of dynamic time step for

. . . . . . . . . . . . . . . . . . . . . . 29
32
4.1 Double-well potential . . . . . . . . . . . . . . . . . . . . . . . 32
4.2 Helium double ionization . . . . . . . . . . . . . . . . . . . . . 34
36

PvB evolutions

5 Conclusions and outlook

4 Examples

2

1. Introduction

The quantum description of multiparticle physical systems is typically char-
acterized by an extremely large Hilbert space, making any sort of wavefunc-
tion simulation extremely challenging [1]. Examples range from electronic
structure, ionization and high harmonic generation in multielectron systems
to chemical reactions and photodissociation of polyatomic molecules. It is
therefore crucial to ﬁnd a compact representation of quantum states which
admits explicit control of accuracy.
A promising direction is the class of methods in which states are represented
explicitly as phase space objects. Such methods reduce resource usage to
only those areas of phase space which are actually occupied. Furthermore,
such representations reveal the physical nature of the state and its classical
correspondence. Despite some recent progress [2, 3], the most commonly used
phase space representation, the Wigner representation, is not well suited for
computational use.
To ﬁll the need for a numerically accurate and eﬃcient phase space based
approach, the periodic von Neumann (PvN) representation was developed
[4, 5, 6]. The method is based on a lattice of phase space localized Gaussians
as proposed by von Neumann [7] (see also Gabor [8]). However, straight-
forward implementation of the von Neumann approach is plagued with dif-
ﬁculties, due to the non-orthogonal nature of the basis [9]. The removal of
these diﬃculties relies on two key insights. First, that the poor convergence
of the von Neumann lattice is a consequence of it being a non-orthogonal
basis. By projecting the basis into the Hilbert space spanned by a discrete
Fourier basis of the same size [10, 11, 12], we obtain exponential convergence
for a wide range of functions. Second, the recognition that although the von
Neumann basis is phase space localized, the biorthogonal basis which we call
BvN (Biorthogonal von Neumann), is not. Since the latter determines the
coeﬃcients, there is typically no sparsity at all in the representation. How-
ever, by exchanging the roles of the von Neumann basis and its biorthogonal
basis, the representation typically becomes extremely sparse. This gives rise
to the name of the method PvB (Periodic von Neumann with Biorthogonal
exchange), and we will refer to the PvB representation. With these two mod-
iﬁcations the method combines the best of both worlds: it is mathematically
equivalent to the Fourier grid, but has the ﬂexibility that basis functions can
be placed only in the areas of phase space where they are needed.

3

In [13] we developed the mathematical underpinnings of the method, in par-
ticular the projection onto subspaces spanned by non-orthogonal bases. In
this manuscript we review the mathematical background and develop the
algorithms necessary for an eﬃcient implementation of the method. These
developments become crucial when applying the methodology to more chal-
lenging systems, such as the helium atom in strong ﬁelds [14]. The paper
also contains additional formal developments, casting the PvB approach as a
similarity transformation and drawing parallels with the Wigner and Husimi
representations.
The paper is organized as follows. Section 2 introduces the formal theory.
Section 3 deals with the algorithmic issues relating to the implementation of
PvB. Some illustrative examples are given in Section 4. Finally in Section
5 we discuss the outlook for the PvB method, and how some of its current
limitations may be alleviated.

2. Theory

In this section we provide a brief summary of the main deﬁnitions, expressions
and insights in the PvB method, in order to provide the context for the
algorithms and implementation considerations discussed in Section. 3.
We begin with a brief review of the PvB approach in Section 2.1. Section
2.2 recasts PvB as a similarity transformation of the Fourier-grid projected
von Neumann lattice. Section 2.3 introduces the reduced PvB representation,
allowing one to represent only those regions of phase space actually occupied
by the current state. In Section 2.4 we derive the form of the Schrödinger
equations in the reduced representation. These subjects are discussed in
greater detail in [13].

2.1. Review of PvB

The PvB representation, developed in [4, 5, 6], is based on projecting the
von Neumann lattice of phase space localized Gaussians (Section 2.1.2) onto
the Fourier grid (Section 2.1.1). As the projected Gaussians form a non-
orthogonal basis, the representation of objects in this Hilbert space requires
the deﬁnition of two biorthogonal bases — one for the bras and the other for
the kets (Section 2.1.3). These elements are combined together in the PvB

4

method (Section 2.1.4). Finally, the Schrödinger equation is recast in the
PvB representation (Section 2.1.5).

2.1.1. The Fourier grid

We brieﬂy review the pseudospectral Fourier method [15, 16] (also known as
the periodic sinc discrete variable representation (DVR [17])), which serves
as the underlying Hilbert space on which we construct the PvB method. See
also [13, 18].
Functions with support on a ﬁnite segment x ∈ [0, L], may be assumed, with-
out loss of generality, to have cyclic boundary conditions. All such functions
are spanned by

(cid:16)

(cid:17)

N(cid:88)

m=1

5

ϕn (x) =

1√
L

exp

2πi

x
L

n

=

1√
L

exp (iknx) , ∀n ∈ Z,

(1)

L

2π

L n. Limiting bandwidth to K deﬁnes a rectangular area of phase
with kn = 2π
space of area 2KL, which is spanned by the orthonormal spectral basis of

size N = 2nmax, {ϕn}n∈[−nmax+1,...,nmax], where nmax :=(cid:4) KL
Any f ∈ H may be expanded as f (x) = (cid:80)N

product deﬁned as (cid:104)f, g(cid:105) :=
grid (FG) Hilbert space, H.

0 f∗ (x) g (x) dx, this constitutes the Fourier

(cid:5) . With an inner

´

ϕ(cid:126)gϕ = (cid:104)f, g(cid:105).

n=1 (cid:104)ϕn, f(cid:105) ϕn (x). We may
now represent f by the column vector of the expansion coeﬃcients, (cid:126)fϕ =
((cid:104)ϕ1, f(cid:105) ,(cid:104)ϕ2, f(cid:105) , . . .(cid:104)ϕN , f(cid:105))T . The norm remains unchanged in the discrete
representation, (cid:126)f†
The FG Hilbert space may also be spanned by another basis, whose coeﬃ-
cients can be computed without integration. Consider the set of Fourier grid
j=0 for some
m=1 as the set of
orthogonal pseudo-spectral functions, within the FG Hilbert space, such that
any function f (x) ∈ H can be expanded as

points, a set of N equidistant sampling points,(cid:8)xj = x0 + L j
x0 ∈(cid:2)0, L
(cid:3). Deﬁne the pseudo-spectral basis, Θ = {θm (x)}N

(cid:9)N−1

N

N

f (x) =

f (xm) θm (x) .

(2)

where

θm (x) =

1
N

nmax(cid:88)

exp (ikn (x − xm)) = eiπ x−xm

L DA

(cid:18)

N, 2π

(cid:19)

,

x − xm

L

n=−nmax+1

sin(N α
2 )
N sin( α
2 )

(3)
being the periodic sinc functions (also known as
with DA (N, α) :=
the Dirichlet functions), which are localized around xm. α := 2π x−xm
L . Note
that (cid:104)θn, θm(cid:105) = N
L δn,m. f may now be represented by its sampling vector,
(cid:126)f = (cid:126)fθ = (f (x1) , f (x2) . . . , f (xN ))T , dropping the basis designation when
implied by context.
Deﬁne the orthogonal projector into the FG Hilbert space by

N(cid:88)

N(cid:88)
function f (x) /∈ H, the projection PSf (x) := (cid:80)

|θm(cid:105)(cid:104)θm| =

P :=

L
N

m=1

n=1

P minimizes the distance to the projected state [19].

In contrast, for a
j f (xj) θj (x) is not an or-
thogonal projection, but rather the sampling pseudo-projection, or collocation
projection.
The FG and its associated spectral and pseudo-spectral bases are just one
possible choice for the phase space underlying PvB. See [20, 21, 22] for alter-
native possibilities.

|ϕn(cid:105)(cid:104)ϕn| .

(4)

2.1.2. The von Neumann lattice and its projection onto the Fourier grid

(PvN)

Consider the inﬁnite von Neumann lattice [7, 23, 8] of Gaussians in the (x, p)
plane. Let (¯xi, ¯pi) indicate the center of Gaussian i, and let (∆x, ∆p) be the
spacing between the lattice sites. We deﬁne

(cid:18) 1

(cid:19)1/4

2πσ2
x

(cid:32)

(cid:18) x − ¯xi

(cid:19)2

2σx

+

(cid:33)
 ¯pi(x − ¯xi)

i

exp

−

g¯xi,¯pi(x) :=

.

(5)

The representation of a state as a linear combination of the above Gaussians
converges poorly [9, 24]. To overcome this problem, we truncate the von

6

Neumann lattice to a ﬁnite domain of size Nx×Np = N, project the Gaussians
onto the FG, and reformulate them in a cyclic fashion,

(6)

L

with modLx := x − L(cid:4) x

gmod
¯xi,¯pi

(x) := (Qg0,0(modL (x − ¯xi)) e

(cid:5). Thus, we achieve convergence properties equiv-

i ¯pi modL(x−¯xi).

alent to the FG [4]. The cyclic projected Gaussians, known as the Periodic
von Neumann or PvN basis, are periodic Gabor functions, admit a general-
ized version of the Fast Fourier Transform [25]. For the conditioning of the
overlap matrices (eq. 12), it is beneﬁcial to choose the von Neumann lattice
points such that ¯xi are a subset of the FG sample points and ¯pi are a subset
of the spectral basis frequencies.
The PvN basis in the Θ representation is

or in Dirac notation:

(cid:12)(cid:12)gmod

¯xk,¯pk

(cid:11) =

Gjk := gmod
¯xk,¯pk

(xj).,

|x(cid:105)(cid:104)θm| g¯xk,¯pk(cid:105) ≈ N(cid:88)

m=1

N(cid:88)

m=1

|θm(cid:105)(cid:104)θm| g¯xk,¯pk(cid:105) .

(7)

(8)

The FG deﬁnes an area of (2K) L = 2πN in phase space. Therefore one may
informally assign a phase space area of 2π to each of the N Gaussians of the
PvN basis, and consider them “phase space pixels”. Deﬁning P := K, each
such pixel covers a phase space area of 2π = h.

2.1.3. Biorthogonal bases

In this section we consider the general theory of non-orthogonal bases and
their biorthogonal bases. In the next section we will specialize to the periodic
von Neumann basis and its biorthogonal basis. In anticipation of that section,
we use the notation G and B here.
Any set of N linearly independent vectors G = {|gk(cid:105)}N
k=1 in H may serve
as a non orthogonal basis of H. Let G be represented in the Θ orthogonal
basis of H by the invertible matrix G. Let B be a similarly deﬁned non-
orthogonal basis of H, represented in Θ by B. The bases G and B are

7

considered biorthogonal bases (a reciprocal relationship) if

G†B = 1N ⇐⇒ (cid:104)gk| bj(cid:105) = δkj.

G is the left pseudo-inverse of B (and vice versa)

B† ⇐⇒ B = G(cid:0)G†G(cid:1)−1

G† =(cid:0)B†B(cid:1)−1
BG† = 1N ⇐⇒ (cid:80)

j |bj(cid:105)(cid:104)gj| = 1.

(9)

(10)

.

One may show that G and B also satisfy the completeness relation

(11)
Deﬁne S and S−1 as the overlap matrices of the G and B bases, respectively,

S := G†G,
S−1 = B†B,

G = BS,
B = GS−1,

(cid:126)ψB = S (cid:126)ψG,
(cid:126)ψG := S−1 (cid:126)ψB.

(12)

Any |ψ(cid:105) ∈ H, with (cid:126)ψ being its pseudo-spectral representation, may be ex-
pressed in B as

(13)
with ψ = B (cid:126)ψB. One may therefore consider G† to represent the bras {(cid:104)gk|},
while B represents the kets, {|bj(cid:105)}. Norms of vectors in B and G are com-
puted via (cid:107)ψG(cid:107)2 = (cid:126)ψ†
GS (cid:126)ψG and (cid:107)ψB(cid:107)2 = (cid:126)ψ†
BS−1 (cid:126)ψB. Note that the G and
B bases cannot be independently normalized.

(cid:126)ψB := G† (cid:126)ψ,

2.1.4. BvN - The basis biorthogonal to PvN

Many wavefunctions of interest, whether bound states or traveling wavepack-
ets, are fairly well localized in phase space. Therefore a representation whose
coeﬃcients are βk = (cid:104)gk| ψ(cid:105), is expected to be sparse, i.e. to have many
near-zero elements.
Any state |ψ(cid:105) ∈ H can be represented in the Periodic von Neumann (PvN)
basis as

|ψ(cid:105) =

|gj(cid:105)(cid:104)bj|

|ψ(cid:105) =

(cid:104)bj| ψ(cid:105)|gj(cid:105).

(14)

(cid:32) N(cid:88)

(cid:33)

N(cid:88)

j=1

j=1

8

Figure 1: Gaussian function (red dashed) and its biorthogonal b function (blue). Note
that b is highly non-local, non-smooth and non-monotonic.

Alternatively, it may be represented in the BvN basis as

(cid:32) N(cid:88)

|ψ(cid:105) =

(cid:33)

N(cid:88)

|bj(cid:105)(cid:104)gj|

|ψ(cid:105) =

(cid:104)gj| ψ(cid:105)|bj(cid:105).

(15)

j=1

j=1

The PvN and BvN bases span exactly the same Hilbert space as the spec-
tral and pseudospectral bases and contain the identical number of functions.
Therefore there is no ambiguity or redundancy, and no loss of information.
Note that although the |g(cid:105) states are localized in phase space, the |b(cid:105) states
are highly delocalized, as can be seen in ﬁg. 1. As a result, the representation
in the BvN basis, eq. 15, is sparse since the localized (cid:104)g| bras determine the
coeﬃcients, while the representation in the PvN representation, eq. 14, is
not sparse since the delocalized (cid:104)b| bras determine the coeﬃcients. See ﬁg.
2 for an illustrative example.
From this point onward, we shall assume all states are in H and use the
discrete Θ representation. We will therefore drop the explicit vector notation,
e.g. in the states (cid:126)ψ and (cid:126)ψB.

2.1.5. The Schrödinger equation in PvB

In the PvB representation, the time independent and time dependent Schrödinger
equations (TISE and TDSE, respectively) take the forms,

(16)

(cid:0)G†HB(cid:1) ψB = λψB.

9

Figure 2: Top left: a Gaussian in the PvB representation shown as a heat map (logarithmic
color scale). Top right: the same as left but shown as a bar plot. The value plotted in
each cell of the von Neumann lattice is the absolute value of the overlap of the state with
the Gaussian centered at that cell of the lattice,
Gaussians is non-vanishing, as is apparent from the amplitude of the bars 2 . . . 5 (purple in
the top right plot). The bottom plots detail how the Gaussian wavefunction is accumulated
from weighted |b(cid:105) functions. Note the counterintuitive result that a smooth Gaussian is
expressed by a small sum of non-smooth non-local functions.

(cid:12)(cid:12)(cid:12) ψ(cid:105)(cid:12)(cid:12)(cid:12). The overlap of neighboring

10

(cid:12)(cid:12)(cid:12)(cid:68)

g¯xj ,¯kj

xk  −10−8−6−4−20246810−10−8−6−4−202468101e−082.38e−085.66e−081.35e−073.45e−078.2e−071.95e−064.64e−061.1e−052.63e−056.25e−050.000160.0003810.0009050.002150.005130.01220.0290.07420.1770.421−9.41−7.06−4.71−2.3502.354.717.069.41−10.7−8.01−5.34−2.6702.675.348.0110.700.20.40.60.81X−X0893541672K−K0-20020-0.200.20.4Gaussian 1c=1-20020-0.200.20.4Gaussian 2c=0.21-20020-0.200.2Gaussian 3c=0.21-20020-0.100.10.20.3Gaussian 4c=0.21-2002000.10.20.3Gaussian 5c=0.21-2002000.10.20.3Gaussian 6c=-0.043-2002000.10.20.3Gaussian 7c=-0.043-2002000.10.20.3Gaussian 8c=-0.043-2002000.10.20.3Gaussian 9c=-0.043-2002000.10.20.3Gaussian 10c=0.0019and

(cid:0)G†HB(cid:1) ψB.

∂tψB = − i


(17)
The term G†HB = B−1HB is a similarity transformation of H and therefore
all eigenvalues are real and all evolutions are unitary. The TISE, eq. 16, may
be rephrased as a generalized eigenvalue problem,

(cid:0)B†HB(cid:1) ψB =(cid:0)B†B(cid:1) λψB.

(18)

One may rewrite the TDSE in four distinct ways, all strictly equivalent. We
denote a Hamiltonian taking a state in basis X and returning a state in basis
Y by HY X,

G†HB = B−1HB =: HBB
B†HB = G−1HB =: HGB
G†HG = B−1HG =: HBG
B†HG = G−1HG =: HGG

−→ ∂tψB =
− i
 HBB ψB ,
−→ ∂tψB =
− i
 S HGB ψB ,
−→ ∂tψB = − i
 HBG S−1 ψB ,
−→ ∂tψB = − i
 S HGG S−1 ψB .

(19)
Although the forms are mathematically equivalent, they require diﬀerent
computational eﬀorts. For example, G†HG is quick to compute as the inte-
grations on both sides are with the highly-local Gaussians. This is counter-
balanced by the need to compute S−1.

2.2. PvB as a similarity transformation

PvB may be reformulated as a similarity transformation from the pseudospec-
tral basis to the non-orthogonal B basis, without explicitly referring to the
G basis. This allows a natural extension of PvB to density matrices and op-
erators, which in turn clariﬁes the connection between PvB and the discrete
versions of the Husimi and Wigner representations.

2.2.1. PvB expressed entirely in terms of B
The basis {|bj(cid:105)}N
j=1 is linearly independent and hence the B matrix is invert-
ible (see discussion in Section 2.1.3). Therefore, any state in the FG may be
converted to and from the B representation by

|ψB(cid:105) = B−1|ψ(cid:105) ⇐⇒ |ψ(cid:105) = B|ψB(cid:105).

(20)

11

Requiring (cid:104)ψB| ψB(cid:105) = 1, and considering eq. 20 suggests that the bra trans-
forms as

(cid:104)ψB| = (cid:104)ψ| B.

(21)
Substituting eq. 20 into the TDSE and multiplying on the left by B−1, we
arrive at i∂t|ψB(cid:105) = B−1HB|ψB(cid:105). This indicates that the Hamiltonian is
converted to the B basis via a similarity transform

HBB = B−1HB,

i∂t|ψB(cid:105) = HBB|ψB(cid:105).

Any density matrix ρ may be expanded as ρ = (cid:80)
eq. 20 and 21, ρ transforms via ρ =(cid:80)

(22)
k pk|ψk(cid:105)(cid:104)ψk|. Utilizing
k (B|ψB,k(cid:105)) ((cid:104)ψB,k| B−1) = BρBBB−1,

giving

ρBB = B−1ρB.

(23)

The equation of motion remains unchanged, i.e. i∂tρBB = [HB, ρBB]. Other
operators transform similarly, OB = B−1OB, as do their respective equations
of motion.

2.2.2. Connection to the Husimi and Wigner representations

The Husimi phase space representation of the density matrix at location
(x0, p0) is deﬁned as [26].

Q (x0, p0) = (cid:104)gx0,p0| ρ|gx0,p0(cid:105) .

(24)

The Husimi representation may alternatively be deﬁned as a Gaussian ﬁlter
applied to the Wigner representation [27]:

ˆ ˆ

Q (x0, p0) =

W (y0, q0) e

−2((x0−y0)2+(p0−q0)2)dy0dq0.

(25)

Somewhat counterintuitively, despite this Gaussian ﬁlter it can be shown to
be informationally equivalent to the Wigner representation [28, 29].

12

Both the Husimi and Wigner representations are complete and consistent
representations of quantum mechanics [30, 31]. Expanding on ideas in [32]
we observe the following: from eqs. 7 and 13, we know that an element of the
vector ψB associated with the Gaussian centered at (¯xk, ¯pk) is (cid:104)g¯xk,¯pk| ψ(cid:105). For
a pure state density matrix, using eq. 23 ρBB = |ψB(cid:105)(cid:104)ψB|, and therefore the
(k, k) element of the density matrix will be |(cid:104)g¯xk,¯pk| ψ(cid:105)|2. This is identical to
the value of the Husimi representation of ψ at this point, eq. 24. Thus, the
Husimi representation can be viewed as the intensity associated with |ψB(cid:105),
deﬁned not only at the von Neumann lattice points, but for continuous values
of x and p.
For arbitrary density matrices, PvB may be rewritten as the discrete version
of eq. 23

ρBB =(cid:10)gxi,pj

(cid:12)(cid:12) ρ(cid:12)(cid:12)bxk,pl

(cid:11) .

(26)

Note the diﬀerence from eq. 24. In light of the discussion in Section 2.1.5,
we may view ρBB (eq. 26) as similar in structure to G†HB (eq. 19), whereas
Husimi’s Q (eq. 24) is similar to G†HG (again, eq. 19).

2.3. The reduced Hilbert space

2.3.1. Deﬁning the reduced Hilbert space, (cid:101)H
As discussed above, if the state |ψ(cid:105)B that we are trying to represent is local-
ized in phase space, it will have signiﬁcant overlap with only a small number
be negligible. We therefore deﬁne a reduced Hilbert subspace, (cid:101)B, spanned by
of the localized Gaussians. As a result, many of the coeﬃcients of |ψ(cid:105)B will
a subset of the |b(cid:105) vectors, whose coeﬃcients are all above some predeﬁned
space, (cid:101)G, and in Section 2.3.3 the projector into this space.
threshold. In Section 2.3.2 we deﬁne the biorthogonal basis for this reduced
nience, let us assume the ﬁrst (cid:101)N coeﬃcients in ψB are signiﬁcant, while the
remaining N − (cid:101)N are negligible. In such a case, we can save computational
(cid:101)N (cid:28) N.
resources by reducing the vector ψB of length N to a vector ψ(cid:101)B of length

Consider a Hilbert space of dimension N spanned by the orthogonal pseu-
dospectral basis Θ (eq. 2) and a set of biorthogonal bases B, G, represented
in Θ by the matrices, B and G (eq. 7,10). For the sake of notational conve-

13

Deﬁne the reduced subspace, (cid:101)H ⊆ H as the Hilbert space spanned by the ﬁrst
(cid:101)N vectors of B, (cid:101)B,

.

(27)

Deﬁne the complementary subspace, ¯H, by

(cid:17)

(cid:101)H = span

(cid:16){|bj(cid:105)}(cid:101)N
H = (cid:101)H ⊕ ¯H ,

j=1

= 0, and

(cid:12)(cid:12)(cid:12)(cid:101)ψ
(cid:69)

the complementary state.

(cid:12)(cid:12)(cid:12)(cid:101)ψ
(cid:69) ∈ (cid:101)H,(cid:12)(cid:12) ¯ψ(cid:11) ∈ ¯H, where

(28)
requiring that every vector in the complementary subspace ¯H be orthogonal

to every vector in the reduced subspace, (cid:101)H. As the B basis is non-orthogonal,
(cid:16){|gk(cid:105)}N
(cid:17)
there is no partitioning of the B functions that spans both subspaces. How-
(cid:12)(cid:12)(cid:12)(cid:101)ψ
(cid:69)
+(cid:12)(cid:12) ¯ψ(cid:11) s.t.
k=(cid:101)N +1
ever, the complementary space may be spanned by ¯H = span
.
(cid:12)(cid:12)(cid:12) ¯ψ
(cid:68)(cid:101)ψ
(cid:69)
is the reduced state and(cid:12)(cid:12) ¯ψ(cid:11)
Given any state |ψ(cid:105) ∈ H, we may therefore decompose |ψ(cid:105) =
2.3.2. Biorthogonal bases for (cid:101)H
denote the ﬁrst (cid:101)N columns of the B matrix with the matrix (cid:101)BN×(cid:101)N, i.e. (cid:101)B
is the Θ representation of the basis deﬁning (cid:101)H. (cid:101)G will be deﬁned as a basis
that is biorthogonal to (cid:101)B, and spans the same Hilbert space as (cid:101)B. In [13] we
show that both requirements are satisﬁed by the right pseudo-inverse of (cid:101)B†,
We stress that (cid:101)B is the natural basis of (cid:101)H, while (cid:101)G is deﬁned in terms of
(cid:101)B. As will be seen in the following section, the columns of (cid:101)G are no longer

We now turn to the biorthogonal bases for the reduced subspace. Let us

(cid:17)−1

(cid:16)(cid:101)B†(cid:101)B

(cid:101)G := (cid:101)B

exactly the projected Gaussians, but have been deformed as the result of the
basis reduction. The overlap matrices in the reduced subspace are

(29)

(cid:17)−1

(cid:16)(cid:101)B†(cid:101)B

(cid:101)S :=

(cid:101)S−1 = (cid:101)B†(cid:101)B =
from which it follows that (cid:101)G = (cid:101)B(cid:101)S and (cid:101)B = (cid:101)G(cid:101)S−1.

= (cid:101)G†(cid:101)G,

(cid:17)−1
(cid:16)(cid:101)G†(cid:101)G

,

(30)

We may also deﬁne the basis for the complementary Hilbert space ¯H with

,

14

here ¯G, not ¯B, is the natural basis. This is because the functions in ¯G, not

¯GN×(N−(cid:101)N) as the last N − (cid:101)N columns of G, and ¯B := ¯G(cid:0) ¯G† ¯G(cid:1)−1. Note that
¯B, are orthogonal to the functions in (cid:101)B.
2.3.3. Projecting into (cid:101)H
Consider the projector from the unreduced H to the reduced (cid:101)H. This may

be written in two alternate forms:

In the Θ representation (i.e. both input and output are represented on the

(cid:12)(cid:12)(cid:12)(cid:101)gj
(cid:69)(cid:68)(cid:101)bj
Fourier grid, (cid:101)P is given by the idempotent matrix
In [13] we showed that the (cid:101)G vectors spanning the reduced basis are the

(cid:101)P := (cid:101)B(cid:101)G†.

(cid:101)P :=

(cid:12)(cid:12)(cid:12)(cid:101)bj

(cid:69)(cid:68)(cid:101)gj

(cid:12)(cid:12)(cid:12) =

(cid:101)N(cid:88)

j=1

(cid:101)N(cid:88)

j=1

(cid:12)(cid:12)(cid:12) .

projection of the G vectors into the reduced subspace, and

(31)

(32)

(33)

|(cid:101)gk(cid:105) = |gk(cid:105) − N(cid:88)
j=(cid:101)N +1

(cid:104)gj| gk(cid:105)(cid:12)(cid:12)¯bj

(cid:11) ∀k ≤ (cid:101)N .

This provides insight into the deformation of the Gaussians due to the basis
reduction, as depicted in ﬁg. 3. The deformation is the result of the sub-

traction of(cid:12)(cid:12)¯b(cid:11) vectors, weighted by the overlap of the Gaussians inside the

reduced subspace with the Gaussians spanning the complementary space.
This clariﬁes why Gaussians at the boundary of the reduced subspace are
modiﬁed more — they have a larger overlap with Gaussians outside the re-
duced subspace.
When projecting from the full to the reduced Hilbert space, the projector
takes diﬀerent forms depending on the source and target representations.

Denote by (cid:101)PY X the projection operator from the full Hilbert space H into
the reduced subspace (cid:101)H, where the Fourier grid representation of the input
basis for H is the matrix X, and the Fourier grid representation for (cid:101)H is

the matrix Y . The projection operator transforms as do all operators, using

15

PY X = Y −1P X (when Y is not square, Y −1 should be taken to be the left

pseudo-inverse of Y ). For example, using (cid:101)B = BR, the projector (cid:101)P(cid:101)GG takes

the form R†, with



1

0

0
1
...
...
0 . . .
0
0
...

0
...
0

0

0
...
...
0
. . .

...
. . .

. . .
...
0
1
0

0
...
0



RN×(cid:101)N :=

(34)

(35)

(36)

(37)

[13]. Figure 4 shows graphically how the transformation between these dif-
ferent representations can be combined in a wide variety of diﬀerent ways.

2.4. The Hamiltonian and the Schrödinger equations for the reduced state

The Schrödinger equation for the reduced state requires projecting the Hamil-
tonian into the reduced subspace. To arrive at the reduced Hamiltonian, we

apply the (cid:101)P projection on both the input and output states of the Hamil-
tonian operator. As the state is represented in the (cid:101)B basis, one can either
convert the vector to Θ, project into (cid:101)H, apply H, project the resulting state
again into (cid:101)H, and transform it to (cid:101)B, or, equivalently, ﬁrst apply the projec-

tion and then the base transformation. These two alternatives correspond to
the following two expressions for H1:

H1 := (cid:101)G†(cid:16)(cid:101)P H(cid:101)P
H1 = (cid:101)G†H(cid:101)B =

(cid:17)(cid:101)B = (cid:101)P(cid:101)BB
(cid:16)(cid:101)B†(cid:101)B

(cid:0)G†HB(cid:1)(cid:101)PB(cid:101)B.
(cid:17)
(cid:17)−1(cid:16)(cid:101)B†H(cid:101)B

.

and

The TISE and TDSE then take the form

Eψ(cid:101)B = H1ψ(cid:101)B

16

Figure 3: Depiction of modiﬁed Gaussians associated with the reduced basis. The reduced

basis is the non-gray area in both plots. On the left, the modiﬁed Gaussian (cid:101)g, which is

centered around a non-edge location in the phase space, is almost unchanged. On the
right, we see a heavily deformed Gaussian, whose center is close to the reduced subspace
boundary. The ˜G basis is modiﬁed by a projection of the G functions into the subspace
spanned by ˜B. The states are plotted as heat maps, where the value of each cell of the
von Neumann lattice is the absolute value of the overlap of the state plotted (here the
modiﬁed Gaussians), with the Gaussian centered at that cell of the lattice,

g¯xj ,¯kj

(cid:12)(cid:12)(cid:12)(cid:68)

(cid:12)(cid:12)(cid:12)(cid:101)g(cid:105)(cid:12)(cid:12)(cid:12).

17

Figure 4: Transformations and projections from continuous wavefunctions, ψ(x) (center),
to the Hilbert space spanned by the Fourier grid (inner circle) and the reduced subspace
(outer circle). Dashed arrows indicate a projection (surjective; with information loss),
continuous arrows are injective (one-to-one but not necessarily on-to) mappings. In the
PvN representation, states are described as a sum of g’s, which serve as the kets, while b’s

serve as the bras. In the PvB representation the roles are reversed. The nomenclature (cid:101)PY X
is used to indicate the projection from representation X of H into representation Y of (cid:101)H.
This diagram may be used, to construct (cid:101)P(cid:101)BB for example, by going through the following
(2) projecting with R†, (3) transforming back to (cid:101)B using (cid:101)S, (4) transforming to base B
using R. Multiplying the matrices appearing from right to left gives (cid:101)PBB = R(cid:101)SR†S−1.

series of transformations: (1), from the B basis to G using the transformation matrix S−1,

Note that although we return to the same point from which started, the resulting operation
is not equal to 1 because of the loss of information in the projection in step (2).

18

∂tψ(cid:101)B = − i

 H1ψ(cid:101)B.

(38)

Eq. 36, 37 and 38 will be the key working equations for the remainder of this
manuscript.

The formulation using only (cid:101)B matrices (r.h.s. of 36) is appealing, as (cid:101)B = BR
is the naturally reduced matrix in (cid:101)P .
(cid:17)−1 (cid:101)B†(cid:19)(cid:16)(cid:101)B
(cid:17)

Note that H1 is similar to a Hermitian matrix, in that the product of matrices
to the left and right of H in eq. 36 produce the identity,
1. Therefore the eigenvalues are real and the evolution is unitary. Moreover,
combining eq. 36 and 37 the TISE may be reformulated as a generalized
eigenvalue equation with Hermitian matrices,

(cid:18)(cid:16)(cid:101)B†(cid:101)B

=

(cid:17)

(cid:16)(cid:101)B†(cid:101)B

λψ(cid:101)B =

(cid:16)(cid:101)B†H(cid:101)B

(cid:17)

(39)

ψB,

thus avoiding the matrix inversion required to compute (cid:101)S. This form is

solvable with an iterative eigensolver, such as Arnoldi. Unfortunately, in this
form it is not possible to restrict the solver’s operations to the more eﬃcient
matrix-vector (i.e. operator-state) multiplications.
While accurate and mathematically rigorous, computing the H1 form in
eq. 36 is time consuming. Most signiﬁcantly, calculation of elements of

the reduced Hamiltonian (cid:101)B†H(cid:101)B can be laborious, particularly in the multi-

dimensional case, as the B functions are non-localized. Fortunately, there
are symmetry considerations and numerical techniques which can accelerate
this computation by several orders of magnitude, discussed at length in the
following section. Alternatively, using eqs. 36, 12 and 30, one may rewrite
H1 as

H1 = (cid:101)S(cid:0)R†S−1G†HGS−1R(cid:1) .

(40)
Eq. 40 may be quicker to compute then 35: due to the locality of G and the
fact that elements of H are usually functions of either position or momentum
(but rarely both), the vast majority of G†HG elements are vanishingly small.
Note that G and S−1 decompose dimensionally. Indeed, one would still have

to calculate (cid:101)S, which requires the inversion of (cid:101)B†(cid:101)B, but this may be acceler-

ated if one is able to store the matrix. If we then use an iterative algorithm
for solving the TISE (e.g. Arnoldi) and the TDSE (e.g. Taylor propagator),

19

one may use only matrix-vector type operations to further accelerate the
process. Similar considerations have been noted in [22].
There are several possible approximations to 38. These are discussed in detail
in [13].

3. Practical considerations and Algorithms

The task of computing the reduced Hamiltonian, H1,

H1 = (cid:101)G†H(cid:101)B =

(cid:16)(cid:101)B†(cid:101)B

(cid:17)−1 (cid:101)B†H(cid:101)B,

(41)

(eq. 35), for multi-dimensional systems can be computationally expensive.
As the reduced basis is adapted dynamically throughout the computation,
H1 must be updated on-the-ﬂy. It is therefore vital that this computation
be performed as eﬃciently as possible.
In Section 3.1 we discuss several
techniques to accelerate this computation, each of which provides over an
order-of-magnitude improvement over the naive approach. Algorithms for
solving the TISE and TDSE, which utilize the ideas presented in Section 3.1,
are discussed in Sections 3.2 and 3.3, respectively.

3.1. Evaluating the reduced Hamiltonian

Computing multi-dimensional Hamiltonians that include the factor (cid:101)B†H(cid:101)B,

(cid:16)(cid:101)B†(cid:101)B

as per eq. 36 may be signiﬁcantly accelerated by decomposing the Hamil-
tonians into a sum of products of one dimensional Hamiltonians. This is
discussed in Section 3.1.1. Further speed-up may be achieved by an iterative
of eq. 36, described in Sec-
update scheme for the inverse matrix
tion 3.1.2. By utilizing the symmetries in the Hamiltonian, and symmetries
inherent to Gabor functions G and B, better than an order-of-magnitude
reduction in computational costs is possible, as detailed in Section 3.1.3.
On top of these, the process of computing new Hamiltonian matrix elements
lends itself to parallelization - both in a multi-core and multi-machine con-
ﬁguration, which further accelerates the process.

(cid:17)−1

20

The cells in phase space will be labeled by their 2 × d × Np phase space
coordinates.

3.1.1. Decomposition of the Hamiltonian into a sum of one dimensional prod-

ucts (POTFIT)

The conversion of the Hamiltonian from the pseudo-spectral representation

(as approximated by sampling) to the reduced (cid:101)B basis can be broken down
the computation of (cid:101)S =

into two parts: ﬁrst, the construction of the Hamiltonian matrix, and second
. In this section we shall concentrate on

(cid:16)(cid:101)B†(cid:101)B

(cid:17)−1

the former, and in the next section on the latter.
In general, H may be written as a sum of terms, some of which depend on a
single Degree of Freedom (DoF) such as linear momentum 2k2
2m , and some of
which depend on multiple DoF such as the Coulomb potential

x

(cid:0)(x1 − x2)2 + (y1 − y2)2 + (z1 − z2)2(cid:1)− 1

2 .

q1q2
4π0
Single DoF terms are easy to compute. As they are functions of either x
or k (but not both), the relevant Hamiltonian term is diagonal in either the
†
jHbk for
pseudospectral or spectral bases, and therefore the multiplication b
such terms requires only vector-vector operations. However, to convert the

terms depending on multiple DoF to (cid:101)B would require multi-dimensional in-

tegration, which may be extremely costly. We would therefore like to replace
the multi-DoF terms with a sum of products of one-dimensional terms.
Most often, the non-decomposable parts of the Hamiltonian are the particle-
particle interaction terms. We therefore seek a decomposition of the multi-
dimensional interaction tensor as

V (x1, x2 . . . xN ) =

m1(cid:88)

. . .

mn(cid:88)

j1=1

jN =1

cj1...jN (t) V (1)
j1

(x1) ⊗ . . . ⊗ V (N )

jN

(xN )

(42)

with the single-particle potential vectors, V (k), normalized and c representing
the magnitude of each term. The problem of ﬁnding an optimal decompo-
sition (with minimal possible error for any number of terms) is an open
problem, and outside the scope of this work. For our purposes, we shall

21

utilize the POTFIT algorithm [33, 34], which is optimal for two degrees of
freedom and applicable generally.

The reduced basis is updated dynamically as the static and dynamic algo-
rithms progress (Sections 3.2 and 3.3.1). Since the number of cells added or

3.1.2. Updating (cid:101)S
removed from the overlap matrix (cid:101)S in each iteration is relatively low com-
pared to the number of elements already in (cid:101)S, one may save signiﬁcantly on
computational eﬀort by updating (cid:101)S to account for the change, rather than
When adding (cid:102)M (cid:28) (cid:101)N rows and columns to the existing (cid:101)N × (cid:101)N matrix (cid:101)S, we
below the existing elements. If (cid:101)S−1 is available from a previous iteration, the
expanded matrix’s inverse, which we shall term (cid:101)Z−1, may be computed by
(cid:33)
(cid:32) (cid:101)S−1 + F (2)C†(cid:101)S−1 −F (2)

shall reorder matrix indexes such that the new elements are to the right and

recomputing it from scratch.

(cid:33)−1

[35]

(cid:32) (cid:101)S(cid:101)N×(cid:101)N C(cid:101)N×(cid:102)M
D(cid:102)M×(cid:102)M
†(cid:102)M×(cid:101)N

C

(cid:101)Z−1
((cid:101)N +(cid:102)M)×((cid:101)N +(cid:102)M)

=

=

F (1)C†(cid:101)S−1

(43)

F (1)

where

Note that at no point do we invert a matrix of dimension (cid:101)N, and that all
matrix multiplications include at least one dimension (cid:102)M (cid:28) (cid:101)N.
The inverse operation - removing (cid:102)M rows and columns (which, after appro-

priate reordering, may be assumed to be on the right and below the elements

(cid:16)

D − C†(cid:101)S−1C
:= (cid:101)S−1CF (1).

:=

F (1)(cid:102)M×(cid:102)M
F (2)(cid:101)N×(cid:102)M

(cid:17)−1

,

(44)

(45)

22

(cid:101)Z−1
((cid:101)N +(cid:102)M)×((cid:101)N +(cid:102)M)

=

†

(cid:33)

(cid:32) WS,(cid:101)N×(cid:101)N WC,(cid:101)N×(cid:102)M
WD,(cid:102)M×(cid:102)M
C,(cid:102)M×(cid:101)N
(cid:101)S−1 = WS + WCW −1

†
D W
C

W

.

(46)

(47)

remaining), divides the larger, previously known, (cid:101)Z−1 into four blocks

From eq. 43, 44 and 45 we derive

In typical dynamics computations, there are two or three orders of magnitude

separating (cid:102)M and (cid:101)N. The above scheme provides a better than order-of-

magnitude acceleration in updating the inverse vs.
scratch.

re-computing it from

3.1.3. Utilizing symmetries in the Hamiltonian and the Gabor basis
The G basis is Gabor (eq. 6). If we choose the von Neumann lattice points to
be a subset of the FG sample points (x) and spectral frequencies (k), then the
discrete G and B matrices are also Gabor, and therefore highly symmetric.
Moreover, there are multiple symmetries within each of the Hamiltonian
matrix elements, resulting in multiple cells of the reduced Hamiltonian having

identical values. This may be utilized to accelerate computation of (cid:101)B†H(cid:101)B

by more than an order of magnitude.
Let us consider a single term in a Hamiltonian which has been decomposed
into a sum of products of one-dimensional terms. In practice, as most such
terms in the Hamiltonian stem from a POTFIT decomposition of multi-
dimensional interaction potentials (see Section 3.1.1), we will focus on V (x)-
type terms.

For purposes of the following discussion, the columns of the (cid:101)B matrix shall
coordinates. Similarly, we shall view (cid:101)B†H(cid:101)B as a 4-dimensional phase space

be enumerated not by a single number, but by their phase space lattice

tensor (see Section 3.1). Gabor basis functions have a momentum dependence

23

of the form eikβ mod L(x−xα). Therefore

(cid:16)(cid:101)B†V (cid:101)B

(cid:17)

(cid:88)

xαkβ xγ kδ =

B∗

−i(kδ−kβ) mod L(xα−xγ ) (cid:88)

xm∈F.G.

xαkβ

= e

(xm) V (xm) Bxγ kδ (xm)

xm∈F.G.

xαk0 (xm) V (xm) Bxγ k0 (xm) ei(kδ−kβ)xm.
B∗

(48)

In principle, treating the kinetic term T is similar, with the roles of x and

Note the dependence is only on kδ − kβ, and not on the individual momenta.
Moreover, if there are symmetries in V , which there often are (e.g. particle
exchange symmetry in the Coulomb potential), these too can be taken into

account. Finally, (cid:101)B†H(cid:101)B is Hermitian, providing an additional symmetry.
p exchanged. Therefore, in many instances the value of the (cid:101)B†H(cid:101)B cell has
cal phase space coordinate for each (cid:101)B†H(cid:101)B cell with the same value. For
example we address (cid:101)B†H(cid:101)B cells by

already been computed previously.
We incorporate these symmetries into the algorithm by creating a canoni-

, converting the
4D coordinate into a 1D linear coordinate for easy comparison. The above
methodology can be extended directly to the multi-dimensional case.

xj1 ,pk1−pk2 ,xj2 ,0

(cid:16)(cid:101)B†H(cid:101)B

(cid:17)

3.2. Statics: The eigenmode algorithm

Given a potential, the initial task is to ﬁnd its ground-state, and possibly
higher excited states. Since we do not have a priori information on the
eigenstate, we use an iterative process, starting with an initial guess at the
local minima of the potential. We then iteratively expand the subspace, until
the designated eigenmodes of the reduced Hamiltonian fall oﬀ to below the
prescribed amplitude at the boundary of the subspace. Note that no classical
considerations are used.
The TISE solving algorithm is as follows:

10 Define the initial reduced basis as the cells at the x-s of the
potential’s local minima, with k = 0.

24

20 Compute eigenmodes for the current reduced basis.

30 If everywhere on the boundary of the reduced basis, all eigenmode
cell amplitudes are below the specified accuracy threshold, stop.
If not, continue.

40 Remove all phase space cells where the amplitude is below the
wavefunction accuracy cutoff.

50 Expand the reduced basis to all neighboring cells (i.e.
at or below some distance r from the current reduced basis), and
compute the new entries of the now expanded, reduced Hamiltonian
matrix.

all cells

60 Go to 20.

A few additional comments:

• The radius of the reduced basis deﬁnes a 2 × d × Np-dimensional ball
associated with the local neighborhood of each phase space cell. In step
50 of the algorithm, we center this ball at each cell in the reduced basis
√
which is above the amplitude cutoﬀ, to determine the new, expanded,
2 (+ to
reduced basis. It has been our experience that a radius of
account for numerical noise), produces the most stable results.

• There is no need to fully diagonalize the reduced Hamiltonian in step
20, as often we are only interested in a few low-lying states. Therefore,
one may resort to the much-faster Arnoldi/Lanczos methods.

• In multi-dimensional systems, the unoptimized algorithm spends the
majority of its time computing elements of the reduced Hamiltonian
(step 50). See above for methods to accelerate this step.

• The algorithm above proves to be extremely stable, including cases of
multiple local minima. However, no proof of convergence is currently
known.

Finally, note that for the eigenvalue problem, there is no need to explic-

itly invert (cid:101)B†(cid:101)B. Instead, one may solve the generalized eigenvalue equation
(cid:101)B†H(cid:101)Bψ(cid:101)B = E

ψ(cid:101)B. as discussed in Section 2.4.

(cid:17)

(cid:16)(cid:101)B†(cid:101)B

25

3.3. Dynamics

3.3.1. Dynamics algorithm

A wavefunction’s evolution in time is continuous, and always proceeds only
to neighboring cells in the von Neumann lattice. Given an initial state in
a reduced subspace, one can modify the reduced subspace containing the
wavefunction on-the-ﬂy, adjusting it as the state evolves. This may be done
by monitoring the wavefunction amplitude at the phase space boundary of the
reduced space. If cells rise above the speciﬁed accuracy threshold, for example
at the “bow” of a traveling wave-packet, the reduced basis is expanded in
that region of the boundary. Conversely, as the amplitude falls below the
threshold at the wavepacket’s “stern”, vectors are removed from the reduced
basis.
Tunneling presents no problem to the method. The onset of tunneling is
apparent as motion through the barrier. The accuracy cutoﬀ is low enough to
avoid discarding the exponentially decreasing wavefunction amplitude inside
the classically forbidden area within the reduced subspace.
The algorithm is presented below. The choice of propagator for step 20 is
discussed in the following section.

10 Set the initial state (usually the ground state) and initial reduced
basis.

20 Propagate the reduced state with the reduced Hamiltonian for ∆t.

30 If everywhere on the boundary of the reduced state the amplitude
is below the specified accuracy threshold, go to 20.

If not, continue.

40 Remove all phase space cells where the amplitude is below the
accuracy threshold.

50 Expand the reduced basis to all neighboring cells (i.e.
at or below some distance r from the current reduced basis):
the additional elements of the now expanded reduced Hamiltonian.

all cells
Compute

60 Go to 20.

26

3.3.2. Time propagation
Until now we have focused on eﬃcient methods for evaluating H1 (eq. 41).
We now turn to evaluating the TDSE, eq. 38, i.e. choosing an eﬃcient prop-
agator given the unique features of PvB. Speciﬁcally, if one is propagating
a state in the reduced PvB basis, there is a need to modify the reduced ba-

sis as the wavefunction changes, and therefore to modify the (cid:101)S and (cid:101)B†H(cid:101)B

matrices (see eqs. 36 and 38). This in turn imposes limits of the duration
of the allowed time step, turning the task into a series of short-time propa-
gations. This subject is discussed in depth in Section 3.3.3. In the case of
time-varying control ﬁelds, where the Hamiltonian is composed of a drift and
control Hamiltonians, H (t) = Hd + Hc (t), the short-time step requirement
above suggests that we should approximate the time-dependent Hamilto-
nian by a series of piecewise constant Hamiltonians. This approximation is
valid given that by the very deﬁnition of the reduced subspace, we are re-
moving components of the state whose amplitude is below some pre-deﬁned
amplitude (e.g. 10−6). In conclusion, we are dealing with short time step
propagation, with a pre-deﬁned limit on required propagation accuracy.
Many propagators are possible in such a scenario, including split-operator,
Lanczos-type methods (e.g. Short Iterative Lanczos and Short Iterative
Arnoldi), Inverse-Free Lanczos and direct Taylor series expansion. Given
our need for a short-time propagation method, we have found the Taylor se-
ries expansion to be both the most eﬃcient and simplest to implement, with
clear and direct control over accuracy. Below is a detailed discussion of the
methods examined.

Split Operator
By prediagonalizing the control Hamiltonian, Hc = W1D1W −1
exponentiating the drift, U0 = exp (τ Hd), we may write (omitting − i
erywhere)

1

exp (τ (H0 + u1H1)) = W1eu1D1W −1

1 U0W1eu1D1W −1

Once the preliminary work is done, one may propagate the state, accounting
for a time-dependent u (t) without resorting to additional matrix exponenti-
ations or diagonalizations. However, within the reduced PvB framework, we

27

and pre-
 ev-

(49)

1 + O(cid:0)τ 3(cid:1) .

must redo the prediagonalization step at each basis change, drastically reduc-
ing its eﬃciency. Moreover, the split operator suﬀers from the accumulation
of the O (τ 3) error (see ﬁg. 5), which is expensive to mitigate by reducing τ.
Therefore the method is both inaccurate and slow for our purposes.

Lanczos-type methods

Krylov methods, such as Short Iterative Lanczos or Short Iterative Arnoldi,
rely on the construction, at each time step, of a small subset of the Hilbert
space called the Krylov space. The Krylov space is obtained by applying the
Hamiltonian to the state iteratively several times. Then, one exponentiates
the small Krylov Hamiltonian. The dimension of the Krylov space should be
adapted dynamically to maintain a constant accuracy.
Unfortunately, it is not possible to directly use a Lanczos-type algorithm

with PvB, as the eﬀective Hamiltonian to propagate, H1 = (cid:101)G†H(cid:101)B, is not

Hermitian, but only similar to a Hermitian matrix. Two resolutions are pos-
sible: ﬁrst, one may apply the Short Iterative Arnoldi (SIA) method, which
allows non Hermitian Hamiltonians. We have found the SIA method to be
comparable in accuracy and performance to the Taylor series expansion (be-
low). However, it is signiﬁcantly more complex to implement, and provides
no discernible advantage.

One may avoid the somewhat costly inversion of (cid:101)S by looking at the problem
as a generalized eigenvalue problem with a Hermitian (cid:101)B†H(cid:101)B Hamiltonian,

and utilizing the Inverse-Free Lanczos (IFL) method [36]. IFL replaces the
inversion in the Lanczos algorithm by a Cholesky decomposition (which is
slightly faster) and the upper triangular Hamiltonian of the Arnoldi algo-
rithm with a tri-diagonal Krylov Hamiltonian (which presents a linear sys-
tem requiring solution - a non trivial task). However, as the full inversion of

(cid:101)S is not required at every modiﬁcation of the reduced basis (Section 3.1.2),

IFL’s advantage is signiﬁcantly reduced.

Taylor series expansion

The simplest propagation method is the expansion of the exponential in a
Taylor series, which may be rephrased as a recursion series. Denoting the

28

k-th derivative of ψ w.r.t time by ψ(k), we have

ψ(0) = ψ (t)
ψ(k) =

Hψ(k−1)

τ
k

∞(cid:88)

k=0

ψ(t+τ ) =

ψ(k).

(50)

This method entails no matrix-matrix operations, but simply vector-matrix
multiplications. Moreover, for reduced PvB dynamics, we may formulate the
recurrence relation as

(cid:16)(cid:101)Hψ(k−1)(cid:17)

(cid:101)S

,

ψ(k) =

τ
k

(51)

thus avoiding the costly (cid:101)S(cid:101)H matrix-matrix multiplication, and replacing it
termined dynamically, by requiring that(cid:13)(cid:13)ψ(k)(cid:13)(cid:13) ≤  (cid:28) 1. Should the series

with two matrix-vector operations, which are signiﬁcantly quicker. Finally,
the order (number to terms) to which the Taylor series is computed is de-

extend beyond some reasonable limit (e.g. 30 terms), the propagator signals
the caller that the time step τ needs to be decreased (see Section 3.3.3) This
allows highly accuracy propagation with minimal computational resources,
and is our method of choice for PvB.

3.3.3. Multi-factor determination of dynamic time step for PvB evolutions

In order to achieve eﬃcient propagation of the state in the PvB scheme, one
needs to take three issues into account.

I. PvB dynamics will occasionally indicate that the reduced PvB basis
needs to be updated (expanded or reduced), which will necessitate a
change in the size of the state vector and computation of new elements

in (cid:101)B†H(cid:101)B before propagation can proceed. See Sections 3.3.1 and 3.1.

II. Most propagator methods, such as the Taylor series expansion, are

accurate and eﬃcient only up to a certain propagation duration.

III. Approximating the control signal by a piecewise constant function, the
propagation step may not exceed the bound dictated by the control

29

Figure 5: Comparison of propagator accuracy. Note that Adaptive Arnoldi, Taylor and
Inverse-free Lanczos all achieve excellent accuracy, while the split-operator suﬀers from

a non-trivial drift, stemming from the O(cid:0)τ 3(cid:1) error inherent to the method. Given these

equivalent accuracies, the simplicity of the Taylor propagator, and the ability to easily
control its accuracy (by dynamically varying both the number of terms in the series and
the time step), make it the method of choice for PvB propagation.

30

050100150200250300−16−15−14−13−12−11−10−9−8−7−6log(1 − Fidelity)Time (a.u.)  Adaptative ArnoldiTaylorInverse Free LanczosSplit Operatorsignal discretization, which in turn is determined by its derivative (see
below).

We therefore dynamically manage the propagation time step as follows:

I. A maximal time step is deﬁned based on the gradient of the control

signal. See discussion below.

II. If a cell that was added to the boundary during the previous time
step is found to be above the wavefunction amplitude cutoﬀ, ζ, after
the propagation step, the last propagation is cancelled, the time step is
reduced by a factor of 2 and then the propagation is redone. Conversely,
if after a small number of time steps there is no expansion of the basis,
then the time step is increased gradually (by 20%), subject to the limit
imposed by the discretization of the control pulse, above.

III. If the propagator concludes that the time step is too large for it to
perform the propagation accurately and eﬃciently (e.g. the number
of elements in the Taylor series reached 30), it signals the integration
loop, which then discards this propagation and redoes it with a smaller
integration interval (usually half the original time step).

Finally, as mentioned above, the maximal time step limit may be derived
from the discretization of the control signal. Taking as an example a P
(momentum) kick control ﬁeld,

(cid:20)

ˆ

T

(cid:21)

|ψ(cid:105) = exp

iT

(52)
with T indicating time-ordering, T (cid:28) 1 and Hc = P = i∂x. A ﬁrst order
approximation gives:

(Hd + u(t)Hc)dt

0

|ψ0(cid:105) ,

ˆ

|ψ(cid:105) ≈

0

which suggests the constraint:
ˆ

−UmKT ≤

0

T

u(t)∂xψ(x, t)dt|ψ0(cid:105) ,

T

u(t)∂xψ(x, t)dt ≤ UmKT ,

(53)

(54)

31

with K the maximum spatial frequency of ψ and Um = max|u|. As T (cid:28) 1
we can approximate Um ≈ T ∂tu(t) which ﬁnally produces the condition:

|ψmax(cid:105) − |ψmin(cid:105) = 2KT 2∂tu(t)|ψ0(cid:105) ≤ ζ ,

or a weaker but more useful condition:

(cid:115)

T ≤

ζ

2K maxt (∂tu(t))

.

(55)

(56)

For example, in the case of the one dimensional model of helium detailed in
4.2, for ζ = 10−4, K ≈ 0.2a.u. and maxt (∂tu(t)) ≈ 2.5, we obtain T ≈ 0.01
a.u.

4. Examples

4.1. Double-well potential

We now demonstrate the PvB method by applying it to the TISE for a
double-well potential. Speciﬁcally

(cid:18)(cid:16)x

d

(cid:17)4 − 2

(cid:16) x

(cid:17)2

(cid:19)

+ 1

,

d

V (x) = mω2b

(57)

where V (0) = b and the local minima are V (±d) = 0, and where m = 1,
ω = 1, b = 20 and d = 22. The Hamiltonian is H = p2
2m + V (x). The lowest
500 eigenmodes are computed using the algorithm in Section 3.2.
Figure 6 shows the eigenmode convergence process (left column) and the re-
sultant eigenmodes (right column). The iterative solution to the TISE begins
with the reduced phase space deﬁned as the local minima of the potential.
With each iteration the phase space can both expand and contract, as needed.
From high-amplitude cells it is iteratively expanded to neighboring cells, un-
til the eigenmode amplitude at the boundary falls below some predeﬁned
threshold. Cells with red x-s will be removed from the reduced space before
the next iteration, cells with green circles will be added to the reduced phase
space in the next iteration, and cells with blue dots will remain untouched.
The large low-amplitude (dark) area in the middle of the state is not pruned

32

Figure 6: Convergence process (left) and eigenmodes (right) for the symmetric double-
well potential. Left column contains 7 of 13 steps in the iterative solution of the TISE,
as detailed in Section 3.2. On the right we see 7 of the 500 eigenmodes computed, with
the blue and green lines denoting the classical energy contours at the eigenmode energy.
Gray area denotes phase space which is outside the reduced subspace. Color of each pixel
denotes the absolute value amplitude of the overlap of the von Neumann grid Gaussian

centered at the pixel and the eigenmode in question, i.e. (cid:10)gmod

33

(cid:12)(cid:12) ψ(cid:11).

¯xk, ¯pk

K = P/hbarConverging to eigenmode: ground+500, E=0, iteration 1, reduced base size: 2  −80−60−40−20020406080−40−30−20−100102030400.7070.7070.7070.7070.707K = P/hbarground state, E=0.286961, Reduced base size: 104  −80−60−40−20020406080−40−30−20−100102030401e−081.16e−081.79e−084.92e−081.14e−07K = P/hbarConverging to eigenmode: ground+500, E=9.32144, iteration 3, reduced base size: 50  −80−60−40−20020406080−40−30−20−100102030401e−085.3e−050.0003970.001090.00249K = P/hbar6th excited state, E=1.99289, Reduced base size: 142  −80−60−40−20020406080−40−30−20−100102030401e−081.01e−079.4e−071.46e−062.06e−06K = P/hbarConverging to eigenmode: ground+500, E=29.7286, iteration 5, reduced base size: 162  −80−60−40−20020406080−40−30−20−100102030401e−081.61e−081.73e−061.55e−054.98e−05K = P/hbar10th excited state, E=3.11387, Reduced base size: 146  −80−60−40−20020406080−40−30−20−100102030401e−082.05e−083.11e−084.14e−085.8e−08K = P/hbarConverging to eigenmode: ground+500, E=45.824, iteration 6, reduced base size: 242  −80−60−40−20020406080−40−30−20−100102030401e−081.36e−081.69e−084.09e−079.84e−07K = P/hbar51st excited state, E=13.4719, Reduced base size: 229  −80−60−40−20020406080−40−30−20−100102030401e−083.91e−085.33e−081.71e−074.48e−07K = P/hbarConverging to eigenmode: ground+500, E=197.462, iteration 11, reduced base size: 693  −80−60−40−20020406080−40−30−20−100102030401e−082.93e−083.5e−084.59e−081.54e−07K = P/hbar103rd excited state, E=23.7662, Reduced base size: 295  −80−60−40−20020406080−40−30−20−100102030401e−084.83e−081.11e−071.95e−064.55e−06K = P/hbarConverging to eigenmode: ground+500, E=193.551, iteration 12, reduced base size: 805  −80−60−40−20020406080−40−30−20−100102030401e−083.05e−089.48e−082.14e−075.65e−07K = P/hbar217th excited state, E=59.0011, Reduced base size: 364  −80−60−40−20020406080−40−30−20−100102030401e−086.63e−082.02e−074.14e−071.27e−06K = P/hbarConverging to eigenmode: ground+500, E=193.551, iteration 13, reduced base size: 765  −80−60−40−20020406080−40−30−20−100102030401e−086.54e−082.34e−071.09e−061.55e−06K = P/hbar498th excited state, E=192.437, Reduced base size: 512  −80−60−40−20020406080−40−30−20−100102030401e−088.21e−082.68e−075.6e−071.3e−06as it contains lower-lying states, which are computed concurrently, but not
plotted.
The right column depicts some of the resulting eigenmodes. Note the tran-
sition from a solution similar to two adjacent harmonic oscillators at lower
energies, to a single well solution at higher energies. Also note the correspon-
dence of the classical energy contours (green and blue lines) and the quantum
mechanically occupied phase space.
While the eigenmodes plotted are highly pixelated, intuitively suggesting a
lower accuracy solution, this is not the case. The eigenmodes of the potential
in question are well localized in phase space, and are accurately represented
within the Fourier grid chosen. The pixelization is just a visual feature of
the method, reﬂecting the size of the phase space basis functions. The only
approximation comes from the explicit cutoﬀ of the wavefunction amplitude
which deﬁnes the reduced subspace (here ζ = 10−6).

4.2. Helium double ionization

To demonstrate the power of the PvB methodology, we turn to an example
where the phase space hyper-rectangle required to bound the dynamics (the
Fourier grid) is far greater than the phase space volume which the state
occupies.
In such a scenario, the reduced phase space is many orders of
magnitude smaller than the unreduced Hilbert space. Speciﬁcally, we shall
look at the problem of multi-electron ionization.
The topic of multi-electron dynamics and its control have been of great in-
terest in recent years. This is largely due to progress made in the ﬁeld of
attosecond physics, speciﬁcally the availability of extreme-ultraviolet (XUV)
attosecond pulses [37] created via high harmonic generation with a high in-
tensity near-infrared (NIR) femtosecond laser pulse. As the natural timescale
of bound electrons is in the attosecond range [38], this opens up the possi-
bility of probing and manipulating both internal molecular dynamics and
atomic ionization processes. Subsequent studies utilized simultaneous NIR
and XUV pulses to control the dynamics [39, 40].
This problem remains a signiﬁcant numerical challenge, even for the smallest
multi-electron system, i.e. the helium atom. Strong NIR pulses populate high
angular momentum levels, making the use of hyperspherical based methods
ineﬃcient, while the traveling wavepackets of the ionized electron requires a

34

H =

(cid:32)

(cid:33)

+

1 + a2
0

2 + a2
0

(cid:113)

1

4π0

qeQ

very large spatial grid. In such scenarios, the PvB method demonstrates its
strength, requiring resources proportional only to the occupied area of phase
space.
In this work we shall only brieﬂy present the problem and show some sample
results of TDSE simulations. A detailed study of both concerted and sequen-
tial multi-electron ionization of helium using PvB will be published by the
authors separately [14].
Our benchmark system, the 1D helium model, consists of two electrons, each
with a single degree of freedom, interacting with each other and a central (nu-
,
clear) potential. We use a regularized form of the Coulomb potential,
r2+a2
0
where the regularizer, a0 = 0.739707902, is such that the ground-state energy
of the model matches the experimentally measured binding energy of helium,
2.903385 amu [41, 42]. The Hamiltonian is therefore:

1√

(cid:0)p2
We solve the TDSE in eq. 38, 36, by transforming the Hamiltonian to the (cid:101)B
basis via (cid:101)B† (T + V )(cid:101)B. In the case of multi-electron dynamics, the electron-

with Q = −2qe and qe being the electron charge.

(x1 − x2)2 + a2

1(cid:112)x2

1(cid:112)x2

0

, is not dimensionally decomposable,
electron interaction term,
and therefore extremely expensive to integrate numerically. We represent it
as a sum-of-products of one dimensional potentials (although in this particu-
lar case a very large number of elements are required to achieve an accurate
representation ). POTFIT was used to perform this decomposition, see Sec-
tion 3.1.1.
The system is driven by a combination of a NIR pulse and two XUV pulses
(see lower panel of ﬁg. 7). The NIR pulse is taken to have a sine en-
velop in order to have exactly zero derivatives at the beginning and at the
end: uNIR = ANIR sin(2πt/TNIR − π) sin(πt/(4TNIR))2 with TNIR = 110.32
a.u.
(= 2.6685fs). This corresponds to a wavelength of 800nm, and a
total duration of 10.67fs. The peak amplitude is ANIR = 0.6627 (corre-
sponding to an intensity of 5 × 1013W/cm2). The XUV pulses have the
form: uXUV = AXUV sin(2πt/TXUV) exp(−(t−5TXUV/4)2/(2σ2)) with TXUV =

1√
(x1−x2)2+a2

+

1

4π0

+

1

2me

q2
e

0

(cid:1)

1 + p2
2

(58)

35

2.07a.u. which corresponds to a wavelength of 15nm. We take σ = 6.207a.u.
(150 attoseconds) and peak amplitude AXUV = 0.08a.u. The control strategy
is to generate a sequential double ionization with the two successive XUV
pulses at the peaks of the NIR pulse.
For this simulation the PvB calculation is based on an underlying grid with
a range x ∈ [−400; 400] with N = 4000 points in each dimension. On such
a grid, the dimension of the unreduced Hilbert space is 16 × 106 while the
maximum dimension of the reduced Hilbert space used during the dynamics
is 28207. This translates to a reduction by a factor of 400 in the size of the
Hilbert space and hence ﬁve orders of magnitude in the number of elements
in the Hamiltonian, as compared to the size of the unreduced Hamiltonian.
For the results of the simulation, see ﬁg. 7 and 8. The two-particle phase
space is four dimensional, and therefore we display 2D projections. In ﬁg.
7 we show the evolution of the two-electron system as a function of time at
three times: just prior to the second XUV pulse, just after the second XUV
pulse and later when the wavepackets have had suﬃcient time to drift away
from the core.
In ﬁgure 8 we look in depth at the state of the system corresponding to
the bottom row of ﬁgure 7. The 4D phase space is projected into 4 planes:
x1, x2 and p1, p2 as well as the single particle projections x1, p1 and x2, p2.
The wavefunction exhibits complex contributions, which may be associated
with speciﬁc NIR and XUV pulses. One may observe interesting phenomena
such as both sequential and concerted double ionization. For an in depth
discussion of these results, refer to [14].

5. Conclusions and outlook

We presented the Periodic von Neumann method with Biorthogonal exchange
(PvB) for quantum mechanical simulations, based on the von Neumann lat-
tice of phase space Gaussians. The use of periodic boundary conditions allows
the method to converge with Fourier accuracy, while the exchange of the role
of the basis and its biorthogonal functions allows the elimination of basis
functions that are not in the occupied regions of phase space. This provides
a sparse representation, leading to a signiﬁcant savings in memory and CPU
resources.

36

37

Figure 7: Snapshots of the two electron wavefunction after the second XUV pulse, sorted
by increasing times from top to bottom. The ﬁrst column shows the x1; x2 correlations.
The second column shows the one dimensional phase space projection of the ﬁrst electron.
The times corresponding to the three snapshots are pointed out by red circles on the
control pulse in the bottom frame. The green arrow in the middle-left plot points to a
concerted ionization contribution.

-2000200x1-200-1000100200-2000200p1-10-505107.99e-072.59e-050.0007960.02580.793-2000200x1-200-1000100200-2000200p1-10-50510x2-2000200x1-200-1000100200x1-2000200p1-10-50510Time (a.u.)0100200300400500Control (a.u.)-1-0.500.51Figure 8: Phase space state of the Helium two electron wavefunction after the second XUV
pulse at t = 275a.u (third red circle in ﬁg. 7). Interpretation of simulation results is that
events unfold as follows: A single ionization is generated by the ﬁrst XUV pulse, and is
denoted by (F) and (G) in the Particle 1 panel, top-right. Then two double ionization event
are triggered by both the second XUV pulse and the on-going NIR pulse, (A) and (C) in
the XX correlation panel, top-left. The contributions of the two pulses are distinguishable
in the single-particle projection (bottom left panel), with the second XUV pulse generating
the (D) ionization, and the NIR generating the (E) ionization. The second XUV pulse
also triggers a second single ionization event, denoted by (B). For an in depth analysis,
see [14].

38

XX correlationx2                                      x2-200-1000100200x1-250-200-150-100-500501001502002501.33e-062.56e-064.92e-069.47e-061.82e-053.5e-057.12e-050.0001370.0002640.0005070.0009760.001880.003610.006950.01340.02570.05220.10.1930.3720.7161.38Particle 1p1                                      p1-15-10-5051015x1-250-200-150-100-500501001502002507.05e-071.36e-062.63e-065.08e-069.82e-061.9e-053.87e-057.49e-050.0001450.000280.000540.001040.002020.00390.007530.01460.02970.05740.1110.2140.4140.8          Particle 2x2                                      x2-200-1000100200p2-15-10-50510157.05e-071.36e-062.63e-065.08e-069.82e-061.9e-053.87e-057.49e-050.0001450.000280.000540.001040.002020.00390.007530.01460.02970.05740.1110.2140.4140.8PP correlationp2                                      p2-15-10-5051015p1-15-10-50510159.93e-061.65e-052.74e-054.56e-057.57e-050.0001260.0002180.0003620.0006020.0010.001660.002760.004580.007620.01270.0210.03640.06050.1010.1670.2780.461EDCBAFG(a)(b)(c)(d)The PvB approach utilizes a phase space-local non-orthogonal basis, which
is related to an underlying Fourier grid via a similarity transformation. By
carefully deﬁning the projection operator for non-orthogonal bases, we were
able to project out all the unoccupied areas of phase space, leaving a far
smaller subspace to contend with, while maintaining a very straightforward
control of accuracy.
Appropriate algorithms for solving the TISE and TDSE were developed. In
both cases one must contend with the a priori ignorance of the exact phase
space area needed to represent the ﬁnal state. For ﬁnding eigenmodes, we
iteratively grow the area from "seeds" at the local minima of the potential,
expanding and pruning the area as needed. For dynamics, we make use of
the smooth transition of the state through phase space to keep track of the
changes in the occupied phase space as a function of time.
The method was demonstrated on the textbook example of the double-well
potential, as well as the more demanding simulation of the double-ionization
of helium in one-dimension.
While PvB is now a mature method, with mathematical rigor and fully
ﬂeshed-out algorithms, signiﬁcant further development is possible. Addi-
tional approximations may be introduced, beyond projecting out areas of
phase space where the wavefunction amplitude is below the speciﬁed thresh-
old. Speciﬁcally, one may further reduce the representation by decomposing
multi-dimensional objects into a sum-of-products series, and truncating the
series when the correlation is suﬃciently low, á la POTFIT (see Section
3.1.1). While this decomposition is currently utilized in the representation
of the unreduced Hamiltonian, much will be gained if this approach can be
extended to the reduced state and the reduced Hamiltonian. This is a chal-
lenging problem, however, as the dynamics continuously modify the reduced
basis, which is generally not easily decomposable.
Further areas of research include the correspondence between PvB and other
phase space representations, such as the Wigner representation. We antici-
pate that PvB will be signiﬁcantly more eﬃcient because of its intrinsically
discrete representation and its excellent convergence properties. We also plan
to explore the explicit incorporation of particle symmetries in multi-particle
systems (bosonic, fermionic) into the PvB framework.
Beyond method development, a wide range of problems in atomic and molec-

39

ular physics can be addressed using the PvB methodology, from electron dy-
namics in multi-electron systems to nuclear dynamics in polyatomic molecules.
We are currently exploring these applications.
To conclude, PvB is an accurate, well-controlled, scalable and eﬃcient method
for quantum dynamics simulations. It is our hope it will ﬁnd its place as part
of the standard quantum numerics toolbox.

Acknowledgement

We wish to thank Henrik Larsson and Tucker Carrington for enlightening
conversations. This work was supported by the Israel Science Foundation
(533/12), the Minerva Foundation with funding from the Federal German
Ministry for Education and Research and the Koshland Center for Basic
Research.

Bibliography

References

[1] W. Kohn, Rev. Mod. Phys. 71 (1999) 1253–1266.

[2] S. Zhang, E. Pollak, J. Chem. Phys. 118 (2003) 4357–4364.

[3] R. Cabrera, D. I. Bondar, K. Jacobs, H. A. Rabitz, Phys. Rev. A 92

(2015) 042122.

[4] F. Dimler, S. Fechner, A. Rodenberg, T. Brixner, D. J. Tannor, New

Journal of Physics 11 (2009) 105052.

[5] A. Shimshovitz, D. J. Tannor, Phys. Rev. Lett. 109 (2012) 070402.

[6] N. Takemoto, A. Shimshovitz, D. J. Tannor, J. Chem. Phys. 137 (2012)

011102.

[7] J. Neumann, Mathematische Annalen 104 (1931) 570–578.

40

[8] D. Gabor, Journal of the Institution of Electrical Engineers - Part III:

Radio and Communication Engineering 93 (1946) 429–441.

[9] M. J. Davis, E. J. Heller, J. Chem. Phys. 71 (1979) 3383–3395.

[10] E. T. Whittaker, Proceedings of the Royal Society of Edinburgh 35

(1915) 181–194.

[11] H. Nyquist, American Institute of Electrical Engineers, Transactions of

the 47 (1928) 617–644.

[12] C. Shannon, Proceedings of the IRE 37 (1949) 10–21.

[13] S. Machnes, E. Assémat, D. J. Tannor, J. Phys. Chem. Accepted (2016).

[14] E. Assémat, S. Machnes, D. J. Tannor, arXiv:1502.05165 (2015).

[15] R. Kosloﬀ, Numerical Grid Methods and Their Application to
Schrödinger’s Equation, Springer Netherlands, Dordrecht, pp. 175–194.

[16] C. C. Marston, G. G. Balint-Kurti, J. Chem. Phys. 91 (1989) 3571–3576.

[17] D. T. Colbert, W. H. Miller, J. Chem. Phys. 96 (1992) 1982–1991.

[18] D. J. Tannor, Introduction to Quantum Mechanics: A Time-Dependent

Perspective, University Science Books, 2007.

[19] T. Genossar, M. Porat, IEEE Transactions on Systems, Man and Cy-

bernetics 22 (1992) 449–460.

[20] D. J. Tannor, N. Takemoto, A. Shimshovitz, Advances in Chemical

Physics 156 (2014) 1–34.

[21] A. Shimshovitz, Z. Bacic, D. J. Tannor, J. Chem. Phys. 141 (2014)

234106.

[22] J. Brown, T. Carrington, J. Chem. Phys. 143 (2015) 044104.

[23] S. Fechner, F. Dimler, T. Brixner, G. Gerber, D. J. Tannor, Opt. Express

15 (2007) 15387–15401.

[24] I. Daubechies, IEEE Transactions on Information Theory 36 (1990) 961–

1005.

41

[25] L. Wang, C.-T. Chen, W.-C. Lin, IEEE Transactions on Image Process-

ing 3 (1994) 87–92.

[26] K. Husimi, Proceedings of the Physico-Mathematical Society of Japan.

3rd Series 22 (1940) 264–314.

[27] H.-W. Lee, Optics Communications 337 (2015) 62–65.

[28] E. Wigner, Phys. Rev. 40 (1932) 749–759.

[29] J. O’Neill, P. Flandrin, W. Williams, Signal Processing Letters, IEEE 6

(1999) 304–306.

[30] D. Lalović, D. M. Davidović, N. Bijedić, Phys. Rev. A 46 (1992) 1206–

1212.

[31] H.-W. Lee, Phys. Rev. A 50 (1994) 2746–2749.

[32] S. Fechner, F. Dimler, T. Brixner, G. Gerber, D. J. Tannor, Opt. Express

15 (2007) 15387–15401.

[33] A. Jäckle, H.-D. Meyer, J. Chem. Phys. 104 (1996) 7974–7984.

[34] D. Peláez, H.-D. Meyer, J. Chem. Phys. 138 (2013) 014108.

[35] S. E. Jo, S. W. Kim, T. J. Park 1 (2004) 955–959.

[36] G. H. Golub, Q. Ye, SIAM Journal on Scientiﬁc Computing 24 (2002)

312–334.

[37] P. M. Paul, E. S. Toma, P. Breger, G. Mullot, F. Augé, P. Balcou, H. G.

Muller, P. Agostini, Science 292 (2001) 1689–1692.

[38] B. Mignolet, R. D. Levine, F. Remacle, Phys. Rev. A 86 (2012) 053429.

[39] E. P. Månsson, D. Guénot, C. L. Arnold, D. Kroon, S. Kasper,

Dahlström, et al., Nature Physics 10 (2014) 207–211.

[40] S. Chen, C. Ruiz, A. Becker, Phys. Rev. A 82 (2010) 033426.

[41] P. J. Mohr, B. N. Taylor, D. B. Newell, J. Phys. and Chem. Ref. Data

41 (2012) 043109.

42

[42] A. Kramida, Y. Ralchenko, J. Reader, NIST Atomic Spectra Database
(ver. 5.1). National Institute of Standards and Technology, Gaithers-
burg, MD (2013).

43

