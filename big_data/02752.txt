6
1
0
2

 
r
a

 

M
8
1

 
 
]

G
L
.
s
c
[
 
 

2
v
2
5
7
2
0

.

3
0
6
1
:
v
i
X
r
a

Best-of-K Bandits

Max Simchowitz msimchow@eecs.berkeley.edu
Kevin Jamieson kjamieson@eecs.berkeley.edu

Ben Recht brecht@eecs.berkeley.edu

University of California, Berkeley, CA 94720 USA

March 22, 2016

Abstract

This paper studies the Best-of-K Bandit game: At each time the player chooses a subset S among
all N-choose-K possible options and observes reward max(X(i) : i in S) where X is a random vector
drawn from a joint distribution. The objective is to identify the subset that achieves the highest expected
reward with high probability using as few queries as possible. We present distribution-dependent lower
bounds based on a particular construction which force a learner to consider all N-choose-K subsets, and
match naive extensions of known upper bounds in the bandit setting obtained by treating each subset
as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain,
favorable distributions because the inﬂuence of high-order order correlations may be dominated by lower
order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the
surprising non-trivial information occlusion that occurs due to only observing the max in the subset.
This may inform strategies for more general dependent measures, and we complement these result with
independent-arm lower bounds.

1 Introduction

This paper addresses a variant of the stochastic multi-armed bandit problem, where given n arms associated

with random variables X1, . . . , Xn, and some ﬁxed 1 ≤ k ≤ n, the goal is to identify the subset S ∈(cid:0)[n]
k(cid:1)

that maximizes the objective E [maxi∈S Xi]. We refer to this problem as “Best-of-K” bandits to reﬂect the
reward structure and the limited information setting where, at each round, a player queries a set S of size
at most k, and only receives information about arms Xi : i ∈ S: e.g. the vector of values of all arms in S,
{Xi : i ∈ S} (semi-bandit), the index of a maximizer (marked bandit), or just the maximum reward over all
arms maxi∈S Xi (bandit). The game and its valid forms of feedback are formally deﬁned in Figure 1.

While approximating the Best-of-K problem and its generalizations have been given considerable atten-
tion from a computational angle, in the regret setting [15, 3, 12, 11, 15, 13], this work aims at characterizing
its intrinsic statistical difﬁculty as an identiﬁcation problem. Not only do identiﬁcation algorithms typically
imply low regret algorithms by ﬁrst exploring and then exploiting, every result in this paper can be easily
extended to the PAC learning setting where we aim to ﬁnd a set whose reward is within ǫ of the optimal, a
pure-exploration setting of interest for science applications [9, 8, 2].

For joint reward distributions with high-order correlations, we present distribution-dependent lower

bounds which force a learner to consider all subsets S ∈ (cid:0)[n]

match naive extensions of known upper bounds in the bandit setting obtained by treating each subset S
as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain,
favorable distributions because the inﬂuence of high-order order correlations may be dominated by lower
order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the

k(cid:1) in each feedback model of interest, and

1

Best-of-k Bandits Game
for t = 1, 2, ...

Player picks St ∈ S and adversary simultaneously picks xt ∈ {0, 1}n

Player observes

Bandit feedback:

Marked-Bandit feedback: 

Semi-bandit feedback:



max
i∈St

xt,i

xt,i ∀i ∈ St

∅
unif(arg max
i∈St

xt,i)

if xt,i = 0 , ∀i ∈ St
otherwise.

Figure 1: Best-of-k Bandits game for the different types of feedback considered. While this work is pri-
marily interested in stochastic adversaries, our lower bound construction also has consequences for non-
stochastic adversaries. Moreover, in marked feedback, we might consider non-uniform and even adversarial
marking.

surprising non-trivial information occlusion that occurs in the bandit and marked bandit feedback models.
This may inform strategies for more general dependent measures, and we complement these result with
independent-arm lower bounds.

1.1 Motivation
In the setting where Xi ∈ {0, 1}, one can interpret the objective maxS∈([n]
k ) maxi∈S Xi as trying to ﬁnd the
set of items which affords the greatest coverage. For example, instead of using spread spectrum antibiotics
which have come under ﬁre for leading to drug-resistant “super bugs” [4], consider the doctor that desires
to identify the best k subset of narrow spectrum antibiotics that leads to as many favorable outcomes as
possible. Here each draw from Xi represents the ith treatment working on a random patient, and for antibi-
otics, we may assume that there are no synergistic effects between different drugs in the treatment. Thus,
the antibiotics example falls under the bandit feedback setting since k treatments are selected but it is only
observed if at least one k-tuple of treatment led to a favorable outcome: no information is observed about
any particular treatment.

Now consider content recommendation tasks where k items are suggested and the user clicks on either 1
or none. Here each draw from Xi represents a user’s potential interest in the i-th item, which we assume is
independent of the other items which are shown with it. Nevertheless, due to the variety and complexity of
users’ preferences, the Xi’s have a highly dependent joint distribution, and we only get to observe marked-
bandit feedback, namely one item which the user has clicked on. Our ﬁnal example comes from virology
where multiple experiments are prepared and performed k at a time, resulting in k simultaneous, noisy
responses [2]; this motivates our consideration of the semi-bandit feedback setting.

1.2 Problem Description

We denote [n] = {1, 2, . . . , n}. For a ﬁnite set W , we let 2W denote its power set,(cid:0)W
all subsets of W of size p, and write V ∼ Unif[W, p] to denote that V is drawn uniformly from(cid:0)W

is a length n vector (binary, real or otherwise) and W ⊂ [n], we let XW denote the sub-vector indexed by
entries i ∈ W .

p(cid:1) denote the set of
p(cid:1). If X

In what follows, let X = (X1, . . . , Xn) be a random vector drawn from the probability distribution ν
over {0, 1}n. We refer to the index i ∈ [n] as the i-th arm, and let νi denote the marginal distribution of its

2

corresponding entry in X, e.g. (Eν[X])i = Eνi[Xi]. We deﬁne S :=(cid:0)[n]

call E[maxi∈S Xi] the expected reward of S, and refer casually to the random instantiations maxi∈S Xi as
simply the reward of S.

k(cid:1), and for a given S ∈ S, we we

At each time t, nature draws a rewards vector xt = X where X is i.i.d from ν. Simultaneously, our
algorithm queries a subset of St ∈ S of k arms, and we refer to the entries i ∈ St as the arms pulled by the
query. As we will describe later, this problem has previously been studied in a regret framework, where a
time horizon T ∈ N is ﬁxed and an algorithm’s objective is to minimize its regret

Rν(T ) = T max
S∈S

Eν[max
i∈S

Xi] − Eν[

max
i∈St

Xi].

(1)

TXt=1

In this work, we are more concerned with the problem of identifying the best subset of k arms. More
precisely, for a given measure ν, denote the optimal subset

S∗ := arg max
S∈S

Eν(cid:20)max

i∈S

Xi(cid:21)

(2)

before our algorithm terminates. The identiﬁcation problem is then

and let TS denote the (possibly random) number of times a particular subset S ∈ (cid:0)[n]
bS such that Pν(bS 6= S∗) ≤ δ, and which minimizes the sumPS∈([n]

Deﬁnition 1 (Best-of-K Subset Identiﬁcation). For any measure ν and ﬁxed δ ∈ (0, 1), return an estimate
k ) TS either in expectation, or with high

k(cid:1) has been played

Again, we remind the reader that an algorithm for Best-of-K Subset Identiﬁcation can be extended to
active PAC learning algorithm, and to an online learning algorithm with low regret (with high probability)
[9, 8, 2].

probability.

1.3 Related Work

Variants of Best-of-K have been studied extensively in the context of online recommendation and ad place-
ment [15, 3, 12]. For example, [11] introduces “Ranked Bandits” where the arms Xi are stochastic random
variables, which take a value 1 if the t-th user ﬁnds item i relevant, and 0 otherwise. The goal is to rec-
ommend an ordered list of items S = (i1, . . . , ik) which maximizes the probability of a click on any item
in the list, i.e. maxi∈S Xi, and observes the ﬁrst item (if any) that the user clicked on. [13] generalizes
to online maximization of a sequence of monotone, submodular function {Ft(S)}1≤t≤T subject to knap-
sack constraints |S| ≤ k, under a variety of feedback models. Since the function S 7→ maxi∈S Xi is
submodular, identifying S∗ corresponds to special case of optimizing the monotone, submodular function
F (S) := E[maxi∈S Xi] subject to these same constraints.

[13], [15], and [11] propose online variants of a well-known greedy ofﬂine submodular optimization

algorithm (see, for example [5]) , which attain (1 − 1

e ) approximate regret guarantees of the form

Ft(St) −(cid:18)1 −

TXt=1

1

e(cid:19) max

S ∗:|S ∗|≤k

Ft(S∗) ≤ R(T )

(3)

where R(T ) is some regret term that decays as O(poly(n, k)) · o(T ). Computationally, this 1 − 1
e is the
best one could hope: Best-of-K and Ranked Bandits are online variants of the Max-K-Coverage problem,
which cannot be approximated to within a factor of 1 − 1
e + ǫ for any ﬁxed ǫ > 0 under standard hardness
assumptions [14]. For completeness, we provide a formal reduction from Best-of-K identiﬁcation to Max-
K-Coverage in Appendix A.

3

1.4 Our Contributions

Focusing on the stochastic pure-exploration setting with binary rewards, our contributions are as follows:

• We propose a family of joint distributions such that any algorithm that solves the best of k identiﬁ-

k(cid:1) combinations of arms. Our lower

cation problem with high probability must essentially query all(cid:0)n

bounds for the bandit case are nearly matched by trivial identiﬁcation and regret algorithms that treat
each k-subset as an independent arm. For semi-bandit feedback, our lower bounds are exponentially
higher in k than those for bandit feedback (though still requiring exhaustive search). To better un-
derstand this gap, we sketch an upper bound that achieves the lower bound for a particular instance
of our construction. While in the general binary case, the difﬁculty of marked bandit feedback is
sandwiched between bandit and semi-bandit feedback, in our particular construction we show that
marked bandit feedback has no beneﬁt over bandit feedback. In particular, for worst-case instances,
our lower bounds for marked bandits are matched by upper bounds based on algorithms which only
take advantage of bandit feedback.

• Our construction plants a k-wise dependent set S∗ among(cid:0)n

needle-in-a-haystack scenario. One weakness of this construction is that the gap between the rewards
of the best and second best subset are exponentially small in k. This is particular to our construction,
but not to our analysis: We present a partial converse which establishes that, for any two k − 1-
wise independent distributions deﬁned over {0, 1}k with identical marginal means µ, the difference
in expected reward is exponentially small in k1. This begs the question: can low order correlation
statistics allows us to neglect higher order dependencies? And can this property be exploited to avoid
combinatorially large sample complexity in favorable scenarios with moderate gaps?

k(cid:1) − 1 k-wise independent sets, creating a

• We lay the groundwork for algorithms for identiﬁcation under favorable, though still dependent, mea-
sures by designing a computationally efﬁcient algorithm for independent measures for the marked,
semi-bandit, and bandit feedback models. Though independent semi-bandits is straightforward [7],
special care needs to be taken in order to address the information occlusion that occurs in the bandit
and marked-bandit models, even in this simpliﬁed setting. We provide nearly matching lower bounds,
and conclude that even for independent measures, bandit feedback may require exponentially (in k)
more samples than in the semi-bandit setting.

2 Lower Bound for Dependent Arms

Intuitively, the best-of-k problem is hard for the dependent case because the high reward subsets may appear
as a collection of individually low-pay off arms if not sampled together. For instance, for k = 2, if X1 =
Bernoulli(1/2), X2 = 1− X1, and Xi = Bernoulli(3/4) for all 3 ≤ i ≤ n, then clearly E[max{X1, X2}] =
1 is the best subset because E[max{X1, Xi}] = 1−(1/2)(1/4) = 7/8 and E[max{Xi, Xj}] = 1−(1/4)2 =
15/16 for all 3 ≤ i ≤ j ≤ n. However, identifying set {1, 2} appears difﬁcult as presumably one would

2(cid:1) sets since if X1 and X2 are not queried together, they appear as Binomial(1/2).

Our lower bound generalizes this construction by introducing a measure ν such that (1) the arms in the
optimal set S∗ are dependent but (2) the arms in every other non-optimal subset of arms S ∈ S − S∗ are
mutually independent. This construction amounts to hiding a “needle-in-a-haystack” S∗ among all other

have to consider all(cid:0)n
(cid:0)n
k(cid:1) − 1 subsets, requiring any possibly identiﬁcation to examine most elements of S.

1Note that our construction requires all subset of k − 1 of S ∗ to be independent

4

We now state our theorem, which characterizes the difﬁculty of recovering S∗ arms in terms of the gap

∆ between the expected reward of S∗ and of the second best subset

∆ := Eν(cid:20)max

i∈S ∗

Xi(cid:21) − max

S∈S\S ∗

Eν(cid:20)max

i∈S

Xi(cid:21)

(4)

Theorem 2.1 (Dependent). Fix k, n ∈ N such that 2 ≤ k < n. For any ǫ ∈ (0, 1] and µ ∈ (0, 1/2] there
exists a distribution ν with ∆ = ǫµk such that any algorithm that identiﬁes S∗ with probability at least 1 − δ
requires, in expectation, at least

(i)

(ii)

4(1 − ǫ( µ

1−µ )k)

3

2
3

µ2k(1 − ǫ)(cid:18)n

·(cid:0)1 − (1 − µ)k(cid:1) (1 − µ)k(cid:18)n
k(cid:19)∆−2 log( 1

semi-bandit

2δ )

k(cid:19)∆−2 log( 1

2δ )

(marked-)bandit, or

3 2−2k(cid:0)n

k(cid:1)∆−2 log( 1

observations. In particular, for any 0 < ξ ≤ (2k)−k there exists a distribution ν with ∆ = ξ that requires
just 1
2δ ) (marked-)bandit observations. And for any 0 < ξ ≤ 2−k−1 there exists a distribution
ν with ∆ = ξ that requires just 1

2δ ) semi-bandit observations.

3(cid:0)n
k(cid:1)∆−2 log( 1

Remark 2.1. Marked-bandit feedback provides strictly less information than semi-bandit feedback but at
least as much as bandit feedback. The above lower bound for marked-bandit feedback and the nearly
matching upper bound for bandit feedback remarked on below suggests that marked-bandit feedback may
provide no more information than bandit feedback. However, the lower bound holds for just a particular
construction and in Section 3 we show that there exist instances in which marked-bandit feedback provides
substantially more information than merely bandit feedback.

In the construction of the lower bound, S∗ = [k] and all other subsets behave like completely inde-
pendent arms. Each individual arm has mean µ, i.e. Eν[Xi] = µ for all i, so each S 6= S∗ has a bandit
reward of Eν[maxi∈S Xi] = 1 − (1 − µ)k. The scaling (1 − (1 − µ)k)(1 − µ)k in the number of bandit
and marked-bandit observations corresponds to the variance of this reward and captures the property that
the number of times a set needs to be sampled to accurately predict its reward is proportional to its variance.
Since µ ≤ 1/2, we note that the term 1 − ǫ( µ
1−µ )k is typically very close to 1, unless µ is nearly 1/2 and ǫ
is nearly 1.

While the lower bound construction makes it necessary to consider each subset S ∈(cid:0)[n]

all forms of feedback feedback, semi-bandit feedback presumably allows one to detect dependencies much
faster than bandit or marked-bandit feedback, resulting in an exponentially smaller bound in k. Indeed,
Remark E.2 describes an algorithm that uses the parity of the observed rewards that nearly achieves the
lower bound for semi-bandits for the constructed instance when µ = 1/2. However, the authors are unaware
of more general matching upper bounds for the semi-bandit setting and consider this a possible future avenue
of research.

k(cid:1) individually for

2.1 Comparison with Known Upper Bounds

By treating each set S ∈ S as an independent arm, standard best-arm identiﬁcation algorithms can be applied
to identify S∗. The KL-based LUCB algorithm from [8] requires O(∆2
samples, matching our bandit lower bound up to a a multiplicative factor of k log n (which is typically

k(cid:1) · k log n)
k(cid:1)). The lil’UCB algorithm of [6] avoids paying this multiplicative k log n factor, but at the

cost of not adapting to the variance term (1 − (1 − µ)k)(1 − µ)k. Perhaps a KL- or variance-adaptive
extension of lil-UCB could attain the best of both worlds.

i (1 − (1 − µ)k)(1 − µ)k(cid:0)n

dwarfed by(cid:0)n

5

we have lim inf T →∞

From a regret perspective, the exact construction as used in the proof of Theorem 2.1 can be used in

Theorem 17 of [9] to state a lower bound on the regret after T =PS∈S Ts bandit observations. Speciﬁcally,
if an algorithm obtain a stochastic regret RT (ν) = o(T α) for all α ∈ (0, 1], then for all S ∈ (cid:0)[n]
k(cid:1) − S∗,
adversarial setting, the above construction with µ = 1/2 also implies a lower bound ofq2−O(k)(cid:0)n
k(cid:1)T =
q(cid:0)Ω(n)
k (cid:1)T for any algorithm over a time budget T . Both of these regret bounds are matched by upper

where ∆ is given in Theorem 2.1. Alternatively, in an

bounds found in [1].

Eν [TS]

log(T ) ≥ (1−(1−µ)k )(1−µ)k

∆2

2.2 Do Complicated Dependencies Require Small Gaps?

While Theorem 2.1 proves the existence a family of instances in which(cid:0)n

sary to identify the best k-subset, the possible gaps ∆ are restricted to be no larger than min{µk, (1 − µ)k}.
It is natural to wonder if this is an artifact of our analysis, a fundamental limitation of k−1-wise independent
sets, or a property of dependent sets that we can potentially exploit in algorithms. The following theorem
suggests, but does not go as far as to prove, that if there are very high-order dependencies, then these depen-
dencies cannot produce gaps substantially larger than the range described by Theorem 2.1. More precisely,
the next theorem characterizes the maximum gap for (k − 1)-wise independent instances.

k(cid:1)∆−2 log(1/δ) samples are neces-

Theorem 2.1. Let X = (X1, . . . , Xk) be a random variable supported on {0, 1}k with k − 1-wise indepen-
dent marginal distributions, such that E[Xi] = µ ∈ [0, 1] for all i ∈ {1, . . . , k}. Then there is a one-to-one
correspondence between joint distributions over X and probability assignments P(X1 = · · · = Xk = 0).
When µ < 1/2, all such assignments lie in the range

(1 − µ)k 1 −(cid:18) µ

1 − µ(cid:19)keven! ≤ P(X1 = · · · = Xk = 0) ≤ (1 − µ)k 1 +(cid:18) µ

1 − µ(cid:19)kodd!

(5)

Here, kodd is the largest odd integer ≤ k, and keven the largest even integer ≤ k. Moreover, when µ ≥ 1/2,
all such assignments lie in the range

0 ≤ P(X1 = · · · = Xk = 0) ≤ (1 − µ)k−1

(6)

Noting that E[maxi∈[k] Xi] = 1 − P(X1 = · · · = Xk = 0), Theorem 2.1 implies that the difference
between the largest possible and smallest possible expected rewards for a set of k arms where each arm has
mean µ and the distribution is k − 1-wise independent is no greater than (1 − µ)k, a gap of the same order
of the gaps used in our lower bounds above. This implies that, in the absence of low order correlations, very
high order correlations can only have a limited effect on the expected rewards of sets.

If it were possible to make more precise statements about the degree to which high order dependencies
can inﬂuence the reward of a subset, strategies could exploit this diminishing returns property to more
efﬁciently search for subsets while also maintaining large-time horizon optimality. In particular, one could
use such bounds to rule out sets that need to be considered based just on their performance using lower order
dependency statistics. To be clear, such algorithms would not contradict our lower bounds, but they may
perform much better than trivial approaches in favorable conditions.

3 Best of K with Independent Arms

While the dependent case is of considerable practical interest, the remainder of this paper investigates the
best-of-k problem where ν is assumed to be a product distribution of n independent Bernoulli distributions.

6

We show that even in this presumably much simpler setting, there remain highly nontrivial algorithm de-
sign challenges related to the information occlusion that occurs in the bandit and marked-bandit feedback
settings. We present an algorithm and analysis which tries to mitigate information occlusion which we hope
can inform strategies for favorable instances of dependent measures.

Under the independent Bernoulli assumption, each arm is associated with a mean µi ∈ [0, 1) and the

expected reward of playing any set S ∈(cid:0)[n]

is precisely the set of arms with the greatest k means µi.

2(cid:1) is equal to 1 −Qi∈S(1 − µi) and hence best subset of k arms

3.1 Results

Without loss of generality, suppose the means are ordered µ1 ≥ . . . µk > µk+1 ≥ . . . µn. Assuming
µk 6= µk+1 ensures that the set of top k means is unique, though our results could be easily extended to a
PAC Learning setting with little effort. Deﬁne the gaps and variances via

For τ > 0, introduce the transformation

µk − µi

∆i :=(µi − µk+1
Tn,δ(τ ) := τ log(cid:18) 16n log2 e

δ

if i ≤ k
if i > k

and

Vi := µi(1 − µi)

log(cid:18) 8nτ log2 e

δ

(cid:19)(cid:19) = ˜Θ(cid:16)τ log(cid:16) n
δ(cid:17)(cid:17)

(7)

(8)

where ˜Θ(·) hides logarithmic factors of its argument. We present guarantees for the Stagewise Elimination
of Algorithm 3 in our three feedback models of interest; the broad brush strokes of our analysis are addressed
in Appendix B, and the details are ﬂeshed in the Appendices C and B.2. Our ﬁrst result is holds for semi-
bandits, which slightly improves upon the best known result for the k-batch setting [7] by adapting to
unknown variances:

Theorem 3.1 (Semi Bandit). With probability 1 − δ, Algorithm 3 with semi-bandit feedback returns the
arms with the top k means using no more than

8Tn,δ(τσ(1)) +

4
k

nXi=k+1

Tn,δ(τσ(i)) = ˜O  τσ(1) +

1
k

nXi=k+1

δ(cid:17)!
τσ(i)! log(cid:16) n

queries where

τi :=

56
∆i

+

i (max{Vi, maxj>k Vj} i ≤ k

max{Vi, maxj≤k Vj} i > k

256
∆2

(9)

(10)

and σ is a permutation so that τσ(1) ≥ τσ(2) ≥ . . . τσ(n).

The above result also holds in the more general setting where the rewards have arbitrary distributions

bounded in [0, 1] almost surely (where Vi is just the variance of arm i.)

In the marked-bandit and bandit settings, our upper bounds incur a dependence on information-sharing
terms H M (marked) and H B (bandit) which capture the extent to which the max operator occludes infor-
mation about the rewards of arms in each query.

Theorem 3.2 (Marked Bandit). Suppose we require each query to pull exactly k arms. Then Algorithm 3
with marked bandit feedback returns the arms with the top k means with probability at least 1 − δ using no
more than

16Tn,δ  τ M

H M! +

σ(1)

8
k

nXi=k+1

Tn,δ  τ M

H M! = ˜O  log (n/δ)

H M  τ M

σ(i)

σ(1) +

σ(i)!!

τ M

1
k

nXi=k+1

(11)

7

queries. Here, τ M

i

is given by

τ M
i

:=

56
∆i

+

i (µi

µk

256
∆2

i ≤ k
i > k

(12)

σ is a permutation so that τσ(1) ≥ τσ(2) ≥ . . . τσ(n), and H M is an “information sharing term” given by

H M := EX1,...,Xk−1"

1

I(Xℓ = 1)#

(13)

If we can pull fewer than k arms per round, then we can achieve

1 +Pℓ∈[k−1]
σ(i)(cid:17) = ˜O   max

i∈{1,k−1}

8 max
i∈[k−1]

iT (τ M

σ(i)) +

8

kH M

nXi=2

Tn,δ(cid:16)τ M

iτ M

σ(1) +

1

kH M

nXi=2

τ M

σ(i)! log(cid:16) n

δ(cid:17)! (14)

We remark that as long as the means are at no more than 1 − c, τi ≤ 1

, and thus the two differ by a
constant factor when the means are not too close to 1 (this difference comes from loosing (1 − µ) term in a
Bernoulli variance in the marked case). Furthermore, note that H M ≥ 1
k . Hence, when we are allowed to
pull fewer than k arms per round, Stagewise Elimination with marked-bandit feedback does no worse than
a standard LUCB algorithms for stochastic best arm identiﬁcation.

c τ M
i

When the means are on the order of 1/k, then H M = Ω(1), and thus Stagewise Eliminations gives the
same guarantees for marked bandits as for semi bandits. The reason is that, when the means are O(1/k), we
can expect each query S to have only a constant number of arms ℓ ∈ S for which Xℓ = 1, and so not much
information is being lost by observing only one of them.

Finally, we note that our guarantees depend crucially on the fact that the marking is uniform. We
conjecture that adversarial marking is as challenging as the bandit setting, whose guarantees are as follows:

Theorem 3.3 (Bandit). Suppose we require each query to pull exactly k arms, n ≥ 7k/2, and ∀i : µi < 1.
Then Algorithm 3 with bandit feedback returns the arms with the top k means with probability at least 1 − δ
using no more than

σ(1)

H B ! +

20Tn,δ  τ B

H B  τ B
queries where H B :=Qℓ∈[k−1](1 − µℓ) is an “information sharing term”,

H B! = ˜O  log (n/δ)

Tn,δ  τ B

nXi=k+1

5
k

σ(i)

σ(1) +

σ(i)!!

τ B

1
k

nXi=k+1

(15)

τ B
i ≤

66
∆i

+

i (2(1 − µk+1)µi + (1 − µk+1)2(1 − H B)

2(1 − µi)µk+1 + (1 − µi)2(1 − H B)

2560
∆2

i ≤ k
i > k

and σ is a permutation so that τ B

σ(1) ≥ τ B

σ(2) ≥ . . . τ B

σ(n).

The condition that µi < 1 ensures identiﬁability (see Remark B.11). The condition n ≥ 7k/2 is an
artifact of using a Balancing Set B deﬁned in Algorithm 4; without B, our algorithm succeeds for all n ≥ k,
albeit with slightly looser guarantees (see Remark B.9).

Remark 3.1. Suppose the means are greater than α(k)/k where α(k) ≥ C log k and C is a constant; for
example, think α(k) = k/2. Then H B ≤ (1 − α(k)
k )k = O(exp(−α(k))) ≪ 1/k. Hence, Successive
Elimination requires on the order of 1
more queries to identify the top k-arms than
the classic stochastic MAB setting where you get to pull 1-arm at a time, despite the seeming advantage

H B = exp(Ω(α(k))

k ·

k

1

8

that the bandit setting lets you pull k arms per query. When α(k) ≥ C log k, then exp(Ω(α(k)))
k
polynomially large in k, and when α = Ω(k), is exponentially large in k (e.g, α(k) = k/2).

is at least

On the other hand, when the means are all on the order of α/k for α = O(1), then H B = Ω(1), but the

term 1 − H B is at least Ω(α). For this case, our sample complexity looks like

˜O(

log(n/δ)

k Xi

α/k + α

∆2
i

+

1
∆i

) = ˜O(log(n/δ)Xi

α
∆2
i

)

(16)

which matches, but does not out-perform, the standard 1-arm-per-query MAB guarantees, with variance
adaptation (e.g., Theorem 3.1 with k = 1, note that α captures the variance). Hence, when the means are
all roughly on the same order, it’s never worse to pull 1 arm at a time and observe its reward, than to pull k
and observe their max. Once the means vary wildly, however, this is certainly not true; we direct the reader
to Remark B.12 for further discussion.

3.2 Algorithm

At each stage t ∈ {0, 1, 2, . . . }, our algorithm maintains an accept set At ⊂ [n] of arms which we are are
conﬁdent lie in the top k, a reject set Rt ⊂ [n] of arms which we are conﬁdent lie in the bottom n − k, and
an undecided set Ut containing arms for which we have not yet rendered a decision. The main obstacle is
to obtain estimates of the relative performance of i ∈ Ut, since the bandit and marked bandit observation
models occlude isolated information about any one given arm in a pull. The key observation is that, if we
sample S ∼ Unif[Ut, k], then for i, j ∈ Ut, the following differences have the same sign as µi − µj (stated
formally in Lemma B.2):

(bandits)

and

E[max
ℓ∈S

Xℓ = 1(cid:12)(cid:12)i ∈ S] − E[max

ℓ∈S

Xℓ(cid:12)(cid:12)j ∈ S]

P( observe Xi = 1(cid:12)(cid:12)i ∈ S) − P( observe Xj = 1(cid:12)(cid:12)j ∈ S) (marked/semi-bandits)

This motivates a sampling strategy where we partition Ut uniformly at random into subsets S1, S2, . . . , Sp
of size k, and query each Sq, q ∈ {1, . . . , p}. We record all arms ℓ ∈ Sq for which Xℓ = 1 in the
semi/marked-bandit settings (Algorithm 1, Line 3), and, in the bandit setting, mark down all arms in Sq if
we observe maxℓ∈Sq Xℓ = 1 - i.e, we observe a reward of 1 (Algorithm 1, Line 4). This recording procedure
is summarized in Algorithm 1:

(17)

Algorithm 1: PlayAndRecord(S, S+, Y )
1 Input S, S+ ⊂ [n], Y ∈ Rn
2 Play S ∪ S+
3
4
5 Return Y

Semi/Marked Bandit Setting: Yℓ ← 1 for all ℓ ∈ S for which we observe Xℓ = 1
Bandit Bandit Setting: If A returns a reward of 1, Yℓ ← 1 for all ℓ ∈ S

Note that PlayAndRecord[S, S+, Y ] plays a the union of S and S+, but only records entries of Y whose

indices lie in S. UniformPlay (Algorithm 2) outlines our sampling strategy. Each call to UniformPlay[U, A, R, k(1)]
returns a vector Y ∈ Rn, supported on entries i ∈ U, for which

E[Yi] =(P

S,S+( observe Xi = 1(cid:12)(cid:12)i ∈ S ∪ S+)
PS,S+(maxℓ∈S∪S+ Xℓ = 1(cid:12)(cid:12)i ∈ S ∪ S+) bandit

where S ∼ Unif[U, k(1)] and S+ is empty unless |Ut| < k or we are allowed to pull fewer than k arms per
query in which case elements of S+ are drawn from A ∪ R as outlined in Algorithm 2, Line 3 otherwise.

marked/semi-bandit

(18)

9

There are a couple nuances worth mentioning. When |U | < k, we cannot sample k arms from the
undecided set U; hence UniformPlay pulls only k(1) from U per query. If we are forced to pull exactly k
arms per query, UniformPlay adds in a “Top-Off” set of an additional k − k(1) arms, from R and A (Lines 3-
9). Furthermore, observe that lines 13-15 in UniformPlay carefully handle divisibility issues so as to not
“double mark” entries i ∈ U, thus ensuring the correctness of Equation 18. Finally, note that each call to
UniformPlay makes exactly ⌈|U |/k(1)⌉ queries.

Algorithm 2: UniformPlay(U, A, R, k(1))
1 Inputs: U, A, R, sample size k(1)
2 Uniformly at random, partition U into p := ⌊|U |/k(1)⌋ sets S(1), . . . , S(p) of size k(1) and place

remainders in S(0) // thus S(1), . . . , S(p) ∼ Unif[U, k(1)], but not indep

3 If Require k Arms per Pull and k(1) < k // Construct Top-Off Set S+
4

k(2) ← k − k(1) // k(2) = |S+|
S+ ← Unif[R, min{|R|, k(2)}] //sample as many items from reject as possible
If |R| < k(2): // sample remaining items from accept

5

6

S+ ← ∅, k(2) ← 0

S+ ← R ∪ Unif[A, k(2) − |R|]

7
8 Else // Top-Off set unnecessary
9
10 Initalize rewards vector Y ← 0 ∈ Rn
11 For q = 1, . . . , p
12
13 If |S(0)| > 0 // if remainder
14

15
16 Return Y

Y ← PlayAndRecord[S(q), S+, Y ] // only mark S(q)

Draw S(0,+) ∼ Unif[U − S(0), k(1) − |S(0)|] // thus S(0) ∪ S(0,+) ∼ Unif[U, k(1)]
Y ← PlayAndRecord[S(0), S(0,+) ∪ S+, Y ] // only mark S(0) to avoid duplicate marking

We deploy the passive sampling in UniformPlay in a stagewise successive elimination procedure for-
malized in Algorithm 3. At each round t = {1, 2, . . . }, use a doubling sample size to T (t) := 2t, and set the
k(1) parameter for UniformPlay to be min{|Ut|, k} (line 3). Next, we construct the sets (U ′
t) from which
UniformPlay samples: in the marked and semi-bandit setting, these are just (Ut, At, Rt) (Line 4), while in
the bandit setting, they are obtained by from Algorithm 4 which transfers a couple low mean arms from Rt
into U ′

t (Line 5). This procedure ameliorates the effect of information occlusion for the bandit case.

Line 7 through 9 average together T (t) := 2t independent, and identically distributed samples from
t, At, k(1)] to produce unbiased estimates ˆµi,t of the quantity E[Yi] deﬁned in Equa-
UniformPlay[U ′
tion 18. ˆµi,t are Binomial, so we apply an empirical Bernstein’s inequality from [10] to build tight 1 − δ
conﬁdence intervals

t, R′

t, R′

bCi,t :=s 2 ˆV log(8nt2/δ)

T (t)

+

8 log(8nt2/δ)
3(T (t) − 1)

where

ˆVi,t :=

T (t)ˆµi,t(1 − ˆµi,t)

T (t) − 1

(19)

Note that ˆVi,t coincide with the canonical deﬁnition of sample variance. The variance-dependence of our
conﬁdence intervals is crucial; see Remarks B.7 and B.8 for more details. For any ℓ ≤ |Ut| let

ℓ

max
j∈Ut

= ℓ-th largest element

(20)

As mentioned above, Lemma B.2 ensures E[ˆµi,t] > E[ˆµj,t] if and only if µi > µj. Thus, accepting an arm
for ˆµi,t is in the top k.

10

Algorithm 3: Stagewise Elimination(S, k, δ)
1 Input S1 = [n], Batch Size k
2 While |At| < k // fewer than k arms accepted
3
4

bandits

Sample Size T (t) ← 2t, Rewards Vector Y (t) ← 0 ∈ Rn, k(1) ← min{|Ut|, k}
(U ′

// Sampling Sets for UniformPlay, identical to Ut and Rt in marked/semi

t) ← (Ut, Rt)

t, R′

If Bandit Setting

// Add low mean arms from Rt to Ut

(U ′

t, R′

t) ← Balance(Ut, Rt)

For s = 1, 2, . . . , T (t)

Y (t) ← Y (t) + UniformPlay[U ′

t, R′

t, At, k(1)]

// get fresh samples

5
6
7

8

9

10

// normalize

T (t) · Y (t)

ˆµi,t ← 1
kt ← k − |At|
At+1 ← At ∪ {i ∈ Ut : ˆµi,t − ˆCi,t > maxkt+1
j∈Ut

If |Rt| = n − k //n − k arms rejected

11
12 Rt+1 ← Rt ∪ {i ∈ Ut : ˆµi,t + ˆCi,t < maxkt
13
14
15
16

Ut+1 ← Ut − {At+1 ∪ Rt+1}
t ← t + 1

At+1 ← At+1 ∪ Ut

j∈Ut

ˆµj,t + ˆCj,t}
ˆµj,t − ˆCj,t}

// Equation 19

The Balance Procedure is described in Algorithm 4, and ensures that U ′

t contains sufﬁciently many arms
that don’t have very high (top k + 1) means. The motivation for the procedure is somewhat subtle, and we
defer its discussion to the analysis in Appendix B.3.3, following Remark B.8:

Algorithm 4: Balance(U, R)
1 Input U, R
2 B ∼ Unif[R, max{0, ⌈ 5k(1)
3 U ′ ← U ∪ B , R′ ← R − B // Transfer B from R to U
4 Return (U ′, R′)

2 − |U | − 1

2 ⌉}] //Balancing Set

4 Lower bound for Independent Arms

In the bandit and marked-bandit settings, the upper bounds of the previous section depended on “information
sharing” terms that quantiﬁed the degree to which other arms occlude the performance of a particular arm
in a played set. Indeed, great care was taken in the design of the algorithm to minimize impact of this
information sharing. The next theorem shows that the upper bounds of the previous section for bandit and
semi-bandit feedback are nearly tight up to a similarly deﬁned information sharing term.

i=1 νi be a product distribution where each
νi is an independent Bernoulli with mean µi. Assume µ1 ≥ · · · ≥ µk > µk+1 ≥ · · · ≥ µn (the ordering is

Theorem 4.1 (Independent). Fix 1 ≤ p ≤ k ≤ n. Let ν =Qn
unknown to any algorithm). At each time the algorithm queries a set S′ ∈(cid:0)[n]

Then any algorithm that identiﬁes the top k arms with probability at least 1 − δ requires, in expectation, at

p(cid:1) and observes E[maxi∈S ′ Xi].

11

(cid:16) max

j=1,...,n

τj +

1
p

nXj=1

τj(cid:17) log( 1

2δ )

1−hj+(µj −∆j)hj

hj

hj

if j > k

if j ≤ k

for bandit observations, and

if j > k

if j ≤ k

for semi-bandit observations.

least

observations where

(i)

(ii)

where hj = maxS∈([n]−j

(1−µj −∆j)

1−hj+µj hj

∆2
j

(1−µj −∆j )µj

∆2
j
(1−µj )

τj =
τj =
p−1 )Qi∈a\j(1 − µi).

(1−µj )(µj −∆j )

∆2
j

∆2
j

Our lower bounds apply to our upper bounds when p = k. In the bandit setting, considering p < k
reveals a trade-off between the information sharing term, which decreases with larger p, with the beneﬁt of
a 1
p factor gained from querying p arms at once. One can construct different instances that are optimized by
the entire range of 1 ≤ p ≤ k. Future research may consider varying the subset size in an adaptive setting
to optimize this trade off.

The information sharing terms deﬁned in the upper and lower bounds correspond to the most pessimistic
and optimistic scenarios, respectively, and result from applying coarse bounds in exchange for simpler
proofs. Thus, our algorithm may fare considerably better in practice than is predicted by the upper bounds.
Moreover, when maxi µi − mini µi is dominated by mini µi our upper and lower bounds differ by constant
factors.

Finally, we note that our upper and lower bounds for independent measures are tailored to Bernoulli
payoffs, where the best k-subset corresponds to the top k means. However, for general product distributions
ν on [0, 1]n, this is no longer true (see Remark B.1). This leaves open the question: how difﬁcult is Best-
of-K for general, independent bounded product measures? And, in the marked feedback setting (where one
receives an index of the best element in the query), is this problem even well-posed?

Acknowledgements

We thank Elad Hazan for illuminating discussions regarding the computational complexity of the Best-
of-K problem, and for pointing us to resources adressing online submodularity and approximate regret.
Max Simchowitz is supported by an NSF GRFP award. Ben Recht and Kevin Jamieson are generously
supported by ONR awards , N00014-15-1-2620, and N00014-13-1-0129. BR is additionally generously
supported by ONR award N00014-14-1-0024 and NSF awards CCF-1148243 and CCF-1217058. This
research is supported in part by gifts from Amazon Web Services, Google, IBM, SAP, The Thomas and
Stacey Siebel Foundation, Adatao, Adobe, Apple Inc., Blue Goji, Bosch, Cisco, Cray, Cloudera, Ericsson,
Facebook, Fujitsu, Guavus, HP, Huawei, Intel, Microsoft, Pivotal, Samsung, Schlumberger, Splunk, State
Farm, Virdata and VMware.

12

References

[1] S´ebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-

armed bandit problems. Machine Learning, 5(1):1–122, 2012.

[2] Linhui Hao, Qiuling He, Zhishi Wang, Mark Craven, Michael A Newton, and Paul Ahlquist. Limited
agreement of independent rnai screens for virus-required host genes owes more to false-negative than
false-positive factors. PLoS Comput Biol, 9(9):e1003235, 2013.

[3] Katja Hofmann, Shimon Whiteson, and Maarten de Rijke.

A probabilistic method for in-
ferring preferences from clicks.
the 20th ACM International Confer-
ence on Information and Knowledge Management, CIKM ’11, pages 249–258, New York,
NY, USA, 2011. ACM.
doi: 10.1145/2063576.2063618. URL
http://doi.acm.org/10.1145/2063576.2063618.

ISBN 978-1-4503-0717-8.

In Proceedings of

[4] Mark M Huycke, Daniel F Sahm, and Michael S Gilmore. Multiple-drug resistant enterococci: the

nature of the problem and an agenda for the future. Emerging infectious diseases, 4(2):239, 1998.

[5] Rishabh K Iyer and Jeff A Bilmes. Submodular optimization with submodular cover and submodular
knapsack constraints. In Advances in Neural Information Processing Systems, pages 2436–2444, 2013.

[6] Kevin Jamieson, Matthew Malloy, Robert Nowak, and S´ebastien Bubeck. lil’ucb: An optimal explo-
ration algorithm for multi-armed bandits. In Proceedings of The 27th Conference on Learning Theory,
pages 423–439, 2014.

[7] Kwang-Sung Jun, Kevin Jamieson, Rob Nowak, and Xiaojin Zhu. Top arm identiﬁcation in multi-
armed bandits with batch arm pulls. In The 19th International Conference on Artiﬁcial Intelligence
and Statistics (AISTATS), 2016.

[8] Emilie Kaufmann and Shivaram Kalyanakrishnan. Information complexity in bandit subset selection.

In Conference on Learning Theory, pages 228–251, 2013.

[9] Emilie Kaufmann, Olivier Capp´e, and Aur´elien Garivier. On the complexity of best arm identiﬁcation

in multi-armed bandit models. The Journal of Machine Learning Research, 2015.

[10] Andreas Maurer and Massimiliano Pontil. Empirical bernstein bounds and sample variance penaliza-

tion. arXiv preprint arXiv:0907.3740, 2009.

[11] Filip Radlinski, Robert Kleinberg, and Thorsten Joachims. Learning diverse rankings with multi-armed
bandits. In Proceedings of the 25th international conference on Machine learning, pages 784–791.
ACM, 2008.

[12] Karthik Raman, Pannaga Shivaswamy, and Thorsten Joachims.

Online learning to diver-
sify from implicit feedback.
the 18th ACM SIGKDD International Con-
ference on Knowledge Discovery and Data Mining, KDD ’12, pages 705–713, New York,
NY, USA, 2012. ACM.
doi: 10.1145/2339530.2339642. URL
http://doi.acm.org/10.1145/2339530.2339642.

ISBN 978-1-4503-1462-6.

In Proceedings of

[13] Matthew Streeter and Daniel Golovin. An online algorithm for maximizing submodular functions. In

Advances in Neural Information Processing Systems, pages 1577–1584, 2009.

[14] Vijay V Vazirani. Approximation algorithms. Springer Science & Business Media, 2013.

13

[15] Yisong Yue and Carlos Guestrin. Linear submodular bandits and their application to diversiﬁed re-

trieval. In Advances in Neural Information Processing Systems, pages 2483–2491, 2011.

14

A Reduction from Max-K-Coverage to Best-of-K

As in the main text, let X = (X1, . . . , Xn) ∈ {0, 1}n be a binary reward vector, let S ∗ = {arg maxS∈([n]
k )
be set of all optimal k-subsets of [n] (we allow for non-uniqueness), and deﬁne the gap ∆ := Eν [maxi∈S ∗ Xi]−
maxS∈S\S ∗ Eν [maxi∈S Xi] as the minimum gap between the rewards of an optimal and sub-optimal k-set.
We say ˜S is α−optimal for α ≤ 1 if E[maxi∈ ˜S Xi] ≥ αE[maxi∈S ∗ Xi], where S∗ ∈ S ∗. We formally
introduce the classical Max-K-Coverage problem:

E[maxi∈S Xi]}

Deﬁnition 2 (Max-K-Coverage(m, k, V)). A Max-K-Coverage instance is a tuple (m, k, V), where V is a
collection of subsets V1, . . . , Vn ∈ 2[m]. We say S ⊂ V is a solution to Max-K-Coverage if |S| = k and S

maximizes |SVi∈S Vi|. Given α ≤ 1, we say S is an α approximation if |SVi∈S Vi| ≥ α maxS ′∈(V

It is well known that Max-K-Coverage in NP-Hard, and cannot be approximated to within α = 1 − 1

e +
o(1) under standard hardness assumptions [14]. The following theorem gives a reduction from Best of K
Indentiﬁcation (under any feedback model) to Max-K-Coverage:

k) |SVi∈S ′ Vi|.

Theorem A.1. Fix α ≤ 1, and let A be an algorithm which indentiﬁes an α-optimal k-subset of n
arms probability in time polynomial in n, k, and 1/∆, with probability at least η (under any feedback
model). Then there is a polynomial time α-approximation algorithm for Max-K-Coverage[m, k, V]which
succeeds with probability at least η. When α = 1, this implies a polynomial time algorithm for exact
Max − K − Coverage[m, k, V].

Proof. Consider an instance of Max − K − Coverage[m, k, V], and set n = |V|. We construct a reward
vector X ∈ {0, 1}n as follows: At each time t, draw ω uniformly from [m], and set Xi := I(ω ∈ Vi). We

[k](cid:1) which is α-optimal with probability
run A on the reward vector X, and it returns a candidate set bS ∈(cid:0) n
η. We then return the sets Vi ∈ V whose indicies lie in bS. We show this reduction completes in polynomial
time, and if bS is α-optimal, then {Vi}i∈bS is an α-approximation for the Max-K-Coverage instance.
∝ |Si∈S Vi|. Hence, an α-optimal subset S corresponds to an
Vi)] = E[I(ω ∈ Si∈S Vi)] =

Correctness: Since ω is uniform from [m], the reward of a subset S ⊂ [n] is E[maxi∈S I(ω ∈

α-approximation to the Max-K-Coverage instance.

Runtime: Let R(n, k, ∆) = O(poly(n, k, 1/∆)) denote an upper bound runtime of A, and let T (n, k, ∆) =

| Si∈S Vi|

m

O(poly(n, k, 1/∆)) be an upper bound on the number of queries required by Algorithm A to return to
α-optimal k-subset. Note that sampling ω takes O(m) time, and setting each Xi(ω) completes in time
m , . . . , 1}, so ∆ ≤ 1/m. Thus, the
runtime of our reduction is R(n, k, ∆) + O(mn) · T (n, k, ∆)) ≤ R(n, k, 1/m) + O(mn) · T (n, k, 1/m)) =
O(poly(n, k, m)).

O(mn). Moreover, the expected reward of any S ∈ (cid:0)[n]

k(cid:1) lies in {0, 1

Remark A.1. Note that the parameter m in the Max-K-Coverage instance shows up in the gap ∆ in
the runtime of the Max-K-Coverage instance. Our lower bound construction holds in the regime where
∆ = exp(−O(k)), which morally corresponds to Max-K-Coverage instances in the regime where m =
exp(Ω(k)).

B High Level Analysis for Independent Upper Bound

B.1 Preliminaries

At each stage t of Algorithm 3, there are three sources of randomness we need to account for. First, there is
the randomness over all events that occurred before we start sampling from UniformPlay: this randomness

15

determines the undecided, accept, and rejected sets Ut, At, and Rt, as well as their modiﬁcations U ′
R′
the state of our algorithm, in round t, before collecting samples.

t. In what follows, we will deﬁne a so-called “Data-Tuple” Dt := (Ut, At, Rt, U ′

t, and
t) which represents

t, R′

The second source of randomness comes from the uniform partitioning of U ′

t into the sets S(0), S(1), . . . , S(q)

(Algorithm 2, Line 2) and the draw of the Top-Off set S+ (Lines 3-3), at each call to UniformPlay. Finally,
there is randomness over the values that the arms Xℓ ∈ S ∪ S+ take, when pulled in PlayAndMark. To clear
up any confusion, we deﬁne the probability and expectation operators

P·|t [·] := P[·(cid:12)(cid:12)Dt]

and E·|t [·] := E[·(cid:12)(cid:12)Dt]

(21)

P·|t [·] and E·|t [·] condition on the data in Dt, and take expectations over the randomness in the partitioning
of U ′

t, draw of S+, and the values of each arm pulled.
Treating Dt as ﬁxed, we will let S denote a set with same distribution of one of the randomly partitioned
subsets S(1), . . . , S(q) of U ′
t in UniformPlay, S+ to denote a set with the distribution of the Top-Off set
chosen in UniformPlay. Recall that the purpose of S+ is simply to ensure that we pull exact k arms per
query. If either k(1) = k, or we do not enforce exactly k-pulls per round, then S+ = ∅. We remark that the
distributions of S and S+ are explicitly

S ∼ Unif[U ′

t, k(1)]

and S+ ∼(Unif[R′

R′

t, k(2)]

t ∪ Unif[At, k(2) − |R′
t|]

|R′
|R′

t| ≥ k(2)
t| < k(2)

(22)

Note that Dt exactly determines k(1) := |S|, which we recall is deﬁned at each round as min{|Ut|, k}
(Algorithm 2, Line 3). It also determines the size of the Top-Off set k(2) (Algorithm 2, Lines 4 and 9). We
further note that the play S(0) ∪S(0,+) (Algorithm 2, Lines 13-15 ) is also uniformly drawn as Unif[U ′
t, k(1)],
and hence has the same distribution of S. We also remark that

Claim B.1. The sets S and S+ are independent and disjoint under Pt. In the marked and semi-bandit
setting, there are always enough accepted/rejected arms in |At ∪ Rt| to ensure that we can ﬁll S+ with
k(2) arms. In the bandit setting, there are sufﬁciently many accepted/rejected arms in |At ∪ R′
t| as long as
n ≥ 7k/2.

This condition n ≥ 7k/2 is an artifact of the balancing set in our algorithm, and is discussed in more

detail in Section B.3.3.

B.2 Guarantees for General Feedback Models

The core of our analysis is common to the three feedback models. To handle bandits and marked/semi
bandits settings simultaneous, we deﬁne a win function W : [n] × 2[n] → {0, 1} which reﬂects the recording
strategy in PlayAndRecord

W(i, S′) =

1
1
0

if bandit setting and maxℓ∈S ′ Xℓ = 1
if marked/semi-bandit setting and observe Xi = 1
otherwise

(23)

That is, PlayAndRecord[S, S+, Y ] sets Yi = 1 ∀i ∈ S : W(i, S ∪ S+) = 1. The following lemma
characterizes the distribution of our estimations ˆµi,t

Lemma B.2.

ˆµi,t ∼

1

T (t)

Binomial(¯µi,t, T (t)) and E[ ˆVi,t] = Vi,t

(24)

16

where

¯µi,t = Et[W(i, S ∪ S+)(cid:12)(cid:12)i ∈ S] and Vi,t := ¯µi,t(1 − ¯µi,t)

Moreover, in semi-bandit and marked bandit settings, and if µ1 ≤ 1 in the bandit setting, then given i, j ∈
St, ¯µi,t > ¯µj,t if and only if µi > µj.

(25)

Remark B.1. In the partial feedback models, the property that ¯µi,t > ¯µj,t if and only if µi > µj is quite
particular to independent Bernoulli observations. The case of dependent Bernoullis measures is adressed by
Theorem 2.1. For independent, non-Bernoulli distributions, consider the setting where n = 3, k = 2, and let
a.s.= 2/3, and X3 ∼ Bernoulli(1/2). Then, E[max(X1, X2)] =
X1, X2, X3 be independent, where X1
2/3, while E[max(X1, X3)] = E[max(X2, X3)] = 1
3 = 5/6. Hence, if S ∼ Unif[{1, 2, 3}, 2],

2 + 1

d= X2

E[maxℓ∈S Xℓ(cid:12)(cid:12)3 ∈ S] > E[maxℓ∈S Xℓ(cid:12)(cid:12)2 ∈ S] = E[maxℓ∈S Xℓ(cid:12)(cid:12)1 ∈ S].

The last preliminary is to deﬁne the stage-wise comparator arms ci,t for i ∈ Ut:

ci,t :=(min{j ∈ Ut : j > k}

max{j ∈ Ut : j ≤ k}

i ≤ k
i > k

(26)

Intuitively, the comparator arm is the arm we are mostly to falsely accept instead of i when i ≤ k, and
falsely reject instead of i when i > k.

Remark B.2. As long as the accept set At only consists of arms i ≤ k, and Rt only consists of arms i > k,
ci,t is guaranteed to exists. Indeed, ﬁx i ∈ Ut, and suppose ci,t does not exist. If i ≤ k, then this would
mean that Ut doesn’t contain any rejected arms, but since At only contains accepted arms, all rejected arms
are in R′
t, in which case Algorithm 3 will have already terminated (Line 14). A similar contradiction arises
when i > k.

Finally, we deﬁne the stagewise effective gaps

∆i,t := |¯µi,t − ¯µci,t,t|

(27)

Observe that, conditioned on the data in Dt, the means ¯µi,t, gaps ∆i,t and the variances Vi,t are all
deterministic quantities. We now have the following guarantee for Algorithm 3, which holds for the bandit,
marked-bandit, and semi-bandit regimes:

Lemma B.3 (General Performance Guarantee for Successive Elimination). In the bandit, marked-bandit,
and semi-bandit settings, the following is true for all t ∈ {0, 1, . . . } simultaneously with probability 1 − δ:
Algorithm 3 never rejects i if i ≤ k and never accepts i if i > k. Furthermore, if for a stage t and arm
i ∈ Ut, the number of sample T (t) := 2t satisﬁes

where

T (t) ≥ Tn,δ(τi,t) := τi,t log(cid:18) 24n

δ

log(cid:18) 12nτi,t
δ (cid:19)(cid:19)

τi,t :=

56
∆i,t

+

256 max{Vi,t, Vi,ci,t}

∆2
i,t

then by the end of stage t, i is accepted if i ≤ k and rejected if i > k + 1.

17

(28)

(29)

Remark B.3. The above theorem holds quite generally, and its proof abstracts out most details of best-of-k
observation model. In fact, it only requires that (1) for each i ∈ Ut, ˆµi,t ∼ 1
T (t) Binomial(¯µi,t, T (t)) and (2)
¯µi,t > ¯µj,t ⇐⇒ µi > µj. In our three settings of interest, both conditions are ensured by Lemma B.2. It
also holds in the semi-bandit setting when the arms have arbitrary distributions, as long as the rewards are
bounded in [0, 1].

The ﬁnal lemma captures the fact that each call to UniformPlay often makes fewer than |Ut| queries to

pull each arm in Ut:

Lemma B.4. Suppose that, at round t, each call of uniformly play queries no more than α|Ut|/k times when
|Ut| ≥ k, and no more than α samples when |Ut| ≤ k. Let t∗
i be the ﬁrst stage at which i /∈ Ut. Then,
Algorithm 3 makes no more than the following number of queries

4αT (t∗

σ(1)) +

2α
k

nXi=k+1

T (t∗

σ(i))

(30)

where σ is permutation chosen so that t∗

σ(1) ≥ t∗

σ(2) ≥ · · · ≥ t∗

σ(n), and T (t) = 2t, as above.

Remark B.4. In the marked-bandit and semi-bandit settings, it is straightforward to verify that one can
take α = 2 in the above lemma. This is because Algorithm 3 always calls UniformPlay (Line 8) on U ′
t = Ut
(Algorithm 4). Then, UniformPlay (Algorithm 8) partitions Ut into at most ⌈|Ut|/k(1)⌉ queries S+
q . Recall
that k(1) = min{|Ut|, k} (Algorithm 3, Line 3) so that ⌈|Ut|/k(1)⌉ ≤ ⌈|Ut|/k⌉ ≤ 2|Ut| when |Ut| ≥ k,
while |Ut|/k(1) = 1 ≤ 2|Ut| once |Ut| < k. Controlling bound on α is slightly more involved in the bandit
setting, and is addressed in Claim B.6.

B.3 Specializing the Results

In the following sections, we again condition on the data Dt := (Ut, At, Rt, U ′
t). We proceed to compute
the stage-wise means ¯µi,t, variances Vi,t, and time parameters τi,t in Lemma B.3. As a warm up, let’s handle
the semi-bandit case:

t, R′

B.3.1 Semi-Bandits

In Semi-Bandits, ¯µi,t = µi, and so

τi,t = τi =

256 max{Vi, Vci,t}

∆2
i

+

56
∆i

as in Theorem 3.1. Noting that ci,t > k if i ≤ k, while ci,t ≤ k if i > k, we can bound

Vci,t ≤(maxj>k Vj

maxj≤k Vj

i ≤ k
i > k

(31)

(32)

Plugging the above display into Equation 31, we see that τi,t ≤ τi, as deﬁned in Theorem 3.1. Combining
this observation with Lemmas B.3 and B.4 and Remark B.4 concludes the proof of Theorem 3.1. Note that
we pick up an extra factor of two, since we might end up collected at most 2Tn,δ(τi) samples before either
accepting, or rejected, an arm i.

18

B.3.2 Marked Bandit

In marked bandits, the limited feedback induces an “information-sharing” phenomenon between entries in
the same pull. We can now deﬁne the information sharing term as:

i,j,t = Et"

H M

1

1 +Pℓ∈S∪S+−{i,j}

I(Xℓ = 1)(cid:12)(cid:12)i ∈ S#

where again S+ has the distribution as S+ in Algorithm 2, and the operator Et treats the data in Dt as
deterministic. The following remark explains the intuition behind H M

i,j,t.

Remark B.5. When we query a set S ∪ S+, marked bandit feedback uniformly selects one arm in {ℓ ∈
S ∪ S+ : Xℓ = 1} if its non-empty and selects no arms otherwise. Hence, the probability of receiving the
feedback that Xi = 1 given that i ∈ S and Xi = 1 is

(33)

(34)

Et"

1

1 +Pℓ∈S∪S+−{i}

I(Xℓ = 1)(cid:12)(cid:12)i ∈ S#

The above display captures how often the observation Xi = 1 is “suppressed” by another arm in the pull. In
contrast, H M
i,j,t is precisely the probability of receiving feedback that Xi = 1, given that Xi = 1 and i ∈ S,
but under a slightly different observation model where arm j is never marked, and instead we observe a
marking uniformly from {ℓ ∈ S ∪ S+ − {j} : Xℓ = 1}. Hence, we can think of H M
i,j,t as capturing how often
arms other than j prevent us from observing Xi = 1. Note that the smaller H M
i,j,t, the more the information
about Xi is suppressed.

We also remark on the scaling of H M

i,j,t:

Remark B.6. Given i ∈ S, |S ∪ S+ − {i, j}| ≤ k − 1, and thus H M
i,j,t ≥ 1/k. When the means are all
high, its likely that Ω(k) arms ℓ in a query will have Xℓ = 1, and so we should expect that H M
i,j,t = O(1/k).
When the means are small, say O(1/k), then H m
i,j,t can be as large as Ω(1). This is because if we observe
that Xi = 1 from a query S ∪ S+, then its very likely that Xi = 1 in only a constant fraction of them.
Stated otherwise: if the means are small, then seeing just one arm uniformly for which Xi = 1 as about as
informative as seeing all the values of all the arms at once.

With this deﬁnition in place, we have

Proposition B.5.

¯µi,t − ¯µj,t = (µi − µj)H M

i,j,t and Vi,t ≤ µiH M
i,j,t

As a consequence, we have

τi,t ≤

where τ M

i

is as in Equation 12.

1
H M

i,ci,t,t(cid:18) 256 max{µi, µci,t}

∆2
i

+

56

∆i(cid:19) ≤

τ M
i
H M

i,ci,t,t

(35)

(36)

Remark B.7. In the above proposition, the variance term Vi,t has a factor H M
the H M
our sample complexity would have to pay a factor of (H M

i,j,t, which cancels out one of
i,t. If we did not take advantage of a variance-adaptive conﬁdence interval,

i,j,t terms from the gap ∆2

i,j,t)−2 instead of just (H M

i,j,t)−1.

19

It is straightforward to give a worst case lower bound on H M

i,j,t ≥ H M := EX1,...,Xk−1"

H M

I(Xℓ)#

(37)

As in the semi-bandit case, we can prove the ﬁrst part Theorem 3.2 by stringing together Lemmas B.3
and B.4 and Remark B.4, using Proposition B.5 to control τi,t, and Equation 37 to give a worst case bound
on the information sharing term. The argument for improving the sample complexity when we can pull fewer
than k arms per query (Equation 14 in Theorem 3.2) is a bit more delicate, and is deferred to section C.2.1.

i,j,t:

1

1 +Pℓ∈[k−1]

B.3.3 Bandit Setting

Fix i, j ∈ U ′
t. When UniformPlay pulls both i and j in the same query, we receive no relative information
about Xi versus Xj. Moreover, when another arm Xℓ for ℓ ∈ S ∪ S+ − {i} takes a value 1 (now assuming
j /∈ S ∪ S+), it masks all information about Xi. Hence the analogue of the information sharing term H M
i,j,t
is the product H B

i,j,t · κ1, where

and

(38)

H B

i,j,t := P·|t(cid:2){Xℓ = 0 : ∀ℓ ∈ S ∪ S+ − {i}}(cid:12)(cid:12)i ∈ S, j /∈ S(cid:3)
κ1 := P·|t(cid:2)j /∈ S ∪ S+(cid:12)(cid:12)i ∈ S(cid:3) = P·|t(cid:2)j /∈ S(cid:12)(cid:12)i ∈ S(cid:3)

We defer the interested reader to the proof of Lemma C.1 in the appendix, which transparently derives the
dependence on H B
i,j,t · κ1. We also show that, due the uniformity of the distribution of S, κ1 does not depend
on the particular indices i and j.
Remark B.8. As in the Marked Bandit setting, we use a variance-adaptive conﬁdence interval to cancel
out one factor of κ1H B
i,j,t. This turns out to incur a dependence on a parameter κ2 - deﬁned precisely in
Section C.3 - which roughly corresponds to the inverse of the fraction of arms in U ′
t whose means do not lie
in the top k + 1.

The balancing set B is chosen precisely to control κ1 and κ2 It ensures that arms i, j ∈ Ut do not
co-occur in the same query with constant probability (thus bounding κ1 below) and that each draw of S ∼
Unif[U ′
t, k(1)] contains a good fraction of small mean arms as well (thus bounding κ2 above). The following
claim makes this precise:

Claim B.6. Let κ1 = P·|t(cid:2)j ∈ S(cid:12)(cid:12)i ∈ S(cid:3) and κ2 be as in Section C.3, Equation 58. Then choice of

5k(1)

|B| = max{0, ⌈

− |U | −

⌉}

(39)

2

1
2

be as in Algorithm 4 ensures that κ1 ≥ 1/2, κ2 ≤ 2, and |U ′| ≤ 5
Algorithm 4 can always sample B from the reject set R.
Remark B.9 (Conditions on n). The condition n ≥ 7k/2 ensures that the balancing set B is large enough
to bound both κ1 and κ2. If we omit the balancing set, our algorithm can then identify the top k means for
any n ≥ k, albeit with worse sample complexity guarantees.
Proposition B.7 (Characterization of the Gaps). For all i, ∆i,t ≥ ∆iH B

2 |U |. Moreover, as long as n ≥ 7k
2 ,

i,ci,t,t and

max{Vi,t, Vci,t}

∆2
i,t

≤ (1 + 2κ2)

≤

1 + 2κ2
κ1H B

·

i,ci,t,t
where κ1 and κ2 are as in Claim B.6.

max{(1 − µi)¯µi,t, (1 − µci,t,t)¯µci,t,t}

∆i ∆i,t

i (2(1 − µk+1)µi + (1 − µk+1)2(1 − H B

2(1 − µi)µk+1 + (1 − µi)2(1 − H B

1
∆2

i,ci,t,t)

i,ci,t,t)

(40)

i ≤ k

i > k

20

Remark B.10. Again, the variance-adaptivity of our conﬁdence interval reduces our dependence on information-
sharing from (H B

i,j,t)−2 to (H B

i,j,t)−1.

Plugging in κ1 and κ2 as bounded by Claim B.6,

τi,t ≤

56
∆iH B

i,ci,t,t

+

2560
H B

i,ci,t,t

·

i (2(1 − µk+1)µi + (1 − µk+1)2(1 − H B

2(1 − µi)µk+1 + (1 − µi)2(1 − H B

1
∆2

i,ci,t,t)

i,ci,t,t)

We can wrap up the proof by a straightforward lower bound on H B

i,j,t:

H B

i,j,t ≥ H B := Yℓ∈[k−1]

(1 − µℓ)

i ≤ k

i > k

(41)

(42)

and by invoking Claim B.6 to apply Lemma B.3 with α = 5/2 as long as n ≥ 7k/2.
Remark B.11 (Conditions on µi). The condition µi < 1 ensures identiﬁability, since the top k arms would
be indistinguishable from any subset of k arms which contains a arm i for which µi = 1. More quantitatively,
this condition ensures that the information sharing term is nonzero.
Remark B.12 (Looseness of Equation 42). When all the means µ1, . . . , µn are roughly on the same order,
the worst case bound on H B
i,j,t in Equation 42 is tight up to constants. Then, as remarked 3.1, there is never
an advantage to looking at k-arms at a time and receiving their max over testing each arm individually. On
the other hand, if the means vary widely in their magnitude, then there may very well be an advantage to
querying k arms at a time.

For example, suppose there are k high means µ1, . . . , µk ≥ 1/2, and the remaining n − k means are
order 1/k, and n ≫ k2. Then, in the early rounds (|Ut| ≫ k2), a random pull of S will contain at most a
constant number of means from with top k with constant probability, and so H B
i,j,t = Ω((1 − O(1/k))k) =

Ω(1). From Lemma C.1, we see empirical meansbµi,t of the high meaned arms will be Ω(1) variance. Thus,

for early stages t, τi,t = O(1/∆2
i ). That is, we neither pay the penalty for a small information sharing term
that we pay when the means are uniformly high, nor pay a factor of k in the variance which would occur
when the means are small. However, we still get to test k arms a time, and hence querying k arms at a time
is roughly k times as effective as pulling 1.

C Computing τi,t with (Marked-)Bandit Feedback

C.1 Preliminaries

We need to describe the distribution of two random subsets related to S. Again, taking the data Dt as given,
deﬁne the sets S−i∨j and S−i∧j as follows

S−i∧j ∼ Unif[U ′

t − {i, j}, k(1) − 2]

and S−i∨j ∼ Unif[U ′

t − {i, j}, k(1) − 1]]

(43)

S−i∧j (read: “S minus i and j”) has the same distribution as S − {i, j} given that both i and j are in S.
Similarly, S−i∨j (read: “S minus i or j”) has the same distribution as S − {i, j} given that either i or j are

in S, but not both. Equivalently, it has the same distribution as S − {i}(cid:12)(cid:12)i ∈ S, j /∈ S, and symmetrically, as
S − {j}(cid:12)(cid:12)j ∈ S, i /∈ S. We will also deﬁne the constant

(44)

κ1 := Pt(j /∈ S(cid:12)(cid:12)i ∈ S) = 1 −

k(1) − 1
|U ′
t| − 1

Note that the deﬁnition of κ1 is independent of i and j, is deterministic given the data Dt, and is well deﬁned
since Algorithm 3 always ensures |U ′

t| > 12.

2the undecided set, and its modiﬁcation, always contain at least two elements

21

C.2 Marked Bandits

In marked bandits, Ut = U ′

t. Recall the deﬁnition

1

H M

i,j,t = E·|t"

I(Xℓ = 1)(cid:12)(cid:12)i ∈ S#
1 +Pℓ∈S∪S+−{i,j}
By splitting up into the case when j /∈ S(cid:12)(cid:12)i ∈ S and j ∈ S(cid:12)(cid:12)i ∈ S, we can also express
1 +Pℓ∈S−i∨j∪S+ I(Xℓ = 1)#
1 +Pℓ∈S−i∧j∪S+ I(Xℓ = 1)#

i,j,t = κ1E·|t"
+ (1 − κ1)E·|t"

H M

1

1

(45)

(46)

(47)

(48)

(49)

(50)

Note that S−i∨j is well deﬁned except when |Ut − {i, j}| = |Ut| − 2 < k(1) − 1. Since |Ut| ≥ k(1),
this issue only occurs if |Ut| = k(1) − 1, and thus κ(1) = 0. To make our notation more compact, we let

|S′|W = Pℓ∈S ′ I(Xℓ = 1) (think “cardinality of winners”). In this notation, the above display takes the

form:

i,j,t = κ1E·|th(cid:0)1 +(cid:12)(cid:12)S−i∨j ∪ S+(cid:12)(cid:12)W(cid:1)−1i + (1 − κ1)E·|th(cid:0)1 +(cid:12)(cid:12)S−i∧j ∪ S+(cid:12)(cid:12)W(cid:1)−1i

Proof of Proposition B.5. Our goal is to bound ¯µi,t − ¯µj,t.

H M

By the law of total probability and the deﬁnition of κ1, we have

¯µi,t = µiE·|th(1 + |S − {i}|W )−1(cid:12)(cid:12)i ∈ Si
= µiP·|t(cid:2)j /∈ St(cid:12)(cid:12)i ∈ S(cid:3) E·|th(cid:0)1 +(cid:12)(cid:12)S−i∨j ∪ S+(cid:12)(cid:12)W(cid:1)−1i
+ µiP·|t(cid:2)j ∈ S(cid:12)(cid:12)i ∈ S(cid:3) E·|th(cid:0)1 +(cid:12)(cid:12){j} ∪ S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)−1i
= µiκ1E·|th(cid:0)1 +(cid:12)(cid:12)S+ ∪ S−i∨j(cid:12)(cid:12)W(cid:1)−1i + µi(1 − κ1)E·|th(cid:0)1 +(cid:12)(cid:12){j} ∪ S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)−1i
µj E·|t(cid:2)(2 +(cid:12)(cid:12)S+ ∪ S−i∧j(cid:12)(cid:12)W)−1(cid:3) + (1 − µj)E·|t(cid:2)(1 +(cid:12)(cid:12)S+ ∪ S−i∧j(cid:12)(cid:12)W)−1(cid:3)

By conditioning on the events when arm j takes the values of 1 or zero, respectively, we can decompose
E[(1 + |{j} ∪ S−i∧j|W )−1] into

Substituting into the previous display and rearranging yields

¯µi,t = µiH M

Hence, we conclude

i,j,t + µiµj(1 − κ1)E·|th(cid:0)2 +(cid:12)(cid:12)S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)−1 −(cid:0)1 +(cid:12)(cid:12)S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)i

To control Vi,t, we have 1 − µi,t ≤ 1, and

¯µi,t − ¯µj,t = (µi − µj)H M
i,j,t

¯µi,t = µiκ1Eh(cid:0)1 +(cid:12)(cid:12)S+ ∪ S−i∨j(cid:12)(cid:12)W(cid:1)−1i + µi(1 − κ1)Eh(cid:0)1 +(cid:12)(cid:12){j} ∪ S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)−1i

≤ µiκ1Eh(cid:0)1 +(cid:12)(cid:12)S+ ∪ S−i∨j(cid:12)(cid:12)W(cid:1)−1i + µi(1 − κ1)Eh(cid:0)1 +(cid:12)(cid:12)S+ ∪ S−i∧j(cid:12)(cid:12)W(cid:1)−1i

= µiH M
i,j,t

22

C.2.1 Improved Complexity With Fewer than k Pulls per Query

In this section, we prove the second part of Theorem 3.2, which describes the setting where we permit fewer
than k pulls per query.

Proof of Second Part of Theorem 3.2. We mirror the proof of Lemma B.4 in Section D.3, and adopt its
notation where t∗
i be the ﬁrst stage at which i /∈ Ut, let t0 be the ﬁrst stage for which |Ut| < k. The
same argument from Lemma B.4 show that

2α
k

nXi=1

T (t∗

i ) +Xt>t0

I(|Ut| > 0)T (t)

(51)

If tf in is the last stage of the algorithm for which |Ut| > 0, then the doubling nature of the sample size lets
us bound

I(|Ut| > 0)T (t) ≤ 2T (tf in)

(52)

Xt>t0

i : i ∈ Utf in}. We now bound τ M

i,j,tf in

for i ∈ Utf in and any j ∈ Utf in. Indeed,

and clearly tf in = min{t∗
recall that

H M

i,j,t = κ1E·|th(cid:0)1 +(cid:12)(cid:12)S−i∨j ∪ S+(cid:12)(cid:12)W(cid:1)−1i + (1 − κ1)E·|th(cid:0)1 +(cid:12)(cid:12)S−i∧j ∪ S+(cid:12)(cid:12)W(cid:1)−1i

When we are allowed to pull fewer than k arms at once, then the “Top-Off Set” S+ is empty (Algorithm 3,
Line 3), and so the above is bounded above by max{|S−i∨j|, |S−i∧j|} ≤ |Ut| − 1. Thus, we can easily
bound H M

|Ut| . In particular, this bound holds when j = ci,t. Hence,

i,j,t ≥ 1

(53)

τi,ci,t,tf in =

τi

Hi,ci,t,tf in

≤ |Utf in| · τi

Recalling that Tn,δ(τ ) is monotone, and applying the easy to verify identity that

for all k′ ≤ n, we have that for all i ∈ Utf in that

Tn,δ(τ · k′) ≤ 2k′Tn,δ(τ )

T (t∗

i ) ≤ 2Tn,δ(τi,j,tf in) ≤ 2Tn,δ(τi|Utf in|) ≤ 4|Utf in|Tn,δ(τi)

(54)

(55)

(56)

If σ is a permutation such that τσ(1) ≥ τσ(2) ≥ · · · ≥ τσ(n), then for i ∈ Utf in, τi ≤ τσ(|Utf in |). Hence,
taking the worst case over |Utf in |, we have

I(|Ut| > 0)T (t) ≤ 2T (tf in) ≤ 8|Utf in |T (τσ(|Utf in |)) ≤ 8 max
i∈[k−1]

iT (τσ(i))

(57)

Xt>t0

C.3 Bandits

In this section, we drop the dependence on t from the sets Ut, At, Rt, U ′
set” from Algorithm 4; thus, U ′ = U ∪ B, A′ = A − B, and R′ = R − B. Let κ1 = 1 − k(1)−1
Equation 44, and let

t, and let B be the “balancing
|U ′|−1 be as in

t, R′

κ2 :=

k(1) − 1

|U ′| − 2k(1)

23

(58)

Finally, introduce the loss function L : 2[n] → {0, 1} by L(S′) = I(∀ℓ ∈ S′ : Xℓ = 0). Note E[L({ℓ})] =
1 − µℓ, and if two sets S′, S′′ ⊂ [n] are disjoint, then L(S′ ∪ S′′) = L(S′) · L(S′′). Moreover, if S′
and S′′ are almost-surely disjoint, random subset of [n] which are independent given the data in Dt, then
EtL(S′ ∪ S′′) = EtL(S′) · EtL(S′′). Hence, the information sharing term can be expressed as

H B

i,j,t := E·|t(cid:2)L(S−i∨j ∪ S+)(cid:3) = E·|t [L(S−i∨j)] · E·|t(cid:2)L(S+)(cid:3)

and note that this term is nonzero as long as all the means are less than 1, since with nonzero probability,
any query of a nonempty set has a nonzero probability of all its arms taking the value zero. The following
lemma gives an expression of (1 − ¯µi,t) in terms of κ1, µi, H B

i,j,t, and an error term:

(59)

Lemma C.1 (Computation of ¯µi,t). For any i 6= j ∈ U ′, we have that

1 − ¯µi,t = (1 − µi)κ1H B

i,j,t · (1 + (1 − µj) Erri,j,t)

where the term

Erri,j,t :=

1 − κ1

κ1

·

E·|t [L(S−i∧j)]
E·|t [L[S−i∨j]

=

k(1) − 1
|U ′| − k(1)

·

E·|t [L(S−i∧j)]
E·|t [L[S−i∨j]

(60)

(61)

is symmetric in i and j.

Proof. Using the independence of the arms, we have

1 − ¯µi,t = E·|t(cid:2)L(S ∪ S+)(cid:12)(cid:12)i ∈ S(cid:3) = (1 − µi)E·|t(cid:2)L(S − {i})(cid:12)(cid:12)i ∈ S(cid:3) E·|t(cid:2)L(S+)(cid:3)

For i 6= j ∈ U ′, we have

E·|t(cid:2)L(S − {i})(cid:12)(cid:12)i ∈ S(cid:3) = κ1E·|t(cid:2)L(S − {i})(cid:12)(cid:12)i ∈ S, j /∈ S(cid:3) + (1 − κ1)E·|t(cid:2)L(S − {i})(cid:12)(cid:12)i ∈ S, j ∈ S(cid:3)

= κ1E·|t [L(S−i∨j)] + (1 − κ1)E[L({j} ∪ S−i∧j]
= κ1E·|t [L(S−i∨j)] + (1 − κ1)(1 − µj)E[L(S−i∧j)]

= κ1E·|t [L(S−i∨j)](cid:18)1 + (1 − µj)

1 − κ1

κ1

·

E·|t [L(S−i∧j)]

E·|t [L(S−i∨j)](cid:19)

The result now follows from plugging in the above display into the ﬁrst one, and using the deﬁnition of
κ1.

Since both H B

i,j,t and Erri,j,t are symmetric in i and j, we get an exact expression for the gaps.

Corollary C.2 (Bandit Gaps).

In particular, ¯µi,t > ¯µj,t if and only if µi > µj, and

¯µi,t − ¯µj,t = κ1Hi,j,t · (µi − µj)

∆i,t = κ1Hi,ci,t,t ·(cid:12)(cid:12)µi − µci,t(cid:12)(cid:12)

(62)

(63)

To get an expression for τi,t, as deﬁned in Lemma B.3, we need to get an expression for the ration of the
. We decompose Vi,t = (1 − ¯µi,t)¯µi,t, and similarly for ci,t, and

variance to the gap-squared, max{Vi,t,Vci,t }
begin by bounding (1 − ¯µi,t)/∆i,t and (1 − ¯µci,t,t)/∆i,t:

∆2
i,t

24

Lemma C.3.

1 − ¯µi,t

∆i,t

≤

(1 + 2κ2)(1 − µi)

∆i

and

1 − ¯µci,t,t

∆i,t

≤

(1 + 2κ2)(1 − µci,t)

∆i

(64)

This result uses 1 − ¯µi,t to kill off one factor of κ1H B

i,j,t from the stagewise gaps ∆i,t, so that our ﬁnal
expression τi,t depends on the inverse information sharing term, and not its square. The proof of the above
lemma is somewhat delicate, and we defer it to the end of this section. Next, we need an upper bound on
¯µi,t. Clearly, we can upper bound this quantity by 1, but this can be loose when the means are small, and so
we introduce the following lemma

Lemma C.4.

max{(1 − µi)¯µi,t, (1 − µci,t)¯µci,t,t}

∆i,t

≤

1

κ1∆iH B

i,ci,t,t(2(1 − µk+1)µi + (1 − µk+1)2(1 − H B

2(1 − µi)µk+1 + (1 − µi)2(1 − H B

i,ci,t,t)

i,ci,t,t)

(65)

(66)

i ≤ k

i > k

Combining Corollary C.2, Lemma C.3 and C.4, establishes Proposition B.7

C.3.1 Proof of Lemma C.4

We start out with a simple upper bound on ¯µi and ¯µci,t:
Lemma C.5.

¯µi,t ≤ µi + µci,t + (1 − µi)(1 − H B

i,ci,t,t)

(67)

and similarly when we swap i and ci,t
Proof of Lemma C.5. Let c = ci,t. For S′ ∈ 2[n], deﬁne the “win” function W(S′) : 1 − L(S′) which takes
a value of 1 if ∃ℓ ∈ S′ : Xℓ = 1. By a union bound, E[W(S′ ∪ S′′)] ≤ E[W(S′)] + E[W(S′′)], even when
S′ and S′′ are dependent. Hence,

Now, using the union bound property of W, we have

Finally, by decomposing into the cases when c ∈ S and c /∈ S, we

Observe that S−i∧c ∼ Unif[U ′, k(1) − 2], whereas S−i∨c ∼ Unif[U ′, k(1) − 1]; consequently, playing S−i∨c
has a greater chance of yielding a win than S−i∧c. Thus, we can bound

¯µi,t = E·|thW(S ∪ ˜S)(cid:12)(cid:12)i ∈ Si

= E·|thI(Xi = 1)W(S ∪ ˜S)(cid:12)(cid:12)i ∈ Si + E·|thI(Xi 6= 1)W(S ∪ ˜S)(cid:12)(cid:12)i ∈ Si
≤ µi + (1 − µi)E·|thW(S − {i} ∪ ˜S)(cid:12)(cid:12)i ∈ Si
E·|thW(S − {i} ∪ ˜S)(cid:12)(cid:12)i ∈ Si ≤ µc + E·|thW(S − {i} − {c} ∪ ˜S)(cid:12)(cid:12)i ∈ Si
E·|thW(S − {i} − {c} ∪ ˜S)(cid:12)(cid:12)i ∈ Si = κ1EtW(S−i∨c) + (1 − κ1)E·|t [S−i∧c]
E·|thW(S − {i} − {c} ∪ ˜S)(cid:12)(cid:12)i ∈ Si ≤ E·|t [W(S−i∨j)] = 1 − H B

i,c,t

25

(68)

(69)

(70)

(71)

(72)

(73)

Now, Lemma C.4 follows from the following claim, together with the expression for the gap ∆i,t from

Corollary C.2:

Claim C.6.

max{(1 − µi)(µi + µci,t), (1 − µci,t)(µi + µci,t)}

|µi − µci,t|

≤

2
∆i

·((1 − µk+1)µi

(1 − µi)µk

i ≤ k
i > k

and

max{(1 − µi)2, (1 − µci,t)2}

|µi − µci,t|

≤

1

∆i((1 − µk+1)2

(1 − µi)2

i ≤ k
i > k

(74)

(75)

Proof. Suppose ﬁrst that i > k, so that (1 − µci,t)(µi + µci,t) ≤ (1 − µi)(µi + µci,t) ≤ 2(1 − µi)µci,t. Then,

2(1 − µi)µci,t
|µci,t − µi|

=

=

≤

≤

≤

2(1 − µi)µci,t

µci,t − µi
2(1 − µi)
1 − µi/µci,t
2(1 − µi)
1 − µi/µk
2(1 − µi)µk

µk − µi

2(1 − µi)µk

∆i

(76)

(77)

(78)

(79)

(80)

The rest follows from similar arguments.

C.3.2 Proof of Lemma C.3

Lemma C.3 follows from the expression for the gaps in Corollary C.2, and the following technical lemma:

Lemma C.7. Fix i ∈ U ′, and let c ∈ U ′ ∩ [k] if i > k and c ∈ U ′ − [k]. Then,

1 − ¯µi,t
|µi − µc|

≤

1 − µi

∆i

· κ1(1 + 2κ2)Hi,j,c

1 − ¯µc,t
|µi − µc|

≤

1 − µc

∆i

· κ1(1 + 2κ2)Hi,j,c

and

Proof. By Lemma C.1,

1 − ¯µi,t = (1 − µi)κ1Hi,c,t (1 + (1 − µc)Erri,c,t) .

(81)

(82)

(83)

The following lemma, proved later, controls the term on Erri,c,t.
Lemma C.8. Suppose that j ∈ [k + 1] , and that the balancing set B satisﬁes B ∩ [k] = ∅. Then, for any
i 6= c ∈ U (where possibly j 6= c), we have

(1 − µj)Erri,c,t ≤ κ2.

(84)

26

When i > k, c ∈ [k] and 1 − ¯µc,t ≤ 1 − ¯µi,t so that

1 − ¯µc,t

|¯µi,t − ¯µc,t|

≤

≤

≤

≤

1 − ¯µi,t

|¯µi,t − ¯µc,t|
(1 − µi)κ1Hi,c,t(1 + κ2)

|¯µi,t − ¯µc,t|
(1 − µi)(1 + κ2)

|µi − µc|

(1 − µi)(1 + κ2)

∆i

(85)

(86)

(87)

(88)

where (86) follows from combining (83) and Lemma C.8, (87) follows from Corollary C.2, and (88) holds
by |µi − µc| ≥ max{∆i, ∆c}. Moreover, swapping the roles of c and i, we have that when i ≤ k,

1 − ¯µc,t

|¯µi,t − ¯µc,t|

≤

≤

(1 − µc)κ1Hi,c,t(1 + κ2)

|¯µi,t − ¯µc,t|
(1 − µc)(1 + κ2)

.

∆i

(89)

(90)

1−¯µi,t
The ﬁnal case we need to deal with is the computation of
|¯µi,t−¯µc,t| when i ≤ k. The problem is that it might
be the case that c > k + 1, impeding the application of Lemma C.8. We get around this issue by breaking
up into cases:

(1) If 1−µc and 1−µi are on the same order, we are not in so much trouble. Indeed, if 1−µc ≤ 2(1−µi),

then, we have

1 − ¯µi,t = (1 − µi)Hi,c,t (1 + (1 − µc)Erri,c,t)

≤ (1 − µi)Hi,c,t (1 + 2(1 − µk+1)Erri,c,t)
≤ (1 − µi)Hi,c,t (1 + 2κ2)

where the last step follows from applying Lemma C.8 with j = k + 1.

(2) What happens when 1 − µc > 2(1 − µi)? Then we have

(µi − µc)−1(1 − µc) =

1 − µc

∆i

·

∆i

µi − µc
∆i

·

·

1 − µc
1 − µk+1

More suggestively, we can write the above as

=

1 − µk+1

∆i

µi − µc

1 − µk+1

∆i

·

(1 − µk+1) − (1 − µi)
(1 − µc) − (1 − µi)

·

1 − µc
1 − µk+1

(91)

As soon as (1 − µc) > 2(1 − µi), Equation 91 is bounded by

(µi − µc)−1(1 − µc) =

1 − µk+1

∆i

·

(1 − µk+1) − (1 − µi)

1
2 (1 − µc)

·

1 − µc
1 − µk+1

=

2((1 − µk+1) − (1 − µi))

∆i

≤ 2

1 − µk+1

∆i

27

Hence,

1

µi − µc

· Hi,c,t (1 + (1 − µc)Erri,c,t) =

≤

=

≤

+

Hi,c,t
µi − µc
Hi,c,t
∆i
Hi,c,t
∆i
Hi,c,t
∆i

+

1 − µc
µi − µc

· Erri,c,tHi,c,t

2Hi,c,t

∆i

((1 − µk+1)Erri,c,t)

(1 + 2(1 − µk+1)Erri,c,t)

(1 + 2κ2)

where the last line follows from Lemma C.8 with j = k + 1.

Proof of Lemma C.8. S−i∨c has the same distribution S−i∧c ∪ y, where y ∼ Unif[U ′ − S−i∧c − {i, c}, 1].
If Y ∼ Bernoulli(µy) then

(92)

Since j ∈ [k + 1], µj ≥ µℓ for all ℓ /∈ [k], and thus (1 − µℓ) ≥ (1 − µj) for all ℓ /∈ [k]. It thus follows that

E·|t [L(S−i∨c)] = E(1 − Y )L(S−i∧c) = E·|t(cid:2)E·|t(cid:2)1 − Y(cid:12)(cid:12)S−i∧c(cid:3) · L(S−i∧c)(cid:3)
E·|t(cid:2)1 − Y(cid:12)(cid:12)S−i∧c(cid:3) =

(1 − µℓ)

1

1

|U ′ − {i, c} − S−i∧c| Xℓ∈U ′−{i,c}−S−i∧c
X
X

|U ′ − {i, c} − S−i∧c|

|U ′ − {i, c} − S−i∧c|

1

|U ′ − {i, c} − S−i∧c − [k]|

(1 − µj)

|U ′ − {i, c} − S−i∧c|

≥

≥

=

ℓ∈U ′−{i,c}−S−i∧c−[k]

ℓ∈U ′−{i,c}−S−i∧c−[k]

(1 − µℓ)

(1 − µj)

If r ∈ [k] ∩ U ′ = U ∪ B, then we must have r ∈ U, since B ∩ [k] = ∅ by assumption. This implies that
|U ′ − {i, c}− S−i∧c − [k]| ≥ |U ′ − {i, c}− S−i∧c|− min{k, |U |}. Using the fact that |U ′ − {i, c}− S−i∧c| =
|U ′| − k(1), and that k(1) = min{k, |U |}, we conclude that

E·|t(cid:2)1 − Y(cid:12)(cid:12)S−i∧c(cid:3) ≥ (1 − µj)

= (1 − µj)

|U ′| − k(1) − min{k, |U |}

|U ′| − k(1)

|U ′| − 2k(1)
|U ′| − k(1)

Thus, this entails that E[L(S−i∨c)] ≥ (1 − µj) |U ′|−2k(1)
|U ′|−k(1)

E[L(S−i∧c)], and hence

(1 − µj)Erri,c,t =

≤

=

k(1) − 1
|U ′| − k(1)
k(1) − 1
|U ′| − k(1)
k(1) − 1

·

·

|U ′| − 2k(1)

(1 − µj)EL(S−i∧c)

EL(S−i∨c)

|U ′| − k(1)
|U ′| − 2k(1)

:= κ2

as needed.

28

(93)

(94)

(95)

(96)

(97)

C.3.3 Controlling κ1 and κ2

Proof of Claim B.6. For ease of notation, drop the dependence on the round t and the deﬁnitions κ1 =
1 − k(1)−1
|U ′|−2k(1) . Noting that |U ′| = |B| + |U |, we see that if κ1 ≥ 1/2 is desired, we require
that

|U ′|−1 and κ2 = k(1)−1

κ1 ≥ 1/2 ⇐⇒ |U ′| − 1 ≥ 2(k(1) − 1) ⇐⇒ |B| ≥ 2k(1) − |U | − 1

Whereas

κ2 ≤ 2 ⇐⇒ 2(|U ′| − 2k(1)) ≥ k(1) − 1 ⇐⇒ |B| ≥

k(1) − |U | −

5
2

1
2

(98)

(99)

Hence κ ≤ 2 =⇒ κ1 ≤ 1/2, and the above display makes it clear that the choice of B in Algorithm 4
ensures that this holds. To verify the second condition, note that when |B| = 0, then |U ′| = |U |. When
|B| > 0, we have

|B| = ⌈

5k(1)

2

− |U | −

1
2

⌉ ≤

5k(1)

2

− |U |

(100)

so that |U ′| = |U | + |B| ≤ 5
2 min{|U |, k}. Finally, in order to always sample a balance set B ⊆ R, we need
to ensure that at each round, |R| ≥ |B|. Again, we may assume that |B| > 0, so that |U | + |B| ≤ 5k
2 . Using
the facts that |R| + |A| + |U | = n (every item is rejected, accepted, and undecided) and |A| ≤ k − 1 (k
accepts ends the algorithm), we have |R| ≥ n − |U | − (k − 1) ≥ n − |U | − (k − 1). But n − |U | − (k − 1) ≥
|B| ⇐⇒ n ≥ (k − 1) + |U ′| ≥ 7k

2 , as needed.

D Concentration Proofs for Section B.2

D.1 An Empirical Bernstein

The key technical ingredient is an empirical version of Bernstein’s inequality, which lets us build variance-
adaptive conﬁdence intervals:

Theorem D.1 (Modiﬁcation of Theorem 11 in [10] ). Let Z := (Z1, . . . , Zn) be a sequence of independent
random variables bounded by [0, 1]. Let ¯Zn = 1
variance of Z,

nPi Zi, ¯Z := E[ ¯Zn], let Varn[Z] denote the empirical

n), and set Var[Z] := E[Varn[Z]]. Then, with probability 1 − δ,

i − ¯Z 2

i=1(Z 2

1

n−1Pn

(cid:12)(cid:12) ¯Z − ¯Zn(cid:12)(cid:12) ≤ r 2Varn[Z] log(4/δ)
≤ r 2Var[Z] log(4/δ)

n

n

+

8 log(4/δ)
3(n − 1)

+

14 log(4/δ)

3(n − 1)

(101)

(102)

The result follows from Bernstein’s Inequality, and the following concentration result regarding the

square root of the empirical variance.

Lemma D.2 (Theorem 10 in [10]). In the set up of Theorem D.1,

(cid:12)(cid:12)(cid:12)pE[Varn[Z]] −pVarn[Z](cid:12)(cid:12)(cid:12) ≤r 2 log(2/δ)

n − 1

hold with probability 1 − δ.

29

(103)

Proof of Theorem D.1. The argument follows the proof of Theorem 11 in [10]. Let W := 1
i=1 Var[Zi].
It is straightforward to verify that W ≤ E[Varn[X]], and hence Bernstein’s inequality yields that, with
probability 1 − δ,

nPn

1
n

nXi=1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Zi − E[Zi](cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

2 log(4/δ)

n

n

+

+

3n

≤r 2W log(4/δ)
≤r 2E[Varn[Z]] log(4/δ)
≤r 2 log(4/δ)
·pVarn[Z] +
<r 2Varn[Z] log(4/δ)
<r 2E[Varn[Z]] log(4/δ)

+

+

n

n

n

2 log(4/δ)

3n

2 log(4/δ)

pn(n − 1)

8 log(4/δ)
3(n − 1)

14 log(4/δ)

3(n − 1)

+

2 log(4/δ)

3n

(104)

which completes the proof.

In our algorithm, the conﬁdence intervals ˆCi,t depend on sample variances, and are thus random. To in-
sure they are bounded above, we deﬁne a conﬁdence parameter Ci,t which depends on the true (but unkown)
stagewise variance parameter

Ci,t :=s 2Vi,t log(8nt2/δ)

T (t)

+

14 log(8nt2/δ)

3(T (t) − 1)

(105)

We extend our Empirical Bernstein bound to a union bound over all rounds t ∈ {1, 2, . . . }, showing that,
uniformly over all rounds, ˆCi,t is a reasonable conﬁdence interval and never exceeds Ci,t:

Lemma D.3 (Stagewise Iterated Logarithm Bound for Empirical Bernstein). Let

E := {∩∞

t=1 ∩n

i=1 {|ˆµi,t − ¯µi,t| ≤ ˆCi,t ≤ Ci,t}}

(106)

Then P(E) ≥ 1 − δ.

Proof. Let Ei,t denote the event that {|ˆµi,t − ¯µi,t| ≤ ˆCi,t ≤ Ci,t}. Conditioned on any realization of the
2nt2 . Integrating over all such

data Dt at stage t, an application of Theorem D.1 shows that P(Ei,t(cid:12)(cid:12)Dt) ≤ δ

2nt2 . Finally, taking a union bound over all stages t and arms i ∈ [n] shows that

realizations, P(Ei,t) ≤ δ

P(E) ≤

P(Ei,t) ≤

t−2 ≤ δ

(107)

∞Xt=1

nXi=1

∞Xt=1

nXi=1

δ
2nt

=

δ
2

∞Xt=1

We now invert the Iterated Logarithm via

Lemma D.4 (Inversion Lemma). For any ∆ > 0 and t ≥ 2, Ci,t ≤ ∆ as long as

T ≥(cid:18) 16Vi,t

∆2 +

14

∆(cid:19) log(cid:18) 24n

δ

log(cid:18) 12n

δ (cid:18) 16Vi,t

∆2 +

14

∆(cid:19)(cid:19)(cid:19)

(108)

30

Proof. It sufﬁces to show thatq 2Vi,t log(8nt2/δ)

(log2 e log(T ))2, it sufﬁces that

T (t)

≤ ∆/2 and 14 log(8nt2/δ)

3(T (t)−1) ≤ ∆/2. Since t2 = (log2(T ))2 ≤

8Vi,t log(8n log2

2 e log2(T (t))/δ))

∆2T (t)

≤ 1

and

28 log(8n log2 e log2(T (t))/δ)

3∆(T (t) − 1)

As long as t ≥ 2, so that T (t) ≥ e, it sufﬁces that

16Vi,t log(8n log2 e log(T (t))/δ))

∆2T (t)

≤ 1

and

14 log(8n log2 e log(T (t))/δ)

∆T (t)

≤ 1

≤ 1

Let α1 = 16Vi,t/∆2, α2 = 14/∆ and β = 8n log2 e/δ < 12n/δ. Then both inequalities take the form

where we simplify T (t) = T . Using the inversion

αp log(β log(T ))/T ≤ 1

T ≥ α log(2β log(αβ)) =⇒ α log(β log(T ))/T ≤ 1

(109)

(110)

we obtain that it is sufﬁcient for T ≥ (α1 + α2) log(2β log(α1 + α2)) ≥ maxp αp log(2β log(αpβ)), or
simply

T ≥(cid:18) 16Vi,t

∆2 +

14

∆(cid:19) log(cid:18) 24n

δ

log(cid:18) 12n

δ (cid:18) 16Vi,t

∆2 +

14

∆(cid:19)(cid:19)(cid:19)

(111)

D.2 Proof of Theorem B.3

We show that Theorem B.3 holds as long as the event E from Lemma D.3 holds. The deﬁnition of E and
Algorithm 3 immediately imply that no arms in [k] are rejected, and no arms in [n] − [k] are accepted. To
prove the more interesting part of the theorem, ﬁx an index i ∈ Ut, and deﬁne

C(i) :=({j ∈ Ut, j > k}

{j ∈ Ut, j ≤ k}

i ≤ k
i > k

(112)

Also, let ci = arg minj∈C(i) |µi − µj|. We can think of C(i) as the set of all arms competing with i for either
an accept or reject, and ci as the competitor closest i in mean. For i > k to be rejected, it is sufﬁcient that, for
all j ∈ C(i), minj∈C(i) ˆµj,t − ˆCj,t ≥ ˆµi,t + ˆCj,t. Under E, ˆµj,t − ˆCj,t ≥ ¯µj,t − 2Cj,t, and ¯µi,t ≤ ¯µi,t + 2Ci,t,
so that it is sufﬁcient for

∀j ∈ C(i) : ¯µj,t − ¯µi,t ≥ 2(Ci,t + Cj,t)

(113)

Analogously, for i ≤ k, i is accepted under E as long as ∀j ∈ C(i) : ¯µi,t − ¯µj,t ≥ 2(Ci,t + Cj,t). Deﬁning
∆i,j,t := |¯µi,t − ¯µj,t|, we subsume both cases under the condition

for which it is sufﬁcient to show that

∀j ∈ C(i) : ∆i,j,t ≥ 2(Ci,t + Cj,t)

∀j ∈ C(i) : Ci,t ≤ ∆i,j,t/4

and Cj,t ≤ ∆i,j,t/4

31

(114)

(115)

To this end deﬁne

τ (1)
i,j,t =

256Vi,t
∆2

i,j,t

+

56

∆i,j,t

and

τ (2)
i,j,t :=

256Vj,t
∆2

i,j,t

+

56

∆i,j,t

(116)

tion 115 will holds as long as

We now show that τi,t = maxj∈C(i) maxnτ (1)
T ≥ τi,t log(cid:18) 24n

i,j,to, which by Lemmas D.3 and D.4 implies that Equa-
log(cid:18) 12nτi,t
δ (cid:19)(cid:19)

i,j,t, τ (2)

(117)

δ

Now, we bound τi,t. Note that ∆i,j,t ≥ ∆i,ci,t := ∆i,t for all j ∈ C(i). This implies that maxj∈C(i) τ (1)
256Vi,t

i,j,t ≤

. On the other hand, it holds that

+ 56
∆i,t

∆2
i,t

τ (2)
i,j,t ≤ 256 max

j∈C(i)  Vj,t

i,j,t! +

∆2

max
j∈C(i)

56
∆i,t

≤

256Vci,t

∆2
i

+

56
∆i,t

(118)

where the second inequality invokes the following lemma.

Lemma D.5. For i ∈ {1, 2, 3}, Zi ∼ Bernoulli(pi), where either p1 < p2 < p3 or p3 > p2 > p1. Then,

Var[Z2]

(E[Z1 − Z2])2 ≥

Var[Z3]

(E[Z1 − Z3])2

(119)

Proof of Lemma D.5. The desired inequality and conditions are invariant under the tranformation pi
7→
1 − pi for i ∈ {1, 2, 3}, so we may assume without loss of generality that. p1 < p2 < p3 ∈ [0, 1]. Then
1 > p1/p2 > p1/p3, which implies that

1

1 − p1/p2

≥

1

1 − p1/p3

=⇒

=⇒

=⇒

which is precisely the desired inequality.

D.3 Proof of Lemma B.4

≥

p3

p3 − p1

p2

p2 − p1
(1 − p2)p2

≥

p2 − p1
(1 − p2)p2
(p2 − p1)2 ≥

(1 − p3)p3

p3 − p1

(1 − p3)p3
(p3 − p1)2

Let et be denote the the “efﬁciency”, so that, at round t, each call of uniform play for s = 1, . . . , T (t) makes
at most et|Ut| queries. Furthermore, let τ0 denote the ﬁrst time such that |Ut| < k. By assumption, we have
that et ≤ α
i = inf{t : i /∈ Ut}. Then, the total
number of samples we collect is

k for 0 ≤ t < τ0, and that et|Ut| ≤ α for t ≥ t0. Finally, let τ ∗

et|Ut|T (t) =

∞Xt=0

≤

et|Ut|T (t) +

et|Ut|T (t)

|Ut|T (t) + α

I(Ut 6= ∅)T (t)

τ0−1Xt=0
τ0−1Xt=0

α
k

32

∞Xt=τ0
∞Xt=τ0

(120)

(121)

The ﬁrst sum can be re-arranged via

τ0−1Xt=0

|Ut|T (t) =

≤

whereas the second sum is bounded above byP∞

t=τ0

τ0−1Xt=0   nXi=1
nXi=1
∞Xt=0

I(i ∈ ut)! T (t) =
nXi=1

I(i ∈ Ut)T (t) ≤

nXi=1

τ0+1Xt=0

I(i ∈ Ut)T (t)

2τ ∗

i +1

I(Ut 6= ∅)T (t) ≤ 2maxj τ ∗

j +1. Hence,

et|Ut|T (t) ≤ 2α(2maxj τ ∗

j +

∞Xt=0

2τ ∗
i )

1
k

nXi=1

(122)

(123)

(124)

Finally, let T ∗
i
a straight forward manipulation of the above display yields that

i , and let σ() : [n] → n denote a permutation such that T ∗

:= 2τ ∗

σ(1) ≥ T ∗

σ(2) . . . T ∗

σ(n). Then,

et|Ut|T (t) ≤ 2α(2T ∗

σ(1) +

∞Xt=0

1
k

nXi=k+1

T ∗
σ(i))

(125)

since 1

i=1 T ∗

σ(i) ≤ T ∗

σ(1).

kPk

E Dependent Lower Bound Proof

Recall that we query subsets of S ⊂ S := (cid:0)[n]

queried, and note that the expected sample complexity is simply:

k(cid:1). Let TS denote the number of times a given subset S is
XS∈S

E[TS]

Further, let d(x, y) denote the KL-divergence between two independent, Bernoulli random variables
with means x and y, respectively. We ﬁrst need a technical lemma, whose proof we defer the end of the
section:

Lemma E.1. Let d(x, y) = x log( x

y ) + (1 − x) log( 1−x

1−y ). Then

(y − x)2/2

supz∈[x,y] z(1 − z)

≤ d(x, y) ≤

(y − x)2/2

x(1 − x) − [(y − x)(2x − 1)]+

≤

(y − x)2/2

min{x(1 − x), y(1 − y)}

(126)

We break the proof up into steps. First we construct the dependent measure ν that is (k − 1)-wise

independent, meaning that for any subset S ∈(cid:0)[n]

k(cid:1), any subset of size (k − 1) of S behaves like independent

arms. The construction makes it necessary to consider each set of k individually. To obtain the lower
bounds we appeal to a change of measure argument (see [9] for details) that proposes an alterantive measure
ν′ in which a different subset is best than that subset that is best in ν, and then we calculate the number of
measurements necessary to rule out ν′. The majority of the effort goes into 1) computing the gap between
the best and all other subsets and 2) computing the KL divergences between ν and the alterantive measures
nu′ under the bandit and semi-bandit feedback mechanisms.
Step 1: Construct ν:

33

Fix p ∈ [0, 1] and µ ∈ [0, 1/2]. Let X = (X1, . . . , Xn) be distributed according to ν. Deﬁne the
independent random variables Y as Bernoulli(p), Zi as Bernoulli(1/2), and Ui as Bernoulli(2µ) for all
i ∈ [n]. For i > 1 let Xi = ZiUi and let

where ⊕ denotes modular-2 addition. Note that Eν[X] = µ1 since

where

X1 = U1eZ1
Eν1[X1] = 2µhp Pν(cid:16)1 + ⊕k

Z1

i=2Zi

eZ1 =(1 + ⊕k
i=2Zi = 1(cid:17) + (1 − p) 1

if Y = 1
if Y = 0

2i = µ

and the calculation for E[Xi] for i > 1 are immediate by independence. Henceforth, denote S∗ =
{1, . . . , k}.
Step 2: Relevant Properties of ν:

1. Any subset of arms S which doesn’t contain all of S∗ are independent.

If Y = 0 then the claim
is immediate so assume Y = 1. We may also assume that 1 ∈ S, since otherwise the arms are
independent by construction. Finally, we remark that even when 1 ∈ S and Y = 1, all arms in S
are conditionally independent given {Zi : i ∈ S ∩ S∗}. Thus, it sufﬁces to verify that {Zi : i ∈

is Bernoulli(1/2), and independent of all the Zi for which i ∈ S∗ ∩ S. Thus, conditioned on any

S ∩ S∗ − 1} ∪ {eZ1} have a product distribution. To see this, note that {Zi : i ∈ S ∩ S∗ − 1}
is a product distribution, so it sufﬁces to show that eZ1 is independent of {Zi : i ∈ S ∩ S∗ − 1}.
Write eZ1 = 1 + ⊕i∈S ∗\1Zi = 1 ⊕i∈S ∗∩S Zi ⊕i∈S ∗\S Zi. The sum over Zi not in S∗, ⊕i∈S ∗\SZi,
realization of {Zi : i ∈ S ∩ S∗}, eZ1 is still Bernoulli(1/2), as needed.

2. The distribution of ν is invariant under relabeling of arms in S∗, and under relabeling of arms [n]\S∗.
The second part of the statement is clear. Moreover, since the arms in [n]\S∗ are independent of those
S∗, it sufﬁces to show that the distribution of arms in S∗ are invariant under relabeling. Using the same
arguments as above, we may reduce to the case where Y = 1, and only verify that the distribution of

{eZ1} ∪ {Zi : i ∈ S∗ − 1} is invariant under relabeling.
To more easily facilliate relabeling, we adjust our notation and set eZi = Zi for i ∈ S∗ \ 1 (recall again

that Y = 1, so there should be no ambiguity). Identify S∗ ≡ [k], ﬁx t ∈ {0, 1}k, and consider any
permutation π : [k] → [k]. We have

P((eZπ(1), . . . , ˜Zπ(k)) = t)
= P((eZπ(1) = t1(cid:12)(cid:12)eZπ(2), . . . , ˜Zπ(k)) = t2, . . . , tk)) · P(eZπ(2), . . . , ˜Zπ(k)) = t2, . . . , tk)

Using our adjusted notation, the relation between between eZi’s becomes eZ1 = 1 ⊕i∈S ∗−1 eZi. This
constraint is deterministic (again, Y = 1) and can be rewritten as ⊕i∈S ∗eZ = 1, which is invariant
under-relabeling. Hence, P(eZπ(1) = t1(cid:12)(cid:12)(eZπ(2), . . . , ˜Zπ(k)) = (t2, . . . , tk)) = I(⊕k
over, we demonstrated above that, for any set S not containing S∗, {Zi : i ∈ S ∩ S∗ − 1} ∪ {eZ1} have
that P((eZπ(2), . . . , ˜Zπ(k)) = t2, . . . , tk) = 2−(k−1). Putting things together, we see that

a product distribution of k − 1 Bernoulli(1/2) random variables. In our adjusted notation, this entails

i=1ti = 1). More-

(127)

which does not dependent on the permutation π.

P((eZπ(1), . . . , ˜Zπ(k)) = t) = 2−(k−1)I(⊕iti = 1)

34

Step 3: Computation of the Gap under ν

Note that if S 6= S∗ then

Eν[max
i∈S

Xi] = Eν[max
i∈S

ZiUi] = P (∪i∈S{Zi = 1, Ui = 1}) = 1 − Pν(∩i∈S{Zi = 1, Ui = 1}c)

Pν({Zi = 1, Ui = 1}c) = 1 −Yi∈S

(1 − Pν(Zi = 1)P(Ui = 1)) = 1 − (1 − µ)k.

(1 − Pν(Zi = 1, Ui = 1))

= 1 −Yi∈S
= 1 −Yi∈S

Otherwise,

where

Eν[max
i∈S ∗

Eν[max
i∈S ∗

Xi] = Eν[max
i∈S ∗

= Eν[max
i∈S ∗

Xi|Y = 1] p + Eν[max
i∈S ∗

Xi|Y = 0] (1 − p)

Xi|Y = 1] p +h1 − (1 − µ)ki (1 − p)

Xi|Y = 1] = 1 − P(max
i≥1
= 1 − P(max
i≥1

UiZi = 0)

UiZi = 0, ⊕i>1Zi = 0) − P(max
i≥1

UiZi = 0, ⊕i>1Zi = 1)

= 1 − (1 − 2µ)P(max
i>1

UiZi = 0, ⊕i>1Zi = 0) − P(max
i>1

UiZi = 0, ⊕i>1Zi = 1)

= 1 − P(max
i>1

UiZi = 0) + 2µP(max
i>1

UiZi = 0, ⊕i>1Zi = 0)

= 1 − (1 − µ)k−1 + 2µP(max
i>1

UiZi = 0, ⊕i>1Zi = 0)

and

P(max
i>1

UiZi = 0, ⊕i>1Zi = 0) =

i>1

⌊

k−1

⌊

i>1

k−1

⌊

k−1

Zi = 2ℓ!
2ℓ (cid:19)2−k+1

UiZi = 0,Xi>1
Zi = 2ℓ!(cid:18)k − 1

P max
2 ⌋Xℓ=0
P max
UiZi = 0(cid:12)(cid:12)(cid:12)(cid:12)Xi>1
2 ⌋Xℓ=0
(1 − 2µ)2ℓ(cid:18)k − 1
2ℓ (cid:19)2−k+1
2 ⌋Xℓ=0
(cid:16)((1 − 2µ) + 1)k−1 + (−1)k−1((1 − 2µ) − 1)k−1(cid:17)
2(cid:16)(1 − µ)k−1 + µk−1(cid:17)

2−(k−1)

2

1

=

=

=

=

since

((1 − 2µ) + 1)k−1 =

=

(1 − 2µ)j(cid:18)k − 1
j (cid:19)
k−1Xj=0
(1 − 2µ)2ℓ(cid:18)k − 1
2ℓ (cid:19) +
2 ⌋Xℓ=0

k−1

⌊

35

⌊

k−1

2 ⌋Xℓ=0

(1 − 2µ)2ℓ+1(cid:18) k − 1
2ℓ + 1(cid:19)

and

((1 − 2µ) − 1)k−1 =

=

⌊

k−1

(−1)j (1 − 2µ)k−1−j(cid:18)k − 1
j (cid:19)
k−1Xj=0
(1 − 2µ)k−1−2ℓ(cid:18)k − 1
2ℓ (cid:19) −
2 ⌋Xℓ=0
(1 − 2µ)2ℓ(cid:18)k − 1
2ℓ (cid:19) − (−1)k−1
2 ⌋Xℓ=0

2 ⌋Xℓ=0

k−1

k−1

⌊

⌊

= (−1)k−1

(1 − 2µ)k−2−2ℓ(cid:18) k − 1
2ℓ + 1(cid:19)
(1 − 2µ)2ℓ+1(cid:18) k − 1
2ℓ + 1(cid:19).
2 ⌋Xℓ=0

k−1

⌊

Putting it all together we have

Eν[max
i∈S ∗

Xi] = [1 − (1 − µ)k−1 + µ(cid:16)(1 − µ)k−1 + µk−1(cid:17)] p +h1 − (1 − µ)ki (1 − p)
= [1 − (1 − µ)k + µk] p +h1 − (1 − µ)ki (1 − p)
=h1 − (1 − µ)ki + µkp

(128)

Thus, ∆ = pµk which is maximized at µ = 1

2 achieving ∆ = p2−k.

νS [maxi∈S Xi] > E

Step 4: Change of measure: Consider the distribution ν that is constructed in Step 1 that is deﬁned
with respect to S∗ = {1, . . . , k}. For all S ∈ S we will now construct a new distribution νS such that
νS [maxi∈S ∗ Xi] = Eν[maxi∈S ∗ Xi]. We begin constructing νS identically to how we
E
constructed ν but modify the distribution of XSℓ where Sℓ = arg min{i : Xi, i ∈ S}. In essence XSℓ with
respect to S ∈ S will be constructed identically to the construction of X1 with respect to S∗ = {1, . . . , k}
with the one exception that in place of Y we will use a new random variable Y S that is Bernoulli(p′) where
p′ > p (this is always possible as p < 1).

Let ν(S) describe the joint probability distribution of ν restricted to the set i ∈ S. And for any S ∈ S
let τ denote the projection of ν(S) down to some smaller event space. For example, τ ν(S) can represent the
Bernoulli probability distribution describing maxi∈S Xi under distribution ν. By (k −1)-wise independence
we have

KL(ν(S′)|νS(S′)) = 0 ∀S′ ∈ S \ S

since S and S′ differ by at least one element and ν(S∗) = νS(S∗). Clearly, KL(τ ν(S′)|τ νS(S′)) = 0 as
well for all S′ ∈ S \ S. By assumption, any valid algorithm correctly identiﬁes S∗ under ν, and S under νS,
with probability at least 1 − δ. Thus, by Lemma 1 of [9], for every S ∈ S \ S∗

Eν[TS ′]KL(τ ν(S′)|τ νS(S′)) = KL(τ ν(S)|τ νS(S))Eν [TS] ,

where we recall that TS is the number of times the set S is pulled. Hence,

log( 1

2δ ) ≤ XS ′∈S
Eν XS∈S\S ∗
TS ≥ XS∈S\S ∗

=

log( 1

KL(τ ν(S)|τ νS(S))(cid:20)(cid:18)n

k(cid:19) − 1(cid:21) ≥

2δ )

2

3 log( 1
2δ )

KL(τ ν(S)|τ νS(S))(cid:18)n
k(cid:19)

log( 1

2δ )

KL(τ ν(S)|τ νS(S))

36

where the equality holds for any ﬁxed S ∈ S by the symmetry of the construction and the last inequality

holds since 2 ≤ k < n,(cid:0)n

Bandit feedback: Let τ ν(S) represent the Bernoulli probability distribution describing maxi∈a Xi under
distribution ν. Then by the above calculations of the gap we have

3(cid:0)n
k(cid:1). It just remains to upper bound the KL divergence.
k(cid:1) − 1 ≥ 2

KL(τ ν(S)|τ νS(S)) = KL(1 − (1 − µ)k|1 − (1 − µ)k + p′µk)

≤

≤

p′2µ2k/2

(1 − (1 − µ)k)(1 − µ)k − 2p′µk[ 1

2 − (1 − µ)k]+

p′2µ2k/2

(1 − (1 − µ)k)((1 − µ)k − p′µk)

by applying Lemma E.1 and noting that

(1 − (1 − µ)k)(1 − µ)k − 2p′µk[ 1

2 − (1 − µ)k]+

≥ min{(1 − (1 − µ)k)(1 − µ)k, (1 − (1 − µ)k)(1 − µ)k − p′µk(1 − 2(1 − µ)k)}
≥ min{(1 − (1 − µ)k)(1 − µ)k, (1 − (1 − µ)k)[(1 − µ)k − p′µk]}
≥ (1 − (1 − µ)k)((1 − µ)k − p′µk)

Finally, let p′ → p. Setting µ = 1 − 2−1/k ≥ 1

2k we have (1 − µ)k = 1/2 and ∆ ≥ p(2k)−k so that

Marked-Bandit feedback: Let τ ν(S) represent the distribution over ⊥ ∪S under ν such that if W ∼ τ ν(S)
then W is drawn uniformly at random from arg maxi∈S Xi if maxi∈S Xi = 1, and W =⊥ otherwise. By

EνhPS∈S\S ∗ TSi ≥ 1
k(cid:1)∆−2 log( 1
3(cid:0)n
the permutation invariance property of ν described in Step 2, we have for any S ∈(cid:0)[n]

k(cid:1) − S∗ and i ∈ S

2δ ).

Pν(W = i|W 6=⊥) = P

νS (W = i|W 6=⊥) =

1
k

so that

Pν(W = w) log(

Pν(W = w)
νS (W = w)
P

)

Pν(W 6=⊥) log(

Pν(W 6=⊥)
νS (W 6=⊥)
P

)

KL(τ ν(S)|τ νS(S)) = Xw∈⊥∪S

= Pν(W =⊥) log(

Pν(W =⊥)
νS (W =⊥)
P

1
k

) +Xi∈S
Xi = 1)(cid:1).

νS (max
i∈S

= KL(cid:0)Pν(max

i∈S

Xi = 1)(cid:12)(cid:12)P

Thus, KL divergence for marked-bandit feedback is equal to that of simple bandit feedback.
Semi-Bandit feedback:

Let P denote the law of the entire construction for independent distribution, and Q the law of the
construction for the distribution. The strategy is to upper bound the KL of X, together with the additional
information from the hidden variables Z2, . . . , Zk. In this section, given v ∈ {0, 1}k, we use the compact
notation v(2;k) to denote the vector v2, . . . , vk. We can upper bound the KL by

KL(p(X), Q(X)) ≤ KL(P (X, Z (2;k)), Q(X, Z (2;k)))

=

X

x∈{0,1}k,z(2;k)∈{0,1}k−1

Q(X = x, Z (2;k) = z(2;k))!
P(cid:16)X = x, Z (2;k) = z(2;k)(cid:17) log  P (X = x, Z (2;k) = z(2;k))

37

By the law of total probability, the above is just

x(2;k)∈{0,1}2;k,z(2;k)∈{0,1}k−1

P(cid:16)X (2;k) = x(2;k), Z (2;k) = z(2;k)(cid:17)

X
Q(X = x, Z (2;k) = z(2;k))!
P(cid:16)X1 = x1(cid:12)(cid:12)X (2;k) = x(2;k), Z (2;k) = z(2;k)(cid:17) log  P (X = x, Z (2;k) = z(2;k))

×  Xx1∈{0,1}

Again, by the law of total probability, we have

P (X = x, Z (2;k) = z(2;k))
Q(X = x, Z (2;k) = z(2;k)

=

P (X1 = x1(cid:12)(cid:12)X (2;k) = x(2;k), Z (2;k) = z(2;k))
Q(X1 = x1(cid:12)(cid:12)X (2;k) = x(2;k), Z (2;k) = z(2;k)))

×

P (X (2;k) = x(2;k), Z (2;k) = z(2;k))
Q(X (2;k) = x(2;k), Z (2;k) = z(2;k)))

Under our construction, (X2, . . . , Xk, Z2, . . . , Zk) have the same joint distribution under either P or Q, so
the second multiplicand in the second line in the above display is just 1. Under the law P , X1 is independent

dependent law Q, X1 only depends on X2, . . . , Xk, Z2, . . . , Zk through W (Z (2;k)) := 1 ⊕k
Hence, if we deﬁne the conditional KL’s:

of X2, . . . , Xk, Z2, . . . , Zk, so P (X1 = x1(cid:12)(cid:12)X (2;k) = x(2;k), Z (2;k) = z(2;k)) = P (X1 = x1). Under the
Q(X1 = x1(cid:12)(cid:12)W (z(2;k)) = 1)!
p(X1 = x1) log 
KL1 := KL(cid:16)P (X1), Q(X1)(cid:12)(cid:12)W (z(2;k)) = 1(cid:17) = Xx1∈{0,1}
and deﬁne KL0 := KL(cid:0)P (X1), Q(X1)(cid:12)(cid:12)W (z(2;k)) = 0(cid:1) analogously, then
P (X1 = x1(cid:12)(cid:12)X (2;k) = x(2;k), Z (2;k) = z(2;k)) log(

Xx1∈{0,1}
= I(cid:16)W (z(2;k)) = 1(cid:17) KL1 + I(cid:16)W (z(2;k)) = 0(cid:17) KL0

P (X = x, Z (2;k) = z(2;k))
Q(X = x, Z (2;k) = z(2;k))

)

i=2 Zi ∈ {0, 1}.

P (X1 = x1)

Putting these pieces together,

KL(P (X, Z (2;k)), Q(X, Z (2lk))) =

I(W (Z (2;k)) = 1)KL1 + I(W (Z (2;k)) = 0)KL0

X

(x(2;k),z(2;k)∈{0,1}2(k−1)

= P(W (Z (2;k)) = 1)KL1 + P(W (Z (2;k)) = 0)KL0

=

1
2

(KL1 + KL0)

where the last line follows the parity W (Z (2;k)) is Bernoulli 1/2. A straightforward computation bounds
KL1 and KL0.

Claim E.2 (Bound on KL1, KL0 ). Let KL0 and KL1 be deﬁned as above. Then KL0 ≤
and KL1 ≤ p2µ/2

1−µ(1+p) .

p2µ/2

(1−p)(1−µ(1−p))

Proof. Note P (X1 = 1) = µ,

Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 0) = Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 1, Y = 1)p + Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 1, Y = 0)(1 − p)

= 0 · p + µ(1 − p) = µ(1 − p)

38

and

Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 1) = Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 1, Y = 1)p + Q(X1 = 1(cid:12)(cid:12)W (z(2;k)) = 1, Y = 0)(1 − p)

= 2µp + µ(1 − p) = µ(1 + p).

Thus, by Lemma E.1 we have

KL0 = Xx1∈{0,1}

P (X1 = x1) log 

P (X1 = x1)

Q(X1 = x1(cid:12)(cid:12)W (z(2;k)) = 0)!

(pµ)2/2

=

= d(µ, µ(1 − p)) ≤

µ(1 − p)(1 − µ(1 − p))

(1 − p)(1 − µ(1 − p))

p2µ/2

.

and

KL1 = Xx1∈{0,1}

P (X1 = x1) log 

P (X1 = x1)

Q(X1 = x1(cid:12)(cid:12)W (z(2;k)) = 1)!

(pµ)2/2

= d(µ, µ(1 + p)) ≤

min{µ(1 − µ), µ(1 + p)(1 − µ(1 + p))}

≤

p2µ/2

1 − µ(1 + p)

.

Remark E.1. Despite our seemingly arbitrary construction of random variables in Theorem 2.1 to produce
the resulting measure ν, Theorem 2.1 states that the joint distribution is unique and would be arrived at
using any other construction that satisﬁed the same properties.

Remark E.2 (An Upper Bound When µ = 1/2). Suppose that µ = 1/2. Then, our construction implies
Zi = Xi for i ≥ 2, and thus our bound on the KL is exact. In fact, we can use a simple parity estimator
W (S) = ⊕i∈SXi to distinguish between a subset S of correlated and uncorrelated arms. When S is
an independent set, W (S) ∼ Bernoulli(1/2). However, a simple computation reveals that W (S∗) ∼
Bernoulli(1/2 + p/2). Thus, using a parity estimator reduces our problem to ﬁnding one coin with bias p/2

k(cid:1) unbiased coins, whose difﬁculty exactly matches our problem

Surprisingly, Theorem 2.1 tells us that the construction outlined in this lower bound is the unique con-
struction which yields k − 1-wise independent marginals of mean µ = 1/2, with gap p2−k; in other words,
in any k − 1-wise independent construction with µ = 1/2, the parity estimator is optimal.

in a bag of(cid:0)n

E.1 Proof of Lemma E.1

Proof of Lemma E.1. If f (z) = d(z, y) then f ′(z) = log( z

1−z ) − log( y

1−y ), and f ′′(z) = 1

z(1−z) so

2(y − x)2 ≤

(y − x)2/2

supz∈[x,y] z(1 − z)

≤ d(x, y) ≤

(y − x)2/2

infz∈[x,y] z(1 − z)

.

If ǫ = y − x then

inf

z∈[x,y]

z(1 − z) = inf

ǫ∈[0,y−x]

x(1 − x) + ǫ(1 − 2x) = x(1 − x) − [(y − x)(2x − 1)]+

39

F Proof of Lower Bound Converse

To prove the above proposition, we need a convenient way of describing all feasible probability distributions
over {0, 1}k which are speciﬁed on their k − 1 marginals. To this end, we introduce the following notation:
We shall ﬁnd it convenient to index the entries of vectors w ∈ Rk−1 by binary strings t ∈ {0, 1}k−1. At
times, we shall need to “insert” indices into strings of length k − 2, as follows: For u ∈ {0, 1}k−2 and
j ∈ [k − 1], denote by u ⊕j 0 the string in {0, 1}k−1 obtained by inserting a 0 in the j-th position of u. We
deﬁne u ⊕j 1 similarly.

Lemma F.1. Let P0 be any distribution over {0, 1}k. Then, a probability distribution P agrees with P0 on
their k − 1 marginals if and only if, for all binary strings t ∈ {0, 1}k−1, P is given by

P(X−k = t, Xk = 0) = w(t)

(129)

where w ∈ R2k−1 satisﬁes the following linear constraints:

∀t ∈ {0, 1}k−1 :
∀j ∈ [k − 1], u ∈ {0, 1}k−2

0 ≤ w(t) ≤ P0(X−k = t)
w(u ⊕j 0) + w(u ⊕j 1) = P0(X−{j,k} = u−j, Xk = 0)

Remark F.1. Note that the above lemma makes no assumptions about k − 1 independence, only that the
k − 1 marginals are constrained

Proof of Theorem 2.1. Let P0 denote the product measure on X1, . . . , Xk, and P denote our coupled distri-
bution. Fix µ ∈ [0, 1]. For p ∈ {0, 1, . . . , k − 1}, deﬁne the probability mass function

ψ(p) := µp(1 − µ)k−1−p

(130)

Further, for u and t in {0, 1}k−2 and {0, 1}k−1, respectively, deﬁne the hamming weights H(t) =Pi ti and
H(u) =Pi ui.

Since our distribution is k − 1 wise independent, and each entry Xi has mean µ, we have P(X−k = t) =

P0(X−k = t) = ψ(H(t)). Moreover,

P0(X−{j,k} = u−j, Xk = 0) = (1 − µ)P0(X−{j,k} = u−j)

= (1 − µ)µH(u)(1 − µ)k−2−H(u)
= µH(u)(1 − µ)k−1−H(u) = ψ(H(u))

Thus, our feasibility set is precisely

∀t ∈ {0, 1}k−1 :

0 ≤ w(t) ≤ ψ(H(t))
∀j ∈ [k − 1], u ∈ {0, 1}k−2 w(u ⊕j 0) + w(u ⊕j 1) = ψ(H(u))

(131)

The equality constraints show there is only one degree of freedom, which we encode into w(0):

Claim F.2. w satisﬁes the equality constraints of the LP if and only if, for all t ∈ {0, 1}k−1 of weight
H(t) = p,

w(t) = (−1)p w (0) + (−1)p−1 Φ (p)

i=0 (−1)iψ(i), so that Φ(0) = 0. Note that Φ satisﬁes the identity

where Φ(p) =Pp−1

Φ(p) = (−1)p−1 ψ (p − 1) + Φ (p − 1)

40

(132)

(133)

Hence, we can replace the equality constraints by the explicit deﬁnitions of w(t) in terms of w(0) and Φ(p).
This leads to the next claim:

Claim F.3. w is feasible precisely when

max

0≤p≤k even

Φ(p) ≤ w(0) ≤ min

1≤p≤k odd

Φ(p)

(134)

We now establish a closed form solution for Φ(p) when µ < 1/2, and parity-wise monotonicity when
µ ≥ 1/2:

Claim F.4. If µ < 1/2, we have Φ(p) = (1 − µ)k(cid:16)1 − ( −µ

1−µ )p(cid:17), so Φ(p) is decreasing for odd p and

increasing for even p. If µ ≥ 1/2, Φ(p) is nondecreasing for odd p and nonincreasing for even p

To conclude, we note that when µ ≥ 1/2, the fact that Φ(p) is nondecreasing for odd p and nonincreasing

for even p implies that

max

0≤p≤k even

Φ(p) ≤ w(0) ≤ min

1≤p≤k odd

Φ(p) ⇐⇒ Φ(0) ≤ w(0) ≤ Φ(1)

⇐⇒ 0 ≤ w(0) ≤ ψ(0)
⇐⇒ 0 ≤ w(0) ≤ (1 − µ)k−1

When µ < 1/2, the fact that Φ(p) is decreasing for odd p and increasing for even p implies that

max

0≤p≤k even

1≤p≤k odd

Φ(p) ≤ w(0) ≤ min

Φ(p) ⇐⇒ Φ(kodd) ≤ w(0) ≤ Φ(keven)

⇐⇒ (1 − µ)k 1 −(cid:18) µ

1 − µ(cid:19)keven! ≤ w(0) ≤ (1 − µ)k 1 +(cid:18) µ

1 − µ(cid:19)kodd!

Since w(0) = P(X1, . . . , Xk = 0), we are done.

F.1 Proofs

Proof Of Lemma F.1. We can consider the joint distribution of (X1, . . . , Xk) as a vector in the 2k simplex.
However, there are many constraints: in particular, the joint distribution of X1, . . . , Xk−1 is entirely deter-
mined by the k − 1-marginals of the distribution. In fact, if P is a distribution over {0, 1}k, then it must
satisfy

P(X−k = t−k, Xk = 1) + P(X−k = t−k, Xk = 0) = P(X−k = t−k).

Hence, without any loss of generality, we may encode any arbitrary probability distribution on {0, 1}k by

P(X = t) :=(w(t−k)

P0(X−k = t−k) − w(t−k)

tk = 0
tk = 1

(135)

for a suitable w ∈ R2k−1. This deﬁnes P on the atomic events {X = t}, and we extend P to all further
events by additivity. We now show that the constraints on the Lemma hold if and only if w induces a proper
probability distribution P whose k − 1 marginals coincide with P.

Recall that P is a proper distribution if and only if it is nonnegative, normalized to one, monotonic,

and additive3. P satisﬁes additivity by construction. Moreover, by deﬁnition Pt∈{0,1}k P(X = t) =

3 As X has ﬁnite support, we don’t need to worry about such technical conditions as σ-additivity

41

Pt−k∈{0,1}k−1 P0(X−k = t−k) = 1, so P is normalized. Finally, monotonicity will follow as long as we

establish non-negativity of P on the atomic events {X = t}. But the constraint that P(X = t) is nonnegative
holds if and only if

0 ≤ w(t1, . . . , tk−1) ≤ P0(X−k = t−k).

(136)

On the other hand, the constraint that P’s k − 1 marginals coincide with P0 is simply that

w(t1, . . . , tj−1, 0, tj+1, . . . , tk−1) + w(t1, . . . , tj−1, 1, tj+1, . . . , tk−1)

= P0(X1 = t1, . . . , Xj−1 = tj−1, Xj+1 = tj+1, . . . , Xk−1 = tk−1, Xk = 0)

which can be expressed more succinctly using the concatenation notation w(u ⊕j 0) + w(u ⊕j 1) =
P0(X−{j,k} = u−j, Xk = 0).

Proof of Claim F.2. First, we prove “only if” by induction on H(t). For H(t) = 0, the claim holds since
Φ(0) = 0. For a general t ∈ {0, 1}k−1 such that H(t) = p ≥ 1, we can construct a sequence t0, . . . , tp ∈
{0, 1}k−1 such that t0 = 0, tp = t, and each string ts is obtained by “ﬂipping on” a zero in the string ts−1
to 1, that is, there is a string us ∈ {0, 1}k−2 such that ts = us ⊕js 1 and ts−1 = us ⊕js 0. Thus, our equality
constraints imply that

w(tp−1) + w(t) = w(tp−1) + w(tp)

= w(us ⊕js 1) + w(us ⊕js 0)
= ψ(H(u)) = ψ(p − 1).

Hence, we get the recursion w(tp) = ψ(p − 1) − w(tp−1), which by the inductive hypothesis on tp−1 and
Equation 133 imply that

w(t) = ψ(p − 1) −(cid:0)(−1)p−1w(0) + (−1)p−2Φ(p − 1)(cid:1)

= (−1)pw(0) + (−1)p−1Φ(p − 1) + ψ(p − 1)
= (−1)pw(0) + (−1)p−1(Φ(p − 1) + (−1)p−1ψ(p − 1))
= (−1)pw(0) + (−1)p−1Φ(p)

as needed. Next, we prove the “if” direction. Let u ∈ {0, 1}k−2 have weight p. Then

w(u ⊕ 0) + w(u ⊕ 1) = (−1)pw(0) + (−1)p−1Φ(p) + (−1)p+1w(0) + (−1)pΦ(p + 1)

= (−1)p−1Φ(p) + (−1)pΦ(p + 1)
= (−1)p−1Φ(p) + (−1)p (Φ(p + 1 − 1) + (−1)pψ(p + 1 − 1))

= (cid:0)(−1)p−1 + (−1)p(cid:1) Φ(p) + (−1)2pψ(p) = ψ(p)

as needed.

Proof of Claim F.3. Our feasibility set is precisely is the set of w(0) such that 0 ≤ w(0) ≤ ψ(0), and for
all p ∈ {1, 2, . . . , k − 1}

0 ≤ (−1)pw(0) + (−1)p−1Φ(p) ≤ ψ(p).

(137)

Suppose ﬁrst that p is even. If p is greater than 1, then the above constraint together with Claim F.2 imply

Φ(p) ≤ w(0) ≤ ψ(p) + Φ(p) = (−1)(p+1)−1ψ(p) + Φ(p) = Φ(p + 1).

42

If p is 0, then Φ(0) = 0 and Φ(1) = ψ(0), so the constraint 0 ≤ w(0) ≤ ψ(0) is equivalent to Φ(p) ≤
w(0) ≤ Φ(p + 1) for p = 0.

On the other hand, when p is odd, we have w(0) ≤ Φ(p), whilst

w(0) ≥ Φ(p) − ψ(p) = Φ(p) + (−1)(p+1)−1ψ(p) = Φ(p + 1).

(138)

In other words, w(0) ≤ Φ(p) for all p which are either odd and between 1 and k − 1, or p of the form
p = q + 1 where q is even and between 1 and k − 1. This is precisely the set of all odd p in 1, . . . , k. By
the same token, w(0) ≥ Φ(p) for all even p in {1, . . . , k}. Taking the intersection of these lower and upper
bounds on w(0) yields

max

0≤p≤k even

Φ(p) ≤ w(0) ≤ min

1≤p≤k odd

Φ(p).

(139)

Proof of Claim F.4. Let ρ = µ

1−µ. We can write Φ yields as geometric series

(−1)iψ(i)

Φ(p) =

=

p−1Xi=0
p−1Xi=0

(−1)i · µi(1 − µ)k−1−i

= (1 − µ)k−1

= (1 − µ)k−1

(−1)i(

µ

1 − µ

)i

(−ρ)i

p−1Xi=0
p−1Xi=0

When µ ≥ 1/2, ρ ≥ 1, and thus this series is nondecreasing for odd p and nonincreasing for even p. When
ρ < 1/2, the series is decreasing for odd p and increasing for even p and in fact we have

1 + ρ

Φ(p) = (1 − µ)k−1

Φ(p) = (1 − µ)k−1 1 − (−ρ)p
1 − (− µ
1 + µ
1−µ
−µ
1 − µ

= (1 − µ)k(cid:18)1 − (

1−µ )p

)p(cid:19)

G Proof of Theorem 4.1: Lower Bound for Independent Arms

As in the proof of Theorem 2.1, let ν(a) describe the joint probability distribution of ν restricted to the

set i ∈ a. Note that ν(a) = Qi∈a νi. And for any a ∈ A let τ ν(a) represent the Bernoulli probability

distribution describing maxi∈a Xi under distribution ν. Let ǫ > 0. For each j ∈ [n] let νj be a product
distirbution of Bernoullis fully deﬁned by its marginals µj

[Xi] and

i := E

νj
i

µj

i =

µk + ǫ
µk+1 − ǫ
µi

if i = j and i > k
if i = j and i ≤ k
if i 6= j.

43

By Lemma 1 of [9], for every j ∈ [n]

Xa∈([n]

p )

Eν[Ta]KL(τ ν(a)|τ νj(a)) ≥ log( 1

2δ ),

for arbitrarily small ǫ, so in what follows let ǫ = 0. Then

0

KL(τ ν(a)|τ νj(a)) =

where for j > k, by invoking Lemma E.1,

≤

if j /∈ a

d(cid:16)(1 − µj)Qi∈a\j (1 − µi)|(1 − µj − ∆j)Qi∈a\j (1 − µi)(cid:17) if j ∈ a and j > k
d(cid:16)(1 − µj)Qi∈a\j (1 − µi)|(1 − µj + ∆j)Qi∈a\j (1 − µi)(cid:17) if j ∈ a and j ≤ k
d(1 − µj) Yi∈a\j

≤

∆2

∆2

(1 − µi)|(1 − µj − ∆j) Yi∈a\j
j(cid:16)Qi∈a\j(1 − µi)(cid:17)2

(1 − µi)
2(cid:16)1 − (1 − µj)Qi∈a\j (1 − µi)(cid:17)(cid:16)(1 − µj − ∆j)Qi∈a\j(1 − µi)(cid:17)
2(cid:16)1 − (1 − µj)Qi∈a\j(1 − µi)(cid:17) (1 − µj − ∆j)
τj =
Xa∈([n]

j(cid:16)Qi∈a\j(1 − µi)(cid:17)
p−1 )Qi∈a\j(1 − µi) and

Eν[Ta] ≥ 2τj log( 1

(1−µj −∆j )

1−(1−µj )hj

1−(1−µj +∆j )hj

∆2
j
(1−µj )

∆2
j

if j > k

if j ≤ k

hj

hj

p ):j∈a

2δ )

and a similar bounds holds for j ≤ k. If hj = maxa∈([n]−j

∀j ∈ [n] then

or, in words, arm j must be included in a number of bandit observations that is at least the right-hand-side
of (140). Because p arms can be selected per evaluation, if we assume perfect divisibility to minimize the
number of evaluations, then we conclude that

Eν[Ta] ≥ 2 log( 1

Xa∈([n]

p )

max

j=1,...,n

τj,

1
p

nXj=1

≥ log( 1

2δ ) max

j=1,...,n

τj +

1
p

nXj=1

τj

τj

where the ﬁrst argument of the max follows from the fact that the number of rounds must exceed the number
of bandit evaluations each arm must be included in.

For semi-bandit feedback, we use the same νj construction but now realize that

(140)

(141)

2δ ) max
KL(ν(a)|νj(a)) =

0
d (1 − µj|1 − µj − ∆j)
d (1 − µj|1 − µj + ∆j)

if j /∈ a
if j ∈ a and j > k
if j ∈ a and j ≤ k.

44

Using the same series of steps as above, we ﬁnd that if

µj (1−µj −∆j)

∆2
j

(µj −∆j)(1−µj )

∆2
j

if j > k

if j ≤ k

τj =

then (141) holds with these deﬁned values of τj for the semi-bandit case.

45

