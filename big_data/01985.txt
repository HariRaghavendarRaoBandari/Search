6
1
0
2

 
r
a

M
7

 

 
 
]
P
A

.
t
a
t
s
[
 
 

1
v
5
8
9
1
0

.

3
0
6
1
:
v
i
X
r
a

Multilevel Models with Stochastic Volatility for
Repeated Cross-Sections: an Application to tribal

Art Prices

Silvia Cagnone ∗, Simone Giannerini †, and Lucia Modugno ‡

Dipartimento di Scienze Statistiche, University of Bologna, Italy

Abstract

In this paper we introduce a multilevel speciﬁcation with stochastic
volatility for repeated cross-sectional data. Modelling the time dynam-
ics in repeated cross sections requires a suitable adaptation of the mul-
tilevel framework where the individuals/items are modelled at the ﬁrst
level whereas the time component appears at the second level. We per-
form maximum likelihood estimation by means of a nonlinear state space
approach combined with Gauss-Legendre quadrature methods to approx-
imate the likelihood function. We apply the model to the ﬁrst database of
tribal art items sold in the most important auction houses worldwide. The
model allows to account properly for the heteroscedastic and autocorre-
lated volatility observed and has superior forecasting performance. Also,
it provides valuable information on market trends and on predictability
of prices that can be used by art markets stakeholders.

Keywords: multilevel model, hedonic regression model, dependent ran-

dom eﬀects, stochastic volatility, autoregression.

1

Introduction

The investigation of the relationship between the art market and ﬁnancial mar-
kets has important implications for institutions as well as for auction houses, art
merchants and individuals. In fact, also due to the recent ﬁnancial crisis, there
has been a sharp increase in the so called alternative investments that comprise
funds specialising in art. These appear to oﬀer a highly beneﬁcial diversiﬁcation
strategy with a complex correlation with traditional assets. Hence, the study of
the features of this new asset class is important and cannot disregard the diﬀer-
ences with respect to traditional stocks. For instance, art items are exchanged a

∗silvia.cagnone@unibo.it
†simone.giannerini@unibo.it
‡lucia.modugno@unibo.it

1

few times and the transaction costs are considerable. Moreover, there is the so
called aesthetic dividend which plays a crucial role (see e.g. Goetzmann, 1993;
Candela et al., 2013, and references therein).

The study of price determination and price indexes for art items is funda-
mental to auction houses and art merchants. Besides estimating the price of
individual items, price indexes can be used to understand market trends, to
assess the main social and economic factors that inﬂuence the art market, to
understand whether investing in art would diversify risk in a long-term invest-
ment portfolio. For art objects, the traditional view of a long run price related
to the cost of production does not hold anymore. Some authors argue that the
art market is inherently unpredictable since it is dictated by collectors’ manias
Baumol (1986). However, there is an ever growing consensus, backed by empiri-
cal evidence, on the idea that “price fundamentals” can be objectively identiﬁed.
The hedonic regression, also known as the grey painting method, is one of the
most used approaches for modelling art prices. It was ﬁrst proposed in Rosen
(1974) and further investigated and applied in Chanel (1995); Ginsburgh and
Jeanﬁls (1995); Agnello and Pierce (1996); Chanel et al. (1996); Locatelli Biey
and Zanola (2005); Collins et al. (2009). According to this method, the price of
an artwork item depends both on market trends and on a set of characteristics
of the item itself. Such dependence is modelled through a ﬁxed eﬀect regression
and the estimated regression coeﬃcients can be interpreted as the price of each
feature, the so-called shadow price. Hence, it is possible to predict the price of
a given object by summing the prices of its features. Also, a time-dependent
intercept can represent the value of the grey painting in that period, that is, the
value of an artwork created by a standard artist, through standard techniques,
with standard dimensions, etc. (Locatelli Biey and Zanola, 2005). Eventually,
the price index is built from the prices of the grey painting in diﬀerent periods.
Despite its potential, the hedonic regression model has several shortcomings.
First, as also remarked in Goetzmann et al. (2014) only a small fraction of
the great variability of the price dynamics is explained. Second, most of the
features are categorical so that the regression equation contains many dummy
variables and the resulting models are not parsimonious. Most importantly, the
time dynamics is not modelled directly but through dummy variables so that
it is not possible to use the model to forecast the prices. Moreover, since it is
practically impossible to follow the selling price of each artwork item over time,
the available datasets have a structure of a repeated cross-section where at each
time point a new sample is observed.

In order to overcome the above-mentioned issues, a multilevel approach can
be used (Goldstein, 2010; Skrondal and Rabe-Hesketh, 2004). The treatment
of repeated cross-sectional data requires the extension of the classical multilevel
model by considering individual heterogeneity within time at the ﬁrst level, and
the variability over time at the second level. This speciﬁcation has been adopted
for the ﬁrst time by DiPrete and Grusky (1990) and Browne and Goldstein
(2010) in the frequentist and Bayesian frameworks, respectively. Motivated by
the construction of a price index for auctioned items of tribal artworks, Modugno
et al. (2015) extended such multilevel speciﬁcation as to add an autoregressive

2

components at the second level. They found a considerable improvement over
classical models in terms of prediction and forecasting but the assumption of
normality of level-1 residuals was violated, probably due to the presence of
heteroscedasticity and kurtosis. They devised an ad hoc solution for deriving
robust standard errors through the wild bootstrap scheme for multilevel models
introduced in Modugno and Giannerini (2015). Similar ﬁndings concerning the
non normality and the heteroscedasticity were reported for other speciﬁcations
for the art market in Bocart and Hafner (2012) and Hodgson and Vorkink
(2004). In Bocart and Hafner (2012) the problem was addressed by estimating
a semiparametric time-varying volatility and Student’s t error with skewness,
whereas Hodgson and Vorkink (2004) did not assume any parametric form for
the disturbances but retained the assumption of serial independence of random
eﬀects. Also, Bocart and Hafner (2013) modeled the volatility of price indexes
by means of a smooth function of time as a component of an unbalanced panel
model with AR(1) time eﬀects. They implemented a linear Gaussian state-
space representation and estimated it through maximum likelihood combined
with a Kalman ﬁlter, and, as above, they found a violation of the normality
assumption. The evidence reported in literature indicates that the volatility of
prices plays a pre-eminent role; assuming it constant is not realistic and might
cause estimation problems.

In this paper we extend the model proposed in Modugno et al. (2015) by
including a stochastic volatility component at the second level by means of a
nonlinear state space approach. The speciﬁcation is motivated by the analysis
of the ﬁrst world database of tribal art prices. This allows to account properly
for the heteroscedastic and autocorrelated volatility of level-1 error terms and
brings in several advantages. Stochastic volatility models (SV) are based on
the assumption that the conditional variance of the observed variable depends
on a latent variable that captures the ﬂow of information arriving from the
market. Similar to ARCH-type models for ﬁnancial time series, SV models allow
to account properly for fat tailed distributions, white-noise-type dependence,
high and lag-decreasing autocorrelations of squared observations. We opt for
a stochastic volatility component since ARCH-type models assume that the
volatility is aﬀected by past information through a deterministic function. Such
a speciﬁcation is not viable for repeated cross-sections.

Model estimation is performed through maximum likelihood via a non-linear
Gaussian ﬁltering process in the spirit of Kitagawa (1987) and Tanizaki and
Mariano (1998). The task poses several computational challenges related to the
presence of time-varying latent variables that must be integrated out from the
likelihood function so that there is no analytical solution. To this aim, Fridman
and Harris (1998) proposed a non-linear Kalman ﬁlter algorithm by expressing
the likelihood function as a nested sequence of one-dimensional integrals approx-
imated by the Gauss Legendre numerical quadrature. Bartolucci and De Luca
(2001) extended this approach by computing analytical ﬁrst and second deriva-
tives of the approximated likelihood. They applied a rectangular quadrature
to approximate the integrals. More recently, Cagnone and Bartolucci (2016)
approximated such integrals by using an Adaptive Gauss Hermite quadrature

3

Table 1: Subset of variables classiﬁed by type: Physical, Historical and Market.

Variable
Type of object

Physical

Material

Patina

Continent

Categories
Furniture, Sticks, Masks,
Religious objects, Ornaments,
Sculptures, Musical instruments,
Tools, Clothing, Textiles,
Weapons, Jewels
Ivory, Vegetable ﬁbre, Wood,
Metal, Gold, Stone,
Precious stone, Terracotta, ceramic,
Silver, Textile and hides
Seashell, Bone, horn, Not indicated
Not indicated, Pejorative,
Present, Appreciative
Africa, America
Eurasia, Oceania

Illustration on the catalogue Absent, Black/white, Coloured,
Illustration width

Hystorical

Description

Specialized bibliography
Comparative bibliography
Exhibition
Historicization

Market

Venue
Auction house

Absent, Miscellaneous,
Quarter page, Half page,
Full page, More than one,
Cover
Absent, Short visual, Visual,
Broad visual, Critical, Broad critical.
Yes, No
Yes, No
Yes, No
Absent, Museum certiﬁcation,
Relevant museum certiﬁcation,
Simple certiﬁcation
New York, Paris,
Sotheby’s, Christie’s

method. Here, we extend the procedure discussed in Fridman and Harris (1998)
by using Gauss-Legendre quadrature methods to approximate the integrals in-
volved in the likelihood.

2 The ﬁrst database of tribal art prices

The ﬁrst database of tribal art prices was created in 2006 from the joint agree-
ment of the department of Economics of the University of the Italian Switzer-
land, the Museum of the Extra-European cultures in Lugano, the Museo degli
Sguardi in Rimini, and the Faculty of Economics of the University of Bologna,
campus of Rimini. For each artwork item, there are 37 variables recorded from
the catalogues released before the auctions. The variables include physical, his-
torical and market characteristics. Some of these are shown in Table 1 and most
of them are categorical. After the auction, the information on the selling price
is added to the record.

Figure 1 shows the boxplots of logged prices aggregated by semester; the
number of items sold in each semester is reported inside the boxes. The structure

4

Figure 1: Boxplots of prices in logarithmic scale (base 10) of the tribal art
market by semester. The amount of items sold in a given semester is reported
inside the boxes.

of the dataset emerges clearly from the graph:
in every semester a diﬀerent
group of artworks is sold; e.g. 407 items were auctioned in 1998-1, 915 objects
diﬀerent from the ﬁrst set were sold in 1998-2, and so on. Hence, tribal art data
has a structure like that of repeated cross-sectional surveys and the medians
(black lines) give an idea of the trend of prices over time. In particular, note
the consistent reduction in the number of auctioned items starting from 2009.
Despite this, the overall turnover did not drop since the average price rose. This
might indicate the adoption by market agents of hedging strategies against the
economic crisis. Overall, we have T = 28 semesters, and nt, the number of
items sold in the semester t, varies between 73 (2011-2) and 915 (1998-2); the
It is convenient to
aggregate the data in semesters rather than auction dates since auction dates
are not equally spaced in time and this feature is important for modelling time
dependence. Also, auctions are organized in two sessions, one in the winter and
one in the summer, and each session contains two to four auctions quite close in
time. The aggregation in semesters respects naturally this organization so that
the results are meaningful from the Economics point of view and this source of
heterogeneity can be explained.

total sample size of sold items (n =(cid:80)T

t=1 nt) is 13955.

5

YearPrice(log10)1998-12000-12002-12004-12006-12008-12010-112345640791558676171059029518145921471085772272153343445067458857054562637614031578425733 The model

In Section 3.1 we brieﬂy review the model proposed in Modugno et al. (2015)
while in Section 3.2 we extend it by introducing the mixed eﬀects model with
stochastic volatility.

3.1 A Multilevel model with autoregressive random ef-

fects

Let yit be the observed price for item i = 1, . . . , nt at time-point t = 1, . . . , T
and let xit be a corresponding column vector of k covariates. Since tribal art
data can be thought to have a two-level structure where items represent level-1
units, and time points represent level-2 units, we consider the following random
intercept model:

log10(yit) = β0 + ut + x(cid:48)

itβ + it,

it|xt ∼ NID(0, σ2)

where ut are time-speciﬁc random intercepts that account for the unobserved
heterogeneity between items within each time point, β is a vector of ﬁxed slopes
and β0 is the overall mean. In repeated cross-sectional data, yit and yi(t+1) are
not the price of the same item i observed at successive time points since the
two objects are physically diﬀerent. Conditionally on the vector of covariates
xt, level-1 errors it (the error term for a given individual at a given time point)
follows a normal distribution with constant variance. In other words, the art
market is assumed to have a constant volatility over time. Note that it is
conditioned on the vector of the covariates xt for all the individuals, that is,
we assume strict exogeneity on the explanatory variables (Wooldridge, 2002).
Diﬀerently from panel data, in repeated cross-sectional data the strict exogeneity
assumption implies that, for each item, the covariates are uncorrelated with the
error terms.

The dynamics of ut can be modelled at the second level by extending the

above multilevel models as follows

ut = ρut−1 + ηt,

ηt|xt ∼ NID(0, σ2
η),

where ηt⊥us and ηt⊥it for all s < t and for all i. In this speciﬁcation, the
random eﬀects follow an autoregressive process of order 1 with |ρ| < 1, that
guarantees stationarity. We denote this model as ARE (Autoregressive Ran-
dom Eﬀects). Modugno et al. (2015) introduced a full maximum likelihood
estimation method via the EM algorithm to ﬁt the ARE model to the tribal
art data. The ARE model improves considerably over classical models in terms
of prediction and forecasting. However, as it will be shown in the application
Section, the assumption of normality of level-1 residuals is violated, probably
due to the presence of heteroscedasticity and kurtosis. As mentioned above, the
assumption of a constant volatility of prices of art assets is not realistic and
might cause severe inference problems.
In the following we extend the ARE
model by including a stochastic volatility component that accounts properly for
the heteroscedastic and autocorrelated volatility of the level-1 error process.

6

3.2 A Multilevel model with autoregressive random ef-

fects and stochastic volatility

We include a stochastic volatility component at level-1 of the ARE model as
follows:

log10(yit) = β0 + ut + x(cid:48)
ut = ρut−1 + ηt
ht = α + δht−1 + σννt,

itβ + exp (ht/2)it

(1)

(2)

(3)

for i = 1, . . . , nt and t = 1, . . . , T . As before, ut is the time dependent random
eﬀect whereas ht is the latent variable that represents the volatility component
at time t. Both ut and ht follow a stationary autoregressive process, so that
|ρ| < 1 and |δ| < 1. We take the corresponding unconditional distributions as

initial conditions for the two processes, namely h1 ∼ N(cid:0)α/(1 − δ), σ2
and u1 ∼ N(cid:0)0, σ2

ν/(1 − δ2)(cid:1)
η/(1 − ρ2)(cid:1). Moreover, we assume that it, ηt and νt are mu-

η) , and νt ∼ NID(0, 1)
tually independent, with it ∼ NID(0, 1), ηt ∼ NID(0, σ2
respectively, where, for simplicity of notation, we omit the conditioning upon
the covariates xt. Under these assumptions, the conditional densities result

yit|ut, ht ∼ NID(β0 + ut + x(cid:48)
ut|ut−1 ∼ NID(ρut−1, σ2
η)
ht|ht−1 ∼ NID(α + δht−1, σ2
ν).

itβ, exp (ht))

We call the new speciﬁcation SVARE (Stochastic Volatility and Autoregressive
Random Eﬀects) model. The system (1)-(3) is a nonlinear state space represen-
tation. Hence, model estimation can be performed by using maximum likelihood
via a non-Gaussian ﬁltering process and poses several non-trivial challenges that
we describe and address in the following section.

4 Model estimation

4.1 The likelihood function

The maximum likelihood estimation is based on the maximization of the follow-
ing likelihood function

(cid:90)
(cid:90)
(cid:90) +∞

h

u

−∞

L(θ|y) =

=

f (y|u, h)f (u, h)dudh =

(cid:90) +∞

(cid:34) T(cid:89)

−∞

t=1

. . .

(cid:35)

f (yt|ut, ht)f (ut|ut−1)f (ht|ht−1)

duT . . . du1dhT . . . dh1

(4)
(cid:81)nt
where θ = {β0, β(cid:48), ρ, ση, α, δ, σν} is the vector of parameters, f (yt|ut, ht) =
i=1 f (yit|ut, ht) for t = 1, . . . , T , f (u1|u0) = f (u1) and f (h1|h0) = f (h1).

7

The computation of L(θ|y) requires solving a 2T -dimensional integral which
is computationally unfeasible. We address the issue by applying an iterated nu-
merical integration procedure introduced by Kitagawa (1987) for non-Gaussian
ﬁltering problems. The procedure is based upon rephrasing the likelihood (4)
as
L(θ|y) =

f (y1|u1, h1)f (u1)f (h1)

(cid:90) +∞

(cid:90) +∞

f (y2|u2, h2)f (u2)f (h2) . . .

−∞

−∞

(cid:90) +∞
(cid:90) +∞

−∞

(cid:90) +∞
(cid:90) +∞

−∞

−∞

−∞

. . .

f (yT|uT , hT )f (uT )f (hT )duT dhT . . . du2dh2du1dh1.

(5)

The resulting bivariate integrals can be approximated by using numerical quadra-
ture techniques. The most common quadrature techniques for stochastic volatil-
ity models are the rectangular quadrature (Bartolucci and De Luca, 2001) and
the Gauss-Legendre quadrature rule (Fridman and Harris, 1998). We adopt the
latter method since in this context we found it superior with respect to other
proposals, especially in terms of computational time. The application of the
Gauss-Legendre quadrature rule to eq. (5) produces the following approximated
likelihood function
˜L(θ|y) =

(cid:19)T nu(cid:88)

nh(cid:88)

whj1 f (y1|u∗

)f (h∗

)f (u∗

, h∗

wui1

)

i1

j1

i1

j1

i1

j1

, h∗

j2

)f (u∗

i2

|u∗

i1

)f (h∗

j2

|h∗

j1

) . . .

(6)

(cid:19)T(cid:18) e − d
nh(cid:88)

2

2

(cid:18) b − a
nu(cid:88)
nu(cid:88)

i2

. . .

wui2

whi2 f (y2|u∗
nh(cid:88)

i2

j2

wuiT

whiT f (yT|u∗

iT

, h∗

jT

)f (u∗

iT

|u∗
iT −1

)f (h∗

jT

|h∗
jT −1

)

iT

jT

i }, with i = 1, . . . , nu, and {h∗

are centered on µu = 0 and µh = α/(1−δ) with a width of 3σu = 3ση/((cid:112)1 − ρ2)

where {u∗
j}, with j = 1, . . . , nh, are sets of Gauss-
Legendre quadrature points, wui and whj are the corresponding weights and
[a, b] and [d, e] are ﬁnite integration limits which replace the inﬁnite ones for the
random eﬀects and the volatility process respectively. The choice of the grids
and the number of evaluation points is crucial for the numerical precision. First,
as proposed in Fridman and Harris (1998), the grids for the two latent processes
1 − δ2); this allows the grids to cover the support of the
and 3σh = 3σν/(
unconditional distributions with non negligible mass. Second, the number of
quadrature points, nu and nh, are chosen according to the degree of smoothness
of the integrands, i.e. the average distance between two points is less or equal
to ση/2 for the random eﬀect process and σν/2 for the volatility process.

√

4.2 Recursive algorithm

In order to facilitate the computation of the approximated likelihood (6) we use
the matrix notation for the recursive algorithm. Deﬁne the (nu×1) and (nh×1)

8

vectors of the initial probabilities as
))(cid:48)

fu1 = (f (u∗

2), . . . , f (u∗

1), f (u∗

nu

and fh1 = (f (h∗

1), f (h∗

2), . . . , f (h∗

nh

))(cid:48)

and the (nunh × 1) vector of the initial conditional probabilities as
f1 = (f (y1|u∗

1), . . . , f (y1|u∗

1), f (y1|u∗

1), f (y1|u∗

1, h∗

2, h∗

1, h∗

, h∗

nu

2), . . . , f (y1|u∗

nu

, h∗

nh

))(cid:48)

nh

)

nh

Fh =

f (u∗

f (h∗

f (h∗

f (h∗

|h∗
1)

. . .
...
. . .

1|h∗
...

1|u∗
1)
...

In the same way, deﬁne the probability transition matrices of the two discretized
latent variables as
1|h∗
1)
...

 Fu =

 f (u∗

 f (h∗

f (u∗
and the (nunh × 1) vector of conditional probabilities for t = 2, . . . , T as
ft = (ft 1, ft 2 . . . ft nh)(cid:48) with ft j = (f (yt|u∗
j ))(cid:48)
, h∗
Finally, deﬁne the vectors wu = (wu1, wu2, . . . , wunu )(cid:48), wh = (wh1, wh2, . . . , whnh)(cid:48)
and the matrices Wu = (wu, wu, . . . , wu), Wh = (wh, wh, . . . , wh) of dimen-
sions (nu×nu) and (nh×nh) respectively. The approximated marginal likelihood
can be computed through the following iterative algorithm

j ), . . . , f (yt|u∗

j ), f (yt|u∗

1|u∗
...

. . .
...
. . .



1, h∗

2, h∗

|u∗
1)

|h∗

nh

)

f (u∗

|u∗

nu

)

)

nu

nu

nu

nu

nh

1. compute the joint probability at the ﬁrst time point (t = 1):

(cid:18) b − a

(cid:19)(cid:18) e − d

(cid:19)

2

2

l1 =

diag(f1)((fh1 ◦ wh) ⊗ (fu1 ◦ wu))

(7)

where ◦ indicates the Hadamard product between two matrices and diag(f1)
is the block-diagonal matrix created from the vector f1. The generic ele-
ment of l1 is l1ij = f (y1, ut = u∗

i , ht = h∗
j ).

2. compute the forward intermediate joint probabilities for t = 2, . . . , T :

diag(ft)((Fh ◦ Wh) ⊗ (Fu ◦ Wu))lt−1,

(8)

(cid:18) b − a

(cid:19)(cid:18) e − d

(cid:19)

2

2

lt =

where diag(ft) is the block-diagonal matrix created from the vector ft.
The generic element of lt is ltij = f (y1, . . . , yt, ut = u∗

i , ht = h∗
j ).

3. compute the approximated marginal likelihood (6) as

˜L(θ|y) = 1(cid:48)lT

(9)

where 1 is a (nunh × 1) vector of ones.

The maximization of expression (9) is carried out by using a quasi-Newton
algorithm in which the gradient and the Hessian matrix are obtained through
numerical derivatives. The choice of the starting values for θ requires two

9

separate strategies, one for the parameters of the stochastic volatility component
and one for the remaining parameters. As for the former, we adapt to repeated
cross-sectional data the method used by Bartolucci and De Luca (2001) in a
time series context. First, consider the stochastic volatility model for the error
terms of the ARE model

it = yit − β0 − ut − x(cid:48)
y∗

itβ = exp(ht/2)it,

(10)

from which, as observed by Harvey et al. (1994), the following expression can
be derived

log y∗2
it) = −1.27 we have that

it = ht + log 2
it

Since E(log 2

ht ≈ h∗

t = log ˆy∗2

it + 1.27

t through a k-term moving average, run a regression of h∗

where ˆyit are obtained as the level-1 residuals of the ARE model. Second,
smooth h∗
t−1 and
use the resulting estimates as initial values of the stochastic volatility param-
eters. As concerns the remaining parameters, the estimates of the ﬁtted ARE
model are taken as starting values.

t on h∗

4.3 Filtering, Smoothing and Prediction

In order to obtain optimal estimators of the unobserved-state vectors u and h,
we perform ﬁltering and smoothing, which diﬀer in the conditioning information
set. Moreover, we derive the one-step-ahead predictors.

4.3.1 Filtering

Denoting with Yt = (y1, . . . , yt), the ﬁltered volatility and the ﬁltered random
eﬀects at time t are deﬁned as

ˆht(Yt) = E(ht|Yt) =
ˆut(Yt) = E(ut|Yt) =

htf (ht|Yt)dht
utf (ut|Yt)dut.

(cid:90)
(cid:90)

10

The ﬁltered values are computed directly from the quantities obtained in the

(cid:90)
(cid:90)

forward recursive algorithm:

ˆht(Yt) =

ˆut(Yt) =

ht

ut

f (ht, Yt)

f (Yt)

f (ut, Yt)

f (Yt)

dht =

dut =

(cid:82)(cid:82) htf (Yt, ut, ht)dutdht
(cid:82)(cid:82) f (Yt, ut, ht)dutdht
(cid:82)(cid:82) utf (Yt, ut, ht)dhtdut
(cid:82)(cid:82) f (Yt, ht, ut)dutdht

(cid:39)

(cid:39)

(cid:80)nu
(cid:80)nh
(cid:80)nu
(cid:80)nh
j h∗
(cid:80)nu
(cid:80)nh
(cid:80)nu
(cid:80)nh
i u∗

j

j

j

i

j

i

i

ltij

j

ltij

ltij

ltij

4.3.2 Smoothing

In the multilevel framework, the random eﬀects are predicted by using either
the Best Linear Unbiased Predictor or the Empirical Bayes Predictor. In both
cases, the best predictor is the expected value conditioned to the whole observed
sample or empirical posterior distribution (for an overview see Searle et al.
(1992) and Skrondal and Rabe-Hesketh (2004)). In stochastic volatility models
the smoothed values are:
ˆht(YT ) = E(ht|YT ) =

f (Yt, ht, ut)f (yt+1, . . . , yT|ht, ut)

dutdht

(11)

ht

ˆut(YT ) = E(ut|YT ) =

ut

f (Yt, ht, ut)f (yt+1, . . . , yT|ht, ut)

dhtdut. (12)

(cid:90) (cid:90)
(cid:90) (cid:90)

f (YT )

f (YT )

In both expressions, the density f (YT ) is approximated through the marginal
likelihood ˜L(θ|y) of Eq. (9) and f (Yt, ht, ut) through ltij. The intermediate
conditional probabilities, f (yt+1, . . . , yT|ht, ut) can be obtained by using the
following backward recursion

1. Deﬁne bT = 1nhnu.
2. Compute the backward conditional probability at time t, with t = T −

(cid:18) b − a

(cid:19)(cid:18) e − d

(cid:19)

1, . . . , 1:

bt =

where the generic element is btij = f (yt+1, . . . , yT|ut = u∗

diag(ft+1)((Fh ◦ Wh) ⊗ (Fu ◦ Wu))bt+1
i , ht = h∗
j ).

With this further recursion, the smoothed values are approximated as

ˆht(YT ) (cid:39)

ltijbtij

ˆut(YT ) (cid:39)

;

ltijbtij

.

2

2

(cid:80)nh
j h∗

j

(cid:80)nu

i

˜L(θ|y)

(cid:80)nu
i u∗

i

(cid:80)nh

j

˜L(θ|y)

4.3.3 Prediction

The one-step-ahead predicted values of volatility and random eﬀects are derived
through the following approximations:

ˆht(Yt−1) = E(ht|Yt−1) =

=

(cid:82) ht
(cid:39) e−d
ˆut(Yt−1) (cid:39) b−a

2

2

(cid:82) htf (ht|Yt−1)f (Yt−1)dht
(cid:82)(cid:82) f (Yt−1, ut−1, ht−1)dht−1dut−1
(cid:110)(cid:82) f (ht|ht−1)(cid:2)(cid:82) f (Yt−1, ut−1, ht−1)dut−1
(cid:3)dht−1
(cid:82)(cid:82) f (Yt−1, ut−1, ht−1)dut−1dht−1
(cid:80)nh
j(cid:48) Fhjj(cid:48)whj(cid:48)(cid:80)nu
(cid:80)nh
(cid:80)nu
(cid:80)nh
(cid:80)nu
(cid:80)nu
i(cid:48) Fuii(cid:48)wui(cid:48)(cid:80)nh
(cid:80)nu
(cid:80)nh

j hjwhj

i uiwui

lt−1,i(cid:48)j

lt−1ij(cid:48)

lt−1,ij

j

j

i

i

i

j

lt−1,ij

(cid:111)

dht

where Fuii(cid:48) and Fhjj(cid:48) denote the generic elements of the transition matrices Fu
and Fh respectively.

11

5 Application to tribal Art prices

In this section we illustrate the application of our model to the ﬁrst database
of ethnic artworks. The responses are the logged prices for 28 semesters for the
overall sample size of 13955 items. We take the ﬁxed eﬀects hedonic speciﬁcation
(FE) as the benchmark model. The covariates are selected through stepwise
(forward and backward) techniques and then combining parsimony with Art
Economics arguments. Table 2 reports the parameter estimates for the three
models: ﬁxed eﬀects (FE), autoregressive random eﬀects (ARE) and stochastic
volatility with autoregressive random eﬀects (SVARE), ﬁtted on the same data
set with the same set of covariates. The asymptotic standard errors for the
FE and SVARE models are derived from the Hessian matrix of the likelihood
functions. The robust standard error for the ARE model are derived by means of
the wild bootstrap for multilevel models introduced in Modugno and Giannerini
(2015).

In order to assess whether the speciﬁcations proposed manage to model sat-
isfactorily the time dynamics and the heterogeneity observed, we have imple-
mented a series of diagnostic tests. Table 3 reports information on the goodness
of ﬁt of the models whereas in Table 4 we present the results of some diagnos-
tic tests and indicators on the residuals. In particular, the ﬁrst row of Table 4
shows the p-values for the Shapiro-Wilk test for normality of the residuals of the
three models; the shapiro.test function in R limits the sample size to 5000.
The results presented are the median p-values over 20000 random subsamples
of size 5000 drawn from the original sample. The last two rows show the in-
dexes of skewness and kurtosis b1 and b2 as in Joanes and Gill (1998) computed
on level-1 residuals. We derive the standardized residuals for the ARE model
from the BLUP of the random eﬀects whereas for the SVARE model we use the
smoothed values for both the random eﬀects (Eq. 12) and the volatility (Eq. 11).
As concerns the time dynamics we assess the adequateness of the models
by computing the sample global and partial autocorrelation functions over time
varying quantities such as level-2 residuals. Moreover, we use the metric entropy
measure Sk deﬁned as

(cid:90) (cid:90) (cid:104){f(Xt,Xt+k)(x1, x2)}1/2 − {fXt(x1)fXt+k (x2)}1/2(cid:105)2

Sk =

1
2

dx1dx2

(13)

where fXt and f(Xt,Xt+k) denote the probability density function of Xt and
of the vector (Xt, Xt+k) respectively. The measure is a particular member
of the family of relative entropies, which includes as a special case non-metric
entropies often referred to as Shannon or Kullback–Leibler divergence. It can be
interpreted as a nonlinear autocorrelation function and possesses many desirable
properties. We use Sk as in Giannerini et al. (2015) to test for nonlinear serial
dependence and as in Granger et al. (2004) to test for serial independence (see
the supplementary material for more details). The tests are implemented in
the R package tseriesEntropy Giannerini (2015). In the spirit of time series
analysis, if the speciﬁcation is appropriate then the residuals behave as a white
noise process and diagnostic tests can suggest directions to improve the existing

12

model.

Finally, Table 5 summarizes and compares the prediction/forecasting capa-
bility of the three models under scrutiny. The aggregate measures of prediction
error are the Mean Absolute (Prediction) Error (MAE) and the Root Mean
Square (Prediction) Error (RMSE):

(cid:118)(cid:117)(cid:117)(cid:116) 1

nT +1

nT +1(cid:88)

i=1

(cid:0)yi,T +1 − ˆyi,T +1

(cid:1)2

nt(cid:88)

nT +1

i=1

MAE =

1

|yi,T +1 − ˆyi,T +1| ; RMSE =

(14)
The ﬁrst two rows of Table 5 report the prediction error over 100 (out of sample)
items within the time span 1998-2011, and the last two rows of the table show
the forecasting performance over all the 73 observations of semester 2011-2.
Such observations have not been included in the model so that the measures
reﬂect a genuine forecasting performance.

5.1 FE and ARE models

The parameter estimates of the FE and ARE models are very similar (ﬁrst two
columns of Table 2), still, there are important diﬀerences: ﬁrst, the ARE ﬁt is
more parsimonious and results in a smaller BIC and AIC (see Table 3); also, it
provides a decomposition of the total variability of the response in between-time
and within-time variability. Furthermore, in the FE model the time dynamics is
modelled through 28 dummy variables while in the ARE model the time dynam-
ics is fully captured through the AR(1) speciﬁcation with the two parameters,
ρ and ση, see Figure 1 and 2 of the Supplementary Material (SM from now
on). The same tests performed on level-2 residuals of the ARE model show no
structure (see Figure 3 and 4 of the SM). Finally, the ARE model provides a
superior one-step-ahead forecasting of the price whereas the prediction perfor-
mance is the same as that of the FE model (see Table 5). The Shapiro-Wilk
test (see Table 4) points to a deviation from normality in level-1 residuals of the
ARE model (whereas it does not reject the assumption of normality for level-2
residuals). As discussed above, this is consistent with the ﬁndings in literature
and might be due to heteroscedasticity. In fact, similarly to other assets, level-1
residuals show a leptokurtic behaviour as shown in Figure 4 and by looking at
the kurtosis index in Table 4. Furthermore, we reject the assumption of ho-
mogeneity of the variance across time points, tested through a non-parametric
version of the Levene (1960) rank-based test (Kruskal and Wallis, 1952).

t

The plot of sARE

, the standard deviations of level-1 residuals ˆit in Fig-
ure 2(left) provides a visual evidence of volatility patterns. The entropy measure
Sk shown in Figure 2(right) conﬁrms the presence of a linear serial dependence
(the test for nonlinearity does not reject, see Figure 6 of the supplementary
material) and the correlograms of Figure 3 indicate a AR(1)-type dependence
structure for the volatility. In the following subsection we account for the ob-
served heterogeneity by ﬁtting the multilevel model with autoregressive random
eﬀects and stochastic volatility (SVARE).

13

Table 2: Parameter estimates for models FE, ARE and SVARE with standard
errors in parentheses. For each categorical variable the baseline category is
indicated. The complete set of estimates is available in the supplementary
material

FE
0.225 (0.006)
-
-
-
-
-
0.103 (0.013)
0.138 (0.010)
0.078 (0.015)
-0.109 (0.011)
-0.126 (0.013)

0.452 (0.021)
1.494 (0.076)
0.996 (0.025)
1.148 (0.026)
1.376 (0.028)
0.823 (0.021)
0.500 (0.047)
0.647 (0.061)
1.024 (0.239)
0.383 (0.029)

σ2
σ2
η
ρ
α
δ
σ2
ν
CABS (Yes vs No)
CABC (Yes vs No)
CAES (Yes vs No)
Christie’s (vs Sotheby’s)
Paris (vs New York)
Illustration: baseline Absent
- Miscellaneous col.
- Col. cover
- Col. half page
- Col. full page
- More than one col.
- Col. quarter page
- Miscellaneous b/w
- b/w half page
- b/w full page
- b/w quarter page
Description on the catalogue: baseline Absent
- Short visual descr.
- Visual descr.
- Broad visual descr.
- Critical descr.
- Broad critical descr.
Type of object: baseline Furniture
- Masks
- Religious objects
- Ornaments
- Sculptures
- Musical instruments
- Tools
- Clothing
- Weapons
Continent: baseline Africa
- America
- Oceania
Patina: baseline Not indicated
- Pejorative
- Appreciative
Historicization: baseline Absent
- Museum certiﬁcation
- Relevant museum certiﬁcation
- Simple certiﬁcation

0.121 (0.025)
0.047 (0.027)
-0.161 (0.026)
0.062 (0.023)
-0.098 (0.036)
-0.088 (0.024)
-0.077 (0.037)
-0.131 (0.030)

0.175 (0.013)
0.167 (0.012)

0.210 (0.046)
0.124 (0.012)

0.045 (0.017)
0.065 (0.016)
0.053 (0.011)

-0.099 (0.037)
0.078 (0.038)
0.325 (0.041)
0.319 (0.041)
0.719 (0.045)

ARE
0.226 (0.004)
0.022 (0.015)
0.837 (0.140)
-
-
-
0.102 (0.015)
0.138 (0.011)
0.078 (0.016)
-0.110 (0.013)
-0.124 (0.015)

SVARE
-
0.021 (0.000)
0.848 (0.025)
-0.142 (0.012)
0.931 (0.035)
0.158 (0.001)
0.093 (0.012)
0.127 (0.010)
0.081 (0.013)
-0.153 (0.011)
-0.076 (0.012)

0.453 (0.031)
1.494 (0.104)
0.995 (0.034)
1.149 (0.034)
1.377 (0.037)
0.823 (0.029)
0.500 (0.040)
0.647 (0.057)
1.025 (0.290)
0.383 (0.033)

-0.100 (0.042)
0.076 (0.044)
0.325 (0.047)
0.319 (0.049)
0.718 (0.055)

0.121 (0.025)
0.046 (0.030)
-0.161 (0.030)
0.061 (0.025)
-0.098 (0.044)
-0.089 (0.027)
-0.078 (0.040)
-0.131 (0.033)

0.441 (0.020)
1.395 (0.075)
0.864 (0.024)
1.030 (0.026)
1.273 (0.027)
0.701 (0.020)
0.411 (0.038)
0.553 (0.047)
0.829 (0.190)
0.302 (0.025)

-0.138 (0.035)
0.036 (0.035)
0.274 (0.038)
0.266 (0.038)
0.640 (0.042)

0.111 (0.023)
0.039 (0.025)
-0.111 (0.024)
0.062 (0.021)
-0.061 (0.033)
-0.075 (0.022)
-0.075 (0.032)
-0.095 (0.028)

0.174 (0.016)
0.167 (0.014)

0.162 (0.013)
0.147 (0.011)

0.209 (0.044)
0.124 (0.014)

0.167 (0.046)
0.104 (0.012)

0.045 (0.021)
0.064 (0.018)
0.053 (0.013)

0.021 (0.016)
0.045 (0.015)
0.061 (0.010)

14

Figure 2: Standard deviations of ARE level-1 residuals sARE
: time plot (left)
and entropy measure of dependence (right). The conﬁdence bands correspond
to the null hypothesis of serial independence at levels 90% and 95% up to 10
lags/semesters.

t

15

SemestersAREt0.40.50.60.71-19981-20021-20061-20102468100.000.020.040.060.08lagSTable 3: Loglikelihood, number of parameters and Information criteria for the
hedonic regression (FE), ARE and SVARE models.

FE

ARE

SVARE

loglik
n. par
AIC
BIC

-9405.833
70
18952
19480

-9472.96
45
19036
19375

-8785.624
47
17665
18020

Table 4: p-values of the Shapiro-Wilk test and indexes of skewness and kurtosis
for the FE, ARE and SVARE (level-1) residuals.

FE

ARE

SVARE

Shapiro-Wilk p-value <2e-17
-0.1683
Skewness
Kurtosis
1.0553

2e-16
-0.1727
1.0630

3e-07
0.0221
0.4568

Figure 3: Global (left) and partial (right) empirical autocorrelation functions of
standard deviations of ARE level-1 residuals.

16

0246810-1.0-0.50.00.51.0LagACF246810-1.0-0.50.00.51.0LagPartialACFFigure 4: Density of level-1 residuals. The right panel is a zoomed detail of the
peak that highlights the kurtosis.

5.2 SVARE model

A ﬁrst important result is that the parameter estimates diﬀer to some extent
from those of the FE/ARE models, see Table 2. Even if in most cases the signif-
icance of the parameters does not change, SVARE estimates account properly
for the volatility and reﬂect more closely the impact of the covariates on art-
work prices. The estimate of the volatility parameter ˆδ = 0.931 agrees with
those of models for ﬁnancial time series reported in literature and indicates a
non-negligible volatility persistence. Indeed, the goodness of ﬁt of the SVARE
model increases considerably as witnessed by the information criteria shown in
Table 3. Note also that the standard errors of the estimates are almost uniformly
the smallest among the three models.

Also for the SVARE model, the Shapiro-Wilk test of normality of level-1
residuals rejects the null hypothesis (Table 4). Nevertheless, the leptokurtic
behaviour of residuals is considerably reduced with respect to both the ARE
and FE models. This is shown in Table 4 (the skewness disappears and the
kurtosis is more than halved) and in Figure 4 where we show the densities
of level-1 residuals for the ARE and SVARE models. Note the agreement of
SVARE residuals with the standard Normal density (dotted in the ﬁgure). See
also Figure 11 of the SM for a normal qqplot of level-1 residuals of the two
models. As in the FE/ARE case, we compute the diagnostic tests of dependence
on level-2 residuals ˆηt and ˆνt. Both the correlograms and the entropy measure
Sk indicate the absence of any dependence structure (see Figures 7 - 10 of the
Supplementary Material) so that we may argue that the SVARE speciﬁcation
manages to capture the volatility dynamics. Finally, from Table 5 it emerges
clearly that the SVARE speciﬁcation performs best among competitors in terms
of both prediction and forecasting.

17

-4-20240.00.10.20.30.4StandardizedresidualsDensityStd.NormalSVAREARE/FE-1.5-1.0-0.50.00.51.01.50.200.250.300.350.40StandardizedresidualsDensityStd.NormalSVAREARE/FETable 5: Prediction/forecasting performance of the three models over 100 out-
of-sample units within the time span 1998-2011 (rows 1-2) and over 73 units of
the out-of-sample semester, 2011-2 (rows 3-4).

FE

ARE SVARE

Prediction MAE

Forecast

0.288
RMSE 0.355
MAE
0.534
RMSE 0.673

0.288
0.355
0.376
0.512

0.278
0.344
0.355
0.479

Note that the choice of the number of quadrature points nu and nh is crucial
to the estimation of the SVARE model. We ﬁrst set nu = 21 and nh = 41
according to the rule given in Section 4.1, then we increased them up to 71.
As for the autoregressive part of the model, we found that the parameters’
estimates are quite robust except for ρ whose estimate stabilizes for nu ≥ 51.
The estimates of the Stochastic Volatility component are more sensitive to the
number of quadrature points so that we set nu = nh = 61. This yields sensible
results even for high values of δ, that is, in those cases where the integrand
is very peaked and requires a large number of quadrature points to be well
approximated.

6 Conclusions

A great added value of the SVARE speciﬁcation for repeated cross sections is
that it encompasses in a unique framework the trends in the mean and in the
volatility of artwork prices. The left panel of Figure 5 compares the resulting
biannual price indexes obtained through the ARE and SVARE ﬁts. They are
computed with ﬁxed base in semester b =“1-1998” as

It =

e ˆβ0t
e ˆβ0b

× 100,

where ˆβ0t are the BLUP values ˆβ0 + ˆut. Note that the indexes are similar,
nevertheless, the SVARE model provides the predicted volatility values ˆht of
Eq. 11 (right panel of Figure 5). This is important additional information on
the predictability of the prices that complements that of the index and can be
exploited by art market stakeholders for an informed decision making.

Acknowledgements

We would like to thank Guido Candela, Antonello Scorcu, Massimiliano Castel-
lani and Pierpaolo Pattitoni for useful discussions. Silvia Cagnone and Lu-
cia Modugno acknowledge the ﬁnancial support from the grant RBFR12SHVV

18

Figure 5: Price index (with base “semester 1-1998”) of the art market for the
ARE and SVARE models (left panel). Plot of volatility of the SVARE model
(right panel).

funded by the Italian Government (FIRB project “Mixture and latent variable
models for causal inference and analysis of socio-economic data”).

References

Agnello, R. and R. Pierce (1996). Financial returns, price determinants,
Journal of Cultural Eco-

and genre eﬀects in american art investment.
nomics 20 (4), 359–383.

Bartolucci, F. and G. De Luca (2001). Maximum likelihood estimation of a
latent variable time-series model. Applied Stochastic Models in Business and
Industry 17, 5–17.

Baumol, W. (1986). Unnatural value: or art investment as ﬂoating crap game.

The American Economic Review 76 (2), 10–14.

Bocart, F. and C. Hafner (2012). Econometric analysis of volatile art markets.

Computational Statistics & Data Analysis 56 (11), 3091 – 3104.

Bocart, F. Y. and C. M. Hafner (2013). Volatility of price indices for hetero-
geneous goods with applications to the ﬁne art market. Journal of Applied
Econometrics. doi: 10.1002/jae.2355.

Browne, W. and H. Goldstein (2010). MCMC sampling for a multilevel model
with nonindependent residuals within and between cluster units. Journal of
Educational and Behavioral Statistics 35, 453–473.

19

SemesterPriceindex801001201401601802001-19981-20021-20061-2010ARESVARESemesterVolatility0.40.50.60.71-19981-20021-20061-2010Cagnone, S. and F. Bartolucci (2016). Adaptive quadrature for maximum like-

lihood estimation of a class of dynamic latent variable models. submitted .

Candela, G., M. Castellani, and P. Pattitoni (2013). Reconsidering psychic

return in art investments. Economics Letters 118 (2), 351 – 354.

Chanel, O. (1995). Is art market behaviour predictable? European Economic

Review 39, 519–527.

Chanel, O., L. A. Grard-Varet, and V. Ginsburgh (1996). The relevance of he-
donic price indices. The case of paintings. Journal of Cultural Economics 20,
1–24.

Collins, A., A. E. Scorcu, and R. Zanola (2009). Reconsidering hedonic art price

indexes. Economics Letters 104, 57–60.

DiPrete, T. A. and D. B. Grusky (1990). The multilevel analysis of trends with

repeated cross-sectional data. Sociological Methodology 20, 337–368.

Fridman, M. and L. Harris (1998). A Maximum Likelihood Approach for Non-
Gaussian Stochastic Volatility Models. Journal of Business & Economic
Statistics 16 (3), 284–291.

Giannerini, S. (2015). tseriesentropy: Entropy Based Analysis and Tests for

Time Series. R package version 0.5-13.

Giannerini, S., E. Maasoumi, and E. Bee Dagum (2015). Entropy testing for

nonlinear serial dependence in time series. Biometrika 102, 661–675.

Ginsburgh, V. and P. Jeanﬁls (1995). Long-term comovements in international

markets for paintings. European Economic Review 39, 538–548.

Goetzmann, W., E. Mamonova, and C. Spaenjers (2014, August). The eco-
nomics of aesthetics and three centuries of art price records. Working Paper
20440, National Bureau of Economic Research.

Goetzmann, W. N. (1993). Accounting for taste: Art and ﬁnancial markets over

three centuries. The American Economic Review 83, 1370–1376.

Goldstein, H. (2010). Multilevel Statistical Models (4th ed.). Chichester: J.

Wiley & Sons.

Granger, C. W. J., E. Maasoumi, and J. Racine (2004). A dependence metric

for possibly nonlinear processes. J. Time Ser. Anal. 25 (5), 649–669.

Harvey, A., E. Ruiz, and N. Shephard (1994). Multivariate stochastic variance

models. The Review of Economic Studies 61 (2), pp. 247–264.

Hodgson, D. and K. Vorkink (2004). Asset pricing theory and the valuation of
canadian paintings. The Canadian Journal of Economics / Revue canadienne
d’Economique 37 (3), pp. 629–655.

20

Joanes, D. and C. Gill (1998). Comparing measures of sample skewness and
kurtosis. Journal of the Royal Statistical Society. Series D (The Statisti-
cian) 47 (1), 183–189.

Kitagawa, G. (1987). Non-gaussian state-space modeling of nonstationary time
series (with discussion). Journal of the American Statistical Association 82,
1032–1063.

Kruskal, W. H. and W. A. Wallis (1952). Use of ranks in one-criterion variance

analysis. Journal of the American Statistical Association 47, 583–621.

Levene, H. (1960). Robust tests for equality of variances. In I. Olkin (Ed.),
Contributions to Probability and Statistics. Palo Alto, CA: Stanford Univ.
Press.

Locatelli Biey, M. and R. Zanola (2005). The market for picasso prints: A

hybrid model approach. Journal of Cultural Economics 29, 127–136.

Modugno, L., S. Cagnone, and S. Giannerini (2015). A multilevel model with
time series components for the analysis of tribal art prices. Journal of Applied
Statistics 42 (10), 2141–2158.

Modugno, L. and S. Giannerini (2015). The wild bootstrap for multilevel models.

Communications in Statistics – Theory and Methods 44 (22), 4812–4825.

Rosen, S. (1974). Hedonic prices and implicit markets: product diﬀerentiation

in pure competition. Journal of Political Economy 82, 34–55.

Searle, S. R., G. Casella, and C. E. McCulloch (1992). Variance components.

New York: Wiley.

Skrondal, A. and S. Rabe-Hesketh (2004). Generalized latent variable modeling:
multilevel, longitudinal, and structural equation models. New York: Chapman
& Hall/CRC.

Tanizaki, H. and R. Mariano (1998). Nonlinear and nonnormal state-space mod-
eling with monte-carlo stochastic simulations. Journal of Econometrics 83,
263–290.

Wooldridge, J. M. (2002). Econometric Analysis of Cross Section and Panel

Data. Cambridge, Massachusetts: The MIT Press.

21

