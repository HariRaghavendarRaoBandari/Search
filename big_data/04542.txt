6
1
0
2

 
r
a

 

M
5
1

 
 
]
T
S
h
t
a
m

.

[
 
 

1
v
2
4
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Optimal rates for parameter estimation of stationary Gaussian

processes

Khalifa Es-Sebaiy1 and Frederi G. Viens 2

Cadi Ayyad University and Purdue University

Abstract: We study rates of convergence in central limit theorems for partial sum of
functionals of general stationary and non-stationary Gaussian sequences, using optimal tools from
analysis on Wiener space. We apply our result to study drift parameter estimation problems for
some stochastic diﬀerential equations driven by fractional Brownian motion with ﬁxed-time-step
observations.

Key words: Central limit theorem; Berry-Esséen; stationary Gaussian processes; Nourdin-

Peccati analysis; parameter estimation; fractional Brownian motion.

1 Introduction

While statistical inference for Itô-type diﬀusions has a long history, statistical estimation for equa-
tions driven by fractional Brownian motion (fBm) is much more recent, partly because the devel-
opment of stochastic calculus with respect to the fBm, which provides tools to study such models,
is itself a recent and ongoing endeavor, and partly because these tools can themselves be unwieldy
in comparison with the convenience and power of martingale methods and the Markov property
which accompany Itô models. Our purpose in this article is to show how the analysis on Wiener
space, particularly via tools recently developed to study the convergence-in-law properties in Wiener
chaos, can be brought to bear on parameter estimation questions for fBm-driven models, and more
generally for arbitrary stationary Gaussian models.

1.1 Context and general ideas

There are several approaches to estimating drift parameters in fBm-driven models, which have been
developed over the course of the past 10 or 15 years. The approaches we mention below are related
to the methods in this article.

• The MLE approach in [17], [27]. In general the techniques used to construct maximum like-
lihood estimators (MLE) for drift parameters are based on Girsanov transforms for fBm and
depend on the properties of the deterministic fractional operators (determined by the Hurst
parameter) related to the fBm. In general, the MLE is not easily computable. In particular,
it relies on being able to compute stochastic integrals with respect to fBm. This is diﬃcult or

1National School of Applied Sciences - Marrakesh, Cadi Ayyad University, Marrakesh, Morocco. Email:

k.essebaiy@uca.ma

2Dept. Statistics and Dept. Mathematics, Purdue University, 150 N. University St., West Lafayette, IN 47907-

2067, USA. E-mail: viens@purdue.edu

1

hopeless for most models since approximating pathwise integrals w.r.t. fBm, when they exist,
is challenging, while Skorohod-type integrals cannot be computed based on the data except in
special cases. The work in [27] is the only one in which a strongly consistent discretization of
the MLE was based on long-horizon asymptotics without also requiring an in-ﬁll (small time
step) condition, though it did not establish any asymptotic distribution.

• A least-squares (LS) approach was proposed in [14]. The study of the asymptotic properties
of the estimator is based on certain criteria formulated in terms of the Malliavin calculus (see
[24]). It should be noted that in [14], the full LS estimator relies on an unobservable Skorohod
integral, and the authors proposed a modiﬁed version of this estimator which can be computed
based on in-ﬁll asymptotics; however, this modiﬁed estimator bears no immediate relation to
an LS one (see [13] for examples of what constitutes a discretization of an LS estimator for
fBm models, and for a comparison with MLE methods, which coincide with LS methods if
and only if H = 1/2).
In the ergodic case, the statistical inference for several fractional
Ornstein-Uhlenbeck (fOU) models via LS methods was recently developed in the papers [14],
[1], [2], [13], [15], [6], [21]. The case of non-ergodic fOU process of the ﬁrst kind and of the
second kind can be found in [3], [11] and [12] respectively.

We bring new techniques to statistical inference for stochastic diﬀerential equations (SDEs)

related to stationary Gaussian processes. Some of these ideas can be summarized as follows:

• Since the theory of inference for these fBm-driven SDEs is still near its inception, and most
authors are concerned with linear problems, whose solutions are Gaussian, this Gaussian
property should be exploited to its fullest extent, given the best tools currently available.

– Therefore we choose to consider polynomial variations of these processes, which then
necessarily live in Wiener chaos, whose properties are now well understood thanks to
new Malliavin-calculus advances which were initiated by Nourdin and Peccati in 2008; in
particular, we rely a general observation and their so-called optimal 4th moment theorem,
in [22].

– As a consequence, we are able to compute upper bounds in the total variation (TV) norm
for the rate of normal convergence of our estimator. In particular, for the quadratic case,
we prove a Berry-Esséen theorem (speed on the order of 1/√n) for this TV norm which
we show is sharp in some cases by ﬁnding a lower bound with the same speed. No
authors as far as we know have ever provided such quantitative estimates of the speed of
asymptotic normality for any drift estimators for any fBm-driven model, let alone shown
that they are sharp.

• Rather than starting from the continuous-time setting of SDEs, and then attempt to discretize
resulting LS estimators, as was done in many of the aforementioned works including our
own [13], we work from discretely observed data from the continuous-time SDEs, and design
estimators based on such Gaussian sequences. In fact, we show that one can develop estimators
valid for any Gaussian sequence, with suitable conditions on the sequence’s auto-correlation

2

function, and then apply them to fBm-driven SDEs of interest.
In this way, we are able
to provide estimators for many other models, while the models studied in [15], [1], [2], [13]
become particular cases in our approach.

• Since our method relies on conditions which need only be checked intrinsically on the auto-
correlation function, it can apply equally well to in-ﬁll situations and increasing-horizon situ-
ations.

– It turns out that, as an artefact of trying to discretize estimators based on continu-
ous paths, prior works were never able to avoid an in-ﬁll assumption on the data (and
sometimes even required both in-ﬁll and increasing-horizon assumptions). In this paper,
we illustrate our methods by showing that in-ﬁll assumptions are never needed for the
examples we cover.

– Essentially, as explained in more detail further below, if a Gaussian stochastic process
has a memory correlation length which is bounded above by that of a fBm with Hurst
parameter H < 3/4, then our polynomial variations estimator based on discrete data
(ﬁxed time step) is asymptotically normal as the number of observations n increases,
with a TV speed as good as 1/√n, as mentioned above.

• Finally, we provide a systematic study of how to go from stationary observations, to ob-
servations coming from a Gaussian process which may not be stationary, by implementing
a fully quantitative strategy to control the contribution of the non-stationarity to the TV
convergence speeds. In the examples we cover, which are those of recent interest in the liter-
ature, the non-stationarity term vanishes exponentially fast, which is more than enough for
our generic condition to hold, but slower power convergences would yield the same results, for
summable powers.

1.2 Summary of results

We summarize our paper’s contents brieﬂy in this section, including some heuristics for easier
reading. Consider a centered stationary Gaussian process Z = (Zk)k∈Z with covariance (auto-
correlation function)

rZ (k) := E [Z0Zk] for every k ∈ Z such that rZ(0) > 0.

Fix a polynomial function fq of degree q where q is an even integer. To estimate the parameter
λfq (Z) := E [fq(Z0)], we use the “polynomial variation” estimator

Qfq,n(Z) :=

1
n

n−1Xi=0

fq(Zi),

which can be considered as a scalar version of a generalized method of moments. Some of the
general results we prove are the following.

3

• Qfq,n(Z) is strongly consistent under a very weak decay condition on rZ (Theorem 1), without

requiring ergodicity.

• To avoid situations where the memory of Z is so long that Qfq,n(Z)’s asymptotics are non-
normal, we introduce the following assumption (condition (12)), which is a special case of the
condition used by Breuer and Major in 1983 to establish normality of Hermite variations (see
[24, Chapter 7]):

uf2 (Z) := 2Xj∈Z

rZ(j)2 < ∞,

with a similar deﬁnition for λfq (Z), the limit of V ar(cid:0)Qfq,n(Z)(cid:1), which is then also ﬁnite.

– Under this condition, as an extension of our main TV convergence rate Theorem 4, we

prove the following for the normalized (Corollary 5):

dT V (cid:0)√n(cid:2)Qfq,n(Z) − λfq (Z)(cid:3) ,N(cid:0)0, ufq (Z)(cid:1)(cid:1)
6 Cq(Z)(cid:18) 4qκ4(Uf2,n(Z)) +qκ4(Uf2,n(Z))(cid:19) + 2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

V ar(cid:0)Qfq,n(Z)(cid:1)

ufq (Z)

1 −

(1)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where Uf2,n(Z) := Qf2,n(Z)− uf2 (Z), which comes from the case q = 2, controls all cases
of q nonetheless. Thus the total variation distance between the renormalized estimator
and the normal law with asymptotic variance ufq (Z) is bounded by the 4th root of the
4th cumulant in the quadratic case, and the relative distance of the estimator’s variance
to its limit.

practical importance.

– If further normalizing by V ar(cid:0)Qfq,n(Z)(cid:1), the last term above vanishes, though the unnor-
malized expression is the only one which can be computed in practice, since V ar(cid:0)Qfq,n(Z)(cid:1)
depends on the parameter λ. Thus the speed of convergence of V ar(cid:0)Qfq,n(Z)(cid:1) is of major
– There are explicit expressions for κ4(Uf2,n(Z)) and V ar(cid:0)Qfq,n(Z)(cid:1) which can be ex-

pressed using rZ , as explained in Section 3.4.1. Consequently, the above upper bound
can be computed explicitly for many cases of rZ. For instance (Corollary 6) , if Z has
a memory which is bounded above by that of fractional Gaussian noise with parameter
H < 5/8, the above result yields

dT V (cid:0)√n(cid:2)Qfq,n(Z) − λfq (Z)(cid:3) ,N(cid:0)0, ufq (Z)(cid:1)(cid:1) 6 1/ 4√n.

• The case where Qfq,n(Z)’s asymptotics are non-normal can be treated using other, less optimal,
tools. For the sake of conciseness, we do not provide detailed arguments in this paper, instead
stating results without proof in Remarks 7 and 16.

• In practice, it is common to encounter situations where observations are not stationary, for
instance because their initial value is a point mass rather than the stationary law of a stochastic
system. Thus, assuming that the observations come from Xk = Zk + Yk where Z is as above

4

and Y is the deviation from a stationary process, we prove a convergence theorem under a
If there exist p0 ∈ N and a
generic assumption on Y which is easily veriﬁed in practice.
constant γ > 0 such that for every p > p0 and for all n ∈ N,

then for the Wasserstein distance (see Theorem 11 for details)

(cid:13)(cid:13)Qfq,n(Z + Y ) − Qfq,n(Z)(cid:13)(cid:13)Lp(Ω) = O(cid:0)n−γ(cid:1)
dW(cid:0)Qfq,n(X) − λfq (Z),N(cid:0)0, ufq (Z)(cid:1)(cid:1)
2−γ + C 4qκ4(Uf2,n(Z)) + C(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1 −

1

V ar(cid:0)Qfq,n(Z)(cid:1)

ufq (Z)

.

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

6 Cn

• When q = 2, up to a constant, the estimator Qf2,n(Z) is in the second chaos. In this case,

sharper results are established.

– For instance, assuming uf2 (Z) < ∞ and the following two conditions (see Theorem 12

for details):

kQf2,n(Z + Y ) − Qf2,n(Z)kL1(Ω)

(cid:12)(cid:12)uf2 (Z) − E(cid:2)U 2

6 O(cid:18) 1
n(cid:19) ,
√n(cid:19) ,
f2,n(Z)(cid:3)(cid:12)(cid:12) 6 O(cid:18) 1
6 dW(cid:0)√n(cid:2)Qfq,n(X) − λfq (Z)(cid:3) ,N(cid:0)0, ufq (Z)(cid:1)(cid:1) 6

c1√n

C1√n

.

then for the Wasserstein distance, assuming constants in the above assumptions are not
too large,

In this sense, we have established conditions under which our variation for a non-
stationary and highly correlated sequence satisﬁes a quantitative Berry-Esséen-type the-
orem with optimal rate (recall that the classical Berry-Esséen theorem is for an i.i.d.
sequence and is stated for the Kolmogorov distance, which is bounded above strictly by
our Wasserstein distance).

– It is remarkable that this results holds for all Gaussian sequences with autocorrelation
bounded above by that of fBm with H < 2/3 (whereas the best results for q > 2 show
that one needs the stronger condition H < 5/8).

• Before moving to speciﬁc examples, we establish two improvements: a strategy for converting
the above results into estimators for parameters which are buried in a functional form for
λfq (Z), and a method for improving rates of convergence by taking ﬁnite diﬀerences.

– If we are interested in a parameter θ which is related to λ via λfq (Z) = g−1 (θ) where g

is a diﬀeomorphism, so that ˇθn := g(cid:0)Qfq,n(Z)(cid:1) is a strongly consistent estimator of θ,
under the condition that g′′(cid:0)Qfq,n(Z)(cid:1) has moments of suﬃciently large order, then

dW(cid:0)√n(cid:0)ˇθn − θ(cid:1) ,N (0, g′(λfq (Z))2V ar(cid:0)Qfq,n(Z)(cid:1))(cid:1)

5

converges to 0 at the same speed as in (1). This is in Theorem 17.

– Finally, by considering X (1)

k = Xk − Xk−1, it is well known that memory length is de-
creased by 2 power units in autocorrelation for all long-memory sequences with power
decay; thus Z (1)
k becomes suﬃciently short memory to allow us to apply the best con-
vergence results above; in particular conditions such as “H < 5/8” are automatically
satisﬁed as soon as one takes a ﬁrst-order ﬁnite diﬀerence. This is explained in Section
5. For instance in Theorem 20, we ﬁnd

c
√n

6 dW(cid:16)Qf2,n(Z (1)) − λf2,n(Z (1)),N(cid:16)0, uf2(Z (1))(cid:17)(cid:17) 6

C
√n

.

Arguably, as long as one can compute λf2,n(Z (1)) and relate it to a parameter of interest,
this improvement allows one to take advantage of the best rate of convergence, that of
Berry-Esséen order. A study of one example of what it means to extract a parameter
from λf2,n(Z (1)) is given in Section 6.3.3, for the fractional Ornstein-Uhlenbeck process.

This bring us to the last sections in which we apply the above results to speciﬁc cases.

• Application to fractional Ornstein Uhlenbeck models. An Ornstein-Uhlenbeck process X =

{Xt, t > 0} is the solution of the linear stochastic diﬀerential equation

X0 = 0;

dXt = −θXtdt + dGt,

t > 0,

(2)

where G is a Gaussian process and θ > 0 is an unknown parameter. The problem here is to
estimate the parameter θ based on discrete equidistant observations (ﬁxed time step, horizon
tending to +∞), and provide precise CLTs, which can be useful for hypothesis testing in
practice via parametric inference.

0 XsδXs(cid:17) /(cid:16)R t

0 X 2

s ds(cid:17) of θ when the

– Fractional Ornstein-Uhlenbeck model (Section 6): the process G in (2) is a fractional
2 , [14]

Brownian motion with Hurst parameter H ∈ (0, 1). By assuming that H > 1

studied the least-squares estimator (LSE) bθt =(cid:16)R t

process X is continuously observed. In this paper, using our approach we construct a
class of explicit estimators of θ when the process X is discretely observed. We study
the asymptotic behavior of these estimators for any H ∈ (0, 1) with Berry-Esséen-type
theorems. We prove the consistency and prove that our estimators are asymptotically
normal when H ∈ (0, 3
4 ]. In the particular case when q = 2 and f2(x) = x2, [15] proved
strong consistency of this discrete estimator and gave a Berry-Esséen-type result when
H ∈ ( 1
4 ) but the proofs in [15] rely on a possibly ﬂawed technique, since the passage
from line -7 to -6 on page 434 is true if H > 3
4 , while one expects normal asymptotics
only for the case H 6 3
4 . Our work resolves the issue of θ estimation via least squares and
their higher-order generalizations, by appealing to our new tools, avoiding the arguments
in [15]. We present a number of results in this section, including Berry-Esséen estimates,
optimal lower bounds thereof, an implementation the inversion of the quadratic variation
estimator to access θ directly, and details of how to increase the rate of convergence via
ﬁnite-diﬀerences.

2 , 3

6

– Ornstein-Uhlenbeck process driven by fractional Ornstein-Uhlenbeck process (Section 7.1):
here X is again given by (2) with drift parameter θ, and G is itself a fractional Ornstein-
Uhlenbeck process with Hurst index H ∈ (0, 1) and drift parameter ρ > 0. Here θ and
ρ are considered as unknown parameters (with θ 6= ρ), and we assume that only X
is observed. This is the long-memory analogue of a continuous-time latent Markovian
framework, in other words a partial observation, or partial information, question. This
question was considered in [13] when H ∈ ( 1
4 ); therein, an estimator of (θ, ρ) was
provided in the continuous and discrete cases, but relatively strong in-ﬁll assumptions
were needed, though the estimators still needed an increasing-horizon setting.
In the
present paper, we extend the result to H ∈ (0, 1) and we propose a class of estimators
with Berry-Esséen behavior, which dispenses with any in-ﬁll assumption. A full set of
results such as in Section 7.1 could also be derived, including optimal Berry-Esséen rates
for the quadratic case in this two-dimensional setting; for the sake of conciseness, we
omit stating all these improvements.

2 , 3

– Fractional Ornstein-Uhlenbeck process of the second kind (Section 7.2): again with X as
in (2), this process arises when G has the form Gt = R t
s
0 e−sdBas with as = He
H and
B = {Bt, t > 0} is a fractional Brownian motion with Hurst parameter H ∈ ( 1
2 , 1), and
where θ > 0 is a unknown real parameter; notationally, to be consistent with previous
work on this topic, we use the letter α instead of θ. The continuous and discrete cases,
when q = 2 and f2(x) = x2, are studied in [1] and [2], though no speeds of convergence
are provided, and in-ﬁll assumptions are needed. In Section 7.2, we propose a class of
estimators and we provide Berry-Esséen-type theorems of them with no in-ﬁll assumption.
The covariance structure of the process is such that our methods easily provide an optimal
convergence rate for the estimator after inversion of the quadratic variation.

In conclusion, our methodology is developed for essentially any stationary Gaussian se-
quence, we can handle some non-stationarity under a weak assumption on the speed of relaxation
to a stationary law, we provide Berry-Esséen rates for the normal asymptotics of our polynomial
variation estimators, particularly in the quadratic case where the rates are often optimal, and we
analyze some of the issues that can arise when inverting a polynomial variation to access a speciﬁc
parameter. This is all achieved by relying on the sharpest estimates known to date, in the frame-
work of Nourdin and Peccati, in Wiener chaos for total variation and Wasserstein convergence in
law. Applications to drift estimation for long-memory models of current interest are provided.

Our article is structured as follows. Section 2 provides some basic elements of analysis on
Wiener space which are helpful for some of the arguments we use. Section 3 provides the general
theory of polynomial variation for general Gaussian sequences, covering the stationary case (Section
3.3, with examples in Section 3.4), non-stationary cases (Section 4), which include optimality in
the quadratic case even under non-stationarity (Section 4.2) and a strategy of how to access a
speciﬁc parameter other than the polynomial’s variance (Section 4.3). Section 5 explains under what
circumstances one can increase the rate of convergence to an optimal level by ﬁnite-diﬀerencing.
Finally, three sets of examples based on fractional Ornstein-Uhlenbeck constructions are given in

7

Sections 6 and 7. Some of the technical results used in various proofs, including the proof of the
basic Berry-Esséen theorem in the stationary case, are in the Appendix (Section 8).

2 Elements of analysis on Wiener space

Here we summarize a few essential facts from the analysis on Wiener space and the Malliavin
calculus. Though these facts and notation are essential underpinnings of the tools and results of
this paper, most of our results and arguments can be understood without knowledge of the elements
in this section. The interested reader can ﬁnd more details in [25, Chapter 1] and [24, Chapter 2].
Let (Ω,F, P) be a standard Wiener space, its standard Wiener process W , where for a
deterministic function h ∈ L2 (R+) =: H, the Wiener integral RR+
h (s) dW (s) is also denoted by
W (h). The inner productRR+
f (s) g (s) ds will be denoted by hf, giH. For every q > 1, let Hq be
the qth Wiener chaos of W , that is, the closed linear subspace of L2(Ω) generated by the random
variables {Hq(W (h)), h ∈ H,khkH = 1} where Hq is the qth Hermite polynomial. The mapping
Iq(h⊗q) : = q!Hq(W (h)) provides a linear isometry between the symmetric tensor product H⊙q
(equipped with the modiﬁed norm k.kH⊙q = 1√q!k.kH⊗q ) and Hq. It also turns out that Iq(h⊗q) is
the multiple Wiener integral of h⊗q w.r.t. W . For every f, g ∈ H⊙q the following product formula
holds

E (Iq(f )Iq(g)) = q!hf, giH⊗q .

For h ∈ H⊗q, the multiple Wiener integrals Iq(h), which exhaust the set Hq, satisfy a hypercon-
tractivity property (equivalence in Hq of all Lp norms for all p > 2), which implies that for any
F ∈ ⊕q

l=1Hl, we have

Though we will not insist on their use in the main body of the paper, leaving associated
technicalities to the proof of one of our main theorems in the appendix, the Malliavin derivative
operator D on L2 (Ω) plays a fundamental role in evaluating distances between random variables
therein. For any function Φ ∈ C 1 (R) with bounded derivative, and any h ∈ H, we deﬁne the
Malliavin derivative of the random variable X := Φ (W (h)) to be consistent with the following
chain rule:

DX : X 7→ DrX := Φ′ (W (h)) h (r) ∈ L2 (Ω × R+) .

A similar chain rule holds for multivariate Φ. One then extends D to the so-called Gross-Sobolev
subset D1,2 & L2 (Ω) by closing D inside L2 (Ω) under the norm deﬁned by

kXk2

1,2 = E(cid:2)X 2(cid:3) + E(cid:20)ZR+ |DrX|2 dr(cid:21) .

Now recall that, if X, Y are two real-valued random variables, then the total variation

distance between the law of X and the law of Y is given by

dT V (X, Y ) = sup

A∈B(R)|P [X ∈ A] − P [Y ∈ A]| .

8

(cid:0)E(cid:2)|F|p(cid:3)(cid:1)1/p

6 cp,q(cid:0)E(cid:2)|F|2(cid:3)(cid:1)1/2

for any p > 2.

(3)

If X, Y are two real-valued integrable random variables, then the Wasserstein distance between the
law of X and the law of Y is given by

dW (X, Y ) = sup

f∈Lip(1)|Ef (X) − Ef (Y )|

where Lip(1) indicates the collection of all Lipschitz functions with Lipschitz constant 6 1. Let
N denote the standard normal law. All Wiener chaos random variable are in the domain D1,2
of D, and are orthogonal in L2 (Ω). The so-called Wiener chaos expansion is the fact that any

X ∈ D1,2 can be written as X = EX +P∞q=0 Xq where Xq ∈ Hq. We deﬁne a linear operator L
which is diagonalizable under the Hq’s by saying that Hq is the eigenspace of L with eigenvalue
for any X ∈ Hq, LX = −qX. The kernel of L is the constants. The operator −L−1 is
−q, i.e.
the negative pseudo-inverse of L, so that for any X ∈ Hq, −L−1X = q−1X. Since the variables we
will be dealing with in this article are ﬁnite sums of elements of Hq, the operator −L−1 is easy to
manipulate thereon.
Two key estimates linking total variation distance and the Malliavin calculus are the follow-

ing.

• Let X ∈ D1,2 with E [X] = 0. Then (see [22, Proposition 2.4]),

• Let a sequence X : Xn ∈ Hq, such that EXn = 0 and V ar [Xn] = 1 , and assume Xn converges
proved originally in [26], is known as the fourth moment theorem). Then we have the following
optimal estimate for dT V (X, N ), known as the optimal 4th moment theorem, proved in [22]:
there exist two constant c, C > 0 depending only on the sequence X but not on n, such that

dT V (X, N ) 6 2E(cid:12)(cid:12)1 −(cid:10)DX,−DL−1X(cid:11)H(cid:12)(cid:12) .
to a normal law in distribution, which is equivalent to limn E(cid:2)X 4
n(cid:3)(cid:12)(cid:12)(cid:9) 6 dT V (X, N ) 6 C max(cid:8)E(cid:2)X 4
κ4 (X) := E(cid:2)X 4(cid:3) − 3.

n(cid:3) = 3 (this equivalence,
n(cid:3) − 3,(cid:12)(cid:12)E(cid:2)X 3
n(cid:3)(cid:12)(cid:12)(cid:9) .

c max(cid:8)E(cid:2)X 4

n(cid:3) − 3,(cid:12)(cid:12)E(cid:2)X 3

Given the importance of the centered 4th moment, also known as a 4th cumulant, of a

standardized random variable, we will use the following special notation:

3 Parameter estimation for stationary Gaussian processes

3.1 Notation and basic question

Consider a centered stationary Gaussian process Z = (Zk)k∈Z with covariance
rZ (k) := E(Z0Zk) for every k ∈ Z such that rZ (0) > 0.

For any centered Gaussian sequence Z indexed by Z (stationary or not), it is always possible to
represent the entirely family of Zn’s jointly as Wiener integrals using a corresponding family of
functions fn ∈ H as

Zn = I1 (fn)

9

in the notation of Section 2. In all that follows, we will use this representation.

Fix a polynomial function fq where q is an even integer such that fq possesses the following

decomposition

fq(x) :=

q/2Xk=0

2 , dfq,2k ∈ R with dfq,q = r

where for every k = 1, . . . , q
every i > 0

dfq,2kH2k  x
prZ (0)!
dfq,2kH2k  ZiprZ (0)! =
q/2Xk=0
dfq,2kI2k(cid:16)ε⊗2k
with Zi /prZ (0) = I1(εi). Deﬁne the following partial sum
n−1Xi=0

Qfq,n(Z) :=

fq(Zi)

fq(Zi) =

q/2Xk=0

1
n

q
2

Z (0). Thus from Section 2, we can write for

i

(cid:17)

(5)

(4)

(6)

and

λfq (Z) := E [fq(Z0)] .

We expect that the polynomial variation Qfq,n(Z), as an empirical mean, should converge to λfq (Z).
Our aim in this section is to estimate the parameter λfq (Z) and the speed of convergence of Qfq,n(Z)
to it.

The “quadratic” case q = 2 is of special importance. In this case, the quadratic function f2

will typically be taken as

f2 (x) = x2 = rZ (0) + rZ (0) H2 

x

prZ (0)! ,

and may also be taken as H2 (x) = x2 − 1 when convenient. We will see in Theorem 4 that certain
functionals related to the quadratic case control the estimator’s asymptotics no matter what q is.
We will also provide an optimal treatment in the case q = 2 itself in Section 4.2.

3.2 Consistency

Theorem 1 Suppose that there exists ε > 0 such that for every n > 0

rZ (j)2 6 n1−ε.

n−1Xk=0

Then Qfq,n(Z) is a consistent estimator of λfq (Z), i.e. almost surely as n → ∞,

Qfq,n(Z) −→ λfq (Z).

10

(7)

(8)

Proof. It follows from (5) that

n

Eh(cid:0)Qfq,n(Z) − λfq (Z)(cid:1)2i = E 1
rZ(0) (cid:19)2k
n−1Xi,j=0(cid:18) rZ (i − j)
q/2Xk=1
n 1 + 2
n−1Xj=1(cid:18) rZ (j)
rZ (0)(cid:19)2k
q/2Xk=1

(2k)!
n2

d2
fq,2k

d2
fq,2k

(2k)!

=

(2k)!

d2
fq,2k

(2k)!
n2

fq(Zj) − Efq(Zj)
2 =
q/2Xk=1
n−1Xj=0
n 1 +
rZ(0)(cid:19)2k
(n − j)(cid:18) rZ (j)
q/2Xk=1
n−1Xj=1
rZ(0)(cid:19)2k .
j(cid:18) rZ (j)

n−1Xj=1

d2
fq,2k

2
n

2
n

−

=

=

Now, using (9), (7), (3) and Lemma 36 in the appendix, the convergence (8) is obtained.

n−1Xi,j=0(cid:18)E(ZiZj)
rZ (0) (cid:19)2k

(9)

(10)

(11)

(12)

Remark 2 If Z is ergodic, the convergence (8) is immediate.

3.3 Asymptotic distribution

Consider the following renormalized partial sum

Then, by (5) we can write

where

Ufq,n(Z) = √n(cid:0)Qfq,n(Z) − λfq (Z)(cid:1)

Ufq,n(Z) =

q/2Xk=1

I2k(g2k,n)

g2k,n := dfq,2k

uf2 (Z) := 2Xj∈Z

1
√n

.

ε⊗2k
i

n−1Xi=0
rZ (j)2 < ∞.

The following condition will play an important role in our analysis:

Under this condition, we can pursue the analysis of expression further. Under (12), rZ (j)2 must
converge to 0 as |j| → ∞. Therefore, under (12), for any k, rZ (j)2k is dominated by rZ (j)2 for
large |j|, and the last term in (9) can be estimated as follows. We ﬁrst ﬁx an ε ∈ (0, 1) and write
for any n > 2

1
n

n−1Xj=1

j · rZ(j)2k =

1
n

[εn]−1Xj=1
[εn]−1Xj=1

6

εn
n

j · rZ (j)2k +

j · rZ (j)2k

1
n

n−1Xj=[εn]
nXj=[εn]

rZ (j)2k +

n
n

11

rZ (j)2k 6 ε uf2 (Z) +

rZ (j)2.

∞Xj=[εn]

By Condition (12), with ε ﬁxed, one can choose n so large thatP∞j=[εn] rZ (j)2 < ε. Thus the last

term in (9) can be made arbitrarily small. This immediately implies the following useful result.

Lemma 3 Under Condition (12), for every even q > 2,

ufq (Z) := lim
n→∞

EhU 2

fq,n(Z)i =

q/2Xk=1

d2

fq,2k(2k)!Xj∈Z(cid:18) rZ (j)
rZ(0)(cid:19)2k

< ∞.

The following notation will be convenient.

(13)

(14)

Ffq,n(Z) :=

Ufq,n(Z)

rEhU 2

fq,n(Z)i .

When the expansion (4) deﬁning the polynomial fq has more than one term, we establish the
following general central limit theorem for Ffq,n(Z) with explicit speed of convergence in total
variation.

Theorem 4 Let fq be the function deﬁned in (4), and recall the stationary Gaussian process Z with
covariance function rZ on Z, the partial sum Qfq,n(Z) := 1
i=0 fq(Zi), its renormalized version
Ufq,n(Z) deﬁned in (10), and its standardized version Ffq,n(Z) in (14). Denote N ∼ N (0, 1). Then
there exists a constant Cq(Z) depending on q, fq and rZ (0) such that

nPn−1

Thus Ffq,n(Z) is asymptotically normal as soon as κ4(Ff2,n(Z)) → 0. In addition, for large n,

dT V (cid:0)Ffq,n(Z), N(cid:1) 6 Cq(Z)rqκ4(Ff2,n(Z)) + κ4(Ff2,n(Z)).
f2,n(Z)i(cid:17)2  .
(cid:16)P|j|<n |rZ (j)|4/3(cid:17)3
n(cid:16)EhU 2

f2,n(Z)i(cid:17)2 = O
(cid:16)EhU 2

κ4(Uf2,n(Z))

κ4(Ff2,n(Z)) =

Proof. See Appendix.
The upper bound in the previous theorem does not require normal convergence, and even
fq,n(Z)] be bounded. By

when this convergence holds, it does not require that the variance E[U 2
Lemma 3, this boundedness holds if and only if Condition (12) holds.

In the next corollary, we look at two examples, one under Condition (12) and one when it fails

is an unobservable sequence because it depends on the parameter-dependent sequence rZ, by the

but normality still holds. In the former case, we replace the normalization termrEhU 2
fq,n(Z)iwhich
constant qufq (Z). While this constant also depends on the parameter λfq (Z), it allows one to
N(cid:0)0, ufq (Z)(cid:1), consistent with common methodological practice. This change of normalization
results in an additional term to reﬂect the speed of convergence ofrEhU 2
fq,n(Z)i toqufq (Z).

measure the total variation distance of the data-based estimator Ufq,n(Z) itself to the ﬁxed law

12

Corollary 5 1) If rY (k) ∼ ck− 1

2 ,then

q,2(Z) log(n).

fq,n(Z)i ∼ 4c2d2
EhU 2
and the upper bound on dT V (cid:0)Ffq,n(Z), N(cid:1) from Theorem 4 holds with
κ4(Ff2,n(Z)) = O(cid:0)log−2(n)(cid:1) .
2) Under Condition (12), i.e. ifPj∈Z |rZ (j)|2 < ∞, we have
dT V (cid:0)Ufq,n(Z),N(cid:0)0, ufq (Z)(cid:1)(cid:1)
6 Cq(Z)rqκ4(Ff2,n(Z)) + κ4(Ff2,n(Z)) + 2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)ufq (Z)(cid:12)(cid:12)2 + 2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
6 Cq(Z)vuuts κ4(Uf2,n(Z))
(cid:12)(cid:12)ufq (Z)(cid:12)(cid:12)2 +

κ4(Uf2,n(Z))

1 −

1 −

the expressions in (17) and (18) converges to 0.

ufq (Z)

fq,n(Z)i
EhU 2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
fq,n(Z)i
EhU 2

ufq (Z)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(15)

(16)

(17)

.

(18)

3) Under the additional assumption that rZ is asymptotically of constant sign and monotone,

Proof. The estimate (15) is a direct consequence of (9). Also, by (15) and the second

estimate of Theorem 4 we obtain (16). The result of point (1) is established.

can write

Ufq,n(Z)

Ufq,n(Z)

Next, we prove the estimate (17). We ﬁrst note that since the laws of Ufq,n(Z) and of N

both have densities with respect to Lebesgue’s measure, dT V (cid:16)Ufq,n(Z),qufq (Z)N(cid:17) is identical to
dT V (cid:16)Ufq,n(Z)/qufq (Z), N(cid:17). Next, from [22, Proposition 2.4] (see bullet points in Section 2) we
dT V 
qufq (Z)
6 2E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
qufq (Z)+
1 −*D
,−DL−1 Ufq,n(Z)
E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
fq,n(Z)i
EhU 2
EhU 2
6 2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
By the expression in (9), the ratio EhU 2
consequence of the same fact that EhU 2

+
fq,n(Z)i
fq,n(Z)i /ufq (Z) is in (0, 1). Therefore the ﬁrst estimate in
fq,n(Z)i < ufq (Z). Point (2) is thus fully established.

, N
qufq (Z)
fq,n(Z)i
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

point (2) follows by the main estimate in the proof of Theorem 4. The estimate (18) is an elementary

fq,n(Z)i ,−DL−1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
1 −*D

rEhU 2

rEhU 2

Ufq,n(Z)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

H

Ufq,n(Z)

1 −

ufq (Z)

+ 2

ufq (Z)

H

13

To prove the corollary’s ﬁnal claim in point (3), we ﬁrst note that by Lemma 3, the term

fq,n(Z)i /ufq (Z)(cid:12)(cid:12)(cid:12) tends to 0. Thus we only need to show that under Condition (12) and

the additional monotonicity assumption on rZ , κ4(Uf2,n(Z)) also tends to 0. By the conclusion of
Theorem 4 and the ﬁniteness of uf2 (Z), we have

(cid:12)(cid:12)(cid:12)1 − EhU 2

Next, we borrow from [20, Proposition 1] that, under the additional assumptions on rZ in the last
statement of the theorem, and using the ﬁniteness of uf2 (Z),

(19)

κ4(Uf2,n(Z)) = On−1X|j|<n
K4 (n) = On−1/3n−1/2X|j|<n
|rZ(j)|3/2
6 4n3/2 1
2n X|j|<n

|rZ (j)|4/3
3 =: K4 (n) .
4/3 .
|rZ (j)|3/2
2
|rZ(j)|2

3/2

n−1/2X|j|<n

From Jensen’s inequality and Lemma 3 we get

2

6 √2uf2 (Z) < ∞.

Thus by (19), κ4(Uf2,n(Z)) = O(cid:0)n−1/3(cid:1), which ﬁnishes the proof of the corollary.

The assumptions of Corollary 5 are very weak, given a memory length shorter than that
of fractional Gaussian noise with Hurst parameter H = 5/8. We state this formally in the next
Corollary, while leaving the question of how to rid oneself of the condition “H < 5/8” to Section
5. In fact, the computations outlined in Section 5, which are based on the convergence speeds (20)
and (21) identiﬁed in Section 3.4.1 which immediately follows, are suﬃcient to obtain this corollary,
whose simple proof we thus omit. Note however that the corollary’s result is not necessarily sharp;
we will see in Section 4.2 that it is not sharp for q = 2.

Corollary 6 Under the notation of Theorem 4, assume that for some H < 5/8,

rZ (k) 6 ck2H−2.

Then Condition (12) holds and for some constant C depending only on q and rZ (0) ,

dT V (cid:0)Ufq,n(Z),N(cid:0)0, ufq (Z)(cid:1)(cid:1) 6 Cn−1/4.

Remark 7 In most cases where Condition (12) fails, the series’ divergence occurs so fast that
Ufq,n(Z)’s asymptotics are not normal. Under certain special circumstances, namely a slowly mod-
ulated (2H − 2)-self-similarity assumption on rZ , classical tools such as in [10] can be used to show
that Ufq,n(Z) tends to a so-called (scaled) Rosenblatt law G(H)
∞ . A now classical result of Davydov
and Martinova [9] was revived in recent years in [5, 20] to estimate total-variation distances to G(H)
∞ .
This can be achieved in our context as well, though for the sake of conciseness, we omit this study,
only stating two basic results here, whose proofs would proceed as in [20] and [5] respectively.

14

1. Assume that for some H ∈ (3/4, 1) and some β > 0, asymptotically

(1 + o (1)) log−β (|k|)|k|2H−2

6 |rZ (k)| /rZ (0) 6 (1 + o (1)) logβ (|k|)|k|2H−2 ,

then for some constant C depending on r and H,

dW

Uf2,n(Z)

2P|k|>n rZ(k)2 ,

4H − 3

2Γ(2 − 2H) cos(cid:16) (2−2H)π

2

1

2vuut

∞  6
(cid:17) G(H)

C

√log n

.

2. If β = 0, then f2 can be replaced above by fq for any even q, and 3/4 can be replaced by

1 − 1/(2q), and √log n by nH−1+1/(2q).
The law of G(H)

∞ can be represented under a standard white noise measure W on C as
G(H)

ei(x+y) ei(x+y) − 1

i(x + y) |xy|1/2−H W (dx)W (dy).

∞ =Z ZR2

3.4 Examples

3.4.1 General considerations

For any degree-q polynomial fq as given in (4), we saw that under the assumptions of Theorem 1
and Theorem 4, Qfq,n(Z) serves as a consistent and asymptotically normal generalized method of
moments estimator λfq (Z) := E [fq(Z0)], or indeed for any parameter which can be extracted from
this quantity.

Condition (12) should be sought in order to invoke the explicit speed of convergence result
of the second part of Corollary 5. This assumption is generic for any stationary process whose
memory length is bounded above strictly by that of the so-called fractional Gaussian noise with
Hurst parameter H = 3/4. The articles [20] and [22] can be consulted for precise statements of
what this means in general scales and in the fractional Brownian scale. Section 5 can be consulted
for a simple transformation of the data to ensure that Condition (12) holds for any long-memory
stationary Gaussian sequence with an asymptotically power-law autocorrelation decay.

Under Condition (12), Part (2) of Corollary 5 shows that the speed of convergence in total
variation is determined by the choice of q via the leading constant Cq (Z) and the speed of conver-

gence of the variance term EhU 2

variance convergence, i.e. the last term in (18), is given by the tail expression

fq,n(Z)i. Speciﬁcally, by Lemma 3, the term corresponding to this
q/2Xk=1

rZ (0)(cid:19)2k
fq,2k (Z) (2k)! X|j|>n(cid:18) rZ(j)

(20)

d2

.

2

ufq (Z)

The other term in (18), which corresponds to the core normal convergence from Theorem 4, asymp-
totically equivalent to

(κ4(Uf2,n(Z)))1/4 ;

(21)

Cq(Z)

qufq (Z)

15

this has a speed which is determined by the fourth root of the estimator’s fourth cumulant no matter
what q is, and the leading constant Cq (Z) can be computed via the explicit formulas (66), (67),
and (68) in the proof of Theorem 4.

There may be a trade-oﬀ between choosing a large q to eﬀect the size of the coeﬃcients d2

fq,2k
and a small q to control the value of Cq (Z). The constants in these expressions are suﬃciently
complex to make it diﬃcult to discern a general rule on how to choose q, particularly since the

speed of convergence of EhU 2

fq,n(Z)i depends heavily on the entire sequence rZ . But this can

be determined on a case-by-case basis since all the constants can be computed explicitly, as the
examples in the subsections that follow show.

Before working out those examples, we ﬁnish this section with an attempt to explain in
qualitative terms where the trade-oﬀ may come from. For the sake of argument, let us compare the
constants for q = 2 with those for a large q.
shows that C2 (Z) = 2√2rZ (0), while the variance-convergence term in (20) easily computes to

For q = 2, the constant C2 (Z) is of moderate size:

inspection of the proof of Theorem 4

2

uf2(Z) X|j|>n

rZ(j)2 = P|j|>n rZ(j)2
Pj∈Z rZ (j)2 .

One may choose a high-degree polynomial fq such that the constant d2

fq,2 (Z) may be much
smaller than C2 (Z); in this case, the dominant term in (20), which is for k = 1, has the same
behavior in terms of n as for q = 2, but would be minimized because of the presence of the small
multiplicative factor d2
fq,2k (Z) for k > 2 were much larger, this
would have little eﬀect for large n since they would be multiplicative of the asymptotically negligible

fq,2 (Z). If the other constants d2

tails P|j|>n rZ(j)2k in (20). In other words, for large q, the speed of convergence in (20) can be
controlled by choosing fq with a small contribution to the term corresponding to H2 in the Hermite
polynomial decomposition (4). However, this must be traded oﬀ against the size of the constant
Cq (Z). All the terms in the expression Cq (Z) are additive and grow quickly as q increases; the term
of highest order is proportional to q3/2 (2q − 4)!. Such rapid growth does not seem to be the case
for d2
fq,2 (Z), as illustrated in the next two typical examples, where access to the variance parameter
E(cid:0)Z 2
Let q ∈ N∗ be an even integer. Then the qth Hermite polynomial Hq can be written as in (4).
Indeed, it follows from the fact that for q even, Hq(x) =P q
q!(−1)k
k!(q−2k)!2k xq−2k. Then we can write,

0(cid:1) = rZ (0) itself is essentially immediate.

3.4.2 Hermite variation

2
k=0

Hq(x) = EHq(Z0) +

q/2Xk=1

prZ(0)!
dHq,2k (Z) H2k  x

16

where for any k ∈ {1, . . . , q

2 − 1}

q
2

dHq,q−2k(Z) = (−1)k(cid:16)r
(−1)k−1(cid:16)r
(−1)1(cid:16)r

. . .

+

+

+

q
2

Z (0) − r

q

2−1
Z

q
2

Z (0) − r

Z (0) − r

q

2−k
Z

q

2−2
Z

q−2k

(0)(cid:17) aq
q−4 . . . aq−2k+2
q−2aq−2
(0)(cid:17) aq
q−4aq−4
q−6 . . . aq−2k+2
(0)(cid:17) aq

q−2k

q−2k

and dHq,q(Z) = r

Z (0), where for every p even, the constants

q
2

ap
p−2k =

p!(−1)k

k!(p − 2k)!2k

k = 0, . . . , p/2

are the ones which satisfy

Consequently, the Hermite variation

Hp(x) =

p/2Xk=0

ap
p−2kxp−2k.

QHq,n(Z) :=

1
n

n−1Xk=0

Hq(Zk)

satisﬁes the results given in Sections 3.2 and 3.3. Moreover the parameter λHq (Z) has the following
explicit expression

λHq (Z) = E [Hq(Z0)] =

=

=

q

q!
2q/2

( q

q

0

q!

2−k

(cid:17)

k!(q − 2k)!2k E(cid:16)Z q−2k
q!(−1)k

2Xk=0
2Xk=0
(−1)k
2 − k)!(cid:2)E(cid:0)Z 2
0(cid:1)(cid:3) q
k!( q
2 )!2q/2(cid:0)E(cid:0)Z 2
0(cid:1) − 1(cid:1)q/2
0(cid:1) = rZ (0). Because of the simple form of (22) as a function

(22)

.

Thus the results of the previous sections provide explicit means for computing total varia-
tion speeds of convergence in a generalized method of moments based on Hermite polynomials for

estimating the variance parameter E(cid:0)Z 2

of rZ (0), for any sequence satisfying Condition (12), one can immediately test the hypothesis of
whether rZ (0) equals a speciﬁc value σ2, using Corollary 5 to account precisely for the error term
due to non-inﬁnite sample size. Since the corollary provides the error in total variation distance,
this error is uniform over σ2 by deﬁnition.

17

3.4.3 Power variation

Let q ∈ N∗ be an even integer. Let cq,2k = 1
monomial φq(x) := xq expanded in the basis of Hermite polynomials :

−∞

e−x2/2
√2π

xqH2k(x) dx be the coeﬃcients of the

(2k)!R ∞
q/2Xk=0

q!

xq =

cq,2kH2k(x).

2q/2−k (q/2 − k)! (2k)!

.

It is known that

cq,2k =

Thus, by relying directly on the results we just saw in the case of Hermite polynomials, the poly-
nomial function φq can be written as in (4). As consequence, the power variation

Qφq,n(Z) =

1
n

(Zi)q.

n−1Xi=0

satisﬁes the results given in Sections 3.2 and 3.3. In this case, the parameter λφq (Z) has the following
explicit expression

λφq (Z) = E [(Z0)q] =

.

(23)

( q

q!

2 )!2q/2(cid:2)E(cid:0)Z 2

0(cid:1)(cid:3)q/2

4 Parameter estimation for non-stationary Gaussian process

In practice, it is often the case that the data comes from a sequence which has visibly not yet
reached a stationary regime. This is a typical situation for the solution of a stochastic system which
initiates from a point mass rather than the system’s stationary distribution; we will see examples
of this in Sections 6 and 7. The rate at which stationarity is reached heavily aﬀects other rates
of convergence, including the total variation speeds in the central limit theorem. To illustrate this
phenomenon more broadly than in the two aforementioned sections, in this section we consider a
general class of models which can be written as the sum of a stationary model and a non-stationary
nuisance term which vanishes asymptotically.

4.1 General case

For a polynomial fq of even degree q, and a random sequence X, recall the polynomial variation
notation introduced in Section 3.1:

Qfq,n(X) :=

1
n

n−1Xi=0

fq(Xi).

Let (Zk)k∈Z be a centered stationary Gaussian process and let (Yk)k∈Z be a process such that the
following condition holds: there exist p0 ∈ N and a constant γ > 0 such that for every p > p0 and
for all n ∈ N,
(24)

(cid:13)(cid:13)Qfq,n(Z + Y ) − Qfq,n(Z)(cid:13)(cid:13)Lp(Ω) = O(cid:0)n−γ(cid:1) .

18

Combining (24), Lemma 36 in the Appendix, and Theorem 1 we get the following result.

Theorem 8 Assume that the conditions (24) and (7) hold. Then

Qfq,n(Z + Y ) −→ λfq (Z)

almost surely as n → ∞.

In Corollary 5, we handled a discrepancy at the level of deterministic normalizing constants,
while retaining statements with the total variation distance. In this section, our discrepancy comes
at a slightly higher price because it is stochastic. We use instead the Wasserstein distance dW , in
order to rely on the following elementary lemma whose proof is in the Appendix.

Lemma 9 Let Y and Z be random variables deﬁned on the same probability space. Then

dW (Y + Z, N ) 6 dW (Z, N ) + kY kL1(Ω) .

Another lemma, proved for instance in [24, Theorem 5.1.3], relates the Wasserstein distance

to a connection between Stein’s method and the Malliavin calculus.

Lemma 10 If F has mean 0, variance 1, and a square-integrable Malliavin derivative, then

dW (F, N ) 6r 2

π

E(cid:2)(cid:12)(cid:12)1 −(cid:10)DF,−DL−1F(cid:11)(cid:12)(cid:12)(cid:3)

By combining these two lemmas (the second one applies because variables with ﬁnite chaos
expansions are inﬁnitely Malliavin-diﬀerentiable with ﬁnite moments of all orders) and the proof of
Theorem 4, by (24) we immediately obtain the following upper bounds.

Theorem 11 Under hypothesis (24) and the assumptions of Theorem 4, for some constant C de-
pending on the relation in (24),

Cq (Z)√2

√π rqκ4(Ff2,n(Z)) + κ4(Ff2,n(Z)).

1

2−γ

n

Ufq,n(Z + Y )

fq,n(Z)i +

dW
fq,n(Z)i , N 6 C
rEhU 2
rEhU 2
In addition, under Condition (12), i.e. ifPj∈Z |rZ (j)|2 < ∞,
√π vuuts κ4(Uf2,n(Z))
, N 6 C
dW
Cq (Z)√2
qufq (Z)
fq,n(Z)i
EhU 2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
π(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
+r 8

qufq (Z)

Ufq,n(Z + Y )

ufq (Z)

1

2−γ

n

1 −

.

+

19

ufq (Z)2 +

κ4(Uf2,n(Z))

ufq (Z)2

(25)

4.2 Quadratic case

In this subsection we assume that q = 2. In this special case, consistent with the notation in (6),
without loss of generality up to deterministic shifting and scaling, the only relevant polynomial of
interest is f2 (x) = x2. Thus the question introduced in Section 3.1 is to estimate the variance

rZ (0) = Eh(Z0)2i where Z is our stationary Gaussian process. Using the notation introduced in

that section, we thus have the following expression for our normalized partial sum

Uf2,n(Z) =

rZ(0)
√n

n−1Xk=0

H2  ZkprZ(0)! = I2  rZ (0)

√n

k ! ,

ε⊗2

n−1Xk=0

where again εk is deﬁned by Zk /prZ (0) = I1 (εk). Using the notation in Section 3.3, the stan-

dardized version of Uf2,n(Z) is thus

Recall the 4th cumulant κ4 (Ff2,n(Z)) = E(cid:2)Ff2,n(Z)4(cid:3) − 3, and deﬁne the third cumulant

Uf2,n(Z)

Ff2,n (Z) =

rEhU 2

f2,n(Z)i .
κ3 (Ff2,n(Z)) := E(cid:2)Ff2,n(Z)3(cid:3) .

dT V (Ff2,n(Z), N ) ≍ |κ3 (Ff2,n(Z))| =(cid:12)(cid:12)E(cid:0)(Ff2,n(Z))3(cid:1)(cid:12)(cid:12) ,
(cid:12)(cid:12)E(cid:0)(Ff2,n(Z))3(cid:1)(cid:12)(cid:12) ≍ (cid:16)P|k|<n |rZ (k)|3/2(cid:17)2
(cid:16)P|k|<n |rZ (k)|2(cid:17)3/2 √n

.

20

We will apply the sharp asymptotics established in [22] (see bullet points in Section 2), by which
a sequence of variance-one random variables Fn in a ﬁxed Wiener chaos which converges in law to
the normal has total variation distance to the normal commensurate with the maximum of its third
and fourth cumulant. We will also apply an explicit version of this theorem, due to [20], tailored
to quadratic variations of stationary Gaussian processes. For positive-valued sequences a and b, we
will use the commensurability notation

an ≍ bn ⇐⇒ 0 < c := inf

n

an
bn

6 sup

n

an
bn

=: C < ∞

where the extrema may be over all positive integers, or all integers exceeding a value n0. Our ﬁrst
result is the following.

Proposition 12 (1) With f2 (x) = x2, assume that κ4(Ff2,n(Z)) −→ 0. Then
dT V (Ff2,n(Z), N ) ≍ max{κ4 (Ff2,n(Z)) ,|κ3 (Ff2,n(Z))|} .

(26)
(2) If rZ is asymptotically of constant sign and monotone, then κ4(Ff2,n(Z)) −→ 0 if and

only if κ3(Ff2,n(Z)) −→ 0, and in this case,

(27)

and moreover,

Proof. The result (26) in Point (1) is a direct consequence of the main result in [22] (see

also [4]). The statements in point (2) come directly from [20, Theorem 3].

The methods used to prove Corollary 5 and Theorem 11 immediately lead from the upper

bound statements in Proposition 12 to the following corollary.

Corollary 13 If the hypothesis (24) holds, under the assumptions in part (2) of Proposition 12, for
some constant C > 0,

In addition, if Condition (12) holds, i.e. Pj∈Z |rZ (j)|2 < ∞, then

dW

1

n

2−γ

Uf2,n(Z + Y )

 .
f2,n(Z)i +(cid:12)(cid:12)E(cid:0)(Ff2,n(Z))3(cid:1)(cid:12)(cid:12)

f2,n(Z)i , N 6 C
rEhU 2
rEhU 2
, N!
dW  Uf2,n(Z + Y )
puf2(Z)
+(cid:12)(cid:12)E(cid:0)(Ff2,n(Z))3(cid:1)(cid:12)(cid:12)! + CP|j|>n |rZ (j)|2
6 C  n
puf2(Z)

uf2(Z)

2−γ

1

.

(28)

Unfortunately, these techniques say nothing about how to obtain lower bounds when one

adds discrepancies corresponding to the speed of convergence of the series Pj |rZ (j)|2, and to a

non-stationary term. We now investigate some slight strengthening of Conditions (12) and (24)
which allow for such lower-bound statements, starting with some elementary considerations.

From (27) and the remainder of Point (2) in Proposition 12, there exists a constant c1 (Z)

depending only on the law of Z such that

6 dT V (Ff2,n(Z), N ) 6 C1 (Z) (cid:16)P|k|<n |rZ (k)|3/2(cid:17)2
(cid:16)P|k|<n |rZ (k)|2(cid:17)3/2 √n

c1 (Z) (cid:16)P|k|<n |rZ (k)|3/2(cid:17)2
(cid:16)P|k|<n |rZ (k)|2(cid:17)3/2 √n
Now assume merely that (12) holds: Pj |rZ(j)|2 converges. Thus, for some constant c′2 (Z) depend-
In cases whereP|rZ (k)|3/2 diverges, we evidently get a larger lower bound than (30), which

would make the rest of the analysis easier. To keep track of multiplicative constants as best we can,
we deﬁne

ing only on the law of Z,

dT V (Ff2,n(Z), N ) >

c′2 (Z)
√n

(29)

(30)

.

.

L (Z) := lim

,

(31)

n→∞(cid:16)P|k|<n |rZ (k)|3/2(cid:17)2
(cid:16)P|k|<n |rZ (k)|2(cid:17)3/2

21

which exists and is positive under condition (12), with the understanding that when L (Z) is +∞,
one can and should replace it by an arbitrarily large constant for n large enough. We will not
comment on the case of diverging L further. The interested reader can work out for herself how
much better the ﬁnal lower bound results would be in this case.

Thus in (30), we may take c′2 (Z) = c1 (Z) L (Z) where c1 (Z) is the lower bound constant
from (27), i.e. as deﬁned in (29). Finally, we relate (30) to the Wasserstein distance through the
following lemma, proved in the appendix.

Lemma 14 Lower bound statements in Proposition 12 hold for dW with an additional factor 2.

Thus, under Condition (12), by the previous development and Lemma 14, with

we ﬁnally get

c2 (Z) := 2c1 (Z) L (Z) ,

dW (Ff2,n(Z), N ) >

c2 (Z)
√n

,

(32)

(33)

and we are ready to state and prove our lower bound theorem in the quadratic case under a
sharpening of condition (24) and a quantitative version of Condition (12).

Theorem 15 Assume the following two conditions.

• Let (Yk)k∈Z be a process such that for all n ∈ N, for some ﬁnite constant c3 > 0,

kQf2,n(Z + Y ) − Qf2,n(Z)kL1(Ω)

6

• Condition (12) holds and for some ﬁnite constant c4 > 0

c3puf2 (Z)

n

.

(34)

(cid:12)(cid:12)uf2 (Z) − E(cid:2)U 2

f2,n(Z)(cid:3)(cid:12)(cid:12) 6

2 c4 uf2 (Z)

√n

.

(35)

With the positive constants c1 (Z) , C1 (Z), and L (Z) deﬁned via (29), (31), and c2 =
2c1 (Z) L (Z) (32), which exist by Proposition 12, if c4 < c2 − c3, then for any ε > 0 such that
c2 − (1 + ε) (c3 + c4) > 0, there exists n0 large enough that for all n > n0,

c1 (Z) L (Z) − (1 + ε) (c3 + c4)

√n

6 dW  Uf2,n (Y + Z)
puf2 (Z)

, N! 6

C1 (Z) L (Z) + c3 + c4

√n

.

Proof. By using Lemma 9, the lower bound (33) implies

c2√n

6 dW

Uf2,n (Y + Z)

rEhUf2,n (Z)2i , N +

1

rEhUf2,n (Z)2i E [|Uf2,n (Y + Z) − Uf2,n (Z)|] .

22

Now using the trivial consequence of Lemma 9 by which, for any random variable Z and constants
a, b, dW (aZ, N ) 6 dW (bZ, N ) + |a − b| kZkL1(Ω), we get

c3√n

.

Uf2,n (Y + Z)

rEhUf2,n (Z)2i , N + puf2 (Z)
rEhUf2,n (Z)2i
, N!

Then by assumption (34),

c2√n

6 dW
6 dW  Uf2,n (Y + Z)
puf2 (Z)
puf2 (Z) −

1

c2√n

+(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1

puf2 (Z) −

1

1

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
rEhUf2,n (Z)2i
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

rEhUf2,n (Z)2i
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

rEhU (Z)2i
rEhU (Z)2i
rEhU (Z)2i

√n

1

1

23

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
6 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
6 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1

√n

pu (Z) −
pu (Z) −
pu (Z) −

1

Regarding the middle term in the right-hand side above, we claim the following: for any ε > 0 and
for n large enough,

E [|Uf2,n (Z + Y )|] + puf2 (Z)
rEhUf2,n (Z)2i

c3√n

.

(36)

E [|Uf2,n (Z + Y )|] 6

c4 (1 + ε)

√n

.

(37)

Let us prove this claim. To lighten the notation, we drop the subscripts. By assumption (34), we
have

E [|U (Z + Y )|]

(E [|Q (Z) − λ (Z)|] + E [|Q (Z + Y ) − Q (Z)|])

 rEhU (Z)2i +

√n ! .
c3pu (Z)

Since EhU (Z)2i converges to u (Z), and after some simple algebra, for n large enough we get
(1 + ε)pu (Z)

1

1

pu (Z) −

rEhU (Z)2i

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

E [|U (Z + Y )|] 6 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

6

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1

1

1 + ε

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
pu (Z) −
rEhU (Z)2i
2u (Z)(cid:12)(cid:12)(cid:12)u (Z) − EhU (Z)2i(cid:12)(cid:12)(cid:12) .
, N! +

(c3 + c4) (1 + ε)

√n

,

Thus (37) follows immediately from assumption (35). Combining (37) with (36), and again using

the convergence of EhUf2,n (Z)2i to uf2 (Z), we ﬁnally obtain that for any ε > 0 and for n large

enough

c2√n

6 dW  Uf2,n (Y + Z)
puf2 (Z)

Since, c4 + c4 < c2, ε > 0 exists such that c2 − (1 + ε) (c3 + c4) > 0, which ﬁnishes the lower bound
of the theorem.
The upper bound is easier to prove, and follows from the same estimates as for the lower

bound. Details are omitted.

Remark 16 The non-central limit theorem in Remark 7 part (1) also holds if Z is replaced by Z +Y
under assumption (24) if γ > 1/2 ; and similarly for part (2) if γ > H − (q − 1) /2q. These results’
proofs, which are omitted, follow the results in Remark 7 and from the tools in this section and those
in [20] and [5].

4.3 Towards a Berry-Esséen theorem for parameter estimators

In the previous two sections, we saw how to prove asymptotically normality for the empirical
sums of the form Ufq,n (Z) (or Ufq,n (Y + Z) where Y is a non-stationary correction process), with
convergence speed theorems in total variation and Wasserstein distances. These apply to parameter
estimation if the quantity one is after is the expected value λfq (Z) := E [fq (Z0)]. In this section
we evaluate the same question if the parameter one seeks is implicit in λfq (Z).

Thus assume that one is looking for the unknown parameter θ > 0 and that there is a

homeomorphism g such that

λfq (Z) = g−1(θ) := θ∗.

As stated, so far, for a degree-q polynomial fq we have studied the “estimator”

bθn = Qfq,n(Z) =

1
n

n−1Xi=0

fq(Zi).

24

We have proved the following in Section 3 (see for instance Theorems 1 and 4, Corollaries 5 and 6)

√n

: bθn −→ θ∗ almost surely and
dW
fq,n(Z)i(cid:16)bθn − θ∗(cid:17) ,N (0, 1) 6 ϕ(n)
rEhU 2
Ufq,n(Z) = √n(cid:0)Qfq,n(Z) − λfq (Z)(cid:1) =bθn − θ∗.

where

and where ϕ (n) tends to 0 as n → ∞ at various speeds which can be determined thanks to the
precise statements in Corollary 5, for instance ϕ (n) = 1/√n in Corollary 6, which is the classical
Berry-Esséen speed.

By using the relation between θ and λ, we naturally deﬁne the estimator of θ by

This is a consistent estimator by Theorem 1 since g is continuous by assumption: ˇθn −→ θ almost
surely. Now assume g is a diﬀeomorphism. By the mean-value theorem we can write

ˇθn := g(cid:16)bθn(cid:17) .

where ξn is a random variable which belongs to [|bθn, θ∗|]. As a consequence

√n

√n

(cid:0)ˇθn − θ(cid:1) = g′(ξn)(cid:16)bθn − θ∗(cid:17)
fq,n(Z)i(cid:0)ˇθn − θ(cid:1) ,N (0, 1)
dW
g′(θ∗)rEhU 2
fq,n(Z)i(cid:16)bθn − θ∗(cid:17)
6 dW
fq,n(Z)i(cid:0)ˇθn − θ(cid:1) ,
g′(θ∗)rEhU 2
rEhU 2
fq,n(Z)i(cid:16)bθn − θ∗(cid:17) ,N (0, 1)
+dW
rEhU 2

√n

√n

The last term above is controlled by ϕ (n) as mentioned. Now assume that g is twice continuously
diﬀerentiable. Then by the mean-value theorem again, for ζn some random variable which belongs

25

√n

√n

6

=

g′(θ∗)rEhU 2

fq,n(Z)i(cid:16)bθn − θ∗(cid:17)
rEhU 2

to [|ξn, θ∗|] ⊂ [|bθn, θ∗|], the other term above is controlled as
dW
fq,n(Z)i(cid:0)ˇθn − θ(cid:1) ,
fq,n(Z)i E(cid:12)(cid:12)(cid:12)√n(cid:16)bθn − θ∗(cid:17)(cid:0)g′(ξn) − g′(θ∗)(cid:1)(cid:12)(cid:12)(cid:12)
g′(θ∗)rEhU 2
fq,n(Z)i E(cid:12)(cid:12)(cid:12)√n(cid:16)bθn − θ∗(cid:17) g′′(ζn) (ξn − θ∗)(cid:12)(cid:12)(cid:12)
g′(θ∗)rEhU 2
fq,n(Z)i E(cid:12)(cid:12)(cid:12)(cid:12)
g′(θ∗)rEhU 2
g′(θ∗)rEhU 2
fq,n(Z)i
√n(cid:20)E(cid:18)(cid:16)bθn − θ∗(cid:17)2p(cid:19)(cid:21)1/p

√n(cid:16)bθn − θ∗(cid:17)2
√n(cid:20)E(cid:18)(cid:16)bθn − θ∗(cid:17)2p(cid:19)(cid:21)1/phE(cid:16)g′′(ζn)p′(cid:17)i1/p′
6 cp√nE(cid:18)(cid:16)bθn − θ∗(cid:17)2(cid:19) = O(

g′′(ζn)(cid:12)(cid:12)(cid:12)(cid:12)

where p and p′ are conjugate reals greater than 1, i.e. 1/p + 1/p′ = 1. Moreover

1
√n

).

6

6

1

1

1

1

Therefore the only question left to transfer the quantitative results of Section 3 to ˇθn is whether
one can prove, for instance, that g′′(ζn) has a bounded moment of order greater than 1. We will
see several examples in Section 6 where this is easy to check. More generally, we advocate checking
this on a case-by-case basis when the function g can be identiﬁed. In the meantime, we summarize
this discussion with the following general principle, which follows from the above discussion.

Theorem 17 Consider the setup from Corollary 5, in which bθn = Qfq,n(Z) := 1

i=0 fq(Zi) and
θ∗ = E [fq (Z0)] , with ϕ (n) an upper bound for the expression in (18) which converges to 0. Assume
that there exists a twice-diﬀerentiable invertible function g and a value θ such that

nPn−1

g−1(θ) := θ∗.

If g′′(cid:16)bθn(cid:17) has a moment of order greater than 1 which is bounded in n, the expression

ˇθn := g(cid:16)bθn(cid:17)

26

is a strongly consistent and asymptotically normal estimator of θ and

dW

√n

g′(θ∗)rEhU 2

fq,n(Z)i(cid:0)ˇθn − θ(cid:1) ,N (0, 1) 6 C

1
√n

+ ϕ (n)

where ϕ (n) is the speed of convergence in Corollary 5.

5 Improving the rate convergence

Consider our usual centered stationary Gaussian sequence Z with autocorrelation function rZ , and
deﬁne :

Z (0)

k = Zk,

k ∈ Z

and for every p > 1

k = Z (p−1)
Z (p)

k+1 − Z (p−1)

k

, k ∈ Z.

It is well known, and easily veriﬁed, that if k 7→ rZ (k) decays like k−α for α > 0 as k → ∞, then
the pth-order ﬁnite diﬀerence process Z (p) deﬁned above is also a centered and stationary Gaussian
sequence, with an autocorrelation function which decays like k−α−2p. On the other hand, the reader
will easily check, or consult the computations in Section 6.5 of [4], which are also summarized in
Proposition 4.2 part (3) in [22], and extended in [20] to cover the case at hand here, that as soon
as −α − 2p < −3/4, we have

κ4(Uf2,n(Z (p))) 6 c (Z) k−1

as k → ∞ for some constant c (Z) depending only on the law of Z. The condition −α − 2p < −3/4
is satisﬁed for any α > 0, as soon as the integer p > 1, evidently. For non-integer p > 0, we may
deﬁne fractional ﬁnite-diﬀerences Z (p) using the standard formal power series expansion, in which
case the condition on p becomes

Thus by applying Theorem 4 and part (3) of Corollary 5, we immediately conclude the following,
which we state for integer p since the case of non-integer p is arguably of lesser practical use.

p > 3/8 − α.

(38)

Theorem 18 Let q be an even positive integer. Assume that Z, rZ , fq, Ufq,n(Z) and Ffq,n(Z) are
as in Theorem 4. Assume that kαrZ (k) converges to a constant for some α > 0 as k → ∞. Then
for every integer p > 1, there exists C depending on p, q and rZ (p) (0) such that

In particular, Z (p) satisﬁes condition (12) and Ufq,n((Z (p))) is asymptotically normal.

dT V (cid:16)Ffq,n((Z (p))), N(cid:17) 6 Cn−1/4.

For instance, if Z has autocorrelation asymptotics which are equivalent to those of a frac-
tional Gaussian noise with Hurst parameter H, then α = 2− 2H > 0 and the above statements hold
for all H ∈ (0, 1).

27

To apply the remainder of Corollary 5, we note that, by the calculation in Section 3.4.1,
under the assumption that rZ (k) ∼ ck−α, since Z (p) satisﬁes condition (12), the control on the
variance discrepancy term given in (20) is of the same order as:

X|j|>n

rZ (p)(j)2 ∼ X|j|>n

j−2α−4p ≍ n−2α−4p+1 = o(cid:0)n−3(cid:1) .

This is negligible compared to n−1/4. Thus we immediately get the following by part (2) of Corollary
5.

Corollary 19 Under the notation and conditions of Theorem 18, for some constant cp,q(Z) de-
pending only on p, q, and the law of Z,

dT V (cid:16)Ufq,n(Z (p)),N(cid:16)0, ufq (Z (p))(cid:17)(cid:17) 6 cp,q(Z)n−1/4.

This holds for instance if Z is as in the last statement in Theorem 18.

For the same reason as in the case of p = 0, there is no reason to believe that the speed
n−1/4 is sharp, but when q = 2, a sharp result can be established. The results of Section 4.2 imply
the next sharp Berry-Esséen-type theorem.

Theorem 20 Under all the assumptions of Theorem 18,

dW(cid:16)Uf2,n(Z (p)),N(cid:16)0, uf2(Z (p))(cid:17)(cid:17) ≍

1
√n

.

Proof. We brieﬂy sketch the ideas in the proof. The details are bookkeeping given what
has already been used to prove Corollary 5 and Theorem 15. The statement in Theorem 20 holds
with U replaced by the normalized version F , by directly checking all the assumptions of Theorem
15; to get the result for U instead of F , an argument of the same type as in the proof of Corollary
5 suﬃces, which works just as we saw in the above justiﬁcation of Corollary 19, because one easily

shows that the variance discrepancy term (20) is still o(cid:0)n−3(cid:1).

Remark 21 Improving rates of convergence by using ﬁnite diﬀerences also works for the non-
stationary processes of Section (4). The reason is simply that, since the process Y is a small
perturbation of Y +Z in L1 (Ω) under assumptions such as (24), these assumptions do not deteriorate
under a ﬁnite diﬀerence of ﬁxed order p, up to the possible inclusion of multiplicative constants
depending only on p, q. All details are omitted for conciseness.

6 Applications to Ornstein-Uhlenbeck processes : the one-parameter

case

6.1 Fractional Ornstein-Uhlenbeck process: general case

Consider an Ornstein-Uhlenbeck process X = {Xt, t > 0} driven by a fractional Brownian motion

t , t > 0(cid:9) of Hurst index H ∈ (0, 1). That is, X is the solution of the following linear

BH = (cid:8)BH

28

stochastic diﬀerential equation

X0 = 0;

dXt = −θXtdt + dBH
t ,

t > 0,

(39)

whereas θ > 0 is considered as unknown parameter. The solution X of (39) has the following explicit
expression:

Thus, we can write

where

Xt =Z t

0

e−θ(t−s)dBH
s .

Xt = Z θ

t − e−θtZ θ

0

Z θ

t =Z t

−∞

e−θ(t−s)dBH
s .

(40)

(41)

(42)

Moreover, it is known that Z θ is an ergodic stationary Gaussian process.
It is the stationary
solution of equation (39). We are thus in the setup of Section 4 with Z = Z θ and Y = −e−θtZ θ
0 .
Consequently, to apply the results of that section, we need only check that Condition 24 holds. It
does, according to the following result.

Lemma 22 Let X and Z θ be the processes given in (39) and (42) respectively. Then for every
p > 1 and for all n ∈ N,

Proof. By (41) and (4) we have

Combining this and the fact that

(cid:13)(cid:13)(cid:13)Qfq,n(X) − Qfq,n(Z θ)(cid:13)(cid:13)(cid:13)Lp(Ω)
H2k  XiprZ (0)! − H2k  Z θ

6

1
n

q/2Xk=0

(cid:13)(cid:13)(cid:13)Qfq,n(X) − Qfq,n(Z θ)(cid:13)(cid:13)(cid:13)Lp(Ω)
dfq,2k(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

n−1Xi=0
iprZ (0)! =
(cid:13)(cid:13)(cid:13)Qfq,n(X) − Qfq,n(Z θ)(cid:13)(cid:13)(cid:13)Lp(Ω)

(2k)!(−1)l
l!(2k − 2l)!2l

kXl=0

= O(cid:0)n−1(cid:1) .
H2k  XiprZ(0)! − H2k  Z θ
2k−2lXj=1

(−1)j(2k−2l
j
rk−l
Z (0)

)e−θij

(Z θ

iprZ (0)!(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Lp(Ω)

.

0 )j(Z θ

i )2k−2l−j.

6 c(θ, fq)

e−iθ.

1
n

n−1Xi=0

we deduce that there exist a constant c(θ, fq) depending on fq and θ such that

Thus the lemma is obtained.

As a consequence, by using Z θ ergodic, Lemma 22 and Theorem 8, we conclude that

Qfq,n(X) −→ λfq (Z θ)

29

almost surely as n → ∞. Moreover, by the Gaussian property of Z θ and Lemma asymptotic 38 in
the Appendix, we can write

λfq (Z θ) := µfq (θ)

where µfq is a univariate function of θ determined by the polynomial fq. Hence, in the case when
the function µfq is invertible, we obtain the following estimator for θ

ˇθfq,n := µ−1

fq (cid:2)Qfq,n(X)(cid:3) .

(43)

Proposition 23 Assume H ∈ (0, 1) and µfq is a homomorphism. Let bθfq,n be the estimator given
in (43). Then, as n −→ ∞, almost surely, ˇθfq,n −→ θ.

These considerations allow us to state and prove the following strong consistency and asymp-

totic normality of ˇθfq,n .

Proposition 24 Denote N ∼ N (0, 1). Then

• If H ∈ (0, 5

8 ), for any q,

• If H ∈ ( 5

8 , 3

4 ), for any q,

• In particular, in both cases, assuming µfq is a diﬀeomorphism,
ufq (Z θ)
(µ′fq

• If H = 3
4 ,

In particular,

Ufq,n(X)

C

Ufq,n(X)

C
n1/4

.

n(4H−3)/2 .

, N 6
dW
qufq (Z θ)
dW
, N 6
qufq (Z θ)
√n(cid:0)ˇθfq,n − θ(cid:1) law−→ N 0,
dW
log(n)(cid:0)ˇθfq,n − θ(cid:1) law−→ N 0,
r n

(θ))2! .
fq,n(Z θ)i , N 6 C log− 1
rEhU 2
(θ))2! .

16θ4(µ′fq

9d2

q,2(Z)

Ufq,n(X)

4 (n).

30

Proof. In this proof, C represents a constant which may change from line to line. It was

proved in [20] (also see [4]) that, with rZ the covariance function of Z θ,

3

|rZ (k)|4/3

while

κ4(Uf2,n(Z θ)) 6 CX|k|<n
fq,n(Z θ)i 6 C X|k|<n
EhU 2
Then by Lemma 38, for all H < 3/4, we easily get EhU 2
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
6 C X|k|>n

fq,n(Z θ)i

Also by Lemma 38, for H < 5/8,

EhU 2

ufq (Z θ)

1 −

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

κ4(Uf2,n(Z θ)) 6 Cn−1

|rZ (k)|2
fq,n(Z θ)i 6 ufq (Z θ) < ∞ and in particular
|rZ (k)|2

6 Cn4H−3.

(44)

while for H > 5/8,

κ4(Uf2,n(Z θ)) 6 Cn2(4H−3).

Then by Theorem 11 and by Lemma 22 which shows that γ = 1, we get

dW

, N 6 Cn−1/2 + 4qκ4(Uf2,n(Z θ)) + Cn4H−3

Ufq,n(Z + Y )

qufq (Z)

n−1/2.

depending on whether H is larger or smaller than 5/8 we get the announced result, since n−1/2

Now, by assumption, µfq has a continuously diﬀerentiable derivative. Thus, by the mean

and n(4H−3)/2 coming from dominate the term 4pκ4(Uf2,n(Z θ)) dominate the error terms n4H−3and
value theorem, there exists a random variable ξfq,n between θ and bθfq,n such that
By the normal convergence in law of µfq (bθq,n) to µfq (θ) and the almost-sure convergence of µ′fq

√n(cid:16)µfq (bθq,n) − µfq (θ)(cid:17) = µ′fq (ξfq,n)√n(cid:16)bθq,n − θ(cid:17) .

(ξfq,n)
(θ), the theorem’s ﬁnal statement when H < 3/4 follows. The special case of H = 3/4 is

to µ′fq
treated similarly.

31

6.2 Examples and a Berry-Esséen theorem for drift estimators

In the two following examples, the function µfq is an explicit diﬀeomorphism except at θ = 0.

• Assume that fq = Hq. Using (22) and Lemma 38, we have

µHq (θ) = λHq (Z θ) =

( q

q!

2 )!2q/2(cid:0)HΓ(2H)θ−2H − 1(cid:1)q/2

.

In this case, the function µ is a diﬀeomorphism with bounded derivatives when the range is
restricted to R+. Since, by the previous strong consistency proposition, Qfq,n(X) ends up
in R+ almost surely, the estimator ˇθfq,n is asymptotically equivalent to the one in which the
function g = µ−1
is restricted to R+. This observation will be helpful below when applying
fq
the results of Section 4.3.

• Assume that fq = φq with φq(x) = xq. From (23) and Lemma 38 we obtain

µφq (θ) = λφq (Z θ) =

( q

q!

2 )!2q/2(cid:2)HΓ(2H)θ−2H(cid:3)q/2

.

The singularity of µ at θ = 0 poses some technical problems when one tries to translate the
consistency of Qfq,n(X) into that of ˇθfq,n thanks to Section 4.3, which we investigate below.

We now show how the principle described in Section 4.3 can be used to estimate the speed
of convergence for the estimator ˇθfq,n itself. To work in a speciﬁc situation, we look at the above
two examples, assuming q = 2.

6.2.1 Berry-Esséen theorem for a Hermite-variations-based estimator for θ
In the notation of Section 4.3, using the convention of replacing QH2,n (Z) by |QH2,n (Z)|, in the
case of the Hermite polynomial H2 we have

µH2(θ) = λH2(Z θ) = HΓ(2H)|θ|−2H − 1 = g−1 (θ)

and thus

g (x) = gH2 (x) := (HΓ(2H))−1/(2H) (1 + |x|)−1/(2H) ,

(45)
and g′′ (x) is proportional to (1 + |x|)−1/(2H)−2. This function is bounded on R+. Hence, according
to Theorem 17, using the speed of convergence from Proposition 12, we obtain the following.
Proposition 25 For the stationary fractional Ornstein-Uhlenbeck Z θ in (42), with QH2,n(cid:0)Z θ(cid:1) =
nPn
k=1 Z θ (k)2 − 1 and g as in (45), we get

1

dW

√n

g′(θ∗)rEhU 2

H2,n(Z)i(cid:16)g(cid:16)QH2,n(cid:16)Z θ(cid:17)(cid:17) − θ(cid:17) ,N (0, 1) 6 C

1
√n

+ ϕ (n)

32

where g (x) = (HΓ(2H))−1/(2H) (1 + |x|)−1/(2H) and θ∗ = g−1 (θ) and

ϕ (n) ≍
In particular, for H < 2/3, ϕ (n) ≍ 1/√n.

(cid:16)P|k|<n |k|3H−3(cid:17)2
(cid:16)P|k|<n |k|4H−4(cid:17)3/2 √n

.

Remark 26 Improvements to the above proposition which include the use of the asymptotic variance
ufq (Z θ) and the nonstationary fractional OU process X in (40) also hold. These are omitted here
for the sake of conciseness; the reader will ﬁnd these topics covered in Section 6.3 below.

6.2.2 Comments and strategy for θ estimators with singular variance function

For the power-2 function, in the notation of Section 4.3 we have

µφ2(θ) = λφ2(Z θ) = HΓ(2H)θ−2H = g−1 (θ)

and thus g′′ (x) = cHx−1/(2H)−2 which has a singularity at 0 and thus is not bounded. A result can

be obtained immediately from the above proposition since g(cid:0)Qφ2,n(cid:0)Z θ(cid:1) − 1(cid:1) = g(cid:0)QH2,n(cid:0)Z θ(cid:1)(cid:1) is

the estimator studied in that proposition. However, for illustrative purposes, we ﬁnish this section
by outlining a method for dealing with the singularity, since this works for any g such that g′′ is
asymptotically decreasing like a negative power, and any process that has an inﬁnite Karhunen-
Loève expansion.

According to Theorem 17, we are asking whether for some p′ > 1,

sup

n

−p′/(2H)−2p′(cid:21) < ∞.

This condition is not entirely trivial, and can fail in some simple pathologically degenerate cases
k=1 Z (k)2 = Z (0)2 is a chi-squared variable with
one degree of freedom, which has no moments of negative order less than −1/2. This pathology
does not occur for the fOU process, though the argument is slightly involved, since the limit law of

E(cid:20)(cid:12)(cid:12)(cid:12)bθn(cid:12)(cid:12)(cid:12)
such as if Z is constant, since then bθn = n−1Pn
the renormalizedbθn is normal, which does not have higher negative moments either. We decompose
bθn<1/√ni + Ehg′′(cid:16)bθn(cid:17) 1
Ehg′′(cid:16)bθn(cid:17)i = Ehg′′(cid:16)bθn(cid:17) 1
By the asymptotic normality of(cid:16)bθn − θ∗(cid:17)√n, we get
+ θ∗(cid:12)(cid:12)(cid:12)(cid:12)
−√nθ∗+1(cid:12)(cid:12)(cid:12)(cid:12)
|bθn|>1/√ni ∼Z ∞
+ θ∗(cid:12)(cid:12)(cid:12)(cid:12)
−√nθ∗/2(cid:12)(cid:12)(cid:12)(cid:12)
e−z2/2dz +Z ∞

Ehg′′(cid:16)bθn(cid:17) 1
−√nθ∗+1 (cid:12)(cid:12)(cid:12)(cid:12)
= Z −√nθ∗/2

6 cst e−nθ∗/8np′(2+1/(2H)) + (θ∗/2)−p′(2+1/(2H))

bθn>1/√ni .

z
√n

+ θ∗(cid:12)(cid:12)(cid:12)(cid:12)

−p′(2+1/(2H))

e−z2/2dz

−p′(2+1/(2H))

e−z2/2dz

−p′(2+1/(2H))

z
√n

z
√n

33

which is bounded for all n.

For the second piece, the normal approximation would not yield a ﬁnite bound, thus we

must return to the original expression of bθn as a 2nd chaos variable. It is known (see [19, page
522]) that Z θ (k) has a Kahunen-Loève expansion P∞m=0 √λmem (k) Wm (where the Wm are i.i.d.
standard normal, and the em are orthonormal in L2 ([0, n]) ) such that λm ∼ cm2H−2. Thus, the
expansion of Z θ contains inﬁnitely many independent terms. One also knows (see [24, Section
2.7.4]) that ˆθn, like any variable in the second chaos, can be expanded as P∞m=0 µmW 2
m where
the µm are summable. One can check that the inﬁnity of distinct terms in the expansion of Z y
implies that for any ﬁxed n, the expansion of ˆθn also contains inﬁnitely many terms, and that the
coeﬃcients are positive. Therefore, for any ﬁxed m0, there exists a positive constant cm0 such that
ˆθn > cm0Pm0
m =: Sm0, which is a random variable with χ2 distribution with m0 degrees of
freedom. Hence the density of S at the origin is of the order z(m0−1)/2, which means it has a negative
moment of order −p′ (2 + 1/(2H)) as soon as m0 > p′ (2 + 1/(2H)) − 1. From this it follows that
bθn<1/√ni is bounded. Thus g and ˆθ comply with the conditions of Theorem 17. In fact,
Ehg′′(cid:16)bθn(cid:17) 1
show that the second-chaos series decomposition of bθn contains 2 independent terms. This covers

since p′ can be taken arbitrarily close to 1, we only need to be able to choose m0 > 1 + 1/(2H).
For instance, if H > 1/2, this means that for Theorem 17 to work with q = 2, one only needs to

all Gaussian processes except for the trivial case of the constant process.

m=0 W 2

6.3 Optimal Berry-Esséen theorem in the quadratic case

As in the previous sections, the convergence speed for general q has no reason to be optimal. We
illustrate this by studying the case q = 2, where we can improve the rate convergence thanks to the
optimal rates obtained in Section 4.2, and even obtain optimal two-sided bounds when H < 5/8.
Note that the results in this section deal with the fully realistic scenario where observations come
from the non-stationary process X in (40) and there is no reference to normalizing constants other
than ﬁnite asymptotic variances.

6.3.1 Setting up the rates of convergence

First assume that H 6 3/4. We ﬁnd that κ3(Ff2,n(Z θ)) −→ 0 and more precisely (see [20]) that

By using Corollary 13, we see that we must compare the rates therein to the rates obtained in (46).
By (44) the rate which controls the convergence of the variances is n4H−3. This can be dominated
by 1/√n if and only if n < 5/8. For H ∈ [2/3, 3/4), n4H−3 dominates the rates in (46). The rate

34

(cid:12)(cid:12)(cid:12)E(cid:16)(Ff2,n(Z θ))3(cid:17)(cid:12)(cid:12)(cid:12) ≍ (cid:16)P|k|<n |rZ (k)|3/2(cid:17)2
(cid:16)P|k|<n |rZ (k)|2(cid:17)3/2 √n

6 C ×

n− 1
2 ,

if 0 < H <

log2(n)n− 1
2 ,

if H =

n6H− 9
2 ,

if

2
3

< H <

log−3/2(n),

if H =

2
3
2
3
3
4
3
4

.

(46)



which controls the non-stationarity term is always of order 1/√n because of Lemma 22, which is
always the lowest-order term. Hence the improved rates in (46) only come into play when H < 5/8
when normalizing by the asymptotic variance. In other words, we have the following two estimates,
where the second one avoids the use of non-empirical statistics.

Proposition 27 If H ∈ (0, 3
4 ],

if H =

< H <

n6H− 9
2 ,

if

2
3

n− 1
2 ,

if 0 < H <

log2(n)n− 1
2 ,

log−3/2(n),

if H =

n− 1
2 ,

if 0 < H <

n4H−3,

if

5
8

6 H <

2
3
2
3
3
4
3
4

5
8
3
4

.

Uf2,n(X)


f2,n(Z θ)i , N 6 C ×
dW
rEhU 2
dW(cid:18)Uf2,n(X),quf2(Z θ)N(cid:19) 6 C ×

and

Next we show how to obtain optimal rates of convergence in the Wasserstein distance when
H < 5/8. This result is important methodologically speaking because, thanks to the strategy in
Section 5, it is essentially always possible to transform one’s long-memory time series into one which
satisﬁes H < 5/8, by using a ﬁnite-diﬀerence transformation.

6.3.2 Applying the optimal theorem

To apply Theorem 15 we must check that conditions (34) and (35) are met. We just saw that this
is the case when H < 5/8. However, we must also check that the corresponding constants c3 and c4
are suﬃciently small. Since H < 5/8, by (44), the constant c4 can be made arbitrarily small for n
large enough. It remains to show that c3 can be chosen small. A direct application of Lemma 22 is
insuﬃcient for this purpose. Therefore, we must modify our estimator slightly, by discarding some
of the ﬁrst terms. We thus ﬁx an integer i0 > 0 and deﬁne

˜Qf2,n (X) :=

1
n

i0+n−1Xi=i0

f2 (Xi) .

(47)

It is easy to check that this is still a consistent and asymptotically normal estimator of rZ (0). By
the proof of Lemma 22, we see that4

(cid:13)(cid:13)(cid:13) ˜Qf2,n (X) − ˜Qf2,n(cid:16)Z θ(cid:17)(cid:13)(cid:13)(cid:13)Lp(Ω)

6 c (θ, f2)

1
n

i0+n−1Xi=i0

e−iθ 6 c (θ, f2)

1
n

e−i0θ.

(48)

35

Since θ > 0, we can make the last expression above as small as we want by choosing i0 suﬃciently
large. Thus Theorem 15 applies, and we have the following optimal Berry-Esséen theorem for the
variance estimator ˜Qf2,n (X), which, as we saw in Section 6.1, gives access to estimators for θ.

Proposition 28 If H ∈(cid:0)0, 5

˜Qf2,n deﬁned in (47) satisﬁes

8(cid:1), then there exists an integer i0 > 0 such that the quadratic variation

Moreover, with g as in (45), we have

dW(cid:16)√nh ˜Qf2,n (X) − rZ (0)i ,N (0, uf2 (Z θ))(cid:17) ≍
dW(cid:16)√n(cid:16)g(cid:16) ˜QH2,n (X)(cid:17) − θ(cid:17) ,N (0, g′ (θ∗)2 uH2(Z θ))(cid:17) ≍

1
√n

.

1
√n

Proof. The ﬁrst result follows from the considerations immediately above. The second

follows from Theorem 17 exactly as did the result in Proposition 25; we omit the details.

6.3.3 Comments on higher-order ﬁnite-diﬀerenced data

Given the claim that one can always reduce a time series to one with H < 5/8, one ought to check
that, in the case of the fOU process, the parameter θ remains explicitly accessible after the ﬁnite-
diﬀerence transformation. We ﬁrst leave it to the reader to check that for fOU with any H < 1, and
any positive real d, the fractional ﬁnite-diﬀerenced process DdZ θ has an auto-correlation function
which decays like k2H−2d−2, so that the memory length parameter H′ = H−d satisﬁes the condition
H′ < 5/8 as soon as d > 3/8. Certainly, one may thus always consider the ﬁrst-order diﬀerence
process

as suggested in Section 5, and one can write X (1) = Z (1),θ + Y and the reader may check that an
estimate such as (48) still holds, so that the proposition above holds for X (1) for any H < 1.

X (1)
k = Xk+1 − Xk

For the quadratic Hermite variation, it remains only to investigate the form of the variance

parameter λφ2(Z (1),θ) = rZ (1),θ (0) to which ˜Qφ2,n(cid:0)X (1)(cid:1) converges. The computation is tedious

and presumably known. We ﬁnd that the variance of Z (1),θ is

rZ (1),θ (0) =

=

eθ

2 + e−2θ rZ θ (0)
2 + e−2θ HΓ(2H)|θ|−2H .

eθ

By considering the Hermite quadratic variation instead, as we did in Section 6.2, one avoids the
singularity at the origin in this function, obtaining that the function to be inverted to transform

˜QH2,n(cid:0)X (1)(cid:1) into an estimator of θ is simply

µH2,Z (1)(θ) :=

eθ

2 + e−2θ(cid:16)HΓ(2H)|θ|−2H − 1(cid:17) .

36

(49)

One is confronted in µH2,Z (1) with a function which has a single negative global minimum at θmin,
and tends to +∞ at 0 and at +∞. Thus in practice, when working with this ﬁrst ﬁnite diﬀerence,
additional information is needed to ﬁnd out on which side of θmin the parameter θ would be located.
On each of the two intervals (0, θmin] and [θmin, +∞) where µH2,Z (1) is a diﬀeomorphism, despite the
transcendental nature of this function of θ, it is a simple matter of inverting it numerically to access
an asymptotically normal estimator for θ for any H ∈ (0, 1). It is immediate that µH2,Z (1) behaves
like |θ|−2H near 0, and like an exponential near +∞. Using Theorem 17 to prove a Berry-Esséen

leading to Proposition 25, to obtain this n−1/2 speed in Wasserstein distance. The moment condition
of Theorem 17 is automatically satisﬁed in the case θ < θmin because the second derivative of

speed of convergence for the θ estimator (cid:16)µH2,Z (1)(cid:17)−1(cid:16) ˜Qφ2,n(cid:0)X (1)(cid:1)(cid:17), one follows the argument
In the case θ > θmin the function (cid:18)(cid:16)µH2,Z (1)(cid:17)−1(cid:19)′′
(cid:16)µH2,Z (1)(cid:17)−1

has
logarithmic growth at +∞; the moment condition in Theorem 17 is then also satisﬁed since chaos
variables have moments of all orders, and certainly thus logarithmic ones. All further details all
omitted. Summarizing, as in Proposition 28, we obtain the following.

is bounded in that case.

Proposition 29 Let µH2,Z (1) be as in (49), θmin be that function’s global minimizer, and assume

either θ < θmin or θ > θmin. Let θ∗ := µH2,Z (1) (θ) and g :=(cid:16)µH2,Z (1)(cid:17)−1

and

˜Qf2,n(cid:16)X (1)(cid:17) :=

1
n

i0+n−1Xi=i0

H2 (Xi − Xi−1) .

Then for any H ∈ (0, 1), we have

lim √n(cid:16) ˜QH2,n(cid:16)X (1)(cid:17) − θ∗(cid:17) =: uH2(Z (1))) < ∞

and there exists an integer i0 > 0 such that g(cid:16) ˜QH2,n(cid:0)X (1)(cid:1)(cid:17) is a strongly consistent estimator of θ

and

dW(cid:16)√n(cid:16)g(cid:16) ˜QH2,n(cid:16)X (1)(cid:17)(cid:17) − θ(cid:17) ,N (0, g′ (θ∗)2 uH2(Z (1)))(cid:17) ≍

1
√n

.

7 Application to Ornstein-Uhlenbeck processes : multi-parameter

examples

In the previous section, we provided a full study of univariate parameter estimation for a fractional
Ornstein-Uhlenbeck process, including all details of how to apply our general theory. In this ﬁnal
section of our article, we give two more examples of applications of our methods. For the sake of
conciseness, we focus on the results, providing only a minimal amount of computations and proofs,
since these are all modeled on the arguments in Section 6.

37

7.1 OU driven by fractional Ornstein-Uhlenbeck process

In this section we assume that X = {Xt, t > 0} is an Ornstein-Uhlenbeck process driven by a frac-
tional Ornstein-Uhlenbeck process V = {Vt, t > 0}. This is given by the following linear stochastic
diﬀerential equations

( X0 = 0;

V0 = 0;

dXt = −θXtdt + dVt,
dVt = −ρVtdt + dBH
t ,

t > 0

t > 0,

(50)

where BH =(cid:8)BH

t , t > 0(cid:9) is a fractional Brownian motion of Hurst index H ∈ (0, 1), whereas θ > 0

Using the notation (42), the explicit solution to this linear system, noted for instance in

and ρ > 0 are two unknown parameters such that θ 6= ρ.
[13], implies the following decomposition of Xt:

On the other hand, we can also write the system (50) as follows

Xt =

X ρ

t +

ρ
ρ − θ

θ

θ − ρ

X θ
t .

where for 0 6 t 6 T

We also have

where

dXt = − (θ + ρ) Xtdt − ρθΣtdt + dBH
t .
Σt =Z t

t − X ρ
X θ
ρ − θ

Vt − Xt

Xsds =

=

θ

0

t

X θ

t = Z θ

t − e−θtZ θ

0

Z θ

t =Z t

−∞

e−θ(t−s)dBH
s .

Moreover, the process(cid:16)Z θ

t , Z θ′

t (cid:17) is an ergodic stationary Gaussian process. As consequence

Xt =

:=

and

Z ρ

t +

ρ
ρ − θ
Z θ,ρ

t −(cid:18) ρe−ρt

ρ − θ

θ

Z θ

θ − ρ
Z ρ

0 +

t −(cid:18) ρe−ρt
0(cid:19)

ρ − θ
Z θ

θe−θt
θ − ρ

Z ρ

0 +

θe−θt
θ − ρ

Z θ

0(cid:19)

Σt =

:=

t

t − Z ρ
Z θ
ρ − θ −
e−θtZ θ
Σθ,ρ
t −

e−θtZ θ

0 − e−ρtZ ρ
ρ − θ
0 − e−ρtZ ρ
ρ − θ

0

0

.

Moreover, Z θ,ρ and Σθ,ρ are ergodic stationary Gaussian processes.

38

(51)

(52)

(53)

(54)

(55)

(56)

(57)

Now, assume that the processes X and Σ are observed equidistantly in time with the step
size ∆n = 1. We will construct estimators for (θ, ρ). By using the ergodicity of Z θ,ρ and Σθ,ρ,
Lemma 22 and (8), we conclude that

(cid:0)Qfq,n(X), Qfq,n(Σ)(cid:1) −→(cid:16)λfq (Z θ,ρ), λfq (Σθ,ρ)(cid:17)

almost surely as n → ∞.
Moreover, by the Gaussian property of Z θ,ρ and Σθ,ρ, and the expressions ηX (θ, ρ) and
ηΣ(θ, ρ) for the variances of Z θ,ρ and Σθ,ρ which are given respectively in (71) and (72) after Lemma
39 in the Appendix, we can write

(cid:16)λfq (Z θ,ρ), λfq (Σθ,ρ)(cid:17) = δfq (θ, ρ)

where δfq is a function which can be expressed via ηX(θ, ρ) and ηΣ(θ, ρ). Hence, in the case when
the function δfq is invertible, we obtain the following estimator for θ

(bθfq,n,bρfq,n) := δ−1

fq (cid:2)(cid:0)Qfq,n(X), Qfq,n(Σ)(cid:1)(cid:3) .

Proposition 30 Assume H ∈ (0, 1) and δfq is a homomorphism. Let (bθfq,n,bρfq,n) be the estimator

given in (58). Then, as n −→ ∞

(59)

(58)

almost surely.

(bθfq,n,bρfq,n) −→ (θ, ρ)

Examples. In the two following examples, the function δfq is invertible and explicit, based on the
expressions for ηX(θ, ρ) and ηΣ(θ, ρ) given respectively in (71) and (72) in the Appendix.

• Suppose that fq = Hq. Using (22), (71) and (72), we have

q!

( q

δHq (θ, ρ) =

2 )!2q/2(cid:16)(ηX(θ, ρ) − 1)q/2 , (ηΣ(θ, ρ) − 1)q/2(cid:17) .
• Suppose that fq = φq with φq(x) = xq. From (23), (71) and (72) we obtain
2 )!2q/2(cid:16)(ηX (θ, ρ))q/2 , (ηΣ(θ, ρ))q/2(cid:17) .

δφq (θ, ρ) =

q!

( q

Theorem 31 Let H ∈(cid:0)0, 3

where

ufq (Z θ,ρ, Σθ,ρ)

4(cid:1). Deﬁne
Γfq (θ, ρ) =(cid:18) ufq (Z θ,ρ)
fq,2k(2k)!Xj∈Z∗

q/2Xk=0

d2

39

ufq (Z θ,ρ, Σθ,ρ) =

ufq (Z θ,ρ, Σθ,ρ)

ufq (Σθ,ρ) (cid:19)
j (cid:17)
E(cid:16)Z θ,ρ
prZ θ,ρ(0)rΣθ,ρ (0)

0 Σθ,ρ

(60)

.

2k

Then

dW(cid:0)(cid:0)Ufq,n(X), Ufq ,n(Σ)(cid:1) ;N(cid:0)0, Γfq (θ, ρ)(cid:1)(cid:1) 6
4(cid:1),
Hence, for any H ∈(cid:0)0, 3
√n(cid:16)bθfq,n − θ,bρfq,n − ρ(cid:17) L−→ N(cid:18)0, Jδ−1

is the Jacobian matrix of δ−1
fq

where Jδ−1

.

(ηX (θ, ρ), ηΣ(θ, ρ)) Γfq (θ, ρ) J T
δ−1
fq

fq

fq

C
n1/4

(61)

(ηX (θ, ρ), ηΣ(θ, ρ))(cid:19)(62)

Proof. Combining (56), (57), Lemma 39 and Theorem 11, we obtain (61). Applying Taylor’s

formula we can write

where dn converges in distribution to zero, because

δ−1

fq (cid:16)λfq (Z θ,ρ), λfq (Σθ,ρ)(cid:17)(cid:0)Ufq,n(X), Ufq ,n(Σ)(cid:1) + dn

√n(cid:16)bθq,n − θ,bρq,n − ρ(cid:17) = J T
kdnk 6 C√n(cid:13)(cid:13)(cid:13)(cid:16)Qfq,n(X) − λfq (Z θ,ρ), Qfq,n(Σ) − λfq (Σθ,ρ)(cid:17)(cid:13)(cid:13)(cid:13)

−→ 0

2

almost surely as n → ∞ by using (61). Thus the 2-d random vector in the left-hand side of (62)
is the sum of a term converging in law to 0 and another converging almost surely to 0; thus it
converges in law to 0, establishing (62).

Example: Here we assume that fq = φq and q = 2, and we can recompute the expression

δφ2 (x, y) = (ηX(x, y), ηΣ(x, y))

for the function δφ2 : (0, +∞)2 7→ (0, +∞)2 as
= HΓ(2H) ×(cid:26) 1

y2−x2(cid:0)y2−2H − x2−2H , x−2H − y−2H(cid:1)
(cid:0)(1 − H)x−2H, Hx−2H−2(cid:1)
Since for every (x, y) ∈ (0, +∞)2 with x 6= y the Jacobian of δφ2 computes as

if y = x.

if x 6= y

(1−H)x1−2H (x2−y2)−x(x2−2H−y2−2H)

(1−H)y1−2H (y2−x2)−y(y2−2H−x2−2H)

Hx−2H−1(x2−y2)+x(x−2H−y−2H)

Hy−2H−1(y2−x2)+y(y−2H−x−2H)

(x2−y2)2
(x2−y2)2

(x2−y2)2
(x2−y2)2

which is non-zero on in (0, +∞)2. So δφ2 is a diﬀeomorphism in (0, +∞)2 and its inverse δ−1
Jacobian

φ2

has a

Jδφ2

Jδ−1
φ2

(x, y) = Γ(2H + 1)
det JF2 (x, y)

Γ(2H + 1)

(a, b) =

Hy−2H−1(y2−x2)+y(y−2H−x−2H)
Hx−2H−1(x2−y2)+x(x−2H−y−2H)

(x2−y2)2
(x2−y2)2

−

(1−H)y1−2H (y2−x2)−y(y2−2H−x2−2H)
−
(1−H)x1−2H(x2−y2)−x(x2−2H−y2−2H )

(x2−y2)2
(x2−y2)2

where (x, y) = δ−1
(a, b). Thus the asymptotic covariance matrix in (62) is explicit. Moreover,
φ2
similarly to the results obtained in Section 6, we can prove the following, all details being omitted.

40

 ,
 ;

Proposition 32 Let (α, β) ∈ R2. Under the assumptions and notation of Theorem 31,

• if H ∈ (0, 5
8 ),

• if H ∈ ( 5

8 , 3

dW(cid:16)αUφ2,n(X) + βUφ2,n(Σ);N(cid:16)0, (α, β) Γφ2(θ, ρ) (α, β)T r(cid:17)(cid:17) ≍
dW(cid:16)αUφ2,n(X) + βUφ2,n(Σ);N(cid:16)0, (α, β) Γφ2(θ, ρ) (α, β)T r(cid:17)(cid:17) 6

4 ),

1
√n

,

C

n4H−3 .

7.2

Fractional Ornstein-Uhlenbeck process of the second kind

The last example we consider is the so-called fractional Ornstein-Uhlenbeck process of the second
kind, deﬁned via the stochastic diﬀerential equation

S0 = 0, and dSt = −αStdt + dY (1)

t

,

t > 0,

(63)

H and B = {Bt, t > 0} is a fractional Brownian motion with
2 , 1), and where α > 0 is the unknown real parameter which we would like

s

0 e−sdBas with as = He

t =R t
where Y (1)
Hurst parameter H ∈ ( 1
to estimate. The equation (63) admits an explicit solution
St = e−αtZ t

s = e−αtZ t

eαsdY (1)

0

0

Hence we can also write

e(α−1)sdBas = H (1−α)H e−αtZ at
t − e−αtSα

a0

0

St = Sα

r(α−1)H dBr.

where

Sα

t = e−αtZ t

−∞

e(α−1)sdBas = H (1−α)H e−αtZ at

0

r(α−1)H d ˜Br,

where the second equality holds by bijective change of variable, where ˜B has the same law as B.
Using a similar argument to that in Lemma 22 we have for every p > 1 and for all n ∈ N,

(64)

As consequence, by using Sα ergodic and (64) we conclude that, almost surely as n → ∞,

(cid:13)(cid:13)Qfq,n(S) − Qfq,n(Sα)(cid:13)(cid:13)Lp(Ω) = O(cid:0)n−1(cid:1) .

Qfq,n(S) −→ λfq (Sα).

Moreover, by the Gaussian property of U α and (74) we can write

λfq (Sα) := νfq (α)

where νfq is a function. Hence, in the case when the function νfq is a homeomorphism, we obtain
the following strongly consistent estimator for α

bαfq,n := ν−1

fq (cid:2)Qfq,n(S)(cid:3) .

41

(65)

Proposition 33 Assume H ∈(cid:0) 1

in (65). Then, almost surely as n −→ ∞

2 , 1(cid:1) and νfq is a homeomorphism. Let bαfq,n be the estimator given

bαfq,n −→ α.

Examples. In the two following examples, the function νfq is homeomorphic and explicit.

• Suppose that fq = Hq. Using (22) and (74), we have

νHq (α) = λHq (Sα) =

q!

2 )!2q/2(cid:18) (2H − 1)H 2H

α

( q

β(1 − H + αH, 2H − 1) − 1(cid:19)q/2

.

.

α

q!

( q

β(1 − H + αH, 2H − 1)iq/2

• The reader will check that in both cases above, the function α 7→ v (α) is monotone (decreas-

• Suppose that fq = φq with φq(x) = xq. From (23) and (74) we obtain νφq (α) = λφq (Sα) =
2 )!2q/2h (2H−1)H 2H
ing) and convex from R+ to R+, and that the moment condition of Theorem 17 on(cid:0)v−1(cid:1)′′ is
Now, we study the asymptotic distribution of bαfq,n. By (75) which is established in Lemma
2 , 1),Pj∈Z |rSα(j)|2 < ∞ and κ4(Ufq,n(Sα)) = O( 1

40 in the Appendix, we have for every H ∈ ( 1
Thus, applying (25) we deduce the following result.

satisﬁed.

n ).

Proposition 34 Suppose that H ∈ ( 1

2 , 1) and α > 0. Then

In particular,

dW(cid:16)ufq (Sα)−1/2Ufq,n(S), N(cid:17) 6 Cn− 1
√n(cid:0)bαfq,n − α(cid:1) law−→ N 0, ufq (Sα)(cid:18)(cid:16)ν−1

4

fq (cid:17)′ (α)(cid:19)−2! .

Quadratic case. In this case we can improve the rate convergence of bαf2,n. By using Theorem 15,
n ) and(cid:12)(cid:12)E(cid:0)(Ff2,n(Sα))3(cid:1)(cid:12)(cid:12) = O( 1√n ), and invoking the properties
the estimates κ4(Uf2,n(Sα)) = O( 1
of uf2 described in the examples (bullet points) above to invoke Theorem 17, we get the following.
Proposition 35 Let H ∈(cid:0) 1
2 , 1(cid:1). Then
dW(cid:16)uf2(Sα)−1/2Uf2,n(S), N(cid:17) ≍
dW √n (bαf2,n − α) ,N (0, uf2 (Sα))(cid:18)(cid:16)ν−1

f2 (cid:17)′ (α)(cid:19)−2! 6

C
√n

1
√n

and

.

,

42

8 Appendix

The following result is a well-known direct consequence of the Borel-Cantelli Lemma (see e.g. [18]).

Lemma 36 Let γ > 0 and p0 ∈ N. Moreover let (Zn)n∈N be a sequence of random variables. If for
every p > p0 there exists a constant cp > 0 such that for all n ∈ N,

kZnkLp(Ω) 6 cp · n−γ,
then for all ε > 0 there exists a random variable ηε such that

|Zn| 6 ηε · n−γ+ε
for all n ∈ N. Moreover, E|ηε|p < ∞ for all p > 1.

almost surely

dT V 

Proof of Theorem 4. Since

Ufq ,n(Z)

rEhU 2
1 −*D

fq ,n(Z)i ∈ D1,2, by [22, Proposition 2.4] we have
+

Ufq,n(Z)

Ufq,n(Z)

Ufq,n(Z)

fq,n(Z)i , N 6 2E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
rEhU 2

rEhU 2

rEhU 2
EhEh(I2k(g2k,n))2i − hDI2k(g2k,n),−DL−1I2k(g2k,n)iHi = 0

fq,n(Z)i ,−DL−1

fq,n(Z)i

H

.

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

On the other hand, exploiting the fact that

we obtain

Moreover, by [23, Lemma 3.1] we have

6

1

Ufq,n(Z)

Ufq,n(Z)

1 − hD

E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

fq,n(Z)i

rEhU 2


fq,n(Z)iiH(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
fq,n(Z)i ,−DL−1
rEhU 2
q/2Xk=1qV ar(cid:0)(2k)−1kDI2k(g2k,n)k2
EhU 2
j (cid:17)4
j2j!2(cid:16)2k
V ar(cid:0)(2k)−1kDI2k(g2k,n)k2
Eh(cid:0)(2l)−1hDI2k(g2k,n), DI2l(f2l,n)iH(cid:1)2i 6 (2k)!(cid:16)2l−1
2k−1(cid:17)2

H(cid:1) = (2k)−2

2k−1Xj=1

+2k2

(l − 1)!2(cid:16)2k−1
2k−1Xj=1

j−1(cid:17)2
j−1 (cid:17)2(cid:16)2l−1

(2k + 2l − 2j)!(cid:18)kg2k,n ⊗2k−j

and for k < l

43

H(cid:1) + X16k6=l6q/2

(2l)−1E |hDI2k(g2k,n), DI2l(g2l,n)iH| .

(4k − 2j)!kg2k,n ˜⊗j

g2k,nk2

H⊗4k−2j ,

(2l − 2k)!Eh(I2k(g2k,n))2ikg2k,n ⊗2l−2k
H⊗2j(cid:19) .
g2k,nk2

H⊗2j + kg2k,n ⊗2l−j

g2k,nk2

g2k,nkH⊗4k

Combining this together with

Eh(I2k(g2k,n))2i =

6

(2k)!d2

fq ,2k

n

(2k)!d2
n

fq ,2k

rZ(0) (cid:19)2k
n−1Xi,j=0(cid:18) rZ (i − j)
rZ(0) (cid:19)2
n−1Xi,j=0(cid:18) rZ (i − j)

=

and the fact that for every 1 6 s 6 2k − 1 with k ∈ {1, . . . , q/2}

(2k)!d2

fq ,2k

2r2

Z (0)

E(U 2

f2,n(Z)).

kg2k,n ⊗s

g2k,nk2

H⊗4k−2s

6 d4

fq,2k(Z)n−2

nXk1,k2,k3,k4=1

6 d4

fq,2k(Z)n−2rZ(0)−4

= d4

fq,2k(Z)κ4(U2,n(Z))

we deduce that

nXk1,k2,k3,k4=1(cid:18) rZ (k1 − k2)

rZ (0) (cid:19)s(cid:18) rZ (k3 − k4)

rZ(0) (cid:19)s(cid:18) rZ(k1 − k3)

rZ (0) (cid:19)2k−s(cid:18) rZ (k2 − k4)

rZ(0) (cid:19)2k−s

rZ(k1 − k2)rZ (k3 − k4)rZ (k1 − k3)rZ (k2 − k4)

and

where

(2l)−1E |hDI2k(g2k,n), DI2l(f2l,n)iH|

H(cid:1) 6 C1,q(Z)qκ4(U2,n(Y ))

(1 +

q/2Xk=1qV ar(cid:0)(2k)−1kDI2k(g2k,n)k2
X16k6=l6q/2
= X16k<l6q/2
6 X16k<l6q/2
6 C2,q(Z)rEhU 2
q/2Xk=1

C1,q(Z) =

(1 +

k
l

k
l

d2

)(2l)−1E |hDI2k(g2k,n), DI2l(f2l,n)iH|

)(cid:16)Eh(cid:0)(2l)−1hDI2k(g2k,n), DI2l(f2l,n)iH(cid:1)2i(cid:17)1/2
f2,n(Z)iqκ4(Uf2,n(Z)) + κ4(Uf2,n(Z)),
fq,2k(Z)(2k)−1vuut

j (cid:17)4
j2j!2(cid:16)2k

(4k − 2j)!,

2k−1Xj=1

(66)

44

and

C2,q(Z) = X16k<l6q/2

(1 +

2k2(d4

fq,2k + d4

(2k + 2l − 2j)!

1/2

.

(67)

d4
fq,2k
2r2
Z (0)

,

k
l

fq,2l)

(2l − 2k)!

) max ((2k)!)2(cid:16)2l−1
2k−1(cid:17)2
j−1(cid:17)2
j−1 (cid:17)2(cid:16)2l−1
(l − 1)!2(cid:16)2k−1
2k−1Xj=1
fq,n(Z)irEhU 2
EhU 2
f2,n(Z)irEhU 2
EhU 2
= Cq(Z)rqκ4(Ff2,n(Z)) + κ4(Ff2,n(Z)),

Cq(Z)

Cq(Z)

6

f2,n(Z)iqκ4(Uf2,n(Z)) + κ4(Uf2,n(Z))
f2,n(Z)iqκ4(Uf2,n(Z)) + κ4(Uf2,n(Z))

Ufq,n(Z)

fq,n(Z)i , N 6
rEhU 2

Furthermore,

dT V 

where

Cq(Z) = 2 max (C1,q(Z), C2,q(Z)) .

(68)

Thus the ﬁrst estimate of the theorem is obtained. The upper bound of the second estimate is
proved in [4, Proposition 6.4].

Proof of Lemma 9. By deﬁnition of the Wasserstein distance,

dW (Y + Z, N ) = sup

h |E [h (Y + Z) − h (Z)] + E [h (Z)] − E [h(N )]|
h |E [h (Y + Z) − h (Z)]| + sup

h |E [h (Z)] − E [h(N )]|

6 sup

6 E [|Y |] + dW (Z, N )

where in the last inequality we used the fact that h is 1-Lipshitz.

Proof of Lemma 14. An inspection of the proof of the main lower bound result in [22]

shows that their lower bound on dT V (Fn, N ) is in fact a lower bound on

1
2

max {|E (cos Fn) − E (cos N )| ;|E (sin Fn) − E (sin N )|} .

Since sin and cos are 1-Lipshitz functions, by deﬁnition of dW , this expression is also a lower bound
on 1

2 dW (Fn, N ). This proves the lemma.

Lemma 37 Let H ∈ (0, 1

2 , 1], m, m′ > 0 and −∞ 6 a < b 6 c < d < ∞. Then

2 ) ∪ ( 1
emsdBH(s)Z d

c

E(cid:18)Z b

a

em′tdBH(t)(cid:19) = H(2H − 1)Z b

a

dsemsZ d

c

dtem′t(t − s)2H−2

45

Proof. We use the same argument as in the proof of [8, Lemma 2.1].

Lemma 38 Let H ∈ (0, 1

2 ) ∪ ( 1

2 , 1), m, m′ > 0 and let Z θ be the process deﬁned in (42). Then,

rZ θ (0) = HΓ(2H)θ−2H

and for large |t|

θ2
Proof. see [8, Theorem 2.3] or Lemma 39.

rZ θ (t) ∼

H(2H − 1)

|t|2H−2.

Lemma 39 Let H ∈ (0, 1

2 , 1), m, m′ > 0 and let Z m be the process deﬁned in (55). Then,

and for large |t|

and for every t > 0

2 ) ∪ ( 1
EhZ m

2 , 1)

mm′

0 Z m′

0 Z m′

HΓ(2H)

HΓ(2H)

|t|2H−2.

H(2H − 1)

0 i =
m + m′ (cid:16)m1−2H + (m′)1−2H(cid:17)
t i ∼
EhZ m
This implies that for H ∈ (0, 1
2 ) ∪ ( 1
ηX(θ, ρ) := E(cid:20)(cid:16)Z θ,ρ
0 (cid:17)2(cid:21) =
ηΣ(θ, ρ) := E(cid:20)(cid:16)Σθ,ρ
0 (cid:17)2(cid:21) =
t (cid:17)i = Eh(cid:16)Z θ,ρ
Eh(cid:16)Z θ,ρ
0 i = mm′Z 0
−∞Z 0
emuem′vE(cid:0)BH
2 Z ∞
0 Z ∞
emuem′v(cid:0)u2H + v2H − |v − u|2H(cid:1) dudv
2(m + m′)(cid:16)m1−2H + (m′)1−2H(cid:17) .

ρ2 − θ2 [ρ2−2H − θ2−2H],
ρ2 − θ2 [θ−2H − ρ−2H],
0 Σθ,ρ

Proof. By using [8, Proposition A.1], we can write

0 (cid:17)i = 0.
v (cid:1) dudv

u BH

EhZ m

Γ(2H + 1)

t Σθ,ρ

HΓ(2H)

0 Z m′

−∞

0

=

=

mm′

Thus the estimate (69) is proved. Now, let 0 < ε < 1

E(cid:16)Z m

0 Z m′

t (cid:17) = e−m′tE(cid:18)Z 0
= e−m′tE(cid:18)Z 0

−∞

−∞

:=

A + B

emudBH

em′vdBH

emudBH

em′vdBH

u Z t
u Z εt

−∞

−∞

v (cid:19)
v (cid:19) + e−m′tE(cid:18)Z 0

−∞

emudBH

u Z t

εt

46

(69)

(70)

(71)

(72)

(73)

em′vdBH

v (cid:19)

t

εt

εt

−∞

=

=

2H − 2

H(2H − 1)

H(2H − 1)

dv em′v(v − u)2H−2

Lemma 37 and integration by parts and linear changes of variables

e−m′(t−z)z2H−2dz + e−m′t(1−ε)Z ∞

du emuZ t
e−m(z−t)z2H−2dz +Z t

where, using [8, Proposition A.1] it is easy to see that |A| = O(cid:16)e−m′t(cid:17). On the other hand, by
B = H(2H − 1)e−m′tZ 0
m + m′ (cid:18)Z ∞
(m + m′) (cid:18) t2H−2
e−m′(1−ε)t −
t2H−2 + o(cid:0)t2H−2(cid:1) ,
Z ∞
e−m(z−t)z2H−3dz 6 t−1Z ∞
e−m′(t−z)z2H−3dz 6 ε2H−3t−1Z t

e−m′(t−z)z2H−3dz + e−m′t(1−ε)Z ∞

e−m(z−εt)z2H−2dz(cid:19)

m Z ∞
Z t

m′

the last inequality coming from the fact that

(εt)2H−2

m′

−
H(2H − 1)

t2−2HZ t

εt

e−mydy → 0,

e−m(z−t)z2H−3dz +

as t → ∞,

e−m′(t−z)dz

2H − 2

t2H−2

m′

+

m

mm′

t

εt

=

εt

t

0

e−m(z−εt)z2H−2dz(cid:19)

εt

εt

= ε2H−3t−1Z (1−ε)t

0

e−m′ydy → 0,

as t → ∞,

and

t2−2He−m′t(1−ε) → 0,
So, we conclude that the estimate (70) is obtained.
Lemma 40 Let H ∈ ( 1

2 , 1). Then,

as t → ∞.

and for large |t|

Eh(Sα

0 )2i =

(2H − 1)H 2H

α

rSα(t) = E [Sα

0 Sα

(74)

(75)

β(1 − H + αH, 2H − 1).

t ] = O(cid:16)e− min{α, 1−H
dyy(α−1)HZ a0
dyy(α−1)HZ y
dyy2αH−1Z 1

H }t(cid:17) .
dx x(α−1)H|x − y|2H−2
dx x(α−1)H (y − x)2H−2
dz z(α−1)H (1 − z)2H−2

0

0

0

0

0

0

Proof. We prove the ﬁrst point (74). We have

Eh(Sα

0 )2i = H(2H − 1)H 2(1−α)HZ a0
= 2H(2H − 1)H 2(1−α)HZ a0
= 2H(2H − 1)H 2(1−α)HZ a0
(2H − 1)H 2H

=

α

β(1 − H + αH, 2H − 1).

47

Thus (74) is obtained. For the point (75) see [16].

References

[1] Azmoodeh, E. and Morlanes, G. I. (2013). Drift parameter estimation for fractional Ornstein-

Uhlenbeck process of the second kind. Statistics. DOI: 10.1080/02331888.2013.863888.

[2] Azmoodeh, E. and Viitasaari, L. (2015). Parameter estimation based on discrete observations
of fractional Ornstein-Uhlenbeck process of the second kind. Statist. Infer. Stoch. Proc. 18, no.
3, 205-227.

[3] Belfadli, R., Es-Sebaiy, K. and Ouknine, Y. (2011). Parameter Estimation for Fractional
Ornstein-Uhlenbeck Processes: Non-Ergodic Case. Frontiers in Science and Engineering (An
International Journal Edited by Hassan II Academy of Science and Technology). 1, no. 1, 1-16.

[4] Biermé, H., Bonami, A., Nourdin, I. and Peccati, G. (2012). Optimal Berry-Esséen rates on

the Wiener space: the barrier of third and fourth cumulants. ALEA 9, no. 2, 473-500.

[5] Breton, J.C. and Nourdin, I. (2008). Error bounds on the non-normal approximation of Hermite

power variations of fractional Brownian motion. Electron. Comm. Probab. 13, 482-493.

[6] Brouste, A. and Iacus, S. M. (2012). Parameter estimation for the discretely observed fractional

Ornstein-Uhlenbeck process and the Yuima R package. Comput. Stat. 28, no. 4, 1529-1547.

[7] Cénac, P. and Es-Sebaiy, K. (2015). Almost sure central limit theorems for random ratios and
applications to LSE for fractional Ornstein-Uhlenbeck processes. Probab. Math. Statist. 35, no.
2, 285-300.

[8] Cheridito, P., Kawaguchi, H. and Maejima, M. (2003). Fractional Ornstein-Uhlenbeck pro-

cesses, Electr. J. Prob. 8, 1-14.

[9] Davydov, Y.A. and Martynova, G. V. (1987). Limit behavior of multiple stochastic integral.

Statistics and control of random process.Preila, Nauka, Moscow, 55-57 (in Russian).

[10] Dobrushin, R. L. and Major, P. (1979). Non-central limit theorems for nonlinear functionals of

Gaussian ﬁelds. Z. Wahrsch. verw. Gebiete, 50, 27-52.

[11] El Machkouri, M., Es-Sebaiy, K. and Ouknine, Y. (2015). Least squares estimator for non-
ergodic OrnsteinUhlenbeck processes driven by Gaussian processes. Journal of the Korean Sta-
tistical Society, DOI: 10.1016/j.jkss.2015.12.001 (In press).

[12] El Onsy, B., Es-Sebaiy, K. and Tudor, C. (2014). Statistical analysis of the non-ergodic frac-

tional Ornstein-Uhlenbeck process of the second kind. Preprint.

[13] El Onsy, B., Es-Sebaiy, K. and Viens, F. (2014). Parameter Estimation for Ornstein-Uhlenbeck

driven by fractional Ornstein-Uhlenbeck processes. Preprint, in revision for Stochastics.

48

[14] Hu, Y. and Nualart, D. (2010). Parameter estimation for fractional Ornstein-Uhlenbeck pro-

cesses. Statist. Probab. Lett. 80, 1030-1038.

[15] Hu, Y. and Song, J. (2013). Parameter estimation for fractional Ornstein-Uhlenbeck processes
with discrete observations. F. Viens et al (eds), Malliavin Calculus and Stochastic Analysis: A
Festschrift in Honor of David Nualart, 427-442, Springer.

[16] Kaarakka, T. and Salminen, P. (2011). On fractional Ornstein-Uhlenbeck Processes. Commu-

nications on stochastic analysis 5, No. 1, 121-133.

[17] Kleptsyna, M. and Le Breton, A. (2002). Statistical analysis of the fractional Ornstein- Uhlen-

beck type process. Statist. Infer. Stoch. Proc. 5, 229-241.

[18] Kloeden, P. and Neuenkirch, A. (2007). The pathwise convergence of approximation schemes

for stochastic diﬀerential equations. LMS J. Comp. Math. 10, 235-253.

[19] Luschgy, H. and Pagès, G. (2002). Functional quantization of Gaussian processes. Journal of

Functional Analysis, 196 (2), 486-531.

[20] Neufcourt, L. and Viens, F. (2014). A third-moment theorem and precise asymptotics
for variations of stationary Gaussian sequences. In press in ALEA; preprint available at
http://arxiv.org/abs/1603.00365

[21] Neuenkirch, A. and Tindel, S. (2014). A least square-type procedure for parameter estimation
in stochastic diﬀerential equations with additive fractional noise.Statist. Infer. Stoch. Proc. 17,
no. 1, 99-120.

[22] Nourdin, I. and Peccati, G. (2015). The optimal fourth moment theorem. Proc. Amer. Math.

Soc. 143, 3123-3133.

[23] Nourdin, I., Peccati, G. and Podolskij, M. (2013). Quantitative Breuer-Major Theorems. Stoch.

Proc. Appl. 121, no. 4, 793-812.

[24] Nourdin, I. and Peccati, G. (2012). Normal approximations with Malliavin calculus :

from
Stein’s method to universality. Cambridge Tracts in Mathematics 192. Cambridge University
Press, Cambridge.

[25] Nualart, D. (2006). The Malliavin calculus and related topics. Springer-Verlag, Berlin.

[26] Nualart, D. and Peccati, G. (2005). Central limit theorems for sequences of multiple stochastic

integrals. Ann. Probab. 33, no. 1, 177-193.

[27] Tudor, C. and Viens, F. (2007). Statistical aspects of the fractional stochastic calculus. Ann.

Statist. 35, no. 3, 1183-1212.

49

