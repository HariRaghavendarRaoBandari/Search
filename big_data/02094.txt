6
1
0
2

 
r
a

M
7

 

 
 
]
I

N
.
s
c
[
 
 

1
v
4
9
0
2
0

.

3
0
6
1
:
v
i
X
r
a

Delay Bounds in Feed-Forward Networks –

A Fast and Accurate Network Calculus Solution

Steﬀen Bondorf, Paul Nikolaus, Jens B. Schmitt
Distributed Computer Systems (DISCO) Lab,

University of Kaiserslautern,

Germany

Abstract

Guaranteeing accurate worst-case bounds on the end-to-end delay that data ﬂows experience in
communication networks is required for a variety of safety-critical systems, for instance in avionics.
Deterministic Network Calculus (DNC) is a widely used method to derive such bounds. The DNC
theory has been advanced in recent years to provide ever tighter delay bounds, though this turned
out a hard problem in the general feed-forward network case. Currently, the only analysis to achieve
tight delay bounds, i.e., best possible ones, is based on an optimization formulation instead of the
usual algebraic DNC analysis. However, it has also been shown to be NP-hard and was accompanied
by a similar, yet relaxed optimization that trades tightness against computational eﬀort.
In our
article, we derive a novel, fast algebraic delay analysis that nevertheless retains a high degree of
accuracy. We show in extensive numerical experiments that our solution enables the analysis of
large-scale networks by reducing the computation time by several orders of magnitude in contrast
to the optimization analysis. Moreover, in networks where optimization is still feasible, our delay
bounds stay within close range, deviating on average by only 1.16% in our experiments.

1

Introduction

Tightly bounding maximum delays is a fundamental problem in the analysis of communication networks.
Deterministic Network Calculus (DNC) can provide such bounds, yet, it proved a hard problem in general
feed-forward networks. The evolution of the methodology resulted in two branches that only share the
DNC system description for the network.

On the one hand, there is the algebraic DNC analysis that is mainly based on the compositionality
of the min-plus convolution. Here, the network analysis is based on a straight-forward extension of
existing results for tandems of servers to a compositional sink-tree [32] and later feed-forward [31] network
analysis. The network description is transformed into a model for analysis by ascribing it in terms of
tandems and deﬁning their order of analysis.

On the other hand, there is the optimization-based DNC analysis.

It started as a compositional
analysis as well [30], yet, most recent work departed from this approach in the endeavor to derive tight
delay bounds. [9] provides a non-compositional analysis that transforms the entire DNC description of a
feed-forward network to a set of linear programs (LPs). It is currently the only analysis to achieve tight
end-to-end delays in general feed-forward networks.

The LP analysis was, however, shown to be NP-hard as the amount of LPs required to ﬁnd the exact
delay causes the computational complexity to grow (possibly super-) exponentially. Thus, it becomes
computationally infeasible to analyze networks of a reasonable size and the authors accompanied their

1

theoretical solution with a practical variant, the so-called ULP (unique linear program). It follows the
same principle of a non-compositional, optimization-based analysis, yet, the ULP trades accuracy against
computational eﬃciency by reducing the amount of LPs to a single one. In this work, we show that even
this maximum tradeoﬀ on the amount of LPs is only applicable to small networks. For example, a network
of 180 devices can already take 13 days for a complete analysis whereas a rather inaccurate algebraic
analysis requires less than 5 hours (yet the delay bounds can be oﬀ by up to 270%). Hence, DNC
currently oﬀers a tight, yet, computationally infeasible analysis and a reasonably fast, but inaccurate
analysis of feed-forward networks.

The choice of DNC analysis in the industrial context is to use the inaccurate but computationally
feasible alternative. Especially the avionics industry has embraced this methodology [17, 11, 25, 12]. In
this work, we provide a new algebraic network analysis that guarantees for more accurate delay bounds.
Moreover, its compositionality enables us to develop our new analysis into an eﬃcient algorithm that
allows analyzing feed-forward networks much faster than any other accurate DNC analysis, speeding up
the calculations by several orders of magnitude. To achieve this comprehensive solution to the problem
of calculating delay bounds in general feed-forward networks, we make the following contributions:

• A detailed analysis of the state-of-the-art DNC yields novel insights crucial for developing our novel

compositional analysis.

• We implemented our analysis as well as the ULP as an extension of the open-source DiscoDNC
tool to practically demonstrate that fast computation of accurate delay bounds is possible with
network calculus.

• In extensive benchmarks, the new analysis achieves delay bounds that deviate from the accurate

optimization analysis ULP by only 1.16% on average.

• Comprehensive numerical experiments with Internet-like topologies as well as a typical industrial
avionics network extend previous DNC assessments by the crucial aspect of computational eﬀort.

The remainder of the article is structured as follows: Section 2 presents the foundations of DNC. In
Section 3, we provide an in-depth analysis of the current DNC network analyses. Section 4 introduces
our new, accurate analysis as well as a fast algorithm for its execution. Section 5 surveys related work,
before Section 6 extensively evaluates the accuracy of delay bounds and computational eﬀort of our new
solution as well as previous proposals. Section 7 concludes the article.

2 Network Calculus Background

2.1 The System Description
Flows are characterized by functions cumulatively counting their data. They belong to the set F0 of
non-negative, wide-sense increasing functions that pass through the origin:

F0 =(cid:8) f : R → R+

(cid:12)(cid:12) f (0) = 0, ∀s ≤ t : f (s)≤ f (t)(cid:9),

∞

∞ := [0, +∞) ∪ {+∞} .
R+

We are particularly interested in the functions A(t) and A(cid:48)(t) cumulatively counting a ﬂow’s data put
into a server s and put out from s, both from the start of operation up until time t. We further demand
servers and ﬂows to preserve causality by fulﬁlling the ﬂow constraint, i.e., ∀t ∈ R+ : A(t) ≥ A(cid:48)(t).
Then, these functions allow for simple deﬁnitions of performance characteristics of a queuing system.

2

Deﬁnition 1. (Delay) Assume a ﬂow with input function A traverses a server s and results in the output
function A(cid:48). The (virtual) delay for a data unit arriving at s at time t is

D(t) = inf {τ ≥ 0 | A(t) ≤ A(cid:48)(t + τ )}.

Note, that the FIFO per µFlow assumption is crucial for the virtual delay deﬁnition. It states that
the oder of date within a single ﬂow is retained. Delay bounding argues that the expected delay is caused
by data that entered s before the data unit under consideration and is therefore served before it.

Network calculus models data arrivals with curves (from F0) that bound behavior in the interval-
time domain, i.e., whereas the function value A(t) returns the cumulative data of interval [0, t], the DNC
arrival curve for α(d) returns an upper bound on data arrivals for any duration of length d = t − 0.
Deﬁnition 2. (Arrival Curve) Let a ﬂow have input function A ∈ F0, then α ∈ F0 is an arrival curve
for A iﬀ it bounds A in any time interval of duration d, i.e.,

∀t∀d, 0 ≤ d ≤ t : A(t) − A(t − d) ≤ α(d).

For causality, we demand that arrival curves fulﬁll α(0) = 0, i.e., there are no instantaneous arrivals.

A useful basic shape for arrival curve is the so-called token bucket. These curves are from the set

FTB ⊆ F0,

FTB =

if d = 0
b + r · d otherwise

, r, b ∈ R+
∞

,

0

γr,b | γr,b(d) =
(cid:40) n(cid:94)

FmTB =

where r denotes the maximum arrival rate and b is the maximum burstiness (bucket size). A common
generalization if FTB is the set of multi-token-bucket curves FmTB

(cid:41)

γri,bi | γri,bi ∈ FTB

⊆ F0.

i=1

These are able to represent diﬀerent traﬃc constraints for diﬀerent time scales [36], each deﬁned by a
token bucket.

Scheduling and buﬀering at a server result in the output function A(cid:48)(t). DNC captures the minimum

forwarding capabilities that lead to A(cid:48) in interval time as well
Deﬁnition 3. (Service Curve) If the service provided by a server s for a given input A results in an
output A(cid:48), then s is said to oﬀer a service curve β ∈ F0 iﬀ

∀t : A(cid:48)(t) ≥ inf
0≤d≤t

{A(t − d) + β(d)}.

A number of servers fulﬁll a stricter deﬁnition of service curves by considering their internal state in

addition to input A.

Deﬁnition 4. (Backlogged Period) A server s is backlogged during period(cid:3)t, t(cid:2) if t ∈ {t(cid:48) ≤ t | A(t) = A(cid:48)(t)}

and t ∈ {t(cid:48)(cid:48) ≥ t | A(t) = A(cid:48)(t)}.

Servers oﬀering strict service guarantees have a higher output during backlogged periods.

Deﬁnition 5. (Strict Service Curve) If, during any backlogged period of duration d, a server s with
input A guarantees an output of at least β(d), it oﬀers a strict service curve β ∈ F0.

3

(a) Device Graph

(b) Server Graph

Figure 1: A graph of network devices with output buﬀering (Subﬁgure 1a) and its transformation to
directly connected servers (Subﬁgure 1b).

A basic shape for service curves is the rate-latency curve deﬁned by the set FTB ⊆ F0,

where R denotes the minimum service rate and T is the maximum latency. Multi-rate-latency curves
are deﬁned by the pointwise maximum over a set of rate latencies

FRL =(cid:8)βR,T

FmRL =

j=1

(cid:9),

∞

(cid:12)(cid:12) βR,T (d) = max{0, R·(d − T )}, R, T ∈R+
 ⊆ F0.
 m(cid:95)

(cid:12)(cid:12) βRj ,Tj ∈ FRL

βRj ,Tj

2.2 The Network

The Topology

Data communication networks are commonly modeled as graphs where nodes represent individual devices
like a router or a switch. These devices can have multiple outputs to connect to other devices (Figure 1a).
This common depiction does, however, not suit network calculus’ queueing analysis well. DNC therefore
transforms such a device graph to its so-called server graph representation for analysis. Assuming that
a device’s input buﬀer is served at line speed, queueing eﬀects manifest at the output buﬀers. These
are modeled by the server graph’s servers [3, 5] (see Figure 1b). Output buﬀering can, e.g., be found in
AFDX (Avionics Full-Duplex Switched Ethernet) equipment (e.g., see [21] where this conversion is called
transposition). In wireless sensor networks, there is usually a single transmitter per sensor node (server)
whose transmission range deﬁnes the server graph’s links [3, 5, 20].

Figure 1 also illustrates that information about the device’s sub-components may be lost during the
transformation. Especially, the highly optimized switching fabric inside network devices is, however,
crucial for our considerations. Although the server most likely works oﬀ queued data in a FIFO manner,
this fabric interconnecting input ports with output ports can rearrange ﬂows [15]. In the server graph,
device ports (i.e., servers) do not share a common switching fabric component; they are directly connected
to each other. The impact of switching fabrics can only be captured by departing from FIFO multiplexing
servers towards more general arbitrary multiplexing behavior. Data units of individual ﬂows do not
overtake each other in switching fabrics, i.e., the FIFO per µFlow property is retained. We assume
directed links in both graph representations, i.e., full duplex links need to be spilt up into two directed
links before the device graph can be transformed. In this article, we will use the term network to refer
to the server graphs and the data ﬂows traversing it.

4

  ......  ......  ......The Feed-forward Property

Another assumption of most current deterministic network calculus analyses is the absence of cyclic
dependencies between ﬂows. Work departing from this assumption can be found in [24, 19] but is not
covered by this article. Instead, we focus on networks that guarantee the feed-forward property by design.
We use the turn prohibition algorithm [33] to break potential cycles when transforming the device graph
into the server graph.

2.3 Algebraic Network Calculus
DNC was cast in a (min, +)-algebraic framework in [22, 14]. We will ﬁrst depict the basic operations
and then present their composition for ﬂow analysis in feed-forward networks.

2.3.1 Operations

These operations allow to manipulate arrival and service curves while retaining worst-case semantics.

Deﬁnition 6. ((min,+)-Operations) The (min,+) aggregation, convolution and deconvolution of two
functions f, g ∈ F0 are deﬁned as follows:

Aggregation:

Convolution:

Deconvolution:

(f + g) (t) = f (t) + g(t)
(f ⊗ g) (t) =
inf
0≤s≤t
(f (cid:11) g) (t) = sup
u≥0

{f (t − s) + g(s)}
{f (t + u) − g(u)}

The service curve deﬁnition then translates to A(cid:48) ≥ A ⊗ β, the arrival curve deﬁnition to A ⊗ α ≥ A,

and performance characteristics can be bounded with the deconvolution α (cid:11) β.
Theorem 7. (Performance Bounds) Consider a server s that oﬀers a service curve β. Assume a ﬂow
f with arrival curve αf traverses s. Then we obtain the following bounds for f:
• (Flow) Delay Bound D

∀t ∈ R+ : Df (t) ≤ inf(cid:8)s ≥ 0

(cid:12)(cid:12)(cid:0)αf (cid:11) β(cid:1) (−s) ≤ 0(cid:9)

= h(cid:0)αf , β(cid:1) =: Df

where h(αf , β) denotes the (maximum) horizontal deviation between α and β. We abbreviate delay bounds
with Df as they are valid independent of parameter t.
• Output Bound α(cid:48)

∀d ∈ R+ : (cid:0)αf(cid:1)(cid:48) (d) =

0
(cid:0)αf (cid:11) β(cid:1) (d) otherwise

if d = 0

Note, that α(cid:48) is an arrival curve for A(cid:48) and thus it is required to pass through the origin1.

Note, that this backlogged period bound requires a strict service curve and an eventual utilization
strictly smaller than 1, i.e., limd→∞ α(d) < limd→∞ β(d). The algebraic properties of these operations
can be found in [22].
DNC also oﬀers operations for compound analysis of servers as well as the separate analysis of
individual ﬂows. Table 1 provides a more comprehensive notation scheme for DNC network modeling
and performance analysis.

1In a slight abuse of notation, we will use the symbol (cid:11) for both, deconvolution and output bounding.

5

Quantiﬁer Deﬁnition

foi The analyzed ﬂow of interest

F, G Generic ﬂow aggregates

[fn, ..., fm] Flow aggregate containing ﬂows fn, ..., fm

αf , α
, α
αf
s

F Arrival curve of ﬂow f, set of ﬂows F
F
s

Arrival bound of f, F at server s

(cid:104)sx, . . . , sy(cid:105) Tandem of consecutive servers from sx to sy
βs
βl.o.f , βl.o.F

Service curve of server s
Left-over service curve of of f, F

Table 1: Network Calculus Notation.

Theorem 8. (Concatenation of Servers) Consider a ﬂow (aggregate) F crossing a tandem of servers
T = (cid:104)s1, . . . , sn(cid:105) and assume that each si, i ∈ {1, . . . , n}, oﬀers a service curve βsi. The overall service
curve oﬀered to F is their concatenation by convolution

n(cid:79)

i=1

βs1 ⊗ . . . ⊗ βsn =

βsi = βT

The service resulting form the concatenation of strict service curves, βT

, is not necessarily strict, too.
It cannot be used to derive a backlogged period bound of the concatenated system [8, 16]. This imposes
challenges if the FIFO per µFlow property cannot be assumed [27, 29]. Also note, that convolution is
commutative, i.e., the order of servers in (cid:104)s1, . . . , sn(cid:105) cannot be reconstructed from βT
service curve:

The worst-case share of data a ﬂow (aggregate) receives from a server is lower bounded by the left-over

.

Theorem 9. (Left-Over Service Curve) Consider a server s that oﬀers a strict service curve βs. Let s
F1, respectively.
be crossed by ﬂow (aggregate) F0 and ﬂow (aggregate) F1 with arrival curves α
Then F1’s worst-case residual service share under arbitrary multiplexing at s, i.e., its left-over service
curve at s, is

F0 and α

βl.o.F1

s

= βs (cid:9) α

F0

where (β (cid:9) α) (d) := sup0≤u≤d {(β − α) (u)} denotes the non-decreasing upper closure of (β − α) (d).

For arbitrary multiplexing servers, the result of this subtraction is not necessarily strict either, i.e.,
consecutive left-over operations are not permitted. However, aggregating arrival curves before subtraction
from service is backed by the DNC.

2.3.2 Tandem Analysis

For network calculus, the shift from single server analysis to end-to-end ﬂow analysis constitutes a big
evolutional leap forward. Building the delay analysis around a speciﬁc ﬂow of interest (foi) shifted its view
towards the tandem of servers crossed by this ﬂow. There, the order of operations proved important for
accuracy improvements. The ﬁrst tandem analysis, Separate Flow Analysis (SFA), constitutes a straight-
forward application of Theorem 9 and Theorem 8: In order to derive the foi’s end-to-end left-over service
curve, its cross-traﬃc is subtracted server by server and then the resulting βl.o.s are concatenated. This
server-local analysis approach has a crucial disadvantage when cross-ﬂows share a longer (sub-)path with
the ﬂow of interest (cf. xf2 in Figure 2a). Then, multiplexing with cross-traﬃc appears multiple times in
the derivation. The so-called Pay Multiplexing Only Once (PMOO) analysis [31] tackles this problem.
It provides a single-step left-over service curve operation for tandems. Internally, the service is convolved
before cross-traﬃc is subtracted. This operation requires arrival curves to be from the set FmTB and

6

(a) Minimal network suﬀering a composition penalty.

(b) Figure 2a’s SFA-internal model.

(c) Figure 2a’s PMOO-internal model.

Figure 2: Analysis models for SFA and PMOO analysis.
Interpretation: Boxes depict tandems for βl.o.
derivation and arrows depict ﬂows. Flows pointing at a box are considered in βl.o., crossing a box means using
its βl.o. to bound the ﬂow’s worst-case shape at the output of the box.

service curves from FmRL. While it results in more accurate bounds in many scenarios, [30] proved that
the SFA can outperform the PMOO analysis if servers at the end of a tandem provide more service.

2.3.3 Compositional Feed-forward Analysis

Evolving the algebraic DNC to a feed-forward network analysis heavily builds on these tandem analysis
results. Conceptually, we can split a feed-forward analysis into two steps [5]:

i) First, the analysis abstracts from the feed-forward network to the analyzed ﬂow’s tandem of servers.

This step is enabled by bounding the arrivals of cross-traﬃc at the locations of interference.

ii) A tandem analysis on the foi’s path constitutes the second step. The ﬂow’s end-to-end service curve

is derived and the delay bound is computed.

Whereas the tandem to analyze in the second step is known from the start, the tandems in the second
step need to be deﬁned. I.e., the network must to be decomposed into tandems that are analyzed in
a speciﬁc order. The decomposition depends on the applied analysis. E.g., Figure 2a depicts a small
network where the foi has two cross-ﬂows, xf 1 and xf 2.
In an additional step, the SFA decomposes
each ﬂow’s paths into smallest possible tandems (i.e., servers), even the foi’s path. SFA then applies
Theorems 9 and 8 (Figure 2b). In contrast, the PMOO analysis does not decompose the foi’s path any
further. In step 2 of the compositional analysis it also decomposes the network into longest possible
tandems to apply its left-over service curve derivation to (Figure 2c).

7

s0s1s2xf1xf2foixf1 l.o.xf2s1xf2 l.o.fois1 l.o.fois2 l.o.xf1s0 l.o.xf2s0foixf1xf2 l.o.xf1s0 l.o.xf2s0 l.o.foihs1,s2ifoi2.4 Optimization-based Network Calculus
In quest of tight delay bounds, Schmitt et al. propose in [30] to formulate an optimization problem
from the tandem’s DNC description. Subsequently, Bouillard et al. extended this work towards a non-
compositional network analysis [9]. It transforms the entire network into a set of linear programs (LPs).
Each LP models exactly one potential entanglement of backlogged periods in the network. Like the
PMOO analysis, the LP analysis requires arrival curves to be from the set FmTB and service curves
from FmRL. The maximum of all LP solutions constitutes the foi’s exact delay bound. Therefore, an
exhaustive modeling of the network in terms of linear programs as well as solving them is necessary in
order to derive the only valid delay bound (which is tight). In fact, [9] also shows that this approach is
NP-hard. Further examples following this DNC branch are presented in [18, 10, 37].

3 State of the Art of DNC

in Feed-forward Networks – An Analysis

In this section, we investigate in detail where existing DNC delay analyses for feed-forward networks are
lacking.

3.1 Optimization-based DNC
The delay analysis of [9] proceeds as follows: For the given ﬂow of interest, starting at its sink server,
the dependencies between backlogged periods at the network’s servers are established. This is achieved
by recursively tracing all ﬂows. The step results in a partial order relating consecutive hops of the
network’s ﬂows. The partial order is then extended to the set of all total orders that are compatible
with it. This step relates the backlogged periods of (partially) parallel paths with each other. It is prone
to a combinatorial explosion and constitutes the underlying reason for this DNC analysis’ NP-hardness.
Each total order is then used to set up a linear program (LP) with constraints covering, among others,
the network description’s arrival curves and service curves.

tree, the number of LPs is lower bounded by Ω(cid:0)(cid:0) n

2

Let us brieﬂy discuss on the number of LPs that have to be solved: In the best case, we have a pure
tandem network of n servers and then a single LP results; in the worst case, we have a so-called fat tree
with one root node and n− 1 leaf nodes directly connected to it, resulting in (n− 1)! LPs. In a full binary

(cid:1)!(cid:1). The latter fact can be derived from a result by

Ruskey [28]. In general, calculating the number of total orders being compatible with a given partial
order is itself not a simple problem. One solution is the Varol-Rotem algorithm [35]; we implemented
this algorithm to provide some numbers for the case of full k-ary trees in Table 2. It is obvious that the
computational eﬀort to solve such large numbers of LPs becomes quickly prohibitive for even moderate
network sizes. Being aware of the potential combinatorial explosion, Bouillard et al. suggest a more

Outdegree k

0
1
1
1
1

1
1
2
6
24

1
2
3
4

Height h
2
1
80

7, 484, 400
3.89 · 1015

3
1

21, 964, 800
3.54 · 1037
1.12 · 10110

Table 2: Number of LPs to solve for full k-ary trees of moderate size. For instance, for a height h = 3
k−1 = 85 nodes but already yields 1.12· 10110 diﬀerent
and outdegree of k = 4 the tree has only n = k(h+1)−1
LPs.

8

(a) Network Analysis Time.

(b) Delay Bound Accuracy.

Figure 3: Network analysis time (Subﬁgure 3a) and delay bound accuracy (Subﬁgure 3b) of feed-forward
analyses in [9]: While SFA is considerably faster, its delay bounds deviate from the ULP bounds by
≈ 21% on average.

eﬃcient optimization formulation [9]. It is solely based on the partial order of backlogged periods without
extending it to the set of compatible total orders. Obviously, this circumvents the combinatorial explosion
in the number of LPs, but results in a unique LP (ULP). The ULP does not relate the backlogged periods
of (partially) parallel paths with each other. In fact, due to the shared network model and the lack of
global knowledge, it employs the same worst-case assumptions as algebraic calculus analyses do. Thus,
the ULP does not result in exact bounds anymore, however, it is shown in [9] to stay very close to the
LP result in an example network. This observation raises hope for computational feasibility in larger
networks. To further investigate this, we implemented the ULP for feed-forward network analysis and
extended the evaluation found in [9] to Internet-like topologies, an avionics network topology, and also
measured the previously not evaluated computational eﬀort to gain more detailed insights on how the
analyses compare. As a lookahead to the evaluation (see Section 6), Figure 3a depicts the time to analyze
entire Internet-like networks; comparing the ULP with the SFA as in, e.g., [9, 7]. The results defeat the
hope in the ULP as its analysis time increases fast with the network size, reaching 13 days at less than
200 devices. Thus, the ULP becomes computationally infeasible to apply, even though it is more eﬃcient
than the LP it was derived from. The SFA ﬁnishes analyzing the same networks in just a fraction of time,
but with much worse delay bounds. Figure 3b depicts the deviation of the SFA delay bounds from the
respective ULP bounds. In our evaluation of 12376 ﬂows across nine networks of diﬀerent size, average
deviation is ≈ 21% and the maximum is as large as 270%.

Current DNC analyses for feed-forward networks thus provide the choice between a computationally
barely feasible, yet accurate optimization approach and a set of feasible, but inaccurate compositional
analyses. We decided to stay with the computationally attractive compositional analysis. For improving
them, we ﬁrst reveal previously unknown weaknesses degrading their accuracy. As we show later, they
are key to a fast and accurate algebraic DNC solution.

3.2 Compositional, Algebraic DNC
We have identiﬁed two new crucial problems with the network’s decomposition into tandems that we
summarize in the composition penalty of algebraic network calculus. They are both caused by the tandem
analyses of Section 2.3.2 – thus they can occur independently of the rejoining ﬂows problem motivated

9

Network devicesNetwork analysis time [hours]20406080100120140160    012243648ULPSFA0−1010−2020−3030−4040−50>50Delay bound deviation [%]Density [%]051015202530SFAin [9]. That problem is caused by the overall analysis procedure given in Section 2.3.3.

Cross-ﬂow Segregation Enforced by Tandem Analyses

The PMOO left-over service curve derivation [31] was constructed to consider shared sub-paths between
the ﬂow of interest and its cross-ﬂows. It demands a distinct arrival curve for each cross-ﬂow (aggregate)
sharing a speciﬁc sub-path. I.e., if two cross-ﬂows xf1 and xf2 interfere in two diﬀerent sub-paths they
require segregate arrival bounding [6]. This procedure causes problems in case these cross-ﬂows share
hops apart from the ﬂow of interest’s path. There, they cannot be aggregated; they must be considered
mutual interference. Figure 2c illustrates this problem. Cross-ﬂows xf1 and xf2 fulﬁll the criteria for
= βs0 (cid:9) αxf2
segregate arrival bounding and their respective left-over service curves at s0 are βl.o.xf1
= βs0 (cid:9) αxf1. The cross-traﬃc arrival bound derivation will have more than one cross-traﬃc
and βl.o.xf2
burstiness for each of the interfering ﬂows xf1 and xf2.

s0

s0

Whereas the PMOO explicitly enforces cross-ﬂow segregation, the SFA can have various degrees of
aggregation and separation within its internal model of the network. The SFA proceeds hop-by-hop, i.e.,
in terms of the PMOO’s sub-path sharing point of view, it can aggregate all cross-ﬂows sharing a single
hop on the ﬂow of interest’s path. Consider Figure 2a’s network again: On the foi’s ﬁrst hop, s1, SFA
allows to aggregately bound the arrivals of xf1 and xf2; it can prevent the PMOO’s problem of mutual
interference here2. Yet, at s2, only xf2 is present and thus a segregated arrival bounding is initiated. In
contrast to the previous hop, the analysis needs to pessimistically assume mutual interference between xf1
= βs1 (cid:9) αxf1
and xf2 at s1 as well as s2. In addition to the above βl.o.xf1
,
i.e., another burst term appears in the derivation.

, we also get βl.o.xf2

and βl.o.xf2

s0

s0

s1

s1

Decisions on Incomplete Knowledge

In [30], the authors show that knowledge of the crossed servers’ sequence is lost in the PMOO analysis.
The SFA, in contrast, retains this knowledge due to its hop-by-hop procedure. This allows the SFA to
outperform the PMOO analysis on tandems where βl.o. curves get considerably faster to the end of the
tandem. In feed-forward networks, either applying the SFA or the PMOO analysis is the ﬁrst decision
to take. That means, the decision does not have the βl.o. curves at its disposal – they remain unknown
until the very of the chosen analysis. They cannot be derived earlier because cross-ﬂows change their
shape due to their distinct paths through the network. These changes must be traced in the step 1 of
the analysis (see Section 2.3.3). Even if all curves – arrival curves and service curves – were equal, their
algebraic manipulation lets all this homogeneity vanish during the analysis. Thus, cross-ﬂows have to
be traced completely. Eventually recognizing the analysis can exploit the sequence of servers better,
i.e., apply the other analysis to decompose the network diﬀerently, requires another, entire feed-forward
analysis of the network.

As already indicated, each compositional analysis has its characteristic combination of the above
problems. They result in a composition penalty whose impact depends on the actual network to be ana-
lyzed. Therefore, feed-forward analyses can outperform each other in more cases than tandem analyses
do.
Claim 10. (Network Analysis: SFA vs. PMOO bounds) In feed-forward networks, SFA and PMOO
analysis can outperform each other, depending on the servers in the front of the ﬂow of interest’s path.
This is an extension of the observation of [30] where it was shown that these analyses can outperform

each other on a tandem, with the servers at then end being crucial.

2Note, that the SFA presented by Bouillard in [7] that is depicted in Figure 2b does not aggregate the cross-ﬂows at s1

either. It always enforces a segregated cross-ﬂow arrival bounding.

10

Figure 4: Delay bounds under increasing Rs1
or becomes large.

: TMnew outperforms existing analyses when Rs1

is small

as well as strict service curves βs0 = βRs0 ,Ts0

,
, αxf2 = γrxf2 ,0
Proof. Consider the network setting of Figure 2a and assume arrival curves αxf1 = γrxf1 ,0
, βs1 = βRs1 ,0, and βs2 = βRs2 ,0. For a ﬁnite
and αfoi = γrfoi,0
delay bounds let Rsm ≥ rxf1 + rxf2 + rfoi, m ∈ {0, 1, 2}, and let Ts0 > 0 for positive burstiness increase of
become positive for each arrival bounding AB ∈ {SFA, PMOO}
the cross-ﬂows. I.e., the burst terms bABF
of any cross-ﬂow (aggregate) F ∈ {xf1, xf2, [xf1, xf2]} at servers s1 and s2.

In this simple setting, the ﬂow of interest’s delay bound is the βl.o.foi
(cid:104)s1,s2(cid:105)

. There-
fore, we derive the latency terms for both analyses as depicted in Figures 2b and 2c. The SFA left-over
latency, abbreviated T l.o.SFA
(cid:104)s1,s2(cid:105)

, respectively the delay DSFA, are:

’s latency term T l.o.foi
(cid:104)s1,s2(cid:105)

sn

bSFAxf1
+ bSFAxf2
s1
Rs1− rxf1 − rxf2
The PMOO left-over latency T l.o.PMOO and delay DPMOO are

T l.o.SFA = DSFA =

s1

+

bSFAxf2
s2
Rs2− rxf2

.

T l.o. PMOO = DPMOO =

Next, we state conditions for DPMOO ≤ DSFA:
1) Rs1−rxf1−rxf2 > Rs2−rxf2:

Rs1− rxf1 − rxf2

Rs2− rxf2

≤

b

2) Rs2− rxf2 ≥ Rs1− rxf1 − rxf2:

bPMOOxf1
s1

(Rs1− rxf1 − rxf2) ∧ (Rs2− rxf2 )

.

+ bPMOOxf2

s1

bSFAxf1
s1
PMOOxf1
+ b
s1

+ bSFAxf2
− b

PMOOxf2
s1

s1

SFAxf2
s2

Rs2−rxf2

Rs1−rxf1−rxf2

≤

PMOOxf1
s1

b

−b

bSFAxf2
s2
SFAxf1
+b
s1

PMOOxf2
s1

−b

SFAxf2
s1

Neither condition is strictly fulﬁlled as both depend on the service rates at s1 and s2. Figure 4 shows
the respective delay bounds when increasing Rs1

(ﬁxing Rs2 = Rs0 = 5 and Ts0 = 1).

We will use these detailed insights we obtained on the composition penalty to derive a new, fast and
accurate analysis that combines the strengths of the existing compositional analyses while circumventing
their weaknesses.

11

0.51.01.52.02.53.0Server 1's rateDelay bound3.04.56.07.59.010.512.013.515.016.518.019.5SFATMnewPMOOFigure 5: Additional TMA-internal model for Figure 2a.

4 The Tandem Matching Analysis

In this section, we propose a feed-forward network analysis that achieves more accurate delay bounds by
compiling the network description into a model best suited for compositional analysis. I.e., we consider
the knowledge obtained above in order to minimize the composition penalty in our new Tandem Matching
Analysis (TMA).

4.1 Exhaustive Tandem Matching
Currently, there is no generic tandem decomposition scheme for the algebraic NC analysis. The com-
positional procedure depends on the choice of tandem analysis (see Section 2.3.3 as well as Figures 2b
and 2c). The SFA ﬁrst matches shortest possible sub-tandems in an additional step, whereas the PMOO
starts with the ﬂow of interest’s entire path and then recursively matches longest possible tandems [6].
We start by illustrating that the tandem matching implied by the existing analyses is harmfully
restrictive. Figure 5 depicts the tandem matching alternative for our sample network of Figure 2a that
is currently neglected, TMnew. It consists of the following left-over service curve derivations:

.

s1

• βl.o.foi
• β

l.o.xf2
(cid:104)s0,s1(cid:105)
l.o.[xf1,xf2]
s0
sumptions.

• β

s2

⊗ βl.o.foi
a tandem analysis bounding xf2 at s2 – xf1 is considered cross-traﬃc due to point one.

– an analysis equal to SFA; with cross-ﬂow segregation enforced by βl.o.foi

= βl.o.foi
(cid:104)s1,s2(cid:105)

s1

exploits aggregate cross-traﬃc bounding at s1, circumventing mutual interference as-

Note, that these three left-over service curves encompass two alternative analysis models. The choice of
’s tandem analysis remains open. It can either be SFA or PMOO. For the ease of presentation,
l.o.xf2
β
(cid:104)s0,s1(cid:105)
we will treat this alternative as a single tandem matching.

In terms of Section 2.3.3’s concept of a compositional feed-forward analysis. The ﬁrst bullet point is
the foi analysis of step 1 and the latter two points are part of the cross-traﬃc arrival bounding of step 2
– together, we thus subsume them in the Tandem Matching Arrival Bounding (TMAB).

Next, we show that the new alternative can actually achieve more accurate delay bounds. That
means, the composition penalty due to cross-traﬃc segregation and mutual interference assumptions of
our new tandem matching alternative TMnew can be smaller than those of the PMOO analysis or the
SFA.

Claim 11. (Network Analysis: TMA vs. SFA vs. PMOO bounds) The tandem matching analysis TMA
can outperform the existing compositional feed-forward analyses SFA and PMOO.

Proof. Assume the same setting as in Claim 10, extended by the tandem matching arrival bounding
TMAB. Then, the tandem matching alternative TMnew depicted in Figure 5 has a delay bound of

DTMnew =

TMAB[xf1,xf2]
b
s1
Rs1− rxf1 − rxf2

+

bTMABxf2
s2
Rs2− rxf2

.

12

Figure 6: TMnew can arbitrarily outperform PMOO and SFA in the network of Figure 2a as it scales
better with increasing bxf1. Sample parameter setting: βs0 = β25,5, βs1 = β25,0, βs2 = β3,5, αfoi = γ0.5,5,
αxf1 = γ2.5,bxf1

, αxf2 = γ2.5,5.

The relations between DTMnew, DSFA and DPMOO are:
1) DTMnew ≤ DSFA, iﬀ

Rs2− rxf2

Rs1− rxf1 − rxf2

≤

bSFAxf2
s2
TMAB[xf1,xf2]
s1

b

− bTMABxf2
− b
− b

s2
SFAxf1
s1

SFAxf2
s1

2) DTMnew ≤ DPMOO:, iﬀ
a) Rs1− rxf1− rxf2 > Rs2− rxf2:

Rs2− rxf2

Rs1− rxf1 − rxf2

≤ bPMOOxf1

s1

− bTMABxf2

s2

s1

+ bPMOOxf2
TMAB[xf1,xf2]
b
s1

b) Rs2− rxf2 ≥ Rs1− rxf1− rxf2:

Rs1− rxf1 − rxf2

Rs2− rxf2

≤ bPMOOxf1

s1

+ bPMOOxf2

− b

TMAB[xf1,xf2]
s1

s1
b

TMABxf2
s2

The observations in Claim 10 hold for the TMA as well: Relations 1), 2a), and 2b) reﬂect the
inﬂuence of the rates on the ﬂow of interest’s path (left terms). A large service rate Rs1
can, in fact,
best be exploited by the new tandem matching alternative. TMnew can thus simultaneously outperform
both existing analyses (see Figure 4). Overall, the tandem matching alternatives have no strict ordering
with respect to delay bounds; each analysis can potentially outperform the others.

Remark 12. Considering the parameters omitted for the ease of presentation, the tandem matching
analysis can arbitrarily outperform SFA and PMOO simultaneously. A detailed example is given in
Figure 6.

We exploit this insight to improve the accuracy of compositional network calculus delay bounds.
Claim 11 also exhibits that the alternatives’ results depend on the actual parameters, which in turn,
recursively depend on accurate derivation themselves. Therefore, the best tandem matching alternative
cannot be derived from the given network description in a static fashion. To that end, we propose to
separate the tandem matching from the analysis and execute it in an exhaustive fashion. Exhaustive
tandem matching generates the entire set of tandem matching alternatives for a feed-forward network.
This approach is inspired by the LP analysis as it creates a comprehensive search space for the analysis.

13

2004006008001000xf1's burstDelay bound121416181101121141161181201221241SFAPMOOTMnewOn the individual tandems, we apply the PMOO left-over service curves – the additional server-by-server
matching of SFA is now explicitly executed by the exhaustive tandem matching. In our search space of
all tandem matchings, we then try to ﬁnd the alternative the minimal composition penalty – similar to
optimization searching for the best result in the constrained region of valid bounds. This new method is
applicable to any feed-forward network. In the following, we use the term TMA to refer to the exhaustive
tandem matching analysis.

Exhaustive tandem matching generalizes all previous algebraic network calculus analyses by making
the step from the network description to the analysis’ internal model more explicit. TMAB follows the
objective to maximize aggregation during the arrival bounding, i.e., it does not artiﬁcially segregate cross-
ﬂows. The PMOO proceeds alike while Bouillard proposes to obtain SFA’s cross-traﬃc arrival bounds by
executing a separate SFA arrival bounding for each cross-ﬂow [7]. In [6], it was shown that aggregating
ﬂows for the SFA-corresponding PBOO arrival bounding results in better cross-traﬃc arrival bounds.
Therefore, the TMA generalizes the given SFA on the ﬂow of interest’s path and TMAB additionally
improves its cross-traﬃc arrival bounding.

An obvious concern about the exhaustive TMA is its computational eﬀort, so let us discuss this in

detail next.

Computational Eﬀort

The computational eﬀort of exhaustive tandem matching becomes apparent when constructing the set
of all tandem matching alternatives, i.e., the entire TMA-internal model of the network that is used
to derive the delay bound. We exemplify the construction on a tandem network with n servers and m
ﬂows; Figure 7 illustrates the steps we take and the amount of tandem matching alternatives in several,
repeating steps of this procedure. Assume the worst case where each server is crossed by every ﬂow,
yet, equal to the SFA, cross ﬂows are not aggregately bounded. Let us start on the ﬂow of interest’s
path – we call this tandem Torig = (cid:104)s1, . . . , sn(cid:105). The number of diﬀerent matching alternatives for Torig
is already 2n−1. As such an alternative derives the foi’s end-to-end delay bound, each has between 1
and n distinct sub-tandems in order to cover all servers on Torig. In our example, we always proceed with
tandem matching alternatives that separate the last hop and we bound a single segregated cross-ﬂow’s
arrivals at this server. We call the recursive tracing to bound cross-traﬃc arrivals Tandem Matching
Arrival Bounding (TMAB). At level 2, the foi has m − 1 cross-ﬂows, deﬁning the search space in the
ﬁrst TMAB step. To bound a single cross ﬂow’s arrival at level 2, a TMAB is applied to its path of
length n − 1, resulting in 2n−2 alternatives (level 3). Again, it is necessary to bound this ﬂow’s cross-
traﬃc arrivals recursively (level 4). As the cross-ﬂow under consideration does not interfere with itself
and as we are on the foi’s path, there are m − 2 cross-ﬂows to bound. In contrast to the shortening
path lengths, this number will not decline until the arrival bounding terminates. We skip the remaining
steps as they are repetitions of level 3 (with increasing x ≤ n in 2n−x) and level 4. Continuing on this
trajectory through the search tree, bounding a single cross-ﬂow of a single sub-tandem of a single tandem
matching alternative of Torig already triggers (m − 1) + (n − 1)· (m − 2) TMABs on the evenly numbered
levels. Levels with odd numbers (≥ 3) scale this number by 2(n−2)! TMA matching alternative until we
eventually reach the end of the tandem.

Obviously, TMA is prone to a combinatorial explosion similar to the extension of partial orders into
compatible total orders as required for the LP optimization. However, in contrast to LP, each tandem
matching alternative of Torig enables to derive a valid delay bound. In principle, this would allow for a
simple, yet ﬂexible tradeoﬀ between computational eﬀort and delay bound accuracy. However, we opted
for the exhaustive tandem matching and designed an eﬃcient algorithm which keeps the computational

14

Figure 7: Search tree [1] for the n servers, m ﬂows sample tandem representing all required arrival
boundings.

eﬀort still tolerable by exploiting the compositionality of the TMA.

4.2 The Eﬃcient TMA Algorithm
In this section, we immediately depart from separately deriving the tandem matchings before comput-
ing their results. This separation was inspired by the optimization-based analyses. They must do so
in order to interface DNC with the linear program solver. Algebraic DNC needn’t do so and we show
that integrating both parts allows for fast delay bound computations. The integration allows our ef-
ﬁcient TMA algorithm to creates a single, large search space instead of the separate search trees of
Figure 7. Intermediate results can then be shared to reduce the amount and length of trajectories in the
search. Nonetheless, our eﬃcient TMA depicted in Algorithm 1 still guarantees for the most accurate
compositional, tandem matching delay bounds in feed-forward networks.

Algorithm 1 derives a ﬂow of interest’s alternative end-to-end service curves under tandem matching
is invoked with the ﬂow of interest’s path P, i.e., Torig := P, and the foi
as follows: First, getBl.o.F
Torig
itself – the algorithm needs to reverse the conceptual two steps of an analysis presented in Section 2.3.3.
P constitutes the ﬁrst tandem to match with 2n−1 disjoint sub-tandems, where n denotes the number
of server on P. For every sub-tandem created, we then derive the cross-traﬃc arrivals with tandem
matching arrival bounding (TMAB, lines 32 – 37). Thus, we derive all tandem matching alternatives
within this recursive arrival bounding method. After the arrival bounding recursion has terminated
(guaranteed by the cycle-free feed-forward network and ﬂows of ﬁnite length), its result is used to derive
the foi’s left-over service curves by convolving the matched sub-tandems’ βl.o. curves – similar to SFA but
βl.o. are not necessary single server left-over service. In a subsequent step (not depicted in Algorithm 1),
we derive delay bounds for all alternative tandem matchings of P. In contrast to the individual linear
programs of the LP analysis, all are valid. I.e., we chose the smallest as ﬁnal delay bound.

Computational Eﬃciency

The compositionality of the TMA enables several eﬃciency improvements:

1. The aggregate cross-traﬃc arrival bounding on tandems shared by multiple ﬂows (lines 32 – 43,
Tshared) naturally counteracts cross-traﬃc segregation. Aggregately bounding cross-ﬂows reduces
the mutual interference assumption vastly and thus prevents recursively bounding cross-ﬂows of
cross-ﬂows; all with exhaustive TMAB.

2. Every recursion level has its Tshared that TMAB matches tandems to. Each of the resulting left-over
service curves yields a cross-traﬃc arrival bound to be used in the previous recursion level. The
second eﬃciency improvement is to convolve all of the alternative arrival bounds when Tshared is

15

Algorithm 1: Eﬃcient TMA Algorithm.
Torig (Tandem Torig, Flow set F)
1 getBl.o.F
/* Disjoint subtandem divisions of Torig */
2
{T1, . . . ,T2n} = getSubtandems(Torig);
3
foreach Subtandem sequence T ∈ {T1, . . . ,T2n} do

foreach Subtandem T ∈ T do

T

T

;

T

);

end

= TMArrivalBounding(T, F);
= PMOOβl.o.(T,AF
T );
⊗= βl.o.F

AF
βl.o.F
T
βl.o.F
T
end
Bl.o.F
.put(βl.o.F
Torig
11
12 return Bl.o.F
Torig
13 TMArrivalBounding( Tandem T , Flow set F)
14
15

/* Eﬃciency improvement: Check for cached AF
try{ return getCacheEntry(T, F)}
/* Cross-traﬃc segregation */
G = xtxSegregation(T, F);
foreach xtxGroup G ∈ G do

T

*/

T

/* Arrival curve for G’s source ﬂows */
AG
src = getSourceFlowαs(G);
.put(AG
AF
/* Flow aggregation requires equal inlinks */
foreach Link l ∈ T .getInLinks() do

src);

=(cid:0)αG

s = l.getSource();
αG
T
AF

.put(αG

(cid:1)(cid:48) = OutputBound(s, G);

);

s

T

T

end

4
5
6
7
8
9
10

16
17

18
19
20
21

22
23
24

25
26
27
28

35
36

37
38

(cid:1)

end
/* Eﬃciency improvement: Cache AF

addCacheEntry(cid:0)AF

29
30
31 return AF
32 OutputBound( Server s, Flow set F)
33
34

T

T

T

*/

(Tshared, F);

= getBl.o.F
Torig

/* Aggregate ﬂows of F on shared servers */
Tshared = getSharedServers(s, F);
/* Compute and store left-over service curves */
Bl.o.F
Tshared
/* Get arrival bound of ﬂows in G at Tshared’s start */
= αG
αTshared
Tshared.getSource()
Tshared ∈ Bl.o.F
foreach βl.o.F
(cid:1)(cid:48) ⊗= αTshared (cid:11) βl.o.F
(cid:1)(cid:48)

/* Complexity reduction: Convolve all α(cid:48) */

;
Tshared do

Tshared

F
s

;

39
40

(cid:0)α
43 return(cid:0)α

end

41
42

F
s

16

analyzed (lines 39 – 42). The reduction to a single arrival bound per level prevents combining any
two adjacent recursion levels’ results. Thus, we strongly counteract the combinatorial explosion;
potential search trajectories are narrowed down.

3. The third improvement is of technical nature. We implemented an arrival bound cache that al-
lows for storage and retrieval of intermediate results (lines 15 and 30) which are plentiful in the
compositional analysis. The cache facilitates early termination of recursions (search trajectories).
It impacts the TMA analysis when alternative matchings share sub-tandems that require equal
cross-traﬃc arrival boundings.

Summing up, we designed an algebraic, compositional network calculus analysis that is strictly superior
to the existing SFA as well as the PMOO network analysis. The more comprehensive procedure of
transforming a network description to analysis-internal models allows optimal application of algebraic
DNC operations and therefore increases the accuracy of delay bounds. Moreover, with Algorithm 1 we
provide an eﬃcient solution to mitigate our analysis’ potentially high computational eﬀort. The practical
evaluation in Section 6 shows that we succeeded in doing so.

5 Related Work

θ

In this work, we rely on the PMOO left-over service curve under arbitrary multiplexing of ﬂows, i.e., the
worst-case remaining service capturing any possible scheduling order of ﬂows at a server. Deterministic
network calculus also oﬀers a left-over service curve for FIFO-multiplexing servers βl.o.
[22]. Similar
to the arbitrary multiplexing one given in Theorem 9, it is only applicable to a single system. Thus,
it allows for an analysis akin to the SFA presented in Section 2.3.2. Again, this raises the problem of
paying multiplexing more than once if cross-ﬂows share multiple consecutive hops with the analyzed
ﬂow of interest. Eﬀort focussed on improved sub-path sharing, however, an algebraic end-to-end FIFO
analysis for tandems that reduces paying for cross-traﬃc multiplexing only once does not exist for FIFO
multiplexing. The most advanced algebraic tandem FIFO analysis is the so-called Least Upper Delay
Bound (LUDB) [23]. If the paths of cross-ﬂows do not overlap (i.e., they are nested into each other),
the LUDB suggests to convolve servers before removing cross-ﬂows according to the nesting. The latter
is done by computing the FIFO left-over service curve. In Figure 2a, xf1’s arrival at server s1 (αxf1
) is
removed from s1, then the left-over service curve βl.o.
is removed
from this curve. Note, that this approach requires segregated cross-ﬂow arrival bounding according
to the nesting, i.e., the compositional penalty presented for PMOO in Section 3.2 also applies to the
LUDB. If paths are not nested, this approach cannot be applied, e.g., if we analyzed xf2 in Figure 2a.
In this case, [23] suggests to cut the tandem into several sub-tandems such that each sub-tandem sees
nested interference only. Then, the foi’s delay is derived for every sub-tandem; they are added up to the
end-to-end delay bound. If there are multiple alternatives to cut a tandem (Figure 2a: Both links), all
alternatives are computed in an exhaustive fashion and the least among all resulting delay bounds is used
as ﬁnal result. Unfortunately, the approach adding up partial delay bounds misses out the Pay Burst
Only Once (PBOO) principle SFA already implements. Therefore, the authors of the LUDB adapt their
analysis in a follow-up article [2]. There, the ﬂow of interest is not cut anymore. Only cross-ﬂows are cut
such that the interference pattern is converted into a nested one. Then, an end-to-end left-over service
curve can be derived for the foi. While this implements the PBOO principle, PMOO is not achieved as
cutting cross-traﬃc requires deriving its arrival bound to be used at the cut.

is convolved with βs2

θ,s1

and ﬁnally αxf1

s2

s1

The sub-tandem cutting of these approaches and the tandem matching of our new analysis are similar,
yet, they also diﬀer in some key aspects. First, our TMA does not require to result in tandems with
nested interference because the PMOO analysis can handle overlapping sub-paths of cross-ﬂows. Our

17

exhaustive approach thus results in more sub-tandem matching alternatives than the LUDB’s cutting.
Secondly, [23] and [2] are concerned with a tandem analysis only. They do not address the composition
penalty of a tandem-based feed-forward analysis we presented in Section 3.2, yet, both LUDB approaches
are based on the idea of sub-path sharing and thus suﬀer from it, too. Moreover, they do not provide
a technical solution for the potential combinatorial explosion problem; [2] rather presents a heuristic to
trade accuracy against computational eﬀort. Applying the LUDB in the exhaustive tandem matching of
this work, is, however, possible in order to gain from our eﬃciency improvements.

An optimization-based DNC approach for tight FIFO-multiplexing feed-forward network analysis
exists as well [10]. It transforms the DNC description of the network into a Mixed-Integer Linear Program
(MILP) where the integer constraints encode the (partially) parallel paths of ﬂows. This circumvents
the step of explicitly extending a partial order to the set of all compatible total orders shown to cause
NP-hardness. However, the computational eﬀort to solve the MILP for large networks is not evaluated.
Instead, the authors advise to remove constraints such that all integer variables are removed, leaving an
ordinary linear program to solve. I.e., tightness is traded for computational eﬀort; similar to the ULP.

6 Evaluation

We have implemented the eﬃcient Tandem Matching Analysis of Algorithm 1 in the Disco Deterministic
Network Calculator 2.2.3 (DiscoDNC) [4].

Experiments were conducted as follows: First we create a device graph and transform it to a turn-
prohibited, feed-forward server graph as outlined in Section 2.2. Then, we randomly chose sources and
sinks from the device graph and route ﬂows on the shortest path in the server graph in order to create
a network to analyze3. The last step, the actual analysis, consists of transforming the network to the
analysis-speciﬁc model and deriving the ﬂow of interest’s delay bound. The run times of this last step
were measured and compared as all previous steps are shared between the alternative analyses.

(a) Tandem network with a non-nested interference pattern of cross-ﬂows.

Figure 8: Networks from the LP evaluation given in [9].

(b) Square network.

6.1 Extending the LP Evaluation of [9]
First, we reproduce and extend the evaluation of the LP analysis with our new TMA. Bouillard et
al. present an evaluation of the two networks posing problems for algebraic NC, yet, are solved with
optimization-based analyses. On the one hand, there is the tandem with non-nested interference of
cross-ﬂows as already used in the ﬁrst paper to motivate optimization in DNC [30] (see Figure 8a). On

3Note, that the shortest path in the turn-prohibited server graph need not coincide with the shortest path in the device

graph. This potential deviation in shortest paths is not relevant for our numerical evaluation of DNC analyses.

18

    ↵foi↵xf↵xf↵xf↵xf↵xf... s1 s2 s3 s4↵f1↵f2↵f3↵f4(a) Tandem, utilization = 90%: DTMA = DLP.

(b) Tandem, length = 20 servers: DTMA = DLP.

(c) Square: DSFA = DTMA = DULP ≥ DLP.

Figure 9: Delay Bounds for the networks shown in Figure 8. TMA and ULP bounds are equal in these
networks.

19

Tandem lengthDelay bound048121620012345678lllllllllllllllllllllSFALPATMAUtilizationDelay bound0204060801000101102103llllllllllSFALPATMAUtilizationDelay bound0204060801000.000.501.001.50llllllllllllllllllllSFAULPATMALPAthe other hand, the authors derive bounds for the square network shown in Figure 8b. This network
was chosen because it reveals the same problem as caused by rejoining ﬂows – the running example in
[9] illustrating the LP analysis’ strengths. In both networks, the compositional analysis procedure of
Section 2.3.3 enforces cross-ﬂow segregation leading to mutual interference assumptions. In contrast, the
similarly harmful cross-ﬂow segregations of Section 3.2 are caused by the tandem analyses of Section 2.3.2.
For tandems of arbitrary lengths, Bouillard et al. provide a tool that generates the (single) LP. In
fact, on tandems, the LP coincides with the ULP. For the square network, the LP’s as well as the ULP’s
linear programs are provided as text ﬁles. All lp ﬁles are formatted to be solved with LpSolve. Figure 9
shows the evaluation results extended by our TMA delay bounds. In non-nested tandem networks, the
TMA achieves the same delay bounds as the LP computes – independent of tandem length or utilization.
In Figures 9a and 9b, the TMA’s blue dots are always in the LP’s black squares. In the square network,
the TMA performs equal to the ULP, i.e., it achieves the same tradeoﬀ between eﬀort and accuracy (see
Figure 9c).

These TMA evaluation results are promising, however, in Section 3.2 we derived the new composition
penalty and in Section 4.1 we showed that it also eﬀects the TMA. The square network is not suﬃciently
complex to evoke it – even the SFA performs equal to the ULP in the square network (see Figure 9c). In
order to evaluate the potential problem of less accurate delay bounds, we provide more comprehensive
numerical experiments in the remainder of this section.

6.2 Numerical Experiments
For our numerical investigation, we created Internet-like topologies according to the general linear pref-
erence (GLP) model [13] with its provided default parameter setting (m0 = 20, m = 1, p = 0.4695,
βGLP = 0.6447). We used the aSHIIP tool [34] to generate these device graphs. Traﬃc was created with
a ﬁxed server-to-ﬂow ratio of 1:4 for all networks. Service curves resemble transmissions via 10Gbps
duplex links and ﬂows’ arrival curves are uniformly shaped to token buckets with rate 5Mbps and bucket
size 5Mb before entering their respective ﬁrst server’s output queue. Table 3 shows the amount of de-
vices, servers and ﬂows for each of the networks we evaluate in this section. Transforming a network
to a sequence of algebraic operations on curves as well as the their computations were done with our
extended version of the DiscoDNC. Moreover, we also extended the DiscoDNC 2.2.3 to derive the ULP
for arbitrary feed-forward networks – the linear program can be formatted to be either solved with the
open-source LpSolve or with IBM CPLEX. We employed LpSolve 5.5.2.0 and CPLEX 12.6.2. All com-
putations were executed on a server equipped with an Intel Xeon E5420 CPU with four physical cores
and 12 GB of RAM.

Devices

20
40
60
80
100
120
140
160
180

Servers Flows
152
472
656
1128
1456
1592
2048
2288
2584

38
118
164
282
364
398
512
572
646

Devices

200
220
240
260
280
300
400
500
1000

Servers Flows
2960
2976
3528
3904
3976
4498
5912
7504
14504

740
744
882
976
994
1122
1478
1876
3626

Table 3: GLP topology sizes and their number of servers and ﬂows when transformed into an analyzable
network.

20

(a) Analysis results for an Internet-like network with 180 devices. Depicted are all the 2584 ﬂows’ end-to-
end delay bounds. TMA and ULP bounds are very close to each other, but the SFA bounds follow a diﬀerent
pattern; oscillating intensely, the SFA is even questionable as a delay bound proxy metric for relative performance
comparisons.

It
(b) Accuracy of the compositional analyses with respect to the ULP delay bounds over all experiments.
comprises every ﬂow analyzed with all methods; 12376 ﬂows across all network sizes shown in Table 3, left. The
TMA accuracy is stable across the network size and stays within a small deviation from the ULP. Except for a
single outlier, all derived bounds are at most 5% larger, mean and median are both at only 1.16%. The outlier
deviates 8.23% from the ULP and thus is still more accurate than 70% of the SFA bounds, which is even oﬀ by
270% for one of the ﬂows.

Figure 10: Delay Bound Evaluation.

21

05001000150020002500Flow IDDelay bound [ms]050100150200SFAULP»TMADelay bound deviation [%]Density [%]0102090100TMASFA0 − 55 − 1010 − 1515 − 2020 − 2525 − 3030 − 3535 − 4040 − 4545 − 50>506.2.1 Delay Bound Accuracy

In Section 3, it was already shown that the tight analysis (LP) is computationally infeasible for larger
networks. Therefore, we use the same authors’ ULP [9] to benchmark against optimization-based analysis
results. Figure 10a exemplarily shows all individual ﬂow delay bounds of the network with 180 devices –
the largest one computationally feasible to analyze with the ULP. Sorting the bounds ascending by their
TMA delays reveals two important observations:

• The ULP and the TMA delay bounds increase pretty much in lockstep and stay close to each other.
Thus, the TMA does not have to compromise on the delay bound accuracy to achieve better run
times. This holds true for all smaller network sizes as well (see Figure 10b).

• The SFA results oscillate wildly with a large amplitude. This behavior can be observed across all
network sizes. In contrast to the TMA, the lack of consistency in the SFA’s gap to the ULP bounds
even prohibits using it as a proxy metric for accurate delay bounds.

Both observations are conﬁrmed by the overall results of our experimental investigation. Figure 10b
depicts the deviation of the SFA and the TMA delay bounds from the ULP. We have evaluated diﬀerently
sized Internet-like topologies with a total of 12376 ﬂows (Table 3, left). This eﬀort conﬁrmed that the
ULP derives the most accurate bounds, up to 2.7 times more accurate than the SFA, yet, the TMA is
barely outperformed. Our new analysis deviates from the ULP on average by just 1.16% and, except for
a single outlier at 8.23%, does not deviate by more than 5%.

When analyzing networks larger than those of Section 6.1, we experienced problems with the LpSolve
solver used in [9]. Already in the smallest network of this numerical evaluation, LpSolve fails to solve
one of the linear programs, reporting it to be unbounded after an extensive period of computations. In
the GLP network with 40 devices, LpSolve fails with a larger number of linear programs, reporting “un-
bounded” or “failed”. Therefore, the presented results were all obtained with the IBM CPLEX solver that
was also used by Bouillard and Stea in [10] to solve the more involved MILPs in their FIFO multiplexing
analysis. CPLEX, in contrast to LpSolve, successfully computes the delay bound in networks up to
160 devices. However, continuing to increase the amount of network devices, CPLEX also reproducibly
fails with certain linear programs. We ﬁrst observed this problem in the 180 devices GLP where seven
out of 2584 could not be solved with optimization. Our algebraic NC tool, the DiscoDNC, successfully
computed the delay bounds for all ﬂows.

6.2.2 Computational Performance

With TMA deriving accurate delay bounds, we now evaluate the eﬀort involved in our new analysis in
order to show that the computational eﬃciency improvements incorporated into Algorithm 1 indeed have
a crucial impact. Figure 11a and Table 11b depict the time to complete a network analysis for our set
of Internet-like topologies. Although the experimental results are subject to ﬂuctuations due to the high
degree of randomness in network and ﬂow creation, we can draw very clear conclusions. Computational
eﬀort and thus the time to analyze grows (fast) with the network size. The ULP’s eﬀort is vastly reduced
in contrast to the LP, yet, our evaluation reveals that it still becomes computationally infeasible quickly.
With 180 network devices, the analysis execution already took 13 days, i.e., the largest network to analyze
with reasonable eﬀort had only 160 network devices, which amounts to 572 output queue servers and
2288 randomly routed ﬂows. The larger the network, the more eﬀort is required to trace the inﬂuence of
ﬂows on each other. Yet, among the two steps of the ULP, deriving the constraints for the linear program
with the DiscoDNC and optimizing it with CPLEX, the latter takes on average 82.4% of the time (cf.

22

(a) Network analysis times below two days.

Network devices ULP1 (1 thread) ULP (4 threads)

SFA (1 thread) TMA (1 thread)

20
40
60
80
100
120
140
160
180
200
220
240
260
280
300
400
500
1000

00:00:12
00:05:49
00:39:44
05:00:33
05:22:02
20:45:44
33:15:36
58:06:08

00:00:13
00:06:04
00:40:41
05:03:00
05:33:44
22:15:22
33:14:00
58:20:54
∼13 days

–
–
–
–
–
–
–
–
–
–
(b) Network analysis time (hh:mm:ss)

–
–
–
–
–
–
–
–
–

00:01:14
00:03:29
00:24:41
00:30:21
00:42:07
03:07:46
02:17:36
01:42:56
04:48:26
02:15:35
10:33:45
18:34:52
04:26:23
∼13 days

–
–
–
–

00:00:11
00:00:13
00:00:38
00:01:14
00:01:54
00:11:44
00:04:48
00:05:35
00:08:19
00:07:23
00:13:43
00:18:18
00:14:26
00:35:53
00:25:50
01:30:25
01:50:51
11:15:34

Figure 11: Computational Eﬀort Evaluation: The ULP and the SFA both become computationally infea-
sible already at moderate network sizes by requiring multiple weeks to terminate. The TMA outperforms
both by several orders of magnitude, exhibiting a much better scaling behavior. The TMA thus enables
to analyze far larger networks.

23

Network devicesNetwork analysis time [hours]204060801001201401601802002202402602803(cid:215)1024(cid:215)1025(cid:215)102103012243648    llllllllllllllllllULP1ULPSFATMAFigure 12: Share of the DiscoDNC linear program creation in the ULP analyses. Mean and median are
both below 20%.

Figure 12). Faster ULP optimization could not be achieved with CPLEX; increasing the parallelism
from 1 to 4 threads4 even yielded slightly slower overall network analysis times due to the overhead for
thread synchronization. Figure 11a depicts the single-threaded CPLEX version in green (label ULP1).
As mentioned, it is slightly below the black ULP line that shows the results when running CPLEX with
up to 4 threads. The ULPs seem to become very complex; the linear program to bound the foi’s delay in
Figure 2a already possesses 68 constraints. The ULP ﬁle sizes may hint at its complexity; we observed
CPLEX lp ﬁles of several gigabytes in size.

Analyzing large feed-forward networks in practice remains solely possible with algebraic, composi-
tional DNC analyses. However, Figure 11a also shows that the SFA, although equipped with our new
caching mechanism, becomes computationally infeasible at 280 network devices (994 servers, 3976 ﬂows;
13 days for analysis). The major reason for this behavior is its worst-case segregation of cross-ﬂows.
Massive computational eﬀort is required to bound all cross-ﬂows’ mutual interference. Our TMA does
not suﬀer from this eﬀort thanks to the improvements in Algorithm 1: Aggregate bounding of cross-
traﬃc as well as the convolution of its intermediate arrival bounds. The TMA scales much better with
the network size and outperforms the other analyses by several orders of magnitude. It is now possible
to analyze a GLP network with 1000 devices (3626 servers, 14504 ﬂows) in a reasonable amount of time.
This makes the TMA by far the fastest DNC analysis and enables to analyze large networks with network
calculus.

6.3 AFDX Case Study
As concluding evaluation, we investigate our new TMA’s delay bound accuracy in the industrial avionics
context mentioned in Section 1. The network we exemplarily analyze here is dimensioned similarly to
the AFDX backbone network in the Airbus A380. It has a dense core of 16 switches that connect a total
of 125 end-systems in the network periphery. Each server has a service curve resembling a 100Mbps
Ethernet link. We created a representative AFDX topology according to the algorithm presented in
[12]. This topology generation scheme has some random factors in it, i.e., from an industrial point of
view, the network we analyze here corresponds to a single alternative in a pre-deployment design space
exploration.

According to the current AFDX speciﬁcation, ﬂows are routed within so-called virtual links (VLs).
Each VL connects a single source end-system to multiple sink end-systems (in the device graph) with

4Note, that among the tools employed in this evaluation, only CPLEX oﬀers an option for parallel execution.

24

setupTime / executionTime [%]Density [%]01020304050020406080100      meanmedian0.9−quantile0.99−quantileFigure 13: AFDX Case Study: Delay Bounds.

In the view of the network calculus,
ﬁxed resource reservation on the path between these systems.
VLs correspond to multicast ﬂows that reserve large resource shares. An examination of the problems
due to VLs’ coarse granularity can be found in [26]. Moreover, network calculus does not provide
a specialized analysis for multicast communication that implements the PBOO or even the PMOO
principle. Implementing them to some degree requires another network transformation before the actual
analysis: Each multicast ﬂow is converted into a set of independent unicast ﬂows; one for every source-
sink pair of connected network devices. This step, however, constitutes a ﬂow segregation similar to the
ones mentioned earlier. For this reasons, we restrict our evaluation to the immutable part of AFDX: The
deployed networks’ common topology design. We added 500 random ﬂows with arrival curves shaped to
unit sized token buckets (rate 1Mbps, bucket 1Mb).

Figure 13 depicts the 500 ﬂow delay bounds. Our previous accuracy observations regarding the TMA
are conﬁrmed whereas the SFA even performs worse than in the Internet-like topologies; its delay bounds
show a gap to TMA and the ULP bounds that tends to grow on average. Additionally, the SFA delay
bounds oscillate compared to the ULP and TMA bounds, such that this analysis is not suitable to
conﬁdently rank AFDX design alternatives regarding their performance.

Figure 14 shows the time it took to analyze each ﬂow in the network. This per-ﬂow eﬀort can diﬀer
more than three orders of magnitude within a the SFA and the ULP analysis. This fact is surprising as
the AFXD topology has such a small network diameter. The recursion through the network required to
trace ﬂow dependencies terminates at ﬂows’ sources and is thus not very deep in an AFDX network. For
this reason the TMA’s eﬀort stays within a much smaller range. In absolute terms, the TMA outperforms
ULP and SFA run times by multiple orders of magnitude – an advantage that can become decisive in
large design space explorations.

7 Conclusion and Outlook

In this article, we contribute a fast and accurate network calculus solution for the derivation of end-to-
end delay bounds in general feed-forward networks. We followed a compositional approach which turned
out key for computational eﬃciency as we show in the implementation and evaluation of our solution to

25

05001000150020002500Flows, ordered by their TMA delay boundDelay bound [ms]0100200300400500      SFATMAULPFigure 14: AFDX Case Study: Computational Eﬀort.

the problem of delay bounding in feed-forward networks. We are able to derive delay bounds very close
to those from optimization-based DNC network analysis. Our novel Tandem Matching Analysis thus
constitutes the ﬁrst deterministic network calculus analysis that is accurate and scalable at the same
time.

Building on the fact that all tandem matchings deliver valid delay bounds we can, in fact, scale
our solution to much larger networks than presented here. We leave the question how this can be
done in an accurate manner for future work. Although we focused on arbitrary multiplexing DNC
analysis, our exhaustive tandem matching can be combined with any other tandem analysis method
of network calculus. Our related work section covers FIFO-multiplexing systems and the observations
of our evaluation suggest that a tandem matching analysis for FIFO multiplexing is most probably
also beneﬁcial for computational eﬀort while achieving a high degree of accuracy with respect to the
optimization approach.

References

[1] Alessandro Biondi, Giorgio Buttazzo, and Stefano Simoncelli. Feasibility analysis of engine control

tasks under edf scheduling. In Proc. Euromicro ECRTS, pages 139–148, July 2015.

[2] Luca Bisti, Luciano Lenzini, Enzo Mingozzi, and Giovanni Stea. Numerical Analysis of Worst-
Case End-to-End Delay Bounds in FIFO Tandem Networks. Springer Real-Time Systems Journal,
48(5):527–569, 2012.

[3] Steﬀen Bondorf and Jens B. Schmitt. Statistical Response Time Bounds in Randomly Deployed

Wireless Sensor Networks. In Proc. IEEE LCN, pages 340–343, October 2010.

[4] Steﬀen Bondorf and Jens B. Schmitt. The DiscoDNC v2 – A Comprehensive Tool for Deterministic

Network Calculus. In Proc. ValueTools, 2014.

[5] Steﬀen Bondorf and Jens B. Schmitt. Boosting Sensor Network Calculus by Thoroughly Bounding

Cross-Traﬃc. In Proc. IEEE INFOCOM, 2015.

26

Flows, ordered by their ULP analysis run timeFlow analysis run time [ms]0100200300400500      10-310-1101ULP_4thrSFATMA[6] Steﬀen Bondorf and Jens B. Schmitt. Calculating Accurate End-to-End Delay Bounds – You Better

Know Your Cross-Traﬃc. In Proc. ValueTools, 2015.

[7] Anne Bouillard. Algorithms and Eﬃciency of Network Calculus. Habilitation thesis, École Normale

Supérieure, 2014.

[8] Anne Bouillard, Laurent Jouhet, and Eric Thierry. Service curves in Network Calculus: dos and

don’ts. Research Report RR-7094, INRIA, 2009.

[9] Anne Bouillard, Laurent Jouhet, and Eric Thierry. Tight Performance Bounds in the Worst-Case

Analysis of Feed-Forward Networks. In Proc. IEEE INFOCOM, pages 1–9, March 2010.

[10] Anne Bouillard and Giovanni Stea. Exact Worst-Case Delay in FIFO-Multiplexing Feed-Forward

Networks. IEEE/ACM Transactions on Networking, 2014.

[11] Marc Boyer and Christian Fraboul. Tightening end to end delay upper bound for afdx network
calculus with rate latency ﬁfo servers using network calculus. In Factory Communication Systems,
2008. WFCS 2008. IEEE International Workshop on, pages 11–20, 2008.

[12] Marc Boyer, Nicolas Navet, and Marc Fumey. Experimental Assessment of Timing Veriﬁcation

Techniques for AFDX. In Proc. ERTS, 2012.

[13] Tian Bu and Don Towsley. On Distinguishing between Internet Power Law Topology Generators.

In Proc. IEEE INFOCOM, pages 638–647, 2002.

[14] Cheng-Shang Chang. Performance Guarantees in Communication Networks. Springer, 2000.

[15] Juan Echagüe and Vicent Cholvi. Tight Arrival Curve at the Output of a Work-Conserving Blind

Multiplexing Server. Informatica, 2010.

[16] Markus Fidler. Survey of deterministic and stochastic service curve models in the network calculus.

Communications Surveys & Tutorials, 2010.

[17] Fabrice Frances, Christian Fraboul, and Jérôme Grieu. Using Network Calculus to Optimize AFDX

Network. In Proc. ERTS, January 2006.

[18] Emanuel Heidinger, Nils Kammenhuber, Alexander Klein, and Georg Carle. Network Calculus and

Mixed-Integer LP Applied to a Switched Aircraft Cabin Network. In Proc. IEEE IWQoS, 2012.

[19] Bengt Jonsson, Simon Perathoner, Lothar Thiele, and Wang Yi. Cyclic dependencies in modular

performance analysis. EMSOFT. ACM, 2008.

[20] Petr Jurcik, Anis Koubâa, Ricardo Severino, Mário Alves, and Eduardo Tovar. Dimensioning and
Worst-Case Analysis of Cluster-Tree Sensor Networks. ACM Transactions on Sensor Networks,
pages 14:1–14:47, September 2010.

[21] Georges Kemayo, Nassima Benammar, Frederic Ridouard, Henri Bauer, and Pascal Richard. Im-

proving AFDX End-to-End Delays Analysis. In Proc. IEEE ETFA, 2015.

[22] Jean-Yves Le Boudec and Patrick Thiran. Network Calculus: A Theory of Deterministic Queuing

Systems for the Internet. Springer, 2001.

[23] Luciano Lenzini, Enzo Mingozzi, and Giovanni Stea. A Methodology for Computing End-to-End
Delay Bounds in FIFO-Multiplexing Tandems. Elsevier Performance Evaluation, 65(11–12):922–
943, 2008.

27

[24] Henrik Schiøler, Jan Jakob Jessen, Jens Dalsgaard Nielsen, and Kim Guldstrand Larsen. Net-
work Calculus for Real Time Analysis of Embedded Systems with Cyclic Task Dependencies. In
Computers and Their Applications, 2005.

[25] Xiaoting Li, Jean-Luc Scharbarg, and Christian Fraboul.

Improving End-to-End Delay Upper
Bounds on an AFDX Network by Integrating Oﬀsets in Worst-Case Analysis. In Proc. IEEE ETFA,
pages 1–8, September 2010.

[26] Renato Mancuso, Andrew V. Louis, and Marco Caccamo. Using Traﬃc Phase Shifting to Improve

AFDX Link Utilization. In Proc. ACM EMSOFT, 2015.

[27] Gianluca Rizzo and Jean-Yves Le Boudec.

“Pay Bursts Only Once” does not hold for non-FIFO

Guaranteed Rate Nodes. Elsevier Performance Evaluation, 62(1–4):366 – 381, 2005.

[28] Frank Ruskey. Combinatorial Generation. 2003.

[29] Jens B. Schmitt, Nicos Gollan, Steﬀen Bondorf, and Ivan Martinovic. Pay Bursts Only Once Holds

for (Some) non-FIFO Systems. In Proc. IEEE INFOCOM, April 2011.

[30] Jens B. Schmitt, Frank A. Zdarsky, and Markus Fidler. Delay Bounds under Arbitrary Multiplexing:
When Network Calculus Leaves You in the Lurch ... In Proc. IEEE INFOCOM, pages 1669–1677,
April 2008.

[31] Jens B. Schmitt, Frank A. Zdarsky, and Ivan Martinovic. Improving Performance Bounds in Feed-
Forward Networks by Paying Multiplexing Only Once. In Proc. GI/ITG MMB, pages 1–15, March
2008.

[32] Jens B. Schmitt, Frank A. Zdarsky, and Lothar Thiele. A Comprehensive Worst-Case Calculus
for Wireless Sensor Networks with In-Network Processing. In Proc. IEEE RTSS, pages 193–202,
December 2007.

[33] David Starobinski, Mark Karpovsky, and Lev A. Zakrevski. Application of Network Calculus to
General Topologies Using Turn-Prohibition. IEEE/ACM Trans. Netw., 11(3):411–421, June 2003.

[34] Joanna Tomasik and Marc-Antoine Weisser.

Internet Topology on AS-level: Model, Generation

Methods and Tool. In Proc. IEEE IPCCC, 2010.

[35] Yaakov L Varol and Doron Rotem. An Algorithm to Generate all Topological Sorting Arrangements.

The Computer Journal, 24(1), 1981.

[36] Dallas E. Wrege and Jörg Liebeherr. Video traﬃc characterization for multimedia networks with a

deterministic service. In Proc. IEEE INFOCOM, volume 2, pages 537–544 vol.2, Mar 1996.

[37] Timothy Zhu, Alexey Tumanov, Michael A Kozuch, Mor Harchol-Balter, and Gregory R Ganger.
PriorityMeister: Tail Latency QoS for Shared Networked Storage. In ACM SOCC, pages 1–4, 2014.

28

