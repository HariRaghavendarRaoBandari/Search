6
1
0
2

 
r
a

M
1

 

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
4
8
2
0
0

.

3
0
6
1
:
v
i
X
r
a

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Dual Smoothing and Level Set Techniques for Variational Matrix

Decomposition

Aleksandr Aravkin
Department of Applied Mathematics
University of Washington
Seattle, WA
Stephen Becker
Department of Applied Mathematics
University of Colorado, Boulder
Boulder, CO

SARAVKIN@UW.EDU

STEPHEN.BECKER@COLORADO.EDU

Citation: chapter in “Robust Low-Rank and Sparse Matrix Decomposition: Applications in Image and Video
Processing”, T. Bouwmans, N. Aybat, E. Zahzah, eds. CRC Press, 2016.

Abstract

We focus on the robust principal component analysis (RPCA) problem, and review a range of old
and new convex formulations for the problem and its variants. We then review dual smoothing and
level set techniques in convex optimization, present several novel theoretical results, and apply the
techniques on the RPCA problem. In the ﬁnal sections, we show a range of numerical experiments
for simulated and real-world problems.

1. Introduction
Linear superposition is a useful model for many applications, including nonlinear mixing problems.
Surprisingly, we can perfectly distinguish multiple elements in a given signal using convex optimiza-
tion as long as they are concise and look sufﬁciently different from one another. Robust principal
component analysis (RPCA) is a key example, where we decompose a signal into the sum of low
rank and sparse components. RPCA is a special case of stable principal component pursuit (SPCP),
where we also allow an explicit noise component within the RPCA decomposition. Applications
include alignment of occluded images (Peng et al., 2012), scene triangulation (Zhang et al., 2011),
model selection (Chandrasekaran et al., 2012), face recognition, and document indexing (Cand`es
et al., 2011a).

For SPCP, our model is

(1)
where A is the observed matrix, L is a low-rank matrix, S is a sparse matrix, and E is an unstructured
nuisance matrix (e.g., a stochastic error term). The classic RPCA formulation (Cand`es et al., 2011a)
assumed E = 0, but in general we do not distinguish between RPCA and SPCP.

A = L + S + E

The RPCA problem uses regularization on the summands L and S in order to improve the
recovery of the solution. In (Cand`es et al., 2011b), the 1-norm regularizer is applied to S to promote
sparsity, and the nuclear norm is applied to L to penalize rank:

min|||L|||∗ + λ(cid:107)S(cid:107)1

s.t. A = L + S.

(2)

1

A. ARAVKIN AND S. BECKER

The 1-norm (cid:107) · (cid:107)1 and nuclear norm |||·|||∗ are given by (cid:107)S(cid:107)1 =(cid:80)

i,j |si,j| and |||L|||∗ =(cid:80)

i σi(L),
where σ(L) is the vector of singular values of L. The parameter λ > 0 controls the relative importance
of the low-rank term L vs. the sparse term S. This problem has been analyzed by (Chandrasekaran
et al., 2009; Cand`es et al., 2011a), and it has perfect recovery guarantees under stylized incoherence
assumptions. There is even theoretical guidance for selecting a minimax optimal regularization
parameter λ (Cand`es et al., 2011a).

There are several modeling choices underlying formulation (2). First is the choice of the (cid:96)1-norm
to promote sparsity and the trace norm (aka nuclear norm) to promote low-rank solutions. We will
keep with these choices throughout the entire chapter, noting where it is possible to use more general
penalties. Second, (2) assumes the data are ﬁt exactly. Unfortunately, many practical problems only
approximately satisfy the idealized assumptions. This motivates the SPCP variant:

|||L|||∗ + λsum(cid:107)S(cid:107)1

min
L,S
subject to (cid:107)L + S − A(cid:107)F ≤ ε,

(SPCPsum)

where the ε parameter accounts for the unknown perturbations A − (L + S) in the data not explained
by L and S. It is useful to deﬁne φ(L, S) = |||L|||∗ + λ(cid:107)S(cid:107)1 as a regularizer on the decision variable
(L, S). The formulation (2) then tries to ﬁnd the tuple (L, S) that ﬁts the data perfectly, and is
minimal with respect to φ.

Third, the functional form of φ is important; in (2) as well as (SPCPsum) the component penalties
are added with a tradeoff parameter λ, but other choices can be made as well. In particular, Aravkin
et al. (2014a) propose a new variant called “max-SPCP”:

max (|||L|||∗, λmax(cid:107)S(cid:107)1)
min
L,S
subject to (cid:107)L + S − A(cid:107)F ≤ ε,

(SPCPmax)

where λmax > 0 acts similar to λsum, and this new formulation offers both modeling and computa-
tional advantages over (SPCPsum) (see Section 5.2). We show that cross-validation with (SPCPmax)
to estimate (λmax, ε) is signiﬁcantly easier than estimating (λsum, ε) in (SPCPsum). Given an oracle
that provides an ideal separation A (cid:39) Loracle + Soracle, we can use ε = (cid:107)Loracle + Soracle − A(cid:107)F in
both cases. However, while we can estimate λmax = |||Loracle|||∗/(cid:107)Soracle(cid:107)1, it is not clear how to
choose λsum from data, without using cross-validation or assuming a probabilistic model.

Finally, both (SPCPsum) and (SPCPmax) assume a least-squares penalty functional to measure the

error up to level . We can consider a more general choice of penalty ρ:
s.t. ρ(A − L − S) ≤ ε.

min φ(L, S)

(3)

Robust losses as well as ρ arising from probabilistic models have been explored in (Aravkin et al.,
2014c, 2016).

Once ρ and φ have been selected, we can choose the type of regularization formulation one wants
to solve. Formulation (3) minimizes the regularizer subject to a constraint on the misﬁt error. Two
other common formulations are

s.t. φ(L, S) ≤ τ,
which minimizes the error subject to a constraint on the regularizer, and

min ρ(A − L − S)

min ρ(A − L − S) + λφ(L, S),

(4)

(5)

2

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

which minimizes the sum of error and regularizer with another tradeoff parameter to balance these
goals.

All three formulations can be effectively used, and are equivalent in the sense that solutions match
for certain values of parameters λ, τ, and ε. Formulation (3) is preferable from a modeling perspective
when the misﬁt level ε is known ahead of time, or can be estimated. However, formulations (4)
and (5) often have fast ﬁrst-order algorithms available for their solution.

It turns out that we can exploit algorithms for (4) to solve (3) using the graph of the value
function for problem (4); this relationship can be used to show that the problems have the same
complexity (Aravkin et al., 2016). Level set optimization was ﬁrst applied for sparsity optimization
by van den Berg and Friedlander (2008), and later extended to gauge optimization (van den Berg and
Friedlander, 2011) and to general convex programming (Aravkin et al., 2013).

The second approach we consider is the TFOCS algorithm (Becker et al., 2011) and software1,
which is based on the proximal point algorithm, and can also handle generic convex minimization
problems. We present a new analysis of TFOCS, along with stronger convergence guarantees, and
also apply TFOCS method to RPCA. TFOCS solves all standard variants of RPCA and SPCP, and
can easily add non-negativity or other types of additional constraints. We brieﬂy detail how the
algorithm can be specialized for the RPCA problem in particular.

The chapter proceeds as follows.

In Section 2, we provide the necessary convex analysis
background to understand our algorithms and results. In Section 3, we look at level set techniques in
the context of the RPCA problem; in particular we describe previous work and algorithms for SPCP
and RPCA in Section 3.2, discuss computationally efﬁcient projections as optimization workhorses
in Section 3.4, and develop new accelerated projected quasi-Newton methods for the ﬂipped and
Lagrangian formulations in Section 3.5. We then present a view of dual smoothing, describe the
TFOCS algorithm, and show to to apply it to RPCA in Section 4. We describe the general class
of problems solvable by TFOCS in Section 4.1, detail the dual smoothing approach in Section 4.2,
and present new convergence results in Section 4.5. Finally, we demonstrate the efﬁcacy of the new
solvers and the overall formulation on synthetic problems and real data problems in Section 5.

2. Convex Analysis Background
We work in ﬁnite dimensional spaces Rn (with Euclidean inner product) unless otherwise speciﬁed;
we note however that much of the general theory below generalizes immediately to Hilbert spaces
and some of it to Banach spaces. Standard deﬁnitions are not referenced, but can be found in convex
analysis textbooks (Rockafellar, 1970b; Rockafellar and Wets, 1998) or in review papers such as
Combettes and Pesquet (2011).

2.1 Key deﬁnitions

In this section, we provide deﬁnitions of objects that we use throughout the chapter.

We work with functions that take on values from the extended real line R := R ∪ {∞}. For

example, we deﬁne the indicator function as follows:

1. http://cvxr.com/tfocs

3

A. ARAVKIN AND S. BECKER

Deﬁnition 1 (Indicator Function of a set C)

χC(x) =

and thus for any functional f on Rn,

(cid:40)

x ∈ C
0
+∞ x /∈ C

min
x∈C

f (x) = min
x∈Rn

f (x) + χC(x).

This allows a uniﬁed treatment of constraints and objectives by encoding constraints using indicator
functions.

The class Γ0(Rn) denotes convex, lower semi-continuous (lsc), proper functionals from Rn to
R. A function is lsc if and only if its graph is closed, and in particular a continuous function is lsc. A
proper function is not identically equal to +∞ and is never −∞. We write domf = {x | f (x) < ∞}.
Further background is widely available, e.g., (Rockafellar, 1970b; Combettes and Pesquet, 2011).
Deﬁnition 2 (Subdifferential and subgradient) Let f ∈ Γ0(Rn), then the subdifferential of f at
the point x ∈ domf is the set

∂f (x) = {d ∈ Rn | ∀y ∈ Rn, f (y) ≥ f (x) + (cid:104)d, y − x(cid:105)}

and elements of the set are known as subgradients.

The sub-differential of an indicator function χC at x is the normal cone to C at x. Fermat’s rule
is that x ∈ arg min f (x) iff 0 ∈ ∂f (x), which follows by the deﬁnition of the subdifferential. If
f, g ∈ Γ0(Rn), then ∂(f + g) = ∂f + ∂g in many situations (i.e., under constraint qualiﬁcations such
as f or g having full domain). In ﬁnite dimensions, Gˆateaux and Fr´echet differentiability coincide on
Γ0(Rn) and ∂f (x) = {d} iff f is differentiable at x with ∇f (x) = d.

We now introduce a key generalization of projections that will be used widely.

Deﬁnition 3 (Proximity operator) If f ∈ Γ0(Rn) and λ > 0, deﬁne

Proxλf (y) = arg min

x

λf (x) +

(cid:107)x − y(cid:107)2 = (I + λ∂f )

−1(y)

1
2

Note that even though ∂f is potentially multi-valued, the proximity operator is always uniquely
deﬁned (if f ∈ Γ0(Rn)), since it is the minimizer of a strongly convex function. When we say that
a proximity operator for f is easy to compute, we mean that the proximity operator for λf is easy
to compute for all λ > 0. Computational complexity will be explored in more detail in subsequent
sections.

The proximity operator generalizes projection, since ProxχC

(y) = ProjC(y) where Proj denotes
orthogonal projection onto a set. Another example is the proximity operator of the (cid:96)1 norm, which
is equivalent to soft-thresholding. The proximity operator is ﬁrmly non-expansive (Combettes and
Pesquet, 2011), just like orthogonal projections.
Deﬁnition 4 ((Fenchel-Legendre) Conjugate function) Let f ∈ Γ0(Rn), then the conjugate func-
tion f

∗ is deﬁned

∗

f

(cid:104)x, y(cid:105) − f (x).

(y) = sup
−1 is the pre-image operation, and f

x

∗∗

= f.

Furthermore, ∂f

∗

= (∂f )

−1, where (·)

4

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Deﬁnition 5 (Gauge) For a convex set C containing the origin, the gauge γ (x | C) is deﬁned by

γ (x | C) = inf

{λ : x ∈ λC}.

(6)
For any norm (cid:107) · (cid:107), the set deﬁning it as a gauge is simply the unit ball B(cid:107)·(cid:107) = {x : (cid:107)x(cid:107) ≤ 1}.
Gauges are useful in our computational context since they easily allow some extensions, such as
inclusion of non-negativity constraints.

λ

We make extensive use of the theory of dual functions. For example, if one can compute Proxf ,

then one can compute Proxf

∗ and related quantities as well, using

∗(x) = x − Proxf (x)
Proxf
Prox ˇf (x) = − Proxf (−x)

(7)
(8)

where ˇf (x) = f (−x).
Deﬁnition 6 (Relative interior) The relative interior (ri) of a set C ⊂ Rn is the interior of C
relative to its afﬁne hull (the smallest afﬁne space containing C).
Deﬁnition 7 (Lipschitz continuity) A function F : Rn → Rm is Lipschitz continuous with constant
(cid:96) if (cid:96) is the smallest real number such that for all x, x

(cid:48) ∈ Rn,
)(cid:107)Rm ≤ (cid:96)(cid:107)x − x

(cid:48)(cid:107)Rn.

(cid:107)F (x) − F (x

(cid:48)

3. Level-set methods for Residual-Constrained SPCP
In this section, we discuss a range of convex formulations for SPCP, their relationships, and survey
prior art. We then show how to apply level set methods to several of the formulations.

3.1 A primer on SPCP
We illustrate (SPCPsum) and (SPCPmax) via different convex formulations. Flipping the objective and
the constraints in (SPCPmax) and (SPCPsum), we obtain the following convex programs

min
L,S
s.t.

ρ(L + S − A)
|||L|||∗ + λsum(cid:107)S(cid:107)1 ≤ τsum
ρ(L + S − A)

min
L,S
s.t. max(|||L|||∗, λmax(cid:107)S(cid:107)1) ≤ τmax

(ﬂip-SPCPsum)

(ﬂip-SPCPmax)

Solutions of (ﬂip-SPCPsum) and (ﬂip-SPCPmax) are implicitly related to the solutions of (SPCPsum)
and (SPCPmax) via the Pareto frontier by Aravkin et al. (2013, Theorem 2.1). While in many
applications, ρ(·) is taken to be the 2-norm squared, the relationship holds in general. For the range of
parameters where the constraints in (SPCPsum) and (SPCPmax) are active, for any parameter ε there
exist corresponding parameters τsum(ε) and τmax(ε), for which the optimal value of (ﬂip-SPCPsum)
and (ﬂip-SPCPmax) is ε, and the corresponding optimal solutions (Ss, Ls) and (Sm, Lm) are also
optimal for (SPCPsum) and (SPCPmax).

5

A. ARAVKIN AND S. BECKER

For completeness, we also include the Lagrangian formulation:

min
L,S

λL|||L|||∗ + λS(cid:107)S(cid:107)1 +

(cid:107)L + S − A(cid:107)2

F

1
2

(lag-SPCP)

Problems (ﬂip-SPCPmax) and (ﬂip-SPCPsum) can be solved using projected gradient optimal
projected gradient methods. The disadvantage of some of these formulations is that it is again
not as clear how to tune the parameters. We show that one can solve (SPCPmax) and (SPCPsum)
using a sequence of ﬂipped problems; moreover this approach inherits the computational complexity
guarantees of (ﬂip-SPCPmax) and (ﬂip-SPCPsum) (Aravkin et al., 2016). In practice, better tuning
also leads to faster algorithms, e.g., ﬁxing ε ahead of time to an estimated ‘noise ﬂoor’ greatly
reduces the amount of required computation if parameters are to be selected via cross-validation.
Finally, in some cases, it is useful to change the ρ(L + S − A) term to ρ(L(L + S − A)) where
L is a linear operator. For example, let Ω be a subset of the indices of a m × n matrix. We may
only observe A restricted to these entries, denoted ProjΩ(A), in which case we choose L = ProjΩ.
Most existing RPCA/SPCP algorithms adapt to the case L = ProjΩ but this is due to the strong
properties of the projection operator ProjΩ. The advantage of our approach is that it seamlessly
handles arbitrary linear operators L.

3.2 Prior Art
While problem (SPCPsum) with ε = 0 has several solvers (e.g., it can be solved by applying the
widely known Alternating Directions Method of Multipliers (ADMM)/ Douglas-Rachford method
(Combettes and Pesquet, 2007)), the formulation assumes the data are noise free. Unfortunately, the
presence of noise we consider in this paper introduces a third term in the ADMM framework, where
extra care must be taken to develop a convergent variant of ADMM (Chen et al., 2013). Interestingly,
there are only a handful of methods that can handle this case. Those using smoothing techniques no
longer promote exactly sparse and/or exactly low-rank solutions. Those using dual decomposition
techniques may require high iteration counts. Because each step requires a partial singular value
decomposition (SVD) of a large matrix, it is critical that the methods only take a few iterations.
As a rough comparison, we start with related solvers that solve (SPCPsum) for ε = 0. Wright
et al. (2009a) solves an instance of (SPCPsum) with ε = 0 and a 800 × 800 system in 8 hours. By
switching to the (lag-SPCP) formulation, Ganesh et al. (2009) uses the accelerated proximal gradient
method (Beck and Teboulle, 2009a) to solve a 1000 × 1000 matrix in under one hour. This is
improved further in Lin et al. (2010) which again solves (SPCPsum) with ε = 0 using the augmented
Lagrangian and ADMM methods and solves a 1500 × 1500 system in about a minute. As a prelude
to our results, our method can solve some systems of this size in about 10 seconds (c.f., Fig. 4).

In the case of (SPCPsum) with ε > 0, Tao and Yuan (2011) propose the alternating splitting
augmented Lagrangian method (ASALM), which exploits separability of the objective in the splitting
scheme, and can solve a 1500 × 1500 system in about ﬁve minutes.

The partially smooth proximal gradient (PSPG) approach of Aybat et al. (2013) smooths just the
nuclear norm term and then applies the well-known FISTA algorithm (Beck and Teboulle, 2009a).
Aybat et al. (2013) show that the proximity step can be solved efﬁciently in closed-form, and the
dominant cost at every iteration is that of the partial SVD. They include some examples on video,
solving 1500 × 1500 formulations in under half a minute.

The nonsmooth adaptive Lagrangian (NSA) algorithm of Aybat and Iyengar (2013) is a variant of
the ADMM for (SPCPsum), and makes use of the insight of Aybat et al. (2013). The ADMM variant

6

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

is interesting in that it splits the variable L, rather than the sum L + S or residual L + S − A. Their
experiments solve a 1500 × 1500 synthetic problems in between 16 and 50 seconds (depending on
accuracy) .

Shen et al. (2014) develops a method exploiting low-rank matrix factorization scheme, maintain-
ing L = U V T . This technique has also been effectively used in practice for matrix completion (Lee
et al., 2010; Aravkin et al., 2014b), but lacks a full convergence theory in either context. The method
of Shen et al. (2014) was an order of magnitude faster than ASALM, but encountered difﬁculties in
some experiments where the sparse component dominated the low rank component. We note that the
factorization technique may potentially speed up some of the methods presented here, but we leave
this to future work, and only work with convex formulations.

3.3 Level set methods for Sum-SPCP and Max-SPCP
Recall that both (SPCPsum) and (SPCPmax) can be written as follows:
s.t. ρ (L + S − A) ≤ ε.

min φ(L, S)

(9)

Earlier, we discussed that both φ and ρ can be chosen by the modeler; in particular sum and max
formulations come from choosing φsum vs. φmax. While classic formulations assume ρ to be the
Frobenius norm, this restriction is not necessary, and we consider ρ to be smooth and convex. In
particular, ρ can be taken to be the robust Huber penalty (Huber, 2004). Even more importantly, this
formulation allows pre-composition of a smooth convex penalty with an arbitrary linear operator L.
In particular, note that the RPCA model is described by a simple linear operator:

L + S =(cid:2)I

(cid:21)
I(cid:3)(cid:20)L

S

.

(10)

Projection onto a set of observed indices Ω is also a simple linear operator that can be included in ρ.
Operators may include different transforms (e.g., Fourier) applied to either L or S.
The problem class (9) falls into the class of problems studied by van den Berg and Friedlander
(2011, 2008) for ρ(·) = (cid:107) · (cid:107)2 and by Aravkin et al. (2013) for arbitrary convex ρ. Following these
references, we deﬁne the value function v(τ ) as

v(τ ) = min
L,S

ρ (L(L, S) − A)

s.t. φ(L, S) ≤ τ.

(11)

This value function provides the bridge between formulations of type (9) and their ‘ﬂipped’ coun-
terparts. Speciﬁcally, one can use Newton’s method to ﬁnd a solution to v(τ ) = ε. The approach
is agnostic to the linear operator L (it can be of the simple form (10), or include restriction in the
missing data case, etc.).
For both formulations of interest, φ is a norm deﬁned on a product space Rn×m × Rn×m, since

we can write

φsum(L, S) =

φmax(L, S) =

(cid:13)(cid:13)(cid:13)(cid:13) |||L|||∗
(cid:13)(cid:13)(cid:13)(cid:13) |||L|||∗

λmax(cid:107)S(cid:107)1

λsum(cid:107)S(cid:107)1

(cid:13)(cid:13)(cid:13)(cid:13)1
(cid:13)(cid:13)(cid:13)(cid:13)∞

7

,

.

(12)

(13)

A. ARAVKIN AND S. BECKER

In particular, both φsum(L, S) and φmax(L, S) are gauges as well as norms, and since we are able to
treat this level of generality, we focus our theoretical results on this wider class.

In order to implement Newton’s method for (11), the optimization problem to evaluate v(τ ) must
be solved (fully or approximately) to obtain (L, S). Then the τ parameter for the next (11) problem
is updated via

τ k+1 = τ k − v(τ k) − 
(τ k)

v

(cid:48)

.

(14)

(cid:48)

Given (L, S), v
simpliﬁes to

(τ ) can be written in closed form using Aravkin et al. (2013, Theorem 5.2), which

◦ denoting the polar gauge to φ. The polar gauge is precisely γ(cid:0)x | C

(LT∇ρ(L(L, S) − A)),

(τ ) = −φ

◦

v

(cid:48)

◦(cid:1), with

with φ

(15)

(16)
In the simplest case, where L is given by (10), and ρ is the least squares penalty, the formula (15)

C

= {v : (cid:104)v, x(cid:105) ≤ 1 ∀x ∈ C}.

◦

becomes

(cid:48)

(τ ) = −φ

v

◦(cid:18)(cid:20)L + S − A

L + S − A

(cid:21)(cid:19)

.

The main computational challenge in the approach outlined in (11)-(15) is to design a fast solver

to evaluate v(τ ). Section 3.5 does just this.

The key to RPCA is that the regularization functional φ is a gauge over the product space used to
decompose A into summands L and S. This makes it straightforward to compute polar results for
both φsum and φmax.
Theorem 8 (Max-Sum Duality for Gauges on Product Spaces) Let γ1 and γ2 be gauges on Rn1
and Rn2, and consider the function

g(x, y) = max{γ1(x), γ2(y)}.

Then g is a gauge, and its polar is given by

◦

g

(z1, z2) = γ

◦
1 (z1) + γ

◦
2 (z2).

Proof Let C1 and C2 denote the canonical sets corresponding to gauges γ1 and γ2. It immediately
follows that g is a gauge for the set C = C1 × C2, since

inf{λ ≥ 0|(x, y) ∈ λC} = inf{λ|x ∈ λC1 and y ∈ λC2}

= max{γ1(x), γ2(y)}.

By Rockafellar (1970a, Corollary 15.1.2), the polar of the gauge of C is the support function of C,
which is given by

sup

x∈C1,y∈C2

(cid:104)(x, y), (z1, z2)(cid:105) = sup
x∈C1
◦
1 (z1) + γ

= γ

(cid:104)x, z1(cid:105) + sup
y∈C2

◦
2 (z2).

(cid:104)y, z2(cid:105)

This theorem allows us to easily compute the polars for φsum and φmax in terms of the polars of

|||·|||∗ and (cid:107) · (cid:107)1, which are the dual norms of the spectral norm and inﬁnity norm, respectively.

8

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Corollary 9 (Explicit variational formulas for (SPCPsum) and (SPCPmax)) We have

(cid:26)

◦
φ
sum(Z1, Z2) = max
◦
max(Z1, Z2) = |||Z1|||2 +

|||Z1|||2,
1

φ

λmax

(cid:27)

1

(cid:107)Z2(cid:107)∞

λsum
(cid:107)Z2(cid:107)∞,

(17)

where |||X|||2 denotes the spectral norm (square root of the largest eigenvalue of X T X) and (cid:107)X(cid:107)∞
denotes the largest entry in absolute value.

We now have closed form solutions for v
(τ ) in (15) for both formulations of interest. The remaining
challenge is to design a fast solver for (11) for formulations (SPCPsum) and (SPCPmax). We focus on
this challenge in the remaining sections of the paper. We also discuss the advantage of (SPCPmax)
from this computational perspective.

(cid:48)

3.4 Projections
In this section, we consider the computational issues of projecting onto the set deﬁned by φ(L, S) ≤ τ.
For φmax(L, S) = max(|||L|||∗, λmax(cid:107)S(cid:107)1) this is straightforward since the set is just the product set
of the nuclear norm and (cid:96)1 norm balls, and efﬁcient projectors onto these are known. In particular,
projecting an m × n matrix (without loss of generality let m ≤ n) onto the nuclear norm ball takes
O(m2n) operations, and projecting it onto the (cid:96)1 ball can be done on O(mn) operations using fast
median-ﬁnding algorithms (Brucker, 1984; Duchi et al., 2008).
For φsum(L, S) = |||L|||∗ + λsum(cid:107)S(cid:107)1, the projection is no longer straightforward. Nonetheless,
the following lemma shows this projection can be efﬁciently implemented. This lemma appears in
van den Berg and Friedlander (2011, Section 9), but supply a proof here since it is not well-known.
We begin with a basic proposition:

Proposition 10 Projection onto the scaled (cid:96)1 ball, that is, {x ∈ Rd |(cid:80)d

αi > 0, can be done in O(d log(d)) time.
We conjecture that fast median-ﬁnding ideas could reduce this to O(d) in theory, the same as the
optimal complexity for the (cid:96)1 ball. The proof of the proposition follows by noting that the solution
can be written in a form depending only on a single scalar parameter, and this scalar can be found by
sorting (|xi|/αi) followed by appropriate summations. Armed with the above proposition, we state
an important lemma below. For our purposes, we may think of S as a vector in Rmn rather than a
matrix in Rm×n.

i=1 αi|xi| ≤ 1} for some

Lemma 11 Let L = U ΣV T and Σ = diag(σ), and let (Si)mn
i=1 be any ordering of the elements of S.
Then the projection of (L, S) onto the φsum ball is (U diag(ˆσ)V T , ˆS), where (ˆσ, ˆS) is the projection

onto the scaled (cid:96)1 ball {(σ, S) | (cid:80)min(m,n)

|σj| +(cid:80)mn

i=1 λsum|Si| ≤ 1}.

j=1

Proof [Sketch of proof] We need to solve

(cid:48)
{(L

,S

(cid:48)

min
(cid:48)
)| φsum(L

(cid:48)

)≤1}

,S

1
2

9

(cid:107)L

(cid:48) − L(cid:107)2

F

A. ARAVKIN AND S. BECKER

Alternatively, solve

(cid:32)

min
(cid:48)
S

{L

(cid:48)||||L

min

(cid:48)|||∗≤1−λsum(cid:107)S

(cid:33)

.

(cid:107)S

(cid:48) − S(cid:107)2

F

1
2

(cid:107)L

(cid:48) − L(cid:107)2

F +

1
2

(cid:48)(cid:107)1}

The inner minimization is equivalent to projecting onto the nuclear norm ball, and this is well-known
to be soft-thresholding of the singular values. Since it depends only on the singular values, recombin-
ing the two minimization terms gives exactly a joint projection onto a scaled (cid:96)1 ball.

All the references to the (cid:96)1 ball can be replaced by the intersection of the (cid:96)1 ball and the non-
negative cone, and the projection is still efﬁcient. As noted in Section 3, imposing non-negativity
constraints is covered by the gauge results of Theorem 8 and Corollary 9. Therefore, the level set
framework can be efﬁciently applied to this interesting case.

3.5 Solving the max ‘ﬂipped’ sub-problem via projected quasi-Newton methods

If we adopt φmax as the regularizer, then the subproblem (ﬂip-SPCPmax) takes the explicit form

min
L,S
s.t.

(cid:107)L + S − A(cid:107)2
1
2
|||L|||∗ ≤ τmax,

F

(cid:107)S(cid:107)1 ≤ τmax/λsum.

(18)

The computational bottle-neck is solving this problem quickly, once at each outer iteration. While
ﬁrst-order methods can be used, we can exploit the structure of the objective by using quasi-Newton
methods. The main challenge here is that for the |||L|||∗ term, it is tricky to deal with a weighted
quadratic term (whereas for (cid:107)S(cid:107)1, we can obtain a low-rank Hessian and solve it efﬁciently via
coordinate descent).
2(cid:107)L(X)−
Let X = (L, S) be the full variable, so we can write the objective function as f (X) = 1
A(cid:107)2
F . To simplify the exposition, we take L = (I, I), but the presented approach applies to general
linear operators (including terms like ProjΩ). The matrix structure of L and S is not yet important
here, so we can think of them as reshaped vectors instead of matrices.

The gradient is ∇f (X) = LT (L(X) − A). For convenience, we use r(X) = L(X) − A and

(cid:18)r(X)
(cid:19)

r(X)

= LT

rk ≡ r(Xk).

,

(cid:19)

(cid:18)∇Lf (X)
∇Sf (X)
(cid:19)

I
I

∇f (X) =

(cid:18)I

The Hessian is LTL =

. We cannot simultaneously project (L, S) onto their constraints
with this Hessian scaling (doing so would solve the original problem!), since the Hessian removes
separability. Instead, we use (Lk, Sk) to approximate the cross-terms.

I

10

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

The true function is a quadratic, so the following quadratic expansion around Xk = (Lk, Sk) is

exact:

f (L, S) = f (Xk) +

+

= f (Xk) +

+

= f (Xk) +

+

rk

1
2

, ∇2f

S − Sk

(cid:28)(cid:18)∇Lf (Xk)
(cid:19)
(cid:18)L − Lk
(cid:19)(cid:29)
(cid:19)
(cid:28)(cid:18)L − Lk
(cid:18)L − Lk
(cid:19)(cid:29)
∇Sf (Xk)
S − Sk
(cid:18)L − Lk
(cid:28)(cid:18)rk
(cid:19)
(cid:19)(cid:29)
S − Sk
(cid:18)I
(cid:28)(cid:18)L − Lk
(cid:19)
(cid:19)(cid:18)L − Lk
(cid:19)(cid:29)
S − Sk
(cid:19)(cid:29)
(cid:18)L − Lk
(cid:28)(cid:18)rk
(cid:19)
S − Sk
(cid:18)L − Lk + S − Sk
(cid:19)
(cid:28)(cid:18)L − Lk
S − Sk
(cid:18)I

L − Lk + S − Sk
(cid:19)

S − Sk

S − Sk

1
2

1
2

,

,

rk

I
I

I

,

,

,

(cid:19)(cid:29)

(cid:18)I

(cid:19)

The coupling of the second order terms, shown in bold, prevents direct 1-step minimization of f,
subject to the nuclear and 1-norm constraints. The FISTA method (Beck and Teboulle, 2009a)
replaces the Hessian
, which solves the coupling issue,
but potentially loses too much second order information. For (ﬂip-SPCPsum), FISTA is about the
best we can do (we actually use SPG (Wright et al., 2009b) which did slightly better in our tests).
However, for (ﬂip-SPCPmax)—and for (lag-SPCP), which has no constraints but rather non-smooth
terms, which can be treated like constraints using proximity operators—the constraints are uncoupled
and we can take a “middle road” approach, replacing

with the upper bound 2

0
0 I

I
I

I

(cid:28)(cid:18)L − Lk
S − Sk
(cid:19)
(cid:28)(cid:18)L − Lk

S − Sk

,

(cid:19)(cid:29)
(cid:18)L − Lk + S − Sk
(cid:19)
(cid:19)(cid:29)
(cid:18)L − Lk + Sk − Sk−1

L − Lk + S − Sk

Lk+1 − Lk + S − Sk

,

.

with

The ﬁrst term is decoupled, allowing us to update Lk, and then this is plugged into the second
term in a Gauss-Seidel fashion. In practice, we also scale this second-order term with a number
slightly greater than 1 but less than 2 (e.g., 1.25) which leads to more robust behavior. We expect
this “quasi-Newton” trick to do well when Sk+1 − Sk is similar to Sk − Sk−1.

4. Dual Smoothing and the Proximal Point method

This section describes the approach of the TFOCS algorithm (Becker et al., 2011) and its imple-
mentation2. The method is based on the proximal point algorithm and handles generic convex
minimization problems. The original analysis in Becker et al. (2011) was in terms of convex cones,
but we re-analyze the method here in terms of extended valued convex functions, and ﬁnd stronger
results.

2. http://cvxr.com/tfocs

11

A. ARAVKIN AND S. BECKER

Secondly, we compare to alternatives in the literature; the basic ingredients involved in TFOCS
are well-known in the optimization community, and there are many variants and applications. We
discuss in detail the relationship with the family of preconditioned ADMM methods popularized by
Chambolle and Pock (2010). The TFOCS algorithm also motivated the work of Devolder, Glineur,
and Nesterov 2012, which promotes an alternative approach that smooths both the primal and the
dual. This approach appeared to obtain stronger guarantees, but there is a price to pay, since in the
context of sparse optimization, smoothing the primal necessarily yields a less sparse solution. We
show that with the improved analysis of TFOCS, TFOCS in fact enjoys the same strong guarantees,
while avoiding smoothing the primal.

Finally, we apply this method to RPCA. The TFOCS formulation is ﬂexible and can solve
all standard variants of RPCA and SPCP, as well as incorporate non-negativity or other types of
additional constraints. We brieﬂy detail how the algorithm can be specialized for the RPCA problem.
Even without specializing the algorithm for RPCA, TFOCS has performed well. The results of tests
from Bouwmans and Zahzah (2014) are that “LSADM (Goldfarb et al., 2013) and TFOCS (Becker
et al., 2011) solvers seem to be the most adapted ones in the ﬁeld of video surveillance.”

4.1 General form of our optimization problem
In this section, we provide a general notation that captures all optimization problems of interest.
Note that even though we do not explicitly write constraints in this formulation, through the use of
extended-value functions we capture constraints, and so in particular can express residual-constrained
formulations using this notation.

We consider the following generic problem

min

x

ω(x) + ψ0(x) +

m(cid:88)

i=1

ψi(Lix − bi)

(19)

where

• ω and ψi for i = 0, . . . , m are proper convex lsc functions on their respective spaces,
• ω is differentiable everywhere, with Lipschitz continuous gradient; note that we can consider

ω(Lx − b) trivially, since this is also differentiable,

• ψi for i = 0, . . . , m has an easily computable proximity function,
• Li for i = 1, . . . , m is a linear operator, and bi is a constant offset.

We distinguish ψ0 from ψi, i ≥ 1, since ψ0 is not composed with a linear operator. This is signiﬁcant
since being able to easily compute the proximity operator of ψ does not imply one can easily compute
the proximity operator of ψi ◦ Li nor of ψi + ψj, so we deal with the i = 1, . . . , m terms specially.
Remark 12 Unlike the Li terms, the offsets bi can be absorbed into ψi, since if (cid:101)ψ(x) = ψ(x − b)
then Prox(cid:101)ψ(x) = b + Proxψ(x − b) (Combettes and Pesquet, 2011). Thus we make these offsets

explicit or implicit as convenient.

RPCA in the general setting (3) can be recovered from the above by setting x = (L, S),
ψ0(x) = φ(L, S), m = 1 and ψ1 = ρ with L1x = −L − S and b1 = −A, and ω = 0. In fact,

12

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

many convex problems from science and engineering ﬁt into this framework (Combettes and Pesquet,
2011). The strength of this particular model is that it is often easy to decompose a complicated
function f by a ﬁnite sum of simple functions ψi composed with linear operators. In this case, f
many not be differentiable, and Proxf need not be easy to compute, so the model allows us to exploit
the structure of the smaller building blocks.

4.2 Dual smoothing approach

We re-derive the algorithm described in Becker et al. (2011), but from a conjugate-function viewpoint,
whereas Becker et al. (2011) used a dual-conic viewpoint. The later viewpoint is subsumed in the
former, and is arguably less elegant.

Consider the problem

min

x

f (x) := ψ0(x) +

m(cid:88)

i=1

ψi(Lix − bi)

(20)

which is similar to (19) but without the differentiable term ω. In addition to our previous assumptions
on these functions (convex, lsc, proper), we now assume that at least one minimizer exists (guaranteed
if any function is coercive, or any set is bounded).

Our main observation is that instead of solving (20) directly, we can instead use the proximal

point method to minimize f, which exploits the fact that

(cid:16)

(cid:107)x − y(cid:107)2(cid:17)

min

x

f (x) = min

y

min

x

f (x) +

µ
2

.

(21)

This fact follows since f (x) ≤ f (x) + µ
the minimizers of f.

2(cid:107)x − y(cid:107)2, and equality is achieved by setting y to one of

Thus we solve a sequence of problems of the form

min

x

f (x) +

(cid:107)x − y(cid:107)2.

µ
2

for a ﬁxed y. The exact proximal point method is

yk+1 = arg min

x

Fk(x) := f (x) +

(cid:107)x − yk(cid:107)2

µk
2

(22)

(23)

where µk is any sequence such that lim sup µk < ∞, and y0 is arbitrary. Note that Fk depends on
µk and yk.

The beneﬁt of (22) over (20) is that Fk is strongly convex, whereas f need not be, and therefore

the dual problem of Fk is easy to solve, which we will make precise.

Rewriting the objective, and ignoring offset terms bi for simplicity (see Remark 12), we have

(cid:107)x − y(cid:107)2

+

ψi(Lix).

(24)

min

x

ψ0(x) +

(cid:124)

µ
2

(cid:123)(cid:122)

Φ(x)

m(cid:88)

i=1

(cid:125)

13

deﬁning a linear operator L and a vector z ∈ R(cid:80)m
For i = 1, . . . , m, each Li is a linear operator from Rn to Rmi. We can further simplify notation by

i=1 mi (e.g., z = L(X)) such that

A. ARAVKIN AND S. BECKER

 ,

...

L2(x)

Lm(x)

 L1(x)


Proxψ1
Proxψ2
...
Proxψm

(z1)
(z2)

(zm)

z =

z2
...
zm

 z1

 and ProxΨ

L(x) =

Then deﬁne

m(cid:88)

i=1

Ψ(z) =

ψi(zi), so ProxΨ(z) =

∗(z) =



∗
1
∗
2

Proxψ
Proxψ
...
Proxψ

∗
m

 .

(z1)
(z2)

(zm)

(25)

(26)

We now rewrite (24) in the following compact representation

min

x

Φ(x) + Ψ(Lx).

We are now in position to apply standard Fenchel-Rockafellar duality (Rockafellar, 1970b; Bauschke
and Combettes, 2011) to arrive at the dual problem

(cid:124)

Φ

min

z

(cid:123)(cid:122)

q(z)

(cid:125)

∗

∗
(L

z) + Ψ

∗

(−z)

.

(27)

Standard constraint qualiﬁcations for ﬁnite dimensional problems (e.g., Thm. 15.23 and Prop. 6.19x
in Bauschke and Combettes (2011)) guarantee a zero duality gap if
ri (domΨ) ∩ L (ri (domΦ)) (cid:54)= ∅.

The primal problem (26) is not amenable to computation because even though we can calculate
the proximity operators of Ψ and Φ, we cannot easily calculate the proximity operator of Ψ ◦ L.
The dual formulation (27) circumvents this because instead of asking for the proximity operator of
∗ ◦ L
∗, which is not easy, we will use its gradient, and in this case the linear term causes no issue.
Φ
We can do this because Φ is at least µ strongly convex, so we have the following well-known result
(see e.g., Prop. 12.60 in Rockafellar and Wets (1998)).

∗ is continuously differentiable and the gradient is Lipschitz continuous
∗ is also continuously differentiable with Lipschitz constant

∗ ◦ L

Lemma 13 The function Φ
with constant µ
(cid:107)L(cid:107)2/µ.

−1, and hence Φ

Note we are taking the operator norm of L, and |||L|||2 = (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)LL

gradient is can be determined by exploiting the relation

∗(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) = (cid:80)n

i=1 |||Li|||2. The actual

∗
∇Φ

(w) = ∂Φ

∗

(w) = ∂Φ

−1(w),

14

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

which follows from Fenchel’s equality (see Rockafellar (1970b, Theorem 23.5)), i.e., if x = ∇Φ
then 0 ∈ ∂Φ(x) − w, so x minimizes Φ(·) − (cid:104)w,·(cid:105). Thus
Φ(x) − (cid:104)x, w(cid:105)

(w) = arg min

∇Φ

∗

∗

(w)

x

x

ψ0(x) +

= arg min

µ
2
µ
2
= Proxψ0/µ (y + w/µ)

= arg min

ψ0(x) +

x

(cid:107)x − y(cid:107)2 − (cid:104)x, w(cid:105)
(cid:107)x − (y + w/µ)(cid:107)2

(28)
∗ ◦

∗

z).

∗
(L

. Furthermore, via the chain rule, we have ∇(Φ

so we can calculate the gradient using Proxψ0
∗
L

)(z) = L∇Φ
Thus we have shown that the dual problem (27) is a sum of two functions, one of which has a
Lipschitz continuous gradient and the other admits an easily computable proximity operator. Such
problems can be readily solved via proximal gradient methods (Combettes and Wajs, 2005) and
accelerated proximal gradient methods (Beck and Teboulle, 2009b, 2014).

∗
If strong duality holds, then if z(cid:63) is a solution of the dual problem, x(cid:63) = ∇Ψ

z(cid:63)) is the
unique solution to the primal problem (cf. Bauschke and Combettes (2011, Prop. 19.3)), and this was
used in Becker et al. (2011) to motivate solving the dual. We actually have much stronger results that
provide approximate optimality guarantees for approximate dual solutions.

∗
(L

Algorithm 1 TFOCS method (Becker et al., 2011), i.e., FISTA (Beck and Teboulle, 2009b) applied
to (27); enforcing tk = 1 recovers proximal gradient descent
Require: (cid:96) ≥ |||L|||2/µ bound on Lipschitz constant; z0 arbitrary
1: w1 = z0, t1 = 1.
2: for k = 1, 2, . . . do
3:
4:

wk) using (28)
∗
(L

∗
(L
∗

∗

Compute(cid:101)xk = ∇Φ
Set G = L(cid:101)xk = L∇Φ
zk = − Prox(cid:96)
√
tk+1 = 1+

−1Ψ
∗
1+4t2
k
2

6:
7: wk+1 = zk + tk−1
8: end for

tk+1

5:

(cid:17)

−1G

(cid:16)−wk + (cid:96)

wk)

≥ tk + 1/2
(zk − zk−1)

using (25) and (7)

We can bound the rate of convergence of the dual objective function q:

Theorem 14 (Thm. 4.4 in Beck and Teboulle (2009b)) The sequence (zk) generated by Algorithm 1
satisﬁes

q(zk) − min
where d0 is the distance from z0 to the optimal set.

z

q(z) ≤ 2(cid:96)d2
k2

0

From this, we can recover a remarkable bound on the primal sequence.

Theorem 15 (Thm. 4.1 in Beck and Teboulle (2014)) Let (xk) be the sequence generated by

xk = ∇Φ

∗

∗

(L

zk)

15

A. ARAVKIN AND S. BECKER

(similar to(cid:101)xk but evaluated at zk not wk). Let x(cid:63) be the (unique) optimal point to (26). Then

µ
2

(cid:107)xk − x(cid:63)(cid:107)2 ≤ q(zk) − min

z

q(z)

for any point zk, and hence for (zk) from Algorithm 1,
√
(cid:107)xk − x(cid:63)(cid:107) ≤ 2
(cid:96)d0√
µk

.

(29)

Note that in practice, one typically uses(cid:101)xk for any convergence tests, since it is a by-product of
then if zk converges, it follows that wk converges to the same limit, so asymptotically xk (cid:39)(cid:101)xk.
computation, whereas xk is expensive to compute. Since 0 ≤ (tk − 1)/tk+1 < 1 for tk ∈ [1,∞),

The result of the above theorem holds regardless of how the sequence (zk) is generated, so if the
dual method has better than worst-case convergence (or if an acceleration such as a line search is
used), then the primal sequence enjoys the same improvements.
√
√
µ shows that (cid:107)xk−x(cid:63)(cid:107) ∝ 1/(µk),
µ, combining with the other factor of 1/
so choosing µ large leads to fast convergence (since the dual problem is very smooth). The trade-off
is that the outer loop (the proximal point method) will converge more slowly with µ large.

(cid:96) = |||L|||/

√

Since

4.3 Comparison with literature
Dual methods The proposed method has been formulated in several contexts; part of the novelty
of Becker et al. (2011) is the generality of the method and pre-built function routines from which
a wide variety of functions could be constructed. The basic concepts of duality and smoothing are
widely used, and using duality to avoid difﬁcult afﬁne terms goes back to Uzawa’s method (see
(Ciarlet, 1989)) and the general concept of domain decomposition.

More recent and speciﬁc approaches include those of (Combettes et al., 2010; Liu et al., 2011;
Malgouyres and Zeng, 2009; Necoara and Suykens, 2008) which particularly deal with signal
processing problems. The work Combettes et al. (2010) considers a single smoothed problem, not the
full proximal point sequence, and uses proximal gradient descent to solve the dual. They establish
convergence of the primal variable but without a bound on the convergence rate. Explicit use of
the proximal point algorithm is mentioned in Liu et al. (2011), which focuses on the nuclear norm
minimization problem, but uses Newton-CG methods, which requires a third level of algorithm
hierarchy and good heuristic values for stopping criteria of the conjugate-gradient method. The
algorithm SDPNAL (Zhao et al., 2010) is similar to Liu et al. (2011) and uses a Newton-CG
augmented Lagrangian framework to solve general semi-deﬁnite programs (SDP). The work of
Malgouyres and Zeng (2009) focuses on a more speciﬁc version of the problem but contains the
same general ideas, and has inner and outer iterations. The algorithm in Necoara and Suykens (2008)
focuses on standard ADMM settings that have non-trivial linear terms, and smooths the dual problem;
they follow Nesterov (2005) and have speciﬁc complexity bounds when the appropriate constraint
set is compact.
Primal-dual methods Another method to remove effects of the linear terms Li is to solve a
(cid:80)m
primal-dual formulation. Many of these are based on duplicating variables into a product space
and then enforcing consensus of the duplicated variables. This can replace many terms, such as
i=1 ψi(Lix), with two generalized functions, which is inherently easier, since it is often amenable
to the Douglas-Rachford algorithm (Combettes and Pesquet, 2007). Speciﬁc examples of this

16

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

approach are (Combettes and Pesquet, 2012; Combettes, 2013; Becker and Combettes, 2014; Bot¸
et al., 2013b,a, 2015; Bot¸ and Csetnek, 2014). The paper by Briceo-Arias and Combettes (2011) is
slightly unique in that it reformulates the primal-dual problem into one that can be solved by the
obscure forward-backward-forward algorithm of Tseng (the forward-backward algorithm does not
apply since in the primal-dual setting, Lipschitz continuity does not imply co-coercivity).

Another main line of primal-dual methods was motivated in Esser et al. (2009) as a preconditioned
variant of ADMM and then analyzed in Chambolle and Pock (2010), and an improved analysis by He
and Yuan (2012a) allowed a generic formulation to be proposed independently by V˜u (2013); Condat
(2013). In more particular settings, it is known as linearized ADMM or primal-dual hybrid gradient
(PDHG), and has seen a recent surge of interest and analysis (Tran-Dinh and Cevher, 2014; He and
Yuan, 2012b; Li et al., 2014; Ren and Lin, 2013; Wang and Yuan, 2012; Yang and Yuan, 2013; Zhang
et al., 2010; Yang and Zhang, 2011; Goldstein et al., 2013). Several recent survey papers (Cevher
et al., 2014; Komodakis and Pesquet, 2015) review these algorithms in more detail.

The PDHG has not been applied speciﬁcally to the RPCA problem to our knowledge. The next

section describes this method in more detail.
Detailed comparison with PDHG On certain classes of problems, our approach is quite similar
to the PDHG approach. Consider the following simpliﬁed version of (20):

ψ0(x) + ψ1(Lx − b)

min

x

At each step of the proximal point algorithm, we minimize the above objective perturbed by µ/2(cid:107)x−
y(cid:107)2, where µ > 0 is arbitrary. Applying FISTA to the dual problem leads to steps of the following
form:

xk+1 = arg min

x

zk+1 = arg min

z

ψ0(x) − (cid:104)z, Lx − b(cid:105) +
∗
1(z) − (cid:104)z, Lxk+1(cid:105) +
ψ

(cid:107)x − y(cid:107)2
(cid:107)z − zk(cid:107)2

µ
2
1
2t

z = zk+1 + θk (zk+1 − zk)

where θk = (tk − 1)/tk−1 as in Algorithm 1 (and limk→∞ θk = 1). We require the stepsize t to
satisfy t ≤ µ/(cid:96)2.

For the PDHG method, pick stepsizes τ σ < 1/(cid:96)2. There is no outer loop over y, and the full

algorithm is:

zk+1 = arg min

z

xk+1 = arg min

x

∗
1(z) − (cid:104)z, Lx(cid:105) +
1
ψ
2σ
ψ0(x) − (cid:104)z, Lx − b(cid:105) +

(cid:107)z − zk(cid:107)2
1
2τ

(cid:107)x − xk(cid:107)2

x = xk+1 + θ (xk+1 − xk)

with θ = 1 (see Algorithm 1 in Chambolle and Pock (2010)).

The two algorithms are extremely similar, the main differences being that the TFOCS approach
updates y occasionally, while PDHG updates y = xk every iteration of the inner algorithm and thus
avoids the outer iteration completely. The lack of the outer iteration is an advantage, mainly since
it avoids the issue of a stopping criteria. However, the advantage of an inner iteration is that we

17

A. ARAVKIN AND S. BECKER

can apply an accelerated Nesterov method, which can only be done in the PDHG if one has further
assumptions on the objective function.

We present a numerical comparison of the two algorithms applied to RPCA in Figures 2 and 3.

√

Detailed comparison with double-smoothing approach For minimizing smooth but not strongly
convex functions f, classical gradient descent generates a sequence of iterates (xk) such that
the objective converges at rate f (xk) − minx f (x) ≤ O(1/k), and (xk) itself converges, with
(cid:107)∇f (xk)(cid:107) ≤ O(1/
k). The landmark work of Nesterov (1983) showed that a simple acceleration
technique similar to the heavy-ball method generates a sequence (xk) such that f (xk)−minx f (x) ≤
O(1/k2), although there are no guarantees about convergence of the sequence3 (xk) nor strong
bounds on (cid:107)∇f (xk)(cid:107). Note that our dual scheme uses FISTA (Beck and Teboulle, 2009a) which is a
generalization of Nesterov’s scheme; we refer to any such scheme with O(1/k2) as “accelerated”.
Deﬁning an -solution to be a point x such that f (x) − minx f (x) ≤ , we see that it takes
√
O(1/) and O(1/
) iterations to reach such a point using the classical and accelerated gradient
descent schemes, respectively.

In 2005 Nesterov introduced a smoothing technique (Nesterov, 2005) which applies to minimizing
√
non-smooth functions over compact sets. A naive approach would use sub-gradient descent, in which
the worst-case convergence of the objective is O(1/
k). By smoothing the primal function by a
sufﬁciently small ﬁxed amount, then using the compact constraints, the smooth function differs from
the original function by less than /2. One can then apply Nesterov’s accelerated method which
√
generates an /2-optimal point (to the smoothed problem, and hence  optimal to the original problem
) in O((cid:96)/
) iterations. The catch is that (cid:96) is the Lipschitz constant of the smoothed objective,
which is proportional to 1/2, so the overall convergence rate is O(1/), which is still better than the
subgradient schemes that would take O(1/2).

The aforementioned smoothing technique is an alternative to our approach, but the two are not
directly comparable, since we do not assume the objective has the same form, nor is our domain
necessarily bounded. Furthermore, smoothing the primal objective can have negative consequences.
For example, it is common to solve (cid:96)1 regularized problems in order to generate sparse solutions.
Our dual-smoothing technique keeps the primal non-smooth and therefore still promotes sparsity,
whereas a primal-smoothing technique would replace (cid:96)1 with the Huber function, and this does not
promote sparsity; see Fig. 1 in Becker et al. (2011).

Another option is the double-smoothing technique proposed by Devolder et al. (2012). This is
the approach most similar with our own. Like our approach, a strongly convex term is added to
the primal problem in order to make the dual problem smooth, and then the dual problem is solved
with an accelerated method. Departing from our approach, they additionally smooth the primal as
well (as in Nesterov (2005)), which makes the dual problem strongly convex. The reason for this is
subtle. Without the strong convexity in the dual (i.e., our approach), we only have a bound on the
dual objective function. To translate this into a bound on the primal variable, measured in terms of
objective function or distance to the feasible set, requires using the gradient of the dual variable. As
mentioned above, accelerated methods have faster rates of convergence in the objective but not of the
gradients. For this reason, one must resort to a classical gradient descent method which has slower
rates of convergence.

3. There is no experimental evidence that the sequence does not converge, and indeed a recent preprint shows that a

slight modiﬁcation of the algorithm can guarantee convergence(Chambolle and Dossal, 2014)

18

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Making the dual problem strongly convex allows the use of special variants of Nesterov’s
accelerated method (see Nesterov (2004)) which converge at a linear rate, and, importantly, so do the
iterates and their gradients. The convergence is in terms of the smooth and perturbed problem, so
the size of these perturbations is controlled in such a manner (again, the domains are assumed to be
bounded) such that one recovers a O(1/ log(1/)) convergence rate.

The analysis of Devolder et al. (2012) suggests that our method of single smoothing is ﬂawed,
but this seems to be an artifact of previous analysis. Using Theorem 15, which is a recent result, we
have a rate on the convergence of the primal sequence, rather than on its objective value or distance
to optimality. In many situations this is a stronger measure of convergence, depending on the purpose
of solving the optimization problem. For robust PCA, the distance to the true solution is indeed a
natural metric, whereas sub-optimality of the objective function is rather artiﬁcial, and distance to
the feasible set depends on the choice of model parameters which maybe somewhat arbitrary.

Furthermore, the lack of bounds on the iterate sequence generated by an accelerated method,
which was the issue in the analysis of Devolder et al. (2012), is mainly a theoretical one, since in
most practical situations, the variables and their gradients do appear to converge at a fast rate. Our
situation is also different since the constraints need not be compact, and we use the proximal point
method to reduce the effect of the smoothing.

4.4 Effect of the smoothing term
The next section discusses convergence of the proximal point method, but we ﬁrst discuss the
phenomenon that sometimes, the proximal point method converges to the exact solution in a ﬁnite
number of iterations. This case is not covered by classical exact penalty results (Bertsekas et al.,
2003), which only apply when the perturbation is non-smooth (e.g., (cid:107)x − y(cid:107)), whereas we use a
smooth perturbation (cid:107)x − y(cid:107)2.

Whenever the functions and constraints are polyhedral, such as for linear programs, ﬁnite
convergence (or the “exact penalty” property) will occur. This was known since the 1970s; see Prop.
8 in Rockafellar (1976) and (Mangasarian and Meyer, 1979; Poljak and Tretjakov, 1974; Bertsekas,
1975). The special case of noiseless basis pursuit was recently analyzed in Yin (2010) using different
techniques. More general results, allowing a range of penalty functions, were proved in Friedlander
and Tseng (2007).

For non-polyhedral problems, exact penalty does not occur in general. For example, one can
construct an example of nuclear norm minimization which does not have the exact penalty property.
However, under additional assumptions that are typical to guarantee exact recovery in the sense of
Cand´es and Plan (2010), it is possible to obtain exact penalty results. Research in this is motivated by
the popularity of the (Cai et al., 2010) algorithm, which is a special case of the TFOCS framework
applied to matrix completion. Results are in Lai and Yin (2013), as well as Zhang et al. (2012) (and
the correction You et al. (2013)) which also provides results for the RPCA problem in particular.
Some results on generalizations to tensors are also available Shi et al. (2013).

4.5 Convergence
Certiﬁcates of accuracy of the sub-problem For solving the smoothed sub-problem minx Fk(x),
we assume the proximity operator of each ψi is easy to compute, and given this, it is reasonable to
expect that it is easy to compute a point in ∂ψi as well. Furthermore, since the algorithm computes the
effect of the linear operators on the current iterate, it may be possible to reuse previously computed

19

A. ARAVKIN AND S. BECKER

values. Thus, computing a point in ∂Fk may be relatively cheap since it is just the sum of the ∂ψi
composed with the appropriate linear operators. We can now obtain accuracy guarantees via the
following proposition.
Proposition 16 (Rockafellar, 1976, Prop. 3) Let y = arg minx Fk(x), then for all points x and all
d ∈ ∂Fk(x),

(cid:107)x − y(cid:107) ≤ µ

−1
k (cid:107)d(cid:107).

(30)

Convergence of the proximal point method The convergence of the proximal point method is
well-understood, but we are particularly interested in the case when the update step is computed
inaccurately. There has been recent work on this (see e.g. (M. Schmidt, 2011; Villa et al., 2013;
Devolder et al., 2011)) but often under the assumption that the computed point is feasible, i.e., it
is inside domf. Using the dual method, this cannot be guaranteed in general (though it certainly
applies to many special cases). One can apply the analysis of gradient descent from (Devolder et al.,
2011) to the proximal point algorithm (viewed as gradient descent on the Moreau-Yosida envelope),
and compute an inexact gradient in the sense that the primal point is the exact gradient of a perturbed
point. This perturbed point is based on the sub-optimality of the dual variable (see (28)), which, per
the discussion of Devolder et al. (2012) above, does not have a bounded converge rate when using an
accelerated algorithm, and hence we do not pursue this line of analysis.

We start with an extremely broad theorem that guarantees convergence under minimal assump-

tions, albeit without an explicit convergence rate:
Theorem 17 (Rockafellar, 1976, Thm. 1) The approximate proximal point method deﬁned by

˜yk+1 = arg min Fk(x)
yk+1 any point satisfying (cid:107)yk+1 − ˜yk+1(cid:107) ≤ k

with(cid:80)∞

k=1 k < ∞, y0 arbitrary, Fk as deﬁned in (23), and lim supk→∞ µk < ∞, will generate a

sequence {yk} that converges to a minimizer of f.
We note that the boundedness of iterates follows by our assumption that a minimizer exists; in inﬁnite
dimensions, convergence is in the weak topology. To guarantee (cid:107)yk+1 − ˜yk+1(cid:107) ≤ k, we can either
bound this a priori using Thm. 15, or we can bound it a posteriori by explicitly checking using
Prop. 16.

We state a second theorem that guarantees local linear convergence under standard assumptions.
This assumption is that there is a unique solution to min f (x) and that f has sufﬁcient curvature
nearby; it is related to the standard second-order sufﬁciency condition, but slightly weaker. See
Rockafellar (1976) for an early use, and Burke and Qian (1997) for a more recent discussion.
−1 is locally
Assumption 1 There is a unique solution x(cid:63) to min f (x), i.e., ∂f
Lipschitz continuous at 0 with constant a, i.e., there is some r such that (cid:107)w(cid:107) ≤ r implies (cid:107)x− x(cid:63)(cid:107) ≤
a(cid:107)w(cid:107) whenever x ∈ ∂f
Recall that via basic convex analysis, 0 ∈ ∂f (x(cid:63)). Finding arg min Fk(x) is the same as computing
−1. Deﬁne Qk = I − Pk, then we have that Pk (and Qk)
the proximity operator Pk
are ﬁrmly non-expansive (Moreau, 1965; Bauschke and Combettes, 2011), meaning
(cid:48)(cid:107)2.

−1(0) = x(cid:63); and ∂f

)(cid:107)2 ≤ (cid:107)x − x

−1
k ∂f )

−1(w).

def= (I + µ

(cid:48)
∀x, x

, (cid:107)Pk(x) − Pk(x

)(cid:107)2 + (cid:107)Qk(x) − Qk(x

(cid:48)

(cid:48)

20

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Furthermore, x(cid:63) = Pk(x(cid:63)) (this is independent of µk), and Qk(x(cid:63)) = 0. Now, we state a novel
theorem, where for simplicity we have assumed µk ≡ µ (cid:54)= 0:
Theorem 18 Under Assumption 1, the approximate proximal point method deﬁned by

˜yk+1 = arg min Fk(x)
yk+1 any point satisfying (cid:107)yk+1 − ˜yk+1(cid:107) ≤ (γ/2)k

with

a(cid:113)

a2 + µ

γ =

< 1

−2

generates a sequence (yk) that converges linearly to x(cid:63) for all k sufﬁciently large, and with rate γ.
Proof Note that we have deﬁned ˜yk+1 = Pk(yk). Observe that the assumption of Theorem 17
holds since the errors are clearly summable, hence (yk) converges, and (cid:107)yk+1 − yk(cid:107) → 0, so this is
arbitrarily small for k sufﬁciently large. We also have

(cid:107)Qk(yk)(cid:107) = (cid:107)yk − Pk(yk)(cid:107) ≤ (cid:107)yk − yk+1(cid:107) + (cid:107)yk+1 − Pk(yk)(cid:107)

and both the terms on the right side go to zero. By basic convex analysis (e.g., Prop. 1a in Rockafellar
(1976)),

Pk(yk) ∈ ∂f

−1(µQk(yk))

and so for k large enough (say, k ≥ k0), we are in the Lipschitz region of the assumption, so

(cid:107)Pk(yk) − x(cid:63)(cid:107) ≤ a(cid:107)µQk(yk)(cid:107).

Now using the ﬁrmly non-expansiveness and properties of x(cid:63) mentioned above,

(cid:107)x(cid:63) − Pk(yk)(cid:107)2 + (cid:107)Qk(yk)(cid:107)2 ≤ (cid:107)x(cid:63) − yk(cid:107)2

so combining (31) with (32) gives

(cid:107)x(cid:63) − Pk(yk)(cid:107) ≤ γ(cid:107)x(cid:63) − yk(cid:107)

(31)

(32)

which in effect proves the eventual linear convergence in the exact case where yk+1 = Pk(yk) (up to
this point, the proof follows Thm. 2 from Rockafellar (1976)).

Now bound

(cid:107)yk+1 − x(cid:63)(cid:107) ≤ (cid:107)yk+1 − Pk(yk)(cid:107) + (cid:107)Pk(yk) − x(cid:63)(cid:107)

≤ (γ/2)k + γ(cid:107)yk − x(cid:63)(cid:107)
≤ (γ/2)k + γ

(γ/2)k−1 + γ(cid:107)yk−1 − x(cid:63)(cid:107)(cid:17)

(cid:16)

...

≤ γk

k(cid:88)
≤ γk(cid:16)
1 + γ1−k0(cid:107)yk0

i=k0

− x(cid:63)(cid:107)(cid:17)

−i + γk+1−k0(cid:107)yk0

2

− x(cid:63)(cid:107)

21

A. ARAVKIN AND S. BECKER

which proves our result.

Again, we can certify that yk+1 (cid:39) Pk(yk) either use Thm. 15, or we can bound it a posteriori by
explicitly checking using Prop. 16. Since the linear convergence only occurs locally, it is not possible
to provide an overall iteration-complexity of the inner and outer iterations (it is possible with further
assumptions on f, such as f having full domain; see Becker (2011)). Without some form of strong
convexity near the solution, it is generally not possible to bound the rate on the iterates, but rather
only bound the rate of the objective function, and this is not possible with the dual approach since
the point may not be feasible.

If we assume that the linear converges occurs globally, then we can combine this with our
complexity bound on the sub-problem from (29). Converting that rate to our new notation, and using
j to index the inner loop, and setting the initial dual variable z0 to the one corresponding to yk, we
have

(cid:107)L(cid:107)dk
µ · j
∗
where dk is the distance from z0 (corresponding to yk = ∇Φ
z0)) to the optimal set of dual
solutions. Bounding this explicitly can be done in some cases (see Bruer et al. (2014)), but for the
sake of analysis we will simply assume dk is upper-bounded by some d.

(cid:107)xj − Pk(yk)(cid:107) ≤ 2

∗
(L

4.6 Solving the dual problem efﬁciently in the case of RPCA
For solving (2), we set ψ0(L, S) = |||L|||∗ + λ(cid:107)S(cid:107)1 and ψ1(L(L, S) − A) = χ{0}(L + S − A) to
enforce the constraint exactly. In this case, ψ
is the identity
— that is to say, the dual problem is unconstrained.

∗
1 is the constant function, and so Proxψ

∗
1

In that case, instead of using FISTA to solve the dual, one may use techniques from unconstrained
optimization, such as non-linear conjugate gradient and L-BFGS (Nocedal and Wright, 2006). These
algorithms work extremely well in practice. We do not go into further detail since we ﬁnd the
exact constraint formulation of RPCA to be artiﬁcial. With inequality constraints, the dual problem
becomes non-smooth so it is necessary to use a proximal gradient method. Due to the cost of the
objective function, it may be worthwhile to use quasi-Newton projected gradient methods such as
that of Schmidt et al. (2009).

5. Numerical Experiments
5.1 Numerical results for TFOCS
To highlight the ﬂexibility of TFOCS, we consider a background subtraction problem of a surveillance
video in which we do not wish to enforce A = L + S but instead we wish to separate A into
components up to the quantization level. The video A is quantized to integer values between 0 and

255, so we can think of this as being the quantized version of some real-valued video (cid:98)A, and thus
(cid:107)(cid:98)A − A(cid:107)∞ ≤ 0.5 since the quantized version is rounded to the nearest integer. Hence we solve the

following:

φ0(L, S) = |||L|||∗ + λ(cid:107)S(cid:107)1

s.t. (cid:107)A − L − S(cid:107)∞ ≤ 0.5.

(33)
In the TFOCS software (written in MATLAB), we work with the primal variable X={L,S}, and

min
L,S

one speciﬁes the fucntion ψ0 in the term obj like

22

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

= { prox_nuclear(1), prox_l1(lambda) };

obj
Next we encode ψ1 and L1 and b1. The linear term, applied to X={L,S}, is L1 = [I, I], and the
offset is b1 = −A. This is encoded as
affine = { 1, 1, -A };

and ψ1 is represented implicitly by giving its conjugate. For standard equality constrained RPCA, the
constraint is A − L − S = 0, so ψ1 is the indicator function of the set {0}, and the conjugate of this
is the function that is constant everywhere, so its proximity operator is the identity (i.e., projection
on Rn). This is written
dualProx = proj_Rn

If instead we wish to solve (33), then ψ1 is the indicator function of the (cid:96)∞ ball of radius 1/2,

and so its conjugate is 1/2(cid:107) · (cid:107)1, which is written
dualProx = prox_l1(0.5);

The code can then be called as follows:

X = tfocs_SCD( obj, affine, dualProx, mu, X0 );

(a) A

(b) L

(c) S

Figure 1: Frame 110 from the movie, showing original A, low-rank L and sparse S components

More detailed code is available as a demo at 4; the video data is from 5. Results are shown in
Fig. 1. Although the walking person is correctly identiﬁed in the S component, a small amount of
the person appears in L. However, it is remarkable that the low-rank component mostly captures the
moving escalator, which is a feat that most background subtraction cannot do without a specially
targeted algorithm.
Comparison with PDHG As discussed in §4.3, the primal-dual hybrid gradient (PDHG) method
is similar to the TFOCS algorithm. In TFOCS, one controls the value of µ and then runs the proximal
point algorithm, and the sub-problem is solved by FISTA (or variants) that use linesearch techniques
and therefore do not need a stepsize. In PDHG, there is no line search, but there are two stepsizes
τ and σ which are linked in the fashion τ σ < 1/(cid:96)2. Larger stepsizes generally lead to better
performance, so by insisting τ σ = 0.99/(cid:96)2, there is only one effective parameter choice.

Using a version of the same escalator ﬁlm discussed in the previous section, we compare PDHG

and TFOCS on (SPCPsum). In TFOCS, we encode this with
4. http://cvxr.com/tfocs/demos/rpca/
5. http://perception.i2r.a-star.edu.sg/bk_model/bk_index.html

23

A. ARAVKIN AND S. BECKER

(a) TFOCS

(b) PDHG

Figure 2: Convergence plots on the elevator data, for various parameter values. The small dots in

the TFOCS plot show where the proximal point algorithm took another outer step.

(a) TFOCS

(b) PDHG

Figure 3: Number of iterations to reach a ﬁxed tolerance, as function of parameter value

dualProx = prox_l2(epsilon);

The parameters  and λ were chosen by running the quasi-Newton solver on (lag-SPCP) and tuning
by hand until results looked acceptable. Running the special purpose solver gives a very accurate
reference answer. From the solution to (lag-SPCP), one can infer  and λsum.

Neither method is speciﬁc for RPCA problems, so we do not expect cutting-edge performance,
but we do see reliable performance, and the ability to adapt to variations in the model. We focus on
parameter selection. Both methods perform roughly equally, and both are strongly dependent on
the parameter choice. A major weakness of all current methods is lack of guidance for choosing
parameters in practice; the effort of Pock and Chambolle (2011) to ﬁnd good values resulted in mixed
success. The software TFOCS automatically rescales variables in order to make all Li terms have
the same spectral norm, which has a small beneﬁcial effect.

Fig. 2 shows the decay of the relative error

F + (cid:107)S0(cid:107)2
F
where (L0, S0) is the accurate reference solution computed via the quasi-Newton algorithm. TFOCS
has the advantage that the sub-problems can use a fast solver with a good linesearch, but the
disadvantage that with the two levels of iterations, the inner iteration must be terminated at the right

F + (cid:107)S − S0(cid:107)2
F /

(cid:113)(cid:107)L − L0(cid:107)2

(cid:113)(cid:107)L0(cid:107)2

24

02040608010−310−210−1IterationsRelativeerror  µ = 1.0e−04µ = 1.0e−03µ = 1.0e−02µ = 1.0e−0102040608010010−310−210−1IterationsRelativeerror  σ = 1.0e−05 τσ = 1.0e−03 τσ = 1.0e−01 τσ = 1.0e+01 τ10−210−110005101520253035Iterationstoreach5%relativeerrorValueofµ10−510−410−310−210−110005101520253035Iterationstoreach5%relativeerrorRatioofσ/τDUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

time. If it is stopped too early, the solution is not accurate enough, while if it is stopped too late, the
algorithm wastes time on ﬁnding a very precise answer to a useless intermediate problem.

Fig. 3 shows the number of iterations required to reach a ﬁxed tolerance. Conﬁrming the behavior
in the previous ﬁgure, it is clear that convergence can be rapid for good parameter choices, and slow
for poor parameter choices.

5.2 Numerical results for quasi-Newton algorithm

We compare new algorithms and formulations to PSPG (Aybat et al., 2013), NSA (Aybat and Iyengar,
2013), and ASALM (Tao and Yuan, 2011)6. We modiﬁed the other software as needed for testing
purposes. PSPG, NSA and ASALM all solve (SPCPsum), but ASALM has another variant which
solves (lag-SPCP) so we test this as well. All three programs also use versions of PROPACK from
Becker and Cand`es (2008) to compute partial SVDs. We measure error as a function of time, since
cost of a single iteration can vary among the solvers. To fairly compare all the algorithms in the
simulated experiments, we measure the (relative) error of a trial solution (L, S) to a reference solution
(L(cid:63), S(cid:63)) as (cid:107)L − L(cid:63)(cid:107)F /(cid:107)L(cid:63)(cid:107)F + (cid:107)S − S(cid:63)(cid:107)F /(cid:107)S(cid:63)(cid:107)F . Time to compute this error is accounted for
(so does not factor into the comparisons). Finally, since stopping conditions are solver dependent, we
show plots of error vs time. All tests are done in Matlab and the dominant computational time was
due to matrix multiplications for all algorithms; all code was run in the same quad-core 1.6 GHz i7
computer.

For our implementations of the (ﬂip-SPCPmax), (ﬂip-SPCPsum) and (lag-SPCP), we use a ran-
domized SVD (Halko et al., 2011). Since the number of singular values needed is not known in
advance, the partial SVD may be called several times (the same is true for PSPG, NSA and ASALM).
Our code limits the number of singular values on the ﬁrst two iterations in order to speed up calcula-
tion without affecting convergence. Since the projection required by (ﬂip-SPCPsum) makes a partial
SVD difﬁcult, so we use Matlab’s dense SVD routine.

5.2.1 SYNTHETIC TEST WITH EXPONENTIAL NOISE
We ﬁrst provide a test with generated data. The observations A ∈ Rm×n with m = 400 and n = 500
were created by ﬁrst sampling a rank 20 matrix A0 with random singular vectors (i.e., from the Haar
measure) and singular values drawn from a uniform distribution with mean 0.1, and then adding
exponential random noise to the entire mtrix (with mean equal to one tenth the median absolute value
of the entries of A0). This exponential noise, which has a longer tail than Gaussian noise, is expected
to be captured partly by the S term and partly by the error term (cid:107)L + S − A(cid:107)F .

Given A, the reference solution (L(cid:63), S(cid:63)) was generated by solving (lag-SPCP) to very high
−2 were picked by hand tuning (λL, λS) to ﬁnd a value
accuracy; the values λL = 0.25 and λS = 10
such that both L(cid:63) and S(cid:63) are non-zero. The advantage to solving (lag-SPCP) is that knowledge of
(L(cid:63), S(cid:63), λL, λS) allows us to generate the parameters for all the other variants, and hence we can test
different problem formulations.
With these parameters, L(cid:63) was rank 17 with nuclear norm 6.754, S(cid:63) had 54 non-zero entries (most
of them positive) with (cid:96)1 norm 0.045, the normalized residual was (cid:107)L(cid:63) + S(cid:63) − A(cid:107)F /(cid:107)A(cid:107)F = 0.385,
and ε = 1.1086, λsum = 0.04, λmax = 150.0593, τsum = 6.7558 and τmax = 6.7540.

6. PSPG, NSA and ASALM available from the experiment package at http://www2.ie.psu.edu/aybat/

codes.html

25

A. ARAVKIN AND S. BECKER

Figure 4: The exponential noise test. The asterisk in the legend means the method uses a fast SVD

(i.e., randomized SVD).

Results are shown in Fig. 4. Our methods for (ﬂip-SPCPmax) and (lag-SPCP) are extremely fast,
because the simple nature of these formulations allows the quasi-Newton acceleration scheme of
Section 3.5. In turn, since our method for solving (SPCPmax) uses the variational framework of
Section 3 to solve a sequence of (ﬂip-SPCPmax) problems, it is also competitive (shown in cyan in
Figure 4). The jumps are due to re-starting the sub-problem solver with a new value of τ, generated
according to (14).

Our proximal gradient method for (ﬂip-SPCPsum), which makes use of the projection in Lemma 11,
converges more slowly, since it is not easy to accelerate with the quasi-Newton scheme due to variable
coupling, and it does not make use of fast SVDs. Our solver for (SPCPsum), which depends on a
sequence of problems (ﬂip-SPCPsum), converges slowly.

The ASALM performs reasonably well, which was unexpected since it was shown to be worse
than NSA and PSPG in (Aybat et al., 2013; Aybat and Iyengar, 2013). The PSPG solver converges to
the wrong answer, most likely due to a bad choice of the smoothing parameter µ; we tried choosing
several different values other than the default but did not see improvement for this test (for other
tests, not shown, tweaking µ helped signiﬁcantly). The NSA solver reaches moderate error quickly
but stalls before ﬁnding a highly accurate solution.

5.2.2 SYNTHETIC TEST FROM AYBAT AND IYENGAR (2013)

The default setting of λsum = 1/(cid:112)max(m, n) was used, and then the NSA solver was run to high

We show some tests from the test setup of Aybat and Iyengar (2013) in the m = n = 1500 case.

accuracy to obtain a reference solution (L(cid:63), S(cid:63)). From the knowledge of (L(cid:63), S(cid:63), λsum), one can
generate λmax, τsum, τmax, ε, but not λS and λL, and hence we did not test the solvers for (lag-SPCP)
in this experiment. The data were generated as A = L0 + S0 + Z0, where L0 was sampled by
multiplication of m × r and r × n normal Gaussian matrices, S0 had p randomly chosen entries
uniformly distributed within [−100, 100], and Z0 was white noise chosen to give a SNR of 45 dB.
We show three tests that vary the rank from {0.05, 0.1} · min(m, n) and the sparsity ranging from

26

0246810121410−410−310−210−1100101102time (s)Error  this paper* (flip−SPCP−max, QN)this paper (flip−SPCP−sum)this paper* (lag−SPCP, QN)this paper* (SPCP−max, QN)this paper (SPCP−sum)NSA* (SPCP−sum)PSPG* (SPCP−sum)ASALM* (SPCP−sum)ASALM* (lag−SPCP)DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

p = {0.05, 0.1} · mn. Unlike Aybat and Iyengar (2013), who report error in terms of a true noiseless
signal (L0, S0), we report the optimization error relative to (L(cid:63), S(cid:63)).
For the ﬁrst test (with r = 75 and p = 0.05·mn), L(cid:63) had rank 786 and nuclear norm 111363.9; S(cid:63)
−4.
had 75.49% of its elements nonzero and (cid:96)1 norm 5720399.4, and (cid:107)L(cid:63)+S(cid:63)−A(cid:107)F /(cid:107)A(cid:107)F = 1.5·10
The other parameters were ε = 3.5068, λsum = 0.0258, λmax = 0.0195, τsum = 2.5906 · 105 and
τmax = 1.1136 · 105. An interesting feature of this test is that while L0 is low-rank, L(cid:63) is nearly
low-rank but with a small tail of signiﬁcant singular values until number 786. We expect methods to
converge quickly to low-accuracy, and then slow down as they try to ﬁnd a highly-accurate larger
rank solution.

Figure 5: The 1500 × 1500 synthetic noise test.

The results are shown in Fig. 5. Errors barely dip below 0.01 (for comparison, an error of 2
is achieved by setting L = S = 0). The NSA and PSPG solvers do quite well. In contrast to the
previous test, ASALM does poorly. Our methods for (ﬂip-SPCPsum), and hence (SPCPsum), are not
competitive, since they use dense SVDs. We imposed a time-limit of about one minute, so these
methods only manage a single iteration or two. Our quasi-Newton method for (ﬂip-SPCPmax) does
well initially, then takes a long time due to a long partial SVD computation. Interestingly, (SPCPmax)
does better than pure (ﬂip-SPCPmax). One possible explanation is that it chooses a fortuitous sequence
of τ values, for which the corresponding (ﬂip-SPCPmax) subproblems become increasingly hard,
and therefore beneﬁt from the warm-start of the solution of the easier previous problem. This is
consistent with empirical observations regarding continuation techniques, see e.g., (Van den berg and
Friedlander, 2008; Wright et al., 2009b).
Fig. 6 is the same test but with r = 150 and p = 0.1· mn, and the conclusions are largely similar.

5.2.3 CLOUD REMOVAL
Figure 7 shows 15 images of size 300 × 300 that come from the MODIS satellite7, after some
transformations to turn images from different spectral bands into one grayscale images. Each image
is a photo of the same rural location but at different points in time over the course of a few months.
The background changes slowly and the variability is due to changes in vegetation, snow cover, and
different reﬂectance. There are also outlying sources of error, mainly due to clouds (e.g., major

7. Publicly available at http://ladsweb.nascom.nasa.gov/

27

010203040506070809010010−210−1100time (s)Error  this paper* (flip−SPCP−max, QN)this paper (flip−SPCP−sum)this paper* (SPCP−max, QN)this paper (SPCP−sum)NSA* (SPCP−sum)PSPG* (SPCP−sum)ASALM* (SPCP−sum)A. ARAVKIN AND S. BECKER

Figure 6: Second 1500 × 1500 synthetic noise test.

Figure 7: Satellite photos of the same location on different days.

clouds in frames 5 and 7, smaller clouds in frames 9, 11 and 12), as well as artifacts of the CCD
camera on the satellite (frame 4 and 6) and issues stitching together photos of the same scene (the
lines in frames 8 and 10).

There are many applications for clean satellite imagery, so removing the outlying error is of great
practical importance. Because of slow changing background and sparse errors, we can model the
problem using the robust PCA approach. We use the (ﬂip-SPCPmax) version due to its speed, and
pick parameters (λmax, τmax) by using a Nelder-Mead simplex search. For an error metric to use
in the parameter tuning, we remove frame 1 from the data set (call it y1) and set A to be frames
2–15. From this training data A, the algorithm generates L and S. Since L is a 3002 × 14 matrix,
it has far from full column span. Thus our error is the distance of y1 from the span of L, i.e.,
(cid:107)y1 − Projspan(L)(y1)(cid:107)2.
Our method takes about 11 iterations and 5 seconds, and uses a dense SVD instead of the
randomized method due to the extremely high aspect ratio of the matrix: the matrix is 15 × 3002,
and the cost of a dense SVD is linear in the large dimension, so the computational burden is not

28

05010015020025010−310−210−1100time (s)Error  this paper* (flip−SPCP−max, QN)this paper (flip−SPCP−sum)this paper* (SPCP−max, QN)this paper (SPCP−sum)NSA* (SPCP−sum)PSPG* (SPCP−sum)ASALM* (SPCP−sum)123456789101112131415DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Figure 8: Showing frames 4, 5 and 12. Leftmost column is original data, middle column is low-rank
term of the solution, and right column is sparse term of the solution. Data have been
processed slightly to enhance contrast for viewing.

large. Some results of the obtained (L, S) outputs are in Fig. 8, where one can see that some of the
anomalies in the original data frames A are picked up by the S term and removed from the L term.
Frame 4 has what appears to be a camera pixel error; frame 6 has another artiﬁcial error (that is,
caused by the camera and not the scene); and frame 12 has cloud cover.

5.2.4 ANALYSIS OF BRAIN ACTIVITY IN THE ZEBRA FISH

Recent work by Ahrens et al. (2013) has produced video recordings of brain activity, in vivo, of
zebra ﬁsh. These datasets are used to conﬁrm scientiﬁc theories about the inner-working of the brain
as well as to discover unexpected connections. Ultimately the goal is to discover causal, not just
correlated, relationships. PCA on these datasets is one of the standard tools used by biologists in
order to uncover correlations.

Using a public video of the dataset, we focus on a single 2D slice, sub-sampled spatially (and
perhaps with video compression artifacts). We use (SPCPmax) as the RPCA technique, and therefore
need to estimate  and λmax. To ﬁnd , we ﬁrst take the SVD of the data matrix A. The corresponding
singular vales σ(A) are plotted in Fig. 9. This gives us an idea of the compressibility of the
data. Keeping about 30 singular values explains over 99% of the data, so if we look for L with
approximately rank 30, then, not including the sparse term S (which we expect to be very sparse),
i (A). This value works well in practice (see Fig. 10) and did not

we should pick  (cid:39)(cid:113)(cid:80)752

require cross-validation.

i=31 σ2

The λmax parameter is tuned by hand, but only takes 3 runs to ﬁnd a reasonable value. This is
much simpler than tuning λmax and  by hand simultaneously. Figure 10 shows the resulting top left
singular vectors of A and of L, as well as their difference. We see that their difference is sparse, as

29

Y4L4S4Y6L6S6Y12L12S12A. ARAVKIN AND S. BECKER

Figure 9: Decay of singular values of A for the zebra ﬁsh dataset. Singular values 51–742 are not

shown.

expected. Since these are singular vectors, not just individual frames from the movie, these sparse
differences are persistent over time, and perhaps meaningful. These unpredictable locations could be
caused by sensor/microscope error, or they could mean that they come from a part of the brain that is
not well correlated with general brain activity. Either way, it is useful to be able to separate out this
effect.

(a) Top left singular vector
of A

(b) Top left singular vector
of L.

(c) Difference of (a) and
(b).

Figure 10: Top left singular vector of A and of L, as well as their difference.

30

01020304050742752102103104105106singular valuesindex of singular value (1 to 752)DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

6. Conclusion

We have discussed both speciﬁc algorithms for the RPCA problem, and general algorithm frameworks
(“TFOCS”, and “ﬂipped” variational value-function approaches) that incorporate RPCA and variants.
The custom RPCA algorithm works extremely well in practice, and the process of “ﬂipping” the
objective has been studied rigorously, but the inner “quasi-Newton” algorithm lacks a rigorous
convergence theory. The general algorithm TFOCS, as well as similar proposals such as the PDHG
algorithm, have more established theory but lack practical guidance on setting parameters, and are
in practice slower than the special purpose algorithms. An obvious goal of future work is to either
improve the analysis of these algorithms (for example, this may give insight into parameter selection),
or derive new algorithms that inherent all the advantages.

The running theme of this work has been the beneﬁts of solving variants of RPCA, in particular
(ﬂip-SPCPsum) and the new variants (SPCPmax) and (ﬂip-SPCPmax). These versions sometimes allow
a good estimate of τ (or ε for (SPCPmax)), thus reducing the parameter selection of the model to the
single scalar λsum or λmax. Our theory allows for different regularizers and data ﬁdelity terms; using
these in practice is interesting future work.

References
M. B. Ahrens, M. B. Orger, D. N. Robson, J. M. Li, and P. J. Keller. Whole-brain functional imaging

at cellular resolution using light-sheet microscopy. Nature Methods, 10(413–420), 2013.

A. Aravkin, S. Becker, V. Cevher, and P. Olsen. A variational approach to stable principal component

pursuit. In Uncertainty in Artiﬁcial Intelligence, Quebec City, 2014a.

A. Y. Aravkin, J. V. Burke, and M. P. Friedlander. Variational properties of value functions. SIAM J.

Opt., 23(3):1689–1717, 2013.

A.Y. Aravkin, R. Kumar, H. Mansour, B. Recht, and F.J. Herrmann. Fast methods for denoising
matrix completion formulations, with applications to robust seismic data interpolation. SIAM
Journal on Scientiﬁc Computing, 36(5):S237–S266, 2014b.

A.Y. Aravkin, R. Kumar, H. Mansour, B. Recht, and F.J. Herrmann. Fast methods for denoising
matrix completion formulations, with applications to robust seismic data interpolation. SIAM
Journal on Scientiﬁc Computing, 36(5):S237–S266, 2014c.

A.Y. Aravkin, J.V. Burke, D. Drusvyatskiy, M.P. Friedlander, and S. Roy. Level-set methods for

convex optimization. arXiv preprint arXiv:1602.01506, 2016.

N. Aybat, D. Goldfarb, and S. Ma. Efﬁcient algorithms for robust and stable principal component

pursuit. Computational Optimization and Applications, accepted, 2013.

N. S. Aybat and G. Iyengar. A fast ﬁrst-order method for stable principal component pursuit.

http://arxiv.org/abs/1309.6553, 2013.

H.H. Bauschke and P. Combettes. Convex analysis and monotone operators theory in Hilbert spaces.

Springer-Verlag, 2011.

31

A. ARAVKIN AND S. BECKER

A. Beck and M. Teboulle. A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse

Problems. SIAM J. Imaging Sciences, 2(1):183–202, January 2009a.

A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM J. Imaging Sci., 2(1):183–202, 2009b. ISSN 1936-4954. doi: 10.1137/080716542.
URL http://dx.doi.org/10.1137/080716542.

A. Beck and M. Teboulle. A fast dual proximal gradient algorithm for convex minimization and
applications. Operations Research Letters, 42(1):1–6, 2014. ISSN 0167-6377. doi: http://dx.
doi.org/10.1016/j.orl.2013.10.007. URL http://www.sciencedirect.com/science/
article/pii/S0167637713001454.

S. Becker. Practical Compressed Sensing: modern data acquisition and signal processing. PhD

thesis, California Institute of Technology, Pasadena, CA, 2011.

S. Becker and E. Cand`es. Singlar value thresholding toolbox, 2008. Available from http://svt.

stanford.edu/.

S. Becker and P. L. Combettes. An algorithm for splitting parallel sums of linearly composed
monotone operators, with applications to signal recovery. J. Nonlinear and Convex Analysis, 15
(1):137–159, 2014.

S. Becker, E. J. Cand`es, and M. Grant. Templates for convex cone problems with applications to

sparse signal recovery. Math. Prog. Comp., 3(3):165–218, 2011.

D. P. Bertsekas. Necessary and sufﬁcient conditions for a penalty method to be exact. Math. Program.,

9:87–99, 1975.

D. P. Bertsekas, A. Nedi´c, and A. E. Ozdaglar. Convex Analysis and Optimization. Athena Scientiﬁc,

2003.

R. I. Bot¸ and E. R. Csetnek. Forward-backward and Tsengs type penalty schemes for mono-
tone inclusion problems. Set-Valued and Variational Analysis, 22(2):313–331, 2014.
ISSN
1877-0533. doi: 10.1007/s11228-014-0274-7. URL http://dx.doi.org/10.1007/
s11228-014-0274-7.

R. I. Bot¸, E. R. Csetnek, and A. Heinrich. A primal-dual splitting algorithm for ﬁnding zeros of sums
of maximal monotone operators. SIAM Journal on Optimization, 23(4):2011–2036, 2013a. doi:
10.1137/12088255X. URL http://dx.doi.org/10.1137/12088255X.

R. I. Bot¸, E. R. Csetnek, and E. Nagy. Solving systems of monotone inclusions via primal-dual

splitting techniques. Taiwanese Journal of Mathematics, 17(6):pp–1983, 2013b.

R. I. Bot¸, E. R. Csetnek, A. Heinrich, and C. Hendrich. On the convergence rate improvement
of a primal-dual splitting algorithm for solving monotone inclusion problems. Mathematical
Programming, 150(2):251–279, 2015. ISSN 0025-5610. doi: 10.1007/s10107-014-0766-0. URL
http://dx.doi.org/10.1007/s10107-014-0766-0.

32

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

T. Bouwmans and E. H. Zahzah. Robust PCA via principal component pursuit: A review for a
comparative evaluation in video surveillance. Computer Vision and Image Understanding, 122(0):
22–34, 2014. ISSN 1077-3142. doi: http://dx.doi.org/10.1016/j.cviu.2013.11.009. URL http:
//www.sciencedirect.com/science/article/pii/S1077314213002294.

L. M. Briceo-Arias and P. L. Combettes. A monotone+skew splitting model for composite monotone

inclusions in duality. SIAM J. Optim., 21(4):1230–1250, 2011.

P. Brucker. An O(n) algorithm for quadratic knapsack problems. Operations Res. Lett., 3(3):163 –

166, 1984. doi: 10.1016/0167-6377(84)90010-5.

J. J. Bruer, J. A. Tropp, V. Cevher, and S. Becker. Time–data tradeoffs by aggressive smoothing. In

Advances in Neural Information Processing Systems, pages 1664–1672, 2014.

J. Burke and M. Qian. A variable metric proximal point algorithm for monotone operators. SIAM J.

Control Opt., 37(2):353–375, 1997.

J-F. Cai, E. J. Cand`es, and Z. Shen. A singular value thresholding algorithm for matrix completion.

SIAM J. Optim., 20:1956–1982, 2010.

E. J. Cand´es and Y. Plan. Matrix completion with noise. Proceedings of the IEEE, 98(6):925–936,

2010.

E. J. Cand`es, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? J. Assoc. Comput.

Mach., 58(3):1–37, May 2011a.

E.J. Cand`es, X. Li, Y. Ma, and J. Wright. Robust principal component analysis? J. ACM, 58
(3):11:1–11:37, June 2011b. ISSN 0004-5411. doi: 10.1145/1970392.1970395. URL http:
//doi.acm.org/10.1145/1970392.1970395.

V. Cevher, S. Becker, and M. Schmidt. Convex optimization for big data: Scalable, randomized, and

parallel algorithms for big data analytics. IEEE Sig. Proc. Mag., 31(5):32–43, 2014.

A. Chambolle and C. Dossal. On the convergence of the iterates of “FISTA”. Technical Report

hal-01060130, HAL, 2014. https://hal.inria.fr/hal-01060130v3.

A. Chambolle and T. Pock. A ﬁrst-order primal-dual algorithm for convex problems with applications

to imaging. J. Math. Imaging Vision, 40(1):120–145, 2010.

V. Chandrasekaran, S. Sanghavi, P. A. Parrilo, and A. S. Willsky. Sparse and low-rank matrix

decompositions. In SYSID 2009, Saint-Malo, France, July 2009.

V. Chandrasekaran, P. A. Parrilo, and A. S. Willsky. Latent variable graphical model selection via

convex optimization. Ann. Stat., 40(4):1935–2357, 2012.

C. Chen, B. He, Y. Ye, and X. Yuan. The direct extension of admm for multi-block convex

minimization problems is not necessarily convergent. Optimization Online, 2013.

P. G. Ciarlet. Introduction to numerical linear algebra and optimisation. Cambridge University

Press, 1989.

33

A. ARAVKIN AND S. BECKER

P. L. Combettes. Systems of structured monotone inclusions: duality, algorithms, and applications.

SIAM J. Optimization, 23(4):2420–2447, 2013.

P. L. Combettes and J.-C. Pesquet. A DouglasRachford Splitting Approach to Nonsmooth Convex
Variational Signal Recovery. IEEE J. Sel. Topics Sig. Processing, 1(4):564–574, December 2007.

P. L. Combettes and J.-C. Pesquet. Proximal splitting methods in signal processing. In H. H. Bauschke,
R. S. Burachik, P. L. Combettes, V. Elser, D. R. Luke, and H. Wolkowicz, editors, Fixed-Point
Algorithms for Inverse Problems in Science and Engineering, pages 185–212. Springer-Verlag,
New York, 2011.

P. L. Combettes and J.-C. Pesquet. Primal-dual splitting algorithm for solving inclusions with
mixtures of composite, Lipschitzian, and parallel-sum type monotone operators. Set-Valued and
Variational Analysis, 20(2):307–330, 2012.

P. L. Combettes and V. R. Wajs. Signal recovery by proximal forward-backward splitting. Multiscale
Model. Simul., 4(4):1168–1200 (electronic), 2005. ISSN 1540-3459. doi: 10.1137/050626090.
URL http://dx.doi.org/10.1137/050626090.

P. L. Combettes, D. D˜ung, and B. C. V˜u. Dualization of signal recovery problems. Set-Valued and

Variational Analysis, 18:373–404, 2010. ISSN 1877-0533.

L. Condat. A primal-dual splitting method for convex optimization involving Lipschitzian, prox-

imable and linear composite terms. J. Optim. Theory Appl., pages 460–479, 2013.

O. Devolder, F. Glineur, and Y. Nesterov. First-order methods of smooth convex optimization with

inexact oracle. Math. Prog. submitted, 2011.

O. Devolder, F. Glineur, and Y. Nesterov. Double smoothing technique for large-scale linearly
constrained convex optimization. SIAM Journal on Optimization, 22(2):702–727, 2012. doi:
10.1137/110826102. URL http://dx.doi.org/10.1137/110826102.

J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chandra. Efﬁcient projections onto the l1-ball for
learning in high dimensions. In Intl. Conf. Machine Learning (ICML), pages 272–279, New York,
July 2008. ACM Press.

E. Esser, X. Zhang, and T. Chan. A general framework for a class of ﬁrst order primal-dual algorithms

for tv minimization. Technical Report 09-67, UCLA, Center for Applied Math, 2009.

M. P. Friedlander and P. Tseng. Exact regularization of convex programs. SIAM J. Optim., 18(4):
1326–1350, 2007. doi: 10.1137/060675320. URL http://link.aip.org/link/?SJE/
18/1326/1.

A. Ganesh, Z. Lin, J. Wright, L. Wu, M. Chen, and Y. Ma. Fast algorithms for recovering a corrupted
low-rank matrix. In Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP),
pages 213–215, Aruba, Dec. 2009.

D. Goldfarb, S. Ma, and K. Scheinberg. Fast alternating linearization methods for minimizing the

sum of two convex functions. Math. Prog. (Series A), 141(1–2):349–382, 2013.

34

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

T. Goldstein, E. Esser, and R. Baraniuk. Adaptive primal-dual hybrid gradient methods for saddle-

point problems. Technical report, 2013. http://arxiv.org/abs/1305.0546.

N. Halko, P.-G. Martinsson, and J. A. Tropp. Finding structure with randomness: Probabilistic
algorithms for constructing approximate matrix decompositions. SIAM review, 53(2):217–288,
2011.

B.S. He and X. M. Yuan. Convergence analysis of primal-dual algorithms for a saddle-point problem:

from contraction perspective. SIAM J. Imaging Sci., pages 119–149, 2012a.

B.S. He and X.M. Yuan. On the o(1/n) convergence rate of the Douglas-Rachford alternating direction

method. SIAM J. Numer. Anal., 50(700–709), 2012b.

P. J. Huber. Robust Statistics. John Wiley and Sons, 2 edition, 2004.

N. Komodakis and J.-C. Pesquet. Playing with duality: An overview of recent primal-dual approaches
for solving large-scale optimization problems. IEEE Sig. Pro. Magazine, to appear, May 2015.
http://arxiv.org/abs/1406.5429v2.

M. Lai and W. Yin. Augmented l1 and nuclear-norm models with a globally linearly convergent

algorithm. SIAM J. Imaging Sci., 6(2):1059–1091, 2013.

J. Lee, B. Recht, R. Salakhutdinov, N. Srebro, and J.A. Tropp. Practical large-scale optimization for

max-norm regularization. In Neural Information Processing Systems (NIPS), Vancouver, 2010.

X. X. Li, L. L. Mo, X. M. Yuan, and J. Z. Zhang. Linearized alternating direction method of
multipliers for sparse group and fused LASSO models. Comput. Statis. Data Anal., 79:203–221,
2014.

Z. Lin, M. Chen, and Y. Ma. The augmented Lagrange multiplier method for exact recovery of

corrupted low-rank matrices. arXiv preprint arXiv:1009.5055, 2010.

Y.-J. Liu, D. Sun, and K.-C. Toh. An implementable proximal point algorithmic framework for

nuclear norm minimization. Mathematical Programming, 2011.

F. Bach M. Schmidt, N. Le Roux. Convergence rates of inexact proximal-gradient methods for

convex optimization. In NIPS, 2011.

F. Malgouyres and T. Zeng. A predual proximal point algorithm solving a non negative basis pursuit

denoising model. Int. J. Comp. Vision, 83(3):294–311, July 2009.

O. L. Mangasarian and R. R. Meyer. Nonlinear perturbation of linear programs. SIAM J. Control

Optim., 17:745–752, 1979.

J.-J. Moreau. Proximit´e et dualit´e dans un espace hilbertien. Bull. Soc. Math. France, 93:273–299,

1965.

I. Necoara and J. A. K. Suykens. Application of a smoothing technique to decomposition in convex

optimization. IEEE Trans. Auto. Control, 53(11):2674–2679, 2008.

35

A. ARAVKIN AND S. BECKER

Y. Nesterov. A method of solving a convex programming problem with convergence rate O(1/k2),

in soviet mathematics doklady. Soviet Mathematics Doklady, 27, 1983.

Y. Nesterov. Introductory lectures on convex optimization: a basic course, volume 87 of Applied

Optimization. Kluwer Academic Publishers, 2004.

Y. Nesterov. Smooth minimization of non-smooth functions. Math. Program., Ser. A, 103:127–152,

2005.

J. Nocedal and S. Wright. Numerical Optimization. Springer, 2 edition, 2006.

Y. Peng, A. Ganesh, J. Wright, W. Xu, and Y. Ma. RASL: Robust alignment by sparse and low-
rank decomposition for linearly correlated images. IEEE Trans. Pattern Analysis and Machine
Intelligence, 34(11):2233–2246, 2012. ISSN 0162-8828. doi: http://doi.ieeecomputersociety.org/
10.1109/TPAMI.2011.282.

T. Pock and A. Chambolle. Diagonal preconditioning for ﬁrst order primal-dual algorithms in
convex optimization. In Computer Vision (ICCV), 2011 IEEE International Conference on, pages
1762–1769, Nov 2011. doi: 10.1109/ICCV.2011.6126441.

B. T. Poljak and N. V. Tretjakov. An iterative method for linear programming and its economic

interpretation. Matecon, 10:81–100, 1974.

X. Ren and Z. Lin. Linearized alternating direction method with adaptive penalty and warm starts

for fast solving transform invariant low-rank textures. Int. J. Comput. Vis., 104:1–14, 2013.

R. T. Rockafellar. Convex analysis. Princeton Mathematical Series, No. 28. Princeton University

Press, Princeton, N.J., 1970a.

R. T. Rockafellar. Monotone operators and the proximal point algorithm. SIAM Journal on Control

and Optimization, 14:877–898, 1976.

R. Tyrrell Rockafellar. Convex Analysis. Priceton Landmarks in Mathematics. Princeton University

Press, 1970b.

R. Tyrrell Rockafellar and Roger J-B. Wets. Variational Analysis, volume 317 of A Series of

Comprehensive Studies in Mathematics. Springer, 1998.

M. Schmidt, E. van den Berg, M. Friedlander, and K. Murphy. Optimizing costly functions with

simple constraints: A limited-memory projected quasi-Newton algorithm. In AISTATS, 2009.

Y. Shen, Z. Wen, and Y. Zhang. Augmented Lagrangian alternating direction method for matrix
separation based on low-rank factorization. Optimization Methods and Software, 29(2):239–263,
March 2014.

Z. Shi, J. Han, T. Zheng, and J. Li. Guarantees of augmented trace norm models in tensor recovery.

In Int. Joint Conf. Artiﬁcial Intell., pages 1670–1676, 2013.

M. Tao and X. Yuan. Recovering low-rank and sparse components of matrices from incomplete and

noisy observations. SIAM J. Optimization, 21:57–81, 2011.

36

DUAL SMOOTHING AND LEVEL SET TECHNIQUES FOR VARIATIONAL MATRIX DECOMPOSITION

Q. Tran-Dinh and V. Cevher.

Constrained convex minimization via model-based ex-
In Z. Ghahramani, M. Welling, C. Cortes, N.D. Lawrence, and K.Q.
cessive gap.
Information Processing Systems 27, pages
Weinberger, editors, Advances in Neural
721–729. Curran Associates, Inc., 2014. URL http://papers.nips.cc/paper/
5494-constrained-convex-minimization-via-model-based-excessive-gap.
pdf.

E. van den Berg and M. P. Friedlander. Probing the Pareto frontier for basis pursuit solutions. SIAM

J. Sci. Comput., 31(2):890–912, 2008.

E. Van den berg and M. P. Friedlander. Probing the Pareto frontier for basis pursuit solutions. SIAM J.
Sci. Computing, 31(2):890–912, 2008. software: http://www.cs.ubc.ca/˜mpf/spgl1/.
E. van den Berg and M. P. Friedlander. Sparse optimization with least-squares constraints. SIAM J.

Optimization, 21(4):1201–1229, 2011.

S. Villa, S. Salzo, L. Baldassare, and A. Verri. Accelerated and inexact forward-backward algorithms.

SIAM J. Optimization, 23(3):1607–1633, 2013. doi: 10.1137/110844805.

B. C. V˜u. A splitting algorithm for dual monotone inclusions involving cocoercive operators. Adv.

Comput. Math, 38(3):667–681, 2013.

X. Wang and X. M. Yuan. The linearized alternating direction method of multipliers for Dantzig

selector. SIAM J. Sci. Comput., 34:2782–2811, 2012.

J. Wright, A. Ganesh, S. Rao, and Y. Ma. Robust principal component analysis: Exact recovery of
corrupted low-rank matrices by convex optimization. In Neural Information Processing Systems
(NIPS), 2009a.

S. J. Wright, R. D. Nowak, and M. A. T. Figueiredo. Sparse reconstruction by separable approxima-

tion. IEEE Trans. Sig. Processing, 57(7):2479–2493, July 2009b.

J. Yang and Y. Zhang. Alternating direction algorithms for l1-problems in compressive sensing.

SIAM J. Sci. Comput., 33(1–2):250–278, 2011.

J. F. Yang and X. M. Yuan. Linearized augmented Lagrangian and alternating direction methods for

nuclear norm minimization. Math. Comput., 82:301–329, 2013.

W. Yin. Analysis and generalizations of the linearized Bregman method. SIAM J. Imaging Sci., 3(4):
856–877, 2010. doi: 10.1137/090760350. URL http://link.aip.org/link/?SII/3/
856/1.

Q. You, Q. Wan, and Y. Liu. A short note on strongly convex programming for exact matrix
completion and robust principal component analysis. Inverse Problems and Imaging, 7(1):305–
306, 2013.

J. Zhang, J.-F. Cai, L. Cheng, and J. Zhu. Strongly convex programming for exact matrix completion

and robust principal component analysis. Inverse Problems and Imaging, 6(2):357–372, 2012.

X. Q. Zhang, M. Burger, and S. Osher. A uniﬁed primal-dual algorithm framework based on Bregman

iteration. J. Sci. Comput., 46:20–46, 2010.

37

A. ARAVKIN AND S. BECKER

Z. Zhang, X. Liang, A. Ganesh, and Y. Ma. TILT: Transform invariant low-rank textures.

In
R. Kimmel, R. Klette, and A. Sugimoto, editors, Computer Vision – ACCV 2010, volume 6494 of
Lecture Notes in Computer Science, pages 314–328. Springer, 2011.

X.-Y. Zhao, D. Sun, and K.-C. Toh. A Newton-CG augmented Lagrangian method for semideﬁnite
programming. SIAM Journal on Optimization, 20(4):1737–1765, 2010. doi: 10.1137/080718206.
URL http://dx.doi.org/10.1137/080718206.

38

