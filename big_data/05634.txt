6
1
0
2

 
r
a

 

M
7
1

 
 
]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[
 
 

1
v
4
3
6
5
0

.

3
0
6
1
:
v
i
X
r
a

A uniﬁed framework for the direct evaluation of
large deviations in both Markovian and
non-Markovian processes

Massimo Cavallaro1 and Rosemary J. Harris2

E-mail: 1m.cavallaro@qmul.ac.uk, 2rosemary.harris@qmul.ac.uk

School of Mathematical Sciences, Queen Mary University of London, Mile End
Road, London, E14NS, UK

Abstract. We propose a general framework to simulate stochastic trajectories
with arbitrarily long memory dependence and eﬃciently evaluate large deviation
functions associated to time-extensive observables. This extends the “cloning”
procedure of Giardin´a et al. [Phys. Rev. Lett. 96 120603 (2006)] to non-Markovian
systems. We demonstrate the validity of this method by testing non-Markovian
variants of an ion-channel model and the Totally Asymmetric Exclusion Process,
recovering results obtainable by other means.

1. Introduction

The theory of large deviations has been widely applied to equilibrium statistical
mechanics [1]. Far from equilibrium, we can still deploy the same formalism, but
targeting trajectories in space-time rather than static conﬁgurations [2].
Instead
of asking for the probability of observing a conﬁguration with a given energy, we
require the probability of a trajectory of duration t with a value J of a time-extensive
observable. For this purpose, the details of the time evolution take on a major role.

When the stochastic dynamics of a model system are Markovian, i.e., memoryless,
we can specify the rules for its evolution in time by means of the constant rates
βxj ,xi of transitions from conﬁguration xi to conﬁguration xj. The full set of rates
encodes inter-event times with exponential waiting-time distributions (WTDs), which
indeed possess the memoryless property. However, to model real-world systems, such
a simpliﬁed description may not be appropriate. In fact, non-exponential WTDs seem
to be relevant in many contexts, see, e.g., [3–7].

Large deviation functionals have been computed in selected non-Markovian
systems (e.g., assuming the so-called temporal additivity principle [8], or by deﬁning
hidden-variables [9]) and have revealed structure hidden in the stationary state.
Analytical progress is diﬃcult and simulations are necessary to explore systematically
more realistic models with memory. However, to our knowledge, numerical schemes
able to eﬃciently probe large deviation functionals have been discussed in general only
for memoryless systems [10–14]. In this letter, we ﬁll this literature gap, and provide
a general numerical method to generate trajectories corresponding to arbitrarily rare
values of J, based on the “cloning” procedure of [10]. The text is organised as follows.
In section 2, we set up the general formalism, while in section 3 we present the

Uniﬁed framework for the direct evaluation of large deviations

2

simulation scheme for non-Markovian systems and the numerical method to evaluate
large deviation functionals. Section 4 deals with the special case of the semi-Markov
process, where the formalism has a particularly lucid interpretation in terms of the
generalised Master equation.
In section 5 we test the method in some examples of
increasing complexity, where the large deviation functions can be computed exactly.
We conclude with a discussion in section 6.

2. Thermodynamics of trajectories

A trajectory or history of a stochastic process, on a conﬁguration space S, is deﬁned
as the sequence

w(t) := (t0, x0, t1, x1, t2, x2 . . . tn, xn, t),

(1)
where xi ∈ S, t0 and x0 are the initial time and conﬁguration, t0 ≤ t1 ≤ . . . ≤ t, and
ti (for i = 1, . . . , n) denotes the instant where the system jumps from conﬁguration
xi−1 to xi. Speciﬁcally, we are interested in the probability density dP [w(t)] that a
trajectory w(t) is observed. Hereafter, we will consider a discrete conﬁguration space
S, although most of the arguments presented remain valid in the continuous case. In
general, we can separate dP [w(t)] into a product over the contributions of each jump,
multiplied by the probability Px0(t0) that the conﬁguration at t0 is x0, i.e.,
dP [w(t)] = φxn[t − tn; w(tn)]ψxn,xn−1[tn − tn−1; w(tn−1)] . . .

n(cid:89)

i=1

Px(t) =

dt1

dt2 . . .

dtn

δx,xn dP [w(t)].

(3)

× ψx1,x0 [t1 − t0; w(t0)]Px0(t0)

dti,

(2)

is

the generic

factor ψxn,xn−1 [tn − tn−1; w(tn−1)]

where
the waiting time
probability density (WTD) that a transition from xn−1 to xn occurs during the
ψxn,xn−1 [tn −
tn−1; w(tn−1)]dtn = 1.
t ψxn,xn−1[tn −
tn−1; w(tn−1)]dtn is the survival probability of the conﬁguration xn for the interval
[tn, t). The special case without dependence on the history before the last jump will
be considered in section 4. The probability that the system has conﬁguration x ∈ S
at t > t0 is

inﬁnitesimal interval [tn, tn + dt); it obeys the normalization(cid:80)
Also, φxn [t − tn; w(tn)] = (cid:80)
(cid:90) t
(cid:88)

(cid:82) ∞
(cid:82) ∞

∞(cid:88)

(cid:90) t

(cid:90) t

tn−1

xn

xn

t0

t1

n=0

tn−1

x0,x1,...,xn

J[w(t)] of the trajectory w(t), that can be written as the sum (cid:80)n−1

We characterise a non-equilibrium system by means of time-extensive functionals
i=0 θxi+1,xi of
elementary contributions corresponding to conﬁguration changes. Alternatively it
is possible to consider “static” contributions θxi−1(ti − ti−1). Functionals of these
types may represent physical observables integrated over the observation time t, e.g.,
the dynamical activity in a glassy system [15], the moles of metabolites produced
in a biochemical pathway [16, 17], the customers served in a queuing network [18],
the ﬂow in interacting particle systems (IPSs) [19], or certain quantities in stochastic
thermodynamics [20, 21]. Hereafter, we will refer to J[w(t)] as the time-integrated
current and to its empirical average J[w(t)]/t = j(t) simply as current. The latter
observable still ﬂuctuates in time, although it is doomed to converge to its ensemble
average (cid:104)j(cid:105) in the limit t → ∞. The consequent computational diﬃculty in obtaining

where s is an intensive conjugate ﬁeld. Assuming a large deviation principle, i.e.,

ln Z(s, t),

1
t

e(s) = − lim
t→∞
P(j, t) ∼ e−tˆe(j),

the rate function ˆe(j) can be obtained by a Legendre-Fenchel transform,

when the SCGF is diﬀerentiable [22]. Equation (4) can be written as

ˆe(j) = sup

s {e(s) − sj},

(cid:90) t

∞(cid:88)

(cid:90) t

(cid:90) t

(cid:88)

Z(s, t) =

dt1

dt2 . . .

dtn

n=0

t0

t1

tn−1

x0,x1,...,xn

φxn [t − tn; w(tn)] ˜ψxn,xn−1[tn − tn−1; w(tn−1)] . . .
× ˜ψx1,x0[t1 − t0; w(t0)]Px0(t0)

dti,

n(cid:89)

i=1

where

(4)

(5)

(6)

(7)

(8)

(9)

Uniﬁed framework for the direct evaluation of large deviations

3

the probability P(j, t) of having a given value of j(t), can be alleviated by introducing
the “canonical” density e−sJ[w(t)]dP [w(t)], the “partition function”

(cid:90)

Z(s, t) =

e−sJ[w(t)]dP [w(t)],

and the scaled cumulant generating function (SCGF)

w(t)

˜ψxn,xn−1[tn − tn−1; w(tn−1)] = esθxn ,xn−1 ψxn,xn−1[tn − tn−1; w(tn−1)]

can be seen as the “biased” WTD of a stochastic dynamics that does not conserve total
probability. This immediately suggests that we can access the SCGF by computing
the exponential rate of divergence of an ensemble of trajectories.

3. A numerical approach

3.1. Non-Markovian stochastic simulation
The WTD can be expressed in terms of a time-dependent rate or hazard βxn,xn−1 [tn−
tn−1; w(tn−1)], which is the probability density that there is a jump from xn−1 to xn
in [tn, tn + dt), conditioned on having no transitions during the interval [tn−1, tn),

ψxn,xn−1 [tn − tn−1; w(tn−1)]
= βxn,xn−1[tn − tn−1; w(tn−1)] × φxn−1[tn − tn−1; w(tn−1)].
For brevity we deﬁne τ = tn − tn−1, which is the value of the age, i.e.
the time
elapsed since the last jump, at which the next jump takes place (see ﬁgure 1).
Roughly speaking, the hazard βxn,xn−1[τ ; w(tn−1)] is the likelihood of having an
almost immediate transition from a state xn−1 known to be of age τ , to a state
xn, and, crucially, can also depend on the history w(tn−1). From equation (10),
βxn,xn−1[τ ; w(tn−1)] and

summing over xn ∈ S, and deﬁning βxn−1 [τ ; w(tn−1)] =(cid:80)
ψxn−1[τ ; w(tn−1)] =(cid:80)

ψxn,xn−1[τ ; w(tn−1)], we get

(10)

xn

xn

ψxn−1[τ ; w(tn−1)] = −

d
dτ

φxn−1[τ ; w(tn−1)]

= βxn−1[τ ; w(tn−1)] × φxn−1[τ ; w(tn−1)].

(11)

Uniﬁed framework for the direct evaluation of large deviations

4

.

Figure 1. Representation of a portion of trajectory. The time elapsed from the
last jump is called age. The conditional probability of having a conﬁguration xn
at an instant tn > tn−1 depends on the age, as well as on events which happened
during the history (e.g., the one marked by the red star).

The age-dependent sum βxn−1[τ ; w(tn−1)] is also referred to as the escape rate from
xn−1, and using equation (11), can be written as a logarithmic derivative

Integrating equation (12) with initial condition φxn−1(0) = 1 gives:

φxn−1[τ ; w(tn−1)] = exp

βxn−1[t; w(tn−1)]dt

,

−

0

ψxn−1 [τ ; w(tn−1)] = βxn−1 [t; w(tn−1)] exp

βxn−1 [t; w(tn−1)]dt

d
dτ

βxn−1 [τ ; w(tn−1)] = −
(cid:18)
(cid:90) τ

ln φxn−1 [τ ; w(tn−1)].

(cid:19)

(cid:18)

(cid:90) τ

−

0

(12)

(13)

. (14)

(cid:19)

These let us cast equation (10) in the more convenient form

ψxn,xn−1 [τ ; w(tn−1)] = pxn,xn−1 [τ ; w(tn−1)] × ψxn−1[τ ; w(tn−1)], (15)

(cid:80)

where

pxn,xn−1 [τ ; w(tn−1)] =

βxn,xn−1[τ ; w(tn−1)]

βxn,xn−1 [τ ; w(tn−1)]

xn−1

,

(16)

xn

(cid:80)

pxn,xn−1 [τ ; w(tn−1)] = 1 and (cid:82) ∞

is the probability that the system jumps into the state xn, given that it escapes the
state xn−1 at age τ .
It is important to notice that the normalization conditions
0 ψxn−1[τ ; w(tn−1)]dτ = 1 are satisﬁed. Hence,
we can sample a random waiting time τ , according to the density ψxn−1[τ ; w(tn−1)]
and, after that, a random arrival conﬁguration xn, according to the probability
mass pxn,xn−1 [τ ; w(tn−1)]. This suggests a standard Monte Carlo algorithm for the
generation of a trajectory (1):

1) Initialise the system to a conﬁguration x0 and a time t0. Set a counter to n = 1.
2) Draw a value τ according to the density (11) and update the time to tn = tn−1 +τ .
3) Update the system conﬁguration to xn, with mass (16).
4) Update n to n + 1 and repeat from 2) until tn reaches the desired simulation time.

Uniﬁed framework for the direct evaluation of large deviations

5

3.2. The cloning step

We now need to take into account the eﬀect of the factor esθxn,xn−1 on the dynamics,
which is to increment (if θxn,xn−1 > 0) or decrement (if θxn,xn−1 < 0) the “weight” of
a trajectory, within an ensemble. This can be implemented by means of the so called
“cloning” method, which consists of assigning to each trajectory of the ensemble a
population of identical clones consistent with its weight. As reviewed, e.g., in [23, 24],
the idea is not new.
It seems to be born in the context of quantum physics and
credited to Enrico Fermi [25]. Since then, it has been extensively applied within
equilibrium statistical physics [26–28], and, recently, also adopted for the evaluation of
large deviation functionals of non-equilibrium Markov processes (in discrete time [10]
and continuous time [11]). Here, we reﬁne and extend this idea for the case of non-
Markovian processes. One of the devices used in [10,11] is to deﬁne modiﬁed transition
probabilities—valid only under the Markovian assumption—and a modiﬁed cloning
factor, encoding the contraction or expansion of the trajectory weight. However, we
argue that the redeﬁnition of such quantities is unnecessary (and may be inconvenient,
see section 4). A more natural choice for the computation of the SCGF, suggested by
equations (8) and (9), consists of the following procedure:

1) Set up an ensemble of N clones and initialise each with a given time t0, a random
conﬁguration x0, and a counter n = 0. Set a variable C to zero. For each clone,
draw a time t of the next jump from the density ψx0[t− t0; w(t0)], and then chose
the clone with the smallest value of t.
2) For the chosen clone, update n to n + 1, and xn−1 to xn according to the mass

3) Generate a new waiting time

pxn,xn−1[t − tn−1; w(tn−1)].
for
ψxn−1[τ ; w(tn−1)] and increment t to t + τ .

τ

the updated clone according to

4) Cloning step. Compute y = (cid:98)esθxn ,xn−1 + u(cid:99), where u is draw from a uniform
1) If y = 0, prune the current clone. Then replace it with another one, uniformly

distribution on [0, 1).

2) If y > 0, produce y copies of the current clones. Then, prune a number y of

chosen among the remaining N − 1.
elements, uniformly chosen among the existing N + y.

5) Increment C to C + ln[(N + esθxn,xn−1 − 1)/N ]. Chose the clone with the smallest
t, and repeat from 2) until the chosen t reaches the desired simulation time T .

The SCGF is ﬁnally recovered as C/T for large T . The net eﬀect of step 4) is to
maintain a constant population of samples whose mean current does not decay to (cid:104)j(cid:105).

4. Semi-Markov systems

A common framework for modelling systems with ﬁnite-range memory is the formalism
of semi-Markov processes, also referred to as continuous-time random walks (CTRWs)
in the physics literature. CTRWs were introduced to model transport on lattices [29,
30] and later used in many other contexts, e.g., to describe quantum dots [31], temporal
networks [32], animal movements [33, 34], biochemical reactions [35], and single-
molecule kinetics [36]. In such systems, the probability of having a jump depends only
on the departure state and on the age, meaning that the memory is lost after each

n(cid:89)

i=0

Uniﬁed framework for the direct evaluation of large deviations

6

jump and the dependence on the previous history is removed. Under this assumption,
the probability density of observing a trajectory (1) is

dP [w(t)] = φxn(t−tn)ψxn,xn−1 (tn−tn−1) . . . ψ(cid:48)

x1,x0

(t1−t0)Px0(t0)

dti, (17)

where the primed WTD can diﬀer from the others‡. The special case where the waiting
times depend on the departure state and not on the destination, i.e., ψxi,xi−1(τ ) =
pxi,xi−1ψxi−1(τ ), is said to satisfy direction-time independence (DTI).

The probability Pxi(t) for the system to be in the conﬁguration xi at time t, in a
semi-Markov process, follows a convenient diﬀerential equation, see [37] and references
therein, which is referred to as the generalised Master equation (GME):

(cid:2)Kxi,xj (t − τ )Pxj (τ ) − Kxj ,xi(t − τ )Pxi(τ )(cid:3) dτ, (18)

dPxi (t)

dt

= Ixi(t) +

(cid:88)

(cid:90) t

xj(cid:54)=xi

t0

where Kxi,xj (t − τ ) is the memory kernel, taking into account the conﬁguration at
time t − τ , and Ixi(t) depends the primed WTDs [37]. The memory kernel is deﬁned
through an equation similar to (10), but in the Laplace domain,

with f (ν) =(cid:82) ∞

0 e−νtf (t)dt.

ψxi,xj (ν) = K xi,xj (ν)φxi(ν),

(19)

The statistics of time-extensive variables in semi-Markov processes have been
studied in [31,38,39] and compared to memoryless processes. In systems described by
a standard Master equation, one strategy is to analyse a process that obeys a modiﬁed
rate equation, obtained replacing the time-independent rates βxi,xj , with the products
esθxi,xj βxi,xj , which are referred to “biased” rates. This is particularly simple when
θxi,xj can only take values −1, 0, 1, i.e., at each step, the total current varies, at most,
by one unit. In semi-Markov systems it is possible to investigate the statistics of J in
a similar, but more general, way. Instead of the standard Master equation, we deploy
the GME (18). The probability P(xi,J)(t) of having a conﬁguration xi with total
current J at time t, under the constraint that the current can only grow or decrease
by one unit at each jump, obeys the following GME:

P(xi,J)(t) = I(xi,J)(t) +

K(xi,J)←(xj ,J)(t − τ )P(xj ,J)(τ )dτ

(cid:90) t

(cid:88)

xj(cid:54)=xi

t0

K(xi,J)←(xj ,J+1)(t − τ )P(xj ,J+1)(τ )dτ +

K(xi,J)←(xj ,J−1)(t − τ )P(xj ,J−1)(τ )dτ

K(xj ,J)←(xi,J)(t − τ )P(xi,J)(τ )dτ −

K(xj ,J+1)←(xi,J)(t − τ )P(xi,J)(τ )dτ

d
dt

+

−

−

(cid:90) t
(cid:88)
(cid:90) t
(cid:88)
(cid:90) t
(cid:88)

xj(cid:54)=xi

xj

t0

t0

xj

t0

(cid:90) t
(cid:88)
(cid:90) t
(cid:88)

xj

t0

xj

t0

K(xj ,J−1)←(xi,J)(t − τ )P(xi,J)(τ )dτ

(20)

We now make the assumption that the memory kernels are independent of the total-
integrated current J (only depending on the current increment), i.e.,

K(xi,J)←(xj ,J−c)(t) = Kxi,xj ,c(t),

(21)
‡ A natural situation is when we observe a portion of a trajectory that started before t0. In this
(t1 − t0) = ψx1,x0 (t1 − t−1)/φx0 (t0 − t−1), as it depends on the time t−1 of the last
case, ψ(cid:48)
jump before t0, being conditioned on the survival until t0. Also, in this case, the probability that xi
survives the interval t − t0 is φ(cid:48)

(t − t0) = φxi (t0 − t−1)/φxi (t − t−1).

x1,x0

xi

Uniﬁed framework for the direct evaluation of large deviations

7

(cid:88)
where c = −1, 0, 1. The system is diagonalised with respect to the current subspace
by means of the discrete Laplace transform
e−sJ P(xi,J)(t)
(cid:90) t
(cid:88)

and is then equivalent to

˜Pxi(s, t) =

(22)

J

˜Pxi(s, t) = ˜Ixi(s, t) +

Kxi,xj ,0(t − τ ) ˜Pxj (s, τ )dτ

xj(cid:54)=xi

t0

(cid:90) t

(cid:88)

xj

t0

e−sKxi,xj ,+1(t − τ ) ˜Pxj (s, τ )dτ

d
dt

+

−

(cid:90) t
(cid:88)
(cid:88)
(cid:90) t

c,xj(cid:54)=xi

xj

t0

(cid:90) t
esKxi,xj ,−1(t − τ ) ˜Pxj (s, τ )dτ +
Kxj ,xi,c(t − τ ) ˜Pxi(s, τ )dτ
(cid:90) t

t0

(23)

(24)

Kxi,xi,−1(t − τ ) ˜Pxi(s, τ )dτ −

−
which can be represented in a more compact form as

Kxi,xi,+1(t − τ ) ˜Pxi (s, τ )dτ,

t0

t0

∂t| ˜P (t)(cid:105) = ˆL(t)| ˜P (t)(cid:105),

product (cid:104)1| ˜P (t)(cid:105), except for s = 0 when (cid:80)

where ˆL(t) is a linear s-dependent integral operator and | ˜P (t)(cid:105) has components
˜Pxi(s, t). The limit as t → ∞ of ln(cid:104)1| ˜P (t)(cid:105)/t (where (cid:104)1| is a row vector with all
entries equal to one) is the SCGF of J. Clearly, equation (24) does not conserve the
Pxi (t) = 1. The dynamics described
by equation (23) is equivalent to the dynamics described by the GME (20), with the
memory kernels, corresponding to jumps that contribute a unit c in the total current,
multiplied by a factor e−cs. From linearity, it follows that the Laplace transformed
kernels are

xi

e−csK xi,xj ,c(ν) = e−csψxi,xj ,c(ν)

φxi(ν) ,

(25)

(cid:46)

where βxi =(cid:80)

This conﬁrms that the modiﬁed dynamics can be simulated biasing the WTDs
ψxi,xj ,c(t), i.e., multiplying them by e−cs.

The Markovian case is recovered for Kxi,xj (t) = βxi,xj δ(t). Using this kernel,
equations (23) and (24) can be written in terms of the s-modiﬁed stochastic generator
˜G of the Markov process with time independent rates βxi,xj and components

{ ˜G}xi,xj = βxi,xj ,0 + e−sβxi,xj ,+1 + esβxi,xj ,−1,
{ ˜G}xi,xi = e−sβxi,xi,+1 + esβxi,xi,−1 − βxi,xi,−1 − βxi,xi,+1 −

(26)

(27)

βxj ,xi,0,

(cid:88)

xj

c,xj(cid:54)=xi

βxj ,xi,c is the rate of escape from xi§. We have just shown that
biasing the rates is consistent with biasing the WTDs. However, from a numerical
point of view, the latter choice remains convenient even for the Markovian case, as it
avoid us having to deﬁne the modiﬁed transition probabilities of [11]. To see this, we
consider the biased Markovian WTD

˜ψxi,xj ,c(τ ) = e−csβxi,xj ,c exp(cid:0)

−βxj τ(cid:1) ,

(28)
§ Note that the equation (27), and also the earlier (23), takes into account events that do not alter
the conﬁguration, but modify the current statistics.

Uniﬁed framework for the direct evaluation of large deviations

which is the product of an exponential probability density ψxj (τ ) = βxj exp(cid:0)
choice is to deﬁne ˜βxi,xj ,c = e−csβxi,xj ,c, set ˜βxj =(cid:80)

a time-independent probability mass pxi,xj ,c = βxi,xj ,c/βxj , and a simple cloning
factor e−cs. These specify the two steps of the standard Doob-Gillespie algorithm for
Markov processes [40], followed by a cloning step of weight e−cs. Another legitimate

−βxj τ(cid:1),

˜βxi,xj ,c, and write

8

˜ψxi,xj ,c(τ ) = exp

τ

.

(29)

(cid:104)

(cid:16) ˜βxj − βxj

xi,c

(cid:17)(cid:105) ˜βxi,xj ,c exp
(cid:16) ˜βxj − βxj
(cid:104)

(cid:17)

(cid:16)
− ˜βxj τ
(cid:17)(cid:105)

With such an arrangement, we recognise the algorithm of [11], i.e., at each step, the
conﬁguration evolves according to a stochastic generator with rates ˜βxi,xj ,c, and the
ensemble is modiﬁed with the cloning factor exp
. As the cloning factor
here is exponential in time, during long intervals the relative number of new clones can
be large. This causes major ﬁnite-ensemble errors, which are shown to be important,
e.g., in [9, 41]. Conversely, our implementation seems less prone to such a problem.

τ

5. Examples

We now test our procedure against three non-Markovian models, whose exact large
deviations are known from the literature or can be deduced from Markovian models.

5.1. Semi-Markov models for ion-channel gating with and without DTI

The current through an ion channel in a cellular membrane can be modelled with
only two states, corresponding to the gate being singly occupied (x1) or empty (x0);
an ion can enter or leave this channel via the left (L) or right (R) boundary and
non-exponential waiting times lead to a complex behaviour [42]. Speciﬁcally, we
denote the WTD for a particle entering (or leaving) through the boundary L by
ψx1,x0,1(τ ) (or ψx0,x1,−1(τ )) with respective density ψx1,x0,0(τ ) (or ψx0,x1,0(τ )) for
the boundary R. The rightwards current is measured by a counter that increases
(decreases) by one when a particle enters (leaves) the system through the boundary L.
Its exact SCGF is obtained numerically in [38] as the leading pole of the time-
Laplace transform of Z(s, t),
for the DTI-case ψxi,xj ,c(τ ) = pxi,xj ,cψxj (τ ) with
c=0,1 px1,x0,c = 1, and the particular choice ψxj (τ ) = g(τ ; kj, λj),

(cid:80)
c=−1,0 px0,x1,c =(cid:80)

where

g(τ ; k, λ) = λkτ k−1 exp(−λτ )/Γ(k),

(30)

and Γ(k) is the Gamma function. Notably, the implementation of the cloning method
of section 3 can be implemented for any WTD, as only a bias of es, for ions leaving the
channel leftwards, and a bias of e−s, for ions entering from left, are needed. Figure 1(a)
shows that this methods reproduces, within numerical accuracy, the solution of [38].
In a quest for more general classes of models to illustrate the power of our
approach, we now relax the constraint of DTI and assume that each transition can
be triggered independently by two mechanisms, corresponding to the two boundaries.
We still assume that memory of the previous history is lost as soon as the system
changes state, thus preserving the semi-Markov nature. At the instant when the box
is emptied, a particle attempts to enter the system from the left boundary after a
waiting time T L
0 (τ ), while another particle attempts
to arrive from the right boundary after a time T R
0 (τ ).
The waiting times T L
1 (τ ) are deﬁned

0 with density distribution ψL

0 distributed according to ψR

0 , as well as the densities ψL

1 (τ ) and ψL

1 and T L

Uniﬁed framework for the direct evaluation of large deviations

9

similarly. In order to have a right (left) jump during the interval [τ, τ + dτ ), we also
require that the left (right) mechanism remains silent until time τ . Consequently, the
WTDs are

ψx1,x0,0(τ ) = ψR
ψx0,x1,0(τ ) = ψR

1 (τ )ϕL
0 (τ )ϕL

0 (τ ),
1 (τ ),

ψx1,x0,−1(τ ) = ψL
ψx0,x1,1(τ ) = ψL

1 (τ )ϕR
0 (τ )ϕR

0 (τ ),
1 (τ ),

(31)

(32)

j (τ ) = (cid:82) ∞

where ϕ(ρ)
j (t)dt are survival probabilities, with ρ denoting the
mechanism L or R. As a concrete choice, we again assign a Gamma probability
distribution to the waiting time of each event,

τ ψ(ρ)

ψ(ρ)

j (τ ) = g(τ ; k(ρ)
so that the survival probabilities are
, λ(ρ)

ϕ(ρ)
j (τ ) = Γ(k(ρ)

j

j

, λ(ρ)

j ),

j τ )/Γ(k(ρ)

j

),

(33)

(34)

where Γ(k, x) is the upper incomplete Gamma function. The time to the next jump,
given that that system just reached state xj (i.e., its age is zero) is min{T L
j } and
is associated to the total survival probability,

j , T R

φxj (τ ) = ϕL

j (τ )ϕR

j (τ ).

(35)

Once the transition time is known, either the left or right trigger is chosen, according
to the age-dependent rates

β(ρ)
j

(τ ) = g(τ ; k(ρ)

j

, λ(ρ)

j )Γ(k(ρ)

j

)/γ(k(ρ)

j

, λ(ρ)

j τ ),

(36)

where γ(k, x) is the lower incomplete Gamma function. The SCGF of the left current
is computed by biasing the WTDs ψx1,x0,1(τ ) and ψx0,x1,−1(τ ) with e∓s, respectively.
While the implementation of the method of section 3.2 remains straightforward
for this model, a general solution for the exact SCGF is missing. We thus specialise
to the case with kR
1 = 2, for which the Laplace transform of

0 = kR

1 = kL

ψxi,xj (t) =(cid:80)

c ψxi,xj ,c(t) is a rational function of ν, viz.,

0 = kL

(cid:1)(cid:18) λj

ν + λj

(cid:19)2

+(cid:0)αR

j + λR

j and

(cid:1)(cid:18) λj

(cid:19)3

ν + λj

j,3 + αL
j,3

,

(37)

ψxi,xj (ν) =(cid:0)αR

j,2 + αL
j,R

where we deﬁned for convenience λj = λL
j )2λR
j
(λj)3

(λL
j )2
(λj)2 , αL

j,2 =

j,3 =

2(λL

αL

, αR

j,2 =

(λR
j )2
(λj)2 , αR

j,3 =

2(λR

j )2λL
j
(λj)3

. (38)

This can be though of as resulting from a walker spending exponentially distributed
times in three hidden stages, as in [43]. Hence, the two-state semi-Markov process
with WTD (31) and (32) can be seen as a six-state Markov process, see [37] for more
details and an alternative formulation. The linearity of the Laplace transform permits
the distinction of the left and right contributions in (37), hence it remains easy to bias
the rates that correspond to a change in J and the SCGF can be exactly found as
the leading eigenvalue of a modiﬁed Markovian stochastic generator [37]. Figure 2(b)
shows convincing agreement of our method with this exact approach.

Uniﬁed framework for the direct evaluation of large deviations

10

Figure 2. SCGF of current in ion channel. (a) DTI model with (k0, λ0, k1, λ1) =
(0.1, 0.01, 1, 1) and (px1,x0,1, px1,x0,0, px0,x1,−1, px0,x1,0) = (0.5, 0.6, 0.4, 0.5); the
cloning result is consistent with the solution of [38]. (b) non-DTI model with
Markov representation and inverse scales (λL
1 ) = (20, 10, 10, 20/3);
The cloning reproduces the leading eigenvalue of the Markovian s-modiﬁed
generator. In both cases N = 1000 and t = 1000.

0 , λL

0 , λR

1 , λR

5.2. Totally Asymmetric Exclusion Process (TASEP) with history dependence

More general non-Markovian systems are those whose WTDs depend on events which
occurred during the whole observation time. Systems in this class are the “elephant”
random walk [44] and its analogues, where the transition probabilities at time t depend
on the history through the time-averaged current j(t). We focus here on an IPS with
such current-dependent rates, namely the TASEP of [45].

Non-Markovian IPSs can be described by assigning a trigger with WTD
ψi[τ ; w(t)] and a corresponding survival function ϕi[τ ; w(t)] to each elementary event
i that controls the particle dynamics. The probability density that the next transition
is of type i and occurs in the time interval [t + τ, t + τ + dt), given that, for each j, a
time tj has elapsed since the last event of type j, is given by

N(cid:89)

j(cid:54)=i,j=1

ψi[τ ; w(t)|t0, t1, t2, . . . , tN ] = ψi[ti + τ ; w(t)|ti]

ϕj[τ + tj; w(t)|tj],

(39)

where ψi[ti + τ ; w(t)|ti] = ψi[ti + τ ; w(t)]/ϕi[ti; w(t)] and ϕi[ti + τ ; w(t)|ti] =
ϕi[ti +τ ; w(t)]/ϕi[ti; w(t)]. With exact expressions for these WTDs, we can implement
the algorithms of section 3.

The TASEP consists of a one-dimensional lattice of length L, where each lattice
site l, 1 ≤ l ≤ L, can be either empty (ηl = 0) or occupied by a particle (ηl = 1).
Particles on a site l < L are driven rightwards: they attempt to jump to site l + 1
with WTD ψn[τ ; w(t)], the attempt being successful if ηl+1 = 0, as in [46–48]. With
open boundaries, a particle that reaches the rightmost site L leaves the system with
WTD ψL[τ ; w(t)]. Also, as soon as η1 = 0, a further boundary mechanism turns on
and particles arrive on the leftmost site with WTD ψ0[τ ; w(t)]. The special choice
ψ0[τ ; w(t)] = αe−ατ , ψn[τ ; w(t)] = pe−pτ , and ψL[τ ; w(t)] = βe−βτ corresponds to
the standard Markovian TASEP with constant left, bulk and right rates α, p, and β.
We now assume that only the left boundary has a non-exponential WTD, while
the particle triggers have exponential WTDs with rate 1 for free particles in the bulk,
and rate β for the particle on the rightmost site. Consequently the inter-event time

−1.0−0.50.00.51.0s−0.10−0.08−0.06−0.04−0.020.000.02e(s)(a)SolutionofRef.[37]Cloning−3−2−10123s−14−12−10−8−6−4−202e(s)(b)HiddenMarkovCloningUniﬁed framework for the direct evaluation of large deviations

11

density distribution, conditioned on a time t0 having elapsed since the last arrival, is

(cid:19)

ψ[τ ; w(t)|t0] =

(1 − δη0) + N + βδηL

(cid:18) ψ0[τ + t0; w(t)]
(cid:26)

ϕ0[t0; w(t)]

(cid:20) ϕ0[τ + t0; w(t)]

(cid:21)

× exp

ln

ϕ0[t0; w(t)]

The probability mass distribution, conditioned on an age τ and elapsed time t0 is

(1 − δη0) − (N + βδηL )τ

.

(40)

(cid:27)

(cid:19)−1
(cid:19)−1

p0[τ ; w(t)|t0] =

×

pi[τ ; w(t)|t0] =

(1 − δη0)

ϕ0[t0; w(t)]

ψ0[τ + t0; w(t)]

(cid:18) ψ0[τ + t0; w(t)]
(cid:18) ψ0[τ + t0; w(t)]

ϕ0[t0; w(t)]

ϕ0[t0; w(t)]

(cid:18) ψ0[τ + t0; w(t)]

ϕ0[t0; w(t)]

(1 − δη0) + N + βδηL

(1 − δη0 ) + N + βδηL

pL[τ ; w(t)|t0] = βδηL

(1 − δη0) + N + βδηL

,

(41)

,

(cid:19)−1

(42)

,(43)

where the Kronecker deltas encode the exclusion rules of the TASEP, i = 1, 2, . . . , N ,
and N is the number of free particles in the bulk, which depends on the lattice
conﬁguration before the jump.

Following [45], let us impose now that the arrival rate α depends linearly on
the inwards current j(t), i.e., α(j) = α0 + aj, which deﬁnes a time-dependent rate
β0(t) := α[j(t)]. The rate function ˆe(j) for this case has already been computed by
means of the temporal additivity principle [8, 45], hence this model provides a testing
ground for the cloning method of Section 3. The particle arrival mechanism starts
when the leftmost site is emptied, when we set an age of τ = 0. Denoting by q the
current immediately after the last arrival, which occurred at t − t0, the value j(t + τ )
at age τ can be expressed as q(t − t0)/(t + τ )), hence the trigger hazard is

β0(t + τ ) = α0 + aq(t − t0)/(t + τ ),

(44)

where τ is the trigger age.
Initial values of t0 and j(t) are chosen to be 1 and 0,
respectively. This allows us to derive the trigger survival probability and resident
time distribution [37, 45] which are, respectively,

ϕ0[τ ; w(t)] =

e−α0τ ,

(45)

(cid:19)aq(t−t0)

(cid:18) t

t + τ

and ψ0[τ ; w(t)] = β0(t + τ )ϕ0[τ ; w(t)]. Using these in equations (40) and (43) allows
us to generate the trajectories, and the large deviation function can be evaluated by
applying a bias e−s to the arrival WTD and following the algorithm of section 3. The
results are plotted in ﬁgure 3 and validated by the exact numerical calculation of [45].

6. Discussion

We have demonstrated a version of the “cloning” algorithm for the evaluation of large
deviations that can be applied consistently for both Markovian and non-Markovian
dynamics. In fact, the cloning/pruning of trajectories at each temporal step can be
performed according to a very simple factor multiplying the WTDs, as in equation (9).
Our analysis encompasses classes of systems with diﬀerent memory dependence and
exploits the similarities between their diﬀerent formalisms. The eﬃcacy of this

Uniﬁed framework for the direct evaluation of large deviations

12

of e(s), while the red line is obtained as (cid:82) s

Figure 3.
(a) Cloning evaluation of the SCGF for the non-Markovian TASEP,
with (α0, a, β) = (0.2, 0.1, 1). The markers corresponds to the direct evaluation
0 (de(σ)/dσ) dσ, according to the
thermodynamic integration of [11]. (b) Comparison between the Legendre-Fenchel
transform of the red line in (a) and the rate function of [45]. The cloning method
suggests the existence of a dynamical phase transition at j∗.

approach is conﬁrmed by numerical results for some of the rare non-Markovian models
whose large deviation functions can be obtained exactly.

For general non-Markovian cases, the implementation of our procedure is not
much harder than the exact simulation of the original trajectories.
In Markov
processes, the procedure is shown to be equivalent to those of [10, 11], but arguable
easier to implement. In fact, a biased dynamics can be conveniently deﬁned without
involving alternative rates or transition probabilities, as typically done in the existing
literature. We expect that, to minimize ﬁnite-size eﬀects, an optimal choice of modiﬁed
WTDs and cloning factors exists for both non-Markovian and Markovian systems,
along the lines of the feedback control of [14]. Further developments can thus be
anticipated.

We also mention that the discrete-time case of [10] is interesting as the jumps and
the cloning steps occur simultaneously for each ensemble element. This feature can be
used to prevent a single clone replacing a macroscopic fraction of the ensemble, thus
reducing ﬁnite size eﬀects [37]. In continuous time an equivalent strategy is to mimic
the discrete-time steps, as in, e.g., [49], so each trajectory evolves independently for
a constant interval ∆t; in this case, the product of the cloning factors encountered
during the interval, as well as the time elapsed since the last jump must be stored.
This permits the application of the cloning step to all clones simultaneously.

Large deviation functionals are often hard to obtain analytically, and such a
diﬃculty is exacerbated in non-Markovian systems, which better describe real-world
situations; we believe that the results of this work open up a promising avenue for
numerical studies.

Acknowledgments

It is a pleasure to thank Ra´ul J. Mondrag´on, Stefan Grosskinsky, Oscar Bandtlow,
and Arturo Narros for many helpful discussions.

−4−3−2−10123s−1.2−1.0−0.8−0.6−0.4−0.20.00.2e(s)j∗(a)CloningCloning(therm.integr.)0.000.050.100.150.200.30j0.000.050.100.150.200.25ˆe(j)0.25j∗(b)Exactnumerics[44]sups{e(s)−sj}(cloning)Uniﬁed framework for the direct evaluation of large deviations

13

References

[1] R. S. Ellis. Entropy, Large Deviations, and Statistical Mechanics. Springer-Verlag Berlin

Heidelberg, 2006.

[2] M. Merolle, J. P. Garrahan, and D. Chandler.

Space-time thermodynamics of the glass

transition. Proc. Nat. Ac. Sci. USA, 102(31):10837–10840, 2005.

[3] D. Ben-Avraham and S. Havlin. Diﬀusion and reactions and disordered systems. Cambridge

University Press, 2000.

[4] J. Voit. The Statistical Mechanics of Financial Markets. Springer, 2005.
[5] J. D. Murray. Mathematical Biology: I. An Introduction. Springer, 2007.
[6] K.-I. Goh and A.-L. Barab´asi. Burstiness and memory in complex systems. EPL, 81(4):48002,

feb 2008.

[7] R. D. Smith. The dynamics of internet traﬃc: self-similarity, self-organization, and complex

phenomena. Adv. Complex Syst., 14(06):905–949, dec 2011.

[8] R. J. Harris and H. Touchette. Current ﬂuctuations in stochastic systems with long-range

memory. J. Phys. A: Math. Theor., 42(34):342001, aug 2009.

[9] M. Cavallaro, R. J. Mondrag´on, and R. J. Harris. Temporally correlated zero-range process

with open boundaries: Steady state and ﬂuctuations. Phys. Rev. E, 92(2):022137, 2015.

[10] C. Giardin`a, J. Kurchan, and L. Peliti. Direct Evaluation of Large-Deviation Functions. Phys.

Rev. Lett., 96(12):120603, mar 2006.

[11] V. Lecomte and J. Tailleur. A numerical approach to large deviations in continuous time. J.

Stat. Mech., 2007(03):P03004–P03004, mar 2007.

[12] M. Gorissen, J. Hooyberghs, and C. Vanderzande. Density-matrix renormalization-group study
of current and activity ﬂuctuations near nonequilibrium phase transitions. Phys. Rev. E,
79(2 Pt 1):020101, feb 2009.

[13] T. Nemoto and S. Sasa. Computation of Large Deviation Statistics via Iterative Measurement-

and-Feedback Procedure. Phys. Rev. Lett., 112(9):090602, 2014.

[14] T. Nemoto, F. Bouchet, R. L. Jack, and V. Lecomte. Population dynamics method with a

multi-canonical feedback control, 2016. arXiv:1601.06648.

[15] J. P. Garrahan, R. L. Jack, V. Lecomte, E. Pitard, K. van Duijvendijk, and F. van Wijland.
First-order dynamical phase transition in models of glasses: an approach based on ensembles
of histories. J. Phys. A: Math. Theor., 42(7):075007, feb 2009.

[16] M. Tomita and T. Nishioka. Metabolomics: The Frontier of Systems Biology. Springer Japan,

2006.

[17] S. J. Court, B. Waclaw, and R. J. Allen. Lower glycolysis carries a higher ﬂux than any

biochemically possible alternative. Nat. Commun., 6:8427, sep 2015.

[18] W. J. Stewart. Probability, Markov Chains, Queues, and Simulation: The Mathematical Basis

of Performance Modeling. Princeton University Press, 2009.

[19] B. Derrida. Non-equilibrium steady states: ﬂuctuations and large deviations of the density and

of the current. J. Stat. Mech., 2007(07):P07023–P07023, jul 2007.

[20] R. J. Harris and G. M. Sch¨utz. Fluctuation theorems for stochastic dynamics. J. Stat. Mech.,

2007(07):P07020–P07020, jul 2007.

[21] U. Seifert. Stochastic thermodynamics, ﬂuctuation theorems and molecular machines. Rep.

Progr. Phys., 75(12):126001, dec 2012.

[22] H. Touchette. The large deviation approach to statistical mechanics. Phys. Rep., 478(1-3):1–69,

2009.

[23] P. Grassberger. Go with the winners: a general Monte Carlo strategy. Comp. Phys. Comm.,

147(1-2):64–70, aug 2002.

[24] P. Grassberger and W. Nadler. ‘Go with the Winners’ Simulations. In Computational Statistical

Physics, pages 169–190. Springer Berlin Heidelberg, Berlin, Heidelberg, oct 2002.

[25] N. Metropolis and S. Ulam. The Monte Carlo method. J. Amer. Statist. Assoc., 44(247):335–41,

sep 1949.

[26] J. Tailleur and J. Kurchan. Probing rare physical trajectories with Lyapunov weighted dynamics.

Nature Phys., 3(3):203–207, feb 2007.

[27] E. J. Janse van Rensburg. Monte Carlo methods for the self-avoiding walk. J. Phys. A: Math.

Theor., 42(32):323001, aug 2009.

[28] H.-P. Hsu and P. Grassberger. A Review of Monte Carlo Simulations of Polymers with PERM.

J. Stat. Phys., 144(3):597–637, jul 2011.

[29] E. W. Montroll and G. H. Weiss. Random Walks on Lattices. II. J. Math. Phys., 6(2):167, feb

1965.

[30] J. W. Haus and K. W. Kehr. Diﬀusion in regular and disordered lattices. Phys. Rep., 150(5-

Uniﬁed framework for the direct evaluation of large deviations

14

6):263–406, 1987.

[31] M. Esposito and K. Lindenberg. Continuous-time random walk for open systems: Fluctuation

theorems and counting statistics. Phys. Rev. E, 77(5):051119, may 2008.

[32] T. Hoﬀmann, M. A. Porter, and R. Lambiotte. Generalized master equations for non-Poisson

dynamics on networks. Phys. Rev. E, 86(4):046102, oct 2012.

[33] L. Giuggioli, F. J. Sevilla, and V. M. Kenkre. A generalized master equation approach
J. Phys. A: Math. Theor.,

to modelling anomalous transport in animal movement.
42(43):434004, oct 2009.

[34] A. Al-Sabbagh. A non-linear subdiﬀusion model for a cell-cell adhesion in chemotaxis, 2015.

arXiv:1512.08438.

[35] O. Flomenbom and J. Klafter. Closed-Form Solutions for Continuous Time Random Walks on

Finite Chains. Phys. Rev. Lett., 95(9):098105, aug 2005.

[36] H. Wang and H. Qian. On detailed balance and reversibility of semi-Markov processes and

single-molecule enzyme kinetics. J. Math. Phys., 48(1):1–15, 2007.

[37] Supplemental material.
[38] D. Andrieux and P. Gaspard. The ﬂuctuation theorem for currents in semi-Markov processes.

J. Stat. Mech., 2008(11):P11007, nov 2008.

[39] C. Maes, K. Netoˇcn´y, and B. Wynants. Dynamical ﬂuctuations for semi-Markov processes. J.

Phys. A: Math. Theor., 42(36):365002, sep 2009.

[40] D. T. Gillespie. A general method for numerically simulating the stochastic time evolution of

coupled chemical reactions. J. Comp. Phys., 22(4):403–434, dec 1976.

[41] P. I. Hurtado and P. L. Garrido. Current ﬂuctuations and statistics during a large deviation

event in an exactly solvable transport model. J. Stat. Mech., 2009(02):P02032, 2009.

[42] E. Barkai, R. S. Eisenberg, and Z. Schuss. Bidirectional shot noise in a singly occupied channel.

Phys. Rev. E, 54(2):1161–1175, 1996.

[43] D. R. Cox. A use of complex probabilities in the theory of stochastic processes. Mathematical

Proceedings of the Cambridge Philosophical Society, 51(02):313, 1955.

[44] G. M. Sch¨utz and S. Trimper. Elephants can always remember: Exact long-range memory

eﬀects in a non-Markovian random walk. Phys. Rev. E, 70(4):045101, oct 2004.

[45] R. J. Harris. Fluctuations in interacting particle systems with memory.

J. Stat. Mech.,

2015(7):P07021, jul 2015.

[46] M. Gorissen and C. Vanderzande. Ribosome Dwell Times and the Protein Copy Number

Distribution. J. Stat. Phys., 148(4):627–635, 2012.

[47] R. J. Concannon and R. A. Blythe. Spatiotemporally Complete Condensation in a Non-

Poissonian Exclusion Process. Phys. Rev. Lett., 112(5):050603, feb 2014.

[48] D. Khoromskaia, R. J. Harris, and S. Grosskinsky. Dynamics of non-Markovian exclusion

processes. J. Stat. Mech., 2014(12):P12013, dec 2014.

[49] J. T. Berryman and T. Schilling. Sampling rare events in nonequilibrium and nonstationary

systems. J. Chem. Phys., 133(24):244101, dec 2010.

Uniﬁed framework for the direct evaluation of large deviations

1

Supplemental material for

“A uniﬁed framework for the direct evaluation of large

deviations in both Markovian and non-Markovian processes”

Massimo Cavallaro1 and Rosemary J. Harris2

E-mail: 1m.cavallaro@qmul.ac.uk, 2rosemary.harris@qmul.ac.uk

School of Mathematical Sciences, Queen Mary University of London, Mile End
Road, London, E1 4NS, UK

1. Generalised Master equation and its long-time behaviour

We ﬁrst derive the generalised Master equation of a CTRW along the lines of [S1–S3].
For a semi-Markov process (represented by equation (17) in the main text) the
probability of having a conﬁguration x at time t, analogue of the equation (3) in
the main text, can be explicitly written as the sum
Px(t) = δx,x0φ(cid:48)

(cid:88)

(cid:90) t

dt1

δx,x1φx1(t − t1)ψ(cid:48)

x1,x0

(t1 − t0)Px0 (t0)

x0

(t − t0)Px0(t0) +

t0

x0

(cid:90) t
(cid:90) t

t0

+

+

dt1

dt1

(cid:90) t
(cid:90) t

t1

(cid:88)
(cid:90) t

x0,x1

dt3

dt2

dt2

t0

t2

t0

x0,x1,x2

+ . . . ,

δx,x2φx2(t − t2)ψx2,x1(ti − t1)ψ(cid:48)
(cid:88)

x1,x0

(t1 − t0)Px0(t0)

δx,x3 φx3(t − t3)ψx3,x1 (t3 − t2)ψx2,x1(t2 − t1)ψ(cid:48)

x1,x0

(t1 − t0)Px0 (t0)
(S1)

(cid:82) t

where “moves” to the same conﬁguration as the departure one are excluded, i.e.,
x1 (cid:54)= x0, x2 (cid:54)= x1, . . .. Denoting by ηxi(t) the probability that the system jumps onto
the state xi at time t, which is the sum of all the arguments of the integral operator
dt1φx(t−t1)· in equation (S1), we can write the standard recursive relations [S2,S3]
(S2)

(cid:90) t

Pxi(t) = φ(cid:48)

t0

(t − t0)Pxi (t0) +

φxi (t − τ )ηxi(τ ) dτ,

t0

ηxi (t) =

ψxi,xj (t − τ )ηxj (τ ) dτ,
which can be expressed even more compactly after a Laplace transform, i.e.,

(t − t0)Pxj (t0) +

xj(cid:54)=xi

xj(cid:54)=xi

xi,xj

t0

xi

(cid:88)

ψ(cid:48)

P xi(ν) = φ(cid:48)
ηxi(ν) =

(cid:88)

xj(cid:54)=xi

ψ(cid:48)

where f (ν) =(cid:82) ∞

xi(ν)Pxi(t0) + φxi (ν)ηxi(ν),

xi,xj (ν)Pxj (t0) +

ψxi,xj (ν)ηxj (ν),

0 e−νtf (t)dt and ν is the variable conjugated to t. Using the following

explicit form for the Laplace transform of the survival probabilities [S4],

φxi(ν) =

1 − ψxi(ν)

,

φ(cid:48)

xi(ν) =

1 − ψ(cid:48)

ν

we get, from equation (S4),
νP xi(ν)−Pxi (t0) = −

ψ(cid:48)

xj ,xi (ν)Pxi(t0)+ηxi(ν)−

ν

(cid:88)

xj(cid:54)=xi

xi(ν)

(cid:88)

xj(cid:54)=xi

,

(S6)

ψxj ,xi (ν)ηxi(ν).(S7)

(cid:90) t

(cid:88)

(cid:88)

xj(cid:54)=xi

(S3)

(S4)

(S5)

(cid:88)
(cid:88)

xj(cid:54)=xi

xj(cid:54)=xi

I xi(ν) = −

−

(cid:88)

xj(cid:54)=xi

(cid:88)

xj(cid:54)=xi

(cid:88)
(cid:88)

xj(cid:54)=xi

(cid:88)

xj(cid:54)=xi

(cid:88)

xj(cid:54)=xi

Uniﬁed framework for the direct evaluation of large deviations

2

Then, using (S5) to substitute for the second term of the r.h.s., yields

νP xi(ν) − Pxi(t0) = −

ψ(cid:48)

xj ,xi(ν)Pxi(t0) +

ψ(cid:48)

xi,xj (ν)Pxj (t0)

+

xj(cid:54)=xi

ψxi,xj (ν)ηxj (ν) −

ψxj ,xi(ν)ηxi (ν).

(S8)

Plugging ηxi (ν) from equation (S4) into the third and fourth terms on the r.h.s. of
equation (S8), we get the equation

νP xi(ν)− Pxi(t0) = I xi(ν) +

ψxi,xj (ν)
φxj (ν)

P xj (ν)−

ψxj ,xi(ν)
φxi (ν)

P xi (ν), (S9)

(cid:88)

xj(cid:54)=xi

(cid:88)

xj(cid:54)=xi

where I xi(ν) contains the terms that explicitly depend on the initial conditions, i.e.,

ψ(cid:48)

xj ,xi(ν)Pxi(t0) +

ψ(cid:48)

xi,xj (ν)Pxj (t0)

ψxi,xj (ν)

φ(cid:48)
xj (ν)
φxj (ν)

Pxj (t0) +

ψxj ,xi(ν)

φ(cid:48)
xi(ν)
φxi (ν)

Pxi(t0). (S10)

(cid:90) ∞
(cid:90) ∞

0

ψxj ,xi (ν) =

=

After an inverse Laplace transform of equation (S9), using the formula for the Laplace
transform of a derivative on the l.h.s., we readily get the GME (18) of the main text.
In some situations, it is not necessary to deal with the initial-condition term. As
an obvious example, if the trajectory begins at the instant where a transition occurs
(as in the examples of section 5.1), then ψxi,xj (ν) = ψ(cid:48)
xi,xj (ν) and I xi(ν) = 0. The
same cancellation occurs when we observe a portion of a trajectory that started before
t0 with exponential WTDs (see footnote on page 6 of the main text). Focusing on the
long-lime behaviour, it is also possible to prove that, for many other natural choices
for the WTDs,

lim
t→∞ Ixi(t) = 0.

(S11)

To see this, we follow [S3, S5] and consider WTDs that have only ﬁnite moments, so
that the following McLaurin series expansion converges:

e−νtψxj ,xi (t) dt

(cid:90) ∞

(cid:90) ∞

0

ν2
2

tψxj ,xi(t)dt +

ψxj ,xi(t)dt − ν

0

0

= Pxj ,xi − νAxj ,xi + O(ν2),

t2ψxj ,xi(t)dt + . . .

(S12)

where the Pxj ,xi and Axj ,xi are, respectively, the zeroth and ﬁrst moments of ψxj ,xi(t),
in this case. Alternatively, we consider α-stable distributions, deﬁned by their Laplace
transform

ψxj ,xi(ν) = Pxj ,xi exp(−ναBxj ,xi /Pxj ,xi)
= Pxj ,xi − ναBxj ,xi + O(ν2α),

(S13)
where Pxj ,xi and Bxj ,xi are implicitly deﬁned after expanding exp(−ναBxj ,xi/Pxj ,xi)
Here 0 < α < 1, which corresponds to WTDs that, in the time domain, decay as
∼ t−α−1 and have inﬁnite mean waiting times. In both the cases (S12) and (S13), the
limits as ν → 0 of ψxi,xj (ν) and ψ(cid:48)
xi,xj (ν) can be represented by the algebraic forms

να, respectively. Using the standard relations (S6)

Uniﬁed framework for the direct evaluation of large deviations

and setting Bxj =(cid:80)
Pxi,xj −Bxi,xj να and P (cid:48)
(cid:20)
(cid:88)

xi

lim
ν→0

I xi(ν) = lim
ν→0

xi,xj

xi,xj −B(cid:48)
(cid:16)
Bxi,xj and B(cid:48)
xj ,xi − B(cid:48)
P (cid:48)

−

xj

(cid:0)Pxi,xj − Bxi,xj να(cid:1) B(cid:48)

xj
Bxj

−

xi

xj

xi,xj

B(cid:48)

=(cid:80)
να(cid:17)
Pxj (t0) +(cid:0)Pxj ,xi − Bxj ,xiνα(cid:1) B(cid:48)

, we get
xi,xj − B(cid:48)
P (cid:48)

Pxi(t0) +

(cid:16)

xj ,xi

xi
Bxi

να(cid:17)

xi,xj

Pxj (t0)

(cid:21)

Pxi(t0)

, (S14)

3

limt→∞ Ixi(t) =
which is constant in ν and implies, by the ﬁnal value theorem,
limν→0 νI xi(ν) = 0. This suggests that, often, we do not need know the exact
behaviour of Ixi(t) to investigate the long-time limit of the generalised Master
equation.

We now consider the s-dependent case, and study the asymptotic behavior of
In the joint conﬁguration-current space, the term

xi,xj ,0(ν)P(xj ,J)(t0) +

xi,xj ,c(ν)P(xj ,J−c)(t0)

encoding for the initial WTDs is

ψ(cid:48)

xj(cid:54)=xi

I (xi,J)(ν) =

˜Ixi(s, t) = (cid:80)
J e−sJ I(xi,J)(t).
(cid:88)
 (cid:88)
(cid:88)
 (cid:88)

φ(cid:48)
xi(ν)
φxi(ν)
φ(cid:48)
xj (ν)
φxj (ν)

xj ,xi,0(ν) +

ψxi,xj ,0(ν)

ψxj ,xi,0(ν)

(cid:88)

xj ,c=±1

xj(cid:54)=xi

xj(cid:54)=xi

ψ(cid:48)

−

−

+

+

xj(cid:54)=xi

 (cid:88)

xj(cid:54)=xi

ψ(cid:48)

xi,xj ,0(ν) +

(cid:88)

xj ,c=±1

ψ(cid:48)

xj ,c=±1

(cid:88)
 P(xi,J)(t0)
(cid:88)

xj ,c=±1

ψxi,xj ,c(ν)

φ(cid:48)
xj (ν)
φxj (ν)

e−csψ(cid:48)

xi,xj ,c(ν)

 ˜Pxi(s, t0)

ψ(cid:48)

xj ,xi,c(ν)

(cid:88)

xj ,c=±1

(cid:88)

xj ,c=±1

hence,

˜I xi(s, ν) =

xj(cid:54)=xi

 (cid:88)
 (cid:88)
 (cid:88)

xj(cid:54)=xi

xj(cid:54)=xi

−

+

−

ψ(cid:48)

xj ,xi,0(ν) +

ψ(cid:48)

xj ,xi,c(ν)

ψxj ,xi,0(ν)

ψxi,xj ,0(ν)

φ(cid:48)
xi(ν)
φxi (ν)
φ(cid:48)
xj (ν)
φxj (ν)

+

+

(cid:88)
(cid:88)

xj ,c=±1

xj ,c±1

e−csψxj ,xi,c(ν)

ψxi,xj ,c(ν)

φ(cid:48)
xj (ν)
φxj (ν)

P(xi,J)(t0) +

ψxj ,xi,c(ν)

P(xi,J−c)(t0)

φ(cid:48)
xi(ν)
φxi(ν)

 P(xj ,J)(t0),
 ˜Pxj (s, t0)
 ˜Pxi(s, t0)
 ˜Pxj (s, t0).

φ(cid:48)
xi(ν)
φxi(ν)

(S15)

(S16)

Using the WTDs (S12) or (S13) we again ﬁnd that the limit as ν → 0 is constant in
ν, hence also ˜Ixi(s, t) decays to zero in the long-time limit.
However, the initial-condition term may still substantially aﬀect the large
deviation functionals and their numerical evaluation, as such a decay may be slow
In general, ˜I xi(s, ν) does not vanish even when
for certain choices of WTDs.

Uniﬁed framework for the direct evaluation of large deviations
ψ(cid:48)

xi,xj ,c(ν) = ψxi,xj ,c(ν). In fact, in this case we have

˜I xi(s, ν) =

ψxj ,xi,+1(ν)Pxi(s, t0) + ψxi,xj ,+1(ν)Pxj (s, t0)

4

(cid:105)

(cid:105)(cid:111)

(cid:88)

xi

(cid:104)

(cid:110)
(e−s − 1)
(cid:104)

+ (es − 1)

ψxj ,xi,−1(ν)Pxi(s, t0) + ψxi,xj ,−1(ν)Pxj (s, t0)

,

(S17)

which is in general non-zero (except for s = 0, when I xi(ν) = 0 is recovered).
Consequently, the algorithm of section 3.2 of the main text must be iterated
for suﬃciently long time in order to neglect this ﬁnite-time contribution. We
ﬁnally mention that, for exponentially distributed waiting times, i.e., ψxi,xj ,c(ν) =
βxi,xj ,c/(βxj +ν) and ψ(cid:48)
+ν), the ﬁnite-time eﬀects are minor,
as shown by the following exact equation,

xi,xj ,c(ν) = β(cid:48)

xi,xj ,c/(β(cid:48)

xj

(cid:88)

˜βxj ,xi,0 − ˜β(cid:48)
xi + ν

˜I xi(s, ν) =

(cid:88)

+

xj(cid:54)=xi

˜β(cid:48)

˜β(cid:48)
xj(cid:54)=xi
xi,xj ,0 − ˜βxi,xj ,0

˜β(cid:48)

xj + ν

(cid:88)

˜βxj ,xi,c − ˜β(cid:48)
xi + ν

˜β(cid:48)
xj ,c=±1
˜β(cid:48)
xi,xj ,c − ˜βxi,xj ,c

˜β(cid:48)

xj + ν

(cid:88)

xj ,c=±1

xj ,xi,0

Pxi(s, t0) +

xj ,xi,c

Pxi(s, t0)

Pxj (s, t0) +

Pxj (s, t0),

(S18)

which implies an exponential decay of Ixi(s, t) to zero.

2. Discrete-time case

A discrete-time chain can be seen as a stochastic process in continuous time
where the next jump occurs after a constant waiting time of one unit. Such a
scenario can be represented by means of a process with WTDs ψxn,xn−1 [τ ; w(t)] =
pxn,xn−1 [w(t)]ψxn−1(τ ), where pxn,xn+1 [w(t)] is an entry of a transfer matrix and
In fact, the
ψxn−1(τ ) = δ(τ − 1) is the Dirac delta measure translated by 1.
procedure of section 3.2 can be implemented with reasonable accuracy by setting

−(τ − 1)2/σ2(cid:3), with σ (cid:28) 1. A discrete-time Markov chain

ψxn−1(τ ) = (σ√2π)−1 exp(cid:2)

can be seen as a special DTI semi-Markov process, since the transition probabilities
do not depend on w(t). However, such a continuous-time implementation neglects the
major computational advantage of dealing with discrete time, namely, all the ensemble
elements can be updated simultaneously. Therefore, we suggest the following parallel
algorithm:

1) Set up an ensemble of N clones and initialise each to its own random conﬁguration
x0. Also, initialise a unique counter to n = 1, the variable C to zero, and each
element of an array C of length N to 1.

pxn,xn−1[w(t)]. Store the individual values of esθxn,xn−1 in C.

2) For each clone, update the conﬁguration from xn−1 to xn according to the mass
3) Cloning step. Compute y = (cid:98)y(cid:48) + u(cid:99), where u is drawn from a uniform
distribution on [0, 1) and y(cid:48) is the sum of all the entries of C. Perform a weighted
random sampling with repetition (see, e.g., [S6]) of N clones from the ensemble,
according to their weights C. This sample replaces the existing ensemble.

4) Increment C to C + ln(y(cid:48)). Update n to n + 1 and reiterate from 2, until n reaches

the desired simulation time.

The SCGF is recovered as C/n for large n (results not shown). As the sampling at
step 3) is performed simultaneously for all the clones, it is very unlikely for a single

Uniﬁed framework for the direct evaluation of large deviations

5

clone to replace all the remaining ones, even in the presence of a strong bias. This
further reduces the ﬁnite ensemble eﬀects.

Finally, to make the link to the procedure proposed in [S7], it is worth noting

that, for the Markovian case, we can arrange the biased WTD as

(cid:80)
(cid:80)

xk,c(cid:48) ˜βxk,xj ,c(cid:48)
xk,c(cid:48) βxk,xj ,c(cid:48)

˜βxi,xj ,c
xk,c(cid:48) ˜βxk,xj ,c(cid:48)

(cid:80)

˜ψxi,xj ,c(t) =

δ(t − 1).

(S19)

This suggests the following steps for each ensemble element:
increase the time
by one unit, change the state according to the modiﬁed transition probability
xk,c(cid:48) ˜βxk,xj ,c(cid:48) and modify the ensemble population according to a cloning

˜βxi,xj ,c/(cid:80)
factor(cid:80)

xk,c(cid:48) ˜βxk,xj ,c(cid:48)/(cid:80)

xk,c(cid:48) βxk,xj ,c(cid:48), as indeed explained in [S7].

3. Model with hidden variables

In general, non-exponential waiting times arise when the system conﬁguration at
the present time does not uniquely determine the probabilities at future times.
In
this case, we can think that such a conﬁguration is only an incomplete description,
which needs further information about the history and the age (i.e., memory) in order
to assign the probability of future states. However, there are situations in which
such information can be simply encoded into additional states, thus extending the
conﬁguration space, but permitting a Markovian description. Such additional states
are referred to as phases (or stages) and said to be hidden. Generically, probability
distributions that deﬁne waiting times with such a property are referred to as phase-
type distributions [S8]. A typical example is the Gamma distribution with integer
shape k (also called Erlang distribution) which describes the random time that a
Markovian walker needs to escape k exponential phases in series. Rather than thinking
of a system that leaves its visible conﬁguration after a non-exponential waiting time,
we assume that the system jumps through a set of phases with exponential waiting
times, before arriving to the next visible conﬁguration.

It is proved in [S9] that any probability density distribution having a rational
Laplace transform f (ν), with k poles and numerator of degree at most k, can be
reproduced by a sequence of k exponential phases. Probability distributions with this
property are called Coxian, and are related to the phase-type distributions. Without
loss of generality, we can make the following partial fraction decomposition

f (ν) = p0 + q0p1

λ1

ν + λ1

+

q0 . . . qi−1pi

,

(S20)

k(cid:88)

i=2

i(cid:89)

λl

ν + λl

l=1

where the poles are at −λi, i = 1, 2, . . . , k, pi + qi = 1 and pk = 1. Equation (S20) has
a simple interpretation in the time domain. At each stage i − 1, there is a probability
pi−1 of immediate escape and a probability qi−1 of entering the stage i, whose WTD
is exponential with rate λi.

We turn now our attention to the model deﬁned by the WTDs (31) and (32) of

the main text. The Laplace transform of the total WTD ψxj ,xi(t), with i = 1, 2, is

ψxj ,xi(ν) =

(λL

i )2(ν + 3λR

i + λL
i )

(λR

i )2(ν + λR

i + 3λL
i )

(cid:0)ν + λR

i + λL
i

(cid:1)3 +

(cid:0)ν + λR

i + λL
i

(cid:1)3

,

(S21)

which is a rational function of ν; its ﬁrst term corresponds to the right boundary, while
the second one corresponds to the left boundary. Notice that there is not dependence

Uniﬁed framework for the direct evaluation of large deviations

6

on the arrival state xj, the model being deﬁned on a two-state conﬁguration space.
Equation (S21) can be conveniently written as
i )2
i + λL

ψxj ,xi(ν) = αi,2

i )3
i + λL

i + λL

i + λL

(ν + λR

(ν + λR

+ αi,3

(S22)

(λR

(λR

i )2

i )3

,

with

αi,2 =

(λR

(cid:0)λR

i )2 + (λL
i + λL
i
(λR

i )2

(cid:1)2 ,
(cid:1)2 =

αi,3 = 1 −

(cid:0)λR

2λR
i λL
i
i + λL
i

(cid:1)2 ,

(S23)

(S24)

which clearly deﬁnes a Coxian distribution. To separate the eﬀect of boundaries we
separately decompose in partial fractions the left and right WTD contributions of
equation (S21), i.e.,

i

i

i )2

2λR
i + λL
i
2λL
i + λL
i

i )2 + (λL
i + λL
i

(cid:0)λR
(cid:0)λL
(cid:1)2
(cid:0)ν + λR
(cid:0)λR
(cid:1)2
(cid:0)ν + λR
(cid:0)λR
(cid:0)ν + λR
(cid:0)λR
(cid:0)ν + λR
(cid:1)2 , αL
(cid:1)2 , αR

(cid:1)2
(cid:1)2

i,2

i
i + λL
i

i
i + λL
i

(cid:0)λL
(cid:1)2
(cid:1)3 +
(cid:0)ν + λR
(cid:1)2
(cid:1)2
(cid:0)λR
(cid:0)ν + λR
(cid:1)3 +
(cid:1)2 ,
(cid:0)λR
(cid:1)2
(cid:1)2 + αL
(cid:0)ν + λR
(cid:1)2
(cid:0)λR
(cid:0)ν + λR
(cid:1)2 + αR
(cid:1)2
2(cid:0)λL
(cid:0)λR
(cid:1)3 ,
2(cid:0)λR
(cid:1)2
(cid:1)3 .
(cid:0)λR

i + λL
i
λL
i

i + λL
i

λR
i

i,3

i,3

i

i

i,3 =

i,3 =

i + λL
i

i + λL
i

i + λL
i

i + λL
i

+ αR
i,2

i

(cid:0)λL
(cid:0)λR
(cid:0)λR
(cid:0)λR

i

i + λL
i

i + λL
i
i,2 + αR

(cid:1)3
(cid:1)3
(cid:1)3
(cid:1)3 ,

i + λL
i

i + λL
i

i + λL
i

i + λL
i

ψxj ,xi(ν) =

+

which can be rearranged as

ψxj ,xi(ν) = αL

where

αL

i,2 =

αR

i,2 =

(S25)

(S26)

(S27)

(S28)

i,2 + αL

i,3 + αR

Notice that αL
i,3 = 1. The ﬁrst and second terms correspond to left
jumps, while the third and fourth terms correspond to right jumps. We also underline
that the choice (S27) and (S28) is only one of the possible decompositions of the
WTD (S21). Equation (37) of the main text follows straightforwardly. A comparison
with (S20) shows that it corresponds to the case with three stages (i.e., k = 3),
p0 = p1 = 0, and p3 = αR
i,2. Hence, the jump from xi to xj can be modelled
as a process of three stages; in each of this the system is trapped for an exponentially
distributed time with rate λi. At time zero, with probability 1, the system enters
the ﬁrst stage and waits there. Then, again with probability 1, it enters a second
identical stage. After leaving the second stage, the escape occurs immediately with
probability p3, or the system enters the third and last phase with probability 1 − p3.
Hence the WTD is the time to absorption of the Markov process with the transition
graph of ﬁgure S1(a), given that we start at state 0. Recalling the notion of trigger, it
is possible to build an alternative but equivalent absorbing Markov process with the

i,2 + αL

Uniﬁed framework for the direct evaluation of large deviations

7

Figure S1. Two graphical representations of the WTD (S22). The waiting time
is equal to the adsorption time of a random walker from the leftmost site to any
of the grey sites.

Figure S2.
Graphical representations of the non-DTI ion-channel model
with hidden states. The bonds corresponding to biased rates are drawn in
thick lines. The modiﬁed generators associated with these two models have the
same leading eigenvalue. (a) and (b) correspond to the WTD representations of
ﬁgure S1.

same time to absorption. We think of each of the two Gamma triggers (R or L) as
a device with two exponential stages (with rate λR
i ). The escape occurs when
any of the two triggers leaves the last stage. The transition graph of the associated
Markov processes is shown in ﬁgure S1(b).

i or λL

With the phase-type

it

representations of ψx1,x0 (τ ) and ψx0,x1 (τ ),

is
straightforward to build a Markov transition graph of the full model.
In order to
study the non-equilibrium aspects, we need to distinguish the contributions of the two
boundaries L and R. Hence, in order to obtain the s-modiﬁed generator and ﬁnd
the SCGF of ﬁgure 2(b) of the main text, we only bias the true/visible transitions of
type L. The resulting Markov representations are then encoded in the multi-graphs
of ﬁgure S2.

(a)(b)////()))(()((a)(b)Uniﬁed framework for the direct evaluation of large deviations

8

References

[S1] J. W. Haus and K. W. Kehr. Diﬀusion in regular and disordered lattices. Phys. Rep., 150(5-

6):263–406, 1987.

[S2] E. W. Montroll and G. H. Weiss. Random Walks on Lattices. II. J. Math. Phys., 6(2):167, feb

1965.

[S3] M. Esposito and K. Lindenberg. Continuous-time random walk for open systems: Fluctuation

theorems and counting statistics. Phys. Rev. E, 77(5):051119, may 2008.

[S4] D. R. Cox. Renewal Theory. Methuen’s monographs on applied probability and statistics.

Methuen, 1962.

[S5] M. F. Shlesinger Asymptotic solutions of continuous-time random walks. J. Stat. Phys.,

10(5):421–434, May 1974.

[S6] P. S. Efraimidis and P. G. Spirakis. Weighted random sampling with a reservoir. Inf. Process.

Lett., 97(5):181–185, mar 2006.

[S7] C. Giardin`a, J. Kurchan, and L. Peliti. Direct Evaluation of Large-Deviation Functions. Phys.

Rev. Lett., 96(12):120603, mar 2006.

[S8] W. J. Stewart. Probability, Markov Chains, Queues, and Simulation: The Mathematical Basis

of Performance Modeling. Princeton University Press, 2009.

[S9] D. R. Cox. A use of complex probabilities in the theory of stochastic processes. Mathematical

Proceedings of the Cambridge Philosophical Society, 51(02):313, 1955.

