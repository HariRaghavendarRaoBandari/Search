MARGINAL STANDARDIZATION OF UPPER

SEMICONTINUOUS PROCESSES. WITH APPLICATION TO

MAX-STABLE PROCESSES

ANNE SABOURIN AND JOHAN SEGERS

Abstract. In the ﬁeld of spatial extremes, stochastic processes with upper
semicontinuous (usc) trajectories have been proposed as random shape functions
for max-stable models. In the literature dealing with usc processes, max-stability
is deﬁned via a sequences of scaling constants, rather than functions, only. It is
however not clear whether and how extreme-value theory (EVT) for continuous
processes extends to usc processes. In particular, classical multivariate and con-
tinuous EVT relies on the probability integral transform and Sklar’s theorem.
This theorem justiﬁes working with standard marginal distributions, simplifying
the task of constructing and characterizing max-stable processes and their do-
mains of attraction. In the present work, we investigate the possibility to follow
these steps for usc processes. Unfortunately, the pointwise probability integral
transform is not necessarily ‘permitted’: without additional assumptions, the ob-
tained process may not even have usc trajectories. We give suﬃcient conditions
for marginal standardization to be possible, and we state a partial extension of
Sklar’s theorem for usc processes, with a particular focus on max-stable ones.

Key words. extreme-value theory; max-stable processes; semicontinuous pro-

cesses; copulas.

6
1
0
2

 
r
a

 

M
4
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
4
9
1
4
0

.

3
0
6
1
:
v
i
X
r
a

1. Introduction

Max-stable processes and generalized Pareto processes appear respectively as
the weak limits of normalized pointwise maxima and high-threshold excesses, re-
spectively, of stochastic processes. This motivates their use in geostatistics to
model spatial processes at extreme levels. Stochastic process models with semi-
continuous trajectories arise naturally when extremes are localized in space. Think
of the behaviour of rain and wind at two sides of a mountain ridge. Another exam-
ple is a rainstorm model with storms being supported by random closed patches,
outside of which there is no rain. Various semicontinuous max-stable models have
been proposed in the literature (Schlather, 2002; Davison and Gholamrezaee, 2012;
Huser and Davison, 2014). Since our focus is on upper extremes, we will hence-
forth work with stochastic processes with upper semicontinuous (usc) trajectories.
Consider a stochastic process, ξ = (ξ(s))s∈D. We will refer to s as the ‘space
variable’. Throughout this paper, the index set D is a non-empty, compact subset
of some ﬁnite-dimensional Euclidean space with no isolated points. One way to

Date: March 15, 2016.

1

2

A. SABOURIN AND J. SEGERS

deal with upper semicontinuity is to consider ξ as a collection of random variables
of which the trajectories are usc almost surely. The drawback of such an approach
is that the ﬁnite-dimensional distributions do not give a handle on path-wise prop-
erties. Think for instance of the supremum of a trajectory over a subregion of D.
To handle such path functionals of ξ, it is convenient to consider it as a random
element in some function space. For functions which are not necessarily continuous,
Skorohod spaces may come to mind. These are less natural, however, when the
dimension of the domain D is higher than one and the meaning of ‘left’ and ‘right’
depends on the choice of the coordinate system. In this paper, we follow Norberg
(1987) and Resnick and Roy (1991) and work with the space USC(D) of upper
semicontinuous functions on D equipped with the hypo-topology. We will assume
that ξ is a usc process, i.e., a Borel measurable map from some probability space
into USC(D); see Section 2 for details.

A common approach in multivariate and spatial analysis is to split the analysis
and modelling of ξ into two parts: the marginal distributions and the ‘dependence
structure’. By the latter is meant the distribution of the random object ξ∗ that
arises from ξ by standardizing the random variables ξ(s) to a common univariate
distribution. In Sklar’s theorem, this is the uniform distribution on [0, 1], whereas
for max-stable processes, the unit-Fr´echet distribution is most common.

For usc processes, it is not at all clear from the outset whether this is possible
too. Does the pointwise probability integral transform turns a given usc process
into another one? If yes, is this transformation a measurable one on USC(D)?
And can the original usc process be reconstructed from the standardized version
and the marginal distributions?

We will provide answers to these questions for general usc processes and then
specialize these to max-stable ones. Some side conditions will enter, and we will
show that unexpected things go wrong if these are not met.

Compared to the set-up with processes with continuous trajectories, the situa-
tion is complicated by two issues. First, the pointwise transformations need not be
continuous with respect to s ∈ D, so that it is not clear that upper semicontinuity
of the trajectories is preserved. Second, the Borel σ-ﬁeld on USC(D) is larger
than the one generated by ﬁnite-dimensional cylinders. Not only does this pose
challenges to proving measurability of certain transformations, moreover, the law
of a usc process is not determined by its ﬁnite-dimensional distributions.

Max-inﬁnitely divisible usc processes have been considered in Gin´e et al. (1990),
and extremes of usc processes have been investigated, among others, by Norberg
(1987) and Resnick and Roy (1991). Max-stability is then deﬁned via a sequence
of norming constants, which are the same for every spatial location. Such processes
are closely related to union-stable random sets (Molchanov, 2005, Chapter 4). The
norming constants involved in the deﬁnition of max-stability determine the shape
parameter of the marginal distributions. Imposing a sequence of norming constants
rather than functions then forces the margins of the usc process to be of the same

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

3

type everywhere. However, modeling spatial extremes often requires space-varying
marginal parameters. This situation is not covered by the present literature, and
motivates the contribution of our paper.

Section 2 sets up the necessary background about usc processes. A general
class of measurable transformations on the space of usc functions is introduced
in Section 3. Under regularity conditions on the marginal distributions, this class
includes the pointwise probability integral transform and its inverse. This property
allows to state a partial generalization of Sklar’s theorem for usc processes in
general (Section 4) and for max-stable ones in particular (Section 5). Section 6
concludes. Some additional results are deferred to the appendices.

2. Random usc processes

We review some essential deﬁnitions and properties of random usc processes, or
usc processes for short. The material in this section may for instance be found in
Salinetti and Wets (1986), Beer (1993, Chapter 5), and Molchanov (2005, Chap-
ter 1.1 and Appendix B).

Recall that D is a non-empty, compact subset of some ﬁnite-dimensional Eu-
clidean space with no isolated points. A function x : D → [−∞, ∞] is upper
semicontinuous (usc) if and only if the set {s ∈ D : x(s) ≥ α} is closed for
each α ∈ R. The deﬁnition of lower semicontinuous (lsc) functions is similar, the
inequality being reversed.

For x : D → [−∞, +∞], deﬁne the epigraph and hypograph by

epi x = {(s, α) ∈ D × R : x(s) ≤ α},

hypo x = {(s, α) ∈ D × R : α ≤ x(s)}.

Observe that epi x and hypo x are subsets of D × R, even if the range of x con-
tains −∞ or +∞. A function is upper or lower semicontinuous if and only if its
hypograph or epigraph, respectively, is closed.

Let USC(D) be the collection of all upper semicontinuous functions from D into
[−∞, ∞]. By identifying the function z ∈ USC(D) with the set hypo z ⊂ D × R,
any topology on the space F = F (D × R) of closed subsets of D × R results in a
trace topology on the space of usc functions.

The Fell hit-and-miss topology on F is deﬁned as follows. Let K and G denote
the families of compact and open subsets of D × R, respectively. A base for the
Fell topology on F is the family of sets of the form

F K

G1,...,Gn = {F ∈ F : F ∩ K = ∅, F ∩ G1 6= ∅, . . . , F ∩ Gn 6= ∅}

for K ∈ K and G1, . . . , Gn ∈ G. A net of closed sets converges to a limit set F if
and only if every compact K missed by F is eventually also missed by the net and
if every open G hit by F is eventually also hit by the net.

The Fell topology on F (D × R) induces a trace topology on USC(D), the hypo-
topology. A sequence xn in USC(D) is said to hypo-converge to x in USC(D) if

4

A. SABOURIN AND J. SEGERS

and only if hypo xn converges to hypo x in the Fell topology. Since the underlying
space D×R is locally compact, Hausdorﬀ, and second countable (LCHS), the space
USC(D) thus becomes a compact, Hausdorﬀ, second-countable space. A conve-
nient pointwise criterion for hypo-convergence is the following one: a sequence
xn ∈ USC(D) hypo-converges to x ∈ USC(D) if, and only if,

∀s ∈ D : ∀sn ∈ D, sn → s : lim sup

xn(sn) ≤ x(s);

n→∞
∀s ∈ D : ∃sn ∈ D, sn → s : lim inf
n→∞

xn(sn) ≥ x(s).

Let (Ω, A, Pr) be a complete probability space and let B(F ) be the Borel σ-ﬁeld
on F = F (D × R) generated by the Fell topology. A random closed set of D × R is
a Borel measurable map from Ω into F . Similarly, a usc process ξ on D is a Borel
measurable map from Ω into USC(D). Equivalently, hypo ξ is a random closed
subset of D × R taking values in the collection of all closed hypographs. Some
authors use the term ‘normal integrand’ to refer to such processes, as a special
case of stochastic processes with usc realizations (Salinetti and Wets, 1986, p. 12).
In this work, a usc process is always a function ξ : D × Ω → [−∞, ∞] such that
the map Ω → F : ω 7→ hypo ξ( · , ω) is Borel measurable.

The capacity functional of hypo ξ is the map T : K → [0, 1] deﬁned by

T (K) = Pr{(hypo ξ) ∩ K 6= ∅},

K ∈ K.

We also call T the capacity functional of ξ rather than of hypo ξ. Since D × R is
LCHS, the Borel σ-ﬁeld B(F ) is generated by the sets

FK = {F ∈ F : F ∩ K 6= ∅},

K ∈ K.

(Molchanov, 2005, p. 2). The collection of complements of the sets FK being a
π-system, the capacity functional determines the distribution of a random closed
set or a usc process.

We emphasize that the Borel σ-ﬁeld on USC(D) is strictly larger than the one
generated by the ﬁnite-dimensional cylinders. Without additional hypotheses, the
ﬁnite-dimensional distributions of a usc process do not determine its distribution
as a usc process. The evaluation mappings USC(D) → [−∞, ∞] : x 7→ x(s) being
hypo-measurable, a usc process ξ is also a stochastic process (i.e., a collection of
random variables) with usc trajectories. The converse is not true, however:
for
such stochastic processes, the map Ω → USC(D) : ω 7→ ξ( · , ω) is not necessarily
hypo-measurable.

3. Transformations of usc functions

The following class of functions plays a fundamental role in our analysis of the

pointwise probability integral transform and its inverse.

Deﬁnition 3.1. A function U : D × [−∞, ∞] → [−∞, ∞] belongs to the class
U(D) if it has the following two properties:

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

5

(a) For every s ∈ D, the map x 7→ U(s, x) is non-decreasing and right-continuous.
(b) For every x ∈ R ∪ {∞}, the map s 7→ U(s, x) is usc.

See Remark 3.1 for the reason why we did not include x = −∞ in condition (b).

Proposition 3.1. Let U ∈ U(D).

(i) If zn hypo-converges to z in USC(D) and if sn → s in D as n → ∞, then

lim supn→∞ U(sn, zn(sn)) ≤ U(s, z(s)).

(ii) For every z ∈ USC(D), the function U∗(z) : D → [−∞, ∞] deﬁned by

(U∗(z))(s) = U(s, z(s)) belongs to USC(D) too.

(iii) For every compact K ⊂ D × R, the set {z ∈ USC(D) : hypo U∗(z) ∩ K 6= ∅}

is hypo-closed.

(iv) The map U∗ : USC(D) → USC(D) is hypo-measurable.

Proof. (i) Consider two cases: z(s) = ∞ and z(s) < ∞.

Suppose ﬁrst that z(s) = ∞. By the assumptions on U, we have

lim sup

n→∞

U(sn, zn(sn)) ≤ lim sup

n→∞

U(sn, ∞) ≤ U(s, ∞) = U(s, z(s)).

Suppose next that z(s) < ∞. Let y > z(s). By hypo-convergence, we have
lim supn→∞ zn(sn) ≤ z(s). As a consequence, there exists a positive integer n(y)
such that zn(sn) ≤ y for all n ≥ n(y). By the properties of U, we have

lim sup

n→∞

U(sn, zn(sn)) ≤ lim sup

n→∞

U(sn, y) ≤ U(s, y).

Since y > z(s) was arbitrary and since x 7→ U(s, x) is non-decreasing and right-
continuous, we ﬁnd lim supn→∞ U(sn, zn(sn)) ≤ inf y>z(s) U(s, y) = U(s, z(s)).

(ii) In statement (i), set zn = z to see that lim supn→∞ U(sn, z(sn)) ≤ U(s, z(s))

whenever sn → s in D as n → ∞.

(iii) Let K ⊂ D × R be compact. Suppose that zn hypo-converges to z in
USC(D) as n → ∞ and that hypo U∗(zn) ∩ K 6= ∅ for all positive integer n. We
need to prove that hypo U∗(z) ∩ K 6= ∅ too.

For each positive integer n, there exists (sn, xn) ∈ K such that U(sn, zn(sn)) ≥
xn. Since K is compact, we can ﬁnd a subsequence n(k) such that (sn(k), xn(k)) →
(s, x) ∈ K as k → ∞. By (i), we have

U(s, z(s)) ≥ lim sup

U(sn(k), zn(k)(sn(k))) ≥ lim sup

xn(k) = x.

k→∞

k→∞

As a consequence, (s, x) ∈ hypo U∗(z) ∩ K.

(iv) The collection of sets of the form {z ∈ USC(D) : hypo(z) ∩ K 6= ∅},
where K ranges over the compact subsets of D × R, generates the Borel σ-ﬁeld
on USC(D) induced by the hypo-topology. By (iii), the inverse image under U∗ of
each such set is hypo-closed and thus hypo-measurable. We conclude that U∗ is
hypo-measurable.
(cid:3)

6

A. SABOURIN AND J. SEGERS

Remark 3.1. In part (b) of the deﬁnition of U(D), we did not include x = −∞. The
reason is that this case is automatically included: by Proposition 3.1(ii) applied
to the function z(s) ≡ −∞, the map s 7→ U(s, −∞) is necessarily usc too.

Condition (b) is also necessary for the conclusion of Proposition 3.1(ii) to hold:

given x, deﬁne z(s) ≡ x.

A convenient property of U(D) is that it is closed under an appropriate kind of
composition. This allows to deconstruct complicated transformations in terms of
more elementary ones.

Lemma 3.1. If U and V belong to U(D), the function W deﬁned by (s, x) 7→
V (s, U(s, x)) belongs to U(D) too, and W∗ = V∗ ◦ U∗.

Proof. First, ﬁx s ∈ D. The map x 7→ V (s, U(s, x)) is non-decreasing: for −∞ ≤
x ≤ y ≤ ∞, we have U(s, x) ≤ U(s, y) and thus V (s, U(s, x)) ≤ V (s, U(s, y)).
The map x 7→ V (s, U(s, x)) is also right-continuous: if xn converges from the right
to x as n → ∞, then so does un = U(s, xn) to u = U(s, x) and thus V (s, un) to
V (s, u).

Next, ﬁx x ∈ R ∪ {∞}. We need to show that the function s 7→ V (s, U(s, x)) is
usc. But the function z deﬁned by s 7→ U(s, x) is usc, and, by Proposition 3.1, so
is the function s 7→ V (s, z(s)) = V (s, U(s, x)).
(cid:3)

Example 3.1. Here are some simple examples of functions U in the class U(D)
and the associated mappings U∗ : USC(D) → USC(D).

(i) If f : [−∞, ∞] → [−∞, ∞] is non-decreasing and right-continuous, the func-
tion (s, x) 7→ f (x) belongs to U(D). The associated map USC(D) → USC(D)
is z 7→ f ◦ z.

(ii) If y ∈ USC(D), the functions (s, x) 7→ x ∨ y(s) and (s, x) 7→ x ∧ y(s) both
belong to U(D). The associated maps USC(D) → USC(D) are z 7→ z ∨ y and
z 7→ z ∧ y, respectively.

(iii) If a : D → (0, ∞) is continuous, then the function (s, x) 7→ a(s) x belongs
to U(D). If b : D → R is usc, then the map (s, x) 7→ x + b(x) belongs to
U(D). The associated maps USC(D) → USC(D) are z 7→ az and z 7→ z + b,
respectively.

A more elaborate example of a function in U(D) is induced by the collection
of right-continuous quantile functions of the marginal distributions of a stochastic
process with usc trajectories. See Appendix A for some background on right-
continuous quantile functions.

Lemma 3.2. Let ξ = (ξ(s) : s ∈ D) be a stochastic process indexed by D and with
values in [−∞, ∞]. Let Fs : x ∈ [−∞, ∞] → Fs(x) = Pr[ξ(s) ≤ x] denote the
right-continuous marginal distribution function of ξ(s). Deﬁne

Qs(p) = sup{y ∈ R : Fs(y) ≤ p},

(s, p) ∈ D × [0, 1].

If ξ has usc trajectories, the function (s, x) 7→ Qs((x ∨ 0) ∧ 1) belongs to U(D).

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

7

Proof. First, by Proposition A.1, the map [0, 1] ∋ p 7→ Qs(p) is non-decreasing
and right-continuous for every s ∈ D, and hence the same is true for the map
[−∞, ∞] ∋ x 7→ Qs((x ∨ 0) ∧ 1).

Second, ﬁx x ∈ [−∞, ∞] and write p = (x ∨ 0) ∧ 1 ∈ [0, 1]. We need to show
that the map s 7→ Qs(p) is usc. Let sn → s in D as n → ∞; we need to show
that Qs(p) ≥ lim supn→∞ Qsn(p). Let Q′ be the right-continuous quantile function
of the random variable lim supn→∞ ξ(sn). The trajectories of ξ are usc, and thus
ξ(s) ≥ lim supn→∞ ξ(sn), which implies Qs(p) ≥ Q′(p). By Lemma A.2, we then
ﬁnd Qs(p) ≥ Q′(s) ≥ lim supn→∞ Qsn(p), as required.
(cid:3)

4. Sklar’s theorem for usc processes

A d-variate copula is the cumulative distribution function of a d-dimensional
random vector with standard uniform margins. Sklar’s celebrated theorem (Sklar,
1959) states two things:

(I) For every copula C and every vector F1, . . . , Fd of univariate distribution
functions, the function (x1, . . . , xd) 7→ C(F1(x1), . . . , Fd(xd)) is a d-variate
distribution function with margins F1, . . . , Fd.

(II) Every d-variate distribution function F can be represented in this way.

Reformulated in terms of random vectors, the two statements read as follows:

(I) For every random vector (U1, . . . , Ud) with uniform components and for every
vector F1, . . . , Fd of univariate distribution functions, the random vector
(Q1(U1), . . . , Qd(Ud)) has marginal distributions F1, . . . , Fd, where Qj is the
(right- or left-continuous) quantile function corresponding to Fj.

(II) Every random vector (X1, . . . , Xd) can be represented in this way.
We investigate up to what extent these statements hold for usc processes too.
According to Proposition 4.1, the ﬁrst statement remains true provided the sec-
tions s 7→ Qs(p) of the right-continuous quantile functions are usc. According to
Proposition 4.2, the Sklar representation is valid for usc processes whose marginal
distribution functions have usc sections, and even then, the equality in distribution
is not guaranteed.

Proposition 4.1 (`a la Sklar I for usc processes). Let Z be a usc process having
standard uniform margins. Let (Fs : s ∈ D) be a family of (right-continuous)
distribution functions and let Qs(p) = sup{x ∈ R : Fs(x) ≤ p} for all (s, p) ∈
D × [0, 1]. Deﬁne a stochastic process ξ by ξ(s) = Qs((Z(s) ∨ 0) ∧ 1) for s ∈ D.
Then the following two statements are equivalent:

(i) ξ is a usc process with marginal distributions given by Fs.
(ii) For every p ∈ [0, 1], the function s 7→ Qs(p) is usc.

Proof. For every s ∈ D, the random variable (Z(s) ∨ 0) ∧ 1 is equal almost surely
to Z(s), so that its distribution is uniform on [0, 1] too. By Proposition A.1(iv),

8

A. SABOURIN AND J. SEGERS

the distribution function of ξ(s) is given by Fs. As a consequence, Qs is the
right-continuous quantile function of the random variable ξ(s).

If (i) holds, then the trajectories s 7→ ξ(s) are usc. By Lemma 3.2, the function

s 7→ Qs(p) is usc for every p ∈ [0, 1].

Conversely, if (ii) holds, then the function U deﬁned by (s, x) 7→ Qs((x ∨ 0) ∧ 1)
belongs to U(D) deﬁned in Deﬁnition 3.1. Let U∗ be the associated map USC(D) →
USC(D); see Proposition 3.1. Then ξ = U∗(Z) is a usc process since Z is a usc
process and U∗ is hypo-measurable by Proposition 3.1(iv).
(cid:3)

Proposition 4.2 (`a la Sklar II for usc processes). Let ξ be a usc process. Let
Fs(x) = Pr[ξ(s) ≤ x] for x ∈ [−∞, ∞] and let Qs(p) = sup{x ∈ R : Fs(x) ≤ p}
for p ∈ [0, 1]. Suppose the following two conditions hold:
(a) For every s ∈ D, the distribution of ξ(s) has no atoms in [−∞, ∞].
(b) For every x ∈ R ∪ {+∞}, the function s 7→ Fs(x) is usc.
Then the following statements hold:

(i) The process Z deﬁned by Z(s) = Fs(ξ(s)) is a usc process with standard

uniform margins.

(ii) The process ˜ξ deﬁned by ˜ξ(s) = Qs(Z(s)) = Qs(Fs(ξ(s)) is a usc process such
that Pr[ ˜ξ(s) = ξ(s)] = 1 for every s ∈ D. In particular, the ﬁnite-dimensional
distributions of ˜ξ and ξ are identical.

Proof. (i) By condition (a), the marginal distributions of Z are standard uni-
form. By condition (b), the function U deﬁned by (s, x) 7→ Fs(x) belongs to U(D)
(Deﬁnition 3.1) and we have Z = U∗(ξ) with U∗ : USC(D) → USC(D) as in Propo-
sition 3.1. By item (iv) of that proposition, the map U∗ is hypo-measurable, so
that Z is a usc process too.

(ii) By Proposition A.1(v) below, we have Pr[ ˜ξ(s) = ξ(s)] = 1 for every s ∈ D.
The function Qs is the right-continuous quantile function of ξ(s) and the stochastic
process (ξ(s) : s ∈ D) has usc trajectories. Then requirement (ii) of Proposition 4.1
is fulﬁlled by an application of Lemma 3.2. By item (i) of the same proposition, ˜ξ
is a usc process.
(cid:3)
Remark 4.1. Although Pr[ ˜ξ(s) = ξ(s)] = 1 for all s ∈ D, it is not necessarily true
that Pr[ ˜ξ = ξ] = 1, and not even that ˜ξ and ξ have the same distribution as usc
processes: see Examples 4.4 and 4.5. However, if Pr[∀s ∈ D : 0 < Fs(ξ(s)) < 1] = 1
and if Qs(Fs(x)) = x for every s and every x such that 0 < Fs(x) < 1, then clearly
Pr[ ˜ξ = ξ] = 1.

The following Lemma helps clarifying the meaning of the assumptions of Propo-

sition 4.2.

Lemma 4.1 (Regularity of the marginal distributions w.r.t. the space variable ).
If ξ is a usc process, conditions (a) and (b) in Proposition 4.2 together imply that
the map s 7→ Fs(x) = Pr(ξ(s) ≤ x) is continuous, for any ﬁxed x ∈ R.

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

9

Proof. By condition (a), we have Pr[ξ(s) < x] = Fs(x) for each ﬁxed (s, x), so that
by Proposition A.1(iii), we have

{s ∈ D : x ≤ Qs(p)} = {s ∈ D : Fs(x) ≤ p}

for every x ∈ [−∞, ∞] and p ∈ [0, 1]. Since ξ is a usc process, the function
s 7→ Qs(p) is usc for p ∈ [0, 1] (Lemma 3.2). The set in the display is thus
closed. But then the map s 7→ Fs(x) is lower semicontinuous, and thus, by (b),
continuous.
(cid:3)

Remark 4.2. Condition (a) in Proposition 4.2, continuity of the marginal distribu-
tions, can perhaps be avoided using an additional randomization device, ‘smearing
out’ the probability masses of any atoms, as in R¨uschendorf (2009). However, even
if this may ensure uniform margins, it may destroy upper semicontinuity, see Ex-
ample 4.1. Since our interest is in extreme-value theory, in particular in max-stable
distributions (Section 5), which are continuous, we do not pursue this issue further.

Remark 4.3. Without condition (b) in Proposition 4.2, the trajectories of the
stochastic process (Z(s) : s ∈ D) may not be usc: see Example 4.2. However,
condition (b) is not necessary either: see Example 4.3.

The examples below illustrate certain aspects of Propositions 4.1 and 4.2. In
the examples, we do not go into measurability issues, that is, we do not prove
that the mappings ξ from the underlying probability space into USC(D) are hypo-
measurable. To do so, one can for instance rely on Molchanov (2005, Example 1.2
on page 3 and Theorem 2.25 on page 37).

Example 4.1 (What may happen without (a) in Proposition 4.2). Consider two
independent, uniformly distributed variables X and Y on [0, 1]. Take D = [−1, 1],
and deﬁne

|s|X
0
sY

ξ(s) =


if −1 ≤ s < 0,
if s = 0,
if 0 < s ≤ 1.

Condition (b) in Proposition 4.2 is fulﬁlled: the trajectories s 7→ Fs(x) = Pr[ξ(s) ≤
x] are continuous for every x 6= 0 and still usc for x = 0. Still, the marginal
probability integral transform produces Z(s) = X for s < 0 and Z(s) = Y for
s > 0. Extending Z to a stochastic process on [−1, 1] with usc trajectories would
require Z(0) ≥ X ∨ Y . But then Z(0) cannot be uniformly distributed on [0, 1].

Example 4.2 (What may happen without (b) in Proposition 4.2). Consider two
independent, uniformly distributed variables X and Y on [0, 1]. On D = [0, 2],
deﬁne

ξ(s) = X ∨ (Y 1{1}(s)) =(X

X ∨ Y

if s 6= 1,
if s = 1.

10

A. SABOURIN AND J. SEGERS

Then ξ is a usc process and the distribution function, Fs, of ξ(s) is given by

Fs(x) = Pr[ξ(s) ≤ x] =(x

x2

if s 6= 1,
if s = 1,

where x ∈ [0, 1]. As a consequence, the function s 7→ Fs(x) is lsc but not usc
if 0 < x < 1, so that condition (b) in Proposition 4.2 is violated. Reducing to
standard uniform margins yields

Z(s) = Fs(ξ(s)) =(X

(X ∨ Y )2

if s 6= 1,
if s = 1.

The event {0 < Y 2 < X < 1} has positive probability, and on this event we have
(X ∨ Y )2 < X, so that the trajectory s 7→ Z(s) is not usc. Hence, statement (i)
in Proposition 4.2 fails.

Example 4.3 (Condition (b) in Proposition 4.2 is not necessary). Let D = [−1, 1]
and let X and V be independent random variables, X standard normal and V
standard uniform. Deﬁne

X
X − 1
X

if −1 ≤ s ≤ 0,
if 0 < s < V ,
if V ≤ s ≤ 1.

ξ(s) =


Let Φ be the standard normal cumulative distribution function and choose x ∈ R.
Then Fs(x) = Pr[ξ(s) ≤ x] = Φ(x) if s ∈ [−1, 0], while for s ∈ (0, 1], we have

Fs(x) = Pr[s < V ] Pr[X − 1 ≤ x] + Pr[V ≤ s] Pr[X ≤ x]

= (1 − s) Φ(x + 1) + s Φ(x).

The function s 7→ Fs(x) is constant on s ∈ [−1, 0] while it decreases linearly from
Φ(x + 1) to Φ(x) for s from 0 to 1, the right-hand side limit at 0 being equal to
Φ(x + 1), which is greater than Φ(x), the value at s = 0 itself. Hence the function
s 7→ Fs(x) is lsc but not usc, and condition (b) in Proposition 4.2 does not hold.
Nevertheless, the random variables Z(s) = Fs(ξ(s)), s ∈ D, are given as follows:

Z(s) = Fs(ξ(s)) =


Φ(X)
(1 − s) Φ(X) + s Φ(X − 1)
(1 − s) Φ(X + 1) + s Φ(X)

if −1 ≤ s ≤ 0,
if 0 < s < V ,
if V ≤ s ≤ 1.

The trajectory of Z is continuous at s ∈ [−1, 1] \ {V } and usc at s = V , hence usc
overall.
Example 4.4 (ξ and ˜ξ in Proposition 4.2 may be diﬀerent in law (1)). Let X and
Y be independent, standard uniform random variables (taking values in [0, 1], to

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

11

avoid trivialities). For s ∈ D = [0, 1], deﬁne

ξ(s) = X + 1(Y = s) =(X

if s 6= Y ,
X + 1 if s = Y .

Since Pr[Y = s] = 0 for every s ∈ [0, 1], the law of ξ(s) is standard uniform
and conditions (a) and (b) in Proposition 4.2 are trivially fulﬁlled with Fs(x) =
(x ∨ 0) ∧ 1 for x ∈ [−∞, ∞] and Qs(p) = p for p ∈ [0, 1) and Qs(1) = ∞. We
obtain

˜ξ(s) = Z(s) =(X if s 6= Y ,

∞ if s = Y .

The processes ˜ξ and ξ have diﬀerent capacity functionals and thus a diﬀerent
distribution as random elements in USC(D): for K = [0, 1] × {x} with x > 2, we
have Pr[hypo ξ ∩ K] = 0 while Pr[hypo ˜ξ ∩ K 6= ∅] = 1.

Example 4.5 (ξ and ˜ξ in Proposition 4.2 may be diﬀerent in law (2)). Let X and
Y be independent random variables, with X uniformly distributed on [0, 1] ∪ [2, 3]
and Y uniformly distributed on [0, 1]. For s ∈ D = [0, 1], deﬁne

ξ(s) = X ∨ (1.5 1(Y = s)) =(X if s 6= Y ,

1.5 if s = Y and X ≤ 1.

Then Pr[ξ(s) = X] = 1 for all s ∈ [0, 1], so that the marginal distribution and
quantile functions Fs and Qs do not depend on s and are equal to those of X,
denoted by FX and QX. The random variable U = FX(X) is uniformly distributed
on [0, 1]. Since FX (1.5) = FX(1) = 0.5, we have

Z(s) = FX (ξ(s)) =(U

if s 6= Y ,

0.5 if s = Y and X ≤ 1.

However, as QX (0.5) = 2, we obtain

˜ξ(s) = QX (Z(s)) =(X if s 6= Y ,

2

if s = Y and X ≤ 1.

On the event {X ≤ 1}, which occurs with probability one half, the hypographs of
ξ and ˜ξ are diﬀerent.

5. Max-stable processes

We apply Propositions 4.1 and 4.2 to max-stable usc processes. These processes
and their standardized variants are introduced in Subsection 5.2, after some pre-
liminaries on generalized extreme-value distributions in Subsection 5.1. The main
results are given Subsection 5.3, followed by some examples in Subsection 5.4.

12

A. SABOURIN AND J. SEGERS

5.1. Generalized extreme-value distributions. The distribution function of
the generalized extreme-value (GEV) distribution with parameter vector θ =
(γ, µ, σ) ∈ Θ = R × R × (0, ∞) is given by

F (x; θ) =(exp[−{1 + γ(x − µ)/σ}−1/γ]

exp[− exp{−(x − µ)/σ}]

if γ 6= 0 and σ + γ(x − µ) > 0,
if γ = 0 and x ∈ R.

The corresponding quantile function is

Q(p; θ) =(µ + σ[{−1/ log(p)}γ − 1]/γ

µ + σ log{−1/ log(p)}

if γ 6= 0,
if γ = 0,

(5.1)

for 0 < p < 1. The support is equal to the interval {x ∈ R : σ + γ(x − µ) > 0}.
In particular, the lower endpoint is equal to Q(0; θ) = −∞ if γ ≤ 0 and Q(0; θ) =
µ − σ/γ if γ > 0.

For every n, there exist unique scalars an,θ ∈ (0, ∞) and bn,θ ∈ R such that the

following max-stability relation holds:

F n(an,θx + bn,θ; θ) = F (x; θ),

x ∈ R.

(5.2)

In fact, a non-degenerate distribution is max-stable if and only if it is GEV. This
property motivates the use of such distributions for modeling maxima over many
variables. The location and scale sequences are given by

an,θ = nγ,

bn,θ =((σ − γµ)(nγ − 1)/γ

σ log n

if γ 6= 0,
if γ = 0.

(5.3)

For quantile functions, max-stability means that
Q(p1/n; θ) = an,θ Q(p; θ) + bn,θ,

p ∈ [0, 1].

(5.4)

Note that Q(e−1; θ) = µ and thus Q(e−1/n; θ) = an µ + bn.

In Sklar’s theorem, the uniform distribution on [0, 1] plays the role of pivot.
Here, it is natural to standardize to a member of the GEV family. Multiple choices
are possible. We opt for the unit-Fr´echet distribution, given by

Φ(x) = F (x; 1, 1, 1) =(0

e−1/x

if x ≤ 0,
if x > 0.

The unit-Fr´echet quantile function is given by Q(p; 1, 1, 1) = −1/ log(p) for 0 <
p < 1. If the law of X is unit-Fr´echet, then the law of Q(Φ(X); θ) is GEV(θ).

For stochastic processes, the GEV parameter θ may depend on the point s ∈ D.
In view of the conditions in Propositions 4.1 and 4.2, the following lemma is
relevant.

Lemma 5.1. Let θ : D → Θ. The functions s 7→ F (x; θ(s)) and s 7→ Q(p; θ(s))
are usc for every x ∈ R and p ∈ [0, 1] if and only if θ is continuous.

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

13

Proof. If θ is continuous, then the maps s 7→ F (x; θ(s)) and s 7→ Q(p; θ(s)) are
continuous and thus usc.

Conversely, suppose that the functions s 7→ F (x; θ(s)) and s 7→ Q(p; θ(s)) are
usc for every x ∈ R and p ∈ [0, 1]. The argument is similar to the proof of
Lemma 4.1. By Proposition A.1(iii), we have

{s ∈ D : x ≤ Q(p; θ(s))} = {s ∈ D : F (x; θ(s)) ≤ p}

for every x ∈ [−∞, ∞] and p ∈ [0, 1]; note that GEV distributions are continuous.
Since the map s 7→ Q(p; θ(s)) is usc, the above sets are closed. But then the map
s 7→ F (x; θ(s)) must be lsc, and thus continuous. Finally, the map sending a GEV
distribution to its parameter is continuous with respect to the weak topology (see
Lemma C.1). Hence, θ is continuous.
(cid:3)

Remark 5.1. If θ : D → Θ is continuous, then the normalizing functions s 7→
an,θ(s) and s 7→ bn,θ(s) are continuous as well. Consider the map Un(s, x) = {x −
bn,θ(s)}/an,θ(s), for (s, x) ∈ D × [−∞, ∞]. Clearly, Un ∈ U(D). By Proposition 3.1,
the transformation USC(D) → USC(D) : z 7→ (z − bn,θ)/an,θ is then well-deﬁned
and hypo-measurable.

5.2. Max-stable usc processes.

Deﬁnition 5.1. A usc process ξ is called max-stable if, for all n ≥ 1, there
exist functions an : D → (0, ∞) and bn : D → R such that, for each vector of
n independent and identically distributed (iid) usc processes ξ1, . . . , ξn with the
same law as ξ, we have

(5.5)
A max-stable usc process ξ∗ is said to be simple if, in addition, its marginal
distributions are unit-Fr´echet. In that case, the norming functions are given by
an(s) = n and bn(s) = 0, i.e., in USC(D), we have

i=1 ξi

d= anξ + bn.

Wn

for iid usc processes ξ∗

1, . . . , ξ∗

n with the same law as ξ∗.

i=1 ξ∗
i

d= nξ∗

Wn

In Deﬁnition 5.1, it is implicitly understood that the functions an and bn are such
that the right-hand side of (5.5) still deﬁnes a usc process. If an is continuous and
bn is usc, then this is automatically the case; see Lemma 3.1 and Example 3.1(iii).
i=1 ξi − bn)/an is
i=1 ξi − bn)/an

Equation (5.5) is not necessarily the same as saying that (Wn
equal in distribution to ξ. The reason is that it is not clear that (Wn

is a usc process. Whether this is the case or not remains an open question.

The evaluation mappings USC(D) → [−∞, ∞] : z 7→ z(s) being measurable,

equation (5.5) implies that

As a consequence, the marginal distribution of ξ(s) is max-stable and therefore
GEV with some parameter vector θ(s) ∈ Θ. The normalizing functions an and

i=1 ξi(s) d= an(s) ξ(s) + bn(s),

s ∈ D.

Wn

14

A. SABOURIN AND J. SEGERS

bn must then be of the form an(s) = an,θ(s) and bn(s) = bn,θ(s) as in (5.3).
If
θ : D → Θ is continuous, then the normalizing functions are continuous too, and

i=1 ξi − bn)/an is equal in distribution to ξ (Remark 5.1).

(Wn

5.3. Sklar’s theorem for max-stable usc processes. We investigate the rela-
tion between general and simple max-stable usc processes via the pointwise prob-
ability integral transform and its inverse. Max-stability of usc processes not being
determined by the ﬁnite-dimensional distributions alone, it is not clear from the
outset that max-stability is preserved by pointwise transformations.

Proposition 5.1 gives a necessary and suﬃcient condition on the GEV margins
to be able to construct a general max-stable usc process starting from a simple
one. Propositions 5.2 and 5.3 treat the converse question, that is, when can a
max-stable usc process be ﬁrst reduced to a simple one and then be reconstructed
from it.

Proposition 5.1 (`a la Sklar I for max-stable usc processes). Let ξ∗ be a simple
max-stable usc process. Let θ : D → Θ. Deﬁne a stochastic process ξ by ξ(s) =
Q(Φ(ξ∗(s)); θ(s)) for s ∈ D. Then the following two statements are equivalent:

(i) ξ is a usc process with marginal distributions GEV(θ(s)).
(ii) For every p ∈ [0, 1], the function s 7→ Q(p; θ(s)) is usc.
If these conditions hold, then ξ is a max-stable usc process with normalizing func-
tions an(s) = an,θ(s) and bn(s) = bn,θ(s).

Proof. By Proposition 4.2(i) applied to ξ∗, the stochastic process Z(s) = Φ(ξ∗(s))
induces a usc process whose margins are uniform on [0, 1]. The equivalence of
statements (i) and (ii) then follows from Proposition 4.1.

Assume that (i) and (ii) are fulﬁlled. We need to show that the right-hand side

in (5.5) deﬁnes a usc process and that the stated equality in distribution holds.

For positive integer n, deﬁne Un(s, x) = Q(Φ(nx); θ(s)) for (s, x) ∈ D×[−∞, ∞].
In view of Lemma 3.1 and Example 3.1, the map Un belongs to U(D). Moreover,
max-stability (5.4) implies

Un(s, x) = Q(Φ(x)1/n; θ(s)) = an,θ(s) Q(Φ(x); θ(s)) + bn,θ(s).

It follows that

an,θ(s) ξ(s) + bn,θ(s) = Un(s, ξ∗(s)).

By Proposition 3.1, the function s 7→ Un(s, z(s)) belongs to USC(D) for every
z ∈ USC(D), and the map Un,∗ from USC(D) to itself sending z ∈ USC(D) to this
function is hypo-measurable. We conclude that an ξ + bn is a usc process.

Next, we prove that ξ is max-stable. Let ξ1, . . . , ξn be iid usc processes with the
n be iid usc processes with the same law as ξ∗.

1, . . . , ξ∗

same law as ξ. Further, let ξ∗
For every i ∈ {1, . . . , n}, we have

ξi

d= ξ = U1,∗(ξ∗) d= U1,∗(ξ∗

i ).

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

15

The last equality in distribution comes from the hypo-measurability of U1,∗. By
independence, it follows that

(ξ1, . . . , ξn) d= (U1,∗(ξ∗

1), . . . , U1,∗(ξ∗

n)) .

Write ( ˜ξ1, . . . , ˜ξn) = (U1,∗(ξ∗

i ), . . . , U1,∗(ξ∗

n)). By monotonicity, we have, for s ∈ D,

i=1

Wn

˜ξi(s) =Wn

i (s)); θ(s)(cid:1) = Q(cid:0)Φ(Wn
Since ξ∗ is a simple max-stable usc process, we have Wn

i=1 Q(cid:0)Φ(ξ∗

But then also

i=1 ξ∗

i (s)); θ(s)(cid:1).

i=1 ξ∗
i

d= nξ∗ in USC(D).

i=1 ξi

Wn

i=1

˜ξi

d=Wn
d= Q(cid:0)Φ(nξ∗); θ(cid:1) = Q(cid:0)Φ(ξ∗)1/n; θ(cid:1)
= an,θ Q(cid:0)Φ(ξ∗); θ(cid:1) + bn,θ = an,θ ξ + bn,θ.

(cid:3)

Proposition 5.2 (`a la Sklar II for usc processes with GEV margins). Let ξ be a
usc process with GEV(θ(s)) margins for s ∈ D. If θ : D → Θ is continuous, then
the following statements hold:

(i) The process ξ∗ deﬁned ξ∗(s) = −1/ log F (ξ(s); θ(s)) is a usc process with

unit-Fr´echet margins.

(ii) The process ˜ξ deﬁned by ˜ξ(s) = Q(Φ(ξ∗(s)); θ(s)) is a usc process and, with

probability one,

∀s ∈ D : ˜ξ(s) =(ξ(s)

if ξ∗(s) < ∞,
∞ if ξ∗(s) = ∞.

Proof. The marginal distributions of ξ are GEV and depend continuously on s.
Conditions (a) and (b) in Proposition 4.2 are therefore satisﬁed.

By Proposition 4.2(i), the process Z deﬁned by Z(s) = F (ξ(s); θ(s)) is a usc
process with standard uniform margins. It then follows that ξ∗ deﬁned by ξ∗(s) =
−1/ log Z(s) is a usc process too, its margins being unit-Fr´echet.

Since 0 ≤ Z(s) ≤ 1 by construction, we have 0 ≤ ξ∗(s) ≤ ∞ and thus
Φ(ξ∗(s)) = Z(s). We ﬁnd ˜ξ(s) = Q(Z(s); θ(s)) = Q(F (ξ(s); θ(s)); θ(s)). By
Proposition 4.2(ii), the process ˜ξ is a usc process.

Recall that GEV distribution functions are continuous and strictly increasing

on their domains. As a consequence, for all x such that x ≥ Q(0; θ(s)), we have

Q(F (x; θ(s)); θ(s)) =(x

if F (x; θ(s)) < 1,
∞ if F (x; θ(s)) = 1.

Moreover, Lemma B.1 implies that ξ ≥ Q(0; θ) almost surely. Since ξ∗(s) < ∞ if
and only if F (ξ(s); θ(s)) < 1, we arrive at the stated formula for ˜ξ.
(cid:3)

16

A. SABOURIN AND J. SEGERS

Proposition 5.3 (`a la Sklar II for max-stable processes). Let ξ be a usc process
with GEV(θ(s)) margins for s ∈ D. Assume that sups∈D F (ξ(s); θ(s)) < 1 with
probability one and that the function θ : D → Θ is continuous. As in Proposi-
tion 5.2, deﬁne two usc processes ξ∗ and ˜ξ by ξ∗(s) = −1/ log F (ξ(s); θ(s)) and
˜ξ(s) = Q(Φ(ξ∗(s)); θ(s)), for s ∈ D. Then, almost surely, ξ = ˜ξ. Furthermore, the
following two statements are equivalent:

(i) The usc process ξ is max-stable.
(ii) The usc process ξ∗ is simple max-stable.

Proof. The fact that ξ∗ is a usc process with unit-Fr´echet margins is a consequence
of the continuity of θ and Proposition 5.2(i). The hypothesis on F (ξ(s); θ(s))
together with Proposition 5.2(ii) imply that ξ = ˜ξ almost surely.

The functions s 7→ an,θ(s) ∈ (0, ∞) and s 7→ bn,θ(s) ∈ R are continuous. The map
D × [−∞, ∞] → [−∞, ∞] deﬁned by (s, x) 7→ an,θ(s) x + bn,θ(s) belongs to U(D).
By Proposition 3.1, the map from USC(D) to itself sending z to the function s 7→
an,θ(s) z(s) + bn,θ(s) is well-deﬁned and hypo-measurable. It follows that an,θ ξ + bn,θ
is a usc process.

Suppose ﬁrst that (ii) holds, i.e., ξ∗ is simple max-stable. By Proposition 5.1,
the usc process ˜ξ is max-stable with norming functions s 7→ an,θ(s) and s 7→ bn,θ(s).
Since ξ and ˜ξ are equal almost surely in USC(D), they are also in equal in law.
Statement (i) follows.

Conversely, suppose that (i) holds. Let (ξ∗

i=1 be vectors of iid
usc processes with common laws equal to the ones of ξ∗ and ξ, respectively. For
z ∈ USC(D), write −1/ log F (z, θ) = (−1/ log F (z(s), θ(s))s∈D. The mapping
z 7→ −1/ log F (z, θ) from USC(D) to itself is hypo-measurable, by an argument as
in the proof of Proposition 5.2. For i ∈ {1, . . . , n}, we have, in USC(D),

i )n

i=1 and (ξi)n

ξ∗
i

d= ξ∗ = −1/ log F (ξ, θ) d= −1/ log F (ξi, θ).

By independence, we have thus have (ξ∗
and max-stability (5.2) now say that

i )n

i=1

d= (−1/ log F (ξi, θ))n

i=1. Property (i)

i=1 ξ∗
i

Wn

i=1 ξi; θ)

d= −1/ log F (Wn

d= −1/ log F (an,θξ + bn,θ; θ)
= −1/ log{F (ξ; θ)1/n}
= n [−1/ log F (ξ; θ)]
= nξ∗.

(cid:3)

Remark 5.2 (Regarding the ﬁniteness of ξ∗ in Proposition 5.2(ii)). Recall that usc
functions reach their suprema on compacta. As a consequence, for z ∈ USC(D),
we have z(s) < ∞ for all s ∈ D if and only if sups∈D z(s) < ∞. The event
{sups∈D ξ∗(s) < ∞} is thus the same as the event {∀s ∈ D : ξ∗(s) < ∞}.

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

17

Remark 5.3 (Regarding the continuity assumption on θ in Proposition 5.2). Ac-
cording to Lemmas 3.2 and 5.1, imposing the continuity of the GEV parameter
vector θ(s) as a function of s ∈ D is equivalent to imposing the upper semiconti-
nuity of the function s 7→ F (x, θ(s)) for each ﬁxed x ∈ R.

5.4. Examples. In comparison to Proposition 4.2, we have added to Proposi-
tion 5.2 the assumption that the margins be GEV. Although their distributions
functions are continuous and strictly increasing on their support, this does not
resolve the issues arising when the marginal distributions are not continuous in
space. Example 5.1, which parallels Example 4.2, illustrates the point.

Example 5.1 (What may happen without the continuity of θ). Consider two
independent, unit-Fr´echet distributed variables X and Y . As in Example 4.2, take
D = [0, 2], and deﬁne

ξ(s) = X ∨ (Y 1{1}(s)) =(X

X ∨ Y

if s 6= 1,
if s = 1.

Then again, ξ is a usc process.
functions an ≡ n and bn ≡ 0. The marginal distribution functions are

It is even a max-stable one with normalizing

F (x; θ(s)) = Pr[ξ(s) ≤ x] =(e−1/x

e−2/x

if s 6= 1,
if s = 1,

where x ≥ 0. Then the function s 7→ Fs(x) is lower rather than upper semicontin-
uous, and the marginal GEV parameter vector is

θ(s) = (γ(s), µ(s), σ(s)) =((1, 1, 1)

(1, 2, 2)

if s 6= 1,
if s = 1,

which is not continuous as a function of s. Standardizing to Fr´echet margins yields

ξ∗(s) = F (ξ(s); θ(s)) =(e−1/X

e−2/(X∨Y )

if s 6= 1,
if s = 1.

The event {0 < X < Y < 2X} has positive probability, and on this event, we have
e−2/(X∨Y ) = e−2/Y < e−1/X . The trajectory s 7→ ξ∗(s) is therefore not usc.

To conclude, we present a construction principle for simple max-stable usc pro-
In combination with Proposition 5.1, this provides a device for
cess processes.
the construction of max-stable usc processes with arbitrary GEV margins. The
method is similar to the one proposed in Schlather (2002, Theorem 2). Proving
max-stability of the usc process that we construct requires special care, since max-
stability in USC(D) does not follow from max-stability of the ﬁnite-dimensional
distributions.

18

A. SABOURIN AND J. SEGERS

Example 5.2. Let Y1 > Y2 > Y3 > . . . denote the points of a Poisson point
process on (0, ∞) with intensity measure y−2 dy. Let V1, V2, . . . be iid usc processes,
independent of the point process (Yi)i, with common distribution equal to the one
of the usc process V . Assume that V satisﬁes the following properties:

• Pr[inf s∈D V (s) ≥ 0] = 1;
• E[sups∈D V (s)] < ∞;
• the mean function f (s) = E(V (s)) is strictly positive and continuous on D.
By Lemma B.3 below, inf D V is indeed a random variable. Note that we do not
impose that inf D V > 0 almost surely.

Deﬁne a stochastic process ξ on D by

ξ(s) = sup
i≥1

Yi

1

f (s)

Vi(s),

s ∈ D.

We will show that ξ is ‘almost surely’ a simple max-stable usc process, in the
following sense:

(a) With probability one, the trajectories of ξ are usc.
(b) Letting Ω1 ⊂ Ω denote a set of probability one on which the trajectories ξ( · , ω)

are usc, the map ξ : Ω1 → USC(D) is measurable.

Consider the space of nonnegative functions

USC(D)+ = {z ∈ USC(D) : ∀s ∈ D, z(s) ≥ 0} = \s∈D

{z ∈ USC(D) : z(s) ≥ 0}.

For each ﬁxed s ∈ D, the set {z ∈ USC(D) : z(s) ≥ 0} is closed, since the
corresponding set of hypographs is the complement set of F {(s,0)}, an open subset
of F (D × R) in the Fell topology. The set USC(D)+ is thus closed in USC(D), as
an intersection of closed sets.

Set E = USC(D)+ \ {0}, where 0 denotes for the null function on D. Since
USC(D) is a compact space with a countable basis (Molchanov, 2005, Theorem B.2,
p. 399), the space E is locally compact with a countable basis. Classical theory
of point processes applies and it is possible to deﬁne Poisson processes on E by
augmentation and/or continuous mappings.

Put Wi = Vi/f . Then for i ∈ N, Wi a random element of USC(D) such that

Wi ∈ E with probability one. The point process Γ deﬁned by

δ(Yi,Wi).

Γ =Xi≥1

is thus a Poisson process on (0, ∞) × E with mean measure dΛ(y, w) = y−2 dy ⊗
dPW (w), where PW is the law of W1 (Resnick, 1987, Proposition 3.8).

The ‘product’ mapping T : (0, ∞) × E → E deﬁned by T (y, w) = yw (y >
0, w ∈ E) is measurable. Provided that the image measure µ = Λ ◦ T −1 is ﬁnite

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

19

on compact sets of E, we ﬁnd that the point process

δ(YiWi)

Π =Xi≥1

is a Poisson process with mean measure µ on E (Resnick, 1987, Proposition 3.7).
To check ﬁniteness of µ on compact sets of E, we must check that for K ⊂ D and
x > 0, writing

FK×{x} = {z ∈ USC(D)+ : sup
s∈K

z(s) ≥ x},

we have µ(FK×{x}) < ∞. Indeed, the set FK×{x} is closed in USC(D), and since
USC(D) is compact, the compact sets in E are the closed sets F in USC(D) such
that F ⊂ E. Thus FK×{x} is compact. Also, any compact set in E must be
contained in such a FK×{x}. Now,

µ(FK×{x}) = −Λ(cid:8)(r, w) ∈ (0, ∞) × USC(D) : r max

s∈K

x

w(s) ≥ x(cid:9)

W (s)o dr
r2i

0

= EhZ ∞
Eh sup

1nr ≥ inf
W (s)i

1
x

s∈Kj

=

s∈K

≤

1
x

E[supD V ]

,

inf D f

which is ﬁnite by assumption on V .

To show (a), we adapt an argument of Gin´e et al. (1990, proof of Theorem 2.1).
For ﬁxed K ⊂ D compact and x > 0, we have µ(FK×{x}) < ∞ and thus
Π(FK×{x}) < ∞ almost surely. Thus, there exists a set Ω1 of probability one,
such that the following two statements hold for all ω ∈ Ω1:

(i) Wi( · , ω) ∈ E for all i ∈ N;
(ii) Π(FK×{x})(ω) < ∞ for every rational x > 0 and every compact rectangle

K ⊂ D with rational vertices.

Take ω ∈ Ω1. We need to show that for s ∈ D and x ∈ Q such that ξ(s, ω) < x,
we have lim supt→s ξ(t, ω) ≤ x. Fix s and x as above, which implies that x > 0.
Let Kn ց {s} be a collection of compact rational rectangles as above such that

s is in the interior of Kn. Then F{(s,x)} = Tn∈N FKn×{x} (the inclusion ‘⊂’ is
immediate; the inclusion ‘⊃’ is obtained by choosing for z ∈ Tn∈N FKn×{x} and

for n ∈ N a point sn ∈ Kn such that z(sn) ≥ x and then observing that sn → s
and thus z(s) ≥ x by upper semicontinuity). From our choice of Ω1, we have
Π(FK1×{x}, ω) < ∞, so that the downward continuity property of the measure
Π( · , ω) applies and

Π(F{(s,x)}, ω) = lim
n→∞

Π(FKn×{x}, ω).

20

A. SABOURIN AND J. SEGERS

By our choice of s, x, and ω, the left-hand side in the display is zero. Since the
sequence on the right-hand side is integer valued, there exists n0 such that for all
n ≥ n0, we have Π(FKn×{x}, ω) = 0. This implies that for n ≥ n0, we have

Yi(ω)Wi(t, ω) < x,

i ∈ N.

sup
t∈Kn

Complete the proof of (a) by noting that

lim sup

t→s

ξ(t, ω) ≤ sup
t∈Kn0

ξ(t, ω) = sup
i∈N

sup
t∈Kn0

Yi(ω)Wi(t, ω) ≤ x.

To show (b), we need to show that, for any compact K ⊂ D × R, the set

A = {ω ∈ Ω1 : hypo ξ( · , ω) ∩ K 6= ∅}

is a measurable subset of Ω. Notice ﬁrst that ξ( · , ω) ∈ USC(D)+ for ω ∈ Ω1;
use property (i) of Ω1. It follows that A = Ω1 as soon as K is not a subset of
D × (0, ∞). Assume K ⊂ D × (0, ∞).

Then on Ω1, we have hypo ξ ∩ K 6= ∅ if and only if Π({z ∈ E : hypo z ∩ K 6=
∅}) ≥ 1. Now FK = {z ∈ E : hypo z ∩ K 6= ∅} is a measurable subset of E, so
that X = Π(FK) is a random variable. It follows that A = X −1([1, ∞]) ∩ Ω1 is
measurable, which shows (b).

A standard argument yields that the margins of ξ are unit-Fr´echet. To show
that ξ is simple max-stable, we need to show that, for independent random copies
i=1 ξi and nξ are the same. That is,

ξ1, . . . , ξn of ξ, the capacity functionals of Wn

we need to show that, for every compact set in D × R, we have

Pr[hypo(Wn

The left-hand side is equal to

i=1 ξ) ∩ K = ∅] = Pr[hypo(nξ) ∩ K = ∅].

(5.6)

Pr[(Sn

i=1 hypo ξi) ∩ K = ∅] = Pr[∀i = 1, . . . , n : hypo ξi ∩ K = ∅]

= (Pr[hypo ξ ∩ K = ∅])n.

(5.7)

Without loss of generality, we may assume that

j=1(Kj × {xj}),

K =Sp

where p ∈ N and where Kj ⊂ D is compact and xj is real, for j ∈ {1, . . . , p}.
Indeed, the capacity functional of a usc process is entirely determined by its values
on such compacta (Molchanov, 2005, p. 340). We may also choose xj > 0, since

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

21

otherwise both sides of (5.6) vanish. For such a set K, we have

Pr[hypo ξ ∩ K = ∅]

= PrhΠ(cid:8)z ∈ E : ∃ 1 ≤ j ≤ p, max
z ≥ xj(cid:9) = 0i
= exp(cid:16) − Λ(cid:8)(r, w) ∈ (0, ∞) × E : ∃j ≤ p , r max
= exp(cid:16) − EhZ ∞
W (s)o dr
r2i(cid:17)
= exp(cid:16) − EhZ ∞
W (s)o dr
r2i(cid:17)
i(cid:17).
= exp(cid:16) − Eh max

1n∃j : r ≥ min
1nr ≥ min

s∈Kj

min
s∈Kj
maxs∈Kj W (s)

j

s∈Kj

0

0

j

xj

Kj

xj

xj

w(s) ≥ xj(cid:9)(cid:17)

For ξ replaced by nξ, we obtain the same result, but with xj replaced by xj/n. In
view of (5.7), the desired equality (5.6) follows.

6. Conclusion

The aim of the paper has been to extend Sklar’s theorem from random vectors
to usc processes. We have stated necessary and suﬃcient conditions to be able to
construct a usc process with general margins by applying the pointwise quantile
transformation to a usc process with standard uniform margins (Propositions 4.1
and 5.1). Furthermore, we have stated suﬃcient conditions for the pointwise prob-
ability integral transform to be possible for usc processes (Propositions 4.2, 5.2
and 5.3). These conditions imply in particular that the marginal distribution
functions are continuous with respect to he space variable (Lemma 4.1). We have
also provided several examples of things that can go wrong when these conditions
are not satisﬁed. However, ﬁnding necessary and suﬃcient conditions remains an
open problem.

The motivation has been to extend the margins-versus-dependence paradigm
used in multivariate extreme-value theory to max-stable usc processes. The next
step is to show that marginal standardization is possible in max-domain of attrac-
tions too. One question, for instance, is whether the standardized weak limit of
the pointwise maxima of a sequence of usc processes is equal to the weak limit
of the pointwise maxima of the sequence of standardized usc processes (Resnick,
1987, Proposition 5.10). Interesting diﬃculties arise: weak convergence of ﬁnite-
dimensional distributions does not imply and is not implied by weak hypoconver-
gence; Khinchin’s convergence-of-types lemma does not apply in its full generality
to unions of random closed sets (Molchanov, 2005, p. 254, ‘Aﬃne normalization’).
This topic will be the subject of further work.

22

A. SABOURIN AND J. SEGERS

Appendix A. Right-continuous quantile functions

The right-continuous quantile function, Q, of a random variable X taking values
in [−∞, ∞] and with distribution function F (x) = Pr[X ≤ x], x ∈ [−∞, ∞], is
deﬁned as

Q(p) = sup{x ∈ R : F (x) ≤ p},

(A.1)
By convention, sup ∅ = −∞ and sup R = ∞. The fact that Q is right-continuous
is stated in part (ii) of the next proposition.

p ∈ [0, 1].

Proposition A.1. Let X be a random variable taking values in [−∞, ∞]. Deﬁne
Q : [0, 1] → [−∞, ∞] as in (A.1).

(i) For all p ∈ [0, 1], we have Q(p) = sup{x ∈ R : Pr(X < x) ≤ p}.
(ii) The function Q is non-decreasing and right-continuous.
(iii) For every x ∈ [−∞, ∞] and every p ∈ [0, 1], we have x ≤ Q(p) if and only if

Pr[X < x] ≤ p.

(iv) If V is uniformly distributed on [0, 1], then the distribution function of Q(V )

is F , i.e., Q(V ) and X are identically distributed.

(v) If the law of X has no atoms in [−∞, ∞], then Pr[X = Q(F (X))] = 1.

Proof. (i) Fix p ∈ [0, 1]. Since Pr[X < x] ≤ Pr[X ≤ x] = F (x), we have

Q(p) := sup{x ∈ R : F (x) ≤ p}

≤ sup{x ∈ R : Pr[X < x] ≤ p} := x0.

Conversely, if Q(p) = +∞, there is nothing to prove. Assume then that Q(p) <
+∞, so that p < 1. Let y > Q(p). We need to show that y > x0 too, that is,
Pr[X < y] > p. But Pr[X < y] = sup{F (z) : z < y}, and this supremum must be
larger than p, since for all z > Q(p) we have F (z) > p.

(ii) The sets {x ∈ R : F (x) ≤ p} becoming larger with p, the function Q is
non-decreasing. Next, we show that Q is right continuous at any p ∈ [0, 1]. If
Q(p) = ∞, there is nothing to show, so suppose Q(p) < ∞ (in particular p < 1).
Let ε > 0. Then Q(p) + ε > Q(p) and thus F (Q(p) + ε) = p + δ > p for some
δ > 0. For r < p + δ, we have F (Q(p) + ε) > r too, and thus Q(r) < Q(p) + ε, as
required.

(iii) First suppose x < Q(p); we show that Pr[X < x] ≤ p. The case x = ∞
is impossible, and if x = −∞, then Pr[X < x] = 0 ≤ p. So suppose that
x ∈ R. Using statement (i), there exists y ∈ R with x ≤ y ≤ Q(p) such that
Pr[X < y] ≤ p. But then also Pr[X < x] ≤ p.

Second suppose that x > Q(p); we show that Pr[X < x] > p. Clearly, we must
have Q(p) < ∞, and so we can without loss of generality assume that x is real.
But then Pr[X < x] > p by statement (i).

Finally, consider x = Q(p); we show that Pr[X < Q(p)] ≤ p. If Q(p) = −∞,
then Pr[X < Q(p)] = 0 ≤ p. If Q(p) > −∞, then Pr[X < y] ≤ p for all y < Q(p),
and thus Pr[X < Q(p)] = supy<Q(p) Pr[X < y] ≤ p too.

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

23

(iv) Without loss of generality, assume that 0 ≤ V ≤ 1 (if not, then replace
V by (V ∨ 0) ∧ 1, which is almost surely equal to V ). Let x ∈ [−∞, ∞]. By
statement (iii), we have x ≤ Q(V ) if and only if Pr[X < x] ≤ V . As a consequence,
Pr[x ≤ Q(V )] = Pr[Pr[X < x] ≤ V ] = 1 − Pr[X < x] = Pr[x ≤ X]. We conclude
that Q(V ) and X are identically distributed and thus that Q(V ) has distribution
function F too.

(v) By deﬁnition, x ≤ Q(F (x)) for every x ∈ R. For x = −∞ and x = +∞, the
same inequality is trivially fulﬁlled too (recall that F (∞) = 1 and Q(1) = ∞). As
a consequence, X ≤ Q(F (X)).

Conversely, let P be the collection of p ∈ [0, 1] such that the set {x ∈ R : F (x) =
p} has positive Lebesgue measure. These sets being disjoint for distinct p, the set
P is at most countably inﬁnite. If x < Q(F (x)), then there exists y > x such that
F (x) = F (y) and thus F (x) ∈ P. However, the law of F (X) is standard uniform,
so that Pr[F (X) ∈ P] = 0. Hence X = Q(F (X)) almost surely.
(cid:3)

Proposition A.2. Let (Xn)n∈N be a sequence of random variables deﬁned on the
same probability space and taking values in [−∞, ∞]. Let Qn and Q be the right-
continuous quantile functions (A.1) of Xn and lim supn→∞ Xn, respectively. Then

Q(p) ≥ lim sup

n→∞

Qn(p),

p ∈ [0, 1].

Proof. If Q(p) = ∞, there is nothing to show, so suppose Q(p) < ∞. Let y > Q(p);
we will show that y ≥ lim supn→∞ Qn(p). This being true for all y > Q(p), we will
have proved the proposition.

By statement (i) of Proposition A.1, we have Pr[lim supn→∞ Xn < y] > p. By
Fatou’s lemma, there exists a positive integer n(y) such that Pr[Xn < y] > p
for all integer n ≥ n(y). But for such n, we have y > Qn(p) too. Hence, y ≥
lim supn→∞ Qn(p), as required.
(cid:3)

Appendix B. Lower bounds of usc processes

Lemma B.1. If ξ is a usc process, then the function ℓ(s) = sup{x ∈ R : Pr[ξ(s) <
x] = 0}, for s ∈ D, is usc. Moreover, ξ ∨ ℓ is a usc process too, and we have
Pr[ξ ≥ ℓ] = Pr[ξ = ξ ∨ ℓ] = 1.

Proof. The function ℓ is equal to the function s 7→ Qs(0), with Qs the right-
continuous quantile function (A.1) of ξs. By Lemma 3.2, the function ℓ is usc, and
by Example 3.1, the map USC(D) → USC(D) : z 7→ z ∨ ℓ is hypo-measurable, so
that ξ ∨ ℓ is a usc process too.

By Lemma B.2, there exists a countable subset, Qℓ, of D with the following
property: for all x ∈ USC(D), we have x(s) ≥ ℓ(s) for all s ∈ D if and only if x(t) ≥
ℓ(t) for all t ∈ Qℓ. Since ℓ(t) = Qt(0), we have Pr[ξ(t) ≥ ℓ(t)] = 1 for all t ∈ Qℓ;
see Proposition A.1(iii). Since Qℓ is countable, also Pr[∀t ∈ Qℓ : ξ(t) ≥ ℓ(t)] = 1.
By the property of Qℓ mentioned earlier, the event {∀t ∈ Qℓ : ξ(t) ≥ ℓ(t)} is equal
to both {ξ ≥ ℓ} and {ξ = ξ ∨ ℓ}.
(cid:3)

24

A. SABOURIN AND J. SEGERS

Lemma B.2. For every z ∈ USC(D), there exists a countable set Qz ⊂ D such
that

z(s) = inf
ε>0

sup

z(t),

s ∈ D.

t∈Qz:d(s,t)≤ε

(B.1)

In particular, for every x ∈ USC(D), we have x(s) ≥ z(s) for all s ∈ D if and only
if x(t) ≥ z(t) for all t ∈ Qz.

Proof. The set hypo z is a subset of the metrizable separable space D × R. Hence,
it is separable too. Let Q be a countable, dense subset of hypo z. Let Qz be the
set of t ∈ D such that (t, x) ∈ Q for some x ∈ R. Then Qz is a countable subset
of D.

Let y(s) denote the right-hand side of (B.1). Since z is usc, we have z(s) ≥ y(s)

for all s ∈ D.

Conversely, let s ∈ D.

If z(s) = −∞, then trivially y(s) ≥ z(s). Suppose
z(s) > −∞. Let −∞ < α < z(s), so that (s, α) ∈ hypo z. Find a sequence
(tn, αn) ∈ Q such that (tn, αn) → (s, α) as n → ∞. Then (tn, αn) ∈ hypo z and
thus z(tn) ≥ αn for all n. Moreover, tn → s and αn → α as n → ∞. It follows
that y(s) ≥ α. Since this is true for all α < z(s), we ﬁnd y(s) ≥ z(s).

We prove the last statement. Let x ∈ USC(D) and suppose that x(t) ≥ z(t) for

all t ∈ Qz. The function x is equal to its own usc hull, i.e.,

x(s) = inf
ε>0

sup

x(t),

s ∈ D.

t∈D:d(s,t)≤ε

Combine this formula together with (B.1) to see that x(s) ≥ z(s) for all s ∈ D. (cid:3)

Lemma B.3. If ξ is a usc process, then inf s∈F ξ(s) is a random variable for any
closed set F ⊂ D.

Proof. Let Q be a countable, dense subset of F . Since every ξ(s) is a random
variable, it suﬃces to show that inf s∈F ξ(s) = inf s∈Q ξ(s). The inequality ‘≤’ is
trivial. To see the other inequality, suppose that x is such that ξ(s) ≥ x for all
s ∈ Q. Then (s, x) ∈ hypo ξ for all s ∈ Q, and thus (s, x) ∈ hypo ξ for all s ∈ F ,
since hypo ξ is closed. It follows that ξ(s) ≥ x for all s ∈ F .
(cid:3)

Appendix C. Continuity of the GEV parameter

Recall the GEV distributions from Subsection 5.1.

Lemma C.1. Let Fn = F ( · , θn), n ≥ 0, be GEV distribution functions with
associated GEV parameters θn = (µn, σn, γn). If (Fn)n converges weakly to F0,
then also limn→∞ θn = θ0 in R × R × (0, ∞).

Proof. By continuity of the GEV distribution, weak convergence is the same as
pointwise convergence, and thus limn→∞ Fn(x) = F0(x) for all x ∈ R.

Recall the expression (5.1) of the quantile function Q( · ; θ). Pointwise conver-
gence of monotone functions implies pointwise convergence of their inverses at

MARGINAL STANDARDIZATION OF UPPER SEMICONTINUOUS PROCESSES

25

continuity points of the limit (Resnick, 1987, Chapter 0). Setting p = e−1, we
obtain

µn = Q(e−1; θn) → Q(e−1; θ0) = µ0,

n → ∞.

As a consequence, for p ∈ (0, 1),

Q(p; γn, 0, σn) = Q(p; θn) − µn

→ Q(p; θ0) − µ0 = Q(p; γ0, 0, σ0),

n → ∞.

(C.1)

This implies that for x, y > 0 such that y 6= 1,

lim
n→∞

xγn − 1
yγn − 1

=

xγ0 − 1
yγ0 − 1

.

For γn = 0, the above expressions are to be understood as log(x)/ log(y). A
subsequence argument then yields that (γn)n must be bounded, and a second sub-
sequence argument conﬁrms that γn → γ0 as n → ∞. Combine this convergence
relation with (C.1) and use the identity Qn(p; γn, 0, σn) = σn Q(p; γn, 0, 1) to con-
clude that σn → σ0 as n → ∞.
(cid:3)

Acknowledgments

Part of A. Sabourin’s work has been funded by the ‘AGREED’ project from
the PEPS JCJC program (INS2I, CNRS) and by the chair ‘Machine Learning
for Big Data’ from T´el´ecom ParisTech. J. Segers gratefully acknowledges funding
by contract “Projet d’Actions de Recherche Concert´ees” No. 12/17-045 of the
“Communaut´e fran¸caise de Belgique” and by IAP research network Grant P7/06
of the Belgian government (Belgian Science Policy).

References

Beer, G. (1993). Topologies on Closed and Closed Convex Sets, volume 268 of Mathe-

matics and its Applications. Kluwer Academic Publishers Group, Dordrecht.

Davison, A. C. and Gholamrezaee, M. M. (2012). Geostatistics of extremes. Pro-
ceedings of the Royal Society A: Mathematical, Physical and Engineering Science,
468(2138):581–608.

Gin´e, E., Hahn, M. G., and Vatan, P. (1990). Max-inﬁnitely divisible and max-stable

sample continuous processes. Probability theory and related ﬁelds, 87(2):139–165.

Huser, R. and Davison, A. C. (2014). Space–time modelling of extreme events. Journal

of the Royal Statistical Society: Series B (Statistical Methodology), 76(2):439–461.

Molchanov, I. (2005). Theory of Random Sets. Probability and its Applications (New

York). Springer-Verlag London, Ltd., London.

Norberg, T. (1987). Semicontinuous processes in multi-dimensional extreme value theory.

Stochastic Processes and Their Applications, 25:27–55.

Resnick, S. I. (1987). Extreme Values, Regular Variation, and Point Processes. Springer-

Verlag, New York.

Resnick, S. I. and Roy, R. (1991). Random usc functions, max-stable processes and

continuous choice. The Annals of Applied Probability, pages 267–292.

26

A. SABOURIN AND J. SEGERS

R¨uschendorf, L. (2009). On the distributional transform, Sklar’s theorem, and the em-
pirical copula process. Journal of Statistical Planning and Inference, 139:3921–3927.
Salinetti, G. and Wets, R. J.-B. (1986). On the convergence in distribution of measurable
multifunctions (random sets) normal integrands, stochastic processes and stochastic
inﬁma. Mathematics of Operations Research, 11(3):385–419.

Schlather, M. (2002). Models for stationary max-stable random ﬁelds. Extremes, 5(1):33–

44.

Sklar, M. (1959). Fonctions de r´epartition `a n dimensions et leurs marges. Publ. Inst.

Statist. Univ. Paris, 8:229–231.

(A. Sabourin) LTCI, CNRS, T´el´ecom ParisTech, Universit´e Paris-Saclay, 75013,

Paris, France

(J. Segers) Universit´e catholique de Louvain, Institut de statistique, biostatis-
tique et sciences actuarielles, Voie du Roman Pays 20, B-1348 Louvain-la-Neuve,
Belgium.

