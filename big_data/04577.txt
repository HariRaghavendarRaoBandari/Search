Generated using version 3.0 of the oﬃcial AMS LATEX template

An Ensemble 4D Seismic History Matching Framework with

Sparse Representation Based on Wavelet Multiresolution Analysis

Xiaodong Luo ∗

International Research Institute Of Stavanger (IRIS), Bergen, Norway

Tuhin Bhakta

International Research Institute Of Stavanger (IRIS), Bergen, Norway

Morten Jakobsen

University of Bergen, and International Research Institute Of Stavanger (IRIS), Bergen, Norway

Geir Nævdal

International Research Institute Of Stavanger (IRIS), Bergen, Norway

∗Corresponding author address: International Research Institute Of Stavanger (IRIS), Thormøhlens Gate

55, 5008 Bergen, Norway

E-mail: xiaodong.luo@iris.no

1

6
1
0
2

 
r
a

 

M
5
1
 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
7
7
5
4
0

.

3
0
6
1
:
v
i
X
r
a

ABSTRACT

In this work we propose an ensemble 4D seismic history matching framework for reservoir

characterization. Compared to similar existing frameworks in reservoir engineering com-

munity, the proposed one consists of some relatively new ingredients, in terms of the type

of seismic data in choice, wavelet multiresolution analysis for the chosen seismic data and

related data noise estimation, and the use of recently developed iterative ensemble history

matching algorithms.

Typical seismic data used for history matching, such as acoustic impedance, are inverted

quantities, whereas extra uncertainties may arise during the inversion processes.

In the

proposed framework we avoid such intermediate inversion processes. In addition, we also

adopt wavelet-based sparse representation to reduce data size. Concretely, we use intercept

and gradient attributes derived from amplitude versus angle (AVA) data, apply multilevel

discrete wavelet transforms (DWT) to attribute data, and estimate noise level of resulting

wavelet coeﬃcients. We then select the wavelet coeﬃcients above a certain threshold value,

and history-match these leading wavelet coeﬃcients using an iterative ensemble smoother.

As a proof-of-concept study, we apply the proposed framework to a 2D synthetic case

originated from a 3D Norne ﬁeld model. The reservoir model variables to be estimated

are permeability (PERMX) and porosity (PORO) at each active gridblock. A rock physics

model is used to calculate seismic parameters (velocity and density) from reservoir properties

(porosity, ﬂuid saturation and pressure), then reﬂection coeﬃcients are generated using a

linearized AVA equation that involves velocity and density. AVA data are obtained by

computing the convolution between reﬂection coeﬃcients and a Ricker wavelet function. The

multiresolution analysis applied to the AVA attributes helps to obtain a good estimation of

1

noise level and substantially reduce the data size. We compare history matching performance

in three scenarios: (S1) with production data only, (S2) with seismic data only, and (S3)

with both production and seismic data. In either scenario S2 or S3, we also inspect two

sets of experiments, one using the original seismic data (full-data experiment) and the other

adopting sparse representations (sparse-data experiment). Our numerical results suggest

that, in this particular case study, using production data largely improves the estimation

of permeability, but has little eﬀect on the estimation of porosity. Using seismic data only

improves the estimation of porosity, but not that of permeability. In contrast, using both

production and 4D seismic data improves the estimation accuracies of both porosity and

permeability. Moreover, in either scenario S2 or S3, provided that a certain stopping criterion

is equipped in the iterative ensemble smoother, adopting sparse representations results in

better history matching performance than using the original data set.

1. Introduction

History matching is an inverse problem that aims to ﬁnd reservoir model variables (e.g., per-

meabilities and porosities at gridblocks) that match observations (Oliver and Chen 2010).

With the advance of computer power, automatic history matching gains popularity in the

community. At the early stage, a lot of eﬀorts were dedicated to gradient-based deterministic

methods (see, for example, Chen et al. 1974; Dadashpour et al. 2008). In a gradient-based

deterministic method, one solves a certain deterministic optimization problem and obtains

a single set of estimated reservoir model variables. Although gradient-based deterministic

methods often work well in both research and practice, there are also a few noticed limita-

2

tions.

One practical limitation is the need to evaluate the Jacobian matrix of observations with

respect to model variables. Such an evaluation can be done through either a numerical

scheme (e.g., ﬁnite diﬀerence approximation, see, for example, Dadashpour et al. 2008) or

an adjoint-based system (see, for example, Chen et al. 1974). Using a numerical scheme

requires to store the Jacobian matrix in memory, therefore it is eﬃcient when the numbers

of both model variables and observations are relatively small. Adopting an adjoint-based

approach can mitigate the intensive demand of storage memory from large models, however,

it is typically time-consuming to develop an adjoint system. Flexibility of adjoint-based

approaches is another hurdle in practice. For instance, one cannot build an adjoint system

for a black-box reservoir simulator. In addition, should either observations or model variables

be changed, the corresponding adjoint system may need to be re-built.

Another limitation is the capacity of quantifying the uncertainty associated with inver-

sion results. Such a quantiﬁcation is essential for better decision-making in reservoir opera-

tions and management. In terms of uncertainty quantiﬁcation, gradient-based deterministic

methods appear less competent by nature, since they are mostly developed in the context of

deterministic inverse problems (see, for example, Engl et al. 2000). Although it is possible to

relate a gradient-based deterministic method to a stochastic approach, e.g., in the context of

Bayesian inverse problems (see, for example, Tarantola 2005), this connection is established

by conﬁning the distributions of model variables and observations to some speciﬁc choices

(e.g., Gaussian distribution), which may not always be valid in practice.

In recent years, ensemble-based history matching methods, for instance, the ensemble

Kalman ﬁlter (EnKF, see, for example, Nævdal et al. 2005; Aanonsen et al. 2009), the

3

ensemble smoother (ES, see, for example, Van Leeuwen and Evensen 1996), the ensemble

Kalman smoother (EnKS, see, for example, Evensen and van Leeuwen 2000) and their itera-

tive versions (see, for example, Chen and Oliver 2013; Emerick and Reynolds 2012a; Gu and

Oliver 2007; Li and Reynolds 2009; Luo et al. 2015), have received a lot of attention in the

community. In contrast to gradient-based deterministic methods, advantages of ensemble-

based approaches include simplicity and ﬂexibility in implementation, and better capacity of

uncertainty quantiﬁcation. Ensemble-based methods are derivative-free in that they do not

evaluate Jacobian matrices in their implementations. They are also non-intrusive approaches

and can work with generic forward simulators (including black-box systems). Having these

two features (derivative-free and non-intrusive), ensemble-based methods emerge as a conve-

nient toolset for history matching and can be adopted in various situations that may involve

reservoir models with diﬀerent sizes, and diﬀerent types of model parameterization and/or

observation data (see, for example, Aanonsen et al. 2009). In addition, ensemble-based meth-

ods can be interpreted as stochastic versions of gradient-based deterministic approaches, and

under suitable conditions, they are Bayesian approaches, regardless of the statistical distribu-

tions of model variables and observations (see, for example, the analysis in Luo et al. 2015).

This forms the ground of uncertainty quantiﬁcation in the context of Bayesian inversion.

In history matching problems it is customary to assimilate production data (e.g., bottom

hole pressures, oil production rates, water cuts etc.) into reservoir models. Production data

are often frequent in time, but have relatively sparse coverage in space. Complementary

to production data, 4D (or time-lapse) seismic data are usually denser in space, and thus

provide valuable additional information for history matching. Seismic history matching using

ensemble-based methods has been carried out in some recent works. For instance, Abadpour

4

et al. (2013); Fahimuddin et al. (2010); Katterbauer et al. (2015); Leeuwenburgh and Arts

(2014); Skjervheim et al. (2007); Trani et al. (2012) use the EnKF or a combination of the

EnKF and EnKS, whereas Emerick and Reynolds (2012b); Emerick et al. (2013) employ the

ensemble smoother with multiple data assimilation (ES-MDA). To reduce the computational

cost in forward simulations, most of seismic history matching studies adopt inverted seismic

properties that are obtained through seismic inversions. Such inverted properties can be, for

instance, acoustic impedance (see, for example, Emerick and Reynolds 2012b; Emerick et al.

2013; Fahimuddin et al. 2010; Skjervheim et al. 2007) or saturation front (see, for example,

Abadpour et al. 2013; Leeuwenburgh and Arts 2014; Trani et al. 2012). One issue in using

inverted seismic properties is that, there may not be associated uncertainty quantiﬁcation,

as inverted seismic properties are often obtained using deterministic inversion algorithms.

Another issue, which is present in either direct or inverted seismic data, is the “big data”

problem, due to spatially dense distributions of seismic data. As discussed in Aanonsen

et al. (2009); Emerick and Reynolds (2012b), in ensemble-based methods large data size

may lead to some numerical problems, e.g., ensemble collapse and high computational cost

in computing Kalman gain matrices. Apart from these, many history matching algorithms

are developed for under-determined inverse problems, whereas a large data size may make

the inverse problem become over-determined instead. This may thus aﬀect the performance

of history matching algorithms, as will be shown in the numerical example later. As a result,

certain procedures (e.g., local analysis, sparse representation) may need to be adopted to

tackle the aforementioned problems.

In this work we propose an ensemble-based 4D seismic history matching framework with

sparse representation based on wavelet multiresolution analysis. Compared to similar exist-

5

ing frameworks (see, for example, Emerick and Reynolds 2012b; Emerick et al. 2013; Gosselin

et al. 2003; Skjervheim et al. 2007), our proposed one has some relatively new ingredients, in

terms of the type of seismic data, wavelet multiresolution analysis for sparse representation

and related noise estimation, and the use of a recently developed iterative ensemble smoother

based on a regularized inversion algorithm (Luo et al. 2015). The seismic data we used are

intercept and gradient attributes of amplitude versus angle (AVA). These two AVA attributes

are processed data that are transformed from raw seismic data but without involving any

inversion, therefore they avoid uncertainty associated with the inversion process. Wavelet

multiresolution analysis is proposed for the following two purposes: one is to reduce the size

of seismic data by exploiting the sparse representation nature of wavelet basis functions, and

the other is to exploit its capacity of noise estimation in the wavelet domain (Donoho and

Johnstone 1995).

This work is organized as follows. First we introduce the ingredients that comprise the

proposed framework, including forward simulation of AVA attributes, sparse representation

and noise estimation in the wavelet domain, and the iterative ensemble history matching

algorithm. As a proof-of-concept study, we adopt a 2D synthetic case, which is originated

from a 3D Norne ﬁeld model, to demonstrate the performance of the proposed framework in

various situations. Finally, we conclude the work and discuss some possible future work on

top of current investigations.

6

2. The proposed ensemble 4D seismic history matching

framework

a. Forward modeling of AVA attributes

As indicated in Figure 1, the forward modeling of AVA attributes involves a few steps.

First we use petro-physical parameters (e.g., permeability and porosity) to generate pore

pressure and ﬂuid saturations through reservoir ﬂow simulation. Then we adopt a petro-

elastic model (PEM) to link pore pressure and ﬂuid saturations to P- and S-wave velocities

and formation density. Finally we employ a certain AVA equation to compute intercept and

gradient attributes.

The changes in pressure and ﬂuid saturations within a reservoir may have signiﬁcant ef-

fects on seismic parameters (such as P-wave velocity, S-wave velocity and density) (Domenico

1974; Nur 1989). The rock-physics analysis provides the link between seismic and reservoir

parameters. Building a proper PEM is therefore very crucial, whereas it is challenging at the

same time. To interpret the changes observed in seismic response over the time, a thorough

knowledge of rock and ﬂuid properties is required (Jack 2001). For example, the P-wave ve-

locity can be linked with the ﬂuid saturation change using the Gassmann model (Gassmann

1951), whereas the Hertz-Mindlin model (Mindlin 1949) can be used as a link between the

P-wave velocity and the eﬀective stress change. By combining the Gassmann model and the

Hertz-Mindlin model, we can then express the changes in seismic parameters in terms of the

changes in ﬂuid-saturation and pore-pressure.

Here, in this study the above mentioned rock-physics models are used. The Hertz-

7

Mindlin model (Mindlin 1949) is used to estimate eﬀective dry moduli of the reservoir rock

as a function of eﬀective stress. The eﬀective bulk modulus (Kd) and shear modulus (µd) of

a dry random packing of identical spheres is given by (Mindlin 1949)

(cid:115)

Kd = n

s

p (1 − φ)2µ2
C 2
18π2(1 − νs)2 Pef f ,
(cid:115)

p (1 − φ)2µ2
3C 2
2π2(1 − νs)2 Pef f ,

s

and

µd =

5 − 4νs
5(2 − νs)

n

(1)

(2)

where µs, νs, Pef f are grain shear modulus, Poisson’s ratio, and eﬀective stress, respectively.

The coordination number Cp denotes the average number of contacts per sphere and n is

the degree of root. For perfect, identical-sphere packing n is equal to 3. For a better ﬁt of

real data we need to adjust between Cp and n. In this study, n equals to 5, and this is the

same as that in the previous work (Dadashpour 2009).

The above equations can be further simpliﬁed as a function of eﬀective stress Pef f , namely,

Kd ∝ µd ∝ P

1
n

ef f ,

(3)

if other parameters remain unchanged over time. Therefore, we can calculate new dry

eﬀective bulk and shear moduli at new eﬀective stress if we know the initial eﬀective stress

and initial dry frame moduli (Kd and µd). Here, we use the same values of initial Kd and µd

as in Dadashpour (2009). Once the pressure eﬀect is modeled for each reservoir grid block,

the saturation eﬀect can be estimated by using the Gassmann model (Gassmann 1951).

Saturated bulk (Ksat) and shear moduli (µsat) can be expressed as

(1 − Kd
+ 1−φ

Ks

Ks

)2
− Kd

K2
s

Ksat = Kd +

φ
Kf

8

,

(4)

and

µsat = µd ,

(5)

where Kd, µd, Ks, Kf , φ are dry/frame bulk modulus, dry/frame shear modulus, solid/mineral

bulk modulus, eﬀective ﬂuid bulk modulus, and porosity, respectively. Here, the eﬀective

ﬂuid bulk modulus (Kf ) is estimated by using the Reuss average (Reuss 1929). Kf for three

phase ﬂuid mixture is given by

Kf = (

Sw
Kw

+

So
Ko

+

)−1 ,

Sg
Kg

(6)

where Kw, Ko, Kg, Sw, So and Sg are bulk modulus of water/brine, bulk modulus of oil,

bulk modulus of gas, saturation of water/brine, saturation of oil and saturation of gas,

respectively.

Further, the saturated density (Mavko et al. 2009) can be written as (for three phase

ﬂuid)

ρsat = (1 − φ)ρm + φSwρw + φSoρo + φSgρg ,

(7)

where ρsat, ρm, ρw, ρo and ρg are saturated density of rock, mineral density, water/brine

density, oil density and gas density, respectively. In this study Sw, So and Sg are obtained

from reservoir ﬂow simulation.

Using the above equations we can obtain P- and S-wave velocities, which can be expressed

as (Mavko et al. 2009)

VP =

and

(cid:115)

3µsat

Ksat + 4
ρsat

,

(8)

(9)

VS =

,

(cid:114)µsat

ρsat

9

where VP and VS are P- and S-wave velocities, respectively.

Once the seismic parameters are estimated as a function of reservoir parameters by using

the PEM, we can then generate synthetic seismogram based on these seismic parameters.

Here, we exploit the amplitude versus angle (AVA) relation by using the linearized AVA

equation (Smith and Gidlow 1987). For a two-layer model where the reservoir layer is below

an overburden layer, the P-wave reﬂectivity (Rpp) can be expressed as (Smith and Gidlow

1987)

Rpp(θ) =

1
2

(

∆ρ
ρ

+

∆α
α

) − 2β2
α2 (

∆ρ
ρ

+

2∆β

β

) sin2 θ +

∆α
2α

tan2 θ

(10)

2(α1 + α2), β = 1

2(β1 + β2) and ρ = 1

where, α = 1
2(ρ1 + ρ2) represent average P-wave velocity,
S-wave velocity and density, between overburden and reservoir layers; and ∆α = α2 − α1,
∆β = β2 − β1 and ∆ρ = ρ2 − ρ1 are lithological contrasts in P-wave velocity, S-wave velocity

and density, respectively, between overburden and reservoir layers. α1, β1 and ρ1 are the P-

wave velocity, S-wave velocity and density of the overburden, respectively. Similarly, α2, β2

and ρ2 are the P-wave velocity, S-wave velocity and density of the reservoir, respectively. θ is

the incidence angle. Eq. (10) is the linearized version of the exact reﬂectivity equation, i.e.,

the Zoeppritz’s equation. The ﬁrst term in Eq. (10) expresses the zero-oﬀset reﬂectivity,

whereas the other two terms include the oﬀset dependency in reﬂectivity. This equation

works reasonably well for small incident angles (up to 30◦) and small contrast between the

layers. Now, considering the conventional AVO formula, R = R0 + G sin2 θ and assuming
tan2 θ ≈ sin2 θ, then Eq. 10 can be further simpliﬁed and split into two terms (R0 and G)

as (Landrø 2001)

R0 =

1
2

(

∆ρ
ρ

+

∆α
α

)

10

(11)

and

G = −2β2
α2 (

∆ρ
ρ

+

2∆β

β

) +

∆α
2α

(12)

Here, R0 and G are intercept and gradient AVA attributes. For multi-layer cases, we need

to calculate intercept and gradient reﬂectivity series as a function of two-way travel time

(see, for example, Buland and Omre 2003). Here, travel time is computed from the P-wave

velocity and vertical thickness of each grid block. Further, we convolve the reﬂectivity series

with a Ricker wavelet of 30 Hz dominant frequency to obtain the seismic AVA attributes

(here R0 and G).

b. Sparse representation of seismic data and noise estimation through wavelet multiresolu-

tion analysis

Let mref ∈ Rm denote the reference reservoir model. To simplify the discussions below,
it is assumed that the AVA attributes are 2D data and saved in the form of p1 × p2 matrices,
such that the forward simulator of AVA attributes g : Rm → Rp1×p2. The observed AVA

attributes do are supposed to be contaminated by some additive noise , such that

do = g(mref ) +  .

(13)

It is further assumed that, for a given AVA attribute (intercept or gradient), the elements

of  are independently and identically distributed (i.i.d) Gaussian white noise, with zero

mean but unknown variance σ2, where σ will be estimated through wavelet multiresolution

analysis below.

For the purpose of reservoir characterization, we aim to ﬁnd an estimate ˆm of mref based

on the observation do. The observation system Eq. (13) suﬃces for this purpose from the

11

algorithmic perspective. However, as aforementioned, certain numerical issues may arise due

to the large data size. To mitigate this problem, one feasible strategy is to employ sparse

representation by transforming the data into a diﬀerent domain, such that the main features

of the original data are kept in relatively few, but dominant components in the transform

domain. An illustration example in this aspect is the low-rank representation of a matrix

through a truncated singular value decomposition (TSVD), in which the original matrix is

approximated by the summation of the products of left and right singular vectors associated

with the singular values above a certain threshold (see, for example, Chen and Oliver 2013;

Luo et al. 2015; Luo and Moroz 2009). In the TSVD example, the singular values can be

interpreted as a representation of the matrix, and the set of the products of left and right

singular vectors comprises the basis functions of the transform domain. Sparse representation

is achieved by keeping leading singular values above a certain threshold, whereas setting those

below the threshold value to zero.

One feature of TSVD is that its singular vectors are data-dependent. This is not desir-

able for our purpose, since history matching involves a comparison between observed and

simulated data. Given diﬀerent singular vectors (hence basis functions), it is not sensible

to compare representations (truncated singular values) of observed and simulated data from

diﬀerent transform domains. To avoid this problem, one of the alternatives is to adopt a dis-

crete wavelet transform (DWT), in which wavelet basis functions are independent of data.

Wavelet-based multiresolution analysis is already used in many works in the community.

For instance, it is adopted in Awotunde (2014); Chen and Oliver (2012); Gentilhomme et al.

(2015); Sahni and Horne (2005) for sparse (or multiscale) representations of reservoir models.

It is also used in Awotunde (2014) for sparse representation of time-lapse saturation maps.

12

However, it seems that Awotunde (2014) does not consider how to estimate the variance of

noise of the transformed data (i.e., wavelet coeﬃcients), which is an issue to be addressed

later.

Figure 2 indicates a similar workﬂow of sparse representation of seismic data through

DWT. Given a set of seismic data, one ﬁrst applies a multilevel DWT to the data. For

a chosen family of wavelet basis functions, the data are represented by the corresponding

wavelet coeﬃcients. For the purpose of sparse representation, one nice feature of wavelet

transform is that, in many cases (e.g., when dealing with noisy signals with structures),

small wavelet coeﬃcients are dominated by noise, while large coeﬃcients mainly carry signal

information (Jansen 2012). Similar to TSVD, sparse representation can be achieved by only

keeping the wavelet coeﬃcients above a certain threshold, while setting those below the
threshold value to zero. Let W and T denote wavelet transform and thresholding operators,

respectively, then after DWT and thresholding, the eﬀective observation system becomes

T ◦ W(do) = T ◦ W ◦ g(mref ) + T ◦ W() .

(14)

For succinctness, an introduction to wavelet theory is omitted here. Interested readers are

referred to, for example, Mallat (2008). For our purpose, we need to adopt a 2D orthogonal

wavelet transform for sparse representation and noise estimation of AVA attributes. The
if W is orthogonal, then

orthogonality requirement is based on the following observation:

the wavelet transform preserves the energy of Gaussian white noise. In addition, similar to

the power spectral distribution of white noise in frequency domain (e.g., as in the situation

of Fourier transform), the noise energy in the wavelet domain is uniformly distributed among

all wavelet coeﬃcients (Jansen 2012). This implies that, if one can estimate the noise level

13

of small wavelet coeﬃcients, then this estimation can also be used to infer the noise level of

leading coeﬃcients used in history matching.

Figure 3 illustrates wavelet multiresolution analysis through a three-level 2D wavelet

decomposition. At each level (say, level j for j = 1, 2, 3) of decomposition, one obtains four

sub-bands of wavelet coeﬃcients, namely, LLj (upper left), HLj (upper right), LHj (lower

left) and HHj (lower right). Here LLj (HHj, respectively) is obtained by applying low-

pass (high-pass, respectively) ﬁlters to the data corresponding to the sub-band LLj−1, along

both horizontal and vertical directions (Jansen 2012) (LL0 corresponding to the original

noisy data itself), whereas HLj (LHj, respectively) is attained by ﬁrst applying a high-pass

ﬁlter along the vertical (horizontal, respectively) direction, then a low-pass ﬁlter along the

horizontal (vertical, respectively) direction. As a result, to estimate the standard deviation

(std) σ of white noise, it is customary to use the sub-band HH1, since it is dominated by
high-frequency components that typically correspond to noise. Concretely, let ˜do = W(do)

be the whole set of wavelet coeﬃcients corresponding to do, and ˜do

HH1 those of the sub-band

HH1. In case of Gaussian white noise, the std σ of noise can be estimated using the median

absolute deviation (MAD) estimator (Donoho and Johnstone 1995):

σ =

median(abs(˜do

HH1))

0.6745

,

(15)

where abs(•) is an element-wise operator, and takes the absolute value of an input vector.

For colored noise, one may apply Eq. (15) on a level-dependent basis, see, for example,

the discussion in Johnstone and Silverman (1997). After estimating σ in an n-level wavelet

decomposition, we apply hard thresholding and select leading wavelet coeﬃcients in HHj,

14

HLj and LHj (j = 1, 2,··· , n) sub-bands in a way such that



T (˜do) =

0

˜do

if ˜do ∈ {HHj, HLj, LHj|1 ≤ j ≤ n} and ˜do < λ ,

(16)

otherwise ,

whereas in the current study the coeﬃcients in the LLn sub-band are not modiﬁed, in light

of the assumption that the LLn sub-band is dominated by low-frequency components which

correspond to signals. The threshold value λ is selected using the universal rule (Donoho

and Johnstone 1994)

λ =(cid:112)2 ln(#do) σ ,

(17)

with #do being the number of elements in do. Since we use leading wavelet coeﬃcients in

HHj, HLj and LHj sub-bands and those in LLn for history matching, the corresponding

observation system becomes

˜do = W ◦ g(mref ) + W() , for ˜do ≥ λ or do ∈ LLn ,

(18)

where ˜do is a vector containing all selected wavelet coeﬃcients, and W() the corresponding

noise component in the wavelet domain, with zero mean and covariance C˜do = σ2I (here I

is the identity matrix with a suitable dimension).

We use an example to illustrate the performance of sparse representation and noise esti-

mation through wavelet multiresolution analysis. In the example, we ﬁrst generate reference

intercept data (see Figure 4(a)) using the forward AVA attribute simulator, and then add

some Gaussian white noise to obtain the noisy intercept data in Figure 4(b). In this case,
the size of intercept data is 251 × 31 = 7781, and the noise level is 30%. Here, noise level is

deﬁned as:

Noise level =

variance of noise

variance of pure signal

.

(19)

15

We apply a three-level DWT to the noisy data using Daubechies wavelets with two vanishing

moments (Mallat 2008), and use hard thresholding combined with the universal rule (Eqs.

(15) – (17)) to select leading wavelet coeﬃcients. After thresholding, the number of leading

wavelet coeﬃcients becomes 581, only 7.5% of the original data size. In addition, by applying

Eq. (15), we have the estimated std of noise to be 0.0141, which is very close to the true

noise std 0.0148 (we have also applied the same wavelet multiresolution analysis procedure to

data with diﬀerent attribute (gradient) and noise levels (0% and 10%), and attained similar

results). By applying an inverse DWT to the thresholded wavelet coeﬃcients, we obtain the

reconstructed intercept data as shown in Figure 4(c). Comparing the ﬁgures in Figure 4,

we see that the reconstructed data capture the main features of the reference data, whereas

substantially remove the noise components (in fact, thresholding is a standard procedure

used in wavelet-based denoising algorithms, for example, see Donoho and Johnstone 1995,

1994; Jansen 2012).

For further illustrations, Figures 5 and 6 show wavelet coeﬃcients associated with the

reference, noisy and reconstructed attributes, and reference and estimated noise, respectively.

As one can see, after applying thresholding to wavelet coeﬃcients of noisy data (Figure 5(b)),

the modiﬁed coeﬃcients (Figure 5(c)) preserve those with large amplitudes. In general, the

modiﬁed coeﬃcients appear similar to those of reference data, but lose some details in some

places with small coeﬃcients (e.g., for indices larger than 8000). Accordingly, in Figure 6

we see that, to some extent, the estimated noise (Figure 6(b)) looks similar to the reference

noise (Figure 6(a)), although there is some “signal leakage” into the estimated noise (Figure

6(c)) due to the fact that some small wavelet coeﬃcients of the reference data are smeared

out in the course of thresholding.

16

c. The ensemble history matching algorithm

A popular ensemble-based method for reservoir history matching is the EnKF (see, for

example, Nævdal et al. 2005; Aanonsen et al. 2009). Recently, the ES (see, for example,

Skjervheim and Evensen 2011) and iterative ES (iES) (see, for example, Chen and Oliver

2013; Emerick and Reynolds 2012b; Luo et al. 2015) have also attracted attention in the

community. Compared to the EnKF, the ES and iES have certain technical advantages in

terms of algorithm implementation and execution, see, for example, the discussions in Luo

et al. (2015); Skjervheim and Evensen (2011).

In this work we use the iES in Luo et al. (2015) for seismic history matching, whereas

other iES variants may serve the same purpose. We provide a short introduction to the chosen

iES, and pay special attention to one of the stopping criteria associated with this iES. The

stopping criterion to be discussed below has a substantial impact on history matching results

of the numerical example in this work.

Similar to Eq. (13), but without loss of generality, let do denote p-dimensional obser-

vations in history matching, which may represent values in the ordinary data space (e.g.,

2D AVA attributes by reshaping matrices into vectors), or their sparse representation in the

transform domain (e.g., leading wavelet coeﬃcients). Here do is assumed to be contaminated

by certain observation errors with zero mean and covariance Cd. Also suppose that g is the

forward simulator that takes an m-dimensional reservoir model m as the input and outputs
simulated observations d ≡ g(m). In the context of iES, let Mi ≡ {mi

j}Ne
j=1 be an ensemble

of Ne reservoir models obtained at the ith iteration step, then the iES aims to update Mi to
a new ensemble Mi+1 ≡ {mi+1

j=1 by solving an optimization problem, which is discussed

j }Ne

17

below. For convenience, we call Si

m, which is deﬁned as

(cid:2)mi

Si

m =

1√
Ne − 1

1 − ¯mi,··· , mi

Ne − ¯mi(cid:3) ;

Ne(cid:88)

j=1

¯mi =

1
Ne

mi
j ,

(20)

a model square root matrix in the sense that Ci

m ≡ Si

m (Si

m)T equals the sample covariance

matrix of the ensemble Mi. Similarly, we call Si

d, which is deﬁned as

(cid:2)g(mi

Si

d =

1√
Ne − 1

1) − g( ¯mi),··· , g(mi

Ne) − g( ¯mi)(cid:3) ,

(21)

a data square root matrix with respect to the ensemble Mi.

Given Mi, a new ensemble Mi+1 is obtained by solving the following minimum-average-

cost (MAC) problem

argmin
{mi+1
}Ne

j

j=1

Ne(cid:88)

j=1

1
Ne

(cid:104)(cid:0)do
j − g(cid:0)mi+1
+γi(cid:0)mi+1

j

j − mi

j

(cid:1)(cid:1)T C−1
(cid:0)do
j − g(cid:0)mi+1
(cid:1)T(cid:0)Ci
(cid:1)−1(cid:0)mi+1

(cid:1)(cid:1)
j − mi

m

d

j

j

(22)

(cid:1)(cid:105)

,

where do

j (j = 1, 2,··· , Ne) are perturbations of do generated by drawing Ne samples from

the normal distribution N (do, Cd), and γi a positive scalar adaptive with iteration step

(which is automatically chosen using a procedure similar to back-tracking line search in

Luo et al. 2015). Through linearization, one obtains an approximate solution to the MAC

problem as follows:

d)T(cid:0)Si

(cid:1)−1(cid:0)do

j − g(cid:0)mi

j

(cid:1)(cid:1) , for j = 1, 2,··· , Ne . (23)

mi+1

j = mi

j + Si

m(Si

d(Si

d)T + γi Cd

As discussed in Luo et al. (2015), the iES using Eq. (23) corresponds to an ensemble im-

plementation of the regularized Levenburg-Marquardt method (Jin 2010)) for inverse prob-

lems. For this reason, this iES is called regularized Levenburg-Marquardt method for the

minimum-average-cost problem (RLM-MAC in short).

18

Numerous studies (see, for example, Engl et al. 2000) indicate that the stopping criterion

is crucial for the performance of an iterative inversion algorithm. In practice, an iteration

process should stop after reaching moderate data mismatch that is neither too large nor too

small, whereas the latter requirement is imposed to avoid over-ﬁtting observations in the

presence of noise (Engl et al. 2000). Let

(cid:104)(cid:0)do
j − g(cid:0)mi

j

(cid:1)(cid:1)T C−1

d

j − g(cid:0)mi
(cid:0)do

j

(cid:1)(cid:1)(cid:105)

(24)

Ne(cid:88)

j=1

Ξi ≡ 1
Ne

be the average (normalized) data mismatch with respect to the ensemble Mi, then following

Proposition 6.3 of Engl et al. (2000), we stop the iteration in Eq. (23) when

Ξi < 4p

(25)

for the ﬁrst time, where p is the number of observations, and the factor 4 is a critical value

below which the iteration process starts to transit from convergence to divergence (Engl et al.

2000, p.158). Note that this critical value is proven on top of the assumption that the noise

level is precisely known, therefore to apply the stopping criterion (25) in practice, it requires

a good estimation of noise level. In addition, using the critical value 4 is only a choice for

robustness, and it does not guarantee the optimality in terms of estimation accuracy. As a

result, in some cases it is possible that one may obtain better inversion results in terms of,

for example, root mean square error (RMSE), by using a factor less than 4. Finally, many

inversion algorithms (including RLM) are developed for under-determined inverse problems,

in which the numbers p of observations are less than the model sizes m. Given a large amount

of seismic data, however, the history matching problem may become over-determined instead,

and this could aﬀect the performance of history matching algorithms to some extent.

19

3. A numerical example

a. Experimental settings

We use a 2D synthetic model for a proof-of-concept study. This reservoir model consists

of three phases (water, oil and gas), and is a vertical section of a 3D Norne ﬁeld model. This

2D model has 26 layers, with 39 gridblocks at each layer. Thus there are 1014 gridblocks

overall, whereas 739 of them are active cells. This reservoir model was previously used

in Dadashpour et al. (2008). The petro-physical properties to be estimated include the

isotropic permeability ﬁeld and the porosity ﬁeld, whereas other parameters, e.g., z-direction

transmissibility multiplier (MULTZ) and relative permeability curves, are assumed to be

known to us. Nevertheless, we do not have the reference permeability and porosity ﬁelds

used in Dadashpour et al. (2008). Therefore we create another reference model based on a

data ﬁle associated with the 3D Norne ﬁled. Figure 7 indicates the x-direction permeability

(PERMX) and porosity (PORO) of our reference model, and Table 1 summarizes some

critical information of the case study.

On average, the gridblock size of the reservoir is around 80 meters horizontally, and 5

meters vertically. There are one injection well (labelled as I1 in Figure 7) and one production

well (labelled as P1 in Figure 7). The completion of I1 is from layer 1 to layer 25, and that of

P1 is from layer 1 to layer 12. The production period is 3750 days, and there are 27 report

time instances from the ECLIPSE c(cid:13) 100 black-oil simulator. The bottom hole pressures

(BHP) from I1 and P1, and gas-oil ratio (GOR), oil production total (OPT) and water cut

(WCT) from P1 at each report time are used for history matching. So overall the size of
production data is 5 × 27 = 135. Gaussian white noise (with zero mean) is added to each

20

production data as the synthetic observation error. For BHP data, the standard deviations

of noise are 1 bar, and for GOR, OPT and WCT, the standard deviations are 10% of the

magnitudes of production data (and if the standard deviations are less than 10−6, they are

reset to 10−6 to avoid the numerical issue of division by zero). It is assumed that observations

errors between diﬀerent types of production data are uncorrelated, so that the corresponding

observation error covariance matrix is diagonal.

Seismic surveys are conducted at three time instances: day 0 (base survey), day 2040 (1st

monitor survey) and day 3750 (2nd monitor survey). The intercepts and gradients of AVA

data at all survey time are used as 4D seismic data. At each survey, the data size of each
AVA attribute is 7781, therefore the total number of seismic data is 3× 2× 7781 = 46686. In

history matching study, Gaussian white noise (with zero mean) is also added to each attribute

data, with the noise level (as deﬁned in Eq. (19)) being 30%. For the purpose of comparison,

we consider two sets of experiments. In one of them, the data to be history-matched are

the original attributes without any transform, therefore the observation size is 46686. In

addition, we assume that the standard deviations of observation noise are already known,

without involving any estimation method (such as the one in Eq. (15)). For distinction, we

call this full-data experiment. In the other set of experiment, we apply three-level 2D DWT

to all AVA attributes using Daubechies wavelets with two vanishing moments. We then select

leading wavelet coeﬃcients by adopting hard thresholding in combination with the universal

rule. These leading wavelet coeﬃcients are used as the data for history matching. In the

current case study, the total number of leading wavelet coeﬃcients is 2746, roughly 5.9%

of the original data size. For each attribute, Eq. (15) is applied to estimate the standard

deviation of observation noise. For distinction, we call this sparse-data experiment.

21

We consider three history matching scenarios, which involve: (S1) production data only;

(S2) 4D seismic data only; and (S3) both production and 4D seismic data, whereas in both

(S2) and (S3) we compare the results of full- and sparse-data experiments. The petro-

physical properties to be estimated are PERMX (in the scale of natural logarithm) and

PORO at active gridblocks. The initial ensemble of log PERMX and PORO are generated

using Gaussian random function simulation in PETREL c(cid:13). Log PERMX and PORO are

generated separately, using the same spherical variogram model whose horizontal range is

1901 meters and vertical one is 12.8 meters. In the course of generating log PERMX and

PORO realizations, the simulation processes are conditioned on synthetic well log data of

I1 and P1 generated from the reference reservoir model. The total number of realizations

(ensemble size) is 100.

RLM-MAC introduced in the proceeding section is used for all history matching scenarios.

Except for the aforementioned stopping criterion (25), we introduce two additional stopping

conditions for run-time control:

(C1) RLM-MAC stops if it reaches a maximum of 10 outer iteration steps;

(C2) RLM-MAC stops if the relative change of average data mismatch over two consecutive iteration steps is less than 0.01% .

For more information of the implementation of RLM-MAC, readers are referred to Luo et al.

(2015). To see the eﬀect of the stopping criterion (25), we also compare the estimation

results obtained by only invoking the stopping conditions (C1) and (C2) and those obtained

by invoking (C1), (C2) and the criterion (25).

22

b. Results of scenario S1 (using production data only)

In this case we only use production data in history matching. Figure 8 shows the boxplots

of data mismatch as a function of iteration step. At iteration 0, the average data mismatch of
the initial ensemble is 1.57× 105. If one only adopts the stopping conditions (C1) and (C2),

then RLM-MAC stops after 10 iterations, with the corresponding average data mismatch

being 202.12.

If the extra stopping criterion (25) is used, then RLM-MAC stops after

3 iterations, at which the average data mismatch is 402.19, lower than the critical value
4 × 135 = 540 (horizontal dashed line in Figure 8) for the ﬁrst time.

Figure 9 examines the RMSEs of log PERMX and PORO obtained at diﬀerent iteration

steps. Let vtr be the (cid:96)-dimensional true property, and ˆv an estimation of the truth, then in

this work RMSE ev of ˆv is deﬁned as follows:

(cid:107)ˆv − vtr(cid:107)2

(cid:96)

,

ev =

(26)

where (cid:107) • (cid:107)2 denotes the Euclidean norm. For both log PERMX and PORO, their RMSEs

decrease at the ﬁrst few iterations but rebound as iteration proceeds further. As a result,

the RMSEs at 10th iteration step tend to be higher than those of the initial ensemble. In

contrast, the RMSEs at the 3rd iteration step tend to be the lowest for both log PERMX and

PORO. This indicates the beneﬁt of equipping the stopping criterion (25) in this particular

case. A further remark is that, if one uses the ensemble at the 3rd iteration step as the ﬁnal

history-matched models, then compared to the initial ensemble, there appear to be more

changes in log PERMX than PORO. In other words, in this particular case production data

appear more sensitive to log PERMX than to PORO.

In the sequel we show production data proﬁles and distributions of log PERMX and

23

PORO with respect to the reference reservoir model, the initial and ﬁnal ensembles of reser-

voir models, respectively. Here, the ﬁnal ensemble is taken as the one from the 3rd iteration

step. Production data proﬁles are indicated in Figures 10 and 11. As one can see there, after

history matching, the ﬁnal ensemble has better predictions of production data and reduced

prediction spreads. This is consistent with the results in Figure 8.

Distributions of log PERMX and PORO are reported in Figures 12 and 13, respectively.

In each ﬁgure, we show the reference property in the ﬁrst row, then the mean and two sample

properties of the initial ensemble in the second row, and ﬁnally the mean and two sample

properties of the ﬁnal ensemble in the 3rd one. One can see diﬀerences between the means

(or samples) of the initial and ﬁnal ensembles. In this particular case, the changes in log

PERMX appear more substantial than those in PORO, consistent with the results in Figure

9.

c. Results of scenario S2 (using 4D seismic data only)

Here we consider the case in which only seismic data are used in history matching. As

aforementioned, we consider both full- and sparse-data experiments for the purpose of com-

parison. In the full-data experiment, the observations are noisy AVA intercepts (denoted

by R0) and gradients (denoted by G) at diﬀerent survey time (see Figure 14), whereas in

the sparse-data experiment, the observations are leading wavelet coeﬃcients of noisy AVA

attributes after thresholding. The data sizes of AVA attributes and the corresponding lead-

ing wavelet coeﬃcients are 46686 and 2746, respectively. Figure 15 indicates AVA attributes

reconstructed from inverse DWT. In these inverse transforms, we keep leading wavelet co-

24

eﬃcients while set the others to zero. Comparing Figures 14 and 15, it is clear that the

reconstructed attributes tend to capture the main features in the original data but remove

the noise components, and this is the rationale behind wavelet-based denoising algorithms

(see, for example, Jansen 2012; Donoho and Johnstone 1995, 1994).

Figure 16 shows boxplots of data mismatch as functions of iteration step in full- and

sparse-data experiments, respectively. In the full-data experiment (Figure 16(a)), data mis-
match is computed in the original data space. The initial average data mismatch is 1.72×108.

Using the stopping conditions (C1) and (C2), RLM-MAC stops after 10 iterations and at-
tains the ﬁnal average data mismatch of 1.19× 108. In this case, the ﬁnal value is above the
threshold 4× 46686 ≈ 1.87× 105, such that the extra stopping criterion (25) is not activated.

In contrast, in the sparse-data experiment (Figure 16(b)), data mismatch is calculated in
the wavelet domain. The initial average data mismatch is 1.46 × 104. By only adopting

the stopping conditions (C1) and (C2), RLM-MAC stops after 10 iterations, with the ﬁnal
average data mismatch being 9.82 × 103. Meanwhile, by applying the stopping criterion
(25), one has the threshold value 4 × 2746 ≈ 1.10 × 104 (corresponding to the horizontal

dashed line in Figure 16(b)), indicating that RLM-MAC should stop at the 2nd iteration

step instead.

In the full-data experiment, the number of attribute data is much larger than the number
of reservoir model variables to be estimated (which is 2 × 739 = 1478). This means that

history matching is an over-determined inverse problem, thus some of the observations might

not be matched well. As a result, the initial average data mismatch per observation, which

is deﬁned as the ratio of average data mismatch to the number of observations, appears very

large (in the order of 103), and RLM-MAC cannot help reduce this ratio very much because

25

of the nature of “over-determinedness” in the inverse problem (In contrast, in scenario S1,

the number of production data is less than the size of reservoir model, therefore history

matching is an under-determined inverse problem, and RLM-MAC substantially reduces

data mismatch, despite the high initial average data mismatch per observation, also in the

order of 103). Through sparse representation, the size of observations is signiﬁcantly reduced,

although it is still larger than the size of reservoir model. By only comparing leading wavelet

coeﬃcients of observed and simulated AVA attributes, the initial average data mismatch per

observation becomes much lower (around 5.32), and through iteration, RLM-MAC reduces

this ratio further to some values below 4, such that the stopping criterion (25) can be

triggered.

Figure 17 shows RMSEs of log PERMX and PORO as functions of iteration step. In all

cases, the RMSEs exhibit U-turn behaviour and their values tend to decrease at the ﬁrst few

iteration steps and then arise. According to Figure 16, if using the stopping conditions (C1)

and (C2) only, one would take the ensembles at the 10th iteration steps as the ﬁnal results.

This leads to almost the worst estimation (except for PORO in Figure 17(b)), in terms of

RMSE, among all possible choices of the ﬁnal ensembles. By adopting the extra stopping

criterion (25) in sparse-data experiment, RLM-MAC stops at the 2nd iteration. This leads

to the lowest RMSEs of PORO, compared to other choices of ﬁnal iteration steps (Figure

17(d)). On the other hand, the RMSEs of log PERMX at the 2nd iteration step are not

the lowest, and even appear slightly higher than those of the initial ensemble (Figure 17(c)).

A possible explanation of this result is that, from the perspective of forward simulation,

porosity aﬀects AVA attributes more directly than permeability.

Indeed, in our forward

simulation, apart from porosity, AVA attributes depend on two reservoir dynamical vari-

26

ables, namely, pressure and saturation, whereas permeability aﬀects pressure and saturation

through reservoir simulation. Therefore the relation between AVA attributes and permeabil-

ity is more complicated, and perhaps also more nonlinear, than that between AVA attributes

and porosity. This extra complexity thus makes it more diﬃcult to invert permeability than

porosity in the current scenario.

A comparison of the results of full- and sparse-data experiments (Figure 17(a) versus

Figure 17(c), or Figure 17(b) versus Figure 17(d)) reveals pros and cons of using full seismic

data, when the stopping criterion (25) is not adopted. On one hand, using full seismic data

results in a high degree of “over-determinedness” in full-data experiment. This provides more

constraints in history matching, and seems to prevent the estimation results from being too

poor (as a contrast, one may see the last few steps of Figures 17(c) and 17(d)). On the other

hand, Figures 17(a) and 17(b) indicate signs of ensemble collapses at the last few iteration

steps. These, however, appear avoided in Figures 17(c) and 17(d).

Next we compare observed and simulated data. For succinctness, in what follows we

present the results of sparse-data experiment only. To this end, we show intercept (R0)

and gradient (G) attributes that are reconstructed using leading wavelet coeﬃcients of the

original noisy attributes (see Figure 14), and leading wavelet coeﬃcients of simulated AVA

attributes, respectively. The former reconstructed attributes are plotted in Figure 15. For

ease of visualization, we show diﬀerences between ensemble means of reconstructed simulated

attributes, and reconstructed observed attributes. Figure 18 illustrates the diﬀerences of

intercept attributes at diﬀerent survey time instances. There, sub-ﬁgures in the ﬁrst row

correspond to the results with respect to the initial ensemble, while those in the second row

to the results with respect to the ﬁnal ensemble (which is the ensemble obtained at the 2nd

27

iteration step). Comparing the results of initial and ﬁnal ensembles, it appears that the

distributions of diﬀerences at the base survey (Figures 18(a) and 18(d)) are similar, and

there are more distinctions at two monitor surveys. Similarly, Figure 19 shows diﬀerences of

gradient attributes. The results with respect to the initial and ﬁnal ensembles stay close at

all survey time. This is possibly because in this particular case, intercept is a more sensitive

attribute than gradient.

Figures 20 and 21 show distributions of log PERMX and PORO. In each ﬁgure, the

reference distribution is plotted in the ﬁrst row, the distributions of mean and two samples

of the initial ensemble in the second row, and the distributions of mean and two samples

of the ﬁnal ensemble in the third row. Comparing the results of initial and ﬁnal ensembles

(e.g., Figure 20(b) versus Figure 20(e)), we see substantial changes in both log PERMX and

PORO after history matching, consistent with the results in Figure 17.

d. Results of scenario S3 (using both production and 4D seismic data)

Finally we consider the scenario in which both production and seismic data are used in

history matching.

In the context of iES, we build an augmented observation vector that

concatenates all production and seismic data at diﬀerent time steps, such that RLM-MAC

can be applied in the same way as in the previous two scenarios. In this scenario, the stopping

criterion (25) applies to individual data mismatch with respect to production and seismic

data, respectively. That is to say, RLM-MAC stops if data mismatch of production and

seismic data both satisﬁes (25) for the ﬁrst time (if applicable). As discussed in the previous
scenarios, the threshold value of (25) is 540 for production data, and around 1.87 × 105

28

(full-data experiment) or 1.10 × 104 (sparse-data experiment) for seismic data.

Figure 22 reports data mismatch as functions of iteration step. In full-data experiment,

the average data mismatch of production data satisﬁes the stopping criterion (25) from

the 4th iteration on, whereas the average data mismatch of seismic data never hits at the

threshold value. As a result, RLM-MAC stops at the 10th iteration step using stopping

conditions (C1) and (C2), which leads to ﬁnal average data mismatch of 324.29 for production
data and around 1.19× 108 for seismic data. Alternatively, since the average data mismatch

of production data can be lower than the threshold value (Figure 22(a)), one may apply the

stopping criterion (25) to production data only and let RLM-MAC stop at the 4th iteration

step, and this leads to ﬁnal average data mismatch of 380.13 for production data and around
1.20 × 108 for seismic data. In sparse-data experiment, the average data mismatch of both

production and seismic data can satisfy the stopping criterion (25). Figures 22(c) and 22(d)

together suggest that RLM-MAC stop at the 3rd iteration, and this corresponds to ﬁnal
average data mismatch of 356.48 for production data and around 1.02× 104 for seismic data.

In contrast, if using stopping conditions (C1) and (C2) only, RLM-MAC stop at the 10th

iteration, which corresponds to ﬁnal average data mismatch of 200.83 for production data
and around 9.82 × 103 for seismic data.

Figure 23 shows RMSEs of log PERMX and PORO as functions of iteration step. In full-

data experiment (Figure 23(a) and 23(b)), the RMSEs of log PERMX and PORO exhibit

U-turn behaviours, such that the RMSEs at the last few iteration steps tend to be larger

than those at the intermediate steps. In addition, there are also signs of ensemble collapses

at the last few iteration steps. As a result, even though the stopping criterion (25) is

valid for production data only, combining stopping conditions (C1) and (C2) and (25) leads

29

to improved estimation results in terms of RMSE, in comparison with the choice of using

stopping conditions (C1) and (C2) only. In sparse-data experiment (Figure 23(c) and 23(d)),

we observe a similar eﬀect of the stopping criterion (25) on the ﬁnal estimation results, but

in this case ensemble collapses are avoided.

To see the eﬀects of using production and/or seismic data on history matching in this

particular example, in Table 2 we compare the average RMSEs of log PERMX and PORO

in all three scenarios (S1 – S3), where the stopping criterion (25) is used as far as possible.

When only using production data in S1 (Figure 9), the average RMSEs of log PERMX and

PORO (at the 3rd iteration) are 0.8941 and 0.0230, respectively, while those of the initial

ensemble are 0.9952 and 0.0236, respectively. Therefore, the ﬁnal estimations of both log

PERMX and PORO are improved in comparison with the initial ensemble. The average

RMSE of log PERMX in S1 is the lowest among all RMSEs of log PERMX in Table 2,

and is about 10.2% less than that of the initial ensemble. Nevertheless, the improvement

for PORO appears less signiﬁcant, and is only about 2.5% less than that of the initial

ensemble. When only using seismic data in S2 (Figure 17), in either full- or sparse-data

experiment (with the ﬁnal iteration steps being 10 and 2, respectively), the estimations

of PORO are improved compared to the initial ensemble, whereas the estimations of log

PERMX become worse. Finally, when using both production and seismic data in S3 (Figure

23), in either full- or sparse-data experiment (with the ﬁnal iteration steps being 4 and 3,

respectively), the estimations of log PERMX and PORO are both improved compared to

the initial ensemble. The RMSEs of log PERMX and PORO in full-data experiment are

0.9454 and 0.0188, respectively, while the RMSEs in sparse-data experiment are 0.9389 and

0.0180, respectively, slightly lower than those in full-data experiment. The RMSE of PORO

30

in sparse-data experiment of S3 is the lowest among all RMSEs of PORO in Table 2, and is

about 23.7% less than that of the initial ensemble. Meanwhile, The RMSE of log PERMX

in sparse-data experiment of S3 is about 5.7% less than that of the initial ensemble. Overall,

in this particular example, it appears that production data are useful for the estimation

of log PERMX, and that seismic data are important for the estimation of PORO. History

matching both production and seismic data (in sparse-data experiment) leads to a better

balance between the estimation accuracies of log PERMX and PORO.

For succinctness, in what follows we show the results of sparse-data experiment in S3,

where the ﬁnal ensemble is the one obtained at the 3rd iteration step. The production

data proﬁles with respect to the ﬁnal ensemble are plotted in Figure 24. Compared to the

corresponding proﬁles of the ﬁnal ensemble in S1 (Figure 11), we see that they appear similar,

but exhibit slight diﬀerences in some cases (e.g., Figure 24(e) versus Figure 11(e)). Figures 25

and 26 show diﬀerences between ensemble means of reconstructed simulated attributes and

reconstructed observed attributes at three survey time instances in sparse-data experiment

of S3, and they are very similar to the results in S2 (Figures 18 and 19). Figures 27 and 28

report some distributions of log PERMX and PORO. Comparing the results of initial and

ﬁnal ensembles (e.g., Figure 27(b) versus Figure 27(e)), we also see substantial changes in

both log PERMX and PORO after history matching, consistent with the results in Figure

23.

31

4. Conclusion and future works

In this study we propose an ensemble 4D seismic history matching framework with

wavelet multiresolution analysis. The seismic data are intercept and gradient attributes

of amplitude versus angle (AVA) data. To reduce data size, we adopt sparse representation

of seismic data in wavelet domain. In the history matching workﬂow, we apply wavelet trans-

forms to seismic data, estimate the noise in wavelet domain, and use an iterative ensemble

smoother to history-match leading wavelet coeﬃcients of seismic data.

As a proof-of-concept study, we apply the proposed framework to a 2D synthetic case.

In the experiments, to prevent the iterative ensemble smoother from over-ﬁtting the obser-

vations, we introduce an extra stopping criterion (25), apart from the stopping conditions

(C1) and (C2). Moreover, to see the impacts of production and/or seismic data on the

history matching performance, we investigate three scenarios (S1 – S3) that involve (S1)

production data only, (S2) 4D seismic data only, and (S3) both production and 4D seismic

data. In addition, to examine the eﬀects of sparse representation in scenarios S2 and S3, we

also compare the history matching performance in two types of experiments: one is the full-

data experiment where the original seismic attributes are used as the observations, and the

other is the sparse-data experiment where leading wavelet coeﬃcients are adopted as sparse

presentation of seismic data. In this particular case study, our numerical results indicate

that,

(1) combining the stopping criterion (25) and the stopping conditions (C1) and (C2)

tends to make the iterative ensemble smoother stop earlier than only using stopping

conditions (C1) and (C2), and this leads to better estimation results in terms of

32

RMSEs;

(2) using both production and seismic data in history matching results in more balanced

improvements on average RMSEs of log PERMX and PORO than only using either

production or seismic data;

(3) provided that the stopping criterion (25) is adopted, using sparse representation sub-

stantially reduces the data size in history matching, while renders better estimation

results (in terms of average RMSEs) than using the original seismic data.

An extension of the proposed framework to 3D case studies will be carried out in the

future. In addition, it is expected that the idea of sparse representation – either based on

wavelet or other basis functions – may also be applied to diﬀerent types of seismic data, for

instance, acoustic impedance or saturation map. This is another topic that will be covered

in our future investigations.

(i) Acknowledgement

We would like to thank Dr. Mohsen Dadashpour for providing us the reservoir model

of 2D Norne ﬁeld, and thank Schlumberger for providing us academic software licenses to

ECLIPSE and PETREL. XL acknowledges partial ﬁnancial supports from the CIPR/IRIS

cooperative research project “4D Seismic History Matching” which is funded by industry

partners Eni, Petrobras, and Total, as well as the Research Council of Norway (PETRO-

MAKS). All authors acknowledge the Research Council of Norway and the industry partners

– ConocoPhillips Skandinavia AS, BP Norge AS, Det Norske Oljeselskap AS, Eni Norge AS,

Maersk Oil Norway AS, DONG Energy A/S, Denmark, Statoil Petroleum AS, ENGIE E&P

33

NORGE AS, Lundin Norway AS, Halliburton AS, Schlumberger Norge AS, Wintershall

Norge AS – of The National IOR Centre of Norway for ﬁnancial supports.

REFERENCES

Aanonsen, S., G. Nævdal, D. Oliver, A. Reynolds, and B. Vall`es, The ensemble Kalman ﬁlter

in reservoir engineering: a review, SPE Journal, 14, 393–412, 2009, SPE-117274-PA.

Abadpour, A., P. Bergey, and R. Piasecki, 4D seismic history matching with ensemble

Kalman ﬁlter-assimilation on Hausdorﬀ distance to saturation front, in SPE Reservoir

Simulation Symposium, Society of Petroleum Engineers, 2013, SPE-163635-MS.

Awotunde, A. A., A multiresolution adjoint sensitivity analysis of time-lapse saturation

maps, Computational Geosciences, 18, 677–696, 2014.

Buland, A. and H. Omre, Bayesian linearized AVO inversion, Geophysics, 68, 185–198, 2003.

Chen, W. H., G. R. Gavalas, J. H. Seinfeld, and M. L. Wasserman, A new algorithm for

automatic history matching, SPE Journal, 14, 593–608, 1974, SPE-4545-PA.

Chen, Y. and D. Oliver, Levenberg-Marquardt forms of the iterative ensemble smoother for

eﬃcient history matching and uncertainty quantiﬁcation, Computational Geosciences, 17,

689–703, 2013.

34

Chen, Y. and D. S. Oliver, Multiscale parameterization with adaptive regularization for

improved assimilation of nonlocal observation, Water Resources Research, 48(4), W04,503,

2012.

Dadashpour, M., Reservoir characterization using production data and time-lapse seismic

data, Ph.D. thesis, Norwegian University of Science and Technology, 2009.

Dadashpour, M., M. Landrø, and J. Kleppe, Nonlinear inversion for estimating reservoir

parameters from time-lapse seismic data, Journal of Geophysics and Engineering, 5, 54,

2008.

Domenico, S. N., Eﬀect of water saturation on seismic reﬂectivity of sand reservoirs encased

in shale, Geophysics, 39, 759–769, 1974.

Donoho, D. L. and I. M. Johnstone, Adapting to unknown smoothness via wavelet shrinkage,

Journal of the American Statistical Association, 90, 1200–1224, 1995.

Donoho, D. L. and J. M. Johnstone, Ideal spatial adaptation by wavelet shrinkage,

Biometrika, 81, 425–455, 1994.

Emerick, A. A. and A. C. Reynolds, Ensemble smoother with multiple data assimilation,

Computers & Geosciences, 55, 3–15, 2012a.

Emerick, A. A. and A. C. Reynolds, History matching time-lapse seismic data using the

ensemble Kalman ﬁlter with multiple data assimilations, Computational Geosciences, 16,

639–659, 2012b.

Emerick, A. A., A. C. Reynolds, et al., History-matching production and seismic data in

35

a real ﬁeld case using the ensemble smoother with multiple data assimilation, in SPE

Reservoir Simulation Symposium, Society of Petroleum Engineers, 2013, SPE-163675-MS.

Engl, H. W., M. Hanke, and A. Neubauer, Regularization of Inverse Problems, Springer,

2000.

Evensen, G. and P. J. van Leeuwen, An ensemble Kalman smoother for nonlinear dynamics,

Mon. Wea. Rev., 128, 1852–1867, 2000.

Fahimuddin, A., S. Aanonsen, and J.-A. Skjervheim, Ensemble based 4D seismic history

matching–integration of diﬀerent levels and types of seismic data, in 72nd EAGE Confer-

ence & Exhibition, 2010.

Gassmann, F., ¨Uber die Elastizit¨at por¨oser Medien, Vierteljahresschrift der Naturforschen-

den Gesellschaft, 96, 1–23, 1951.

Gentilhomme, T., D. S. Oliver, T. Mannseth, G. Caumon, R. Moyen, and P. Doyen,

Ensemble-based multi-scale history-matching using second-generation wavelet transform,

Computational Geosciences, 19, 999–1025, 2015.

Gosselin, O., S. Aanonsen, I. Aavatsmark, A. Cominelli, R. Gonard, M. Kolasinski, F. Ferdi-

nandi, L. Kovacic, K. Neylon, et al., History matching using time-lapse seismic (HUTS), in

SPE Annual Technical Conference and Exhibition, Society of Petroleum Engineers, 2003,

SPE-84464-MS.

Gu, Y. and D. Oliver, An iterative ensemble Kalman ﬁlter for multiphase ﬂuid ﬂow data

assimilation, SPE Journal, 12, 438–446, 2007, SPE-108438-PA.

36

Jack, I., The coming of age for 4D seismic, First Break, 19, 24–28, 2001.

Jansen, M., Noise reduction by wavelet thresholding, vol. 161, Springer Science & Business

Media, 2012.

Jin, Q., On a regularized Levenberg–Marquardt method for solving nonlinear inverse prob-

lems, Numerische Mathematik, 115, 229–259, 2010.

Johnstone, I. M. and B. W. Silverman, Wavelet threshold estimators for data with correlated

noise, Journal of the royal statistical society: series B (statistical methodology), 59, 319–

351, 1997.

Katterbauer, K., I. Hoteit, and S. Sun, History matching of electromagnetically heated

reservoirs incorporating full-waveﬁeld seismic and electromagnetic imaging, SPE Journal,

20, 923 – 941, 2015, SPE-173896-PA.

Landrø, M., Discrimination between pressure and ﬂuid saturation changes from time-lapse

seismic data, Geophysics, 66, 836–844, 2001.

Leeuwenburgh, O. and R. Arts, Distance parameterization for eﬃcient seismic history match-

ing with the ensemble Kalman ﬁlter, Computational Geosciences, 18, 535–548, 2014.

Li, G. and A. Reynolds, Iterative ensemble Kalman ﬁlters for data assimilation, SPE Journal,

14, 496–505, 2009, SPE-109808-PA.

Luo, X. and I. M. Moroz, Ensemble Kalman ﬁlter with the unscented transform, Physica D,

238, 549–562, 2009.

37

Luo, X., A. Stordal, R. Lorentzen, and G. Nævdal, Iterative ensemble smoother as an approx-

imate solution to a regularized minimum-average-cost problem: theory and applications,

SPE Journal, 20, 962–982, 2015, SPE-176023-PA.

Mallat, S., A wavelet tour of signal processing, Academic press, 2008.

Mavko, G., T. Mukerji, and J. Dvorkin, The rock physics handbook: Tools for seismic analysis

of porous media, Cambridge University Press, 2009.

Mindlin, R. D., Compliance of elastic bodies in contact, Journal of Applied Mechanics, 16,

259–268, 1949.

Nævdal, G., L. M. Johnsen, S. I. Aanonsen, E. H. Vefring, et al., Reservoir monitoring and

continuous model updating using ensemble Kalman ﬁlter, SPE journal, 10, 66–74, 2005,

SPE-84372-PA.

Nur, A., Four-dimesional seismology and (true) direct detection of hydrocarbons: The petro-

physical basis, The Leading Edge, 8, 30–36, 1989.

Oliver, D. and Y. Chen, Recent progress on reservoir history matching: a review, Computa-

tional Geosciences, 15, 185–221, 2010.

Reuss, A., Berechnung der ﬂießgrenze von mischkristallen auf grund der plas-

tizit¨atsbedingung f¨ur einkristalle., ZAMM-Journal of Applied Mathematics and Mechan-

ics/Zeitschrift f¨ur Angewandte Mathematik und Mechanik, 9, 49–58, 1929.

Sahni, I. and R. N. Horne, Multiresolution wavelet analysis for improved reservoir descrip-

tion, SPE Reservoir Evaluation & Engineering, 8, 53–69, 2005, SPE-87820-PA.

38

Skjervheim, J.-A. and G. Evensen, An ensemble smoother for assisted history matching, in

SPE Reservoir Simulation Symposium, The Woodlands, Texas, USA, 2011, SPE-141929-

MS.

Skjervheim, J.-A., G. Evensen, S. I. Aanonsen, B. O. Ruud, and T.-A. Johansen, Incorpo-

rating 4D seismic data in reservoir simulation models using ensemble Kalman ﬁlter, SPE

Journal, 12, 282 – 292, 2007, SPE-95789-PA.

Smith, G. and P. Gidlow, Weighted stacking for rock property estimation and detection of

gas, Geophysical Prospecting, 35, 993–1014, 1987.

Tarantola, A., Inverse Problem Theory and Methods for Model Parameter Estimation,

SIAM., 2005.

Trani, M., R. Arts, and O. Leeuwenburgh, Seismic history matching of ﬂuid fronts using the

ensemble Kalman ﬁlter, SPE Journal, 18, 159–171, 2012, SPE-163043-PA.

Van Leeuwen, P. J. and G. Evensen, Data assimilation and inverse methods in terms of a

probabilistic formulation, Mon. Wea. Rev., 124, 2898–2913, 1996.

39

List of Tables

1

2

Information summary of the 2D model case study

Average RMSEs of log PERMX and PORO of the initial ensemble and ﬁnal

ones obtained in diﬀerent scenarios. The last row also lists the corresponding

iteration steps at which these ensembles are obtained.

41

42

40

Table 1.

Model dimension
Gridblock size
Reservoir simulator
Well completion
Production period
Production data
Seismic survey time
Seismic data
DWT (seismic)
Thresholding
History matching method iES (RLM-MAC) with an ensemble of 100 reservoir models

Information summary of the 2D model case study
39 × 26 (1014 gridblocks), with 739 out of 1014 being active cells
Irregular. Average ∆X ≈ 80m, average ∆Z ≈ 5m
ECLIPSE 100 (control mode RESV)
Injector I1: layer 1 – 25; Producer P1: layer 1 – 12
3750 days (with 27 report time)
I1: BHP; P1: BHP, GOR, OPT, WCT. Total number: 5 × 27 = 135
Base: day 0; Monitor (1st): day 2040; Monitor (2nd): day 3750
AVA intercepts and gradients at survey time. Total number: 46686
2D Daubechies wavelets with two vanishing moments
Hard thresholding based on universal rule

41

Table 2. Average RMSEs of log PERMX and PORO of the initial ensemble and ﬁnal
ones obtained in diﬀerent scenarios. The last row also lists the corresponding iteration steps
at which these ensembles are obtained.
initial
0.9952
0.0236

S2 (full) S2 (sparse) S3 (full) S3 (sparse)
1.0519
0.0205

Average RMSE (log PERMX)

Average RMSE (PORO)

S1

0.8941
0.0230

1.0088
0.0181

0.9454
0.0188

0.9389
0.0180

Stopping step

0

3

10

2

4

3

42

List of Figures

48

49

50

1

Flowchart of forward modeling of AVA attributes.

2 Workﬂow of sparse representation of seismic data through discrete wavelet

3

4

transform (DWT).

Three-level wavelet decomposition.

An illustration of sparse representation of intercept data generated by a for-

ward AVA attribute simulation. (a) Reference intercept data; (b) Noisy inter-

cept data obtained by adding Gaussian white noise (noise level = 30%) to the

reference data; (c) Reconstructed intercept data obtained by ﬁrst conducting

a 2D DWT on the noisy data, then applying hard thresholding (using the

universal threshold value) to wavelet coeﬃcients, and ﬁnally reconstructing

the data using an inverse 2D DWT based on the modiﬁed wavelet coeﬃcients. 51

5

As in Figure 4, but with (a) Wavelet coeﬃcients of reference data; (b) Wavelet

coeﬃcients of noisy data; (c) Wavelet coeﬃcients after thresholding. These

are used to reconstruct the data in Figure 4(c) through an inverse 2D DWT.

52

6

As in Figure 4, but with (a) reference noise, deﬁned as the diﬀerence between

noisy data and reference data; (b) Estimated noise, deﬁned as the diﬀerence

between noisy data and reconstructed data; (c) Noise diﬀerence, deﬁned as

the diﬀerence between estimated noise in (b) and reference noise in (a).

7

PERMX and PORO ﬁelds of the reference reservoir model used in the case

study. Figures are generated using PETREL c(cid:13).

53

54

43

8

Boxplots of data mismatch as a function of iteration step (scenario S1). The
horizontal dashed line indicates the threshold value (4 × 135 = 540) for the

stopping criterion (25). For visualization, the vertical axis is in the logarithmic

scale. In each box plot, the horizontal line (in red) inside the box denotes

the median; the top and bottom of the box represent the 75th and 25th

percentiles, respectively; the whiskers indicate the ranges beyond which the

data are considered outliers, and the whiskers positions are determined using

the default setting of MATLAB c(cid:13) R2015b, while the outliers themselves are

plotted individually as plus signs (in red).

9

Boxplots of RMSEs of (a) log PERMX and (b) PORO as functions of iteration

step (scenario S1).

10 Production data proﬁles (scenario S1). (a) BHP at I1; (b) BHP at P1; (c)

GOR; (d) OPT; (e) WCT. In each sub-ﬁgure, blue curves represent production

data forecasts with respect to the initial ensemble, orange curve corresponds

to true data of the reference model, and red dots are observations.

11 As in Figure 10, but now blue curves correspond to production data forecasts

with respect to the ensemble obtained at the 3rd iteration step.

12 Distributions of log PERMX (scenario S1). (a) Reference model; (b) – (d)

Mean and 2 sample realizations of the initial ensemble of log PERMX; (e) –

(g) Corresponding mean and 2 sample realizations of the ﬁnal ensemble. In

each sub-ﬁgure, there are two white dots on the top layer, and they are used

to indicate locations of the wells.

13 As in Figure 12, but now for the distributions of PORO in scenario S1.

44

55

56

57

58

59

60

14 Noisy AVA attributes (intercept and gradient) at three survey time instances.

These attributes are used as the observations of full-data experiment.

61

15 As in Figure 14, but attributes are reconstructed from inverse DWT using

leading wavelet coeﬃcients after thresholding. Note that it is leading wavelet

coeﬃcients that are used as the observations of sparse-data experiment.

62

16 Boxplots of data mismatch as functions of iteration step (scenario S2). (a)

Full-data experiment; and (b) Sparse-data experiment. The horizontal dashed

line in (b) represents the threshold of the stopping criterion (25), whereas data

mismatch in (a) is too high to hit at the threshold value.

63

17 Boxplots of RMSEs as functions of iteration step (scenario S2). Sub-ﬁgures

(a) and (b) in the ﬁrst row are for the results of full-data experiment, and (c)

and (d) in the second row for the results of sparse-data experiment.

64

18 Diﬀerences between ensemble means of reconstructed simulated intercepts and

reconstructed observed intercepts at three survey time instances in scenario

S2. Sub-ﬁgures in the ﬁrst row (a–c) are for the results with respect to the

initial ensemble, whereas those in the second row (d – f) for the results with

respect to the ensemble obtained at the 2nd iteration step in sparse-data

experiment.

19 As in Figure 18, but now for gradient attributes in scenario S2.

20 Distributions of log PERMX (scenario S2). (a) Reference model; (b) – (d)

Mean and 2 sample realizations of the initial ensemble of log PERMX; (e) –

(g) Corresponding mean and 2 sample realizations of the ﬁnal ensemble.

21 As in Figure 20, but now for the distributions of PORO in scenario S2.

65

66

67

68

45

22 Boxplots of data mismatch as functions of iteration step (scenario S3) for

(a) production data (full-data experiment), (b) seismic data (full-data exper-

iment), (c) production data (sparse-data experiment) and (d) seismic data

(sparse-data experiment). Except for (c), the horizontal dashed line in each

sub-ﬁgure represents the threshold value of stopping criterion (25) for either

production or seismic data, whereas data mismatch in (c) is too high to hit

at a threshold value.

69

23 Boxplots of RMSEs as functions of iteration step (scenario S3). Sub-ﬁgures

(a) and (b) in the ﬁrst row are for the results of full-data experiment, and (c)

and (d) in the second row for the results of sparse-data experiment.

70

24 As in Figure 11, but now blue curves correspond to production data forecasts

with respect to the ensemble obtained at the 3rd iteration step, using both

production and seismic data (scenario S3, sparse-data experiment).

71

25 Diﬀerences between ensemble means of reconstructed simulated intercepts and

reconstructed observed intercepts at three survey time instances in scenario

S3. Sub-ﬁgures in the ﬁrst row (a–c) are for the results with respect to the

initial ensemble, whereas those in the second row (d – f) for the results with

respect to the ensemble obtained at the 3rd iteration step in sparse-data ex-

periment.

26 As in Figure 25, but now for gradient attributes in scenario S3.

27 Distributions of log PERMX (scenario S3). (a) Reference model; (b) – (d)

Mean and 2 sample realizations of the initial ensemble of log PERMX; (e) –

72

73

(g) Corresponding mean and 2 sample realizations of the ﬁnal ensemble.

74

46

28 As in Figure 27, but now for the distributions of PORO in scenario S3.

75

47

Fig. 1. Flowchart of forward modeling of AVA attributes.

48

Fig. 2. Workﬂow of sparse representation of seismic data through discrete wavelet trans-
form (DWT).

49

Fig. 3. Three-level wavelet decomposition.

50

(a) Reference intercept data

(b) Noisy intercept data

(c) Reconstructed intercept data

Fig. 4. An illustration of sparse representation of intercept data generated by a forward
AVA attribute simulation. (a) Reference intercept data; (b) Noisy intercept data obtained
by adding Gaussian white noise (noise level = 30%) to the reference data; (c) Reconstructed
intercept data obtained by ﬁrst conducting a 2D DWT on the noisy data, then applying
hard thresholding (using the universal threshold value) to wavelet coeﬃcients, and ﬁnally
reconstructing the data using an inverse 2D DWT based on the modiﬁed wavelet coeﬃcients.

51

5101520253050100150200250-0.15-0.1-0.0500.050.10.150.25101520253050100150200250-0.15-0.1-0.0500.050.10.150.25101520253050100150200250-0.15-0.1-0.0500.050.10.150.2(a) Coeﬃcients of reference data

(b) Coeﬃcients of noisy data

(c) Coeﬃcients of
data

reconstructed

Fig. 5. As in Figure 4, but with (a) Wavelet coeﬃcients of reference data; (b) Wavelet
coeﬃcients of noisy data; (c) Wavelet coeﬃcients after thresholding. These are used to
reconstruct the data in Figure 4(c) through an inverse 2D DWT.

52

0200040006000800010000-0.5-0.4-0.3-0.2-0.100.10.20.30.40.50200040006000800010000-0.5-0.4-0.3-0.2-0.100.10.20.30.40.50200040006000800010000-0.5-0.4-0.3-0.2-0.100.10.20.30.40.5(a) Reference noise

(b) Estimated noise

(c) Noise diﬀerence

Fig. 6. As in Figure 4, but with (a) reference noise, deﬁned as the diﬀerence between noisy
data and reference data; (b) Estimated noise, deﬁned as the diﬀerence between noisy data
and reconstructed data; (c) Noise diﬀerence, deﬁned as the diﬀerence between estimated
noise in (b) and reference noise in (a).

53

5101520253050100150200250-0.15-0.1-0.0500.050.10.150.25101520253050100150200250-0.15-0.1-0.0500.050.10.150.25101520253050100150200250-0.15-0.1-0.0500.050.10.150.2Fig. 7. PERMX and PORO ﬁelds of the reference reservoir model used in the case study.
Figures are generated using PETREL c(cid:13).

54

Fig. 8.
Boxplots of data mismatch as a function of iteration step (scenario S1). The
horizontal dashed line indicates the threshold value (4×135 = 540) for the stopping criterion
(25). For visualization, the vertical axis is in the logarithmic scale. In each box plot, the
horizontal line (in red) inside the box denotes the median; the top and bottom of the box
represent the 75th and 25th percentiles, respectively; the whiskers indicate the ranges beyond
which the data are considered outliers, and the whiskers positions are determined using the
default setting of MATLAB c(cid:13) R2015b, while the outliers themselves are plotted individually
as plus signs (in red).

55

012345678910Iteration number103104105106Data mismatch(a) RMSEs of log PERMX

(b) RMSEs of PORO

Fig. 9. Boxplots of RMSEs of (a) log PERMX and (b) PORO as functions of iteration
step (scenario S1).

56

012345678910Iteration number0.70.80.911.11.21.3RMSE (PERMX)012345678910Iteration number0.0180.020.0220.0240.0260.0280.03RMSE (PORO)(a) BHP (bar)

(b) BHP (bar)

(c) GOR

(d) OPT (sm3)

(e) WCT

Fig. 10. Production data proﬁles (scenario S1). (a) BHP at I1; (b) BHP at P1; (c) GOR;
(d) OPT; (e) WCT. In each sub-ﬁgure, blue curves represent production data forecasts with
respect to the initial ensemble, orange curve corresponds to true data of the reference model,
and red dots are observations.

57

0100020003000Time (days)250300350400450I1ensref.meas.0100020003000Time (days)210220230240250260270P1ensref.meas.0100020003000Time (days)0200400600P1ensref.meas.0100020003000Time (days)02468×105P1ensref.meas.0100020003000Time (days)00.20.40.6Water cutP1ensref.meas.(a) BHP (bar)

(b) BHP (bar)

(c) GOR

(d) OPT (sm3)

(e) WCT

Fig. 11. As in Figure 10, but now blue curves correspond to production data forecasts
with respect to the ensemble obtained at the 3rd iteration step.

58

0100020003000Time (days)280300320340I1ensref.meas.0100020003000Time (days)230240250260270P1ensref.meas.0100020003000Time (days)0200400600P1ensref.meas.0100020003000Time (days)02468×105P1ensref.meas.0100020003000Time (days)00.10.20.30.40.5Water cutP1ensref.meas.(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 12. Distributions of log PERMX (scenario S1). (a) Reference model; (b) – (d) Mean
and 2 sample realizations of the initial ensemble of log PERMX; (e) – (g) Corresponding
mean and 2 sample realizations of the ﬁnal ensemble. In each sub-ﬁgure, there are two white
dots on the top layer, and they are used to indicate locations of the wells.

59

102030510152025PERMX, reference2468102030510152025PERMX, Mean2345678102030510152025PERMX, Member: 12345678102030510152025PERMX, Member: 22468102030510152025PERMX, Mean2345678102030510152025PERMX, Member: 12468102030510152025PERMX, Member: 22468(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 13. As in Figure 12, but now for the distributions of PORO in scenario S1.

60

102030510152025PORO, reference00.10.20.30.4102030510152025PORO, Mean00.10.20.30.4102030510152025PORO, Member: 100.10.20.30.4102030510152025PORO, Member: 200.10.20.30.4102030510152025PORO, Mean00.10.20.30.4102030510152025PORO, Member: 100.10.20.30.4102030510152025PORO, Member: 200.10.20.30.4(a) Intercept (day 0)

(b) Intercept (day 2040)

(c) Intercept (day 3750)

(d) Gradient (day 0)

(e) Gradient (day 2040)

(f) Gradient (day 3750)

Fig. 14. Noisy AVA attributes (intercept and gradient) at three survey time instances.
These attributes are used as the observations of full-data experiment.

61

Observed R0 trace51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed R0 trace51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed R0 trace51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed G trace51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4Observed G trace51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4Observed G trace51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4(a) Intercept (day 0)

(b) Intercept (day 2040)

(c) Intercept (day 3750)

(d) Gradient (day 0)

(e) Gradient (day 2040)

(f) Gradient (day 3750)

Fig. 15. As in Figure 14, but attributes are reconstructed from inverse DWT using leading
wavelet coeﬃcients after thresholding. Note that it is leading wavelet coeﬃcients that are
used as the observations of sparse-data experiment.

62

Observed R0 trace after denoising51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed R0 trace after denoising51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed R0 trace after denoising51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Observed G trace after denoising51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4Observed G trace after denoising51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4Observed G trace after denoising51015202530Trace No.50100150200250Time (ms)-0.4-0.3-0.2-0.100.10.20.30.4(a) Full-data experiment

(b) Sparse-data experiment

Boxplots of data mismatch as functions of iteration step (scenario S2).

Fig. 16.
(a)
Full-data experiment; and (b) Sparse-data experiment. The horizontal dashed line in (b)
represents the threshold of the stopping criterion (25), whereas data mismatch in (a) is too
high to hit at the threshold value.

63

012345678910Iteration number1.522.53Data mismatch×108012345678910Iteration number11.522.533.5Data mismatch×104(a) RMSEs of log PERMX (full-data)

(b) RMSEs of PORO (full-data)

(c) RMSEs of log PERMX (sparse-data)

(d) RMSEs of PORO (sparse-data)

Fig. 17. Boxplots of RMSEs as functions of iteration step (scenario S2). Sub-ﬁgures (a)
and (b) in the ﬁrst row are for the results of full-data experiment, and (c) and (d) in the
second row for the results of sparse-data experiment.

64

012345678910Iteration number0.70.80.911.11.21.3RMSE (PERMX)012345678910Iteration number0.0160.0180.020.0220.0240.0260.028RMSE (PORO)012345678910Iteration number0.811.21.41.6RMSE (PERMX)012345678910Iteration number0.0160.0180.020.0220.0240.0260.0280.030.032RMSE (PORO)(a) Initial ensemble, base survey

(b) Initial ensemble, 1st monitor sur-
vey

(c) Initial ensemble, 2nd monitor sur-
vey

(d) Final ensemble, base survey

(e) Final ensemble, 1st monitor sur-
vey

(f) Final ensemble, 2nd monitor sur-
vey

Fig. 18. Diﬀerences between ensemble means of reconstructed simulated intercepts and
reconstructed observed intercepts at three survey time instances in scenario S2. Sub-ﬁgures
in the ﬁrst row (a–c) are for the results with respect to the initial ensemble, whereas those
in the second row (d – f) for the results with respect to the ensemble obtained at the 2nd
iteration step in sparse-data experiment.

65

Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2(a) Initial ensemble, base survey

(b) Initial ensemble, 1st monitor sur-
vey

(c) Initial ensemble, 2nd monitor sur-
vey

(d) Final ensemble, base survey

(e) Final ensemble, 1st monitor sur-
vey

(f) Final ensemble, 2nd monitor sur-
vey

Fig. 19. As in Figure 18, but now for gradient attributes in scenario S2.

66

Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 20. Distributions of log PERMX (scenario S2). (a) Reference model; (b) – (d) Mean
and 2 sample realizations of the initial ensemble of log PERMX; (e) – (g) Corresponding
mean and 2 sample realizations of the ﬁnal ensemble.

67

102030510152025PERMX, reference2345678102030510152025PERMX, Mean2345678102030510152025PERMX, Member: 12345678102030510152025PERMX, Member: 22345678102030510152025PERMX, Mean2345678102030510152025PERMX, Member: 12345678102030510152025PERMX, Member: 22345678(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 21. As in Figure 20, but now for the distributions of PORO in scenario S2.

68

102030510152025PORO, reference00.10.20.30.4102030510152025PORO, Mean00.10.20.30.4102030510152025PORO, Member: 100.10.20.30.4102030510152025PORO, Member: 200.10.20.30.4102030510152025PORO, Mean00.10.20.30.4102030510152025PORO, Member: 100.10.20.30.4102030510152025PORO, Member: 200.10.20.30.4(a) Production data, full-data experiment

(b) Seismic data, full-data experiment

(c) Production data, sparse-data experiment

(d) Seismic data, sparse-data experiment

Fig. 22. Boxplots of data mismatch as functions of iteration step (scenario S3) for (a) pro-
duction data (full-data experiment), (b) seismic data (full-data experiment), (c) production
data (sparse-data experiment) and (d) seismic data (sparse-data experiment). Except for
(c), the horizontal dashed line in each sub-ﬁgure represents the threshold value of stopping
criterion (25) for either production or seismic data, whereas data mismatch in (c) is too high
to hit at a threshold value.

69

012345678910103104105106Iteration numberData mismatch0123456789101.522.53x 108Iteration numberData mismatch012345678910103104105106Iteration numberData mismatch01234567891011.522.533.5x 104Iteration numberData mismatch(a) RMSEs of log PERMX (full-data)

(b) RMSEs of PORO (full-data)

(c) RMSEs of log PERMX (sparse-data)

(d) RMSEs of PORO (sparse-data)

Fig. 23. Boxplots of RMSEs as functions of iteration step (scenario S3). Sub-ﬁgures (a)
and (b) in the ﬁrst row are for the results of full-data experiment, and (c) and (d) in the
second row for the results of sparse-data experiment.

70

012345678910Iteration number0.70.80.911.11.21.3RMSE (PERMX)012345678910Iteration number0.0160.0180.020.0220.0240.0260.028RMSE (PORO)012345678910Iteration number0.811.21.41.6RMSE (PERMX)012345678910Iteration number0.020.0250.030.035RMSE (PORO)(a) BHP (bar)

(b) BHP (bar)

(c) GOR

(d) OPT (sm3)

(e) WCT

Fig. 24. As in Figure 11, but now blue curves correspond to production data forecasts
with respect to the ensemble obtained at the 3rd iteration step, using both production and
seismic data (scenario S3, sparse-data experiment).

71

0100020003000Time (days)280300320340I1ensref.meas.0100020003000Time (days)230240250260270P1ensref.meas.0100020003000Time (days)0200400600P1ensref.meas.0100020003000Time (days)02468×105P1ensref.meas.0100020003000Time (days)00.10.20.30.40.5Water cutP1ensref.meas.(a) Initial ensemble, base survey

(b) Initial ensemble, 1st monitor sur-
vey

(c) Initial ensemble, 2nd monitor sur-
vey

(d) Final ensemble, base survey

(e) Final ensemble, 1st monitor sur-
vey

(f) Final ensemble, 2nd monitor sur-
vey

Fig. 25. Diﬀerences between ensemble means of reconstructed simulated intercepts and
reconstructed observed intercepts at three survey time instances in scenario S3. Sub-ﬁgures
in the ﬁrst row (a–c) are for the results with respect to the initial ensemble, whereas those
in the second row (d – f) for the results with respect to the ensemble obtained at the 3rd
iteration step in sparse-data experiment.

72

Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated R0 trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2(a) Initial ensemble, base survey

(b) Initial ensemble, 1st monitor sur-
vey

(c) Initial ensemble, 2nd monitor sur-
vey

(d) Final ensemble, base survey

(e) Final ensemble, 1st monitor sur-
vey

(f) Final ensemble, 2nd monitor sur-
vey

Fig. 26. As in Figure 25, but now for gradient attributes in scenario S3.

73

Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2Ensemble mean of simulated G trace - observed51015202530Trace No.50100150200250Time (ms)-0.2-0.15-0.1-0.0500.050.10.150.2(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 27. Distributions of log PERMX (scenario S3). (a) Reference model; (b) – (d) Mean
and 2 sample realizations of the initial ensemble of log PERMX; (e) – (g) Corresponding
mean and 2 sample realizations of the ﬁnal ensemble.

74

102030510152025PERMX, reference2345678102030510152025PERMX, Mean  2345678102030510152025PERMX, Member: 1  2345678102030510152025PERMX, Member: 2  2345678102030510152025PERMX, Mean  2345678102030510152025PERMX, Member: 1  2345678102030510152025PERMX, Member: 2  2345678(a) Reference

(b) Initial mean

(c) Initial member 1

(d) Initial member 2

(e) Final mean

(f) Final member 1

(g) Final member 2

Fig. 28. As in Figure 27, but now for the distributions of PORO in scenario S3.

75

102030510152025PORO, reference00.10.20.30.4102030510152025PORO, Mean  00.10.20.30.4102030510152025PORO, Member: 1  00.10.20.30.4102030510152025PORO, Member: 2  00.10.20.30.4102030510152025PORO, Mean  00.10.20.30.4102030510152025PORO, Member: 1  00.10.20.30.4102030510152025PORO, Member: 2  00.10.20.30.4