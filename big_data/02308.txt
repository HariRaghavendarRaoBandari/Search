Towards Automated Android App Collusion Detection

Irina Mariuca As˘avoae1, Jorge Blasco2, Thomas M. Chen2, Harsha Kumara Kalutarage3, Igor

Muttik4, Hoang Nga Nguyen5, Markus Roggenbach ∗,1, and Siraj Ahmed Shaikh5

1Swansea University, UK

2City University London, UK

3Queen’s University of Belfast, UK

4Intel Security, UK

5Coventry University, UK

6
1
0
2

 
r
a

M
7

 

 
 
]
E
S
.
s
c
[
 
 

1
v
8
0
3
2
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

Android OS supports multiple communication
methods between apps. This opens the pos-
sibility to carry out threats in a collaborative
fashion, c.f. the Soundcomber example from
2011. In this paper we provide a concise deﬁ-
nition of collusion and report on a number of
automated detection approaches, developed in
co-operation with Intel Security.

1 Introduction

The Android operating system (OS) is designed with a
number of built-in security features such as app sand-
boxing and fairly granular access controls based on
permissions. In real life, however, isolation of apps is
limited. In some respects even the opposite is true –
there are many ways for apps to communicate across
sandbox boundaries. The Android OS supports mul-
tiple communication methods which are fully docu-
mented (such as messaging via intents). The ability
of apps with diﬀerent security postures to communi-
cate has a negative eﬀect on security as an app (in a
sandbox which has permissions to handle such data)
is allowed to let sensitive data ﬂow to another app (in
another sandbox which has been denied permission to
handle such data) and eventually leak out.

∗ Corresponding author M.Roggenbach@swan.ac.uk

Copyright c(cid:13) by the paper’s authors. Copying permitted for
private and academic purposes.

In: A. Editor, B. Coeditor (eds.): Proceedings of the XYZ
Workshop, Location, Country, DD-MMM-YYYY, published at
http://ceur-ws.org

The Android ecosystem exacerbates the problem
as the market pressure leads many developers to em-
bed advertisement libraries into their apps. As a re-
sult, such code may be present in thousands of apps
(all bearing diﬀerent permissions). Advertisers have a
known tendency to disregard user privacy in favour of
monetisation. So there exists a risk that ad-libraries
may communicate between sandboxes even without
knowledge of apps authors to transmit sensitive data
across, risking exposure and disregarding privacy.

Of course, any unscrupulous developer may also
split functionality which they prefer to hide between
multiple apps. Malicious behaviours similar to this are
evident from known cases of apps exploiting insecure
exposure of sensitive data by other apps [2].

Researchers have demonstrated that sets of apps
may violate the permissions model causing data leaks
or carrying malware [21]. Such apps are called col-
luding sets of apps and the phenomenon is called app
collusion. Unfortunately, there are no eﬀective tools
to detect for app collusion. The search space posed
by possible combination of apps means that this is not
straightforward. Eﬀective methods are needed to nar-
row down the search to collusion candidates of interest.
This paper contributes towards a practical auto-
mated system for collusion detection. We give a def-
inition of collusion in Section 2. This is followed by
two potential approaches to ﬁlter down to potential
candidates for collusion, using a rule based approach
developed in Prolog in Section 3 and another statisti-
cal approach in Section 4. Section 5 presents a model-
checking approach to detecting collusion in Android
Dalvik apps. Section 6 delves into the experimental
outcomes and Section 7 discusses related work. Sec-
tion 8 summarises our contributions and Section 9 con-
cludes the paper with thoughts on future work.

1

2 Deﬁning collusion

Our notion of collusion refers to the ability for a set
of apps to carry out a threat in a collaborative fash-
ion. This is in contrast to most existing work, where
collusion is usually associated with inter-app commu-
nications and information leakage (see Section 7). We
consider that colluding apps can carry out any threat
such as the ones posed by single apps. The range of
such threats includes [23]:

• Information theft: happens when one app accesses
sensitive information and the other sends informa-
tion outside the device boundaries.

• Money theft: happens when an app sends infor-
mation to another app that is capable of using
money sensitive API calls (e.g. SMS).

• Service misuse: happens when one app is able to
control a system service and receives information
(commands) from another app to control those
services.

A threat can be described by a set of actions ex-
ecuted in a certain order. We model this by a par-
tially ordered set (T,≤), where T is the set of actions
and ≤ speciﬁes the execution order. When (T,≤) is
carried out, actions from T are sequentially executed,
according to some total order ≤∗ such that ≤⊆≤∗; in
other words, (T,≤∗) is a total extension of (T,≤). Let
Ex((T,≤)) denote the set of all possible total exten-
sions of (T,≤); i.e., all possible ways of carrying out
threat (T,≤). Similarly, we also deﬁne inter-app com-
munication as a partially ordered set.

We deﬁne collusion as follows:

A1: Actions are operations provided by Android API
(such as record audio, access ﬁle, write ﬁle, send
data, etc.). Let Act denote the set of all actions.

A2: Actions can be characterised by a number of at-
tributes (such as permissions, input parameters,
etc.). Let B denote the set of all action attributes
and pms : Act → ℘(B) specify the set of permis-
sions required by Android to execute an action.
A3: A threat t = (T,≤) is a partially ordered set. Let
τ denote the set of all threats. In the scope of this
paper, τ represents the set of all known threats
caused by single applications.

A4: An inter-app communication c = (C,≤) is a par-
tially ordered set. Let com denote the set of all
known inter-app communications.

Deﬁnition 1 (Collusion). A set S consisting of at
least two apps is colluding if together they execute a
sequence A ∈ Act∗ such that:

Figure 1: An example of colluding apps

1. there exists a subsequence A(cid:48) of A such that A(cid:48) ∈
Ex(t) for some t ∈ τ ; furthermore, A(cid:48) is collec-
tively executed involving all apps in S, i.e., each
app in S executes at least one action in A(cid:48); and
2. there exists a subsequence C(cid:48) of A such that C(cid:48) ∈

Ex(c) for some c ∈ com.

To illustrate our deﬁnition we present an example.

Example 1 (Stealing contact data). The two apps
graphically represented in Figure 1 perform infor-
the Contact app reads the contacts
mation theft:
database to pass the data to Weather app, which sends
the data to a remote server controlled by the adversary.
The information is sent through shared preferences.

=
pms(asend f ile)
=
information threat

Using the collusion deﬁnition we can describe the
actions performed by both apps as: ActContact app =
{ar ead contacts}, ActWeather app = {asend f ile}. with
{Permission contacts}
pms(ar ead contacts)
{Permission internet}.
and
=
is
The
{ar ead contacts, asend f ile} and deﬁning ar ead contacts <
asend f ile. The
inter-app communication is de-
{sendshared pref s},
ﬁned
and
comWeather app
sendshared pref s < recvshared pref s.

=
{recvshared pref s}

as

comContact app

t

given by T

=

3 Detecting collusion threat

Our ﬁrst approximation to detect app collusion utilises
Logic Programming in Prolog. Its goal is to serve as
a fast, computationally cheap ﬁlter that detects po-
tential colluding apps. It (1) uses Androguard [9] to
extract facts about the communication channels and
permissions of all single apps in a given app set S, (2)
which is then abstracted into an over-approximation
of actions and communication channels that could be
used by a single app. (3) Finally the collusion rules are
ﬁred if the proper combinations of actions and commu-
nications are found in S.

We utilise an action set Actprolog composed out of
four diﬀerent high level actions: accessing sensitive in-
formation, use an API that can directly cost money,
control device services (e.g. camera, etc.), and send
information to other devices and the Internet. To ﬁnd
out which of these actions an app could carry out,
we extract its set of permissions pmsprolog. Each per-
mission is mapped to one or more of the four high
level actions. For example, an app that declares the

2

Contact_appWeather_appREADCONTACTSINTERNETSharedPrefs.INTERNET permission will be capable of sending in-
formation outside the device:

uses(App, PInternet) → information outside(App)
The communication channels established by an app
are characterised by its API calls and the permissions
declared in its manifest ﬁle. We cover all communica-
tion actions (comprolog) that can be created as follows:
• Intents are messages used to request actions from
other application components (activities, services
or broadcast receivers). Activities, services and
broadcast receivers declare the intents they can
handle by declaring a set of IntentFilters .

• External Storage is a storage space shared be-
tween all the apps installed without restrictions.
Apps accessing the external storage need to de-
clare the READ EXTERNAL STORAGE per-
mission. To enable writing, apps must declare
WRITE EXTERNAL STORAGE.

• Shared Preferences are an OS feature to store key-
value pairs of data. Although it is not intended for
inter-app communication, apps can use key-value
pairs to exchange information if proper permis-
sions are deﬁned (before Android 4.4).

We map apps to sending and receiving actions by
inspecting their code and manifest ﬁles. When using
Intents and SharedPreferences we are able to spec-
ify the communication channel using the intent ac-
tions and preference ﬁle and package respectively. If
an application sends a BroadcastIntent with an action
SEND FILE we consider the following:

send broadcast(App, Intentsend f ile)
→ send(App, Intentsend f ile)

We consider that two apps communicate if one of them
is able to send and the other to receive through the
same channel. This allows to detect communication
paths composed by an arbitrary number of apps:
send(Appa, channel) ∧ receive(Appb, channel) →
communicate(Appa, Appb, channel)

Our threat set τprolog considers information theft,
money theft and service misuse. As our deﬁnition
states, each of the threats is characterised by a se-
quence of actions. For example, the information theft
threat is codiﬁed as the following Prolog rule:

sensitive information(Appa)
∧ information outside(Appb)
∧ communicate(Appa, Appb, channel)

collusion(Appa, Appb)

→

Currently, we do not take into account the order of
action execution.

4 Assessing the collusion possibility

In this section, we apply machine learning to classify
app sets into colluding and non-colluding ones. To this
end, we ﬁrst deﬁne a probabilistic model. Then we
train the model, i.e., estimate the model parameters
on a training data set. As a third step we validate
the model using a validation data set. Additionally, in
Section 6.3, we check the model with testing data.

Estimating the collusion possibility within a set S
of apps involves to estimate two diﬀerent likelihood
components Lτ and Lcom. Lτ denotes the likelihood
of carrying out a threat. Lcom denotes the likelihood of
performing some inter-app communication. Hence, the
likelihood of colluding within S is given by Lτ × Lcom.
In order to estimate Lτ , we employ a so-called Naive
Bayesian informative [17] model. We consider a multi-
variate random variable Y = (y1, . . . , yk). Here, k is
the total number of permissions in Android OS, and
yj ∈ {0, 1} are independent Bernoulli random vari-
ables. Variable yj is 1 if permission j is found in S,
0 otherwise. P (Y ) stands for the probability of ob-
taining S with permissions as described by Y . Our
probabilistic model is then given by equation (1)

P (Y ) =

j (1 − λj)1−yj
λyj

(1)

where λj ∈ [0, 1] is the Bernoulli parameter.

To compute Lτ we deﬁne Lτ = ln{(P (Y ))−1}. This
reﬂects on the likelihood of an app set to “being ma-
licious” increasing as the number of permissions re-
quested increase. Therefore, any monotonically de-
creasing function can be chosen [17]. For comparisons
we average out Lτ and scale down to the range [0,1].
To complete our modelling, we need to estimate val-
ues ˆλj that replace λj in the computation of Lτ . To
this end – to avoid over ﬁtting P (Y ) – we estimate
λj using informative beta prior distributions [13] and
deﬁne the maximum posterior estimation

k(cid:89)

j=1

(cid:80) yj + αj

N + αj + βj

ˆλj =

(2)

where N is the number of apps in the training set and
αj, βj are penalty eﬀects. In this work we set αj = 1.
βj depend on the critical level of permissions as given
in [20, 17]. βj can take either the value 2N (most
critical), N (critical) or 1 (non-critical).
We consider Lcom to be a binary function such that
Lcom ∈ {1, 0} which takes the value 1 if there is inter
app communication within S, 0 otherwise.

To the best of our knowledge, there are no known
colluding examples in the wild. However, there are
sets of apps available, where individual apps have been
classiﬁed by industry experts. Thus, we have utilised

3

Figure 3: Work-ﬂow

measure provides a way to judge the overall perfor-
mance of the model for each class. The higher these
values, the better the performance. Such values could
be due to a bias of the validation sample towards the
methodology. Further investigation on the bias of the
evaluation dataset is left for future work.

5 Model-Checking for collusion

We demonstrate the eﬀective attempt to detect col-
lusion via model-checking. Figure 3 shows the basic
work-ﬂow employed: it starts with a set of apps in the
Dalvik Executable format DEX [1]; this code is dis-
assembled and (currently manually) translated into a
semantically faithful representation in the framework
K [18] – this step also triggers a data ﬂow analysis
of the app code; compilation translates the K repre-
sentation into a rewrite theory in Maude [7]; using the
Maude model-checker provides an answer if the app set
colludes or not: in case of collusion, the tool provides
a readable counter example trace (see Section 6.4).

The rewriting logic semantics framework K allows
the user to deﬁne conﬁgurations, computations and
rules [18]. Conﬁgurations organise the program state
in units called cells. In case of SMALI assembly pro-
grams, on the method level program states essentially
consist of the current instruction, registers and param-
eters, and the class it belongs to. The operational se-
mantics of, say, the assembly instruction

const Register, Int

for loading an integer constant Int into a register Reg-
ister is captured by a rule

which reads: provided the current instruction is to load
an integer I into a register R, then the cell “regs” cap-
turing the state of the registers is updated by binding
the value I to register R. The SMALI language also in-
cludes procedure calls. These allow to access function-
ality provided by the Android operating system, e.g.,
to read protected resources such as the GPS location
or to send/receive a broadcast intent. Thus, besides
encoding SMALI instructions in K, we also model the
infrastructure that Android provides to apps.

Figure 2: Distribution of Lτ over evaluation sample.
Blue dotted line: best possible linear discriminant line.

one such set provided by Intel Security, which consists
of 9k+ malicious and 9k+ clean apps. As mentioned in
Section 2, there is no evidence suggesting diﬀerences
between threats caused by single apps and colluding
apps. Thus, we can estimate Lτ based on this set. As
for Lcom, there is no need to estimate any constants.
We validate our model on a larger set of apps (a
blind sample) that was produced for calibration of col-
lusion detection mechanisms. This validation set con-
sists of 240 app pairs in which half are colluding pairs,
the other half is non-colluding.

For this analysis, we implemented an automated
process using R and Bash scripts, which also includes
calls to a third party research prototype [5] to ﬁnd
intent based communications. Additionally, a simple
permission based rule set was deﬁned to ﬁnd commu-
nication using external storage. Overall, this process
consists of the following steps: (1) extracting permis-
sions of all single apps in a given app set S; (2) comput-
ing Lτ using extracted permissions; (3) if Lτ is greater
than a certain threshold then estimating Lcom as men-
tioned above; and ﬁnally (4) computing Lτ × Lcom.

Figure 2 presents Lτ values for the validation
dataset in which a clear separation can be seen be-
tween two classes with a lower (=0.50) and upper
(=0.69) bounds for a discriminant line. Table 1
presents the confusion matrix obtained by ﬁtting the
best possible linear discriminant line at Lτ = 0.55 in
Figure 2.

n=240

Predicted
Colluding
Predicted

Non-Colluding

Actual

Actual

Colluding

Non-Colluding

114

6

7

113

Table 1: Confusion matrix for the evaluation sample.

Performance measures precision(=0.94) and F-
measure(=0.95) were computed using the Table 1.
Precision quantiﬁes the notion of speciﬁcity while F-

4

0501001502000.20.61.0App pair indexTLColluding pairs Non-colluding pairsLT=0.55The executions of the above semantics, instruction
after instruction, deﬁnes the computations. However,
the concrete semantics is far too detailed for eﬀective
model-checking. Therefore, we implement an abstrac-
tion in form of a data ﬂow analysis. Here we represent
each method individually as a graph, where registers,
types, and constants are the nodes, and there is an
edge between two nodes n1 and n2 iﬀ n2 is a param-
eter of the SMALI command that stores a value in
n1. For example, the SMALI command const r1, 42
would lead to an edge from node “42” to node “R1”.
Analysing such graphs allows to detect which com-
mands inﬂuence the values sent, say, in a broadcast
intent, or publishing via the internet; these commands
can be grouped into blocks and – rather than comput-
ing with concrete values – their eﬀect can be captured
symbolically.

For the detection of collusion, our K semantics car-
ries a “trace” cell that records which operations pro-
vided by the Android API – see Deﬁnition 1 – have
been executed in a speciﬁc run. Based on the “trace”
cell we deﬁne collusion via a K rule: provided that the
GPS location has been accessed, this value has been
sent in a broadcast, this value has been received from
a broadcast, and ﬁnally this value has been published,
in that case we detect collusion “information theft”.

Practical experiments with small apps demonstrate
that this approach is feasible. Using the Maude model-
checker, the state space of the (abstraction) of two
apps is small, with only 8 states for the given example
and the check takes less than a second.

We use symbolic analysis over the byte code of the
set S in order to obtain an in-depth inspection of the
communication patterns. In the byte code of each app
in S we detect the ﬂow of communication with another
app and a safe over-approximation of the data being
communicated. We use static analysis over the byte
code of apps to extract communication-ﬂow between
apps and data-ﬂow inside each app. The data-ﬂow
information is ﬁltered based on the private data being
read and communicated.

It is future work, to complete the encoding to cover
the full DEX language and to experiment with larger
apps. We further intend to prove the abstraction to be
sound, to show that if model-checking the abstracted
code detects collusion then there is collusion in the
original code, and to have a more general deﬁnition of
collusion that covers diﬀerent variants.

6 First experimental results

In this section we compile experimental results ob-
tained by applying the three methods discussed above
to an artiﬁcial set.

4

5 6 7 8 9 10 11 12 13 14

♣ ♣

$♣ ♠ ♠

♣ ♣
♣ ♣ ♣ ♣

♣

♣

♣ ♣

♣
♣ ♣

♣

♣

id 1 2 3
1
2
3
4
5
6
7
8
9
10
11
12
13
14

Table 2: Collusion Matrix of the Prolog program. ♣
= Information theft. $ = Money theft. ♠ = Service
misuse. ♣, $, ♠ = False positives.

6.1 An artiﬁcial colluding app set

In order to validate our diﬀerent approaches against
a known ground truth, we have created fourteen apps
that cover all threats and use all communication chan-
nels described earlier in this paper. They are or-
ganised in four colluding sets: The Document Ex-
tractor set consists of one app (id 1 ) that looks
for sensitive documents on the external storage; the
other app (id 2 ) sends the information received (via
SharedPreferences) to a remote server. The Botnet
set consists of four apps. One app (id 3 ) acts as a re-
lay that receives orders from the command and control
center. The other colluding apps execute commands
(delivered via BroadcastIntents) depending on their
permissions: sending SMS messages (id 4 ), stealing
the user’s contacts (id 5 ) and starting and stopping
tasks (id 6 ). The Contact Extractor set consists of
three apps. The ﬁrst (id 7 ) reads contacts from the
address book, the second (id 8 ) forwards them via the
external storage to the third one (id 9 ), which sends
them to the Internet. The ﬁrst and second app com-
municate via BroadcastIntents. The Location Steal-
ing set consists of one app (id 12 ) that reads the user
location and shares it with the second app (id 13 ),
which sends the information to the Internet.

The three non-colluding apps are a document
viewer (id 10 ), an information sharing app (id 11 )
and a location viewer (id 14 ). The ﬁrst app is able
to display diﬀerent ﬁle types in the device screen and
use other apps (via BroadcastIntents) to share their
uniform resource identiﬁer (URI). The second app re-
ceives text fragments from other apps and sends them
to a remote server. The third app receives a location
from another app (with the same intent used by apps
12 and 13) and shows it to the user on the screen.

5

6.2 Detecting collusion threat with Prolog

Table 6.2 shows the results obtained with our ruled
based approached from Section 3 on the apps from
Section 6.1. The entry “dark red club” in row 1, col-
umn 2 means: the program detects that app id 1 sends
information to app id 2, and these two apps collude
on an “information theft”. As we take communica-
tion direction into consideration, the resulting matrix
is non-symmetric, e.g., there is no entry in row 2, col-
umn 1. The entry “light red club” in row 1, column 10
means: the program ﬂags collusion of type “informa-
tion theft” though the set {id 1, id 10} is clean.The
approach identiﬁes all colluding app sets. It also ﬂags
eight false positives due to over-approximation. Note,
that there are no false negatives due to the nature
of our test set:
it utilises only those communication
methods that our Prolog approach is able to identify.

6.3 Computing collusion possibility

Table 6.3 shows results from our alternative approach
from Section 4 on the same set of apps. Each cell de-
notes the Lτ value for the corresponding pair. To min-
imise false negatives, we use the lower bound (=0.50)
gained from the validation data set for the discrimi-
nant line as threshold for Lτ . We report possible col-
lusion if Lτ ≥ 0.5 and Lcom = 1, otherwise we report
non-collusion. This yields symmetric data – for read-
ability we leave the lower half of the matrix empty.
Dark red shows true positives, light red shows false
positives, dark green shows true negatives, and light
green shows false negatives.

This approach ﬁnds two of the four colluding app
sets and ﬂags ﬁve false positives.
It relies on a 3rd
party tool to detect inter-app communication which
ignores communication using SharedPreferences, thus
the app set {id 1, id 2} is not detected. As we restrict
ourselves to pairwise analysis only, the app set {id 7, id
9} can’t be detected, as it communicates via id 8. Fi-
nally, app set {id 12, id 13} was not reported since its
Lτ value is less than the chosen threshold. Choosing
a lower threshold could avoid this false negative, but
at the cost of a lower class accuracy and performance.
A precise estimation of Lcom would be useful in or-
der to reduce the number of false positives in our anal-
ysis. However, communication is only a necessary, not
a suﬃcient condition for collusion. A recent study [10]
shows that 84.4% of non-colluding apps in the mar-
ket place can communicate with other apps either us-
ing explicit (11.3%) or implicit (73.1%) intent calls.
Therefore the threat element (i.e. Lτ ) is far more in-
formative in collusion estimation than the communi-
cation element (Lcom) in our model.

Both approaches to detect the potential of collusion
are constrained in terms of the type of inter-app com-

munication channels they account for due to reasons
explained previously. This makes it diﬃcult to provide
for a straightforward comparison. The rule-based ap-
proach is not limited to pairs of set for collusion (which
may involve more than two apps). It also allows us as-
sess for the direction of the colluding behaviour (for
cases of information ﬂow). Deﬁning rules requires ex-
pert knowledge and for some cases explicit rules may
not exist; this is overcome by providing for rules to
over-approximate for potentially colluding behaviour.
A statistical approach, on the other hand, has the
advantage that it can reﬂect on varying degrees of pos-
sible collusion for a given set of apps. In this paper we
have largely focused on static attributes, such as per-
missions, a number of other similar static attributes
(such as developer ID, download metrics, and so on)
may also be placed on a scale of suspicion for collusion;
albeit the current implementation of the statistical ap-
proach in this paper is limited due to tool availability.

6.4 Software model-checking
We inspect two sets of applications, one colluding {id
12, id 13} and another non-clouding pair {id 12, id
14} with software model checking as described in Sec-
tion 5. The sender id 12 and receiver (id 13 or id
14 ) communicate via broadcast messages containing
the details of the GPS location. In the colluding case
the broadcast is successful, i.e., the sender reads the
GPS location then broadcasts it, and the receiver gets
the broadcast then publishes the GPS location on the
internet.
In the non-colluding case, the sender still
broadcasts the private data which reaches the receiver
but this data is never published.
Instead, the re-
ceiver publishes something else. The data-ﬂow analy-
sis shows, for the non-colluding case, that the private
data is received but is never published. This aspect is
not obvious for our Prolog ﬁlter. Similarly, the data-
ﬂow analysis detects collusion in the ﬁrst case and re-
ports its path witnesses, such as:
<trace> call(readSecret, p1)
-> r1 := callRet(readSecret)
-> call(getBroadcast,r1,r1,"locsteal",p1)
-> call(sendBroadcast,"locsteal",r1)
-> r2 := callRet(getBroadcast)
-> call(publish,r2)
</trace>

7 Related work

App collusion can be traced back to confused deputy
attacks [12]. They happen in form of permission re-
delegation attacks [11, 8, 24] when a permission is care-
lessly exposed through a public component. Sound-
comber [21] is an example where extracted information
is transmitted using both overt and covert channels.

6

ID
1
2
3
4
5
6
7
8
9
10
11
12
13
14

1

2
0.51

3
0.61
0.48

4
0.97
0.62
0.69

5
1
0.55
0.64
1

6
0.8
0.49
0.56
0.84
0.84

7
1
0.55
0.64
1
1
0.84

8
0.81
0.58
0.48
0.85
0.86
0.68
0.86

9
0.77
0.51
0.61
0.71
0.67
0.58
0.67
0.51

10
0.77
0.51
0.61
0.71
0.67
0.58
0.67
0.51
0.77

11
0.77
0.58
0.72
0.82
0.82
0.65
0.82
0.58
0.77
0.77

12
0.44
0.31
0.41
0.56
0.47
0.43
0.47
0.31
0.44
0.44
0.47

13
0.44
0.31
0.41
0.56
0.47
0.43
0.47
0.31
0.44
0.44
0.47
0.47

14
0.95
0.49
0.58
0.95
1
0.78
1
0.77
0.61
0.61
0.73
0.41
0.41

Table 3: Matrix for collusion possibility.

Marforio et al. [16] deﬁne colluding applications as
those applications that cooperate in a violation of some
security property of the system. Another deﬁnition is
given by [15] where multiple apps can come together to
perform a certain task, which is out of their permission
capabilities. The malicious component of collusion is
also acknowledged by Bagheri, Sadeghi et al. [19]. A
more detailed deﬁnition is given by Elish [10], which
deﬁnes it as the collaboration between malicious apps,
likely written by the same adversary, to obtain a set
of permissions to perform attacks.

ComDroid [6] is a static analysis tool that looks
for confused deputies through Intents. XManDroid [3]
and TrustDroid [4] extend the Android OS. Both allow
for ﬁne-grained policies that control inter-app informa-
tion exchange; none of them address covert channels.
In [22] authors analyze, using diﬀerent risk metrics,
several compartmentalisation strategies to minimise
the risk of app collusion, showing two or three app
compartments drastically reduce the risk of collusion
for a set of 20 to 50 apps.

8 Summary

We have presented a new, concise deﬁnition of collu-
sion in the context of Android OS. Colluding apps may
carry out information theft, money theft, or service
misuse; to this end, malware is distributed over multi-
ple apps. As demonstrated by Soundcomber (and our
own app set), collusion is a possibility – but it is yet
unclear whether it exists in the wild. Together with
our industrial partner Intel Security, we have devel-
oped a number of approaches towards eﬀectively de-
tecting collusion. Early experimental results on small
app sets (of a size nearly the scale of the number of
apps one has on a phone) look promising: a combi-
nation of the rule based approach and the machine
learning approach could serve as a ﬁlter, after which
we employ model checking as a decision procedure.

9 Future work

A frontal attack on detecting collusions to analyse
analysing pairs, triplets and larger sets is not practical
given the search space. An eﬀective collusion-discovery
tool must include an eﬀective set of methods to isolate
potential sets which require further examination.

We have to emphasise that such tools are essen-
tial for many collusion-detection methods. Besides
our model checking approach, one could, for example,
think of the approach to merge pair of apps into a sin-
gle app to inspect aggregated data ﬂows [14]. Merging
is slow and therefore app-combining approach is pred-
icated on eﬀective ﬁltering of app pairs of interest.

Alternatively (or additionally), to the two ﬁlters
described in our paper, imprecise heuristic methods
to ﬁnd “interesting” app sets may include: statistical
code analysis of apps (e.g. to locate APIs potentially
responsible to communication, accessing sensitive in-
formation, etc.); and taking into account apps’ pub-
lication time and distribution channel (app market,
direct installation, etc.).

Attackers are more likely to release colluding apps
in a relatively short time frame and that they are likely
to engineer the distribution in such a way that suﬃ-
cient number of users would install the whole set (likely
from the same app market). To discover such sce-
narios one can employ: analysis of security telemetry
focused on users devices to examine installation/re-
moval of apps, list of processes simultaneously execut-
ing, device-speciﬁc APK download/installation logs
from app markets (like Google PlayTM) and meta-data
about APKs in app markets (upload time by develop-
ers, developer ID, source IP, etc.). Such data would al-
low constructing a full view of existing app sets on user
devices. Only naturally occurring sets (either installed
on same device or actually executing simultaneously)
may be analysed for collusion which should drastically
reduce the number of sets that require deeper analysis.
Our goal is to build a fully automated and eﬀective
collusion detection system, and tool performance will
be central to address scale. It is not clear yet where
the bottleneck will be when we apply our approach to

7

real-life apps. Further work will focus on identifying
these bottlenecks to optimise the slowest elements of
our tool-chain. Detecting covert channels would be a
challenge as modelling such will not be trivial.

Acknowledgement

This work has been funded by EPSRC and we are
excited to work on this challenging piece of research1.

References

[1] Android Open Source Project. Dalvik Byte-
code. https://source.android.com/devices/
tech/dalvik/dalvik-bytecode.html, 2016.

[2] S. Arzt, S. Rasthofer, C. Fritz, E. Bodden, A. Bar-
tel, J. Klein, Y. Le Traon, D. Octeau, and P. Mc-
Daniel. FlowDroid: precise context, ﬂow, ﬁeld,
object-sensitive and lifecycle-aware taint analysis
for Android apps. In ACM SIGPLAN Notices -
PLDI’14, volume 49, pages 259–269. ACM, 2014.

[3] S. Bugiel, L. Davi, A. Dmitrienko, T. Fischer, and
A.-R. Sadeghi. XManDroid: A new Android evo-
lution to mitigate privilege escalation attacks. TU
Darmstadt, TR-2011-04, 2011.

[4] S. Bugiel, L. Davi, A. Dmitrienko, S. Heuser,
A.-R. Sadeghi, and B. Shastry. Practical and
lightweight domain isolation on Android.
In
SPSM’11, pages 51–62. ACM, 2011.

[5] J. Burket, L. Flynn, W. Klieber, J. Lim, W. Shen,
and W. Snavely. Making DidFail succeed: En-
hancing the CERT static taint analyzer for An-
droid app sets. CMU/SEI-2015-TR-001. 2015.

[6] E. Chin, A. P. Felt, K. Greenwood, and D. Wag-
ner. Analyzing inter-application communication
in Android. In MobiSys’11, pages 239–252, 2011.

[7] M. Clavel, F. Duran, S. Eker, P. Lincoln,
N. Martı-Oliet, J. Meseguer, and C. Talcott. All
about Maude. LNCS, 4350, 2007.

[8] L. Davi, A. Dmitrienko, A.-R. Sadeghi, and
M. Winandy. Privilege escalation attacks on An-
droid.
In Information Security, pages 346–360.
2010.

[9] A. Desnos. Androguard. https://github.com/

androguard/androguard, 2016.

[10] K. O. Elish, D. Yao, and B. G. Ryder. On the need
of precise inter-app ICC classiﬁcation for detect-
ing Android malware collusions. In MoST, 2015.

1All code related to the project can be found in our GitHub

page: https://www.github.com/acidrepo

[11] A. P. Felt, H. J. Wang, A. Moshchuk, S. Hanna,
and E. Chin. Permission re-delegation: Attacks
and defenses. In USENIX Security 2011.

[12] N. Hardy. The confused deputy:(or why capabil-
ities might have been invented). ACM SIGOPS
Operating Systems Review, 22(4):36–38, 1988.

[13] K. Krishnamoorthy. Handbook of statistical dis-

tributions with applications. CRC Press, 2015.

[14] L. Li, A. Bartel, T. F. Bissyand´e, J. Klein, and
Y. Le Traon. ApkCombiner: Combining multiple
Android apps to support inter-app analysis.
In
SEC’15, pages 513–527. Springer, 2015.

[15] T. Mall and S. Gupta. Critical evaluation of secu-
rity framework in Android applications: Android-
level security and application-level security. Int.
Res. J. of Comp. and Elec. Engg., 2, 2014.

[16] C. Marforio, A. Francillon, and S. Capkun. Ap-
plication collusion attack on the permission-based
security model and its implications for modern
smartphone systems. technical report, 2011.

[17] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy. Us-
ing probabilistic generative models for ranking
risks of Android apps. In CCS’12, pages 241–252.

[18] G. Rosu. From rewriting logic, to programming
language semantics, to program veriﬁcation.
In
Logic, Rewriting, and Concurrency, pages 598–
616. 2015.

[19] A. Sadeghi, H. Bagheri, and S. Malek. Analysis
of Android inter-app security vulnerabilities using
COVERT. In ICSE’15, pages 725–728, 2015.

[20] B. P. Sarma, N. Li, C. Gates, R. Potharaju,
C. Nita-Rotaru, and I. Molloy. Android permis-
sions: a perspective combining risks and beneﬁts.
In SACMAT’12, pages 13–22. ACM, 2012.

[21] R. Schlegel, K. Zhang, X.-y. Zhou, M. Int-
wala, A. Kapadia, and X. Wang. Soundcomber:
A stealthy and context-aware sound trojan for
smartphones. In NDSS’11, pages 17–33, 2011.

[22] G. Suarez-Tangil, J. E. Tapiador, and P. Peris-
Lopez. Compartmentation policies for Android
apps: A combinatorial optimization approach. In
Network and System Security, pages 63–77. 2015.

[23] G. Suarez-Tangil, J. E. Tapiador, P. Peris-Lopez,
and A. Ribagorda. Evolution, detection and anal-
ysis of malware for smart devices. Comm. Surveys
& Tutorials, IEEE, 16(2):961–987, 2014.

8

[24] L. Wu, X. Du, and H. Zhang. An eﬀective ac-
cess control scheme for preventing permission leak
in Android. In Comp., Networking and Comm.,
pages 57–61. IEEE, 2015.

9

