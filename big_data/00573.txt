6
1
0
2

 
r
a

M
2

 

 
 
]

Y
S
.
s
c
[
 
 

1
v
3
7
5
0
0

.

3
0
6
1
:
v
i
X
r
a

A jammer’s perspective of reachability and LQ optimal control (cid:63)

Sukumar Srikant a, Debasish Chatterjee a,

aSystems & Control Engineering, Indian Institute of Technology Bombay, Powai, Mumbai 400076, India.

Abstract

This article treats two problems dealing with control of linear systems in the presence of a jammer that can sporadically turn oﬀ the
control signal. The ﬁrst problem treats the standard reachability problem, and the second treats the standard linear quadratic regulator
problem under the above class of jamming signals. We provide necessary and suﬃcient conditions for optimality based on a nonsmooth
Pontryagin maximum principle.

Key words: sparse control, L0-seminorm, optimal control, adaptive control

Introduction

1
Given a controllable linear system

˙x(t) = Ax(t) + Bu1(t)

with x(t) ∈ Rd and u1(t) ∈ Rm, 1 we let a jammer corrupt
the control u1 with a signal t (cid:55)−→ u2(t) ∈ {0, 1} that enters
multiplicatively, and that can sporadically be “turned oﬀ”,
i.e., set to 0. The eﬀect, therefore, of u2 turning oﬀ is that
the control u1 is deactivated simultaneously, and the sys-
tem evolves in open-loop. The signal u2 provides a stan-
dard model for denial-of-service attacks for control systems
in which the controller communicates with the plant over a
network, and such models have been extensively studied in
the context of cyberphysical systems; see, e.g., [17] and the
references therein. In this setting we ask whether it is possi-
ble to construct a control t (cid:55)−→ u1(t) to execute the transfer
of states of the resulting system

˙x(t) = Ax(t) + Bu1(t)u2(t)

(1)

from given initial to given ﬁnal states. Or, for instance,
whether it is possible to stabilize the resulting system (1) to
the origin by suitably designing the control u1. Since both
these problems are trivially impossible to solve if the jam-
mer turns the signal u2 ‘oﬀ’ entirely, to ensure a well-deﬁned

(cid:63) This paper was not presented at any IFAC meeting. Correspond-
ing author D. Chatterjee. Tel. +91-22-2576-7879. Fax +91-22-
2572-0057.

(cid:18)

Email addresses: srikant.sukumar@iitb.ac.in (Sukumar

(cid:19)
Srikant), dchatter@iitb.ac.in (Debasish Chatterjee).
1 By controllability here we mean that the rank of the matrix
B AB ··· Ad−1B

is equal to d.

(cid:82) t+T

t

problem, in the adaptive control literature typically a persis-
tence of excitation condition, such as, there exist T, ρ > 0
u2(s) ds (cid:62) ρ, is imposed
such that for all t we have 1
T
on u2. Very little, however, is known about either reacha-
bility or stabilizability of (1) under the above persistence of
excitation condition. In particular, the problem of designing
a state feedback u1(t) (cid:66) K(t)x(t) such that the closed-loop
system is asymptotically stable under the preceding persis-
tence of excitation condition, is open, with partial solutions
reported in [19], [12].
In this article we study two problems concerning the con-
trol system (1). In the ﬁrst problem we turn the above-
mentioned reachability question around and examine the
limits of favourable conditions for the jammer. We ask the
question: how long does the jamming signal u2 need to be
set to ‘on’ or 1 for the aforementioned reachability problem
to be solvable? To wit, we are interested in the limiting con-
dition such that if the jamming signal u2 is set to ‘oﬀ’ or
0 for any longer time, then the standard reachability prob-
lem for (1) under the control u1 would cease to be feasible.
More precisely, we study the optimal control problem: given
initial time ¯t and ﬁnal time ˆt > ¯t,

minimize

u1,u2

subject to



(cid:107)u2(cid:107)L0([¯t,ˆt])
˙z(t) = Az(t) + Bu1(t)u2(t)
z(¯t) = ¯z ∈ Rd,
z(ˆt) = ˆz ∈ Rd,
u1 : [¯t, ˆt] −→ U ⊂ Rm compact,
u2 : [¯t, ˆt] −→ {0, 1},
u1, u2 Lebesgue measurable,

for a.e. t ∈ [¯t, ˆt],

(2)
Here the cost function is the L0-seminorm of the control u2,
deﬁned to be the Lebesgue measure of the set of times at

Preprint submitted to Automatica

3 March 2016

which the control is non-zero, i.e.,

(cid:16)(cid:8)s ∈ [¯t, ˆt]

(cid:12)(cid:12)(cid:12) u2(s) (cid:44) 0(cid:9)(cid:17)

.

(cid:107)u2(cid:107)L0([¯t,ˆt]) (cid:66) Leb

We assume that the time diﬀerence ˆt − ¯t is larger than the
minimum time required to execute the transfer of the states
from ¯z to ˆz in order to have a well-deﬁned problem, and in
addition assume that 0 ∈ Rm is contained in the interior of
U. Notice that while the control u1 tries to execute the de-
sired manoeuvre, the control u2 tries to switch to ‘on’ for
the least length of time to enable execution of the afore-
mentioned manoeuvre. We provide necessary conditions for
these reachability manoeuvres and in addition provide con-
ditions for optimality in (2).
The second problem that we study in this article is that of the
performance of the linear quadratic regulator with respect
to the control u1 in the presence of the jammer u2. We ask
the question: How good is the performance of the standard
linear quadratic regulator when the jammer corrupts the u1
signal by turning it ‘oﬀ’ sporadically? To be precise, given
symmetric and non-negative deﬁnite matrices Q f , Q ∈ Rd×d
and a symmetric and positive deﬁnite matrix R ∈ Rm×m,
initial time ¯t and ﬁnal time ˆt > ¯t, we study the following
optimal control problem:

(cid:68)
(cid:90) ˆt
γ(cid:107)u2(cid:107)L0([¯t,ˆt]) + 1
(cid:16)(cid:104)z(t), Qz(t)(cid:105) + (cid:104)u1(t), Ru1(t)(cid:105)(cid:17)

z(t), Q f z(t)

(cid:69)

2

dt
for a.e. t ∈ [¯t, ˆt],

(3)
where γ > 0 is a ﬁxed constant. If u2 is set to ‘oﬀ’ for the
entire duration [¯t, ˆt], the cost accrued by the quadratic terms
corresponding to an L2([¯t, ˆt]) cost involving the states z and
the control u1 will be high. If u2 is set to ‘on’ for the entire
duration [¯t, ˆt], the cost corresponding to (cid:107)u2(cid:107)L0([¯t,ˆt]) will be
high. Any solution to the optimal control problem (3) strikes
a balance between the two costs: L2([¯t, ˆt])-costs with respect
to u1 and the states, and the L0([¯t, ˆt])-cost with respect to u2.
As in the case of (2), we provide necessary conditions for
solutions to (3), and in addition provide suﬃcient conditions
for optimality in (3).
It turns out that the optimal control u∗
1 corresponding to
the optimal control problem (2) is the sparsest control that
achieves the steering of the states from ¯z to ˆz within the al-
lotted time ˆt− ¯t — see Remark 4. The optimal control prob-
lem (3) is closely related to the “sparse quadratic regulator”
problem treated in [8]; see Remark 8. While the authors of
[8] approached the optimal control problem using approx-
imate methods via L1 and total variation relaxations, it is
possible to tackle the problem directly without any approx-
imations, as we demonstrate in Remark 8. Sparse controls

minimize

u1,u2

subject to



+ 1
2

¯t

˙z(t) = Az(t) + Bu1(t)u2(t)
z(¯t) = ¯z ∈ Rd,
u1 : [¯t, ˆt] −→ Rm,
u2 : [¯t, ˆt] −→ {0, 1},
u1, u2 Lebesgue measurable,

are increasingly becoming popular in the control community
with pioneering contributions from [10], [8], [11], [6], [1],
[14], [7], [13], [15], [16]. Two distinct threads have emerged
in this context: one, dealing with the design of sparse con-
trol gains, as in [1], [15], [16], and two, dealing with the
design of sparsest control maps as functions of time, as evi-
denced in the articles [8], [13], [7], [14]. With respect to [1],
[15], [16] our work diﬀers in the sense that we do not de-
sign sparse feedback gains, but are interested in the design
of sparse control maps that attain certain control objectives.
The articles [8], [13], [7], [14] deal with L0-optimal control
problems, but none of them treat the precise conditions for
L0-optimality, preferring instead to approximate sparse so-
lutions with the aid of L1-regularized optimal control prob-
lems. To the best of our knowledge, this is the ﬁrst time
that the two optimal control problems (2) and (3) are being
studied.
Observe that both the optimal control problems (2) and (3)
involve discontinuous instantaneous cost functions, and are
consequently diﬃcult to solve. We employ a nonsmooth ver-
sion of the Pontryagin maximum principle to solve these two
problems and study the nature of their solutions. Insofar as
the existence of optimal controls is concerned, once again,
the discontinuous nature of the instantaneous cost functions
lends a nonstandard ﬂavour to the above two problems. We
derive our suﬃcient conditions for optimality with the aid of
what is known as an inductive technique. These results are
presented in §2. We provide detailed numerical experiments
in §3 and conclude in §4.
Our notations are standard; in particular, for a set S we let
1S (·) denote the standard indicator/characteristic function
deﬁned by 1S (z) = 1 if z ∈ S and 0 otherwise, and we denote
by (cid:104)v, w(cid:105) = v(cid:62)w the standard inner product on Euclidean
spaces.

2 Main Results
We apply the nonsmooth maximum principle [5, Theorem
22.26] to the optimal control problems (2) and (3), for which
we ﬁrst adapt the aforementioned maximum principle from
[5] to our setting, and refer the reader to [5] for related
notations, deﬁnitions, and generalizations:
Theorem 1 Let −∞ < ¯t < ˆt < +∞, and let U ⊂ Rm de-
note a Borel measurable set. Let a lower semicontinuous
instantaneous cost function Rd × U (cid:51) (ξ, µ) (cid:55)−→ Λ(ξ, µ) ∈
R, with Λ continuously diﬀerentiable in ξ for every ﬁxed
µ, 2 and a continuously diﬀerentiable terminal cost function
(cid:96) : Rd × Rd −→ R be given. Consider the optimal control

2 Recall that a map ϕ : X −→ R from a topological space X into
the real numbers is said to be lower semicontinuous if for every
c ∈ R the set {z ∈ X | ϕ(z) (cid:54) c} is closed.

2

problem

minimize

u

subject to

(cid:90) ˆt
Λ(cid:0)x(t), u(t)(cid:1) dt
(cid:96)(cid:0)x(¯t), x(ˆt)(cid:1) +

˙x(t) = f(cid:0)x(t), u(t)(cid:1)
(cid:0)x(¯t), x(ˆt)(cid:1) ∈ E ⊂ Rd × Rd,

u(t) ∈ U for a.e. t ∈ [¯t, ˆt],
u Lebesgue measurable,

¯t

for a.e. t ∈ [¯t, ˆt],

(4)
where f : Rd × Rm −→ Rd is continuously diﬀerentiable,
and E is a closed set. For a real number η, we deﬁne the
Hamiltonian Hη by

Hη(x, u, p) = (cid:104)p, f (x, u)(cid:105) − ηΛ(x, u).

If [¯t, ˆt] (cid:51) t (cid:55)−→ (cid:0)x∗(t), u∗(t)(cid:1) is a local minimizer of (4),

then there exist an absolutely continuous map p : [¯t, ˆt] −→
Rd together with a scalar η equal to 0 or 1 satisfying the
nontriviality condition

(cid:0)η, p(t)(cid:1) (cid:44) 0

for all t ∈ [¯t, ˆt],

(5)

E

(6)

(7)

adjoint equation

for a.e. t ∈ [¯t, ˆt],

the transversality condition

the Hamiltonian maximum condition

where ∂x(cid:96) is the gradient of (cid:96) and NL
E

(cid:0)x∗(¯t), x∗(ˆt)(cid:1),
(cid:0)p(¯t),−p(ˆt)(cid:1) ∈ η∂x(cid:96)(cid:0)x∗(¯t), x∗(ˆt)(cid:1) + NL
(cid:0)x∗(¯t), x∗(ˆt)(cid:1) is the
limiting normal cone of E at the point (cid:0)x∗(¯t), x∗(ˆt)(cid:1), 3 the
− ˙p(t) = ∂xHη(cid:0)·, u∗(t), p(t)(cid:1)(x∗(t))
Hη(cid:0)x∗(t), u∗(t), p(t)(cid:1) = sup
Hη(cid:0)x∗(t), u∗(t), p(t)(cid:1) = h

for a.e. t ∈ [¯t, ˆt] and some h ∈ R.
(9)
The assumptions of [5, Theorem 22.26] are considerably
weaker than what we have stipulated above; we refer the
reader to [5, Chapter 22] for details.
lift of the optimal state-action trajectory [¯t, ˆt] (cid:51) t

The quadruple(cid:0)η, p(·), x∗(·), u∗(·)(cid:1) is known as the extremal
(cid:0)x∗(t), u∗(t)(cid:1). The number η is called the abnormal multi-

Hη(cid:0)x∗(t), v, p(t)(cid:1)

as well as the constancy of the Hamiltonian

(cid:55)−→

for a.e. t ∈ [¯t, ˆt],
(8)

v∈U

plier. The abnormal case — when η = 0 — may arise, e.g.,
when the constraints of the optimal control problem are
so tight that the cost function plays no role in determining

3 The limiting normal cone of a closed subset S of Rν is deﬁned
by means of a closure operation applied to the proximal normal
cone of the set S ; see, e.g., [5, p. 240] for the deﬁnition of the
proximal normal cone, and [5, p. 244] for the deﬁnition of the
limiting normal cone.

3

the optimal solution t (cid:55)−→ (cid:0)x∗(t), u∗(t)(cid:1) is “isolated” in the

the solution. For instance, we have an abnormal case when

sense that there is no other solution satisfying the end-point
constraints in the vicinity — as measured by the supremum
norm — of the optimal solution.
2.1 Reachability
We recast the problem (2) as an optimal control problem
with a discontinuous cost function as follows: Since (cid:107)u2(cid:107)L0
=
1{0}(u2(s)) ds, the optimal control problem (2) is

ˆt − ¯t −(cid:82) ˆt

¯t

equivalent to

minimize

u1,u2

subject to

(cid:90) ˆt

¯t

−



1{0}(u2(s)) ds

˙z(t) = Az(t) + Bu1(t)u2(t)
z(¯t) = ¯z ∈ Rd,
z(ˆt) = ˆz ∈ Rd,
u1 : [¯t, ˆt] −→ U ⊂ Rm compact,
u2 : [¯t, ˆt] −→ {0, 1},
u1, u2 Lebesgue measurable,

for a.e. t ∈ [¯t, ˆt],



(10)
Measurability of the instantaneous cost function in (10) fol-
lows from the fact that it is an indicator function of a closed
set in Rm. Theorem 1 applied to the optimal control problem
(10) yields the following:
Theorem 2 Consider the optimal control problem (10). As-
sume that ˆt− ¯t is larger than the minimum time necessary to
execute the transfer z(¯t) = ¯z to z(ˆt) = ˆz. Associated to every
an absolutely continuous map [¯t, ˆt] (cid:51) t (cid:55)−→ p(t) ∈ Rd and a
scalar η = 0 or 1, such that for a.e. t ∈ [¯t, ˆt]:

solution [¯t, ˆt] (cid:51) t (cid:55)−→ (cid:0)z∗(t), u∗

2(t)(cid:1) to (10) there exist

1(t), u∗

1(t)u∗

2(t),

z∗(¯t) = ¯z, z∗(ˆt) = ˆz,

˙z∗(t) = Az∗(t) + Bu∗
(cid:68)
˙p(t) = −A(cid:62) p(t),
1(t) ∈ arg max
u∗
v1∈U

B(cid:62) p(t), v1

u∗
2(t) =

if supv1∈U
otherwise,


(cid:40)1

0

1

(cid:69)
(cid:10)B(cid:62) p(t), v1

,

(cid:11) (cid:62) 1,

if η = 1,

if η = 0.

equation for t (cid:55)−→(cid:0)z∗(t), p(t)(cid:1), and as such is a well-posed

Theorem 2 features a 2d-dimensional ordinary diﬀerential

problem in view of the fact that there are 2d boundary con-
ditions — the initial and ﬁnal conditions of z∗.
Remark 3 Note that in the abnormal case, i.e., when η = 0,
2(t) ≡ 1 in Theorem 2. This situation may occur,
we have u∗
e.g., when the time diﬀerence ˆt − ¯t is the minimum time
needed to execute the transfer of states from ¯z to ˆz; in this
2(t) ≡ 1 for the entire duration of
situation we must have u∗
the aforementioned execution.
Remark 4 In the normal case, i.e., η = 1, the control u∗
1u∗
2
may be regarded as the sparsest possible control to execute
the reachability manoeuvre in Theorem 2.
Proof of Theorem 2: We employ Theorem 1 to derive our

assertions. Notice that the instantaneous cost function Λ in
this case is solely dependent on the control, so continuous
diﬀerentiability of Λ with respect to the space variable is
automatically satisﬁed. The Hamiltonian function for the
optimal control problem (10) is

Rd × (U × {0, 1}) × Rd (cid:51)(cid:0)ξ, (µ1, µ2), p(cid:1) (cid:55)−→
Hη(cid:0)ξ, (µ1, µ2), p(cid:1) (cid:66) (cid:104)p, Aξ + Bµ1µ2(cid:105) + η1{0}(µ2) ∈ R;

The nontriviality condition in (5) translates to
for all t ∈ [¯t, ˆt].

(cid:0)η, p(t)(cid:1) (cid:44) (0, 0)

E(¯z, ˆz) of E at the point (cid:0)z(¯t), z(ˆt)(cid:1) is Rd × Rd, and

Since E is the singleton (¯z, ˆz) in our case, the limiting normal
cone NL
therefore the transversality condition (6) in our setting is
given by

(cid:0)p(¯t),−p(ˆt)(cid:1) ∈ Rd × Rd.

In other words, the end-points of the adjoint are uncon-
strained. The adjoint equation in (7) is given by

− ˙p(t) = ∂xHη(cid:0)·, u∗

2(t), p(t)(cid:1)(x∗(t)) = A(cid:62) p(t),

1(t), u∗

with the absolutely continuous solution:

p(t) = e−(t−¯t)A(cid:62)

p(¯t)

for all t ∈ [¯t, ˆt].

Since the minimum time needed to execute the transfer
z(¯t) = ¯z to z(ˆt) = ˆz is smaller than ˆt − ¯t, the Hamiltonian
maximization condition (8) is given by

2(t), p(t)(cid:1)
(cid:8)(cid:104)p(t), Az(t) + Bv1v2(cid:105) + η1{0}(v2)(cid:9) ,

Hη(cid:0)z∗(t), u∗

1(t), u∗
= sup
v1∈U
v2∈{0,1}

(cid:69)

(cid:110)(cid:68)

(cid:0)u∗

1(t), u∗

(v1,v2)∈U×{0,1}

v2 + η1{0}(v2)

In other words, if η = 1, then for a.e. t ∈ [¯t, ˆt],

2(t)(cid:1) ∈ arg max
(cid:68)

where the supremum is attained in view of Weierstrass’s
theorem since the function on the right-hand side above is
upper semicontinuous in (v1, v2) and U × {0, 1} is compact.
We see at once that the order of maximization is irrelevant,
(cid:111)
and that the optimal controls are given by
B(cid:62) p(t), v1
(cid:69)
(cid:10)B(cid:62) p(t), v1
(cid:69)

(cid:68)
if η = 0, then for a.e. t ∈ [¯t, ˆt],

1(t) ∈ arg max
u∗
v1∈U
u∗
2(t) =

if supv1∈U
0 otherwise;

(cid:11) (cid:62) 1,

B(cid:62) p(t), v1

(cid:40)1

.

,

B(cid:62) p(t), v1

,

u∗
2(t) = 1.

1(t) ∈ arg max
u∗
v1∈U

4

(cid:3)
The assertion follows at once from the steps above.
In the particular case of the dimension of u1 being 1 and
U = [−1, 1], we have the following simple formulas for the
optimal control if η = 1:

1(t) = sgn(cid:0)B(cid:62) p(t)(cid:1),

u∗

u∗
2(t) =

(cid:40)1

0

(cid:12)(cid:12)(cid:12)B(cid:62) p(t)
(cid:12)(cid:12)(cid:12) (cid:62) 1,

if
otherwise.

(11)

2.2 Linear quadratic performance
The optimal control problem (3) is equivalent to

minimize

u1,u2

subject to

¯t

(cid:68)

(cid:69)

(cid:90) ˆt
(cid:16) 1
(cid:17)
2 (cid:104)z(t), Qz(t)(cid:105) + 1
− γ1{0}(u2(t))

2 (cid:104)u1(t), Ru1(t)(cid:105)
z(ˆt), Q f z(ˆt)
dt + 1
2
for a.e. t ∈ [¯t, ˆt],
˙z(t) = Az(t) + Bu1(t)u2(t)
z(¯t) = ¯z ∈ Rd,
u1 : [¯t, ˆt] −→ Rm,
u2 : [¯t, ˆt] −→ {0, 1},
u1, u2 Lebesgue measurable,



(12)

where γ > 0 is a ﬁxed constant.
Measurability of the instantaneous cost function follows
from the fact that the indicator function is one of a closed
set in Rm. Theorem 1 applied to the optimal control problem
(12) yields the following:
Theorem 5 In the optimal control problem (12), associated
exists an absolutely continuous map [¯t, ˆt] (cid:51) t (cid:55)−→ p(t) ∈ Rd,
such that for a.e. t ∈ [¯t, ˆt]:

to every solution [¯t, ˆt] (cid:51) t (cid:55)−→(cid:0)z∗(t), u∗

2(t)(cid:1) to (12) there

1(t), u∗



˙z∗(t) = Az∗(t) + BR−1B(cid:62) p(t)u∗
˙p(t) = Qz∗(t) − A(cid:62) p(t),
u∗
1(t) =

p(ˆt) = −Q f z∗(ˆt),
if u∗
2(t) = 1,
otherwise,

2(t),

z∗(¯t) = ¯z,

(cid:40)R−1B(cid:62) p(t)
1
(cid:68)

0

0

if
otherwise.

B(cid:62) p(t), R−1B(cid:62) p(t)

(cid:69) (cid:62) γ,

u∗
2(t) =

equation for t (cid:55)−→(cid:0)z∗(t), p(t)(cid:1) with 2d boundary conditions

Theorem 5 features a 2d-dimensional ordinary diﬀerential
— initial condition for z∗ and ﬁnal condition for p. As such
it is a well-posed problem.
Remark 6 Unlike in the reachability manoeuvres treated
above, the abnormal case (η = 0) does not arise in the setting
of Theorem 5, as we shall establish in the proof of Theorem
5 given below.
Remark 7 Note that the optimal control u∗
1 is sparse in the
sense that it is set to ‘oﬀ’ or 0 at certain times. It is in fact the
sparsest control that strikes a balance between the L2([¯t, ˆt])
costs corresponding to the states and control u1 versus the
L0([¯t, ˆt]) costs corresponding to the signal u2.

Proof of Theorem 5: We employ Theorem 1 to derive our
assertions. Notice that the instantaneous cost function Λ in
this case depends quadratically on the states and on the con-
trol u1 in addition to the L0([¯t, ˆt]) seminorm of the signal
u2, so continuous diﬀerentiability of Λ with respect to the
space variable is satisﬁed. The Hamiltonian function corre-
sponding to the optimal control problem (12) is given by

2 (cid:104)µ1, Rµ1(cid:105) − γ1{0}(µ2)(cid:1) ∈ R.

Rd × (Rm × {0, 1}) × Rd (cid:51)(cid:0)ξ, (µ1, µ2), p(cid:1) (cid:55)−→
Hη(cid:0)ξ, (µ1, µ2), p(cid:1) (cid:66) (cid:104)p, Aξ + Bµ1µ2(cid:105)
− η(cid:0) 1
2 (cid:104)ξ, Qξ(cid:105) + 1
(cid:0)η, p(t)(cid:1) (cid:44) (0, 0)

Since the ﬁnal cost function (cid:96)(cid:0)z(ˆt)(cid:1) = 1

(cid:68)
for all t ∈ [¯t, ˆt].

The nontriviality condition (5) translates to the condition

is
smooth, the object ∂x(cid:96) is precisely the gradient Q f z(ˆt) of
(cid:96), and since the constraint at the ﬁnal time is absent, the
transversality condition (6) becomes
−p(ˆt) = ηQ f z∗(ˆt).

z(ˆt), Q f z(ˆt)

2

(cid:69)

The Hamiltonian is smooth in the space variable ξ; conse-
quently, the adjoint equation (7) is given by

− ˙p(t) = ∂ξHη(cid:0)···, u∗

1(t), u∗
= A(cid:62) p(t) − ηQz∗(t)

2(t), p(t)(cid:1)(cid:0)z∗(t)(cid:1)

a.e. t ∈ [¯t, ˆt].

To wit, the adjoint equation is the following boundary value

problem:(cid:40) ˙p(t) = −A(cid:62) p(t) + ηQz∗(t)

p(ˆt) = −ηQ f z∗(ˆt).

a.e. t ∈ [¯t, ˆt],

We claim that η = 1. Indeed, if not, then the terminal bound-
ary condition −ηQ f z∗(ˆt) and the forcing term ηQz∗(t) in the
adjoint equation both vanish. In view of the resulting linear-
ity of the adjoint equation, the entire map [¯t, ˆt] (cid:51) t (cid:55)−→ p(t) ∈
Rd vanishes. But then this contradicts the nontriviality con-
dition mentioned above. The adjoint equation is, therefore,

given by(cid:40) ˙p(t) = −A(cid:62) p(t) + Qz∗(t)

p(ˆt) = −Q f z∗(ˆt).

a.e. t ∈ [¯t, ˆt],

In view of the preceding analysis we commit to η = 1 and
henceforth write H instead of Hη. We have

H(cid:0)ξ, (µ1, µ2), p(cid:1) = (cid:104)p, Aξ + Bµ1µ2(cid:105) + γ1{0}(µ2)

(cid:0)(cid:104)ξ, Qξ(cid:105) + (cid:104)µ1, Rµ1(cid:105)(cid:1).

− 1

2

Observe that
◦ the order of maximization of the Hamiltonian function H

with respect to the controls is irrelevant;

5

◦ the Hamiltonian function H is smooth and concave in u1
on Rm due to positive deﬁniteness of the matrix R, which
shows that the maximum over u1 ∈ Rm is unique;
◦ the Hamiltonian function H is upper semicontinuous in
u2, and by Weierstrass’s theorem the maximum is attained
on the compact set {0, 1}.

(cid:0)u∗

Therefore, the Hamiltonian maximization condition (8) leads
to: for a.e. t ∈ [¯t, ˆt],
(cid:110)(cid:68)
1(t), u∗

2(t)(cid:1) ∈

(cid:111)

v2 − 1

2 (cid:104)v1, Rv1(cid:105) + γ1{0}(v2)

,

arg max

(v1,v2)∈Rm×{0,1}

B(cid:62) p(t), v1

(cid:69)
(cid:40)R−1B(cid:62) p(t)
1
(cid:68)

0

0

if u∗
2(t) = 1,
otherwise,

(cid:69) (cid:62) γ,

B(cid:62) p(t), u∗

if
otherwise.

1(t)

which gives

and

u∗
1(t) =

u∗
2(t) =

(cid:3)
The assertion follows at once from the steps above.
From Theorem 5 we get the following ‘canonical’ set of
dynamical equations, in which the matrix H(t) is sometimes
referred to as the Hamiltonian matrix:

z∗(t)


p(t)

˙p(t)

˙z∗(t)
 =
(cid:67) H(t)
(cid:26)

Q

2(t)



−A(cid:62)

A BR−1B(cid:62)u∗
z∗(t)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:68)
A BR−1B(cid:62)1S (t)

s ∈ [¯t, ˆt]

p(t)

H(t) =

 .

−A(cid:62)

Q

Letting S (cid:66)
rewrite the Hamiltonian matrix as

B(cid:62) p(s), R−1B(cid:62) p(s)

for a.e. t ∈ [¯t, ˆt].

(cid:69) (cid:62) γ

(cid:27)

, we

Standard arguments as in [9, Chapter 6] may be employed
to show that the state adjoint p(t) is linearly related to z∗(t)
given by p(t) = −P(t)z∗(t), where P(·) satisﬁes the ordinary
diﬀerential equation

˙P(t) + A(cid:62)P(t) + P(t)A + Q

− P(t)BR−1B(cid:62)P(t)1S (t) = 0

for a.e. t ∈ [¯t, ˆt],

(13)

with boundary condition P(ˆt) = Q f . This Riccati equation
(13) is a bona ﬁde “hybrid” ordinary diﬀerential equation;
to our knowledge no closed form solution to this diﬀeren-
tial equation is available. It switches between a Lyapunov
equation and a full-ﬂedged Riccati diﬀerential equation at
time s ∈ [¯t, ˆt] depending on whether (cid:107)p(s)(cid:107)2
BR−1B(cid:62) (cid:62) γ or not,

minimize

u

subject to

(cid:90) ˆt
(cid:16) 1
(cid:17)
2 (cid:104)z(t), Qz(t)(cid:105) + 1
− γ1{0}(u(t))

¯t

˙z(t) = Az(t) + Bu(t)
z(¯t) = ¯z ∈ Rd,
u : [¯t, ˆt] −→ Rm,
u Lebesgue measurable,



2 (cid:104)u(t), Ru(t)(cid:105)
dt + 1
2

(cid:68)
(cid:69)
z(ˆt), Q f z(ˆt)
for a.e. t ∈ [¯t, ˆt],

√(cid:104)·, M·(cid:105) for a symmetric and non-negative
where (cid:107)·(cid:107)M (cid:66)
deﬁnite matrix M. Note that (13) is intimately connected
with the dynamics of the states z∗(·), which makes it a chal-
lenging equation to deal with.
Remark 8 Consider the quadratic regulator problem with
L0-regularization:

(14)
where γ > 0 is a ﬁxed constant. If (z∗, u∗) is an optimal state-
action trajectory solving (14), observe that u∗ is by deﬁnition
sparsest in the sense that it is turned oﬀ for the maximal
duration of time; cf. [8]. Straightforward calculations with
the support of the nonsmooth Pontryagin maximum principle
Theorem 1 shows that the optimal control for the problem
(14) is characterized by

(cid:40)R−1B(cid:62) p(t)

u∗(t) =

0

if (cid:107)p(t)(cid:107)2
otherwise,

BR−1B(cid:62) (cid:62) γ,

where [¯t, ˆt] (cid:51) t (cid:55)−→ p(t) ∈ Rd is an absolutely continuous
map that solves the diﬀerential equation

(cid:40) ˙p(t) = −A(cid:62) p(t) + Qz∗(t),

p(ˆt) = −Q f z∗(ˆt).

The abnormal case (η = 0) does not arise here, as can be
readily seen by mimicking the arguments in the proof of
Theorem 5.
Remark 9 It remains a challenging open problem to ensure
stability of the closed-loop system in the L0-regularized LQ
problem discussed in Remark 8. The standard analysis of
letting the ﬁnal time ˆt → +∞ and analyzing the associated
Riccati equation turns out to be diﬃcult because the Riccati
equation in this setting becomes hybrid, with a discontinuity
set connected to the dynamics of the adjoint p.
2.3 Existence of optimality
So far we have employed necessary conditions for solutions
to (2) and (3) under the aegis of a nonsmooth Pontryagin
maximum principle, but have sidestepped the matter of suf-
ﬁcient conditions for optimality of the state-action trajec-
tories satisfying the necessary conditions. In this subsec-
tion we treat the problem of optimality of such state-action
trajectories. In other words, having identiﬁed the extremals
corresponding to the problems (2) and (3), we wish to as-
certain whether the necessary conditions in Theorem 2 and
Theorem 5 are also suﬃcient for optimality.
To this end, we have the following:

t

2(t))

Proof:

1(t), u∗

are locally optimal.

is aﬃne and therefore concave on the set

action trajectories [¯t, ˆt] (cid:51) t (cid:55)−→ (cid:0)z∗(t), u∗

Proposition 10
(10-a) Consider the problem (2). If there exist adjoint solu-
tions to (2) corresponding to η = 1 satisfying the con-
ditions of Theorem 2, then the corresponding state-

(10-b) For the problem (3) state-action trajectories satisfy-
ing the conditions in Theorem 5 are locally optimal.
(cid:55)−→
(10-a): Assume that η = 1, and let
1(t), u∗

2(t)(cid:1)
2(t)(cid:1) denote a state-action trajectory satisfying
(cid:17) ∈ R

2(t)(cid:11) + 1{0}(u∗

the corresponding assertions of Theorem 2. Pick δ > 0, and
note that the map

(cid:0)z∗(t), u∗
Rd (cid:51) z (cid:55)−→(cid:16)(cid:10)p(t), Az + Bu∗
1(t)u∗
z ∈ Rd(cid:12)(cid:12)(cid:12)(cid:12) (cid:107)z − z∗(t)(cid:107) < δ
(cid:110)
(cid:111)
t (cid:55)−→(cid:0)z∗(t), u∗
2(t)(cid:1) is optimal in the δ-neighborhood of
2(t)(cid:1) denote a state-action
(cid:55)−→ (cid:0)z∗(t), u∗
Rd (cid:51) z (cid:55)−→(cid:18)(cid:10)p(t), Az + Bu∗
2(t)(cid:11) + γ1{0}(u∗
1(t)(cid:11)(cid:17)(cid:19) ∈ R
(cid:16)(cid:104)z, Qz(cid:105) +(cid:10)u∗
(cid:12)(cid:12)(cid:12)(cid:12) (cid:107)z − z∗(t)(cid:107) < δ
(cid:111)
(cid:110)
z ∈ Rd
2(t)(cid:1) in the δ-neighborhood
optimality of t (cid:55)−→(cid:0)z∗(t), u∗

Now [5, Corollary 24.2] applies directly, and implies that
z∗(·).
(10-b): Let t
trajectory satisfying the assertions of Theorem 5. Pick δ > 0.
Assume that the conditions in Theorem 5 hold. Then the
map

for a.e. t ∈
is concave on the set
[¯t, ˆt]. Once again, [5, Corollary 24.2] immediately gives us
of z∗(·).

1(t)u∗
1(t), Ru∗

for a.e. t ∈ [¯t, ˆt].

1(t), u∗

1(t), u∗

1(t), u∗

− 1

2

2(t))

(cid:3)

3 Examples
Example 11 Now we illustrate the optimal control problem
on the Linear Quadratic performance index in the presence of
the jammer, problem (3). The ﬁrst set of simulations consider
a linearized, second-order inverted pendulum dynamics as
below,

A =

1

mgl
I

1
−b
I

 0
 B =
0

 , R = 3, γ = 0.01,
10 0
 , Q f =
3 0

(15)

0 10

0 3

To the aforementioned dynamical system, the optimal con-
trol described by Theorem 5 is applied with parameter val-
ues, m = 2 kg, l = 1 m, g = 9.81 m/s2, I = ml2/3 kgm2, b =

0.02, weights, Q =

6

Linear Quadratic performance (12). The plot of (cid:107)z∗(t)(cid:107) shows
a clear decay to 4e-4 before starting to rise again. (cid:107)z∗(t)(cid:107)
continues to decay well beyond 0.77 s when u∗
2(t) goes to
zero and starts to rise again under the inﬂuence of unstable
dynamics beyond t = 1.25 s. In Figure 1, is also superim-
posed the optimal trajectories corresponding to the classical
Linear Quadratic Regulator (LQR). The corresponding tra-
jectories are obtained simply by setting γ = 0 in the opti-
mal control problem (12). As expected, (cid:107)z∗(t)(cid:107) correspond-
ing to the classical LQR solution converges to about 2e-5,
which is much lower than our non-smooth solution based on
Theorem 5. It is however interesting to note that at around
t = 0.77 s, (cid:107)z∗(t)(cid:107) corresponding to implementation of The-
orem 5 (γ = 0.01) starts to decay at a faster rate than the
classical LQR case (γ = 0). The sudden increase in the de-
cay rate is coincident with deviation of u∗
1(t) from uLQ cor-
responding to the classical LQR solution. The deviation in
the control magnitudes for both cases lasts for about 0.02 s
beyond which u∗
1(t) = 0 while uLQ continues to asymptoti-
cally converge to zero.
In order to illustrate the eﬀect of L0 cost on the jammer,
another set of simulations with γ = 1 is shown in Figure 2
along with the classical LQR control solution. Similar to the
γ = 0.01 case shown in Figure 1, a distinct change in the
control magnitude is observed at around 0.35s which also
corresponds to faster rate of decay of (cid:107)z∗(t)(cid:107) with the LQ+L0
based control from 0.35 − 0.85 s. However, as expected, a
higher weightage on the L0 norm of the jammer results in
2(t) = 0 (≈1.45 s), as compared to
longer span of time with u∗
the previous case with γ = 0.01 (≈1.15 s). On the contrary,
the least value achieved by (cid:107)z∗(t)(cid:107) is 2e-3 when γ = 1, while
it is 4e-4 for the γ = 0.01 case. These diﬀerences are due to
changes in the relative weightage of each term in the cost
(12).
Example 12 For the next set of simulations, a linearized
inverted pendulum on a cart system is considered. The fourth
order model is represented by,

A =

(16)



 .

0
1
M
0
− 1

 B =

0
0 1
0
0 0 − mg
M 0
0 0
1
0
0 0 (m+M)g
(2Ml) 0


 , Q f = 100, R = 1, γ = 0.1 and initial

(2Ml)

(cid:19)(cid:62)

The optimal control as per Theorem 5 is computed
as in the second order example for parameter values,
m = 2 kg, l = 1 m, g = 9.81 m/s2, M = 2 kg, weights,



1 0 0 0
0 1 0 0
0 0 1 0
0 0 0 1

(cid:18)

Q =

0 π/10 0 0

conditions, x0 =
(cid:107)z∗(t)(cid:107) evolution with the optimal control, u∗
u∗
2(t) for a time span of 1.9 s.

. Figure 3 shows the plot of
1(t) and jammer,

a. Norm of states (cid:107)z∗(t)(cid:107) against t

b. Control u∗

1(t) and jammer u∗

2(t) against t

Fig. 1. Inverted pendulum stabilization with γ = 0.01

 0

π/10

. The integration tolerance

and initial conditions x0 =

for all cases is kept at 1e-4.
The two point boundary value problem (TPBVP) arising
from Theorem 5 is solved using a multiple-shooting tech-
nique [3]. The aim of multiple shooting is to iterate on an
appropriate value of p(¯t) such that given an initial condition,
z∗(¯t), the ﬁnal constraint, p(ˆt) = −Q f z∗(ˆt) is satisﬁed. The
iterates are computed using a suitable nonlinear program-
ming (NLP) technique. The current article utilizes the trust-
region based fmincon routine in MATLAB c(cid:13). A compari-
son of numerical eﬃciency of NLP schemes can be found
in [2], [18], [4]. The simulated results for a time span of
2 s are shown in Figure 1. The plots show the evolution of
(cid:107)z∗(t)(cid:107) as well as the commanded control u∗
1(t) and jammer
u∗
2(t). The jammer signal u∗
2(t) goes to zero approximately
beyond 0.75 s as evident from the plots. For the given set
of parameter values, initial conditions and weights this indi-
cates the maximum duration over which the control can be
switched oﬀ while still optimizing the prescribed modiﬁed

7

LQ+L0LQtime(s)∥z∗(t)∥00.20.40.60.811.21.41.61.8210−510−410−310−210−11001u1(t)u2(t)uLQ (t)time(s)u(t)00.20.40.60.811.21.41.61.82−3.5−3−2.5−2−1.5−1−0.500.511a. Norm of states (cid:107)z∗(t)(cid:107) against t

a. Norm of states (cid:107)z∗(t)(cid:107) against t

b. Control u∗

1(t) and jammer u∗

2(t) against t

Fig. 2. Inverted pendulum stabilization example with γ = 1

The optimal jammer signal, u∗
2(t) is initially non-zero and
goes intermittently to zero for a short time span around 0.2 s
and 1.5 s indicating zero control input to the system. On
careful examination of the (cid:107)z∗(t)(cid:107) plot, the phase of zero
control is reﬂected in the form of sharp changes in the norm.
After a period of initial decay up to around t = 0.9 s, (cid:107)z∗(t)(cid:107)
rises again. Compared to the second order case, the controls
1(t)u∗
u∗
2(t) are required to be ‘on’ for a larger percentage of
the simulation window as observed from the plots.

4 Conclusion
We have studied the reachability problem (2) and the LQ
optimal control problem (3), both in the presence of a jam-
mer, and have derived necessary and suﬃcient conditions
for optimality in §2; our primary analytical apparatus was a
non-smooth Pontryagin maximum principle. In §3 we have
compared the performance of the linear quadratic problem
in the presence of a jammer against its standard operation.

8

b. Control u∗
Fig. 3. Inverted pendulum on cart stabilization

1(t) and jammer u∗

2(t) against t

Acknowledgements
The authors thank Harish Pillai and Debasattam Pal for help-
ful discussions on the Riccati equation. S. Srikant was sup-
ported in part by the grant 12IRCCSG007 from IRCC, IIT
Bombay. D. Chatterjee was supported in part by the grant
12IRCCSG005 from IRCC, IIT Bombay.

References
[1] M. Bahavarnia, Sparse linear-quadratic feedback design using aﬃne

approximation. http://arxiv.org/pdf/1507.08592.pdf, 2015.

[3]

large-scale nonlinear optimization algorithms,

[2] H. Y. Benson, D. F. Shanno, and R. J. Vanderbei, A comparative
study of
in High
performance algorithms and software for nonlinear optimization,
Springer, 2003, pp. 95–127.
J. T. Betts, Practical Methods for Optimal Control and Estimation
using Nonlinear Programming, Advances in Design and Control 19,
Society for Industrial & Applied Mathematics, 2nd edition ed., 2009.
J. T. Betts, S. Eldersveld, and W. Huffman, A performance
comparison of nonlinear programming algorithms for large sparse
problems, in AIAA Guidance, Navigation and Control Conference,
1993, pp. 443–455.

[4]

LQ+L0LQtime(s)||z∗(t)||00.20.40.60.811.21.41.61.8210−510−410−310−210−11001011u1(t)u2(t)uLQ(t)time(s)u(t)00.20.40.60.811.21.41.61.82−4−3−2−10121time(s)∥z∗(t)∥00.20.40.60.811.21.41.61.820.30.320.340.360.380.40.420.440.460.481u1(t)u2(t)time(s)u(t)00.20.40.60.811.21.41.61.82−3−2−1012341[5] F. Clarke, Functional Analysis, Calculus of Variations and Optimal
Control, vol. 264 of Graduate Texts in Mathematics, Springer,
London, 2013.

[6] M. Fardad, F. Lin, and M. R. Jovanovi´c, Design of optimal sparse
interconnection graphs for synchronization of oscillator networks,
IEEE Transactions on Automatic Control, 59 (2014), pp. 2457–2462.
[7] T. Ikeda and M. Nagahara, Value function in maximum hands-oﬀ

control. http://arxiv.org/abs/1412.7840, 2014.

[8] M. Jovanovi´c and F. Lin, Sparse quadratic regulator, in Proceedings
of the European Control Conference (ECC), 2013, pp. 1047–1052.
[9] D. Liberzon, Calculus of Variations and Optimal Control Theory,
A concise

Princeton University Press, Princeton, NJ, 2012.
introduction.

[10] F. Lin, M. Fardad, and M. R. Jovanovi´c, Augmented Lagrangian
approach to design of structured optimal state feedback gains, IEEE
Transactions on Automatic Control, 56 (2011), pp. 2923–2929.

[11]

, Design of optimal sparse feedback gains via the alternating
direction method of multipliers, IEEE Transactions on Automatic
Control, 58 (2013), pp. 2426–2431.

[12] G. Mazanti, Y. Chitour, and M. Sigalotti, Stabilization of two-
dimensional persistently excited linear control systems with arbitrary
rate of convergence, SIAM Journal on Control and Optimization, 51
(2013), pp. 801–823.

[13] M. Nagahara, D. E. Quevedo, and D. Neˇsi´c, Hands-oﬀ control as

green control. http://arxiv.org/abs/1407.2377, 2014.

[14]

, Maximum hands-oﬀ control: a paradigm of control eﬀort
minimization, IEEE Transactions on Automatic Control, 61 (2016).
[15] B. Polyak, M. Khlebnikov, and P. Shcherbakov, An LMI approach
to structured sparse feedback design in linear control systems, in
European Control Conference (ECC), 2013, July 2013, pp. 833–838.
, Sparse feedback in linear control systems, Automation and

[16]

Remote Control, 75 (2014), pp. 2099–2111.

[17] D. R. Raymond and S. F. Midkiff, Denial-of-service in wireless
sensor networks: attacks and defenses, IEEE Pervasive Computing,
7 (2008), pp. 74–81.

[18] K. Schittkowski, C. Zillober, and R. Zotemantel, Numerical
comparison of nonlinear programming algorithms for structural
optimization, Structural Optimization, 7 (1994), pp. 1–19.

[19] S. Srikant and M. R. Akella, Persistence ﬁlter-based control for
systems with time-varying control gains, Systems & Control Letters,
58 (2009), pp. 413–420.

9

