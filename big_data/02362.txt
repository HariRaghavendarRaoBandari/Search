6
1
0
2

 
r
a

M
8

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
2
6
3
2
0

.

3
0
6
1
:
v
i
X
r
a

SPECTRAL TERM STRUCTURE MODELS

SI CHENG AND MICHAEL R. TEHRANCHI

UNIVERSITY OF CAMBRIDGE

Abstract. This note studies a certain stochastic evolution equation in the space of probability measures,
including existence and uniqueness results. A solution of this equation gives rise, in a natural way, to an
interest rate term structure model, in the same spirit as the Heath-Jarrow-Morton framework.

In this note, we are interested in a stochastic process (µt)t≥0 taking values in the space of (Borel) proba-

bility measures on R and whose stochastic evolution can be described formally by the equation

(1)

where

d [µt(dr)] = (Rt − r)µt(dr)dt + M (dr × dt)

and M is a random signed measure on R× R+ with the property that M (R× (0, t]) = 0 for all t ≥ 0. We will
give a more rigorous account of the evolution equation (1) later, but for the moment, one should interpret
it to mean that the real-valued process M ϕ deﬁned by

Rt =ZR

r µt(dr)

M ϕ

t =ZR

ϕ(r)µt(dr) −ZR

ϕ(r)µ0(dr) −Z t

0 (cid:18)ZR

ϕ(r)(Rs − r)µs(dr)(cid:19) ds

is a local martingale for all test functions ϕ : R → R in some suitable collection.
let

The reason for our interest in the process (µt)t≥0 is contained in the following computation. For 0 ≤ t ≤ T ,

Then by a formal application of Itˆo’s formula we have

P (t, T ) =ZR

e−(T −t)rµt(dr).

e− R t

0 RuduP (t, T ) = P (0, T ) +ZR×(0,t]

e− R s

0 Rudu−(T −s)rM (dr × ds).

Of course, the stochastic integral on the right-hand side must be interpreted carefully. Nevertheless, if we
proceed optimistically, we can hope to ﬁnd suitable assumptions such that the right-hand side is a true
martingale, and, in particular, since P (T, T ) = 1, we have will have

Ehe− R T

t Rsds|Fti = P (t, T )

for all 0 ≤ t ≤ T. The above formula has a ﬁnancial interpretation. Consider a continuous-time market
model where the the time-t spot interest rate is Rt and the time-t price of the zero-coupon bond of maturity
T is P (t, T ). Then the underlying probability measure P is a risk-neutral measure for the model, and in
particular, the bond market has no arbitrage.

In term structure modelling, it is often desirable to have non-negative interest rates. One appealing feature
of this framework is that it is very easy to ensure that the interest rate rt is non-negative: it is suﬃcient
that the measure µt is supported on [0,∞).
The above form of modelling the interest rate term structure is inspired by the recent paper [5] of Siegel.
Siegel’s modelling scheme can be described as follows. Fix n ≥ 2, and n real numbers r1, . . . , rn. Suppose
the processes X 1, . . . , X n evolve as

dX i

t = X i

t (Rt − ri)dt + dM i

t

1

for all 1 ≤ i ≤ n, where

n

and the processes M 1, . . . , M n are local martingales. The measure µt deﬁned by

Rt =

riX i
t

µt =

X i

t δri ,

Xi=1

n

Xi=1

n

Xi=1

M (dr × dt) =

δri(dr)dM i
t .

satisﬁes the evolution equation (1), where the notation δr denotes the Dirac measure concentrated at r and
formally

The goal of this paper is to treat the inﬁnite dimensional version of the Siegel’s model in the spirit of
Filipovic’s account [3] of the Heath–Jarrow–Morton term structure framework. Two technical challenges
appear in studying the formal evolution equation (1). The ﬁrst challenge is to deal with the nonlinearity
appearing in the drift. Indeed, the nonlinearity is quadratic, and thus not globally Lipschitz. Our solution
to this problem is to restrict our attention to measures with bounded support, in which case it is possible
to treat the nonlinearity as though it were Lipschitz. The second challenge is how to deﬁne properly the
stochastic integral with respect to a local martingale taking values in a possibly inﬁnite-dimensional space
of signed measure. We by-pass this diﬃculty by letting our local martingale take values in a larger space of
distributions which can be endowed with the structure of a separable Hilbert space, and then appealing to
the well-known Hilbert space stochastic integration theory. Finally, to ensure that the distribution valued
process (µt)t≥0 actually takes values in the set of probability measures, we employ a discretisation argument.

1. Set-up and mathematical preliminaries

Although the object of interests µt are probability measures, we study the evolution equation (1) in the

well-known Hilbert space framework, in the style of the book of Da Prato & Zabzcyck [2].

1.1. The state space. Fix a bounded closed interval I ⊂ R containing the origin. For an absolutely
continuous function ϕ on I let

kϕkH = ϕ(0)2 +ZI
Let H be the space of absolutely continuous functions φ such that kφkH < ∞. It is well-known that H is a
separable Hilbert space with respect to the norm k · kH.

ϕ′(r)2dr

Now for a ﬁnite signed measure µ on I, let

Let H ∗ be the completion of the space of ﬁnite signed measures with respect to this norm k·kH ∗ . The space
H ∗ is the dual space of H with respect to the Banach structure of H. We will occasionally use the notation
h·,·iH ∗,H : H ∗ × H → R to denote the duality pairing, so that when µ is a signed measure

kµkH ∗ =

sup

ϕ∈H,kφkH =1ZI

ϕ(r)µ(dr)

hµ, ϕiH ∗,H =ZI

ϕ(r)µ(dr).

But since H is a separable Hilbert space, we know by the Riesz representation theorem that the dual
space H ∗ can be identiﬁed isometrically with H. Indeed, assuming I = [−a, b], each signed measure µ ∈ H ∗
corresponds to a function ϕ ∈ H by

and hence the norm can be computed for signed measures µ by the formula

ϕ(r) = µ(I) +(cid:26) R r
0 µ(s, b]ds
R 0
r µ[−a, s)ds
µ[−a, r)2dr +Z b
H ∗ = |µ(I)|2 +Z 0
kµk2

−a

0

2

if r > 0
if r ≤ 0

µ(r, b]2dr.

Finally, we single out an important subset:

P = { probability measures on I} ⊂ H ∗.

1.2. The local martingale. We now explain how we construct the ‘random signed measure’ appearing in
equation (1). Given the set-up described above, we will consider local martingales valued in H ∗. Such local
martingales will be built from stochastic integrals with respect to a cylindrical Brownian motion.

Let G an arbitrary real separable Hilbert. Since the speciﬁc structure of G is irrelevant, we will identify
the dual space G∗ with G without comment and denote the inner product by h·,·iG : G × G → R. Indeed,
the reader may let G = ℓ2 without loss.

Let W be a Brownian motion deﬁned cylindrically in G. Recall that this means that

W = {Wt(g) : t ≥ 0, g ∈ G}

is such that for each g ∈ G such that kgkG = 1, the process W (g) is a Brownian motion, and W is linear in
the sense that W (αg + βh) = αW (g) + βW (h) for all g, h ∈ G and α, β ∈ R. Heuristically, the cylindrical
Brownian motion can be realised by the formal sum

∞

where W 1, W 2, . . . are independent Brownian motions and (en)n is a complete orthonormal basis of G.

For a linear map A : G → H ∗ deﬁne

Wt =

W i

t ei.

Xi=1

kAk2

LHS =Xn

kAenk2

H ∗ ,

where (en)n is a complete orthonormal basis of G as before. In fact, the norm k · kLHS is independent of the
choice of basis (en)n. The space of operators A such that kAkLHS < ∞ are the Hilbert–Schmidt operators
LHS(G, H ∗). Occasionally we will identify an operator in LHS(G, H ∗) with a vector in the tensor product
space H ∗ ⊗ G in the obvious way. Finally, for an element A ∈ LHS(G, H ∗) we let A∗ ∈ LHS(H, G) be the
adjoint deﬁned by

We recall basic result of the Hilbert space integration theory used here.

hAg, ϕiH ∗,H = hg, A∗ϕiG for all g ∈ G, ϕ ∈ H.

Proposition 1.1. Let (σt)t≥0 be a predictable process taking values in LHS(G, H ∗) and such that

Then the stochastic integral

Z t
0 kσsk2

LHS

ds < ∞ almost surely for all t ≥ 0.

is well-deﬁned, and the process M is a continuous local martingale taking values in H ∗.

Mt =Z t

0

σsdWs

For a proof see [1] or [2].

1.3. An aside on technical conventions. Because an inﬁnite dimensional Hilbert space such as H ∗ or
LHS(G, H ∗) can be equipped with several inequivalent topologies, it is necessary to make some conventions
to clarify our meaning. When we speak of measurable maps into a Banach space, we mean measurable
with respect to the Borel sigma-ﬁeld generated by its norm topology. In fact, this notion of measurability
is equivalent to the a priori weaker notion of weak measurability if the Hilbert space is separable [?].Also,
when we say that M is a martingale valued in a Hilbert space, we mean that the real random variable kMtk
is integrable and the conditional expectation

is interpreted in the sense of Bochner. Finally, when we say a Hilbert space-valued process is continuous, we
mean the almost sure continuity of the sample paths with respect to the norm topology.

3

E(Mt|Fs) = Ms for all 0 ≤ s ≤ t

where 1 ∈ H is deﬁned by

Note that if µ ∈ H ∗ is a signed measure then

and

R(µ) = hρ∗µ, 1iH ∗,H

1(r) = 1 for all r ∈ I.

(ρ∗µ)(dr) = rµ(dr)

R(µ) =ZI

r µ(dr),

We now consider the evolution equation (1) with extra structure that

2. Existence and uniqueness

To make things precise, we study the stochastic diﬀerential equation

Mt =Z t

0

σ(µs)dWs.

(2)
where W is a cylindrical Brownian motion in the Hilbert space G; the map σ : P → LHS(G, H ∗) is given;
the bounded linear operator ρ : H → H is deﬁned by

dµt = (R(µt) − ρ∗)µtdt + σ(µt)dWt

(ρϕ)(r) = rϕ(r) for all ϕ ∈ H, r ∈ I,

and its adjoint ρ∗ : H ∗ → H ∗ is deﬁned by

and the linear map R : H ∗ → R is deﬁned by

hρ∗µ, ϕiH ∗,H = hµ, ρϕiH ∗ ,H for all µ ∈ H ∗, ϕ ∈ H,

so the SDE given in equation (2) captures the main features of our evolution equation (1).

We now make the following additional assumptions:

Assumption 2.1. The map σ : P → LHS(G, H ∗) has the following properties:

Centering: For all µ ∈ P, we have

σ(µ)∗1 = 0.

Lipschitz: There is a constant C > 0 such that for all µ, ν ∈ P we have

kσ(µ) − σ(ν)kLHS ≤ Ckµ − νkH ∗ .

Absolute continuity: There exist a function g : P × I → G and a constant C > 0 such that

kg(µ, r)kG ≤ C for all µ ∈ P, r ∈ I and

σ(µ)(dr) = g(µ, r)µ(dr).

With this preparation, we now can state the main result:

Theorem 2.2. For every µ0 ∈ P, the SDE given by equation (2) has a unique solution (µt)t≥0 valued in
the space of probability measures P on I.

Step 1: Estimates of integrals

In this subsection, we are going to prove:

3. Proofs

Theorem 3.1. Suppose ¯µ = (µt)t≥0 and ¯ν = (νt)t≥0 are two P-valued solutions of the SDE (2). Then
¯µ, ¯ν ∈ ST for any T > 0. And there is a constant K > 0 such that for all T ≥ 0 we have
(3)

E( sup

H ∗ eKT 2

0≤t≤T kµt − νtk2

H ∗ ) ≤ kµ0 − ν0k2

In particular, if SDE (2) has solution, it must be unique.

4

Let (Wt)t≥0 be a Brownian motion deﬁned cylindrically on G with ﬁltration (Ft)t≥0 deﬁned on some
background probability space (Ω,F , P). Fix any T ≥ 0 and deﬁne ST to be the set of continuous H ∗-valued
processes ¯µ = (µt)0≤t≤T , adapted to ﬁltration (Ft)t≥0, that has ﬁnite |k · k|T norm. Where the norm on ST
is deﬁned as

2 = E(X 2) is the L2-norm.

Where kXk2
Remark 1. The continuous property of ¯µ allows us to make sense of Lebesgue integrals of ¯µ by deﬁning:

|k¯µk|T :=(cid:13)(cid:13) sup

t≤T kµtk(cid:13)(cid:13)2

< φ,Z t

0

µsds >:=Z t

0

< φ, µs > ds

since for any test function φ ∈ H, the function t 7→< φ, µt(ω) > is bounded continuous and hence integrable.

| < φ, µt > | ≤ kφkkµtk ≤ kφk(sup

t≤T kµtk) < ∞ a.s.

| < φ, µt > − < φ, µs > | = | < φ, µt − µs > | ≤ kφkkµt − µsk → 0 as

t → s

Lemma 3.2. For any T ≥ 0, the metric space (ST ,|k · k|) is complete.
Proof. Let (¯µn)n be Cauchy in ST .
such that

i.e.

|k¯µn − ¯µmk| → 0 as m, n → 0. We can ﬁnd a subsequence (nk)k
Xk

|k¯µnk+1 − ¯µnkk| < ∞

By applying triangle inequality of L2 norm, we have

kXk
Hence for almost every ω ∈ Ω,

sup

t≤T kµnk+1

t

− µnk

|k¯µnk+1 − ¯µnkk| < ∞

t k2 ≤Xk
(ω) − µnk

nk+1
t

t (ω)k < ∞

sup
t≤T kµ

Xk

Especially (µnk
Fix any ǫ > 0, we can also ﬁnd some j(ω) such that

t (ω))k is Cauchy in H ∗ for every t and hence converges to some µt(ω) by completeness of H ∗.

∞

Xk=j(ω)

t≤T kµ
sup

nk+1
t

(ω) − µnk

t (ω)k < ǫ

2

Now given any t ≤ T , since µnk
2 , whenever k > K(t, ω). Then we have the following estimate for any t ≤ T :

t (ω) → µt(ω), there exist some constant K(t, ω) such that kµnk

ǫ

t (ω)− µt(ω)k <

K(t,ω)

nj(ω)
t

kµ

(ω) − µt(ω)k ≤
< ǫ

Xk=j

2 + ǫ

t

kµnk+1
2 < ǫ

(ω) − µnk

t (ω)k + kµ

nK(t,ω)+1
t

(ω) − µt(ω)k

In other word, we’ve found a constant nj(ω) such that

nj(ω)
t

sup
t≤T kµ

(ω) − µt(ω)k < ǫ

Hence

kµt(ω) − µs(ω)k ≤ kµt(ω) − µ

(ω)k + kµ

nj(ω)
t

nj(ω)
t
nj(ω)
t

(ω) − µt(ω)k + kµ

(ω) − µ

nj(ω)
s

(ω) − µ

nj(ω)
t

(ω)k + kµ
(ω)k

nj(ω)
s

nj(ω)
s

(ω) − µs(ω)k

t≤T kµ

≤ 2 sup
< 3ǫ

if s, t are close enough

5

Hence ¯µ = (µt)t≤T is a.s continuous. i.e. ¯µ ∈ ST and it remains to show that this is indeed the limit of the
original sequance (¯µn)n, but

t≤T kµn

|k¯µn − ¯µk|2 = E(cid:18)sup
= E(cid:18)sup
≤ lim inf
= lim inf

k→∞

t≤T

t − µtk2(cid:19)
k→∞ kµn
lim inf
E(cid:18)sup

t≤T kµn

t − µnk

t − µnk

t k2(cid:19)
t k2(cid:19) Fatou’s lemma

k→∞ |k¯µn − ¯µnkk|2 → 0 as n → ∞

because (¯µn)n is a Cauchy sequence in ST .

(cid:3)

Suppose now ¯µ = (µt)t≥0 and ¯ν = (νt)t≥0 are two solutions to SDE (2) such that µt, νt ∈ P for all t.

Then we have the following estimate:

kµt − νtk2 = kµ0 − ν0 +Z t

0

F (µs) − F (νs)ds +Z t

0

σ(µs) − σ(νs)dWsk2

0

≤ 3(cid:18)kµ0 − ν0k2 + kZ t
Where F (µ) := (R(µ) − ρ∗) µ. Hence we have:
T ≤ 3(cid:18)kµ0 − ν0k2 + |kZ ·
(4)

|k¯µ − ¯νk|2

F (µs) − F (νs)dsk2 + kZ t
T + |kZ ·

F (µs) − F (νs)dsk|2

T(cid:19)
σ(µs) − σ(νs)dWsk|2
First we estimate the ﬁnal stochastic term of (4). Notice that if ¯µ ∈ ST for some T , then Mt =R t

is a local martingale. The expectation of quadratic variation is then

σ(µs) − σ(νs)dWsk2(cid:19)

0

0

0

E[M ]T = EZ T
≤ 2EZ T
≤ 2T (kσ(0)k2 + C2|k¯µk|2
Hence (Mt)t≤T is a true martingale and bounded in L2.

Ito’s isometry

0 kσ(µs)k2ds
0 kσ(0)k2 + C2kµsk2ds Lipschitz property

T ) < ∞

0 σ(µs)dWs

Theorem 3.3 (Doob’s L2 inequality). Let H be a separable Hilbert space and M = (Mt)t≥0 be a H-valued
martingale, then

By applying above theorem, we have

Ek sup

t≤T

Mtk2

H ≤ 4EkMTk2

H

|kZ ·

0

σ(µs) − σ(νs)dWsk|2

0 kσ(µs) − σ(νs)k2ds(cid:19)

t≤TZ t
T = E(cid:18)sup
≤ 4EZ T
0 kσ(µs) − σ(νs)k2ds
≤ 4C2Z T
≤ 4C2Z T

Ekµs − νsk2ds

|k¯µ − ¯νk|2

sds

0

0

6

Now we estimate the second term of (4). Notice that if ¯m = (ms)s≤T ∈ ST , then

kZ t

0

msdsk = sup

h∈H

khkH =1

0

msds > |

| < h,Z t
0 | < h, ms > |ds

h∈H

khkH =1Z t
≤ sup
≤Z t
0 kmskds

Lemma 3.4. For any µ, ν ∈ H ∗,

kF (µ) − F (ν)k ≤p2(a + b)kµ + νkkµ − νk +p2((a + b)2 + 2(a + b) + 2)kµ − νk

In particular, if µ, ν ∈ P are probability measures on interval I = [−a, b], we have

kF (µ) − F (ν)k ≤ C1kµ − νk
where C1 = 2p2(a + b)(1 + a + b) +p2((a + b)2 + 2(a + b) + 2).
Proof. By previous notation R(µ) =RI rµ(dr) is linear in µ and

|R(µ)| = | < r, µ > | ≤ krkHkµkH ∗ = √a + bkµk

Now deﬁne (µ ∗ ν)(dr) := R(µ)ν(dr), a bilinear binary operation.

kµ ∗ νk = sup
= sup

khk=1| < h, µ ∗ ν > |
khk=1|R(µ)|| < h, ν > |
√a + bkµkkνk

≤

For any h(r) ∈ H, we have (rh(r))′ = h(r) + rh′(r) and

krh(r)k2

(h(r) + rh′(r))2

dr

−a

H =Z b
≤ 2 Z b

−a

h2(r)dr +Z b

−a

r2(h′(r))2dr!

The second term can be bounded easily by (a + b)2khk2, for the ﬁrst term, we have:

h′(s)ds

0

h(r) = h(0) +Z r
h2(r) ≤ 2 h2(0) +(cid:18)Z r
≤ 2(cid:18)h2(0) + rZ r
≤ 2(a + b + 1)khk2

0

0

h′(s)ds(cid:19)2!
(h′(s))2ds(cid:19) Cauchy-Schwarz inequality

Combing the two terms gives:

krh(r)k2 ≤ 2((a + b)2 + 2(a + b) + 2)khk2

7

Finally grouping all the above estimates gives:

kF (µ) − F (ν)k = kµ ∗ µ − ν ∗ ν + ρ∗(µ − ν)k

Notice that kµ + νk ≤ kµk + kνk and for probability measures we have:

2

(µ + ν) ∗ (µ − ν) + µ − ν) ∗ (µ + ν)

≤(cid:13)(cid:13)(cid:13)
≤p2(a + b)kµ + νkkµ − νk +p2((a + b)2 + 2(a + b) + 2)kµ − νk
H ∗ := µ(I)2 +Z b

µ(r, N ]2dr +Z 0

µ[−N, r)2dr ≤ 1 + a + b

+ kρ∗(µ − ν)k

(cid:13)(cid:13)(cid:13)

−a

0

||µ||2

(cid:3)

Which gives the ﬁnal assertion of the lemma.

Back to the estimate of the second term of (4):

|kZ ·

0

F (µs) − F (νs)dsk|2

T = E sup

2

0

F (µs) − F (νs)dsk2
0 kF (µs) − F (νs)kds(cid:19)

t≤T kZ t
t≤T(cid:18)Z t
≤ E sup
≤ ET Z T
0 kF (µs) − F (νs)k2ds
1 TZ T
≤ C2

|k¯µ − ¯νk|2

sds

0

Hence for any µ ∈ H ∗

kρ∗µk = sup
= sup

khk=1| < h(r), ρ∗µ > |
khk=1| < rh(r), µ > |
≤ sup
khk=1krh(r)kkµk
≤p2((a + b)2 + 2(a + b) + 2)kµk

Hence the estimate (4) takes the ﬁnal form

(5)

Where C2 = 4C2 + C2

|k¯µ − ¯νk|2

|k¯µ − ¯νk|2
1 T . Here we can use Gronwall’s lemma, which states:

T ≤ 3 kµ0 − ν0k2 + C2Z T

0

sds!

Lemma 3.5 (Gronwall’s lemma). Let T > 0 and let f be a non-negative bounded measurable function on
[0, T ]. Suppose that for some α, β ≥ 0:

f (t) ≤ α + βZ t

0

f (s)ds

0 ≤ t ≤ T.

Then f (t) ≤ αeβt for all t ∈ [0, T ].

Hence by setting f (t) = |k¯µ − ¯νk|2

t , we get

|k¯µ − ¯νk|2

T ≤ 3kµ0 − ν0k2 exp(3C2T ) = 3kµ0 − ν0k2 exp(12C2T + 3C2

1 T 2)

and hence we’ve showed the inequality in theorem 3.1.

It remains to verify the uniqueness assertion. If ¯µ = (µt)t≥0 and ¯ν = (νt)t≥0 are two solutions to (2) with
the same initial condition µ0. Then by Assumption 2.1, they must be P-valued. Also since ¯µ, ¯ν start at the
same initial point,

and hence µt = νt for all t ≥ 0

8

E( sup

0≤t≤T kµt − νtk2

H ∗ ) = 0 ∀T > 0

Step 2: Existence and uniqueness in the atomic probability measure case:

We call a (signed) measure µ atomic if it takes the form:

k

µ =

X iδri

Xi=1

where Xi, ri ∈ R and δri is the dirac-delta measure concentrated at ri ∈ R. If in addition, X i > 0 and
Pk

i=1 X i = 1. Then µ is an atomic probability measure.
In this subsection, we are going to show

Theorem 3.6. Under Assumption 2.1, given any initial atomic probability measure µ0, there exists a solution
(µt)t≥0 to the SDE (2)
Proposition 3.7. Fix n ≥ 1, and let

xi = 1)
For 1 ≤ i ≤ n, let bi : Q → R and σi : Q → G be Lipschitz functions such that

Q =(x = (x1, . . . , xn) : xi ≥ 0 for all i,

Xi=1

n

n

n

Xi=1
for all x ∈ Q and such there exists a constant C > 0 such that

bi(x) = 0 and

Xi=1

σi(x) = 0

|bi(x)| + kσi(x)k ≤ Cxi

for all x ∈ Q where x = (x1, . . . , xn).
and

Then for every ξ ∈ Q there exists unique adapted process (Xt)t≥0 taking values in Q such that X0 = ξ

dXt = b(Xt)dt + σ(Xt)dWt.

Remark 2. We are interested in the following situation. Fix a collection of real numbers r1, . . . , rn and let

bi(x) = xi


n

Xj=1

rjxj − ri


for x = (x1, . . . , xn) ∈ Q.
Proof. Uniqueness follows from the Lipschitz assumption in the usual way. We need only prove existence.
Let Π be the projection onto the closed convex set Q. Note that Π is Lipschitz, and hence the functions

b ◦ Π and σ ◦ Π are also Lipschitz. Given ξ ∈ Q, let (Xt)t≥0 be the unique strong solution to the SDE

which exists by Itˆo’s theorem. Note that by summing over the indices, we have

dXt = b ◦ Π(Xt)dt + σ ◦ Π(Xt)dWt.

d

n

Xi=1

X i
t = 0 ⇒

n

Xi=1

X i
t = 1 for all t ≥ 0.

We need only show that X i

First we suppose that ξi > 0 for all 1 ≤ i ≤ n. Let T = inf{t ≥ 0 : min ˆX i

T = ∞ almost surely. For each 1 ≤ i ≤ n, we deﬁne bounded functions ci and τi by the formula

t = 0}. We will now show that

t ≥ 0 for all t ≥ 0 and all i. We would be done since Π(x) = x when x ∈ Q.

and

0

xi

ci(x) =(cid:26) bi(x)
τi(x) =(cid:26) σi(x)

xi

0

9

if xi > 0
otherwise

if xi > 0
otherwise

where x = (x1, . . . , xn) ∈ P. In particular

X i

t∧T = ξi +Z t

0

X i

s∧T dZ i
t

where Z i is the continuous semimartingale

Hence we can write

Z i

t =Z t

0

1{s≤T }[ci(Xs)ds + τi(Xs)dWs]

X i

t∧T = ξieZ i

t −[Z i]t/2.

Since the right-hand side is strictly positive almost surely for all ﬁnite t, the event {T < ∞} must have
probability zero, as claimed.
Now consider the case where there is at least one i such that ξi = 0. By relabelling if necessary, we may

write ξ = ( ˆξ, 0) where ˆξ ∈ Rm for some m < n and 0 ∈ Rn−m. In fact, we have ˆξ ∈ ˆQ where

ˆQ =(ˆx ∈ Rm : ˆxi > 0 for all i,

ˆxi = 1) .

m

Xi=1

Note that by assumption that for all ˆx ∈ ˆQ we have

and hence

bi(ˆx, 0) = 0 and σi(ˆx, 0) = 0 for all m + 1 ≤ i ≤ n

m

m

bi(ˆx, 0) = 0 and

σi(ˆx, 0) = 0.

Xi=1

Xi=1

By the above argument there exists a process ( ˆX)t≥0 taking values in ˆQ such that

d ˆXt = ˆb( ˆXt)dt + ˆσ( ˆXt)dWt

where the functions ˆb and ˆσ are deﬁned by ˆbi(ˆx) = bi(ˆx, 0) ˆσi(ˆx) = σi(ˆx, 0) for ˆx ∈ ˆQ and 1 ≤ i ≤ m. In
particular the process X = ( ˆX, 0) solves the original SDE and takes values in Q as desired.

(cid:3)

For what follows, ﬁx points r1, . . . , rN ∈ I.
Lemma 3.8. For all x1 . . . xN ≥ 0 such that Pj xj = 1 there exist functions σi : RN → G such that

Proof. By assumption, since r1, . . . , rN are ﬁxed, there are function gi such that

σ Xi
σ Xi

xiδri! =Xi
xiδri! =Xi

σi(x1, . . . , xN )δri .

gi(x1, . . . , xN )xiδri .

Let σi(x) = gi(x)xi.
Proposition 3.9. Let σ : P → LHS(G, H ∗) be Lipschitz, so that there exists a K > 0 such that

for all µ, ν ∈ P. Deﬁne σi : RN → G as in Lemma 3.8. Then the functions σi are Lipschitz.

kσ(µ) − σ(ν)kLHS ≤ Kkµ − νkH ∗ .

We need a lemma, which amounts to the well-known fact that norms on RN are Lipschitz equivalent:

(cid:3)

Lemma 3.10. For any z1, . . . , zN ∈ G, there exists constants 0 < c < C such that

cXi

kzikG ≤(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
Xi

ziδri(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)LHS

10

≤ CXi

kzikG.

Proof of Lemma 3.10. First note by the triangle inequality

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
Xi

ziδri(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)LHS

kzikGkδrikH ∗

≤Xi
≤ CXi

kzikG

≤ kµkH ∗kφkH

1

kφkH (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Xi

ziφ(ri)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)G

≥

(cid:12)(cid:12)(cid:12)(cid:12)
Z φ(r)µ(dr)(cid:12)(cid:12)(cid:12)(cid:12)
ziδri(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)LHS
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
Xi
ziδri(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)LHS
(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
Xi

≥ |φj(rj )|
kφjkH kzjkG for all j
≥ cXi
kzik

c =

1
N

min

j

|φj(rj )|
kφjkH

.

where C = maxi kδrikH ∗ .
Now by the inequality

we have

where

Let φi ∈ H be such φi(ri) > 0 but φi(rj ) = 0 for j 6= i. For instance, suppose r1 < . . . < rN and let the
graph of φi be a little triangle with base between ri−1 and ri+1 and vertex at ri for 1 < i < N , and the
construction appropriately modiﬁed for i = 1, N . By the above inequality we have

Proof of Proposition 3.9. Let

We have by Lemma 3.10 that

µ =Xj

kσi(x) − σi(y)kG ≤

Xi

1

yjδrj .

xjδrj and ν =Xj
(σi(x) − σi(y))δri(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)LHS
c (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
Xi
1
ckσ(µ) − σ(ν)kLHS
(xj − yj)δrj(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)H ∗
K(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
1
Xj
c
KXj
|xj − yj|.

C
c

≤

=

≤

Now by Assumption 2.1,

n

Centering implies

σi(x) = 0

Xi=1

Lipschitz of σ implies Lipschitz of σi by Proposition 3.9
Boundedness in absolute continuity implies kσi(x)k

xi

≤ C

11

(cid:3)

(cid:3)

And for any µ =Pn

j=1 xjδrj , we have

(R(µ) − ρ∗)µ = xi


n

Xj=1

rjxj − ri


Therefore applying Proposition 3.7, we have a unique adapted process (Xt)t≥0 = (X 1

t , . . . , X n

t )t≥0 in Q and

i=1 X i

t δri, we have

deﬁne µt =Pn
Lemma 3.11. µt is a solution to SDE (2) with initial condition µ0 =Pn
Proof. Take an arbitrary test function φ ∈ H, we are going to check that
< φ, (R(µs) − ρ∗)µs > ds +Z t

< φ, µt >=< φ, µ0 > +Z t

0

0

i=1 X i

0δri

second term is then

The LHS is clearly Pn
Z t

0

i=1 X i

t φ(ri). For the RHS, ﬁrst notice that R(µs) =< r, µs >= Pn
< φ, (R(µs) − ρ∗)µs > ds =

X j
s rs − ri)X i

sφ(ri)ds

(

n

n

Xi=1Z t

0

Xj=1

< φ, σ(µs)dWs >

j=1 X j

s rs and the

The last term is

Z t

0

Therefore the RHS is given by

< φ,

< φ, σ(µs)dWs > =Z t
Xi=1Z t

=

n

0

0

σi(Xs)dWsδri >

n

Xi=1

σi(Xs)dWsφ(ri)

X i

0φ(ri) +

n

Xi=1

n

Xi=1Z t

0

n

(

Xj=1

X j
s rs − ri)X i

sdsφ(ri) +

n

Xi=1Z t

0

σi(Xs)dWsφ(ri)

Clearly LHS = RHS because (Xt)t≥0 is a solution in Proposition 3.7.

(cid:3)

Step 3: Convergence of atomic solutions

Lemma 3.12. Let (µn)n≥0 be a sequence of probability measures on I = [−a, b]. Given a further µ ∈ H ∗
such that µ{−a, b} = 0. then

µn → µ weakly if and only if µn → µ in H ∗

In particular, µ is also a probability measure.
Proof. Now suppose µn → µ in H ∗, given any bounded continuous test function φ. Clearly φ ∈ H and

| < φ, µn > − < φ, µ > | = | < φ, µn − µ > |
≤ kφkkµn − µk → 0

Hence µn → µ weakly. In particular, taking φ(r) = 1 gives < 1, µ >= 1 which proves that µ is indeed a
probability measure.

For the other direction, assume that µn → µ weakly, then

1 = µn(I) =< 1, µn >→< 1, µ >= µ(I) = 1

Fix any r < 0, by setting A = [−a, r), we have ∂A = {−a, r}. Then for almost every r with respect to
Lebesgue measure

µ(∂A) = µ{−a} + µ{r} = 0

12

Since there are only countably many discontinuities in distribution function of µ. Hence µ(A) − µn(A) → 0
for almost every r by weak convergence. Also |µ(A)− µn(A)| ≤ 2 since there are probability measures. Then
by dominated convergence theorem:

Similarly,

and hence kµ − µnk → 0.

−a

Z 0
Z b

0

(µ(A) − µn(A))2 dr → 0

(µ(r, b] − µn(r, b])2 dr → 0

(cid:3)

Now we are ready to prove the main theorem 2.2

Proof. Let µ0 ∈ P be any such probability measure on I. Let (µn
0 )n≥0 be a sequence of atomic probability
measures that converge weakly to µ. This is always possible since the set of atomic measures is dense. By
the previous lemma, we have

t )t≥0 to the SDE (2) such

µn
0 → µ0

in H ∗

By step 2, we know that for each n, there exists a continuous solution ¯µn = (µn
that µn

t ∈ P for each n, t. Then by theorem 3.1, for any T > 0:

|k¯µm − ¯µnk|2

T ≤ kµm

0 − µn

0k2 exp(KT 2) → 0 as m, n → ∞

Hence the sequence (¯µn)n≥0 is Cauchy in ST and therefore tends to some limit ¯µ ∈ ST .

In particular ﬁx any t ≤ T

Since µn

t are probability measures, then 1 = µn

E(kµn

t − µtk2) ≤ |kµn − µk|2 → 0

t (I) =< 1, µn
E (1 − µt(I))2 = E| < 1, µn
Hkµn
≤ E(cid:0)k1k2
≤ E(cid:0)kµn
t − µtk2

t > and hence:
t > − < 1, µt > |2
t − µtk2
H ∗(cid:1)
H ∗(cid:1) → 0

Then E (1 − µt(I))2 = 0 implies µt(I) = 1 almost surely. Then µt ∈ P for all t.

Now since ¯µn = (µn

t )t≥0 are solutions, i.e.

Now we proceed similarly as in theorem 3.1.

σ(µn

s )dWs

0

0

F (µn

µn
t = µn

0 +Z t

s )ds +Z t
s )dWs −Z ·
T = E(cid:18)sup
(Doob’s L2 inequality) ≤ 4EZ T

σ(µs)dWsk|2

0

0

t≤T kZ t
0 kσ(µn

|kZ ·

0

σ(µn

σ(µn

s ) − σ(µs)dWsk2(cid:19)

s ) − σ(µs)k2ds

T → 0

Therefore for any T > 0

0

Similarly, since µn

(cid:18)Z t
(cid:18)Z t
take n → ∞ both side we get:

0

σ(µn

0

σ(µs)dWs(cid:19)t≤T

(Lipschitz of σ) ≤ 4CT|k¯µn − ¯µk|2
s )dWs(cid:19)t≤T →(cid:18)Z t
s )dWs(cid:19)t≤T →(cid:18)Z t
µt = µ0 +Z t

F (µs)ds +Z t

F (µs)dWs(cid:19)t≤T

σ(µs)dWs

0

0

0

13

F (µn

in ST

in ST

s , µs are probability measures for any s, n. We could apply lemma 3.12 and get

i.e ¯µ = (µt)t≤T is a solution. Since T > 0 was ﬁxed arbitrarily, we get a solution ¯µ = (µt)t≥0 to SDE (2)
subject to initial condition µ0 ∈ P.
(cid:3)

The generic element of H ∗ is a distribution but in principle may be much wilder than a signed measure.

However, we recall this useful fact is Theorem 6.22 of the book of Lieb & Loss [4]:

Proposition 3.13. Let

If µ ∈ H ∗ is such that

H+ = {ϕ ∈ H : ϕ(r) ≥ 0 for all r ∈ I}.

hµ, φiH ∗,H ≥ 0 for all ϕ ∈ H+

then µ is non-negative measure on I.

4. Extensions

Before we launch into a rigorous study of the stochastic evolution equation (1), we brieﬂy discuss the
deterministic version of the equation, where the case where the martingale term is identically zero. In this
case, we can solve the equation. Indeed, given a signed measure µ0 with µ0(R) = 1, let µt be the equivalent
signed measure deﬁned by

where the normalising constant

is assumed positive and ﬁnite. Letting

µt(dr) =

1
Gt

e−rtµ0(dr)

Gt =ZR

e−rtµ0(dr)

Rt =Z ∞
= −

−∞
d
dt

r µt(dr)

log Gt

we have

Note that we also have the identity

d [µt(dr)] = (Rt − r)µt(dr)dt.

e− R T

t Rudu =

GT
Gt

e−(T −t)rµt(dr)

=ZR

as expected.

We do not restrict our attention to non-negative measures, since doing so introduces an unexpected

constraint. Indeed, note that by integrating formally the evolution equation (1) we have

dRt = −ZR

(Rt − r)2µt(dr)dt +ZR

r M (dr × dt).

In particular, we see that the process (Rt)t≥0 is a supermartingale if we assume that µt is non-negative for
all t ≥ 0. That is to say, in order to allow for mean reversion of the interest rate under the risk-neutral
measure, we are forced to work with signed measures.
14

References

[1] R. Carmona and M. Tehranchi. Interest rate models: an Inﬁnite Dimensional Stochastic Analysis Perspective. Springer

Finance. (2006)

[2] G. Da Prato and J. Zabczyk. Stochastic equations in inﬁnite dimensions. Cambridge University Press. (1992)
[3] D. Filipovic. Consistency problems for Heath-Jarrow-Morton interest rate models, Lecture Notes in Math. 1760, Springer-

Verlag. (2001)

[4] E. Lieb and M. Loss. Analysis. Graduate Studies in Mathematics: Volume 14. American Mathematics Association. (2001)
[5] A.F.Siegel. Price-admissibility conditions for arbitrage-free linear price function models for the term structure of interest

rates. Mathematical Finance. (2014)
Here is a result when µt is supported on a ﬁnite number of atoms r1, . . . , rn.

Proposition 4.1. Let G be a real separable Hilbert space, on which W is a cylindrical Brownian motion.
Fix n ≥ 1, and let

xi = 1)
For 1 ≤ i ≤ n, let bi : P → R and σi : P → G be Lipschitz functions such that

P =(x = (x1, . . . , xn) : xi ≥ 0 for all i,

Xi=1

n

n

n

Xi=1
for all x ∈ P and such there exists a constant C > 0 such that

bi(x) = 0 and

Xi=1

σi(x) = 0

|bi(x)| + kσi(x)k ≤ Cxi

for all x ∈ P where x = (x1, . . . , xn).
and

Then for every ξ ∈ P there exists unique adapted process (Xt)t≥0 taking values in P such that X0 = ξ

dXt = b(Xt)dt + σ(Xt)dWt.

Furthermore,

Remark 3. We are interested in the following situation. Fix a collection of real numbers r1, . . . , rn and let

X i
t > 0 for all t ≥ 0 almost surely if and only if ξi > 0.

rjxj − ri

for x = (x1, . . . , xn) ∈ P. Then the atomic measure valued process

bi(x) = xi


Xj=1

n

n

µt =

X i

t δri

Xi=1

evolves according the evolution equation. Note that the measures µs and µt equivalent almost surely for all
0 ≤ s ≤ t.
Proof. Uniqueness follows from the Lipschitz assumption in the usual way. We need only prove existence.
Let Π be the projection onto the closed convex set P. Note that Π is Lipschitz, and hence the functions

b ◦ Π and σ ◦ Π are also Lipschitz. Given ξ ∈ P, let (Xt)t≥0 be the unique strong solution to the SDE

which exists by Itˆo’s theorem. Note that by summing over the indices, we have

dXt = b ◦ Π(Xt)dt + σ ◦ Π(Xt)dWt.

d

n

Xi=1

X i
t = 0 ⇒

n

Xi=1

X i
t = 1 for all t ≥ 0.

First we suppose that ξi > 0 for all 1 ≤ i ≤ n. Let T = inf{t ≥ 0 : min ˆX i

0 ≤ t ≤ T . We will now show that T = ∞ almost surely.

15

We need only show that X i

t ≥ 0 for all t ≥ 0 and all i. We would be done since Π(x) = x when x ∈ P.

t = 0}. Note that Xt ∈ P for all

For each 1 ≤ i ≤ n, let

and

xi
0

ci(x) =(cid:26) bi(x)
τi(x) =(cid:26) σi(x)
t∧T = ξi +Z t

X i

xi
0

0

if xi > 0
otherwise

if xi > 0
otherwise

X i

s∧T dZ i
t

where x = (x1, . . . , xn) ∈ P. Note that by assumption the functions ci and τi are bounded and in particular

where Z i is the continuous semimartingale deﬁned by

Hence we can write

Z i

t =Z t

0

1{s≤T }[ci(Xs)ds + τi(Xs)dWs].

X i

t∧T = ξieZt−[Z]t/2.

Since the right-hand side is strictly positive almost surely for all ﬁnite t, the event {T < ∞} must have
probability zero, as claimed.
Now consider the case where there is at least one i such that ξi = 0. By relabelling if necessary, we may

write ξ = ( ˆξ, 0) where ˆξ ∈ Rm for some m < n and 0 ∈ Rn−m. In fact, we have ˆξ ∈ ˆP where

Note that by assumption that for all ˆx ∈ ˆP we have

and hence

ˆP =(ˆx ∈ Rm : ˆxi > 0 for all i,

ˆxi = 1) .

m

Xi=1

bi(ˆx, 0) = 0 and σi(ˆx, 0) = 0 for all m + 1 ≤ i ≤ n

m

m

bi(ˆx, 0) = 0 and

σi(ˆx, 0) = 0.

Xi=1

Xi=1

By the above argument there exists a process ( ˆX)t≥0 taking values in ˆP such that

d ˆXt = ˆb( ˆXt)dt + ˆσ( ˆXt)dWt

where the functions ˆb and ˆσ are deﬁned by ˆbi(ˆx) = bi(ˆx, 0) ˆσi(ˆx) = σi(ˆx, 0) for ˆx ∈ ˆP and 1 ≤ i ≤ m. In
particular the process X = ( ˆX, 0) solves the original SDE and takes values in P as desired.

(cid:3)

For completeness, the statement and proof of a standard result from convex analysis is included below.
Lemma 4.2 (Orthogonal projection onto a convex sets is 1-Lipschitz.). Let P be a closed convex subset of
Rn. Then for every x ∈ Rn, there is a point Π(x) ∈ P such that

Furthermore, the inequality

kx − Π(x)k ≤ kx − pk for all p ∈ P.

holds for all x, y ∈ Rn.
Proof. First, we show the existence of the projection. Fix x ∈ Rk and let

kΠ(x) − Π(y)k ≤ kx − yk

d = inf

p∈P kx − pk.

Let (πk)k be a sequence in P such that
We will show that (πk)k is Cauchy. For ﬁxed k, h, note that the 1
2 (πk + πh)k ≥ d.

kx − πkk → d.

kx − 1

16

2 (πk + πh) ∈ P by convexity, and hence

Therefore, by the parallelogram law we have

kπk − πhk2 = 2kx − πkk2 + 2kx − πhk2 − 4kx − 1

2 (πk + πh)k2

≤ 2kx − πkk2 + 2kx − πhk2 − 4d2
→ 2d2 + 2d2 − 4d2 = 0.

By the completeness, the sequence (πk)k converges to some point Π ∈ Rn. And since P is closed by
assumption, we will have Π ∈ P.
Now, ﬁx x and p ∈ P and let pθ = (1 − θ)Π(x) + θp for 0 ≤ θ ≤ 1. Again by convexity, we have the
inclusion pθ ∈ P. Note by the deﬁnition of Π(x) we have

0 ≤ kx − pθk2 − kx − Π(x)k2
= 2θhx − Π(x), Π(x) − pi + θ2kΠ(x) − pk2.

Sending θ ↓ 0 in the above inequality yields the conclusion that

hΠ(x) − x, Π(x) − pi ≤ 0

for all p ∈ P. Hence

kΠ(x) − Π(y)k2 = hΠ(x) − x, Π(x) − Π(y)i + hy − Π(y), Π(x) − Π(y)i + hx − y, Π(x) − Π(y)i

≤ hx − y, Π(x) − Π(y)i
≤ kx − ykkΠ(x) − Π(y)k

from which the Lipschitz bound follows.

(cid:3)

Statistical Laboratory, Centre for Mathematical Sciences, Wilberforce Road, Cambridge CB3 0WB, UK
E-mail address: m.tehranchi@statslab.cam.ac.uk

17

