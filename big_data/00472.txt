6
1
0
2

 
r
a

M
1

 

 
 
]
h
p
-
t
n
a
u
q
[
 
 

1
v
2
7
4
0
0

.

3
0
6
1
:
v
i
X
r
a

Super-additivity in communication of classical information through quantum channels

from a quantum parameter estimation perspective

Jan Czajkowski, Marcin Jarzyna, and Rafa l Demkowicz-Dobrza´nski

Faculty of Physics, University of Warsaw, Pasteura 5, PL-02-093 Warszawa, Poland

(Dated: March 3, 2016)

We point out a contrasting role the entanglement plays in communication and estimation scenar-
ios. In the ﬁrst case it brings noticeable beneﬁts at the measurement stage (output super-additvity),
whereas in the latter it is the entanglement of the input probes that enables signiﬁcant performance
enhancement (input super-additvity). We identify a weak estimation regime where a strong connec-
tion between concepts crucial to the two ﬁelds is demonstrated; the accessible information and the
Holevo quantity on one side and the quantum Fisher information related quantities on the other.
This allows us to shed new light on the problem of super-additivity in communication using the
concepts of quantum estimation theory.

I.

INTRODUCTION

The greatest achievement of classical communication
theory is realization of the fact that being able to use a
noisy communication channel many times allows one to
encode, transmit and decode a message in an error-free
way at a non-zero asymptotic rate referred to as the ca-
pacity of the channel. A classical channel is described via
a conditional probability distribution relating input and
output symbols from which the capacity of the channel
can be directly calculated [1, 2]. In a quantum setting
[3, 4], two additional elements, that have an impact on
the amount of classical information that can be trans-
mitted through the channel, need to be considered. The
ﬁrst one is the family of quantum states that are used
to send the encoded information and the second is the
measurement that provides the read-out. Only then the
corresponding conditional probability can be evaluated
and the capacity can be calculated using the classical
formula.

There is more to it, however. In a quantum scenario
we can imagine states entering inputs corresponding to
diﬀerent uses of a channel to be entangled. This may in
principle lead to an advantage in communication capacity
compared with a strategy where only separable states are
allowed, see Fig 1. This potential gain thanks to entan-
glement of input states is referred to as super-addtivity
of quantum channel capacity and its actual existence is
a topic of long and hot debate in quantum communica-
tion community [5–12]. In this paper we will refer to this
concept as the input super-additivity. Moreover, even if
we do not employ entangled state at the input we are
still left with the possibility to perform collective mea-
surements at the output—measure states arriving at dif-
ferent channel outputs coherently. This may and indeed
in many cases does provide a beneﬁt in the form of in-
creased capacity and we will refer to this eﬀect as the
output super-additivity [13–16].

Quantum parameter estimation theory has been
largely developed before the quantum communication
ﬁeld achieved its maturity. These two ﬁelds share a com-
mon element, they both care to ﬁnd the measurement

FIG. 1. General schemes illustrating the role of entangled
inputs (input super-additivity) and collective measurements
(output super-additivity) in communication (i) and estima-
tion (ii) protocols. The performance is quantiﬁed by channel
capacity C for communication and the quantum Fisher infor-
mation FQ for estimation problems, while the labels in the
superscripts inform whether entanglement is utilized (∞) or
not (1) at the input and output stages respectively. While in
communication scenarios it is the measurement stage where
the super-additivity appears naturally, when the practical role
of input super-additivity is debatable, it is the entanglement
at the input that oﬀers a signiﬁcant precision enhancement
in case of parameter estimation. Note that an estimation
scenario can be regarded as a special case of a communica-
tion task where parameter encoding is ﬁxed by the channel
parameter dependence Λx.

optimal for the purpose of extracting classical informa-
tion encoded in quantum states.
In a communication
problem the quantum channel is given, but the character
of the information and the way that it is being encoded
in the quantum states is arbitrary and it is ideally cho-
sen in a way to maximize the ﬁnal information transfer.
In an estimation problem, on the other hand, the infor-
mation is encoded in quantum states in a particular way
either directly or via the action of some parameter de-
pendent channels, see Fig 1. In this sense the estimation

problem may formally be regarded as a restricted commu-
nication problem, even though the traditional ﬁgures of
merit used in estimation and communication approaches
are usually diﬀerent [14]. The central problem of quan-
tum communication and estimation theories is to identify
the potential beneﬁts coming from exploiting entangle-
ment in the input states as well as at the measurement
stage of the protocols. Interestingly, unlike in the com-
munication problem, there is a great number of examples
demonstrating signiﬁcant gains coming from the use of
entangled input probes in quantum estimation protocols,
with applications ranging from optical and atomic inter-
ferometry, via magnetometry to spectroscopy and atomic
clocks stablization [17–20]. At the same time, in a typical
estimation protocol utilizing unentangled input probes
collective measurements are typically irrelevant. Thus a
contrasting picture emerges: when thinking of capacities
of quantum channels gains in information processing aris-
ing from utilizing entanglement are at the measurement
stage whereas it is the input stage where entanglement
makes a diﬀerence in the estimation scenarios.

The goal of this paper is to better understand the
connections between the two ﬁelds from the point of
view of the super-additivity issue, understood here as
a general question of utility of entanglement in estima-
tion/communication protocols. We show that in the
weak estimation regime, where the amount of informa-
tion extractable on the parameter is very small com-
pared to the prior information, the accessible informa-
tion as well as the Holevo quantity can be expressed us-
ing Fisher information-like concepts, which allows us to
discuss utility of entanglement in communication using
the properties of quantities well understood within the
ﬁeld of quantum estimation. We also point out that in a
communication problem encoding a large number of inde-
pendent parameters is favoured even at the cost of their
limited estimation precision, which makes the estimation
strategy of learning a given parameter with highest pos-
sible accuracy not likely to be useful for the communica-
tion purposes. In order to make the paper self-contained
we also recall some of the recent results on applications
of rate-distorion theory in quantum estimation, which is
another way of connecting the communication and esti-
mation ﬁelds [21, 22]. Let us point out here, however,
that while the rate-distortion theory allowed to draw in-
teresting conclusion on performance of certain estimation
protocols using results from communication ﬁeld our di-
rection of reasoning in this paper is mostly the opposite.
Using results from estimation theory we aim at getting
some interesting intuitions regarding the communication
tasks. This approach has to be taken with care, since, as
pointed out before, the estimation problem is a kind of
restricted communication problem where parameter en-
coding is already ﬁxed and typically not optimal for com-
munication purposes. Hence, if certain statements are
made on the communication problem they only apply to
this particular kind of information encoding employed in
the considered estimation protocol. We therefore cannot

2

claim, and indeed we do not, that our observations have
general implications on the fundamental task of quantum
communication theory that is of ﬁnding the ultimate ca-
pacity of the channel under optimal encoding. Our main
purpose is to elucidate connections between the ﬁelds and
only if a particular example of encoding considered hap-
pens to be optimal for communication purposes, a con-
nection between fundamental quantum channel capacity
and the estimation related quantities can be established,
as will be demonstrated in a particular case of commu-
nication through bosonic channels.

The paper is organized as follows. Sec. II and Sec. III
contain a review of relevant concepts from quantum com-
munication and estimation theories highlighting the role
of entanglement in both ﬁelds. Sec. IV discusses known
results relating communication and estimation aspects
of quantum information processing via concepts of rate-
distortion theory. Sec.V discusses the weak estimation
regime where the connections between the mutual infor-
mation and the Holevo quantity with Fisher information-
like quantities are established and the super-additivity
issue is discussed from this perspective. Finally, Sec.VI
contains examples illustrating the applicability of the
weak-estimation approximation and discusses its impli-
cations on communication via qubit channels in presence
of dephasing and bosonic channel under loss and thermal
noise.

II. COMMUNICATION

The main goal of classical communication theory is
understanding the limits of sending credible information
through noisy channels. For this purpose the sender
needs to appropriately encode the message and the re-
ceiver needs to decode it in a way that the message is
not corrupted by the noise of the channel. Mathemati-
cally, a classical communication channel is modeled by a
probabilistic map connecting input (X) and output (Y )
random variables via conditional probability distribution
p(y|x), x ∈ X , y ∈ Y. According to the Channel Coding
Theorem [1, 2], the maximal number of bits that can be
correctly transmitted per channel use, referred to as the
capacity of the channel C, reads:

C = max
{p(x)}

I(X : Y ),

(1)

where I(X : Y ) = H(Y ) − H(Y |X) is the Shan-
non mutual information, H(Y ) ≡ −Py p(y) log p(y) is
the Shannon entropy of the output and H(Y |X) =
−Px,y p(y|x)p(x) log p(y|x) is the Shannon conditional
entropy. In this paper all logarithms are assumed to be
in base 2.
It is important to stress that even though
the symbols sent through diﬀerent independent channels
may be correlated, the formula for the capacity is given
in terms of relation between input and output variables
of a single channel. This automatically implies that the
capacity CN of a channel constructed by grouping N in-

dividual independent channels into a single entity, fulﬁlls
the additivity property CN = N C.

Quantum communication [4, 23]

is concerned with
sending messages encoded in quantum states through
quantum channels, see Fig. 1(i).
In this paper we
will only consider the problem of sending classical mes-
sages through quantum channels, ignoring the problem of
transmiting faithfully quantum states themselves, as only
this aspect of communication can be expected to have
some relation with the estimation problem which in the
end deals with extraction of classical parameter encoded
in quantum states. Mathematically, a quantum channel
is a completely positive trace preserving (CPTP) map
Λ [3] acting on quantum states represented as density
operators. Communication performance of the channel
crucially depends on the states {ρin
x }x∈X in which we en-
code input symbols x as well as the operators {Πy}y∈Y
representing the ﬁnal measurement. To keep full gen-
erality one typically allows for general positive opera-
tor valued measurements (POVM) [3], so that the only
condition on the measurement operators are: Πy ≥ 0,
Py∈Y
Πy = 11. With the family of input states as well as
the measurement operators ﬁxed, the conditional prob-
ability distribution relating input and output symbols
reads p(y|x) = Tr(ρxΠy), where ρx = Λ(ρin
x ) represent
the input states after they have been transmitted through
channel Λ. Using now the classical formula for channel
capacity, Eq. (1), we get the corresponding formula for
capacity of a quantum channel:

C(1,1) =

max
{p(x),ρin

x ,Πy}

I(X : Y ),

(2)

where superscript (1,1) indicates that no entanglement is
involved neither at the input nor at the output stage of
the protocol. Unlike in a classical scenario the issue of
additivity of the capacity of the quantum channel is far
from obvious. We may both perform collective measure-
ments involving multiple output states as well as send
states which are entangled throughout diﬀerent channel
inputs. This makes classical additivity arguments in gen-
eral invalid as the full conditional probability relating in-
put and output symbols of multiple channels no longer
factorizes into single channel quantities.

Indeed, when collective measurements are allowed, the
capacity is in general larger than the one given in (2) [13–
16] and is expressed via the so called Holevo quantity χ:

C(1,∞) = max
{p(x),ρin
x }

χ({px, Λ(ρin

x )}),

(3)

where

χ({px, ρx}) = S Xx

p(x)ρx! −Xx

p(x)S(ρx),

(4)

with S(ρ) = −Tr(ρ log ρ) being the von Neuman entropy.
The replacement of 1 with ∞ in the right superscript rep-
resents the possibility of measuring colectively arbitrary
number of output channels. Apart from covering a more

3

general scenario the above formula has also a clear ad-
vantage over (2) as it no longer requires optimization over
measurements.

When the input states are additionally allowed to be
entangled, one can also formally write a formula for the
capacity using regularization of the Holevo quantitiy [5]

C(∞,∞) = lim
N→∞

1
N

max

{p(x),ρN,in

x

χ({px, Λ⊗N (ρN,in

x

)}), (5)

}

which is, however, infeasible to deal with due to the ne-
cessity of considering entangled quantum states of arbi-
trary large number of subsystems. In case of commonly
encountered quantum channels it is proven or at least
strongly expected based on numerical investigations that
C(∞,∞) = C(1,∞) [24, 25]. The overall picture is more
complicated, however, due to the example of Hastings
[10] where a construction of two channels is given for
which the Holevo quantity is demonstrated to be strictly
super-additive. The construction is probabilistic and
deals with channels of potentially very high dimensions,
and as a result it is hard to assess the quantitative im-
pact of thus demonstrated super-additivity for practical
communication scenarios. To the best knowledge of the
authors, up till know there has been no explicit exam-
ple of a low dimensional channel relevant for communi-
cation purposes for which input super-additivity would
be demonstrated. Therefore in this paper, we will write

?
that C(∞,∞)
& C(1,∞) which is supposed to represent the
fact that while there are input super-additive properties
of the Holevo quantity, up till now they have not been
demonstrated to be relevant in practical communication
scenarios.

To summarize this section we may therefore write the

following relation:

C(∞,∞)

?

& C(1,∞) ≥ C(1,1),

(6)

pointing out to the presence of the output and the prac-
tical lack of the input super-additivity when thinking of
the classical capacity of quantum channels.

III. ESTIMATION

Classical estimation theory provides methods to opti-
mally estimate a value of a parameter x based on obser-
vations y that are known to be distributed according to
probability distribution p(y|x), that represents the prob-
abilistic model for the problem considered. For this pur-
pose one looks for the optimal estimator function ˜x(y)
that minimizes the estimated parameter deviation from
the true parameter value. Identifying the optimal estima-
tor is non-trivial and its form in general critically depends
on the prior knowledge available. Nevertheless, assuming

the estimator is unbiased: h˜xi = Py p(y|x)˜x(y) = x—so

that it on average returns the true value—the Cram´er-
Rao (CR) inequality [26] allows to write a lower bound

on the estimator variance:

∆2 ˜x ≥

1

F (x)

, F (x) =Xy

˙p(y|x)2
p(y|x)

,

(7)

where ∆2 ˜x = Py p(y|x)(˜x(y) − x)2, dot denotes diﬀer-

entiation with repsect to x and F is the Fisher infor-
mation (FI). Provided one identiﬁes an estimator satu-
rating the above bound one is sure to have found the
optimal one. Even though saturation of the bound is
possible for only a very limited class of probability func-
tions, the so called exponential family of distributions
[26, 27], the situation is much clearer in the asympto-
totic regime when one registers many observations yi,
i ∈ {1, . . . , N} independently and identically distributed
according to p(yi|x).
In this case the joined probabil-
ity distribution p(y1, . . . , yN|x) = ΠN
i=1p(yi|x) is prod-
uct and hence, thanks to additivity of FI on indepen-
dent probability distributions, the corresponding FI for
p(y1, . . . , yN|x) equals FN = N F . As a result the es-
timation variance based on N observation is bounded
according to (7) as:

∆2 ˜xN ≥

1

N F (x)

.

(8)

Most importantly, the above bound is saturable in the
asymptotic limit of N → ∞ and the optimal estimator is
the max-likelihood estimator [26, 27] . Saturability of the
CR bound for large N is intimately related with the local
asymptotic normality theorem [28] proving that, in the
limit of large N and after a suitable reparametrization,
probability distribution ΠN
i=1p(yi|x) can be viewed as a
gaussian distribution with mean being shifted by √N x
and the variance equal to 1/F . Since Gaussian distri-
bution with its mean as a parameter to be estimated is
a member of the exponential family of distributions for
which the CR bound is saturated this proves the fact.

In a typical quantum estimation problem we are given
a family of states {ρx} with the task of learning the pa-
rameter x. Apart from the issue of ﬁnding the optimal
estimator ˜x(y) we also need to ﬁnd the optimal measure-
ment {Πy} that yields the actual conditional probability
distribution of observed results p(y|x) = Tr(ρxΠy). The
quantum generalization of the CR inequality yields the
lower bound on the achievable variance irrespectively of
the measurement applied [29]:

∆2 ˜x ≥

1

FQ(ρx)

, FQ(ρx) = TrρxL2
x,

(9)

where FQ is the quantum Fisher information (QFI) and
Lx is the symmetric logarithmic derivative (SLD) opera-
tor implicitly deﬁned by:

˙ρx =

1
2

(ρxLx + Lxρx) .

(10)

When written explicitly in terms of eigenvalues and

4

eigevectors of ρx =Pd

d

FQ(ρx) =

+ 2

d

n=1 pn|nihn|, the QFI reads:
Xn,m=1

(pn − pm)2
pn + pm |hn| ˙mi|2, (11)

pn+pm6=0

˙p2
n
pn

Xn=1

where both the eigenvalues and eigenvectors in general
depend on x and in case of pure states estimation, ρx =
|ψxihψx|, the above formula simpliﬁes to

FQ(|ψxi) = 4(cid:16)h ˙ψx| ˙ψxi − |h ˙ψx|ψxi|2(cid:17) .

QFI is additive on product states, so that F (ρ⊗N
N F (ρx). Hence, given N copies of the state we get:

x

∆2 ˜xN ≥

1

N FQ(ρx)

.

(12)

) =

(13)

Moreover, when a measurement is chosen so that it is a
projective measurement in the SLD eigenbasis, the cor-
responding FI equals the QFI. Therefore, applying the
arguments from from the classical case, the above quan-
tum CR inequality is also asymptotically saturable in the
limit o large N .

If the family of states to be considered is not given, but
the parameter to be estimated is rather encoded in the
action of a channel Λx, we are additionally challenged to
ﬁnd the optimal probe states ρin that allow the parame-
ter x to be estimated with smallest possible uncertainty
by measuring the output states ρx = Λx(ρin). When
the probe state is sent into inputs of N copies of the
channel Λx, one can again ask whether entangled input
states and collective measurements oﬀer any advantage
compared to uncorrelated strategies. The answer to this
question is the key to understanding the beneﬁts of quan-
tum enhanced estimation scenarios, see Fig. 1(ii).

If only product input states are allowed, the maximal

QFI per channel use reads:

Q = F (1,∞)
F (1,1)

Q

= max
ρin

FQ[Λx(ρin)],

(14)

Q

Q

= F (1,∞)

where the equality F (1,1)
arises thanks to ad-
divitiy of QFI on product states and the fact that there
always exist a local measurement for which FI equals to
the corresponding QFI [30]. Therefore, unlike in the com-
munication case, there is no beneﬁt from application of
collective measurements when product input states are
used. However, when inspecting QFI for entangled input
probes there are a plethora of examples when entangle-
ment at the input increases the resulting QFI. In partic-
ular, for unitary parameter estimation the QFI may in-
crease at a rate proportional to N 2 rather than linearly
in N [18–20] and even though decoherence typically re-
duces the asymptotic scaling again to a linear one, the
entanglement enhancement beneﬁt remains in terms of a
larger multiplicative constant [31–33]. Hence, in general
QFI is input super-additive and we can therefore write:

F (∞,∞)
Q

≥ F (1,∞)

Q

= F (1,1)
Q ,

(15)

which contrasts the analogous relation for communica-
tion capacities given in (6). Note that we take the con-
vention where F (∞,∞)
denotes the QFI per channel use
to make it more like the capacity concept introduced be-
fore.

Q

Up till now we have based our whole discussion of
the quantum estimation problem on the analysis of the
QFI. When communication and estimation approaches
are to be related, however, it is more natural to adopt
the Bayesian perspective on estimation, as the prior dis-
tributions of the parameters to be estimated naturally
translate to input symbol probability distributions in a
communication problem. Taking the quadratic cost as
a ﬁgure of merit, the optimal Bayesian estimation of a
paramerter x, given the familiy of states ρx distributed
according to the prior p(x), is the one that minimizes the
average variance:

∆2 ˜x =Z dx p(x)Z dyp(y|x)(˜x(y) − x)2

(16)

over the choice of measurement operators {Πy} and esti-
mators ˜x(y). A general solution to the problem is known
and the minimal achievable variance equals to [34, 35]:

∆2 ˜x = ∆2

0 − Tr(¯ρL2),

(17)

where ¯x = R dx p(x)x is
R dx p(x)(x − ¯x)2 the variance of the prior whereas L

is implicitly deﬁned via the following relation:

the mean and ∆2

0 =

¯ρ′ =

1
2

(¯ρL + L ¯ρ),

with ¯ρ, ¯ρ′ deﬁned as

¯ρ =Z dx p(x)ρx, ¯ρ′ =Z dx p(x)xρx.

(18)

(19)

The apparent similarity of (18) to the SLD formula (10)
becomes even stronger when the prior p(x) is assumed to
be Gaussian in which case (17) becomes:

∆2 ˜x = ∆2

0(cid:2)1 − ∆2

0FQ(¯ρ)(cid:3) ,

(20)

with FQ(¯ρ) being the QFI for the problem of estimating
the mean of the prior ¯x given the averaged state ¯ρ.

The Bayesian perspective is indeed adopted in papers
making use of rate-distortion theory to derive bounds on
estimation precision using communication tools [21, 22]—
see section IV. Fortunately, the conclusions on the role
of entanglement in the quantum estimation problem dis-
cussed above using the QFI concept remain qualitatively
unchanged when the Bayesian methodology is applied
[20]. Hence it is often enough to study the properties
of the QFI which is easier to analyze. The QFI re-
lated quantities will also prove useful in Sec.V where it is
demonstrated that they play an important role in analyz-
ing communication performance in the weak estimation
regime.

5

IV. RATE-DISTORTION THEORY

A ﬁrst natural place to look for relations between
estimation and communication problems is the rate-
distortion theory [2, 36]. The main objective of the rate-
distortion theory is to quantify how much information
can be transmitted provided given level of errors and vice
versa. In particular, viewing the estimation protocol as
a communication channel form the input symbol x to its
estimator ˜x, it is possible to lower bound the correspond-
ing mutual information I(X : ˜X) via [2]

I(X : ˜X) ≥ H(X) −

1
2

log(2πe∆2 ˜x),

(21)

where ∆2 ˜x is the average estimation variance.
Intu-
itively, this relation reﬂects the fact that the better the
estimation precision the higher the communication rate.
Or stated the other way round, one needs to communi-
cate a lot in order to estimate very precisely. Note, that
here we refer to the estimation problem using Bayesian
perspective as we explicitly take into account the form
of prior distribution. Recall also that in the whole paper
we focus on transmitting classical information encoded in
quantum systems and therefore utilize results of classical
rate-distrotion theory abstracting from a more general
quantum rate-distortion theory [37] where faithful com-
munication of quantum states themselves is considered.
Utilizing (21) together with the fact that I(X : ˜X) is
upper bounded by the Holevo quantity χ one can get a
lower bound on the achievable estimation variance [21,
22, 38]

∆2 ˜x ≥

4H(X)−χ({px,ρx})

2πe

.

(22)

Thinking of states ρx as the outputs of a parameter de-
pendend channel ρx = Λx(ρin), we may obtain the lower
bound ∆2 ˜x valid for arbitrary input probe states, pro-
vided we are able to upper bound the corresponding
Holevo quantity χ[{px, Λx(ρin)}]. A good candidate is
the capacity C(1,∞), Eq. (2), of the channel which is ob-
viously an upper bound for χ. The problem is that typ-
ically the formula for the capacity is not easily obtained
and also the resulting bound may not be very informa-
tive. For example, for a single mode lossy bosonic channel
with eﬀective transmission η it is known that if the av-
erage number of photons at the input is upper bounded
by ¯n the capacity of the channel reads:
C(1,∞) = C(∞,∞) = (η¯n + 1) log(η¯n + 1) − η¯n log(η¯n).
(23)
When plugged into (22) this yields in the large ¯n ≫ 1
limit: ∆2 ˜x ≥ 4H(X)
(η ¯n)2 . Thinking now of phase estima-
tion, the bound is reasonably tight for the lossless case
η = 1. However, in case of losses (η < 1), the bound is
highly unsatisfactory since it is known that the Heisen-
berg limit is lost [20], and the achievable asymptotic scal-
ing of phase estimation variance is 1/¯n rather than 1/¯n2.

2πe3

1

This is related to the fact that the optimal encoding that
saturates the capacity of the channel is not the phase en-
coding characteristic for the phase estimation problem.
Therefore, instead of plugging in the capacity of the chan-
nel itself it may be more reasonable to insert a tighter
bound on χ obtained for an encoding present in a given
estimation problem. Following this way of reasoning, a
much more informative bound has been derived for the
case of unitary parameter estimation Λx(ρin) = UxρinU†x,
Ux = exp(−iGx), [22]:
1

4H(X)+S(ρin)−H(G|ρin),

(24)

∆2 ˜x ≥

2πe

where H(G|ρin) is the Shannon entropy of the measure-
ment statistics corresponding to measuring ρin in the
eigenbasis of the generator G. This approach allowed
to obtain useful precision bounds in case of decoherence-
free nonlinear quantum metrology [22] and lossy optical
estimation [21], where the correct 1/¯n phase estimation
variance scaling in presence of losses has been recovered.
The results summarized above made used of connec-
tions between estimation and communication ﬁelds in
order to obtain original results in estimation theory. In
this paper we focus on a complementary goal. We aim
to obtain a better insight into communication aspects of
quantum channels beneﬁting from our understanding of
estimation related quantities.

V. WEAK ESTIMATION REGIME

In this section we identify a regime where a connec-
tion between Shannon and Holevo quantities on one side
and the QFI related quantities on the other can be estab-
lished. This regime corresponds to a situation which we
refer to as the weak estimation regime. The precise condi-
tions will be given further in this section, but intuitively
the regime we are interested in corresponds to a situ-
ation in which the knowledge on the parameter gained
from measurement of the output state is small compared
to the prior knowledge.

A. Classical case

Let us ﬁrst discuss the classical case and write mutual

information between the sender and the receiver

I(X : Y ) = H(Y ) − H(X|Y ) =
−Z dy p(y) log p(y) +Z dxdy p(x)p(y|x) log p(y|x).

(25)

Assuming p(y|x) is suﬃciently smooth in x and the prior
p(x) is suﬃciently narrow we approximate p(y|x) using
expansion around the prior mean ¯x up to the second order
p(y|x) ≈ p(y|¯x) + ˙p(y|¯x)(x − ¯x) + 1
2 ¨p(y|¯x)(x − ¯x)2, where

6

dots denote derivatives with respect to x taken at x = ¯x.
Taking the expectation value of this expression with re-
0 ¨p(y|¯x)
,
0 is the prior variance. Using this approximation,

spect to the prior p(x) we obtain p(y) ≈ p(y|¯x)+ ∆2
where ∆2
the ﬁrst term in (25) hence reads:

2

−Z dy (cid:18)p(y|¯x) +

∆2
0 ¨p(y|¯x)

2

(cid:19) log(cid:18)p(y|¯x) +

∆2
0 ¨p(y|¯x)

2

(cid:19) .

(26)

We now expand the log function and keep the leading
order terms in ∆2

0 arriving at:

H(Y ) ≈
−Z dy (cid:20)(cid:18)p(y|¯x) +

∆2
0 ¨p(y|¯x)

2

(cid:19) log p(y|¯x) +

∆2
2 ln 2 (cid:21) .
0 ¨p(y|¯x)

(27)

By doing so, we have made an implicit assumption that
p(y|¯x) > 0, otherwise the expansion would not be pos-
sible. Within our order of approximation, ignoring con-
tribution from terms for which p(y|¯x) = 0, is justiﬁed
provided in this cases ˙p(y|¯x) = ¨p(y|¯x) = 0 as well. This
is the technical assumption which intuitively means that
events which are impossible when x = ¯x do not gain
probability too rapidly when moving away from ¯x.

Moving on to the second term. We expand the condi-
tional entropy around ¯x up to the second order in (x− ¯x):
Z dy p(y|x) log p(y|x) ≈Z dy(cid:20)p(y|¯x) log p(y|¯x)+

(cid:18) ˙p(y|¯x) log p(y|¯x) +
˙p(y|¯x)2
p(y|¯x) ln 2

2(cid:18)¨p(y|¯x) log p(y|¯x) +

1

ln 2 (cid:19) (x − ¯x)+
˙p(y|¯x)

+

ln 2 (cid:19) (x− ¯x)2(cid:21).
¨p(y|¯x)

(28)

Taking now the average of the above expression over the
prior p(x), the linear term vanishes and the result reads:

H(Y |X) ≈ −Z dy(cid:20)p(y|¯x) log p(y|¯x)+
˙p(y|¯x)2
−
p(y|¯x) ln 2

2 (cid:18)¨p(y|¯x) log p(y|¯x) +

∆2
0

+

ln 2 (cid:19)(cid:21).
¨p(y|¯x)

(29)

Subtracting (29) from (27) we arrive at:

I(X : Y ) ≈

∆2
0
2 ln 2

F (¯x),

(30)

where F (¯x) is the FI of p(y|x) evaluated at ¯x.
Note, that in the above derivation, while expanding the
logarithm in the expression for Shannon entropy H(Y )
we have assumed that ∆2
¨p(y|x)| ¯x
p(y|¯x) ≪ 1. In order to ex-
pand logarithm in the expression for conditional entropy

2 ln 2

0

H(Y |X) we additionally assumed also that ∆2
0 ≪ 1/F (¯x)
meaning the prior variance is much smaller than the vari-
ance dictated by the CR bound. This intuitively means
that for the approximation (30) to hold our gain of knowl-
edge on the parameter obtained from the observed data
must be small compared to prior knowledge.

Eq. (30) reminds of a known relation between the FI
and the relative entropy. Relative entropy D(pkq) =
Py p(y) log[p(y)/q(y)] is a natural measure of a diﬀerence
between two probability distributions. When consid-
ering two neighbouring probability distributions p(y|x),
p(y|x + dx) their relative entropy is approximated by the
FI up to the second order in dx [39]:

D[p(y|x + dx)||p(y|x)] ≈

1

2 ln 2

F (x)dx2.

(31)

On the other hand mutual information may be expressed
via relative entropy as:

I(X : Y ) =Z dx p(x)D[p(y|x)||p(y)].

(32)

Had we replaced p(y) in the above formula with p(y|¯x)
and expanded relative entropy around ¯x using (31) we
would indeed get (30). Validity of this replacement
hinges upon the assumption that knowledge of the input
parameter to be equal to the prior mean does not alter
the conditional probability substantially. This again in-
tuitively corresponds to the weak estimation regime, but
is hard to justify formally without a more detailed anal-
ysis as presented above.

B. Quantum case

Moving now on to the quantum world, we ask for the
generalization of (30) that would provide a connection
between quantum communication and quantum estima-
tion concepts. The most natural step would be to re-
place the FI appearing in (30) with the QFI. Indeed, this
is a right approach provided we use product input states
and no collective measurements, hence the (1, 1) scenario.
In this case we simply replace single channel probabili-
ties p(y|x) with Tr(ρxΠy). Since there always exist a
measurement for which the corresponding FI equals to
the QFI, this implies that when communicating using ρx
states with variance of prior distribution much narrower
than 1/FQ(ρ¯x) the mutual information may be approxi-
mated as:

max
{Πy}

I(X : Y ) ≈

∆2
0
2 ln 2

FQ(ρ¯x).

(33)

As a side remark, note that utilizing inequality (21), as-
suming a Gaussian prior and making use of an explicit
relation between the the Bayesian cost and the QFI given
in Eq. (20) leads to:

max
{Πy}

I(X : Y ) ≥ H(X) −

1
2

log[2πe∆2

0(1 − ∆2

0FQ(¯ρ)].

(34)

Since for Gaussian prior H(X) = 1

2 log(2πe∆2

0), we get:

7

I(X : Y ) ≥ −

1
2

log[1 − ∆2

0FQ(¯ρ)] ≈

∆2
0
2 ln 2

FQ(¯ρ).

max
{Πy}

(35)
Where the right hand side of the above inequality diﬀers
from (33) only by the replacement of ρ¯x with ¯ρ. Clearly
this makes sense, as mixing a state cannot increase the
QFI, and hence the above inequality is indeed in agree-
ment with our approximation.

Let us now consider the Holevo quantity given by
(4) describing communication capabilities when collective
measurements are allowed. First note, that the Holevo
quantity may be expressed as

χ({px, ρx}) =Z dx p(x)D(ρx||¯ρ),
where ¯ρ =R dx ρx is the average state and
D(ρ||σ) = Trρ(log ρ − log σ)

(36)

(37)

is the quantum relative entropy [3]. Interestingly, when
expanding the quantum relative entropy for neighbouring
quantum states up to the second order we get [40]

D(ρx+dx||ρx) ≈

1

2 ln 2

J(ρx)dx2

(38)

where

J(ρx) =

˙p2
n
pn

d

Xn=1

+ 2

d

(pn − pm)|hn| ˙mi|2 ln pn, (39)

Xn,m=1

with pn and |ni being the eigenvalues and eigenvectors
of ρx and d the dimension of the Hilbert space. Compar-
ing the above equation with (11) it is clear that J(ρx)
is in general not equal to the QFI, and we will refer
to it as the relative entropy quantum Fisher informa-
tion (REQFI). In fact it upperbounds the respective QFI
J(ρx) ≥ FQ(ρx), with equality for diagonal density ma-
trixes [40]. Moreover, REQFI gives meaningful results
only on mixed states, being inﬁnite on pure states. This
last fact is a counterpart of the inﬁniteness of quantum
relative entropy for pure states.

Proceeding by analogy to the classical case, one might
attempt to replace ¯ρ with ρ¯x in (36), plug in the expan-
sion (38) and arrive at an approximate formula for Holevo
quantity as in (33) but with QFI replaced by the REQFI.
Instead, we provide below a general derivation for the
approximating formula for the Holevo quantity, which
proves that the above heuristic argument only works in
case of full rank states (or states which are eﬀectively
full rank in the sense that their kernel subspace can be
trivially removed from the considerations) and is not jus-
tiﬁed in general. Intuitively, this is related with the fact
that ¯ρ which is obtained as a probabilistic mixture may
in general be a state of higher rank than ρ¯x, and has a
signiﬁcant impact on the Holevo quantity.

Taking the Holevo quantity

(41) we get:

8

χ = S(¯ρ) −Z dxp(x)S(ρx)

(40)

0 ¨ρ¯x
2

we expand ρx around the prior mean ¯x up to the second
order and get ρx ≈ ρ¯x + ˙ρ¯x(x − ¯x) + 1
2 ¨ρ¯x(x − ¯x)2. The
average state at the output is therefore equal to ¯ρ =
R dx p(x)ρx ≈ ρ¯x + ∆2
. Let pn denote eigenvalues and
|ni denote eigenbasis of ρ¯x, which in case of degeneracy is
further specialized to diagonalize ¨ρ¯x on each degenerate
subspace. To calculate the ﬁrst term in (40) we only need
to know eigenvalues ¯pn of ¯ρ. Treating ∆2
term as a
small perturbation added to ρ¯x we make use of standard
perturbation theory and get that up to the ﬁrst-order
, where (¨ρ¯x)nn = hn|¨ρ¯x|ni

corection ¯pn ≈ pn + ∆2

0( ¨ρ¯x)nn

0 ¨ρ¯x
2

2

and hence

S(¯ρ) ≈ −

d

Xn=1(cid:18)pn +

∆2

0(¨ρ¯x)nn

2

(cid:19) log(cid:18)pn +

∆2

0(¨ρ¯x)nn

2

(cid:19) .

(41)
We make analogous assumption as in the classical deriva-
tion, namely that eigenvalues that are zero when x = ¯x do
not grow too rapidly when moving away from ¯x. Hence
we assume that if pn = 0 then also ˙pn = ¨pn = 0. Still
the situation we face is signiﬁcantly diﬀerent than in the
classical case. Even with the assumptions made, we are
not entitled to neglect the terms for which pn = 0 since
˙pn = ¨pn = 0 does not imply that (¨ρ¯x)nn = 0. This is
a crucial point and is related to the intrinsically quan-
tum transformation of the states—the unitary transfor-
mation. Let r ≤ d be the rank od ρ¯x. We split (41) into
two parts depending on whether pn is strictly positive
(1 ≤ n ≤ r) or zero (r + 1 ≤ n ≤ d) and expand the
logarithm whenever it is positive

S(¯ρ) ≈ −

r

Xn=1(cid:18)pn +
Xn=r+1

−

d

∆2

0(¨ρ¯x)nn

2

(cid:19) log pn +

∆2

0(¨ρ¯x)nn
2 ln 2

+

∆2

0(¨ρ¯x)nn

2

log

∆2

0(¨ρ¯x)nn

2

.

(42)

Moving on to the second term in (40), note that S(ρx)
only depends on eigenvalues of ρx and its expansion is
identical as in the classical case. Hence after averaging
over p(x) we get

r

Z dxp(x)S(ρx) ≈
Xn=1(cid:20)pn log pn +
−

∆2
0

2 (cid:18)¨pn log pn +

˙p2
n

pn ln 2

+

¨pn

ln 2(cid:19)(cid:21),

(43)

where the sum is over non-zero pn. Subtracting (43) from

χ ≈

r

Xn=1

∆2
0

2 ln 2(cid:18)[¨pn − (¨ρ¯x)nn][ln pn + 1] +

˙p2
n

pn(cid:19) +

d

−

Xn=r+1

∆2

0(¨ρ¯x)nn

2

log

∆2

0(¨ρ¯x)nn

2

.

(44)

n=1 ¨pn = 0, and
n=1(¨ρ)nn = 0 (note the summation upper limit is d),

r

and as a result:

Thanks to trace preservation Pr
Pd
χ ≈

2 ln 2(cid:18)[¨pn − (¨ρ¯x)nn] ln pn +
Xn=1
Xn=r+1
−

(cid:18) 1

0(¨ρ¯x)nn

+ log

∆2
0

ln 2

∆2

2

d

˙p2
n

pn(cid:19) +

∆2

0(¨ρ¯x)nn

2

(cid:19) .

(45)

Writing (¨ρ¯x)nn explicitly we have

(¨ρ¯x)nn = ¨pn − 2pnh ˙n| ˙ni + 2

r

Xk=1

pk|hn| ˙ki|2.

(46)

Note that h ˙n| ˙ni =Pd
orthonormal eigenvectors then
can replace h ˙n|ki with −hn| ˙ki arriving at:

k=1 |h ˙n|ki|2 and since |ki, |ni denote
˙hk|ni = 0 and hence we

(¨ρ¯x)nn = ¨pn + 2

d

(pk − pn)|hn| ˙ki|2.
Xk=1

(47)

Plugging the above formula into (45) and recalling the
deﬁnition of REQFI, Eq. (39), we arrive at the ﬁnal ex-
pression:

∆2
0
2 ln 2

χ ≈

J(ρ¯x) −

d

Xn=r+1

∆2

0Fn(ρ¯x)

4

log

∆2

0Fn(ρ¯x)

4e

, (48)

where the underline symbol in J indicates that the sum
in the deﬁnition of J is restricted to n ≤ r, avoiding zero
pn, and thus, unlike J which may sometimes be inﬁnite,
J is always ﬁnite. The Fn quantities appearing in the
second term read:

Fn(ρ¯x) = 2(¨ρ¯x)nn.

(49)

In order to interpret them note that when diﬀerentiating
the deﬁnition of SLD, Eq. (10), we get:

1

¨ρ¯x =

2(cid:16) ˙ρ¯xL¯x + ρ¯x ˙L¯x + ˙L¯xρ¯x + L¯x ˙ρ¯x(cid:17)

and using Eq. (10) again yields

(50)

¨ρ¯x =

1

2(cid:18)L¯xρ¯xL¯x +

1
2

(ρ¯xL2

¯x + L2

¯xρ¯x) + ρ¯x ˙L¯x + ˙L¯xρ¯x(cid:19) .

(51)

Sandwiching with |ni, which is outside the support of ρ¯x
(n ≥ r + 1), and plugging into Eq. (49) we arrive at

Fn(ρ¯x) = hn|L¯xρ¯xL¯x|ni.

(52)

Comparing this with the deﬁnition of the QFI, Eq. (9),
which can be rewritten as:

FQ(ρ¯x) = Tr(ρ¯xL2

¯x) =

d

hn|L¯xρ¯xL¯x|ni,

Xn=1

(53)

we see that Fn represent contributions to QFI from the
subspace laying outside the support of ρ¯x—the kernel of
ρ¯x. Recall that the eigenbasis |ni outside the support of
ρ¯x is not arbitrary but was assumed to diagonalize ¨ρ¯x.
The approximate expression for Holevo quantity,
Eq (48), simpliﬁes in two special cases. When ρ¯x is full
rank, or ¨ρ lives on the support of ρ¯x, the second term in
Eq (48) vanishes and the Holevo quantity only depends
on J:

∆2
0
2 ln 2

χ ≈

J(ρ¯x).

(54)

Going to the other extreme, if ρ¯x = |ψ¯xihψ¯x| is pure then
the SLD can be written explicitly:

L¯x = 2(|ψ¯xih ˙ψ¯x| + | ˙ψ¯xihψ¯x|)

(55)

and so:

L¯xρ¯xL¯x = 4(cid:18)| ˙ψ¯xih ˙ψ¯x| + |h ˙ψ¯x|ψi|2|ψ¯xihψ¯x|+

h ˙ψ¯x|ψ¯xi|ψ¯xih ˙ψ¯x| + hψ¯x| ˙ψ¯xi| ˙ψ¯xihψ¯x|(cid:19).

(56)

Thanks to h ˙ψ¯x|ψ¯xi + hψ¯x| ˙ψ¯xi = 0 identity we have
hψ|LρL|ψi = 0 and hence the whole contribution to QFI
comes from the kernel of ρ¯x. Let P0 be projector on the
kernel of ρ¯x, then:

2P0 ¨ρ¯xP0 = P0L¯xρ¯xL¯xP0 = 4P0| ˙ψ¯xih ˙ψ¯x|P0.

(57)

Let us write | ˙ψ¯xi = a|ψ¯xi + b|ψ⊥¯x i, where |ψ⊥¯ψ i is orthog-
onal to |ψ¯xi. It is now clear that the |ψ⊥¯x i is a proper
choice of eigenvector in the kernel subspace that makes
| ˙ψ¯xi diagonal on this subspace. Moreover, this is the only
vector that will yield any contribution to QFI, and hence
there is only one non zero Fn (n = 1 + 1) which reads:

F2 = 4|hψ⊥¯x | ˙ψ¯xi|2 = 4(h ˙ψ¯x| ˙ψ¯xi − |hψ¯x| ˙ψ¯xi|2) = FQ (58)
and is equal to the QFI, see Eq. (12). Summarizing,
for pure state protocols Holevo quantity can be approxi-
mated using only the QFI as:

χ ≈ −

∆2
0FQ(|ψ¯xi)

4

log

∆2
0FQ(|ψ¯xi)

4e

.

(59)

9

C. Manifestations of super-additivity

Approximate formulas for the mutual

information,
Eq. (33), as well as for the Holevo quantity, Eq. (48),
provide an interesting insight into the issues of super-
additivity. Let us ﬁrst assume that no entanglement is
used at the input, and that the output states coming out
of individual channels are ρx = Λx(ρin). Let Cp(x),Λx de-
note the “capacity” of the channel under a ﬁxed encoding
deﬁned by the prior as well as channel parameter depen-
dence {p(x), Λx}. Note that when talking about capacity,
we implicitly consider a scenario where the above spec-
iﬁed encoding is repeated independently over N chan-
nels. By independently, one should understand here that
the full action of N channels is Λx1 ⊗ ··· ⊗ ΛxN , where
xi are i.i.d. distributed according to the prior distribu-
tion considered. Assuming the prior is narrow enough so
that our approximations hold, and we restrict ourselves
to only individual measurements at the output then in-
voking the approximate formula (33) for the mutual in-
formation yields:

C(1,1)
p(x),Λx ≈ max

ρin

∆2

0FQ[Λ¯x(ρin)]

2 ln 2

.

(60)

If, however, collective measurements are allowed then uti-
lizing Eq. (48) we get:

ρin

C(1,∞)
p(x),Λx ≈ max
∆2
Xn=r+1

d

∆2
0
2 ln 2

J(Λ¯x(ρin))−
∆2

log

4

0Fn[Λ¯x(ρin)]

0Fn[Λ¯x(ρin)]

,

(61)

4e

where the rank r here refers to the rank of ρ¯x = Λ¯x(ρin).
Comparing the above two formulas one can easily ap-
preciate the advantages coming from the use of collective
measurements. Let us deﬁne a natural measure of output
super-additivity as the ratio of the two capacities

γ(1,∞) = C(1,∞)
p(x),Λx

/C(1,1)

p(x),Λx

.

(62)

Focusing for clarity on the two extreme cases of full rank
and pure output states, in which simple approximate for-
mulas (54,59) for Holevo are valid, the super-additivity
measure reads

γ(1,∞) ≈( J(ρ¯x)
− ln 2

FQ(ρ¯x)

2 log ∆2

0FQ(|ψ¯xi)

4e

full-rank

pure

.

(63)

Inspecting the full-rank case, we see that the measure
of output super-additivity is equal to the ratio of the
REQFI J and the QFI FQ. We have already stressed
before that in general J ≥ FQ and now we can fully
appreciate that the gap between these two quantities is
actually responsible for the output super-additivity in the
weak communication regime.

On the other hand, in case of pure states, γ(1,∞) is
determined solely by the QFI and is divergent in the limit

∆2
0 → 0 indicating a more than a constant factor gain in
communication potential thanks to the use of collective
measurements.

Approaching now the input super-additivity issue, let
us consider a scenario where N channels are divided into
k-channel subgroups, Λ⊗k
x , that accept k-partite entan-
gled probes at their inputs, so that the action of all chan-
nels is described as Λ⊗k
. Note that all chan-
nels within one subgroup encode the same value of the
parameter, and this is repeated independently for other
subgroups. The corresponding “capacity” reads:

x1 ⊗···⊗Λ⊗k

xN/k

C(k,∞)
p(x),Λx

=

1
k

max
ρk,in

χ({p(x), Λ⊗k

x (ρk,in)}).

(64)

Provided we stay in the regime where our weak com-
munication assumption holds, the Holevo quantity is ex-
pressible using FQ and J and the issue of input super-
additivity is therefore related to the issue of super-
additivity of the QFI and the REQFI.

i.e.

> F (1,∞)

Super-additivity of QFI,

the property that
F (k,∞)
, has been already discussed in Sec. III
Q
and is a typical feature of most quantum channels estima-
tion problems with an exception of a very narrow class,
e.g.
loss estimation, where no entanglement at the in-
put is needed to reach the optimal performance [41]. For
example, when ideal unitary parameter estimaion is con-
sidered then F (k,∞)
grows linearly in k and when plugged
into pure-state approximate formula for Holevo (59) the
“capacity” (64) will get a further boost from the input
super-additivity.

Q

Q

Super-additivity of the REQFI is much less studied,
but its relevance is clear from our above analysis as noisy
channels produce output states ρ¯x which are likely to
be highly mixed and satisfy the conditions which make
the simpler formula for Holevo approximation (54) valid.
While the tools for studying the QFI in noisy channels are
highly developed and allow to draw immediate conclu-
sions on e.g. the maximal gain that can be oﬀered by en-
tangled probes, analogous studies have not been pursued
in case of REQFI, as this quantity being an upper bound
on QFI typically provides looser bounds in quantum es-
timation problems and hence apart from mathematical
investigations was rarely appreciated in a more practical-
oriented studies. We hope that our present work, will
boost the interest in the REQFI, as an element provid-
ing a connection between estimation and communication
problems. For the time being, we provide here an ex-
ample of reasoning that shows how super-additivity of
REQFI may be analyzed using tools developed in the
quantum estimation ﬁeld.

One of the simplest ideas allowing to ﬁnd the limit on
the maximal achievable QFI when entangled probes are
used, is the idea of classical simulation of the channel
[32, 42].
In this approach, one treats quantum chan-
nel space as a probability space over which classical pa-
rameter dependent probability distribution emulates the
quantum channel change, and one upper bounds the QFI

10

by a classical FI of this probability distribution. The ba-
sic property of the QFI that is used in this derivation is
that it does not increase under parameter-independent
channels and reduces to classical FI for diagonal density
matrices. The same properties are, however, also enjoyed
by the REQFI. One can therefore immediately apply the
known upper bounds on QFI derived using classical sim-
ulation method to REQFI. Now provided, the bound on
QFI is asymptotically saturable, this automatically im-
plies that since J ≥ FQ the bound is saturable for J as
well, and in this way one can obtain an asymptotic for-
mula for J optimized over entangled input state of large
number of probes proving in particular its input super-
additivity. We present quantitative results obtained with
the help of this kind of reasoning in Sec. VI.

Therefore, it is clear from the discussion above that
in the weak estimation regime, we enjoy both aspects of
quantum super-additivity; ﬁrst on the level of measure-
ments (output super-additivity) formally reﬂected by the
replacement of FQ by J or − ln 2FQ log ∆2
0FQ/4e in the
approximate formula for the Holevo quantity; and second
on the level of input probes related to the input super-
additivity of FQ and J.

We should note, however, that the requirements of our
approximation never allow us to increase k too much, and
least of all consider k → ∞. This is because our weak
estimation assumption requires that what we learn at the
output is small compared to prior knowledge. Clearly, by
increasing k we increase the information available about
the input parameter and hence at some point the approx-
imation needs to break down. In the next subsection, for
completeness of our presentation we discuss in more de-
tail the opposite regime of k → ∞, which we refer to
as the strong estimation regime and contrast it with the
weak estimation regime discussed so far.

D. Strong estimation regime

k|x) = Πk

We start with a classical scenario. Consider k inde-
pendent repetitions of an experiment governed by the
same conditional probability distribution p(yi|x) so that
k =
the joined probability distribution of k results y
{y1, . . . , yk} reads: p(y
i=1p(yi|x). Note the
ﬁxed value x for all experiments. As mentioned already
in Sec. III, thanks to the local asymptotic normality theo-
rem [28] we know that in the limit of large k, the problem
can be translated to that of estimating x from a Gaussian
distribution with mean being shifted by √kx and vari-
ance equal to 1/F (x). Less formally, we can think of this
problem as estimating shift x from a Gaussian distribu-
tion with variance narrowing as 1/(kF (x)). This allows
to obtain an asymptotic formula for the mutual informa-
tion in this protocol treating it as a communication task

of transmitting x [27, 43]:

I(X : Y k) = H(X) − H(X|Y k) ≈
−Z dx p(x) log p(x)−Z dx p(x)

1
2

log(cid:18)2πe

1

kF (x)(cid:19)+o(1),

(65)

where the second term represents the average entropy of
a Gaussian distributions with variance 1/(kF (x)), and
the o(1) is a term of order 1 appearing due to the fact
that perfect Gaussianity is achieved only asymptotically.
The above formula can be rewritten in a more appealing
form

I(X : Y k) ≈

1
2

log

k

2πe

+Z dx p(x) log pF (x)

p(x)

+ o(1),

(66)
which clearly shows that the information communicated
increases only logarithmical with k, and that it is max-

imised for Jeﬀreys prior p(x) ∼ pF (x) [27]. Jeﬀreys

prior is often considered the least informative prior and
therefore it is used to represent a complete lack of knowl-
edge about the parameter [44].

Due to only logarithmic increase in mutual informa-
tion, the strong estimation regime is not likely to be in-
teresting for communication purposes. Given N to be a
total number of available uses of a channel, it is preferable
to keep k relatively small and repeat the communication
procedure N/k times using independently distributed in-
put parameters xi. While each of the parameters will not
be estimated particularly well, the resulting mutual in-
formation will scale like N/k quickly surpassing the log N
behaviour which we would be left with had we set k to its
maximal available value N in order to perform the most
precise parameter estimation possible.
In other words,
for the purposes of communication it is much better to
have an increasing number of independent parameters
transmitted under ﬁxed noise, rather than a ﬁxed num-
ber of parameters transmitted under decreasing noise.

Considering the quantum counterpart of the above sce-
nario with no entanglement used at the input, i.e. the re-
ceiver obtains ρ⊗k
state, and no collective measurements
allowed at the output, we immediately get an analogue
of (66) by substituting F (x) with FQ(ρx). This is be-
cause one can always ﬁnd a local measurement for which
F = FQ.

x

On the other hand, if we allow for collective measure-
ments we no longer enjoy the product structure of the
conditional probability distribution, and therefore can-
not directly apply the results of classical local normal-
ity theory. Fortunately, quantum generalization of local
asymptotic normality [45, 46] states that the estimation
of a parameter from a product state ρ⊗k
in the limit of
large number of copies k → ∞ is equivalent to estima-
tion of a displacement of a particular Gaussian quantum
state with a variance in the direction of the shift corre-
sponding to the QFI—there exist CP maps that trans-
late one problem to another under trace norm. Thanks

x

11

to continuity of the von-Neuman entropy with respect
to the trace norm [47, 48] we may therefore argue that
calculation of the Holevo quantity may also be done us-
ing the Gaussian states. We do not attempt to give a
rigorous proof here, but by analogy these observations
suggest that a good approximation to Holevo quantity in
the strong estimation regime should be

χ({p(x), ρ(x)⊗k}) ≈

1
2

log

k

2πe

+Z dx p(x) log pFQ(ρx)

p(x)

+ o(1).

(67)

Therefore, this intuition suggest that collective measure-
ments oﬀer no additional advantage here, unlike in the
weak estimation regime.

Thinking now of entangled input probes in the strong
estimation scenario, one should not expect a relation like
above to hold in general. Some fundamental incompat-
ibilities between QFI based and entropy-communication
based approaches when entangled input probes are con-
sidered where underlined in [22, 38]. The most striking
is the example of phase estimation using NOON states.
While QFI grows as k2, the information communicated
is never larger than a single bit as the output state is
restricted to a two-dimensional subspace. Something rel-
atively general, can nevertheless be said. In case channels
Λx are noisy, the QFI at the output for optimally entan-
gled input probes generically scales linearly with k and
the quantum enhancement amount to a constant factor
improvement [33]. Moreover, as argued in [49, 50] one
can achieve almost optimal performance utilizing states
where k probes are divided into groups of g particles
where entanglement is present only among the particles
belonging to the same group. In such a scenario, one can
approximate the input state as a product state of large
number of groups, number of which will tend to inﬁnity
while their size will remain constant when k → ∞. This
makes it possible again to apply the reasoning based on
quantum local asymptotic normality, and argue that for
this class of states (67) holds where FQ(ρx) is replaced
with 1
g FQ(Λ⊗g(ρg,in)) representing a performance gain
thanks to the use of entangled input probes.

In short. While in the weak estimation/communicaton
regime we have observed both the eﬀects of input and
output super-additivity in the strong-estimation regime
there seems to be no gain from the use of collective mea-
surements while one may still observe beneﬁts coming
from entanglement present in the input states.

VI. EXAMPLES

In this section we provide two examples of communi-
cation for which one can easily analyze issues of input
and output super-additivity using the knowledge of the
behavior of the QFI and the REQFI and study the va-
lidity of our approximation by comparing it to rigorous
calculations.

1.00
0.98
0.96
0.94
0.92
0.90
0.88

2.0

1.8

1.6

1.4

1.2

Γ

1.0

0.0

r
p
a
Χ

Χ

1

2

5

D0

10 20
2´10-3

50 100

0.2

0.4

0.6

0.8

1.0

Η

p(ϕ),Λϕ

p(ϕ),Λϕ

p(ϕ),Λϕ

/C (1,1)

/C (1,1)

The output super-additive gain factor γ(1,∞) =
FIG. 2.
C (1,∞)
(black) for qubit dephasing channel as a
function of dephasing parameter η is compared with the case
when entanglement between two channels inputs is addition-
ally allowed γ(2,∞) = C (2,∞)
(red); the prior vari-
ance is assumed to be ∆2
0 = 2 × 10−2. The dashed curves
represent the same quantities calculated using narrow-prior
approximate formulas (71). The inset depicts the validity of
our approximation by presenting the ratio of the exact Holevo
information (70) to the approximate expressions as a function
of variance of prior distribution in decoherence-free case η = 1
(black, dotted) as well as in presence od dephasing η = 0.9
for product (black, solid) and optimally entagled two-channel
inputs (red, solid).

p(ϕ),Λϕ

A. Qubit dephasing channel

As a ﬁrst, illustrative example, let us consider a phase
encoding qubit channel in presence of partial dephasing:

ρϕ = Λϕ(ρin) = Uϕ  1
Xi=0

KiρinK†i! U†ϕ,

(68)

where Uϕ = e−iϕσz /2 is the unitary phase encoding oper-
ator, with σz denoting Pauli z operator, whereas Ki are
Kraus operators of the dephasing map

K0 =r 1 + η

2

1, K1 =r 1 − η

2

σz,

(69)

where η is the dephasing parameter.

0

1√2π∆2

e−ϕ2/2∆2

We choose a Gaussian prior probability distribution
p(ϕ) =
0 which is a valid probability dis-
tribution on a circle ϕ ∈ [−π, π] for small variances ∆2
0
which is the regime we are interested in. The Holevo in-
formation for this model is maximized for input states
lying on the equator of the Bloch ball and can be easily
calculated yielding

C(1,∞)

p(ϕ),Λϕ

= h2  1 + ηe−∆2

2

0/2

! − h2(cid:18) 1 + η
2 (cid:19) ,

(70)

where h2(x) = −x log x − (1 − x) log(1 − x) denotes a
binary entropy function.
In the limit of narrow prior
distribution ∆2

12

(71)

0 ≪ 1 the above formula becomes
p(ϕ),Λϕ≈( η∆2
− ∆2

log 1+η
1−η
4 log ∆2
0
4e

η = 1

η < 1

4

.

C(1,∞)

0

0

Let us now analyze this model with the help of the
ideas developed in this paper. From (60) we know that
C(1,1) can be expressed through the QFI. Phase estima-
tion in presence of dephasing is a well understood prob-
lem, the QFI is again maximzed for states lying on the
equator and reads maxρin FQ[Λ0(ρin)] = η2. Hence

C(1,1)
p(ϕ),Λϕ ≈

η2∆2
0
2 ln 2

.

(72)

p(ϕ),Λϕ

p(ϕ),Λϕ

2 ln 1+η

2η ln 1+η

Knowledge of the maximal QFI is also suﬃcient to cal-
culate approximate C(1,∞)
in the decoherence-free case
(η = 1) with the help of (59) and yields the result which
agrees with (71). On the other hand, in presence of de-
coherence, η < 1, in order to get an approximate ex-
pression for C(1,∞)
we need to calculate the REQFI
and optimize it over input states. The resulting expres-
sion reads maxρin J[Λ0(ρin)] = η
1−η . Since the output
state Λ0(ρin) is supported on the whole Hilbert space we
may utilize (54) and as a result get the same expression as
in (71). In this case the output super-additivity measure
γ(1,∞) = 1
1−η ≥ 1 proving the generic advantage of
the use of collective measurements in this communication
protocol. Note, however, that for large dephasing η ≪ 1
we have γ(1,∞) → 1 and super-additive behavior of the
capacity is lost, see Fig. 2.
To analyze input super-additivity we need to analyze
the QFI and REQFI for phase estimation in presence of
dephasing when inputs states are allowed to be entan-
gled. For decohrenece free case QFI exhibits Heisenberg
limited scaling and we have F (N,∞)
= N which means
that with optimal procedure F (N,∞)
> F (1,∞)
. Conse-
quently, the optimal QFI for dephasing is super-additive
and therefore also capacity for decoherence-free commu-
nication exhibits input super-additivity. If, on the other
hand, the decoherence is present in our setup, we should
consider REQFI instead of QFI. It was shown in [31, 32]
that asymptotically, for large number N of two-level par-
ticles the QFI per particle is bounded by an expression
F (N,∞)
1−η2 and the bound is tight in a sense that for
Q
large N one can ﬁnd an entangled input state and mea-
surement for which the inequality is saturated. However,
as stated in Sec. V C, REQFI must obey the same classi-
cal simulation bound as QFI and since the bound can be
saturated by the latter quantity it necessarily also have
to be tight for the former one. Therefore we may ap-
ply the same reasoning as in the decoherence-free case,
this time with a conclusion that J (N,∞) > J (1,1). This
implies that also in the presence of nonzero dephasing
sending entangled input states can improve the capacity

≤ η2

Q

Q

Q

r
p
a
Χ

Χ

1.00
0.95
0.90
0.85
0.80
0.75
0.70
0.65

10-4 0.001 0.01

0.1

n

3.5

3.0

2.5

2.0

1.5

Γ

1.0

0.0

0.2

0.4

0.6

0.8

1.0

Η

p(α),Λα

p(α),Λα

/C (1,1)

FIG. 3. The output super-additive gain factor γ(1,∞) =
C (1,∞)
for optical communication utilizing coher-
ent states with narrow gaussian amplitude distribution via a
thermal lossy channel as a function of transmission coeﬃcient
η for average input photon number ¯n = 0.01 and thermal
number of photons nth = 0.1 (red, solid), nth = 1 (black,
solid). The dashed lines represent the same quantities calcu-
lated using our approximation. The ratio of the exact Holevo
value to the approximated one is depicted in the inset as a
function of the average input photon number which plays the
role of the width of input parameter distribution: nth = 0,
η = 0.9 (black, dotted), nth = 0.1, η = 0.5 (red, solid),
nth = 1, η = 0.99 (black, solid).

in addition to gains already present thanks to utilizing
collective measurements, see Fig. 2 where the beneﬁts of
entangling two inputs are depicted and it is clear that
C(2,∞)

> C(1,∞)

.

p(ϕ),Λϕ

p(ϕ),Λϕ

B. Bosonic thermal channel

The utility of our approximated formulas applied to
the qubit example presented above may be questioned
as they are only valid in the weak estimation regime of
narrow prior phase distribution and it is not clear what
practical motivation might justify the use of such a nar-
row input phase encoding for communication purposes.
In order to show that the limit is actually of physical in-
terest, as our second example let us consider a model of
optical communication through a thermal channel which
is a quantum analogue of classical additive white Gaus-
sian noise channel. As will be clariﬁed below, in this
case the weak estimation limit we are interested in ap-
pears naturally in practical applications as it corresponds
to the regime of small input light intensities—a regime
of high relevance and extensively investigated in optical
communication literature [15, 16, 51, 52].

Intuitively, the evolution of an input state of light
through the thermal channel may be described as mixing
a single mode input state with a thermal state ρ¯nth =
(¯nth+1)n+1|nihn| with average number of photons

¯nn
th

P∞n=0

13

¯nth on a beamsplitter with transmissivity η. Note, that
in the extreme case ¯nth = 0 the thermal channel de-
scribes pure photon losses. We assume that the encoding
of information is in the amplitude α ∈ R of a coher-
ent state with a Gaussian prior probability distribution
e−α2/2¯n, where ¯n is the average number of
p(α) = 1√2π ¯n
photons per channel use in our communication proce-
dure and simultaneously plays the role of the variance
of the amplitude random variable. The encoding pro-
cedure is realized by the action of a displacement oper-
ator on the input vacuum state |αi = D(α)|0i, where
D(α) = eαˆa†−αˆa and ˆa, ˆa† are respectively annihilation
and creation operators of the input bosonic mode. Since
both coherent and thermal states as well as the evolution
are Gaussian we may easily express the output state. To
do this we apply the methods from [53] and get displaced
thermal states at the output

ρα = Λα(|0ih0|) = D(√ηα)ρ(1−η)¯nth D(√ηα)†.

(73)

4η

1+2(1−η)¯nth

and J = 2η ln 1+(1−η)¯nth
(1−η)¯nth

Since the above state is already written in its eigenba-
sis we can use (11) and calculate QFI and REQFI for
the problem of displacement parameter estimation, which
read FQ =
respec-
tively. We can now use these results in order to write
communication rate in the regime of small average num-
ber of photons ¯n ≪ 1, which is exactly the regime of
narrow prior distributions. First of all, in the absence of
thermal environment ¯nth = 0 i.e. for lossy channel, the
output states are pure ρα = |√ηαih√ηα| so according to

(59) we have

χ ≈ η¯n log

e
η¯n

,

(74)

whereas even if only a small amount of thermal photons
is present the output state is mixed and by (54) the rate
is reduced to

χ ≈ η¯n log

1 + (1 − η)¯nth

(1 − η)¯nth

.

(75)

These expressions agree with the expansion in the aver-
age number of photons of the exact Holevo information
for thermal channel which is given by

(76)

χ = f(cid:16)pβ(2η¯n + β)(cid:17) − f (β) ,
where the function f (x) = (cid:0)x + 1
2(cid:1) −
(cid:0)x − 1
2 + (1 − η)¯nth is the di-
agonal element of the covariance matrix of the thermal
state ρ(1−η)¯nth [54]. The convergence of approximate and
exact formulas for small average number of photons can
be seen in the inset of Fig. 3.

2(cid:1) and β = 1

2(cid:1) log(cid:0)x + 1

2(cid:1) log(cid:0)x − 1

The above results imply that in the limit of small av-
erage number of photons Holevo information behavior
changes drastically depending whether there are thermal
photons in the environment or not. In the ﬁrst case, ac-
cording to (75), the rate scales linearly with the average

number of photons. If, however, the environment is in
the vacuum state, that is we are dealing with purely lossy
channel, we see from (74) that rate scales super-linearly
with ¯n. The presence of thermal environment therefore
can reduce the rate signiﬁcantly in the regime of weak
signal power.

From the form of the QFI and the REQFI it is also
evident that information transmission rates for the con-
sidered setup clearly exhibit output super-additivity. In
both cases, either the pure lossy channel or thermal chan-
nel, we see that Holevo information is larger than the
respective accessible information, which in the weak esti-
mation limit is clearly visible thanks to the use of formu-
las (63) and the fact that in our case J > FQ. This super-
additive behavior is depicted in Fig. 3. Note, however,
that large thermal noise reduces the gain from using col-
lective measurements and asymptotically for ¯nth ≫ 1 we
do not see super-additive behavior limnth→∞ γ(1,∞) = 1.
On the other hand, in the absence of thermal photons,
one still gets the advantage from output super-additivity
in the regime of small average number of signal photons
irrespectively of losses present.

Finally, let us also point out that (74) and (75) agree
with asymptotic expansion of the capacity of lossy and
thermal channels respectively [55, 56] in the limit of small
average number of signal photons. Therefore based on
our approximation we can conclude that in the regime
of weak signal power in order to obtain optimal per-
formance of communication it is suﬃcient to encode in-
formation using just the displacement in single quadra-
ture and Gaussian prior probability. This is an example,
where the encoding in the estimation problem considered
happens to be the optimal encoding in the problem of un-
restricted capacity optimization, and hence results may

14

be directly related with the actual channel capacity for-
mulas and not only with the channel “capacities” under
sub-optimal encodings.

VII. CONCLUSIONS

We have highlighted a connection between communica-
tion concepts such as mutual information and the Holevo
quantity and Fisher information related quantities uti-
lized in quantum estimation theory. The presented ap-
proach allows to trace the aspects of super-additivity
both at the input as well as at the output stages of the
communication protocols provided one operates in the
weak estimation regime where the amount of informa-
tion learned from the measurements is small compared to
the prior knowledge. This regime is in particular highly
relevant in optical communication utilizing weak light
beams. The main message of the paper is that in this
regime the input super-additivity can be linked to the
input super-additivity of the QFI FQ and the REQFI J
whereas the output super-additivity is intimately related
with the majorization of FQ by J. Our results provide
also a new operational interpretation for J, as it appears
naturally in the approximate formula for the Holevo in-
formation in case of full rank output states as well as for
FQ which determines the communication performance in
case of pure output states.

We thank Michal Horodecki for useful discussions.
This work was supported by EU FP7 IP project SIQS
co-ﬁnanced by the Polish Ministry of Science and Higher
Education as well as by the Polish Ministry of Science
and Higher Education Iuventus Plus program for years
2015-2017 No. 0088/IP3/2015/73.

[1] C. Shannon, Bell System Technical Journal 27, 379 (1948).
[2] T. M. Cover and J. A. Thomas, Elements of information

theory (John Wiley & Sons, 2012).

[3] M. A. Nielsen and I. L. Chuang, Quantum computation
and quantum information (Cambridge university press,
2010).

[4] M. M. Wilde, Quantum Information Theory (Cambridge,

2013).

[5] B.

Schumacher

and M.

D. Westmoreland,

Phys. Rev. A 56, 131 (1997).

[13] M. Sasaki, K. Kato, M.

Izutsu,

and O. Hirota,

Physical Review A 58, 146 (1998).

[14] H. P. Yuen, “Quantum squeezing,”

(Springer, 2004)
Chap. Communication and Measurement with Squeezed
States, pp. 227–258.

[15] S. Guha, Phys. Rev. Lett. 106, 240502 (2011).
[16] K. Banaszek, Nature Photonics 6, 351353 (2012).
[17] D. Leibfried, M. D. Barrett, T. Schaetz, J. Britton,
J. Chiaverini, W. M. Itano, J. D. Jost, C. Langer, and
D. J. Wineland, Science 304, 1476 (2004).

[6] A. Holevo, Information Theory, IEEE Transactions on 44, 269 (1998).
[7] W. P. Shor, Communications in Mathematical Physics 246, 453 (2003).
[8] M.

Fukuda

Wolf,

and

M.

M.

[18] V. Giovannetti,

S. Lloyd,

and L. Maccone,

Phys. Rev. Lett. 96, 010401 (2006).

[19] V. Giovannetti,

S. Lloyd,

and L. Maccone,

Journal of Mathematical Physics 48, 072101 (2007),
arXiv:0704.1092 [quant-ph].

G.

[9] F.
M.
Open Systems and Information Dynamics 14, 333 (2007).

Horodecki,
Virmani,

L.
Plenio,

Brandao,

M.
S.

and

B.

S.

[10] M. B. Hastings, Nature Physics 5, 255 (2009).
[11] P. W. Shor, Nature Physics 5, 247 (2009).
[12] F. G.

and M. Horodecki,
Open Systems and Information Dynamics 17, 31 (2010).

L. Brandao

S.

Nature Photonics 5, 222 (2011).

[20] R.
M.
Progress in Optics (2015), 10.1016/bs.po.2015.02.003.

Demkowicz-Dobrza´nski,
Ko lody´nski,

Jarzyna,

and

J.

[21] R. Nair, arXiv preprint arXiv:1204.3761 (2012).
[22] M.

Hall

and

M.

H.

J.

Wiseman,

Physical Review X 2, 041006 (2012).

[23] A.

S.

Holevo

and

V.

Giovannetti,

Reports on progress in physics 75, 046001 (2012).

[24] N.

Datta

and

M.

B.

Ruskai,

Physical review letters 98, 160401 (2007).

Journal of Physics A: Mathematical and General 38, 9785 (2005).

[42] K.

Matsumoto,

ArXiv e-prints (2010),

[25] M.

M.

Wolf

and

J.

Eisert,

arXiv:1006.0300 [quant-ph].

15

New Journal of Physics 7, 93 (2005).

[26] S. Kay, Fundamentals of Statistical Signal Processing:
Estimation Theory, Fundamentals of Statistical Signal
Processing (Prentice-Hall, 1993).

[27] E. Lehmann and G. Casella, Theory of Point Estimation,
Springer Texts in Statistics (Springer New York, 2003)
chapter 4.5.

[28] A. W. Van der Vaart, Asymptotic statistics, Vol. 3 (Cam-

bridge university press, 2000) chapter 7.

[29] A. S. Holevo, Probabilistic and statistical aspects of quan-
tum theory, Vol. 1 (Springer Science & Business Media,
2011).

[43] B.

S.

Clarke

and

A.

R.

Barron,

Information Theory, IEEE Transactions on 36, 453 (1990).

[44] D. J. MacKay, Information theory, inference and learning

algorithms (Cambridge university press, 2003).

[45] M.

Gut¸˘a

and

J.

Kahn,

Physical Review A 73, 052108 (2006).
Gut¸˘a,

Gill,

M.

D.

I.

[46] R.

et

al.,

in

From Probability to Statistics and Back: High-Dimensional Models and
(Institute of Mathematical Statistics, 2013) pp. 105–127.
Fannes,

Alicki

and

M.

[47] R.

Journal of Physics A: Mathematical and General 37, L55 (2004).

[48] K.

M.

Audenaert

and

J.

Eisert,

[30] S.

L.

Braunstein

and

C.

M.

Caves,

Journal of mathematical physics 46, 102104 (2005).

Physical Review Letters 72, 3439 (1994).

[49] M.

Jarzyna

and

R.

Demkowicz-Dobrza´nski,

[31] B. M. Escher, R. L. de Matos Filho, and L. Davidovich,

Physical review letters 110, 240405 (2013).

Nature Phys. 7, 406 (2011).

[50] M.

Jarzyna

and

R.

Demkowicz-Dobrza´nski,

[32] R. Demkowicz-Dobrza´nski, J. Ko lody´nski, and M. Gut¸˘a,

New Journal of Physics 17, 013010 (2015).

Nature communications 3, 1063 (2012).

[33] R.

Demkowicz-Dobrza´nski

and

L. Maccone,

Physical review letters 113, 250801 (2014).

[34] C. W. Helstrom, Quantum detection and estimation the-

ory (Academic press, 1976).

[35] K. Macieszczak, M. Fraas,

and R. Demkowicz-
Dobrza´nski, New Journal of Physics 16, 113002 (2014).

[36] C. E. Shannon, IRE Nat. Conv. Rec 4, 1 (1959).
[37] N. Datta, M.-H. Hsieh,

and M. M. Wilde,

[51] S. Guha,

J. L. Habifa,
J. Mod. Opt. 58, 257 (2011).

and M. Takeoka,

[52] A. Waseda, M. Sasaki, M. Takeoka, M. Fu-
and A. Assalini,

jiwara, M. Toyoshima,
J. Opt. Commun. Netw. 3, 514 (2011).

[53] A.

Seraﬁni,

M.

G.

luminati,
J. Opt. B: Quantum Semiclass. Opt. 7, R19 (2005).

and

A.
S.

Paris,
De

F.

Il-
Siena,

[54] G. Adesso,

Entanglement

of Gaussian

states,

Information Theory, IEEE Transactions on 59, 615 (2013).

Ph.D. thesis, Universita degli Studi di Salerno (2006).

[38] M. J. Hall, arXiv preprint arXiv:1307.2683 (2013).
[39] C. Gourieroux, A. Monfort, and Q. Vuong, Statistics and
Econometric Models, Statistics and Econometric Mod-
els 2 volume set No. Vol 1 (Cambridge University Press,
1995) chapter 3.3.2.

[55] V. Giovannetti,

S. Guha,

cone,
Phys. Rev. Lett. 92, 027902 (2004).

Shapiro,

J. H.

S. Lloyd, L. Mac-
and H. P. Yuen,

[56] V. Giovannetti, R. Garc´ıa-Patr´on, N. J. Cerf, and A. S.

Holevo, Nat. Phot. 8, 796 (2014).

[40] D. Petz, Journal of Physics A: Mathematical and General 35, 929 (2002).
[41] A.

Monras

Paris,

and

M.

G.

