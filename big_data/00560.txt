6
1
0
2

 
r
a

M
2

 

 
 
]

V
C
.
s
c
[
 
 

1
v
0
6
5
0
0

.

3
0
6
1
:
v
i
X
r
a

Learnt Quasi-Transitive Similarity for Retrieval from Large Collections of Faces

School of Computer Science

University of St Andrews
St Andrews, KY16 9SX

Ognjen Arandjelovi´c

United Kingdom

ognjen.arandjelovic@gmail.com

Abstract

We are interested in identity-based retrieval of face sets
from large unlabelled collections acquired in uncontrolled
environments. Given a baseline algorithm for measuring
the similarity of two face sets, the meta-algorithm intro-
duced in this paper seeks to leverage the structure of the
data corpus to make the best use of the available base-
line. In particular, we show how partial transitivity of inter-
personal similarity can be exploited to improve the retrieval
of particularly challenging sets which poorly match the
query under the baseline measure. We: (i) describe the use
of proxy sets as a means of computing the similarity between
two sets, (ii) introduce transitivity meta-features based on
the similarity of salient modes of appearance variation be-
tween sets, (iii) show how quasi-transitivity can be learnt
from such features without any labelling or manual inter-
vention, and (iv) demonstrate the effectiveness of the pro-
posed methodology through experiments on the notoriously
challenging YouTube database and two successful baselines
from the literature.

1. Introduction

The dramatic increase in the capability for large amounts
of visual information to be acquired and stored witnessed in
the last 10–15 years has effected a profound change on the
context in which face recognition algorithms are expected
to operate. While the early work on face recognition fo-
cused on recognition from a single image using veriﬁca-
tion and identiﬁcation protocols on small databases (usually
a few dozen people), and at least partly controlled condi-
tions [34, 46, 48], more recent efforts have been directed to-
wards video or image set-based recognition [10, 8, 25, 30],
and large databases acquired in highly uncontrolled envi-
ronments [9, 29, 45].

Early work on face recognition in the context of large

data collections primarily sought to extend existing meth-
ods and adapt them for use on low quality images. This
includes pose normalization by afﬁne warps [14] or sim-
pliﬁed 3D head models [21], illumination normalization by
ﬁltering [1, 2] and illumination invariance through the use
of local gradient-based features [4]. Later work has been
increasingly oriented towards challenges associated with
learning problems which emerge in large data sets [16, 45].
Another popular direction involves the use of text informa-
tion and natural language processing to extract and asso-
ciate names with detected faces [20, 36]. Concurrently with
the research on face recognition in the context of large data
collections, there has been much progress in video and set-
based recognition[3, 15]. Inﬂuential contributions include
advances in the representation of face sets [17, 40], and in
particular manifold-based representations [32, 44], illumi-
nation models [11], and similarity measures [5, 13, 28, 44].
The broad topic of the present paper is that of face set
retrieval and its contribution relates both to the previous
work on set-based recognition and the work concerned with
recognition in the context of large data collections. In con-
trast to most work in the literature our key interest is neither
in the representation of face sets nor the associated similar-
ity measures per se. Rather, given a baseline algorithm for
measuring the similarity of two face sets, our work seeks
to leverage the structure of the data at the large scale, that
of the entire database, to make the best use of the available
baseline. In the sense that our method has as an input both
data (face image sets) and an algorithm (the baseline), it can
be accurately described as a meta-algorithm.

Problem speciﬁcation Given a query face set our aim is
to retrieve from a large database (gallery), sets of the same
person. More speciﬁcally, we wish to order the gallery
sets in decreasing order of conﬁdence that they match the
query in identity. Thus the ideal retrieval has all sets of the
query person ﬁrst (‘matches’) followed by all others (’non-
matches’). We assume that the gallery is entirely unlabelled

1

and may contain multiple sets of the same person.

2. Learnt transitive similarity

In this section we introduce the main contribution of
the present paper.
In particular, we describe a general
framework for face retrieval especially well suited for large
collections of face images acquired ‘in the wild’ i.e. in
largely unconstrained imaging conditions, and character-
ized by highly unbalanced amounts of training data per class
(person). We start by motivating the intuition behind our
method in the section which follows, and subsequently ex-
plain how this intuition can be formalized into a general re-
trieval framework.
2.1. Motivation and the key idea

It is useful to consider the motivation behind our idea in
the context of related previous work and in particular the
recent Matched Background Similarity (MBS) method of
Wolf et al. [45]. In brief, Wolf et al. argue that in build-
ing a classiﬁer which discriminates the appearance of a spe-
ciﬁc person and all other people, the focus should be on dis-
criminating between this person and those individuals most
similar to him/her; improvements in discrimination against
very dissimilar people matter less as these individuals are
unlikely to be conﬂated with the person of interest anyway.
Our idea can be seen as complementary and builds upon a
similarly simple basic principle. Speciﬁcally, we make use
of the observation that if person A is alike in appearance to
person B, and similarly person B to person C, on average
persons A and C are more likely to look alike than two ran-
domly chosen individuals. We term this Quasi-Transitive
Similarity; ‘quasi-’ because the stated regularity is a statis-
tical rather than a universal one, as we shall explain shortly.
This is illustrated conceptually in Figure 1 using images
of the prime minister of Australia, Tony Abbot, and the ac-
tor Daniel Craig. For clarity, the variability of a person’s ap-
pearance is shown as a 1D manifold. Speciﬁcally, the man-
ifolds shown in black represent the appearance variability
within the corresponding set. The dotted manifold shown
in red represents the range of appearance of Tony Abbott
which is present neither in the gallery nor in the query set
(in this conceptual example these are left semi-proﬁle to left
proﬁle images).

As stated in our introduction above, the transitivity of
similarity in appearance does not hold universally. It is pos-
sible that persons A and B are similar by virtue of one set of
physical features, and B and C of another. A useful mental
picture can be formed by drawing an analogy from statistics
(or geometry): random variables (or vectors) A and B, and
B and C may be positively correlated (have a positive dot
product), yet A and C may be negatively correlated (have a
negative dot product) with one another.

Lastly, it is worth contrasting our work with that of Yin

Figure 1. The similarity between a query and the correct target (ini-
tially poorly matched) may be better estimated indirectly via proxy
data. 1D manifolds shown in black represent the appearance vari-
ability within sets. The dotted manifold shown in red represents
the range of appearance of T Abbott present neither in the gallery
nor in the query set. The query is poorly matched to the correct
set because the person’s pose in the query is vastly different than
any of the poses in the target set. However, the query matches well
the proxy set which contains more extensive pose variability of a
person similar in appearance to the target person, the said simi-
larity being directly inferable from data from the similarity of the
matched images in the two sets.

et al. [47]. Unlike ours, their method necessitates the lo-
calization of face parts, which is problematic and highly
likely to fail in severe illuminations, extreme poses, or in
poor quality images. Their method also needs to extract es-
timates of pose and illumination, again very much unlike
ours which does not have any of the aforementioned bot-
tlenecks – all learning is performed directly from data and
without the need for an explicit model at a higher semantic
level.
2.2. Transitivity meta-features

We have already noted that the observed transitivity
of similarity is a statistical rather than a universal phe-
nomenon. In other words, while the similarity of persons A
and B, and B and C, on average leads to a greater similarity
between A and C, in some instances this will not be the case.
This suggests that in addition to inter-personal similarities
A-B and B-C, a richer set of features should be used to infer
the similarity A-C. Clearly these features should comple-
ment the inter-personal similarities in the sense that jointly
they should allow for a better estimate of the similarity A-
C than just similarities A-B and B-C, or a direct baseline
comparison of A and C (i.e. without the use of additional
indirect information provided by the relationship of B with

QueryProxyTargetA and C).

To motivate the meta-features that we propose in this pa-
per consider the conceptual illustrations shown in Figure 2.
Solid coloured lines depict the range of appearance varia-
tion within face sets. Our aim is to estimate the similarity
of the query (green) and the set denoted as ‘target’ (red).
The face set marked ‘proxy’ is a database face set of a per-
son similar in appearance to the ‘target’, as assessed by the
baseline similarity measure; for example, the proxies of a
particular target set can be selected as its nearest kp sets in
the database. The dotted red line represents the range of
possible appearance of the ‘target’ person which is not ac-
tually present in the ‘target’ face set. For the time being
the reader may assume that face sets are represented as sets
of actual exemplars and the similarity between two sets is
given by the similarity between their most similar members
– we will explain how the ideas introduced herein can be
generalized in the next section.

Both in the case shown in Figure 2(a) and that in Fig-
ure 2(b), the baseline similarity measure tells us that ‘query’
is close to ‘proxy’, and of course ‘proxy’ is close to ‘target’
by design i.e. by the former being a proxy in the ﬁrst place.
The difference between the two cases, illustrated concep-
tually, lies in the similarity of exemplars ftq and ftp i.e.
the exemplars best matching the query and proxy sets. In
particular, the observation that the baseline similarity mea-
sure deems the proxy set signiﬁcantly more similar than the
query to the target on the one hand, while both similarities
are explained by similar target exemplars, informs us that
the divergence in query and proxy appearances from the tar-
get are of different natures. Thus, even if similarities s1, s2,
and s3 are the same in Figure 2(a) and Figure 2(b), the in-
formation contained in relationships between ftq and ftp,
and fpq and fpt tells us that we should infer different query-
target similarities in the two cases. Therefore we introduce
what we term transitivity meta-features which we use for
the said inference. Given a baseline similarity measure and
a triplet consisting of query, target, and proxy sets, the cor-
responding transitivity meta-feature v(query,target|proxy)
comprises ﬁve similarities – s1 (‘query’ to ‘proxy’ similar-
ity), s2 (‘query’ to ‘target’ similarity), s3 (‘proxy’ to ‘tar-
get’ similarity), s4 (similarity between the ‘proxy’ exem-
plar most similar to ‘query’ and the ‘proxy’ exemplar most
similar to ‘target’), and s5 (similarity between the ‘target’
exemplar most similar to ‘query’ and the ‘target’ exemplar
most similar to ‘proxy’):

v(query,target|proxy) =(cid:2)s1

(cid:3)T

s2

s3

s4

s5

(1)

2.3. Non-exemplar based representations

In the preceding discussion we asked the reader to think
of appearance variation within each set as being represented
using what is probably conceptually the simplest choice of
representation: as a collection of exemplars. In other words,

each set was a set of representations of individual faces.
This was done for pedagogical reasons and we now show
that the proposed framework is in no way reliant on this
representation.

In particular, to make the transition of applying the pro-
posed method on the special case in which a face set is rep-
resented using a set of directly observed exemplars to the
general case in which an arbitrary set representation is em-
ployed, we need to explain how the concept of a pair of the
most similar exemplars such as those labelled fqp and fpq
in Figure 2(a), as well as the similarity between them (such
as that between fpq and fpt), can be generalized. This is
not difﬁcult – all that is required is a slight reframing of the
concept. Instead of seeking the nearest pair of speciﬁc ex-
emplars, in the general case we are interested in the pair of
the most similar modes of variation captured by the repre-
sentations of two sets (as measured by the baseline similar-
ity measure of course). We illustrate this idea with a few
examples.

If the variation within a set is modelled using a lin-
ear subspace and the subspace-to-subspace generalization
of the distance from feature space (DFFS) [44] adopted as
the (dis)similarity measure between them, the most similar
modes of variation between two sets represented using such
subspaces are sub-subspaces themselves. These correspond
to different exemplars fxy in Figure 2 and can be compared
using the DFFS baseline. If, on the other hand, similarity is
measured using the maximum correlation between subspace
spans as in [6], the most similar modes of variation between
two sets are readily extracted as the ﬁrst pair of the canoni-
cal vectors between subspaces [23] and compared using the
cosine similarity measure [35]. For manifold-to-manifold
distances such as that of Lee et al. [30] the most similar
modes of variation are simply the nearest pairs of points
on two manifolds, with the similarity of two points on the
same manifold readily quantiﬁed by the geodesic distance
between them.

The same ideas are readily applied to any of a variety of
set representations and similarity measures described in the
literature.
2.4. Learning quasi-transitive similarity

Given a triplet comprising a query, a target, and a proxy
data set, our aim now is to infer the similarity between the
query and the target using the corresponding transitivity fea-
ture deﬁned in (1). Without loss of generality, let us quan-
tify inter-set similarity with a real number in the range [0, 1],
where 0 signiﬁes the least and 1 the greatest possible sim-
ilarity. Then our problem can be stated more formally by
saying that we are seeking a mapping mqts:

mqts : R5 → [0, 1],

(2)
with the ideal output of mqts(v(query,target|proxy)) being
0 iff the identities in the query and target sets are different,

(a) Query and target: same identity

(b) Query and target: different identities

Figure 2. Transitivity features extracted using a baseline set comparison: conceptual motivation, using (a) a matching (same identity)
query-target set pair, and (b) a non-matching (differing identities) query-target set pair.

and 1 iff they are the same. Observe that since we are inter-
ested in conﬁdence-based ranking of all sets in a database,
the codomain of mqts is not the set {0, 1}, which would
make this a binary classiﬁcation problem, but rather [0, 1]
(a range) which makes it a regression task.

In the types of problem setting in which face recognition
is addressed by most of the existing research, obtaining fea-
tures for training, at least in principle, is simple. Whether
it is veriﬁcation (1-to-1 matching) or identiﬁcation (1-to-N
matching), the database ‘known’ to the algorithm comprises
data which is, it is assumed, correctly partitioned by the
identity. The retrieval setting adopted in this work is more
challenging in this sense and consequently the learning pro-
cess needs to be approached with more care. In particular,
as described in Section 1, we assume that our database is en-
tirely unlabelled and that it may contain multiple sets of the
same person. We neither know how many individuals there
are in the database nor the number of sets of each individual
(which can of course vary person to person). Since for any
two database sets we cannot know for certain if they belong
to the same or different individuals, an obvious corollary
is that in the extraction of transitivity features described by
(1) both intra-personal and inter-personal training sets may
contain incorrect examples.

2.4.1 Extraction of transitivity features for training

Given that our data is unlabelled i.e. that we do not know
if the two face sets in the database correspond to the same
person or not, we cannot extract training transitivity fea-
tures in the obvious manner by considering different query,
target, and proxy triplets, with the query and the target ei-
ther matching (producing same identity training data) or not
(producing differing identities training data).
Instead, we
describe how training data, albeit corrupted (this issue is
dealt with in the next section), can be collected by consid-

ering only pairs of sets, that is, all possible database sets
and their proxies. We do this for the two baseline set com-
parison methods adopted from the work by Wolf et al. [45]
(described in more detail in Section 3.3): (i) maximum max-
imorum cosine similarity between sets of exemplars [35],
and (ii) the maximum correlation between vectors conﬁned
to linear subspaces describing within set variability [6, 12].

Exemplar-based baseline Consider a particular database
face set (‘reference’) used for training and one of its proxies.
To extract training transitivity features which correspond
to same identity query-target comparisons, we select both
query and target data from the reference set (i.e. a single
video). In particular, we treat all possible pairs of exem-
plars in the reference set as possible pairs fqt and ftq. In-
deed, for speciﬁc choices of possible query and reference
sets, any two appearances may present themselves as the
nearest exemplars in them. The second element s2 in the
transitivity feature is then simply given by the similarity be-
tween the two exemplars. On the other hand the similarity
s1 between the query and the proxy is given by the sim-
ilarity between the unitary set consisting of the reference
set exemplar treated as fqt and the proxy set. The nearest
proxy exemplar to fqt is of course fpq. The similarity s3
is simply computed as the similarity between the reference
set and the proxy, which also gives us exemplars fpt and
ftp, and allows for a straightforward computation of s4 (as
the similarity between fpq and fpt) and s5 (as the similarity
between ftq and ftp). A single pair of reference and proxy
sets thus gives us nr(nr − 1) ‘positive’ training transitivity
features, where nr is the number of faces in the reference
set.

The extraction of training transitivity features which cor-
respond to differing identities query-target comparisons is
similar. Now we iterate through all exemplar pairs of the
proxy set, taking each pair as fqt and fpq in turn. The

TargetProxyQueryTargetProxyQueryclosest target exemplar to fqt becomes ftq, while fpt and
ftp are determined as before, allowing for all transitivity
feature entries (exemplar similarities) to be computed as in
the case of same identity query-target training data extrac-
tion. A single pair of reference and proxy sets thus gives us
np(np − 1) ‘negative’ training transitivity features, where
np is the number of faces in the proxy set.

It is important to observe that the set of ‘negative’ train-
ing transitivity features extracted in the described manner
may be corrupt. This is an inherent consequence of the
problem setting – since the database is entirely unlabelled
we cannot know if the identities of the people in the ref-
erence and proxy set are actually different. The proposed
process of training the regressor, described in Section 2.4.2,
takes this into account. Nevertheless, the amount of im-
provement achieved with the proposed method over its base-
line is tied to the proportion of ‘negative’ training data
which is incorrect – the improvement inevitably decreases
as this proportion is increased. However, if this is so, i.e.
if a great proportion of proxies of sets in the database ac-
tually represent the same identity as the sets they are prox-
ies to, this by design means that the baseline comparison is
very good to start with so no signiﬁcant improvement can
be reasonably expected. Thus, our method is particularly
attractive in challenging conditions in which the baseline
classiﬁer does not perform well.

Subspace-based maximum correlation baseline The
extraction of training data for this representation is some-
what simpler than in the previous case. We again extract
transitivity feature training data using only face set pairs
(rather than triplets) which are now represented by linear
subspaces. To extract training transitivity features which
correspond to same identity query-target comparisons, we
iterate through all reference set exemplars as fqt and ob-
tain ftq and fpq by projecting them to respectively the ref-
erence and proxy subspaces. Vectors fpt and ftp are readily
obtained using the baseline set comparison as the princi-
pal vectors of the subspaces corresponding to reference and
proxy subspaces. A single pair of reference and proxy sets
thus gives us nr ‘positive’ training transitivity features.

The extraction of training transitivity features which
correspond to differing identities query-target comparisons
proceeds in exactly the same manner, with the difference
that it is proxy set exemplars that are iterated through as fqt
(as before also taken to be fqp). A single pair of reference
and proxy sets gives us nr ‘positive’ training transitivity fea-
tures, where nr is the number of faces in the reference set,
and np ‘negative’ training transitivity features, where np is
the number of faces in the proxy set. A single pair of ref-
erence and proxy sets thus gives us np ‘negative’ training
transitivity features. The same remarks as before regarding
the corruption of the ‘negative’ training set hold here too.

Closing note
In Section 2.1 we remarked that the basic
idea behind the proposed method can be seen as comple-
mentary to those of Wolf et al. [45]. However, when the pro-
posed training scheme is considered it can be seen to con-
tain both conceptually similar elements and complementary
elements to MBS. In particular, since the negative training
set of quasi-transitivity features is extracted by considering
elements of the proxy set as the query, our method learns to
discriminate precisely between a person and those individu-
als most similar to him/her (as in MBS), while exploiting the
quasi-transitivity of similarity (complementary to MBS).

2.4.2 Training the predictor

We adopt the use of the  support vector (-SV) regres-
sion [41]. For comprehensive detail of this regression tech-
nique the reader is referred to the original work by Vap-
nik (also see Sch¨olkopf and Smola [38]); here we present a
brief summary of the ideas relevant to the proposed method.
Given training data {(x1, y1), . . . , (xl, yl)} ⊂ F×R, where
F is the input space (in our case this is R5), -SVR aims
to ﬁnd a function h(x) which deviates at most  from its
targets y. As in other SV-based methods, an implicit map-
ping of input data x → Φ(x) is performed by employing
a Mercer-admissible kernel [33] k(xi, xj) which allows for
the dot products between mapped data to be computed in
the input space: Φ(xi) · Φ(xj) = k(xi, xj). The function
h(x) of the form

l(cid:88)

i=1

h(x) =

(αi − α

∗
i )k(xi, x) + b

(3)

(4)

is then learnt by minimizing

l(cid:88)

l(cid:88)

l(cid:88)

(αi − α

i )(αj − α
∗

∗
j )k(xi, xj)

∗

i ) − l(cid:88)
i=1(αi − α∗

i=1

yi(αi − α
∗
i )

i=1

j=1
+

subject to the constraints(cid:80)l

(αi + α

i=1

i ∈
[0, c]. The parameter c can be seen as penalizing prediction
errors greater than  i.e. as balancing the trade-off between
the smoothness of h(x) and the amount of data predicted
with an error greater than .

i ) = 0 and αi, α∗

The nature of -SV regression is particularly well suited
to the problem at hand. Speciﬁcally, we train the regres-
sor using the value of 1 as the target for same identity
transitivity features, and 0 for different identities, allow-
ing for a large prediction error margin of  = 0.4 but
severely penalizing greater errors with c = 1000. The
large penalty C ensures that it is the outliers in the form
of the wrongly labelled training data that deﬁne the bound-
ary between the penalized and non-penalized regions of the
high-dimensional space, while the wide margin  = 0.4 en-
sures that the correctly labelled bulk of the training corpus

is pushed away from the boundary towards the desired ex-
treme values of 0 and 1. We used the radial basis function
kernel k(xi, xj) = exp{−0.2(cid:107)xi − xj(cid:107)2}.

2.4.3 Retrieval

Given a query data set we compute its similarity with a
target database set by computing the regression-based es-
timate mqts(v(query,target|proxy)) using each of target’s kp
proxies, and taking the maximum of these and the baseline
similarity between the query and the target. Database sets
are then ordered by decreasing similarity with respect to the
query.

Figure 3. The cumulative distribution function (CDF) of the data
energy contained in the 2nd and 3rd nonlinear kernel PCA com-
ponents relative to the energy of the 1st component, across sets in
the YouTube Faces Database. The variation within sets is strongly
dominated by the 1st nonlinear principal component.

Figure 4. Conceptual illustration of our robust sample selection:
(i) original exemplars are projected onto their 1st kernel principal
component, (ii) uniform sampling between the extreme projections
is performed in the 1D kernel space, and (iii) the obtained samples
are re-projected into the original space (step not shown).

3. Evaluation

In this section we report our evaluation of the proposed
methods and discuss our ﬁndings. We start by describing

Figure 5. CDF of the error introduced by our robust sample selec-
tion (10 samples were used) in the exemplar-based set method.

For

the data set on which the evaluation was performed, con-
sider the measure we used to assess performance, summa-
rize the evaluated baseline set representations and distances
and their derivatives, and ﬁnally present and discuss the re-
sults.
3.1. Evaluation data
evaluation we

adopted the YouTube Faces
Database [45] which contains sets of faces extracted
from YouTube videos. There are two key reasons which
motivated this choice. Firstly, the manner in which this
data set was collected and the nature of its contents are
representative of the conditions which the present work
targets.
In particular, the total amount of data is large
(3425 videos/sets of 1595 individuals, with the average set
size of approximately 181.3 faces or equivalently 620,953
faces in total), it was extracted from videos acquired in
unconstrained conditions in which large changes in illu-
mination, pose, and facial expressions are present, and the
distribution of data is heterogeneous both with respect to
the set sizes (48–6,070) as well as the number of sets (1–6)
for each person in the database. The second reason lies in
the reproducibility of results and the ease of comparison
with alternatives in the literature – the database has been
widely adopted as a standard benchmark and a number of
standard face representations are provided ready for use.
Full detail can be found in the original publication [45].
3.2. Performance evaluation

As the cornerstone measure of retrieval performance we
adopt the average normalized rank (ANR) [19, 37]. In brief,
ANR treats each retrieved datum as either matching or not
matching the query and computes the average rank of the
former group, normalized to the range [0, 1], with the ANR
value of 0 corresponding to the best possible performance
(all matching data retrieved before any non-matching) and
1 the worst (all non-matching data retrieved before any
matching). Formally:

(cid:80)c
i=1 ri − m
M − m

AN R(n,{r1, . . . , rc}) =

(5)
where n is the database size, {r1, . . . , rc} the set of retrieval
ranks corresponding to the data of interest (i.e. data match-

00.050.10.150.20.250.30.350.40.450.500.20.40.60.81Nonlinear principal component energyCumulative probability2nd relative to 1st3rd relative to 1stRobust samplesOriginal feature space1D KPCA space00.050.10.150.20.2500.20.40.60.81Relative error of set−to−set comparisonsCumulative probabilitying the query), and m and M respectively the minimum and
maximum possible values of the sum of r1, . . . , rc:

c(cid:88)
n(cid:88)

i=1

i =

c × (c + 1)
i = c × 2n − c + 1

2

2

(6)

(7)

m =

M =

i=n+1−c

In comparison with other common performance mea-
sures, such as the receiver operating characteristic (ROC)
curve [22], commonly used in veriﬁcation and identiﬁcation
problems [7], the average normalized rank more directly
captures the ultimate aim of a retrieval algorithm.
3.3. Methods

Motivated by the results reported by Wolf et al. which
demonstrate its superiority over a number of alternatives,
we adopt the standard local binary pattern (LBP) represen-
tation of individual faces [27]. Using LBP we consider two
baseline set representations: (i) a set of LBP exemplars,
and (ii) a linear LBP subspace, both of which were also
evaluated by Wolf et al. The former simply stores all face
exemplars (that is, the corresponding LBP vectors), while
the latter uses principal component analysis to represent the
main modes of the observed exemplar variation; previous
work suggests that for individual face sets 6-dimensional
subspaces produce good results so this is the dimensional-
ity we adopt too.

We adopt two baseline set similarity measures, again mo-
tivated by the reports of their good performance in the ex-
isting literature. The ﬁrst of these is the maximum maxi-
morum (‘max-max’) cosine similarity between sets of ex-
1 f2/(cid:107)f1(cid:107)/(cid:107)f2(cid:107) which in the ex-
emplars maxf1∈S1,f2∈S2 f T
periments of Wolf et al. [45] outperformed a number of al-
ternatives including by a large margin the pyramid match
kernel of Graumanand and Darrell [24] and the locality-
constrained linear coding (LLC) of Wang et al. [43]. The
second baseline comparison which we adopt for the com-
parison of sets represented as linear subspaces is the alge-
braic method based on the maximum correlation between
pairs of vectors lying in two subspaces. This method too
performed well in the experiments of Wolf et al. [45] as
well as a number of other authors [6]. Thus in summary,
our two baseline methods are:

• LBP + maximum maximorum set similarity, and
• LBP + maximum correlation between subspaces.

These are used to establish reference performance. They
are then employed in the context of several different ways
of applying our observation of quasi-transitivity:

• Simple arithmetic mean-based quasi-transitivity,
• Simple geometric mean-based quasi-transitivity,
• Simple quadratic mean-based quasi-transitivity, and

• Proposed learnt quasi-transitivity (L-QTS)

√

ρQP × ρP T and(cid:112)0.5ρQP

The ﬁrst three methods in the list are simple combination
rules. In the ﬁrst of these, the arithmetic mean-based quasi-
transitivity, two set similarity of dissimilarity measures ρQP
(query-proxy) and ρP T (proxy-target) are combined by
computing their arithmetic mean i.e. 0.5 × (ρQP + ρP T ).
Similarly, in the geometric and quadratic mean-based meth-
ods quasi-transitivity is attempted by computing respec-
2 [26]. The
tively
proposed learnt quasi-transitivity (applied atop of both base-
line methods) was evaluated using different numbers of
proxy sets (1–10) and as detailed in Section 2.4.2, -SV re-
gression was learnt using the parameter values  = 0.4 and
c = 1000.
3.4. Protocol

2 + 0.5ρP T

We train the -SV regressor using 200 randomly selected
sets and their proxies (which are not necessarily in the ran-
dom 200).
In principle there is no reason why the entire
database would not be used (recall that no labelling or man-
ual intervention is used whatsoever) but we found that 200
sets were sufﬁcient to gather sufﬁcient training data. Ex-
amples are shown in Figure 7; clear patterns are observable
both within positive and negative training sets which differ
one from another signiﬁcantly.

The evaluation of the methods described in the previous
section was performed by examining all possible retrievals.
In other words, we used every set in our database as the
query in turn and evaluated the resulting retrieval. To make
this feasible we propose a robust sample selection method
so as to reduce the computational demands of the otherwise
computationally intensive exemplar-based baseline.

Exemplar baseline: robust sample selection It is well
established by the existing work on face recognition that
the appearance of a face is constrained and thus conﬁned to
a region of the image space. Within this region, which is
nonlinear, the appearance variation is mostly approximately
smooth – this is sometimes somewhat loosely stated as the
face appearance being constrained to a nonlinear appear-
ance manifold [32, 44]. That being said, the range of ap-
pearance variation of a person’s face within a single video
typically covers only a portion of the entirety of possible
variation. It is a simple yet important observation that even
within this range of appearance the underlying manifold
is not uniformly sampled, e.g. a person may spend more
time in a speciﬁc pose than in others. One consequence is
that while largely redundant face exemplars of the densely
sampled portions of the manifold add little new information
about the appearance of the person’s face, they can dramat-
ically increase the computational cost of set-based compar-
isons. This is the case for example for face set-based com-
parisons which utilize all sample pairs comparisons such as

(a) Exemplar baseline, various methods

(b) Exemplar baseline, proposed

(c) Subspace baseline, various methods

(d) Subspace baseline, proposed

Figure 6. CDF of the average normalized rank obtained using the exemplar-based (a,b) and subspace-based (c,d) methods. (a,c) Comparison
of the respective baseline approach, the three simple quasi-transitivity estimation methods, and the proposed learnt quasi-transitivity. (b,d)
Comparison of the respective baseline approach and the corresponding proposed method for different numbers of proxies.

those based on the maximum maximorum similarity (i.e. all
pairs maximum similarity) [18] or the maximum minimorum
distance (a variation of the Hausdorff distance [42]). More
worryingly, if a sample voting scheme is used [45], redun-
dant exemplars can unduly affect the result even though they
carry little additional information.

We overcome both of the problems described above by
employing a robust sample selection scheme. Our starting
point is the observation that although the intrinsic dimen-
sionality of the entire face manifold is estimated to be in
the range 15–22 [31], the appearance variation exhibited in
a typical video clip is typically dominated by a single fac-
tor such as face yaw changes; the plot in Figure 3 corrob-
orates this. Led by this insight we employ kernel principal
component analysis (KPCA) [39] to project the original face
exemplars onto their dominant nonlinear principal compo-
nent, uniformly sample the resulting 1D space between the

two projections of the two most extreme exemplars, and ﬁ-
nally project them back into the original space. The pro-
cess is illustrated in Figure 4. The plot in Figure 5 demon-
strates that the proposed sample selection does not greatly
affect inter-set similarities; a computational improvement
of over 2.5 orders of magnitude (approximately 330 times)
was achieved.

3.5. Results and discussion

The main set of results of our experiments is summarized
in the plots in Figure 6(a) and 6(c) which show the cumu-
lative densities of the ANR achieved for the two baseline
methods and different quasi-transitivity approaches. Firstly
note that the two baseline methods performed approxi-
mately equally well, which is consistent with the previous
reports in the literature [45]. The three simple attempts at
exploiting quasi-transitivity worsened performance signiﬁ-

00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91Average normalised rankCumulative probability distributionBaselineSimple arithmetic meanSimple geometric meanSimple quadratic meanProposed L−QTS, 10 proxies00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91Average normalised rankCumulative probability distributionBaselineProposed L−QTS, 1 proxyProposed L−QTS, 2 proxiesProposed L−QTS, 5 proxiesProposed L−QTS, 10 proxies00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91Average normalised rankCumulative probability distributionBaselineSimple arithmetic meanSimple geometric meanSimple quadratic meanProposed L−QTS, 10 proxies00.10.20.30.40.50.60.70.80.9100.10.20.30.40.50.60.70.80.91Average normalised rankCumulative probability distributionBaselineProposed L−QTS, 1 proxyProposed L−QTS, 2 proxiesProposed L−QTS, 5 proxiesProposed L−QTS, 10 proxieswith the peak of the exemplar baseline) for kp = 1 already
(ANR plots for different kp are virtually indistinguishable
and require signiﬁcant magniﬁcation). Although we are not
sure of the exact mechanism that explains this behaviour,
it does appear to be linked to the inherent properties of the
subspace-based baseline which is additionally supported by
the observation that the within-class variability of the corre-
sponding training meta-features is signiﬁcantly smaller than
for the exemplar-based baseline; see Figure 7.

Let us next turn our attention to the plot in Figure 8(a).
It shows the proportion of retrievals (i.e. the empirical es-
timate of the corresponding probability) which result in
at least one correct match being retrieved in the top 100
ranked sets as a function of the total number of target sets
in the database which correctly match the query. Plotted
as solid blue and red lines are the results obtained using
the proposed method (with 10 neighbours used as quasi-
transitivity proxies) atop of the exemplar-based baseline,
and the baseline itself (as expected from Figure 6, the re-
sults for the subspace-based method are similar and are thus
not included to avoid unnecessary repetition). The plots also
show predictions based on the methods’ performances for
queries in which only a single correct match is present in
the entire database. Speciﬁcally, starting from the estimate
of the probability p1,100 of a correct match being retrieved
in the top 100 ranked sets using queries where only a sin-
gle correct match is possible, if different correct matches
are ranked independently when k correct matches exist, the
probability of at least a single correct match being retrieved
in the top 100 is approximately 1 − (1 − p1,100)k. Since
the greatest number of admissible queries (591 individuals
in the database have only a single set; clearly these were not
meaningful queries for performance evaluation), approxi-
mately 48%, has k = 1 this is a reasonable estimate to base
the prediction on. The estimates are plotted as dashed blue
and red lines.

Figure 8(a) reveals interesting insight into the perfor-
mance of the proposed method. Speciﬁcally, note that un-
like the empirical plot of the baseline, the empirical plot
of the proposed method grows faster with the number of re-
trievable sets than the corresponding prediction. This means
that the independence assumption underlying the predic-
tion does not hold well, supporting the premise that quasi-
transitivity of similarity can be used to improve the retrieval
of sets poorly retrieved by the baseline by propagating in-
formation from similarly looking individuals or sets of the
same person which are acquired in less challenging condi-
tions.

Lastly, Figure 8(b) shows the average number of correct
matches retrieved in the top 100 ranked sets as a function
of the total number of target sets in the database which
correctly match the query. As before the plots also show
the corresponding predictions based on the methods’ per-

(a) Inter-class transitivity features

(b) Intra-class transitivity features

(d) Intra-class transitivity features
(c) Inter-class transitivity features
Figure 7. Training data for the exemplar-based (a,b) and subspace-
based (c, d) experiments, in the form of intra-class and inter-class
transitivity features. Feature are vectors comprising 5 similarities
in (1), and are shown using parallel coordinates.

cantly, save for the arithmetic mean-based similarity combi-
nation for the subspace-based baseline which effected nei-
ther an improvement nor deterioration. This conﬁrmed our
expectation expressed in Section 2.2 that the use of inter-
personal similarities only is unlikely to be successful and
that a richer set of similarity features is needed instead. This
leads us to the proposed method which in both cases ef-
fected a major performance improvement over both of the
baselines. For example, while the exemplar-based baseline
produced retrievals with the ANR less than 0.3 in 54.0%
of the cases, the corresponding learnt quasi-transitivity did
so in 72.5% of the cases (an improvement of 34%). Simi-
larly, while the subspace-based baseline produced retrievals
with the ANR less than 0.3 in 54.9% of the cases, the cor-
responding learnt quasi-transitivity did so in 72.8% of the
cases. It is particularly interesting to observe in how few
cases our method produced bad results (i.e. high ANR) –
for both baselines our method achieved ANR lower than 0.5
for over 98% of retrievals. In contrast, the 98% quantile of
the baseline methods corresponds to the ANR values of 0.92
and 0.88 for the exemplar and subspace-based methods.

The effect of the number of proxies is summarized in
Figure 6(b) and Figure 6(d). For both baselines performance
improvement is immediately apparent even for the mini-
mum number of kp = 1 proxy per set. Interestingly, while
in the case of the exemplar baseline the performance gradu-
ally improves up until kp = 5, staying approximately steady
thereafter, the improvement using the subspace-based base-
line is much more dramatic and reaches its peak (on par

s1s2s3s4s500.20.40.60.81Similarity featureSimilarity values1s2s3s4s500.20.40.60.81Similarity featureSimilarity values1s2s3s4s500.20.40.60.81Similarity featureSimilarity values1s2s3s4s500.20.40.60.81Similarity featureSimilarity valueformances for queries in which only a single correct match
is present in the entire database. Starting from n1,100 the
average number of correct matches retrieved in the top
100 ranked sets using queries where only a single correct
match is possible, if different correct matches are ranked
independently when k correct matches exist, the expected
number of correct matches in the top 100 is approximately
k × n1,100. The improvement effected by the proposed
method is again consistent and signiﬁcant.

strated on the notoriously challenging YouTube database.

References
[1] O. Arandjelovi´c. Unfolding a face: from singular to mani-
fold. In Proc. Asian Conference on Computer Vision, 3:203–
213, 2009.

[2] O. Arandjelovi´c. Colour invariants under a non-linear photo-
metric camera model and their application to face recognition
from video. Pattern Recognition, 45(7):2499–2509, 2012.

[3] O. Arandjelovi´c. Computationally efﬁcient application of the
generic shape-illumination invariant to face recognition from
video. Pattern Recognition, 45(1):92–103, 2012.

[4] O. Arandjelovi´c.

Gradient edge map features

for
frontal face recognition under extreme illumination changes.
In Proc. British Machine Vision Conference,
2012.
DOI: 10.5244/C.26.12.

[5] O. Arandjelovi´c. Making the most of the self-quotient im-
In Proc. IEEE International Con-
age in face recognition.
ference on Automatic Face and Gesture Recognition, 2013.
DOI: 10.1109/FG.2013.6553708.

[6] O. Arandjelovi´c. Discriminative extended canonical corre-
lation analysis for pattern set matching. Machine Learning,
94(3):353–370, 2014.

[7] O. Arandjelovi´c. A framework for improving the per-
formance of veriﬁcation algorithms with a low false pos-
In Proc.
itive rate requirement and limited training data.
IEEE/IAPR International Joint Conference on Biometrics,
2014. DOI: 10.1109/BTAS.2014.6996275.

[8] O. Arandjelovi´c. Hallucinating optimal high-dimensional

subspaces. Pattern Recognition, 47(8):2662–2672, 2014.

[9] O. Arandjelovi´c and R. Cipolla. Automatic cast listing in
In
feature-length ﬁlms with anisotropic manifold space.
Proc. IEEE Conference on Computer Vision and Pattern
Recognition, 2:1513–1520, 2006.

[10] O. Arandjelovi´c and R. Cipolla. Face set classiﬁcation using
maximally probable mutual modes. In Proc. IAPR Interna-
tional Conference on Pattern Recognition, pages 511–514,
2006.

[11] O. Arandjelovi´c and R. Cipolla. Achieving robust face recog-
nition from video by combining a weak photometric model
and a learnt generic face invariant. Pattern Recognition,
46(1):9–23, 2013.

[12] O. Arandjelovi´c, R. I. Hammoud, and R. Cipolla. Thermal
and reﬂectance based personal identiﬁcation methodology
in challenging variable illuminations. Pattern Recognition,
43(5):1801–1813, 2010.

[13] K. Assaleh, T. Shanableh, and K. Abuqaaud. Combined fea-
tures for face recognition in surveillance conditions. Ad-
vances in Neural Information Processing Systems, pages
503–514, 2014.

[14] T. L. Berg, A. C. Berg, J. Edwards, M. Maire, R. White, Y. W.
Teh, E. Learned-Miller, and D. A. Forsyth. Names and faces
in the news. In Proc. IEEE Conference on Computer Vision
and Pattern Recognition, 2:848–854, 2004.

[15] K. Bowyer, K. Chang, P. Flynn, and X. Chen. Face recogni-
tion using 2-D, 3-D, and infrared: is multimodal better than
multisample? In Proc. IEEE, 94(11):2000–2012, 2006.

(a) Match prob. w/in rank-100

(b) Match num. w/in rank-100

Figure 8. Rank-100: (a) probability of a correct match being re-
trieved, and (b) number of correct matches retrieved, vs. number
of matches in the database.

4. Summary and conclusions

We introduced a novel framework for improving the per-
formance of retrieval algorithms on large and highly hetero-
geneous face sets acquired in uncontrolled conditions. In
sharp contrast to the previous work, the proposed method
learns to beneﬁt from inter-personal similarity using what
we term quasi-transitivity. A principled and carefully en-
gineered framework performs learning automatically, with
no human intervention whatsoever, making our approach
readily employable on large data. Effectiveness was demon-

1234500.20.40.60.81Numberofretrievablein−classvideosProportion of retrievalswith >0 match in top 100Empirical (proposed L−QTS)Empirical (baseline)Predicted (L−QTS)Predicted (baseline)1234500.511.5Numberofretrievablein−classvideosMean number of targetsets retrieved in top 100Empirical (proposed L−QTS)Empirical (baseline)Predicted (L−QTS)Predicted (baseline)[16] Y. Cao, Q. Ying and P. Li. Similarity metric learning for
face recognition. In Proc. IEEE International Conference on
Computer Vision, pages 2408–2415, 2013.

[17] R. Chellappa, P. Sinha, and P. J. Phillips. Face recognition

by computers and humans. Computer, 43(2):46–55, 2010.

[18] T. Cour, B. Sapp, A. Nagle, and B. Taskar. Talking pictures:
Temporal grouping and dialog-supervised person recogni-
In Proc. IEEE Conference on Computer Vision and
tion.
Pattern Recognition, 2010.

[19] T. Deselaers, D. Keysers, and H. Ney. Classiﬁcation error
rate for quantitative evaluation of content-based image re-
trieval systems. In Proc. IAPR International Conference on
Pattern Recognition, 2:505–508, 2004.

[20] M. Everingham, J. Sivic, and A. Zisserman. Taking the bite
out of automatic naming of characters in TV video. Image
and Vision Computing, 27(5):545–559, 2009.

[21] M. Everingham and A. Zisserman. Identifying individuals in
video by combining generative and discriminative head mod-
In Proc. IEEE International Conference on Computer
els.
Vision, 2005.

[22] T. Fawcett. An introduction to ROC analysis. Pattern Recog-

nition Letters, pages 861–874, 2006.

[23] K. Fukumizu, F. Bach, and A. Gretton. Consistency of kernel
canonical correlation analysis. Journal of Machine Learning
Research, 8:361–383, 2007.

[24] K. Grauman and T. Darrell. The pyramid match kernel: Dis-
In
criminative classiﬁcation with sets of image features.
Proc. IEEE International Conference on Computer Vision,
2:1458–1465, 2005.

[25] A. Hadid and M. Pietik¨ainen. Combining appearance and
motion for face and gender recognition from videos. Pattern
Recognition, 42(11):2818–2827, 2009.

[26] Y. Haitovsky. A note on the maximization of ¯R2. The Amer-

ican Statistician, 23(1):20–21, 1969.

[27] M. Heikkil¨a, M. Pietik¨ainen, and C. Schmid. Description of
interest regions with local binary patterns. Pattern Recogni-
tion, 42(3):425–436, 2009.

[28] H. Hu. Face recognition with image sets using locally Grass-
mannian discriminant analysis. IEEE Transactions on Cir-
cuits and Systems for Video Technology, 24(9):1461–1474,
2014.

[29] G. B. Huang, M. Ramesh, T. Berg, and E. Learned-Miller.
Labeled faces in the wild: A database for studying face
recognition in unconstrained environments. Technical Re-
port 07–49, University of Massachusetts, Amherst, October
2007.

[30] K. Lee, M. Ho, J. Yang, and D. Kriegman. Acquiring linear
subspaces for face recognition under variable lighting. IEEE
Transactions on Pattern Analysis and Machine Intelligence,
27(5):684–698, 2005.

[31] M. B. Lewis. Face-space-R: towards a uniﬁed account of

face recognition. Visual Cognition, 11(1):29–69, 2004.

[32] Y. M. Lui and J. R. Beveridge. Grassmann registration mani-
folds for face recognition. In Proc. European Conference on
Computer Vision, 2:44–57, 2008.

[33] J. Mercer. Functions of positive and negative type and their
connection with the theory of integral equations. Philosophi-
cal Transactions of the Royal Society A, 209:415–446, 1909.
[34] B. Moghaddam and A. Pentland. Probabilistic visual learn-
ing for object representation. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 19(7):696–710, 1997.

[35] H. V. Nguyen and L. Bai. Cosine similarity metric learning
for face veriﬁcation. In Proc. Asian Conference on Computer
Vision, 2:709–720, 2010.

[36] D. Ozkan and P. Duygulu. A graph based approach for nam-
ing faces in news photos. In Proc. IEEE Conference on Com-
puter Vision and Pattern Recognition, 2:1477–1482, 2006.

[37] G. Salton and M. J. McGill. Introduction to Modern Infor-

mation Retrieval. McGraw Hill, New York, 1983.

[38] B. Sch¨olkopf and A. Smola. Learning with kernels. MIT

Press, Cambridge, MA, 2002.

[39] B. Sch¨olkopf, A. Smola, and K. M¨uller. Advances in Kernel
Methods – SV Learning, chapter Kernel principal component
analysis., pages 327–352. MIT Press, Cambridge, MA, 1999.
[40] J. Sivic, M. Everingham, and A. Zisserman. Person spotting:
video shot retrieval for face sets. In Proc. IEEE International
Conference on Image and Video Retrieval, pages 226–236,
2005.

[41] V. Vapnik.

The Nature of Statistical Learning Theory.

Springer-Verlag, 1995.

[42] E. P. Vivek and N. Sudha. Robust hausdorff distance measure
for face recognition. Pattern Recognition, 40(2):431–442,
2007.

[43] J. Wang, J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong.
Locality-constrained linear coding for image classiﬁcation.
In Proc. IEEE Conference on Computer Vision and Pattern
Recognition, pages 3360–3367, 2010.

[44] R. Wang, S. Shan, X. Chen, and W. Gao. Manifold-manifold
distance with application to face recognition based on image
set. In Proc. IEEE Conference on Computer Vision and Pat-
tern Recognition, pages 1–8, 2008.

[45] L. Wolf, T. Hassner, and I. Maoz. Face recognition in uncon-
strained videos with matched background similarity. In Proc.
IEEE Conference on Computer Vision and Pattern Recogni-
tion, pages 529–534, 2011.

[46] M. Yang, D. Kriegman, and N. Ahuja. Detecting faces in
images: A survey. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 24(1):34–58, 2002.

[47] Q. Yin, X. Tang, and J. Sun. An associate-predict model for
In Proc. IEEE Conference on Computer

face recognition.
Vision and Pattern Recognition, pages 497–504, 2011.

[48] W. Zhao, R. Chellappa, P. J. Phillips, and A. Rosenfeld. Face
recognition: A literature survey. ACM Computing Surveys,
35(4):399–458, 2004.

