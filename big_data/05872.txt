6
1
0
2

 
r
a

 

M
8
1

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
2
7
8
5
0

.

3
0
6
1
:
v
i
X
r
a

(Draft: 2016/03/17)

A distribution-function-valued SPDE

and its applications 1

Li Wang, Xu Yang2, Xiaowen Zhou

Abstract. In this paper we further study the stochastic partial diﬀerential equation
ﬁrst proposed by Xiong [23]. Under localized conditions on the coeﬃcients we show
that the solution is in fact distribution-function-valued and we establish the pathwise
uniqueness of the solution. As applications we obtain the well-posedness of the martin-
gale problems for two classes of measure-valued diﬀusions: interacting super-Brownian
motions and interacting Fleming-Viot processes. Properties of the two superprocesses
such as the existence of density ﬁelds and the extinction behaviors are also studied.

Mathematics Subject Classiﬁcations (2010): 60H15; 60F15; 60J80.

Keywords: Distribution, stochastic partial diﬀerential equation, strong uniqueness,
pathwise uniqueness, martingale problem, super-Brownian motion, Fleming-Viot pro-
cess, interacting superprocesses.

1

Introduction

It is well known that the density process {Xt(x) : t > 0, x ∈ R} of a one-dimensional binary
branching super-Brownian motion solves the following non-linear stochastic partial diﬀerential
equation (SPDE):

∂
∂t

Xt(x) =

1
2

∆Xt(x) +pXt(x) ˙Wt(x),

t > 0, x ∈ R,

(1.1)

where ∆ denotes the Laplacian operator and { ˙Wt(x) : t ≥ 0, x ∈ R} is the derivative of a space-
time Gaussian white noise. This SPDE was ﬁrst derived and studied independently by Konno
and Shiga [9] and Reimers [21]. The weak uniqueness of the solution to (1.1) follows from that
of a martingale problem for super-Brownian motion. But the strong (pathwise) uniqueness of
nonnegative solution to (1.1) remains open even though it has been studied by many authors.
The main diﬃculty comes from the unbounded drift coeﬃcient and the non-Lipschitz diﬀusion
coeﬃcient. Progresses have been made in considering modiﬁed forms of SPDE (1.1). When the
random ﬁeld {Wt(x) : t ≥ 0, x ∈ R} is colored in space and white in time, the strong uniqueness
of nonnegative solution to (1.1) and to more general equations were studied in [17, 22, 19].
When {Wt(x) : t ≥ 0, x ∈ R} is a space-time Gaussian white noise and the solutions are allowed
to take both positive and negative values with pXt(x) replaced by σ(t, x, Xt(x)) (σ(·,·, u) is
H¨older continuous in u of index β0 > 3/4) in (1.1), the pathwise uniqueness of the solution
was proved by Mytnik and Perkins [16] and further investigated by Mytnik and Neuman [15].

1Supported by grants from NSFC 11301020, 11401012 and NSERC.
2Corresponding author (xuyang@mail.bnu.edu.cn).

1

Recently, some negative results were obtained. When pXt(x) is replaced by |Xt(x)|β1 in (1.1),

nonuniqueness results were obtained for 0 < β1 < 3/4 in [1, 13]. It was also shown in Chen [2]
that the solution is a super-Brownian motion with immigration and the pathwise nonuniqueness
holds when a positive function is added on the right-hand side of (1.1). We refer to Li [10] and
Xiong [24] for introductions on superprocesses and the related SPDEs.

A novel approach for studying the strong uniqueness of (1.1) was proposed by Xiong [23],
where an SPDE for the distribution-function process of measure-valued super-Brownian motion
was formulated and the strong existence and uniqueness for this SPDE were established. Similar
stochastic equations of distribution-function processes for superprocesses were also established
in Dawson and Li [3]. He et al.
[7] showed that the distribution-function process of a one-
dimensional super-L´evy process with general branching mechanism is the strong unique solution
to an SPDE generalizing (1.1). The uniqueness of the solution to the martingale problem of a
superprocess with interactive immigration mechanism was established in Mitnik and Xiong [18],
and then in Xiong and Yang [25] (for a more general process) by studying the corresponding
SPDE for its distribution-function process.

Let X0(R) be the Hilbert space consisting of all measurable functions f on R satisfying
RR |f (x)|e−|x|dx < ∞. Let D(R) be the set of bounded right-continuous nondecreasing functions
f on R satisfying f (−∞) = 0. Let Dc(R) be the subset of D(R) consisting of continuous
functions.

Given any Polish space E and σ-ﬁnite Borel measure π on E, consider the following SPDE:

Yt(y) = Y0(y) +

1

2 Z t

0

∆Ys(y)ds +Z t

0 ZE

G(u, Ys(y))W (ds, du),

Y0 ∈ X0(R),

(1.2)

where {W (ds, du) : s ≥ 0, u ∈ E} is a Gaussian white noise with intensity dsπ(du) and G is a
Borel function on E × R+ (R+ := [0,∞)). Then a X0(R)-valued process {Yt(y) : t ≥ 0, y ∈ R} is
a solution to (1.2) if for any f ∈ C 2
0 (R) (given at the end of this section) with RR |f (x)|dx < ∞,

hYt, fi = hY0, fi +

G(u, Ys(y))f (y)dyiW (ds, du), P-a.s.

(1.3)

1

0 hYs, f ′′ids +Z t
2 Z t

0 ZE hZR

Xiong [23] proved that (1.2) has a strong unique X0(R)-valued solution if G satisﬁes the following
conditions: there is a constant C > 0 so that

ZE |G(u, x)|π(du) ≤ C(1 + x2), x ∈ R

and

ZE |G(u, x1) − G(u, x2)|2π(du) ≤ C|x1 − x2|, x1, x2 ∈ R.

(1.4)

(1.5)

For G(u, v) = 1{0≤u≤v} and G(u, v) = 1{0≤u≤v≤1} − v, the solutions to (1.2) are the distribution-
function processes of super-Brownian motion and Fleming-Viot process, respectively.

In this paper we further improve the results in [23]. In particular, we establish a comparison
theorem which shall be of independent interest. Using it we prove that (1.2) indeed has a strong
unique Dc(R)-valued solution when G satisﬁes certain conditions. And we then apply the results
to show the well-posedness of martingale problems for an interacting super-Brownian motion
and an interacting Fleming-Voit process. We summarize the main results in the following.

2

Our ﬁrst main result of this paper, Theorem 2.3, shows that SPDE (1.2) has a strong unique

Dc(R)-valued solution when G satisﬁes the following conditions:

ZE |G(u, 0)|π(du) = 0,

for each k ≥ 1 there is a constant Ck > 0 so that

ZE |G(u, x)|π(du) ≤ Ck(1 + x2),

x ∈ [0, k]

and

ZE |G(u, x1) − G(u, x2)|2π(du) ≤ Ck|x1 − x2|,

x1, x2 ∈ [0, k].

(1.6)

(1.7)

(1.8)

In our second main results of this paper, Theorems 3.2 and 4.2, we prove that the martingale
problems for both the interacting super-Brownian motion and the interacting Fleming-Viot
process are well-posed by ﬁrst associating the martingale problems to the corresponding SPDEs

(1.2) with E = R+, G(u, x) = 1{u≤x}pσ(u) and with E = [0, 1]2, G(a, b, x) = 1{a≤x≤b}pγ(a, b)

for nonnegative functions σ and γ (see Lemmas 3.1 and 4.1), respectively, and then applying
Theorem 2.3. They generalize the recent work of [18, 25].

We want to point out that, in our paper, the existence of solutions to the martingale problems
follows directly from the existence of solutions to the corresponding SPDEs, which is diﬀerent
from the approach of approximating martingale problem for the classical superprocesses in [18,
Proposition 2.4] and the approach of approximating branching interacting particle system in
Xiong and Yang [25, Theorem 3.3].

Our last main results, Theorems 3.3–3.5 and 4.3, concern properties such as the existence of
density ﬁelds and extinction behaviors of the interacting super-Brownian motions and Fleming-
Viot processes. In particular, using martingale arguments we discuss the extinct properties of
the interacting super-Brownian motion {Xt : t ≥ 0} determined by the local martingale problem
(3.3)-(3.4). We show that the total mass process {Xt(1) : t ≥ 0} satisﬁes Xt(1) = 0 for all t large
enough if R x
0 σ(y)dy
decreases to 0 fast enough.

0 σ(y)dy decreases to 0 slow enough as x → 0+ and Xt(1) > 0 for all t if R x

The rest of the paper is organized as follows.

In Section 2, the comparison theorem and
the strong uniqueness of Dc(R)-valued solution to (1.2) are established. The interacting super-
Brownian motions and Fleming-Viot processes are studied in Sections 3 and 4, respectively.

Notations: We always assume that all random elements are deﬁned on a ﬁltered complete
probability space (Ω, F , (Ft)t≥0, P) satisfying the usual hypotheses. For a topological space V
let B(V ) be the space of Borel measurable functions and Borel sets on V . Let B(V ) be the
bounded functions on V furnished with the supremum norm k·k and C(V ) the space of bounded
continuous functions on V . For f, g ∈ B(R) write hf, gi = RR f (x)g(x)dx whenever it exists.
Let C 2(R) be the space of twice continuously diﬀerentiable functions on R. Let C0(R) be the
subset of C(R) consisting of functions vanishing at inﬁnity and let C k
0 (R) (k ≥ 1) be the subset
of functions with derivatives up to order k belonging to C0(R). We use the superscript “+” to
denote the subsets of non-negative elements of the function spaces. Denote M (R) for the space
of ﬁnite Borel measures on R equipped with the topology of weak convergence. Then there is
an obvious one-to-one correspondence between M (R) and D(R) by associating a measure to
its distribution function. We endow D(R) with the topology induced by this correspondence

3

from the weak convergence topology on M (R). Then for any M (R)-valued stochastic process
{Xt : t ≥ 0}, its distribution-function process {Yt : t ≥ 0} is a D(R)-valued stochastic process.
For µ ∈ M (R) and f ∈ B(R) write µ(f ) ≡ hµ, fi := RR f (x)µ(dx). Write f (∞) := limx→∞ f (x)
and f (−∞) := limx→−∞ f (x) for f ∈ D(R). Let λ denote Lebesgue measure on R. In the proofs
let C denote a positive constant whose value might change from line to line. We also write Cn
if the constant depends on n ≥ 1.

2 Existence and strong uniqueness of solution to SPDE

In this section we establish the existence and strong uniqueness of D(R)-valued solutions to
the SPDE (1.2) under conditions (1.4)–(1.6) and conditions (1.6)–(1.8), respectively. Xiong [23]
proved that (1.2) has a unique strong X0(R)-valued solution under conditions (1.4)–(1.5). So
we only need to show that the X0(R)-valued solution is in fact D(R)-valued under additional
condition (1.6) and further prove that (1.2) has a strong unique Dc(R)-valued solution under
conditions (1.6)–(1.8).

For this purpose, we ﬁrst establish the following comparison theorem for (1.2) under the two
sets of conditions, which are of independent interest. The corresponding strong uniqueness then
follows.

Proposition 2.1 (i) Let { ¯Y0,t : t ≥ 0} and { ¯¯Y0,t : t ≥ 0} be any two X0(R)-valued solutions of
(1.2) under conditions (1.4)–(1.5). If ¯Y0,0(x) ≤ ¯¯Y0,0(x) P-a.s. for λ-a.e. x and

sup

t∈[0,T ]hZR

¯Y0,t(x)2e−|x|dx +ZR

¯¯Y0,t(x)2e−|x|dxi < ∞

P-a.s.

(2.1)

for each T > 0, then for each t > 0,

P{ ¯Y0,t(x) ≤ ¯¯Y0,t(x) for λ-a.e. x} = 1.

(ii) Let { ¯Y1,t : t ≥ 0} and { ¯¯Y1,t : t ≥ 0} be any two D(R)-valued solutions of (1.2) under

conditions (1.7)–(1.8). If ¯Y1,0(x) ≤ ¯¯Y1,0(x) P-a.s. for all x ∈ R and

sup
t∈[0,T ]

[ ¯Y1,t(∞) + ¯¯Y1,t(∞)] < ∞

P-a.s.

(2.2)

for all T > 0, then for each t > 0,

P{ ¯Y1,t(x) ≤ ¯¯Y1,t(x) for all x ∈ R} = 1.

Proof. The proof is inspired by that of [25, Lemma 4.10] and [18, Proposition 3.1]. It is divided
into four steps.

Step 1. For n ≥ 1 and x, y ∈ R let
n(y) := gn(x − y) := r n
expn −

gx

2π

n(x − y)2

2

o, φn(x) := Z ∞

−∞

[(x − y) ∨ 0]gn(y)dy.

Then

φ′

n(x) = Z x

−∞

gn(y)dy, φ′′

n(x) = gn(x) ≥ 0, φn(x) → x ∨ 0

4

as n → ∞ and |x|φ′′

n(x) ≤ 1 for all n ≥ 1 and x ∈ R. Deﬁne
e−|y|ρ0(x − y)dy

J(x) := ZR

with the molliﬁer ρ0 given by

ρ0(x) := ˜C exp(cid:8) − 1/(1 − x2)(cid:9)1{|x|<1},
where ˜C is a constant so that RR ρ0(x)dx = 1. By (2.1) in [12], for each n ≥ 0 there exist
constants ˜cn, ˜Cn > 0 so that the n-derivative J (n) of J satisﬁes

which implies

˜cne−|x| ≤ |J (n)(x)| ≤ ˜Cne−|x|,

x ∈ R,

|J (n)(x)| ≤ ˜CnJ(x),

x ∈ R.

Step 2. Let t > 0 be ﬁxed in the following. For k ≥ 1 deﬁne stopping times

(2.3)

(2.4)

τ0,k := infns ≥ 0 : h ¯Y 2

0,s, Ji + h ¯¯Y 2

0,s, Ji > ko

and

τ1,k := inf (cid:8)s ≥ 0 : ¯Y1,s(∞) + ¯¯Y1,s(∞) > k(cid:9)
with the convention inf ∅ = ∞. It follows from (2.1) and (2.2) that

lim
k→∞

τ0,k = ∞ and

lim
k→∞

τ1,k = ∞ P-a.s.

(2.5)

For x ∈ R, m ≥ 1 and i = 0, 1, s ≥ 0 let

Yi,s := ¯Yi,s − ¯¯Yi,s, ˜Gi(s, u, x) := G(u, ¯Yi,s(x)) − G(u, ¯¯Yi,s(x)), vm

i,s(x) := hYi,s, gx
mi.

By conditioning we may assume that ¯Yi,0 and ¯¯Yi,0 are deterministic. It follows from (1.3) and
Itˆo’s formula that for each x ∈ R,

φn(vm

i,t∧τi,k (x)) = φn(vm

i,0(x)) +

i,s(x))∆vm

i,s(x)ds

+

Therefore,

1

2 Z t∧τi,k

0

1

2 Z t∧τi,k
φ′
n(vm
0
i,s(x))dsZE hZR
φ′′
n(vm

˜Gi(s, u, y)gx

m(y)dyi2

π(du) + mart.

EnZR
= ZR

φn(vm

i,t∧τi,k (x))J(x)dxo

φn(vm

i,0(x))J(x)dx +

+

1
2

EnZ t∧τi,k

0

dsZR

1
2
φ′′
n(vm

dsZR

EnZ t∧τi,k
φ′
n(vm
i,s(x))J(x)dxZE hZR

0

i,s(x))∆vm

˜Gi(s, u, y)gx

i,s(x)J(x)dxo
m(y)dyi2

π(du)o

=: I0(i, m, n) + I1(i, m, n, k, t) + I2(i, m, n, k, t).

(2.6)

5

Step 3. Observe that

ZR

φ′
n(vm

i,s(x))∆vm

i,s(x)J(x)dx = ZR

(φn(vm

i,s(x)))′′J(x)dx −ZR

φ′′
n(vm

i,s(x))|∇vm

i,s(x)|2J(x)dx.

Since φ′′

n = gn ≥ 0, the second term on the right-hand side is negative. Thus
i,s(x)))′′J(x)dxo
i,s(x))J ′′(x)dxo
i,s(x))J(x)dxo,
φn(vm

2I1(i, m, n, k, t) ≤ EnZ t∧τi,k
= EnZ t∧τi,k
≤ C EnZ t∧τi,k

dsZR
dsZR
dsZR

(φn(vm

φn(vm

0

0

0

(2.7)

where integration by parts and (2.4) were used. By the H¨older inequality and conditions (1.5)
and (1.8),

2I2(i, m, n, k, t) ≤ EnZ t∧τi,k
dsZR
φ′′
n(vm
≤ CkEnZ t∧τi,k
dsZR
nk + kφ′′′
nk ≤ 1, kφ′′

For i = 0, by the fact kφ′

0

0

see that for 0 ≤ s ≤ τ0,k,

i,s(x))J(x)dxZR
φ′′
i,s(x))h|Yi,s|, gx
n(vm

gx

m(y)dyZE
miJ(x)dxo.

˜Gi(s, u, y)2π(du)o

n k ≤ Cn and [23, Lemma 2.1], it is elementary to

hvm
0,s, Ji → hY0,s, Ji, h|φn(vm

0,s) − φn(Y0,s)|, Ji ≤ h|vm

0,s − Y0,s|, Ji → 0,

and

(2.8)

(2.9)

(2.10)

(2.11)

ZR

(cid:12)(cid:12)(cid:12)
φ′′
n(vm
≤ ZRhkφ′′
≤ kφ′′

0,s(x))h|Y0,s|, gx
nk(cid:12)(cid:12)h|Y0,s|, gx
nkZRh(cid:12)(cid:12)h|Y0,s|, gx
n khZR(cid:12)(cid:12)vm
+kφ′′′

miJ(x)dx −ZR
mi − |Y0,s(x)|(cid:12)(cid:12) + kφ′′′
mi − |Y0,s(x)|(cid:12)(cid:12)J(x)dx

0,s(x) − Y0,s(x)(cid:12)(cid:12)

φ′′

n(Y0,s(x))|Y0,s(x)|J(x)dx(cid:12)(cid:12)(cid:12)
0,s(x) − Y0,s(x)(cid:12)(cid:12)|Y0,s(x)|iJ(x)dx
n k(cid:12)(cid:12)vm

2J(x)dx ·ZR |Y0,s(x)|2J(x)dxi

1

2 → 0

as m → ∞. Observe that

φn(x) ≤ |x| +ZR |y|gn(y)dy ≤ |x| + 1

for all n ≥ 1. Then by (2.13) in [23],
ZR

φn(vm

ZR

sup

0,s(x))J(x)dx(cid:12)(cid:12)(cid:12)

m≥1(cid:12)(cid:12)(cid:12)

+(cid:12)(cid:12)(cid:12)

By [25, Lemma 4.5], one can check that (2.9)–(2.10) and (2.12) also hold for i = 1. Combining
this with (2.7)–(2.8) and dominated convergence we get

φ′′
n(vm

0,s(x))h|Y0,s|, gx

< ∞, on {s ≤ τ0,k}. (2.12)

miJ(x)dx(cid:12)(cid:12)(cid:12)

lim
m→∞

EnZR

φn(vm

i,t∧τi,k (x))J(x)dxo = EnZR

φn(Yi,t∧τi,k (x))J(x)dxo

6

and

lim
m→∞

I0(i, m, n) = hφn(Yi,0), Ji =: J0(i, n),
I1(i, m, n, k, t) ≤ C EnZ t∧τi,k
dsZR
I2(i, m, n, k, t) ≤ CkEnZ t∧τi,k
dsZR

0

0

lim sup
m→∞

lim sup
m→∞

φn(Yi,s(x))J(x)dxo =: J1(i, n, k, t),
n(Yi,s(x))|Yi,s(x)|J(x)dxo =: J2(i, n, k, t)
φ′′

for both i = 0, 1.

Now taking m → ∞ in (2.6) we have

EnZR

φn(Yi,t∧τi,k (x))J(x)dxo ≤ J0(i, n) + J1(i, n, k, t) + J2(i, n, k, t).

(2.13)

Step 4. Since 0 ≤ |x|φ′′

n(x) ≤ 1 for all x ∈ R, n ≥ 1 and limn→∞ |x|φ′′

n(x) = 0 for each x ∈ R,

by dominated convergence we have

lim
n→∞

J2(i, n, k, t) ≤ CkEnZ t∧τi,k

0

dsZR

lim
n→∞

n(Yi,s(x))|Yi,s(x)|J(x)dxo = 0.
φ′′

(2.14)

Using dominated convergence and (2.11) we know that

(Yi,0(x))+J(x)dx = 0,

lim
n→∞

lim
n→∞

lim
n→∞

J0(i, n) = ZR
J1(i, n, k) = C EnZ t∧τi,k
EnZR

0

dsZR

(Yi,s(x))+J(x)dxo,

φn(Yi,t∧τi,k (x))J(x)dxo = EnZR(cid:16)Yi,t∧τi,k (x)(cid:17)+

J(x)dxo.

Combining with (2.13)–(2.14) we get

En1{t≤τi,k }ZR

(Yi,t(x))+J(x)dxo ≤ EnZR(cid:16)Yi,t∧τi,k (x)(cid:17)+
dsZR
0 h1{s≤τi,k}ZR

≤ C EnZ t∧τi,k
= C EnZ t

0

J(x)dxo
(Yi,s(x))+J(x)dxo

(Yi,s(x))+J(x)dxidso.

Then by Grownwall’s lemma,

which implies that

En1{t≤τi,k }ZR

(Yi,t(x))+J(x)dxo = 0,

1{t≤τi,k}ZR

(Yi,t(x))+J(x)dx = 0, P-a.s.

Letting k → ∞ we see that RR(Yi,t(x))+J(x)dx = 0 P-a.s. by (2.5). Then the desired result

follows.

✷

7

Lemma 2.2 Suppose that conditions (1.4)–(1.6) hold and Y = {Yt : t ≥ 0} is a solution of (1.2)
t , e−|·|i} < ∞ for each T > 0. If Y0 ∈ D(R), then Y has a C([0,∞)×R)-
satisfying supt∈[0,T ] E{hY 2
valued modiﬁcation ˜Y = { ˜Yt : t ≥ 0} with ˜Y0 ∈ D(R) (i.e. P{h|Yt − ˜Yt|, 1i = 0} = 1 for each
t ≥ 0). Moreover, P{ ˜Yt ∈ Dc(R) for all t > 0} = 1 and supt∈[0,T ]

˜Yt(∞) < ∞, P-a.s.

Proof. The proof is proceeded in four steps.

Step 1. By the assertion and proof of [23, Theorem 1.2], the solution Y of (1.2) has a
C([0,∞) × R)-valued modiﬁcation ˜Y = { ˜Yt : t ≥ 0}. Observe that Yt ≡ 0 is also a solution of
(1.2). It then follows from Proposition 2.1(i) that P{ ˜Yt(x) ≥ 0 for all t ≥ 0 and x ∈ R} = 1.

Fixed y1 ≥ y2, let Y1,t(x) := Yt(x + y1) and Y2,t(x) := Yt(x + y2). It follows from Proposition

2.1(i) again that Y1,0(x) ≥ Y2,0(x) for all x ∈ R and

which implies

P{Yt(x + y1) ≥ Yt(x + y2) for λ-a.e. x} = 1

P{ ˜Yt(x) ≥ ˜Yt(y) for all x ≥ y ∈ R} = 1.

Step 2. It follows from (2.12) in [23], for each |f| ≤ CJ, we have for any t > 0,
G(u, Ys(z))Pt−sf (z)dziW (ds, du) P-a.s.

hYt, fi = hY0, Ptfi +Z t

0 ZE hZR

Without loss of generality we assume that Y0 is deterministic in the following. Thus E{hYt, Jni} =
hY0, PtJni for Jn(x) := J(x − n). By monotone convergence and h1, Ji = 2 we have
˜Yt(x + n)J(x)o = h1, JiE{ ˜Yt(∞)} = 2E{ ˜Yt(∞)}

E{hYt, Jni} = lim

EnZR

lim
n→∞

n→∞

and

n→∞hY0, PtJni = lim
lim

n→∞ZR

Y0(z + n)dzZR

pt(y)J(z − y)dy = 2Y0(∞),

which implies

Similarly, by dominated convergence and h1, Jni = 2 we also get

E{ ˜Yt(∞)} = Y0(∞).

(2.15)

2E{ ˜Yt(−∞)} = E[

n→−∞hYt, Jni] = lim
lim

n→−∞

E[hYt, Jni] = lim

n→−∞hY0, PtJni = 0.

(2.16)

Step 3. In this step we show that supt∈[0,T ]

Burkholder-Davis-Gundy inequality,

˜Yt(∞) < ∞ for each T > 0. By (1.3) and the

En sup

1

2 Z T
t∈[0,T ]hYt, Jnio ≤ hY0, Jni +
Z T
dsZEhG(u, Ys), Jni2π(du)(cid:12)(cid:12)(cid:12)
+CEn(cid:12)(cid:12)(cid:12)

E{hYs,|J ′′

n|i}ds

0

1

2o.

(2.17)

0

8

Under conditions (1.5)–(1.6), for each y ≥ 0,

ZE

G(u, y)2π(du) = ZE |G(u, y) − G(u, 0)|2π(du) ≤ C|y|.

It then follows from the H¨older inequality and h1, Jni = 2 that

ZEhG(u, Ys), Jni2π(du) ≤ 2ZEhG(u, Ys)2, Jniπ(du)

= 2ZR

Jn(x)dxZE

G(u, Ys(x))2π(du) ≤ C ZR |Ys(x)|Jn(x)dx.

Putting together (2.17) and (2.4) we have

En sup

Y0(x + n)J(x)dx + CZ T
t∈[0,T ]hYt, Jnio ≤ ZR
Z T
+C(cid:12)(cid:12)(cid:12)

dtZR
E{Yt(x + n)}J(x)dx(cid:12)(cid:12)(cid:12)

dtZR

0

0

It then follows from (2.15) and (2.18) that for each T > 0,

E{Yt(x + n)}J(x)dx

1

2 .

(2.18)

sup
n≥1

En sup

t∈[0,T ]hYt, Jnio ≤ 2Y0(∞) + CT Y0(∞) + C[T Y0(∞)]

1

2 .

Thus by monotone convergence

h1, JiEn sup

t∈[0,T ]

= En lim

n→∞

sup

t∈[0,T ],n≥1ZR
˜Yt(∞)o = En
˜Yt(x + n)J(x)dxo = lim

n→∞

˜Yt(x + n)J(x)dxo
t∈[0,T ]hYt, Jnio,
En sup

(2.19)

sup

t∈[0,T ]ZR
˜Yt(∞) < ∞, P-a.s.

which implies that supt∈[0,T ]

Step 4. By (2.16), (2.18) and dominated convergence

h1, JiEn sup

t∈[0,T ]

˜Yt(−∞)o ≤ En sup

t∈[0,T ]ZR

˜Yt(−∞)J(x)dxo
En sup

≤ En lim

n→−∞

sup

˜Yt(x + n)J(x)dxo ≤ lim

t∈[0,T ]ZR
˜Yt(−∞) = 0, P-a.s. Therefore, P{ ˜Yt ∈ D(R)} = 1 for each t > 0, which

t∈[0,T ]h ˜Yt, Jnio = 0,

n→−∞

✷

which implies supt∈[0,T ]
ﬁnishes the proof.

Now we are ready to present the main theorem.

Theorem 2.3 Suppose that conditions (1.6)–(1.8) hold. Then for any Y0 ∈ D(R) SPDE (1.2)
has a pathwise unique continuous Dc(R)-valued solution {Yt : t > 0}.

Proof. The pathwise uniqueness follows immediately from Proposition 2.1(ii). We prove the
existence of a Dc(R)-valued solution to (1.2) in the following. We assume that Y0 is deterministic.

9

By [23, Theorem 1.2] and Lemma 2.2, the following SPDE has a strong unique continuous Dc(R)-
valued solution:

Yt(y) = Y0(y) +

1

2 Z t

0

∆Ys(y)ds +Z t

0 ZE

Gm(u, Ys(y))W (ds, du),

(2.20)

where Gm(u, y) := G(u, y ∧ m) for m ≥ 1. For each m ≥ 1, let {Y m
continuous Dc(R)-valued solution to (2.20) with Y m
0
stopping time τ m
that P-a.s.

: t ≥ 0} be a strong
:= Y0. For each m, n ≥ 1, deﬁne the
t (∞) ≥ n}. It then follows from the uniqueness of (2.20)

n := inf{t ≥ 0 : Y m

t

Y m
t∧τ m

m ∧τ m+1

m

= Y m+1
t∧τ m

m ∧τ m+1

m

,

t ≥ 0.

τ m
m

m ≤ τ m+1

m , then Y m+1
m . Therefore, τ m

If τ m
m ≥ τ m+1
τ m
m. Observe that for Jn(x) = J(x − n) we have hY m
from (2.20) that

(∞) = Y m
m = τ m+1

·∧τ m
m

m

t

(∞) = m, which, by the deﬁnition of τ m+1
τ m
m
. This implies that τ m
and Y m

= Y m+1

m , implies that
m is increasing in
t (y + n)J(y)dy. It then follows

·∧τ m+1

m

, Jni = RR Y m
dsZR

ZR

Y m

t (y + n)J(y)dy = ZR
+Z t

Y0(y + n)J(y)dy +

0 ZE hZR

Gm(u, Y m

0

1

2 Z t
s (y + n)J ′′(y)dy
Y m
s (y + n))J(y)dyiW (ds, du).

Letting n → ∞ we have

Y m

t (∞) = Y0(∞) +Z t
0 ZE
m ∧t(∞)} = Y0(∞). Thus
m < t} = E(cid:8)Y m
(∞)1{τ m

τ m
m

τ m

which implies E{Y m
mP{τ m
Letting t → ∞, we have

Gm(u, Y m

s (∞))W (ds, du),

m <t}(cid:9) ≤ E{Y m

τ m

m ∧t(∞)} = Y0(∞).

P{τ m
as m → ∞. So, we must have τ m
Yt = Y m

for t ≤ τ m

t∧τ m
m

m . This completes the proof.

m < ∞} ≤ Y0(∞)/m → 0
m ↑ ∞. Therefore, we can deﬁne the solution to (1.2) by

✷

3

Interacting super-Brownian motions

In the early work of M´el´eard and Roelly [11] a measure-valued branching process with mean
ﬁeld interaction was introduced. Using particle system approximation,
it is shown that if
˜σ ∈ C(M (R) × R)+, then the continuous M (R)-valued solution {Xt : t ≥ 0} to the follow-
ing martingale problem exists: for any f ∈ C 2(R),
2 Z t
1

:= Xt(f ) − X0(f ) −

Xs(f ′′)ds,

t ≥ 0

M f
t

(3.1)

0

10

is a square-integrable continuous martingale with

hM fit = Z t

0 hXs, ˜σ(Xs)f 2ids.

(3.2)

However, owing to the interaction, the fundamental multiplicative property of the measure
branching process disappears and one cannot associate the interacting measure branching pro-
cesses with a cumulant semigroup, characterized as the unique solution of a non-linear partial
diﬀerential equation. The uniqueness of solution to the above martingale problem is still un-
known. Using snake representation and random time change techniques, Delmas and Dhersin [4]
proved the existence of solution to a similar martingale problem for interacting super-Brownian
motion. But again, the uniqueness of solution is left open in general.

In this section, we consider an interacting super-Brownian motion {Xt : t ≥ 0}, which is a
continuous M (R)-valued process solving the following local martingale problem: for any f ∈
C 2(R),

Mt(f ) := Xt(f ) − X0(f ) −

1

2 Z t

0

Xs(f ′′)ds,

t ≥ 0

is a continuous local martingale with quadratic variation process

hM (f )it = Z t

σ(Xs(−∞, x]))f (x)2Xs(dx),
where the branching rate function σ ∈ B(R+)+ is bounded on [0, n] for each n ≥ 1 and

σ(Xs, x)f (x)2Xs(dx) := Z t

dsZR

dsZR

0

0

(3.3)

(3.4)

λ{u ∈ R+ : σ(u) = 0} = 0.

Note that the local martingale problem (3.3)–(3.4) is not covered by that of (3.1)–(3.2). For
constant σ, super-Brownian motion with branching rate σ is the unique solution to the above-
mentioned martingale problem.

We will establish both the existence and uniqueness of solution to martingale problem (3.3)-
(3.4) by associating its solution with an SPDE of type (1.2). Then properties of the interacting
super-Brownian motion will be investigated.

3.1 Well-posedness of the martingale problem

The next result is on the connection between the local martingale problem and the corresponding
distribution-function-valued SPDE. We say a D(R)-valued process {Yt : t ≥ 0} is a distribution-
function process of a M (R)-valued process {Xt : t ≥ 0} if Yt(x) = Xt((−∞, x]) for all t ≥ 0 and
x ∈ R.

Lemma 3.1 A continuous D(R)-valued process {Yt : t ≥ 0} is the distribution-function process
of the interacting super-Brownian motion if and only if there is, on an enlarged probability
space, a Gaussian white noise {W (dt, du) : t ≥ 0, u ≥ 0} with intensity dtdu so that {Yt : t ≥ 0}
solves the following SPDE:

Yt(x) = Y0(x) +

1

2 Z t

0

∆Ys(x)ds +Z t

0 Z ∞

0

1{u≤Ys(x)}pσ(u)W (ds, du).

(3.5)

11

Remark Choose E = R+, π =Lebesgue measure on R+ and

G(u, x) = 1{u≤x}pσ(u),

u, x ∈ R+.

Then {Yt : t ≥ 0}, the D(R)-valued solution to SPDE (1.2) with conditions (1.6)–(1.8), is in
fact the distribution-function process of the measure-valued process {Xt : t ≥ 0} which solves
the local martingale problem (3.3)–(3.4). Consequently, the existence of solution to the local
martingale problem follows from the existence of solution to (1.2), which is diﬀerent from the
approaches in [4, 11], and the uniqueness of the solution follows from the strong uniqueness of
the SPDE. The following theorem generalizes the results of [18, 25] in which σ is required to be
bounded.

Theorem 3.2 The local martingale problem (3.3)–(3.4) is well-posed.

Proof. The result follows from Theorem 2.3 and Lemma 3.1 immediately.

✷

Proof of Lemma 3.1. The proof is a modiﬁcation of those of [23, Theorem 1.3] and [7, Theorem
3.1]. Suppose that {Yt : t ≥ 0} is a continuous D(R)-valued solution of (3.5). By integration by
parts, Xt(f ) = −hYt, f ′i for each f ∈ C 3

0 (R). It then follows from (3.5) that

1

0 hYs, f ′′′ids −Z t
2 Z t
Xt(f ) = −hY0, f ′i −
0 Z ∞
Xs(f ′′)ds −Z t
2 Z t
1
0
2 Z t
Xs(f ′′)ds + ˜It(f ),

= X0(f ) +

= X0(f ) +

0 Z ∞
hZR

1

0

0

0

hZR
f ′(x)1{Y −1

f ′(x)1{u≤Ys(x)}dxipσ(u)W (ds, du)
(u)≤x}dxipσ(u)W (ds, du)

s

where

Y −1
t

(u) := inf{x ∈ R : Yt(x) ≥ u}

(3.6)

with the convention inf ∅ = ∞ and
˜It(f ) := Z t

0 Z ∞

0

f (Y −1

s

(u))pσ(u)W (ds, du).

One can see that { ˜It(f ) : t ≥ 0} is a continuous local martingale with quadratic variation process

h ˜I(f )it = Z t

0 Z ∞

0

σ(u)f (Y −1

s

(u))2du = Z t

0

dsZR

σ(Xs(−∞, x])f (x)2Xs(dx).

By an approximation argument, one can see the above relation remains true for all f ∈ C 2(R).
Therefore, {Xt : t ≥ 0} is an interacting super-Brownian motion.

Suppose that {Xt : t ≥ 0} is an interacting super-Brownian motion determined by the local
martingale problem (3.3)–(3.4). We will show that the distribution-function process {Yt : t ≥ 0}
of {Xt : t ≥ 0} solves (3.5). We assume that X0 is deterministic in the following.

Observe that

Xt(1) = X0(1) + Mt(1),

where {Mt(1) : t ≥ 0} is a continuous local martingale and {Mt∧τn (1) : t ≥ 0} is a continuous
martingale for each n ≥ 1 with stopping time τn deﬁned by τn := inf{t ≥ 0 : Xt(1) ≥ n}. It

12

then follows that E{Xt∧τn (1)} = X0(1). Since t 7→ Xt(1) is continuous, τn → ∞ as n → ∞.
Thus by Fatou’s lemma,

E{Xt(1)} = En lim inf

n→∞

Xt∧τn (1)o ≤ lim inf

n→∞

E(cid:8)Xt∧τn(1)(cid:9) = X0(1).

(3.7)

We can complete the proof in four steps.

Step 1. We say { ¯Mt(B) : t ≥ 0, B ∈ B(R)} is a continuous local martingale measure if there
are stopping times ˜σn with ˜σn → ∞ P-a.s. so that for each n ≥ 1, { ¯Mt∧˜σn (B) : t ≥ 0, B ∈ B(R)}
is a continuous martingale measure. That is for each B ∈ B(R), { ¯Mt∧˜σn (B) : t ≥ 0} is a square-
integrable continuous martingale and for every disjoint sequence {B1, B2,··· } ⊂ B(R) we have

¯Mt∧˜σn(cid:16)

∞

[k=1

Bk(cid:17) =

∞

Xk=1

¯Mt∧˜σn (Bk)

t

by the convergence in L2(Ω, P). For any n ≥ 1 and f ∈ B(R), let M n
t (f ) = Mt∧τn (f ) which
determines a continuous martingale measure {M n
t (B) : t ≥ 0, B ∈ B(R)} by the same argument
as in the proof of [10, Theorem 7.25]. Then by the same argument as in [14, Lemma 5.6] we
have M n
t∧τn for n ≥ 1. Thus we can deﬁne the continuous local martingale measure
{Mt(B) : t ≥ 0, B ∈ B(R)} by Mt = M n

for t ≤ τn.

t = M n+1

and

Step 2. Let B(R+× R× Ω) be the space of progressively measurable functions on R+× R× Ω
F = nF ∈ B(R+ × R × Ω) : Z t
dsZR
Fb = nF ∈ B(R+ × R × Ω) : EnZ t
In this step we show that the stochastic integral of F ∈ F with respect to {M (ds, dx) : s ≥
0, x ∈ R} is well deﬁned. By the same argument as in [10, pp.160–166], the stochastic integral
of F ∈ Fb with respect to {M (ds, dx) : s ≥ 0, x ∈ R} is well deﬁned. For F ∈ F deﬁne stopping
times τ ′

σ(Xs(−∞, x])F (s, x)2Xs(dx) < ∞, t > 0, P-a.s.o,
dsZR
σ(Xs(−∞, x])F (s, x)2Xs(dx)o < ∞, ∀t > 0o.

0

0

n by

τ ′

n = inf nt ≥ 0 : Z t

0

dsZR

σ(Xs(−∞, x])F (s, x)2Xs(dx) ≥ no.

n → ∞ P-a.s. and the stochastic integral of F ∈ F with respect to {M (ds, dx) : s ≥

Then τ ′
0, x ∈ R} is deﬁned by

Z t
0 ZR

F (s, x)M (ds, dx) = Z t

0 ZR

F (s, x)1{s≤τ ′

n}M (ds, dx),

t ≤ τ ′
n.

Step 3. For g ∈ B(R+) deﬁne continuous local martingale t 7→ Zt(g) by

Zt(g) = Z t

0 ZR

g(Ys(x))σ(Ys(x))− 1

2 1{σ(Ys(x))6=0}M (ds, dx).

(3.8)

Observe that the quadratic variation process of t 7→ Zt(g) satisﬁes

hZt(g)it = Z t

0

dsZR

g(Ys(x))2σ(Ys(x))−11{σ(Ys(x))6=0}σ(Ys(x))Xs(dx)

13

= Z t
= Z t

0

0

dsZR
dsZ ∞

0

g(Ys(x))2σ(Ys(x))−11{σ(Ys(x))6=0}dYs(x)
g(u)21{σ(u)6=0,u≤Ys(∞)}du = Z t
dsZR

0

g(u)21{u≤Ys(∞)}du,

where λ{u ∈ R+ : σ(u) = 0} = 0 was used in the last equation. Combining this with (3.7) one
sees that {Zt(g) : t ≥ 0} is a martingale for each g ∈ B(R+). Then the family {Zt(g) : t ≥ 0, g ∈
B(R+)} determines a martingale measure {Z(dt, dx) : t ≥ 0, x ≥ 0}. Then by [5, Theorem III-6],
on an extended probability space, there is a Gassian white noise {W (ds, du) : s ≥ 0, u > 0} so
that

Zt(g) = Z t

0 Z ∞

0

g(u)1{u≤Ys(∞)}W (ds, du).

Then we can extend the deﬁnition of the stochastic integral of

g ∈ F0 := ng ∈ B(R+ × R+ × Ω) : Z t
with respect to the martingale measure {Z(dt, dx) : t ≥ 0, x ≥ 0} and

dsZ ∞

0

0

g(s, u)21{u≤Ys(∞)}du < ∞ P-a.s., ∀t ≥ 0o

0 Z ∞
Z t

0

g(s, x)Z(ds, dx) = Z t

0 Z ∞

0

g(s, u)1{u≤Ys(∞)}W (ds, du).

(3.9)

It follows from Step 2 and (3.8) that for each g ∈ F0,

0 Z ∞
Z t

0

g(s, u)Z(dt, du) = Z t

0 ZR

g(s, Ys(x))σ(Ys(x))− 1

2 1{σ(Ys(x))6=0}M (ds, dx).

Combining this with (3.9) we know that

Z t
0 ZR

g(s, Ys(x))σ(Ys(x))− 1
0 Z ∞
= Z t

0

2 1{σ(Ys(x))6=0}M (ds, dx)

g(s, u)1{u≤Ys(∞)}W (ds, du),

g ∈ F0.

(3.10)

Step 4. Observe that for each x ∈ R,

1{Ys(y)≤Ys(x)}M (ds, dy) −Z t

1{y≤x}M (ds, dy)

Z t
0 ZR
= Z t
0 ZR
= Z t
0 ZRh1{Ys(y)≤Ys(x)}σ(Ys(y))
+Z t
0 ZR

1

=: ˜M1(t, x) + ˜M2(t, x) − ˜M3(t, x).

0 ZR

1{Ys(y)≤Ys(x),σ(Ys(y))=0}M (ds, dy) −Z t
0 ZR

1{Ys(y)≤Ys(x),y>x}M (ds, dy)

2iσ(Ys(y))− 1

2 1{σ(Ys(y))6=0}M (ds, dy)

1{Ys(y)≤Ys(x),y>x}M (ds, dy)

Letting g(s, u) = 1{u≤Ys(x)}σ(u)

1

2 in (3.10) we obtain

˜M1(t, x) = Z t

0 Z ∞

0

1{u≤Ys(x)}σ(u)

1

2 W (ds, du).

14

(3.11)

(3.12)

Observe that

E{ ˜M2(t, x)2} = EnZ t

0

dsZR

1{Ys(y)≤Ys(x),σ(Ys(y))=0}σ(Ys(y))dyo = 0,

which implies that

Observe that the quadratic variation process h ˜M3(x)it of t 7→ ˜M3(t, x) satisﬁes

˜M2(t, x) = 0, P-a.s.

(3.13)

h ˜M3(x)it = Z t
= Z t

0

0

dsZR
dsZR

σ(Xs(−∞, y]))1{Ys(y)≤Ys(x),y>x}Xs(dx)
σ(Ys(y))1{Ys(y)≤Ys(x),y>x}dYs(y) = 0,

which implies ˜M3(t, x) = 0 P-a.s. Combining (3.11)–(3.13) one has

Z t
0 ZR

1{y≤x}M (ds, dy) = Z t

0 Z ∞

0

1{u≤Ys(x)}σ(u)

1

2 W (ds, du), P-a.s.

Then by stochastic Fubini’s theorem, for f ∈ C 2
¯f (y)M (ds, dy) = Z t

0 (R) with h|f|, 1i < ∞ and ¯f (y) := R ∞
0 ZRhZR

f (x)1{y≤x}dxiM (ds, dy)

y f (x)dx,

Mt( ¯f ) = Z t
= ZR
= ZR

0 ZR
f (x)dxZ t
f (x)dxZ t

0 ZR
0 Z ∞

0

1{y≤x}M (ds, dy)

1{u≤Ys(x)}σ(u)

1

2 W (ds, du), P-a.s.

By integration by parts, we have P-a.s.

Mt( ¯f ) = Xt( ¯f ) − X0( ¯f ) −

1

2 Z t

0

Xs(( ¯f )′′)ds = hYt, fi − hY0, fi −

1

2 Z t

0 hYs, f ′′ids,

which yields that {Yt : t ≥ 0} solves (3.5).

✷

3.2 Properties

In this subsection we discuss the existence of density ﬁeld and long time extinction behaviors of
the interacting super-Brownian motion.

: t ≥ 0} is the interacting super-Brownian motion with
Theorem 3.3 Suppose that {Xt
distribution-function process {Yt : t ≥ 0} solving SPDE (3.5). Then for any f ∈ C 2(R), P-
a.s.

Xt(f ) = X0(f ) +

1

2 Z t

0

Xs(f ′′)ds +Z t

0 Z ∞

0

f (Y −1

s

(u))pσ(u)W (ds, du),

t ≥ 0,

(3.14)

and for any f ∈ B(R) and t > 0,
Xt(f ) = X0(Ptf ) +Z t

0 Z ∞

0

Pt−sf (Y −1

s

(u))pσ(u)W (ds, du) P-a.s.,

(3.15)

15

where Pt denotes the transition semigroup for Brownian motion and recall that Y −1
(u) is deﬁned
by (3.6). Moreover, for each t > 0 the random measure Xt(dx) is absolutely continuous with
respect to Lebesgue measure and the density Xt(x) satisﬁes

t

Xt(x) = ZR

pt(x − y)X0(dy) +Z t

0 Z ∞

0

pt−s(x − Y −1

s

(u))pσ(u)W (ds, du) P-a.s.,

(3.16)

where pt is the transition density function for Brownian motion.

Proof. By the proof of Lemma 3.1, we easily get (3.14). We then ﬁnish the proof in the following
two steps.

Step 1. Let t > 0 be ﬁxed. For n ≥ 1 deﬁne stopping time τn by

τn = inf{s ≥ 0 : Xs(1) ≥ n}.

Then τn → ∞ as n → ∞. In this step we want to show that for each f ∈ C 2(R) and n ≥ 1,

Xt∧τn (Pt−(t∧τn )f ) = X0(Ptf ) +Z t

(u))pσ(u)1{s≤τn}W (ds, du) P-a.s. (3.17)
Consider a partition ∆m := {0 = t0 < t1 < ··· < tm = t} of [0, t]. Let |∆m| := max1≤i≤m |ti −
ti−1|. It is obvious that dPsf

2 ∆Psf for s ≥ 0. It then follows from (3.14) that

0 Z ∞

Pt−sf (Y −1

ds = 1

0

s

Xt∧τn (Pt−(t∧τn)f )

m

= X0(Ptf ) +

m

Xi=1

Xti∧τn(cid:0)Pt−(ti∧τn)f − Pt−(ti−1∧τn)f(cid:1)

Xs(∆Pt−(ti−1∧τn)f )1{s≤τn}ds

(u))pσ(u)1{s≤τn}W (ds, du)

+

Xi=1 (cid:2)Xti∧τn(Pt−(ti−1∧τn)f ) − Xti−1∧τn(Pt−(ti−1∧τn)f )(cid:3)
Z ti
Xi=1

Xti∧τn(∆Psf )ds +

1
2

m

m

ti−1

= X0(Ptf ) +

0

1
2

t−(ti−1∧τn)

Z t−(ti∧τn)
Xi=1
ti−1 Z ∞
Z ti
Pt−(ti−1∧τn)f (Y −1
2 Z t
Xi=1
Xi=1
Ii(s)Pt−(ti−1∧τn)f (Y −1

1

m

m

0

0

s

s

m

+

Xi=1

= X0(Ptf ) +

+Z t

0 Z ∞

Ii(s)(cid:2)Xs(∆Pt−(ti−1∧τn)f ) − Xti∧τn(∆Pt−sf )(cid:3)1{s≤τn}ds

(u))pσ(u)1{s≤τn}W (ds, du)

=: X0(Ptf ) + ˜I1(t, m, n)/2 + ˜I2(t, m, n),

(3.18)

m

lim

|∆m|→0| ˜I1(t, m, n)| ≤ Z t

where Ii(s) := 1(ti−1,ti](s). Observe that by the dominated convergence and the continuities of
s 7→ Psf and s 7→ Xs(Pt′f ) for t′ > 0, we have
Ii(s)h(cid:12)(cid:12)Xs(∆Pt−(ti−1∧τn)f ) − Xs(∆Pt−sf )(cid:12)(cid:12)
Xi=1
+(cid:12)(cid:12)Xs(∆Pt−sf ) − Xti∧τn(∆Pt−sf )(cid:12)(cid:12)i1{s≤τn}ds
0 Z ∞
(u))pσ(u)1{s≤τn}W (ds, du)i2o

Enh ˜I2(t, m, n) −Z t

Pt−sf (Y −1

|∆m|→0

|∆m|→0

and

lim

lim

0

0

s

16

= lim

|∆m|→0

= EnZ t

0

EnhZ t

dsZ ∞

0

m

0

Xi=1

0 Z ∞
−Pt−sf (Y −1
lim

m

s

|∆m|→0

Xi=1

Ii(s)(cid:2)Pt−(ti−1∧τn)f (Y −1

s

(u))

(u))(cid:3)pσ(u)1{s≤τn}W (ds, du)i2o

Ii(s)(cid:2)Pt−(ti−1∧τn)f (Y −1
−Pt−sf (Y −1

s

s

(u))

(u))(cid:3)2σ(u)1{s≤τn}duo = 0.

Thus (3.17) follows by letting |∆m| → 0 in (3.18).

Step 2. Equation (3.17) holds for each f ∈ B(R) by an approximation argument and then
(3.15) follows by letting n → ∞. We now prove the last assertion. By (3.17) we have that for
each f ∈ B(R),

EnhXt∧τn , Pt−(t∧τn )fio = X0(Ptf ).

It follows from Fatou’s lemma that for f ∈ B(R)+,
E{Xt(f )} = En lim inf

n→∞ hXt∧τn , Pt−(t∧τn )fio ≤ lim inf

n→∞

Thus,

EnhXt∧τn , Pt−(t∧τn )fio = X0(Ptf ).

s

0

0

0

f (x)dxZ t

EnZR
≤ EnZR
≤ EnZR
≤ cnEnZR
≤ cnEnZ t

(u))2σ(u)duo

pt−s(x − Y −1
2 dsZ ∞
2 dsZ ∞
2 dsZ ∞

1{s≤τn}dsZ ∞
(t − s)− 1
(t − s)− 1
(t − s)− 1
2 Xs(Pt−sf )dso ≤ cnµ(Ptf )Z t

(u))σ(u)1{s≤τn }duo
pt−s(x − Y −1
pt−s(x − y)σ(Ys(y))1{s≤τn}Xs(dy)o
pt−s(x − y)Xs(dy)o
(t − s)− 1

f (x)dxZ t
f (x)dxZ t
f (x)dxZ t
(t − s)− 1

2 ds < ∞,

0

0

0

0

0

0

0

s

where cn := supx∈[0,n] σ(x). Then by [10, Theorem 7.24], for each t0 > 0 we have

hXt0∧τn, Pt0−(t0∧τn)fi = ZR

f (x)Kt0 (t0 ∧ τn, x)dx P-a.s.

(3.19)

where

Kt0(t, x) := ZR

pt0(x − y)X0(dy) +Z t

0 Z ∞

0

pt0−s(x − Y −1

s

(u))pσ(u)W (ds, du).

Letting n → ∞ in (3.19) we get Xt(f ) = RR f (x)Kt(t, x)dx P-a.s., which ﬁnishes the proof. ✷
Write σ0(x) := R x
0 σ(y)dy for x ≥ 0. Notice that σ0(x) is an increasing continuous function
and σ0(x) = 0 if and only if x = 0. In the following of this subsection we always assume that
µ ∈ M (R) and {Xt : t ≥ 0} is an interacting super-Brownian motion with X0 = µ. Taking
f = 1 in (3.14) we get

Xt(1) = X0(1) +Z t

0 Z Xs(1)

0

pσ(u)W (ds, du).

17

Thus the total mass process {Xt(1) : t ≥ 0} is a nonnegative continuous local martingale with
quadratic variation process

hX(1)it = Z t

0

dsZ Xs(1)

0

σ(y)dy = Z t

0

σ0(Xs(1))ds.

(3.20)

By the uniqueness of solution to the local martingale problem, if µ is a zero measure, then
P{Xt(1) = 0 for all t > 0} = 1. So we assume that µ(1) > 0 in the following subsection.

For a ≥ 0 let

with the convention inf ∅ = ∞.

ˆτa := inf{t ≥ 0 : Xt(1) = a}

Theorem 3.4 For any ﬁnite measure µ and constant a > 0 satisfying µ(1) > a > 0, we have
P{ˆτa < ∞} = 1. Further, P-a.s. Xt(1) → 0 as t → ∞.
Proof. Notice that for any ˜λ > 0, process

expn − ˜λXt(1) −

˜λ2

2 Z t

0

σ0(Xs(1))dso

is a bounded continuous martingale. Then by optional sampling,

e−˜λµ(1) = En exph − ˜λXt∧ˆτa (1) −
Letting t → ∞, by dominated convergence we have

˜λ2

2 Z t∧ˆτa

0

σ0(Xs(1))dsio.

En exph − ˜λa −

˜λ2

2 Z ˆτa

0

σ0(Xs(1))dsio

= lim
t→∞

En exph − ˜λXt∧ˆτa (1) −

Now letting ˜λ → 0 we have

˜λ2

2 Z t∧ˆτa

0

σ0(Xs(1))dsio = e−˜λµ(1).

PnZ ˆτa

0

σ0(Xs(1))ds < ∞o = 1.

Observe that by the assumption on function σ we have inf y≥x σ0(y) > 0 for any x > 0, which
implies that

σ0(Xs(1))ds = ∞o.
Then we have P{ˆτa < ∞} = 1, which proves the ﬁrst assertion.

{ˆτa = ∞} ⊂ nZ ˆτa

0

For any n ≥ 1 and small ε > 0 let

An := {ˆτεn+1 < ∞, ˆτε ◦ θˆτεn+1 < ˆτεn+2 ◦ θˆτεn+1},

where θ denotes the shift operator.

18

Since {Xt(1) : t ≥ 0} is a continuous local martingale, then by optional stopping we have

εn+1 = Xˆτεn+1 (1) = E(cid:2)Xˆτ1,ε,n∧ˆτ2,ε,n(1)(cid:12)(cid:12)Xˆτεn+1 (1)(cid:3)

≥ E(cid:2)Xˆτ1,ε,n (1)1{ˆτ1,ε,n <ˆτ2,ε,n}(cid:12)(cid:12)Xˆτεn+1 (1)(cid:3) = εP(cid:2)ˆτ1,ε,n < ˆτ2,ε,n(cid:12)(cid:12)Xˆτεn+1 (1)(cid:3),

where ˆτ1,ε,n := ˆτε ◦ θˆτεn+1 and ˆτ2,ε,n := ˆτεn+2 ◦ θˆτεn+1 . Then we know that
P{An} ≤ PnP(cid:2)ˆτ1,ε,n < ˆτ2,ε,n(cid:12)(cid:12)Xˆτεn+1 (1)(cid:3)o ≤ εn.

It follows from the Borel-Cantelli lemma that P{An inﬁnitely often} = 0. Then by the ﬁrst
assertion, for all n large enough,

ˆτεn < ∞,

ˆτεn+1 ◦ θˆτεn < ˆτε ◦ θˆτεn ,

P-a.s.

Therefore, P-a.s. for n large enough Xt(1) < ε for all t ∈ [ˆτεn, ˆτ0), where ˆτ0 = limm→∞ ˆτεm. If
ˆτ0 < ∞, then Xt(1) = 0 for all t ≥ ˆτ0; otherwise, Xt(1) → 0 as t → ∞ but Xt(1) > 0 for all t.
Putting them together, we have Xt(1) → 0.

✷

The extinction behavior of {Xt : t ≥ 0} depends on the branching rate when the total mass

is close to 0. So, it depends on how fast σ0(x) converges to 0 when x → 0+.
Theorem 3.5 (i) If there exists a constant γ1 ∈ [0, 2) so that lim inf x→0+ σ0(x)/xγ1 > 0, we
have P{ˆτ0 < ∞} = 1 and Xt(1) = 0 for all large enough t.
(ii) If there exists a constant
γ2 ∈ [2,∞) so that lim supx→0+ σ0(x)/xγ2 < ∞, we have P{ˆτ0 = ∞} = 1 and Xt(1) > 0 for all
t.

Corollary 3.6 If there is a constant γ′ ≥ 0 so that σ(x) = xγ ′
for γ′ < 1 and P{ˆτ0 = ∞} = 1 for γ′ ≥ 1.
Proof. Since σ0(x) = R x

diately.

0 σ(y)dy = xγ ′+1/(γ′ + 1), the assertion follows from Theorem 3.5 imme-

✷

for all x ≥ 0, then P{ˆτ0 < ∞} = 1

We end this section with the proof of Theorem 3.5.

Proof of Theorem 3.5. The assertions for the behavior of the total mass process follows im-
mediately from the end of the proof of Theorem 3.5. We ﬁnish the rest of the proof in the
following.

(i) Fix a ε > 0 small enough so that σ0(x) ≥ b1xγ1 for all 0 ≤ x ≤ √ε and some b1 > 0, let
T ′ := ˆτε1+δ ∧ ˆτε1/2 for δ > 0. By (3.20) one can see that

expn − ˜λXt(1) −

˜λ2
2 hX(1)ito = expn − ˜λXt(1) −

˜λ2

2 Z t

0

σ0(Xs(1))dso

is a continuous local martingale. Then by optional sampling, for µ(1) = ε we have

e−˜λε = En exph − ˜λXT ′(1) −
˜λ2
≤ En exph − ˜λε1+δ −
2

0

˜λ2

2 Z T ′
σ0(Xs(1))dsio
b1εγ1(1+δ) ˆτε1+δi1{ˆτε1+δ <ˆτ

ε1/2 }o + P{ˆτε1+δ > ˆτε1/2}. (3.21)

19

Let ˆτ3,ε := ˆτε1+δ ∧ ˆτε1/2. Then by optional stopping again,

ε = E{Xˆτ3,ε (1)} ≥ EnXˆτ

ε1/2 (1)1{ˆτε1+δ >ˆτ

ε1/2 }o = √εP{ˆτε1+δ > ˆτε1/2},

which implies

P{ˆτε1+δ > ˆτε1/2} ≤ √ε.
Since 0 ≤ γ1 < 2, we can choose 0 < δ < 1/2 so that

γ1(1 + δ) < 2 − 4δ.

Then by (3.21)–(3.23), for ˜λ = ε−1+δ we have

(3.22)

(3.23)

1 − 2εδ ≤ e−˜λ(ε−ε1+δ)

≤ En exp(cid:2) − 2−1˜λ2b1εγ1(1+δ) ˆτε1+δ(cid:3)1{ˆτε1+δ <ˆτ
≤ En exp(cid:2) − 2−1b1ε−2δ ˆτε1+δ(cid:3)o + √εe
≤ P{ˆτε1+δ ≤ εδ} + exp(cid:2) − 2−1b1ε−2δεδ(cid:3)P{ˆτε1+δ > εδ} + √εe
= 1 − P{ˆτε1+δ > εδ} + exp(cid:2) − 2−1b1ε−δ(cid:3)P{ˆτε1+δ > εδ} + √εe

˜λε1+δ

ε1/2 }o + P{ˆτε1+δ > ˆτε1/2}e

˜λε1+δ

˜λε1+δ

˜λε1+δ

.

(3.24)

Solving inequality (3.24) for P{ˆτε1+δ > εδ}, then for small ε,

P{ˆτε1+δ > εδ} ≤

2εδ + √εe˜λε1+δ
1 − exp(cid:2) − 2−1b1ε−δ(cid:3) ≤ 3εδ.

Put xn := ε(1+δ)n

for n ≥ 1. Then by the Markov property of {Xt(1) : t ≥ 0},
n|Xˆτxn (1)} ≤ 3xδ
n,

n|Xˆτxn (1)} = P{ˆτxn+1 ◦ θˆτxn > xδ

P{ˆτxn+1 − ˆτxn > xδ

which implies that

∞

Xn=0

P{ˆτxn+1 − ˆτxn > xδ

n} =

∞

Xn=0

PnP(cid:2)ˆτxn+1 − ˆτxn > xδ

n|Xˆτxn (1)(cid:3)o ≤

∞

Xn=0

3xδ

n < ∞.

Then by Borel-Cantelli lemma we have

It follows from Theorem 3.4 that there are at most ﬁnitely many n so that ˆτxn < ∞ and
ˆτxn+1 − ˆτxn > xδ

n < ∞, then

n=0 xδ

Pn{ˆτxn < ∞} ∩ {ˆτxn+1 − ˆτxn > xδ
n, P-a.s. Since P{ˆτxn < ∞ for all n} = 1 and P∞

n} inﬁnitely ofteno = 0.

∞

∞

ˆτ0 = lim
n→∞

ˆτxn = ˆτx0 +

Xn=0

[ˆτxn+1 − ˆτxn] ≤ ˆτx0 +

Xn=0

xδ
n < ∞, P-a.s.

and we have the desired result for µ with µ(1) = ε. Then the result for general µ follows.

(ii) Given small ε, δ > 0 so that σ0(x) ≤ b2xγ2 for all 0 < x ≤ ε1−δ and some b2 > 0, for any

ﬁnite measure µ on R with µ(1) = ε and T ′′ := ˆτε1+δ ∧ ˆτε1−δ . By Ito’s formula we have
σ0(Xs(1))Xs(1)−3ds.

Xt∧T ′′ (1)−1 = X0(1)−1 −Z t∧T ′′

Xs(1)−2dXs(1) +Z t∧T ′′

0

0

20

Then by integration by parts,

0

Xt∧T ′′ (1)−1 expn −Z t∧T ′′
= X0(1)−1 +Z t
+Z t
= X0(1)−1 −Z t∧T ′′

0

0

0

σ0(Xs(1))Xs(1)−2dso

expn −Z s∧T ′′

0

σ0(Xr(1))Xr(1)−2drod(Xs∧T ′′(1)−1)

Xs∧T ′′(1)−1d(cid:16) expn −Z t∧T ′′

0

σ0(Xs(1))Xs(1)−2dso(cid:17)

Xs(1)−2 expn −Z t∧T ′′

0

σ0(Xs(1))Xs(1)−2dsodXs(1)

is a martingale. Then by optional sampling

ε−1 = EnXt∧T ′′ (1)−1 exph −Z t∧T ′′

0

σ0(Xs(1))Xs(1)−2dsio

≥ EnXt∧ˆτε1+δ (1)−1 exph −Z t∧ˆτε1+δ
≥ EnXt∧ˆτε1+δ (1)−1 exp(cid:2) − b2ε(1−δ)(γ2 −2)ˆτε1+δ(cid:3)1{ˆτε1+δ <ˆτε1−δ }o.

b2Xs(1)γ2−2dsi1{ˆτε1+δ <ˆτε1−δ }o

0

Letting t → ∞ in above inequality we get

which implies

ε−1 ≥ EnXˆτε1+δ (1)−1 exp(cid:2) − b2ε(1−δ)(γ2 −2)ˆτε1+δ(cid:3)1{ˆτε1+δ <ˆτε1−δ }o

= Enε−1−δ exp(cid:2) − b2ε(1−δ)(γ2−2) ˆτε1+δ(cid:3)1{ˆτε1+δ <ˆτε1−δ }o,
En exp(cid:2) − b2ε(1−δ)(γ2−2) ˆτε1+δ(cid:3)1{ˆτε1+δ <ˆτε1−δ }o ≤ εδ.

Applying optional sampling we have

ε = E{XT ′′(1)} ≥ EnXˆτε1−δ (1)1{ˆτε1−δ <ˆτε1+δ }o = ε1−δP{ˆτε1−δ < ˆτε1+δ},
which implies P{ˆτε1−δ < ˆτε1+δ} ≤ εδ. It then follows the Markov inequalty that

(3.25)

P{T ′′ < 1}

≤ P{ˆτε1−δ < ˆτε1+δ} + P{ˆτε1+δ < 1 ∧ ˆτε1−δ}
≤ P{ˆτε1−δ < ˆτε1+δ} + Pn exp(cid:2) − b2ε(1−δ)(γ2 −2) ˆτε1+δ(cid:3)
≤ εδ + exp(cid:2)b2ε(1−δ)(γ2 −2)(cid:3)En exp(cid:2) − b2ε(1−δ)(γ2 −2) ˆτε1+δ(cid:3)1{ˆτε1+δ <1∧ˆτε1−δ }o
≤ εδ + exp(cid:2)b2ε(1−δ)(γ2 −2)(cid:3)εδ ≤ (1 + eb2)εδ,

> exp(cid:2) − b2ε(1−δ)(γ2 −2)(cid:3), ˆτε1+δ < 1 ∧ ˆτε1−δo

where we have used (3.25) for the fourth inequity.

Taking xn = ε(1+δ)n

for n ≥ 1, we have

and repeating the above argument with T ′′ replaced by Tn := ˆτx1+δ

n ∧ ˆτx1−δ

n

P(cid:8)ˆτxn+1 − ˆτxn < 1|Xˆτxn (1)(cid:9) = P(cid:8)ˆτxn+1 ◦ θˆτxn < 1|Xˆτxn (1)(cid:9)

≤ P(cid:8)Tn ◦ θˆτxn < 1|Xˆτxn (1)(cid:9) ≤ (1 + eb2)xδ

n = (1 + eb2)εδ(1+δ)n

.

21

It then follows that

P(cid:8)ˆτxn < ∞, ˆτxn+1 − ˆτxn < 1(cid:9) ≤ P(cid:8)ˆτxn+1 − ˆτxn < 1(cid:9)

≤ PnP(cid:2)ˆτxn+1 − ˆτxn < 1|Xˆτxn (1)(cid:3)o ≤ (1 + eb2)εδ(1+δ)n

.

By the Borel-Cantelli lemma,

Pn{ˆτxn < ∞} ∩ {ˆτxn+1 − ˆτxn < 1}

inﬁnitely ofteno = 0.

It thus follows from Theorem 3.4 that for n large enough, ˆτxn+1 − ˆτxn ≥ 1. We can thus conclude
that P{ˆτ0 = ∞} = 1. Then the desired result follows for any positive measure µ.

✷

4

Interacting Fleming-Viot processes

Let D1(R) be the subset of D(R) consisting of continuous functions f with f (∞) = 1 and
M1(R) the space of probability measures on R equipped with the topology of weak convergence.
Then there is an obvious one-to-one correspondence between D1(R) and M1(R) by associating
a probability measure to its distribution function. We endow D1(R) with the topology induced
by this correspondence from the weak convergence topology on M1(R).

In this section we study the continuous M1(R)-valued solution to the following martingale

problem for interacting Fleming-Viot process {Xt : t ≥ 0}: for any f ∈ C 2(R),

Nt(f ) := Xt(f ) − X0(f ) −

1

2 Z t

0

Xs(f ′′)ds,

t > 0

is a continuous martingale with quadratic variation process

hN (f )it = Z t

0

dsZR

Xs(dx)ZR

(f (y) − f (x))2γ0(Xs, x, y)Xs(dy),

(4.1)

(4.2)

where γ0(µ, x, y) := γ(µ(−∞, x], µ(−∞, y]) for γ ∈ B([0, 1]2)+, µ ∈ M1(R) and x, y ∈ R. If γ is
a positive constant function, then the solution {Xt : t ≥ 0} is the so-called Fleming-Viot process
with constant resampling rate γ and Brownian mutation on type space R; see [6] for details. In
the following two subsections we show that the martingale problem (4.1)–(4.2) is well-posed and
investigate some properties of this process.

4.1 Well-posedness of the martingale problem

The following lemma is on the connection between the martingale problem (4.1)–(4.2) and the
distribution-function-valued SPDE.

Lemma 4.1 A continuous D1(R)-valued process {Yt : t ≥ 0} is the distribution-function process
of the interacting Fleming-Viot process if and only if there is, on an enlarged probability space,
a Gaussian white noise {W (ds, da, db) : s ≥ 0, a, b ∈ [0, 1]} with intensity dsdadb so that
{Yt : t ≥ 0} solves equation
2 Z t

∆Ys(y)ds +Z t

1{a≤Ys(y)≤b}pγ(a, b)W (ds, da, db).

0 Z 1

0 Z 1

Yt(y) = Y0(y) +

(4.3)

1

0

0

22

Theorem 4.2 The martingale problem (4.1)–(4.2) is well posed.

Proof. Let Y0 ∈ D1(R). Take E = [0, 1]2, π =Lebesgue measure on [0, 1]2 and

G(a, b, x) = 1{a≤x≤b}pγ(a, b),

x, a, b ∈ [0, 1].

Then the conditions in Theorem 2.3 hold.
x1, x2 ∈ [0, 1] with x1 ≤ x2,
daZ 1

Z 1

G(a, b, x1)2db ≤ kγkZ x1

0

0

0

daZ 1

x1

db ≤ kγkx1

In fact, it is elementary to check that for each

and

Z 1

0

daZ 1
≤ kγkZ x1

0

0 |G(a, b, x1) − G(a, b, x2)|2db ≤ kγkZ 1

0

daZ 1

daZ x2

x1

db + kγkZ x2

x1

daZ 1

x2

db ≤ kγk[x2 − x1].

0 (cid:12)(cid:12)1{a≤x1≤b} − 1{a≤x2≤b}(cid:12)(cid:12)db

This means that conditions (1.7) and (1.8) hold. It is obvious that G(a, b, 0) = 0 for all a ∈ (0, 1]
and b ∈ [0, 1], which implies that condition (1.6) holds. Therefore, equation (4.3) has a pathwise
unique continuous D(R)-valued solution {Yt : t ≥ 0} with Y0 ∈ D1(R).
Observe that the process { ¯Yt : t ≥ 0}, deﬁned by ¯Yt(x) = 1 for all x ∈ R and t ≥ 0, is a
solution to (4.3) with ¯Y0 = 1. Since Y0 ≤ 1, then by Proposition 2.1(ii), Yt ≤ ¯Yt = 1 P-a.s.,
especially Yt(∞) ≤ 1. Moreover, we known from (2.15) that

E{Yt(∞)} = Y0(∞),

thus Y0(∞) = 1 implies that Yt(∞) = 1 P-a.s.
for each t > 0, which means that (4.3) has a
strong unique continuous D1(R)-valued solution as Y0 ∈ D1(R). Then the assertion follows from
Lemma 4.1 immediately.

✷

Proof of Lemma 4.1. The proof is carried out in two steps.

Step 1. Suppose that {Yt : t ≥ 0} is a solution to (4.3), and {Xt : t ≥ 0} is the corresponding
0 (R), we have Xt(f ) = −hYt, f ′i,

measure-valued process. By integration by parts, for any f ∈ C 3
and so (4.3) yields

1

−Z t

2 Z t
Xt(f ) = −hYt, f ′i −
0 Z 1
0 Z 1
0 hZR
2 Z t
0 Z 1
0 hZR

0 Z 1

+Z t

= X0(f ) +

1

0

0 hYs, f ′′′ids
1{a≤Ys(y)≤b}f ′(y)dyipγ(a, b)W (ds, da, db)

Xs(f ′′)ds

1{a≤Ys(y)≤b}f ′(y)dyipγ(a, b)W (ds, da, db),

which implies that

˜Nt(f ) := Xt(f ) − X0(f ) −

1

2 Z t

0

Xs(f ′′)ds

23

= Z t

0 Z 1

0 Z 1

0

(f (Y −1

s

(b)) − f (Y −1

s

(a)))pγ(a, b)W (ds, da, db)

is a square-integrable continuous martingale with

h ˜N (f )it = Z t

0

dsZR

Xs(dx)ZR

(f (y) − f (x))2γ0(Xs, x, y)Xs(dy),

t

(u) is deﬁned by (3.6). By an approximation argument, one can see the above relation

where Y −1
remains true for any f ∈ C 2(R). Thus, {Xt : t ≥ 0} is an interacting Fleming-Viot process.

Step 2. Suppose that {Xt : t ≥ 0} is an interacting Fleming-Viot process and Yt(x) :=
Xt(−∞, x] for x ∈ R and t ≥ 0. Let S(R) be the Schwartz space and S ′(R) the space of
Schwartz distributions. Let f ∈ S(R) and ¯f (y) = R ∞
2 Z t

Xs(( ¯f )′′)ds + Mt( ¯f )

y f (x)dx. Then

1

hYt, fi = Xt( ¯f ) = X0( ¯f ) +
2 Z t

= hY0, fi +

1

0

0 hYs, f ′′ids + ˆIt( ¯f ),

h ˆI( ¯f )it = Z t

where { ˆIt( ¯f ) : t ≥ 0} ia a martingale with quadratic variation process
( ¯f (y) − ¯f (x))2γ0(Xs, x, y)Xs(dy),
: t ≥ 0} by Nt(f ) = ˆIt( ¯f ) for any f ∈ S(R). Then

Xs(dx)ZR
Deﬁne the S ′(R)-valued process {Nt
{Nt : t ≥ 0} is a square-integrable continuous S ′(R)-valued martingale with

dsZR

t ≥ 0.

0

0

hN (f )it = Z t
= Z t
= Z t

0

0

dsZRZR
dsZ 1
dsZ 1

[ ¯f (y) − ¯f (x)]2γ0(Xs, x, y)Xs(dy)Xs(dx)
daZ 1
(a))]2γ(a, b)db
0 Z 1

(b)) − ¯f (Y −1
1{a≤Ys(y)≤b}f (y)dyi2

dahZR

γ(a, b)db.

[ ¯f (Y −1

0

0

0

s

s

Let f ∈ L2(R) be the subset of B(R) consisting of functions f with hf 2, 1i < ∞ and deﬁne
L2([0, 1]2) similarly. Similar to the martingale representation theorem (see [8, Theorem 3.3.6] or
[5, Theorem III-6]), there exist a L2([0, 1]2)-cylindrical Brownian motion {Bt : t ≥ 0} (possibly
on an extended probability space) so that

hN (f )it = Z t

0 hΦ(s)f, dBsiL2([0,1]2),

where Φ(s) is linear map from L2(R) to L2([0, 1]2) so that for f ∈ L2(R),

(Φ(s)f )(a, b) = pγ(a, b)ZR

1{a≤Ys(y)≤b}f (y)dy.

Let {hj} be a complete orthonormal system of the Hilbert space L2([0, 1]2) and deﬁne random
measure {W (ds, da, db) : s ≥ 0, a, b ∈ [0, 1]} as
h1A, hjiBhj

t ≥ 0, A ∈ B([0, 1]2).

W ([0, t] × A) =

∞

,

t

Xj=1

24

It is easy to show that {W (ds, da, db) : s ≥ 0, a, b ∈ [0, 1]} is a Gaussian white noise with
intensity dsdadb. Furthermore,

Nt(f ) = Z t

0 Z 1

0 Z 1

0 hZR

1{a≤Ys(y)≤b}f (y)dyipγ(a, b)W (ds, da, db),

which obtains the desired result.

✷

4.2 Properties

Theorem 4.3 Suppose that {Xt : t ≥ 0} is the interacting Fleming-Viot process with distribution-
function process {Yt : t ≥ 0} solving (4.3). Then for any f ∈ C 2(R)

Xt(f ) = X0(f ) +

Xs(f ′′)ds

1

2 Z t
0 Z 1

0

0
[f (Y −1

s

0 Z 1
+Z t
and for any f ∈ B(R), P-a.s.,
0 Z 1
0 Z 1
Xt(f ) = X0(Ptf ) +Z t

0

(b)) − f (Y −1

s

(a))]pγ(a, b)W (ds, da, db),

(4.4)

[Pt−sf (Y −1

s

(b)) − Pt−sf (Y −1

s

(a))]pγ(a, b)W (ds, da, db),

(4.5)

where Y −1
absolutely continuous with respect to Lebesgue measure and the density Xt(x) satisﬁes

(u) is deﬁned by (3.6). Moreover, for each t > 0 the random measure Xt(dx) is

t

Xt(x) = ZR

pt(x − y)X0(dy) +Z t

0 Z 1
0 Z 1
0 (cid:2)pt−s(x − Y −1
−pt−s(x − Y −1
(a))(cid:3)pγ(a, b)W (ds, da, db) P-a.s.

(b))

s

s

(4.6)

Proof. The proof is similar to that of Theorem 3.3. By the Step 1 of the proof of Lemma 4.1,
we obtain (4.4). By a similar argument as in the proof of (3.15), we obtain (4.5) from (4.4)
immediately. By conditioning we may assume that X0 is deterministic and X0 = µ ∈ M1(R). It
follows from (4.5) that E{Xt(f )} = µ(Ptf ) for f ∈ B(R). Thus for f ∈ B(R)+,

0

0

f (x)dxZ t

EnZR
≤ 2(2π)− 1
= 2(2π)− 1
≤ kγkZ t

dsZ 1
2kγkEnZR
2kγkEnZR
(t − s)− 1

0

s

0

daZ 1
f (x)dxZ t
f (x)dxZ t

[pt−s(x − Y −1
(t − s)− 1
(t − s)− 1

0

0

s

(a))]2γ(a, b)dbo
(b)) − pt−s(x − Y −1
2 dsZ 1
(a))dao
pt−s(x − Y −1
2 dsZR
pt−s(x − y)Xs(dy)o

0

s

2 E{Xs(Pt−sf )}ds = kγkµ(Ptf )Z t

0

(t − s)− 1

2 ds < ∞.

Now using [10, Theorem 7.24] we obtain

Xt(f ) = ZR

f (x) ˇIt(x)dx,

where ˇIt(x) equals to the right-hand side of (4.6). This gives the desired result.

✷

25

References

[1] Burdzy, K., Mueller, C. and Perkins, E. A. (2010): Nonuniqueness for nonnegative solutions

of parabolic stochastic partial diﬀerential equations. Illinois J. Math. 54, 1481–1507.

[2] Chen, Yu-Ting (2015): Pathwise nonuniqueness for the SPDEs of some super-Brownian

motions with immigration. Ann. Probab. 43, 3359–3467.

[3] Dawson, D. A. and Li, Z. (2012): Stochastic equations, ﬂows and measure-valued processes.

Ann. Probab. 40, 813–857.

[4] Delmasa, J. F. and Dhersin, J. S. (2003): Super-Brownian motion with interactions. Probab.

Theory Related Fields. 107, 301–325.

[5] El Karoui, N. and M´el´eard, S. (1990): Martingale measures and stochastic calculus. Probab.

Theory Related Fields. 84, 83–101.

[6] Fleming, W. H. and Viot, M. (1979): Some measure-valued markov processes in population

genetics theory. Indiana Univ. Math. J. 28, 817–843.

[7] He, H., Li, Z. and Yang, X. (2014): Stochastic equations of super-L´evy processes with

general branching mechanism. Stochastic Process. Appl. 124, 1519–1565.

[8] Kallianpur, G. and Xiong, J. (1995):

Stochastic Diﬀerential Equations in Inﬁnite-
Dimensional Spaces. An extended version of the lectures delivered by Gopinath Kallianpur
as part of the 1993 Barrett Lectures at the University of Tennessee, Knoxville, TN.

[9] Konno, N. and Shiga, T. (1998): Stochastic partial diﬀerential equations for some measure-

valued diﬀusions. Probab. Theory Related Fields. 79, 201–225.

[10] Li, Z. (2011): Measure-valued Branching Markov Processes. Springer, Heidelberg.

[11] M´el´eard, M. and Roelly, S. (1993): Interacting measure branching processes: some bounds

for the support. Stoch. Stoch. Reports. 44, 103–121.

[12] Mitoma, I. (1985): An ∞-dimensional inhomogeneous Langevin equaion. J. Funct. Anal.

61, 342–359.

[13] Mueller, C., Mytnik, L. and Perkins, E. (2014): Nonuniqueness for a parabolic SPDE with

3

4 − ε-H¨older diﬀusion coeﬃcients. Ann. Probab. 42, 2032–2112.

[14] Mytnik L. (2002): Stochastic partial diﬀerential equation driven by stable noise. Probab.

Theory Related Fields. 123, 157–201.

[15] Mytnik, L. and Neuman, E. (2015): Pathwise uniqueness for the stochastic heat equation
with H¨older continuous drift and noise coeﬃcients. Stochastic Process. Appl. 125, 3355–
3372.

[16] Mytnik, L. and Perkins, E. (2011): Pathwise uniqueness for stochastic heat equations with
H¨older continuous coeﬃcients: the white noise case. Probab. Theory Related Fields. 149,
1–96.

[17] Mytnik, L., Perkins, E. and Sturm, A. (2006): On pathwise uniqueness for stochastic heat

equations with non-Lipschitz coeﬃcients. Ann. Probab., 34, 1910–1959.

26

[18] Mytnik, L. and Xiong, J. (2015): Well-posedness of the martingale problem for superprocess

with interaction. Illino. J. Math. To appear.

[19] Neuman, E. (2014): Pathwise uniqueness of the stochastic heat equations with spatially

inhomogeneous white noise. Submitted. arXiv:1403.4491.

[20] Perkins E. A. (2002): Dawson-Watanabe Superprocesses and Measure-Valued Diﬀusions.

Lect. Note Math., Springer-Verlag, 1781, 125–329.

[21] Reimers, M. (1989): One dimensional stochastic diﬀerential equations and the branching

measure diﬀusion. Probab. Theory Related Fields. 81, 319–340.

[22] Rippl, T. and Sturm, A. (2013): New results on pathwise uniqueness for the heat equation

with colored noise. Electron. J. Probab. 18, 1–46.

[23] Xiong, J. (2013): Super-Brownian motion as the unique strong solution to an SPDE. Ann.

Proboa. 41, 1030–1054.

[24] Xiong, J. (2013): Three Classes of Nonlinear Stochastic Partial Diﬀerential Equations.

World Scientiﬁc, Singapore.

[25] Xiong, J. and Yang, X. (2015): Superprocesses with interaction and immigration. Submit-

ted.

Li Wang

School of Sciences, Beijing University of Chemical Technology, Beijing, P.R. China.

Xu Yang

School of Mathematics and Information Science, Beifang University of Nationalities, Yinchuan, P.R.
China.

Xiaowen Zhou

Department of Mathematics and Statistics, Concordia University,1455 de Maisonneuve Blvd. West,
Montreal, Quebec, H3G 1M8, Canada.

E-mails: wangli@mail.buct.edu.cn, xuyang@mail.bnu.edu.cn, xiaowen.zhou@concordia.ca.

27

