6
1
0
2

 
r
a

M
6

 

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
5
7
7
1
0

.

3
0
6
1
:
v
i
X
r
a

Combined Analysis of Amplitude and Phase Variations in Functional Data

Sungwon Leea,∗, Sungkyu Junga

aDepartment of Statistics, University of Pittsburgh, Pittsburgh, PA 15260, U.S.A.

Abstract

When functional data manifest amplitude and phase variations, a commonly-employed framework

for analyzing them is to take away the phase variation through a function alignment so that standard

statistical tools can be applied to the aligned functions. A downside of this approach is that the

important variations contained in the phases are completely ignored. To combine both of amplitude

and phase variations, we propose a principal component analysis (PCA) that aims to capture

a non-linear principal component that simultaneously explains the amplitude, phase and their

associations. The proposed method, which we call functional combined PCA, is aimed to provide

more eﬃcient dimension reduction via interpretable components, when there are some associations

between the amplitude and phase of a functional data set. Our strategy is to combine the aligned

function and the time-warping function used in the alignment, so that a standard PCA can be

used to capture the joint variation among them. A data-adaptive weighting procedure helps our

dimension reduction to attain a maximal explaining power of observed functions. We also discuss an

application of functional canonical correlation analysis in investigation of the correlation structure

between the two variations. We show that for two sets of real data, the proposed method provides

interpretable major non-linear components, which are not typically found in a simple functional

PCA.

Keywords: Functional data; data structure; amplitude variation; phase variation; FPCA; FCCA.

1. Introduction

Functional data [14], observations measured over a continuum and so best described as curves,

are frequently encountered in modern sciences. When functional data consist of repeated mea-

surements of a common activity or development over time, they often show a similar pattern of

progression with two types of major variations, called amplitude and phase variations. When the

∗Corresponding author
Email addresses: sul23@pitt.edu (Sungwon Lee), sungkyu@pitt.edu (Sungkyu Jung)

Preprint submitted to Computational Statistics & Data Analysis

March 8, 2016

phase variation resides in functional data, a na¨ıve application of the functional versions of stan-

dard statistical tools such as the pointwise mean and variance, and functional principal component

analysis (FPCA) tend to yield misleading results [2]. To this end, a curve registration (or func-

tion alignment) has been routinely performed to disregard the phase diﬀerences; cf. [7]. Recently,

several researchers have pointed out that the phase variation also contains important information

about the data [10, 8, 19, 4, 5, 12].

A prominent example where the phase variation is commonly observed is growth curves. In

particular, the growth rate curves of 39 boys from Berkeley growth study [15] share common events

such as pubertal growth spurt and maturity, as shown in Figure 1(a). Visual inspection reveals that

the curves develop those events with varying magnitudes of height, which represents the amplitude

variation, and at varying temporal paces, which stands for the phase variation [1]. Moreover,

these two types of variations are clearly associated to each other; boys who reach the phase of

pubertal growth spurt (corresponding to the main peaks of curves) later in their ages tend to show

smaller maximum pubertal growth rates. This important major association is not captured in the

application of FPCA to the original data or to the aligned data (shown in Figure 1(b) and (c)).

In this paper, we propose a principal component analysis for the original, unregistered data,

combining the two types of variations into one. The principal components (PCs) obtained from the

proposed method, called functional combined principal component analysis (FCPCA), eﬀectively

capture all of the amplitude and phase variations, including their associations. An advantage of

FCPCA is exempliﬁed for the growth data in Figure 1, where the dominant association between

the amplitude and phase variations is well-captured in the ﬁrst combined PC, which is not possible

in applications of a linear PCA to the original data.

To achieve this aim, we assume that the observation f is composed of an amplitude function,

say y, and a time-warping function, say γ, and that the observed functions are well-aligned by

time-warping functions. Our method is developed for a particular class of time-warpings, denoted

by Γ, consisting of orientation-preserving diﬀeomorphisms of the unit interval [0, 1], as used in

[18, 8, 19, 10].

In line with the use of Γ, we demonstrate our PCA method using the function

alignment by utilizing the Fisher-Rao distance as a cost function of the alignment. The Fisher-Rao

distance fFR between two functions is formulated by the square-root velocity function of f , deﬁned

by qf (x) := f (x)/(cid:112)|f(cid:48)(x)|, so that fFR(f, g) = (cid:107)qf − qg(cid:107)2, where (cid:107) · (cid:107)2 is the usual L2 norm. The

cost function used in the alignment of two functions is then inf γ ||qf − qg◦γ||2, which equals to
inf γ ||qf◦γ − gg||2. We refer to Srivastava et al. [18] for a full description of the Fisher-Rao function

2

Figure 1. (a) Berkeley growth velocity curves in [15], boys only. (b) The ﬁrst functional principal component
(PC) of the original data. The black curve stands for the mean, and the red and blue curves show the
functions corresponding to the ±2 standard deviations along the ﬁrst PC. The resulting mode of variation
is not easy to interpret. (c) The ﬁrst functional PC of the aligned data, which contains no information on
the apparent phase variation. (d) The ﬁrst combined PC of the proposed method, applied to the original
data. The non-linear major variation in the data shown in (a) is well-captured by the proposed method.

alignment. Our proposal works with other choices of functional registration methods, as long as the

resulting alignment function is a diﬀeomorphism. See [12] for a detailed discussion on the choices

of function alignment methods, and their connections to decomposition of amplitude and phase

variations.

For the combined analysis of amplitude and phase functions, we further deﬁne a bijection φ

between Γ and a convex subset of the function space. This additional step enables the use of

standard linear functional operations to x := φ(γ), as we discuss in detail in Section 2.2. The

two resulting functions y and x are then joined together, to which a standard functional PCA

is applied. The functions y and x are adaptively weighted so that the resulting combined PCs

achieve the maximal explaining power of the observed functions. The result of the analysis is

represented and visualized in the original function space, which can be used to aid interpretation

of each principal component.

We also demonstrate a use of the functional canonical correlation analysis (FCCA) in the

detection of maximally correlated components in the amplitude and phase functions.

3

In recent years, there have been a few attempts to analyze the phase variations. In particular,

the phase variations are used for segmentation of periodic signals [8], clustering [17], functional

regression [3, 4, 5] and classiﬁcation [19]. In [18, 10, 8, 19], the Fisher-Rao function alignment is

used to obtain the time-warping functions, and the authors suggest several diﬀerent approaches

of analyzing the phase variation through time-warping functions. They, however, did not discuss

the association between two types of variations. Since we use the same alignment procedure as

used in [18, 10, 8, 19], our proposed methods are indebted to these previous work. An analysis

combining the phase and amplitude variations has been reported in [4], in which the authors used a

log transformation for phase functions, in contrast to our use of the transformation φ. Moreover, the

strategy of [4] in combining the two variations is diﬀerent from ours. Speciﬁcally, they use a linear

functional model consisting of individual principal component scores from each of amplitude and

phase functions. In contrast, we directly combine the two functions using data-adaptive weights,

for our purpose of dimension reduction through non-linear principal components.

The rest of this paper is organized as follows. In Section 2, we formally deﬁne a population

structure to model the amplitude, phase and their association, and introduce our two models,

functional combined PCA and CCA. Estimation procedures for the model parameters are discussed

in Section 3. The advantages of the proposed methods are demonstrated in data analyses of the

Berkeley growth [15] and lip motion [13]. Numerical studies for the performance of the proposed

methods are contained in Section 5, followed by a conclusion.

2. Models

2.1. Decomposition into two variations

We consider a smooth random function f that inherently contains amplitude and phase varia-

tions, composed of two random functions y and γ,

f (t) = (y ◦ γ)(t) = y(γ(t)),

t ∈ [0, 1].

(1)

We restrict the domain of f to be [0, 1] without losing generality. The amplitude function y is a
2 < ∞}. The
smooth square-integrable function on [0, 1], i.e., y ∈ L2[0, 1] := {h : [0, 1] (cid:55)→ R | E(cid:107)h(cid:107)2
time-warping function γ is a orientation-preserving diﬀeomorphism on [0, 1], and lies in

Γ = {h : [0, 1] (cid:55)→ [0, 1] | h(0) = 0, h(1) = 1, h(cid:48)(t) > 0 ∀ t ∈ (0, 1)} ⊂ L2[0, 1].

4

Note that the endpoint constraint restricts the warping of f to only occur on the given interval,

and the positive derivative constraint does not allow the warps travel back into the past. For any
γ ∈ Γ, the inverse function γ−1 exists, and is also a member of Γ. This implies that y = f ◦ γ−1.
We assume that the identity function γid(t) = t is the center of the random warping function,

where the center is deﬁned below in Section 2.2. This assumption formally deﬁnes phase variation

as deviation of γ from the identity. Our analysis using the Fisher-Rao function alignment and

the transformation of γ discussed in Section 2.2 is insensitive to diﬀerent choices of the center; cf.

[12]. Finally, we note that Γ is the set of cumulative distribution functions of absolutely continuous

random variables on [0, 1].

2.2. Simplifying the geometry of Γ

Working with γ directly is not desirable due to the non-linearity of the set Γ. To see this,
let γ1, γ2 ∈ Γ and c > 0. Then in general γ1 + γ2 /∈ Γ and cγ /∈ Γ, and, thus, standard vector
operations are not simply used. To address this problem, we adopt the geometric approach laid
out in [18, 10, 19], and introduce a bijection φ : Γ → B, where B is a convex subset of L2[0, 1]
containing 0, so that standard vector operations can be employed.

2.2.1. Mapping to unit sphere

The level of diﬃculty in dealing with γ is eased with taking the square-root velocity function

of γ, by the mapping Θ : Γ → L2[0, 1], given by

Θ(γ) := qγ =(cid:112)γ(cid:48).

(2)

Let S = {h(t) ∈ L2[0, 1] : (cid:107)h(cid:107)2 = 1} be the unit sphere in L2[0, 1]. It can be checked that for any
γ ∈ Γ, qγ lies in the positive orthant of S, denoted by S+. Then, Θ : Γ → S+ is a bijection. A
signiﬁcant beneﬁt of taking this representation is that the complicated structure of Γ is simpliﬁed

to that of the well-known unit sphere.

2.2.2. Mapping to tangent space

While the geometry of S is more tractable than that of Γ, it still is a non-linear manifold, and

the usual vector operations lead unsatisfactory results (see Figure 2(a) for an example). There

are several approaches of statistical procedures for random variables on S; see [11, 6, 19, 10]. Our

approach is a linear approximation of S by the tangent space.

5

Figure 2. Schematic illustration of S and TµS. (a) The pointwise mean µ(cid:48) of two functions a, b ∈ S does not
γ(cid:48) ∈ S to a tangent space TµS by the log map. An example of Sµ is given as a
lie on S. (b) Mapping of
ball in S centered at µ.

√

The tangent space of S at a point µ ∈ S, denoted by TµS, is the collection of functions in

L2[0, 1] orthogonal to µ,

TµS = {h(t) ∈ L2[0, 1] : (cid:104)h, µ(cid:105) = 0},

where (cid:104)·,·(cid:105) is the usual inner product in L2[0, 1]. Functions in S will be approximated by functions
in TµS. Figure 2(b) schematically illustrates TµS and the approximation of the S-valued functions

by functions in TµS. To help understand the tangent space approximation, we take the hyperplane

T in L2[0, 1] tangent to S at µ. The tangent space TµS is obtained by a translation of the hyperplane

T such that the tangent point µ is transformed to the origin; TµS is a subspace in L2[0, 1].

Points (or functions) on the tangent space TµS provide good approximations of functions in a
subset Sµ ⊂ S containing µ. In particular, when the distance between a, b ∈ S is measured by
their great-circle (geodesic) distance, dg(a, b) := arccos((cid:104)a, b(cid:105)), the log map is frequently used for
the approximation. The log map Logµ : Sµ → TµS is deﬁned by

(3)

Logµ(qγ) =

dg(qγ, µ)

sin(dg(qγ, µ))

((cid:112)γ(cid:48) − cos(dg(qγ, µ))µ).

√

The dg(qγ, µ) measures the distance between qγ and µ by the length of the shortest arc on S that
γ(cid:48) and µ. When the standard L2-norm is used for TµS, the geodesic distance between µ and
joins
qγ and the direction in which qγ shoots from µ, for every qγ ∈ S+, are preserved by the log map.

6

A sensible choice of the tangential point µ is given by the assumption that the center of γ is
γid. It can be seen that Θ(γid(t)) = 1 for all t ∈ [0, 1]. Thus we choose the constant function 1 as
µ. We further assume that, for any random warping function γ, logµ(Θ(γ)) ∈ TµS has zero mean,
so that the intrinsic mean of Θ(γ) with respect to the geodesic distance is µ ≡ 1. Therefore we
call γid = Θ−1(1) the center of γ, which is, in general, diﬀerent from the mean of γ.

In short, we transform the time-warping function γ to the phase function x := logµ(Θ(γ)), so
that the standard vector operations can be used. The combined mapping φ = logµ ◦Θ has the
image B ⊂ TµS, which is a convex subset of L2[0, 1]. In what follows, we always assume µ ≡ 1.

2.3. Construction of f by the amplitude and phase functions

Any pair of amplitude and phase functions (y, x) ∈ L2[0, 1] × B can be composed to a single

function, by reverting the decomposition in Sections 2.1 and 2.2.

To deﬁne the composition, we note that the log map is indeed the inverse of the exponential

map, Expµ : TµS → S, deﬁned by

Expµ(x) =

sin(cid:107)x(cid:107)2
(cid:107)x(cid:107)2

x + cos(cid:107)x(cid:107)2µ.

(4)

For any phase function x ∈ B ⊂ TµS, the corresponding time-warping function γ := φ−1(x) =
(Θ−1 ◦ Expµ)(x) can be uniquely constructed, using the following relation:

(cid:90) t

0

(cid:90) t

(cid:104)(cid:112)γ(cid:48)(s)

(cid:105)2

(cid:90) t

0

0

Exp2

µ(x)(s)ds =

ds =

γ(cid:48)(s)ds = γ(t) − γ(0) = γ(t), t ∈ [0, 1].

For any random functions (y, x) ∈ L2[0, 1] × B, we construct a random function f in the form of
(1) by

f (t) = (y ◦ γ)(t) = (y ◦ φ−1(x))(t) = y

Exp2

µ(x)(s)ds

, t ∈ [0, 1].

(5)

(cid:19)

(cid:18)(cid:90) t

0

2.4. Models for joint variability of amplitude and phase functions

In this subsection, we deﬁne the joint population structures of the amplitude and phase functions

(y, x), of which our methods aim to provide the estimates. By construction, we have E(x) = 0, so

that the mean of x corresponds to the identity time-warping γid.

7

2.4.1. Model for functional combined principal components

To model the association between y and x, we deﬁne a random function gC on the extended

domain [0, 2] for a C > 0,

gC(t) =

y(t),

Cx(t − 1),

t ∈ [0, 1),
t ∈ [1, 2].

(6)

The exclusion of the end point {1} of the domain [0, 1] of y in the contruction of gC does not lose any
information since y is assumed to be continuous. Note that for any y, x, C, we have gC ∈ L2[0, 2].
The parameter C is introduced to adjust scaling imbalance between y and x. We will discuss the

role of C shortly, but for now we let C be ﬁxed.

For a given C, we denote the eigen-decomposition of the covariance function ΣgC of gC by

ΣgC (s, t) =

λC
i ξC

i (s)ξC

i (t),

s, t ∈ [0, 2],

∞(cid:88)

i=0

i ’s denote eigenvalues of ΣgC with λC

where λC
i ’s are the corresponding
j (cid:105) = 0 for i (cid:54)= j. The superscript C is used to emphasize
eigenfunctions with (cid:107)ξC
the dependence of the decomposition on C. Then by the Karhunen-Lo´eve decomposition, gC(t) =

i (cid:107)2 = 1 and (cid:104)ξC

i , ξC

1 ≥ λC

2 ≥ ··· ≥ 0, and ξC

i (t), t ∈ [0, 2], where zC

i=1 zC
i )2) = λC

i ξC
i ’s are uncorrelated mean-zero random variables with
i . Note that the mean function µ = E(gC) does not depend on C since y is irrelevant

E((zC

µ(t) +(cid:80)∞

of C and E(x) = 0. The function gC is then divided into the amplitude and phase functions as

∞(cid:88)

∞(cid:88)

i=1

yC(t) = µ(t) +

zC
i ξC

i (t),

t ∈ [0, 1),

xC(t) =

i=1

zC
i
C

ξC
i (t + 1),

t ∈ [0, 1].

(7)

In (7), the joint variation between y and x is paired in eigenfunctions ξC
i .

The role of the scaling parameter C in (6) becomes clear from (7). As opposed to the unit-

free x, values of y depend on the unit in which measurements of y (or f ) are made. The overall

analysis should not depend on the particular scaling of y (due to, for example, change of units).
Since scaling of y by C is equivalent to scaling x by C−1, we introduce the scaling parameter C
applied only to the “x part” of gC, in order to keep the original unit of y. The eigenfunctions
{ξC
i }∞
few eigenfunctions ξC

i=1 may vary for diﬀerent choices of C; for a small C, the ﬁrst

i are bound to capture more variations from the amplitude variation, while

i=1 and their eigenvalues {λC

i }∞

8

for a large C, the leading eigenfunctions reﬂect more phase variations. For any given f , or the pair
(y, x), there exists a continuum of diﬀerent sets {ξC
i=1, depending on the value of C ∈ (0,∞),
which causes an identiﬁability issue. To our aim of succinctly representing the combined variation

i }∞

of y and x in the original function space, we choose C to be dependent on the original random

function f as discussed below.

Let m be a positive integer. From (5) and (7), for a given C > 0, we deﬁne AC

m(f ) as a projection

of f onto the m-dimensional eigen-space, spanned by the ﬁrst m eigenfunctions, by

(cid:18)(cid:90) t

0

(cid:19)

Exp2

µ(xC

m)(s)ds

t ∈ [0, 1),

,

AC

m(f )(t) = yC
m

where for t ∈ [0, 1),

m(cid:88)

i=1

zC
i ξC

i (t),

yC
m(f )(t) = µ(t) +

m(cid:88)

i=1

xC
m(f )(t) =

zC
i
C

ξC
i (t + 1).

(8)

(9)

This projection utilizes the standard orthogonal projection of gC to its eigen-space in L2[0, 2], but
is non-linear in the original function space L2[0, 1]. To minimize the approximation error of AC

m(f )

with respect to f , the scaling parameter C := Cm is chosen as follows:

C = argminC∈RE(d2(AC

m(f ), AC∞(f ))) = argminC∈RE(d2(AC

m(f ), f )),

(10)

where d is a distance function on L2[0, 1]. We use d(f, g) = (cid:107)f − g(cid:107)2 for fast computation and
mathematical convenience, but other choices for d, including the Fisher-Rao distance [18], L1-

distance and the earth mover’s distance [16] can be used.

To visualize the combined eﬀect of y and x for a chosen C, as decomposed in (7), each eigen-

(cid:113)
i = ±c

mode can be represented in the original function space. In particular, the ith mode of variation of
f can be visualized by overlaying the curves of ˜fi,c := ˜yi,c ◦ φ−1(˜xi,c), where ˜yi,c and ˜xi,c are given
j = 0 for all j (cid:54)= i in (7). Figure 1(d) shows empirical
by setting zC
estimates of ˜f1,c, c = −1, 0, 1, for the growth data. The estimation procedure is discussed in Section
3.

for c ∈ R and zC

λC
i

9

2.4.2. Model for correlation analysis

As another approach to model the joint variation between y and x, we brieﬂy discuss a model

called functional combined canonical correlation analysis (CCA).

Let ψy, ψx ∈ L2[0, 1] and let ρ(ψy, ψx) be the correlation coeﬃcient between (cid:104)ψy, y(cid:105) and (cid:104)ψx, x(cid:105).
In functional combined CCA, the association between the amplitude (y) and the phase (x) functions

is modeled by seeking the canonical weight function pair (ψy, ψx) that maximizes ρ(ψy, ψx). In

general, the ith canonical weight function pair (ψy,i, ψx,i) maximizes ρ(ψy,i, ψx,i), with the constraint
that Cov((cid:104)ψy,i, y(cid:105),(cid:104)ψy,j, y(cid:105)) = Cov((cid:104)ψx,i, x(cid:105),(cid:104)ψx,j, x(cid:105)) = 0 for 1 ≤ j < i. The correlation coeﬃcient
ρi := ρ(ψy,i, ψx,i) is called the ith canonical correlation coeﬃcient.

The joint variation modeled by the ith canonical weight functions ψy,i and ψx,i can be visualized

in the original function space. For a, b ∈ R, let

Py,(i,a)(t) = µ(t) + aψy,i,

t ∈ [0, 1],

Px,(i,b)(t) = bψx,i,

t ∈ [0, 1].

(11)

Then the ith mode of variation given by the functional combined CCA is visualized by overlaying
the curves of ˜fi,a,b := Py,(i,a) ◦ φ−1(Px,(i,b)) for various values of (a, b). A reasonable choice of (a, b)
satisﬁes a/b = β, where β is the slope from the regression of (cid:104)ψxi, x(cid:105) against (cid:104)ψyi, y(cid:105)

3. Estimation

In this section we discuss our procedures for the application of functional combined PCA and

CCA to a data set.

3.1. Decomposition into amplitude and phase functions

Let fi, i = 1, 2, .., n, be the ith realization of an underlying random function f from n inde-

pendent experiments. The realizations fi’s do not manifest themselves in a direct way. They are

usually recorded at discrete time points and sometimes blurred with measurement errors. We as-
sume that smoothing the observations {fij}ni
approximation of fi. Denote the approximations to {fi}n

j=1 with a suitable basis function system gives a close

i=1 by { ˆfi}n

i=1.

Each ˆfi is decomposed into the amplitude and phase functions by an application of function

alignment to { ˆfi}n

i=1. We choose to use the Fisher-Rao function alignment [18] for its good perfor-

10

mance [8, 12]. This gives (ˆyi, ˆγi), satisfying

ˆfi(t) = ˆyi(ˆγi(t)), i = 1, 2, .., n, t ∈ [0, 1].

(12)

Let ˆxi = φ(ˆγi). As explained in Section 2, (ˆyi, ˆxi) is the observed pair of the amplitude and phase

functions.

3.2. Functional combined PCA

In the model for the functional combined PCA (FCPCA), the population eigen-structure de-

pends on the unknown parameter C. We ﬁrst discuss the empirical eigen-decomposition for any

given C, and then present the procedure to obtain a data-adaptive estimate of C.

3.2.1. Estimation of (µ, λC

i , ξC
i )

Let the scaling parameter C be given. For easy computation, we evaluate the functions ˆyi and
ˆxi on a ﬁne grid, 0 = t1 < t2 < ··· < tk = 1, to obtain their vector expressions ˆyi and ˆxi. For each
pair, let

ˆgC
i =

 , ˆyi = [ˆyi(t1) . . . ˆyi(tk)]T , ˆxi = [ˆxi(t1) . . . ˆxi(tk)]T ,

 ˆyi
i /n. The eigen-decomposition of the sample covariance matrix (cid:98)ΣgC obtained from

C ˆxi

and ˆµ =(cid:80)n

i=1 ˆgC

{ˆgC

i }n

i=1 provides (n − 1) pairs of eigenvalues and eigenvectors (ˆλC

i , ˆξ

n(cid:88)

(cid:98)ΣgC =

n−1(cid:88)

C
i ),

(cid:17)T

,

(cid:16)ˆξ

C
i

i − ˆµ][ˆgi − ˆµ]T =
[ˆgC

ˆλC
i

ˆξ

C
i

i=1

i=1

where ˆλC

1 ≥ ˆλC

2 ≥ ··· ≥ ˆλC

n−1 ≥ 0, (cid:107)ˆξ

C

i (cid:107)2 = 1 and (cid:104)ˆξ

C
i , ˆξ

C

j (cid:105) = 0 for i (cid:54)= j. Estimates ˆµ of µ and ˆξC

i

of ξC

i are obtained by interpolation of the elements of ˆµ and ˆξ

C
i .

3.2.2. Estimation of C
The estimates {(ˆλC

i , ˆξC

i )}n−1

i=1 are dependent on the value of C. We emphasize that the true
parameter C depends on the number of principal components, m, used in the approximation of

(10). For the purpose of exploratory analysis and visualization of the data, m is typically chosen as

a small number. For a given m, our strategy in the estimation of C is to use an empirical minimizer
m( ˆfi) for

j (cid:105) be the jth score of the ith observation. We write AC

of (10). For this, let aC

ij = (cid:104)ˆgC

i , ˆξC

11

an approximation of the ith observation ˆfi by the ﬁrst m empirical principal components, which is
deﬁned by (8), by replacing yC

m and xC

m with

m( ˆfi)(t) =
ˆxC

m( ˆfi)(t) = ˆµ(t) +
ˆyC

j (t), t ∈ [0, 1),
ˆξC

aC
ij

m(cid:88)

j=1

m(cid:88)

j=1

aC
ij
C

j (t + 1), t ∈ [0, 1].
ˆξC
n(cid:88)

m( ˆfi) − ˆfi(cid:107)2

(cid:107) ˆAC

2

.

C>0

i=1

n

Our choice of ˆC is then

ˆC = argmin

(13)

In other words, the ﬁrst m combined principal components ˆξ ˆC
i

found at C = ˆC reconstruct { ˆfi}n
most faithfully, compared to other values of C. In practice, we use a numerical method to solve

i=1

(13), which is almost instantaneous for small values of m.

In all of our numerical studies, the minimizer ˆC always exists, and does not degenerate to 0 or ∞.
Heuristically, this is because we assume the observation has both amplitude and phase variations.
Large (or small) values of C force the eigenfunctions ˆξC
to explain only the phase variation (or
i
amplitude variation, respectively). For large C, the amplitude variation of ˆfi is typically not found
in ˆAC

m( ˆfi); for small C, the two functions ˆfi and ˆAC

m( ˆfi) exhibit diﬀerent phases.

3.3. Functional combined CCA

In functional combined CCA of the data {fi : i = 1, . . . , n}, we again use the decomposed
functions (ˆyi, ˆxi), obtained in Section 3.1, to compute estimates of the triple (ρj, ψy,j, ψx,j) as

deﬁned in Section 2.4.2.

It is well know that a na¨ıve adaptation of multivariate CCA to functional data often leads to

spurious estimates of the triple with the estimated canonical correlation coeﬃcient close to one.

Following the suggestions in [9], we use the regularized functional CCA as follows. For a given

smoothing parameter λ > 0, the estimates of the canonical weight functions are

( ˆψy,1, ˆψx,1) =

max

ψy,ψx∈L2[0,1]

(cid:100)Cov((cid:104)ψy, ˆyi(cid:105),(cid:104)ψx, ˆxi(cid:105))

subject to (cid:100)Var((cid:104)ψy, ˆyi(cid:105)) + λ(cid:107)D2ψy(cid:107)2

2 = (cid:100)Var((cid:104)ψx, ˆxi(cid:105)) + λ(cid:107)D2ψy(cid:107)2

2 = 1, where (cid:100)Cov and (cid:100)Var de-

note sample covariance and variance and D2 is the second order diﬀerential operator. Subse-
quent pairs ( ˆψy,j, ˆψx,j) are obtained similarly with the additional orthogonality constraint. The ith

12

(14)

empirical canonical correlation coeﬃcient ˆρi is the sample correlation coeﬃcient, computed from
((cid:104)ψy,1, ˆyi(cid:105),(cid:104)ψx,1, ˆxi(cid:105)). We refer to [14] for the detailed procedure and the choice of λ by a generalized
cross-validation.

4. Combined analysis of amplitude and phase variations in real data sets

In this section, we illustrate an application of the proposed methods to two sets of real data.

4.1. Berkeley growth data

The Berkeley growth data set [15] consists of the height measurements of 39 boys and 54 girls

from age 1 to 18. We present here the results of our analysis for the boy-only data. The analysis

for girls’ growth leads to a similar conclusion. To highlight periods of slower and faster growths,

we use the growth velocity curves, by taking derivatives of the smoothed growth curves. These are

shown in Figure 3(a).

We have applied the functional combined PCA (FCPCA), and obtained an interesting result. In

particular, the ﬁrst two combined principal components (PCs) well explain the association between

the growth velocities (amplitude variation) and temporal paces (phase variations).

The mode of variation captured in the ﬁrst combined PC, explaining 65% of the total variability,

explains the pattern that boys with higher overall growth rates tends to have fast temporal paces

(e.g., reaching their pubertal growth spurt earlier than others).

In Figure 3(b), the blue curve

explains this patten. On the other hand, boys with lower growth rate tend to have slow paces,

as shown in the ﬁgure by the red curve. The second combined PC captures a contrast, which is

characterized by the growths before and after 10 years old. Speciﬁcally, the second PC captures the

variability regarding a growth pattern that the growth rate and pace are positively associated for

growths in ages 0-10, and negatively associated for growths in ages 10-18. The mode of variation

in the second combined PC is visualized in Figure 3(c). As mentioned earlier, the FCPCA aims

to simultaneously capture the amplitude, phase and their association. The interpretable modes of

variation shown in Figure 3(b)-(c) are not typically found in applications of functional PCA; see

Figure 1.

An application of our functional combined CCA to the data set reveals a diﬀerence between

our proposed methods. The reconstructed functions from the most correlated component in the

amplitude and phase variations, with ˆρ1 = 0.82, are shown in Figure 3(d). These are visually

diﬀerent from either of the two combined PCs shown in Figure 3(b)-(c). To interpret, we see that

13

Figure 3. (a) Smoothed growth velocity curves of 39 boys. (b) Three functions describing the ﬁrst mode of
variation from FCPCA. (c) Three functions describing the second mode of variation from FCPCA. (d) Three
functions describing a combined eﬀect of the most correlated directions from functional combined CCA.

early temporal paces are correlated with lower growth rates before age 10 and with higher growth

rates afterwards. The diﬀerences in patterns found by functional combined PCA and CCA should

not be surprising. The internal variations within each of amplitude and phase functions aﬀect the

combined PCA, while, in CCA, they are simply ignored.

4.2. Lip motion data

The data set we analyze here is a part of lip motion data used in [13]. The data set is composed

of measurements at 51 equally-spaced points in the timeframe from 0 to 340 milliseconds of a

vertical position of lower lip while the subject speaks a syllable “bob” 20 times. The dynamics of

lip motion is well captured by its acceleration. These second derivatives plotted in Figure 4(a) show

a common pattern. Lip movement is ﬁrst accelerated negatively and then pass through a positive

acceleration phase during which the descent of the lower lip is stopped. This lip opening phase is

followed by a short period of near zero acceleration when pronunciation of the vowel “o” is at its

full force, followed by another strong acceleration upward initiating lip closure. The movement is

completed by a negative acceleration episode as the lip returns to the closed position [13].

By an application of FCPCA, we found that the ﬁrst combined PC explains a large portion

(78%) of the total variation. The ﬁrst mode of variation, shown in Figure 4(b), explains a speech

14

Figure 4. (a) 20 acceleration curves of lip movement. (b) Three functions describing a ﬁrst mode of variation
from FCPCA. (c) Three functions describing a combined eﬀect of the most correlated directions from the
functional combined CCA, with ˆρ = 0.79.

habit of the speaker; as he makes the sound of the word louder (or softer), he tends to speak

faster (or slower, respectively). For this data set, the ﬁndings from the function combined CCA

are similar to those of FCPCA.

5. Numerical studies

5.1. Eﬃciency of functional combined PCA under non-linear associations

The success of the proposed methods depends on the existence and the type of the association

between the amplitude and phase variations.

If there is no association, then our approach of

detecting the joint variation makes little sense. Moreover, our methods are well-suited for a linear

dependency between the amplitude and phase functions. To elaborate this point, we present a toy

data analysis.

Three sets of data are prepared by sampling from the amplitude and phase function pair (y, x).

We have set each of y and x has one major principal component, and the association between the

PC score of y and that of x is either linear, near-linear or severely non-linear (quadratic). The
three sets of data are obtained by the function composition, f = y ◦ φ−1(x), and displayed in the
ﬁrst row of Figure 5. The types of association, or the degrees of non-linearity, are illustrated in

the scatters of the two individual PC scores, shown in the second row of Figure 5. Apparently, our

functional combined PCA works well for the ﬁrst data set, where the association between y and x

is linear.

To investigate the sensitivity of our method to the degrees of non-linearity, we evaluate for
each data set the approximation error using only the ﬁrst m components, as a function of m ≥ 1,

15

computed by n−1(cid:80)n

i=1 (cid:107) ˆA ˆC

m( ˆfi) − ˆfi(cid:107)2

Figure 5. Reconstruction errors of functional combined PCA, FPCA and the separate method. The asso-
ciation between the amplitude and phase variations is linear (in the left column), near-linear (middle) and
severely non-linear (right).

2. These errors are compared with errors from other natural

competitors: the usual functional PCA (FPCA) and a composite functional PCA that we call a

“separate” method. The FPCA is applied to the original data (without applying function align-

ment), and the ﬁrst m components are used to approximate the observations.

In the separate

method, functional PCA is applied to each individual functions (y and x), and the ﬁrst m compo-

nents from both y and x are used to approximate the observations. For each of these methods, the

corresponding approximation errors are shown in the last row of Figure 5.

Note that our deﬁnition of one-dimensional “linear” association, as shown in the ﬁrst column

of Figure 5, typically results in a one-dimensional non-linear mode of variation in the original

function space. This non-linear variation is not completely captured in a single component of

FPCA, and oftentimes needs multiple components. As shown in the ﬁrst column of the ﬁgure, our

method eﬃciently captures the linear association and shows the smallest approximation error when

16

a small number of components is used. For this type of association, the usual FPCA needs several

components to capture the non-linear variation in the original space, and is less favorable. The

separate method, on the other hand, uses 2m linear components (compared to only m components

in the other two methods), thus is expected to show better performances than FPCA in general.

Note that our functional combined PCA has smaller errors than the separate method has for this

data set.

As the degrees of non-linearity intensify, the advantage of the functional combined PCA gradu-

ally lessens. For the severely non-linear case (shown in the third column of the ﬁgure), our method

fails to capture the non-linear mode of variation in one component. However, it performs better or

comparable to other methods when more than one component is used, i.e. for m > 1.

5.2. Performance of estimation in functional combined PCA

In this and next subsections, we exhibit good performances of our estimation procedures. The

success of our methods is largely dependent upon the quality of the alignment. The Fisher-Rao

function alignment we choose to use has been shown to work well in practice [8], but its theoretical

results (for e.g. consistency in the estimation of µ) are limited [18]. Instead, we use simulated data

sets to glimpse the consistency of the estimators. We have tried a range of parameter settings, and

i (t) = µ(t)+(cid:80)4

j=1 zij

(cid:112)λjξj(t),

the results are concordant across settings. Below we present representative cases.

As a representative model, we use a four-component model for (6), gC

t ∈ [0, 2]. The corresponding function f is then obtained by the function composition in equations
(5) and (7). We set C = 1, (λ1, . . . , λ4) = (3.5, 2.6, 0.3, 0.1), and set the mean function µ and

the eigenfunctions ξj as shown in Figure 6. The scores zij are sampled from the standard normal

distribution. These parameters are carefully chosen, by a numerical method, so that C = 1 satisﬁes

(10) for m = 2. Recall from Section 2.4.1 that the eigen-pairs (λC

j , ξC

j ) are dependant on the value

of C. For C = 1, we have λC

j = λj and ξC

j = ξj for j = 1, . . . , 4. The random function fi is observed

at a dense grid with a measurement error independently drawn from N (0, 0.1).

For sample sizes n = 30, 100, we generated f1, . . . , fn from the model described above and

obtained the estimates ( ˆC, ˆµ, ˆλ ˆC

1 , ˆξ ˆC

1 , ˆλ ˆC

2 , ˆξ ˆC

2 ), from our procedure discussed in Section 3.2. This is

repeated 100 times to witness the sampling distributions of the estimators. The result is summarized

in Table 1. We empirically observed that the estimators approach their population counterparts as

the sample size increases.

17

Figure 6. Parameters ξ1, ξ2, ξ3, ξ4 and µ

.

ˆC (C = 1)

ˆλ ˆC
1 (λ1 = 3.5)
ˆλ ˆC
2 (λ2 = 2.6)
(cid:107)µ − ˆµ(cid:107)2
1 (cid:107)2
(cid:107)ξ1 − ˆξ ˆC
(cid:107)ξ1 − ˆξ ˆC
2 (cid:107)2

n = 30

n = 100

1.44 (0.31)

1.28 (0.29)

4.12 (0.26)

3.81 (0.21)

2.98 (0.37)

2.74 (0.18)

2.89 (1.27)

2.15 (0.85)

0.49 (0.24)

0.38 (0.36)

0.71 (0.41)

0.34 (0.50)

Table 1. Simulation results for functional combined PCA. The mean and standard deviation (in parentheses)
of scalar estimates and L2-distances of functional estimates to their parameter counterparts are shown for
diﬀerent sample sizes.

5.3. Performance of estimation in functional combined CCA

For a model for the functional combined CCA, the amplitude and phase functions are each

modeled using four principal components, where yi(t) = µy(t) +(cid:80)4
(cid:80)4

(cid:112)λy,iξy,i(t), xi(t) =
(cid:112)λx,iξx,j(t), t ∈ [0, 1], so that the corresponding function f is obtained by the function

i=1 ui

j=1 vj

composition (5). We set µy as the same as µ in Figure 5, restricted to domain [0, 1], and set

ξy,i, ξx,j as shown in Figure 7. We choose to model only one canonical weight function pair by

setting (ψy,1, ψx,1) := (ξy,1, ξx,2) with the canonical correlation coeﬃcient 0.8. The variances of

individual principal components are set to be λy,i = 5, 3.5, 0.8, 0.7 for i = 1, . . . , 4, respectively,

and 100λx,i = 1, 0.7, 0.16, 0.14 for i = 1, . . . , 4 respectively. The scores (ui, vj) are independently

sampled from N (0, 1), except that Cov(u1, v2) = 0.8. The random function fi is observed at a

18

Figure 7. Parameter settings for {ξy,i}4
weight functions with canonical correlation coeﬃcient ρ = 0.8.

i=1 and {ξx,i}4

i=1, where ξy,1 and ξx,2 are also used for the canonical

n = 30

n = 100

ˆρ1 (ρ1 = 0.8)
(cid:107)ψy,1 − ˆψy,1(cid:107)2
(cid:107)ψx,1 − ˆψx,1(cid:107)2

0.68 (0.21)

0.72 (0.19)

0.89 (0.31)

0.43 (0.18)

0.72 (0.28)

0.55 (0.15)

Table 2. Simulation results for functional combined CCA. The mean and standard deviation (in parentheses)
of ˆρ and L2-distances of functional estimates to their parameter counterparts are shown for diﬀerent sample
sizes.

dense grid with a measurement error drawn from N (0, 0.1).

We obtained the empirical sampling distributions of the estimators (ˆρ1, ˆψy,1, ˆψx,1), for sam-

ple sizes n = 30, 100 with 100 repetitions. The results, summarized in Table 2, suggest a good

performance of our estimation procedure. Note that we have used the generalized cross valida-

tion to choose the smoothing parameter of functional CCA following [14]. Diﬀerent choices of the

smoothing parameter may impact our analysis, which is beyond the scope of this work.

6. Conclusion

This paper presents a novel framework for exploring the combined structure of amplitude and

phase variations in functional data. Na¨ıve application of standard statistical tools such as the

functional PCA to this type of data sometimes produces unsatisfactory results. The commonly-

19

employed framework of statistical analysis of aligned functions by the use of function alignment

disregards the relevant phase variation. To overcome the disadvantages, we propose functional

combined PCA and CCA to investigate major modes of variation and correlated directions of data

in the underlying space, in which the association between amplitude and phase variations can be

addressed. The analysis results are visually presented in the original form of observed functions to

aid interpretation.

References

References

[1] Gasser, T., K¨ohler, W., M¨uller, H.-G., Kneip, A., Largo, R., Molinari, L., Prader, A., 1984.

Velocity and acceleration of height growth using kernel estimation. Annals of Human Biology

11 (5), 397–411.

[2] Gasser, T., M¨uller, H.-G., K¨ohler, W., Molinari, L., Prader, A., 1984. Nonparametric regression

analysis of growth curves. The Annals of Statistics 12 (1), 210–229.

[3] Gervini, D., 2015. Warped functional regression. Biometrika 102 (1), 1–14.

[4] Hadjipantelis, P., Aston, J., M¨uller, H.-G., Evans, J., 2015. Unifying amplitude and phase

analysis: A compositional data approach to functional multivariate mixed-eﬀects modeling of

mandarin chinese. Journal of the American Statistical Association 110 (510), 545–559.

[5] Hadjipantelis, P., Aston, J., M¨uller, H.-G., Moriarty, J., 2014. Analysis of spike train data: A

multivariate mixed eﬀects model for phase and amplitude. Electronic Journal of Statistics 8,

1797–1807.

[6] Jung, S., Dryden, I. L., Marron, J. S., 2012. Analysis of Principal Nested Spheres. Biometrika

99 (3), 551–568.

[7] Kneip, A., Ramsay, J., 2008. Combining registration and ﬁtting for functional models. Journal

of the American Statistical Association 103 (483), 1155–1165.

[8] Kurtek, S., Wu, W., Christensen, G., Srivastava, A., 2013. Segmentation, alignment and

statistical analysis of biosignals with application to disease classiﬁcation. Journal of Applied

Statistics 40 (6), 1270–1288.

20

[9] Leurgans, S., Moyeed, R., Silverman, B., 1993. Canonical correlation analysis when the data

are curves. Journal of the Royal Statistical Society 55 (3), 725–740.

[10] Lu, X., Marron, J., 2013. Principal nested spheres for time warped functional data analysis.

arXiv.

[11] Mardia, K. V., Jupp, P. E., 2000. Directional Statistics. Vol. 28 of Wiley series in probability

and statistics. Wiley.

[12] Marron, J., Ramsay, J., Sangalli, L., Srivastava, A., 2015. Functional data analysis of amplitude

and phase variation. MOX-Report No.27/2015.

[13] Ramsay, J., K.G. Munhall, V. G., Ostry, D., 1996. Functional data analyses of lip motion.

Acoustical Society of America 99 (6), 3718–3727.

[14] Ramsay, J., Silverman, B., 2005. Functional Data Analysis, 2nd Edition. Springer.

[15] R.D.Tuddenham, Snyder, M., 1954. Physical growth of california boys and girls from birth to

eighteen years. Univ. of Calif. Publications in Child Development 1 (2), 183–364.

[16] Rubner, Y., Tomasi, C., Guibas, L., 1998. A metric for distributions with applications to image

databases. Proceedings of the 1998 IEEE International Conference on Computer Vision.

[17] Sangalli, L., Secchi, P., Vantini, S., Vitelli, V., 2010. K-mean alignment for curve clustering.

Computational Statistics and Data Analysis 54 (5), 1219–1233.

[18] Srivastava, A., Wu, W., Kurtek, S., Klassen, E., Marron, J., 2011. Registration of functional

data using ﬁsher-rao metric. arXiv.

[19] Tucker, J., Wu, W., Srivastava, A., 2013. Generative models for functional data using phase

and amplitude separation. Computational Statistics and Data Analysis 60, 50–66.

21

