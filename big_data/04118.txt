6
1
0
2

 
r
a

 

M
4
1

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
8
1
1
4
0

.

3
0
6
1
:
v
i
X
r
a

Bandit Approaches to Preference Learning Problems with Multiple

Populations

Aniruddha Bhargava∗, Ravi Sastry Ganti†, and Robert Nowak‡

University of Wisconsin, Madison WI

March 15, 2016

Abstract

In this paper we study an extension of the stochastic multi-armed bandit (MAB) framework, where in each round
a player can play multiple actions and receive a stochastic reward which depends on the actions played. This problem
is motivated by applications in recommendation problems where there are multiple populations of users and hence
no single choice might be good for the entire population. We speciﬁcally look at bandit problems where we are
allowed to make two choices in each round. We provide algorithms for this problem in both the noiseless and noisy
case. Our algorithms are computationally efﬁcient and have provable sample complexity guarantees. In the process
of establishing sample complexity guarantees for our algorithms, we establish new results regarding the Nystr¨om
method which can be of independent interest. We supplement our theoretical results with experimental comparisons.

1 Introduction

In this work, we are interested in multi-armed bandit games, where the user is allowed to play multiple arms simul-
taneously in each round. The user then observes a scalar reward that is some known function of the rewards of each
of the arms. We are interested in discovering a near optimal set of arms by repeated game playing. This framework
is motivated by problems in preference modeling, where we have multiple sub-populations of users, with users from
the same sub-population having similar preferences for the different items. For example, consider the situation where
there are two sub-populations, one of vegetarians and the other of non-vegetarians, and we are tasked with recom-
mending a pair of items from a menu. Assuming that we do not know the identity of the incoming customer, and we
are allowed to recommend two items at a time, a seemingly good strategy would be to recommend a popular vegetarian
item and a popular non-vegetarian item. While, in the above example it might be easy to obtain information if the
customer is vegetarian or not, by simply asking them, obtaining such contextual information may be very expensive
in many cases. For example, for ads posted at a bus stop or items that are available in a section of a super market
[Rosenbloom, 2010], [Gopalaratnam, 2015], it is possible to put cameras to count how many people looked at them.
But we cannot change the ads very often. Indeed, to get more data, we may only be able to try different combination
of ads at different locations. This also means that we have little information about the person themselves.

Preference modeling problems such as the one described above and more are ubiquitous and show up in in-
ternet advertising [Babaioff et al., 2009, Devanur and Kakade, 2009], econometrics [Hensher et al., 1998], market-
ing [Louviere and Woodworth, 1983], clinical trials [Kuleshov and Precup, 2014]. In this paper we propose two games
that model the problem of preference modeling as multi-armed bandit (MAB) problems. For these games we provide
computationally efﬁcient algorithms.

Contributions: Our contributions in this paper are as follows

∗aniruddha@wisc.edu
†gmravi2003@gmail.com
‡nowak@ece.wisc.edu

The ﬁrst two authors made equal contributions to the paper.

1

1. We introduce two games for preference modeling problem, when there are r populations and K items. In each
game the player gets to play a pair of arms, and the player gets a reward which is a function of the pair of
arms played. This reward is large if either of the arms in the chosen pair is “good”. For both the games we
are interested in ﬁnding a near-optimal pair of arms, using as few trials as possible. The difference between the
games is whether the reward is stochastic or deterministic.

2. The core idea behind the proposed algorithms for both the games is that we have to ﬁnd a near-smallest element
of a certain low-rank, symmetric positive semi-deﬁnite matrix (SPSD). The rank of the matrix is equal to the
number of populations, r. While, one could in principle use low-rank matrix completion (LRMC) techniques as
in Cand`es and Recht [2009], our proposed algorithms explicitly exploit the SPSD structure in the problem.

3. For the deterministic game, we propose an algorithm called MISA, that is provably better than an algorithm

based on LRMC techniques. The MISA algorithm could be of independent interest.

4. For stochastic games we propose two algorithms. When the number of populations, r is small we use a robust
version of MISA, called MISAR. When the number of populations is large, we propose using a robust version
of the Nystr¨om algorithm.

5. For all of the algorithms we establish sample complexity bounds of ﬁnding an (ǫ, δ) optimal pair of arms.
Establishing such sample complexity bounds leads to interesting problems in matrix approximation in the max-
norm. The contributions we make here could be of independent interest in the low-rank matrix approximation
literature.

6. We demonstrate experiments on synthetic and real world datasets to show the sample effectiveness of our pro-

posed algorithms.

Finally, note that these problems can be naively reduced into a regular MAB problem. If there are K arms and we
may propose 2 of them at every time, then we can look at this as an instance of a regular MAB problem with Θ(K 2)
arms. The state of the art algorithms will have sample complexity O(K 2). In contrast, our proposed algorithms
have nearly linear sample complexity, since they exploit additional structure in the problem, which is lost via a naive
reduction to a regular MAB problem.

2 Related Work

Mixture modeling given passively generated data has been well studied in the past. See Kleinberg and Sandler [2004],
Anandkumar et al. [2013]. Online versions of latent collaborative ﬁltering have been investigated in Bresler et al.
[2014].

Gentile et al. [2014], look at the problem of online clustering of bandits where they assume that all the users
belong to one of a small number of clusters and that the users behave similarly within a cluster. They proceed by
estimating clusters and simultaneously estimating optimal choices within clusters. Similar approaches using additional
social network type information have also been investigated [Cesa-Bianchi et al., 2013]. Maillard and Mannor [2014]
suggest an approach where they assume that the rewards are indexed, not only by the arms, but also by type, the latter
of which can be clustered into a small number of groups and analyze the problem when both the cluster memberships
are known or unknown. The problem with online clustering based approach is that due to the nature of the clustering
problem the approach becomes quickly infeasible in the presence of a large number of users. The multi-armed bandit
framework has seen a ﬂurry of activity since the publication of [Auer et al., 1995]. Bandit problems have been studied
both in the stochastic as well as adversarial setting [Bubeck and Cesa-Bianchi, 2012]. As mentioned in the introduction
a naive reduction of our problem into a bandit problem with Θ(K 2) arms is infeasible when K is large. In our paper,
we look at the problem of low-rank SPSD matrix completion problem both in the noiseless and noisy cases. Many
other authors have studied the problem of SPSD matrix completion [see Bishop and Byron, 2014, and references
there]. However, all of these papers consider the passive case, i.e. the entries of the matrix that have been revealed
are not under their control. In contrast, we have an active setup, where we can decide which entries in the matrix
to reveal. For stochastic games one of the algorithm that we propose is the Nystrom method. These methods were

2

Table 1: Comparison of the different games.

Feature
Stochastic
States
Feedback

Game 1 Game 2

[0, 1]

{0, 1}

proposed for scaling kernel matrices which are commonly SPSD matrices [Drineas and Mahoney, 2005, Gittens, 2011,
Kumar et al., 2009].

In the Web search literature click models have been proposed to model user behaviour [Guo et al., 2009b,a,
Craswell et al., 2008] and a bandit analysis of such models have also been proposed [Combes et al., 2015, Kveton et al.,
2015]. However, these models assume that all the users come from a single population and tend to use richer informa-
tion in their formulations (for example information about which exact link was clicked)

3 Proposed games

In this section, we propose two games for the preference modeling problem. In both the proposed games the player
plays a pair of arms, and receives a reward which is a function of the the pair of arms played and possibly other external
factors. For both of the games we are interested in pure exploration in the PAC setting, i.e. we want to design
algorithms that discover, using as few trials as possible, an (ǫ, δ) best pair in the PAC framework. That is, for
both the games we are interested in outputting with probability at least 1 − δ, a pair of arms that is ǫ close to the best
pair. The difference between the two games is that in Game I the reward obtained is a deterministic function of the pair
of arms played, whereas in Game II the reward obtained is a noisy function of the pair of arms played and an external
random state that is unknown to the player. Table 1 summarizes features of both the proposed games.

Notations and deﬁnitions. ∆r represents the r dimensional probability simplex. Matrices and vectors are rep-
resented in bold font. For a matrix L, the notation Li,j represents (i, j) element of L, and Li:j,k:l is the submatrix
consisting of rows i, i + 1, . . . , j and columns k, k + 1, . . . , l. The matrix k·k1 and k·k2 norms are always operator
norms. The matrix k·k∞ is the element wise norm (max norm). Finally, let 1 be the all 1 column vector.
Deﬁnition 3.1. The principal minor of a matrix L, indexed by a set S, is the determinant of the square sub-matrix of
L consisting of rows and columns from the set S. For example, if S = {1, 2}, then the principal minor of L indexed
by the set S is the determinant of the matrix:(cid:20)L1,1 L1,2
L2,1 L2,2(cid:21).

3.1 Deterministic game

As mentioned above, Game 3.1 is a deterministic game, where the reward of pulling a pair of arms (it, jt) is deﬁned
as follows: Let, Zt be a multinomial random variable whose output space is the set {1, 2, . . . , r}. Let uZt be a reward
vector in [0, 1]K indexed by Zt. Then the reward obtained by playing the pair of arms (it, jt) in round t of (3.1) is
given by Equation (1).

It is clear from the above deﬁnition of our game that the optimal pair of arms is given by the equation

(i⋆, j⋆) = arg mini,j

EZt∼p(1 − uZt (i))(1 − uZt (j)).

(2)

Since, we are interested in returning an (ǫ, δ) optimal pair of arms it is enough if the pair returned by our algorithm
attains an objective function value that is at most ǫ more than the optimal value of the objective function shown in
equation (2), with probability at least 1 − δ.
As a concrete example of the above game consider the case of an advertising company that wants to show two
advertisement to each incoming customer. A randomly chosen customer belongs to one of the two possible categories
with probability deﬁned by a probability vector p. This advertising company makes $1 whenever, a random incoming
customer clicks on either of the one of the two displayed advertisements, and $0 otherwise. The reward shown in

3

✗
✓
✗
✓
Game 3.1 Non-stochastic real valued rewards independent of state

1: while TRUE do
2:
3:

Player plays a pair of arms (it, jt).
Player receives the reward yt deﬁned as

yt = 1 − EZt∼p(1 − uZt(it))(1 − uZt (jt))

(1)

STOP if we have a certiﬁable (ǫ, δ) optimal pair of arms.

4:
5: end while

equation (1) for this setting is just the probability of getting $1, when the pair of advertisements (it, jt) is shown to a
random incoming customer.

3.2 Stochastic game

Game 3.2 Stochastic 0-1 rewards + stochastic states

1: while TRUE do
2:
3:
4:

Adversary chooses Zt ∼ Mult(p), but does not reveal it to the player.
Player plays a pair of arms (it, jt).
Player receives reward yt deﬁned as follows

yt = max{yit, yjt}
yit ∼ Bern(uZt(it))
yjt ∼ Bern(uZt(jt))

(3)
(4)
(5)

STOP if we have a certiﬁable (ǫ, δ) optimal pair of arms.

5:
6: end while

The stochastic game shown in Figure (3.2) is the stochastic counterpart of the deterministic game shown in Fig-
ure (3.1). In the stochastic game the reward received when the pair of arms (it, jt) is played depends on two sources
of randomness. (i) The state of the game which is dictated by a random variable Zt sampled from a multinomial
distribution deﬁned by a vector p, and (ii) independent, random draws from Bernoulli distributions with parameters
uZt(it) and uZt (jt).

4 Low rank structure in our games

Let p ∈ ∆r, and let the reward matrix R ∈ RK×K be such that its (i, j) entry is the probability of obtaining a reward
of 1 when the pair of arms (i, j) are pulled. Then from equation (1) we know that the reward structure for both the
deterministic and stochastic games has the form

Ri,j = 1 − EZt∼p(1 − uZj (i))(1 − uZj (j))
pk(1 − uk(i))(1 − uk(j)).

= 1 −

r

Xk=1

(6)

4

The above equation can be rewritten as

R = 11⊤ −

.

(7)

r

Xk=1
|

pk(1 − uk)(1 − uk)⊤
}

{z

L

As mentioned before our goal is to ﬁnd a pair of arms that are (ǫ, δ) optimal. Hence, it is enough to ﬁnd an entry
in the matrix L that is ǫ close to the smallest entry in the matrix L with probability at least 1 − δ. In order to do
this an obvious approach is to look at all Θ(K 2) pairs of arms and run standard algorithms for multi-armed bandits
on these Θ(K 2) pairs. For example one could run a Successive Elimination (SE) algorithm or Median Elimination
algorithm (ME) on these Θ(K 2) pairs [Even-Dar et al., 2006] to ﬁnd an (ǫ, δ) optimal arm. The sample complexity
of the SE or ME algorithms on these Θ(K 2) pairs would be roughly ˜O( K 2
ǫ2 ) 1. In typical applications that we are
interested in, K can be very large, and therefore the sample complexity of Successive Elimination can be very large.
Moreover, typical bandit algorithms assume that individual arms are independent of each other and hence have a linear
dependence on the number of arms. In contrast, in the naive reduction sketched above, two pairs of arms (i, j), (i′, j′)
are not independent if i = i′ or j = j′. A natural question to ask is can we modify the SE, ME algorithm or some
other algorithm to obtain a new algorithm that has a sample complexity which is linear in K? It turns out that in our
problem we can get away with sample complexity far smaller than K 2. In order to do this we exploit the structural
properties of matrix L, which are enunciated in the following simple proposition.
Proposition 4.1. Let L = 1 − R. Then matrix L shown in equation (6) satisﬁes the following two properties

1. rank(L) ≤ r
2. L (cid:23) 0.

Proof. From equation (6) it is clear that the matrix L can be written as a sum of r rank-1 matrices. Hence rank(L) ≤ r.
Furthermore, since these rank-1 matrices are all positive semi-deﬁnite and L is a convex combination of such, we can
conclude that L (cid:23) 0.

The low-rank of the matrix L and its SPSD structure is what we shall exploit in our algorithms to obtain sample

complexity that is linear in K.

5 Algorithms for determinstic games

Our approach to game (3.1) is via matrix completion. In this game playing the pair of arms (i, j) reveals the (i, j)
entry of matrix R. As can be seen from equation (6) the matrix R has rank at most r + 1. One can use standard
matrix completion results which relies on nuclear norm minimization techniques [Cand`es and Recht, 2009, Recht,
2011]. This result states that we need to see O(Krµ log2(K)) random entries in the matrix R, where µ is the upper
bound on the coherence of the row and column space of matrix R, for exact recovery of the matrix R. We provide
a simple algorithm that recovers the matrix R after querying O(Kr) entries in the matrix R. Our algorithm called
Minor Sampling (MS) is shown in Figure (5.1) and works with the matrix L 2.

5.1 The MInor SAmpling algorithm

The MInor SAmpling (MISA) algorithm uses the following successive sampling strategy: MISA ﬁrst sample the ﬁrst
column and the diagonal elements. This requires K + K − 1 = 2K − 1 samples. MISA then searches for all possible
2 × 2 principal minors of L formed by rows and columns of (1, i), i ∈ {2, 3, . . . , K − 1}. If a certain pricipal minor
is non-zero, then MISA adds it to the list of independent columns and stops the search. MISA then samples all the
K − 2 remaining elements of the latest independent column found. This process is repeated but with MISA searching

1The ˜O notation in this paper will hide logarithmic dependence on 1
δ
2Pulling the pair (i,j) gets us Ri,j , which can be used to populate Li,j = 1 − Ri,j

, K, 1
δ

5

for higher order principal minors. This is done until MISA is unable to ﬁnd a principal minor greater than 0. At this
point MISA has succesfully found all the linearly independent columns in the matrix L, and the remaining dependent
columns are imputed by solving a system of linear equations. The algorithm is shown in Figure (5.1).

Algorithm 5.1 Minor Sampling Algorithm

1: Play the pairs (1, 1), (1, 2), . . . (1, K). This gives us the ﬁrst row and column (by symmetry) of the matrix L.
2: Play the pairs (2, 2), . . . , (K, K). This gets us the diagonal of the matrix L.
3: J = {1}, {Columns which have been fully sampled}
4: D = {2, . . . , K}
5: for k = 1 to k = r − 1 do
for j ∈ D do
6:
Let L(k+1)
7:
if det(cid:16)L(k+1)
J ← J ∪ {j}, D ← D \ {j}
Play all the pairs (·, j) that have not been played before.
k ← k + 1
D ← D \ {j}

be the principle sub-matrix formed by the indices in J ∪ {j}.
(cid:17) 6= 0 then

else

8:

j

j

9:
10:
11:
12:
13:
14:
15:
16: end for
17: Impute column j /∈ J as L1:K,J L−1

end if
end for

J ,J LJ ,j

The sampling algorithm (5.1) requires: K + (K − 1) + (K − 2) + . . . + (K − (r − 1)) + (K − r) ≤ (r + 1)K

samples from the matrix L.
Theorem 5.1. If L ∈ Rn×n is a symmetric, SPSD matrix of rank r, then the sequential sampling algorithm (5.1) can
reconstruct L by observing at most K(r + 1) samples from L.

Proof. L is a positive semi-deﬁnite matrix, hence, if a principal minor is non-zero then it implies that the corresponding
columns are linearly independent. MISA exploits this fact by sequentially testing if certain principal minors are non-
zero. This test is performed in line 8 of Algorithm (5.1). The sample complexity of the algorithm follows by a simple
counting argument.

The following corollary follows immediately.

Corollary 5.2. Using algorithm (5.1) we can output a (0, 0) optimal arm for Game I using at the most K(r + 1) pulls
of pair of arms.

5.2 Handling the approximate low-rank case

Theorem (5.1) says that we need to see O(Kr) samples for exact recovery. While this is attractive when r is small,
when r is large the sample complexity of algorithm (5.1) can be very large. For example, if there are a lot of populations
from which the users can come to an online advertiser then r can be large. However, even though r is large it could
be the case that 99% of the incoming visitors belong to only a small fraction of these r classes. In this case instead of
exactly ﬁnding the smallest element in the matrix L it is enough if we ﬁnd an (ǫ, δ) optimal arm. So a natural question
to ask is what is the sample complexity of ﬁnding an (ǫ, δ) optimal arm? We next present an algorithm, in Figure (5.2)
based on Nystr¨om sampling that allows us to construct a matrix ˆLk such that || ˆLk − L||∞ ≤ ǫ
2 with probability at
least 1 − δ. Construction of such a matrix ˆLk immediately implies that the pair of arms (i, j) corresponding to the
smallest entry in the matrix ˆLk is an (ǫ, δ) optimal pair.
In order to establish an inﬁnity norm bound of || ˆL−L||∞ we need the following important result of Gittens [2011].

6

Algorithm 5.2 Nystr¨om Sampling Algorithm
1: Select l ≪ K columns of L at random to deﬁne the matrix C.
2: Let W be the l × l elements of W indexed by the same rows and columns as the columns selected in previous
3: Output ˆLk = CW †C ⊤.

step

Theorem 5.3. (From Gittens [2011]) Let A be a PSD matrix of size K. Given an integer k ≤ K, partition A using
its eigenvalue decomposition as:

A =(cid:2) U1 U2 (cid:3)(cid:20) Σ1

2 (cid:21)
Σ2 (cid:21)(cid:20) U ⊤

1
U ⊤

where, Σ1 is a k × k diagonal matrix containing the top k eigenvalues of A and the remaining eigenvalues are in Σ2.
U1 contains the k eigenvectors corresponding to the top k eigenvalues. Then deﬁne τ = µ0(U1), the incoherence of
the columns of U1. Fix a failure probability δ ∈ (0, 1). For any ǫ ∈ (0, 1), if

l ≥

2τ k log(k/δ)

(1 − ǫ2)

columns of A are chosen uniformly at random and used to form a Nystr¨om extension, ˆAk, then the spectral norm error
of the approximation satisﬁes:

kA − ˆAkk2 ≤ λk+1(A)(cid:18)1 +

K

ǫl(cid:19)

Theorem 5.4. Let ǫ ∈ (0, 1) and for a target β ∈ (0, 1), deﬁne c = 2τ k log(k/δ), and ǫ = βc
L satisﬁes

K+c . Then if the matrix

λk+1(L) ≤ ǫ2

(8)

and if we sample l ≥ c(cid:16) K+c
method (Algorithm 5.2). Then, with probability 1 − δ:

K+(1−β)c(cid:17)2

columns randomly from the matrix L and estimate ˆLk using the Naive Nystrom

Proof. This is a direct result of picking the right constants in Theorem 5.3. We have,

(cid:13)(cid:13)(cid:13)L − ˆLk(cid:13)(cid:13)(cid:13)∞ ≤ β

(9)

(cid:13)(cid:13)(cid:13)L − ˆLk(cid:13)(cid:13)(cid:13)∞ ≤(cid:13)(cid:13)(cid:13)L − ˆLk(cid:13)(cid:13)(cid:13)2
≤ λk+1(L)(cid:18)1 +
ǫK
≤ ǫ2 +
l ≤ ǫ2 + ǫ
K
= β [ by deﬁnition of ǫ]
≤ ǫ + ǫ
c

ǫl(cid:19) [using Theorem (5.3)]
(1 − ǫ1)2 ≤ ǫ2 + ǫ

K
c

K
c

K

Remark 5.3. Notice that in the above result, if the k + 1 eigenvalue of L is very small then β = ǫ(K+c)

is also small,

and hence we need l = O(cid:0)k log k

output an (ǫ, δ) optimal pair our Nystr¨om based algorithm would need to pull O(nk log(k/δ)) pairs of arms. The
parameter k can be considered to be the approximate rank of the matrix L.

δ(cid:1) for Nystr¨om algorithm shown in (5.2) to succeed. This means that in order to

c

7

6 Algorithms for stochastic games

For the stochastic game proposed in the paper we shall propose an algorithm similar to algorithm (5.1). Any algorithm
for the stochastic game has to be robust to randomness in the reward information. For stochastic games too we provide
two algorithms. Our ﬁrst algorithm called MISAR combines successive-elimination on minors along with repeated
sampling and imputation, and works well when r = 2. For larger r we use a robust version of the Nystrom algorithm
shown in Figure (5.2), where we ﬁrst randomly choose l columns of the matrix L, and then repeatedly sample these
randomly chosen columns to get robust estimates of the matrices C, W used there. We begin by explaining the
MISAR algorithm

6.1 The MInor SAmpling Robust algorithm

The MISAR algorithm can be thought of as a robust extension of the MISA algorithm. The MISAR algorithm, shown
in Figure (6.1) involves the three steps which we explain next. For this subsection we shall assume that r = 2

Successive elimination on 2 × 2 principal minors. The ﬁrst step is to consider a bandit problem with K − 1
“meta-arms” {{1, j} : j ≥ 2}. Each meta-arm indexed as (1, j) is a stochastic arm which gives an average reward
equal to the principal minor corresponding to the pair (1, j). A single pull of the meta-arm (1, j) can be simulated
by pulling the pairs (1, 1), (j, j) each once and the pair (1, j) twice. Using these 4 random samples one can obtain
an unbiased estimate of the principal minor indexed by the meta-arm {1, j}. Using many such random draws one can
construct conﬁdence bounds on the principal minor indexed by a given tuple {1, j}. Let κ be the smallest non-zero
principal minor indexed by a set of the form {1, j} This allows us to run a SE/ME algorithm to ﬁnd an ( κ
2 , δ) optimal
meta-arm. The sample complexity of this procedure is T1 := ˜O( K
κ2 ).
Repeated sampling to obtain accurate estimate of basis vectors. The successive elimination algorithm run
in the previous step returns to us some set which represent independent columns of the matrix L. For notational
convenience, let this set be {1, 2}. What we shall do next is we shall repeatedly sample elements of columns 1, 2 so
that each entry of these two columns is well approximated to an accuracy of ¯ǫ with probability at least 1− δ. The value
of ¯ǫ depends on ǫ and is chosen such that accurate imputation of the matrix L is possible. The sample complexity of
this step is Tapprx := O( K
Impute the rest of the columns of matrix L based on noisy estimates obtained in the previous step. Our
imputation technique is based on the fact that each column of the matrix L is a linear combination of the independent
columns of L. Hence to impute column j of L we just need to calculate ˆL1:K,1:2a where the vector a satisﬁes the
equation

¯ǫ2 log( 2K

δ )).

ˆL1:2,1:2a = ˆL1:2,j

Once imputed we have a matrix ˆL which is a good estimate of L, and we can now output the pair of indices (ˆi, ˆj) as a
near optimal pair.

Algorithm 6.1 Minor Sampling Algorithm - Robust
1: Perform successive elimination on 2 × 2 principal minors of
2: Suppose the set returned from above step is {1, 2}. Repeatedly sample columns 1, 2, so that each element of
2K . This gets us a matrix ˆL for

{1, 2},{1, 3}, . . . ,{1, K} to return a single set.
columns 1, 2 is approximated within an accuracy of ¯ǫ with probability at least 1 − δ
which we have noisy estimates of the ﬁrst two rows and columns.
ˆL1:2,j.

3: Impute columns j(j > 2) of matrix ˆL as ˆL1:K,1:2 ˆL−1
4: Output a pair of indices (ˆi, ˆj) corresponding to the smallest entry in ˆL.

indexed by the sets

the matrix L,

1:2,1:2

Lemma 6.1. It is enough to approximate each entry of the ﬁrst two columns to within ¯ǫ := ǫ∆2
(L1,1L2,2 − L2

1,2) so that imputation step imputes each element to within ǫ error.

12∆+8 , where ∆ :=

8

Proof. Any element (i, j) of the matrix ˆL can be written as

Li,j =

1

L1,1L2,2 − L2

1,2

[Li,1(L2,2L1,j − L1,2L2,j)+
Li,2(−L1,2L1,j + L1,1L2,j)]

Taking partial derivative of Li,j w.r.t. all the parameters, and by elementary algebraic calculations we get the desired
result.

Note that by deﬁnition, ∆ > κ, and one could safely replace ∆ by κ in lemma (6.1).

Theorem 6.2. Then, MISAR outputs an (ǫ, δ) optimal arm, and its sample complexity is

T1 + T2 = ˜O(cid:18) K
ǫ2κ3(cid:19)

step involves ﬁlling up the ﬁrst two columns such that each element is approximated to ¯ǫ error. Using Hoeffding

Proof. Step 1 involves SE/ME on the meta-arms. The sample complexity of this step is equal to ˜O(cid:0) K
bounds and the expression of ¯ǫ from lemma (6.1) implies that we need a total of ˜O(cid:0) K

step which is the imputation step does not need any samples. The statement now follows.

κ2(cid:1). The second
ǫ2κ3(cid:1) samples. Finally the last

6.2 Robust Nystr¨om algorithm for stochastic games

The MISAR algorithm shown in Figure (6.1) works well when matrix L is rank-2. However, it is hard to extend this
algorithm beyond the rank-2 case as determinants are not robust to noise. To get around this problem we suggest using
a robust Nystr¨om algorithm. Once we choose l columns of the matrix L to form matrix C, W , we repeatedly sample
the entries of C, W to obtain robust estimators ˆC, ˆW . These robust estimators are then used to obtain a Nystr¨om
extension as ˆL = ˆC ˆW −1 ˆC ⊤. Repeated sampling of matrices C, W are required in order to beat the randomness in
stochastic games. A natural question to ask is how many times do we have to sample each entry of the matrix C, and
what is the sample complexity of the robust Nystrom algorithm. The following theorem provides an answer to this
question.

Theorem 6.3. Let Lk be a Nystrom extension of L, using matrices C, W . Assume W is invertible. Let, ˆW , ˆC be
sample versions of the matrices W , C obtained by repeatedly sampling independent Bernoulli random variables from
the entries of the matrices W , C respectively. Deﬁne the robust Nystr¨om extension ˆLk = ˆC ˆW −1 ˆC ⊤. Then with
probability at least 1 − δ, we have || ˆLk − Lk||∞ ≤ ǫ after querying
l2||W −1||2
||W −1||2

˜O  Kl3||CW −1||2

l8||W −1||4

!

ǫ2

ǫ2

1

+

2

∞

+

∞

number of samples, where ˜O hides terms logarithmic in K, l, 1
δ .

The proof is deferred to the Appendix.

Remark 6.3. The above bound immediately implies that using approximately ˜O(
) pulls of pairs of
arms, we can locate an (ǫ, δ) optimal pair using the robust Nystrom algorithm. The price that we need to pay because of
the stochasticity in stochastic games is an additional factor of O(l2). As was shown in Theorem (5.4) and remark (5.3),
if λk+1(L) is small and if the matrix L is incoherent, then we can use l = ˜O(k log(k)) columns for Nystr¨om extension.

ǫ2

∞

Kl3kCW −1k2

9

Table 2: Comparison of results for the low rank case with exact rank, where we have 400 arms.

Algorithm Samples (rank 2)
Naive
Nystr¨om
MISA

79800
8000
1197

Samples (rank 100)
79800
4240000
1197

Table 3: Comparison of results for the low rank case with approximate rank, where we have 400 arms.

Algorithm Samples (rank 2)
Naive
Nystr¨om
MISA

79800
8000
1594

Samples (rank 100)
79800
1844000
11194

7 Experiments

7.1 Deterministic games on synthetic datasets
Here we picked the number of arms, K = 400 and r = 2. Then we created a random matrix A ∈ [0, 1]K×r. Then
taking L = AA⊤ gives us a rank 2 matrix but now its elements might no longer be bounded above by 1. Therefore
dividing A by a large enough number such that resultant matrix has entries that represent probabilities gave us the
synthetic data to test on. In the case of the approxim ately low-rank matrix, we follow the same steps, except that we
added to A a perturbation matrix ǫE, ǫ = 10−4, E ∈ [0, 1]K×r. We also ensured that the minimum of the matrix
occurred on an off-diagonal element in order to ensure that the results would be non-trivial.

Noiseless results

The results can be seen in tables 2 and 3. Notice that the number of samples for the Naive algorithm doesn’t change

as in the noiseless case, it always samples all (cid:0)K

algorithms by a considerable margin.

r(cid:1) arms. As it can be seen, our algorithm out performs the other

7.2 Real-world datasets

We use the ML-100K dataset to exhibit the performance of various algorithms. The ML-100K dataset consists of
movie ratings as given by different users. The number of movies is 1682. This dataset has a lot of missing entries. We
use a standard matrix completion algorithm to ﬁll-in the missing ratings.

Experimental results with deterministic games We set ǫ = 0.1, and δ = 0.05, and compare the number of trials
that are needed by different algorithms. Table (4) compares the number of pulls needed by different algorithms. A
naive algorithm will have to pull all pairs of arms. Hence the number of pulls needed by a naive algorithm is K(K+1)
.
As can be seen MISA is better than both the Nystrom and the Naive algorithms.

2

Table 4: Number of arm pulls needed by different algorithms to ﬁnd the best pair of movies when playing deterministic
games. The Nystrom implementation uses l ≈ k log(k/δ) random columns, where k = 2. The Naive algorithm
performs simply goes through all the(cid:0)K
2(cid:1) choices of pairs-of-arms and picks the best one after having sampled each
one exactly once.

dataset
ML-100K-gender
ML-1M-gender

K MISA Nystrom
6728
15808

5043
11853

1682
3952

Naive
1415403
7811128

10

Table 5: Number of arm pulls needed by different algorithms to ﬁnd the best pair of movies when playing stochastic
games. The Nystrom implementation uses l ≈ k log(k/δ) random columns, where k = 2, and repeatedly samples
each entry in the randomly chosen columns O( l2
ǫ2 ). The constants in the O notation are chosen as the smallest integers
that allows the Nystrom algorithm to output a good arm. The Naive algorithm performs SE on(cid:0)K

2(cid:1) arms.

Nystrom

MISAR

dataset

Naive

576404814
3138599114
9010105451

ML-100K-gender

31222751(18.46)
ML-100K-occupation-LR 21973410 (142.8)
ML-100K-occupation-HR

N/A

63566144(9)

63566144 (49.37)

174753072

Table 6: The mean absolute error ± standard deviation of absolute error of two algorithms averaged over 10 rounds.
The errors are the absolute difference between the reward of the true best arm and the reward of the best arm as output
by the algorithm. LRMC is low-rank matrix completion based approach.

dataset

Nystrom

ML-100K-gender

0.0478± 0.0424
ML-100K-occupation-LR 0.0384± 0.0223
ML-100K-occupation-HR 0.0234± 0.0117

LRMC

0.0297± 0.0168
0.0196± 0.0179
0.0141± 0.0071

Experimental results with stochastic games For experiments on stochastic games we consider only the ML-
100K dataset and half the movies in the dataset. This leads to problems with 841 arms. We create three datasets, by
clustering users into two or more groups based on gender/ occupation.

1. ML-100K-gender: We threshold the completed ratings matrix into a 0/1 matrix by thresholding all ratings
greater than or equal to 3 to 1 and all ratings less than 3 to 0. The users are clustered into two classes as per
the gender, and the vectors u1, u2 are constructed by calculating the class-conditional probabilities of a random
user, liking a certain movie, given that he is chosen from the class. By construction

2. ML-100K-occupation-LR: In this case the dataset is constructed as in the case of ML-100K-gender, but now
users are clustered into three groups as per their occupation. The ﬁrst group are users who are either students
of programmers, a second group of engineers or educator, and a third small group of lawyers, homeakers, or
doctors. This leads to a problem that is rank-3 but approximately rank-2

3. ML-100K-occupation-HR: In this case we have clustered users into seven groups. The L matrix for this problem

is now rank 7, and approximately rank-3.

The results are shown in Table (7.2). As we can see both the Nystrom and the MISAR algorithm are much more

sample efﬁcient than the Naive algorithm.

7.3 Comparison with low rank matrix completion based procedures

As mentioned in the introduction one can repeatedly sample a bunch of random pairs of arms, and then perform a
low-rank matrix completion using the estimated rewards of the random pairs chosen. Unfortunately, there do not
exist guarantees in the max norm of the recovery of low-rank matrices using nuclear norm based low-rank matrix
completion (LRMC). This is one of the reasons why we did not pursue an approach based on LRMC in this paper.
However, in Table (6), we report the mean absolute difference in the estimate of the reward of the best arm as output
by different algorithms w.r.t. the true best arm. These results are averaged over 10 runs of the experiment. As can be
seen from this table an approach based on LRMC does just as well as the robust Nystrom method, in spotting a good
pair-of-arms quickly for the same given budget of arms pulls. This points that the theoretical guarantees that we have
robust Nystrom method might just as well be applicable to LRMC also.

11

8 Conclusions

In this paper we introduced bandit games, where the player can choose 2 arms in each round. We studied a deter-
ministic game and a stochastic game, and showed that the problem has a low-rank structure that can be exploited to
design efﬁcient algorithms. There are many possible extensions to the problem studied in this paper such as extensions
to games where player can play more than 2 arms, developing MISAR like algorithms which are more adaptive than
Nystrom based methods, but that can work for larger rank.

References

A. Anandkumar, R. Ge, D. Hsu, and S. M. Kakade. A tensor approach to learning mixed membership community

models. arXiv preprint arXiv:1302.2684, 2013.

P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire. Gambling in a rigged casino: The adversarial multi-armed
bandit problem. In Foundations of Computer Science, 1995. Proceedings., 36th Annual Symposium on, pages 322–
331. IEEE, 1995.

M. Babaioff, Y. Sharma, and A. Slivkins. Characterizing truthful multi-armed bandit mechanisms. In Proceedings of

the 10th ACM conference on Electronic commerce, pages 79–88. ACM, 2009.

W. E. Bishop and M. Y. Byron. Deterministic symmetric positive semideﬁnite matrix completion. In Advances in

Neural Information Processing Systems, pages 2762–2770, 2014.

G. Bresler, G. H. Chen, and D. Shah. A latent source model for online collaborative ﬁltering. In Advances in Neural

Information Processing Systems, pages 3347–3355, 2014.

S. Bubeck and N. Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. arXiv

preprint arXiv:1204.5721, 2012.

E. J. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations of Computational mathe-

matics, 9(6):717–772, 2009.

N. Cesa-Bianchi, C. Gentile, and G. Zappella. A gang of bandits. In Advances in Neural Information Processing

Systems, pages 737–745, 2013.

R. Combes, S. Magureanu, A. Proutiere, and C. Laroche. Learning to rank: Regret lower bounds and efﬁcient algo-
rithms. In Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling
of Computer Systems, pages 231–244. ACM, 2015.

N. Craswell, O. Zoeter, M. Taylor, and B. Ramsey. An experimental comparison of click position-bias models. In

Proceedings of the 2008 International Conference on Web Search and Data Mining, pages 87–94. ACM, 2008.

N. R. Devanur and S. M. Kakade. The price of truthfulness for pay-per-click auctions. In Proceedings of the 10th

ACM conference on Electronic commerce, pages 99–106. ACM, 2009.

P. Drineas and M. W. Mahoney. On the nystr¨om method for approximating a gram matrix for improved kernel-based

learning. The Journal of Machine Learning Research, 6:2153–2175, 2005.

E. Even-Dar, S. Mannor, and Y. Mansour. Action elimination and stopping conditions for the multi-armed bandit and

reinforcement learning problems. JMLR, 7:1079–1105, 2006.

C. Gentile, S. Li, and G. Zappella. Online clustering of bandits. arXiv preprint arXiv:1401.8257, 2014.

A. Gittens. The spectral norm error of the naive nystrom extension. arXiv preprint arXiv:1110.5305, 2011.

S. Gopalaratnam. In-store analytics: tracking real-world customers just like online shoppers, February 2015. URL

http://goo.gl/IvD4Ql. [Online; posted February 27, 2015].

12

F. Guo, C. Liu, A. Kannan, T. Minka, M. Taylor, Y.-M. Wang, and C. Faloutsos. Click chain model in web search. In

Proceedings of the 18th international conference on World wide web, pages 11–20. ACM, 2009a.

F. Guo, C. Liu, and Y. M. Wang. Efﬁcient multiple-click models in web search. In Proceedings of the Second ACM

International Conference on Web Search and Data Mining, pages 124–131. ACM, 2009b.

D. Hensher, J. Louviere, and J. Swait. Combining sources of preference data. Journal of Econometrics, 89(1):197–221,

1998.

J. Kleinberg and M. Sandler. Using mixture models for collaborative ﬁltering. In Proceedings of the thirty-sixth annual

ACM symposium on Theory of computing, pages 569–578. ACM, 2004.

V. Kuleshov and D. Precup. Algorithms for multi-armed bandit problems. arXiv preprint arXiv:1402.6028, 2014.

S. Kumar, M. Mohri, and A. Talwalkar. Sampling techniques for the nystrom method. In International Conference on

Artiﬁcial Intelligence and Statistics, pages 304–311, 2009.

B. Kveton, C. Szepesvari, Z. Wen, and A. Ashkan. Cascading bandits: Learning to rank in the cascade model. In

Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 767–776, 2015.

J. J. Louviere and G. Woodworth. Design and analysis of simulated consumer choice or allocation experiments: an

approach based on aggregate data. Journal of marketing research, pages 350–367, 1983.

O.-A. Maillard and S. Mannor. Latent bandits. 2014.

B. Recht. A simpler approach to matrix completion. The Journal of Machine Learning Research, 12:3413–3430,

2011.

S. Rosenbloom.

shoppers, March
http://www.nytimes.com/2010/03/20/business/20surveillance.html.
March 19, 2010].

cameras

In

bid

track

to

sway

sales,

2010.
URL
[Online; posted

A Proof of sample complexity for the Robust Nystr¨om method

We will divide the bounds as follows:

(cid:13)(cid:13)CW −1C ⊤ − ¯C ¯W −1 ¯C ⊤(cid:13)(cid:13)∞ =(cid:13)(cid:13)CW −1C ⊤ − ¯CW −1C ⊤ + ¯CW −1C ⊤ − ¯C ¯W −1 ¯C ⊤(cid:13)(cid:13)∞
≤(cid:13)(cid:13)CW −1C ⊤ − ¯CW −1C ⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13) ¯CW −1C ⊤ − ¯C ¯W −1 ¯C ⊤(cid:13)(cid:13)∞
=(cid:13)(cid:13)CW −1C ⊤ − ¯CW −1C ⊤(cid:13)(cid:13)∞
+(cid:13)(cid:13) ¯CW −1C ⊤ − ¯C ¯W −1C ⊤ + ¯C ¯W −1C ⊤ − ¯C ¯W −1 ¯C ⊤(cid:13)(cid:13)∞
≤(cid:13)(cid:13)CW −1C ⊤ − ¯CW −1C ⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13) ¯CW −1C ⊤ − ¯C ¯W −1C ⊤(cid:13)(cid:13)∞
+(cid:13)(cid:13) ¯C ¯W −1C ⊤ − ¯C ¯W −1 ¯C ⊤(cid:13)(cid:13)∞
=(cid:13)(cid:13)(C − ¯C)W −1C ⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13) ¯C(W −1 − ¯W −1)C ⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13) ¯C ¯W −1(C − ¯C)⊤(cid:13)(cid:13)∞

Now, we need to bound each of the last three terms.

13

. So:

A.1 Bounding(cid:13)(cid:13)(cid:13)(C − ˆC)W −1C ⊤(cid:13)(cid:13)(cid:13)∞
Let M = W −1C ⊤, then(cid:13)(cid:13)(C − ¯C)W −1C ⊤(cid:13)(cid:13)∞ =(cid:13)(cid:13)(C − ¯C)M(cid:13)(cid:13)∞
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Xp=1
((C − ¯C)W −1C ⊤)i,j =
∴(cid:13)(cid:13)(C − ¯C)W −1C ⊤(cid:13)(cid:13)∞ = max

i,j

l

Now:

( ¯C)i,p ∼

1
m

Bernoulli(m, Ci,p)

l

(C − ¯C)i,pMp,j
Xp=1

(C − ¯C)i,pMp,j(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

⇒ (C − ¯C)i,p = Ci,p −

1
m

Bernoulli(m, Ci,p)
mCi,p − Bernoulli(m, Ci,p)

=

= ri,p (deﬁne)

i,j

⇒(cid:13)(cid:13)(C − ¯C)W −1C ⊤(cid:13)(cid:13)∞ = max
Zp,s(i, j)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

P (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Xp=1

Xs=1

m

l

m

l

ri,pMp,j(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xp=1
> t! ≤ 2 exp(cid:18) −t2/2
σ2 + Rt/3(cid:19)

Let us now apply the Bernstein inequality:

on the concentration of the random variables Zp,s(i, j) later deﬁned. For this we need to ﬁrst note the following
bounds:

• −1 ≤ ri,p ≤ 1 ⇒ R = 1
• Eri,p = 0
• V ar(ri,p) ≤ 1/4m
• Let rs

i,p be the s-th random i.i.d. draw of the random variable ri,p.

To apply the standard Bernstein inequality, we also note that:

• Zs,p,i,j = rs
i,pMp,j
• |Zs,p(i, j)| = |rs

respectively, we get σ2 = ml kMk2

∞ /4.

i,pMp,j| ≤ |Mp,j| ≤ kMk∞. Since we are summing over, p and s with l and m terms each

Therefore, applying the previous Bernstein inequality on Zp,s(i, j) with the constants R, σ2 that we have calculated,
we get, with probability ≥ 1 − δ:
Xp=1

≤ kMk∞

+ kMk∞

3m

2
δ

m

l

m

Zp,s(i, j)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xs=1
⇒(cid:13)(cid:13)(C − ¯C)W −1C⊤(cid:13)(cid:13)∞ ≤ (cid:13)(cid:13)W −1C ⊤(cid:13)(cid:13)∞

3m

log

2
δ

log

2 r 2l
+ (cid:13)(cid:13)W −1C ⊤(cid:13)(cid:13)∞

2

2nl
δ

log

r 2l

m

log

2nl
δ

14

A.2 Bounding(cid:13)(cid:13)(cid:13)

ˆC ˆW −1(C − ˆC)⊤(cid:13)(cid:13)(cid:13)∞

Let us proceed by splitting this up further:

(cid:13)(cid:13) ¯C ¯W −1(C − ¯C)⊤(cid:13)(cid:13)∞ ≤(cid:13)(cid:13)( ¯C ¯W −1 − CW −1 + CW −1)(C − ¯C)⊤(cid:13)(cid:13)∞

≤(cid:13)(cid:13)( ¯C ¯W −1 − CW −1)(C − ¯C)⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13)CW −1(C − ¯C)⊤(cid:13)(cid:13)∞

Proposition A.1. For two real matrices M1 ∈ Rn1×n2 , M2 ∈ Rn2×n3:

kM1M2k∞ ≤ kM1k∞ kM2k1

kM1M2k∞ ≤(cid:13)(cid:13)M ⊤

1 (cid:13)(cid:13)1 kM2k∞

where, the k·k1 is the induced 1 norm.
Proof.

i,j

kM1M2k∞ = max
≤ max
≤ max
= kM1k∞ kM2k1

(cid:12)(cid:12)e⊤
i M1M2ej(cid:12)(cid:12)
i M1(cid:13)(cid:13)∞ kM2ejk1
i,j (cid:13)(cid:13)e⊤
i M1(cid:13)(cid:13)∞ max
i (cid:13)(cid:13)e⊤
To get the second inequality, note that kM1M2k∞ =(cid:13)(cid:13)M ⊤
1 (cid:13)(cid:13)∞

Continuing the bound:

i kM2ejk1

2 M ⊤

and that(cid:13)(cid:13)M ⊤

2 (cid:13)(cid:13)∞ = kM2k∞.
(cid:13)(cid:13) ¯C ¯W −1(C − ¯C)⊤(cid:13)(cid:13)∞ ≤(cid:13)(cid:13)( ¯C ¯W −1 − CW −1)(C − ¯C)⊤(cid:13)(cid:13)∞ +(cid:13)(cid:13)CW −1(C − ¯C)⊤(cid:13)(cid:13)∞
≤(cid:13)(cid:13) ¯C ¯W −1 − CW −1(cid:13)(cid:13)∞(cid:13)(cid:13)(C − ¯C)⊤(cid:13)(cid:13)1 +(cid:13)(cid:13)CW −1(cid:13)(cid:13)∞(cid:13)(cid:13)(C − ¯C)⊤(cid:13)(cid:13)1
And, (cid:13)(cid:13) ¯C ¯W −1 − CW −1(cid:13)(cid:13)∞ ≤(cid:13)(cid:13) ¯C ¯W −1 − C ¯W −1 + C ¯W −1 − CW −1(cid:13)(cid:13)∞
≤(cid:13)(cid:13) ¯C ¯W −1 − C ¯W −1(cid:13)(cid:13)∞ +(cid:13)(cid:13)C ¯W −1 − CW −1(cid:13)(cid:13)∞
=(cid:13)(cid:13)( ¯C − C) ¯W −1(cid:13)(cid:13)∞ +(cid:13)(cid:13)C( ¯W −1 − W −1)(cid:13)(cid:13)∞
≤(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1(cid:13)(cid:13) ¯W −1(cid:13)(cid:13)∞ + kCk∞(cid:13)(cid:13) ¯W −1 − W −1(cid:13)(cid:13)1
=(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)
+(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1(cid:13)(cid:13)CW −1(cid:13)(cid:13)∞

⇒(cid:13)(cid:13) ¯C ¯W −1(C − ¯C)⊤(cid:13)(cid:13)∞ ≤(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1(cid:0)(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1(cid:13)(cid:13) ¯W −1(cid:13)(cid:13)∞ + kCk∞(cid:13)(cid:13) ¯W −1 − W −1(cid:13)(cid:13)1 +(cid:13)(cid:13)CW −1(cid:13)(cid:13)∞(cid:1)
1(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1(cid:13)(cid:13) ¯W −1(cid:13)(cid:13)∞ +(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1 kCk∞(cid:13)(cid:13) ¯W −1 − W −1(cid:13)(cid:13)1

2

Make the following observations:

• kCk∞ ≤ 1 as all the elements of C are between 0 and 1.

Using the above two bounds, we ﬁnally get:

• With probability≥ 1 − δ,(cid:13)(cid:13)( ¯C − C)⊤(cid:13)(cid:13)1 ≤ lq log 2/δ
(cid:13)(cid:13) ¯C ¯W −1(C − ¯C)⊤(cid:13)(cid:13)∞ ≤

m(cid:13)(cid:13) ¯W −1(cid:13)(cid:13)∞

log 2/δ

m

l2

m .

+ l(cid:13)(cid:13) ¯W −1 − W −1(cid:13)(cid:13)1r log 2/δ

m

+ l(cid:13)(cid:13)CW −1(cid:13)(cid:13)1r log 2/δ

m

15

Let’s ﬁrst begin by breaking down the expression further:

A.3 Bounding(cid:13)(cid:13)(cid:13)

ˆC(W −1 − ˆW −1)C ⊤(cid:13)(cid:13)(cid:13)∞
(cid:13)(cid:13) ¯C(W −1 − ¯W −1)C ⊤(cid:13)(cid:13)∞ ≤(cid:13)(cid:13) ¯C(W −1 − ¯W −1)(cid:13)(cid:13)∞(cid:13)(cid:13)C ⊤(cid:13)(cid:13)1

≤ l(cid:13)(cid:13) ¯C(W −1 − ¯W −1)(cid:13)(cid:13)∞
≤ min(cid:8)l2(cid:13)(cid:13)W −1 − ¯W −1(cid:13)(cid:13)∞ , l(cid:13)(cid:13)W −1 − ¯W −1(cid:13)(cid:13)1(cid:9)
and(cid:13)(cid:13)W −1 − ¯W −1(cid:13)(cid:13)1

.

Hence, we need to bound(cid:13)(cid:13)W −1 − ¯W −1(cid:13)(cid:13)∞

Theorem A.2. (Matrix Bernstein inequality): Let Zi be a sequence of independent random matrices size n1 × n2.
Assume that:

EZi = 0 and kZik2 ≤ R , a.s.

EZiZ ⊤

and deﬁne σ2 = max(cid:8)(cid:13)(cid:13)Pi
P (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi

EZ ⊤

i Zi(cid:13)(cid:13)(cid:9) Then, ∀t > 0:
i (cid:13)(cid:13) ,(cid:13)(cid:13)Pi
Zi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2
≥ t! ≤ (n1 + n2) exp(cid:18) −t2/2
σ2 + Rt/3(cid:19)
8σ2(cid:17)
≤( (n1 + n2) exp(cid:16)− 3t2
(n1 + n2) exp(cid:0)− 3t
8R(cid:1)

, if t ≤ σ2/R
, if t > σ2/R

Corollary A.3. Let Zi = Ai − ˆAi i.e.Pm
(cid:13)(cid:13)A − ¯A(cid:13)(cid:13)2 ≤( R

i=1 Zi = mA −Pm
log(cid:18) n1 + n2

3ǫ

δ

ˆAi and deﬁne ¯A = 1
m

i=1

(cid:19) ,s 8σ2

3ǫ2 log(cid:18) n1 + n2

δ

ˆAi, then w.p. 1 − δ:
(cid:19))

where, A ∈ [0, 1]n1×n2
Proof. This is just an application of Theorem A.2 to our case where Wi, ˆWi ∈ Rl×l. Then all that remains is to
rearrange terms to get the result.

This leads us to the following proposition, that gives a sample complexity bound for estimating W from its sample

averages ˆW :

Proposition A.4. If we sample each element of W , m times where:

m ≥(cid:26) l

3ǫ

δ(cid:19) ,
log(cid:18) 2l

2l

δ(cid:19)(cid:27)
3ǫ2 log(cid:18) 2l

Proof. This comes directly from the following observations:

• R ≥ kZik2 =(cid:13)(cid:13)(cid:13)

as √l2 = l.

ˆWi(cid:13)(cid:13)(cid:13)2 ≥ l. This is because the matrix ˆWi is a matrix of 0, 1 and its spectral norm can be as big

16

• Now for the second part:

EZiZ ⊤

EZ ⊤

i (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
,(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi
i (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
,(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi

i Zi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
)
ˆWi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
)

E ˆW ⊤
i

E ˆWi ˆW ⊤

, since ˆWi is symmetric

σ2 = max((cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi
= max((cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi
=(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Xi

i (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

E ˆWi ˆW ⊤

Now note, that the matrix ˆXi = ˆWi ˆW ⊤
i

is a Gram-matrix. i.e. ˆXk(i, j) =D row i of ˆWk, column j of ˆWkE
= D column i of ˆWk, column j of ˆWkE. This means that from the independence of the entries of ˆWi, the

off-diagonal entries of E ˆWi ˆW ⊤

i are zero. The diagonal entries:

ED column i of ˆWk, column i of ˆWkE =
≤

l

l

Xp=1
Xp=1
≤ l/4

E ˆWk(i, p)2

1/4

Therefore σ2 ≤ l/4.

Applying these two values of σ2 and R in Corollary A.3 and rearranging terms completes the proof.

Let us deﬁne ˆW = W + EW where EW is the error-matrix and ˆW is the sample average of m independent

samples of a random matrix where E ˆWk(i, j) = W (i, j).

log(cid:0) 2l

δ(cid:1)(cid:27) uniform samples to form ˆW ,

log(cid:0) 2l

δ(cid:1) uniform samples to form ˆW then

3ǫ

3ǫ2

8kW −1k2

log(cid:0) 2l
δ(cid:1) ,

Proposition A.5. If we average over m ≥ (cid:26) 2kW −1k
then(cid:13)(cid:13)W −1EW(cid:13)(cid:13)2 < 1 w.p. ≥ 1 − δ.
Proof. Notice that if we pick ǫ ← 1
Proposition A.6. If(cid:13)(cid:13)W −1EW(cid:13)(cid:13)2 < 1, and we sample m ≥ kW −1k4
with probability ≥ 1 − δ,(cid:13)(cid:13)(cid:13)
Proof. Since(cid:13)(cid:13)W −1EW(cid:13)(cid:13)2 < 1, we can apply the Taylor series expansion:

ˆW − W(cid:13)(cid:13)(cid:13)∞ ≤ ǫ.

ǫ2

l2

1

2kW −1k and apply Corollary A.3, we get the desired result.

(W + EW )−1 = W −1 − W −1EW W −1 + W −1EW W −1EW W −1 + ···

17

Therefore:

(cid:13)(cid:13)(cid:13)
ˆW − W(cid:13)(cid:13)(cid:13)∞

⇒ ǫ1(c2

2

=(cid:13)(cid:13)W −1 − W −1EW W −1 + W −1EW W −1EW W −1 + ··· − W −1(cid:13)(cid:13)∞
≤(cid:13)(cid:13)W −1EW W −1(cid:13)(cid:13)∞ +(cid:13)(cid:13)W −1EW W −1EW W −1(cid:13)(cid:13)∞ + ···
≤(cid:13)(cid:13)W −1(cid:13)(cid:13)
1 kEWk∞ +(cid:13)(cid:13)W −1(cid:13)(cid:13)
1 kEWk3
1ǫ1  ∞
(c1ǫ1)i! , where c1 =(cid:13)(cid:13)W −1(cid:13)(cid:13)1
Xi=1
≤ c2
and kEWk∞ ≤ ǫ1
1 − c1ǫ1

∞ +(cid:13)(cid:13)W −1(cid:13)(cid:13)

1 kEWk2

∞ + ···

c2
1ǫ1

=

4

3

c2
1ǫ1

1 − c1ǫ1 ≤ ǫ
⇒ c2
1 + c1ǫ) ≤ ǫ
⇒ ǫ1 ≤

1ǫ1 ≤ ǫ − c1ǫ1ǫ

ǫ

c1(c1 + ǫ)

≤ ǫ/c2

1

⇒(cid:13)(cid:13)(cid:13)
ˆW − W(cid:13)(cid:13)(cid:13)∞ ≤ ǫ , if kEWk∞ ≤ ǫ1 = ǫ/c2

1

To complete the proof, note that the elements of EW are distributed as follows: EEW (i, j) = 0 and EEW (i, j)2 ≤
1/4. Therefore if we apply Hoeffding inequality to the concentration of EW (i, j), we get that if we sample W (i, j)
˜m ≥ 1
δ times, then with probability ≥ 1 − δ, |EW (i, j)| ≤ ǫ1. To union bound over all l2 elements of W , we
1. Plugging these into the Hoeffding inequality, we ﬁnish the
need to set δ ← δ/l2. Besides, we also have ǫ1 ← ǫ/c2
proof.

log 2

2ǫ2

1

18

