6
1
0
2

 
r
a

 

M
6
1

 
 
]
T
S
h
t
a
m

.

[
 
 

1
v
0
9
2
5
0

.

3
0
6
1
:
v
i
X
r
a

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR

LÉVY-DRIVEN SDE’S

ARNAUD GLOTER, DASHA LOUKIANOVA AND HILMAR MAI

Abstract. The problem of drift estimation for the solution X of a stochastic diﬀerential equation
with Lévy-type jumps is considered under discrete high-frequency observations with a growing
observation window. An eﬃcient and asymptotically normal estimator for the drift parameter
is constructed under minimal conditions on the jump behavior and the sampling scheme.
In
the case of a bounded jump measure density these conditions reduce to n∆3−ε
n → 0, where n
is the number of observations and ∆n is the maximal sampling step. This result relaxes the
condition n∆2
→ 0 usually required for joint estimation of drift and diﬀusion coeﬃcient for
SDE’s with jumps. The main challenge in this estimation problem stems from the appearance
of the unobserved continuous part X c in the likelihood function.
In order to construct the
drift estimator we recover this continuous part from discrete observations. More precisely, we
estimate, in a nonparametric way, stochastic integrals with respect to X c. Convergence results
of independent interest are proved for these nonparametric estimators. Finally, we illustrate the
behavior of our drift estimator for a number of popular Lévy–driven models from ﬁnance.

n

1. Introduction

The class of solutions of Lévy-driven stochastic diﬀerential equations (SDE’s) has recently at-
tracted a lot of attention in the literature due to its many applications in various area such as
ﬁnance, physics and neuroscience. Indeed, it includes important examples taken from ﬁnance such
as the well-known Barndorﬀ-Nielsen-Shephard model, the Kou model and the Merton model (cf.
Barndorﬀ-Nielsen and Shephard [2001], Kou [2002] and Merton [1976]) as well as the stochastic
Morris-Lecar neuron model (cf. for example Ditlevsen and Greenwood [2013]) from neuroscience to
name just a few. Consequently, statistical inference for these models has recently become an active
domain of research.

In this work we aim at estimating the unknown drift parameter θ ∈ Θ ⊂ Rd based on discrete

observations X θ

t0, . . . , X θ

tn of the process X θ given by
0 +ˆ t

s ) ds +ˆ t

b(θ, X θ

σ(X θ

0

0

s ) dWs +ˆ t

0

γ(X θ

s−) dLs,

t ∈ R+,

(1)

X θ

t = X θ

where W = (Wt)t≥0 is a one-dimensional Brownian motion and L a pure jump Lévy process with
Lévy measure ν.

We consider here the setting of high frequency observations with a growing time window, i.e.
for the discrete sample X θ
tn with 0 ≤ t0 ≤ . . . ≤ tn we assume that the sampling step
∆n := max{ti − ti−1 : 1 ≤ i ≤ n} tends to 0 and tn → ∞ as n → ∞. It is well known that due
to the presence of the diﬀusion part, one can only estimate the drift consistently if tn → ∞. A

t0 , . . . , X θ

Key words and phrases. Lévy-driven SDE, eﬃcient drift estimation, maximum likelihood estimation, high fre-

quency data, ergodic properties.

1

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

2

crucial point for applications in the high frequency setting is to impose minimal conditions on the
sampling step size ∆n. This will be one of our main objectives in this paper.

The topic of high frequency estimation for discretely observed diﬀusions without jumps is well
developed by now. See for example Yoshida [1992], Kessler [1997] and references therein for joint
estimation of drift and diﬀusion coeﬃcient. Less results are known when a jump component is
added to the process. In the case of high frequency estimation for diﬀusion with an additional jump
component Masuda [2013] investigates Gaussian quasi-likelihood estimators of a joint drift-diﬀusion-
jump part parameter. Shimizu and Yoshida [2006] deﬁne a contrast-type estimation function, for
joint estimation of drift, diﬀusion and jump parts when the jumps are of compound Poisson type.
Shimizu [2006] generalizes these results to include more general driving Lévy processes. The LAN
property for drift and diﬀusion parameters is studied in Tran [2014] via Malliavin calculus tech-
niques. In all these papers joint estimation is considered under conditions on the sampling scheme
and the Lévy measure, which, in the case of a bounded jump measure density, is at best n∆2
n → 0.
It is important to note here that the principles of the estimation of the drift, diﬀusion or jump
law parameters are of completely diﬀerent nature. The estimation of the volatility is feasible on
a compact interval, whereas the estimation of the drift and the jump law requires a growing time
window. Also due to the Poisson structure of the jump part the estimation of the jump parameter
can be well separated from those of the drift and the diﬀusion part. In this work we focus therefore
on the estimation of the drift parameter only and construct a consistent, asymptotically normal
and eﬃcient estimator, under conditions on the jump behavior and the sampling scheme, which, in
the case of bounded jump measure density reduce to n∆3−ε

A natural approach to estimate the unknown drift parameter would be to use a maximum
likelihood estimation, but the likelihood function based on the discrete sample is not tractable in
this setting, since it depends on the transition densities of X which are not explicitly known. On
the contrary, the continuous-time likelihood function is explicit. Our aim is to approximate this
function from discrete data and hence deﬁne some contrast function. The main diﬃculty is that
the continuous-time likelihood involves the continuous part X c of X that is unobservable under
discrete sampling. Intuitively, this tells us that the continuous part X c has to be recovered, hence
the jumps of X have to be removed in order to obtain an approximation of the continuous likelihood
function.

n → 0.

The question of estimation of the continuous part of an Itô-semimartingale appears naturally in
many statistical inference questions (cf. for example Mancini [2011] and Bibinger and Winkelmann
[2015]) and constitutes in itself an interesting nonparametric problem.
In this article we study
the question of estimation of stochastic integrals with respect to the continuous part of X from a
discrete sample of X. Propositions 6 and 7 give explicit rates of convergence for our estimators of
these quantities. Besides being of independent interest these results constitute the main tool for
the asymptotic analysis of our drift estimators.

The technique we use in order to recover stochastic integrals with respect to the continuous
part of X consists in comparing the increments of X with a threshold vn, suggested by the typical
behavior of a diﬀusion path. This approach will be called jump ﬁltering in the sequel. Similar
ideas of thresholding were also used in Shimizu and Yoshida [2006], Mancini [2011], Mai [2014] and
Bibinger and Winkelmann [2015]. In this article we have paid particular attention to the study of
the joint law of the biggest jump and of the total contribution of the other jumps in each sampling
interval (Lemma 16), which permits us to improve existing conditions on the sampling scheme in
the drift estimation problem.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

3

The drift estimator is then constructed by applying a jump ﬁlter to the discretized likelihood
function and maximizing the resulting criterion function to obtain what will be called the ﬁltered
MLE (FMLE). To study the properties of the FMLE we ﬁrst focus on the MLE obtained from
continuous observations and show that this MLE is asymptotically normal (Theorem 13) with
explicit asymptotic variance. We then prove the LAN property which gives by Hàjek-Le Cam’s
convolution theorem that the continuous MLE is eﬃcient (Theorem 14). We show in the next
step that the FMLE attains asymptotically the same distribution as the MLE based on continuous
observations, which proves the eﬃciency of the FMLE (Theorems 3, 4). The last step is mainly
based on our results for the jump ﬁlter (Propositions 6 and 7).

The consistency of the FMLE is obtained without further assumptions on the sampling scheme.
The asymptotic normality necessitates some additional conditions on the rate at which ∆n goes
to 0 that depend on the behavior of the Lévy measure ν near zero.
In the case where ν has a
bounded Lebesgue density these conditions reduce to n∆3−ε
n → 0 for some ε > 0. We believe that
this condition is unavoidable, because it is already necessary in the Euler discretization scheme
of the stochastic integral with respect to X c (Lemma 10). It is in accordance with the condition
n∆3
n → 0 of Florens-Zimrou [1989] in the case of drift estimation for continuous diﬀusions, hence
our result can be seen as a generalization of Florens-Zimrou [1989] to the presence of jumps.
In the literature on joint estimation of drift and diﬀusion parameters for models with diﬀusion
and jump part the condition n∆2
n → 0 is usually required (cf. Masuda [2013], Shimizu and Yoshida
[2006] and Shimizu [2006]). The same condition on the sampling scheme appears for joint estimation
in the case of continuous diﬀusions in Yoshida [1992]. Hence, our work shows that by focusing on
drift estimation the condition n∆2

n → 0 can be relaxed in the presence of jumps as well.

As will be seen in Section 5 many popular models lead to explicit estimators, which do not

require the knowledge of the diﬀusion coeﬃcient and that perform well in numerical examples.

The structure of the paper is as follows. In Section 2 the problem setting and the main assump-
tions of this work are introduced. Section 3 contains the construction of the drift estimator from
discrete observations together with the main results. In Section 4 we discuss the approximation of
the continuous martingale part and prove the convergence of the jump ﬁlter. Section 5 is devoted to
applications to popular parametric jump diﬀusion models and some numerical examples. Finally,
in Section 6 and 7 we prove the main results and the convergence of the jump ﬁlter respectively,
and Section 8 contains some auxiliary results that are frequently used in the sequel.

Let Θ be a compact subset of Rd and X θ a solution to (1) which can be rewritten as

2. Model, assumptions and ergodicity

X θ

t = X θ

0 +ˆ t

0

b(θ, X θ

s ) ds +ˆ t

0

σ(X θ

s ) dWs +ˆ t

0 ˆR

γ(X θ

s−)zµ(ds, dz),

t ∈ R+,

where W = (Wt)t≥0 is a one-dimensional Brownian motion and µ is the Poisson random measure
on [0,∞) × R associated with the jumps of the Lévy process L = (Lt)t≥0 with Lévy-Khintchine
triplet (0, 0, ν) such that ´R |z|dν(z) < ∞. The initial condition X θ
0 , W and L are independent. We
assume without loss of generality that 0 ∈ Θ and b(0,·) ≡ 0.
2.1. Assumptions. We suppose that the functions b : Θ × R → R, σ : R → R and γ : R → R
satisfy the following assumptions:
Assumption 1. The functions σ(x), γ(x) and for all θ ∈ Θ, b(θ, x) are globally Lipschitz. Moreover,
the Lipschitz constant of b is uniformly bounded on Θ.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

4

Under Assumption 1 equation (1) admits a unique non-explosive càdlàg adapted solution pos-

sessing the strong Markov property, cf. Applebaum [2009](Theorems 6.2.9. and 6.4.6).
Assumption 2. For all θ ∈ Θ there exists a constant t > 0, such that X θ
t (x, y)
with respect to the Lebesgue measure on R; bounded in y ∈ R and in x ∈ K for every compact K ⊂ R.
Moreover, for every x ∈ R, and every open ball U ∈ R there exists a point z = z(x, U ) ∈ supp(ν)
such that γ(x)z ∈ U.

t admits a density pθ

The last Assumption was used in Masuda [2007] to prove the irreducibility of the process X θ.

See also Masuda [2009] for other sets of conditions, suﬃcient for irreducibility.

Assumption 3 (Ergodicity).

(i): For all q > 0, ´|z|>1 |z|qν(dz) < ∞.

(ii): For all θ ∈ Θ there exists a constant C > 0 such that xb(θ, x) ≤ −C|x|2, if |x| → ∞.
(iii): |γ(x)|/|x| → 0 as |x| → ∞.
(iv): |σ(x)|/|x| → 0 as |x| → ∞.
(v): ∀θ ∈ Θ, ∀q > 0 we have E|X θ

0|q < ∞.

Assumption 2 ensures together with Assumption 3 the existence of unique invariant distribution

πθ, as well as the ergodicity of the process X θ, as stated in Lemma 1 below.

Assumption 4 (Jumps).

(i): The jump coeﬃcient γ is bounded from below, i.e. inf x∈R |γ(x)| :=

γmin > 0 (wlog we suppose γmin ≥ 1).

(ii): the Lévy measure ν satisﬁes ´0<|z|≤1 |z|ν(dz) < ∞,
(iii): the Lévy measure ν is absolutely continuous with respect to the Lebesgue measure,
(iv): the jump coeﬃcient γ is upper bounded, i.e. supx∈R |γ(x)| := γmax < ∞.

Note that the integrability condition given by the Assumption 4 (ii) is automatically satisﬁed in
the ﬁnite activity case ν(R) < ∞. This condition insures that the trajectories of the driving Lévy
process L are a.s. of ﬁnite variation and hence the integral with respect to L in (1) can be deﬁned
as a deterministic Lebesgue-Stieltjes integral. The third and the fourth point of the Assumption 4
are technical and need in the inﬁnite activity case.

The following assumption insures the existence of the likelihood function.

Assumption 5 (Non-degeneracy). There exists some α > 0, such that σ2(x) ≥ α for all x ∈ R.
Assumption 6 (Identiﬁability). For all θ 6= θ′, (θ, θ′) ∈ Θ2,

ˆR

(b(θ, x) − b(θ′, x))2

σ2(x)

dπθ(x) > 0

We can see (cf. Proposition 17) that this last assumption is equivalent to

∀θ 6= θ′,

(θ, θ′) ∈ Θ2,

(2)
For f : Θ → R denote by ∇θf : Θ → Rd the gradient column vector and by ∂2
the Hessian matrix of f . We deﬁne |θ| as the Euclidian norm of θ ∈ Rd, and |∂2
θi,θj
as the Euclidian norm of the Hessian matrix of f . The following assumption is used to insure the
uniform in θ convergence needed in the proofs of consistency and asymptotic normality:

θ f :=(cid:16)∂2
θ f| :=qPn

θi,θj f(cid:17)1≤i,j≤d
i,j=1 |∂2
f|2

b(θ, .) 6= b(θ′, .).

Assumption 7 (Hölder-continuity of drift).

(i): For all x ∈ R, b(., x) is Hölder-continuous

with respect to θ ∈ Θ:

∀θ, θ′,

|b(θ, x) − b(θ′, x)| ≤ K(x)|θ − θ′|κ,

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

5

(ii): For all x ∈ R, b(., x) is twice continuously diﬀerentiable with respect to θ and ∇b(., x)

where 0 < κ ≤ 1 and K : R → R+ is at most of polynomial growth.
and ∂2b(., x) are Hölder-continuous with respect to θ ∈ Θ :

∀θ, θ′,
∀θ, θ′,

|∇b(θ, x) − ∇b(θ′, x)| ≤ K1(x)|θ − θ′|κ1
|∂2
θ b(θ, x) − ∂2
θ b(θ′, x)| ≤ K2(x)|θ − θ′|κ2

where 0 < κ1, κ2 ≤ 1 and K1, K2 : R → R+ are at most of polynomial growth.

We also need the following technical assumption:

Assumption 8. The functions b, σ,∇θb, ∂2
The functions σ′, σ′′ as well as the functions

θ b are twice continuously diﬀerentiable with respect to x.

x 7→ sup
θ∈Θ|

∂i+jb(θ, x)

∂ix∂jθ

|

are sub-polynomial for all 0 ≤ i ≤ 2 and 0 ≤ j ≤ 2.

Deﬁne the asymptotic Fisher information by

(3)

I(θ) =(cid:18)ˆR

∂θib(θ, x)∂θj b(θ, x)

σ2(x)

πθ(dx)(cid:19)1≤i,j≤d

.

Assumption 9. For all θ ∈ Θ, I(θ) is non-degenerated.
2.2. Ergodic properties of solutions. In all our statistical analysis an important role is played
by ergodic properties of solutions of equation (1). The following lemma is a generalization of a
result of Masuda [2007]. It states conditions for the existence of an invariant measure πθ such that
an ergodic theorem holds and moments of all order exist. A proof is given in Section 8.
Lemma 1. Under assumptions (1) to (4), for all θ ∈ Θ, X θ admits a unique invariant distribution
πθ and the ergodic theorem holds:

(1) for every measurable function g : R → R satisfying πθ(g) < ∞, we have a.s.

1

t ˆ t

0

lim
t→∞

g(X θ

s )ds = πθ(g).

(2) For all q > 0, πθ(|x|q) < ∞.
(3) For all q > 0, supt∈R E[|X θ
(4) Moreover,

t |q] < ∞ and supt∈R E[|X θ

t−|q] < ∞.

1

t ˆ t

0

lim
t→∞

E[|X θ

s|q]ds = πθ(|x|q).

3. Construction of the estimator and main results

We deﬁne a discrete approximation to the continuous time likelihood function by employing a
jump ﬁltering technique and hence obtain an approximate maximum likelihood estimator. We prove
that this drift estimator attains asymptotically the same performance as the maximum likelihood
estimator based on continuous observations under suitable assumptions on the jump behavior of
the driving Lévy process L.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

6

3.1. Construction of the estimator. Let X θ be given by (1). We denote by P θ the law of X θ
on the Skorokhod space D[0,∞) of real-valued càd làg functions, and P θ
its restriction on D[0, t).
From now on we denote the true parameter value by θ⋆, an interior point of the parameter space Θ
that we want to estimate. We shorten X for X θ⋆
. Suppose
that we observe a ﬁnite sample

and P, E, π for respectively P θ⋆

, Eθ⋆

, πθ⋆

t

(4)

Xt0 , . . . , Xtn ;

0 = t0 ≤ t1 ≤ . . . ≤ tn.

Every observation time point depends also on n, but to simplify our notation we suppress this
index. We will be working in a high-frequency setting, i.e.

∆n := sup

i=0,...,n−1

(ti+1 − ti) n→∞−−−−→ 0.

We assume limn→∞ tn = ∞ and n∆n = O(tn) as n → ∞. Under Assumption 5, P θ
t are
mutually locally absolutely continuous for any θ ∈ Θ (cf. for example Jacod and Shiryaev [2003])
and the likelihood function is given by

t and P 0

(5)

Lt(θ, X) =

dP θ
t
dP 0
t

(X) = exp(cid:18)ˆ t

0

We deﬁne the log-likelihood function as

σ(Xs)−2b(θ, Xs) dX c

s −

1

2 ˆ t

0

σ(Xs)−2b(θ, Xs)2 ds(cid:19) .

(6)

ℓt(θ) := lnLt(θ, X).

The crucial point here is the appearance of X c in (5), since when X is observed discretely, its
continuous part remains unknown. To handle this problem we use a jump ﬁlter as described below.
i X = Xti − Xti−1 ,

i g = gti − gti−1, i = 1, . . . n. In particular, ∆n
i Id = ti − ti−1. Let ε ∈ (0, 1/2) and denote

For g : [0, tn] → R, set ∆n
ti−1 and ∆n
i X c = X c

ti − X c

∆n

(7)
Deﬁne a discrete, jump-ﬁltered approximation ℓn

n

vn = ∆1/2−ε

, n ≥ 1.

tn of the log-likelihood function as follows.

(8)

ℓn
tn(θ) =

σ(Xti−1 )−2b(θ, Xti−1 )∆n

i X 1|∆n

i X|≤vn −

1
2

σ(Xti−1 )−2b(θ, Xti−1 )2∆n

i Id.

The cut-oﬀ sequence (vn) is chosen in order to asymptotically ﬁlter the increments of X containing
jumps. The increments of the continuous martingale part are typically of the order ∆1/2
n , which
leads to the deﬁnition (7). The challenge now is to ﬁnd suitable conditions on ∆n, ǫ and ν to make
the likelihood (6) well approximated by its discretized and jump ﬁltered counterpart (8) even in
the case of inﬁnite activity. Of course we can choose ε arbitrarily small, which is a choice we have
in mind. Finally, we deﬁne an estimator ˆθn of θ⋆ as
ˆθn ∈ argmax
(9)
θ∈Θ
and in the sequel we call it the ﬁltered MLE (FMLE).

ℓn
tn(θ)

3.2. Main results. The following theorem gives a general consistency result for the FMLE ˆθn that
holds for ﬁnite and inﬁnite activity without further assumptions on n, ∆n and vn.
Theorem 2 (Consistency). Suppose that Assumptions 1 to 8 hold, then the FMLE ˆθn is consistent
in probability:

ˆθn

P−→ θ⋆,

n → ∞.

n

Xi=1

n

Xi=1

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

7

To obtain a central limit theorem for the estimation error we consider ﬁnite and inﬁnite activity
separately, since we obtain diﬀerent conditions on the relation of n, ∆n and the cut-oﬀ sequence
vn.

Theorem 3 (Asymptotic normality: ﬁnite activity). Assume that the Lévy process L has a ﬁnite
jump activity : ν(R) < ∞. Suppose that Assumptions 1 to 3, 4(i) and 6 to 9 hold.

n ´|z|<2vn |z|ν(dz) → 0 as n →

If n∆3−ε

n → 0, √n∆1−ε/2

n

∞, then we conclude that the FMLE ˆθn is asymptotically normal:

ν(dz)(cid:17)1−ε/2

→ 0 and √n∆1/2

(cid:16)´|z|≤2vn
n (ˆθn − θ⋆) L→ N (0, I−1(θ⋆)), n → ∞,
t1/2

where I is the Fisher information given by (3).

Furthermore, the FMLE ˆθn is asymptotically eﬃcient in the sense of the Hàjek-Le Cam convo-

lution theorem.

Remark 1. If ν has a bounded Lebesgue density, the conditions of the Theorem 3 on the sampling
scheme and the jump behavior reduce to n∆3−4ε

n → 0.

The following theorem generalizes the results of Theorem 3 to driving Lévy processes of inﬁnite

activity.

Theorem 4 (Asymptotic normality: general case). Assume that the Lévy process L has inﬁnite
jump activity : ν(R) = ∞. Suppose Assumptions 1 to 9 hold. If n∆3−ε

n → 0,

pn∆n ˆ

|z|≤3vn/γmin |z|ν(dz)!1−ε/2

and √n∆3/2−2ε

n

→ 0

 ˆ

|z|≥3vn/γmin

ν(dz)!1−ε/2

→ 0

as n → ∞, then all conclusions of Theorem 3 hold.

Theorem 4 applies for both ﬁnite and inﬁnite jump activity. Besides diﬀerent conditions on the
sampling scheme and the behavior of ν near zero it uses that the Lévy measure ν admits a density,
which is not supposed in Theorem 3. In the case where ν admits a bounded Lebesgue density, all
the conditions on the ∆n and n of the Theorem 4 became n∆3−˜ε
n → 0 for some ˜ε > 0 as in the
Theorem 3.

Example 5 (tempered stable jumps). To illustrate the inﬂuence of the jump behavior of L on the
conditions on n and ∆n given in Theorem 4 let us consider the example of a tempered α-stable
driving Lévy process. Tempered stable processes have been popular in ﬁnancial modeling to over-
come the limitations of the classical models based on Brownian motion alone (cf. Cont and Tankov
[2004]). The Lévy measure in this case has an unbounded and non-integrable density given by

ν(dz) = C|z|−(1+α)e−λ|z|dz

The conditions on n, ∆n and ν in Theorem 4 can now be summarized as n∆2−α−˜ǫ

with λ > 0 and a normalizing constant C > 0 that satisﬁes the conditions of Theorem 4 if 0 < α < 1.
→ 0 for some
ǫ > 0. We observe that a higher Blumenthal-Getoor index α requires a faster convergence ∆n to
zero. This is in line with the intuition that when the intensity of small jumps increases (i.e. α
increases) more and more frequent observations are needed to have a suﬃcient performance of the
jump ﬁlter.

n

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

8

4. Nonparametric estimation of X c via jump filtering.

The estimation problem considered in this work leads naturally to the more fundamental problem
of approximation of the continuous martingale part X c from discrete observations of a jump diﬀusion
X. In this section we prove approximation results of this sort for integral functionals with respect
to X c. Since we need both uniform and non-uniform versions for the drift estimation problem, both
settings will be discussed. The following proposition concerns the ﬁnite activity case. The cut-oﬀ
sequence vn and ε were deﬁned in (7).

Proposition 6 (jump ﬁltering: ﬁnite activity). Suppose that L is of ﬁnite activity and Assumptions
1 to 4 hold. Suppose that f : Θ × R → R satisﬁes:

a) for all x ∈ R, f (., x) is Hölder continuous with respect to θ ∈ Θ :
|f (θ, x) − f (θ′, x)| ≤ C(x)|θ − θ′|κ,

∀θ, θ′,

where 0 < κ ≤ 1 and C : R → R+ is at most of polynomial growth;
at most of polynomial growth.

b) for all θ ∈ Θ, f (θ, .) ∈ C2(R) and supθ∈Θ |f (θ, .)|, supθ∈Θ |f′x(θ, .)| and supθ∈Θ |f′′x (θ, .)| are

Then the following statements hold:

(i) without any assumption on the way that ∆n → 0 as n → ∞,

(n∆n)−1 sup

f (θ, Xs) dX c

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ˆ tn
n → 0, √n∆1−ε/2
n ´|z|≤2vn |z|ν(dz) → 0 as n → ∞, then for any θ ∈ Θ,

s −
ν(dz)(cid:17)1−ε/2

(cid:16)´|z|≤2vn

f (θ, Xti−1)∆n

→ 0 and

n

Xi=1

0

n

i X 1|∆n

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(ii) if n∆3−ε
√n∆1/2

P−→ 0;

(10)

(n∆n)−1/2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ˆ tn

0

f (θ, Xs) dX c

s −

n

Xi=1

f (θ, Xti−1)∆n

i X 1|∆n

P−→ 0.

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

The case of inﬁnite activity is treated in the following proposition.

Proposition 7 (jump ﬁltering:
inﬁnite activity). Suppose that L is of inﬁnite activity and As-
sumptions 1 to 4 hold. Suppose that f : Θ × R → R satisﬁes the assumptions of Proposition 6.
Then,

(i) statement (i) of Proposition 6 holds;
(ii) if n∆3−ε

n → 0,

pn∆n ˆ

|z|≤3vn/γmin |z|ν(dz)!1−ε/2

 ˆ
as n → ∞, then for any θ ∈ Θ, the convergence (10) holds.

→ 0 and √n∆3/2−ε

n

ν(dz)!1−ε/2

→ 0

|z|≥3vn/γmin

The proofs of both propositions are based on the following three lemmas. Lemma 8 and 9
describe the approximation of the discretized stochastic integral with respect to X c by the jump
ﬁlter in the cases of ﬁnite and inﬁnite activity, respectively. To prove the propositions 6 and 7 we
also need a convergence result for the Euler scheme in order to approximate the stochastic integral
with respect to X c by the corresponding discrete sum. This will be done in Lemma 10.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

9

Lemma 8 (jump ﬁltering error: ﬁnite activity). Assume that L is of ﬁnite activity and f : Θ× R →
R is such that supθ∈Θ |f (θ, x)| is sub-polynomial. Under Assumption 1 to 4, we obtain

(i)

i X 1|∆n

i X|≤vn(cid:1)| = OL1(n∆3/2−ε/2

n

).

sup

θ∈Θ|

n

Xi=1

f (θ, Xti−1 )(cid:0)∆n
i X c − ∆n
n → 0 as n → ∞,
i X c − ∆n

n

(ii) for all θ ∈ Θ, if n∆3−ε
f (θ, Xti−1 )(cid:0)∆n
n∆5/2−ε

Xi=1
+ OL1

n

i X|≤vn(cid:1) = oP (cid:16)pn∆n(cid:17)
i X 1|∆n
 ˆ

ν(dz)!1−ε/2

|z|≤2vn

+ n∆nˆ

+ n∆3/2−ε/2

n

|z|≤2vn |z|ν(dz)
 .

The next lemma extends the uniform bound to the case of inﬁnite activity.

Lemma 9 (jump ﬁltering error:
Θ × R → R is such that supθ∈Θ |f (θ, x)| is sub-polynomial.

(i) Under Assumption 1 to 4, we obtain

inﬁnite activity). Assume that L is of inﬁnite activity and f :

n

sup

Xi=1
f (θ, Xti−1)(cid:0)∆n
θ∈Θ|
OL1
n∆n ˆ

i X c − ∆n
|z|≤3vn |z|ν(dz)!1−ε/2
n (cid:16)´|z|≥3vn/γmin
i X c − ∆n

n

(ii) for all θ ∈ Θ, if n∆3−ε
Xi=1
f (θ, Xti−1 )(cid:0)∆n
+ oL1 n∆2−ε
n (ˆ

i X|≤vn(cid:1) = oP (cid:16)pn∆n(cid:17)
i X 1|∆n
ν(dz))1−ε/2! + OL1 n∆n(ˆ

i X 1|∆n

+ n∆3/2−ε

i X|≤vn(cid:1)| =
 ˆ
→ 0, as n → ∞, then

|z|≥vn/γmin

n

ν(dz)(cid:17)2−ε

ν(dz)!1−ε/2


|z|≤3vn/γmin |z|ν(dz))1−ε/2! .
Lemma 10 (Euler scheme). Suppose that f : Θ × R → R satisﬁes the following assumptions:

The approximation of the stochastic integral is treated in the following lemma.

|z|≥3vn/γmin

a) for all x ∈ R, f (., x) is Hölder continuous with respect to θ ∈ Θ :
|f (θ, x) − f (θ′, x)| ≤ K(x)|θ − θ′|κ;

∀θ, θ′,

b) for all θ ∈ Θ, f (θ, .) ∈ C2(R) and supθ∈Θ |f (θ, .)|, supθ∈Θ |f′x(θ, .)| and supθ∈Θ |f′′x (θ, .)| are

where 0 < κ ≤ 1 and K : R → R+ is at most of polynomial growth;
at most of polynomial growth.
Under Assumptions 1 to 4, we obtain

(i) as n → ∞,

sup
θ∈Θ

(n∆n)−1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

ˆ tn

0

f (θ, Xs) dX c

s −

n

Xi=1

f (θ, Xti−1)∆n

i X c(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

P−→ 0;

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

10

(ii) if n∆3−ε

n → 0, then, as n → ∞,
ˆ tn
∀θ ∈ Θ,

0

(n∆n)−1/2(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f (θ, Xs) dX c

s −

f (θ, Xti−1 )∆n

P−→ 0.

n

Xi=1

i X c(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

We have now collected all the tools to prove the convergence of the jump ﬁlter approximation
towards integral functionals with respect to the continuous martingale part as stated in Proposition
6 and 7.

Proof of Proposition 6. We decompose the diﬀerence as follows:

f (θ, Xs) dX c

f (θ, Xti−1 )∆n

i X 1|∆n

ˆ tn

0

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(11)

ˆ tn

0

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

Xi=1

n

s −
Xi=1

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

≤

n

Xi=1

i X c(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

+(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f (θ, Xs) dX c

s −

f (θ, Xti−1)∆n

f (θ, Xti−1)∆n

i X c −

f (θ, Xti−1 )∆n

i X 1|∆n

We ﬁrst prove (i). By Lemma 10, the ﬁrst term on the right hand side of (11) divided by n∆n goes
to zero uniformly, without any condition on ∆n. Combining it with (i) of the Lemma 8 we get the
result.

We now prove (ii). For the ﬁrst term of (11) divided by (n∆n)1/2 we use (ii) of the Lemma 10.

Moreover, the (ii) of the Lemma 8, gives, for any θ ∈ Θ,

n

(n∆n)−1/2

Xi=1
f (θ, Xti−1)(cid:0)∆n
i X c − ∆n
 ˆ
√n∆2−ε
n + √n∆1−ε/2

n

|z|≤2vn

i X 1|∆n

i X|≤vn(cid:1) = oP (1)+
+ √n∆1/2
n ˆ

ν(dz)!1−ε/2

OL1


under conditions (ii) of the proposition.

|z|≤2vn |z|ν(dz)


P−→ 0

(cid:3)

Proof of Proposition 7. We use the decomposition (11)

and prove ﬁrst the statement (i). Using the Lemma 10 the ﬁrst term of (11) divided by n∆n

goes to zero uniformly without any condition on ∆n.

Lemma 9 together with the Assumption 4 (ii) and the fact that vn = ∆1/2−ε

n

gives

n

Xi=1

(n∆n)−1 sup
θ |

f (θ, Xti−1 )(cid:0)∆n
OL1
|z|≤3vn |z|ν(dz)!1−ε/2
 ˆ
OL1
|z|≤3vn |z|ν(dz)!1−ε/2
 ˆ

+

i X c − ∆n

+ ∆1/2−ε/2

n

∆1/2−ε/2
n
v1−ε/2
n

i X 1|∆iX|≤vn(cid:1)| =
 ˆ
 ˆ

ν(dz)!1−ε/2
 =
|z|≥vn/γmin |z|ν(dz)!1−ε/2


|z|≥vn/γmin

P−→ 0.

Hence statement (i) is proved.
Now we prove statement (ii). For any θ ∈ Θ, under the condition n∆3−ε
n → 0, the second statement
of Lemma 10 gives the convergence to 0 of the ﬁrst term in the decomposition (11), divided by

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

11

√n∆n. The convergence to 0 of the second term of (11), divided by √n∆n, immediately follows
from Lemma 9 and the conditions of (ii).

(cid:3)

When discretizing the likelihood function, we need the following lemma, whose proof can be

found in the Section 8.
Lemma 11. Suppose that Assumptions 1–4 are satisﬁed . Suppose that f : Θ× R → R is such that
∀θ ∈ Θ, f (θ, .) ∈ C1(R) and supθ∈Θ |f′(θ, .)| is sub-polynomial. Then we obtain:

(i) as n → ∞,

ˆ tn

0

f (θ, Xs) ds −

sup

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(ii) if n∆3−ε

n

n→∞−−−−→ 0, then

n

Xi=1

f (θ, Xti−1 )∆n

i Id(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

= OL1(n∆3/2

n );

(n∆n)−1/2|ˆ tn

0

f (θ, Xs) ds −

n

Xi=1

f (θ, Xti−1)∆n

i Id| P−→ 0.

5. Examples and numerical results

In this section we consider concrete applications of the drift estimator in popular jump diﬀusion
models and investigate the numerical performance in ﬁnite sample studies. We consider both
examples with ﬁnite and inﬁnite jump activity.

In the ﬁrst part we give explicit drift estimators for Ornstein-Uhlenbeck-type and CIR processes
and compare there performance in a Monte Carlo study for ﬁnite activity jumps. Then we apply our
method to a hyperbolic diﬀusion process with α-stable jump component of inﬁnite jump activity.
We consider here for convenience only linear models in the drift parameter that lead to explicit
maximum likelihood estimators in order to avoid the need for numerical maximization techniques.
Note that the method developed in this work applies equally well to non-linear models by using
standard maximization methods on the discretized and jump-ﬁltered likelihood function (8).

It turns out that our estimators can be applied even beyond the scope of our theoretical results.
To demonstrate this we include in Section 5.2 models that do not posses moments of all orders and
consider Lévy processes of unbounded variation in our simulations.

5.1. Finite activity. In this section we consider two diﬀerent jump diﬀusion models with ﬁnite
activity jumps. The ﬁrst model will consist of Ornstein-Uhlenbeck-type processes that recently
became popular in ﬁnancial modeling (cf.
for example Barndorﬀ-Nielsen and Shephard [2001]).
In the second part we extend a Cox-Ingersoll-Ross model from ﬁnance (cf. Cox et al. [1985]) by
including jumps and investigate the ﬁnite sample behavior of the drift estimator and jump ﬁlter for
varying observation settings. The jump process L is of compound Poisson type in the case of ﬁnite
activity such that it can be written as

(12)

Lt =

Nt

Xi=1

Zi, for t ≥ 0,

where (Nt)t≥0 is a Poisson process with intensity λ and (Zi)i∈N are i.i.d. real random variables
independent of N , with distribution ν/λ.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

12

5.1.1. Ornstein-Uhlenbeck-type processes. Suppose that we have given a discrete sample

(13)
of an Ornstein-Uhlenbeck-type (OU) process (Xt)t≥0 that is deﬁned as a solution of the stochastic
diﬀerential equation

for ti = i∆n and i = 0, . . . , n,

Xt0 , . . . , Xtn

dXt = (θ2 − θ1Xt) dt + σ dWt + dLt X0 = x,

where (Wt)t≥0 is a standard Brownian motion and (Lt)t≥0 a pure jump Lévy process. Our goal is
to estimate the unknown drift parameter θ = (θ1, θ2) ∈ R2. The volatility parameter σ > 0 might
be unknown and can be seen as a nuisance parameter. The jump component (Lt)t≥0 will be of
compound Poisson type, i.e. it can be written as in (12) with intensity λ and the jump heights Zi
are supposed to be iid with exponential distribution with rate 1.

From (8) and (9) we ﬁnd that the FMLE for θ is the solution ˆθOU

n = (ˆθOU

1,n , ˆθOU

2,n ) to the following

set of linear equations in θ1 and θ2.

θ2In(X, 1) −Pn

i=1 ∆n

i X 1|∆n

i X 1|∆n

i=1 Xti ∆n
In(X 2)
i X|≤vn + θ1In(X, 1)
tn

,

i X|≤vn

,

θ1 =

θ2 = Pn

X p

ti∆n

i Id for p ∈ R.

(14)

(15)

where we introduced the functional

The FLME for the ﬁrst component of θ results in
i=1 ∆n

In(X, 1)2

n

In(X, p) :=

Xi=1
In(X, 2) (cid:19)−1 In(X, 1)Pn

ˆθOU

1,n =(cid:18)1 −

i X 1|∆n

i X|≤vn − tnPn

tnIn(X, 2)

i=1 Xti∆n

i X 1|∆n

i X|≤vn

.

The second component ˆθOU

2,n follows now easily by plugging ˆθOU

1,n into (14).

In Table 1 we give simulation results for ˆθOU

1,n . The given mean and standard deviation are each
based on 500 Monte Carlo samples of ˆθOU
in order to
1,n .
approximate well the continuous martingale part that appeared in the likelihood function (5). We
compare diﬀerent observation schemes and diﬀerent jump intensities λ for true parameter values
given by θ1 = 2 and θ2 = 0. The drift estimator performs well over the whole range of settings
provide that the discretization distance ∆n is suﬃciently small. We also give the average number
of jumps that were detected by the jump ﬁlter and observe that this number scales as expected
linearly in tn.

In this example we choose vn = ∆1/3

n

5.1.2. Cox-Ingersoll-Ross (CIR) processes with jumps. We deﬁne a CIR or square-root process
X = (Xt)t≥0 with jumps as a solution to the SDE

where θ1, θ2, σ > 0, (Wt) is a standard Brownian motion and (Lt) a pure jump Lévy process.
The two-dimensional drift parameter θ = (θ1, θ2) is unknown and will be estimated from discrete
observations of X as in (13).

Xt = (θ1 − θ2Xt) dt + σpXt dWt + dLt,

The classical CIR process without jumps (e.g. Lt ≡ 0) has the property that it stays non-
negative at all times which makes it an interesting model for ﬁnancial applications e.g. in interest
rate modeling (Vasicek model) and stochastic volatility models (Heston model). We consider here

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

13

tn

2

5

10

λ = 1

λ = 6

n

mean std dev jumps ﬁlt mean std dev jumps ﬁlt

100
300
600
800
600
1200
4000
6000
600
2000

1.4
1.8
2.0
2.0
1.4
1.8
2.0
2.1
1.2
2.0

0.7
0.8
0.8
0.8
0.6
0.6
0.7
0.7
0.26
0.27

6.5
6.8
7.9
7.2
13.1
13.6
13.6
12.4
19.1
21.6

1.4
1.7
1.9
2.0
1.3
1.7
1.8
1.9
1.3
1.6

0.6
0.6
0.5
0.6
0.39
0.39
0.39
0.37
0.21
0.2

15.8
15.9
16.3
16.5
39.5
40.4
41.4
41.5
67
75

Table 1. Monte Carlo estimates of mean and standard deviation from 500 samples
of ˆθOU
1,n for an OU process with compound Poisson jumps with intensity λ and true
parameter θ1 = 2.

therefore a jump component (Lt) of compound Poisson type that exhibits only positive jumps such
that X will stay non-negative. In fact, we take a driving Lévy process (Lt) as in (12) with intensity
λ = 1 and exponentially distributed jumps with rate η > 0, e.g. Zi ∼ Exp(η).
(9). It is given as the solution ˆθCIR
parameters θ1 and θ2.

The ﬁltered maximum likelihood estimator for θ is this model can be easily derived from (8) and
2,n ) to the following set of linear equations in the

n = (ˆθCIR

1,n , ˆθCIR

(16)

θ1 =

θ2tn −Pn

i=1 X−1

ti ∆n
In(X,−1)

i X 1|∆n

i X|≤vn

,

θ2 =

θ1tn −Pn

i X 1|∆n

i=1 ∆n
In(X, 1)

i X|≤vn

,

where In(X, p) for p ∈ R was deﬁned in (15). We obtain for ˆθCIR
2,n = (In(X,−1)In(X, 1) − tn)−1  n
Xi=1

i X 1|∆n

ti ∆n

ˆθCIR

X−1

i X|≤vn − In(X,−1)

2,n the FMLE

∆n

i X 1|∆n

i X|≤vn! .

n

Xi=1

The ﬁrst component ˆθCIR

1,n follows now immediately by plugging ˆθCIR

2,n into (16).

To obtain Monte Carlo estimates of mean and standard deviation of ˆθCIR

n we simulate discrete
samples of X on an equidistant grid as in the previous example. We take vn = ∆1/3
in order to
approximate the continuous martingale part of X. In Table 2 we report the results for ˆθCIR
2,n from
1000 Monte Carlo samples each. The results are given for diﬀerent tn, n and σ for true parameter
values θ1 = 0.1 and θ2 = 2. We ﬁnd that ˆθCIR
2,n performs well as long as the discretization step size
∆n is ﬁne enough such that a high-frequency approximation becomes valid.

n

5.2. Inﬁnite activity. In this section we investigate estimation of the drift when the driving Lévy
process is of inﬁnite jump activity. This is of course a more challenging problem with regards to the
approximation of the continuous martingale part i.e. the jump ﬁltering problem, since we have to
distinguish a diﬀusion component from a process that jumps inﬁnitely often in ﬁnite time intervals.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

14

σ = 0.25

σ = 0.5

tn

n

mean std dev jumps ﬁlt mean std dev jumps ﬁlt

5

10

200
400
800
500
1000
1500
20 1000
2000
3000

1.7
1.9
2.0
1.7
1.9
1.9
1.8
1.9
2.0

0.22
0.12
0.09
0.15
0.08
0.06
0.13
0.06
0.04

6.8
5.1
4.5
12
9.7
9.5
25
19
19

1.7
1.8
1.9
1.7
1.8
1.9
1.6
1.8
1.9

0.28
0.2
0.17
0.21
0.14
0.13
0.16
0.11
0.09

8.0
6.6
5.6
15
12
11
30
24
22

Table 2. Monte Carlo estimates of mean and standard deviation of ˆθCIR
2,n for a
CIR process with Gaussian component and compound Poisson jumps with intensity
λ = 1 and true drift parameter θ2 = 2.

5.2.1. Hyperbolic diﬀusions with jumps. In this section we apply the drift estimator to hyperbolic
diﬀusion processes with jumps. They are deﬁned as solutions (Xt)t≥0 of the following SDE:

dXt = −

θXt
(1 + X 2

t )1/2 dt + σ dWt + dLt, X0 = x.

Here, the drift parameter θ > 0 and the diﬀusion coeﬃcient σ > 0 are unknown and we aim
at estimating θ form discrete observations Xt0, . . . , Xtn of X, where ti = i∆n for ∆n > 0 and
i = 0, . . . , n. The driving Lévy process (Lt)t≥0 will be an α-stable process with Lévy-Khintchine
triplet (0, 0, ν) such that the Lévy measure is of the form ν(dx) = dx/|x|1+α.

From (5) we obtain an explicit pseudo MLE for θ in this model class given by

0

ˆθhyp

t = −´ t
´ t

0

Xs
(1+X 2

s )1/2 dX c

s

.

X 2
s

(1+X 2

s ) ds

Via discretization and jump ﬁltering this leads to the following drift estimator based on discrete
observations:

ˆθhyp
n = −

Xti
(1 + X 2

ti)1/2 ∆n

i X 1|∆n

n

Xi=1

i X|≤vn  n
Xi=1

X 2
ti

(1 + X 2

ti)!−1

To assess the performance of ˆθhyp
X via a Euler scheme with suﬃcient small step size.

n

in Monte Carlo experiments we simulate discrete trajectories of

In Table 3 we give estimated mean and standard deviation of ˆθhyp

from 500 Monte Carlo samples
each for diﬀerent observation length tn and number of observations n. We consider two diﬀerent
values for the index of stability α and give also the number of jumps that have been detected by the
jump ﬁlter. It turns out that ˆθhyp
performs remarkably well over the whole range of diﬀerent setting
even in the case α = 1 of inﬁnite variation jumps that is not covered by our theoretical results,

n

n

since we have assumed that ´R |x|ν(dx) < ∞. It might therefore be reasonable to expect that the
convergence results presented here can be extended to jumps processes with Blumenthal-Getoor
index α ≥ 1.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

15

α = 0.5

α = 1

tn

n

mean std dev jumps ﬁlt mean std dev jumps ﬁlt

5

600
1200
1500
10 1000
2000
4000
20 2000
4000
8000

1.7
1.9
1.9
1.6
1.8
1.9
1.6
1.8
1.9

0.53
0.54
0.57
0.33
0.34
0.35
0.23
0.24
0.23

26
27
26
51
53
50
104
106
101

1.6
1.8
1.9
1.5
1.7
1.9
1.6
1.7
1.9

0.62
0.60
0.66
0.40
0.38
0.43
0.27
0.28
0.30

37
40
41
71
79
85
142
158
170

Table 3. Monte Carlo estimates of mean and standard deviation from 500 samples
of ˆθhyp
for a hyperbolic diﬀusion process with Gaussian component and α-stable
jumps and true drift parameter θ = 2

n

6. Proofs of main results

6.1. MLE for continuous observations. Let ¯θt be the true MLE maximizing the log-likelihood
function given by (6) and based on continuous observations :

(17)

¯θt ∈ argmax
θ∈Θ

ℓt(θ).

Before moving to discrete observations we prove here some asymptotic results for ¯θt. This is a ﬁrst
step in order to prove the asymptotic results for the FMLE.

Theorem 12. Suppose that Assumptions 1–6 and 7(i) are satisﬁed. Then

lim
t→∞

¯θt = θ⋆ P − a.s.

Proof. Denote

(18)

˜ℓt(θ) := ˆ t

0

(b(θ, Xs) − b(θ⋆, Xs))

σ(Xs)

dWs −

1

2 ˆ t

0

(b(θ, Xs) − b(θ⋆, Xs))2

σ2(Xs)

ds.

Using (1) and the fact that the observed trajectory corresponds to the true value of parameter

θ⋆, we can easily see that

ℓt(θ) = ˜ℓt(θ) +

σ2(Xs)
The diﬀerence between ℓ(θ) and ˜ℓt(θ) does not depend on θ, hence also

σ(Xs)

0

1

2 ˆ t

b(θ⋆, Xs)

dWs +

1

2 ˆ t

0

b2(θ⋆, Xs)

ds.

(19)

For θ ∈ Θ, deﬁne

¯θt ∈ argmax
θ∈Θ

˜ℓt(θ).

Mt(θ) := ˆ t

0

(b(θ, Xs) − b(θ⋆, Xs))

σ(Xs)

dWs.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

16

The process (Mt(θ), t ≥ 0) is a continuous local martingale, with quadratic variation given by

At(θ) :=< M (θ) >t= ˆ t

0

(b(θ, Xs) − b(θ⋆, Xs))2

ds.

σ2(Xs)

Note that

(20)

˜ℓt(θ) = −

1
2

At(θ) + Mt(θ),

Recall that π, given by the Lemma 1 is an invariant distribution of X and denote

(21)

˜ℓ(θ) = −

1
2

π(cid:18) (b(θ, .) − b(θ⋆, .))2

σ2(.)

(cid:19)

Using Assumptions 5, 7(i) and Lemma 1(2), we see that for all θ ∈ Θ, ˜ℓ(θ) ∈ R. Hence, using the
Lemma 1(1) for all θ ∈ Θ,

lim

t→∞ −

1
2t

At(θ) = ˜ℓ(θ)

P − a.s.

Moreover, using again Assumptions 5 and 7(i) we can see that the family

(22)

Indeed,

1
t

{

At(θ)}t>0 is equicontinuous P − a.s.

1

t |At(θ) − At(θ′)| ≤ C|θ − θ′|κ 1

t ˆ t

0

K 2(Xs)ds,

where C = 2[Diam(Θ)]κ and K given by the Assumptions 7(i) is sub-polynomial. Using ergodic
t ´ t
theorem, which holds thanks to the Lemma1, 1
0 K 2(Xs)ds converges almost surely to some ﬁnite
limit. Hence (22) follows. As a consequence,
At(θ) − ˜ℓ(θ)(cid:12)(cid:12)(cid:12)(cid:12)

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)

P − a.s.

lim
t→∞

Denote

1
2t

(23)

= 0

sup

−

At(θ, θ′) :=< Mt(θ) − Mt(θ′) >t .

Using Assumptions 5 and 7(i), for all (θ, θ′) ∈ Θ2,

0 ( K 2(Xs)

σ2(Xs) ∨ 1)ds → ∞,

where Vt := ´ t
Loukianova and Loukianov [2005] are satisﬁed. As a conclusion, the family { Mt(θ)
satisﬁes the Uniform Law of Large Numbers on any compact K ∈ Θ not containing θ⋆, i.e.

t → ∞. Therefore all assumptions of the Theorem 2 in
At(θ) ; θ ∈ Θ, t ≥ 0}

At(θ, θ′) ≤ |θ − θ′|2κVt,
if

lim
t→∞

lim
t→∞

sup

θ∈K(cid:12)(cid:12)(cid:12)(cid:12)
θ∈K(cid:12)(cid:12)(cid:12)(cid:12)

sup

Mt(θ)

At(θ)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)

Mt(θ)

t

= 0

= 0

sup

θ∈K |t−1 ˜ℓt(θ) − ˜ℓ(θ)| → 0.

We deduce, using (23), that

and hence, P − a.s.
(24)

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

17

We can now derive the a.s. consistency of ¯θt following classical Wald’s method. We refer for instance
to Theorem 5.7 in Van der Vaart [1998] for a simple presentation of Wald’s approach, and stress out
the fact that all convergences and hence consistency holds P -a.s.
in our setting. Indeed, observe
that

(25)

and hence

(26)

˜ℓ(θ) ≤ 0,

˜ℓ(θ) = 0 ⇐⇒ θ = θ⋆

sup

˜ℓ(θ) < ˜ℓ(θ⋆)

θ: d(θ,θ⋆)≥ε

is trivially satisﬁed in our case. We deduce from (24) and (26) that P -a.s. for all ε > 0,

lim
t→∞

sup

d(θ,θ⋆)≥ε

1
t

˜ℓt(θ) < ˜ℓ(θ⋆)

and hence for t > t(ω) large enough

and ﬁnally for t > t(ω),

˜ℓt(θ) < ˜ℓt(θ⋆)

sup

d(θ,θ⋆)≥ε

d(¯θt, θ⋆) < ε,

which means the a.s. consistency.

(cid:3)

Recall that I is the Fisher information given by (3).
The next result is a central limit theorem for the estimation error. It is important for us in the

sequel, since the asymptotic variance serves as a benchmark for the case of discrete observations.
Theorem 13. Suppose that Assumptions 1–9 hold. Then the MLE ¯θt is asymptotically normal:

t1/2(¯θt − θ⋆) L→ N (0, I−1(θ⋆))

as

t → ∞.

Proof. Due to Assumptions 5 and 7, Theorem 2.2 in Hutton and Nelson [1984] and Theorem 1 in
Loukianova and Loukianov [2005] for all t > 0 the criterion function ˜ℓt(θ, X) is twice continuously
diﬀerentiable in θ.

From (18) the score function can be written as ∇θℓ = ∇θ ˜ℓ = (∂θ1
ds +ˆ t

(b(θ, Xs) − b(θ⋆, Xs))∂θi b(θ, X)

˜ℓt(θ) = −ˆ t

σ2(Xs)

∂θi

0

˜ℓt, . . . , ∂θd
∂θib(θ, Xs)

0

σ(Xs)

(27)

˜ℓt)T where

dWs,

for i = 1, . . . , d. A Taylor expansion around ¯θt yields

(28)

ˆ 1

0

1
t

∂2
θ

˜ℓt(θ⋆ + s(¯θt − θ⋆))ds × √t(¯θt − θ⋆) = −

1

√t∇θ ˜ℓt(θ⋆).

Hence, to obtain a CLT for the estimation error t1/2(¯θt − θ⋆) we will ﬁrst show the convergence of
the right hand side in (28). The equation (27) gives for θ = θ⋆
∇θb(θ⋆, Xs)

dWs

∇θ ˜ℓt(θ⋆) = ˆ t

0

σ(Xs)

such that the central limit theorem for multidimensional local martingales Küchler and Sørensen
[1999] gives

(29)

t−1/2∇θ ˜ℓt(θ⋆) = t−1/2ˆ t

0

∇θb(θ⋆, X)

σ(Xs)

dWs L→ N (0, I).

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

18

In the next step we prove the convergence of

ˆ 1

0

1
t

∂2
θ

˜ℓt(θ⋆ + s(¯θt − θ⋆))ds.

From (27) we see that for (i, j) ∈ {1, . . . , d},

∂2
θiθj

(30)

(b(θ, Xs) − b(θ⋆, Xs))∂2

θi,θj b(θ, Xs)

σ2(Xs)

˜ℓt(θ) = −ˆ t
+ˆ t

0

0
∂2
θiθj b(θ, Xs)

dWs

σ(Xs)
t (θ) + U 2

:= U 1

t (θ) + U 3

t (θ).

ds −ˆ t

0

∂θib(θ, Xs)∂θj b(θ, Xs)

σ2(Xs)

ds

Using the ergodic theorem, P -a.s.

U 1
t (θ) → U 1

∞(θ) := −ˆR

(b(θ, x) − b(θ⋆, x))∂2

θiθj b(θ, x)

σ2(x)

π(dx);

U 2
t (θ) → U 2

∞(θ) := −ˆR

∂θib(θ, x)∂θj b(θ, x)

σ2(x)

π(dx) = −Ii,j(θ).

1
t

1
t

tinuity (22) we obtain that the families of functions (θ 7→ U 1

Moreover, using Assumption 7 and 8 and the same argument which were used to prove the equicon-
t (θ))t≥0 are
almost surely equicontinuous. Finally, the uniform law of large numbers for local martingales
Loukianova and Loukianov [2005] together with Assumptions 5 ,7 and 8 gives that P -a.s.

t (θ))t≥0 and (θ 7→ U 2

t

t

sup
θ∈Θ

t−1|U 3

t (θ)| = sup
θ∈Θ

t−1|ˆ t

0

∂2
θ b(θ, Xs)
σ(Xs)

dWs|→0

Using (30) and the four last displays we obtain P -a.s.

Using this uniformity together with a.s. convergence ¯θt → θ⋆ we get P -a.s.

(31)

and

(32)

sup

θ∈Θ(cid:12)(cid:12)(cid:12)
s∈[0,1](cid:12)(cid:12)(cid:12)
t−1ˆ 1

sup

0

t−1∂2
θ

˜ℓt(θ) − (U 1

∞(θ) − I(θ))(cid:12)(cid:12)(cid:12) →0
˜ℓt(θ⋆ + s(¯θt − θ⋆)) − (−I(θ⋆))(cid:12)(cid:12)(cid:12)→0

t−1∂2
θ

∂2
θ

˜ℓt(θ⋆ + s(¯θt − θ⋆))ds→ − I(θ⋆).

Finally, from the non-degeneracy of the Fisher information matrix I(θ⋆), (29), (32), and Slutsky’s
(cid:3)

theorem, we deduce the asymptotic normality of the estimator.

6.2. Local asymptotic normality and eﬃciency. To obtain an asymptotic eﬃciency result in
the sense of Hàjek-Le Cam’s convolution theorem we prove now the local asymptotic normality
property for the statistical experiment (Ω,F , (Ft),P). From this result we can then deduce later
on eﬃciency of the discretized estimator with jump ﬁlter (cf. Theorem 3 and 4).

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

19

Theorem 14. Suppose that Assumptions 1 to 9 are satisﬁed. Then the family (P θ)θ∈Θ is locally
asymptotically normal. That is, for all h ∈ Rd, we have the convergence in distribution under P ,
(33)

as

ℓt(θ⋆ +

) − ℓt(θ⋆) L→ −1/2h⊤I(θ⋆)h + N,

t → ∞,

h
√t

where N ∼ N (0, h⊤I(θ⋆)h). As a consequence the drift estimator ¯θt is asymptotically eﬃcient in
the sense of the Hájek-Le Cam convolution theorem.

1

2 ˆ t

0

(b(θ⋆ + h√t

, Xs) − b(θ⋆, Xs))2ds
σ2(Xs)

) − ℓt(θ⋆) = −

h
√t
(b(θ⋆ + h√t

ℓt(θ⋆ +
+ˆ t

0

1

0   1
0 ˆ 1
2 ˆ 1
t ˆ t
= −
√t ˆ t
∇bT (θ⋆, Xs)h
1

σ(Xs)

+

0

0

, Xs) − b(θ⋆, Xs))
σ(Xs)

dWs

h⊤(∇b(θ⋆ + hu√t

dWs + Rt.

, Xs)∇b⊤(θ⋆ + hu′
√t
σ2(Xs)

, Xs)h

ds! dudu′

Proof.

Where

Rt := ˆ t

0

(b(θ⋆ + h√t

, Xs) − b(θ⋆, Xs))
σ(Xs)

dWs −

1

√t ˆ t

0

∇bT (θ⋆, Xs)h

σ(Xs)

dWs.

Using Assumption 7 and the ergodic theorem, for all ﬁxed r > 0, r′ > 0 such that θ⋆ + r ∈ Θ,
θ⋆ + r′ ∈ Θ we obtain

h⊤∇b(θ⋆ + r, Xs)∇b⊤(θ⋆ + r′, Xs)h

h⊤∇b(θ⋆ + r, x)∇b⊤(θ⋆ + r′, x)h

dπ(x)

σ2(Xs)

σ2(Xs)

ds = ˆR

1

t ˆ t

0

lim
t→∞

P -a.s. and Assumption (8) and Lemma 1 imply that this last limit is ﬁnite. Moreover, using

Assumption 7 it can be shown that this convergence is uniform, hence for hu/√t → 0 it gives that
P − a.s.

(34)

lim

t→∞ˆ 1

0

duˆ 1

0

du′ 1

t ˆ t

0

h⊤∇b(θ⋆ + hu√t

, Xs)∇b⊤(θ⋆ + hu′
√t
σ2(Xs)

, Xs)h

ds

= ˆR

h⊤∇b(θ⋆, x)∇b⊤(θ⋆, x)h

σ2(Xs)

dπ(x) = h⊤I(θ⋆)h.

Using Markov inequality

(35)

P (|Rt| ≥ ε) ≤

V arRt

ε2 ≤ khk2

ε2

1

0 (cid:18)khk√t (cid:19)2κ
t ˆ t

1 (Xs)

E(cid:18) K 2

σ2(Xs)(cid:19) ds,

where K1 is a Holder constant of ∇b is supposed to be at most of polynomial growth. Using ergodic
theorem in mean, we obtain Rt → 0 in P probability.

Due to the CLT for martingales in Küchler and Sørensen [1999]

1

√t ˆ t

0

∇b⊤(θ⋆, Xs)h

σ(Xs)

dWs → N (0, h⊤I(θ⋆)h)

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

20

in distribution. Combining the latter equation with (34)–(35), we obtain (33). This implies together
with Theorem 13 that ¯θt is asymptotically eﬃcient in the sense of the Hájek-Le Cam convolution
theorem.
(cid:3)

6.3. Proofs of Theorems 2, 3 and 4.
Proof of Theorem 2. Let ˜ℓ : Θ → R be given by (21) and deﬁne
π(cid:18) b2(θ⋆, x)
σ2(x) (cid:19) .
(36)

ℓ(θ) = ˜ℓ(θ) +

1
2

Under Assumptions 1 and 5 the last term in the right hand side of (36) is ﬁnite.We will apply Wald’s
method for proving consistency of M estimators (see for example Theorem 5.7 in Van der Vaart
[1998]). It follows from (25) that

(37)

Therefore, it remains to prove that

sup

θ; d(θ,θ⋆)≥ε

ℓ(θ) ≤ ℓ(θ⋆).

To obtain this last statement we decompose this diﬀerence as follows:

lim
n→∞

sup

n ℓn
θ∈Θ|t−1

tn(θ) − ℓ(θ)| = 0 in probability.

(38)

sup

θ∈Θ|ℓ(θ) − t−1
n ℓn

tn (θ)| ≤ sup

θ∈Θ|ℓ(θ) − t−1

n ℓtn(θ)| + sup

θ∈Θ|t−1

n (ℓtn(θ) − ℓn

tn(θ))|.

Using respectively the Ergodic Theorem given by Lemma 1 (1) and the Law of Large Numbers

for continuous local martingales (? p.178) we see that a.s.

and

1

t ˆ t

0

b2(θ⋆, Xs)

σ2(Xs)

ds → π(cid:18) b2(θ⋆, x)
σ2(x) (cid:19)

1

t ˆ t

0

b(θ⋆, Xs)

σ(Xs)

dWs → 0

Using these two last display and (24) we see that the ﬁrst term of the decomposition (38) tends
to zero P -a.s..
In order to show the convergence to zero in probability of the second term, we
decompose it as follows.

n (ℓtn (θ) − ℓn

tn (θ))(cid:12)(cid:12)

sup

t−1

≤ sup
θ∈Θ

θ∈Θ(cid:12)(cid:12)t−1
n (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
n (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

+ sup
θ∈Θ
= sup
θ∈Θ

t−1

t−1
n |A1

n

s −

σ(Xs)−2b(θ, Xs) dX c

Xi=1
Xi=1
σ(Xs)−2b(θ, Xs)2 ds −

1
2

n

0

1

ˆ tn
2 ˆ tn
n(θ)| + sup
θ∈Θ

0

t−1
n |A2

n(θ)|.

σ(Xti−1 )−2b(θ, Xti−1 )∆n

i X 1|∆n

σ(Xti−1 )−2b(θ, Xti−1 )2∆n

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i Id(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Hence, it remains to prove the convergence to zero of t−1
n(θ)| uniformly in θ.
For t−1
n(θ)| we apply Proposition 6 in the ﬁnite activity case and Proposition 7 in the case of
inﬁnite activity, together with the fact that n∆n = O(tn). Indeed, using Assumption 7 and 8 we

n(θ)| and t−1

n |A2

n |A1

n |A1

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

21

see that the function f (θ, x) = σ(x)−2b(θ, x)2 satisﬁes all assumptions of Propositions 6 or 7. For
the second term t−1
(cid:3)

n |A2

n(θ)| we use Lemma 11.

Proof of Theorem 3. A Taylor expansion around ˆθn yields

(39)

1

tn ˆ 1

0

tn (θ⋆ + s(ˆθn − θ⋆))ds × t1/2
θ ℓn
∂2

n (ˆθn − θ⋆) = −

1
n ∇θℓn
t1/2

tn(θ⋆).

For the right hand side we ﬁnd that

(40)

1
1/2∇θℓn
tn

tn(θ⋆) = ∇θℓn

tn(θ⋆) − ∇θℓtn (θ⋆)

√tn

+ ∇θℓtn (θ⋆)

√tn

.

By (29) we have that under P

(41)

∇θℓtn (θ⋆)

√tn

L→ N (0, I(θ⋆)), n → ∞.

The ﬁrst term of the sum on the right hand side of (40) has the form

∇θℓn

t1/2
n

tn(θ⋆) − ∇θℓtn(θ⋆)
n  ˆ tn
2 ˆ tn

1

0

0

n

σ(Xti−1 )−2∇θb(θ⋆, Xti−1 )∆n

Xi=1
s −
Xi=1
σ(Xti−1 )−2∇θb(θ⋆, Xti−1)2∆n

n

i X 1|∆n
i Id! .

i X|≤vn!

= −t−1/2

σ(Xs)−2∇θb(θ⋆, Xs) dX c

+ t−1/2

n

σ(Xs)−2∇θb(θ⋆, Xs)2 ds −

By applying Proposition 6 for k = 1, . . . d with fk(θ⋆, x) = σ(x)−2∂θk b(θ⋆, x), and using Assump-
tions 7– 8 we obtain that

n  ˆ tn

0

t−1/2

σ(Xs)−2∂θk b(θ⋆, Xs) dX c

Xi=1
as n → ∞. Furthermore, Lemma 11 (ii) leads to

s −

n

σ(Xti−1 )−2∂θk b(θ⋆, Xti−1 )∆n

i X 1|∆n

i X|≤vn! P−→ 0

t−1/2

n  ˆ tn

0

σ(Xs)−2∂θk b(θ⋆, Xs)2 ds −

σ(Xti−1 )−2∂θk b(θ⋆, Xti−1)2∆n

i Id! P−→ 0,

n

Xi=1

as n → ∞. Combining now the last three displays results in

∇θℓn

tn (θ⋆) − ∇θℓtn(θ⋆)

t1/2
n

P−→ 0

such that (40) and (41) give

n ∇θℓn
t1/2

tn (θ⋆) d→ N (0, I(θ⋆)), n → ∞.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

22

To ﬁnish the proof it remains to show the convergence of the left hand side in (39). For (j, k) ∈
{1, . . . , d}2 and θ ∈ Θ,
t−1
n sup

0

n sup

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:16)∂2
θjθk ℓn
θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ˆ tn
θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ˆ tn
θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ˆ tn
n + U 3
n.

n + U 2

n sup

n sup

0

0

≤ t−1

+ t−1

+ t−1

= U 1

tn (θ) − ∂2

θj θk ℓtn (θ)(cid:17)(cid:12)(cid:12)(cid:12)

n

s −

σ(Xs)−2∂2

θj θk b(θ, Xs) dX c

Xi=1
Xi=1
σ(Xs)−2∂θj b(θ, Xs)∂θk b(θ, Xs) ds −
Xi=1

θjθk b(θ, Xs)b(θ, Xs) ds −

σ(Xs)−2∂2

n

n

σ(Xti−1 )−2∂2

θjθk b(θ, Xti−1 )∆n

i X 1|∆n

σ(Xti−1 )−2∂θj b(θ, Xs)∂θk b(θ, Xs)∆n

σ(Xti−1 )−2∂2

θj θk b(θ, Xs)b(θ, Xs)∆n

i X|≤vn(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i Id(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i Id(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Proposition 6 together with Assumptions 7– 8 state that

(42)

Lemma 11 (i) gives for k=2,3

U 1
n

P→ 0,

as n → ∞.

as n → ∞.
(43)
Combining (42) and (43) with consistency of ˆθ and ¯θ we get

U k
n

P→ 0,

ˆ 1

0

1
tn (θ⋆ + s(ˆθn − θ⋆)) − ∂2
tn|∂2
θ ℓn

θ ℓtn (θ⋆ + s(¯θtn − θ⋆))|ds P→ 0,

and hence, using (32)

1

tn ˆ 1

tn(θ⋆ + s(ˆθn − θ⋆))ds P→ −I(θ⋆)
θ ℓn
∂2
as n → ∞ such that the result follows.
Proof of Theorem 4. By replacing in the previous proof Proposition 6 by Proposition 7 we obtain
the result for the inﬁnite activity case.
(cid:3)

(cid:3)

0

7. Proofs for jump filtering

In this section we prove the results that were used in the Section 4 to obtain the convergence
of the jump ﬁlter (cf. Proposition 6 and 7) to integral functionals with respect to the continuous
martingale part of X. We start by proving the Lemma 8 that shows the convergence of the jump
ﬁlter approximation to the continuous part in the ﬁnite activity case.

We recall some notations: µ denotes the Poisson random measure on [0,∞) × R associated with
the jumps of the Lévy process L, the intensity of this jump measure is ds × ν(dz). We deﬁne
˜µ = µ − ds × ν(dz) as the compensated Poisson measure such that we have Lt = ´ t
0 ´R zµ(ds, dz).
In the speciﬁc situation where the Lévy process L has a ﬁnite intensity ν(R) < ∞, we shall denote
by Nt = ´ t
0 ´R µ(ds, dz) the process that counts the number of jumps up to time t.
Proof of Lemma 8. For all n ∈ N∗, i ∈ N∗ we deﬁne the set where increments of X are small:
(44)

n = {|∆n
K i

i X| ≤ vn} ,

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

23

the event that L and so also X do not jump:

(45)

i N = 0} ,
and the event that an increment of the jump part is small:
vn

n = {∆n

M i

(46)

where we denoted by X J the jump part of X given by

i X J(cid:12)(cid:12) ≤

3 o ,

Di

n =n(cid:12)(cid:12)∆n
0 ˆR\{0}

X J

t = ˆ t

γ(Xs−)zµ(ds, dz),

t ≥ 0.

We start by proving (i). Using the previously deﬁned sets we introduce the following quantities.

n

(47)

(48)

(49)

G1

n(θ) :=

G2

n(θ) :=

G3

n(θ) :=

n

Xi=1
Xi=1
Xi=1

n

f (θ, Xti−1)(cid:0)∆n

i X J(cid:1) 1K i

n)c,

n∩(M i

f (θ, Xti−1) (∆n

i X c) 1(K i

n)c∩Di

n

,

f (θ, Xti−1) (∆n

i X c) 1(K i

n)c∩(Di

n)c,

and decompose the diﬀerence to be estimated as follows:

(50)

n

Xi=1

f (θ, Xti−1 )(cid:0)∆n

i X c − ∆n

i X 1|∆n

i X|≤vn(cid:1) = G1

n(θ) + G2

n(θ) + G3

n(θ).

To prove the convergence of G1

n(θ) we decompose the set K i

n)c into three disjoint events

n ∩ (M i

1

(51)

K i

n∩(M i

n)c = 1
+ 1

+ 1

{∆n
{∆n

i N≥2}∩K i
i N =1,|∆n

i N =1,|∆n
i L|<2vn/γmin}∩K i

{∆n

n

n

i L|≥2vn/γmin}∩K i

n

Using Lemma 15 (3), the deﬁnition of vn and Markov’s inequality we can see that the second

indicator of this decomposition is on an event that has small probability. Indeed, for all p > 1,

P (cid:0){∆n

i N = 1,|∆n

i L| ≥ 2vn/γmin} ∩ K i

i X c| ≥ vn) = O(∆p/2

n v−p

n ) = O(∆εp

n ).

Then, using the L2–isometry for stochastic integral with respect to the compensated Poisson mea-
sure and the Jensen’s inequality, we get

n(cid:1) ≤ P (|∆n

2

≤ 2E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
i X J(cid:12)(cid:12)
E(cid:12)(cid:12)∆n
≤ 2ˆ ti
ti−1 ˆR\{0}

ˆ ti
ti−1 ˆR\{0}
E[γ2(Xs)]z2dsν(dz) + 2ˆ ti

γ(Xs−)z ˜µ(ds, dz)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ti−1 ˆR\{0}

ti−1 ˆR\{0}

+ 2E"ˆ ti
E[γ2(Xs)]|z|dsν(dz)ˆ ti

γ(Xs)zdsν(dz)#2
ti−1 ˆR\{0}

2

|z|dsν(dz)

(52)

= O(∆n),

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

24

where in the last line we have used Assumption 1, Assumption 3 (i), Assumption 4 (ii) and Lemma
1 statement (3). Using Hölder’s inequality twice and Lemma 1 statement (3) we get for all p > 0,

E sup

n

Xi=1

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(53)

f (θ, Xti−1)∆n

i X J 1{∆n

i N =1,|∆n

i L|≥2vn/γmin}∩K i

= O(n∆εp

n ).

For the third indicator function in (51) we observe that

n

E sup

n

i N =1,|∆n

i L|<2vn/γmin}∩K i

Xi=1
f (θ, Xti−1)(cid:0)∆n
θ∈Θ|
ˆ ti
ti−1 ˆ
Xi=1
≤
= O(n∆n ˆ

i X J(cid:1) 1{∆n
θ∈Θ|f (θ, Xti−1 )γ(Xs)|(cid:21)|z|dsν(dz)
E(cid:20)sup
|z|<2vn/γmin
|z|<2vn/γmin |z|ν(dz)),

n

(54)

where we have used the sub-polynomial growth of γ, f and Lemma 1 statement(3).

For the ﬁrst indicator in (51) we obtain by Hölder’s inequality with conjugated exponents, p, q,

such that p−1 + q−1 = 1, and q−1 = 1 − ε/2,

E sup

n

n

≤

E sup

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1
f (θ, Xti−1 )(cid:0)∆n
Xi=1
θ∈Θ|f (θ, Xti−1 )| (|∆n
Xi=1(cid:18)E sup
θ∈Θ|f (θ, Xti−1 )|p(|∆n
n + vn)∆2/q

≤
= O(n(∆1/2

n

i X c − ∆n

i X 1|∆n

i X|≤vn(cid:1) 1{∆n

i N≥2}∩K i

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

i N≥2}

i X c| + vn) 1{∆n
i X c| + vn)p(cid:19)1/p

P (∆n

i N ≥ 2)1/q

(55)

n = O(n∆5/2−2ε

n

),

where we have used that P (∆n

i N ≥ 2) = O(∆2
n).

From (53), (54) and (55) it follows that

(56)

E sup

θ∈Θ|G1

n(θ)| ≤ O(n∆n ˆ

|z|≤2vn/γmin |z|ν(dz)) + O(n∆5/2−2ε

n

).

To estimate G2

n(θ) note ﬁrst that for any p > 1,

n)c ∩ Di

P (cid:0)(K i

n(cid:1) ≤ P (|∆n

i X c| > 2vn/3) = O(∆εp
n ).

Hence, by using Hölder’s inequality, sub-polynomial growth of f , (3) of Lemma 1 and (3) of Lemma
15 we obtain for any p > 1,

(57)

E sup

θ∈Θ|G2

n(θ)| = E sup
θ∈Θ|

n

Xi=1

f (θ, Xti−1) (∆n

i X c) 1(K i

n)c∩Di

n| = O(n∆εp
n ).

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

25

To estimate G3

n(θ) note ﬁrst that

P ((Di

|z|≥vn

|z|≥vn

|z|<vn

n)c) = P (|∆n
≤ P (|ˆ ti
ti−1 ˆ
≤ P (|ˆ ti
ti−1 ˆ
≤ P (ˆ ti
ti−1 ˆ
µ(ds, dz) ≥ 1) +
= 1 − exp −ˆ ti
ti−1 ˆ
= O ∆n(ˆ

i X J| > vn/3)
γ(Xs−)zµ(ds, dz)| > vn/6) + P (|ˆ ti
ti−1 ˆ
E[|ˆ ti
ti−1 ˆ
γ(Xs−)zµ(ds, dz)| > 0) +
E[|ˆ ti
ti−1 ˆ
γ(Xs)zdsν(dz)|]
E[|ˆ ti
ti−1 ˆ
|z|<vn |z|ν(dz))! .

dsν(dz)! +
vn ˆ

ν(dz) +

|z|≥vn

|z|≥vn

|z|≥vn

|z|<vn

|z|<vn

|z|<vn

6
vn

6
vn

6
vn

1

γ(Xs)zdsν(dz)|]

γ(Xs−)zµ(ds, dz)| > vn/6)

γ(Xs)zdsν(dz)|]

Hence, using Hölder’s inequality, the assumptions on f and (3) of Lemma 15 we obtain for any
q > 1 that

n

E sup

θ∈Θ|G3

Xi=1
n(θ)| ≤ E
n  ˆ

n )∆1/q

sup

θ∈Θ|f (θ, Xti−1 )||∆n
vn ˆ

ν(dz) +

i X c|1{|∆n
|z|<vn |z|ν(dz)!1/q

1

i X|>vn,(Di

.

|z|≥vn

(58)

≤ O(n∆1/2

n)c} ≤ O(n∆1/2

n )P ((Di

n)c)1/q

n

Finally, choosing q−1 = 1 − ε/2, we get from (56), (57) and (58) that
# ≤ O(n∆nˆ
vn ˆ
|z|<vn |z|ν(dz))1−ε/2

i X c − ∆n
)(ˆ

f (θ, Xti−1 )(cid:0)∆n

i X|≤vn(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
E"sup

) + O(n∆3/2−ε/2

+ O(n∆5/2−2ε

i X 1|∆n

Xi=1

ν(dz) +

|z|≥vn

1

n

n

|z|≤2vn/γmin |z|ν(dz))

In particular, using the deﬁnition of vn, ﬁniteness of ν and of its ﬁrst moment we immediately get

E sup

n

Xi=1

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f (θ, Xti−1)(cid:0)∆n

i X c − ∆n

i X 1|∆n

= O(n∆3/2−ε/2

n

),

i X|≤vn(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

hence (i) is proved.
To prove (ii) we decompose the approximation by the jump ﬁlter as follows:

(59)

n

Xi=1

f (θ, Xti−1 )(cid:0)∆n

i X c − ∆n

i X 1|∆n

i X|≤vn(cid:1) = G1

n(θ) + A2

n(θ) + A3

n(θ),

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

26

where G1

n(θ) is given by (47) and

(60)

Observe that

A2

n(θ) :=

A3

n(θ) :=

n

n

Xi=1
Xi=1

f (θ, Xti−1 ) (∆n

i X c) 1(K i

n)c∩(M i

n)c

f (θ, Xti−1 ) (∆n

i X c) 1(K i

n)c∩M i

n

.

n

n

A2

(61)

n(θ) =

Xi=1

f (θ, Xti−1 )∆n

Xi=1
We ﬁrst show that after suitable renormalization the ﬁrst term of this decomposition converges to
zero in probability. Let ei := f (θ, Xti−1 )∆n
n)c . Denote Fi = σ{(Ws)0<s≤ti , (Ls)0<s≤ti , X0},
then

f (θ, Xti−1)∆n

i X|≤vn}∩(M i

n)c −

i X c1

i X c1

i X c1

{|∆n

n)c.

(M i

(M i

E[ei|Fi−1] = f (θ, Xti−1)E"ˆ ti
+ f (θ, Xti−1 )E"ˆ ti

ti−1

ti−1

σ(Xs)dWs1(M i

b(θ⋆, Xs)ds1(M i

n)c|Fi−1#
n)c|Fi−1#

Observe that (Ws)s≥0 remains a Brownian motion with respect to the ﬁltration that is enlarged by
σ(L), since L and W are independent. Therefore,

E"ˆ ti

ti−1

and so

(62)

Recall that

σ(Xs)dWs1(M i

n)c|Fi−1# = E"1(M i

n)cE"ˆ ti

ti−1

σ(Xs)dWs|Fi−1 ∨ σ(L)# |Fi−1# = 0

|E[ei|Fi−1]| ≤ |f (θ, Xti−1)|ˆ ti

ti−1

E(cid:2)|b(θ⋆, Xs)| 1(M i

n)c|Fi−1(cid:3) ds.

Using Hölder inequality, Lipshitz continuity of b(θ⋆, .), the continuity of its Lipshitz constant given
by the Assumption 1 and Lemma 15 (2) we can write for p, q such that p−1 + q−1 = 1, p ≥ 2 and
C > 0,

P(cid:0)(M i

n)c(cid:1) = 1 − P (∆n

i N = 0) = O(∆n).

n)c|Fi−1(cid:3) ≤ (E [|b(θ⋆, Xs)|p |Fi−1])1/p ∆1/q
E(cid:2)|b(θ⋆, Xs)| 1(M i
≤ C(cid:0)E[|b(θ⋆, Xs) − b(θ⋆, Xti−1 )|p|Fti−1 ] + |b(θ⋆, Xti−1)|p(cid:1)1/p
≤ C(cid:16)(cid:0)E(cid:2)|Xs − Xti−1|p|Fti−1(cid:3)(cid:1)1/p
+ |b(θ⋆, Xti−1)|(cid:17) ∆1/q
≤ C∆1/q

n (1 + |Xti−1|p)1/p + |b(θ⋆, Xti−1)|(cid:17) .

n (cid:16)∆1/p

n

n

∆1/q

n

(63)

Using the fact that b(θ⋆, .) and supθ∈Θ |f (θ, .)| are sub-polynomial and choosing again 1/q =

1 − ε/2, (which also guarantees p > 2,) we obtain
(64)

|E[ei|Fi−1]| ≤ h(|Xti−1|)∆2−ε/2

n

,

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

27

where h is a polynomial function. Finally this implies that under the condition n∆3−ε

n → 0,

(65)

# = O(n1/2∆3/2−ε/2

n

) → 0.

Next, we bound the moment of order two of ei.

(66)

By Hölder’s inequality with 1/q = 1 − ε/2, 1/p = 1 − 1/q, we have
P (cid:2)(M i

i X c)2p(cid:3)1/p

= O(∆2−ε/2

),

n)c(cid:3)1/q

n

E[e2

E" n
ei√n∆n|Fi−1(cid:21)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1(cid:12)(cid:12)(cid:12)(cid:12)
E(cid:20)
i ] ≤ E(cid:2)f (θ, Xti−1 )2p(∆n
n)c(cid:3)1−ε/2
≤ ∆nP (cid:2)(M i
|Fi#(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
# =

E"(cid:18) ei√n∆n(cid:19)2

n

where in the last line we used again Hölder’s inequality, the sub-linear growth of f , together with
Lemma 15 (3). Hence,

(67)

) → 0.
Under (65) and (67) we obtain from Lemma 9 in Genon-Catalot and Jacod [1993] that

E"(cid:18) ei√n∆n(cid:19)2# = O(∆1−ε/2

Xi=1

n

n

E"(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1

(68)

if n∆3−ε

n

1

P−→ 0
n → 0. Recall that the second term in the decomposition (61) of A2

f (θ, Xti−1)∆n

√n∆n

Xi=1

Xi=1

i X c1

n)c =

(M i

ei√n∆n

n

n is given by

n

Xi=1

f (θ, Xti−1)∆n

i X c1

K i

n∩(M i

n)c.

(69)

(70)

n

Xi=1

E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(72)

We will now bound this term in L1. We use again the decomposition (51) of K i
that by computations similar to (55) and (53) respectively, we have

n ∩ (M i

n)c. We ﬁnd

n

n

Xi=1
Xi=1

E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

f (θ, Xti−1)∆n

i X c1

{∆n

i N≥2}∩K i

= O(n∆5/2−2ε

n

),

f (θ, Xti−1)∆n

i X c1

i N =1,|∆n

i L|≥2vn/γmin}∩K i

{∆n
i L| < 2vn/γmin) = P (´ ti

ti−1 ´|z|<2vn/γmin

= O(n∆εp
n )

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Moreover, we have that P (∆n
∆n´|z|<2vn

(71)

i N = 1,|∆n

ν(dz), where we used γmin ≥ 1. From this, we can easily get
 ˆ

i L|<2vn/γmin}∩K i

= O

i X c1{∆n

i N =1,|∆n

f (θ, Xti−1)∆n

From (61), (68), (69)–(71), we deduce that if n∆3−ε

n

n∆3/2−ε/2

|z|<2vn

µ(ds, dz) = 1) ≤

ν(dz)!1−ε/2
 .

A2

n(θ) = oP (pn∆n) + OL1

|z|<2vn
It follows immediately from Lemma 15 (3) that for any p > 1,

ν(dz)!1−ε/2

n∆3/2−ε/2

n


 .

P ((K i

n)c ∩ M i

i X c| > vn) = O(∆εp
n ).

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
n → 0,
+ ˆ

n

n∆5/2−2ε
n) ≤ P (|∆n

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

28

Hence, using again Hölder’s inequality and Lemma 15 (3) again, we see that for any p > 1,

(73)

i X|≤vn(cid:1) 1(K i
Finally, from (56), (72), (73) we obtain that for any θ ∈ Θ, if n∆3−ε

f (θ, Xti−1 )(cid:0)∆n

i X c − ∆n

i X 1|∆n

Xi=1

n → 0,

n)c∩M i

= O(n∆εp

n ).

n(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

n

n(θ)(cid:12)(cid:12) = E(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
E(cid:12)(cid:12)A3
Xi=1
f (θ, Xti−1 )(cid:0)∆n
oP (pn∆n) + OL1

This proves (ii).

i X|≤vn(cid:1) =

i X 1|∆n
+ ˆ

i X c − ∆n
n∆5/2−2ε

n

ν(dz)!1−ε/2

|z|<2vn

n∆3/2−ε/2

n

+ n∆nˆ

|z|≤2vn |z|ν(dz)
 .

(cid:3)

Proof of Lemma 9. We start by proving (i). In the inﬁnite jump activity case, the Lévy process has
inﬁnite number of jumps on all compact intervals. Hence, it is impossible to introduce the events
that the process had no jump, one jump, or more than two jumps on (ti−1, ti] as it was done in the
proof of Lemma 8.

Here, we deﬁne the event on which all the jumps of L are small :

N i
n = {|∆Ls| ≤ 3vn/γmin; ∀s ∈ (ti−1, ti]} ,

n and Di

n from (44), we deﬁne

(74)
where ∆Ls := Ls − Ls−. Using the sets K i
i X J(cid:1) 1K i
(75) B1

f (θ, Xti−1 )(cid:0)∆n

and decompose the diﬀerence as follows

Xi=1

n(θ) :=

n

n)c; B2

n(θ) :=

n∩(N i

n

Xi=1

f (θ, Xti−1 )(cid:0)∆n

i X J(cid:1) 1K i

n∩N i

n

;

n

Xi=1

f (θ, Xti−1 )(cid:0)∆n

i X c − ∆iX 1|∆n

i X|≤vn(cid:1) = B1

n(θ) + B2

n(θ) + G2

n(θ) + G3

n(θ),

n(θ) and G3

n(θ) are deﬁned in (48)–(49). We start by studying the convergence of B1

where G2
n(θ).
Let T ∗i ∈ (ti−1; ti] such that |∆LT ∗
is well deﬁned,
as from Assumption 4 (iii) there is, almost surely, a unique time at which the Lévy process admits
a jump with maximal size. We introduce the event

i | = max{|∆Ls|; s ∈ (ti−1; ti]}. Remark that T ∗i

where γmax is deﬁned in Assumption 4 (iv).

To estimate B1

Ai

n =
Xti−1<s≤ti;s6=T ∗

c
n ∩ (N i
n)

= K i

i

n(θ) we make the decomposition
∩ Ai

c
n ∩ (N i
K i
n)

|∆Ls| ≤

,

vn

γmax

c
n ∩ (N i
n)

n ∪ K i

∩ (Ai

n)c.

(76)

(77)

∩ Ai

n

Note that
c
n ∩ (N i
K i
n)
⊂ {|∆n
⊂ {|∆n

i X c| ≥ vn} .

i X c + γ(XT ∗

i −)∆LT ∗

i

+ Xs6=T ∗

i

∆Xs| ≤ vn;

|γ(XT ∗

i −)∆LT ∗

i | > 3vn;

| Xs6=T ∗

i

∆Xs| ≤ vn}

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

29

Hence, using (3) from Lemma 15 we get for all p > 1 :

(78)

P (K i

c
n ∩ (N i
n)

∩ Ai

n) ≤ P (|∆n

i X c| ≥ vn) = O(∆p/2

n v−p

n ) = O(∆εp

n ).

Together with (52), which is still true in the inﬁnite activity case, Hölder’s inequality, sub-polynomial
growth of f and (3) from Lemma 1 this gives for any p > 1 that

n

(79)

E sup

θ∈Θ|

Xi=1

f (θ, Xti−1)(cid:0)∆n

i X J(cid:1)(cid:0)1K i

n∩(N i

n)c∩Ai

n(cid:1)| = O(n∆εp

n ).

Using Hölder inequality, sub-polynomial growth of f , Lemma 1 (3), and Lemma 16, we get for

1/p + 1/q = 1 and some C > 0,

n

i X|≤vn(cid:1) 1K i
(cid:16)P ((N i

n∩(N i

n)c∩(Ai

c
n)

∩ (Ai

n)c|
n)c)(cid:17)1/q

i X c − ∆n

i X 1|∆n

E sup

n

Xi=1
θ∈Θ|
Xi=1(cid:18)E sup
≤
≤ Cn(∆1/2

f (θ, Xti−1)(cid:0)∆n
θ∈Θ|f (θ, Xti−1)|p(|∆n
n + vn)  ∆2
vn ˆ
n  ˆ

≤ Cnvε/2

n ∆2−ε

|z|≥3vn/γmin

n

i X c| + vn)p(cid:19)1/p
ν(dz)!1/q

ν(dz)!1−ε/2

|z|≥3vn/γmin

,

choosing 1/q = 1 − ε/2.

From (79) and (80), we get

(80)

(81)

To estimate B2

n(θ) we use the bound

ti−1 ˆR\{0}

n

n

E|f (θ, Xti−1)ˆ ti
Xi=1
E ˆ ti
ti−1 ˆ
Xi=1
≤
ˆ ti
ti−1 ˆ
Xi=1

≤

n

|z|≤3vn/γmin

Since γmin ≥ 1, we obtain,
(82)

E sup

n(θ)| = o

E sup

θ∈Θ|B1

n

n∆3/2−ε/2

 ˆ

|z|≥vn/γmin

ν(dz)!1−ε/2
 .

γ(Xs−)zµ(ds, dz)|1K i

n∩N i

n

|z|≤3vn/γmin |f (θ, Xti−1 )γ(Xs−)z|µ(ds, dz)

E[|f (θ, Xti−1 )γ(Xs)|]|z|ν(dz)ds = O(n∆n ˆ

|z|≤3vn/γmin |z|ν(dz)).

n(θ)| = O(n∆n ˆ

θ∈Θ|B2

|z|≤3vn/γmin |z|ν(dz)) ≤ O(n∆n ˆ

|z|≤3vn |z|ν(dz)).

The L1 norms of supθ∈Θ |G2

n(θ)| and supθ∈Θ |G3
n(θ)| have been studied in the Lemma 8, when the
Lévy process has ﬁnite activity. However, the proofs of the upper bounds (57) and (58), obtained
in Lemma 8, do not use the fact that ν(R) < ∞.
the proof of (ii). Using the events K i

Finally, collecting (57), (58) with 1/q = 1 − ε/2, (81), and (82) we obtain (i). We continue with

n given by (44) and (74) we deﬁne

n and N i

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

30

B3

n(θ) :=

n

Xi=1

f (θ, Xti−1 ) (∆n

i X c) 1(K i

n)c; B4

n(θ) :=

n)c∩(N i

n

Xi=1

f (θ, Xti−1) (∆n

i X c) 1(K i

n)c∩(N i

n);

and decompose the diﬀerence as follows

(83)

n

Xi=1

f (θ, Xti−1)(cid:0)∆n

i X c − ∆iX 1|∆n

i X|≤vn(cid:1) = B1

where B1

n(θ) and B2

n(θ) are given by (75). Using (79) and (80) we can see that

n(θ) + B2

n(θ) + B3

n(θ) + B4

n(θ),

(84)

E|B1

n(θ)| = o
while (82) gives the bound for E|B2
the case of the inﬁnite activity is similar to the role of M i
case. Therefore, to estimate B3
by N i

n  ˆ
n∆2−ε
n(θ)|. The role of the event N i

|z|≥3vn/γmin

n which leads to

ν(dz)!1−ε/2
 ,

n (all the jumps of L are small) in
n (L does not jump) in the ﬁnite activity
n(θ) we use a decomposition similar to (61), where we replace M i
n

(85)

B3

n(θ) =

n

Xi=1

f (θ, Xti−1) (∆n

i X c) 1(N i

n)c −

n

Xi=1

f (θ, Xti−1) (∆n

i X c) 1K i

n)c .

n∩(N i

We will show that the ﬁrst term of this decomposition goes to zero after suitable normalization.
Let ˜ei := f (θ, Xti−1)∆n

(N i

i X c1

n)c. Recall that
n)c(cid:1) = 1 − P (ˆ ti
ti−1 ˆ

|z|>3vn/γmin

P(cid:0)(N i

µ(ds, dz) = 0) = 1 − e−∆n ´|z|>3vn /γmin

ν(dz)

= O ∆nˆ

|z|>3vn/γmin

ν(dz)! .

Therefore, the same arguments that were used to obtain (64) give here

(86)

|E[˜ei|Fi−1]| ≤ h(|Xti−1|)∆2−ε/2

n

 ˆ

|z|>3vn/γmin

,

ν(dz)!1−ε/2
n (cid:16)´|z|>3vn/γmin

where h is a polynomial function. Hence, under the condition n∆3−ε

(87)

E(cid:20)

E" n
Xi=1(cid:12)(cid:12)(cid:12)(cid:12)

˜ei√n∆n |Fi−1(cid:21)(cid:12)(cid:12)(cid:12)(cid:12)

# = O

 ˆ

n

n1/2∆3/2−ε/2

Next, we bound the second moment of ˜ei. Similarly to (66) we obtain

|z|>3vn/γmin

→ 0,

ν(dz)!1−ε/2

ν(dz)(cid:17)2−ε
 → 0.

(88)

E[˜e2

i ] ≤ ∆nP [(N i

n)c]1−ε/2 = O

n

∆2−ε/2

 ˆ

|z|>3vn/γmin

ν(dz)!1−ε/2
 ,

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

31

Hence, using ∆n ´|z|>3vn/γmin

we have

n (cid:16)´|z|>3vn/γmin

ν(dz)(cid:17)2−ε

→ 0,

Under (87) and (89) we obtain from Lemma 9 in Genon-Catalot and Jacod [1993] that

(89)

(90)

n

ν(dz) → 0, which is implied by n∆3−ε
E"(cid:18) ˜ei√n∆n(cid:19)2
 ˆ
∆1−ε/2

E"(cid:18) ˜ei√n∆n(cid:19)2#
Xi=1
ν(dz)!1−ε/2
 → 0.

|Fi#(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
# =

|z|>3vn/γmin

n

n

E"(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1
= O

f (θ, Xti−1 )∆n

i X c1(N i

n)c =

˜ei√n∆n

P−→ 0

n

Xi=1

n

1

Xi=1
√n∆n
ν(dz)(cid:17)2−ε

→ 0.

if n∆3−ε

n (cid:16)´|z|>3vn/γmin

Recall that the second term in the decomposition (85) of B3

n is given by

f (θ, Xti−1 )∆n

i X c1

n

Xi=1

K i

n∩(N i

n)c.

We will now bound this term in L1. Using the set Ai

n deﬁned by (77) we decompose

The ﬁrst term of this decomposition is bounded in L1 using (78). As a result, for all p > 1,

1

K i

n∩(N i

n)c = 1

K i

n∩(N i

n)c∩Ai

n

+ 1

K i

n∩(N i

n)c∩(Ai

n)c .

(91)

E sup

θ∈Θ|

n

Xi=1

Then, exactly as in (80), we get

f (θ, Xti−1) (∆n

i X c)(cid:0)1K i

n∩(N i

n)c∩Ai

n(cid:1)| = O(n∆εp

n ).

(92)

E|

n

Xi=1

As a result,

(93)

f (θ, Xti−1 ) (∆n

i X c)(cid:0)1K i

n∩(N i

n)c∩(Ai

n)c(cid:1)| = o n∆2−ε
n (ˆ

|z|≥vn/γmin

ν(dz))1−ε/2! .

B3

n(θ) = oP (pn∆n) + oL1 n∆2−ε
n (ˆ

|z|≥vn/γmin

ν(dz))1−ε/2! .

It remains to estimate the term B4

n in the decomposition (83). Observe that for all p > 1,

P ((K i
P (|∆n

n) =

n)c ∩ N i
i X c + Xti−1<s≤ti
n + P (|ˆ ti

ti−1

C∆εp

∆Xs| > vn; N i

n) ≤ P (|∆n

i X c| >

γ(Xs−)ˆ

zµ(ds, dz)| >

vn
2

|z|≤3vn/γmin

vn
2

) + P (| Xti−1<s≤ti
vn ˆ
) ≤ C∆εp

n +

∆n

∆Xs| >

vn
2

; N i

n) ≤

|z|≤3vn/γmin |z|ν(dz),

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

32

where C > 0. Using Hölder’s inequality twice, this last bound, sub-polynomial growth of f and
Lemma 15 (iii) we can easily see that with 1/q = 1 − ε/2 we get
(94)

n

E|B4
n(θ)| =
Xi=1
E|
n   ∆n
vn ˆ

n∆1/2

f (θ, Xti−1) (∆n

i X c) 1(K i

n)c∩N i

n| ≤

|z|≤3vn/γmin |z|ν(dz)!1−ε/2

n

Xi=1(cid:0)E|f (θ, Xti−1 )|p|∆n
≤ n∆1+ε/2

n

i X c|p(cid:1)1/p

P 1/q(K i

n)c ∩ N i

n) ≤

|z|≤3vn/γmin |z|ν(dz)!1−ε/2
 ˆ

.

Finally, collecting (82), (84), (93) and (94) we obtain assertion (ii) of the lemma.

(cid:3)

Proof of Lemma 10. Using dX c

s = b(θ⋆, Xs)ds + σ(Xs)dWs we decompose the diﬀerence as

(95)

where

(96)

ˆ tn

0

f (θ, Xs) dX c

s −

n

Xi=1

f (θ, Xti−1)∆n

i X c = An,1(θ) + An,2(θ) + An,3(θ),

An,1(θ) :=

An,2(θ) :=

ti−1

ˆ ti
ˆ ti
ˆ ti

ti−1

ti−1

n

n

Xi=1
Xi=1
Xi=1

n

(f (θ, Xs) − f (θ, Xti−1))σ(Xs)dWs,

(f (θ, Xs) − f (θ, Xti−1))(b(θ⋆, Xs) − b(θ⋆, Xti−1))ds,

(f (θ, Xs) − f (θ, Xti−1))b(θ⋆, Xti−1 )ds.

(97)

An,3(θ) :=

Let us start by proving (ii). Let as previously Ft = σ{X0, Wu, Lu; u ≤ t}, t ≥ 0. Using martingale
property and Itô’s isometry of the stochastic integral together with the ﬁnite increments formula
applied to f , we obtain

E[A2

n

n

ti−1

(f (θ, Xs) − f (θ, Xti−1 ))σ(Xs)dWs!2
n,1(θ)] = E
Xi=1 ˆ ti


ˆ ti
Xi=1
(f (θ, Xs) − f (θ, Xti−1 ))2σ2(Xs)ds
ˆ ti
Xi=1
E(cid:2)(Xs − Xti−1 )2f′2(θ, ˜x)σ2(Xs)(cid:3) ds,

= E

≤

ti−1

ti−1

n

where ˜x is a point between Xs and Xti−1 . Note that |˜x| ≤ |Xs| + |Xti−1|. Using sub-polynomial
growth of σ and supθ |f′(θ, .)|, Hölder’s inequality, (3) of the Lemma 1 and (1) of the Lemma 15
yields

E(cid:2)(Xs − Xti−1)2f′2(θ, ˜x)σ2(Xs)(cid:3) ≤ CE[|Xs − Xti−1|2q]1/q ≤ C∆1/q

(98)
where q > 1 and C is a positive constant. Hence, for all θ ∈ Θ,
n,1(θ)] ≤ Cn∆1+1/q

E[A2

n

n ,

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

33

and consequently

(99)

1

√n∆n

An,1(θ) L2

−→ 0.

Using Lipshitz continuity of b, and the same arguments than for obtaining (98), it follows imme-

diately that

(100)

E[sup

θ∈Θ|An,2(θ)|] ≤ Cn∆1+1/q

n

Hence, by choosing q = 1 − ε/2 such that n∆1+2/q

n

= n∆3−ε

1

√n∆n

sup

θ∈Θ|An,2(θ)| L1

n → 0 it follows that
−→ 0.

(101)

Observe that by Itô’s formula An,3(θ) can be written as

An,3(θ) = an(θ) + bn(θ) + cn(θ),

where

n

an(θ) =

bn(θ) =

cn(θ) =

n

Xi=1
Xi=1
Xi=1

n

ti−1

b(θ⋆, Xti−1 )ˆ ti
b(θ⋆, Xti−1 )ˆ ti
b(θ⋆, Xti−1)ˆ ti

ti−1

ti−1

Denote

en
i :=

1

√n∆n ˆ ti

ti−1

ti−1

dsˆ s
dsˆ s
ds Xτ∈[ti−1,s]
dsˆ s

ti−1

f′(θ, Xu)σ(Xu)dWu,

ti−1(cid:20)f′(θ, Xu)b(θ⋆, Xu) + f′′(θ, Xu)

1
2

σ2(Xu)(cid:21) du,

(f (θ, Xτ ) − f (θ, Xτ−)).

b(θ⋆, Xti−1 )f′(θ, Xu)σ(Xu)dWu

Using martingale property of the stochastic integral with respect to W we obtain

Using Hölder’s inequality and isometry property of the stochastic integral we get

E(cid:2)en
i |Fti−1(cid:3) = 0.
dsE ˆ s
dsˆ s

ti−1

ti−1

ti−1

1

n ˆ ti
n ˆ ti

1

ti−1

b(θ⋆, Xti−1)f′(θ, Xu)σ(Xu)dWu!2
E(cid:2)b2(θ⋆, Xti−1)f′2(θ, Xu)σ2(Xu)(cid:3) du ≤ C

∆2
n
n

,

E(cid:0)E(cid:2)(en

i )2|Fti−1(cid:3)(cid:1) = E(cid:2)(en

i )2(cid:3) ≤

=

where in the last inequality we have used the uniform in θ sub-polynomial growth of f′ and b,
sub-linear growth of σ and Lemma 1(3). Therefore

E

n

Xi=1

Eh(en

i )2 |Fti−1i ≤ C∆2

n → 0 when n → ∞.

We conclude, using Lemma 9 in Genon-Catalot and Jacod [1993], that ∀θ ∈ Θ,
(102)

an(θ) =

1

n

√n∆n

en
i

P−→ 0.

Xi=1

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

34

Using again uniform in θ sub-polynomial growth of b, f′, f′′, sub-linearity of σ and (3) of the Lemma
1 we easily see that

(103)

E sup

θ∈Θ|bn(θ)| ≤ Cn∆2

n.

Let us now derive a bound for the jump term cn.

(104)

(105)

E sup

n

θ∈Θ|cn(θ)|
ˆ ti
Xi=1
≤
ˆ ti
Xi=1

≤

ti−1

ti−1

n

ti−1

dsˆ s
dsˆ s

duˆR\{0}
duˆR\{0}

E|b(θ⋆, Xti−1)||f (θ, Xu− + γ(Xu−)z) − f (θ, Xu−)|µ(du, dz)

E|b(θ⋆, Xti−1)f′(θ, ˜x)γ(Xu−)||z|ν(dz).

ti−1

where in the second inequality we used again the ﬁnite increments formula and denoted ˜x the
corresponding point between Xu− and Xu = Xu− + γ(Xu−)z. Note that again |˜x| ≤ |Xu−| + |Xu|.
According to the Assumptions 3 (i), (iii) and the assumption b) of the Lemma, the functions γ,
b(θ⋆, .) and supθ |f′(θ, .)| are sub-polynomial, and ν(|z|) < ∞. Therefore, using (3) from Lemma 1
we have

sup

θ∈ΘˆR\{0}

E|b(θ⋆, Xti−1)f′(θ, ˜x)γ(Xu−)||z|ν(dz) < ∞.

This last inequality together with (104) gives

(106)

E sup

θ∈Θ|cn(θ)| = O(n∆2

n).

From (102), (103) and (106) we conclude that under condition n∆3−ε

n → 0,

(107)

1

√n∆n

An,3(θ) P−→ 0.

Finally, the previous display together with (99) and (101) proves (ii) of the lemma. To prove the
claim (i) we will again use the decomposition of the diﬀerence given by (95).

Using the same arguments as in (98) and Lemma 15 (1), we get for some p > 1, C > 0 and ˜x

between Xs and Xti−1:

n

n

C

E sup

ti−1

ˆ ti
Xi=1
E(cid:16)(cid:12)(cid:12)Xs − Xti−1(cid:12)(cid:12)

E(cid:2)|f′(θ, ˜x)(1 + |Xti−1|p)|(cid:12)(cid:12)Xs − Xti−1(cid:12)(cid:12)(cid:3) ds ≤
2(cid:17)1/2
(cid:0)E(cid:2)|f′(θ, ˜x)|2(1 + |Xti−1|2p)(cid:3)(cid:1)1/2
n ds ≤ Cn∆3/2
n .

ds ≤

θ∈Θ|An,3(θ)| ≤ C
ˆ ti
Xi=1
ˆ ti
Xi=1

C∆1/2

ti−1

ti−1

n

1

n∆n

sup

θ∈Θ|An,3(θ)| L1

−→ 0.

Hence

(108)

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

35

The bound (100) gives

(109)

From (99) we know that

1

n∆n

sup

θ∈Θ|An,2(θ)| L1

−→ 0.

∀θ ∈ Θ,

1

n∆n

An,1(θ) P−→ 0.

Let us prove that this convergence holds uniformly with respect to θ. Denote φ : [0, tn] → [0, tn],
φ(s) = ti−1 if ti−1 ≤ s < ti, i = 0, . . . , n − 1, and deﬁne

Mn(θ) :=

1
tn

An,1(θ) =

1

tn ˆ tn

0

(f (θ, Xs) − f (θ, Xφ(s)))σ(Xs)dWs.

Using Burkholder-Davis-Gundy inequality, Hölder continuity of f , sub-polynomial growth of its
Hölder constant K, sub-linear growth of σ and the boundedness of moments of X given by (3) of
Lemma 1 we ﬁnd that for any p ≥ 2 and some C > 0,

E|Mn(θ) − Mn(θ′)|p ≤ |θ − θ′|κp C
tp/2
n
≤ |θ − θ′|κp C
tp/2+1
n

(cid:0)K 2(Xs) + K 2(Xφ(s))(cid:1) σ(Xs)2ds(cid:19)

tn ˆ tn
E(cid:18) 1
ˆ tn
E(cid:0)K 2(Xs) + K 2(Xφ(s))(cid:1)p/2

σ(Xs)pds ≤ C|θ − θ′|κp.
κ and using the Theorem 20 in the Appendix of I. Ibragimov [2013] we obtain

Choosing p > d

0

0

p/2

and the statement (i) follows.

1

n∆n

sup

θ∈Θ|An,1(θ)| P−→ 0

8. Auxiliary results

(cid:3)

In this section we gather some auxiliary results that are frequently used in our proofs. Further-
more, we give a proof of the ergodicity results of Lemma 1. We start by some moment inequalities
for jump diﬀusions and their continuous martingale part.

Lemma 15. Let X satisfy Assumption 1. Then for all t > s,

(1) ∀p ≥ 2,

E[|Xt − Xs|p]1/p ≤ C|t − s|1/p.

(2) Let Fs = σ{Xu, 0 ≤ u ≤ s}. Then for p ≥ 2, p ∈ N,

E[|Xt − Xs|p|Fs] ≤ |t − s|(1 + |Xs|p).

(3) ∀p > 1,

E [|X c

t − X c

s|p]1/p ≤ C|t − s|1/2.

Proof. The ﬁrst claim follows easily from the two lemmas and Theorem 66 on p. 339 in Protter
[2004]. The second claim follows from Proposition 3.1 in Shimizu and Yoshida [2006] and the third
from the ﬁrst two lemmas on p.339 in Protter [2004].
(cid:3)

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

36

Lemma 16. Under assumptions 1 to 4, we have for some C > 0,

P ((N i

n)c ∩ (Ai

n)c) ≤ C

∆2
n

vn/γmin ˆ

|z|≥3vn

ν(dz).

Proof. We need to introduce some notations. For z > 0, we deﬁne Uz = ´ ti
ti−1 ´|y|≥1/z µ(ds, dy)
the number of jumps of (Xs), s ∈ (ti−1, ti], with a size greater than 1/z, and we set U0 = 0. It
is clear that (Uz)z≥0 is a process whose increments are independent and distributed with Poisson
laws. Hence, it is a Poisson process, and by a simple computation we can show that it has a jump
intensity equal to (ti − ti−1)z−2(ν(z−1) + ν(−z−1)), where ν(z) = ν(dz)/dz exists by Assumption
4 (iii).
We deﬁne the ﬁltration generated by the process (Uz)z≥0, by setting for all z ≥ 0, Gz = σ{Uy; y ≤
z}. We note Z∗1 the ﬁrst jump time of the process U , which is a stopping time. By construction,
we have that 1/Z∗1 is the size of the biggest jumps of the Lévy process L on (ti−1, ti], or with the
notations of Lemma 9 that, 1/Z∗1 = |∆LT ∗

i | = max{|∆Ls|; s ∈ (ti−1; ti]}.

i |, where |∆LT ∗

Moreover, we can write

Xti−1<s≤ti;s6=T ∗

i

|∆Ls| = ˆ ti
ti−1 ˆ

|y|<1/Z∗

1

|y|µ(ds, dy) = ˆ(Z∗

1 ,∞)

1
z

dUz,

where we have used that ∆LT ∗

i

is the only jump with the maximal size 1/Z∗1 . Hence, we have

|∆Ls| >

vn

γmax


n)c) = P 

i | >

3vn
γmin

;

3vn
γmin

;

|∆LT ∗
ˆ(Z∗
P  ˆ(Z∗

1 ,∞)

c
P ((N i
n)

∩ (Ai
= P  (Z∗1 )−1 >
= E"1
≤

E"1

γmax

{(Z∗

vn

{(Z∗

1 )−1> 3vn

γmin }

z−1dUz >

z−1dUz >

i

vn

Xti−1<s≤ti;s6=T ∗
γmax!
1!#
vn
γmax | GZ∗
1!# ,

1 )−1> 3vn

γmin }

z−1dUz | GZ∗

1 ,∞)

E ˆ(Z∗

1 ,∞)

where we have used the Markov inequality in the last line. Using now that (Uz)z≥0 is a Poisson
process with an explicit jump intensity U (z) := (ti − ti−1)z−2(ν(z−1) + ν(−z−1)), we deduce,

c
P ((N i
n)

∩ (Ai

n)c) ≤

γmax

vn

E"1

{(Z∗

1 )−1> 3vn

γmin }

E ˆ(Z∗

1 ,∞)

z−1U (z)dz | GZ∗

1!# .

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

37

But, by a simple change of variable, ´(Z∗

We conclude

P ((N i
n)

c

∩ (Ai

n)c) ≤

γmax

1 ,∞) z−1U (z)dz = (ti−ti−1)´|y|<1/Z∗
∆n(cid:18)ˆR |y|ν(y)dy(cid:19) P(cid:20)(Z∗1 )−1 >
γmin(cid:21)
P (cid:18)µ((ti−1, ti] × [(−∞,−
) ∪ (
vn ˆ

3vn
γmin

vn
∆n
vn
∆2
n

ν(dz),

3vn
γmin

3vn

≤ C

≤ C

|z|> 3vn

γmin

1 |y|ν(y)dy ≤ ∆n´R |y|ν(y)dy.

, +∞)]) ≥ 1(cid:19)

where C > 0. The lemma is proved.

(cid:3)

Proposition 17. Under Assumptions 1 to 4, the Assumption 6 is equivalent to the condition

∀(θ, θ′) ∈ Θ2,

such that

θ 6= θ′,

b(θ, .) 6= b(θ′, .).

Proof. It is suﬃcient to show that if O is some non empty, open set, then πθ(O) > 0. It is proved
in Masuda [2007] (see equation (13) p.43) that for all ∆ > 0, x ∈ R, and O non empty, open set,
P (X θ

∆ ∈ O | X θ

0 = x) > 0. From this, we deduce that
∆ ∈ O | X θ

πθ(O) = ˆR

P (X θ

0 = x)dπθ(x) > 0.

We conclude this section with a proof of the ergodicity results and moment bounds of Lemma

(cid:3)

1. The proof is based on Masuda [2007].
Proof of Lemma 1. Let q > 2, q even and f ⋆(x) = |x|q. We show that f ⋆ satisﬁes the drift condition

where c1 > 0, c2 > 0. Denote

Af ⋆ ≤ −c1f ⋆ + c2,

1
2

Gf (x) =
J f (x) = ˆR

σ2(x)f′′(x) + b(θ, x)f′(x),

(f (x + zγ(x)) − f (x))ν(dz).

for any f such that the two previous expressions are deﬁned and decompose

Using Taylor’s formula together with Assumptions 3 (iii) and 4 (ii) we can write

A = G + J .

sup

u∈[x,x+zγ(x)]|f ⋆′

(u)|ν(dz) ≤ Cγ(x)|x|q−1 ˆR |z|(1 + |z|)q−1ν(dz) = o(|x|q)

|J f ⋆(x)| ≤ ˆR |zγ(x)|
as x → ∞. Using Assumption 3 (ii) and (iv) we get
Gf ⋆(x) =
σ2(x)q(q − 1)xq−2 + b(θ, x)xqxq−2 ≤ −C|x|2qxq−2 + o(|x|q) ≤ −Cqf ⋆(x) + o(|x|q),
for some C > 0. As Af ⋆(x) is locally bounded, using two previous displays we can choose c2 > 0
and c1 > 0 such that for all x ∈ R,

1
2

Af ⋆(x) ≤ −c1f ⋆(x) + c2.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

38

Hence, Assumption 3⋆ from Masuda [2007] holds and using Theorem 2.2 from Masuda [2007] we
get then

(110)

and using Fatou’s lemma results in

E[|X θ

s|q] < ∞

sup
s≥0

E[|X θ

s−|q] < ∞.

sup
s≥0

Hence we proved the assertion (3). Using Assumption 2 and the Theorem 2.1 from Masuda [2007]
we get for all θ ∈ Θ that X θ admits the unique invariant distribution πθ, f ⋆ ∈ L1(πθ) and the
ergodic theorem holds. We proved (1) and (2). We continue with the proof of (4). Using ergodic
theorem, for all q > 0,

1

t ˆ ∞

0

lim
t→∞

|X θ

s|qds = πθ(|x|q), P − a.s.

Moreover, using Jensen’s inequality and the bound (110) we get the uniform integrability of the
t ´ t
family { 1
0 |X θ

s|qds, t > 0}:
E(cid:18) 1

1+ε

t ˆ t
0 |X θ

s|qds(cid:19)

1

t ˆ t

0

≤

[E|X θ

s|q(1+ε)]ds ≤ C,

where C > 0, and hence

lim
t→∞

1

t ˆ t

0

E|X θ

s|qds = πθ(|x|q).

(cid:3)

Proof of Lemma 11. Let us ﬁrst prove (i). Using Lemma 15 (1), with some ˜x between Xti−1 and
Xs in the third line below we obtain:

E sup

0

n

n

n

θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1
Xi=1

n

= E sup

Xi=1

f (θ, Xs) − f (θ, Xti−1 ) ds(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
f (θ, Xti−1)∆iId(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
θ∈Θ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ˆ ti
ˆ tn
Xi=1
f (θ, Xs) ds −
ˆ ti
ˆ ti
θ∈Θ|f′(θ, ˜x)|(cid:12)(cid:12)Xs − Xti−1(cid:12)(cid:12)(cid:21) ds
E(cid:20)sup
θ∈Θ(cid:12)(cid:12)f (θ, Xs) − f (θ, Xti−1 )(cid:12)(cid:12)(cid:21) ds ≤
E(cid:20)sup
Xi=1
θ∈Θ|f′(θ, ˜x)|2(cid:19)1/2
ˆ ti
ti−1(cid:18)E sup
(cid:0)E|Xs − Xti−1|2(cid:1)1/2
ds ≤ Cn∆3/2
n .

ti−1

ti−1

ti−1

n

≤

≤

We now prove (ii). We ﬁnd that

ˆ tn

0

f (θ, Xs) ds −

n

Xi=1

f (θ, Xti−1 )∆n

i Id =

n

Xi=1

ˆ ti
ti−1(cid:0)f (θ, Xs) − f (θ, Xti−1)(cid:1) ds,

and it is then apparent that this term can be treated exactly as the term An,3(θ) given by the
equation (97). Hence, from (107) (which requires the condition n∆3−ε
n → 0) we have the result. (cid:3)

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

39

References

David Applebaum. Lévy processes and stochastic calculus. 2nd ed. Cambridge Studies in Advanced

Mathematics 116. Cambridge University Press., 2009.

Ole E. Barndorﬀ-Nielsen and Neil Shephard. Non-Gaussian Ornstein-Uhlenbeck-based models and
some of their uses in ﬁnancial economics. J. R. Stat. Soc., Ser. B, Stat. Methodol., 63(2):167–241,
2001.

Markus Bibinger and Lars Winkelmann. Econometrics of co-jumps in high-frequency data with
noise. Journal of Econometrics, 184(2):361 – 378, 2015. ISSN 0304-4076. doi: http://dx.doi.org/
10.1016/j.jeconom.2014.10.004.

Rama Cont and Peter Tankov. Financial modelling with jump processes. Chapman & Hall, 2004.
John C. Cox, Jonathan E. Ingersoll, and Stephen A. Ross. A theory of the term structure of interest

rates. Econometrica, (53):363–384, 1985.

Susanne Ditlevsen and Priscilla Greenwood. The morris–lecar neuron model embeds a leaky
integrate-and-ﬁre model. Journal of Mathematical Biology, 67(2):239–259, 2013. ISSN 0303-6812.
doi: 10.1007/s00285-012-0552-7. URL http://dx.doi.org/10.1007/s00285-012-0552-7.

D. Florens-Zimrou. Approximate discrete-time schemes for statistics of diﬀusion processes,. Statis-

tics, 20:547–557, 1989.

Valentine Genon-Catalot and Jean Jacod. On the estimation of the diﬀusion coeﬃcient for multi-
dimensional diﬀusion processes. Annales de l’institut Henri Poincaré (B) Probabilités et Statis-
tiques, 29(1):119–151, 1993.

James E. Hutton and Paul . Nelson.

Interchanging the order of diﬀerentiation and stochastic

integration. Stochastic Processes and their Applications, 18(2):371–377, 1984.

R. Has’minskii I. Ibragimov. Statistical estimation:asymptotic theory. 2013.
Jean Jacod and Albert N. Shiryaev. Limit theorems for stochastic processes. 2nd ed. Grundlehren

der Mathematischen Wissenschaften. 288. Berlin: Springer, 2003.

Mathieu Kessler. Estimation of an ergodic diﬀusion from discrete observations. Scandinavian
Journal of Statistics, 24(2):211–229, 1997. ISSN 1467-9469. doi: 10.1111/1467-9469.00059. URL
http://dx.doi.org/10.1111/1467-9469.00059.

S. G. Kou. A jump-diﬀusion model for option pricing. Management Science, 48(8):1086–1101, 2002.

doi: 10.1287/mnsc.48.8.1086.166. URL http://dx.doi.org/10.1287/mnsc.48.8.1086.166.

Uwe Küchler and Michael Sørensen. A note on limit theorems for multivariate martingales.

Bernoulli, 5(3):483–493, 1999. URL http://dx.doi.org/10.2307/3318713.

D. Loukianova and O. Loukianov. Uniform law of large numbers and consistency of estimators for
Harris diﬀusions. Statist. Probab. Lett., 74(4):347–355, 2005. ISSN 0167-7152. doi: 10.1016/j.spl.
2005.04.056. URL http://dx.doi.org/10.1016/j.spl.2005.04.056.

Hilmar Mai.
processes.
20(2):919–957,
http://dx.doi.org/10.3150/13-BEJ510.

Eﬃcient maximum likelihood estimation for Lévy-driven Ornstein-Uhlenbeck
Bernoulli,
URL

10.3150/13-BEJ510.

05 2014.

doi:

Cecilia Mancini. The speed of convergence of the threshold estimator of integrated variance. Sto-

chastic Process. Appl., 121(4):845–855, 2011.

Hiroki Masuda. Ergodicity and exponential β-mixing bounds for multidimensional diﬀusions with

jumps. Stochastic Process. Appl., 117(1):35–56, 2007.

Hiroki Masuda. Erratum to :"ergodicity and exponential β-mixing bound for multidimensional

diﬀusions with jumps". Stochastic Processes and their Applications, 119:676–678, 2009.

Hiroki Masuda. Convergence of gaussian quasi-likelihood random ﬁelds for ergodic lévy driven sde
observed at high frequency. Ann. Statist., 41(3):1593–1641, 06 2013. doi: 10.1214/13-AOS1121.

JUMP FILTERING AND EFFICIENT DRIFT ESTIMATION FOR LÉVY-DRIVEN SDE’S

40

URL http://dx.doi.org/10.1214/13-AOS1121.

Robert Merton. Option pricing when underlying stock returns are discontinuous. J. Financial

Economics, 3:125–144, 1976.

Philip E. Protter. Stochastic integration and diﬀerential equations. 2nd ed. Applications of Math-

ematics 21. Berlin: Springer, 2004.

Yasutaka Shimizu. M-estimation for discretely observed ergodic diﬀusion processes with inﬁnetely

many jumps. Stat. Inference Stoch. Process., 9:179–225, 2006.

Yasutaka Shimizu and Nakahiro Yoshida.

cesses with jumps from discrete observations.
cesses, 9(3):227–277, 2006.
ISSN 1387-0874.
http://dx.doi.org/10.1007/s11203-005-8114-x.

Estimation of parameters for diﬀusion pro-
Statistical Inference for Stochastic Pro-
doi:
URL

10.1007/s11203-005-8114-x.

Ngoc Khue Tran. LAN property for jump diﬀusion processes with discrete observations via Malliavin

calculus. PhD thesis, University Paris 13, 2014.

Aad W. Van der Vaart. Asymptotic statistics. Cambridge Series in Statistical and Probabilistic

Mathematics, Cambridge University Press., 1998.

Nakahiro Yoshida. Estimation for diﬀusion processes from discrete observation. Journal of Multi-

variate Analysis, 41(2):220 – 242, 1992.

Université d’Evry Val d’Essonne, 91037 Évry Cedex, France
E-mail address: arnaud.gloter@univ-evry.fr

Université d’Evry Val d’Essonne, 91037 Évry Cedex, France
E-mail address: dasha.loukianova@maths.univ-evry.fr

Centre de Recherche en Economie et Statistique, ENSAE-ParisTech, 92245 Malakoff, France
E-mail address: hilmar.mai@ensae.fr

