Design and Analysis Framework for Sparse FIR

Channel Shortening

1

Abubakr O. Al-Abbasi∗, Ridha Hamila∗, Waheed U. Bajwa†, and Naofal Al-Dhahir‡

∗ Dept. of Electrical Engineering, Qatar University, Qatar

† Dept. of Electrical and Computer Engineering, Rutgers University, USA

‡ Dept. of Electrical Engineering, University of Texas at Dallas, USA

6
1
0
2

 
r
a

M
1

 

 
 
]
T
I
.
s
c
[
 
 

1
v
0
6
1
0
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—A major performance and complexity limitation in
broadband communications is the long channel delay spread
which results in a highly-frequency-selective channel frequency
response. Channel shortening equalizers (CSEs) are used to
ensure that the cascade of a long channel impulse response (CIR)
and the CSE is approximately equivalent to a target impulse
response (TIR) with much shorter delay spread. In this paper,
we propose a general framework that transforms the problems
of design of sparse CSE and TIR ﬁnite impulse response (FIR)
ﬁlters into the problem of sparsest-approximation of a vector in
different dictionaries. In addition, we compare several choices
of sparsifying dictionaries under this framework. Furthermore,
the worst-case coherence of these dictionaries, which determines
their sparsifying effectiveness, are analytically and/or numerically
evaluated. Finally, the usefulness of the proposed framework for
the design of sparse CSE and TIR ﬁlters is validated through
numerical experiments.

I. INTRODUCTION

In many applications, the channel delay spread, deﬁned
as the duration in time, or samples, over which the channel
impulse response (CIR) has signiﬁcant energy, is too long and
results in performance and complexity limitations for com-
munications transceivers. For instance, a large delay spread
exceeding the cyclic preﬁx (CP) length causes inter-symbol
interference (ISI) and inter-carrier interference (ICI) in multi-
carrier modulation (MCM) systems [1] and increases the com-
plexity of sequence estimators such as the Viterbi algorithm [2]
whose computational complexity increases exponentially with
the number of CIR taps. In MCM, ISI and ICI are prevented
by inserting a CP whose length must be greater than or equal
to the CIR length, which results in a data rate reduction [3].
The aim of the channel shortening equalizers (CSEs) is to
ensure that the combined impulse response of the channel and
the CSE is approximately equivalent to a short target impulse
response (TIR). Several CSE design approaches have been
investigated in the literature. In [4], a uniﬁed framework for
computing the optimum settings of a TIR is proposed under
the unit-tap constraint (UTC) and the unit-energy constraint
(UEC). This framework is extended in [5] to accommodate
multiple-input multiple-output (MIMO) systems. A CSE is
designed in [6] to maximize the output signal-to-interference
ratio, also known as the channel-shortening SNR. In [7], the
mean-square error (MSE) between the CIR-CSE cascade and

This paper was made possible by grant number NPRP 06-070-2-024 from
the Qatar National Research Fund (a member of Qatar Foundation). The
statements made herein are solely the responsibility of the authors.

the TIR is minimized subject to a UEC on the TIR. However,
none of these designs impose a sparsity constraint on the
CSE to reduce its implementation complexity. One possible
approach to design a sparse ﬁlter is the exhaustive search
method [8]. However, it is applicable only to the design of
low-order sparse ﬁnite impulse response (FIR) ﬁlters since
its computational cost increases exponentially with the ﬁlter
order. Channel shortening in [9] is performed blindly in which
the CSE coefﬁcients can be inferred directly from the received
data without the channel knowledge. In [10], a framework for
designing sparse CSE and TIR is proposed. Using greedy algo-
rithms, the proposed framework achieved better performance
by designing the TIR taps to be non-contiguous compared to
the approach in [4], where the TIR taps are assumed to be
contiguous. However, this approach involves inversion of large
matrices and Cholesky factorization, whose computational cost
could be large for channels with large delay spreads. In
addition, no theoretical sparse approximation guarantees are
provided.

In this paper, we develop a general framework1 for the
design of sparse CSE and TIR FIR ﬁlters that transforms
the original problem into one of sparse approximation of a
vector using different dictionaries. The developed framework
can then be used to ﬁnd the sparsifying dictionary that leads to
the sparsest FIR ﬁlter subject to an approximation constraint.
Moreover, we investigate the coherence of the sparsifying
dictionaries that we propose as part of our analysis and identify
one dictionary that has the smallest coherence. Then, we use
simulations to validate that the dictionary with the smallest
coherence results in the sparsest FIR design. Finally,
the
numerical results demonstrate the signiﬁcance of our approach
compared to conventional sparse TIR designs, e.g., in [12], in
terms of both performance and computational complexity.

Notations: We use the following standard notation in
this paper: I N denotes the identity matrix of size N.
Upper- and lower-case bold letters denote matrices and
vectors,
respectively. Underlined upper-case bold letters,
e.g., X, denote frequency-domain vectors. The notations
(.)−1, (.)∗, (.)T and (.)H denote the matrix inverse, the ma-
trix (or element) complex conjugate, the matrix transpose and
the complex-conjugate transpose operations, respectively. E [.]
denotes the expected value operator. (cid:107).(cid:107)(cid:96) and (cid:107).(cid:107)F denote
1This framework generalizes our results in [11] from linear equalization
(which follows as a special case of our framework presented here by setting
the TIR to be a single delayed impulse) to CSE.

2

We denote the span (the ﬁlter length) of the CSE by Nf and
the span of the TIR by Nb. The kth channel shortening error
sample ek is deﬁned as follows (see Figure 1):

ek =

nyk−m − Nb(cid:88)

∗

m=0

Nf −1(cid:88)
= (cid:2) w∗
(cid:124)
(cid:2) 01×∆ b∗
(cid:124)

w
0 w∗

1

0

∗
nxk−∆−n

(cid:3)
(cid:125)

b
. . . w∗

n=0

Nf −1

(cid:123)(cid:122)

wH

b∗

1

. . .

b∗

Nb

yk:k+Nf +1 −
(cid:3)
(cid:125)

01×s

(cid:123)(cid:122)

bH

xk:k−Nf −v+1

= wH yk:k+Nf +1 − bH xk:k−Nf −v+1 ,

(5)
where ∆ represents the decision delay and s = Nf + v − ∆−
Nb − 1. Hence, the MSE, denoted as ξ (w, b) is given by

(cid:12)(cid:12)(cid:3)

ξ (w, b) (cid:44) E(cid:2)(cid:12)(cid:12)e2
(cid:105)
(cid:104)

k

= wH Ryyw − wH Ryxb − bRH

yxwH + bH Rxxb. (6)

Using the well-known orthogonality principle for MMSE, i.e.,
the error sequence is uncorrelated with the observed data,
E

= 0, we get

ekyk:k+Nf +1

wH Ryy = bH Ryx.

(7)

Combining (6) and (7), we derive the MSE as

ξ (b) = bH(cid:0)Rxx − RxyR−1
(cid:123)(cid:122)

(cid:124)

Rδ

(cid:1)
(cid:125)

yy Ryx

b.

(8)

Minimizing ξ (b) over b, gives the trivial solution b = 0.
Thus, to preclude this trivial case, we minimize ξ (b) subject
to the UTC2 where one of the (Nb + 1) nonzero taps is set
to unity. The index of this unit tap i (0 < i ≤ Nf + v − 1) is
chosen such that the MSE ξ (b) is minimized. To minimize
the MSE subject to the UTC, bH ei = 1 (where ei is the ith
unit vector), we express Rδ in (8) as AH A where A is the
square root matrix of Rδ in the spectral-norm sense, which
results from Cholesky or eigen decomposition [14]. Then, (8)
can be written as

ξ (b, i) = bH AH Ab = (cid:107)Ab(cid:107)2

2

(cid:13)(cid:13)(cid:13)(cid:101)A(cid:101)b + ai

(cid:13)(cid:13)(cid:13)2

,

2

=

(9)

is the ith column of A, (cid:101)A is composed of all
columns of A except ai, and(cid:101)b is formed by all elements of b

where ai

except the ith entry with unit value. Since only (Nb + 1) taps
out of the total (Nf + v) TIR taps are nonzero, the locations
and weights of these taps need to be estimated such that ξ (b)
is minimized. Towards this goal, we need ﬁrst to optimize the
location of the unit tap index i. By formulating the Lagrangian
function: LU T C (b, λ) = ξ (b)+λ
, where λ is the

bH ei − 1

(cid:16)

(cid:17)

2The UTC is a generalization of the monicity constraint which is, in general,
imposed on linear prediction ﬁlters [13] where it results in a white error
sequence ek when the length of the ﬁlters increases, i.e., Nb converges to v
and Nf converges to inﬁnity.

v(cid:88)

Figure 1. A schematic of the system model.

the (cid:96)-norm and Frobenius norm, respectively. ⊗ denotes the
Kronecker product of matrices. The components of a vector
starting from k1 and ending at k2 are given as subscripts to
the vector separated by a colon, i.e., xk1:k2.

II. SYSTEM MODEL AND ASSUMPTIONS

A schematic of the system model studied in this paper
is shown in Figure 1. We assume a linear, time-invariant,
dispersive and noisy communication channel. The standard
complex-valued equivalent baseband signal model is assumed.
At time k, the received sample yk is given by

yk =

hl xk−l + nk,

(1)

l=0

where hl is the CIR whose memory is v, nk is the additive
noise symbol and xk−l is the transmitted symbol at time (k−l).
We assume a symbol-spaced CSE but our proposed design
framework can be easily extended to the general fractionally-
spaced case. Over a block of Nf output samples, the input-
output relation in (1) can be written in a compact form as

(cid:104)

yk:k−Nf +1 = H xk:k−Nf−v+1 + nk:k−Nf +1 ,

(2)
where yk:k−Nf +1, xk:k−Nf−v+1 and nk:k−Nf +1 are column
vectors grouping the received, transmitted and noise samples.
Furthermore, H is an Nf × (Nf + v) Toeplitz matrix whose
ﬁrst row is formed by {hl}l=v
l=0 followed by zero entries.
It is useful, as will be shown in the sequel, to deﬁne the
output auto-correlation and the input-output cross-correlation
matrices based on the block of length Nf . Using (2), the input
correlation and the noise correlation matrices are, respectively,
deﬁned by Rxx (cid:44) E
and Rnn (cid:44)
. Both the input and noise processes
E
are assumed to be white; hence, their auto-correlation matrices
are assumed to be (multiples of) the identity matrix, i.e.,
SN R I Nf . Moreover, the output-
Rxx = I Nf +v and Rnn = 1
input cross-correlation and the output auto-correlation matrices
are, respectively, deﬁned as
yk:k−Nf +1xH
yk:k−Nf +1yH

Ryx (cid:44) E
Ryy (cid:44) E

= HRxxH H + Rnn. (4)

xk:k−Nf −v+1xH

nk:k−Nf +1nH

= HRxx , and

k:k−Nf −v+1

k:k−Nf −v+1

k:k−Nf −1

k:k−Nf +1

(cid:104)
(cid:104)

(cid:104)

(cid:105)

(cid:105)

(cid:105)

(cid:105)

(3)

III. SPARSE CHANNEL SHORTENING AND EQUALIZATION
A. Problem Formulation

As shown in Figure 1,

in minimum-mean-square-error
(MMSE) shortening [4], the objective is to design the CSE, w,
and the TIR, b, ﬁlters such that the overall impulse response
which is the convolution of the CIR and the CSE vectors
best approximates, in the MSE sense, a TIR with few taps.

Lagrangian multiplier, and then performing the minimization
with respect to b, we get [4]

bopt =

−1
δ eiopt
(iopt, iopt)

R
−1
δ

R

, and MMSE =

1

(iopt, iopt)

−1
δ

R

.

(10)

Note that iopt is the index that achieves the MMSE and is
given by

conventional CSE design based on the MMSE criterion. To
solve (15), we can use either convex optimization or greedy
algorithms with the latter being more desirable due to their low
complexity. We are now ready to discuss a general framework
for designing sparse CSE and TIR FIR ﬁlters such that the
performance loss does not exceed an acceptable predeﬁned
limit.

3

iopt (cid:44) argmax

0<i≤Nf +v−1

−1
δ

(i, i) .

(11)

R

(cid:107)b(cid:107)0

b∈CNf +v

After computing iopt, we formulate the following problem

for the design of a sparse TIR ﬁlter:

(cid:101)bs (cid:44) argmin
subject to ξ (b, iopt) ≤ δcs , (12)
where (cid:107)b(cid:107)0 is the number of nonzero elements in its argument
and the threshold δcs can be used as a design parameter to
control the performance-complexity tradeoff. Although one
can attempt to use convex-optimization-based approaches (af-
ter replacing (cid:107).(cid:107)0 with its convex approximation (cid:107).(cid:107)1 in (12)
vector,(cid:101)bs, a number of greedy algorithms can be used to solve
to reduce the search space [15]) for the sparse approximation
Once (cid:101)bs is calculated, we insert the unit tap in the ith

this problem efﬁciently with low complexity, especially in the
situations where a speciﬁc number of Nb taps is desired.

location to construct the sparse TIR, bs. Then, the optimum
CSE taps (in the MMSE sense) are determined from (7) to be

t(cid:122) (cid:125)(cid:124) (cid:123)

Ryxbs .

wopt = R−1

yy

(13)

Notice that the MMSE CSE, wopt, is not sparse and, hence,
its design complexity still increases proportional to (Nf )2,
which can be computationally expensive [16]. In contrast,
any choice for w other than wopt leads to performance loss,
especially for channels with large delay spreads. Therefore,
we also propose a sparse implementation for the FIR CSE, w,
as follows. After computing the TIR coefﬁcients, bs, the MSE
will be a function only of w and can be expressed as
ξ(w) = wH Ryyw − wH Ryxbs − bsRH

yxwH + bH

s Rxxbs

= bH

s Rδbs

(cid:124)

(cid:123)(cid:122)

ξmin

(cid:125)

+ (w − R

(cid:124)

yy t)H Ryy(w − R
−1

(cid:123)(cid:122)

ξex(w)

−1
yy t)

(cid:125)

.

(14)

The MSE ξ (w) is minimized by minimizing the term ξex(w)
since ξmin does not depend on w. Hence,
the optimum
choice for w, in the MMSE sense, is the one given in (13).
However, its computation and implementation complexity are
high. Alternatively, to design a sprase CSE, we propose to use
the excess MSE term, ξex (w), as a design constraint to once
again achieve a desirable performance-complexity tradeoff. In
particular, we formulate the following problem for the design
of sparse FIR CSE, w:

(cid:107)w(cid:107)0

subject to ξex (w) ≤ δeq , (15)

(cid:98)ws (cid:44) argmin

w∈CNf

where δeq is a parameter selected by the designer to control
the performance loss from the non-sparse highly-complex

B. Proposed Sparse Approximation Framework

z

(16)

2 ≤  ,

(cid:107)z(cid:107)0 subject to (cid:107)K (Φz − d)(cid:107)2

Unlike earlier works, including the one by one of the co-
authors [10], we provide a general framework for designing
both sparse CSE and TIR FIR ﬁlters that can be considered as
the problem of sparse approximation using different dictionar-
ies. Mathematically, this framework poses the design problem
as follows:

(cid:98)zs (cid:44) argmin
dictionary Φ. Notice that(cid:98)zs ∈(cid:110)(cid:98)ws,(cid:101)bs

where Φ is the dictionary that will be used to sparsely approx-
imate d, while K is a known matrix and d is a known data
vector, both of which change depending upon the sparsifying
and  ∈ {δcs, δeq}.
Notice that also by completing the square in (15) the problem
reduces to the one shown in (16). Hence, one can use any
factorization for Rδ in (8) or Ryy in (14) to formulate a
sparse approximation problem. Using the Cholesky or eigen
decomposition for Rδ or Ryy, we will have different choices
for K, Φ and d. For instance, by deﬁning the Cholesky
factorization [14] of Rδ as Rδ (cid:44) LδLH
δ , or in the equivalent
form Rδ (cid:44) P δΣδP H
(where Lδ is a lower-
triangular matrix, P δ is a lower-unit-triangular (unitriangular)
matrix and Σδ is a diagonal matrix), the problem in (16) can,
respectively, take one of the forms shown below:

δ = ΩδΩH
δ

(cid:111)

is formed by all columns of ΩH

the ith column, pi is the ith column of ΩH
by all entries of b except the ith unity entry. Similarly, by
writing the Cholesky factorization of Ryy as Ryy (cid:44) LyLH
y
or the eigen decomposition of Ryy as Ryy (cid:44) U yDyU H
y , we
can formulate the problem in (16) as follows:

min
w∈CNf
(cid:107)w(cid:107)0 s.t.

(cid:107)w(cid:107)0

(cid:13)(cid:13)(cid:13)(cid:13)(cid:18)

(cid:107)w(cid:107)0

min
w∈CNf

min
w∈CNf

s.t. (cid:13)(cid:13)(cid:0)LH
s.t. (cid:13)(cid:13)L−1

y w − L−1

y t(cid:1)(cid:13)(cid:13)2
(cid:19)(cid:13)(cid:13)(cid:13)(cid:13)2
(Ryyw − t)(cid:13)(cid:13)2

− 1
y U H
y t

y w − D

y U H

1
2

y

2

2

2

D

2

≤ δeq ,

(19)

≤ δeq, and (20)
≤ δeq .

(21)

1
2

y U H
y

y , D

Note that the sparsifying dictionaries in (19), (20) and (21)
are LH
the
matrix K is an identity matrix in all cases except in (21),
where it is equal to L−1
y .

and Ryy, respectively. Furthermore,

We conclude this section by pointing out that several other
sparsifying dictionaries can be used to sparsely design the CSE

min

b∈CNf +v

(cid:107)b(cid:107)0
(cid:107)b(cid:107)0

s.t.

s.t.

min

b∈CNf +v

Recall that (cid:101)Ω

H
δ

2

H

≤ δcs , and

(cid:13)(cid:13)(cid:13)(cid:16)(cid:101)L
(cid:17)(cid:13)(cid:13)(cid:13)2
δ (cid:101)b + li
(cid:17)(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)(cid:16)(cid:101)Ω
δ (cid:101)b + pi
δ , and(cid:101)b is formed

δ except

≤ δcs .

(17)

(18)

H

2

and TIR FIR ﬁlters. Due to lack of space, we presented above
some of those possible choices and the other choices can be
derived by applying suitable transformations to (8) and (14).

C. Reduced-Complexity Design

In this section, we propose reduced-complexity designs
for the CSE and TIR FIR ﬁlters. The proposed designs
in Section III-B involve Cholesky factorization and/or eigen
decomposition, whose computational costs could be large for
channels with large delay spreads. For a Toeplitz matrix,
the most efﬁcient algorithms for Cholesky factorization are
Levinson or Schur algorithms [17], which involve O(M 2)
computations, where M is the matrix dimension. In contrast,
since a circulant matrix is asymptotically equivalent
to a
Toeplitz matrix, for reasonably large dimension [18],
the
eigen decomposition of a circulant matrix can be computed
efﬁciently using the fast Fourier transform (FFT) and its
inverse with only O (M log(M )) operations. By using this
asymptotic equivalence between Toeplitz and circulant matri-
ces, all computations needed for Ryy and Rδ factorization can
be done efﬁciently with the FFT and inverse FFT. In addition,
direct matrix inversion can be avoided.

It is well known that a circulant matrix, C, has the discrete
Fourier transform (DFT) basis vectors as its eigenvectors and
the DFT of its ﬁrst column as its eigenvalues. An M × M
circulant matrix C can be decomposed as C = 1
M ΛcF M ,
where F M is the discrete Fourier transform (DFT) matrix
with fk,l = e−j2πkl/M , 0 ≤ k, l ≤ M − 1, and Λc is
an M by M diagonal matrix whose diagonal elements are
the M-point DFT of c = {c}i=M−1
, the ﬁrst column of
the circulant matrix. We denote by Ryy, Ryx and Rδ the
circulant approximation to the matrices Ryy, Ryx and Rδ,
respectively. In addition, we denote the noiseless channel

output vector as (cid:101)y, i.e., (cid:101)y = Hx. Hence, the autocorrelation

M F H

i=0

matrix Ryy is computed as

Ryy = E [(cid:101)yk(cid:101)yk]
(cid:123)(cid:122)
(cid:125)
R(cid:101)y(cid:101)y

(cid:124)

+

1

SN R(cid:124) (cid:123)(cid:122) (cid:125)

σ2
n

I Nf .

(22)

time-averaged autocorrelation function as follows:

To approximate Ryy as a circulant matrix, we assume that

{(cid:101)yk} is cyclic. Hence, E [(cid:101)yk(cid:101)yk] can be approximated as a
R(cid:101)y(cid:101)y =
(cid:19)

C yC H
y

1
Nf

k =

(cid:19)(cid:18) 1

k=0

Nf ΛH(cid:101)Y F Nf

F H

Nf

Nf

F H

1
Nf

Nf −1(cid:88)
(cid:101)yk(cid:101)yH
(cid:18) 1
Nf Λ(cid:101)Y F Nf
Nf Λ(cid:101)Y ΛH(cid:101)Y F Nf
(cid:17)
(cid:16)
Nf Λ|(cid:101)Y |2 F Nf
(cid:3), F Nf
. . . (cid:101)y0

F H

,

F H

=

=

1
Nf
1
N 2
f
1
N 2
f

=

(cid:101)Y

(cid:2) (cid:101)yNf−1 (cid:101)yNf−2

where

(23)

the Nf -point DFT
is

is
of
=
an Nf × Nf
|.| denotes element-wise norm square, and
DFT matrix.
Cy = circ (c1) where circ denotes a circulant matrix whose
ﬁrst column is c1. Note that F H
= Nf I Nf .
Nf

F Nf = F Nf F H
Nf

c1

4

Without

as a column vector form as

loss of generality, we can write the noiseless

channel output sequence(cid:101)yk in the discrete frequency domain
e−j2π(Nf−1)∆/Nf (cid:3)T , and (cid:12) denotes
(cid:2) 1

(cid:101)Y = H H (cid:12) P ∆ (cid:12) X ,
(cid:12)(cid:12)(cid:12)(cid:101)Y

where H is the Nf -point DFT of the CIR h, P ∆ =

element-wise multiplication. Note that
Then,

= Nf |H|2.

e−j2π∆/Nf

(24)

. . .

nI Nf

=

F H
Nf

1
N 2
f

(cid:16)
Ryy = R(cid:101)y(cid:101)y + σ2
 1
(cid:18) 1

= F H
Nf

Nf

= F H
Nf

Nf

ΛNf |H|2+Nf σ2

n1Nf

F Nf

Λ|H|2 + σ2

n1Nf

(cid:123)(cid:122)



(cid:124)
(cid:19)

Λ

F Nf = QQH .

(25)

(cid:12)(cid:12)(cid:12)2
(cid:17)
 F Nf

(cid:125)

Using the matrix inversion lemma [14], the inverse of Ryy

is then

−1
yy =

R

1

=

−1

Nf

H
yxR

F H
Nf

F H
Nf

Nf σ2
n

Nf σ2
n

F Nf .

(cid:19)

(cid:19)

(cid:26)

= F H
Nf

(cid:18) 1
(cid:20) 1

(cid:16)
ΛH(cid:101)Y Λ(cid:101)Y + I Nf
 ΛH(cid:101)Y

(cid:18)
F Nf
Λ
I Nf − 1
(cid:18)
Nf σ2
n
I Nf − 1
Nf

(cid:27)−1
Λ(cid:101)Y
Λ(cid:101)Y Λ
Similarly, Rδ can be expressed as
(cid:26) 1
Rδ = Rxx − R
N 2(cid:101)F
= Rxx − R
(cid:17)
= I N − R
X − ΛY Λθ(cid:19)θΛH
(cid:16)
(cid:17)
Λ(cid:101)Y Λ1(cid:19)θΛH(cid:101)Y
(cid:17)
ΛX ΛH(cid:101)Y Λ(cid:101)Y Λ1(cid:19)θΛH
(cid:17)
(cid:1) F N

(cid:16)
(cid:101)F
(cid:26) 1
(cid:26) 1
(cid:16)
N σ2
n
(cid:16)
N 2 F H
(cid:0)I N − Λθ(cid:19)θ
N I N − ΛX Λθ(cid:19)θΛH

(cid:16)
Λ(cid:101)Y ΛH

1
N 2 F H
1
F H
N
N

−1
yy Ryx
−1
yy

= I N − Rxy

(cid:26) 1

H
yxR
yx ×

= I N −

ΛY ΛH

N 2σ2
n

(cid:17)

F H
N

H
Nf

H
Nf

F N

=

=

X

X

X

X

H

N

N

(cid:19)(cid:21)

(cid:17)−1

F Nf

(26)

(cid:27)

F N

F N

(cid:27)
(cid:27)
(cid:27)

F N

F N

(27)

= Γ Γ H ,

where (cid:19) denotes element-wise division, N = Nf + v, (cid:101)F
(cid:12)(cid:12)(cid:12)(cid:101)Y

H
Nf
is an N × Nf DFT matrix, θ = θ + N σ2
.
Substituting (25) and (27) into (14) and (8), respectively,
we can design the CSE and TIR FIR ﬁlters in a reduced-
complexity manner where neither a Choleskey nor an eigen
factorization is needed.

n1N , and θ =

(cid:12)(cid:12)(cid:12)2

We have now shown that the problem of designing sparse
CSE and TIR FIR ﬁlters can be cast
into one of sparse
approximation of a vector by a ﬁxed dictionary. Furthermore,
this dictionary can be obtained in an efﬁcient manner using
only the FFT and its inverse. The general form of this problem

is given by (16). To solve this problem, we use the well-
known Orthogonal Matching Pursuit (OMP) greedy algorithm

[19] that estimates (cid:98)zs by iteratively selecting a set S of the

sparsifying dictionary columns (i.e., atoms φi’s) of Φ that are
most correlated with the data vector d and then solving a
restricted least-squares problem using the selected atoms. The
OMP stopping criterion (ρ) is traditionally either a predeﬁned
sparsity level (number of nonzero entries) of zs or an upper-
bound on the norm of the residual error. In our problem, ρ
in the latter case is changed from an upper-bound on the
residual error norm to an upper-bound on the norm of the
Projected Residual Error (PRE), i.e., “K × Residual Error”.
The computations involved in the OMP algorithm are well
documented in the sparse approximation literature (e.g., [19])
and are omitted here due to page limitations.

Note that unlike conventional compressive sensing tech-
niques [20], where the measurement matrix is a fat matrix,
the sparsifying dictionary in our framework is either a tall
matrix (fewer columns than rows) with full column rank as in
(17) and (18) or a square one with full rank as in (19)–(21).
However, OMP and similar methods can still be used if Ryy
and Rδ can be decomposed into ΨΨH and the data vector d
is compressible [21], [22].

Our next challenge is to determine the best sparsifying
dictionary for use in our framework. We know from the
sparse approximation literature that the sparsity of the OMP
solution tends to be inversely proportional to the worst-case
coherence µ (Φ), µ (Φ) (cid:44) max
[23], [24]. Notice
i(cid:54)=j
that µ (Φ) ∈ [0, 1]. Next, we investigate the coherence of the
dictionaries involved in our analysis.

|(cid:104)φi, φj(cid:105)|
(cid:107)φi(cid:107)2(cid:107)φj(cid:107)2

D. Worst-Case Coherence Analysis

We perform a coherence metric analysis to gain some
insight
into the performance of the proposed sparsifying
dictionaries and the behavior of the resulting sparse CSE and
TIR FIR ﬁlters. First and foremost, we are concerned with
analyzing µ (Φ) to ensure that it does not approach 1 for any
of the proposed sparsifying dictionaries. In addition, we are
interested in identifying which Φ has the smallest coherence
and, hence, gives the sparsest design. We have two kinds
of sparsifying dictionaries. The ﬁrst kind is the dictionaries
resulting from Rδ factorization while the second kind is either
Ryy itself or any of its factors. We proceed as follows to
characterize upper-bounds on each kind of dictionary. We
estimate upper bounds on the worst-case coherence of both
Rδ and Ryy separately and evaluate their closeness to 1.
Then, through simulation, we demonstrate that the coherence
of the Rδ and Ryy factors will be less than that of µ(Rδ) and
µ(Ryy), respectively. It is important to note here that the other
dictionaries, which result from decomposing Rδ and Ryy, can
be considered as square roots of them in the spectral-norm
and
sense. For example,

(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)Rδ
(cid:13)(cid:13)(cid:13)2
our framework to compute (cid:101)b that best approximates (cid:101)A(cid:101)b

(cid:13)(cid:13)(cid:13)Ryy
(cid:13)(cid:13)(cid:13)2
≤(cid:13)(cid:13)(cid:13)D1/2
(cid:13)(cid:13)(cid:13)2
(cid:13)(cid:13)(cid:13)U δDδU H

Even though the matrix Rδ is comprised of Toeplitz ma-
is generally non-Toeplitz. We use its factors in

(cid:13)(cid:13)(cid:13)LyLH
(cid:13)(cid:13)(cid:13)2

≤ (cid:13)(cid:13)(cid:13)LH

(cid:13)(cid:13)(cid:13)2

δ U H

trices,

=

=

it

.

y

y

2

δ

2

δ

5

(cid:104)

(cid:104)

(cid:105)−1

(cid:105)−1

=

nnH

H H H

I + 1
σ2
n

to ai as shown in (9). The formula of Rδ in (8) can be
written in terms of the SNR and CIR coefﬁcients as Rδ =
R−1
xx + H H R−1
. Hence, at
low SNR, the noise effect dominates, i.e., Rδ ≈ I, and,
consequently, µ (Rδ) → 0. As the SNR increases, the noise
effect decreases and the effect of the channel taps starts to
appear which makes µ (Rδ) converge to a constant. Through
simulation, we show that this constant does not approach 1
and, accordingly, the other dictionaries generated from Rδ
have a coherence that is also less than that of µ (Rδ).

On the other hand, Ryy has a well-structured (Hermitian
Toeplitz) closed-form in terms of the CIR coefﬁcients, ﬁlter
time span Nf and SNR, i.e., Ryy = HH H + 1
SN R I. It can
be expressed in matrix form as

(cid:122)
(cid:0)(cid:2) r0

v(cid:88)

(cid:125)(cid:124)

φH
1

. . .

0

rv

. . .

−1, rj = (cid:80)v

(cid:123)
0 (cid:3)(cid:1) ,

(28)

Ryy = Toeplitz

r1

(cid:114) 2

where r0 =

|hi|2 + (SNR)

i−j, ∀j (cid:54)= 0.
In [11], we showed that an upper-bound on µ(Ryy) in the
high SNR setting can be derived by solving the following
optimization problem

i=j hih∗

i=0

where h =(cid:2) h0 h1

max
h

s.t. hH h = 1 ,

(cid:3)H is the length-(v + 1) CIR

(29)

. . . hv

(cid:12)(cid:12)(cid:12)hH Rh

(cid:12)(cid:12)(cid:12)

vector and R is a matrix that has ones along the super and
sub-diagonals. It is also shown that the solution of (29) is the
eigenvector corresponding to the maximum eigenvalue of R.
The eigenvalues λs and eigenvectors h(s)
j of the matrix R have
the following simple closed-forms [25]:

λs = 2 cos(

πs

v + 2

) , h(s)

j =

sin( jπs

v+2 ) ,

(30)

v + 2

j

where s, j = 1, . . . , v + 1. Finally, by numerically eval-
uating h(s)
for the maximum λs, we ﬁnd that the worst-
case coherence of Ryy (for any v) is sufﬁciently less than
1. This observation points to the likely success of OMP in

providing the sparsest solution (cid:98)ws which corresponds to the

dictionary that has the smallest coherence. Next, we will
report the results of our numerical experiments to evaluate
the performance of our proposed framework under different
sparsifying dictionaries.

IV. SIMULATION RESULTS

The CIRs used in our numerical results are unit-energy
symbol-spaced FIR ﬁlters with v taps generated as zero-
mean uncorrelated complex Gaussian random variables. The
CIR taps are assumed to have a uniform power-delay-proﬁle3
(UPDP). The performance results are calculated by aver-
aging over 5000 channel realizations. We use the notation
D(χt, χe) to refer to a TIR designed based on the sparsifying
dictionary χt and a CSE designed based on the sparsifying
dictionary χe.

To quantify the accuracy of approximating the matrices
Ryy, Rδ by their equivalent circulant matrices Ryy and Rδ,

3This type of CIRs can be considered as a wrost-case assumption since
the inherent sparsity of other channel models, e.g., [26] and [27], can lead to
further shortening of the dealy spread of the CIR.

6

Figure 4. Worst-case coherence for the sparsifying dictionaries LH
y U H
y
and Ryy versus input SNR for UPDP with v = 8 and Nf = 80. Dashed
lines represent the coherence of the corresponding circulant approximation
for D

y (i.e., QH) and Ryy (i.e., Ryy =QQH).

y , D

y U H

1
2

1
2

Figure 5. Maximum shortening SNR versus CSE taps for UPDP CIR with
v = 5, SNR = 20 dB. Solid lines represent the D(Γ H , QH ) approach while
the dashed lines represent the “signiﬁcant-taps” approach proposed in [12].

increases for all TIR designs, as expected, and our sparse TIR
outperforms, for all scenarios, the proposed approach in [12].
Notice that as Nb increases, the sparse TIR becomes more
accurate in approximating the actual CIR.

(cid:16)

SN R(wopt)

Next, we compare the sparse TIR designs to study the effect
of µ (Φ) on their performance. The OMP algorithm is used
to compute the sparse approximations. The OMP stopping
criterion is set to be either a predeﬁned number of nonzero
taps Nb or a function of the PRE such that: Performance
Loss (η)= 10 Log10
Here, δeq is computed based on an acceptable ηmax and, then,

(cid:17) (cid:44) ηmax.
the coefﬁcients of (cid:98)ws are computed using (16). The percentage

(cid:17) ≤ 10 Log10

(cid:16) SN R(ws)

of the active taps is calculated as the ratio between the number
of nonzero taps to the total number of ﬁlter taps, i.e., Nf . For
the optimal CSE, where none of the coefﬁcients is zero, the
number of active ﬁlter taps is equal to the ﬁlter span. The
decision delay ∆ and the unit-tap index i should be optimized
to avoid performance degradation. However, a near optimum
performance is achieved by choosing these parameters to be
around (Nf + v)/2 [4].

1 + δeq
ξm

The effect of our sparse CSE and TIR FIR ﬁlter designs on
the performance is shown in Figure 6. We plot the number of
active (non-zero) CSE taps as a percentage of the total CSE
span Nf versus the maximum loss in the shortening SNR.
Allowing a higher loss in the shortening SNR yields a bigger
reduction in the number of CSE taps. Moreover, the active
CSE taps percentage increases as Nb decreases because the
equalizer needs more taps to shorten the CIR to a shorter TIR.
We also observe that allowing a maximum of only 0.25 dB in
SNR loss with Nb = 2 results in a substantial 60% reduction

Figure 2. Performance of circulant approximation based approach for UPDP
channel with v = 5 and input SNR = 20 dB.

Figure 3. Worst-case coherence for the sparsifying dictionaries (cid:101)Lδ and (cid:101)U δ

versus input SNR for UPDP with v = 8 and Nf = 80. Note that we estimate
µ(Φ) after removing the column corresponding to the ith unit tap as discussed
in (9). Moreover, changing the location of the ith column has insigniﬁcant
effect on µ(Φ).
respectively, we plot the optimal shortening SNR and the
shortening SNR obtained from the circulant approximation
versus the number of CSE taps (Nf ) in Figure 2. The gap
between the optimal shortening SNR and the shortening SNR
from the circulant approximation approaches zero as the num-
ber of the CSE taps increases, as expected. A good choice for
Nf , to obtain an accurate approximation, would be Nf ≥ 5v.

To investigate the performance of the sparsifying dictio-
naries used in our analysis in terms of coherence, we plot
the worst-case coherence versus the input SNR in Figure

3 for sparsifying dictionaries (cid:101)Lδ and (cid:101)U δ (which is formed

1
2

δ U H

by all columns of D
δ except the ith column) generated
from Rδ. Note that a smaller value of µ(Φ) indicates that a
reliable sparse approximation is more likely. Both sparsifying
dictionaries have the same µ (Φ), which is strictly less than
1. Similarly, in Figure 4, we plot the worst-case coherence
of the proposed sparsifying dictionaries which we used to
design the sparse CSE. At high SNR levels, the noise effects
are negligible and, hence, the sparsifying dictionaries (e.g.,
Ryy ≈ HH H) do not depend on the SNR. As a result, the
coherence converges to a constant. On the contrary, at low
SNR, the noise effects dominate the channel effects. Hence,
the channel can be approximated as a memoryless (i.e., 1
tap) channel. As such the dictionaries (e.g., Ryy ≈ 1
SN R I)
can be approximated as a multiple of the identity matrix, i.e.,
µ (Φ) → 0.

In Figure 5, we compare our proposed sparse TIR design
with that in [12], which we refer to it as the “signiﬁcant-
taps” approach, in terms of shortening SNR where we plot the
shortening SNR versus CSE taps Nf for the UPDP channel.
We vary Nb, the number of TIR taps, from 1 (lower curve)
to 5 (upper curve). The shortening SNR increases as Nb

020406080101214161820Number of CSE taps ( Nf )SNR(wopt)  SNR from the optimal solutionSNR from the proposed circulant approx. D(ΓH, QH)−40−200204060800.10.20.30.40.50.60.70.80.9SNR, dBWorst−case coherece ( µ )   µ ( LHδ ) µ (UHδ)µ ( Rδ)−20020406000.10.20.30.40.50.60.70.8SNR, dBWorst−case coherece ( μ )   μ ( LHy ) μ ( Dy1/2UyH)μ ( Ryy )020406080100120140−505101520 CSE taps Nf Maximum Shortening SNR, dB   D(ΓH,QH) − Nb = 1D(ΓH,QH) − Nb = 2D(ΓH,QH) − Nb = 3D(ΓH,QH) − Nb = 4D(ΓH,QH) − Nb = 5Nb increases from 1 to 57

REFERENCES

[1] J. A. Bingham, “Multicarrier modulation for data transmission: An idea
whose time has come,” IEEE Commun. Magazine, vol. 28, no. 5, pp.
5–14, 1990.

[2] N. C. McGinty, R. A. Kennedy, and P. Hoeher, “Parallel trellis Viterbi
algorithm for sparse channels,” IEEE Commun. Letters, vol. 2, no. 5,
pp. 143–145, 1998.

[3] A. M. Tonello, S. D’Alessandro, and L. Lampe, “Cyclic preﬁx design
and allocation in bit-loaded OFDM over power line communication
channels,” IEEE Trans. on Commun., vol. 58, no. 11, pp. 3265–3276,
2010.

[4] N. Al-Dhahir and J. M. Ciofﬁ, “Efﬁciently computed reduced-parameter
input-aided MMSE equalizers for ML detection: A uniﬁed approach,”
IEEE Trans. on Info. Theory, vol. 42, no. 3, pp. 903–915, 1996.

[5] N. Al-Dhahir, “FIR channel-shortening equalizers for MIMO ISI chan-

nels,” IEEE Trans. on Commun., vol. 49, no. 2, pp. 213–218, 2001.

[6] P. Melsa, R. Younce, and C. Rohrs, “Impulse response shortening for
discrete multitone transceivers,” IEEE Trans. on Commun., vol. 44,
no. 12, pp. 1662–1672, Dec 1996.

[7] D. Falconer and F. Magee, “Adaptive channel memory truncation
for maximum likelihood sequence estimation,” Bell System Technical
Journal, vol. 52, no. 9, pp. 1541–1562, 1973.

[8] A. Chopra and B. L. Evans, “Design of sparse ﬁlters for channel
shortening,” Journal of Signal Processing Systems, vol. 66, no. 3, pp.
259–272, 2012.

[9] J. Balakrishnan, R. K. Martin, and C. R. Johnson Jr, “Blind, adap-
tive channel shortening by sum-squared auto-correlation minimization
(SAM),” IEEE Trans. on Sig. Processing, vol. 51, no. 12, pp. 3086–
3093, 2003.

[10] A. Gomaa and N. Al-Dhahir, “A new design framework for sparse FIR
MIMO equalizers,” IEEE Trans. on Commun., vol. 59, no. 8, pp. 2132–
2140, 2011.

[11] A. O. Al-Abbasi, R. Hamila, W. U. Bajwa, and N. Al-Dhahir, “A
General Framework for the Design and Analysis of Sparse FIR Linear
Equalizers.”

in IEEE GlobalSIP Conference, 2015, pp. 1–5.

[12] S. Roy, T. M. Duman, and V. K. McDonald, “Error rate improvement
in underwater MIMO communications using sparse partial response
equalization,” IEEE Journal of Oceanic Engineering, vol. 34, no. 2,
pp. 181–201, 2009.

[13] S. Haykin, Adaptive Filter Theory (3rd Ed.). Upper Saddle River, NJ,

USA: Prentice-Hall, Inc., 1996.

[14] R. A. Horn and C. R. Johnson, Eds., Matrix Analysis. New York, NY,

USA: Cambridge University Press, 1986.

[15] J. A. Tropp, “Just relax: Convex programming methods for identifying
sparse signals in noise,” IEEE Trans. on Info. Theory, vol. 52, no. 3,
pp. 1030–1051, 2006.

[16] J. Proakis and M. Salehi, Digital Communications, 5th Edition. New

York, NY, USA: McGraw-Hill, 2007.

[17] M. H. Hayes, Statistical Digital Signal Processing and Modeling, 1st ed.

New York, NY, USA: John Wiley & Sons, Inc., 1996.

[18] J. Pearl, “On coding and ﬁltering stationary signals by discrete Fourier
transforms (Corresp.),” IEEE Trans. on Info. Theory, vol. 19, no. 2, pp.
229–232, 1973.

[19] J. Tropp and A. Gilbert, “Signal recovery from random measurements
via orthogonal matching pursuit,” IEEE Trans. on Info. Theory, vol. 53,
no. 12, pp. 4655–4666, 2007.

[20] D. L. Donoho, “Compressed sensing,” IEEE Trans. on Info. Theory,

vol. 52, no. 4, pp. 1289–1306, 2006.

[21] X. Feng, “Sparse equalizer ﬁlter design for multi-path channels,” Mas-

ter’s thesis, Massachusetts Institute of Technology, 2012.

[22] D. Wei, C. Sestok, and A. Oppenheim, “Sparse ﬁlter design under a
quadratic constraint: Low-complexity algorithms,” IEEE Trans. on Sig.
Processing, vol. 61, no. 4, pp. 857–870, 2013.

[23] W. U. Bajwa and A. Pezeshki, “Finite frames for sparse signal process-

ing,” in Finite Frames. Springer, 2013.

[24] J. Tropp, “Greed is good: algorithmic results for sparse approximation,”

IEEE Trans. on Info. Theory,, vol. 50, no. 10, pp. 2231–2242, 2004.

[25] G. H. Golub, “CME 302: Eigenvalues of Tridiagonal Toeplitz Matrices,”

Stanford University, USA.

[26] “Guidelines for The Evaluation of Radio Transmission Technologies for
IMT-2000 [Available online]: .” Recommendation ITU-R M.1225, 1997.
[27] IEEE-P802.15, “TG3C Channel Modeling Sub-committee Final Report,”

2009.

[28] G. Kutz and D. Raphaeli, “Determination of tap positions for sparse
equalizers,” IEEE Trans. on Commun., vol. 55, no. 9, pp. 1712–1724,
2007.

Figure 6. Percentage of active CSE taps versus the performance loss (ηmax)
for sparse TIR designs with SNR = 20 dB, v = 5 and Nf = 40.

Figure 7. Percentage of active CSE taps versus the performance loss (ηmax)
for a sparse TIR with Nb = 3, SNR = 20 dB, 30 dB, v = 8 and Nf = 80.

in the number of CSE active taps (the equalizer can shorten
the channel using only 16 out of 40 taps).

δ , LH

y ) at SNR equals to 30 dB. D(D

In Figure 7, we plot the percentage of the active CSE taps
versus ηmax for different sparsifying dictionaries assuming
Nb = 3. We notice that a lower active taps percentage is
obtained when the coherence of the sparsifying dictionary is
smaller. For instance, allowing for 0.25 dB SNR loss results in
a signiﬁcant reduction in the number of active CSE taps. Al-
most 60% of the taps are eliminated when using D(Γ H , QH )
and D(LH
δ , Ryy)
needs more active taps to achieve the same SNR loss as
that of the other dictionaries due to its higher coherence for
a given constraint on TIR taps Nb. This suggests that the
smaller the worst-case coherence is, the sparser the CSE will
be. Moreover, a lower sparsity level (active taps percentage)
is achieved at higher SNR levels which is consistent with
the previous ﬁndings (e.g., in [28]). Moreover, reducing the
number of active taps decreases the design complexity and,
consequently, the power consumption since a smaller number
of complex multiply-and-add operations are required.

δ U H

1
2

V. CONCLUSIONS

In this paper, we proposed a general framework for sparse
CSE and TIR FIR designs based on a sparse approxima-
tion formulation using different dictionaries. Based on the
asymptotic equivalence of Toeplitz and circulant matrices, we
proposed reduced-complexity designs, for both CSE and TIR
FIR ﬁlters, where matrix factorizations can be carried out
efﬁciently using the FFT and inverse FFT with negligible
performance loss as the number of ﬁlter taps increases. In
addition, we analyzed the coherence of the proposed dictio-
naries involved in our design and showed that the dictionary
with the smallest coherence gives the sparsest ﬁlter design.
The signiﬁcance of our approach was also quantiﬁed through
simulations.

00.511.522.5102030405060708090100 SNR Loss, dB ( ηmax ) % Percentage of active taps  D(LHδ,LHy)D(ΓH,QH)Nb = 1 to 5−0.050.250.550.851.151.451.752.052.352.60102030405060708090100 SNR Loss, dB ( ηmax ) % Percentage of active taps  D(LHδ, LHy) − Nb = 3D(ΓH,QH) − Nb = 3D(D1/2δUHδ,Ryy) − Nb =3SNR = 30 dB