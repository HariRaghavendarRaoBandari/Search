6
1
0
2

 
r
a

M
9

 

 
 
]
L
F
.
s
c
[
 
 

1
v
8
2
9
2
0

.

3
0
6
1
:
v
i
X
r
a

FIRST Technical Report 001

March 10, 2016

Weight Computation of Regular Tree Languages

Jochen Burghardt

jochen@ﬁrst.fhg.de

Abstract. We present a general framework to deﬁne an application–dependent weight mea-
sure on terms that subsumes e.g. total simpliﬁcation orderings, and an O(n · log n) algorithm
for the simultaneous computation of the minimal weight of a term in the language of each
nonterminal of a regular tree grammar, based on Barzdins’ liquid–ﬂow technique.

Keywords. Regular tree language, Term weight, Minimal term, Simpliﬁcation ordering

1

Introduction

Regular tree grammars or automata [TW68] are a generalization of regular (word)
grammars allowing the description of inﬁnite sets of terms, aka. trees. The set of
regular tree languages is closed wrt. boolean operations like intersection and com-
plement, language equivalence and the sublanguage property are decidable. They
are an important tool in various areas of computer science.

Emmelmann [Emm91,Emm94] used them in a compiler generator to compute opti-
mal target code depending on the instruction set of the target machine, employing
a notion of weighted language membership to reﬂect instruction execution costs.
Aiken and Murphy [AM91] exploited the equivalence between regular tree lan-
guages and systems of linear set constraints in a type checking algorithm for a
functional programming language. In [Bur95] we used regular tree grammars to
compute simple invariants of data types that are needed in reﬁnement veriﬁcation
and synthesis. McAllester [McA92] represented congruence classes induced by non–
orientable equations in term rewriting by regular tree languages and gave algorithms
to rewrite grammars instead of terms. Based on an almost similar representation,
Heinz [Hei94,Hei95] computed complete sets of term generalizations wrt. an equa-
tional background theory (E–anti–uniﬁcation). Comon [Com90] used regular tree
languages to describe sets of ground constructor terms as sorts, and the correspond-
ing automaton constructions to implement sort operations. He provided a transfor-
mation system to decide ﬁrst–order formulas with equality and sort membership
as the only predicates. He showed the decidability of inductive reducibility as an
application.

Comon [Com89] pointed out the equivalence between regular tree automata and
elementary sorted signatures, or linear term declarations by Schmidt-Schauß [SS88];
Uribe [Uri92] showed the equivalence to linear set constraints; Bachmair et. al.
[BGW93] showed the equivalence to the monadic class, i.e. the class of ﬁrst–order

1

predicate logic formulas with arbitrary quantiﬁers, with unary predicates only, and
without function symbols.

In many of the above applications, it is necessary to enumerate terms of some com-
puted tree language in order of increasing height, or, more generally, some measure of
weight which is deﬁned dependent on the environment the grammar algorithms are
used in. To this end, it is necessary to compute the minimal height, or weight, of each
nonterminal’s language. As a by–product, this computation also determines which
nonterminals produce the empty language, which enables to simplify the grammar
accordingly; Aiken and Murphy [AM91] found out that in their application area this
optimization had the largest impact on practical run times at all.

In 1991, Barzdin and Barzdin [BB91] proposed their liquid–ﬂow algorithm which
takes an incompletely given ﬁnite algebra and acquires hypotheses about what are
probable axioms, using a rather involved technique including labeled graphs with
several kinds of nodes and arcs. Recently [Bur02], we gave a rational reconstruction
of this work that is based on well–known algorithms on regular tree grammars. It
revealed that the core of the liquid–ﬂow algorithm in fact amounts to a classical
ﬁxpoint algorithm to compute the minimal term heights of all languages generated
by nonterminals simultaneously. However, the version of Barzdin and Barzdin has
only linear time complexity while the classical algorithm [AM91, Sect.4] is quadratic.

In this paper, we generalize the liquid–ﬂow algorithm to compute used–deﬁned
weights instead of heights. In the Sect. 2, we present a rather general framework
to deﬁne an application–dependent weight measure on terms that subsumes e.g. any
total simpliﬁcation ordering [DJ90, Sect. 5.2] as a special case. In Sect. 3, we show
that a naive transfer of Barzdins’ liquid–ﬂow technique leads to a sub–quadratic
weight computation algorithm only under very restrictive assumptions. In Sect. 4,
we present an improved algorithm for our framework that has a time complexity of
O(n · log n) without any restrictions. We give correctness and complexity proofs for
all presented algorithms.

2 Grammars and weights

We assume familiarity with terms and (word) grammars.

Let Σ be a ﬁnite set of function symbols, together with their arities. Let ar denote
the maximal arity of any function symbol in Σ. We abbreviate the set of all n–ary
functions by Σn, and the set of all at least n–ary functions by Σ>n. Let T denote
the set of ground terms over Σ, deﬁned in the usual way. Let N be a ﬁnite set of
nonterminal symbols; we use nt := #N to denote its cardinality.

A regular tree grammar is a triple G = hΣ, N , Ri, where R is a ﬁnite set of pro-
duction rules of the form N ::= f1(N11, ..., N1n1) | . . . | fm(Nm1, ..., Nmnm), where
N, Nij ∈ N and fi ∈ Σni. If some ni is zero, fi is a constant; if m is zero, N pro-
duces the empty language. We call fi(Ni1, . . . , Nini) an alternative of the rule for N.

2

Let al denote the total number of alternatives in the grammar G; we use it as a size
measure for G.

For each nonterminal N ∈ N , exactly one deﬁning rule in R must exist with N as
its left–hand side. Given a ﬁxed grammar G and a nonterminal N ∈ N , the language
produced by N, viz. L(N) ⊆ T , is deﬁned in the usual way as the set of all terms
derivable from N as the start symbol.

Let D be a set and (<) an irreﬂexive, total, and well–founded1 order on D with a
maximal element ∞. Let (6) denote the reﬂexive closure of (<). A function f :
Dn −→ D is called monotonic and increasing iﬀ

n

(

^

i=1

xi 6 yi) ⇒ f (x1, . . . , xn) 6 f (y1, . . . , yn) and

n

^

i=1

xi 6 f (x1, . . . , xn),

respectively. f is called a weight function iﬀ it is monotonic and increasing. Let
D be as above and a signature Σ be given. For each n ∈ IN and f ∈ Σn, let
a weight function f : Dn −→ D be given. Deﬁne wg : T −→ D inductively by
wg(f (t1, . . . , tn)) := f (wg(t1), . . . , wg(tn)). For T ⊆ T , deﬁne

wg(T ) := min{wg(t) | t ∈ T }.

Note that wg(T ) ∈ D is always well–deﬁned and wg(T ) = wg(t) for some t ∈ T .
If N is a nonterminal of a given regular tree grammar over the signature Σ, we
additionally deﬁne wg(N) := wg(L(N)). A term t ∈ L(N) is called minimal wrt. N
if wg(t) = wg(N). We assume that f (x1, . . . , xn) can always be computed in time
O(n).

The most familiar examples of weight measures are the size sz(t), and the height
hg(t) of a term t, i.e. the total number of nodes, and the length of the longest path
from the root to any leaf, respectively. If D := IN ∪ {∞} and f (x1, . . . , xn) := 1 +
x1 + . . . + xn for each f ∈ Σn, we get wg(t) = sz(t); the deﬁnitions f (x1, . . . , xn) :=
1 + max{x1, . . . , xn} for f ∈ Σn yield wg(t) = hg(t).

For a more pretentious example, let 3 ∈ Σ0 and (+), (·) ∈ Σ2, and consider the
term t′(x, y) := x + 3 · y with the set of proper subterms S := {X, 3, 3 · X}. Let
D := (IN ×S)∪{∞}. The following deﬁnitions of weight functions lead to wg(t) being
a pair of the number of occurrences of t′ in t and the largest term in S occurring
at the root of t. Let ij ∈ IN and tj ∈ {X, 3, 3 · X}; we use inﬁx notation for weight

1 I.e., each non–empty subset S of D contains a minimal element min S ∈ S. We additionally deﬁne

min{} := ∞.

3

functions as well and assume f (. . . , ∞, . . .) := ∞ for all f .

3

:= h0, 3i

hi1, 3i · hi2, t2i
hi1, t1i · hi2, t2i
hi1, t1i + hi2, 3 · Xi
hi1, t1i + hi2, t2i
f (hi1, t1i, . . . , hin, tni) := hi1 + . . . + in, Xi for all other f ∈ Σ

:= hi1 + i2, 3 · Xi
:= hi1 + i2, Xi
:= hi1 + i2 + 1, Xi
:= hi1 + i2, Xi

if t2 6= 3 · X

if t1 6= 3

This example can be generalized to an arbitrary linear term t′(x1, . . . , xn).

The following Lemma characterizes the weight measures wg that can be deﬁned by
appropriate weight functions in our framework.

Lemma 1.
Let D, (<), and a mapping φ : T −→ D be given. There exist weight functions
f : Dn −→ D such that ∀t ∈ T : wg(t) = φ(t) iﬀ

1. φ(t′) 6 φ(t) if t′ is a subterm of t, and
2. φ(t1) 6 φ(t2) ⇒ φ(f (. . . , t1, . . .)) 6 φ(f (. . . , t2, . . .)).

Let wg(t) = φ(t).

Proof.
Let t′ be a subterm of t = c[t′]; then wg(t′) 6 wg(t)
“⇒”:
follows from increasingness of weight functions by induction on the height of the
context c[·]. Property 2. follows directly from monotonicity.

“⇐”:

– First note that by 2. and the symmetry of (6), t1 ∼ t2 :⇔ φ(t1) = φ(t2) deﬁnes

a congruence relation on T .
We denote by [t] ∈ T /∼ the congruence class of t ∈ T .
We thus obtain an injective mapping φ∗ : (T /∼) −→ D deﬁned by φ∗([t]) := φ(t).
In the following, we may thus assume w.l.o.g. that T /∼ ⊆ D,
i.e. φ∗([t]) = [t] = φ(t).
Assumptions 1. and 2. then read:
1’. [t′] 6 [t] if t′ is a subterm of t, and
2’. [t1] 6 [t2] ⇒ [f (. . . , t1, . . .)] 6 [f (. . . , t2, . . .)].

– For x1, . . . , xn ∈ D, deﬁne f (x1, . . . , xn) := min{[f (t1, . . . , tn)] | Vn
– We have f ([t1], . . . , [tn]) = [f (t1, . . . , tn)] for all t1, . . . , tn ∈ T :

i=1 xi 6 [ti]}.

f ([t1], . . . , [tn]) 6 [f (t1, . . . , tn)] is obvious, since Vn
For any t′
[f (t1, . . . , tn)] 6 [f (t′
Hence, [f (t1, . . . , tn)] 6 min{[f (t′

i with [ti] 6 [t′
n)].

1, . . . , t′

1, . . . , t′

i=1 [ti] 6 [ti].

i] we have by repeated application of 2’. that

n)] | Vn

i=1 [ti] 6 [t′

i]} = f ([t1], . . . , [tn]).

4

– Each f is increasing:

f (x1, . . . , xn)

= min{[f (t1, . . . , tn)] | Vn
> min{tj | Vn
i=1 xi 6 [ti]}
> xj

i=1 xi 6 [ti]}

Def. f

by 1’.

– Each f is monotonic:

Let Vn

i=1 xi 6 yi, then:

f (x1, . . . , xn)

= min{[f (t1, . . . , tn)] | Vn
6 min{[f (t1, . . . , tn)] | Vn
= f (y1, . . . , yn)

i=1 xi 6 [ti]}
i=1 yi 6 [ti]}

– wg(t) = [t] for all terms t

follows immediately by induction on t.

Def. f
since Vn
Def. f

i=1 yi 6 [ti] ⇒ Vn

i=1 xi 6 [ti]

⊓⊔

As an application of Lem. 1, let D = T ∪ {∞}, ordered by a (reﬂexive) total simpli-
ﬁcation ordering (6) [DJ90, Sect. 5.2], and let φ be the identity function. Property
1. and 2. is satisﬁed, since (6) contains the subterm ordering and is closed under
context application, respectively. Then wg(t) = t for each term t, i.e., no two distinct
terms have the same weight, and wg(N) yields the least term of L(N) wrt. (6).

In the rest of this paper, we assume a ﬁxed given grammar G = hΣ, N , Ri. For a
nonterminal N ∈ N , we tacitly assume its deﬁning rule to be

N ::= f1(N11, ..., N1n1) | . . . | fm(Nm1, ..., Nmnm).

3 Simple Fixpoint Algorithm

First, we adapt the classical algorithm from [AM91] to our framework.

Algorithm 2.
(Naive ﬁxpoint language weight computation) Let x(i)

N ∈ D be deﬁned by

– x(0)
– x(k+1)

N

N := ∞ for each N, and

:= min{f i(x(k)

Ni1, . . . , x(k)
Nini

) | 1 6 i 6 m} for each N and k = 1, . . . , nt.

In the k’th computation cycle, all x(k)
by the above
formula. When the algorithm stops after the nt’th cycle, we have x(nt)
N = wg(N)
by Cor. 6 below. Since in each cycle all alternatives are evaluated, we get a time
complexity of O(nt · al · ar).
⊓⊔

N are computed from all x(k−1)

N

5

Lemma 3.
Given the settings of Alg. 2, we have for all nonterminals N of G, all t ∈ L(N), and
all k ∈ IN, that hg(t) 6 k ⇒ x(k)

N 6 wg(t).

Proof. Induction on k:

– k = 0: trivial, since no ground terms of height 0 exist.
– k   k + 1: if t = fi(t1, . . . , tni) ∈ L(N) has a height 6 k + 1, and assuming the

rule N ::= m

i=1 fi(Ni1, . . . , Nini), we have hg(tj) 6 k for j = 1, . . . , n, and

N

Ni1, . . . , x(k)
Nini

x(k+1)
6 f i(x(k)
6 f i(wg(t1), . . . , wg(tni))
= wg(t)

)

Alg. 2

tj ∈ L(Nij) for j = 1, . . . , ni, I.H., f i monotonic
Def. wg

⊓⊔

Lemma 4.
Given the settings of Alg. 2, we have for all nonterminals N that
x(k)
N < ∞ ⇒ ∃t ∈ L(N) : hg(t) 6 k ∧ x(k)

N = wg(t).

Proof. Induction on k:

– k = 0: trivial, since x(0)
– k   k + 1: Assume the rule N ::= m

N = ∞.

i=1 fi(Ni1, . . . , Nini). First, we have

∞

N

Alg. 2

assumption

) | 1 6 i 6 m}

, . . . , x(k)
Nlnl

Ni1, . . . , x(k)
Nini

) for some l ∈ {1, . . . , m} Def. min

> x(k+1)
= min{f i(x(k)
= f l(x(k)
Nl1
> x(k)
for j = 1, . . . , nl
Nlj
If nl = 0, fl ∈ L(N) and wg(fl) = f l = x(k+1)
If nl > 0, by induction hypothesis, for each j = 1, . . . , nl exists some tj ∈ L(Nlj)
with hg(tj) 6 k and x(k)
Nlj
hence fl(t1, . . . , tnl) ∈ L(N) ∧ hg(fl(t1, . . . , tnl)) 6 k + 1, and

f l increasing
as above, and we are done.

= wg(tj),

N

wg(fl(t1, . . . , tnl))

)

Def. wg

, . . . , x(k)
Nlnl

= f l(wg(t1), . . . , wg(tnl))
= f l(x(k)
Nl1
= min{f i(x(k)
= x(k+1)
(Note that this induction step holds even for k = 1, since x(1)
nullary fl in the rule of N.)

) | 1 6 i 6 m} Def. l

Ni1, . . . , x(k)
Nini

property of the tj

Alg. 2

N

N < ∞ requires some
⊓⊔

6

Lemma 5.
x(k)
N = min{wg(t) | t ∈ L(N), hg(t) 6 k}.

Proof.
For x(k)
For x(k)

N = ∞, we have min{wg(t) | t ∈ L(N), hg(t) 6 k} = ∞ by Lemma 3.
N < ∞, let t0 be the term obtained by Lemma 4. Then:

x(k)

N

6 min{wg(t) | t ∈ L(N), hg(t) 6 k} Lemma 3

6 wg(t0)
= x(k)

N

since t0 ∈ L(N), hg(t0) 6 k
Lemma 4

⊓⊔

Corollary 6.
(Correctness of Alg. 2) x(nt)

N = wg(N) for all N.

Proof.
If L(N) = {}, we have by Cor. 5 that x(k)
Else, by the pumping lemma for regular tree languages [CDG+99, Sect. 1.2], we can
ﬁnd for each term t ∈ L(N) with hg(t) > k > nt a smaller one t′ ∈ L(N) with
hg(t′) 6 nt.

N = ∞ = wg(N) for all k.

Since all weight functions f are increasing, the well–known construction of t′ from
t ensures that wg(t′) 6 wg(t); i.e., t does not contribute to the minimum wg(N).
Hence:

wg(N)

= min{wg(t) | t ∈ L(N)}

= min{wg(t) | t ∈ L(N), hg(t) 6 k}
= x(k)

N

Def. wg

see above

Cor. 5

⊓⊔

Next, we apply Barzdins’ liquid–ﬂow technique in a straight forward way to Alg. 2.
The basic idea is to recompute an alternative only if some of its argument values
has changed, i.e. belongs to the water front.

Algorithm 7.
(Barzdins’ liquid–ﬂow technique) The weights of all nonterminals can be computed
in time O(nt · al · ar), using the following ﬁxpoint algorithm. Maintain a set F ⊆ N ,
called water front in [BB91], such that F (k+1) = {N ∈ N | x(k+1)
N } for all
k ∈ IN. Deﬁne

< x(k)

N

– x(0)
– x(1)

N := ∞ for each N,
N := min{f i | 1 6 i 6 m, fi ∈ Σ0} for each N, and

7

– x(k+1)

N

:= min({x(k)

N } ∪ {f i(x(k)

for each N and each k ∈ IN.

Ni1, . . . , x(k)
Nini

) | 1 6 i 6 m, Wni

j=1 Nij ∈ F (k)})

– Stop the computation after cycle (k + 1), if F (k+1) is empty.

In cycle (1), the entire grammar has to be inspected once, to compute x(1)
N and at the
same time F (1). In each later cycle, we tacitly assume that we need to inspect only
those alternatives fi(Ni1, . . . , Nini) for which Nij ∈ F (k) for some j ∈ {1, . . . , ni}.

As in [BB91], an appropriate pointer structure, linking each nonterminal Nij (domain
node in [BB91]) to all alternatives (functional nodes) it occurs in, is assumed to have
been built before cycle (0), by inspecting the whole grammar once.

Below we will show linear complexity under certain restrictive requirements to the
⊓⊔
weight functions.

It is easy to see by induction on k that each x(k)
Alg. 2. Since F (k) = {} ⇒ x(k+1)
this case.

= x(k)

N

N has the same value in Alg. 7 as in
N ∧ F (k+1) = {}, the algorithm may stop in

Q0

::= a

Qn+1 ::= q(Pn+1) | j(Qn)

Pn+1 ::= p(Qn)

q(x) := x

p (x) := 2 · x

j (x) := 2 · x + 1

a

:= 0

L(Qn)

hg

wg

qp . . . qp a 2 · n + 1 0

j . . . j a

n + 1

2n − 1

Fig. 1. Example grammar, weight functions, and minimal / maximal terms

k Q0 P1

Q1

P2

Q2

P3

Q3

0 ∞ ∞ ∞

∞

∞

∞

∞

1 a 0

2

3

4

5

6

7

p a 0 j a 1

qp a 0 p j a 2

j j a 3

p qp a 0 j qp a 1

(qp j a 2)

p j j a 6

j j j a 7

qp qp a 0

p j qp a 2

j j qp a 3

(qp j j a 6)

p qp qp a 0 j qp qp a 1

(qp j qp a 2)

qp qp qp a 0

Fig. 2. Algorithm 2 / 7 running on the example grammar

As an example, let Σ0 := {a} and Σ1 := {q, p, j }; consider the grammar (left) and
weight functions (middle) shown in Fig. 1, where D := IN ∪{∞} and n = 0, . . . , nmax.

8

The grammar has 2 · nmax + 1 rules and 3 · nmax + 1 alternatives. Since we have at
most unary functions, we can omit parentheses around function arguments in terms
to enhance readability and to indicate the connection to word grammars.

Observe that each term t in L(Qn) can be read as a binary number in reversed
notation2, e.g. L(Q3) ∋ qpj j a ˆ= 110, and that by construction the weight wg(t)
corresponds to this binary number, e.g. wg(qpj j a) = 6.

In this correspondence, L(Qn) is the set of all binary numbers with exactly n digits;
in particular, each L(Qn) is ﬁnite. Hence, both a term of maximal height and of
maximal weight exists, by construction, it has minimal weight and minimal height,
respectively; cf. Fig. 1 (right).

Figure 2 shows the cycles of Alg. 2 in computing the weights of each Qn and Pn,
where nmax = 3. For each nonterminal N, the right entry in its column shows the
value of x(k)
N while the left entry shows a term of this weight in L(N). Empty entries
mean that x(k)
. Entries in parentheses are computed by the algorithm, but
don’t lead to an update, since they are larger than their predecessors.

N = x(k−1)

N

The algorithm stops after cycle (7), since there are 7 distinct nonterminals in the
grammar. Since Alg. 7 computes the same values as Alg. 2, Fig. 2 illustrates both
algorithms simultaneously. The water front F (k) consists of all nonterminals having
a nonempty entry in line k, except for k = 0.

Next, we give a suﬃcient criterion for Alg. 7 to run in linear time. Deﬁne

:= min{f | f ∈ Σ0},
:= max{f | f ∈ Σ0},

l0
h0
l(x) := min{f (l0, ..., x, ..., l0) | f ∈ Σ>1}, and
h(x) := max{f (x, . . . , x) | f ∈ Σ>1}.

In the deﬁnition of l(x), the minimum ranges over all argument positions of x, e.g.
l(x) = min{g(x, l0), g(l0, x)} if Σ>1 = Σ2 = {g}. Note that the maxima in the
deﬁnitions of h0 and h(x) are well–deﬁned since they range over a ﬁnite set each.

Lemma 8.
In the settings of Alg. 2, we have for each N ∈ N and each k ∈ IN
that x(k+1)
for each t′ ∈ L(N) with hg(t′) 6 k.

< x(k)

N

N iﬀ some t ∈ L(N) exists with hg(t) = k + 1 and wg(t) < wg(t′)

Proof. Follows immediately from Cor. 5,
since min A < min B iﬀ ∃a ∈ A\B ∀b ∈ B : a < b for arbitrary ordered sets.

⊓⊔

2 Think of “q” and “p ” as forming the left and right half of the digit “0”, respectively, think of “j ” as of

the digit “1”, and ignore “a”.

9

Lemma 9.
If some p0 ∈ IN exists such that #{d ∈ D | li(l0) 6 d 6 hi(h0)} 6 p0 for all i ∈ IN,
then each x(·)
N can change its value at most p0 times during the execution of Alg. 2.
(Here, li(l0) denotes the i–fold application of l to l0, etc.)

Proof.

1. l(·) and h(·) are monotonic and increasing:

If x 6 y, then f (l0, ..., x, ..., l0) 6 f (l0, ..., y, ..., l0) for all f ∈ Σ>1, and hence
Since x 6 f (l0, ..., x, ..., l0) for all f ∈ Σ>1, we have x 6 l(x).
l(x) 6 l(y).
Similar for the monotonicity and increasingness of h.

2. l0 6 f 6 h0 for all f ∈ Σ0:

Obvious.

3. l(max{x1, . . . , xn}) 6 f (x1, . . . , xn) 6 h(max{x1, . . . , xn})

for all x1, . . . , xn in the range of wg and all f ∈ Σ>1:
Since each xi is in the range of wg, we have l0 6 xi.
W.l.o.g. let x1 = max{x1, . . . , xn}. Then,

l(x1)

6 f (x1, l0, ..., l0)
6 f (x1, . . . , xn)
6 f (x1, . . . , x1)
6 h(x1)

Def. l

l0 6 xi
xi 6 x1
Def. h

4. lhg(t)−1(l0) 6 wg(t) 6 hhg(t)−1(h0) for all t ∈ T :

Induction on t:
If t = f is a constant, we have lhg(t)−1(l0) = l0 6 f = wg(t) 6 h0 = hhg(t)−1(h0).
If t = f (t1, . . . , tn), we have hg(ti) = hg(t) − 1 for some i ∈ {1, . . . , n},
and hg(tj) 6 hg(t) − 1 for all j = 1, . . . , n. Hence,

lhg(t)−1(l0)

6 l(wg(ti))
6 l(max{wg(t1), . . . , wg(tn)})
6 f (wg(t1), . . . , wg(tn))
= wg(t)

since lhg(t)−2(l0) = lhg(ti)−1(l0) 6 wg(ti) by I.H.
Def. max,

i ∈ {1, . . . , n}

by 3.

Def. wg(t)

6 h(max{wg(t1), . . . , wg(tn)})
6 hhg(t)−1(h0)

by 3.
since wg(tj) 6 hhg(t)−2(h0) for all j by I.H.

5. If in Alg. 2 the value of x(·)

N changes at k = k1, . . . , kp, then p 6 p0:
N } and k1 < . . . < kp.

< x(k)

N

Let {k1, . . . , kp} := {k + 1 ∈ IN | x(k+1)
From Cor. 8, we obtain t1, . . . , tp ∈ L(N)
such that hg(ti) = ki and wg(ti) = x(ki)
From 4., we thus have
lkp−1(l0) 6 wg(tp) = x(kp)
Hence, by assumption p 6 p0.

N < . . . < x(k1)

N for i = 1, . . . , p.

N = wg(t1) 6 hk1−1(h0) 6 . . . 6 hkp−1(h0).
⊓⊔

10

Let us compute the time requirements of Alg. 7 under the assumption of Lem. 9. Let
CN denote the number of cycles where x(·)
N changes its value during the computation,
i.e. where x(k+1)
N . From Lem. 9, we get CN 6 p0 for all N ∈ N and some
p0 ∈ IN depending not on the grammar, but only on the choice of the weight
functions. A certain alternative f i(x(k)

) is recomputed

Ni1, . . . , x(k)
Nini

< x(k)

N

ni

X

j=1

CNij 6

ni

X

j=1

p0 6 ar · p0

times during algorithm execution. Altogether, there are at most al · ar · p0 re–
computations of alternatives, requiring time O(al · ar2 · p0), including updating the
respective x(·)
N . Initialization of the pointer structure and cycles (0) and (1) requires
time O(al · ar + nt + al). Hence, we get an overall time requirement of O(al · ar2 · p0),
i.e. the algorithm runs linear in the number of alternatives.

In the binary numbers example from above, the computation still takes O(n2
max) cy-
cles since the requirements of Lem. 9 are not satisﬁed. In general, these requirements
are violated as soon as there are two weight functions f and g such that f (x) < g(x)
for all x ∈ D and g is strictly monotonic3, since then

li(l0) 6 f

i

(l0) < g(f

i−1

(l0)) < g2(f

i−2

(l0)) < . . . < gi(l0) 6 hi(h0).

At least, the requirements hold if wg(t) = hg(t), thus we can duplicate the result of
Barzdin [BB91], and improve the time complexity for the optimization of Aiken and
Murphy [AM91] based on detecting nonterminals producing the empty language.

In the following section, we present an improved algorithm which takes at most
O(al · log nt) time in any case.

4 Lazy Propagation Algorithm

As we saw above, a naive transfer of Barzdins’ liquid–ﬂow technique to our frame-
work is not suﬃcient to obtain a sub–quadratic weight computation algorithm, ex-
cept for very special cases. The reason for this is essentially that the algorithm con-
siders terms in order of increasing height, cf. Lem. 5, but terms with small height
may have large weight and vice versa. For example, in Fig. 2, the value x(2)
Q1 = 1
is propagated to x(3)
Q2 = 3; in the next cycle, the value improves to
x(3)
Q1 = 0, and both propagations have to be redone, leading to x(4)
Q2 = 1,
of which the latter is still non–optimal.

P2 = 2 and x(3)

P2 = 0 and x(4)

The basic idea of the following improved liquid–ﬂow algorithm is to defer propagation
of a x(k)
N value until we safely know it is the ﬁnal, minimal one for N, following the

3 I.e., x < y ⇒ g(x) < g(y). We use unary functions for simplicity; the argument is similar for higher arity

functions.

11

motto less haste more speed . The algorithm may need more computation cycles4,
but in each cycle less updates are made, and, more important, the right updates are
made.

Algorithm 10.
(Lazy propagation) The weights of all nonterminals can be computed using the
following improved ﬁxpoint algorithm.

Maintain three sets of nonterminals F (k), M (k), and D(k), called water front, mini-
mals, and done, respectively. For N ∈ N , let x(0)
N := ∞; let F (0) := {}, M (0) := {},
D(0) := {}, and, for simplicity of proofs, D(−1) := {}.

For each N and each k ∈ IN, deﬁne

N } ∪ {f i(x(k)

:= min({x(k)
:= (F (k) ∪ {N | x(k+1)

x(k+1)
N
F (k+1)
M (k+1) := {N ∈ F (k+1) | ∀N ′ ∈ F (k+1) : x(k+1)
D(k+1) := D(k) ∪ M (k+1).

Ni1, . . . , x(k)
Nini
< x(k)

N }) \ D(k),

N

N

6 x(k+1)

N ′

},

and

) | 1 6 i 6 m ∧ Vni

j=1 Nij ∈ D(k)})

Stop if F (k+1) = {}.

⊓⊔

Informally, this algorithm works as follows. When an x(·)
<
x(k)
N , we add N to the water front F (k+1), as does Alg. 7. However, only those N
having minimal x(k+1)
values in F (k+1) are used for propagation. They are collected
in the set minimal , i.e. M (k+1), and added to the set done, i.e. D(k+1).
In Lem. 12 below, we will show that their x(·)
This is what is intuitively expected, since only larger values are in circulation.

N value in fact doesn’t change any further.

N value changes, i.e. x(k+1)

N

N

At ﬁrst glance, we observe the following facts about Alg. 10.

Lemma 11.

N > x(k+1)

i=0 M (i), where all M (i) are pairwise disjoint.

1. D(k) = Sk
2. D(k) ⊆ D(k+1), and D(k) ⊂ D(k+1) ⇔ M (k+1) 6= {} ⇔ F (k+1) 6= {}.
3. x(k)
4. N ∈ F (k) ∪ D(k) iﬀ x(k)
5. If N ∈ M (k) and N ′ 6∈ D(k−1), then x(k)
N 6 x(k)
N ′ .
6. N ∈ F (k+1) \ F (k) iﬀ x(k+1)
< ∞ = x(k)
N .

N < ∞; both implies ∃k′ : N ∈ D(k′).

N

N

.

Proof.

4 In fact, this is not the case, as shown in Lem. 20 below.

12

1. D(k) = Sk

i=0 M (i) follows from Def. D(·).

To see the disjointness, note that
N ∈ M (k) ⇒ N ∈ F (k) ⇒ N 6∈ D(k−1) by Def. M (k), F (k).

2. D(k) ⊆ D(k+1) follows from Def. D(k+1).

D(k) ⊂ D(k+1) ⇔ M (k+1) 6= {} follows from 1.
M (k+1) 6= {} ⇔ F (k+1) 6= {} follows from Def. M (k+1).

3. Follows from Def. x(k+1)
4. First, we show N 6∈ F (k) ∪ D(k−1) ⇒ x(k)

N

.

N = ∞ by induction on k:

k = 0: x(0)
k   k + 1:

N = ∞ for all N.

N 6∈ F (k+1) ∧ N 6∈ D(k)

N

N

N

6 ∞, using 3.

= x(k)
= x(k)

N 6 x(k′)

N < x(k′−1)

by Def. F (·) and 2.

N ∧ N 6∈ F (k) ∧ N 6∈ D(k−1)
N = ∞

⇒ x(k+1)
⇒ x(k+1)
by I.H.
Next, if N ∈ F (k), let k′ be minimal with that property,
then x(k)
If N ∈ D(k), then N ∈ M (k′) ⊆ F (k′) for some k′ 6 k by 1.;
hence x(k)
Finally, assume for contradiction N ∈ F (k) and N 6∈ D(k′) for all k′ ∈ IN.
Then N ∈ F (k′+1) for all k′ > k by Def. F (k′+1).
From 2., we get #D(k+nt+1) > nt, where nt = #N ,
which contradicts D(k+nt+1) ⊆ N .
N 6 x(k)

N ′ by Def. M (k).

N < ∞ by 3.

N 6 x(k′)

5. If N ′ ∈ F (k), we have x(k)

If N ′ 6∈ F (k) ⊇ M (k), then N ′ 6∈ D(k) by 1., and we have x(k)

N 6 ∞ = x(k)

N ′ by 4.

6. “⇒”:

N 6∈ F (k) and N ∈ F (k+1)
N and N 6∈ D(k)

< x(k)

⇒ x(k+1)
⇒ x(k)
“⇐”:

N
N = ∞

x(k+1)

N

< ∞ = x(k)

N

⇒ N ∈ F (k+1) ∨ N ∈ D(k)
and N 6∈ F (k) ∪ D(k)
⇒ N 6∈ F (k) and N ∈ F (k+1)

Def. F (k+1)

by 4.

Def. F (k+1)

by 4.

We now prove the core property of Alg. 10:
the values corresponding to nonterminals in the done set don’t change any more.

⊓⊔

Lemma 12.
If N ∈ D(k) and k 6 k′, then x(k)

N = x(k′)
N .

13

Proof.
We show

∀k′ ∈ IN ∀k 6 k′ ∀N ∈ M (k) ∀N ′ 6∈ D(k−1) : x(k)

N 6 x(k′)

N ′

N ′

for k 6 k′ + 1 and N ∈ M (k), N ′ 6∈ D(k−1).

by induction on k′. The case k′ = 0 is trivial, since then k = 0 and x(0)
In the case k′   k′ + 1, we have to show
N 6 x(k′+1)
x(k)
We are done by Lem. 11.5 if k = k′ + 1, so let k 6 k′ in the following.
Consider the deﬁnition of x(k′+1)
If x(k′+1)
If x(k′+1)
we distinguish the following cases:

N ′ , we are done immediately, using the I.H. x(k)

) for some i ∈ {1, . . . , m} with N ′

= x(k′)
= f i(x(k′)

N 6 x(k′)
N ′ .

, . . . , x(k′)
N ′

N ′
i1

ini

N ′

N ′

N ′

.

N = ∞ = x(0)
N ′ .

i1, . . . , N ′

ini ∈ D(k′),

– N ′

ij ∈ D(k−1) for all j ∈ {1, . . . , ni}:

Note that this implies k > 0 or ni = 0.
By Lem. 11.1, for each j = 1, . . . , ni some kj 6 k − 1 exists with N ′
We have for all j ∈ {1, . . . , ni}:

ij ∈ M (kj ).

by I.H., since N ′

x(kj )
N ′
ij
6 x(k′)
N ′
ij
6 x(k−1)
N ′
ij
6 x(kj )
N ′
ij
That is, all these terms are equal; in particular, x(k−1)

by Lem. 11.3, since k − 1 6 k′

by Lem. 11.3, since kj 6 k − 1

ij ∈ M (kj ), hence N ′

ij 6∈ D(kj −1), and kj 6 k′

= x(k′)
N ′
ij

for all j. Hence:

N ′
ij

N

N ′

x(k)
6 x(k)
6 f i(x(k−1)
= f i(x(k′)
N ′
i1
= x(k′+1)

N ′
i1

N ′

, . . . , x(k−1)

N ′
, . . . , x(k′)
N ′

ini
)

ini

by Lem. 11.5, since N ∈ M (k), N ′ 6∈ D(k−1)
by Alg. 10, since N ′

ij ∈ D(k−1) for all j

)

as shown above

by assumption

– N ′

N

ij 6∈ D(k−1) for some j ∈ {1, . . . , ni}:
x(k)
6 x(k′)
N ′
ij
6 f i(x(k′)
N ′
i1
= x(k′+1)

, . . . , x(k′)
N ′

ini

)

N ′

by assumption

by I.H., since N ∈ M (k), N ′

ij 6∈ D(k−1), k 6 k′

since f i is increasing

This completes the induction proof.

Now, if N ∈ D(k), then N ∈ M (k′′) for some k′′ 6 k,
and we get x(k′′)
N 6 x(k)
i.e. all these values are equal.

N from above and x(k′)

N 6 x(k′)

N 6 x(k′′)

N

from Lem. 11.3,

⊓⊔

14

Corollary 13.
Let N, N ′ ∈ N ,

k 6 k′, N ∈ D(k),

and N ′ 6∈ D(k−1). Then:

1. x(k)
2. x(k)

N = x(k′)
N , and
N 6 x(k′)
N ′ .

Proof.

1.

N ∈ D(k)

2.

⇒ N ∈ M (k′′) for some k′′ 6 k
⇒ N 6∈ D(k′′−1)
⇒ x(k′′)
N 6 x(k′)
N ∈ D(k)

N 6 x(k′′)

N 6 x(k)

N

⇒ N ∈ M (k′′) for some k′′ 6 k
∧ N ′ 6∈ D(k′′−1)
N 6 x(k′′)
⇒ x(k)

N 6 x(k′)

N ′

by Lem. 11.1

by Lem. 11.1
by Lem. 12 and 11.3, since k′′ 6 k 6 k′

by Lem. 11.1
by Lem. 11.2, since k′′ − 1 6 k − 1
by Lem. 11.3 and 12, since k′′ 6 k 6 k′

Lemma 14.
F (k+1) = (F (k) ∪ {N | x(k+1)

N

< x(k)

N }) \ M (k).

Proof. “⊆”: obvious, since D(k) ⊇ M (k) by 11.1.
“⊇”:
hence N 6∈ D(k) = D(k−1) ∪ M (k) by 11.1.
If x(k+1)
N and N 6∈ M (k),
then N 6∈ D(k), since else x(k+1)

= x(k)

< x(k)

N

If N ∈ F (k) and N 6∈ M (k), then N 6∈ D(k−1) by Def. F (k),

N

N by Lem. 12.

⊓⊔

⊓⊔

Lemma 15.
N ∈ D(k) ⇒ ∃t ∈ L(N) : wg(t) = x(k)
N .

Proof. Induction on k:

– k = 0: trivial, since D(0) = {}.

15

– k   k + 1:

First, we have
N ∈ D(k+1)

⇒ N ∈ M (k′) ⊆ F (k′) for some k′ 6 k + 1
⇒ x(k′′)
⇒ x(k′′)

N < x(k′′−1)
N = f i(x(k′′−1)
for some i with ∀j : Nij ∈ D(k′′−1)

for some k′′ 6 k′

, . . . , x(k′′−1)

Nini

Ni1

)

N

by Lem. 11.1
by Def. F (·)

by Alg. 10

Let k′′′ be the maximal k′′ with that property, i.e., let
k′′′ = max{k′′ ∈ IN | k′′ 6 k′, ∃i : x(k′′)
Then:

N = f i(x(k′′−1)

Ni1

, . . . , x(k′′−1)
Nini

x(k+1)

N

) ∧ ∀j : Nij ∈ D(k′′−1)}.

N

= x(k′)
= x(k′−1)
= f i(x(k′′′−1)

N

Ni1

= . . . = x(k′′′)

N

, . . . , x(k′′′−1)

Nini

)

by Cor. 13.1, since N ∈ D(k′)
by Def. k′′′

for some i with ∀j : Nij ∈ D(k′′′−1)

by Def. k′′′

= f i(wg(t1), . . . , wg(tni))

for some tj ∈ L(Nij)

= wg(fi(t1, . . . , tni))

by I.H., since k′′′ 6 k′ 6 k + 1

by Def. wg(·)

⊓⊔

Lemma 16.
Let N ∈ N with L(N) 6= {} be given.
Then, a derivation N ∗−→ t exists such that each subterm t′ of t is minimal wrt.
the nonterminal ν(t′) it has been derived from (Note that in a nondeterministic
grammar, ν(·) is well–deﬁned only in the context of a given derivation).
We call such a t thoroughly minimal.

∗−→ f (t1, . . . , tn) = t and t be minimal wrt. N.

Proof.
We show that for each derivation of a minimal t wrt. N a derivation of some thor-
oughly minimal t′′ wrt. N exists, by induction on the structure of t:
Let N −→ f (N1, . . . , Nn)
Since ti ∈ L(Ni) 6= {}, we can ﬁnd a derivation Ni
By I.H., we ﬁnd for i = 1, . . . , n a derivation Ni
t′′
i wrt. Ni.
Let t′′ := f (t′′
then wg(t′′) = f (wg(N1), . . . , wg(Nn)) 6 f (wg(t1), . . . , wg(tn)) = wg(t) = wg(N),
hence t′′ is minimal, and therefor also thoroughly minimal, wrt. N.

i of some minimal t′
i wrt. Ni.
i of some thoroughly minimal

∗−→ t′
∗−→ t′′

1, . . . , t′′

n),

⊓⊔

16

Lemma 17.
If wg(N) < ∞, then N ∈ D(k) for some k.

Proof.
If wg(N) < ∞, we can ﬁnd some derivation N ∗−→ t of some thoroughly minimal t
wrt. N by Lem. 16.
We show that t thoroughly minimal wrt. N and wg(t) < ∞ implies x(k)
and N ∈ D(k) for some k ∈ IN, by induction on the structure of t:
Let t = f (t1, . . . , tn). Then N −→ f (N1, . . . , Nn) for some Ni, each ti is thoroughly
minimal wrt. Ni, and wg(Ni) = wg(ti) 6 wg(t) < ∞.
By I.H., we get some ki with x(ki)
Ni
Let k := max{k1, . . . , kn}. Then

6 wg(ti) and Ni ∈ D(ki) for i = 1, . . . , n.

N 6 wg(t)

N

N1 , . . . , x(k)
Nn)

x(k+1)
6 f (x(k)
6 f (wg(t1), . . . , wg(tn))
= wg(t)

by Alg. 10, since Ni ∈ D(k) by Lem. 11.2
since x(k)
Ni
by Def. wg(·)

6 wg(ti) by Lem. 11.3

6 x(ki)
Ni

< ∞
From Lem. 11.4, we get N ∈ D(k′) for some k′.
Setting k′′ := max{k + 1, k′},
we have x(k′′)

by assumption

N 6 x(k+1)

N

6 wg(t) and N ∈ D(k′) ⊆ D(k′′) by Lem. 11.3 and 2.

⊓⊔

Lemma 18.
F (k+1) = {} iﬀ D(k) = {N ∈ N | wg(N) < ∞}.
In this case, we reached a ﬁxpoint,
i.e. M (k+1) = {}, D(k+1) = D(k), x(k+2)

= x(k+1)

N

N

, and F (k+2) = {}.

Proof.

1. D(k+1) = D(k) ⇒ x(k+2)

N

= x(k+1)

N

:

x(k+2)

N

Nij

∪{f i(...x(k+1)
∪{f i(...x(k+1)
Nij
∪{f i(...x(k)
Nij ...)
N }∪{f i(...x(k)
Nij ...)

...) | 1 6 i 6 m, Vni
...) | 1 6 i 6 m, Vni
| 1 6 i 6 m, Vni
| 1 6 i 6 m, Vni

j=1 Nij ∈ D(k+1)})
j=1 Nij ∈ D(k)})
j=1 Nij ∈ D(k)})
j=1 Nij ∈ D(k)})

= min({x(k+1)
N }
= min({x(k+1)
N }
= min({x(k+1)
N }
> min({x(k+1)
N , x(k)
= x(k+1)
> x(k+2)

N

N

Alg.10

ass.

Cor.13.1

min

Alg.10

Lem.11.3

17

2. If F (k+1) = {}, we reached a ﬁxpoint:

F (k+1) = {}
⇒ M (k+1) = {}
⇒ D(k+1) = D(k)
⇒ x(k+2)
= x(k+1)
N
⇒ F (k+2) = {}

N

by Def. M (k+1)

by Lem. 11.1

for all N ∈ N

by 1.
by Def. F (·), since F (k+1) = {}

3. F (k+1) = {} ⇐ D(k) = {N ∈ N | wg(N) < ∞}:

Assume for contradiction F (k+1) 6= {}.
By Lem. 11.2, we have N ∈ M (k+1) ⊆ F (k+1) for some N with wg(N) = ∞.
By Lem. 15, wg(t) = x(k+1)
Hence, wg(N) 6 wg(t) = x(k+1)

< ∞, which is a contradiction.

for some t ∈ L(N).

N

N

4. Let F (k+1) = {}, we show wg(N) < ∞ ⇔ N ∈ D(k):

wg(N) < ∞

⇒ N ∈ D(k′) for some k′
⇒ N ∈ D(k)
⇒ wg(N) 6 x(k)
∧ x(k)

N < ∞

N

by Lem. 17
since D(k′) ⊆ D(k) by 2. and Lem. 11.2

by Lem. 15

by Lem. 11.4

⊓⊔

⊓⊔

Lemma 19.
If F (k+1) = {}, then x(k)

N 6 wg(t) for all N ∈ N and all t ∈ L(N).

Proof. Induction on t:
Let t = f (t1, . . . , tn) ∈ L(N),
i.e., N ::= . . . f (N1, . . . , Nn) . . . and tj ∈ L(Nj) for j = 1, . . . , n.
If wg(tj) = ∞ for some j, then x(k)
If wg(tj) < ∞ for all j, then

N 6 ∞ = wg(t), since f is increasing.

x(k)

N

N

N1 , . . . , x(k)
Nn)

= x(k+1)
6 f (x(k)
6 f (wg(t1), . . . , wg(tn))
= wg(t)

by Lem. 18.2
by Alg. 10, since Nj ∈ D(k) for all j by Lem. 18.3
I.H., f monotonic

Def. wg

Corollary 20.
(Correctness of Alg. 10)

If F (k+1) = {}, then x(k)

N = wg(N) for all N ∈ N .

18

Proof.
By Lem. 11.2, we have F (k+1) = {} for some k 6 nt.
By Lem. 18.2 and 3, thus F (nt+1) = {} and D(nt) = {N ∈ N | wg(N) < ∞}.
By Lem. 19, we have x(nt)
By Lem. 15, we have x(nt)
For all N ∈ N \ D(nt), we have ∀k : N 6∈ D(k) by Lem. 18.2 and 11.2,
hence wg(N) = ∞ = x(nt)

N 6 wg(N) for all N ∈ N .
N > wg(N) for all N ∈ D(nt).

N by Lem. 11.4.

We now duplicate the transformation from Alg. 2 to Alg. 7 for Alg. 10:

Algorithm 21.
Replace in Alg. 10 the deﬁnition rule for x(k+1)

N

, and F (k+1) by

x(k+1)

N

:= min({x(k)

N } ∪ { f i(x(k)

(Vni
F (k+1) := (F (k) ∪ {N | x(k+1)

N

) | 1 6 i 6 m ∧

Ni1, . . . , x(k)
Nini
j=1 Nij ∈ D(k)) ∧ (Wni
< x(k)

N }) \ M (k)

j=1 Nij ∈ M (k))}) , and

,

while all other deﬁnitions remain unchanged.

⊓⊔

⊓⊔

Lemma 22.
(Correctness of Alg. 21)
Alg. 21 as in Alg. 10.

In Alg. 21, each x(k)

N , and each F (k) has the same value in

Proof. “x(k)
“F (k)”:

Induction on k using Lem. 12.

N ”:
follows immediately from Lem. 14.

⊓⊔

To estimate the complexity of Alg. 21, we need the following

Lemma 23.
For each alternative f i(x(k)
the formula (Vni

Ni1, . . . , x(k)
Nini
j=1 Nij ∈ D(k)) ∧ (Wni
j=1 Nij ∈ M (k)) holds for at most one k.

),

Proof. For each j ∈ {1, . . . , ni}, Nij is in at most one M (k) by Lem. 11.1.
Denoting this k by kj, we have Nij 6∈ D(k) for all k < kj, again by Lem. 11.1.
Hence, the formula can hold at most for k = max{k1, . . . , kni}.

⊓⊔

19

Corollary 24.
(Complexity of Alg. 21)
Algorithm 21 has a time complexity of O(al · (ar + log nt)).
Its memory complexity is that of the input grammar, viz. O(al · ar).

Proof. Due to the diﬀerent access modes, the sets F (·), M (·), and D(·) can be imple-
mented by a heap [AHU74, Sect. 3.4], a linked list, and a bit vector, respectively.
Due to Lem. 11.6, it is suﬃcient to enter a nonterminal N into the heap iﬀ x(·)
N is
decreased for the ﬁrst time.

We add a counter in the range {0, . . . , ar} to each alternative

N ::= . . . fi(Ni1, . . . , Nini) . . . ,

which counts the number of Nij with Nij ∈ D(k).
when some Nij is added to D(k) and we visit all alternatives Nij occurs in.
counter of an alternative reaches its arity ni, we know that the formula

It is initially 0 and is increased
If the

ni

(

^

j=1

Nij ∈ D(k)) ∧ (

ni

_

j=1

Nij ∈ M (k))

holds, and evaluate the alternative, setting x(k+1)
)}.
It may be neccessary to reorder the heap F (·) to get N to its appropriate place.
Since the value of x(·)
N cannot have grown, it is suﬃcient to move N upwards in the
heap. After evaluation, the alternative will not be considered any more during the
algorithm.

Ni1, . . . , x(k)
Nini

N

:= min{x(k)

N , f i(x(k)

For a certain alternative, increasing and checking the counter takes at most ar · O(1)
time, evaluation of f takes O(ar) time, reordering the heap takes O(log nt) time,
and all other set operations are dominated by the latter. Hence, the overall time
complexity is O(al · (ar + log nt)). The memory complexity is obvious, since the
input grammar dominates all other data structures, including the counters.

If we omit the counters, we get a time complexity of O(al · (ar2 + log nt)), since
each of the ni times we visit an alternative Nij occurs in, we have to test whether
Vni
j ′=1 Nij ′ ∈ D(k). For small values of ar, this complexity may be acceptable, and
we can avoid to extend a possibly huge input grammar by additional counter ﬁelds.
If alternatives are stored in preﬁx form in memory, i.e. one word for f , followed by
ni words for Ni1, . . . , Nini, it is suﬃcient to add two binary ﬂags to each nonterminal
of each alternative, one indicating whether it has been visited, the other indicating
whether it is the rightmost argument of its alternative. The latter ﬂag should be
set in the word for f , too, in order to delimit the memory area for Ni1, . . . , Nini to
⊓⊔
the left.

20

k

Q0

P1

Q1

P2

Q2

x F D

x F D

x F D

x F D

x F D

0 ∞

∞

∞

∞

∞

1 a 0 + +

2

3

4

5

6

+ p a 0 + + j a 1 +

+

+

+

+

+ qp a 0 + +

+

+

+

+ p qp a 0 + + j qp a 1 +

+

+

+ qp qp a 0 + +

+

+

Fig. 3. Lazy propagation algorithm Alg. 10

Consider again the grammar and the weight functions from Fig. 1. Figure 3 shows
the cycles of Alg. 10 in computing the weights of each Qn and Pn, where nmax = 2.
For each nonterminal N, we show (from left to right) a term of weight x(k)
N , the value
of x(k)
N , a ﬂag indicating whether N ∈ F (k), and ﬂag indicating whether N ∈ D(k). A
“+” ﬂag indicates that the corresponding relation holds, an empty ﬂag ﬁeld indicates
the contrary. An empty x ﬁeld means that x(k)
. The algorithms stops after
cycle 6 since F (6) = {}. Note that each alternative of each rule is evaluated just
once.

N = x(k−1)

N

5 Partial weight orderings

It would be desirable to provide an equivalent to Alg. 21 for a partial weight order
(<) on D. This would allow us to deﬁne weight functions such that wg(t) is the set
of distinct variables occuring in t. In many applications, a term is more interesting
if it contains fewer distinct variables. For example, if terms denote transformation
rules, f (x)   g(x) is usually preferred over f (x)   g(y). However, we have the
following negative results.

Lemma 25.
There is no total nontrivial order (<) on the power set ℘(V) of variables such that
V ⊆ W ⇒ V 6 W for all V, W ⊆ V and (∪) is monotonic wrt. (<).

Proof. Let x, y, z ∈ V. If {x, y} < {x, z}, then {y} 6 {x, y} < {x, z} and trivially
{x, z} 6 {x, z}; hence {x, y, z} 6 {x, z} by monotonicity. Similarly, {x, z} < {x, y}
implies {x, y, z} 6 {x, y}. In each case, there are two sets V 6= W such that V 6
⊓⊔
W 6 V .

21

Deﬁnition 26.
It is straight-forward to generalize the deﬁnitions from Sect. 2 to non-total orderings.
A partial order (<) on the power set ℘(V) of variables can be deﬁned by: v1 < v2 ⇔
v1 ( v2 for all v1, v2 ⊆ V.

If we deﬁne x = {x} for each variable x ∈ V, and f (v1, . . . , vn) = v1 ∪ . . . ∪ vn for
each n-ary function, including constants, we get wg(t) = var(t). That is, a weight is
a set of variables.

Not every set of weights has a unique minimal element, since (<) is not total. There-
fore, we deﬁne for a set T of terms

wg(T ) = {v ⊆ V | (∃t ∈ T : wg(t) = v) ∧ (¬∃t′ ∈ T : wg(t) < v)}.

In contrast to Sect. 2, wg(T ) ⊆ D is a set of weights rather than a single weight. ⊓⊔

The following notion is needed for Lem. 29 below.

Deﬁnition 27.
For m sets S1, . . . , Sm of sets, deﬁne S· m
pointwise union.

i=1Si = {Sm

i=1 si | Vm

i=1 si ∈ Si} as their

For example, if S1 = {{a, b, c}, {a, d, e}} and S2 = {{b, c, d}, {d, e}}, we have
S· 2
⊓⊔

i=1Si = {{a, b, c, d}, {a, b, c, d, e}, {a, d, e}}.

Lemma 28.
The pointwise set union from Def. 27 has the following properties:

i=1 s ∈ Si,
i=1Si,

1. If Vm
2. If
3. If #s = n and Vm

s ∈ S· m

then s ∈ S· m
then Vm

i=1 Vsi∈Si

i=1Si.

i=1 ∃si ∈ Si : si ⊆ s.

#si = n,

then Vm

i=1 s ∈ Si ⇔ s ∈ S· m

i=1Si.

Proof.

1. By Def. 27, s = Sm
2. If s = Sm
3. Follows from 1 and 2.

i=1 si, then si ⊆ s for each i.

i=1 s is an element of S· m

i=1Si.

⊓⊔

Lemma 29.
The problem to compute minimal nonterminal weights wrt. (<) from Def. 26 is NP
hard.

22

Proof. Let a conjunctive normal form C be given. Let {x1, . . . , xn} be the set of
propositional variables occurring in C. Without loss of generality, we assume

C ⇔ D1 ∧ . . . ∧ Dm
Di ⇔ Ai1 ∨ . . . ∨ Aini
Aij ∈ {xj, (¬xj)}

and

for i = 1, . . . , ni, where

for i = 1, . . . , m and j = 1, . . . , ni .

We use a signature Σ = {c, d} ∪ {y1, . . . , yn} ∪ {z1, . . . , zn} and consider y1, . . . , yn
and z1, . . . , zn as variables. Consider the following grammar:

1, . . . , D′

m).

i ::= ψ(Ai1) | . . . | ψ(Aini),

C ′ ::= c(D′
D′

Pj ::= yj,

Nj ::= zj,

Fj ::= yj | zj,

i = 1, . . . , m.

j = 1, . . . , n.

j = 1, . . . , n.

j = 1, . . . , n,

where ψ is a mapping from atoms to alternatives deﬁned by:

ψ(xj) = d(F1, . . . , Pj, . . . , Fn)
ψ(¬xj) = d(F1, . . . , Nj, . . . , Fn)

The grammar has 1 + m + n · 3 rules and 1 + (Pm
i=1 ni) + n · 4 alternatives, while
the conjunctive normal form has Pm
i=1 ni atoms. Observe that the set L(C ′) of all
terms derivable from C ′ is ﬁnite, since the grammar does not contain recursive
rules; similarly, all L(D′
i) are ﬁnite. If α is a nonterminal or an alternative, deﬁne
ξ(α) = {var(t) | t ∈ L(α)}.

For example, from (x1 ∨ ¬x3) ∧ (¬x2 ∨ x3), we obtain the grammar

1, D′

2),

C ′ ::= c(D′
D′
D′

1 ::= d(P1, F2, F3) | d(F1, F2, N3),
2 ::= d(F1, N2, F3) | d(F1, F2, P3),

P1 ::= y1,
N1 ::= z1,
F1 ::= y1 | z1, F2 ::= y2 | z2, F3 ::= y3 | z3.

P2 ::= y2,
N2 ::= z2,

P3 ::= y3,
N3 ::= z3,

We call a mapping σ : {x1, . . . , xn} −→ {true, false} a truth value assignment. Each
such mapping can be homomorphically extended to all propositional formulas over
{x1, . . . , xn}.
Deﬁne V = {{w1, . . . , wn} | Vn
j=1 wj ∈ {yj, zj}}. Each member of V is a set of
cardinality n. Deﬁne a bijective mapping ρ from truth value assignments to V by
ρ(σ) = {yj | σ(xj) = true} ∪ {zj | σ(xj) = false}.

Observe the following facts:

23

1. Each ξ(ψ(Aij)) is a subset of V :

This follows from the deﬁnition of ψ(Aij). In the example, ξ(ψ(¬x3)) =
{{y1, y2, z3}, {y1, z2, z3}, {z1, y2, z3}, {z1, z2, z3}}.

2. Each ξ(D′

i) is a subset of V :

This follows from 1, using L(D′
the example, we have

i) = Sni

j=1 L(ψ(Aij)) and the deﬁnition of ξ. In

ξ(D′
ξ(D′

1) = {{y1, y2, y3}, {y1, y2, z3}, {y1, z2, y3}, {y1, z2, z3}, {z1, y2, z3}, {z1, z2, z3}},
2) = {{y1, y2, y3}, {y1, z2, y3}, {y1, z2, z3}, {z1, y2, y3}, {z1, z2, y3}, {z1, z2, z3}}.

3. An atom Aij is satisﬁed by a truth value assignment σ iﬀ ρ(σ) ∈ ξ(ψ(Aij)):

If Aij = xj, then

ξ(ψ(Aij))

= ξ(d(F1, . . . , Pj, . . . , Fn))
= {var(t) | t ∈ L(d(F1, . . . , Pj, . . . , Fn))}
= {{w1, . . . , yj, . . . , wn} | Vk6=j wk ∈ {yk, zk}}
= {v ∈ V | yj ∈ v}

Def. ψ

Def. ξ

Def. L, var, Fk, Pj

Def. V

Hence,

Aij is satisﬁed by σ

⇔ σ(xj) = true

⇔ yj ∈ ρ(σ)

⇔ ρ(σ) ∈ ξ(ψ(Aij))

Aij = xj

Def. ρ

by the above argument

If Aij = (¬xj), then similarly ξ(ψ(Aij)) = {v ∈ V | zj ∈ v};
and σ satisﬁes Aij iﬀ ρ(σ) ∈ ξ(ψ(Aij)).

4. A disjunct Di is satisﬁed by a truth value assignment σ iﬀ ρ(σ) ∈ ξ(D′

i):

σ satisﬁes Di

⇔ ∃j : σ satisﬁes Aij

⇔ ∃j : ρ(σ) ∈ ξ(ψ(Aij))
⇔ ρ(σ) ∈ Sni
j=1 ξ(ψ(Aij))
⇔ ρ(σ) ∈ ξ( ni
j=1ψ(Aij))
⇔ ρ(σ) ∈ ξ(D′
i)

Def. Di

by 3

Def. ξ, L
Def. D′
i

5. wg(C ′) ⊆ ξ(C ′) = S· m

i=1ξ(D′

i):

The inclusion from the deﬁnition of wg. The equality follows from the deﬁnitions
of ξ, L, and var. In the example, we have wg(C ′) = {{y1, y2, y3}, {y1, z2, y3},
{y1, z2, z3}, {z1, z2, z3}, {z1, y2, y3, z3}} and e.g. {y1, z1, y2, y3} ∈ ξ(C ′) \ wg(C ′).

24

6. C is satisﬁed by a truth value assignment σ iﬀ ρ(σ) ∈ ξ(C ′):

σ satisﬁes C

⇔ ∀i : σ satisﬁes Di
⇔ ∀i : ρ(σ) ∈ ξ(D′
i)
⇔ ρ(σ) ∈ S· m
i=1ξ(D′
i)
⇔ ρ(σ) ∈ ξ(C ′)

Def. C

by 4

by 2 and Lem. 28.3

by 5

7. Let v be a member of wg(C ′) with least cardinality. C is satisﬁable iﬀ #v = n:

#v = n

⇒ ∀i : v ∈ ξ(D′
i)

by Lem. 28.3, using 5 and 2

⇒ v ∈ V

⇒ ∃σ : v = ρ(σ)
⇒ σ satisﬁes C ′

⇒ #v 6 n

⇒ #v = n

by 2

ρ bijective

by 6
since v has minimal cardinality in ξ(C ′)

by 5, 2, and Lem. 28.2

Hence, the NP complete problem to decide the satisiﬁability of a conjunctive normal
form C has been reduced to the problem to compute the minimal cardinality of a
set from wg(C ′).
⊓⊔

References

[AHU74] Alfred V. Aho, John E. Hopcroft, and Jeﬀrey D. Ullman. The Design and Analysis of Computer

[AM91]

[BB91]

Algorithms. Addison-Wesley, 1974.
A. Aiken and B. Murphy.
Functional Programming Languages and Computer Architecture, pages 427–447, Aug 1991.
J.M. Barzdin and G.J. Barzdin. Rapid construction of algebraic axioms from samples. Theo-
retical Computer Science, 90:199–208, 1991.

Implementing regular tree expressions.

In ACM Conference on

[BGW93] Leo Bachmair, Harald Ganzinger, and Uwe Waldmann. Set constraints are the monadic class.

[Bur95]

[Bur02]

In Eight Annual IEEE Symposium on Logic in Computer Science, pages 75–83, 1993.
J. Burghardt. Regular substitution sets: A means of controlling E-uniﬁcation. volume 914 of
LNCS, pages 382–396. Springer-Verlag, 1995.
Jochen Burghardt. Axiomatization of ﬁnite algebras. In Proc. KI 2002, number 2479 in LNAI,
pages 222–234. Springer, 2002.

[CDG+99] H. Comon, M. Dauchet, R. Gilleron, F. Jacquemard, D. Lugiez, S. Tison, and M. Tommasi. Tree
Automata Techniques and Applications. Available from www.grappa.univ-lille3.fr/tata, Oct
1999.

[Com89] H. Comon. Inductive proofs by speciﬁcation transformation. volume 355 of LNCS, pages 76–91.

Springer, 1989.

[Com90] Hubert Comon. Equational formulas in order-sorted algebras. In Proc. ICALP, 1990.
[DJ90]

N. Dershowitz and J.-P. Jouannaud. Rewrite Systems, volume B of Handbook of Theoretical
Computer Science, pages 243–320. Elsevier, 1990.

25

[Emm91] Helmut Emmelmann. Code selection by regularly controlled term rewriting. In Susan L. Graham
Robert Giegerich, editor, Code Generation — Concepts, Tools, Techniques, Proc. Int. Workshop
on Code Generation, Dagstuhl/Saarland, Workshops in Computing, pages 3–29. Springer, May
1991.

[Emm94] Helmut Emmelmann. Codeselektion mit regulr gesteuerter Termersetzung. PhD thesis, Univer-

[Hei94]

[Hei95]

sity Karlsruhe, 1994.
Birgit Heinz. Lemma discovery by anti-uniﬁcation of regular sorts. Technical Report 94–21,
TU Berlin, 1994.
Birgit Heinz. Anti-Uniﬁkation modulo Gleichungstheorie und deren Anwendung zur Lemma-
generierung. PhD thesis, TU Berlin, Dec 1995.

[McA92] David McAllester. Grammar rewriting.

In Proc. CADE-11, volume 607 of LNAI. Springer,

[SS88]

[TW68]

[Uri92]

1992.
Manfred Schmidt-Schau. Computational Aspects of an Order-Sorted Logic with Term Declara-
tions. PhD thesis, Univ. Kaiserslautern, Apr 1988.
J.W. Thatcher and J.B. Wright. Generalized ﬁnite automata theory with an application to a
decision problem of second-order logic. Mathematical Systems Theory, 2(1), 1968.
T.E. Uribe. Sorted uniﬁcation using set constraints.
volume 607 of LNCS, pages 163–177, 1992.

In D. Kapur, editor, Proc. CADE–11,

26

