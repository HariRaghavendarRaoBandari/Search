Impacts of Network Topology on the Performance of a Distributed

Algorithm Solving Linear Equations

Hong-Tai Cao1, Travis E. Gibson2, Shaoshuai Mou3 and Yang-Yu Liu4

6
1
0
2

 
r
a

 

M
4
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
4
5
1
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract— Recently a distributed algorithm has been pro-
posed for multi-agent networks to solve a system of linear
algebraic equations, by assuming each agent only knows part of
the system and is able to communicate with nearest neighbors to
update their local solutions. This paper investigates how the net-
work topology impacts exponential convergence of the proposed
algorithm. It is found that networks with higher mean degree,
smaller diameter, and homogeneous degree distribution tend
to achieve faster convergence. Both analytical and numerical
results are provided.

I. INTRODUCTION

A major goal in studying networked systems is to under-
stand the impact of network topology within the context of
the application of interest, from epidemic spreading [1], [2]
to synchronization [3], [4], controllability [5]–[7] , observ-
ability [8], ﬂocking [9], [10] and consensus [11]–[14].

Recently, Mou et al. proposed a network-based distributed
algorithm to solve for x in the linear equation Ax = b [15],
[16]. In this algorithm it is assumed that each agent is located
in a communication network and has partial knowledge of
A and b. Under mild conditions on the connectivity of the
underlying network, all the agents’ states (or local solutions)
converge to the exact solution x = A−1b [15]–[19].

The proposed algorithm in [16] is distributed, applicable
for all
linear equations as long as they have solutions,
works for time-varying networks, converges exponentially
fast, operates asynchronously, and does not involve any small
step-size. The aim of this paper is to further characterize the
relation between its exponential convergence and the network
topology. The main contribution of this work is an analytical
bound that connects the convergence rate of the algorithm to
the network topology and the linear equation. Both theoret-
ical and numerical results show that networks with higher
mean degree, smaller diameter, and homogeneous degree
distributions tend to speed up this distributed algorithm.

The following notation is used throughout the paper. The
ℓ2-norm is denoted as k · k. Matrices are denoted by upper
case letters in bold such as A and P. A partition of a

1Department of Electrical Engineering, University of Southern Cali-
fornia, Los Angeles, California 90089, USA. Channing Division of Net-
work Medicine, Brigham and Women’s Hospital, Harvard Medical School,
Boston, Massachusetts 02115, USA. Email:caohongtai2014@gmail.com

2Channing Division of Network Medicine, Brigham and Women’s
Hospital, Harvard Medical School, Boston, Massachusetts 02115, USA.
Email:tgibson@mit.edu

3School of Aeronautics & Astronautics, Purdue University, West

Lafayette, Indiana 47907, USA. Email:mous@purdue.edu

4Channing Division of Network Medicine, Brigham and Women’s Hos-
pital, Harvard Medical School, Boston, Massachusetts 02115, USA. Center
for Cancer Systems Biology, Dana-Farber Cancer Institute, Boston, Mas-
sachusetts 02115, USA. Email: yyl@channing.harvard.edu

matrix is denoted by an upper case letter with a subscript,
i.e. Ai is a partition of matrix A, which can also be a row
vector. Vectors are denoted by lower case italic letters, such
as x, y, z. A network or graph is denoted as G(V,E), where
V is the node (or vertex) set and E is the link (or edge)
set. The network topology is represented by the adjacency
matrix A = {αij} of the network. This paper is organized
as follows. The network-based distributed algorithm is
brieﬂy presented in Section II. The theory of how the
network topology impacts
the algorithm performance
is present in Section III. The main proof is presented in
Section IV. Finally, the conclusion is presented in Section V.

II. A DISTRIBUTED ALGORITHM FOR SOLVING LINEAR

EQUATIONS

Consider a system of linear algebraic equations

Ax = b,

(1)
which has a unique solution x∗. Here A ∈ Rn×n , b ∈ Rn
and x ∈ Rn. The partition of the matrix A is deﬁned as
A = col{A1, A2,··· , Am}, where col{·} is an operator that
stacks elements into a column, Ai ∈ Rni×n, and the partition
of the vector b is deﬁned as b = [b1, b2,··· , bm]T, bi ∈ Rni,
wherePm
i=1 ni = n. Assume that the entire system (A, b) is
unavailable to a single agent; instead different partitions of
the system (cid:0)Ani×n

i (cid:1) are available to different agents. In

this paper we consider the simplest case: ni = 1 and m = n,
i.e. each agent knows exactly one row of A matrix and one
element of the b vector.

, bni

i

The distributed algorithm proposed in [16] computes the
solution of the linear equation (1) through a multi-agent
network G(V,E), where V = {1, 2,··· , n} and E ⊆ V × V.
The topology of this n-agent network is represented by its
adjacency matrix A(G) = [αij ]n×n with
αij =( 1 if(i, j) ∈ E

0 otherwise.

Agent i in the network is synonymous with vertex i in the
graph G(V,E). The topology of the multi-agent network is
completely independent of the linear equation in (1).
For simplicity we make the following assumption:
Assumption 1: The graph G is undirected and connected.
Every vertex has a self loop and there are no multiple edges
between two vertices.

Consider agent i who knows (Ai, bi). It calculates its local
solution xi ∈ Rn to Aixi = bi and exchanges the solution

xi with its neighbors, denoted as Ni = {j ∈ V|(i, j) ∈ E}.
In this work t is the discrete time variable and takes values
in {0, 1, 2,···}. The exact (or global) solution to Ax = b
is obtained when all the local solutions xi’s reach consensus
through the following iteration procedure:

(2)

1
di

xi(t + 1) = xi(t) −

Pi
dixi(t) − Xj∈Ni
i (cid:1)−1
i (cid:0)Ai · AT

xj(t)
 ,
where Pi = I− AT
tion on the kernel of Ai, i = 1,··· , n, and di = Pn
is the degree of agent i.
Let x∗ be the true solution to (1) and it must satisfy
Aix∗ = bi for i = 1,··· , n. Deﬁne the error between xi(t)
and x∗ as
(3)

Ai is the orthogonal projec-
j=1 αij

yi(t) = xi(t) − x∗,

which is in the kernel of Ai. In addition, note that P2
i = Pi
and Piyi(t) = yi(t). Replacing xi(t+ 1) and xi(t) by yi(t+
1) and Piyi(t) in (2), we get the error updating equation

yi(t + 1) =

1
di

Pi Xj∈Ni

Pj yj(t),

(4)

y(0) = Mty(0),

for i = 1,··· , n. These n equations can be rewritten in the
following compact form
y(t) =(cid:0)Pdiag(cid:2)(cid:0)D−1AT(cid:1) ⊗ I(cid:3) Pdiag(cid:1)t
(5)
where the matrix M is called the updating matrix and
y(t) = col{y1(t), y2(t),··· , yn(t)}. The matrix Pdiag =
diag{P1, P2,··· , Pn} ∈ Rn2×n2 is a block diagonal matrix
with Pi ∈ Rn×n and D = diag{d1, d2,··· , dn} is a
diagonal matrix. The operator ⊗ is the kronecker product
[20].
This algorithm has been proven to converge by using the

mixed norm [21] [16, Chapter 4.3.1] of M deﬁned as

kMkmix = kQk∞,

where Q = {qij}, qij = αij
di kPiPjk. Indeed, Mt satisﬁes
limt→∞ kMtkmix = 0 if the undirected multi-agent network
is connected [16]. Therefore y = Mty(0) → 0 and thus
xi → x∗ for all i ∈ V.
Network properties play important roles in consensus
problems. In particular, the second smallest eigenvalue λ2(L)
of the graph laplacian bounds the convergence rate of con-
sensus [14], [22]. Given the fact that projection matrices Pi’s
are used in constructing the updating matrix M, it is not clear
how the network topology A impacts the convergence rate
of this algorithm. Thus, in this work we approach the proof
of convergence from a different angle.

III. IMPACTS OF NETWORK TOPOLOGY ON THE

DISTRIBUTED ALGORITHM

A. Theoretical Analysis

In this section, we study how network topology impacts
the performance of the network-based distributed algorithm.

Before we state the main theorem, we introduce the following
deﬁnitions.

Deﬁnition 3.1 (Walk): In a graph G, a walk wl ∈ V l+1
[23] of length l is a sequence of vertices (v0, v1,··· , vl)
with {vi−1, vi} ∈ E(G) for all 1 6 i 6 l when l > 1. If
l = 0, then w0 is simply a vertex v0. Speciﬁcally, we denote
a walk of length l starting at vertex v0 and ending at vertex
vl as wl

.

Deﬁnition 3.2 (f (wl, β) Product of a Walk): Let wl be a
walk of length l. Let βvi ∈ U be a value associated with
vertex vi. We can deﬁne a function of the walk wl as

v0vl

f (wl, β) = Πi=l

i=0βvi ,

where β is indexed by the walk wl = (v0, v1,··· , vl) with
values β = (βv0 , βv1 ,··· , βvl ). The function f (wl, β) ∈ U
is called the product of walk wl. In this work U is either R
or Rn×n.

Deﬁnition 3.3 (S(l) and S1(l) Spaces): In a graph G, all
the possible walks of length l form the S(l) Space. Denote
a subspace of S(l) as S1(l) if and only if

• the walk wl starts from an arbitrary vertex v0 and ends
at vl and visits all the vertices vi ∈ V of G,
• there does not exist a vertex vj ∈ V that divides wl into
two sub-walks, where one walk starts at v0 and ends at
vj, the other one starts at vj and ends at vl, that both
of them visit all the vertices vi ∈ V of G.

Note that the end vertex of the previous sub-walk and the
starting vertex of the following sub-walk are repeated twice
when dividing a walk. It is trivial that for wl walks of length
l 6 n − 1, they can’t be in the S1(l) subspace.
Deﬁnition 3.4 (Order r): If a walk wl can be divided
into several walks wl1, wl2, ··· , wlr , where li > 1 and
wli ∈ S1(li), then all the walks of the same number r form
a subspace Sr(l) where r is called the order of the space.
We also say that r is the order of the walk wl. Sr(l) ( S(l)
for any order r.

1

i

di

, 1
dv1

Let ϕ =

If a walk wl does not visit all the vertices in a graph G,
then its order is r = 0 and it is in S0(l). This special case
means that there exists at least one vertex vi ∈ V which does
not appear in the sequence of the walk wl. The order of any
wl walk is uniquely determined and non-negative, i.e. r > 0.
1
d =

(kAik),
indexed by the walk wt

(√nτkA−1k)2 , τ = max
dj(cid:17) be

(cid:16) 1
,··· , 1
ij =
(i, v1,··· , vt−1, j) which starts at agent i and ends at agent
j where wt
ij ∈ V t+1, then we have the following theorem
Theorem 3.5 (Convergence Bound): Given a linear equa-
tion Ax = b, A = col{Ai} ∈ Rn×n and its unique solution
x∗, let xi(t) be the local solution at agent i located in
an undirected network G(V,E) whose adjacency matrix is
A = {αij}, then the error yi(t) deﬁned in (3) is bounded as
kyi(t + 1)k 6XNj

Xr=0 Xwt

) (1 − ϕ)

ij∈Sr

f (wt

ij,

nr

2 kyj(0)k
(6)

rm(t)

1
d

for i = 1,··· , n. Here rm(t) 6 ⌊ t
of the product. Note that w0
ij = w0

n⌋ is the maximum order
ii = (i) and w1
ij = (i, j).
Theorem 3.5 provides another method to prove that the
distributed algorithm converges to the true solution x∗ be-
sides the mixed norm method in [16], which is discussed
at the end of this work. The bound in (6) connects the
network topology with the convergence rate of the algorithm,
by the degree di of agent i explicitly, and by counting
the number of wt ∈ Sr(t) walks in every order r > 0
in the network implicitly. Before moving to the detailed
proof of this theorem, we ﬁrst discuss how topology impacts
the performance of the algorithm. To illustrate the topology
impacts, we start with the deﬁnition of a walk wt, then we
discuss the properties of the corresponding f (wt, 1
d ) product.
Given a network G of size n, all the possible walks of
length t are determined by its adjacency matrix A = {αij}.
Let 1
be the inverse degree of agent i, then the product
di
1
, 1
di1 ··· 1
1
can be represented by f r(wt
d ), where we
dit
di0
recall that 1
. For simplicity,
d is indexed by the walk wt
we let i = i0 and j = it. Hence given a starting agent i,
the summation of all products of the walk w1 from i to all
. In

general, we have

the agents j = 1, 2,··· , n is represented as Pn
Xr=0 Xwt
···

Xlt−1=1

Xl1=1

αil1 αl1l2

f r(wt

didl1

···

αij
didj

) =

rm(t)

1
d

ij ,

j=1

i0 it

i0it

ij

n

n

αlt−1j
dlt−1

1
dj

.

ij , 1

ij, f (wt

ij, j = 1, 2,··· , n are repeated by walks wt+1

It is trivial that for any r, i, j and the walk wt
d ) ∈
(0, 1). We now explore a scenario when the above mentioned
sum remains a constant, even if the walk length increases.
Given a network G and given a starting agent i, if all
walks wt
ij ′ who
visit one more agent j′ at the end, after reaching agent j,
then the summation of all f (wt+1
d ) products remains the
same. This visit of agent j′ generates n products based on
ij , 1
d ),
each f (wt
j = 1, 2,··· , n. Only dj out of n products are not zero when
αjj ′ = 1. The summation of all newly generated products is
unchanged, which is

d ) and each of them equals to αjj′

ij ′ , 1

f (wt

ij, 1

dj′

XNj′

1

dj ′ XNj

f (wt

ij,

1
d

) =XNj

f (wt

ij ,

1
d

)

(7)

for PNj′ = dj ′. In general, the summation of all products

of all walks by t + 1 visits starting from a given agent i to
all the neigbors of all the agents j is

rm(t)

1
d

n

n

)

=

ij ,

f (wt

ij∈Sr (t)
n
n

XNj
Xr=0 Xwt
Xj ′=1
Xj
Xit−1
···
Given a network G and a starting agent i, the summation
d ) is never increasing and the order
ij∈S0(t) f (wt
PNjPwt
d ) product is never decreasing as the walk
, 1
d ) product of the

r of the f (wt, 1
length t grows. Given an arbitrary f (wt

αit−1j
dit−1

Xi1

αjj ′
dj

αii1
di

ij , 1

···

= 1.

(8)

i0 it

i0it

i0it ∈ S0(t), when the walk wt

makes one more
walk wt
visit from agent it to the next agent it+1, it forms dit new
products and the summation of all dit products is unchanged,
which is already shown in (7). However, there exists a walk
of length t1 when there exists at least one walk changing
from the S0(t1) subspace to the S0(t1 + 1) subspace. For
every wt2 walk (of order r > 1) of length t2, it never changes
to a walk of order r = 0. This hold for any walk wt ∈ S0(t),
hence the summation of all f (wt, 1
d ), wt ∈ S0(t) product is
never increasing, that is

XNj Xwt+1

ij ∈S0(t+1)

f (wt+1

ij

,

1
d

) 6XNj Xwt

ij∈S0(t)

f (wt

ij,

1
d

)

and given a walk of length t and a starting agent i, the bound
in (6) decreases when the order of walks increases, due to
the exponential factor limr→∞ (1 − ϕ)
2 = 0. Since the
summation of all f products starting from a chosen agent
i is always 1 (8), the bound in 3.5 can only be decreased
by either i) for a ﬁxed length t, increasing the percentage of
walks with higher r, or ii) by increasing the order r for all
walks as rapidly as possible.

nr

With the above two observations we conclude that given
any two networks G1 and G2, the distributed algorithm (2)
tends to converge faster on networks G1 if G1 and G2 have
similar topology properties except any combinations of the
following
1 G1 has a shorter diameter,
2 G1 has a more homogeneous degree distribution,
3 G1 has a higher mean degree.
Although Theorem 3.5 has 1
d as a factor in the products,
it is not trivial to conclude that higher degree makes the
products smaller since higher degree decreases each product
while increases the number of products. The summation of
all products remains a constant, as shown in (8). However the
bound decreases when the order r of the products increases.
We address these three points in order.

1) Diameter: For two graphs G1 and G2 with the same
degree distribution and hence the same mean degree, if G1
has a shorter diameter [24] than G2, then for ﬁxed t, walks
from G1 will necessarily have a larger minimum order r as
compared to those from G2. This follows from the fact that
all the agents can be visited with fewer steps in a network
with shorter diameter. Thus, all things being equal between
two graphs, if r(t) increases more rapidly for one graph
as opposed to another, the exponential factor (1 − ϕ)
will decrease more rapidly. Therefore networks with shorter
diameter make the distributed algorithm converge faster.

nr
2

2) Degree Distribution: Let G1 and G2 be two graphs with
same mean degree but different degree distributions. Let G1
have a more homogeneous degree distribution than G2. Walks
in G2 typically have lower order r than the walks of the
same length in G1. This is because walks on G2 rather than
G1 have to walk though the high degree vertices again and
again to reach all the other low degree vertices. Hence for
a given length of walks, the order r from the walks on G1

is higher. Therefore homogeneous degree distribution makes
the algorithm converges faster.

3) Mean Degree: Adding edges to a graph typically
results in a shorter diameter. Given two graphs G1 and
G2 with similar degree distribution where G1 has a higher
mean degree,
the diameter of G1 is typically no larger
than G2. Hence the orders r’s from G1 are typically higher
than those in G2 for walks of ﬁxed length. Adding a new
edge can either make the degree distribution homogeneous
or make it heterogeneous, depending on where the new
edge is added. The overall change of degree distribution for
each newly added edge is difﬁcult to analyze. However, if
multiple new edges are added uniformly to a graph, this will
typically result in a more homogeneous degree distribution,
thus increasing the mean degree of the network makes the
distributed algorithm converge faster.

B. Simulation Results

To verify our theoretical predictions, we perform extensive
numerical simulations. We ﬁrst quantify the convergence rate
of the network-based distributed algorithm. One measure
is the solution accuracy of the algorithm, which is the
Euclidean distance between the local solution and the exact
(or global) one:

ǫi(t) = kxi(t) − x∗k, i = 1, 2,··· , n.

R

 

R

 

100

10−10

10−20

10−30

 

100

10−10

10−20

10−30

 

(a) <k>=8

SW p=0
SW p=0.003
SW p=0.01
SW p=0.03
SW p=0.1
SW p=1

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

 Iteration Steps

(d) <k>=8

 

 

SF γ=2.2
SF γ=3
SF γ=4.5
SF γ=6.5
ER p=0.08
RR md=8

R

 

R

 

100

10−10

10−20

10−30

 

100

10−10

10−20

10−30

 

(b) <k>=16

SW p=0
SW p=0.003
SW p=0.01
SW p=0.03
SW p=0.1
SW p=1

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

 Iteration Steps

(e) <k>=16

 

 

SF γ=2.2
SF γ=3
SF γ=4.5
SF γ=6.5
ER p=0.16
RR md=16

R

 

R

 

100

10−10

10−20

10−30

 

100

10−10

10−20

10−30

 

(c) <k>=32

SW p=0
SW p=0.003
SW p=0.01
SW p=0.03
SW p=0.1
SW p=1

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

 Iteration Steps

(f) <k>=32

 

 

SF γ=2.2
SF γ=3
SF γ=4.5
SF γ=6.5
ER p=0.32
RR md=32

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

0
0
5
 

0
0
0
1

0
0
5
1

0
0
0
2

0
0
5
2

0
0
0
3

0
0
5
3

0
0
0
4

0
0
5
4

0
 
 
 

 Iteration Steps

 Iteration Steps

 Iteration Steps

Fig. 1.
Impact of network topology on the performance of the network-
based distributed algorithm. . Tens of different linear equations are solved
by the distributed algorithm on six groups of networks of size n = 100.
The complex networks in each group are (a-c) Small-world (SW) networks;
(d-f) Scale-free (SF) networks, Erd¨os-R´enyi (ER) random graphs, random
regular (RR) graphs. In each case, we show the box-and-whisker plots and
the median value of the relative error (or convergence rate) R(t) as functions
of t. At each marked iteration step t, a box-and-whisker plot is drawn. The
mean degree of the complex networks is represented as hki.

Smaller ǫi means faster convergence rate and hence better
algorithm performance. The impacts of different network
topologies are measured by the statistical performances of
the distributed algorithm, i.e. E (Pn
i=1 ǫi) on an ensemble
of linear equations. We notice that the Euclidean distance
deﬁned above needs a reference. For example, if the true
solutions of two cases are kx∗,1k = 100 and kx∗,2k = 0.1
respectively, while the summation of Euclidean distances of
all local solutions to x∗,j are both Pn
i −
x∗,jk = 1, j = 1, 2, it is obvious the accuracy of the former
iterative process is much higher than the latter one. Therefore
the Euclidean distance should be scaled by the initial error
Pn

i=1 ǫi(0), yielding the relative error

i = Pn

i=1 kxj

i=1 ǫj

i=1 ǫi(t)
i=1 ǫi(0)

R(t) = Pn
Pn

= Pn
i=1 kxi(t) − x∗k2
Pn
i=1 kxi(0) − x∗k2

.

In this way, convergence performances among a system of
linear equations can be compared.

(9)

Fig. 2.
Convergence rate at a chosen time step for complex networks
with different topologies. The box-plot shows the relative errors at a given
step Ts = 2000. Networks with similar topological features are grouped
together in a particular subﬁgure.

Figure. 1 shows the relative error changes with different
network topologies, including small-world (SW) networks
[25] with random rewiring probability p, scale-free (SF)
networks [26] with degree exponent γ, Erd¨os-R´enyi (ER)
random graphs [27] with connectivity probability p and
random regular (RR) graphs [28] with mean degree hki.
The networks in each subﬁgure are the same in their mean
degree and they are different on only one parameter. Small-
world networks (a-c) are different in rewiring probabilities
p, which determines network diameters. Scale-free networks,
graphs and RR graphs are drastically different in their degree
distributions: scale-free networks are most heterogeneous and
random regular graphs are most homogeneous.

The numerical results shown in Figure. 1 clearly verify
our theoretical predictions, i.e. if two networks share sim-
ilar topological properties, the one with smaller diameter
(or more homogeneous degree distribution, or higher mean
degree) perform better than the other. To further demonstrate
the topology impacts, consider R(t) at t = 2000 shown
as box-and-whisker plots in Figure. 2. The smaller relative
error R(t) means higher convergence rate. It is clear from
Figure. 2a-c and Figure. 2d-f that the upper bound of relative
errors decreases as the mean degree increases for a given
network model. In other words, higher mean degree makes
the algorithm reach the true solution faster, and is consistent

with our theoretical analysis. Figure. 2a-c display that small-
world networks with higher rewiring probability (and hence
smaller diameters) have smaller relative errors R , conﬁrming
our theoretical prediction smaller diameter contributes to
higher convergence rate. As shown in Figure. 2d-f, for any
given mean degree, the random regular graphs have the
smallest relative errors while scale free networks perform
the worst. This means that the degree heterogeneity degrades
the performance of the network-based distributed algorithm
in solving linear equations (1).

IV. PROOF OF THE BOUND THEOREM

Before the formal proof of Theorem 3.5, we discuss the
structure of the matrix Mt (5) and introduce some technical
lemmas.

Let m(1)

ij ∈ Rn×n be the i, j-th partition matrix of M,

then

m(1)

ij =

αij
di

Pi · Pj,

where we recall that Pi is an orthogonal projection matrix
deﬁned right after (2). Theses block matrices m(1)
are
ij
actually the updating matrix of yi(t), which means yi(t +
ij denote the partition

ij yj(t). Similarly, let m(t)

j=1 m(1)

1) =Pn

matrix of Mt, then

n

n

m(t)

ij =

n

Xlt−1=1
Xlt−1=1

···

Xl1=1
αlt−1j
dlt−1 ···

mil1 ··· mlt−1j
Xl1=1

n

=

αil1 · αl1l2
di · dl1
Although the expression of m(t)
is long, it shows that Mt
ij
is simply a weighted sum of projection products. It follows
ij yj(0). Deﬁne

Pi ··· Plt−1 Pj.

that (4) can be written as yi(t) = Pn

j=1 m(t)

µij = αij

n

di ∈ [0, 0.5], then we have
Xj=1

Xl1=1

···

n

yi(t) =

µil1 ··· µlt−1lj Pi ··· Plt−1 Pjyj(0).

(10)
Note that it is a summation of nt products. We now separate
µil1 µl1l2 ··· µlt−1lj PiPl1 ··· Plt−1 Pjyj(0) into a µ product
(11)

µil1 µl1l2 ··· µlt−1j

and its corresponding projection product with yj(0), which
is called error sequence,

PiPl1 ··· Plt−1 Pjyj(0).

(12)

From (7) the summation of all µ products (11) satisﬁes the
following equality

n

n

Xj=1

Xlt−1=1

···

n

Xl1=1

µil1 µl1l2 ··· µlt−1j = 1.

(13)

The construction of Mt as a µ product and an error
sequence of projections allows us to separate the topological
features from the part of the algorithm that is speciﬁc to
a particular linear equation. We ﬁrst analyse each product

in the error updating equation (10) by bounding the error
sequences of (12).

Deﬁne a sequence of vectors z(t) ∈ Rn as following

z(j)(t + 1) = z(t) +

bj − Aj z(t)

kAjk2

AT
j ,

(14)

where t > 0 and the superscript (j) corresponds to its row
vector Aj and its scaler bj. Then

Pi (z(0) − x∗) = z(0) −
= z(0) +

Aiz(0)
kAik2
bi − Aiz(0)

i − x∗ +
AT
i − x∗
AT

kAik2

bj
kAik2

AT
i

= z(i)(1) − x∗.

Let z(j)(0) = xj(0), then each error sequence in (12) can
be written as

AT

lt−1 − x∗!

blt−1 − Alt−1 z(j)(0)

PiPl1 ··· Plt−2 Plt−1 Pjyj(0)
=PiPl1 ··· Plt−2 Plt−1(cid:16)z(j)(0) − x∗(cid:17)
=Pi ··· Plt−2 z(j)(0) +
kAlt−1k2
=Pi ··· Plt−2(cid:16)z(jlt−1)(1) − x∗(cid:17)
=z(il1···lt−2lt−1j)(t) − x∗.
(15)
Essentially, z(il1···lt−2lt−1j)(t) forms the sequence of z(t)
by taking different combinations of orthogonal projection
Pi at different agents, i = 1, 2,··· , n. We now show that
sequences z(t) can be bounded, so that the error sequence
is bounded as well.

We now present two theorems for bounding z(t) − x∗,
is associated with
ﬁrst for the case when the walk wt
the product f (wt, Pi), wt ∈ S0(t), and second for the
f (wt, Pi) product where wt ∈ Sr(t) and r > 1.
Theorem 4.1 (f 0 Bound): For any wt ∈ S0(t) it follows
that kf (wt, P)k 6 1 and thus kf (wt, P)k 6 1. Therefore
the dynamics in (14) satisfy the following inequality

(16)
Proof: Given that Pi is a normalized projection matrix

kz(t) − x∗k 6 kz(0) − x∗k

it follows that kPik = 1.
Theorem 4.2 (f Bound): The sequence z(t) − x∗ of the
part whose PiPl1 ··· Plt−1 Pj product is an f (wt, P) prod-
uct where wt ∈ Sr(t) and r > 1, then all the sequence
Pi1 Pi2 ··· yj(0) in this part from (15) can be written as

z(t) − x∗ = f(cid:0)wt, P(cid:1) yj(0),

where z(t) − x∗ consists of several f (wi, P), wi ∈ S1(i)
products. Then all the sequences z(t) − x∗ in this part are
bounded by

kz(t) − x∗k 6 1 −

1

(√nτkA−1k)2!

nr

nr
2

kz(0) − x∗k

<(cid:0)1 − κ(A)−2(cid:1)

2 kz(0) − x∗k,

where κ(A) = kAk · kA−1k is the usual condition number
of A and we recall the deﬁnition τ = max
The proof of Theorem 4.2 requires several technical Lem-

(kAik).

i

mas.

Lemma 1 (Orthogonal Projection): Let z(t) ∈ Rn,

kz(0)k = 0 be a sequence that follows

z(j)(t + 1) = z(t) +

bj − Aj z(t)

kAjk2

AT
j ,

where Aj, bj are deﬁned as those in linear equation (1),
which is the same as (14). Then the orthogonal projection
matrix P⋆
i onto the solution space of the linear equation (1)
is given in [29] as

z(t + 1) = P⋆

i z(t).

Let hz(t+1), z(t)i denotes the inner product of two vectors
z(t + 1) and z(t), then the above equation can be written as
follows by using the updating function (14)

P⋆
i z(t) = z(t) −

AT
i

Aiz(t) − bi
Aiz(t) − Aiz∗

kAik2

kAik

AT
i
= z(t) −
kAik
= z(t) − hz(t) − z∗, ZiiZ T
i ,
where Zi = Ai
, i = 1, 2,··· , n, kZik = 1 is a set of
kAik
normal vectors in the hyperplane {z(t) : hAi, z(t)i = bi}.
Lemma 2 (Orthogonality): Consider the linear equation
(1) and let x∗ be the unique solution. The difference of two
vectors z(t+1) and z(t) is in the kernel of P⋆
i by Orthogonal
Projection Lemma 1, which means that it is orthogonal to the
solution space. Therefore it is also orthogonal to z(t+1)−x∗.
In other words, the orthogonality of two vectors z(t+1)−z(t)
and z(t + 1) − x∗ satisﬁes
kz(t + 1) − z(t)k2 + kz(t + 1) − x∗k2 = kz(t) − x∗k2.
Lemma 3 (Inequality): Let A = col{Ai}, A ∈ Rn×n is
full rank. Then the following inequality holds

n

Xi=1

kh

Ai
kAik

, xik2 >

1

(τkA−1k)2kxk2.

where hAi, xi denotes the inner product of vector Ai and x
and we recall the deﬁnition τ = max
Proof: [Proof of Inequality Lemma 3] Consider the lin-
ear equation in (1) and using the submultiplicative property
of the ℓ2-norm the following holds

(kAik).

i

kA−1k2 · kAxk2 > kA−1Axk2, ∀ x ∈ Rn,

where A−1 is deﬁned because x∗ is the unique solution of
the linear equation in (1). Considering the matrix partition
A = col{Ai}, we have
Xi=1
Xi=1

, xik2 > kxk2
kA−1k2

khAi, xik2 =

kAik2kh

Ai
kAik

n

n

.

Moreover,
n

Xi=1

τ 2kh

Ai
kAik

, xik2 >

>

Ai
kAik

, xik2

n

Xi=1
kAik2kh
1
kA−1k2kxk2,

where τ > 0 since A is full rank. Dividing by τ we arrive
at the following inequality

n

Xi=1

kh

Ai
kAik

, xik2 >

1

(τkA−1k)2kxk2.

Proof: [Proof of f Bound 4.2] Let x∗ denote the unique
solution to the linear equation (1). Let z(t) − x∗ be vector
sequence from the f (wt, Pi), wt ∈ Sr(t) product part of the
error sequence (15) where r > 1 and substitute the z(t+1) by
the updating function (14) in the the Orthogonality Lemma
2 then we have

kz(t + 1) − x∗k2
= − kz(t + 1) − z(t)k2 + kz(t) − x∗k2
= − khAi, z(t) − x∗i
= − khz(t) − x∗, Ziik2 + kz(t) − x∗k2,

kAikk2 + kz(t) − x∗k2

kAik

AT
i

where Zi = Ai
kAik
subscript i in Zi = Ai
kAik
least once. There exists θi(t) > 0 such that

. Since the walk wt ∈ Sr(t), r > 1, the
takes all the values 1, 2,··· , n at

khz(t) − x∗, Ziik2 >

θi(t)

(τkA−1k)2kz(t) − x∗k2

for i(t) = 1, 2,··· , n, by the Inequality Lemma 3. Note that

θi(t)

(τkA−1k)2kz(t) − x∗k2 6 khz(t) − x∗, Ziik2

6 kz(t) − x∗k2,
(τkA−1k)2 6 1 for i(t) =

θi(t)

where kZik = 1. Therefore
1,··· , n, and then kz(t) − x∗k2 is bounded as
kz(t) − x∗k2
6 1 −
θi(1)

(τkA−1k)2!··· 1 −

θi(t)

(τkA−1k)2!kz(0) − x∗k2,

where

0 6 1 −

θi(t)

(τkA−1k)2! 6 1.

(17)

Note that the sequence z(t) − x∗ forms the f (wt, P),
wt ∈ Sr(t), r > 1 product part. Because of the fact Pr
i = Pi,
all i(t) = 1, 2,··· , n are present at least once in the each
sub-walk of the original walk by deﬁnition. Hence the walk
(τkA−1k)2(cid:17)
wt corresponding to (cid:16)1 − θi(1)
is divided into r sub-walks wti ∈ S1(ti) and each sub-walk
(τkA−1k)2(cid:17) product where
corresponds to an f(cid:16)wti , 1 −

(τkA−1k)2(cid:17)···(cid:16)1 − θi(t)

θ = (θi) are the values at all the agents indexed by the

θ

walk wti and all the agents i = 1, 2,··· , n appear in the
walk wti at least once. Then each sub-part of the product
corresponding to the walk wti is denoted as

Πwti  1 −

θi(t)

(τkA−1k)2! = f wti , 1 −

θ

(τkA−1k)2!

θ

where the subscript wti denotes the consecutive product
corresponding to the walk wti . Furthermore each product
corresponding to a wti ∈ S1(ti) is bounded as
i=1 1 −
(τkA−1k)2!
f wti , 1 −
since we can always pick n agents i = 1, 2,··· , n in the
walk wti and keep their values unchanged and let all the left
θi = 0. Since (cid:16)1 − θi(t)

(τkA−1k)2! 6 Πn

θi

(τkA−1k)2(cid:17) > 0 (17) and
θl!n
l=1θl 6  1

n

n

Πn

Xl=1

holds when θl > 0. Therefore the kz(t) − x∗k2 is bounded
as

n

θ

θi

6Πr

6Πr

l=1Πn

kz(t) − x∗k2
i=1f wti , 1 −
6Πr
i=1 1 −
Xi=1  1 −
(√nτkA−1k)2!nr

(τkA−1k)2!kz(0) − x∗k2
(τkA−1k)2!kz(0) − x∗k2
(τkA−1k)2!!n
kz(0) − x∗k2,
i=1 θi = 1 by the Inequality Lemma 3.

l=1  1
= 1 −
where Pn
kAk·kA−1k is as follows. Since τ = max
full rank, then

θi

n

1

A loose bound given in terms of condition number κ(A) =
(kAik) and A is

i

kz(0) − x∗k2

τ = max

i

(kAik) < kAkF ,
i=1Pn

j=1 a2

where kAkF = qPn
ij is the Frobenius norm.
The scaled condition number [30] κs(A) = kAkFkA−1k
and the condition number κ(A) satisﬁes the following in-
equality 1 6

6 κ(A), then

κs(A)√n

√nτkA−1k < √nkAkFkA−1k 6 κ(A)

and therefore the loose bound is

kz(t) − x∗k2 <(cid:0)1 − κ(A)−2(cid:1)nr

This concludes the proof of Theorem 4.2.

kz(0) − x∗k2.

Remark 1: The f Bound Theorem 4.2 is important since
it also bounds the convergence rate of Kaczmarz’s algorithm
[31], which was not well solved in literature [32]. It gives a
tight bound in terms of matrix inverse kA−1k and a loose

bound in terms of condition number κ(A). The bounds
can be easily computed when the iterative sequence of
Kaczmarz’s algorithm is given, compared to the known
estimate [33]. Furthermore the f Bound Theorem 4.2 clearly
explains the reason that Kaczmarz’s algorithm is slower than
a randomized Kaczmarz’s algorithm [29], [32], [34].

Remark 2: With the help of f 0 Bound Theorem 4.1 and
f Bound Theorem 4.2, each product in the error updating
equation (10) can be divided into two parts and bounded
separately. One corresponding to the f product part where
r > 1 and all the 1 6 i 6 n are present and the other one
corresponding to the f 0 product part where not all 1 6 i 6 n
are present. We can now prove the Bound Theorem 3.5.

Proof: [Proof of Bound Theorem 3.5] Let f (wt, µij )
denote the corresponding µ product of the error sequence
(12) in (10), then according to the f 0 Bound Theorem 4.1 and
f Theorem 4.2 the error updating equation (10) is bounded
as follows

n

n

n

6

rm(t)

···

kyi(t + 1)k
6
Xl1=1
Xj=1

Xr=1 Xwt
Xj=1
Xj=1 Xwt
Xr=0 Xwt
Xj=1

ij∈S0(t)

ij∈Sr

rm(t)

+

=

n

n

ij∈Sr (t)

kµil1 ··· µlt−1lj Pi ··· Pj yj(0)k

2 kyj(0)k

) (1 − ϕ)

f (wt

1
d

ij,

nr

f (wt

ij ,

1
d

) (1 − ϕ)

0

2 kyj(0)k

f (wt

ij,

1
d

) (1 − ϕ)

nr

2 kyj(0)k

where µij = αij
di

. Hence the proof is ﬁnished.

The bound in (6) gives another proof that the distributed
algorithm studied in this paper converges to x∗ for connected
undirected networks, as shown below.

Discussion of the Algorithm Convergence

Note that the order of a wt walk typically increases as
the length of walks keeps growing, since G is a connected
network. This implies that for any given order r, the total
number of wt ∈ Sr(t) is limited and hence the summation
of all corresponding f (wt, 1
d ) products is bounded, for the
summation of all walks is 1 (8). The number of all walks
starting at vertex vi for any given order r and length t can
be estimated by combinatorics. This method is shown when
the network topology is a complete graph. For any given
network, the number of walks can be bounded similarly, but
it can become quite involved.

For any walk of length t starting at a ﬁxed vertex v0 in a
complete network G ∈ Rn×n, the total number of all walks
is nt. Let t ≫ n. In order to count the maximum number of
wt ∈ S0(t) walks, we ﬁrst choose subsets of vertices V 0
k ( V
by picking k 6 n − 2 vertices out of n and V 0
n−1 ( V by
picking n−1 vertices except the case v0 is not picked, which
results in walks in S1(t) space rather than S0(t). There are

n =

n of V 0

k sets where C k

n − 1 of V 0

k!(n−k)! , k 6 n − 2
a total C k
and C n−1
n−1 sets. Then we choose a vertex with
n−1 and put it into the
replacement each time from V 0
sequence of walks to generate all possible walks. The total
number c0(t) of w0(t) walks is

k and V 0

n!

c0(t) =

nkt − (n − 1)t .
C k

n−1

Xk=1

The wt ∈ S1(t) walks are regarded as combinations of wn ∈
S1(n) walks and wt−n ∈ S0(t− n) walks. We ﬁrst choose n
positions out of t in the sequences of walks and make these
n positions form wn ∈ S1(n) walks. There are C n
t ways to
n set and the number w1(n)
choose n vertices to form a V 1
walks is exactly n! for each set, so the number of different
sub-sequences in w1(t) walks is P n
t . The number
of walks w0(t − n) is simply c0(t − n). Hence the number
of w1(t) walks is bounded by

t = n!C n

c1(t) = P n

t c0(t − n).

In general cases where r > 2, we pick n positions out of
1,··· , t − (r − 1)n locations to form the ﬁrst wn ∈ S1(n)
walk sequence and pick the left-over locations till t−(r−2)n
to form the second wn ∈ S1(n) walk and so on. Let t1 denote
the start position and t2−1 be the end position picked out by
the ﬁrst wn ∈ S1(n) walk sequence, then the total number of
. Deﬁne t3,··· tr similarly, then the
sub-sequences is P n
second wn ∈ S1(n) walk sequence can pick from position
t2 till t3 − 1 in the original wt ∈ Sr(t) sequence. The total
number of sub-sequences for the second wn ∈ S1(n) walk
t3−t2. The total number of wr(t) walks is bounded by
is P n

t2−t1

cr(t) = Πr

i=1P n

ti+1−ti

c0 (t − rn) .

The number of total walks then satisﬁes

cr(t)
nt = lim
t→∞

trnc0(t − rn)
nrnnt−rn = 0

lim
t→∞
since c0(t−rn)
reduces exponentially to 0. This means for
nt−rn
any given order r, the corresponding walks account for only
a minor portion of all walks. In other words, the order of all
products keeps growing when the length of walks increases.

Since the summation of all f(cid:0)wt, 1

the limit of the portion of walks among all walks of a given
order rc is 0, therefore the following two limits exist

d(cid:1) products is 1 (8) and

lim
t→∞

ρ1 = lim
t→∞

lim
t→∞

ρ2 = lim
t→∞

n

n

Xj=1
Xj=1

rm(t)

ij∈Sr

rc

Xr=rc+1 Xwt
Xr=0 Xwt

ij∈Sr(t)

f (wt

ij , µ) = 1,

f (wt

ij , µ) = 0.

for any ﬁnite rc. Furthermore, the limit of the error in (3)
satisﬁes the following
t→∞kyi(t + 1)k
ρ1 (1 − ϕ)
6 lim
t→∞

2 kyj(0)k + lim
t→∞

ρ2 (1 − ϕ)

2 kyj(0)k

lim

nr

nr

=0,

where limt→∞ rm(t) = ∞. Therefore the algorithm con-
verges as all the limt→∞ xi(t) → x∗ for regular networks.
Future work will look to analyze the combinatorics of
more general network topologies.

V. CONCLUSIONS

In this work, we systematically study the impact of net-
work topology on the performance of a network-based dis-
tributed algorithm in solving linear algebraic equations. Both
theoretical analysis and simulation results show that net-
works with higher mean degree, smaller diameter, and more
homogeneous degree distribution make the algorithm con-
verge faster. Interestingly, k-regular random networks with
small mean degree could have a comparable performance as
degree-heterogeneous networks with very high mean degree.
Hence, it is possible to reduce the communication cost (i.e.
by designing sparser networks) and simultaneously keep the
fast convergence rate.

Besides classical consensus problems, we expect that more
complicated problems can also be solved with network-based
distributed algorithms. Our results presented here provide
a method to analyse the topology impacts on a network-
based distributed algorithm. It may shed light on the design
of better network topologies to improve the performance of
general multi-agent distributed algorithms in solving more
challenging real-world problems.

ACKNOWLEDGEMENT

This work was partially supported by the John Templeton

Foundation (award number 51977).

REFERENCES

[1] R. Pastor-Satorras and A. Vespignani, “Epidemic spreading in scale-
free networks,” Physical review letters, vol. 86, no. 14, p. 3200, 2001.
[2] R. Cohen, K. Erez, D. Ben-Avraham, and S. Havlin, “Resilience of
the internet to random breakdowns,” Physical review letters, vol. 85,
no. 21, p. 4626, 2000.

[3] T. Nishikawa, A. E. Motter, Y.-C. Lai, and F. C. Hoppensteadt,
“Heterogeneity in oscillator networks: Are smaller worlds easier to
synchronize?” Physical review letters, vol. 91, no. 1, p. 014101, 2003.
[4] W. Wang and J.-J. E. Slotine, “On partial contraction analysis for
coupled nonlinear oscillators,” Biological cybernetics, vol. 92, no. 1,
pp. 38–53, 2005.

[5] Y.-Y. Liu, J.-J. Slotine, and A.-L. Barab´asi, “Controllability of complex

networks,” Nature, vol. 473, no. 7346, pp. 167–173, 2011.

[6] A. Jadbabaie, N. Motee, and M. Barahona, “On the stability of the
kuramoto model of coupled nonlinear oscillators,” in American Control
Conference, 2004. Proceedings of the 2004, vol. 5.
IEEE, 2004, pp.
4296–4301.

[7] F. Pasqualetti, S. Zampieri, and F. Bullo, “Controllability metrics,
limitations and algorithms for complex networks,” Control of Network
Systems, IEEE Transactions on, vol. 1, no. 1, pp. 40–52, 2014.

[8] Y.-Y. Liu, J.-J. Slotine, and A.-L. Barab´asi, “Observability of complex
systems,” Proceedings of the National Academy of Sciences, vol. 110,
no. 7, pp. 2460–2465, 2013.

[9] T. Vicsek, A. Czir´ok, E. Ben-Jacob, I. Cohen, and O. Shochet, “Novel
type of phase transition in a system of self-driven particles,” Physical
review letters, vol. 75, no. 6, p. 1226, 1995.

[10] A. Jadbabaie, J. Lin, et al., “Coordination of groups of mobile
autonomous agents using nearest neighbor rules,” Automatic Control,
IEEE Transactions on, vol. 48, no. 6, pp. 988–1001, 2003.

[11] J. N. Tsitsiklis, “Problems in decentralized decision making and

computation.” DTIC Document, Tech. Rep., 1984.

[12] J. N. Tsitsiklis, D. P. Bertsekas, M. Athans, et al., “Distributed
asynchronous deterministic and stochastic gradient optimization al-
gorithms,” IEEE transactions on automatic control, vol. 31, no. 9, pp.
803–812, 1986.

[13] R. Olfati-Saber and R. M. Murray, “Consensus protocols for networks
of dynamic agents,” in Proceedings of the 2003 American Controls
Conference, 2003.

[14] R. Olfati-Saber, J. A. Fax, and R. M. Murray, “Consensus and
cooperation in networked multi-agent systems,” Proceedings of the
IEEE, vol. 95, no. 1, pp. 215–233, 2007.

[15] S. Mou and A. S. Morse, “A ﬁxed-neighbor, distributed algorithm for
solving a linear algebraic equation,” in Control Conference (ECC),
2013 European.

IEEE, 2013, pp. 2269–2273.

[16] S. Mou, “Distributed control of multi-agent systems,” Ph.D. disserta-

tion, YALE UNIVERSITY, 2014.

[17] J. Liu, S. Mou, and A. S. Morse, “An asynchronous distributed
algorithm for solving a linear algebraic equation,” in Decision and
Control (CDC), 2013 IEEE 52nd Annual Conference on.
IEEE, 2013,
pp. 5409–5414.

[18] B. Anderson, S. Mou, A. S. Morse, and U. Helmke, “Decentralized
gradient algorithm for solution of a linear equation,” arXiv preprint
arXiv:1509.04538, 2015.

[19] S. Mou, J. Liu, and A. S. Morse, “A distributed algorithm for solving
a linear algebraic equation,” IEEE Transactions on Automatic Control,
vol. 60, no. 11, pp. 2863–2878, 2015.

[20] H. Neudecker, “A note on kronecker matrix products and matrix
equation systems,” SIAM Journal on Applied Mathematics, vol. 17,
no. 3, pp. 603–606, 1969.

[21] G. Russo, M. Di Bernardo, and E. D. Sontag, “A contraction approach
to the hierarchical analysis and design of networked systems,” Auto-
matic Control, IEEE Transactions on, vol. 58, no. 5, pp. 1328–1331,
2013.

[22] M. Fiedler, “Algebraic connectivity of graphs,” Czechoslovak Mathe-

matical Journal, vol. 23, no. 2, pp. 298–305, 1973.

[23] F. R. Chung, Spectral graph theory. American Mathematical Soc.,

1997, vol. 92.

[24] R. Diestel, “Graph theory. 2005,” Grad. Texts in Math, 2005.
[25] D. J. Watts and S. H. Strogatz, “Collective dynamics of small-

worldnetworks,” nature, vol. 393, no. 6684, pp. 440–442, 1998.

[26] A.-L. Barab´asi and R. Albert, “Emergence of scaling in random

networks,” science, vol. 286, no. 5439, pp. 509–512, 1999.

[27] P. Erd˝os and A. R´enyi, “On the evolution of random graphs,” Publ.

Math. Inst. Hungar. Acad. Sci, vol. 5, pp. 17–61, 1960.

[28] N. C. Wormald, “Models of random regular graphs,” London Mathe-

matical Society Lecture Note Series, pp. 239–298, 1999.

[29] T. Strohmer and R. Vershynin, “A randomized kaczmarz algorithm
with exponential convergence,” Journal of Fourier Analysis and Ap-
plications, vol. 15, no. 2, pp. 262–278, 2009.

[30] J. W. Demmel, “The probability that a numerical analysis problem is
difﬁcult,” Mathematics of Computation, vol. 50, no. 182, pp. 449–480,
1988.

[31] S. Kaczmarz, “Angen¨aherte auﬂ¨osung von systemen linearer gleichun-
gen,” Bulletin International de lAcademie Polonaise des Sciences et
des Lettres, vol. 35, pp. 355–357, 1937.

[32] R. M. Gower and P. Richt´arik, “Randomized iterative methods for
linear systems,” SIAM Journal on Matrix Analysis and Applications,
vol. 36, no. 4, pp. 1660–1690, 2015.

[33] A. Gal´antai, “On the rate of convergence of the alternating projection
method in ﬁnite dimensional spaces,” Journal of mathematical analysis
and applications, vol. 310, no. 1, pp. 30–44, 2005.

[34] L. Dai, M. Soltanalian, and K. Pelckmans, “On the randomized
kaczmarz algorithm,” IEEE SIGNAL PROCESSING LETTERS, vol. 21,
no. 3, 2014.

