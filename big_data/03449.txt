6
1
0
2

 
r
a

M
9

 

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
9
4
4
3
0

.

3
0
6
1
:
v
i
X
r
a

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

A Practical Bias Estimation Algorithm for

Multisensor–Multitarget Tracking

Ehsan Taghavi, R. Tharmarasa and T. Kirubarajan
McMaster University, Hamilton, Ontario, Canada
Email: {taghave, tharman, kiruba}@mcmaster.ca

Yaakov Bar-Shalom

University of Connecticut, Storrs, Connecticut, USA

Email: ybs@ee.uconn.edu

Mike McDonald

Defence Research and Development Canada

Ottawa, Ontario, Canada

Email: mike.mcdonald@drdc-rddc.gc.ca

Abstract

Bias estimation or sensor registration is an essential step in ensuring the accuracy of global tracks in multisensor-multitarget
tracking. Most previously proposed algorithms for bias estimation rely on local measurements in centralized systems or tracks
in distributed systems, along with additional information like covariances, ﬁlter gains or targets of opportunity. In addition, it is
generally assumed that such data are made available to the fusion center at every sampling time. In practical distributed multisensor
tracking systems, where each platform sends local tracks to the fusion center, only state estimates and, perhaps, their covariances
are sent to the fusion center at non-consecutive sampling instants or scans. That is, not all the information required for exact
bias estimation at the fusion center is available in practical distributed tracking systems. In this paper, a new algorithm that is
capable of accurately estimating the biases even in the absence of ﬁlter gain information from local platforms is proposed for
distributed tracking systems with intermittent track transmission. Through the calculation of the Posterior Cram´er–Rao lower
bound and various simulation results, it is shown that the performance of the new algorithm, which uses the tracklet idea and
does not require track transmission at every sampling time or exchange of ﬁlter gains, can approach the performance of the exact
bias estimation algorithm that requires local ﬁlter gains.

Multitarget–multisensor tracking, registration, bias estimation, tracklets, distributed fusion.

Index Terms

I. INTRODUCTION

Bias estimation and compensation are essential steps in distributed tracking systems. The objective of sensor registration is
to estimate the biases in sensor measurements, such as scaling and offset biases in range and azimuth measurements of a radar,
clock bias and/or uncertainties in sensor positions [1]. In a distributed multisensor tracking scenario, each local tracker provides
its own estimates of target states for fusion. Local ﬁlters can be, e.g., Kalman ﬁlters or Interacting Multiple Model (IMM)
estimators with different motion models. These local tracks, i.e., state estimate vectors and associated covariance matrices, are
sent to the fusion center for further processing. Next, the fusion center carries out track–to–track fusion. The fusion is done
sequentially subsequent to the estimation of biases based on common targets that are tracked by various sensors in different
locations.

Usually, bias estimation is considered as a two–sensor problem [2], [3] where a stacked vector is assumed with all unknown
biases and states target. A drawback of this approach is the computational burden due to increased dimension of the stacked
vector. In addition, most of the algorithms proposed for estimating the biases operate on the measurements directly [4]. That
is, such methods perform ﬁltering on the measurements received from sensors, which also include the biases. In many practical
tracking systems, access to measurements before tracking at the sensor level is not always feasible. That is, sensors may provide
only processed tracks to the user for further processing [1]. Thus, methods that can simultaneously handle track–to–track fusion
and bias estimation are needed.

Although there are many different methods in the literature for bias estimation and compensation, there is still a need for a
method that requires only the local track estimates and associated covariance matrices for bias estimation. In [5] and [6] a joint
track-to-track bias estimation and fusion algorithm based on equivalent measurements of the local tracks was proposed. In [7],
another approach based on pseudo-measurement along with the Expectation-Maximization (EM) algorithm to perform joint
fusion and registration was proposed. A different method that uses a multistart local search to handle the joint track-to-track
association and bias estimation problem was introduced in [8]. The concept of pseudo-measurement was used in [9] for exact

Yaakov Bar–Shalom was supported by ARO Grant W991NF–10–1–0369.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

bias estimation with further extensions in [10] and [11]. In order to achieve exact bias estimation, the algorithms in [9]–[11]
require the Kalman gains from local trackers, which are not normally sent to the fusion center in practical systems [12].
Moreover, the previously mentioned algorithms assumed that the fusion center receives the local tracks from all sensors at
every time step, which is not realistic in systems with bandwidth limitations [13]. In addition, these methods require perfect
knowledge about each local ﬁlter and its dynamic model. Also, as the number of sensors increases, the bias estimation problem
suffers from the curse of dimensionality because of the commonly used stacked bias vector implementation [2]. Finally, as the
number of sensors changes over time, the algorithms in [9]–[11] require appropriate pseudo–measurement to be deﬁned for
the speciﬁc number of sensors.

In this paper, these issues are addressed and a practical solution, which is mathematically sound and computationally feasible,
is presented. The new approach is based on reconstructing the Kalman gains of the local trackers at the fusion center. In this
approach, the tracklet method [12], [14], [15] along with sequential update as a fusion method is used to provide a low
computational cost algorithm for bias estimation. Also, some of the constraints that were discussed above are relaxed in the
proposed algorithm. The main contributions of the new algorithm are: a) reconstruction of Kalman gains at the fusion center,
b) relaxing the constraints on receiving local tracks at every time step, c) correcting local tracks at the fusion center and d)
providing a fused track with low computational cost.

The paper is structured as follows: The bias model and the assumptions for bias estimation are discussed in Section II. In
Section III, a review of the exact bias estimation method [9]–[11] is given. The new approach and its mathematical developments
are given in Section IV. Section V presents the calculation of the Cram´er–Rao Lower Bound (CRLB) for proposed algorithm.
Section VI demonstrates the performance of the new algorithm for synchronous sensors and compares it with that of the
method in [9] and shows comparisons with the CRLB. Conclusions are discussed in Section VII.

II. PROBLEM FORMULATION

Assume that there are M sensors reporting range and azimuth measurements1 in polar coordinates of N targets in the
common surveillance region. Note that N is not exactly known to the algorithm and that it could be time varying. That is,
bias estimation is carried out based on time–varying and possibly erroneous numbers of tracks reported by the local trackers.
The model for the measurements originating from a target with biases at time k in polar coordinates (denoted by superscript
p) for sensor s is [9]–[11]

(cid:20) rp

(cid:21)

zp
s (k) =

s (k)
θp
s (k)

=

(cid:20) [1 + r
(cid:2)1 + θ

s(k)(cid:3) θs(k) + bθ

s(k)] rs(k) + br

(cid:21)

s(k) + wr
s(k) + wθ

s(k)
s (k)
s(k) and bθ

s = 1, . . . , M

(1)

where rs(k) and θs(k) are the true range and azimuth, respectively, br
azimuth, respectively, r
wr
mutually independent.

s(k) are the offset biases in the range and
s(k) are the scale biases in the range and azimuth, respectively. The measurement noises
θ, respectively, and are assumed

s (k) in range and bearing are zero-mean with corresponding variances σ2

s(k) and wθ

s(k) and θ

The bias vector βs(k) =(cid:2) br

s(k)

bθ
s(k)

r
s(k)

θ

of scans (non–random variable). Consequently, the maximum likelihood (ML) estimator [16] or the weighted least squares
(LS) estimator [17] can be used for bias estimation. On the other hand, a Gauss-Markov random model [18] can also be used,
in which case a Kalman ﬁlter can be adopted for bias estimation. We model the measurement as

r and σ2

s(k) (cid:3)T can be modeled as an unknown constant over a certain window
(cid:20) rs(k)
(cid:21)
(cid:20) 1

(cid:20) wr
(cid:21)

+ Cs(k)βs(k) +

s(k)
s (k)

θs(k)

(cid:21)

(2)

wθ

rs(k)

0

(cid:52)
=

Cs(k)

0
1

0

0

θs(k)

where

zp
s (k) =

Here, the measured azimuth θm

s (k) can be utilized in (3) without any signiﬁcant loss of performance [9]–[11].
Estimating the bias vector βs(k) for all the sensors is the main objective of this paper. After bias estimation, all the biases

s (k) and range rm

can be compensated for in the state estimates at the fusion center.

Since target motion is better modeled and most trackers operate in Cartesian coordinates, the polar measurements are
converted into Cartesian coordinates. It is assumed that this does not introduce biases [19]; this is veriﬁed in the simulations.
Then, sensor s has the measurement equation (with the same Hs(k) = H(k) for all s)

where the state vector x(k) =(cid:2) x(k)

˙x(k)

y(k)

zs(k) = H(k)x(k) + Bs(k)Cs(k)βs(k) + ws(k)

˙y(k) (cid:3)T and H(k) is the measurement matrix given by
(cid:20) 1

(cid:21) (cid:52)

H(k) =

0
0

0
1

0
0

0

= H

(3)

(4)

(5)

1While this assumes 2–D radars, the extension to 3–D radars is straightforward.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Since distributed tracking systems may cover a large geographical area, the earth can no longer be assumed to be ﬂat and
coordinate transformations need to include an earth curvature model like WGS-84 [20], [21].

The matrix Bs(k) is a nonlinear function with the true range and azimuth as its arguments. A constant Bs(k)Cs(k) also
s (k) from sensor s,

results in incomplete observability as discussed in [11]. Using the measured azimuth θm
Bs(k) can be written as [19]

s (k) and range rm

(cid:20) cos θm

sin θm

Bs(k) =

s (k) −rm
s (k) sin θm
rm
s (k) cos θm
s (k)

s (k)
s (k)

(cid:21)

(6)

(7)

Finally, the new covariance matrix of the measurement in Cartesian coordinates (omitting index k in the measurements for
clarity) is given by

(cid:18) r2
(cid:0)σ2

(cid:1) sin θs cos θs

r cos2 θs

θ sin2 θs + σ2
sσ2
r − r2

sσ2
θ

(cid:0)σ2

(cid:1) sin θs cos θs

r sin2 θs

r − r2
r2
sσ2
θ cos2 θs + σ2

sσ2
θ

(cid:19)

Rs(k) =

where one can use the observed range and azimuth as well.

III. REVIEW OF SYNCHRONOUS SENSOR REGISTRATION

In this section, the bias estimation method introduced in [9]–[11] for synchronous sensors with known sensor locations is
reviewed. Further, the methods in our previous work [22] are examined in more detail and are extended in this paper with
various simulations and the calculation of the lower bounds for bias estimation in multisensor–multitarget scenarios.

Consider a multisensor tracking system with the decentralized architecture [1]. In this case, each local tracker runs its own
ﬁltering algorithm and obtains a local state estimate using only its own measurements. Then, all local trackers send their
estimates to the fusion center where bias estimation is addressed. Only after bias estimation can the fusion center fuse local
estimates correctly to obtain accurate global estimates.

The dynamic equation for the target state is

x(k + 1) = F (k)x(k) + v(k)

(8)

where F (k) is the transition matrix, and v(k) is a zero-mean additive white Gaussian noise with covariance Q(k).

Because the local trackers are not able to estimate the biases on their own, they yield inaccurate estimates of tracks by
assuming no bias in their measurements. Hence, the state space model considered by local trackers for a speciﬁc target t and
sensor s is

xt(k + 1) = F (k)xt(k) + v(k)

zt
s(k) = H(k)xt(k) + ws(k)

(9)
(10)

The difference between (1) and (10) is that the latter has no bias term and, as a result, the local tracks are bias-ignorant
[9]–[11]. Note that this mismatch should be compensated for.

A. The pseudo-measurement of the bias vector

In this subsection, a brief discussion on how to ﬁnd an informative pseudo-measurement by using the local tracks for the case
M = 2 synchronized sensors is presented, based on the method given in [9]–[11]. As in these previous works, it is assumed
that the local platforms run a Kalman ﬁlter-based tracker, although this assumption may not always be valid. However, as
shown in the sequel, multiple-model based trackers can be handled within the proposed framework with some extensions.

In [9]–[11] it was assumed that one has access to the ﬁlter gain W1(k + 1) and the residual ν1(k + 1) from the Kalman

ﬁlter of local tracker 1 [23]. Then, one can write

ˆx1(k + 1 | k + 1) = F (k)ˆx1(k | k) + W1(k + 1)ν1(k + 1)

= F (k)ˆx1(k | k) + W1(k + 1)(cid:2)z1(k + 1) − ˆz0

1(k + 1 | k)(cid:3)

= [I − W1(k + 1)H(k + 1)] F (k)ˆx1(k | k) + W1(k + 1) [H(k + 1)

F (k)x1(k) + H(k + 1)v(k) + B1(k + 1)C1(k + 1)β1(k + 1)
(11)
+w1(k + 1)]
1(k + 1 | k) is based on the measurement in which no bias is assumed by local
Note that the predicted measurement ˆz0
tracker 1, i.e., tracker 1 used a bias-ignorant measurement model. Therefore, there is no term related to biases in the predicted
measurement.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Hence, if the local state estimate is moved to the left–hand side of (11), and left-multiplied by the left pseudo-inverse [24]

of the gain, one has

b (k + 1) (cid:44) W
z1

†
1 (k + 1) [ˆx1(k + 1 | k + 1)− (I − W1(k + 1)H(k + 1))F (k)ˆx1(k | k)]

= H(k + 1)F (k)x(k) + H(k + 1)v(k) + B1(k + 1)C1(k + 1)β1(k + 1)

where the pseudo-inverse of the gain is

+w1(k + 1)

(cid:44) (cid:0)W T

s Ws

(cid:1)−1

W T
s

W †

s

Similarly, one can deﬁne

b (k + 1) (cid:44) W
z2

†
2 (k + 1) [ˆx2(k + 1 | k + 1) − (I − W2(k + 1)H(k + 1))F (k)ˆx2(k | k)]

= H(k + 1)F (k)x(k) + H(k + 1)v(k) + B2(k + 1)C2(k + 1)β2(k + 1)

+w2(k + 1)

(12)

(13)

(14)

It is worth mentioning that x(k) and v(k) in (12) and (14) are the same. Thus, a pseudo-measurement of the bias vector, as
in [9]–[11], can be deﬁned as follows:

zb(k + 1) (cid:44) z1

b (k + 1) − z2

b (k + 1)

for the case of using similar sensors. Then,

zb(k + 1) = B1(k + 1)C1(k + 1)β1(k + 1) − B2(k + 1)C2(k + 1)β2(k + 1)

+w1(k + 1) − w2(k + 1)

(15)

(16)

That is, one has the pseudo-measurement of the bias vector

(17)
where the pseudo-measurement matrix H, the bias parameter vector b and the pseudo-measurement noise ˜w(k + 1) are deﬁned
as

zb(k + 1) = H(k + 1)b(k + 1) + ˜w(k + 1)

H(k + 1) (cid:44) [B1(k + 1)C1(k + 1), −B2(k + 1)C2(k + 1)]

(cid:21)

(cid:20) β1(k + 1)

β2(k + 1)

b(k + 1) (cid:44)

and

˜w(k + 1) (cid:44) w1(k + 1) − w2(k + 1)

The bias pseudo-measurement noises ˜w are additive white Gaussian with zero–mean, and their covariance is

R(k + 1) = R1(k + 1) + R2(k + 1)

(18)

(19)

(20)

(21)

The main property of (20) is its whiteness, which results in a bias estimate that is exact [9]–[11]. In this approach, there
is no approximation in deriving (17)–(21) unlike the methods previously proposed in [25]–[27]. This was one of the main
contributions of [9].

When the measurement matrices Hs(k) are the same for different local trackers, but only the second sensor has a bias, the

following simpliﬁcations result:

b (k + 1) − z2

b (k + 1)

zb(k + 1) = z1
b(k + 1) = β2(k + 1)
H(k + 1) = −B2(k + 1)C2(k + 1)
˜w(k + 1) = w1(k + 1) − w2(k + 1)
R(k + 1) = R1(k + 1) + R2(k + 1).

(22)
(23)
(24)
(25)
(26)

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Input: ˆb0(k), Σ0(k), z1
b,t(k), z2
Output: ˆb0(k + 1), Σ0(k + 1)
1: At time k
2: for t = 1, ..., N do
3:

b,t(k)

Get the new pseudo-measurement using

4:

5:

zb,t(k) (cid:44) z1

b,t(k) − H(k)H†(k)z2

b,t(k)

Gt(k) = Σt−1(k)Ht(k)T(cid:2)Ht(k)Σt−1(k)Ht(k)T Rt(k)]

−1

Compute the bias update gain and the residual

rt(k) = zb,t(k) − Ht(k)ˆbt−1(k + 1)

Update the bias estimate and covariance

ˆbt(k) = ˆbt−1(k + 1) + Gt(k)rt(k)

Σt(k) = Σt−1(k) − Σt−1(k)Ht(k)T)T [Ht(k) Σt−1(k)Ht(k)T + Rt(k)(cid:3)−1 Ht(k)Σt−1(k)

6: end for
7: return

ˆb0(k + 1) (cid:44) ˆbN (k)
Σ0(k + 1) (cid:44) ΣN (k)

Fig. 1: The Recursive Least Square Bias Estimation (RLSBE) algorithm [9].

B. The recursive least square bias estimator

If the biases are constant over a certain window of scans, one can construct a Recursive Least Square (RLS) estimator by
using the pseudo-measurement equation (17) [9]. The recursion of the RLS estimator has two stages: the ﬁrst is to update the
bias estimate recursively for different targets and the second is to update it through different time scans.
Assume that at time k, one has access to the estimate of the bias vector and its associated covariance matrix up to time k
as ˆbt−1(k) and Σt−1(k), form on the ﬁrst t − 1 targets and all previously updated estimates. Now, the RLS method can be
carried out as in Figure 1 to update the bias estimation at time k for all targets [9]–[11].

Note that the covariance update equation in line 5 of Figure 1 may cause Σt(k) to lose positive deﬁniteness due to numerical

errors. To avoid this problem, the Joseph’s form of the covariance update is used [19] as

Σt(k) = [I − Gt(k)Ht(k)] Σt−1(k) [I − Gt(k)Ht(k)]T + Gt(k)Gt(k)T

(27)

C. Time-varying bias estimation: The optimal MMSE estimator

In the case of time-varying biases with the standard linear white–Gaussian assumptions one can implement the optimal
MMSE estimator based on the pseudo-measurement equation (17) and the dynamic model of the bias [9]. f For the stacked
bias vector, the dynamics model can be deﬁnes as

b(k + 1) = Fb(k)b(k) + vb(k)

(28)
in which Fb(k) is the transition matrix of the stacked bias vector b, and vb(k) is the stacked process noise of the bias vector,
zero-mean white with covariance Qb(k).
Assume that at time k one has access to the estimate of the bias vector and its associated covariance matrix up to time k
as ˆbt−1(k | k) and Σt−1(k | k), respectively. Now, a Kalman ﬁlter can be used as in Figure 2 to update the bias estimates at
time k for all targets [9]–[11].

IV. THE NEW BIAS ESTIMATION ALGORITHM

The algorithms given in Section III, i.e., Recursive Least Square Bias Estimation (RLSBE, Figure 1) and Optimal MMSE
Bias Estimation (OMBE, Figure 2), are dependent on the Kalman gains provided by the local trackers, in addition to the
state estimates and the associated covariance matrices at every time step. Moreover, as the number of the sensors increases,
the above algorithms face an increase in computational requirements cubic in M. This is because a stacked vector of bias
parameters is used. In addition, for M > 2, it is challenging to extend (15) and (17). The extension of (15) and (17) can be

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Input: ˆb0(k | k), Σ0(k | k), z1
Output: ˆb0(k + 1 | k + 1), Σ0(k + 1 | k + 1)
1: At time k
2: for t = 1, ..., N do
3:

Get the new pseudo-measurement using

b,t(k), z2

b,t(k)

zb,t(k) (cid:44) z1

b,t(k) − H(k)H†(k)z2

b,t(k)

4:

Compute the bias update gain and the residual

Gt(k) = Σt−1(k | k)Ht(k)T [Ht(k)Σt−1(k | k)

Ht(k)T + Rt(k)]

−1

rt(k) = zb,t(k) − Ht(k)ˆbt−1(k | k)

5:

Update the bias estimate and covariance

ˆbt(k | k) = ˆbt−1(k | k) + Gt(k)rt(k)
Σt(k | k) = Σt−1(k | k) − Σt−1(k | k)Ht(k)T

(cid:2)Ht(k)Σt−1(k | k)Ht(k)T +Rt(k)]

−1 Ht(k)Σt−1(k | k)

6: end for
7: Update the bias estimate according to the model

ˆb(k + 1 | k) (cid:44) Fb(k)ˆbN (k | k)
Σ(k + 1 | k) (cid:44) Fb(k)ΣN (k | k)Fb(k)T + Qb(k)

8: return

ˆb0(k + 1 | k + 1) = ˆb(k + 1 | k)
Σ0(k + 1 | k + 1) = Σ(k + 1 | k)

Fig. 2: The optimal MMSE bias estimation algorithm [9] (OMBE).

done as in [28] by taking M − 1 differences. Moreover, these approaches do not address the joint fusion problem as well.
With this motivation, in this section, a new approach to relax the requirement of the Kalman gain matrices availability from
the local trackers is given. In addition, the new algorithm alleviates the problem of the dimensionality by taking advantage of
(22)–(26) for a multisensor–multitarget scenario, and by solving the fusion problem as well. Finally, the algorithm is able to
function properly with asynchronous local track updates.

In order to obtain the new algorithm, ﬁrst, a simple approach to calculate tracklets based on [12] is discussed. This approach
makes it possible to obtain approximate equivalent measurements of the local tracks directly and efﬁciently without any
further processing and it supports updating the bias estimates whenever a new local track is available at the fusion center. In
addition, it can handle asynchronous updates from different local trackers and map them to a common time [12], [15]. Then, a
sequential update algorithm is proposed for the fusion step. Although it is not an optimal approach for fusing the local tracks,
it is computationally cheaper than parallel update [1]. Finally, the complete algorithm based on these two approaches with
additional steps is presented.

A. Equivalent measurement computation using the inverse Kalman ﬁlter method based tracklet

The main goal in this subsection is to construct a set of approximately uncorrelated equivalent measurements (“tracklets”)
from the local tracks and the associated covariance matrices for sequential update in the fusion step and also to reconstruct
the local Kalman gains at the fusion center. It also relaxes the requirements of receiving the local tracks at every time step.
To do so, the “inverse Kalman ﬁlter based” tracklet method from [12] is used (for a clear derivation and the reason for its
suboptimality, see [1, p. 577]). Based on this method, the equations relating to the equivalent measurement vector, us(k, k(cid:48)),
for a local track from platform s at time frame k, given that the track data was previously sent to the global tracker for time
frame k(cid:48) < k, are as follows:

us(k, k(cid:48)) = ˆxs(k | k(cid:48)) + As(k | k(cid:48)) [ˆxs(k | k) − ˆxs(k | k(cid:48))]

(29)

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

where

where Zk(cid:48)

s =

(cid:110)

s, ..., zk(cid:48)
z1

s

(cid:111)

, and

E(cid:104)
˜us(k, k(cid:48)) | Zk(cid:48)(cid:105)

= 0

us(k, k(cid:48)) = x(k) + ˜us(k | k)

−1
As(k, k(cid:48)) = Ps(k | k(cid:48)) [Ds(k, k(cid:48))]
Ds(k, k(cid:48)) = Ps(k | k(cid:48)) − Ps(k | k)

Us(k, k(cid:48)) = E(cid:104)

˜us(k, k(cid:48)) (˜us(k, k)(cid:48))T | Zk(cid:48)

s

= As(k, k(cid:48))Ps(k | k)
= [As(k, k(cid:48)) − I] Ps(k | k(cid:48))

(cid:105)

(30)
(31)

(32)
(33)

(34)

The information that the global tracker or the fusion center uses consists of the calculated equivalent measurement vector
us(k, k(cid:48)) and its error covariance matrix Us(k, k(cid:48)). Note that in order to calculate ˆxs(k | k(cid:48)) and Ps(k | k(cid:48)) one needs the
estimated target state ˆxs(k(cid:48) | k(cid:48)) and its covariance matrix Ps(k(cid:48) | k(cid:48)), in addition to the dynamic models the local trackers
used for ﬁltering. Then one needs to compute L = k− k(cid:48) prediction steps without any new measurement data to ﬁnd ˆxs(k | k(cid:48))
and Ps(k | k(cid:48)). Here, it is necessary to consider the L-step prediction of transition and process noise covariance matrices
as F (k, k(cid:48)) and Q(k, k(cid:48)), respectively. One can use the concept of missing observations in Kalman ﬁlter to ﬁnd F (k, k(cid:48))
and Q(k, k(cid:48)) as in [29, pp. 110]. It should be mentioned that all these computations require that Ps(k(cid:48) | k(cid:48)), Ps(k | k(cid:48))

and (cid:2)Ps(k | k)−1 − Ps(k | k(cid:48))−1(cid:3) be non-singular. This method was previously used in [6] for k(cid:48) = k − 1 (for which the

non-singularity requirement does not hold in general) and with a different approach for sensor registration. For the proof of
(34) see Appendix A.

B. Sequential update as fusion method

After calculating the equivalent measurements of the state for each local track at the fusion center, they can be used as new
measurements for the estimation of fused state and its covariance matrix. To do this recursively, it should be assumed that the
fused state estimate and its covariance matrix at time k(cid:48) as xf (k(cid:48) | k(cid:48)) and Pf (k(cid:48) | k(cid:48)), respectively, are already computed.
For k(cid:48) = 1, the parameters xf (k(cid:48) | k(cid:48)) and Pf (k(cid:48) | k(cid:48)) are initialized with x(k(cid:48) | k(cid:48)) and P(k(cid:48) | k(cid:48)), respectively. Then these
two can be updated by following the steps in Figure 3. Although the sequential update is sub-optimal [1], it has the advantage
of being computationally efﬁcient to implement and, in addition, it is not dependent on the previous equivalent measurements
at time k(cid:48).

C. Multisensor fusion and track-to-track bias estimation

The ﬁrst step for implementing a general bias estimation algorithm for radar systems is to ﬁnd the Kalman gains of each
local track at the fusion center, by only using the state estimates and the associated covariance matrices. To do so, ﬁrst, one
must calculate the equivalent measurement and its covariance matrix as in (29) and (34) for sensor s, and at time frame k (the
target index is omitted for simplicity). Since the measurement model here is linear, one has

Rs,k = H(k)Us(k, k(cid:48))H(k)T

Ws,k = Ps(k | k(cid:48))H(k)T(cid:2)H(k)Ps(k | k(cid:48))H(k)T +Rs,k]

ys,k = H(k)us(k, k(cid:48))

−1

(35)
(36)
(37)

Note that the reason to keep the position information only is that further in the new bias estimation algorithm we use the
corrected positions as new measurements for sequential fusion. Because the equivalent measurements are used for the fused
track, the Kalman gain for it (denoted by subscript f) at time frame k can be recovered as

(cid:34) M(cid:88)

i=1

(cid:35)−1

Rf,k = H(k)

Wf,k = Pf (k | k(cid:48))H(k)T(cid:2)H(k)Pf (k | k(cid:48))H(k)T +Rf,k]

(Ui(k, k(cid:48)))

H(k)T

−1

−1

(38)

(39)

Note that the noises/errors in the equivalent measurements are not white so using a Kalman ﬁlter is not optimal. This amounts
to the same approximation as in [1, p. 563]. Also in (39), a common coordinate system is used for equivalent measurements.
As a result, the use of a common measurement matrix H(k) for all the equivalent measurements is feasible.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Input: xf (k(cid:48) | k(cid:48)) and Pf (k(cid:48) | k(cid:48)), ys,k and Rs,k for s = 1, ..., M
Output: xf (k | k) and Pf (k | k)
1: Compute xf (k | k(cid:48)) and Pf (k | k(cid:48)) according to their dynamic model (prediction step)
2: Assign:

xtemp = xf (k | k(cid:48))
Ptemp = Pf (k | k(cid:48)).

3: for s = 1, ..., M do
4:

Update xtemp and Ptemp with new measurement and its covariance matrix, i.e., ys,k and Rs,k according to

xtemp = xtemp + Wtemp ˜y

Wtemp = PtempH T(cid:0)HPtempH T + Rs,k

(cid:1)−1

˜y = ys,k − Hxtemp

Ptemp = (I − WtempH) Ptemp

(cid:21)

(cid:20) 1

0

0
0

0
1

0
0

5: end for
6: return

H =

xf (k | k) = xtemp
Pf (k | k) = Ptemp

Fig. 3: The Sequential Fusion Algorithm (SFA) with equivalent measurements

The sensor registration method proposed here uses the simpliﬁed formulas, i.e., (22)–(26). To use these formulas, an
approximately bias-compensated2 fused track needs to be found at the fusion center for the set {S}\ s, where S = 1, 2, ..., M.
The notation {S} \ s stands for the set that contains all those elements of S excluding element s. Then, the bias estimation
problem can be reduced to the case of two sensors. The ﬁrst one is an equivalent sensor with fusion of bias-corrected
measurements of the set {S}\ s, and the second is sensor s which has bias. Then the bias in sensor s can be found with either
the RLSBE (see Figure 1) or OMBE (see Figure 2) algorithm.

The next step in this approach is to correct the biases in the measurement domain of the sensors (except for sensor s) and
then fuse them together. This can be done by going from the Cartesian coordinate of equivalent measurements to the polar
coordinate of the radar and correct with the previously estimated biases. Then by correcting the covariance matrix of the new
bias compensated measurements, they can be fused by sequentially updating the fused track (excluding the track from sensor
s) by using the Sequential Fusion Algorithm (SFA). Then, the Kalman gain for the fused and the now-corrected track can be
calculated using (39).

For the equivalent measurement, deﬁne

where time and target indexes are omitted for simplicity. Then, to correct the biases in the measurement domain, assuming
that the latest–estimated biases are ˆθ, ˆr, ˆbθ and ˆbr, one has3

Now that the scale and offset biases are compensated for, one can go back to Cartesian coordinates as follows:

2Here, bias-compensated means a fused track, in which the bias-corrected equivalent measurements by using the latest estimated biases are used for fusion.
3Here, the superscript “b-c” is used to denote the bias-corrected bearing and range.

us (cid:44) (cid:2) ux

(cid:3)T

˙ux uy

˙uy

(cid:16) uy

ux

(cid:17) − ˆbθ

arctan

(cid:113)

(1 + ˆθ)

(ux)2 + (uy)2 − ˆbr

θb-c
s

=

rb-c
s

=

(1 + ˆr)

(cid:1)
cos(cid:0)θb-c
(cid:1)
sin(cid:0)θb-c
(cid:3)T

s
ub-c

s

y

s

ub-c
x
ub-c
y

= λθrb-c
= λθrb-c

Y b-c = (cid:2) ub-c

s

x

(40)

(41)

(42)

(43)
(44)
(45)

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

where

(cid:19)

(cid:18)

− σ2
θ
2

λθ = exp

(46)

is the compensation factor for the bias in coordinate conversion from polar to Cartesian [30]. The method from [30] is used here
because of the fact that bias correction and compensation along with the changes in the covariance matrices and uncertainties
may violate the assumptions made for the debaised conversion in Section II. The next step is to update the covariance matrix of
the corrected equivalent measurements. In addition to the term (35), the additional uncertainty in the bias estimates, i.e., their
associated covariance matrix and the uncertainty in the model of the radar, both in Cartesian coordinates, must be accounted
for. The ﬁnal formula for the covariance matrix with proper conversion from polar to Cartesian coordinate is

(cid:20) σ2

r
0

(cid:21)

0
σ2
θ

Bb-c

s

(k)T

(47)

Rb-c

s

where

= H(k)Us(k | k)H(k)T + Bb-c
(k)T

(k)Pb,s(k | k)K b-c

+K b-c

s

s

s

(k)

(48)
and Pb,s(k | k) is the latest-updated bias covariance matrix at time k and for sensor s. Now that all the required formulations
and variables are available, the new algorithm to ﬁnd the bias estimates for all the sensors is given in Figure 4.

(k) = Bb-c

(k)C b-c

K b-c

(k)

s

s

s

Input: inputs of SFA and RLSBE (deﬁned within the corresponding algorithms).
Output: bs(k) and Σs(k) for s = 1, ..., M.
1: At time k
2: for s = 1, ..., M do
3:
4:

Compute Ws,k as in (36) and

†
s,k [ˆx(k | k) − (I − Ws,kHs(k))F (k, k − L)ˆx(k − L | k − L)]

f (k(cid:48) | k(cid:48)) and Ps

f (k(cid:48) | k(cid:48)), Y b-c

¯s

(k | k) and Rb-c

¯s (k | k).

f (k | k) − (I − W s

f,kHf (k))F (k, k − L)ˆxs

f (k − L | k − L)(cid:3)

b,t(k) (cid:44) W
zs
¯s ∈ {1, ..., M}\s
Call SFA with inputs xs
Compute W s

f,k as in (39) and

b,f (k) (cid:44) (cid:0)W s

zs

f,k

(cid:1)†(cid:2)ˆxs

5:
6:
7:

8:

matrix.

9:
10: end for

return bs(k) and Σs(k)

Call RLSBE with inputs zs

b,t(k), zs

b,f (k) and the last update of the estimated biases and their associated covariance

Fig. 4: The Fused Bias Estimation algorithm (FBEA)

As shown in Figure 4, one only needs to call SFA and RLSBE with new input parameters. One of the advantages of this
approach is that in each “for loop” only a low dimensional Kalman ﬁlter that is independent of the size of the stacked bias
vector and number of the sensors is needed. In addition, the fusion of local tracks can be done by only adding one sequential
update for the latest corrected measurement of sensor s to the previously fused track. It is also important to note that the
there is no constraint on the rate of receiving local tracks from the individual sensors. To show how well this new algorithm
performs, in the next section, the simulation results on two different scenarios are used to compare its performance with those
of the previously proposed algorithm in [9]–[11] for synchronous sensors.

To better illustrate how the new bias estimation algorithm (FBEA) works, a block–diagram representation of the method is
shown in Figure 5 for a single time step estimation of the biases for the ﬁrst sensor. In Figure 5, by receiving the local track
estimates from all available sensors at time step k, the ﬁrst step is to calculate the tracklet for all of them using (29)–(34).
Then, the equivalent measurement of the ﬁrst sensor is sent for Kalman gain recovery using (35) and (36). At the same
time, the equivalent measurements of all other sensors are sent to bias correction to ﬁrst remove the bias from the equivalent
measurements by using the previously estimated biases at time step k − 1 using (41)–(45) and the Kalman gain recovery in
(38) and (39). The next step is to fuse the tracks by using SFA algorithm. Then, the fused and corrected estimate is sent to the
pseudo–measurement calculation block for each individual sensor. At this point one has a two–sensor problem with only one
sensor having biases in the measurement. The output is now sent to the RLSBE algorithm along with the previously estimated
biases for the ﬁrst sensor so that the bias estimates can be updated at time step k before proceeding to the next time step.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 5: Block diagram of the new offset and scaling bias estimation algorithm.

V. CRAM ´ER-RAO LOWER BOUND FOR SENSOR REGISTRATION

In this section, a step-by-step procedure is given for calculating the CRLB for sensor registration algorithms as the benchmark.

Rewriting (4) for the case of two similar sensors, one has

and

z1(k) − H(k)x(k) = B1(k)β1(k) + w1(k)

z2(k) − H(k)x(k) = B2(k)β2(k) + w2(k)

If no biases exist, the sensors must point to the same position of the observed target. Consequently, one has

and by reordering the measurement terms and using the matrix form, one can rewrite it as

z1(k) − B1(k)β1(k) − w1(k) = z2(k) − B2(k)β2(k) − w2(k)

[z1(k) − z2(k)] =(cid:2) B1(k) −B2(k) (cid:3)(cid:20) β1(k)

(cid:21)

β2(k)

+ w1,2(k)

Further, for future use, one can denote the terms in (52) as

Y (k) = B(k)b(k) + w1,2(k)

where

Y (k) = [z1(k) − z2(k)]

B(k) = (cid:2) B1(k) −B2(k) (cid:3)

(cid:21)

(cid:20) β1(k)

β2(k)

b(k) =

(49)

(50)

(51)

(52)

(53)

(54)
(55)

(56)

and w1,2(k) is additive white Gaussian noise with covariance matrix equal to R1(k) + R2(k)

A. Calculation of the CRLB

In the case of having two sensors and multiple targets, the CRLB can be calculated as a batch process. Taking all the (linearly

independent) K pairs of measurements for N targets in the surveillance region, one can write the measurement equation as

where Y, g and u are stacked vectors given by

(cid:104) (cid:0)Y 1(1)(cid:1)T ···
(cid:104) (cid:0)B1(1)(cid:1)T ···

Y =

g =

Y = gb + u

(cid:0)Y N (1)(cid:1)T ···
(cid:0)BN (1)(cid:1)T ···

(cid:0)Y 1(K)(cid:1)T ···
(cid:0)B1(K)(cid:1)T ···

(cid:0)Y N (K)(cid:1)T (cid:105)T
(cid:0)BN (K)(cid:1)T (cid:105)T

(57)

(58)

(59)

Sensor 1 Sensor 2 Sensor M Tracklet Calculation Tracklet Calculation Tracklet Calculation Bias Correction Bias Estimation Algorithm (Recursive Least Square estimation) Previously Estimated Biases Fusion Center Kalman Gain Recovery Pseudo-measurement Kalman Gain Recovery Fusion Pseudo-measurement Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

and

u =

Further, the covariance matrix of the noise vector u is

(cid:104) (cid:0)w1
1,2(1)(cid:1)T ···
R = diag(cid:0)(cid:2) R1(1)

(cid:0)wN
1,2(1)(cid:1)T ···

(cid:0)w1
1,2(K)(cid:1)T ···

1,2(K)(cid:1)T (cid:105)T
(cid:0)wN

··· RN (K) (cid:3)(cid:1)

(61)
2(k) and the lower index indicates a speciﬁc sensor. As stated in [19], the covariance matrix of an

··· RN (1)

··· R1(K)

where Ri(k) = Ri
unbiased estimator ˆb is bounded from below as
E

1(k) + Ri

In the above, J is the Fisher Information Matrix (FIM) given by

J = E(cid:110)
= E(cid:110)

≥ J−1

(cid:26)(cid:16)ˆb − b
(cid:17)T(cid:27)
(cid:17)(cid:16)ˆb − b
[∇b ln p(Y | b)] [∇b ln p(Y | b)]T(cid:111) |b=btrue
[∇bλ] [∇bλ]T(cid:111) |b=btrue
(2π)K(cid:112)|R| exp

[Y − gb]T R−1 [Y − gb]

− 1
2

(cid:26)

1

(cid:27)

p(Y | b) =

and therefore

(63)
where btrue is the true value of the bias vector b, p(Y | b) is the likelihood function of b, λ = − ln p(Y | b) and ∇ is
gradient operator. From (57), one has

Using the results from [31] to simplify the differentiations, ∇bλ can be written as

λ = Const. +

[Y − gb]T R−1 [Y − gb]

1
2

∇bλ = gTR−1 (Y − gb)

which yields

Finally, when calculating the FIM, CRLB of desired elements (here the diagonal) will be

J = gTR−1g

CRLB{[b]i} =(cid:2)J−1(cid:3)

ii

for i = 1, 2, 3, 4.

B. Multitarget–multisensor CRLB

(60)

(62)

(64)

(65)

(66)

(67)

(68)

(69)

(70)

When number of the targets is greater than two, the same procedure as the proposed bias estimation algorithm to calculate
the CRLB can be used. In this case, one should fuse all the measurements, except for sensor “i” to create a single pseudo-
measurement for this “combined” sensor and then treat the problem as a two–sensor problem. Starting with the calculation of
the combined measurement and covariance matrix of the set Sı as in [1] yields

Zcomb = Rcomb

(Rj)

−1 zj



 (cid:88)
 (cid:88)

j∈{S}\i

j∈{S}\i

−1

R−1

j

and

Rcomb =

As in the bias estimation algorithm, it is assumed that only sensor “i” has bias. This means that in the calculation of CRLB
one should have access to the measurements both with and without bias. The next is to calculate Bcomb(k). Similar to the bias
estimation algorithm, one should deﬁne H(k) = −Bcomb(k) and use the combined covariance and measurement matrices as
a bias free measurement to ﬁnd the CRLB of the bias estimation for sensor “i”. Finally, R(k) can be calculated as

R(k) = Rcomb(k) + Ri(k)

(71)

By using (69), (70) and (71), the formulas for two sensors and multiple targets can be modiﬁed to calculate the CRLB for the
case of multisensor–multitarget scenario.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 6: Initial locations of the targets and sensors

A. Motion dynamics and measurement parameters

VI. SIMULATION RESULTS

Here, a distributed tracking scenario with ﬁve sensors and sixteen targets is considered as shown in Figure 6. It is assumed
that all sensors are synchronized. Without loss of generality and to easily compare the results of bias estimation for different
sensors, all the biases are assumed as

βs = [ 20m 1mrad ]T

(72)

The standard deviations of measurement noises are σr = 10 m and σθ = 1 mrad for target range and azimuth measurements,
respectively. In this problem r (cid:39) 20000. According to [19], rσ2
= 2 × 10−3 (cid:28) 0.4 which is the threshold for
polar to Cartesian conversion to be unbiased. Note that this condition holds for r (cid:39) 200km as well.

= 2×104×10−6

θ
σr

10

Scaling biases can be handled by the proposed method as well but ignored for simplicity. The true dynamics of the targets
are modeled using the Discretized Continuous White Noise Acceleration (DCWNA) or nearly constant velocity (NCV) model
with qx = qy = 0.1 m2
s . As for the ﬁltering in local trackers, DCWNA and
Continuous Wiener Process Acceleration (CWPA) are used with various settings to be able to create different scenarios for the
simulation (for detail see [19, p. 268 and p. 467]).

s3 and constant turn rate model with rate ω = 0.1 deg

B. A two-sensor problem

To compare the results of the new approach with those of the previously proposed algorithm [9]–[11], the case of two sensors
(placed at (0m, 0m) and (5000m, 0m) in Cartesian coordinates) is considered with the same kinematics and ﬁlter settings as
in [9]. The new algorithm that uses the reconstructed Kalman gains detailed in (35) and (36) is denoted as EXL while the
previous algorithm in [9]–[11] is denoted as EX. Note that there is no fusion step in this case and the two methods only differ
in the Kalman gain calculation, which in the EXL 4 case is reconstructed approximately.

The settings of the variables are as follows. To handle the L = 1 and non–singularity problem, the “tracklet with decorrelated
state estimate” 5 that can be used with only one measurement in the tracklet interval [12] must be selected instead of “tracklet
computed using inverse Kalman ﬁlter” . The sampling intervals are T = 1s. The lag between each update at the fusion center
is L = k − k(cid:48) = 1. The initial state estimates are the converted measurements from polar coordinate to Cartesian coordinate
with zero velocity and covariance matrix [9]–[11]

(cid:104)

(73)

(74)

Finally, the initial bias parameter estimate of all the sensors are zero with initial bias covariance

Ps(0 | 0) = diag

(200m)2

Σs(0 | 0) = diag(cid:2) (20m)2

(cid:0)20m/s2(cid:1)2
(1mrad)2 (cid:3)

(200m)2

(cid:0)20m/s2(cid:1)2 (cid:105)

s = 1, 2

In the simulations, 100 Monte Carlo runs are used over 20 frames. The results of the Root Mean Squared Error (RMSE)
in logarithmic scale for offset bias estimates are shown in Figures 7 and 8. From Figures 7 and 8, it can be seen that
the performance of the EXL method, which recovers the Kalman gain at the fusion center by taking advantage of tracklet

4The EXL algorithm has the luxury of operating without the local Kalman gains.
5This is equivalent to the information matrix fusion method, which, for L = 1, is algebraically equivalent to the Kalman ﬁlter (see [1, eq. (8.4.1-14)]).

−1−0.500.511.522.53x 104−1−0.500.511.52x 104x (m)y (m)  Target initial locationsSensor locationsAccepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

calculation, is very close to the accuracy of the EX method. The small variations in the results are due to the fact that the
logarithmic scale is used to show the convergence rates clearly.
The CPU time for one iteration of bias estimation for a single target is 4.84 × 10−4 s for the EX method and 6.02 × 10−4
s for the EXL method, which represents a 20% increase in CPU time for the Kalman gain reconstruction. The CPU time over
all iterations and targets for bias estimation with the above methods are 0.1526 and 0.1877 s, respectively. All simulations are
done on a computer with Intel R(cid:13) CoreTM i7-3720Qm 2.60GHz processor and 8GB RAM.

Fig. 7: RMSE of the bias parameter br for sensors 1 and 2 in logarithmic scale (comparison between the previous (EX) and
the proposed (EXL) algorithm)

Fig. 8: RMSE of the bias parameter bθ for sensors 1 and 2 in logarithmic scale (comparison between the previous (EX) and
the proposed (EXL) algorithm))

C. A ﬁve–sensor problem with nearly constant velocity (NCV) Kalman ﬁlter as local tracker

In the second case, a scenario with ﬁve sensors with the same sixteen targets, L = k − k(cid:48) = 10 and k = 1, ..., 100 is
simulated. The motivation for using 100 time steps is to have enough update steps to demonstrate the convergence results in
terms of RMSE. Here the Fused Bias Estimation Algorithm (FBEA, Figure 4) is used to estimate the biases at the fusion
center. The results of this simulation are shown in Figure 9.

From Figure 9, it can be seen that the proposed algorithm works well in a scenario with ﬁve sensors and with tracklet update
at every L = 10 steps. Note that the FBEA is using only a two-dimensional state space for the bias estimation step for each
sensor. For the same scenario, the previous EX algorithm would required a ten dimensional state space model. At its core,
FBEA is a recursive least square (RLS) estimator. The computational complexity of RLS is of the order of O(n2), where n
is number of parameters to be estimated. With n = 10 in the simulation, the computational complexity of the EX algorithm
will be substantially higher.

To show the performance of the new algorithm in the fusion step, the results in terms of RMSE of the local track estimates
for a speciﬁc sensor (sensor 1) and the fused estimates are presented in Figure 10 in logarithmic scale. To compare the results,
the RMSE values of the local tracks and fused tracks with no biases are also included.

Figure 10 shows that the sequential fusion step used in the proposed bias estimation algorithm (FBEA) is a viable solution
to the fusion problem. Clearly, the RMSE of the fused track with corrected measurements is between those of the local track
and the fused track of measurements with no biases. This observation indicates that the bias correction and fusion steps work
well, which is another feature in the new algorithm, as this correction is done at the fusion center and not at the local trackers.
In this case, there is no need for a feedback channel. This reduces the communication requirements.

In order to further evaluate the performance of the proposed algorithm, one can assume that all sensors have scaling and

offset biases. Let the value of biases be

(75)
The results in terms of the RMSE of the local track estimates for a speciﬁc sensor (sensor 1) and the fused estimates are
shown in Figure 11 in logarithmic scale. Figure 11 shows that the proposed algorithm can handle offset and scaling biases at
the same time and fuse the corrected tracks in order to achieve better estimates of the targets’ state.

βs = [ 20m 1mrad 0.001

0.001 ]T

5101520100101Time kRMSE (m)Sensor #15101520100101Time kRMSE (m)Sensor #2  510152010−410−310−2Time kRMSE (rad)Sensor #1  510152010−410−310−2Time kRMSE (rad)Sensor #2  EXLEXEXLEX5101520100101Time kRMSE (m)Sensor #15101520100101Time kRMSE (m)Sensor #2  510152010−410−310−2Time kRMSE (rad)Sensor #1  510152010−410−310−2Time kRMSE (rad)Sensor #2  EXLEXEXLEXAccepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 9: RMSE of the bias parameter br (left column) and bθ (right column) for all 5 sensors from sensor 1 (top) to sensor 5
(bottom) in logarithmic scale. Note that residual bias RMSE is an order of magnitude below the measurement noise standard
deviations, i.e., it becomes negligible.

Fig. 10: RMSE of local track (sensor 1) and the output of the fusion algorithm including offset biases for all sensors in
logarithmic scale

D. A ﬁve–sensor problem with a two–NCV IMM as local estimator

Previously, the noise levels of local tracker ﬁlters were assumed to be known. To demonstrate how well the proposed
algorithm works when this information is not available, the IMM estimator is used in the next two examples as local tracker
ﬁlters. To start with, an IMM estimator with two nearly constant velocity (NCV) or DCWNA Kalman ﬁlters with different
noise intensities are used. The ﬁrst ﬁlter uses qx = qy = 10 m2
s3 as intensities in the

s3 while the second one uses qx = qy = 2 m2

050100100102RMSE (m)Results for bsr05010010−410−3RMSE (rad)Results for bsθ050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)Time k05010010−410−3RMSE (rad)Time k020406080100101102103Target #3RMSEx (m)Time Step k  Local track (uncorrected)Local track (no bias)Suboptimal fusion (corrected)Suboptimal fusion (no bias)Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 11: RMSE of local track (sensor 1) and the output of the fusion algorithm including scaling and offset biases for all
sensors in logarithmic scale

east and north directions, respectively. Note that the noise intensity parameters qx and qy have the same meaning as in [10], i.e.,
power spectral densities. To ensure accurate bias estimation, parameters of the RLSBE algorithm should be changed to handle
the mismatch in the models between local trackers and fusion center which uses only an NCV model for data processing.
Although there is no systematic way to select the intensities for the NCV model at the fusion center, q should be the value
of the higher intensity in each coordinate. Figure 12 shows the RMSE results for the bias parameters that are estimated in
the case of having NCV–NCV IMM estimators as local trackers and only one NCV model at the fusion center with inﬂated
intensity level.

Figure 12 shows how well the bias estimation can be handled by EXL even when it is not possible to recover the exact
Kalman gains that are used the at local trackers. The difference in convergence between the previous example (Figure 9) and
Figure 12 is negligible, which shows the effectiveness of the new algorithm in different situations.

E. A ﬁve–sensor problem with nearly constant acceleration–nearly constant velocity (NCA–NCV) IMM as local estimators

Next, we demonstrate the effectiveness of the new algorithm in recovering the Kalman gain and estimating the biases and
show how well the new algorithm works in the case of mismatch in the models at the fusion center and local trackers. In
this example it is assumed that local trackers are using an IMM estimator with one nearly constant acceleration (NCA) and
one NCV Kalman ﬁlter with qx = qy = 10 m2
for the NCV model. The issue in
s3
this case is that the local trackers send only the combined output from the IMM estimator without any information about the
acceleration. Figure 13 shows the results on the scenario of this subsection with qx = qy = 200 m2

for the NCA model and qx = qy = 2 m2
s3

s3 at the fusion center.

Simulation results show convergence as in the previous examples (Figures 9 and 12). This demonstrates the robustness of

the new algorithm even in the presence of uncertainty about the local trackers.

F. Lower bound and convergence results

The calculation of the CRLB was discussed in Section V. Three different examples are used to demonstrate the performance
of the proposed algorithm with respect to the CRLB. The ﬁrst example is the scenario implemented in Subsection VI-C. The

comparison is between the square root of the diagonal elements of the CRLB ((cid:112)CRLB{[b]i}) , the square root of the diagonal
Σii and the RMSE follow the (cid:112)CRLB{[b]i}. The results for the examples in Subsections

√
elements of bias estimation covariance matrix (

Σii) and the RMSE of the estimated biases.

Figure 14 shows that both

√

VI-D and VI-E are shown in Figure 15 and Figure 16, respectively. These are approximately within the 95% probability region
around the CRLB [32]. Once again, the ﬁgures show that the estimation errors follow the CRLB.

G. Consistency of bias estimation algorithms

In this section, a brief analysis of consistency of the proposed bias estimation algorithms is given. The analysis is based
on Normalized Estimation Error Squared (NEES) [19]. First, the results for EXL algorithm are shown in Figure 17 for 100

020406080100101102103Target #3  Time Step kRMSEx (m)Local track (uncorrected)Local track (no bias)Suboptimal fusion (corrected)Suboptimal fusion (no bias)Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 12: RMSE of the bias parameter br (left column) and bθ (right column) for all 5 sensors from sensor 1 (top) to sensor 5
(bottom) in logarithmic scale. The local trackers use IMM estimators with NCV–NCV models.

TABLE I: Offset bias br1related RMSE,(cid:112)CRLB{[b]i} and

√

Σii at ﬁnal time-step for three different local ﬁlters

√
RMSE
Σii

(cid:113)
CRLB(cid:8)[b]i

(cid:9)

Upper 95% conﬁdence interval
Lower 95% conﬁdence interval

Kalman ﬁlter

NCV–NCV

NCA–NCV

0.7621
1.018

0.8795
1.055
0.7036

1.002
1.025

0.9122
1.106
0.7666

1.105
1.029

0.9350
1.220
0.7481

Monte–Carlo runs. The bounds are for the 95% probability interval which shows that the EXL algorithm is consistent at each
time step.

To further examine the consistency of the proposed algorithm, the NEES for FBEA are computed and shown in Figure 18
for three different types of local estimators, i.e., Kalman ﬁlter, NCV–NCV IMM and NCA–NCV IMM for 100 Monte–Carlo
runs. Here we used one–sided 95% probability interval. The results show that FBEA is a pessimistic ﬁltering approach. This
is mostly due to the fact that the use of the pseudo–measurement in a Kalman ﬁlter fashion is an approximation because its
error and the state prediction error at the fusion center are correlated because of the common process noise.

update for sensor 1. As can be seen from Tables I and II, both RMSE and

Finally, in Tables I and II the RMSE,(cid:112)CRLB{[b]i} and
(cid:112)CRLB{[b]i}, which indicates that the parameter estimates are unbiased.
TABLE II: Offset bias bθ1related RMSE,(cid:112)CRLB{[b]i} and

√

√

Σii are compared for both offset bias parameters at their last
Σii are within the 95% conﬁdence region of

√

Σii at ﬁnal time-step for three different local ﬁlters

√
RMSE
Σii

(cid:113)
CRLB(cid:8)[b]i

(cid:9)

Upper 95% conﬁdence interval
Lower 95% conﬁdence interval

Kalman ﬁlter
9.266 × 10−5
9.322 × 10−5
9.826 × 10−5
11.79 × 10−5
7.861 × 10−5

NCV–NCV
7.950 × 10−5
9.434 × 10−5
9.714 × 10−5
11.66 × 10−5
7.771 × 10−5

NCA–NCV
9.197 × 10−5
9.198 × 10−5
10.090 × 10−5
12.10 × 10−5
8.069 × 10−5

050100100102RMSE (m)Results for bsr05010010−410−3RMSE (rad)Results for bsθ050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)Time k05010010−410−3RMSE (rad)Time kAccepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 13: RMSE of the bias parameter br (left column) and bθ (right column) for all 5 sensors from sensor 1 (top) to sensor 5
(bottom) in logarithmic scale. The local trackers use IMM estimators with NCA–NCV models.

Fig. 14: Comparison between the square root of diagonal elements of CRLB ((cid:112)CRLB{[b]i}), square root of diagonal elements

√
of the covariance matrix of bias estimation algorithm (
Kalman ﬁlter as local trackers (only the results for the ﬁrst sensor are shown).

Σii) and RMSE of the bias estimation for the case of 5 sensors with

050100100102RMSE (m)Results for bsr05010010−410−3RMSE (rad)Results for bsθ050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)05010010−410−3RMSE (rad)050100100102RMSE (m)Time k05010010−410−3RMSE (rad)Time k0102030405060708090100100101(meters)  010203040506070809010010−410−310−2(radians)Time k√ΣiiRMSEpCRLB{[b]i}95%ConﬁdenceIntervalAccepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 15: Comparison between the square root of diagonal elements of CRLB ((cid:112)CRLB{[b]i}), square root of diagonal elements

√
of the covariance matrix of bias estimation algorithm (
NCV–NCV IMM estimator as local trackers (only the results for the ﬁrst sensor are shown).

Σii) and RMSE of the bias estimation for the case of 5 sensors with

Fig. 16: Comparison between the square root of diagonal elements of CRLB ((cid:112)CRLB{[b]i}), square root of diagonal elements

√
of the covariance matrix of bias estimation algorithm (
NCA–NCV IMM estimator as local trackers (only the results for the ﬁrst sensor are shown).

Σii) and RMSE of the bias estimation for the case of 5 sensors with

VII. CONCLUSIONS

In this paper, a new bias estimation algorithm that works with only the state estimates and their associated covariance
matrices from synchronized local trackers at varying reporting rates was presented. The algorithm does not require the stacking
of the bias vectors of all the sensors together, which is a problem for previous algorithms with a large number of sensors in the
surveillance area. Also, the new algorithm works without the local ﬁlter gains, which are not available at the fusion center in
practical systems. In addition, it gives a solution to the problem of joint fusion and bias estimation. The results from simulations
show that the algorithm works reliably in different scenarios with various numbers of sensors. Furthermore, this algorithm

020406080100100101(meters)  02040608010010−410−310−2(radians)Time k√ΣiiRMSEpCRLB{[b]i}95%ProbabilityInterval0102030405060708090100100101(meters)  010203040506070809010010−410−310−2(radians)Time k√ΣiiRMSEpCRLB{[b]i}95%ProbabilityIntervalAccepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Fig. 17: NEES for EXL algorithm with Kalman gain recovery instead of using original Kalman gains.

Fig. 18: NEES for FBEA and three different local tracker estimators (Kalman ﬁlter, NCV–NCV IMM and NCA–NCV IMM)
for sensor 1 (top) to sensor 5 (bottom) compared to the upper–bound of 95% probability interval.

can work with low data rates between the sensors and the data fusion center. Finally, the CRLB for multisensor–multitarget
scenarios with bias estimation was presented and the RMSE results matched well with the CRLB. This demonstrates the
statistical efﬁciency and the versatility of the new algorithm.

APPENDIX A

5101520012345NEESSensor #15101520012345NEESSensor #2Time k  NEES95% Probability Interval102030405060708090100024NEES  102030405060708090100024NEES  102030405060708090100024NEES  102030405060708090100024NEES102030405060708090100024NEESTime k  Upper BoundKFNCV−NCVNCA−NCVUsing the properties

and

E(cid:104)

˜x (k | k) ˜x (k | k(cid:48))T | Zk(cid:48)

s

(cid:105)

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

DERIVATION OF THE EQUIVALENT MEASUREMENT COVARIANCE (34)

E(cid:104)
E(cid:2)˜us (k, k(cid:48)) | Zk

˜us (k, k(cid:48)) | Zk(cid:48)

s

(cid:105)
(cid:3)

s

= 0
(cid:54)= 0

= E [E [[xs(k) − ˆxs (k | k)]

= E(cid:104)E(cid:104)
E(cid:2)[xs(k)−ˆxs (k|k)]|Z k
(cid:124)
(cid:105)

= Ps (k | k)

(cid:123)(cid:122)

+E

=0

s

(cid:3)
(cid:125)

[xs(k) − ˆxs (k | k) + ˆxs (k | k) − ˆxs (k | k(cid:48))]T | Zk
[xs(k) − ˆxs (k | k)] [xs(k) − ˆxs (k | k)]T | Zk

s

s

(cid:105) | Zk(cid:48)
(cid:105) | Zk(cid:48)

s

s

(cid:105)
(cid:105)



[ˆxs (k | k) − ˆxs (k | k(cid:48))]T | Zk(cid:48)

s

(76)

(77)

(78)

(79)

(80)

(81)

Us (k, k(cid:48)) can be expanded as

Us (k, k(cid:48)) = E(cid:104)

˜us (k, k(cid:48)) ˜us (k, k(cid:48))T | Zk(cid:48)

s

= AsPs (k | k) AT

s + [As − I] Ps (k | k(cid:48)) [As − I]T
−AsPs (k | k) [As − I]T − [As − I] Ps (k | k) As
= [As − I] Ps (k | k(cid:48)) [As − I]T − AsPs (k | k) AT

s + AsPs (k | k) + Ps (k | k) AT

s

(cid:104)

[As − I] Ps (k | k(cid:48)) =

where the arguments of As(k, k(cid:48)) are dropped for clarity. By using the property
−1 − I
Ps (k | k(cid:48)) [Ps (k | k(cid:48)) − Ps (k | k)]
−1 − Ps (k | k(cid:48))
[Ps (k | k(cid:48)) − Ps (k | k)]
= Ps (k | k(cid:48))
−1(cid:105)
−1
= Ps (k | k(cid:48)) [Ps (k | k(cid:48)) − Ps (k | k)]
−1(cid:105)

I − [Ps (k | k(cid:48)) − Ps (k | k)] Ps (k | k(cid:48))

(cid:104)

(cid:104)

(cid:104)

I − I + Ps (k | k) Ps (k | k(cid:48))

Ps (k | k(cid:48))

Ps (k | k(cid:48))

−1(cid:105)

Ps (k | k(cid:48))

(cid:105)

= As
= AsPs (k | k)

Us (k, k(cid:48)) can be further simpliﬁed as

Ps (k | k(cid:48))

Us (k, k(cid:48)) = AsPs (k | k) [As − I]T − AsPs (k | k) AT

s + AsPs (k | k) + Ps (k | k) AT

s

s − AsPs (k | k) − AsPs (k | k) AT

s + AsPs (k | k) + Ps (k | k) AT

s

= AsPs (k | k) AT
= Ps (k | k) AT

(82)
which yields (34). Note that (81) and (82) are transpose of each other, but, since Us (k, k(cid:48)) is symmetric, they are equal to
each other.

s

REFERENCES

[1] Y. Bar-Shalom, P.K. Willett, and X. Tian. Tracking and Data Fusion: A Handbook of Algorithms. YBS Publishing, Storr, CT, 2011.
[2] B. Friedland. “Treatment of bias in recursive ﬁltering”. IEEE Transactions on Automatic Control, vol. 14, no. 4, pp. 359–367, 1969.
[3] M. P. Dana. “Registration: A prerequisite for multiple sensor tracking”. Multitarget-Multisensor Tracking: Advanced Applications, vol. 1, pp. 155–185,

[4] N. Nabaa and R. H. Bishop. “Solution to a multisensor tracking problem with sensor registration errors”. IEEE Transactions on Aerospace and Electronic

[5] N. Okello and B. Ristic. “Maximum likelihood registration for multiple dissimilar sensors”. IEEE Transactions on Aerospace and Electronic Systems,

[6] N. Okello and S. Challa. “Joint sensor registration and track-to-track fusion for distributed trackers”. IEEE Transactions on Aerospace and Electronic

[7] D. Huang, H. Leung, and E. Bosse. “A pseudo-measurement approach to simultaneous registration and track fusion”. IEEE Transactions on Aerospace

[8] D. J. Papageorgiou and J. D Sergi. “Simultaneous track-to-track association and bias removal using multistart local search”. Proc. IEEE Aerospace

and Electronic Systems, vol. 48, no. 3, pp. 2315–2331, 2012.

Conference, BigSky, MT, March 2008.

Artech House, Norwood, MA, 1990.

Systems, vol. 35, no. 1, pp. 354–363, 1999.

vol. 39, no. 3, pp. 1074–1083, 2003.

Systems, vol. 40, no. 3, pp. 808–823, 2004.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

[9] X. Lin, Y. Bar-Shalom, and T. Kirubarajan. “Exact multisensor dynamic bias estimation with local tracks”.

IEEE Transactions on Aerospace and

Electronic Systems, vol. 1, no. 40, pp. 576–590, 2004.

[10] X. Lin, Y. Bar-Shalom, and T. Kirubarajan. “Multisensor-multitarget bias estimation of asynchronous sensors”. Proc. SPIE, vol. 5429, pp. 105–116,

[11] X. Lin, Y. Bar-Shalom, and T. Kirubarajan. “Multisensor multitarget bias estimation for general asynchronous sensors”. IEEE Transactions on Aerospace

and Electronic Systems, vol. 41, no. 3, pp. 899–921, 2005.

[12] O. E. Drummond. “Track and tracklet fusion ﬁltering”. Proc. SPIE, Signal and Data Processing of Small Targets, vol. 4728, pp. 176–195, 2002.
[13] H. Chen and X. R. Li. “On track fusion with communication constraints”. International Conference on Information Fusion, Quebec, QC, Canada, July

2004.

2007.

1997.

1997.

[14] O. E. Drummond. “A hybrid sensor fusion algorithm architecture and tracklets”. Proc. SPIE, Signal and Data Processing of Small Targets, vol. 3163,

[15] O. E. Drummond. “Tracklets and a hybrid fusion with process noise”. Proc. SPIE, Signal and Data Processing of Small Targets, vol. 3163, pp. 512–524,

[16] A. Balleri, A. Nehorai, and J. Wang. “Maximum likelihood estimation for compound-Gaussian clutter with inverse gamma texture. IEEE Transactions

on Aerospace and Electronic Systems, vol. 43, no. 2, pp. 775–779, 2007.

“Weighted least squares estimation with missing data”.

Available at: http://www.statmodel.com/download/

[17] T. Asparouhov and B. Muth´en.
GstrucMissingRevision.pdf, 2010.

[18] H. Rue and L. Held. Gaussian Markov Random Fields: Theory and Applications. CRC Press, Boca Raton, FL, 2005.
[19] Y. Bar-Shalom, X.R. Li, and T. Kirubarajan. Estimation with Applications to Tracking and Navigation: Theory, Algorithms and Software. Wiley, New

[20] I. Li and J. Georganas. “Multi-target multi-platform sensor registration in geodetic coordinates”. Proc. International Conference on Information Fusion,

vol. 1, pp. 366–373, Annapolis, MD, July 2002.

[21] M. Yeddanapudi, Y. Bar-Shalom, and K. Pattipati. “IMM estimation for multitarget-multisensor air trafﬁc surveillance”. Proc. IEEE, vol. 85, no. 1, pp.

York, NY, 2001.

80-96, 1997.

[22] E. Taghavi, R. Tharmarasa, T. Kirubarajan, and Y. Bar-Shalom. “Bias estimation for practical distributed multiradar-multitarget tracking systems”.

International Conference on Information Fusion, pp. 1304–1311, Istanbul, Turkey, July 2013.

[23] G. Welch and G. Bishop. An Introduction to The Kalman Filter. University of North Carolina: Chapel Hill, North Carolina, 1995.
[24] R. A. Horn and C. R. Johnson. Matrix Analysis. Cambridge university press, Cambridge, UK, 2012.
[25] K. Kastella, B. Yeary, T. Zadra, R. Brouillard, and E. Frangione. “Bias modeling and estimation for GMTI applications”. International Conference on

[26] P. J. Shea, T. Zadra, D. Klamer, E. Frangione, R. Brouillard, and K. Kastella. “Precision tracking of ground targets”. Proc. IEEE Aerospace Conference,

Information Fusion, pp. TUC1–7, Paris, France, July 2000.

pp. 473–482, BigSky, MT, March 2000.

[27] B. A. van Doorn and H.A.P. Blom. “Systematic error estimation in multisensor fusion systems”. Proc. SPIE Conference on Aerospace Sensing, vol.

1954, pp. 450–461, 1993.

July 2006.

[28] Y. Bar-Shalom and H. Chen. “Multisensor track-to-track association for tracks with dependent errors. Journal of Advances in Information Fusion, 1(1),

[29] J. Durbin and S. J. Koopman. Time Series Analysis by State–Space Methods. no. 38, Oxford University Press, Oxford, UK, 2012.
[30] M. Longbin, S. Xiaoquan, Z. Yiyu, S. Z. Kang, and Y. Bar-Shalom. “Unbiased converted measurements for tracking”. IEEE Transactions on Aerospace

and Electronic Systems, vol. 34, no. 3, pp. 1023–1027, 1998.

[31] F. A. Graybill. Theory and Applications of The Linear Model. Duxbury Press, Belmont, CA, 1976.
[32] D. Belfadel, R. W. Osborne, and Y. Bar-Shalom. “Bias estimation for optical sensor measurements with targets of opportunity”. International Conference

on Information Fusion, pp. 1805–1812, Istanbul, Turkey, July 2013.

Ehsan Taghavi received the M.Sc. degree in communication engineering in 2012 from Chalmers University of Technology, Gothen-
burg, Sweden, where he worked on particle ﬁlter smoother. He is currently pursuing the Ph.D. degree in computational science and
engineering at McMaster University, Hamilton, Canada. His research interests include estimation theory, scientiﬁc computing, signal
processing, parameter estimation, mathematical modeling and algorithm design.

Ratnasingham Tharmarasa was born in Sri Lanka in 1975. He received the B.Sc.Eng. degree in electronic and telecommunication
engineering from University of Moratuwa, Sri Lanka in 2001, and the M.A.Sc and Ph.D. degrees in electrical engineering from
McMaster University, Canada in 2003 and 2007, respectively.

From 2001 to 2002 he was an instructor in electronic and telecommunication engineering at the University of Moratuwa, Sri Lanka.
During 2002-2007 he was a graduate student/research assistant in ECE department at the McMaster University, Canada. Currently
he is working as a Research Associate in the Electrical and Computer Engineering Department at McMaster University, Canada. His
research interests include target tracking, information fusion and sensor resource management.

Accepted for publication in IEEE Transactions on Aerospace and Electronics Systems, June 2015

Thiagalingam Kirubarajan (S’95M’98SM’03) was born in Sri Lanka in 1969. He received the B.A. and M.A. degrees in electrical
and information engineering from Cambridge University, England, in 1991 and 1993, and the M.S. and Ph.D. degrees in electrical
engineering from the University of Connecticut, Storrs, in 1995 and 1998, respectively.

Currently, he is a professor in the Electrical and Computer Engineering Department at McMaster University, Hamilton, Ontario.
He is also serving as an Adjunct Assistant Professor and the Associate Director of the Estimation and Signal Processing Research
Laboratory at the University of Connecticut. His research interests are in estimation, target tracking, multisource information fusion,
sensor resource management, signal detection and fault diagnosis. His research activities at McMaster University and at the University
of Connecticut are supported by U.S. Missile Defense Agency, U.S. Ofﬁce of Naval Research, NASA, Qualtech Systems, Inc.,
Raytheon Canada Ltd. and Defense Research Development Canada, Ottawa. In September 2001, Dr. Kirubarajan served in a DARPA
expert panel on unattended surveillance, homeland defense and counterterrorism. He has also served as a consultant in these areas
to a number of companies, including Motorola Corporation, Northrop-Grumman Corporation, Paciﬁc-Sierra Research Corporation,
Lockhead Martin Corporation, Qualtech Systems, Inc., Orincon Corporation and BAE systems. He has worked on the development of a number of engineering
software programs, including BEARDAT for target localization from bearing and frequency measurements in clutter, FUSEDAT for fusion of multisensor data
for tracking. He has also worked with Qualtech Systems, Inc., to develop an advanced fault diagnosis engine.

Dr. Kirubarajan has published about 100 articles in areas of his research interests, in addition to one book on estimation, tracking and navigation and two

edited volumes. He is a recipient of Ontario Premiers Research Excellence Award (2002).

Yaakov Bar–Shalom was born on May 11, 1941. He received the B.S. and M.S. degrees from the Technion, Israel Institute of
Technology, in 1963 and 1967 and the Ph.D. degree from Princeton University in 1970, all in electrical engineering. From 1970
to 1976 he was with Systems Control, Inc., Palo Alto, California. Currently he is Board of Trustees Distinguished Professor in the
Dept. of Electrical and Computer Engineering and Marianne E. Klewin Professor in Engineering at the University of Connecticut.
He is also Director of the ESP (Estimation and Signal Processing) Lab. His current research interests are in estimation theory,
target tracking and data fusion. He has published over 500 papers and book chapters in these areas and in stochastic adaptive
control. He coauthored the monograph Tracking and Data Association (Academic Press, 1988), the graduate texts Estimation and
Tracking: Principles, Techniques and Software (Artech House, 1993; translated into Russian, MGTU Bauman, Moscow, Russia,
2011), Estimation with Applications to Tracking and Navigation: Algorithms and Software for Information Extraction (Wiley, 2001),
the advanced graduate texts MultitargetMultisensor Tracking: Principles and Techniques (YBS Publishing, 1995), Tracking and Data
Fusion (YBS Publishing, 2011), and edited the books MultitargetMultisensor Tracking: Applications and Advances (Artech House,

Vol. I, 1990; Vol. II, 1992; Vol. III, 2000).

He has been elected Fellow of IEEE for “contributions to the theory of stochastic systems and of multi target tracking”. He has been consulting to numerous
companies and government agencies, and originated the series of MultitargetMultisensor Tracking short courses offered via UCLA Extension, at Government
Laboratories, private companies and overseas. During 1976 and 1977 he served as Associate Editor of the IEEE Transactions on Automatic Control and from
1978 to 1981 as Associate Editor of Automatica. He was Program Chairman of the 1982 American Control Conference, General Chairman of the 1985 ACC,
and CoChairman of the 1989 IEEE International Conference on Control and Applications. During 198387 he served as Chairman of the Conference Activities
Board of the IEEE Control Systems Society and during 198789 was a member of the Board of Governors of the IEEE CSS. He was a member of the Board
of Directors of the International Society of Information Fusion (1999–2004) and served as General Chairman of FUSION 2000, President of ISIF in 2000
and 2002 and Vice President for Publications in 2004-13. In 1987 he received the IEEE CSS Distinguished Member Award. Since 1995 he is a Distinguished
Lecturer of the IEEE AESS and has given numerous keynote addresses at major national and international conferences. He is corecipient of the M. Barry
Carlton Award for the best paper in the IEEE Transactions on Aerospace and Electronic Systems in 1995 and 2000 and recipient of the 1998 University of
Connecticut AAUP Excellence Award for Research. In 2002 he received the J. Mignona Data Fusion Award from the DoD JDL Data Fusion Group. He is
a member of the Connecticut Academy of Science and Engineering. In 2008 he was awarded the IEEE Dennis J. Picard Medal for Radar Technologies and
Applications, and in 2012 the Connecticut Medal of Technology. He has been listed by academic.research.microsoft (top authors in engineering) as number
1 among the researchers in Aerospace Engineering based on the citations of his work.

Michael McDonald received a B.Sc (Hons) degree in Applied Geophysics from Queens University in Kingston, Canada in 1986 and
a M.Sc. degree in Electrical Engineering in 1990, also from Queen’s University. He received a Ph.D in Physics from the University
of Western Ontario in London, Canada in 1997. He was employed at ComDev in Cambridge, Canada from 1989 through 1992 in
their space science and satellite communications departments and held a post-doctoral position in the Physics department of SUNY
at Stony Brooke from 1996 through 1998 before commencing his current position as Defence Scientist in the Radar Systems section
of Defence Research and Development Canada, Ottawa, Canada. His current research interests include the application of STAP
processing and nonlinear ﬁltering to the detection of small maritime and land targets as well as the development and implementation
of passive radar systems.

