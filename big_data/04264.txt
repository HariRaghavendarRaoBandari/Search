Novel Speech Features for Improved Detection of

Spooﬁng Attacks

Email: ∗dipjyotipaul@ece.iitkgp.ernet.in, †monisankhapal@iitkgp.ac.in, ‡gsaha@ece.iitkgp.ernet.in

∗†‡ Dept of Electronics & Electrical Communication Engineering, Indian Institute of Technology, Kharagpur, India

Dipjyoti Paul∗, Monisankha Pal†, Goutam Saha‡

6
1
0
2

 
r
a

 

M
4
1

 
 
]

D
S
.
s
c
[
 
 

1
v
4
6
2
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Now-a-days, speech-based biometric systems such
as automatic speaker veriﬁcation (ASV) are highly prone to
spooﬁng attacks by an imposture. With recent development
in various voice conversion (VC) and speech synthesis (SS)
algorithms, these spooﬁng attacks can pose a serious potential
threat to the current state-of-the-art ASV systems. To impede
such attacks and enhance the security of the ASV systems, the
development of efﬁcient anti-spooﬁng algorithms is essential that
can differentiate synthetic or converted speech from natural or
human speech. In this paper, we propose a set of novel speech
features for detecting spooﬁng attacks. The proposed features
are computed using alternative frequency-warping technique and
formant-speciﬁc block transformation of ﬁlter bank log energies.
We have evaluated existing and proposed features against several
kinds of synthetic speech data from ASVspoof 2015 corpora.
The results show that
the proposed techniques outperform
existing approaches for various spooﬁng attack detection task.
The techniques investigated in this paper can also accurately
classify natural and synthetic speech as equal error rates (EERs)
of 0% have been achieved.

Index Terms—anti-spooﬁng, ASVspoof 2015, countermeasures,
mel-frequency cepstral coefﬁcient (MFCC), speech-signal-based
frequency cepstral coefﬁcient (SFCC), speaker recognition

I. INTRODUCTION

Synthetic speech signal can be obtained non-intrusively by
using different voice conversion (VC) [1] and speech synthesis
(SS) [2] techniques. Due to the advancements in speech
technology, VC and SS techniques have been developed a lot
which can be used to generate synthetic voice with excellent
quality and naturalness like a real human speech. These
techniques generally concentrate on mapping the spectral
characteristics. Among the VC techniques, Gaussian mixture
model (GMM) based [3], frequency warping based [4] and
unit-selection based [5] approaches are well known. Now-a-
days, speech synthesis technique like hidden Markov model
(HMM) based text-to-speech (TTS) [6] and speaker adapted
speech synthesis [7] are very much popular. These synthetic
speechs can be deliberately used as a spooﬁng attack to
deceive the speech-based biometric systems like ASV systems
[8]. Thus in order to enhance the security of ASV systems,
development of an efﬁcient anti-spooﬁng mechanism that can
distinguish between real speech and synthetic speech is highly
essential.

During the last decade, a signiﬁcant effort has been made to
develop the countermeasures that can prevent spooﬁng attack
in ASV systems [9]. An anti-spooﬁng system consists of

978–1–4673–6540–6/15/$31.00 c(cid:13) 2015 IEEE

two major blocks: feature extraction or front-end for speech
parameterization and classiﬁer or back-end for modeling real
and synthetic speech class. In feature level, several features
such as mel-frequency cepstrum coefﬁcient (MFCC), modiﬁed
group delay function and cos-phase features were studied
for anti-spooﬁng [10]. Phase information is usually neglected
during the process of speech synthesis. Therefore, the phase
based features can be used as an informative cue for synthetic
speech detection. Phase based features like relative phase shift
(RPS) [11], [12], modiﬁed group delay phase [10], [13] were
investigated for reliable detection of HMM-based synthetic
speech. Modulation features extracted from magnitude as well
as phase spectrum were also used to detect HMM-based
synthetic speech from natural speech [14]. Better results were
reported in score level fusion when phase based modulation
and short-term spectral features were used. Prosodic features
using several pitch statistics were also used for the anti-
spooﬁng task [15]. Other countermeasure techniques devel-
oped for this purpose were based on high level dynamic
features and voice quality assessment [16], pairwise distance
between input and target speaker data in training [17] and local
binary pattern analysis [18], [19]. Moreover, the robustness of
various state-of-the-art speech based biometric systems against
different voice conversion attacks and a possible solution to
prevent such attacks were provided in [20]. On the other
hand, a useful comparative study showing vulnerability of
various types of short-term, dynamic and complementary
features for spooﬁng detection system was given in [21].
Different classiﬁer level experiments were also conducted in
[22] where GMM trained using maximum-likelihood (GMM-
ML) criterion [18] classiﬁer outperforms other methods for
different kinds of spooﬁng attacks.

In this paper, we have evaluated several features for spooﬁng
detection which were successfully used in speaker veriﬁcation
task [23]. Usually voice conversion techniques utilize mel-
warping where lower frequency components are more empha-
sized. As a result, the higher frequency regions are not well
mapped. This is also illustrated in the spectrogram in Fig. 1
for natural and three different voice converted speech signals.
In order to represent high frequency speech information for
spooﬁng detection task, we propose features based on inverted
warping scale. In cepstral feature extraction algorithm, the
ﬁlter bank structure is computed in such a way that it mimics
human auditory perception. Moreover, most of the cepstral
feature coefﬁcients are determined by giving more emphasis

Fig. 1. Spectrogram of “The lace was of a delicate ivory color, faintly tinted with yellow” from CMU-ARCTIC database of natural and different converted
speech signals. The converted signals are generated by using VC techniques based on (b) GMM, (c) dynamic frequency warping (DFW), and (d) mixture of
factor analyzer (MFA) based algorithms, respectively.

on low frequency regions due to the mel-warped ﬁlter bank
structure. Here, to get more information from high frequency
region, the inverted warping scale is used for computing ﬁlter
bank structure. In speaker recognition task [24], it is found
that speech-signal-based frequency warping (SFCC) and mel
overlapped block transform (MOBT) [25] based short-term
spectral features provide better performance than standard
MFCC. Motivated by this, we formulated inverted version
of those cepstral coefﬁcients for spooﬁng attack detection.
Experiments are conducted on the development section of
the recently released ASVspoof 2015 speech corpus. We have
obtained improved classiﬁcation accuracy with our proposed
features for ﬁve different VC and SS techniques.

The remainder of the paper is organized as follows: different
feature extraction techniques are described in Section II.
Section III provides database description and experimental
framework. In Section IV, experimental results are discussed.
The conclusion of the work is summarized in Section V.

II. FEATURE EXTRACTION TECHNIQUES FOR

COUNTERMEASURES

Real and synthetic speech can be discriminated by their
spectral characteristics which is very much prominent in Fig.
1. It is also clear that the discriminative information between
human and synthetic speech signal resides in the high fre-
quency zone of their corresponding spectrograms. Therefore,
feature related information captured from the high frequency
region can be employed for our classiﬁcation task. Several
short-term spectral feature extraction techniques are analyzed
to detect spooﬁng attacks in [21]. The detailed descriptions of
all the existing and proposed feature extraction algorithms are

described in this section. The basic functional block diagram
of their extraction process is pictorially represented in Fig. 2.

A. Mel-Frequency Cepstral Coefﬁcient (MFCC)

MFCC [26], [27] feature captures spectral and phonetic
information related to speech signal. A brief description of
this feature extraction technique can be described as follows:
Discrete Fourier transform (DFT) is computed on the
framed speech signal s(n) to estimate the short-term power
spectrum. Each speech frame is passed through a mel scaled
triangular ﬁlter bank, where the output would be the multi-
plication of frequency response of the framed speech signal
and the ﬁlters used in the ﬁlter bank. The mel scale can

be represented as fmel = 2595 log10(cid:16)1 + f

is frequency in Hz. Mel ﬁlter bank log energy (MFLE) of
speech frames are derived using the logarithm operation to the
ﬁlterbank energies. At the ﬁnal stage, discrete cosine transform
(DCT) is applied to all the MFLE coefﬁcients to generate
decorrelated feature vectors.

700(cid:17), where f

The inverted mel-frequency scale of the competing ﬁlter
bank structure is used to extract inverse mel-frequency cepstral
coefﬁcient (IMFCC) that can capture information in the higher
frequency components [28], [29].

B. Mel-warped Overlapped Block Transformation (MOBT)

In block-based transformation [25], the MFLE coefﬁcients
of each speech frame are divided into non-overlapping and
overlapping blocks. In order to compute cepstral features
from MFLE using block transformation, linear DCT kernel
is applied to process each block individually. This kernel is

Framing and
Windowing

Power

Spectrum

Computation

Mel-Based
Warping

Speech-Based

Warping

Conventional

Inverted

Conventional

Inverted

DCT

OBT

DCT

OBT

DCT

OBT

DCT

OBT

MFCC

MOBT

IMFCC

IMOBT

SFCC

SOBT

ISFCC

ISOBT

Fig. 2. The basic functional block diagram of different feature extraction techniques used in our work.

selected for transforming segments of MFLE coefﬁcients into
cepstral feature vectors.

MOBT [30] feature is calculated in the same manner
as MFCC, except the fact that DCT on the whole MFLE
coefﬁcients is replaced by block-based DCT. Here, each block
corresponds to a chunk of ﬁlter bank log energies. The ﬁrst
and the second block in MOBT computation are chosen in
such a manner so that they can cover the ﬁrst (F 1) and
second (F 2), third (F 3) formant frequencies respectively [31].
After applying the block-based transformation kernel, a 22-
dimensional feature vector is obtained from each speech frame.
The inverted mel scale can also be used for the purpose of
extracting meaningful information from the higher frequency
components of the speech signal.

C. Speech-Signal-Based Frequency Cepstral Coefﬁcient
(SFCC)

SFCC feature is obtained using speech-signal-based fre-
quency warping technique [32], [33]. The processing steps of
this method are described as follows.

Short-term Fourier transform (STFT) is computed from the
given input speech signal x(n). After that, periodogram-based
power spectral density (PSD) is estimated for each frame of
the speech signal. It can be written as

and

Ai = Ai+1,

i = 1, . . . , M − 1,

(3)

where Ai is the i-th interval area. wi and wi+1 denotes lower
and upper cut-off frequencies respectively. M point speech-
signal-based frequency warping function can be calculated as

W (cid:18) wi + wi+1

2

(cid:19) =

i
M

,

i = 1, . . . , M,

(4)

where W (w) function becomes continuous as M approaches
to inﬁnity and its value lies between 1 and −1.

Spectral domain to cepstral domain feature calculation is
similar to the procedure followed in MFCC computation.
The difference is that instead of using mel scale ﬁlter bank,
the speech-signal-based warping function is used to generate
triangular ﬁlter bank. The inverted warping function based
ﬁlter bank can also be used for ISFCC feature computation.
Motivated by the computation of MOBT, SFCC can also
be computed alternatively in reference to the block-based
computation of feature. The proposed feature SOBT is the
combination of SFCC and MOBT features. In this feature, the
scale of the ﬁlter bank is generated in a speech-signal-based
adaptive manner. The inverted version of this feature is also
introduced, which can be called as ISOBT.

III. EXPERIMENTAL SETUP

S(n, w) =

1
N

|X(n, w)|2,

(1)

A. Speech Corpora

where N is the number of samples in analysis window. By
averaging S(n, w) over the entire speech corpus, ensemble
energy ¯S(w) is calculated. A logarithm of the ensemble
average spectrum is calculated and divided into equal area,
such that

Ai = Z wi+1

wi

log ¯S(w)dw,

i = 1, . . . , M,

(2)

The experiment for the performance evaluation of several
anti-spooﬁng methods has been conducted on recently released
ASVspoof 2015 corpus whose detailed description is available
in [34]. The synthetic speech is generated by ﬁve different
techniques as follows: frame selection (FS) based VC algo-
rithm (S1), ﬁrst mel-cepstral (C1) based VC algorithm (S2),
HMM-based synthesis algorithm (S3 and S4) and lastly, VC
toolkit within Festvox system (S5). The database contains

human and spoofed speech data for both the training and
development set. Training data consists of 3750 utterances for
human and 12625 for spoofed speech signals. Development
data set contains 3497 utterances for genuine and 49875
utterances for synthetic speech.

B. Parameters of Feature Extraction

Features are extracted from speech frames with frame size
20 ms and of overlap 50%. Windowing is performed using
Hamming window [35]. Voice activity detector (VAD) [36]
is not used for all the experiments performed. We have also
included the energy coefﬁcients in speech feature computation.
For all the experiments, 20-dimensional short-term features
(MFCC, MOBT and SFCC) vectors are used along with their
delta (20) and double delta (20) coefﬁcients. Static, static and
dynamic and only dynamic feature elements are incorporated
for anti-spooﬁng operation. Dynamic feature is calculated
using three consecutive speech frames. On the other hand in
MOBT, two blocks are set to contain seven and ﬁfteen number
of ﬁlters. Static, static+∆∆2 and only ∆∆2 feature vectors
of dimension 22, 66 an 44 are considered respectively for
overlapped block transformation features. The frequency bands
covered by the two segments are 0 − 1128 Hz and 575 − 8000
Hz respectively. They are dominated by the ﬁrst three formants
(F 1) and (F 2), (F 3). The ﬁlter bank of the SFCC and ISFCC
features are generated using training data set of the database
and after that cepstral features are computed.

C. Classiﬁer

Proposed and existing features are evaluated using GMM-
ML classiﬁer since it is widely used for speaker veriﬁcation
systems. Ten iterations of expectation-maximization (EM)
[37] algorithm are used to estimate each class parameters
via maximum-likelihood criteria. The number of Gaussian
components is set as 512. Two target models λnatural and
λsynthetic are created from natural and synthetic speech data
respectively. The log-likelihood score is calculated as,

Λ(X) = L(X|λnatural) − L(X|λsynthetic),

(5)

where X = {x1, . . . , xT } is the feature matrix of the
test utterance, T is the number of frames and L(X|λ) =
t=1 log p(xt|λ) is the average log-likelihood of X
given GMM model λ. In our experiment, all the training data
is used for modeling and development data is used for testing
purpose.

(1/T )PT

D. Performance Evaluation Metric

Equal error rate (EER) is used as the performance metric to
evaluate the spooﬁng attack detection. We use Bosaris toolkit
1 to calculate the EER using receiver operating characteristics
convex hull (ROCCH) method. The lower the value of EER,
better is the anti-spooﬁng performance. The average and indi-
vidual EER are reported for all kind of VC and SS algorithms
[38].

1https://sites.google.com/site/bosaristoolkit/

TABLE I

COMPARATIVE ACCURACY (EER IN %) OF EXISTING AND PROPOSED
CEPSTRAL FEATURES FOR GMM-ML CLASSIFIER IN ASVSPOOF 2015

CORPORA

Feature

Type

Static

MFCC

Static+∆∆2

∆∆2

Static

MOBT

Static+∆∆2

∆∆2

Static

SFCC

Static+∆∆2

∆∆2

Static

S1

S2

S3

S4

S5

Avg.

0.981

11.720

0.000

0.000

6.030

3.746

0.036

0.037

4.597

0.657

0.000

0.000

0.649

1.056

0.000

0.000

0.020

0.143

0.897

10.451

0.000

0.000

4.714

0.016

0.016

3.290

0.455

0.000

0.000

0.349

0.000

0.000

0.017

3.212

0.731

0.098

2.395

18.402

0.000

0.000

5.750

5.309

0.025

0.062

7.718

2.205

0.000

0.000

0.582

1.665

0.000

0.000

0.077

0.469

2.360

16.664

0.000

0.000

5.851

4.975

SOBT

Static+∆∆2

∆∆2

0.037

0.053

6.038

1.555

0.000

0.000

0.326

1.280

0.000

0.000

0.154

0.352

TABLE II

COMPARATIVE ACCURACY (EER IN %) OF EXISTING AND PROPOSED

INVERTED CEPSTRAL FEATURES FOR GMM-ML CLASSIFIER IN

ASVSPOOF 2015 CORPORA

Feature

Type

Static

S1

S2

S3

S4

S5

Avg.

0.142

4.777

0.000

0.000

3.215

1.627

IMFCC

Static+∆∆2

0.017

1.749

0.000

0.000

0.252

0.404

∆∆2

Static

0.030

0.141

0.039

0.057

0.000

0.042

0.000

0.290

0.000

0.000

1.673

0.393

IMOBT

Static+∆∆2

0.000

0.078

0.000

0.000

0.047

0.025

∆∆2

Static

0.000

0.000

0.000

0.000

0.000

0.000

0.037

1.585

0.000

0.000

0.835

0.491

ISFCC

Static+∆∆2

0.000

0.587

0.000

0.000

0.089

0.135

∆∆2

Static

0.000

0.107

0.037

0.045

0.024

0.043

0.000

0.104

0.000

0.000

0.399

ISOBT

Static+∆∆2

0.000

0.009

0.000

0.000

0.010

∆∆2

0.000

0.000

0.000

0.000

0.000

0.101

0.004

0.000

IV. RESULTS AND DISCUSSION

The performance evaluation of several short-term spectral
features in the anti-spooﬁng systems for different synthetic
data is shown in Table I. The results are reported for various
feature combinations like static, static+∆∆2 and ∆∆2. Table
I shows that both the S3 and S4 synthetic data are easy to
detect than all other different features. We observe that the
performance of the spooﬁng detector to distinguish between
natural and synthetic speech data increases with addition of
∆∆2 to static features. The table also illustrates that amongst
the four different features, the MOBT feature yields less EER
value than other features. This can be probably explained

by the fact
that MOBT features extract formant speciﬁc
speech information more efﬁciently, where the discriminative
information resides. The table also shows that our GMM-ML
recognizer with all the features faces difﬁculty in classiﬁcation
for S2 converted data.

In order to further reduce the EER value of the anti-spooﬁng
system, we also incorporated the inverted version of the above
mentioned features. The results are shown in Table II. The
table shows that features in inverted scale further reduce the
EER value for all sets of synthetic data. We also ﬁnd that
the newly formulated IMOBT and ISFCC features outperform
existing IMFCC. The best result is obtained for our proposed
feature, i.e. ISOBT. It produces zero EER value or 100% ac-
curacy in classiﬁcation for ∆∆2 case which is better than any
results given in Table II [34] . The usefulness of the inverted
feature over static and dynamic features in our classiﬁcation
task can be justiﬁed by the fact that discriminative information
between natural and synthetic data lies in the high-frequency
region of the spectrum. Usually in all the speech synthesis and
voice conversion techniques, the high frequency components
of the speech signal are not considered properly. The more
visible formant structure in the high-frequency component in
the natural speech signal is distorted in the synthetic speech
signal. In inverted feature extraction, the ﬁlter bank is applied
on the ﬂipped version of the spectrum. Therefore, it captures
high-frequency information more accurately.

V. CONCLUSION

In this paper, we have investigated features for efﬁciently
detecting speech-based spooﬁng attacks. The important ﬁnd-
ings of our study can be summarized as follows:

• Importance of high-frequency components: It is found
that high frequency regions are more informative for
recognizing synthetic speech. The experimental results
show that speech parameterizations using inverted-scale
perform better than their conventional formulations.

• Usefulness of dynamic coefﬁcients: Dynamic features
give better performance than static as well as combi-
nation features. From these results we can conclude
that dynamic component of all the studied (existing and
proposed) features carry more discriminative information
for the classiﬁcation of human and synthetic speech.

• Effectiveness of block transformation: The block-based
features are computed using segment wise transformation
of log energies unlike full-band DCT. Each block contains
formant-speciﬁc spectral information. In our study, we
ﬁnd that block-based approach gives better improvement
in spooﬁng detection.

• Improvement with speech-frequency-based frequency
warping: We have also investigated that ﬁlter bank
generated from speech-signal-based warped frequency
scale improves the accuracy of spooﬁng detection than
conventional mel-frequency based computing.

Based on the above ﬁndings, we have introduced novel
speech features which are dynamic coefﬁcients of cepstral

features that are computed by formant-speciﬁc block transfor-
mation of log energies derived using inverted speech-signal-
based warping method. Proposed features yield 0% classiﬁca-
tion error rate in the experiments conducted on development
section of ASVspoof 2015 corpus. Even though we are able to
accurately classify synthetic speech for ﬁve different spooﬁng
attacks,
it is to be noted that all the spooﬁng techniques
tested here are known i.e. similar types of spoofed speech ﬁles
are used for training. Therefore, it is interesting to study the
performance of the proposed features in presence of unknown
spooﬁng attacks. In future, experiments will be conducted on
the evaluation part of the database which contains additional
test data as well as data from unseen spooﬁng attacks.

ACKNOWLEDGEMENT

This work is partially supported by Indian Space Research
Organization (ISRO), Government of India. We would also
like to thank Dr. Md Sahidullah from University of Eastern
Finland, Finland for his valuable suggestions.

REFERENCES

[1] Y. Stylianou, O. Capp´e, and E. Moulines, “Continuous probabilistic
transform for voice conversion,” Speech and Audio Processing, IEEE
Transactions on, vol. 6, no. 2, pp. 131–142, 1998.

[2] E. Moulines and F. Charpentier, “Pitch-synchronous waveform pro-
cessing techniques for text-to-speech synthesis using diphones,” Speech
communication, vol. 9, no. 5, pp. 453–467, 1990.

[3] A. Kain and M. W. Macon, “Spectral voice conversion for text-to-
speech synthesis,” in Acoustics, Speech and Signal Processing, 1998.
Proceedings of the 1998 IEEE International Conference on, vol. 1.
IEEE, 1998, pp. 285–288.

[4] T. Toda, H. Saruwatari, and K. Shikano, “Voice conversion algorithm
based on Gaussian mixture model with dynamic frequency warping
of straight spectrum,” in Acoustics, Speech, and Signal Processing,
2001. Proceedings.(ICASSP’01). 2001 IEEE International Conference
on, vol. 2.

IEEE, 2001, pp. 841–844.

[5] D. S¨undermann, H. H¨oge, A. Bonafonte, H. Ney, A. Black, and
S. Narayanan, “Text-independent voice conversion based on unit selec-
tion,” in Acoustics, Speech and Signal Processing, 2006. ICASSP 2006
Proceedings. 2006 IEEE International Conference on, vol. 1.
IEEE,
2006.

[6] T. Yoshimura, K. Tokuda, T. Masuko, T. Kobayashi, and T. Kitamura,
“Simultaneous modeling of spectrum, pitch and duration in HMM-based
speech synthesis,” Proceedings of 6th European Conference on Speech
Communication and Technology.

[7] M. Tamura, T. Masuko, K. Tokuda, and T. Kobayashi, “Speaker adap-
tation for HMM-based speech synthesis system using MLLR,” in the
third ESCA/COCOSDA Workshop (ETRW) on Speech Synthesis, 1998.
[8] T. Kinnunen, Z.-Z. Wu, K. A. Lee, F. Sedlak, E. S. Chng, and H. Li,
“Vulnerability of speaker veriﬁcation systems against voice conversion
spooﬁng attacks: The case of telephone speech,” in Acoustics, Speech
and Signal Processing (ICASSP), 2012 IEEE International Conference
on.

IEEE, 2012, pp. 4401–4404.

[9] Z. Wu, N. Evans, T. Kinnunen, J. Yamagishi, F. Alegre, and H. Li,
“Spooﬁng and countermeasures for speaker veriﬁcation: a survey,”
Speech Communication, vol. 66, pp. 130–153, 2015.

[10] Z. Wu, C. E. Siong, and H. Li, “Detecting converted speech and
natural speech for anti-spooﬁng attack in speaker recognition.” in
INTERSPEECH, 2012.

[11] P. L. De Leon, M. Pucher, J. Yamagishi, I. Hernaez, and I. Saratxaga,
“Evaluation of speaker veriﬁcation security and detection of HMM-
based synthetic speech,” Audio, Speech, and Language Processing, IEEE
Transactions on, vol. 20, no. 8, pp. 2280–2290, 2012.

[12] J. Sanchez, I. Saratxaga, I. Hernaez, E. Navas, D. Erro, and T. Raitio,
“Toward a universal synthetic speech spooﬁng detection using phase
information,” Information Forensics and Security, IEEE Transactions
on, vol. 10, no. 4, pp. 810–820, 2015.

[34] Z. Wu, T. Kinnunen, N. Evans, J. Yamagishi, C. Hanilc¸i, M. Sahidul-
lah, and A. Sizov, “Asvspoof 2015:
the ﬁrst automatic speaker
veriﬁcation spooﬁng and countermeasures challenge,” online link:
http://www.spooﬁngchallenge.org/is2015 asvspoof.pdf , vol. 10, no. 15,
p. 3750.

[35] M. Sahidullah and G. Saha, “A novel windowing technique for efﬁcient
computation of MFCC for speaker recognition,” Signal Processing
Letters, IEEE, vol. 20, no. 2, pp. 149–152, 2013.

[36] ——, “Comparison of speech activity detection techniques for speaker

recognition,” arXiv preprint arXiv:1210.0297, 2012.

[37] D. Reynolds and R. C. Rose, “Robust text-independent speaker iden-
tiﬁcation using Gaussian mixture speaker models,” Speech and Audio
Processing, IEEE Transactions on, vol. 3, no. 1, pp. 72–83, 1995.

T. Kinnunen,
2015:

J. Yamagishi,
[38] Z. Wu,
spooﬁng
“Asvspoof
and
link:
http://www.spooﬁngchallenge.org/asvSpoof.pdf , vol. 10, no. 15, p.
3750, 2014.

Evans,
speaker
evaluation

Automatic
challenge

countermeasures

N.

and
veriﬁcation

plan,”

online

[13] Z. Wu, T. Kinnunen, E. S. Chng, H. Li, and E. Ambikairajah, “A study
on spooﬁng attack in state-of-the-art speaker veriﬁcation: the telephone
speech case,” in Signal & Information Processing Association Annual
Summit and Conference (APSIPA ASC), 2012 Asia-Paciﬁc.
IEEE, 2012,
pp. 1–5.

[14] Z. Wu, X. Xiao, E. S. Chng, and H. Li, “Synthetic speech detection
using temporal modulation feature,” in Acoustics, Speech and Signal
Processing (ICASSP), 2013 IEEE International Conference on.
IEEE,
2013, pp. 7234–7238.

[15] P. L. De Leon, B. Stewart, and J. Yamagishi, “Synthetic speech dis-
crimination using pitch pattern statistics derived from image analysis.”
in INTERSPEECH, 2012.

[16] F. Alegre, R. Vipperla, and N. Evans, “Spooﬁng countermeasures for the
protection of automatic speaker recognition systems against attacks with
artiﬁcial signals,” in INTERSPEECH 2012, 13th Annual Conference of
the International Speech Communication Association, 2012.

[17] F. Alegre, A. Amehraye, and N. Evans, “Spooﬁng countermeasures to
protect automatic speaker veriﬁcation from voice conversion,” in Acous-
tics, Speech and Signal Processing (ICASSP), 2013 IEEE International
Conference on.

IEEE, 2013, pp. 3068–3072.

[18] ——, “A one-class classiﬁcation approach to generalised speaker veri-
ﬁcation spooﬁng countermeasures using local binary patterns,” in Bio-
metrics: Theory, Applications and Systems (BTAS), 2013 IEEE Sixth
International Conference on.

IEEE, 2013a, pp. 1–8.

[19] F. Alegre, R. Vipperla, A. Amehraye, and N. Evans, “A new speaker
veriﬁcation spooﬁng countermeasure based on local binary patterns,”
in INTERSPEECH 2013, 14th Annual Conference of the International
Speech Communication Association, Lyon: France (2013), 2013b, p. 5p.
[20] M. Pal and G. Saha, “On robustness of speech based biometric systems
against voice conversion attack,” Applied Soft Computing, vol. 30, pp.
214–228, 2015.

[21] M. Sahidullah, T. Kinnunen, and C. Hanilc¸i, “A comparison of features
for synthetic speech detection,” in Sixteenth Annual Conference of the
International Speech Communication Association, 2015.

[22] C. Hanilc¸i, T. Kinnunen, M. Sahidullah, and A. Sizov, “Classiﬁers
for synthetic speech detection: A comparison,” in Sixteenth Annual
Conference of the International Speech Communication Association,
2015.

[23] T. Kinnunen and H. Li, “An overview of text-independent speaker
recognition: From features to supervectors,” Speech communication,
vol. 52, no. 1, pp. 12–40, 2010.

[24] J. P. Campbell Jr, “Speaker recognition: A tutorial,” Proceedings of the

IEEE, vol. 85, no. 9, pp. 1437–1462, 1997.

[25] M. Sahidullah and G. Saha, “Design, analysis and experimental evalu-
ation of block based transformation in MFCC computation for speaker
recognition,” Speech Communication, vol. 54, no. 4, pp. 543–565, 2012.
[26] S. B. Davis and P. Mermelstein, “Comparison of parametric repre-
sentations for monosyllabic word recognition in continuously spoken
sentences,” Acoustics, Speech and Signal Processing, IEEE Transactions
on, vol. 28, no. 4, pp. 357–366, 1980.

[27] A. Poddar, M. Sahidullah, and G. Saha, “Performance comparison of
speaker recognition systems in presence of duration variability,” in India
IEEE, 2015 (Accepted).
Conference (INDICON), 2015 Annual IEEE.
text-
independent speaker identiﬁcation by combining MFCC with evidence
from ﬂipped ﬁlter banks,” International Journal of Signal Processing,
vol. 4, no. 2, pp. 114–122, 2007.

[28] S. Chakroborty, A. Roy, and G. Saha, “Improved closed set

[29] S. Chakroborty, “Some studies on acoustic feature extraction, feature
selection and multi-level fusion strategies for robust text-independent
speaker identiﬁcation,” Ph.D. dissertation, Indian Institute of Technology
Kharagpur, 2008.

[30] M. Sahidullah, “Enhancement of speaker recognition performance using
block level, relative and temporal information of subband energies,” PhD
Thesis, Indian Institute of Technology Kharagpur, India, January 2015.
[31] D. O’shaughnessy, Speech communication: human and machine. Uni-

versities press, 1987.

[32] K. Paliwal, B. Shannon, J. Lyons, and K. W´ojcicki, “Speech-signal-
based frequency warping,” Signal Processing Letters, IEEE, vol. 16,
no. 4, pp. 319–322, 2009.

[33] S. K. Sarangi and G. Saha, “A novel approach in feature level for robust
text-independent speaker identiﬁcation system,” in Intelligent Human
Computer Interaction (IHCI), 2012 4th International Conference on.
IEEE, 2012, pp. 1–5.

