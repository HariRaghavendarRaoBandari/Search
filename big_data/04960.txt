6
1
0
2

 
r
a

 

M
6
1
 
 
]
h
p
-
h
t
a
m

[
 
 

1
v
0
6
9
4
0

.

3
0
6
1
:
v
i
X
r
a

LOCAL EQUILIBRIUM IN INHOMOGENEOUS STOCHASTIC

MODELS OF HEAT TRANSPORT

P´ETER N ´ANDORI

Abstract. We extend the duality of Kipnis Marchioro and Presutti [KMP82]
to inhomogeneous lattice gas systems where either the components have dif-
ferent degrees of freedom or the rate of interaction depends on the spatial
location. Then the dual process is applied to prove local equilibrium in
the hydrodynamic limit for some inhomogeneous high dimensional systems
and in the nonequilibrium steady state for one dimensional systems with
arbitrary inhomogeneity.

1. Introduction

Describing the emergence of local equilibrium in systems forced out of equi-
librium is one of the main challenges of nonequilibrium statistical mechanics.
Most mathematical works concern stochastic interacting particle systems as
they are generally more tractable than the deterministic ones. Despite the big
amount of recent work in this ﬁeld, little is known for systems with spatial
inhomogeneity.

The present paper extends the classical duality result of Kipnis Marchioro
and Presutti [KMP82] to inhomogeneous systems, where the inhomogeneity
means that either (A) the components of the system have diﬀerent degrees of
freedom or (B) the interaction rate between the components depends on their
location. The dual process is roughly speaking a collection of biased random
walkers that interact with one another once their distance is not bigger than
1, and are completely independent otherwise. We leverage the dual process to
prove the existence of local equilibrium in several cases. Some of these results
were announced in [LNY15]. The systems we consider are somewhat similar
to the ones recently introduced in [CGRS15], but are not the same.

1.1. Informal description. To ﬁx notation, we denote by Γ(α, c) the prob-
ability distribution with density xα−1 exp(−x/c)
for x > 0, where α > 0 is the
shape parameter and c > 0 is the scale parameter (Γ is the usual Gamma
function). The kth moment of the Gamma distribution is

cαΓ(α)

(1)

Z ∞

0

xk+α−1 exp(−x/c)

cαΓ(α)

dx =

ckΓ(α + k)

Γ(α)

1

2

P´ETER N ´ANDORI

The Beta(α, β) distribution with parameters α, β > 0 has density Γ(α+β)
x)β−1 for x > 0. For brevity, we will write B(α, β) = Γ(α)Γ(β)
Γ(α+β) .

Γ(α)Γ(β) xα−1(1−

Our model can be informally described as follows. First consider two systems
with degrees of freedom ωi and energy ξi for i = 1, 2. Now let the two systems
exchange energies by a microcanonical procedure: redistribute the total energy
according to the law of equipartition. Representing the energy per the jth
j for j = 1, ..., ω1 + ω2, ~X is thus uniformly distributed
degree of freedom by X 2
on the sphere (ξ1 + ξ2)Sω1+ω2−1. Writing ~X = (ξ1 + ξ2)~Y /k~Y k, where ~Y has
ω1 + ω2 dimensional standard normal distribution, the ﬁrst system’s energy is
updated to

ξ′1 = X 2

1 + ... + X 2

ω1 =

(ξ1 + ξ2)(Y 2

1 + ... + Y 2
ω1)

Y 2
1 + ... + Y 2

ω1+ω2

which is well known to have (ξ1 + ξ2)Beta(ω1/2, ω2/2) distribution.

In the simplest case, our model consists of a one dimensional chain of sys-
tems located at sites 1, 2, ..., L − 1 and possibly having diﬀerent degrees of
freedom. Then we choose pairs of nearest neighbors randomly and update
their energies by the above rule. Furthermore, the systems at site 1 and L− 1
are coupled to heat baths of diﬀerent temperature. Then we study the macro-
scopic energy propagation and the emergence of local equilibrium. The special
case of constant 2 degrees of freedom is [KMP82], while systems with (arbi-
trary) constant degrees of freedom have been studied in [CGRS15]. A chain
of alternating billiard particles (2 degrees of freedom) and pistons (1 degree of
freedom), has been proposed in [BGNSzT15]. There, the energies are updated
via a much more complicated deterministic rule.

Finally, we consider two more generalizations: (A) to higher dimensions and

(B) to inhomogeneity in the rate of interaction.

1.2. Random walks end electrical networks. Here, we review the con-
nection between one dimensional random walks and electrical networks as we
will need them in the study of the dual process. The connection extends to
much more general graphs than Z1, see e.g.
[K14], Section 19. Assume that
the weights (conductances) wi+1/2, i = A, A + 1, ..., B, are given and a random
walker Sk is deﬁned on the set {A, A + 1, ..., B} by S(0) = I and
P(Sk = i+1|Sk = i) =
, P(Sk = i−1|Sk = i) =

wi−1/2 + wi+1/2
for all i = A + 1, ..., B − 1 (the states A and B are absorbing). Then the
resistances Ri+1/2 = 1/wi+1/2 and the hitting probability

wi−1/2 + wi+1/2

wi+1/2

wi−1/2

p = P(min{k : Sk = 0} < min{k : Sk = N})

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

3

are connected by the well known formula

(2)

.

i=I Ri
i=A Ri

p = PB−1
PB−1

Finally, to ﬁx terminology, we denote by SSRW the simple symmetric ran-
dom walk, i.e. a random walk with independent steps, uniformly distributed
on the neighbors of the origin in Zd.

1.3. Organization. The rest of the paper is organized as follows. We deﬁne
our model precisely in Section 2.
In Section 3, the dual process is deﬁned
and the duality relation is proved. In Section 4 the main results, namely local
equilibrium in the hydrodynamic limit in dimension ≥ 2 and in the nonequi-
librium steady state in dimension 1, are formulated. Section 5 contains the
proofs of the theorems concerning the hydrodynamic limit, namely Theorems
1 and 2, except for the proof of Proposition 6. Then Proposition 6 is proved
in Section 6 (except for the proof of Lemma 6). Section 7 is the proof of Theo-
rem 3, which is the case of nonequilibrium steady state. Finally, the Appendix
contains the proof of Lemma 6.

2. The model

Let us ﬁx a dimension d ≥ 1, and D ⊂ Rd, a bounded, connected open set
for which ∂D is a piecewise C2 submanifold with no cusps. We prescribe a
continuous function T : Rd \ D → R+ to be thought of as temperature. For
L ≫ 1, the physical domain of our system is

DL = LD ∩ Zd .

At each lattice point z ∈ DL (which will be called a site) there is a physical
system of ωz degrees of freedom. The rate of interaction along the edge e =
(u, v) ∈ E(DL) is denoted by re = r(u,v) (here, E(DL) is the set of edges
of the lattice Zd restricted to DL). Finally, we also ﬁx rates of interaction
between boundary sites and the heat bath: r(u,v) for u ∈ DL, v ∈ Zd \DL with
ku − vk = 1.
Throughout this paper, | · | denotes the cardinality of a ﬁnite set, and for
v ∈ Rd, hvi is its closest point in Zd.

The time evolution of the energies X(t) = X (L)(t) = (ξ(L)

v

Markov process with generator

(t))v∈DL is a

(Gf )(ξ) = (G1f )(ξ) + (G2f )(ξ),

where G1 describes interactions within DL and G2 stands for interaction with
the bath. We deﬁne G1 as follows. There is an exponential clock at each
edge e = (u, v) ∈ E(DL) of rate e(u,v). When it rings, the energies of the

L(cid:1)(cid:1). That is,
X

u∈DL,v∈Zd\DL,ku−vk=1

(G2f )(ξ) =

where

ωu

ωu

η

T( v

L)(cid:21)
2 −1 exp(cid:20)− η
2 Γ(cid:0) ωu
(cid:2)T (cid:0) v
L(cid:1)(cid:3)
2 (cid:1)
if w 6= u
if w = u.

0

r(u,v)Z ∞
ξ′′w =(cid:26) ξw

η

[f (ξ′′) − f (ξ)]dη

4

P´ETER N ´ANDORI

two corresponding systems (ξu and ξv) are pooled together and redistributed
according to a Beta(ωu/2, ωv/2) distribution. Thus

where

(G1f )(ξ) = X(u,v)∈E(DL)
ξ′w =


r(u,v)Z 1

0

1
2 , ωv

2 (cid:1)

B(cid:0) ωu

ξw
p(ξu + ξv)
(1 − p)(ξu + ξv)

p

ωu

2 −1(1 − p)

ωv

2 −1[f (ξ′) − f (ξ)]dp

if w /∈ {u, v}
if w = u
if w = v.

Every edge e = (u, v) where u ∈ DL and v ∈ Zd \ DL provides connection
to the heat bath of temperature T (v/L): with rate r(u,v), ξu is updated to
Γ(cid:0) ωu

2 , T (cid:0) v

This completes the deﬁnition of X (L)(t).

3. The dual process

As mentioned in the Introduction, we want to understand the asymptotic
behavior of X(t) by switching to a dual process. This section is devoted to
the discussion of duality.

For D ⊂ Rd and L as in Section 2, we now introduce a Markov process
v (t))v∈BL) designed to carry certain dual object,

Y (L)(t) = ((n(L)
which we call particles, from sites in DL to

v (t))v∈DL, (ˆn(L)

BL = {v ∈ Zd \ DL : ∃v ∈ DL : ku − vk = 1}.

Here, nv the number of particles at site v ∈ DL and ˆnw the number of particles
permanently drooped oﬀ to the storage at w ∈ BL. The generator of the
process Y (t) is given by

(Af )(n) = (A1f )(n) + (A2f )(n),

where A1 corresponds to movements inside DL and A2 corresponds to the
process of dropping oﬀ the particles to the storage. That is,

r(u,v)

nv+nw

(A1f )(n) = X(u,v)∈E(DL)
Xk=0 (cid:18)nu + nv

k (cid:19)B(k + ωu

2 , nu + nv − k + ωv
2 )
B( ωu

2 , ωv
2 )

[f (n′) − f (n)]

where

(3)

n′w =


LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

5

nw
k
nv + nw − k

if w /∈ {u, v}
if w = u.
if w = v.

and

ˆn′w = ˆnw∀w ∈ BL.

Recall that in case of the process X, the energies are redistributed according
to a beta distribution with parameters ωu/2, ωv/2. In case of the dual process
Y , we redistribute the particles with the so called beta binomial distribution:
ﬁrst we choose a p according to Beta(ωu/2, ωv/2), then we choose n′u with
binomial distribution of parameters nu + nv, p and n′v = nu + nv − n′u.
The second part of the generator is given by

(A2f )(n) =

Xu∈DL,v∈BL,ku−vk=1

r(u,v)[f (n′) − f (n)]

where

n′w =(cid:26) nw

0

if w 6= u
if w = u.

and

ˆn′w =(cid:26)

ˆnw
ˆnv + nu

if w 6= v
if w = v

This completes the deﬁnition of Y (L)(t).

Now we turn to the duality. Let us deﬁne the function with respect to which

the duality holds

(4)

F (n, ξ) = Yu∈DL

ξnu
u Γ(ωu/2)

Γ(nu + ωu/2) Yv∈BLhT (cid:16) v

L(cid:17)iˆnv

The duality with respect to F means that

Proposition 1. For any ξ any n and any t > 0,

E(F (n, X(t))|X0 = ξ) = E(F (Y (t), ξ)|Y0 = ξ)

Proof. Clearly it is enough to prove that for any ξ and n,

GF (ξ, n) = AF (ξ, n).

To prove this, we consider the following two cases, where Case i corresponds
to Gi and Ai for i = 1, 2.

Case 1. The clock on the edge (u, v) rings. The term corresponding to u and
v in G1F can be written as r(u,v) · I · II, where

and

I = Γ(ωu/2)Γ(ωv/2) Yw∈DL\{u,v}
II = R 1
2 −1(1 − p)nv+ ωv

0 pnu+ ωu

2 −1

Γ(nu + ωu

ξnw
w Γ(ωw/2)

L(cid:17)iˆnw

Γ(nw + ωw/2) Yw∈BLhT (cid:16)w
2 ) (ξu + ξv)nu+nvdp − ξnu

1
2 , ωv
B( ωu
2 )Γ(nv + ωv
2 )

u ξnv
v

6

P´ETER N ´ANDORI

Then we compute

=

II +

ξnu
u ξnv
v
2 )Γ(nv + ωv
Γ(nu + ωu
2 )
1
2 , ωv
B( ωu
2 )
1
2 , ωv
B( ωu
2 )

Γ(nu + nv + ωu+ωv

Γ(nu + nv + ωu+ωv

1

1

2

2

)

)

=

=

(ξu + ξv)nu+nv

nu+nv

u ξnv
v

Xk=0 (cid:18)nu + nv

k (cid:19)ξnu
, nu + nv − k +

nu+nv

=

1
2 , ωv
B( ωu
2 )

Xk=0 (cid:18)nu + nv

2 (cid:17)
Thus r(u,v) · I · II is the term corresponding to u and v in A1F .

k (cid:19)B(cid:16)k +

ωu
2

ωv

ξnu
u

ξnv
v

Γ(k + ωu
2 )

Γ(n − k + ωv
2 )

Case 2. The energy at site u ∈ DL is updated by the heat bath at v ∈ BL
(where ku − vk = 1). As before, we write the term corresponding to (u, v) in
G2F as r(u,v) · I · II, where
I = Yu′∈DL\{u}

Γ(nu′ + ωu′/2) Yv′∈BL\{v}(cid:20)T (cid:18) v′

L(cid:19)(cid:21)ˆnv′

ξnu′
u′ Γ(ωu′/2)

and

II =

Γ( ωu
2 )
Γ(nu + ωu
2 )

By (1), we obtain that


Z ∞


0

ηnu+ ωu

T( v

L)(cid:21)
2 −1 exp(cid:20)− η
(cid:2)T (cid:0) v
2 Γ(cid:0) ωu
L(cid:1)(cid:3)
2 (cid:1)

ωu

II +

u Γ( ωu
ξnu
2 )
Γ(nu + ωu

=hT (cid:16) v
Thus r(u,v) · I · II is the term corresponding to v in A2F .

2 )hT (cid:16) v

L(cid:17)iˆnv

hT (cid:16) v

L(cid:17)iˆnv

u 
dη − ξnu

L(cid:17)iˆnv+nu

(cid:3)

Note that the process Y preserves the total number of particles, which will
be denoted be N. We conclude this section with the following simple lemma.

Lemma 1. The restriction of the process Y to arbitrary subset of K particles
(with K < N) is also a Markov process and satisﬁes the deﬁnition of Y with
N replaced by K.

Proof. Without loss of generality, we can consider a system with K = N − 1
particles, assume that the clock attached to the edge (v, w) rings and the union
of the particles at sites u and v prior to the mixing are labeled {1, . . . , n}.

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

7

Then the probability that after the mixing, the set of particles at site u is

exactly {j1, ...jl} ⊂ {1, 2, ..., n} is given by
(5)

p(j1, ..., jl) =(cid:18)n

l(cid:19) Γ(l + ωu/2)Γ(n − l + ωv/2)

Γ(n + ωu/2 + ωv/2)

Γ(ωu/2 + ωv/2)
Γ(ωu/2)Γ(ωv/2)

1

(cid:0)n
l(cid:1)

Now assume we add a new particle (of index N). If this new particle is not
at sites u or v, then clearly the situation is not disturbed. If it is there, we
compute

(6)

p(j1, ..., jl) + p(j1, ..., jl, N + 1) =
Γ(l + ωu/2)Γ(n + 1 − l + ωv/2)

Γ(n + 1 + ωu/2 + ωv/2)
Γ(l + 1 + ωu/2)Γ(n − l + ωv/2)

+

Γ(n + 1 + ωu/2 + ωv/2)

Γ(ωu/2 + ωv/2)
Γ(ωu/2)Γ(ωv/2)

Γ(ωu/2 + ωv/2)
Γ(ωu/2)Γ(ωv/2)

An elementary computation shows that (5) is equal to (6). The lemma follows.
(cid:3)

4. Local Equilibrium

Let d, D and L be as before such that DL is connected.
First we state the existence and uniqueness of invariant measure in the

equilibrium case.
Proposition 2. Fix arbitrary functions ω : DL → Z+ and r : E(DL) → R+.
If T is constant, then

µ(L)

e = Yv∈DL

Γ(cid:18)ωv

2

,

1

T(cid:19)

is the unique invariant probability measure of the process X (L)(t).

Proof. The discussion in Section 1.1 implies the following statement (which
is actually well known, see e.g. Lemma 3 in [CHS81]). Let ξ1 and ξ2 be
independent Gamma distributed random variables with shape parameter k
and l, respectively and with the same scale parameter. Let Z be independent
from X and Y and have Beta distribution with parameters k/2 and l/2. Then
the pair (Z(ξ1 + ξ2), (1 − Z)(ξ1 + ξ2)) has the same distribution as (ξ1, ξ2).
Proposition 2 follows.

(cid:3)

Our primary interest is in the out-of-equilibrium settings where the bath

temperature is non constant:
Proposition 3. Let ω : DL → Z+ and r : E(DL) → R+ be arbitrary. The pro-
cess X (L)(t) has a unique invariant probability measure µ(L). Furthermore, the
distribution of X (L)(t) converges to µ(L) as t → ∞ for any initial distribution
of X (L)(0).

8

P´ETER N ´ANDORI

We skip the proof of Proposition 3 since it is very similar to the analogous
propositions in earlier similar models, see Proposition 1.2 in [RY07], Proposi-
tion 2 in [LNY15].

4.1. Hydrodynamic limit. In order to discuss the local equilibrium in the
hydrodynamic limit, we need some deﬁnitions. First we introduce some prop-
erties of the initial measures.

Deﬁnition 1. We say that X(0) is associated with f if for any ﬁxed δ and
any k

(7)

E  k
Yi=1

ξ(L)

vi (0)! ∼

k

Yi=1

ωvi
2

f (vi/L)

as L → ∞ uniformly for every v1, ..., vk ∈ DL satisfying kvi − vjk ≥ δL
for i 6= j and with some ﬁxed continuous function f : Rd → R+ such that
f|Rd\D = T
Deﬁnition 2. We say that X(0) satisﬁes the uniform moment condition if
there are constants Ck such that E(ξk
v (0)) < Ck for every L and for every
v ∈ DL.

Recall that the L´evy-Prokhorov distance is the metrization of weak conver-

gence of measures.
Deﬁnition 3. We say that X (L)(t) approaches local equilibrium in the hydro-
dynamic limit at x ∈ D and t > 0 if for any ﬁnite set S ⊂ Zd the L´evy-
Prokhorov distance of the distribution of X (L)(tL2) restricted to the compo-
nents (ξhxLi+s)s∈S and

Ys∈S
converges to zero as L → ∞.

Γ(cid:0)ωhxLi+s/2, u(t, x)(cid:1)

We will choose the initial distributions, i.e. the distributions of X (L)(0),
which are associated with a continuous function f . The interesting question
is that what kind of equation deﬁnes u for diﬀerent choices of ω and r. In
any case, we expect that the initial condition is given by f and the boundary
condition by T . We will consider the two simplest cases here.
Theorem 1. Assume d ≥ 2 and ωv = ω0 ∈ Z+ for every site v. Assume
furthermore that r(u,v) = R( u+v
2L ) for every u ∈ DL and v ∈ Zd with ku−vk = 1,
where R ∈ C2(Rd, R+). Also assume that X (L)(0) is associated with f , a
continuous function f : ¯D → R+, and satisfy the uniform moment condition.
Then X (L)(t) approaches local equilibrium in the hydrodynamic limit for all
x ∈ D and t > 0 with u the unique solution of the equation


ut = ∇(R∇u),
u(0, x) = f (x),

u(t, x)|∂D = T (x).

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

9

Remark about the initial conditions Note that f represents the energy
per degrees of freedom at time zero, that is why we need the multiplier ωv/2
on the right hand side of (7). We do not have to assume local equilibrium
at zero, which would correspond to the special choice of X(0): the product
of Gamma distributions (with shape parameter ωv/2, and scale parameter
f (v/L)). One interesting consequence of Theorem 1 (and similarly that of
Theorem 2) is that the system satisﬁes the local equilibrium for arbitrary
positive macroscopic time even if it only satisﬁes the given weaker condition
at time zero. Since we want to leverage the duality via moments, we also
need to assume some condition on the higher moments. The simplest one is
the uniform moment condition. Most probably, neither condition (7) nor the
uniform moment condition is optimal, but we do not pursue the most general
case here.

Our next choice is the simplest non-continuous environment: we consider
D = [−1, 1]d with one of the functions ω and r being constant on D and the
other one is constant on [−1, 0] × [−1, 1]d−1 and [0, 1] × [−1, 1]d−1. Thus we
have the following
Theorem 2. Let d ≥ 2, D = [−1, 1]d. Assume that X (L)(0) is associated
with f , a continuous extension of T to ¯D, and satisﬁes the uniform moment
condition
(a) Let ωv = ω−1 if v1 < 0 and ωv = ω1 if v1 ≥ 0 with some positive
integers ω−1, ω1 and let r be constant. Then X (L)(t) approaches local
equilibrium in the hydrodynamic limit for all x ∈ D with x1 6= 0 and
all t > 0 with u the unique solution of the equation

∂x1+ u(t, (0, x2, ..., xd)) = ω−1

for x ∈ D with x1 6= 0,
∂x1−

∂

∂

ut = r∆u
ω1
u(0, x) = f (x),
u(t, x)|∂D = T (x).

u(t, (0, x2, ..., xd))

(b) Let r(u,v) = r−1 if u1 + v1 < 0 and r(u,v) = r1 otherwise, where r−1, r1
are ﬁxed positive numbers. Similarly, rw = r−1 if w1 < 0 and rw = r1
otherwise. Let ω be constant. Then X (L)(t) approaches local equilib-
rium in the hydrodynamic limit for all x ∈ D with x1 6= 0 and all t > 0
with u the unique solution of the equation







∂x1+ u(t, (0, x2, ..., xd)) = r−1

u(t, (0, x2, ..., xd))

∂

∂x1−

for x ∈ D with x1 6= 0,

∂

ut = rsign(x1)∆u
r1
u(0, x) = f (x),
u(t, x)|∂D = T (x).

4.2. Nonequilibrium steady state. Now we are interested in the invariant
measure of the Markov chains for ﬁnite (but large) L. Speciﬁcally, we are
looking for a function u(x), x ∈ D such that in the limit limL→∞ limt→∞ the

10

P´ETER N ´ANDORI

local temperature exists and is given by u(x). In case the hydrodynamic limit
is known, u(x) is expected to be equal to limt→∞ u(t, x). We will choose
arbitrary environment (r and ω), that is why we deﬁne the local equilibrium
in a little more general form, namely with an L dependent u. Of course in all
natural examples, one expects u(L) to converge.

Deﬁnition 4. We say that X (L)(t) approaches local equilibrium in the nonequi-
librium steady state if for any x ∈ D and any ﬁnite set S ⊂ Zd the L´evy-
Prokhorov distance of the invariant measure of X (L)(t) restricted to the com-
ponents (ξhxLi+s)s∈S and

Ys∈S
converges to zero as L → ∞.

Γ(cid:0)ωhxLi+s/2, u(L)(x)(cid:1)

Let us ﬁx d = 1 and D = (0, 1). To simplify notation, we will write rm+1/2 :=
r(m,m+1), ω0 := ω1 and ωL := ωL−1. Furthermore, we will need the following
two deﬁnitions:

ψ(m) =

ωm−1 + ωm
rm−1/2ωm−1ωm

for 1 ≤ m ≤ L

and

A(L)(x) = P⌊xL⌋m=1 ψ(m)

m=1 ψ(m)

.

PL

Theorem 3. Let d = 1 and D = (0, 1). Assume that the functions r and ω
are bounded away from zero and inﬁnity uniformly in L and the temperature
on the boundary is given by T (0), T (1) ∈ R+ ∪ {0}. Then X (L)(t) approaches
local equilibrium in the nonequilibrium steady state with

u(L)(x) = (1 − A(L)(x))T (0) + A(L)(x)T (1).

Clearly, u(L)(x) can easily diverge in this generality. That is why we consider
two special cases. In case (a), r is constant and ω is random. In this case, we
prove the quenched local equilibrium in the nonequilibrium steady state, i.e.
the almost sure convergence of u(L)(x) to a deterministic limit. In case (b), ω
is constant but r is prescribed by a non-constant macroscopic function. We
also prove that u(L)(x) converges in this case.

Proposition 4.

(a) Let r be constant, K be the maximal degrees of free-

dom and let us ﬁx some continuous function

κ : [0, 1] → {p ∈ RK : p ≥ 0,

K

Xi=1

pi = 1}.

For each L, let us choose ω(L)
another with

v

randomly and independently from one

P(ω(L)

v = i) = κi(v/L).

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

11

Then for almost every realization of the random functions ω(L),

κi(y)dy
κi(y)dy

.

1

1

0

i R x
i R 1

0

0 1/̺(y)dy
0 1/̺(y)dy

.

(b) Let ω be constant, ̺ : [0, 1] → R+ is a continuous function. For each

v+1/2 = ̺(v/L).Then

i=1

i=1

lim

L→∞A(L)(x) = PK
PK
L and v = 0, 1, ...L − 1 deﬁne r(L)
L→∞A(L)(x) = R x
R 1

lim

Before turning to the proofs of the above results, we brieﬂy comment on

some possibilities of extension.

4.3. Possible extensions. As we will see, the proof of Theorems 1 and 2 also
provides the local equilibrium in the nonequilibrium steady state.

Corollary 4. Consider the setup of either Theorem 1 or 2. Then X (L)(t)
approaches local equilibrium (assuming x1 6= 0 in case of Theorem 2) in the
nonequilibrium steady state with U(x) = limt→∞ u(t, x).

Indeed, for δ > 0 ﬁxed one can ﬁnd some t large such that with probability
at least 1 − δ, all processes in Proposition 6 have arrived at the boundary
before tL2. In such cases, ˜Y (L)
(∞), and the latter can be used
to prove local equilibrium in the nonequilibrium steady state (cf. the proof of
Theorem 3).

(tL2) = ˜Y (L)

i

i

Furthermore, it seems likely that our proof could be adapted to a version
of Theorem 2 with more general domains and with piecewise constant r and
ω (see [P90] for the extension of skew Brownian motion to such scenarios).

However, the case of more general inhomogeneity in either high dimensions
or in the hydrodynamic limit can be diﬃcult. For example, if κ is constant in
Proposition 4(a), then in order to verify the hydrodynamic limit, one would
have to compute the scaling limit of some interacting random walkers among
iid conductances, whereas even the case of one random walker is non obvious
(see [SSz04]). Clearly, the case of high dimensions or non iid environments are
even much harder.

5. Proof of Theorems 1 and 2

Since the proofs of Theorems 1 and 2 are very similar, we provide one proof
and distinguish between cases Theorems 1, 2(a) and 2(b) if necessary. Let us
ﬁx some t > 0, a point x ∈ D and a ﬁnite set S ⊂ Zd. We need to show that
the (joint) distribution of (ξhxLi+s(tL2))s∈S converges to the product of gamma
distributions with the scale parameter u(t, x). As it is well known, any product
of Gamma distributions is characterized by its moments (see [Z83]). Thus it is
enough to prove that the moments of (ξhxLi+s)s∈S converge to the product of
the moments of gamma distributions (convergence of second moments implies

12

P´ETER N ´ANDORI

tightness). When computing the moments of order n∗s ∈ N, s ∈ S, we can use
Proposition 1 to switch to the dual process.
We need to introduce some auxiliary processes. Let us denote by ˜Y the
slight variant of Y where the position of distinguishable particles are recorded.
More precisely, the phase space of ˜Y = ( ˜Y (L)
(t))0≤t,1≤i≤N is (DL∪BL)N , where

i

N =Ps∈S n∗s and the initial condition is given such that for all s ∈ S,
For any t ≥ 0 we deﬁne ˜Y (t) so that
(8) #{i : ˜Yi(t) = v ∈ DL} = nv(tk), #{i : ˜Yi(t) = v ∈ BL} = ˆnv(tk)
and for all t,

#{i : ˜Yi(0) = hxLi + s} = n∗s.

#{i : ˜Yi(t−) 6= ˜Yi(t+)} ≤ 1.

We want to show that the diﬀusively rescaled version of ˜Y converges weakly
to N independent copies of some (generalized) diﬀusion processes Y. Then the
Kolmogorov backward equation associated with these processes will provide
the function u. Clearly, the process Y will have to be stopped on ∂D. So as
to shed light on the main component of the proof, namely the convergence to
the diﬀusion process, we introduce a further simpliﬁcation by not stopping the
particles.

We can assume that R is bounded in case of Theorem 1 (possibly by mul-
tiplying with a smooth function which is constant on D and decays quickly)
and extend the deﬁnition of ωv, r(u,v) in case of Theorem 2 for any u, v ∈ Zd.
Then we consider the process Z(t) = (nv(t))v∈Zd on the space

zv ∈ Z+, Xv∈Zd

zv = N

with the generator A′1, obtained from A1 by replacingP(u,v)∈E(DL) withP(u,v)∈E(Zd).

Then we deﬁne ˜Z from Z the same way as we deﬁned ˜Y from Y . Observe
that by construction (and with the natural coupling) for N = 1 we have

(9)

˜Y (L)(s) = ˜Z(s ∧ τDL) where

τDL = min{s : ˜Z(s) /∈ DL}

Now we deﬁne the limiting process (Z(s))0≤s≤t with Z(0) = x and with the
generator

i=1 R(x) ∂2
∂x2
i
i=1 r ∂2
∂x2
i
i=1 rsign(x1)

∂2
∂x2
i

i=1

+Pd

∂R
∂xi

∂
∂xi

in Theorem 1

in Theorem 2(a)

in Theorem 2(b).

L =
Pd
Pd
Pd

(1) functions φ ∈ C2

acting on

0 in case of Theorem 1

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

13

∂

∂x1−
∂
∂x1−

φ(0, x2, ..., xd) = ω1
φ(0, x2, ..., xd) = r1

on (R− ∪ 0) × Rd−1 and (R+ ∪ 0) × Rd−1 and

(2) compactly supported continuous functions φ which admit C2 extensions
(ω−1
r−1
Note that Z is a diﬀusion process in case of Theorem 1 and a generalized
diﬀusion process in case of Theorem 2 (see [P90] for a survey on generalized
diﬀusion processes and [A78] for an early proof of the existence of Z in case
of Theorem 2(b)). Now let us stop Z on ∂D and deﬁne
(10)

in case of Theorem 2(a)
in case of Theorem 2(b)

∂
∂x1+ φ(0, x2, ..., xd)
∂
∂x1+ φ(0, x2, ..., xd)

Y(s) = Z(s ∧ τD) where

τD = min{s : Z(s) ∈ ∂D}

The connection between the processes ˜Y and the PDE’s deﬁning u is most

easily seen in the simplest case of one particle.

Let ⇒ denote weak convergence in the Skorokhod space D[0, T ] with respect
to the supremum metric and with some T to be speciﬁed. (Although we need
the Skorokhod space as the trajectories of ˜Z are not continuous, but the
limiting measures will always be supported on C[0, T ] and we can use the
supremum metric. Alternatively, one could smooth the trajectories of ˜Z and
only use the space C[0, T ].)
Lemma 2. If N = 1, then

  ˜Z(sL2)

L !0≤s≤t

⇒ (Z(s))0≤s≤t.

Proof. In the setup of Theorem 1, this follows from Theorem 11.2.3 in [SV07].
More precisely, as we can neglect events of small probability, we can assume
that (A) the particle jumps less than L3 times before tL2 and consequently
(B) the smallest time between two consecutive jumps before tL2 is bigger than
L−4. Now choosing h = L−4, ˜Z can only jump at most once on the interval
[kh, (k + 1)h] for all k < tL6. Now we choose

(cid:19)

L

z

,

,

L

L

L

z + ei

L (cid:19) = L−2R(cid:18)x + ei/2

Πh(cid:18) z
R(cid:18)x + ei/2
for any z ∈ Zd and any unit vector ei. With this choice, we easily see that
aii(x) = 2R(x) and bi(x) = ∂
R(x) at the end of page 267 in [SV07]. Applying
∂xi
Theorem 11.2.3, the Lemma follows.

L(cid:17) = 1−L−2Xei

(cid:19) , Πh(cid:16) z

In case of Theorem 2(a), we consider the ﬁrst coordinate of ˜Z and the
other d − 1 coordinates separately. Under diﬀusive scaling, the former one
converges to a skew Brownian motion by e.g. [ChShY04], while the latter one
converges to a d − 1 dimensional Brownian motion by Donsker’s theorem. A
slight technical detail is that we need to switch to discrete time so as to apply
the result of [ChShY04]. Let us thus deﬁne Z′1(k) = ˜Z1(τ1,k) for non-negative

14

P´ETER N ´ANDORI

integers k, where τ1,0 = 0 and τ1,k = min{t > τ1,k−1 : ˜Z1(t−) 6= ˜Z1(t+)}.
Then by [ChShY04] we have that

(11)

(cid:18) Z′1(sL2)

L

(cid:19)0≤s≤4rt ⇒(cid:0)SBMω1/(ω−1+ω1)(s)(cid:1)0≤s≤4rt ,

where SBMω1/(ω−1+ω1) is the skew Brownian motion with parameter ω1/(ω−1+
ω1), which is by deﬁnition equal to Z1(s)/√2r. Now observe that by the law of
large numbers, the functions s 7→ 2rτ1,sL2/(sL2) converge in probability to the
identity function on D[0, t]. Hence the statement of the Lemma, restricted to
the ﬁrst component, follows. Finally, the other components are independent
from the ﬁrst one and under diﬀusive scaling, they converge to Brownian
motion by Donsker’s theorem.

In case of Theorem 2(b) we use a similar argument to the one in the previous

paragraph. Namely, we still have the analogue of (11) and by independence

(12)

where

(cid:18) Z′(sL2)

L (cid:19)0≤s≤T ⇒(cid:0)SBMr1/(r−1+r1)(s/d),Wd−1(s/d)(cid:1)0≤s≤T ,

T = 4d max{r−1, r1}t,

Wd−1 is a d − 1 dimensional standard Brownian motion and Z′(k) = ˜Z(τk)
with τ0 = 0 and τk = min{t > τk−1 : ˜Z(t−) 6= ˜Z(t+)} for positive integers k.
The diﬀerence from the case of Theorem 2(a) is that now in order to recover
the convergence of ˜Z, we need a nonlinear time change (and consequently have
to work with all coordinates at the same time). To do so, let us introduce the
local time the ﬁrst coordinate spends on the negative and positive halﬂine:

τ+(s) =Z s
for f = (f1, ..., fd) ∈ D([0, T ], Rd). Now we can deﬁne

τ−(s) =Z s

1f1(y)<0dy,

0

1f1(y)>0dy,

0

ρ(s) = min{y :

τ−(y)
2dr−

+

τ+(y)
2dr+ ≥ s}

and

by

Θ : D([0, T ]) → D([0, 3t/2])

(Θ(f ))(s) =(f (ρ(s))

0

if τ−(T ) + τ+(T ) ≥ 3T /4
otherwise.

The function Θ is well deﬁned because of the choice of T . Let us denote by
QL and Q the measure on D[0, T ] given by the left and right hand sides of
(12). Next, we observe that

Q(τ−(T ) + τ+(T ) = T ) = 1.

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

15

and Θ is continuous on the set {τ−(T ) + τ+(T ) = T}. Now we can apply
the continuous mapping theorem (see e.g. Theorem 5.1 in [B68]) to conclude
Θ∗QL ⇒ Θ∗Q. Here, Θ∗QL is the distribution of a process ( ˆZ(s))0≤s≤3t/2
obtained from (Z′(s))0≤s≤T by rescaling time with Θ. Since Θ∗Q is the distri-
bution of Z(s), it suﬃces to show that

(13)

  ˜Z(sL2) − ˆZ(sL2)

L

!0≤s≤t

⇒ 0.

Let us introduce the notations zk = Z′(k) − Z′(k − 1), Ti = τi − τi−1. By

an elementary estimate on the local time of random walks, we have

P(#{k < tL2 : Z′(k)1 = 0} > L3/2) = o(1).

Since we prove weak convergence, we can neglect the above event and subse-
quently assume that z1, ..., ztL2 is such that the ﬁrst coordinate’s local time at
zero is smaller than L3/4. Especially, we use the ﬁrst line of the deﬁnition of
Θ when we construct ˆZ for L large. Thus with the notation

i

i

˜is = max{i :

Tj < s} ˆis = max{i :

E(Tj1{Z ′(j)16=0}|z1, ..., ztL2) < s}.

we have ˜Z(s) = Z′(˜is) and ˆZ(s) = Z′(ˆis). Now with some ﬁxed small δ let us
write

Xj=1

k

Xj=1

k∗

for k = 1, 2, ..., T /δ. Then by Chebyshev’s inequality,

X

i∈[kδL2,(k+1)δL2],Z(i)16=0

> δ3L2|z1, ..., zztL2!

<

k∗

k∗

and

X = Xi∈[kδL2,(k+1)δL2]
P (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
XTi −
δL2
4d2 min{r2
P  (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
XTi −
i=1 Ti satisfy

X =
X E(Ti|z1, ..., ztL2)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
XTi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1
δ6L4 < δ10

−1}

1, r2

for L large enough. Furthermore, by our assumption on z1, ..., ztL2,

k

k∗

> δ3L2|z1, ..., ztL2! < δ10
also holds for L large. Consequently the random times ˜sl =Pl
and ˆsl =PlL2/δ
• 0 = ˜s0 < ˜s1 < ˜s2... < ˜sT , ˜sT ≥ 3t/2 and ˜sl − ˜sl−1 < Cδ
• for all l with ˜sl < t, P(|ˆsl − ˜sl| > 2δ2) < δ8 and ˆZ(ˆslL2) = ˜Z(˜slL2)

This together with tightness of Z′ (proved in the usual way) gives (13). We
have ﬁnished the proof of Lemma 2.
(cid:3)

k=1Pk∗ E(Ti|z1, ..., ztL2)

16

P´ETER N ´ANDORI

Lemma 3. If N = 1, then

  ˜Y (L)(sL2)

L

!0≤s≤t

⇒ (Y(s))0≤s≤t.

Proof. This is a consequence of the continuous mapping theorem, Lemma 2,
(9) and (10).
(cid:3)

Next, we prove a simpler version of Theorems 1 and 2, namely the conver-

gence of the expectations

Proposition 5. Consider the setup of either Theorem 1 or Theorem 2. Then

(14)

lim
L→∞

E(cid:16)ξ(L)

hxLi

(tL2)(cid:17) = u(t, x)

ωx
2

,

where ωx = ω in case of Theorems 1 and 2(b) and = ωsign(x1) in case of
Theorem 2(a)

Proof. By Proposition 1, the left hand side of (14) is equal to

ωhxLi
2

E ξ∗˜Y (tL2)

2

ω ˜Y (tL2)

1

{ ˜Y (tL2)∈DL}

+ T   ˜Y (tL2)

L ! 1

{ ˜Y (tL2)∈BL}! =: I + II,

where ξ∗v = ξv(0).
obtain

In case of Theorems 1 and 2(b), ω is constant, thus we

P( ˜Y (tL2) = v)E(ξ∗v).

I = Xv∈DL

Recall that (7) gives E(ξ∗v) = ω
deﬁnition of the weak convergence, we obtain

2 f (v/L) + o(1). Applying Lemma 3 and the

Similarly,

I =

lim
L

II =

lim
L

ω
2

ω
2

E(f (Y(t))1{Y(t)∈D})

E(T (Y(t))1{Y(t)∈∂D})

Now the proposition follows from the fact that u(t, x) solves the Kolmogorov
equation associated with the process Y. Finally, in case of Theorem 2(a), we
consider the function h on D with h(y) = 0 if y1 < 0, h(y) = y1/δ if 0 ≤ y1 < δ
and h(y) = 1 if y1 > δ and approximate I by Ia+Ib, where Ia is obtained from
I by multiplying the integrand with h( ˜Y (tL2)/L) and Ib is obtained from I by
multiplying the integrand with h(− ˜Y (tL2)/L). Clearly, I−ε < Ia+Ib < I for
δ small enough. Then we can repeat the above argument since ω is constant
on the integration domain in both Ia and Ib.
(cid:3)

In order to complete the proof of Theorems 1 and 2, we need an extension

of Lemma 3 from N = 1 to arbitrary N:

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

17

Proposition 6. The processes

i

  ˜Y (L)

(sL2)
L

!0≤s≤t

for i = 1, ..., N converge weakly to N independent copies of (Y(s))0≤s≤t.

Now, we prove Theorems 1 and 2 assuming Proposition 6. By the discussion
at the beginning of this section and by (1), Theorems 1 and 2 will be proved
once we establish

s

ξn∗

(15)

E Ys∈S
hxLi+s(tL2)! ∼ u(t, x)NYs∈S
By Proposition 6, limL P(A(L)
δ = {k ˜Y (L)
Aδ = A(L)

δ ) = oδ(1), where
(tL2) − ˜Y (L)

j

i

Γ(n∗s + ωhxLi+s/2)

Γ(ωhxLi+s/2)

.

(tL2)k ≤ δL for some i 6= j}.

This, combined with the uniform moment condition and the Cauchy-Schwarz
inequality gives

lim
L

E(cid:0)1AδF (Y (tL2), ξ∗)(cid:1) = oδ(1),

where ξ∗v = ξv(0) and F is the duality function deﬁned in (4). Now Proposition
1 and the fact that ξ∗ is associated with f implies that the left hand side of
(15) is oδ(1) close to

Ys∈S
× E"1

Γ(n∗s + ωhxLi+s/2)
Γ(ωhxLi+s/2) ×
Yi=1 ξ∗˜Y (tL2)

Aδ

2

N

ω ˜Y (tL2)

1

{ ˜Y (tL2)∈DL}

+ T   ˜Y (tL2)

L ! 1

{ ˜Y (tL2)∈BL}!# .

Now we can cut this integral to 2N pieces and apply a version of the proof of
Proposition 5 to conclude (15).

In order to complete the proof of Theorems 1 and 2 it only remains to prove

Proposition 6, which is the subject of the next section.

6. Proof of Proposition 6

We are going to prove a variant of Proposition 6 obtained by replacing ˜Yi
and Y with ˜Z and Z. Proposition 6 follows from this variant the same way
as Lemma 3 follows from Lemma 2.
The idea of the proof is borrowed from [LNY15], Section 5: we show that
with probability close to 1, ˜Zi(s) and ˜Zj(s) will not meet after getting sep-
arated by a distance Lγ with some γ close to 1. Since ˜Zi(s) and ˜Zj(s)
move independently if their distance is bigger than 1, we can replace ˜Z(s)
for s > τ = max{τi,j} by N independent copies of ˜Z1(s), where τi,j is the ﬁrst
time s when k ˜Zi(s) − ˜Zj(s)k > Lγ.
It only remains to show that ˜Zi(τ ) is

18

P´ETER N ´ANDORI

close to xL and τ /L2 is negligible. We complete this strategy in the case of
Theorem 1, N = 2 and d = 2 in Section 6.1 and for all other cases in Section
6.2.

6.1. Case of Theorem 1, N = 2 and d = 2. Recalling the notation of
Section 5, let us write Z(k) = Z′2(k)− Z′1(k). Note that Z is not a particularly
nice process: it is neither Markov, nor translation invariant. As long as both
Z′1(k) and Z′2(s) are εL-close to xL, Z is well approximated by a Brownian
motion. In particular, if kZk = M, then the probability that kZk reaches M/2
before reaching 2M is close to 1/2 and thus kZk performs an approximate
simple symmetric random walk (SSRW) on the circles
Cm = {z ∈ Z2 : |kzk − 2m| < 2}.

We will estimate the goodness of this approximation by a SSRW.

Assuming that Z(s0) ∈ Cm, denote by s1 the smallest s > s0 such that

Z(s) ∈ Cm−1 or Z(s) ∈ Cm+1. We also write

log = log2, M = 2m,

P(Z(s1) ∈ Cm−1) −

.

Note that s1 is a stopping time with respect to the ﬁltration generated by
Z′2(s), Z′1(s).

EL,M =(cid:12)(cid:12)(cid:12)(cid:12)

1

2(cid:12)(cid:12)(cid:12)(cid:12)

We will need a series of lemmas.

Lemma 4. If kZ(k)k ≥ 2, then

P (Z(k + 1) − Z(k) = e) =

1
4

+ O(cid:18)kZ(k)k
L2 (cid:19)

for e = (1, 0), (−1, 0), (0, 1), (0,−1). Here, the constants involved in O only
depend on the C2 norm of R.
Proof. Using that R is a C2 function on a compact domain containing D, the
lemma follows from the deﬁnition.

(cid:3)

Lemma 4 enables us to couple Z(k) with a planar SSRW W (k) such that

P(Z(k) − Z(k − 1) = W (k) − W (k − 1)|Z(k)) ≥ 1 −

CkZ(k)k

L2

.

We are going to apply such a coupling several times in the forthcoming lemmas.
Lemma 5. There are constants ε0 > 0, C0 < ∞ and θ < 1 such that

P(s1 > n) < C0θn/M 2

assuming kZ(s0)k = M < ε0L.
Proof. To verify Lemma 5, we couple Z(k), k ∈ [s0, s0 + M 2] to a SSRW
W (k), k ∈ [s0, s0 + M 2], W (s0) = Z(s0). By Lemma 4, we can guarantee that
kZ(k) − W (k)k < CM 3/L2 for all k < M 2 with some probability bounded
away from zero. Here, C only depends on the C2 norm of R. Thus by choosing

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

19

ε0 small, we can guarantee CM 3/L2 < M/10. Since W is close to a Brownian
motion, it reaches Cm−2 or Cm+2 before M 2 with some positive probability.
Consequently, there is some p independent of L such that P(s1 < M 2) > p.
Applying this argument in an inductive fashion gives Lemma 5.
(cid:3)

Let us introduce the notation

(16)

τ γ = τ γ(L) = min{k : kZ(k)k > Lγ}

Now we claim the following
Lemma 6. For every γ < 1 with 1 − γ small, there exists some ξ > 0 such
that for L large enough, the following estimates hold.

(a) Tiny gap: If m < 3

5 log L, then
P(τ3/5 > L13/10) = O(L−1/10)

(b) Small gap:

3
10
(c) Moderate gap:

If

log L ≤ m < γ log L, then EL,M = O(L−ξ)

If γ log L < m < log L − log log L, then EL,M = O(log−3/2 L)

(d) Large gap: There is some ε > 0 such that

if log L − log log L < m < log L + log ε, then EL,M < 1/100

As the proof of Lemma 6 is slightly longer than the other lemmas, we post-

pone it to the Appendix. Next, we formulate our key lemma:

Lemma 7. For any small δ > 0, there exists γ < 1 such that for L large
enough,

P(∄k : τ γ < k < tL2 : kZ(k)k ≤ 2) > 1 − δ.

Proof. In order to derive Lemma 7 from Lemma 6, recall the connection of
random walks and electrical networks from Section 1.1. Using the notation
from there, we choose A = 3
10 log L, B = log L+log ε and I = γ log L, RI+1/2 =
If Ri+1/2 is deﬁned for some i ∈ [I, log L − log log L], then let us deﬁne
1.
Ri+3/2 = Ri+1/2(1 + K log−3/2 L). If Ri+1/2 is deﬁned for some i ∈ [log L −
log log L, B − 1], then let us deﬁne Ri+3/2 = 11
10wi+1/2. Similarly, if Ri+1/2 is
deﬁned for some i ∈ [A, I], then we deﬁne Ri−1/2 = Ri+1/2(1 − KL−ξ). Now
by Lemma 6(b-d)
P(min{k : kZ(k + s0)k < L3/10} < min{k : kZ(k + s0)k > εL}|kZ(s0)k = Lγ)
is bounded from above by (2). An elementary computation shows that (2)
can be made arbitrarily small by choosing γ close to 1. Thus after τ γ, kZ(k)k
reaches εL before reaching 2 with probability close to 1. Finally, Lemmas 1
and 2 yield that for ﬁxed ε the two particles do not meet after separating by
a distance εL and before tL2 with probability close to 1. This proves Lemma
7.
(cid:3)

20

P´ETER N ´ANDORI

As a consequence of Lemma 7, we will be able to replace ˜Z1(s) and ˜Z2(s)

with two independent copies after time

˜τ γ = min{s : k ˜Z1(s) − ˜Z2(s)k > Lγ}.

Then Proposition 6 will easily follow once we establish that (A) ˜τ γ/L2 is
negligible and (B) ( ˜Zi(τ γ) − xL)/L is negligible. This is what we do in the
next two lemmas.

Lemma 8. For any ﬁxed γ < 1 and δ > 0, we have

P(τ γ < L1+γ) > 1 − δ

for L large enough.
Proof. By Lemma 6(a), it is enough to prove P(τ α − τ 3/5 > L1+γ) < δ. We
write s0 = τ 3/5 and if Z(si) ∈ Cm with m > 3
10 log L, then si+1 is the ﬁrst time s
when either Z(s) ∈ Cm−1 or Z(s) ∈ Cm+1. If Z(si) ∈ C⌊ 3
, then si+1 is the
10 log L⌋+1. By Lemma 6(b), bi := log kZ(si)k can
ﬁrst time s when Z(s) ∈ C⌊ 3
be approximated by a one dimensional SSRW (reﬂected at 3
10 log L, absorbed
at γ log L) with an error of O(Lξ) at each step.
In particular, if t is the
smallest i when bi ≥ γ log L, then P(t > log3 L) < δ/10 and thus bi, i ≤ t
can be coupled to a SSRW with an error < δ/5. Now if ζ = (1 − γ)/2 and
ℓm = #{i < t : bi = m}, then

10 log L⌋

P(ℓm > Lζ) < δ/10

P(∃m : ℓm > Lζ) ≤ log L max

m

by the gambler’s ruin estimate P(ℓm > n + 1|ℓm > n) < 1− log−1 L. If ℓm < Lζ
for all m, then

τ α <

γ log L

Xm= 3

10 log L

Lζ

Xi=1

Tm,i,

where Tm,1 is the random time s1 − s0 if kZ(s0)k = m and for ﬁxed m, Tm,i’s
are iid. Consequently, we have

P(τ α > L1+γ) <

3δ
10

+ (log L)Lζ max

m

by Lemma 5 and Lemma 6(a).

Now, with the notation

P(cid:0)Tm,1 > L1+γ−ζ log−1 L(cid:1) < δ

(cid:3)

˜τ γ = ˜τ γ(L) = min{k : k ˜Z1(k) − xLk > Lγ or k ˜Z2(k) − xLk > Lγ}

we have

Lemma 9. For any ﬁxed γ < 1 and δ > 0, we have
) > 1 − δ

P(L1+γ < ˜τ γ+3

4

for L large enough.

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

21

Proof. By Lemma 1, it is enough to consider the case of one particle. A
simpliﬁed version of Lemma 2 yields that

s<L1+γ k ˜Z1(s) − xLk < KL
max

1+γ

2

with probability 1 − δ for some K and L large.

(cid:3)

The variant of Proposition 6 (explained in the beginning of Section 6) easily
follows from Lemmas 7, 8 and 9. Since we can neglect an event of small
probability, we can assume that all events hold in Lemmas 7, 8 and 9. Note
that by deﬁnition, ˜Z1(s) and ˜Z2(s) move independently if their distance is
bigger than 2. Thus for s > ˜τ γ, we can replace ( ˜Z1(˜τ γ + k))k=1,...,T L2 and
( ˜Z2(˜τ γ +k))k=1,...,T L2 with independent random walks, both of them converging
to Z(s) under the proper scaling. Finally, by Lemmas 8 and 9, τ γ/L2 < δ and
( ˜Zi(˜τ γ) − x)/L < δ. Proposition 6 follows in the case of Theorem 1, N = 2,
d = 2.

6.2. Completing the proof of Proposition 6. The case of general N fol-
lows from Lemma 1 and from the case N = 2. Indeed, Lemmas 1, 7 and 8
imply that for some γ < 1,

P(∃s ∈ [L1+γ, tL2], i, j ∈ {1, 2, ..., N} : k ˜Zi(s) − ˜Zj(s)k ≤ 2) < δ.
Furthermore, we have the analogue of Lemma 9 with ˜τ α replaced by

min{k : ∃i < N : k ˜Zi(k) − xLk > Lα}.

Whence the case of general N follows the same way as before.

The case of dimension d > 2 is simpler than d = 2 as the particles only meet

ﬁnitely many times.

Lemma 10. In case of Theorem 1, d > 2, N = 2, there is some positive p
such that k ˜Z1(s) − ˜Z2(s)k ≥ 2 for all k ∈ [2, tL2] with probability at least p.
Proof. Consider the process Z(k) = Z′2(k)− Z′1(k) as in Section 6.1. Let us ﬁx
some small ε > 0. We will show that the probability of the event {kZk reaches
εL before reaching 1} is bounded away from zero. From this the lemma will
follow by the same argument as in d = 2 (cf. the end of the proof of Lemma
7).

Similarly to Lemma 4, we have

(17)

1
2d −

c0ε
L

< P (Z(k + 1) − Z(k) = e) <

1
2d

+

c0ε
L

assuming kZ(k)k ≤ εL for all unit vectors e ∈ Zd and L large enough. Now
we deﬁne a random walk B(k) on Zd with weights. Speciﬁcally B(3) = Z(3)
and we choose the weights

w(u,v) =(cid:16)1 −

c1ε

L (cid:17)l

, where |u|1 = l − 1, |v|1 = l and c1 ≫ c0 is a ﬁxed constant.

22

P´ETER N ´ANDORI

Clearly kZ(3)k ≥ 2 holds with some positive probability. Let us write tB,l =
min{k > 3 : |B(k)|1 = l}, where min ∅ = ∞ and similarly tZ,l = min{k > 3 :
kZ(k)k = l}. Now we claim that
Lemma 11. Assuming c1 = c1(c0) is large enough, there exists a coupling
between the processes B and Z such that |Bi(k)| ≤ |Zi(k)| holds for all k ∈
[3, tB,1 ∧ tZ,εL) and i ≤ d almost surely.
By Lemma 11, it suﬃces to prove that

(18)

P(tB,εL < tB,1) is bounded away from zero.

This follows from a simple application of the connection between random walks
and electrical networks. Note that the weights w(u,v) are bounded away from
zero in the εL neighborhood of the origin. In such cases, (18) follows from a
standard argument, see e.g. the proof of Theorem 19.30 in [K14]. In order to
complete the proof of the Lemma 10, it only remains to prove Lemma 11. (cid:3)

Proof of Lemma 11. We prove by induction on k. Assume |Bi(k)| ≤ |Zi(k)|
for all i ≤ d.
If |Bi(k + 1)| = |Bi(k)| + 1, then we deﬁne Z(k + 1) by |Zi(k + 1)| = |Zi(k)| + 1.
We can do so by (17) and by the deﬁnition of B: if c1 is large enough, then

Case 1: none of the coordinates of B(k) and Z(k) are zero.

P(|Bi(k + 1)| = |Bi(k)| + 1) ≤ P(|Zi(k + 1)| = |Zi(k)| + 1).

(19)
Similarly, if |Zi(k + 1)| = |Zi(k)|− 1, then we deﬁne B(k + 1) by |Bi(k + 1)| =
|Bi(k)| − 1. We can do so as similarly to (19), we have

P(|Zi(k + 1)| = |Zi(k)| − 1) ≤ P(|Bi(k + 1)| = |Bi(k)| + 1).

The coupling is arbitrary on the remaining set (sometimes we may have to
move B and Z in diﬀerent directions to match the probabilities, i.e. to deﬁne
a proper coupling). This proves the inductive step for the case when none of
the coordinates of B(k) and Z(k) are zero.

Case 2: none of the coordinates of B(k) are zero or for all i with Bi(k) = 0,

Zi(k) = 0 also holds.
The same argument works as in Case 1.

Note that the coupling of Case 1 will not work if Bi(k) = 0 and Zi(k) 6= 0 as
P(|Bi(k + 1)| = |Bi(k)| + 1) ≈ d−1 while P(|Zi(k + 1)| = |Zi(k)| + 1) ≈ (2d)−1.
Let I denote the set of indices i with Bi(k) = 0, Zi(k) 6= 0 and let I′ ⊂ I be
the set of indices i with Bi(k) = 0 and |Zi(k)| = 1.
If |Bi(k + 1)| = |Bi(k)| + 1 with some i ∈ I, then we can deﬁne Z(k + 1) by
changing the ith coordinate (either increasing or decreasing), since we have

Case 3: |Zi(k)| ≥ 2 for all i ∈ I.

(20)

P(B(k + 1) = B(k) + ei or B(k) − ei)
≤ P(Z(k + 1) = Z(k) + ei or Z(k) − ei).

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

23

The proof of (20) is similar to that of (19): the ﬁrst line of (20) is

Here the denominator can be bounded from below by

.

w(B(k),B(k)+ei) + w(B(k),B(k)−ei)

Pv:kv−B(k)k=1 w(B(k),v)
L (cid:17)|B(k)|1h1 + (2d − 1)(cid:16)1 −

c1ε

(cid:16)1 −

c1ε

L (cid:17)i,

which corresponds to the case when only one coordinate is nonzero (note that
we have excluded B(k) = 0 since k < tB,1). Combining this estimate with (17)
gives (20) assuming that c1 = c1(c0) is large enough. The other coordinates
are treated the same way as in Case 1.
Case 4: |I′| 6= 0 is an even integer.
Consider a perfect matching of I′. Let (i, j) ∈ I′2 be an arbitrary pair. If
Zi(k + 1) = 0, then we deﬁne B(k + 1) such that |Bj(k + 1)| = 1. We can do so,
since P(Zi(k + 1) = 0) ≈ (2d)−1 and P(|Bj(k + 1)| = 1) ≈ d−1. Analogously,
if Zj(k + 1) = 0, then we deﬁne B(k + 1) such that |Bi(k + 1)| = 1. Then,
we do the coupling of movements in other directions as discussed in cases 1-3.
Finally, we couple the remaining set (including Zi(k + 1) = 2, Zj(k + 1) = 2)
arbitrarily.

Case 5: |I′| = n is an odd integer.
First we consider a matching of n − 1 elements of I′, and do the coupling
described in Case 4. Let us denote the remaining index by i. Now we claim
that there is some j /∈ I′ such that |Zj(k)| − |Bj(k)| ≥ 1. Indeed, if there was
no such j, then Pd
m=1 |Zm(k)| − |Bm(k)| = n would be an odd number, which
is a contradiction with the fact that Z(0) = B(0) and both processes move to
nearest neighbors at each step. Now if |Zj(k + 1)| = |Zj(k)|− 1, then we deﬁne
B(k + 1) such that |Bi(k + 1)| = 1. If Zi(k + 1) = 0, we deﬁne B(k + 1) by
changing the jth coordinate (either decreasing or increasing). These can be
done as before. Then, we consider the cases corresponding to other coordinates
as discussed in cases 1-3. Finally, we couple the remaining set arbitrarily.

(cid:3)

Using Lemma 10, one can easily prove a much simpliﬁed version of Lemmas
7, 8 and 9 with Lγ, L
replaced by constants K1(δ), K2(δ), K3(δ) This
implies Proposition 6 for the case d > 2, N = 2. Then the case of general N
follows the same way as in d = 2.

2 , L

1+γ

3+γ

4

Finally, in case of Theorem 2 we have assumed that x1 6= 0. Then choosing
ε < |x1|, the proof of the case of Theorem 1 (with the choice R is the constant
1 function) applies.

7. Proof of Theorem 3 and Proposition 4

As in the proof of Theorems 1 and 2, we prove the weak convergence by
showing that the moments converge. The latter one is showed by switching to
the dual process. Recalling some notation from Section 5, we deﬁne Y ′ from

24

P´ETER N ´ANDORI

˜Y (t) the same way as we deﬁned Z′ from ˜Z(t). The proof consists of two
parts. First we consider the case when the number of particles is N = 2 and
prove

Proposition 7.

E"T   Y

′(L)
1

(∞)
L

lim
L→∞

! T   Y

′(L)
2

(∞)
L

!# /(cid:2)u(L)(x)(cid:3)2

= 1

Then we can derive an extension of Proposition 7 to arbitrary N. The idea
of the proof of Proposition 7 is borrowed from [RY07] (the main diﬀerence is
in Lemma 14). The extension to arbitrary N is very similar to the argument
in [KMP82, LNY15].

′(L)
Let us write P (L)(A1) = P(Y
1
′(L)
P (L)(A1, A2) = P(Y
1

(∞) = A1) and
(∞) = A1, Y

′(L)
2

(∞) = A2)

for A1, A2 ∈ {0, L}. The asymptotic hitting probabilities of one particle are
given by

P (L)(L)

A(L)(x) = 1.

Lemma 12. limL→∞
Proof. Although this lemma follows from the connection between random
walks and electrical networks, we give a direct proof as its extensions will
be needed later. Note that by the deﬁnition of ω0, ωL and ψ(m), we have for
any 1 ≤ m ≤ L − 1
ωm−1
(21)

rm+1/2ψ(m + 1).

ωm+1

rm−1/2ψ(m) =

ωm + ωm+1

Let us write Φ(m) = Pm

i=1 ψ(i) for 0 ≤ m ≤ L. Then (21) means that
Φ(Y ′1 (k)) is a bounded martingale. After the ﬁrst hitting of either 0 or L,
this martingale clearly stays constant. Then by the martingale convergence
theorem,

ωm−1 + ωm

P (L)(L)Φ(L) = Φ(Y ′1 (0)).
Since A(L)(x) ∼ Φ(Y ′1 (0))/Φ(L), Lemma 12 follows.
Now with the notation Φ(m) = PL

construct submartingales using

Sk := Φ(Y ′1 (k))Φ(Y ′2 (k)) + Φ(Y ′1 (k))Φ(Y ′2 (k))

i=m+1 ψ(i) for 0 ≤ m ≤ L our aim is to

(cid:3)

and

Tk =

max{Y ′

1 (k),Y ′

2 (k)}

Xi=min{Y ′

1 (k),Y ′

2 (k)}+1

ψ(i).

Lemma 13. There exists some constant C only depending on the upper and
lower bound of r and ω such that Sk + CTk is a submartingale and Sk − CTk
is a supermartingale.

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

25

Proof. Let us compute the conditional expectations with respect to (Fk)k, the
ﬁltration generated by the process Y ′. First, observe that E(Sk+1|Fk) = Sk if
|Y ′1 (k) − Y ′2 (k)| ≥ 2. Next, by deﬁnition E(Sk+1|Y ′1 (k) = Y ′2 (k) = i) is equal
to

ri+1/2

ri−1/2+ri+1/2

0

p2[Φ(i + 1)2 + Φ(i + 1)2]

Z 1
+2p(1 − p)[Φ(i)Φ(i + 1) + Φ(i)Φ(i + 1)]
+(1 − p)2[Φ(i)2 + Φ(i)2]dBeta(ωi+1/2, ωi/2, p)

+ ri−1/2

ri−1/2+ri+1/2 Z 1

0

p2[Φ(i − 1)2 + Φ(i − 1)2]

+2p(1 − p)[Φ(i)Φ(i − 1) + Φ(i)Φ(i − 1)]
+(1 − p)2[Φ(i)2 + Φ(i)2]dBeta(ωi−1/2, ωi/2, p)

where we used the shorthand dBeta(α, β, p) = 1
puting the integrals and using (21) gives

B(α,β) pα−1(1 − p)β−1dp. Com-

E(Sk+1 − Sk|Y ′1 (k) = Y ′2 (k) = i)

ri+1/2

ωi+1(ωi+1 + 2)

= 2[ψ(i)]2(cid:18)
ri−1/2

+

ri−1/2 + ri+1/2

(ωi + ωi+1)(ωi + ωi+1 + 2)
ωi−1(ωi−1 + 2)

(ωi−1 + ωi)(ωi−1 + ωi + 2)(cid:19)

ri−1/2 + ri+1/2

Similarly, E(Sk+1 − Sk|Y ′1 (k) = i, Y ′2 (k) = i + 1) is by deﬁnition equal to

ri−1/2

ri−1/2+ri+1/2+ri+3/2

ωi−1

ri+1/2

ri−1/2+ri+1/2+ri+3/2 (cid:8)Z 1

[−ψ(i)Φ(i + 1) + ψ(i)Φ(i + 1)]

ωi−1 + ωi
0 (cid:0)p2[Φ(i + 1)2 + Φ(i + 1)2]
+2p(1 − p)[Φ(i)Φ(i + 1) + Φ(i + 1)Φ(i)]
+(1 − p)2[Φ(i)2 + Φ(i)2] − Sk(cid:1)dBeta(ωi−1, ωi, p)
−Φ(i)2 − Φ(i)2(cid:9)

[Φ(i)ψ(i + 2) − Φ(i)ψ(i + 2)].

ωi+1 + ωi+2

ωi+2

+

+

ri+3/2

ri−1/2+ri+1/2+ri+3/2

A similar computation to the previous one gives
E(Sk+1 − Sk|Y ′1 (k) = i, Y ′2 (k) = i + 1)

= −[ψ(i + 1)]2

2ri+1/2

ωiωi+1

ri−1/2 + ri+1/2 + ri+3/2

(ωi + ωi+1)(ωi + ωi+1 + 2)

.

Just like in the case of Sk, we have E(Tk+1|Fk) = Tk if |Y ′1 (k) − Y ′2 (k)| ≥ 2.
Furthermore,

E(Tk+1 − Tk|Y ′1 (k) = Y ′2 (k) = i) = [ψ(i + 1)]

ri+1/2

ωiωi+1

ri−1/2 + ri+1/2

(ωi + ωi+1)

,

26

and

P´ETER N ´ANDORI

E(Tk+1 − Tk|Y ′1 (k) = i, Y ′2 (k) = i + 1) = [ψ(i + 1)]

1
3

ωiωi+1

(ωi + ωi+1 + 2)

.

We conclude that there is some positive constant c such that

• 0 < E(Sk+1 − Sk|Y ′1 (k) = Y ′2 (k)) < 1
• −1/c < E(Sk+1 − Sk||Y ′1 (k) − Y ′2 (k)| = 1) < 0
• c < E(Tk+1 − Tk|Y ′1 (k) = Y ′2 (k))
• c < E(Tk+1 − Tk||Y ′1 (k) − Y ′2 (k)| = 1)

c

The lemma follows.

(cid:3)

P (L)(L,L)+P (L)(0,0)

[A(L)(x)]2+[1−A(L)(x)]2 = 1.

Lemma 14. limL→∞
Proof. Since Mk := Sk + CTk is a bounded submartingale, we can apply the
martingale convergence theorem to deduce
M0 ≤ E(M∞) = (P (L)(L, L)+P (L)(0, 0))Φ2(L)+(P (L)(0, L)+P (L)(L, 0))CΦ(L)
Since Φ(L)/L is bounded away from zero and inﬁnity, the lower bound fol-
lows. The upper bound is derived similarly from the fact that Sk + CTk is a
supermartingale.
(cid:3)

Now we are ready to prove Proposition 7.

Proof of Proposition 7. By Lemma 1,

P (L)(L, L) =

1
2

Then by Lemmas 12 and 14,

[P (L)(L) + P (L)(L, L) + P (L)(0, 0) − P (L)(0)]
P (L)(L, L) ∼(cid:2)A(L)(x)(cid:3)2

.

Similarly, P (L)(0, 0) ∼(cid:2)1 − A(L)(x)(cid:3)2
A(L)(x)]. Proposition 7 follows.

, P (L)(L, 0) ∼ P (L)(0, L) ∼(cid:2)A(L)(x)(cid:3) [1−

(cid:3)

Since the extension of Proposition 7 to arbitrary N can be proved the same
way as its analogues in [KMP82], Section 3 and [LNY15], Section 6.2, we omit
the proof here. Thus we have ﬁnished the proof of Theorem 3.

Finally, Proposition 4(b) is elementary and Proposition 4(a) follows from
the connection between random walks and electrical networks (namely, from
(2) or Lemma 12) and the law of large numbers.

Appendix

Here, we prove Lemma 6. We will use the notations of Section 6. The proof
uses similar coupling to the one in the proof of Lemma 5. This will suﬃce in
case of (a), as kZk is small and in case of (d), as we only need a weak esti-
mate. However, we need to perform the coupling on a mesoscopic timescale
to complete the proof of (b) and (c).

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

27

Proof of (d).

We prove the following slightly stronger statement
For every η > 0 there is ε = ε(η) > 0 such that if log L − log log L < m <
log L + log ε and L is large enough, then EL,M < η.
With some ﬁxed C1, we couple Z(k), k ∈ [s0, (s0 + C1M 2) ∧ s1] to a SSRW
W (k), k ∈ [s0, (s0 + C1M 2) ∧ s1], W (s0) = Z(s0). We ﬁx C1, as we can by
Lemma 5, such that P(s1 > s0 + C1M 2) < η/10. Second, Lemma 4 implies
that by choosing C2 = C2(C1) large enough,

P(kW (k) − Z(k)k > C2M 3/L2 for some k < (s0 + C1M 2) ∧ s1) < η/10.

Now let us deﬁne

s1 = min{k : kW (k)k < (1/2 + ζ)M or kW (k)k > (2 − ζ)M},
s1 = min{k : kW (k)k < (1/2 − ζ)M or kW (k)k > (2 + ζ)M}

Where ζ is ﬁxed in such a way that the following events concerning a planar
Brownian motion W have probability at least 1 − η/10:

R2 \ B(0, 2 − ζ) and
B(0, 1/2 + ζ).

(A) if kW(0)k = 1/2 + ζ then W reaches B(0, 1/2 − ζ) before reaching
(B) if kW(0)k = 2 − ζ then W reaches R2 \ B(0, 2 + ζ) before reaching
By the fact that log kWk is martingale and by Donsker’s theorem, we can also
assume

possibly by further reducing ζ and by choosing L large. Finally, we choose

|P(kW (s1)k < (1/2 + ζ)M) − 1/2| < η/10,

ε =pζ/C2 so as ζM > C2M 3/L2. Lemma 6(d) follows.
Proof of (a)
If 2 ≤ kZ(k + s0)k for some k < L13/10 ∧ τ 3/5, then using Lemma 4 we can
couple Z(k)− Z(k− 1) to a step of a SSRW W (k)− W (k− 1) with probability
O(L−7/5). Thus the probability
P(Z(k) − Z(k − 1) = W (k) − W (k − 1) for all k < L13/10, 2 ≤ kZ(k + s0)k)
is O(L−1/10). Now Lemma 6(a) follows from the proof of Lemmas 10 and 11
in [LNY15].

Proof of (b) and (c)
The idea of the proof of these cases is borrowed from [DSzV08]. First,
we ﬁx some positive ξ < 3/20, write K = ⌊Lξ⌋ and consider the process
(Z(s0 + jK))j≥1, stopped upon reaching B(0, M/2− K) or R2\ B(0, 2M + K).
Let us denote by ¯s the corresponding stopping time, i.e. ¯s = sK with the
smallest s such that Z(s0 + sK) is stopped. We will also write z = Z(s0 +
jK) − Z(s0 + (j − 1)K) and xj = log kZ(s0 + jK)k2. Now we have

kZ(s0 + (j + 1)K)k2 = kZ(s0 + jK)k2 + 2(Z(s0 + jK), z) + kz, zk2

28

and

P´ETER N ´ANDORI

xj+1 − xj = log(cid:18)1 +

By Taylor expansion,

2(Z(s0 + jK), z) + kz, zk2

kZ(s0 + jK)k2

(cid:19)

xj+1 − xj
2(Z(s0 + jK), z)
kZ(s0 + jK)k2 +

=

= I + II + III + O(L3ξM−3)

kzk2

kZ(s0 + jK)k2 −

2(Z(s0 + jK), z)2

kZ(s0 + jK)k4 + O(L3ξM−3)

As before, we couple z to a SSRW W (K) by Lemma 4 such that if y =
z − W (K), then for all positive integer n,

P(kyk = k) = O(Lnξ−2nM n)

If Fk is the ﬁltration generated by ˜Zi(s0 + l), l ≤ k, i = 1, 2, then
E (I) = E(cid:18) E (2(Z(s0 + jK), W (K))|Fj)
(cid:19) + E(cid:18)E (2(Z(s0 + jK), y)|Fj)
(cid:19)
Here, the ﬁrst term is zero by symmetry of the SSRW W , and the second is
estimated by the Cauchy-Schwarz inequality in cases 1 ≤ kyk ≤ 2 and kyk ≥ 3.
We conclude E(I) = Lξ−2. A similar argument shows that

kZ(s0 + jK)k2

kZ(s0 + jK)k2

E(kzk2) = K + O(ML3ξ−2).

(22)
The above leading term is E(kW (K)k2) = K, which can be easily proved
by leveraging the fact that (W(1)(k) − W(1)(k − 1))1≤k≤K and (W(2)(k) −
W(2)(k − 1))1≤k≤K are two independent one dimensional SSRW’s, where v(1) =
((1/√2, 1/√2), v) and v(2) = ((1/√2,−1/√2), v). Finally,

2Z(i)(s0 + jK)Z(j)(s0 + jK)E(z(i)z(j))

2

E(2(Z(s0 + jK), z)2|Fj)
Xi,j=1
Xi=1

2

=

=

2(Z(i)(s0 + jK))2E[(W(i)(K))2] + O(M 2L3ξ−2)

= kZ(s0 + jK)k2K + O(M 2L3ξ−2).

We conclude that

E((xj+1 − xj)1¯s>jK) = O(L3ξM−3 + Lξ−2).

Recall that we are given some γ < 1.

E(xmin{¯s/K,A/K}) = 2m + O(cid:0)AL2ξM−3 + AM L−2(cid:1)

(23)

Thus

(24)

LOCAL EQUILIBRIUM IN INHOMOGENEOUS MODELS

29

• In case of Lemma 6(b), let us choose A = M 2+ 1−γ
γ . Assuming, as we
can that ξ < 1 − γ gives AL−2 < L−ξ. If ξ is small (say smaller than
1/20), then AL2ξM−3 < L−ξ holds as well.
• In case of Lemma 6(c) let us choose A = L2 log−3/2 L. Since both 1− γ
and ξ are small, we have AL2ξM−3 + AM L−2 = O(log−3/2 L).
Thus the error term in (24) can be replaced by O(E), where E = L−ξ in case
of Lemma 6(b) and E = log−3/2 L in case of Lemma 6(c). Next, by Lemma 5,

(25)

xmin{¯s/K,A/K} = 2m ± 2 + O(LξM−1) = 2m ± 2 + O(L−ξ)

holds except on a set of probability O(θA/M 2). On this exceptional set, we
bound the left hand side of (25) by O(log M).
In case of Lemma 6(b),
θA/M 2 log M is superpolynomially small in L. In case of Lemma 6(c), θA/M 2 log M <
θ√log L log L = O(log−3/2 L). It follows that

P(kZs0+¯sKk ≤ M/2 − K) =

1
2 − O(E)

Since kZs0+¯sKk ≤ M/2 − K implies Z(s1) ∈ Cm−1, we conclude

P(Z(s1) ∈ Cm−1) ≥

An analogous argument shows

1
2 − O(E).

P(Z(s1) ∈ Cm+1) ≥

1
2 − O(E).

Lemma 6(b) and (c) follow.

Acknowledgements

I am highly indebted to Imre P´eter T´oth for raising a question which initi-
ated this research. I am also grateful to Lai-Sang Young for discussions and
encouragement. This project began while I was aﬃliated with the Courant
Institute, New York University.

References

[A78] Anulova, S. V., Diﬀusion process with singular characteristics, International sympo-

sium on stochastic diﬀerential equations, Vilnius, 7-11 (1978).

[BGNSzT15] B´alint, P., Gilbert, T., N´andori, P., Sz´asz, D., T´oth, I. P., On the limiting
Markov process of energy exchanges in a rarely interacting ball-piston gas Preprint
http://arxiv.org/abs/1510.06408 (2015).

[B68] Billingsley, P., Convergence of probability measures, Wiley (1968).
[CHS81] Cambanis, S., Huang, S., Simons, G., On the theory of elliptically contoured dis-

tributions, Journal of Multivariate Analysis 11 3 368–385 (1981).

[CGRS15] Carinci, G., Giardin`a, C., Redig, F., Sasamoto, T., Asymmetric stochastic trans-
port models with Uq(su(1, 1)) symmetry Preprint http://arxiv.org/pdf/1507.01478.pdf
(2015).

30

P´ETER N ´ANDORI

[ChShY04] Cherny, A., Shiryaev, A. and Yor, M. (2004). Limit behav ior of the ”horizontal-
vertial” random walk and some extension of the Donsker-Prokhorov invariance princi-
ple. Theory Probab. Appl. 47 3 377-394 (2004).

[DSzV08] Dolgopyat, D., Sz´asz, D., Varj´u, T., Recurrence properties of Lorentz gas, Duke

Math. J. 142 241-281 (2008).

[KMP82] C. Kipnis, C. Marchioro, E. Presutti: Heat ﬂow in an exactly solvable model

Journal of Stat. Phys. 27 65-74 (1982)

[K14] Klenke, A., Probability Theory, Universitext, 2014.
[L06] Lejay, A., On the constructions of the skew Brownian motion, Probability Surveys 3

413–466 (2006).

[LNY15] Li, Y., N´andori, P., Young L-S., Local thermal equilibrium for certain stochastic

models of heat transport preprint (2015).

[P90] Portenko, N. I. Generalized diﬀusion processes. Translations of Mathematical Mono-

graphs 83 American Mathematical Society (1990).

[RY07] Ravishankar, K., Young, L.-S., Local Thermodynamic Equilibrium for some Models

of Hamiltonian Origin Journal of Stat. Phys. 128 3 (2007)

[RY99] Revuz, D., Yor, M., Continuous Martingales and Brownian Motion, Grundlehren

der mathematischen Wissenschaften 1999.

[SSz04] Sidoravicius, V., Sznitman, A.-L., Quenched invariance principles for walks on clus-
ters of percolation or among random conductances, Probability theory and related ﬁelds
129 2 219–244 (2004).

[SV07] Stroock, D., W, Varadhan, S.R.S., Multidimensional Diﬀusion Processes, Springer,

2007.

[Z83] Zessin, H., The Method of Moments for Random Measures, Z. Wahrscheinlichkeits-

theorie verw. Gebiete 62 395–409 (1983).

P´eter N´andori: Department of Mathematics, University of Maryland, Col-

lege Park, MD 20742, USA

E-mail address: pnandori@math.umd.edu

