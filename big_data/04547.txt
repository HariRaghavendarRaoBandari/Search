Stochastic quasi-Newton methods for non-strongly convex problems:

convergence and rate analysis

Farzad Youseﬁan1 and Angelia Nedi´c2 and Uday V. Shanbhag3

6
1
0
2

 
r
a

 

M
5
1

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
7
4
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract— Motivated by applications in optimization and
machine learning, we consider stochastic quasi-Newton (SQN)
methods for solving stochastic optimization problems. In the
literature, the convergence analysis of these algorithms relies
on strong convexity of the objective function. To our knowledge,
no theoretical analysis is provided for the rate statements in the
absence of this assumption. Motivated by this gap, we allow the
objective function to be merely convex and we develop a cyclic
regularized SQN method where the gradient mapping and the
Hessian approximation matrix are both regularized at each
iteration and are updated in a cyclic manner. We show that,
under suitable assumptions on the stepsize and regularization
parameters,
the objective function value converges to the
optimal objective function of the original problem in both
almost sure and the expected senses. For each case, a class of
feasible sequences that guarantees the convergence is provided.
Moreover, the rate of convergence in terms of the objective
function value is derived. Our empirical analysis on a binary
classiﬁcation problem shows that the proposed scheme performs
well compared to both classic regularization SQN schemes and
stochastic approximation method.

I. INTRODUCTION

In this paper, we study a stochastic optimization problem

of the form:

min
x∈Rn

f (x) := E[F (x, ξ(ω))] ,

(1)

where F : Rn × Rd → R is a function, the random vector ξ
is deﬁned as ξ : Ω → Rd, (Ω,F, P) denotes the associated
probability space and the expectation E[F (x, ξ)] is taken with
respect to P. A variety of applications can be cast as the
model (1) (see [1], [2], [3], [4]). An important example in
machine learning is the support vector machine (SVM) prob-
lem ([5], [6], [7]). In such problems, a training set containing
a large number of input/output pairs {(ui, vi)}N
i=1 ∈ Rm×R
is given where vi ∈ {−1, 1} is the class’ index. The goal is
to learn a classiﬁer (e.g., a hyperplane) h(x, u) where x is
the vector of parameters of the function h and u is the input
data. To measure the distance of an observed output vi from
the classiﬁer function h, a real-valued convex loss function
(cid:96)(h; v) is deﬁned. The objective function is considered as the

1Assistant Professor, School of

Industrial Engineering & Man-
agement, Oklahoma State University, Stillwater, OK 74078, USA
farzad.yousefian@okstate.edu

2Associate Professor,

Industrial & Enterprise Systems Engineering,
University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA
angelia@illinois.edu

Professor,

3Associate

Industrial & Manufacturing Engineering,
Pennsylvania State University, University Park, PA 16802, USA
udaybag@psu.edu

following averaged loss over the training set

N(cid:88)

i=1

f (x) :=

1
N

(cid:96)(h(x, ui); vi).

(2)

The preceding objective can be seen as a stochastic optimiza-
tion model of the form (1), where F (x, ξ) := (cid:96)(h(x, u); v)
and ξ = (u, v).

Although, problem (1) may be seen as a deterministic
problem, the challenges still arise when standard determinis-
tic schemes are employed. In particular, when the expectation
is over a general measure space (making computation of
∇xE[F (x, ξ)] difﬁcult or impossible) or the distribution P
is unavailable, standard gradient or Newton-based schemes
cannot be directly applied. This has led to signiﬁcant research
on Monte-Carlo sampling techniques. Monte Carlo simula-
tion methods have been used widely in the literature to solve
stochastic optimization problems. Of these, sample average
approximation (SAA) methods [8] and stochastic approxima-
tion (SA) methods ([9], [10]) (also referred to as stochastic
gradient descent methods in the context of optimization)
are among popular approaches. It has been discussed that
when the sample size is large, the computational effort for
implementing SAA schemes does not scale with the number
of samples and these methods become inefﬁcient ([10], [11]).
SA methods, introduced by Robbins and Monro [9], require
the construction of a sequence {xk}, given a randomly
generated x0 ∈ Rn:

for k ≥ 0,

xk+1 := xk − γk∇F (xk, ξk),

(SA)
where γk > 0 denotes the stepsize and ∇F (xk, ξk) denotes
the sampled gradient of the function f with respect to x at
xk. Note that the gradient ∇F (xk, ξk) is assumed to be an
unbiased estimator of the true value of the gradient ∇f (x) at
xk, and assumed to be generated by a stochastic oracle. SA
schemes are characterized by several disadvantages, includ-
ing the poorer rate of convergence (than their deterministic
counterparts) and the detrimental impact of conditioning on
their performance. In deterministic regimes, when second
derivatives are available, Newton schemes and their quasi-
Newton counterparts have proved to be useful alternatives,
particularly from the standpoint of displaying faster rates of
convergence ([12], [13]).

Recently, there has been a growing interest in applying
stochastic variants of quasi-Newton (SQN) methods for solv-
ing optimization and large scale machine learning problems.
In these methods, xk is given by the following update rule:
(SQN)

xk+1 := xk − γkH−1

k ∇F (xk, ξk),

for k ≥ 0,

where Hk (cid:23) 0 is an approximation of the Hessian matrix at
iteration k that incorporates the curvature information of the
objective function within the algorithm. The convergence of
this class of algorithms can be derived under a careful choice
of the matrix Hk and the stepsize sequence γk. In particular,
boundedness of the eigenvalues of Hk is an important factor
in achieving global convergence in convex and nonconvex
problems ([14], [15]). While in [16] the performance of
SQN methods displayed to be favorable in solving high
dimensional problems, Mokhtari et al. [17] developed a
regularized BFGS method (RES) by updating the matrix Hk
according to a modiﬁed version of BFGS update rule to
assure convergence. To address large scale applications, lim-
ited memory variants (L-BFGS) were employed to ascertain
scalability in terms of the number of variables ([6], [18]). In
a recent extension [19], a stochastic quasi-Newton method
is presented for solving nonconvex stochastic optimization
problems. Also, a variance reduced SQN method with a
constant stepsize was developed [20] for smooth strongly
convex problems characterized by a linear convergence rate.
Motivation: One of the main assumptions in the developed
stochastic SQN method (e.g. [6], [18]) is the strong convexity
of the objective function. Speciﬁcally, this assumption plays
an important role in deriving the rate of convergence of
the algorithm. However, in many applications, the objective
function is convex, but not strongly convex such as, for
example, the logistic regression function that is given by
(cid:96)(uT x, v) := ln(1 + exp(−uT xv)) for u, x ∈ Rn and v ∈ R.
While lack of strong convexity might lead to a very slow
convergence, no theoretical results on the convergence rate in
given in the literature of stochastic SQN methods. A simple
remedy to address this challenge is to regularize the objective
2 µ(cid:107)x(cid:107)2 and solve the approximate
function with the term 1
problem of the form

min
x∈Rn

f (x) +

(cid:107)x(cid:107)2,

µ
2

(3)

(cid:17)

they display the optimal rate of O(cid:16) 1√

where µ > 0 is the regularization parameter. A trivial
drawback of this technique is that
the optimal solution
to the approximate problem (3) is not an optimal of the
original problem (3). Importantly, choosing µ to be a small
number deteriorates the convergence rate of the algorithm.
This issue is resolved in SA schemes through employing
averaging techniques for non-strongly convex problems and
(see [10], [21]). A
limitation to averaging SA schemes is that boundedness of
the gradient mapping is required to achieve such a rate.
Contributions: Motivated by these gaps, in this paper, we
consider stochastic optimization problems with non-strongly
convex objective functions and Lipschitz but possibly un-
bounded gradient mappings. We develop a so-called cyclic
regularized stochastic BFGS algorithm to solve this class
of problems. Our framework is general and can be adapted
within other variants of SQN methods. Unlike the classic
regularization, we allow the regularization parameter µ, de-
noted by µk, to be updated and decay to zero through imple-
menting the iterations. This enables the generated sequence

k

to approach to the optimal solution of the original problem
and also, beneﬁts the scheme by guaranteeing a derived rate
of convergence. A challenge in employing this technique is
to maintain the secant condition and ascertain the positive
deﬁniteness of the BFGS matrix. We overcome this difﬁculty
by carefully updating the regularization parameter and the
BFGS matrix in a cyclic manner. We show that, under
suitable assumptions on the stepsize and the regularization
parameter (referred to as tuning sequences), the objective
function value converges to the exact optimal value in an
almost sure sense. Moreover, we show that under different
settings, the algorithm achieves convergence in mean and
we derive and upper bound for the error of the algorithm in
terms of the tuning sequences. We complete our analysis by
showing that under a speciﬁc choice of the tuning sequences,
the rate of convergence in terms of the objective function
value is of the order

5√

.

1

k

The rest of the paper is organized as follows. Section II
presents the outline of the proposed algorithm addressing
problems with non-strongly convex objectives. In Section III,
we prove the convergence of the scheme in both almost sure
and expected senses and derive the rate statement. We present
the numerical experiments in Section IV. The paper ends
with some concluding remarks in Section V.
Notation: A vector x is assumed to be a column vector and
xT denotes its transpose, while (cid:107)x(cid:107) denotes the Euclidean
xT x. We write a.s. as the
vector norm,
abbreviation for “almost surely”. For a symmetric matrix B,
we write λmin(B) to denote its smallest eigenvalue. We use
E[z] to denote the expectation of a random variable z. A
function f : X ⊂ Rn → R is said to be strongly convex
with parameter µ > 0, if f (y) ≥ f (x) + ∇f (y)T (y − x) +
2(cid:107)x− y(cid:107)2, for any x, y ∈ X. A mapping F : X ⊂ Rn → R
µ
is Lipschitz continuous with parameter L > 0 if for any
x, y ∈ X, we have (cid:107)F (x) − F (y)(cid:107) ≤ L(cid:107)x − y(cid:107).

i.e., (cid:107)x(cid:107) =

√

II. OUTLINE OF THE ALGORITHM

We begin by stating our general assumptions for prob-
lem (1). The underlying assumption in this paper is that the
function f is convex and smooth.
respect to x for any ξ ∈ Ω.
tinuous gradients over Rn with parameter L > 0.

(b) f (x) is continuously differentiable with Lipschitz con-

(a) The function F (x, ξ) is convex with

Assumption 1:

(c) The optimal solution set of problem (1) is nonempty.
Next, we state the assumptions on the random variable ξ
and the properties of the stochastic estimator of the gradient
mapping, i.e. ∇F .
Assumption 2:
(a) Random variables ξk are i.i.d. for
any k ≥ 0;
(b) The stochastic gradient mapping ∇F (x, ξ) is an unbi-
ased estimator of ∇f (x), i.e. E[∇F (x, ξ)] = ∇f (x),
and has bounded variance, i.e., there exists a scalar
any x ∈ Rn.

ν > 0 such that E(cid:2)(cid:107)∇F (x, ξ) − ∇f (x)(cid:107)2(cid:3) ≤ ν2 for

To solve (1), we propose a regularization algorithm that

generates a sequence {xk} for any k ≥ 0:

(cid:0)B−1
k + δkI(cid:1) (∇F (xk, ξk) + µkxk) .

xk+1 := xk − γk

(CR-SQN)
Here, γk > 0 denotes the stepsize at iteration k, Bk denotes
the approximation of the Hessian matrix, µk > 0 is the
regularization parameter of the gradient mapping where

(cid:40)

µk+1 = µk,
µk+1 < µk,

if k is even
if k is odd,

(4)

while δk > 0 is the regularization parameter of the matrix
Hk. We assume when k is even, µk < µk−1 is chosen such
that ∇F (xk, ξk) + µkxk (cid:54)= 0.1 Let us deﬁne the matrix Bk
by the following rule:

(cid:40)

Bk+1 :=

k Bk

Bk − BksksT
Bk,

sT
k Bksk

+ yB
k (yB
k yB
sT
k

k )T

+ ρµkI, k even
k odd,

(5)

where for an even k,
sk := xk+1 − xk,
k := ∇F (xk+1, ξk) − ∇F (xk, ξk) + (1 − ρ)µksk,
yB

and 0 < ρ < 1 is the regularization factor of the matrix
Bk+1 at iteration k. To state the properties of the matrix Bk,
we start by deﬁning the regularized function.
the sequence {µk} of positive
scalars. The regularized function fk : Rn → R is deﬁned
as follows:

Deﬁnition 1: Consider

fk(x) := f (x) +

(cid:107)x(cid:107)2,

for any k ≥ 0.

µk
2

Similar notation can be used for the regularized stochastic
2 (cid:107)x(cid:107)2. We can
function Fk as Fk(x, ξ) := F (x, ξ) + µk
now deﬁne the term yreg
as the difference between the
value of the regularized stochastic gradient mappings at two
consecutive points as follows:

k

yreg
k

:= ∇Fk(xk+1, ξk) − ∇Fk(xk, ξk).

In the following result, we show that at iterations that
the matrix Bk is updated, the secant condition is satisﬁed
implying that Bk is well-deﬁned. Also, we show that Bk is
positive deﬁnite for k ≥ 0.
Lemma 1: Let Assumption 1(a) hold, and let Bk be given
by the update rule (5). Suppose B0 (cid:23) ρµ0I is a symmetric
matrix. Then, for any even k, the secant condition holds, i.e.,
k > 0, and Bk+1sk = yreg
k . Moreover, for any k, Bk is
sT
k yB
symmetric and Bk+1 (cid:23) ρµkI.

Proof: It can be easily seen, by the induction on k, that
all Bk are symmetric when B0 is symmetric, assuming that
the matrices are well deﬁned. We use the induction on even
values of k to show that the other statements hold and that
the matrices are well deﬁned. Suppose k ≥ 2 is even and

1Note that we can ensure this non-zero condition, as follows. If we have
∇F (xk, ξk)+µkxk = 0 and xk (cid:54)= 0, then by replacing µk with a smaller
value the relation will hold. If xk = 0, then we can draw a new sample of
ξk to satisfy the relation. We can get stuck at xk with sampling if 0 solves
the original problem.

t > 0,
for any even values of t with t < k, we have sT
, and Bt+1 (cid:23) ρµtI. We show that all of these
Bt+1st = yreg
k > 0, Bk+1sk = yreg
relations hold for t = k, i.e., sT
k ,
and Bk+1 (cid:23) ρµkI. First, we prove that the secant condition
holds. We can write

k yB

t yB

t

k = (xk+1 − xk)T (∇F (xk+1, ξk) − ∇F (xk, ξk)

sT
k yB

+ (1 − ρ)µk(xk+1 − xk))
≥ (1 − ρ)µk(cid:107)xk+1 − xk(cid:107),

where we used the convexity of F (·, ξ).
From the induction hypothesis, Bk−1 (cid:23) ρµk−2I since
k − 2 is even. Furthermore, since k − 1 is odd, we have
Bk = Bk−1 by the update rule (5). Therefore, Bk is
positive deﬁnite. Note that since k is even,
the choice
of µk is such that ∇F (xk, ξk) + µkxk (cid:54)= 0 (see the
discussion following (4)). Since Bk is positive deﬁnite,
the matrix B−1
k + δkI is positive deﬁnite. Therefore, we
xk+1 (cid:54)= xk. Hence

k + δkI(cid:1) (∇F (xk, ξk) + µkxk) (cid:54)= 0, implying that

have(cid:0)B−1

k ≥ (1 − ρ)µk(cid:107)xk+1 − xk(cid:107)2 > 0,

sT
k yB

where we used ρ < 1. Thus, the secant condition holds.

Also, since k− 1 is odd, by update rule (4), it follows that
µk = µk−1. From the update rule (5) and that Bk is positive
deﬁnite and symmetric, we have

Bk+1 (cid:23) B0.5

I − B0.5

k sk(sk)T B0.5
k
(cid:107)B0.5

k sk(cid:107)2

B0.5 + ρµkI,

(6)

(cid:18)

(cid:19)

k )T (cid:23) 0 and sT

where the last relation is due to yB

Since xk+1 (cid:54)= xk we have sT

k >0.
k (yB
k Bksk (cid:54)= 0. Thus, the matrix
I− B0.5
k sk(sk)T B0.5
is well deﬁned and positive semideﬁnite,
(cid:107)sT
since it is symmetric with eigenvalues are between 0 and 1.
k . Using

Next, we show that Bk+1 satisﬁes Bk+1sk = yreg

k (cid:107)2

k yB

k B0.5

k

the update rule (5), for even k we have,
Bk+1sk = Bksk− BksksT

k Bksk

+

sT
k Bksk
= Bksk−Bksk + yB
= ∇F (xk+1, ξk) − ∇F (xk, ξk)+µksk.
Since k is even, we have µk+1 = µk implying that

k + ρµksk

k )T sk
k (yB
yB
sT
k yB
k

+ ρµksk

Bk+1sk = ∇F (xk+1, ξk) − ∇F (xk, ξk)

+ µk+1xk+1 − µkxk
= ∇Fk(xk+1, ξk) − ∇Fk(xk, ξk) = yreg
k ,

where the last equality follows by the deﬁnition of the
regularized mappings.

From the preceding discussion, we conclude that

the
induction hypothesis holds also for t = k. Therefore, all
the desired results hold for any even k. To complete the
proof, we need to show that for any odd k, we have Bk+1 =
Bk (cid:23) ρµkI. By the update rule (5), we have Bk+1 = Bk.
Since k − 1 is even, Bk (cid:23) ρµk−1I. Also, from (4) we have
µk = µk−1. Therefore, Bk+1 = Bk (cid:23) ρµkI.

III. CONVERGENCE ANALYSIS

In this section, we analyze the convergence properties
of the stochastic recursion (CR-SQN). The following as-
sumption provides the required conditions on the stepsize
sequence γk and is a commonly used assumption in the
regime of stochastic approximation methods [17], [19], [6].
Property 1: [Properties of the regularized function] The
function fk from Deﬁnition 1 for any k ≥ 0 has the following
properties:
(a) fk is strongly convex with a parameter µk.
(b) fk has Lipschitzian gradients with parameter L + µk.
(c) fk has a unique minimizer over Rn, denoted by x∗
k.

Moreover, for any x ∈ Rn,
2µk(fk(x) − fk(x∗

k)) ≤ (cid:107)∇fk(x)(cid:107)2,
(cid:107)∇fk(x)(cid:107)2 ≤ 2(L + µk)(fk(x) − fk(x∗

k)).

The existence and uniqueness of x∗

k in Property 1(c) is
due to the strong convexity of the function fk (see, for
example, Sec. 1.3.2 in [22]), while the relation for the
gradient is known to hold for a strongly convex function
with a parameter µ that also has Lipschitz gradients with a
parameter L (see Lemma 1 in page 23 in [22]).

The next result provides an important property for the
recursion (CR-SQN) that will be subsequently used to show
the convergence of the scheme. Throughout, we let Fk
denote the history of the method up to time k, i.e., Fk =
{x0, ξ0, ξ1, . . . , ξk−1} for k ≥ 1 and F0 = {x0}. Also,
we denote the stochastic error of the regularized gradient
estimator by

wk := ∇F (xk, ξk) − ∇f (xk),

for all k ≥ 0.

(7)

Lemma 2: [A recursive error bound inequality] Consider
the algorithm (CR-SQN). Suppose sequences γk, δk, and µk
are chosen such that for any k ≥ 0, µk satisﬁes (4), and

(cid:0)(ρµk−1)−1 + δk

(cid:1)2 ≤ δkµk.

(L + µk)2γk

(8)
Under Assumptions 1 and 2, for any k ≥ 1 and any optimal
solution x∗, we have

E[fk+1(xk+1) | Fk] − f∗
≤ (1 − γkδkµk) (fk(xk) − f∗) + γkδk

(cid:0)(ρµk−1)−1 + δk

(cid:1)2

(L + µk)

(9)

(cid:107)x∗(cid:107)2

µ2
k
2

γ2
k

+
Proof: The Lipschitzian property of ∇fk (see Prop-

2

ν2.

erty 1(b)) and the recursion (CR-SQN) imply that
fk(xk+1) ≤ fk(xk) + ∇fk(xk)T (xk+1 − xk)

+

2

(L + µk)

= fk(xk) − γk∇fk(xk)T(cid:0)B−1

(cid:107)xk+1 − xk(cid:107)2

k + δkI(cid:1) (∇F (xk, ξk) + µkxk)

k + δkI(cid:1) (∇F (xk, ξk) + µkxk)(cid:107)2.

k(cid:107)(cid:0)B−1

γ2

+

(L + µk)

2

From the deﬁnition of the stochastic error wk (see (7)) and
and the deﬁnition of the regularized function (see Deﬁni-
tion 1), we have
∇F (xk, ξk)+µkxk = ∇f (xk)+µkxk+wk = ∇fk(xk)+wk.
Hence,

fk(xk+1) ≤ fk(xk)
− γk∇fk(xk)T (B−1

2

2

2

+

+

γ2

γ2
k

(L + µk)

(L + µk)

(L + µk)

(cid:1) I.

k(cid:107)B−1
γ2

δkI (cid:22) B−1

Note that Lemma 1(b) implies that

k + δkI)(∇fk(xk) + wk)

+
≤ fk(xk) − γkλmin

k(cid:107)(cid:0)B−1
k + δkI(cid:1) (∇fk(xk) + wk)(cid:107)2
(cid:0)B−1
k + δkI(cid:1)(cid:107)∇fk(xk)(cid:107)2
−γk∇fk(xk)T(cid:0)B−1
k + δkI(cid:1) wk
k + δkI(cid:107)2(cid:0)(cid:107)∇fk(xk) + wk(cid:107)2(cid:1).
k + δkI (cid:22)(cid:0)(ρµk−1)−1 + δk
k + δkI(cid:1) wk
(cid:0)(ρµk−1)−1 + δk

− γk∇fk(xk)T(cid:0)B−1

(cid:1)2 (cid:107)∇fk(xk) + wk(cid:107)2.
Assumption 2, E[wk | Fk] = 0 and E(cid:2)(cid:107)wk(cid:107)2 | F(cid:3) ≤ ν2.

Next, we take the expected value from both sides with respect
to Fk. Note that the matrix Bk and xk are both deterministic
parameters if the history Fk is known. Note that from

From the preceding two relations we obtain
fk(xk+1) ≤ fk(xk) − γkδk(cid:107)∇fk(xk)(cid:107)2

Thus, we obtain
E[fk(xk+1) | Fk] ≤ fk(xk) − γkδk(cid:107)∇fk(xk)(cid:107)2

E(cid:2)(cid:107)∇fk(xk) + wk(cid:107)2 | Fk
(cid:3) ≤ (cid:107)∇fk(xk)(cid:107)2 + ν2.
(cid:0)(ρµk−1)−1 + δk
(cid:1)2(cid:0)(cid:107)∇fk(xk)(cid:107)2 + ν2(cid:1) .
(cid:0)(ρµk−1)−1 + δk
(cid:1)2
(cid:1)2
(cid:0)(ρµk−1)−1 + δk
(cid:0)(ρµk−1)−1 + δk

Using Property 1(c) for the function fk, we have
E[fk(xk+1) | Fk] ≤ fk(xk) − 2γkδkµk (fk(xk) − fk(x∗
k))
(fk(xk) − fk(x∗
+ (L + µk)2γ2
k))
k
ν2.

γk, δk and µk, we have (L + µk)2γ2
k
γkδkµk. Thus,
E[fk(xk+1) | Fk] ≤ fk(xk) − γkδkµk (fk(xk) − fk(x∗
k))

Due to our assumption on the choice of the sequences

(cid:1)2 ≤

(L + µk)2

Therefore,

(L + µk)

γ2
k

γ2
k

+

+

2

2

(cid:0)(ρµk−1)−1 + δk

(cid:1)2

ν2.

(L + µk)2

+

γ2
k

2

(10)
In the last step, we build a recursive inequality for the error
term fk(xk) − f∗. Adding and subtracting f∗, we obtain

fk(xk) − fk(x∗
= (fk(xk) − f∗) +

k) = (fk(xk) − f∗) + (f∗ − fk(x∗
k))
(cid:107)x∗(cid:107)2 − fk(x∗
k)

fk(x∗) − µk
2

(cid:17)

,

(cid:16)

where the last equality follows from f∗ = fk(x∗)− µk
Since x∗
fk(x∗

k is the minimizer of fk(x∗

2 (cid:107)x∗(cid:107)2.
k), we have fk(x∗) −

k) ≥ 0, implying that

fk(xk) − fk(x∗

k) ≥ fk(xk) − f∗ − µk
2

(cid:107)x∗(cid:107)2.

By substituting the preceding inequality in (10), we obtain
E[fk(xk+1) | Fk] ≤ fk(xk) − γkδkµk (fk(xk) − f∗)

(cid:0)(ρµk−1)−1 + δk

(cid:1)2

ν2.

+ γkδk

µ2
k
2

(cid:107)x∗(cid:107)2 +

(L + µk)

γ2
k

2

2

By subtracting f∗ from both sides of the preceding inequal-
ity, we see that
E[fk(xk+1) | Fk] − f∗ ≤ (1 − γkδkµk) (fk(xk) − f∗)
ν2.

(cid:0)(ρµk−1)−1 + δk

(cid:107)x∗(cid:107)2 +

(L + µk)

(cid:1)2

+ γkδk

γ2
k

µ2
k
2

Next, we relate the values fk+1(xk+1) and fk(xk+1). From
Deﬁnition 1 and µk being non-increasing we can write

fk+1(xk+1) = f (xk+1) +
≤ f (xk+1) +

µk+1

(cid:107)xk+1(cid:107)2

2
(cid:107)xk+1(cid:107)2 = fk(xk+1).
µk
2

Therefore, the desired inequality (9) holds.
We make use of the following result, which can be found
in [22] (see Lemma 11 on page 50).
Lemma 3: Let {vk} be a sequence of nonnegative random
variables, where E[v0] < ∞, and let {αk} and {βk} be
deterministic scalar sequences such that:
E[vk+1|v0, . . . , vk] ≤ (1 − αk)vk + βk
0 ≤ αk ≤ 1,

a.s. for all k ≥ 0,

βk ≥ 0,

αk = ∞,

βk < ∞,

lim
k→∞

βk
αk

= 0.

k

(cid:1)2

k(cid:107)x∗(cid:107)2 + (L + µk)γ2

(cid:0)(ρµk−1)−1 + δk

Then, vk → 0 almost surely.
In order to apply Lemma 3 to the inequality (9) and prove the
almost sure convergence, we use the following deﬁnitions:
vk := fk(xk) − f∗, αk := γkδkµk,
βk := γkδkµ2

ν2.
(11)
To satisfy the conditions of Lemma 3, we identify a set of
sufﬁcient conditions on the sequences {γk},{µk}, and {δk}
in forthcoming assumption. Later in Lemma 4, we provide
a class of sequences that meet these assumptions.
Assumption 3: [Sufﬁcient conditions on sequences for a.s.
convergence] Let the sequences {γk},{µk}, and {δk} be
non-negative and satisfy the following conditions:
(a) limk→∞ γk
µ3
(b) δkµk−1 ≤ 1 for k ≥ 1;
kδk
(c) µk satisﬁes (4) and µk → 0;

= 0;

(d) (cid:80)∞
(e) (cid:80)∞
(f) (cid:80)∞

(cid:16) γk

(cid:17)2
k=0 γkδkµk = ∞;
< ∞;
k < ∞;

k=0
k=0 γkδkµ2

µk

(g) γkδkµk ≤ 1 for k ≥ 0;

∞(cid:88)

k=0

∞(cid:88)

k=0

With Assumption 3, we have the following result.
Theorem 1: [Almost sure convergence] Consider the al-
gorithm (CR-SQN). Suppose Assumptions 1, 2 and 3 hold.
Then, limk→∞ f (xk) = f∗ a.s.
Proof: First, note that from Assumption 3(a), there
≤
exists K ≥ 1 such that for any k ≥ K we have
(L+µ0)2 . Taking this into account, using Assumption 3(b)
and (c) we can write

4γk
ρ2µ3

kδk

1

(cid:0)(ρµk−1)−1 + δk

(cid:1)2 ≤ γk

(cid:0)2(ρµk−1)−1(cid:1)2

γk
≤ 4γk
ρ2µ2
k−1

≤ 4γk
ρ2µ2
k

= (µkδk)

4γk

ρ2δkµ3
k

≤ δkµk

(L + µk)2 ,

implying that condition (8) of Lemma 2 holds. Hence,
relation (9) holds for any k ≥ K. Next, we apply Lemma 3 to
prove a.s. convergence of the algorithm (CR-SQN). Consider
the deﬁnitions in (11) for any k ≥ K. The non-negativity of
αk and βk is implied by the deﬁnition and that γk, δk, and
µk are positive. From (9), we have

E[vk+1 | Fk] ≤ (1 − αk)vk + βk

for all k ≥ K.

Since f∗ ≤ f (x) for any arbitrary x ∈ Rn, we can write
(cid:107)xk(cid:107)2 ≥ 0.

vk = fk(xk) − f∗ = (f (xk) − f∗) +

From Assumption 3(g), we obtain αk ≤ 1. Also, from
k=K αk = ∞. Using Assump-
tion 3(b) and the deﬁnition of βk in (11), for an arbitrary
solution x∗, we can write

Assumption 3(d), we get (cid:80)∞
∞(cid:88)

∞(cid:88)

∞(cid:88)

µk
2

γkδkµ2

k + 4(L + µ0)

βk ≤ (cid:107)x∗(cid:107)2

ν2
ρ2

< ∞,

γ2
k
µ2
k

k=K

k=K
where the last inequality is deduced by Assumptions 3(e)
and 3(f). Similarly, we can write

k=0

lim
k→∞

βk
αk

≤ (cid:107)x∗(cid:107)2 lim

k→∞ µk + 4(L + µ0)

= (cid:107)x∗(cid:107)2 lim

k→∞ µk + 4(L + µ0)

ν2
ρ2 lim
k→∞
ν2
ρ2 lim
k→∞

k

kµ−2
γ2
γkδkµk
γk
µ3
kδk

= 0,

where the last equation is implied by Assumptions3(a)
and 3(c). Therefore, all the conditions of Lemma 3 hold and
we conclude that vk := fk(xk) − f∗ converges to 0 a.s.
2 (cid:107)xk(cid:107)2, so that
Let us deﬁne v(cid:48)
k are non-negative, and vk → 0
k . Since v(cid:48)
vk = v(cid:48)
k → 0 a.s., implying that
a.s., it follows that v(cid:48)
limk→∞ f (xk) = f∗ a.s.
Lemma 4: Let the sequences γk, δk, and µk be given by

k := f (xk) − f∗ and v(cid:48)(cid:48)

k and v(cid:48)(cid:48)
k → 0 and v(cid:48)(cid:48)

k +v(cid:48)(cid:48)

k := µk

the following rules:

γk =

γ0

(k + 1)a ,

δk =

δ0

(k + 1)b , µk =

µ02c
(k + κ)c ,

(12)

where κ = 2 if k is even and κ = 1 otherwise, γk, δ0, µ0
are positive scalars such that δ0µ0 ≤ 2b and γ0δ0µ0 ≤ 1,
and a, b, and c are positive scalars that satisfy the following
conditions:

a > 3c + b, a + b + c ≤ 1
a − c > 0.5, a + 2c + b > 1.

Then, the sequences γk, δk, and µk satisfy Assumption 3.

Proof:

In the following, we show that the presented
class of sequences satisfy each of the conditions listed in
Assumption 3:
(a) Replacing the sequences by their given rules we obtain

γk
µ3
kδk

γ0
=
8cµ3
0δ0
≤ γ0
8cµ3

0δ0

(k + 1)−a+b(k + κ)3c
(k + 1)−a+b+3c.

Since a > b + 3c, the preceding term goes to zero verfying
Assumption 3(a).
(b) The given rules (12) imply that δk and µk are both non-
increasing sequences. Therefore, we have δkµk−1 ≤ δ1µ0
for any k ≥ 1. So, to show that Assumption 3(b) holds,
it is enought to show that δ1µ0 ≤ 1. From (12) we have
δ1 = δ02−b. Since we assumed that δ0µ0 ≤ 2b, we can
conclude that δ1µ0 ≤ 1 implying that Assumption 3(b) holds.
(c) Let k be an even number. Thus, κ = 2. From (12) we
have µk = µk+1 = µ02c
(k+2)c . Now, let k be an odd number.
Again, according to (12) can write
µ02c
(k + 1)c =

µ02c
(k + κ)c = µk.

((k + 1) + 2)c <

µk+1 =

µ02c

Therefore, µk given by (12) satisﬁes (4). Also, from (12) we
have µk → 0. Thus, Assumption 3(c) holds. µk satisﬁes (4)
and µk → 0.
(d) From (12), we can write

γkδkµk = γ0δ0µ02c

k=0

k=0

(k + 1)−(a+b+c) = ∞,

where the last inequality is due to the assumption that a +
b + c ≤ 1. Therefore, Assumption 3(d) holds.
(e) From (12), we have

∞(cid:88)

∞(cid:88)

(cid:18) γk

k=0

µk
≤ γ2
0
µ2
04c

(cid:19)2
(cid:32) 1(cid:88)

=

k=0

(k + κ)2c
(k + 1)2a

γ2
0
µ2
04c

k=0
(k + κ)2c
(k + 1)2a +

∞(cid:88)

k=2

(2k)2c

k2a

(cid:33)

< ∞

∞(cid:88)

∞(cid:88)

∞(cid:88)

∞(cid:88)

where the last inequality is due to a − c > 0.5. Therefore,
Assumption 3(e) is veriﬁed.
(f) Using (12), it follows

γkδkµ2

k = γ0δ0µ2

04c

(k + κ)−2c(k + 1)a+b

∞(cid:88)

k=0

≤ γ0δ0µ2
04c

k=0

(k + 1)−(2c+a+b) < ∞,

k=0

where the last inequality is due to a + 2c + b > 1. Therefore,
Assumption 3(e) holds.
(g) The rules in (12) imply that γk ,δk and µk are all non-
increasing sequences. We also assumed that γ0δ0µ0 ≤ 1.
Hence, γkδkµk ≤ 1 for any k ≥ 1 and Assumption 3(f)
holds.

Remark 1: When a = 0.75, b = 0, and c = 0.24, and

= 0;

γ0 = δ0 = µ0 = 0.9, the Assumption 3 is satisﬁed.
Assumption 4: [Sufﬁcient conditions on sequences for
convergence in mean] Let the sequences {γk},{µk}, and
{δk} be non-negative and satisfy the following conditions:
(a) limk→∞ γk
µ3
(b) δkµk−1 ≤ 1 for k ≥ 1;
kδk
(c) µk satisﬁes (4);
(d) There exist 0 < α < 1 and K1 ≥ 0 such that
≤ γk
kδk
(e) There exist a scalar B > 0 and K2 ≥ 0 such that

(1 + αγkδkµk) for k ≥ K1;

γk−1
k−1δk−1
µ3
k ≤ Bγk for k ≥ K2;

Theorem 2: [Convergence in mean] Consider the algo-
rithm (CR-SQN). Suppose Assumptions 1, 2 and 4 hold.
Then, there exists some K ≥ 0 such that

δkµ4

µ3

E[f (xk+1)] − f∗ ≤ θ

for any k ≥ K,

(13)

γk
µ3
kδk

where f∗ is the optimal value of problem (1),

θ = max

KδKeK+1

,

γK

0.5B(cid:107)x∗(cid:107)2 + 2(L + µ0) ν2

ρ2

1 − α

Proof:

with eK+1 := E[fK+1(xK+1)] − f∗.
Similar to the proof of Theorem 1, from
Assumption 4(a), there exists K ≥ 1 such that for any
k ≥ K0, the condition (8) holds and, therefore, the inequality
(9) holds. Let K = max{K0, K1, K2}. Taking expectation
from both sides of (9), we obtain for any solution x∗,

(cid:26) µ3

(cid:27)

,

ek+1 ≤ (1 − γkδkµk)ek + γkδk

(cid:107)x∗(cid:107)2

(cid:0)(ρµk−1)−1 + δk

µ2
k
2

(cid:1)2

ν2,

(L + µk)

+

γ2
k

2

where ek := E[fk(xk)] − f∗. Using Assumption 4(b), (c)

,

(14)

+ 2(L + µ0)

and (e), the preceding inequality yields
B
(cid:107)x∗(cid:107)2 γ2
ek+1 ≤ (1 − γkδkµk)ek +
k
µ2
2
k
γ2
for k ≥ K,
k
µ2
k

= (1 − γkδkµk)ek + B1
where B1 := B
ρ2 . We use induction to
show the desired result. First, we show that (13) holds for
k = K. We have
eK+1 = E[fK+1(xK+1)] − f∗

2 (cid:107)x∗(cid:107)2 + 2(L + µ0) ν2

ν2
ρ2

γ2
k
µ2
k

KδK(E[fK+1(xK+1)] − f∗)

γk−1
k−1δk−1
µ3

γK
µ3
KδK
implying that (13) holds for k = K. Now assume that ek ≤
, for some k ≥ K. We show that ek+1 ≤ θ γk
.
θ
From the induction hypothesis and (14) we have
+ B1

ek+1 ≤ (1 − γkδkµk) θ

γk−1
k−1δk−1
µ3
Using Assumption 4(d) we obtain

(cid:19) γK

(cid:18) µ3

µ3
KδK

γ2
k
µ2
k

≤ θ

γK

kδk

=

µ3

,

,

ek+1 ≤ (1 − γkδkµk)θ

(1 + αγkδkµk) + B1

γk
µ3
k δk

γ2
k
µ2
k

.

The deﬁnition of θ and B1 imply that the term θ(1− α)−B1
is non-negative. It follows

ek+1 ≤ θ

= θ

γk
µ3
kδk
γk
µ3
kδk

− θ(1 − α)

γ2
k
µ2
k

− (θ(1 − α) − B1)

γ2
+ B1
k
µ2
k
γ2
k
µ2
k

≤ θ

γk
µ3
kδk

,

This shows that the induction argument holds true. Also, we
2 (cid:107)xk+1(cid:107)2 ≥ f (xk+1).
have fk+1(xk+1) = f (xk+1) + µk+1
Therefore, we conclude that (13) holds.
Lemma 5: Let the sequences γk, δk, and µk be given
by (12), where γk, δ0, µ0 are positive scalars such that
δ0µ0 ≤ 2b, and a, b, and c are positive scalars that satisfy
the following conditions:

a > 3c + b, a + b < 1, −a + 4c + b ≥ 0.

(cid:18)

(cid:19)a − 1

Then, the sequences γk, δk, and µk satisfy Assumption 4.

Proof:

In the following, we verify the conditions of

Assumption 4.
Conditions (a), (b), and (c): This is already shown in parts
(a), (b) and (c) of the proof of Lemma 4 due to a > 3c + b,
c > 0, and δ0µ0 ≤ 2b.
(d) It sufﬁces to show there exist K1 and α ∈ (0, 1) such
that for any k ≥ K1
γk−1
γk

− 1 ≤ αγkδkµk.

δk
δk−1

(15)

µ3
k
µ3
k−1
From (12), we obtain

− 1 =

1 +

1
k

= 1 +

γk−1
γk

δk
δk−1
1
k

µ3
k
µ3
k−1
a
k

− 1 ≤ γk−1
γk
) − 1 = O

(cid:18) 1
(cid:19)
used the Taylor’s expansion of(cid:0)1 + 1

+ o(

k

,

k

where the ﬁrst inequality is implied due to both µk and δk
are non-increasing sequences, and in the second equation we

(cid:1)a. Therefore, since the

1

right hand-side of the relation (15) is of the order
ka+b+c and
that a + b + c < 1, the preceding inequality shows that such
α and K1 exist such that Assumption 4(d) holds.
(e) From (12), we have
δkµ4
k
γk

(k + 1)−a+b+4c .
Since we assumed −a + 4c + b ≥ 0, there exists B > 0 such
that Assumption 4(e) is satisﬁed.

= δ0µ02c(k + κ)−4c(k + 1)a−b ≤

δ0µ02c

Theorem 3: [Rate of convergence] Consider the algorithm
(CR-SQN). Suppose Assumptions 1 and 2 are satisﬁed. Let
the sequences γk, δk, and µk be given by (12) with a = 0.8,
b = 0, and c = 0.2, and δ0 = µ0 = 0.9 and γ0 > 0. Then,
(a) limk→∞ f (xk) = f∗ almost surely, where f∗ is the

Proof:

(a) The given values of a, b, c and δ0 and µ0
satisfy the conditions of Lemma 4. Therefore, all conditions
of Theorem 1 are met, and the desired statement follows.

optimal value of problem (1).

(b) We have

E[f (xk)] − f∗ = O(

√
1
k

5

).

(b) The given values of a, b, c and δ0 and µ0 satisfy
the conditions of Lemma 5. Therefore, all conditions of
Theorem 2 are satisﬁed, so from (13) we obtain

E[f (xk+1)] − f∗ ≤ θ

= O

γk
µ3
kδk

= O(

√
1
k

5

).

(cid:19)

(cid:18) k−0.8

k−0.6

Remark 2 (Computational cost): In large scale settings, a
natural concern related to the implementation of algorithm
(CR-SQN) is the computational effort in calculation of B−1
k .
An efﬁcient technique to calculate the inverse is the Cholesky
factorization where the matrix Bk is stored in the form of
k and only the matrices Lk and Dk are updated
LkDkLT
at each iteration. This calculation can be done in O(n2)
operations (see [13]). In large scale settings, the limited
memory variant of the proposed algorithm can be considered
which is a subject of our future work.

IV. NUMERICAL EXPERIMENTS

We consider a binary classiﬁcation problem studied in
[23] where the goal is to classify the credit card clients into
credible and non-credible based on their payment records
and other information. The data set is from the UCI Ma-
chine Learning repository. There are 23 features including
education, marital status, history of past payment and the
mount of bill statement in the past six months. We employ
the logistic regression loss function given by (2) where

(cid:96)(uT

i x, vi) := −vi ln(c(x, ui)) − (1 − vi) ln(1 − c(x, ui))
(16)
where c(x, ui) := (1 + exp(−uT
i x))−1, vi ∈ {0, 1} charac-
terizes the class’ type and ui ∈ R23 represents the vector of
features. We use 1000 data points to run the simulations.
We compare the performance of the proposed algorithm
(CR-SQN) with that of the regularized stochastic BFGS
(RES) algorithm in [17] and also the SA algorithm (SA). To
employ RES, since the objective function (2) is non-strongly
convex, we assume the function is regularized as in (3) for
some constant µ. Fig. 1 and 2 compare the performance
the three algorithms. Here we assumed that for CR-SQN,
ρ = 0.9, µ0 = δk = 1 for any k, and that γk and µk are
given by (12) with a = 0.8, and c = 0.2. Also, for RES,
we set µ = 1, δ = 1. In both RES and SA schemes, we
use γk = γ0/(k + 1). It is observed that in both cases, CR-
SQN outperforms RES. Comparing Fig. 1 with Fig. 2, we
also observe that the SA scheme seems very sensitive to the
choice of the initial stepsize γ0 which is known as a main
drawback of this scheme.

To perform a sensitivity analysis, we compare CR-SQN
with RES and SA in Table I and II. In Table I, we report the
averaged loss function of CR-SQN and RES for different set-
tings of regularization. We maintain the initial regularization
parameter of CR-SQN, µ0 and the regularization parameter
of RES, µ to be equal. We observe that in all settings, CR-
SQN attains a lower averaged loss value. In Table II, we
observe that by changing the initial stepsize γ0, except for
the case γ0 = 0.1, CR-SQN outperforms the SA scheme.

on a binary classiﬁcation problem is promising.

REFERENCES

[1] J. C. Spall, Introduction to Stochastic Search and Optimization:

Estimation, Simulation, and Control. Wiley, Hoboken, NJ, 2003.

[2] Y. M. Ermoliev, “Stochastic quasigradient methods,” in Numerical
Sringer-Verlag, 1983, pp.

Techniques for Stochastic Optimization.
141–185.

[3] V. S. Borkar and S. P. Meyn, “The O.D.E. method for convergence of
stochastic approximation and reinforcement learning,” SIAM J. Control
Optim., vol. 38, no. 2, pp. 447–469 (electronic), 2000.

[4] F. Facchinei and J.-S. Pang, Finite-dimensional variational inequalities
and complementarity problems. Vols. I,II, ser. Springer Series in
Operations Research. New York: Springer-Verlag, 2003.

[5] L. Bottou, “Large-scale machine learning with stochastic gradient
descent,” in Proceedings of the 19th International Conference on
Computational Statistics, Y. Lechevallier and G. Saporta, Eds. Paris,
France: Springer, 2010, pp. 177–187.

[6] R. H. Byrd, S. L. Hansen,

J. Nocedal, and Y. Singer, “A
stochastic Quasi-Newton method for large-scale optimization,” 2015,
arXiv:1401.7020v2 [math.OC].

[7] R. Tibshirani, “Regression shrinkage and selection via the lasso,”
Journal of Royal Statistical Society, vol. 58, no. 1, pp. 267–288, 1996.
[8] A. Shapiro, “Monte Carlo sampling methods,” in Handbook in Op-
erations Research and Management Science. Amsterdam: Elsevier
Science, 2003, vol. 10, pp. 353–426.

[9] H. Robbins and S. Monro, “A stochastic approximation method,” Ann.

Math. Statistics, vol. 22, pp. 400–407, 1951.

[10] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro, “Robust stochas-
tic approximation approach to stochastic programming,” SIAM Journal
on Optimization, vol. 19, no. 4, pp. 1574–1609, 2009.

[11] F. Youseﬁan, A. Nedi´c, and U. V. Shanbhag, “Self-tuned stochastic
approximation schemes for non-Lipschitzian stochastic multi-user op-
timization and nash games,” IEEE Transactions on Automatic Control,
2015, to appear.

[12] D. C. Liu and J. Nocedal, “On the limited memory bfgs method for
large scale optimization,” Math. Program., vol. 45, no. 3, pp. 503–528,
Dec. 1989. [Online]. Available: http://dx.doi.org/10.1007/BF01589116
[13] J. Nocedal and S. J. Wright, Numerical Optimization, 2nd ed. New

York: Springer, 2006.

[14] D.-H. Li and M. Fukushima, “A modiﬁed BFGS method and its global
convergence in nonconvex minimization,” Journal of Computational
and Applied Mathematics, vol. 129, pp. 15–35, 2001.

[15] A. Bordes and L. B. N. P. Gallinari, “SGD-QN: Careful quasi-newton
stochastic gradient descent,” Journal of Machine Learning Research,
vol. 10, pp. 1737–1754, 2009.

[16] N. N. Schraudolph, J. Yu, and S. Gunter, “A stochastic quasi-newton
method for online convex optimization,” In Proc. 11th Intl. Conf. on
Artiﬁcial Intelligence and Statistics (AIstats), pp. 433–440, 2007.

[17] A. Mokhtari and A. Ribeiro, “RES: regularized stochastic BFGS
algorithm,” IEEE Transactions on Signal Processing, vol. 62, no. 23,
pp. 6089–6104, 2014.

[18] ——, “Global convergence of online limited memory BFGS,” Journal

of Machine Learning Research, vol. 16, pp. 3151–3181, 2015.

[19] X. Wang, S. Ma, and W. Liu, “Stochastic quasi-Newton meth-
ods for nonconvex stochastic optimization,” 2014, arXiv:1412.1196
[math.OC].

[20] A. Lucchi, B. McWilliams, and T. Hofmann, “A variance reduced
stochastic newton method,” arXiv preprint arXiv:1503.08316 (2015).
[21] A. Nedi´c and S. Lee, “On stochastic subgradient mirror-descent
algorithm with weighted averaging,” SIAM Journal on Optimization,
vol. 24, no. 1, pp. 84–107, 2014.

[22] B. Polyak, Introduction to optimization. New York: Optimization

Software, Inc., 1987.

[23] I. C. Yeh and C. H. Lien, “The comparisons of data mining techniques
for the predictive accuracy of probability of default of credit card
clients,” Expert Systems with Applications, vol. 36, no. 2, pp. 2473–
2480, 2007.

Fig. 1: CR-SQN vs. RES vs. SA - γ0 = 0.01

Fig. 2: CR-SQN vs. RES vs. SA - γ0 = 0.1

V. CONCLUDING REMARKS

To address stochastic optimization problems in the ab-
sence of strong convexity, we developed a cyclic regularized
stochastic SQN method where at each iteration, the gradient
mapping and the Hessian approximate matrix are regularized.
To maintain the secant condition and carry out the conver-
gence analysis, we do the regularization in a cyclic manner.
Under speciﬁc update rules for stepsize and regularization
parameters, our algorithm generates a sequence that con-
verges to an optimal solution of the original problem in both
almost sure and expected senses. Importantly, our scheme is
characterized by a derived convergence rate in terms of the
objective function values. Our preliminary empirical analysis

CR-SQN

µ0
1
0.1
0.01
0.001

ave. loss
0.6684
0.6683
0.8205
4.3090

RES

ave. loss
0.6839
0.6949
0.9017
5.0424

µ
1
0.1
0.01
0.001

TABLE I: CR-SQN vs. RES: varying regularization

parameter

CR-SQN

γ0
0.1
0.01
0.001
0.0001

ave. loss
0.6673
0.6683
0.6901
0.6928

SA

ave. loss
0.6540
0.6888
0.6927
0.6931

γ0
0.1
0.01
0.001
0.0001

TABLE II: CR-SQN vs. SA: varying initial stepsize

Iteration01002003004005006007008009001000Log of average loss-0.4-0.39-0.38-0.37SARESCR-SQNIteration01002003004005006007008009001000Log of average loss-0.42-0.4-0.38-0.36SARESCR-SQN