6
1
0
2

 
r
a

M
8

 

 
 
]

B
D
.
s
c
[
 
 

2
v
3
9
8
0
0

.

3
0
6
1
:
v
i
X
r
a

Frequency-hiding Dependency-preserving Encryption for

Outsourced Databases

Boxiang Dong, Wendy Wang
Department of Computer Science
Stevens Institute of Technology

Hoboken, NJ

bdong, hwang4@stevens.edu

ABSTRACT
The cloud paradigm enables users to outsource their data to
computationally powerful third-party service providers for
data management. Many data management tasks rely on
the data dependencies in the outsourced data. This raises an
important issue of how the data owner can protect the sen-
sitive information in the outsourced data while preserving
the data dependencies. In this paper, we consider functional
dependency (F D), an important type of data dependency.
We design a F D-preserving encryption scheme, named F 2,
that enables the service provider to discover the F Ds from
the encrypted dataset. We consider the frequency analysis
attack, and show that the F 2 encryption scheme can defend
against the attack under Kerckhoﬀ’s principle with provable
guarantee. Our empirical study demonstrates the eﬃciency
and eﬀectiveness of F 2.

1.

INTRODUCTION

With the fast growing of data volume, the sheer size of
today’s data sets is increasingly crossing the petabyte bar-
rier, which far exceeds the capacity of an average business
computer. In-house solutions may be expensive due to the
purchase of software, hardware, and staﬃng cost of in-house
resources to administer the software. Lately, due to the
advent of cloud computing and its model for IT services
based on the Internet and big data centers, a new model has
emerged to give companies a cheaper alternative to in-house
solutions: the users outsource their data management needs
to a third-party service provider. Outsourcing of data and
computing services is becoming commonplace and essential.
Many outsourced data management applications rely on
data dependencies in the outsourced datasets. A typical
type of data dependency is functional dependency (FD). In-
formally, a F D : A → B constraint indicates that an at-
tribute set A uniquely determines an attribute set B. For
example, the FD Zipcode→City indicates that all tuples of
the same Zipcode values always have the same City values.
FDs serve a wide range of data applications, for example,

ID A
a1
t1
t2
a1
a1
t3
t4
a1

B
b1
b1
b1
b1

C
c1
c2
c3
c1

(a) Base table D

(F D : A → B)

ID A
C
ˆa1
ˆc1
t1
1
1
ˆa1
ˆc1
t2
1
2
ˆa2
ˆc1
t3
1
3
ˆa2
ˆc2
t4
1
1
(c) ˆD2 encrypted by

B
ˆb1
1
ˆb2
1
ˆb1
1
ˆb2
1

C
ID A
ˆc1
ˆa1
t1
ˆc2
ˆa1
t2
ˆc3
ˆa1
t3
ˆc1
ˆa1
t4
(b) ˆD1 encrypted

B
ˆb1
ˆb1
ˆb1
ˆb1

by deterministic encryption

(not frequency-hiding)

ID A
ˆa1
t1
1
ˆa1
t2
1
ˆa2
t3
1
ˆa2
t4
1
(d) ˆD3 encrypted by

B
ˆb1
1
ˆb1
1
ˆb2
1
ˆb2
1

C
ˆc1
1
ˆc1
2
ˆc1
3
ˆc2
1

probabilistic encryption on

A and B individually
(not FD-preserving)

probabilistic encryption
on attribute set {A, B}

(Frequency-hiding & FD-preserving)

Figure 1: An example of various encryption schemes

improving schema quality through normalization [3, 6], and
improving data quality in data cleaning [10]. Therefore, to
support these applications in the outsourcing paradigm, it is
vital that FDs are well preserved in the outsourced datasets.
Outsourcing data to a potentially untrusted third-party
service provider (server) raises several security issues. One
of the issues is to protect the sensitive information in the
outsourced data. The data conﬁdentiality problem is tra-
ditionally addressed by means of encryption [8]. Our goal
is to design eﬃcient FD-preserving data encryption meth-
ods, so that the FDs in the original dataset still hold in
the encrypted dataset. A naive method is to apply a sim-
ple deterministic encryption scheme (i.e. the same plaintext
values are always encrypted as the same ciphertext for a
given key) on the attributes with FDs. For instance, con-
sider the base table D in Figure 1 (a). Assume it has a FD:
F : A → B. Figure 1 (b) shows the encrypted dataset ˆD1
by applying a deterministic encryption scheme on individ-
ual values of the attributes in D. Apparently F is preserved
in ˆD1. However, this naive method has drawbacks. One
of the main drawbacks is that the deterministic encryption
scheme is vulnerable against the frequency analysis attack,
as the encryption preserves the frequency distribution. The
attacker can easily map the ciphertext (e.g., ˆa1) to the plain-
text values (e.g., a1) based on their frequency.

A straightforward solution to defend against the frequency
analysis attack is instead of the deterministic encryption
schemes, using the probabilistic encryption schemes (i.e., the
same plaintext values are encrypted as diﬀerent ciphertexts)
to hide frequency. Though the probabilistic encryption can

1

i , ˆcj

i (ˆbj

provide provable guarantee of semantic security [11], it may
destroy the FDs in the data. As an example, consider the
table D shown in Figure 1 (a) again. Figure 1 (c) shows an
instance ˆD2 by applying the probabilistic encryption scheme
at the attributes A, B, and C individually. We use the no-
tation ˆaj
i , resp.) as a ciphertext value of ai (bi, ci,
resp.) by the probabilistic encryption scheme. The four oc-
currences of the plaintext value a1 are encrypted as two ˆa1
1s
(tuple t1 and t2) and two ˆa2
1s (tuple t3 and t4), while the four
occurrences of the plaintext value b1 are encrypted as two ˆb1
1s
(tuple t1 and t3) and two ˆb2
1s (tuple t2 and t4). Now the fre-
quency distribution of the plaintext and ciphertext values is
not close. However, the FD A → B does not hold on ˆD2 any-
more, as the same (encrypted) value ˆa1 of attribute A is not
associated with the same cipher value of attribute B. This
example shows that the probabilistic encryption scheme, if
it is applied on individual attributes, cannot preserve the
FDs. This raises the challenge of ﬁnding the appropriate at-
tribute set to be encrypted by the probabilistic encryption
scheme. It is true that applying the probabilistic encryption
scheme on FD attributes as a unit (e.g., on {A, B} as shown
in Figure 1 (d)) can preserve FDs. However, ﬁnding F Ds
needs intensive computational eﬀorts [16]. The data owner
may lack of computational resources and/or knowledge to
discover FDs by herself. Therefore, we assume that FDs are
not available for the encryption.

Contributions. In this paper, we design F 2, a frequency-
hiding, FD-preserving encryption scheme based on proba-
bilistic encryption. We consider the attacker who may pos-
sess the frequency distribution of the original dataset as well
as the details of the encryption scheme as the adversary
knowledge. We make the following contributions.

(i) F 2 allows the data owner to encrypt the data with-
out awareness of any FD in the original dataset. To defend
against the frequency analysis attack on the encrypted data,
we apply the probabilistic encryption in a way that the fre-
quency distribution of the ciphertext values is always ﬂat-
tened regardless of the original frequency distribution. This
makes F 2 robust against the frequency analysis attack. To
preserve FDs, we discover maximal attribute sets (M ASs)
on which F Ds potentially exist. Finding M ASs is much
cheaper than ﬁnding F Ds, which enables the data owner to
aﬀord its computational cost. The probabilistic encryption
is applied at the granularity of M ASs.

(ii) We consider both cases of one single M AS and mul-
tiple M ASs, and design eﬃcient encryption algorithms for
each case. The challenge is that when there are multiple
M ASs, there may exist conﬂicts if the encryption is applied
on each M AS independently. We provide conﬂict resolution
solution, and show that the incurred amounts of overhead
by conﬂict resolution is bounded by the size of the dataset
as well as the number of overlapping M AS pairs.

(iii) Applying probabilistic encryption may introduce false
positive FDs that do not exist in the original dataset but in
the encrypted data. We eliminate such false positive FDs by
adding a small amount of artiﬁcial records. We prove that
the number of such artiﬁcial records is independent of the
size of the outsourced dataset.

(iv) We formally deﬁne the frequency analysis attack, and
the α-security model to defend against the frequency anal-
ysis attack. We show that F 2 can provide provable security
guarantee against the frequency analysis attack, even under
the Kerckhoﬀs’s principle [27] (i.e., the encryption scheme

2

is secure even if everything about the encryption scheme,
except the key, is public knowledge).

(v) We evaluate the performance of F 2 on both real and
synthetic datasets. The experiment results show that F 2 can
encrypt large datasets eﬃciently with high security guaran-
tee. For instance, it takes around 1,500 seconds to encrypt
a benchmark dataset of size 1GB with high security guaran-
tee. Furthermore, F 2 is much faster than FD discovery. For
instance, it takes around 1,700 seconds to discover FDs from
a dataset of 64KB records, while only 8 seconds to encrypt
the dataset by F 2.
Applications This is the ﬁrst algorithm that preserves use-
ful FDs with provable security guarantees against the fre-
quency analysis attack in the outsourcing paradigm. To
see the relevance of this achievement, consider that FDs
have been identiﬁed as a key component of several classes
of database applications, including data schema reﬁnement
and normalization [3, 6, 21], data cleaning [4, 10], and schema-
mapping and data exchange [20]. Therefore, we believe that
the proposed FD-preserving algorithm represents a signiﬁ-
cant contribution towards the goal of reaching the full matu-
rity of data outsourcing systems (e.g., database-as-a-service
[13] and data-cleaning-as-a-service [9] systems).

The rest of this paper is organized as follows. Section 2
describes the preliminaries. Section 3 discusses the details of
our encryption scheme. Section 4 presents the security anal-
ysis. Section 5 evaluates the performance of our approach.
Related work is introduced in Section 6, and Section 7 con-
cludes the paper.
2. PRELIMINARIES
2.1 Outsourcing Setting

We consider the outsourcing framework that contains two
parties: the data owner and the service provider (server).
The data owner has a private relational table D that con-
sists of m attributes and n records. We use r[X] to specify
the value of record r on the attribute(s) X. To protect the
private information in D, the data owner encrypts D to ˆD,
and sends ˆD to the server. The server discovers the depen-
dency constraints of ˆD. These constraints can be utilized for
data cleaning [10] or data schema reﬁnement [3]. In princi-
ple, database encryption may be performed at various levels
of granularity. However, the encryption at the coarse levels
such as attribute and record levels may disable the depen-
dency discovery at the server side. Therefore, in this paper,
we consider encryption at cell level (i.e., each data cell is
encrypted individually). Given the high complexity of FD
discovery [16], we assume that the data owner is not aware
of any FD in D before she encrypts D.
2.2 Functional Dependency

In this paper, we consider functional dependency (FD)
as the data dependency that the server aims to discover.
Formally, given a relation R, there is a FD between a set
of attributes X and Y in R (denoted as X → Y ) if for any
pair of records r1, r2 in R, if r1[X] = r2[X], then r1[Y ] =
r2[Y ]. We use LHS(F ) (RHS(F ), resp.)
to denote the
attributes at the left-hand (right-hand, resp.) side of the
FD F . For any FD F : X → Y such that Y ⊆ X, F is
considered as trivial. In this paper, we only consider non-
trivial F Ds. It is well known that for any FD F : X → Y
such that Y contains more than one attribute, F can be
decomposed to multiple functional dependency rules, each

having a single attribute at the right-hand side. Therefore,
for the following discussions, WLOG, we assume that the
FD rules only contain one single attribute at the right-hand
side.
2.3 Deterministic and Probabilistic Encryp-

tion

Our encryption scheme Π consists of the following three

algorithms:

• k ← KeyGen(λ) generates a key based on the input se-

curity parameter λ.

• y ← Encrypt(x, k) encrypts the input value x using key

k and outputs the ciphertext y.

• x ← Decrypt(y, k) computes the plaintext x based on the

ciphertext y and key k.

Based on the relationship between plaintexts and cipher-
texts, there are two types of encryption schemes: determin-
istic and probabilistic schemes. Given the same key and
plaintext, a deterministic encryption scheme always gener-
ates the same ciphertext. One weakness of the determinis-
tic ciphertexts is that it is vulnerable against the frequency
analysis attack. On the other hand, the probabilistic encryp-
tion scheme produces diﬀerent ciphertexts when encrypting
the same message multiple times. The randomness brought
by the probabilistic encryption scheme is essential to defend
against the frequency analysis attack [18]. In this paper, we
design a FD-preserving, frequency-hiding encryption scheme
based on probabilistic encryption. We use the private proba-
bilistic encryption scheme based on pseudorandom functions
[17]. Speciﬁcally, for any plaintext value p, its ciphertext
e =< r, Fk(r) ⊕ p >, where r is a random string of length
λ, F is a pseudorandom function, k is the key, and ⊕ is the
XOR operation.
2.4 Attacks and Security Model

In this paper, we consider the curious-but-honest server,
i,e., it follows the outsourcing protocols honestly (i.e., no
cheating on storage and computational results), but it is
curious to extract additional information from the received
dataset. Since the server is potentially untrusted, the data
owner sends the encrypted data to the server. The data
owner considers the true identity of every cipher value as
the sensitive information which should be protected.
Frequency analysis attack. We consider that the at-
tacker may possess the frequency distribution knowledge of
data values in D. In reality, the attacker may possess ap-
proximate knowledge of the value frequency in D. However,
in order to make the analysis robust, we adopt the conserva-
tive assumption that the attacker knows the exact frequency
of every plain value in D, and tries to break the encryption
scheme by utilizing such frequency knowledge. We formally
deﬁne the following security game Expf req
A,Π on the encryp-
tion scheme Π = (KeyGen, Encrypt, Decrypt) :

• A random key k is generated by running KeyGen. A set
of plaintexts P is encrypted by running Encrypt(P, k). A
set of ciphertext values E ← Encrypt(P, k) is returned.

• A ciphertext value e is randomly chosen from E . Let
p = Decrypt(e, k). Let f reqP (p) and f reqE (e) be the
frequency of p and e respectively. Let f req(P) be the fre-
quency distribution of P. Then e, f reqE (e) and f req(P)
is given to the adversary Af req.

• Af req outputs a value p′ ∈ P.

• The output of the experiment is deﬁned to be 1 if p′ =
Decrypt(e, k), and 0 otherwise. We write Expf req
A,Π = 1 if
the output is 1 and in this case we say that Af req succeed.

Security Model. To measure the robustness of the en-
cryption scheme against the frequency analysis attack, we
formally deﬁne α-security.

Definition 2.1. [α-security]

An encryption scheme
Π is α-secure against frequency analysis attack if for every
adversary Af req it holds that

P r[Expf req

A,Π = 1] ≤ α,

where α is a value between 0 and 1.

Intuitively, the smaller α is, the stronger security that Π is
against the frequency analysis attack. In this paper, we aim
at designing an encryption scheme that provides α-security
for any given α ∈ (0, 1).
Kerckhoﬀs’s principle. Kerckhoﬀs’s principle [27] requires
that a cryptographic system should be secure even if ev-
erything about the system, except the key, is public knowl-
edge. Thus, we also require the encryption scheme to satisfy
α-security under Kerckhoﬀs’s principle (i.e., the adversary
knows the details of F 2 encryption algorithm).

3. FD-PRESERVING ENCRYPTION

The key to design a FD-preserving encryption algorithm
is to ﬁrst identify the set of attributes on which the proba-
bilistic encryption scheme is applied. We have the following
theorem to show that for any FD F , if the probabilistic en-
cryption scheme is applied on the attribute set that includes
both LHS(F ) and RHS(F ), F is still preserved in the en-
crypted data.

Theorem 3.1. Given a dataset D and any FD F of D,
let the attribute set A be the attribute sets on which the prob-
abilistic encryption scheme is applied on, and let ˆD be the
encryption result. Then F always holds in ˆD if LHS(F ) ∪
RHS(F ) ⊆ A.

Proof. Assume that there is a FD: A → B which holds
in D but not in ˆD.
It must be true that there exists at
least one pair of records r1, r2 such that r1[A] = r2[A] and
r1[B] = r2[B] in D, while in ˆD, ˆr1[A] = ˆr2[A] but ˆr1[B] 6=
ˆr2[B]. According to the HS scheme which is applied on an
attribute set A s.t. LHS(F ) ∪ RHS(F ) ⊆ A, there are two
cases. First, if r1 and r2 are taken as the same instance, then
ˆr1 and ˆr2 have the same value in every attribute. It cannot
happen as ˆr1[B] 6= ˆr2[B]. Second, if r1 and r2 are taken as
diﬀerent instances, then it must be true that ˆr1[A] 6= ˆr2[A]
and ˆr1[B] 6= ˆr2[B] according to Requirement 2 of the HS
scheme. So ˆr1 and ˆr2 cannot break the FD: A → B in ˆD.

To continue our running example, consider the base ta-
ble in Figure 1 (a). Figure 1 (d) shows an example table
ˆD3 of applying the probabilistic encryption scheme on the
attribute set {A, B}. By this scheme, the four instances of
(a1, b1) are encrypted as (ˆa1
1). Now the FD
A → B still holds on ˆD3.

1) and (ˆa2

1, ˆb1

1, ˆb2

Based on Theorem 3.1, we formally deﬁne our FD-preserving

probabilistic encryption scheme. We use |σA=r[A](D)| to
specify the number of records in D that have the same value
as r[A], for a speciﬁc record r and a set of attributes A.

3

Definition 3.1. [FD-preserving probabilistic encryp-

tion scheme] Given a table D, a FD F of D, and a set
of attributes A = {A1, . . . , Ag} of D such that LHS(F ) ∪
RHS(F ) ⊆ A, for any instance r{a1, . . . , ag} ∈ D, let
f = |σA=r[A](D)|. When f > 1, the FD-preserving proba-
bilistic encryption scheme encrypts the f instances as t > 1
unique instances {r1, . . . , rt}, such that r1 = {ˆa1
g} of
frequency f1, . . . , and rt = {ˆat
g} of frequency ft. We
require that:

1, . . . , ˆa1

1, . . . , ˆat

• Requirement 1: Pt

• Requirement 2: ∀i (1 ≤ i ≤ g), ˆax
[1, t] where x 6= y.

i=1 fi = f ;

i 6= ˆay

i , for all x, y ∈

Requirement 1 requires when encrypting a plaintext value
set to multiple diﬀerent ciphertext instances, the sum of
frequency of these ciphertext instances is the same as the
frequency of the plaintext value set. Requirement 2 requires
that the ciphertext values of the same plaintext value set
do not overlap at any single attribute. The aim of Require-
ment 2 is to provide α-security under Kerckhoﬀs’s principle
(more details in Section 4.2). We require that f > 1, since
the probabilistic encryption scheme becomes a deterministic
encryption scheme when f = 1.

Our FD-preserving probabilistic encryption method con-
sists of four steps: (1) ﬁnding maximum attribute sets; (2)
splitting-and-scaling; (3) conﬂict resolution; and (4) elimi-
nating false positive FDs. We explain the details of these
four steps in the following subsections.
3.1 Step 1: Finding Maximum Attribute Sets
Theorem 3.1 states that the set of attributes on which the
probabilistic encryption scheme is applied should contain
all attributes in FDs. Apparently the set of all attributes
of D satisﬁes the requirement. However, it is not a good
solution since it is highly likely that there does not exist
a probabilistic encryption scheme, due to the reason that
f = |σA=r[A](D)| is more likely to be 1 when A contains
more attributes. Now the main challenge is to decide the
appropriate attribute set A that the probabilistic encryption
scheme will be applied on, assuming that the data owner
is not aware of the existence of any F D. To address this
challenge, we deﬁne the maximum attribute set on which
there exists at least one instance whose frequency is greater
than 1. Formally,

Definition 3.2. [Maximum Attribute Set (M AS)]
Given a dataset D, an attribute set A of D is a maximum
attribute set M AS if: (1) there exists at least an instance ⊣
of A such that |σA=⊣(D)| > 1; and (2) for any attribute set
A′ of D such that A ⊆ A′, there does not exist an instance
⊣′ of A′ s.t. |σA′=⊣′ (D)| > 1.
Our goal is to design the algorithm that ﬁnds all M ASs of
a given dataset D. Note that the problem of ﬁnding M ASs
is not equivalent to ﬁnding FDs. For instance, consider the
base table D in Figure 1 (a). Its M ASs is {A, B, C}. But its
FD is A → B. In general, given a set of M ASs M and a set
of FDs F, for each FD F ∈ F, there always exists at least
an M AS M ∈ M such that (LHS(F ) ∪ RHS(F )) ⊆ M .

In general, ﬁnding M ASs is quite challenging given the
exponential number of attribute combinations to check. We
found out that our M AS is equivalent to the maximal non-
unique column combination [15]. Informally, maximal non-
unique column combination refers to a set of columns whose
projection has duplicates. It has been shown that ﬁnding

all (non-)unique column combination is an NP-hard prob-
lem [12].
In [15], the authors designed a novel algorithm
named Ducc that can discover maximal non-unique column
combinations eﬃciently. The complexity of Ducc is decided
by the solution set size but not the number of attributes.
Therefore, we adapt the Ducc algorithm [15] to ﬁnd M ASs.
Due to the space limit, we omit the details of the algorithm
here. For each discovered M AS, we ﬁnd its partitions [16].
We say two tuples r and r′ are equivalent with respect to a
set of attributes X if r[X] = r′[X].

Definition 3.3. [Equivalence Class (EC) and Par-
[16] The equivalence class (EC) of a tuple r with
titions]
respect to an attribute set X, denoted as rX , is deﬁned as
rX = {r′|r[A] = r′[A], ∀A ∈ X}. The size of rX is deﬁned
as the number of tuples in rX, and the representative value
of rX is deﬁned as r[X]. The set πX = {rX |r ∈ D} is de-
ﬁned as a partition of D under the attribute set X. That
is, πX is a collection of disjoint sets (ECs) of tuples, such
that each set has a unique representative value of a set of
attributes X, and the union of the sets equals D.
As an example, consider the dataset ˆD3 in Figure 1 (d),
π{A,B} consists of two ECs whose representative values are
{ˆa1
1}. Apparently, a M AS is an attribute
set whose partitions contain at least one equivalence class
whose size is more than 1.
3.2 Step 2: Splitting-and-scaling Encryption
After the M ASs and their partitions are discovered, we
design two steps to apply the probabilistic encryption scheme
on the partitions: (1) grouping of ECs, and (2) splitting and
scaling on the EC groups. Next, we explain the details of
the two steps.
3.2.1 Step 2.1. Grouping of Equivalence Classes

1} and {ˆa2

1, ˆb2

1, ˆb1

To provide α-security, we group the ECs in the way that
each equivalence class belongs to one single group, and each
group contains at least k ≥ [ 1
α ] ECs, where α is the thresh-
old for α-security. We use ECG for the equivalence class
group in short.

We have two requirements for the construction of ECGs.
First, we prefer to put ECs of close sizes into the same
group, so that we can minimize the number of new tuples
added by the next splitting & scaling step (Section 3.2.2).
Second, we do not allow any two ECs in the same ECG to
have the same value on any attribute of M AS. Formally,

Definition 3.4. [Collision of ECs] Given a M AS M
and two equivalence classes Ci and Cj of M , we say Ci and
Cj have collision if there exists at least one attribute A ∈ M
such that Ci[A] = Cj [A].
For security reason, we require that all ECs in the same
ECG should be collision-free (more details in Section 4.1).
To construct ECGs that satisfy the aforementioned two
requirements, ﬁrst, we sort the equivalence classes by their
sizes in ascending order. Second, we group the collision-free
ECs with the closest size into the same ECG, until the
number of non-collisional ECs in the ECG reaches k = [ 1
α ].
It is possible that for some ECGs, the number of ECs that
can be found is less than the required k = [ 1
In this
case, we add fake collision-free ECs to achieve the size k
requirement. The fake ECs only consist of the values that
do not exist in the original dataset. The size of these fake
ECs is set as the minimum size of the ECs in the same
ECG. We must note that the server cannot distinguish the

α ].

4

fake values from real ones, even though it may be aware
of some prior knowledge of the outsourced dataset. This
is because both true and fake values are encrypted before
outsourcing.

Equivalence class
{r1, r4, r5, r7, r12}

ID Representative value
C1
C2
C3
C4
C5
Figure 2: An example of ECG construction

(a1, b1)
(a1, b2)
(a2, b2)
(a2, b1)
(a3, b3)

{r3, r9, r16}
{r10, r11}
{r13, r15}

{r2, r6, r8, r14}

Size

5
4
3
2
2

As an example, consider an M AS M = {A, B} and its
ﬁve ECs shown in Figure 2. Assume it is required to meet
1
3 -security (i.e., α = 1
3 ). The two ECGs are ECG1 =
{C1, C3, C6}, and ECG2 = {C2, C4, C5}, where C6 (not
shown in Figure 2) is a fake EC whose representative value
is (a4, b4) (a4 and b4 do not exist in the original dataset).
Both ECG1 and ECG2 only have collision-free ECs, and
each ECG contains at least three ECs. Note that C1 and
C2 cannot be put into the same ECG as they share the same
value a1, similarly for C2 and C3 as well as for C3 and C4.

3.2.2 Step 2.2. Splitting-and-scaling (S&S)

This step consists of two phases, splitting and scaling. In
particular, consider an ECG C = {C1, . . . , Cx}, in which
each EC Ci is of size fi (1 ≤ i ≤ x). By splitting, for
each Ci, its fi (identical) plaintext values are encrypted to
̟ unique ciphertext values, each of frequency [ fi
̟ ], where
̟ is the split factor whose value is speciﬁed by the user.
The scaling phase is applied after splitting. By scaling, all
the ciphertext values reach the same frequency by adding
additional copies up to [ fmax
̟ ], where fmax is the maximum
size of all ECs in C. After applying the splitting & scaling
(S&S), all ciphertext values in the same ECG are of the
same frequency.

It is not necessary that every EC must be split. Our aim
is to ﬁnd a subset of given ECs whose split will result in the
minimal amounts of additional copies added by the scaling
phase.
In particular, given an ECG C = {C1, . . . , Ck} in
which ECs are sorted by their sizes in ascending order (i.e.,
Ck has the largest size), we aim to ﬁnd the split point j
of C such that each EC in {C1, . . . , Cj−1} is not split but
each EC in {Cj , . . . , Ck} is split. We call j the split point.
Next, we discuss how to ﬁnd the optimal split point that
delivers the minimal amounts of additional copies by the
scaling phase. There are two cases: (1) the size of Ck is still
the largest after the split; and (2) the size of Ck is not the
largest anymore, while the size of Cj−1 (i.e., the EC of the
largest size among all ECs that are not split) becomes the
largest. We discuss these two cases below.

Case 1:

[ fk
̟ ] ≥ fj−1, i.e., the split of Ck still has the
largest frequency within the group. In this case, the total
number of copies added by the scaling step is

R1 =

([

fk
̟

j−1

Xi=1

] − fi) +

k

Xi=j

(fk − fi).

It can be easily inferred that when j = max{j|fj−1 ≤ [ fk
R1 is minimized.

̟ ]},

Case 2: [ fk

̟ ] < fj−1, which means that Cj−1 enjoys the
largest frequency after splitting. For this case, the number
of duplicates that is to be added is:

R2 =

j−1

Xi=1

(fj−1 − fi) + ̟

(fj−1 − [

fi
̟

]).

k

Xi=j

R2 is not a linear function of j. Thus we deﬁne jmax =
max{j|[ fk
̟ ] > fj−1}. We try all j ∈ [jmax, k] and return j
that delivers the minimal R2.

For any given ECG, the complexity of ﬁnding its optimal
split point is O(|ECG|). In practice, the optimal split point
j is close to the ECs of the largest frequency (i.e., few split
is needed).

Essentially the splitting procedure can be implemented by
the probabilistic encryption. In particular, for any plaintext
value p, it is encrypted as e =< r, Fk(r) ⊕ p >, where r is
a random string of length λ, F is a pseudorandom function,
k is the key, and ⊕ is the XOR operation. The splits of the
same EC can easily be generated by using diﬀerent random
values r.
In order to decrypt a ciphertext e =< r, s >,
we can recover p by calculating p = Fk(r) ⊕ s. For security
concerns, we require that the plaintext values that appear in
diﬀerent ECGs are never encrypted as the same ciphertext
value. The reason will be explained in Section 4.1. The
complexity of the S&S step is O(t2), where t is the number
of equivalence classes of D. As t = O(nq), the complexity is
O(n2q2), where n is the number of tuples in D, and q is the
number of M ASs.
3.3 Step 3: Conﬂict Resolution

So far the grouping and splitting & scaling steps are ap-
plied on one single M AS.
In practice, it is possible that
there exist multiple M ASs. The problem is that, applying
grouping and splitting & scaling separately on each M AS
may lead to conﬂicts. There are two possible scenarios of
conﬂicts:
(1) Type-1. Conﬂicts due to scaling: there exist tuples that
are required to be scaled by one M AS but not so by another
M AS; and
(2) Type-2. Conﬂicts due to shared attributes: there exist
tuples whose value on attribute(s) Z are encrypted diﬀer-
ently by multiple M ASs, where Z is the overlap of these
M ASs.

It initially seems true that there may exist the conﬂicts
due to splitting too; some tuples are required to be split ac-
cording to one M AS but not by another. But our further
analysis shows that such conﬂicts only exist for overlapping
M ASs, in particular, the type-2 conﬂicts. Therefore, deal-
ing with type-2 conﬂicts covers the conﬂicts due to splitting.
The aim of the conﬂict resolution step is to synchronize
the encryption of all M ASs. Given two M ASs of the at-
tribute sets X and Y , we say these two M ASs overlap if X
and Y overlap at at least one attribute. Otherwise, we say
the two M ASs are non-overlapping. Next, we discuss the
details of the conﬂict resolution for non-overlapping M ASs
(Section 3.3.1) and overlapping M ASs (Section 3.3.2).
3.3.1 Non-overlapping M ASs

Given two M ASs of attribute sets X and Y such that X
and Y do not overlap, only the type-1 conﬂicts (i.e., conﬂicts
due to scaling) are possible. WLOG we assume a tuple r is
required to be scaled by applying scaling on the ECG of rX
but not on any ECG of rY . The challenge is that simply
scaling of r makes the ECG of rY fails to have homogenized
frequency anymore. To handle this type of conﬂicts, ﬁrst,
we execute the grouping and splitting & scaling over πX and
πY independently. Next, we look for any tuple r such that r

5

ID A
a3
r1
a1
r2
a2
r3
a2
r4
r5
a3
a1
r6

B
b2
b2
b2
b2
b2
b1

C
c1
c1
c1
c2
c2
c3

ID A
ˆa1
r1
3
ˆa1
r2
1
ˆa1
r3
2
ˆa1
r4
2
ˆa1
r5
3
ˆa2
r6
1

B
ˆb1
2
ˆb3
2
ˆb2
2
ˆb2
2
ˆb1
2
ˆb1
1

ID B
ˆb3
r1
2
ˆb3
r2
2
ˆb3
r3
2
ˆb4
r4
2
ˆb4
r5
2
ˆb1
r6
1

C
ˆc1
1
ˆc1
1
ˆc1
2
ˆc1
2
ˆc1
2
ˆc1
3

ID A
ˆa1
r1
3
ˆa1
r2
1
ˆa1
r3
2
ˆa1
r4
2
ˆa1
r5
3
ˆa2
r6
1

B

2

ˆb1
2 / ˆb3
ˆb3
2
ˆb2
2 / ˆb3
ˆb2
2 / ˆb4
ˆb1
2 / ˆb4
ˆb1
1

2

2

2

C
ˆc1
1
ˆc1
1
ˆc1
1
ˆc1
2
ˆc1
2
ˆc1
3

ID A
ˆa1
r1
3
ˆa1
r2
1
ˆa1
r3
2
ˆa1
r4
2
ˆa1
r5
3
ˆa2
r6
1

B
ˆb1
2
ˆb3
2
ˆb3
2
ˆb4
2
ˆb1
2
ˆb1
1

C
ˆc1
1
ˆc1
1
ˆc1
1
ˆc1
2
ˆc1
2
ˆc1
3

ID
r1
r2
r3
r4
r5
r6
r7
r8
r9
r10

(a) Dataset D

F : C → B

(b) EncX (D)

(c) EncY (D)

(d) Encryption with

conﬂicts

(e) ˆD1: Encryption by

the naive solution

Figure 3: An example of conﬂict resolution of two overlapping M ASs

(f) ˆD2: Encryption by

conﬂict resolution

A
ˆa1
3
ˆa1
1
ˆa1
2
ˆa1
2
ˆa1
3
ˆa2
1
ˆa2
3
ˆa2
2
ˆa3
2
ˆa3
3

B
ˆb1
2
ˆb3
2
ˆb2
2
ˆb2
2
ˆb1
2
ˆb1
1
ˆb3
2
ˆb3
2
ˆb4
2
ˆb4
2

C
ˆc2
1
ˆc1
1
ˆc3
1
ˆc2
2
ˆc3
2
ˆc1
3
ˆc1
1
ˆc1
1
ˆc1
2
ˆc1
2

is required to have ℓ (ℓ > 1) copies to be inserted by splitting
& scaling over πX but free of split and scaling over πY . For
such r, we modify the values of the ℓ copies of tuple r, ensur-
ing that for each copy r′, r′[X] = r[X] while r′[Y ] 6= r[Y ].
To avoid collision between ECGs, we require that no r′[Y ]
value exists in the original dataset D. By doing this, we
ensure that the ECGs of both rX and rY still achieve the
homogenized frequency distribution. Furthermore, by as-
signing new and unique values to each copy on the attribute
set Y , we ensure that M ASs are well preserved (i.e., both
M ASs X and Y do not change to be X ∪ Y ). The complex-
ity of dealing with type-1 conﬂicts is O(n′q), where n′ is the
number of the tuples that have conﬂicts due to scaling, and
q is the number of M ASs.

3.3.2 Overlapping M ASs

When M ASs overlap, both types of conﬂicts are possible.
The type-1 conﬂicts can be handled in the same way as
for non-overlapping M ASs (Section 3.3.1). In the following
discussion, we mainly focus on how to deal with the type-2
conﬂicts (i.e., the conﬂicts due to shared attributes). We
start our discussion from two overlapping M ASs. Then we
extend to the case of more than two overlapping M ASs.
Two overlapping MASs. We say two ECs Ci ∈ πX and
Cj ∈ πY are conﬂicting if Ci and Cj share at least one tuple.
We have the following theorem to show that conﬂicting ECs
never share more than one tuple.

Theorem 3.2. Given two overlapping M ASs X and Y ,

for any pair of ECs Ci ∈ πX and Cj ∈ πY , |Ci ∩ Cj | ≤ 1.

The correctness of Theorem 3.2 is straightforward: if |Ci ∩
Cj | > 1, there must exist at least one equivalence class of
the partition πX∪Y whose size is greater than 1. Then X ∪Y
should be a M AS instead of X and Y . Theorem 3.2 ensures
the eﬃciency of the conﬂict resolution, as it does not need
to handle a large number of tuples.

A naive method to ﬁx type-2 conﬂicts is to assign the
same ciphertext value to the shared attributes of the two
conﬂicting ECs. As an example, consider the table D in
Figure 3 (a) that consists of two M ASs: X = {A, B} and
Y = {B, C}. Figure 3 (b) and Figure 3 (c) show the encryp-
tion EncX (D) over X and EncY (D) over Y independently.
The conﬂict appears at tuples r1, r3, r4, and r5 on attribute
B (shown in Figure 3 (d)). Following the naive solution,
only one value is picked for tuples r1, r3, r4, and r5 on at-
tribute B. Figure 3 (e) shows a conﬂict resolution scheme
ˆD1 by the naive method. This scheme is incorrect as the
FD F : C → B in D does not hold in ˆD1 anymore.

We design a robust method to resolve the type-2 conﬂicts
for two overlapping M ASs. Given two overlapping M ASs
X and Y , let Z = X ∩Y , for any tuple r, let rX[Z] and rY [Z]
(rX [Z] 6= rY [Z]) be the value constructed by encryption over
X and Y independently. We use X − Z (Y − Z, resp.) to
denote the attributes that appear in X (Y , resp.) but not
Z. Then we construct two tuples r1 and r2:

• r1: r1[X − Z] = r[X − Z], r1[Y − Z] = vX , and r1[Z] =

rX [Z];

• r2: r2[X − Z] = vY , r2[Y − Z] = r[Y − Z], and r2[Z] =

rY [Z].

where vX and vY are two values that do not exist in D. Note
that both X − Z and Y − Z can be sets of attributes, thus
vX and vY can be set of values. Tuples r1 and r2 replace
tuple r in ˆD. As an example, consider the table in Figure 3
(a), the conﬂict resolution scheme by following our method
is shown in Figure 3 (f). For example, r1 and r7 in Figure 3
(f) are the two records constructed for the conﬂict resolution
of r1 in Figure 3 (d).

Our conﬂict resolution method guarantees that the cipher-
text values of each ECG of X and Y are of homogenized
frequency. However, it requires to add additional records.
Next, we show that the number of records added by resolu-
tion of both types of conﬂicts is bounded.

Theorem 3.3. Given a dataset D, let ˆD1 be the dataset
after applying grouping and splitting & scaling on D, and ˆD2
be the dataset after conﬂict resolution on ˆD1, then | ˆD2| −
| ˆD1| ≤ hn, where h is the number of overlapping M AS pairs,
and n is the size of D.
Due to the space limit, we only give the proof sketch here.
Note that the resolution of type-1 conﬂicts does not add
any fake record. Thus we only prove the bound of the new
records for resolution of type-2 conﬂicts. This type of con-
ﬂicts is resolved by replacing any conﬂicting tuple with two
tuples for each pair of conﬂicting ECs. Since two over-
lapping M ASs have n conﬂicting equivalence class pairs at
most, there will be at most hn new records inserted for this
type of resolution for h overlapping M AS pairs. We must
note that hn is a loose bound. In practice, the conﬂicting
ECs share a small number of tuples. The number of such
tuples is much smaller than n. We also note that when h =
0 (i.e., there is no overlapping M AS), no new record will be
inserted.
More than Two Overlapping MASs. When there are
more than two overlapping M ASs, one way is to execute the
encryption scheme that deals with two overlapping M ASs
repeatedly for every two overlapping M ASs. This raises the

6

ECG1

ECG2

EC A
C1
a1
a2
C2
a1
C3
C4
a2

B
b1
b3
b2
b4

Freq
5
2
4
3

A
ˆa1
1
ˆa2
1
ˆa1
2
ˆa3
1
ˆa2
2

B
ˆb1
1
ˆb2
1
ˆb1
3
ˆb1
2
ˆb1
4

Freq
3
3
3
4
4

ECG1

ECG2

A
ˆa3
ˆa3
ˆa4
ˆa4
ˆa5
ˆa5

B
ˆb5
ˆb6
ˆb7
ˆb8
ˆb9
ˆb10

Freq
1
1
1
1
1
1

(a) Base table D

(A → B does not hold)

(b) ˆD: encryption by Step 1 - 3
(A → B becomes false positive)

(c) Constructed ∆D to remove

false positive F D A → B

Figure 4: An example of eliminating false positive F Ds

question in which order the M ASs should be processed. We
have the following theorem to show that indeed the conﬂict
resolution is insensitive to the order of M ASs.

Theorem 3.4. Given a dataset D that contains a set of
overlapping M ASs M , let ˆD1 and ˆD2 be the datasets after
executing conﬂict resolution in two diﬀerent orders of M ,
then | ˆD1| = | ˆD2|.

Proof. It is easy to show that no new record is inserted
by resolution of type-1 conﬂicts. To ﬁx type-2 conﬂicts, for
each pair of overlapping M ASs, every conﬂicting tuple is
replaced by two tuples. The number of conﬂicting tuples
is equal to the number of conﬂicting equivalence class pairs
of the two overlapping M ASs. Assume there are q such
overlapping M AS pairs, each having oi pairs of conﬂict-
ing equivalence class pairs. The conﬂict resolution method

q

adds O =

oi records in total. The number of records

Pi=1

is independent from the orders of M ASs in which conﬂict
resolution is executed.

Since the order of M ASs does not aﬀect the encryption,
we pick the overlapping M AS pairs randomly. For each
overlapping M AS pair, we apply the encryption scheme for
two overlapping M ASs. We repeat this procedure until all
M ASs are processed.
3.4 Step 4. Eliminating False Positive FDs

Before we discuss the details of this step, we ﬁrst deﬁne
false positive FDs. Given the dataset D and its encrypted
version ˆD, we say the FD F is a false positive if F does not
hold in D but holds in ˆD. We observe that the encryption
scheme constructed by Step 1 - 3 may lead to false positive
FDs. Next, we show an example of false positive FDs.

Example 3.1. Consider the table D in Figure 4 (a). Ap-
parently the F D F : A → B does not exist in D, as the
two ECs C1 and C3 have collisions. However, in the en-
crypted dataset ˆD that is constructed by Step 1 - 3 (Figure 4
(b)), since no splits of any two ECs have collision anymore,
F : A → B now holds in ˆD.

Indeed, we have the following theorem to show that free
of collision among ECs is the necessary and suﬃcient con-
ditions for the existence of FDs.

Theorem 3.5. For any MAS X, there must exist a FD
on X if and only if for any two ECs Ci and Cj of πX, Ci
and Cj do not have collision.

Following Theorem 3.5, the fact that Step 1 - 3 construct
only collision-free ECs may lead to a large number of false
positive F Ds, which hurts the accuracy of dependency dis-
covering by the server.

7

ABC:{}

ABD:{}

AB:C

AC:B

AD:B

BC:A

BD:A

AB:D

A:C

B:C

C:B

A:B

D:B

C:A

B:A

D:A

B:D

A:D

Figure 5: An example of FD lattice

The key idea to eliminate the false positive F Ds is to re-
store the collision within the ECs. Note that eliminating
the false positive FD F : X → Y naturally leads to the
elimination of all false positive FDs F ′ : X ′ → Y such that
X ′ ⊆ X. Therefore, we only consider eliminating the max-
imum false positive FDs whose LHS is not a subset of LHS
of any other false positive FDs.

A simple approach to eliminate the false positive FDs is
that the data owner informs the server the ECs with col-
lisions. Though correct, this solution may bring security
leakage as it implies which ciphertext values are indeed en-
crypted from the same plaintext. For example, consider Fig-
ure 4 (b). If the server is informed that ECG1 and ECG2
have collisions before encryption, it can infer that the three
distinct ciphertext values in ECG1 must only map to two
plaintext values (given the two distinct ciphertext values in
ECG2). Therefore, we take a diﬀerent approach based on
adding artiﬁcial records to eliminate false-positive FDs.

We use the FD lattice to help restore the ECs with col-
lision and eliminate false positive FDs. The lattice is con-
structed in a top-down fashion. Each M AS corresponds to
a level-1 node in the lattice. We denote it in the format
M : {}, where M is the M AS that the node corresponds to.
The level-2 nodes in the lattice are constructed as following.
For each level-1 node N , it has a set of children nodes (i.e.,
level-2 nodes) of format X : Y , where Y corresponds to a
single attribute of D, and X = M − {Y }, where M is the
M AS that node N corresponds to. Starting from level 2,
for each node X : Y at level ℓ (ℓ ≥ 2), it has a set of children
nodes of format X ′ : Y ′, where Y ′ = Y , and X ′ ⊂ X, with
|X|′ = |X| − 1 (i.e., X ′ is the largest subset of X). Each
node at the bottom of the lattice is of format X : Y , where
both X and Y are 1-attribute sets. An example of the FD
lattice is shown in Figure 5.

Based on the FD lattice, the data owner eliminates the
false positive FDs by the following procedure. Initially all
nodes in the lattice are marked as “un-checked”. Starting
from the second level of lattice, for each node N (in the
format X : Y ), the data owner checks whether there exists
at least two ECs Ci, Cj ∈ πM such that Ci[X] = Cj [X]
but Ci[Y ] 6= Cj[Y ], where M is the MAS that N ’s parent
node corresponds to. If it does, then the data owner does
the following two steps. First, the data owner inserts k =
⌈ 1
α ⌉ artiﬁcial record pairs {P1, . . . , Pk}, where α is the given

i , v1

i , a2

6= v2

i 6= a2

i and v2

i , and v1

i , and r1
i , and r2

i [Y ] = a1
i [Y ] = a2

i and r2
i :
i [X] = xi, r1
i [X] = xi, r2

threshold for α-security. The reason why we insert k such
pairs will be explained in Section 4. Each Pi consists of two
records r1
i [M AS−X−{Y }] = v1
i : r1
• r1
i ;
i [M AS−X−{Y }] = v2
• r2
i : r2
i .
where xi, a1
i are artiﬁcial values that do not
exist in ˆD constructed by the previous steps. We require
that a1
i . We also require that all arti-
ﬁcial records are of frequency one. Second, the data owner
marks the current node and all of its descendants in the lat-
tice as “checked” (i.e., the current node is identiﬁed as a
maximum false positive FD). Otherwise (i.e., the ECs do
not have collisions), the data owner simply marks the cur-
rent node as “checked”. After checking all the nodes at the
level ℓ, the data owner moves to the level ℓ + 1 and ap-
plies the above operation on the “un-checked” lattice nodes.
The data owner repeats the procedure until all nodes in the
lattice are marked as “checked”.

i

i and C ′

i[X] = C ′

j[X] but C ′

j in ∆D, where C ′

Let ∆D be the artiﬁcial records that are constructed by
the above iterative procedure. It is easy to see that for any
FD X → Y that does not hold in D, there always exist two
ECs C ′
i[Y ] 6=
C ′
j [Y ]. This makes the FD X → Y that does not hold in D
fails to hold in ˆD too. To continue our Example 3.1, we show
how to construct ∆D. It is straightforward that the M AS
{A, B} contains the ECs that have collision (e.g. E1 and
E3 in Figure 4 (a)). Assume α = 1/3. Then ∆D (shown in
Figure 4 (c)) consists of three pairs of artiﬁcial tuples, each
pair consisting of two records of the same value on attribute
A but not on B. The false positive FD F : A → B does not
exist in ˆD + ∆D any more.

Next, we show that the number of artiﬁcial records added

by Step 4 is bounded.

Theorem 3.6. Given a dataset D, let M1, . . . , Mq be the
M ASs of D. Let ˆD1 and ˆD2 be the dataset before and after
eliminating false positive FDs respectively. Then

2k ≤ | ˆD2|−| ˆD1| ≤ min(2km m − 1

[ m−1

]!, 2k

2

]!),
|Mi| |Mi| − 1

[ |Mi|−1

2

q

Xi=1

where k = ⌈ 1
α ⌉ (α as the given threshold for α-security), m
is the number of attributes of D, q is the number of M ASs,
and |Mi| as the number of attributes in Mi.

Proof. Due to the limited space, we show the proof
sketch here. We consider two extreme cases for the lower
bound and upper bound of the number of artiﬁcial records.
First, for the lower bound case, there is only one M AS whose
ECs have collisions.
It is straightforward that our con-
struction procedure constructs 2k artiﬁcial records, where
k = ⌈ 1
α ⌉. Second, for the upper bound case, it is easy to in-
fer that the maximum number of nodes in the FD lattice that

For each such lattice node, there are 2k artiﬁcial records.
So the total number of artiﬁcial records is no larger than

needs to construct artiﬁcial records is Pq
2kPq

i=1 |Mi|(cid:0) |Mi|−1
](cid:1).
](cid:1). On the other hand, as for each max-

imum false positive FD, its elimination needs 2k artiﬁcial
records to be constructed. Therefore, the total number of
artiﬁcial records added by Step 4 equals 2ku, where u is the
number of maximum false positive FDs. It can be inferred

i=1 |Mi|(cid:0) |Mi|−1

|Mi |−1

|Mi|−1

[

[

2

2

[ m−1

that u ≤ m(cid:0) m−1
records cannot exceed min(2kPq

](cid:1). Therefore, the number of artiﬁcial
](cid:1), 2km(cid:0) m−1

i=1 |Mi|(cid:0) |Mi|−1

[ m−1

|Mi|−1

[

2

2

2

](cid:1)).

8

Note that the number of artiﬁcial records is independent of
the size of the original dataset D. It only relies on the num-
ber of attributes of D and α.

The time complexity of eliminating false positive F Ds for
a single M AS M is O(2|M |t), where |M | is the number of
attributes in M , and t is the number of ECs of M . In our
experiments, we observe t << n, where n is the number
of records in D. For instance, on a benchmark dataset of
n = 15, 000, 000, the average value of t is 11, 828. Also,
the experiment results on all three datasets show that at
most |M | = m
2 . With the existence of q > 1 M ASs, the
i=1 2|Mi|ti), where ti is the number
of equivalence classes in Mi, and |Mi| is the number of at-
tributes of M AS Mi. Considering that ti << n, the total
complexity is comparable to O(nm2).

time complexity is O(Pq

We have the following theorem to show that the FDs in

ˆD and D are the same by our 4-step encryption.

Theorem 3.7. Given the dataset D, let ˆD be the dataset
after applying Step 1 - 4 of F 2 on D, then: (1) any FD of
D also hold on ˆD; and (2) any FD F that does not hold in
D does not hold in ˆD either.

Proof. First, we prove that the grouping, splitting &
scaling and conﬂict resolution steps keep the original FDs.
We prove that for any FD X → A that holds on D, it must
also hold on ˆD. We say that a partition π is a reﬁnement
of another partition π′ if every equivalence class in π is a
subset of some equivalence class (EC) of π′.
It has been
proven that the functional dependency X → A holds if and
only if πX reﬁnes π{A}[16]. For any functional dependency
X → A, we can ﬁnd a M AS M such that (X ∪ {A}) ⊂ M .
Obviously, πM reﬁnes πX , which means for any EC C ∈ πM ,
there is an EC Cp ∈ πX such that C ⊂ Cp. Similarly, πM
reﬁnes π{A}. So for any equivalence class C ∈ πM , we can
ﬁnd Cp ∈ πX and Cq ∈ π{A} such that C ⊂ Cp ⊂ Cq. First,
we prove that our grouping over M keeps the FD: X →
A. It is straightforward that grouping ECs together does
not aﬀect the FD. The interesting part is that we add fake
ECs to increase the size of a ECG. Assume we add a fake
equivalence class Cf into πM . Because Cf is non-collisional,
πX = πX ∪ {Cf } and π{A} = π{A} ∪ {Cf }. Therefore, πX
still reﬁnes π{A}. The FD is preserved. Second, we show
that our splitting scheme does not break the FD: X → A.
Assume that we split the equivalence class C ∈ πM into
̟ unique equivalence classes C 1, . . . , C ̟. After the split,
Cp = Cp − C, Cq = Cq − C. This is because the split
copies have unique ciphertext values. As a result, πX =
πX ∪ {C 1, . . . , C ̟} and π{A} = π{A} ∪ {C 1, . . . , C ̟}.
It
is easy to see that πX is still a reﬁnement of π{A}. The
scaling step after splitting still preserves the FD, as it only
increases the size of the equivalence class C ∈ πM by adding
additional copies. The same change applies to both Cp and
Cq. So Cp is still a subset of Cq. As a result, the FD: X → A
is preserved after splitting and scaling. Lastly, we prove that
our conﬂict resolution step keeps the F Ds. First, the way of
handling non-overlapping M ASs is FD-preserving because
we increase the size of an equivalence class in a partition
while keeping the stripped partitions of the other M ASs.
Second, the conﬂict resolution for overlapping M ASs is also
FD-preserving. Assume C ∈ πM and C ′ ∈ πN conﬂict over
a tuple r. According to our scheme, we use r1 and r2 to
replace r with r1[M ] = rM [M ], r2[N ] = rN [N ], r1[N − M ]
and r2[M − N ] having new values. The eﬀect is to replace

r ∈ C with r1. This change does not aﬀect the fact that
Cp ⊂ Cq. Therefore the F Ds are still preserved. Here we
prove that by inserting artiﬁcial records, all original FDs are
still kept while all the false positive FDs are removed.

Next, we prove that insertion of artiﬁcial records preserves
all original FDs. The condition to insert fake records is
that there exists equivalence classes Ci and Cj such that
Ci[X] = Cj [X] but Ci[Y ] 6= Cj[Y ] on the attribute sets X
and Y . For any FD that holds on D, this condition is never
met. Hence the real FDs in D will be kept.

Last, we prove that any FD F : X → Y that does not hold
in D is also not valid in ˆD. First we show that if there does
not exist a M AS M such that X ∪ {Y } 6⊂ M , X → Y can
not hold in ˆD. Since our splitting & scaling procedure en-
sures that diﬀerent plaintext values have diﬀerent ciphertext
values, and each value in any equivalence class of a M AS is
encrypted to a unique ciphertext value, the set of M ASs in
D must be the same as the set of M ASs in ˆD. As a conse-
quence, in ˆD, there do not exist any two records ri, rj such
that ri[X] = rj[X] and ri[Y ] = rj[Y ]. Therefore, X → Y
cannot be a FD in ˆD. Second, we prove that for any M AS
M such that X ∪ {Y } ⊂ M , if F does not hold on D, then
F must not hold on ˆD.

4. SECURITY ANALYSIS

In this section, we analyze the security guarantee of F 2
against the frequency analysis attack, for both cases of with-
out and under Kerckhoﬀs’s principle. We assume that the
attacker can be the compromised server.
4.1 Without Kerckhoffs’s Principle

For any e ∈ E be a ciphertext value, let G(e) = {p|p ∈
P, f reqP (p) = f reqE (e)} be the set of distinct plaintext
values having the same frequency as e.
It has shown [26]
that for any adversary Af req and any ciphertext value e, the
chance that the adversary succeeds the frequency analysis
attack is P r[Expf req
|G(e)| , where |G(e)| is the size
of G(e).
In other words, the size of G(e) determines the
success probability of Expf req
A,Π .

A,Π = 1] = 1

Apparently, the scaling step of F 2 ensures that all the
equivalence classes in the same ECG have the same fre-
quency. Hence, for any encrypted equivalence class EC ′,
there are at least |ECG| plaintext ECs having the same fre-
quency. Recall that the way we form the equivalence class
groups does not allow any two equivalence classes in the
same ECG to have the same value on any attribute. There-
fore, for any attribute A, a ECG contains k distinct plain-
text values on A, where k is the size of ECG. Thus for
any e ∈ E , it is guaranteed that |G(e)| = k. As k ≥ [ 1
α ],
it is guaranteed that G(e) ≥ [ 1
In this way, we have
P r[Expf req
A,Π = 1] ≤ α. Thus F 2 is α-secure against the
frequency analysis attack.
4.2 Under Kerckhoffs’s principle

α ].

We assume the attacker knows the details of the F 2 algo-
rithm besides the frequency knowledge. We discuss how the
attacker can utilize such knowledge to break the encryption.
We assume that the attacker does not know the α and ̟
values that data owner uses in F 2. Then the attacker can
launch the following 4-step procedure.
Step 1: Estimate the split factor ̟. The attacker
ﬁnds the maximum frequency f P
m of plaintext values and

m
f P
m

m of ciphertext values. Then it

. It is highly likely that ̟′ = ̟.

the maximum frequency f E
calculates ̟′ = f E
Step 2: Find ECGs. The attacker applies Step 2.1 of
F 2 bucketizes E by grouping ciphertext values of the same
frequency into the same bucket. Each bucket corresponds
to one ECG.
Step 3: Find mappings between ECGs and plain-
text values. The attacker is aware of the fact that for a
given ciphertext value e, its frequency f ˆD(e) must satisfy
that f ˆD(e) ≥ ̟fD(p), where p is the corresponding plain-
text value of e. Following this reasoning, for any ECG (in
which all ciphertext values are of the same frequency f ),
the attacker ﬁnds all plaintext values P ′ such that ∀P ∈ P ′,
̟fD(p) ≤ f .
Step 4: Find mappings between plaintext and ci-
phertext values. For any ECG, the attacker maps any
ciphertext value in ECG to a plaintext value in the candi-
date set returned by Step 3. Note the attacker can run F 2
to ﬁnd the optimal split point of the given ECG.

Next, we analyze the probability that the attacker can
map a ciphertext value e to a plaintext value p by the 4-
step procedure above. It is possible that the attacker can
ﬁnd the correct mappings between ECGs and their plaintext
values with 100% certainty by Step 1 - 3. Therefore, we
mainly analyze the probability of Step 4. Given an ECG
that matches to k plaintext values, let y be the number of
its unique ciphertext values. Then the number of possible
mapping of y ciphertext values (of the same frequency) to

k plaintext values is (cid:0)y
are (cid:0)y−1

k(cid:1)ky−k. Out of these mappings, there
k−1(cid:1)ky−k−1 mappings that correspond to the mapping

e → p. Therefore,

P rob(e → p) = (cid:0)y−1
k−1(cid:1)ky−k−1
(cid:0)y
k(cid:1)ky−k

=

1
y

.

Assume in the given ECG, k′ ≤ k plaintext values are split
by F 2. The total number of ciphertext values of the given
ECG is y = ̟k′ + k − k′. It is easy to compute that y ≥
k. As we always guarantee that k ≥ 1
α , P rob(e → p) =
k ≤ α. Therefore, F 2 guarantees α-security against the
1
y ≤ 1
frequency analysis attack under Kerckhoﬀs’s principle.
5. EXPERIMENTS

In this section, we discuss our experiment results and pro-

vide the analysis of our observations.
5.1 Setup
Computer environment. We implement our algorithm
in Java. All the experiments are executed on a PC with
2.5GHz i7 CPU and 60GB memory running Linux.
Datasets. We execute our algorithm on two TPC-H bench-
mark datasets, namely the Orders and Customer datasets,
and one synthetic dataset. More details of these three datasets
can be found in Table 1. Orders dataset contains nine maxi-
mal attribute sets M ASs. All M ASs overlap pairwise. Each
M AS contains either four or ﬁve attributes. There are ﬁf-
teen M ASs in Customer dataset. The size of these M ASs
(i.e., the number of attributes) ranges from nine to twelve.
All M ASs overlap pairwise. The synthetic dataset has two
M ASs, one of three attributes, while the other of six at-
tributes. The two M ASs overlap at one attribute.
Evaluation. We evaluate the eﬃciency and practicality of
our encryption scheme according to the following criteria:

9

Dataset # of attributes # of tuples

size

Orders

Customer
Synthetic

9
21
7

(Million)

15
0.96

4

1.64GB
282MB
224MB

Table 1: Dataset description

• Encryption time: the time for the data owner to encrypt

the dataset (Sec. 5.2);

• Space overhead: the amounts of artiﬁcial records added

by F 2 (Sec. 5.3);

• Outsourcing versus local computations: (1) the time of
discovering FDs versus encryption by F 2, and (2) the FD
discovery time on the original data versus that on the
encrypted data (Sec. 5.4).

Baseline approaches. We implement two baseline encryp-
tion methods (AES and Paillier) to encode the data at cell
level. The AES baseline approach uses the well-known AES
algorithm for the deterministic encryption. We use the im-
plementation of AES in the javax.crypto package. The Pail-
lier baseline approach is to use the asymmetric Paillier en-
cryption for the probabilistic encryption. We use the UTD
Paillier Threshold Encryption Toolbox1. Our probabilistic
approach is implemented by combining a random string (as
discussed in Section 3.2) and the AES algorithm. We will
compare the time performance of both AES and Paillier
with F 2.
5.2 Encryption Time

In this section, we measure the time performance of F 2
to encrypt the dataset. First, we evaluate the impact of
security threshold α on the running time. We measure the
time of our four steps of the algorithm: (1) ﬁnding maxi-
mal attribute sets (MAX), (2) splitting-and-scaling encryp-
tion (SSE), (3) conﬂict resolution (SYN), and (4) eliminat-
ing false positive FDs (FP), individually. We show our re-
sults on both Orders and the synthetic datasets in Figure
6. First, we observe that for both datasets, the time perfor-
mance does not change much with the decrease of α value.
This is because the running time of the MAX, SYN and
FP steps is independent on α.
In particular, the time of
ﬁnding M ASs stays stable with the change of α values, as
its complexity relies on the data size, not α. Similarly, the
time performance of FP step is stable with various α val-
ues, as its complexity is only dependent on the data size
and data schema. The time performance of SYN step does
not vary with α value because we only need to synchronize
the encryption on the original records, without the worry
about the injected records. It is worth noting that on the
Orders dataset, the time took by the SYN step is negligi-
ble. This is because the SYN step leads to only 24 artiﬁcial
records on the Orders dataset (of size 0.325GB). Second, the
time of SSE step grows for both datasets when α decreases
(i.e., tighter security guarantee). This is because smaller α
value requires larger number of artiﬁcial equivalence classes
to form ECGs of the desired size. This addresses the trade-
oﬀ between security and time performance. We also observe
that the increase in time performance is insigniﬁcant. For
example, even for Orders dataset of size 0.325GB, when α
is decreased from 0.2 to 0.04, the execution time of the SSE
1http://cs.utdallas.edu/dspl/cgi-bin/pailliertoolbox/.

10

step only increases by 2.5 seconds. This shows that F 2 en-
ables to achieve higher security with small additional time
cost on large datasets. We also observe that diﬀerent steps
dominate the time performance on diﬀerent datasets: the
SSE step takes most of the time on the synthetic dataset,
while the MAX and FP steps take the most time on the Or-
ders dataset. This is because the average number of ECs of
all the M ASs in the synthetic dataset is much larger than
that of the Orders dataset (128,512 v.s. 1003). Due to the
quadratic complexity of the SSE step with regard to the
number of ECs, the SSE step consumes most of the time on
the synthetic dataset.

SSE
SYN
MAX
FP

)
e

t

u
n
M

i

(
 

e
m
T

i

 12

 10

 8

 6

 4

 2

 0

1/5

1/1

0

1/1

5

SSE
SYN
MAX
FP

)
e

t

u
n
M

i

(
 

e
m
T

i

 10

 8

 6

 4

 2

 0

1/3

0

1/3

5

1/4

0

1/5

1/1

0

5

1/1
α value

1/2

0

1/2

5

1/2

5

0

1/2
α value

(a) Synthetic dataset (53MB)

(b) Orders dataset (0.325GB)

Figure 6: Time performance for various α

Second, to analyze the scalability of our approach, we
measure the time performance for various data sizes. The
results are shown in Figure 7. It is not surprising that the
time performance of all the four steps increases with the
data size. We also notice that, on both datasets, the time
performance of the SSE step is not linear to the data size.
This is due to the fact that the time complexity of the SSE
step is quadratic to the number of ECs. With the increase of
the data size, the average number of ECs increases linearly
on the synthetic dataset and super-linearly on the Orders
dataset. Thus we observe the non-linear relationship be-
tween time performance of SSE step and data size. On the
synthetic dataset, the dominant time factor is always the
time of the SSE step. This is because of the large aver-
age number of ECs (can be as large as 1 million) and the
quadratic complexity of the SSE step. In contrast, the aver-
age number of ECs is at most 11, 828 on the Orders dataset.
So even though the synthetic dataset has fewer and smaller
M ASs than the Orders dataset, the vast diﬀerence in the
number of ECs makes the SSE step takes the majority of
the time performance on the synthetic dataset.

To sum up the observations above, our F 2 approach can
be applied on the large datasets with high security guaran-
tee, especially for the datasets that have few number of ECs
on the M ASs. For instance, it takes around 30 minutes for
F 2 to encrypt the Orders dataset of size 1GB with security
guarantee of α = 0.2.

SSE
SYN
MAX
FP

)
e
t
u
n
M

i

(
 
e
m
T

i

 120

 100

 80

 60

 40

 20

 0

25

53

110
Data Size (MB)

224

)
e
t
u
n
M

i

(
 
e
m
T

i

 80
 70
 60
 50
 40
 30
 20
 10
 0

SSE
SYN
MAX
FP

0.325 0.653 0.981 1.309 1.637

Data Size (GB)

(a) Synthetic dataset (α=0.25)

(b) Orders dataset (α=0.2)

Figure 7: Time performance for various data sizes
We also compare the time performance of F 2 with the two
baseline methods. The result is shown in Figure 8. It is not
surprising that F 2 is slower than AES, as it has to handle

F2
AES
Paillier

 1000

 100

 10

)
e

t

u
n
M

i

(
 

e
m
T

i

 1

25

F2
AES
Paillier

 1000

 100

 10

)
e

t

u
n
M

i

(
 

e
m
T

i

53
Data Size (MB)

110

224

 1
0.325

0.653

0.981

1.309

1.637

Data Size (GB)

(a) Synthetic dataset (α=0.25)

(b) Orders dataset (α=0.2)

Figure 8: Time performance Comparison

with the FD-preserving requirement. On the other hand,
even though F 2 has to take additional eﬀorts to be FD-
preserving (e.g., ﬁnding M ASs, splitting and scaling, etc.),
its time performance is much better than Paillier. This
shows the eﬃciency of our probabilistic encryption scheme.
It is worth noting that on the Orders dataset, Paillier takes
1247.27 minutes for the data of size 0.325GB, and cannot
ﬁnish within one day when the data size reaches 0.653GB.
Thus we only show the time performance of Paillier for the
data size that is below 0.653GB.

d
a
e
h
r
e
v
O

d
a
e
h
r
e
v
O

SYN
SCALE
GROUP
FP

 0.05
 0.045
 0.04
 0.035
 0.03
 0.025
 0.02
 0.015
 0.01
 0.005
 0

1 1/2

1/3

1/4

1/7

1/8

1/9

1/1

0

1/5
1/6
α value

(a) Various α values
(Customer 73MB)

 0.12

 0.1

 0.08

 0.06

 0.04

 0.02

 0

SYN
SCALE
GROUP
FP

17

35

73

149

291

585

Data Size (MB)

d
a
e
h
r
e
v
O

d
a
e
h
r
e
v
O

SYN
SCALE
GROUP
FP

 0.05
 0.045
 0.04
 0.035
 0.03
 0.025
 0.02
 0.015
 0.01
 0.005
 0

1 1/2

1/3

1/4

1/7

1/8

1/9

1/1

0

1/5
1/6
α value

(b) Various α values

(Orders 0.325GB)

 0.07

 0.06

 0.05

 0.04

 0.03

 0.02

 0.01

 0

SYN
SCALE
GROUP
FP

0.325 0.653 0.981 1.309 1.637

Data Size (GB)

(c) Various data size
(Customer α = 0.2)

(d) Various data size

(Orders α=0.2)

Figure 9: Amounts of Artiﬁcial Records Added by F 2
5.3 Amounts of Artiﬁcial Records

In this section, we measure the amounts of the artiﬁ-
cial records added by F 2 on both the Orders and Customer
datasets. We measure the amounts of the artiﬁcial records
added by Step 2.1 grouping (GROUP), Step 2.2 splitting-
and-scaling encryption (SCALE), Step 3 conﬂict resolution
(SYN), and Step 4 eliminating false positive FDs (FP) in-
dividually. For each step, we measure the data size before
and after the step, let them be s and s′, and calculate the
space overhead r = s′−s

.

On the Customer dataset, we measure the overhead un-
der various α values in Figure 9 (a). We observe that the
GROUP and FP steps introduce most of the overhead. The
overhead increases when α decreases, since smaller α value
requires larger ECGs, and thus more collision-free equiva-
lence classes. But in general, the overhead is very small,
always within in 5%. This is because the domain size of the
attributes in M ASs of the Customer dataset is large. For in-
stance, both the C Last and C Balance attribute have more
than 4,000 unique values across 120,000 records. Under such
setting, diﬀerent M ASs are unlikely collide with each other.

s

As a consequence, the number of artiﬁcial records added by
the GROUP step is very small. When α < 0.2, the GROUP
step does not even introduce any overhead. The overhead
brought by the FP step increases with the decrease of α
value. This is because for each maximum false positive FD,
F 2 inserts 2k artiﬁcial records, where k = ⌈ 1
α ⌉. As k in-
creases, the number of inserted records decreases. But even
for small α value such as 1
10 , the overhead brought by the
FP step is still very small (around 1.5%). In any case, the
space overhead of F 2 on the Customers dataset never ex-
ceeds 5%. We also measure the space overhead with var-
ious α values on the Orders dataset. The result is shown
in Figure 9 (b). First, the GROUP step adds dominant
amounts of new records. The reason is that the domain size
of attributes in M ASs on the Orders dataset is very small.
For example, among the 1.5 million records, the OrderSta-
tus and OrderPriority attributes only have 3 and 5 unique
values respectively. Therefore the ECs of these attributes
have signiﬁcant amounts of collision. This requires F 2 to
insert quite a few artiﬁcial records to construct the ECGs
in which ECs are collision-free. Nevertheless, the amounts
of artiﬁcial records is negligible compared with the number
of original records. The space overhead is 4.5% at most.

In Figure 9 (c) and (d), we show the space overhead of
both datasets of various sizes. On the Customer dataset, the
overhead reduces with the increase of data size. Such over-
head decreases for both GROUP and FP steps. Next we give
the reasons. Regarding the GROUP step, this is because in
the Customer dataset, the collision between ECs is small. It
is more likely that the GROUP step can ﬁnd collision-free
ECs to form the ECGs, and thus smaller number of the
injected artiﬁcial records. Regarding the FP step, its space
overhead decreases when the data size grows is due to the
fact that the number of artiﬁcial records inserted by the FP
step is independent of the data size. This makes the num-
ber of artiﬁcial records constant when the data size grows.
Therefore, the overhead ratio decreases for larger datasets.
On the Orders dataset, again, the GROUP step contributes
most of the injected artiﬁcial records. However, contrary
to the Orders dataset, the overhead increases with the data
size. This is because the ECs of Orders have signiﬁcant
amounts of collision. Thus, the number of ECs increases
quadratically with the dataset size. Therefore, the space
overhead of the GROUP step increases for larger datasets.
Combining the observations above, our F 2 method in-
troduces insigniﬁcant amounts of artiﬁcial records. For in-
stance, the amounts of artiﬁcial records takes at most 6%
for the Orders dataset, and 12% for the Customer dataset.

5.4 Outsourcing VS. Local Computations

First, we compare the data owner’s performance of ﬁnd-
ing F Ds locally and encryption for outsourcing. We im-
plemented the TANE algorithm [16] and applied it on our
datasets. First, we compare the time performance of ﬁnd-
ing F Ds locally (i.e. applying TANE on the original dataset
D) and outsourcing preparation (i.e., encrypting D by F 2).
It turns out that ﬁnding F Ds locally is signiﬁcantly slower
than applying F 2 on the synthetic dataset. For example,
TANE takes 1,736 seconds on the synthetic dataset whose
size is 25MB to discover FDs, while F 2 only takes 2 seconds.
Second, we compare the performance of discovering F Ds
from the original and encrypted data, for both Customer and
Orders datasets. We deﬁne the dependency discovery time

11

d
a
e
h
r
e
v
O
e
m
T

 

i

 0.4
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0

1/2

1/4

1/6

α value

1/8

1/10

d
a
e
h
r
e
v
O
e
m
T

 

i

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

1/2

1/4

1/6

α value

1/8

1/10

(a) Customer dataset (73MB)

(b) Orders dataset (0.325GB)

Figure 10: Dependency Discovery Time Overhead

T

overhead o = T ′−T
, where T and T ′ are the time of discov-
ering F Ds from D and ˆD respectively. The result is shown
in Figure 10. For both datasets, the time overhead is small.
It is at most 0.4 for the Customers dataset and 0.35 for the
Orders dataset. Furthermore, the discovery time overhead
increases with the decrease of α value. This is because with
smaller α, the GROUP and FP steps insert more artiﬁcial
records to form ECGs for higher security guarantee. Con-
sequently the FD discovery time increases. This is the price
to pay for higher security guarantee.

6. RELATED WORK

Data security is taken as a primary challenge introduced
by the database-as-a-service (DaS) paradigm. To protect
the sensitive data from the DaS service provider, the client
may transform her data so that the server cannot read the
actual content of the data outsourced to it. A straight-
forward solution to data transformation is to encrypt the
data while keeping the decryption key at the client side.
Hacigumus et al.
[14] is one of the pioneering work that
explores the data encryption for the DaS paradigm. They
propose an infrastructure to guarantee the security of stored
data. Diﬀerent granularity of data to be encrypted, such
as row level, ﬁeld level and page level, is compared. Chen
et al.
[13] develop a framework for query execution over
encrypted data in the DaS paradigm. In this framework,
the domain of values of each attribute is partitioned into
some bucket. The bucket ID which refers to the partition to
which the plain value belongs serves as an index of cipher-
text values. Both encryption methods are vulnerable against
the frequency analysis attack as they only consider one-to-
one substitution encryption scheme. Curino et al.
[7] pro-
pose a DaS system that provides security protection. Many
cryptographic techniques like randomized encryption, order-
preserving encryption and homomorphic encryption are ap-
plied to provide adjustable security. CryptDB [25] supports
processing queries on encrypted data. It employs multiple
encryption functions and encrypts each data item under var-
ious sequences of encryption functions in an onion approach.
Alternatively, Cipherbase [1] exploits the trusted hardware
(secure co-processors) to process queries on encrypted data.
These cryptographic techniques are not FD-preserving.

Data encryption for outsourcing also arises the challenge
of how to perform computations over the encrypted data.
A number of privacy-preserving cryptographic protocols are
developed for speciﬁc applications. For example, searchable
encryption [29, 5] allows to conduct keyword searches on the
encrypted data, without revealing any additional informa-
tion. However, searchable encryption does not preserve FDs.
Homomorphic encryption [28] enables the service provider to
perform meaningful computations on the data, even though

12

it is encrypted.
theory, but it is not yet eﬃcient enough for practice [22].

It provides general privacy protection in

Integrity constraints such as FDs are widely used for data
cleaning. There have been very few eﬀorts on ﬁnding data
integrity constraints and cleaning of inconsistent data in pri-
vate settings. Talukder et al. [30] consider a scenario where
one party owns the private data quality rules (e.g., F Ds)
and the other party owns the private data. These two par-
ties wish to cooperate by checking the quality of the data in
one party’s database with the rules discovered in the other
party’s database. They require that both the data and the
quality rules need to remain private. They propose a cryp-
tographic approach for FD-based inconsistency detection in
private databases without the use of a third party. The
quadratic algorithms in the protocol may incur high cost
on large datasets [30]. Barone et al.
[2] design a privacy-
preserving data quality assessment that embeds data and
domain look-up table values with Borugain Embedding. The
protocol requires a third party to verify the (encrypted) data
against the (encrypted) look-up table values for data incon-
sistency detection. Both work assume that the data quality
rules such as F Ds are pre-deﬁned. None of these work can
be directly applied to our setting due to diﬀerent problem
deﬁnition and possibly high computational cost.

Eﬃcient discovery of FDs in relations is a well-known chal-
lenge in database research. Several approaches (e.g., TANE
[16], FD MINE [31], and FUN [23]) have been proposed.
[24] classiﬁes and compares seven FD discovery algorithms
in the literature.
[19] presents an excellent survey of FD
discovery algorithms.
7. CONCLUSION AND DISCUSSION

In this paper, we presented F 2 algorithm that is FD-
preserving and frequency-hiding. It can provide provable se-
curity guarantee against the frequency analysis attack, even
under the Kerckhoﬀs’s principle. Our experiment results
demonstrate the eﬃciency of our approach.

We acknowledge that F 2 does not support eﬃcient data
updates, since it has to apply splitting and scaling (Step
2.2) from scratch if there is any data update. For the future
work, we will consider how to address this important issue.
Another interesting direction is to extend to malicious at-
tackers that may not follow the outsourcing protocol and
thus cheats on the data dependency discovery results. The
problem of verifying whether the returned FDs are correct is
challenging, given the fact that the data owner is not aware
of any F D in the original dataset.

8. ACKNOWLEDGEMENT

This material is based upon work supported by the Na-
tional Science Foundation under Grant SaTC-1350324 and
SaTC-1464800. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of the
author(s) and do not necessarily reﬂect the views of the Na-
tional Science Foundation.

9. REFERENCES
[1] A. Arasu, S. Blanas, K. Eguro, R. Kaushik,

D. Kossmann, R. Ramamurthy, and R. Venkatesan.
Orthogonal security with cipherbase. In CIDR, 2013.

[2] D. Barone, A. Maurino, F. Stella, and C. Batini. A

privacy-preserving framework for accuracy and

completeness quality assessment. Emerging Paradigms
in Informatics, Systems and Communication, 2009.

[3] C. Batini, M. Lenzerini, and S. B. Navathe. A

comparative analysis of methodologies for database
schema integration. ACM computing surveys (CSUR),
18(4):323–364, 1986.

[4] P. Bohannon, W. Fan, F. Geerts, X. Jia, and

A. Kementsietsidis. Conditional functional
dependencies for data cleaning. In International
Conference on Data Engineering, 2007.

[5] D. Boneh, G. Di Crescenzo, R. Ostrovsky, and

G. Persiano. Public key encryption with keyword
search. In Advances in Cryptology, 2004.

[6] L. Chiticariu, M. A. Hern´andez, P. G. Kolaitis, and

L. Popa. Semi-automatic schema integration in clio. In
Proceedings of the VLDB Endowment, pages
1326–1329, 2007.

Computer and Communications Security, 2015.

[19] J. Liu, J. Li, C. Liu, and Y. Chen. Discover

dependencies from data a review. IEEE Transactions
on Knowledge & Data Engineering, (2):251–264, 2010.
[20] B. Marnette, G. Mecca, and P. Papotti. Scalable data
exchange with functional dependencies. Proceedings of
the VLDB Endowment, 3(1-2):105–116, 2010.

[21] R. J. Miller, Y. E. Ioannidis, and R. Ramakrishnan.

The use of information capacity in schema integration
and translation. In VLDB, 1993.

[22] M. Naehrig, K. Lauter, and V. Vaikuntanathan. Can
homomorphic encryption be practical? In Proceedings
of the 3rd ACM Cloud Computing Security Workshop,
pages 113–124, 2011.

[23] N. Novelli and R. Cicchetti. Fun: An eﬃcient

algorithm for mining functional and embedded
dependencies. In Database Theory (ICDT). 2001.

[7] C. Curino, E. Jones, R. A. Popa, N. Malviya, E. Wu,

[24] T. Papenbrock, J. Ehrlich, J. Marten, T. Neubert,

S. Madden, H. Balakrishnan, and N. Zeldovich.
Relational cloud: A database service for the cloud. In
5th Biennial Conference on Innovative Data Systems
Research, 2011.

J.-P. Rudolph, M. Sch¨onberg, J. Zwiener, and
F. Naumann. Functional dependency discovery: An
experimental evaluation of seven algorithms.
Proceedings of the VLDB Endowment, 8(10), 2015.

[8] G. I. Davida, D. L. Wells, and J. B. Kam. A database

[25] R. A. Popa, C. Redﬁeld, N. Zeldovich, and

H. Balakrishnan. Cryptdb: Processing queries on an
encrypted database. Communications of the ACM,
55(9):103–111, 2012.

[26] T. Sanamrad, L. Braun, D. Kossmann, and

R. Venkatesan. Randomly partitioned encryption for
cloud databases. In Data and Applications Security
and Privacy XXVIII, pages 307–323. 2014.

[27] C. E. Shannon. Communication theory of secrecy

systems*. Bell System Technical Journal, 1949.

[28] N. P. Smart and F. Vercauteren. Fully homomorphic

encryption with relatively small key and ciphertext
sizes. In Public Key Cryptography (PKC). 2010.
[29] D. X. Song, D. Wagner, and A. Perrig. Practical

techniques for searches on encrypted data. In
Proceedings of IEEE Symposium on Security and
Privacy, pages 44–55, 2000.

[30] N. Talukder, M. Ouzzani, A. K. Elmagarmid, and

M. Yakout. Detecting inconsistencies in private data
with secure function evaluation. Technical report,
Purdue University, 2011.

[31] H. Yao, H. J. Hamilton, and C. J. Butz. Fd mine:
discovering functional dependencies in a database
using equivalences. In IEEE International Conference
on Data Mining, pages 729–732, 2002.

encryption system with subkeys. ACM Transactions
on Database Systems (TODS), 6(2):312–328, 1981.

[9] B. Dong, R. Liu, and W. H. Wang. Prada:

Privacy-preserving data-deduplication-as-a-service. In
Proceedings of the International Conference on
Information and Knowledge Management, pages
1559–1568, 2014.

[10] W. Fan, F. Geerts, J. Li, and M. Xiong. Discovering

conditional functional dependencies. IEEE
Transaction of Knowledge and Data Engineering,
23(5):683–698, 2011.

[11] S. Goldwasser and S. Micali. Probabilistic encryption.

Journal of Computer and System Sciences, 1984.

[12] D. Gunopulos, R. Khardon, H. Mannila, S. Saluja,

H. Toivonen, and R. S. Sharma. Discovering all most
speciﬁc sentences. ACM Transactions on Database
Systems (TODS), 28(2):140–174, 2003.

[13] H. Hacigumus, B. Iyer, C. Li, and S. Mehrotra.

Executing sql over encrypted data in the
database-service-provider model. In Proceedings of the
International Conference on Management of Data,
pages 216–227, 2002.

[14] H. Hacigumus, B. Iyer, and S. Mehrotra. Providing

database as a service. In Proceedings of International
Conference on Data Engineering. IEEE, 2002.

[15] A. Heise, J.-A. Quian´e-Ruiz, Z. Abedjan, A. Jentzsch,
and F. Naumann. Scalable discovery of unique column
combinations. Proceedings of the VLDB Endowment,
7(4):301–312, 2013.

[16] Y. Huhtala, J. K¨arkk¨ainen, P. Porkka, and

H. Toivonen. Tane: An eﬃcient algorithm for
discovering functional and approximate dependencies.
The computer journal, 42(2):100–111, 1999.

[17] J. Katz and Y. Lindell. Introduction to modern

cryptography: principles and protocols. CRC press,
2007.

[18] F. Kerschbaum. Frequency-hiding order-preserving

encryption. In Proceedings of the Conference on

13

