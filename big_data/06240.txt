6
1
0
2

 
r
a

 

M
0
2

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
0
4
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Numerical stability of generalized entropies

Gy¨orgy Steinbrecher

University of Craiova, A. I. Cuza 13, 200585 Craiova, Romania.

Email: gyorgy.steinbrecher@gmail.com

Giorgio Sonnino

Department of Theoretical Physics and Mathematics, Universit´e
Libre de Bruxelles (ULB), Campus Plain CP 231, Boulevard de

Triomphe, 1050 Brussels, Belgium &

Royal Military School (RMS)

Av. de la Renaissance 30, 1000 Brussels - Belgium.

E-mail: gsonnino@ulb.ac.be

March 22, 2016

Abstract

In many applications, the probability density function is subject to
experimental errors. In this work the continuos dependence of a class of
generalized entropies on the experimental errors is studied. This class
includes the C. Shannon, C. Tsallis, A. R´enyi and generalized R´enyi en-
tropies. By using the connection between R´enyi or Tsallis entropies, and
the distance in a family of metric functional spaces, family that includes
the Lebesgue normed vector spaces, we introduce a further extensive gen-
eralizations of the R´enyi entropy. In this work we suppose that the exper-
imental error is measured by some Lp norm. In line with the methodology
normally used for treating the so called ill-posed problems, auxiliary sta-
bilizing conditions are determined, such that small - in the sense of Lp
metric - experimental errors provoke small variations of the classical and
generalized entropies. These stabilizing conditions are formulated in terms
of Lp metric in a class of generalized Lp spaces of functions. Shannon’s
entropy requires, however, more restrictive stabilizing conditions.

1 Introduction

The generalizations of the Boltzmann-Shannon entropy (BSE) [1], the R´enyi
entropy (RE) [2]-[5] and the Tsallis entropy (TE) [6]-[9] were introduced, inde-
pendently, by an axiomatic respectively physical approach. These entropies are
algebraically related to the same norm, or distance functional, in suitable Lp
spaces [10]. There are many applications of this class of generalized entropies

1

[8], [9], [11]-[15]. The problem of mathematical naturalness of the generalized
entropies, in the sense of category theory, is treated in [16]. Since in the generic
cases, the classical and generalized entropies, are functionals deﬁned in inﬁnite-
dimensional Lp spaces, where p is exactly the parameter in the RE and TE (see
[10] and references therein), the ﬁrst problem is related to the correct deﬁni-
tion, the ﬁniteness of the deﬁning functionals. Here, we shall use the general,
Lebesgue Lp space formalism [10], [16].

In applications the probability density function (PDF) is known only ap-
proximately, so the second, practical, problem concerns the numerical stability
of the generalized and the classical entropies when the PDF is known only ap-
proximately. This problem is studied in relation to the convergence in Central
Limit Theorem in [17]. Since the PDF is always integrable, one of the natural
measure of the approximation of PDF is the L1 distance between the exact
and approximate PDFs. This distance is always ﬁnite. In the case of discrete
probability distribution, the numerical stability is studied in [18]. The numer-
ical stability is formulated in terms of l1 distance for the input-data, and of
relative error of the entropy for the output-data. This criterion applies to the
case of BSE and TE, but not for RE. We are then pushed to extend the con-
cepts of ﬁniteness and numerical stability by using the general formalism of
the probability theory in general measure spaces [19]-[21]. Generally, when the
only informations is related to the L1 norm, we have no control on the other
Lp distances, both for RE and TE. Both TE and RE (in the sequel, referred to
as RTE) may be expressed in terms of Lp-distances of the PDFs. However in
general, despite the L1-convergence of the approximate PDF sequence, diﬀerent
Lp-convergences (and topologies) are not equivalent [19]-[21]. It is clear that
in the generic inﬁnite-dimensional case, the continuity of entropies in the case
of approximation of PDFs cannot be deduced without evoking extra stabiliz-
ing conditions. In our work we follow the methods adopted for treating the so
called ill-posed problem (in the sense of J. Hadamard). This method is used
in the ﬁeld of strong interactions in physics not only for establishing numerical
methods [22], [23], but also for formulating the problem in more rigorous terms
[24]-[27]. Likely, this method can be reformulated appropriately to tackle and
solve our problem. In this work we shall ﬁrstly ﬁnd auxiliary stabilizing condi-
tions e.g., by imposing that RTE is ﬁnite for a particular value of the parameter
p. Secondly, we shall prove that, by imposing these stabilizing conditions, for a
large range of the parameter p, the absolute error for the RTE is controlled by
the L1 error in the input-PDFs. The reason to use the absolute error instead of
the relative error is discussed in [28]. This choice is also justiﬁed in a counter
example shown and discussed in the Subsection ??.
Indeed, it is possible to
have very small relative errors in TE even when TE diverges. By using the
absolute error as a measure of numerical stability, it follows that the quantities
that are related by continuos functions, like RTE, as well as the corresponding
Lp distances, must have similar numerical stability properties. Note that spe-
cial attention should be addressed to the limit case of BSE: the conditions that
stabilize RTE are not suﬃcient to stabilize BSE, more stabilizing conditions are
necessary and in the stability proof the powerful functional analytic methods

2

used previously in high-energy physics are involved [24]-[27].

The classical deﬁnitions of the quantity of information, or of the degree of
randomness, at least in the case of discrete (atomic) phase space, tacitly assume
the invariance of the quantity of information, or entropy, under measure pre-
serving groups that in classical simple cases are the permutations [1]-[3], [6] -[9].
This symmetry assumption applies to the case of more abstract deﬁnitions i.e.
the previous deﬁnitions of the entropy are invariant under the group of measure
preserving transformations. This reﬂects our complete lack of knowledge on the
possible dynamical behavior [14]. Larger symmetry group means less informa-
tion. Nevertheless, for real physical systems, for instance when the phase space
is a direct product of subspaces having completely diﬀerent physical interpreta-
tion and diﬀerent mathematical structures (e.g., the case when the total system
splits into driving and driven system [10]), we have already an information. In
such a situation, the general measure preserving transformations has no phys-
ical interpretation and should not be considered as a true, we mean physical,
symmetry [16]. Consequently, we need a new generalization of the entropy able
to take into account this direct product structure. The ﬁrst step in this direc-
tion can be found in a previous work cited in Ref.
[10] where a new class of
extensive generalization of R´enyi’s entropy is introduced to analyze the case of
a phase space, which may be split as a direct product of two sub-spaces (note
that the approach illustrated in this work applies equally to the case where the
phase-space may be split in an arbitrary, but ﬁnite, number of direct products
of sub-spaces). We expect that this new class of entropy will be useful in the
processing of Big Data with tensor structures.

In this work our aim is to study the stability properties of this class of
entropies. As in the previous work [10], our guiding line is to re-interpret the
generalized entropy in terms of distance in some generalization of classical [19]-
[29] or anisotropic Lp spaces [30].

The properties of Lp spaces, and associated ”distances”, will be used for
setting the numerical stability properties when auxiliary stabilizing conditions
are imposed. In this work the stabilizing conditions are expressed as ﬁniteness
of some classical or generalized (anisotropic [30]) Lebesgue space distances. In
some particular cases, these stabilizing conditions may be found by studying
directly the partial diﬀerential equations for the PDFs. This allows obtaining
bounds on the Sobolev space norm and, by using the embedding theorems,
getting information on the Lp norms [30], [31]. Another possibility is the study
of the heavy tail index [32], [33].

The work is organized as follows. In Section 2, Subsection 2.1, we relate the
RTE to a norm or pseudo-norm in a suitable deﬁned Lp spaces. In the Subsec-
tion 2.2, the domain of deﬁnition and the problem of continuity of the Shannon,
R´enyi and Tsallis entropies are studied, when the PDF is approximated in the
sense of distance in Lp spaces, with particular emphasis on the natural (from
probabilistic point of view) L1 distance. In particular, we discuss about diﬀerent
concepts of stability (continuity, in mathematical terms) of the entropies when
the PDF is known only approximately. We ﬁnd suﬃcient stabilizing conditions
for generic RTE. It is also proven (by counter examples) that in the case of

3

BSE, when a sequence of PDF ρn converges in the L1 norm to the PDFρ, extra
stabilizing conditions are necessary to ensure the continuity of BSE. We deter-
mine the stability of BSE under suitable stabilizing conditions. We emphasize
the central role of the functional Zq[ρ] (see below, [16]) that appears in the both
deﬁnition of RTE and BSE. The special analytic properties of this functional as
well as its relation to the distances in Lp spaces are used in the proofs.

In Section 3, we introduce a further, natural, extension of the Generalized
R´enyi Entropy (GRE), studied in the previous work ref.([10], [13], [16]) and
we explore their numerical stability. The ﬁniteness and continuity results from
Section 2 are extended to the most general case of GRE, by assuming suitable
stabilizing conditions.

We emphasize that the stabilizing conditions are expressed in the terms of
measure theoretic concepts. Hence, the results can equally be applied to both
continuos and discrete probability distributions, on a general measured space.
No continuity or diﬀerentiable properties of the PDF are assumed.

Mathematical details can be found in the Appendix 5. In Subsection5.1, the
powerful analytic extrapolation method is exposed. This method is necessary
to prove the stability of BSE. In Subsection 5.2 and In Subsection 5.3 we found
details on the proofs of counter examples and we expose the properties of a
class of metric vector spaces, related to the deﬁnition and properties of GRE,
respectively. In Subsection 5.4, the logarithmic convexity of a class of functionals
related to RTE and GRE is presented. These functionals are used in the main
proofs of the bound and the numerical stability of the RTE and GRE. For easy
reference, since our proof will be generalized to the study of the GRE, some of
the known logarithmic convexity properties of the classical Lp norms [21] are
demonstrated. The long proofs of stability of the classical Shannon-Boltzmann
entropy and of GRE are also presented in detail.

2 Finiteness and continuity aspects of the Shan-

non, R´enyi and Tsallis entropies

2.1 Deﬁnitions of generalized entropies in term of norms

and pseudo norms

Let’s consider a standard measure space (Ω, A, m) where Ω is the phase space of
a natural system (usually Rn, or in simplest probability models, some ﬁnite or
denumerable set, or the space of all Brownian trajectories), A is some σ−algebra
generated by a family-subsets of Ω (that are usually viewed as the collection of
the observable events in a probability space), and m is a σ-ﬁnite measure deﬁned
on A. In this framework the R´enyi divergence is expressed by R´enyi entropy
[16].

In the simplest cases of discrete (atomic) probability spaces, the measure
(not necessary ﬁnite) m is a counting measure. Note that in this simple case
the counting measure is invariant under the group of permutations on Ω. In
general, the measure m is chosen to be invariant under some symmetry group

4

of the physical system under study, but there are simple examples for measures
with trivial measure preserving group [16]. In the sequel, we consider only prob-
ability measures deﬁned on (Ω, A) that are continuos with respect to some ﬁxed
measure m, that means that for A ∈ A the probability p(A) can be represented
by probability density function (PDF) ρ as follows

p(A) =ZA
ρ(x) ≥ 0; ZΩ

ρ(x)dm(x); A ⊂ Ω

ρ(x)dm(x) = 1

(1)

(2)

or in shorthand notation dp(x) = ρ(x)dm(x). In this framework, the classical
BSE is given by

log [ρ(x)] ρ(x)dm(x)

(3)

Scl[ρ] = −ZΩ

The next subsequent generalizations, R´enyi’s [2]-[5] and Tsallis’ [6]-[9], [7] en-
tropies can be reformulated in the terms of distances [10] in the Lp(Ω, dm)
spaces of the distribution functions as follows. They correspond to the norms
kρkp [20] for p ≥ 1 and the pseudo-norm Np[ρ] [19], [29], [10] for 0 < p < 1,
respectively:

Details can be found in Ref. [10], Section III. In order to have a uniﬁed treatment
for both cases p ≶ 1, we introduce the following basic condensed notations:

kρkp,m =
ZΩ
Np,m[ρ] =ZΩ

1
p

; p ≥ 1

[ρ(x)]p dm(x)


[ρ(x)]p dm(x); 0 < p ≤ 1

i(p) := 1/p f or p ≥ 1; i(p) := 1 f or p ≤ 1

Dp,m[f ] :=
ZΩ
Zw,m[f ] :=ZΩ

i(p)

|f (x)|p dm(x)


|f (x)|w dm(x); Re(w) > 0

(4)

(5)

(6)

(7)

(8)

Remark 1 The function Dp,m[f ] is a generalized distance from the ”point” f
(in the function space) to the origin. Note that particular cases of Dp,m[f ]
are kf kp,m (p ≥ 1) and Np,m[ρ] (for 0 < p ≤ 1) deﬁned in Eqs.(4, 5). The

5

functional f → Dp,m[f ] has following basic metric properties:

Dp,m[f1 + f2] ≤ Dp,m[f1] + Dp,m[f2]

|Dp,m[f1] − Dp,m[f2]| ≤ Dp,m[f1 − f2]

Dp,m[αf ] = |α|s(p) Dp,m[f ] ; α ∈ R

(9)

(10)

(11)

s(p) = pi(p)

(12)
For p ≥ 1 the functional Dp,m[f ] = kf kp,m (i.e., the classical Lp norm), and
for 0 < p ≤ 1 the functional Dp,m[f ] = Np,m[f ] (i.e., the ”exotic” Lp pseudo
norm from Refs.([19]), [29]). The ”precision of approximation ρn of the true
PDF ρ ” is quantiﬁed by Dp.m[ρ − ρn] for some p > 0. A possible natural choice

is p = 1, because D1,m[ρ − ρn] = RΩ |ρ − ρn| dm is at least well deﬁned due to

Eq.(2).

The corresponding generalized entropies proposed by R´enyi [2]-[5] SR,q,m

and by C. Tsallis [6]-[9] ST,q,m, are given respectively by

SR,q,m[ρ] =

SR,q,m[ρ] =

1

1 − q
1

log Zq,m[ρ]

(1 − q)i(q)

log Dq,m[ρ]

ST,q,m[ρ] =

1

1 − q

[1 − Zq,m[ρ]] =

From Eqs.(3, 8) results

1

1 − q n1 − [Dq,m[ρ]]1/i(q)o

Scl[ρ] = −

d
dw

Zw,m(ρ)|w=1

(13)

(14)

(15)

(16)

when it exists. The functionals ST,q,m[ρ], ST,q,m[ρ], Dq,m[ρ] and Zq,m[ρ] are
algebraically related so they contain exactly the same amount of information.
Functional Zq,m[ρ] is the best candidate for including the entropy related func-
tionals in a powerful formalism of category theory [16]. This functional pos-
sesses also the remarkable analytic and log-convex properties (see below). In
the following proof, we shall use successively the representation of the entropies
by functionals Zq,m[ρ] and the distance function Dq,m[ρ]. From the previous
deﬁnitions we get the following result:

Remark 2 Let ρn, ρ ∈ Lp(Ω, dm) ∩ L1(Ω, dm), p 6= 1 with RΩ
RΩ

ρ(x)dm(x) = 1. The following convergencies are equivalent:

Dq,m[ρn] →

Dq,m[ρ]

n→∞

ρn(x)dm(x) =

Zq,m[ρn] →

n→∞
ST,q,m[ρn] →

n→∞

Zq,m[ρ]

ST,q,m[ρ]

If in addition Dq,m[ρ] > 0 then the previous convergences are equivalent to the
statement SR,q,m[ρn] →

SR,q,m[ρ].

n→∞

6

Remark 3 Note that when Ω is a ﬁnite or denumerable set, if we denote by pk
the probabilities of element xk ∈ Ω, with the measure m denoting the counting
measure (equal to number of elements in a subset) on the space Ω, then from
the previous Eqs.(4-14) we get the original deﬁnitions Refs. [2]-[5], [6]-[9]

SR,q[ρ] =

ST,q[ρ] =

pq
k

1

1 − q

logXk
1 − q "Xk

1

pq

k − 1#

(17)

(18)

2.2 Domain of deﬁnition (ﬁniteness) and continuity of the

Tsallis, R´enyi and Shannon entropies.

2.2.1 Generic case: Tsallis and R´enyi entropies

Domain of ﬁniteness of RTE’s.
In the study of the stability (or continuity)
properties we consider the general case, when the measure m(Ω) is not necessary
ﬁnite and its support does not reduce, necessarily, to a denumerable set. By
simple inspection of the Eqs.(8, 13-15) we conclude that the R´enyi and Tsallis
entropy (RTE) with same q as well as the functionals Dq,m and Zq,m, are ﬁnite
or inﬁnite, simultaneously. The problem related to the domain of deﬁnition
and continuity of the generalized entropies, when some approximations of the
probability density are used, is reduced to the problem of ﬁniteness of continuity
of the norm Eq.(4), pseudo norms Eq.(5) or the functional Zw(ρ) from Eq.(8),
respectively. Note that in the case of general measure space, when the measure
m is neither atomic nor probabilistic, for instance when Ω = R and dm(x) = dx,
as well as the pseudo norms Nq1 [ρ], Nq2 [ρ],
when q1 6= q2 the norms kρkq1
are not equivalent (the ﬁniteness or convergence of a sequence ρn in the norm
kρnkq1
[20], [19] and
there is no general inequality relating them). Consider the following example.

is not related to ﬁniteness or convergence in the norm kρnkq2

, kρkq2

Example 4 Let Ω = R, dm(x) = dx and consider the PDF ρ1(x), such that
|ρ1(x)|rdx <

RR

ρ1(x)dx = kρ1k1 = 1 and even moreRR

|ρ1(x) log ρ1(x)| dx < ∞, RR

∞ for all r > 0. Denote ρλ(x) := λρ1(λx). Despite kρλk1 = 1 observe that
when λ → ∞ for p > 1 the RTE diverges, for 0 < p < 1 the RE diverges. In
the limit λ → 0 for p < 1 the RTE diverges and for p > 1 the RE diverges.
The BSE of ρλ(x) diverges both in limits λ → ∞ and λ → 0.

It follows that at ﬁrst sight the answer to the previous questions is tau-
tological. But if we add the physical conditions Eqs (2) we can obtain more
information on the ﬁniteness and convergence. The following lemma comes
from the well known results [21], when p > 1. For easy reference we give an
elementary proof, which will be generalized to the study of GRE (Generalized
R´enyi entropies).

7

Lemma 5 Consider the measure space (Ω, A, m) and let f ∈ L1(Ω, dm) ∩
Ls(Ω, dm), s 6= 1, s > 0 with the property

|f (x)| dm(x) ≤ a1

|f (x)|s dm(x) ≤ as

ZΩ
ZΩ

Then for all r in the range

we have also the bound

min (1, s) < r < max (1, s)

|f (x)|r dm(x) ≤ a

s−r
s−1
1

r−1
s−1
s

a

ZΩ

(19)

(20)

(21)

This Lemma is a particular case of the Theorem 29, from the Appendix 5.4.
Before studying the continuity (also called stability) of the generalized entropies
with respect to small variations of the input PDF, ﬁrstly we should discuss the
problem of the ﬁniteness of the generalized entropies. The singular case of
classical entropy will be discussed later. From the previous Lemma 5 results the
following

Proposition 6 Let p 6= 1 and min (1, p) < r < max (1, p). For the PDF ρ

obeying Eq.(2), ρ ∈ L1(Ω, dm) ∩ Lp(Ω, dm), and RΩ

[ρ(x)]pdm(x) ≤ ap we have

[ρ(x)]rdm(x) ≤ a

r−1
p−1
p

ZΩ

(22)

Consequently if the norm kρkp is ﬁnite for some ﬁxed index index p > 1, then
kρkr, SR,r[ρ], ST,r[ρ] remain ﬁnite for all r in the range 1 < r ≤ p. If for some
ﬁxed p, with 0 < p < 1 the pseudonorm Np[ρ] is ﬁnite, then for all r in the
range p ≤ r < 1 also Nr[ρ], SR,r[ρ], ST,r[ρ] remain ﬁnite.
Proof. By setting in Lemma 5 f (x) = ρ(x) from the normalization condition
Eq.(2) results a1 = 1. Eq.(22) results directly from Eq.(21). The ﬁniteness of
entropies results from Eqs.(8, 13, 15).

When Ω = R and dm(x) := dx, the pseudo-norm Np[ρ], and the generalized
entropies SR,p[ρ], ST,p[ρ] are divergent for low values of p < p0 < 1 (or, in
practical estimations, they have large ﬂuctuations), we may argue that the PDF
|x|−1/p0 , like in models of stochasticity-induced
has a heavy tail: ρ(x) ≍

|x|→∞

instability [33]. If there exists some p1 such that for p > p1 > 1 the entropies,
and both norm and SR,p[ρ], ST,p[ρ] are divergent, this suggests that the PDF

8

has an integrable singularity of the type |x− x0|−1/p1 , for instance in the models
of noise driven intermittency [34]. Similarly, in the case of PDF deﬁned in higher
dimensional, anisotropic space the maximal domain of deﬁnition of generalized
R´enyi entropies [10] is related to more complicated singularity structure and
asymptotic behavior of the multivariate PDF.

In the continuation let us suppose to have an exact PDF ρ ∈ Lp(Ω, dm) ∩
L1(Ω, dm), with p 6= 1, which is approximated by an approximant sequence
ρn ∈ Lp(Ω, dm) ∩ L1(Ω, dm), and ρ, ρn satisfy the Eq.(2). We also suppose that
the ”true” limit PDF ρ exists, so ρn is a Cauchy sequence, in L1.

Remark 7 Our approach on the stability problem is diﬀerent from Ref.[18],
where no stabilizing conditions are imposed. There are simple counter exam-
ples ?? of sequences of probability distributions on N that are convergent in l1,
consequently bounded and convergent in lp (p > 1) norm but the BSE diverges,
despite it is Lesche stable (see below). We mention that in the case when we
restrict ourselves to discrete distributions, from all of the convergence results
based on stabilizing conditions it follows also the Lesche stability. The counter
example from ?? proves that there exist sequences of PDF’s ρn that are con-
vergent in all the spaces Lp([0, 1/2], dx) with 0 < p ≤ 1, nevertheless the BSE
diverges.

Continuity of RTE’s when the PDF is approximated in L1 norm.
Suppose that for some p 6= 1 we have Lp bounds

|ρn(x)|p dm(x) ≤ b1

|ρ(x)|p dm(x) ≤ b2

ZΩ
ZΩ

For instance, such kind of bounds could be obtained by the technique used
in the study of the heavy tail phenomena in random aﬃne processes [32], [33].
The quality of the approximation is quantiﬁed in the L1 norm kρn − ρkL1
. By
using Eq.(9) it follows

|ρn(x) − ρ(x)|p dm(x) ≤ b

|ρn(x) − ρ(x)| dm(x) ≤ εn →

n→∞

0

ZΩ
ZΩ

(23)

(24)

Here b = b1 + b2 for 0 < p < 1 and b = (cid:16)b1/p

, see Eq.(7). By using
Eqs.(23, 24) and the Lemma 5, with a1 = εn, ap = b, with f (x) := ρn(x) − ρ(x),
we get for min (1, p) < r < max (1, p)

1 + b1/p

2 (cid:17)p

9

|ρn(x) − ρ(x)|r dm(x) ≤ ε

p−r
p−1
n

b

r−1
p−1

ZΩ

[Dr,m[ρn − ρ]]

1

i(p) ≤ ε

p−r
p−1
n

b

r−1
p−1

From Eqs.(26, 7, 8, 10) we obtain

|Dr,m[ρn] − Dr,m[ρ]| ≤ δn →
n→∞

0

p−r
p−1

n m

δn =(cid:20)ε

r−1

p−1(cid:21)i(p)

(25)

(26)

(27)

(28)

Taking into account remark 2 we can summarize the previous results Eq.(27) as
follows

Proposition 8 Suppose that, for some p 6= 1, we have boundednes of |ρn(x) − ρ(x)|
in the Lp norm (Eq (23)) and convergence of the sequence ρn(x) to ρ(x) in L1
norm Eq. (24). Then it follows the convergence in Lr(Ω, dm) distance for all
values of r in the range min (p, 1) < r < max (p, 1)

Dr,m[ρn(x) − ρ(x)] →

n→∞

0

(29)

In particular we have for all the Tsallis and R´enyi entropies and functionals
Dr,m[] with r in this range

ST,r[ρn] →

n→∞
SR,r[ρn] →

n→∞

ST,r[ρ]

SR,r[ρ]

Dr,m[ρn(x)] →

n→∞

Dr,m[ρ(x)]

(30)

(31)

(32)

Remark 9 From the previous result we note that the boundednes of the RE for
some p 6= 1 has a stabilizing eﬀect, only in the subset of all the PDFs satisfying
Eq.(23). Hence, from the convergence in the natural L1 distance we can conclude
the convergence of the R´enyi or Tsallis entropies. Note that from Eq.(25) and
p > 1, when r ր p the error in the Lr norm increases and ﬁnally, when r = p
it attains the upper bound Eq.(23).

From the point of view of statistical physics the convergence of sequence of
PDF deﬁned by some Lp distance is important because it follows the convergence
of the expectation values of physical observable that belongs to the dual spaces
[20]. Hence, in the case p > 1, from Eq.(29) we get the convergence kρn − ρkr →
0 for 1 < r < p and it follows the continuity of the expectation values of
observable f (x) from the dual space f ∈ Lq(Ω, dm) where 1/q + 1/r = 1

ZΩ

ρn(x)f (x)dm(x) →

n→∞ZΩ

ρ(x)f (x)dm(x)

f ∈ Lq(Ω, dm); q >

p

p − 1

10

(33)

(34)

For 0 < q < 1, it is possible that the dual space S of Lq(Ω, dm) is trivial. When
S is not trivial (e.g., the space of sequences lq) and f ∈ S), from Lp we obtain
again the continuity of corresponding expectation values, similar to Eq.(33).

Continuity of RTE’s when the PDF is approximated in Lp norm. Sup-
pose that the quality of approximation ρn(x) of the true PDF ρ(x) is quantiﬁed
in some Lp norm with p 6= 1. A convenient choice in the applications is p = 2.
Suppose that ρ(x), ρn(x) ∈ L1(Ω, m) ∩ Lp(Ω, m) and in analogy to the previous
case we have

|ρn(x) − ρ(x)|p dm(x) ≤ εn →
n→∞

0

ZΩ

ρn(x)dm(x) = 1

ZΩ

From the normalization condition, for ρ, ρn Eq.(2, 36) we obtain

|ρn(x) − ρ(x)| dm(x) ≤ 2

ZΩ

(35)

(36)

(37)

By using the Lemma 5 with a1 = 2 and ap = εn and Eq.(7) we obtain for all r
in the domain

the following bounds

D = {r| min(1, p) < r < max(1, p)}

|ρn(x) − ρ(x)|r dm(x) ≤ 2

p−r

p−1 ε

ZΩ

r−1
p−1

n →

n→∞

[Dr,m[ρn − ρ]]

1
i(p) ≤ 2

p−r

p−1 ε

r−1
p−1
n

By using Eqs.(40, 7, respectively, 10) is

|Dr,m[ρn] − Dr,m[ρ]| ≤ δn →
n→∞

0

δn :=(cid:20)2

p−r

p−1 ε

r−1
p−1

n (cid:21)i(p)

0

(38)

(39)

(40)

(41)

(42)

From the Eqs.(41, 13-15) and Remark 2 we have the following stability results

Proposition 10 Under the conditions Eqs.(2, 35, 36) for r in the range
min(1, p) < r < max(1, p) we have

ST,r[ρn] →

n→∞
SR,r[ρn] →

n→∞

ST,r[ρ]

SR,r[ρ]

We recall that in the case when the measure dm(x) is probabilistic,

if
. If the measure dm(x) is atomic, then from the
p > q ≥ 1 then kf kLq
convergence or boundednes in some lp norm results the convergence or bound-
ednes in all lq norm, with q > p, including l∞.

< kf kLp

11

2.2.2 Boundednes and stability of the BSE

Details are given in Appendix 5.2

Counter example 1, discrete distribution We shall provide some counter
examples that prove that the previous stabilizing conditions are not suﬃcient for
the stability of the BSE. The details can be found in Appendix 5.2.1. Consider
now the problem of continuity of the classical entropy, in the simplest case of the
countable inﬁnite probability space, with probabilities p := {p1, ..., pn, ...} :=
{pk}∞

k=1. In this case

∞

Clearly

Scl[p] = −

pk log pk

Xk=1

∞

1 =

pk = kpkl1

Xk=1

and it is logical to consider that the distance between two probability laws
p := {p1, ..., pn, ...} and p′ := {p′

n, ...} is given by l1 distance:

1, ..., p′

kp − p′kl1 :=

|pk − p′
k|

∞

Xk=1

Consider now the sequence that is convergent in the l1

where

k o∞
p(n) :=np(n)

k=1

p(n)
k

:=

1
Kn
∞

Kn =

Xk=1

1

(k + 4) [log (k + 4)]2+ 1

n

1

(k + 4) [log (k + 4)]2+ 1

n

< ∞

(45)

(46)

(47)

Note that (cid:13)(cid:13)p(n)(cid:13)(cid:13)l1 = 1 and the limit of the sequence p(n) in the space l1 is the

probability distribution given by p := {pk}∞

k=1 where

(43)

(44)

(48)

(49)

(50)

p := {pk}∞
k=1

pk =

K =

1
K
∞

Xk=1

1

(k + 4) [log (k + 4)]2

1

(k + 4) [log (k + 4)]2 < ∞

12

We have also the following (general) inclusion:

= 1 ⇒ p(n) ∈ lq ; q > 1

(51)

Despite the sequence p(n) is convergent in l1:

(cid:13)(cid:13)(cid:13)
p(n)(cid:13)(cid:13)(cid:13)l1
(cid:13)(cid:13)(cid:13)
p(n) − p(cid:13)(cid:13)(cid:13)

→

n→∞

0

it is easy to prove that the classical entropy is divergent:

Scl[p(n)] = O(n); n → ∞

(52)

Consequently, the functional p →Scl[p] from the space l1 to R is not continuos,
despite the classical entropy has the Lesche stability property and we have
stabilizing condition from Eq.(51) in the form of lp boundednes with p > 1.

Counter example 2, continuos distribution with ﬁnite measure m.
A second counter example is the following. Consider Ω = [0, 1/2], dm(x) = dx
and deﬁne

ρn(x) =

Mn

x(cid:0)log 1

x(cid:1)α ; x ≥

1
n

ρn(x) = 0; 0 < x <

M

ρ(x) =

x(cid:1)α
x(cid:0)log 1

1 < α < 2

1
n

(53)

(54)

(55)

(56)

where Mn, M are ﬁnite normalization constants. Note that (for further details
see Appendix 5.2.2)

Dp(ρn) < Cp; Dp(ρ) < Cp

(57)

for some constants Cp < ∞, that does not depend on n. Consequently ρn, ρ ∈
L1 ∩ Lp for all 0 < p ≤ 1 and

D1[ρn − ρ] = kρn − ρkL1 →
n→∞

0

(58)

so we have a wide choice of stabilizing conditions (see Proposition 8) assuring
that SR,q(ρn) → SR,q(ρ) for all q in the range p < q < 1. Nevertheless, the
classical entropy diverges:

Scl[ρn] = −O(log n)2−α → −∞

(59)

13

2.2.3 Boundednes and stability of the BSE.

At the ﬁrst stage, let us suppose in the following that the true PDF ρ(x) is
approximated by the sequence ρn ∈ Lp(Ω, dm) ∩ Lq(Ω, dm) where 0 < p < 1
and q > 1 in the L1 norm:

ZΩ

|ρn(x) − ρ(x)| dm(x) := εn →

n→∞

0

(60)

By Theorem 29 we have also ρn ∈ L1(Ω, dm). Suppose, without loss of gener-
ality, that in addition we have the following stabilization conditions

Zp,m[ρn] = Dp,m[ρn] ≤ A; p < 1

Zp,m[ρ] = Dp,m[ρ] ≤ A; p < 1
Zq,m[ρn] = Dq,m[ρn]q ≤ A; q > 1
Zq,m[ρ] = Dq,m[ρ]q ≤ A; q > 1

(61)

(62)
(63)

(64)

For the sake of simplicity we will used a less strict bounds. These bounds are
compatible with the normalization condition Z1,m[ρn] = 1 if 1 ≤ A. From
Theorem 29, from the Appendix 5.4 and previous bounds, we get

Zr,m[ρn] = [Dr,m[ρn]]1/i(r) ≤ A; p ≤ r ≤ q
Zr,m[ρ] = [Dr,m[ρ]]1/i(r) ≤ A; p ≤ r ≤ q

(65)

(66)

From Eqs.(65, 66, 8) we extend these bounds to the complex domain, p ≤
Re(w) ≤ q:

|Zw,m[ρn]| =(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
ZΩ

and in similar manner

|ρn(x)|w dm(x)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

≤ZΩ

|ρn|Re(w) dm(x) ≤ A

(67)

|Zw,m[ρ]| ≤ A; p ≤ Re(w) ≤ q

(68)

Boundednes
[36] of the analytic function w → Zw,m[ρ], and related to the BSE by Eq.(16)

In the following Zq,m[ρ] can be considered a particular value

Proposition 11 Under the conditions Eqs.[61,63 ] there exists an analytic con-
tinuation of the function Zr,m[ρn], denoted by

Fn(z) :=ZΩ

|ρn(x)|z dm(x)

(69)

in the strip from the complex z plane D = {z|p < Re(z) < q} such that Fn(x) =
Zx,m[ρn] for p ≤ x ≤ q. We have for all z ∈ D the bound

|Fn(z)| ≤ A

(70)

14

The BSE of the PDF is given by the Cauchy integral

Scl[ρn] = −(cid:20) d

dz

Fn(z)(cid:21)z=1

= −

1

2πiIC

Fn(w)dw
(w − 1)2

(71)

where C is a suﬃciently small circle centered in w = 1. The BSE is bounded by

|Scl[ρn| ≤

2A

min(q − 1, 1 − p)

(72)

Proof. The Eq.(70) results from Corollary 30, Appendix (5.4). Eq.(71) is a
direct consequence of Eqs (16, 69). To prove Eq.(72), we denote

r = min(q − 1, 1 − p)/2

(73)

the radius of the circle C, which is in the interior to the analyticity domain of
Fn(w). By Cauchy theorem and Eq.(71) we have

Fn(z) =

Scl[ρn] = −

1

2πiIC
2πiIC

1

Fn(z′)
z′ − z

dz′

Fn(z′)
(z′ − 1)2 dz′

where C is the circle with radius r, so |z′ − 1| = r. By Eqs.(67, 68)

From Eq.(75) we get

|Fn(z′)| ≤ A

|Scl[ρn]| ≤

1
r

max
z∈C ′

|Fn(z)|

which combined with Eqs.(73, 76) completes the proof.

(74)

(75)

(76)

Stability of the BSE .
Consider now the stability problem. Suppose that the sequence of PDF ρn
approximates the exact PDF ρ in the sense of Eq.(60) and we have the bounds
Eqs.(61-64). We obtain the following result on the stability of the BSE:

Theorem 12 Under the he previous conditions Eqs.(60-64) we have

lim
n→∞

Scl[ρn] = Scl[ρ]

(77)

The proof (See Appendix 5.4.2) uses mathematical methods adopted in high
energy physics [24]-[27].
In conclusion, the problem of numerical approximation of the classical and gen-
eralized entropies in the general case, cannot be solved without additional as-
sumptions, that are tacitly used in practice. Among auxiliary assumptions that

15

could stabilize the numerical instability in the computation of the entropies, we
have smoothness conditions and bounds on the tail of the probability density
function. We also mention that in many practical situation, the cumulative
probability distribution function is approximated by the empirical cumulative
distribution obtained from experiment.
In this case the goodness of the ﬁt-
ting is characterized by a random variable, whose distribution is described by
the Kolmogorov-Smirnov or the Anderson-Darling statistics. Consequently, the
computed entropies are itself random variables and the problem of continuity
must be formulated in terms of convergence of random variables. This class of
problems deserves a further study.

3 The generalized R´enyi entropies (GRE).

3.1 Motivations

Our generalization of the GRE deﬁned in the previous work [10] is a straight-
forward extension of the previous case when the full phase space is a Cartesian
product of two spaces, to the more general case of N factors. The line of rea-
soning is the same: ﬁrst, we remark the mathematical relation between classical
R´enyi entropy and the metric in Lebesgue spaces and, second, we deﬁne the
new entropies by using the metric in generalized Lebesgue spaces [30] (similar
to the particular case N = 2 studied in [10]). The introduction of GRE is justi-
ﬁed by the fact that it provide a large family of Liapunov functionals and there
is an application of the GRE to the study of perturbed Hamiltonian systems
[13], that cannot be performed with the classical R´enyi, Tsallis or Boltzmann-
Shannon entropy. There are also an intrinsic mathematical motivation [16].
Other motivations for this generalization are the following.

3.1.1 Avoiding integrability problems

The PDF functions in many variables may have a more complex singularity
structure such that all the RTE diverge. We proved in [10] that the GRE can
solve this problem, in the case of PDF with two variables. The generaliza-
tion introduced here is intended to treat similar integrability problems in many
variables. As speciﬁed in the previous part, the domain of the entropy param-
eter q, where the R´enyi or the Tsallis entropies are deﬁned, is related to the
singularities and to the asymptotic behavior of the PDF. Indeed, consider the
case when the PDF depends on the real variable x so (Ω, A, m) = (R, B(R), λ1)
where B(R) is the family of subsets of R generated by denumerable intersections
and unions of open and close intervals, and λ1 is the Lebesgue measure (more
exactly dm = dλ1 = dx). Suppose that the PDF ρ(x) has the decomposition
in a regular part, ρ0(x) is diﬀerentiable and decays, at least exponentially at
inﬁnity, in both singular part and a heavy tail part

ρ(x) = ρ0(x)(cid:20)1 +

A

|x|α(cid:21) +

B

1 + |x|1+β

16

where A, B, β > 0, and 0 < α < 1. The RTE is ﬁnite when 1/ (1 + β) < q <
1/α. In processing the experimental data, the large value of the RTE for some
q < 1 is a signal characterized by a heavy tail of PDF (this is shown in the
stationary PDF in self organized criticality models as well as in the linearized
stochastic models with multiplicative noise [33]). The large value of RTE for
some q > 1 suggests the existence of local singularity, that in some models is
related to the phenomenon of noise driven intermittency [34]. Consequently, the
plotting of the RTE is a good practice for detecting the existence of singularity
and heavy tail eﬀects.
Suppose now that we have a PDF depending of 3 variables ρ(x1, x2, x3) that
similarly has a regular part ρ0 that is diﬀerentiable and decay exponentially at
inﬁnity, and singular and heavy tail parts

ρ(x1, x2, x3) = ρ0(x1, x2, x3)"1 +

3

Xi=1

Ai

|xi|αi# +

3

Yi=1

Bi

1 + |xi|1+βi

(78)

with α1 < α2 < α3 and β1 < β2 < β3. Note that the RTE associated to ρ from
Eq.(78) is deﬁned in the domain

1/ (1 + β1) < q < 1/α3

(79)

so it cannot detect the singularity (possible intermittency phenomena) in the
variables x1, x2 and the heavy tail (possible SOC eﬀects) in the variable x2, x3.
In the sequel we will introduce a subsequent generalization that overcomes this
diﬃculty.

3.1.2 Invariance under measure preserving transformations.

The classical as well as generalized entropies are general functionals that ex-
tracts/condense information about PDF, according to most general rules of the
probability theory. As a result the BSE, RTE are invariant under measure pre-
serving transformations. For illustration we consider the simplest case, when
we have a ﬁnite discrete probability distribution pi,α, with 1 ≤ i ≤ N and

N

Pi=1

A

Pa=1

1 ≤ α ≤ A, with

pi,α = 1. Consider the case when the measure m in

Eqs(8, 13) is the product of the counting measures on the sets {1, ..., N } and
{1, ..., A}.
In the terminology of ”Big Data”, the N A data are presented in
tensorized form [35]. The corresponding BSE and RE are

Scl = −

N

A

Xi=1

Xa=1

SR,w =

1

1 − w

log

pi,α log pi,α

N

A

Xi=1

Xa=1

pw
i,α; w > 0

(80)

(81)

These entropies are invariant under the change of variables

pi,α → pσ(i,α)

17

where the transformation σ :
(i, α) → σ(i, α) is an element of the permuta-
tion group SN A of N A objects, SN A having (N A)! elements, that reﬂect our
complete lack of information about state space and ignore its Cartesian product
structure. However, when the indices i and α have diﬀerent physical meaning,
such an extended symmetry hypothesis is not appropriate. On the other hand,
the GRE’s whose construction use the Cartesian product structure for generic
pi,α [10]

Sv,w :=

S(permuted)

p,q

:=

1

1 − w

log

1

1 − w

log

N

Xi=1" A
Xa=1
Xα=1" N
Xi=1

A

v

v

pw

i,α#
i,α#

pw

(82)

(83)

is not invariant under full permutation group SN A. The knowledge of SR,q
from Eq.(81) for all w > 0 allows to reconstruct the probabilities pi,a modulo
permutation group SN A (i.e. reconstruct the probabilities without speciﬁcation
of their place in the list). On the other hand the knowledge of the GRE’s from
Eqs.(82, 83) for all v > 0, w > 0 allows to reconstruct pi,a modulo smaller
group SN × SA (see [16]). Similar problems appear in the case of probability
distribution pi,α,m where the indices i, α, m have diﬀerent interpretation. The
invariance group SN AM of the R´enyi entropy

SR,q =

1

1 − q

log

N

A

M

Xi=1

Xa=1

Xm=1

pq
i,α,m

is too large, it contains (N AM )! elements. In contrast, the generalized R´enyi
entropy, introduced in this work

1

1 − q3

log

N

Xi=1" A

Xa=1" M
Xm=1

q1

pq3

q2#
i,α,m#

(84)

is no more invariant under full permutation group SN AM . On the other hand it
is easy to see that the invariance group of Eq.(84) contains at least the product
of subgroups, having at least N !A!M ! elements. For more detailed discussion,
see [16]. In conclusion, while the RTE, BSE are constructed by using the most
fundamental structures of the probability theory, the GRE also take into ac-
count the Cartesian product structure of the phase space and the corresponding
product structures of measures.

3.2 Deﬁnitions and notations

We follow the same approach as in ref.[10]. We will deﬁne the Generalized
R´enyi entropies by using the results on Banach spaces with the anisotropic
norm, exposed in ref.[30]. In the ﬁrst part of the discussion we will restrict our
discussions to the set of parameters that deﬁnes the GRE, when a) The integrals

18

that appear in the deﬁnition can be interpreted as the distance in a suitable
function space and b) The formula for entropy can be related to convexity or
concavity properties of some functional, in the subspace of non negative density
functions. Consequently, we will deﬁne only two class of distance-functionals
and entropies, in analogy to functionals S(1)
qy,qz [ρ] deﬁned in ref.[10].
Consider that the measure space (Ω, A, m) has the following direct product

py,pz [ρ] and S(2)

structure. First, the phase space Ω is split into N subspaces

Ω = Ω1 × Ω2 × ... × ΩN

(85)

This means that the argument x of probability density function can be repre-
sented as x = {x1, x2, ..., xN }, so

ρ(x) = ρ(x1, x2, ..., xN )

(86)

with xk ∈ Ωk, 1 ≤ k ≤ N . We mention also that, in general, it is possible
that the component spaces Ωk are discrete, or has the structure of Rn or more
in general, of an inﬁnite dimensional measure space. Each of the spaces Ωk
(The σ−algebra A, that contains subsets of Ω =
has their σ−algebra Ak.
Ω1 × Ω2 × ... × ΩN is deﬁned as a tensor product of the σ−algebras Ak :
it
pk→ Ωk are
is the smallest σ−algebra on Ω such that all of the projections Ω
measurable [19]-[21]). The measure m is also factorizable:

dm(x) =dm(x1, x2, ..., xN ) =

dmk(xk)

(87)

N

Yj=1

where the measures mk are deﬁned on the σ−algebras (space of events) Ak. In
other words, the measure space (Ω, A, m) is the direct product

(Ω, A, m) =

N

(Ωj , Aj, mj)

Oj=1

The elementary probability dP (x) is given by

dP (x) = ρ(x1, x2, ..., xN )dm(x)

(88)

(89)

where dm(x) is given by Eq.(87). Consider a vector p = {p1, p2, ..., pN } of real
numbers with pk ≥ 1. According to Ref.[30], in close analogy to Ref.[10] (where
the particular case N = 2 was studied), we deﬁne recursively the anisotropic
norm (depending on the measure m) kρkp,m as follows (see Appendix, subsection

19

5.3)

ρN (, x1, x2, ..., xN ) := ρ(x1, x2, ..., xN )

ρN −1(x1,, x2, ..., xN −1) :=
ZΩN
ρk−1(x1, x2, ..., xk−1) :=
ZΩk
ρ1 (x1) :=
ZΩ2
kρkp,m :=
ZΩ1

1/pk

[ρN (x1, ..., xN )]pN dmN (xN )

[ρk (x1, ..., xk)]pk dmk(xk)

[ρ2 (x1, x2)]p2 dm2(x2)

[ρ1 (x1)]p1 dm1(x1)


1/p1

1/p2

1/pN

(90)

....

(91)

...

(92)

(93)

(94)

In analogy with Eqs.(4, 13) and Ref. [10] we deﬁne the GRE, with respect to
the measure m

S(1)

p [ρ, m] =

p1

1 − pN

log kρkp,m ; pi > 1

(95)

Note that the also the anisotropic norm function ρ → kρkp,m is convex and
satisﬁes the axioms related to the norm [30]. The corresponding normed vector
space is complete, i. e.
it is a Banach space (see Ref.[30]). There is another
range of parameters that generalizes the R´enyi entropy corresponding to Eqs.(5,
14). Consider a vector q = {q1, q2, ..., qN } of real numbers with 0 < qk ≤ 1. In
analogy to Eqs.(90-94) we deﬁne recursively

ρ′
N (x1, x2, ..., xN ) := ρ(x1, x2, ..., xN )

ρ′

ρ′

N −1(x1, x2, ..., xN −1) := ZΩN
k−1(x1, x2, ..., xk−1) :=ZΩk
1 (x1) :=ZΩ2
Nq,m[ρ] :=ZΩ1

ρ′

[ρ′

M (x1, ..., xN )]qN dmN (xN )....

[ρ′

k (x1, ..., xk)]qk dmk(xk)...

[ρ′

2 (x1, x2)]q2 dm2(x2)

[ρ′

1 (x1)]q1 dm1(x1)

(96)

(97)

(98)

(99)

(100)

Observe that the mapping ρ → Nq,m[ρ] deﬁnes a pseudo-norm on the space
of probability density functions (see Appendix, subsection 5.3). The map ρ →
Nq,m[ρ] deﬁnes a concave function, in the subset of physically admissible PDF’s,

20

when ρ(x1, x2, ..., xN ) ≥ 0. The GRE will be deﬁned in analogy to Eqs.(5, 14)
and to the case N = 2 from Ref. [10]

S(2)

q [ρ, m] =

1

1 − qN

log Nq,m[ρ]; 0 < qi < 1

(101)

For the sake of simplicity, we will use the extrapolated form of Eq. (101) in
all range qk > 0 of the parameters {q1, ..., qN } allowing to relate S(2)
q [ρ, m] to
S(1)
p [ρ, m]. We obtain

S(2)
q [ρ, m] = S(1)

p [ρ, m]

when pi and qi are related as follows

Nq,m[ρ] =hkρkp,mip1

qN = pN

qN −1 =

qk =

q1 =

...

, ...

pN −1
pN
pk
pk+1
p1
p2

(102)

(103)

(104)

(105)

(106)

(107)

Remark 13 The algebraic equations for the Lagrange multipliers associated to
maximal entropy problem are very complicated in the general case, nevertheless
from the convexity or concavity properties the uniqueness of the solution follows.
According to Eqs.(102-107), we are in the domain when ρ → kρkp,m is a convex
functional when

pk =

N

Yj=k

qj ≥ 1

(108)

In this case, the problem of maximal entropy with linear restriction is equiva-
lent to minimization of a positive convex function and has unique solution. In
the domain 0 < qk < 1, where the map ρ → N [ρ]q,m is a concave function,
the generalized MaxEnt problem is equivalent to the maximization of a concave
function with linear restriction. If the solution exists, it is unique. In the more
general case exposed below the problem of uniqueness deserves further study.

To have a more compact, more general extension of both the deﬁnitions of
kρkp,m in Eqs.(90 -94) and Nq,m[ρ] in Eqs.(96 -100), we deﬁne a more general
distance functional for a more general range of parameters p, that are general-
izations of the functional deﬁned in Eq.(7). We shall use the notation of Eq.(6),
so the generalization of Eqs.(90-94, 96-100) are the following (for another equiv-

21

alent construction see Appendix subsection 5.3)

fN (, x1, x2, ..., xN ) := f (x1, x2, ..., xN )

fN −1(x1,, x2, ..., xN −1) :=
ZΩN
fk−1(x1, x2, ..., xk−1) :=
ZΩk
f1(x1) :=
ZΩ2
Dp,m [f ] :=
ZΩ1

|fN (x1, ..., xN )|pN dmN (xN )

|fk (x1, ..., xk)|pk dmk(xk)

|f2 (x1, x2)|p2 dm2(x2)

|f1 (x1)|p1 dm1(x1)


i(p1)

i(pk)

i(p2)

(109)

i(pN )

....

(110)

...

(111)

(112)

(113)

(114)
(115)

(116)

We have the following important properties

Proposition 14 The functional f → Dp,m [f ] is a pseudo norm

Dp,m [αf ] = |α|s Dp,m [f ] ; α ∈ R
Dp,m [f + g] ≤ Dp,m [f ] + Dp,m [g]

|Dp,m [f ] − Dp,m [g]| ≤ Dp,m [f − g]

where the homogeneity degree from Eq.(114) is s =

For proof see Appendix, Subsection 5.3

[i(pk)pk]

N

Qk=1

Always is it possible to relate the functionals Dp,m [f ] by Nq,m [f ]. By compar-
ing Eqs.(96-100) we obtain

Dp,m [f ] = [Nq,m[f ]]i(p1)

(117)

where the relation between exponents q =(q1, ..., qN ) and p = (p1, ..., pN ) is

qN = pN

qN −1 = pN −1i(pN )
qN −2 = pN −2i(pN −1)

...

q2 = p2i(p3)
q1 = p1i(p2)

22

(118)

(119)
(120)

(121)
(122)

(123)

From previous equations we have that the GRE can be expressed always either
by functional Dp,m [ρ] or by the functional Nq,m[ρ]

S(2)

q [ρ, m] =

1

1 − qN

log Nq,m[ρ] = S(2)

q [ρ, m] =

1

i(p1)(1 − pN )

log Dp,m [f ]

(124)

Remark 15 Beside the previous deﬁnitions a more complete information about
PDF can be obtained from S(2)
and the map k → T (k) is a permutation of N indices.

q [ρ(perm), m] where ρ(perm)(x1, ..., xN ) := ρ(xT (1), ..., xT (N ))

3.3 Properties of the GRE

3.3.1 Extensivity, in the classical sense

The extensivity follows from the multiplicative property of the norms kρkp or
pseudo-norms N [ρ]q. Suppose that for all of measure spaces (Ωj, Aj, mj) that
appear in Eq.(88) we have the splitting

(Ωj, Aj, mj) = (Ω(1)

j

, A(1)

j

, m(1)

j ) ⊗ (Ω(2)

j

, A(2)

j

, m(2)
j )

(125)

that means in particular that Ωj = Ω(1)

j × Ω(2)

j

, xj = {x(1)

j

, x(2)

j } ∈ Ωj,

dmj(xj ) = dmj(x(1)

j

, x(2)

j ) = dm(1)

j (x(1)

j )dm(2)

j (x(2)
j )

Accordingly we have the splitting of the phase space Ω

Ω = Ω(1) × Ω(2)

dm(x)=dm(1)(x(1))dm(2)(x(2))

x(a) = {x(a)

1 , x(a)

2 ..., x(a)

N }; a = 1, 2

where

Ω(a) = Ω(a)

1 × Ω(a)

2 × ... × Ω(a)

N ; a = 1, 2

dm(a)(x(a))=

N

Yk=1

dm(a)

j

(x(a)

j

); a = 1, 2

or in compact notation

(126)

(127)

(128)

(129)

(130)

(131)

(Ω, A, m) = (Ω(1), A(1), m(1)) ⊗ (Ω(2), A(2), m(2))

(132)

Suppose that the PDF is also factorized

ρ(x) = ρ1(x(1))ρ2(x(2))

(133)

23

Then we have the following relations, for all values of the parameters {p1, ..., pN }
or {q1, ..., qN } such that the integrals make sense

kρ2kp,m2
kρkp,m = kρ1kp,m1
Nq,m[ρ] = Nq,m1[ρ1]Nq,m2[ρ2]
S(1)
p [ρ, m] = S(1)
p [ρ1, m1] + S(1)
S(2)
q [ρ, m] = S(2)
q [ρ1, m1] + S(2)

p [ρ2, m2]

q [ρ2, m2]

(134)

(135)

(136)

(137)

In the previous relations we deﬁned S(1)
101) and correspondingly

p [ρ, m] and S(2)

q [ρ, m] according to Eqs.(95,

S(1)

p [ρa, ma] =

S(2)

q [ρa, ma] =

p1

1 − pN

1

1 − qN

log kρakp,ma

; a = 1, 2

log Nq,ma[ρa]; a = 1, 2

(138)

(139)

For the sake of clarity, consider the following example with N = 3. Suppose
0 < q1, q2, q3 ≤ 1 and p1, p2, p3 ≥ 1. We deﬁne Nq,ma[ρa] respectively kρakp,ma
with a = 1, 2 as follows

Nq,ma[ρa] = ZΩ(a)

1

dm(a)

1 (x(a)
1 )

dm(a)

2 (x(a)

dm(a)

3 (x(a)

1 , x(a)

2 , x(a)

3 )ρ(cid:16)x(a)

dm(a)

2 (x(a)

dm(a)

3 (x(a)

1 , x(a)

2 , x(a)

3 )ρ(cid:16)x(a)

kρakp1

p,ma

dm(a)

1 (x(a)
1 )

2


ZΩ(a)

= ZΩ(a)

ZΩ(a)


1

2

2 )
ZΩ(a)


3

2 )
ZΩ(a)


3

(140)

(141)

(142)

p1/p2

(143)

q1

q2
3 (cid:17)q3



p2/p3
3 (cid:17)p3



3.3.2 Particular cases.

In the following we will omit the measure, when no confusion arise: kρkp,m :=
kρkp; N [ρ]q,m := N [ρ]q; S(a)
In the particular case when
p1 = ... = pN > 1, or 0 < q1 = q2 = ... = qN −1 = 1 and qN < 1 the GRE is

p [ρ, m] := S(a)

p [ρ].

24

equal to the classical R´enyi entropy from Eqs.(13, 14):

respectively

S(1)

p [ρ] = SR,pN [ρ] =

pN

1 − pN

log kρkpN

kρkpN

=
ZΩ

1/pN

dm(x)ρ(x)pN


S(2)

q [ρ] = SR,qN [ρ] =

1

1 − qN

log N [ρ]qN

NqN [ρ] =ZΩ

dm(x)ρ(x)qN

(144)

(145)

(146)

(147)

We used the notation from Eqs.(96-101). In particular when pN ց 1 in Eqs.(144,
145) and when q1 = q2 = ... = qN −1 = 1; qN ր 1 in Eqs.(146, 147), respectively,
we obtain the classical BSE

lim

p1=...=pN ց1

S(1)

p [ρ] =

lim

q1=...=qN −1=1; qN ր1

S(2)

q [ρ] == −ZΩ

dm(x)ρ(x) log ρ(x)

(148)

3.3.3 Symmetry properties

Recall that the R´enyi entropy is invariant under the group Γ(Ω, m) of invert-
ible transformations of Ω that preserve the measure m. A measure preserving
T
→ Ω of the measure space (Ω, A, m) is a transformation such
transformation Ω

that for all A ⊂ Ω, A ∈ A, we have m(cid:2)T −1 (A)(cid:3) = m (A). Deﬁne the operator

UT acting on the distribution function as

ρ → UT ρ = ρ′
ρ′(x) := ρ [T (x)]

Then it is easy to verify that both Tsallis and R´enyi entropies are invariant: for
all ρ such that SR,q[ρ] is ﬁnite we have for all T ∈ Γ(Ω, m)

SR,q[ρ] = SR,q[UT ρ]

In the case of the classical deﬁnition of the R´enyi entropy, when the mea-
sure space is discrete and the measure m is the counting measure, the group
Γ(Ω, m) is the group generated by permutations of ﬁnite subsets of elements of
Ω. Clearly, from Eq.(17), SR,q[ρ] is invariant under permutations. This prop-
erty was one of the axioms in the axiomatic deﬁnitions of the classical R´enyi
entropy.
We denote by Γ(Ωj , mj)
the group of measures preserving transformations
of the measure space (Ωj , Aj, mj) from the decomposition of (Ω, A, m) from
Eqs.(85 -88). Then we have the following

25

Proposition 16 The GRE S(1)
q [ρ], deﬁned by Eqs.(95, 101), is invari-
ant under the sub group Γ(Ω1 , m1) × Γ(Ω2 , m2) × ... × Γ(ΩN , mN ) of the full
group Γ(Ω, m). Let Tk be a transformation of the space Ωk that preserves the
measure mk. In other words Tk ∈ Γ(Ωk , mk). Deﬁne

p [ρ], S(2)

ρ′(x1, ..., xN ) := ρ [T1(x1), ..., TN (xN )]

Then we have the invariance properties

S(1)
p [ρ] = S(1)
S(2)
q [ρ] = S(2)

p [ρ′]
q [ρ′]

with S(1)

p [ρ], S(2)

q [ρ] deﬁned in Eqs.(95, 101).

Fore more details on the symmetry properties of GRE with respect to mea-

sure preserving transformations, see ref. [16], [13].

3.3.4 Geometric properties

Beyond the physical applications, the previous geometric deﬁnitions of the R´enyi
entropy and GRE are more advantageous; in our approach the basic objects are
the norms deﬁned in Eqs.(90-94) or pseudo-norms deﬁned in Eqs.(96 -100). In
the case when pk ≥ 1, p = {p1, ..., pN }, (see [30]) the norm k.kp has the usual
properties: for a ∈ R we have kaρkp,m = |a| kρkp,m, respectively [30]

kρ1 + ρ2kp,m ≤ kρ1kp,m + kρ2kp,m

(149)

In particular, it follows the convexity of the mapping ρ → kρkp : for 0 ≤ α ≤ 1
we have

kαρ1 + (1 − α) ρ2kp,m ≤ α kρ1kp,m + (1 − α) kρ2kp,m

(150)
In the case 0 < qk ≤ 1, q = {q1, ..., qN }, the properties of the pseudo-norms
N [ρ]q,m deﬁned in Eqs.(96 -100) also allows geometrical interpretations. We
have

Nq,m[ρ1 + ρ2] ≤ N [ρ1]q,m + N [ρ2]q,m

(151)

This can be proven recursively by using the deﬁnition and the simple inequality
|x + y|q ≤ |x|q + |y|q, with 0 < q ≤ 1. Instead of convexity we have the following
concavity inequality in the ﬁrst octant only (ρ1,2 ≥ 0)

Nq,m[αρ1 + (1 − α) ρ2] ≥ αNq,m[ρ1] + (1 − α)Nq,m[ρ2]

(152)

The Eq.(152) can be proven recursively by using the concavity of the function
f (x) := xq with 0 < q ≤ 1.

By deﬁning, the distance function between distribution functions ρ1 and ρ2
in the inﬁnite dimensional space of PDF’s by d(ρ1, ρ2) := kρ1 − ρ2kp for pk ≥ 1
and d(ρ1, ρ2) := Nq,m[ρ1 − ρ2] for 0 < qk ≤ 1, respectively, we have the triangle
inequality

d(ρ1, ρ3) ≤ d(ρ1, ρ2) + d(ρ2, ρ3)

(153)

allowing the geometrical interpretation of GRE in term of distance in the func-
tional space of admissible PDF’s. The more general functional Dp,m(ρ) is ex-
posed in Appendix, subsection 5.3

26

3.4 Bound and stability properties of GRE.

By the results and notations from subsection 5.4.3, the problem of boundednes
of GRE can be treated directly.
In the following we consider, according to
the notations from subsection 3.2, the measure space (Ω, A, m) Eq.(87, 88) and
probability measure dP (x) = ρdm from Eq.(89). Consider the set of exponents
(q1, ..., qN ) := q the associated functional Nq,m from Eq.(100) and the hyper
rectangle DN ⊂ RN deﬁned in Eq.(294), Appendix 5.4.3 and suppose, for tech-
nical reasons, that we are in the generic case: DN has non zero volume. Suppose
in the continuation that at least one of the vertices of the hyper rectangle DN
contains the point qi = 1; 1 ≤ i ≤ N , and denote this point by u. Due to the
normalization condition PDF we have Nu,m(ρ) = 1, so it is plausible to suppose
that the functional Nq,m is deﬁned also in some neighborhood of u = (1, ...1).
According to Theorem 31 the function q → Nq,m(ρ) is log-convex in the vari-
able q. Suppose that on the vertices of the hyper rectangle DN we have the
bounds Eqs.(295), where in our case

g(w1, ...wN ) = Nw,m(ρ)

(154)

Then, according to the Corollary 34, we have the bounds Eq.(303) (with the
notations in subsection 5.4.3, Eqs.(296-301, 302)

log Nw,m(ρ) ≤ bN (w); w ∈ DN

(155)

Denote by VN the set of vertices of the hyper rectangle DN and by V ′
N the set
of vertices excepting the vertex u = (1, ...1). Consider the exact PDF ρ(x) and
the approximating sequence ρn(x)

ZΩ

dm(x) |ρn(x) − ρ(x)| dm(x) ≤ εn →

n→∞

0

(156)

or, equivalently, (Eqs. 96-100)

Nu,m(ρn − ρ) ≤ εn →

n→∞

0

Suppose that on the rest of the vertices v ∈ V ′

N we have the bounds

Nv,m(ρn) ≤ B; v ∈ V ′
N
Nv,m(ρ) ≤ B; ; v ∈ V ′
N

(157)

(158)
(159)

where B is a constant. Denote by D′
Int (DN ), the set of interior points of DN , deﬁned by Int(DN ) := {w|a(1)
wk < a(2)
k
The following stability result will be proved:

N the subset of the hyper rectangle the set
k <
N is non void.

; k = 1, N }. By our previous technical assumption, D′

27

Proposition 17 Under previous conditions Eqs.(156 -159) for all w ∈D′
have

N we

Nw,m(ρn) →

Nw,m(ρ)

n→∞
q [ρn, m] →
n→∞

S(2)

S(2)

q [ρ, m]

(160)

(161)

Proof. The bounds from Eqs.(158, 159) can be translated in terms of distances
Dp,m [ρ], by using Eqs.(117 -123) :

Dv,m(ρn) ≤ B′; v ∈ V ′
N
Dv,m(ρ) ≤ B′; v ∈ V ′
N

B′ = max
v∈V ′

N(cid:16)Bi(v1)(cid:17)

(162)

(163)

From Eqs.(115, 162, 163) results

Dv,m(ρn − ρ) ≤ 2B′; v ∈ V ′
N

(164)

This set of bounds we rewrite again in the term of Nw,m, by using Eqs.(117-123):

Nv,m(ρn − ρ) ≤ B”; v ∈ V ′
N

(165)

B” = max
v∈V ′
N

(2B′)1/i(v1)

Now we have bounds on all of the vertices of DN and we can use Corrolary 34
and Eq.(302) with g(w) = Nw,m(ρn − ρ). We get:

log Nw,m(ρn − ρ) ≤ bN (w); w ∈ D′

N = Int(DN )

bN (w) := Xv∈VN

P (v, w) log A′

v

0 < P (v, w) < 1; w ∈ D′
N

Because VN = V ′

N ∪ {u} the Eq.(167) can be rewritten as follows

bN (w) = Xv∈VN

Pv(w) log Av

0 < Pv(w) < 1; w ∈ D′
N

(166)

(167)

(168)

(169)

(170)

and Av are the bounds on g(w) on the vertices VN . By using Eqs.(157, 165) we
rewrite Eq.(169) as follows

log Nw,m(ρn − ρ) ≤ bN (w) = Pu(w) log εn + K(w); w ∈ D′
N

K(w) = Xv∈V ′

N

Pv(w) log B′′

28

(171)

(172)

From Eqs.(156, 170-172) results

Nw,m(ρn − ρ) →

n→∞

0; w ∈ D′
N

By using Eqs.(117, 123)

Dw,m(ρn − ρ) →

n→∞

0; w ∈ D′
N

From Eq.(116) we obtain

|Dw,m(ρn) − Dw,m(ρ)| ≤ Dw,m(ρn − ρ) →

n→∞

0; w ∈ D′
N

and using again Eqs.(117, 123) we ﬁnd the requested stability results

Dw,m(ρn) →

n→∞
Nw,m(ρn) →

n→∞

Dw,m(ρ); w ∈ D′
N
Nw,m(ρ); w ∈ D′
N

and from Eq.(124) and normalization of the PDF’s ρ, ρn

S(2)

w [ρn, m] →
n→∞

S(2)
w [ρn, m]; w ∈ D′
N

which completes the proof.

Remark 18 Note that it is possible the extend the proof to the case when the
volume of DN is zero, or to extend the stability proof to the part of boundary of
DN , where Pu(w) > 0.

4 Conclusions

We proved that, in the general case of measure spaces, the entropies deﬁned
by C. Tsallis (TE), A. R´enyi (RE) as well as the generalized R´enyi’s entropy
(GRE), are well deﬁned concepts and can be computed in a numerically stable
manner for a large range of parameters, if a stabilizing condition is imposed.
However, for the case of Shannon-Boltzmann’s entropy (BSE) two stabilizing
conditions are necessary. In all cases the stabilizing conditions are expressed
in the term of ﬁniteness of Lebesgue space Lp norm of the probability density
functions. As a mathematical by-product, we proved the logarithmic convexity
of the integrals related to generalized Lebesgue space norms.

Acknowledgement 19 The authors are grateful to Prof. M. Van Schoor and
Dr D. Van Eester from Royal Military School, Brussels. Gy. Steinbrecher
is grateful to Prof. S. Ciulli, University Montpelier, G. Nenciu, Institute of
Mathematics ”Simion Stoilow” of the Romanian Academy, I. Sabba S¸tef˜anescu,
University Karlsruhe and C. Pomponiu for useful discussions. Giorgio Sonnino
is also grateful to Prof. P. Nardone and Dr. P. Peeters of the Universit´e Libre
de Bruxelles (ULB) for useful discussions and suggestions.

29

5 Appendix

5.1 Analytic extrapolation theorem.

For easy reference, we shall prove in a special case the following theorem [24],
[25], [26]. Denote by D the domain in the complex plain C deﬁned as follows

D = {z|z ∈ C, 0 < Im(z) < b, a1 < Re(z) < a2}

(173)

The boundary of the domain is ∂D = Γ0 ∪ Γ2 ∪ Γ2 ∪ Γ3 where

Γ0 = {z|z ∈ C, Im(z) = 0, a1 < Re(z) < a2}
Γ1 = {z|z ∈ C, b ≥ Im(z) ≥ 0, Re(z) = a1}
Γ2 = {z|z ∈ C, b ≥ Im(z) ≥ 0, Re(z) = a2}
Γ3 = {z|z ∈ C, Im(z) = b, a1 < Re(z) < a2}

Denote by Kε the family of analytic functions in D, such that for all f (z) ∈ Kε
we have

|f (z)| ≤ ε; z ∈ Γ0
|f (z)| ≤ m; z ∈ Γ1 ∪ Γ2 ∪ Γ3

(174)

(175)

We shall prove the following theorem

Theorem 20 Let z0 ∈ D and the constant m ﬁxed. Under the previous con-
ditions Eqs.(174, 175), for ﬁxed m and for all f (z) ∈ Kε we have

where δ(ε) does not depend on f and

|f (z0)| ≤ δ(ε)

δ(ε) = 0

lim
ε→0

(176)

(177)

Proof. Denote by Γm := Γ1∪Γ2∪Γ3 and by u0(z), u1(z) the harmonic functions
in D with the following Dirichlet boundary conditions.

u0(z) = 1; z ∈ Γ0
u0(z) = 0; z ∈ Γm
u1(z) = 1; z ∈ Γm
u1(z) = 0; z ∈ Γ0

(178)
(179)

(180)
(181)

According to the standard terminology [37], [38], [27] the function u0(z) is the
harmonic measure of the subset Γ0 while u1(z) is the harmonic measure of Γm.
We remark that

0 < uk(z0) < 1; k = 0, 1

(182)

with strict inequalities, because z0 is an interior point. This property is a conse-
quence of the interpretation of uk(z0) as hitting probability of planar Brownian

30

motion [38]. These inequalities has also obvious physical meaning in the case
when uk(z) are stationary temperature ﬁelds. Denote

Uε(z) := u0(z) log ε + u1(z) log m

(183)

Also denote by Vε(z) the real harmonic conjugate of Uε(z), such that the func-
tion

is an analytic function in D. Denote

Kε(z) := Uε(z) + iVε(z)

Cε(z) := exp Kε(z)

(184)

(185)

From Eqs.(178-185) we have that Cε(z) is analytic, without zeroes in D and
have the following properties

|Cε(z)| = ε; z ∈ Γ0
|Cε(z)| = m; z ∈ Γm
Cε(z0) = 0; z0 ∈ D

lim
e→0

G(z) := f (z)/Cε(z)

(186)

(187)
(188)

(189)

The function

is analytic in D and from Eqs.(174, 175, 186, 187) we have that |G(z)| ≤ 1 for
all z ∈ ∂D. From the maximum modulus principle [19] we get

|G(z)| ≤ 1; ∀z ∈ ∂D ∪ D

(190)

By denoting δ(ε) := Cε(z0), from Eqs.(189, 190) we have that |f (z0| ≤ δ(ε),
which according to Eq.(188) completes the proof.

5.2 Some convergence results

5.2.1 Discrete case, counterexample 1, subsection 2.2.2

Proof of the inequalities (47, 50)
It is suﬃciently to prove Eq.(50), the
convergence in Eq.(47) results by comparison: Kn < K. Because in Eq.(50) the
sequence of pk is monotone decreasing, we use the integral criteria: we have to
prove that

K < lim
N→∞

N

Z0

dk

1

(k + 4) [log (k + 4)]2 < M

for some M > 0. By change of variable

k = exp(x) − 4

31

(191)

(192)

the Eq.(191) is reduced to the obvious bound for N large

log(N +4)

Zlog(4)

dx
x2 < M

In conclusion M = 1/ log(4) and

Kn < K < M

(193)

By considering only the ﬁrst term in the inﬁnite sum, we also obtain from
Eq.(47),

1

5[log(5)]2+1/n < Kn

(194)

(195)

(196)

(197)

(198)

Proof of Eq.(52) We use Eqs.(43, 46, 47)

Scl[p(n)] = A(n) + B(n) + C(n)

A(n) :=

∞

Xk=1

B(n) := (2 +

C(n) :=

∞

Xk=1

p(n)
k

log Kn

1
n

)

∞

Xk=1

p(n)
k

log log(k + 4)

p(n)
k

log(k + 4)

From Eq.(44) we have A(n) = log Kn and from Eq.(193, 194) we get

− log[5(log(5))2+1/n] < A(n) ≤ log M

(199)

We will denote by C1,2,.. some ﬁxed constants, that do not depend on n. From
Eqs.(194, 197) we have

B(n) < C1

∞

Xk=1

1

(k + 4) [log (k + 4)]2 log log(k + 4)

(200)

Let N such that for all k ≥ N − 1 the summand in Eq.(200) is monotone
decreasing. We obtain

B(n) < C2 + C1

∞

Xk=N

1

(k + 4) [log (k + 4)]2 log log(k + 4)

(201)

32

In order to prove that the inﬁnite sum in Eq.(201) is convergent we use the
integral criteria and the change of variable Eq.(192)

B(n) < C2 + C1

= C2 + C1

∞

ZN −1
Zlog(4)

∞

dk

1

(k + 4) [log (k + 4)]2 log log(k + 4) <

dx

log(x)
x2 < +∞

(202)

(203)

In conclusion we ﬁnd that B(n) is uniformly bounded. The summand in Eq.(198)
is monotone, so by the integral criteria we ﬁnd

∞

Z0

dk

1

(k + 4) [log (k + 4)]1+1/n < C(n) <

∞

Z1

dk

1

(k + 4) [log (k + 4)]1+1/n (204)

We use again Eq.(192) and we get

n log(4) < C(n) < n log(5)

that together to Eqs.(195, 199, 203) prove Eq.(52)

5.2.2 Proof of the results from Counter Example 2, subsection 2.2.2

In the following we shall estimate, or explicitly compute, the integrals by using
the substitution

x = exp(−t)

(205)

The normalization constants Mn, M from Eqs(53-56) can be computed exactly
by using Eq.(205)

M −1

n =

M −1 =

α − 1h(log 2)1−α − (log n)1−αi ; n > 2

1

1

(log 2)1−α

α − 1

(206)

(207)

It follows that Mn → M , ρn, ρ ∈ L1, kρnkL1 = kρkL1 = 1 and by simple
calculations and Eq.(205) results

In order to prove Eq.(57) it is suﬃcient to prove that for 0 < p < 1

1/2

Z1/n

|Mn − M |dx

x(cid:0)log 1

x(cid:1)α → 0

dx < ∞

kρn − ρkL1 =

1/n

Z0

M dx

x(cid:1)α +
x(cid:0)log 1
x(cid:1)α#p
x(cid:0)log 1

1

33

1/2

Z0

"

resulting from the inequality log 1/x > log 1/2, for 0 < x < 1/2, or by direct
calculation by using Eq.(205).

In order to prove Eq.(59) we denote

f (x) :=

1

x(cid:1)α
x(cid:0)log 1

and from Eqs.(3, 53, 54, 208) we obtain

Scl(ρn) = − log Mn − MnIn

1/2

In =

Z1/n

f (x) log f (x) dx

We use Eqs.(205, 208) so the last integral is rewritten as follows

In =

log n

Zlog 2

dt
tα (t − α log t)

(208)

(209)

(210)

(211)

In the range 1 < α < 2 the integral

term for n → ∞ is given by

∞

Rlog 2

dt
tα log t is convergent, so the leading

In ≍

1

2 − α

[log n]2−α

that proves Eq.(59)

5.3 Class of metric vector spaces and the functional Dp,m[f ],

associated to GRE

We expose here a formalism in order to have a clear control on the pseudo-norms
in the case of arbitrary number of variables. The notation from Eq.(6) will
be used in continuation. In analogy to the compact notation for the pseudo-
norm deﬁned in the case of single variables Eq.(7), we present here another,
equivalent, deﬁnition with Eqs.(109-113) of the functional Dp,m[f ]. We have
in mind the measure space (Ω, A, m) and a function f (x1, x2, ..., xN ) similar to
PDF ρ(x1, x2, ..., xN ) with the structure speciﬁed in Eqs (85-89). We use the
following

Deﬁnition 21 Let E a Metric Vector Space (MVS) with a real-valued metric
(distance to origin) δ : E → R+ such that for x, y ∈ E the distance is d(x, y) :=
δ(x − y) . The function E (cid:127) v → δ(v) ∈ R+ is called pseudo-norm, if it satisfy

34

the triangle inequality and it is homogenous with degree s

δ(u + v) ≤ δ(u) + δ(v)

δ(αv) = |α|s δ(v);

0 < s ≤ 1

δ(v) = 0 ⇒ v = 0

(212)
(213)

(214)
(215)

This metric vector space E with pseudo-norm δ will be denoted (E, δ).

Recall that in the case of norms in general we have s = 1 and in the case of

pseudo norms N p,m(ρ) from Eq.(100) s =

qk < 1. In the case of distance

N

Qk=1

N

Qk=1

deﬁned previously in Eqs.(7, 113) s =

ki(pk) < 1 (see below). Note that

s ≤ 1 results from Eqs.(212, 213). If s < 0, then δ( 1
n → ∞, and if s = 0 then δ( 1
discontinuous near v = 0.

n v) = n−s δ(v) → ∞ for
n v) = δ(v). So in both cases the distance is

Remark 22 From Eq.(212) follows the useful inequality

|δ(u) − δ(v)| ≤ δ(u − v)

(216)

We can deﬁne the convergence of a sequence of vectors un to u in E by the
distance: δ(un − u) → 0. Then Eq.(216) means that the function u → δ(u) is
continuous: un → u ⇒ δ(un) → d(u).

5.3.1 The space Lp(Ω, m, E, d) and the functional Dp,m,E(f ).

In order to obtain an equivalent deﬁnition of Dp,m [f ], from Eq.(113) we extend
the deﬁnition of Eq.(7) in such a manner that the properties Eq. (6-11) of the
pseudo-norm are preserved. We have the following

Deﬁnition 23 Denote by Lp(Ω, m, F, δ) the vector space of all functions de-
ﬁned on the measure space (Ω, A, m) with values in the MVS (F, δ)

f : Ω → F

(217)

such that

Dp,m,F (f ) :=
ZΩ

[δ [f (x)]]p dm(x)


where δ is a pseudo-norm with homogeneity degree s.

i(p)

< ∞

(218)

We observe that in Eq.(218) can be obtained from Eq.(7) by performing the

change

|f | → δ(f )

From Eqs.(212, 213 218) we have the following

35

Proposition 24 The functional Dp,m,F (f ) from Eq.(218)
is a pseudo-norm
(see deﬁnition 21) and it is homogenous with degree σ = spi(p) where s is the
homogeneity degree of the pseudo-norm δ(.).

Proof. The homogeneity results directly from Eqs.(213, 218). From Eqs.(212,
218) we get

Dp,m,F (f + g) ≤
ZΩ

[δ [f ] + δ [g]]p dm(x)


i(p)

(219)

In the case 0 < p < 1, we have i(p) = 1 and by using the inequality (|a|+|b|)p ≤
|a|p + |b|p we obtain

Dp,m,F (f + g) ≤ Dp,m,F (f ) + Dp,m,F (g)

(220)

In the case p ≥ 1 Eq.(220) results from Minkowski inequality for Lp space norms

Note that according to Remark 22, we have

|Dp,m,F (f ) − Dp,m,F (g)| ≤ Dp,m,F (f − g)

(221)

5.3.2 Proof of the Proposition 14

The proof is by backward induction, in close analogy to the recurrent deﬁni-
tion Eq.(109-113). At each step we deﬁne, according to Deﬁnition 23, a MVS
(Ek, ∆k). We shall denote by σk the homogeneity degree of the pseudo-norm
∆k. In the ﬁrst step we set in Deﬁnition 23 Ω = ΩN , m = mN , p = pN , F = R,
δ(.) = |.|. Deﬁne the corresponding MVS (EN , ∆N ) as follows

EN = LpN (ΩN , mN , R, |

∆N (fN ) =
ZΩN

|fN |pN dmN


|) = LpN (ΩN , mN )
i(pN )

; fN ∈ EN

(222)

(223)

Note that, at this stage, (EN , ∆N ) is the standard Lp MVS. We get the same
conclusion by the Proposition 24: ∆N is a pseudo-norm (for pN ≥ 1 it is the
standard Lp norm), homogenous with degree σN = pN i(pN ).
In the second step, for the sake of clarity, we repeat the previous construction:
we set in Deﬁnition 23 Ω = ΩN −1, m = mN −1, p = pN −1, but we select,
F = EN , δ(.) = ∆N (.) from Eqs.(222, 223). Deﬁne the corresponding MVS
(EN −1, ∆N −1) as follows.

EN −1 = LpN −1(ΩN −1, mN −1, EN , ∆N )

(224)

∆N −1(fN −1) =
 ZΩN −1

i(pN −1)

[∆N (fN −1)]pN −1 dmN −1


; fN −1 ∈ EN −1 (225)

36

By Proposition 24, ∆N −1 is a pseudo-norm with σN −1 = pN −1i(pN −1) σN , so
EN −1 is a MVS.

Now we proceed to the induction step. Consider that it is proven that ∆k
is a MVS, with

is a pseudo-norm with homogeneity degree σk and (Ek, ∆k)
the structure:

Ek = Lpk (Ωk, mk, Ek+1, ∆k+1)

∆k(fk) =
ZΩk

[∆k+1(fk)]pk dmk


i(pk)

(226)

(227)

; fk ∈ Ek

according to the induction hypothesis. We construct again the MVS (Ek−1, ∆k−1)
: we set in Deﬁnition 23 Ω = Ωk−1, m = mk−1, p = pk−1, and we select,
F = Ek, δ(.) = ∆k(.) from Eqs.(226, 227). We obtain

Ek−1 = Lpk−1 (Ωk−1, mk−1, Ek, ∆k)

(228)

∆k−1(fk−1) =
 ZΩk−1

[∆k(fk−1)]pk−1 dmk−1


i(pk−1)

; fk−1 ∈ Ek−1

(229)

By Proposition 24 ∆k−1 is a pseudo-norm with σk−1 = pk−1i(pk−1) σk, so
Ek−1 is a MVS, that completes the induction step. The ﬁnal MVS is E1 =
Lp1(Ω1, m1, E2, ∆2)

By continuing this procedure down to k = 1 we obtain the pseudo-norm

∆1(f1) ≡ Dp,m [fN ] with σ1 =

N

Qk=1

pki(pk) that completes the proof.

5.4

Logarithmic convexity related to the R´enyi and gen-
eralized R´enyi entropies

Typical examples of log-convex functions are the integrals that deﬁne the Lp
norms as functions of the exponent p. Consequently, many of the properties of
the Tsallis and R´enyi, as well as the generalized R´enyi entropies can be derived
from the properties of log-convex functions. We mention that in the case of
single variable all of the results can be reduced to the well known facts [21].
Nevertheless we give here an self-contained treatment including also the case of
single variable, because only our approach can be extended to the case of many
variables. We have the following general

Deﬁnition 25 A non-negative real valued function g(w) = g(w1, ..., wn), de-
ﬁned in the vector space Rn is log-convex if all of the one variable functions
wk → log g(a1, ..ak−1, wk, ak+1, ..., an) are convex functions. Equivalently, every
log-convex function can be represented as exp k(w1, ..., wn) where k(w1, ..., wn)
is a convex function separately in each of the variables, not necessary in the
ensemble of all of the variables.

37

We emphasize that the deﬁnition for many variables is adapted to our prob-

lem and it might diﬀer from deﬁnitions in the standard textbooks.

5.4.1 Single variable

This part is used for the proof of results related to R´enyi and Tsallis entropies,
and it is the starting point for higher dimensional generalizations.

For a function of a single variable g(w) that has continuos second derivative

a necessary and suﬃcient condition for log-convexity is

d2
dw2 log g(w) =

g(w)g′′(w) − g′(w)2

g2(w)

≥ 0

(230)

The most important fact is the following well known interpolation property [21].
For easy reference, we give an elementary treatment

Proposition 26 Let w → g(w) be a non-negative function of real variable w,
deﬁned at least on the interval [a, b]. If g(w) is log-convex and

then for all w ∈ [a, b] we have the bound

g(a) ≤ A; g(b) ≤ B

g(w) ≤ A

b−w

b−a B

w−a
b−a

Proof. The function k(w) = log f (w) is convex, so

(231)

(232)

k(αa + (1 − α)b) ≤ αk(a) + (1 − α)k(b)

(233)

where 0 ≤ α ≤ 1. Take α = (b − w)/(b − a) and from Eq.(233) results

log g(w) = k(w) ≤

b − w
b − a

k(a) +

w − a
b − a

k(b)

that with Eq.(231) results to be

log g(w) = k(w) ≤

b − w
b − a

log A +

w − a
b − a

log B

that completes the proof.
We have the following

Proposition 27 Consider in the measure space (Ω, A, m) the family of func-
tions f (x, w), such that for every ﬁxed value of the variable x = x0 ∈ Ω the one
variable function w → f (x0, w) is log-convex (consequently f (x0, w) > 0), for
each ﬁxed value of the variable w = w0, the function x → f (x, w0) is integrable
with respect to measure dm(x) and the function g(w)

g(w) :=ZΩ

dm(x)f (x, w)

(234)

has second derivative. Then g(w) is log-convex. Equivalently, linear combina-
tion with non negative coeﬃcients of log-convex functions is log-convex too

38

Proof. From the log-convexity of f (x0, w) results that for some function
k(x, w), which is convex in the variable w, we have

f (x, w) = exp k(x, w)

According to Eq.(230) we have to prove

g(w)g′′(w) − g′2(w) ≥ 0

From Eqs.(234, 235, 236) results

(235)

(236)

dm(x)

∂k
∂w

exp k(x, w)(cid:21)2

≥ 0

g(w)ZΩ

dm(x)( ∂2k

∂w2 +(cid:20) ∂k

∂w(cid:21)2) exp k(x, w) −(cid:20)ZΩ

(237)
The ﬁrst term in Eq.(237) is always positive, since k(x, w) is convex in the

variable w. For ﬁxed w we deﬁne a new probability measure (RΩ dP (x) = 1)

and introduce a new notation h(x)

dP (x) := dm(x)

exp k(x, w)

g(w)

h(x) :=

∂k(x, w)

∂w

(238)

(239)

By using the notations Eqs.(238, 239) and ∂2k
∂w2 ≥ 0, the proof is reduced to
the well known inequality between mean value and mean square value of the
random variable h(x)

ZΩ

dP (x) [h(x)]2 −(cid:20)ZΩ

dP (x)h(x)(cid:21)2

≥ 0

(240)

that that proves Eq.(237).

Corollary 28 Consider a measure space (Ω, A, m) and the real valued function
φ(y) deﬁned on Ω, such that the function

g(w) :=ZΩ

|φ(x)|w dm(x)

(241)

is ﬁnite on some interval a ≤ w ≤ b. Then g(w) is log-convex.

Proof. It follows from the previous Proposition 27 with f (x, w) = |φ(x)|w that
is clearly log-convex.

From Corollary 28 and Proposition 26 it follows the following result. It can
be deduced from known properties of the Lp norm in the case 1 ≤ p < q, or
from the Hadamard three line theorem [21].

39

Theorem 29 Suppose that φ(x) ∈ Lp(Ω, m) ∩ Lq(Ω, m) with 0 < p < q and

|φ(x)|p dm(x) ≤ Ap

|φ(x)|q dm(x) ≤ Aq

ZΩ
ZΩ

Then φ(x) ∈ Lr(Ω, m) with 0 < p ≤ r ≤ q and

|φ(x)|r dm(x) ≤ A

r−p
q−p

q−r
q−p
q A
p

ZΩ

(242)

(243)

(244)

Corollary 30 Under the condition of the previous theorem 29 there exists an

unique analytic function F (z) = RΩ |φ(x)|z dm(x) deﬁned in the strip p <

Re(z) < q such that

|F (x + iy)| ≤ A

x−p
q−p

q−x
q−p
q A
p

; p ≤ x ≤ q

(245)

The previous results are suﬃcient to have a simple proof of the interpolation

Lemma5
Proof. In the previous Theorem 29 we put φ(x) = f (x), p = min(1, s) and
q = max(1, s)

5.4.2 Proof of the stability of the BSE (Theorem 12)

In the ﬁrst step of the proof, we shall obtain convergence bounds on the function

RΩ |ρn(x)|r dm(x) −RΩ |ρ(x)|r dm(x) on a subset of the interval [p, q]. From the

bounds Eqs.(61-64) and triangle inequality Eq.(9), by simple algebra, we obtain
the bounds

|ρn(x) − ρ(x)|p dm(x) ≤ Bp := 2A; p < 1

|ρn(x) − ρ(x)|q dm(x) ≤ Bq := 2qA; q > 1

(246)

(247)

ZΩ
ZΩ

where Bp, Bq are constants. By using Eqs. (60, 246) and Theorem 29, with
Φ(x) = ρn(x) − ρ(x) we obtain, for all r with p ≤ r ≤ 1

|ρn(x) − ρ(x)|r dm(x) ≤ (εn)

r−p

1−p B

1−r
1−p
p

(248)

ZΩ

Similarly, from Eqs.(60, 247) and Theorem 29, for all r in the domain 1 ≤ r ≤ q
the following inequality is obtained

|ρn(x) − ρ(x)|r dm(x) ≤ B

r−1
q−1
q

q−r
q−1

(εn)

(249)

ZΩ

40

In the following we will restrict ourselves to a smaller domain: let p1 = (1 + p)/2
and q1 = (1 + q)/2. Denote

d1,n := max
r∈[p1,1]

(εn)

r−p

1−p B

1−r
1−p
p

d2,n := max
r∈[1,q1]

B

r−1
q−1
q

q−r
q−1

(εn)

(250)

(251)

and remark that from Eqs.(249, 60), for all r, in the domain p1 ≤ r ≤ 1, the
following uniform convergence is found (p1 < 1 < q1)

|ρn(x) − ρ(x)|r dm(x) ≤ d1,n →
n→∞

0

ZΩ

Denote

(252)

(253)

Gn(r) :=ZΩ

|ρn(x)|r dm(x) −ZΩ

|ρ(x)|r dm(x)

that, according to the Corollary 30, can be analytically continued to the strip
{z|p ≤ Re z ≤ q}. In the domain p1 ≤ r ≤ 1, from the inequality (10) and
Eq.(252) results for all p1 ≤ r ≤ 1

|Gn(r)| ≤ZΩ

|ρn(x) − ρ(x)|r dm(x) ≤ d1,n →
n→∞

0

(254)

In a similar manner, in the domain 1 ≤ r ≤ q1, from the inequality(10) and
Eq.(252) we have kρn − ρkr ≤ [d2,n ]1/r and from Eq.(10) we get

|kρn kr − kρkr| ≤ [d2,n]1/r →

n→∞

0

kρn kr =(cid:20)ZΩ

|ρn(x)|r dm(x)(cid:21)1/r

; r ≥ 1

(255)

(256)

We have to obtain bounds on Gn(r) on the interval 1 ≤ r ≤ q1. From Eq.(255)
results that there exists N suﬃciently large such that for all n > N we have

where we denoted

Ar ≤ kρn kr ≤ Br

Ar = kρkr − d1/r
Br = kρkr + d1/r

2,N

2,N > 0

(257)

(258)

(259)

Note that if r ≥ 1, Ar ≤ x ≤ Br, Ar ≤ y ≤ Br we have the following algebraic
inequality

|xr − yr| ≤ rBr−1

r

|x − y|

(260)

By setting x = kρkr and y = kρnkr and by using Eqs.(255, 260) and the notation
Eq.(253), we obtain, for all 1 ≤ r ≤ q1

|Gn(r)| ≤ rBr−1

r

[d2,n]1/r

(261)

41

(Hint: use the mean value theorem for the function x → xr). Combined with
Eq.(254), we obtain the following bound in the domain p1 ≤ r ≤ q1

|Gn(r)| ≤ δn

δn = max(d3,n, d1,n)

d3,n = max
1≤r≤q1

rBr−1

r

[d2,n]1/r

(262)

(263)

(264)

From Eq.(254, 255, 261-264) the following uniform convergence bound results

|Gn(r)| ≤ δn →

n→∞

0

r ∈ Γ0 := [p1, q1]

(265)

(266)

Let b := q − p > 0 and denote

Γ0 := {z|p1 ≤ Re z ≤ q1, Im z = 0}
Γ1 := {z|z = p1 + it; 0 ≤ t ≤ b}
Γ2 := {z|z = q1 + it; 0 ≤ t ≤ b}
Γ3 := {z|p1 ≤ Re z ≤ q1, Im z = b}
Γm := Γ1 ∪ Γ2 ∪ Γ3

and deﬁne the domain D := {z|p1 < Re z < q1,
0 < Im z < b} that is
contained in the domain of holomorphy of Gn. Now we prepare to use the
previous extrapolation Theorem 20. According to the Corollary 30 Gn(r) can
be analitically continued to the strip {z|p ≤ Re z ≤ q}. From Eqs.(67, 68, 8) we
get

|Gn(z)| ≤ m = 2A; z ∈ D ∪ Γ0 ∪ Γm

(267)

Similarly to the proof of the Proposition 11, consider now a circle C with the
center at z = 1 and having radius R = min((1 − p1)/2, (q1 − 1)/2). From
Eqs.(253, 71) we obtain

dz

Scl[ρ] = −(cid:20) d
F (z) :=ZΩ

F (z)(cid:21)z=1

= −

1

2πiIC

F (w)dw
(w − 1)2

|ρ(x)|z dm(x)

and ﬁnally results

Scl[ρn] − Scl[ρ] = −

1

2πiIC

Gn(w)dw
(w − 1)2

It is clear that the convergence of the classical entropy is controlled by

|Scl[ρn] − Scl[ρ]| ≤

1
R

max
w∈C

|Gn(w)|

42

(268)

(269)

Now we use the Theorem 20, with the input data given in Eqs.(265, 266, 267).
Then for all w in the half circle in the upper complex half plane we have

|Gn(w)| ≤ K exp[log(δn) u0(w)]; |w − 1| = R; Im(w) ≥ 0

(270)

where the harmonic function u0(w) was deﬁned by Eqs.(178, 179), and K is a
constant. Since Gn(w) is real in the real axis, the previous Eq.(270) extends
also in the lower semicircle. Since in the interior of the domain D the harmonic
measure u0(w) is strictly positive, we have Gn(w) → 0. From compactness of
the circle, the uniform convergence max
|Gn(w)| → 0 is ensured, and ﬁnally we
w∈C

obtain that |Scl[ρn] − Scl[ρ]| →

n→∞

0, which completes the proof.

5.4.3 Logarithmic convexity properties and bounds in the case of

many variables.

Our deﬁnition of the log-convexity, in the case of many variables, diﬀers from
the usual deﬁnition: In the generalization to many variables we shall restrict
our study to the case when a function of N variables is log-convex in one of
variables while the remaining N − 1 are ﬁxed. Typical example of interest is
the nested integral that appear in the deﬁnition of the GRE. We will study the
function of many variables w = (w1,w2, ..., wN ), that is deﬁned recurrently in
Eqs.(96-100). We set

g(w1,w2, ..., wN ) := Nw,m[ρ]

(271)

By using the previous Corollary 28 it is clear that for ﬁxed w(0)
function w → g(w, w(0)
general result

N , the
N ) is log-convex. We have the following more

2 , ..., w(0)

2 , ..., w(0)

Theorem 31 For all 1 ≤ k ≤ N , for ﬁxed w(0)
N = qN , the function w → g(w(0)
qk+1, ..., w(0)
h(w) is log-convex in the variable w.

k−1, w, w(0)

1 = q1, ..., w(0)
1 , ..., w(0)

k−1 = qk−1, w(0)
k+1, ..., w(0)

k+1 =
N ) :=

43

Proof. The proof is by induction. We rewrite the part of interest from the
reccurence relations Eqs.(96-100) as follows

ρ′

k(x1, x2, ..., xk) :=ZΩk (cid:2)ρ′
k−1(w, x1, x2, ..., xk−1) :=ZΩk
k−2(w, x1, x2, ..., xk−2) :=ZΩk

[ρ′

[ρ′

ρ′

ρ′

k+1 (x1, ..., xk+1)(cid:3)qk+1 dmk+1(xk+1)

k (x1, ..., xk)]w dmk(xk)

k (x1, ..., xk)]qk−1 dmk(xk)

...

ρ′

1 (w, x1) :=ZΩ2
h(w) :=ZΩ1

[ρ′

2 (w, x1, x2)]q2 dm2(x2)

[ρ′

1 (w, x1)]q1 dm1(x1)

(272)

(273)

(274)

(275)

(276)

(277)

From Corollary 28 results that the function ρ′
k−1(w, x1, x2, ..., xk−1), given by
Eq.(273), is log-convex in the variable w. By successive application of the Propo-
sition 27 to Eqs.(274-277) and by observing that any positive power of a log
convex function is log-convex, we conclude by induction, successively, that the
functions ρ′
1 (w, x1), h(w) are all log-convex in the
variable w.

k−2(w, x1, x2, ..., xk−2) ,..., ρ′

For the sake of clarity we consider ﬁrst the case N = 2. Suppose now that

g(w1, w2) is log-convex in the variables w1, w2, in the rectangular domain D2

(278)

(279)

(280)

(281)

(282)

a(1)
1 ≤ w1 ≤ a(2)

1 ; a(1)

2 ≤ w2 ≤ a(2)

2

and we have the following bounds in the corner points of D2

1 , a(1)
1 , a(1)
1 , a(2)
1 , a(2)

g(cid:16)a(1)
g(cid:16)a(2)
g(cid:16)a(1)
g(cid:16)a(2)

2 (cid:17) ≤ A1,1
2 (cid:17) ≤ A2,1
2 (cid:17) ≤ A1,2
2 (cid:17) ≤ A2,2

44

We denote

ρ(1)
1 (w1) =

ρ(2)
1 (w1) =

ρ(1)
2 (w2) =

ρ(2)
2 (w2) =

a(2)
1 − w1
1 − a(1)
a(2)
1
w1 − a(1)
1
1 − a(1)
a(2)
1
a(2)
2 − w2
2 − a(1)
a(2)
2
w2 − a(1)
2
a(2)
2 − a(1)

2

(283)

(284)

(285)

(286)

Remark 32 If w = {w1, w2} is an interior point of the rectangle D2 then
0 < ρ(i)(wk) < 1, for all 1 ≤ i ≤ 2 and 1 ≤ k ≤ 2

By using successively the Proposition 26, we deﬁne the following bound in
the interior point with coordinates (w1, w2), in terms of values on the corner
points of the rectangle Eq.(278):

log g(w1, w2) ≤ b2(w1, w2) := b2(w)

b2(w) = P1,1(w) log A1,1 + P1,2(w) log A1,2
+ P2,1(w) log A2,1 + P2,1(w) log A2,2

(287)

(288)

(289)

Pm1,m2(w) = Pm1,m2(w1, w2)=ρ(m1)

1

(w1)ρ(m2)

2

(w2); m1, m2 = 1, 2

(290)

From the previous remark results 0 < Pm1,m2 (w) < 1 if w is an interior point
of the rectangle D2

From Eq.(287) we obtain the following generalization of Proposition 26

Proposition 33 Suppose that we have the sequence of n functions gn(w1, w2)
that are log convex (hence non negative) in the domain Eq.(278) and on the 4
corner points we have the uniform bound

gn(a(i)

1 , a(j)

2 ) ≤ Ai,j ; i, j = 1, 2

(291)

Then in the all interior points of the rectangle Eq.(278) we have the uniform
bound

gn(w1, w2) ≤ exp b(w1, w2)

with b(w1, w2) given by Eq.(288).
(a(i0)

) we have

, a(j0)

If in at least in one of the corner points

1

2

gn(a(i0)

1

, a(j0)

2

) → 0

(292)

and in the rest of the corner points we have the uniform bound Eq.(291) then
for all interior points (w1, w2) we have also

gn(w1, w2) → 0

(293)

for all interior points in the rectangle deﬁned by Eq.(278).

45

Now we extend the previous result for arbitrary number of variables. The
relations that follows in the particular case N = 2 reduces to Eqs.(278-293).
Suppose that g(w1, w2, ..., wN ) is log-convex in the variables w1, w2, ..., wN , in
the N dimensional hyper rectangle domain DN ⊂ RN

a(1)
k ≤ wk ≤ a(2)

k

; k = 1, N

(294)

Suppose that in the 2N corner points of DN (the set of vertices VN of the
hyper-rectangle ) we have the bounds

g(a(v1)

1

, a(v2)

2

, ..., a(vN )

N ) ≤ Av1,v2,...,vN ; vj = 1, 2;

j = 1, N

(295)

or denoting v := (v1, ..., vN ) ∈ {1, 2}N , the set of vertices VN are represented as
follows: (a(v1)
N ) := a(v) ∈ VN . In analogy with Eqs.(283-286) we
introduce the following notations

, ..., a(vN )

1

, a(v2)

2

ρ(1)
k (wk) =

ρ(2)
k (wk) =

a(2)
k − wk
a(2)
k − a(1)
k
wk − a(1)
k
a(2)
k − a(1)

k

; k = 1, N

; k = 1, N

(296)

(297)

To obtain a more compact notation for the generalization of Eqs.(287-290), we
use the following new notations for the set of constants Av1,v2,...,vN

A′

v := Av1,v2,...,vN vj = 1, 2;

j = 1, N

and deﬁne the function P : VN × DN → R as follows

N

P (v, w) :=

ρ(vk)
k

(wk); vj = 1, 2;

j = 1, N

Yk=1

v := (v1, ..., vN ) ∈ {1, 2}N
w=(w1, ..., wN )

By Remark 32 we have

0 < P (v, w) < 1; w ∈ Int(DN ); v ∈ VN

(298)

(299)

(300)

(301)

(302)

k < wk <
; k = 1, N . By using successively the Proposition 26, with the notations

where the set of interior points Int(DN ) ⊂ DN is deﬁned by a(1)
a(2)
k
Eqs.(298-301) the following bounds results

Corollary 34 If the function w → g(w) is log-convex, then under previous
conditions Eqs.(295-297) we have the bound in the hyper-rectangle DN

where we denote

log g(w1, w2, ..., wN ) ≤ bN (w)

bN (w) := Xv∈VN

P (v, w) log A′

v

46

(303)

(304)

Remark 35 It can be proven that Pv∈VN

P (v, w) = 1

References

[1] C. E. Shannon, A Mathematical Theory of Communication, Bell System

Technical Journal, 27, 379-423 & 623-656 (1948).

[2] A. R´enyi (1960), On measures of information and entropy, Proceedings of
the fourth Berkeley Symposium on Mathematics, Statistics and Probability,
June 20-July 30, 1960, Volume I, University of California Press, Berkeley
and Los Angeles, 547-561 1960. pp. 547–561.

[3] A. R´enyi, Wahrscheinlichkeitstheorie (De Gruyter, Berlin, 1974).

[4] A. R´enyi, On statistical

laws of accumulation of information, in R´enyi
Alfr´ed V´alogatott Munk´ai (A. R´enyi Selected works), volume 3, 1962-1970,
Akad´emiai Kiad´o, Budapest 1977, page 33.

[5] A. R´enyi, Rev. Int. Inst. Stat., 33, 1-14 (1965).

[6] C. Tsallis, Journal of Statistical Physics, 52, 479–487 (1988).

[7] C. Tsallis, R. S. Mendes and A. R. Plastino, Physica A, 261, 534-554

(1998).

[8] C. Tsallis, Introduction to nonextensive statistical mechanics approaching

a complex world, ( Springer, 2009).

[9] M. Gell-Mann, C. Tsallis, Nonextensive entropy- Interdisciplinary applica-

tions, (Oxford University Press, USA, 2004).

[10] G. Sonnino, G. Steinbrecher, Phys. Rev. E 89, 062106 (2014).

[11] Yu. L. Klimontovich, Chaos, Solitons, Fractals, 5, 1985-2002 (1995).

[12] I. Csisz´ar, I.E.E.E. Transactions on Information Theory, 41 -1, 26, (1995).

[13] G. Steinbrecher, G. Sonnino, ”Generalized R´enyi Entropy and Struc-
ture Detection of Complex Dynamical Systems”, arXiv:1512.06108v1
[physics.data-an] (2015).

[14] T. Maszczyk and X. Duch, Comparison of Shannon, R´enyi and Tsallis
Entropy used in Decision Trees, Lecture Notes in Computer Science, 5097,
643 (2008).

[15] T. van Erven, P. Harremo¨es, ”R´enyi Divergence and Kullback-Leibler Di-

vergence”, e-print arXive:1206.2459v2 (2014).

[16] G. Steinbrecher, A. Sonnino, G. Sonnino, Journal of Modern Physics, 7,

251-266 (2016).

47

[17] Hongfei Cui, Jianqiang Sun, Yiming Ding, The rates of convergence
for generalized entropy of the normalized sums of IID random variables,
arXiv:1106.3381v1 [cs.IT] (2011).

[18] B. Lesche, Journal of Statistical Physics, 27, 419-422, (1982).

[19] W. Rudin (1987), Real and Complex Analysis, McGraw Hill Inc. 3rd Ed.

page 74.

[20] M. Reed and B. Simon, Functional Analysis (Methods of Modern Mathe-

matical Physics). Vol. 1, Academic Press (1981).

[21] E. M. Stein, R. Shakarchi, Functional Analysis, Introduction to further
topics, Princeton Lectures in Analysis IV, Princeton Univ. Press, Princeton
(2011),page 36 exerc. 9.c. page 39 exerc. 20.

[22] M. Ciulli, S. Ciulli, Computer Physics Communications, 18, 215 (1981).

[23] I. Caprini, M. S˘araru, C. Pomponiu, M. Ciulli, S. Ciulli, I. Sabba-

S¸tef˜anescu,Computer Physics Communications 18, 305-326 (1979).

[24] S. Ciulli, Stability Problems in Analytic Continuation, Lectures given at the
1972 Int. Institute for theoretical strong interaction physics, Kaiserslautern.
Pag. 70-105, Springer Berlin Heidelberg (1973).

[25] S. Ciulli, G. Nenciu, J. Math. Phys. 14, 1675 (1973).

[26] S. Ciulli, C. Pomponiu, I. Sabba-S¸tef˜anescu, Physics Reports 17, 133-224

(1975).

[27] G. Nenciu, Lettere al Nuovo Cimento, 4, Issue 3, pp. 96-100 (1970).

[28] P. Jizba, T. Arimitsu, Phys. Rev. E 69, 026128 (2004).

[29] H. Luschgy and G. Pag`es, Electronic Communication in Probability, 13,

422-434 (2008).

[30] O. V. Besov, V. P. Il’in and S.M. Nikol’skii, Integral representations of func-
tions and embedding theorems, Ed. Nauka, pp. 9-40, Moscow (in Russian)
(1975).

[31] E. M. Stein, Singular Integrals and Diﬀerentiable Properties of Functions.

Princeton Univ. Press. (1971).

[32] G. Steinbrecher, X. Garbet and B. Weyssow, ”Large time behavior in ran-

dom multiplicative processes”, arXiv:1007.0952v1, (2010).

[33] G. Steinbrecher, B. Weyssow, Phys. Rev. Lett. 92, 12503 (2004); T. L.

Rhodes et al., Phys. Lett. A 253, 181 (1999).

[34] S. Aumaˆıtre, F. P´etr´elis and K. Mallick, Phys. Rev. Lett. 95, 064101 (2005).

48

[35] A. Chicocki, ”Tensor Networks for Big Data Analytics and Large-Scale

Optimization Problems”, arXiv:1407.3124v2 [cs.NA] (2014).

[36] P. Jizba, T. Arimitsu, Annals of Physics, 312,17–59 (2004).

[37] Rolf Nevanlinna, Analytic Functions,Springer Berlin Heidelberg, pp. 26-45

(1970).

[38] B. Oksendal, Stochastic Diﬀerential Equations, Springer, Heidelberg, NY.,

p. 117 (2000).

49

