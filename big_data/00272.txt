6
1
0
2

 
r
a

M
1

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
2
7
2
0
0

.

3
0
6
1
:
v
i
X
r
a

Stochastic systems with memory and jumps

D.R. Baños∗, F. Cordoni†, G. Di Nunno‡, L. Di Persio§, and E.E. Røse¶

March 2, 2016

Abstract

Stochastic systems with memory naturally appear in life science, economy, and ﬁnance.
We take the modeling point of view of stochastic functional delay equations and we study these
structures when the driving noises admit jumps. Our results concern existence and uniqueness
of strong solutions, estimates for the moments and the fundamental tools of calculus, such as
the Itô formula. We study the robustness of the solution to the change of noises. Speciﬁcally,
we consider the noises with inﬁnite activity jumps versus an adequately corrected Gaussian
noise. The study is presented in two diﬀerent frameworks: we work with random variables in
inﬁnite dimensions, where the values are considered either in an appropriate Lp-type space or
in the space of càdlàg paths. The choice of the value space is crucial from the modelling point
of view as the diﬀerent settings allow for the treatment of diﬀerent models of memory or delay.
Our techniques include tools of inﬁnite dimensional calculus and the stochastic calculus via
regularization.

Keywords: Stochastic delay equations, memory, jump diﬀusions, Itô formula, moment

estimates, calculus via regularization.
AMS classiﬁcation: 34K50, 60H07

1 Introduction

Delay equations are diﬀerential equations whose coeﬃcients depend also on the past history of
the solution. Besides being of mathematical interest on their own, delay equations naturally arise
in many applications, ranging from mathematical biology to mathematical ﬁnance, where often
the eﬀect of the memory or delay on the evolution of the system cannot be neglected, we refer to
[8, 9, 28, 29, 32, 33, 36, 43] and references therein for applications in diﬀerent areas.

When dealing with a delay diﬀerential equation (DDE), one cannot in general relay on standard
existence and uniqueness theorems, but ad hoc results have to be proven. In general this is done
by lifting the DDE, from having a solution with values in a ﬁnite dimensional state space, such
as Rd, to having values in an inﬁnite dimensional path space, which has to be carefully chosen
according to the speciﬁc problem. For the case of deterministic delay diﬀerential equations an
extensive literature exists, we refer the reader to the monographs [21, 24] for details.

When considering stochastic delay diﬀerential equations (SDDE), that is DDE perturbed by
a stochastic noise, one encounters problems that did not appear in the deterministic case or in

∗Institute of Mathematics of the University of Barcelona, University of Barcelona, Gran Via de les Corts Cata-
lanes 585, 08007, Barcelona, and Department of Mathematics, University of Oslo, P.O. Box 1053 Blindern, N-0316
Oslo, Norway, Email: davidru@math.uio.no

†Department of Mathematics, University of Trento, Via Sommarive, 14, 38123 Trento,

Italy.

Email:

francesco.cordoni@unitn.it

‡Department of Mathematics, University of Oslo, P.O. Box 1053 Blindern, N-0316 Oslo, Norway, and Nor-
wegian School of Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway. Email: giu-
lian@math.uio.no

§Department of Computer Science, University of Verona, Strada le Grazie, 15, 37134 Verona, Italy. Email:

luca.dipersio@univr.it

¶Department of Mathematics, University of Oslo, P.O. Box 1053 Blindern, 0316 Oslo, Norway. Email:

elinero@math.uio.no

1

classical stochastic diﬀerential equations.
In particular the SDDE fails to satisfy the Markov
property, hence one cannot rely on the well established setting of Markov processes for the study
of the solution. As in the deterministic case, however, one can apply the key idea to lift the SDDE
to have values in a suitable inﬁnite dimensional path space. In doing so, one is able to recover
the Markov property, nevertheless the main drawback is that now one is dealing with an inﬁnite
dimensional stochastic partial diﬀerential equation (SPDE). Although a well established theory for
SPDE’s exists, some fundamental results, known in the ﬁnite dimensional case, fail to hold true in
the inﬁnite dimension. In particular when considering inﬁnite dimensional SPDE’s, the concept
of quadratic variation is not a straightforward generalization of the classical notion of quadratic
variation. Indeed concrete results around this concept in inﬁnite dimensions have appeared only
recently, see [20]. Major consequence of this is that essential tools of stochastic analysis, such as
the Itô formula, cannot be easily derived.

SDDE’s have been ﬁrst studied in the seminal works [10, 35] and then extensively studied
in [26, 36, 44], though in a diﬀerent, but yet related setting. Recently there has been a renewed
interest in SDDE’s motivated by ﬁnancial applications. In [23] a path dependent stochastic calculus
was ﬁrst suggested and then widely developed in [12, 13].

From the stochastic calculus point of view, the recently introduced technique of regularization
has been proved to be extremely powerful to deﬁne the notion of stochastic integral and to prove
a general Itô formula for stochastic diﬀerential equation both in ﬁnite and inﬁnite dimensions.
The ﬁrst results exploiting the stochastic calculus via regularization dates back to [41, 42] where a
generalization of the Itô formula has been proved. More recently in [19] a new consistent concept
of quadratic variation for Banach space-valued processes has been proposed and applied to prove
a suitable Itô formula for inﬁnite dimensional stochastic processes. This has triggered a stream of
studies aimed at deriving a suitable Itô’s formula for delay equations and at studying deterministic
problems that can be tackled by a stochastic approach. Particular attention has been given to
the Kolmogorov equation. We refer to [14, 15, 16, 25, 26]. Eventually in [15, 25] the relationship
between the pathwise calculus and the Banach-space calculus has been detailed.

So far all the aforementioned results for delay equations are proved in the case when the driving
noise is continuous, such as for a standard Brownian motion. Very few results exist when the noise
allows for random jumps to happen, see, e.g. [39, 40].

As mentioned above, there are diﬀerent approaches to deal with SDDE’s. We work with the
setting of stochastic functional delay diﬀerential equations (SFDDE), ﬁrst introduced in [35] and
further developed in [36, 44]. This choice is motivated by the fact that it appears to be the right
compromise between a general purely inﬁnite dimensional SPDE and a classical ﬁnite dimensional
SDE. In fact, even if the stochastic delay equation is treated as an inﬁnite dimensional equation,
there is always a clear connection with its ﬁnite dimensional realizations of the delay equation, so
that standard ﬁnite dimensional Itô calculus can be often used.

The aim of the present paper is to extend the theory of SFDDE, studied in [35] for a Brownian
driving noise, to include jumps, that is to deal with noises of jump-diﬀusion type. Speciﬁcally
we aim at settling the existence and unicity of solutions, and derive the fundamental tools of
a stochastic calculus for SFDE’s with jumps. We also study the robustness of the solutions of
SFDDEs to changes of the driving noise.

In particular we consider an Rd−valued SDE of the form

dX(t) =f (t, X(t), X(t + ·))dt + g(t, X(t), X(t + ·))dW (t)

h(t, X(t), X(t + ·))(z) ˜N (dt, dz) ,

t ∈ [0, T ],

(1.1)

+ZR0

where W is a standard Brownian motion, ˜N is a compensated Poisson random measure and f , g
and h are some given suitable functional coeﬃcients. With the notation X(t + ·) we mean that
the coeﬃcient may depend also on the past values of the solution on the interval [t − r, r] for some
ﬁxed delay r > 0. It is this dependence on the past values of the evolution that is identiﬁed as
memory or, equivalently, delay. The formal introduction of the current notation will be carried

2

out in the next section. Notice that at this stage equation (1.1) is a ﬁnite dimensional SDE with
values in Rd.

We now lift the process (1.1) to have values in a suitable inﬁnite dimensional path space. The
choice of the suitable space is truly a key issue. As illustration, consider the purely diﬀusive case
and denote the maximum delay appearing in (1.1) by r > 0. Then, in [44] a product space of
the form M p := Lp([−r, 0]; Rd) × Rd, p ∈ [2, ∞), has been chosen, whereas in [36] the space of
continuous functions C := C([−r, 0]; Rd) has been taken as reference space. With the former choice
one can rely on well-established results and techniques for Lp−spaces. Nevertheless this choice
may seem artiﬁcial when dealing with a past path-dependent memory. For this reason the second
choice, the space of continuous functions, is often considered the right space where to study delay
equations, though it requires mathematically careful considerations.

The natural extension of SFDDE’s to the jump-diﬀusion case correspondingly leads to two
possible choices of setting: the product space M p and the space of càdlàg (right continuous with
ﬁnite left limit) functions D := D([−r, 0]; Rd). We decided to carry out our study in both settings
in order to give a general comprehensive and critical presentation of the when and in the what
sense it may be more suitable to treat the study in the one or the other setting. In fact, on the one
side, we have the inclusion D ⊂ M p, with the injection being continuous, so that the M p−setting
appears to be more general, on the other side we see that existence and uniqueness of the solution
of an SFDDE cannot be established in general in the space Mp. This in fact depends on the choice
of type of delay or memory. In fact the drawback of the M p approach is that it does not apply to
to SFDDE’s with discrete delay, which are equations of the form

X(t) =Z t

0

X(s + ρ)ds +Z t

0

X(s + ρ)dW (s) ,

(1.2)

where ρ ∈ [−r, 0) is a ﬁxed parameter. Certainly, the reason is that X(t+ ρ) is actually interpreted
as an evaluation of the segment Xt = {X(t + s), s ∈ [−r, 0]} at the point s = ρ. Such operation is
not well-deﬁned in the M p-setting. To see this, simply take two elements (η1, η1(0)), (η2, η2(0)) ∈
M p such that η1(s) = η2(s) for all s ∈ [−r, 0] \ {ρ} and η1(ρ) 6= η2(ρ). Then, clearly (η1, η1(0))
and (η2, η2(0)) belong to the same class in M p but the evaluation at ρ is not uniquely determined.
However, the discrete delay case can be treated in the setting given by D.

In the sequel, we thus lift equation (1.1) to have values either in M p, with p ∈ [2, ∞), or in D,

exploiting the notion of segment. We then study a SFDDE of the form,

dX(t) = f (t, Xt)dt + g(t, Xt)dW (t) +ZR0

X0 = η

h(t, Xt)(z) ˜N (dt, dz)

(1.3)

where we denote Xt the segment of the process X on an interval [t − r, t], that is

Xt := {X(t + θ) : θ ∈ [−r, 0]} ,

being r > 0 the maximum delay. By X(t) we denote the present value of the process at time t.
Also η is a function on [−r, 0].

In this paper, ﬁrst we establish existence, uniqueness and moment estimates for the equation
(1.3) where the segment Xt takes values either in M p or in D. Then we look at the robustness of
the model to changes of the noise. In particular, we study what happens if we replace the small
jumps of the inﬁnite activity Poisson random measure N , by a continuous Brownian noise B. This
is done by comparing a process X with dynamics

dX(t) = f (t, Xt)dt + g(t, Xt)dW (t) +ZR0

X0 = η,

h0(t, Xt)λ(z) ˜N (dt, dz)

(1.4)

to the process X (ǫ) deﬁned by

dX (ǫ)(t) = f (t, X (ǫ)

t )dt + g(t, X (ǫ)

t

)dW (t) + h0(t, X (ǫ)

t

)Z|z|<ǫ

|λ(z)|2ν(dz)dB(t)

3

+Z|z|>ǫ

h0(t, X (ǫ)

t

)λ(z) ˜N (dt, dz)

(1.5)

X (ǫ)

0 = η .

We remark that the choice of this approximate guarantees the same so-called total volatility, using
a terminology from ﬁnancial modelling.

Eventually, exploiting the stochastic calculus via regularization we prove an Itô type formula
for stochastic delay equations with jumps, showing that the results are in fact coherent with the
results obtained in [36, 44]. We work with forward integrals in the following sense. In general,
given the stochastic processes X = {Xs, s ∈ [0, T ]}, and Y = {Ys, s ∈ [0, T ]}, taking values in
Lp([0, T ], Rd) and its topological dual, respectively, we deﬁne the forward integral of Y against X
as

qhYs , dXsip := lim

ds ,

(1.6)

Z t

0

ǫ↓0Z t

0 (cid:28)Ys ,

Xs+ǫ − Xs

ǫ

(cid:29)p

where the limit holds in probability and we denoted by h·, ·ip the paring between Lp([−r, 0], Rd)
and its dual. Furthermore, if the above limit holds uniformly on probability on compact sets (ucp)
then we immediately have that the process

(cid:18)Z t

0

qhYs , dXsip(cid:19)t∈[0,T ]

,

admits a càdlàgversion and we will say that the forward integral exists. When the two processes
have values in the space M p and M p∗, we are able to show that the above limit holds in fact
ucp, characterizing thus the forward integral in terms of the derivative of the process X, which
coincides with the operators introduced in [44] and in [25].

The present work is structured as follows. In Section 2 we introduce the main notation used
throughout the whole paper. In Section 2.3 we study existence and uniqueness results for equation
(1.3) with values in D, whereas in Section 2.4 we prove the same results in the M p setting. Then,
in Section 2.5 we prove the robustness of equation (1.3) to the change of the noise. Eventually in
Section 3 we prove a suitable Itô-type formula for SFDDE’s with values in M p and in D.

2 Stochastic functional diﬀerential equations with jumps

2.1 Notation

Let (Ω, F , F := {Ft}t∈[0,T ], P ) be a complete, ﬁltered probability space satisfying the usual hy-
potheses for some ﬁnite time horizon T < ∞. Let r > 0 be a non-negative constant denoting the
maximum delay of the equations considered. We extend the ﬁltration by letting Fs = F0 for all
s ∈ [−r, 0]. This will still be denoted by F.

Let W = (W 1, . . . , W m)T be an m-dimensional F-adapted Brownian motion and N = (N 1, . . . , N n)T

be the jump measures associated with n independent F-adapted Lévy processes, with Lévy mea-
sures ν = (ν1, . . . , νn) respectively. We denote by ˜N , the compensated Poisson random measure

˜N (dt, dz) := (N 1(dt, dz) − ν1(dz)dt, . . . , N n(dt, dz) − νn(dz)dt)T .

Consider the equation

dX(t) = f (t, Xt)dt + g(t, Xt)dW (t) +ZR0

X0 = η,

h(t, Xt)(z) ˜N (dt, dz)

(2.1)

where f ,g and h are some given functionals on a space containing the segments Xt, t ∈ [0, T ] of the
process X. We will give precise deﬁnitions of the segments and the coeﬃcient functionals below.

4

Equations of the form (2.1) will be referred to as stochastic functional delay diﬀerential equation
(SFDDE).

We remark that equation (2.1) is to be interpreted component-wise as a system of SFDDE of

the following form:

dX i(t) = f i(t, Xt)dt +

gi,j(t, Xt)dW j (t) +

X i

0 = ηi ,

i = 1, . . . , d .

mXj=1

nXj=1ZR0

hi,j(t, Xt, z) ˜N j(dt, dz),

With the component-wise interpretation in mind, it is natural to require that the images
f (t, Xt) and g(t, Xt) of the coeﬃcient functionals f and g are contained in the spaces L2(Ω, Rd)
and L2(Ω, Rd×m) respectively. Similarily, we want the image h(t, Xt) of h to be contained in a
set of matrices with j’th column in L2(Ω, L2(νj, Rd)). To express the space of all such matrices
in a compact manner, we introduce the following notation. For the Rn-valued measure ν =
(ν1, . . . , νn)T, we will write Lp(ν) = Lp(ν, Rd×n) (p > 2), to denote the set of measurable functions

H : R0 → Rd×n,

such that

kHkp

Lp(ν) :=

nXj=1

kH ,jkp

Lp(νj ,Rd) < ∞.

(2.2)

Here we have used the notation H ,j to denote the j’th column of H. Notice also that the Bochner
space

Lq(Ω, Lp(ν, Rd×n))

(q > 2)

consists of the measurable functions H : Ω 7→ Lp(ν, Rd×n) such that

kHkq

Lp(Ω,Lp(ν,Rd×n)) := E[kHkq

Lp(ν,Rd×n)] < ∞.

(2.3)

For convenience, we will sometimes omit to explicitly specify the spaces Rd, Rd×m and Rd×n,
when it is clear from the context which space to consider and no confusion is possible. In this
paper, when no confusion will occur, the standard Euclidean norm k · kRk×l, will be denoted by
| · | for any k, l ∈ N.

Hereafter we introduce the relevant spaces we work with in the sequel. For 0 6 u 6 T , let

Du := D([−r, u], Rd),

(2.4)

denote the space of all càdlàg functions from [−r, u] to Rd, equipped with the uniform norm

kηkDu := sup

{|η(θ)|},

−r6θ6u

η ∈ Du.

(2.5)

Set D := D0. For 2 6 p < ∞, let Lp

u := Lp([−r, u], Rd) and

M p

u := Lp

u × Rd

with norm given by

Set Lp := Lp

0 and M p := M p
0 .

k(η, v)kp

M p
u

:= kηkp
Lp
u

+ |v|p,

η ∈ M p
u

We recall that the M p

u is also a Hilbert space. On
the other side Du equipped with the topology given by (2.5) is a non-separable Banach space. The

u-spaces are separable Banach spaces and M 2

5

space Du equipped with the Skorohod topology is separable metric space. Moreover, there exists
also a topology on Du, equivalent to the Skorohod topology, such that Du is a complete separable
metric space. See e.g. [7, 37].

Observe that if η ∈ D, then

k(η1[−r,0), η(0))kp

M p = kη1[−r,0)kp

Lp + |η(0)|p 6 (r + 1)kηkp
D.

(2.6)

By (2.6), and since the elements in M p have at most one càdlàgrepresentative, the linear functional

η 7→ (η1[−r,0), η(0))

is a linear continuous embedding of D into M p. Note that we will write kηkM p in place of
k(η1[−r,0), η(0))kM p .

We now introduce the notion of segment that will play an important role in this paper. For

any stochastic process Y : [−r, T ] × Ω → Rd, and each t ∈ [0, T ], we deﬁne the segments

Yt : [−r, 0] × Ω → Rd,

by Yt(θ, ω) := Y (t + θ, ω),

θ ∈ [−r, 0], ω ∈ Ω.

In view of the arguments above, if Y is a càdlàg process, we can also regard the segments Yt as
functions

Ω ∋ ω 7→ Yt(·, ω) ∈ D (or M p).

We recall the following deﬁnitions. Let G ⊆ F be a σ-algebra on Ω, containing all the P -null

sets. Let D be equipped with the σ-algebra D generated by the Skorohod topology.

Deﬁnition 2.1. We say that a function η : Ω → D is a (G-measurable) D-valued random variable
if it is G-measurable with respect to the σ-algebra D, or equivalently, if the Rd-valued function
ω 7→ η(θ, ω) is G-measurable for each θ ∈ [−r, 0].

Recall that D ( B(D), where B(D) is the Borel σ-algebra generated by the topology given by the
norm (2.5).

Deﬁnition 2.2. We say that a function (η, v) : Ω → M p is a (G-measurable) M p-valued random
variable if it is measurable with respect to the σ-algebras G and B(M p), or equivalently if the
function

ω 7→Z 0

−r

η(θ, ω)φ(θ)dθ + v(ω) · u

is G-measurable for every (φ, u) ∈ M p∗ = M

p

p−1 .

Notice also that if η is a G-measurable D-valued-random variable, then it is G-measurable as an
M p-valued random variable. Corresponding deﬁnitions apply in the cases of the Du or M p
u spaces
above.

We are now ready to introduce the spaces of measurable D-valued and M p-valued random

variables.

Recall that Du is equipped with the σ-algebra Du generated by the Skorohod topology on Du.

Let η be a Du-valued random variable. For p > 2, deﬁne

kηkp

Sp(Ω;Du) := E" sup

θ∈[−r,u]

|η(θ)|p# = E[kη(θ)kp

D],

and the equivalence relation η1 ∼ η2 ⇔ kη1 − η2kSp(Ω;Du) = 0. Let

Sp(Ω, G; Du)

6

denote the space of equivalence classes of D-valued random variables ω 7→ η(ω, ·) such that
kηkp

Sp(Ω;Du) < ∞.
For p > 2, let

Lp(Ω, G; M p

u),

denote the Bochner spaces Lp(Ω, M p
that the norm given by

u) consisting of the M p

u-valued random variables (η, v) such

k(η, v)kp

Lp(Ω;M p

u ) := E[k(η, v)kp
M p
u

]

is ﬁnite. We recall that both Sp(Ω; Du) and Lp(Ω; M p
η ∈ Sp(Ω, G; D), then

u) are Banach spaces. Observe that if

k(η, η(0))kp

Lp(Ω;M p)

6 (r + 1)kηkp

Sp(Ω;D)

(2.7)

thus, it also holds that

Sp(Ω, G; D) ⊂ Lp(Ω, G; M p),

and the embedding is continuous. With the appropriate boundedness and integrability conditions
on a càdlàg adapted process Y , then for each t, the segment Yt can be regarded as an element in
the spaces Sp(Ω, Ft; D) or Lp(Ω, Ft; M p).

In line with the deﬁnitions given above, we also use the following notation for any u ∈ [0, T ]

and 2 6 p < ∞. Let

Sp
ad(Ω, Fu; Du) ⊆ Sp(Ω, Fu; Du)

denote the subspace of elements in Sp(Ω, Fu; Du) admitting a F-adapted representative. We
remark that if Z ∈ Sp(Ω, FT ; DT ), then we have that

kZkSp(Ω;D) 6 kZkSp(Ω;Dt) 6 kZkSp(Ω;DT ).

(2.8)

Also, consider the Banach space

with the usual norm given by:

Lp(Ω; Lp
u)

Then

kY kp

Lp(Ω;Lp

u) := E(cid:2)kY kp

u(cid:3) < ∞ .

Lp

Lp
ad(Ω; Lp

u) ⊆ Lp(Ω; Lp
u)

denotes the subspace of elements admitting F-adapted representative.

Suppose now that Y ∈ Lp

ad(Ω; Lp

T ). Since Y (t) is well-deﬁned for a.e. t ∈ [−r, T ], it makes

sense to consider the segments Yt as elements in Lp(Ω, Ft; Lp) for a.e. t. Then,

Z u

−r

kYtkp

Lp(Ω;M p)dt 6Z u

−r(cid:16)kY kp

6 2(r + u)kY kp

Lp(Ω;Lp

u).

Lp(Ω;Lp

t ) + kY (t)kp

Lp(Ω;Rd)(cid:17)dt

(2.9)

Even though we can not consider Sp

ad(Ω; Dt) as a subspace of Lp

ad(Ω; Lp

t ), since the function

is not injective, this function is continuous, and

Sp
ad(Ω; Dt) ∋ η 7→ η ∈ Lp

ad(Ω; Lp
t )

kY kp

Lp(Ω;Lp
t )

6 (t + r)kY kp

Sp(Ω;Dt).

(2.10)

7

Remark 2.3. In the continuous setting (see e.g.
[36]), the segments of an SFFDE are often
considered as elements of the Bochner space L2(Ω; C), where C denotes the set of continuous
functions from [−r, 0] to Rd. We remark that the càdlàg counterpart, namely the Bochner space
Lp(Ω, G; D) of D-valued functions turns out to be too restrictive to contain a suﬃciently large class
of càdlàg segments. This can bee seen from the following lemma:

Lemma 2.4. Suppose that X is a càdlàg Lévy-Itô process with X ∈ Lp(Ω, G; D[a, b]). Then X is
continuous with probability 1.

To see why this holds, we ﬁrst recall that by an equivalent deﬁnition of Bochner spaces (see [22]
for more on these spaces), Lp(Ω, G; D) consists of equivalence classes of the (G, B(D))-measurable
functions X : Ω → D such that the image X(Ω0) is separable for some subset Ω0 ⊂ Ω with P (Ω0) =
1, and E[kXkp
D([a,b])] < ∞ holds1. By [27, lemma 9.12], we know that X(Ω0) is separable if and
only if there exist a countable set T0 ∈ [a, b], such that ∆X(t, ω) = 0 whenever t /∈ T0, ω ∈ Ω0.
In other words, except for a negligible set of sample paths of X, all the jumps of X occur at a
countable number of times.

Proof of Lemma 2.4. Since X ∈ Lp(Ω, G; D([a, b])), we can choose Ω0, T0 be as above. Now since
X is a càdlàg Lévy-Itô process, it also holds that P (ω : ∆X(t, ω) 6= 0) = 0 for every t, and hence

N := [t∈T0

{ω ∈ Ω0 : ∆X(t, ω) 6= 0}

is a null set. But then if ω ∈ Ω0 \ N , it holds that ∆X(t, ω) = 0 for every t, that is X is continuous
on Ω0 \ N and P (Ω0 \ N ) = 1.

2.2 Examples

To illustrate some possible ways to model memory or delay in a stochastic diﬀerential equation,
we include some examples of delay terms, that has been seen in applications.

i) Distributed delay: the functional

F (St) =Z 0

−r

S(t + θ)α(d θ) .

(2.11)

where α is a ﬁnite Borel measure on [−r, 0], is an example of a distributed delay-functional.
This is a general type of delay in the sense that examples ii, iii, can be regarded particular
cases, as we will see below. A general ﬁnancial framework in this setting has been studied in
[8, 9] where the authors considered a price evolution for the stock of the form

dS(t) = M (St)dt + N (St)dW (t) =Z 0

−r

S(t + s)αM (ds)dt +Z 0

−r

αM and αN being suitable functions of bounded variation.

See also [36, Sec. V], where α is taken as a probability measure.

S(t + s)αN (ds)dW (t) ,

ii) Absolutely continuous distributed delay: in the particular case α << L, where we have
denoted by L the Lebesgue measure, we have that the measure α admits a density κ := dα
dL .
Therefore the functional (2.11) reads as

F (St) :=Z 0

−r

S(t + θ)κ(θ)d θ, .

1in fact this deﬁnition is valid for D([a, b]) replaced by any Banach space V

8

A more advanced example has been provided in [29] where a functional of the form

F (t, St) =Z 0

−r

H(t, S(t + θ))h(θ)dθ, ,

has been treated.

iii) Discrete delay: if we let α = δτ , in equation (2.11), where δτ is the Dirac measure concen-

trated at τ ∈ [−r, 0], then we have a discrete delay functional, namely

F (St) =Z 0

−r

S(t + θ)δτ (dθ) = S(t − τ ) .

(2.12)

A discrete delay model using functionals on the form (2.12), is widely used in concrete ap-
plications, spanning from mathematical biology, as in the case of the delayed Lotka-Volterra
[21, 32, 36], to mathematical ﬁnance, as it happens for the delayed Black-
model, see, e.g.
In particular,
Scholes model, see, e.g.
in [3], the authors give an explicit form for the price a European call option written on an
underlying evolving as

[3, 28], or for commodities markets, see, e.g., [33].

dS(t) = µS(t − a)dt + σ(S(t − b))dW (t) ,

for µ ∈ R and a suitable function σ.

A particular case of the discrete delay example is the no delay case, i.e. τ = δ0. A multiple

delay case, can be deﬁned by letting α =PN

i=1 δτi, τi ∈ [−r, 0], i = 1, 2, . . . , N .

iv) Brownian delay: our setting allows also to consider delays with respect to a Brownian

motion, namely

Z 0

−r

S(t + θ)d W (θ) ,

hence taking into account noisy memory models, as in the cases arise, e.g. [28, 43], in modeling
the stochastic volatility of an asset price, or when dealing with stochastic control problems,
see, e.g. [18].

v) Lévy delay: similarly to the Brownian delay, we can also consider a delay with respect to a

square integrable Lévy process of the form

Z 0

−r

S(t + θ)d L(θ) .

Such type of delay has been employed in [43] in order to consider some stochastic volatility
models related to energy markets.

vi) Mean ﬁeld delay: we can consider a delay of the form

E(cid:20)Z 0

−r

S(t + θ) α(dθ)(cid:21) ,

where α is as in example i, see e.g. [1].

9

2.3 D framework

Fix p ∈ [2, ∞). Consider again the equation

dX(t) = f (t, Xt)dt + g(t, Xt)dW (t) +ZR0

X0 = η,

h(t, Xt)(z) ˜N (dt, dz)

(2.13)

In this section, we require that f (t, ·) is a Rd-valued functional deﬁned on Sp(Ω, Ft; D) for each

ﬁxed t. Therefore, we introduce the space

p := {(t, η) ∈ [0, T ] × Sp(Ω, F ; D) such that η ∈ Sp(Ω, Ft; D)},
SF

(2.14)

as the domain of the coeﬃcient functionals f, g, h in the SFDDE (2.13).
require that:

In particular we will

η ∈ Sp(Ω, F0; D)
f : SF
g : SF
h : SF

p → Lp(Ω, Rd)
p → Lp(Ω, Rd×m),
p → Lp(Ω, L2(ν, Rd×n)),

In order for the equations to be well-deﬁned, it is always assumed that whenever X ∈ Sp
the processes f (t, Xt), g(t, Xt), and h(t, Xt), t ∈ [0, T ], have predictable modiﬁcations.

ad(Ω; DT ),

Deﬁnition 2.5. We say that X ∈ Sp
each t ∈ [0, T ]

ad(Ω; DT ) is a strong solution to the equation (2.13) if for

X(t) = η(0) +Z t

0

f (s, Xs)ds + Z t

0

g(s, Xs)dW (s) +Z t

0 ZR0

h(s, Xs)(z) ˜N (ds, dz)

(2.15)

X0 = η.

If the solution is unique, we will write ηX to denote the solution of (2.15) with initial datum
ηX0 = η.

To prove existence and uniqueness of the solution of the SFDDE, we rely on the following

result.

Lemma 2.6 (Kunita’s inequality). Let q > 2. Suppose that F, G and H are predictable processes
taking values in Rd, Rd×m and Rd×n respectively. If

Y (t) = Y0 +Z t

0

F (s)ds +Z t

0

G(s)dW (s) +Z t
0 ZR0

H(s, z) ˜N (ds, dz),

t ∈ [0, T ],

then there exists a constant C = C(q, d, m, n, T ), independent of the processes F, G and H and the
initial value Y0, such that whenever t 6 T the following inequality holds

|Y (t)|q] 6 CnkY0kq

E[ sup
06u6t
+ kH(s)kq

Lq(Ω,Lq(ν)) + kH(s)kq

Lq(Ω,Rd) +Z t

0 (cid:16)kF (s)kq
Lq(Ω,L2(ν))(cid:17)dso

Lq(Ω,Rd) + kG(s)kq

Lq(Ω,Rd×m)

(2.16)

For n = 1 (and arbitrary m and d), this is a rewritten version of Corollary 2.12 in [34]. We

have justiﬁed the extension to general n in Appendix A.1.

10

2.3.1 Existence, uniqueness and moment estimates

Before giving suﬃcient conditions for existence and uniqueness of solutions to the equation (2.13),
we will establish a set of hypotheses.

Assumption. (D1) There exists L > 0, such that whenever t ∈ [0, T ] and η1, η2 ∈ Sp(Ω, Ft; D),

then

kf (t, η1) − f (t, η2)kp

Lp(Ω;Rd) + kg(t, η1) − g(t, η2)kp

Lp(Ω;Rd×n)

+ kh(t, η1) − h(t, η2)kp
6 Lkη1 − η2kp

Sp(Ω;D).

Lp(Ω,Lp(ν)) + kh(t, η1) − h(t, η2)kp

Lp(Ω,L2(ν))

(D2) There exists K > 0, such that whenever t ∈ [0, T ] and η ∈ Sp(Ω, Ft; D), then

kf (t, η)kp

Lp(Ω;Rd) + kg(t, η)kp

Lp(Ω;Rd×n)

Lp(Ω,Lp(ν)) + kh(t, η)kp

Lp(Ω,L2(ν))

+ kh(t, η)kp
6 K(1 + kηkp

Sp(Ω;D)).

(2.17)

Remark 2.7. As usual, D2 is implied by D1, if we assume that whenever η = 0, the left-hand-side
of inequality (2.17) is bounded by some K ′, uniformly in t ∈ [0, T ].

Theorem 2.8 (Existence and Uniqueness I).

(i) Suppose that hypothesis D1 holds. If X, Y ∈ Sp

ad(Ω; DT ) are strong solutions to (2.1), then

X = Y .

(ii) Suppose that hypotheses D1 and D2 hold. Then there exists a strong solution X ∈ Sp
to the equation (2.1). Moreover, there exists D = D(K, p, T, d, m, n) > 0, such that

ad(Ω; DT )

kXkp
Sp

ad(Ω;DT )

6 eDt(Dt + kηkp

Sp(Ω;D))

(2.18)

whenever t 6 T .

Proof. We will use a standard Picard iteration argument to show that a solution exists. First, we
deﬁne, for each k > 0, a sequence of processes in Sp

ad(Ω; DT ) inductively by

X 1(t) = η(0),

X 1

0 = η

X k+1(t) = η(0) +Z t

0

g(s, X k

s )dB(s)

t ∈ [0, T ],

t ∈ [0, T ]

f (s, X k

s )ds +Z t

0

+Z t

0

X k+1

t = η.

h(s, X k

s )(z) ˜N (ds, dz),

We immediately have that X 1 ∈ Sp
ad(Ω; DT ) then by
assumption f (X k), g(X k), and h(X k) admit predictable versions so that by assumption (D2) it
follows that

ad(Ω; DT ). Also if we assume that X k ∈ Sp

Z T
0 (cid:16)kf (t, X k
6Z T

0

+ kh(t, X k

t )kp

Lp(Ω;Rd) + kg(t, X k

t )kp

Lp(Ω;Rd×n)

t )kp

Lp(Ω,Lp(ν)) + kh(t, Xt)kp

Lp(Ω,L2(ν))(cid:17)dt

K(1 + kX k

t kp

Sp(Ω;D))dt 6 KT (1 + kX kkp
ad(Ω;DT )) < ∞.
Sp

11

(2.19)

In particular, the integrands of X k+1 are Itô integrable, so that X k+1 is càdlàgand adapted, and
ﬁnally by Kunita’s inequality, we have that X k+1 ∈ Sp

ad(Ω; DT ).

We now claim that for each k ∈ N the following estimate holds for every t ∈ [0, T ],

kX k+1 − X kkp
Sp

ad(Ω;Dt)

6

(LCt)k−1
(k − 1)!

kX 2 − X 1kp
Sp

ad(Ω;DT )

.

(2.20)

This trivially holds when k = 1. Now suppose that (2.20) holds for each t ∈ [0, T ]. Using the
deﬁnition of X k+2, X k+1, Kunita’s inequality (2.16), and assumption (D2), we ﬁnd that

kX k+2 − X k+1kp
Sp

ad(Ω;Dt)

0 (cid:16)kf (s, X k+1

s

) − f (s, X k

s )kp

Lp(Ω;Rd) + kg(s, X k+1

s

) − g(s, X k

s

6 C Z t
+ kh(s, X k+1
6 LC Z t
6 LC Z t

0

0

) − h(s, X k

s )kp

Lp(Ω;Rd×n)

s )kp
Lp(Ω,L2(ν))(cid:17)ds

) − h(s, X k

Lp(Ω,Lp (ν)) + kh(s, X k+1

s

s )kp
Sp(Ω;D)ds 6 LC Z t
s kp

0

kX k+1

s − X k

kX k+1 − X kkp

Sp(Ω;Ds)ds

(LCs)k−1
(k − 1)!

kX 2 − X 1kp
Sp

ad(Ω;DT )

ds =

(LCt)k

k!

kX 2 − X 1kp
Sp

ad(Ω;DT )

.

Now, by induction, (2.20) holds for each k ∈ N. In particular

kX k − X ikp
Sp

ad(Ω;Dt)

6 kX 2 − X 1kp
Sp

ad(Ω;DT )

∞

Xj=min{k,i}

(LT C)j−1
(j − 1)!

→ 0 ,

as k, i → ∞ ,

so that {X k}k>0 is a Cauchy sequence in Sp
{X k}k>0 converges to some X in Sp

ad(Ω; DT ). Clearly X0 = η P -a.s.

ad(Ω; DT ). Since Sp

ad(Ω; DT ) is complete, we have that

We will now show that the limit X satisﬁes (2.15) by showing that

06t6T(cid:12)(cid:12)(cid:12)
d := Eh sup

X(t) −nη(0) + Z t
+ Z t

f (s, Xs)ds + Z t
pi1/p
h(s, Xs)(z) ˜N (ds, dz)o(cid:12)(cid:12)(cid:12)

0 ZR0

0

0

g(s, Xs)dW (s)

= 0

(2.21)

For arbitrary k, we subtract X k+1 and add its integral representation inside the supremum in
(2.21). Then by the triangle inequality, Kunita’s inequality, and ﬁnally the Lipschitz condition
(D1) we ﬁnd that

d 6 kX − X k+1kSp

ad(Ω;DT ) +nC Z T

0 (cid:16)kf (t, X k

t ) − f (t, Xt)kp

Lp(Ω;Rd)

+ kg(t, Xt) − g(t, X k

+ kh(t, Xt) − h(t, X k

6 kX − X k+1kSp

6 kX − X k+1kSp

Lp(Ω,Lp(ν))

t )kp

t )kp

t )kp

Lp(Ω;Rd×n) + kh(t, Xt) − h(t, X k
Lp (Ω,L2(ν))(cid:17)dto1/p
kXt − X k

ad(Ω;DT ) +(cid:8)CLZ T
ad(Ω;DT ) + (CLT )1/pkX − X kkSp

Sp(Ω;D)dt(cid:9)1/p
t kp
ad(Ω;DT ) → 0.

0

Since for any ǫ > 0 we have that 0 6 d < ǫ, it follows that d = 0, and hence a solution exists.

Suppose now that X and Y are solutions of (2.13). We will show that X = Y . Exploiting
the integral representation of X and Y , Kunita’s inequality and the Lipschitz condition (D1), we
have that, for all t ∈ [0, T ],

kX − Y kp
Sp

ad(Ω;Dt)

0 (cid:16)kf (s, Xs) − f (s, Ys)kp

6C Z t
+ kh(s, Xs) − h(s, Ys)kp
6CLZ t

kXs − Yskp

0

Sp(Ω;D)ds 6 CLZ t

0

Lp(Ω;Rd) + kg(s, Xs) − g(s, Ys)kp

Lp(Ω;Rd×n)

Lp(Ω,Lp (ν)) + kh(s, Xs) − h(s, Ys)kp

Lp(Ω,L2(ν))(cid:17)ds

kX − Y kp

Sp(Ω;Ds)ds.

12

and thus we have kX − Y kp
ad(Ω;Dt) = 0 for every t ∈ [0, T ] from Grönwall’s inequality.
Sp

Similarly, if X is a solution to (2.13), from the integral representations, Kunita’s inequality

and the linear growth condition (D2) we have that

kXkp
Sp

ad (Ω;Dt)

6Cnkηkp

Sp(Ω;D) +Z t

0 (cid:16)kf (s, Xs)kp

Lp(Ω;Rd)

+ kg(s, Xs)kp

Lp (Ω;Rd×n) + kh(s, Xs)kp

Lp(Ω,Lp (ν)) + kh(s, Xs)kp

6 C(cid:16)kηkp

Sp(Ω;D) + K(cid:0)Z t

0

1 + kXskp

Sp(Ω;D)ds(cid:1)(cid:17) 6 Ckηkp

Lp(Ω,L2(ν))(cid:17)dso
Sp (Ω;D) + CKt + CK Z t

0

kXkp

Sp(Ω;Ds)ds ,

so applying Grönwall’s inequality we obtain

kXkp
Sp

ad (Ω;Dt)

6 (cid:16)Ckηkp

Sp(Ω;D) + CKt(cid:17)eCKt,

for all t ∈ [0, T ].

Remark 2.9 (Path dependent SDEs). Suppose that for each t ∈ [0, T ] and every η ∈ Sp
it holds that,

ad(Ω, F0; D)

f (t, η)(ω) = F (t, η(ω))
g(t, η)(ω) = G(t, η(ω))

h(t, η, ω, ζ) = H(t, η(ω), ζ),

P -a.s for some deterministic functionals

F :[0, T ] × D → Rd,
G :[0, T ] × D → Rd×m,
H :[0, T ] × D → L2(ν) ∩ Lp(ν).

then the assumptions (D1) and (D2) hold whenever F, G are Lipschitz continuous in the second
variable, uniformly with respect to the ﬁrst, and H is Lipschitz continuous in the second variable,
uniformly with respect to the ﬁrst, using both norms k · kL2(ν) and k · kLp(ν).

2.4 M p framework

Now, consider equation

dX(t) = f (t, Xt, X(t))dt + g(t, Xt, X(t))dW (t) +ZR0

X0 = η.

h(t, Xt, X(t))(z) ˜N (dt, dz)

(2.22)

Here (2.22) we have used the notation f (·, Xt, X(t)) to emphasize the structure of the product space
of M p. Now for each t ∈ [0, T ] we will require that (Xt, X(t)) belongs to the space Lp(Ω, Ft; M p)
for some p ∈ [2, ∞), that will be ﬁxed throughout the section. Therefore, we introduce

LF

p := {(t, (η, x)) ∈ [0, T ] × Lp(Ω, F ; M p) such that (η, x) ∈ Lp(Ω, Ft; M p)},

(2.23)

In particular, we will require that:

(η, v) ∈ Lp(Ω, F0; M p)
p → Lp(Ω, Rd))
f : LF
p → Lp(Ω, Rd×m),
g : LF
p → Lp(Ω, L2(ν, Rd×n)),
h : LF

In order for the equations to be well-deﬁned, it is always assumed that whenever X ∈ Lp

ad(Ω; Lp
t ),

the processes f (t, Xt), g(t, Xt), and h(t, Xt), t ∈ [0, T ], have predictable modiﬁcations.

13

Deﬁnition 2.10. We say that X ∈ Lp

ad(Ω; Lp

t ) is a strong solution to (2.22) if for each t ∈ [0, T ]

X(t) = x +Z t

0
X0 = (η, x).

f (s, Xs, X(s))ds +Z t

0

g(s, Xs, X(s))dW (s) +Z t
0 ZR0

h(s, Xs, X(s))(z) ˜N (ds, dz)

(2.24)

If the solution is unique, we will sometimes write η,xX to denote the solution of (2.24) with initial
data η,xX0 = (η, x).

Note that if X(t), t ∈ [0, T ] is the solution of (2.22), it is a semimartingale and hence it admits a
càdlàg modiﬁcation. In the sequel we always refer to this modiﬁcation. Remark also that, being
X(t), t ∈ [0, T ], càdlàg, implies that the M p-valued process Xt, t ∈ [0, T ] is càdlàg. This can be
easily seen by noticing that

kXt − Xskp

M p = lim
t→s

t>sZ 0

−r

lim
t→s
t>s

|X(t + β) − X(s + β)|pdβ + lim
t→s
t>s

|X(t) − X(s)|p

6 r lim
t→s
t>s

sup

β∈[−r,0]

|X(t + β) − X(s + β)|p + lim
t→s
t>s

|X(t) − X(s)|p

= 0,

and similarly for the left-limits.

2.4.1 Existence and uniqueness

The Lp-analogue of the hypotheses (D1) and (D2), are deﬁned below.

Assumption. (L1) There exists L > 0, such that whenever t ∈ [0, T ] and (η1, x1), (η2, x2) ∈ Lp(Ω, Ft; M p),

then

kf (t, η1, x1) − f (t, η2, x2)kp

Lp(Ω;Rd) + kg(t, η1, x1) − g(t, η2, x2)kp

Lp(Ω;Rd×n)

+ kh(t, η1, x1) − h(t, η2, x2)kp
6 Lk(η1, x1) − (η2, x2)kp

Lp(Ω;M p).

Lp(Ω,Lp(ν)) + kh(t, η1, x1) − h(t, η2, x2)kp

Lp(Ω;L2(ν))

(L2) There exists K > 0, such that whenever t ∈ [0, T ] and (η, v) ∈ Lp(Ω, Ft; M p), then

kf (t, η, x)kp

Lp(Ω;Rd) + kg(t, η, x)kp

Lp(Ω;Rd×n)

+ kh(t, η, x)kp
6 K(1 + k(η, x)kp

Lp(Ω;M p)).

Lp(Ω,Lp(ν)) + kh(t, η, x)kp

Lp(Ω,L2(ν))

Theorem 2.11 (Existence and Uniqueness II).

(i) Suppose that hypothesis (L1) hold. If X, Y ∈ Lp

ad(Ω; Lp

T ) are strong solutions to (2.22) , then

X = Y .

(ii) Suppose that hypotheses (L1) and (L2) holds. Then there exists a strong solution X to equa-

tion (2.22). Moreover, there exists D = D(K, p, T, d, m, n) > 0, such that

kXkp
Lp

ad(Ω;Lp
t )

6 eDt(Dt + k(η, x)kp

Lp(Ω;M p)),

(2.25)

whenever t 6 T .

14

The proof uses the same argument as in the proof of Theorem 2.8 and for the sake of brevity
the details are omitted. However, we mention that if we replace the space Sp(Ω; D), respectively,
Sp
ad(Ω; DT ), with the space Lp(Ω; M p), respectively, Lp
t ),throughout the proof of Theorem
2.8, then all the inequalities are still valid, with the exception of using a diﬀerent set of constants.
As an example, in this setting we obtain, using inequality (2.9), that the inequality (2.19), can be
replaced by

ad(Ω; Lp

Z T
0 (cid:16)kf (t, X k
6Z T

0

+ kh(t, X k

t , X k(t))kp

Lp(Ω;Rd) + kg(t, X k

t , X k(t))kp

Lp(Ω;Rd×n)

Lp(Ω,L2(ν))(cid:17)dt

t , X k(t))kp

Lp(Ω,Lp(ν)) + kh(t, X k

t , X k(t))kp

(2.26)

K(1 + kX k

t kp

Lp(Ω;M p))dt 6 KT (1 + (T + R)kX kkp
Lp

ad(Ω;Lp

t )) < ∞.

Let us stress that when the initial value is càdlàg, then the previous section (2.3) is indeed

more general, as the assumptions (L1) and (L2) implies assumptions (D1) and (D2).

2.5 Robustness SFDDEs

In the present section we study robustness of SFDDE to changes of the noise. In particular, we
want to approximate the solution of an SFDDE X, with an approximate processes X ǫ, where
X ǫ are deﬁned by substituting the integrals with respect to the small jumps with integrals with
respect to scaled Brownian motions. We follow rather closely, the presentation in [6] for ordinary
SDE’s and remark that a related problem is also considered in [31]. In this paper we also include a
new ingredient, by giving suﬃcient conditions which ensure that the approximations X ǫ converge
to X in the p’th mean.

The main motivation for studying such robustness problem is that it is diﬃcult to perform
simulations of distributions corresponding to a Lévy process. Indeed, simulation of such distribu-
tions are often performed by neglecting the jumps below a certain size ǫ. However, when needed to
preserve the variation of the inﬁnite activity Lévy process, a scaled Brownian motion is typically
replacing the small jumps. Under some additional assumptions, it is known that given a square
integrable (1-dimensional) Lévy process with Lévy measure µ and compensated Poisson random

measure fM , the expression

Z|z|<ǫ

z2µ(dz)−1/2Z t

0 Z|z|<ǫ

z ˜M(dz, ds),

converges in distribution to a standard Brownian motion W , as ǫ tends to 0. We refer to [4, 11]
for more details on this topic. We remark that the robustness problem in this paper, does not rely
on the above mentioned additional assumptions.

2.5.1 The model

Fix p ∈ [2, ∞). We want to consider the following dynamical systems with memory and jumps

X(t) = η(0) +Z t

0

f (s, Xs)ds +Z t

0

X0 = η ∈ Sp(Ω, D) .

g(s, Xs)dB(s) +Z t
0 ZR0

h0(s, Xs)λ(z) ˜N (ds, dz),

t ∈ [0, T ]

(2.27)

Here,

and

h0 : SF

p → Lp(Ω, Rd×k),

λ ∈ L2(ν, Rk×n) ∩ Lp(ν, Rk×n)

15

for some k ∈ N. Moreover, we assume that whenever Y is a càdlàg adapted process on [−r, T ],
then h0(t, Xt) is predictable. Observe that

h := h0λ : SF

p → Lp(Ω, L2(ν, Rd×n)).

Example 2.12. Let us suppose that n = k = d and that h0(t, η) and λ are diagonal matrices. In
particular,

is a diagonal matrix with entries hi,i
of the jump integral in the SFDDE (2.27) is given by

0 (t, η)λi,i(z) for i = 1, . . . , n. Then the component-wise form

h0(t, η)λ(z)

Z t
0 ZR0

hi,i
0 (s, Xs)λi,i(z) ˜Ni(ds, dz).

If we let the delay parameter r be equal to 0, then this example reduces to the robustness to

model choise- problem in [30].

Now let us impose the following assumptions on f, g, h0 and λ:

Assumption. (i) The coeﬃcient functionals f and g and h are assumed to satisfy all (corre-

sponding) hypotheses of Section 2.3.

(ii) The functional h0 satisﬁes the Lipschitz and linear growth conditions

kh0(t, η1) − h0(t, η2)kp
kh0(t, η)kp

Lp(Ω,Rd×k)

Lp(Ω,Rd×k)

6 Lkη1 − η2kp
6 K(1 + kηkp

Sp(Ω;D),
Sp(Ω;D)).

We claim now that the functional h := h0λ also satisﬁes the (corresponding) assumptions from
Section 2.3. Observe that

kh(t, η1) − h(t, η2)kp

Lp(Ω,Lp(ν)) + kh(t, η1) − h(t, η2)kp

Lp(Ω,L2(ν))

k(h0(t, η1) − h0(t, η2))λ,j kp

Lp(Ω,Lp(νj )) + k(h0(t, η1) − h0(t, η2))λ,jkp

Lp(Ω,L2(νj ))

=

nXj=1

6 kh0(t, η1) − h0(t, η2)kp

Lp(Ω;Rd×k)

Lp(νj ) + kλ,jkp

6 Lkη1 − η2k2

Lp(ν) + kλkp

Sp(Ω;D)(cid:0)kλkp

nXj=1(cid:0)kλ,jkp
L2(ν)(cid:1).

L2(νj )(cid:1)

Thus h satisﬁes the Lipschitz assumption (D1). A similar argument yields h also satisﬁes the linear
growth assumption (D2). Thus, by the existence and uniqueness Theorem 2.8, the following result
holds.

Corollary 2.13. The equation (2.27) has a unique solution ηX in Sp
exists D = D(K, λ, p, T, d, m, n) > 0, such that

ad(Ω; DT ). Moreover, there

E(cid:20) sup

−r6s6t

|ηX(s)|p(cid:21) 6 eDt(Dt + kηkp

Sp(Ω;D)),

(2.28)

for any t 6 T .

16

2.5.2 The approximating model

Let us ﬁrst introduce some notation. For any ε ∈ (0, 1), deﬁne λε(z) ∈ Rk×n by

λε(z) = 1{|z|<ε}(z)λ(z),

for a.e. z. Now, let B be an n-dimensional F-adapted Brownian motion, independent of ˜N .
Independence of B and W is not required, (see e.g. [6]). We want to approximate equation (2.27)
by replacing the integral with respect to the small jumps with an integral with respect to the
Brownian motion B. More speciﬁcally, we will replace the integrators

with the integrators

ZR0

ε (z) ˜N j(dt, dz) ,
λi,j

Λi,j(ε)dBj (t) ,

(2.29)

(2.30)

for i = 1, . . . , k; j = 1, . . . , n. Here, Λ(ǫ) can be any bounded deterministic function with values
in Rk×n converging to 0 as ε → 0. We choose to let

Λi,j(ε) = kλi,j

ε kL2(νj ).

This choice corresponds to what has previously been used in the literature, see e.g.
justiﬁcation of this choice is considered in Remark 2.14 below. Notice now that

[6]. A

|Λ(ε)|2 = kλεkL2(νj ).

Remark 2.14. The choice Λi,j(ǫ) = kλi,j
ε kL2(νj ) above is reasonable in the sense that for a given
predictable square integrable process Y , this change of integrator preserves the variance of the
integrals, i.e.

Eh(cid:16)Z t
0 ZR0

Y (s)λi,j

ε (z) ˜N j(ds, dz)(cid:17)2i = EhZ t

0

Y (s)2dsikλi,j

ε k2

L2(νj ) = Eh(cid:16)Z t

0

Y (s)Λi,j (ǫ)dBj(s)(cid:17)2i,

for i = 1, . . . , k; j = 1, . . . , n. From a ﬁnancial terminology perspective where these models can be
[3, 6, 8, 9, 28, 29, 33, 43]), this choice of Λ, preserves the total volatilityof a
applied (see e.g.
process, when (2.29) is replaced by (2.30). However, this particular choice of Λ is not necessary
for the analysis, as we will see in Remark 2.17 below.

Now, we are ready to exploit the dynamics of the approximated processes X ǫ. Consider

X (ǫ)(t) = η(0) +Z t

0

+Z t

0

h0(s, X ǫ

h0(s, X ǫ

s)(λ(z) − λε(s)) ˜N (ds, dz)

(2.31)

f (s, X ǫ

g(s, X ε

s)ds +Z t
s)Λ(ǫ)dB(s) +Z t
0 ZR0

0

s )dW (s)

X (ǫ)

0 = η

Before proceeding to the main result of this section, we make the following observations regarding
the functionals in the approximated equation (2.31):

• The functionals

g1
7−→ h0(t, η)Λ(ǫ) ,
h1
7−→ h0(t, η)(λ − λε) ,

η

η

satisfy the corresponding hypotheses from Section 2.3

17

• The Lipschitz and linear growth constant appearing in assumptions (D1) and (D2) can be
chosen independent of ǫ. In particular, we can deduce the following linear growth estimate:

kh0(t, η)Λ(ǫ)kp
6 kh0(t, η)kp

Lp(Ω;Rd×n) + kh0(t, η)(λ − λε)kp
L(Ω;Rd×k) sup
ε∈(0,1)

|Λ(ǫ)|p + kh0(t, η)kp

Lp(Ω,Lp(ν)) + kh0(t, η)(λ − λε)kp

Lp(Ω,L2(ν))

Lp(Ω;Rd×k)kλkp

Lp(ν) + kh0(t, η)kp

Lp(Ω;Rd×k)kλkp

L2(ν)

6 K ′(1 + kηkp

Sp(Ω;D)).

A similar estimate holds for the Lipschitz condition (D1).

The following existence and uniqueness result immediately follows from Theorem 2.8.

Corollary 2.15. For each ǫ > 0, there exists a unique strong solution ηX ǫ to the equation (2.31).
Moreover, there exists a D = D(K, λ, p, T, d, m, n) > 0, independent of ǫ, such that

E(cid:20) sup

−r6s6t

|ηX ǫ(s)|p(cid:21) 6 eDt(Dt + kηkp

Sp(Ω;D))

(2.32)

for any t 6 T .

Now, we are ready to state the main result of the present section. This result guarantees that,
when ε tends to 0, Xε converges to X in Sp

ad(Ω; DT ).

Theorem 2.16 (Robustness). Suppose that X satisﬁes equation (2.27) and X ǫ satisﬁes equation
(2.31). Then there exist a constant A := A(p, T, η, K, L, λ) > 0, independent of ǫ, such that

E(cid:20) sup

−r6s6t

|ηX(s) − ηX ǫ(s)|p(cid:21) 6 AeAt(kλεkp

L2(ν) + kλεkp

Lp(ν)).

(2.33)

Proof. Writing out the integral representation of X(s) and X ǫ(s), we have that

u)du + Z s

0

g(u, Xu) − g(u, X ǫ

u)dW (u)

(h0(u, Xu) − h0(u, X ǫ

u))λ(z) + h0(u, X ǫ

u)λε(z) ˜N (du, dz)

0

X(s) − X ǫ(s) = Z s
+ Z s
− Z s

X0 − X ǫ

0
0 = 0.

f (u, Xu) − f (u, X ǫ
0 ZRd
h0(u, X ǫ

0

u)Λp(ǫ)dB(u),

Let us ﬁrst consider some estimates for the integrands of ˜N and B. Observe that

k(h0(u, Xu) − h0(u, X ǫ

u))λ + h0(u, X ǫ
6 k(h0(u, Xu) − h0(u, X ε
6 L1/pkXu − X ǫ

u)λεkLp(Ω;Lp(ν))
u)kLp(Ω;Rd×k)kλkLp(ν) + kh0(u, X ǫ

u)kLp(Ω;Rd×k)kλεkLp(ν)

ukSp(Ω;D)kλkLp(ν) + K 1/p(1 + kX ǫ

ukSp(Ω;D))1/pkλεkLp(ν),

and hence

k(h0(u, Xu) − h0(u, X ǫ

u))λ + h0(u, X ǫ

u)λεkp

Lp(Ω,Lp(ν))

ukp

Sp(Ω;D)kλkp

Lp(ν) + K(1 + kX ǫ

ukp

Sp(Ω;D))kLp(Ω)kλεkp

In an analogous manner we have that

k(h0(u, Xu) − h0(u, X ǫ

u))λ + h0(u, X ǫ

u)λεkp

Lp(Ω,L2(ν))

6 2p−1(cid:16)LkXu − X ǫ

6 2p−1(cid:16)LkXu − X ǫ

Lp(ν)(cid:17).

(2.34)

(2.35)

L2(ν)(cid:17),

ukp

Sp(Ω;D)kλkp

L2(ν) + K(1 + kX ǫ

ukp

Sp(Ω;D))kλεkp

18

and that

kh0(u, X ǫ

u)Λ(ε)kp

Lp(Ω;Rd×n)

6 K(1 + kX ǫ

ukp

Sp(Ω;D))|Λ(ε)|p

Using Lemma 2.6, the Lipschitz condition (D1), estimates (2.34), (2.35), and Corollary 2.15 we
have that there exist a constant D′ := D′(p, K, L, λ), independent of ε such that

sup

−r6s6t

|ηX(s) −η X ǫ(s)|p(cid:3)
αε(t) : = E(cid:2)
6Z t
0 (cid:16)kf (u, Xu) − f (u, X ǫ

u)kp

Lp(Ω;Rd) + kg(u, Xu) − g(u, X ǫ

u)kp

Lp(Ω;Rd×n)

Lp(Ω;Lp(ν))

Lp(Ω,L2(ν))

+ k(h0(u, Xu) − h0(u, X ǫ
+ k(h0(u, Xu) − h0(u, X ǫ

u))λ + h0(u, X ǫ
u))λ + h0(u, X ǫ

u)λεkp
u)λεkp

+ kh0(u, X ǫ

u)Λ(ε)kp

Lp(Ω;Rd×n)(cid:17)du
0 (cid:16)kXu − X ǫ
Sp(Ω;D) +(cid:0)1 + kX ǫ
αε(u)du + tD′(cid:0)1 + eDt(Dt + kηkp

ukp

6 D′Z t
6 D′Z t

0

ukp

L2(ν) + kλεkp

Sp(Ω;D)(cid:1)(cid:0)kλεkp
Sp(Ω;D))(cid:1)(cid:0)kλεkp

Lp(ν) + |Λ(ε)|p(cid:1)(cid:17)du
Lp(ν) + |Λ(ε)|p(cid:1).
Sp(Ω;D))(cid:1) which is a non-decreasing function in t and hence

L2(ν) + kλεkp

Now, set Bt := tD′(cid:0)1 + eDt(Dt + kηkp

by Grönwall’s inequality, it follows that

αε(t) 6 BteD′t(cid:0)kλεkp

L2(ν) + kλεkp

Lp(ν) + |Λ(ε)|p(cid:1).

Since |Λ(ε)|p = kλεkp

L2(ν), the result holds with A := max{2BT , D′}.

Remark 2.17. We have chosen to scale the Brownian motions Bj in the equation (2.31) for X ǫ
ε kL2(νj ). However, if we return to (2.29)-(2.30), we could let Λǫ be any Rk×n-
with Λi,j(ǫ) := kλi,j
valued function Λ(ε) > 0, ε > 0, bounded from above and converging to 0 as ε → 0. Corollary
2.15 and Theorem 2.16 still hold, with the inequality (2.33) replaced by

E(cid:20) sup

−r6s6t

|ηX(s) − ηX ǫ(s)|p(cid:21) 6 A′eA′t(kλεkp

L2(ν) + kλεkp

Lp(ν) + |Λ(ε)|p).

(2.36)

This can be easily seen by reexamining the proofs of Corollary 2.15 and Theorem 2.16.

3 Itô’s formula

In this section we aim at deriving Itô’s formula for the SFDDE’s studied in Section 2, which we
recall, have the form (2.1),

dX(t) = f (t, Xt)dt + g(t, Xt)dW (t) +ZR0

X0 = η ,

h(t, Xt, z) ˜N (dt, dz)

where Xt is the segment of the process X in [t − r, t], with r > 0 a ﬁnite delay, taking values in
a suitable path space, and X(t) ∈ Rd the present value of the process X. For the whole section
we work in the M p-framework and we further assume that the functionals f , g and h satisfy
assumptions of Lipschitz continuity and linear growth, such that equation (2.1) admits a unique
strong solution. Moreover, we assume that f , g and h are deterministic functionals, see Remark
2.9.

19

The main problem, when dealing with the SFDDE (2.1) is that the inﬁnite dimensional process
(Xt)t∈[0,T ] fails, in general, to be a semimartingale and standard Itô calculus does not apply. In
order to overcome this problem several approaches have been used in the literature.

The ﬁrst attempts go back to [36, 44] where an Itô-type formula for continuous SFDDE was
proved via Malliavin calculus. More recently, exploiting the concepts of horizontal derivative and
vertical derivative, a pathwise Itô calculus for non-anticipative stochastic diﬀerential equation was
derived in [12, 13].

In [20], an Itô formula for Banach-valued continuous processes was proved exploiting the cal-
culus via regularization, where an application to window processes (see [20, Deﬁnition 1.4]) is also
provided. Several works have followed studying Itô-type formulae for delay equations exploiting
the calculus via regularization and showing that the Banach-valued setting and the path-dependent
setting can be in fact connected, see, e.g. [14, 15]. Eventually, the connection between the Banach
space stochastic calculus and the pathwise calculus was made deﬁnitely clear in [16, 25].

We remark that the literature on Itô formulae by the calculus via regularization deals with
equations driven by continuous noises. In this paper, we focus on the SFDDE’s with jumps, thus
completing the existing literature in this respect. We have chosen to consider the approach of the
calculus via regularization, ﬁrst introduced in [41, 42], which was proved to be well-suited when
dealing with inﬁnite-dimensional processes or in the non-semimartingale case, see e.g. [14, 16, 17,
19, 20]. In particular, we prove an Itô formula for the SFDDE (2.1) with values in M p and we
show that our result is coherent with those of [36, 44]. In the Appendix we provide a connection
with the path-dependent calculus developed in [12, 13].

Recall that, for a ﬁnite delay r > 0, Lp := Lp([−r, 0]; Rd) endowed with the standard norm
k · kLp, p ∈ [2, ∞). In what follows we implicitly identify the topological dual of Lp, i.e. (Lp)∗,
with Lq being 1

q = 1, via the natural isomorphism given by

p + 1

J :Lq → (Lp)∗

g 7→ J(g) = qhg, ·ip,

where J(g) acts on Lp as follows

J(g)(f ) = qhg, f ip =Z 0

−r

g(s) · f (s)ds,

g ∈ Lq,

f ∈ Lp,

being · in the integral the usual scalar product in Rd. It is well-known that J is a continuous
linear isomorphism and hence, with a slight abuse of notation, we just write h ∈ (Lp)∗ when we
actually mean J −1(h) ∈ Lq, i.e. (Lp)∗ ∼= Lq.

Moreover, we denote by C1(Lp) the space of once Fréchet diﬀerentiable, not necessarily linear,
functionals F : Lp → R with continuous derivative, that is DF : Lp → L(Lp, R) where L(Lp, R)
denotes the space of continuous linear operators from Lp to R. Now, since F is R-valued, we
actually have that L(Lp, R) = (Lp)∗. Hence we can regard DF (f ), f ∈ Lp as an element in Lq
via J −1. In a summary, we identify DF (f ) with J −1(DF (f )) and simply write DF : Lp → Lq so
that

where the ﬁrst equality is, by an abuse of notation, meant as an identiﬁcation.

Also, recall that | · | denotes the Euclidean norm in Rd. Finally, recall that M p = Lp × Rd

endowed with the standard product norm.

Let the SFDDE

(dX(t) = f (t, Xt, X(t))dt + g(t, Xt, X(t))dW (t) +RR0

(X0, X(0)) = (η, x) ∈ M p ,

h(t, Xt, X(t))(z) ˜N (dt, dz) ,

(3.1)

for t ∈ [0, T ], T < ∞. We assume that f : [0, T ] × M p → Rd, g : [0, T ] × M p → Rd×m and
h : [0, T ] × M p × R0 → Rd×n satisfy Assumptions (L1) and (L2) so that Theorem 2.11 holds and
equation (3.1) admits a unique strong solution.

20

DF (f )(g) = qhDF (f ), gip =Z 0

−r

DF (f )(s) · g(s)ds,

f ∈ Lp,

g ∈ Lq,

In the sequel every process is indexed by the time t ∈ [0, T ] and following [20], if necessary, we

extend the process X = (X(t))t∈[0,T ] to the real line as follows

X(t) :=

0
X(t)
X(T )

for t < 0 ,
for t ∈ [0, T ] ,
for t > T ,

.

Next, we consider the deﬁnition of forward integral as given in [5, Deﬁnition 3.1].

Deﬁnition 3.1. Let X = {X(s), s ∈ [0, T ]} and Y = {Y (s), s ∈ [0, T ]} two Rd−valued process.
0 Y (s) ·dX(s) as the following

For every t ∈ [0, T ] we deﬁne the forward integral of Y w.r.t. X byR t

limit,

Y (s) · dX(s) := lim

Y (s) ·

ds ,

(3.2)

X(s + ǫ) − X(s)

ǫ

where the convergence is uniformly on compacts in probability (ucp).

Similarly, let X = {Xs, s ∈ [0, T ]}, and Y = {Ys, s ∈ [0, T ]}, be Lp-valued and Lq-valued
processes, respectively. For every t ∈ [0, T ] we deﬁne the Lp−forward integral of Y w.r.t. X as
the following limit,

Z t

0

ǫ↓0Z t

0

Ys(θ) · dXs(θ) := lim

Ys(θ) ·

Xs+ǫ(θ) − Xs(θ)

ǫ

dθds ,

(3.3)

where the convergence is uniformly on compacts in probability. We introduce the short-hand nota-
tion:

Z t
0 Z 0

−r

−r

ǫց0Z t
0 Z 0
qhYs, dXsip :=Z t
0 Z 0

−r

Z t

0

Ys(θ) · dXs(θ) .

Recall that a sequence of real-valued processes {X n}n>1 converges to a process X uniformly

on compacts in probability (ucp), if for each t ∈ [0, T ] we have that

sup
06s6t

|X n

s − Xs| → 0 ,

in probability. See e.g. [38, p.57]. In this section, if not otherwise stated, any limit will be taken
in the ucp sense.

Remark 3.2. Following [20], in Deﬁnition 3.1 we have considered the ucp limit since, being
the approximating sequence in the right-hand-side of equation (3.2) càdlàg, the ucp convergence
ensures that the limiting process, that is the forward integral, is also càdlàg.

Let us now introduce the notation we will use in the present work.

Deﬁnition 3.3. Let F : [0, T ] × Lp × Rd → R a given function, we say that

F ∈ C1,1,2(cid:0)[0, T ] × Lp × Rd(cid:1) ,

if F is continuously diﬀerentiable w.r.t. the ﬁrst variable, Fréchet diﬀerentiable with continuous
derivative w.r.t. the second variable, and twice continuously diﬀerentiable w.r.t. the third variable.
We thus denote by ∂t the derivative w.r.t. to time, DiF the Fréchet derivative w.r.t. the i-th
component of the segment Xt and ∂i the derivative w.r.t. the i-th component of the present state
X(t) and ﬁnally, ∂i,j the second order derivative w.r.t. the i, j-th component of X(t).

We will then deﬁne the Fréchet gradient w.r.t. the segment as

the gradient w.r.t. the present state

D := (D1, . . . , Dd) ,

∇x := (∂1, . . . , ∂d) ,

and the Hessian matrix w.r.t. the present state

∇2

x := (∂i,j)i,j=1,...,d .

21

Deﬁnition 3.4. Let η ∈ W 1,p([−r, 0]; Rd) =: W 1,p, then we deﬁne by ∂θ,iη and ∂+
θ,iη the weak
derivative and the right weak derivative, respectively, of the i-th component of η. Accordingly we
deﬁne the gradient as

∇θ := (∂θ,1, . . . , ∂θ,d) ,

resp. ∇+

θ :=(cid:16)∂+

θ,1, . . . , ∂+

θ,d(cid:17) .

Eventually, in proving Itô’s formula, we will need the notion of modulus of continuity of oper-

ators between inﬁnite-dimensional normed spaces.

Deﬁnition 3.5 (Modulus of continuity). Let (Y1, k · kY1) and (Y2, k · kY2) be two normed spaces
and F : Y1 → Y2 a uniformly continuous function. We deﬁne the modulus of continuity of F as

̟(ǫ) :=

sup

kF (y) − F (y′)kY2 ,

ǫ > 0.

ky−y′kY1 6ǫ

We thus have the following Itô’s formula for SFDDE (3.1).

R such that F ∈ C1,1,2(cid:0)[0, T ] × Lp × Rd(cid:1) and such that DF (t, η, x) ∈ W 1,q, (q such that 1

Theorem 3.6 (Itô’s formula). Let X be the solution to equation (3.1) and let F : [0, T ]×Lp×Rd →
q = 1)
for any t ∈ [0, T ], η ∈ Lp and x ∈ Rd and ∇θDF (t, ·, x) : Lp → Lq is uniformly continuous. Then
the following limit exists in the ucp sense,

p + 1

lim
ǫց0

1

ǫZ t

0

qhDF (s, Xs, X(s)), Xs+ǫ − Xsip ds =:Z t

0

qhDF (s, Xs, X(s)), dXsip.

(3.4)

Moreover, for t ∈ [0, T ], we have that

0

0
1

∇xF (s, Xs, X(s)) · dX(s) +

F (t, Xt, X(t)) = F (0, X0, X(0)) +Z t
∂tF (s, Xs, X(s))ds +Z t
+Z t
2Z t
T r(cid:2)g∗(s, Xs, X(s))∇2
+Z t
0 ZR0
−Z t
0 ZR0

∇xF (s, Xs, X(s))h(s, Xs, X(s))(z)N (ds, dz) ,

0

0

(F (s, Xs, X(s) + h(s, Xs, X(s))(z)) − F (s, Xs, X(s))) N (ds, dz)

qhDF (s, Xs, X(s)) , dXsip

xF (s, Xs, X(s))g(s, Xs, X(s))(cid:3) ds

(3.5)

holds, P -a.s., where we have denoted by T r the trace and by g∗ the adjoint of g and the fourth
term in equation (3.5) has to be intended component-wise, that is

Z t
0 ZR0
nXi=1Z t

:=

(F (s, Xs, X(s) + h(s, Xs, X(s))(z)) − F (s, Xs, X(s))) N (ds, dz)

0 ZR0(cid:0)F (s, Xs, X(s) + h·,i(s, Xs, X(s))(z)) − F (s, Xs, X(s))(cid:1) N i(ds, dz) .

Proof. Let t ∈ [0, T ]. First, observe that for ε > 0 small enough, we have

F (s + ǫ, Xs+ǫ, X(s + ǫ)) − F (s, Xs, X(s)) ds =

F (s, Xs, X(s))ds −

F (s, Xs, X(s)) ds =

(3.6)

F (s, Xs, X(s))ds −

F (s, Xs, X(s))ds ,

1

1

0

ǫZ t
ǫZ t+ǫ
ǫZ t+ǫ

ǫ
1

=

t

1

εZ t
ǫZ ǫ

0
1

0

22

which, by the continuity of F and the right-continuity of X(s) and Xs, s ∈ [0, T ], converges ucp
to

F (t, Xt, X(t)) − F (0, X0, X(0)) .

The ﬁrst part of (3.6) can be rewritten as

1

ǫZ t

0

F (s + ǫ, Xs+ǫ, X(s + ǫ)) − F (s, Xs, X(s)) ds

0

1

ǫZ t
|

+

+

=

F (s + ǫ, Xs+ǫ, X(s + ǫ)) − F (s, Xs+ǫ, X(s + ǫ)) ds

J 1
ǫ

{z

F (s, Xs+ǫ, X(s + ǫ)) − F (s, Xs+ǫ, X(s)) ds

}

J 2
ǫ

{z

F (s, Xs+ǫ, X(s)) − F (s, Xs, X(s)) ds

}

.

J 3
ǫ

{z

}

0

1

ǫZ t
|
ǫZ t
|

1

0

Following the same arguments as in the proof of [20, Theorem 5.2] we can show that

J 1

ǫ =Z t

0

lim
ǫց0

∂tF (s, Xs, X(s))ds,

ucp.

Let us now consider J 2

ǫ . A straightforward application of [5, Corollary 4.4] implies that

J 2

ǫ →Z t

0

0

1

+

2Z t
+Z t
0 ZR0
−Z t
0 ZR0

∇xF (s, Xs, X(s)) · dX(s)

T r(cid:2)g∗(s, Xs, X(s))∇2

xF (s, Xs, X(s))g(s, Xs, X(s))(cid:3) ds

(F (s, Xs, X(s) + h(s, Xs, X(s), z)) − F (s, Xs, X(s))) N (ds, dz)

∇xF (s, Xs, X(s))h(s, Xs, X(s), z)N (ds, dz) ,

as ǫ ց 0 .

Let us now show that

lim
ǫց0

J 3

ǫ =Z t

0

qhDF (s, Xs, X(s)) , dXsipds .

By an application of the inﬁnite-dimensional version of Taylor’s theorem of order one (see e.g. [45,

23

qhDF (s, Xs + τ (Xs+ǫ − Xs), X(s)) , Xs+ǫ − Xsip dτ ds

DF (s, Xs + τ (Xs+ǫ − Xs), X(s))(α) · (X(s + ǫ + α) − X(s + α))dαdτ ds

Ch. 4, Theorem 4.C]), we obtain

F (s, Xs+ǫ, X(s)) − F (s, Xs, X(s)) ds

0

0

0

1

1

1

1

−r

=

=

ǫZ t
ǫZ t
0 Z 1
0 Z 1
ǫZ t
0 Z 0
= −Z t
0 Z 0
ǫZ 1
−r(cid:0)DF (s, X τ
|
+Z t
ǫZ 1
0 Z 0
|
−Z t
ǫZ 1
0 Z 0
|

DF (s, X τ

DF (s, X τ

−r

−r

1

1

0

0

s,s+ǫ, X(s))(α + ǫ) − DF (s, X τ

s,s+ǫ, X(s))(α)(cid:1) · X(s + ǫ + α)dαdτ
}

ds

J 3,1

{z

ǫ

s,s+ǫ, X(s))(α + ǫ) · X(s + α + ǫ)dαdτ ds

J 3,2

{z

ǫ

}

ds ,

s,s+ǫ, X(s))(α) · X(s + α)dαdτ

J 3,2

{z

ǫ

}

(3.7)

where we have denoted by X τ
g(α) = α + ǫ to the ﬁrst term of J 3,2

ǫ

s,s+ǫ := Xs + τ (Xs+ǫ − Xs). We apply the change of variables

in Equation (3.7) in order to obtain

J 3,2
ǫ =

=

−

1

1

1

−r

−r+ǫ

ǫZ 1
0 Z ǫ
ǫZ 1
0 Z 0
ǫZ 1
0 Z ǫ
|
ǫZ 1
0 Z −r+ǫ
|

−r

1

0

−

DF (s, X τ

s,s+ǫ, X(s))(α) · X(s + α)dαdτ

DF (s, X τ

s,s+ǫ, X(s))(α) · X(s + α)dαdτ

DF (s, X τ

s,s+ǫ, X(s))(α) · X(s + α)dαdτ

DF (s, X τ

s,s+ǫ, X(s))(α) · X(s + α)dαdτ

.

J 3,2,1

ǫ

{z

J 3,2,2

ǫ

{z

}

}

We thus have, from the continuity of DF and the right-continuity of Xs, that

J 3,2,1
ǫ

lim
ǫց0

= DF (s, Xs, X(s))(0) · X(s) ,

J 3,2,2
ǫ

lim
ǫց0

= DF (s, Xs, X(s))(−r) · X(s − r) .

Let ∇θDF (s, X τ
W 1,q. Consider J 3,1
by Fubini’s theorem we have

ǫ

s,s+ǫ, X(s)) denote a version of the weak derivative of DF (s, X τ
s,s+ǫ, X(s)) ∈
. Using the mean value-theorem and interchanging the order of integration

J 3,1
ǫ =

=

1

1

α

−r

0 Z 0
ǫZ 1
−rZ α+ǫ
ǫZ 1
0 Z −r+ǫ
Z β
ǫZ 1
0 Z 0
−r+ǫZ β
ǫZ 1
0 Z ǫ
0 Z 0

β−ǫ

−r

1

1

+

+

β−ǫ

∇θDF (s, X τ

s,s+ǫ, X(s))(β) dβ · X(s + ǫ + α)dαdτ

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ

(3.8)

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ.

24

Now, we add and subtract integral terms so that the second integral on the right-hand side of

(3.8) goes from −r to 0, that is

J 3,1
ǫ =

+

−

β−ǫ

1

1

ǫZ 1
0 Z 0
−rZ β
0 Z ǫ
ǫZ 1
0 Z 0
ǫZ 1
0 Z −r+ǫ

−r

1

β−ǫ

Z −r

β−ǫ

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ

(3.9)

∇θDF (s, X τ

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ.

Then, Lebesgue’s diﬀerentiation theorem implies that the second and third integral on the right-
hand side of (3.9) converge to 0 as ǫ → 0. Concerning the ﬁrst integral on the right-hand side of
(3.9), we add and subtract the corresponding terms in order to have

1

1

=

β−ǫ

∇θDF (s, X τ

−rZ β
0 Z 0
ǫZ 1
ǫZ 1
0 Z 0
−r(cid:0)∇θDF (s, X τ
|
∇θDF (s, Xs, X(s))(β) · Z β
ǫZ 1
0 Z 0
|

{z

J 3,1,2

+

−r

1

ǫ

β−ǫ

J 3,1,1

ǫ

{z

X(s + ǫ + α)dα! dβdτ
}

.

s,s+ǫ, X(s))(β) · X(s + ǫ + α) dαdβdτ

s,s+ǫ, X(s))(β) − ∇θDF (s, Xs, X(s))(β)(cid:1) · Z β

β−ǫ

X(s + ǫ + α)dα! dβdτ
}

(3.10)

we have

Using Hölder’s inequality with exponents, p, q > 2, 1

p + 1

q = 1 on J 3,1,1

ǫ

|J 3,1,1

ǫ

|

0

6Z 1
6Z 1

0

k∇θDF (s, X τ

k∇θDF (s, X τ

−r(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
s,s+ǫ, X(s)) − ∇θDF (s, Xs, X(s))kLq dτ Z 0

s,s+ǫ, X(s)) − ∇θDF (s, Xs, X(s))kLq dτ kM [Xs]kLp,

ǫZ β+ǫ

1

β

p

dβ!1/p

Xs(α)dα(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where

M [Xs](β) := sup
ǫ>0

1

ǫZ β+ǫ

β

|Xs(α)| dα,

is the Hardy-Littlewood maximal operator, which is a (non-linear) bounded operator from Lp to
Lp, p > 1. Hence, we can apply Lebesgue’s dominated convergence theorem and the fact that by
Lebesgue’s diﬀerentiation we have

ǫց0 Z 0

lim

−r

1

ǫZ β

β−ǫ

|X(s + ǫ + α)|p dαdβ!1/p

= kXskLp.

The above arguments in connection with the uniform continuity of ∇θDF (s, Xs, X(s)) implies the
following estimate for J 3,1,1

: there is a constant C > 0 independent of ǫ such that

ǫ

|J 3,1,1

ǫ

| 6 C̟(ǫ)kXskLp → 0 ,

as ǫ → 0 ,

25

where ̟(ǫ) denotes the modulus of continuity of ∇θDF (s, ·, X(s)) from Deﬁnition 3.5. Further,
we can formally apply integration by parts to J 3,1,2

in order to obtain

ǫ

J 3,1,2
ǫ

=

1
ǫ

DF (s, Xs, X(s))(β) ·Z β

β−ǫ

Then it follows that

Xs+ǫ(α)dα(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

0

−r

−Z 0

−r

DF (s, Xs, X(s))(β) ·

Xs+ǫ(β) − Xs(β)

ǫ

dβ.

(3.11)

J 3,1,2
ǫ → DF (s, Xs, X(s))(−r) · X(s − r) − DF (s, Xs, X(s))(0) · X(s) − qhDF (s, Xs, X(s)) , dXsip,

as ǫ ց 0. Altogether, we have ﬁnally shown that

J 3

ǫ =Z t

0

lim
ǫց0

qhDF (s, Xs, X(s)) , dXsip .

This corresponds to (3.4). Hence, we conclude the proof.

In Appendix A.2 it is shown, exploiting the results obtained in [25], that the Itô formula (3.5)
is coherent with the Itô formula for path-dependent processes with jumps proved in [12], as well
as the results obtained in [25].

Let us consider the forward integral

Z t

0

qhDF (s, Xs, X(s)) , dXsip ,

introduced in Theorem 3.6, we want now to relate the forward integral to the operator introduced
in [44]. In fact, since the right-derivative operator introduced in Deﬁnition 3.4 is the inﬁnitesimal
generator of the left-shift semigroup introduced in [44], it can be shown that the forward inte-
gral does coincide, under some suitable regularity conditions, with the operator SF (s, Xs, X(s))
introduced in [44].

Proposition 3.7. Let X be the solution to equation (3.1) and let F : [0, T ] × Lp × Rd → R be such

is well-deﬁned as a limit in probability uniformly on compacts. Additionally, let us assume that
Xs ∈ W 1,p for every s ∈ [0, T ]. Then

that F ∈ C1,1,2(cid:0)[0, T ] × Lp × Rd(cid:1) and such that the forward integral deﬁned in Equation (3.4)
Z t

qhDF (s, Xs, X(s)) , dXsip =Z t

θ Xsipds =Z t

qhDF (s, Xs, X(s)) , ∇+

SF (s, Xs, X(s))ds

0

0

0

(3.12)

holds P -a.s., where SF (s, Xs, X(s)) is the operator introduced in [44, Section. 9].
Proof. Let Xs ∈ W 1,p. From the fundamental theorem of calculus for absolutely continuous
functions we have, P-a.s.,

lim
ǫց0

qhDF (s, Xs, X(s)) ,

− ∇+

θ Xsip

Xs+ǫ − Xs

ǫ

−r

lim

ǫց0Z 0
ǫց0Z 0

DF (s, Xs, X(s))(β) ·(cid:18) (X(s + ǫ + β) − X(s + β))
DF (s, Xs, X(s))(β) ·  1

ǫZ s+β+ǫ

= lim

∇θX(r)dr − ∇+

− ∇+

θ X(s + β)(cid:19) dβ
θ X(s + β)! dβ

s+β

−r

ǫ

Now, by Lebesgue’s dominated convergence theorem, which is justiﬁed by analogous arguments
as for the convergence of (3.10), we ﬁnally get

ǫց0Z 0

lim

−r

DF (s, Xs, X(s))(β) ·  1

ǫZ s+β+ǫ

s+β

∇θX(r)dr − ∇+

θ X(s + β)! dβ = 0.

26

Exploiting the standard deﬁnition of the Poisson random measure, we can now give another

formulation of the Itô formula (3.6).

Theorem 3.8 (Itô’s formula). Let the hypothesis of Theorem 3.6 hold, then

0

F (t, Xt, X(t)) = F (0, X0, X(0)) +Z t
∂tF (s, Xs, X(s))ds +Z t
+Z t
2Z t
0 Z t
T r(cid:2)g∗(s, Xs, X(s))∇2
+Xs6t

0
1

+

0

0

qhDF (s, Xs, X(s)) , dXsipds+

∇xF (s, Xs, X(s)) · dX(s)ds+

xF (s, Xs, X(s))g(s, Xs, X(s))(cid:3) ds+

F (s, Xs, X(s)) − F (s, Xs, X(s−)) − ∆X(s) · ∇xF (s, Xs, X(s)) ,

(3.13)

holds P -a.s., where the notation is as in Theorem 3.6 and ∆X(s) is the jump of the process X at
time s, namely

∆X(s) := X(s) − X(s−) .

Proof. It immediately follows from Theorem 3.6 and [2, Theorem 4.4.10].

Hereinafter, we state a crucial probabilistic property of the solution of SFDDE (2.1) which
is needed for the derivation of Feynman-Kac’s formula also stated below. As it is perceptible,
the ﬁnite-dimensional process (η,x)X(t), t ∈ [0, T ], (η, x) ∈ M p is not Markov, since the value of
(η,x)X(t) depends on the near past. Nevertheless, if we enlarge the state space and regard the
process X as a process of the segment, i.e. with inﬁnite-dimensional state space, in the present
case M p, then such process is indeed Markovian.

The proof follows almost immediately given the fact that the Markov property of the solution
is fully known for the case without jumps, i.e. h = 0, see [35, Theorem (III. 1.1)], which actually
follows from measure theoretical properties of the driving noise and not path or distributional
properties of it. More concretely, one would expect the Markov property of the solution to hold
if, for instance, the driving noises have independent increments which is the case in our setting.

In order to state the Markov property one is compelled to look at solutions starting at time
t1 > 0, that is we hereby consider (t1,η,x)Xt, t > t1, (η, x) ∈ M p, the segment of the solution
starting in (η, x) at times t1 > 0, i.e.

(t1,η,x)X(t) = η(0) +Z t
+Z t
t1ZR0

t1

f (s, (t1,η,x)Xs, (t1,η,x)X(s))ds +Z t
h(s,(t1,η,x) Xs, (t1,η,x)X(s), z)eN (ds, dz) ,

t1

g(s, (t1,η,x)Xs, (t1,η,x)X(s))dW (s)

for every t ∈ [t1, T ] and (t1,η,x)X(t) = η(t − t1) for every t ∈ [t1 − t, t1). Deﬁne further the family
of operators

T t1
t

: L2(Ω, Ft1; M p) −→ L2(Ω, Ft; M p)

(η, x) 7−→(cid:16)(t1,η,x)Xt, (t1,η,x)X(t)(cid:17) .

We denote Tt = T 0
and the family of operators {T t1

t . It turns out that, under hypotheses (L1) and (L2), T t1
t

is Lipschitz continuous

t }06t16t6T deﬁnes a semigroup on L2(Ω, M p), i.e.

Tt2(η, x) = T t1

t2 ◦ Tt1 (η, x),

for every 0 6 t1 6 t2 6 T and (η, x) ∈ L2(Ω, F0; M p). The latter property can easily be obtained
by showing that both sides of the identity solve the same SFDDE and the fact that solutions are
unique, see [35, Theorem (II. 2.2)] for the case h = 0.

27

Theorem 3.9 (The Markov property). Assume hypotheses (L1) and (L2) hold and (η,x)X(t),
t ∈ [0, T ], (η, x) ∈ M p denotes the unique strong solution of the SFDDE (2.1). Then the random
ﬁeld

describes a Markov process on M p with transition probabilities given by

n(cid:16)(η,x)Xt, (η,x)X(t)(cid:17) : t ∈ [0, T ], (η, x) ∈ M po

p(t1, (η, x), t2, B) = P(ω ∈ Ω, T t1

t2 (η, x)(ω) ∈ B),

for 0 6 t1 6 t2 6 T , (η, x) ∈ M p and Borel set B ∈ B(M p). In other words, for any (η, x) ∈
L2(Ω, F0; M p) and Borel set B ∈ B(M p), the Markov property

P(Tt2(η, x) ∈ B|Ft1 ) = p(t1, Tt1(η, x), t2, B) = P(Tt2(η, x) ∈ B|Tt1(η, x))

holds a.s. on Ω.

Proof. we can see that for every 0 6 t1 6 t2 6 T and every (η, x) ∈ M p, the mapping B 7→
p(t1, (η, x), t2, B) = P ◦ (T t1
t2 (η, x))−1(B), B ∈ B(M p) deﬁnes a probability measure on M p, since
the random variable T t1
t2 (η, x) : Ω → M p is (F , B(M p))-measurable. We would then like to show
that, if 0 6 t1 6 t2 6 T , then

P(cid:16)ω ∈ Ω : Tt2(η, x)(ω) ∈ B|Ft1(cid:17)(ω′) = p(t1, Tt1(η, x)(ω′), t2, B)

(3.14)

for almost all ω′ ∈ Ω, every Borel set B ∈ B(M p) and any (η, x) ∈ L2(Ω, F0; M p). The right-hand
side of (3.14) equals

ZΩ

1B(cid:18)(cid:0)T t1

t2 (Tt1 (η)(ω′))(cid:1) (ω)(cid:19)P(dω)

for almost all ω′ ∈ Ω. Hence, by the deﬁnition of conditional expectation, identity (3.14) is
synonymous with

ZA

1B (Tt2(η, x)(ω)) P(dω) =ZAZΩ

1B(cid:0)(cid:0)T t1

t2 (Tt1 (η, x)(ω′))(cid:1) (ω)(cid:1) P(dω)P(dω′)

(3.15)

for all A ∈ Ft1 and all B ∈ B(M p). In a summary, the main challenge is to verify relation (3.15)
which is stated in quite general terms.

Let Gt, t ∈ [0, T ] be the σ-algebra generated by {N ((s, u], B), t < s 6 u 6 T, B ∈ B(R0)}.
The key steps in proving (3.15) according to [35, Theorem (III. 1.1)] are the following. First, the
family of operators {Tt}t∈[0,T ] deﬁnes a semigroup on L2(Ω, M p). Secondly, the σ-algebras Ft and
Gt are independent for every t ∈ [0, T ], and {T t1
t (η, x)}t>t1 is adapted to {Ft ∩ Gt1 }t>t1, being
each Ft ∩ Gt1 independent of Ft1 . Finally, a key point to prove (3.15) is that one can ﬁrst prove

ZA

f (Tt2(η, x)(ω)) P(dω) =ZAZΩ

f(cid:0)(cid:0)T t1

t2 (Tt1 (η, x)(ω′))(cid:1) (ω)(cid:1) P(dω)P(dω′)

(3.16)

for any bounded continuous function f : M p → R. Then one can use a limit argument to show the
relation (3.15) for the case f = 1B being B just an open set of M p and eventually for any general
indicator function on Borel sets. The argument which transfers (3.16) into the case f = 1B for
any open set B in M p requires that the state space in consideration is separable so that 1B, being
B an open set of M p, can be approximated by uniformly continuous partitions of unity {fm}m∈N,
fm : M p → R such that
fm = 1B. All these properties above mentioned are indeed satisﬁed
in our framework.

lim
m→∞

Exploiting Itô’s formula from Theorem 3.6 together with the Markov property from Theorem

3.9, we can now prove a Feynman-Kac theorem for M p−valued SFDDE’s with jumps.

28



Theorem 3.10 (Feynman-Kac theorem). Let the hypothesis of Theorem 3.6 hold, then the fol-
lowing path-dependent partial integro-diﬀerential equation (PPIDE) holds

∂tF (t, η, x) = qhDF (s, η, x) , dηip + ∇xF (t, η, x) · f (t, η)

+ 1

2 T r(cid:2)g(t, η, x)g∗(t, η, x)∇2
+RR0

= Φ(η, x) ,

xF (t, η, x)(cid:3)

F (T, η, x)

(F (t, η, x + h(t, η)) − F (t, η, x) − ∇xF (t, η, x)h(t, η, x)) ν(dz) ,

(3.17)

with Φ ∈ C1,2(Lp × Rd), then we have

F (t, η, x) := E [ Φ(XT , X(T ))| Xt = η, X(t) = x] ,

t ∈ [0, T ] ,

(3.18)

where (Xt, X(t)) solves the SFDDE (3.1). If further Φ ∈ C1,2(Lp × Rd), then the converse holds
true, as well.

Proof. We have to show that if a function F : [0, T ] × Lp × Rd → R satisﬁes the PIDE (3.17), then
we have that equation (3.18) holds. Let us assume X is the unique solution to equation (3.1), as
in Section 2.2 we will use the notation (τ,η,x)X to denote the process with initial time τ ∈ [0, T ]
and initial value (η, x) ∈ M p. If F satisﬁes equation (3.17) by Itô’s formula (3.5) we have

F (T,(τ,η,x) XT ,(τ,η,x) X(T )) − F (τ, η, x)

τ

∇xF (s,(τ,η,x) Xs,(τ,η,x) X(s)) · g(s,(τ,η,x) Xs,(τ,η,x) X(s))dW (s)

=Z T
+Z T
τ ZR0(cid:16)F (s,(τ,η,x) Xs,(τ,η,x) X(s) + h(s,(τ,η,x) Xs,(τ,η,x) X(s)) ˜N (ds, dz)
−Z T
τ ZR0

F (s,(τ,η,x) Xs,(τ,η,x) X(s))(cid:17) ˜N (ds, dz) .

(3.19)

Taking now the expectation, exploiting the fact that the right-hand side of equation (3.19) has
null conditional expectation and using the terminal condition we have for any 0 6 τ < t 6 T ,

F (t, η, x) = E [ Φ(XT , X(T ))| Xt = η, X(t) = x] ,

and the ﬁrst implication is proved.

Conversely, let us now suppose equation (3.18) holds true, then from the Markov property
from Theorem 3.9 of the M p-valued process and the tower rule for the conditional expectation,
we have that for 0 6 τ < t 6 T ,

E [ F (t, Xt, X(t)) − F (τ, Xτ , X(τ ))| Xτ = η, X(τ ) = x] =
= E [ E [ Φ(XT , X(T ))| Xt, X(t)] − E [ Φ(XT , X(T ))| Xτ , X(τ )]| Xτ , X(τ )] =
= E [ Φ(XT , X(T ))| Xτ , X(τ )] − E [ Φ(XT , X(T ))| Xτ , X(τ )] = 0 .

On the other side, we can apply Itô’s formula (Theorem 3.6) to the function F , then we have that
for 0 6 τ < t 6 T ,

τ

τ

τ

1

∇xF (s, Xs, X(s)) · dX(s) +

F (t, Xt, X(t)) = F (τ, Xτ , X(τ )) +Z t
qhDF (s, Xs, X(s)) , dXsip +Z t
+Z t
2Z t
T r(cid:2)g∗(s, Xs, X(s))∇2
+Z t
τ ZR0
−Z t
τ ZR0
+Z t
τ ZR0

∇xF (s, Xs, X(s))h(s, Xs, X(s))(z)ν(dz) ds

(F (s, Xs, X(s) + h(s, Xs, X(s))(z)) − F (s, Xs, X(s))) ν(dz) ds

(F (s, Xs, X(s) + h(s, Xs, X(s))(z)) − F (s, Xs, X(s))) ˜N (ds, dz) .

∂tF (s, Xs, X(s))ds

τ

xF (s, Xs, X(s))g(s, Xs, X(s))(cid:3) ds

29

Then taking conditional expectation the PPIDE (3.17) holds true.

A Appendix

A.1 Kunita’s inequality

In section 2.3, we introduced a general version of Kunita’s inequality, (Corollary 2.12 in [34]). For
n = 1, this is a rewritten version of Corrolary 2.12 in [34]). Below, we explain how to extend the
reuslt to general n.

Proof of Lemma 2.6. Notice that since norms on Rn are equivalent, it holds that

for some constants C0, C1 depending only on n and q. We may assume that C0 > 1

, and

|aj|(cid:17)q

|aj|q,

nXj=1
(cid:0) nXj=1

6 C1

|aj|q 6 C0(cid:16) nXj=1
nXj=1
|aj|(cid:1)q
nXj=1(cid:0)ZR0

2

|H ,j(s, z)|2νj(dz)(cid:17) q
2(cid:17)q

= C0kH(s)kq

1

|H ,j(s, z)|2νj(dz)

L2(ν,Rd).

Then, if we write out "the columns wise" form of the ˜N -integral, we obtain

q

6 nq−1 sup
06u6t

q

H ,j(s, z) ˜N (ds, dz)(cid:12)(cid:12)(cid:12)

kH ,j(s)kLq(Ω,Lq(νj ,Rd)) + kH ,j(s)kLq(Ω,L2(νj ,Rd)) ds

sup

06u6t(cid:12)(cid:12)(cid:12)

nXj=1

kH ,j(s)kq

L2(νj ,Rd) =

6 nq−1

6 C0(cid:0) nXj=1ZR0
nXj=1Z u
0 ZR0
H ,j(s, z) ˜N (ds, dz)(cid:12)(cid:12)(cid:12)
nXj=1Z t
= nq−1Z t
Eh nXj=1
6 nq−1Z t
EhkH(s)kq
6 nq−1C0Z t

kH ,j(s)kq

kH(s)kq

0

0

0

0

nXj=1(cid:12)(cid:12)(cid:12)Z u
0 ZR0
L2(νj ,Rd)ids

L2(ν,Rd×n)ids

Lq(νj ,Rd) +

kH ,j(s)kq

nXj=1

Lq(ν,Rd×n) + C0kH(s)kq

Lq(Ω,Lq(ν,Rd×n)) + kH(s)kq

Lq(Ω,L2(ν,Rd×n))ds.

A.2 Connection with path-dependent calculus

In what follows we provide a connection between Itô’s formula (3.6) and the path-dependent Itô’s
formula given in [12, 13] which relies on the concepts of vertical and horizontal derivative, there
introduced. Let us ﬁrst set the notation we use in the current section.

Let (Ω, F , P ) be the probability space with Ω = D([0, T ], Rd) endowed with the P -augmented
(right-continuous) ﬁltration {Ft}t∈[0,T ] generated by the canonical process Y : [0, T ] × Ω → Rd,
Y (t, ω) = ω(t) and here F := FT .
In this setting we deﬁne, for every ω ∈ Ω and t ∈ [0, T ],
ωt := {ω(s), 0 6 s 6 t} ∈ D([0, t]), the trajectory up to time t. A stochastic process is a function
ϕ : [0, T ] × Ω → Rd, (t, ω) 7→ ϕ(t, ω). In addition, we say ϕ is non-anticipative if it is deﬁned on
D([0, t]; Rd), i.e. ϕ(t, ω) = ϕ(t, ωt) := ϕt(ωt).

30

Let ϕ = {ϕt, t ∈ [0, T ]} be a non-anticipative stochastic process and {ei}d

i=1 ⊂ Rd the canonical

basis, we deﬁne the so-called vertical derivative as the following (pathwise) limit

DV,iϕt(ωt) = lim
h→0

ϕt(ωhei

t

) − ϕt(ωt)
h

,

where ωhei
t means adding a jump of size h
at time t on the direction of ei and hence the name. We then deﬁne the vertical gradient of ϕt as

(s) := ωt(s) + hei1{t}(s), for every s ∈ [0, t]. Here, ωhei

t

Furthermore, we deﬁne the horizontal derivative as the following (pathwise) limit

DV ϕt =(cid:0)DV,1ϕt, . . . , DV,dϕt(cid:1) .

DH ϕt(ωt) = lim
hց0

ϕt+h(ωt,h) − ϕt(ωt)

h

,

where ωt,h(s) := ωt(s)1[0,t](s) + ωt(t)1(t,t+h](s), for every s ∈ [0, t + h]. Here, ωt,h is the extension
of the trajectory ωt on [0, t] to [0, t + h] by an horizontal line of length h at ωt(t) and hence the
name.

We consider a functional F : [0, T ] × D([0, T ]; Rd) → R which will act on processes ϕt. We say

F is non-anticipative if

F (t, ψ) = F (t, ψt) =: Ft(ψt),

for every non-anticipative stochastic process ψt. Next, we state an Itô formula for Ft(ψt) where
Ft is a non-anticipative functional which is once horizontally and twice vertically diﬀerentiable.
This result is taken from [12, Proposition 6].

Theorem A.1 (Functional Itô’s formula). Consider an Rd-valued non-anticipative stochastic pro-
cess ϕt which admits the following càdlàg semimartingale representation

ϕt = ϕ0 +Z t
0 Eh|µ(s)| + kσ(s)k2 +RR0
R T

for processes µ :

0

0

σ(s)dW (s) +Z t
0 ZR0

µ(s)ds +Z t
γ(s−, z)eN (ds, dz)
kγ(s, z)k2ν(dz)i ds < ∞ being k · k a matrix norm.

[0, T ] → Rd×m and γ :

[0, T ] → Rd, σ :

[0, T ] × R0 → Rd×n such that

Let F be a once horizontally and twice vertically diﬀerentiable non-anticipative functional sat-
isfying some technical continuity conditions on F (see [12, Proposition 6]), DV Ft, DV DV Ft and
DH Ft. Then for any t the following functional Itô formula holds P -a.s.

Ft (ϕt) = F0 (ϕ0) +Z(0,t]

DV Fs(ϕs− ) dX(s)

DH Fs(ϕs− )ds +Z(0,t]
T r(cid:2)σ∗(s)DV DV Fs(ϕs− )σ(s)(cid:3) ds
DV Fs(ϕs− )(cid:0)Fs(ϕs− + γ(s−, z)1{s}) − Fs(ϕs− ) − γ(s−, z)(cid:1) N (ds, dz) .

1
2

+Z(0,t]
+Z(0,t]ZR0

(A.1)

To be able to show that the path-dependent Itô’s formula (A.1) and the Itô’s formula from
Theorem 3.6 do coincide we need ﬁrst to connect the two settings. Such a link can be established
following [25], where the following operators are considered:

• the restriction operator, for every t ∈ [0, r]

Mt : D([−r, 0], Rd) → D([0, t], Rd) ,
Mt(f )(s) = f (s − t) ,

s ∈ [0, t) ,

31

• the backward extension operator, for every t ∈ (0, r)

Lt : D([0, t], Rd) → D([−r, 0], Rd) ,
Lt(f )(s) = f (0)1[−r,−t)(s) + f (t + s)1[−t,0)(s) ,

s ∈ [−r, 0) ,

Let us consider a non-anticipative functional b : [0, T ] × D([0, T ]; Rd) → R, b(t, ψ) = b(t, ψt) =:

bt(ψt) for any non-anticipative stochastic process ψ, then one can deﬁne a diﬀerent functionalbb

on [0, T ] × D([−r, 0]; Rd) × Rd as

(Xt, X(t)) ∈ D([−r, 0]; Rd) × Rd ,

bb(t, Xt, X(t)) := bt(cid:16) ˜MtXt(cid:17) ,

with

˜MtXt(s) :=(Mt(Xt)(s)

Xt(s)

if s ∈ [0, t)
if s = t

.

The converse holds true as well, in fact let us consider a given functionalbb on [0, T ]×D([−r, 0]; Rd),

then we can obtain a corresponding functional bt on D([0, t]; Rd) as

see [25] for details.

bt(ϕt) :=bb(t, Ltϕt, ϕt(t)) , ϕt ∈ D([0, t]; Rd) ,

(A.2)

We can now show how the vertical and horizontal derivatives can be written in terms of the
Fréchet derivative D and the derivative with respect to the present state. Part of the next theorem
was already established in [25, Theorem 6.1].

Proposition A.2. Consider a function F : [0, T ] × D([−r, 0]; Rd) → R and let us deﬁne ut :
D([0, t]; Rd) → R as above in (A.2) ut(Xt) := F (t, LtXt, X(t)). Then the i-th vertical derivative
DV,i of ut coincides with the derivative with respect to the present state X i(t) of F , namely

DV,iut(Xt) = ∂xiF (t, LtXt, X(t)) .

(A.3)

Furthermore, we have

ut(X hi

t ) − ut(Xt) = F (t, LtXt, X(t) + hi(t, LtXt, X(t)) − F (t, LtXt, X(t)) .

(A.4)

If we assume that Xt ∈ W 1,p, then

DH ut(Xt) = ∂tF (t, LtXt, X(t)) +(cid:10)DF (t, LtXt, X(t)), ∇+

θ LtXt(cid:11)D ,

holds, where the notation is given in Section 3.

Proof. Concerning (A.3) we have

DV,iut(Xt) = lim
h→0

= lim
h→0

1

1

1

t ) − ut(Xt)(cid:1) = lim

h(cid:0)ut(X h
h(cid:0)F (t, X(t) + h, LtX h

h(cid:0)F (t, LtX h

t , X h(t)) − F (t, LtXt, X(t))(cid:1)
t ) − F (t, X(t), LtXt)(cid:1) = ∂iF (t, X(t), LtXt) .

h→0

For what concerns (A.4), proceeding as in (A.6), we immediately have

(A.5)

(A.6)

ut(X hi

t ) − ut(Xt) = F (t, LtX hi

t

, X hi

(t)) − F (t, LtXt, X(t)) =

We refer to [25, Theorem 6.1] for a proof of equation (A.5)

= F (t, X(t) + hi, LtX hi

t ) − F (t, X(t), LtXt) .

32

In the framework of this section, exploiting the previous proposition we have that, for suitable
regular coeﬃcients, Itô’s formula from Theorem 3.6 and the path-dependent Itô’s formula in
Theorem A.1 coincide. In particular let us consider a process X evolving according to

(dXt = f (t, Xt)dt + g(t, Xt)dW (t) +RR0

X0 = η ,

h(t, Xt, z) ˜N (dt, dz) ,

(A.7)

for some suitably regular enough coeﬃcients f , g and h. Then proceeding as above we have that
Equation (A.7) can be written as a path dependent process

(dXt = ˆft(Xt)dt + ˆgt(Xt)dW (t) +RR0

X0 = η ,

ˆht(Xt) ˜N (dt, dz) ,

with ˆft, ˆgt and ˆht deﬁned as in (A.2). Then we have the following result.

Theorem A.3. Let F : [0, T ] × M p → R, F ∈ C1,1,2([0, T ] × D × Rd) and let us deﬁne ut :
D([0, t]; Rd) → R as in (A.2) ut(Xt) := F (t, LtXt, X(t)). Then Itô’s formula from Theorem 3.6
and the path dependent Itô’s formula from Theorem A.1 coincide.

Proof. It is straightforward from Proposition A.2 exploiting the backward extension operator Lt
and eventually using Itô’s formula from Theorem 3.6 and the path-dependent Itô formula from
Theorem A.1.

Acknowledgements

At its early stage, this research has beneﬁt of the sponsorship of the program Stochastics
in environmental Finance and Economics (SEFE) hosted at and funded by the Centre of Ad-
vanced Studies (CAS) of the Norwegian Academy of Science and Letters in the year 2014/15.
CAS is thanked for its generous support and nice working environment. This research was
completed within the NFR project FINEWSTOCH which is gratefully acknowledged.

References

[1] N. Agram and E. E. Røse. Optimal control of forward-backward mean-ﬁeld stochastic delayed

systems. arXiv:1412.5291.

[2] D. Applebaum. Lévy Processes and Stochastic Calculus, volume 116 of Cambridge Studies in

Advanced Mathematics. Cambridge University Press, Cambridge, second edition, 2009.

[3] M. Arriojas, Y. Hu, S.-E. Mohammed, and G. Pap. A delayed Black and Scholes formula.

Stoch. Anal. Appl., 25(2):471–492, 2007.

[4] S. Asmussen and J. Rosiński. Approximations of small jumps of Lévy processes with a view

towards simulation. J. Appl. Probab., 38(2):482–493, 2001.

[5] E. Bandini and F. Russo. Weak Dirichlet processes with jumps. arXiv:1512.06236.

[6] F. E. Benth, G. Di Nunno, and A. Khedher. Robustness of option prices and their deltas in

markets modelled by jump-diﬀusions. Commun. Stoch. Anal., 5(2):285–307, 2011.

[7] P. Billingsley. Convergence of Probability Measures. John Wiley & Sons Inc., New York, 1968.

[8] M.-H. Chang and R. K. Youree. The European option with hereditary price structures: basic

theory. Appl. Math. Comput., 102(2-3):279–296, 1999.

[9] M.-H. Chang and R. K. Youree. Inﬁnite-dimensional Black-Scholes equation with hereditary

structure. Appl. Math. Optim., 56(3):395–424, 2007.

33

[10] A. Chojnowska-Michalik. Representation theorem for general stochastic delay equations.

Acad. Pol. Sci., Ser. Sci. Math. Astron. Phys, 26:635–642, 1978.

[11] S. Cohen and J. Rosiński. Gaussian approximation of multivariate Lévy processes with ap-

plications to simulation of tempered stable processes. Bernoulli, 13(1):195–210, 2007.

[12] R. Cont and D.-A. Fournié. Change of variable formulas for non-anticipative functionals on

path space. Journal of Functional Analysis, 259(4):1043–1072, 2010.

[13] R. Cont and D.-A. Fournié. Functional Itô calculus and stochastic integral representation of

martingales. The Annals of Probability, 41(1):109–133, 2013.

[14] A. Cosso, C. Di Girolami, and F. Russo. Calculus via regularizations in Banach spaces and

Kolmogorov-type path-dependent equations. arXiv:1411.8000.

[15] A. Cosso and F. Russo. Functional Itô versus Banach space stochastic calculus and strict

solutions of semilinear path-dependent equations. arXiv:1505.02926.

[16] A. Cosso and F. Russo. A regularization approach to functional Itô calculus and strong-

viscosity solutions to path-dependent PDEs. arXiv:1401.5034.

[17] R. Coviello, C. Di Girolami, and F. Russo. On stochastic calculus related to ﬁnancial assets

without semimartingales. Bulletin des Sciences mathématiques, 135(6):733–774, 2011.

[18] K. R. Dahl, S.-E. A. Mohammed, B. Øksendal, and E. Røse. Optimal control of systems with

noisy memory and BSDEs with Malliavin derivatives. arXiv:1403.4034.

[19] C. Di Girolami and F. Russo. Generalized covariation and extended Fukushima decomposition
for Banach space-valued processes: applications to windows of Dirichlet processes. Inﬁnite
Dimensional Analysis, Quantum Probability and Related Topics, 15(02), 2012.

[20] C. Di Girolami and F. Russo. Generalized covariation for Banach space valued processes, Itô

formula and applications. Osaka J. Math., 51(3):729–783, 2014.

[21] O. Diekmann, S. A. Van Gils, S. V. Lunel, and H.-O. Walther. Delay equations: functional-,

complex-, and nonlinear analysis. Springer-Verlag, 1995.

[22] N. Dunford and J. T. Schwartz. Linear operators. Part I. Wiley Classics Library. John Wiley
& Sons, Inc., New York, 1988. General theory, With the assistance of William G. Bade and
Robert G. Bartle, Reprint of the 1958 original, A Wiley-Interscience Publication.

[23] B. Dupire. Functional Itô calculus. Bloomberg Portfolio Research paper, 2009.

[24] K.-J. Engel and R. Nagel. One-parameter semigroups for linear evolution equations, volume

194. Springer Science & Business Media, 2000.

[25] F. Flandoli and G. Zanco. An inﬁnite-dimensional approach to path-dependent Kolmogorov’s

equations. arXiv:1312.6165.

[26] M. Fuhrman, F. Masiero, and G. Tessitore. Stochastic equations with delay: optimal control
via BSDEs and regular solutions of Hamilton-Jacobi-Bellman equations. SIAM Journal on
Control and Optimization, 48(7):4624–4651, 2010.

[27] S. Janson and S. Kaijser. Higher moments of Banach space valued random variables. Mem.

Amer. Math. Soc., 238(1127):vii+110, 2015.

[28] Y. Kazmerchuk, A. Swishchuk, and J. Wu. A continuous-time Garch model for stochastic

volatility with delay. Can. Appl. Math. Q., 13(2):123–149, 2005.

[29] Y. Kazmerchuk, A. Swishchuk, and J. Wu. The pricing of options for securities markets with

delayed response. Math. Comput. Simulation, 75(3-4):69–79, 2007.

34

[30] A. Khedher. Computation of the delta in multidimensional jump-diﬀusion setting with ap-

plications to stochastic volatility models. Stoch. Anal. Appl., 30(3):403–425, 2012.

[31] J. Kiessling and R. Tempone. Diﬀusion approximation of Lévy processes with a view towards

ﬁnance. Monte Carlo Methods Appl., 17(1):11–45, 2011.

[32] Y. Kuang. Delay diﬀerential equations with applications in population dynamics, volume 191

of Mathematics in Science and Engineering. Academic Press, Inc., Boston, MA, 1993.

[33] U. Kuchler and E. Platen. Time delay and noise explaining cyclical ﬂuctuations in prices of

commodities. University of Technology, Sydney, 2007.

[34] H. Kunita. Stochastic diﬀerential equations based on Lévy processes and stochastic ﬂows of
diﬀeomorphisms. In Real and stochastic analysis, Trends Math., pages 305–373. Birkhäuser
Boston, Boston, MA, 2004.

[35] S. E. A. Mohammed. Stochastic Functional Diﬀerential Equations, volume 99 of Research

Notes in Mathematics. Pitman (Advanced Publishing Program), Boston, MA, 1984.

[36] S.-E. A. Mohammed. Stochastic diﬀerential systems with memory: theory, examples and
applications. In Stochastic analysis and related topics, VI (Geilo, 1996), volume 42 of Progr.
Probab., pages 1–77. Birkhäuser Boston, Boston, MA, 1998.

[37] K. R. Parthasarathy. Probability measures on metric spaces. Probability and Mathematical

Statistics, No. 3. Academic Press, Inc., New York-London, 1967.

[38] P. E. Protter. Stochastic Integration and Diﬀerential Equations, volume 21 of Stochastic

Modelling and Applied Probability. Springer-Verlag, Berlin, 2005.

[39] M. Reiß. Nonparametric estimation for stochastic delay diﬀerential equations. PhD thesis,

Humboldt-Universität zu Berlin, Mathematisch-Naturwissenschaftliche Fakultät II, 2002.

[40] M. Reiß, M. Riedle, and O. van Gaans. Delay diﬀerential equations driven by Lévy processes:

stationarity and Feller properties. Stochastic Process. Appl., 116(10):1409–1432, 2006.

[41] F. Russo and P. Vallois. The generalized covariation process and Itô formula. Stochastic

Process. Appl., 59(1):81–104, 1995.

[42] F. Russo and P. Vallois. Itô formula for C1-functions of semimartingales. Probab. Theory

Related Fields, 104(1):27–41, 1996.

[43] A. Swishchuk. Modeling and pricing of variance swaps for stochastic volatilities with delay.

Wilmott Magazine, 19(September):63–73, 2005.

[44] F. Yan and S. Mohammed. A stochastic calculus for systems with memory. Stoch. Anal.

Appl., 23(3):613–657, 2005.

[45] E. Zeidler. Applied Functional Analysis. Main Principles and Their Applications. Springer-

Verlag 1995. New York, third edition, 1995.

35

