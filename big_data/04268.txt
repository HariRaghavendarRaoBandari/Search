6
1
0
2

 
r
a

 

M
4
1
 
 
]

.

O
C
h
t
a
m

[
 
 

1
v
8
6
2
4
0

.

3
0
6
1
:
v
i
X
r
a

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS:

APPROXIMATE FACTORIZATION PROPERTY

PIOTR ´SNIADY

ABSTRACT. Jack characters are a generalization of the characters of
the symmetric groups; a generalization that is related to Jack symmetric
functions. We investigate the structure coefﬁcients for Jack characters;
they are a generalization of the connection coefﬁcients for the symmet-
ric groups. More speciﬁcally, we study the cumulants which measure
the discrepancy between these structure coefﬁcients and the simplistic
structure coefﬁcients related to the disjoint product. We show that Jack
characters satisfy approximate factorization property: their cumulants
are of very small degree and the character related to a given partition is
approximately equal to the product of the characters related to its parts.
This result will play a key role in the proof of Gaussianity of ﬂuctuations
for a class of random Young diagrams related to the Jack polynomials.

0. PROLOGUE

We study algebraic combinatorial problems related to Jack characters
Chπ, which form a natural family (indexed by partition π) of functions on
the set Y of Young diagrams. Jack characters can be viewed as a natural
deformation of the classical normalized characters of the symmetric groups;
a deformation that is associated with Jack symmetric functions. In order to
intrigue the Reader and to keep her motivated we shall present now some
selected highlights before getting involved in somewhat lengthy deﬁnitions
in the Introduction. We also postpone the bibliographic details.

Some Readers may prefer to fast forward directly to Section 0.11 where

concrete motivations for our research are discussed.

0.1. Structure coefﬁcients. The main problem which we address in cur-
rent paper is to understand the structure coefﬁcients of Jack characters.
More speciﬁcally, for any partitions π and σ one can uniquely express the

2010 Mathematics Subject Classiﬁcation. Primary 05E05; Secondary 05E10 20C30,

05E15,

Key words and phrases. Jack polynomials, Jack characters, structure coefﬁcients, ap-

proximate factorization of characters.

Version identiﬁer: 3a5fd52 .

1

2

PIOTR ´SNIADY

pointwise product of the corresponding Jack characters

(0.1)

Chπ Chσ =Xµ

gµ
π,σ(δ) Chµ

in the linear basis of Jack characters. The coefﬁcients gµ
π,σ(δ) ∈ Q[δ] in this
expansion are called structure coefﬁcients. Each of them is a polynomial in
the deformation parameter δ, on which Jack characters depend implicitly.
The existence of these polynomials is a non-trivial fact [DF16, Theorem
1.4]. For example,

Ch3 Ch2 = 6δ Ch3 + Ch3,2 +6 Ch2,1 +6 Ch4,
Ch3 Ch3 = (6δ2 + 3) Ch3 +9δ Ch2,1 +18δ Ch4 +3 Ch1,1,1 +

+ 9 Ch3,1 +9 Ch2,2 +9 Ch5 + Ch3,3 .

Exploration of the numerical examples such as the ones above suggests that
the structure coefﬁcients for Jack characters might have a rich algebraic and
combinatorial structure and encourages to state the following conjecture.

Conjecture 0.1 (Structure coefﬁcients of Jack characters). For any parti-
tions π, σ, µ the corresponding structure coefﬁcient

gµ
π,σ(δ) ∈ Q[δ]

is a polynomial with non-negative integer coefﬁcients.

0.2. Symmetric groups. As we already mentioned, Jack characters im-
plicitly depend on some deformation parameter. In the special case when
δ = 0 their structure coefﬁcients have a known, classical form which will
be discussed in the following.

Let us ﬁx an integer n ≥ 1. For a partition π = (π1, . . . , πℓ) we consider
a speciﬁc element of the symmetric group algebra C[S(n)]. This element
Aπ;n is equal (up to some normalization constants) to the indicator of the
conjugacy class in the symmetric group S(n), which consists of permuta-
tions with the cycle decomposition given by π; possibly with some addi-
tional ﬁxpoints. Impatient Readers may fast forward to Section 0.3 since
now we are going to present some ﬁne details of the deﬁnition of Aπ;n.

We deﬁne Aπ;n as the following formal combination of the permutations

[KO94, IK99, Bia03]:

Aπ;n =Xf

(f1,1, f1,2, . . . , f1,π1) · · · (fℓ,1, fℓ,2, . . . , fℓ,πℓ).

The above sum runs over injective functions

f : {(i, j) : 1 ≤ i ≤ ℓ, 1 ≤ j ≤ πi} → {1, . . . , n}.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

3

In other words, we ﬁll the boxes of the Young diagram π with the elements
of the set [n] := {1, . . . , n} in such a way that each number is used at most
once; for each ﬁlling we interpret the rows as cycles in the cycle decompo-
sition of the permutation.

The deﬁnition of the elements Aπ;n can be further improved by replacing
the notion of permutations by partial permutations [IK99]. This allows to
deﬁne some abstract conjugacy class indicators Aπ which are elements of
some suitable inverse limit and thus do not depend on n, the rank of the
symmetric group group S(n).

0.3. The case δ = 0 and the symmetric groups. One can show the fol-
lowing fact.

Fact 0.2. The specialization δ = 0 of the polynomials gµ
ture coefﬁcients for the family (Aπ) of the conjugacy class indicators.

π,σ gives the struc-

In other words:

AπAσ =Xµ

gµ
π,σ(0) Aµ,

where the product on the left-hand side is the usual convolution product in
the group algebra C[S(n)] (or, more precisely, the convolution product in
the semigroup algebra of partial permutations).

The above fact sheds some light on the structure coefﬁcients gµ

π,σ ∈ Q[δ].
Firstly, since the structure coefﬁcients for the conjugacy classes Aπ are non-
negative integers with a very well-understood combinatorial interpretation
(they are the connection coefﬁcients for the symmetric groups) [IK99], the
same can be said about the evaluation gµ

π,σ(0).

Secondly, the above Fact 0.2 suggests that a plausible explanation of Con-

jecture 0.1 would be the following one.

Conjecture 0.3. There exists some natural deformation of the symmetric
group algebra C[S(n)] which depends on the deformation parameter δ in
which the structure coefﬁcients for the hypothetical ‘conjugacy class indi-
cators’ are given by the structure coefﬁcients gµ

π,σ of Jack characters.

0.4. Kerov–Lassalle positivity conjecture, simplistic version. Free cu-
mulants R2, R3, . . . are a certain convenient family of functions on the set
of Young diagrams; they provide a description of the macroscopic shape of
a given Young diagram.

In this section it will be more convenient to use a different deformation
parameter on which the Jack characters depend implicitly; it is the variable
γ given by

Also free cumulants depend implicitly on γ.

γ = −δ.

4

PIOTR ´SNIADY

It has been proved by Lassalle [Las09a] that for each partition π there
exists a unique polynomial, called Kerov–Lassalle polynomial, which gives
the values of the Jack character Chπ. For example, in the simplest case
when the partition π = (k) consists of a single part,

Ch1 = R2,

Ch2 = R3 + R2γ,

Ch3 = R4 + 3R3γ + 2R2γ2 + R2,

Ch4 = R5 + 6R4γ + R2

2γ + 11R3γ2 + 6R2γ3 + 5R3 + 7R2γ.

Based on such numerical examples, Lassalle [Las09a] formulated the fol-
lowing challenging conjecture.

Conjecture 0.4 (Kerov–Lassalle positivity conjecture). For each integer
k ≥ 1 the polynomial which expresses the Jack character Chk in terms of
the variables γ, R2, R3, . . . has non-negative integer coefﬁcients.

Note that in the current paper we use a normalization of Jack characters
and free cumulants based on the paper of Doł˛ega and Féray [DF16] which
differs from the normalization from the original paper of Lassalle [Las09a].

0.5. Covariance for Jack characters. One can wonder if Conjecture 0.4
would hold true for Kerov–Lassalle polynomials corresponding to more
complicated Jack characters Chπ in the case when the partition π consists
of more than one part. Regretfully, this is not the case, as one can see on
the following simple example

(0.2) Ch2,2 =

R2

2 − 10R3γ − 6R2γ2 − 2R2

3 + 2R3R2γ + R2

2γ2 − 4R4 − 2R2

which contains both positive and negative coefﬁcients in the expansion. In
other words, Jack characters Chπ corresponding to such more complicated
partitions π are not the right quantities to consider and we should look for
a convenient replacement.

It turns out that for partitions π = (a, b) which consist of two parts,
instead of the character Cha,b it is more convenient to consider a kind of
covariance
(0.3)
For example, in the case considered in Eq. (0.2) above, the corresponding
Kerov–Lassalle polynomial is given by

κ•(Cha, Chb) := Cha,b − Cha Chb .

κ•(Ch2, Ch2) = −(cid:2)4R4 + 2R2

2 + 10R3γ + 6R2γ2 + 2R2(cid:3).

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

5

As one can see in this example, apart from a global change of the sign, the
positivity of the coefﬁcients is restored which supports the claim that the
covariance κ•(Cha, Chb) is indeed the right quantity.

The remaining question is: how to generalize these covariances (0.3) for
even more complicated partitions π? We shall address this question in the
following.

0.6. Cumulants in classical probability theory. A problem that is anal-
ogous to the one above appears in the probability theory: how to describe
the joint distribution of a family (Xi) of random variables in the most con-
venient way? A simple solution is to use the family of moments, which are
just the expected values of the products of the form

EXi1 · · · Xil.

However, the simplest solution is often not the best one, and this is also the
case here.

It has been observed that it is much more convenient to pass to some new
quantities, called cumulants or semi-invariants [Hal81, Fis28], which are
deﬁned as the coefﬁcients of the expansion of the logarithm of the multidi-
mensional Laplace transform around zero:

(0.4) κ(X1, . . . , Xn) = [t1 · · · tn] log Eet1X1+···+tnXn =

∂n

∂t1 · · · ∂tn

log Eet1X1+···+tnXn(cid:12)(cid:12)(cid:12)(cid:12)t1=···=tn=0

.

Each such a cumulant is a linear map with respect to each of its arguments.
There are many good reasons for claiming superiority of the cumulants
over the moments; we shall discuss very brieﬂy only one of them. Roughly
speaking, the convolution of measures corresponds to the product of the
Laplace transforms or, in other words, to the sum of the logarithms of the
Laplace transforms. It follows that the cumulants behave in a very simple
way with respect to the convolution, namely cumulants linearize the convo-
lution.

Cumulants allow also a combinatorial description: one can show that the

deﬁnition (0.4) is equivalent to the following system of equations:

(0.5)

E(X1 · · · Xn) =Xν Yb∈ν

κ(Xi : i ∈ b)

which should hold true for any choice of the random variables X1, . . . , Xn
for which all their moments are ﬁnite. The above sum runs over the set-
partitions ν of the set [n] and the product runs over the blocks of the partition

6

PIOTR ´SNIADY

ν (for missing deﬁnitions see Section 1.2). For example, we require that

E(X1) = κ(X1),

E(X1X2) = κ(X1, X2) + κ(X1)κ(X2),

E(X1X2X3) = κ(X1, X2, X3) + κ(X1)κ(X2, X3)

+ κ(X2)κ(X1, X3) + κ(X3)κ(X1, X2)
+ κ(X1)κ(X2)κ(X3),

...

(0.6)

(0.7)





0.7. Cumulants of Jack characters. We will use the above ideas from the
classical probability theory as a heuristic motivation for some new func-
tions κ•(Cha, . . . , Chz) on the set of Young diagrams, for arbitrary integers
a, b, c, . . . ≥ 1. Roughly speaking, we rewrite the system of equations (0.6)
as follows: for the random variables X1 = Cha, X2 = Chb, . . . we take
the Jack characters corresponding to partitions with only one part (‘single
letter’). As the moment on the left-hand side of (0.6) we take the Jack char-
acter corresponding to the partition equal to the concatenation of the letters.
For example,

Cha = κ•(Cha),

Cha,b = κ•(Cha, Chb) + κ•(Cha)κ•(Chb),

Cha,b,c = κ•(Cha,b,c) + κ•(Cha)κ•(Chb, Chc)

+ κ•(Chb)κ•(Cha, Chc) + κ•(Chc)κ•(Cha, Chb)
+ κ•(Cha)κ•(Chb)κ•(Chc),

...

We shall revisit this deﬁnition in Section 1.12.

The system of equations (0.7) can be iteratively solved. For example,

κ•(Cha) = Cha,

κ•(Cha, Chb) = Cha,b − Cha Chb,

...



in other words the ﬁrst cumulant κ•(Cha) coincides with the usual Jack
character and the second cumulant κ•(Cha, Chb) coincides with the covari-
ance (0.3).

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

7

These cumulants are in the focus of the current paper. In the following
Sections 0.8–0.10 we shall discuss a couple of ways in which the following
rather vague claim can be made concrete.
Vague Claim 0.5. The cumulants κ• have a much nicer structure than Jack
characters themselves.

0.8. Kerov–Lassalle conjecture for the cumulants. The ﬁrst advantage
of the cumulants over the characters is related to positivity. For example,
Kerov–Lassalle polynomial for one of the cumulants is given by

(0.8) κ•(Ch2, Ch2, Ch2) = 40R5 + 64R3R2 + 176R4γ + 96R2

2γ+

256R3γ2 + 80R3 + 120R2γ3 + 104R2γ

which should be compared to the analogous expression for the correspond-
ing character:

(0.9) Ch2,2,2 = R3

2γ2 − 6R3R2
2

3 + 3R2

3R2γ − 12R4R3 + 3R3R2

− 30R2
3γ − 12R4R2γ + R3
58R3R2 + 176R4γ − 18R2

2γ3 − 6R3
2γ3 + 90R2

2γ + 40R5 − 48R3R2γ2+
2γ + 256R3γ2 + 80R3+

120R2γ3 + 104R2γ.

The coefﬁcients on the right-hand side of (0.8) are all positive, which is a
great advantage from the perspective of an algebraic combinatorialist. This
positivity does not hold for (0.9). Based on such numerical evidence, Las-
salle [Las09a] stated the following conjecture which is an extension of Con-
jecture 0.4.

Conjecture 0.6 (Kerov–Lassalle positivity conjecture). For all integers
k1, . . . , kℓ ≥ 1 the polynomial which expresses the (signed) cumulant

(−1)ℓ−1κ•(Chk1, . . . , Chkℓ)

in terms of the variables γ, R2, R3, . . . has non-negative integer coefﬁ-
cients.

Clearly, this conjecture gives some support to Claim 0.5.

0.9. Structure coefﬁcients revisited. One can show that the product (0.1)
is always of the form

Chπ Chσ = Chπσ + · · · ,

where the product πσ denotes the concatenation of the partitions. In other
words, the corresponding structure coefﬁcient

is particularly simple.

gπσ
π,σ = 1

8

PIOTR ´SNIADY

It follows that Conjecture 0.1 is equivalent to the following statement:

each (signed) coefﬁcient (−1)dµ

π,σ ∈ Q[δ] in the expansion

κ•(Chπ, Chσ) = Chπσ − Chπ Chσ =Xµ

dµ
π,σ(δ) Chµ

is a polynomial in δ with non-negative integer coefﬁcients. The left-hand
side is a generalization of the covariance (0.3) to the case when partitions
π and σ have more than one part. In particular, Conjecture 0.1 is a special
case ℓ = 2 of the following more general conjecture.

Conjecture 0.7. For partitions π1, . . . , πℓ we consider the expansion

κ•(Chπ1, . . . , Chπℓ) =Xσ

dσ
π1,...,πℓ(δ) Chσ .

Then (−1)ℓ−1dσ

π1,...,πℓ ∈ Q[δ] is a polynomial with non-negative integer

coefﬁcients.

For example,

κ•(Ch2, Ch2, Ch2) =

(8δ2 + 8) Ch2 +8δ Ch1,1 +64δ Ch3 +64 Ch2,1 +40 Ch4 .

Clearly, Conjecture 0.7 gives support and some meaning to our vague
Claim 0.5. Conjecture 0.7 also gives some support to the viewpoint that the
coefﬁcients dµ
are a kind of structure coefﬁcients on steroids which we
shall adapt in the following.

π1,...,πℓ

0.10. The main result: approximate factorization of Jack characters.
Our vague Claim 0.5 that the cumulants κ• have a much nicer structure than
Jack characters themselves can be made concrete in yet another way which
will be the core of the current paper. We start with an observation that the
expression (0.8) for the cumulant is less complex and thus more beautiful
than the corresponding expression (0.9) for the character. On a very silly
level, comparison of complexity of two formulas is just a measurement of
the amount of ink necessary to write each of them.

A more clever way is to deﬁne a ﬁltration by declaring that the degrees

of the variables are given by

deg Rn = n
deg γ = 1.

for each n ≥ 2;

According to this approach, the complexity of an expression is measured by
its degree according to this ﬁltration.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

9

In our example,

is given by
deg κ•(Ch2, Ch2, Ch2) = 5 which is indeed much smaller than the degree
of the corresponding moment (0.9), given by deg Ch2,2,2 = 9.

the degree of

the cumulant

(0.8)

The following theorem is the main result of the current paper.

Theorem 0.8 (The main result: approximate factorization of Jack charac-
ters). For any partitions π1, . . . , πℓ the corresponding cumulant is of much
smaller degree than one would expect:

deg κ•(Chπ1, · · · , Chπℓ) ≤ deg Chπ1···πℓ −2(ℓ − 1).

We will prove this result in an equivalent but more fancy formulation
as Theorem 1.9. We refer to this result as approximate factorization of
characters because, informally speaking, it states that the character corre-
sponding to the concatenation π1 · · · πℓ of partitions is approximately equal
to the product of the characters Chπi corresponding to each of the partitions
separately:

Chπ1,...,πℓ ≈ Chπ1 · · · Chπℓ .

0.11. Motivations.

0.11.1. Structure coefﬁcients. Until now we have recalled some old conjec-
tures (Conjectures 0.4 and 0.6) and we have stated some new conjectures
(Conjectures 0.1 and 0.7). From the perspective of an algebraic combina-
torialist they provide a purely aesthetic motivation for investigation of the
and Kerov–Lassalle polynomials
structure coefﬁcients on steroids dµ
π1,...,πℓ
for κ•(Cha, . . . , Chz) with a, . . . , z ≥ 1.

Our main result, Theorem 0.8 gives some partial answer to Conjecture 0.7,
namely it gives some non-trivial upper bound on the degree of the polyno-
mial dµ
π1,...,πℓ ∈ Q[δ] or, in other words, it shows that some concrete co-
efﬁcients of this polynomial are indeed non-negative integers (to be more
speciﬁc: zero). In the same spirit, Theorem 0.8 sheds also some light on
Conjecture 0.6.

0.11.2. Some special structure coefﬁcients. From the perspective of enu-
merative combinatorics, proving non-negativity and integrality of some num-
bers by showing that they are equal to zero, might be somewhat disappoint-
ing. On the bright side, our main Theorem 0.8 can be also used for some
more positive enumerative results:
in a forthcoming paper [Bur16] Bur-
chardt gives an explicit combinatorial interpretation for the coefﬁcients of
high-degree monomials in the deformation parameter δ for some special
choices of the partitions. The simplest coefﬁcient for which Burchardt’s
results are applicable is

[δk+l+1−m]g(m)

(k),(l)

10

PIOTR ´SNIADY

for integers k, l, m ≥ 1.

0.11.3. Jack polynomials. The motivations which we discussed above, ﬁt
all into the category “no matter what Jack characters are and where they
come from, they seem to give rise to interesting combinatorics”. However,
there are also some good self-standing reasons for studying Jack charac-
ters: they come from the fact that — as the name itself suggests — Jack
characters are related to Jack polynomials.

π (cid:1) (indexed by an integer

Henry Jack [Jac71] introduced a family(cid:0)J (α)

partition π) of symmetric functions which depend on an additional param-
eter α. During the last forty years, many connections of these Jack poly-
nomials with various ﬁelds of mathematics and physics were established:
it turned out that they play a crucial role in understanding Ewens random
permutations model [DH92], generalized β-ensembles and some statistical
mechanics models [OO97], Selberg-type integrals [Kan93], certain random
partition models [BO05], and some problems of the algebraic geometry
[Oko03], among many others. Better understanding of Jack polynomials
is also very desirable in the context of generalized β-ensembles and their
discrete counterpart model [DF16]. Jack polynomials are a special case of
the celebrated Macdonald polynomials which “have found applications in
special function theory, representation theory, algebraic geometry, group
theory, statistics and quantum mechanics” [GR05].

We expand Jack polynomial in the basis of power-sum symmetric func-

tions:

(0.10)

J (α)

λ =Xπ

θ(α)
π (λ) pπ.

The above sum runs over partitions π such that |π| = |λ|. The coefﬁcient
θ(α)
π (λ) is called unnormalized Jack character; with the right choice of the
normalization it becomes the normalized Jack character Chπ(λ) (the details
of this relationship will be given in Deﬁnition 1.1). Thus Jack characters
θ(α)
(respectively, Chπ) provide a kind of dual information about the Jack
π
polynomials; a better understanding of the combinatorics of Jack characters
may lead to a better understanding of Jack polynomials themselves.

0.11.4. Connection coefﬁcients for Jack symmetric functions. A simplistic
version of the structure coefﬁcients which we study in the current paper can
be traced back to the work of Goulden and Jackson [GJ96, Eqs. (1) and (5)]
who considered the following expansion of the left-hand side in terms of

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

11

the power-sum symmetric functions:

1

hJθ, Jθiα

Xθ∈P

J (α)

θ

(x)J (α)

θ

(y)J (α)

θ

(z)t|θ| =

Xn≥1

tn Xλ,µ,ν⊢n

cλ
µ,ν
αℓ(λ)

|Cλ|
n!

pλ(x)pλ(y)pλ(z).

It is worth pointing out that the coefﬁcients (cλ

For the missing notation we refer to the original work of Goulden and Jack-
son. The coefﬁcients cλ
µ,ν in this expansion depend implicitly on the defor-
mation parameter α; Goulden and Jackson argued that they can be viewed
as a generalization of the connection coefﬁcients for the symmetric groups.
µ,ν) are indexed by three
partitions of the same size while the quantities (gλ
µ,ν) considered in the
current paper and in [DF16] are indexed by triples of arbitrary partitions.
Doł˛ega and Féray [DF16, Section 4.2 and Appendix B.2] investigated the
relationship between these two families of coefﬁcients; in particular they
found [DF16, Eq. (21)] an explicit formula which gives (cλ
µ,ν) in terms of
(gλ

µ,ν).
Thus a better understanding of the structure coefﬁcients (gλ

µ,ν) might shed
some light on the open problems stated by Goulden and Jackson and, in
particular, on b-conjecture [GJ96, Conjecture 3.5].

0.11.5. Gaussian ﬂuctuations for Jack-deformed random Young diagrams.
Our personal motivation for proving Theorem 0.8 comes from a forthcom-
ing joint paper with Doł˛ega [D´S16]. The latter paper has a purely prob-
abilistic ﬂavor: it concerns some random Young diagrams related to Jack
polynomials. We show there that the ﬂuctuations of these random Young
diagrams around the limit shapes are asymptotically Gaussian. This result
is a generalization of the results from our previous paper [´Sni06a] to a much
more general class of probability distributions related to Jack polynomials
and Jack deformation. One of these probability distributions is, for exam-
ple, Plancherel–Jack measure for which the Gaussianity of ﬂuctuations was
proved only very recently [DF16].

The main result of the current paper, Theorem 0.8, is the key technical

tool which will be necessary in [D´S16].

1. INTRODUCTION

1.1. Partitions. A partition λ = (λ1, . . . , λl) is deﬁned as a weakly de-
creasing ﬁnite sequence of positive integers. If λ1 + · · · + λl = n we also
say that λ is a partition of n. We also deﬁne

|λ| := λ1 + · · · + λl

12

PIOTR ´SNIADY

and say that ℓ(λ) := l is the number of parts of λ and that

mi(λ) :=(cid:12)(cid:12){k : λk = i}(cid:12)(cid:12)

is the multiplicity of i ≥ 1 in the partition λ.

For an integer n ≥ 0 we denote by Pn the set of all partitions of the

number n. We denote by

the set of all partitions.

When dealing with partitions we will use the shorthand notation

P := Gn≥0

Pn

1l := (1, . . . , 1

).

l times

| {z }

For partitions π1, π2, . . . , πk we deﬁne their product π1 · · · πk as their con-

catenation.

The expression Young diagram is fully synonymous to the expression
partition. However, for aesthetical reasons we will use each of them in a
different context. Since partitions are used in order to enumerate conjugacy
classes of the symmetric groups while Young diagrams in order to enumer-
ate irreducible representations of the symmetric groups, similarly the Jack
character Chπ(λ) depends on the partition π and on the Young diagram λ.
The empty partition as well as the empty Young diagram will be denoted

by the same symbol ∅.

1.2. Set-partitions. We say that ν = {ν1, . . . , νl} is a set-partition of some
set X if ν1, . . . , νl are disjoint, non-empty sets such that

νi = X.

G1≤i≤l

We refer to the sets ν1, . . . , νl as blocks of the set-partition ν.

1.3. Normalized Jack characters, the ﬁrst deﬁnition. In this section we
shall present the deﬁnition of Jack characters Chπ which appeared histori-
cally as the ﬁrst one and which is based on the notion of Jack polynomials.
The results of this paper will not refer to this deﬁnition; for this reason the
Readers faint at heart, who do not appreciate Jack polynomials too much
may fast forward to Section 1.4 where we start preparation for an alterna-
tive, equivalent, self-contained deﬁnition of Chπ.

The usual way of viewing the characters of the symmetric groups is to
ﬁx the representation λ and to consider the character as a function of the
conjugacy class π. However, there is also another very successful viewpoint
due to Kerov and Olshanski [KO94], called dual approach, which suggests

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

13

to do roughly the opposite. Lassalle [Las08, Las09a] adapted this idea to
the framework of Jack characters.

In order for this dual approach to be successful (both with respect to the
usual characters of the symmetric groups and for the Jack characters) one
has to choose the most convenient normalization constants. In the current
paper we will use the normalization introduced by Doł˛ega and Féray [DF16]
which offers some advantages over the original normalization of Lassalle.
Thus, with the right choice of the multiplicative constant, the unnormalized
Jack character θ(α)
λ (π) from (0.10) becomes the normalized Jack character
Ch(α)

π (λ), deﬁned as follows.

Deﬁnition 1.1. Let α > 0 be given and let π be a partition. The normalized
Jack character Ch(α)
(1.1)

π (λ) is given by:

m1(π)

(cid:0)|λ|−|π|+m1(π)
zπ =Yi

imi(π) mi(π)!

π (λ) :=(α− |π|−ℓ(π)

0

2

Ch(α)

where

π,1|λ|−|π|(λ)

(cid:1) zπ θ(α)

if |λ| ≥ |π|;
if |λ| < |π|,

is the standard numerical factor. The choice of an empty partition π = ∅ is
acceptable; in this case Ch(α)

∅ (λ) = 1.

The above deﬁnition and, in particular, the choice of the normalization
factors may at the ﬁrst sight appear repulsive even for the Readers who
appreciate Jack polynomials. Later on, in Deﬁnition 1.5 we shall see that
thanks to this choice of the normalization Jack characters allow a convenient
alternative description.

1.4. The deformation parameters. In order to avoid dealing with the square
root of the variable α we introduce an indeterminate A such that

A2 = α.

Jack characters are usually deﬁned in terms of the deformation parameter
α. After the substitution α := A2 each Jack character becomes a function of
A; in order to keep the notation light we will make this dependence implicit
and we will simply write Chπ(λ).

The algebra of Laurent polynomials in the indeterminate A will be de-

noted by Q [A, A−1].

Deﬁnition 1.2. For an integer d we will say that a Laurent polynomial

f =Xk∈Z

fkAk ∈ Q(cid:2)A, A−1(cid:3)

14

PIOTR ´SNIADY

is of degree at most d if fk = 0 holds for each integer k > d.

A special role will be played by the quantity

(1.2)

γ := −A +

1
A

∈ Q(cid:2)A, A−1(cid:3) .

1.5. α-content. For drawing Young diagrams we use the French conven-
tion and the usual Cartesian coordinate system; in particular, the box (x, y) ∈
N2 is the one in the intersection of the column with the index x and the row
with the index y. We index the rows and the columns by the elements of the
set

N = {1, 2, . . . }

of positive integers; in particular the ﬁrst row as well as the ﬁrst column
correspond to the number 1.

Deﬁnition 1.3. For a box (cid:3) = (x, y) of a Young diagram we deﬁne its
α-content by

α-content((cid:3)) = α-content(x, y) := Ax −

1
A

y ∈ Q(cid:2)A, A−1(cid:3) .

1.6. The algebra P of α-polynomial functions, the ﬁrst deﬁnition. In
our recent paper [´Sni15, Deﬁnition 1.5] we have deﬁned a ﬁltered algebra
P, which is called the algebra of α-polynomial functions. This algebra
consists of certain functions on the set Y of Young diagrams with values
in the ring Q [A, A−1] of Laurent polynomials. The following deﬁnition
speciﬁes P as a set and deﬁnes the ﬁltration on it.

Deﬁnition 1.4. For an integer d ≥ 0 we say that

F : Y → Q(cid:2)A, A−1(cid:3)

is an α-polynomial function of degree at most d if there exists a sequence
p0, p1, . . . of polynomials which satisﬁes the following properties:

• for each k ≥ 0 we have that pk ∈ Q[γ, c1, . . . , ck] is a polynomial

in the variables γ, c1, . . . , ck of degree at most d − 2k;

• for each Young diagram λ,

F (λ) =Xk≥0 X(cid:3)1,...,(cid:3)k∈λ

pk(γ, c1, . . . , ck) ∈ Q(cid:2)A, A−1(cid:3) ,

where the second sum runs over all tuples of boxes of the Young
diagram; furthermore

c1 := α-content((cid:3)1),

. . . ,

ck := α-content((cid:3)k)

are the corresponding α-contents, and the substitution (1.2) is used.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

15

The multiplication in P was understood in [´Sni15] as the pointwise

product of the functions.

1.7. Jack characters, the second deﬁnition. One of the main results of
our recent work [´Sni15, Theorem 1.7] is the equivalence between Deﬁni-
tion 1.1 and the following abstract deﬁnition of Jack characters which does
not refer to the notion of Jack polynomials.

Deﬁnition 1.5. Jack character Chπ is the unique α-polynomial function F
which fulﬁlls the following properties:

(K1) F ∈ P is an α-polynomial function of degree at most |π| + ℓ(π);
(K2) for each m ≥ 1 the function in m variables

Y ∋ (λ1, . . . , λm) 7→ F (λ1, . . . , λm) ∈ Q(cid:2)A, A−1(cid:3)

is a polynomial of degree |π| and its homogeneous top-degree part
is equal to

A|π|−ℓ(π) pπ(λ1, . . . , λm),

where pπ is the power-sum symmetric polynomial;

(K3) for each Young diagram λ ∈ Y such that |λ| < |π| we have

F (λ) = 0;

(K4) for each Young diagram λ ∈ Y the evaluation F (λ) ∈ Q [A, A−1] is

a Laurent polynomial of degree at most |π| − ℓ(π).

Roughly speaking, conditions (K1), (K2) and (K4) specify the asymp-

totic behavior of the character Chπ(λ) in three kinds of limits:

• when the shape of the Young diagram λ tends to inﬁnity together

with the variable γ,

• when the rows λ1, λ2, . . . of the Young diagram tend to inﬁnity,
• when the deformation parameter A tends to inﬁnity;

on the other hand condition (K3) is of quite different ﬂavor because it con-
cerns the values of the Jack character on small Young diagrams.

16

PIOTR ´SNIADY

Example 1.6. By easily checking that the conditions from Deﬁnition 1.5 are
fulﬁlled, one can verify the following equalities:

Ch∅(λ) = 1,

1,

2(c1 + γ),

Ch1(λ) = X(cid:3)1∈λ
Ch2(λ) = X(cid:3)1∈λ
Ch3(λ) = X(cid:3)1∈λ(cid:18)3(c1 + γ)(c1 + 2γ) +
Ch1,1(λ) = X(cid:3)1∈λ

(−1) + X(cid:3)1,(cid:3)2∈λ

1,

where γ is given by (1.2).

3

2(cid:19) + X(cid:3)1,(cid:3)2∈λ(cid:18)−

3

2(cid:19) ,

1.8. The algebra P of α-polynomial functions, the second deﬁnition.
Proposition 1.7 ([´Sni15, Proposition 2.17]). The family of functions
(1.3)

γp Chπ : Y → Q(cid:2)A, A−1(cid:3)

over integers p ≥ 0 and partitions π ∈ P is linearly independent over Q.

The linear space of the elements of P of degree at most d is spanned

(over Q) by the elements (1.3) such that

p + |π| + ℓ(π) ≤ d.

In other words, if we take Jack characters Chπ as a primitive notion (for
example, by using Deﬁnition 1.1) one can deﬁne the linear structure of P
as the free Q[γ]-module with the linear basis given by Jack characters Chπ.
With this approach, the degrees of the generators are given by

(1.4)

(cid:26) deg Chπ = |π| + ℓ(π),

deg γ = 1.

1.9. Algebra P• of α-polynomial functions with the disjoint product •.
The set P of α-polynomial functions can be equipped with another mul-
tiplication •, called disjoint product, which is deﬁned on the linear base of
Jack characters by concatenation (see the end of Section 1.1) of the corre-
sponding partitions

(γp Chπ) • (γq Chσ) := γp+q Chπσ .

It is easy to check that this product is commutative and associative; the set
of α-polynomial functions equipped with this multiplication becomes an
algebra which will be denoted by P•. It is easy to check that the usual

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

17

ﬁltration (1.4) works ﬁne also with this product; in this way P• becomes a
ﬁltered algebra.

1.10. Conditional cumulants. Let A and B be commutative unital alge-
bras and let E : A → B be a unital linear map. We will say that E is a
conditional expectation value; in the literature one usually imposes some
additional constraints on the structure of A, B and E, but for the purposes
of the current paper such additional assumptions will not be necessary.
For any tuple x1, . . . , xn ∈ A we deﬁne their conditional cumulant as
κB
A(x1, . . . , xn) = [t1 · · · tn] log Eet1x1+···+tnxn =

∂n

∂t1 · · · ∂tn

log Eet1x1+···+tnxn(cid:12)(cid:12)(cid:12)(cid:12)t1=···=tn=0

∈ B

where the operations on the right-hand side should be understood in the
sense of formal power series in variables t1, . . . , tn.
1.11. Approximate factorization property. The following deﬁnition is
key for the current paper.
Deﬁnition 1.8. Let A and B be ﬁltered unital algebras and let E : A → B be
A the corresponding cumulants.
a conditional expectation; we denote by kB
We say that E has approximate factorization property if for all choices of
x1, . . . , xl ∈ A we have that

deg kB

A(x1, . . . , xl) ≤ deg x1 + · · · + deg xl − 2(l − 1).

1.12. The main result: conditional cumulants between the disjoint and
the usual product. We consider the ﬁltered unital algebras P• and P, and
as a conditional expectation between them we take the identity map:

id

P.

P•

(1.5)
This structure may appear to be misleadingly simple. Note, however, that
even though P• and P are equal as vector spaces, they are furnished
with different multiplication structures: the disjoint product • and the usual
pointwise product of functions, respectively. For this reason this identity
map is far from being trivial.

We denote by κ• the conditional cumulants related to the conditional ex-
pectation (1.5). Informally speaking, this cumulant quantiﬁes how big is
the discrepancy between the two multiplications on the set of α-polynomial
functions: the disjoint product • and the usual pointwise multiplication of
functions.

Based on Proposition 1.7, the main result of the current paper, Theo-
rem 0.8, can be equivalently reformulated in the following more abstract
way.

18

PIOTR ´SNIADY

Theorem 1.9 (Equivalent formulation of the main result). The identity map

P•

id

P.

has approximate factorization property.

In other words, for any partitions π1, . . . , πl ∈ P the corresponding con-

ditional cumulant

is of degree at most

κ•(Chπ1, · · · , Chπl) ∈ P

|π1| + · · · + |πl| + ℓ(π1) + · · · + ℓ(πl) − 2(l − 1).

The proof will be presented in Section 2.11.

1.13. History of the result.

π

1.13.1. Approximate factorization for the characters of the symmetric groups.
The normalized Jack characters Ch(α)
are a generalization of the usual nor-
malized characters of the symmetric groups Ch(1)
[Las09a, DF16]; one of
π
the manifestations of this phenomenon was discussed in Fact 0.2. This clas-
sical context when the deformation parameter is specialized to α = 1 carries
more algebraic, representation-theoretic and combinatorial structures than
the general case of Jack characters and Jack polynomials; for this reason
much more is known in this case. We shall review this special case α = 1
from the perspective of approximate factorization of Jack characters (The-
orem 1.9).

First of all, the algebra P for α = 1 still makes sense but it becomes
an algebra of functions on the set Y of Young diagrams with values in the
rational numbers Q. We denote this algebra by P (1), respectively by P (1)
in the case when as the multiplication we take the disjoint product •. There
is no need to speak about the indeterminate γ (which becomes now a con-
stant, equal to zero). Also our deﬁnition of the ﬁltration on P is remains
valid for α = 1; thus P (1) and P (1)
are ﬁltered algebras. As a conse-
•
quence, the statement of Theorem 1.9 is well-deﬁned in this case and takes
the following concrete form.

•

Theorem 1.10. The identity map

(1.6)

id

P (1)

•

P (1).

has approximate factorization property.

In other words, for any partitions π1, . . . , πl ∈ P the corresponding con-

ditional cumulant

κ•(cid:16)Ch(1)

π1

, · · · , Ch(1)

πl(cid:17) ∈ P (1)

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

19

is a linear combination (with rational coefﬁcients) of normalized characters
of the symmetric groups Ch(1)

π over partitions π such that
|π| + ℓ(π) ≤ |π1| + · · · + |πl| + 2 − l.

This result is much simpler than our original goal, Theorem 1.9 and sev-

eral of its proofs are available; we shall review them in the following.

1.13.2. Approximate factorization via multiplication of partial permuta-
tions. Consider the conditional expectation deﬁned as the inverse of the
identity map from (1.6):

(1.7)

P (1)

•

id

P (1).

We shall denote by κ• the corresponding cumulants.

Remark 1.11. There are two different cumulants (namely κ• and κ•) which
measure the discrepancy between the two products which are available in
P (1). This might be quite confusing and, indeed, there is some confusion
in the literature around this issue. As far as we know, the cumulant κ• is
considered only in the papers [´Sni06a, ´Sni06b] while the cumulant κ• is
considered in the remaining articles in the ﬁeld, including [R´S08, Fér09,
DF´S10, F´S11]. Regretfully, the papers [DF´S10, Fér09] wrongfully claim
that [´Sni06a] concern the cumulants κ•.

The difference between κ• and κ• is that the roles played by the disjoint

product and the pointwise product are interchanged. For example,

κ•(Chπ1, Chπ2) = Chπ1 • Chπ2 − Chπ1 Chπ2 = Chπ1,π2 − Chπ1 Chπ2

while

κ•(Chπ1, Chπ2) = Chπ1 Chπ2 − Chπ1 • Chπ2 = Chπ1 Chπ2 − Chπ1,π2 .

For a larger number of arguments the difference between κ• and κ• becomes
more complicated than just a change of the sign.

We previously proved the the following result.

Theorem 1.12 ([´Sni06a, Theorem 15]). The map (1.7) has approximate
factorization property.

Formally speaking, Theorem 1.10 in its exact formulation does not ap-
pear in [´Sni06a], but it is not very difﬁcult to use Brillinger’s formula
(Lemma 2.11 below) in order to show that Theorem 1.10 and Theorem 1.12
are equivalent. We leave the details to the Reader.

The proof of Theorem 1.12 from [´Sni06a] was based on the ideas which
we discussed in Sections 0.2 and 0.3. More speciﬁcally, for each integer

20

PIOTR ´SNIADY

n ≥ 1 the algebra of functions on the set of Young diagrams with n boxes
is isomorphic (via noncommutative Fourier transform) to the center of the
symmetric group algebra C[S(n)] with the product given by convolution.
The image of the character Ch(1)
π under this isomorphism is equal, up to
some simple multiplicative constant, to the indicator function of the conju-
gacy class in S(n) of the permutations with the cycle decomposition given
by π. This means that the problem of understanding the pointwise multipli-
cation of functions on Y can be translated into the problem of understanding
convolution of conjugacy classes in the symmetric group algebra.

This observation can be further improved if, instead of the usual permu-
tations, one uses partial permutations of Ivanov and Kerov [IK99]. In this
way the above isomorphism becomes a map between the algebra P (1) and
a certain semigroup algebra of partial permutations. The advantage of this
viewpoint comes from the fact that the disjoint product in P (1)
corresponds
under this isomorphism to the disjoint product of partial permutations. This
means that our original problem of understanding the relationship between
the pointwise and the disjoint product in P is equivalent to ﬁnding the anal-
ogous relationship between the convolution product and the disjoint product
in the algebra of partial permutations and for the latter problem one can ﬁnd
some explicit formulas.

•

One can ask whether this strategy of proof could be used to prove our
goal, Theorem 1.9. In order to do this we would have to ﬁnd some concrete,
convenient algebra (which should be some generalization and deformation
of the group algebra of the symmetric group, respectively, the algebra of
the semigroup of partial permutations), the representation theory of which
would be given by Jack characters. Existence of such an algebra is the
content of Conjecture 0.3.

Regretfully, not much is known about the combinatorics of the structure
coefﬁcients for Jack characters [DF16, Bur16]; the structure of the hypo-
thetical deformation of the group algebra of the symmetric group remains
even more elusive. Thus this path of proving Theorem 1.9 is currently not
available.

1.13.3. Approximate factorization via explicit formulas for the characters.
Another way of proving Theorem 1.10 is to start with some formula for the
characters Ch(1)
π of the symmetric groups. A good choice is a formula which
was conjectured by Stanley [Sta06], proved by Féray [Fér09] and reformu-
lated in a convenient way in our joint paper with Féray [F´S11, Theorem 2].
The second step is to use the above formula in order to get a closed formula
for the cumulants κ•, see [Fér09, Section 1.6] and [DF´S10, Theorem 4.7].

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

21

The third and the ﬁnal step is to use the latter formula for κ• in order to ﬁnd
a suitable upper bound for the degree of these cumulants.

Regretfully, in the case of general Jack characters Ch(α)

the problem of
ﬁnding a convenient closed formula still remains elusive [DF´S14, ´Sni15]
and this path of proving Theorem 1.9 is currently not available.

π

1.14. How to prove the main result? New product ⊗. We start with a
heuristic overview of the general strategy for proving Theorem 1.9.

1.14.1. The vanishing property. Condition (K3) in the abstract deﬁnition
of Jack character Chπ (Deﬁnition 1.5) states that

(1.8)

Chπ(λ) = 0

if |λ| < |π|.

Clearly, this vanishing property is a trivial consequence of the way normal-
ized Jack characters were deﬁned via Jack polynomials (Deﬁnition 1.1);
the interesting part is that (1.8) can be seen as a system of a sufﬁcient num-
ber of linear equations which is necessary in order to characterize the Jack
character uniquely.

This observation gives rise to the following natural question: would it be
possible to mimic these ideas and to ﬁnd an abstract characterization of
the cumulants κ• which would be analogous to Deﬁnition 1.5? Regretfully,
already in the simplest non-trivial example

(1.9)

κ•(Cha, Chb) = Cha,b − Cha Chb,

where a, b ≥ 1 are some integers we encounter a serious difﬁculty: the van-
ishing condition (1.8) for Jack characters implies that the analogous condi-
tion for the cumulant

(1.10)

(cid:0)κ•(Cha, Chb)(cid:1)(λ) = 0

holds true only for relatively small Young diagrams λ such that |λ| <
max(a, b).
In other words, (1.10) gives rise to too few linear equations
in order to characterize κ•(Cha, Chb) uniquely. For our purposes it would
be more preferable to have (1.10) (or some its analogue) for all Young dia-
grams λ such that |λ| < a + b.

1.14.2. New product ⊗. The source of our problems is the pointwise prod-
uct of functions which enters the second summand on the right-hand side of
(1.9). This motivates investigation of some new product ⊗ of functions on
Y which would have the following desirable property.

22

PIOTR ´SNIADY

Property 1.13. Assume that a, b ≥ 0 are integers and F, G : Y → Q [A, A−1]
are functions on the set Y of Young diagrams such that
(1.11)

F (λ) = 0

holds true for all λ ∈ Y such that |λ| < a,
holds true for all λ ∈ Y such that |λ| < b.

G(λ) = 0

Then

(F ⊗ G)(λ) = 0

holds true for all λ ∈ Y such that |λ| < a + b.

A convenient example of a product with this property, the separate prod-
uct, will be presented in Section 2.4. This product gives rise to new cumu-
lants κ⊗

• , for example:
κ⊗
• (Cha, Chb) = Cha,b − Cha ⊗ Chb .
As a consequence of Property 1.13, the cumulants κ⊗

• have an advantage

that an analogue of the vanishing property
(1.12)
holds true for all Young diagrams such that |λ| < a + b; in other words
(1.12) gives a sufﬁcient number of linear equations in order to understand
the cumulants κ⊗

(cid:0)κ⊗
• (Cha, Chb)(cid:1)(λ) = 0

• well.

1.14.3. Three ﬁltered algebras. Regretfully, the cumulants κ⊗
• are not the
ones which we want to understand in Theorem 1.9. For this reason we will
• to the cumulants κ• and to
need to relate the properties of the cumulants κ⊗
show that they are not far one from the other.

To summarize; we consider three products of functions on Y, namely:
the disjoint product •, the pointwise product, and the separate product ⊗.
These three products correspond to the three algebras in the following com-
mutative diagram:

(1.13)

P•

id

P

id

id

R⊗

Each of the three arrows in this diagram can be viewed as a conditional ex-
pectation between commutative unital algebras, thus it gives rise to some
conditional cumulants. Our original goal (proving Theorem 1.9) corre-
sponds to understanding the cumulants κ• which correspond to the hori-
zontal arrow. However, the discussion from the above Section 1.14.2 shows
• which correspond to the diagonal arrow have some
that the cumulants κ⊗

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

23

advantages. Our general strategy will be make advantage of the commu-
tative diagram (1.13) and of the nice properties of the cumulants which
correspond to the diagonal arrow and to the vertical one.

2. PROOF OF THEOREM 1.9

2.1. Towards the proof: Lemma 2.3. The proof of Theorem 1.9 is cen-
tered around Lemma 2.3 which was stated and proved in our recent paper
[´Sni15, Theorem 7.2] for quite different purposes, but it turns out to be also
well-suited for the problems studied in the current paper. Roughly speak-
ing, Lemma 2.3 provides a criterion for verifying that a given α-polynomial
function F ∈ P which a priori is of some high degree, in fact turns out
to be of some smaller degree (which is, obviously, the context of Theo-
rem 1.9).

We shall start in Section 2.2 by gathering the deﬁnitions which are nec-
essary to state Lemma 2.3. In Section 2.3 we state the key Lemma 2.3.
In Sections 2.4–2.10 we will verify that the assumptions of Lemma 2.3 are
indeed fulﬁlled in our context of the proof of Theorem 1.9. Finally, in Sec-
tion 2.11 we apply Lemma 2.3 and in this way we prove Theorem 1.9.

2.2. Notations.

2.2.1. Extension of the domain of functions on Y. Let F be a function on
the set of Young diagrams. Such a function can be viewed as a function
F (λ1, . . . , λℓ) deﬁned for all non-negative integers λ1 ≥ · · · ≥ λℓ. We will
extend its domain, as follows.

Deﬁnition 2.1. If (ξ1, . . . , ξℓ) is an arbitrary sequence of non-negative inte-
gers, we denote

F sym(ξ1, . . . , ξℓ) := F (λ1, . . . , λℓ),

where (λ1, . . . , λℓ) ∈ Y is the sequence (ξ1, . . . , ξℓ) sorted in the reverse
order λ1 ≥ · · · ≥ λℓ. In this way F sym(ξ1, . . . , ξℓ) is a symmetric function
of its arguments.

2.2.2. The difference operator.

Deﬁnition 2.2. If F = F (λ1, . . . , λℓ) is a function of ℓ arguments and 1 ≤
j ≤ ℓ, we deﬁne a new function ∆λj F by

(cid:0)∆λj F(cid:1) (λ1, . . . , λℓ) :=

F (λ1, . . . , λj−1, λj + 1, λj+1, . . . , λℓ) − F (λ1, . . . , λℓ).

We call ∆λj a difference operator.

24

PIOTR ´SNIADY

2.3. The key lemma. The assumptions of the following lemma may ap-
pear complicated. Condition (Z1), (Z2) and (Z2) have been been modeled
after the analogous conditions from the abstract characterization of Jack
characters (Deﬁnition 1.5). Only condition (Z3) is more mysterious:
it
turns out to be a version of (Z3) crafted in such a way that condition (Z3)
holds true for any α-polynomial function F ∈ P which is of order at most
n + r − 1 (see Lemma 2.13).
Lemma 2.3 ([´Sni15, Theorem 7.2]). Let integers n ≥ 0 and r ≥ 1 be given
and let F : Y → Q [A, A−1] be a function on the set of Young diagrams.
Assume that:

(Z1) F ∈ P is of degree at most n + r;
(Z2) for each m ≥ 1 the function in m variables

Y ∋ (λ1, . . . , λm) 7→ F (λ1, . . . , λm) ∈ Q(cid:2)A, A−1(cid:3)

is a polynomial of degree at most n − 1;

(Z3) the equality

(2.1)

[An+r−2k]∆λ1 · · · ∆λk F sym(λ1, . . . , λk) = 0

holds true for the following values of k and λ:

• k = r and λ = (λ1, . . . , λr) ∈ Y with at most r rows is such

that |λ| ≤ n + r − 2k − 1;

• k > r and λ = (λ1, . . . , λk) ∈ Y with at most k rows is such

that |λ| ≤ n + r − 2k;

(Z4) for each λ ∈ Y, the Laurent polynomial F (λ) ∈ Q [A, A−1] is of

degree at most n + 1 − r.

Then F ∈ P is of degree at most n + r − 1.

Alternative version: the result remains valid for all integers n ≥ 0 and
r ≥ 0 if the assumption (Z2) is removed and the condition (Z3) is replaced
by the following one:
(Z3a) the equality (2.1) holds true for all k ≥ r and λ = (λ1, . . . , λk) ∈ Y

with at most k rows such that |λ| ≤ n + r − 2k.

As we shall see, only assumption (Z3) will turn out to be troublesome in
our context of the proof of Theorem 1.9. Sections 2.4–2.10 will be devoted
entirely to proving that this assumption indeed holds true.

2.4. The strategy: row functions. Our strategy in showing that the as-
sumption (Z3) holds true will be based on the ideas which we already dis-
cussed in Section 1.14. Namely, we will introduce a convenient ﬁltered
vector space which consists of some functions on the set Y of Young dia-
grams, with values in Laurent polynomials Q [A, A−1]. This linear space of

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

25

row functions can be equipped with the following two distinct multiplica-
tion structures.

Firstly, as a product we may take the usual pointwise multiplication of
functions. In this way we obtain the ﬁltered algebra R which was intro-
duced and studied in our recent paper [´Sni15, Section 6]. Heuristically, the
algebra R consists of the functions which behave with respect to condi-
tion (Z3) in an analogous way as α-polynomial functions. In particular, we
shall prove that P ⊆ R, furthermore the multiplicative structure and the
ﬁltration structure of both algebras are compatible with each other. In other
words, the passage from P to R causes no difﬁculties.

Secondly, as a product on the linear space of row functions we may take a
new separate product ⊗ which was crafted in such a way that Property 1.13
holds true. This gives rise to a ﬁltered algebra R⊗ which is the bottom node
in the diagram (1.13).

Thus, we have two multiplicative structures on the vector space of row
functions. This naturally calls for investigation of the cumulants related to
the conditional expectation

(2.2)

R

id

R⊗

which would measure the discrepancy between these two multiplicative
structures. Because of the nice properties of the inclusion P ⊆ R in-
vestigation of the conditional expectation (2.2) is almost the same as inves-
tigation of the vertical arrow in (1.13) which is our intermediate goal for
proving that condition (Z3) holds true.

We shall present the details in the following.

2.5. Row functions.

Deﬁnition 2.4. Let a sequence (indexed by r ≥ 0) of symmetric functions
fr : Nr

0 → Q [A, A−1] be given, where

N0 = {0, 1, 2, . . . }.

We assume that:

• if 0 ∈ {x1, . . . , xr} then fr(x1, . . . , xr) = 0,
• fr = 0 except for ﬁnitely many values of r,

26

PIOTR ´SNIADY

• there exists some integer d ≥ 0 with the property that for all r ≥ 0
and all x1, . . . , xr ∈ N0, the evaluation fr(x1, . . . , xr) ∈ Q [A, A−1]
is a Laurent polynomial of degree at most d − 2r.

We deﬁne a function F : Y → Q [A, A−1] given by

(2.3)

F (λ) :=Xr≥0 Xi1<···<ir

fr(λi1, . . . , λir ).

We will say that F is a row function of degree at most d and that (fr) is the
convolution kernel of F .

As we already mentioned, we deﬁne R as the set of row functions equipped
with the pointwise product of functions; one can show [´Sni15, Lemma 6.4]
that with this product R becomes a ﬁltered algebra.

We deﬁne R⊗ as the set of row functions equipped with the separate

product ⊗. It is deﬁned on the linear basis by declaring

Xi1<···<il
Xk1<···<kl+m

f (λi1, . . . , λil) ⊗ Xj1<···<jm
Xi1<···<il

j1<···<jm

{k1,...,kl+m}={i1,...,il}⊔{j1,...,jm}

g(λj1, . . . , λjm) :=

f (λi1, . . . , λil)g(λj1, . . . , λjm)

;

}

|

hl+m(λk1

,...,λkl+m )

{z

we extend this deﬁnition by bilinearity to general elements of R⊗. In other
words, the separate product is deﬁned by a kind of a tensor product of the
corresponding convolution kernels. This product is well-deﬁned since the
convolution kernel is uniquely determined by the row function (see [´Sni15,
Remark 6.2]).

It is a very simple exercise to check that the algebra R⊗ equipped with

the notion of degree from Deﬁnition 2.4 becomes a ﬁltered algebra.

2.6. Approximate factorization property for the vertical arrow. The
conditional cumulants which correspond to the vertical arrow in (1.13) will
be denoted by κ⊗.

Proposition 2.5. The vertical arrow from (1.13) has approximate factoriza-
tion property.
Proof. In [´Sni15, Lemma 6.5] it has been proved that the algebra of α-
polynomial functions P is a subalgebra of R (as a side remark: this implies
also that the diagonal and the vertical arrows in (1.13) are well-deﬁned);
also P and R are equipped with the same multiplication. Furthermore, it
has been proved there that each α-polynomial function F ∈ P which —

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

27

regarded as an element of P — is of degree at most d was proved there
also to be — this time regarded as an element of R — of degree at most d.
This fact implies that it is enough to show a stronger result that the map
(2.2) has approximate factorization property. The remaining part of this
section will be devoted to the proof of the latter result; it is stated as Propo-
sition 2.8.
(cid:3)

2.6.1. Closed formula for the cumulants κ⊗. Since this does not lead to
confusion, the cumulants for the vertical arrow in (1.13) and for the map
(2.2) will be denoted by the same symbol κ⊗.

Our goal in this section will be to ﬁnd a closed formula for the cumulant
κ⊗(x1, . . . , xn) for x1, . . . , xn ∈ R. By linearity of cumulants we may
assume that for each value of the index i, the function xi ∈ R has the form

(2.4)

xi(λ) = Xj

(i)
1 <···<j

(i)
m(i)

gi(cid:18)λ

, . . . , λ

j

j

(i)
1

m(i)(cid:19) .

(i)

It follows that the pointwise product of functions is given by

(2.5)

(x1 · · · xn)(λ) =

Xj

(1)
1 <···<j

(1)
m(1)

· · · Xj

(n)
1 <···<j

m(n) Y1≤i≤n

(n)

gi(cid:18)λ

, . . . , λ

j

(i)
1

m(i)(cid:19) .

(i)

j

Let us ﬁx some summand on the right-hand side. We denote

(2.6)

J (i) := {j(i)

1 , . . . , j(i)

m(i)}

and consider the graph G with the vertex set [n] = {1, 2, . . . , n} the ele-
ments of which correspond to the factors; we draw an edge between the
vertices a and b if the sets J (a) and J (b) are not disjoint. The connected
components of the graph G deﬁne a certain partition of the set [n].

It follows that the right-hand side of (2.5) can be written in the form

(2.7)

x1 · · · xn =Xν Yb∈νfκ⊗(xi : i ∈ b),

where the sum runs over all set-partitions π of the set [n] and the product

of a prescribed connected component of the graph G, i.e.

runs over the blocks of π. In the above formulafκ⊗ denotes the contribution
(2.8) (cid:16)fκ⊗(xi1, . . . , xil)(cid:17) (λ1, λ2, . . . ) :=
m(ik )(cid:19)
· · · Xj

m(il) Y1≤k≤l

Xj

(i1)
1 <···<j

gik(cid:18)λ

(il)
1 <···<j

, . . . , λ

(i1)
m(i1)

(il)

(ik )
1

j

(ik)

j

28

PIOTR ´SNIADY

is deﬁned as the sum over such choices of the indices that the restriction of
the above graph G to the vertex set {i1, . . . , il} is a connected graph.

The moment-cumulant formula (0.5) takes the following concrete form

in our current setup:

(2.9)

x1 · · · xn =Xν Yb∈ν

κ⊗(xi : i ∈ b).

Comparison of (2.7) with (2.9) shows that the quantitiesfκ⊗ fulﬁll the same

recurrence relations as the cumulants κ⊗. Since the system of equations
(2.9) has the unique solution, it follows that

thus (2.8) gives an explicit formula for the latter cumulants.

In this way we proved the following result.

κ⊗ =fκ⊗

Lemma 2.6. If xi ∈ R are given by (2.4) then the corresponding cumulant
κ⊗(xi1, . . . , xir ) is given by the right-hand side of (2.8).

In the following lemma we shall use the notations from the above proof.
Also, for a graph G we denote by c(G) the number of its connected compo-
nents.

Lemma 2.7. Let a family J (1), . . . , J (n) of sets (2.6) be given.

(1) Assume that G′ is a subgraph of G with the same vertex set [n]. Then

≤ m(1) + · · · + m(n) + c(G′) − n,

where the ﬁrst sum on the left-hand side runs over the connected
components of G′.

(2)

XC (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)[a∈C
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) [1≤a≤n

J (a)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
J (a)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

≤ m(1) + · · · + m(n) + c(G) − n

Proof. The proof of the ﬁrst part of the lemma is a simple induction with
respect to the number of the edges of the graph G′ based on the inclusion-
exclusion principle |A ∪ B| = |A| + |B| − |A ∩ B|.

The second part of the lemma follows from the ﬁrst time by setting G′ :=
(cid:3)

G.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

29

2.6.2. The end of the proof of Proposition 2.5.

Proposition 2.8. The map (2.2) has approximate factorization property.

Proof. Let x1, . . . , xn ∈ R be of the form (2.4).

Lemma 2.6 gives explicitly the convolution kernel (fr) for the cumulant

κ⊗(x1, . . . , xn) =Xr≥0 Xi1<···<ir

fr(λi1, . . . , λir).

More speciﬁcally, the summand on the right-hand side for some speciﬁed
value of r corresponds to the summands on the right-hand side of (2.8) for
which

|J (1) ∪ · · · ∪ J (n)| = r.

We keep notations from (2.4). Assume that xi ∈ R is of degree at most
di; in other words we assume that the corresponding convolution kernel gi
takes only values in Laurent polynomials of degree at most di − 2m(i). It
follows that the function fr takes values in Laurent polynomials of degree
at most

di − 2m(i).

X1≤i≤n

On the other hand, the second part of Lemma 2.7 shows that non-zero
contribution can be obtained only for the values of r which fulﬁll the bound

r = |J (1) ∪ · · · ∪ J (n)| ≤ m(1) + · · · + m(n) + 1 − n.

It follows that κ⊗(x1, . . . , xn) is a row-function of degree at most

 X1≤i≤n

di − 2m(i)! + 2r ≤ X1≤i≤n

di! + 2(n − 1),

which concludes the proof.

(cid:3)

This completes the proof of Proposition 2.5.

2.7. Cumulants in terms of moments. From both deﬁnitions of the cu-
mulants (i.e., from (0.4) and (0.5)) it is easy to show that the cumulant

κ(X1, . . . , Xn)

is a linear combination (with rational coefﬁcients) of the products of the
moments of the form

(2.10)

E Yi∈b

Yb∈ν

Xi!

over set-partitions of the set [n].

We will show now that if n ≥ 2 then the sum of these coefﬁcients is
equal to zero. Indeed, if we set X1 = · · · = Xn = 1 to be a deterministic

30

PIOTR ´SNIADY

random variable then from both deﬁnitions of the cumulants it follows that
the corresponding cumulant κ(1, . . . , 1) = 0 while each product (2.10) is
equal to 1.
Lemma 2.9. For any partitions π1, . . . , πl ≥ 1 the function
(2.11)
is a linear combination (with integer coefﬁcients) of expressions of the form

κ⊗
• (Chπ1, . . . , Chπl)

ChQi∈b πi

Ob∈ν

over set-partitions ν of the set [l]. For example, in the case l = 3 the
function (2.11) is a linear combination of the following ﬁve expressions:

Chπ1 ⊗ Chπ2 ⊗ Chπ3 Chπ1π2 ⊗ Chπ3 Chπ1π3 ⊗ Chπ2

Chπ2π3 ⊗ Chπ1 Chπ1π2π3 .

Furthermore, if l ≥ 2 then the sum of the coefﬁcients in this linear com-

bination is equal to 0.

The above results hold true also for the cumulants κ• if the product ⊗ is

replaced by the usual pointwise multiplication of the functions.

2.8. Conditional cumulants for the diagonal arrow.
Lemma 2.10. For any partitions π1, . . . , πn

κ⊗
• (Chπ1, . . . , Chπn)(λ) = 0

holds true for any Young diagram λ such that |λ| < |π1| + · · · + |πn|.
Proof. We start by showing that Property 1.13 is indeed fulﬁlled if F, G ∈
R are row functions and ⊗ is the disjoint product.

Assume that F is a row function with the convolution kernel (fr), see
(2.3) and that F fulﬁlls the assumption (1.11) from Property 1.13. The
right-hand side of (2.3) involves only the values of fr over r ≤ ℓ(λ) thus the
collection of equalities (2.3) can be viewed as an upper-triangular system
of linear equations. It follows immediately that

holds true for all r ≥ 0 and all non-negative integers x1, . . . , xr such that

fr(x1, . . . , xr) = 0

x1 + · · · + xr < a.

The property is fulﬁlled by the convolution kernel of the row function G

(with the variable a replaced by b).

From the very deﬁnition of the disjoint product it follows that the convo-
lution kernel of F ⊗G also fulﬁlls this property (with the variable a replaced
by a + b). This concludes the proof of Property 1.13 for row functions.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

31

Lemma 2.10 is now a straightforward consequence of Lemma 2.9 and
(cid:3)

Property 1.13.

2.9. Conditional cumulants for a commutative diagram. We state the
following lemma with the commutative diagram (1.13) in mind.
Lemma 2.11 ([Bri69]). Assume that A, B and C are commutative unital
algebras and let EB
A be unital maps between them such that the
following diagram commutes:

B and EC

A, EC

EB
A

A

EC
A

B

C

EC
B

Then

Example 2.12.

κC

B(cid:16)κB
A(xi : i ∈ b) : b ∈ ν(cid:17).

κC
A(x1) = κC

A(x1, x2) = κC
κC

κC
A(x1, x2, x3) = κC

κC

A(x1, . . . , xn) = Xν∈Pn
B(cid:16)κB
A(x1)(cid:17),
B(cid:16)κB
A(x1, x2)(cid:17) + κC
B(cid:16)κB
B(cid:16)κB
A(x1, x2, x3)(cid:17) + κC
B(cid:16)κB
A(x1, x3)(cid:17) + κC
B(cid:16)κB
B(cid:16)κB
A(x3)(cid:17).
B(cid:16)κB

A(x2), κB

A(x1), κB

A(x2), κB

κC

κC

A(x1), κB

A(x2)(cid:17)
A(x2, x3)(cid:17)+
A(x1, x2)(cid:17)+

A(x1), κB

A(x3), κB

2.10. Condition (Z3) for row functions of small degree.
Lemma 2.13 ([´Sni15, Lemma 6.8]). Let d ≥ 1 be an integer and assume
that F ∈ R is of degree at most d − 1.

Then for each integer k ≥ 0 and each Young diagram λ = (λ1, λ2, . . . )

[Ad−2k]∆λ1 · · · ∆λkF sym(λ1, λ2, . . . ) = 0.

2.11. Proof of the main result. We are now ready to show the proof of
Theorem 1.9. For Reader’s convenience we will restate this theorem in the
following form.
Theorem 2.14 (Reformulation of Theorem 1.9). For any partitions π1, . . . , πl ∈
P the corresponding conditional cumulant

F := κ•(Chπ1, . . . , Chπl) ∈ P

32

PIOTR ´SNIADY

is of degree at most

|π1| + · · · + |πl| + ℓ(π1) + · · · + ℓ(πl) − 2(l − 1).

Proof. We use induction over l. For the induction base l = 1

F = κ•(Chπ1) = Chπ1

and there is nothing to prove. In the following we shall consider the case
l ≥ 2; we assume that the statement of the theorem holds true for all l′ < l.

We start with an observation that if for some value of the index i we have
πi = ∅ then Chπi = 1 is the unit in P thus (for l ≥ 2) the corresponding
cumulant vanishes:

F = κ•(Chπ1, . . . , 1, . . . , Chπl) = 0

and the claim holds trivially true. From the following on we shall assume
that π1, . . . , πl 6= ∅ are all non-empty.

We denote

d := |π1| + · · · + |πl| + ℓ(π1) + · · · + ℓ(πl).

We will use a nested induction over j ∈ {0, . . . , l −1} and show that F is of
degree at most d − 2j. This result (for the special choice j = l − 1) would
ﬁnish the proof of the inductive step with respect to the variable l and thus
would conclude the proof.

Lemma 2.9 (in the alternative formulation, for the cumulants κ•) implies
that F ∈ P is of degree at most d and thus the induction base j = 0 holds
trivially true.

The inductive hypothesis with respect to the variable j states that F is
of degree (at most) d − 2j for some choice of j ∈ {0, . . . , l − 2}. We
shall prove the induction step with respect to the variable j by applying
Lemma 2.3 twice.

The ﬁrst application of Lemma 2.3. Our strategy is to apply Lemma 2.3

either:

• in the original formulation (in the case j = 0), or,
• in the alternative formulation (in the case j ≥ 1)

for

n : = |π1| + · · · + |πl| − j − 2 ≥ 2,
r : = ℓ(π1) + · · · + ℓ(πl) − j ≥ 2;

we ﬁrst check that its assumptions are fulﬁlled.

Assumption (Z1). This assumption is just the inductive hypothesis.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

33

Assumption (Z2). We have to verify this assumption only in the case
j = 0. By Lemma 2.9 and condition (K2) from Deﬁnition 1.5 it follows
that

(2.12)

Y ∋ (λ1, . . . , λm) 7→ F (λ1, . . . , λm) ∈ Q(cid:2)A, A−1(cid:3)

is a priori a polynomial of degree |π1| + · · · + |πl| and its homogeneous
top-degree part is equal to some multiple of

A|π1|+···+|πl|−ℓ(π1)−···−ℓ(πl) pπ1···πl(λ1, . . . , λm).

However, since l ≥ 2, the second part of Lemma 2.9 implies that this mul-
tiple is actually equal to zero. In other words, (2.12) is a polynomial of
degree at most |π1| + · · · + |πl| − 1 = n − 1, as required.

Assumption (Z4). Lemma 2.9 and condition (K4) from Deﬁnition 1.5
imply that for any Young diagram λ the evaluation F (λ) is a Laurent poly-
nomial of degree at most |π1| + · · · + |πl| − ℓ(π1) − · · · − ℓ(πl) = n − r as
required.

Assumptions (Z3) and (Z3a). Since κ•(x) = x it follows that

κ⊗

• (Chπ1, . . . , Chπl) −Xν6=1

(2.13) F = κ•(Chπ1, . . . , Chπl) = κ•(cid:0)κ•(Chπ1, . . . , Chπl)(cid:1) =

where the last equality follows from Lemma 2.11; the sum on the right-hand
side runs over set-partitions of [l] which are different from the maximal

κ•(cid:16)κ•(Chπi : i ∈ b) : b ∈ ν(cid:17),
partition 1 =(cid:8){1, . . . , l}(cid:9). We will substitute the right-hand side into (2.1)
Firstly, Lemma 2.10 shows that (cid:0)κ⊗
• (Chπ1, . . . , Chπl)(cid:1)(λ) = 0 for all

λ ∈ Y such that |λ| ≤ |π1| + · · · + |πl| − 1 thus for any integer k ≥ r
(2.14)

and we will investigate the resulting expression.

∆λ1 · · · ∆λk(cid:0)κ⊗

• (Chπ1, . . . , Chπl)(cid:1)sym

(λ) = 0

for all λ ∈ Y such that

|λ| ≤ |π1| + · · · + |πl| − 1 − k = (n + r − 2k) + (j − 1) + (k − r).

It follows that:

• if j = 0 then (2.14) holds true for all values of k and λ which appear

in condition (Z3);

• if j ∈ {1, . . . , l − 2} then (2.14) holds true for all k and λ appear in

condition (Z3a).

Secondly, let us ﬁx the value of the set-partition ν 6= 1 and let us investi-
gate the corresponding summand on the right-hand side of (2.13). From the

34

PIOTR ´SNIADY

inductive hypothesis over the variable l it follows for each block b ∈ ν that
the cumulant κ•(Chπi : i ∈ b) ∈ P is of degree at most

Thus Proposition 2.5 implies that

|πi| + ℓ(π)! − 2(|b| − 1).

 Xi∈b
G := κ•(cid:16)κ•(Chmi : i ∈ b) : b ∈ ν(cid:17) ∈ R
|πi| + ℓ(π)! − 2(|b| − 1)# + 2 − 2|ν| =

is of degree (at most)

Xb∈ν" Xi∈b

d − 2(l − 1) ≤ n + r − 2.

The latter bound on the degree of G and Lemma 2.13 imply that

[An+r−2k]∆λ1 . . . ∆λk G(λ1, . . . , λi) = 0.

It follows that:

• if j = 0 then condition (Z3) holds true;
• if j ∈ {1, . . . , l − 2} then stronger condition (Z3a) holds true.

Conclusion of the ﬁrst application of Lemma 2.3. Lemma 2.3 implies that

F is of degree at most d − 2j − 1.

The second application of Lemma 2.3. We shall apply Lemma 2.3 again;

this time in the alternative formulation for

n : = |π1| + · · · + |πl| − j − 2 ≥ 2,
r′ : = r − 1 = ℓ(π1) + · · · + ℓ(πl) − j − 1 ≥ 1.

Veriﬁcation that the assumptions are fulﬁlled is not very difﬁcult: ﬁrstly,
we do not have to verify assumption (Z2)). Secondly, for the remaining
conditions it is enough to revisit the above ﬁrst application of Lemma 2.3
and make some minor adjustments. Indeed, veriﬁcation of the assumption
(Z4) is easier now because r′ < r while the veriﬁcation of (Z3a) remains
essentially the same as before.

Thus Lemma 2.3 shows that F is of degree at most d − 2j − 2. This
(cid:3)

concludes the proof of the induction step over variable j.

STRUCTURE COEFFICIENTS FOR JACK CHARACTERS

35

ACKNOWLEDGMENTS

All numerical examples presented in the current paper are based on data

provided by Michel Lassalle [Las09b].

I thank Maciej Doł˛ega and Valentin Féray for several years of collabora-

tion on topics related to the current paper.

Research supported by Narodowe Centrum Nauki, grant number

2014/15/B/ST1/00064.

REFERENCES

[Bia03] Philippe Biane. Characters of symmetric groups and free cumulants. In Asymp-
totic combinatorics with applications to mathematical physics (St. Petersburg,
2001), volume 1815 of Lecture Notes in Math., pages 185–200. Springer, Berlin,
2003.

[BO05] Alexei Borodin and Grigori Olshanski. Z-measures on partitions and their scal-

ing limits. European Journal of Combinatorics, 26(6):795–834, 2005.

[Bri69] David R. Brillinger. The calculation of cumulants via conditioning. Annals of

the Institute of Statistical Mathematics, 21(1):215–218, 1969.

[Bur16] Adam Burchardt. Some structure constants for Jack polynomials. In preparation,

2016.

[DF16] Maciej Doł˛ega and Valentin Féray. Gaussian ﬂuctuations of Young dia-
grams and structure constants of Jack characters. Duke Math. J., to appear,
doi:10.1215/00127094-3449566; also available as preprint arXiv:1402.4615v3,
2016.

[DF´S10] Maciej Doł˛ega, Valentin Féray, and Piotr ´Sniady. Explicit combinatorial inter-
pretation of Kerov character polynomials as numbers of permutation factoriza-
tions. Adv. Math., 225(1):81–120, 2010.

[DF´S14] Maciej Doł˛ega, Valentin Féray, and Piotr ´Sniady. Jack polynomials and ori-
entability generating series of maps. Sém. Lothar. Combin., 70:Art. B70j, 50,
2014.

[DH92] Persi Diaconis and Phil Hanlon. Eigen-analysis for some examples of the me-

tropolis algorithm. Contemporary Mathematics, 138:99–117, 1992.

[D´S16] Maciej Doł˛ega and Piotr ´Sniady. Gaussian ﬂuctuations of Jack-deformed random

Young diagrams. Work in progress, 2016.

[Fér09] Valentin Féray. Combinatorial interpretation and positivity of Kerov’s character

polynomials. J. Algebraic Combin., 29(4):473–507, 2009.

[Fis28] R. A. Fisher. Moments and Product Moments of Sampling Distributions. Proc.

London Math. Soc., S2-30(1):199, 1928.

[F´S11] Valentin Féray and Piotr ´Sniady. Asymptotics of characters of symmetric groups
related to Stanley character formula. Ann. of Math. (2), 173(2):887–906, 2011.
I. P. Goulden and D. M. Jackson. Connection coefﬁcients, matchings, maps
and combinatorial conjectures for Jack symmetric functions. Trans. Amer. Math.
Soc., 348(3):873–892, 1996.

[GJ96]

[GR05] Adriano Garsia and Jeffrey B. Remmel. Breakthroughs in the theory of Macdon-
ald polynomials. Proc. Natl. Acad. Sci. USA, 102(11):3891–3894 (electronic),
2005.

36

PIOTR ´SNIADY

[Hal81] A. Hald. T. N. Thiele’s contributions to statistics. Internat. Statist. Rev., 49(1):1–

20 (one plate), 1981.

[IK99] V. Ivanov and S. Kerov. The algebra of conjugacy classes in symmetric groups,
and partial permutations. Zap. Nauchn. Sem. S.-Peterburg. Otdel. Mat. Inst.
Steklov. (POMI), 256(Teor. Predst. Din. Sist. Komb. i Algoritm. Metody. 3):95–
120, 265, 1999.

[Jac71] Henry Jack. A class of symmetric polynomials with a parameter. Proc. Roy. Soc.

Edinburgh Sect. A, 69:1–18, 1970/1971.

[Kan93] Jyoichi Kaneko. Selberg integrals and hypergeometric functions associated with
jack polynomials. SIAM journal on mathematical analysis, 24(4):1086–1110,
1993.

[KO94] Serguei Kerov and Grigori Olshanski. Polynomial functions on the set of Young

diagrams. C. R. Acad. Sci. Paris Sér. I Math., 319(2):121–126, 1994.

[Las08] Michel Lassalle. A positivity conjecture for Jack polynomials. Math. Res. Lett.,

15(4):661–681, 2008.

[Las09a] Michel Lassalle.

Jack polynomials and free cumulants. Adv. Math.,

222(6):2227–2269, 2009.

[Las09b] Michel

Lassalle.

free
http://igm.univ-mlv.fr/~lassalle/free.html,
cessed: 1/12/2012.

polynomials

Jack

and

cumulants.
2009. Ac-

[Oko03] A. Okounkov. The uses of random partitions. In Fourteenth International Con-

gress on Mathematical Physics, pages 379–403. Word Scientists, 2003.

[OO97] Andrei Okounkov and Grigori Olshanski. Shifted Jack polynomials, binomial

formula, and applications. Math. Res. Lett., 4(1):69–78, 1997.

[R´S08] Amarpreet Rattan and Piotr ´Sniady. Upper bound on the characters of the sym-
metric groups for balanced Young diagrams and a generalized Frobenius for-
mula. Adv. Math., 218(3):673–695, 2008.

[ ´Sni06a] Piotr ´Sniady. Gaussian ﬂuctuations of characters of symmetric groups and of

Young diagrams. Probab. Theory Related Fields, 136(2):263–297, 2006.

[ ´Sni06b] Piotr ´Sniady. Gaussian ﬂuctuations of representations of wreath products. Inﬁ-
nite Dimensional Analysis, Quantum Probability and Related Topics, 9(4):529–
546, 2006.

[ ´Sni15] Piotr ´Sniady. Top degree of Jack characters. Preprint arXiv:1506.06361v2, 2015.
[Sta06] Richard P. Stanley. A conjectured combinatorial interpretation of the nor-
the symmetric group. Preprint

malized irreducible character values of
arXiv:math.CO/0606467, 2006.

WYDZIAŁ MATEMATYKI I INFORMATYKI, UNIWERSYTET IM. ADAMA MICKIEWICZA,

COLLEGIUM MATHEMATICUM, UMULTOWSKA 87, 61-614 POZNA ´N, POLAND,

INSTYTUT MATEMATYCZNY, POLSKA AKADEMIA NAUK, UL. ´SNIADECKICH 8,

00-956 WARSZAWA, POLAND

E-mail address: piotr.sniady@amu.edu.pl

