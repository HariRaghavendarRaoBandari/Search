Learning a Discriminative Null Space for Person Re-identiﬁcation

Li Zhang

Tao Xiang

Queen Mary University of London

{david.lizhang, t.xiang, s.gong}@qmul.ac.uk

Shaogang Gong

6
1
0
2

 
r
a

M
7

 

 
 
]

V
C
.
s
c
[
 
 

1
v
9
3
1
2
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

Most existing person re-identiﬁcation (re-id) methods fo-
cus on learning the optimal distance metrics across camera
views. Typically a person’s appearance is represented using
features of thousands of dimensions, whilst only hundreds
of training samples are available due to the difﬁculties in
collecting matched training images. With the number of
training samples much smaller than the feature dimension,
the existing methods thus face the classic small sample size
(SSS) problem and have to resort to dimensionality reduc-
tion techniques and/or matrix regularisation, which lead to
loss of discriminative power. In this work, we propose to
overcome the SSS problem in re-id distance metric learn-
ing by matching people in a discriminative null space of the
training data. In this null space, images of the same per-
son are collapsed into a single point thus minimising the
within-class scatter to the extreme and maximising the rela-
tive between-class separation simultaneously. Importantly,
it has a ﬁxed dimension, a closed-form solution and is very
efﬁcient to compute. Extensive experiments carried out on
ﬁve person re-identiﬁcation benchmarks including VIPeR,
PRID2011, CUHK01, CUHK03 and Market1501 show that
such a simple approach beats the state-of-the-art alterna-
tives, often by a big margin.

1. Introduction

The problem of person re-identiﬁcation (re-id) has at-
tracted great attention in the past ﬁve years [34, 10]. When
a person is captured by multiple non-overlapping views, the
objective is to match him/her across views among a large
number of imposters. Despite the best efforts from the com-
puter vision researchers, re-id remains a largely unsolved
problem. This is because that a person’s appearance of-
ten undergoes dramatic changes across camera views due to
changes in view angle, body pose, illumination and back-
ground clutter. Furthermore, since people are mainly dis-
tinguishable by their clothing under a surveillance setting,
many passers-by can be easily confused with the target per-
son because they wear similar clothes.

Figure 1. Training images of same identity are projected to a single
point in a learned discriminative null space.

Existing approaches focus on developing discrimina-
tive feature representations that are robust against
the
view/pose/illumination/background changes [12, 38, 6, 18,
26, 41, 22], or learning a distance metric [12, 17, 31, 44, 28,
33, 30, 21, 40, 39, 36, 27, 23, 22], or both jointly [20, 1].
Among them, the distance metric learning methods are most
popular and are the focus of this paper. Given any fea-
ture representation and a set of training data consisting of
matching image pairs across camera views, the objective is
to learn the optimal distance metric that gives small values
to images of the same person and large values for those of
different people. Distance metric learning has been exten-
sively studied in machine learning [37], and existing metric
learning methods employed for re-id are either originated
elsewhere or extensions of existing methods with modiﬁ-
cations to address the additional challenges arising from the
re-id task. Although they have been shown to be effective in
improving the existing re-id benchmarks over the past ﬁve
years, all these models are still limited by some of classical
problems in model learning.

Speciﬁcally, a key challenge for distance metric learning
when applied to person re-id is the small sample size (SSS)
problem [4]. Speciﬁcally, to capture rich person appear-
ance whilst being robust against those condition changes
mentioned above, the feature representations used by most

1

recent re-id works are of high dimension – typically in the
order of thousands or tens of thousands.
In contrast, the
number of training samples is typically small, normally in
hundreds. This is because that collecting training samples
of matched person pairs across views is labour intensive
and tedious. As a result the sample size is much smaller
(often in an order of magnitude) than the feature dimen-
sion, a problem known as the SSS problem. Metric learning
methods suffer from the SSS problem because they essen-
tially aim to minimise the within-class (intra-person) vari-
ance (distance), whilst maximising the inter-class (inter-
person) variance (distance). With a small sample size, the
within-class scatter matrix becomes singular [4]; to avoid
it, unsupervised dimensionality reduction or regularisation
are required. This in turn makes the learned distance metric
sub-optimal and less discriminative [4, 43, 13].

In this paper, we argue that the SSS problem in person
re-id distance metric learning can be best solved by learning
a discriminative null space of the training data. In partic-
ular, instead of minimising the within-class variance, data
points of the same classes are collapsed, by a transform,
into a single point in a new space (see Fig. 1). By keep-
ing the between-class variance non-zero, this automatically
maximises the Fisher discriminative criterion and results in
a discriminative subspace. The null space method, also
known as the null Foley-Sammon transfer (NFST) [13] is
speciﬁcally designed for the small sample case, with rigor-
ous theoretical proof on the resulting subspace dimension.
Importantly, it has a closed-form solution, no parameter to
tune, requires no pre-precessing steps to reduce the feature
dimension, and can be computed efﬁciently. Furthermore,
to deal with the non-linearity of the person’s appearance, a
kernel version can be developed easily to further boost the
matching performance within the null space. It therefore of-
fers a perfect solution to the challenging person re-id prob-
lem. In addition to formulating the NSFT model as a fully
supervised model to solve the person re-id problem, we also
extend it to the semi-supervised setting to further alleviate
the effects of the SSS problem by exploiting unlabelled data
abundant in re-id applications.

The contributions of this work are as follows: (1) We
identify the small sample size (SSS) problem suffered by
all existing metric learning based re-id methods and argue
that their solutions to this problem is suboptimal. (2) For
the ﬁrst time, we propose to overcome the SSS problem
in person re-id by learning a discriminative null space of
the training data. (3) We develop a novel semi-supervised
learning method in the null space to exploit the abun-
dant unlabelled data to further alleviate the effects of the
SSS problem. Extensive experiments carried out on ﬁve
person re-identiﬁcation benchmarks including VIPeR [11],
PRID2011 [14], CUHK01 [19], CUHK03 [19] and Mar-
ket1501 [42] show that such a simple and computationally

very efﬁcient approach beats all state-of-the-art methods
presented to date, often by a large margin.

2. Related Work

Existing works on person re-id can be roughly cate-
gorised into three groups. The ﬁrst group of methods de-
sign invariant and discriminant features [20, 12, 6, 18, 26,
41, 24, 38, 22]. The general trend is that the dimensions of
the proposed features are getting higher. For instance the di-
mensions of two representations, recently proposed in [24]
and [22] and used in our experiments, are 5,138 and 26,960
respectively. However, no matter how robust the designed
features are, they are unlikely to be completely invariant to
the often drastic cross-view pose/illumination/background
changes. Therefore, the second group of methods focus on
learning robust and discriminative distance metrics or sub-
spaces for matching people across views [12, 17, 31, 44, 28,
33, 30, 21, 40, 39, 36, 27, 24, 23, 22, 29]. Recently, the third
group of methods start to appear which are based on deep
learning [20, 1]. However, person re-id seems to be one
of the few vision problems that deep learning has not been
able to shine due to the small training sample size problem
addressed in this work.

Apart from a few exceptions [12, 31] based on ranking
or boosting, the second groups of methods can be further di-
vided into two major sub-groups: those on learning distance
metrics [17, 44, 28, 33] and those on learning discriminative
subspaces [30, 24, 36, 22]. Seemingly different, these two
sub-groups are closely related [9]. Speciﬁcally, most metric
learning methods focus on Mahalanobis form metrics. If the
linear projection of a feature vector xi in a learned discrim-
inative subspace is denoted as yi, we have yi = WT xi.
The Euclidean distance between yi and yj is exactly a Ma-
halanobis distance ||yi − yj||2 = (xi − xj)T A(xi − xj)
where A = WT W is a positive semideﬁnite matrix. In
other words, learning a discriminative subspace followed
by computing Euclidean distance is equivalent to comput-
ing a discriminative Mahalanobis distance over feature vec-
tors in the original space. By making this connection, it
is not difﬁcult to see why both methods suffer from the
same SSS problem typically associated with the subspace
learning methods [4, 43, 13]. Most existing methods need
to work with a reduced dimensionality [30], achieved typi-
cally by PCA whose dimension has to be carefully tuned for
each dataset. Some works additionally require introducing
matrix regularisation term if the intra-class scatter matrix is
used in the formulation, in order to prevent matrix singular-
ity [30, 24, 36, 22], again with free parameters to tune. Crit-
ically, they suffer from the degenerate eigenvalue problem
(i.e. several eigenvectors share the same eigenvalue), which
makes the solution sub-optimal resulting in loss of discrim-
inant ability [43]. In contrast, for our discriminative null
space based approach, neither dimensionality reduction be-

fore model learning nor regularisation term is required, and
it has no parameters to tune.

As a solution proposed speciﬁcally to address the SSS
problem, the null Foley-Sammon transfer (NFST) method
has been around for a long time [13], but received very little
attention apart from a recent application to the novelty de-
tection problem [2]. A possible reason is that by restricting
the learned discriminative projecting directions to the null
projecting directions (NPDs), on which within-class dis-
tance is always zero and between-class distance is positive,
the model is extreme, leaving little space for further exten-
sion with clear added-value. For example, the more relaxed
Fisher discriminative analysis (FDA) can be extended, gain-
ing notable advantage, by exploit graph laplacian to pre-
serve local data structure, known as LFDA[32], which has
been successfully applied to re-id [30]. However, a similar
graph laplacian extension to NFST does not apply due to its
single point per class nature. Despite the restrictions, given
the acute SSS problem in re-id distance metric learning, the
basic idea of learning a null space for overcoming this prob-
lem becomes very attractive. The general concept of col-
lapsing same-class data points to a single point has been
exploited in a Mahalanobis distance learning framework,
known as maximally collapsing metric learning (MCML)
[9]. However, MCML does not exploit a null space. In-
stead, the MCML model must make approximations with
plenty of free parameters to tune and no closed-form solu-
tion.

In this work, we exploit the original null Foley-Sammon
transfer (NFST) method [13] with its conventional su-
pervised learning approach, beneﬁting from its attractive
closed-form solution and no parameters tuning required.
Moreover, we extend the original fully supervised null
space model to a semi-supervised learning setting. This is to
explore, in addition to a few labelled data, a larger quantities
of unlabelled data typically available in person re-id scenar-
ios for model learning. The problem of semi-supervised
re-id has attracted interest lately due to its potential to over-
come the lack of training data problem. One approach is
by dictionary learning for sparse coding [25, 16], which has
an unsupervised nature, thus can be learned with both la-
belled and unlabelled data. In this work, we compare the
new semi-supervised null space model against dictionary
learning based methods and demonstrate the superior per-
formance from the new model.

3. Methodology
3.1. Problem Deﬁnition

Given a set of N training data denoted as X ∈ Rd×N .
Each column of the data descriptor matrix X, xi is a fea-
ture vector representing the i-th training sample.
In the
case of person re-id, this feature vector is extracted from

a person detection box and contains appearance informa-
tion about the person, and its dimension d is typically very
high. We assume that each data point belongs to one of C
classes, i.e. C different identities. The objective of learning
a discriminative null space is to learn a projection matrix
W ∈ Rd×m to project the original high-dimensional fea-
ture vector xi into a lower-dimensional one yi ∈ Rm with
m < d. Person re-id can then be performed by computing
the Euclidean distance between two projected vectors in the
learned discriminative null space.
3.2. Foley-Sammon Transform

The learned null Foley-Sammon transform (NFST)
space is closely related to linear discriminant analysis
(LDA), also known as Foley-Sammon transform (FST) [8].
So before we formulate NFST, let us ﬁrst brieﬂy revisit FST.
The objective of FST is to learn a projection matrix
W ∈ Rd×m so that each column, denoted as w, is an op-
timal discriminant direction that maximises the Fisher dis-
criminant criterion:

J (w) =

w(cid:62)Sbw
w(cid:62)Sww

,

(1)

where Sb is the between-class scatter matrix and Sw is the
within-class scatter matrix. The optimisation of Eq. (1)
can be done by solving the following generalised eigen-
problem:

Sbw = λSww.

(2)

If Sw

non-singular, C − 1
eigenvectors
is
w(1), ..., w(c−1)
can be computed corresponding to
the C − 1 largest eigenvalues of S−1
w Sb. Using them as
the projection matrix W can project the
the columns,
original data into a C − 1 dimensional discriminative sub-
space where the C classes become maximally separable.
However, in the small sample size case, we have d > N;
as a result, Sw is singular. FST thus runs in numerical
problems and common solutions include reducing d by
PCA or adding a regularisation term to Sw.
In [13], a
more principled way to overcome the SSS problem in
FST is proposed, termed as Null Foley-Sammon transform
(NFST).
3.3. Null Foley-Sammon transform

NFST aims to learn a discriminative subspace where the
training data points of each of the C classes are collapsed
to a single point, resulting in C points in the space. In order
to make this subspace discriminative, these C points should
not further collapse to a single point. Formally, we aim to
learn the optimal projection matrix W so that each of its
column w satisﬁes the following two conditions:

w(cid:62)Sww = 0,

(3)

w(cid:62)Sbw > 0.

(4)
That is, it satisﬁes zero within-class scatter and positive
between-class scatter. This guarantees the best separabil-
ity of the training data in the sense of Fisher discriminant
criterion. Such a linear projecting direction w is called Null
Projecting Direction (NPD) [13].

Next, we show that a NPD must lie in the null space of

Sw. In particular, we have the following Lemma:

Lemma 1. Let W be a projection matrix which maps a
sample x into the null space of Sw, where the null space is
spanned by the orthonormal set of W, that is, SwW = 0.
If all samples are mapped into the null space of Sw through

W, the within-class scatter matrix(cid:98)Sw of the mapped sam-
n be the nth sample of the cth ∈ {1, ...C}
n denote the mapped

ples is a complete zero matrix.

Proof. Let xc

class which has Nc samples in total. yc
feature vector through W. We have:
n − yc)(cid:62)

n − yc)(yc

(cid:98)Sw =

(yc

c=1

n=1

C(cid:88)
Nc(cid:88)
C(cid:88)
Nc(cid:88)
= W(cid:62) C(cid:88)

n=1

c=1

=

Nc(cid:88)

(xc
= W(cid:62)SwW = 0

n=1

c=1

(W(cid:62)xc

n − W(cid:62)µc)(W(cid:62)xc

n − W(cid:62)µc)(cid:62)

n − µc)(xc

n − µc)(cid:62)W

(cid:80)Nc

n = W(cid:62)xc

n,
where yc
n=1 xc
Nc is the number of samples in class c, and µc is the mean
vector of all data belonging to the class c.

n, yc = W(cid:62)µc, µc = 1

Nc

Now with Lemma 1, we know that Eq. (3) holds as long
as w is from the null space of Sw. Next we take a look the
condition in the inequality (4). It is easy to see that when
Eq. (3) holds, (4) also holds if:

w(cid:62)Stw > 0,

(5)

(6)

where St = Sb + Sw is the total scatter matrix. We now
denote the null space of the St and Swas:

Zt =(cid:8)z ∈ Rd | Stz = 0(cid:9) ,
Zw =(cid:8)z ∈ Rd | Swz = 0(cid:9) ,

(7)
and their orthogonal complements as Z⊥
w respec-
tively. Now since Sb is non-negative deﬁnite, we can see
that in order for the NPDs to satisfy both Eqs. (3) and (4)
simultaneously, they must lie in the shared space between
Zw and Z⊥

t and Z⊥

t , that is:

w ∈ (Z⊥

t ∩ Zw).

(8)
It has been proved in [13] that there are precisely C − 1
NPDs w that satisfy both Eq. (3) and (4). In other words, the
discriminative null space we are looking for has m = C − 1
dimensions.

3.4. Learning the Discriminative Null Space
Let Xw be the matrix consisting of vectors xc

i − µc.
Xt be the matrix consisting of vectors xi − µ with µ =

(cid:80)N

1
N

i=1 xi. We then have,

Sw =

XwX(cid:62)

w, St =

1
N

XtX(cid:62)

t

1
N

(9)

Now we know where to look for the NPDs – the shared
space between Zw and Z⊥
t . Next, we shall see how to com-
pute them. Let us ﬁrst take a look at how to compute w that
satisﬁes w ∈ Z⊥

Zt =(cid:8)z ∈ Rd | Stz = 0(cid:9) =(cid:8)z ∈ Rd | z(cid:62)Stz = 0(cid:9)
=(cid:8)z ∈ Rd | (X(cid:62)
=(cid:8)z ∈ Rd | X(cid:62)

t z = 0(cid:9)

t z = 0(cid:9) .

t . First we notice that:

t z)(cid:62)X(cid:62)

t

Hence, Z⊥
is the subspace spanned by zero-mean data
xi − µ. We can obtain the orthonormal basis U =
[u(1), ..., u(N−1)] of the zero-mean data using Gram-
Schmidt orthonormalisation, then represent each solution w
as:

w = β1u(1) + ... + βN−1u(N−1) = Uβ,

(10)
Note that there are N − 1 basis vectors because the rank of
St is N − 1.
So now after expressing w using Eq. (10), it must satisfy
t . The next step is the make it also satisfy w ∈ Zw.
w ∈ Z⊥
This can be achieved by substituting Eq. (10) into Eq. (3)
and solve the following eigen-problem:
(U(cid:62)SwU)β = 0,

(11)
for which we know that C − 1 solutions β(1), ..., β(C−1)
exist, giving C − 1 NPDs, Uβ.

In summary, the problem of learning the discriminative
null space boils down to solving an eigen-problem which
has a closed-form solution and can be solved very efﬁ-
ciently. Importantly, the whole optimisation algorithm has
no free parameter to tune.

3.5. Kernelisation

The NFST model is a linear model. It has been demon-
strated [36] that many distance metric learning or discrimi-
native subspace based methods for person re-id beneﬁt from
kernelisation because of the non-linearity in person’s ap-
pearance. In the following we describe how the discrimina-
tive null space can be kernelised.
Given a kernel function k(xi, xi) = (cid:104)Φ(xi), Φ(xj)(cid:105),
where Φ(xi) maps xi to an implicit higher dimensional
space, we can compute the data kernel matrix K ∈ RN×N
for training data X as K = Φ(X)(cid:62)Φ(X). Now the within-
class scatter matrix Sw and total-class scatter matrix St can

be kernelised as:

Kw = K(I − L)(I − L)(cid:62)K,
Kt = K(I − M)(I − M)(cid:62)K,

where I is a N × N identity matrix, L is a block diagonal
matrix with block sizes equal to the number of data points
Nc for each class c ∈ {1, ...C} and M is a N × N matrix
N .
with all entries equal to 1

Now to write Eq. (11) in its kernelised form, we need
to replace Sw with Kw, and compute the orthonormal ba-
sis of Kt to replace U. The orthonormal basis of Kt can
be computed using kernel PCA. First, we compute the cen-

tred kernel matrix (cid:101)K. Second, the eigendecomposition of
(cid:101)K is written as Kt = VEV(cid:62) with E being the diagonal
the scaled eigenvectors (cid:101)V = VE−1/2 contain coefﬁcients

matrix containing N − 1 non-zero eigenvalues and V con-
taining the corresponding eigenvectors in its columns. Now

for the kernelised orthonormal basis used to replace U in
Eq. (11). Let

H = ((I − M)(cid:101)V)(cid:62)K(I − L),

and with Eq. (9), we can rewrite Eq. (11) as:

HH(cid:62)β = 0.

(12)

(13)

By solving the eigen-problem Eq. (13), we obtain the ﬁnal
C − 1 null projection directions (NPDs) as:

w(i) = ((I − M)(cid:101)V)(cid:62)β(i) ∀i = 1, ..., C − 1.

(14)

3.6. Semi-supervised Learning

The NFST method is a fully supervised method. When
applied to the problem of re-id, the labelled training set is
used to learn the projection W. The test data are then pro-
jected into the same subspace and matched by computing
the Euclidean distance between a query sample and a set of
gallery samples.

In a real-world application scenario, the labelled train-
ing data are scarce but there are often plenty of unlabelled
data (person images collected from different views) that can
be used to alleviate the small sample size problem. To this
end, the NFST method is extended to the semi-supervised
setting. More speciﬁcally, given a training set X contains
a labelled subset Xl of N l samples and an unlabelled sub-
set Xu of N u samples. Using the NFST method described
above, we can ﬁrst learn an initial projection matrix W0 us-
ing Xl only. Then Xu is projected to the lower-dimensional
subspace through W0 and becomes Yu
W0. To utilise the
unlabelled data Xu, we use their projections Yu
W0 to build
a cross-view correspondence matrix A ∈ RNu×Nu which
captures the identity relationship for the unlabelled people
across views. Note, since the data are unlabelled, the true

Algorithm 1 Semi-supervised null space learning
Input: Xl, Xu, k, P0 = 0.
Output: The learned projection W.
1: Estimate W0 using Xl;
2: t = 0;
3: while not converged do
4:
5:
6:
7:
8:
9: end while

project Xu through Wt to obtain Yu
build k-nn graph G with Yu
take top f percent to create the pseudo-classes Pt+1
learn Wt+1 with Xl + Pt+1
t = t + 1

Wt

Wt

cross-view correspondence relationship is unknown. We
therefore use A to represent a soft cross-view correspon-
dence relationship. That is, each person in one view can
correspond to multiple people in another view depending
on their visual similarity in the learned discriminative sub-
space parameterised by W0. To this end, we ﬁrst con-
struct a k-nearest-neighbour (k-nn) graph G across cam-
era views with Nu vertices, where each vertex represents
a unlabelled data point. A is then computed as the weight
matrix of G using a heat kernel. With this k-nn graph, we
then create pseudo-classes, each consisting one vertex from
one view and its k-nearest-neighbours from the other view.
Next these pseudo-classes are augmented with the labelled
classes in Xl to create a new training set, denoted P, on
which a new project matrix W1 is computed using NFST.
Re-learning the projection matrix runs iteratively till the av-
erage distance for the k-nearest-neighbours stop decreasing.
In our experiments, we found that the algorithm converges
rapidly.

This semi-supervised learning is essentially based on
self-training, a popular strategy taken by many semi-
supervised learning methods [45]. For any self-training
based methods, preventing model drift is of paramount im-
portance. Apart from examining the average distance for
the k-nearest-neighbours, another measure taken is to rank
the k-nearest-neighbours and take only the top f percent
with the smallest distance to create the pseudo-classes. The
complete semi-supervised null space learning algorithm is
summarised in Alg. 1.

4. Experiments
4.1. Datasets and Settings
Datasets
Five widely used datasets are selected for ex-
periments, including the three largest benchmarks available
(CUHK01, CUHK03, and Market1501).
VIPeR [11] contains 632 identities and each has two im-
ages captured outdoor from two views with distinct view
angles. All images are scaled to 128 × 48 pixels. The

632 people’s images are randomly divided into two equal
halves, one for training and the other for testing. This is
repeated for 10 times and the averaged performance is re-
ported.
PRID2011 [14] consists of person images recorded from
two cameras. Speciﬁcally, it has two camera views. View
A captures 385 people, whilst View B contains 749 people.
Only 200 people appear in both views. The single shot ver-
sion of the dataset is used in our experiments as in [15]: In
each data split, 100 people with one image from each view
are randomly chosen from the 200 present in both camera
views for the training set, while the remaining 100 of View
A are used as the probe set, and the remaining 649 of View
B are used as gallery. Experiments are repeated over the 10
splits provided in [15].
CUHK01 [19] contains 971 identities with each person
having two images in each camera view. All the images
are normalised to 160 × 60 pixels. Following the standard
setting, images from camera A are used as probe and those
from camera B as gallery. We randomly partition the dataset
into 485 people for training and 486 for testing (multi-shot)
following [22, 41], again over 10 trials.
CUHK03 [20] contains 13,164 images of 1,360 identities,
captured by six surveillance cameras with each person only
appearing in two views. It provides both manually labelled
pedestrian bounding boxes and bounding boxes automati-
cally detected by the deformable-part-model (DPM) detec-
tor [7]. A real-world re-id system has to rely on a person
detector; the latter version of the data is thus ideal for test-
ing performance given detector errors. We report results on
both of the manually labelled and detected person images.
The 20 training/test splits provided in [20] is used under
and the single-shot setting as in [22] – two images are ran-
domly chosen for testing; one is for probe and the other for
gallery.
Market1501 [42] is the biggest re-id benchmark dataset to
date, containing 32,668 detected person bounding boxes of
1,501 identities. Each identity is captured by six cameras
at most, and two cameras at least. During testing, for each
identity, one query image in each camera is selected, there-
fore multiple queries are used for each identity. Note that,
the selected 3,368 queries in [42] are hand-drawn, instead
of DPM-detected as in the gallery. Each identity may have
multiple images under each camera. We use the provided
ﬁxed training and test set, under both the single-query and
multi-query evaluation settings.
Feature Representations
By default the recently pro-
posed Local Maximal Occurrence (LOMO) features [22]
are used for person representation. The descriptor has
26,960 dimensions. To test our method’s ability to fuse dif-
ferent representations, we also consider another histogram-
based image descriptor proposed in [24]. These include
colour histogram, HOG and LBP which are concatenated

resulting in 5138 dimensions.
Evaluation metrics We use Cumulated Matching Char-
acteristics (CMC) curve to evaluate the performance of per-
son re-identiﬁcation methods for all datasets in this paper.
Due to space limitation and for easier comparison with pub-
lished results, we only report the cumulated matching accu-
racy at selected ranks in tables rather than plotting the actual
curves. Note that for the Market1501 dataset, since there are
on average 14.8 cross-camera ground truth matches for each
query, we additionally use mean average precision(mAP) as
in [42] to evaluate the performance.
Parameter setting
There is no free parameter to tune for
our model. However, with the kernelisation, kernel selec-
tion is necessary. Unless stated otherwise, RBF kernel is
used with the kernel width determined automatically using
the mean pairwise distance of samples. For other compared
methods, different model speciﬁc parameters have to be
tuned carefully to report the highest results. Note that under
the semi-supervised null space learning algorithm, there are
free parameters: the value of k in the k-nn graph is ﬁxed to
3 for all experiments. The percentage of neighbours f kept
for creating pseudo classes are ﬁxed at 40%. We found that
the results are not sensitive to the values of these parame-
ters.

4.2. Fully Supervised Learning Results

For the fully supervised setting, all the labels of the train-
ing data are used for model learning. For different datasets,
we select different most representative and competitive al-
ternative methods for comparison.
Results on VIPeR We ﬁrst evaluate our method against
the state-of-the-art on VIPeR. We compare with 17 exist-
ing methods. Among them, the distance metric learning
based methods are RPLM [15], MtMCML [27], Mid-level
Filter [41], SCNCD [38], Similarity Learning [3], LADF
[21], ITML [5], LMNN [35], KISSME [17], and MCML
[9], whilst the others are discriminative subspace learning
based methods including kCCA [24], MFA [36], kLFDA
[36], and XQDA [22]. Note that XQDA can be considered
as hybrid between metric learning and subspace learning. In
addition, deep learning based model is also compared [1].
For fair comparison, whenever possible (i.e. code is avail-
able and features can be replaced), we compare with these
methods using the same LOMO features. Otherwise, the
reported results are presented.

From the results shown in Table 1, we can make the fol-
lowing observations: (1) Our method achieves the highest
performance when a single type of features are used (Rank 1
of 42.28% compared to the closest competitor XQDA [22]
which gives 40.00%). (2) For fair comparison against meth-
ods which fuse more than one types of features [29] or more
than one models [41], we also present our method’s result
obtained by a simple score-level fusion using the two types

Table 1. Fully supervised results on VIPeR
10

1

5

20

Rank
RPLM [15]
MtMCML [27]
MCML [9]
Mid-level [41]
SCNCD [38]
LADF [21]
Improved Deep [1]
Similarity Learning [3]
ITML (LOMO) [5]
LMNN (LOMO) [35]
KISSME (LOMO) [17]
kCCA (LOMO) [24]
MFA (LOMO) [36]
kLFDA (LOMO) [36]
XQDA (LOMO) [22]
Ours (LOMO)
Mid-level+LADF [41]
Metric Ensembles [29]
Ours (Fusion)

27.00
28.83
20.19
29.11
37.80
30.22
34.81
36.80
24.65
29.43
34.81
30.16
38.67
38.58
40.00
42.28
43.39
45.90
51.17

55.30
59.34
47.31
52.34
68.50
64.70
63.61
70.40
49.78
59.78
60.44
62.69
69.18
69.15
68.13
71.46
73.04
77.50
82.09

69.00 83.00
75.82 88.51
63.96 77.69
65.95 79.87
81.20 90.40
78.92 90.44
75.63 84.49
83.70
91.70
63.04 78.39
73.51 84.91
77.22 86.71
76.04 86.80
80.47 89.02
80.44 89.15
80.51 91.08
92.06
82.94
84.87 93.70
88.90 95.80
90.51 95.92

of features described earlier. Our method (Ours (Fusion))
beats the nearest rival [29] by over 5% on Rank 1. (3) The
discriminative subspace learning based methods seem to be
more competitive compared with the distance metric learn-
ing based methods. Note that all of them have been ker-
nelised and we observe a signiﬁcant drop in performance
without kernelisation. This conﬁrms the conclusion drawn
in [36] that kernelisation is critical for addressing the non-
linearity problem in re-id.
(4) The most related methods
MCML [9] and MtMCML [27] yeild much poorer results1,
indicating that the principle of collapsing same-class sam-
ples is better realised in a subspace learning framework
which provides an exact and closed-form solution. (5) The
deep learning based method [1] does not fare well on this
small dataset despite the fact that the model has been pre-
trained on the far-larger CUHK01+CUHK03 datasets. This
suggests that the model learned from other datasets are not
transferable by the simple model ﬁne-tuning strategy and
small sample size remains a bottle-neck for applying deep
learning to re-id.
Results on PRID2011 We compare the state-of-the-
art [15, 29] results reported on PRID2011 in Table 2. With
access to the implementation codes, we also compare with
the methods in [22, 36, 24] using the same LOMO fea-
tures. The results show clearly with a single feature type,
our method is the state-of-the-art; when fusing two types of

1The result of MCML is from [27] using different features. We did
have access to the code of MCML. However, no matter how hard we try, it
would not converge to a meaningful solution using the higher-dimensional
LOMO features.

features, the result is improved dramatically (over 10% in-
crease on both Rank 1 and 5), and signiﬁcantly higher than
the reported results of the feature fusion method in [29],
which fuses four different types of features including the
deep convolutional neural network (CNN) features.

Table 2. Fully supervised results on PRID2011

Rank
RPLM [15]
kCCA (LOMO) [24]
MFA (LOMO) [36]
kLFDA (LOMO) [36]
XQDA (LOMO) [22]
Ours (LOMO)
Metric Ensembles [29]
Ours (Fusion)

1

15.00
14.30
22.30
22.40
26.70
29.80
17.90
40.90

5

32.00
37.40
45.60
46.50
49.90
52.90
39.00
64.70

10

42.00
47.60
57.20
58.10
61.90
66.00
50.00
73.20

20

54.00
62.50
68.20
68.60
73.80
76.50
62.00
81.00

Results on CUHK01 & CUHK03
Compared with
VIPeR and PRID2011, these two datasets are much big-
ger with thousands of training samples. However, the sam-
ple size is still much smaller than the feature dimension,
i.e. the SSS problem still exists. Table 3 shows that on
CUHK01, our method beats all compared existing meth-
ods at low ranks and when two types of features are fused,
the margin is signiﬁcant. As for CUHK03, there are two
versions:
the one with manually cropped person images,
and the one with bounding boxes produced by a detector.
The latter obviously is harder as reﬂected by the decrease
of matching accuracy for all compared methods. But it is
also a better indicator of real-world performance. It can be
seen from Table 4 that, as expected, on this much larger
dataset, the deep learning based model [1] with its millions
of parameters becomes much more competitive – with man-
ually cropped images, our result with single feature type is
higher on Rank 1 but lower on other ranks. However, with
the detector boxes, our method is less affected and outper-
forms the deep model in [1] by a big margin. In addition,
our performance is further boosted by fusing two types of
features.

Table 3. Fully supervised results on CUHK01

Rank
SalMatch [39]
Mid-level Filter [41]
Improved Deep [1]
kCCA (LOMO) [24]
MFA (LOMO) [36]
kFLDA (LOMO) [36]
XQDA (LOMO) [22]
Ours (LOMO)
Metric Ensembles [29]
Ours (Fusion)

1

28.45
34.30
47.53
56.30
54.79
54.63
63.21
64.98
53.40
69.09

5

45.85
55.06
71.60
80.66
80.08
80.45
83.89
84.96
76.40
86.87

10

20

67.95
55.67
74.94
64.96
87.45
80.25
93.00
87.94
92.72
87.26
86.87
92.02
90.04 94.16
89.92 94.36
90.50
84.40
91.77
95.39

Results on Market1501
This dataset is the largest and
most realistic dataset with natural detector errors abundant

1

5

CUHK03 (Manual)

Table 4. Fully supervised results on CUHK03. ’-’ means that no
reported results is available.
Dataset
Rank
DeepReID [20]
Improved Deep [1]
XQDA (LOMO) [22]
Ours (LOMO)
Metric Ensembles [29] 62.10 89.10 94.30 97.80
Ours (Fusion)

20.65 51.50 66.50 80.00 19.89 50.00 64.00 78.50
54.74 86.50 93.88 98.10 44.96 76.01 83.47 93.15
52.20 82.23 92.14 96.25 46.25 78.90 88.55 94.25
58.90 85.60 92.45 96.30 53.70 83.05 93.00 94.80

62.55 90.05 94.80 98.10 54.70 84.75 94.80 95.20

CUHK03 (Detected)
1

10

20

10

20

5

-

-

-

-

in the provided data as they were collected in front of a busy
supermarket. Since it is new, few reported results are avail-
able. The baseline presented in [42] is not competitive be-
cause it is based on a weaker BoW features and L2-Norm
distance. We compare our method with four alternatives
with the same LOMO features. The results in Table 5 again
show that our method signiﬁcantly outperforms the alterna-
tives, under both the single query and multi-query settings
and with both evaluation metrics. This is despite the fact
that with 12,936 training samples, the SSS problem is the
least severe in this dataset.

Table 5. Fully supervised results on Market1501
multiQ

singleQ

Query
Evaluation metrics
Baseline [42]
Baseline (+HS) [42]
KISSME (LOMO) [17]
MFA (LOMO) [36]
kLFDA (LOMO) [36]
XQDA (LOMO) [22]
Ours (LOMO)
Ours (Fusion)

Rank-1 mAP Rank-1 mAP
34.38 14.10 42.64 19.47
47.25 21.88

-

-

-
-

-
-

40.50 19.02
45.67 18.24
51.37 24.43 52.67 27.36
43.79 22.22 54.13 28.41
55.43 29.87 67.96 41.89
61.02 35.68 71.56 46.03

trast, the performance of our method decrease much more
gracefully from 29.80% to 24.70% on Rank 1. This is partly
because our self-training based method can exploit the un-
labelled data. It also shows that it can better cope with the
SSS problem in its extreme.

1

20

VIPeR
5
10

Table 6. Semi-supervised Re-ID results on VIPeR and PRID2011
Dataset
Rank
25.60 53.70 68.20 83.60
SSCDL [25]
13.64 37.97 53.77 69.94 5.80 16.00 24.70 36.00
kCCA (LOMO) [24]
25.47 53.25 66.49 80.13 12.00 27.10 37.80 50.30
kLFDA (LOMO) [36]
XQDA (LOMO) [22]
28.04 56.30 69.65 81.74 12.60 29.40 40.20 53.00
IterativeLap (LOMO) [16] 29.43 49.05 59.18 69.62 18.70 34.60 43.50 52.30
31.68 59.40 72.78 84.91 24.70 46.80 58.20 68.20
Ours (LOMO)
41.01 69.81 81.61 91.04 35.80 58.10 69.10 78.90
Ours (Fusion)

PRID2011
10
5
-
-

20
-

1
-

4.4. Running Cost

We compare the run time of our method with XQDA,
kLFDA and MFA on Market1501. We calculate the overall
training time over 12,936 samples and test time over 3,368
queries. All algorithms are implemented in Matlab and run
on a server with 2.6GHz CPU cores and 384GB memory.
Table 7 shows that for training, our method is the most ef-
ﬁciently, whilst on testing it is much slower than XQDA,
but faster than kLFDA and MFA. Considering the test time
is over 3,368 queries, it is more than adequate for real-time
applications.

Table 7. Run time comparison on Market1501 (in seconds)

Method Ours XQDA [22] kLFDA [36] MFA [36]
Training 393.1
Testing
31.3

995.2
43.4

437.8
43.2

3233.8

1.6

4.3. Semi-supervised Learning Results

For semi-supervised setting, we use the VIPeR and
PRID2011 datasets. The same data splits are used as in
the fully-supervised setting. The difference is that only one
third of the training data are labelled following the setting
in [25, 16]. For comparison, apart from the state-of-the-art
methods in [25, 16], we also choose three subspace learning
based methods trained on the labelled data only.

The results in Table 6 show that the performance of our
method is clearly superior to that of the compared alterna-
tives. The advantage is more signiﬁcant on PRID2011. This
dataset has only 100 pairs or 200 training samples; with
only one third of them labelled, the SSS problem becomes
the most acute than any experiment we conducted before.
Comparing Table 6 with Table 2, it is apparent that the per-
formance of all three compared subspace learning methods,
kCCA, kLFDA, and XQDA degrades drastically. In con-

5. Conclusion

We proposed to solve the person re-id problem by learn-
ing a discriminative null space of the training samples.
Compared with existing re-id models, the employed NFST
model is much simpler, with a closed-form solution and
no parameters to tune. Yet, it is very effective in dealing
with the SSS problem faced by the re-id methods. Exten-
sive experiments on ﬁve benchmarks show that our method
achieves the state-of-the-art performance on all of them un-
der both fully supervised and semi-supervised settings.

Acknowledgement

This work was funded in part by the European FP7

Project SUNNY (grant agreement no. 313243).

References
[1] E. Ahmed, M. Jones, and T. K. Marks. An improved deep
learning architecture for person re-identiﬁcation. In CVPR,
2015. 1, 2, 6, 7, 8

[2] P. Bodesheim, A. Freytag, E. Rodner, M. Kemmler, and
J. Denzler. Kernel null space methods for novelty detection.
In CVPR, 2013. 3

[3] D. Chen, Z. Yuan, G. Hua, N. Zheng, and J. Wang. Similar-
ity learning on an explicit polynomial kernel feature map for
person re-identiﬁcation. In CVPR, 2015. 6, 7

[4] L.-F. Chen, H.-Y. M. Liao, M.-T. Ko, J.-C. Lin, and G.-J. Yu.
A new lda-based face recognition system which can solve the
small sample size problem. Pattern Recognition, 2000. 1, 2
[5] J. V. Davis, B. Kulis, P. Jain, S. Sra, and I. S. Dhillon.
In ICML, 2007. 6,

Information-theoretic metric learning.
7

[6] M. Farenzena, L. Bazzani, A. Perina, M. Cristani, and
V. Murino. Person re-identiﬁcation by symmetry-driven ac-
cumulation of local features. In CVPR, 2010. 1, 2

[7] P. F. Felzenszwalb, R. B. Girshick, D. McAllester, and D. Ra-
manan. Object detection with discriminatively trained part-
based models. TPAMI, 2010. 6

[8] D. Foley and J. Sammon. An optimal set of discriminant

vectors. IEEE Trans. Computers, 1975. 3

[9] A. Globerson and S. T. Roweis. Metric learning by collaps-

ing classes. In NIPS, 2005. 2, 3, 6, 7

[10] S. Gong, M. Cristani, S. Yan, and C. C. Loy. Person Re-

Identiﬁcation. Springer, 2014. 1

[11] D. Gray, S. Brennan, and H. Tao. Evaluating appearance
models for recognition, reacquisition, and tracking. In Proc.
IEEE International Workshop on PETS, 2007. 2, 5

[12] D. Gray and H. Tao. Viewpoint invariant pedestrian recogni-
tion with an ensemble of localized features. In ECCV, 2008.
1, 2

[13] Y.-F. Guo, L. Wu, H. Lu, Z. Feng, and X. Xue. Null foley–

sammon transform. Pattern recognition, 2006. 2, 3, 4

[14] M. Hirzer, C. Beleznai, P. M. Roth, and H. Bischof. Person
re-identiﬁcation by descriptive and discriminative classiﬁca-
tion. In Image Analysis. 2011. 2, 6

[15] M. Hirzer, P. M. Roth, M. K¨ostinger, and H. Bischof. Re-
laxed pairwise learned metric for person re-identiﬁcation. In
ECCV, 2012. 6, 7

[16] E. Kodirov, T. Xiang, and S. Gong. Dictionary learning with
iterative laplacian regularisation for unsupervised person re-
identiﬁcation. In BMVC, 2015. 3, 8

[17] M. Koestinger, M. Hirzer, P. Wohlhart, P. M. Roth, and
H. Bischof. Large scale metric learning from equivalence
constraints. In CVPR, 2012. 1, 2, 6, 7, 8

[18] I. Kviatkovsky, A. Adam, and E. Rivlin. Color invariants for

person reidentiﬁcation. IEEE TPAMI, 2013. 1, 2

[19] W. Li and X. Wang. Locally aligned feature transforms

across views. In CVPR, 2013. 2, 6

[20] W. Li, R. Zhao, T. Xiao, and X. Wang. Deepreid: Deep ﬁlter
pairing neural network for person re-identiﬁcation. In CVPR,
2014. 1, 2, 6, 8

[21] Z. Li, S. Chang, F. Liang, T. S. Huang, L. Cao, and J. R.
Smith. Learning locally-adaptive decision functions for per-
son veriﬁcation. In CVPR, 2013. 1, 2, 6, 7

[22] S. Liao, Y. Hu, X. Zhu, and S. Z. Li. Person re-identiﬁcation
by local maximal occurrence representation and metric
learning. In CVPR, 2015. 1, 2, 6, 7, 8

[23] G. Lisanti, I. Masi, A. Bagdanov, and A. Del Bimbo. Per-
son re-identiﬁcation by iterative re-weighted sparse ranking.
IEEE TPAMI, 2014. 1, 2

[24] G. Lisanti, I. Masi, and A. Del Bimbo. Matching people
across camera views using kernel canonical correlation anal-
ysis. In Proceedings of the International Conference on Dis-
tributed Smart Cameras. ACM, 2014. 2, 6, 7, 8

[25] X. Liu, M. Song, D. Tao, X. Zhou, C. Chen, and J. Bu.
Semi-supervised coupled dictionary learning for person re-
identiﬁcation. In CVPR, 2014. 3, 8

[26] B. Ma, Y. Su, and F. Jurie. Local descriptors encoded by
In ECCV Work-

ﬁsher vectors for person re-identiﬁcation.
shop, 2012. 1, 2

[27] L. Ma, X. Yang, and D. Tao. Person re-identiﬁcation over
camera networks using multi-task distance metric learning.
IEEE TIP, 2014. 1, 2, 6, 7

[28] A. Mignon and F. Jurie. Pcca: A new approach for distance
learning from sparse pairwise constraints. In CVPR, 2012.
1, 2

[29] S. Paisitkriangkrai, C. Shen, and A. ven den Hengel. Learn-
ing to rank in person re-identiﬁcation with metric ensembles.
In CVPR, 2015. 2, 6, 7, 8

[30] S. Pedagadi, J. Orwell, S. Velastin, and B. Boghossian. Local
ﬁsher discriminant analysis for pedestrian re-identiﬁcation.
In CVPR, 2013. 1, 2, 3

[31] B. Prosser, W.-S. Zheng, S. Gong, and T. Xiang. Person re-
identiﬁcation by support vector ranking. In BMVC, 2010. 1,
2

[32] M. Sugiyama. Local ﬁsher discriminant analysis for super-

vised dimensionality reduction. In ICML, 2006. 3

[33] D. Tao, L. Jin, Y. Wang, Y. Yuan, and X. Li. Person re-
identiﬁcation by regularized smoothing kiss metric learning.
IEEE TCSVT, 2013. 1, 2

[34] R. Vezzani, D. Baltieri, and R. Cucchiara. People reidentiﬁ-
cation in surveillance and forensics: A survey. ACM Comput.
Surv., 2013. 1

[35] K. Q. Weinberger, J. Blitzer, and L. K. Saul. Distance metric
learning for large margin nearest neighbor classiﬁcation. In
NIPS, 2005. 6, 7

[36] F. Xiong, M. Gou, O. Camps, and M. Sznaier. Person re-
identiﬁcation using kernel-based metric learning methods. In
ECCV, 2014. 1, 2, 4, 6, 7, 8

[37] L. Yang and R. Jin. Distance metric learning: A comprehen-

sive survey. Michigan State Universiy, 2006. 1

[38] Y. Yang, J. Yang, J. Yan, S. Liao, D. Yi, and S. Z. Li. Salient
color names for person re-identiﬁcation. In ECCV, 2014. 1,
2, 6, 7

[39] R. Zhao, W. Ouyang, and X. Wang. Person re-identiﬁcation

by salience matching. In ICCV, 2013. 1, 2, 7

[40] R. Zhao, W. Ouyang, and X. Wang. Unsupervised salience

learning for person re-identiﬁcation. In CVPR, 2013. 1, 2

[41] R. Zhao, W. Ouyang, and X. Wang. Learning mid-level ﬁl-
In CVPR, 2014. 1, 2, 6,

ters for person re-identiﬁcation.
7

[42] L. Zheng, L. Shen, L. Tian, S. Wang, J. Wang, and Q. Tian.
In ICCV,

Scalable person re-identiﬁcation: A benchmark.
2015. 2, 6, 8

[43] W. Zheng, L. Zhao, and C. Zou. Foley-sammon optimal dis-
criminant vectors using kernel approach. IEEE TNN, 2005.
2

[44] W.-S. Zheng, S. Gong, and T. Xiang. Re-identiﬁcation by
relative distance comparison. IEEE TPAMI, 35(3), 2013. 1,
2

[45] X. Zhu. Semi-supervised learning literature survey. 2005. 5

