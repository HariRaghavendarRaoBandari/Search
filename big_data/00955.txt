6
1
0
2

 
r
a

M
3

 

 
 
]

Y
S
.
s
c
[
 
 

1
v
5
5
9
0
0

.

3
0
6
1
:
v
i
X
r
a

Decentralized State Estimation via a

Hybrid of Consensus and Covariance

intersection

Amirhossein Tamjidi, Suman Chakravorty, Dylan Shell

March 4, 2016

Abstract

This paper presents a new recursive information consensus ﬁlter for decentralized

dynamic-state estimation. No structure is assumed about the topology of the network

and local estimators are assumed to have access only to local information. The

network need not be connected at all times. Consensus over priors which might

become correlated is performed through Covariance Intersection (CI) and consensus

over new information is handled using weights based on a Metropolis Hastings Markov

Chains. We establish bounds for estimation performance and show that our method

produces unbiased conservative estimates that are better than CI. The performance

of the proposed method is evaluated and compared with competing algorithms on an

atmospheric dispersion problem.

0.1 Introduction

This paper studies decentralized estimation using multiple robotic agents with

applications to the estimation of a dynamic random ﬁeld. When the ﬁeld dynamics

can be described by a linear, lumped-parameter model, the classical solution is the

Kalman ﬁlter (KF). However, bandwidth and energy constraints may preclude the

centralized implementation of such a ﬁlter and necessitate the design of a decentralized

estimator.

In general, a decentralized sensor network cannot achieve the estimation quality

of a centralized estimator but is inherently more ﬂexible and robust to network failure

and consequently is advantageous in certain applications [1].

In decentralized estimation settings, the system comprises a set of nodes connected

to each other through a communication network with some topology. Nodes are

assumed to make noisy observations of a global state from which the full state of

the system cannot necessarily be recovered. The goal is to design local estimators

that can recursively calculate an estimate of the global state with access only to

the information locally available to nodes. We desire that estimates be conservative

and the estimator be consistent. No prior knowledge about the network topology is

assumed.

When the topology of the network is known a priori and it remains connected

throughout, some existing methods recover the centralized estimator’s performance

[2, 3] for dynamic state estimation. However, such methods are not applicable for the

case where the network does not remain connected all the time.

For static state/parameter estimation Xia, et al., introduce a method based on

distributed averaging that can converge to the global state estimator provided that

the inﬁnitely occurring communication graphs are jointly connected [4]. This method

1

relies on the distributed averaging property of Metropolis-Hastings Markov Chains

(MHMC). The advantage of it is that the network topology can be dynamically

changing and it need not be connected at all times. The local estimators exchange

information only with their immediate neighbors and remain agnostic about the

topology of the rest of the network. Their work is limited to static ﬁeld/parameter

estimation. In the dynamic state estimation, when the network becomes disconnected,

the estimate priors can drift away while they still have some mutual information.

Performing distributed averaging on those priors is wrong since it results in multiple

counting of the mutual information. In order to solve this problem one would have

to resort to decentralized estimators that account for the correlations between local

estimates.

In [5], a Decentralized Delayed-State Extended Information Filter (DDSEIF) is

described that handles the correlation between local estimates. This method only

works in directed networks that do not have any loops. It is claimed that under certain

assumptions local estimates would converge to the centralized estimate. However, the

method requires a large amount of data communication, storage memory, and book-

keeping overhead, and therefore, does not lend itself to online resource constrained

recursive distributed state estimation.

Another approach to deal with the correlation of local estimates is to use Covariance

Intersection (CI) methods [6] that produce conservative estimates in the absence

of correlation knowledge. The work in references [7, 6, 8, 9, 10, 11] fall into this

category. They propose diﬀerent optimization criteria to perform CI and/or use

diﬀerent iterative CI schemes for decentralized state estimation.

The downside of decentralized CI based methods is that they produce overly

conservative estimates by unnecessarily performing the covariance intersection on

generally uncorrelated new information at the current step. This incurs signiﬁcant

2

performance loss compared to MHMC based distributed averaging, which is a superior

way to reach consensus on uncorrelated information.

Motivating Example

In ﬁg. 1 a motivating example is given for the method proposed in this paper.

Consider an atmospheric dispersion scenario as an example where there exists 6

pollutant sources and 8 receptor distributed in the ﬁeld connected to each other

through a time varying graph. At ﬁrst, all receptors are connected and all the nodes

reach a consensus over the ﬁeld estimate. Later, for a time interval, we have two

disconnected groups. The sensors in each group continue receiving new information

and calculate their local estimates to the best of their knowledge, After some time

the network becomes connected again and agents in each group will get access to

the information accumulated in the other group during the disconnection time. As

explained earlier, since the priors of the two groups become diﬀerent, simple averaging

is no longer applicable, and using Covariance Intersection results in too conservative

estimates. The question is how to handle the consensus over estimates when agents

are connected, during the disconnection time, and after reconnection.

Figure 1: A motivating example: In an atmospheric dispersion scenario there exists
6 pollutant sources and 8 receptor distributed in the ﬁeld connected to each other
through a time varying graph. At ﬁrst all receptors are connected and for a time
interval we have two disconnected groups. The question is how to handle the consensus
over estimates after reconnection.

3

In this paper we strive to bring together the best of the two worlds namely, MHMC

based distributed averaging, and CI. The former is suitable for reaching consensus

over uncorrelated information and the later is useful for combining estimates whose

correlations are unknown or diﬃcult to keep track of. We propose a hybrid scheme

that has comparable performance to MHMC consensus while being robust to network

failures like the one in Fig. 1. Albeit the method is explained with respect to the

dynamic ﬁeld estimation example, it is more generally applicable to most distributed

estimation scenarios.

In Section 0.2, the notation used in this paper is explained as well as assumptions

and system model. Section 0.3 discusses some preliminaries on distributed estimation

which paves the way for introducing our problem objective and method. Our proposed

method is presented in Section 0.4 along with its theoretical performance analysis

compared to MHMC and CI. We extensively evaluate our method’s performance in

Section 0.5.

0.2 Modeling

In this paper the atmospheric dispersion problem is considered as a study case. The

three-dimensional advection-diﬀusion equation describing the contaminant transport

in the atmosphere is:

+ ∇ · (c(cid:126)u) = ∇ · ( (cid:126)K∇c) + Qδ( (cid:126)X − (cid:126)Xs),

∂c
∂t

(1)

where c(x, y, z, t) is the mass concentration at location (cid:126)X = (x, y, z), (cid:126)Xs = (xs, ys, zs)

is the location of the point source.
(cid:126)u is the wind velocity, and assume (cid:126)u =
(ucos(α), usin(α), 0), for some constant u ≥ 0, α is the direction of the wind in the

horizontal plane and the wind velocity is aligned with the positive x-axis when α = 0 .

Q is the contaminant emitted rate. The eddy diﬀusivities (cid:126)K = (Kx(x), Ky(x), Kz(x))

4

are functions of the downwind distance x only. Assume that the wind velocity is

suﬃciently large that the diﬀusion in the x-direction is much smaller than advection,

such that the term Kx∂2

xc can be neglected. The boundary conditions are:

c(0, y, z, t) = 0, c(∞, y, z, t) = 0,
c(x,±∞, z, t) = 0, c(x, y,∞, t) = 0,

Kz

∂c
∂z

(x, y, 0, t) = 0.

(2a)

(2b)

(2c)

With proper discretization of the above PDE, one can deﬁne a state vector by stacking

the values of the ﬁeld at a given time k over all sites of the discretization lattice.

The PDE model then becomes a lumped parameter, discrete-time linear (LTI) state

equation of the form

x(k + 1) = Ax(k) + Bu(k),

(3)

where x(k) = [Fk(1, 1, 1)··· Fk(n, n, n)] and Fk(ix, iy, iz) = c(ix∆x, iy∆y, iz∆z, k∆t).

Stochastic Field Model

Since we consider the case where we have noise and the system is stochastic, we

model the evolution of the ﬁeld using the following equation which relates the state

at time step k to k + 1:

x(k + 1) = Ax(k) + Bu(k) + w(k).

(4)

In the above equation u(k) ∈ Rm accounts for m input variables and the vector w(k) ∼
N (0, Q(k)) represents additive white noise used to model unknown perturbations.

5

Network Topology

Assume that we have N homogeneous agents associated with nodes of a graph.

These agents can communicate with each other under a time-varying network topology
Gk = (cid:104)Vk,Ek(cid:105) where Vk and Ek are the set of graph nodes and edges respectively. If
(i, j) ∈ Ek, it means agents i and j can communicate. The node corresponding to the

i-th agent is denoted by vi. Neighbors of node vi are deﬁned as

N i = vi ∪ {∀vj ∈ V, (i, j) ∈ E}.

(5)

Also |N i| is the cardinality of N i.

Each agent has a processor and a sensory package on-board. Sensors make

observations every ∆t seconds and processors and the network are fast enough to

handle calculations based on message passing among agents every δt seconds. We
assume that δt (cid:28) ∆t. We also assume that the agents exchange their information

over the communication channel which is free of delay or error.

We assume that x(k) denotes the state of the ﬁeld at time-step k. Each agent

retains a local version of x(k) which is denoted by xi(k). For random variables we
use the following notation: ˆx = E(x) and Px = E[x − ˆx]2 are the expected value and

the covariance of the random variable x respectively.

Observation Model

We assume that each agent has a sensor that produces noisy observations that

are functions of the state of the ﬁeld. The observation model of the i’th sensor is

zi(k) = Hi(k)x(k) + vi(k),
vi(k) ∼ N (0, Ri(k)).

(6)

(7)

6

0.3 Decentralized Filtering Preliminaries

Filtering is the process of recursively computing the posterior probability of a

random dynamic process x(k) conditioned on a sequence of measurements Z k =
{z(1), z(2), . . . , z(k)}, where z(k) denotes the observation vector at the time-step k.

Under the Gaussian assumption, the Kalman Filter (KF) is the optimal recursive

ﬁlter for linear state space systems. The KF consists of a prediction and an update.

The former uses the motion model to propagate the uncertainty to the next step,

and the latter makes adjustments to the predicted values using the most recent

observation. We denote the predicted and estimated mean and covariance at time k
by (ˆx−(k), P −(k)) and (ˆx(k), P (k)).

Centralized Kalman Filter

The KF steps are generally formulated based on the mean and covariance matrix

representation of gaussian random variables involved; however, an alternative repre-

sentation, called the information form of the KF is more useful and intuitive in the

development of the decentralized ﬁlter. In this representation we deﬁne

x (k)x(k),

y(k) = P −1
Y (k) = P −1

x (k),

(8a)

(8b)

where y(k) and Y (k) are the information vector and information matrix respectively.

The prediction step of the KF can then be written as

M (k) = A−T Y (k − 1)A−1,
P (k) = M (k) + Q(k)−1,
y−(k) = M (k) − M (k)P (k)−1M (k),

7

(9a)

(9b)

(9c)

y−(k) = Y −(k)AY (k − 1)y(k − 1).

(9d)

The information content of an observation zj(k) is δij(k) = H T

with the information matrix δI j(k) = H T

j (k)Rj(k)

−1zj(k) along
−1Hj(k). Assuming that information

j (k)Rj(k)

from all agents is available to a central processor, the update step of KF can be

carried out by adding the information from diﬀerent observations to the predicted

values.

y(k) = y−(k) +

y(k) = y−(k) +

(cid:88)N
(cid:88)N

j=1

j=1

δij(k)

δI j(k)

(10a)

(10b)

This formulation is called the Centralized Information Filter (CIF).

The fundamental assumption in the CIF is that there is a central processor which

has access to all the information available. However, when there is no central processor

and each agent can only communicate with its neighbors, we want to formulate a

decentralized version of the information ﬁlter. When run by all agents they should

converge to the centralized estimate of the ﬁeld state.

Decentralized Estimator Designs

1) Consensus Based Estimator

We start with CIF procedure outlined in previous section. Looking at Eq. 10, one

can see that δi(k) (cid:44) N(cid:0) 1

N

j=1 δij(k)(cid:1) (cid:44) N ¯δi(k) and δI(k) (cid:44) N(cid:0) 1
(cid:80)N

N

j=1 δI j(k)(cid:1) (cid:44)
(cid:80)N

N ¯δI(k).

Now if all the agents have the same prior information and if via a distributed

averaging method the agents can reach a consensus over ¯δi(k) and ¯δI(k), they can

use Eq. 10 to get a decentralized estimate whose results asymptotically converge to

8

the centralized estimate.

Fortunately, such a method exists. The distributed averaging method of [4] makes

minimal assumptions about the network topology and only relies on local information

exchange between neighboring nodes of a graph to reach a consensus over the average

initial value of the nodes. The method uses an iterative linear consensus ﬁlter based

on the weights calculated from an MHMC. To avoid confusion we use l to indicate

consensus iteration throughout this paper. Consider communication graph G(l).

One can use the message passing protocol of the form x(l + 1) =(cid:80)|Nl|

j=1γij(l)xj(l) to
calculate the average of the values on the graph nodes in which di(l) = |N i(l)| is the

degree of the node vi, and

γij(l) =



1

1+max{di(l),dj (l)}

1 −(cid:80)

if (i, j) ∈ El,

(i,m)∈E(l) γim if i = j,

(11)

0

otherwise .

Note that for each node i, γij’s only depend on the degrees of its neighboring nodes.

Also, due to averaging property of MHMC weights, after reaching consensus, MHMC

estimates converge to the centralized estimator’s results. Therefore, given the ideal

centralized estimate (ˆx, Px), we have ˆxM H

i = ˆx and P M H

xi

= Px in the limit.

In many practical cases the priors become diﬀerent as a result of network dis-

connection. In those cases agents have some shared information from the time they

were connected to each other and accumulate some new information during the

disconnection time. Consequently, priors become diﬀerent over the network and after

reconnection, their consensus should be handled carefully.

9

2) Covariance Intersection Based Estimator

It follows from the above discussion that if the priors are not the same among

the network nodes, distributed averaging alone will not produce consistent estimates.

One way of handling such a scenario is using Covariance Intersection (CI) methods.

We may use an iterative Covariance Intersection method to reach a consensus over the

local estimates when the priors are not the same, either due to disconnection or early

stopping of consensus process. In iterative CI, the goal is to fuse diﬀerent estimates of

a random variable without having any knowledge about the cross covariance between

such estimates. Iterative CI, iteratively solves the following optimization problem

and updates local estimates accordingly until it reaches consensus.

Iterative CI

At each iteration l, for each agent, deﬁne the local information to be

Ii(l) ∆= Yi(l) + δIi(l).

Solve for w∗ such that

ω∗ = argmin

J(cid:0)[
(cid:88)|N i(l)|

ω

s.t.

ωj = 1,

j=1

(cid:88)

j∈N i(l)

ωjIj(l)]−1(cid:1),

∀j ωj ≥ 0,

(12)

where J (·) is an optimization objective function; It can be trace(·) or log det(·).

Estimates are then updated locally for the next iteration

yi(l + 1) =(cid:80)
Yi(l + 1) =(cid:80)

j∈N i(l)ω∗
j∈N i(l)ω∗

j [yj(l) + δij(l)],

j [Yj(l) + δIj(l)].

(13)

(14)

10

As will be discussed in Section 0.4, CI and iterative CI (ICI) generate conservative
estimates which means that E[x − ˆxCI
≥ Px for the local

] = E[x − ˆxi] = 0 and P CI

i

xi

estimates and the consensus value. The disadvantage of CI is that it generates overly

conservative estimates by continually neglecting the cross correlation information.

Problem Objective

Our goal is to design a network agnostic recursive decentralized estimator to

calculate the local estimate xi along with an associated covariance Pxisuch that the

following properties hold:

E[x − ˆxCI
J (P M H

] = E[x − ˆxi] = E[x − ˆxM H
) ≤ J (Pxi) ≤ J (P CI

),

i

i

xi

xi

] = 0,

(15)

i.e., we are looking for an unbiased estimate whose covariance is less than that of CI.

0.4 Hybrid CI consensus

We propose to use iterative CI to reach consensus over priors and the MHMC

based consensus ﬁlter for distributed averaging of local information updates. Our

method is summarized in Algorithm 1. We explain the ﬂow of the proposed method

using a simple scenario with two agents. Generalization to more than two agents is

straightforward and follows similar steps.

Imagine a scenario consisting of two agents, observing a dynamic ﬁeld with state

vector x, that are communicating with each other through a time-varying network
topology. At time t0, the agents start with priors [y−

1 (t0)] and [y−

2 (t0), Y −

1 (t0), Y −

2 (t0)]

respectively.

At time t1 the ﬁeld evolves to the new state x(t1) and agents calculate their own

local prediction (line 1 in the algorithm). Then they make observations z1(t1) and

11

Algorithm 1: Proposed Method

Input

: [yj(t0), Yj(t0)]

1 Use Eqns. 9c - 9d to calculate predicted values [y−

j (t1), Y −

j (t1)] given

[yj(t0), Yj(t0)] Collect local observation zj(t1) and calculate jacobian and noise
covariance [Hj(t1), Rj(t1)] Calculate the local information update

δij(t1) = H T
δIj(t1) = H T

j (t1)R−1
j (t1)R−1

j (t1)zj(t1)
j (t1)Hj(t1)

Initialize consensus variables (l = 0)

[y k
j , Y l
[δi l
j, δI l

j (t1), Y −

j ] = [y−
j] = [δij(t1), δI j(t1)]

j (t1)]

while NOT COVERGED do
j , δi l
BROADCAST[y l
l, δI l
RECEIVE[y l
l , Y l
Collect received data

j, Y l
l , δi l

j, δI l
j]
l] ∀l ∈ N j(l)

Ck
j = {y k
Mk
j = {δi k

l , Y k
l , δI k

| l ∈ N j(k)}
l | l ∈ N j(k)}

l

Do one iteration of CI on consensus variables for local prior information Cl

j

[y l+1

j

, Y l+1

j

] = CI(Cl
j)

Do one iteration of MHMC on consensus variables for new information Cl

j

[δi l+1

j

, δI l+1

j

] = MHMC(Ml
j)

l ← l + 1

2

3

4

5

6

7 Calculate the posteriors according to:

Yj(t1) = Y l
yj(t1) = y l

j + nCGδI l
j + nCGδi l

j

j

return Yj(t1), yj(t1)]

12

z2(t1), respectively, and compute the local information updates [δi1(t1), δI 1(t1)] and

[δi2(t1), δI 2(t1)] (lines 2 and 3 of the algorithm).

The two agents, if performing CI, would ﬁnd a fused estimate

Y CI = wCI(Y −

1 + δI 1) + (1 − wCI)(Y −

2 + δI 1),

where wCI is obtained from solving the optimization problem in Eq. 12. Note that
doing MHMC alone is not possible here since Y −

2 are diﬀerent. In our hybrid

1 and Y −

method we do the following:

Y Hyb = wHybY −

(cid:124)

(cid:125)
1 + (1 − wHyb)Y −

(cid:123)(cid:122)

2

CI to reach

consensus over priors

(cid:124)

(cid:123)(cid:122)

.

+ δI 1 + δI 2
consensus over
the incremental

information

(cid:125)

1 + (1 − wCI)Y −

2 ) ≥
It can be seen that δI 1+δI 2 ≥ wCIδI 1+(1−wCI)δI 2 and J (wHybY −
J (wCIY −
2 and Y −
has the optima wHyb. If J (·) has the property that if J (Y1) ≥ J (Y2) and I1 ≥ I2
then J (Y1 + I1) ≥ J (Y2 + I2), then our method is guaranteed to outperform CI.

2 ) due to the fact that optimization problem for Y −

1 +(1−wHyb)Y −

2

For an N -agent system with the i(cid:48)th agent having prior Y −

, the ICI approach

i

is used to ﬁnd a consensus over the priors using Eq. 12 recursively. The MHMC

approach is used to form the consensus over the new information, i.e.,(cid:80)N

j=1 δI j (Eq.

11). In line 12 of the algorithm, nCG is the number of agents that form a connected

group, and it can be determined by assigning unique IDs to the agents and passing

these IDs along with the consensus variables. Each agent keeps track of unique IDs it

receives and passes them to its neighbors. The following propositions hold.

Proposition 1. If the objective function J is strictly convex, the ICI process is
guaranteed to reach a consensus over the priors, i.e., ∃Y −
∞ ∀i as

i (l) → Y −

∞ , Y −

13

l → ∞. The same result holds for the information vector as well.

Proof. At each iteration ’l’ and for each agent ’j’, ICI solves an instance of the

optimization problem in Eq. 12. The ICI updates local variables, Yi(l), according to

(cid:88)

j∈N i(l)

Yi(l + 1) =

ω∗
j Yj(l).

(16)

(17)

The very deﬁnition of the optimization problem requires that1

J (Y −1

i

(l + 1)) ≤ J (Y −1

j

(l)) ∀j ∈ N i(l)

Lets deﬁne V (Yi, l) = J (Y −1

i

at iteration l to be

N(cid:88)

(l)). Take the Lyapunov function of the whole network

V(Y1,··· YN , l) =

V (Yi, l).

(18)

If J (X−1) is a positive and monotonically decreasing function over the set of {X ∈
S + (cid:44) Symmetric Positive Deﬁnite matrices}, i.e., J (X−1) > 0 ∀X ∈ S + and

i=1

∀X, Y ∈ S +, X ≥ Y ⇒ J (X−1) ≤ J (Y −1),

then ∀l, V(Y1,··· YN , l) > 0. Also, based on Eq.
17 V(Y1,··· YN , l + 1) ≤
V(Y1,··· YN , l). Since V(Y1,··· YN , l) is monotonically decreasing and since it is

a positive function, it has a lower bound > 0. If it reaches this lower bound, all Yi’s
should be equal; otherwise, V(Y1,··· YN , l + 1) < V(Y1,··· YN , l) due to the strictly
convex property of J which is a contradiction. Therefore, by performing ICI, the

Lyapunov function of the network is guaranteed to reach a lower bound in which

all Yi’s are equal. Therefore if there exists a Y∞ then the network is guaranteed

1Can be easily proved by contradiction.

14

to converge to it. Conditions for J (X−1) are satisﬁed for J (X−1) = log det(X−1).

Remark 1. It is straghtforward to show that ICI and our method both produce

unbiased estimates. Regardig the second part of Eq. 15, our extensive experiments

on the system considered in this paper and various other systems show that the
inequality holds for J = log det(·). The existence of a theoretical proof is currently

being investigated and will be the subject of future work.

0.5 Experiments

We perform two sets of experiments on an atmospheric dispersion problem to show

the eﬀectiveness of our method and evaluate its performance during disconnection and

after reconnection. This is a three dimensional problem and after proper discretizing

of its Partial Diﬀerential Equation (PDE), we get a system in the format of Eq. 4.

For our experiments after discretization, the dimension of the state is 80. We

assume that there are 10 sources emitting pollutant Zinc (referred to as Zn from now

on) into atmosphere. There are also 9 receptors making noisy measurements of the

concentrations of Zn around their location in space. We assume that receptors can

communicate to each other through a time varying network which does not remain

connected at all times. Receptors receive information only from their immediate

neighbors. They all have access to the sources’ locations and the source emission is

modeled as a white noise process with known covariance.

Investigating the eﬀect of disconnection on estimation performance

In this experiment we intend to evaluate the performance of the proposed method

during the phase where some receptors become disconnected from the rest of the

group and get connected again after some interval. The topology of the network takes

one of the forms depicted in Fig. 2. The network starts fully connected and starting

15

from timestep 3, receptors 7, 8 and 9 become isolated and remain in this situation

for 2 steps, then they are connected back to the rest of the receptors. Similarly,
disconnection happens in intervals [17 − 20] and [23 − 30].

In order to make a comparison we obtain the estimation result using pure CI, our

method and also a centralized estimator to see how much of its performance can be

recovered. Note that the MHMC consensus cannot be done here due to disconnection.

The results are depicted in Fig. 3. We use three measures to evaluate the estimates.

1. The Bhattacharyya distance [12] between the estimation results and the cen-

tralized estimator. The Bhattacharyya distance can be used to evaluate the

similarity of two continuous probability distribution function. For gaussian
distributions parametrized as (µ1, Σ1), and (µ2, Σ2), 0 ≤ DB(p1, p2) ≤ 1 and is

deﬁned:

DB(p1, p2) = e−D(p1,p2)

(19)

1
8
det Σ

(µ1 − µ2)T Σ(µ1 − µ2)+
Σ1 + Σ2

D(p1, p2) =

√

ln

1
2

det Σ1 det Σ2

, Σ =

2

Here DB(p1, p2) = 1 means complete similarity and DB(p1, p2) = 0 means

complete dissimilarity.

2. [ det Pcen

det PCI/Hyb

]

1

nd which is a non-dimensionalized measure of covariance volume

ratio in which nd is the dimensionality of the state vector.

3. rmse estimation error.

As it can be seen, the proposed method outperforms pure CI as expected and is able

to get the performance very close to centralized estimator results after reconnection.

16

Figure 2: Topology of the Network when all receptors are connected (left) and when
receptors 7,8 and 9 get disconnected from the rest of the group (right).

Based on Bhattacharyya distance, closeness between centralized and decentralized

estimators drops during disconnection interval as expected since receptors do not

have access to all the information available to the centralized estimator. While the

proposed method is able to immediately recover after reconnection, pure CI continues

to have lower performance even after re-connection due to the fact that it ignores the

correlations.

Fig. 4 takes a closer look at the performance of the proposed method and compares

the estimation results of receptor 5 and 8 during two diﬀerent time steps. The vertical

axes represent consensus steps not time. Based on Fig. 2, receptor 5 remains in a

group of size 6 during disconnection period whereas receptor 8 remains totally isolated

in that period. The higher diﬀerence between centralized and decentralized estimate

for this receptor can be explained based on the fact that it has less information at

its disposal. However, after reconnection both receptors are able to converge to the

same value which is very close to the centralized estimator.

Performance analysis and robustness to link failure

In this experiment we evaluate the performance of our method in a systematic

way to establish its usefulness and robustness to networks with high probability of

link failure. We consider the same system as in the ﬁrst experiment and simulate it

for 50 time steps. At the beginning of each step a 4 regular graph with 9 nodes is

generated, and given a probability of failure for each link, some links in the graph

17

will randomly be disconnected. Depending on the regularity degree, and probably of

failure, in some percentage of times, the graph still remains connected. However, if

the regularity degree goes down or the probability of failure increases, more often

than not, the graph becomes disconnected.

In practice, for p ≥ 0.2, consensus methods are no longer guaranteed to succeed

since the network almost always get disconnected at some point in time.

We ran our method for 50 steps, as explained earlier, for each probability of

link failure and compared its performance with the ideal centralized result (which is

obtained by assuming full connectivity at all times). The performance is evaluated

by calculating the average value for Bhattacharyya distance and determinant ratio

measure at all steps and for all receptors. Based on Fig. 5, for the case considered

in this experiment, our decentralized estimator performs very similar to the ideal
centralized one for p ∈ [0.0, 0.4] while drastically outperforming pure CI all the time.

This means that in the case considered here, our method can perform almost as well

as the ideal estimator for an unreliable network. Obviously, the performance can vary

from one system to another and under diﬀerent network topologies. However, our

method can recover the performance of the centralized method when the network

is unreliable and substantially outperforms pure CI always as it has already been

established theoretically.

0.6 Conclusion

This paper proposes a decentralized estimator for dynamic systems in networks

with changing topology and those that do not remain connected all the time. Sepa-

rating the process of consensus for the correlated and uncorrelated information was

the key to achieve a better performance compared to Covariance Intersection alone.

Evaluating the proposed method on an 80-dimensional estimation problem showed

18

substantial performance improvement compared to CI and also the ability to recover

after a disconnection interval occurs.

19

4 · 10−2
3 · 10−2
2 · 10−2
1 · 10−2
0

r
o
r
r
e

e
s
m

r

0
8
/
1

]
o
i
t
a
r

t
e
d
[

1

0.8

0.6

rmse error

Hybrid
CI
Centralized

0

5

10

15

20

25

30

35

40

45

50

time(s)

[det ratio]1/80

Hybrid
CI

0

5

10

15

20

25

30

35

40

45

50

time(s)

Bhattacharyya Distance

1

B
D

0.5

0

0

Hybrid
CI

5

10

15

20

25

30

35

40

45

50

time(s)

Figure 3: Comparison of the estimation results using centralized kalman ﬁlter, pure
covariance intersection, and our method.

20

Figure 4: Estimation performance comparison among receptors.

21

[det ratio]1/80

Hybrid
CI

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Probablity of Link Failure
Bhattacharyya Distance

Hybrid
CI
Centralized

0
8
/
1

]
o
i
t
a
r

t
e
d

[

B
D

1

0.9

0.8

0.7

0.6

1

0.8

0.6

0.4

0.2

0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Probablity of Link Failure

Figure 5: Composite diagram for performance comparison for diﬀerent probablity of
link failure.

22

Bibliography

[1] H. Zhang, J. Moura, and B. Krogh, “Dynamic ﬁeld estimation using wireless

sensor networks: Tradeoﬀs between estimation error and communication cost,”

Signal Processing, IEEE Transactions on, vol. 57, no. 6, pp. 2383–2395, June

2009.

[2] R. Olfati-Saber, “Distributed kalman ﬁlter with embedded consensus ﬁlters,”

in Decision and Control, 2005 and 2005 European Control Conference. CDC-

ECC’05. 44th IEEE Conference on.

IEEE, 2005, pp. 8179–8184.

[3] R. Olfati-Saber and J. S. Shamma, “Consensus ﬁlters for sensor networks and

distributed sensor fusion,” in Decision and Control, 2005 and 2005 European

Control Conference. CDC-ECC’05. 44th IEEE Conference on.

IEEE, 2005, pp.

6698–6703.

[4] L. Xiao, S. Boyd, and S. Lall, “A scheme for robust distributed sensor fusion

based on average consensus,” in Information Processing in Sensor Networks,

2005. IPSN 2005. Fourth International Symposium on, April 2005, pp. 63–70.

[5] J. Capitan, L. Merino, F. Caballero, and A. Ollero, “Delayed-state information

ﬁlter for cooperative decentralized tracking,” in Robotics and Automation, 2009.

ICRA ’09. IEEE International Conference on, May 2009, pp. 3865–3870.

23

[6] L. Chen, P. O. Arambel, and R. K. Mehra, “Estimation under unknown correla-

tion: covariance intersection revisited,” Automatic Control, IEEE Transactions

on, vol. 47, no. 11, pp. 1879–1882, 2002.

[7] Y. Wang and X. Li, “Distributed estimation fusion with unavailable cross-

correlation,” Aerospace and Electronic Systems, IEEE Transactions on, vol. 48,

no. 1, pp. 259–278, Jan 2012.

[8] D. Casbeer and R. Beard, “Distributed information ﬁltering using consensus

ﬁlters,” in American Control Conference, 2009. ACC ’09., June 2009, pp. 1882–

1887.

[9] J. Hu, L. Xie, and C. Zhang, “Diﬀusion kalman ﬁltering based on covariance

intersection,” Signal Processing, IEEE Transactions on, vol. 60, no. 2, pp. 891–

902, 2012.

[10] Z. Deng, P. Zhang, W. Qi, J. Liu, and Y. Gao, “Sequential covariance intersection

fusion kalman ﬁlter,” Information Sciences, vol. 189, pp. 293–309, 2012.

[11] A. Cristofaro, A. Renzaglia, and A. Martinelli, “Distributed information ﬁlters

for mav cooperative localization,” in Distributed Autonomous Robotic Systems.

Springer, 2013, pp. 133–146.

[12] A. Bhattacharyya, “On a measure of divergence between two multinomial popu-

lations,” Sankhy¯a: The Indian Journal of Statistics, pp. 401–406, 1946.

24

