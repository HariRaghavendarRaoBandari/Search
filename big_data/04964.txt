6
1
0
2

 
r
a

 

M
6
1

 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
4
6
9
4
0

.

3
0
6
1
:
v
i
X
r
a

Optimal Remote State Estimation for Self-Propelled Particle

1

Models

Shinkyu Park and Nuno C. Martins

Abstract

We investigate the design of a remote state estimation system for a self-propelled particle (SPP). Our framework
consists of a sensing unit that accesses the full state of the SPP and an estimator that is remotely located from the
sensing unit. The sensing unit must pay a cost when it chooses to transmit information on the state of the SPP to the
estimator; and the estimator computes the best estimate of the state of the SPP based on received information. In this
paper, we provide methods to design transmission policies and estimation rules for the sensing unit and estimator,
respectively, that are optimal for a given cost functional that combines state estimation distortion and communication
costs. We consider two notions of optimality: joint optimality and person-by-person optimality.1 Our main results
show the existence of a jointly optimal solution and describe an iterative procedure to ﬁnd a person-by-person optimal
solution. In addition, we explain how the remote estimation scheme can be applied to tracking of animal movements
over a costly communication link. We also provide experimental results to show the effectiveness of the scheme.

I. INTRODUCTION

Consider a self-propelled particle (SPP) moving in a two-dimensional plane whose state xk is represented as

follows:

with the initial condition x0 = x0 =
p1,0
tional and angular velocities, respectively.

p2,0

θ0

. The random processes vk and φk represent the transla-

In this paper, we consider a remote estimation system formed by a sensing unit and remotely located estimator:
The sensing unit accesses xk and has the authority to decide whether to transmit it to the estimator. The sequence

Shinkyu Park and Nuno C. Martins are with the Department of Electrical and Computer Engineering, University of Maryland College Park,

College Park, MD 20742-4450, USA. {skpark, nmartins}@umd.edu

1The precise deﬁnitions of joint optimality and person-by-person optimality are given in Deﬁnition II.2 and Deﬁnition II.3, respectively.

where (p1,k, p2,k) and θk represent the location in the plane and the orientation at time k, respectively. The state
of the SPP evolves according to the following model:

(1)

xk =

p1,k p2,k θk

(cid:16)
 =

(cid:17)T ∈ R2 × [0, 2π)
 , k ≥ 0
p1,k + vk cos (θk + φk)
(cid:17)T

p2,k + vk sin (θk + φk)

θk + φk

p1,k+1
(cid:16)

p2,k+1

θk+1

2

of decisions on whether to transmit is represented by Rk, for which Rk = 1 if the sensing unit decides to transmit
and Rk = 0 otherwise. The cost of each transmission is represented by ck. The estimator computes a state estimate
based on received information. The diagram in Fig. 1 depicts the overall framework

(cid:17)T

(cid:16)

ˆp2,k

ˆθk

ˆxk =
ˆp1,k
adopted here.

A. Outline of Main Results

Let a transmission policy T k and an estimation rule Ek for the sensing unit and estimator at time k, respectively,

be deﬁned as follows:

(cid:110)

xj

where the variable I k =
k.

T k :(cid:0)R2 × [0, 2π)(cid:1)k+1 × {0, 1}k−1 → {0, 1}
Ek :(cid:0)R2 × [0, 2π)(cid:1)|Ik|+1 × {0, 1}k → R2 × [0, 2π)
(cid:12)(cid:12)(cid:12) Rj = 1, 1 ≤ j ≤ k

(cid:111)

represents information transmitted to the estimator up to time

Our main goal is to obtain methods to design transmission policies (T 1,··· ,T N ) and estimation rules

(E1,··· ,EN ) that are optimal for the following cost functional:

J (x0, (T 1,··· ,T N ) , (E1,··· ,EN ))

N(cid:88)

E(cid:104)

=

d2 (xk, ˆxk) + ck · Rk

(cid:12)(cid:12)(cid:12) x0 = x0, (T 1,··· ,T N ) , (E1,··· ,EN )
(cid:105)

subject to the SPP model (1) and

k=1

for each k in {1,··· , N}, where we use Frobenius norm to deﬁne the metric d as follows:

Rk = T k ((x0,··· , xk) , (R1,··· , Rk−1))
ˆxk = Ek

(cid:0)(cid:0)x0,I k(cid:1) , (R1,··· , Rk)(cid:1)
 −

cos θk

p1,k

p2,k

cos ˆθk − sin ˆθk

cos ˆθk

sin ˆθk

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
cos θk − sin θk

sin θk

0

0

1

0

0

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)F


ˆp1,k

ˆp2,k

1

d (xk, ˆxk) =

(2)

(3a)

(3b)

Our problem is non-trivial because (2) is in general non-convex and searching for a solution that achieves the
minimum over a function space is computationally complex. We adopt a team decision framework in which the
sensing unit and the estimator are viewed as players. The following are our main contributions:

1) First, we show that there is a jointly optimal solution which minimizes the cost functional (2). As joint
optimality implies person-by-person optimality, this result ensures that the set of person-by-person optimal
solutions is non-empty.

2) We propose an iterative procedure, which is inspired by Lloyd’s algorithm [1], to compute a person-by-person
optimal solution. The procedure alternates between ﬁnding the best transmission policies for (2) with the
estimation rules ﬁxed, and vice versa; and it generates a sequence of sub-optimal solutions. Our analysis

1 Transmission

0 No Transmission

Rk =

{xk}N

k=1

S

SPP

I N

E

{ˆxk}N

k=1

3

(cid:110)

Fig. 1.
IN =

xk

(cid:12)(cid:12)(cid:12) Rk = 1, 1 ≤ k ≤ N

(cid:111)

.

A remote estimation framework comprised of a self-propelled particle (SPP), a sensing unit (S), and an estimator (E), where

will show that the sequence has a convergent subsequence; and the limit of any convergent subsequence is a
person-by-person optimal solution.

3) We illustrate the performance of the optimal remote estimation scheme in the context of tracking of animal
movements over a costly communication link. Our numerical results use GPS data collected from a monitoring
device mounted on an African buffalo.

B. Paper Organization

In Section II, we describe the problem formulation considered throughout the paper, and brieﬂy describe our
methodology to ﬁnd a solution. The main strategy is to decompose the problem into sub-problems, which we can
solve sequentially. In Section III, we examine the existence of a jointly optimal solution to each sub-problem.
We also describe an iterative procedure for ﬁnding a person-by-person optimal solution. Section IV discusses an
application of our results to tracking of animal movements and also presents experimental results.

A. Notation and Terminology

II. PROBLEM FORMULATION

• For a ﬁnite sequence of elements a1,··· , aN belonging to a set, we adopt the shorthand notation a1:N = (a1,··· , aN ).
• For a ﬁnite sequence of functions A1,··· ,AN deﬁned on a set, we adopt the shorthand notation A1:N = (A1,··· ,AN ).
• For {Rj}k−1

j=1 , we deﬁne2

(cid:12)(cid:12)(cid:12) Rj = 1
(cid:111)

(cid:110)

τk = max

1 ≤ j ≤ k − 1

We refer to τk as the last transmission time before time k.

2We adopt a convention that τk = 0 if Rj = 0 for all j in {1, · · · , k − 1}.

4

B. Problem Description

We start by assuming that transmission policies and estimation rules have the following structure3: The transmis-
sion policy, which may be randomized4, at time k depends on the last transmission time τk, the information xτk
transmitted to the estimator at time τk, and the current state xk of the SPP. The estimation rule at time k depends
on the last transmission time τk and the information xτk received from the sensing unit at time τk.

According to (3) and the structural assumptions mentioned above, the variable Rk and estimate ˆxk are determined

by a transmission policy T k and an estimation rule Ek as follows:

Rk = T k (τk, xτk , xk)

Ek (τk, xτk )

xk

ˆxk =

if Rk = 0

otherwise

(4a)

(4b)

We formally state our main problem as follows.

Problem II.1: Find transmission policies T 1:N and estimation rules E1:N that are optimal for the cost functional

(2) subject to the SPP model (1) with the initial condition x0 = x0 and (4).5

We consider the following two notions of optimality for Problem II.1.
Deﬁnition II.2: We say that transmission policies T ∗

1:N and estimation rules E∗

they achieve the global minimum for every x0 in R2 × [0, 2π).

1:N are jointly optimal for (2) if

Deﬁnition II.3: We say that transmission policies T ∗

1:N and estimation rules E∗

1:N are person-by-person optimal

for (2) if the following relations hold for every x0 in R2 × [0, 2π):

J (x0,T ∗

1:N ,E∗

1:N ) = minT 1:N

1:N )
1:N ,E1:N )

J (x0,T 1:N ,E∗
J (x0,T ∗
1:N ﬁxed, the estimation rules E∗

(5)

1:N minimize the cost

= minE1:N
Equation (5) implies that with the transmission policies T ∗
functional (2), and vice versa.

We maintain the following assumption throughout the paper.
Assumption II.4: Let B be a Borel σ-algebra on R2 × [0, 2π). We assume that vk and φk in (1) are random

processes for which the following hold for every k in {1,··· , N}:

1) For every Borel set A in B, the function x (cid:55)→ P(cid:16)
2) For every non-empty open set O, the function x (cid:55)→ P(cid:16)

xk ∈ A(cid:12)(cid:12)(cid:12) xk−1 = x
(cid:17)
xk ∈ O(cid:12)(cid:12)(cid:12) xk−1 = x

(cid:17)

is well-deﬁned and continuous.

is positive for all x in R2×[0, 2π).

3We do not lose any optimality from imposing these structures. This can be veriﬁed by similar arguments as in Lemma 1 and Lemma 3 of

[2].

4See Appendix B for a detailed description of randomized transmission policies policies.
5The underlying SPP model and the initial condition x0 = x0 are common knowledge to both the sensing unit and estimator.

To ﬁnd a solution to Problem II.1, we decompose the problem into a set of N sub-problems, which we solve
sequentially. We start by describing the so-called Two-Player Optimal Stopping Problem, which we use to decompose
Problem II.1 into sub-problems. We then describe how to obtain a solution to Problem II.1 by solving the sub-
problems.

Problem II.5 (Two-Player Optimal Stopping Problem): Given positive real numbers(cid:8)c(cid:48)

and rules E <k−1>

k:N

that are optimal for the following cost functional:

(cid:17)

(cid:16)

 K(cid:88)

j=k

Jk

xk−1,T <k−1>

k:N

,E <k−1>

k:N

= E

d2 (xj, ˆxj) + c(cid:48)

K · RK

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) xk−1 = xk−1,T <k−1>

k:N

,E <k−1>

k:N

subject to (1) with the initial condition xk−1 = xk−1 and

ˆxj =

for each j in {k,··· , N}, where6

Rj = T <k−1>

(xk−1, xj)

j

j

E <k−1>
(cid:110)

xj

(xk−1)

if Rj = 0

otherwise

(cid:12)(cid:12)(cid:12) Rj = 1
(cid:111)

K = min

k ≤ j ≤ N

5

j

j=k

(cid:9)N


, ﬁnd policies T <k−1>

k:N

(6)

(7a)

(7b)

Note that the total expected cost (6) consists of running costs d2 (xj, ˆxj) and stopping costs c(cid:48)
j.
Similar to Deﬁnitions II.2 and II.3, we adopt two notions of optimality for Problem II.5 as follows.
Deﬁnition II.6: We say that policies T ∗<k−1>
the global minimum for every xk−1 in R2 × [0, 2π).

and rules E∗<k−1>

k:N

k:N

are jointly optimal for (6) if they achieve

are person-by-person optimal for (6) if the

Deﬁnition II.7: We say that policies T ∗<k−1>

k:N

and rules E∗<k−1>

k:N

following relations hold for every xk−1 in R2 × [0, 2π):

(cid:16)

Jk

xk−1,T ∗<k−1>

k:N

,E∗<k−1>

k:N

(cid:17)

Jk

= min

T <k−1>

k:N

Jk

= min
E <k−1>

k:N

(cid:16)
(cid:16)
xk−1,T ∗<k−1>

xk−1,T <k−1>

k:N

k:N

,E∗<k−1>

k:N

,E <k−1>

k:N

(cid:17)
(cid:17)

(cid:8)c(cid:48)

(cid:9)N

j

described as follows: Suppose that policies T <j>

To explain how to decompose Problem II.1 into sub-problems, we consider recursive computations of constants
j+1:N and rules E <j>
j+1:N are given for all j in {k,··· , N}.
(cid:16)
(cid:17)

By proceeding backwards from j = N to j = k, for each step j, let us compute

j=k

j = cj + Jj+1
c(cid:48)

0,T <j>

j+1:N ,E <j>

j+1:N

N = cN , where cj is given in (2) and Jj+1 is deﬁned in (6). In computing Jj+1

0,T <j>

j+1:N ,E <j>

j+1:N

, we

(cid:16)

with c(cid:48)
use the constants {c(cid:48)

l}N
l=j+1 that are obtained in preceding steps.

(8)

(9)

(cid:17)

6We adopt a convention that K = N if Rj = 0 for all j in {k, · · · , N}.

We describe the k-th sub-problem of Problem II.1 as follows.

6

(cid:8)c(cid:48)

Sub-problem k: Given policies T <j>

according to (9). Using(cid:8)c(cid:48)

(cid:9)N

(cid:9)N
j+1:N and rules E <j>

, ﬁnd a solution T <k−1>

k:N

j

j=k

j

j=k

j+1:N for all j in {k,··· , N}, let us compute constants

and E <k−1>

k:N

to Problem II.5.

j+1:N for all j in {k,··· , N}, to compute the constants(cid:8)c(cid:48)

Our main strategy for solving Problem II.1 is as follows: We solve each Sub-problem k backwards in time
from k = N to k = 1, where for each Sub-problem k we use solutions to all preceding sub-problems, i.e., T <j>
j+1:N
and E <j>
. Once solutions to all the sub-problems are
found, we determine transmission policies T 1:N and estimation rules E1:N for Problem II.1 in the following way:

(cid:9)N

j=k

j

T j (k − 1, xk−1, xj) = T <k−1>

j

(xk−1, xj)

(10a)

(10b)
for each j in {k,··· , N} and k in {1,··· , N}. It can be veriﬁed that the transmission policies and estimation rules
determined by (10) are a solution to Problem II.1.

(xk−1)

j

Ej (k − 1, xk−1) = E <k−1>

C. Brief Survey of Related Work

Finite time-horizon problem formulations are considered in [2]–[5]. The authors of [3] found a jointly optimal
solution for a remote estimation problem under ﬁrst-order linear processes driven by Gaussian noise where it is
shown that transmission policies of jointly optimal solutions are of threshold-type. An iterative procedure for ﬁnding
transmission policies and estimation rules was proposed in [2]. The authors performed a convergence analysis on
the proposed procedure in the same problem formulation of [3], which essentially leads to an alternative proof of
the main results of [3]. The work of [4] considered a problem setting in which the sensing unit has an energy
harvesting capability. Preliminary results of our work were presented in [5] under some technical assumptions.7

Inﬁnite time-horizon formulations are considered in [6]–[9]. The authors of [6] studied the structure of optimal
transmission policies for a remote estimation problem under linear processes driven by Gaussian noise, and proposed
a procedure based on the value iteration algorithm to compute an optimal policy. In [7], an algorithm for ﬁnding
a sub-optimal solution was proposed. The authors showed that when the underlying process is linear and driven
by Gaussian noise, the proposed algorithm incurs a cost that is within a constant factor of the optimum. While the
question of whether transmission policies of jointly optimal solutions are of threshold-type for the problems under
multi-dimensional linear processes remains unanswered, the authors of [8] analyzed the performance of threshold-
type transmission policies for such problems. In [9], the authors proposed a polynomial approximation-based method
to ﬁnd sub-optimal transmission policies.

7The analysis and results presented in this work can be readily extended to the problem formulation considered in [5]. Due to the space

constraints, we will focus on SPP models.

7

Our problem formulation and methods are distinguished from previous ones found in literature by the following

facts:

1) We adopt a random process model that is nonlinear.
2) We do not impose any structural assumptions on transmission policies and estimation rules that result in the

loss of optimality.

3) We investigate optimization of a given performance criterion over both transmission policies and estimation

rules.

In this section, we investigate Sub-problem k in which, to determine the constants (cid:8)c(cid:48)

III. TWO-PLAYER OPTIMAL STOPPING PROBLEM

, we use solutions
to the preceding sub-problems – Sub-problem N to Sub-problem k + 1. We start by re-writing (6) into a suitable
form using the following deﬁnition.

(cid:9)N

j=k

j

Deﬁnition III.1: For each j in {k,··· , N}, we deﬁne a (random) function P j : R2 × [0, 2π) → {0, 1} and a

variable ˆxj in R2 × [0, 2π) as follows:

P j (xj) = T <k−1>
ˆxj = E <k−1>

j

(0, xj)

(11a)

(11b)
We refer to P j and ˆxj as the (randomized) policy and estimate at time j (for the initial condition xk−1 = 0),
respectively.8

(0)

j

Given that xk−1 = 0, we can re-write (6) as follows:9

Exk [Jk (xk,P k:N , ˆxk:N )]

subject to (1) with the initial condition xk−1 = 0 and

Rj = P j (xj)

for each j in {k,··· , N}, where Jk is recursively deﬁned as follows:

(12)

(13)

(cid:16)

Jj (xj,P j:N , ˆxj:N )

=

d2 (xj, ˆxj) + Exj+1

(cid:104)

Jj+1 (xj+1,P j+1:N , ˆxj+1:N )

(cid:12)(cid:12)(cid:12) xj = xj

(cid:105)(cid:17) · (1 − Rj) + c(cid:48)

j · Rj

for each j in {k,··· , N} with JN +1 = 0. Note that Jj satisﬁes the following for every j in {k,··· , N}:
Exj

Jj (xj,P j:N , ˆxj:N )

(cid:104)
(cid:16)Exj
· P(cid:16)

(cid:104)

=

d2 (xj, ˆxj)

Rj = 0

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
j · P(cid:16)
(cid:17)

+ c(cid:48)

+ Exj+1

(cid:104)

Jj+1 (xj+1,P j+1:N , ˆxj+1:N )

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

(14)

Rj = 1

8See Appendix B for a detailed description of randomized policies.
9For concise presentation, we will omit the dependence of the cost functional (12) on the initial condition unless it is necessary.

We will proceed with ﬁnding an optimal solution P∗
how we can derive a solution to Sub-problem k from P∗

k:N and ˆx∗
k:N and ˆx∗

k:N for (12). Remark III.2 given below explains
k:N .

Remark III.2: Consider the transformations given below:

− sin θk−1

sin θk−1
cos θk−1

 cos θk−1
cos θk−1 − sin θk−1

cos θk−1

sin θk−1

0

0

0

0

 ·
 ·

0

0

1

0

0

1

p2,j − p2,k−1
θj − θk−1


p1,j − p1,k−1
p1,k−1
 +
p1,j

p2,j

p2,k−1
θk−1

θj



M (xk−1, xj) =

M† (xk−1, xj) =

8

(15a)

(15b)

k:N are optimal policies and estimates for (12), respectively, and that a solution to Sub-

k:N and ˆx∗

Suppose that P∗
problem k are determined as follows: For each j in {k,··· , N},
(xk−1, xj) = P∗

T ∗<k−1>

j

(xk−1) = M†(cid:0)xk−1, ˆx∗

j (M (xk−1, xj))

(cid:1)

j

E∗<k−1>

j

Based on Deﬁnition III.1, it can be veriﬁed that the following holds for all xk−1 in R2 × [0, 2π):

(cid:16)

(cid:17)

Jk

xk−1,T ∗<k−1>

k:N

,E∗<k−1>

k:N

= Exk [Jk (xk,P∗

k:N , ˆx∗

k:N )]

where Jk is deﬁned in (6). This implies that the value of (6) evaluated at an optimal solution does not depend on
the initial condition; and by ﬁnding an optimal solution for the sub-problem with the initial condition xk−1 = 0,
(cid:4)
we can derive a solution to Sub-problem k using (15).

A. Deﬁnitions and Preliminary Results

We restate Deﬁnition II.6 and Deﬁnition II.7 as follows.
Deﬁnition III.3: We say that policies P∗

k:N and estimates ˆx∗

k:N are jointly optimal for (12) if they achieve the

global minimum.

Deﬁnition III.4: We say that policies P∗

k:N and estimates ˆx∗

k:N are person-by-person optimal for (12) if the

following relations hold:

Exk [Jk (xk,P∗

k:N , ˆx∗

k:N )] = minP k:N

In what follows, we deﬁne best response mappings P and X.
Deﬁnition III.5: Given estimates ˆxk:N , we deﬁne P (ˆxk:N ) as the collection of policies P k:N satisfying

Deﬁnition III.6: Given policies P k:N , we deﬁne X (P k:N ) as the collection of estimates ˆxk:N satisfying

k:N

Exk [Jk (xk,P k:N , ˆxk:N )] = minP(cid:48)

Exk

Exk [Jk (xk,P k:N , ˆx∗
Exk [Jk (xk,P∗

k:N , ˆxk:N )]

k:N )]

= min
ˆxk:N

(cid:2)Jk

(cid:0)xk,P(cid:48)

k:N , ˆxk:N

(cid:1)(cid:3)

Exk [Jk (xk,P k:N , ˆxk:N )] = min

Exk [Jk (xk,P k:N , ˆx(cid:48)

k:N )]

ˆx(cid:48)

k:N

9

(19a)

(19b)

(20)

We omit the detail for brevity.

Corollary III.10: Given estimates ˆxk:N , for each j in {k,··· , N}, let us deﬁne sets Dj and D

j as follows:

Exk

minP(cid:48)

k:N

(cid:110)
(cid:110)

Dj =
D

j =

xj ∈ R2 × [0, 2π)
xj ∈ R2 × [0, 2π)

(cid:1)(cid:3) = Exk [J∗

k (xk, ˆxk:N )]

J∗
j+1 (xj+1, ˆxj+1:N )
J∗
j+1 (xj+1, ˆxj+1:N )

(cid:12)(cid:12)(cid:12) xj = xj
(cid:12)(cid:12)(cid:12) xj = xj

(cid:111)
(cid:111)

(cid:105) ≤ c(cid:48)
(cid:105)

< c(cid:48)

j

j

k:N , ˆxk:N

(cid:2)Jk
(cid:0)xk,P(cid:48)
(cid:12)(cid:12)(cid:12) d2 (xj, ˆxj) + Exj+1
(cid:12)(cid:12)(cid:12) d2 (xj, ˆxj) + Exj+1
0

Pj(xj) =

(cid:104)
(cid:104)

P(cid:16)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj0−1 = 0
(cid:17)

Deﬁnition III.7: Policies P k:N are said to be degenerate if there exists j0 in {k,··· , N} for which it holds that

(16)
Remark III.8: Let P k:N be degenerate policies such that (16) holds for j0 in {k,··· , N}. From (14), we can

Rj0 = 0

= 0

derive that

Exj0

(cid:104)
Jj0 (xj0,P j0:N , ˆxj0:N )

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj0−1 = 0
(cid:105)

= c(cid:48)

j0

from which we can infer that the cost (12) does not depend on the choice of estimates ˆxj0:N .

Proposition III.9: Suppose that non-degenerate policies P k:N and estimates ˆxk:N are given. The policies P k:N

belong to P (ˆxk:N ) if and only if the following holds for all j in {k,··· , N}:

Jj (xj,P j:N , ˆxj:N )

J∗
j (xj, ˆxj:N )

(cid:104)

Exj
= Exj

(cid:104)
(cid:110)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:105)
(cid:104)

J∗
j+1 (xj+1, ˆxj+1:N )

(cid:105)

(cid:111)

, c(cid:48)

j

(17)

(18)

(cid:12)(cid:12)(cid:12) xj = xj

where for each j in {k,··· , N},

J∗
j (xj, ˆxj:N ) = min

d2 (xj, ˆxj) + Exj+1

N +1 = 0

with J∗
The proof follows from (14), Deﬁnition III.5, and the fact that

Consider (deterministic) policies Pk:N deﬁned by

if xj ∈ Dj
otherwise
for each j in {k,··· , N}, where Dj is a measurable set satisfying D
P (ˆxk:N ).

1

j ⊆ Dj ⊆ Dj. The policies Pk:N belong to

Proposition III.11: Consider that non-degenerate policies P k:N and estimates ˆxk:N are given. The estimates

ˆxk:N belong to X (P k:N ) if and only if the following holds for all j in {k,··· , N}:

(cid:104)

Exj

d2 (xj, ˆxj)

=

min

j∈R2×[0,2π)
ˆx(cid:48)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:104)
d2(cid:0)xj, ˆx(cid:48)

(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)

j

Exj

The proof follows from (14) and Deﬁnition III.6. We omit the detail for brevity.

Corollary III.12: Given non-degenerate policies P k:N , for each j in {k,··· , N}, let us consider an estimate

(cid:16)

(cid:17)T

ˆxj =

ˆp1,j

ˆp2,j

ˆθj

determined as follows:

and ˆθj takes a value in [0, 2π) that satisﬁes

provided

α = E2(cid:2)sin θj

10

(21a)

(21b)

(22a)

(22b)

(23)

(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3)
(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3)
(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3)
(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3)

ˆp1,j = E(cid:2)p1,j
ˆp2,j = E(cid:2)p2,j
sin ˆθj = α−1 · E(cid:2)sin θj
cos ˆθj = α−1 · E(cid:2)cos θj
(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3) + E2(cid:2)cos θj

(cid:12)(cid:12) Rk = 0,··· , Rj = 0(cid:3)
(cid:12)(cid:12)(cid:12) xj−1 = xj−1

(cid:105)

is non-zero; otherwise ˆθj takes any value in [0, 2π). The estimates ˆxk:N belong to X (P k:N ).

Proposition III.13: Consider functions {Gj}N

(cid:104)

j=k deﬁned as follows:10 For each j in {k,··· , N},
= Exj

J∗
j (xj, ˆxj:N )

def

Gj (xj−1, ˆxj:N )

j is given in (18). The functions {Gj}N

where J∗
The proof is given in Appendix E.

j=k are all continuous.

B. Existence of a Jointly Optimal Solution

Proposition III.14: Let policies P∗

k:N and estimates ˆx∗

k:N are jointly optimal for (12). The policies P∗

k:N are

not degenerate in the sense of Deﬁnition III.7.
The proof is given in Appendix F.

Theorem III.15: There exist policies P∗
To prove Theorem III.15, we need the following lemma.
Lemma III.16: Let us deﬁne

k:N and estimates ˆx∗

k:N that are jointly optimal for (12).

with the initial condition xk−1 = 0, where J∗

for which the following holds for all ˆxk:N in(cid:0)R2 × [0, 2π)(cid:1)N−k+1:

def

G (ˆxk:N )

= Exk [J∗

k is deﬁned in (18). There exists a compact set K ⊂(cid:0)R2 × [0, 2π)(cid:1)N−k+1

k (xk, ˆxk:N )]

(24)

The proof is given in Appendix F.

k:N∈KG (ˆx(cid:48)

inf

ˆx(cid:48)

k:N ) ≤ G (ˆxk:N )

Proof of Theorem III.15: Recall the deﬁnitions of Gk and G given in (23) and (24), respectively. According to
Proposition III.13 and by the fact that G (ˆxk:N ) = Gk (0, ˆxk:N ), we can see that G is a continuous function. Note
10Note that Gj is a function deﬁned on(cid:0)R2 × [0, 2π)(cid:1)N−j+2. See Appendix A for some remarks on the continuity of functions on a product

space.

that Lemma III.16 implies that, if it exists, a global minimizer of G resides in a compact set. In what regards to
ﬁnding a global minimizer, without loss of generality, we may assume that the domain of G is compact. Hence, by
the continuity of G and compactness of its domain, there exist estimates ˆx∗
k:N that achieve the global minimum of
G.

11

Next, let us choose policies P∗

k:N belonging to P (ˆx∗

of G given as in (24) and by the fact that ˆx∗
and the estimates x∗

k:N are jointly optimal for (12).

k:N ) using, for instance, Corollary III.10. By the deﬁnition

k:N is a global minimizer of G, we conclude that the policies P∗

k:N

C. Iterative Procedure for Finding a Person-by-Person Optimal Solution

As numerically illustrated in [2], the function G in (24) may be non-convex; consequently, ﬁnding a jointly optimal
solution for (12) would be computationally intractable. Instead, we seek a person-by-person optimal solution based
on Procedure 1 described below. In the procedure, η is a pre-selected non-negative constant that determines a
stopping criterion (Line 17), and the function G is deﬁned in (24).

Procedure 1: Finding a Person-by-Person Optimal Solution
input : η ≥ 0, ˆx(0)
output: P (i+1)
k:N , ˆx(i)

k:N

k:N

1 begin

j ← N
while j ≥ k do
Choose P (1)
using ˆx(0)
k:N
j ← j − 1

j

according to Corollary III.10

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

i ← 0
repeat

i ← i + 1
j ← k
while j ≤ N do
Choose ˆx(i)
j
using P (i)
j ← j + 1

k:N

according to Corollary III.12

j ← N
while j ≥ k do

j

Choose P (i+1)
using ˆx(i)
k:N
j ← j − 1

(cid:17) − G(cid:16)

ˆx(i)
k:N

(cid:12)(cid:12)(cid:12)G(cid:16)

until

according to Corollary III.10

(cid:17)(cid:12)(cid:12)(cid:12) ≤ η

ˆx(i−1)

k:N

(cid:110)(cid:16)P (i)

(cid:17)(cid:111)

k:N , ˆx(i)

k:N

Let

i∈N be a sequence of solutions generated through repeated computations of policies and
estimates by Procedure 1 (Line 2 − 16). In the rest of this section, we discuss convergence of the sequence to a
(cid:111)
person-by-person optimal solution. We ﬁrst deﬁne convergence of policies and estimates. For notational convenience,
i∈N and P k:N , let us deﬁne
we adopt the following: Let B be a Borel σ-algebra on R2 × [0, 2π). Given
the following: For each A in B,

k:N

(cid:110)P (i)
xj ∈ A(cid:12)(cid:12)(cid:12) R(i)
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)

k = 0,··· , R(i)

j = 0

j|j (A) = P(cid:16)
µj|j (A) = P(cid:16)

µ(i)

subject to

12

(25a)

(25b)

(26a)

(26b)

(28a)

(28b)

j = P (i)
R(i)
(xj)
Rj = P j (xj)

j

for all i in N and j in {k,··· , N}.

Deﬁnition III.17: Let

the following hold for all j in {k,··· , N}:

(cid:110)P (i)

k:N

(cid:111)
i∈N be a sequence of policies. We say that the sequence converges to P k:N if

and

P(cid:16)

R(i)

j = 0

(cid:12)(cid:12)(cid:12) R(i)

k = 0,··· , R(i)

j−1 = 0

subject to (26).11 We denote the convergence by P (i)
and P(cid:48)

k:N are equal if the following hold for all j in {k,··· , N}:

j|j → µj|j
µ(i)

(27a)

(cid:17) → P(cid:16)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

Rj = 0

(27b)
k:N ⇒ P k:N . In addition, we say that two sets of policies P k:N

µj|j = µ(cid:48)
j|j

and

P(cid:16)

Rj = 0

subject to Rj = P j (xj) and R(cid:48)

j = P(cid:48)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

= P(cid:16)

R(cid:48)

j = 0
j (xj) for all j in {k,··· , N}.

(cid:12)(cid:12)(cid:12) R(cid:48)

k = 0,··· , R(cid:48)

j−1 = 0

(cid:17)
(cid:110)P (i)

(cid:111)

Remark III.18 (Uniqueness of the Limit of Policies): Suppose that a sequence of policies

to both P k:N and P(cid:48)
of convergence of probability measures, we can derive that

k:N . Then the two sets of the policies P k:N and P(cid:48)

i∈N converges
k:N are equal. To see this, using the deﬁnition

k:N

(29)
for every bounded, continuous function g : R2 × [0, 2π) → R. Based on Lemma 9.3.2 in [10], we can see that (28)
holds for all j in {k,··· , N}.

g dµj|j =

R2×[0,2π)

R2×[0,2π)

g dµ(cid:48)
j|j

(cid:90)

(cid:90)

(cid:110)

(cid:111)

11Equation (27a) implies that the sequence of the probability measures

9.3 of [10] for the deﬁnition of convergence of probability measures.

µ(i)
j|j

i∈N converges to the probability measure µj|j. See Chapter

(cid:110)

(cid:111)

Deﬁnition III.19: Let

ˆx(i)
k:N

following holds for all j in {k,··· , N}:

i∈N be a sequence of estimates. We say that the sequence converges to ˆxk:N if the

= 0

(30)

We denote the convergence by ˆx(i)
equal if the following holds for all j in {k,··· , N}:

k:N ⇒ ˆxk:N . In addition, we say that two sets of estimates ˆxk:N and ˆx(cid:48)
(cid:111)

(31)
i∈N be a sequence of policies. We say that the policies are strictly non-degenerate

(cid:1) = 0

k:N are

j

(cid:110)P (i)

k:N

if there exists a positive constant  for which the following holds for all i in N and j in {k,··· , N}:

Deﬁnition III.20: Let

(cid:16)

(cid:17)

lim
i→∞ d

ˆx(i)
j , ˆxj

d(cid:0)ˆxj, ˆx(cid:48)
(cid:12)(cid:12)(cid:12) R(i)
(cid:110)(cid:16)P (i)

j = 0

k:N , ˆx(i)

k:N

P(cid:16)

R(i)

(cid:17) ≥ 

j−1 = 0

k = 0,··· , R(i)
(cid:17)(cid:111)

P (i)
k:N ∈ P
k:N ∈ X
ˆx(i)

(cid:17)
(cid:17)

ˆx(i−1)

k:N

(cid:16)
(cid:16)P (i)
(cid:110)(cid:16)P (i)

k:N

(cid:17)(cid:111)

13

(32)

(33a)

(33b)

subject to (26a).

Recall that the sequence of solutions

all i in N:

i∈N generated by Procedure 1 satisﬁes the following for

(cid:110)P (i)

(cid:111)

The following theorem states convergence of the sequence to a person-by-person optimal solution.

Theorem III.21: Consider a sequence of solutions

i∈N satisfying (33). Suppose that the policies
i∈N are strictly non-degenerate. Then, the sequence has a convergent subsequence, and the limit of any

k:N , ˆx(i)

k:N

k:N

convergent subsequence is a person-by-person optimal solution.

(cid:110)P (i)

To prove Theorem III.21, we need the following three lemmas.
k:N , ˆx(i)
Lemma III.22: Consider a sequence of solutions
k:N
ˆx(i)
j

i∈N are strictly non-degenerate. Then the sequence

(cid:111)

(cid:110)

k:N

Lemma III.22 is a special case of Lemma F.15 given in Appendix F.

Lemma III.23: Consider a sequence of solutions
subset {il}l∈N of N, the following hold: P (il)
ˆxk:N belong to X (P k:N ).

k:N , ˆx(i)
k:N ⇒ P k:N , ˆx(il)

k:N

(cid:110)(cid:16)P (i)
(cid:110)(cid:16)P (i)
(cid:110)(cid:16)P (i)

(cid:17)(cid:111)
(cid:111)
i∈N satisfying (33). Suppose that the policies
i∈N is bounded for all j in {k,··· , N}.
(cid:17)(cid:111)
(cid:17)(cid:111)

i∈N satisfying (33). Suppose that for an inﬁnite
k:N . Then the estimates

k:N ⇒ ˆx(cid:48)

k:N ⇒ ˆxk:N , and ˆx(il−1)

(cid:110)P (i)

Lemma III.24: Consider a sequence of solutions

(cid:111)
i∈N are strictly non-degenerate and that for an inﬁnite subset {il}l∈N of N, it holds that ˆx(il−1)

i∈N satisfying (33). Suppose that the policies
(cid:111)
k:N .
l∈N has a convergent subsequence, and the limit P k:N of any convergent subsequence

(cid:110)P (il)

k:N ⇒ ˆx(cid:48)

k:N , ˆx(i)

k:N

k:N

Then, the sequence
belongs to P (ˆx(cid:48)
The proofs of Lemmas III.23 and III.24 are given in Appendix G.

k:N ).

k:N

Proof of Theorem III.21: We ﬁrst note that according to Lemma III.22, the sequence

(cid:110)

ˆx(i)
j

(cid:111)

i∈N is contained in a

14

(cid:111)

(cid:110)

(cid:110)

compact set for every j in {k,··· , N}.12 Hence, by the compactness, there exists an inﬁnite subset I of N for which
the subsequences
k:N be the respective limits of
the subsequences. Also, according to Lemma III.24, there is an inﬁnite subset I(cid:48) of I for which the subsequence

(cid:111)
i∈I are both convergent. Let ˆxk:N and ˆx(cid:48)

(cid:111)
i∈I(cid:48) is convergent. Let P k:N be the limit of this subsequence.

To complete the proof, it remains to show that P k:N and ˆxk:N constitute a person-by-person optimal solution,

(cid:110)P (i)

i∈I and

ˆx(i−1)

ˆx(i)
k:N

k:N

k:N

i.e., it holds that

P k:N ∈ P (ˆxk:N )
ˆxk:N ∈ X (P k:N )

(34a)

(34b)

Equation (34b) is ensured by Lemma III.23, hence it remains to show that (34a) is true.

By contradiction, suppose that the policies P k:N do not belong to P (ˆxk:N ). Note that by Lemma III.24, P k:N
k:N belonging to P (ˆxk:N ):

k:N ). We can see that the following relations hold for any policies P(cid:48)

belong to P (ˆx(cid:48)

(cid:19)av−1

(cid:18) v

sv

fvk (v) =

av
sv

fφk (φ) =

·

1
2π

, for v ≥ 0

sv )av

−( v
e
1 − a2

φ

1 + a2

φ − 2aφ cos (φ − mφ)

(36a)

(36b)

12The metric space(cid:0)R2 × [0, 2π), d(cid:1) is proper; hence for any bounded subset of R2 × [0, 2π), we can ﬁnd a compact set that contains the

subset.

13The development and deployment of animal-borne monitoring devices were performed under a research grant NSF ECCS 1135726. The

GPS data were collected at the Gorongosa National Park, Mozambique.

G (ˆxk:N ) = Exk

(cid:2)Jk

(cid:0)xk,P(cid:48)

(cid:1)(cid:3)
k:N , ˆxk:N
< Exk [Jk (xk,P k:N , ˆxk:N )]
(ii)≤ Exk [Jk (xk,P k:N , ˆx(cid:48)

(i)

(35)
(i) follows from the hypothesis that P k:N /∈ P (ˆxk:N ); and (ii) is due to (34b). On the other hand, since G is
holds for all i in N, it
non-negative and decreasing along the sequence
= α for some real number α. In conjunction with the continuity of G (see Proposition
k:N ) = α which contradicts (35). Therefore we conclude that the policies

holds that limi→∞ G(cid:16)

(cid:111)
i∈N, i.e., G(cid:16)

(cid:17) ≤ G(cid:16)

ˆx(i+1)
k:N

ˆx(i)
k:N

ˆx(i)
k:N

ˆx(i)
k:N

(cid:110)

(cid:17)

(cid:17)

k:N )

k:N )] = G (ˆx(cid:48)

III.13), this implies that G (ˆxk:N ) = G (ˆx(cid:48)
P k:N belong to P (ˆxk:N ).

IV. APPLICATION TO TRACKING OF ANIMAL MOVEMENTS

In this section, we apply our results to estimation of animal movements over a costly communication link where
the performance of the optimal scheme are illustrated using GPS data collected from a monitoring device mounted
on an African buffalo.13 Fig. 2 shows the GPS track of the buffalo. To represent the movement of the buffalo, as
described in [11], we adopt the SPP model (1) in which vk and φk are the Weibull and Wrapped Cauchy random
processes, respectively. Note that the probability density functions of vk and φk are given as follows:

15

Fig. 2. A screenshot of a GPS track (the white trajectory) of an African buffalo in the Google Earth.

Using the collected GPS data, we compute the maximum likelihood estimates of the parameters for (36) as follows:

(av, sv) = (1.35, 4.66)

(aφ, mφ) = (0.65, 0.00)

(37a)

(37b)

The graphs in Fig. 3 show comparisons between the resulting probability density functions and the histograms
obtained from the GPS data.

We have selected the communication costs ck = 10 for all k in {1,··· , N} and the length of the time-horizon
N = 100. Using Procedure 1, (10), and (15), we have found the optimal remote estimation scheme where Fig.
4 illustrates the performance of the scheme in terms of the state estimation distortion computed by the metric
d (xk, ˆxk). Note that the (red) circles on the time axis (x-axis) represents the time steps at which the sensing unit
transmitted information on the full state xk to the estimator, and the state estimate ˆxk was set to ˆxk = xk (hence
d (xk, ˆxk) = 0). Our experimental results show that the optimal scheme achieved the error of location estimation
less than 5 meters compared to the total traveled distance of 372.53 meters; and the information transmissions
occurred 32 times over 100 time steps.

16

Fig. 3. Comparisons between the probability density functions of vk and φk under (37) and the histograms obtained from the GPS data.

Fig. 4. State estimation distortion of the optimal remote estimation scheme

A. On Product Metric Space

APPENDIX

Given a metric space (X, d), we deﬁne a metric d on the product space Xk as follows: For x1:k = (x1,

··· , xk)

(38)

and y1:k = (y1,

··· , yk) in Xk,

d(x1:k, y1:k) =(cid:2)d2 (x1, y1) + ··· + d2 (xk, yk)(cid:3)1/2

Note that(cid:0)Xk, d(cid:1) is a (product) metric space. For (X, d) and(cid:0)Xk, d(cid:1), the following are true:

(F1) Let {Kj}k

j=1 be a collection of compact subsets of X. The product set K1 × ··· × Kk is a compact subset of

0510152025v0.000.020.040.060.080.100.120.140.16fvk(v)Weibull01234567 0.00.10.20.30.40.50.60.70.8f k( )WrappedCauchy17

Xk.

(F2) Consider a sequence

(cid:110)

x(i)
1:k

(cid:111)
i∈N in Xk. The sequence converges to x1:k in Xk, i.e.,

(cid:110)

x(i)
j

if and only if

(cid:111)
i∈N converges to xj for all j in {1,··· , k}, i.e.,

x(i)
1:k, x1:k

i→∞ d
lim

= 0

(cid:16)
(cid:16)

(cid:17)
(cid:17)

i→∞ d
lim

x(i)
j , xj

= 0

holds for all j in {1,··· , k}.

(cid:16)

(cid:17)

As a consequence of (F2), a function G : Xk → R is continuous at x1:k ∈ Xk if for any sequence

for which limi→∞ d

x(i)
j , xj

= 0 holds for all j in {1,··· , k}, it holds that limi→∞

(cid:110)
(cid:17) − G (x1:k)

x(i)
1:k

(cid:111)
(cid:12)(cid:12)(cid:12) = 0.

i∈N

(cid:12)(cid:12)(cid:12)G(cid:16)

x(i)
1:k

B. On Randomized Policies

Let (τk, xτk , xk) (cid:55)→ T k (τk, xτk , xk) be a randomized transmission policy deﬁned in Section II that dictates the

random variable Rk as in (4). Given a realization (τk, xτk , xk) of (τk, xτk , xk), the variable Rk satisﬁes

Rk =

Let xj (cid:55)→ P j (xj) be a randomized policy deﬁned in Section III that dictates the random variable Rj as in (13).

Given a realization xj of xj, the variable Rj satisﬁes

(cid:12)(cid:12)(cid:12) τk = τk, xτk = xτk , xk = xk
(cid:12)(cid:12)(cid:12) τk = τk, xτk = xτk , xk = xk

(cid:17)
(cid:17)

(cid:12)(cid:12)(cid:12) xj = xj
(cid:12)(cid:12)(cid:12) xj = xj

(cid:17)
(cid:17)

Rj =

0 with probability P(cid:16)T k (τk, xτk , xk) = 0
1 with probability P(cid:16)T k (τk, xτk , xk) = 1
0 with probability P(cid:16)P j (xj) = 0
1 with probability P(cid:16)P j (xj) = 1
(cid:12)(cid:12)(cid:12) xj = xj
P(cid:16)P j (xj) = 0
(cid:17)
0
(cid:12)(cid:12)(cid:12) xj = xj

P(cid:16)P j (xj) = 0

if xj ∈ Dj
otherwise

P j(xj) =

(cid:17)

=

1

0

1

if xj ∈ Dj
otherwise

Throughout the work, we restrict our attention to the policies in which

is a measurable function of xj on the measurable space (cid:0)R2 × [0, 2π), B(cid:1) where B is a Borel σ-algebra on

R2 × [0, 2π). As a case in point, consider a (deterministic) policy deﬁned by

where Dj ∈ B. It can be veriﬁed that

is a measurable function of xj.

18

C. Preliminary Concepts in Probability Theory

We ﬁrst review some of key deﬁnitions and results from probability theory [10], [12]. Let (X, d) be a complete
separable metric space, and let T and B be a topology and a Borel σ-algebra derived from the metric, respectively.
Deﬁnition C.1: Let µ be a probability measure on (X, B). The probability measure is said to be tight if for

every positive constant , there exists a compact subset K of (X,T ) for which µ (K) > 1 −  holds.

The following is adopted from Theorem 7.1.4 in [10].
Lemma C.2: Any probability measure µ on (X, B) is tight.
Deﬁnition C.3: A probability measure µ deﬁned on (X, B) is said to be closed regular if for every A in B, it

holds that

µ(A) = sup(cid:8)µ(F)(cid:12)(cid:12) F ∈ B closed, F ⊂ A(cid:9)

(39)

From Theorem 7.1.3 in [10], we can state the following Lemma.
Lemma C.4: Any probability measure µ on (X, B) is closed regular.
Remark C.5: Let µ be a closed regular probability measure deﬁned on (X, B) and let A be a measurable subset
in B. For every positive constant , there exists a closed set F for which F ⊂ X\ A and µ (X \ A) < µ (F) + . Let
us deﬁne an open set O = X \ F. We can see that O satisﬁes O ⊃ A and µ (O) < µ (A) + . Hence we conclude
that

Deﬁnition C.6 (Convergence of Probability Measures): Let(cid:8)µ(i)(cid:9)

(40)
i∈N and µ be a sequence of probability mea-
sures and a probability measure deﬁned on (X, B), respectively, and let Cb (X) be the set of all bounded, continuous,
real-valued functions on X. The sequence is said to converge to µ if it holds that

µ (A) = inf(cid:8)µ (O)(cid:12)(cid:12) O ∈ B open, O ⊃ A(cid:9)

(cid:90)

(cid:90)

g dµ

g dµ(i) =
for every g in Cb (X). We denote the convergence by µ(i) → µ.

lim
i→∞

Deﬁnition C.7: Let(cid:8)µ(i)(cid:9)

i∈N be a sequence of probability measures deﬁned on (X, B). The probability measures
are said to be uniformly tight if for every positive constant , there exists a compact subset K of (X,T ) for which
µ(i) (K) > 1 −  holds for all i in N.

A measurable subset A of X is said to be a µ-continuity set if its boundary set has the zero measure with respect

to µ, i.e., µ (bd (A)) = 0. The following is the portmanteau theorem (See Theorem 11.1.1 in [10]).

Theorem C.8: For a sequence (cid:8)µ(i)(cid:9)

i∈N of probability measures and a probability measure µ on (X, B), the

following are equivalent:
1) µ(i) → µ
2) lim supi→∞ µ(i) (F) ≤ µ (F) for any closed subset F of X
3) lim inf i→∞ µ(i) (O) ≥ µ (O) for any open subset O of X
4) limi→∞ µ(i) (A) = µ (A) for any µ-continuity subset A of X.

19

D. Preliminary Results

Lemma D.10: Given estimates ˆxk:N , let P k:N be non-degenerate policies that belong to P (ˆxk:N ). The following

Lemma D.9: The metric space(cid:0)R2 × [0, 2π), d(cid:1) deﬁned in Section II is complete, separable, and proper.
1) P(cid:16)
2) P(cid:16)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17)

are true for all j in {k,··· , N}:

xj ∈ Dj
xj ∈ D

= 1

= 0

j

subject to Rj = P j (xj) for each j in {k,··· , N}, where Dj and D
The proof directly follows from Proposition III.9.

j are deﬁned in (19).

Based on Lemma D.10, we can state the following proposition.
Proposition D.11: Given estimates ˆxk:N , let P k:N be non-degenerate policies that belong to P (ˆxk:N ). Consider

compact sets {Kj}N

j=k given by14

The following holds for all j in {k,··· , N}:

P(cid:16)

xj ∈ Kj

(cid:110)

Kj =

x ∈ R2 × [0, 2π)

(cid:111)

(cid:12)(cid:12)(cid:12) d2 (x, ˆxj) ≤ c(cid:48)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)

j

= 1

(41)

(42)

(43a)

subject to Rj = P j (xj) for each j in {k,··· , N}.
The proof follows from the fact that Kj contains the set Dj deﬁned in (19a) and Lemma D.10.

Proposition D.12: Given policies P k:N , for each j in {k,··· , N}, let us deﬁne

µj|j (A) = P(cid:16)
µj|j−1 (A) = P(cid:16)

xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

(43b)
subject to Rj = P j (xj) for each j in {k,··· , N}, where A is a Borel-measurable subset. The probability measures
(43) evolve according to the following update rules:

1) Policy update rule:

provided that P(cid:16)

Rj = 0

2) Process update rule:

(cid:17)

µj|j (A) =

(cid:12)(cid:12)(cid:12) xj = x

A P(cid:16)P j (xj) = 0
(cid:82)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
P(cid:16)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
P(cid:16)
(cid:17)

µj|j−1 (A) =

is positive.

dµj|j−1

Rj = 0

(cid:90)

R2×[0,2π)

dµj−1|j−1

14Due to the properness of the metric space(cid:0)R2 × [0, 2π), d(cid:1) (see Lemma D.9), every closed ball is a compact set.

20

(44)

(45)

(46)

E. Proof of Proposition III.13

Gj (xj−1, ˆxj:N ) = Exj

To start with, we note that for each j in {k,··· , N}, the function Gj can be written as follows:

(cid:2)gj (xj, ˆxj:N )(cid:12)(cid:12) xj−1 = xj−1
(cid:9).
with GN +1 = 0, where gj(xj, ˆxj:N ) = min(cid:8)d2 (xj, ˆxj) + Gj+1 (xj, ˆxj+1:N ) , c(cid:48)
(cid:111)

We prove the statement using mathematical induction starting from j = N + 1. Since GN +1 is constant, e.g.,
GN +1 = 0, it is a continuous function. Now suppose that Gj+1 is a continuous function. Note that gj in (44) is a
continuous function. To verify the continuity of Gj, let
x(i)
i∈N be sequences that converge to
j−1
xj−1 and ˆxj:N , respectively. For each set A in B, let us deﬁne

ˆx(i)
j:N

(cid:3)

j

By Assumption II.4 and Theorem C.8, we can see that

Since(cid:0)R2 × [0, 2π), d(cid:1) is a complete, separable metric space by Lemma D.9, using the Skorokhod representation

i∈N converges to µj.

µ(i)
j

theorem [13], we can see that there is a sequence of random variables
deﬁned on a common probability space (Ω, F, ν) in which the following three facts are true:
(F1) µ(i)
j
(F2) µj is the probability measure of yj, i.e., ν
(F3)
i∈N converges to yj almost surely.

is the probability measure of y(i)

j , i.e., ν

ω ∈ Ω

= µ(i)
j

(cid:110)

(cid:111)

y(i)
j

y(i)
j

= µj (A) for each A in B.

(A) for each A in B.

i∈N and a random variable yj all

(cid:111)

j−1

(cid:111)

(cid:111)

(cid:17)
(cid:17)

i∈N and

(cid:110)
(cid:110)
xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x(i)
xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = xj−1
(cid:110)
(cid:110)
(cid:12)(cid:12)(cid:12) y(i)
j (ω) ∈ A(cid:111)(cid:17)
(cid:12)(cid:12)(cid:12) yj(ω) ∈ A(cid:111)(cid:17)

ω ∈ Ω

(A) = P(cid:16)
µj (A) = P(cid:16)

µ(i)
j

(cid:16)(cid:110)
(cid:16)(cid:110)
(cid:17) − Gj (xj−1, ˆxj:N )
(cid:17)(cid:12)(cid:12)(cid:12) xj−1 = x(i)
(cid:90)
(cid:17)
(cid:16)

dν −

j:N

Ω

0 ≤ gj

From (F1) and (F2), we can derive

(cid:16)
(cid:90)

Gj
x(i)
j−1, ˆx(i)
= Exj

gj

(cid:16)

(cid:104)

j:N

xj, ˆx(i)
j:N

(cid:16)

y(i)
j (ω), ˆx(i)
Notice that by the fact that c(cid:48)

gj

=

Ω

(cid:105) − Exj

(cid:104)

gj (xj, ˆxj:N )

(cid:12)(cid:12)(cid:12) xj−1 = xj−1

(cid:105)

j−1

gj (yj(ω), ˆxj:N ) dν

(47)

j is a ﬁxed constant and g is a non-negative function, it holds that

y(i)
j (ω), ˆx(i)

j:N

(cid:17) ≤ c(cid:48)
(cid:110)

j

gj

(cid:16)

for every i in N and every ω ∈ Ω. Hence, the sequence of functions
Also, by the continuity of gj and (F3), it holds that

(cid:16)

(cid:17)

lim
i→∞ gj

y(i)
j (ω), ˆx(i)

j:N

= gj (yj(ω), ˆxj:N )

j (·), ˆx(i)
y(i)

j:N

i∈N is uniformly bounded.

for almost every ω in Ω. Using the bounded convergence theorem (see Theorem 16.5 in [12]), we have that

lim
i→∞

x(i)
j−1, ˆx(i)

j:N

(cid:16)

= lim
i→∞

Ω

gj

y(i)
j (ω), ˆx(i)

j:N

(cid:12)(cid:12)(cid:12)
(cid:17) − Gj (xj−1, ˆxj:N )
(cid:90)

(cid:17)

dν −

Ω

(cid:12)(cid:12)(cid:12)Gj
(cid:16)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)

which proves that the function Gj is continuous.

Finally, by induction, we conclude that the functions {Gj}N

j=k are all continuous.

gj (yj(ω), ˆxj:N ) dν

(cid:17)(cid:111)

(cid:12)(cid:12)(cid:12)(cid:12) = 0

F. Proofs of Proposition III.14 and Lemma III.16

Lemma F.13: For each j in {k,··· , N}, there exist estimates ˆxj:N for which the set given by
< c(cid:48)

(cid:12)(cid:12)(cid:12) d2 (xj, ˆxj) + Exj+1

(cid:12)(cid:12)(cid:12) xj = xj

J∗
j+1 (xj+1, ˆxj+1:N )

xj ∈ R2 × [0, 2π)

(cid:110)

(cid:104)

(cid:105)

j =

D

j

21

(48)

(cid:111)

is non-empty, where J∗

j+1 is deﬁned in (18).

Proof: Recall how c(cid:48)

j is determined by (9) with the solutions T <j>

j+1:N and E <j>

Let us select a ﬁxed point xo
{j + 1,··· , N}, by a similar argument as in Remark III.2, we can see that

j in R2 × [0, 2π). Under the choice of ˆxj = xo

j+1:N to Sub-problem j + 1.
(xj) for each l in

j and ˆxl = E <j>

l

J∗
j+1 (xj+1, ˆxj+1:N )

J∗
Exj+1
(0) for each l in {j + 1,··· , N}. Hence, at xj = xo

= Exj+1

where ˆx(cid:48)

l = E <j>

l

(cid:104)

(cid:105)

(cid:12)(cid:12)(cid:12) xj = xj
(cid:104)

(cid:1)(cid:12)(cid:12)(cid:12) xj = 0
(cid:105)

j+1:N

(cid:105)

j, it holds that

(cid:104)

j+1

(cid:0)xj+1, ˆx(cid:48)
(cid:12)(cid:12)(cid:12) xj = xj
(cid:12)(cid:12)(cid:12) xj = xj
(cid:105)
(cid:12)(cid:12)(cid:12) xj = xj
(cid:105)
(cid:1)(cid:12)(cid:12)(cid:12) xj = 0
(cid:105)

= c(cid:48)

j

(cid:104)

J∗
j+1 (xj+1, ˆxj+1:N )

d2 (xj, ˆxj) + Exj+1
J∗
= Exj+1
j+1 (xj+1, ˆxj+1:N )
< cj + Exj+1
= cj + Exj+1

(cid:0)xj+1, ˆx(cid:48)

J∗
j+1 (xj+1, ˆxj+1:N )
J∗

(cid:104)
(cid:104)

j+1:N

j+1

j deﬁned in (19) are closed and open, respectively, for

This proves the Lemma.

Lemma F.14: Given estimates ˆxk:N , the sets Dj and D

all j in {k,··· , N}.
The proof directly follows from the continuity of the functions {Gj}N

Proof of Proposition III.14: By contradiction, suppose that the degenerate policies P∗

jointly optimal for (12). Let j0 ∈ {k,··· , N} be the smallest integer for which

j=k, each deﬁned in (23) (See Proposition III.13).
k:N are

k:N and estimates ˆx∗

(49)
j (xj) for each j in {k,··· , N}. Since j0 is the smallest such integer, by Proposition D.12,

= 0

j0

holds subject to R∗
the probability measure µj0|j0−1 of xj0 is well-deﬁned.

j = P∗

Using Lemma F.13, let us choose ˆx◦

(cid:110)
xj0 ∈ R2 × [0, 2π)

D◦
j0

=

is non-empty. Note that according to Lemma F.14, the set D◦
tion D.12, we have that

= 0

R∗

(cid:17)

j0−1 = 0

(cid:12)(cid:12)(cid:12) R∗

k = 0,··· , R∗

P(cid:16)
j0:N ∈(cid:0)R2 × [0, 2π)(cid:1)N−j0+1 for which the set given by
(cid:12)(cid:12)(cid:12) d2(cid:0)xj0, ˆx◦
(cid:1)(cid:12)(cid:12)(cid:12) xj0 = xj0
P(cid:16)

(cid:0)xj0+1, ˆx◦
(cid:17)

(cid:1) + Exj0+1
(cid:12)(cid:12)(cid:12) R∗

k = 0,··· , R∗

xj0 ∈ D◦

j0−1 = 0

j0+1:N

J∗

(cid:104)

> 0

j0+1

j0

j0

j0 is open; hence, from Assumption II.4 and Proposi-

(cid:105)

(cid:111)

< c(cid:48)

j0

(50)

(51)

For each j in {j0,··· , N}, let us deﬁne a function P◦

j : R2 × [0, 2π) → {0, 1} as follows:

0

1

P◦
j (xj) =

if xj ∈ D◦
otherwise

j

where

(cid:110)

xj ∈ R2 × [0, 2π)

D◦
j =

(cid:104)

J∗

j+1

(cid:0)xj+1, ˆx◦

j+1:N

(cid:1)(cid:12)(cid:12)(cid:12) xj = xj

(cid:105)

(cid:111)

< c(cid:48)

j

Let us select new policies P(cid:48)

k:N and estimates ˆx(cid:48)

k:N as follows: for each j in {k,··· , N},

By deﬁnition, under the new policies P(cid:48)

subject to R(cid:48)

j = P(cid:48)

j (xj) for each j in {k,··· , N}. This implies that
xj0 ∈ D◦

j0−1 = 0

j0

P(cid:16)
= P(cid:16)

xj0 ∈ D◦

k = 0,··· , R(cid:48)

j0

= 0

k = 0,··· , R(cid:48)

j0−1 = 0

(cid:17)

22

(52a)

(52b)

(53)

(54)

(55)

P(cid:48)

j

j

j =

(cid:12)(cid:12)(cid:12) d2(cid:0)xj, ˆx◦
(cid:1) + Exj+1
P∗
ˆx∗
(cid:12)(cid:12)(cid:12) R(cid:48)

k:N , it holds that

xj0 ∈ D◦

ˆx(cid:48)
j =

P◦

ˆx◦

j0

j

j

j

P(cid:16)

if j ∈ {k,··· , j0 − 1}
if j ∈ {j0,··· , N}
if j ∈ {k,··· , j0 − 1}
if j ∈ {j0,··· , N}

(cid:17)

= 1

= 0

(cid:12)(cid:12)(cid:12) R(cid:48)
(cid:17)

j0

k = 0,··· , R(cid:48)
(cid:17)
(cid:17) · P(cid:16)

R(cid:48)

= 0

j0

(cid:12)(cid:12)(cid:12) R(cid:48)

j0

j0

= 0

(cid:104)

k = 0,··· , R(cid:48)

(cid:12)(cid:12)(cid:12) R(cid:48)
(cid:12)(cid:12)(cid:12) R(cid:48)
P(cid:16)
(cid:0)xj0,P∗
(cid:0)xj0,P(cid:48)
(cid:104)
(cid:0)xj0, ˆx(cid:48)
(cid:0)xj0 ,P(cid:48)
(cid:0)xj0,P∗

J∗

(cid:104)

(cid:104)

(cid:104)

j0

Exj0
Jj0
= Exj0

Exj0
Jj0
< Exj0
j and ˆx(cid:48)

Jj0
j = ˆx∗

j0:N , ˆx(cid:48)

j0:N

(cid:2)Jk

(cid:0)xk,P(cid:48)

Exk

k:N , ˆx(cid:48)

k:N

k = 0,··· , R(cid:48)

j0−1 = 0

> 0

j0−1 = 0

= c(cid:48)

j0

(cid:105)

j0−1 = 0
< c(cid:48)

j0

j0−1 = 0

(cid:105)

(cid:105)

(cid:105)

j0:N

k = 0,··· , R(cid:48)

k = 0,··· , R(cid:48)

k = 0,··· , R∗

(cid:1)(cid:12)(cid:12)(cid:12) R∗
(cid:1)(cid:12)(cid:12)(cid:12) R(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) R(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) R(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) R∗
(cid:1)(cid:3) < Exk [Jk (xk,P∗

k = 0,··· , R(cid:48)

j0:N

k:N , ˆx∗

k:N )]

j0:N , ˆx(cid:48)

j0:N

j0:N , ˆx∗

j0−1 = 0

k = 0,··· , R∗

j0−1 = 0

(cid:105)

By (51), (52a), and (54), we can see that
R(cid:48)

Due to (49), by Remark III.8, we can see that
j0:N , ˆx∗

Exj0

Jj0

j0:N

While, by (14), (52), and (55), we can see that

These relations imply that

Using the facts that P(cid:48)
(49) holds, from (14), we can infer that

j = P∗

j for each j in {k,··· , j0 − 1}, and j0 is the smallest integer for which

which violates ˆx∗

k:N is a global minimizer. Therefore, every global minimizer has to be non-degenerate.

Lemma F.15: Consider policies

for all i
in {k,··· , N}. Suppose that there exists a positive constant  for which the following holds for all i in N and j
in {k,··· , j0}:

i∈N and estimates

ˆx(i)
k:N

k:N

k:N

(cid:111)

(cid:110)P (i)
P(cid:16)

(cid:12)(cid:12)(cid:12) R(i)

(cid:110)

(cid:111)
i∈N satisfying P (i)
(cid:17) ≥ 

(cid:110)

(cid:111)

R(i)

j = 0

k = 0,··· , R(i)

j−1 = 0

(xj) for each i in N and j in {k,··· , j0}. Then the sequence

23

(cid:16)

(cid:17)

k:N ∈ P

ˆx(i−1)

j = P (i)

j

subject to R(i)
j in {k,··· , j0}.

(cid:110)

of

(cid:111)

Proof: By contradiction, suppose that there exists j(cid:48) in {k,··· , j0} such that for a subsequence
ˆx(i)
j(cid:48)

i∈N, it holds that

(cid:16)

0, ˆx(il−1)

j(cid:48)

d

(cid:110)

(cid:17) l→∞−→ ∞

x ∈ R2 × [0, 2π)

ˆx(i)
j

i∈N is bounded for all

(cid:110)

ˆx(il−1)
j(cid:48)

(cid:17) ≤ c(cid:48)

j

x, ˆx(il−1)

j(cid:48)

(cid:111)

(cid:12)(cid:12)(cid:12) d2(cid:16)
(cid:17)

. Then, according

For each l in N, let us choose a compact set K(il)

j(cid:48) =
to Proposition D.11, the following holds for all l in N:

P(cid:16)

(cid:12)(cid:12)(cid:12) R(il)

xj(cid:48) ∈ K(il)
j(cid:48)

k = 0,··· , R(il)

j(cid:48) = 0

= 1

subject to R(il)

(xj) for each l in N and j in {k,··· , j(cid:48)}. Using (56), we can derive the following:

holds for all l in N. Hence, by Lemma C.2 and (57), we can see that

(cid:17)

lim
l→∞

xj(cid:48) ∈ K(il)
j(cid:48)

= 0

P(cid:16)
(cid:12)(cid:12)(cid:12) R(il)

P(cid:16)

(cid:17)

= 0

In conjunction with (59), we conclude that

j(cid:48)−1 = 0
This contradicts the fact that (56) holds for all i in N and j in {k,··· , j0}.

j(cid:48) = 0

lim
l→∞

R(il)

k = 0,··· , R(il)

Proof of Lemma III.16: For a positive real r, let us deﬁne

ˆxk:N ∈(cid:0)R2 × [0, 2π)(cid:1)N−k+1 (cid:12)(cid:12)(cid:12) d (0, ˆxj) ≤ r for all j in {k,··· , N}(cid:111)
(cid:110)

Kr

def
=

To prove the lemma, it is sufﬁcient to show that there exists r > 0 for which with K = Kr, the statement of
the lemma is true. By contradiction, suppose that there exists a sequence
satisﬁes the following hypotheses:

(cid:111)
i∈N ⊂(cid:0)R2 × [0, 2π)(cid:1)N−k+1 that

ˆx(i)
k:N

(cid:110)

(cid:17)

· P(cid:16)

xj(cid:48) ∈ K(il)
j(cid:48)

(cid:12)(cid:12)(cid:12) R(il)

j(cid:48)−1 = 0

(cid:17)

k = 0,··· , R(il)

j(cid:48)−1 = 0

P(cid:16)

j(cid:48) = 0

j = P (il)

j

j(cid:48)

(cid:17)

k = 0,··· , R(il)
j(cid:48)−1 = 0
(cid:17)
k = 0,··· , R(il)
, R(il)
(cid:17)
k = 0,··· , R(il)
j(cid:48) = 0

(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) xj(cid:48) ∈ K(il)
(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) R(il)
xj(cid:48) ∈ K(il)
j(cid:48)
k = 0,··· , R(il)
(cid:12)(cid:12)(cid:12) R(il)
k = 0,··· , R(il)
, R(il)
(cid:17)

k = 0,··· , R(il)

j(cid:48)−1 = 0

j(cid:48)−1 = 0

j−1 = 0

(cid:17)

(cid:17)

xj(cid:48) ∈ K(il)
j(cid:48)
R(il)
j = 0
xj(cid:48) ∈ K(il)
j(cid:48)

=

R(il)

R(il)

j(cid:48) = 0

P(cid:16)
P(cid:16)
≤ P(cid:16)
P(cid:16)
P(cid:16)
(cid:81)j(cid:48)−1
≤ k−j(cid:48) · P(cid:16)

j=k

=

xj(cid:48) ∈ K(il)
j(cid:48)

(56)

(cid:111)

l∈N

(57)

(58)

(59)

(60)

(61)

(62)

We constructively prove that the hypothesis (H2) is violated for sufﬁciently large i in N. To proceed, let us select
. Let j0 ∈ {k,··· , N} be the smallest integer for which there

ˆx(i−1)

(cid:17)
k:N /∈ Ki.

ˆx(i)
k:N

.

k:N of the sequence, it holds that ˆx(i)

policies

(cid:110)P (i)

(H1) For each element ˆx(i)

(H2) For every ˆxk:N in Ki, it holds that G (ˆxk:N ) > G(cid:16)
(cid:16)
(cid:17)
(cid:111)
k:N ∈ P
(cid:12)(cid:12)(cid:12) R(il)
i∈N satisfying15

(cid:111)
(cid:110)P (il)
(cid:110)P (i)
i∈N that satisfy P (i)
P(cid:16)
(cid:16)

k:N
is a subsequence

j = P (il)

subject to R(il)

l∈N of

R(il)
j0

lim
l→∞

(cid:111)

(cid:104)

= 0

k:j0

k:j0

k:N

j

(cid:17)

(xj) for each l in N and j in {k,··· , j0}. Note from (14) and (63), we have that
Exj0

k = 0,··· , R(il)

j0−1 = 0

= c(cid:48)

Jj0

j0:N

j0

lim
l→∞

is non-empty, where J∗

j0+1 is deﬁned in (18). Note that by Proposition III.13

Also, according to Lemma F.15, the sequence

Using Lemma F.13, let us choose ˆx◦

(cid:110)
xj0 ∈ R2 × [0, 2π)

D◦
j0

=

j0

d2(cid:0)xj0 , ˆx◦
(cid:12)(cid:12)(cid:12) d2(cid:0)xj0 , ˆx◦

j0

(cid:110)
xj0 ∈ R2 × [0, 2π)

B =

is non-empty and open.

For each j in {j0,··· , N}, let us deﬁne a function P◦

is a continuous function of xj0. Hence, for a positive constant , the set deﬁned by

where

D◦
j =

(cid:110)

xj ∈ R2 × [0, 2π)

Also, let us select sequences of policies
in {k,··· , N},

24

(63)

(64)

(65)

(66)

(67a)

(67b)

(cid:111)

< c(cid:48)

j0

(cid:111)

− 

j0

k = 0,··· , R(il)

j0−1 = 0

= 0

j0

j0+1

j0+1

j0+1

(cid:105)

(cid:105)

J∗

J∗

J∗

j0+1:N

j0+1:N

j0+1:N

ˆx(i)
j

< c(cid:48)

(cid:0)xj0+1, ˆx◦

(cid:17)(cid:12)(cid:12)(cid:12) R(il)
(cid:110)
(cid:111)
j0:N , ˆx(il−1)
xj0 ,P (il)
j0:N ∈(cid:0)R2 × [0, 2π)(cid:1)N−j0+1 for which the set given by
i∈N is bounded for all j in {k,··· , j0 − 1}.
(cid:12)(cid:12)(cid:12) d2(cid:0)xj0, ˆx◦
(cid:1)(cid:12)(cid:12)(cid:12) xj0 = xj0
(cid:104)
(cid:105)
(cid:1) + Exj0+1
(cid:0)xj0+1, ˆx◦
(cid:1)(cid:12)(cid:12)(cid:12) xj0 = xj0
(cid:104)
(cid:105)
(cid:1) + Exj0+1
(cid:0)xj0+1, ˆx◦
(cid:1)(cid:12)(cid:12)(cid:12) xj0 = xj0
(cid:104)
(cid:1) + Exj0+1
0
(cid:12)(cid:12)(cid:12) d2(cid:0)xj, ˆx◦
(cid:1) + Exj+1
(cid:110)P(cid:48)(i)
(cid:111)
P (i)
ˆx(i)

if j ∈ {k,··· , j0 − 1}
if j ∈ {j0,··· , N}
if j ∈ {k,··· , j0 − 1}
if j ∈ {j0,··· , N}
(cid:111)

j : R2 × [0, 2π) → {0, 1} as follows:

(cid:1)(cid:12)(cid:12)(cid:12) xj = xj

if xj ∈ D◦
otherwise

i∈N and estimates

P◦
j (xj) =

P(cid:48)(i)
j =

(cid:48)(i)
j =

P◦

J∗

(cid:104)

(cid:105)

(cid:110)

ˆx◦

j

j

j

j+1

k:N

ˆx

j

j

1

j

(cid:0)xj+1, ˆx◦
(cid:111)
(cid:110)
i∈N as follows: for each i in N and j

(cid:48)(i)
ˆx
k:N

< c(cid:48)

j+1:N

j

(cid:111)

15Such j0 always exists; otherwise according to Lemma F.15, the sequence

ˆx(i)
k:N

i∈N is bounded, which violates (H1).

k:N ∈ Ki−1 and G(cid:16)

(cid:48)(i−1)

(cid:48)(i−1)
k:N

(cid:17)

ˆx(i−1)

ˆx

We argue that ˆx

hold for sufﬁciently large i. This contradicts the
hypothesis (H2); hence it completes the proof of the lemma. In what follows, we show that this argument is
valid. Note that by Lemma F.15, the sequence
i∈N is bounded. By Proposition D.11 and by the fact that
P(cid:48)(i)
j = P (i)
for all i in N and j in {k,··· , j0 − 1}, there exists a compact set Kj0−1 for which the following
holds for all i in N:

k:N

j

25

ˆx(i−1)
j0−1

< G(cid:16)
(cid:111)

(cid:17)
(cid:110)
(cid:12)(cid:12)(cid:12) R
(cid:12)(cid:12)(cid:12) R(i)

By Proposition D.12, we can write that

where the probability measure µ

(cid:17)

(cid:17)

(cid:48)(i)
k = 0,··· , R

(cid:48)(i)
j0−1 = 0

k = 0,··· , R(i)

j0−1 = 0

= 1

(cid:17)

(cid:48)(i)
j0−1|j0−1

dµ

(cid:48)(i)
j0−1 = 0

(cid:17)

(cid:48)(i)
k = 0,··· , R

xj0 ∈ B(cid:12)(cid:12)(cid:12) xj0−1 = x
xj0−1 ∈ A(cid:12)(cid:12)(cid:12) R

(cid:48)(i)
j0−1|j0−1 is deﬁned as follows: For each A in B,
(cid:48)(i)
j0−1 = 0

(cid:48)(i)
k = 0,··· , R

(cid:17)

(cid:48)(i)
µ

xj0−1 ∈ Kj0−1

xj0−1 ∈ Kj0−1

P(cid:16)
= P(cid:16)
xj0 ∈ B(cid:12)(cid:12)(cid:12) R
P(cid:16)
(cid:90)
P(cid:16)
j0−1|j0−1 (A) = P(cid:16)
xj0 ∈ B(cid:12)(cid:12)(cid:12) R

P(cid:16)

Kj0−1

=

Due to Assumption II.4 and the compactness of Kj0−1, for a positive constant δj0 and for the set B given by (66),
the following holds for all i in N:

(cid:17)

(cid:48)(i)
k = 0,··· , R

(cid:48)(i)
j0−1 = 0

=

(cid:110)

j0:N , ˆx

Exj0

Jj0

(cid:48)(i−1)
j0:N

ˆx(i−1)

j

≥ δj0 · µ

xj0,P(cid:48)(i)

(cid:48)(i)
j0−1|j0−1 (Kj0−1) = δj0

(cid:111)
(68)
i∈N is bounded for all j in {k,··· , j0 − 1}, for sufﬁciently large i, we can see that
Since the sequence
(cid:48)(i−1)
k:N ∈ Ki−1. In addition, by (14), (66), (67), and (68), we can see that the following relations hold for all i in
ˆx
(cid:17)(cid:12)(cid:12)(cid:12) R
(cid:104)
N:
(cid:16)Exj0
· P(cid:16)
(i)≤(cid:16)Exj0
· P(cid:16)
< (cid:0)c(cid:48)

(cid:105)
(cid:104)
(cid:105)
(cid:48)(i)
(cid:0)xj0+1, ˆx◦
k = 0,··· , R
(cid:12)(cid:12)(cid:12) R
1 − P(cid:16)
(cid:17)
j0−1 = 0, xj0 ∈ B(cid:105)
(cid:1)(cid:12)(cid:12)(cid:12) R
j0−1 = 0, xj0 ∈ B(cid:105)(cid:17)
xj0 ∈ B(cid:12)(cid:12)(cid:12) R
1 − P(cid:16)
(cid:17)
(cid:48)(i)
k = 0,··· , R
j0+1
j0+1:N
xj0 ∈ B(cid:12)(cid:12)(cid:12) R
1 − P(cid:16)
·(cid:16)
(cid:17)
(cid:48)(i)
(cid:48)(i)
k = 0,··· , R
+ c(cid:48)
j0−1 = 0
(cid:48)(i)
(cid:48)(i)
k = 0,··· , R
j0−1 = 0

(cid:16)
(cid:104)
d2(cid:0)xj0, ˆx◦
(cid:12)(cid:12)(cid:12) R
(cid:104)
d2(cid:0)xj0 , ˆx◦
(cid:104)
xj0 ∈ B(cid:12)(cid:12)(cid:12) R
− (cid:1) · P(cid:16)

(cid:1)(cid:12)(cid:12)(cid:12) R
(cid:1)(cid:12)(cid:12)(cid:12) R
(cid:0)xj0+1, ˆxo
xj0 ∈ B(cid:12)(cid:12)(cid:12) R

(cid:17)(cid:17)
(cid:48)(i)
(cid:48)(i)
k = 0,··· , R
j0−1 = 0
(cid:48)(i)
k = 0,··· , R

(cid:48)(i)
j0−1 = 0
(cid:48)(i)
(cid:48)(i)
k = 0,··· , R

(cid:17)(cid:17)
(cid:48)(i)
k = 0,··· , R
(cid:48)(i)
j0−1 = 0

j0
(cid:48)(i)
k = 0,··· , R

(cid:48)(i)
j0−1 = 0
+ Exj0+1

(cid:48)(i)
k = 0,··· , R

(cid:48)(i)
k = 0,··· , R

(cid:1)(cid:12)(cid:12)(cid:12) R

(cid:48)(i)
j0−1 = 0

+ Exj0+1

= 0
+ c(cid:48)

j0+1
(cid:48)(i)
j0

·(cid:16)

·(cid:16)

(cid:17)(cid:17)

(cid:48)(i)
j0

R

= 0

(cid:48)(i)
j0

= 0

+ c(cid:48)

j0

R

= 0

(ii)

j0

j0

J∗

(cid:48)(i)
j0

j0+1:N

J∗

(cid:48)(i)

j0

j0

(cid:105)(cid:17)

(iii)≤ c(cid:48)

j0

−  · δj0

(69)

To obtain (i), we use the fact that

d2(cid:0)xj0, ˆx◦

j0

(cid:1) + Exj0+1

(cid:104)

J∗

j0+1

26

(cid:0)xj0+1, ˆx◦

j0+1:N

(cid:105)

(cid:1)(cid:12)(cid:12)(cid:12) xj0

< c(cid:48)

j0

(cid:48)(i)
j0

= 0 (or equivalently xj0 ∈ D◦
(cid:16)

if R
j0; whereas (ii) and (iii) follow from (66) and
(68), respectively. By a similar argument as in the proof of Proposition III.14, from (64) and (69), we can observe
that for sufﬁciently large i, there exists ˆx(i−1)
xk,P(cid:48)(i)

j0), and B is a subset of D◦
(cid:104)

k:N in Ki−1 for which it holds that
xk,P (i)

(cid:17) ≤ Exk

= G(cid:16)

G(cid:16)

k:N , ˆx(i−1)

ˆx(i−1)

(cid:48)(i−1)
k:N

(cid:48)(i−1)
k:N

< Exk

(cid:17)(cid:105)

(cid:17)(cid:105)

k:N , ˆx

(cid:17)

(cid:16)

(cid:104)

Jk

Jk

k:N

k:N

ˆx

G. Proofs of Lemmas III.23 and III.24

Proof of Lemma III.23: To prove the lemma, we ﬁrst claim that the following hold for all j in {k,··· , N}:

lim
l→∞
j = P (il)

j

cos θj
(xj) and Rj = P j (xj) for each l in N and j in {k,··· , N}.

j = 0

cos θj

subject to R(il)

For notational convenient, let us deﬁne

If α is non-zero, then by Corollary III.12, ˆx(il)

p1,j

p2,j

lim
l→∞

lim
l→∞

E(cid:104)
E(cid:104)
E(cid:104)
E(cid:104)

lim
l→∞

sin θj

sin θj

α = E2(cid:104)
1,j = E(cid:104)
2,j = E(cid:104)

p(il)

p(il)

p1,j

p2,j

p1,j

p2,j

sin θj

j = 0

j = 0

j = 0

(cid:105)
(cid:105)
(cid:105)
(cid:105)

+ E2(cid:104)

= E(cid:104)
= E(cid:104)
= E(cid:104)
= E(cid:104)

k = 0,··· , R(il)
k = 0,··· , R(il)
k = 0,··· , R(il)
k = 0,··· , R(il)

(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) R(il)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:16)
(cid:12)(cid:12)(cid:12) R(il)
(cid:105)
(cid:12)(cid:12)(cid:12) R(il)
(cid:105)
k = 0,··· , R(il)
(cid:12)(cid:12)(cid:12) R(il)
k = 0,··· , R(il)
(cid:12)(cid:12)(cid:12) R(il)
(cid:105)
k = 0,··· , R(il)
(cid:12)(cid:12)(cid:12) R(il)
cos θj
(cid:12)(cid:12)(cid:12) R(il)
(cid:105)
k = 0,··· , R(il)
cos θj
k = 0,··· , R(il)
cos θj
(cid:16)

sin θj
k = 0,··· , R(il)

E(cid:104)
E(cid:104)

(cid:104)
(cid:104)

j = 0

j = 0

j = 0

j = 0

+ E2

+ E2

j =

cos θj

ˆp(il)
1,j

ˆp(il)
2,j

ˆθ(il)
j

(cid:17)

lim
l→∞ d

ˆx(il)
j

, ˆxj

= 0

(cid:104)
(cid:104)

sin θj

sin θj

sin ˆθ(il)

j =

cos ˆθ(il)

j =

E2

E2

and

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:17)T

(cid:16)

and ˆxj =

ˆp1,j

ˆp2,j

(70a)

(70b)

(70c)

(70d)

(cid:17)T

ˆθj

satisfy

j = 0

(cid:105)
(cid:12)(cid:12)(cid:12) R(il)
(cid:105)
k = 0,··· , R(il)
(cid:12)(cid:12)(cid:12) R(il)
k = 0,··· , R(il)

j = 0

j = 0

j = 0

(cid:105)
(cid:105)

(71)

For each j in {k,··· , N}, let us deﬁne ˆx∗

Note that by Corollary III.12, it holds that ˆx∗

Therefore, we conclude that ˆxk:N ∈ X (P k:N ).

Otherwise, if α is zero then the value of

27

j

2,j

1,j

as

ˆθ∗

ˆp∗

ˆp∗

p1,j

j =

(cid:17)
(cid:16)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)

1,j = E(cid:104)
2,j = E(cid:104)
j = α−1 · E(cid:104)
j = α−1 · E(cid:104)
(cid:16)
k:N ∈ X (P k:N ). From (70) and (71), we can observe that
(cid:1) ≤ d
d(cid:0)ˆxj, ˆx∗

p∗
p∗
sin ˆθ∗
cos ˆθ∗

cos θj

sin θj

p2,j

ˆx(il)
j

j

j

, ˆxj

+ d

, ˆx∗

ˆx(il)
j

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:17) l→∞−→ 0
(cid:16)
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)

(cid:104)

Exj

d2 (xj, ˆxj)

p1,j = E(cid:104)
p2,j = E(cid:104)

p1,j

p2,j

does not depend on ˆθj, and by Proposition III.11 and Corollary III.12, we can show that ˆxk:N ∈ X (P k:N ) if the
following hold for all j in {k,··· , N}:

This can be veriﬁed by similar arguments given above and (70). It remains to prove the claim.

(cid:105)

= E(cid:104)
(cid:110)P (il)

E(cid:104)

(cid:12)(cid:12)(cid:12) R(il)

Proof of the Claim: Notice that p1,j, p2,j, sin ˆθj, cos ˆθj are all continuous functions of xj. Hence to show that

(70) is true, it is sufﬁcient to show that the following holds for any continuous function g : R2 × [0, 2π) → R:

g (xj)

g (xj)

lim
l→∞

j = 0

k = 0,··· , R(il)

j|j and µj|j given in (25). Since

(cid:111)
(72)
j|j → µj|j for all j in {k,··· , N}. Since(cid:0)R2 × [0, 2π), d(cid:1) is a complete, separable metric space, by
l∈N converges to P k:N , by Deﬁnition III.17,
(cid:111)

i∈N and the Skorokhod representation theorem [13], there exist a sequence of random
l∈N and a random variable yj all deﬁned on a common probability space (Ω, F, ν) in which the

µ(il)
j|j

(cid:110)

(cid:111)

k:N

Recall the deﬁnitions of µ(il)

it holds that µ(il)
the convergence of

(cid:110)

y(il)
j

variables
following three facts are true:

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)

(cid:16)(cid:110)
(cid:16)(cid:110)

ω ∈ Ω

ω ∈ Ω

(cid:12)(cid:12)(cid:12) y(il)
(ω) ∈ A(cid:111)(cid:17)
(cid:12)(cid:12)(cid:12) yj(ω) ∈ A(cid:111)(cid:17)

j

(cid:110)

j|j is the probability measure of y(il)

(F1) µ(il)
(F2) µj|j is the probability measure of yj, i.e., ν
(F3)
i∈N converges to yj almost surely.

y(il)
j

(cid:111)

j

, i.e., ν

(cid:110)

(cid:111)
l∈N is a convergent sequence, according to Proposition D.11, there is a compact set Kj for which

Since
j|j (Kj) = 1 for all l in N. Hence, by (F1), the following holds for a positive real β:
µ(il)

ˆx(il−1)

j

= µj|j (A) for each A in B.

= µ(il)

j|j (A) for each A in B.

(cid:90)(cid:40)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)g

ω∈Ω

(cid:16)

(il )
y
j

(ω)

(cid:17)(cid:12)(cid:12)(cid:12)>β

(cid:16)

(cid:41)(cid:12)(cid:12)(cid:12)g

y(il)
j

(ω)

(cid:17)(cid:12)(cid:12)(cid:12) dν =

(cid:90)
(cid:110)

(cid:12)(cid:12) |g(x)|>β

x∈R2×[0,2π)

(cid:111) |g (x)| dµ(il)

j|j = 0

(73)

28

(74)

(75)

(77)

(78)

(79)

holds for all l in N. Using Proposition III.13 and by the fact that

ˆx(i)
k:N

i∈N converges to ˆxk:N , we can derive

As the rest of the proof is similar to the above arguments, we omit the detail for brevity.

for all l in N. In conjunction with (F3), by an application of Theorem 10.3.6 in [10], we have that

Therefore, from (F2) and (74), we can see that

(cid:90)

lim
l→∞

R2×[0,2π)

g (x) dµ(il)

j|j = lim
l→∞

Ω

(cid:90)

(cid:16)

(cid:17)

lim
l→∞

Ω

g

y(il)
j

(ω)

dν =

g (yj(ω)) dν

(cid:90)

Ω

(cid:90)

(cid:90)
(cid:90)

Ω

=

=

(cid:16)

g

y(il)
j

(ω)

(cid:17)

dν

g (yj(ω)) dν

g (x) dµj|j

R2×[0,2π)

i∈N be a sequence of estimates that converges to ˆxk:N . The following inclusions hold

D(l)
j

D(l)
j

(cid:110)

(cid:111)

This proves the claim.
Lemma G.16: Let

for all j in {k,··· , N}:

ˆx(i)
k:N

where

and

D

i∈N

l≥i

i∈N

l≥i

Dj =
D

j =

xj ∈ R2 × [0, 2π)
xj ∈ R2 × [0, 2π)

Dj ⊃ (cid:92)
(cid:91)
j ⊂ (cid:91)
(cid:92)
(cid:12)(cid:12)(cid:12) d2 (xj, ˆxj) + Exj+1
(cid:104)
(cid:12)(cid:12)(cid:12) d2 (xj, ˆxj) + Exj+1
(cid:104)
(cid:12)(cid:12)(cid:12) d2(cid:16)
(cid:12)(cid:12)(cid:12) d2(cid:16)
i∈N(cid:83)
Proof: Let xj be an element of (cid:84)
(cid:17)

xj ∈ R2 × [0, 2π)
xj ∈ R2 × [0, 2π)

holds for all l in N. Hence, we can see that

(cid:110)
(cid:110)
(cid:110)
(cid:110)

+ Exj+1
+ Exj+1

j+1 is deﬁned in (18).

xj, ˆx(i)
j

xj, ˆx(i)
j

D(i)

j =

D(i)

j =

(cid:17)
(cid:17)

l≥i

xj, ˆx(il)

j

+ Exj+1

J∗

j+1

d2(cid:16)

where J∗

which xj ∈ D(il)

j

d2 (xj, ˆxj) + Exj+1
which shows that xj ∈ Dj. This proves (76a).

To show that (76b) is true, we consider

(76a)

(76b)

(cid:111)
(cid:111)

j

< c(cid:48)

(cid:12)(cid:12)(cid:12) xj = xj
(cid:105) ≤ c(cid:48)
(cid:12)(cid:12)(cid:12) xj = xj
(cid:105)
(cid:17)(cid:12)(cid:12)(cid:12) xj = xj
(cid:17)(cid:12)(cid:12)(cid:12) xj = xj

(cid:111)
(cid:111)
(cid:105) ≤ c(cid:48)
(cid:105)

< c(cid:48)

j

j

j

J∗
j+1 (xj+1, ˆxj+1:N )
J∗
j+1 (xj+1, ˆxj+1:N )

(cid:104)
(cid:104)

J∗
J∗

j+1

j+1

(cid:16)
(cid:16)

xj+1, ˆx(i)

j+1:N

xj+1, ˆx(i)

j+1:N

j . By deﬁnition, there exists an inﬁnite index set {il}l∈N for
D(l)
(cid:16)

(cid:17)(cid:12)(cid:12)(cid:12) xj = xj
(cid:105) ≤ c(cid:48)
(cid:111)
(cid:12)(cid:12)(cid:12) xj = xj
(cid:105) ≤ c(cid:48)

j

j

(cid:104)
(cid:104)

xj+1, ˆx(il)

j+1:N

(cid:110)

J∗
j+1 (xj+1, ˆxj+1:N )

j ⊃ (cid:92)

Dc

i∈N

(cid:17)c

(cid:16)D(l)

j

(cid:91)

l≥i

29

(80a)

(80b)

Proof of Lemma III.24: For every A in B, let us deﬁne

j|j−1 (A) = P(cid:16)
j|j (A) = P(cid:16)

µ(i)

xj ∈ A(cid:12)(cid:12)(cid:12) R(i)
xj ∈ A(cid:12)(cid:12)(cid:12) R(i)

µ(i)

(cid:17)
(cid:17)
(cid:111)

k = 0,··· , R(i)
(cid:110)
k = 0,··· , R(i)

j−1 = 0

j = 0
ˆx(il−1)

j = P (i)

(xj) for all i in N and j in {k,··· , N}. Since

subject to R(i)
according to Proposition D.11, there exist compact subsets {Kj}N
and j in {k,··· , N}:

j

l∈N is a convergent sequence,
j=k for which the following holds for all l in N

k:N

j|j (Kj) = 1
µ(il)

(cid:110)

(cid:111)

Hence, for all j in {k,··· , N}, the probability measures
tion C.7. By Theorem 11.5.4 in [10], for each j in {k,··· , N}, there exists a subsequence
R(i)

(cid:111)
l∈N are uniformly tight in the sense of Deﬁni-
(cid:12)(cid:12)(cid:12) R(i)
(cid:17)
l∈N that converges
k = 0,··· , R(i)
j−1
takes a value in a compact set [, 1] for all i in N and j in {k,··· , N}. Hence, there is an inﬁnite index set {i(cid:48)(cid:48)
l }l∈N
of {i(cid:48)

to a probability measure µj|j deﬁned on(cid:0)R2 × [0, 2π), B(cid:1). In addition, note that P(cid:16)
(cid:17)

l}l∈N for which the following holds for all j in {k,··· , N}:

µ(i(cid:48)
l)
j|j

j = 0

µ(il)
j|j

(cid:110)

R(i(cid:48)(cid:48)
l )
j = 0

k = 0,··· , R(i(cid:48)(cid:48)

l )

l )
j−1 = 0

= qj

P(cid:16)

(cid:12)(cid:12)(cid:12) R(i(cid:48)(cid:48)

lim
l→∞

where qj belongs to [, 1]. For clear and simple presentation, without loss of generality, we prove the lemma by
imposing the following three assumptions: For each j in {k,··· , N},
(A1) The estimates
(A2) The probability measures

ˆx(i−1)

(cid:110)

k:N .

k:N

i∈N converge to µj|j.

(A3) limi→∞ P(cid:16)

R(i)

j = 0

(cid:111)
(cid:110)
i∈N converge to ˆx(cid:48)
(cid:12)(cid:12)(cid:12) R(i)
k = 0,··· , R(i)

(cid:111)

µ(i)
j|j

(cid:17)

j−1 = 0

= qj holds, where qj belongs to [, 1]

To complete the proof of the lemma, it is sufﬁcient to show that there exist policies P k:N for which

(F1) For every A in B, it holds that

and

µj|j (A) = P(cid:16)
qj = P(cid:16)

Rj = 0
subject to Rj = P j (xj) for all j in {k,··· , N}.
k:N ), where ˆx(cid:48)

(F2) The policies P k:N belong to P (ˆx(cid:48)
For notational convenience, let us deﬁne
xj ∈ R2 × [0, 2π)
xj ∈ R2 × [0, 2π)

Dj =
D

(cid:110)
(cid:110)

j =

(cid:12)(cid:12)(cid:12) d2(cid:0)xj, ˆx(cid:48)
(cid:12)(cid:12)(cid:12) d2(cid:0)xj, ˆx(cid:48)

j

j

xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:111)
(cid:110)
(cid:1)(cid:12)(cid:12)(cid:12) xj = xj
(cid:0)xj+1, ˆx(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) xj = xj
(cid:0)xj+1, ˆx(cid:48)

(cid:1) + Exj+1
(cid:1) + Exj+1

k:N is the limit of

ˆx(i−1)

J∗
J∗

i∈N.

(cid:104)
(cid:104)

j+1:N

j+1:N

j+1

j+1

k:N

(81a)

(81b)

(82a)

(82b)

(cid:111)
(cid:111)

(cid:105) ≤ c(cid:48)
(cid:105)

< c(cid:48)

j

j

and

(cid:110)
(cid:110)

xj ∈ R2 × [0, 2π)
xj ∈ R2 × [0, 2π)

(cid:12)(cid:12)(cid:12) d2(cid:16)
(cid:12)(cid:12)(cid:12) d2(cid:16)

D(i)

j =

D(i)

j =

(cid:17)
(cid:17)

+ Exj+1
+ Exj+1

j

xj, ˆx(i−1)
xj, ˆx(i−1)

j

(cid:104)
(cid:104)

J∗
J∗

j+1

j+1

(cid:16)
(cid:16)

xj+1, ˆx(i−1)
xj+1, ˆx(i−1)

j+1:N

j+1:N

(cid:17)(cid:12)(cid:12)(cid:12) xj = xj
(cid:17)(cid:12)(cid:12)(cid:12) xj = xj

(cid:105) ≤ c(cid:48)
(cid:105)

< c(cid:48)

j

j

30

(83a)

(83b)

(cid:111)
(cid:111)

for each i in N and j in {k,··· , N}, where J∗
sets Dj and D(i)

are closed, and the sets D

j

j and D(i)

j

are open.

j+1 is deﬁned in (18). Note that according to Proposition III.13, the

We ﬁrst make the following two claims to show that (F1) is true.

Claim 1: For each A in B, let us deﬁne

xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
(cid:17)
Then, µj|j−1 is a probability measure on(cid:0)R2 × [0, 2π), B(cid:1), and it holds that

µj|j−1 (A)

P(cid:16)

R2×[0,2π)

def
=

(cid:90)

dµj−1|j−1

i→∞ µ(i)
lim

j|j−1 (A) = µj|j−1 (A)

(84)

for all A in B.

To prove the claim, based on Proposition D.12, we note that

(cid:90)

(cid:90)

P(cid:16)

xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x

(cid:17)

(cid:17)

xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
P(cid:16)
xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
(cid:17)

j|j−1 (A) =
µ(i)

xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
holds for each A in B. By deﬁnition, for ﬁxed x in R2×[0, 2π), the mapping A (cid:55)→ P(cid:16)
probability measure on(cid:0)R2 × [0, 2π), B(cid:1). In conjunction with Assumption II.4, we can see that x (cid:55)→ P(cid:16)

R2×[0,2π)

j−1|j−1

dµ(i)

(85)

(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x
(cid:17)

deﬁnes a

is a bounded, continuous function. Hence, using (A2), we have that

i→∞ µ(i)
lim

j|j−1 (A) = lim
i→∞

Lastly, the argument that µj|j−1 is a probability measure on (cid:0)R2 × [0, 2π), B(cid:1) follows from (86) and the fact
that A (cid:55)→ P(cid:16)

(cid:90)
is a probability measure on(cid:0)R2 × [0, 2π), B(cid:1).

xj ∈ A(cid:12)(cid:12)(cid:12) xj−1 = x

dµj−1|j−1 = µj|j−1 (A)

P(cid:16)

R2×[0,2π)

R2×[0,2π)

j−1|j−1

dµ(i)

(cid:17)

(86)

(cid:3)

=

Claim 2: There exists a measurable function fj : R2 × [0, 2π) → [0, 1] for which

(cid:82)

µj|j (A) =
holds for all A in B, where µj|j−1 is deﬁned in (84).

A fj dµj|j−1

qj

(87)

Based on Lemma C.8 and Proposition D.12, for any open set O, we can see that the following relations hold:

µj|j (O) ≤ lim inf

i→∞ µ(i)

j|j (O)

(cid:12)(cid:12)(cid:12) R(i)

j|j−1 (O)
µ(i)
k = 0,··· , R(i)

j−1 = 0

(cid:17)

P(cid:16)

(i)≤ lim
i→∞
R(i)
µj|j−1 (O)

(ii)
=

qj

j = 0

(88)

31

where (i) follows from Proposition D.12, and (ii) follows from Claim 1 and (A3). We argue that the following
holds for any set A in B:

To justify the argument, by contradiction, suppose that for a set A in B it holds that

µj|j (A) ≤ µj|j−1 (A)

qj

µj|j (A) >

µj|j−1 (A)

qj

(89)

(90)

By the closed regularity theorem (see Theorem 7.1.3 in [10]) and Remark C.5, we can choose an open set O
containing A for which the following holds:

µj|j (O) ≥ µj|j (A) >

µj|j−1 (O)

≥ µj|j−1 (A)

qj

qj

(91)

This contradicts (88).

Notice that (89) implies that µj|j is absolutely continuous with respect to µj|j−1. According to the Radon-
Nikodym theorem, there is a measurable function fj : R2 × [0, 2π) → R+ for which the following holds for all A
in B:

(cid:82)

µj|j (A) =

A fj dµj|j−1

(92)
In addition, it can be veriﬁed that fj(x) ≤ 1 for almost every x in R2 × [0, 2π); otherwise (89) would be violated.
(cid:3)
Proof of (F1): Using the function fj obtained in Claim 2, let us deﬁne policies P k:N as follows: For each j in
{k,··· , N}

qj

In conjunction with (92), we can verify that under the policies P k:N , the following holds:

Using (94) and Proposition D.12, it can be veriﬁed that the following hold for every A in B:

P j(x) =

1 with probability 1 − fj(x)

0 with probability fj(x)
(cid:12)(cid:12)(cid:12) xj = x
(cid:17)
A P(cid:16)P j(xj) = 0
(cid:82)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
µj|j (A) = P(cid:16)
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
qj = P(cid:16)
(cid:17)

Rj = 0

qj

dµj|j−1

µj|j (A) =

(93)

(94)

and

subject to Rj = P j (xj) for all j in {k,··· , N}. This completes the proof.

Henceforth, we make two additional claims under the policies P k:N determined as in (93) to show that (F2) is

true.

32

(96)

Claim 3: For any Borel measurable subset A contained in Dc

P(cid:16)

xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)

j, it holds that

= 0

where the set Dj is deﬁned in (82a).

Notice that

P(cid:16)

=

Rj = 0

xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
P(cid:16)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
P(cid:16)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17) · P(cid:16)
P(cid:16)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:16)O ∩ D(i)
(cid:12)(cid:12)(cid:12) R(i)

(cid:16)O ∩ D(i)

j|j (O) = µ(i)
µ(i)
j|j

(cid:17) ≤

P(cid:16)

P(cid:16)

µ(i)
j|j−1

j = 0

Rj = 0

Rj = 1

R(i)

(cid:17)
k = 0,··· , R(i)

j

j

−

(cid:17)

j−1 = 0

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

the following:

where the set D(i)
in N:

j

To prove the claim, let O be an open set contained in Dc

j. By Lemma D.10 and Proposition D.12, we can derive

is deﬁned in (83a). By applying Theorem C.8, we can show that the following holds for all i0

µj|j (O) ≤ lim inf

i→∞ µ(i)

j|j (O)

P(cid:16)
P(cid:16)

≤ lim inf
i→∞

≤ lim inf
i→∞

P(cid:16)

(i)≤

µj|j−1

Rj = 0

(cid:17)
(cid:17)

j−1 = 0

j−1 = 0

R(i)

R(i)

j

l≥i

D(l)
j

j = 0

j = 0

µ(i)
j|j−1

µ(i)
j|j−1

(cid:16)O ∩ D(i)
(cid:17)
(cid:12)(cid:12)(cid:12) R(i)
(cid:16)O ∩(cid:16)(cid:83)
(cid:17)(cid:17)
k = 0,··· , R(i)
(cid:12)(cid:12)(cid:12) R(i)
(cid:16)O ∩(cid:16)(cid:83)
(cid:17)(cid:17)
k = 0,··· , R(i)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:110)(cid:83)
(cid:111)
(cid:16)O ∩(cid:16)(cid:84)
(cid:17)(cid:17)
i∈N(cid:83)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0

D(l)
j

D(l)
j

D(l)
j

l≥i0

l≥i

l≥i

(cid:17) = 0

µj|j (O) ≤ µj|j−1

Rj = 0

P(cid:16)

where (i) follows from Claim 1, (F1), and the fact that
sets. Hence, from Lemma G.16, we have that

i∈N is a decreasing sequence of measurable

j is an open set, by selecting O = Dc

j, we conclude that the following holds for every Borel measurable

Since Dc
subset A of Dc
j:

(cid:17)

(cid:16)Dc

j

µj|j (A) ≤ µj|j

= 0

(cid:3)

Claim 4: Suppose that P(cid:16)

Rj = 1

A contained in the set D

j given in (82b), it holds that

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17)
P(cid:16)

= 0

is non-zero. Then, for any Borel measurable subset

33

(97)

To prove the claim, let F be a closed set contained in D

j. Notice that, by Lemma D.10, the following holds for

all i in N:

Using (97) and Theorem C.8, we can show that the following holds for all i0 in N:

µj|j (F) ≥ lim sup
i→∞
≥ lim sup
i→∞

= lim sup
i→∞

≥ lim sup
i→∞

(i)≥

xj ∈ F ∩ D(i)

j

P(cid:16)

=

P(cid:16)
P(cid:16)

(cid:17)

j|j (F)
µ(i)

xj ∈ F ∩ D(i)

R(i)

j = 0

j

j

(cid:17)

(cid:17)

j−1 = 0

j−1 = 0

j = 0
k = 0,··· , R(i)

k = 0,··· , R(i)

k = 0,··· , R(i)

(cid:12)(cid:12)(cid:12) R(i)
(cid:12)(cid:12)(cid:12) R(i)
(cid:12)(cid:12)(cid:12) R(i)
(cid:16)F ∩ D(i)
(cid:17)
(cid:16)F ∩ D(i)
j = 0(cid:12)(cid:12) R(i)
(cid:16)F ∩(cid:16)(cid:84)
j = 0(cid:12)(cid:12) R(i)
(cid:16)F ∩(cid:16)(cid:84)
(cid:17)(cid:17)
(cid:110)(cid:84)
(cid:111)
(cid:16)F ∩(cid:16)(cid:83)
i∈N(cid:84)

(cid:17)
(cid:17)(cid:17)
k = 0,··· , R(i)
k = 0,··· , R(i)
D(l)
j

µ(i)
j|j−1

µ(i)
j|j−1

D(l)
j

l≥i

j

R(i)

R(i)

l≥i

l≥i0

D(l)
j

µj|j−1

P(cid:0)Rj = 0(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0(cid:1)
(cid:17)(cid:17)
P(cid:0)Rj = 0(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0(cid:1)
P(cid:0)Rj = 0(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0(cid:1)

µj|j−1 (F)

µj|j−1

D(l)
j

l≥i

=

µ(i)
j|j

P(cid:16)
P(cid:16)

µj|j (F) ≥

(cid:17)
(cid:17)

j−1 = 0

j−1 = 0

where (i) follows from Claim 1, (F1), and the fact that
sets. Hence, from Lemma G.16, we have that

i∈N is an increasing sequence of measurable

Using this relation, we can see that

µj|j−1 (F)

xj ∈ F(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
= P(cid:16)
(cid:17)
xj ∈ F(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
= P(cid:16)
(cid:17) · P(cid:16)
xj ∈ F(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
+ P(cid:16)
(cid:17) · P(cid:16)
xj ∈ F(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17) · P(cid:16)
+ P(cid:16)

≥ µj|j−1 (F)

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

Rj = 0

Rj = 1

Rj = 1

Using the fact that P(cid:16)

Rj = 1

(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)

Based on the closed regularity theorem (see Theorem 7.1.3 in [10]), we can see that the following holds for any
Borel measurable set A contained in D

is non-zero, we obtain

= 0

P(cid:16)

xj ∈ F(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17)
xj ∈ A(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:17)
P(cid:16)
(cid:0)xj,P j:N , ˆx(cid:48)

j:

(cid:104)

= 0

(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:105)
(cid:0)xk,P(cid:48)

(cid:2)Jk

Exk

(cid:1)(cid:3)

k:N , ˆx(cid:48)

k:N

Proof of (F2): Recall that Exj
j are deﬁned in (14) and
(18), respectively, and that Rj = P j (xj) for all j in {k,··· , N}. We will use the mathematical induction to show
that the following is true:

Jj

j:N

and J∗

k:N )] = minP(cid:48)
Using Claim 3 and Claim 4, we can derive the following:

k:N

Exk [Jk (xk,P k:N , ˆx(cid:48)

34

(cid:3)

(98a)

(98b)

and

provided that P(cid:16)

RN = 1

(cid:12)(cid:12)(cid:12) Rk = 0,··· , RN−1 = 0
(cid:17)
N (xN , ˆx(cid:48)
J∗
N )
(cid:104)

(cid:104)

N

N

N )

(cid:104)

(cid:104)
(cid:104)

N ) , c(cid:48)

d2 (xN , ˆx(cid:48)

c(cid:48)
N = ExN
= ExN

ExN
= ExN
= ExN

min(cid:8)d2 (xN , ˆx(cid:48)

N (xN , ˆx(cid:48)
J∗
N )
(cid:104)
(cid:104)

(cid:12)(cid:12)(cid:12) RN = 0
(cid:105)
(cid:9)(cid:12)(cid:12)(cid:12) RN = 0
(cid:105)
min(cid:8)d2 (xN , ˆx(cid:48)
(cid:12)(cid:12)(cid:12) RN = 0
(cid:105)
N ) , c(cid:48)
(cid:9)(cid:12)(cid:12)(cid:12) RN = 1
(cid:105)
(cid:12)(cid:12)(cid:12) RN = 1
(cid:105)
(cid:12)(cid:12)(cid:12) RN−1 = 0
(cid:105)
(cid:12)(cid:12)(cid:12) RN−1 = 0
(cid:105)
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:0)xj+1,P j+1:N , ˆx(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)
(cid:0)xj+1, ˆx(cid:48)
Jj+1
J∗
(cid:105)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:1)(cid:12)(cid:12)(cid:12) xj
(cid:105)
(cid:104)
(cid:0)xj+1,P j+1:N , ˆx
(cid:1)(cid:12)(cid:12)(cid:12) xj
(cid:111)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:104)
(cid:105)
(cid:1) + Exj+1
(cid:0)xj+1, ˆx
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 0
(cid:105)

JN (xN ,P N , ˆx(cid:48)
N )
J∗
N (xN , ˆx(cid:48)
N )

ExN
= ExN

(cid:48)
j+1:N
(cid:48)
j+1:N

∗
j+1

Jj+1

j+1:N

j+1:N

j+1

J

(cid:48)
j

, c

(cid:104)

Exj+1
= Exj+1

(cid:104)
(cid:104)
d2(cid:0)xj, ˆx
(cid:1) + Exj+1
(cid:104)
(cid:110)
d2(cid:0)xj, ˆx
(cid:104)
(cid:0)xj, ˆx

min

(cid:48)
j:N

∗
j

(cid:48)
j

(cid:48)
j

J

Exj
= Exj
= Exj

(99)

(100)

(101a)

(cid:105)

is nonzero. From (14), (18), and (98), we can derive that

Suppose that the following relation holds:

Then, using Claim 3 and Claim 4, we can derive the following:

(cid:105)

(cid:111)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:105)

(cid:48)
j

, c

(cid:48)
j

(cid:48)
j:N

∗
j+1

J

(cid:48)
j+1:N

(cid:1)(cid:12)(cid:12)(cid:12) xj

(cid:104)
(cid:110)
(cid:0)xj+1, ˆx
(cid:1) + Exj+1
d2(cid:0)xj, ˆx
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj = 1
(cid:105)
(cid:0)xj, ˆx
(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:17)
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:104)
(cid:105)
(cid:0)xj,P j:N , ˆx(cid:48)
(cid:1)(cid:12)(cid:12)(cid:12) Rk = 0,··· , Rj−1 = 0
(cid:105)
(cid:104)
(cid:0)xj, ˆx(cid:48)
(cid:2)Jk
(cid:0)xk,P(cid:48)

(cid:1)(cid:3) = Exk [J∗

Exj
Jj
= Exj

k (xk, ˆx(cid:48)

k:N , ˆx(cid:48)

J∗

j

k:N

j:N

j:N

Exk

minP(cid:48)

k:N

k:N )]

is non-zero. From (14), (18), and (101), we can derive that

35

(101b)

(102)

(cid:104)
(cid:104)

and

provided that P(cid:16)

(cid:48)
j = Exj
c
= Exj

min

∗
j

J

Rj = 1

By induction, we conclude that (102) holds for all j in {k,··· , N}. By Deﬁnition III.5 and the fact that

we conclude that the policies P k:N belong to P (ˆx(cid:48)

k:N ).

REFERENCES

[1] Q. Du, V. Faber, and M. Gunzburger, “Centroidal voronoi tessellations: Applications and algorithms,” SIAM Review, vol. 41, no. 4, pp.

637–676, 1999.

[2] A. Molin and S. Hirche, “An iterative algorithm for optimal event-triggered estimation,” in 4th IFAC Conference on Analysis and Design

of Hybrid Systems, June 2012, pp. 64–69.

[3] G. M. Lipsa and N. C. Martins, “Remote state estimation with communication costs for ﬁrst-order LTI systems,” IEEE Trans. Automat.

Contr., vol. 56, no. 9, pp. 2013–2025, Sept 2011.

[4] A. Nayyar, T. Baar, D. Teneketzis, and V. V. Veeravalli, “Optimal strategies for communication and remote estimation with an energy

harvesting sensor,” IEEE Transactions on Automatic Control, vol. 58, no. 9, pp. 2246–2260, Sept 2013.

[5] S. Park and N. Martins, “Individually optimal solutions to a remote state estimation problem with communication costs,” in Decision and

Control (CDC), 2014 IEEE 53rd Annual Conference on, Dec 2014, pp. 4014–4019.

[6] Y. Xu and J. P. Hespanha, “Optimal communication logics in networked control systems,” in Decision and Control, 2004. CDC. 43rd

IEEE Conference on, vol. 4, Dec 2004, pp. 3527–3532.

[7] R. Cogill, S. Lall, and J. P. Hespanha, “A constant factor approximation algorithm for event-based sampling,” in American Control

Conference, 2007. ACC ’07, July 2007, pp. 305–311.

[8] L. Li and M. Lemmon, “Performance and average sampling period of sub-optimal triggering event in event triggered state estimation,” in

Decision and Control and European Control Conference (CDC-ECC), 2011 50th IEEE Conference on, Dec 2011, pp. 1656–1661.

[9] L. Li, Z. Wang, and M. Lemmon, “Polynomial approximation of optimal event triggers for state estimation problems using SOSTOOLS,”

in American Control Conference (ACC), 2013, June 2013, pp. 2699–2704.

[10] R. M. Dudley, Real Analysis and Probability, 2nd ed. Cambridge University Press, 2002.
[11] B. T. McClintock, R. King, L. Thomas, J. Matthiopoulos, B. J. McConnell, and J. M. Morales, “A general discrete-time modeling framework

for animal movement using multistate random walks,” Ecological Monographs, vol. 82, no. 3, pp. 335–349, 2012.

[12] P. Billingsley, Probability and measure, 3rd ed. Wiley, 1995.
[13] A. V. Skorokhod, “Limit theorems for stochastic processes,” Theory of Probability & Its Applications, vol. 1, no. 3, pp. 261–290, 1956.

