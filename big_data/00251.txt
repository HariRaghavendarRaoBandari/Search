An Introduction to Lévy and Feller

Processes

– Advanced Courses in Mathematics - CRM Barcelona 2014 –

René L. Schilling

TU Dresden, Institut für Mathematische Stochastik,

01062 Dresden, Germany

rene.schilling@tu-dresden.de

http://www.math.tu-dresden.de/sto/schilling

These course notes will be published, together Davar Khoshnevisan’s notes on Invariance and

Comparison Principles for Parabolic Stochastic Partial Differential Equations as From Lévy-type

Processes to Parabolic SPDEs by the CRM, Barcelona and Birkäuser, Cham 2016. The arXiv-version and

the published version may differ in layout, pagination and wording, but not in content.

6
1
0
2

 
r
a

M
1

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
1
5
2
0
0

.

3
0
6
1
:
v
i
X
r
a

Contents

Preface

Symbols and notation

1. Orientation

2. Lévy processes

3. Examples

4. On the Markov property

5. A digression: semigroups

6. The generator of a Lévy process

7. Construction of Lévy processes

8. Two special Lévy processes

9. Random measures

10.A digression: stochastic integrals

11.From Lévy to Feller processes

12.Symbols and semimartingales

13.Dénouement

A. Some classical results

Bibliography

1

3

5

7

12

16

24

30

36

44

49

55

64

75

84

93

97

104

Preface

These lecture notes are an extended version of my lectures on Lévy and Lévy-type processes
given at the Second Barcelona Summer School on Stochastic Analysis organized by the Centre
de Recerca Matemàtica (CRM). The lectures are aimed at advanced graduate and PhD students.
In order to read these notes, one should have sound knowledge of measure theoretic probability
theory and some background in stochastic processes, as it is covered in my books Measures,
Integals and Martingales [53] and Brownian Motion [55].

My purpose in these lectures is to give an introduction to Lévy processes, and to show how
one can extend this approach to space inhomogeneous processes which behave locally like Lévy
processes. After a brief overview (Chapter 1) I introduce Lévy processes, explain how to char-
acterize them (Chapter 2) and discuss the quintessential examples of Lévy processes (Chapter 3).
The Markov (loss of memory) property of Lévy processes is studied in Chapter 4. A short analytic
interlude (Chapter 5) gives an introduction to operator semigroups, resolvents and their generators
from a probabilistic perspective. Chapter 6 brings us back to generators of Lévy processes which
are identiﬁed as pseudo differential operators whose symbol is the characteristic exponent of the
Lévy process. As a by-product we obtain the Lévy–Khintchine formula.

Continuing this line, we arrive at the ﬁrst construction of Lévy processes in Chapter 7. Chap-
ter 8 is devoted to two very special Lévy processes: (compound) Poisson processes and Brownian
motion. We give elementary constructions of both processes and show how and why they are
special Lévy processes, indeed. This is also the basis for the next chapter (Chapter 9) where we
construct a random measure from the jumps of a Lévy process. This can be used to provide a
further construction of Lévy processes, culminating in the famous Lévy–Itô decomposition and
yet another proof of the Lévy–Khintchine formula.

A second interlude (Chapter 10) embeds these random measures into the larger theory of ran-
dom orthogonal measures. We show how we can use random orthogonal measures to develop an
extension of Itô’s theory of stochastic integrals for square-integrable (not necessarily continuous)
martingales, but we restrict ourselves to the bare bones, i.e. the L2-theory. In Chapter 11 we in-
troduce Feller processes as the proper spatially inhomogeneous brethren of Lévy processes, and
we show how our proof of the Lévy–Khintchine formula carries over to this setting. We will see,
in particular, that Feller processes have a symbol which is the state-space dependent analogue of
the characteristic exponent of a Lévy process. The symbol describes the process and its gener-
ator. A probabilistic way to calculate the symbol and some ﬁrst consequences (in particular the
semimartingale decomposition of Feller processes) is discussed in Chapter 12; we also show that

3

4

R. L. Schilling: An Introduction to Lévy and Feller Processes

the symbol contains information on global properties of the process, such as conservativeness. In
the ﬁnal Chapter 13, we summarize (mostly without proofs) how other path properties of a Feller
process can be obtained via the symbol. In order to make these notes self-contained, we collect in
the appendix some material which is not always included in standard graduate probability courses.

It is now about time to thank many individuals who helped to bring this enterprise on the way.
I am grateful to the scientiﬁc board and the organizing committee for the kind invitation to deliver
these lectures at the Centre de Recerca Matemàtica in Barcelona. The CRM is a wonderful place
to teach and to do research, and I am very happy to acknowledge their support and hospitality. I
would like to thank the students who participated in the CRM course as well as all students and
readers who were exposed to earlier (temporally & spatially inhomogeneous. . . ) versions of my
lectures; without your input these notes would look different!

I am greatly indebted to Ms. Franziska Kühn for her interest in this topic; her valuable comments

pinpointed many mistakes and helped to make the presentation much clearer.

And, last and most, I thank my wife for her love, support and forbearance while these notes

were being prepared.

Dresden, September 2015

René L. Schilling

Symbols and notation

This index is intended to aid cross-referencing, so notation that is speciﬁc to a single chapter is
generally not listed. Some symbols are used locally, without ambiguity, in senses other than those
given below; numbers following an entry are page numbers.

Unless otherwise stated, functions are real-valued and binary operations between functions such
n→∞−−−→ f , limn fn,

as f ± g, f · g, f ∧ g, f ∨ g, comparisons f (cid:54) g, f < g or limiting relations fn
liminfn fn, limsupn fn, supn fn or infn fn are understood pointwise.

General notation: analysis

positive
negative

N

inf /0
a∨ b
a∧ b
(cid:98)x(cid:99)
|x|
x· y

1A

δx
D

∆
∂ j
∇, ∇x

F f , (cid:98)f
F−1 f , qf

always in the sense (cid:62) 0
always in the sense (cid:54) 0
1,2,3, . . .
inf /0 = +∞
maximum of a and b
minimum of a and b
largest integer n (cid:54) x
norm in Rd: |x|2 = x2
scalar product in Rd: ∑d

1,

0,

x ∈ A
x /∈ A

1 +··· + x2
d
j=1 x jy j

1A(x) =

point mass at x
domain
Laplace operator
partial derivative ∂
∂ x j
, . . . , ∂
∂ xd

gradient(cid:0) ∂
(cid:1)(cid:62)
(2π)−d(cid:82) e−ix·ξ f (x)dx
(cid:82) eix·ξ f (x)dx

Fourier transform

inverse Fourier transform

∂ x1

General notation: probability
∼
⊥⊥
a.s.
iid

‘is distributed as’
‘is stochastically independent’
almost surely (w. r. t. P)
independent and identically
distributed

N, Exp, Poi normal, exponential, Poisson

distribution
probability, expectation
variance, covariance
deﬁnition of a Lévy process, 7
12

P, E
V, Cov
(L0)–(L3)
(L2(cid:48))

Sets and σ-algebras

complement of the set A
closure of the set A
disjoint union, i.e. A∪ B for
disjoint sets A∩ B = /0
open ball,
centre x, radius r
support, { f (cid:54)= 0}
Borel sets of E

Ac
A
A∪· B

Br(x)

supp f
B(E)

5

R. L. Schilling: An Introduction to Lévy and Feller Processes

canonical ﬁltration σ (Xs : s (cid:54) t)

Spaces of functions

6

F X
t
F∞
Fτ
Fτ+
P

σ(cid:0)(cid:83)

t(cid:62)0 Ft

(cid:1)

75
29
predictable σ-algebra, 101

Stochastic processes

Px, Ex

Xt−
∆Xt
σ ,τ

τx
r ,τr

càdlàg

law and mean of a Markov
process starting at x, 24
left limit lims↑t Xs
jump at time t: Xt − Xt−
stopping times: {σ (cid:54) t} ∈ Ft,
t (cid:62) 0
inf{t > 0 : |Xt − X0| (cid:62) r}, ﬁrst
exit time from the open ball Br(x)
centered at x = X0
right continuous on [0,∞) with
ﬁnite left limits on (0,∞)

B(E)
Bb(E)
C(E)
Cb(E)
C∞(E)

Cc(E)
Cn(E)

Cn
b(E)

Cn
∞(E)

Borel functions on E
– – , bounded
continuous functions on E
– – , bounded
– – ,

f (x) = 0

lim|x|→∞

– – , compact support
n times continuously diff’ble
functions on E
– – , bounded (with all
derivatives)
– – , 0 at inﬁnity (with all
derivatives)
– – , compact support

Cn
c(E)
Lp(E, µ),Lp(µ),Lp(E)

Lp space w. r. t. the

S(Rd)

measure space (E, A , µ)
rapidly decreasing smooth
functions on Rd, 36

1. Orientation

Stochastic processes with stationary and independent increments are classical examples of Markov
processes. Their importance both in theory and for applications justiﬁes to study these processes
and their history.

The origins of processes with independent increments reach back to the late 1920s and they are
closely connected with the notion of inﬁnite divisibility and the genesis of the Lévy–Khintchine
formula. Around this time, the limiting behaviour of sums of independent random variables

X0 := 0 and Xn := ξ1 + ξ2 +··· + ξn,

n ∈ N,

was well understood through the contributions of Borel, Markov, Cantelli, Lindeberg, Feller, de
Finetti, Khintchine, Kolmogorov and, of course, Lévy; two new developments emerged, on the
one hand the study of dependent random variables and, on the other, the study of continuous-time
analogues of sums of independent random variables. In order to pass from n ∈ N to a continuous
parameter t ∈ [0,∞) we need to replace the steps ξk by increments Xt − Xs. It is not hard to see
that Xt, t ∈ N, with iid (independent and identically distributed) steps ξk enjoys the following
properties:

stationary increments
independent increments

X0 = 0

a.s.
Xt − Xs ∼ Xt−s − X0
∀s (cid:54) t
Xt − Xs⊥⊥σ (Xr,r (cid:54) s) ∀s (cid:54) t

(L0)
(L1)
(L2)

where ‘∼’ stands for ‘same distribution’ and ‘⊥⊥’ for stochastic independence. In the non-discrete
setting we will also require a mild regularity condition

continuity in probability
which rules out ﬁxed discontinuities of the path t (cid:55)→ Xt. Under (L0)–(L2) one has that

lim
t→0

P(|Xt − X0| > ε) = 0

∀ε > 0

Xt =

n

∑

k=1

ξk,n(t)

and

ξk,n(t) = (X kt

n

− X (k−1)t

n

) are iid

(L3)

(1.1)

for every n ∈ N. Letting n → ∞ shows that Xt arises as a suitable limit of (a triangular array of)
iid random variables which transforms the problem into a question of limit theorems and inﬁnite
divisibility.

7

8

R. L. Schilling: An Introduction to Lévy and Feller Processes

This was ﬁrst observed in 1929 by de Finetti [15] who introduces (without naming it, the name
is due to Bawly [6] and Khintchine [29]) the concept of inﬁnite divisibility of a random variable
X

∀n ∃ iid random variables ξi,n : X ∼ n
∑

i=1

ξi,n

(1.2)

and asks for the general structure of inﬁnitely divisible random variables. His paper contains two
remarkable results on the characteristic function χ(ξ ) = Eeiξ·X of an inﬁnite divisible random
variable (taken from [38]):

De Finetti’s ﬁrst theorem. A random variable X is inﬁnitely divisible if, and only if, its charac-

teristic function is of the form χ(ξ ) = limn→∞ exp(cid:2)− pn(1− φn(ξ ))(cid:3) where pn (cid:62) 0 and φn

is a characteristic function.

De Finetti’s second theorem. The characteristic function of an inﬁnitely divisible random vari-

able X is the limit of ﬁnite products of Poissonian characteristic functions

χn(ξ ) = exp(cid:2)− pn(1− eihnξ )(cid:3),

and the converse is also true. In particular, all inﬁnitely divisible laws are limits of convo-
lutions of Poisson distributions.

Because of (1.1), Xt is inﬁnitely divisible and as such one can construct, in principle, all indepen-
dent-increment processes Xt as limits of sums of Poisson random variables. The contributions
of Kolmogorov [32], Lévy [36] and Khintchine [28] show the exact form of the characteristic
function of an inﬁnitely divisible random variable

(cid:90)

(cid:16)
(cid:17)
1− eiy·ξ + iξ · y1(0,1)(|y|)

ν(dy)

(1.3)

− log Eeiξ·X = −il · ξ +

ξ · Qξ +

1
2

y(cid:54)=0

Rd \ {0} such that (cid:82)

where l ∈ Rd, Q ∈ Rd×d is a positive semideﬁnite symmetric matrix, and ν is a measure on
y(cid:54)=0 min{1,|y|2}ν(dy) < ∞. This is the famous Lévy–Khintchine formula.
The exact knowledge of (1.3) makes it possible to ﬁnd the approximating Poisson variables in de
Finetti’s theorem explicitly, thus leading to a construction of Xt.

A little later, and without knowledge of de Finetti’s results, Lévy came up in his seminal paper
[36] (see also [37, Chap. VII]) with a decomposition of Xt in four independent components: a
deterministic drift, a Gaussian part, the compensated small jumps and the large jumps ∆Xs :=
Xs − Xs−. This is now known as Lévy–Itô decomposition:
(cid:90)

(cid:33)

(1.4)

∑
0<s(cid:54)t

∆Xs −t

yν(dy)

ε(cid:54)|y|<1

ε(cid:54)|∆Xs|<1
y (N(ds,dy)− dsν(dy)) +

∆Xs

+ ∑
(cid:90)(cid:90)
0<s(cid:54)t
|∆Xs|(cid:62)1

(0,t]×B1(0)

(0,t]×B1(0)c

yN(ds,dy).

(1.5)

(cid:32)
Xt = tl +(cid:112)QWt + lim
(cid:90)(cid:90)
= tl +(cid:112)QWt +

ε→0

Chapter 1: Orientation

9

Lévy uses results from the convergence of random series, notably Kolmogorov’s three series the-
orem, in order to explain the convergence of the series appearing in (1.4). A rigorous proof based
on the representation (1.5) are due to Itô [23] who completed Lévy’s programme to construct Xt.
The coefﬁcients l,Q,ν are the same as in (1.3), W is a d-dimensional standard Brownian mo-
tion, and Nω ((0,t]× B) is the random measure #{s ∈ (0,t] : Xs(ω)− Xs−(ω) ∈ B} counting the
jumps of X; it is a Poisson random variable with intensity EN((0,t]×B) = tν(B) for all Borel sets
B ⊂ Rd \{0} such that 0 /∈ B.

Nowadays there are at least six possible approaches to constructing processes with (stationary

and) independent increments X = (Xt)t(cid:62)0.

The de Finetti–Lévy(–Kolmogorov–Khintchine) construction. The starting point is the
observation that each Xt satisﬁes (1.1) and is, therefore, inﬁnitely divisible. Thus, the character-
istic exponent log Eeiξ·Xt is given by the Lévy–Khintchine formula (1.3), and using the triplet
√
(l,Q,ν) one can construct a drift lt, a Brownian motion
QWt and compound Poisson processes,
i.e. Poisson processes whose intensities y ∈ Rd are mixed with respect to the ﬁnite measure
νε (dy) := 1[ε,∞)(|y|)ν(dy). Using a suitable compensation (in the spirit of Kolmogorov’s three
series theorem) of the small jumps, it is possible to show that the limit ε → 0 exists locally uni-
formly in t. A very clear presentation of this approach can be found in Breiman [10, Chapter
14.7–8], see also Chapter 7.

The Lévy–Itô construction. This is currently the most popular approach to independent-in-
crement processes, see e.g. Applebaum [2, Chapter 2.3–4] or Kyprianou [35, Chapter 2]. Origi-
nally the idea is due to Lévy [36], but Itô [23] gave the ﬁrst rigorous construction. It is based on
the observation that the jumps of a process with stationary and independent increments deﬁne a
Poisson random measure Nω ([0,t]×B) and this can be used to obtain the Lévy–Itô decomposition
(1.5). The Lévy–Khintchine formula is then a corollary of the pathwise decomposition. Some of
the best presentations can be found in Gikhman–Skorokhod [18, Chapter VI], Itô [24, Chapter 4.3]
and Bretagnolle [11]. A proof based on additive functionals and martingale stochastic integrals is
due to Kunita & Watanabe [34, Section 7]. We follow this approach in Chapter 9.

Variants of the Lévy–Itô construction. The Lévy–Itô decomposition (1.5) is, in fact, the
semimartingale decomposition of a process with stationary and independent increments. Using the
general theory of semimartingales – which heavily relies on general random measures – we can
identify processes with independent increments as those semimartingales whose semimartingale
characteristics are deterministic, cf. Jacod & Shiryaev [27, Chapter II.4c]. A further interesting
derivation of the Lévy–Itô decomposition is based on stochastic integrals driven by martingales.
The key is Itô’s formula and, again, the fact that the jumps of a process with stationary and in-
dependent increments deﬁnes a Poisson point process which can be used as a good stochastic

10

R. L. Schilling: An Introduction to Lévy and Feller Processes

integrator; this unique approach1 can be found in Kunita [33, Chapter 2].

Kolmogorov’s construction. This is the classic construction of stochastic processes starting
from the ﬁnite-dimensional distributions. For a process with stationary and independent incre-
ments these are given as iterated convolutions of the form

E f (Xt0, . . . ,Xtn)

(cid:90)

(cid:90)
···

=

with pt(dy) = P(Xt ∈ dy) or(cid:82) eiξ·y pt(dy) = exp [−tψ(ξ )] where ψ is the characteristic exponent

f (y0,y0 + y1, . . . ,y0 +··· + yn) pt0(dy0)pt1−t0(dy1) . . . ptn−tn−1(dyn)

(1.3). Particularly nice presentations are those of Sato [50, Chapter 2.10–11] and Bauer [5, Chapter
37].

The invariance principle.
Just as for a Brownian motion, it is possible to construct Lévy
processes as limits of (suitably interpolated) random walks. For ﬁnite dimensional distributions
this is done in Gikhman & Skorokhod [18, Chapter IX.6]; for the whole trajectory, i.e. in the
space of càdlàg2 functions D[0,1] equipped with the Skorokhod topology, the proper references
are Prokhorov [41] and Grimvall [19].

Random series constructions. A series representation of an independent-increment pro-
cess (Xt)t∈[0,1] is an expression of the form
n

(cid:0)Jk1[0,t](Uk)−tck

(cid:1)

a.s.

Xt = lim
n→∞

∑

k=1

The random variables Jk represent the jumps, Uk are iid uniform random variables and ck are
suitable deterministic centering terms. Compared with the Lévy–Itô decomposition (1.4), the
main difference is the fact that the jumps are summed over a deterministic index set {1,2, . . .n}
while the summation in (1.4) extends over the random set {s : |∆Xs| > 1/n}. In order to construct
a process with characteristic exponent (1.3) where l = 0 and Q = 0, one considers a disintegration

(cid:90) ∞

0

ν(dy) =

σ (r,dy)dr.

It is possible, cf. Rosi´nski [46], to choose σ (r,dy) = P(H(r,Vk) ∈ dy) where V = (Vk)k∈N is any
sequence of d-dimensional iid random variables and H : (0,∞)× Rd → Rd is measurable. Now
let Γ = (Γk)k∈N be a sequence of partial sums of iid standard exponential random variables and
U = (Uk)k∈N iid uniform random variables on [0,1] such that U,V,Γ are independent. Then

(cid:90) k

(cid:90)

Jk := H(Γk,Vk)

and ck =

yσ (r,dy)dr

k−1

|y|<1

1It reminds of the elegant use of Itô’s formula in Kunita-and-Watanabe’s proof of Lévy’s characterization of Brow-

nian motion, see e.g. Schilling & Partzsch [55, Chapter 18.2].

2A french acronym meaning ‘right-continuous and ﬁnite limits from the left’.

Chapter 1: Orientation

11

is the sought-for series representation, cf. Rosi´nski [46] and [45]. This approach is important if
one wants to simulate independent-increment processes. Moreover, it still holds for Banach space
valued random variables.

2. Lévy processes

Throughout this chapter, (Ω, A , P) is a ﬁxed probability space, t0 = 0 (cid:54) t1 (cid:54) . . . (cid:54) tn and 0 (cid:54) s < t
are positive real numbers, and ξk,ηk, k = 1, . . . ,n, denote vectors from Rd; we write ξ · η for the
Euclidean scalar product.
Deﬁnition 2.1. A Lévy process X = (Xt)t(cid:62)0 is a stochastic process Xt : Ω → Rd satisfying (L0)–
(L3); this is to say that X starts at zero, has stationary and independent increments and is continu-
ous in probability.

One should understand Lévy processes as continuous-time versions of sums of iid random vari-

ables. This can easily be seen from the telescopic sum

(cid:0)Xtk − Xtk−1

(cid:1),

Xt − Xs =

n

∑

k=1

s < t, n ∈ N,

(2.1)

n (t − s). Since the increments Xtk − Xtk−1 are iid random variables, we see that all
where tk = s + k
Xt of a Lévy process are inﬁnitely divisible, i.e. (1.2) holds. Many properties of a Lévy process
will, therefore, resemble those of sums of iid random variables.

Let us brieﬂy discuss the conditions (L0)–(L3).

Remark 2.2. We have stated (L2) using the canonical ﬁltration F X
t
X. Often this condition is written in the following way

:= σ (Xr, r (cid:54) t) of the process

Xtn − Xtn−1, . . . ,Xt1 − Xt0

are independent random variables

for all n ∈ N, t0 = 0 < t1 < ··· < tn.

It is easy to see that this is actually equivalent to (L2): From

it follows that

(Xt1, . . . ,Xtn)

bi-measurable

←−−−−−−−→ (Xt1 − Xt0, . . . ,Xtn − Xtn−1)

F X

t = σ(cid:0)(Xt1, . . . ,Xtn), 0 (cid:54) t1 (cid:54) . . . (cid:54) tn (cid:54) t(cid:1)
= σ(cid:0)(Xt1 − Xt0, . . . ,Xtn − Xtn−1), 0 = t0 (cid:54) t1 (cid:54) . . . (cid:54) tn (cid:54) t(cid:1)
= σ(cid:0)Xu − Xv, 0 (cid:54) v (cid:54) u (cid:54) t(cid:1),

and we conclude that (L2) and (L2(cid:48)) are indeed equivalent.
The condition (L3) is equivalent to either of the following

12

(L2(cid:48))

(2.2)

Chapter 2: Lévy processes

13

• ‘t (cid:55)→ Xt is continuous in probability’;
• ‘t (cid:55)→ Xt is a.s. càdlàg’1 (up to a modiﬁcation of the process).

The equivalence with the ﬁrst claim, and the direction ‘⇐’ of the second claim are easy:

lim
u→t

P(|Xu − Xt| > ε) = lim|t−u|→0

P(|X|t−u|| > ε) (cid:54) lim
h→0

E(|Xh|∧ ε),

1
ε

(2.3)

but it takes more effort to show that continuity in probatility (L3) guarantees that almost all paths
are càdlàg.2 Usually, this is proved by controlling the oscillations of the paths of a Lévy process,
cf. Sato [50, Theorem 11.1], or by the fundamental regularization theorem for submartingales, see
Revuz & Yor [43, Theorem II.(2.5)] and Remark 11.2; in contrast to the general martingale setting
[43, Theorem II.(2.9)], we do not need to augment the natural ﬁltration because of (L1) and (L3).
Since our construction of Lévy processes gives directly a càdlàg version, we do not go into further
detail.

The condition (L3) has another consequence. Recall that the Cauchy–Abel functional equa-

tions have unique solutions if, say, φ, ψ and θ are (right-)continuous:

φ (s +t) = φ (s)· φ (t)
ψ(s +t) = ψ(s) + ψ(t)
θ (st) = θ (s)· θ (t)

(s,t (cid:62) 0)

φ (t) = φ (1)t,
=⇒ ψ(t) = ψ(1)·t

θ (t) = tc, c (cid:62) 0.

(2.4)

The ﬁrst equation is treated in Theorem A.1 in the appendix. For a thorough discussion on condi-
tions ensuring uniqueness we refer to Aczel [1, Chapter 2.1].

Proposition 2.3. Let (Xt)t(cid:62)0 be a Lévy process in Rd. Then

Eeiξ·Xt =(cid:2)Eeiξ·X1(cid:3)t

t (cid:62) 0, ξ ∈ Rd.

,

(2.5)

Proof. Fix s,t (cid:62) 0. We get

Eeiξ·(Xt+s−Xs)+iξ·Xs (L2)

= Eeiξ·(Xt+s−Xs) Eeiξ·Xs (L1)

= Eeiξ·Xt Eeiξ·Xs,

or φ (t + s) = φ (t)· φ (s), if we write φ (t) = Eeiξ·Xt . Since x (cid:55)→ eiξ·x is continuous, there is for
every ε > 0 some δ > 0 such that

|φ (t)− φ (s)| (cid:54) E(cid:12)(cid:12)eiξ·(Xt−Xs) − 1(cid:12)(cid:12) (cid:54) ε + 2P(|Xt − Xs| (cid:62) δ ) = ε + 2P(|X|t−s|| (cid:62) δ ).

Thus, (L3) guarantees that t (cid:55)→ φ (t) is continuous, and the claim follows from (2.4).

Notice that any solution f (t) of (2.4) also satisﬁes (L0)–(L2); by Proposition 2.3 Xt + f (t)
is a Lévy process if, and only if, f (t) is continuous. On the other hand, Hamel, cf. [1, p. 35],
constructed discontinuous (non-measurable and locally unbounded) solutions to (2.4). Thus, (L3)
means that t (cid:55)→ Xt has no ﬁxed discontinuities, i.e. all jumps occur at random times.

1‘Right-continuous and ﬁnite limits from the left’
2More precisely: that there exists a modiﬁcation of X which has almost surely càdlàg paths.

14

R. L. Schilling: An Introduction to Lévy and Feller Processes

Corollary 2.4. The ﬁnite-dimensional distributions P(Xt1 ∈ dx1, . . . ,Xtn ∈ dxn) of a Lévy process
are uniquely determined by

(cid:33)

(cid:104)

(cid:105)tk−tk−1

Eexp

i

ξk · Xtk

n

∑

k=1

=

n

∏

k=1

Eexp (i(ξk +··· + ξn)· X1)

(2.6)

for all ξ1, . . . ,ξn ∈ Rd, n ∈ N and 0 = t0 (cid:54) t1 (cid:54) . . . (cid:54) tn.

(cid:32)

(cid:33)

Proof. The left-hand side of (2.6) is just the characteristic function of (Xt1, . . . ,Xtn). Consequently,
the assertion follows from (2.6). Using Proposition 2.3, we have

(cid:32)

Eexp

i

= Eexp

i

ξk · Xtk

n

∑

k=1

(cid:33)
ξk · Xtk + i(ξn + ξn−1)· Xtn−1 + iξn · (Xtn − Xtn−1)

(cid:33)(cid:0)Eeiξn·X1(cid:1)tn−tn−1.

(cid:32)
(cid:32)

n−2
∑
k=1
n−2
∑

k=1

(L2)
=
(L1)

Eexp

i

ξk · Xtk + i(ξn + ξn−1)· Xtn−1

Since the ﬁrst half of the right-hand side has the same structure as the original expression, we can
iterate this calculation and obtain (2.6).

It is not hard to invert the Fourier transform in (2.6). Writing pt(dx) := P(Xt ∈ dx) we get

P(Xt1 ∈ B1, . . . ,Xtn ∈ Bn) =

=

1Bk (x1 +··· + xk)ptk−tk−1(dxk)

1Bk (yk)ptk−tk−1(dyk − yk−1).

(2.7)

(2.8)

(cid:90)
(cid:90)

(cid:90) n
∏
(cid:90) n
∏

k=1

k=1

···

···

Let us discuss the structure of the characteristic function χ(ξ ) = Eeiξ·X1 of X1. From (2.1)
we see that each random variable Xt of a Lévy process is inﬁnitely divisible. Clearly, |χ(ξ )|2 is
1 is an independent

the (real-valued) characteristic function of the symmetrization(cid:101)X1 = X1 − X(cid:48)
copy of X1) and (cid:101)X1 is again inﬁnitely divisible:
1 (X(cid:48)
(cid:105)
∑

−(cid:101)X k−1

(cid:101)X1 =

In particular, |χ|2 = |χ1/n|2n where |χ1/n|2 is the characteristic function of (cid:101)X1/n. Since everything

k=1

k=1

− X(cid:48)
k−1
n

((cid:101)X k

)− (X(cid:48)

− X k−1

n

∑

(X k
n

(cid:104)

) =

n

n

)

.

n

n

k
n

is real and |χ(ξ )| (cid:54) 1, we get

θ (ξ ) := lim
n→∞

|χ1/n(ξ )|2 = lim
n→∞

|χ(ξ )|2/n,

ξ ∈ Rd,

which is 0 or 1 depending on |χ(ξ )| = 0 or |χ(ξ )| > 0, respectively. As χ(ξ ) is continuous at
ξ = 0 with χ(0) = 1, we have θ ≡ 1 in a neighbourhood Br(0) of 0. Now we can use Lévy’s
continuity theorem (Theorem A.5) and conclude that the limiting function θ (ξ ) is continuous
everywhere, hence θ ≡ 1. In particular, χ(ξ ) has no zeroes.

Chapter 2: Lévy processes

15

Corollary 2.5. Let (Xt)t(cid:62)0 be a Lévy process in Rd. There exists a unique continuous function
ψ : Rd → C such that

Eexp(iξ · Xt) = e−tψ(ξ ),
The function ψ is called the characteristic exponent.
Proof. In view of Proposition 2.3 it is enough to consider t = 1. Set χ(ξ ) := Eexp(iξ · X1). An
obvious candidate for the exponent is ψ(ξ ) = −log χ(ξ ), but with complex logarithms there is
always the trouble which branch of the logarithm one should take. Let us begin with the unique-
ness:

t (cid:62) 0, ξ ∈ Rd.

e−ψ = e−φ =⇒ e−(ψ−φ ) = 1 =⇒ ψ(ξ )− φ (ξ ) = 2π ikξ

for some integer kξ ∈ Z. Since φ ,ψ are continuous and φ (0) = ψ(0) = 1, we get kξ ≡ 0.

To prove the existence of the logarithm, it is not sufﬁcient to take the principal branch of the
logarithm. As we have seen above, χ(ξ ) is continuous and has no zeroes, i.e. inf|ξ|(cid:54)r |χ(ξ )| > 0
for any r > 0; therefore, there is a ‘distinguished’, continuous3 version of the argument arg◦ χ(ξ )
such that arg◦ χ(0) = 0.

This allows us to take a continuous version of log χ(ξ ) = log|χ(ξ )| + arg◦ χ(ξ ).

Corollary 2.6. Let Y be an inﬁnitely divisible random variable. Then there exists at most one4
Lévy process (Xt)t(cid:62)0 such that X1 ∼ Y .
Proof. Since X1 ∼ Y , inﬁnite divisibility is a necessary requirement for Y . On the other hand,
Proposition 2.3 and Corollary 2.4 show how to construct the ﬁnite-dimensional distributions of a
Lévy process, hence the process, from X1.

So far, we have seen the following one-to-one correspondences

(Xt)t(cid:62)0 Lévy process 1:1←→ Eeiξ·X1 1:1←→ ψ(ξ ) = −log Eeiξ·X1

and the next step is to ﬁnd all possible characteristic exponents. This will lead us to the Lévy–
Khintchine formula.

3A very detailed argument is given in Sato [50, Lemma 7.6], a completely different proof can be found in Dieudonné

[16, Chapter IX, Appendix 2].

4We will see in Chapter 7 how to construct this process.

distributions are uniquely determined by Y .

It is unique in the sense that its ﬁnite-dimensional

3. Examples

We begin with a useful alternative characterisation of Lévy processes.

Theorem 3.1. Let X = (Xt)t(cid:62)0 be a stochastic process with values in Rd, P(X0 = 0) = 1 and
t = σ (Xr, r (cid:54) t). The process X is a Lévy process if, and only if, there exists an exponent
Ft = F X
ψ : Rd → C such that

= e−(t−s)ψ(ξ )

for all s < t, ξ ∈ Rd.

(3.1)

E

eiξ·(Xt−Xs)(cid:12)(cid:12)(cid:12) Fs
(cid:16)
(cid:17)
eiξ·(Xt−Xs)(cid:12)(cid:12)(cid:12) Fs
(cid:16)
(cid:17) (L2)

E

Proof. If X is a Lévy process, we get

= Eeiξ·(Xt−Xs) (L1)

= Eeiξ·Xt−s Cor. 2.5

= e−(t−s)ψ(ξ ).

Conversely, assume that X0 = 0 a.s. and (3.1) holds. Then

Eeiξ·(Xt−Xs) = e−(t−s)ψ(ξ ) = Eeiξ·(Xt−s−X0)

which shows Xt − Xs ∼ Xt−s − X0 = Xt−s, i.e. (L1).

For any F ∈ Fs we ﬁnd from the tower property of conditional expectation

E

(cid:16)
1F · eiξ·(Xt−Xs)(cid:17)
(cid:16)
eiu1F eiξ·(Xt−Xs)(cid:17)

E

= E

(cid:105)(cid:17)

(cid:16)

1F E

eiξ·(Xt−Xs)(cid:12)(cid:12)(cid:12) Fs
(cid:104)
(cid:16)
1Fceiξ·(Xt−Xs)(cid:17)
= E(cid:0)1Fc + eiu1F

= E

(3.2)

(cid:16)
1Feiueiξ·(Xt−Xs)(cid:17)
(cid:1)e−(t−s)ψ(ξ )

+ E

Observe that eiu1F = 1Fc + eiu1F for any u ∈ R; since both F and Fc are in Fs, we get

= E1F · e−(t−s)ψ(ξ ).

(3.2)

= Eeiu1F Eeiξ·(Xt−Xs).
(3.2)

Thus, 1F ⊥⊥(Xt − Xs) for any F ∈ Fs, and (L2) follows.

Finally, limt→0 Eeiξ·Xt = limt→0 e−tψ(ξ ) = 1 proves that Xt → 0 in distribution, hence in proba-

bility. This gives (L3).

Theorem 3.1 allows us to give concrete examples of Lévy processes.

Example 3.2. The following processes are Lévy processes.
a) Drift in direction l/|l|, l ∈ Rd, with speed |l|: Xt = tl and ψ(ξ ) = −il · ξ .

16

Chapter 3: Examples

17

b) Brownian motion with (positive semi-deﬁnite) covariance matrix Q ∈ Rd×d: Let (Wt)t(cid:62)0 be a
standard Wiener process on Rd and set Xt :=
Then ψ(ξ ) = 1

2ξ · Qξ and P(Xt ∈ dy) = (2πt)−d/2(detQ)−1/2 exp(−y· Q−1y/2t)dy.

√
QWt.

c) Poisson process in R with jump height 1 and intensity λ . This is an integer-valued counting
process (Nt)t(cid:62)0 which increases by 1 after an independent exponential waiting time with mean λ .
Thus,

Nt =

∞
∑

k=1

1[0,t](τk),

τk = σ1 +··· + σk, σk ∼ Exp(λ ) iid.

Using this deﬁnition, it is a bit messy to show that N is indeed a Lévy process (see e.g. Çinlar [12,
Chapter 4]). We will give a different proof in Theorem 3.4 below. Usually, the ﬁrst step is to show
that its law is a Poisson distribution

P(Nt = k) = e−tλ (λt)k
k!

,

k = 0,1,2, . . .

(thus the name!) and from this one can calculate the characteristic exponent

= e−tλ exp(cid:2)λteiu(cid:3) = exp(cid:2)−tλ (1− eiu)(cid:3),

EeiuNt =

∞
∑

k=0

eiuke−tλ (λt)k
k!

i.e. ψ(u) = λ (1− eiu). Mind that this is strictly weaker than (3.1) and does not prove that N is a
Lévy process.

d) Compound Poisson process in Rd with jump distribution µ and intensity λ . Let N = (Nt)t(cid:62)0
be a Poisson process with intensity λ and replace the jumps of size 1 by independent iid jumps of
random height H1,H2, . . . with values in Rd and H1 ∼ µ. This is a compound Poisson process:

Ct =

Nt∑

k=1

Hk, Hk ∼ µ iid and independent of (Nt)t(cid:62)0.

We will see in Theorem 3.4 that compound Poisson processes are Lévy processes.

Let us show that the Poisson and compound Poisson processes are Lévy processes. For this we
need the following auxiliary result. Since t (cid:55)→ Ct is a step function, the Riemann–Stieltjes integral

(cid:82) f (u)dCu is well-deﬁned.

Lemma 3.3 (Campbell’s formula). Let Ct = H1 +··· + HNt be a compound Poisson process as in
Example 3.2.d) with iid jumps Hk ∼ µ and an independent Poisson process (Nt)t(cid:62)0 with intensity
λ . Then

(cid:19)

Eexp

i

f (t + s)dCt

= exp

λ

(eiy f (s+t) − 1) µ(dy)dt

(3.3)

(cid:18)

(cid:90) ∞

0

(cid:19)

(cid:18)

(cid:90) ∞
(cid:90)

0

y(cid:54)=0

holds for all s (cid:62) 0 and bounded measurable functions f : [0,∞) → Rd with compact support.

18

R. L. Schilling: An Introduction to Lévy and Feller Processes

Proof. Set τk = σ1 +··· + σk where σk ∼ Exp(λ ) are iid. Then

φ (s) :=Eexp

f (s +t)dCt

(cid:19)

(cid:33)

(cid:18)
(cid:32)

i

i

(cid:90) ∞

0
∞
(cid:32)
∑

(cid:33)
(cid:125)

(cid:124)

f (s + σ1 +··· + σk)Hk

=Eexp

iid
=

0

i

k=1

∞
∑

Eexp

(cid:90) ∞
(cid:124)
(cid:90) ∞
=φ (s+x)
(cid:90) ∞
φ (s + x)γ(s + x)e−λ x dx

(cid:123)(cid:122)

k=2

γ(t)φ (t)e−λt dt.

=λ

0
=λ eλ s

s

(cid:90) ∞

s

f (s + x + σ2 +··· + σk)Hk

Eexp(i f (s + x)H1)

P(σ1 ∈ dx)

(cid:123)(cid:122)

(cid:125)

(cid:124)

(cid:123)(cid:122)

(cid:125)

=:γ(s+x)

=λ e−λ x dx

This is equivalent to

e−λ sφ (s) = λ

(φ (t)e−λt)γ(t)dt

and φ (∞) = 1 since f has compact support. This integral equation has a unique solution; it is now
a routine exercise to verify that the right-hand side of (3.3) is indeed a solution.
Theorem 3.4. Let Ct = H1 +··· + HNt be a compound Poisson process as in Example 3.2.d) with
iid jumps Hk ∼ µ and an independent Poisson process (Nt)t(cid:62)0 with intensity λ . Then (Ct)t(cid:62)0 (and
also (Nt)t(cid:62)0) is a d-dimensional Lévy process with characteristic exponent

ψ(ξ ) = λ

(3.4)
Proof. Since the trajectories of t (cid:55)→ Ct are càdlàg step functions with C0 = 0, the properties (L0)
and (L3), see (2.3), are satisﬁed. We will show (L1) and (L2). Let ξk ∈ Rd, 0 = t0 (cid:54) . . . (cid:54) tn, and
a < b. Then the Riemann–Stieltjes integral

y(cid:54)=0

(1− eiy·ξ ) µ(dy).

(cid:90)

(cid:90) ∞

0

1(a,b](t)dCt =

∞
∑

k=1

1(a,b](τk)Hk = Cb −Ca

exists. We apply the Campbell formula (3.3) to the function

and with s = 0. Then the left-hand side of (3.3) becomes the characteristic function of the incre-
ments

while the right-hand side is equal to

(cid:34)

(cid:90)

exp

λ

(cid:90) tk

tk−1

n

∑

k=1

y(cid:54)=0

(eiξk·y − 1)dt µ(dy)

(cid:21)

(eiξk·y − 1) µ(dy)

f (t) :=

ξk1(tk−1,tk](t)

n

∑

k=1

(cid:32)

Eexp

i

k=1

,

n

(cid:33)
ξk · (Ctk −Ctk−1)
∑
(cid:35)
(cid:20)
(cid:90)
Eexp(cid:2)iξk ·Ctk−tk−1

λ (tk −tk−1)

∏

exp

k=1

=

=

∏

n

n

k=1

y(cid:54)=0

(cid:3)

Chapter 3: Examples

19

(use Campbell’s formula with n = 1 for the last equality). This shows that the increments are
independent, i.e. (L2(cid:48)) holds, as well as (L1): Ctk −Ctk−1 ∼ Ctk−tk−1.

If d = 1 and Hk ∼ δ1, Ct is a Poisson process.

Denote by µ∗k the k-fold convolution of the measure µ; as usual, µ∗0 := δ0.

Corollary 3.5. Let (Nt)t(cid:62)0 be a Poisson process with intensity λ and Ct = H1 +··· + HNt a com-
pound Poisson process with iid jumps Hk ∼ µ. Then, for all t (cid:62) 0,

P(Nt = k) = e−λt (λt)k
k!
∞
P(Ct ∈ B) = e−λt
∑

,

(λt)k
k!

k=0

k = 0,1,2, . . .
µ∗k(B), B ⊂ Rd Borel.

(3.5)

(3.6)

Proof. If we use Theorem 3.4 for d = 1 and µ = δ1, we see that the characteristic function of Nt is
χt(u) = exp[−λt(1− eiu)]. Since this is also the characteristic function of the Poisson distribution
(i.e. the r.h.s. of (3.5)), we get Nt ∼ Poi(λt).

Since (Hk)k∈N⊥⊥(Nt)t(cid:62)0, we have for any Borel set B

P(Ct ∈ B) =

∞
∑

k=0

P(Ct ∈ B, Nt = k)
∞
∑

= δ0(B)P(Nt = 0) +

= e−λt

∞
∑

k=0

(λt)k
k!

k=1
µ∗k(B).

P(H1 +··· + Hk ∈ B)P(Nt = k)

Example 3.2 contains the basic Lévy processes which will also be the building blocks for all
Lévy processes. In order to deﬁne more specialized Lévy processes, we need further assumptions
on the distributions of the random variables Xt.

Deﬁnition 3.6. Let (Xt)t(cid:62)0 be a stochastically continuous process in Rd. It is called self-similar,
if

∀a (cid:62) 0 ∃b = b(a) : (Xat)t(cid:62)0 ∼ (bXt)t(cid:62)0

(3.7)

in the sense that both sides have the same ﬁnite-dimensional distributions.

Lemma 3.7 (Lamperti). If (Xt)t(cid:62)0 is self-similar and non-degenerate, then there exists a unique
index of self-similarity H (cid:62) 0 such that b(a) = aH. If (Xt)t(cid:62)0 is a self-similar Lévy process, then
H (cid:62) 1
2.
Proof. Since (Xt)t(cid:62)0 is self-similar, we ﬁnd for a,a(cid:48) (cid:62) 0 and each t > 0
b(aa(cid:48))Xt ∼ Xaa(cid:48)t ∼ b(a)Xa(cid:48)t ∼ b(a)b(a(cid:48))Xt,

20

R. L. Schilling: An Introduction to Lévy and Feller Processes

and so b(aa(cid:48)) = b(a)b(a(cid:48)) as Xt is non-degenerate.1 By the convergence of types theorem (Theo-
rem A.6) and the continuity in probability of t (cid:55)→ Xt we see that a (cid:55)→ b(a) is continuous. Thus, the
Cauchy functional equation b(aa(cid:48)) = b(a)b(a(cid:48)) has the unique continuous solution b(a) = aH for
some H (cid:62) 0.

Assume now that (Xt)t(cid:62)0 is a Lévy process. We are going to show that H (cid:62) 1

2. Using self-
similarity and the properties (L1), (L2) we get (primes always denote iid copies of the respective
random variables)

(n + m)HX1 ∼ Xn+m = (Xn+m − Xm) + Xm ∼ X(cid:48)(cid:48)

n + X(cid:48)

m ∼ nHX(cid:48)(cid:48)

1 + mHX(cid:48)
1.

(3.8)

Any standard normal random variable X1 satisﬁes (3.8) with H = 1
a second moment, we get (n + m)VX1 = VXn+m = VX(cid:48)(cid:48)
identity for variances, i.e. (3.8) can only hold with H = 1
second moment has to satisfy (3.8) with H = 1
of a second moment, we have reached a contradiction.

n + VX(cid:48)

1 + mVX(cid:48)

m = nVX(cid:48)(cid:48)

2. On the other hand, if X1 has
1 by Bienaymés
2. Thus, any self-similar X1 with ﬁnite
2 implies the existence

2. If we can show that H < 1

If Xn is symmetric and H < 1

2, we ﬁnd because of Xn ∼ nHX1 some u > 0 such that
P(|Xn| > unH) = P(|X1| > u) <

.

1
4

By the symmetrization inequality (Theorem A.7),

1
2

(cid:0)1− exp{−nP(|X1| > unH)}(cid:1) (cid:54) P(|Xn| > unH) <
(cid:90) ∞

x P(|X1| > x)dx (cid:54) 2(u + 1) + 2c(cid:48)(cid:90) ∞

1
4

E|X1|2 = 2

0

which means that nP(|X1| > unH) (cid:54) c for all n ∈ N. Thus, P(|X1| > x) (cid:54) c(cid:48)x−1/H for all x > u +1,
and so

u+1

x1−1/H dx < ∞
n where X(cid:48)

2. If Xn is not symmetric, we use its symmetrization Xn − X(cid:48)

n are iid copies of

as H < 1
Xn.

Deﬁnition 3.8. A random variable X is called stable if
∀n ∈ N ∃bn (cid:62) 0, cn ∈ Rd : X(cid:48)

1 +··· + X(cid:48)

n ∼ bnX + cn

(3.9)

1, . . . ,X(cid:48)

where X(cid:48)
n are iid copies of X. If (3.9) holds with cn = 0, the random variable is called
strictly stable. A Lévy process (Xt)t(cid:62)0 is (strictly) stable if X1 is a (strictly) stable random variable.

1We use here that bX ∼ cX =⇒ b = c if X is non-degenerate. To see this, set χ(ξ ) = Eeiξ·X and notice

|χ(ξ )| =(cid:12)(cid:12)χ(cid:0) b

c ξ(cid:1)(cid:12)(cid:12) = ··· =(cid:12)(cid:12)χ(cid:0)(cid:0) b

c

(cid:1)nξ(cid:1)(cid:12)(cid:12).

If b < c, the right-hand side converges for n → ∞ to χ(0) = 1, hence |χ| ≡ 1, contradicting the fact that X is non-
degenerate. Since b,c play symmetric roles, we conclude that b = c.

Chapter 3: Examples

21

Note that the symmetrization X − X(cid:48) of a stable random variable is strictly stable. Setting

χ(ξ ) = Eeiξ·X it is easy to see that (3.9) is equivalent to

∀n ∈ N ∃bn (cid:62) 0, cn ∈ Rd : χ(ξ )n = χ(bnξ )eicn·ξ .

(3.9(cid:48))

Example 3.9. a) Stable processes. By deﬁnition, any stable random variable is inﬁnitely divisible,
and for every stable X there is a unique Lévy process on Rd such that X1 ∼ X, cf. Corollary 2.6.
A Lévy process (Xt)t(cid:62)0 is stable if, and only if, all random variables Xt are stable. This follows

at once from (3.9(cid:48)) if we use χt(ξ ) := Eeiξ·Xt :

= (cid:0)χ1(ξ )n(cid:1)t (3.9(cid:48))

χt(ξ )n (2.5)

= χ1(bnξ )tei(tcn)·ξ (2.5)

= χt(bnξ )ei(tcn)·ξ .

It is possible to determine the characteristic exponent of a stable process, cf. Sato [50, Theorem
14.10] and (3.10) further down.

b) Self-similar processes. Assume that (Xt)t(cid:62)0 is a self-similar Lévy process. Then

∀n ∈ N : b(n)X1 ∼ Xn =

(Xk − Xk−1) ∼ X(cid:48)

1,n +··· + X(cid:48)

n,n

n

∑

k=1

where the X(cid:48)
converse is also true:

k,n are iid copies of X1. This shows that X1, hence (Xt)t(cid:62)0, is strictly stable. In fact, the

c) A strictly stable Lévy process is self-similar. We have already seen in b) that self-similar
Lévy processes are strictly stable. Assume now that (Xt)t(cid:62)0 is strictly stable. Since Xnt ∼ bnXt we
get

e−ntψ(ξ ) = Eeiξ·Xnt = Eeibnξ·Xt = e−tψ(bnξ ).

Taking n = m, t (cid:32) t/m and ξ (cid:32) b−1

m ξ we see

e− t

m ψ(ξ ) = e−tψ(b−1

m ξ ).

From these equalities we obtain for q = n/m ∈ Q+ and b(q) := bn/bm

e−qtψ(ξ ) = e−tψ(b(q)ξ ) =⇒ Xqt ∼ b(q)Xt =⇒ Xat ∼ b(a)Xt

for all t (cid:62) 0 because of the continuity in probability of (Xt)t(cid:62)0. Since, by Corollary 2.4, the ﬁnite-
dimensional distributions are determined by the one-dimensional distributions, we conclude that
(3.7) holds.

This means, in particular, that strictly stable Lévy processes have an index of self-similarity
2. It is common to call α = 1/H ∈ (0,2] the index of stability of (Xt)t(cid:62)0, and we have

H (cid:62) 1
Xnt ∼ n1/αXt.

If X is ‘only’ stable, its symmetrization is strictly stable and, thus, every stable Lévy process
has an index α ∈ (0,2]. It plays an important role for the characteristic exponent. For a general

22

R. L. Schilling: An Introduction to Lévy and Feller Processes

stable process the characteristic exponent is of the form

(cid:90)
(cid:90)



Sd

Sd

|z· ξ|α(cid:0)1− isgn(z· ξ )tan απ
|z· ξ|(cid:0)1 + 2

(cid:1)σ (dz)− i µ · ξ ,
π isgn(z· ξ )log|z· ξ|(cid:1)σ (dz)− i µ · ξ ,

2

ψ(ξ ) =

(α (cid:54)= 1),

(α = 1),

(3.10)

and (cid:82)

where σ is a ﬁnite measure on Sd and µ ∈ Rd. The strictly stable exponents have µ = 0 (if α (cid:54)= 1)
Sd zk σ (dz) = 0, k = 1, . . . ,d (if α = 1). These formulae can be derived from the general
Lévy–Khintchine formula; a good reference is the monograph by Samorodnitsky & Taqqu [47,
Chapters 2.3–4].

ψ(ξ ) = c|ξ|α. If Xt is symmetric, i.e. Xt ∼ −Xt, then ψ(ξ ) =(cid:82)

If X is strictly stable such that the distribution of Xt is rotationally invariant, it is clear that
Sd |z· ξ|α σ (dz) for some ﬁnite,

symmetric measure σ on the unit sphere Sd ⊂ Rd.

Let us ﬁnally show Kolmogorov’s proof of the Lévy–Khintchine formula for one-dimensional

Lévy processes admitting second moments. We need the following auxiliary result.

Lemma 3.10. Let (Xt)t(cid:62)0 be a Lévy process on R. If VX1 < ∞, then VXt < ∞ for all t > 0 and

EXt = tEX1 =: tµ and VXt = tVX1 =: tσ 2.
Proof. If VX1 < ∞, then E|X1| < ∞. With Bienaymé’s identity, we get

VXm =

m

∑

k=1

V(Xk − Xk−1) = mVX1

and VX1 = nVX1/n.

In particular, VXm, VX1/n < ∞. This, and a similar argument for the expectation, show

VXq = qVX1

and EXq = qEX1

for all q ∈ Q+.

Moreover, V(Xq − Xr) = VXq−r = (q− r)VX1 for all rational numbers r (cid:54) q, and this shows that
Xq − EXq = Xq − qµ converges in L2 as q → t. Since t (cid:55)→ Xt is continuous in probability, we can
identify the limit and ﬁnd Xq − qµ → Xt −tµ. Consequenctly, VXt = tσ 2 and EXt = tµ.

We have seen in Proposition 2.3 that the characteristic function of a Lévy process is of the form

χt(ξ ) = Eeiξ Xt =(cid:2)Eeiξ X1(cid:3)t

= χ1(ξ )t.

Let us assume that X is real-valued and has ﬁnite (ﬁrst and) second moments VX1 = σ 2 and
EX1 = µ. By Taylor’s formula

Eeiξ (Xt−tµ) = E

ξ 2(Xt −tµ)2 (1− θ )eiθξ (Xt−tµ) dθ

(cid:20)

(cid:90) 1
1 + iξ (Xt −tµ)−
(cid:90) 1

(cid:20)

ξ 2(Xt −tµ)2

0

0

= 1− E

(cid:21)

(1− θ )eiθξ (Xt−tµ) dθ

.

(cid:21)

Thus, χ1/n(ξ ) (cid:54)= 0 if n (cid:62) N(ξ ) ∈ N is large, hence χ1(ξ ) = χ1/n(ξ )n (cid:54)= 0. For ξ ∈ R we ﬁnd
(using a suitable branch of the complex logarithm)

Since

we get

0

1
2

,

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90) 1

0

(1− θ )dθ =

(1− θ )eiθξ (Xt−tµ) dθ

(cid:12)(cid:12)(cid:12)(cid:12) (cid:54)(cid:90) 1
(cid:12)(cid:12)Eeiξ Xt(cid:12)(cid:12) =(cid:12)(cid:12)Eeiξ (Xt−tµ)(cid:12)(cid:12) (cid:62) 1− ξ 2
(cid:2)χ1(ξ )(cid:3)t(cid:12)(cid:12)(cid:12)(cid:12)t=0
ψ(ξ ) := −log χ1(ξ ) = − ∂
∂t
1− Eeiξ Xt
(cid:90) ∞
(cid:0)1− eiyξ + iyξ(cid:1) pt(dy)− iξ µ
(cid:90) ∞
−∞
1− eiyξ + iyξ

= lim
t→0

= lim
t→0

tσ 2.

2

1
t

t

πt(dy)− iξ µ

= lim
t→0

−∞

y2

Chapter 3: Examples

23

(3.11)

where pt(dy) = P(Xt ∈ dy) and πt(dy) := y2 t−1 pt(dy). Yet another application of Taylor’s theo-
rem shows that the integrand in the above integral is bounded, vanishes at inﬁnity, and admits a
continuous extension onto the whole real line if we choose the value 1
2 ξ 2 at y = 0. The family
(πt)t∈(0,1] is uniformly bounded,

(cid:90)

1
t

y2 pt(dy) =

1
t

E(X 2

t ) =

1
t

(cid:16)
VXt +(cid:2)EXt

(cid:3)2(cid:17)

= σ 2 +tµ2 t→0−−→ σ 2,

hence sequentially vaguely relatively compact (see Theorem A.3). We conclude that every se-
quence (πt(n))n∈N ⊂ (πt)t∈(0,1] with t(n) → 0 as n → ∞ has a vaguely convergent subsequence.
But since the limit (3.11) exists, all subsequential limits coincide which means2 that πt converges
vaguely to a ﬁnite measure π on R. This proves that

(cid:90) ∞

ψ(ξ ) = −log χ1(ξ ) =

1− eiyξ + iyξ

−∞

y2

π(dy)− iξ µ

for some ﬁnite measure π on (−∞,∞) with total mass π(R) = σ 2. This is sometimes called the de
0 := π{0}, we obtain
Finetti–Kolmogorov formula. If we set ν(dy) := y−21{y(cid:54)=0} π(dy) and σ 2
the Lévy–Khintchine formula

(cid:90)

(cid:0)1− eiyξ + iyξ(cid:1)ν(dy)

ψ(ξ ) = −i µξ +

1
2

σ 2
0 ξ 2 +

y(cid:54)=0

0 +(cid:82)

where σ 2 = σ 2

y(cid:54)=0 y2 ν(dy).

(cid:0)1− eiyξ + iyξ(cid:1)/y2, i.e. the kernel appearing in (3.11) is indeed measure-determining.

2Note that eiyξ = ∂ 2
ξ

4. On the Markov property

Let (Ω, A , P) be a probability space with some ﬁltration (Ft)t(cid:62)0 and a d-dimensional adapted
stochastic process X = (Xt)t(cid:62)0, i.e. each Xt is Ft measurable. We write B(Rd) for the Borel sets

and set F∞ := σ ((cid:83)

t(cid:62)0 Ft).

The process X is said to be a simple Markov process, if

P(Xt ∈ B | Fs) = P(Xt ∈ B | Xs),

s (cid:54) t, B ∈ B(Rd),

(4.1)

holds true. This is pretty much the most general deﬁnition of a Markov process, but it is usually
too general to work with. It is more convenient to consider Markov families.

Deﬁnition 4.1. A (temporally homogeneous) Markov transition function is a measure kernel
pt(x,B), t (cid:62) 0, x ∈ Rd, B ∈ B(Rd) such that

a) B (cid:55)→ ps(x,B) is a probability measure for every s (cid:62) 0 and x ∈ Rd;
b) (s,x) (cid:55)→ ps(x,B) is a Borel measurable function for every B ∈ B(Rd);

c) the Chapman–Kolmogorov equations hold

(cid:90)

ps+t(x,B) =

pt(y,B) ps(x,dy)

for all s,t (cid:62) 0, x ∈ Rd, B ∈ B(Rd).

(4.2)

Deﬁnition 4.2. A stochastic process (Xt)t(cid:62)0 is called a (temporally homogeneous) Markov pro-
cess with transition function if there exists a Markov transition function pt(x,B) such that

P(Xt ∈ B | Fs) = pt−s(Xs,B)

a.s. for all s (cid:54) t, B ∈ B(Rd).

(4.3)

Conditioning w.r.t. σ (Xs) and using the tower property of conditional expectation shows that
(4.3) implies the simple Markov property (4.1). Nowadays the following deﬁnition of a Markov
process is commonly used.
Deﬁnition 4.3. A (universal) Markov process is a tuple (Ω, A , Ft,Xt,t (cid:62) 0, Px,x ∈ Rd) such
that pt(x,B) = Px(Xt ∈ B) is a Markov transition function and (Xt)t(cid:62)0 is for each Px a Markov
process in the sense of Deﬁnition 4.2 such that Px(X0 = x) = 1. In particular,

Px(Xt ∈ B | Fs) = PXs(Xt−s ∈ B) Px-a.s. for all s (cid:54) t, B ∈ B(Rd).

(4.4)

24

Chapter 4: On the Markov property

25

We are going to show that a Lévy process is a (universal) Markov process. Assume that (Xt)t(cid:62)0

is a Lévy process and set Ft := F X

t = σ (Xr, r (cid:54) t). Deﬁne probability measures

where Γ is a Borel set of the path space (Rd)[0,∞) = {w | w : [0,∞) → Rd}.1 We set Ex :=(cid:82) . . .dPx.

Px(X• ∈ Γ) := P(X• + x ∈ Γ),

x ∈ Rd,

By construction, P = P0 and E = E0.

Note that X x
t

:= Xt + x satisﬁes the conditions (L1)–(L3), and it is common to call (X x

t )t(cid:62)0 a

Lévy process starting from x.

Lemma 4.4. Let (Xt)t(cid:62)0 be a Lévy process on Rd. Then
pt(x,B) := Px(Xt ∈ B) := P(Xt + x ∈ B),

t (cid:62) 0, x ∈ Rd, B ∈ B(Rd),

is a Markov transition function.
Proof. Since pt(x,B) = E1B(Xt + x) (the proof of) Fubini’s theorem shows that x (cid:55)→ pt(x,B) is
a measurable function and B (cid:55)→ pt(x,B) is a probability measure. The Chapman–Kolmogorov
equations follow from

ps+t(x,B) = P(Xs+t + x ∈ B) = P((Xs+t − Xt) + x + Xt ∈ B)

(cid:90)
(cid:90)
(cid:90)

Rd

Rd

Rd

(L2)
=

(L1)
=

=

P(y + Xt ∈ B) P((Xs+t − Xt) + x ∈ dy)
P(y + Xt ∈ B) P(Xs + x ∈ dy)

pt(y,B) ps(x,dy).

Remark 4.5. The proof of Lemma 4.4 shows a bit more: From

pt(x,B) =

1B(x + y) P(Xt ∈ dy) =

1B−x(y) P(Xt ∈ dy) = pt(0,B− x)

(cid:90)

(cid:90)

we see that the kernels pt(x,B) are invariant under shifts in Rd (translation invariant). In slight
abuse of notation we write pt(x,B) = pt(B− x). From this it becomes clear that the Chapman–
Kolmogorov equations are convolution identities pt+s(B) = pt ∗ ps(B), and (pt)t(cid:62)0 is a convolu-
tion semigroup of probability measures; because of (L3), this semigroup is weakly continuous at
t = 0, i.e. pt → δ0 as t → 0, cf. Theorem A.3 et seq. for the weak convergence of measures.

Lévy processes enjoy an even stronger version of the above Markov property.

Theorem 4.6 (Markov property for Lévy processes). Let X be a d-dimensional Lévy process and
set Y := (Xt+a − Xa)t(cid:62)0 for some ﬁxed a (cid:62) 0. Then Y is again a Lévy process satisfying

a) Y ⊥⊥(Xr)r(cid:54)a, i.e. F Y
1Recall that B((Rd)[0,∞)) is the smallest σ-algebra containing the cylinder sets Z = ×t(cid:62)0 Bt where Bt ∈ B(Rd)

∞ ⊥⊥ F X
a .

and only ﬁnitely many Bt (cid:54)= Rd.

26

R. L. Schilling: An Introduction to Lévy and Feller Processes

b) Y ∼ X, i.e. X and Y have the same ﬁnite dimensional distributions.

Proof. Observe that F Y
erty of conditional expectation yields for all s (cid:54) t

s = σ (Xr+a − Xa, r (cid:54) s) ⊂ F X

eiξ·(Yt−Ys)(cid:12)(cid:12)(cid:12) F Y
(cid:16)

s

(cid:17)

E

(cid:104)

eiξ·(Xt+a−Xs+a)(cid:12)(cid:12)(cid:12) F X
(cid:16)

s+a

(cid:105)

(cid:17)(cid:12)(cid:12)(cid:12) F Y

s

= E

E

= e−(t−s)ψ(ξ ).

s+a. Using Theorem 3.1 and the tower prop-

Thus, (Yt)t(cid:62)0 is a Lévy process with the same characteristic function as (Xt)t(cid:62)0. The property
(L2(cid:48)) for X gives

Xtn+a − Xtn−1+a, Xtn−1+a − Xtn−2+a, . . . , Xt1+a − Xa⊥⊥ F X
a .

As σ (Yt1, . . . ,Ytn) = σ (Ytn −Ytn−1, . . . ,Yt1 −Yt0)⊥⊥ F X

a for all t0 = 0 < t1 < ··· < tn, we get

F Y

∞ = σ

σ (Yt1, . . . ,Ytn)

⊥⊥ F X
a .

(cid:32) (cid:91)

t1<···<tn, n∈N

(cid:33)

(cid:90)

(cid:90)

Using the Markov transition function pt(x,B) we can deﬁne a linear operator on the bounded

Borel measurable functions f : Rd → R:

Pt f (x) :=

f (y) pt(x,dy) = Ex f (Xt),

(4.5)
For a Lévy process, cf. Remark 4.5, we have pt(x,B) = pt(B− x) and the operators Pt are actually
convolution operators:

f ∈ Bb(Rd), t (cid:62) 0, x ∈ Rd.

f (y + x) pt(dy) = f ∗(cid:101)pt(x) where (cid:101)pt(B) := pt(−B).

(4.6)

Pt f (x) = E f (Xt + x) =

Deﬁnition 4.7. Let Pt, t (cid:62) 0, be deﬁned by (4.5). The operators are said to be

a) acting on Bb(Rd), if Pt : Bb(Rd) → Bb(Rd).
b) an operator semigroup, if Pt+s = Pt ◦ Ps for all s,t (cid:62) 0 and P0 = id.
c) sub-Markovian if 0 (cid:54) f (cid:54) 1 =⇒ 0 (cid:54) Pt f (cid:54) 1.
d) contractive if (cid:107)Pt f(cid:107)∞ (cid:54) (cid:107) f(cid:107)∞ for all f ∈ Bb(Rd).
e) conservative if Pt1 = 1.
f) Feller operators, if Pt : C∞(Rd) → C∞(Rd).2
g) strongly continuous on C∞(Rd), if limt→0(cid:107)Pt f − f(cid:107)∞ = 0 for all f ∈ C∞(Rd).
h) strong Feller operators, if Pt : Bb(Rd) → Cb(Rd).

2C∞(Rd) denotes the space of continuous functions vanishing at inﬁnity. It is a Banach space when equipped with

the uniform norm (cid:107) f(cid:107)∞ = supx∈Rd | f (x)|.

Chapter 4: On the Markov property

27

Lemma 4.8. Let (Pt)t(cid:62)0 be deﬁned by (4.5). The properties 4.7.a)–e) hold for any Markov process,
4.7.a)–g) hold for any Lévy process, and 4.7.a)–h) hold for any Lévy process such that all transition
probabilities pt(dy) = P(Xt ∈ dy), t > 0, are absolutely continuous w.r.t. Lebesgue measure.
Proof. We only show the assertions about Lévy processes (Xt)t(cid:62)0.

a) Since Pt f (x) = E f (Xt + x), the boundedness of Pt f is obvious, and the measurability in x

follows from (the proof of) Fubini’s theorem.

b) By the tower property of conditional expectation, we get for s,t (cid:62) 0

Pt+s f (x) = Ex f (Xt+s) = Ex(cid:0)Ex[ f (Xt+s) | Fs](cid:1)

= Ex(cid:0)EXs f (Xt)(cid:1) = Ps ◦ Pt f (x).

(4.4)

For the Markov transition functions this is the Chapman–Kolmogorov identity (4.2).

c) and d), e) follow directly from the fact that B (cid:55)→ pt(x,B) is a probability measure.
f) Let f ∈ C∞(Rd). Since x (cid:55)→ f (x + Xt) is continuous and bounded, the claim follows from

dominated convergence as Pt f (x) = E f (x + Xt).

g) f ∈ C∞ is uniformly continuous, i.e. for every ε > 0 there is some δ > 0 such that

|x− y| (cid:54) δ =⇒ | f (x)− f (y)| (cid:54) ε.

Hence,

(cid:107)Pt f − f(cid:107)∞ (cid:54) sup
x∈Rd

(cid:90)
(cid:18)(cid:90)

| f (Xt)− f (x)|dPx

| f (Xt)− f (x)|dPx +
Px(|Xt − x| > δ )

= sup
|Xt−x|(cid:54)δ
x∈Rd
(cid:54) ε + 2(cid:107) f(cid:107)∞ sup
x∈Rd
= ε + 2(cid:107) f(cid:107)∞ P(|Xt| > δ )

(L3)−−−→
t→0

ε.

(cid:90)

|Xt−x|>δ

(cid:19)

| f (Xt)− f (x)|dPx

Since ε > 0 is arbitrary, the claim follows. Note that this proof shows that uniform conti-
nuity in probability is responsible for the strong continuity of the semigroup.

h) see Lemma 4.9.

Lemma 4.9 (Hawkes). Let X = (Xt)t(cid:62)0 be a Lévy process on Rd. Then the operators Pt deﬁned
by (4.5) are strong Feller if, and only if, Xt ∼ pt(y)dy for all t > 0.
Proof. ‘⇐’: Let Xt ∼ pt(y)dy. Since pt ∈ L1 and since convolutions have a smoothing property

(e.g. [53, Theorem 14.8] or [54, Satz 18.9]), we get with(cid:101)pt(y) = pt(−y)

Pt f = f ∗(cid:101)pt ∈ L∞ ∗ L1 ⊂ Cb(Rd).

g(x)Pt 1N(x)dx =

=

g(x)1N(x + y) pt(dy)dx

g(x)1N(x + y)dx

pt(dy) = 0.

(cid:123)(cid:122)

=0

(cid:125)

(cid:90)(cid:90)
(cid:90) (cid:90)
(cid:124)

(cid:90)

28

R. L. Schilling: An Introduction to Lévy and Feller Processes

‘⇒’: We show that pt(dy) (cid:28) dy. Let N ∈ B(Rd) be a Lebesgue null set λ d(N) = 0 and

g ∈ Bb(Rd). Then, by the Fubini–Tonelli theorem

(cid:90)

Take g = Pt 1N, then the above calculation shows

(Pt 1N(x))2 dx = 0.

Hence, Pt 1N = 0 Lebesgue-a.e. By the strong Feller property, Pt 1N is continuous, and so Pt 1N ≡ 0,
hence

pt(N) = Pt 1N(0) = 0.

Remark 4.10. The existence and smoothness of densities for a Lévy process are time-dependent
properties, cf. Sato [50, Chapter V.23]. The typical example is the Gamma process. This is a
(one-dimensional) Lévy process with characteristic exponent
log(1 +|ξ|2)− iarctanξ ,

ξ ∈ R,

ψ(ξ ) =

1
2

and this process has the transition density
1
Γ(t)

pt(x) =

xt−1e−x 1(0,∞)(x),

t > 0.

The factor xt−1 gives a time-dependent condition for the property pt ∈ Lp(dx). One can show, cf.
[31], that

lim|ξ|→∞

Reψ(ξ )

log(1 +|ξ|2)

= ∞ =⇒ ∀t > 0 ∃pt ∈ C∞(Rd).

The converse direction remains true if ψ(ξ ) is rotationally invariant or if it is replaced by its
symmetric rearrangement.
Remark 4.11. If (Pt)t(cid:62)0 is a Feller semigroup, i.e. a semigroup satisfying the conditions 4.7.a)-g),
then there exists a unique stochastic process (a Feller process) with (Pt)t(cid:62)0 as transition semi-
group. The idea is to use Kolmogorov’s consistency theorem for the following family of ﬁnite-
dimensional distributions

(cid:16)

(cid:0)1B2Pt3−t2(. . .Ptn−tn−1(1Bn))(cid:1)(cid:17)

(x)

t1,...,tn(B1 ×···× Bn) = Pt1
px

1B1Pt2−t1

Here Xt0 = X0 = x a.s. Note: It is not enough to have a semigroup on Lp as we need pointwise
evaluations.

If the operators Pt are not a priori given on Bb(Rd) but only on C∞(Rd), one still can use the
Riesz representation theorem to construct Markov kernels pt(x,B) representing and extending Pt
onto Bb(Rd), cf. Lemma 5.2.

Chapter 4: On the Markov property

29

Recall that a stopping time is a random time τ : Ω → [0,∞] such that {τ (cid:54) t} ∈ Ft for all t (cid:62) 0.
It is not hard to see that τn := ((cid:98)2nτ(cid:99) + 1)2−n, n ∈ N, is a sequence of stopping times with values
k2−n, k = 1,2, . . ., such that

τ1 (cid:62) τ2 (cid:62) . . . (cid:62) τn ↓ τ = inf
n∈N

τn.

This approximation is the key ingredient to extend the Markov property (Theorem 4.6) to random
times.

Theorem 4.12 (Strong Markov property for Lévy processes). Let X be a Lévy process on Rd
and set Y := (Xt+τ − Xτ )t(cid:62)0 for some a.s. ﬁnite stopping time τ. Then Y is again a Lévy process
satisfying

τ+ :=(cid:8)F ∈ F X

t ∀t (cid:62) 0(cid:9).

∞ ⊥⊥ F X

a) Y ⊥⊥(Xr)r(cid:54)τ, i.e. F Y
b) Y ∼ X, i.e. X and Y have the same ﬁnite dimensional distributions.
Proof. Let τn := ((cid:98)2nτ(cid:99) + 1)2−n. For all 0 (cid:54) s < t, ξ ∈ Rd and F ∈ F X
continuity of the sample paths (or by the continuity in probability (L3))

∞ : F ∩{τ < t} ∈ F X

τ+ we ﬁnd by the right-

(cid:104)

E

eiξ·(Xt+τ−Xs+τ ) 1F

(cid:105)

(cid:105)

E

(cid:104)
∞
∑
k=1
∞
∑

k=1

∞
∑

k=1

(cid:105)

E

E

= lim
n→∞

= lim
n→∞

eiξ·(Xt+τn−Xs+τn ) 1F

(cid:104)
eiξ·(Xt+k2−n−Xs+k2−n ) 1{τn=k2−n} · 1F
(cid:104)
(cid:105)
(cid:124)
(cid:123)(cid:122)
(cid:125)
E(cid:2)eiξ·Xt−s(cid:3) P(cid:0)(cid:8)(k− 1)2−n (cid:54) τ < k2−n(cid:9)∩ F(cid:1)
= E(cid:2)eiξ·Xt−s(cid:3) P(F).

eiξ·(Xt+k2−n−Xs+k2−n )

1{(k−1)2−n(cid:54)τ<k2−n} 1F

k2−n as F∈F X

= lim
n→∞

= lim
n→∞

(cid:125)

(cid:124)

⊥⊥ F X

k2−n by (L2)

(cid:123)(cid:122)

∈ F X

τ+

In the last equality we use(cid:83)· ∞

and ξ1, . . . ,ξn ∈ Rd. Then

(cid:104)

The same calculation applies to ﬁnitely many increments. Let F ∈ F X

τ+, t0 = 0 < t1 < ··· < tn

k=1{(k− 1)2−n (cid:54) τ < k2−n} = {τ < ∞} for all n (cid:62) 1.

E

ei∑n

k=1 ξk·(Xtk +τ−Xtk−1+τ ) 1F

eiξk·Xtk−tk−1

P(F).

(cid:105)

(cid:104)

=

n

∏

k=1

E

(cid:105)

This shows that the increments Xtk+τ − Xtk−1+τ are independent and distributed like Xtk−tk−1. More-
over, all increments are independent of F ∈ F X
τ+.

Therefore, all random vectors of the form (Xt1+τ − Xτ , . . . ,Xtn+τ − Xtn−1+τ ) are independent of
τ+, and we conclude that F Y

∞ = σ (Xt+τ − Xτ , t (cid:62) 0)⊥⊥ F X
τ+.

F X

5. A digression: semigroups

We have seen that the Markov kernel pt(x,B) of a Lévy or Markov process induces a semigroup
of linear operators (Pt)t(cid:62)0. In this chapter we collect a few tools from functional analysis for the
study of operator semigroups. By Bb(Rd) we denote the bounded Borel functions f : Rd → R, and
C∞(Rd) are the continuous functions vanishing at inﬁnity, i.e. lim|x|→∞ f (x) = 0; when equipped
with the uniform norm (cid:107)·(cid:107)∞ both sets become Banach spaces.
Deﬁnition 5.1. A Feller semigroup is a family of linear operators Pt : Bb(Rd) → Bb(Rd) satisfy-
ing the properties a)–g) of Deﬁnition 4.7: (Pt)t(cid:62)0 is a semigroup of conservative, sub-Markovian
operators which enjoy the Feller property Pt(C∞(Rd)) ⊂ C∞(Rd) and which are strongly contin-
uous on C∞(Rd).

Notice that (t,x) (cid:55)→ Pt f (x) is for every f ∈ C∞(Rd) continuous. This follows from

|Pt f (x)− Ps f (y)| (cid:54) |Pt f (x)− Pt f (y)| +|Pt f (y)− Ps f (y)|
(cid:54) |Pt f (x)− Pt f (y)| +(cid:107)P|t−s| f − f(cid:107)∞,

Lemma 5.2. If (Pt)t(cid:62)0 is a Feller semigroup, then there is a Markov transition function pt(x,dy)

Proof. By the Riesz representation theorem we see that the operators Pt are of the form

the Feller property 4.7.f) and the strong continuity 4.7.g).

(Deﬁnition 4.1) such that Pt f (x) =(cid:82) f (y) pt(x,dy).
(cid:90)

Pt f (x) =

f (y) pt(x,dy)

where pt(x,dy) is a Markov kernel. The tricky part is to show the joint measurability of the
transition function (t,x) (cid:55)→ pt(x,B) and the Chapman–Kolmogorov identities (4.2).

For every compact set K ⊂ Rd the functions deﬁned by

fn(x) :=

d(x,U c
n )

d(x,K) + d(x,U c
n )

,

d(x,A) := inf
a∈A

|x− a|, Un := {y : d(y,K) < 1/n},

are in C∞(Rd) and fn ↓ 1K. By monotone convergence, pt(x,K) = infn∈N Pt fn(x) which proves
the joint measurability in (t,x) for all compact sets.

By the same, the semigroup property Pt+s fn = PsPt fn entails the Chapman–Kolmogorov identi-

ties for compact sets: pt+s(x,K) =(cid:82) pt(y,K) ps(x,dy). Since

B ∈ B(Rd)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (t,x) (cid:55)→ pt(x,B) is measurable &

pt(y,B) ps(x,dy)

pt+s(x,B) =

(cid:90)



D :=

30

Chapter 5: A digression: semigroups

31

is a Dynkin system containing the compact sets, we have D = B(Rd).

To get an intuition for semigroups it is a good idea to view the semigroup property

Pt+s = Ps ◦ Pt

and P0 = id

as an operator-valued Cauchy functional equation. If t (cid:55)→ Pt is—in a suitable sense—continuous,
the unique solution will be of the form Pt = etA for some operator A. This can be easily made
rigorous for matrices A,Pt ∈ Rn×n since the matrix exponential is well deﬁned by the uniformly
convergent series

Pt = exp(tA) :=

and A =

∞
∑

k=0

tkAk
k!

(cid:12)(cid:12)(cid:12)t=0

d
dt

Pt

with A0 := id and Ak = A◦ A◦···◦ A (k times). With a bit more care, this can be made to work
also in general settings.

Deﬁnition 5.3. Let (Pt)t(cid:62)0 be a Feller semigroup. The (inﬁnitesimal) generator is a linear opera-
tor deﬁned by

(cid:12)(cid:12)(cid:12)(cid:12) ∃g ∈ C∞(Rd) : lim

t→0

(cid:13)(cid:13)(cid:13)(cid:13)Pt f − f

t

(cid:27)

(cid:13)(cid:13)(cid:13)(cid:13)∞

− g

= 0

D(A) :=

f ∈ C∞(Rd)
Pt f − f

A f := lim
t→0

t

f ∈ D(A).

,

The following lemma is the rigorous version for the symbolic notation ‘Pt = etA’.

Lemma 5.4. Let (Pt)t(cid:62)0 be a Feller semigroup with inﬁnitesimal generator (A, D(A)). Then
Pt(D(A)) ⊂ D(A) and

Moreover,(cid:82) t

Pt f = APt f = PtA f

for all
0 Ps f ds ∈ D(A) for any f ∈ C∞(Rd), and

f ∈ D(A), t (cid:62) 0.

(cid:26)

d
dt

(5.1)

(5.2)

(5.3)

(5.4)

(5.5)

0

=

(cid:90) t
(cid:90) t
Pt f − f = A
(cid:13)(cid:13)(cid:13)(cid:13)Pt−ε
(cid:13)(cid:13)(cid:13)(cid:13)Pε f − f

(cid:13)(cid:13)(cid:13)(cid:13)∞

(cid:54)

(cid:54)

ε

Ps f ds,

0
PsA f ds,

f ∈ C∞(Rd), t > 0
f ∈ D(A), t > 0.

− Pt−εA f

+(cid:13)(cid:13)Pt−εA f − Pt−εPεA f(cid:13)(cid:13)∞

(cid:13)(cid:13)(cid:13)(cid:13)∞
+(cid:13)(cid:13)A f − PεA f(cid:13)(cid:13)∞ −−→

0

ε→0

Pε f − f

ε
− A f

(cid:13)(cid:13)(cid:13)(cid:13)∞

(cid:13)(cid:13)(cid:13)(cid:13)Pt f − Pt−ε f

ε

− PtA f

Proof. Let 0 < ε < t and f ∈ D(A). The semigroup and contraction properties give

where we use the strong continuity in the last step. This shows d−
(but simpler) calculation proves this also for d+

dt Pt f .

dt Pt f = APt f = PtA f ; a similar

and so,

(cid:90) t

0

Pε − id

ε

(cid:90) t

0

Pε

Ps f (x)ds =

0

PεPs f (x)ds,

(cid:90) t
(cid:90) t
(cid:0)Ps+ε f (x)− Ps f (x)(cid:1)ds
(cid:90) ε
(cid:90) t+ε

0

Ps f (x)ds− 1
ε

0

t

1
ε
1
ε

Ps f (x)ds.

Ps f (x)ds =

=

(cid:90) r+ε

1
ε

lim
ε→0

r

Ps f (x)ds = Pr f (x)

32

R. L. Schilling: An Introduction to Lévy and Feller Processes

Let f ∈ C∞(Rd) and t,ε > 0. By Fubini’s theorem and the representation of Pt with a Markov

transition function (Lemma 5.2) we get

Since t (cid:55)→ Pt f (x) is continuous, the fundamental theorem of calculus applies, and we get

for r (cid:62) 0. This shows that(cid:82) t

from

0 Ps f ds ∈ D(A) as well as (5.4). If f ∈ D(A), then we deduce (5.5)
(cid:90) t

(cid:90) t

Ps f (x)ds = Pt f (x)− f (x)

(5.4)
= A

Ps f (x)ds.

0

PsA f (x)ds (5.3)
=

d
ds

0

(cid:90) t

0

Remark 5.5 (Consequences of Lemma 5.4). Write C∞ := C∞(Rd).

a) (5.4) shows that D(A) is dense in C∞, since D(A) (cid:51) t−1(cid:82) t

0 Ps f ds −−→
t→0

f for any f ∈ C∞.

b) (5.5) shows that A is a closed operator, i.e.

fn ∈ D(A), ( fn,A fn)

−−−−−−→
uniformly

n→∞

( f ,g) ∈ C∞ × C∞ =⇒ f ∈ D(A) & A f = g.

c) (5.3) means that A determines (Pt)t(cid:62)0 uniquely.

Let us now consider the Laplace transform of (Pt)t(cid:62)0.

Deﬁnition 5.6. Let (Pt)t(cid:62)0 be a Feller semigroup. The resolvent is a linear operator on Bb(Rd)
given by

Rλ f (x) :=

(5.6)
The following formal calculation can easily be made rigorous. Let (λ − A) := (λ id−A) for

f ∈ Bb(Rd), x ∈ Rd, λ > 0.

e−λtPt f (x)dt,

(cid:90) ∞

0

λ > 0 and f ∈ D(A). Then

(cid:90) ∞
(cid:90) ∞
(λ − A)Rλ f = (λ − A)
e−λtPt f dt
e−λt(λ − A)Pt f dt
(cid:90) ∞
(cid:90) ∞
e−λtPt f dt −
e−λt
(cid:90) ∞
(cid:90) ∞
e−λtPt f dt − λ
e−λtPt f dt − [e−λtPt f ]∞

(cid:18) d

parts
= λ

= λ

(cid:19)

(5.4),(5.5)

Pt f

dt

dt

=

0

0

0

0

0

0

t=0 = f .

A similar calculation for Rλ (λ − A) gives

Chapter 5: A digression: semigroups

33

Theorem 5.7. Let (A, D(A)) and (Rλ )λ >0 be the generator and the resolvent of a Feller semi-
group. Then

Rλ = (λ − A)−1

for all λ > 0.

Since Rλ is the Laplace transform of (Pt)t(cid:62)0, the properties of (Rλ )λ >0 can be found from
(Pt)t(cid:62)0 and vice versa. With some effort one can even invert the (operator-valued) Laplace trans-
form which leads to the familiar expression for ex:

(cid:16)n

(cid:17)n

R n
t

t

=

(cid:16)
id− t
n

(cid:17)−n strongly

−−−−−→
n→∞

A

etA = Pt

(5.7)

(5.8)

(the notation etA = Pt is, for unbounded operators A, formal), see Pazy [40, Chapter 1.8].

Lemma 5.8. Let (Rλ )λ >0 be the resolvent of a Feller1 semigroup (Pt)t(cid:62)0. Then

Proof. Using a symmetry argument we see

dn
dλ n Rλ = n!(−1)nRn+1
(cid:90) t
(cid:90) t
(cid:90) tn

λ

n ∈ N0.
(cid:90) t2

(cid:90) t

0

tn =

. . .

dt1 . . .dtn = n!

. . .

dt1 . . .dtn.

0

0

0

0

0

(cid:90) ∞

(−1)n dn

dλ n Rλ f (x) =

Let f ∈ C∞(Rd) and x ∈ Rd. Then
(cid:90) ∞
(−1)n dn
(cid:90) t2
(cid:90) ∞
(cid:90) t
(cid:90) tn
dλ n e−λtPt f (x)dt =
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
e−λtPt f (x)dt dt1 . . .dtn
(cid:90) ∞
(cid:90) ∞
(cid:90) ∞
e−λ (t+t1+···+tn)Pt+t1+···+tn f (x)dt dt1 . . .dtn

e−λtPt f (x)dt1 . . .dtn dt

tne−λtPt f (x)dt

0
= n!

= n!

= n!

0

0

. . .

. . .

tn

0

0

0

0

t1

0

. . .

0
f (x).

= n!Rn+1

λ

The key result identifying the generators of Feller semigroups is the following theorem due to
Hille, Yosida and Ray, a proof can be found in Pazy [40, Chapter 1.4] or Ethier & Kurtz [17,
Chapter 4.2]; a probabilistic approach is due to Itô [25].

Theorem 5.9 (Hille–Yosida–Ray). A linear operator (A, D(A)) on C∞(Rd) generates a Feller
semigroup (Pt)t(cid:62)0 if, and only if,

a) D(A) ⊂ C∞(Rd) dense.
b) A is dissipative, i.e. (cid:107)λ f − A f(cid:107)∞ (cid:62) λ(cid:107) f(cid:107)∞ for some (or all) λ > 0.
c) (λ − A)(D(A)) = C∞(Rd) for some (or all) λ > 0.
1This Lemma only needs that the operators Pt are strongly continuous and contractive, Deﬁnition 4.7.g), d).

34

R. L. Schilling: An Introduction to Lévy and Feller Processes

d) A satisﬁes the positive maximum principle:
f ∈ D(A), f (x0) = sup
x∈Rd

f (x) (cid:62) 0 =⇒ A f (x0) (cid:54) 0.

(PMP)

This variant of the Hille–Yosida theorem is not the standard version from functional analysis
since we are interested in positivity preserving (sub-Markov) semigroups. Let us brieﬂy discuss
the role of the positive maximum principle.
Remark 5.10. Let (Pt)t(cid:62)0 be a strongly continuous contraction semigroup on C∞(Rd), i.e.

(cid:107)Pt f(cid:107)∞ (cid:54) (cid:107) f(cid:107)∞

and

lim
t→0

(cid:107)Pt f − f(cid:107)∞ = 0,

cf. Deﬁnition 4.7.d),g).2
1◦ Sub-Markov ⇒ (PMP). Assume that f ∈ D(A) is such that f (x0) = sup f (cid:62) 0. Then

Pt f (x0)− f (x0)

f(cid:54) f +(cid:54) P+

t

f (x0)− f +(x0) (cid:54) (cid:107) f +(cid:107)∞ − f +(x0) = 0.

=⇒ A f (x0) = lim
t→0

Pt f (x0)− f (x0)

t

(cid:54) 0.

Thus, (PMP) holds.

2◦ (PMP) ⇒ dissipativity. Assume that (PMP) holds and let f ∈ D(A). Since f ∈ C∞(Rd), we

may assume that f (x0) = | f (x0)| = sup| f| (otherwise f (cid:32) − f ). Then

(cid:107)λ f − A f(cid:107)∞ (cid:62) λ f (x0)− A f (x0)

(cid:62) λ f (x0) = λ(cid:107) f(cid:107)∞.

(cid:124) (cid:123)(cid:122) (cid:125)(cid:54)0

3◦ (PMP) ⇒ sub-Markov. Since Pt is contractive, we have Pt f (x) (cid:54) (cid:107)Pt f(cid:107)∞ (cid:54) (cid:107) f(cid:107)∞ (cid:54) 1 for all
f ∈ C∞(Rd) such that | f| (cid:54) 1. In order to see positivity, let f ∈ C∞(Rd) be non-negative.
We distinguish between two cases:
1◦ Rλ f does not attain its inﬁmum. Since Rλ f ∈ C∞(Rd) vanishes at inﬁnity, we have nec-

essarily Rλ f (cid:62) 0.

2◦ ∃x0 : Rλ f (x0) = infRλ f . Because of the (PMP) we ﬁnd

λ Rλ f (x0)− f (x0) = ARλ f (x0) (cid:62) 0

=⇒ λ Rλ f (x) (cid:62) infλ Rλ f = λ Rλ f (x0) (cid:62) f (x0) (cid:62) 0.

This proves that f (cid:62) 0 =⇒ λ Rλ f (cid:62) 0. From (5.8) we see that λ (cid:55)→ Rλ f (x) is completely
monotone, hence it is the Laplace transform of a positive measure. Since Rλ f (x) has the
integral representation (5.6), we conclude that Pt f (x) (cid:62) 0 (for all t (cid:62) 0 as t (cid:55)→ Pt f is contin-
uous).
Using the Riesz representation theorem (as in Lemma 5.2) we can extend Pt as a sub-Markov
operator onto Bb(Rd).

2These properties are essential for the existence of a generator and the resolvent on C∞(Rd).

Chapter 5: A digression: semigroups

35

In order to determine the domain D(A) of the generator the following ‘maximal dissipativity’

result is handy.

Lemma 5.11 (Dynkin, Reuter). Assume that (A, D(A)) generates a Feller semigroup and that
(A, D(A)) extends A, i.e. D(A) ⊂ D(A) and A|D(A) = A. If

u ∈ D(A), u− Au = 0 =⇒ u = 0,

(5.9)

then (A, D(A)) = (A, D(A)).
Proof. Since A is a generator, (id−A) : D(A) → C∞(Rd) is bijective. On the other hand, the
relation (5.9) means that (id−A) is injective, but (id−A) cannot have a proper injective extension.

Theorem 5.12. Let (Pt)t(cid:62)0 be a Feller semigroup with generator (A, D(A)). Then

(cid:26)

D(A) =

f ∈ C∞(Rd)

(cid:12)(cid:12)(cid:12)(cid:12) ∃g ∈ C∞(Rd) ∀x : lim

t→0

Pt f (x)− f (x)

t

(cid:27)

= g(x)

.

(5.10)

Proof. Denote by D(A) the right-hand side of (5.10) and deﬁne

A f (x) := lim
t→0

Pt f (x)− f (x)

t

for all

f ∈ D(A), x ∈ Rd.

Obviously, (A, D(A)) is a linear operator which extends (A, D(A)). Since (PMP) is, essentially,
a pointwise assertion (see Remark 5.10, 1◦), A inherits (PMP); in particular, A is dissipative (see
Remark 5.10, 2◦):

(cid:107)A f − λ f(cid:107)∞ (cid:62) λ(cid:107) f(cid:107)∞.
This implies (5.9), and the claim follows from Lemma 5.11.

6. The generator of a Lévy process

We want to study the structure of the generator of (the semigroup corresponding to) a Lévy process
X = (Xt)t(cid:62)0. This will also lead to a proof of the Lévy–Khintchine formula.

Our approach uses some Fourier analysis. We denote by C∞

c (Rd) and S(Rd) the smooth, com-
pactly supported functions and the smooth, rapidly decreasing ‘Schwartz functions’.1 The Fourier

transform is denoted by(cid:98)f (ξ ) = F f (ξ ) := (2π)−d

(cid:90)

Rd

f (x)e−iξ·x dx,

f ∈ L1(dx).

Observe that F f is chosen in such a way that the characteristic function becomes the inverse
Fourier transform.

We have seen in Proposition 2.3 and its Corollaries 2.4 and 2.5 that X is completely character-

ized by the characteristic exponent ψ : Rd → C

Eeiξ·Xt =(cid:2)Eeiξ·X1(cid:3)t

= e−tψ(ξ ),

t (cid:62) 0, ξ ∈ Rd.

We need a few more properties of ψ which result from the fact that χ(ξ ) = e−ψ(ξ ) is a character-
istic function.

Lemma 6.1. Let χ(ξ ) be any characteristic function of a probability measure µ. Then

|χ(ξ + η)− χ(ξ )χ(η)|2 (cid:54) (1−|χ(ξ )|2)(1−|χ(η)|2),

ξ ,η ∈ Rd.

(6.1)

Proof. Since µ is a probability measure, we ﬁnd from the deﬁnition of χ

χ(ξ + η)− χ(ξ )χ(η) =

=

1
2

(cid:90)(cid:90) (cid:0)eix·ξ eix·η − eix·ξ eiy·η(cid:1) µ(dx) µ(dy)
(cid:90)(cid:90) (cid:0)eix·ξ − eiy·ξ(cid:1)(cid:0)eix·η − eiy·η(cid:1) µ(dx) µ(dy).

In the last equality we use that the integrand is symmetric in x and y, which allows us to in-
terchange the variables. Using the elementary formula |eia − eib|2 = 2 − 2cos(b − a) and the

1To be precise, f ∈ S(Rd), if f ∈ C∞(Rd) and if supx∈Rd (1 + |x|N )|∂ α f (x)| (cid:54) cN,α for any N ∈ N0 and any

multiindex α ∈ Nd
0.

36

Chapter 6: The generator of a Lévy process

37

Cauchy–Schwarz inequality yield

|χ(ξ + η)− χ(ξ )χ(η)|

(cid:90)(cid:90) (cid:12)(cid:12)eix·ξ − eiy·ξ(cid:12)(cid:12)·(cid:12)(cid:12)eix·η − eiy·η(cid:12)(cid:12) µ(dx) µ(dy)
(cid:90)(cid:90) (cid:112)1− cos(y− x)· ξ(cid:112)1− cos(y− x)· η µ(dx) µ(dy)
(cid:114)(cid:90)(cid:90) (cid:0)1− cos(y− x)· ξ(cid:1) µ(dx) µ(dy)
(cid:20)(cid:90)

(cid:90)

cos(y− x)· ξ µ(dx) µ(dy) = Re

eiy·ξ µ(dy)

(cid:54) 1
2

=

(cid:54)

(cid:90)(cid:90)

This ﬁnishes the proof as

(cid:114)(cid:90)(cid:90) (cid:0)1− cos(y− x)· η(cid:1) µ(dx) µ(dy).

(cid:21)

e−ix·ξ µ(dx)

= |χ(ξ )|2.

Theorem 6.2. Let ψ : Rd → C be the characteristic exponent of a Lévy process. Then the function

ξ (cid:55)→(cid:112)|ψ(ξ )| is subadditive and

(6.2)
Proof. We use (6.1) with χ = e−tψ, divide by t > 0 and let t → 0. Since |χ| = e−t Reψ, this gives

|ψ(ξ )| (cid:54) cψ (1 +|ξ|2),

ξ ∈ Rd.

|ψ(ξ + η)− ψ(ξ )− ψ(η)|2 (cid:54) 4Reψ(ξ )Reψ(η) (cid:54) 4|ψ(ξ )|·|ψ(η)|.

By the lower triangle inequality,

|ψ(ξ + η)|−|ψ(ξ )|−|ψ(η)| (cid:54) 2(cid:112)|ψ(ξ )|(cid:112)|ψ(η)|
and this is the same as subadditivity:(cid:112)|ψ(ξ + η)| (cid:54)(cid:112)|ψ(ξ )| +(cid:112)|ψ(η)|.

In particular, |ψ(2ξ )| (cid:54) 2|ψ(ξ )|. For any ξ (cid:54)= 0 there is some integer n = n(ξ ) ∈ Z such that

2n−1 (cid:54) |ξ| (cid:54) 2n, so

|ψ(ξ )| = |ψ(2n2−nξ )| (cid:54) max{1,22n} sup
|η|(cid:54)1

|ψ(η)| (cid:54) 2 sup
|η|(cid:54)1

|ψ(η)|(1 +|ξ|2).

c (Rd) ⊂ D(A).

Lemma 6.3. Let (Xt)t(cid:62)0 be a Lévy process and denote by (A, D(A)) its inﬁnitesimal generator.
Then C∞
Proof. Let f ∈ C∞
c (Rd). By deﬁnition, Pt f (x) = E f (Xt + x). Using the differentiation lemma for
parameter-dependent integrals (e.g. [53, Theorem 11.5] or [54, 12.2]) it is not hard to see that
Pt : S(Rd) → S(Rd). Obviously,

e−tψ(ξ ) = Eeiξ·Xt = Exeiξ·(Xt−x) = e−ξ (x)Pteξ (x)

for eξ (x) := eiξ·x. Recall that the Fourier transform of f ∈ S(Rd) is again in S(Rd). From

Pt f = Pt

(cid:90) (cid:98)f (ξ )eξ (·)dξ =

(cid:90) (cid:98)f (ξ )Pteξ (·)dξ
(cid:90) (cid:98)f (ξ )eξ (·)e−tψ(ξ ) dξ

(6.3)
=

(6.3)

(6.4)

R. L. Schilling: An Introduction to Lévy and Feller Processes

38

we conclude that (cid:99)Pt f = (cid:98)f e−tψ. Hence,

Consequently,

Pt f = F−1((cid:98)f e−tψ ).
e−tψ(cid:98)f −(cid:98)f

(cid:99)Pt f −(cid:98)f

=

(cid:98)f∈S(Rd )
=====⇒ Pt f (x)− f (x)

t

−ψ(cid:98)f

−−−→
t→0

g(x) := F−1(−ψ(cid:98)f )(x).

t
−−−→
t→0

(6.5)

t

Since ψ grows at most polynomially (Lemma 6.2) and (cid:98)f ∈ S(Rd), we see ψ(cid:98)f ∈ L1(dx) and, by

the Riemann–Lebesgue lemma, g ∈ C∞(Rd). Using Theorem 5.12 it follows that f ∈ D(A).
Deﬁnition 6.4. Let L : C2

b(Rd) → Cb(Rd) be a linear operator. Then

is the symbol of the operator L = Lx.

L(x,ξ ) := e−ξ (x)Lxeξ (x)

(6.6)

The proof of Lemma 6.3 actually shows that we can recover an operator L from its symbol

L(x,ξ ) if, say, L : C2

Lu(x) = L

b(Rd) → Cb(Rd) is continuous:2 Indeed, for all u ∈ C∞

(cid:90) (cid:98)u(ξ )eξ (x)dξ
(cid:90) (cid:98)u(ξ )Lxeξ (x)dξ
(cid:90) (cid:98)u(ξ )L(x,ξ )eξ (x)dξ = F−1(L(x,·)Fu(·))(x).

=

=

c (Rd)

Example 6.5. A typical example would be the Laplace operator (i.e. the generator of a Brownian
motion)

1

2∆ f (x) = − 1
2 ( 1

i ∂x)2 f (x) =

or the fractional Laplacian of order 1
Lévy process

i.e. L(x,ξ ) = −1
2

|ξ|2,

2α ∈ (0,1) which generates a rotationally symmetric α-stable

(cid:90) (cid:98)f (ξ )(cid:0)− 1
2|ξ|2(cid:1)eiξ·x dξ ,
(cid:90) (cid:98)f (ξ )(cid:0)−|ξ|α(cid:1)eiξ·x dξ ,

−(−∆)α/2 f (x) =

i.e. L(x,ξ ) = −|ξ|α .

More generally, if P(x,ξ ) is a polynomial in ξ , then the corresponding operator is obtained by
replacing ξ by 1

i ∇x and formally expanding the powers.

Deﬁnition 6.6. An operator of the form

(cid:90) (cid:98)f (ξ )L(x,ξ )eix·ξ dξ ,

L(x,D) f (x) =

f ∈ S(Rd),

(6.7)

is called (if deﬁned) a pseudo differential operator with (non-classical) symbol L(x,ξ ).

2As usual, C2

b(Rd) is endowed with the norm (cid:107)u(cid:107)(2) = ∑0(cid:54)|α|(cid:54)2(cid:107)∂ α u(cid:107)∞.

Chapter 6: The generator of a Lévy process

39

Remark 6.7. The symbol of a Lévy process does not depend on x, i.e. L(x,ξ ) = L(ξ ). This
is a consequence of the spatial homogeneity of the process which is encoded in the translation
invariance of the semigroup (cf. (4.6) and Lemma 4.4):

Pt f (x) = E f (Xt + x) =⇒ Pt f (x) = ϑx(Pt f )(0) = Pt(ϑx f )(0)

where ϑxu(y) = u(y +x) is the shift operator. This property is obviously inherited by the generator,
i.e.

A f (x) = ϑx(A f )(0) = A(ϑx f )(0),

f ∈ D(A).

As a matter of fact, the converse is also true: If L : C∞

c (Rd) → C(Rd) is a linear operator
satisfying ϑx(L f ) = L(ϑx f ), then L f = f ∗ λ where λ is a distribution, i.e. a continuous linear
functional λ : C∞

c (Rd) → R, cf. Theorem A.10.

Theorem 6.8. Let (Xt)t(cid:62)0 be a Lévy process with generator A. Then

(cid:2) f (x + y)− f (x)− ∇ f (x)· y1(0,1)(|y|)(cid:3)ν(dy)

(6.8)

(cid:90)

y(cid:54)=0

A f (x) = l · ∇ f (x) +

1
2

∇· Q∇ f (x) +

for any f ∈ C∞

on Rd \{0} such that(cid:82)

y(cid:54)=0 min{1,|y|2}ν(dy) < ∞.
Equivalently, A is a pseudo differential operator

c (Rd), where l ∈ Rd, Q ∈ Rd×d is a positive semideﬁnite matrix, and ν is a measure

Au(x) = −ψ(D)u(x) = −

(6.9)
whose symbol is the characteristic exponent −ψ of the Lévy process. It is given by the Lévy–
Khintchine formula

c (Rd),

u ∈ C∞

(cid:90) (cid:98)u(ξ )ψ(ξ )eix·ξ dξ ,
(cid:16)
(cid:17)
(cid:90)
1− eiy·ξ + iξ · y1(0,1)(|y|)

y(cid:54)=0

ν(dy)

(6.10)

ψ(ξ ) = −il · ξ +

ξ · Qξ +

1
2

where the triplet (l,Q,ν) as above.

I learned the following proof from Francis Hirsch; it is based on arguments by Courrège [13]
and Herz [20]. The presentation below follows the version in Böttcher, Schilling & Wang [9,
Section 2.3].

Proof. The proof is divided into several steps.

1◦ We have seen in Lemma 6.3 that C∞
2◦ Set A0 f := (A f )(0) for f ∈ C∞

c (Rd) ⊂ D(A).

c (Rd). This is a linear functional on C∞

c . Observe that

f ∈ C∞

c (Rd),

f (cid:62) 0,

f (0) = 0

(PMP)

===⇒ A0 f (cid:62) 0.

40

R. L. Schilling: An Introduction to Lévy and Feller Processes

3◦ By 2◦, f (cid:55)→ A00 f := A0(|·|2 · f ) is a positive linear functional on C∞

bounded. Indeed, let f ∈ C∞
function such that 1K (cid:54) φ (cid:54) 1. Then

c (K) for a compact set K ⊂ Rd and let φ ∈ C∞

c (Rd). Therefore it is
c (Rd) be a cut-off

(cid:107) f(cid:107)∞φ ± f (cid:62) 0.

By linearity and positivity (cid:107) f(cid:107)∞A00φ ± A00 f (cid:62) 0 which shows |A00 f| (cid:54) CK(cid:107) f(cid:107)∞ with the
constant CK = A00φ.
By Riesz’ representation theorem, there exists a Radon measure3 µ such that

(cid:90)

(cid:90)

A0(|·|2 f ) =

f (y) µ(dy) =

|y|2 f (y)

|y|2 f (y)ν(dy).

(cid:90)

=

(cid:124) (cid:123)(cid:122) (cid:125)

µ(dy)
|y|2
=:ν(dy)
f0 ∈ C∞

c (Rd \{0});

This implies that

(cid:90)

y(cid:54)=0

A0 f0 =

f0(y)ν(dy)

for all

since any compact subset of Rd \{0} is contained in an annulus BR(0)\ Bε (0), we have
supp f0 ∩ Bε (0) = /0 for some sufﬁciently small ε > 0. The measure ν is a Radon measure
on Rd \{0}.
4◦ Let f ,g ∈ C∞

c (Rd), 0 (cid:54) f ,g (cid:54) 1, supp f ⊂ B1(0), suppg ⊂ B1(0)

c and f (0) = 1. From

(cid:0)(cid:107)g(cid:107)∞ f (y) + g(y)(cid:1) = (cid:107)g(cid:107)∞ = (cid:107)g(cid:107)∞ f (0) + g(0)

sup
y∈Rd

and (PMP), it follows that A0((cid:107)g(cid:107)∞ f + g) (cid:54) 0. Consequently,

If g ↑ 1− 1

Hence,(cid:82)

5◦ Let f ∈ C∞

A0g (cid:54) −(cid:107)g(cid:107)∞A0 f .

B1(0), then this shows(cid:90)

|y|>1

ν(dy) (cid:54) −A0 f < ∞.

y(cid:54)=0(|y|2 ∧ 1)ν(dy) < ∞.
c (Rd) and φ (y) = 1(0,1)(|y|). Deﬁne
(cid:90)

(cid:2) f (y)− f (0)− y· ∇ f (0)φ (y)(cid:3)ν(dy).

S0 f :=

y(cid:54)=0

(6.11)

By Taylor’s formula, there is some θ ∈ (0,1) such that

f (y)− f (0)− y· ∇ f (0)φ (y) =

1
2

d

∑

k,l=1

∂ 2 f (θy)
∂ xk∂ xl

ykyl.

3A Radon measure on a topological space E is a Borel measure which is ﬁnite on compact subsets of E and regular:
for all open sets µ(U) = supK⊂U µ(K) and for all Borel sets µ(B) = infU⊃B µ(U) (K, U are generic compact and open
sets, respectively).

Chapter 6: The generator of a Lévy process

41

Using the elementary inequality 2ykyl (cid:54) y2

| f (y)− f (0)− y· ∇ f (0)φ (y)| (cid:54)

(cid:54) |y|2, we obtain

(cid:13)(cid:13) ∂ 2

∂ xk∂ xl

f(cid:13)(cid:13)∞|y|2,

k + y2
l

 1

k,l=1

4 ∑d
2(cid:107) f(cid:107)∞,

|y| < 1
|y| (cid:62) 1

This means that S0 deﬁnes a distribution (generalized function) of order 2.

(cid:54) 2(cid:107) f(cid:107)(2)(|y|2 ∧ 1).

6◦ Set L0 := A0 − S0. The steps 2◦ and 5◦ show that A0 is a distribution of order 2. Moreover,

(cid:90)

(cid:2) f0(0)− y· ∇ f0(0)φ (y)(cid:3)ν(dy) = 0

L0 f0 =

y(cid:54)=0

for any f0 ∈ C∞
c (Rd) with f0|Bε (0) = 0 for some ε > 0. Hence, supp(L0) ⊂ {0}.
Let us show that L0 is almost positive (also: ‘fast positiv’, ‘prèsque positif’):

f0 ∈ C∞
Indeed: Pick 0 (cid:54) φn ∈ C∞

f0(0) = 0,

c (Rd),
c (Rd \{0}), φn ↑ 1Rd\{0} and let f0 be as in (PP). Then

f0 (cid:62) 0 =⇒ L0 f0 (cid:62) 0.

(PP)

L0 f0

suppL0⊂{0}

=

=

f0(0)=0
∇ f0(0)=0

=

2◦
(cid:62)
(PMP)

L0[(1− φn) f0)]
A0[(1− φn) f0]− S0[(1− φn) f0]
A0[(1− φn) f0]−
(cid:90)

(cid:90)

y(cid:54)=0

(1− φn(y)) f0(y)ν(dy) −−−→
n→∞

−

0

(1− φn(y)) f0(y)ν(dy)

by the monotone convergence theorem.

7◦ As in 5◦ we ﬁnd with Taylor’s formula for f ∈ C∞

c (Rd), supp f ⊂ K and φ ∈ C∞

c (Rd) satis-

fying 1K (cid:54) φ (cid:54) 1

( f (y)− f (0)− ∇ f (0)· y)φ (y) (cid:54) 2(cid:107) f(cid:107)(2)|y|2φ (y).

(As usual, (cid:107) f(cid:107)(2) = ∑0(cid:54)|α|(cid:54)2(cid:107)∂ α f(cid:107)∞.) Therefore,

2(cid:107) f(cid:107)(2)|y|2φ (y) + f (0)φ (y) + ∇ f (0)· yφ (y)− f (y) (cid:62) 0,

and (PP) implies

L0 f (cid:54) f (0)L0φ +|∇ f (0)|L0(|·|φ ) + 2(cid:107) f(cid:107)(2)L0(|·|2φ ) (cid:54) CK(cid:107) f(cid:107)(2).

8◦ We have seen in 6◦ that L0 is of order 2 and suppL0 ⊂ {0}. Therefore,

L0 f =

1
2

d

∑

k,l=1

qkl

∂ 2 f (0)
∂ xk∂ xl

+

d

∑

k=1

lk

∂ f (0)
∂ xk

− c f (0).

(6.12)

42

R. L. Schilling: An Introduction to Lévy and Feller Processes

We will show that (qkl)k,l is positive semideﬁnite. Set g(y) := (y·ξ )2 f (y) where f ∈ C∞
is such that 1B1(0) (cid:54) f (cid:54) 1. By (PP), L0g (cid:62) 0. It is not difﬁcult to see that this implies

c (Rd)

qklξkξl (cid:62) 0,

for all ξ = (ξ1, . . . ,ξd) ∈ Rd.

d

∑

k,l=1

9◦ Since Lévy processes and their semigroups are invariant under translations, cf. Remark 6.7,

we get A f (x) = A0[ f (x +·)]. If we replace f by f (x +·), we get

A f (x) = c f (x) + l · ∇ f (x) +

1
2

∇· Q∇ f (x)

(cid:2) f (x + y)− f (x)− y· ∇ f (x)1(0,1)(|y|)(cid:3)ν(dy).

(cid:90)

+

y(cid:54)=0

(6.8(cid:48))

We will show in the next step that c = 0.
10◦ So far, we have seen in 5◦,7◦ and 9◦ that

(cid:107)A f(cid:107)∞ (cid:54) C(cid:107) f(cid:107)(2) = C ∑
|α|(cid:54)2

(cid:107)∂ α f(cid:107)∞,

f ∈ C∞

c (Rd),

which means that A (has an extension which) is continuous as an operator from C2
Cb(Rd). Therefore, (A, C∞

c (Rd)) is a pseudo differential operator with symbol
−ψ(ξ ) = e−ξ (x)Axeξ (x),

eξ (x) = eiξ·x.

b(Rd) to

Inserting eξ into (6.8(cid:48)) proves (6.10) and, as ψ(0) = 0, c = 0.

Remark 6.9. In step 8◦ of the proof of Theorem 6.8 one can use the (PMP) to show that the
coefﬁcient c appearing in (6.8(cid:48)) is positive. For this, let ( fn)n∈N ⊂ C∞
c (Rd), fn ↑ 1 and fn|B1(0) = 1.
By (PMP), A0 fn (cid:54) 0. Moreover, ∇ fn(0) = 0 and, therefore,

(cid:90)

S0 fn = −

(1− fn(y))ν(dy) −−−→
n→∞

0.

Consequently,

limsup
n→∞

L0 fn = limsup
n→∞

(A0 fn − S0 fn) (cid:54) 0 =⇒ c (cid:62) 0.

For Lévy processes we have c = ψ(0) = 0 and this is a consequence of the inﬁnite life-time of

the process:

P(Xt ∈ Rd) = Pt1 = 1

and we can use the formula Pt f − f = A(cid:82) t
Deﬁnition 6.10. A Lévy measure is a Radon measure ν on Rd \{0} s.t.(cid:82)

c = A1 = 0 ⇐⇒ Pt1 = 1.

for all t (cid:62) 0,

y(cid:54)=0(|y|2∧1)ν(dy) < ∞.
A Lévy triplet is a triplet (l,Q,ν) consisting of a vector l ∈ Rd, positive semi-deﬁnite matrix
Q ∈ Rd×d and a Lévy measure ν.

0 Ps f ds, cf. Lemma 5.4, for f ≡ 1 to show that

Chapter 6: The generator of a Lévy process

43

The proof of Theorem 6.8 incidentally shows that the Lévy triplet deﬁning the exponent (6.10)
or the generator (6.8) is unique. The following corollary can easily be checked using the represen-
tation (6.8).

Corollary 6.11. Let A be the generator and (Pt)t(cid:62)0 the semigroup of a Lévy process. Then the

Lévy triplet is given by(cid:90)

f0 dν = A f0(0) = lim
t→0

Pt f0(0)

t

(cid:90)

c (Rd \{0}),

lk = Aφk(0)−
yk
qkl = A(φkφl)(0)−

∀ f0 ∈ C∞

(cid:2)φ (y)− 1(0,1)(|y|)(cid:3)ν(dy),
(cid:90)

φk(y)φl(y)ν(dy),

y(cid:54)=0

k = 1, . . . ,d,

(6.13)

k,l = 1, . . .d,

where φ ∈ C∞
determined by A or the characteristic exponent ψ.

c (Rd) satisﬁes 1B1(0) (cid:54) φ (cid:54) 1 and φk(y) := ykφ (y). In particular, (l,Q,ν) is uniquely

We will see an alternative uniqueness proof in the next Chapter 7.

Remark 6.12. Setting pt(dy) = P(Xt ∈ dy), we can recast the formula for the Lévy measure as

ν(dy) = lim
t→0

pt(dy)

t

(vague limit of measures on the set Rd \{0}).

Moreover, a direct calculation using the Lévy–Khintchine formula (6.13) gives the following al-
ternative representation for the qkl:

1
2

ξ · Qξ = lim
n→∞

ψ(nξ )

n2

ξ ∈ Rd.

,

7. Construction of Lévy processes

Our starting point is now the Lévy–Khintchine formula for the characteristic exponent ψ of a Lévy
process

(cid:90)

y(cid:54)=0

(cid:2)1− eiy·ξ + iξ · y1(0,1)(|y|)(cid:3)ν(dy)

ψ(ξ ) = −il · ξ +

ξ · Qξ +

1
2

(7.1)

where (l,Q,ν) is a Lévy triplet in the sense of Deﬁnition 6.10; a proof of (7.1) is contained in
Theorem 6.8, but the exposition below is independent of this proof, see however Remark 7.7 at
the end of this chapter.

What will be needed is that a compound Poisson process is a Lévy process with càdlàg paths

and characteristic exponent of the form

φ (ξ ) =

(cid:90)

y(cid:54)=0

(cid:2)1− eiy·ξ(cid:3)ρ(dy)

(ρ is any ﬁnite measure), see Example 3.2.d), where ρ(dy) = λ · µ(dy).
(cid:2)|y|2 ∧ 1(cid:3)ν(dy) < ∞, the measure ρ(B) := ν(B ∩ Aa,b) is a ﬁnite measure, and there is a
(cid:82)
corresponding compound Poisson process. Adding a drift with l = −(cid:82) yρ(dy) shows that for

Let ν be a Lévy measure and denote by Aa,b = {y : a (cid:54) |y| < b} an annulus. Since we have
y(cid:54)=0

every exponent

ψa,b(ξ ) =

(cid:90)

(cid:2)1− eiy·ξ + iy· ξ(cid:3)ν(dy)

a(cid:54)|y|<b
)t(cid:62)0. In fact,

(7.2)

(7.3)

there is some Lévy process X a,b = (X a,b
Lemma 7.1. Let 0 < a < b (cid:54) ∞ and ψa,b given by (7.3). Then the corresponding Lévy process
X a,b is an L2(P)-martingale with càdlàg paths such that

t

E(cid:2)X a,b

(cid:3) = 0 and E(cid:2)X a,b

t

t

· (X a,b
t

)(cid:62)(cid:3) =

(cid:90)

(cid:18)

t

(cid:19)

ykyl ν(dy)

a(cid:54)|y|<b

.

k,l

Proof. Set Xt := X a,b
parameter-dependent integrals we see that ψ is twice continuously differentiable and

, ψ := ψa,b and Ft := σ (Xr, r (cid:54) t). Using the differentiation lemma for

t

∂ψ(0)
∂ξk

= 0 and

∂ 2ψ(0)
∂ξk∂ξl

=

ykyl ν(dy).

a(cid:54)|y|<b

Since the characteristic function e−tψ(ξ ) is twice continuously differentiable, X has ﬁrst and second
moments, cf. Theorem A.2, and these can be obtained by differentiation:

EX (k)

t =

1
i

∂
∂ξk

Eeiξ·Xt

= it

∂ψ(0)
∂ξk

= 0

(cid:90)

(cid:12)(cid:12)(cid:12)(cid:12)ξ =0

44

Chapter 7: Construction of Lévy processes

45

and

E(X (k)

t X (l)
t

) = − ∂ 2
∂ξk∂ξl

Eeiξ·Xt

(cid:12)(cid:12)(cid:12)(cid:12)ξ =0

=

t∂ 2ψ(0)
∂ξk∂ξl

(cid:90)

a(cid:54)|y|<b

= t

− t∂ψ(0)
∂ξk

t∂ψ(0)

∂ξl

ykyl ν(dy).

The martingale property now follows from the independence of the increments: Let s (cid:54) t, then

E(Xt | Fs) = E(Xt − Xs + Xs | Fs) = E(Xt − Xs | Fs) + Xs

(L2)
=
(L1)

E(Xt−s) + Xs = Xs.

We will use the processes from Lemma 7.1 as main building blocks for the Lévy process. For

this we need some preparations.

Lemma 7.2. Let (X k
X := X 1 + X 2 is a Lévy process with characteristic exponent ψ = ψ1 + ψ2.

t )t(cid:62)0 be Lévy processes with characteristic exponents ψk. If X 1⊥⊥X 2, then

:= σ (X k

s , s (cid:54) t) and Ft = σ (F 1

t , F 2

t ). Since X 1⊥⊥X 2, we get for F = F1 ∩ F2,

Proof. Set F k
t
Fk ∈ F k
s ,

(cid:16)

E

eiξ·(Xt−Xs)1F

(cid:17)

(cid:16)
(cid:16)

(cid:17)

= E

eiξ·(X 1
eiξ·(X 1

t −X 1

t −X 1

(cid:17)

(cid:16)
s )1F1 · eiξ·(X 2
s )1F1

t −X 2
eiξ·(X 2

s )1F2
t −X 2

(L2)

E

s )1F2
= E
= e−(t−s)ψ1(ξ )P(F1)· e−(t−s)ψ2(ξ )P(F2)
= e−(t−s)(ψ1(ξ )+ψ2(ξ ))P(F).

(cid:17)

As {F1 ∩ F2 : Fk ∈ F k

s } is a ∩-stable generator of Fs, we ﬁnd

eiξ·(Xt−Xs)(cid:12)(cid:12)(cid:12) Fs
(cid:16)

(cid:17)

E

= e−(t−s)ψ(ξ ).

Observe that Fs could be larger than the canonical ﬁltration F X
w.r.t. E(··· | F X
exponent ψ = ψ1 + ψ2.

s . Therefore, we ﬁrst condition
s ) and then use Theorem 3.1, to see that X is a Lévy process with characteristic

Lemma 7.3. Let (X n)n∈N be a sequence of Lévy processes with characteristic exponents ψn.
Assume that X n

t → Xt converges in probability for every t (cid:62) 0. If

either: the convergence is uniform in probability, i.e.

(cid:18)

(cid:19)

= 0,

|X n
s − Xs| > ε

∀ε > 0 ∀t (cid:62) 0 : lim
n→∞

P

sup
s(cid:54)t

or: the limiting process X has càdlàg paths,

then X is a Lévy process with characteristic exponent ψ := limn→∞ ψn.

46

R. L. Schilling: An Introduction to Lévy and Feller Processes

Proof. Let 0 = t0 < t1 < ··· < tm and ξ1, . . . ,ξm ∈ Rd. Since the X n are Lévy processes,

(cid:34)

(cid:35)

(cid:104)

(cid:105)

Eexp

i

ξk · (X n

tk − X n

tk−1)

m

∑

k=1

(L2),(L1)

=

m

∏

k=1

Eexp

iξk · X n

tk−tk−1

and, because of convergence in probability, this equality is inherited by the limiting process X.
This proves that X has independent (L2(cid:48)) and stationary (L1) increments.

The condition (L3) follows either from the uniformity of the convergence in probability or the

càdlàg property. Thus, X is a Lévy process. From
Eeiξ·X n

lim
n→∞
we get that the limit limn→∞ ψn = ψ exists.

1 = Eeiξ·X1

Lemma 7.4 (Notation of Lemma 7.1). Let (an)n∈N be a sequence a1 > a2 > . . . decreasing to zero
and assume that the processes (X an+1,an)n∈N are independent Lévy processes with characteristic
exponents ψan+1,an. Then X := ∑∞
n=1 ψan+1,an
and càdlàg paths. Moreover, X is an L2(P)-martingale.

n=1 X an+1,an is a Lévy process with exponent ψ := ∑∞

Proof. Lemmas 7.1, 7.2 show that X an+m,an = ∑m
exponent ψan+m,an = ∑m
and Lemma 7.1

k=1 X an+k,an+k−1 is a Lévy process with characteristic
k=1 ψan+k,an+k−1, and X an+m,an is an L2(P)-martingale. By Doob’s inequality

(cid:18)

|X an+m,an
s

|2

E

sup
s(cid:54)t

(cid:19)

(cid:54) 4 E(cid:0)|X an+m,an
(cid:90)

t

|2(cid:1)

= 4t

an+m(cid:54)|y|<an

y2 ν(dy)

−−−−−−−−−→
dom. convergence

m,n→∞

0.

Hence, the limit X = limn→∞ X an,a1 exists (uniformly in t) in L2, i.e. X is an L2(P)-martingale;
since the convergence is also uniform in probability, Lemma 7.3 shows that X is a Lévy process
with exponent ψ = ∑∞
n=1 ψan+1,an. Taking a uniformly convergent subsequence, we also see that
the limit inherits the càdlàg property from the approximating Lévy processes X an,a1.

We can now prove the main result of this chapter.

Theorem 7.5. Let (l,Q,ν) be a Lévy triplet and ψ be given by (7.1). Then there exists a Lévy
process X with càdlàg paths and characteristic exponent ψ.

Proof. Because of Lemma 7.1, 7.2 and 7.4 we can construct X piece by piece.

1◦ Let (Wt)t(cid:62)0 be a Brownian motion and set

X c

t := tl +(cid:112)QWt
n=0 An with A0 := {|y| (cid:62) 1} and An :=(cid:8) 1

and ψc(ξ ) := −il · ξ +

n+1

ξ · Qξ .

1
2
(cid:54) |y| < 1
n

(cid:9); set λn := ν(An)

2◦ Write Rd \{0} =(cid:83)· ∞

and µn := ν(·∩ An)/ν(An).

Chapter 7: Construction of Lévy processes

47

3◦ Construct, as in Example 3.2.d), a compound Poisson process comprising the large jumps

X 0
t

:= X 1,∞

t

and ψ0(ξ ) :=

and compensated compound Poisson processes taking account of all small jumps

X n
t

:= X an+1,an

t

,

an :=

1
n

and ψn(ξ ) :=

(cid:90)

1(cid:54)|y|<∞

(cid:90)

An

(cid:2)1− eiy·ξ(cid:3)ν(dy)
(cid:2)1− eiy·ξ + iy· ξ(cid:3)ν(dy).

We can construct the processes X n stochastically independent (just choose independent jump
time processes and independent iid jump heights when constructing the compound Poisson
processes) and independent of the Wiener process W .

4◦ Setting ψ = ψ0 + ψc + ∑∞

n=1 ψn, Lemma 7.2 and 7.4 prove the theorem. Since all approx-
imating processes have càdlàg paths, this property is inherited by the sums and the limit
(Lemma 7.4).

The proof of Theorem 7.5 also implies the following pathwise decomposition of a Lévy process.

We write ∆Xt := Xt − Xt− for the jump at time t. From the construction we know that

(large jumps)

(small jumps)

(compensated small jumps)

J[1,∞)
t

J[1/n,1)
t

[1/n,1)

(cid:101)Jt

are Lévy processes and J[1,∞)⊥⊥(cid:101)J[1/n,1).

∆Xs1[1,∞)(|∆Xs|)
∆Xs1[1/n,1)(|∆Xs|)

= ∑
s(cid:54)t
= ∑
s(cid:54)t

− EJ[1/n,1)

t

∆Xs1[1/n,1)(|∆Xs|)−t

t

= J[1/n,1)
= ∑
s(cid:54)t

(7.4)

(7.5)

(7.6)

(cid:90)

yν(dy).

(cid:54)|y|<1

1
n

Corollary 7.6. Let ψ be a characteristic exponent given by (7.1) and let X be the Lévy process
constructed in Theorem 7.5. Then

(cid:90)

(cid:19) (cid:21)(cid:21)(cid:21)
(cid:21)(cid:21)(cid:21)

∆Xs1[1/n,1)(|∆Xs|)−t

∑
s(cid:54)t
∆Xs1[1,∞)(|∆Xs|).

[1/n,1)

yν(dy)

=: Mt, L2-martingale

=: At, bdd. variation

Xt =(cid:112)QWt + lim

n→∞

(cid:18)

tl

+ ∑
s(cid:54)t

continuous
Gaussian

pure jump part

where all appearing processes are independent.

Proof. The decomposition follows directly from the construction in Theorem 7.5. By Lemma 7.4,
limn→∞ X 1/n,1 is an L2(P)-martingale, and since the (independent!) Wiener process W is also an
L2(P)-martingale, so is their sum M.

48

R. L. Schilling: An Introduction to Lévy and Feller Processes

The paths t (cid:55)→ At(ω) are a.s. of bounded variation since, by construction, on any time-interval
t (ω) < ∞ a.s., the total variation of At(ω) is less

t (ω) jumps of size (cid:62) 1. Since N0
[0,t] there are N0
or equal than |l|t + ∑s(cid:54)t |∆Xs|1[1,∞)(|∆Xs|) < ∞ a.s.
Remark 7.7. A word of caution: Theorem 7.5 associates with any ψ given by the Lévy–Khintchi-
ne formula (7.1) a Lévy process. Unless we know that all characteristic exponents are of this form
(this was proved in Theorem 6.8), it does not follow that we have constructed all Lévy processes.
On the other hand, Theorem 7.5 shows that the Lévy triplet determining ψ is unique. Indeed,
assume that (l,Q,ν) and (l(cid:48),Q(cid:48),ν(cid:48)) are two Lévy triplets which yield the same exponent ψ. Now
we can associate, using Theorem 7.5, with each triplet a Lévy process X and X(cid:48) such that

Eeiξ·Xt = e−tψ(ξ ) = Eeiξ·X(cid:48)
t .

Thus, X ∼ X(cid:48) and so these processes have (in law) the same pathwise decomposition, i.e. the same
drift, diffusion and jump behaviour. This, however, means that (l,Q,ν) = (l(cid:48),Q(cid:48),ν(cid:48)).

8. Two special Lévy processes

We will now study the structure of the paths of a Lévy process. We begin with two extreme cases:
Lévy processes which only grow by jumps of size 1 and Lévy processes with continuous paths.
Throughout this chapter we assume that all paths [0,∞) (cid:51) t (cid:55)→ Xt(ω) are right-continuous with
ﬁnite left-hand limits (càdlàg).
This is a bit stronger than (L3), but it is always possible to
construct a càdlàg version of a Lévy process (see the discussion on page 13). This allows us to
consider the jumps of the process X

∆Xt := Xt − Xt− = Xt − lim
s↑t

Xs.

Theorem 8.1. Let X be a one-dimensional Lévy process which moves only by jumps of size 1.
Then X is a Poisson process.

Proof. Set F X
t
Since {T1 > t} = {Xt = 0} ∈ F X

t

, T1 is a stopping time.

:= σ (Xs, s (cid:54) t) and let T1 = inf{t > 0 : ∆Xt = 1} be the time of the ﬁrst jump.

Let T0 = 0 and Tk = inf{t > Tk−1 : ∆Xt = 1}, be the time of the kth jump; this is also a stopping

time. By the Markov property ((4.4) and Lemma 4.4),

P(T1 > s +t) = P(T1 > s, T1 > s +t)

= E(cid:2)1{T1>s}PXs(T1 > t)(cid:3)
= E(cid:2)1{T1>s}P0(T1 > t)(cid:3)

= P(T1 > s)P(T1 > t)

where we use that Xs = 0 if T1 > s (the process hasn’t yet moved!) and P = P0.

Since t (cid:55)→ P(T1 > t) is right-continuous, P(T1 > t) = exp[t log P(T1 > 1)] is the unique solution
of this functional equation (Theorem A.1). Thus, the sequence of inter-jump times σk := Tk−Tk−1,
k ∈ N, is an iid sequence of exponential times. This follows immediately from the strong Markov
property (Theorem 4.12) for Lévy processes and the observation that

Tk+1 − Tk = T Y

1 where Y = (Yt+Tk −YTk )t(cid:62)0

and T Y

1 is the ﬁrst jump time of the process Y .

Obviously, Xt = ∑∞

k=1 1[0,t](Tk), Tk = σ1 +··· +σk, and Example 3.2.c) (and Theorem 3.4) show

that X is a Poisson process.

A Lévy process with uniformly bounded jumps admits moments of all orders.

49

50

R. L. Schilling: An Introduction to Lévy and Feller Processes

Lemma 8.2. Let (Xt)t(cid:62)0 be a Lévy process such that |∆Xt(ω)| (cid:54) c for all t (cid:62) 0 and some constant
c > 0. Then E(|Xt|p) < ∞ for all p (cid:62) 0.
Proof. Let F X
t

:= σ (Xs, s (cid:54) t) and deﬁne the stopping times

Since X has càdlàg paths, τ0 < τ1 < τ2 < . . .. Moreover, by the strong Markov property (Theo-
τn−1, i.e. (τn − τn−1)n∈N is an iid sequence. Therefore,
rem 4.12) τn − τn−1 ∼ τ1 and τn − τn−1⊥⊥ F X

τ0 := 0,

τn := inf(cid:8)t > τn−1 : |Xt − Xτn−1| (cid:62) c(cid:9) .
Ee−τn =(cid:0)Ee−τ1(cid:1)n
(cid:0)|∆Xτk|
(cid:124)(cid:123)(cid:122)(cid:125)(cid:54)c

(cid:125)
(cid:124)
+|Xτk− − Xτk−1|

= qn

(cid:123)(cid:122)

(cid:54)c

k=1

(cid:1) (cid:54) 2nc.

for some q ∈ [0,1). From the very deﬁnition of the stoppping times we infer

|Xt∧τn| (cid:54) n
∑

k=1

|Xτk − Xτk−1| (cid:54) n
∑

Thus, |Xt| > 2nc =⇒ τn < t, and by Markov’s inequality

P(|Xt| > 2nc) (cid:54) P(τn < t) (cid:54) et Ee−τn = et qn.

Finally,

E(cid:0)|Xt|p(cid:1) =

∞
∑

n=0

E(cid:0)|Xt|p1{2nc<|Xt|(cid:54)2(n+1)c}(cid:1)

(cid:54) (2c)p

(n + 1)pP(|Xt| > 2nc) (cid:54) (2c)pet

∞
∑

n=0

∞
∑

n=0

(n + 1)pqn < ∞.

Recall that a Brownian motion (Wt)t(cid:62)0 on Rd is a Lévy process such that Wt is a normal random
variable with mean 0 and covariance matrix t id. We will need Paul Lévy’s characterization of
Brownian motion which we state without proof. An elementary proof can be found in [55, Chapter
9.4].

Theorem 8.3 (Lévy). Let M = (Mt, Ft), M0 = 0, be a one-dimensional martingale with contin-
t − t, Ft)t(cid:62)0 is also a martingale. Then M is a one-dimensional
uous sample paths such that (M2
standard Brownian motion.

Theorem 8.4. Let (Xt)t(cid:62)0 be a Lévy process in Rd whose sample paths are a.s. continuous. Then
√
QWt where l ∈ Rd, Q is a positive semideﬁnite symmetric matrix, and W is a standard
Xt ∼ tl +
Brownian motion in Rd.

We will give two proofs of this result.

Proof (using Theorem 8.3). By Lemma 8.2, the process (Xt)t(cid:62)0 has moments of all orders. There-
:= ξ · (Xt − EXt) exists for any ξ ∈ Rd and is a martingale for the canonical
fore, Mt := Mξ
t
ﬁltration Ft := σ (Xs, s (cid:54) t). Indeed, for all s (cid:54) t

E(Mt | Fs) = E(Mt − Ms | Fs)− Ms

(L2)
=
(L1)

EMt−s + Ms = Ms.

Chapter 8: Two special Lévy processes

51

Moreover

E(M2

t − M2

s | Fs)

=

(L2)
=

Lemma 3.10

=

E((Mt − Ms)2 + 2Ms(Mt − Ms) | Fs)
E((Mt − Ms)2) + 2MsE(Mt − Ms)
(t − s)EM2

1 = (t − s)VM1,

and so (M2

t −tVM1)t(cid:62)0 and (Mt)t(cid:62)0 are martingales with continuous paths.

Now we can use Theorem 8.3 and deduce that ξ · (Xt − EXt) is a one-dimensional Brownian
motion with variance ξ · Qξ where tQ is the covariance matrix of Xt (cf. the proof of Lemma 7.1
√
or Lemma 3.10). Thus, Xt − EXt =
QWt where Wt is a d-dimensional standard Brownian motion.
Finally, EXt = tEX1 =: tl.
Standard proof (using the CLT). Fix ξ ∈ Rd and set M(t) := ξ · (Xt − EXt). Since X has moments
of all orders, M is well-deﬁned and it is again a Lévy process. Moreover,

EM(t) = 0 and tσ 2 = VM(t) = E[(ξ · (Xt − EXt))2] = tξ · Qξ

where Q is the covariance matrix of X, cf. the proof of Lemma 7.1. We proceed as in the proof of
the CLT: Using a Taylor expansion we get

(cid:19)n

.

(cid:18)
1− 1
2

(cid:16)
EeiM(t/n)(cid:17)n
n )|.
(cid:19)n
n ) = t

=

EM2(t/n) + Rn
If we can show that |Rn| (cid:54) ε t
nσ 2
= e− 1

2 (σ 2+2ε)t −−−→
ε→0

2 σ 2t.

e− 1

n for large

EeiM(t) = Eei∑n

k=1[M(tk/n)−M(t(k−1)/n)] (L2(cid:48))
=
(L1)
E|M3( t
The remainder term Rn is estimated by 1
6
n = n(ε) and any ε > 0, we get because of EM2( t
t
n

(cid:18)
1− 1
2

EeiM(t) = lim
n→∞

(σ 2 + 2ε)

This shows that ξ · (Xt − EXt) is a centered Gaussian random variable with variance σ 2. Since
EXt = tEX1 we conclude that Xt is Gaussian with mean tl and covariance tQ.

We will now estimate E|M3( t

n )|. For every ε > 0 we can use the uniform continuity of s (cid:55)→ M(s)

on [0,t] to get

Thus, we have for all ε > 0

lim
n→∞

1 = lim
n→∞

= lim
n→∞

(L2)
=
(L1)

lim
n→∞

= lim
n→∞
(cid:54) lim
n→∞

n t)| (cid:54) ε

(cid:17)
n t)| (cid:54) ε(cid:9)(cid:19)

|M( k

nt)− M( k−1

n t)| = 0.

max
1(cid:54)k(cid:54)n

(cid:16)
(cid:18) n(cid:92)

P

P

|M( k

max
1(cid:54)k(cid:54)n

nt)− M( k−1
nt)− M( k−1

(cid:8)|M( k
(cid:2)1− P(|M( t
n )| > ε)(cid:3)n

k=1
P(|M( t

n )| (cid:54) ε)

∏

k=1

n

e−n P(|M(t/n)|>ε) (cid:54) 1

E|M3( t

n )| (cid:54) εEM2( t

(cid:54) ε

t
n

σ 2 +

(cid:113)
|M3( t
n )|dP
n )| > ε)

EM6( t

n ).

|M(t/n)|>ε

P(|M( t

(cid:90)

n ) +

(cid:113)

(cid:115)

52

R. L. Schilling: An Introduction to Lévy and Feller Processes

where we use the inequality 1 + x (cid:54) ex. This proves limn→∞ n P(|M(t/n)| > ε) = 0. Therefore,

It is not hard to see that EM6(s) = a1s +··· + a6s6 (differentiate EeiuM(s) = e−sψ(u) six times at
u = 0), and so

E|M3( t

n )| (cid:54) ε

t
n

σ 2 + c

t
n

P(|M(t/n)| > ε)

t/n

=

t
n

(cid:0)εσ 2 + o(1)(cid:1)

We close this chapter with Paul Lévy’s construction of a standard Brownian motion (Wt)t(cid:62)0.
Since W is a Lévy process which has the Markov property, it is enough to construct a Brownian
motion W (t) only for t ∈ [0,1], then produce independent copies (W n(t))t∈[0,1],n = 0,1,2, . . ., and
join them continuously:

W 0(t),

Wt :=

W 0(1) +··· +W n−1(1) +W n(t − n),

t ∈ [0,1),
t ∈ [n,n + 1).

Since each Wt is normally distributed with mean 0 and variance t, we will get a Lévy process with
2ξ 2, ξ ∈ R. In the same vein we get a d-dimensional Brownian motion
characteristic exponent 1
, . . . ,W (d)
by making a vector (W (1)
)t(cid:62)0 of d independent copies of (Wt)t(cid:62)0. This yields a Lévy
t
1 +··· + ξ 2
d ), ξ1, . . . ,ξd ∈ R.
process with exponent 1
2 (ξ 2

Denote a one-dimensional normal distribution with mean m and variance σ 2 as N(m,σ 2). The
motivation for the construction is the observation that a Brownian motion satisﬁes the following
mid-point law (cf. [55, Chapter 3.4]):

t

P(W(s+t)/2 ∈ • | Ws = x,Wt = y) = N(cid:0) 1

4 (t − s)(cid:1),

2 (x + y), 1

s (cid:54) t, x,y ∈ R.

This can be turned into the following construction method:
Algorithm. Set W (0) = 0 and let W (1) ∼ N(0,1). Let n (cid:62) 1 and assume that the random variables
W (k2−n), k = 1, . . . ,2n − 1 have already been constructed. Then

W (k2−n),
(cid:0)W (k2−n) +W ((k + 1)2−n)(cid:1) + Γ2n+k,

1
2

l = 2k,
l = 2k + 1,

W (l2−n−1) :=

where Γ2n+k is an independent (of everything else) N(0,2−n/4) Gaussia random variable, cf. Fig-
ure 8.1. In-between the nodes we use piecewise linear interpolation:

W2n(t,ω) := Linear interpolation of(cid:0)W (k2−n,ω), k = 0,1, . . . ,2n(cid:1),

n (cid:62) 1.

At the dyadic points t = k2− j we get the ‘true’ value of W (t,ω), while the linear interpolation

is an approximation, see Figure 8.1.

Chapter 8: Two special Lévy processes

53

Figure 8.1.: Interpolation of order four in Lévy’s construction of Brownian motion.

Theorem 8.5 (Lévy 1940). The series

(cid:0)W2n+1(t,ω)−W2n(t,ω)(cid:1) +W1(t,ω),

t ∈ [0,1],

W (t,ω) :=

∞
∑

n=0

converges a.s. uniformly. In particular (W (t))t∈[0,1] is a one-dimensional Brownian motion.
Proof. Set ∆n(t,ω) := W2n+1(t,ω)−W2n(t,ω). By construction,

∆n

(cid:18)

P

(cid:19)

max
1(cid:54)k(cid:54)2n

are iid N(0,2−(n+2)) distributed random variables. Therefore,

(cid:0)(2k− 1)2−n−1,ω) = Γ2n+(k−1)(ω),
(cid:0)(2k− 1)2−n−1(cid:1)(cid:12)(cid:12) >
(cid:12)(cid:12)∆n
(cid:90) ∞
xn
√
(cid:12)(cid:12)∆n
Choose c > 1 and xn := c
2nlog2. Then

xn√
2n+2
(cid:90) ∞
(cid:0)(2k− 1)2−n−1(cid:1)(cid:12)(cid:12) >

e−r2/2 dr (cid:54) 2n+1√
2π

2· 2n√
2π
(cid:18)

and the right-hand side equals

(cid:54) 2nP

r
xn

xn

(cid:19)

∞
∑

n=1

P

max
1(cid:54)k(cid:54)2n

xn√
2n+2

k = 1,2, . . . ,2n,

(cid:16)(cid:12)(cid:12)√

2n+2 ∆n

(cid:0)2−n−1(cid:1)(cid:12)(cid:12) > xn

(cid:17)

,

e−r2/2 dr =

2n+1
√
2π
xn

e−x2

n/2.

(cid:54) ∞
2n+1
√
∑
2π
c
n=1
∞
2
√
∑
2π

=

c

n=1

e−c2 log2n

2−(c2−1)n < ∞.

Using the Borel–Cantelli lemma we ﬁnd a set Ω0 ⊂ Ω with P(Ω0) = 1 such that for every ω ∈ Ω0
there is some N(ω) (cid:62) 1 with

(cid:12)(cid:12)∆n

(cid:0)(2k− 1)2−n−1(cid:1)(cid:12)(cid:12) (cid:54) c

(cid:114)nlog2

2n+1

max
1(cid:54)k(cid:54)2n

for all n (cid:62) N(ω).

Ë12+1()2()()−122−12+12Ë11341214141234154

R. L. Schilling: An Introduction to Lévy and Feller Processes

∆n(t) is the distance between the polygonal arcs W2n+1(t) and W2n(t); the maximum is attained at
one of the midpoints of the intervals [(k− 1)2−n,k2−n], k = 1, . . . ,2n, see Figure 8.1. Thus,

(cid:12)(cid:12)W2n+1(t,ω)−W2n(t,ω)(cid:12)(cid:12) (cid:54) max

1(cid:54)k(cid:54)2n

sup
0(cid:54)t(cid:54)1

for all n (cid:62) N(ω) which means that the limit

W (t,ω) := lim
N→∞

W2N (t,ω) =

∞
∑

n=0

(cid:114)nlog2

2n+1 ,

(cid:0)(2k− 1)2−n−1,ω(cid:1)(cid:12)(cid:12) (cid:54) c

(cid:12)(cid:12)∆n
(cid:0)W2n+1(t,ω)−W2n(t,ω)(cid:1) +W1(t,ω)

exists for all ω ∈ Ω0 uniformly in t ∈ [0,1]. Therefore, t (cid:55)→ W (t,ω), ω ∈ Ω0, inherits the continuity

of the polygonal arcs t (cid:55)→ W2n(t,ω). Set(cid:101)W (t,ω) := W (t,ω)1Ω0(ω).
(cid:101)W (l2−n)−(cid:101)W (k2−n) = W2n(l2−n)−W2n(k2−n)

By construction, we ﬁnd for all 0 (cid:54) k (cid:54) l (cid:54) 2n

(cid:0)W2n(l2−n)−W2n((l − 1)2−n)(cid:1)

=

l

∑

l=k+1

iid∼ N(0, (l − k)2−n).

Since t (cid:55)→ (cid:101)W (t) is continuous and the dyadic numbers are dense in [0,t], we conclude that the
increments (cid:101)W (tk)−(cid:101)W (tk−1), 0 = t0 < t1 < ··· < tN (cid:54) 1 are independent N(0,tk −tk−1) distributed
random variables. This shows that ((cid:101)W (t))t∈[0,1] is a Brownian motion.

9. Random measures

We continue our investigations of the paths of càdlàg Lévy processes. Independently of Chapters 5
and 6 we will show in Theorem 9.12 that the processes constructed in Theorem 7.5 are indeed all
Lévy processes; this gives also a new proof of the Lévy–Khintchine formula, cf. Corollary 9.13.
As before, we denote the jumps of (Xt)t(cid:62)0 by

∆Xt := Xt − Xt− = Xt − lim
s↑t

Xs.

Deﬁnition 9.1. Let X be a Lévy process. The counting measure

Nt(B,ω) := #{s ∈ (0,t] : ∆Xs(ω) ∈ B} , B ∈ B(Rd \{0})

(9.1)

is called the jump measure of the process X.

Since a càdlàg function x : [0,∞) → Rd has on any compact interval [a,b] at most ﬁnitely many

jumps |∆xt| > ε exceeding a ﬁxed size,1 we see that

Nt(B,ω) < ∞ ∀t > 0, B ∈ B(Rd) such that 0 /∈ B.

Notice that 0 /∈ B is equivalent to Bε (0)∩ B = /0 for some ε > 0. Thus, B (cid:55)→ Nt(B,ω) is for every
ω a locally ﬁnite Borel measure on Rd \{0}.
Deﬁnition 9.2. Let Nt(B) be the jump measure of the Lévy process X. For every Borel function
f : Rd → R with 0 /∈ supp f we deﬁne

(cid:90)

Nt( f ,ω) :=

f (y)Nt(dy,ω).

Since 0 /∈ supp f , it is clear that Nt(supp f ,ω) < ∞, and for every ω

Nt( f ,ω) = ∑
0<s(cid:54)t

f (∆Xs(ω)) =

∞
∑

n=1

f (∆Xτn(ω))1(0,t](τn(ω)).

(9.2)

(9.2(cid:48))

(9.3)

Both sums are ﬁnite sums, extending only over those s where ∆Xs(ω) (cid:54)= 0. This is obvious in the
second sum where τ1(ω),τ2(ω),τ3(ω) . . . are the jump times of X.
Lemma 9.3. Let Nt(·) be the jump measure of a Lévy process X, f ∈ Cc(Rd \{0}, Rm) (i.e. f
takes values in Rm), s < t and tk,n := s + k

Nt( f ,ω)− Ns( f ,ω) = ∑
s<u(cid:54)t

n (t − s). Then

f(cid:0)∆Xu(ω)(cid:1) = lim

n→∞

f(cid:0)Xtk+1,n(ω)− Xtk,n(ω)(cid:1).

n−1
∑

k=0

1Otherwise we would get an accumulation point of jumps within [a,b], and x would be unbounded on [a,b].

55

56

R. L. Schilling: An Introduction to Lévy and Feller Processes

Proof. Throughout the proof ω is ﬁxed and we will omit it in our notation. Since 0 /∈ supp f ,
there is some ε > 0 such that Bε (0)∩ supp f = /0; therefore, we need only consider jumps of size
|∆Xt| (cid:62) ε. Denote by J = {τ1, . . . ,τN} those jumps. For sufﬁciently large n we can achieve that

• #(cid:0)J ∩ (tk,n,tk+1,n](cid:1) (cid:54) 1 for all k = 0, . . . ,n− 1;

• |Xtκ+1,n − Xtκ,n| < ε if κ is such that J ∩ (tκ,n,tκ+1,n] = /0.

Indeed: Assume this is not the case, then we could ﬁnd sequences s < sk < tk (cid:54) t such that
tk − sk → 0, J ∩ (sk,tk] = /0 and |Xtk − Xsk| (cid:62) ε. Without loss of generality we may assume
that sk ↑ u and tk ↓ u for some u ∈ (s,t]; u = s can be ruled out because of right-continuity.
By the càdlàg property of the paths, |∆Xu| (cid:62) ε, i.e. u ∈ J, which is a contradiction.

Since we have f (Xtκ+1,n −Xtκ,n) = 0 for intervals of the ‘second kind’, only the intervals containing
some jump contribute to the (ﬁnite!) sum (9.3), and the claim follows.
Lemma 9.4. Let Nt(·) be the jump measure of a Lévy process X.

a) (Nt( f ))t(cid:62)0 is for all f ∈ Cc(Rd \{0}, Rm) a Lévy process on Rm.
b) (Nt(B))t(cid:62)0 is for all B ∈ B(Rd) such that 0 /∈ B a Poisson process.
c) ν(B) := EN1(B) is a locally ﬁnite measure on Rd \{0}.

Proof. Set Ft := σ (Xs, s (cid:54) t).
a) Let f ∈ Cc(Rd \{0}, Rm). From Lemma 9.3 and (L2(cid:48)) we see that Nt( f ) is Ft measurable
and Nt( f )− Ns( f )⊥⊥ Fs, s (cid:54) t. Moreover, if NY
t (·) denotes the jump measure of the Lévy process
Y = (Xt+s− Xs)t(cid:62)0, we see that Nt( f )− Ns( f ) = NY
t−s( f ). By the Markov property (Theorem 4.6),
X ∼ Y , and we get NY
t−s( f ) ∼ Nt−s( f ). Since t (cid:55)→ Nt( f ) is càdlàg, (Nt( f ))t(cid:62)0 is a Lévy process.
b) By deﬁnition, N0(B) = 0 and t (cid:55)→ Nt(B) is càdlàg, i.e. the conditions (L0) and (L3) are clearly
fulﬁlled. Let us show that for all 0 (cid:54) s < t and B ∈ B(Rd) such that 0 /∈ B

Nt(B) is Ft measurable, Nt(B)− Ns(B)⊥⊥ Fs

(9.4)
If B = K, 0 /∈ K, is a compact set, we can ﬁnd a sequence fn ∈ Cc(Rd \{0}) such that fn ↓ 1K.

and Nt(B)− Ns(B) ∼ Nt−s(B).

For example,

fn(x) :=

|x− a|, Un := {y : d(y,K) < 1/n},
where n is so large that B2/n(0)∩ K = /0. Thus we get (9.4) from a) by approximation of

d(x,K) + d(x,U c
n )

d(x,U c
n )

,

d(x,A) := inf
a∈A

Nt(K)− Ns(K) = lim
n→∞

(Nt( fn)− Ns( fn)).

Let Dn := {B ∈ B(Rd \ B1/n(0)) : (9.4) holds}. Then Dn is a Dynkin system containing all
compact sets (cf. b)) of Rd \ B1/n(0). Therefore, it coincides with the σ-algebra B(Rd \ B1/n(0))
generated by the compact sets.

Chapter 9: Random measures

57

The condition 0 /∈ B ensures that B ∈ Dn for some n as well as Nt(B) < ∞ a.s. Since Nt(B) is a

Lévy process which has only jumps of size 1, it is a Poisson process, cf. Theorem 8.1.

c) The intensity of (Nt(B))t(cid:62)0 is ν(B) = EN1(B). By Fubini’s theorem it is clear that ν is a
measure, and for all ε > 0

P(Nt(B) > ε) (cid:54) 1− e−tν(B) −−→
t→0

0

shows that ν(B) < ∞.
Deﬁnition 9.5. Let Nt(·) be the jump measure of a Lévy process X. The intensity measure is the
measure ν(B) := EN1(B) from Lemma 9.4.

We will see in Corollary 9.13 that ν is the Lévy measure of (Xt)t(cid:62)0 appearing in the Lévy–

Khintchine formula.
Lemma 9.6. Let Nt(·) be the jump measure of a Lévy process X and ν the intensity measure. For

every f ∈ L1(ν), f : Rd → Rm, the random variable Nt( f ) :=(cid:82) f (y)Nt(dy) exists as L1-limit of

integrals of simple functions and satisﬁes

(cid:90)

(cid:90)

y(cid:54)=0

ENt( f ) = E

f (y)Nt(dy) = t

f (y)ν(dy).

(9.5)

Proof. For any step function f of the form f (y) = ∑m
follows from ENt(Bk) = tν(Bk) and the linearity of the integral.

k=1 fk1Bk (y) with 0 /∈ Bk the formula (9.5)

Since ν is deﬁned on Rd \ {0}, any f ∈ L1(ν) can be approximated by a sequence of step

functions ( fn)n∈N in L1(ν)-sense, and we get
E|Nt( fn)− Nt( fm)| (cid:54) t

(cid:90)

| fn − fm|dν −−−−→
m,n→∞

0.

Because of the completeness of L1(P), the limit limn→∞ Nt( fn) exists, and with a routine argument
we see that it is independent of the approximating sequence fn → f ∈ L1(ν). This allows us to
deﬁne Nt( f ) for f ∈ L1(ν) as L1(P)-limit of stochastic integrals of simple functions; obviously,
(9.5) is preserved under this limiting procedure.
Theorem 9.7. Let Nt(·) be the jump measure of a Lévy process X and ν the intensity measure.

a) Nt( f ) :=(cid:82) f (y)Nt(dy) is a Lévy process for every f ∈ L1(ν), f : Rd → Rm.

b) X B
t

:= Nt(y1B(y)) and Xt − X B

t are for every B ∈ B(Rd), 0 /∈ B, Lévy processes.

Proof. a) Note that ν is a locally ﬁnite measure on Rd \{0}. This means that, by standard density
results from integration theory, the family Cc(Rd \ {0}) is dense in L1(ν). Fix f ∈ L1(ν) and
choose fn ∈ Cc(Rd \{0}) such that fn → f in L1(ν). Then, as in Lemma 9.6,

(cid:90)

E|Nt( f )− Nt( fn)| (cid:54) t

| f − fn|dν −−−→
n→∞

0.

58

R. L. Schilling: An Introduction to Lévy and Feller Processes

(cid:82) | f|dν → 0 for every ε > 0 as t → 0, the process Nt( f ) is continuous

Since P(|Nt( f )| > ε) (cid:54) t
ε
in probability. Moreover, it is the limit (in L1, hence in probability) of the Lévy processes Nt( fn)
(Lemma 9.4); therefore it is itself a Lévy process, see Lemma 7.3.
b) Set f (y) := y1B(y) and Bn := B∩ Bn(0). Then fn(y) = y1Bn(y) is bounded and 0 /∈ supp fn,
hence fn ∈ L1(ν). This means that Nt( fn) is for every n ∈ N a Lévy process. Moreover,

(cid:90)

B

yNt(dy) = Nt( f )

a.s.

(cid:90)

Nt( fn) =

yNt(dy) −−−→
n→∞

Bn

Since Nt( f ) changes its value only by jumps,

P(|Nt( f )| > ε) (cid:54) P(X has at least one jump of size B in [0,t])

= P(Nt(B) > 0) = 1− e−tν(B),

which proves that the process Nt( f ) is continuous in probability. Lemma 7.3 shows that Nt( f ) is a
Lévy process.

Finally, approximate f (y) := y1B(y) by a sequence φl ∈ Cc(Rd \{0}, Rd). Now we can use

Lemma 9.3 to get

Xt − Nt(φl) = lim
n→∞

n−1
∑

k=0

(cid:2)(Xtk+1,n − Xtk,n)− φl(Xtk+1,n − Xtk,n)(cid:3),

The increments of X are stationary and independent, and so we conclude from the above for-
mula that X − N(φl) has also stationary and independent increments. Since both X and N(φl) are
continuous in probability, so is their difference, i.e. X − N(φl) is a Lévy process. Finally,

Nt(φl) −−→
l→∞

Nt( f )

and Xt − Nt(φl) −−→
l→∞

Xt − Nt( f ),

and since X and N( f ) are continuous in probability, Lemma 7.3 tells us that X − N( f ) is a Lévy
process.

We will now show that Lévy processes with ‘disjoint jump heights’ are independent. For this

we need the following immediate consequence of Theorem 3.1:

Lemma 9.8 (Exponential martingale). Let (Xt)t(cid:62)0 be a Lévy process. Then

Mt :=

= eiξ·Xt etψ(ξ ),

eiξ·Xt
Eeiξ·Xt
t = σ (Xs, s (cid:54) t) such that sups(cid:54)t |Ms| (cid:54) et Reψ(ξ ).

t (cid:62) 0,

is a martingale for the ﬁltration F X
Theorem 9.9. Let Nt(·) be the jump measure of a Lévy process X and U,V ∈ B(Rd), 0 /∈ U,0 /∈ V
and U ∩V = /0. Then the processes

XU
t

:= Nt(y1U (y)), XV
t

:= Nt(y1V (y)), Xt − XU∪V

t

are independent Lévy processes in Rd.

Chapter 9: Random measures

59

Proof. Set W := U ∪V . By Theorem 9.7, XU ,XV and X −XW are Lévy processes. In fact, a slight
variation of that argument even shows that (XU ,XV ,X − XW ) is a Lévy process in R3d.

In order to see their independence, ﬁx s > 0 and deﬁne for t > s and ξ ,η,θ ∈ Rd the processes

eiξ·(XU

E(cid:2)eiξ·(XU

t −XU
s )
t −XU

Ct :=

s )(cid:3) − 1,
E(cid:2)eiθ·(Xt−XW

eiθ·(Xt−XW

Dt :=

t −Xs+XW
s )
t −Xs+XW

eiη·(XV

E(cid:2)eiη·(XV
s )(cid:3) − 1.

s )(cid:3) − 1,

t −XV
s )
t −XV

Et :=

By Lemma 9.8, these processes are bounded martingales satisfying ECt = EDt = EEt = 0. Set
tk,n = s + k

(cid:32) n−1
n (t − s). Observe that
(cid:32)n−1

E(CtDtEt) = E

∑

k,l,m=0

(cid:33)
(Ctk+1,n −Ctk,n)(Dtl+1,n − Dtl,n)(Etm+1,n − Etm,n)
(cid:33)
(Ctk+1,n −Ctk,n)(Dtk+1,n − Dtk,n)(Etk+1,n − Etk,n)

.

= E

∑

k=0

In the second equality we use that martingale increments Ct −Cs,Dt − Ds,Et − Es are independent
of F X

s , and by the tower property

An argument along the lines of Lemma 9.3 gives

E(cid:2)(Ctk+1,n −Ctk,n)(Dtl+1,n − Dtl,n)(Etm+1,n − Etm,n)(cid:3) = 0
(cid:19)
(cid:125)

E(CtDtEt) = E

∆Cu ∆Du ∆Eu

(cid:18)

unless k = l = m.

cannot jump simultaneously since U, V and Rd \W are mutually

, XV

as XU
t
disjoint. Thus,

t

t and Yt := Xt − XW
(cid:104)

eiξ·(XU

(cid:104)

E

= E

t −XU
eiξ·(XU

s )eiη·(XV
t −XU

=0

= 0

t −XV

∑
s<u(cid:54)t

(cid:123)(cid:122)
(cid:124)
s )eiθ·(Yt−Ys)(cid:105)
(cid:104)
s )(cid:105)· E
eiθ·(Yt−Ys)(cid:105)
(cid:104)
s )(cid:105)· E
)ei∑k θk·(Ytk+1−Ytk )(cid:17)

eiη·(XV

t −XV

−XV
tk

tk+1

.

(9.6)

Since all processes are Lévy processes, (9.6) already proves the independence of XU, XV and
Y = X − XW . Indeed, we ﬁnd for 0 = t0 < t1 < . . . < tm = t and ξk,ηk,θk ∈ Rd

(cid:16)

ei∑k ξk·(XU

tk+1

−XU
tk

E

(cid:16)

tk+1

)ei∑k ηk·(XV
eiξk·(XU
∏
k
eiξk·(XU
eiξk·(XU

(cid:16)
(cid:16)

tk+1

tk+1

= E

(L2(cid:48))
= ∏
k
(9.6)
= ∏
k

E

E

)eiθk·(Ytk+1−Ytk )(cid:17)
)eiθk·(Ytk+1−Ytk )(cid:17)
(cid:16)
)(cid:17)
eiθk·(Ytk+1−Ytk )(cid:17)

−XV
tk

E

.

−XU
tk

)eiηk·(XV
)eiηk·(XV

−XV
tk

tk+1

−XV
tk

tk+1

−XU
tk

−XU
tk

)(cid:17)

(cid:16)

eiηk·(XV

tk+1

E

The last equality follows from (9.6); the second equality uses (L2(cid:48)) for the Lévy process

(XU

t ,XV

t ,Xt − XW
t ).

60

R. L. Schilling: An Introduction to Lévy and Feller Processes

This shows that the families (XU
t , t (cid:62) 0), σ (XV

tk )k, (XV

tk+1 −XU
t , t (cid:62) 0) and σ (Xt − XW

tk+1 −XV

the σ-algebras σ (XU
Corollary 9.10. Let Nt(·) be the jump measure of a Lévy process X and ν the intensity measure.

, t (cid:62) 0) are independent.

t

tk )k and (Ytk+1 −Ytk )k are independent, hence

a) (Nt(U))t(cid:62)0⊥⊥(Nt(V ))t(cid:62)0 for U,V ∈ B(Rd), 0 /∈ U, 0 /∈ V , U ∩V = /0.
b) For all measurable f : Rd → Rm satisfying f (0) = 0 and f ∈ L1(ν)
(cid:90)

(cid:16)
eiξ·Nt ( f )(cid:17)
(cid:0)|y|2 ∧ 1(cid:1) ν(dy) < ∞.

(cid:16)
ei(cid:82) ξ· f (y)Nt (dy)(cid:17)

(cid:16)
y(cid:54)=0[1−eiξ· f (y)]ν(dy)(cid:17)
e−t(cid:82)

= E

= E

c)

E

y(cid:54)=0

.

(9.7)

t )t(cid:62)0 and (XV

Proof. a) Since (Nt(U))t(cid:62)0 and (Nt(V ))t(cid:62)0 are completely determined by the independent pro-
cesses (XU
b) Let us ﬁrst prove (9.7) for step functions f (x) = ∑n
U1, . . . ,Un ∈ B(Rd) such that 0 (cid:54)∈ U k. Then

t )t(cid:62)0, cf. Theorem 9.9, the independence is clear.

k=1 fk1Uk (x) with fk ∈ Rm and disjoint sets
(cid:20)

(cid:21)

(cid:20)

n

(cid:90)

(cid:90)

(cid:21)
ξ · fk1Uk (y)Nt(dy)

= Eexp

Eexp

i

ξ · f (y)Nt(dy)

i

∑

k=1

a)
=

9.4.b)
=

n

∏

k=1

n

∏

k=1

= exp

= exp

exp

Eexp [iξ · fk Nt(Uk)]

tν(Uk)(cid:2)eiξ· fk − 1(cid:3)(cid:105)
(cid:104)
(cid:21)
(cid:2)eiξ· fk − 1(cid:3)ν(Uk)
(cid:21)
(cid:90) (cid:2)1− eiξ· f (y)(cid:3)ν(dy)

n

t

∑
k=1
−t

(cid:20)
(cid:20)

.

For any f ∈ L1(ν) the integral on the right-hand side of (9.7) exists.
inequality |1− eiu| (cid:54) |u|∧ 2 and ν{|y| (cid:62) 1} < ∞ (Corollary 9.4.c)) yield
(cid:90)

(cid:12)(cid:12)(cid:12)(cid:12) (cid:54) |ξ|
(cid:2)1− eiξ· f (y)(cid:3)ν(dy)

| f (y)|ν(dy) + 2

0<|y|<1

(cid:90)

|y|(cid:62)1

Indeed, the elementary

ν(dy) < ∞.

Therefore, (9.7) follows with a standard approximation argument and dominated convergence.
c) We have already seen in Corollary 9.4.c) that ν{|y| (cid:62) 1} < ∞.

0<|y|<1|y|2 ν(dy) < ∞. For this we take U = {δ < |y| < 1}. Again by Theo-

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)
Let us show that(cid:82)

y(cid:54)=0

rem 9.9, the processes XU

Since XU
t

is a compound Poisson process—use part b) with f (y) = y1U (y)—we get for all |ξ| (cid:54) 1

t are independent, and we get

t and Xt − XU

0 <(cid:12)(cid:12)Eeiξ·Xt(cid:12)(cid:12) =(cid:12)(cid:12)Eeiξ·XU
0 <(cid:12)(cid:12)Eeiξ·XU

t (cid:12)(cid:12)·(cid:12)(cid:12)Eeiξ·(Xt−XU
U (1−cosξ·y)ν(dy) (cid:54) e−t(cid:82)

t (cid:12)(cid:12) = e−t(cid:82)

t )(cid:12)(cid:12) (cid:54)(cid:12)(cid:12)Eeiξ·XU
t (cid:12)(cid:12).

δ <|y|(cid:54)1

1

4 (ξ·y)2 ν(dy).

Chapter 9: Random measures

61

For the equality we use |ez| = eRez, the inequality follows 1

4u2 (cid:54) 1−cosu if |u| (cid:54) 1. Letting δ → 0

we see that(cid:82)

0<|y|<1|y|2 ν(dy) < ∞.

Corollary 9.11. Let Nt(·) be the jump measure of a Lévy process X and ν the intensity measure.
For all f : Rd → Rm satisfying f (0) = 0 and f ∈ L2(ν) we have2

(cid:18)(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)

E

f (y)(cid:2)Nt(dy)−tν(dy)(cid:3)(cid:12)(cid:12)(cid:12)(cid:12)2(cid:19)

(cid:90)

= t

y(cid:54)=0

| f (y)|2 ν(dy).

(9.8)

Proof. It is clearly enough to show (9.8) for step functions of the form

f (x) =

n

∑

k=1

fk1Bk (x), Bk disjoint, 0 (cid:54)∈ Bk, fk ∈ Rm,

and then use an approximation argument.

Since the processes Nt(Bk,·) are independent Poisson processes with mean ENt(Bk) = tν(Bk)

and variance VNt(Bk) = tν(Bk), we ﬁnd

Therefore,

if Bk ∩ Bl = /0, i.e. k (cid:54)= l,
if k = l,



=

VNt(Bk) = tν(Bk),

E(cid:2)(Nt(Bk)−tν(Bk))(Nt(Bl)−tν(Bl))(cid:3)
 0,
f (y)(cid:0)Nt(dy)−tν(dy)(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)2(cid:19)
(cid:18)(cid:90)(cid:90)

= tν(Bk ∩ Bl).

(cid:18)(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)

E

f (y) f (z)(cid:0)Nt(dy)−tν(dy)(cid:1)(cid:0)Nt(dz)−tν(dz)(cid:1)(cid:19)
(cid:16)(cid:0)Nt(Bk)−tν(Bk)(cid:1)(cid:0)Nt(Bl)−tν(Bl)(cid:1)(cid:17)
(cid:125)
(cid:124)

(cid:123)(cid:122)

fk fl E

= E

=

n

∑

k,l=1

(cid:90)

=tν(Bk∩Bl )
| f (y)|2 ν(dy).

= t

n

∑

k=1

| fk|2 ν(Bk) = t

In contrast to Corollary 7.6 the following theorem does not need (but constructs) the Lévy triplet

(l,Q,ν).
Theorem 9.12 (Lévy–Itô decomposition). Let X be a Lévy process and denote by Nt(·) and ν the

2This is a special case of an Itô isometry, cf. (10.8) in the following chapter.

62

R. L. Schilling: An Introduction to Lévy and Feller Processes

jump and intensity measures. Then

Xt =(cid:112)QWt +

(cid:90)
(cid:90)

tl

+

continuous
Gaussian

y(cid:0)Nt(dy)−tν(dy)(cid:1) (cid:21)(cid:21)(cid:21)
(cid:21)(cid:21)(cid:21)

0<|y|<1

yNt(dy).

|y|(cid:62)1

pure jump part

=: Mt, L2-martingale

=: At, bdd. variation

(9.9)

where l ∈ Rd and Q ∈ Rd×d is a positive semideﬁnite symmetric matrix and W is a standard
Brownian motion in Rd. The processes on the right-hand side of (9.9) are independent Lévy
processes.
Proof. 1◦ Set Un := { 1

n < |y| < 1}, V = {|y| (cid:62) 1}, Wn := Un ∪· V and deﬁne
(cid:90)

(cid:90)

XV
t

:=

V

t )t(cid:62)0, ((cid:101)XUn

yNt(dy)

t

:=

and

yNt(dy)−t

(cid:90)
(cid:101)XUn
t )t(cid:62)0 and(cid:0)Xt − XWn
Un yν(dy)(cid:1)
t + t(cid:82)
X = (X −(cid:101)XUn − XV ) +(cid:101)XUn + XV ,

Un

By Theorem 9.9 (XV
cesses. Since

yν(dy).

Un

t(cid:62)0 are independent Lévy pro-

the theorem follows if we can show that the three terms on the right-hand side converge separately
as n → ∞.

2◦ Lemma 9.6 shows E(cid:101)XUn

t = 0; since (cid:101)XUn is a Lévy process, it is a martingale: for s (cid:54) t
(cid:16)(cid:101)XUn

(cid:12)(cid:12)(cid:12) Fs
(cid:16)(cid:101)XUn
(cid:17)
t −(cid:101)XUn
+(cid:101)XUn
(cid:16)(cid:101)XUn
(cid:17)
+(cid:101)XUn
s =(cid:101)XUn

(cid:12)(cid:12)(cid:12) Fs

(cid:17)

= E

t−s

E

.

s

s

s

t

(L2)
=
(L1)

E

(Fs can be taken as the natural ﬁltration of XUn or X). By Doob’s L2 martingale inequality we ﬁnd
for any t > 0 and m < n

E

(cid:18)

(cid:12)(cid:12)2(cid:19)

sup
s(cid:54)t

(cid:12)(cid:12)(cid:101)XUn
s −(cid:101)XUm

(cid:12)(cid:12)2(cid:17)
(cid:16)(cid:12)(cid:12)(cid:101)XUn
t −(cid:101)XUm
(cid:54) 4E
(cid:90)
0<|y|<1 y(cid:0)Nt(dy)− tν(dy)(cid:1) = L2-limn→∞(cid:101)XUn

n <|y|(cid:54) 1

= 4t

m

s

1

t

|y|2 ν(dy) −−−−→
m,n→∞

0.

Therefore, the limit(cid:82)

exists locally uniformly (in t).
The limit is still an L2 martingale with càdlàg paths (take a locally uniformly a.s. convergent
subsequence) and, by Lemma 7.3, also a Lévy process.
3◦ Observe that

(X −(cid:101)XUn − XV )− (X −(cid:101)XUm − XV ) =(cid:101)XUm −(cid:101)XUn,

t

Chapter 9: Random measures

:= L2-limn→∞(Xt −(cid:101)XUn
t − XV

and so X c
t

|∆(Xt −(cid:101)XUn

t − XV

t )| (cid:54) 1

t ) exists locally uniformly (in t) Since, by construction
n, it is clear that X c has a.s. continuous sample paths. By Lemma 7.3 it
is a Lévy process. From Theorem 8.4 we know that all Lévy processes with continuous sample
√
QWt where W is a Brownian motion, Q ∈ Rd×d a symmetric positive
paths are of the form tl +
semideﬁnite matrix and l ∈ Rd.
4◦ Since independence is preserved under L2-limits, the decomposition (9.9) follows. Finally,

63

yNt(dy,ω) = ∑
0<s(cid:54)t

∆Xs(ω)1{∆Xs(ω)(cid:62)1} − ∑
0<s(cid:54)t

|∆Xs(ω)|1{∆Xs(ω)(cid:54)−1}

|y|(cid:62)1

(cid:90)

is the difference of two increasing processes, i.e. it is of bounded variation.

Corollary 9.13 (Lévy–Khintchine formula). Let X be a Lévy process. Then the characteristic
exponent ψ is given by

(cid:90)

(cid:104)
(cid:105)
1− eiy·ξ + iξ · y1(0,1)(|y|)

ν(dy)

(9.10)

ψ(ξ ) = −il · ξ +

ξ · Qξ +

1
2

y(cid:54)=0

where ν is the intensity measure, l ∈ Rd and Q ∈ Rd×d is symmetric and positive semideﬁnite.

Proof. Since the processes appearing in the Lévy–Itô decomposition (9.9) are independent, we
see

QW1) · Eei(cid:82)

0<|y|<1 ξ·y(N1(dy)−ν(dy)) · Eei(cid:82)|y|(cid:62)1 ξ·yN1(dy).

√
e−ψ(ξ ) = Eeiξ·X1 = Eeiξ·(−l+
Since W is a standard Brownian motion,
√
QW1) = eil·ξ− 1
Eeiξ·(l+

Using (9.7) with f (y) = y1Un(y), Un = { 1
we get

(cid:20)

(cid:90)

Eexp

i

0<|y|<1

ξ · y(N1(dy)− ν(dy))

2 ξ·Qξ .

n < |y| < 1}, subtracting(cid:82)
(cid:21)
(cid:104)

(cid:20)

(cid:90)

= exp

−

0<|y|<1

Un yν(dy) and letting n → ∞

(cid:105)

(cid:21)

1− eiy·ξ + iξ · y

ν(dy)

;

ﬁnally, (9.7) with f (y) = y1V (y), V = {|y| (cid:62) 1}, once again yields

(cid:90)

(cid:20)

i

|y|(cid:62)1

(cid:21)

(cid:20)

(cid:90)

1− eiy·ξ(cid:105)
(cid:104)

(cid:21)

ν(dy)

ξ · yN1(dy)

= exp

−

|y|(cid:62)1

Eexp

ﬁnishing the proof.

10. A digression: stochastic integrals

In this chapter we explain how one can integrate with respect to (a certain class of) random mea-
sures. Our approach is based on the notion of random orthogonal measures and it will include
the classical Itô integral with respect to square-integrable martingales. Throughout this chapter,
(Ω, A , P) is a probability space, (Ft)t(cid:62)0 some ﬁltration, (E, E ) is a measurable space and µ is
a (positive) measure on (E, E ). Moreover, R ⊂ E is a semiring, i.e. a family of sets such that
/0 ∈ R, for all R,S ∈ R we have R ∩ S ∈ R, and R \ S can be represented as a ﬁnite union of
disjoint sets from R, cf. [53, Chapter 6] or [54, Deﬁnition 5.1]. It is not difﬁcult to check that
R0 := {R ∈ R : µ(R) < ∞} is again a semiring.
Deﬁnition 10.1. Let R be a semiring on the measure space (E, E , µ). A random orthogonal
measure with control measure µ is a family of random variables N(ω,R) ∈ R, R ∈ R0, such that
(10.1)
(10.2)

E(cid:2)|N(·,R)|2(cid:3) < ∞ ∀R ∈ R0

E [N(·,R)N(·,S)] = µ(R∩ S) ∀R,S ∈ R0.

The following Lemma explains why N(R) = N(ω,R) is called a (random) measure.

Lemma 10.2. The random set function R (cid:55)→ N(R) := N(ω,R), R ∈ R0, is countably additive in
L2, i.e.

N

Rn

for every sequence (Rn)n∈N ⊂ R0 of mutually disjoint sets such that R :=(cid:83)· ∞

In
particular, N(R∪· S) = N(R) + N(S) a.s. for disjoint R,S ∈ R0 such that R∪· S ∈ R0 and N(/0) = 0
a.s. (notice that the exceptional set may depend on the sets R,S).

n=1 Rn ∈ R0.

N(Rk) a.s.

= L2- lim
n→∞

(10.3)

n=1

n

∑

k=1

(cid:33)

(cid:32) ∞(cid:91)·

Proof. From R = S = /0 and E[N(/0)2] = µ(/0) = 0 we get N(/0) = 0 a.s. It is enough to prove (10.3)
as ﬁnite additivity follows if we take (R1,R2,R3,R4 . . . ) = (R,S, /0, /0, . . . ). If Rn ∈ R0 are mutually

disjoint sets such that R :=(cid:83)· ∞

(cid:34)(cid:16)

E

N(R)− n
∑

k=1

N(Rk)

n=1 Rn ∈ R0, then

(cid:17)2(cid:35)

n

∑

j(cid:54)=k, j,k=1

E [N(R j)N(Rk)]

= EN2(R) +

n

∑

k=1

EN2(Rk)− 2

n

∑

k=1

E [N(R)N(Rk)] +

(10.2)

= µ(R)− n
∑

k=1

µ(Rk) −−−→
n→∞

0

where we use the σ-additivity of the measure µ.

64

Chapter 10: A digression: stochastic integrals

65

(White noise) Let R = {(s,t] : 0 (cid:54) s < t < ∞} and µ = λ be Lebesgue
Example 10.3. a)
measure on (0,∞). Clearly, R = R0 is a semiring. Let W = (Wt)t(cid:62)0 be a one-dimensional standard
Brownian motion. The random set function

N(ω, (s,t]) := Wt(ω)−Ws(ω),

0 (cid:54) s < t < ∞

is a random orthogonal measure with control measure λ . This follows at once from

E(cid:2)(Wt −Ws)(Wv −Wu)(cid:3) = t ∧ v− s∨ u = λ(cid:2)(s,t]∩ (u,v](cid:3)

for all 0 (cid:54) s < t < ∞ and 0 (cid:54) u < v < ∞.

and observe that(cid:83)· n Rn = (0,1]. Since W has stationary and independent increments, and scales
Mind, however, that N is not σ-additive. To see this, take Rn := (1/(n + 1),1/n], where n ∈ N,
like Wt ∼ √

tW1, we have

Eexp(cid:2)−∑∞

n=1|N(Rn)|(cid:3) = Eexp(cid:2)−∑∞

n=1|W1/(n+1) −W1/n|(cid:3)
(cid:104)−(n(n + 1))−1/2|W1|(cid:105)

Eexp

n=1

= ∏∞
Jensen’s(cid:54)
ineq. ∏∞

n=1 α (n(n+1))−1/2

, α := Ee−|W1| ∈ (0,1).

n=1(n(n + 1))−1/2 diverges, we get Eexp [−∑∞

n=1|N(Rn)|] = 0 which means that
As the series ∑∞
n=1|N(ω,Rn)| = ∞ for almost all ω. This shows that N(·) cannot be countably additive. Indeed,
∑∞
countable additivity implies that the series

(cid:32)

(cid:33)

∞(cid:91)

n=1

N

ω,

Rn

=

∞
∑

n=1

N(ω,Rn)

converges. The left-hand side, hence the summation, is independent under rearrangements. This,
n=1|N(ω,Rn)| < ∞ which does not hold as
however, entails absolute convergence of the series ∑∞
we have seen above.

b) (Martingale noise) Let M = (Mt)t(cid:62)0 be a square-integrable martingale with respect to the ﬁl-
tration (Ft)t(cid:62)0, M0 = 0, and with càdlàg paths. Denote by (cid:104)M(cid:105) the predictable quadratic variation,
i.e. the unique ((cid:104)M(cid:105)0 := 0) increasing predictable process such that M2−(cid:104)M(cid:105) is a martingale. The
random set function

N(ω, (s,t]) := Mt(ω)− Ms(ω),

s (cid:54) t,

is a random orthogonal measure on R = {(s,t] : 0 (cid:54) s < t < ∞} with control measure

µ(s,t] = E((cid:104)M(cid:105)t −(cid:104)M(cid:105)s).

This follows immediately from the tower property of conditional expectation
if t (cid:54) v

= E[Mt E(Mv | Ft)] = E[M2

t ] = E(cid:104)M(cid:105)t

E[MtMv]

tower

66

R. L. Schilling: An Introduction to Lévy and Feller Processes

which, in turn, gives for all 0 (cid:54) s < t and 0 (cid:54) u < v

E[(Mt − Ms)(Mv − Mu)] = E(cid:104)M(cid:105)t∧v − E(cid:104)M(cid:105)s∧v − E(cid:104)M(cid:105)t∧u + E(cid:104)M(cid:105)s∧u

= µ(cid:0)(s,t]∩ (0,v](cid:1)− µ(cid:0)(s,t]∩ (0,u](cid:1)
= µ(cid:0)(s,t]∩ (u,v](cid:1).

c) (Poisson random measure) Let X be a d-dimensional Lévy process,

S :=(cid:8)B ∈ B(Rd) : 0 /∈ B(cid:9), R :=(cid:8)(s,t]× B : 0 (cid:54) s < t < ∞, B ∈ S(cid:9),
(cid:101)N(ω, (s,t]× B) := [Nt(ω,B)−tν(B)]− [Ns(ω,B)− sν(B)], R = (s,t]× B ∈ R,

and Nt(B) the jump measure (Deﬁnition 9.1). The random set function

is a random orthogonal measure with control measure λ × ν where λ is Lebesgue measure on
(0,∞) and ν is the Lévy measure of X. Indeed, by deﬁnition R = R0, and it is not hard to see that
R is a semiring1.

Set(cid:101)Nt(B) :=(cid:101)N((0,t]× B) and let B,C ∈ S , t,v (cid:62) 0. As in the proof of Corollary 9.11 we have

E(cid:2)(cid:101)Nt(B)(cid:101)Nt(C)(cid:3) = tν(B∩C).

Since S is a semiring, we get B = (B∩C)∪· (B\C) = (B∩C)∪· B1 ∪· ···∪· Bn with ﬁnitely many
The processes (cid:101)N(Bk) and (cid:101)N(C) are independent (Corollary 9.10) and centered. Therefore we
mutually disjoint Bk ∈ S such that Bk ⊂ B\C.

have for t (cid:54) v

E(cid:2)(cid:101)Nt(B)(cid:101)Nv(C)(cid:3) = E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nv(C)(cid:3) +
= E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nv(C)(cid:3) +
= E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nv(C)(cid:3).

n

∑

k=1

n

∑

k=1

E(cid:2)(cid:101)Nt(Bk)(cid:101)Nv(C)(cid:3)
E(cid:101)Nt(Bk)· E(cid:101)Nv(C)

Use the same argument over again, as well as the fact that(cid:101)Nt(B∩C) has independent and centered

increments (Lemma 9.4), to get

(cid:123)
(cid:122)
=E(cid:101)Nt (B∩C) E[(cid:101)Nv(B∩C)−(cid:101)Nt (B∩C)]=0
E(cid:2)(cid:101)Nt(B∩C)(cid:8)(cid:101)Nv(B∩C)−(cid:101)Nt(B∩C)(cid:9)(cid:3)

(cid:125)(cid:124)

(10.4)

E(cid:2)(cid:101)Nt(B)(cid:101)Nv(C)(cid:3)
= E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nv(B∩C)(cid:3)
= E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nt(B∩C)(cid:3) +
= E(cid:2)(cid:101)Nt(B∩C)(cid:101)Nt(B∩C)(cid:3)

= tν(B∩C)
= λ ((0,t]∩ (0,v])ν(B∩C).

1Both S and I := {(s,t] : 0 (cid:54) s < t < ∞} are semirings, and so is their cartesian product R = I × S , see [53,

Lemma 13.1] or [54, Lemma 15.1] for the straightforward proof.

Chapter 10: A digression: stochastic integrals

67

For s (cid:54) t, u (cid:54) v and B,C ∈ S a lengthy, but otherwise completely elementary, calculation based
on (10.4) shows

E(cid:2)(cid:101)N((s,t]× B)(cid:101)N((u,v]×C)(cid:3) = λ ((s,t]∩ (u,v])ν(B∩C).

(Space-time white noise) Let R :=(cid:8)(0,t]× B : t > 0, B ∈ B(Rd)(cid:9) and µ = λ Lebesgue

d)
measure on the half-space H+ := [0,∞)× Rd.

Consider the mean-zero, real-valued Gaussian process (W(R))R∈B(H+) whose covariance func-
tion is given by Cov(W(R)W(S)) = λ (R∩ S).2 By its very deﬁnition W(R) is a random orthog-
onal measure on R0 with control measure λ .

We will now deﬁne a stochastic integral in the spirit of Itô’s original construction.

Deﬁnition 10.4. Let R be a semiring and R0 = {R ∈ R : µ(R) < ∞}. A simple function is a
deterministic function of the form
n
∑

n ∈ N, ck ∈ R, Rk ∈ R0.

ck1Rk (x),

f (x) =

(10.5)

k=1

Intuitively, IN( f ) = ∑n

k=1 ckN(Rk) should be the stochastic integral of a simple function f . The
only problem is the well-deﬁnedness. Since a random orthogonal measure is a.s. ﬁnitely addi-
tive, the following lemma has exactly the same proof as the usual well-deﬁnedness result for the
Lebesgue integral of a step function, see e.g. Schilling [53, Lemma 9.1] or [54, Lemma 8.1]; note
that ﬁnite unions of null sets are again null sets.

Lemma 10.5. Let f be a simple function and assume that f = ∑n
representations as step-function. Then

k=1 ck1Rk = ∑m

j=1 b j1S j has two

n

∑

k=1

ckN(Rk) =

m

∑

j=1

b jN(S j) a.s.

Deﬁnition 10.6. Let N(R), R ∈ R0, be a random orthogonal measure with control measure µ. The
stochastic integral of a simple function f given by (10.5) is the random variable

IN(ω, f ) :=

n

∑

k=1

ckN(ω,Rk).

(10.6)

The following properties of the stochastic integral are more or less immediate from the deﬁni-

tion.
Lemma 10.7. Let N(R), R ∈ R0, be a random orthogonal measure with control measure µ, f ,g
simple functions, and α,β ∈ R.

2The map (R,S) (cid:55)→ λ (R∩ S) is positive semideﬁnite, i.e. for R1, . . . ,Rn ∈ B(H+) and ξ1, . . . ,ξn ∈ R
λ (dx) (cid:62) 0.

ξ j1R j (x)ξk1Rk (x)λ (dx) =

ξ jξkλ (R j ∩ Rk) =

ξk1Rk (x)

(cid:17)2

(cid:90)

n

n

(cid:90) (cid:16) n
∑
k=1

∑
j,k=1

∑
j,k=1

68

R. L. Schilling: An Introduction to Lévy and Feller Processes

a) IN(1R) = N(R) for all R ∈ R0;
b) S (cid:55)→ IN(1S) extends N uniquely to S ∈ ρ(R0), the ring generated by R0;3
c) IN(α f + β g) = αIN( f ) + β IN(g);

d) E(cid:2)IN( f )2(cid:3) =(cid:82) f 2 dµ;

(linearity)

(Itô’s isometry)

Proof. The properties a) and c) are clear. For b) we note that ρ(R0) can be constructed from R0
by adding all possible ﬁnite unions of (disjoint) sets (see e.g. [53, Proof of Theorem 6.1, Step 2]).
In order to see d), we use (10.5) and the orthogonality relation E [N(R j)N(Rk)] = µ(R j ∩ Rk) to
get

E(cid:2)IN( f )2(cid:3) =

j,k=1

n

n

∑
∑
(cid:90)
(cid:90)

j,k=1
n

∑

=

=

=

c jckE [N(R j)N(Rk)]

c jckµ(R j ∩ Rk)

c j1R j (x)ck1Rk (x) µ(dx)

j,k=1
f 2(x) µ(dx).

Itô’s isometry now allows us to extend the stochastic integral to the L2(µ)-closure of the simple
functions: L2(E,σ (R), µ). For this take f ∈ L2(E,σ (R), µ) and any approximating sequence
( fn)n∈N of simple functions, i.e.

(cid:90)

lim
n→∞

| f − fn|2 dµ = 0.

In particular, ( fn)n∈N is an L2(µ) Cauchy sequence, and Itô’s isometry shows that the random
variables (IN( fn))n∈N are a Cauchy sequence in L2(P):

E(cid:2)(IN( fn)− IN( fm))2(cid:3) = E(cid:2)IN( fn − fm)2(cid:3) =

(cid:90)

( fn − fm)2 dµ −−−−→
m,n→∞

0.

Because of the completeness of L2(P), the limit limn→∞ IN( fn) exists and, by a standard argument,
it does not depend on the approximating sequence.
Deﬁnition 10.8. Let N(R), R ∈ R0, be a random orthogonal measure with control measure µ. The
stochastic integral of a function f ∈ L2(E,σ (R), µ) is the random variable

f (x)N(ω,dx) := L2(P)- lim
n→∞

IN(ω, fn)

(10.7)

where ( fn)n∈N is any sequence of simple functions which approximate f in L2(µ).

3A ring is a family of sets which contains /0 and which is stable under unions and differences of ﬁnitely many sets.
Since R∩ S = R\ (R\ S), it is automatically stable under ﬁnite intersections. The ring generated by R0 is the smallest
ring containing R0.

(cid:90)

Chapter 10: A digression: stochastic integrals

It is immediate from the deﬁnition of the stochastic integral, that f (cid:55)→(cid:82) f dN is linear and enjoys

69

Itô’s isometry

E

(cid:20)(cid:16)(cid:90)

(cid:17)2(cid:21)

(cid:90)

f (x)N(dx)

=

f 2(x) µ(dx).

(10.8)

Remark 10.9. Assume that the random orthogonal measure N is of space-time type, i.e. E =
(0,∞)× X where (X, X ) is some measurable space, and R = {(0,t]× B : B ∈ S } where S is
a semiring in X . If for B ∈ S the stochastic process Nt(B) := N((0,t]× B) is a martingale w.r.t.
the ﬁltration Ft := σ (N((0,s]× B), s (cid:54) t,B ∈ S ), then

Nt( f ) :=

1(0,t](s) f (x)N(ds,dx), 1(0,t] ⊗ f ∈ L2(µ), t (cid:62) 0,

(cid:90)(cid:90)

is again a(n L2-)martingale. For simple functions f this follows immediately from the fact that
sums and differences of ﬁnitely many martingales (with a common ﬁltration) are again a martin-
gale. Since L2(P)-limits preserve the martingale property, the claim follows.

At ﬁrst sight, the stochastic integral deﬁned in 10.8 looks rather restrictive since we can only
integrate deterministic functions f . As all randomness can be put into the random orthogonal mea-
sure, we have considerable ﬂexibility, and the following construction shows that Deﬁnition 10.8
covers pretty much the most general stochastic integrals.

From now on we assume that

• the random measure N(dt,dx) on (E, E ) = ((0,∞)×X, B(Rd)⊗ X ) is of space-time type,

cf. Remark 10.9, with control measure µ(dt,dx);

• (Ft)t(cid:62)0 is some ﬁltration in (Ω, A , P).

Let τ be a stopping time; the set(cid:75)0,τ(cid:75) := {(ω,t) : 0 < t (cid:54) τ(ω)} is called stochastic interval.

We deﬁne

• E◦ := Ω× (0,∞)× X;
• E ◦ := P ⊗ X where P is the predictable σ-algebra in Ω× (0,∞), see Deﬁnition A.8 in

the appendix;

• µ◦(dω,dt,dx) := P(dω)µ(dt,dx) as control measure;

• R◦ := {(cid:75)0,τ(cid:75)× B : τ bounded stopping time, B ∈ S };
• N◦(cid:0)ω,(cid:75)0,τ(cid:75)× B(cid:1) := N(cid:0)ω, (0,τ(ω)]× B(cid:1) as random orthogonal measure4.
ck ∈ R, (cid:75)0,τk(cid:75)× Bk ∈ R◦

0 and µ◦ be as above. The R◦
∑

ck1(cid:75)0,τk(cid:75)(ω,t)1Bk (x),

0-simple processes

f (ω,t,x) :=

n

k=1

0

Lemma 10.10. Let N◦, R◦

are L2(µ◦)-dense in L2(E◦, P ⊗ σ (S ), µ◦).

4To see that it is indeed a random orthogonal measure, use a discrete approximation of τ.

70

R. L. Schilling: An Introduction to Lévy and Feller Processes

Proof. This follows from standard arguments from measure and integration; notice that the pre-

dictable σ-algebra P ⊗ σ (S ) is generated by sets of the form(cid:75)0,τ(cid:75)× B where τ is a bounded

stopping time and B ∈ S , cf. Theorem A.9 in the appendix.

Observe that for simple processes appearing in Lemma 10.10

(cid:90)(cid:90)

(cid:20)(cid:16)(cid:90)(cid:90)

E

f (ω,t,x)N(ω,dt,dx) :=

is a stochastic integral which satisﬁes

f (·,t,x)N(·,dt,dx)

n

k=1

∑

ck N◦(ω,(cid:75)0,τk(cid:75)× Bk) =
(cid:17)2(cid:21)

n

k µ◦((cid:75)0,τk(cid:75)× Bk) =

c2

=

∑

k=1

ck N(ω, (0,τk(ω)]× Bk)

n

∑

k=1

k Eµ((0,τk]× Bk).
c2

n

∑

k=1

Just as above we can now extend the stochastic integral to L2(E◦, P ⊗ σ (S ), µ◦).

Corollary 10.11. Let N(ω,dt,dx) be a random orthogonal measure on E of space-time type
(cf. Remark 10.9) with control measure µ(dt,dx) and f : Ω× (0,∞)× X → R be an element of
L2(E◦, P ⊗ σ (S ), µ◦). Then the stochastic integral

(cid:90)(cid:90)

f (ω,t,x)N(ω,dt,dx)

exists and satisﬁes the following Itô isometry

(cid:17)2(cid:21)

(cid:90)(cid:90)

=

E f 2(·,t,x) µ(dt,dx).

(10.9)

f (·,t,x)N(·,dt,dx)

(cid:20)(cid:16)(cid:90)(cid:90)

E

(cid:90)(cid:90)

Let us show that the stochastic integral w.r.t. a space-time random orthogonal measure extends

the usual Itô integral. To do so we need the following auxiliary result.

Lemma 10.12. Let N(ω,dt,dx) be a random orthogonal measure on E of space-time type (cf.
Remark 10.9) with control measure µ(dt,dx) and τ a stopping time. Then

φ (ω)1(cid:75)τ,∞(cid:74)(ω,t) f (ω,t,x)N(ω,dt,dx)

(cid:90)(cid:90)

= φ (ω)

1(cid:75)τ,∞(cid:74)(ω,t) f (ω,t,x)N(ω,dt,dx)

(10.10)

grands appearing in (10.10) are predictable, hence all stochastic integrals are well-deﬁned.

for all φ ∈ L∞(Fτ ) and f ∈ L2(E◦, P ⊗ σ (S ), µ◦).
Proof. Since t (cid:55)→ 1(cid:75)τ,∞(cid:74)(ω,t) is adapted to the ﬁltration (Ft)t(cid:62)0 and left-continuous, the inte-
1◦ Assume that φ (ω) = 1F (ω) for some F ∈ Fτ and f (ω,t,x) = 1(cid:75)0,σ(cid:75)(ω,t)1B(x) for some
bounded stopping time σ and(cid:75)0,σ(cid:75)× B ∈ R◦

0. Deﬁne

Nσ (ω,B) := N(ω, (0,σ (ω)]× B) = N◦(ω,(cid:75)0,σ(cid:75)× B)

Chapter 10: A digression: stochastic integrals

71

for any(cid:75)0,σ(cid:75)× B ∈ R◦

0. The random time τF := τ1F + ∞1Fc is a stopping time5, and we have

φ 1(cid:75)τ,∞(cid:74) f = 1F 1(cid:75)τ,∞(cid:74)1(cid:75)0,σ(cid:75)1B = 1(cid:75)τF ,∞(cid:74)1(cid:75)0,σ(cid:75)1B = 1(cid:75)τF∧σ ,σ(cid:75)1B.

From this we get (10.10) for our choice of φ and f :

(cid:90)(cid:90)

φ 1(cid:75)τ,∞(cid:74)(t) f (t,x)N(dt,dx) =

(cid:90)(cid:90)
= Nσ (B)− NτF∧σ (B)
= 1F · (Nσ (B)− Nτ∧σ (B))
= 1F

1(cid:75)τF∧σ ,σ(cid:75)(t)1B(x)N(dt,dx)
(cid:90)(cid:90)
1(cid:75)τ∧σ ,σ(cid:75)(t)1B(x)N(dt,dx)
(cid:90)(cid:90)
1(cid:75)τ,∞(cid:74)1(cid:75)0,σ(cid:75)(t)1B(x)N(dt,dx)
(cid:90)(cid:90)
1(cid:75)τ,∞(cid:74)(t) f (t,x)N(dt,dx).

= 1F

= φ

2◦ If φ = 1F for some F ∈ Fτ and f is a simple process, then (10.10) follows from 1◦ because of
the linearity of the stochastic integral.
3◦ If φ = 1F for some F ∈ Fτ and f ∈ L2(µ◦), then (10.10) follows from 2◦ and Itô’s isometry:
Let fn be a sequence of simple processes which approximate f . Then

E

(cid:20)(cid:16)(cid:90)(cid:90) (cid:0)φ 1(cid:75)τ,∞(cid:74)(t) fn(t,x)− φ 1(cid:75)τ,∞(cid:74)(t) f (t,x)(cid:1)N(dt,dx)
(cid:17)2(cid:21)
(cid:104)(cid:0)φ 1(cid:75)τ,∞(cid:74)(t) fn(t,x)− φ 1(cid:75)τ,∞(cid:74)(t) f (t,x)(cid:1)2(cid:105)
(cid:90)(cid:90)
(cid:104)(cid:0) fn(t,x)− f (t,x)(cid:1)2(cid:105)
(cid:54)(cid:90)(cid:90)

µ(dt,dx) −−−→
n→∞

0.

=

E

E

µ(dt,dx)

4◦ If φ is an Fτ measurable step-function and f ∈ L2(µ◦), then (10.10) follows from 3◦ because
of the linearity of the stochastic integral.
5◦ Since we can approximate φ ∈ L∞(Fτ ) uniformly by Fτ measurable step functions φn, (10.10)
follows from 4◦ and Itô’s isometry because of the following inequality:

E

(cid:20)(cid:16)(cid:90)(cid:90) (cid:2)φn1(cid:75)τ,∞(cid:74)(t) f (t,x)− φ 1(cid:75)τ,∞(cid:74)(t) f (t,x)(cid:3) N(dt,dx)
(cid:17)2(cid:21)
(cid:16)(cid:2)φn1(cid:75)τ,∞(cid:74)(t) f (t,x)− φ 1(cid:75)τ,∞(cid:74)(t) f (t,x)(cid:3)2(cid:17)

E(cid:2) f 2(t,x)(cid:3) µ(dt,dx).

(cid:90)(cid:90)
=
(cid:54) (cid:107)φn − φ(cid:107)2

E

(cid:90)(cid:90)

L∞(P)

µ(dt,dx)

We will now consider ‘martingale noise’ random orthogonal measures, see Example 10.3.b),
which are given by (the predictable quadratic variation of) a square-integrable martingale M. For
these random measures our deﬁnition of the stochastic integral coincides with Itô’s deﬁnition.

5Indeed, {τF (cid:54) t} = {τ (cid:54) t}∩ F =

∈ Ft for all t (cid:62) 0.

(cid:40) /0,

F,

(cid:41)

τ > t
τ (cid:54) t

72

R. L. Schilling: An Introduction to Lévy and Feller Processes

Recall that the Itô integral driven by M is ﬁrst deﬁned for simple, left-continuous processes of the
form

f (ω,t) :=

n

∑

k=1

φk(ω)1(cid:75)τk,τk+1(cid:75)(ω,t),

t (cid:62) 0,

(10.11)

where 0 (cid:54) τ1 (cid:54) τ2 (cid:54) . . . (cid:54) τn+1 are bounded stopping times and φk bounded Fτk measurable
random variables. The Itô integral for such simple processes is

f (ω,t)dMt(ω) :=

n

∑

k=1

φk(ω)(cid:0)Mτk+1(ω)− Mτk (ω)(cid:1)

and it is extended by Itô’s isometry to all integrands from L2(Ω× (0,∞), P,dP⊗ d(cid:104)M(cid:105)t). For
details we refer to any standard text on Itô integration, e.g. Protter [42, Chapter II] or Revuz & Yor
[43, Chapter IV].

We will now use Lemma 10.12 in the particular situation where the space component dx is not

present.

Theorem 10.13. Let N(dt) be a ‘martingale noise’ random orthogonal measure induced by the
square-integrable martingale M (Example 10.3). The stochastic integral w.r.t. the random orthog-
onal measure N(dt) and Itô’s stochastic integral w.r.t. M coincide.
Proof. Let 0 (cid:54) τ1 (cid:54) τ2 (cid:54) . . . (cid:54) τn+1 be bounded stopping times, φk ∈ L∞(Fτk ) bounded random
variables and f (ω,t) be a simple stochastic process of the form (10.11). From Lemma 10.12 we
get

(cid:90)

(cid:90)

(cid:90)(cid:90)

(cid:90) n
∑
(cid:90)

k=1

n

∑

k=1

n

∑

k=1

φk

f (t)N(dt) =

=

=

=

φk1(cid:75)τk,τk+1(cid:75)(t)N(dt)
φk1(cid:75)τk,∞(cid:74)(t)1(cid:75)0,τk+1(cid:75)(t)N(dt)
(cid:90)
1(cid:75)τk,∞(cid:74)(t)1(cid:75)0,τk+1(cid:75)(t)N(dt)

φk(Mτk+1 − Mτk ).

n

∑

k=1

This means that both stochastic integrals coincide on the simple stochastic processes. Since both
integrals are extended by Itô’s isometry, the assertion follows.

Example 10.14. Using random orthogonal measures we can re-state the Lévy-Itô decomposition

appearing in Theorem 9.12. For this, let(cid:101)N(dt,dx) be the Poisson random orthogonal measure (Ex-

ample 10.3.c) on E = (0,∞)× (Rd \{0}) with control measure dt × ν(dx) (ν is a Lévy measure).
Additionally, we deﬁne for all deterministic functions h : (0,∞)× Rd → R

h(s,x)N(ω,ds,dx) := ∑
0<s<∞

h(s,∆Xs(ω)) ∀ω ∈ Ω

Chapter 10: A digression: stochastic integrals

73

provided that the sum ∑0<s<∞|h(s,∆Xs(ω))| < ∞ for each ω.6 If X is a Lévy process with charac-
teristic exponent ψ and Lévy triplet (l,Q,ν), then

Xt =(cid:112)QWt +

(cid:90)(cid:90)
(cid:90)(cid:90)

tl

+

continuous
Gaussian

1(0,t](s)y1(0,1)(|y|)(cid:101)N(ds,dy)

1(0,t](s)y1{|y|(cid:62)1} N(ds,dy).

pure jump part

(cid:21)(cid:21)(cid:21)
(cid:21)(cid:21)(cid:21)

=: Mt, L2-martingale

=: At, bdd. variation

Example 10.14 is quite particular in the sense that N(·,dt,dx) is a bona ﬁde positive measure,

and the control measure µ(dt,dx) is also the compensator, i.e. a measure such that

(cid:101)N((0,t]× B) = N((0,t]× B)− µ((0,t]× B)

is a square-integrable martingale.

Following Ikeda & Watanabe [22, Chapter II.4] we can generalize the set-up of Example 10.14
in the following way: Let N(ω,dt,dx) be for each ω a positive measure of space-time type. Since

t (cid:55)→ N(ω, (0,t]× B) is increasing, there is a unique compensator (cid:98)N(ω,dt,dx) such that for all B
with E(cid:98)N((0,t]× B) < ∞(cid:101)N(ω, (0,t]× B) := N(ω, (0,t]× B)−(cid:98)N(ω, (0,t]× B),
is a square-integrable martingale. If t (cid:55)→(cid:98)N((0,t]× B) is continuous and B (cid:55)→(cid:98)N((0,t]× B) a σ-
t =(cid:98)N(cid:0)(0,t]× (B∩C)(cid:1).

This means, in particular, that(cid:101)N(ω,dt,dx) is a random orthogonal measure with control measure
µ((0,t]× B) = E(cid:98)N((0,t]× B), and we are back in the theory which we have developed in the ﬁrst

(cid:10)(cid:101)N((0,·]× B),(cid:101)N((0,·]×C)(cid:11)

ﬁnite measure, then one can show that the angle bracket satisﬁes

t (cid:62) 0,

part of this chapter.

It is possible to develop a fully-ﬂedged stochastic calculus for this kind of random measures.

Deﬁnition 10.15. Let (Ω, A , P) be a probability space with a ﬁltration (Ft)t(cid:62)0. A semimartin-
gale is a stochastic process X of the form

(cid:90) t
(cid:90)

0

f (·,s,x)(cid:101)N(ds,dx) +

(cid:90) t
(cid:90)

0

g(·,s,x)N(ds,dx)

Xt = X0 + At + Mt +

((cid:82) t
0 :=(cid:82)

(0,t]) where

• X0 is an F0 measurable random variable,
6This is essentially an ω-wise Riemann–Stieltjes integral. A sufﬁcient condition for the absolute convergence is,
e.g. that h is continuous and h(t,·) vanishes uniformly in t in some neighbourhood of x = 0. The reason for this is the
fact that Nt (ω,Bc
ε (0)) < ∞, i.e. there are at most ﬁnitely many jumps of size exceeding ε > 0.

ε (0)) = N(ω, (0,t]× Bc

74

R. L. Schilling: An Introduction to Lévy and Feller Processes

• M is a continuous square-integrable local martingale (w.r.t. Ft),
• A is a continuous Ft adapted process of bounded variation,

• N(ds,dx),(cid:101)N(ds,dx) and(cid:98)N(ds,dx) are as described above,
• f 1(cid:75)0,τn(cid:75) ∈ L2(Ω× (0,∞)× X, P ⊗ X , µ◦) for some increasing sequence τn ↑ ∞ of bounded
• g is such that(cid:82) t

(cid:82) g(ω,s,x)N(ω,ds,dx) exists as an ω-wise integral,

stopping times,

0

• f (·,s,x)g(·,s,x) ≡ 0.

In this case, we even have Itô’s formula, see [22, Chapter II.5], for any F ∈ C2(R, R):

F(Xt)− F(X0) =

0

0

0

(cid:90) t

F(cid:48)(Xs−)dMs +

(cid:90) t
(cid:90) t
(cid:90) t
(cid:90) (cid:2)F(Xs− + f (s,x))− F(Xs−)(cid:3)(cid:101)N(ds,dx)
F(cid:48)(Xs−)dAs +
(cid:90) t
(cid:90) (cid:2)F(Xs− + g(s,x))− F(Xs−)(cid:3)N(ds,dx)
(cid:90) t
(cid:90) (cid:2)F(Xs + f (s,x))− F(Xs)− f (s,x)F(cid:48)(Xs)(cid:3)(cid:98)N(ds,dx)

F(cid:48)(cid:48)(Xs−)d(cid:104)M(cid:105)s

1
2

0

+

+

0

where we use again the convention that(cid:82) t

+

0

0 :=(cid:82)

(0,t].

11. From Lévy to Feller processes

We have seen in Lemma 4.8 that the semigroup Pt f (x) := Ex f (Xt) = E f (Xt + x) of a Lévy pro-
cess (Xt)t(cid:62)0 is a Feller semigroup. Moreover, the convolution structure of the transition semigroup

E f (Xt +x) =(cid:82) f (x +y)P(Xt ∈ dy) is a consequence of the spatial homogeneity (translation invari-

ance) of the Lévy process, see Remark 4.5 and the characterization of translation invariant linear
functionals (Theorem A.10). Lemma 4.4 shows that the translation invariance of a Lévy process
is due to the assumptions (L1) and (L2).

It is, therefore, a natural question to ask what we get if we consider stochastic processes whose
semigroups are Feller semigroups which are not translation invariant. Since every Feller semi-
group admits a Markov transition kernel (Lemma 5.2), we can use Kolmogorov’s construction to
obtain a Markov process. Thus, the following deﬁnition makes sense.
Deﬁnition 11.1. A Feller process is a càdlàg Markov process (Xt)t(cid:62)0, Xt : Ω → Rd, t (cid:62) 0, whose
transition semigroup Pt f (x) = Ex f (Xt) is a Feller semigroup.

Remark 11.2. It is no restriction to require that a Feller process has càdlàg paths. By a fundamental
result in the theory of stochastic processes we can construct such modiﬁcations. Usually, one
argues like this: It is enough to study the coordinate processes, i.e. d = 1. Rather than looking
at t (cid:55)→ Xt we consider a (countable, point-separating) family of functions u : R → R and show
that each t (cid:55)→ u(Xt) has a càdlàg modiﬁcation. One way of achieving this is to use martingale
regularization techniques (e.g. Revuz & Yor [43, Chapter II.2]) which means that we should pick
u in such a way that u(Xt) is a supermartingale. The usual candidate for this is the resolvent
e−λtRλ f (Xt) for some f ∈ C+
∞(R). Indeed, if Ft = σ (Xs, s (cid:54) t) is the natural ﬁltration, f (cid:62) 0 and
s (cid:54) t, then

e−λ uPu f (Xs)du (cid:54) eλ (t−s)

e−λ uPu f (Xs)du

e−λ rPrPt−s f (Xs)dr

(cid:90) ∞

0

Ex(cid:2)Rλ f (Xt) | Fs

(cid:3) = EXs

(cid:90) ∞
(cid:90) ∞
e−λ rPr f (Xt−s)dr =
0
= eλ (t−s)
= eλ (t−s)Rλ f (Xs).

t−s

(cid:90) ∞

0

Let Ft = F X
t

:= σ (Xs, s (cid:54) t) be the canonical ﬁltration.

Lemma 11.3. Every Feller process (Xt)t(cid:62)0 is a strong Markov process, i.e.

Ex(cid:2) f (Xt+τ ) | Fτ

(cid:3) = EXτ f (Xt), Px-a.s. on {τ < ∞}, t (cid:62) 0,

(11.1)

holds for any stopping time τ, Fτ := {F ∈ F∞ : F ∩{τ (cid:54) t} ∈ Ft ∀t (cid:62) 0} and f ∈ C∞(Rd).

75

76

R. L. Schilling: An Introduction to Lévy and Feller Processes

A routine approximation argument shows that (11.1) extends to f (y) = 1K(y) (where K is a

compact set) and then, by a Dynkin-class argument, to any f (y) = 1B(y) where B ∈ B(Rd).

Proof. To prove (11.1), approximate τ from above by discrete stopping times τn =(cid:0)(cid:98)2nτ(cid:99) +1(cid:1)2−n

and observe that for F ∈ Fτ ∩{τ < ∞}

Ex[1F f (Xt+τ )]

(i)
= lim
n→∞

Ex[1F f (Xt+τn)]

(ii)
= lim
n→∞

Ex(cid:2)1F EXτn f (Xt)(cid:3) (iii)

= Ex(cid:2)1F EXτ f (Xt)(cid:3).

Here we use that t (cid:55)→ Xt is right-continuous, plus (i) dominated convergence and (iii) the Feller
continuity 4.7.f); (ii) is the strong Markov property for discrete stopping times which follows
directly from the Markov property: Since {τn < ∞} = {τ < ∞}, we get

Ex[1F f (Xt+τn)] =

Ex(cid:2)1F∩{τn=k2−n} f (Xt+k2−n)(cid:3)
Ex(cid:2)1F∩{τn=k2−n}EXk2−n f (Xt)(cid:3)

∞
∑
k=1
∞
∑

=

= Ex(cid:2)1F EXτn f (Xt)(cid:3).

k=1

In the last calculation we use that F ∩{τn = k2−n} ∈ Fk2−n for all F ∈ Fτ.

Once we know the generator of a Feller process, we can construct many important martingales

with respect to the canonical ﬁltration of the process.

Corollary 11.4. Let (Xt)t(cid:62)0 be a Feller process with generator (A, D(A)) and semigroup (Pt)t(cid:62)0.
For every f ∈ D(A) the process

M[ f ]
t

:= f (Xt)−

(cid:90) t
:= σ (Xs, s (cid:54) t) and any Px, x ∈ Rd.

A f (Xr)dr,

t (cid:62) 0,

0

(11.2)

s and Mt := M[ f ]
t

. By the Markov property

is a martingale for the canonical ﬁltration FX
t
Proof. Let s (cid:54) t, f ∈ D(A) and write, for short, Fs := FX
f (Xt)− f (Xs)−
= EXs f (Xt−s)− f (Xs)−
On the other hand, we get from the semigroup identity (5.5)

Ex [Mt − Ms | Fs] = Ex

(cid:20)

(cid:90) t
(cid:90) t−s

s

0

(cid:21)

(cid:12)(cid:12)(cid:12)(cid:12) Fs

A f (Xr)dr

EXsA f (Xu)du.

(cid:90) t−s

0

(cid:90) t−s

0

which shows that Ex [Mt − Ms | Fs] = 0.

EXsA f (Xu)du =

PuA f (Xs)du = Pt−s f (Xs)− f (Xs) = EXs f (Xt−s)− f (Xs)

Our approach from Chapter 6 to prove the structure of a Lévy generator ‘only’ uses the positive
maximum principle. Therefore, it can be adapted to Feller processes provided that the domain
c (Rd) ⊂ D(A). All we have to do is to take into account that
D(A) is rich in the sense that C∞
Feller processes are not any longer invariant under translations. The following theorem is due to
Courrège [14] and von Waldenfels [60, 61].

Chapter 11: From Lévy to Feller processes

77

Theorem 11.5 (von Waldenfels, Courrège). Let (A, D(A)) be the generator of a Feller process
such that C∞

c (Rd) ⊂ D(A). Then A|C∞

c (Rd ) is a pseudo differential operator

(cid:90)
q(x,ξ )(cid:98)u(ξ )eix·ξ dξ
(cid:2)1− eiy·ξ + iy· ξ 1(0,1)(|y|)(cid:3)ν(x,dy)

(11.3)

(11.4)

whose symbol q : Rd × Rd → C is a measurable function of the form

Au(x) = −q(x,D)u(x) := −
(cid:90)

−il(x)· ξ +

ξ · Q(x)ξ +

1
2

y(cid:54)=0

q(x,ξ ) = q(x,0)

(cid:124) (cid:123)(cid:122) (cid:125)(cid:62)0

and (l(x),Q(x),ν(x,dy)) is a Lévy triplet1 for every ﬁxed x ∈ Rd.

If we insert (11.4) into (11.3) and invert the Fourier transform we obtain the following integro-

differential representation of the Feller generator A:

A f (x) = l(x)· ∇ f (x) +

1
2

∇· Q(x)∇ f (x)

(cid:2) f (x + y)− f (x)− ∇ f (x)· y1(0,1)(|y|)(cid:3)ν(x,dy).

(cid:90)

+

y(cid:54)=0

(11.5)

This formula obviously extends to all functions f ∈ C2
f (x) = eξ (x) = eix·ξ , and get2

b(Rd). In particular, we may use the function

e−ξ (x)Aeξ (x) = −q(x,ξ ).

(11.6)

Proof of Theorem 11.5 (sketch). For a worked-out version see [9, Chapter 2.3]. In the proof of The-
orem 6.8 use, instead of A0 and A00

A0 f (cid:32) Ax f := (A f )(x)

and A00 f (cid:32) Axx f := Ax(|·−x|2 f )

for every x ∈ Rd. This is needed since Pt and A are not any longer translation invariant, i.e. we
cannot shift A0 f to get Ax f . Then follow the steps 1◦–4◦ to get ν(dy) (cid:32) ν(x,dy) and 6◦–9◦ for
(l(x),Q(x)). Remark 6.9 shows that the term q(x,0) is non-negative.

The key observation is, as in the proof of Theorem 6.8, that we can use in steps 3◦ and 7◦ the

positive maximum principle3 to make sure that Ax f is a distribution of order 2, i.e.

|Ax f| = |Lx f + Sx f| (cid:54) CK(cid:107) f(cid:107)(2)

for all

f ∈ C∞

c (K) and all compact sets K ⊂ Rd.

Here Lx is the local part with support in {x} accounting for (q(x,0),l(x),Q(x)), and Sx is the
non-local part supported in Rd \{x} giving ν(x,dy).

With some abstract functional analysis we can show some (local) boundedness properties of

x (cid:55)→ A f (x) and (x,ξ ) (cid:55)→ q(x,ξ ).

1Cf. Deﬁnition 6.10
2This should be compared with Deﬁnition 6.4 and the subsequent comments.
3To be precise: its weakened form (PP), cf. page 41.

78

R. L. Schilling: An Introduction to Lévy and Feller Processes

(11.7)

(11.8)

Corollary 11.6. In the situation of Theorem 11.5, the condition (PP) shows that

|A f (x)| (cid:54) Cr(cid:107) f(cid:107)(2)

for all

f ∈ C∞

c (Br(0))

sup
|x|(cid:54)r

and the positive maximum principle (PMP) gives

Proof. In the above sketched analogue of the proof of Theorem 6.8 we have seen that the family
of linear functionals

sup
|x|(cid:54)r

for all

f ∈ C∞

c (Rd), r > 0.

|A f (x)| (cid:54) Cr,A(cid:107) f(cid:107)(2)
(cid:110)

(cid:111)
c (Br(0)) (cid:51) f (cid:55)→ Ax f : x ∈ Br(0)
C∞

where Ax f := (A f )(x) satisﬁes

|Ax f| (cid:54) cr,x(cid:107) f(cid:107)(2),

f ∈ C∞

c (Br(0)),

b(Br(0)),(cid:107)·(cid:107)(2)) → (R,|·|) is bounded. By the Banach–Steinhaus theorem (uniform

i.e. Ax : (C2
boundedness principle)

|Ax f| (cid:54) Cr(cid:107) f(cid:107)(2).

sup
|x|(cid:54)r

Since A also satisﬁes the positive maximum principle (PMP), we know from step 4◦ of the

(suitably adapted) proof of Theorem 6.8 that

(cid:90)

ν(x,dy) (cid:54) Aφ0(x) for some φ0 ∈ Cc(B1(0)).
|y|>1
c (Rd) such that 1B2r(0) (cid:54) χ (cid:54) 1B3r(0). We get for |x| (cid:54) r
Let r > 1, pick χ = χr ∈ C∞
(cid:90)

A f (x) = A[χ f ](x) + A[(1− χ) f ](x)

(cid:2)(1− χ(x + y)) f (x + y)− (1− χ(x)) f (x)
(cid:125)

(cid:123)(cid:122)

(cid:124)

= A[χ f ](x) +

|y|(cid:62)r

(cid:3)ν(x,dy),

=0

and so

|A f (x)| (cid:54) Cr(cid:107)χ f(cid:107)(2) +(cid:107) f(cid:107)∞(cid:107)Aφ0(cid:107)∞ (cid:54) Cr,A(cid:107) f(cid:107)(2).

sup
|x|(cid:54)r

Corollary 11.7. In the situation of Theorem 11.5 there exists a locally bounded nonnegative func-
tion γ : Rd → [0,∞) such that

|q(x,ξ )| (cid:54) γ(x)(1 +|ξ|2),

x,ξ ∈ Rd.

(11.9)

Proof. Using (11.8) we can extend A by continuity to C2

−q(x,ξ ) = e−ξ (x)Aeξ (x),

b(Rd) and, therefore,
eξ (x) = eix·ξ

makes sense. Moreover, we have sup|x|(cid:54)r |Aeξ (x)| (cid:54) Cr,A(cid:107)eξ(cid:107)(2) for any r (cid:62) 1; since (cid:107)eξ(cid:107)(2) is a
polynomial of order 2 in the variable ξ , the claim follows.

Chapter 11: From Lévy to Feller processes

79

For a Lévy process we have ψ(0) = 0 since P(Xt ∈ Rd) = 1 for all t (cid:62) 0, i.e. the process Xt
does not explode in ﬁnite time. For Feller processes the situation is more complicated. We need
the following technical lemmas.

Lemma 11.8. Let q(x,ξ ) be the symbol of (the generator of ) a Feller process as in Theorem 11.5
and F ⊂ Rd be a closed set. Then the following assertions are equivalent.

a) |q(x,ξ )| (cid:54) C(1 +|ξ|2) for all x,ξ ∈ Rd where C = 2 sup
|ξ|(cid:54)1

|q(x,ξ )|.

sup
x∈F

b) sup
x∈F

q(x,0) + sup
x∈F

|l(x)| + sup
x∈F

(cid:107)Q(x)(cid:107) + sup
x∈F

y(cid:54)=0

|y|2
1 +|y|2 ν(x,dy) < ∞.

(cid:90)

If F = Rd, then the equivalent properties of Lemma 11.8 are often referred to as ‘the symbol

has bounded coefﬁcients’.
Outline of the proof (see [56, Appendix] for a complete proof ). The direction b)⇒a) is proved as
Theorem 6.2. Observe that ξ (cid:55)→ q(x,ξ ) is for ﬁxed x the characteristic exponent of a Lévy process.
The ﬁniteness of the constant C follows from the assumption b) and the Lévy–Khintchine formula
(11.4).

For the converse a)⇒b) we note that the integrand appearing in (11.4) can be estimated by
c |y|2
1+|y|2 which is itself a Lévy exponent:

(cid:90) ∞

0

(cid:90)

|y|2
1 +|y|2 =
(cid:90)

[1− cos(y· ξ )]g(ξ )dξ ,

g(ξ ) =

1
2

(2πλ )−d/2e−|ξ|2/2λ e−λ /2 dλ .

Therefore, by Tonelli’s theorem,

|y|2
1 +|y|2 ν(x,dy) =

y(cid:54)=0

(cid:90)(cid:90)
(cid:90)

y(cid:54)=0

=

g(ξ )

[1− cos(y· ξ )] ν(x,dy)g(ξ )dξ

(cid:18)
Req(x,ξ )− 1
2

ξ · Q(x)ξ − q(x,0)

dξ .

(cid:19)

Lemma 11.9. Let A be the generator of a Feller process, assume that C∞
by q(x,ξ ) the symbol of A. For any cut-off function χ ∈ C∞
χr(x) := χ(x/r) one has

c (Rd) ⊂ D(A) and denote
c (Rd) satisfying 1B1(0) (cid:54) χ (cid:54) 1B2(0) and

(cid:12)(cid:12)q(x,D)(χreξ )(x)(cid:12)(cid:12) (cid:54) 4 sup

|q(x,η)|

|η|(cid:54)1

(cid:90)

Rd

(cid:2)1 + r−2|ρ|2 +|ξ|2(cid:3)(cid:12)(cid:12)(cid:98)χ(ρ)(cid:12)(cid:12)dρ,

A(χreξ )(x) = −eξ (x)q(x,ξ )
Proof. Observe that (cid:100)χreξ (η) = rd(cid:98)χ(r(η − ξ )) and

lim
r→∞

for all x,ξ ∈ Rd.

(cid:90)
(cid:90)
(cid:90)

q(x,η)eix·η (cid:100)χreξ (η)dη
q(x,η)eix·η rd(cid:98)χ(r(η − ξ ))dη
q(x,ξ + r−1ρ)eix·(ξ +ρ/r)(cid:98)χ(ρ)dρ.

q(x,D)(χreξ )(x) =

=

=

(11.10)

(11.11)

(11.12)

80

R. L. Schilling: An Introduction to Lévy and Feller Processes

Therefore we can use the estimate (11.9) with the optimal constant γ(x) = 2sup|η|(cid:54)1|q(x,η)| and
the elementary estimate (a + b)2 (cid:54) 2(a2 + b2) to obtain

(cid:12)(cid:12)q(x,D)(χreξ )(x)(cid:12)(cid:12) (cid:54)(cid:90) (cid:12)(cid:12)q(x,ξ + r−1ρ)(cid:12)(cid:12)(cid:12)(cid:12)(cid:98)χ(ρ)(cid:12)(cid:12)dρ

(cid:90) (cid:2)1 + r−2|ρ|2 +|ξ|2(cid:3)(cid:12)(cid:12)(cid:98)χ(ρ)(cid:12)(cid:12)dρ.

(cid:54) 4 sup
|η|(cid:54)1

|q(x,η)|

This proves (11.10); it also allows us to use dominated convergence in (11.12) to get (11.11). Just

observe that(cid:98)χ ∈ S(Rd) and(cid:82)(cid:98)χ(ρ)dρ = χ(0) = 1.

Lemma 11.10. Let q(x,ξ ) be the symbol of (the generator of ) a Feller process. Then the following
assertions are equivalent:

a) x (cid:55)→ q(x,ξ ) is continuous for all ξ .
b) x (cid:55)→ q(x,0) is continuous.

c) Tightness: lim
r→∞

sup
x∈K

ν(x, Rd \ Br(0)) = 0 for all compact sets K ⊂ Rd.

sup
x∈K

d) Uniform continuity at the origin: lim|ξ|→0

|q(x,ξ )− q(x,0)| = 0 for all compact K ⊂ Rd.
Proof. Let χ : [0,∞) → [0,1] be a decreasing C∞-function satisfying 1[0,1) (cid:54) χ (cid:54) 1[0,4). The
functions χn(x) := χ(|x|2/n2), x ∈ Rd and n ∈ N, are radially symmetric, smooth functions with
1Bn(0) (cid:54) χn (cid:54) 1B2n(0). Fix any compact set K ⊂ Rd and some sufﬁciently large n0 such that
K ⊂ Bn0(0).
a)⇒b) is obvious.
b)⇒c) For m (cid:62) n (cid:62) 2n0 the positive maximum principle implies

1K(x)A(χn − χm)(x) (cid:62) 0.

Therefore, −1K(x)q(x,0) = limn→∞ 1K(x)Aχn+n0(x) is a decreasing limit of continuous functions.
Since the limit function q(x,0) is continuous, Dini’s theorem implies that the limit is uniform on
the set K. From the integro-differential representation (11.5) of the generator we get

1K(x)|Aχm(x)− Aχn(x)| = 1K(x)

Letting m → ∞ yields

n−n0(cid:54)|y|(cid:54)2m+n0

(cid:90)

(cid:90)
(cid:90)

(cid:0)χm(x + y)− χn(x + y)(cid:1)ν(x,dy).
(cid:0)1− χn(x + y)(cid:1)ν(x,dy)
(cid:0)1− 1B2n+n0 (0)(y)(cid:1)ν(x,dy)
2n+n0(0)(cid:1) .

1K(x)|q(x,0) + Aχn(x)| = 1K(x)
(cid:62) 1K(x)

|y|(cid:62)n−n0

(cid:62) 1K(x)ν(cid:0)x,Bc

|y|(cid:62)n−n0

Chapter 11: From Lévy to Feller processes

81

where we use that K ⊂ Bn0(0) and

χn(x + y) (cid:54) 1B2n(0)(x + y) = 1B2n(0)−x(y) (cid:54) 1B2n+n0 (0)(y).

Since the left-hand side converges uniformly to 0 as n → ∞, c) follows.
c)⇒d) Since the function x (cid:55)→ q(x,ξ ) is locally bounded, we conclude from Lemma 11.8 that
supx∈K |l(x)| + supx∈K (cid:107)Q(x)(cid:107) < ∞. Thus, lim|ξ|→0 supx∈K(|l(x) · ξ| + |ξ · Q(x)ξ|) = 0, and we
may safely assume that l ≡ 0 and Q ≡ 0. If |ξ| (cid:54) 1 we ﬁnd, using (11.4) and Taylor’s formula for
the integrand,

|q(x,ξ )− q(x,0)|

(cid:104)
(cid:105)
1− eiy·ξ + iy· ξ 1(0,1)(y)
(cid:90)
|y|2|ξ|2 ν(x,dy) +

y(cid:54)=0

1
2

0<|y|2<1

(cid:12)(cid:12)(cid:12)(cid:12)

ν(x,dy)

=

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)
(cid:54)(cid:90)
(cid:54)(cid:90)

Since this estimate is uniform for x ∈ K, we get d) as |ξ| → 0.
d)⇒c) As before, we may assume that l ≡ 0 and Q ≡ 0. For every r > 0

0<|y|2<1/|ξ|

1
2

ν(x,Bc

2ν(x,dy)

|y||ξ|ν(x,dy) +

|y|2

|y|2(cid:62)1/|ξ|

1(cid:54)|y|2<1/|ξ|

1 +|y|2 ν(x,dy)(cid:0)1 +|ξ|−1/2(cid:1)|ξ| + 2ν(cid:0)x,{y : |y|2 (cid:62) 1/|ξ|}(cid:1).
r(0)) (cid:54)(cid:90)
(cid:90)
(cid:54)(cid:90)

|y/r|2
(cid:16)
(cid:17)
(cid:90)
1 +|y/r|2 ν(x,dy)
η · y
(cid:2)Req(cid:0)x, η
r

g(η)dη ν(x,dy)

1− cos

|y|(cid:62)r

|y|(cid:62)r

Rd

=

where g(η) is as in the proof of Lemma 11.8. Since(cid:82) (1 +|η|2)g(η)dη < ∞, we can use (11.9)

Rd

r

and ﬁnd

ν(x,Bc

r(0)) (cid:54) cg sup
|η|(cid:54)1/r

Taking the supremum over all x ∈ K and letting r → ∞ proves c).
c)⇒a) From Lemma 11.9 we know that limn→∞ e−ξ (x)A[χneξ ](x) = −q(x,ξ ). Let us show that
this convergence is uniform for x ∈ K. Let m (cid:62) n (cid:62) 2n0. For x ∈ K

(cid:12)(cid:12)e−ξ (x)A[eξ χn](x)− e−ξ (x)A[eξ χm](x)(cid:12)(cid:12)

=

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90)
(cid:54)(cid:90)
(cid:54)(cid:90)

y(cid:54)=0

y(cid:54)=0

(cid:12)(cid:12)(cid:12)(cid:12)
(cid:2)eξ (y)χn(x + y)− eξ (y)χm(x + y)(cid:3)ν(x,dy)
(cid:2)χm(x + y)− χn(x + y)(cid:3)ν(x,dy)
(cid:2)χm(x + y)− χn(x + y)(cid:3)ν(x,dy)

n−n0(cid:54)|y|(cid:54)2m+n0
n−n0(0)).

(cid:54) ν(x,Bc

(cid:90)

(cid:1)− q(x,0)(cid:3) g(η)dη,
(cid:12)(cid:12)Req(x,η)− q(x,0)(cid:12)(cid:12).

82

R. L. Schilling: An Introduction to Lévy and Feller Processes

In the penultimate step we use that, because of the deﬁnition of the functions χn,

supp(cid:0)χm(x +·)− χn(x +·)(cid:1) ⊂ B2m(x)\ Bn(x) ⊂ B2m+n0(0)\ Bn−n0(0)

for all x ∈ K ⊂ Bn0(0). The right-hand side tends to 0 uniformly for x ∈ K as n → ∞, hence
m → ∞.
Remark 11.11. The argument used in the ﬁrst three lines of the step b)⇒c) in the proof of Lemma
11.10 shows, incidentally, that

x (cid:55)→ q(x,ξ )

is always upper semicontinuous

since it is (locally) a decreasing limit of continuous functions.
c (Rd) ⊂ D(A);
Remark 11.12. Let A be the generator of a Feller process, and assume that C∞
although A maps D(A) into C∞(Rd), this is not enough to guarantee that the symbol q(x,ξ ) is
continuous in the variable x. On the other hand, if the Feller process X has only bounded jumps,
i.e. if the support of the Lévy measure ν(x,·) is uniformly bounded, then q(·,ξ ) is continuous.
This is, in particular, true for diffusions.

This follows immediately from Lemma 11.10.c) which holds if ν(x,Bc

r(0)) = 0 for some r > 0

and all x ∈ Rd.

We can also give a direct argument: pick χ ∈ C∞

c (Rd) satisfying 1B3r(0) (cid:54) χ (cid:54) 1. From the

representation (11.5) it is not hard to see that

A f (x) = A[χ f ](x)

for all

f ∈ C2

b(Rd) and x ∈ Br(0);

in particular, A[χ f ] is continuous.

If we take f (x) := eξ (x), then, by (11.6), −q(x,ξ ) = e−ξ (x)Aeξ (x) = e−ξ (x)A[χeξ ](x) which

proves that x (cid:55)→ q(x,ξ ) is continuous on every ball Br(0), hence everywhere.

We can now discuss the role of q(x,ξ ) for the conservativeness of a Feller process.

Theorem 11.13. Let (Xt)t(cid:62)0 be a Feller process with inﬁnitesimal generator (A, D(A)) such that
c (Rd) ⊂ D(A), symbol q(x,ξ ) and semigroup (Pt)t(cid:62)0.
C∞
a) If x (cid:55)→ q(x,ξ ) is continuous for all ξ ∈ Rd and Pt1 = 1, then q(x,0) = 0.
b) If q(x,ξ ) has bounded coefﬁcients and q(x,0) = 0, then x (cid:55)→ q(x,ξ ) is continuous for all

ξ ∈ Rd and Pt1 = 1.

Proof. Let χ and χr, r ∈ N, be as in Lemma 11.9. Then eξ χr ∈ D(A) and, by Corollary 11.4,

(cid:90)

[0,t)

Mt := eξ χr(Xt)− eξ χr(x)−

A(eξ χr)(Xs)ds,

t (cid:62) 0,

is a martingale. Using optional stopping for the stopping time

τ := τx

R := inf{s (cid:62) 0 : |Xs − x| (cid:62) R},

x ∈ Rd, R > 0,

Chapter 11: From Lévy to Feller processes

83

the stopped process (Mt∧τ )t(cid:62)0 is still a martingale. Since ExMt∧τ = 0, we get

Ex(χreξ )(Xt∧τ )− χreξ (x) = Ex

A(χreξ )(Xs)ds.

[0,t∧τ)

Note that the integrand is evaluated only for times s < t ∧ τ where |Xs| (cid:54) R + x. Since A(eξ χr)(x)
is locally bounded, we can use dominated convergence and Lemma 11.9 and we ﬁnd, as r → ∞,

Exeξ (Xt∧τ )− eξ (x) = −Ex

eξ (Xs)q(Xs,ξ )ds.

[0,t∧τ)

a) Set ξ = 0 and observe that Pt1 = 1 implies that τ = τx

R → ∞ a.s. as R → ∞. Therefore,

and with Fatou’s Lemma we can let R → ∞ to get

Px(Xt∧τ ∈ Rd)− 1 = −Ex
(cid:90)

(cid:20)

q(Xs,0)ds (cid:62) Ex

liminf
R→∞

(cid:90)

0 = liminf
R→∞

Ex

[0,τ∧t)

q(Xs,0)ds

[0,τ∧t)

q(Xs,0)ds,

[0,τ∧t)

(cid:21)

(cid:90) t

0

= Ex

q(Xs,0)ds.

Since x (cid:55)→ q(x,0) is continuous and q(x,0) non-negative, we conclude with Tonelli’s theorem that

(cid:90)

(cid:90)

(cid:90)

(cid:90)

b) Set ξ = 0 and observe that the boundedness of the coefﬁcients implies that

(cid:90) t

0

q(x,0) = lim
t→0

1
t

Exq(Xs,0)ds = 0.

Px(Xt ∈ Rd)− 1 = −Ex

q(Xs,0)ds

[0,t)

as R → ∞. Since the right-hand side is 0, we get Pt1 = Px(Xt ∈ Rd) = 1.

Remark 11.14. The boundedness of the coefﬁcients in Theorem 11.13.b) is important.
If the
coefﬁcients of q(x,ξ ) grow too rapidly, we may observe explosion in ﬁnite time even if q(x,0) = 0.
A typical example in dimension 3 is the diffusion process given by the generator

L f (x) =

a(x)∆ f (x)

1
2

satisﬁes (cid:82) ∞

where a(x) is continuous, rotationally symmetric a(x) = α(|x|) for a suitable function α(r), and
√
r)dr < ∞, see Stroock & Varadhan [59, p. 260, 10.3.3]; the corresponding
1 1/α(
2a(x)|ξ|2. This process explodes in ﬁnite time. Since this is essentially a
symbol is q(x,ξ ) = 1
time-changed Brownian motion (see Böttcher, Schilling & Wang [9, Chapter 4.1]), this example
works only if Brownian motion is transient, i.e. in dimensions d = 3 and higher. A sufﬁcient
criterion for conservativeness in terms of the symbol is

liminf
r→∞

sup

|y−x|(cid:54)2r

sup
|η|(cid:54)1/r

|q(y,η)| < ∞ for all x ∈ Rd,

see [9, Theorem 2.34].

12. Symbols and semimartingales

So far, we have been treating the symbol q(x,ξ ) of (the generator of) a Feller process X as an an-
alytic object. On the other hand, Theorem 11.13 indicates, that there should be some probabilistic
consequences. In this chapter we want to follow this lead, show a probabilistic method to calcu-
late the symbol and link it to the semimartingale characteristics of a Feller process. The blueprint
for this is the relation of the Lévy–Itô decomposition (which is the semimartingale decomposition
of a Lévy process, cf. Theorem 9.12) with the Lévy–Khintchine formula for the characteristic
exponent (which coincides with the symbol of a Lévy process, cf. Corollary 9.13).

For a Lévy process Xt with semigroup Pt f (x) = Ex f (Xt) = E f (Xt + x) the symbol can be cal-

culated in the following way:
e−ξ (x)Pteξ (x)− 1

lim
t→0

t

Exeiξ·(Xt−x) − 1

t

e−tψ(ξ ) − 1

t

= lim
t→0

= −ψ(ξ ).

= lim
t→0

(12.1)

For a Feller process a similar formula is true.

Theorem 12.1. Let X = (Xt)t(cid:62)0 be a Feller process with transition semigroup (Pt)t(cid:62)0 and gen-
c (Rd) ⊂ D(A).
If x (cid:55)→ q(x,ξ ) is continuous and q has bounded
erator (A, D(A)) such that C∞
coefﬁcients (Lemma 11.8 with F = Rd), then

Exeiξ·(Xt−x) − 1

− q(x,ξ ) = lim
t→0

c (Rd), 1B1(0) (cid:54) χ (cid:54) 1B2(0) and set χn(x) := χ(cid:0) x

t

.

n

(cid:1). Obviously, χn → 1 as n → ∞.

(12.2)

Proof. Pick χ ∈ C∞
By Lemma 5.4,

Pt[χneξ ](x)− χn(x)eξ (x) =

APs[χneξ ](x)ds

(cid:90) t

0

(cid:90) t
(cid:90) t
(cid:90)
(cid:90) t

0

0
= Ex
= −

Rd

A[χneξ ](Xs)ds

(cid:17)
Ex(cid:16)
eη (Xs)q(Xs,η)(cid:100)χneξ (η)
(cid:124) (cid:123)(cid:122) (cid:125)
=nd(cid:98)χ(n(η−ξ ))
(cid:2)eξ q(·,ξ )(cid:3)(x)ds.
(cid:0)Pteξ (x)− eξ (x)(cid:1) = −eξ (x)q(x,ξ ).

−−−→
n→∞

−

Ps

0

dη ds

1
t

lim
t→0

84

Since x (cid:55)→ q(x,ξ ) is continuous, we can divide by t and let t → 0; this yields

Chapter 12: Symbols and semimartingales

85

Theorem 12.1 is a relatively simple probabilistic formula to calculate the symbol. We want to
relax the boundedness and continuity assumptions. Here Dynkin’s characteristic operator becomes
useful.

Lemma 12.2 (Dynkin’s formula). Let (Xt)t(cid:62)0 be a Feller process with semigroup (Pt)t(cid:62)0 and
generator (A, D(A)). For every stopping time σ with Exσ < ∞ one has

(cid:90)

Ex f (Xσ )− f (x) = Ex

(cid:90)

[0,τr∧n)

f ∈ D(A).

[0,σ )

A f (Xs)ds,

:= f (Xt)− f (X0)−(cid:82) t

(12.3)

Proof. From Corollary 11.4 we know that M[ f ]
t
thus (12.3) follows from the optional stopping theorem.
Deﬁnition 12.3. Let (Xt)t(cid:62)0 be a Feller process. A point a ∈ Rd is an absorbing point, if

0 A f (Xs)ds is a martingale;

Pa(Xt = a, ∀t (cid:62) 0) = 1.

Denote by τr := inf{t > 0 : |Xt − X0| (cid:62) r} the ﬁrst exit time from the ball Br(x) centered at the

starting position x = X0.
Lemma 12.4. Let (Xt)t(cid:62)0 be a Feller process and assume that b ∈ Rd is not absorbing. Then there
exists some r > 0 such that Ebτr < ∞.
Proof. 1◦ If b is not absorbing, then there is some f ∈ D(A) such that A f (b) (cid:54)= 0. Assume the
contrary, i.e.

A f (b) = 0
By Lemma 5.4, Ps f ∈ D(A) for all s (cid:62) 0, and
Pt f (b)− f (b) =

for all

f ∈ D(A).

(cid:90) t

0

A(Ps f )(b)ds = 0.

So, Pt f (b) = f (b) for all f ∈ D(A). Since the domain D(A) is dense in C∞(Rd) (Remark 5.5), we
get Pt f (b) = f (b) for all f ∈ C∞(Rd), hence Pb(Xt = b) = 1 for any t (cid:62) 0. Therefore,

Pb(Xq = b, ∀q ∈ Q, q (cid:62) 0) = 1

and Pb(Xt = b, ∀t (cid:62) 0) = 1,

because of the right-continuity of the sample paths. This means that b is an absorbing point,
contradicting our assumption.
2◦ Pick f ∈ D(A) such that A f (b) > 0. Since A f is continuous, there exist ε > 0 and r > 0 such
that A f|Br(b) (cid:62) ε > 0. From Dynkin’s formula (12.3) with σ = τr ∧ n, n (cid:62) 1, we deduce

εEb(τr ∧ n) (cid:54) Eb

A f (Xs)ds = Eb f (Xτr∧n)− f (b) (cid:54) 2(cid:107) f(cid:107)∞.

Finally, monotone convergence shows that Ebτr (cid:54) 2(cid:107) f(cid:107)∞/ε < ∞.

86

R. L. Schilling: An Introduction to Lévy and Feller Processes

Deﬁnition 12.5 (Dynkin’s operator). Let X be a Feller process. The linear operator (A, D(A))
deﬁned by

lim
(cid:110)

Ex f (Xτr )− f (x)

A f (x) :=

D(A) :=

,

if x is not absorbing,

Exτr

r→0
0,
f ∈ C∞(Rd) : the above limit exists pointwise

otherwise,

(cid:111)

,

is called Dynkin’s (characteristic) operator.

Lemma 12.6. Let (Xt)t(cid:62)0 be a Feller process with generator (A, D(A)) and characteristic opera-
tor (A, D(A)).

a) A is an extension of A, i.e. D(A) ⊂ D(A) and A|D(A) = A.
b) (A, D) = (A, D(A)) if D = { f ∈ D(A) : f , A f ∈ C∞(Rd)}.

Proof. a) Let f ∈ D(A) and assume that x ∈ Rd is not absorbing. By Lemma 12.4 there is some
r = r(x) > 0 with Exτr < ∞. Since we have A f ∈ C∞(Rd), there exists for every ε > 0 some δ > 0
such that

Without loss of generality let δ < r. Using Dynkin’s formula (12.3) with σ = τδ , we see

|A f (y)− A f (x)| < ε

(cid:12)(cid:12) (cid:54) Ex
(cid:12)(cid:12)Ex f (Xτδ )− f (x)− A f (x)Exτδ
(cid:0)Ex f (Xτr )− f (x)(cid:1)(cid:14)Exτr = A f (x).

(cid:90)

for all y ∈ Bδ (x).
(cid:123)(cid:122)
(cid:124)

|A f (Xs)− A f (x)|

(cid:125)

[0,τδ )

(cid:54)ε

Thus, limr→0

If x is absorbing and f ∈ D(A), then A f (x) = 0 and so A f (x) = A f (x).
b) Since (A, D) satisﬁes the (PMP), the claim follows from Lemma 5.11.

ds (cid:54) εExτδ .

Theorem 12.7. Let (Xt)t(cid:62)0 be a Feller process with inﬁnitesimal generator (A, D(A)) such that
c (Rd) ⊂ D(A) and x (cid:55)→ q(x,ξ ) is continuous1. Then
C∞

− q(x,ξ ) = lim
r→0

Exei(Xτr−x)·ξ − 1

Exτr

(12.4)

for all x ∈ Rd (as usual, 1
Proof. Let χn ∈ C∞

∞ := 0). In particular, q(a,ξ ) = 0 for all absorbing states a ∈ Rd.

c (Rd) such that 1Bn(0) (cid:54) χn (cid:54) 1. By Dynkin’s formula (12.3)

e−ξ (x)Ex[χn(Xτr∧t)eξ (Xτr∧t)]− χn(x) = Ex

e−ξ (x)A[χneξ ](Xs)ds.

[0,τr∧t)

(cid:90)

1For instance, if X has bounded jumps, see Lemma 11.10 and Remark 11.12. Our proof will show that it is actually

enough to assume that s (cid:55)→ q(Xs,ξ ) is right-continuous.

Chapter 12: Symbols and semimartingales

87

Observe that A[χneξ ](Xs) is bounded if s < τr, see Corollary 11.6. Using the dominated conver-
gence theorem, we can let n → ∞ to get

e−ξ (x)Exeξ (Xτr∧t)− 1 = Ex
= −Ex
(11.6)

(cid:90)

[0,τr∧t)

e−ξ (x)Aeξ (Xs)ds
eξ (Xs − x)q(Xs,ξ )ds.

(12.5)

(cid:90)

[0,τr∧t)

(cid:90)

If x is absorbing, we have q(x,ξ ) = 0, and (12.4) holds trivially. For non-absorbing x, we pass to
the limit t → ∞ and get, using Exτr < ∞ (see Lemma 12.4),

e−ξ (x)Exeξ (Xτr )− 1

Exτr

= − 1
Exτr

Ex

[0,τr)

eξ (Xs − x)q(Xs,ξ )ds.

Since s (cid:55)→ q(Xs,ξ ) is right-continuous at s = 0, the limit r → 0 exists, and (12.4) follows.

A small variation of the above proof yields

Corollary 12.8 (Schilling, Schnurr [56]). Let X be a Feller process with generator (A, D(A)) such
that C∞

c (Rd) ⊂ D(A) and x (cid:55)→ q(x,ξ ) is continuous. Then

− q(x,ξ ) = lim
t→0

Exei(Xt∧τr−x)·ξ − 1

t

(12.6)

for all x ∈ Rd and r > 0.

Proof. We follow the proof of Theorem 12.7 up to (12.5). This relation can be rewritten as

Exei(Xt∧τr−x)·ξ − 1

t

= −1
t

Ex

eξ (Xs − x)q(Xs,ξ )1[0,τr)(s)ds.

(cid:90) t

0

Observe that Xs is bounded if s < τr and that s (cid:55)→ q(Xs,ξ ) is right-continuous. Therefore, the limit
t → 0 exists and yields (12.6).

Every Feller process (Xt)t(cid:62)0 such that C∞

c (Rd) ⊂ D(A) is a semimartingale. Moreover, the
semimartingale characteristics can be expressed in terms of the Lévy triplet (l(x),Q(x),ν(x,dy))
of the symbol. Recall that a (d-dimensional) semimartingale is a stochastic process of the form

(cid:90) t
(cid:90)

0

y1(0,1)(|y|)(cid:2)µX (·,ds,dy)− ν(·,ds,dy)(cid:3) +∑

Xt = X0 + X c

t +

1[1,∞)(|∆Xs|)∆Xs + Bt

s(cid:54)t

where X c is the continuous martingale part, B is a previsible process with paths of ﬁnite variation
(on compact time intervals) and with the jump measure

µX (ω,ds,dy) = ∑

s:∆Xs(ω)(cid:54)=0

δ(s,∆Xs(ω))(ds,dy)

whose compensator is ν(ω,ds,dy). The triplet (B,C,ν) with the (predictable) quadratic variation
C = [X c,X c] of X c is called the semimartingale characteristics.

88

R. L. Schilling: An Introduction to Lévy and Feller Processes

Theorem 12.9 (Schilling [52], Schnurr [58]). Let (Xt)t(cid:62)0 be a Feller process with inﬁnitesimal
c (Rd) ⊂ D(A) and symbol q(x,ξ ) given by (11.4). If q(x,0) = 0,2
generator (A, D(A)) such that C∞
then X is a semimartingale whose semimartingale characteristics can be expressed by the Lévy
triplet (l(x),Q(x),ν(x,dy))

(cid:90) t

0

(cid:90) t

0

Bt =

l(Xs)ds, Ct =

Q(Xs)ds,

ν(·,ds,dy) = ν(Xs(·),dy)ds.

Proof. 1◦ Combining Corollary 11.4 with the integro-differential representation (11.5) of the
generator shows that

(cid:90)
(cid:90)

[0,t)

(cid:90)

[0,t)

[0,t)

y(cid:54)=0

t = f (Xt)−
M[ f ]
= f (Xt)−
(cid:90)

−

A f (Xs)ds
l(Xs)· ∇ f (Xs)ds− 1
2

(cid:90)

(cid:2) f (Xs + y)− f (Xs)− ∇ f (Xs)· y1(0,1)(|y|)(cid:3)ν(Xs,dy)ds

∇· Q(Xs)∇ f (Xs)ds

[0,t)

b(Rd)∩ D(A) a martingale.

is for all f ∈ C2
2◦ We claim that C2
and pick a sequence fn ∈ C∞

c(Rd) ⊂ D(A). Indeed, let f ∈ C2

c(Rd) with supp f ⊂ Br(0) for some r > 0

c (B2r(0)) such that limn→∞(cid:107) f − fn(cid:107)(2) = 0. Using (11.7) we get
|A fn(x)− A fm(x)| (cid:54) c3r(cid:107) fn − fm(cid:107)(2) −−−−→
m,n→∞
c (B3r(0)) with | fn(x)| (cid:54) u(x).

0.

sup
|x|(cid:54)3r

Since supp fn ⊂ B2r(0) and fn → f uniformly, there is some u ∈ C∞
Therefore, we get for |x| (cid:62) 2r

|A fn(x)− A fm(x)| (cid:54)(cid:90)

(cid:90)

y(cid:54)=0

| fn(x + y)− fm(x + y)|ν(x,dy)
u(x + y)ν(x,dy) = 2Au(x) −−−→
|x|→∞

0

(cid:54) 2

y(cid:54)=0

uniformly for all m,n. This shows that (A fn)n∈N is a Cauchy sequence in C∞(Rd). By the closed-
ness of (A, D(A)) we gather that f ∈ D(A) and A f = limn→∞ A fn.
3◦ Fix r > 1, pick χr ∈ C∞
c (Rd) such that 1B3r(0) (cid:54) χ (cid:54) 1, and set

σ = σr := inf{t > 0 : |Xt − X0| (cid:62) r}∧ inf{t > 0 : |∆Xt| (cid:62) r}.

Since (Xt)t(cid:62)0 has càdlàg paths and inﬁnite life-time, σr is a family of stopping times with σr ↑ ∞.

2A sufﬁcient condition is, for example, that X has inﬁnite life-time and x (cid:55)→ q(x,ξ ) is continuous (either for all ξ

or just for ξ = 0), cf. Theorem 11.13 and Lemma 11.10.

Chapter 12: Symbols and semimartingales

89

For any f ∈ C2(Rd)∩ Cb(Rd) and x ∈ Rd we set fr := χr f , f x := f (·− x), f x

r (·− x), and consider

(cid:90)
(cid:90)
(cid:90)
(cid:90)

t∧σ = f x(Xt∧σ )−
M[ f x]

(cid:90)

= f x

−
[0,t∧σ )
r (Xt∧σ )−
(cid:90)
−

[0,t∧σ )

(cid:90)

(cid:90)

[0,t∧σ )

∇· Q(Xs)∇ f x(Xs)ds

l(Xs)· ∇ f x(Xs)ds− 1
2

(cid:2) f x(Xs + y)− f x(Xs)− ∇ f x(Xs)· y1(0,1)(|y|)(cid:3)ν(Xs,dy)ds
r (Xs)· y1(0,1)(|y|)(cid:3)ν(Xs,dy)ds
(cid:2) f x

[0,t∧σ )
r (Xs)− ∇ f x

r (Xs)ds− 1
2

r (Xs + y)− f x

l(Xs)· ∇ f x

∇· Q(Xs)∇ f x

r (Xs)ds

[0,t∧σ )

y(cid:54)=0

[0,t∧σ )

0<|y|<r

= M[ f x
r ]
t∧σ .
c(Rd) ⊂ D(A), we see that M[ f x]

t

Since fr ∈ C2
is a local martingale (with reducing sequence σr,
r > 0), and by a general result of Jacod & Shiryaev [27, Theorem II.2.42], it follows that X is a
semimartingale with the characteristics mentioned in the theorem.

We close this chapter with the discussion of a very important example: Lévy driven stochastic

differential equations. From now on we assume that

Φ : Rd → Rd×n is a matrix-valued, measurable function,

L = (Lt)t(cid:62)0 is an n-dimensional Lévy process with exponent ψ(ξ ),

and consider the following Itô stochastic differential equation (SDE)

dXt = Φ(Xt−)dLt, X0 = x.

(12.7)

If Φ is globally Lipschitz continuous, then the SDE (12.7) has a unique solution which is a strong
Markov process, see Protter [42, Chapter V, Theorem 32]3. If we write X x
t for the solution of (12.7)
with initial condition X0 = x = X x
is continuous [42, Chapter V, Theorem
38].

0 , then the ﬂow x (cid:55)→ X x

If we use Lt = (t,Wt,Jt)(cid:62) as driving Lévy process where W is a Brownian motion and J is a
pure-jump Lévy process (we assume4 that W ⊥⊥J), and if Φ is a block-matrix, then we see that
(12.7) covers also SDEs of the form

t

dXt = f (Xt−)dt + F(Xt−)dWt + G(Xt−)dJt.

Lemma 12.10. Let Φ be bounded and Lipschitz, X the unique solution of the SDE (12.7), and
denote by A the generator of X. Then C∞

c (Rd) ⊂ D(A).

3Protter requires that L has independent coordinate processes, but this is not needed in his proof. For existence and
uniqueness the local Lipschitz and linear growth conditions are enough; the strong Lipschitz condition is used for the
Markov nature of the solution.

4This assumption can be relaxed under suitable assumptions on the (joint) ﬁltration, see for example Ikeda &

Watanabe [22, Theorem II.6.3]

90

R. L. Schilling: An Introduction to Lévy and Feller Processes

Proof. Because of Theorem 5.12 (this theorem does not only hold for Feller semigroups, but
for any strongly continuous contraction semigroup satisfying the positive maximum principle), it
sufﬁces to show

1
t

lim
t→0

(cid:0)Ex f (Xt)− f (x)(cid:1) = g(x)
(cid:90) t

Ex f (Xt)− f (x) = Ex

and g ∈ C∞(Rd)

A f (Xs)ds,

0

for any f ∈ C∞

c (Rd). For this we use, as in the proof of the following theorem, Itô’s formula to get

and a calculation similar to the one in the proof of the next theorem. A complete proof can be
found in Schilling & Schnurr [56, Theorem 3.5].

Theorem 12.11. Let (Lt)t(cid:62)0 be an n-dimensional Lévy process with exponent ψ and assume that Φ
is Lipschitz continuous. Then the unique Markov solution X of the SDE (12.7) admits a generalized
symbol in the sense that

Exei(Xt∧τr−x)·ξ − 1

lim
t→0

= −ψ(Φ(cid:62)(x)ξ ),

r > 0.

t
c (Rd) ⊂ D(A) and q(x,ξ ) = ψ(Φ(cid:62)(x)ξ ) is the symbol of the

If Φ ∈ C1
generator.

b(Rd), then X is Feller, C∞

Theorem 12.11 indicates that the formulae (12.4) and (12.6) may be used to associate symbols
not only with Feller processes but with more general Markov semimartingales. This has been
investigated by Schnurr [57] and [58] who shows that the class of Itô processes with jumps is
essentially the largest class that can be described by symbols; see also [9, Chapters 2.4–5]. This
opens up the way to analyze rather general semimartingales using the symbol. Let us also point
out that the boundedness of Φ is only needed to ensure that X is a Feller process.

Proof. Let τ = τr be the ﬁrst exit time for the process X from the ball Br(x) centered at x = X0.
We use the Lévy–Itô decomposition (9.9) of L. From Itô’s formula for jump processes (see, e.g.
Protter [42, Chapter II, Theorem 33]) we get

Ex(cid:0)eξ (Xt∧τ − x)− 1(cid:1)
(cid:20)(cid:90) t∧τ

1
t

(cid:90) t∧τ

=

Ex

1
t

0

ieξ (Xs− − x)ξ dXs − 1
2

eξ (Xs− − x)ξ · d[X,X]c
sξ

(cid:0)eξ (Xs)− eξ (Xs−)− ieξ (Xs−)ξ · ∆Xs

0

(cid:1)(cid:21)

+ e−ξ (x) ∑
s(cid:54)τ∧t

=: I1 + I2 + I3.

Chapter 12: Symbols and semimartingales

91

We consider the three terms separately.

I1 =

=

(cid:90) t∧τ
(cid:90) t∧τ
(cid:90) t∧τ

0

0

Ex

Ex

Ex

1
t
1
t
1
t

=

0
=: I11 + I12

ieξ (Xs− − x)ξ dXs
(cid:20)
ieξ (Xs− − x)ξ · Φ(Xs−)dLs
ieξ (Xs− − x)ξ · Φ(Xs−)ds

ls +

(cid:21)

yNs(dy)

(cid:90)

|y|(cid:62)1

where we use that the diffusion part and the compensated small jumps of a Lévy process are a
martingale, cf. Theorem 9.12. Further,

0

y(cid:54)=0

eξ (Xs− − x)(cid:2)eξ (Φ(Xs−)y)− 1− iξ · Φ(Xs−)y1(0,1)(|y|)(cid:3) dsNs(dy)
eξ (Xs− − x)(cid:2)eξ (Φ(Xs−)y)− 1− iξΦ(Xs−)y1(0,1)(|y|)(cid:3) ν(dy)ds

(cid:90)
(cid:90) t∧τ
(cid:90) t∧τ
(cid:90)
(cid:2)eiξ·Φ(x)y − 1− iξ · Φ(x)y1(0,1)(|y|)(cid:3)ν(dy).

y(cid:54)=0

0

=

I3 + I12
1
t
1
=
t
−−→
t→0

Ex

Ex

(cid:90)

y(cid:54)=0

0

Ex

1
t

I11 =

(cid:105)c

[X,X]c =

(cid:90) t∧τ

iξ · Φ(x)l,

and, ﬁnally, we observe that

Here we use that ν(dy)ds is the compensator of dsNs(dy), see Lemma 9.5. This requires that the
(cid:82)
integrand is ν-integrable, but this is ensured by the local boundedness of Φ(·) and the fact that
y(cid:54)=0 min{|y|2,1}ν(dy) < ∞. Moreover,
ieξ (Xs− − x)ξ · Φ(Xs−)l ds −−→
t→0
(cid:104)(cid:90)
(cid:90)
(cid:90)
(cid:90) t∧τ
(cid:90) t∧τ
ξ · Φ(x)QΦ(cid:62)(x)ξ .

eξ (Xs− − x)ξ · d[X,X]c
sξ
eξ (Xs− − x)ξ · Φ(Xs−)QΦ(cid:62)(Xs−)ξ ds

Φ(Xs−)d[L,L]c
Φ(Xs−)QΦ(cid:62)(Xs−)ds ∈ Rd×d

(cid:90)
Φ(Xs−)dLs
s Φ(cid:62)(Xs−)

Ex

I2 = − 1
2t
= − 1
Ex
2t
−1
−−→
t→0
2

Φ(Xs−)dLs,

which gives

0

0

=

=

This proves

q(x,ξ ) = −il · Φ(cid:62)(x)ξ +

(cid:90)

1
2

ξ · Φ(x)QΦ(cid:62)(x)ξ

(cid:2)1− eiy·Φ(cid:62)(x)ξ + iy· Φ(cid:62)(x)ξ 1(0,1)(|y|)(cid:3)ν(dy)

+

y(cid:54)=0

= ψ(Φ(cid:62)(x)ξ ).

92

R. L. Schilling: An Introduction to Lévy and Feller Processes

c (Rd) ⊂ D(A). The con-
For the second part of the theorem we use Lemma 12.10 to see that C∞
tinuity of the ﬂow x (cid:55)→ X x
t (Protter [42, Chapter V, Theorem 38])—X x is the unique solution of
0 = x—ensures that the semigroup Pt f (x) := Ex f (Xt) = E f (X x
the SDE with initial condition X x
t )
maps f ∈ C∞(Rd) to Cb(Rd). In order to see that Pt f ∈ C∞(Rd) we need that lim|x|→∞|X x
t | = ∞
a.s. This requires some longer calculations, see e.g. Schnurr [57, Theorem 2.49] or Kunita [33,
Proof of Theorem 3.5, p. 353, line 13 from below] (for Brownian motion this argument is fully
worked out in Schilling & Partzsch [55, Corollary 19.31]).

13. Dénouement

It is well known that the characteristic exponent ψ(ξ ) of a Lévy process L = (Lt)t(cid:62)0 can be used
to describe many probabilistic properties of the process. The key is the formula

Exeiξ·(Lt−x) = Eeiξ·Lt = e−tψ(ξ )

(13.1)
which gives access to the Fourier transform of the transition function Px(Lt ∈ dy) = P(Lt +x∈ dy).
Although it is not any longer true that the symbol q(x,ξ ) of a Feller process X = (Xt)t(cid:62)0 is the
characteristic exponent, we may interpret formulae like (12.4)

−q(x,ξ ) = lim
r→0

Exei(Xτr−x)·ξ − 1

Exτr

as inﬁnitesimal versions of the relation (13.1). What is more, both ψ(ξ ) and q(x,ξ ) are the
Fourier symbols of the generators of the processes. We have already used these facts to discuss
the conservativeness of Feller processes (Theorem 11.13) and the semimartingale decomposition
of Feller processes (Theorem 12.9).

It is indeed possible to investigate further path properties of a Feller process using its symbol
q(x,ξ ). Below we will, mostly without proof, give some examples which are taken from Böttcher,
Schilling & Wang [9]. Let us point out the two guiding principles.

(cid:73) For sample path properties, the symbol q(x,ξ ) of a Feller process assumes same
role as the characteristic exponent ψ(ξ ) of a Lévy process.
(cid:73)(cid:73) A Feller process is ‘locally Lévy’, i.e. for short-time path properties the Feller
process, started at x0, behaves like the Lévy process (Lt + x0)t(cid:62)0 with characteristic
exponent ψ(ξ ) := q(x0,ξ ).

The latter property is the reason why such Feller processes are often called Lévy-type processes.
The model case is the stable-like process whose symbol is given by q(x,ξ ) = |ξ|α(x) where the
exponent α : Rd → (0,2) is sufﬁciently smooth1. This process behaves locally, and for short times
t (cid:28) 1, like an α(x)-stable process, only that the index now depends on the starting point X0 = x.
The key to many path properties are the following maximal estimates which were ﬁrst proved
in [52]. The present proof is taken from [9], the observation that we may use a random time τ
instead of a ﬁxed time t is due to F. Kühn.

1In dimension d = 1 Lipschitz or even Dini continuity is enough (see Bass [4]), in higher dimensions we need

something like C5d+3-smoothness, cf. Hoh [21].

93

94

R. L. Schilling: An Introduction to Lévy and Feller Processes

Theorem 13.1. Let (Xt)t(cid:62)0 be a Feller process with generator A, C∞
q(x,ξ ). If τ is an integrable stopping time, then

c (Rd) ⊂ D(A) and symbol

Px

sup
s(cid:54)τ

|Xs − x| > r

(cid:54) c Exτ sup
|y−x|(cid:54)r

sup
|ξ|(cid:54)r−1

|q(y,ξ )|.

(13.2)

Proof. Denote by σr = σ x

r the ﬁrst exit time from the closed ball Br(x). Clearly,
{σ x

|Xs − x| > r

r < τ} ⊂

r (cid:54) τ} .

⊂ {σ x

Pick u ∈ C∞

c (Rd), 0 (cid:54) u (cid:54) 1, u(0) = 1, suppu ⊂ B1(0), and set

(cid:27)
(cid:18)y− x

(cid:19)

.

r

(cid:18)

(cid:19)

(cid:26)

sup
s(cid:54)τ

ux
r(y) := u

In particular, ux

r|Br(x)c = 0. Hence,

r (cid:54)τ} (cid:54) 1− ux

1{σ x

r(Xτ∧σ x

r ).

Now we can use (5.5) or (12.3) to get

r (cid:54) τ) (cid:54) Ex(cid:2)1− ux

Px(σ x

r(Xτ∧σ x

(cid:90)
(cid:90)
(cid:90)

= Ex

= Ex

[0,τ∧σ x
r )

[0,τ∧σ x
r )

(cid:54) Ex

[0,τ∧σ x
r )
= Ex [τ ∧ σ x
r ]

(cid:90)
(cid:90)
(cid:90)

q(Xs,D)ux

r(Xs)ds

r )(cid:3)
1Br(x)(Xs)eξ (Xs)q(Xs,ξ )(cid:98)ux
r(ξ )|dξ ds
r(ξ )|dξ
(1 +|ξ|2)|(cid:98)u(ξ )|dξ .

|q(y,ξ )||(cid:98)ux
|q(y,ξ )||(cid:98)ux
(cid:90)

|q(y,ξ )|

sup
|y−x|(cid:54)r

sup
|y−x|(cid:54)r

r(ξ )dξ ds

(11.9)(cid:54)
L 11.8

c Exτ sup
|y−x|(cid:54)r

sup
|ξ|(cid:54)r−1

There is a also a probability estimate for sups(cid:54)t |Xs − x| (cid:54) r, but this requires some sector

condition for the symbol, that is an estimate of the form
|Imq(x,ξ )| (cid:54) κ Req(x,ξ ),

x,ξ ∈ Rd.

(13.3)

One consequence of (13.3) is that the drift (which is contained in the imaginary part of the symbol)
is not dominant. This is a familiar assumption in the study of path properties of Lévy processes,
see e.g. Blumenthal & Getoor [8]; a typical example where this condition is violated are (Lévy)
symbols of the form ψ(ξ ) = iξ +|ξ| 1
2 . For a Lévy process the sector condition on ψ coincides
with the sector condition for the generator and the associated non-symmetric Dirichlet form, see
Jacob [26, Volume 1, 4.7.32–33].

Chapter 13: Dénouement

95

With some more effort (see [9, Theorem 5.5]), we may replace the sector condition by imposing

conditions on the expression

sup
|y−x|(cid:54)r

Req(x,ξ )

|ξ||Imq(y,ξ )|

as r → ∞.

Theorem 13.2 (see [9, pp. 117–119]). Let (Xt)t(cid:62)0 be a Feller process with inﬁnitesimal generator
A, C∞

c (Rd) ⊂ D(A) and symbol q(x,ξ ) satisfying the sector condition (13.3). Then

(cid:18)

(cid:19)

Px

sup
s(cid:54)t

|Xs − x| < r

(cid:54)

cκ,d

t sup|ξ|(cid:54)r−1 inf|y−x|(cid:54)2r |q(y,ξ )| .

(13.4)

The maximal estimates (13.2) and (13.4) are quite useful tools. With them we can estimate the

mean exit time from balls (X and q(x,ξ ) are as in Theorem 13.2):

r (cid:54)
sup|ξ|(cid:54)1/r inf|y−x|(cid:54)r |q(y,ξ )| (cid:54) Exσ x

for all x ∈ Rd and r > 0 and with k∗ = arccos(cid:112)2/3 ≈ 0.615.

c

cκ

sup|ξ|(cid:54)k∗/r inf|y−x|(cid:54)r|q(y,ξ )|

Recently, Kühn [30] studied the existence of and estimates for generalized moments; a typical

result is contained in the following theorem.

Theorem 13.3. Let X = (Xt)t(cid:62)0 be a Feller process with inﬁnitesimal generator (A, D(A)) and
c (Rd) ⊂ D(A). Assume that the symbol q(x,ξ ), given by (11.4), satisﬁes q(x,0) = 0 and has
C∞
(l(x),Q(x),ν(x,dy)) as x-dependent Lévy triplet. If f : Rd → [0,∞) is (comparable to) a twice
continuously differentiable submultiplicative function such that

representatives, for a full discussion we refer to [9].

Deﬁnition 13.4. Let q(x,ξ ) be the symbol of a Feller process. Then

β x
∞ := inf

λ > 0 :

δ x
∞ := sup

λ > 0 :

lim|ξ|→∞

lim|ξ|→∞

sup|η|(cid:54)|ξ| sup|y−x|(cid:54)1/|ξ||q(y,η)|
inf|η|(cid:54)|ξ| inf|y−x|(cid:54)1/|ξ||q(y,η)|

|ξ|λ

|ξ|λ

(cid:27)
(cid:27)

= 0

= ∞

,

.

(13.5)

(13.6)

f (y)ν(x,dy) < ∞ for a compact set K ⊂ Rd,
then the generalized moment supx∈K sups(cid:54)t Ex f (Xs∧τK − x) < ∞ exists and

sup
x∈K

here τK = inf{t > 0 : Xt /∈ K} is the ﬁrst exit time from K, C = CK is some absolute constant and

(cid:16)|l(x)| +|Q(x)| +

Ex f (Xt∧τK ) (cid:54) c f (x)eC(M1+M2)t;
(cid:90)

(|y|2 ∧ 1)ν(x,dy)

(cid:17)

(cid:90)

M1 = sup
x∈K

, M2 = sup
x∈K
If X has bounded coefﬁcients (Lemma 11.8), then K = Rd is admissible.

y(cid:54)=0

|y|(cid:62)1

f (y)ν(x,dy).

There are also counterparts for the Blumenthal–Getoor and Pruitt indices. Below we give two

(cid:90)

(cid:26)
(cid:26)

96

R. L. Schilling: An Introduction to Lévy and Feller Processes

By deﬁnition, 0 (cid:54) δ x
function α(x), then β x
coincide.

∞ (cid:54) β x
∞ = δ x

∞ (cid:54) 2. For example, if q(x,ξ ) = |ξ|α(x) with a smooth exponent
∞ = α(x); in general, however, we cannot expect that the two indices

As for Lévy processes, these indices can be used to describe the path behaviour.

Theorem 13.5. Let (Xt)t(cid:62)0 be a d-dimensional Feller process with the generator A such that
c (Rd) ⊂ D(A) and symbol q(x,ξ ). For every bounded analytic set E ⊂ [0,∞), the Hausdorff
C∞
dimension

(cid:40)

(cid:41)

dim{Xt : t ∈ E} (cid:54) min

d, sup
x∈Rd

β x
∞ dimE

.

(13.7)

A proof can be found in [9, Theorem 5.15]. It is instructive to observe that we have to take
the supremum w.r.t. the space variable x, as we do not know how the process X moves while we
observe it during t ∈ E. This shows that we can only expect to get ‘exact’ results if t → 0. Here is
such an example.

Theorem 13.6. Let (Xt)t(cid:62)0 be a d-dimensional Feller process with symbol q(x,ξ ) satisfying the
sector condition. Then, Px-a.s.

sup0(cid:54)s(cid:54)t |Xs − x|
sup0(cid:54)s(cid:54)t |Xs − x|

t1/λ

t1/λ

lim
t→0

lim
t→0

= 0

= ∞

∀λ > β x
∞,
∀λ < δ x
∞.

(13.8)

(13.9)

As one would expect, these results are proved using the maximal estimates (13.2) and (13.4) in

conjunction with the Borel–Cantelli lemma, see [9, Theorem 5.16].

If we are interested in the long-term behaviour, one could introduce indices ‘at zero’, where we
replace in Deﬁnition 13.4 the limit |ξ| → ∞ by |ξ| → 0, but we will always have to pay the price
that we loose the inﬂuence of the starting point X0 = x, i.e. we will have to take the supremum or
inﬁmum for all x ∈ Rd.

With the machinery we have developed here, one can also study further path properties, such as
invariant measures, ergodicity, transience and recurrence etc. For this we refer to the monograph
[9] as well as recent developments by Behme & Schnurr [7] and Sandri´c [48, 49].

A. Some classical results

In this appendix we collect some classical results from (or needed for) probability theory which
are not always contained in a standard course.

The Cauchy–Abel functional equation

Below we reproduce the standard proof for continuous functions which, however, works also for
right-continuous (or monotone) functions.

Theorem A.1. Let φ : [0,∞) → C be a right-continuous function satisfying the functional equation
φ (s +t) = φ (s)φ (t). Then φ (t) = φ (1)t.

Proof. Assume that φ (a) = 0 for some a (cid:62) 0. Then we ﬁnd for all t (cid:62) 0

φ (a +t) = φ (a)φ (t) = 0 =⇒ φ|[a,∞) ≡ 0.

To the left of a we ﬁnd for all n ∈ N

0 = φ (a) =(cid:2)φ(cid:0) a

n

(cid:1)(cid:3)n

=⇒ φ(cid:0) a

n

(cid:1) = 0.

Since φ is right-continuous, we infer that φ|[0,∞) ≡ 0, and φ (t) = φ (1)t holds.

Now assume that φ (1) (cid:54)= 0. Setting f (t) := φ (t)φ (1)−t we get

f (s +t) = φ (s +t)φ (1)−(s+t) = φ (s)φ (1)−sφ (t)φ (1)−t = f (s) f (t)

as well as f (1) = 1. Applying the functional equation k times we conclude that

n

f(cid:0) k
(cid:1)(cid:3)k
(cid:1) =(cid:2) f(cid:0) 1
=(cid:2) f(cid:0) 1
(cid:1)(cid:3)n k
(cid:1)(cid:3)k
n =(cid:2) f(cid:0) n

n

n

(cid:2) f(cid:0) 1

n

for all k,n ∈ N.

(cid:1)(cid:3) k
n =(cid:2) f (1)(cid:3) k

n = 1.

n

The same calculation done backwards yields

f|Q+ ≡ 1. Since φ, hence f , is right-continuous, we see that f ≡ 1 or, equivalently,

Hence,
φ (t) = [φ (1)]t for all t > 0.

97

98

R. L. Schilling: An Introduction to Lévy and Feller Processes

Characteristic functions and moments

Theorem A.2 (Even moments and characteristic functions). Let Y = (Y (1), . . . ,Y (d)) be a random
variable in Rd and let χ(ξ ) = Eeiξ·Y be its characteristic function. Then E(|Y|2) exists if, and
only if, the second derivatives ∂ 2
χ(0), k = 1, . . . ,d, exist and are ﬁnite. In this case all mixed
∂ξ 2
k
second derivatives exist and

EY (k) =

1
i

∂ χ(0)
∂ξk

and E(Y (k)Y (l)) = −∂ 2χ(0)
∂ξk∂ξl

.

(A.1)

Proof. In order to keep the notation simple, we consider only d = 1. If E(Y 2) < ∞, then the formu-
lae (A.1) are routine applications of the differentiation lemma for parameter-dependent integrals,
see e.g. [53, Theorem 11.5] or [54, Satz 12.2]. Moreover, χ is twice continuously differentiable.

Let us prove that E(Y 2) (cid:54) −χ(cid:48)(cid:48)(0). An application of l’Hospital’s rule gives

(cid:19)

χ(cid:48)(0)− χ(cid:48)(−2h)

2h

χ(cid:48)(cid:48)(0) = lim
h→0

= lim
h→0

= lim
h→0

= lim
h→0

E

= − lim
h→0

(cid:18) χ(cid:48)(2h)− χ(cid:48)(0)

+

2h

1
2
χ(cid:48)(2h)− χ(cid:48)(−2h)
χ(2h)− 2χ(0) + χ(−2h)

4h

2h

4h2

(cid:19)2(cid:35)
(cid:34)(cid:18)eihY − e−ihY
(cid:34)(cid:18)sinhY
(cid:19)2(cid:35)
(cid:34)
(cid:18)sinhY

(cid:19)2(cid:35)

E

h

.

From Fatou’s lemma we get

= −E(cid:2)Y 2(cid:3).
In the multivariate case observe that E|Y (k)Y (l)| (cid:54) E(cid:2)(Y (k))2(cid:3) + E(cid:2)(Y (l))2(cid:3).

χ(cid:48)(cid:48)(0) (cid:54) −E

lim
h→0

h

Vague and weak convergence of measures

A sequence of locally ﬁnite1 Borel measures (µn)n∈N on Rd converges vaguely to a locally ﬁnite
measure µ if

(cid:90)

(cid:90)

lim
n→∞

φ dµn =

φ dµ for all φ ∈ Cc(Rd).

(A.2)

Since the compactly supported continuous functions Cc(Rd) are dense in the space of continuous
functions vanishing at inﬁnity C∞(Rd) ={φ ∈ C(Rd) : lim|x|→∞ φ (x) = 0}, we can replace in (A.2)
the set Cc(Rd) with C∞(Rd). The following theorem guarantees that a family of Borel measures
is sequentially relatively compact2 for the vague convergence.

1I.e. every compact set K has ﬁnite measure.
2Note that compactness and sequential compactness need not coincide!

Appendix A: Some classical results

99

Theorem A.3. Let (µt)t(cid:62)0 be a family of measures on Rd which is uniformly bounded, in the sense
that supt(cid:62)0 µt(Rd) < ∞. Then every sequence (µtn)n∈N has a vaguely convergent subsequence.

If we test in (A.2) against all bounded continuous functions φ ∈ Cb(Rd), we get weak conver-

gence of the sequence µn → µ. One has

Theorem A.4. A sequence of measures (µn)n∈N converges weakly to µ if, and only if, µn converges
vaguely to µ and limn→∞ µn(Rd) = µ(Rd) (preservation of mass). In particular, weak and vague
convergence coincide for sequences of probability measures.

Chapter III.6] or Schilling [54, Chapter 25].

Proofs and a full discussion of vague and weak convergence can be found in Malliavin [39,

For any ﬁnite measure µ on Rd we denote byqµ(ξ ) :=(cid:82)
If µn → µ weakly, then the characteristic functionsqµn(ξ ) converge locally uniformly toqµ(ξ ).
Conversely, if the limit limn→∞qµn(ξ ) = χ(ξ ) exists for all ξ ∈ Rd and deﬁnes a function χ
which is continuous at ξ = 0, then there exists a ﬁnite measure µ such that qµ(ξ ) = χ(ξ ) and

Theorem A.5 (Lévy’s continuity theorem). Let (µn)n∈N be a sequence of ﬁnite measures on Rd.

Rd eiξ·y µ(dy) its characteristic function.

µn → µ weakly.

A proof in one dimension is contained in the monograph by Breiman [10], d-dimensional ver-

sions can be found in Bauer [5, Chapter 23] and Malliavin [39, Chapter IV.4].

Convergence in distribution
By d−−→ we denote convergence in distribution.
Theorem A.6 (Convergence of types). Let (Yn)n∈N, Y and Y (cid:48) be random variables and suppose
that there are constants an > 0, cn ∈ R such that

Yn

d−−−→
n→∞

Y

and

anYn + cn

d−−−→
n→∞

Y (cid:48).

If Y and Y (cid:48) are non-degenerate, then the limits a = lim
n→∞

an and c = lim
n→∞

cn exist and Y (cid:48) ∼ aY + c.

Proof. Write χZ(ξ ) := Eeiupξ Z for the characteristic function of the random variable Z.
1◦ By Lévy’s continuity theorem (Theorem A.5) convergence in distribution ensures that

χanYn+cn(ξ ) = eicn·ξ χYn(anξ )

−−−−−−→
locally unif.
Take some subsequence (an(k))k∈N ⊂ (an)n∈N such that limk→∞ an(k) = a ∈ [0,∞].
2◦ Claim: a > 0. Assume, on the contrary, that a = 0.

and χYn(ξ )

−−−−−−→
locally unif.

χY(cid:48)(ξ )

n→∞

n→∞

χY (ξ ).

|χan(k)Yn(k)+cn(k)(ξ )| = |χYn(k)(an(k)ξ )| −−−→
k→∞

|χY (0)| = 1.

100

R. L. Schilling: An Introduction to Lévy and Feller Processes

Thus, |χY(cid:48)| ≡ 1 which means that Y (cid:48) would be degenerate, contradicting our assumption.
3◦ Claim: a < ∞. If a = ∞, we use Yn = (an)−1(Yn − cn) and the argument from step 1◦ to reach
the contradiction

(an(k))−1 −−−→
k→∞

a−1 > 0 ⇐⇒ a < ∞.

4◦ Claim: There exists a unique a ∈ [0,∞) such that limn→∞ an = a. Assume that there were two
different subsequential limits an(k) → a, am(k) → a(cid:48) and a (cid:54)= a(cid:48). Then

|χan(k)Yn(k)+cn(k)(ξ )| = |χan(k)Yn(k)(ξ )| −−−→
k→∞
|χam(k)Ym(k)+cm(k)(ξ )| = |χam(k)Ym(k)(ξ )| −−−→
k→∞

χY (aξ ),
χY (a(cid:48)ξ ).

On the other hand, χY (aξ ) = χY (a(cid:48)ξ ) = χY(cid:48)(ξ ). If a(cid:48) < a, we get by iteration

|χY (ξ )| =(cid:12)(cid:12)χY

a ξ(cid:1)(cid:12)(cid:12) = ··· =(cid:12)(cid:12)χY
(cid:0) a(cid:48)

(cid:0)(cid:0) a(cid:48)

a

(cid:1)Nξ(cid:1)(cid:12)(cid:12) −−−→

N→∞

|χY (0)| = 1.

Thus, |χ| ≡ 1 and Y is a.s. constant. Since a,a(cid:48) can be interchanged, we conclude that a = a(cid:48).
5◦ We have

eicn·ξ =

χanYn+cn(ξ )
χanYn(ξ )

=

χanYn+cn(ξ )
χYn(anξ )

−−−→
n→∞

χY(cid:48)(ξ )
χY (aξ )

.

Since χY is continuous and χY (0) = 1, the limit limn→∞ eicn·ξ exists for all |ξ| (cid:54) δ and some small
δ . For ξ = tξ0 with |ξ0| = 1, we get

(cid:12)(cid:12)(cid:12)(cid:12) =

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) lim

n→∞

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) (cid:54) liminf

n→∞

2

|cn · ξ0| ,

eiδ cn·ξ0 − 1
icn · ξ0

(cid:12)(cid:12)(cid:12)(cid:12)(cid:90) δ

0

0 <

(cid:12)(cid:12)(cid:12)(cid:12) =

(cid:12)(cid:12)(cid:12)(cid:12) lim

n→∞

(cid:90) δ

0

χY(cid:48)(tξ0)
χY (taξ0)

dt

eitcn·ξ0 dt

and so limsupn→∞|cn| < ∞; if there were two limit points c (cid:54)= c(cid:48), then eic·ξ = eic(cid:48)·ξ for all |ξ| (cid:54) δ .
This gives c = c(cid:48), and we ﬁnally see that cn → c, eicn·ξ → eic·ξ , as well as

χY(cid:48)(ξ ) = eic·ξ χY (aξ ).

A random variable is called symmetric if Y ∼ −Y .

Theorem A.7 (Symmetrization inequality). Let Y1, . . . ,Yn be independent symmetric random vari-
ables. Then the partial sum Sn = Y1 +··· +Yn is again symmetric and
|Yk| > u

P(|Y1 +··· +Yn| > u) (cid:62) 1

(A.3)

(cid:16)

(cid:17)

P

.

2

max
1(cid:54)k(cid:54)n

If the Yk are iid with Y1 ∼ µ, then

P(|Y1 +··· +Yn| > u) (cid:62) 1

2

(cid:0)1− e−nP(|Y1|>u)(cid:1).

(A.4)

Appendix A: Some classical results

101

Proof. By independence, Sn = Y1 +··· +Yn ∼ −Y1 −···−Yn = −Sn.

Let τ = min{1 (cid:54) k (cid:54) n : |Yk| = max1(cid:54)l(cid:54)n|Yl|} and set Yn,τ = Sn −Yτ. Then the four (counting

all possible ± combinations) random variables (±Yτ ,±Yn,τ ) have the same law. Moreover,
P(Yτ > u) (cid:54) P(Yτ > u, Yn,τ (cid:62) 0) + P(Yτ > u, Yn,τ (cid:54) 0) = 2P(Yτ > u, Yn,τ (cid:62) 0),

and so

P(Sn > u) = P(Yτ +Yn,τ > u) (cid:62) P(Yτ > u, Yn,τ (cid:62) 0) (cid:62) 1

2

P(Yτ > u).

By symmetry, this implies (A.3). In order to see (A.4), we use that the Yk are iid, hence

P( max
1(cid:54)k(cid:54)n

|Yk| (cid:54) u) = P(|Y1| (cid:54) u)n (cid:54) e−nP(|Y1|>u),

along with the elementary inequality 1− p (cid:54) e−p for 0 (cid:54) p (cid:54) 1. This proves (A.4).

The predictable σ-algebra

Let (Ω, A , P) be a probability space and (Ft)t(cid:62)0 some ﬁltration. A stochastic process (Xt)t(cid:62)0 is
called adapted, if for every t (cid:62) 0 the random variable Xt is Ft measurable.
Deﬁnition A.8. The predictable σ-algebra P is the smallest σ-algebra on Ω× (0,∞) such that
all left-continuous adapted stochastic processes (ω,t) (cid:55)→ Xt(ω) are measurable. A P measurable
process X is called a predictable process.

For a stopping time τ we denote by

(cid:75)0,τ(cid:75) := {(ω,t) : 0 < t (cid:54) τ(ω)}

and (cid:75)τ,∞(cid:74):= {(ω,t) : t > τ(ω)}

(A.5)

the left-open stochastic intervals. The following characterization of the predictable σ-algebra is
essentially from Jacod & Shiryaev [27, Theorem I.2.2].

Theorem A.9. The predictable σ-algebra P is generated by any one of the following families of
random sets

a) (cid:75)0,τ(cid:75) where τ is any bounded stopping time;

b) Fs × (s,t] where Fs ∈ Fs and 0 (cid:54) s < t.

Proof. We write Pa and Pb for the σ-algebras generated by the families listed in a) and b),
respectively.
1◦ Pick 0 (cid:54) s < t, F = Fs ∈ Fs and let n > t. Observe that sF := s1F +n1Fc is a bounded stopping

time3 and F × (s,t] =(cid:75)sF ,tF(cid:75). Therefore,(cid:75)sF ,tF(cid:75) =(cid:75)0,tF(cid:75)\(cid:75)0,sF(cid:75) ∈ Pa, and we conclude that

Pb ⊂ Pa.

3Indeed, {sF (cid:54) t} = {s (cid:54) t}∩ F =

∈ Ft for all t (cid:62) 0.

(cid:40) /0,

F,

(cid:41)

s > t
s (cid:54) t

102

R. L. Schilling: An Introduction to Lévy and Feller Processes

2◦ Let τ be a bounded stopping time. Since t (cid:55)→ 1(cid:75)0,τ(cid:75)(ω,t) is adapted and left-continuous, we
have Pa ⊂ P.
3◦ Let X be an adapted and left-continuous process and deﬁne for every n ∈ N

X n
t

:=

∞
∑

k=0

Xk2−n1(cid:75)k2−n, (k+1)2−n(cid:75)(t).

Obviously, X n = (X n
limn→∞ X n

t )t(cid:62)0 is Pb measurable; because of the left-continuity of t (cid:55)→ Xt, the limit

t = Xt exists, and we conclude that X is Pb measurable; consequently, P ⊂ Pb.

The structure of translation invariant operators

Let ϑx f (y) := f (y + x) be the translation operator and (cid:101)f (x) := f (−x). A linear operator L :
c (Rd) → C(Rd) is called translation invariant if
C∞

ϑx(L f ) = L(ϑx f ).

(A.6)
c (Rd))(cid:48), i.e. a continuous linear func-
c (Rd) is deﬁned

A distribution λ is an element of the topological dual (C∞
tional λ : C∞
as

c (Rd) → R. The convolution of a distribution with a function f ∈ C∞

f ∗ λ (x) := λ (ϑ−x(cid:101)f ),

λ ∈(cid:0)C∞

If λ = µ is a measure, this formula generalizes the ‘usual’ convolution

, f ∈ C∞

c (Rd), x ∈ Rd.

c (Rd)(cid:1)(cid:48)
(cid:90) (cid:101)f (y− x) µ(dy) = µ(ϑ−x(cid:101)f ).

(cid:90)

f ∗ µ(x) =

f (x− y) µ(dy) =

Theorem A.10. If λ ∈ (C∞
invariant continuous linear map L : C∞

c (Rd) → C(Rd).

c (Rd))(cid:48) is a distribution, then L f (x) := f ∗ λ (x) deﬁnes a translation

c (Rd) → C(Rd) is of the

Conversely, every translation-invariant continuous linear map L : C∞

form L f = f ∗ λ for some unique distribution λ ∈ (C∞
Proof. Let L f = f ∗ λ . From the very deﬁnition of the convolution we get

c (Rd))(cid:48).

(ϑ−x f )∗ λ = λ (ϑ−x

(cid:93)ϑ−x f ) = λ (ϑ−x[ f (x−·)])

For any sequence xn → x in Rd and f ∈ C∞
λ is a continuous linear functional on C∞

lim
n→∞

L f (xn) = lim
n→∞

= ϑ−xλ (ϑ−x[ f (−·)])
= ϑ−x( f ∗ λ ).

c (Rd) we know that ϑ−xn(cid:101)f → ϑ−x(cid:101)f in C∞
λ (ϑ−xn(cid:101)f ) = λ (ϑ−x(cid:101)f ) = L f (x)

c (Rd), we conclude that

c (Rd). Since

which shows that L f ∈ C(Rd). (With a similar argument based on difference quotients we could
even show that L f ∈ C∞(Rd).)

Appendix A: Some classical results

103

In order to prove the continuity of L, it is enough to show that L : C∞

c (K) → C(Rd) is continuous
c (Rd)). We
c (Rd) and fn ∗ λ → g in C(Rd), then

for every compact set K ⊂ Rd (this is because of the deﬁnition of the topology in C∞
will use the closed graph theorem: Assume that fn → f in C∞
we have to show that g = f ∗ λ .

For every x ∈ Rd we have ϑ−x(cid:101)fn → ϑ−x(cid:101)f in C∞
Assume now, that L is translation invariant and continuous. Deﬁne λ ( f ) := (L(cid:101)f )(0). Since L
is linear and continuous, and f (cid:55)→ (cid:101)f and the evaluation at x = 0 are continuous operations, λ is a

λ (ϑ−x(cid:101)fn) = λ (ϑ−x(cid:101)f ) = ( f ∗ λ )(x).

( fn ∗ λ )(x) = lim
n→∞

c (Rd), and so

g(x) = lim
n→∞

continuous linear map on C∞

c (Rd). Because of the translation invariance of L we get

(L f )(x) = (ϑxL f )(0) = L(ϑx f )(0) = λ ((cid:103)ϑx f ) = λ (ϑ−x(cid:101)f ) = ( f ∗ λ )(x).
(µ − λ )((cid:101)f ) = f ∗ (µ − λ )(0) = f ∗ µ(0)− f ∗ λ (0) = 0

If µ is a further distribution with L f (0) = f ∗ µ(0), we see

f ∈ C∞

for all

c (Rd)

which proves µ = λ .

Bibliography

[1] Aczél, J.: Lectures on Functional Equations and Their Applications. Academic Press, New

York (NY) 1966.

[2] Applebaum, D.: Lévy Processes and Stochastic Calculus. Cambridge University Press, Cam-

bridge 2009 (2nd ed).

[3] Barndorff-Nielsen, O.E. et al.: Lévy Processes. Theory and Applications. Birkhäuser, Boston

(MA) 2001.

[4] Bass, R.: Uniqueness in law for pure-jump Markov processes. Probab. Theor. Relat. Fields

79 (1988) 271–287.

[5] Bauer, H.: Probability Theory. De Gruyter, Berlin 1996.

[6] Bawly, G.M.: Über einige Verallgemeinerungen der Grenzwertsätze der Wahrscheinlich-

keitsrechnung. Mat. Sbornik (Réc. Math. Moscou, N.S.) 1 (1936) 917–930.

[7] Behme, A., Schnurr, A.: A criterion for invariant measures of Itô processes based on the

symbol. Bernoulli 21 (2015) 1697–1718.

[8] Blumenthal, R.M., Getoor, R.K.: Sample functions of stochastic processes with stationary

independent increments. J. Math. Mech. 10 (1961) 493–516.

[9] Böttcher, B., Schilling, R.L., Wang, J.: Lévy-type Processes: Construction, Approxima-
tion and Sample Path Properties. Lecture Notes in Mathematics 2099 (Lévy Matters III),
Springer, Cham 2014.

[10] Breiman, L.: Probability. Addison–Wesley, Reading (MA) 1968 (several reprints by SIAM,

Philadelphia).

[11] Bretagnolle, J.L.: Processus à accroissements independants. In: Bretagnolle, J.L. et al.:
École d’Été de Probabilités: Processus Stochastiques. Springer, Lecture Notes in Mathe-
matics 307, Berlin 1973, pp. 1–26.

[12] Çinlar, E.: Introduction to Stochastic Processes. Prentice–Hall, Englewood Cliffs (NJ) 1975

(reprinted by Dover, Mineola).

104

Bibliography

105

[13] Courrège, P.: Générateur inﬁnitésimal d’un semi-groupe de convolution sur Rn, et formule

de Lévy–Khintchine. Bull. Sci. Math. 88 (1964) 3–30.

[14] Courrège, P.: Sur la forme intégro différentielle des opérateurs de C∞

k dans C satisfaisant
au principe du maximum. In: Séminaire Brelot–Choquet–Deny. Théorie du potentiel 10
(1965/66) exposé 2, pp. 1–38.

[15] de Finetti, B.: Sulle funzioni ad incremento aleatorio. Rend. Accad. Lincei Ser. VI 10 (1929)

163–168.

[16] Dieudonné, J.: Foundations of Modern Analysis. Academic Press, New York (NY) 1969.

[17] Ethier, S.N., Kurtz, T.G.: Markov Processes. Characterization and Convergence. John Wiley

& Sons, New York (NY) 1986.

[18] Gikhman, I.I., Skorokhod, A.V.: Introduction to the Theory of Random Processes. W.B.

Saunders, Philadelphia (PA) 1969 (reprinted by Dover, Mineola 1996).

[19] Grimvall, A.: A theorem on convergence to a Lévy process. Math. Scand. 30 (1972) 339–

349.

[20] Herz, C.S.: Théorie élémentaire des distributions de Beurling. Publ. Math. Orsay no. 5, 2ème

année 1962/63, Paris 1964.

[21] Hoh, W.: Pseudo differential operators with negative deﬁnite symbols of variable order. Rev.

Mat. Iberoamericana 16 (2000) 219–241.

[22] Ikeda, N., Watanabe S.: Stochastic Differential Equations and Diffusion Processes. North-

Holland Publishing Co./Kodansha, Amsterdam and Tokyo 1989 (2nd ed).

[23] Itô, K.: On stochastic processes. I. (Inﬁnitely divisible laws of probability). Japanese J. Math.

XVIII (1942) 261–302.

[24] Itô, K.: Lectures on Stochastic Processes. Tata Institute of Fundamental Research, Bombay

1961 (reprinted by Springer, Berlin 1984).
http://www.math.tifr.res.in/~publ/ln/tifr24.pdf

[25] Itô, K.: Semigroups in probability theory. In: Functional Analysis and Related Topics, Pro-
ceedings in Memory of K. Yosida (Kyoto 1991). Springer, Lecture Notes in Mathemtics
1540, Berlin 1993, 69–83.

[26] Jacob, N.: Pseudo Differential Operators and Markov Processes (3 volumes). Imperial Col-

lege Press, London 2001–2005.

[27] Jacod, J., Shiryaev, A.N.: Limit Theorems for Stochastic Processes. Springer, Berlin 1987

(2nd ed Springer, Berlin 2003).

106

R. L. Schilling: An Introduction to Lévy and Feller Processes

[28] Khintchine, A.Ya.: A new derivation of a formula by P. Lévy. Bull. Moscow State Univ. 1
(1937) 1–5 (Russian; an English translation is contained in Appendix 2.1, pp. 44–49 of [44]).

[29] Khintchine, A.Ya.: Zur Theorie der unbeschränkt teilbaren Verteilungsgesetze. Mat. Sbornik
(Réc. Math. Moscou, N.S.) 2 (1937) 79–119 (German; an English translation is contained in
Appendix 3.3, pp. 79–125 of [44]).

[30] Kühn, F.: Existence and estimates of moments for Lévy-type processes. Preprint TU, Dres-

den 2015 (arXiv: 1507.07907).

[31] Knopova, V., Schilling, R.L.: A note on the existence of transition probability densities for

Lévy processes. Forum Math. 25 (2013) 125–149.

[32] Kolmogorov, A.N.: Sulla forma generale di un processo stocastico omogeneo (Un problema
die Bruno de Finetti). Rend. Accad. Lincei Ser. VI 15 (1932) 805–808 and 866–869 (an En-
glish translation is contained in: Shiryayev, A.N. (ed.): Selected Works of A.N. Kolmogorov.
Kluwer, Dordrecht 1992, vol. 2, pp.121–127).

[33] Kunita, H.: Stochastic differential equations based on Lévy processes and stochastic ﬂows
of diffeomorphisms. In: Rao, M.M. (ed.): Real and Stochastic Analysis. Birkhäuser, Boston
(MA) 2004, pp. 305–373.

[34] Kunita, H., Watanabe, S.: On square integrable martingales. Nagoya Math. J. 30 (1967)

209–245.

[35] Kyprianou, A.: Introductory Lectures on Fluctuations and Lévy Processes with Applications.

Springer, Berlin 2006.

[36] Lévy, P.: Sur les intégrales dont les élements sont des variables aléatoires indépendantes.

Ann. Sc. Norm. Sup. Pisa 3 (1934) 337–366.

[37] Lévy, P.: Théorie de l’addition des variables aléatoires. Gauthier–Villars, Paris 1937.

[38] Mainardi, F., Rogosin, S.V.: The origin of inﬁnitely divisible distributions: from de Finetti’s
problem to Lévy–Khintchine formula. Math. Methods Economics Finance 1 (2006) 37–55.

[39] Malliavin, P.: Integration and Probability. Springer, New York (NY) 1995.

[40] Pazy, A.: Semigroups of Linear Operators and Applications to Partial Differential Equations.

Springer, New York (NY) 1983.

[41] Prokhorov, Yu.V.: Convergence of random processes and limit theorems in probability the-

ory. Theor. Probab. Appl. 1 (1956) 157–214.

[42] Protter, P.E.: Stochastic Integration and Differential Equations. Springer, Berlin 2004 (2nd

ed).

Bibliography

107

[43] Revuz, D., Yor, M.: Continuous Martingales and Brownian Motion. Springer, Berlin 2005

(3rd printing of the 3rd ed).

[44] Rogosin, S.V., Mainardi, F.: The Legacy of A.Ya. Khintchine’s Work in Probability Theory.

Cambridge Scientiﬁc Publishers, Cambridge 2010.

[45] Rosi´nski, J.: On series representations of inﬁnitely divisible random vectors. Ann. Probab.

18 (1990) 405–430.

[46] Rosi´nski, J.: Series representations of Lévy processes from the perspective of point pro-

cesses. In: Barndorff-Nielsen et al. [3] (2001) 401–415.

[47] Samorodnitsky, G., Taqqu, M.S.: Stable Non-Gaussian Random Processes. Chapman &

Hall, New York (NY) 1994.

[48] Sandri´c, N.: On recurrence and transience of two-dimensional Lévy and Lévy-type pro-

cesses. To appear in Stoch. Proc. Appl. (2015).

[49] Sandri´c, N.: Long-time behavior for a class of Feller processes. To appear in Trans. Am.

Math. Soc. (2015).

[50] Sato, K.: Lévy Processes and Inﬁnitely Divisible Distributions. Cambridge University Press,

Cambridge 1999 (2nd ed 2013).

[51] Schilling, R.L.: Conservativeness and extensions of Feller semigroups. Positivity 2 (1998)

239–256.

[52] Schilling, R.L.: Growth and Hölder conditions for the sample paths of a Feller process.

Probab. Theor. Relat. Fields 112 (1998) 565–611.

[53] Schilling, R.L.: Measures, Integrals and Martingales. Cambridge University Press, Cam-

bridge 2011 (3rd printing).

[54] Schilling, R.L.: Maß und Integral. De Gruyter, Berlin 2015.

[55] Schilling, R.L., Partzsch, L.: Brownian Motion. An Introduction to Stochastic Processes. De

Gruyter, Berlin 2014 (2nd ed).

[56] Schilling, R.L., Schnurr, A.: The symbol associated with the solution of a stochastic differ-

ential equation. El. J. Probab. 15 (2010) 1369–1393.

[57] Schnurr, A.: The Symbol of a Markov Semimartingale. PhD Thesis, Technische Universität

Dresden 2009. Shaker-Verlag, Aachen 2009.

[58] Schnurr, A.: On the semimartingale nature of Feller processes with killing. Stoch. Proc. Appl.

122 (2012) 2758–2780.

108

R. L. Schilling: An Introduction to Lévy and Feller Processes

[59] Stroock, D.W., Varadhan, S.R.S.: Multidimensional Stochastic Processes. Springer, Berlin

1997 (2nd corrected printing).

[60] von Waldenfels, W.: Eine Klasse stationärer Markowprozesse. Kernforschungsanlage Jülich,

Institut für Plasmaphysik, Jülich 1961.

[61] von Waldenfels, W.: Fast positive Operatoren. Z. Wahrscheinlichkeitstheorie verw. Geb. 4

(1965) 159–174.

