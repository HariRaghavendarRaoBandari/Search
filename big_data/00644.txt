A Novel Interleaving Scheme for Polar Codes

Ya Meng∗, Liping Li∗, Yanjun Hu∗

∗ Key Laboratory of Intelligent Computing and Signal Processing of the Ministry

of Education of China Anhui University, China,

Email: mengya@ahu.edu.cn, liping li@ahu.edu.cn, yanjunhu@ahu.edu.cn

6
1
0
2

 
r
a

M
 
0
2

 
 
]
T
I
.
s
c
[
 
 

2
v
4
4
6
0
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—It’s known that the bit errors of polar codes with
successive cancellation (SC) decoding are coupled. We call the
coupled information bits the correlated bits. In this paper,
concatenation schemes are studied for polar codes (as inner
codes) and LDPC codes (as outer codes). In a conventional
concatenation scheme, to achieve a better BER performance, one
can divide all Nl bits in a LDPC block into Nl polar blocks
to completely de-correlate the possible coupled errors. In this
paper, we propose a novel interleaving scheme between a LDPC
code and a polar code which breaks the correlation of the errors
among the correlated bits. This interleaving scheme still keeps the
simple SC decoding of polar codes while achieves a comparable
BER performance at a much smaller delay compared with a
Nl-block delay scheme.

I. INTRODUCTION

Polar codes are proposed by Arıkan in [1] which prov-
ably achieve the capacity of symmetric binary-input discrete
memoryless channels (B-DMCs) with a low encoding and
decoding complexity. The encoding and decoding process
(with successive cancellation, SC) can be implemented with
a complexity of O(N log N ). The idea of polar codes is to
transmit information bits on those noiseless channels while
ﬁxing the information bits on those completely noisy channels.
The ﬁxed bits are made known to both the transmitter and
receiver.

To improve the polar code performance in the ﬁnite domain,
various decoding processes [2]–[5] and concatenation schemes
[6]–[8] were proposed. The decoding processes in these works
have higher complexity than the original SC decoding of
[1]. Systematic polar codes are later proposed in [9] which
have almost the same decoding complexity. In non-systematic
encoding, the codeword x is obtained by x = uG, where G
is the generator matrix. The basic idea of systematic polar
codes is to use some part of the codeword x to transmit
information bits instead of directly using the source bits u to
transmit them. In [9], it’s shown that systematic polar codes
achieve better BER performance than non-systematic polar
codes. But, theoretically, this better BER performance is not
expected from the indirect decoding process: ﬁrst decoding ˆu
(ˆu is the estimation of u from the normal SC decoding) then
re-encoding ˆx as ˆuG. One would expect that any errors in ˆu
would be ampliﬁed in this re-encoding process.

In [10], the reason that systematic polar codes have better
BER performance than non-systematic polar codes has been
studied. From [10], we already see that the number of errors of
polar codes with the SC decoding is not necessarily ampliﬁed
in the indirect decoding process of systematic polar codes.

It all depends on how the errors are distributed in the SC
decoding process. From the re-encoding ˆx = ˆuG and that
the number of errors in ˆx is smaller than that of ˆu, we can
conclude that the coupling of the errors in ˆu are controlled by
the columns of G. We provide a proposition of this coupling
pattern in this paper. Based on this coupling pattern, a novel
interleaving scheme is introduced to improve the performance
of polar codes with ﬁnite block lengths while still maintaining
the low complexity of the SC decoding. We use a LDPC code
as the outer code and a polar code as the inner code. Note that
the concatenation of polar codes with LDPC codes is studied
in [6] and [7] where no interleaving is used and BP (belief-
propagation) decoding is applied for polar codes.

The advantage of the proposed interleaving scheme between
LDPC codes and polar codes is that the coupled errors between
the correlated information bits are divided into different LDPC
blocks. Therefore, to achieve the same BER performance as
a conventional concatenation scheme, either a simpler LDPC
code or a larger code rate can be applied. The proposed
interleaving scheme achieves a comparable BER performance
as a blind interleaving scheme where all the K information
bits of polar codes are de-coupled into K LDPC blocks. We
provide simulation results to verify our interleaving scheme.
1 to
represent a row vector with elements (v1, v2, ..., vN ). We also
use v to represent the same vector for notational convenience.
Suppose a vector vN
i is a subvector (vi, ..., vj )
with 1 ≤ i, j ≤ N . If there is a set A ∈ {1, 2, ..., N }, then
vA denotes a subvector with elements in {vi, i ∈ A}.

Following the notations in [1], in this paper, we use vN

1 , the vector vj

The rest of the paper is organized as follows. Section II
introduces the fundamentals of non-systematic and systematic
polar codes. Also introduced in this section is the coupling
pattern of polar codes with the SC decoding. Section III
proposes the new interleaving scheme with a detailed algo-
rithm. Section IV presents the simulation results. Finally the
conclusion remarks are provided at the end.

II. SYSTEMATIC POLAR CODES

In the ﬁrst part of this section, the relevant theories on
non-systematic polar codes and systematic polar codes are
presented. In the second part of this section, the correlation
among errors is introduced, which is the basis of the proposed
interleaving scheme.

(cid:108)

u
1

u=
1

(cid:108)

u

2

u=
5

(cid:108)

u
3

u=
3

(cid:108)

u

4

u=

7

(cid:108)

u
5

u=

2

(cid:108)

u

6

(cid:108)

u

7

u=

6

u=

4

(cid:108)

u
8

u=
8

x
1

x
2

x
3

x
4

x
5

x
6

x
7

x
8

Fig. 1: An encoding circuit of the non-systematic polar codes
with N = 8. Signals ﬂow from the left to the right. Each edge
carries a signal of 0 or 1.

A. Preliminaries of Non-Systematic Polar Codes

The generator matrix for polar codes is GN = BF ⊗n where
B is a bit-reversal matrix, F = (cid:0) 1 0
1 1 (cid:1), n = log2 N , and F ⊗n is
the nth Kronecker power of the matrix F over the binary ﬁeld
F2. In this paper, we consider an encoding matrix G = F ⊗n
without the permutation matrix B. This matrix is the basis of
analyzing the interleaving scheme of this paper.

Mathematically, the encoding is a process to obtain the
codeword x through x = uG for a given source vector u.
The source vector u consists of the information bits and the
frozen bits, denoted by uA and u ¯A, respectively. Here the set
A includes the indices for the information bits and ¯A is the
complementary set. The set A can be constructed by selecting
indices of the bit channels with the smallest Bhattacharyya
parameters. In [1],
there are detailed deﬁnition of the bit
channels and the corresponding Bhattacharyya parameters.
Both sets A and ¯A are in {1, 2, ..., N } for polar codes with a
block length N = 2n.

An encoding circuit is shown in Fig. 1. If the nodes in
Fig. 1 are viewed as memory elements, the encoding process
is to calculate the corresponding values to ﬁll all the memory
elements from the left to the right.

B. Construction of Systematic Polar Codes

For systematic polar codes, we also focus on a generator
matrix without the permutation matrix B, namely G = F ⊗n.
The source bits u can be split as u = (uA, u ¯A). The ﬁrst
part uA consists of user data that are free to change in each
round of transmission, while the second part u ¯A consists of
data that are frozen at the beginning of each session and made
known to the decoder. The codeword can then be expressed
as

x = uAGA + u ¯AG ¯A

(1)

where GA is the sub-matrix of G with rows speciﬁed by the
set A. The systematic polar code is constructed by specifying

a set of indices of the codeword x as the indices to convey the
information bits. Denote this set as B and the complementary
set as ¯B. The codeword x is thus split as (xB, x ¯B). With some
manipulations, we have

xB = uAGAB + u ¯AG ¯AB
x ¯B = uAGA ¯B + u ¯AG ¯A ¯B

(2)

The matrix GAB is a sub-matrix of the generator matrix
with elements {Gi,j}i∈A,j∈B. Given a non-systematic encoder
(A, u ¯A), there is a systematic encoder (B, u ¯A) which performs
the mapping xB 7→ x = (xB, x ¯B). To realize this systematic
mapping, x ¯B needs to be computed for any given information
bits xB. To this end, we see from (2) that x ¯B can be computed
if uA is known. The vector uA can be obtained as the
following

uA = (xB − u ¯AG ¯AB)(GAB)−1

(3)

From (3), it’s seen that xB 7→ uA is one-to-one if xB has
the same elements as uA and if GAB is invertible. In [9], it’s
shown that B = A satisﬁes all these conditions in order to
establish the one-to-one mapping xB 7→ uA. In the rest of
the paper, the systematic encoding of polar codes adopts this
selection of B to be B = A. Therefore we can rewrite (2) as

xA = uAGAA + u ¯AG ¯AA
x ¯A = uAGA ¯A + u ¯AG ¯A ¯A

(4)

C. Correlated Bits

In [9][10],

it’s shown that

the re-encoding process of
ˆx = ˆuG after decoding ˆu does not amplify the number of
errors in ˆu. Instead, there are less errors in ˆx than in ˆu. This
clearly shows that the coupled errors in ˆu are de-coupled (or
cancelled) in the re-encoding process. In this section, we ﬁrst
restate a corollary from [10] and then provide a proposition
to show the coupling pattern of the errors in ˆu. This coupling
pattern is used in Section III to design the interleaving scheme.

Corollary 1: The matrix G ¯AA = 0.

The proof of this corollary can be found in [10]. The following
proposition shows the pattern of the coupling of the errors in
ˆu from the SC decoding process.

Proposition 1: Let the indices of the non-zero entries of
column i ∈ A of GN be Ai. Then, the errors of ˆuAi are
dependent.

The proof of Proposition 1 is omitted in the current paper
due to the space limit. From Proposition 1, an error pattern
the
among the errors in ˆu is shown. We call bits ˆuAi
correlated estimated bits. This says that statistically, the errors
of bits ˆuAi are coupled. To show this coupling, we give an
example of N = 16 and R = 0.5 in a BEC channel with
an erasure probability 0.2. The indices selected in this case
for information bits are {8, 10, 11, 12, 13, 14, 15, 16} (indexed
from 1 to 16). The coupling effect (similar to the correlation
coefﬁcient) of bits indicated by non-zero positions of column
10, 11, and 13 is recorded in simulations and is shown in Table
I. From Table I, the coupling of the errors in column 10, 11,
and 13 is clearly shown.

TABLE I: Coupling effect for N = 16, R = 0.5 in a BEC
channel with an erasure probability of 0.2

Original Input Bits

columns of G

coupling coefﬁcient

10
11
13

76%
74%
74%

To the authors’ knowledge, there is no attempt yet to utilize
this coupling pattern to improve the performance of polar
codes. In the next section of this paper, we propose a novel
interleaving scheme to break the coupling of errors to improve
the BER performance of polar codes while still maintaining
the low complexity of the SC decoding.

III. THE PROPOSED INTERLEAVING SCHEME

In this section we consider an interleaving scheme between
a LDPC code (the outer code) and a polar code (the inner
code). From Proposition 1, we know the exact correlated
information bits of the polar codes. The task of the interleaving
scheme is thus to make sure that the correlated bits of the inner
polar codes come from different LDPC blocks. In this way, the
de-interleaved LDPC blocks have independent errors. We call
this interleaving scheme the correlation-breaking interleaving
(CBI). Before explaining our interleaving scheme, a blind
interleaving (BI) is introduced which breaks all bits in one
LDPC block into different polar code blocks. The scheme
guarantees that errors in each LDPC block are independent.
This BI scheme serves as a benchmark for our CBI scheme.

A. The Blind Interleaving Scheme

In this section, the scheme of scattering all bits in a LDPC
block into different polar code blocks is introduced. Suppose
one LDPC code block has Kl information bits and the block
length is Nl. These Nl bits are divided into Nl polar code
blocks, which guarantees that the errors in each LDPC block
are independent as they come from different polar code blocks.
We give an example in Fig. 2 where Kl = 64 and Nl = 155.
In Fig. 2, bit i of all the Kl = 64 LDPC code blocks form the
input vector to the ith polar code encoder. Polar code in this
example has N = 256 and a rate R = 1/4. In the receiver
side, after the polar codes decoding, a de-interleaving is done
to collect the Nl = 155 outputs for one LDPC block from
Nl = 155 polar code blocks. For one LDPC block, the delay
is thus Nl = 155 polar code blocks.

B. The Correlation-Breaking Interleaving (CBI) Scheme

The BI scheme in Section III-A has a long delay. From
Section II-C, we know that it is not necessary to scatter all bits
in a LDPC block into different polar blocks since not all bits
in a polar block are correlated. Only those bits in {Ai}K
i=1 are
correlated. The interleaving scheme in this section is to make
the bits {Ai}K
i=1 of one polar block composed of different
LDPC blocks. Or in other words, the interleaving scheme is
to scatter the information bits {Ai}K
i=1 of each polar block
into different LDPC blocks.

Grouping

LDPC

encoding

Interleaving

Polar

encoding

group 1
64 bits

group 2
64 bits

...

group 64
64 bits

1

2

...

155

1

2

...

155

...

1

2

...

155

1

1

...

1

2

2

...

2

...

155

155

...

155

Polar group 1

Polar group 2

...

Polar group 155

Fig. 2: An blind interleaving (BI) scheme. The block length
of the LDPC code is Nl = 155, and the code rate is 64/155.
The block length of the polar code is N = 256, and the code
rate is R = 1/4.

The difﬁculty in designing a CBI scheme is that the sets
i=1 are different for different block lengths and data rates.
{Ai}K
They are also different for different underlying channels for
which polar codes are designed. A CBI scheme is dependent
on at least three parameters: the block length N , the data rate
R, and the underlying channel W . Let’s denote a CBI scheme
as CBI(N ,R,W ) to show this dependence. A CBI(N ,R,W )
optimized for one set of (N ,R,W ) is not necessarily optimized
for another set (N ′,R′,W ′). It may not even work for the set
(N ′,R′,W ′) if N ′R′ 6= N R. In the following, we provide a
CBI scheme which works for any sets of (N ,R,W ), but not
necessarily optimal for one speciﬁc set of (N ,R,W ).

As Ai are the indices of the non-zero entries of column
i ∈ A, we ﬁrst extract the K = |A| columns of G and denote
it as the submatrix G(:, A). Divide the submatrix G(:, A) as
G(:, A) = [G ¯AA GAA]. Since the submatrix G ¯AA = 0, we
only need to analyze the submatrix GAA. If a CBI needs to
look at each individual set Ai, then a general CBI is beyond
reach. However, we can simplify this problem by dividing the
information bits only into two groups: the correlated bits Ac
and the uncorrelated bits ¯Ac. The following proposition can
be used to ﬁnd the sets Ac and ¯Ac.

Proposition 2: For the submatrix GAA, the row indices
(relative to the submatrix GAA) with Hamming weight greater
than one is denoted as the set ˜Ac. The corresponding set of
˜Ac with respect to the matrix G is the set Ac.

The proof of Proposition 2 is omitted in this paper due to
the space limit. We give an example of how to use Proposition
2 to ﬁnd the set Ac and ¯Ac. Let the block length be N = 16,
the code rate R = 0.5, and the underlying channel is the
BEC channel with an erasure probability 0.2. The set A is the
same as the example in Section II-C. With Proposition 2, we
can easily ﬁnd that ˜Ac = {4, 6, 7, 8} for the submatrix GAA.
Relative to the matrix G16, this set is Ac = {12, 14, 15, 16}.
The uncorrelated set is thus ¯Ac = {8, 10, 11, 13}.

With the sets Ac and ¯Ac obtained for any (N ,R,W ), we

Grouping

LDPC

encoding

Interleaving

Polar

encoding

Original Input Bits

group 1

group 2

group 3

group 4

Ac

Ac

Ac

Ac

...

...

Ac

Ac

Polar group 

Fig. 3: A general correlation-breaking interleaving scheme.
Here the set Ac consists of the indices of the correlated bits
and the set ¯Ac is the complementary set of Ac.

can devise a CBI scheme. Let Kc = |Ac| and Kuc = | ¯Ac|.
Fig. 3 is a general CBI scheme. And Algorithm 1 shows a
detailed implementation. Algorithm 1 contains two parts. Part
one (from line 5 to 16) is collecting the encoded LDPC bits
as the uncorrelated information bits of polar groups. Part two
(from line 17 to the end) collects the encoded LDPC bits for
the correlated information bits of polar groups. The principle
is of course that: the correlated information bits of polar codes
come from different LDPC blocks while the uncorrelated
information bits can be from the same LDPC block. Note that
the Kuc uncorrelated information bits of one polar block can
be directly taken from a continuous chunk of a LDPC block.
However, taking the Kc correlated information bits for each
polar encoding block needs a ﬁne design. In Algorithm 1, two
new sets Acc (line 19) and Acp (line 22) are deﬁned which
control the collecting of the correlated information bits for
each polar encoding block.

The CBI scheme in Algorithm 1 runs every Kn = Kc + 1
LDPC blocks. For each of these LDPC blocks, nd ∗ Kn + mo
polar blocks are needed where nd, Kn and mo are deﬁned
at the top of Algorithm 1. The average delay looking from
the LDPC side (in terms of the polar blocks) is: ⌈(nd ∗ Kn +
mo)/Kn⌉ ≤ nd + 1.

IV. SIMULATION RESULT

In this section, simulation results are provided to verify the
performance of the CBI scheme shown in Algorithm 1. The
example we take is the same as the BI scheme in Fig. 2. All
the LDPC codes used in this section is the (155,64,20) Tanner
code [11]. Therefore Nl = 155 and Kl = 64. The polar code
has the N = 256 and R = 1/4. The underlying channel is the
AWGN channel. The polar code construction is based on [12]
which produces the set A. Then the submatrix GAA is formed
from the generator matrix G256. Based on the submatrix GAA,
the correlated set Ac (Kc = 36) and the un-correlated set ¯Ac
(Kuc = 28) is obtained. Algorithm 1 is implemented with the
following details.

13
14

18
19
20
21

22
23
24

29
30
31

INPUT : Nl, K, Kc, Kuc, Ac,
OUTPUT:
the input bits UA of ⌊Nl/K⌋ ∗ (Kc + 1) + Nl%K
groups of polar codes

1 nd=⌊Nl/K⌋ ;
2 nu=⌈Nl/K⌉ ;
3 mo=Nl%K (// take Nl modulo K);
4 Kn=Kc + 1;
5 for j ← 1 to nd do // collect bits from

LDPC blocks as input bits ¯Ac for the
ith polar encoding

6
7
8

for i ← (j − 1) ∗ Kn + 1 to (j − 1) ∗ Kn + Kn do

ls = ((i − 1)%Kn) ∗ Nl;
UA((i−1)∗K + ¯Ac)=UL(ls+i−j +Kuc∗(j −
1)+1 : ls+i−j +Kuc ∗(j −1)+1+Kuc −1);

end

9
10 end
11 if mo! = 0 && j == nu then
12

for i ← (nu − 1) ∗ Kn + 1 to
(nu − 1) ∗ Kn + mo do

ls = ((i − 1)%Kn) ∗ Nl;
UA((i − 1) ∗ K + ¯Ac)=
UL(ls + i − nu + Kuc ∗ (nu − 1) + 1 : ls + i −
nu + Kuc ∗ (nu − 1) + 1 + (Kuc − i%Kn − 1));

end

15
16 end
17 for j ← 1 to nd do // collect bits from

LDPC blocks as input bits Ac for the
ith polar encoding

for i ← (j − 1) ∗ Kn + 1 to (j − 1) ∗ Kn + Kn do

Acc={1, 2, ..., i − Kn ∗ (j − 1) − 1};
lc = (Acc − 1) ∗ Nl;
UA((i − 1) ∗ K + Ac(Acc))=UL(lc + i − j +
Kuc ∗ j);
Acp={(i − Kn ∗ (j − 1) + 1), ..., Kn};
lm = (Acp − 1) ∗ Nl;
UA((i − 1) ∗ K + Ac(Acp − 1))=UL(lm +
i − (j − 1) + Kuc ∗ (j − 1));

end

25
26 end
27 if mo! = 0 && j == nu then
28

for i ← (nu − 1) ∗ Kn + 1 to
(nu − 1) ∗ Kn + mo do

Acp={(i − Kn ∗ (nu − 1) + 1), ..., Kn};
lm = (Acp − 1) ∗ Nl;
UA((i − 1) ∗ K + Ac(Acp − 1))=UL(lm +
i − (nu − 1) + Kuc ∗ (nu − 1));

end

32
33 end
Algorithm 1: The algorithm of a general correlation-
breaking interleaving scheme. Transmitting Kn LDPC
blocks needs nd ∗ Kn + mo groups of polar codes
where Kn, nd, and mo are deﬁned at the top of this
algorithm.

• Consider the ith polar encoding block for 1 ≤ i ≤ Kc +
1 = 37. The information bits ¯Ac of the ith polar block is
composed of bit i to (i+28−1) of the ((i−1)%37+1)th
LDPC code block. The information bits Ac for the ith
polar block are collected through two sets Acc and Acp
with Acc = {i − 1, i − 2, ...1} and Acp = {37, 36, 35...i +
1}. These two sets Acc and Acp are the indices of LDPC
blocks. The bits of Ac of the ith polar block are from
two parts: the (i − 1 + 28)th bit of LDPC groups Acc and
the ith bit of LDPC groups Acp.

• Consider the ith polar group for 38 ≤ i ≤ 74. The
information bits ¯Ac for the ith polar code consists of
bits (i − 2 + 28 + 1) to ((i − 2 + 28 + 1) + 28 − 1)
of the ((i − 1)%37 + 1)th LDPC block. In this case
Acc = {(i − 37) − 1, (i − 37) − 2, ...1} and Acp =
{37, 36, 35, ...(i − 37) + 1}. Therefore the bits Ac of the
ith polar code are from bit (i − 2 + 28 ∗ 2) of LDPC
groups Acc and bit (i − 1 + 28) of LDPC groups Acp.
• Now consider the ith polar group for 75 ≤ i ≤ 101. The
bits ¯Ac of the ith polar code is made up of bits from
(i−3+28∗2+1) to ((i−3+28∗2+1)+(28−i%37)−1)
of the ((i − 1)%37 + 1)th LDPC block. In this case,
there is only Acp = {37, 36, 35, ...(i − 37 ∗ 2) + 1}. The
information bits Ac for the ith polar code are from bit
(i − 2 + 28 ∗ 2) of LDPC groups Acp.

In this example, the average delay in terms of the po-
lar blocks is nd + 1 = 3, which is much smaller than
Nl = 155. The BER performance of the CBI scheme is
shown in Fig. 4 where the solid line with diamonds is the
performance of the CBI scheme. The legend for this scheme is:
LDPC+CBI+Polar(SC). The solid line with stars is the the per-
formance of polar code directly concatenated with the LDPC
code (no interleaving being performed), with a legend of
LDPC+Polar(SC). Note that compared with the BI scheme (the
solid line with triangles and the legend LDPC+BI+Polar(SC)),
the CBI scheme achieves almost the same performance while
having a delay Nl/(nd + 1) = 51 times smaller. Both the CBI
and the BI scheme has a better BER performance than the
direct concatenation.

To compare with a direct concatenation of polar codes
(BP decoding) with LDPC codes,
the same simulation is
carried out (shown in Fig. 4 by the dashed circled line).
The legend for this scheme is LDPC+Polar(BP). At
low
SNR regions,
the LDPC+CBI+Polar(SC) scheme outper-
forms the LDPC+Polar(BP) scheme. The computational com-
plexity of the LDPC+CBI+Polar(SC) system is lower than
LDPC+Polar(BP) systems at a relatively small cost of the
delay.

V. CONCLUSION

In this paper, we proposed a novel interleaving scheme,
the correlation-break interleaving (CBI), which can improve
the BER performance of polar codes while still maintaining
the low complexity of the SC decoding of polar codes. The

CBI scheme has a small average delay compared with a
blind interleaving scheme. Simulation results are provided

100

10-1

10-2

10-3

10-4

R
E
B

LDPC+CBI+Polar(SC)
LDPC+BI+Polar(SC)
LDPC+Polar(SC)
LDPC+Polar(BP)

10-5

-4

-3.5

-3

-2.5

-2
-1.5
SNR(dB)

-1

-0.5

0

0.5

Fig. 4: The BER performance of a polar code concatenated
with a LDPC code in AWGN channels. The polar code has a
block length N = 256 and the data rate R = 1/4. The LDPC
code is the (155,64,20) Tanner code.

which veriﬁed that the concatenation of polar codes with SC
decoding and the CBI scheme achieves almost the same BER
performance as the concatenation scheme of polar codes with
the BP decoding.

REFERENCES

[1] E. Arikan, “Channel Polarization: A Method for Constructing Capacity-
Achieving Codes for Symmetric Binary-Input Memoryless Channels,”
IEEE Transactions on Information Theory, vol. 55, no. 7, pp. 3051–
3073, 2009.

[2] ——, “A Performance Comparison of Polar Codes and Reed-Muller
codes,” IEEE Communications Letters, vol. 12, no. 6, pp. 447–449, 2008.
[3] N. Hussami, S. Korada, and R. Urbanke, “Performance of Polar Codes
for Channel and Source Coding,” in IEEE International Symposium on
Information Theory (ISIT), June 2009, pp. 1488–1492.

[4] I. Tal and A. Vardy, “List decoding of polar codes,” Information Theory,

IEEE Transactions on, vol. 61, no. 5, pp. 2213–2226, May 2015.

[5] K. Chen, K. Niu, and J. Lin, “Improved Successive Cancellation Decod-
ing of Polar Codes,” IEEE Transactions on Communications, vol. 61,
no. 8, pp. 3100–3107, August 2013.

[6] A. Eslami and H. Pishro-Nik, “A Practical Approach to Polar Codes,” in
IEEE International Symposium on Information Theory, 2011, pp. 16–20.
[7] J. Guo, M. Qin, A. G. i Fabregas, and P. H. Siegel, “Enhanced Belief
Propagation Decoding of Polar Codes through Concatenation,” in 2014
IEEE International Symposium on Information Theory Proceedings
(ISIT), 2014, pp. 2987 – 2991.

[8] U. U. Fayyaz and J. R. Barry, “Polar Codes for Partial Response
Channels,” in 2013 IEEE International Conference on Communications
(ICC), 2013, pp. 4337 – 4341.

[9] E. Arikan, “Systematic Polar Coding,” IEEE Communications Letters,

vol. 15, no. 8, pp. 860–862, August 2011.

[10] L. Li, W. Zhang, and Y. Hu, “On the Error Performance of Systematic

Polar Codes,” http://arxiv.org/abs/1504.04133, 2015.

[11] R. M. Tanner, D. Sridhara, A. Sridharan, T. E. Fuja, and D. J. Costello,
“Ldpc block and convolutional codes based on circulant matrices,”
Information Theory, IEEE Transactions on, vol. 50, no. 12, pp. 2966–
2984, December 2004.

[12] I. Tal and A. Vardy, “How to construct polar codes,” Information Theory,

IEEE Transactions on, vol. 59, no. 10, pp. 6562–6582, Oct 2013.

