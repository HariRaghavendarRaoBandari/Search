6
1
0
2

 
r
a

 

M
8
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
0
0
9
5
0

.

3
0
6
1
:
v
i
X
r
a

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

RELATED TO IMPORTANCE SAMPLING OF IT ˆO DIFFUSIONS

HAN CHENG LIE† ‡

Abstract. We consider the problem of rare event importance sampling, where the random
variable of interest is a path functional of an Itˆo diﬀusion computed up to the ﬁrst exit from a d-
dimensional bounded domain. Dupuis and Wang (Ann. Appl. Probab., 15 (2005), pp. 1-38) studied
the importance sampling problem by formulating it as a stochastic optimal control problem, where
the value function is related to the conditional cumulant generating function of the random variable.
In this paper, we show that the suﬃcient conditions for the value function to be twice-diﬀerentiable
and α-uniformly H¨older continuous on the closure of the domain are also suﬃcient conditions for
positive deﬁniteness of the second variation of the control functional on the space of diﬀerentiable,
α-uniformly H¨older continuous Rd-valued feedback controls. We derive an expression for the second
variation using Kazamaki’s suﬃcient condition for Lq-boundedness of exponential martingales, and
using Fredholm theory to prove the ﬁniteness of the moment generating function of the ﬁrst exit time
over any bounded interval containing the origin. The strict convexity result suggests that one may be
able to solve the corresponding Hamilton-Jacobi-Bellman boundary value problem in a dimension-
robust way, by combining convex optimisation and Monte Carlo methods. We apply the result to
analyse a gradient descent algorithm proposed by Hartmann and Sch¨utte (J. Stat. Mech. Theor.
Exp. (2012), P11004) for eﬃcient rare event simulation.

Key words. Optimal stochastic control, Hamilton-Jacobi-Bellman equation, Feynman-Kac
formula, elliptic boundary value problem, rare events, ﬁrst exit time, importance sampling, convex
optimisation, Monte Carlo methods

AMS subject classiﬁcations. 49M30, 60H30, 65C60, 82C80, 93E20

1. Introduction. The estimation of statistical properties of rare events is a
common problem in computational physics. For example, the estimation of ther-
modynamic free energy diﬀerences between two equilibrium states is integral to the
study of complex macromolecules in computational biophysics and drug design. Ac-
cordingly, many methods for rare event estimation have been proposed, especially in
the case of free energy computations. Some methods, e.g. the adaptive biasing force
method [5] or hyperdynamics [26,27], involve driving the dynamical system of interest
by applying an external force; in certain cases, this is achieved by changing the (po-
tential) energy landscape on which the system lives, e.g. metadynamics [19]. Other
methods, such as the Passerone-Parrinello method [22], study a variational problem
and apply a least action principle, while others focus on improving the simulation of
rare trajectories that dominate the statistical property of interest, e.g. the transition
path sampling method [6] or the forward ﬂux sampling method [1]. A mathematical
treatment of free energy computations is given in [20].

The motivation of the present article is the analysis of a gradient descent method
for solving a stochastic optimal control problem, proposed by Hartmann and Sch¨utte
[13]. This method shares some characteristics with the methods mentioned above: the
method improves the collection of rare event statistics by tilting the potential in order
to bias the path measure towards trajectories that dominate an exponential average
(see, e.g. [15]), each modiﬁcation to the potential corresponds to the application of a
feedback control force, and a variational principle enters via the duality relationship

†Institut f¨ur Mathematik, Freie Universit¨at Berlin, Berlin, Germany (hlie@math.fu-berlin.de).
‡This research was funded by a Ph.D. scholarship from the International Max-Planck Research
School for Computational Biology and Scientiﬁc Computing of the Max Planck-Institut f¨ur moleku-
lare Genetik, and by the Deutsche Forschungsgemeinschaft (DFG) through grant CRC 1114.

1

2

H. C. LIE

between free energy and relative entropy (see, e.g. [4]).

In this article, we describe suﬃcient conditions under which the control functional
of the stochastic optimal control problem is strictly convex, by rigorously deriving an
expression for the second variation of the control functional, and by showing that a
deterministic lower bound on the path functional suﬃces to guarantee strict positive
deﬁniteness of the second variation. Strict convexity implies the well-posedness of the
restriction of the stochastic optimal control problem to any ﬁnite-dimensional sub-
space of the set of admissible feedback control functions. In particular, in the limit
of inﬁnitely large sample size and inﬁnitesimally small descent step size, it follows
that the gradient descent method mentioned above converges to the unique minimiser
corresponding to the best approximation in the ﬁnite-dimensional subspace. For the
functionals and systems considered here, the strict convexity result renders the impor-
tance sampling problem amenable to other methods for solving convex optimisation
problems that may be more eﬃcient than gradient descent. This is important, because
the connections between the optimisation problems considered here and certain ellip-
tic Dirichlet boundary value problems imply that one can obtain numerical methods
for solving Hamilton-Jacobi-Bellman boundary value problems that scale well with
the spatial dimension.

Our initial reference for the idea of formulating an importance sampling problem
as a stochastic optimal control problem is [13], which examined the problem of accel-
erating simulations of rare events by using the connection between risk-sensitive, exit
time control and importance sampling [7] and the aforementioned free energy-relative
entropy duality relationship [4]; the work [10] also studied stochastic optimal control
formulations of importance sampling problems. The connections between importance
sampling, large deviations, and diﬀerential games has been studied in [9], these ideas
have been further developed for rare event simulation of multiscale diﬀusions [8, 25].
We shall not consider the large deviations aspect of rare event importance sampling.
Instead, we shall view importance sampling as an optimisation problem deﬁned over a
set of measures; this idea has been applied to Markov decision processes in [3], and in
the cross-entropy minimisation method introduced by Kullback [18]. Cross-entropy
minimisations have been applied to importance sampling for rare event estimation
by Rubenstein in the work [24], and recently by Asmussen, Kroese, and Rubenstein
in [2]. In molecular dynamics, importance sampling and cross-entropy minimisation
have been treated in [12], and Zhang et. al. [29].

The present work may diﬀer from some of those mentioned above in the follow-
ing ways. First, although we ﬁrst consider the importance sampling problem, our
primary concern is an analysis of the stochastic optimal control problem via the con-
trol functional. Second, our analysis is motivated by the desire to better understand
what numerical methods may be applied to solve such problems eﬃciently in high-
dimensional domains. Third, we employ functional analytic tools from the theory
for classical solutions to elliptic partial diﬀerential equations, as opposed to large de-
viations techniques. Furthermore, since the approach we consider does not involve
minimising the relative entropy alone, it diﬀers from the cross-entropy minimisation
methods mentioned earlier. To the best of our knowledge, no work to date has ad-
dressed the question of whether the control functional is convex over a suitably chosen
function space. An advantage of our functional-analytic approach is that the suﬃ-
cient conditions we specify are deterministic; such conditions may be easier to verify
in practical situations.

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

3

2. Overview. Let d ∈ N be the dimension of the state space (conﬁguration
space) of a stochastic dynamical system whose paths belong to the canonical ﬁltered
probability space (Θ,F , (Ft)t≥0, P ), where Θ = C([0,∞); Rd) and P is the standard
Wiener measure. Consider an Itˆo diﬀusion, i.e. a stochastic dynamical system with
continuous paths that satisﬁes the stochastic diﬀerential equation (SDE)

(2.1)

dX u

t = (u − ∇V ) (X u

t )dt + √2εdBt, X u

0 = x,

where u = (ut)t≥0 denotes a predictable control process, V ∈ C1(Rd; R) is an (po-
tential) energy function that is bounded from below and that satisﬁes the growth
conditions

(2.2a)

(2.2b)

|V (x′)| ≤ K0(1 + |x′|)
1 (1 + |x′|2)

|∇V (x′)|2 ≤ K 2

for some constants K0, K1 > 0 and for all x′ ∈ Rd, ε > 0 is a ﬁxed temperature, and B
is the standard Brownian motion with respect to P . In the context of computational
physics and molecular dynamics, the SDE (2.1) is the overdamped Langevin equation
that models the evolution of a large molecule in equilibrium with a heat bath composed
of many smaller solvent molecules, where ∇V corresponds to the force ﬁeld that arises
from bonded and non-bonded interactions of the constituent atoms, and the white
noise term models the eﬀect of the heat bath on the molecule. The control u models
the eﬀect of a controllable external force that acts on the molecule, such as a pressure
or electromagnetic ﬁeld. Given u, the corresponding solution to (2.1) is a random
variable X u : Θ → Θ. Letting P x(A) := P (θ ∈ A|θ0 = x) denote the conditioning
of P on the deterministic initial condition x ∈ Rd, we then write the law of X u, its
conditioned version, and the conditional expectation of a path functional φ ∈ L1(Θ; R)
as

(2.3)

µu := P ◦ (X u)−1, µu,x := P x ◦ (X u)−1, Eu,x[φ] =ZΘ

φ(θ)µu,x(dθ).

We shall refer to µ0,x as the ‘reference measure’, because all desired statistics shall
deﬁned with respect to µ0,x.

2.1. Importance sampling and stochastic optimal control. For a given
path functional W ∈ L1(Θ, µ0,x; R), we wish to estimate the statistics of W with re-
spect to µ0,x. In the setting of importance sampling, an optimal importance sampling
measure is any measure that yields a zero-variance estimator of the desired expected
value. In our case, the optimal importance sampling measure solves the problem
(2.4)

Thus, we seek to minimise the variance (with respect to µu,x) of φ dµ0
dµu over the set of
measures µu that are mutually equivalent to µ0 when restricted to Ft for all t > 0.
Recall that if the control process u′ satisﬁes Kazamaki’s or Novikov’s condition, then
the Radon-Nikodym derivative of µu+u′
with respect to µu is a uniformly integrable
exponential martingale with respect to µu+u′
, and the desired mutual equivalence

min(Eu,x"(cid:18)φ

dµ0

dµu − Eu,x(cid:20)φ

dµ0

dµu(cid:21)(cid:19)2#(cid:12)(cid:12)(cid:12)(cid:12) µu|Ft ≪ µ0(cid:12)(cid:12)Ft

, µ0(cid:12)(cid:12)Ft ≪ µu|Ft ∀t > 0) .

4

H. C. LIE

holds, by the Cameron-Martin-Girsanov theorem on change of measure. The Radon-
Nikodym derivative of µu with respect to µu+u′

is

= E(M−u′

)t := exp(cid:20)M−u′

t −

1
2hM−u′

it(cid:21)

dµu

dµu+u′(cid:12)(cid:12)(cid:12)(cid:12)Ft

where M u′
associated quadratic variation process,

is a continuous local martingale with respect to (Ft)t≥0 and hM u′

i is the

(2.5)

(2.6)

M u′
t

:=

1

√2εZ t

0

u′sdBs,

hM u′

it :=

1

2εZ t
0 |u′s|2ds.

By (2.5), we have the reweighting formula

Eu,x [W ] = Eu+u′,xhWE(M−u′

)i .

A useful mnemonic device for applying the reweighting formula (2.6) is that the sum of
the control superscripts on the left-hand side equals the sum of the control superscripts
on right-hand side: u = (u + u′) + (−u′).
We now give some structure to the path functional of interest. Let Ω ⊂ Rd be an
open, bounded, and connected set, where every point on the boundary ∂Ω satisﬁes
an exterior sphere condition. Deﬁne the ﬁrst exit time of X u from Ω by

(2.7)

τ (X u) := inf {t > 0 | X u

t /∈ Ω} .

Let κr ∈ C(Ω; [0,∞)) and κt ∈ C(∂Ω; R). Deﬁne the path functional W by

(2.8)

W (X u) :=Z τ (X u)

0

κr(X u

s )ds + κt(cid:16)X u

τ (X u)(cid:17) .

We shall refer to κr and κt as the ‘running cost’ and ‘terminal cost’ respectively. Let
σ > 0 be ﬁxed, and deﬁne the functions

(2.9a)

(2.9b)

ψ(σ, x) := E0,x [exp(−σW )]
F (σ, x) := −σ−1 log ψ(σ, x).

Observe that (2.9b) resembles Jarzynski’s equality [14] in statistical physics, which
relates the thermodynamic free energy diﬀerence between two equilibrium states of a
statistical-mechanical system to an exponential average of nonequilibrium work. In
the statistical physics context, σ may be understood as an inverse temperature. Two
important diﬀerences between the situation we consider and the situation considered
by Jarzynski in [14] are that, in the former, the control force applied to the system
is a function of the state and the control is applied up to a random stopping time,
whereas in the latter, the control force is applied according to a preset schedule and
over a deterministic time.

We wish to compute, for given σ and x, the value of F (σ, x). By (2.9a), it suﬃces
to compute ψ(σ, x). Provided that u satisﬁes Novikov’s condition, we may combine
(2.9a) and (2.6) in order to obtain

(2.10)

ψ(σ, x) = Eu,x(cid:2)exp(−σW )E(M−u)(cid:3) .

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

5

Thus, we may formulate the task of computing ψ(σ, x) as an importance sampling
problem of the form (2.4):
(2.11)

min(cid:26)Eu,xh(cid:0)exp(−σW )E(M−u) − ψ(σ, x)(cid:1)2i(cid:12)(cid:12)(cid:12)(cid:12) E(M−u) uniformly integrable(cid:27) .

In order to reformulate the importance sampling problem (2.11) as a stochastic opti-
mal control problem, we deﬁne

(2.12)

K σ,u,α := W + (2σ)−1hM uiτ + ασ−1M u

τ , α ∈ {0, 1} .

By (2.5) and (2.10), it follows that ψ(σ, x) = Eu,x(cid:2)exp(cid:0)−σK σ,u,1(cid:1)(cid:3). For an arbitrary,

adapted continuous local martingale M and stopping time T , we shall write

:=(MT∧t

0

M T
t

{0 < T}
{0 = T} .

Since the diﬀusion matrix is a strictly positive multiple of the identity matrix, it holds
that τ ∈ L1(µu,x) (see [16, Section 5.7, Lemma 7.4]). Thus, if u ∈ L∞(Ω), then it
follows that (M u)τ is a L2(µu,x)-bounded martingale, since

lim
t→∞

Eu,x[((M u)τ

t )2] = Eu,x[h(M u)τi∞] ≤ kuk2

L∞Eu,x[τ ].

Since Lp-boundedness for p > 1 implies uniform integrability, we may apply the
optimal stopping theorem to obtain Eu,x[M u
τ ] = 0 and Eu,x[K σ,u,1] = Eu,x[K σ,u,0].
By the strict concavity of the logarithm, Jensen’s inequality and (2.9b) yield

(2.13)

F (σ, x) ≤ Eu,x(cid:2)K σ,u,0(cid:3) =: φσ,x(u)

where inequality holds if and only if the random variable K σ,u,1 is µu,x-almost surely
constant (see, e.g. [21, Theorem 5]). Thus, we have shown that we can compute
F (σ, x) by solving the stochastic optimal control problem

(2.14)

φσ,x(u)

subject to (2.1),

min
u∈U

where U denotes the set of all previsible control processes. It was shown in [13] that
there exists a unique, Markovian optimal control uσ

opt given by

(2.15)

uσ
opt(x′) = −2εσ∇xF (σ, x′) ∀x′ ∈ Ω.

The link between the optimal control and importance sampling problems is evident
from (2.15) since the optimal (zero-variance) importance sampling measure associated
to uσ

opt is deﬁned in terms of F .

2.2. Connections to elliptic partial diﬀerential equations. In this section,
we recall some fundamental results concerning the functions ψ(σ,·) and F (σ,·). We
shall consider second order partial diﬀerential operators of the form

(2.16)

L :=

dXi,j=1

aij

∂
∂xi

∂
∂xj

+

bi

∂
∂xi

+ c

dXi=1

6

H. C. LIE

where the functions (aij )i,j , (bi)i, c ∈ C(Ω; R). Following the nomenclature from
stochastic analysis (see [16, Section 5.7A, Deﬁnition 7.1]), we shall say that L is
‘uniformly elliptic’ on Ω if there exists a constant λ > 0 such that

(2.17)

λ|ξ|2 ≤ ξ · aξ ∀ξ 6= 0.

Recall that the linear Dirichlet boundary value problem is given by

(2.18a)

(2.18b)
for f ∈ C(Ω; R) and ϕ ∈ C(∂Ω; R). Let u in (2.1) be an element of C(Ω; Rd). Then
the inﬁnitesimal generator corresponding to the SDE (2.1) given by

Lv(x) = f (x) x ∈ Ω,
v(y) = ϕ(y) y ∈ ∂Ω,

(2.19)

Au := ε∆ + (u − ∇V ) · ∇

is a second order, uniformly elliptic partial diﬀerential operator. Deﬁne the linear
Dirichlet boundary value problem

(2.20a)

A0ψ(σ, x) − σκr(x)ψ(σ, x) = 0 x ∈ Ω
ψ(σ, y) = exp(−σκt(y)) y ∈ ∂Ω.

(2.20b)
We can rewrite (2.20) as a problem of the form (2.18), with L := A0 − σκr and f = 0
on Ω, and with ϕ = exp(−σκt) on ∂Ω. The following classical result establishes (2.9a)
as the ‘Feynman-Kac formula’ for the solution to (2.20):

Proposition 2.1. If
(i) Ω is an open, bounded domain,
(ii) the ﬁrst-order coeﬃcient −∇V satisﬁes the growth conditions (2.2), and
(iii) κr ∈ C(Ω; [0,∞)) and κt ∈ C(∂Ω; R),

then there exists a unique solution ψ(σ,·) ∈ C2(Ω; R) ∩ C(Ω; R) that solves (2.20),
and ψ(σ,·) is of the form (2.9a).

Proof. See [16, Section 5.7, Proposition 7.2] and [16, Section 5.7, Lemma 7.4].
Proposition 2.1 is important in establishing a link between the function ψ(σ,·)
deﬁned in (2.9a) and the linear Dirichlet boundary value problem (2.20). In §3, we
shall require more regularity on the solution ψ(σ,·) in order to show L2-boundedness
of exponential martingales. Since we will also work with continuous functions that
are bounded on the compact set Ω, we also wish to know when the optimal control
uσ
opt deﬁned in (2.15) is bounded on Ω. Recall that a bounded domain Ω ⊂ Rd is of
class Ck,α for k ∈ N0 and 0 ≤ α ≤ 1 if ∂Ω is the graph of a Ck,α function of d − 1
coordinates [11, Section 6.2].

Theorem 2.2. Let 0 ≤ α ≤ 1 and L be uniformly elliptic. If
(i) Ω is an open, bounded, C2,α domain,
(ii) the coeﬃcients of L and f in (2.18a) belong to Cα(Ω),
(iii) the zeroth-order coeﬃcient of L is nonpositive, i.e. c ≤ 0 on Ω, and
(iv) κt ∈ C2,α(Ω),
Proof. See [11, Section 6.3, Theorem 6.14].
By the deﬁnitions (2.9a) and (2.9b), it holds that ψ(σ,·) = exp(−σF (σ,·)). By
the chain rule from ordinary calculus, we can formally transform the linear Dirichlet
problem (2.20) into the nonlinear Dirichlet problem

then the Dirichlet problem (2.18) has a unique solution v ∈ C2,α(Ω).

(2.21a)
(2.21b)

A0F (σ, x) − εσ|∇xF (σ, x)|2 + κr(x) = 0 x ∈ Ω
F (σ, y) = κt(y) y ∈ ∂Ω,

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

7

where (2.21a) is the Hamilton-Jacobi-Bellman (HJB) equation of the stochastic opti-
mal control problem (2.14). If there exists a unique solution F (σ,·) of (2.21), then it is
the value function of the stochastic optimal control problem. In general, there are no
classical solutions to (2.21), and one must search for a viscosity solution. Although vis-
cosity solutions are interesting objects in their own right, our present interest pertains
solely to classical solutions. For completeness, we shall consider suﬃcient conditions
for which there exists a classical solution to the nonlinear Dirichlet problem (2.21).
Let Γ := Ω × R × Rd × Rd×d, γ = (x, z, p, r) ∈ Γ be arbitrary, and H : Γ → R be

deﬁned by

(2.22)

H(x, z, p, r) := ε Xi

rii! − ∇V (x) · p − εσ|p|2 + κr(x).

From (2.22), it follows that H is constant with respect to z, concave with respect to
p, and linear with respect to r. Note that we can rewrite (2.21a) as

H(x, F (σ, x),∇xF (σ, x),∇2

xF (σ, x)) = 0 x ∈ Ω.

We have

Theorem 2.3. Let H be deﬁned as in (2.22).
(i) If Ω is a bounded domain satisfying an exterior sphere condition at each

boundary point, and

(ii) ∇V ∈ C2(Ω; Rd) and κr ∈ C2(Ω; R),

then the classical Dirichlet problem (2.21) is uniquely solvable in C2(Ω; R) ∩ C(Ω; R)
for any terminal cost κt ∈ C(∂Ω; R).
Proof. The proof follows from an application of [11, Section 17.5, Theorem 17.17].
Therefore, we must verify that the assumptions of that result hold for the operator H
deﬁned in (2.22). The assumptions of the present theorem guarantee that H ∈ C2(Γ),
and that H is constant with respect to z, concave with respect to p, and linear
with respect to r. Let Hij(x, z, p, r) := ∂H∂rij
(x, z, p, r). It remains to verify that the
structure conditions (see [11, Section 17.5, Eq. (17.53)])
0 < λ|ξ|2 ≤Xi,j

Hijξiξj ≤ Λ|ξ|2

(2.23a)

(2.23b)
(2.23c)

|Hp|,|Hz|,|Hrx|,|Hpx|,|Hzx| ≤ µλ,
|Hx|,|Hxx| ≤ µλ(1 + |p| + |r|),

are satisﬁed for nonzero ξ ∈ Rd, arbitrary (x, z, p, r) ∈ Γ, a function λ that is non-
increasing in |z|, and functions Λ and µ that are nondecreasing in |z|. By (2.22),
condition (2.23a) holds with λ = Λ = ε since Hij = δijε. Furthermore, Hz and Hrx
vanish everywhere, and

(2.24a)

(2.24b)

(2.24c)

(2.24d)

∂H
∂pi
∂2H
∂pi∂xj
∂H
∂xi
∂2H
∂xi∂xj

(x, z, p, r) = −

∂V
∂xi
∂2V
(x, z, p, r) = −
∂xixj
∂
∂xi
∂2

(x, z, p, r) =

(x, z, p, r) =

(x) − 2εσpi,

(x),

(κr(x) − ∇V (x) · p) ,

∂xixj

(κr(x) − ∇V (x) · p) .

8

H. C. LIE

Since neither of the right-hand sides of (2.24) depends on |z|, we may deﬁne µ : Γ → R
to be any function that satisﬁes (2.23b)–(2.23c).
Note that we may generalise Theorem 2.3 by weakening the requirement (ii),
i.e. by only requiring that ∇V and κr be twice weakly diﬀerentiable functions of
the spatial variable x and interpreting the structure conditions (2.23) in the weak
sense [11, Chapter 17, Problem 17.4].

Theorem 2.2 may be generalised to larger classes of domains that need not be
bounded (see [11, Section 6.3, Theorem 6.13] and the notes at the end of [11, Chapter
6]). Note that even if the zeroth-order coeﬃcient of the operator L fails to satisfy
the nonpositivity condition, solutions of (2.18) still belong to Ck+2,α(Ω) for k ∈ N0,
provided that the domain is Ck+2,α, the boundary function belongs to Ck+2,α(Ω),
and the coeﬃcients of the uniformly elliptic operator L belong to Ck,α(Ω). However,
uniqueness of solutions no longer holds [11, Section 6.4, Theorem 6.19].

3. Variational analysis of the control functional. In this section, we derive
expressions for the ﬁrst variation and the second variation of the control functional
with respect to admissible perturbations of the feedback control function. In Lemma
3.2, we adapt an argument due to Gilbarg and Trudinger, and use Fredholm theory
in order to assert that the moment generating function of the ﬁrst exit time deﬁned
in (2.7) is ﬁnite over any open, bounded interval containing the origin. We then use
Lemma 3.2 to show that Kazamaki’s suﬃcient condition (3.3) for Lq-boundedness of
exponential martingales holds for the case that q > 1. Together with the Cauchy-
Schwarz inequality and Lebesgue’s dominated convergence theorem, Lq-boundedness
yields the expressions for the ﬁrst and second variations. The main result of this
section, Theorem 3.14, shows the strict convexity of the control functional by prov-
ing that the second variation is a positive deﬁnite functional on the Banach space
C1,α(Ω; Rd) whenever the work path functional W deﬁned in (2.8) is bounded from
below. Recall that σ > 0 is a ﬁxed parameter. All the results in this section, unless
otherwise stated, shall be based upon the following
Assumption 3.1. Let 0 ≤ α ≤ 1. It holds that
(i) the domain Ω is bounded and of class C2,α,
(ii) the gradient of the potential ∇V ∈ Cα(Ω; Rd) ∩ W 2(Ω; Rd),
(iii) the running cost κr ∈ Cα(Ω; [0,∞)) ∩ W 2(Ω; R), and
(iv) the terminal cost κt ∈ C2,α(Ω; R).
By Theorem 2.2, there exists a unique solution to (2.18) in C2,α(Ω; R) with f = 0
on Ω and ϕ = exp(−σκt) on ∂Ω. Proposition 2.1 guarantees that the unique solution
is described by the Feynman-Kac formula (2.9a). It follows from (2.9a) and Jensen’s
inequality that exp(E0,x[−σW ]) ≤ ψ(σ, x); since ﬁniteness of ψ(σ, x) on Ω implies
ﬁniteness of E0,x[−σW ], it follows that ψ(σ, x) is bounded away from zero on Ω. On
the other hand, the maximum principle implies that ψ(σ, x) is bounded from above.
Thus, given the relation (2.9b), it follows that F (σ,·) ∈ C2,α(Ω; R). By Theorem
2.3, F (σ,·) is a classical solution of the HJB problem (2.21), and the optimal control
belongs to C1,α(Ω; Rd).

3.1. Lq-bounded exponential martingales. The ﬁrst result below is of cru-

cial importance:

Lemma 3.2. Suppose that Assumption 3.1 holds.

If u ∈ Cα(Ω), then for all
r > 0, there exists σp > r such that Eu,x [exp(σpτ )] is ﬁnite for all x ∈ Ω.
Proof. We prove the statement using Fredholm theory, following the argument
outlined at the end of [11, Section 6.3]. Observe that, for an arbitrary σn < 0,
Eu,x[exp(σnτ )] uniquely solves the Feynman-Kac boundary value problem (2.20) with

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

9

the choice of −σ = σn < 0, κr = 1 and κt = 0. Since κr and κt are constant, they
may be extended to all of Ω. Therefore, we may conclude from Theorem 2.2 that
Eu,x[exp(σnτ )] belongs to C2,α(Ω; R). We rewrite this Feynman-Kac boundary value
problem as an elliptic boundary value problem of the form (2.18):
Lu,σn v(x) := Auv(x) + σnv(x) = 0, x ∈ Ω,

(3.1a)

(3.1b)

v(y) = 1, y ∈ ∂Ω.

Since all the coeﬃcients of Lu,σn belong to Cα(Ω), the operator L deﬁnes a closed
map from coeﬃcients that belong to Cα(Ω) to solutions that belong to C2,α(Ω).
By [11, Theorem 5.5], it follows that there is a countable, discrete set Σ ⊂ R, such
that if σ ∈ Σ, then the homogeneous problem
(3.2a)
(3.2b)

Lu,σn−σv(x) = Lu,σn v(x) − σv(x) = 0, x ∈ Ω,

v(y) = 0, y ∈ ∂Ω

has nontrivial solutions. Therefore, for σ /∈ Σ, the homogeneous problem (3.2) has
only the trivial solution v ≡ 0. By the Fredholm alternative (see [11, Section 6.3,
Theorem 6.15]), it follows that the corresponding inhomogeneous problem obtained
by replacing (3.2b) with (3.1b) has a unique solution in C2,α(Ω). By the extreme
value theorem and compactness of Ω, the unique solution is ﬁnite on Ω. By Itˆo’s
formula, the unique solution admits the representation v(x) = Eu,x [exp((σn − σ)τ )].
Now let r > 0 be arbitrary. Since Σ is discrete, there exists a σ ∈ (−∞, 0) ∩ Σ∁ such
that σp := σn − σ > r, and the conclusion follows.
Corollary 3.3. For all x ∈ Ω, σn < 0 and r > 0, there exists a closed
interval [σn, σp] with σp > r such that the moment generating function deﬁned by
Eu,x [exp(στ )] is ﬁnite for all σ ∈ [σn, σp].
Proof. Let x ∈ Ω be arbitrary. For any σn < 0, Eu,x[exp(σnτ )] ≤ 1 by monotonic-
ity of the integral. By Lemma 3.2, there exists a σp > r such that Eu,x[exp(σpτ )] is ﬁ-
nite. For arbitrary σn < σ < σp, there exists a 0 < θ < 1 such that σ = θσn+(1−θ)σp.
By the strict convexity of the exponential, we have

exp(στ ) < θ exp(σnτ ) + (1 − θ) exp(σpτ ).

Taking expectations with respect to µu,x yields the desired conclusion.

Theorem 3.4. Let τ be an arbitrary stopping time, and let σ > 0 be such that

E [exp(στ )] is ﬁnite. If for some 1 < p < ∞, it holds that ϕ ∈ L∞(Ω) satisﬁes
(3.3)

(√p − 1)2

,

kϕk2

L∞(Ω) ≤ 2σ

p

then the stopped exponential martingale E((M ϕ)τ ) is an Lq-bounded martingale for
q−1 = 1 − p−1 and E[E(M ϕ)q
Proof. Let p and q be a pair of H¨older conjugate exponents. Recall [17, Section
1.2, Theorem 1.5]: for a given continuous local martingale M , if

τ ] is ﬁnite.

(3.4)

sup(cid:26)E(cid:20)exp(cid:18) 1

2

√p
√p − 1

MT(cid:19)(cid:21)(cid:12)(cid:12)(cid:12)(cid:12) T a bounded stopping time(cid:27) < ∞,

then the exponential martingale E(M ) is Lq-bounded. Let T be an arbitrary bounded
stopping time. Since it follows from (2.5) that

exp(cid:18) 1

2

MT(cid:19) = (E(M )T )1/2 exp(cid:18) 1

4hMiT(cid:19) ,

10

H. C. LIE

it holds by the Cauchy-Schwarz inequality that

(3.5)

(3.6)

Combining the inequality (3.5) with (3.4), we therefore obtain that

.

2

2hMiT(cid:19)(cid:21)1/2

MT(cid:19)(cid:21) ≤ E(cid:20)exp(cid:18) 1

E(cid:20)exp(cid:18) 1
2(√p − 1)2hMiT(cid:19)(cid:21)(cid:12)(cid:12)(cid:12)(cid:12) T a bounded stopping time(cid:27) < ∞

p

sup(cid:26)E(cid:20)exp(cid:18)

is a suﬃcient condition for the Lq-boundedness of E(M ). By the assumption that
ϕ ∈ L∞(Ω), it holds that

Since (3.3) is equivalent to

h(M ϕ)τiT ≤ kϕk2

L∞(Ω) (τ ∧ T ) .

p

2(√p − 1)2kϕk2

L∞(Ω) ≤ σ,

and since E[exp(στ )] is ﬁnite, it follows that (3.6) is satisﬁed, by the monotonicity
of the exponential and of the integral. Therefore E(M ϕ)τ is Lq-bounded. By the
deﬁnition of Lq-boundedness, it follows that E(M ϕ)τ ∈ Lq(µu,x), as desired.
The next result combines Lemma 3.2 and Theorem 3.4 to show that, for any
ϕ ∈ L∞(Ω; Rd), it holds that E((M ϕ)τ ) is Lq(µu,x)-bounded for any q > 1.
holds. If u ∈ Cα(Ω) and ϕ ∈ L∞(Ω), then

Corollary 3.5. Let τ be deﬁned as in (2.7) and suppose that Assumption 3.1

(i) E(M ϕ)τ is Lq(µu,x)-bounded for all q > 1, and
(ii) for any 1 ≤ r < ∞, Eu,x[hM ϕir
τ ] is ﬁnite, and for any 0 < s < ∞,
Proof. We ﬁrst prove statement (i). Let p be the H¨older conjugate of q, and deﬁne

Eu,x[sup0≤t≤τ |M ϕ

t |s] is ﬁnite.

rp :=

p

2(√p − 1)2kϕk2

L∞(Ω).

To prove statement (ii), observe that (3.6) implies that E[hM ϕir

Since u ∈ Cα(Ω), there exists a σp > rp so that Eu,x [exp(σpτ )] is ﬁnite for all x ∈ Ω,
by Lemma 3.2. Hence, ϕ satisﬁes (3.3), and the conclusion follows by Theorem 3.4.
τ ] is ﬁnite for
all r ∈ N, and hence for all 1 ≤ r < ∞, by Jensen’s inequality. The second asser-
tion of statement (ii) follows from this observation and the Burkholder-Davis-Gundy
inequalities [23, Chapter IV, §4, Theorem 4.1].
controls u, the quantity Eu,x [exp(−σW )] is a ﬁnite for all x ∈ Ω.
If u ∈ L∞(Ω), then Eu,x [exp(−σW )] is ﬁnite, and W ∈ Ln(µu,x) for all n ∈ N.
Proof. Since the constant 0 belongs to Cα(Ω), and since we assumed that u ∈
L∞(Ω), we may apply Corollary 3.5 to assert that E(M u)τ is L2(µ0,x)-bounded. By
the reweighting formula (2.6) and the Cauchy-Schwarz inequality,

The next result shows that Assumption 3.1 suﬃces to guarantee that, for bounded

Lemma 3.6. Let W be deﬁned as in (2.8) and suppose that Assumption 3.1 holds.

Eu,x [exp(−σW )] ≤(cid:0)E0,x [exp(−2σW )] E0,x(cid:2)E(M u)2

τ(cid:3)(cid:1)1/2

,

where Theorem 2.2 implies that the ﬁrst term on the right-hand side is ﬁnite and
L2(µ0,x)-boundedness of E(M u)τ implies that the second term on the right-hand side

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

11

is ﬁnite. This proves the ﬁrst conclusion. The second conclusion follows from the
series expansion of the exponential.

The next result of this section will be useful later and follows from statement (ii)

of Corollary 3.5 and Lemma 3.6.

Corollary 3.7. Suppose that Assumption 3.1 holds. If σ > 0 and u ∈ Cα(Ω),

then K σ,u,0, K σ,u,1 ∈ Ln(µu,x) for all n ∈ N.

3.2. Convergence lemma. By the deﬁnition (2.5) of the exponential martin-
gale, it holds that for 0 6= δ ∈ R, a Borel-measurable function ϕ : Rd → Rd, and a
stopping time τ ,

E(M δϕ)τ = exp(cid:20)M δϕ

τ −

1

2hM δϕiτ(cid:21) = exp(cid:20)δ(cid:18)M ϕ

τ −

δ

2hM ϕiτ(cid:19)(cid:21) .

The series expansion of the exponential thus yields

(3.7)

and hence

(3.8)

E(M δϕ)τ = 1 +

∞Xm=1

δm(cid:0)M ϕ

E(M δϕ)τ − 1

δ

− M ϕ

τ = −

δ
2hM ϕiτ +

m!

τ − δ2−1hM ϕiτ(cid:1)m
δm−1(cid:0)M ϕ

∞Xm=2

τ − δ2−1hM ϕiτ(cid:1)m

m!

.

We have the following convergence result:

Lemma 3.8. Suppose that Assumption 3.1 holds, that u ∈ Cα(Ω), and ϕ ∈
L∞(Ω). Then for any nonzero sequence (δn)n satisfying δn → 0 as n → ∞, it holds
that E(M δnϕ)τ ∈ L2(µu,x) for all n ∈ N, and
(3.9)

(3.10)

lim
n→∞

lim
n→∞

Eu,xh(cid:0)E(M δnϕ)τ − 1(cid:1)2i = 0,
τ(cid:19)2# = 0.

Eu,x"(cid:18)E(M δnϕ)τ − 1

− M ϕ

δn

Proof. Without loss of generality, we may assume that the sequence (|δn|)n is

bounded by 0 < r < 1, so that

kδnϕkL∞(Ω) ≤ rkϕkL∞(Ω) < kϕkL∞(Ω).

(3.11)
Therefore, for all n ∈ N, δnϕ ∈ L∞(Ω), and by Corollary 3.5,
it follows that
E(M δnϕ)τ ∈ L2(µu,x) for all n ∈ N. By H¨older’s inequality, we have (see the proof
of [17, Section 1.2, Theorem 1.5])

Applying (3.5) and (3.11) to the inequality above yields

Eu,x(cid:2)E(M δnϕ)2

Eu,x(cid:2)E(M δnϕ)2

τ(cid:3) ≤ Eu,x"exp  √2
2(√2 − 1)
τ(cid:3) ≤ Eu,x(cid:20)exp(cid:18)
< Eu,x(cid:20)exp(cid:18)

(√2 − 1)2kδnϕk2
(√2 − 1)2kϕk2

1

1

τ !#2/(√2+1)

M δnϕ

.

L∞(Ω)τ(cid:19)(cid:21)1/(√2+1)
L∞(Ω)τ(cid:19)(cid:21)1/(√2+1)

.

(3.12)

12

H. C. LIE

By Corollary 3.3, it follows that the collection of random variables (E(M δnϕ)τ )n is
bounded in L2(µu,x). We can therefore apply Lebesgue’s dominated convergence
theorem and the identity (3.7) in order to obtain

which proves (3.9). To prove (3.10), we ﬁrst observe that by (3.7), the random series

lim
n→∞

Eu,xh(cid:0)E(M δnϕ)τ − 1(cid:1)2i = Eu,xh lim
R(δn) :=(cid:0)E(M δnϕ)τ − 1(cid:1)2

− δ2

(3.13)

τ )2 ∈ L1(µu,x)
consists of terms that are cubic or higher in δn, so that limn→∞ δ−2
Then there exists some constant C(r) > 0 so that

n (M ϕ

n→∞(cid:0)E(M δnϕ)τ − 1(cid:1)2i = 0,

n Eu,x[R(δn)] = 0.

Eu,x"(cid:18)E(M δnϕ)τ − 1

δn

(3.14)

(cid:19)2# = Eu,x [hM ϕiτ ] + C(r)

≤ Eu,xhkϕk2

L∞(Ω)τi + C(r).

Thus the sequence (δ−1
τ be-
longs to L2(µu,x) and since L2(µu,x) is a vector space, it follows that the sequence
(δ−1
τ )n is bounded in L2(µu,x). We can then apply Lebesgue’s
n (E(M δnϕ)τ − 1) − M ϕ
dominated convergence theorem and the identity (3.8) to obtain

n (E(M δnϕ)τ − 1))n is bounded in L2(µu,x). Since M ϕ

Eu,x"(cid:18)E(M δnϕ)τ − 1

δn

lim
n→∞

as desired.

τ(cid:19)2# = Eu,x" lim

n→∞(cid:18)E(M δnϕ)τ − 1

δn

− M ϕ

τ(cid:19)2# = 0,

− M ϕ

3.3. First variation of control functional. In order to derive an expression
for the ﬁrst variation of the control functional φ deﬁned in (2.13), we shall proceed
by showing the convergence in L1(µu,x) of a sequence of ﬁnite diﬀerences of φσ,x. For
a given sequence (δn)n and function ϕ that satisfy the conditions of Lemma 3.8, we
deﬁne the ﬁnite diﬀerence random variables by

(3.15) hσ,u,ϕ

n

:= K σ,u,0E(M δnϕ)τ − 1

δn

+

1

σ(cid:18)hM u, M ϕiτ +

δn

2 hM ϕiτ(cid:19)E(M δnϕ)τ .

We show that the (hσ,u,ϕ

)n are indeed the appropriate ﬁnite diﬀerences in the next
Lemma 3.9. Suppose that Assumption 3.1 holds, that u ∈ Cα(Ω), ϕ ∈ L∞(Ω)
)n

and (δn)n be an arbitrary nonzero sequence satisfying δn → 0 as n → ∞. Let (hσ,u,ϕ
be the corresponding sequence given by (3.15). Then (hσ,u,ϕ

n

n

n

)n ⊂ L1(µu,x) and

φσ,x(u + δnϕ) − φσ,x(u)

δn

= Eu,x [hσ,u,ϕ

n

] ∀n ∈ N.

Proof.

|n ∈ N} ⊂ L1(µu,x), we shall apply the
Cauchy-Schwarz inequality individually to the three summands on the right-hand
side of (3.15). Recall the inequality of arithmetic and geometric means,

In order to show that {hσ,u,ϕ

n

(3.16)

|ab| ≤ 2−1(a2 + b2),

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

13

with equality holding if and only if a = b, and the Kunita-Watanabe inequality

(3.17)

hM ϕ, M ζiτ ≤(cid:0)hM ϕiτhM ζiτ(cid:1)1/2

that holds almost surely, with equality holding almost surely if and only if ϕ = ζ
except on a set of Lebesgue measure zero. The stated assumptions guarantee that W ∈
L2(µu,x), by Lemma 3.6; that the sequences (δ−1
n (E(M δnϕ)τ − 1))n and (E(M δnϕ)τ )n
are bounded sequences in L2(µu,x), by (3.14) and (3.12); and that integer moments of
quadratic variation processes belong to L2(µu,x), by Corollary 3.5 (ii). Since K σ,u,0 ∈
L2(µu,x) by Corollary 3.7 and

Eu,x(cid:2)|hM u, M ϕiτ|2(cid:3) ≤ Eu,x(cid:2)hM uiτ + hM ϕi2
τ(cid:3)

(3.18)
by (3.16) and (3.17), it follows that {hn|n ∈ N} ⊂ L1(µu,x), thus proving the ﬁrst
statement.
To prove the second statement, observe that by Lemma 3.8, it follows that each
E(M δnϕ) is a L2(µu,x)-bounded exponential martingale. Since Lq-boundedness for
q > 1 implies uniform integrability, we can apply the reweighting formula (2.6) to
express φσ,x(u + δnϕ) as an expectation with respect to µu,x. By the deﬁnition of the
quadratic variation, we have for any stopping time τ that

By the reweighting formula and (3.19) we therefore have

(3.19)

hM u+δnϕiτ = hM uiτ + δ2
φσ,x(u + δnϕ) = Eu,x(cid:20)(cid:18)W + hM uiτ

2σ

+

nhM ϕiτ + 2δnhM u, M ϕiτ .

δ2
n
2σhM ϕiτ +

δn

σ hM u, M ϕiτ(cid:19)E(M δnϕ)τ(cid:21) .

Taking diﬀerences yields the desired conclusion.

We now deﬁne the limiting random variable to be

(3.20)

hσ,u,ϕ := K σ,u,0M ϕ

τ + σ−1hM u, M ϕiτ ,

and show that the expected value of hσ,u,ϕ is equal to the ﬁrst variation of φσ,x(u) in
the direction of ϕ:

Theorem 3.10. If the hypotheses of Lemma 3.9 are satisﬁed, then h ∈ L1(µu,x),

hn converges to h in L1(µu,x), and the ﬁrst variation of φσ,x(u) along ϕ satisﬁes

(3.21)

Φσ,x(u; ϕ) := lim
n→∞

φσ,x(u + δnϕ) − φσ,x(u)

δn

= Eu,x[hσ,u,ϕ].

|Eu,x [hσ,u,ϕ − hσ,u,ϕ

(3.22)
The ﬁrst conclusion, that hσ,u,ϕ ∈ L1(µu,x), follows from the observation that

Proof. The third conclusion follows from the second, since
]| ≤ Eu,x [|hσ,u,ϕ − hσ,u,ϕ
τ |(cid:3) + σ−1Eu,x [|hM u, M ϕiτ|] ,

Eu,x [|hσ,u,ϕ|] ≤ Eu,x(cid:2)|K σ,u,0M ϕ

and by using the Cauchy-Schwarz inequality, Corollary 3.7, and (3.18).

|] .

n

n

It remains to show the convergence in L1(µu,x) of hσ,u,ϕ

n

to hσ,u,ϕ. We apply the

triangle inequality to obtain

(3.23)

|hσ,u,ϕ

n

τ(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)
− hσ,u,ϕ| ≤(cid:12)(cid:12)(cid:12)(cid:12)K σ,u,0(cid:18)E(M δnϕ)τ − 1
σ(cid:0)(cid:12)(cid:12)hM u, M ϕiτ(cid:0)E(M δnϕ)τ − 1(cid:1)(cid:12)(cid:12)(cid:1) + |δn|

− M ϕ

δn

+

1

2σ hM ϕiτE(M δnϕ)τ .

14

H. C. LIE

Recall that (E(M δnϕ)τ )n is a bounded sequence in L2(µu,x), by (3.12). Therefore,
by the Cauchy-Schwarz inequality and Lebesgue’s dominated convergence theorem,
the third term on the right-hand side converges to zero in L1(µu,x). By the Cauchy-
Schwarz inequality, the bound (3.18), and the convergence result (3.9), the second
term on the right-hand side converges to zero in L1(µu,x). By the Cauchy-Schwarz
inequality, Corollary 3.7, and the convergence result (3.10), the ﬁrst term on the
right-hand side converges to zero in L1(µu,x). This completes the proof.

Corollary 3.11. The ﬁrst variation Φσ,x(u; ϕ) satisﬁes

(3.24)

τ(cid:3) .
Φσ,x(u; ϕ) = Eu,x(cid:2)K σ,u,1M ϕ

In particular, the ﬁrst variation Φσ,x(u; ϕ) vanishes if and only if K σ,u,1 and M ϕ
uncorrelated with respect to µu,x.

τ are

Proof. The ﬁrst assertion follows from the deﬁnition (2.12) of K σ,u,α and the fact

that Eu,x[hM u, M ϕiτ ] = Eu,x[M u
Corollary 3.11 is consistent with the assertion made earlier, that the optimal
control that solves the stochastic optimal control problem (2.14) yields an optimal
importance sampling measure, i.e. a zero-variance estimator for the value function F
for any given pair of arguments.

τ ]. The second assertion follows from (3.24).

τ M ϕ

3.4. First variation of ﬁrst variation. In this section, we derive an expression
for the ﬁrst variation of the functional Φσ,x(u; ϕ) along an admissible perturbation ζ,
where the argument u is perturbed and the parameters σ, x, and ϕ are held ﬁxed. As
in §3.3, we shall ﬁrst deﬁne for a given sequence (δn)n a sequence of ﬁnite diﬀerences:

(3.25)

hσ,u,ϕ,ζ
n

:=(cid:18)K σ,u,0M ϕ

τ +

1

σhM u, M ϕiτ(cid:19) E(M δnζ)τ − 1

δn
τ + hM ϕ, M ζiτ +

1

+

The following result is analogous to Lemma 3.9:

σ(cid:18)hM u, M ζiτ M ϕ

2 hM ζiτ(cid:19)E(M δnζ)τ .
Lemma 3.12. Suppose that Assumption 3.1 holds, that u ∈ Cα(Ω), that ϕ, ζ ∈
L∞(Ω), and that (δn)n is an arbitrary nonzero sequence satisfying δn → 0 as n → ∞.
Let (hσ,u,ϕ,ζ)n be the corresponding sequence given by (3.25). Then (hσ,u,ϕ,ζ
)n ⊂
L1(µu,x) and

δn

n

Φσ,x(u + δnζ; ϕ) − Φσ,x(u; ϕ)

δn

= Eu,x(cid:2)hσ,u,ϕ,ζ

n

(cid:3) .

Proof. We ﬁrst prove that the terms on the ﬁrst row of (3.25) belong to L1(µu,x).
By the triangle inequality and the inequality (3.16) of arithmetic and geometric means,
it holds that

(cid:18)K σ,u,0M ϕ

τ +

1

σhM u, M ϕiτ(cid:19)E(M δnζ)τ − 1
≤ |K σ,u,0M ϕ

δn

E(M δnζ )τ − 1

δn

2

+ σ−2hM u, M ϕi2
τ .

τ |2 + 2(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

The third term on the right-hand side belongs to L1(µu,x) by (3.18), the second
term on the right-hand side belongs to L1(µu,x) by (3.14), and the ﬁrst term on the
right-hand side belongs to L1(µu,x), by statement (ii) of Corollary 3.5 and 3.7.

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

15

Of the terms on the second row of (3.25), we only need to show that the product
τ ∈ L2(µu,x), since the other terms were shown to belong to L1(µu,x)

hM u, M ζiτ M ϕ
in the proof of Lemma 3.9. By the Cauchy-Schwarz inequality, (3.16), and (3.17),

(3.26)

Eu,xh(cid:0)hM u, M ζiτ M ϕ

τ(cid:1)2i ≤(cid:0)Eu,x(cid:2)hM ui4

τ + hM ζi4
∈ L1(µu,x) for all n.

n

which completes the proof that hσ,u,ϕ,ζ

τ(cid:3) Eu,x [hM ϕiτ ](cid:1)1/2

,

The second conclusion of the lemma follows in the same manner as for the second
conclusion of Lemma 3.9, i.e. by expanding the quadratic variation according to
(3.19), using the reweighting formula (2.6), and taking diﬀerences.

We deﬁne the limiting random variable of the sequence (hσ,u,ϕ,ζ

n

)n by

(3.27)

hσ,u,ϕ,ζ := K σ,u,0M ϕ

τ M ζ

τ +

1

σ(cid:0)hM ϕ, M ζiτ + M ζ

τ hM u, M ϕiτ + M ϕ

τ hM u, M ζiτ(cid:1) ,

and show that, in expectation, hσ,u,ϕ,ζ equals the ﬁrst variation of Φσ,x(u; ϕ) along ζ:
If the hypotheses of Lemma 3.12 are satisﬁed, then hσ,u,ϕ,ζ
converges to hσ,u,ϕ,ζ in L1(µu,x), and the ﬁrst variation

Theorem 3.13.

belongs to L1(µu,x), hσ,u,ϕ,ζ
of Φσ,x(u; ϕ) along ζ satisﬁes

n

(3.28)

Φσ,x(u; ϕ, ζ) := lim
n→∞

Φσ,x(u + δnζ; ϕ) − Φσ,x(u; ϕ)

δn

= Eu,x(cid:2)hσ,u,ϕ,ζ(cid:3) .

Proof. As in the proof of Theorem 3.10, the third conclusion follows from the
second, by (3.22). The ﬁrst conclusion, that hσ,u,ϕ,ζ belongs to L1(µu,x) follows from
Corollary 3.7, (3.18), and (3.26).

It remains to prove the second conclusion, i.e.

hσ,u,ϕ,ζ in L1(µu,x). We apply the triangle inequality to obtain

the convergence of hσ,u,ϕ,ζ

to

n

|hσ,u,ϕ,ζ

n

− hσ,u,ϕ,ζ| ≤(cid:0)|K σ,u,0M ϕ

τ | + σ−1|hM u, M ϕiτ|(cid:1)(cid:12)(cid:12)(cid:12)(cid:12)
σ(cid:0)(cid:12)(cid:12)hM ϕ, M ζiτ(cid:12)(cid:12) +(cid:12)(cid:12)hM u, M ζiτ M ϕ

E(M δnζ)τ − 1

τ(cid:12)(cid:12)(cid:12)(cid:12)
τ(cid:12)(cid:12)(cid:1)(cid:12)(cid:12)E(M δnζ )τ − 1(cid:12)(cid:12)

− M ζ

δn

1

2σ hM ζiτE(M δnζ)τ .

+
+ |δn|

The L1(µu,x) convergence to zero of the term on the third row of the right-hand side
was shown in the proof of Theorem 3.10. Of the two terms on the second row, only
τ | and |E(M δnζ)τ − 1| has not been
the convergence of the product of |hM u, M ζiτ M ϕ
proven, but this follows by the Cauchy-Schwarz inequality, (3.26), and (3.9). The
L1(µu,x) convergence to zero of the terms on the ﬁrst row follows from the Cauchy-
Schwarz inequality and the convergence result (3.10).

We now use Theorem 3.13, along with some standard results from the calculus of
variations concerning second-order conditions for convexity of C2 functionals deﬁned
on Banach spaces, in order to specify a suﬃcient condition for convexity of the control
functional φ deﬁned in (2.13).

Theorem 3.14. Assume that the hypotheses of Theorem 3.13 hold. Let σ > 0

and x ∈ Ω \ ∂Ω be ﬁxed. If the terminal cost κt satisﬁes the lower bound
(3.29)

κt(y) ≥ σ−1 ∀y ∈ ∂Ω,

then the undiscretised control functional φσ,x : C1,α(Ω; Rd) → R is strictly convex.

16

H. C. LIE

Proof. By setting ϕ = ζ in (3.27) and taking expectations, we obtain the following

expression for the second variation of φσ,x at u in the direction of ϕ:

(3.30)

Φσ,x(u; ϕ, ϕ) = Eu,x(cid:2)K σ,u,0(M ϕ

τ )(cid:3) .
τ )2 + σ−1 (hM ϕiτ + 2hM u, M ϕiτ M ϕ

Recall (see, e.g. [28, Section 2.9, Corollary 4]) that if the second variation of a C2
functional on a Banach space is positive deﬁnite, then the functional is strictly convex.
With this in mind, we show that (3.29) suﬃces to guarantee positive deﬁniteness of
the second variation. Let u ∈ C1,α(Ω) and 0 6= ϕ ∈ C1,α(Ω) be arbitrary. Observe
that, by the Kunita-Watanabe inequality and Young’s inequality, we have

|hM u, M ϕiτ M ϕ

τ | ≤ (hM uiτhM ϕiτ )1/2 |M ϕ

τ | ≤ 4−1hM uiτ (M ϕ

τ )2 + hM ϕiτ .

Therefore, we have

Φσ,x(u; ϕ, ϕ) ≥ Eu,x(cid:20)K σ,u,0(M ϕ

σ(cid:18) 1
4hM uiτ (M ϕ
τ )2 −
= Eu,x(cid:2)(W − σ−1)(M ϕ
τ )2(cid:3) ,

2

τ )2 + hM ϕiτ(cid:19)(cid:21)

(3.31)

where we used the deﬁnition (2.12) of K σ,u,α and the Itˆo isometry to obtain (3.31).
Since x ∈ Ω\ ∂Ω and κr is nonnegative by Assumption 3.1, it follows from (3.29) that
W − σ−1 is strictly positive µu,x-almost surely. Furthermore, since ϕ 6= 0 and since
τ )2 = hM ϕiτ is strictly positive µu,x-almost surely. This
x ∈ Ω\∂Ω, it follows that (M ϕ
proves that the the random variable inside the expectation in (3.31) is strictly positive
µu,x-almost surely, and thus the variation Φσ,x(u; ϕ, ϕ) of the control functional φσ,x
is positive deﬁnite on C1,α(Ω).

Remark on second-order characterisation of convexity. The advantage of proving
strict convexity of the control functional φσ,x by proving positive deﬁniteness of the
second variation is that that one can bound the second variation from below by a
quantity that does not contain any exponential martingales, as we have shown above.
This leads to a simple suﬃcient condition (3.29) for positive deﬁniteness. On the other
hand, one can verify using the reweighting formula that the zeroth- and ﬁrst-order
characterisations of convexity involve expressions that contain exponential martin-
gale terms, and thus the suﬃcient conditions obtained from these characterisations
are more complicated. Furthermore, for the zeroth-order characterisation, one needs
to check that the Radon-Nikodym derivative exists and is a uniformly integrable ex-
ponential martingale, in order to express all the expected values that appear in the
zeroth-order characterisation in terms of a common path measure µu′,x. Although
Novikov’s condition is well-known in stochastic analysis for being a suﬃcient condi-
tion for uniform integrability, we do not know of any suﬃcient conditions for Novikov’s
condition that can be veriﬁed for arbitrary bounded domains of suﬃcient regularity
and stopping times that are integrable but not almost-surely bounded, aside from the
hypotheses of Theorem 3.4. However, once the hypotheses of Theorem 3.4 hold, then
it follows that the second variation exists, and one can prove the strict convexity of
the control functional using the second-order characterisation, as we have done above.
Given that we have imposed strong conditions on the data of the stochastic opti-
mal control problem, such as boundedness and regularity of the domain Ω and restric-
tion to feedback controls belonging to C1,α(Ω; Rd), it seems reasonable that we obtain
strong results on the control functional. Let Π2(B) be the set of all predictable pro-
cesses that are adapted to the ﬁltration generated by the Brownian motion B. Given

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

17

u ∈ Cα(Ω; Rd), deﬁne the function k · kB,u : Π2(B) → [0,∞) according to
(3.32)

kϕkB,u := (Eu,x [hM ϕiτ ])1/2 .

It follows from the deﬁnition of the quadratic variation process that k · kB,u deﬁnes
a norm on Π2(B). Since feedback processes ut := u(X u
t ) are predictable processes, it
follows that k·kB,u induces a norm on the set of feedback control processes, including
those generated by feedback controls belonging to C1,α(Ω; Rd). We can therefore
consider k · kB,u as a norm on C1,α(Ω; Rd). We then have the following

Corollary 3.15. Suppose that

(3.33)

γ := γ(σ, κt) := min
y∈∂Ω

κt(y) − σ−1

is strictly positive. Then for all u ∈ C1,α(Ω; Rd), the second variation Φσ,x(u; ϕ, ϕ) is
a coercive functional of ϕ with parameter γ on C1,α(Ω; Rd), in the sense that

Φσ,x(u; ϕ, ϕ) ≥ γ(σ, κt)kϕk2

(3.34)
for all 0 6= ϕ ∈ C1,α(Ω; Rd).
We emphasise that Theorem 3.14 are consistent with the classical result (Theo-
rem 2.2) concerning the existence of a unique solution to the linear Dirichlet problem.
In the context of linear elliptic Dirichlet boundary value problems, κt is a continuous
function on a compact set. Therefore, one can always ensure that the suﬃcient con-

B,u

where C = max{0,−γ(σ, κt)}.

dition (3.29) holds, by considering the translated terminal cost function bκt := κt + C,

4. Approximation by a ﬁnite-dimensional subspace. In this section, we
consider some consequences of the strict convexity result Theorem 3.14, given that
Assumption 3.1 holds. The ﬁrst consequence of Theorem 3.14 that we shall consider
(Theorem 4.4 below) concerns the well-posedness of the gradient descent algorithm
proposed by Hartmann and Sch¨utte in [13]. The second consequence concerns the best
approximation of the value function F (σ,·) that solves the Hamilton-Jacobi-Bellman
equation of the stochastic optimal control problem (2.14).
i=1 of linearly independent, nonconstant functions

bi ∈ C2,α(Ω; R), and let Si :=(cid:8)x ∈ Ω | bi(x) 6= 0(cid:9) denote the support of bi in Ω. We

Fix a ﬁnite collection b := (bi)n

shall assume that

(4.1)

λ(Si) > 0, ∪n

i=1Si = Ω,

i.e. the support of each function bi has strictly positive Lebesgue measure, and the
closures of the supports cover Ω. Let ϕi := ∇bi and consider the following subspace
of C1,α(Ω; Rd):

(4.2)

UMarkov(b) :=(u ∈ UMarkov (cid:12)(cid:12)(cid:12)(cid:12) u = ua :=Xi

ai∇bi for some a ∈ Rn) .

bφσ,x with respect to the i-th coordinate ai.

By linear independence of the basis vector ﬁelds (ϕi)i,
it holds that every u ∈
UMarkov(b) admits a unique representation u = ua. Therefore, the restriction of the
control functional φσ,x to the subspace UMarkov(b) may be uniquely represented by
(4.3)

bφσ,x : Rn → R,

bφσ,x(a) := φσ,x(ua).

By Corollary 3.11, we obtain an expression for the partial derivative of the function

18

H. C. LIE

4.1. An initial value problem. Consider the initial value problem

(4.4)

d
dt

a(s) = −∇aφσ,x(a(s)), a(0) ∈ Rn.

The main result of this section concerns the existence of solutions to (4.4). To prove
the result, we make the following

Assumption 4.1. Let ∇V ∈ Cα(Ω) and τ be deﬁned as in (2.7). Then for all
1 ≤ i ≤ n, there exists a pair 0 ≤ t0(i) < t1(i) ≤ τ such that for all t0(i) < t < t1(i),
X 0
t ∈ Si with positive P x-probability.
Proposition 4.2. Suppose that Assumptions 3.1 and 4.1 hold, and let τ be
deﬁned as in (2.7). If ua ∈ UMarkov(b), then for all 1 ≤ i ≤ n, there exists a pair
0 ≤ t0(i) < t1(i) ≤ τ such that for all t0(i) < t < t1(i), X ua
t ∈ Si with positive
P x-probability.
)τ )
is a L2(µ0,x)-bounded martingale, and hence is uniformly integrable with respect to
µ0,x. By the change of measure theorem, the restrictions of µ0,x and µua,x to Ft are
mutually absolutely continuous for all t > 0. The desired conclusion follows from
Assumption 4.1.

Proof. By Assumption 3.1, we may apply Corollary 3.5 to assert that E((M ua

Corollary 4.3. Given an arbitrary a(0) ∈ Rn and compact neighbourhood N

of a(0), it holds that

(4.5)

mx(N ) := min
a∈N

min
1≤i≤n

Eua,x [hM ϕiiτ ] > 0.

Proof. By the representation (4.2), the distribution µua,x depends continuously
on a. Therefore the map a 7→ mini Eua,x[hM ϕiiτ ] is continuous. By Proposition 4.2,
the map is strictly positive for every a ∈ Rn. The conclusion follows by compactness.
Now consider the restriction to UMarkov(b) of the stochastic optimal control prob-

lem deﬁned in (2.14),

(4.6)

subject to (2.1) .

min

a∈Rn bφσ,x(a)

The restricted problem diﬀers from the original stochastic optimal control problem
(2.14) only in the function space over which the control functional is to be minimised.
The gradient descent algorithm proposed in [13] for solving the restricted problem
above consisted of the following steps: Given UMarkov(b), an initial condition a(0),
Niter, Ntraj ∈ N, and a sequence of descent steps (hℓ)0≤ℓ≤Niter−1 ⊂ (0,∞), we have:

for ℓ = 1 : Niter do

– Sample Ntraj trajectories of (2.1) with u = ua(i−1)

– Approximate bφσ,x(a(ℓ − 1)) and ∇abφσ,x(a(ℓ − 1)) by Monte Carlo

– Update the coeﬃcient vector a(ℓ − 1) to a(ℓ) via

(4.7)

end

a(ℓ) = a(ℓ − 1) − hℓ−1∇abφσ,x(a(ℓ − 1))

That is, the gradient descent algorithm (4.7) is the discrete time, ﬁnite-sample size
analogue of the initial value problem (4.4). We shall study the well-posedness of

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

19

the gradient descent algorithm via (4.4). The following result shows that, under
Assumptions 3.1 and 4.1, the restricted problem (4.6) is well-posed.

Theorem 4.4. Suppose that the hypotheses of Theorem 3.13 are satisﬁed.

If

(3.29) holds, then there exists a unique a∞ ∈ Rn such that
(4.8)
and for every initial condition a(0) ∈ Rn, there exists a unique solution (a(t))0≤t<∞
of the initial value problem (4.4) to a∞. If, in addition to the above hypotheses, it
holds that

0 = ∇abφσ,x(a∞),

(4.9)

Si ∩ Sj = ∂Si ∩ ∂Sj,

then the unique solution converges exponentially to a∞, with
(4.10)

|a∞ − a(t)|2 ≤ |a(0) − a∞|2 exp(−tγmx(N )),

where mx(N ) is deﬁned in (4.5).

Proof. Since the hypotheses of Theorem 3.13 hold, and since (3.29) holds, it
follows that the control functional φσ,x is strictly convex on C1,α(Ω; Rd), by Theorem

3.14. This implies that the function bφσ,x is twice continuously diﬀerentiable and

strictly convex on any bounded, open, nonempty convex subset of Rn, so there exists
a unique global minimiser that satisﬁes (4.8). By the standard results on existence
and uniqueness of solutions to ordinary diﬀerential equations, it follows that for any
initial condition a(0), there exists a unique solution (a(t))t≥0 that exists for all time.
By Theorem 3.13, (3.27), and linearity of the representation ua, it holds that,
given the Hessian ∇2
z · ∇2
By (3.30), the value of z ·∇2
at ua′

abφσ,x : Rn → Rn×n, arbitrary a′ ∈ Rn and 0 6= z ∈ Rn,
τ (cid:17)i .
,xhK σ,ua
iτ M uz
abφσ,x(a′)z equals the value of the second variation of φσ,x
abφσ,x(a′)z ≥ γEua′
z · ∇2

By the chain rule, Taylor’s theorem and the property (4.8), there is a z ∈ Rn that is
a convex combination of a(s) and a∞ such that

τ )2 + σ−1(cid:16)hM uz

abφσ,x(a′)z = Eua

,xhhM uz

iτi .

along the element uz. By Corollary 3.15,

iτ + 2hM ua

′

, M uz

′

,0(M uz

(4.11)

′

d
dt

1
2|a(s) − a∞|2 ≤ −
≤ −

1
2
1
2

(4.12)

(a∞ − a(s)) · ∇2
γEuz,xhhM ua∞ −a(s)

iτi .

abφσ,x(z)(a∞ − a(s))

Observe that by Assumption 3.1, µua,x is unique, and therefore X ua
has the strong
Markov property. Under the condition (4.9) on the supports, it holds that ϕi(x)·ϕj (x)
is zero except on a set of zero Lebesgue measure, and therefore hM ϕi, M ϕjiτ has
vanishing µua,x-expectation. Let N be the smallest compact set that contains all
convex combinations of a(t) and a∞ for all t ≥ 0. It follows from the vanishing of the
covariance processes that φσ,x is strongly convex on N , since

Euz ,xhhM ua∞ −a(s)

iτi ≥ mx(N )|a∞ − a(s)|2.

Substituting the above inequality in (4.12), integrating the resulting diﬀerential in-
equality, and applying Gronwall’s lemma, we obtain (4.10).

20

H. C. LIE

4.2. Approximation of solution to the HJB equation. In this section,

we relate the unique minimiser of the restricted control functional bφσ,x to the best
approximation in the ﬁnite-dimensional subspace UMarkov(b) of F (σ,·). Recall that, by
Theorem 2.2, the function ψ(σ,·) for ψ deﬁned in (2.9a) belongs to the space C2,α(Ω).
Since ψ(σ,·) = exp(−σF (σ,·)), this implies that F (σ,·) ∈ C2,α(Ω), and since Ω is
compact, this implies that F (σ,·) ∈ L2(Ω; R). In fact, by the same reasoning, F (σ,·)
is an element of the Sobolev space H 2,p(Ω) for 1 ≤ p < ∞. The unique equilibrium a∞
deﬁned in (4.8) gives the best approximation in the space UMarkov(b) of the optimal
control uσ
opt. Therefore, the unique equilibrium a∞ gives the best approximation of
∇xF (σ,·), up to scaling. Since we have assumed Ω to be a connected, bounded domain
with C2,α-boundary, we may apply the Poincar´e inequality as follows: deﬁne

where the additive constant in the parentheses on the right-hand side ensures that

1

Ferr(σ, x)dx.

Fapprox(σ, x′) :=Xi

(a∞)ibi(x)! ,
Fapprox(σ, x) = bφσ,x(a∞). Deﬁne Ferr and the average value (Ferr)Ω by
Then since Ferr(σ,·) ∈ W 1,p(Ω), the Poincar´e inequality yields the estimate
(4.13)

(a∞)ibi(x′) + bφσ,x(a∞) −Xi
vol(Ω)ZΩ

Ferr(σ, x) := F (σ, x) − Fapprox(σ, x), (Ferr)Ω :=

kFerr(σ,·) − (Ferr)ΩkLp(Ω) ≤ C(n, p, Ω)k∇xFerr(σ,·)kLp(Ω)

for 1 ≤ p < ∞ and C(n, p, Ω) independent of Ferr(σ,·). The estimate emphasises the
importance of the approximation quality of the subspace UMarkov(b): as the approxi-
mation quality of UMarkov(b) improves, the right-hand side of (4.13) decreases, giving
smaller Lp-errors in the approximation of F (σ,·).

5. Conclusion. In this article, we proved that the control functional of a stochas-
tic optimal control problem is strictly convex, under the conditions that guarantee
the existence and uniqueness of a value function that is uniformly H¨older continuous
on the closure of a bounded, C2,α domain. Our results relied on applying Fredholm
theory in order to show that the moment generating function of the ﬁrst exit time
with respect to the law µu,x for feedback controls u ∈ L∞(Ω) is ﬁnite on any bounded
open interval containing the origin. From this result, we obtained the L2-boundedness
of the exponential martingale associated to the feedback control. We then used L2-
boundedness to derive an expression for the second variation of the control functional.
Positive deﬁniteness then followed from a speciﬁc lower bound on the terminal cost
function. The result of strict convexity holds independently of the dimension d of the
domain. The signiﬁcance of this result is that one may solve the Hamilton-Jacobi-
Bellman boundary value problem, and thereby the rare event importance sampling
problem, by using methods for convex optimisation in conjunction with Monte Carlo
methods. The advantage of doing so is that both classes of methods scale well with
dimension.

Acknowledgments. The author thanks Christof Sch¨utte, Carsten Hartmann,
and Tim Sullivan from the Freie Universit¨at Berlin for their encouragement and sup-
port of the thesis on which this article is based, Patrick J. Fitzsimmons from the
University of California at San Diego for pointing out Kazamaki’s book [17], and
Giacomo di Ges`u from CERMICS - ´Ecole des Ponts ParisTech for pointing out an
important subtlety concerning the mutual absolute continuity of path measures.

CONVEXITY OF A STOCHASTIC CONTROL FUNCTIONAL

21

REFERENCES

[1] R. J. Allen, D. Frenkel, and P. R. ten Wolde, Simulating rare events in equilibrium or

nonequilibrium stochastic systems, J. Chem. Phys., 124 (2006).

[2] S. Asmussen, D. P. Kroese, and R. Y. Rubinstein, Heavy tails, importance sampling and

cross-entropy, Stochastic Models, 21 (2005), pp. 57–76.

[3] V. S. Borkar, A convex analytic approach to markov decision processes, 78 (1988), pp. 583–

602.

[4] P. dai Pra, L. Meneghini, and W. J. Runggaldier, Connections between stochastic control

and dynamic games, Math. Control Signals Syst., 9 (1996), pp. 303–326.

[5] E. Darve, D. Rodriguez-Gomez, and A. Pohorille, Adaptive biasing force method for scalar

and vector free energy calculations, J. Chem. Phys., 128 (2008).

[6] C. Dellago, P. G. Bolhuis, F. S. Csajka, and D. Chandler, Transition path sampling and

the calculation of rate constants, J. Chem. Phys., 108 (1998), pp. 1964–1977.

[7] P. Dupuis and W. M. McEneaney, Risk-sensitive and robust escape criteria, SIAM J. Control

Optim., 35 (1997), pp. 2021–2049.

[8] P. Dupuis, K. Spiliopoulos, and H. Wang, Importance sampling for multiscale diﬀusions,

Multiscale Model. Simul., 10 (2012), pp. 1–27.

[9] P. Dupuis and H. Wang, Importance sampling, large deviations, and diﬀerential games,

Stochastics Stochastics Rep., 76 (2004), pp. 481–508.

[10]

, Dynamic importance sampling for uniformly recurrent markov chains, Ann. Appl.

Probab., 15 (2005), pp. 1–38.

[11] D. Gilbarg and N. S. Trudinger, Elliptic Partial Diﬀerential Equations of Second Order,
Grundlehren der mathematischen Wissenschaften, Springer, Berlin, 2001. (Reprint of the
1998 edition).

[12] C. Hartmann, R. Banisch, M. Sarich, T. Badowski, and C. Sch¨utte, Characterization of

rare events in molecular dynamics, Entropy, 16 (2013), pp. 350–376.

[13] C. Hartmann and C. Sch¨utte, Eﬃcient rare event simulation by optimal nonequilibrium

forcing, J. Stat. Mech. Theor. Exp., 2012 (2012), p. P11004.

[14] C. Jarzynski, Nonequilibrium equality for free energy diﬀerences, Phys. Rev. Lett., 78 (1997),

pp. 2690–2693.

[15]

, Rare events and the convergence of exponentially averaged work values, Phys. Rev. E,

73 (2006), p. 046105.

[16] I. Karatzas and S. E. Shreve, Brownian Motion and Stochastic Calculus, Springer, Berlin,

1991.

[17] N. Kazamaki, Continuous Exponential Martingales and BMO, Lecture Notes in Mathematics,

Springer-Verlag, Berlin, 1994.

[18] S. Kullback, Information Theory and Statistics, Wiley, New York, 1959.
[19] A. Laio and M. Parrinello, Escaping free-energy minima, Proc. Natl. Acad. Sci. U.S.A., 99

(2002), pp. 12562–12566.

[20] T. Leli`evre, M. Rousset, and G. Stoltz, Free Energy Computations: A Mathematical

Perspective, Imperial College Press, London, 2010.

[21] E. J. McShane, Jensen’s inequality, Bull. Amer. Math. Soc., 43 (1937), pp. 521–527.
[22] D. Passerone and M. Parrinello, Action-derived molecular dynamics in the study of rare

events, Phys. Rev. Lett., 87 (2001), p. 108302.

[23] D. Revuz and M. Yor, Continuous Martingales and Brownian Motion, Grundlehren der
mathematischen Wissenschaften, Springer, Berlin, 2005. Corrected third printing of third
edition.

[24] R. Y. Rubinstein, Optimization of computer simulation models with rare events, Eur. J. Oper.

Res., 99 (1997), pp. 89 – 112.

[25] E. Vanden-Eijnden and J. Weare, Rare event simulation of small noise diﬀusions, Comm.

Pure Appl. Math., 65 (2012), pp. 1770–1803.

[26] A. F. Voter, Hyperdynamics: Accelerated molecular dynamics of infrequent events, Phys. Rev.

Lett., 78 (1997), pp. 3908–3911.

[27]

, A method for accelerating the molecular dynamics simulation of infrequent events, J.

Chem. Phys., 106 (1997), pp. 4665–4677.

[28] E. Zeidler, Applied Functional Analysis: Main Principles and Their Applications, vol. 109 of

Applied Mathematical Sciences, Springer-Verlag, Berlin, 1995.

[29] W. Zhang, H. Wang, C. Hartmann, M. Weber, and C. Sch¨utte, Applications of the cross-
entropy method to importance sampling and optimal control of diﬀusions, SIAM J. Sci.
Comput., 36 (2014), pp. A2654–A2672.

