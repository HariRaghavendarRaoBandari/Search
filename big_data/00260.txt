Event Search and Analytics

Detecting Events in Semantically Annotated Corpora for Search & Analytics

Max Planck Institute for Informatics, Saarbrücken, Germany

Saarbrücken Graduate School of Computer Science, Saarbrücken, Germany

Dhruv Gupta

dhgupta@mpi-inf.mpg.de

6
1
0
2

 
r
a

M
1

 

 
 
]

R

I
.
s
c
[
 
 

1
v
0
6
2
0
0

.

3
0
6
1
:
v
i
X
r
a

ABSTRACT
In this article, I present the questions that I seek to answer
in my PhD research.
I posit to analyze natural language
text with the help of semantic annotations and mine im-
portant events for navigating large text corpora. Semantic
annotations such as named entities, geographic locations,
and temporal expressions can help us mine events from the
given corpora. These events thus provide us with useful
means to discover the locked knowledge in them.
I pose
three problems that can help unlock this knowledge vault in
semantically annotated text corpora: i. identifying impor-
tant events; ii. semantic search; and iii. event analytics.

Keywords
Information Retrieval; Text Analytics; Text Summarization;
Semantic Annotations; Diversity & Novelty; Semantic Search

1.

INTRODUCTION

Information retrieval systems have largely relied on word
statistics in text corpora to satisfy information needs of users
by retrieving documents with high relevance for a given key-
word query. In my PhD research I hypothesize that infor-
mation needs of users can be satisﬁed to a greater extent by
using events as a means of navigating text corpora. Events
in our context would be an act performed by certain ac-
tor(s) at a speciﬁc location during a speciﬁc time interval.
An example would be : Usain Bolt won the gold medal at the
2008 summer Olympics in Bejing. With the availability of
annotators that can provide us with accurate semantic anno-
tations in form of named entities, geographic locations, and
temporal expressions; we can leverage the growing number
of knowledge resources such as Wikipedia [37] and ontologies
such as Freebase [12] to understand natural language text
and mine important events. Formally the central hypothesis
can be stated as follows:

Central Hypothesis Given text corpora with seman-
tic annotations; traditional information retrieval mod-
els can be improved by utilizing knowledge about events
and using events as proxies for information need.

As a toy example consider the following text snippet 1

with demonstrative semantic annotations in Figure 1 :

. . . Beijing(cid:104)W iki : Beijing(cid:105)(cid:104)Geo : (39.55, 116.23)(cid:105) where
Bolt (cid:104)W iki : U sain Bolt(cid:105) announced himself to the world
with two Olympic golds and two world records in
2008(cid:104)T ime : [01 − 01 − 2008, 31 − 12 − 2008](cid:105) . . .

Figure 1: Semantically annotated text 1 snippet

In the text snippet (Figure 1), we obtain the named en-
tity Usain Bolt whose mention has been identiﬁed and dis-
ambiguated to point to an external knowledge source. Also
identiﬁed is a geographical location - Beijing, which is disam-
biguated and resolved to its geographical coordinates. Like-
wise the temporal expression 2008 has also been resolved to
time range. Having these semantic annotations we can now
devise algorithms that can deduce that the event is that of
Usain Bolt winning Olympic competition in Beijing, China.
The goal of the proposed research is to leverage the seman-
tic annotations for mining important events and use them
to navigate text corpora. The research will ﬁnd application
in many domains of research such as digital humanities, in
which social scientists are interested in computational his-
tory in large digital-born text collections. Anthropologists
are interested in cultural and linguistic shifts that occur in
such collections. Collectively we can allow computational
culturomics [24] on corpora to study cultural trends. Events
can also be used to link information in multiple and diverse
text collections. In short, important events provide a way
to create a gist from semantically annotated corpora, which
otherwise is not possible through manual human eﬀort.

Outline. The article consists of:
• a literature survey (Section 2);
• an overview of the research problems (Section 3);
• available corpora, test sources and evaluation measures

for research (Section 5);

• discussion of few open technical problems (Section 6).

1

http://www.bbc.com/sport/0/athletics/34032366

2. RELATED WORK

In this section I discuss the progress already made in the
area of analyzing diﬀerent semantic annotations in isolation
as well as in conjunction for some of the problems proposed.
Temporal Information Retrieval and Extraction.
Researchers have considered only temporal annotations in
text corpora to improve retrieval eﬀectiveness by analyzing
the time sensitivity of keyword queries and incorporating
the time dimension in retrieval models. Some methods of
analysis of time-sensitive queries rely on publication dates
of documents [21, 22], while others also look at the tempo-
ral expressions in document contents [15]. Several works also
take into account the time dimension for re-ranking docu-
ments [10] and diversifying them along time [11, 25]. One of
the seminal works in extracting temporal events was by Ling
and Weld [23]. They outline a probabilistic model to solve
the problem of extracting relations from text with temporal
constraints.

Important Events in Annotated Corpora. One of
the most important seminal works in identifying existing
and emerging events were the various tasks in Topic Detec-
tion and Tracking (TDT) [7]. The TDT program aimed to
“search, organize and structure” broadcast news media from
multiple sources. The ﬁve tasks laid within the ambit of
TDT where topic tracking, link detection, topic detection,
ﬁrst story detection, and story segmentation. The task of
topic tracking required to build a system to detect on topic
stories from an evaluation corpus after being trained on a
set on topic stories. The link detection task involved an-
swering a boolean query to whether two given stories are
related by a common topic. The topic detection task com-
prised of declaring new topics from incoming stories which
had not been presented to the system. First story detection
was another boolean decision task of determining whether
the given story is a seed story (ﬁrst-story) to create a new
topic cluster. Story segmentation task required segmenta-
tion of an incoming stream of text into stories.

Focusing speciﬁcally on extracting and summarizing events
in the future, Jatowt and Yeung [20] present a model-based
clustering algorithm. The clustering considers both textual
and temporal similarities. For computing temporal similar-
ity, the authors model time as a probability distribution by
utilizing diﬀerent family of distributions based on whether
its is singular time point, starting date or and ending date.
The similarity is then computed using KL-divergence.

Radinsky et al. [26] present an algorithm Pundit, which
based on the past events in text is able to predict a fu-
ture event given a query to the system. The events are
represented as multidimensional attributes such as time, ge-
ographic location and participating entities. The algorithm
derives these events from external text collection and builds
an abstraction tree, which is the result from hierarchical ag-
glomerative clustering. In order to predict the future Pundit
is trained to select the most similar cluster from the abstrac-
tion tree and produce an event representation.

The work by Yeung and Jatowt [38] tackles the problem
of analysis of historical events in multiple large document
collections. They utilize latent Dirichlet allocation to iden-
tify topic distributions along time. Thereafter they perform
analytics to answer questions such as i. signiﬁcant years and
topics, ii. triggers that caused remembrance of the past and
iii. historical similarity of countries.

Most recently, Abujabal and Berberich [5] present a sys-
tem which identiﬁes important events in text collections by
counting frequent itemsets of sentences containing named
entities and temporal expressions. For evaluation they re-
sort to Wikipedia’s event directory as a ground truth.

Semantic Search. Summarizing text collections in a
timeline visualization is a natural choice. Swan and Al-
lan [31] present an approach for producing a timeline that
depicts most important topics and events closely modeled
on the Topic Detection and Tracking task. The algorithms
analyzes features based on named entities and noun phrases.
The analysis involves construction of 2 × 2 contingency ta-
ble on presence or absence of features, and subsequent mea-
surement of χ2 statistic for measuring signiﬁcance of co-
occurrence of a pair of features.

The seminal work by Baeza-Yates [8] proposed a future re-
trieval (FR) system. The FR system considers both text and
temporal expressions to identify future events that might be
relevant to an input query. Baeza-Yates outlined the com-
ponents of a FR system to be composed of an information
extraction (IE) module, information retrieval (IR) module,
and a text mining (TM) module. The IE module would act
as a temporal annotator; identify temporal expressions and
normalize them. The IR system is designed to incorporate
the time dimension in an index; thus retrieving documents
with text and time similarity. The TM module would iden-
tify the most relevant topics given a time period. He pre-
sented a retrieval model, in which each document consists
of a multiple temporal events. A temporal event consists of
a time segment and its associated likelihood of occurring.
The score of the document is thus obtained by its textual
similarity and the maximum likelihood of all the temporal
events in that document.

Bast and Buchhold [9] outline a joint index structure over
ontologies and text. Which allows for fast semantic search
and provide context sensitive auto-complete suggestions.

Events as a means of search document collections has also
been explored by Str¨otgen and Gertz [28]. Events were
modeled by the geographic location and time of their oc-
currence. For temporal queries expressed in simple natu-
ral language they outline an extended Backus-Naur form
(EBNF) language that incorporates time intervals with stan-
dard boolean operations. Geographical queries are also mod-
eled as EBNF language, however the input for them is a
minimum bounding rectangle (MBR). Using this multidi-
mensional querying model the user is able to visualize search
results in form of events; which are additionally represented
on a map.

Giving special attention to geographical information re-
trieval, Samet et al. [27] present a system NewsStand, that
is able to resolve and pinpoint a news article based on the
geographic information present in its content. They discuss
various methods for toponymn resolution, which is in essence
disambiguating the geographic location based on its surface
form in the news content. The system involves a streaming
clustering algorithm that can keep track of emerging news
in new locations and present them in a map-based interface.
Event Analytics. By disambiguating and linking named
entities to ontologies, Hoﬀart et al. [17, 18] provide a frame-
work for semantic search and performing analytics on them.
They provide features for giving auto-complete suggestions
in the form of similar entities for the input named-entity.
In [17] they provide analytics that leverage accurate entity

Query:

summer olympics

Event

Words

c1

c2

c3

micheal, phelps, bejing, china,
tibet
[08− 08− 2008, 24− 08− 2008]
(cid:104)China(cid:105), (cid:104)M icheal P helps(cid:105)

Time
Location (cid:104)Beijing, China(cid:105)
Entities

london, usain, bolt, england,
badminton
[27− 07− 2012, 12− 08− 2012]
(cid:104)London, England(cid:105)
(cid:104)England(cid:105), (cid:104)Badminton(cid:105)

brazil,copacabana,

rio,
de-
odoro, maracan˜a
[05− 08− 2016, 21− 08− 2016]
(cid:104)RiodeJaneiro, Brazil(cid:105)
(cid:104)Brazil(cid:105), (cid:104)Copacabana(cid:105)

Figure 2: Example important events for an example query summer olympics

counts and provide entity co-occurrence statistics which is
helpful in analyzing semantically similar named-entities.

3. RESEARCH OBJECTIVES

Given the text corpora with semantic annotations, I de-
scribe three important research problems in this section: i.
identifying important events; ii. using identiﬁed events for
improving retrieval eﬀectiveness; and iii. using identiﬁed
events for analytics.
3.1 Notation

Let us consider multiple corpora for the purpose of anal-
ysis. This allows us to capture frequently occurring events
as well as link similar events across corpus. Given corpora

D =

Dk,

N(cid:91)

k=1

n(cid:91)

d =

xi.

where each document d ∈ D consists of word sequence x at
appropriate granularity (e.g. paragraph or sentence):

i=1

Further each x ∈ d contains semantic annotations in form
of i. named entities (e), ii. geographical location (g), and
iii. temporal expressions (t). Additionally x also consists of
the a bag of words W drawn from a vocabulary V. Formally
represented as:

x = (cid:104)E, g, t,W(cid:105)

3.2 Problem Deﬁnition

The objective is to design a family of algorithms:

where X =(cid:83) x, Q represents an input query and α ∈ Rm,

Event*(X, Q, α)

where α is set of parameters.

The input query Q can be a combination of following in-
time qtime, iii.

put components:
geographical location qgeo, and iv. named entity qentity.

i. keyword query q, ii.

Given the input, we need to design the algorithms Event*
according to the diﬀerent problems. We discuss the design
objectives for the three diﬀerent purposes in this section.

Identifying Important Events. Events are the pro-
posed building blocks for further text analysis. An event in
our context is deﬁned to be an activity or an act involving
named entities that happens in a speciﬁc geographical loca-
tion anchored to a speciﬁc time interval. Mathematically,
given a multidimensional query :

Q = (cid:104)q, qtime, qgeo, gentity(cid:105),

and a subset of highly relevant documents R ⊆ D, the algo-
rithm for this purpose EventDetect should produce a set
of ordered events :

C = {c1, c2, . . . , ck},

where, c = (cid:104)E, g, t,W(cid:105). The event c is hence described by
the participating named entities E, its location g, its time
of occurrence t, and frequently occurring contextual terms
around these semantic annotations W. This requires propos-
ing a probability mass function, P (C, R), using which we can
impose a total order on C.

As an example consider the keyword-only query summer
olympics to the processed corpora of news articles. The
designed algorithm shall then identify the important events
as in Figure 2.

Diversifying and Summarizing Search Results are
retrieval tasks that try to address the information need un-
derlying an ambiguous query at diﬀerent levels of textual
granularity. Each task tries to maximize the coverage of
diﬀerent information needs underlying the given ambiguous
query. As information intents, we propose to use the mined
set of events. Accomplishing these tasks would allow for
automatic creation of event timelines or entity biographies.
We brieﬂy discuss an intuition of achieving the same.

When diversifying search results we would like to present
users with documents such that the user ﬁnds at least one
document that satisﬁes her information intent. For this we
need to devise an algorithm EventDiverse which considers
as an input Q and R ⊆ D. As an output it returns a set of
documents S ⊂ R which cover all events in C.

Summarizing search results would require us to construct
an algorithm EventSummary to piece together, sentences

ˆS =(cid:83) x, such that the text summary covers all events in C.

Semantic Search and Analytics. The mined set of
events can further be utilized for search and analytics. For
this purpose we can utilize inherent hierarchy in the se-
mantic annotations. For example a given year 2015 can be
broken down to diﬀerent months and subsequently days in
those months. Similarly, we can utilize the type hierarchies
in named entities. Such as Usain Bolt and Justin Gatlin are
subtypes of Athletes. This can jointly be modeled by using
the concept of a data cube [16] as shown in Figure 3.

Formally, given a query Q, the objective would to ﬁrst
model the mined set of events as a data cube and subse-
quently provide data cube operations [16]:

• roll ((cid:13)),
• slice ((cid:9)),
• dice (⊕),
• drill up ((cid:52)),
• drill down ((cid:53)).

Temporal Expressions, both implicit and explicit, can
be extracted and normalized from text by using temporal
taggers such as HeidelTime [29] or SUTime [13].

5. EVALUATION

To test our approach we need to construct query sets
that contain an event description associated with the query;
along with participating named entities, geographical loca-
tions where the event took place and relevant time interval
associated with it. I describe a tentative approach to achieve
this here.

Test Data. To evaluate the correctness of the various
algorithms, I plan to use reliable encyclopedic resources on
the Web such as Wikipedia [37] or other curated knowledge
sources. For an objective evaluation, I propose the following
diﬀerent sources depending on the algorithm under evalua-
tion.

• Identify important events

– Events in a particular year/decade etc. pages

available on Wikipedia [33].

– Testing of past events can be done by extracting
important topics from Category pages on various
historical topics on Wikipedia [35].

– Events in the future can be evaluated by using im-

portant infrastructure projects, engineering projects
etc. These can be extracted from Wikipedia and
other sources on the Internet.

– Current events extracted from Wikipedia [36].

– Alternatively, we can manually construct a list of
prominent events and extract relevant informa-
tion such as named entities, geographical location,
and time from ontologies such as: YAGO [30],
Freebase [12], etc.

• Diversifying and summarizing search events

– Biographies of eminent personalities, for example

United States presidents [32].

– Historical timelines of various countries, for ex-

ample for India [34].

Structure. Each event in our test bed is then composed
of a fact with an accompanying query. Formally, a fact in our
testbed is a 4-tuple extracted from one of the aforementioned
sources:

(cid:104)q,E, g, t,W(cid:105)

where q consists of keyword query describing the event, E
is a bag of participating entities, g is the geographic location,
t is the time of its occurrence, and W are important terms
describing the event.

Metrics. Based on the structure of the testbed of events,
metrics such as precision, recall and F1 can be utilized to
measure the eﬀectiveness of the algorithms for detecting im-
portant events in semantically annotated corpora. How ef-
fectively the algorithm diversiﬁes documents along multiple
dimensions can be evaluated by metrics such as α-nDCG [6].
Quality of summaries can be measured by an automatic eval-
uation metric called Rouge [39].

Figure 3: Example data cube based on set of events C

Figure 4: Example data cube operations for the query all
races won during 2008 by usain bolt in china

As a concrete example consider the query all races won
during 2008 by usain bolt in china. To produce an ap-
propriate result the sequence of operations would be: ﬁrst
a slice on the entity Usain Bolt; second dice on China; and
ﬁnally drill up to year 2008 (see Figure 4).

4. DATA

Corpora. There are several readily available massive
data sets. They are available from news corporation such as
the New York Times [4], English Gigaword [3]. These cor-
pora have the beneﬁt of being available with reliable publi-
cation dates and grammatically well-formed text. On larger
scale are Web collections such as ClueWeb’09 [1]/’12 [2],
which are not always accompanied by reliable creation dates
and many are ill-formed documents.

Semantic Annotations. The text corpora next need to
be annotated for text mining. I explain how to obtain the
diﬀerent semantic annotations in the following paragraphs.
Named Entities. For disambiguating and linking named
entities in text to an external knowledge source such as
Wikipedia [37] or an ontology such as YAGO [30] or Free-
base [12]; I use the AIDA system [19]. The AIDA system
does named entity disambiguation and linking by leveraging
contexts extracted from ontologies such as YAGO. For Web
collections such ClueWeb’09/’12 the entity disambiguation
and linking has been released as facc1 : Freebase annotation
of ClueWeb Corpora [14].

Geographical Locations can be obtained by utilizing
geographic named entities such as those known to be cities,
countries, or continents. Geographical relations stored in an
ontology can be used to resolve these locations to its geo-
graphical coordinates. Having obtained a set of coordinates,
we can subsequently construct a geographical representation
such as a minimum bounding rectangle over the coordinates.

6. DISCUSSION

I brieﬂy present some open technical challenges that I will
address along with the research objectives in my PhD dis-
sertation.

Mathematical Models. One key aspect that occurs in
the design of the algorithms is that of computational mod-
els for named entities, geographical locations and temporal
expressions. What would be the most descriptive mathe-
matical models for each of these semantic annotations?

Similarity Functions. Given a pair of named entities,
geographical locations or temporal expressions; how can we
eﬃciently compute the similarity between the same type of
annotations?

Eﬃciency & Scalability.

Identifying data structures
for indexing corpora along with their semantic annotations,
such that their asymptotic run times scale linearly with the
size of the corpora.

Evaluation. Since evaluation of the solutions outlined
are very subjective in nature; what are other reliable sources
of objective ground truth ? What other metrics can be em-
ployed to test the eﬀectiveness of our methods ?

7. CONCLUSION

In this article I laid out an outline of the research work
that I envisage to carry out for my PhD dissertation. The re-
search would in its culmination provide us methods to com-
putationally extract world history as sequence of temporally
ordered events and portray future events to take place from
semantically annotated corpora. The research would also
provide ways to perform semantic search and large scale
event analytics on these annotated corpora.
I further de-
scribed already available resources that can be utilized for
carrying out the research; test cases that can be built from
encyclopedic resources on the Internet; and the metrics that
can be utilized for evaluation.

8. REFERENCES

[1] Clueweb’09. [Online; accessed 26-August-2015]

http://www.lemurproject.org/clueweb09.php/.

[2] Clueweb’12. [Online; accessed 26-August-2015]

http://www.lemurproject.org/clueweb12.php/.

[3] English gigaword. [Online; accessed 26-August-2015]

https://catalog.ldc.upenn.edu/LDC2003T05.

[4] New york times anotated corpus. [Online; accessed

26-August-2015]
https://catalog.ldc.upenn.edu/LDC2008T19.

[5] Abujabal A. and Berberich K. Important events in the

past, present, and future. WWW’15 Companion Volume.
[6] Agrawal R. et al. Diversifying search results. WSDM’09.
[7] Allan J., editor. Topic Detection and Tracking:

Event-based Information Organization. Kluwer Academic
Publishers, Norwell, MA, USA, 2002.

[8] Baeza-Yates R. Searching the future. SIGIR’05 Workshop

MF/IR.

[9] Bast H. and Buchhold B. An index for eﬃcient semantic

full-text search. CIKM’13.

[13] Chang A. X. and Manning C. D. SUTIME: A library for
recognizing and normalizing time expressions. LREC’12.

[14] Ringgaard M. et al. Facc1: Freebase annotation of clueweb
corpora, version 1 (release date 2013-06-26, format version
1, correction level 0), June 2013.
http://lemurproject.org/clueweb12/.

[15] Gupta D. and Berberich K. Temporal query classiﬁcation

at diﬀerent granularities. SPIRE’15.

[16] Han J. et al. Data Mining: Concepts and Techniques.

Morgan Kaufmann Publishers Inc., San Francisco, CA,
USA, 3rd edition, 2011.

[17] Hoﬀart J. et al. AESTHETICS: analytics with strings,

things, and cats. CIKM’14.

[18] Hoﬀart J. et al. STICS: searching with strings, things, and

cats. SIGIR’14.

[19] Hoﬀart J. et al. Robust disambiguation of named entities in

text. EMNLP’11.

[20] Jatowt A. and Yeung C. A. Extracting collective

expectations about the future from large text collections.
CIKM’11.

[21] Jones R. and Diaz F. Temporal proﬁles of queries. ACM

Trans. Inf. Syst., 25(3), July 2007.

[22] Kanhabua N. and Nørv˚ag K. Determining time of queries

for re-ranking search results. ECDL’10.

[23] Ling X. and Weld D. S. Temporal information extraction.

AAAI’10.

[24] Michel J. B. et al. Quantitative analysis of culture using

millions of digitized books. Science’10.

[25] Nguyen T. N. and Kanhabua N. Leveraging dynamic query

subtopics for time-aware search result diversiﬁcation.
ECIR’14.

[26] Radinsky K. et al. Learning to predict from textual data. J.

Artif. Intell. Res. (JAIR), 45:641–684, 2012.

[27] Samet H. et al. Reading news with maps by exploiting
spatial synonyms. Commun. ACM, 57(10):64–77, 2014.

[28] Str¨otgen J. and Gertz M. Event-centric search and

exploration in document collections. JCDL’12.

[29] Str¨otgen J. and Gertz M. Multilingual and cross-domain

temporal tagging. Language Resources and Evaluation,
47(2):269–298, 2013.

[30] Suchanek F. M. et al. Yago: A large ontology from

wikipedia and wordnet. Web Semant., 6(3):203–217,
September 2008.

[31] Swan R. C. and Allan J. Automatic generation of overview

timelines. SIGIR’00.

[32] Wikipedia. List of presidents of the united states —

Wikipedia, the free encyclopedia, 2015. [Online; accessed
26-August-2015]https://en.wikipedia.org/wiki/List_of_
Presidents_of_the_United_States.

[33] Wikipedia. List of years — Wikipedia, the free

encyclopedia, 2015. [Online; accessed 26-August-
2015]https://en.wikipedia.org/wiki/List_of_years.
[34] Wikipedia. List of years in india — Wikipedia, the free

encyclopedia, 2015. [Online; accessed 26-August-2015]
https:
//en.wikipedia.org/wiki/List_of_years_in_India.

[35] Wikipedia. Portal:contents/history and events —

Wikipedia, the free encyclopedia, 2015. [Online; accessed
26-August-2015]https://en.wikipedia.org/wiki/Portal:
Contents/History_and_events.

[36] Wikipedia. Portal:current events — Wikipedia, the free

encyclopedia, 2015. [Online; accessed
26-August-2015]https://en.wikipedia.org/wiki/Portal:
Contents/History_and_events.

[10] Berberich K. et al. A language modeling approach for

[37] Wikipedia. Wikipedia, the free encyclopedia, 2015. [Online;

temporal information needs. ECIR’10.

[11] Berberich K. and Bedathur S. Temporal diversiﬁcation of

search results. TAIA’13.

[12] Bollacker K. et al. Freebase: A collaboratively created

graph database for structuring human knowledge.
SIGMOD’08.

accessed 26-August-2015]http://en.wikipedia.org/.
[38] Yeung C. A. and Jatowt A. Studying how the past is

remembered: towards computational history through large
scale text mining. CIKM’11.

[39] Lin C. Y. Rouge: a package for automatic evaluation of

summaries. ACL-04 workshop.

