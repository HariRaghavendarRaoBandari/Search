6
1
0
2

 
r
a

 

M
7
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
2
9
6
5
0

.

3
0
6
1
:
v
i
X
r
a

Optimal Energy-Efﬁcient Downlink Transmission

Scheduling for Real-Time Wireless Networks

Lei Miao, Jianfeng Mao, and Christos G. Cassandras, Fellow, IEEE

1

Abstract—It has been shown that using appropriate channel
coding schemes in wireless environments, transmission energy
can be signiﬁcantly reduced by controlling the packet trans-
mission rate. This paper seeks optimal solutions for downlink
transmission control problems, motivated by this observation
and by the need to minimize energy consumption in real-time
wireless networks. Our problem formulation deals with a more
general setting than the paper authored by Gamal et. al., in
which the MoveRight algorithm is proposed. The MoveRight
algorithm is an iterative algorithm that converges to the optimal
solution. We show that even under the more general setting, the
optimal solution can be efﬁciently obtained through an approach
decomposing the optimal sample path through certain “critical
tasks” which in turn can be efﬁciently identiﬁed. We include
simulation results showing that our algorithm is signiﬁcantly
faster than the MoveRight algorithm. We also discuss how to
utilize our results and receding horizon control to perform on-
line transmission scheduling where future task information is
unknown.

Index Terms—optimization, wireless

networks,
efﬁciency, real-time systems, receding horizon control.

energy-

I. INTRODUCTION

Because wireless nodes are normally powered by batteries
and are expected to remain in operation for extended periods of
time, how to conserve energy in order to extend node lifetime
and network lifetime is a major research issue in most wireless
networks. One way of saving energy is to operate these nodes
at low power as long as possible. However, this will also
signiﬁcantly downgrade their functionality. Therefore, there
is a trade-off between energy and the “quality” delivered
by wireless nodes. When “quality” is measured in terms of
latency, the trade-off is between energy and time. Examples
arise in real-time computing, where a processor trades off
processing rate for energy [1]; and in wireless transmission,
where a transmitter trades off transmission speed for energy
[2].

When the energy of a wireless node is consumed mostly
by communication tasks, scheduling a RF transmission efﬁ-
ciently becomes extremely important in conserving the energy

L. Miao is with the Department of Engineering Technology, Mid-
dle Tennessee State University, Murfreesboro, TN 37132 USA e-mail:
lei.miao@mtsu.edu.

J. Mao is with the Division of Systems and Engineering Management,

Nanyang Technological University, Singapore email: jfmao@ntu.edu.sg.

C. G. Cassandras is with the Division of Systems Engineering and the
Deptartment of Electrical and Computer Engineering, Boston University,
Brookline, MA 02446 USA email: cgc@bu.edu.

The authors’ work is supported in part by the National Science Foundation
under Grant DMI-0330171, by AFOSR under grants FA9550-04-1-0133
and FA9550-04-1-0208, by ARO under grant DAAD19-01-0610, and by
Honeywell Laboratories.

of the node. It is well known that there exists an explicit
relationship between transmission power and channel capacity
[3];
transmission power can be adjusted by changing the
transmission rate, provided that appropriate coding schemes
are used. This provides an option to conserve the transmission
energy of a wireless node by slowing down the transmission
rate. Increased latency is a direct side effect caused by the low
transmission rate and it can affect other Quality-of-Service
(QoS) metrics as well. For example, excessive delay may
cause buffer overﬂow, which increases the packet dropping
rate. The existence of this trade-off between energy and
latency motivates Dynamic Transmission Control techniques
for designing energy-efﬁcient wireless systems.

To the best of our knowledge, the earliest work that captures
the trade-off between energy and latency in transmission
scheduling is [4], in which Collins and Cruz formulated a
Markov decision problem for minimizing transmission cost
subject
to some power constraints. By assuming a linear
dependency between transmission cost and time, their model
did not consider the potential of more energy saving by varying
the transmission rate. Berry [5] considered a Markov decision
process in the context of wireless fading channels to minimize
the weighted sum of average transmission power and a buffer
cost, which corresponds to either average delay or probability
of buffer overﬂow. Using dynamic programming and assuming
the transmission cost to be a convex function of time, Berry
discovered some structural properties of the optimal adaptive
control policy, which relies on information on the arrival state,
the queue state, and the channel state. In [6] and [7], Ata
developed optimal dynamic power control policies subject
to a QoS constraint for Markovian queues in wireless static
channels and fading channels respectively. In his work, the
optimization problem was formulated to minimize the long-
term average transmission power, given a constraint of buffer
overﬂow probability in equilibrium; dynamic programming
and Lagrangian relaxation approaches were used in deriving
the optimal policies, which can be expressed as functions of
the packet queue length and the channel state. Neely utilized
a Lyapunov drift technique in [8] to develop a dynamic power
allocation and routing algorithm that minimizes the average
power of a cell-partitioned wireless network. It was shown that
the on-line algorithm operates without knowledge of trafﬁc
rates or channel statistics, and yields average power that is
arbitrarily close to the off-line optimal solution. A related
problem of maximizing throughput subject to peak and average
power constraints was also discussed in [8].

Today’s real-time data communications require Quality-of-
Service (QoS) guarantee for each individual packet. Another

line of research aims at minimizing the transmission energy
over a single wireless link while providing QoS guarantee. In
particular, it is assumed that each packet is associated with
an arrival time (generally random), a number of bits, a hard
deadline that must be met, and an energy function. This line
of work was initially studied in [9] with follow-up work in [2]
where a ”homogeneous” case is considered assuming all pack-
ets have the same deadline and number of bits. By identifying
some properties of this convex optimization problem, Gamal
et al. proposed the ”MoveRight” algorithm in [2] to solve it
iteratively. However, the rate of convergence of the MoveRight
algorithm is only obtainable for a special case of the problem
when all packets have identical energy functions; in general the
MoveRight algorithm may converge slowly. Zafer et al. [10]
studied an optimal rate control problem over a time-varying
wireless channel, in which the channel state was considered
to be a Markov process. In particular, they considered the
scenario that B units of data must be transmitted by a common
deadline T, and they obtained an optimal rate-control policy
that minimizes the total energy expenditure subject to short-
term average power constraints. In [11] and [12], the case of
identical arrival time and individual deadline is studied by
Zafer et. al. In [13], the case of identical packet size and
identical delay constraint is studied by Neely et. al. They
extended the result for the case of individual packet size and
identical delay constraint in [14]. In [15], Zafer et. al. used a
graphical approach to analyze the case that each packet has
its own arrival time and deadline. However, there were certain
restrictions in their setting, for example, the packet that arrives
later must have later deadlines. Wang and Li [16] analyzed
scheduling problems for bursty packets with strict deadlines
over a single time-varying wireless channel. Assuming slotted
transmission and changeable packet transmission order, they
are able to exploit structural properties of the problem to
come up with an algorithm that solves the off-line problem. In
[17], Poulakis et. al. also studied energy efﬁcient scheduling
problems for a single time-varying wireless channel. They
considered a ﬁnite-horizon problem where each packet must
be transmitted before Dmax. Optimal stopping theory was
used to ﬁnd the optimal start transmission time between [0,
Dmax] so as to minimize the expected energy consumption
and the average energy consumption per unit of time. In
[18], an energy-efﬁcient and deadline-constrained problem was
formulated in lossy networks to maximize the probability
that a packet is delivered within the deadline minus a trans-
mission energy cost. Dynamic programming based solutions
were developed under a ﬁnite-state Markov channel model.
Shan et. al. [19] studied discrete rate scheduling problems
for packets with individual deadlines in energy harvesting
systems. Under the assumption that later packet arrivals have
later deadlines, they established connections between contin-
uous rate and discrete rate algorithms. A truncation algorithm
was also developed to handle the case that harvested energy
is insufﬁcient to guarantee all packets’ deadlines are met.
Tomasi et. al. [20] developed transmission strategies to deliver
a prescribed number of packets by a common deadline T
while minimizing transmission attempts. Modeling the time-
varying correlated wireless channel as a Markov chain, they

2

used dynamic programming and a heuristic strategy to address
three systems, in which the receiver provides the channel state
information to the transmitter differently. Zhong and Xu [21]
formulated optimization problems that minimize the energy
consumption of a set of tasks with task-dependent energy
functions and packet lengths. In their problem formulation, the
energy functions include both transmission energy and circuit
power consumption. To obtain the optimal solution for the
off-line case with backlogged tasks only, they developed an
iterative algorithm RADB whose complexity is O(n2) (n is
the number of tasks). The authors show via simulation that
the RADB algorithm achieves good performance when used
in on-line scheduling. In [22], Vaze derived the competitive
ratios of on-line transmission scheduling algorithms for single-
source and two-source Gaussian channels in energy harvesting
systems. In Vaze’s problem formulation, the goal is to min-
imize the transmission time of ﬁxed B bits using harvested
energy, which arrive in chunks randomly.

In the above papers, the closest ones to this paper are [2],
[14], and [15]. In this paper, we consider the transmission con-
trol problem in the scenario that each task has arbitrary arrival
time, deadline, and number of bits. Therefore, the problem we
study in this paper is more generic and challenging.

Our model also allows each packet to have its own energy
function. This makes our results especially applicable to
Download Transmission Scheduling (DTS) scenarios, where
a transmitter transmits to multiple receivers over slow-fading
channels. Our contributions are the following: by analyzing
the structure of the optimal sample path, we solve the DTS
problem efﬁciently using a two-fold decomposition approach.
First, we establish that the problem can be reduced to a
set of subproblems over segments of the optimal sample
path deﬁned by “critical tasks”. Secondly, we establish that
solving each subproblem boils down to solving nonlinear
algebraic equations for the corresponding segments. Based
on the above decomposition approach, an efﬁcient algorithm
that solves the DTS problem is proposed and compared to
the MoveRight algorithm. Simulation results show that our
algorithm is typically an order of magnitude faster than the
MoveRight algorithm.

The main results of the paper were previously published
in [23]. In this journal version, we have improved most
proofs and moved them to an appendix in order to enhance
the continuity of the analysis in the paper. We have added
summaries and explanations between the technical results to
enhance its readability.

We have added Section III.C, in which the maximum power

constraints are added and discussed.

In addition, we have added Section IV. In this section,
we discuss how to use our algorithm and Receding Horizon
Control to perform on-line transmission scheduling where the
task information is unknown. New simulation results are also
provided in this section.

The structure of the paper is the following: in Section II, we
formulate our DTS problem and discuss some related work;
the main results of DTS are presented in Section III, where
an efﬁcient algorithm is proposed and shown to be optimal;
in Section IV, we discuss how our main results can be used

to perform on-line transmission control; ﬁnally, we conclude
in Section V.

in (1) is constant, ωi(τ ) is kept ﬁxed during the transmission
of task i.

We formulate the off-line DTS problem as follows:

3

II. THE DOWNLINK TRANSMISSION SCHEDULING

PROBLEM AND RELATED WORK

We assume the channel between the transmitter and the re-
ceiver is an Additive White Gaussian Noise (AWGN) channel
and the interference to the receiver is negligible. The received
signal at time t can be written as:

Y (t) =pg(t)X(t) + n(t),

(1)

where g(t) is the channel gain, X(t) is the transmitted signal,
and n(t) is additive white Gaussian noise [24]. Note that
in this section we consider the case when the transmitter is
in isolation from other transmitters so that the interference
is negligible. Due to channel fading, g(t) is time-varying in
general. We will consider g(t) to be time-invariant during
the transmission of a single packet. Although in practice
the channel state may change during the transmission of a
packet, our results are still helpful, since, it is valid to estimate
unknown future channel state to be static for each packet in an
on-line setting. Note that our results can be possibly extended
to fast fading channels as well.

The DTS problem arises when a wireless node has a set
of N packets that need to be sent to different neighboring
nodes. The goal is to minimize the total transmission energy
consumption while guaranteeing hard deadline satisfaction for
each individual packet. Since each packet can be considered
as a communication task, we the terms “task” and “packet”
interchangeably in what follows. We model the transmitter as a
single-server queueing system operating on a nonpreemptive
and First-Come-First-Ferved (FCFS) basis, whose dynamics
are given by the well-known max-plus equation

xi = max(xi−1, ai) + si

(2)

where ai is the arrival time of task i = 1, 2, . . . , xi is the
time when task i completes service, and si is its (generally
random) service time.

Note that although preemption is often easy and straightfor-
ward in computing systems, it is very costly and also techni-
cally hard in wireless transmissions. Therefore, we assume a
nonpreemptive model in this paper. Transmission rate control
typically occurs in the physical layer, and changing packet
order may cause problems in the upper layers of the network
stack. Thus, we use a simple FCFS model to avoid packet
out-of-sequence problems. It is also worth noting that even if
the packet order is changeable, determining the optimal packet
order is a separate problem. Once the order of transmission is
decided by a speciﬁc scheduling policy, our work can be used
to minimize the energy expenditure for that speciﬁc order.

The service time si

is controlled by the transmission
rate, which is determined by transmission power and coding
scheme. However, it turns out that it is more convenient to use
the reciprocal of the transmission rate as our control variable
in the DTS problem. Thus, we deﬁne τ to be the transmission
time per bit and ωi(τ ) to be the energy cost per bit for task i.
Clearly, ωi(τ ) is a function of τ. Since the channel gain g(t)

P1:

s.t.

min

τ1,...,τNPN

i=1 viωi(τi)

xi = max(xi−1, ai) + viτi ≤ di, i = 1, . . . N
τi > 0, x0 = 0.

where di and vi are the deadline and the number of bits of
task i respectively.

In realistic scenarios, the maximum transmission power of a
wireless system puts a constraint on each τi, i.e., τi ≥ τi min,
where τi min is the minimum amount of time used for trans-
mitting one bit in task i. For ease of analysis, we omitted this
constraint in P1. However, it is important to note that special
handling is needed in real-world systems for the case that the
is below the minimum value τi min. For
optimal solution τ ∗
i
example, the system may simply choose to drop the packet
or transmit the packet using control τi min. We will discuss
the problem that includes this constraint in Section III.C and
Section IV.

Note that in the off-line setting, we consider ai, di and vi
are known. The downlink scheduling problem formulated in
[2] is a special case of P1 above: in [2] each task has the
same deadline and number of bits, i.e., di = T, vi = v, for
all i. Note that transmission rate constraints are omitted in P1
and we assume the transmission rate can vary continuously.
In practical systems, the control can always be rounded to the
nearest achievable value [25].

Problem P1 above is similar to the general class of problems
studied in [26] and [27] without the constraints xi ≤ di,
where a decomposition algorithm termed the Forward Algo-
rithm (FA) was derived. As shown in [26] and [27], instead
of solving this complex nonlinear optimization problem, we
can decompose the optimal sample path into a number of
busy periods. A busy period (BP) is a contiguous set of
tasks {k, ..., n} such that the following three conditions are
satisﬁed: xk−1 < ak, xn < an+1, and xi ≥ ai+1, for every
i = k, . . . , n − 1. Notice that P1 above exploits static control
(τi kept ﬁxed during the service time of task i). This is straight-
forward in wireless transmission control since the transmission
rate of a single packet/task is often ﬁxed. In addition, it has
been shown in [28] that when the energy functions ωi(τ ),
i = 1, . . . N, are strictly convex and monotonically decreasing
in τ, there is no beneﬁt in applying dynamic control (τi varies
over time during the service time of task i). It has also been
shown in [29] that when the energy functions are identical in
P1, its solution is obtained by an efﬁcient algorithm (Critical
Task Decomposition Algorithm) that decomposes the optimal
sample path even further and does not require solving any
convex optimization problem at all. In this paper, we will
consider the much harder case that the energy functions are
task-dependent. When the energy functions are homogeneous,
it is shown in [29] that the exact form of the energy function
does not matter in ﬁnding the optimal solutions. The main
challenge of having heterogeneous energy functions is that
these energy functions will be used to identify the optimal
solutions, and this adds an extra layer of complexity. We shall

still use the decomposition idea in [29], and we will use {τ ∗
i }
i }, i = 1, . . . , N , to denote the optimal solution of P1
and {x∗
and the corresponding task departure times respectively.

Typically, ωi(τ ) is determined by factors including the chan-
nel gain g(t), transmission distance, signal to noise ratio, and
so on. Therefore, when a wireless node transmits to different
neighbors at different time, different ωi(τ ) are involved. We
begin with an assumption that will be made throughout our
analysis.

Assumption 1: In AWGN channels, ωi(τ ) is nonnegative,
strictly convex, monotonically decreasing, differentiable, and
limτ →0 ˙ωi(τ ) = −∞ .

Assumption 1 is justiﬁed in [2] and channel coding schemes
supporting this assumption can be found in [9]. Note that the
result obtained in [28] can be readily applied here: the unique
optimal control to P1 is static. This means that we do not need
to vary the transmission rate of task i during its transmission
time.

III. MAIN RESULTS OF DTS

A. Optimal Sample Path Decomposition

The following two lemmas help us to decompose the
optimal sample path of P1. Their proofs are very similar to
the proofs for Lemmas 1 in [29], and only monotonicity of
ωi(τ ) is required. We omit the proofs here.
i = di.

Lemma 3.1: If di < ai+1, then x∗
Lemma 3.2: If di ≥ ai+1, then ai+1 ≤ x∗
i .
Recalling the deﬁnition of a BP, Lemmas 3.1, 3.2 show
that the BP optimal structure can be explicitly determined by
the deadline-arrival relationship, i.e., a sequence of contiguous
packets {k, . . . , n} is a BP if and only if the following
is satisﬁed: dk−1 < ak, dn < an+1, di ≥ ai+1, for
all i ∈ {k, . . . , n − 1}. After identifying each BP on the
optimal sample path, problem P1 is reduced to solving a
separate problem over each BP. We formulate the following
optimization problem for BP {k, . . . , n}.

Q(k, n) :

s.t.

i=k viωi(τi)

min

τk,...,τnPn
xi = ak +Pi

τi > 0, i = k, . . . , n,
xi ≥ ai+1, i = k, . . . , n − 1.

j=k viτi ≤ di, i = k, . . . , n

Although Q(k, n) is easier than P1 (since it does not contain
max-plus equations, which are nondifferentiable), it is still a
hard convex optimization problem. Naturally, we would like
to solve Q(k, n) efﬁciently. As we will show, this is indeed
possible by further decomposing a BP {k, . . . , n} through
special
tasks”, which are deﬁned as
follows:

tasks called “critical

Deﬁnition 1: Suppose both task i and i + 1 are within a
i ) 6=
i+1), then
i+1), then task i is

BP {k, . . . , n} on the optimal sample path of P1. If ˙ωi(τ ∗
˙ωi+1(τ ∗
task i is left-critical. If ˙ωi(τ ∗
right-critical.

i+1), task i is critical. If ˙ωi(τ ∗

i ) > ˙ωi+1(τ ∗

i ) < ˙ωi+1(τ ∗

These critical tasks are special because the derivatives of
the energy function change after these tasks are transmitted on
the optimal sample path. Therefore, identifying critical tasks
is crucial in solving Q(k, n). In fact, Gamal et al. [2] observed

4

the existence of left-critical tasks. However, they did not make
use of them in characterizing the optimal sample path. In order
to accomplish this, we need to study the relationship between
critical tasks and the structure of the optimal sample path. An
auxiliary lemma will be introduced ﬁrst.

Lemma 3.3: If v1τ1 +v2τ2 = v1τ

′

′

′

1 +v2τ

2, τ

1 < τ1, τ

1) > ˙ω2(τ

2), then, v1ω1(τ1)+v2ω2(τ2) > v1ω1(τ

′

′

2 > τ2,
1)+

′

′

and ˙ω1(τ
2).
v2ω2(τ

′

Lemma 3.3 implies that under Assumption 1 (especially,
the convexity assumption), it takes the least amount of energy
to transmit two tasks in a given amount of time when the
derivatives of the two energy functions have the least amount
of difference. As we will see later, this auxiliary lemma will be
used to establish other important results. Next, we will discuss
what exactly makes the critical tasks (deﬁned in Deﬁnition 1)
special.

Lemma 3.4: Suppose both task i and i + 1 are within a BP
{k, . . . , n} on the optimal sample path of P1. (i) If task i is
left-critical, then x∗
i = ai+1. (ii) If task i is right-critical, then
x∗
i = di.
This result shows that if a task is left-critical or right-critical
on the optimal sample path, its optimal departure time is given
by the next arrival time or its deadline respectively. The lemma
implies that when ai+1 < x∗
i < di, task i is neither left-
critical nor right-critical. In our next step, we will study the
commonality among a block of consecutive non-critical tasks,
which are in the middle of two adjacent critical tasks. By
hoping so, we will have a better understanding of the structure
of the optimal sample path, using which we will develop an
efﬁcient algorithm to solve Q(k, n).

Remark 3.1: For any two neighboring tasks i and i + 1 in
a BP {k, . . . , n} on the optimal sample path of P1, if task i
is not a critical task, then ˙ωi(τ ∗

i ) = ˙ωi+1(τ ∗

i+1).

This remark is the direct result of Deﬁnition 1. Using
this remark and Lemma 3.4, we can obtain the structure
of BP {k, . . . , n} on the optimal sample path of P1 as
follows: {k, . . . , n} is characterized by a sequence of tasks
S = {c0, . . . , cm+1}, in which c0 = k, {c1, . . . , cm} contains
all critical tasks in {k, . . . , n} (the optimal departure times
of these critical tasks are given by Lemma 3.4), and task
cm+1 = n. Moreover, let ci, ci+1 be adjacent tasks in S.
Then, the segment of tasks

(cid:26) {ci, . . . , ci+1},

{ci + 1, . . . , ci+1},

if i = 0
if 0 < i ≤ m

(3)

is operated at some τ such that the derivatives of their energy
functions are all the same. To have a better understanding of
this optimal structure, see Fig. 1. In this example, task 2 is
left-critical and task 4 is right-critical. Their optimal departure
times are a3 and d4 respectively. In the set S = {1, 2, 4, ...},
tasks {1, 2} and {3, 4} are examples of the segments deﬁned
above. Invoking Remark 3.1, τ ∗
4 are characterized by
˙ω1(τ ∗
3 ),
˙ω4(τ ∗

1 ) = ˙ω2(τ ∗
2 ),
4 ) < ˙ω5(τ ∗
5 ).

4 ) and ˙ω2(τ ∗

3 ) = ˙ω4(τ ∗

2 ) > ˙ω3(τ ∗

1 , . . . , τ ∗

˙ω3(τ ∗

In order to obtain our main result of this section and the
explicit algorithm that solves Q(k, n), we deﬁne next a system
of nonlinear algebraic equations as follows with i < j, 0 ≤

1a

2a

3a

4a

5a

6a

*
1x

x* =

2

a
3

*
3x

x* =

4

d

4

*
5x

… t

left-critical

right-critical

w

t
(

*
1

)

&

1

=
w

t
(

*
2

)

&

2

>
w

t
(

*
3

)

&

3

=
w

t
(

*
4

)

&

4

<
w

&

5

NE

;2,1(

1 aa
3

,

)

NE

;4,3(

3 da

,

4

)

  )

t
*
(
5
…

Fig. 1: IllustrationoftheoptimalstructureofBP{k,...,n}.

t1 ≤ t2, and unknown variables τi, . . . , τj :

N E(i, j; t1, t2) : Pj

m=i τmvm = t2 − t1,
˙ωm(τm) = ˙ωm+1(τm+1),
m = i, . . . , j − 1.

Its solution minimizes the total energy of transmitting tasks
{i, . . . , j} that do not contain critical tasks within time interval
t2 − t1. Note that when i = j, the above nonlinear algebraic
equations reduce to a single linear equation τivi = t2 − t1.

In Fig. 1, we illustrated the structure of a BP on the optimal
sample path of P1. In fact, given all critical tasks in the BP,
the optimal solution can be obtained by solving a set of N E
systems, one for each segment deﬁned in (3). For example,
in Fig. 1, the optimal controls of tasks {1, 2} and {3, 4} can
be obtained by solving N E(1, 2; a1, a3) and N E(3, 4; a3, d4)
respectively.

At this point, we have established that solving problem
Q(k, n) boils down to identifying critical tasks on its optimal
sample path. This relies on some additional properties of the
optimal sample path. To obtain them, we need to ﬁrst study
the properties of N E(i, j; t1, t2).
solution

by
τi(t1, t2), . . . , τj (t1, t2). We deﬁne the common derivative in
N E(i, j; t1, t2):

to N E(i, j; t1, t2)

We

denote

the

σi,j (t1, t2) = ˙ωm(τm(t1, t2)), for any m, i ≤ m ≤ j.

and note that σi,j (t1, t2) is the derivative of the energy
function of any task in {i, . . . , j}. When t1 = t2, we set
σi,j (t1, t2) to −∞. Later, when invoking the deﬁnition of
critical tasks, we will use σi,j(t1, t2) instead of the derivative
of the energy function of a single task.

Now, we are ready to introduce the properties of

N E(i, j; t1, t2) in the next lemma.

Lemma 3.5: When t1 < t2, N E(i, j; t1, t2) has the follow-

ing properties:

(i) It has a unique solution.
(ii) The common derivative σi,j (t1, t2) is a monotonically

increasing function of ∆ = t2 − t1, i.e.,

σi,j(t1, t2) < σi,j(t3, t4), if t4 − t3 > t2 − t1.

5

Pp

(iii) For any p, i ≤ p < j, deﬁne the partial sum Sip ≡
m=i τm(t1, t2)vm. Then,

σi,p(t1, t1 + Sip) = σp+1,j (t1 + Sip, t2) = σi,j(t1, t2)

(iv) For any p, i ≤ p < j, t1 < t3 < t2, let c1 = σi,p(t1, t3),
c2 = σp+1,j (t3, t2), c3 = σi,j (t1, t2). If cq 6= cr ∀q, r ∈
{1, 2, 3}, q 6= r, then min(c1, c2) < c3 < max(c1, c2).

B. Left and Right-critical Task Identiﬁcation

it

Based on the above results, we have characterized the
special structure of the optimal sample path of P1. To sum-
marize, Lemmas 3.1 and 3.2 show that the BP structure of
the optimal sample path can be explicitly determined by the
deadline-arrival relationship. This transforms P1 into a set of
simpler convex optimization problems with linear constraints.
Although the problem becomes easier to solve,
is still
computationally hard for wireless devices without powerful
processors and sufﬁcient energy. Note that in the homogeneous
case, when all tasks have the same arrival time and deadline,
they should be transmitted with the same derivatives of their
cost functions. In this case,
the optimal solution can be
obtained by solving the nonlinear system N E(i, j; t1, t2).
With the presence of inhomogeneous real-time constraints, we
showed in Lemma 3.4 and Remark 3.1 that a set of “critical
tasks” play a key role to determine the optimal sample path,
i.e., the derivatives of the cost functions only change at these
critical tasks. Once they are determined, the original problem
Q(k, n) boils down to set of nonlinear algebraic equations.

Having obtained the properties of N E(i, j; t1, t2), we will
next develop an efﬁcient algorithm to identify critical tasks.
Without loss of generality, we only prove the correctness of
identifying the ﬁrst critical task. Other critical tasks can be
identiﬁed iteratively. In addition, our proof will focus on right-
critical tasks only, and we omit the proof for left-critical tasks,
which is very similar.

We will ﬁrst give some deﬁnitions. For tasks (p, i) within

a BP {k, . . . , n}, i.e., k ≤ p < i ≤ n, deﬁne:

T1(k, p) =(cid:26) ak, p = k
T2(n, i) =(cid:26) ai+1, i < n

x∗
p−1, p > k

dn, i = n

Recalling the deﬁnition of a BP, T1(k, p) is deﬁned as
the optimal starting transmission time for task p, which is
within a BP starting with task k. Recalling Lemmas 3.1 and
3.2, T2(n, i) is deﬁned as the earliest possible transmission
ending time for task i, which is within a BP ending with task
n. Note that in order to guarantee the real-time constraints,
task i must be done by its deadline di. We will use T1(k, p),
T2(n, i), and di later to identify critical tasks.

We further deﬁne:

Ri = arg max

{
s∈{p,...,i−1}

σp,s(T1(k, p), ds)

≤ σp,j(T1(k, p), dj),

(4)

for i, p < i ≤ n, and all j ∈ {p, . . . , i − 1}}

(cid:215)
(cid:215)
(cid:215)
Li = arg max

{
s∈{p,...,i−1}

σp,s(T1(k, p), T2(n, s))
≥ σp,j(T1(k, p), T2(n, j)),
for i, p < i ≤ n, and all j ∈ {p, . . . , i − 1}}

6

(ii) If

(5)

σk,j(ak, dj ) ≥ σk,Lj (ak, aLj +1),

σk,j (ak, aj+1) ≤ σk,Rj (ak, dRj ), and

σk,i(ak, di) < σk,Li (ak, aLi+1),

Note that Ri and Li are the tasks with the largest index in
{p, . . . , i − 1} that satisﬁes the inequalities in (4) and (5)
respectively. It is clear that p ≤ Ri < i, p ≤ Li < i.

A special case of (4) and (5) arises when p is the ﬁrst
task of a BP {k, . . . , n}, i.e., p = k. Then, according to the
deﬁnitions above, we obtain the following inequalities, which
will be used in our later results:

σk,Ri (ak, dRi) ≤ σk,m(ak, dm),

for i, k < i ≤ n, and all m ∈ {k, . . . , i − 1}

σk,Li (ak, T2(n, Li)) ≥ σk,m(ak, T2(n, m)),
for i, k < i ≤ n, and all m ∈ {k, . . . , i − 1}.

(6)

(7)

After introducing the above deﬁnitions and notations, we
are now ready to introduce three important lemmas, which
will be used to prove our main theorem.

Lemma 3.6: Let tasks {k, . . . , n} form a BP on the optimal
sample path of P1 and task r > k be the ﬁrst right-critical task
in {k, . . . , n}. If σk,r(ak, dr) ≥ σk,Lr (ak, aLr+1), then there
is no left-critical task in {k, . . . , r − 1}.

Lemma 3.7: Let tasks {k, . . . , n} form a BP on the optimal
sample path of P1. Consider task Ri, for i, k < i ≤ n.
If σk,j (ak, dj) ≥ σk,Lj (ak, aLj +1) and σk,j (ak, aj+1) ≤
σk,Rj (ak, dRj ), for all j, k < j < i, then there is no right-
critical task before task Ri.

Lemma 3.8: Let tasks {k, . . . , n} form a BP on the opti-
mal sample path of P1. If σk,i(ak, ai+1) > σk,Ri (ak, dRi ),
σk,j (ak, dj) ≥ σk,Lj (ak, aLj +1) and σk,j (ak, aj+1) ≤
σk,Rj (ak, dRj ), for i, k < i ≤ n, and for all j, k < j < i,
then Ri is right-critical.

Before we introduce the main theorem, we would like to

ﬁrst summarize the above three lemmas.

Lemma 3.6 provides the conditions under which there are
no left-critical tasks before the ﬁrst right-critical task r in a
BP.

Lemma 3.7 provides the conditions under which there are

no right-critical tasks before a given task Ri in a BP.

Lemma 3.8 provides the conditions under which task Ri in

a BP is right-critical.

With the help of the above auxiliary results, we are able to
establish the following theorem, which can identify the ﬁrst
critical task in a BP on the optimal sample path of P1:

Theorem 3.1: Let tasks {k, . . . , n} form a BP on the opti-

mal sample path of P1.

(i) If

σk,j (ak, dj) ≥ σk,Lj (ak, aLj +1),

σk,j (ak, aj+1) ≤ σk,Rj (ak, dRj ), and

σk,i(ak, ai+1) > σk,Ri (ak, dRi),

(8)

(9)

(10)

for i, k < i ≤ n, and all j, k < j < i, then Ri is the ﬁrst
critical task in {k, . . . , n}, and it is right-critical.

for i, k < i ≤ n, and all j, k < j < i, then Li is the ﬁrst
critical task in {k, . . . , n}, and it is left-critical.

Let us look at the ﬁrst part of Theorem 3.1 again. The
ﬁrst right-critical task of a BP on the optimal sample path
of P1 can be correctly identiﬁed if we can ﬁnd i and Ri
which satisfy (8)-(10). In essence, (8) guarantees that there is
no left-critical task before Ri, (9) guarantees that there is no
right-critical task before Ri, and (10) guarantees that Ri is a
right-critical task. A similar argument applies to the second
part of the theorem. Therefore, the conditions in Theorem 3.1
are not only sufﬁcient but also necessary for identifying the
ﬁrst critical task.

After obtaining the ﬁrst critical task, either left-critical or
right-critical, the rest of the BP, can be considered as a new
BP. Invoking Lemma 3.4, the new BP starts at either the ﬁrst
critical task’s deadline (if it is right-critical) or the arrival time
of the next task after the ﬁrst critical task (if it is left-critical).
Applying Theorem 3.1 on the next BP, we are able to identify
its ﬁrst critical task, which is the second critical task of the
original BP. Iteratively applying Theorem 3.1 helps us ﬁnd all
critical tasks on the original optimal sample path. This leads
directly to an efﬁcient algorithm which can identify all critical
tasks in BP {k, . . . , n} on the optimal sample path of P1.
Meanwhile, as we have illustrated in Fig. 1, after identifying
all critical tasks in BP {k, . . . , n} on the optimal sample path
of P1, we can ﬁnd all segments in {k, . . . , n} with the same
energy function derivatives. Solving a N E problem for each
segment and combining the solutions gives us the optimal
solution to Q(k, n).

The Generalized Critical Task Decomposition Algorithm
(GCTDA) which identiﬁes critical tasks and solves Q(k, n)
is as follows:

step 1 p = k;
step 2 i = p + 1, Solve N E(p, p; T1(k, p), T2(n, p))
and N E(p, p; T1(k, p), dp);

Identify the ﬁrst critical task in (p, n)
while (i ≤ n)
{Solve N E(p, i; T1(k, p), T2(n, i))
and N E(p, i; T1(k, p), di);
Compute Ri;
if (σp,i(T1(k, p), T2(n, i)) > σp,Ri (T1(k, p), dRi )
{Ri is the ﬁrst right-critical task in (p, n);
τ ∗
j = τj (T1(k, p), dRi), j = p, . . . , Ri;
xR∗
aj = dRi , for all j, s.t., j > Ri, aj < dRi ;
p = Ri + 1; go to step 2;}

= dRi ;

i

Compute Li;
if (σp,i(T1(k, p), di) < σp,Li(T1(k, p), aLi+1)

{Li is the ﬁrst left-critical task in (p, n);
τ ∗
j = τj (T1(k, p), aLi+1), j = p, . . . , Li;
x∗
Li
p = Li + 1; go to step 2;}

= aLi+1;

i = i + 1;
}
τ ∗
j = τj(T1(k, p), dn), j = p, . . . , n;
END

Note that GCTDA ﬁnds the critical tasks in a BP on the
optimal sample path of P1 iteratively. The optimal departure
times of these critical tasks can be easily obtained using the
results in Lemma 3.4. Finally, the optimal solution to the off-
j , j = 1, . . . N, is also calculated in GCTDA.
line problem: τ ∗
Regarding the complexity of our algorithm, the most time
consuming part is solving N E(i, j; t1, t2). In the worst case,
the optimal sample path is a single BP containing N − 1
critical tasks and the GCTDA algorithm may need to solve
N E(i, j; t1, t2) 2Nr times to identify each critical task, where
Nr is the number of tasks remaining. Therefore, the worst case
complexity of the GCTDA algorithm is O(N 2).

C. Maximum Power Constraint

In P1, we omitted the constraint: τi ≥ τi min, which is
essentially the maximum transmission rate or transmission
power constraint for task i. This constraint is very important
in real-world scenarios because a transmitter simply cannot
transmit above the maximum transmission rate/power. We now
formulate P2:

P2:

s.t.

NPN

i=1 viωi(τ ′
i )

min
τ ′
1,...,τ ′
i = max(x′
x′
τ ′
i > τi min, x0 = 0.

i−1, ai) + viτ ′

i ≤ di, i = 1, . . . N

and x′∗
i

Notice that the only difference between P1 and P2 is the
constraint on the control. We use τ ′∗
to denote the
i
optimal control and optimal departure time of task i in P2,
respectively.
It is easy to show that Lemmas 3.1 and 3.2 also apply to P2.
Similar to how we handled P1, we only need to consider a
single BP {k, . . . , n} in the optimal sample path of P2. We
formulate the following problem for BP {k, . . . , n}:

Q′(k, n) :

s.t.

i=k viωi(τ ′
i )

nPn
i = ak +Pi

min
τ ′
k,...,τ ′
x′
τ ′
i ≥ τi min, i = k, . . . , n
x′
i ≥ ai+1, i = k, . . . , n − 1.

j=k viτ ′

i ≤ di, i = k, . . . , n

In order to establish the connection between Problems
P1 and P2, we now introduce the following assumption,
which will be used to derive the results in this subsection.
Justiﬁcations for this assumption in transmission scheduling
are provided in the appendix.

Assumption 2: a) If τi min < τj min, then ˙ωi(τi min) <
˙ωj(τj min) and ˙ωi(τ ) > ˙ωj(τ ); b) If τi min ≥ τj min, then
˙ωi(τi min) ≥ ˙ωj(τj min) and ˙ωi(τ ) ≤ ˙ωj(τ ).

Let

τmin = inf

τi min.

i=k,...,n

Under Assumption 2, we introduce the following auxiliary

lemma:

Lemma 3.9: If ∃τ ∗

i < τmin, then Q′(k, n) is infeasible.

7

Lemma 3.9 establishes certain connections between the
power unconstrained problem Q(k, n) and the power con-
strained problem Q′(k, n). When the problem is homoge-
neous, i.e., the cost functions are identical among the tasks,
we can easily derive that if Q′(k, n) is feasible, then the
optimal solution to Q(k, n) must also yield the maximum
power constraint. In the inhomogeneous case, however, it is
possible that Q(k, n) may return an optimal solution above the
maximum power constraint while Q′(k, n) is indeed feasible.
When this occurs, the optimal solution to Q′(k, n) would be
close to τi min, and the controller could simply apply τi min as
the control since there is not much beneﬁt to do optimization
in this case.

D. Off-line Performance Comparisons

Next, we will test the off-line performance of the GCTDA
algorithm. In this case, all task information including arrival
times, deadlines, and number of bits is known. For compar-
ison purposes, we obtain numerical results for the following
algorithms:

GCTDA: Off-line algorithm knowing all task information
exactly and having full computational capability to solve
N E(i, j; t1, t2).

GCTDA TL: Off-line algorithm knowing all exact task
information and using pre-established tables to ﬁnd an
approximate solution to the nonlinear algebraic system
N E(i, j; t1, t2). The purpose of this algorithm is to re-
duce the computational overhead associated with solving
N E(i, j; t1, t2), at
the cost of more energy consumption.
Speciﬁcally, we pre-calculate the derivatives of 1000 τ values
for each energy function ωi(τ ) and save these data into tables.
Using these tables and binary search, we ﬁnd approximate
solutions to N E(i, j; t1, t2) in GCTDA.

MoveRight: The algorithm proposed in [2]. It is an iterative
algorithm that converges to the optimal solution. We choose
it for performance comparison purposes because to the best
of our knowledge, it is the only other algorithm available for
solving problems with task-dependent cost functions.

In each experiment, in order to make the comparison fair,
we use the same setting (i.e., same arrival times, deadlines,
task sizes, and energy functions) for each algorithm. Note that
what the “best” function solves in the MoveRight algorithm
is actually a nonlinear system N E(i, i + 1; t1, t2). All exper-
iments are done using a 1.8GHz Athlon XP processor.

The setting of the ﬁrst experiment in Table I is as follows:
500 tasks of Poisson arrivals with mean inter-arrival time 5s,
each task has its own deadlines (uniformly distributed between
[ai + 5, ai + 20] for task i), task sizes are different, and
the energy functions are the same. The GCTDA algorithm
outperforms the MoveRight algorithm in terms of CPU time
by two orders of magnitude. Because the optimal sample
path is likely to contain multiple BPs and the energy func-
tions are identical, GCTDA is very fast. We terminated the
MoveRight algorithm after 10000 passes. It can be seen that
the MoveRight algorithm did not converge at this point yet (the
cost is still higher than the optimal cost returned by GCTDA.)
Another observation is that the solution of GCTDA TL is

GCTDA

GCTDA TL
MoveRight

CPU time (sec)

Cost

0.031

1.579

54.704

3.41919

3.56494

3.43264

TABLE I: Different task deadlines and identical energy functions

GCTDA

GCTDA TL
MoveRight

CPU time (sec)

Cost

12.516

2.469

200.703

8.87826

8.98774

9.08324

TABLE II: Different deadlines and different energy functions

a good approximation to the one of GCTDA. This makes
GCTDA TL a good candidate for on-line control. However, it
can be seen that GCTDA TL takes longer than GCTDA when
the energy functions are identical. The reason is that in this
case, the nonlinear system N E(i, j; t1, t2) becomes a linear
system, which can be easily solved. So there is no beneﬁt
in using the table lookup approximation approach. However,
when the energy functions are different, as we will see later,
the approximation method does help.

In the next experiment for 500 tasks in Table II, we
keep the same setting as above, except that we make the
energy functions different for each task. We terminate the
MoveRight algorithm after 100 passes. It can be seen that
in this experiment, GCTDA TL takes much less CPU time
than GCTDA. Both of them are much faster (by an order of
magnitude) and MoveRight has not yet converged.

In Table III, we make all 500 tasks have the same deadline
and the same energy function. In this case,
the optimal
sample path contains a single BP. We terminate the MoveRight
algorithm after 10000 passes. It can be seen that at the time
of termination, it was still far from converging to the optimal
solution. Again, the CPU time of GCTDA TL is higher than
GCTDA, since the energy functions are identical.

In Table IV, the setting is the same as above, except that
we now consider 100 tasks with different energy functions.
We terminate the MoveRight algorithm after 1000 passes.

IV. ON-LINE CONTROLLER DESIGN

We proved that our off-line algorithm GCTDA can return
each critical task on the optimal sample path correctly. There-
fore, using it, we can get the off-line optimal solution. We
are also interested in designing good on-line controllers, in
which case there are two difﬁculties: 1) lack of future task

GCTDA

GCTDA TL
MoveRight

CPU time (sec)

Cost

0.593

98.469

61.969

0.0687325

0.0688239

0.0837155

TABLE III: Identical deadlines and identical energy functions

GCTDA

GCTDA TL
MoveRight

CPU time (sec)

48

11.594

434.687

Cost
0.1997

0.200008

0.72739

TABLE IV: Identical deadlines and different energy functions

8

information; 2) high computational complexity in solving the
nonlinear equations.

To overcome the ﬁrst difﬁculty, we design a Receding
Horizon (RH) controller assuming that at each decision point,
the controller always has some task information within a given
RH window, and nothing beyond this window. The size of the
RH window H can be measured either by time units or the
number of tasks. In this paper, we use the latter to measure
the RH window H. This RH window, together with the task
information within it, is often referred to as the planning
horizon. In contrast to the planning horizon, the RH controller
will apply controls over an action horizon, which contains a
subset of tasks over the planning horizon. Such controllers
have been proposed and analyzed in [30] and [31] for the
homogeneous case that the cost functions are identical. In this
paper, we consider the RH control for the inhomogeneous case
that the cost functions are task-dependent.

As we will see later, the off-line results we obtained in pre-
vious sections provide insight to RH on-line controller design
and performance evaluation. We now introduce some notations
similar to the ones in [31]. Let ˜xt be the departure time of
task t on the RH state trajectory, which is also a decision point
when the RH controller is invoked with lookahead window
H. Let ˜τt be the control associated with task t as determined
by the RH controller. When task t + 1 starts a new BP (i.e.,
at+1 > ˜xt), then the RH controller does not need to act until
at+1 rather than ˜xt; for notational simplicity, we will still use
˜xt to represent the decision point for task t + 1 (i.e., the time
when the control ˜τt+1 is determined). Let h denote the last
task included in the window that starts at the current decision
point ˜xt, i.e.,

h = arg max r≥t{ar : ar ≤ ˜xt + H}.

Note that although the value of h depends on t, for notational
simplicity, we will omit this dependence and only write ht
when it is necessary to indicate dependence on t. When the
RH controller is invoked at ˜xt, it is called upon to determine
˜τi, the control associated with task i for all i = t + 1, . . . , h,
and let ˜xi denote the corresponding departure time of task i
which is given by ˜xi = max(˜xi−1, ai)+ ˜τivi. The values of ˜xi
and ˜τi are initially undeﬁned, and are updated at each decision
point ˜xt for all i = t + 1, . . . , h. Control is applied to task
t + 1 only. That control and the corresponding departure time
are the ones showing in the ﬁnal RH sample path. In other
words, for any given task i, ˜xi and ˜τi may vary over different
planning horizons, since optimization is performed based on
different available information. It is only when task i is the
next one at some decision point that its control and departure
time become ﬁnal.

Given these deﬁnitions, we are now ready to discuss the
worst case estimation process to be used. If h = N , then
the optimization process is ﬁnalized, so we will only consider
the more interesting case when h < N . Then, our worst case
estimation pertains to the characteristics of task h + 1, the
ﬁrst one beyond the current planning horizon determined by
h, i.e., its arrival time, deadline, and number of bits which are
unknown. We deﬁne task arrival times and task deadlines for

i = t + 1, . . . , h + 1 as follows:

and formulate problem ˆQ(t + 1, ˆh) :

9

˜ai = (cid:26)
˜di = (cid:26)

ai,

˜xt + H,

if t + 1 ≤ i ≤ h
if i = h + 1

di,

˜ah+1 + τi minvh+1,

if t + 1 ≤ i ≤ h
if i = h + 1

(11)

(12)

ˆQ(t + 1, ˆh) :

s.t.

min

˜τt+1,...,˜τˆh Pˆh

i=t+1 viωi(˜τi)

˜τi ≥ 0, i = t + 1, . . . , ˆh.
˜xi = max(˜xi−1, ai) + ˜τivi ≤ ˆdi, ˜xt known.

The RH control algorithm at each decision point ˜xt is shown
in Table V. Note that ˜Q(t+1, h) and ˆQ(t+1, ˆh) essentially are
smaller scale off-line optimization problems. This implies that
at each on-line decision point, we shall use an off-line control
algorithm, i.e., GCTDA or GCTDA TL, to solve ˜Q(t + 1, h)
and ˆQ(t + 1, ˆh).

In the next result, we discuss the feasibility of the proposed

on-line RH control mechanism.

Theorem 4.1: If the off-line problem P2 is feasible, then

the RH control in Table V is also feasible.

Theorem 4.1 reveals that the RH control in Table V guar-
antees feasibility when the off-line problem P2 is feasible.
Next, we will analyze the performance of the proposed RH
controller using simulation. To overcome the high computa-
tional complexity, we use the GCTDA TL algorithm, rather
than GCTDA algorithm for on-line RH control. As we have
mentioned previously, the GCTDA TL algorithm uses some
piecewise constant functions to approximate the derivatives
of the energy functions at different τ. Optimization can be
approximated by searching efﬁciently in a pre-established table
containing these functions.

Step 1:

Step 2:

i , ˜x∗
i ,

i = t + 1, . . . , h

i ≥ τi min for all i,

t+1 to task t + 1 and go to END.

Solve ˜Q(t + 1, h) and get eτ ∗
If eτ ∗
apply eτ ∗
If ˆh exists, solve ˆQ(t + 1, ˆh) and get eτ ∗
If eτ ∗
apply eτ ∗

t+1 to task t + 1 and go to END.

i ≥ τi min for all i,

i = t + 1, . . . , ˆh.

i , ˜x∗
i ,

In (11), the arrival times of tasks i = t + 1, . . . , h are known
and we introduce a “worst case” estimate for the ﬁrst unknown
task beyond ˜xt + H, i.e., we set it to be the earliest it could
possibly occur. In (12), the deadlines of tasks i = t + 1, . . . , h
are known and we introduce a “worst case” estimate for the
ﬁrst unknown task’s deadline to be the tightest possible, since
τi min is the minimum feasible time per bit. Note that vh+1
is in fact unknown at time ˜xt, but we will see that this does
not affect our optimization process as the value of ˜dh+1 is
not actually required for analysis purposes. We point it out
that we do not have to worry about estimates for the unknown
tasks beyond h + 1 (this is because of the FCFS nature of our
system).

Therefore, the optimization problem the RH controller faces
at time ˜xt is over tasks t + 1, . . . , h with the added constraint
that they must all be completed by time ˜ah+1 = ˜xt + H. This
is equivalent to redeﬁning ˜di as

˜di =(cid:26)

di,

min(dh, ˜ah+1),

if t + 1 ≤ i ≤ h
if i = h

(13)

Our on-line RH control problem at decision point ˜xt will be
denoted by ˜Q(t + 1, h) and is formulated as follows:

˜Q(t + 1, h) :

s.t.

min

˜τt+1,...,˜τh Ph

i=t+1 viωi(˜τi)

˜τi ≥ 0, i = t + 1, . . . , h.
˜xi = max(˜xi−1, ai) + ˜τivi ≤ ˜di, ˜xt known.

where ˜di is deﬁned in (13). We also formulate the on-line RH
control problem with the maximum power constraint:

˜Q′(t + 1, h) :

s.t.

min

˜τt+1,...,˜τh Ph

i=t+1 viωi(˜τi)

˜τi ≥ τi min, i = t + 1, . . . , h.
˜xi = max(˜xi−1, ai) + ˜τivi ≤ ˜di, ˜xt known.

Step 3: Apply τt+1 min to task t + 1
END

Similar to the RH problem in [31], ˜Q(t + 1, h) may not be
feasible even if the off-line problem is feasible. This is due
to the worst-case estimation. One way of relaxing the worst-
case estimation is to use ˆh (deﬁned below), instead of h in ˜Q
above. Let

ˆxj = max(ˆxj−1, aj) + τj minvj ,
ˆxt = ˜xt, j = t + 1, . . . , h
S = {j : t + 1 ≤ j < h,
ˆxi ≤ min(di, aj+1) for all i, t + 1 ≤ i ≤ j}

ˆh = (cid:26) sup S,

∞,

if S 6= ∅,
otherwise

We then deﬁne ˆdi :

ˆdj =(cid:26)

dj ,

j = t + 1, . . . , ˆh − 1,

min(dj , ˜aj+1),

j = ˆh.

,

(14)

Table V: RH Control

In our simulation, all tasks have 512 bytes and a ﬁxed
deadline, i.e., di = ai + d. The value of d is set to 10s.
In each ﬁgure below, we run the experiment 1000 times,
and 500 tasks are executed in each run. The simulation is
performed on a PC with a third generation Intel Core i5-
3570K Ivy Bridge 3.4GHz Quad-Core Desktop Processor. To
quantify the deviation of the RH cost from the optimal off-line
cost, we deﬁne the cost difference as: (RH cost - optimal off-
line cost) / optimal off-line cost. The ﬁgures below plot the
average cost difference, worst-case cost difference, best-case
cost difference, and average calculation time versus the RH
window size H in seconds.

In Fig. 2, we consider Poisson arrivals with λ = 0.2.
With RH window size H varying from 1s to 11s, the cost
differences are well below 2%. When H becomes larger,
the cost differences are reduced; the calculation time per

0.015

e
c
n
e
r
e

f
f
i

d

 
t
s
o
C

0.01

0.005

0.03

e
c
n
e
r
e

f
f
i

d

 
t
s
o
C

0.025

0.02

0.015

0.01

Poisson arrivals, lambda=0.2

Average cost difference
Worst case cost difference
Best case cost difference
Average calculation time per task

)×10-3
1

d
n
o
c
e
s
-
i
l
l
i

m

(
 
k
s
a

t
 
r
e
p

 

e
m

i
t
 

n
o

i
t

0.5

l

a
u
c
a
c
 

l

2

4

6

8

10

RH window size H (seconds)

e
g
a
r
e
v
A

0

Fig. 2: Simulation Results of Poisson Arrivals

.
Bursty arrivals

Worst case cost difference
Average cost difference
Best case cost difference
Average calculation time per task

2

4

6

8

10

RH window size H (seconds)

)×10-3
8

d
n
o
c
e
s
-
i
l
l
i

6

4

2

0

m

(
 
k
s
a

t
 
r
e
p

 

e
m

i
t
 

n
o

i
t

l

l

a
u
c
a
c
 
e
g
a
r
e
v
A

Fig. 3: Simulation Results of Bursty Arrivals

task increases since at each decision point, the optimization
problem involves more tasks.

In the next experiment shown in Fig. 3, we consider
bursty arrivals with the burst interval uniformly distributed
over [8, 12]s, the number of tasks in each burst chosen from
{10, . . . , 20} with equal probability, and the task intervals
within the same burst uniformly distributed within [0, 1].
Although the cost differences are just slightly higher than those
in the Poisson case, the average calculation time per task is
now much larger. This is because in the bursty arrival case, a
large number of backlogged tasks are involved at each decision
point.

Our simulation results show that the proposed RH control
mechanism can not only guarantee feasibility when the off-line
problem is feasible, but also achieve near optimal solutions.

V. CONCLUSIONS

In this paper, we ﬁrst study the Downlink Transmission
Scheduling (DTS) problem. A simpler version of this prob-
lem has been studied in [2] and [9], where the MoveRight
algorithm is proposed. The MoveRight algorithm is an iterative
algorithm, and its rate of convergence is obtainable only when
the cost function is not task-dependent. Compared with the
work in [9] and [2], we deal with a much harder problem: i)
our cost function is task-dependent and ii) each task has its
own arrival time and deadline. This is essentially a hard convex

(15)

(16)

(17)

′

′

′

′

′

′

′

′

′

10

optimization problem with nondifferentiable constraints. By
analyzing the special structure of the optimal sample path, an
efﬁcient algorithm, known as the Generalized Critical Task
Decomposition Algorithm (GCTDA), is proposed to solve the
problem. Simulation results show that our algorithm is more
appropriate for real-time applications than the MoveRight
algorithm. Finally, we show that our results can be used in
on-line control to achieve near optimal solutions for Poisson
and bursty arrivals.

APPENDIX

Proof of Lemma 3.3: Since ωi(τ ) is strictly convex and

differentiable,

v1ω1(τ1) − v1ω1(τ

1) > v1(τ1 − τ

1) ˙ω1(τ

1)

v2ω2(τ2) − v2ω2(τ

2) > v2(τ2 − τ

2) ˙ω2(τ

2)

′

′

′

′

Because v1τ1 + v2τ2 = v1τ

′

1 + v2τ

2,

′

v1(τ1 − τ

1) = −v2(τ2 − τ

2) = C > 0

′

Summing (15) and (16) above, and using (17), we get:

v1ω1(τ1) + v2ω2(τ2) − v1ω1(τ

1) − v2ω2(τ

2) >

′

C( ˙ω1(τ

1) − ˙ω2(τ

2))

Since C > 0, and by assumption, ˙ω1(τ

′

1) − ˙ω2(τ

2) > 0,

v1ω1(τ1) + v2ω2(τ2) > v1ω1(τ

1) + v2ω2(τ

2). (cid:4)

∗

Proof of Lemma 3.4: We only prove part (i). Part (ii) can
n be the optimal solution.
i ) >
i+1). Because tasks i and i + 1 are within a single BP,
i > ai+1. Consider a feasible solution

be proved similarly. Let τ
By the deﬁnition of a left-critical task, we have ˙ωi(τ ∗
˙ωi+1(τ ∗
i ≥ ai+1. Suppose x∗
x∗
τ
k, . . . , τ

k , . . . , τ ∗

n, s.t.,

′

′

′

∗

j = τ
τ
i < τ ∗
τ

j , j 6= i, j 6= i + 1,
˙ωi(τ

i+1 > τ ∗

i , τ

i+1,

′

′

′

i ) > ˙ωi+1(τ

i+1)

′

′

Note that such a feasible solution always exists as long as
i+1 respectively.
i and τ
τ
From Lemma 3.3, we get:

i+1 are arbitrarily close to τ ∗

i and τ ∗

′

viωi(τ ∗

i ) + vi+1ωi+1(τ ∗

i+1) > viωi(τ

i ) + vi+1ωi(τ

i+1).

′

′

′

∗

j = τ

j , j 6= i, j 6= i + 1, using the above inequality,

Since τ
we get:

nXi=k

viωi(τ ∗

i ) >

nXi=k

viωi(τ

′

i ),

which contradicts the assumption that τ
solution. Therefore, x∗

i = ai+1. (cid:4)

∗

k , . . . , τ ∗

n is the optimal

Proof of Lemma 3.5: (i) Since ωm(τ ) is strictly con-
vex, continuous and differentiable, ˙ωm(τ ) is also continuous.
N E(i, j; t1, t2) has a feasible solution, because ˙ωm(τ ) is
continuous and monotonically increasing, and τ can take
any value in (0, ∞). Now, suppose there are two different
solutions to N E(i, j; t1, t2) : τi(t1, t2), . . . , τj(t1, t2) and
the common derivatives of
i (t1, t2), . . . , τ
τ
these two solutions are different. Without
loss of gener-
i,j (t1, t2), which means
ality, we assume σi,j (t1, t2) > σ

j (t1, t2). Then,

′

′

′

′

˙ωm(τm(t1, t2)) > ˙ωm(τ
the convexity of ωm(τ ), we obtain τm(t1, t2) > τ
for any m, i ≤ m ≤ j, and

m(t1, t2)), for any m, i ≤ m ≤ j. By
m(t1, t2),

′

jXm=i
jXm=i

τm(t1, t2)vm = t2 − t1 >

′

m(t1, t2)vm = t2 − t1,
τ

which is a contradiction. Therefore, N E(i, j; t1, t2) has a
unique solution.

′

(ii) Let σi,j (t1, t2), σi,j (t3, t4) be the common derivative
of N E(i, j; t1, t2) and N E(i, j; t3, t4) respectively, 0 <
= t4 − t3. Let τi(t1, t2), . . . , τj(t1, t2),
∆ = t2 − t1 < ∆
τi(t3, t4), . . . , τj (t3, t4) be the solution to N E(i, j; t1, t2) and
N E(i, j; t3, t4) respectively. We need to show σi,j (t1, t2) <
σi,j (t3, t4). Suppose σi,j (t1, t2) ≥ σi,j(t3, t4). Then, by
deﬁnition, we get
˙ωm(τm(t1, t2)) ≥ ˙ωm(τm(t3, t4)), for any
m, i ≤ m ≤ j. By the convexity of ωm(τ ), τm(t1, t2) ≥
τm(t3, t4), i ≤ m ≤ j. Therefore,

jXm=i
jXm=i

τm(t1, t2)vm = t2 − t1 = ∆ ≥

τm(t3, t4)vm = t4 − t3 = ∆

′

which contradicts our assumption that ∆ < ∆
. Therefore,
the common derivative of N E(i, j; t1, t2) is a monotonically
increasing function of ∆ = t2 − t1.

′

(iii) It can be easily checked that τi(t1, t2), . . . , τp(t1, t2)
and τp+1(t1, t2), . . . , τj(t1, t2) are the unique solutions
to N E(i, p; t1, t1 + Sip) and N E(p + 1, j; t1 + Sip, t2)
respectively. Therefore, by the deﬁnition of N E(i, j; t1, t2)
and σi,j (t1, t2), we have σi,p(t1, t1 + Sip) = σi,j(t1, t2) and
σp+1,j(t1 + Sip, t2) = σi,j (t1, t2), which implies σi,p(t1, t1 +
Sip) = σp+1,j(t1 + Sip, t2) = σi,j (t1, t2).

(iv) Let Sip be the same as in (iii). By assumption, cq 6= cr
∀q, r ∈ {1, 2, 3}, q 6= r. This implies that t3 6= Sip, otherwise
cq = cr. From the monotonicity of σi,j(t1, t2) shown in part
(ii), we get min(c1, c2) < c3 < max(c1, c2). (cid:4)

Proof of Lemma 3.6: Invoking Lemma 3.4, we get x∗

r =
dr. Suppose there are left-critical tasks in {k, . . . , r − 1} and
the closest left-critical task to r is task l, k ≤ l < r. Invoking
Lemma 3.4, x∗

l = al+1. By assumption,

σk,Lr (ak, aLr+1) ≤ σk,r(ak, dr).

Because l < r, from (7),

σk,l(ak, al+1) ≤ σk,Lr (ak, aLr +1).

From (18) and (19), the following must be true:

σk,l(ak, al+1) ≤ σk,r(ak, dr)

(18)

(19)

(20)

When the equality holds in (20), from (iii) of Lemma 3.5, we
get

11

When the inequality holds in (20), from (iv) of Lemma 3.5,
we obtain

σl+1,r(al+1, dr) > σk,r(ak, dr).

From (20) and the above inequality, we get

σl+1,r(al+1, dr) > σk,l(ak, al+1).

Combining (21) and (22), we get

σl+1,r(al+1, dr) ≥ σk,l(ak, al+1)

(22)

(23)

Since there is no right-critical or left-critical task in {l +
1, . . . , r − 1}, invoking Lemma 3.1, we get

˙ωs(τ ∗

s ) = ˙ωs+1(τ ∗
∀s ∈ {l + 1, . . . , r − 1}.

s+1) = σl+1,r(al+1, dr),

From the deﬁnition of left-critical tasks, we get

˙ωl(τ ∗

l ) > ˙ωl+1(τ ∗

l+1) = σl+1,r(al+1, dr).

(24)

We consider two cases:

Case 1: k = l. Then, σk,l(ak, al+1) = ˙ωl(τ ∗

l ). Inequalities

(23) and (24) contradict each other.

Case 2: k < l. We will use a contradiction argument to
show that there must exist a right-critical task m, k ≤ m < l,
i.e.,

˙ωm(τ ∗

m) < ˙ωm+1(τ ∗

m+1).

Suppose such a task m does not exist. i.e.,

˙ωm(τ ∗

m) ≥ ˙ωm+1(τ ∗

m+1), k ≤ m < l.

(25)

Let

ym =(cid:26) ak, m = k − 1

x∗
m m = k, . . . , l.

Inequality (25) is equivalent to the following:

σm,m(ym−1, ym) ≥ σm+1,m+1(ym, ym+1),

(26)

for m = k, . . . , l − 1.

We will use a recursive proof next:

Step 1: Letting m = k in (26), we have

σk,k(yk−1, yk) ≥ σk+1,k+1(yk, yk+1).

(27)

When the equality holds in (27), invoking part (iii) of Lemma
3.5, we get

σk,k+1(yk−1, yk+1) = σk+1,k+1(yk, yk+1).

(28)

When the inequality holds in (27), invoking part (iv) of Lemma
3.5, we get

σk,k+1(yk−1, yk+1) > σk+1,k+1(yk, yk+1).

Combining (28) and (29) above, we have

σk,k+1(yk−1, yk+1) ≥ σk+1,k+1(yk, yk+1).

Step 2: Letting m = k + 1 in (26), we have

(29)

(30)

σk+1,k+1(yk, yk+1) ≥ σk+2,k+2(yk+1, yk+2).

Combining (30) and the above inequality, we obtain

σl+1,r(al+1, dr) = σk,l(ak, al+1).

(21)

σk,k+1(yk−1, yk+1) ≥ σk+2,k+2(yk+1, yk+2).

Similarly to the derivation of (28), (29), and (30), we can get

σk,k+2(yk−1, yk+2) ≥ σk+2,k+2(yk+1, yk+2).

Repeating the process up to step l − k, we obtain

σk,l(yk−1, yl) ≥ σl,l(yl−1, yl).

Since task l is left-critical, from the deﬁnition of ym and
Lemma 3.4, yl = x∗
l = al+1, and the above inequality is
equivalent to

σk,l(ak, al+1) ≥ ˙ωl(τ ∗

l ).

(31)

From (31) and (24), we get

σk,l(ak, al+1) > σl+1,r(al+1, dr).

Invoking (iv) of Lemma 3.5, we obtain

σk,l(ak, al+1) > σk,r(ak, dr)

which contradicts (20). Therefore, there must exist a task m,
k ≤ m < l, s.t.,

˙ωm(τ ∗

m) < ˙ωm+1(τ ∗

m+1)

By Deﬁnition 1, task m is a right-critical task, which contra-
dicts our assumption that task r is the ﬁrst right-critical task
in {k, . . . , n}. Therefore, there is no left-critical task before
task r. (cid:4)

Proof of Lemma 3.7: We use a contradiction argument to
prove the lemma. Suppose there are right-critical tasks before
task Ri and the one with smallest index is task r, k ≤ r < Ri.
By assumption, σk,j (ak, dj) ≥ σk,Lj (ak, aLj +1), for all j,
k < j < i. When r > k, letting j = r, we have σk,r(ak, dr) ≥
σk,Lr (ak, aLr +1). Then we can invoke Lemma 3.6 to establish
that there is no left-critical task in {k, . . . , r − 1}. Since there
is also no right-critical task in {k, . . . , r − 1}, from Lemma
3.1,

˙ωs(τ ∗

s ) = σk,r(ak, dr), ∀s ∈ {k, . . . , r}.

(32)

Since k ≤ r < Ri, from (6), we have

σk,Ri (ak, dRi ) ≤ σk,r(ak, dr).

Then, from (ii) of Lemma 3.5,

σk,Ri (ak, x∗

Ri ) ≤ σk,Ri (ak, dRi ).

Combining (33) and (34), we get

σk,Ri (ak, x∗

Ri ) ≤ σk,r(ak, dr).

Since r is right-critical, from (32) and Deﬁnition 1,

σk,r(ak, dr) = ˙ωr(τ ∗

r ) < ˙ωr+1(τ ∗

r+1).

(33)

(34)

(35)

(36)

From (35) and (36), there must exist at least one left-critical
task in {r + 1, . . . , Ri − 1}; otherwise, from the deﬁnition
of a left-critical task in Deﬁnition 1 and a simple contradic-
tion argument, we have ˙ωs(τ ∗
s+1), ∀s ∈ {r +
1, . . . , Ri − 1}. Using this result, (36) and a similar method as
in obtaining (31), we can get σk,r(ak, dr) < σk,Ri (ak, x∗
Ri ),
which contradicts (35).

s ) ≤ ˙ωs+1(τ ∗

12

Let the left-critical task with smallest index be l. From
l = al+1. Similar to obtaining σk,r(ak, dr) <
) above, we can get

Lemma 3.4, x∗
σk,Ri (ak, x∗
Ri

σk,r(ak, dr) < σk,l(ak, x∗

l ) = σk,l(ak, al+1).

(37)

By assumption, σk,j (ak, aj+1) ≤ σk,Rj (ak, dRj ), and setting
j = l, we get

σk,l(ak, al+1) ≤ σk,Rl (ak, dRl ).

Since, from (6), we have σk,Rl (ak, dRl ) ≤ σk,r(ak, dr),
combining this and the above inequality, we obtain

σk,l(ak, al+1) ≤ σk,r(ak, dr)

which contradicts (37) and completes the proof. (cid:4)

Proof of Lemma 3.8: Suppose task Ri is not right-critical.

By assumption,

σk,Ri (ak, dRi) < σk,i(ak, ai+1),
Ri ≤ dRi , from (ii) of Lemma 3.5,

Because x∗

σk,Ri (ak, x∗

Ri ) ≤ σk,Ri (ak, dRi ).

From the two inequalities above, we obtain:

σk,Ri (ak, x∗

Ri ) < σk,i(ak, ai+1).

(38)

(39)

Invoking Lemma 3.7, there is no right-critical task before task
Ri. Next, we use a contradiction argument to show that there
must exist at least one right-critical task in {Ri, . . . , i − 1}.
Suppose there is no right-critical task in {Ri, . . . , i − 1}.
Because there is no right-critical task in {k, . . . , i − 1}, by
Deﬁnition 1, we have

˙ωm(τ ∗

m) ≥ ˙ωm+1(τ ∗

m+1), m = k, . . . , i − 1.

Let

ym =


m = k − 1

ak,
x∗
m, m = k, . . . , i − 1
ai+1, m = i

The above inequality can be rewritten as

σm,m(ym−1, ym) ≥ σm+1,m+1(ym, ym+1),

m = k, . . . , i − 1.

Similar to the way of obtaining (31) in proving Lemma 3.6,
we obtain

σk,Ri (ak, x∗

Ri ) ≥ σk,i(ak, ai+1),

which contradicts (39).

We showed there must exist at least one right-critical task in
{Ri, . . . , i − 1}. From the initial contradiction assumption, Ri
is not right-critical. When i = Ri + 1, the contradiction proof
is completed. Next, we consider the case when i > Ri + 1.

Let r be the closest right-critical task to Ri in {Ri, . . . , i −
1}. Since there is no right-critical task in {k, . . . , r − 1}, by
Deﬁnition 1,

˙ωm(τ ∗

m) ≥ ˙ωm+1(τ ∗

m+1), m = k, . . . , r − 1.

Let

ym =(cid:26) ak, m = k − 1

x∗
m, m = k, . . . , r

The above inequality can be rewritten as

σm,m(ym−1, ym) ≥ σm+1,m+1(ym, ym+1),

m = k, . . . , r − 1.

Similar to the way of obtaining (31) in proving Lemma 3.6,
we obtain

σk,Ri (ak, x∗

Ri ) ≥ σk,r(ak, x∗

r) = σk,r(ak, dr).

From the above inequality and (38), we obtain

13

i.e., the channel gain of task i is greater than that of task j.
Using (42), we get

˙ωi(τ ) > ˙ωj(τ ). (cid:4)

Proof of Lemma 3.9: Let us assume that there exists tasks
{p, . . . , q} (k < p ≤ q < n) in a BP {k, . . . , n} of the optimal
sample path of Q(k, n) such that
p−1 ≥ τp−1 min, τ ∗
τ ∗
τ ∗
i < τmin, i = p, . . . , q

q+1 ≥ τq+1 min,

(44)

σk,r(ak, dr) ≤ σk,Ri (ak, dRi )

From Assumption 1,

which contradicts the deﬁnition of Ri in (4), since Ri < r < i.
Therefore, task Ri must be right-critical. (cid:4)

Proof of Theorem 3.1: We only prove part (i). Part (ii) can
be proven similarly. The proof contains several steps: 1) using
(8), Lemma 3.6, and setting j = Ri, we conclude that there is
no left-critical task before Ri; 2) using (8), (9), and Lemma
3.7, we establish that there is no right-critical task before Ri;
3) using (8), (9), (10), and Lemma 3.8, it follows that Ri
is a right-critical task; and ﬁnally 4) combining the results
established in the previous steps 1)-3), we can obtain that Ri
is the ﬁrst critical task in {k, . . . , n}, and it is right-critical. (cid:4)
Justiﬁcations for Assumption 2: We only justify Part a).
Part b) can be justiﬁed similarly. Using Shannon’s theorem, τi
can be represented by the following equation:

τi =

1

B log2(1 + siP
N0

)

where B is the bandwidth of the channel, si
is the task-
dependent channel gain, P is the transmission power, and N0
is the power of the noise. Since siP
≫ 1 in typical scenarios,
N0
we can omit the 1 above and represent P in terms of τi :

P (τi) =

1

Bτi )

N0(2
si

(40)

We assume that the maximum transmission power of each task
is constant Pmax, and it determines τi min:

˙ωp−1(τ ∗
˙ωq+1(τ ∗

p−1) ≥ ˙ωp−1(τp−1 min),
q+1) ≥ ˙ωq+1(τq+1 min)

(45)

Let

z = arg min
i=k,...,n

τi min.

Because τi min ≥ τz min, we invoke Assumption 2 and get

˙ωi(τmin) ≤ ˙ωz(τmin), i = p, . . . , q

From Assumption 1 and (44), we have

˙ωi(τ ∗

i ) < ˙ωi(τmin), i = p, . . . , q

Combine (46) and (47) above, we have

˙ωi(τ ∗

i ) < ˙ωz(τmin), i = p, . . . , q

(46)

(47)

(48)

Because τp−1 min ≥ τmin, we invoke Assumption 2 and get

˙ωp−1(τp−1 min) ≥ ˙ωz(τmin)

(49)

Similarly, we use τq+1 min ≥ τmin and Assumption 2 to get

˙ωq+1(τq+1 min) ≥ ˙ωz(τmin)

Combining (45), (49), and (50), we have

˙ωp−1(τ ∗

p−1) ≥ ˙ωz(τmin) and ˙ωq+1(τ ∗
Then, we combine (48) and (51) to get

q+1) ≥ ˙ωz(τmin).

˙ωp−1(τ ∗

p−1) > ˙ωi(τ ∗

i ) and ˙ωi(τ ∗

i ) < ˙ωq+1(τ ∗

q+1),

Pmax =

N0(2

1

Bτi min )
si

i = p, . . . , q.

(41)

From the inequalities above, we have

Because

˙ωp−1(τ ∗

p−1) > ˙ωp(τ ∗

p ) and ˙ωq(τ ∗

q ) < ˙ωq+1(τ ∗

q+1).

ωi(τi) = P (τi)τi,

Invoking Lemma 3.4, we have

(50)

(51)

(52)

we use (40) and (41) to get

˙ωi(τi) = P (τi)(1 −

1
Bτi

) =

1

Bτi )

N0(2
si

(1 −

1
Bτi

)

˙ωi(τi)|τi=τi min = Pmax(1 −

1

Bτi min

)

Using (43) and τi min < τj min, we have

˙ωi(τi min) < ˙ωj(τj min).

Using (41) and τi min < τj min, we get

si > sj ,

(42)

(43)

Because x∗

q = x∗

i=p viτ ∗

i , we use (44) and (52) to get:

x∗
p−1 = ap and x∗

q = dq.

p−1 +Pq

x∗
q − x∗

p−1 = dq − ap =

viτ ∗
i

qXi=p
qXi=p

<

qXi=p

viτmin ≤

viτi min

For any feasible solution of Q′(k, n), we must have

qXi=p

viτ ′

i ≤ dq − ap ≤

qXi=p

viτi min,

which implies that there exists at least one τ ′
such that τ ′
is infeasible. (cid:4)

i , i = p, . . . , q,
i < τi min. This completes the proof that Q′(k, n)

Proof of Theorem 4.1: Because P2 is feasible, we have

′∗
i ≤ di.
x

′∗
To prove the theorem, we only need to show that ˜xi ≤ x
i
i = 1, . . . , N. We use induction to prove it.

for

1) When t = 0, we are at the ﬁrst decision point ˜x0 = a1.

We have two cases:

Case 1.1: We apply τ1 min to task 1. It is obvious that

˜x1 ≤ x

′∗
i .

i

1 ≤ d1.

′∗
1 . Therefore, ˜x1 = x′∗

problem ˜Q′(1, h). We have two subcases:

Case 1.2.2: We now consider the more interesting case

1 obtained in either Step 1
or Step 2 of Table V to task 1. Without loss of generality,
1 is obtained from Step 1 of Table V. In
i , i = 1, . . . , h, are the solution to ˜Q(1, h) and
is also the solution to

Case 1.2: We apply control eτ ∗
let us assume that eτ ∗
this case, eτ ∗
i ≥ τi min for all i. Therefore, eτ ∗
eτ ∗
eτ ∗
that di ≥ eai+1, i = 1, . . . , h. To compare the RH problem

Case 1.2.1: When the planning horizon contains the end of
a busy period on the optimal sample path, it is trivial that
1 = τ

and the off-line problem, we now add subscripts to indicate
the starting and ending times of each problem. In particular,
we use ˜Q′
a1,a1+H (1, h) to show that the starting transmission
time of ˜Q′(1, h) is a1 and the ending transmission time is
a1 + H. Similarly, we use Q′
(1, h) to show that the
starting transmission time of Q′(1, h) is a1 and the ending
′∗
h . Because ah+1 > a1 + H and
transmission time is x
′∗
dh ≥ a1 + H, we must have x
h ≥ a1 + H. Looking at
˜Q′
(1, h), they are exactly the same,
except that the ending transmission time of Q′
(1, h) is
potentially at a later time. Therefore, the optimal departure
time of any task in Q′
(1, h) must not be earlier than that
in ˜Q′

a1,a1+H (1, h), which means ˜x1 ≤ x′∗
1 .

a1,a1+H (1, h) and Q′

a1,x′∗
h

a1,x′∗
h

a1,x′∗
h

a1,x′∗
h

2) Suppose that the RH controller is at decision point ˜xt,

and ˜xt ≤ x′∗

t . We also have two cases:

Case 2.1: We apply τt+1 min to task t + 1. It is obvious that

˜xt+1 ≤ x′∗

t+1.

i

to problem ˜Q′(t + 1, h). We consider two subcases:

t+1 obtained in either Step 1
or Step 2 of Table V to task 1. Without loss of generality, let
t+1 is obtained from Step 1 of Table V. In
i , i = t + 1, . . . , h, are the solution to ˜Q(t + 1, h)
is also the solution

Case 2.2: We apply control eτ ∗
us assume that eτ ∗
this case, eτ ∗
i ≥ τi min for all i. Therefore, eτ ∗
and eτ ∗
task jǫ{t + 1, . . . , h} s.t. dj < eaj+1, we focus on tasks

Case 2.2.1: When the planning horizon contains the end of
a busy period on the optimal sample path, i.e., there exists

{t + 1, . . . , j}. In this case, the controls of these tasks on the
RH sample path are the solutions to problem ˜Q′
(t + 1, j),
and the control of these tasks on the optimal sample path of
P2 are the solutions to problem Q′
(t + 1, j). Looking
at ˜Q′
(t + 1, j), they are identical,
except that the starting transmission time of ˜Q′
(t + 1, j) is
(t + 1, j). Therefore,
potentially earlier than that of Q′

(t + 1, j) and Q′

t ,dj

t ,dj

˜xt,dj

˜xt,dj

˜xt,dj

x′∗

x′∗

x′∗

t ,dj

14

the optimal departure time of any task in ˜Q′
must be no later than that in Q′
˜xt+1 ≤ x′∗

t ,dj

(t + 1, j)
(t + 1, j), which means

˜xt,dj

x′∗

t+1.

x′∗

t ,x′∗
h

Case 2.2.2: di ≥ eai+1, i = t + 1, . . . , h. In this case, the

controls of tasks {t + 1, . . . , h} on the RH sample path are the
solutions to problem ˜Q′
˜xt,˜xt+H (t + 1, h), and the control of
these tasks on the optimal sample path of P2 are the solutions
(t + 1, h). Because ah+1 > ˜xt + H and
to problem Q′
′∗
dh ≥ ˜xt + H, we must have x
h ≥ ˜xt + H. Looking at
˜Q′
(t + 1, h), they are exactly the
same, except that both the starting and ending transmission
times of ˜Q′
˜xt,˜xt+H (t + 1, h) are potentially sooner than those
of Q′
(t + 1, h). Therefore, the optimal departure time of
any task in ˜Q′
˜xt,˜xt+H(t + 1, h) must be no later than that in
Q′

(t + 1, h), which means ˜xt+1 ≤ x′∗

˜xt,˜xt+H(t + 1, h) and Q′

t ,x′∗
h

t ,x′∗
h

x′∗

x′∗

t+1. (cid:4)

x′∗

t ,x′∗
h

REFERENCES

[1] T. D. Burd, T. A. Pering, A. J. Stratakos, and R. W. Brodersen, “A
dynamic voltage scaled microprocessor system,” IEEE Journal of Solid-
state Circuits, vol. 35, pp. 1571–1580, Nov. 2000.

[2] A. E. Gamal, C. Nair, B. Prabhakar, E. Uysal-Biyikoglu, and S. Zahedi,
“Energy-efﬁcient scheduling of packet transmissions over wireless net-
works,” in Proceedings of IEEE INFOCOM, vol. 3, 23-27, New York
City, USA, 2002, pp. 1773–1782.

[3] C. E. Shannon and W. Weaver, The Mathematical Theory of Communi-

cation. Urbana, Illinois: University of Illinois Press, 1949.

[4] B. E. Collins and R. L. Cruz, “Transmission policies for time varying
channels with average delay constraints,” in Proceedings of Allerton
Conference on Communications, Control, and Computing, Monticello,
IL, 1999.

[5] R. Berry, “Power and delay trade-offs in fading channels,” Ph.D. Disser-

tation, Massachusetts Institute of Technology, Cambridge, MA, 2000.

[6] B. Ata, “Dynamic power control in a wireless static channel subject to a

quality of service constraint,” Operations Research, vol. 53, 2005.

[7] ——, “Dynamic power control in a wireless fading channel subject to a

quality of service constraint,” submitted for publication.

[8] M. Neely, “Energy optimal control for time varying wireless networks,”

IEEE Trans. on Information Theory, vol. 52, pp. 2915 – 2934, 2006.

[9] E. Uysal-Biyikoglu, B. Prabhakar, and A. E. Gamal, “Energy-efﬁcient
packet transmission over a wireless link,” IEEE/ACM Transactions on
Networking, vol. 10, pp. 487–499, Aug. 2002.

[10] M. Zafer and E. Modiano, “Minimum energy transmission over a
wireless channel with deadline and power constraints,” IEEE Trans. on
Automatic Control, vol. 54, pp. 2841 – 2852, 2009.

[11] ——, “Delay-constrained energy efﬁcient data transmission over a
wireless fading channel,” in IEEE Information Theory and Applications
Workshop, San Diego, CA, USA, Jan-Feb 2007.

[12] ——, “Optimal rate control for delay-constrained data transmission over
a wireless channel,” IEEE Trans. on Information Theory, vol. 54, pp. 4020
– 4039, 2008.

[13] W. Chen, M. Neely, and U. Mitra, “Energy efﬁcient scheduling with
individual packet delay constraints: ofﬂine and online results,” in IEEE
Infocom, Anchorage, Alaska, USA, May 2007.

[14] W. Chen, U. Mitra, and M. Neely, “Energy-efﬁcient scheduling with
individual packet delay constraints over a fading channel,” ACM Wireless
Networks, vol. 15, pp. 601–618, 2009.

[15] M. Zafer and E. Modiano, “A calculus approach to energy-efﬁcient data
transmission with quality-of-service constraints,” IEEE/ACM Trans. on
networking, vol. 17, pp. 898–911, 2009.
[16] X. Wang and Z. Li, “Energy-efﬁcient

transmissions of bursty data
packets with strict deadlines over time-varying wireless channels,” IEEE
Trans. on Wireless Communications, vol. 12, pp. 2533–2543, 2013.

[17] M. I. Poulakis, A. D. Panagopoulos, and P. Canstantinou, “Channel-
aware opportunistic transmission scheduling for energy-efﬁcient wireless
links,” IEEE Trans. on Vehicular Technology, vol. 62, pp. 192–204, 2013.
[18] Z. Zhou, P. Soldati, H. Zhang, and M. Johansson, “Energy-efﬁcient
deadline-constrained maximum reliability forwarding in lossy networks,”
IEEE Trans. on Wireless Communications, vol. 11, pp. 3474–3483, 2012.

15

[19] F. Shan, J. Luo, W. Wu, M. Li, and X. Shen, “Discrete rate scheduling
for packets with individual deadlines in energy harvesting systems,” IEEE
Journal on Selected Areas in Communications, vol. 33, pp. 438–451,
2015.

[20] B. Tomasi and J. C. Preisig, “Energy-efﬁcient transmission strategies for
delay constrained trafﬁc with limited feedback,” IEEE Trans. on Wireless
Communications, vol. 14, pp. 1369–1379, 2015.

[21] X. Zhong and C. Xu, “Online energy efﬁcient packet scheduling with
delay constraints in wireless networks,” in IEEE Infocom, Phoenix, AZ,
April 2008.

[22] R. Vaze, “Competitive ratio analysis of online algorithms to minimize
packet transmission time in energy harvesting communication system,”
in IEEE Infocom, Turin, April 2013.

[23] L. Miao and C. G. Cassandras, “Optimal transmission scheduling for
energy-efﬁcient wireless networks,” in Proceedings of IEEE INFOCOM,
Barcelona, Spain, 2006, pp. 1–11.

[24] A. J. Goldsmith, “The capacity of downlink fading channels with
variable rate and power,” IEEE Transactions on Information Theory,
vol. 46, pp. 569–580, Aug 1997.

[25] R. R. Kompella and A. C. Snoeren, “Practical

lazy scheduling in
sensor networks,” in Proceedings of the 1st International Conference on
Embedded Networked Sensor Systems, Los Angeles, CA, 2003, pp. 280–
291.

[26] Y. C. Cho, C. G. Cassandras, and D. L. Pepyne, “Forward decomposition
algorithms for optimal control of a class of hybrid systems,” International
Journal of Robust and Nonlinear Control, vol. 11(5), pp. 497–513, 2001.
[27] P. Zhang and C. G. Cassandras, “An improved forward algorithm for
optimal control of a class of hybrid systems,” IEEE Trans. on Automatic
Control, vol. 47, pp. 1735–1739, 2002.

[28] L. Miao and C. G. Cassandras, “Optimality of static control policies in
some discrete event systems,” IEEE Transactions on Automatic Control,
vol. 50, pp. 1427–1431, Sep 2005.

[29] J. Mao, C. G. Cassandras, and Q. Zhao, “Optimal dynamic voltage scal-
ing in energy-limited nonpreemptive systems with real-time constraints,”
IEEE Trans. on Mobile Computing, vol. 6, no. 6, pp. 678–688, 2007.

[30] C. G. Cassandras and R. Mookherjee, “Receding horizon optimal control
for some stochastic hybrid systems,” in Proceedings of the 42nd IEEE
Conference on Decision and Control, vol. 3, Dec. 2003, pp. 2162–2167.
[31] L. Miao and C. G. Cassandras, “Receding horizon control for a class of
discrete-event systems with real-time constraints,” IEEE Transactions on
Automatic Control, vol. 52, pp. 825–839, May 2007.

