6
1
0
2

 
r
a

 

M
4
1

 
 
]

V
C
.
s
c
[
 
 

1
v
7
2
3
4
0

.

3
0
6
1
:
v
i
X
r
a

AutomaticDiscriminationofColorRetinalImagesusingtheBagofWordsApproachIbrahimSadekSupervisors:Professor.FabriceMeriaudeauAssociateProfessor.DésiréSidibéCentreUniversitaireCondorcetUniversitédeBourgogne,LeCreusot,FranceAThesisSubmittedfortheDegreeofMScErasmusMundusinVisionandRobotics(VIBOT)·2014·AbstractDiabeticretinopathy(DR)andagerelatedmaculardegeneration(ARMD)areamongthemajorcausesofvisualimpairmentworldwide.DRismainlycharacterizedbyredspots,namelymicroaneurysmsandbrightlesions,speciﬁcallyexudateswhereasARMDismainlyidentiﬁedbytinyyelloworwhitedepositscalleddrusen.Sinceexudatesmightbetheonlymanifestationoftheearlydiabeticretinopathy,thereisanincreasedemandforautomaticretinopathydiagnosis.Exudatesanddrusenmaysharesimilarappearances,thusdiscriminatingbetweenthemisofinteresttoenhancescreeningperformance.Inthisresearch,weinvestigativetheroleofbagofwordsapproachintheautomaticdiagnosisofretinopathydiabetes.Weproposedtouseasinglebasedandmultiplebasedmethodsfortheconstructionofthevisualdictionarybycombiningthehistogramofwordoccurrencesfromeachdictionaryandbuildingasinglehistogram.Theintroducedapproachisevaluatedforautomaticdiagnosisofnormalandabnormalcolorfundusimageswithbrightlesions.Thisapproachhasbeenimplementedon430fundusimages,includingsixpubliclyavailabledatasets,inadditiontoonelocaldataset.Themeanaccuraciesreportedare97.2%and99.77%forsinglebasedandmultiplebaseddictionariesrespectively.Imaginationismoreimportantthanknowledge....AlbertEinsteinContentsAcknowledgments81Introduction11.1Aimsandobjectives.......................................21.2ThesisStructure.........................................31.3ProjectPlanning.........................................32Background42.1EyeAnatomy...........................................42.1.1Retina...........................................52.2RetinalImagingTechniques...................................72.3ClinicalLesionsoftheRetina..................................82.3.1SoftExudatesorCottonWoolSpots(CWS).....................92.3.2HardExudates(HE)...................................92.3.3Drusen...........................................92.3.4Microaneurysms(MAs).................................92.3.5Hemorrhages(HEM)...................................92.4DiabeticEyeDiseases......................................102.5DiabeticRetinopathy.......................................112.5.1MildNonproliferativeRetinopathy...........................112.5.2ModerateNonproliferativeRetinopathy........................112.5.3SevereNonproliferativeRetinopathy..........................112.5.4ProliferativeRetinopathy................................112.5.5DiabeticMacularEdema................................1212.5.6AgerelatedMacularDegeneration...........................123StateofTheArt133.1AutomaticDetectionandClassiﬁcationofExudates.....................133.2AutomaticDetectionandClassiﬁcationofDrusen.......................163.3AutomaticDetectionandDiscriminationofDrusenandExudates..............184Methodology214.1Preprocessing...........................................224.1.1Intensitynormalization.................................234.2FeatureExtraction........................................234.2.1SpeededUpRobustFeatures(SURF).........................254.2.2Histogramoforientedgradients(HOG)........................274.2.3LocalBinaryPattern(LBP)..............................284.3CodebookGeneration......................................304.4FeatureEncodingandPooling..................................314.5Classiﬁcation...........................................325ResultsandDiscussion345.1DatasetsDescription.......................................345.1.1STARE..........................................345.1.2DRIVE..........................................355.1.3DRIDB..........................................355.1.4HEI-MED.........................................355.1.5MESSIDOR........................................365.1.6HRF............................................365.1.7ORNL...........................................375.2DatasetsDistribution......................................375.3ExperimentalResults.......................................385.3.1PerformanceusingSetBasatrainingsetandSetAasatestset..........395.3.2PerformanceusingSetAasatrainingsetandSetBasatestset..........416ConclusionandFutureWork436.1Conclusion............................................4326.2Futurework............................................44Bibliography493ListofFigures1.1Exudateexampleintheouterlayeroftheretina[4]......................11.2DrusenexamplewithinBruch’smembrane[5]..........................21.3Masterthesisplanning......................................32.1Electromagneticspectrum[7]...................................42.2Crosssectionofahumaneyeanatomy..............................52.3Schematicviewofretinalayersorganization[11]........................62.4Examplesofretinalimages;(a)healthy,(b)diabeticretinopathy,(c)agerelatedmaculardegeneration,(d)glaucomaretinalimages............................72.5AnOCTscanofanormalhumanmacula;(a)aframecapturedatthestartofthescanassistsinlocation,(b)anOCTofthespeciﬁedscanlocation,(c)colormaprepresentingthelogfunctionofthereﬂectivityencounteredbytheprobebeam.[17]...........92.6Typicalfundusimages;(a)normal,(b)hemorrhages,andhardExudates(c)softexudates,(d)neovascularization,(e)microaneurysms,(f)drusen.....................102.7Normalvisionandthesamesceneviewedbyapersonwithdiabeticretinopathy;(a)normalvision,(b)sceneviewedbyapersonwithdiabeticretinopathy[22]..............114.1Trainingﬂowchart.........................................214.2Testingﬂowchart..........................................224.3Intensitydistributionofasamplecolorfundusimage.Theimage’schannelsarerespectivelyred,blue,andgreenfromlefttoright..............................224.4(a)Normalimage,(b)drusenimage,(c)equalizednormalimage,and(d)equalizeddrusenimage................................................2344.5PreprocessingresultonadrusenimagefromtheSTAREdataset.(a)drusenimage,(b)enhancedredimage,(b)enhancedgreenimage,and(d)enhancedblueimage.Intheredandblueimage,thedrusen(insidetheredcircle)cannotbeidentiﬁedasoppositetothegreenimage.............................................244.6SURFanddenseSURFinterestpoints.(a)and(b)showSURFpointsonthegreenchannelofanexudateandadrusenimagerespectively.(c)showsdenseSURFpointsonanormalimage................................................244.7HOGdescriptors.Theimageisdividedintoblocksandahistogramisexecratedfromeachblock................................................254.8Integralimage[39].S1isthesumofpixelsinrectangleA,similarlyS2,S3,andS4showA+C,A+B,A+B+C+Drespectively..............................264.9LaplacianofGaussianapproximations[40].FirstrowrepresentssecondorderGaussianderivativesinthex,y,andxydirections,whilesecondrowshowscorrespondingweightedboxﬁlterapproximationsinthesamedirections........................264.10Orientationassignments[40].Whenthewindowmovesaroundtheorigin(60degrees)thecomponentsoftheresponsesarecollectedtoyieldthevectorsshowninblue.Thelargestsuchvectordeterminesthedominantorientation........................274.11Haarwaveletsanddescriptorcomponents[40].(a)Theleftﬁltercomputestheresponseinthexdirectionandtherighttheydirection.Weightsare1forblackregionsand-1forthewhite.(b)Thegreensquareencapsulatesoneofthe16subregionsandbluecirclesshowsthesamplepointsatwhichwaveletresponsesarecomputed..................274.12Histogramoforeintedgradients[http://www.vision.rwth-aachen.de].............284.13IllustrationofthebasicLBPoperator..............................294.14AnexampleofnewLBPoperatorcomputation.[http://www.scholarpedia.org/]......294.15Codebookgenerationusingk-meansclusteringalgorithm.{x1,x2,...,xM}arethefeaturesetsand{w1,w2,...,wK}representthevisualwords.....................304.16Singlebaseddictionaryexample.Thesetoffeaturesrepresentasingleimageinthetrainingdataset...............................................314.17Multiplebaseddictionaryexample.Thesetoffeaturesrepresentasingleimageinthetrainingdataset..........................................314.18SVMoptimalhyperplaneforasetof2D-points........................3255.1DrusenimagefromtheSTAREdatabase............................345.2NormalimagefromtheDRIVEdatabase............................355.3NormalimagefromtheDRIDBdatabase............................355.4TwoexamplesofnormalandexudateimagesfromHEI-MEDdatabase...........365.5ExudateimagefromtheMESSIDORdatabase.........................365.6NormalimagefromtheHRFdatabase..............................375.7TwodrusenexamplesofORNLdatabase............................375.8ConfusionmatrixofDSURFdescriptorsatK=70(testSetAVs.SetB)..........405.9ConfusionmatrixofmultiplebaseddictionaryatK=100(testSetAVs.SetB)......405.10AccuracyVs.visualwordsKforasingleandmultiplebaseddictionaries(testSetAVs.SetB).All:multiplebaseddictionariesapproach........................415.11ConfusionmatrixofHOGdescriptorsatK=100(testSetBVs.SetA)...........425.12ConfusionmatrixofmultiplebaseddictionaryK=100(testSetBVs.SetA)........425.13AccuracyVs.visualwordsKforasingleandmultiplebaseddictionaries(testSetBVs.SetA).All:multiplebaseddictionariesapproach........................426ListofTables2.1Diﬀerencesbetweenrodsandconesinahumanretina.....................52.2Diﬀerentfundusimagingmodalities[15].............................83.1Summaryofseveralmethodsusedtodiscriminatehardexudates,anddrusen.Thistableshowsresultsoftheimagebasedcriterion.However,[.]*representsalesionbasedcri-terion.State:thepaperusesmorethanonedataset,L:thelengthofthefeature,EX:Exudates,Dru:Drusen,SE:meansensitivity,SP:meanspeciﬁcity,AC:meanaccuracy,AUC:Areaunderthecurve,FCV:foldcrossvalidation,LOOCV:leaveoneoutcrossval-idation,NNs:neuralnetworks,KNN:K-nearestneighbour,SVM:supportvectormachine,LS:leastsquare,LDA:lineardiscriminantanalysis,DTW:dynamictimewrapping,GMP:generalizedmotionpatterns....................................205.1DatadistributionofSetAandSetB.MES1:MESSIDORsite1,MES2:MESSIDORsite2,andMES3:MESSIDORsite3.................................385.2TestSetAversusSetBusingdiﬀerentnumberofvisualwords................405.3TestSetBversusSetAusingdiﬀerentnumberofvisualwords................417AcknowledgmentsFirstofall,Iwouldliketoexpressmydeepgratitudetomysupervisorsandallthepeoplethathelpedinthisproject:Prof.FabriceMeriaudeau,Dr.DésiréSidibé.Thanks,fortheirsupport,guidanceandpatienceforthesuccessofthiswork.SpecialthanksshouldbegiventomyErasmusMundusmobilitygrantprogram(ErasmusMundusinComputerandRobotics-VIBOT).IwouldliketothanktheprogramcoordinatorDr.DavidFoﬁforhisguidanceandsupportthroughtheentireperiodofmymaster.Andlast,butnotleastimportant,veryspecialthanksgotomybelovedwifeLamees,parents,whosupportedandencouragedmeduringstressfulmoments.8Chapter1IntroductionAccordingtotheworldhealthorganization(WHO)diabetesmellitus(DM)isalifelongdisorderwhichtakesplaceeitherwhenthepancreasdoesn’tproducesuﬃcientinsulin(type1diabetes)orwhenthebodycannoteﬀectivelybeneﬁttheinsulinitproduces(type2diabetes).Insulinisahormoneproducedinthepancreasbybetacellsthatregulatesthelevelofbloodsugar.Hyperglycemia,orincreasedbloodsugarlevelcausesseriousdamagetobody’ssystem,includingdiabeticretinopathy.Themostimportantreasonsofdiabetesareincreasingage,overweight,andsedentarylifestyle.Duringtheﬁrsttwodecadesofdisease,approximatelyallpatientswithtype1diabetesandmorethan60%ofpatientswithtype2diabeteshaveretinopathy[1].Theprevalenceofdiabetesisestimatedtoincreasefrom2.8%to4.4%inthetimespanof2000−2030.Thetotalnumberofpeopleisprojectedtoincreasefrom171millionin2000to360millionin2030[2].Diabeticpatientscanpreventseverevisuallossbyattendingregulardiabeticeyescreeningprogramsandreceivingoptimaltreatments[3].Figure1.1:Exudateexampleintheouterlayeroftheretina[4].Diabeticretinopathy(DR)andagerelatedmaculardegeneration(ARMD)areamongtheleadingcausesofvisualimpairmentworldwide.DRoccursmostfrequentlyinadultaged(20−74)years,anditis1Chapter1:Introduction2characterizedbythepresenceofredlesions(microaneurysms)andbrightlesions(exudates)whichappearassmallwhiteoryellowishwhitedepositswithsharpmarginsandvariableshapeslocatedintheouterlayeroftheretina,theirdetectionisessentialfordiabeticretinopathyscreeningsystems.ARMDusuallyaﬀectspeopleover50yearsofage.Itiscausedbyadamagetothemacula,thesmallsensitiveareaoftheretinathatgivescentralvision(seeingﬁnedetailsandcolors),andcategorizedbydrusen,tinyyelloworwhitedepositsinaretinalayercalledBruch’smembrane.TheSeverityofARMDcanbecategorizedintothreeclasses:early,intermediate,andadvancedasdiscussedinSection2.5.TwoexamplesofexudateanddruseninahumanretinaareshowninFig.1.1andFig.1.2respectively.Figure1.2:DrusenexamplewithinBruch’smembrane[5].Insomepatientsbrightlesionssuchasretinalexudatescanbetheonlymanifestationsofearlydiabeticretinopathy.Thus,computeraideddetection(CAD)systemshavebeenproposedinordertodetectexudates.However,thesebrightlesionsmustbeidentiﬁedfromdrusenbecausetheysharecommoncharacteristics[6].ThisrepresentsachallengeforreadersorCADbasedscreeningsystemsdesignedforDRdiagnosis.Consequently,developingaCADsystemforreadingandanalyzingretinalimagesdecreasesobservationalunintentionalfailureandthefalsenegativeratesofophthalmologistsinterpretingtheseimages.1.1AimsandobjectivesTheaimofthisresearchworkistodesignasystemthatwillbeabletoidentifynormal,drusen,andexudatesincolorretinalfundusimagesusingthebagofwordsapproach(BOW),sincethereisafewapproachesintheliteraturedesignedforthispurpose.Thethesisoverviewisexplainedasfollows:•Imagepreprocessinginordertocorrectunevenilluminationandenhancecontrastbetweenlesionsintheretinaandotherstructures.•Extractingdiﬀerentfeaturesfromthetrainingset.•BuildingavisualvocabularyandﬁndingahistogramofwordfrequenciesinthevocabularyforconstructingtheBOWfeature.31.2ThesisStructure•Trainingaclassierandﬁndingthebestparametersbycarryingoutaclassclassiﬁcationwith10foldcrossvalidation.•Measuringtheperformanceofthesystem.1.2ThesisStructureThisthesisisstructuredasdiscussedbelow:1.Chapter1brieﬂydescribestheproblemstatementandtheobjectiveofthisproject.2.Chapter2brieﬂydescribesthehumaneyeanatomyandtheoverallarrangementofretinallay-ers,diﬀerentretinalimagingtechniques,clinicallesionsoftheretinai.e.cottonwoolspots,hardexudates,drusen,microaneurysms.Besides,diabetesmellitus,anddiabeticretinopathy.3.Chapter3presentsastateoftheartreview,diﬀerentmethodsusedtodiﬀerentiatebetweendrusenandexudates.4.Chapter4thestagesinvolvedinDRdiagnosisarediscussed.Thesestagesincludepreprocessing,lesionsclassiﬁcationusingtheBOWapproach.5.Chapter5providesresultsanddiscussion.6.Chapter6givesconclusionsandrecommendationsforthefuturework.1.3ProjectPlanningThedurationofthemasterthesisis4months,beginningat3rdofFebruary2014.Themasterplanningisorganizedasfollows:Figure1.3:Masterthesisplanning.Chapter2BackgroundThischapterisorganizedsuchas.Section2.1brieﬂydescribesthehumaneyeanatomyandtheoverallarrangementofretinallayers.Section2.2introducesdiﬀerentretinalimagingtechniques.Section2.3discussesclinicallesionsoftheretinai.e.cottonwoolspots,hardexudates,drusen,microaneurysms.Section2.4describesdiabetesmellitus.Section2.5presentsassociateddiabeticdisordersanditsmani-festations.2.1EyeAnatomyHumaneyeisresponsibleforthedetectionofvisiblelight,thepartoftheelectromagneticspectrumwithwavelengthsrangingapproximatelyfrom400to700nmasshowninFig.2.1.Thecolorofvisiblelightdependsonitswavelength.Forexample,violethasawavelengthof400nm,andredhasawavelengthof700nm[7].Figure2.1:Electromagneticspectrum[7].Apparently,mostpeoplewouldagreethatvisionismuchmorevaluablethanothersenseorganspresentinourbody,becauseweusuallyuseoureyesinalmostalldailyactivitiesweperform.Thereexistmanysimilaritiesbetweenthehumaneyeandacamera.Forinstance,inacamera,aﬁlmisused452.1EyeAnatomytorecordtheimage;intheeyetheimageisfocusedontheretina;alsoastheshutterinacamera,thepupilatthecenteroftheiriscontroltheamountoflightthatgetsthroughthelens[8].Figure2.2:Crosssectionofahumaneyeanatomy.Fig.2.2presentsacrosssectionofahumaneyeanatomy.Whenlightenterstheeye,itﬁrstcomesincontactwiththecornea.Thecorneaﬁltersandrefractsthelight,allowingtheimagetoconvergeinsidetheeyetoitswaytotheirisandpupil.Theiriswillconstrictordilate(widen)inordertoadjustthepupilsize,asaresultregulatingtheamountoflightthatcanentertheeye.Thelenscanchangeitsshapewiththehelpofauxiliarymusclesandbringobjectsintofocus,alsoitslightlyimprovesthealreadyreﬁnedimagefromthecorneaandprojectsitontotheretina[9].Thestructuresofretinaaremorerelatedtoourresearchworkamongtheseveralocularstructures,henceitwillbeelaboratedindepthasinSection2.1.1.2.1.1RetinaTheretinaisthelightsensitivetissuethatcoverstheinteriorsurfaceoftheeye.Thecorneaandlensfocuslightraysontheretina.Then,theretinaconvertsthelightreceivedintoelectricalimpulsesthataresentviatheopticnervetothebrainwhichinterpretsthemasimages.Thecorneaandlensintheeyebehavelikethecameralens,whiletheretinaisanalogoustotheﬁlm.Iftheimagesarenotfocusedproperly,theﬁlmorretinareceivesblurryimages.Theretinaconsistsoftwomainphotoreceptors;therodsandthecones[10].Table2.1showsthemaindiﬀerencesbetweentherodsandcones.RodsConesRequireaverylowleveloflighttogeneratesignals.Requireahigherleveloflighttogeneratesig-nals.Approximately125millionsphotoreceptors.Approximately6millionsphotoreceptors.Specializedforlowlightvision.Mediatedaylightandcolorvision.Distributedintheperipheryoftheretina.Concentratedinthefovea,whichliesinthecenterofthemacula.Table2.1:Diﬀerencesbetweenrodsandconesinahumanretina.Chapter2:Background6TheretinacanbedividedintomanydistinguishablelayersasshowninFig.2.3.Figure2.3:Schematicviewofretinalayersorganization[11].Thediﬀerentlayersofretinaareorganizedasfollows[12]:1.TheInnerLimitingMembrane(ILM)istheboundarybetweenvitreousbodyandtheretina.2.GanglionCellLayer(GCL)encompassesthecellbodiesandaxonsoftheganglioncells.3.InnerPlexiformLayer(IPL)comprisesthesynapsesbetweenbipolar,amacrine,andganglioncells.4.InnerNuclearLayer(INL)involvesbipolarcell,horizontalandamacrinecellbodies.5.OuterPlexiformLayer(OPL)consistsofbipolarcells,horizontalandreceptorsynapses.6.OuterNuclearLayer(ONL)containsthenucleiofphotoreceptor.7.OuterLimitingMembrane(OLM)comesintocontactwiththebaseoftheinnersegmentsofphotoreceptor.8.PhotoreceptorLayercontainstheinnerandoutersegmentsofphotoreceptors.9.ThePigmentEpitheliumLayeristheoutermostlayeroftheretinabecomposedofpigmentedcuboidalcellsthatcontainMelanin.Melaninistheblackpigmentwhichabsorbsanyexcesslightthatisnotcapturedbytheretinaandpreventsitfromreﬂectionbacktotheretina.Thus,protectsthephoto-receptorsfromdamagingleveloflight.Thepigmentepitheliumcellsprovidenutritionsuchasglucose,andessentialionstophotoreceptors.72.2RetinalImagingTechniquesTheganglioncellsareatypeofneuronreceivingvisualinformationfromphotoreceptorsthroughtwointermediateneurons(horizontal,andamacrine).Thehorizontalcellswhichareinterconnectingneurons,helpintegrateandregulatetheinputfrommultiplephotoreceptorcells.2.2RetinalImagingTechniquesRetinalimagesareacquiredbyhighlyspecializedcameracalledfunduscamera.Asamatteroffact,retinalimagesplayanimportantroleindiagnosingseveraleyediseasessuchasdiabeticretinopathy,glaucoma,andagerelatedmaculardegeneration.Formanyyears,ophthalmoscopy,fundusphotography,ﬂuoresceinangiography,anddiagnosticultrasoundwereconsideredtheonlyretinalimagingmodalities.Recently,diﬀerenttechniqueshavebeenintroducedincludingindocyanineangiography,opticalcoherencetomography(OCT),scanninglaserophthalmoscopy(SLO),andinfraredimaging.Additionally,digitaltechnologypermitseasydataprocessingandstorageaswellasworldwideimagesexchange[13].(a)(b)(c)(d)Figure2.4:Examplesofretinalimages;(a)healthy,(b)diabeticretinopathy,(c)agerelatedmaculardegeneration,(d)glaucomaretinalimages.Typically,ophthalmoscopy(fundoscopy)isusedtodeterminethehealthoftheretinaandvitreoushumor.Therearetwotypesofophthalmoscopes:directandindirect.Theﬁrst,isaninstrumentaboutthesizeofasmallﬂashlightwithseverallensesandamagniﬁcationupto15times.Thesecond,isprovidedwithalightattachedtoaheadwhichcanprovideawiderviewoftheinsideoftheeye.FundusPhotographyisfrequentlyusedtocreateapictureoftheinteriorsurfaceoftheeye,involvingtheretina,opticdisc,andmaculathroughthedilatedpupilofthepatientinordertoenhancethequalityoftheimage.Ithelpstransferimagesvianetworksforremoteviewingbyspecialistsortrainedmedicalprofessionals.Inaddition,itallowsforlargescalescreeningprogramswhichisakeyinpreventingdia-beticretinopathyandinducedvisiondeteriorationthatcanleadtoblindness.Afunduscameraisalowpowermicroscopewithanattachedcamerawhichprovidesanuprightmagniﬁedviewofthefundus.Anangleof30◦,consideredthetypicalangleofview,creates2.5xmagniﬁcation.Wideanglefunduscamerascaptureimagesbetween45◦to140◦andprovidelessmagniﬁcation.Whereas,anarroweranglefunduscamerashave20◦orlessangleofview[14].Fig.2.4showsdiﬀerentexamplesofretinalfundusimages.Accordingto[15]fundusimagingcanbedeﬁnedasanyprocessinvolving2Drepresentationofthe3Dretinalstructuresprojectedontotheimageplaneandobtainedusingreﬂectedlight,suchthatim-ageintensitiesrepresenttheamountofreﬂectedquantityoflight.Furthermore,techniques/modalitiesbelongingtofundusimagingaregroupedtogetherasdiscussedinTable2.2.Chapter2:Background8NameDescriptionFundusPhotographyAtaspeciﬁcwavelength,imageintensitiescor-respondtotheamountofreﬂectedlight.Thisincludesredfree,wheretheredcolorisﬁlteredoutfromtheimaginglight,enhancingcontrastofvesselsandotherstructures.ColorFundusPhotographyTheretinaisfullyexaminedincolorbymeansofwhitelightillumination.Subsequently,im-ageintensitiesrepresenttheamountofre-ﬂectedred,green,andbluewavebands.StereoFundusPhotographyAllowsdepthestimationbyexploitingtwoormorediﬀerentviewangles.HyperspectralImagingProducesmultiplespeciﬁcwavelengthbands.Potentialdiseasesmaybeindicatedbymoni-toringoxygenconsumptionintheretina.ScanningLaserOphthalmoscopy(SLO)Providessharpretinalimagesbyasinglewave-lengthlaserlightobtainedsequentiallyintimewhichcanreachthesurfaceoftheretinaandrecordsitssurfacedetails.AdaptiveOpticsScanningLaserOphthal-moscopy(AOSLO)Opticallightiscorrectedbymodelingthede-viationinitswavefront.FluoresceinAngiographyImageintensitiesconstitutetheamountsofemittedphotonsfromphotosensitivemateri-alsi.e.ﬂuoresceinorindocyaninegreenﬂuo-rophoreinjectedintothepatientbloodstream.Table2.2:Diﬀerentfundusimagingmodalities[15].Ophthalmicultrasound,becomesincreasinglyimportantwhendoctorscannotseetheretinaduetobleedinginsidetheeye,severecataract,orcornealscarring.Thistechniqueissimilartotypicalultra-soundusedtoscandiﬀerentorgansofhumanbody,soundwavesaresentfromaprobeplacedontheeyetoprovidesonarimagesoftheinsideoftheeye[16].Essentially,opticalcoherencetomography(OCT)isbasedonthefundamentalsoflowcoherenceinterferometry,inordertomeasuretheechotimedelayoftheback-scatteredlightinthesampleinthesamemannerasA-Scanultrasoundacquisition.Atemporallyandspatially,lowcoherentbeamoflight(generatedfromlaserdiode)splitintotwodisjointpathsoneisdirectedintothesample,whiletheotherisdirectedintoareferencemirror(atknown,butvariabledistancefromthesource).Lightfrombothbeamsarethenreﬂectedandoverlapwithingaﬁber-opticinterferometer[17].Fig.2.5showsanexampleofanOCTimageofanormalhumanmacula.2.3ClinicalLesionsoftheRetinaInthissection,twogroupsofretinaldiseaseswillbediscussed:yellowwhitespots,andredspots.Theformer,includescottonwoolspots,hardexudates,anddrusen.Thelatter,consistsofmicroaneurysms,andhemorrhages[18,19].92.3ClinicalLesionsoftheRetinaFigure2.5:AnOCTscanofanormalhumanmacula;(a)aframecapturedatthestartofthescanassistsinlocation,(b)anOCTofthespeciﬁedscanlocation,(c)colormaprepresentingthelogfunctionofthereﬂectivityencounteredbytheprobebeam.[17].2.3.1SoftExudatesorCottonWoolSpots(CWS)SoftExudatesorCottonWoolSpotsappearaswhite,featheryspotswithfuzzyborders.CWSphysicallycorrespondtosmallretinalclosures(infarcts)andswellingsoftheretinalnerveﬁberlayerbecauseofmicrovasculardiseases.Theyarelocatedinthesuperﬁcial(inner)retina,sotheymayobscurenearbyvessels.Fig.2.6(c)showsanexampleofsuchlesions.2.3.2HardExudates(HE)HardExudatesarelipoproteinandotherkindsofproteinoriginatingfromleakingmicroaneurysms.HEappearassmallwhiteoryellowishwhitedepositswithsharpedges,irregularshape,andvariablesizeaspresentedinFig.2.6(b).Thephysicallocationsoftheselesionsaredeeperintheretinathancottonwoolspots.2.3.3DrusenDrusenarevariablesizedyellowishlipoproteinaceousdepositsthatformbetweentheretinalpigmentedepithelium(RPE),andBruch’smembrane.Usually,drusenalonedonotcontributetovisionloss.However,anincreaseinthesizeornumberofsuchlesionsaretheearliestsignsofagerelatedmaculardegeneration(ARMD).Fig.2.6(f)showsanexample.2.3.4Microaneurysms(MAs)Microaneurysmsareamongtheearliestnoticeableindicationofretinaldamage.MAsappearassmall,roundanddarkreddotsontheretinalsurfacethathavesharpmargins.Bydeﬁnition,theirsizesarelessthemainopticveinsastheycrosstheopticdisc.Theyarethephysicaldilation(weakening)ofthecapillarywallswhichstimulatethemtoleakages.Fig.2.6(e)showsanexampleoftwoMAslesions.2.3.5Hemorrhages(HEM)Hemorrhageshappenduetoleakageofweakcapillariesi.e.bleedingundertheconjunctivawhichistheoutermostprotectivelayeroftheeyeball.Generally,theyhaveseveralshapessuchasdot,blot,andﬂame.HEMaredescribedasredspotswithuneven,orindistinctedgesandcoloring.TheirsizesaregreaterthanMAssizesasshowninFig.2.6(b).Chapter2:Background10(a)(b)(c)(d)(e)(f)Figure2.6:Typicalfundusimages;(a)normal,(b)hemorrhages,andhardExudates(c)softexudates,(d)neovascularization,(e)microaneurysms,(f)drusen.Neovascularization,istheabnormalgrowthofnewbloodvesselsontheinnersurfaceoftheretinaasshowninFig.2.6(d)inanattempttocompensateforthelackofoxygensupplywheresuchareasofretinasendsignalstostimulatethegrowthofnewbloodvesselsinordertoreestablishthesupplyofoxygen.Thesebloodvesselsarefragileandtendtobleedintovitreouscavity.Asaresult,visioncanbeobscured.2.4DiabeticEyeDiseasesDiabetesmellitus(DM)isamajormedicalproblemthroughouttheworld,thatcanbeidentiﬁedasachronicconditionconnectedwiththeimpairedmetabolismofglucoseasaresultofinsulindeﬁciencyoritsresistance.Diabetescausesawidevarietyoflongtermsystemiccomplicationsthatcanaﬀectheart,bloodvessels,nerves,eyesandkidneys[20].Thenumberofpeoplewithdiabetesisprojectedtoincreasefrom2.8%to4.4%inthetimespanof2000−2030[19],moreoveritisthecommoncauseof112.5DiabeticRetinopathylegalblindnessinindividualbetween20and65yearsofageintheunitedstates.Diabeticretinopathyanddiabeticmacularedemaarethemostwidespreadophthalmiccomplicationscausedbydiabetes.2.5DiabeticRetinopathyDiabeticretinopathy(DR)isamicrovascularcomplicationthatcausesdamagestobloodvesselssupplyingtheretinaandisaleadingcauseofseverevisionlossinpeoplewithdiabetesifnotproperlytreated[21].Usually,itdamagesretinasinbotheyes.However,earlydiagnosisandpropertreatmentcanminimizevisionloss.Fig.2.7(a)and(b)showtwodiﬀerentscenesviewedbyanormalpersonandapersonsuﬀeringfromdiabeticretinopathyrespectively.DRcanbeclassiﬁedintofourstagesasfollows[23]:(a)(b)Figure2.7:Normalvisionandthesamesceneviewedbyapersonwithdiabeticretinopathy;(a)normalvision,(b)sceneviewedbyapersonwithdiabeticretinopathy[22].2.5.1MildNonproliferativeRetinopathyThefeaturesofmildnonproliferativeretinopathyaresomeoftheearliestsignsofdiabeticretinopathy.Atthispoint,microaneurysmsoccuralongwithhemorrhagesandcottonwoolspots.Itisworthpointingoutthatnotallpatientswillnoticeachangeintheirvision.2.5.2ModerateNonproliferativeRetinopathyManymoremicroaneurysms,hemorrhages,andcottonwoolspotsappear,Inadditiontofurtherdamagetoretinalbloodvessels.Subsequently,thebloodﬂowtothesurroundingretinaltissueisreducedgivingrisetovisionloss.2.5.3SevereNonproliferativeRetinopathyAtthisstage,largeareasoftheretinaaredeprivedofbloodﬂow.Asaresult,theseareasoftheretinasendsignaltothebodyinordertoproducenewbloodvesselstoenhancenourishment.2.5.4ProliferativeRetinopathyProliferativeretinopathyisthemoreadvancedmodesofdiabeticretinopathy.Atthisadvancedstage,newbloodvesselsstarttogrowastheretinasendssignaltothebodyfornourishmentenhancement.Thesenewbloodvesselsareabnormalandfragilewhichgrowalongtheretinaandotherpartsoftheeye.Thesebloodvesselsdonotattributesymptomsorvisionlossbythemselves.However,theirwallsarethinandfragile,whenevertheyleakbloodseverevisionlossandevenpermanentblindnesscanoccur.Chapter2:Background122.5.5DiabeticMacularEdemaMacularedema(ME)correspondstoaccumulationofﬂuidandproteinwithintheretina,speciﬁcallyinthetheouterplexiformandinnernuclearlayers,asanon-distinctresponsetoabreakdowninthebloodretinalbarriers.MEisthemainreasonofcentralvisionlossinpatientswithdiabetesmellitusandpatientsfollowingintraocularoperations[24].Accordingto[25]MEoccursifoneofthefollowingconditionsisfulﬁlled:1.Thereexistsswelling/thickeningoftheretinaincludingthecenteroftheretina(macula)ortheareawithin500µofit.2.Hardexudatespresentatorwithin500µofthecenteroftheretinawithswellingoftheadjacentretina.3.Ifthereiszoneorzonesofretinalswelling/thickening1diskareaorlargerinsize;anypartofwhichiswithin1diskdiameterofthecenterofthemacula.2.5.6AgerelatedMacularDegenerationAgerelatedmaculardegeneration(AMDorARMD)isacommoneyeconditionthatgenerallyaﬀectsolderadultandcausesalossofvisioninthemaculaowingtodamageoftheretina.Ablurredareanearthemaculaisafrequentmanifestation.Inthelongrun,thisblurredareamaybecomelarger,orblankspotsmaybedevelopedincentralvision.AMDoccursinthreediﬀerentformsdependingonthenumberandsizeofdrusenundertheretina.1.EarlyAMD.Generally,peoplewithearlyAMDdon’thavevisionloss,andmediumsizeddrusenarecommonsigns.2.IntermediateAMD.IntermediateAMDmaycausesomevisionloss.Largedrusen,pigmentchangesintheretinaorbotharetypicallyfoundinpeopleaﬀectedbyintermediateAMD.3.LateAMD.TherearetwotypesoflateAMD,Dryandwet.Theformer(geographicatrophy),isaprogressivedamageofthelightsensitivecellsinthemaculawhichmayleadtocentralvisionloss.Thelatter(neovascular),ischaracterizedbyabnormalbloodvesselsgrowthunderneaththeretinathatcanleakﬂuidandblood,blurringordistortingcentralvision.Asaconclusion,thischaptersummarizedthehumaneyeanatomyaswellastheoverallarrangementofretinallayers.Italsodiscussedretinalimagingmodalities,clinicallesionsoftheretina,anddiabeticdiseases.Thenextchapterreviewstheliteratureregardingdiﬀerentmethodsusedtodiscriminatebetweendrusenandexudates.Chapter3StateofTheArtThegrowingprevalenceofdiabetesworldwideincreasesthenumberofcasesthatneedtobereviewedbyophthalmologists.Additionally,thehighcostofphysicalexaminationandlackofprofessionalexpertspreventalotofpeoplefromreceivinganadequatetreatment.Computeraideddetection(CAD)systemsofretinallesionsassociatedwithdiabetescanoﬀermanyinterestingbeneﬁtsbothinscreeningandclinicalsetting.Intheformer,itcangivetheopportunitytoinvestigatealargenumberofimages.Inthelatter,typicalexaminationcostscanbereducedasaconsequenceofreducingtheworkloadoftrainedgraders.Inliterature,awidevarietyofCADsystemstodetectretinalfeaturesandlesionsinvolvethreemainsteps.Theﬁrststepisthepreprocessinginordertocompensateforgreatvariabilitybetweenandwithinretinalimages.Greenchannelisconsideredthemostpreferablechoice,becauseitprovidesamaximumcontrastbetweendiﬀerentretinallesionsandstructures.Thesecondstepistoextractcandidatelesions,insomeapproachesfeatureselectionproceduremaybeperformedtoremoveredundantfeatures.Thelaststepistoclassifycandidatelesionsintonormalorabnormal.Table3.1summarizesdiﬀerentapproachesusedtoclassifyimageswithbrightlesionssuchasdrusenandexudatesintermsofpreprocessing,methodology,features,classiﬁcation,thesizeofthedataset,performancemeasurements(sensitivity,speciﬁcity,accu-racy,andareaunderthecurve).Thischapterisorganizedasfollows:Section3.1discussessomemechanismstodetectandclassifyexudates,Section3.2discussesafewschemesinordertodetectandclassifydrusen,whilethelastSection3.3willdeliversomediscussionaboutthediﬀerentmethodsusedtodiﬀerentiatebetweendrusenandexudates.3.1AutomaticDetectionandClassiﬁcationofExudatesThepaperintroducedbyGarcíaetal.[26]isbasedonaneuralnetworktoextracthardexudatesfromcolorfundusimages.Theproposedmethodcomposedofprepossessing,segmentation,andclassiﬁcationusesthreeneuralnetworkclassiﬁersincludingmultilayerback-propagation(MLP),radialbasisfunction(RBF),andsupportvectormachine(SVM).Luminosityandcontrastnormalizationhavebeenperformedonthegreenchannelasapreprocessingstep.Next,theenhancedimageissubjectedtoacombinationofglobalandlocaladaptivehistogramthresholdinginordertoﬁndcandidateexudateregionsthathaveto13Chapter3:StateofTheArt14beclassiﬁedlater.Priortoclassiﬁcationtheopticdiskisremovedsinceitscharacteristicsaresimilartoexudatelesions.Atotalof117imagesareused,thetrainingsetconsistsof50images.Aftersegmentationanumberofregionsareextracted,thengivenlabelsbyexpertsasexudateornonexudate.Inthisway,theyhavecreatedafullylabeledgroundtruthdatasettotraintheclassiﬁerswiththese50images.Thetestsetcontains67images(27arehealthyretinasand40areDRpatients).Theyhaveselected18featuresincluding(1-6)meanandstdoftheRGBvaluesinsidetheregion,(7-12)meanandstdoftheRGBvaluesofthepixelsbelongingtoarectangularareaaroundtheregion(5pixelsdistance),(13-15)RGBvaluesoftheregion,(16)regionsize;thenumberofpixelsinsidetheregion,(17)regioncompactness;theratiobetweenthesquareoftheperimeterandtheareaoftheregion,inthissituationaboundarytrackingalgorithmisneeded,(18)regionedgestrength;theaverageofedgevaluesintheperimeteroftheregion,insuchcasePrewittoperatorisrequired.Tenfoldcrossvalidationisconductedtoassessthegeneralizationabilityofthenetwork,aswellastwocriteriaarefollowedforﬁnalclassiﬁcation;imagebasedcriterionwhichistheabilityofthealgorithmtoseparatepathologicalimagesfromnormalimages.lesionbasedcriterionwhichisthenumberofexudatesintheimagesthatarecorrectlydetected.Usingalesion-basedcriterion,theyobtainedameansensitivity(SE)of88.14%andameanpositivepredictivevalue(PPV)of80.72%forMLP.WithRBFtheyachievedSE=88.49%andPPV=77.41%,whiletheyreachedSE=87.61%andPPV=83.51%usingSVM.Withanimagebasedcriterion,ameansensitivity(SE)of100%,ameanspeciﬁcity(SP)of92.59%andameanaccuracy(AC)of97.01%wereachievedwithMLP.UsingRBFtheyreachedSE=100%,SP=81.48%andAC=92.54%.WiththeSVMtheimagebasedresultswereSE=100%,SP=77.78%andAC=91.04%.Adetectionandclassiﬁcationapproachofdiabeticmacularedema(DME)severityisintroducedbyDeepaketal.[27].HEcanbeconsideredasastandardmanifestationtoassessDME,wheretheseverityoftheriskisevaluatedonthebasisoftheproximityoftheHEtothemacula.Thedetectionpartisachievedthroughasupervisedlearningapproachonnormalimages,insuchcaseanydeviationfromthenormalcharacteristicsmightbeanindicationofabnormality.Thecenterofthemaculaisautomaticallydetected,afterthattheregionofinterest(ROI)isextractedbyﬁttingthebestcirclewithinthefundusmaskwithmaculaatthecenter,moreovertheopticisremoved.TheyhaveproposedtogeneratemotionpatternswithinROIsinceHEmaycauseabrightsmearpattern,whereasthetexturedbackgroundwillbesmoothedout.InordertocreateamotionpatternimageIMP,rotatedversionsofagiveninputimagearegenerated,thentheserotatedimagesarecombinedusingameanoramaximumfunctiontofuseallintensitiesateachpixellocation.RadonbasedfeaturesareextractedfromtheimageIMPatdiﬀerentanglesandthedesiredfeaturevectorthenisconstructedbyconcatenatingtheresponsesfordiﬀerentorientations.Subsequently,usingasingleclassclassiﬁereachimagecanbeclassiﬁedasnormalorabnormalhardexudateimage.Diseaseseverityisassessedviaarotationalasymmetrymetric,suchthatinnormalcasesthemaculaisrelativelydarkerthanotherregionsandcharacterizedbyarotationalsymmetry.However,abnormalcasesshowasymmetrycharacteristicsaroundthemacula.WithintheROIeightangularsampleswereusedtocreateeightpatchesandahistogramof10binsiscreatedforeachpatchwhichiscalledthesymmetrymeasure.Finally,atagiventhreshold,eachROIcanbeassessedasmoderateorsevereriskofDME.Theyhaveusedimagesfromfourdiﬀerentpubliclyavailabledatasets153.1AutomaticDetectionandClassiﬁcationofExudatesasfollows:HEI-MED1,MESSIDOR2,Diaretdb3,andDiaretdb14.Intotal,theyare644imagesofwhich367arenormaland277areabnormalimages.TenfoldcrossvalidationisperformedinordertoensuretheresultofDMEassessment.Thedetectionsensitivityis100%withspeciﬁcitybetween74%and90%.Immediatereferralcasesaredetectedwithasensitivityof100%andspeciﬁcityof97%.Theseverityclassiﬁcationaccuracyis81%forthemoderatecasesand100%forseverecases.AnautomaticmethodforidentiﬁcationofretinalHEincolorfundusimagesisproposedbyOsarehetal.[28].Theproposedpreprocessingcombinestwosteps;imagenormalizationviahistogramspeciﬁcationandlocalcontrastenhancement.Theideaistoselectareferenceimage,thenadjustthevaluesofeachimagesuchthatitsfrequencyhistogrammatchesthereferenceimagedistribution.Inthenextstep,localcontrastenhancementisappliedinordertodistributethevaluesofpixelsaroundthelocalmean.ThisoperationisperformedontheintensitychannelafterconvertingRGBimagesintoHSIcolorspace.ThepreprocessedimagesaresegmentedbyfuzzyC-means(FCM)clusteringalgorithm.Atotalof18featuresareextractedinthesamemanneras[26],butwithdiﬀerentcolorspaces.Intheﬁnalstage,athreelayerperceptronneuralnetworkisusedfortheclassiﬁcationpurposewith18inputnodes(selectedfeaturespace),15hiddenunits,andasingleoutputnode.Theyhaveused75colorimages,including25normaland50abnormalimagesfortraining.Theoutputofthesegmentationcontainsanumberofexudateandnonexudateregions,whicharelabeledbymedicalexpertstoobtainafullylabeledtrainingdataset.Inordertoinvestigatethediagnosticperformanceofthesystem,67colorimageswereused.Theproposedsystemisabletoachieve95.0%sensitivityand88.9%speciﬁcityforimagebasedclassiﬁcation,and93.0%sensitivityand94.1%speciﬁcityregardinglesionbasedclassiﬁcation.ThemethodproposedbyGiancardoetal.[29]fortheDMEdiagnosisisbasedontheclassiﬁcationofasinglefeaturevectorperimage,wherethisfeaturevectorisfoundonthreetypesofanalysis:theexudateprobabilitymap,thecolor,andwaveletanalysis.Intheﬁrsttypeofanalysis,thegreenchannelbesidestheintensitychannelfromtheHSIcolorspaceareemployed.Theimagesareresizedtoapredeﬁnedheightwithmaintainingheight/widthratio,thenthebackgroundimageisestimatedbyalargemedianﬁlterwhosesizeisapproximately1/30theheightofthefundusimage.Thenormalizationisenhancedwithmorphologicalreconstructioninordertoimprovetheremovalofnerveﬁberlayerandotherstructuresattheedgesoftheopticnerve.Theexudatesprobabilitymapisobtainedbyahardthresholding.Theﬁeldofview(theblackareaaroundthefundusimage)isidentiﬁedthroughafastmethodbasedonaregiongrowingwithfourseedsplacedatthecornersofadownsampledversionoftheimage,moreovertheopticdiskisremovedascommontoallmethodsintheliterature.Theexudatecandidatesareselectedbyrunningakirschcompasskernelontheprobabilitymapandassigningascoreforeachcandidate.Inthesecondtypeofanalysis,thecolorsofanewinputimageareequalizedtoareferenceimagebytakingintoaccountthescalarmeanandstandarddeviationofthatimage.Intheﬁnalstage,astationaryHaarwaveletanalysisisperformeduptothesecondleveloftheintensitychannelofHSIcolorspace.ColorandshapefeaturesareextractedsuchasAvg,Std,Max,MinandMedfromdiﬀerentcolorspacesviatwodiﬀerentapproaches;intheformer,theexudateprobabilitymapisconvertedtotwobinarymasks1TheHamiltoneyeinstitutemacularedemadataset(http://vibot.u-bourgogne.fr/luca/heimed.php)2Methodstoevaluatesegmentationandindexingtechniquesintheﬁeldofretinalophthalmologydataset(http://messidor.crihan.fr/index-en.php)3Standarddiabeticretinopathydatabase-calibrationlevel0(http://www2.it.lut.fi/project/imageret/diaretdb0/)4Diabeticretinopathydatabaseandevaluationprotocol(http://www2.it.lut.fi/project/imageret/diaretdb1/)Chapter3:StateofTheArt16whicharesuperimposedonthecolorandwaveletanalysisoutputs;inthelatter,theexudateprobabilitymapisusedtoweightheanalysisoutputsatapixellevel.Fourdiﬀerentclassiﬁersareusedtoevaluatethesystemperformance.However,SVMwithlinearkernelachievesthebestperformance.Theauthorprovidedanewpubliclyavailabledataset(HIE-MED)whichconsistsof169patientsfromvariousethnicgroupsandlevelsofDME,appliedthisoneandanothertwopubliclyavailabledatasets(MESSIDORandDIARETDB1)theywereabletoachieveanareaunderthecurve(AUC)between0.88and0.94dependingonthedataset/featuresused.3.2AutomaticDetectionandClassiﬁcationofDrusenHijazietal.[30]comeupwithanideatoclassifyretinalimagesaseitheragerelatedmaculardegeneration(ARMD)ornonARMDbyadoptingacasebasedreasoningapproach(CBR).CBRconsistsinthreestagesasfollows:1-ImagepreprocessingThisstageincludestwosteps;imageenhancementandsegmentationofretinalstructures.Intheformer,colornormalizationisappliedﬁrst,followedbyilluminationnormalizationandthencontrastenhancementtoincreasethevisibilityofthemainretinalanatomy.Inthelatter,2DGaborwaveletﬁltersareappliedtoidentifywhetherapixelisclassiﬁedasavesselornonvesselbymeansofaBayesianclassiﬁer.2-SpatialhistogramgenerationUsually,colorhistogramisusedasasimplewaytorepresentanimageforthepurposeofobjectidentiﬁcation.Inthisapproach,thenumberofcolorsperimageisquantized(reduced)inordertoreducethecomputationaltimecost,andtheimageispartitionedintoanumberofequallysizedregions.Subsequently,spatialhistogramswhichkeepthecolorandspatialinformationoftheimagearecomputedforeachregion.Then,allthesehistogramsareconcatenatedintoasinglefeaturehistogram.Tosumup,eachretinalimageisrepresentedasaseriesofhistogramseachencapsulatedasatimeseriescurve(thex-axisrepresentsthehistogrambinsandthey-axisrepresentsthenumberofpixelscontainedineachbin).3-FeatureselectionBasically,featureselectionisaprocesstoreducethenumberoffeaturesbyremovingirrelevant(redundant)features,aclassseparabilitybasedmethodisadopted(Kullback-Leiblerdistancemea-sure)forthisreason.Finally,newcasesareclassiﬁedaccordingtothemostsimilarcaseinthecasebase(CB),sincethehistograminCBcanberepresentedasatimeseriescurveasimilaritymeasurecanbeachievedviaadynamictimewrapping(DTW).Inordertomeasurethesystemperformance,atenfoldcrossvalidationmethodisapplied;inaddition,twoparametershavebeenintroducedincludingnumberofbinsandtheTparameter(Numberofselectedfeatures).Theirbestresultsareconductedwithafewnumberofcolorbins(32)andaTparameterof5wherespeciﬁcity,sensitivity,andaccuracyare74%,79%,and77%respectivelyforatotalof144retinalimagesdescribedas86AMDand58nonAMDimages.173.2AutomaticDetectionandClassiﬁcationofDrusenHijazietal.[31]proposedanotherapproachwhichreliesonimageangularandcirculardecomposition.Theoutputofthedecompositionstepisasetoftreerepresentedimages(eachimageisrepresentedasatree).Aweightedfrequentsub-treeminingapproachisusedtodeterminethemostoftenoccurringsub-trees.Theweightedfrequentsub-treesarethenemployedtoadaptthetraininginputdatainavectorrepresentationform(onevectorperimage)throughalinearsupportvectormachinetoreducethedimensionalityoftheselectedfeatures.Twoclassiﬁersarethenusedforﬁnalclassiﬁcation,supportvectormachineandNaiveBayes.Atotalof258imagesfromtwodiﬀerentpubliclydataset,i.e.ARIA5andSTARE6including160AMDand98normalareused.Theclassiﬁer’sperformanceisassessedthroughaclassclassiﬁcationusingtenfoldcrossvalidation.Theyhaveachievedanaccuracyof100%withSVMandslightlysimilarresult(95%accuracy)withNaiveBayes.Akrametal.[32]proposedanalgorithmtoautomaticallysegmentdruseninfundusimagesforARMDdiagnosis.Theproposedalgorithmincorporatesthreesteps.Firstly,darkregionsareeliminatedusingmorphologicalclosing,afterthatanimageintensityenhancementisperformedbyapplyinganadaptivehistogramequalization.Secondly,theyhaveadoptedGaborkernelbasedﬁlterbanksinordertoﬁndallpossiblebrightlesions(candidateselection).OpticdiskiseliminatedusingHoughtransform.Finally,somefeatureshavebeencomputed,i.e.area,compactness,averageboundaryintensity,minimumbound-aryintensity,maximumboundaryintensity,meanhue,meansaturation,meanintensityvalue,meangradientmagnitude.Leastsquaresupportvectormachineisadoptedtoperformtheclassiﬁcation.TheyhaveusedimagesfromtheSTAREdataset,thedatasetencompasses400imagesoutofthese58imagescontainsdrusen.Theaccuracy,sensitivity,andspeciﬁcityachievedarerespectively97%,95%and98.4%.Theseparametersarecomputedbycomparingtheproposedsystemwithgroundtruthdata.However,thesystemachieved100%accuracyinﬁndingdrusenatimagelevel.Zhengetal.[33]introducedasystemwhichcombinesasetofalgorithmsi.e.patternrecognition,computervision,andmachinelearning.Imagepreprocessingincorporatesseveralprocesses.Theseen-compassimagedenoising(nonlocalmeanﬁltering),retinamaskgeneration(imagethresholdingandsomemorphologicalerosion),illuminationcorrection,andcolortransfertoreturnalltestimagessimilarincolor.Thedetectionstrategyisfoundontwoconsecutiveprocedures,i.e.apixelwiseclassiﬁcationandagroupwiseclassiﬁcation.Theideaoftheformer,istodetectwhetherapixelisadrusenornotusingcolorimagedescriptors(Hessianfeatures)andmulti-scaleimagelocaldescriptors(totalvariationfeatures).TheyhaveusedAda-boostforfeatureselectionandLeastsquaresupportvectormachineforclassiﬁcation.ThegroupwiseclassiﬁcationisexploitedtoremovefalsepositivecomponentsfrompixelwiseclassiﬁcationanditisaccomplisheddirectlybyLeastsquaresupportvectormachine.Thesystem’svalidationismadebycomparingitsoutputtomanuallysegmenteddrusenonapixelbypixelbasis.Twodiﬀerentdatasetsareusedasfollows:50imagesfromCAPT7and88fromAMISH.Accuracybetween80%and86%,sensitivitybetween82%and87%,andspeciﬁcitybetween71%and78%arerespectivelyachievedbasedonthedataset.5Automatedretinalimageanalysisdataset(http://www.eyecharity.com/aria_online.html)6Structuredanalysisoftheretinadataset(http://www.ces.clemson.edu/~ahoover/stare/)7Thecomplicationsofage-relatedmaculardegenerationpreventiontrialdatasetChapter3:StateofTheArt183.3AutomaticDetectionandDiscriminationofDrusenandEx-udatesNiemeijeretal.[6]developedanalgorithmthatcanautomaticallydetectbrightlesionsinretinalimagesandcandiﬀerentiateamongexudates,cottonwoolspots,anddrusen.Onehundredthirtyimagescon-tainingallbrightlesionsareusedtobuildthetrainingset.Allpixelsintheseimagesaresegmentedbyretinalspecialistswhethertheyareexudates,cotton-woolspot,drusenorbackgroundretina.Vessels,opticdisc,andredlesionsweretreatedasbackgroundretina.Threehundredimagesareusedtoperformdiagnosisvalidation(100imagescontainlesionsand200imagescontainnolesions).Theoverallmethod-ologyiscomposedoffourstages;probabilitymapgeneration,brightlesionpixelclusters,brightlesiondetection,andbrightlesionclassiﬁcation.Firstly,thegreenchannelisconvolvedwithasetof14digitalﬁlters,becausebrightlesionﬁlterresponseswillbediﬀerentfromtheﬁlterresponsesfornonlesionpixels.Secondly,aK-nearestneighbor(KNN)classiﬁerisusedtoclassifythepixelsbasedontheﬁlterresponsessuchthatpixelswithaprobabilityhigherthanapredeterminedthresholdaregroupedintobrightlesionpixelclusters.Eachbrightlesionpixelclusterisusuallyreferredtoasapotentiallesion.Thirdly,asecondKNNclassiﬁeristrainedusingasetofsamplepotentiallesionsextractedfromthetrainingsettodiscardfalsebrightlesionclusters.EachbrightlesionpixelclusterisassignedaprobabilityindicatingthelikelihoodthatthepixelclusterisatruebrightlesionbasedonanumberoffeatureslikethecontrastofclustersintheRGBcolorspace,inadditiontosize,shape,andcontrastofpotentiallesions;theirproximitytotheclosestvessel;andproximitytotheclosestredlesions,wherethemorecloserpotentiallesionsfromredlesionsthemorelikelytobetruebrightlesions.Finally,alineardiscriminantanalysisclassiﬁeristrainedusingthenumberofredlesionsintheimage,thenumberofdetectedbrightlesions,andthebrightlesionclusterprobabilitytoclassifythebrightlesionsintoexudates,cottonwoolspots,ordrusen.Thesystemachievedanareaunderthecurve,sensitivity,andspeciﬁcityof95%,95%,and88%foranytypeofbrightlesiondetection,95%−86%,70%−93%,and77%−88%forexudates,cotton-woolspots,anddrusen,detection.Grinsvenetal.[34]providedanalgorithmtoautomaticallydiscriminateandretrieveimageswithexudatesordrusen.Thealgorithminitializeswithpartitioningtheimage(aftermeansubtractionofthecolorplanes)intoaﬁxednumberofsquaredpatches.Thesetoffeaturesappropriatefordiscriminatingbetweennormalandabnormalareasfollows:colorhistogramfeaturesobtainedfromtheRGB,HSVandYCbCrcolorplanes:RandBplanes(32binseach);S(64bins)andV(32bins);Cb(16bins).HistogramofLaplacianofGaussian(8bins,sigma=12ofGaussian),HoG(64orientationbins);LBP(16bins)andgranulometry(scales1,3,5,7,9,11).While,thesetoffeaturessuitablefordiﬀerentiatingbetweendrusenandexudatesaresuchas:colorhistogramfeaturesextractedfromthegreenandbluecolorplanes(16binseach);H,Splanes(64binseach)andV(32);Y(32).HoGandLBP(128binseach).ByusingAda-Boostfeaturesselectiontechnique,thetwosetsoffeaturesarereducedto24and32dimensionalfeaturevectorsrespectively.Featuresareselectedempiricallybyadoptingaclassvalidationwith5foldcrossvalidation.Abagofwordsapproachisthenutilizedfortwopurposesimageretrievalaswellasimageclassiﬁcation.Somesimilaritymeasuresareemployedtohelpretrieveimages,i.e.,squaredchord,L1-norm,L2-norm.However,thebestresultisachievedusingweightedsquaredchord,whileaweightednearestneighborapproachisusedfortheclassiﬁcationusingthedistanceasasimilaritymetric.Threediﬀerentdatasets193.3AutomaticDetectionandDiscriminationofDrusenandExudatesincludingSTARE,MESSIDOR,andEUGENDA8withatotalof415imagesareemployed.Theyhaveconstructedtwodatasets:SetAandSetB.Eachsetisfurthersubdividedintoatrainingsetandtestset.ThetestsetissimilartosetAandB.Inthismanner,theycantesthowwellthemethodgeneralizeswhenthetestsetcontainsonlyimagesfromadiﬀerentpopulation.Aprecisionof0.76andAUCof0.9areachievedrespectivelyforretrievalandclassiﬁcation.Deepaketal.[35]suggestedtouseavisualsaliencybasedframeworkforbrightlesiondetectioninclud-inghardexudatesanddrusen.Thegreenchannelofagivenimageistophatﬁlteredusingadiskshapedstructuralelementinordertoenhancethelocalcontrast.Then,thebackgroundimageisestimatedusingmedianﬁlteringandsubtractedfromtheenhancedimagetominimizetheeﬀectofunevenillumination.Acontraststretchingisperformedasaﬁnalstepinpreprocessingpriortosaliencycomputation.Thespec-tralresidual(SR)modelisemployedforsaliencycomputationinordertodetectperceptualobjectsi.e.hardexudatesanddrusen.Theyhaveusedthegeneralizedmotionpatterns(GMP)theyhaveproposedin[27].FeatureextractionisperformedonthesaliencymapusingGMPbyextractingradonfeatureswithorientationsbetween0◦–180◦withastepof3◦and256bins.Atthisstageimagesareclassiﬁedasnormalorhavinglesionsusingak-nearestneighbor(K-NN)classiﬁer.Thesaliencymapprovidesusefulinformationonlocationsofabnormalitiesinanimage,soitmayhelpdiﬀerentiatebetweenanimagewithhardexudatesanddrusen.Thesaliencyimageisdividedintoaﬁxednumberofsquarepatches.Patcheswithlesionsareidentiﬁediftheirsaliencyvalueisgreaterthanapredeterminedthreshold.Localbinarypatterns(LBP)areextractedfromthegreenchannelofallpatcheswithlesions,thentheyarefedtoasupportvectormachine(SVM)classiﬁerwithRBFkernelinsuchcaseeveryabnormalimagecanbeclassiﬁedashavingHEordrusen.Theyhaveusedﬁvepubliclyavailabledataset(HEI-MED,Diaretdb,MESSIDOR,ARIA,STARE),anareaunderthecurveof0.88to0.98fordetectionandaccuraciesrangingfrom0.93to0.96forlesiondiscriminationareyieldedbasedonthedatasetused.Sofar,wehavesummarizedthediﬀerenttechniquesusedintheliteraturetoclassifyimageswithbrightlesions,namelydrusenandexudatesasshowninTable3.1.Theproposedmethodologywillbeelaboratedindepthinthenextchapter.8TheEuropeangeneticdataset(http://www.eugenda.org/)Chapter3:StateofTheArt20AuthorsLesionsPreprocessingMethodology[State]Features{L}ClassiﬁcationDatasetResultsTrainTestSE%SP%AC%AUCGarcíaetal.[26]EXLuminositynormal-ization&contrastenhancementGlobalandlocalhistogramthresh-olding[]Colorandshapefeatures{18}NNs(10FCV)506710092.5997.01...Deepaketal.[27]EXNotnecessaryCreatemotionpat-ternsofacircularROI[]Radonbasedfea-tures{36}PCA(10FCV)367277.........0.92Osarehetal.[28]EXHistogramspeciﬁ-cationandcontrastenhancementFCMclustering[]Colorandshapefeatures{18}NNs75259394.1......Giancardoetal.[29]EXImagenormaliza-tionColorwaveletde-composition[]Statisticalfeatures(Avg,Std,Max,Min,Med){48}SVM(LOOCV)169............0.94Hijazietal.[30]DruLuminositynormal-ization&contrastenhancement2DGaborwaveletﬁlters[]Spatialhistograms{160}DTW(10FCV)144...797477...Hijazietal.[31]DruLuminositynormal-ization&contrastenhancementAngularandcircu-lardecomposition[]weightedfrequentsub-graphminingapproach{3671}SVM(10FCV)258...100100100...Akrametal.[32]*DruMorphologicalclos-ingandhistogramequalizationGaborﬁlterbanks[]Colorandshapefeatures{10}LS-SVM400...9598.497...Zhengetal.[33]*DruMeanﬁltering,reti-nalmaskgenera-tionandillumina-tioncorrectionPixelandgroupbasedclassiﬁcation[]HessianandtotalvariationfeaturesLS-SVM88...877886...Niemeijeretal.[6]Dru&EXConvolutionwith14digitalﬁltersbrightlesionsclus-teringKNN[]Shape,color,con-trast,andposition{83}LDA1303009588...0.95Grinsvenetal.[34]Dru&EXMeansubtractionBagofWordsap-proach[]Histograms,LOG,HOG,LBP,andgranulometry{58×noofpatches}KNN(5FCV)225/37936.........0.9Deepaketal.[35]Dru&EXTophatﬁltering,inadditiontocontraststretchingVisualsaliencymapandGMP[]LBP{256×noofpatches}SVM(10FCV)388............0.96Table3.1:Summaryofseveralmethodsusedtodiscriminatehardexudates,anddrusen.Thistableshowsresultsoftheimagebasedcriterion.However,[.]*representsalesionbasedcriterion.State:thepaperusesmorethanonedataset,L:thelengthofthefeature,EX:Exudates,Dru:Drusen,SE:meansensitivity,SP:meanspeciﬁcity,AC:meanaccuracy,AUC:Areaunderthecurve,FCV:foldcrossvalidation,LOOCV:leaveoneoutcrossvalidation,NNs:neuralnetworks,KNN:K-nearestneighbour,SVM:supportvectormachine,LS:leastsquare,LDA:lineardiscriminantanalysis,DTW:dynamictimewrapping,GMP:generalizedmotionpatterns.Chapter4MethodologyTheproposedmethodisbasedonthebagofwords(BOW)approachtoautomaticallydiscriminatebetweennormal,drusen,andexudatesincolorretinalfundusimages.Inthisapproach,SURFaswellasHOGandLBPfeaturesareextractedfromlocalregionsofretinalimages.Then,avisualcodebookisconstructedusingK-meansclusteringalgorithm.Theclustercentersareconsideredasvisualwordswithinthecodebook.Eachindividualfeatureintheimageisquantizedtothenearestwordinthecodebook,andanentireimageissubstitutedbyaglobalhistogramcountingthenumberofoccurrencesofeachwordinthecodebook.Thesizeoftheresultanthistogramisthesameasthenumberofwordsinthecodebookandalsothenumberofclustersobtainedfromtheclusteringalgorithm.TheFinalhistogramrepresentationisfedintoalinearkernelSVMforclassiﬁcation.Fig.4.1showstheﬂowchartoftrainingphase,whileFig.4.2showstheﬂowchartoftestingphase.Figure4.1:Trainingﬂowchart.Thischapterisorganizedasfollows:Section4.1describesstepsinvolvedinthepreprocessingstep,Section4.2discussesindetaildiﬀerentfeaturesemployedforabnormalitydetection,Section4.3describesthecodebookconstructionusingk-meansclusteringalgorithm,Section4.4investigatestheencodingmethodaswellasthehistogrampoolingprocess,andSection4.5explainsthelinearsupportvectormachinewhichisusedfortheﬁnalclassiﬁcationpurpose.21Chapter4:Methodology22Figure4.2:Testingﬂowchart.4.1PreprocessingThegoalofthepreprocessingstepistocompensateforimagevariationbynormalizingtheoriginalimageagainstareferenceimage.Typically,imagevariationappearswithinthesameimage(intraimagevariability)aswellasbetweenimages(interimagevariability).Thereasonsofintraimagevariabilityarediﬀerencesinlightdiﬀusion,thepresenceofabnormalities,variationinreﬂectivity,andfundusthickness,whileinterimagevariabilityiscausedbydiﬀerencesincameras,illumination,acquisitionangle,andretinalpigmentation.IntheRGBcolorspace,thegreenchannelprovidesthebestcontrastbetweenthebloodvesselsandbackgroundwhereastheredchannelsuﬀersfromover−saturationandthebluechannelcanbeunder−saturatedandnoisy[36]asshowninFig.4.3.Figure4.3:Intensitydistributionofasamplecolorfundusimage.Theimage’schannelsarerespectivelyred,blue,andgreenfromlefttoright.234.2FeatureExtraction4.1.1IntensitynormalizationThemainpurposeoftheintensitynormalizationistoreducetheinterandintrapatientvariability.AccordingtothepaperintroducedbyCreeetal.[37]thebackground-lessfundusimagehasnormallydistributedcolors.Thus,theimagecanberepresentedbythescalarmean(µ)andstandarddeviation(σ)throughouttheentireimage.Ifthesetwoparametersarecalculatedforareferenceimage,itispossibletoequalizethecolorsofthenewimagetothereferenceoneinamoreeﬀectivemannerthansimplehistogramequalization[29].Inthiswork,themean(µ)andstd(σ)areempiricallychosenforalldatasetsinsteadofcomputingthemfromareferenceimage.Furthermore,thepreprocessingisappliedonlytothegreenchannelratherthanthethreeplanesoftheRGBcolorspace.Allimagesareresizedtoaheightof512pixels,whilemaintainingtheaspectratiobecauseoftheirlargesizes.Thedescriptionoftheprocessforasinglecolorplaneisexplainedasfollows:µref=0.5σref=0.1Iout=Iin−medianFilter(Iin)µout=mean(Iout)(4.1)σout=std(Iout)I1out=(Iout−µout)÷σoutI2out=(I1out×σref)+µrefThebackgroundimageisestimatedbyamedianﬁlter,whosesizeisapproximately130theheightofthefundusimage.Iinistheimagetobeequalized,Ioutisthebackground-lessimage,andI2outistheequalizedimage.Fig.4.4showsanexamplefornormalimageequalizationaswellasdrusenimageequalization.Althoughthetwoimages(Fig.4.4(a)and(b))havediﬀerentethicbackgroundsandqualitylevel,theresultant(Fig.4.4(c)and(d))imageshaveverysimilarcolors.(a)(b)(c)(d)Figure4.4:(a)Normalimage,(b)drusenimage,(c)equalizednormalimage,and(d)equalizeddrusenimage.4.2FeatureExtractionFeatureextractionisnothingbuttransformingtheinputimageintoasetoffeaturesthateﬃcientlyrepresentinterestpartsofthatimage.Thus,thesefeaturesshouldbecarefullychosen.Basedondiﬀerentapproachesrevisedintheliterature[34,35,50],itisnoticeablethatlocalbinarypatterns(LBP),speededChapter4:Methodology24uprobustfeatures(SURF),andhistogramoforientedgradients(HOG)achievesatisfactoryresultswhentheyareusedfordiabeticretinopathydiagnosis.Inthiswork,allfeaturesareextractedfromthethreechannelsoftheRGBcolorspace.Asdiscussedintheprevioussectionthepreprocessingisonlyappliedtothegreenimage,thisisbecauseinsomedatasetssuchasSTAREifapreprocessingstepisappliedontheredorbluechannel,mostoftheinformationwouldbeprobablylostasshowninFig.4.5.(a)(b)(c)(d)Figure4.5:PreprocessingresultonadrusenimagefromtheSTAREdataset.(a)drusenimage,(b)enhancedredimage,(b)enhancedgreenimage,and(d)enhancedblueimage.Intheredandblueimage,thedrusen(insidetheredcircle)cannotbeidentiﬁedasoppositetothegreenimage.Typically,ThedimensionoftheSURFdescriptorsare64×numberofinterestpoints(seeSec-tion4.2.1).Inourcasetwoapproachesareadaptedasfollows:ordinarySURFanddenseSURF.Intheﬁrst,SURFdescriptorsareextractedfromallRGBcolorchannels,thentheyarehorizontallyconcate-natedtogetafeaturematrixofasize64×totalnumberofinterestpointsextractedfromthethreechannelsasshowninFig.4.6(a)and(b).Inthesecond,SURFdescriptorsareextractedfromadensegriduniformlydistributedthroughouttheimagei.e.SURFdescriptorsarecomputedon16×16pixelpatches(nonoverlapping)withaspacingof16pixels,thisisshowninFig.4.6(c).Asoppositetoor-dinarySURF,foreachpatchwegetafeaturevectorofadimension64,thenforeachimagechannelwegetafeaturematrixofasize64×numberofpatches.Finally,eachimageconstitutesafeaturematrixofasize192×numberofpatchesbyverticallyconcatenatingeachfeaturematrix.TheimplementationofSURFisdoneusingmat-labbuiltinfunction.(a)(b)(c)Figure4.6:SURFanddenseSURFinterestpoints.(a)and(b)showSURFpointsonthegreenchannelofanexudateandadrusenimagerespectively.(c)showsdenseSURFpointsonanormalimage.TheHOGdescriptorsareobtainedassimilarto[42](seeSection4.2.2),duetoitslowerdimensionanddiscriminativepower.Eachimagechannelisdividedintoﬁxednumberofblockswithasizeof32×32pixels,theneachblockissubdividedinto4cells(eachcellis16×16pixels),asaresulteachblockcontributestoafeaturehistogramofadimension31.Foreachchannel,thehistogramsarevertically254.2FeatureExtractionconcatenatedformingafeaturematrixofasize31×numberofblocks.Intotal,thethreechannelswillconstituteafeaturematrixofasize93×numberofblocks.Thenulldescriptorsoriginatingfromtheblackareasurroundingthefundusimagearenotarenottakenintoaccount.Fig.4.7showsanexampleofHOGdescriptorsextraction.Figure4.7:HOGdescriptors.Theimageisdividedintoblocksandahistogramisexecratedfromeachblock.TheLBPdescriptorsareextractedfromlocalpatchesofasize32×32pixelssimilartotheHOG(seeSection4.2.3).However,foreachpatchLBPfeaturesarecomputedusinga3×3movingwindowcenteredateachpixelwithinthepatch.Theuniformlocalbinarypatternsareselectedbecauseofitslowerdimensionandreducingthenumberofcodesinﬂictedbyhighfrequencynoise.Thesizeofthefeaturematrixperimageis58×numberofpatches,sointotalwegetafeaturematrixofasize174×numberofpatches.TheHOGandLBPareimplementedusingtheVLFeatopensourcelibrary[45].4.2.1SpeededUpRobustFeatures(SURF)SURF(SpeededUpRobustFeatures)isalocalinvariantinterestpointdetector−descriptor,ﬁrstproposedbyBayetal.[38].Itisbasedontwosteps:fastinterestpointdetectionanddistinctivepointdescription.Intheprevious,integralimagesareusedsincetheyallowforfastcomputationofboxtypeconvolutionﬁlters.IntegralimagescanbecreatedbyEq.(4.2).ii(x,y)=i≤xXi=0i≤yXj=0i(x,y)(4.2)wherei(x,y)isthebrightnessvaluesofthepixelinoriginalimageandii(x,y)istheintegralimage.Introducingintegralimage,theareaofanyuprightrectangularregiontakesonlythreearithmeticoper-ationsi.e.calculationtimeisindependentonitssize.ThesumofbrightnessinareaDiscalculatedasS4+S1−(S2+S3)asshowninFig.4.8.Thekeypointdetectionisbasedonthedeterminantofthehessianmatrix.Apointx=[x,y]Tinoriginalimagei,thehessianmatrixH(x,σ)inxatascale(σ)isdeﬁnedasfollows:Chapter4:Methodology26Figure4.8:Integralimage[39].S1isthesumofpixelsinrectangleA,similarlyS2,S3,andS4showA+C,A+B,A+B+C+Drespectively.H(x,σ)="Lxx(x,σ)Lxy(x,σ)Lxy(x,σ)Lyy(x,σ)#(4.3)HereLxx(x,σ)istheconvolutionofthesecondorderGaussianderivativewiththeimageatapointx=[x,y]TandthesameforLyyandLxy.ThesederivativesareknownastheLaplacianofGaussian.SURFproposedanapproximationtothesederivativesbyusingboxﬁlterrepresentation.Dxx(x,σ)isanapproximationtoLxx(x,σ)likewiseDxy(x,σ)isLxy,Fig.4.9showsanexampleofboxﬁlterapproxi-mations.Theperformanceincreaseswhentheseﬁltersareusedinconjunctionwiththetheintegralimage.TheapproximationofthehessiandeterminantisgivenbyEq.(4.4).det(Happrox)=DxxDyy−(0.9Dxy)2(4.4)Figure4.9:LaplacianofGaussianapproximations[40].FirstrowrepresentssecondorderGaussianderivativesinthex,y,andxydirections,whilesecondrowshowscorrespondingweightedboxﬁlterapproximationsinthesamedirections.Keypointlocalizationisperformedbothinscaleandimagespacebyapplyingkernelsofincreasingsizetotheoriginalimage,thisisbecausetheprocessingtimeofkernelsusedinSURFissizeinvariant.Theresponsesofappliedkernelsarethresholded.Thus,increasingthethresholdleavesonlythestrongestpointswhiledecreasingallowsformanypointstobedetected.Next,anonmaximumsuppressionina3×3×3neighborhoodisperformedwhereapixelisselectedasakeypointifitisgreaterthanthe274.2FeatureExtractionFigure4.10:Orientationassignments[40].Whenthewindowmovesaroundtheorigin(60degrees)thecomponentsoftheresponsesarecollectedtoyieldthevectorsshowninblue.Thelargestsuchvectordeterminesthedominantorientation.surroundingpixelsonitsintervalandintervalaboveandbelow.Inthelatter,eachdetectedinterestpointisassignedareproducibleorientationtoachievearotationinvariance.Haarwaveletresponsesofsize4(σ)arecomputedforanumberofpixelswithinaradiusof6(σ)aspresentedinFig.4.10.HaarwaveletsaresimpleﬁltersthatcanbeemployedtoﬁndgradientsinthexandydirectionasshowninFig.4.11(a).Then,asquarewindowofasize20(σ)isconstructedaroundtheinterestpoint,furthermorethewindowissubdividedinto4×4regularregions.WithineachofthesesubregionsHaarwaveletsofsize2(σ)arecomputedfor25regularlydistributedsamplepointsasshowninFig.4.11(b).Thedescriptorencompasses(Pdx,Pdy,P|dx|,P|dy|)wheredxanddyarethexandywaveletresponses,thusthedescriptordimensionwillbe4×4×4=64D.TheﬁnalSURFdescriptorisinvarianttorotation,scale,brightness,andcontrastafterreductiontoaunitlength.(a)(b)Figure4.11:Haarwaveletsanddescriptorcomponents[40].(a)Theleftﬁltercomputestheresponseinthexdirectionandtherighttheydirection.Weightsare1forblackregionsand-1forthewhite.(b)Thegreensquareencapsulatesoneofthe16subregionsandbluecirclesshowsthesamplepointsatwhichwaveletresponsesarecomputed.4.2.2Histogramoforientedgradients(HOG)Thehistogramoforientedgradients(HOG)introducedbyDalaletal.[41]arefeaturedescriptorsusedincomputervisionandimageprocessingforobjectrecognition.Theoverallprocesscanbesummarizedasdiscussedbelow:GradientComputationSimpleﬁnitediﬀerencemasks[-1,0,1]anditstransposeworkbestwithnoGaussiansmoothing(σ=0).WeightedvoteintospatialandorientationcellsTheimageisdecomposedintosquarecellsofagivensize.Then,ahistogramoforientedgradientsiscomputedineachcellwithﬁxednumberofpredeterminedbins.TheorientationbinsarespacedChapter4:Methodology28over[0◦,180◦](unsignedgradients).Thegradientmagnitudesofthepixelsinthecellareusedtovoteintotheorientationhistogram.Themagnitudeandphasearecomputedrespectivelyasfollows:k∇Fk=s(cid:18)∂f∂y(cid:19)2+(cid:18)∂f∂x(cid:19)2(4.5)θ=arctan(cid:18)∂f∂y/∂f∂x(cid:19)(4.6)ContrastnormalizationoveroverlappingspatialblocksCellsaregroupedintolargerspatialblockswith50%overlappingasshowninFig.4.12.Next,eachblockisL2normalizedinordertoprovidebetterinvariancetoillumination,shadowing,andedgecontrast.Eachcellissharedbetweenseveralblocksbecauseoftheoverlapping.However,itsnormalizationisblockdependentandthusdiﬀerent.Thecellappearsmanytimesintheﬁnaloutputvectoralongwithdiﬀerentnormalizations.Thismaylookredundantbutitimprovestheresult.CollectHOG’SoverdetectionwindowEachblockconsistofacertainnumberofcells(typically2×2)andeachcellcontains(n×n)pixelswithﬁxednumberofbinsforeachcell(typically9).Eachcellyieldsalocal1-Dhistogramofgradientsoverallthepixelsinthecell,foratotalof4×(numberoforientations)=36.Figure4.12:Histogramoforeintedgradients[http://www.vision.rwth-aachen.de].TheHOGpresentedbyFelzenszwalbetal.[42]computesdirected,undirectedgradients,andafourdimensionaltextureenergyfeature.Thedirectedgradient(sensitivegradient[0◦,360◦])isspeciﬁedaccordingtothecontrastdirectionwithadimensionof2×(numberoforientations).Theundirectedgradient(insensitivegradient[0◦,180◦])doesn’tdependonthecontrastdirectionwithhalfthesize.Hereeachcellwithinablockisindividuallyl2normalizedoppositeto[41].Intotal4×(2+1)×(numberoforientations)elementsareyielded.However,theresultisprojecteddownto(2+1)×(numberoforien-tations)byaveragingcorrespondinghistogramdimensions.Thefourdimensiontextureenergyfeatureisobtainedbyl1normalizingeachofthealreadyl2normalizedundirectedhistogram[43].Finaldimensionbecomes(2+1)×(numberoforientations)+additionalfourdimensions=31.4.2.3LocalBinaryPattern(LBP)Thelocalbinarypattern(LBP)isasimpleveryeﬃcienttexturedescriptorthatcategorizeslocalimageprimitivessuchascurvededges,spots,andﬂatareasintoafeaturehistogram.Theoriginalimplementa-294.2FeatureExtractiontionoftheLBPoperator[44,45]atagivenpixelisperformedbythresholdingthe3×3neighborhoodofeverypixelwiththecenter’spixelvalue.Assumegcbethecenterpixelgraylevelandgp(p=0,1,2,...,7)bethegraylevelofeachsurroundingpixel.Ifgiissmallerthangc,sothebinaryresultofthepixelissetto0,otherwiseto1.Allresultsareaggregatedtoa8-bitbinaryvalue.ThedecimalvalueofthebinaryistheLBPfeature.Fig.4.13showsanexampleofcomputationofLBPoperatorina3×3neighborhood.Figure4.13:IllustrationofthebasicLBPoperator.ThestandardLBPoperatorisnotveryrobustagainstlocalchangesinthetexturesuchaschangesinviewpointorillumination.Asaresult,localfeaturescomputedina3×3neighborhoodcannotcapturelargescalestructuresthatmaybetheonlyrelevanttexturefeatures.Inordertosolvethisproblem,itisimportanttoextendthisideatoamultiresolutionLBPoperator[46].Thenewideaistouseasetofpointsequallyspacedonacirclecenteredatapixeltobelabeled.Thus,thispermitsanyradiusandnumberofsamplingpoints.Ifasamplingpointdoesn’tfallinthecenterofapixel,bilinearinterpolationisused.Fig.4.14showsanexamplefornewLBPoperatorcomputation.Figure4.14:AnexampleofnewLBPoperatorcomputation.[http://www.scholarpedia.org/].Anotherextensionusinguniformpatternsisproposed,whichcanbeappliedinordertoreducethelengthofthefeaturevectorwhilekeepingitsdiscriminativepower.ALBPpatterniscalleduniformifthebinarypatternencompassesmaximumtwobitwisetransitionsfrom0−1orfrom1−0.Forinstance,thepatterns(00000000)(notransitions),(01110000)(twotransitions)areuniform,whereas(11001001)(4transitions)and(01010010)(6transitions)arenotuniform.ThisconstraintreducesthenumberofChapter4:Methodology30theLBPpatternsfrom256to58foreightpoints[47].4.3CodebookGenerationK-meansclusteringalgorithmisoneofthemostpopularvectorquantizationmethods.ThepurposeoftheK-meansistopartitionNmeasurementsintoKclustersinwhicheachobservationbelongstotheclusterwiththeclosestmean.Assumethesetoffeaturesextractedfromthetrainingsetcanbeexpressedas{x1,x2,...,xM}wherexm∈RD,thegoalistopartitionthisfeaturesetintoKclusters{d1,d2,...,dK}dk∈RD.Considerforeachfeaturexm,thereisacorrespondingsetofbinaryindicatorvariablesrmk∈{0,1}.IfxmisappointedtoclusterK,thenrmk=1andrmj=0forj6=k.TheobjectivefunctioncanbedeﬁnedbyEq.(4.7):minH({rmk,dk})=MXi=1KXi=1rmkkxm−dkk2(4.7)ThemainideaistoﬁndvaluesforbothrmkanddktominimizetheobjectivefunctionH.Usually,thisfunctionisoptimizedinaniterativeprocedurewhereeachiterationconsistsoftwosuccessivestepsrelatingtosuccessiveoptimizationofrmkanddk[48].Fig.4.15showsanexampleofvisualwordgenerationfromasetoffeaturesusingK-means.Figure4.15:Codebookgenerationusingk-meansclusteringalgorithm.{x1,x2,...,xM}arethefeaturesetsand{w1,w2,...,wK}representthevisualwords.Twocriteriaareintroducedinordertoconstructthevisualdictionarysuchas;asinglebasedcriterionandamultiplebasedcriterion.Intheformer,asingledictionaryDiiscreatedfromapooloffeatures,i.e.DSURF,SURF,HOG,orLBP.Then,foreachimagefeaturexmﬁnditscorrespondingvisualwordfromeverydictionaryDi.Thesevisualwordsarecombinedintoindividualhistogramshiforeachdictionary(seeSection4.4)andthesystemperformanceisassessedaccordingly.Inthelatter,similarstepsarefollowed.However,theindividualhistogramsareconcatenatedintoasingleonei.e.h=[h1,h2,...,hN].ThesetwomethodsareshownrespectivelyinFig.4.16andFig.4.17.314.4FeatureEncodingandPoolingFigure4.16:Singlebaseddictionaryexample.Thesetoffeaturesrepresentasingleimageinthetrainingdataset.4.4FeatureEncodingandPoolingForeachindividualimageinthetrainingdataset,considerXbeasetofD-dimensionaldescriptorssuchasX={x1,x2,...,xN}∈RDxN.Givenavisualdictionary(theonealreadycomputedinthepreviousstep)withKvisualwordsi.e.D={d1,d2,...,dK}∈RDxK.ThepurposeoftheencodingstepistocomputeacodeforinputxwithD.Thus,eachfeaturedescriptorxnisallocatedtothenearestvisualwordinthedictionarybysatisfyingargminkkxn−dkk2.AsaresultasinglevectorPcontainingthecorrespondingwordsofeachfeaturedescriptorxnisobtained;thisisusuallycalledhardassignmentcoding[48].ThepoolingprocessissimplyperformedbycountingthenumberofoccurrencesofeachvisualwordintheresultantvectorP,thenL2-normalizethisvectorasfollows:P=Pq(PKk=1p2k(4.8)Toconclude,eachimagewillberepresentedbyasinglenormalizedfeaturehistogramcorrespondingtothenumberofoccurrencesofeachvisualwordinthatimage.Subsequently,thesehistogramswillfedintoalinearsupportvectormachineforﬁnalclassiﬁcationwhichwillbeexplainedinSection4.5.Figure4.17:Multiplebaseddictionaryexample.Thesetoffeaturesrepresentasingleimageinthetrainingdataset.Chapter4:Methodology324.5ClassiﬁcationTheproblemoftheclassiﬁcationhasbeenperformedusingLIBSVM9.ItisapopularopensourcemachinelearninglibrarydevelopedbyNationalUniversityofTaiwanandwritteninC++[49].Supportvectormachines(SVMs)areusuallyadaptedforthepurposeofdataclassiﬁcation.Mostprobably,inanyclassiﬁcationproblemthedataisseparatedintotrainingandtestingsets.Eachexampleinthetrainingsetcontainsaclasslabelandseveralfeatures.Basedonthetrainingdata,theobjectiveofsupportvectormachineistoproduceamodelwhichisabletoestimatethetargetvaluesofthetestdatagivenonlythetestdatafeatures.Assumeatrainingsetofinstancepairoflabels(xi,yi),i=1,2,...,lwherexi∈Rnandy∈{1,−1}lsuchthaty=+1forpositivesamplesandy=−1fornegativesamples,theSVMrequiressolutionofthefollowinglagrangeoptimizationproblem:minw,b,ξ12wTw+ClXi=1ξisubjecttoyi(wTφ(x)+b)≥1−ξi(4.9)ξi≥0Thetrainingvectorsxiaremappedintoahigherdimensionalspacebythekernelfunctionφ(x).TheSVMﬁndsalinearhyperplanewhichmaximizesthemargin12wTwinthishigherdimensionalspaceaswecanseeinFig.4.18.C>0isthepenaltyparameteroftheerrorterm.Thisparameterisreferredtoasbestcwhichshouldbetunedcarefullyduringthetrainingphasesinceitsigniﬁcantlyaﬀectstheclassiﬁerperformance.Therearediﬀerentkernelfunctionsavailablei.e.linear,polynomial,radialbasisfunction,andsigmoid.However,inourcaseweconsiderthelinearonesinceitprovidesuswiththebestclassiﬁcationresults.ThelinearkernelfunctionisdeﬁnedasK(xi,xj)=xTixj.Figure4.18:SVMoptimalhyperplaneforasetof2D-pointsItseemsreasonabletoconcludethat,thischapterdescribesindetailthepreprocessingstepsaswellasfeatureextractiontechniques.Furthermore,itexplainsthepipelineofthebagofwordsapproachbesides9http://www.csie.ntu.edu.tw/~cjlin/libsvm334.5Classiﬁcationabriefsummaryaboutthesupportvectormachine.Thenextchapterwilldescribethediﬀerentdatasetsbeingused,inadditiontoresultsanddiscussion.Chapter5ResultsandDiscussionInthisresearch,wehaveused430imagesfromsixpubliclyavailabledatasetssuchas;STARE10,DRIVE11,DRIDB12,HEI-MED13,MESSIDOR14,andHRF15,inadditiontooneprivatedatasetobtainedfromtheOakRidgeNationalLaboratory,USA(ORNL).Thedescriptionanddistributionofthesedatasetsaredescribedinthefollowingtwosections.5.1DatasetsDescription5.1.1STARESTARE(structuralanalysisofretina)dataset[52]consistsof400PPMimages,theseimagesaredigitizedslidescapturedbyaTopConTRV-50funduscamerawith35degreeﬁeldofview.Eachslidewasdigitizedtoproduce605×700pixelimagewith24bitsperpixel.Annotationsatimagelevelareavailable.Fig.5.1showsanexampleofanimagefromthedatabase.Figure5.1:DrusenimagefromtheSTAREdatabase.10see(http://www.ces.clemson.edu/~ahoover/stare/)11see(http://www.isi.uu.nl/Research/Databases/DRIVE/)12see(http://www.fer.unizg.hr/ipg/resources/image_database)13see(http://vibot.u-bourgogne.fr/luca/heimed.php)14kindlyprovidedbytheMessidorprogrampartners(seehttp://messidor.crihan.fr)15see(http://www5.cs.fau.de/research/data/fundus-images/)34355.1DatasetsDescription5.1.2DRIVEDRIVE(digitalretinalimagesforvesselsegmentation)dataset[53]contains40TIFFimagesandtheirgroundtruth(vesselsegmentation).Outofthe40imagesinthedatabase,7containsdiseaseslikeexudates,hemorrhagesandpigmentepitheliumchanges.AllimagesaredigitizedusingacanonCR5non-mydriatic3CCDcamerawith45degreeﬁeldofview.Everyimageiscapturedusing24bitsperpixelatimagesizeof584×565pixels.Fig.5.2presentsanexampleofsuchimage.Figure5.2:NormalimagefromtheDRIVEdatabase.5.1.3DRIDBDRIDB(diabeticretinopathyimagedatabase)dataset[54]encompasses50BMPimagesandtheirgroundtruth(microaneurysms,hemorrhages,hardexudates,softexudates,bloodvessels,opticdisk,andmacula).Theimagesarecapturedataresolutionof720×576inRGBcolorwith8bitspercolorplanwithaZEISSVISUCAM200funduscameraat45degreeﬁeldofview.Fig.5.3showsonesuchimage.Figure5.3:NormalimagefromtheDRIDBdatabase.5.1.4HEI-MEDHEI-MED(Hamiltoneyeinstitutemacularedema)dataset[29]isacombinationof169JPEGimages(highqualityfundusimagesfromdiﬀerentethnicbackgrounds).Furthermore,amanualgroundtruthChapter5:ResultsandDiscussion36lesionmapandothermeta-dataareavailable.Itismainlyusedforexudatesanddiabeticmacularedemadetection.TheimagesareacquiredbyZEISSVISUCAMPROfunduscameraataresolutionof2196×1958andwithaﬁeldofview45degree.TwoexamplesareshowninFig.5.4.(a)(b)Figure5.4:TwoexamplesofnormalandexudateimagesfromHEI-MEDdatabase.5.1.5MESSIDORMESSIDOR(methodtoevaluatesegmentationandindexingtechniquesintheﬁeldofretinalophthal-mology)dataset[55]combines1200TIFFimages.Theseimagesareacquiredusingacolorvideo3CDDcameraonaTopConTRCNW6non-mydriaticretinopathywith45degreeﬁeldofviewwith8bitspercolorplaneat1440×960,2240×1488or2304×1536pixels.800imageswereacquiredwithpupildilationand400withoutdilation.Theimagesaretakenatthreediﬀerentclinicalsites.Gradingfordiabeticretinopathyandtheriskofmacularedemaineachimageareprovided.Forthebestofourknowledge,itisthelargestavailableimagesontheinternet.AnexampleofsuchimagesisshowninFig.5.5Figure5.5:ExudateimagefromtheMESSIDORdatabase.5.1.6HRFHRF(highresolutionfundus)dataset[56]comprises15imagesofhealthypatients,15imagesofpatientswithdiabeticretinopathy,and15imagesofglaucomatouspatients.Theimagesareacquiredusinga375.2DatasetsDistributioncanonCR-1funduscameraataresolutionof2336×3504withaﬁeldofview45degreeanddiﬀerentacquisitionsetting.Groundtruthforvesselsegmentationisavailable.Fig.5.6showsanexample.Figure5.6:NormalimagefromtheHRFdatabase.5.1.7ORNLORNL(OakRidgeNationalLaboratory,USA)datasetiscapturedataresolutionof1024×1360and1958×2196with45degreeﬁeldofview.Thedatasetconsistsof61drusenonlyimages,36normalimages,and20exudatesonlyimages.Nogroundtruthisavailable.TwoexamplesarepresentedinFig.5.7.(a)(b)Figure5.7:TwodrusenexamplesofORNLdatabase.5.2DatasetsDistributionInthisstudy,wehaveused81normalimages,85drusenimages,and264exudateimagesobtainedfrom(ORNL,HRF,DRIDB,andDRIVE),(ORNLandSTARE),and(ORNL,HEI-MED,andMESSIDOR)respectively.Theimagesaredividedintotwosets;SetAandSetB.SetAcontains220imagesacquiredfromORNL,HEI-MED,HRF,DRIVE,DRIDB,andonlyoneclinicalsiteofMESSIDORnamedMES1whereasSetBconstitutes210imagesobtainedfromORNL,HEI-MED,HRF,DRIVE,DRIDB,andtwoclinicalsitesofMESSIDORnamedMES2andMES3.TheideaistouseSetAasatrainingset,thenmeasurethesystemperformancebasedonSetBandvice-versa.Inthisway,wecanassesshowwellthesystembehaveswhenthetestsetcontainsdiﬀerentChapter5:ResultsandDiscussion38imagesthantheonesincludedinthetrainingset.Thisisusuallycalledcrossdatasettesting.Thatmeanstheproposedsystem(selectedfeatures,dictionary:singleormultiple,andnumberofvisualwords)shouldbediscriminatingenoughtoclassifythedatepresentintheSetAbasedonSetB,alsothedatapresentinSetBbasedonSetA.Table5.1showsSetAandSetBimagedistribution.SETANormalDrusenExudatesORNL183010HEI-MED......13STARE...12...HRF7......DRIDB5......DRIVE10......MSE1......115MSE2.........MSE3.........Numberofimages4042138SETBNormalDrusenExudatesORNL183110HEI-MED......13STARE...12...HRF8......DRIDB5......DRIVE10......MSE1.........MSE2......63MSE3......40Numberofimages4143126Table5.1:DatadistributionofSetAandSetB.MES1:MESSIDORsite1,MES2:MESSIDORsite2,andMES3:MESSIDORsite3.5.3ExperimentalResultsAsdiscussedinSection4.3,thereexisttwodiﬀerentmethodstoconstructthevisualdictionary:singlebasedmethodandmultiplebasedmethod.Thegoalofthesinglebasedmethodistobuildasingledic-tionaryusingasetoffeaturessuchasDSURF,SURF,HOG,orLBPwhereasthemultiplebasedmethodisbasedonconstructingmultipledictionariesfromallsetoffeatures,thencombiningallhistogramsintoonehistogram.Thesystemperformanceisassessedusingtheaccuracymeasurementwhichiscomputedasfollows:395.3ExperimentalResultsAccuracy=TotalnumberofcorrectlyclassiﬁedimagesTotalnumberofimages%(5.1)orAccuracy=TN+TPTN+FP+FN+TP%(5.2)where•TP(truepositive):Abnormalimagescorrectlydiagnosedasabnormal•FP(falsepositive):Normalimagesincorrectlydiagnosedasabnormal•TN(truenegative):Normalimagescorrectlydiagnosedasnormal•FN(falsenegative):AbnormalimagesincorrectlydiagnosedasnormalTheclassiﬁer’sparameteri.e.thevalueofCwhichisreferedtoasbestciscomputedbycarryingoutaclassclassiﬁcationwith10foldcrossvalidation.Theideaistobreakthetrainingdatainto10setsofasizen10,trainon9datasetsandteston1.Then,repeat10timesandtakethemeanaccuracy.SinceK-meansclusteringalgorithm(hardassignment)isemployed,diﬀerentvaluesofKareusedsuchasK=[10,20,30,40,50,60,70,80,90,100]inordertoachievesatisfactoryclassiﬁcationresults.Twoexperimentsareperformed.TheﬁrstexperimentistouseSetBasatrainingsetandSetAasatestset,whilethesecondexperimentistouseSetAasatrainingsetandSetBasatestset.5.3.1PerformanceusingSetBasatrainingsetandSetAasatestsetRegardingthesinglebaseddictionary,thehighestaccuracy98.63%isobtainedusingDSURFdescriptorsatK=70,subsequentlyHOG,SURF,andLBPachieveaccuraciesof97.27%atK=100,85.91%atK=90,and91.36%atK=80respectivelyasshowninTable5.2.NeitherSURFnorLBPdescriptorsprovidesatisfactoryresultsasexpected.Onthecontrary,HOGgivesapproximatelysimilarresultstoDSURF97.27%atK=100.Sincethereisnopreprocessingsteptoremovetheopticdisk,itmightbeconfusingfortheSURForLBPdescriptorstodiscriminatebetweennormalandexudateimagesastheintensitycharacteristicsoftheopticdiskareverysimilartotheexudatelesions.AlthoughDSURFdescriptorsachievethebestaccuracy,thereisstillaproblembecauseanexudateimageismisclassiﬁedasnormalwhichinfactcanbeconsideredasadisadvantagetothesystem.Ifadiabeticpatientismisdiagnosedasnormal(falsenegative),thatmeansweareintroubles.However,ifanormalpatientismisdiagnosedasdiabetic(falsepositive)heorshemayrepeatthetesttomakesureaboutthedisease.Falsenegativeismoreperniciousthanfalsepositive.Fig.5.8showstheconfusionmatrixofDSURFdescriptorsatK=70.Allnondiagonalelementsontheconfusionmatrixrepresentmisclassiﬁeddatawhereasdiagonalelementsrepresentcorrectlyclassiﬁeddata.Thus,agoodclassiﬁerwillyieldaconfusionmatrixwithmorediagonalelements.Theaccuracyoftheaboveexampleiscomputedasfollows:Chapter5:ResultsandDiscussion40Training:SetB,Testing:SetASingleDictionaryMultipleDictionariesKDenseSURFSURFHOGLBPDSURF,HOG,LBP1075.454578.181890.45458091.36362088.181883.181893.636485.454596.36363093.181884.090993.181888.636495.4545409583.636493.636488.636498.63645097.727383.181895.909189.090997.72736095.909183.636492.272788.636497.72737098.636484.545596.36369097.72738097.72738593.181891.363699.09099097.727385.909195.909190.909198.636410098.181885.454597.272789.545599.5455Max98.636485.909197.272791.363699.5455Table5.2:TestSetAversusSetBusingdiﬀerentnumberofvisualwords.Figure5.8:ConfusionmatrixofDSURFdescriptorsatK=70(testSetAVs.SetB).Accuracy=40+41+13640+41+136+3=98.63%(5.3)Ontheotherhand,multiplebaseddictionaryapproachovercomesthesinglebaseddictionary.AtK=100,anaccuracyof99.54%isobtained.Thisisaccomplishedwithonlyonefalsenegativesamplei.e.oneexudateimageismisidentiﬁedasnormalasshowninFig.5.9.However,therearenoanyfalsepositivecaseslikeDSURFdescriptors.Figure5.9:ConfusionmatrixofmultiplebaseddictionaryatK=100(testSetAVs.SetB).InfactforallvaluesofK,multiplebaseddictionaryapproachachieveshigherresultsthanthesinglebasedmethod,exceptatK=70DSURFdescriptorsresult98.63%isslightlybetterthanmultiplebased97.72%.Fig.5.10showstheresultantaccuracyforalldescriptorsversusdiﬀerentvaluesofvisualwords.415.3ExperimentalResultsFigure5.10:AccuracyVs.visualwordsKforasingleandmultiplebaseddictionaries(testSetAVs.SetB).All:multiplebaseddictionariesapproach.5.3.2PerformanceusingSetAasatrainingsetandSetBasatestsetWithrespecttothesinglebaseddictionary,theHOGdescriptorsachievethehighestaccuracy97.14%atK=100,afterthatDSURF,SURF,andHOGachieveaccuraciesof90.95%atK=50,85.23%atK=80,and84.76%atK=70respectivelyasshowninTable5.3.Training:SetA,Testing:SetBSingleDictionaryMultipleDictionariesKDenseSURFSURFHOGLBPDSURF,HOG,LBP1064.761973.333390.476278.571490.47622077.142979.047692.857183.809595.71433080.952480.476292.38154.285798.09524082.85718095.714354.285798.09525090.952481.428692.857177.142996.66676089.047679.523894.761970.952497.6197086.666784.285796.190584.761998.09528088.571485.238192.38170.952499.52389090.476283.333395.238177.142998.571410090.476281.428697.142972.381100Max90.952485.238197.142984.7619100Table5.3:TestSetBversusSetAusingdiﬀerentnumberofvisualwords.TheconfusionmatrixoftheHOGdescriptorsshowninFig.5.11indicatesthattwodrusenimagesbesideoneexudateimagearemisidentiﬁedasnormal,whichremainsadrawbacktothesystemaswediscussedbefore.TheDSURFdescriptorsyieldlowerresults90.95%thantheoneobtainedinthepreviousexperiment.SURFandLBPdescriptorsattainrelativelysimilarresultsasbefore.WecannoticethattheDSURFdescriptorsdon’tattainsimilarperformancesinbothexperimentsowingtothesharpdecreaseinaccuracyfrom98.63%to90.95%.However,theHOGdescriptorsachievesatisfactoryresultswiththetwoexperimentswhichimpliesthediscriminativepowerofthesedescriptors.Chapter5:ResultsandDiscussion42Figure5.11:ConfusionmatrixofHOGdescriptorsatK=100(testSetBVs.SetA).Figure5.12:ConfusionmatrixofmultiplebaseddictionaryK=100(testSetBVs.SetA).Oncemore,themultiplebaseddictionaryapproachovercomesthesinglebaseddictionarysinceatK=100a100%accuracyisachievedaspresentedintheconfusionmatrixofFig.5.12,thefalsepositiveandfalsenegativearezeros.Furthermore,forallvisualwords,itachievehigherresultsthanthesinglebasedmethodasshowninFig.5.13.Sofar,wecanconcludethatthemultiplebasedapproachachievessigniﬁcantresultsinbothconditions,whichindicatestheimportanceofintegratingseveraldescriptorsinthetaskofdiabeticretinopathydiagnosis.AsmentionedinSection5.2theproposedapproachshouldbeabletodiscriminatethedatapresentinSetAbasedonSetBandvice-versa,themultiplebasedapproachmanagedtoaccomplishthistaskwithsatisfyingresultssuchas99.54%,100%fortheﬁrstandsecondexperimentrespectivelyandameanaccuracyof99.77%.Figure5.13:AccuracyVs.visualwordsKforasingleandmultiplebaseddictionaries(testSetBVs.SetA).All:multiplebaseddictionariesapproach.Chapter6ConclusionandFutureWorkInthislastchapterwepresentconclusionsaboutourwork.Moreover,wedescribepossibleresearchdirectionstocontinuetheworkdescribedinthisthesis.6.1ConclusionInthisthesis,abagofwordsapproachwasemployedinordertodiscriminatebetweennormalfundusimagesandabnormalfundusimageswithbrightlesions,speciﬁcallydrusenandexudates.Wehavepro-posedtouseasinglebasedandmultiplebaseddictionary.Intheﬁrst,asingledictionaryisconstructedfromDSURF,SURF,HOG,orLBPdescriptors,afterthatahistogramofwordoccurrencesisgeneratedforeachimageandthesystemperformanceisassessedaccordingly.Inthesecond,theimagegetsahistogramfromeachdictionarywhicharehorizontallyconcatenatedtoformasinglehistogram,whereeachfeaturegetsNentriesinthehistogram,onefromeachdictionary.Thetwoschemesareevaluatedonsixpubliclyavailabledatasets,namelySTARE,DRIVE,DRIDB,HEI-MED,MESSIDOR,andHRFbesideonelocaldatasetobtainedfromtheOakRidgeNationalLab-oratory,USA.Thedatasetshavebeendividedintotwosets:SetAandSetB.SetAcontainsdatafromtheﬁrstclinicalsiteofMESSIDORwhereasSetBcomprisesdatafromthesecondandthirdclinicalsitesofMESSIDOR.ThegoalwastoevaluateSetAbasesonSetBandvice-versa.Insuchway,wewillbeabletotesthowwellthesystemgeneralizewhenthetestsetcontainsdiﬀerentdatathantheonesincludedinthetrainingset.Weachievedameanaccuracyof97.2%withrespecttothesinglebaseddictionary,whileourbestaccuracyisobtainedusingthemultiplebaseddictionarywithameanaccuracyof99.77%whichreﬂectsthediscriminativepowerofthisapproach.Toconclude,thebagofwordsapproachcanplayasigniﬁcantroleintheclassiﬁcationofnormalfundusimagesandabnormalfundusimageswithbrightlesions,alsoithelpsphysiciansintheearlydiagnosisofdiabeticretinopathyasexudatesmightbetheonlysignofdiabeticretinopathyaswediscussedinChapter1.43Chapter6:ConclusionandFutureWork446.2FutureworkInthefuturework,newdirectionsmightbeincludedtotheproposedapproachasfollows:1.Increasingthesizeofthedatasets,andperformingmoreexperiments.2.Introducingapreprocessingsteptolocalizeandsegmenttheopticdisk,becauseoftheconfusionbetweennormalandexudatesimages.3.AddingcolorfeaturestoSURF,HOG,andLBPdescriptors.4.Extendingtheproposedapproachtodealwithmorechallengingspotlesions,namelymicroa-neurysms.Bibliography[1]Fong,D.,Aiello,L.,Gardner,T.,King,G.,Blankenship,G.,Cavallerano,J.,Ferris,F.andKlein,R.(2004).Retinopathyindiabetes.Diabetescare,27(suppl1),pp.84--87.[2]Wild,S.,Roglic,G.,Green,A.,Sicree,R.andKing,H.(2004).Globalprevalenceofdiabetesestimatesfortheyear2000andprojectionsfor2030.Diabetescare,27(5),pp.1047--1053.[3]Yen,G.andLeong,W.(2008).Asortingsystemforhierarchicalgradingofdiabeticfundusimages:apreliminarystudy.InformationTechnologyinBiomedicine,IEEETransactionson,12(1),pp.118--130.[4]Gardner,H.(2012).Challengingthepathophysiologicconnectionbetweensubduralhematoma,retinalhemorrhage,andshakenbabysyndrome.WesternJournalofEmergencyMedicine,13(6),p.535.[5]Scienceofamd.org,(2014).Learn|ScienceOfAMD.[online]Availableat:http://www.scienceofamd.org/learn/[Accessed4May.2014].[6]Niemeijer,M.,vanGinneken,B.,Russell,S.,Suttorp-Schulten,M.andAbramoﬀ,M.(2007).Auto-mateddetectionanddiﬀerentiationofdrusen,exudates,andcotton-woolspotsindigitalcolorfundusphotographsfordiabeticretinopathydiagnosis.Investigativeophthalmology&visualscience,48(5),pp.2260--2267.[7]Tortora,G.andDerrickson,B.,2009.Principlesofanatomyandphysiology.12thed.Chichester:Wiley.[8]Smith,S.,2002.Thescientistandengineer’sguidetodigitalsignalprocessing.1sted.[SanDiego,Calif.]:CaliforniaTechnicalPub.[9]Litzinger,ThomasC.,andKatiaDelRio-Tsonis.EyeAnatomy.EncyclopediaofLifeSciences(2002).[10]Mukherjee,P.,2013.Ophthalmicassistant.1sted.NewDelhi:JaypeeBrothersMedicalPub.[11]Caprette,C.,Lee,M.,Shine,R.,Mokany,A.andDownhower,J.,2004.Theoriginofsnakes(Ser-pentes)asseenthrougheyeanatomy.BiologicalJournaloftheLinneanSociety,81(4),pp.469--482.[12]Garhart,C.andLakshminarayanan,V.,2012.AnatomyoftheEye.SpringerBerlinHeidelberg,pp.73--83.[13]Heimann,H.,Kellner,U.andFoerster,M.,2006.Atlasoffundusangiography.1sted.Stuttgart:Thieme.45BIBLIOGRAPHY46[14]Saine,P.andTyler,M.,2002.Ophthalmicphotography.1sted.Boston:Butterworth-Heinemann.[15]Abràmoﬀ,M.,Garvin,M.andSonka,M.,2010.Retinalimagingandimageanalysis.BiomedicalEngineering,IEEEReviewsin,3,pp.169--208.[16]Retinalmd.com.2014.OphthalmicUltrasound|RetinalConsultants.[online]Availableat:http://www.retinalmd.com/en/services/examination/ophthalmic-ultrasound[Accessed20Apr.2014].[17]Broecker,E.andDunbar,M.,2005.Opticalcoherencetomography:itsclinicaluseforthediagnosis,pathogenesis,andmanagementofmacularconditions.Optometry-JournaloftheAmericanOptometricAssociation,76(2),pp.79--101.[18]Bucca,B.,2014.Ophthalmology|SchoolofMedicine|UniversityofColoradoDenver.[online]Ucden-ver.edu.Availableat:http://www.ucdenver.edu/academics/colleges/medicalschool/centers/BarbaraDavis/Clinical/Pages/Ophthalmology.aspx[Accessed20Apr.2014].[19]Mookiah,M.,Acharya,U.,Chua,C.,Lim,C.,Ng,E.andLaude,A.,2013.Computer-aideddiagnosisofdiabeticretinopathy:Areview.Computersinbiologyandmedicine,43(12),pp.2136--2155.[20]Alghadyan,A.,2011.Diabeticretinopathy–Anupdate.SaudiJournalofOphthalmology,25(2),pp.99--111.[21]Cade,W.,2008.Diabetes-relatedmicrovascularandmacrovasculardiseasesinthephysicaltherapysetting.Physicaltherapy,88(11),pp.1322--1335.[22]DiabeticRetinopathy|PatientEducation|TheRetinaGroupofWashington(RGW).2014.[online]Rgw.com.Availableat:http://rgw.com/patient-education/eye-diseases/diabetic-retinopathy[Accessed21Apr.2014].[23]DiabeticEyeDisease,FactsAbout[NEIHealthInformation].2014.[online]Nei.nih.gov.Availableat:http://www.nei.nih.gov/health/diabetic/retinopathy.asp[Accessed21Apr.2014].[24]Ober,M.,Klais,C.andCunninghamJr,E.,2005.Managementoptionsformacularedema.ReviewofOphthalmologyOctober.[25]Ciulla,T.,Amador,A.andZinman,B.,2003.Diabeticretinopathyanddiabeticmacularedemapathophysiology,screening,andnoveltherapies.Diabetescare,26(9),pp.2653--2664.[26]García,M.,Sánchez,C.,López,M.,Abásolo,D.andHornero,R.(2009).Neuralnetworkbaseddetectionofhardexudatesinretinalimages.ComputerMethodsandprogramsinbiomedicine,93(1),pp.9--19.[27]Deepak,K.andSivaswamy,J.(2012).Automaticassessmentofmacularedemafromcolorretinalimages.MedicalImaging,IEEETransactionson,31(3),pp.766--776.[28]Osareh,A.,Mirmehdi,M.,Thomas,B.andMarkham,R.(2003).Automatedidentiﬁcationofdia-beticretinalexudatesindigitalcolourimages.BritishJournalofOphthalmology,87(10),pp.1220--1223.47BIBLIOGRAPHY[29]Giancardo,L.,Meriaudeau,F.,Karnowski,T.,Li,Y.,Garg,S.,TobinJr,K.andChaum,E.(2012).Exudate-baseddiabeticmacularedemadetectioninfundusimagesusingpubliclyavailabledatasets.Medicalimageanalysis,16(1),pp.216--226.[30]Hijazi,M.,Coenen,F.andZheng,Y.(2011).Retinalimageclassiﬁcationforthescreeningofage-relatedmaculardegeneration.SpringerBerlinHeidelberg,pp.325--338.[31]Hijazi,M.,Jiang,C.,Coenen,F.andZheng,Y.(2011).Imageclassiﬁcationforage-relatedmaculardegenerationscreeningusinghierarchicalimagedecompositionsandgraphmining.SpringerBerlinHeidelberg,pp.65--80.[32]Akram,M.U.;Mujtaba,S.;Tariq,A.,Automateddrusensegmentationinfundusimagesfordiag-nosingagerelatedmaculardegeneration,Electronics,ComputerandComputation(ICECCO),2013InternationalConferenceon,vol.,no.,pp.17,20,7-9Nov.2013.[33]YuanjieZheng;Vanderbeek,B.;Daniel,E.;Stambolian,D.;Maguire,M.;Brainard,D.;Gee,J.,Anautomateddrusendetectionsystemforclassifyingage-relatedmaculardegenerationwithcolorfundusphotographs,BiomedicalImaging(ISBI),2013IEEE10thInternationalSymposiumon,vol.,no.,pp.1448,1451,7-11April2013.[34]vanGrinsven,M.J.J.P.;Chakravarty,A.;Sivaswamy,J.;Theelen,T.;vanGinneken,B.;Sanchez,C.I.,ABagofWordsapproachfordiscriminatingbetweenretinalimagescontainingexudatesordrusen,BiomedicalImaging(ISBI),2013IEEE10thInternationalSymposiumon,vol.,no.,pp.1444,1447,7-11April2013.[35]Ujjwal;Deepak,K.S.;Chakravarty,A.;Sivaswamy,J.,Visualsaliencybasedbrightlesiondetec-tionanddiscriminationinretinalimages,BiomedicalImaging(ISBI),2013IEEE10thInternationalSymposiumon,vol.,no.,pp.1436,1439,7-11April2013.[36]Bock,R.,Meier,J.,Nyúl,L.,Hornegger,J.andMichelson,G.(2010).Glaucomariskindex:Auto-matedglaucomadetectionfromcolorfundusimages.Medicalimageanalysis,14(3),pp.471--481.[37]M.J.Cree,E.Gamble,andD.J.Cornforth,Colournormalisationtoreduceinter-patientandintra-patientvariabilityinmicroaneurysmdetectionincolourretinalimages,inWorkshoponDigitalImageComputing,2005,pp.163-169.[38]Bay,H.,Ess,A.,Tuytelaars,T.andVanGool,L.(2008).Speeded-uprobustfeatures(SURF).Computervisionandimageunderstanding,110(3),pp.346--359.[39]Kim,J.(2012).Advancedmethods,techniques,andapplicationsinmodelingandsimulation.1sted.Tokyo:SpringerBerlinHeidelberg.[40]Evans,C.(2009).Notesontheopensurflibrary.UniversityofBristol,Tech.Rep.CSTR-09-001,January.[41]Dalal,N.;Triggs,B.,Histogramsoforientedgradientsforhumandetection,ComputerVisionandPatternRecognition,2005.CVPR2005.IEEEComputerSocietyConferenceon,vol.1,no.,pp.886,893vol.1,25-25June2005.BIBLIOGRAPHY48[42]Felzenszwalb,P.,Girshick,R.,McAllester,D.andRamanan,D.(2010).Objectdetectionwithdiscriminativelytrainedpart-basedmodels.PatternAnalysisandMachineIntelligence,IEEETrans-actionson,32(9),pp.1627--1645.[43]VLFeat:AnOpenandPortableLibraryofComputerVisionAlgorithms(2008)byA.Vedaldi,B.Fulkerson.[44]Ojala,T.;Pietikainen,M.;Harwood,D.,Performanceevaluationoftexturemeasureswithclassiﬁca-tionbasedonKullbackdiscriminationofdistributions,PatternRecognition,1994.Vol.1-ConferenceA:ComputerVision&ImageProcessing.,Proceedingsofthe12thIAPRInternationalConferenceon,vol.1,no.,pp.582,585vol.1,9-13Oct1994.[45]Ojala,T.,Pietikainen,M.andHarwood,D.(1996).Acomparativestudyoftexturemeasureswithclassiﬁcationbasedonfeatureddistributions.PatternRecognition,1,pp.51--59.[46]Huang,D.,Jo,K.,Lee,H.,Kang,H.andBevilacqua,V.(2009).ProceedingsoftheIntelligentcom-puting5thinternationalconferenceonEmergingintelligentcomputingtechnologyandapplications.Springer-Verlag.[47]Luo,J.(2012).Softcomputingininformationcommunicationtechnology.1sted.Berlin:SpringerBerlinHeidelberg.[48]Wang,X.,Wang,L.andQiao,Y.(2013).Acomparativestudyofencoding,poolingandnormaliza-tionmethodsforactionrecognition.SpringerBerlinHeidelberg,pp.572--585.[49]Chang,C.andLin,C.(2011).LIBSVM:alibraryforsupportvectormachines.ACMTransactionsonIntelligentSystemsandTechnology(TIST),2(3),p.27.[50]Pires,R.;Jelinek,H.F.;Wainer,J.;Goldenstein,S.;Valle,E.;Rocha,A.,AssessingtheNeedforReferralinAutomaticDiabeticRetinopathyDetection,BiomedicalEngineering,IEEETransactionson,vol.60,no.12,pp.3391,3398,Dec.2013[51]MohamedAlyandMarioMunichandPietroPerona.(2011).UsingMoreVisualWordsinBagofWordsLargeScaleImageSearch.Caltech,USA.[52]A.Hoover,V.KouznetsovaandM.Goldbaum,LocatingBloodVesselsinRetinalImagesbyPiece-wiseThrehsoldProbingofaMatchedFilterResponse,IEEETransactionsonMedicalImaging,vol.19no.3,pp.203--210,March2000.[online]Availableat:http://www.ces.clemson.edu/~ahoover/stare/[Accessed18May.2014].[53]M.Niemeijer,J.J.Staal,M.GinnekenB.v.,Loog,andM.D.Abramoﬀ.(2004)DRIVE:digitalreti-nalimagesforvesselextraction.[online]Availableat:http://www.isi.uu.nl/Research/Databases/DRIVE[Accessed18May.2014].[54]Prentasic,P.,Loncaric,S.,Vatavuk,Z.,Bencic,G.,Subasic,M.,Petkovic,T.,Dujmovic,L.,Malenica-Ravlic,M.,Budimlija,N.andTadic,R.(2013).DiabeticRetinopathyImageDatabase(DRiDB):anewdatabasefordiabeticretinopathyscreeningprogramsresearch.pp.711--716.[online]Availableat:http://www.fer.unizg.hr/ipg/resources/image_database[Accessed18May.2014].49BIBLIOGRAPHY[55]Messidor.crihan.fr,(2014).Messidor.[online]Availableat:http://messidor.crihan.fr/index-en.php[Accessed18May.2014].[56]Budai,A.,Hornegger,J.andMichelson,G.(2009).Multiscaleapproachforbloodvesselsegmenta-tiononretinalfundusimages.InvestigativeOphtalmologyandVisualScience,50(5),p.325.[online]Availableat:http://www5.cs.fau.de/research/data/fundus-images/[Accessed18May.2014].