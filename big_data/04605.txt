6
1
0
2

 
r
p
A
6

 

 
 
]

.

C
O
h
t
a
m

[
 
 

2
v
5
0
6
4
0

.

3
0
6
1
:
v
i
X
r
a

A stabilizing iteration scheme for model predictive control

based on relaxed barrier functions

Christian Feller and Christian Ebenbauer ∗

Institute for Systems Theory and Automatic Control

University of Stuttgart, Pfaﬀenwaldring 9, 70550 Stuttgart, Germany

e-mail: {christian.feller,ce}@ist.uni-stuttgart.de

Abstract

We propose and analyze a stabilizing iteration scheme for the algorithmic implementation of model predictive control
for linear discrete-time systems. Polytopic input and state constraints are considered and handled by means of so-
called relaxed logarithmic barrier functions. The required on-line optimization is based on warm starting and performs
only a limited, possibly small, number of optimization algorithm iterations between two consecutive sampling instants.
The optimization algorithm dynamics as well as the resulting suboptimality of the applied control input are taken
into account explicitly in the stability analysis, and the origin of the resulting overall closed-loop system, consisting
of state and optimization algorithm dynamics, is proven to be asymptotically stable. The corresponding constraint
satisfaction properties are also analyzed. The theoretical results and a presented numerical example illustrate the fact
that asymptotic stability as well as a satisfactory closed-loop performance can be achieved by performing only a single
optimization algorithm iteration at each sampling step.

I.

Introduction

Model predictive control (MPC) is a control strategy

that solves, at each sampling instant, a suitably cho-
sen ﬁnite horizon open-loop optimal control problem in
a receding horizon fashion. While there exist various
theoretical results concerning stability properties of the
closed-loop system, see, e.g., [17] and references therein,
these are often based on the assumption that the exact
optimal solution is available immediately when the next
state measurement becomes available. However, this as-
sumption might not be valid when considering applica-
tions in which the optimization algorithm operates on
the same time scale as the system to be controlled, for
example due to fast system dynamics and/or the use of
low-cost hardware. In this case, special measures have to
be taken in order to ensure stability properties, or even
recursive feasibility, of the closed-loop system.
One possible approach is to speed up the optimization
accordingly and then use again the aforementioned time-
scale separation argument. In the case of linear systems,
this might for example be achieved by making use of ex-
plicit MPC solutions [2, 26] or tailored, fast QP algo-

∗This work was supported by the Deutsche Forschungsgemein-
schaft (Emmy-Noether-Grant, Novel Ways in Control and Com-
putation, EB 425/2-1, and Cluster of Excellence in Simulation
Technology, EXC 310/2).

rithms [7, 11, 12, 16, 22, 23, 24, 27]. Another approach is
to settle for approximate solutions and then take the sub-
optimality of the applied inputs explicitly into account
within the stability analysis, see for example [18, 25, 30],
or to compute the optimal solution based on a one-step-
ahead prediction [29]. However, there are only few works
which explicitly consider the dynamics of the optimiza-
tion algorithm and acknowledge the fact that the opti-
mization typically needs to be performed in parallel to
the evolving system dynamics. Interesting exceptions are
given by the works [5, 6], in which the authors present, for
the case of unconstrained nonlinear systems, a so-called
real-time iteration scheme that performs only one New-
ton based optimizer update per sampling instant. The
authors rigorously analyze the combined dynamics con-
sisting of system and optimizer state and provide a proof
that the state of the corresponding overall closed-loop sys-
tem asymptotically converges to zero over time. How-
ever, no input and state constraints are considered and
the theoretical analysis is, as the authors themselves em-
phasize, carried out based on some technical assumptions
that might be hard to verify for general practical appli-
cations. Nevertheless, the results represent a theoretical
underpinning of the proposed iteration scheme and nicely
illustrate possible beneﬁts that might be gained by com-
bining ideas from the areas of MPC stability theory and
optimization algorithms.

1

In contrast to this, we focus in this paper on the linear
MPC case with polytopic input and state constraints and
show that, by making use of the relaxed barrier func-
tion based framework presented in [8, 9], an MPC it-
eration scheme can be derived that allows to guarantee
desirable systems theoretic properties based on standard
linear MPC assumptions that can be easily veriﬁed. The
iteration scheme is based on the idea to predict at each
sampling instant the next system state, start the opti-
mization procedure based on a suitable warm start solu-
tion, and then, at the end of the available computation
time, simply apply the ﬁrst element of the current, possi-
bly suboptimal, optimizer state. Related to this scheme,
the main contributions of this paper are as follows. First,
we present an analysis of the resulting overall closed-loop
system, consisting of plant and algorithm dynamics, in
which we prove that, under standard assumptions, the
origin of the combined state and optimizer dynamics will
be asymptotically stable for any number of internal opti-
mization algorithm iterations – including the case of per-
forming only a single optimizer update at each sampling
step. Second, we also study the resulting constraint satis-
faction properties and show that, for a suitable subset of
feasible initial conditions, the input and state constraints
can be satisﬁed with arbitrary tolerance – including the
case of exact constraint satisfaction – if the underlying
relaxation as well as the initialization of the iteration
scheme are chosen in a suitable way. Third, possible re-
alizations of the underlying optimization algorithm are
discussed based on gradient and Newton-type line search
methods. In summary, we thus present a barrier function
based MPC iteration scheme for which we prove asymp-
totic stability as well as desirable constraint satisfaction
properties of the closed-loop system,
independently of
both the actual realization of the underlying optimization
algorithm and the number of performed optimization al-
gorithm iterations. To the best of our knowledge, an MPC
algorithm with such guaranteed systems theoretic and al-
gorithmic properties has not been discussed so far in the
literature.
Note that eﬃcient optimization algorithms for (nonre-
laxed) barrier function based linear MPC approaches
have,
for example, been discussed in [7, 23, 27, 28].
However, none of the aforementioned works analyzes the
closed loop consisting of both system and optimization
algorithm dynamics, and no proof of stability is given.
Nevertheless, some of the presented concepts may in the
future be helpful for speeding up the required line search
also in the relaxed barrier function based framework.
The paper is organized as follows: necessary background
on relaxed barrier function based MPC as well as some
preliminary results are presented in Section II; in Sec-
tion III, we state and discuss our main results concerning
the outlined MPC iteration scheme; in Section IV we il-
lustrate some related aspects by means of a numerical
example, before we state our conclusions in Section V.

Some remarks on the used notation are in place. R+, R++,
and N+ denote the sets of nonnegative real, strictly pos-
itive real, and strictly positive natural numbers. Sn
+ and
Sn
++ refer to the sets of positive semi-deﬁnite and positive
deﬁnite matrices of dimension n ∈ N+. For any given
matrix M or vector v, M i and vi refer to the i-th row or
element, and kxkM := (x⊤M x)1/2 for M ∈ S+. A poly-
tope is deﬁned as compact intersection of a ﬁnite number
of halfspaces and Bn
r (z0) is the n-dimensional Euclidean
ball with radius r and center z0. For any set S, S ◦ de-
notes the open interior. Moreover, 1 := [1 · · · 1]⊤. A
function α : R+ → R+ with α(0) = 0 is a K-function if it
is continuous and strictly increasing; it is a K∞ function
if α ∈ K and in addition α(s) → ∞ for s → ∞. A func-
tion β : R+ × R+ → R+ is a KL-function if β(·, t) ∈ K for
ﬁxed t ∈ R+ while, for ﬁxed s ∈ R+, the function β(s, ·)
is decreasing and β(s, t) → 0 as t → ∞.

II. Preliminary Results

In the following, we introduce the problem setup as well
as some necessary background on relaxed barrier function
based MPC.

A. Problem setup

We consider the control of linear time-invariant discrete-
time systems of the form

x(k + 1) = Ax(k) + Bu(k) ,

(1)

where x(k) ∈ Rn refers to the vector of system states and
u(k) ∈ Rm refers to the vector of system inputs, both at
time instant k ≥ 0. Moreover, the matrices A ∈ Rn×n and
B ∈ Rn×m describe the corresponding system dynamics,
where we assume (A, B) to be stabilizable. The control
task is to regulate the system state to the origin while
minimizing a given quadratic performance criterion and
satisfying, whenever possible, polytopic state and input
constraints of the form

x(k) ∈ X = {x ∈ Rn : Cxx ≤ dx} ,
u(k) ∈ U = {u ∈ Rm : Cuu ≤ du} ,

(2a)

(2b)

where Cx ∈ Rqx ×n, Cu ∈ Rqu×m and dx ∈ Rqx
++, du ∈
Rqu
++ with qx, qu ∈ N+. Note that both X and U contain
the origin in their interior. In linear MPC, this problem
setup is handled by solving, for current system state x =
x(k) and ﬁnite prediction horizon N ∈ N+, an open-loop
optimal control problem of the form

N −1

J ∗
N (x) = min

u

ℓ(xk, uk) + F (xN )

(3a)

(3b)
(3c)

(3d)

Xk=0

s.t. xk+1 = Axk + Buk, x0 = x ,

xk ∈ X , k = 0, . . . , N − 1, xN ∈ Xf ,
uk ∈ U, k = 0, . . . , N − 1 ,

2

++, P ∈ Sn

where the stage cost ℓ : Rn × Rm → R+ and the terminal
cost F : Rn → R+ are chosen as ℓ(x, u) = kxk2
Q + kuk2
R
and F (x) = kxk2
P for appropriate weight matrices Q ∈
Sn
+, R ∈ Sm
++. Furthermore, u = {u0, . . . , uN −1}
denotes the sequence of control inputs over the predic-
tion horizon N , while Xf refers to a closed and con-
vex terminal constraint set that may be used to guar-
antee stability properties of the closed-loop system. Note
that we make use of subindices to distinguish open-loop
predictions xk, uk from actual state and input trajec-
tories x(k), u(k). The control law is obtained by solv-
ing (3) at each sampling instant k ≥ 0 and applying
u(k) = u∗
0(x(k)) in a receding horizon fashion, where u∗
0
is the ﬁrst element of the optimal input sequence u∗. Dif-
ferent approaches on how to choose the corresponding pa-
rameters in order to guarantee stability properties of the
closed-loop state dynamics are summarized in [17] and
references therein – however, as discussed above, under
the assumption that the exact optimal solution is avail-
able instantaneously.

B. Relaxed Logarithmic Barrier Function Based MPC

The concept of relaxed logarithmic barrier function based
MPC has been proposed recently in [9]. Here, the term
relaxed relates to a logarithmic barrier function that is
smoothly extended by a suitable penalizing term, which
in general
is assumed to be convex and globally de-
ﬁned [3, 14, 20]. For example, a relaxed logarithmic bar-
rier function for the set R+ may be given by

ˆB(z) =(− ln(z)

β(z; δ) := 1

z > δ

(4)

δ (cid:1)2
2h(cid:0) z−2δ

−1i− ln(δ) z ≤ δ,

where δ ∈ R++ denotes the so-called relaxation parameter
and β(·; δ) is a quadratic relaxing function [9, 14]. Ob-
viously, the function ˆB(·) is globally deﬁned, twice con-
tinuously diﬀerentiable, and convex. For a polytopic set
of the form P = {ξ ∈ Rr : Cξ ≤ d} with C ∈ Rq×r,
ˆB(zi(ξ)) with
d ∈ Rq
zi(ξ) = −Ciξ +di and ˆB(·) deﬁned according to (4). Posi-
tive deﬁniteness of the barrier function ˆBP (·) with respect
to the origin can be achieved by making use of suitable
recentering procedures, see [10] and[9] for more details.
For example, when using a weighting based recentering
approach, we obtain

++, we may simply use ˆBP (ξ) =Pq

i=1

ˆBP (ξ) =

q

Xi=1(cid:0)1 + wi(cid:1)(cid:16) ˆB(−Ciξ + di) + ln(di)(cid:17) ,

(5)

which can easily be shown to be positive deﬁnite for any
0 < δ ≤ min{d1, . . . , dq} and any w ∈ Rq
+ satisfying
∇ ˆBP (0) = C ⊤diag( 1
dq )(1 + w) = 0 [10]. For the
rest of the paper we can simply think of the recenter-
ing as a modiﬁcation which ensures positive deﬁniteness
of a (relaxed) barrier function while preserving its main

d1 , . . . , 1

3

characteristics. The open-loop optimal control problem
of relaxed barrier function based MPC then reads

N −1

ˆJ ∗
N (x) = min

u

ˆℓ(xk, uk) + ˆF (xN )

Xk=0

s. t. xk+1 = Axk + Buk, x0 = x .

(6a)

(6b)

+ , wu ∈ Rqu

Here, ˆℓ(x, u) := ℓ(x, u) + ε ˆBx(x) + ε ˆBu(u) is the modi-
ﬁed stage cost, while ˆBx(·) and ˆBu(·) are recentered re-
laxed logarithmic barrier functions of the form (5) for
the polytopic constraint sets X and U in (2) for a given
relaxation parameter δ ∈ R++ and suitable weighting vec-
tors wx ∈ Rqx
+ . The positive scalar ε ∈ R++
is the barrier function weighting parameter which deter-
mines the inﬂuence of the barrier function values on the
overall cost function. Note that the parameters ε and δ
are assumed to take ﬁxed values and are not decreased
to zero, as it is for example done in conventional interior-
point methods or the trajectory optimization approach
discussed in [14]. Furthermore, ˆF : Rn → R+ denotes a
suitable terminal cost function term which, as discussed
in [9], is crucial for the stability properties of the closed-
loop system.
In the following, we consider a quadratic
terminal cost function of the form

ˆF (x) = x⊤P x ,

(7)

where P ∈ Sn
lowing algebraic Riccati equation

++ is a positive deﬁnite solution to the fol-

K = −(cid:0)R + B⊤P B + εMu(cid:1)

P = (A⊤

K P AK + K ⊤(R + εMu)K + Q + εMx ,

−1

B⊤P A

(8a)

(8b)

2δ2 C ⊤

2δ2 C ⊤

with AK := A + BK, Mx := 1
x diag (1 + wx) Cx and
Mu := 1
u diag (1 + wu) Cu, respectively. For more
details on this approach as well as on alternative choices
for ˆF (·), we refer the reader to Section IV.C of [9]. By
eliminating the linear equality constraints and using a
vectorized representation, problem (6) can be formulated
as unconstrained minimization of a cost function of the
form

ˆJN (U, x) =

1
2

U ⊤HU + x⊤F U + x⊤Y x + ε ˆBxu(U, x) , (9)

· · · u⊤

++ , F ∈ Rn×N m, Y ∈ Sn

N −1]⊤ ∈ RN m is the stacked
where U := [u⊤
0
open-loop input vector and ˆBxu : RN m × Rn → R+
is a positive deﬁnite, convex, and continuously diﬀeren-
tiable relaxed logarithmic barrier function for polytopic
constraints of the form GU ≤ d + Ex. The matrices
H ∈ SN m
+, G ∈ Rq×N m, d ∈ Rq,
and E ∈ Rq×n with q = N (qx + qu) can be constructed
from (6) and the corresponding constraints by means of
simple matrix operations, see Appendix A.1. Due to the
design of the relaxed barrier functions, the above cost
function is twice continuously diﬀerentiable and globally
deﬁned. Furthermore, we can state the following results,
for which a proof is given in Appendix A.2.

Lemma 1. Let the cost function ˆJN : RN m × Rn → R+
given in (9) be associated to the relaxed barrier function
based MPC approach based on (4)–(8). Then,

i) ∃ α, ¯α ∈ K∞ such that for all (U, x) ∈ RN m × Rn it

holds that α(k(U, x)k) ≤ ˆJN (U, x) ≤ ¯α(k(U, x)k);

ii) ˆJN (U, x) is strongly convex in U , convex in x, and
there exist σ, L ∈ R++ such that for all (U, x) ∈
RN m × Rn it holds that

III. Main Results

In this section we are going to present our main results,
consisting of the outlined barrier function based MPC
iteration scheme (Section A), an analysis concerning sta-
bility and constraint satisfaction properties of the corre-
sponding closed-loop system (Sections B and C), as well
as a discussion on diﬀerent realizations of the underlying
iterative optimization algorithm (Section D).

σI ≤ ∇2
U

ˆJN (U, x) ≤ LI

(10a)

A. The iteration scheme

k∇U ˆJN (U1, x) − ∇U ˆJN (U2, x)k ≤ LkU1 − U2k ; (10b)

iii) ∃ kf : RN m ×Rn → Rm with kf (0, 0) = 0 such that for

any (U0, x0) with successor state x+

0 := Ax0 + Bu0,

ˆJN (U +

0 , x+

0 ) − ˆJN (U0, x0) ≤ −ˆℓ(x0, u0) ,

(11)

where U +

1

0 :=(cid:2)u⊤

· · ·

u⊤

N −1

k⊤

f (U0, x0)(cid:3)⊤

.

Using property iii) of the above Lemma together with
standard optimality arguments, it is easy to show that,
for any initial condition x(0) ∈ Rn and any k ∈ N, the
feedback u(k) = u∗

0(x(k)) yields

ˆJ ∗
N (x(k + 1)) − ˆJ ∗

N (x(k)) ≤ −ˆℓ(x(k), ˆu∗

0(x(k))) ,

(12)

which implies that the origin of the closed-loop system
will be globally asymptotically stable, cf. Theorem 5 in
[9]. Thus, based on the above relaxed barrier function
based formulation, an asymptotically stabilizing control
input is given by

(13)

u(k) = Π0 ˆU ∗(x(k)), Π0 =(cid:2)Im 0 · · ·

0(cid:3) ,

where ˆU ∗(x) = arg minU ˆJN (U, x) is the state-dependent
minimizer of (9). Note that Lemma 1 implies that for
any given x ∈ Rn, the cost function ˆJN (·, x) belongs to
the class of strongly convex C2 functions with Lipschitz
continuous gradient, for which many well-known and eﬃ-
cient optimization algorithms exist, e.g., like fast and con-
jugated gradient methods, the heavy-ball, or the Newton
method. For these algorithms, we may then in principle
obtain bounds on the number of iterations, and hence on
the computation time, that is required for a given desired
level of suboptimality, cf. [18, 24]. However, in this paper
we want to follow a diﬀerent approach and propose an it-
eration scheme which allows not only to analyze the over-
all closed-loop system consisting of both system state and
optimization algorithm dynamics in an integrated fashion
but also to prove stability properties of this system for an
arbitrary, and not necessarily a priori speciﬁed, number
of optimization algorithm iterations – including the case
of performing only a single optimizer update at each sam-
pling instant.

The rather intuitive idea underlying the following MPC
iteration scheme is to predict at each sampling instant
the next system state, start the optimization procedure
for this predicted state based on a suitable warm start
solution, and then, at the end of the available computa-
tion time, simply apply the ﬁrst element of the current,
possibly suboptimal, optimizer state. A pseudo-code de-
scription of the iteration scheme is given in Algorithm 1
above, while a graphical illustration of the main idea can
be found in Fig. 1. Aiming for a systems theoretic anal-
ysis, we may write the corresponding closed-loop system
dynamics as

x(k + 1) = A x(k) + BΠ0 U (k) ,
x(0) = x0 ,
U (k + 1) = ΦiT(k) (U (k), x(k)) , U (0) = U0 ,

(14a)

(14b)

where (14a) describes the dynamics of the controlled plant
with Π0 ∈ Rm×N m being deﬁned by (13). The dynamics
of the controlled system state are coupled with the dy-
namics of the optimization algorithm, which are described
by (14b). Here, ΦiT(k) : RN m × Rn → RN m denotes a
suitable optimization algorithm operator that describes
how the next optimizer state is computed at each sam-
pling instant k ∈ N based on the current optimizer state
U (k) and the measured system state x(k) by performing
iT(k) ∈ N optimization algorithm iterations. To be more
precise, for given iT(k) ∈ N, the operator ΦiT(k) will be
deﬁned recursively as

Φ0(U, x) = Ψs(U, x)

Φi(U, x) = Ψo(cid:0)Φi−1(U, x), Ax + BΠ0U(cid:1) ,

where a suitable warm start solution for the predicted
next system state x+ =, Ax + BΠ0U is in the ﬁrst step
obtained via the shift operator

(15a)

(15b)

Ψs(U, x) =(cid:2)u⊤

1

u⊤
2

· · ·

u⊤

N −1

⊤

,

(16)

k⊤

f (U, x)(cid:3)

with kf : RN m × Rn → Rm chosen according to Lemma 1.
Furthermore, Ψo : RN m × Rn → RN m denotes a so-called
optimizer update operator. We assume that

ˆJN (Ψo(U, x), x) − ˆJN (U, x) ≤ −γ(U, x)

(17)

for all (U, x) ∈ RN m × Rn, where γ : RN m × Rn → R+ is a
function satisfying γ(U, x) ≥ 0 ∀ (U, x) ∈ RN m × Rn and

4

γ(U, x) = 0 ⇔ ∇U ˆJN (U, x) = 0. Diﬀerent realizations
of the operator Ψo will be discussed later in Section D,
where we will also relate the function γ(·, ·) directly to the
step size and the search direction of the respective opti-
mization algorithm. For the moment, we may think of
ΦiT(k) as an operator that improves the current solution
by applying a ﬁxed number of suitable optimizer updates
to the shifted warm start solution (16). In the context of
the rbMPC approach discussed above, we can exploit the
fact that an explicit expression for a good warm start so-
lution always exists, see property iii) of Lemma 1.
In the
following, we will show that, under rather mild assump-
tions, Algorithm 1 leads to global asymptotic stability of
the overall closed-loop system (14) and in addition allows
us to give hard guarantees concerning the satisfaction of
the now relaxed input and state constraints.

B. Stability properties of the closed-loop system

Concerning the stability properties of the overall closed-
loop system we can state the following results.

Theorem 1. Let the cost function ˆJN : RN m × Rn → R+
given in (9) be associated to the relaxed barrier function
based MPC approach based on (4)–(8). Moreover, con-
sider the closed-loop system (14) with the operator ΦiT(k)
being deﬁned according to (15)–(17). Then, for any se-
quence iT = {iT(0), iT(1), . . . }, the origin (U, x) = (0, 0)
of system (14) is globally asymptotically stable.

Proof: We know that α(k(U, x)k) ≤ ˆJN (U, x) ≤
¯α(k(U, x)k) ∀ (U, x) ∈ RN m × Rn for some α, ¯α ∈ K∞, see
Lemma 1. In the following, we show that ˆJN (U (k), x(k))
will in addition always decrease to zero along trajectories
of the closed-loop system. To this end, assume that we
are given arbitrary initial conditions (U0, x0) ∈ RN m×Rn.
Consider now the next system state x+
0 = Ax0 + BΠ0 U0
as well as U +
0 = Ψs(U0, x0). With the shift operator
Ψs(·, ·) being deﬁned by (16), it holds that

ˆJN (U +

0 , x+

0 ) − ˆJN (U0, x0) ≤ −ˆℓ(x0, Π0 U0)

(18)

due to property iii) of Lemma 1. Thus, U +
can be
0
seen as a warm start solution for the next system state

Algorithm 1 rbMPC iteration scheme

1: for k = 0, 1, 2, . . . do
2:

obtain the current system state x(k);
if k = 0 then set U (0) = U0 ∈ RN m;
apply u(k) = Π0 U (k) with Π0 according to (13);

shift update: ¯U0(k) = Ψs(cid:0)U (k), x(k)(cid:1);

for i = 0, 1, . . . , iT(k) − 1 do optimizer update

¯Ui+1(k) = Ψo( ¯Ui(k), Ax(k) + BΠ0 U (k));

3:
4:

5:

6:
7:

8:

end for
set U (k + 1) = ¯UiT(k)(k);

9:
10: end for

1st iteration phase

2nd iteration phase

3rd iteration . . .

i = 0

i = 1

i = 2

iT(0) = 3

i = 0 i = 1

. . .

iT(1) = 5

i = 0

i = 1

. . .

U (0) = U0

U (1) = Φ3(cid:0)U (0), x(0)(cid:1)

U (2) = Φ5(cid:0) . . .

)
k
(
U

U0

e
t
a
d
p
u

t
f
i

h
s

(cid:9) optimizer update

e
t
a
d
p
u

t
f
i

h
s

(cid:9) optimizer update

e
t
a
d
p
u

t
f
i

h
s

measure x(0)

measure x(1)

measure x(2)

k = 0

k = 1

k = 2

· · ·

Figure 1: Schematic illustration of the proposed rbMPC it-
eration scheme with three optimizer iterations in the ﬁrst and
ﬁve optimizer iterations in the second iteration phase (scalar
case). The resulting control law is u(k) = Π0 U (k).

lead to an even further decrease.

that will lead to a decrease in the cost function. Fur-
thermore, condition (17) ensures that the optimization
i.e., applying the operator Ψo(·, ·),
algorithm update,
will
In particu-
lar, ˆJN (Φi(U0, x0), x+
0 ) ≤ ˆJN (U +
0 ) − γ(U +
0 ) ≤
ˆJN (U0, x0) − ˆℓ(x0, Π0 U0) − γ(U +
0 ) for any number
i ∈ N+ of optimization algorithm iterations. As the above
also holds for any (U (k), x(k)), this ﬁnally leads to

0 , x+
0 , x+

0 , x+

ˆJN (U (k + 1), x(k + 1)) − ˆJN (U (k), x(k))

≤ −ˆℓ(x(k), Π0 U (k)) − γ(U +(k), x+(k))

(19)

for all k ∈ N, where U +(k) := Ψs(U (k), x(k)) and
x+(k) = Ax(k) + BΠ0 U (k). As both ˆℓ(·, ·) and γ(·, ·)
are nonnegative, this implies that (U, x) = 0 is stable.
In particular k(U (k), x(k))k ≤ α−1(¯α(k(U (0), x(0))k)) by
property i) of Lemma 1. Furthermore, the only solution
that can stay identically in Ω = {(U, x) ∈ RN m × Rn :
ˆℓ(x, Π0 U ) + γ(U +, x+) = 0} is given by (U, x) = 0, by
which global asymptotic stability of the origin follows
from the Barbashin-Krasovskii Theorem [13]. The fact
that Ω = {0} can be shown with the following argu-
ments. First of all, positive deﬁniteness of ˆℓ(·, ·) implies
x = 0 as well as Π0 U = 0. As a direct consequence,
x+ = Ax + BΠ0 U = 0. Moreover, γ(U +, x+) = 0 implies
that U + = ˆU ∗(x+) and, hence, U + = ˆU ∗(0) = 0. As
U + = Ψs(U, x) with Ψs(·, ·) deﬁned according to (16), it
follows that ui = 0 for i = 1, . . . , N − 1. Together with
Π0 U = u0 = 0, this ﬁnally shows that U = 0.
(cid:4)

A direct consequence of Theorem 1 is that a ﬁxed number
of optimization algorithm updates may be chosen by the
user without jeopardizing the stability properties of the
overall closed-loop system – including the case of perform-
ing only one optimizing step at each sampling instant. On
the other hand, iT(k) may also be time-varying and im-
plicitly deﬁned as the number of iterations after which the
optimization algorithm is forced to return a solution. In
this light, Algorithm 1 can be seen as a stabilizing any-
time MPC algorithm in the sense that it returns a valid
and asymptotically stabilizing control input after each of
its internal iterations, cf. [1]. Note, however, that no sat-

5

uration or truncation of input or state variables has been
considered, cf. Remark 4 in [10].

Remark 1. We want to emphasize that procedures like
computing the control input with a one-step-ahead pre-
diction or performing only a limited number of optimiza-
tion algorithm iterations are well-known in the literature,
see [25, 27, 29] and, in particular, [5, 6]. To the best of
the authors knowledge, however, no iteration scheme of
the form (14) with stability properties as in Theorem 1
has been presented so far. Note also that the presented
stability results follow directly from the properties of the
relaxed barrier function based MPC approach and that no
additional assumptions are needed.

Remark 2. Note that Theorem 1 implies that if the opti-
mizer dynamics are initialized with kU0k ≤ α0(kx0k) for
some α0 ∈ K∞, then the controlled system state dynam-
ics will be asymptotically stable in the sense that there
exists βx ∈ KL such that kx(k)k ≤ βx(kx0k, k) for all
x(0) = x0 ∈ Rn.
1 Suitable initializations with this
property are for example given by U0 = ˆU ∗(x0), i.e., the
optimal relaxed barrier function based input for x0, by
U0 = ¯Kx0 with ¯K ∈ RN m×n, or simply by U0 = 0.

C. Guarantees on closed-loop constrain satisfaction

When applying the above MPC iteration scheme, the in-
put and state constraints in (2) may be violated in closed-
loop operation due to the relaxation of the underlying bar-
rier functions. However, depending on the choice of the
relaxation parameter δ and the initialization of the itera-
tion scheme, we can nevertheless state several interesting
results concerning the constraint satisfaction properties of
the closed-loop system. We begin our studies with the fol-
lowing Theorem, which provides an upper bound on the
maximal constraint violation that is, in addition, shown
to be monotonically decreasing over time.

Theorem 2. Let the cost function ˆJN : RN m × Rn → R+
given in (9) be associated to the relaxed barrier func-
tion based MPC approach based on (4)–(8). Consider
system (14) with the operator ΦiT(k) being deﬁned ac-
cording to (15)–(17). Moreover, let {x(0), x(1), . . . } and
{u(0), u(1), . . . } with u(k) = Π0 U (k) denote the result-
ing closed-loop state and input trajectories. Then, for
any initialization (U0, x0) ∈ RN m × Rn, any sequence
iT = {iT(0), iT(1), . . . }, and any k ∈ N it holds that

Cxx(k) ≤ dx + ˆzx(k), Cuu(k) ≤ du + ˆzu(k),

(20)

where the elements of the maximal constraint violation
vectors ˆzx(k) ∈ Rqx and ˆzu(k) ∈ Rqu decrease monotoni-
cally over time and are given by (23). Furthermore, there
exists a ﬁnite k0 ∈ N such that ˆzx(k) ≤ 0, ˆzu(k) ≤ 0
∀k ≥ k0.

1If β ∈ KL is the KL function related to the stable overall system

dynamics (14), then βx(r, s) = β((α0 + id)(r), s).

6

Proof:

The proof consists of two parts. First we
show that for any k ∈ N, the relaxed barrier functions
satisfy

ε ˆBx(x(k)) ≤ ˆJN (U (k), x(k)) − x(k)⊤P ∗
ε ˆBu(u(k)) ≤ ˆJN (U (k), x(k)) − x(k)⊤P ∗

ucx(k) ,
ucx(k) ,

(21a)

(21b)

uc ∈ Sn

where P ∗
++ is the solution to the discrete-time al-
gebraic Riccati equation (DARE) related to the inﬁnite-
horizon LQR problem for the setup (A, B, Q, R).
In a
second step we then derive an upper bound for the maxi-
mal constraint violations and use the decrease of the value
function to show the claimed monotonicity result.
Part 1. Based on (19) and positive deﬁniteness of γ(·, ·),
we know that ˆJN (U (i + 1), x(i + 1)) − ˆJN (U (i), x(i)) ≤
−ˆℓ(x(i), u(i)) for any i ∈ N and any initialization
(U0, x0) ∈ RN m × Rn, which in particular implied
that limi→∞ ˆJN (U (i), x(i)) = 0.
Summing up over
all future sampling instants beginning at i = k and
using a telescoping sum on the left hand side, we
ˆℓ(x(i), u(i)) for any k ∈
ˆℓ(x(i), u(i)) ≥
N.
ˆBx(x(i))+ ˆBu(u(i)) due to the def-
x(k)⊤P ∗
inition of ˆℓ(·, ·) and the optimality of the unconstrained
inﬁnite-horizon LQR solution. In combination, this yields
ˆBx(x(i)) +
ˆJN (U (k), x(k)) ≥ x(k)⊤P ∗
ˆBu(u(i)) and ﬁnally, since all terms in the sum on
the right hand side are positive deﬁnite, ε ˆBx(x(k)) ≤
uc x(k) as well as ε ˆBu(u(k)) ≤
ˆJN (U (k), x(k)) − x(k)⊤P ∗
ˆJN (U (k), x(k)) − x(k)⊤P ∗
uc x(k) ∀ k ∈ N.
Part 2. For ease of notation, let us deﬁne
ˆα(k) := ˆJN (U (k), x(k)) − x(k)⊤P ∗

get ˆJN (U (k), x(k)) ≥ P∞

it holds that P∞

uc x(k) + εP∞

uc x(k)+εP∞

Furthermore,

(22)

uc x(k) .

i=k

i=k

i=k

i=k

From (21) and (22) it follows immediately that upper
bounds for the maximal violations of state and input con-
straints are given by

(23a)

(23b)

ˆzi
x(k) = max

xξ − di

ˆzj
u(k) = max

uv − dj

ξ (cid:8)Ci
v (cid:8)Cj

x(cid:12)(cid:12) ε ˆBx(ξ) ≤ ˆα(k)(cid:9) ,
u(cid:12)(cid:12) ε ˆBu(v) ≤ ˆα(k)(cid:9) ,

where i = 1, . . . , qx and j = 1, . . . , qu This shows that (20)
holds with the elements of ˆzx(k) ∈ Rqx and ˆzu(k) ∈
Rqu given by (23). Note that the optimization prob-
lems in (23) are convex as the involved barrier func-
tions are convex. Moreover, as can be seen from the fol-
lowing arguments, ˆα(k) is monotonically decreasing and
limk→∞ ˆα(k) = 0. On the one hand, the decrease in the
cost function implies that ˆα(k + 1) − ˆα(k) = ˆJN (U (k +
1), x(k + 1)) − ˆJN (U (k), x(k)) − x(k + 1)⊤P ∗
uc x(k + 1) +
x(k)⊤P ∗
uc x(k +
uc x(k). On the other hand, ˆℓ(x(k), u(k)) =
1) + x(k)⊤P ∗
ℓ(x(k), u(k)) + ε ˆBx(x(k)) + ε ˆBu(u(k)), while the prin-
ciple of optimality ensures that ℓ(x(k), u(k)) + x(k +
1)⊤P ∗

uc x(k) ≤ −ˆℓ(x(k), u(k)) − x(k + 1)⊤P ∗

uc x(k + 1) ≥ x(k)⊤P ∗
ˆα(k + 1) − ˆα(k) ≤ −ε( ˆBx(x(k)) + ˆBu(u(k))) ,

uc x(k). Thus,

(24)

x(k) and ˆzj

which proves our claims since ˆBx(·) and ˆBu(·) are positive
deﬁnite. By these properties of ˆα(·), it follows immedi-
ately that ˆzi
u(k) given by (23) also decrease
monotonically over time. Finally, as both x(k) and u(k)
converge asymptotically to the origin (see Theorem 1),
there exists a ﬁnite k0 ∈ N such that ˆzx(k) ≤ 0, ˆzu(k) ≤ 0
∀ k ≥ k0.
(cid:4)

Remark 3. Note that the above results imply that the
maximal violations of the state and input constraints will
always be upper bounded by ˆzx(0) and ˆzu(0), respectively,
which can for a given initialization (U0, x0) be computed
by solving the convex optimization problems stated in (23)
for ˆα(0) := ˆJN (U0, x0) − x⊤

0 P ∗

uc x0.

Thus, for any choice of the relaxation parameter δ, an
upper bound for the maximal possible constraint viola-
tion can be computed a priori. What is more, the fol-
lowing result, in fact, shows that we can in many cases
ensure approximate (or even exact) constraint satisfac-
tion by choosing relaxation parameter and initialization
accordingly. In particular, the core message of the follow-
ing theorem is, that at least for a suitable set of feasible
initial conditions, the input and state constraints can be
satisﬁed with any desired tolerance if we choose δ small
enough and initialize the iteration scheme good enough,
i.e., close enough to the optimal solution.
Theorem 3. Let the cost function ˆJN : RN m × Rn → R+
given in (9) be associated to the relaxed barrier function
based MPC approach based on (4)–(8). Consider sys-
tem (14) with the operator ΦiT(k) being deﬁned according
to (15)–(17). Let {x(0), x(1), . . . } and {u(0), u(1), . . . }
with u(k) = Π0 U (k) denote the resulting closed-loop state
and input trajectories. Furthermore, assume (A, B) to be
controllable and let the set XN be deﬁned as

XN = {x ∈ Rn : ∃ U ∈ RN m, uk ∈ U, such that
xk(U, x) ∈ X , xN (U, x) = 0} ,

(25)

where x0 = x while xk(U, x) for k = 1, . . . , N are given
according to (43). Then, for any compact set of initial
+ , ˆzu,tol ∈ Rqu
conditions X0 ⊆ X ◦
+ ,
there exists ¯δ0 ∈ R++ and µ ∈ K∞ such that for any re-
laxation parameter 0 < δ ≤ ¯δ0, any x0 ∈ X0, any initial-
µ(δ)( ˆU ∗(x0)), any iT = {iT(0), iT(1), . . . },
ization U0 ∈ BN m
and any k ∈ N, it holds that

N and any ˆzx,tol ∈ Rqx

Cxx(k) ≤ dx + ˆzx,tol , Cuu(k) ≤ du + ˆzu,tol .

(26)

Proof: We proof the result for the case of no con-
straint violation, i.e. ˆzx,tol = 0, ˆzu,tol = 0, which com-
prises all cases with positive tolerances. The proof con-
sists of two parts. First, we show that there exists for any
δ ∈ R++ a compact and nonempty set ˆZN (δ) ⊆ RN m × Rn
such that for any (U0, x0) ∈ ˆZN (δ), the state and input
constraints will be satisﬁed also for all future steps, i.e.,
(26) will hold with ˆzx,tol = 0, ˆzu,tol = 0. Then, we show in
the second part that for any compact set X0 ⊆ X ◦
N there

exists ¯δ0 ∈ R++ and µ ∈ K∞ such that if δ ≤ ¯δ0, x0 ∈ X0,
and U0 ∈ BN m
Part 1. Let us for a given relaxation parameter δ ∈ R++
deﬁne the scalars ¯βx(δ), ¯βu(δ), ¯β(δ) ∈ R++ as

µ(δ)( ˆU ∗(x0)), then (U0, x0) ∈ ˆZN (δ).

¯βx(δ) := min
i,ξ
¯βu(δ) := min
j,v

{ ˆBx(ξ)| Ci

xξ = di

x}, i = 1, . . . , qx ,

{ ˆBu(v)| Cj

uv = dj

u}, j = 1, . . . , qu ,

¯β(δ) = min{ ¯βx(δ), ¯βu(δ)} .

(27a)

(27b)

(27c)

Note that ¯βx(δ) and ¯βu(δ) can be interpreted as lower
bounds for the values that are attained by the relaxed bar-
rier functions on the boundaries of the constraint sets X
and U, respectively. As a consequence, the ¯β(δ)-sublevel
sets of ˆBx(·) and ˆBu(·) will always be contained within
the sets X , U – see Lemma 2 in the Appendix. Based on
this observation and inspired by the proof of Theorem 2,
we introduce

(28)

(29)

ˆα(U, x) := ˆJN (U, x) − x⊤P ∗

uc x

and deﬁne the set ˆZN (δ) ⊂ RN m × Rn as

uc ∈ Sn

ˆZN (δ) :=(cid:8)(U, x) ∈ RN m×Rn | ˆα(U, x) ≤ ε ¯β(δ)(cid:9) ,

where ¯β(δ) is given by (27) and P ∗
++ is again the so-
lution to the DARE related to the inﬁnite-horizon LQR
problem for (A, B, Q, R). Suppose now that (U0, x0) ∈
ˆZN (δ). Based on the proof of Theorem 2, we know that
ε ˆBx(x(k)) ≤ ˆα(U (k), x(k)), ε ˆBu(u(k)) ≤ ˆα(U (k), x(k)),
see (21).
In addition, ˆα(U (k), x(k)) ≤ ˆα(U0, x0) for all
k ∈ N, cf. (24). So if (U0, x0) ∈ ˆZN (δ), then ˆBx(x(k)) ≤
¯β(δ), ˆBu(u(k)) ≤ ¯β(δ), which by the deﬁnition of ¯β(δ)
and Lemma 2 implies that x(k) ∈ X , u(k) ∈ U for all
k ∈ N. Thus, for given δ ∈ R++, (26) holds with ˆzx,tol = 0,
ˆzu,tol = 0 whenever (U0, x0) ∈ ˆZN (δ).
Part 2. In the following, we are going to prove our sec-
ond claim, i.e., the existence of ¯δ0 ∈ R++ and µ ∈ K∞
with the properties speciﬁed above. As we need to vary
the relaxation parameter, we make the inﬂuence of δ on
the cost function more explicit.
In particular, we will
use ˆJN (U, x; δ) to denote the value of the cost function
for (U, x) ∈ RN m × Rn and a given relaxation parame-
ter δ ∈ R++. In accordance with (28), we further deﬁne
ˆα(U, x; δ) := ˆJN (U, x; δ) − x⊤P ∗
uc x. Based on this nota-
tion, it obviously holds that

(U0, x0) ∈ ˆZN (δ) ⇔ ˆα(U0, x0; δ) ≤ ε ¯β(δ) .

(30)

We now proceed as follows: ﬁrst we show in a) that for a
ﬁxed x0 ∈ X0 ⊆ X ◦
N and a corresponding suitably chosen
U0 there exists a δ′
0(x0) such that (30) holds for all
δ ≤ δ′
0(x0); in part b), we then show the claimed result
for X0 by uniformly choosing ¯δ0 = minx0∈X0 δ′
N and let ˜U ∗(x0) and
a) Assume x0 ∈ X0 ⊆ X ◦
˜J ∗
N (x0) = ˜JN ( ˜U ∗(x0), x0) denote the optimal
input
vector and value function for a nonrelaxed barrier

0(x0).

7

x, −Cj

x˜xk + di

u ˜uk + dj

function based problem formulation with additional
constraint xN = 0, see Lemma 3 in the Appendix.
Note that the additional constraint xN = 0 is required
in order to ensure that ˜J ∗
N (x0) does not depend on δ
via the quadratic terminal cost deﬁned in (7) and
(8). By deﬁnition, ˜U ∗(x0) exists for any x0 ∈ X0 and
results in strictly feasible state and input sequences
{˜x0, ˜x1, . . . ˜xN } and {˜u0, ˜u1, . . . ˜uN −1}, respectively. Now
deﬁne δ0(x0) := mini,j,k{−Ci
u},
where i = 1, . . . , qx, j = 1, . . . , qu, k = 0, . . . , N − 1,
which characterizes the minimal distance of the non-
relaxed open-loop trajectories to the boundaries of the
respective constraint sets. Due to (4), the cost function
values of relaxed and nonrelaxed formulation will be
identical, i.e., ˆJN ( ˜U ∗(x0), x0; δ) = ˜J ∗
N (x0), if we choose
δ ≤ δ0(x0), see also [14]. In addition, it always holds by
N (x0; δ) ≤ ˆJN ( ˜U ∗(x0), x0; δ) and, hence,
deﬁnition that ˆJ ∗
N (x0; δ) ≤ ˜J ∗
ˆJ ∗
N (x0) for all δ ≤ δ0(x0). As the smooth
and convex problem formulation ensures that ˜U ∗(x0) will
be continuous, see Lemma 3 in the Appendix, δ0(x0) will
be a continuous function of x0.
Next, we derive an upper bound for the cost function
ˆJN (U0, x0; δ) for input vectors U0 in the neighborhood
of ˆU ∗(x0). Assume that δ ≤ δ0(x0) and consider
U0 ∈ BN m
i.e.
U0 = ˆU ∗(x0) + µ0d, kdk ≤ 1. Due to Taylor’s Theorem,
it holds that ˆJN (U0, x0; δ) =
see [21, Theorem 2.1],
µ0∇U ˆJN ( ˆU ∗(x0), x0; δ)⊤d+
ˆJN ( ˆU ∗(x0), x0; δ)
+
ˆJN ( ˆU ∗(x0)+sd, x0; δ)d for some s ∈ (0, 1). But,
1
2 µ2
together with ˆJN ( ˆU ∗(x0), x0; δ) = ˆJ ∗
N (x0),
this implies

µ0 ( ˆU ∗(x0)) for arbitrary µ0 ∈ R++,

N (x0; δ) ≤ ˜J ∗

0d⊤∇2
U

ε(1 + ¯w)

µ2
0
2

kH +

N (x0)+

ˆJN (U0, x0; δ) ≤ ˜J ∗

δ2 G⊤Gk2 , (31)
where we used that kdk ≤ 1, ∇U ˆJN ( ˆU ∗(x0), x0; δ) = 0,
and ∇2
δ2 G⊤G for any (U, x) ∈
U
RN m × Rn, see the proof of Lemma 1. Let us now choose
µ0 = δ. Then, it follows from (31) that for any x0 ∈ X0,
any U0 ∈ BN m

( ˆU ∗(x0)), and any δ ≤ δ0(x0),

ˆJN (U, x; δ) ≤ H + ε(1+ ¯w)

δ

ˆJN (U0, x0; δ) ≤ ˜J ∗

N (x0) +

1
2

kδ2H + ε(1 + ¯w)G⊤Gk . (32)

This shows that the cost function value, and hence also
ˆα(U0, x0; δ) in (30), will stay bounded for any δ ≤ δ0(x0).
Let us now choose δ′
0(x0) ≤ δ0(x0) in such a way that
the right hand side of (30) is satisﬁed for all δ ≤ δ′
0(x0),
which then implies via (30) that (U0, x0) ∈ ˆZN (δ).
In
particular, we deﬁne δ′
0(x0) := max{δ ∈ R++ | δ ≤ δ0(x0),
uc x0 ≤ ε ¯β(δ)}. In
˜J ∗
N (x0)+ 1
combination with (22), it follows from (32) that the right
hand side of (30) is satisﬁed for any δ ≤ δ′
0(x0). Hence,
(U0, x0) ∈ ˆZN (δ) for any δ ≤ δ′
0(x0). We may picture
the construction of δ′
0(x0) as decreasing δ from δ(x0) un-
til also the second condition in the foregoing deﬁnition is
satisﬁed. As ¯β(δ) is strictly monotonic and grows with-
out bound for decreasing δ, this can always be achieved,

2 kδ2H +ε(1+ ¯w)G⊤Gk−x⊤

0 P ∗

0(x0) is continuous.

which shows that δ′(x0) exists for any x0 ∈ X ◦
N . More-
over, since ¯β(δ) is continuous in δ and both δ0(x0) and
˜J ∗
N (x0) are continuous in x0, see Lemmas 2 and 3 in the
Appendix, δ′
b) Consider now an arbitrary compact set X0 ⊆ X ◦
N
and deﬁne ¯δ0 ∈ R++ as ¯δ0 = minx0∈X0 δ′
0(x0). Due
to the continuity of δ′
0(x0) and the compactness of X0,
this value always exists by virtue of the Weierstraß ex-
treme value theorem. Then, by the above arguments,
(U0, x0) ∈ ˆZN (δ) for any δ ≤ ¯δ0 and any x0 ∈ X0 if we
µ(δ)( ˆU ∗(x0)) with µ(·) = id ∈ K∞,
choose U0 as U0 ∈ BN m
which proves our second claim. As mentioned above, the
zero tolerance case comprises all other cases with nonzero
tolerances ˆzx,tol ∈ Rqx
(cid:4)

+ , ˆzu,tol ∈ Rqu
+ .

Remark 4. Note that the above results, including the
restriction of x0 to the set X ◦
N , are more of a conceptual
nature and tend to be rather conservative when compared
to the actual closed-loop behavior, see also Section IV.
For practical applications, more appropriate choices or
selection regimes for δ and U0 may for example be found
based on numerical simulations.

D. Choosing the optimizer update operator

Apart from condition (17), we provided up to now no
explicit characterization of the optimizer update operator
Ψo : RN m × Rn → RN m. In the following, we propose to
choose Ψo(·, ·) based on a line search method of the form

Ψo(U, x) = U + s p(U, x) ,

(33)

where s ∈ R++ is a step size parameter and p : RN m ×
Rn → RN m is chosen according to a a suitable search
direction rule. Note that the step size s is not ﬁxed but
has to be chosen at each iteration step based on the cur-
rent search direction. In order to ensure a cost function
decrease at each optimizer update, we are especially in-
terested in search direction and step size selection ap-
proaches which ensure that p and s satisfy the so-called
strong Wolfe conditions [21]

ˆJN (U + sp, x) ≤ ˆJN (U, x) + c1s ∇U ˆJN (U, x)⊤p
|∇U ˆJN (U + sp, x)⊤p| ≤ c2|∇U ˆJN (U, x)⊤p|

(34a)

(34b)

for positive constants c1, c2 ∈ R++ with 0 < c1 < c2 < 1.
In fact, (34a) ensures that (17) will hold with γ(U, x) =
−c1s ∇U ˆJN (U, x)⊤p(U, x) if p = p(U, x) is chosen as a de-
scent direction, i.e., if ∇U ˆJN (U, x)⊤p(U, x) < 0 whenever
∇U ˆJN (U, x) 6= 0. Suitable approaches for the choice of
p = p(U, x) are for example given by the gradient method
(G), the conjugated gradient method (CG), the Newton
method (N), or the Quasi-Newton method (QN), i.e.

G : p(U, x) = −∇U ˆJN (U, x) ,

CG : p(U, x) = −∇U ˆJN (U, x) + βCG p−1 ,

(35)

(36)

N : p(U, x) = −(cid:16)∇2

U

ˆJN (U, x)(cid:17)−1

∇U ˆJN (U, x) ,

(37)

8

QN : p(U, x) = − ˆB ∇U ˆJN (U, x) .

(38)

Here, ˆB ∈ SN m
++ is a suitably updated approximation of
the inverse Hessian matrix, for example computed by us-
ing the well-known BFGS formula, while βCG in (36) is a
scalar that ensures that p(U, x) is conjugate to the previ-
ously used search direction p−1, see [21] for more details.
In combination with a suitable step size selection pro-
cedure, all the aforementioned approaches can be shown
to provide a descent direction, which implies that any of
them may be used within the optimizer update operator
of the above MPC iteration scheme. In particular, we can
state the following corollary.

Corollary 1. Let the cost function ˆJN : RN m ×Rn → R+
given in (9) be associated to the relaxed barrier func-
tion based MPC approach based on (4)–(8). Moreover,
consider the closed-loop system (14) with the operator
ΦiT(k) deﬁned according to (15), (16), and (33), where
p = p(U, x) is chosen according to one of the approaches
in (35)–(38) with p and s satisfying the strong Wolfe con-
ditions (34) at each internal iteration. Then, for any se-
quence iT = {iT(0), iT(1), . . . }, the origin (U, x) = (0, 0)
of system (14) is globally asymptotically stable. More-
over, concerning the maximal possible constraint viola-
tions, Theorem 2 and Theorem 3 apply.

As the cost function ˆJN (·, x) is continuously diﬀeren-
tiable and bounded from below and p = p(U, x) is a de-
scent direction, there always exists a nonempty interval
of step lengths such that the strong Wolfe condition (34)
will be satisﬁed, see Lemma 3.1 in [21]. For a discussion
of suitable step size selection procedures we refer the in-
terested reader to [21, Chapter 3.4].
A particular interesting case is to use the Newton search
direction from (37) together with a so-called backtrack-
ing line search, in which a suitable step size is found by
increasing an integer parameter j starting from j = 0
until s = ρj satisﬁes the Armijo condition (34a), where
ρ ∈ (0, 1) is an a priori chosen design parameter. With the
help of (10a), it can be shown that (34a) will be satisﬁed
for all s ≤ ¯s := 2σ(1 − c1)/L, see Appendix A.4, which
implies that the backtracking line search will always ter-
minate with a step size not smaller than 2ρσ(1 − c1)/L.
From this, we can derive the following upper bound on
the number of backtracking line search iterations

j ≤ jmax := 1 + logρ (2σ(1 − c1)/L) ,

(39)

which then yields the following upper bound for the over-
all complexity that is inferred by the proposed MPC it-
eration scheme in each sampling step

Citer(k) ≤ Cshift + iT(k) (jmax Cbt + Cnd) .

(40)

Here, Cshift and Cbt refer to the computational complexi-
ties of performing one shift update and one backtracking
line search iteration, respectively, while Cnd denotes the

complexity of computing the Newton direction. It can be
expected that the complexity of the Newton step will in
most cases dominate the other terms. A thorough com-
plexity analysis as well as a discussion on how the com-
plexity of the optimizer update (33) can be reduced is the
topic of ongoing research. Nevertheless, the above argu-
ments already allow to compute a rough estimate of the
number of possible algorithm iterations for a given sam-
pling time, or, vice versa, to choose a suitable sampling
time for a desired number of optimizer updates.

IV. Numerical Example

We want to brieﬂy illustrate some aspects of the discussed
barrier function based MPC iteration scheme by means of
an academic numerical example. The discussion deliber-
ately focuses on the systems theoretic properties analyzed
above, leaving a thorough investigation of the related nu-
merical aspects for future work. Considered is a double
integrator system of the form

x(k + 1) =(cid:20)1 Ts

0

1(cid:21) x(k) +(cid:20)T 2

Ts(cid:21) u(k) , Ts = 0.1 ,

s

(41)

+ , wu ∈ Rqu

with the input and state constraint sets U and X being
deﬁned by U = {u ∈ R : |u| ≤ 1} and X = {x ∈ R2 :
−2 ≤ x1 ≤ 3, |x2| ≤ 1}, respectively. Prediction horizon,
weight matrices, and barrier function parameters are cho-
sen as N = 30, Q = diag(1, 0.1), R = 0.1, ε = 10−3, and
δ = 10−3 if not stated otherwise. The weighting vectors
wx ∈ Rqx
+ for the recentering are computed
according to the procedure presented in [10]. The barrier
function based MPC cost function is formulated based
on the design from Section B, and the proposed iteration
scheme is, combined with the line search approaches from
Section D, implemented and tested for various initializa-
tions (U0, x0). A backtracking line search with ρ = 0.5 is
used for the gradient and Newton method, while the more
involved step size procedure from Mor´e and Thuente is
used for both the conjugated gradient and Quasi-Newton
method, see [19]. The Wolfe condition parameters are
chosen as c1 = 10−3, c2 = 0.9. The inverse Hessian ap-
proximation ˆB in the Quasi-Newton method is initialized
with H −1 and then handed over between consecutive sam-
pling instances. Fig. 2 summarizes exemplary closed-loop
results for the case of applying only one optimizer update
per sampling step, i.e. iT(k) = 1 ∀ k ∈ N.
The left subplot of Fig. 2 illustrates that a quite good
closed-loop performance,
including the satisfaction of
state constraints, can be achieved even when the itera-
tion scheme is initialized with a suboptimal (and in many
cases infeasible) U0 = ¯Kx0. For the example at hand,

¯K = [K ⊤ . . . (A + BK)N −1⊤

K ⊤] ,

(42)

which corresponds to initialization with the open-loop in-
put sequence resulting from the controller gain K in (8a).

9

2
x

e
t
a
t
s

1.5

1

0.5

0

-0.5

-1

-1.5

-2

x0,3

XK

′

x0,1

X

N

x0,2

-2

-1

0
1
state x1

2

3

800

600

400

200

)
)
k
(
x

,
)
k
(
U
(
N
ˆJ

0

0

shift update only
Gradient
Conj. Gradient
Quasi-Newton
Newton
full optimization

120

100

80

60

40

20

)
)
k
(
x

,
)
k
(
U
(
N
ˆJ

shift update only
Gradient
Conj. Gradient
Quasi-Newton
Newton
full optimization

10

20

sampling instant k

30

0

0

10

20

30

sampling instant k

Figure 2: Left: Closed-loop state trajectories for the rbMPC iteration scheme when applying only one Newton iteration per
sampling step. For x0,1 = [2.5, −0.65], we vary the relaxation parameter δ ∈ {0.1, 2.5×10−2, 10−2, 10−3}; for x0,2 = [−1.5, −1.5],
we plot for comparison also the optimal trajectory [+] corresponding to iT(k) = 100; for x0,3 = [1, 1.25], we compare the
behavior for the initializations U0 = ¯Kx0 [◦], U0 = ˆU ∗(x0) [+], and U0 = 0 [×]. Also depicted are the constraint set X , the set
XK = {x ∈ X : Kx ∈ U} and the feasible set X ′
Middle: Averaged evolution of the cost function for 200 random initial conditions x0 and U0 = ¯Kx0. Newton based optimization
achieves the fastest decay, while the gradient method is almost similar to applying only the shift operator (iT(k) ≡ 0).
Right: Averaged evolution of the cost function for 200 random initial conditions x0 and U0 = ˆU ∗(x0). Performing a single
Newton step at each sampling instant achieves almost the same behavior as when applying the optimal solution.

N = {x ∈ X : ∃U ∈ RNm s.t. GU ≤ Ex + d}.

It turns out that, although the initialization is far from
optimal, almost exact constraint satisfaction (in input
and states) can be achieved for x0,1 whenever δ ≤ 10−3.
This illustrates the practical relevance, but, to a certain
extent, also the conservatism of the results presented in
Section C. Moreover, it can be seen that the approach
even allows for infeasible initial conditions x0 /∈ X and
that, at least in the case of a Newton based optimization,
neither the number of performed optimizer updates nor
the quality of the initialization U0 has a very big impact
on the resulting closed-loop behavior.
The middle and right subplots of Fig. 2 show, averaged
over 200 randomly chosen initial conditions x0 from the
set X , the strictly monotonic decay of the cost function
over time when applying the diﬀerent line search methods
discussed above, based on the initializations U0 = ¯Kx0
and U0 = ˆU ∗(x0), respectively. Again, only one optimizer
update is performed per sampling step.
It can be seen
that particularly the Newton method based optimization
does result in a good closed-loop performance, especially
in the case of optimal initialization. The observed behav-
ior is in principle also reﬂected on the level of maximal
constraint violations.
In particular, while one Newton
iteration is often enough to achieve almost the same con-
straint satisfaction properties as the fully optimized so-
lution, the Quasi-Newton and conjugated gradient based
methods tend to require a few more, say ﬁve to ten, iter-
ations. This reﬂects the fact that these approaches may
need some internal iterations in order to reconstruct the
second order information that is in the Newton method
directly provided by the Hessian. The gradient method
performs rather poorly, which, in principle, had to be ex-
pected as the considered optimization problems are often
ill-conditioned due to the underlying relaxation.
Thus, although the resulting closed-loop behavior may

depend on the line search method that is used within the
optimizer update, we are, in summary, able to reproduce
and conﬁrm many of the systems theoretic properties dis-
cussed above. In particular, asymptotic stability of the
overall closed-loop system is observed for all initial condi-
tions and independently of both the applied optimization
procedure and the number of optimizer iterations. Our
simulations furthermore suggest that the Newton based
line search often converges already after only ﬁve to eight
iterations, which nicely relates to the observations re-
ported in [27]. On the other hand, the above results also
show a promising behavior of the optimizer update ap-
proaches based on a Quasi-Newton or conjugated gradient
line search, which suggests that knowledge and inversion
of the full Hessian matrix might not always be necessary.

V. Conclusion

We presented and analyzed an MPC iteration scheme
which is based on the concept of relaxed logarithmic bar-
rier functions and performs only a limited number of op-
timization algorithm iteration between two consecutive
sampling instants. The stability properties of the over-
all closed-loop system, consisting of system state and op-
timization algorithm dynamics, were discussed and we
showed that, under standard assumptions on the op-
timization procedure and the system to be controlled,
asymptotic stability of the origin can be guaranteed in-
dependently of the number of optimization algorithm it-
erations. In addition, we studied the corresponding con-
straint satisfaction properties and showed that, assum-
ing an appropriate initialization of the optimization algo-
rithm, both approximate and exact constraint satisfaction
may in many cases be recovered by a suitable design of
the underlying relaxed barrier functions.

10

These results were also illustrated by means of the pre-
sented numerical example.
As outlined above, the discussed iteration scheme can be
seen as a stabilizing anytime MPC algorithm in the sense
that it always returns an asymptotically stabilizing con-
trol input and improves the quality of the returned control
at each of its internal iterations. This shows the potential
relevance of the presented approach for practical applica-
tions in which the time and hardware resources that are
available for the on-line optimization may be limited or
even varying over time.
Interesting open problems include a robustness analysis
of the discussed iteration scheme, a thorough investiga-
tion of the numerical implementation and performance, as
well as the design of tailored optimization algorithms that
may use properties or structure of the underlying barrier
function based formulation. Finally, some of the above
results may not necessarily be limited to the discussed
barrier function based approach but could also be appli-
cable to existing MPC schemes based on penalty functions
or soft constraints, as well as to more general classes of
parametric optimization problems not necessarily related
to MPC.

Appendix

A.2. Proof of Lemma 1

Due to compactness of the constraint sets X and U and
the design of the corresponding relaxed barrier functions,
both ˆℓ(x, u) and ˆF (x) are continuous, positive deﬁnite,
and radially unbounded. Since xk, k = 1, . . . , N , depends
linearly on x and U via (43), the same holds for ˆJN (U, x),
which implies that α, ¯α ∈ K∞ satisfying property i) will
always exist, see Lemma 4.3 in [15].
Strong convexity in U and convexity in x follow from
R ∈ Sm
+ and convexity of the relaxed barrier
functions. In fact, the overall barrier function reads

++, Q ∈ Sn

q

ˆBxu(U, x) =

Xi=1(cid:0)1 + wi(cid:1)(cid:0) ˆB (zi(U, x)) − ln(cid:0)di(cid:1)(cid:1),

(46)

where the relaxed logarithmic barrier function ˆB(·) is de-
ﬁned according to (4) with zi(U, x) = −GiU + Eix + di,
while the weighting vector w ∈ Rq
+ is used for recentering
around the origin. Based on this, we can easily compute
the Hessian of the cost function with respect to U as

∇2
U

ˆJN (U, x) = H + εG⊤diag(cid:0)D1(U, x), . . . , Dq(U, x)(cid:1)G ,

with Di(U, x) for i = 1, . . . , q being deﬁned as

(47)

Di(U, x) =( 1+wi

zi(U,x)2
1+wi

δ2

zi(U, x) > δ
zi(U, x) ≤ δ .

(48)

A.1. Condensed problem formulation

Note that for given x ∈ Rn and U ∈ RN m, the predicted
system states for k = 1, . . . , N can be expressed as

xk(U, x) = Akx +

k−1

Xi=0

AiBuk−1−i .

(43)

By writing (6) in matrix form and eliminating the pre-
dicted system states by means of (43), we get that the
cost function matrices in (9) are given by

Obviously, it holds that 0 ≤ Di(U, x) ≤ 1+ ¯w
maxi{wi}, which immediately yields that

δ2 with ¯w :=

σI (cid:22) ∇2
U

ˆJ(U, x) (cid:22) LI ,

(49)

with σ = λmin(H), L = λmax(H + ε(1+ ¯w)
δ2 G⊤G) ∈ R++.
Thus, the cost function is not only strongly convex but
we can also give a global upper bound on the Hessian,
and (10a) holds. By means of the mean value theorem
for multivariable functions we further obtain

∇U ˆJN (U1, x) − ∇U ˆJN (U2, x) =

(50)

H = 2(cid:16) ˜R + Γ⊤ ˜QΓ(cid:17) , F = 2Ω⊤˜QΓ, Y = 2(cid:16)Q + Ω⊤ ˜QΩ(cid:17)
Ω =


0
...
AN −1B · · · B

, Γ =


AN


˜R = IN ⊗ R ,

˜Q = IN ⊗ Q




· · ·
. . .

B
...

A
...

,

while the constraint matrices G, d, and E can be con-
structed as

([IN −1 0] ⊗ Cx)Γ

([IN −1 0] ⊗ Cx)Ω




, E =


In

0




G =

d =(cid:2)d⊤

x

0

IN ⊗ Cu

· · ·

,

d⊤

u(cid:3)⊤

Note that the representation of G, d, and E may change
if redundant constraints are removed by making use of a
suitable algorithm.

∇2
U

ˆJN (U2 + s(U1 − U2), x) ds (U1 − U2)

Z 1

0

and hence, with the above bounds on the Hessian,
k∇U ˆJN (U1, x) − ∇U ˆJN (U2, x)k ≤ LkU1 − U2k

(51)

for all U1, U2 ∈ RN m, x ∈ Rn, which proves property ii).
A proof for property iii) has been presented in the proof
of Theorem 5 in [9] and only a sketch is given here. Based
on the quadratic relaxation, the barrier functions can be
shown to satisfy ˆBx(x) ≤ x⊤Mx x ∀ x ∈ Rn as well as
ˆBu(u) ≤ u⊤Mu u ∀ u ∈ Rm, see Lemma 3 in [9]. Let
now K and P be given by (8) and choose kf (U, x) =
KxN (U, x), where xN (U, x) is given according to (43).
Then, the aforementioned quadratic upper bounds ensure
that ˆF ((A + BK)xN ) − ˆF (xN ) ≤ −ˆℓ(xN , KxN ) ∀ xN ∈
Rn. Deﬁning U +
0 as in Lemma 1 and using a telescoping
sum, this directly implies that (11) holds. Thus, prop-
erty iii) holds with kf (U, x) = KxN (U, x).
(cid:4)

11

A.3. Some auxiliary continuity and feasibility results

Lemma 2. Let ˆBP (·) be a recentered relaxed logarith-
mic barrier functions of the form (5) for a polytopic set
P = {x ∈ Rr : Cξ ≤ d} with C ∈ Rq×r and d ∈ Rq
++.
Let ¯β(δ) be deﬁned as ¯β(δ) := mini,ξ{ ˆBP (ξ)| Ciξ = di}
with i = 1, . . . , q. Then, ¯β(·) is a continuous function.
Furthermore, S ˆB = {x ∈ Rn| ˆBP (x) ≤ ¯β(δ)} ⊆ P for any
δ ∈ R++.

Proof:

The barrier function ˆBP (·) is continu-
ous in both ξ and δ and possesses compact sublevel
sets for any ﬁxed value of δ.
This implies that
¯βi(δ) := minξ{ ˆBP(ξ)| Ciξ = di} will be continuous in δ
for any i = 1, . . . , q, see Proposition 4.4 in [4]. Hence,
¯β(δ) := mini ¯βi(δ) will also be continuous.
Assume there exists an ¯ξ ∈ S ˆB with ¯ξ /∈ P,
i.e.,
ˆBP ( ¯ξ) ≤ ¯β(δ) and C ¯ξ > d. However, then there would
exists a λ ∈ (0, 1) such that if ξ := λ ¯ξ, then Cξ ≤ d
and Ciξ = di for some i = 1, . . . , q. Now, due to the
convexity and positive deﬁniteness of ˆBP (·),
it holds
that ˆBP (ξ) = ˆBP (λ ¯ξ) ≤ λ ˆBP ( ¯ξ) < ¯β(δ), which is a
contradiction to the deﬁnition of ¯β(δ) as Ciξ = di. Thus,
¯ξ ∈ P whenever ¯ξ ∈ S ˆB, which completes the proof. (cid:4)

Lemma 3. Assume (A, B) to be controllable and let
XN := {x ∈ Rn : ∃ U ∈ RN m s.t. uk ∈ U, xk(U, x) ∈
X for k = 1, . . . , N −1, xN (U, x) = 0} be the set of states
for which the problem

N −1

˜J ∗
N (x) = min

U

˜ℓ(xk, uk)

Xk=0

s. t. xk+1 = Axk + Buk, xN = 0, x0 = x .

(52a)

(52b)

with ν ∗(x0) denoting the associated Lagrange multiplier.
Now, the implicit function theorem states that unique and
continuously diﬀerentiable solutions ˜U ∗(x), ν ∗(x) to (54)
will exist if the corresponding Jacobian with respect to
( ˜U ∗, ν ∗), given by

˜JN (U ∗(x0), x0) S⊤
1

U

(cid:20)∇2

S1

0 (cid:21) ,

(55)

In particular, ∇2
U

is nonsingular for all feasible x0. Indeed, this follows from
applying block inversion and noting that both the upper
left corner block and the Schur complement are nonsin-
++ ∀ x0 ∈
gular.
N (strong convexity) and S1∇2
X ◦
1 ∈
U
Sn
++ ∀ x0 ∈ X ◦
N (S1 has full row rank due to controlla-
bility of (A, B)). Note that, using this result, it can be
shown easily that the value function ˜J ∗
N : Rn → R+ is in
fact twice continuously diﬀerentiable.
(cid:4)

˜JN (U ∗(x0), x0) ∈ SN m

˜JN (U ∗(x0), x0)S⊤

A.4. Step size bound for the Newton method

For the Newton method search direction from (37), the
Armijo condition (34a) can be rewritten as

ˆJN (U + sp, x) ≤ ˆJN (U, x) − c1s λ(U, x)2

(56)

with the corresponding squared Newton decrement

λ(U, x)2 := ∇U ˆJN (U, x)⊤(cid:16)∇2

U

ˆJN (U, x)(cid:17)−1

∇U ˆJN (U, x).

Applying Taylor’s Theorem to the left-hand side of (56)
and using the upper and lower bounds from (10a), we
obtain that

Q + kuk2

has a solution. Here, ˜ℓ(x, u) := kxk2
R + εBu(u) +
εBx(x), where Bu(u) and Bx are recentered logarithmic
barrier functions, e.g. barrier functions of the form (5)
with ˆB(·) being replaced by B(z) = − ln(z). Then, for
N , the optimizer ˜U ∗(x0) associated to (52) is
any x0 ∈ X ◦
unique and ˜U ∗ : X ◦
N → RN m is a continuously diﬀeren-
tiable function.

Proof: Using the input vector notation, problem (52)

is equivalent to

˜J ∗
N (x) = min

U

˜JN (U, x) s. t. S1U + S2x = 0

(53)

where ˜JN (·, ·) is the nonrelaxed barrier function based
cost function similar to (9), strongly convex in U , and

S1 = (cid:2)AN −1B · · · B(cid:3), S2 = AN are used to encode

the terminal equality constraint xN (U, x) = 0, see (43).
For given x0 ∈ X ◦
N , the KKT conditions for (52), which
are in this case necessary and suﬃcient conditions for op-
timality, read

∇U ˜JN (U ∗(x0), x0) + S⊤

1 ν ∗(x0) = 0
S1 ˜U ∗(x0) + S2x0 = 0 ,

(54a)

(54b)

ˆJN (U + sp, x) ≤ ˆJN (U, x) − s(cid:16)1 −

L
2σ

s(cid:17)λ(U, x)2,

(57)

which directly implies that (56) will be satisﬁed for any
s ≤ ¯s := 2σ(1 − c1)/L.

References

[1] A. Bemporad, D. Bernardini, and P. Patrinos. A convex
feasibility approach to anytime model predictive control.
arXiv:1502.07974, 2015.

[2] A. Bemporad, M. Morari, V. Dua, and E. N. Pistikopou-
los. The explicit linear quadratic regulator for constrained
systems. Automatica, 38:3–20, 2002.

[3] A. Ben Tal, M. Tsibulevskii, and I. Yusefovich. Modi-
ﬁed barrier methods for constrained and minimax prob-
lems. Technical report, Optimization Laboratory, Tech-
nion, 1992.

[4] J. F. Bonnans and A. Shapiro. Perturbation analysis of

optimization problems. Springer, 2000.

[5] M. Diehl, R. Findeisen, and F. Allg¨ower. A stabilizing
iteration scheme for nonlinear model predictive control.
In: Real-Time and Online PDE-Constrained Optimiza-
tion, pages 23–52, 2007.

12

quadratic programming algorithms for embedded linear
model predictive control. In Proc. of the 4th IFAC NMPC
Conf., pages 14–20, Noordwijkerhout, Netherlands, 2012.
[23] C. V. Rao, S. J. Wright, and J. B. Rawlings. Applica-
tion of interior point methods to model predictive con-
trol. Journal of Optimization Theory and Applications,
99(3):723–757, 1998.

[24] S. Richter, C. N. Jones, and M. Morari. Computational
complexity certiﬁcation for real-time MPC with input
constraints based on the fast gradient method.
IEEE
Trans. Autom. Control, 57(6):1391–1403, 2012.

[25] P. O. M. Scokaert, D. Q. Mayne, and J. B. Rawlings.
Suboptimal model predictive control (feasibility implies
stability). IEEE Trans. Autom. Control, 44(3):648–654,
1999.

[26] P. Tøndel, T. A. Johansen, and A. Bemporad. An algo-
rithm for multi-parametric quadratic programming and
explicit MPC solutions. Automatica, 39:489–497, 2003.

[27] Y. Wang and S. Boyd. Fast Model Predictive Control Us-
ing Online Optimization. IEEE Trans. on Control Sys-
tems Technology, 18(2):267–278, 2012.

[28] S. J. Wright. Applying new optimization algorithms to
model predictive control. In AIChE Symposium Series,
volume 93, pages 147–155, 1997.

[29] V. M. Zavala and L. T. Biegler. The advanced-step
NMPC controller: Optimality, stability and robustness.
Automatica, 45(1):86–93, 2009.

[30] M. N. Zeilinger and C. N. Jones. Real-Time Subopti-
mal Model Predictive Control Using a Combination of
Explicit MPC and Online Optimization.
IEEE Trans.
Autom. Control, 56(7):1524–1534, 2011.

[6] M. Diehl, R. Findeisen, F. Allg¨ower, H. Bock, and
J. Schl¨oder. Nominal stability of real-time iteration
scheme for nonlinear model predictive control. IEE pro-
ceedings – Control Theory and Applications, 152(3):296–
308, 2005.

[7] A. Domahidi, A. U. Zgraggen, M. N. Zeilinger, M. Morari,
and C. N. Jones. Eﬃcient interior point methods for mul-
tistage problems arising in receding horizon control. In
Proc. of the 51st IEEE Conf. Dec. and Contr. (CDC),
pages 668–674, 2012.

[8] C. Feller and C. Ebenbauer. Input-to-state stability prop-
erties of relaxed barrier function based MPC. In Proc. of
the 5th IFAC NMPC Conf., pages 302–307, Seville, Spain,
2015.

[9] C. Feller and C. Ebenbauer. Relaxed logarithmic barrier
function based model predictive control of linear systems.
arXiv:1503.03314 [math.OC], 2015.

[10] C. Feller and C. Ebenbauer. Weight recentered barrier
functions and smooth polytopic terminal set formulations
for linear model predictive control. In Proc. of the 2015
American Contr. Conf., pages 1647–1652, Chicago, IL,
USA, 2015.

[11] H. J. Ferreau, H. G. Bock, and M. Diehl. An online active
set strategy to overcome the limitations of explicit MPC.
International Journal of Robust and Nonlinear Control,
18(8):816–830, 2008.

[12] P. Giselsson.

Improved fast dual gradient methods for
embedded model predictive control. In Proc. of the 19th
IFAC World Congress, pages 2303–2309, 2014.

[13] A. Halanay and V. Rasvan. Stability and stable oscilla-

tions in discrete time systems. CRC Press, 2000.

[14] J. Hauser and A. Saccon. A Barrier Function Method
for the Optimization of Trajectory Functionals with Con-
In Proc. of the 45th Conf. Dec. and Contr.
straints.
(CDC), pages 864–869, San Diego, USA, 2006.

[15] Hassan Khalil. Nonlinear Systems. Prentice Hall, 2002.
[16] M. K¨ogel and R. Findeisen. Fast predictive control of
linear systems combining Nesterov’s gradient method and
the method of multipliers. In Proc. of the 50th IEEE Conf.
on Dec. and Contr. (CDC-ECC), pages 501–506, 2011.

[17] D. Q. Mayne, J. B. Rawlings, C. V. Rao, and P. O. M.
Scokaert. Constrained model predictive control: Stability
and optimality. Automatica, 36:789–814, 2000.

[18] L. K. McGovern and E. Feron. Closed-loop stability of
systems driven by real-time, dynamic optimization algo-
rithms. In Proc. of the 38th IEEE Conf. Dec. and Contr.
(CDC), volume 4, pages 3690–3696, 1999.

[19] J. J. Mor´e and D. J. Thuente. Line search algorithms
with guaranteed suﬃcient decrease. ACM Transactions
on Mathematical Software (TOMS), 20(3):286–307, 1994.
[20] S. G. Nash, R. Polyak, and A. Sofer. Large Scale Opti-
mization: State of the Art, chapter A numerical compari-
son of barrier and modiﬁed barrier methods for large-scale
bound-constrained optimization, pages 319–338. Kluwer
Academic Publishers, 1994.

[21] J. Nocedal and S. J. Wright. Numerical Optimization.

Springer, 1999.

[22] P. Patrinos and A. Bemporad. Simple and certiﬁable

13

