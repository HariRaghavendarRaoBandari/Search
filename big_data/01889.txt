6
1
0
2

 
r
a

 

M
4
2

 
 
]

.

R
P
h
t
a
m

[
 
 

2
v
9
8
8
1
0

.

3
0
6
1
:
v
i
X
r
a

The rate of convergence of some

asymptotically chi-square distributed

statistics by Stein’s method

Robert E. Gaunt and Gesine Reinert

Department of Statistics

University of Oxford

24-29 St. Giles’
Oxford OX1 3LB
United Kingdom

Abstract: We build on recent works on Stein’s method for functions
of multivariate normal random variables to derive bounds for the rate
of convergence of some asymptotically chi-square distributed statistics.
We obtain some general bounds and establish some simple suﬃcient
conditions for convergence rates of order n−1 for smooth test functions.
These general bounds are applied to Friedman’s statistic for comparing
r treatments across n trials and the family of power divergence statis-
tics for goodness-of-ﬁt across n trials and r classiﬁcations, with index
parameter λ ∈ R (Pearson’s statistic corresponds to λ = 1). We obtain
a O(n−1) bound for the rate of convergence of Friedman’s statistic for
any number of treatments r ≥ 2. We also obtain a O(n−1) bound on the
rate of convergence of the power divergence statistics for any r ≥ 2 when
λ is a positive integer or any real number greater than 5. We conjecture
that the O(n−1) rate holds for any λ ∈ R.

Primary 60F05, 62G10, 62G20.
Keywords and phrases: Stein’s method, Friedman’s statistic, power
divergence statistics, chi-square approximation, functions of multivariate
normal random variables, rate of convergence.

1. Introduction

In this paper, we use Stein’s method, introduced in 1972 by Stein [28], to
obtain bounds on the rate of convergence of some asymptotically chi-square
distributed statistics. In particular, we make use of a recent variant of Stein’s
method, due to [8], that allows one to obtain approximation theorems when
the limit distribution can be represented as a function of multivariate nor-
mal random variables. In this paper, we achieve two goals. Firstly, we obtain
bounds on the rate of convergence of Friedman’s statistic and the power
divergence family of statistics that improve on those from the existing liter-

1

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

2

ature. Secondly, in deriving these bounds we generalise some of the theory
developed in the recent work of [8]. We demonstrate that the theory can be
applied in situations in which there is a dependence amongst the random
variables of interest (these being, for example, the rankings of treatments
across the trials for Friedman’s statistic). We also obtain some simple suﬃ-
cient conditions for O(n−1) convergent rates that weaken those of [8]. The
theory developed in this paper allows for the distributional approximation of
a large class of statistics (which include the Friedman and Pearson statistics
as popular special cases) to be treated within one framework.

1.1. Chi-square statistics for complete block designs

In this paper, we study the rate of convergence of a class of statistics for non-
parametric tests for complete block designs. That is, statistics for comparing
r treatments or classiﬁcations across n independent trials. In Section 2, we
develop some general theory and in Section 3 this theory is applied to several
common chi-square statistics, which we now present.

1.1.1. Friedman’s chi-square statistic

Friedman’s chi-square test [6] is a non-parametric statistical test that, given
r treatments across n independent trials, can be used to test the null hypoth-
esis that there is no treatment eﬀect against the general alternative. Sup-
pose that for the i-th trial we have the ranking πi(1), . . . , πi(r), where πi(j) ∈
{1, . . . , r}, over the r treatments. Under the null hypothesis, the rankings are
independent permutations π1, . . . , πn, with each permutation being equally
likely. Let Xij =
i=1 Xij. Then the

Friedman chi-square statistic, given by

√12√r(r+1)(cid:0)πi(j)− r+1

2 (cid:1) and set Wj = 1√n Pn

Fr =

r

Xj=1

W 2
j ,

(1.1)

is asymptotically χ2

(r−1) distributed under the null hypothesis.

1.1.2. Pearson’s chi-square and the power divergence family of statistics

Another non-parametric test for complete block designs is Pearson’s chi-
square goodness-of-ﬁt test, introduced in [25]. Consider n independent trials,
with each trial leading to a unique classiﬁcation over r classes. Let p1, . . . , pr

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

3

represent the non-zero classiﬁcation probabilities, and let U1, . . . , Ur repre-
sent the observed numbers arising in each class. Then Pearson’s chi-square
statistic, given by

r

χ2 =

Xj=1

(Uj − npj)2

npj

,

(1.2)

is asymptotically χ2
(r−1) distributed. Pearson’s statistic is a special case (λ =
1) of the so-called power divergence family of statistics introduced by [5]:

r

2

Uj(cid:20)(cid:18) Uj

npj(cid:19)λ

− 1(cid:21).

λ(λ + 1)

Tλ(W) =

Xj=1
The statistic Tλ(W) is asymptotically χ2
(r−1) distributed for all λ ∈ R. When
λ = 0,−1, the notation (1.3) should be understood a result of passage to
the limit (see [29], Remark 1). Indeed, the case λ = 0 corresponds to the
log-likelihood ratio statistic and the case λ = −1/2 is the Freeman-Tukey
statistic (see [29], Remark 2).

(1.3)

1.1.3. Rates of convergence of chi-square statistics

In the existing literature, the best bound on the rate of convergence of
Friedman’s statistic is the following Kolmogorov distance bound of [15]:

sup

z≥0 |P(Fr ≤ z) − P(Y ≤ z)| ≤ C(r)n−r/(r+1),

where the (non-explicit) constant C(r) depends only on r and Y ∼ χ2
(r−1).
The rate of convergence of other asymptotically chi-square distributed has
also received attention in the literature. For Pearson’s statistic over n inde-
pendent trials with r classiﬁcations, it was shown by [30] using Edgeworth
expansions that the rate of convergence of Pearson’s statistic, in the Kol-
mogorov distance was O(n(r−1)/r), for r ≥ 2, which was improved by [14]
to O(n−1) for r ≥ 6. Also, [29] and [1] have used Edgeworth expansions to
study the rate of convergence of the more general power divergence fam-
ily of statistics. For r ≥ 4, [29] obtained a O(n(r−1)/r) bound on the rate
of convergence in the Kolmogorov distance and, for r = 3, [1] obtained a
O(n−3/4+0.065) bound on the rate of convergence in the same metric, with
both bounds holding for all λ ∈ R.
To date, the application of Stein’s method to the problem of determining
rates of convergence of asymptotically chi-square distributed statistics has

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

4

been quite limited. In particular, there has been no application to Friedman’s
statistic in the literature. Pearson’s statistic, however, has received some
treatment. An investigation is given in the unpublished papers [20] and [21],
with a O(n−1/2) Kolmogorov distance bound given for Pearson’s statistic
with general null distribution. In a recent work [10], a bound of order n−1,
for smooth test functions, was obtained. This bound is valid under any null
distribution provided r ≥ 2, and involves the classiﬁcation probabilities,
under the null model, p1, . . . , pr correctly in the sense that the bound goes
to zero if and only if np∗ → ∞, where p∗ = min1≤i≤r pi.
In this paper, we obtain bounds for the rate of convergence of a class of
statistics for complete block designs that includes the Friedman and Pearson
statistics and the power divergence family of statistics, at least for certain
values of the index parameter λ. By building on the proof techniques of
[8] and [10], we establish some simple conditions under which the rate of
convergence is of order n−1 for smooth test functions, and present the general
O(n−1) bounds in Theorems 2.4, 2.5 and 2.6. In Section 3, we consider the
application of these general bounds to particular chi-square statistics. In
particular, in Theorem 3.1, we obtain an explicit O(n−1) bound on the
distributional distance between Friedman’s statistic and its limiting chi-
square distribution, for smooth test functions. In Theorem 3.3, we also show
that the rate of convergence of the power divergence family of statistics is
O(n−1) for the cases that the index parameter λ is either a positive integer
or any real number greater than 5. It is conjectured that this rate holds for
any λ ∈ R.

1.2. Elements of Stein’s method for functions of multivariate

normal random variables

To derive our approximation theorems for Friedman’s statistic, we employ
the powerful probabilistic technique Stein’s method. Originally developed
for normal approximation by [28], the method has since been extended to
many other distributions, such as the multinomial [17], exponential [3, 26],
gamma [10, 18, 23], variance-gamma [7] and multivariate normal [2, 13]. For
a comprehensive overview of the current literature and an outline of the basic
method see [16]. We now outline how Stein’s method can be used to prove
approximation theorems when the limit distribution can be represented as
a function of multivariate normal random variables (for more details see
[8]). We describe the general approach and explain how it can be applied to
statistics and for block designs, such as Friedman’s statistic.

Let g : Rd → R be continuous and let Z denote the standard d-dimensional

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

5

multivariate normal distribution, so that Σ1/2Z ∼ MVN(0, Σ), where the
covariance matrix Σ is non-negative deﬁnite. Suppose that we are interested
in bounding the distributional distance between g(W) and g(Σ1/2Z), where
W D→ Σ1/2Z. To see, for example, that Freidman’s statistic falls into this
framework, note that Fr can be written in the form g(W), where g(w) =
Pr
j=1 w2
j and the Wi are asymptotically normally distributed by the central
limit theorem. Now, consider the multivariate normal Stein equation (see
[12]) with test function h(g(·)):

∇T Σ∇f (w) − wT∇f (w) = h(g(w)) − Eh(g(Σ1/2Z)).

(1.4)
We can therefore bound the quantity of interest |Eh(g(W))− Eh(g(Σ1/2Z))|
by solving (1.4) for f and then bounding the expectation

E[∇T Σ∇f (W) − WT∇f (W)].

(1.5)

A number of coupling techniques have been developed for bounding such
expectations (see [4, 11, 12, 22, 27]). These papers also give general plug-
in bounds for this quantity, although these only hold for the classical case
that the derivatives of the test function (here h(g(·))) are bounded, in which
standard bounds for the derivatives of the solution to (1.4) can be applied
(see [9, 12, 22]). However, in general the derivatives of the test function
h(g(·)) will be unbounded (this is the case for Friedman’s statistic) and
therefore the derivatives of the solution
f (w) = −Z ∞

[Eh(g(e−sw +p1 − e−2sΣ1/2Z)) − Eh(g(Σ1/2Z))] ds (1.6)

0

will also in general be unbounded. The partial derivatives of the solution
(1.6) were bounded by [8] for a large class of function g : Rd → R; in par-
ticular, bounds are given for the case that the partial derivatives of g have
polynomial growth. These bounds are relevant to our study and are stated
in Lemma 2.3. With such bounds on the solution and the coupling strategies
developed for multivariate normal approximation it is in principle possible
to bound the expectation (1.5), although we cannot directly apply the exist-
ing plug-in bounds. This is the approach we shall take when obtaining our
general approximation theorems in Section 2.

1.3. Outline of the paper

In Section 2, we derive general bounds for the distributional distance be-
tween statistics g(W) for complete block designs and their limiting distri-
bution g(Σ1/2Z). We give two general O(n−1/2) bounds, one for the case

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

6

of non-negative covariance matrices (Theorem 2.2) and another for positive
deﬁnite covariance matrices (Theorem 2.3). When the function g is even
(g(w) = g(−w) for all w ∈ Rd), the rate of convergence can be improved to
O(n−1) for smooth test functions (see Theorem 2.4). In Section 2.3, we see
that it is possible to obtain O(n−1) bounds when the assumption that g is
relaxed a little (see Theorem 2.6). In Section 3, we consider the application
of the general bounds of Section 2 to the Friedman and Pearson statistics,
as well as the power divergence statistics. In particular, in Theorem 3.1,
we obtain an explicit O(n−1) bound for the distributional distance between
Friedman’s statistics and its limiting chi-square distribution. In Theorem
3.3, we obtain a O(n−1) bound on the rate of convergence for the family of
power divergence statistics for the cases that λ is a positive integer or any
real number greater than 5. We end by conjecturing that this rate holds for
all λ ∈ R.

2. General bounds for the distributional distance between g(W)

and g(Σ1/2Z)

2.1. Preliminary lemmas

j

1 , . . . , W (i)

Let Xij, i = 1, . . . , n, j = 1, . . . , d, be random variables which have mean
zero, but which are not necessarily independent or identically distributed.
Indeed, we shall suppose that X1,j, . . . , Xn,j are independent for a ﬁxed j,
but that the random variables Xi,1, . . . , Xi,d may be dependent for any ﬁxed
i. For j = 1, . . . , d, let Wj = 1√n Pn
i=1 Xij and denote W = (W1, . . . , Wd)T .
To deal with this dependence structure, we introduce the random variables
W (i)
j = Wj − 1√n Xij, so that W (i)
and Xij are independent. We also write
W(i) = (W (i)
d )T . Suppose that the covariance matrix Σ of W is
non-negative deﬁnite. Let Z have the standard d-dimensional multivariate
normal distribution, so that Σ1/2Z ∼ MVN(0, Σ). Let σjk = (Σ)jk and
Zi = (Σ1/2Z)i ∼ N (0, σii).
In this section, we shall obtain bounds on the distributional distance
between g(W) and g(Σ1/2Z), where g : Rd → R is a suﬃciently diﬀerentiable
function. Note that g(W) takes the form of a statistic for complete block
designs. In this subsection, we give two bounds: one for general g and a
second for the case that g is an even function (g(w) = g(−w) for all w ∈
Rd). In the next subsection, we shall specialise to the case that the partial
derivatives of g have polynomial growth. Before presenting our bounds, we
introduce some notation. We shall let C k(I) denote the class of real-valued

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

7

functions deﬁned on I ⊆ Rd whose partial derivatives of order k all exist.
We shall also let C k(I) denote the class of real-valued functions deﬁned on
I ⊆ Rd whose partial derivatives of order k all exist and are bounded.
Lemma 2.1. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as above. Sup-
pose h and g are such that f ∈ C 3(Rd), where f is given by (1.6). Then, if
the expectations on the right-hand side of (2.1) exist,

XijXikXil

∂3f

∂wj∂wk∂wl

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

(2.1)

∂3f

∂wj∂wk∂wl

(W(i)

(cid:27),

θ )(cid:12)(cid:12)(cid:12)(cid:12)

|Eh(g(W)) − Eh(g(Σ1/2Z))|
≤

2n3/2

1

n

d

Xi=1

Xj,k,l=1
+ 2|EXijXik| sup

θ

E(cid:12)(cid:12)(cid:12)(cid:12)

θ

(cid:26) sup
E(cid:12)(cid:12)(cid:12)(cid:12)

Xil

where W(i)

θ = W(i) + θ√n Xi for some θ ∈ (0, 1) and Xi = (Xi,1, . . . , Xi,d)T .
Proof. We aim to bound Eh(g(W)) − Eh(g(Z)), and do so by bounding the
quantity

E[∇T Σ∇f (W)−WT∇f (W)] = E(cid:20) d
Xj,k=1
(W) about W(i)

Taylor expanding ∂f
∂wj

j gives

σjk

∂2f

∂wj∂wk

(W)−

d

Xj=1

Wj

∂f
∂wj

(W)(cid:21).

d

Xj=1

EWj

∂f
∂wj

(W) =

1
√n

n

d

Xi=1

Xj=1

EXij

∂f
∂wj

(W)

=

=

=

=

1
√n

1
√n

n

d

Xi=1

Xj=1

n

d

Xi=1

Xj=1

EXij

∂f
∂wj

(W(i)) +

1
n

n

d

Xi=1

Xj,k=1

EXijXik

∂2f

∂wj∂wk

(W(i)) + R1

EXij E

∂f
∂wj

(W(i)) +

1
n

n

d

Xi=1

Xj,k=1

EXijXik E

∂2f

∂wj∂wk

(W(i)) + R1

1
n

n

d

Xi=1

Xj,k=1

EXijXik E

∂2f

∂wj∂wk

(W) + R1 + R2

d

Xj,k=1

σjkE

∂2f

∂wj∂wk

(W) + R1 + R2,

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

8

where

|R1| ≤

1

2n3/2

n

d

Xi=1

Xj,k,l=1

sup

θ

n

d

E(cid:12)(cid:12)(cid:12)(cid:12)

XijXikXil

∂3f

∂wj∂wk∂wl

(W(i)

,

θ )(cid:12)(cid:12)(cid:12)(cid:12)
θ )(cid:12)(cid:12)(cid:12)(cid:12)

(W(i)

.

|R2| ≤

1

n3/2

Xj,k,l=1

|EXijXik| sup

θ

Xil

∂3f

∂wj∂wk∂wl

E(cid:12)(cid:12)(cid:12)(cid:12)

Here we used that 1

EXijXik = EWjWk = σjk. The proof is complete.

i=1

Xi=1
n Pn

Remark 2.1. In the statement of Lemma 2.1, we did not give precise condi-
b (Rd), nor restrictions on the Xij such that
tions on h and g such that f ∈ C 3
the expectations on the right-hand side of (2.1) exist. In applying, Lemma
2.1 in practice (see Section 2.2), one would need to check that h, g and
the Xij are such that these conditions are met. The same comment applies
equally to Lemma 2.2.

We now obtain an analogue of Lemma 2.1 for the case that g is an even
function. The symmetry of the function g allows us to obtain O(n−1) con-
vergence rates for smooth test functions h. The following partial diﬀerential
equation

∇T Σ∇ψjkl(w) − wT∇ψjkl(w) =

∂3f

∂wj∂wk∂wl

(w)

(2.2)

shall appear in our proof.

Lemma 2.2. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as they were for
Lemma 2.1. Suppose g : Rd → R is an even function. Suppose further that
the solution (1.6), denoted by f , belongs to the class C 4(Rd) and that the
solution ψjkl to (2.2) is in the class C 3(Rd). Then, if the expectations on

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

9

XijXikXilXit

∂4f

∂wj∂wk∂wl∂wt

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

the right-hand side of (2.3) exist,
|Eh(g(W)) − Eh(g(Σ1/2Z))|
≤

1
6n2

n

d

Xi=1

Xj,k,l,t=1
+ 9|EXij Xik| sup

θ

XilXit

∂wj∂wk∂wl∂wt

∂4f

∂4f

+ 3|EXij XikXil| sup

θ

Xit

∂wj∂wk∂wl∂wt

+

1
4n3

n

d

Xi=1

Xj,k,l=1

|EXijXikXil|

n

d

Xa,b,c=1

Xα=1
∂3ψjkl

E(cid:12)(cid:12)(cid:12)(cid:12)

θ

(cid:26) sup
E(cid:12)(cid:12)(cid:12)(cid:12)

E(cid:12)(cid:12)(cid:12)(cid:12)

(W(i)

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)
θ )(cid:12)(cid:12)(cid:12)(cid:12)
(cid:27)
E(cid:12)(cid:12)(cid:12)(cid:12)
(cid:26) sup
θ )(cid:12)(cid:12)(cid:12)(cid:12)
(cid:27).

θ

XαaXαbXαc

∂3ψjkl

∂wa∂wb∂wc

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

+ 2|EXαaXαb| sup
Proof. By a similar argument to the one used in the proof of Lemma 2.1,

∂wa∂wb∂wc

Xαc

θ

(2.3)

(W(i)

E(cid:12)(cid:12)(cid:12)(cid:12)

d

Xj=1

EWj

∂f
∂wj

(W) =

=

1
n

1
n

n

d

Xi=1

Xj,k=1

n

d

Xi=1

Xj,k=1

EXijXik E

EXijXik E

∂2f

∂wj∂wk

∂2f

∂wj∂wk

where

(W(i)) + N1 + R1

(W) + N1 + N2 + R1 + R2,

N1 =

1

2n3/2

n

d

Xi=1

Xj,k,l=1

EXijXikXilE

∂3f

∂wj∂wk∂wl

(W(i)),

N2 = −

1

n3/2

n

d

Xi=1

Xj,k,l=1

EXijXik EXil

∂3f

∂wj∂wk∂wl

(W),

|R1| ≤

|R2| ≤

1
6n2

1
2n2

n

d

Xi=1

Xj,k,l,t=1

sup

θ

n

d

Xi=1

Xj,k,l,t=1

E(cid:12)(cid:12)(cid:12)(cid:12)

|EXijXik| sup

θ

We can write N1 as

XijXikXilXit

∂4f

∂wj∂wk∂wl∂wt

(W(i)

∂4f

∂wj∂wk∂wl∂wt

XilXit

E(cid:12)(cid:12)(cid:12)(cid:12)

,

θ )(cid:12)(cid:12)(cid:12)(cid:12)
θ )(cid:12)(cid:12)(cid:12)(cid:12)

(W(i)

.

N1 =

1

2n3/2

n

d

Xi=1

Xj,k,l=1

EXijXikXilE

∂3f

∂wj∂wk∂wl

(W) + R3,

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

10

where

|R3| ≤

1
2n2

n

d

Xi=1

Xj,k,l,t=1

|EXijXikXil| sup

θ

and we can also write N2 as

∂4f

∂wj∂wk∂wl∂wt

Xit

E(cid:12)(cid:12)(cid:12)(cid:12)

,

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

N2 = −

1

n3/2

n

d

Xi=1

Xj,k,l=1

EXijXik EXilE

∂3f

∂wj∂wk∂wl

(W(i)) + R4 = R4,

where

|R4| ≤

1
n2

n

d

Xi=1

Xj,k,l,t=1

|EXijXik| sup

θ

Combining bounds gives that

XilXit

E(cid:12)(cid:12)(cid:12)(cid:12)

∂4f

∂wj∂wk∂wl∂wt

.

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

|Eh(g(W)) − Eh(g(Σ1/2Z))|
≤

2n3/2

1

Xj,k,l=1

d

n

Xi=1

+ |R1| + |R2| + |R3| + |R4|.

|EXijXikXil|(cid:12)(cid:12)(cid:12)(cid:12)

E

∂3f

∂wj∂wk∂wl

(W)(cid:12)(cid:12)(cid:12)(cid:12)

(2.4)

To achieve the desired O(n−1) bound we need to show that E
(W)
is of order n−1/2, since in general EXijXikXil 6= 0. We consider the MVN(0, Σ)
Stein equation with test function

∂wj∂wk∂wl

∂ 3f

:

∂ 3f

∂wj∂wk∂wl

∇T Σ∇ψjkl(w)− wT∇ψjkl(w) =

∂3f

∂wj∂wk∂wl

(w)− E(cid:20)

∂3f

∂wj∂wk∂wl

(Σ1/2Z)(cid:21).

Since g is an even function, the solution f , as given by (1.6), is an even
function (see [8], Lemma 3.2). Therefore E

(Σ1/2Z) = 0, and so

∂ 3f

∂wj∂wk∂wl

E(cid:20)

∂3f

∂wj∂wk∂wl

(W)(cid:21) = E[∇T Σ∇ψjkl(W) − WT∇ψjkl(W)].

(2.5)

We can use Lemma 2.1 to bound the right-hand side of (2.5), which allows
us to obtain a O(n−1/2) bound for this quantity. All terms have now been
bounded to the desired order and the proof is complete.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

11

2.2. Approximation theorems for polynomial P

Lemmas 2.1 and 2.2 allow one to bound the distributional distance between
g(W) and g(Σ1/2Z) if bounds are available for the expectations on the right-
hand side of (2.1) and (2.3), respectively. In this subsection, we obtain such
bounds for the case that the partial derivatives of g have polynomial growth.
We begin, with Lemma 2.3 (below), in which we state some bounds (see
[8], Corollary 2.2 and 2.3) for the solutions f and ψjkl. In [8] bounds for
f and ψjkl are also available for the case that the partial derivatives of g
have exponential growth, although for space reasons we do not include these
bounds (polynomial bounds suﬃce for our applications).

We say that the function g : Rd → R belongs to the class C m

P (Rd) if all m-
th order partial derivatives of g exist and there exists a dominating function
P : Rd → R+ such that, for all w ∈ Rd, the partial derivatives satisfy

d

m/k

(cid:12)(cid:12)(cid:12)(cid:12)

Xi=1

k = 1, . . . , m,

Bi|wi|ri,

∂kg(w)
j=1 ∂wij

≤ P (w) := A +

(cid:12)(cid:12)(cid:12)(cid:12)
Qk
where A ≥ 0, B1, . . . , Bd ≥ 0 and r1, . . . , rd ≥ 0. We shall write hm =
Pm
j=1(cid:8)m
j(cid:9)kh(j)k, where khk = khk∞ = supw∈R |h(w)| and the Stirling num-
i=0(−1)j−i(cid:0)j
bers of the second kind are given by (cid:8)m
i(cid:1)im (see [24]).
Lemma 2.3. Suppose Σ is positive deﬁnite and h ∈ C m−1
(R) and g ∈
C m−1
(Rd) for m ≥ 2. Let Zi = (Σ1/2Z)i ∼ N (0, σii). Then, for all w ∈ Rd,
2riBi(cid:0)|wi|ri E|(Σ−1/2Z)l|

1≤l≤d(cid:20)AE|(Σ−1/2Z)l| +

≤ hm−1 min

j(cid:9) = 1

j! Pj

Xi=1

P

d

b

(cid:12)(cid:12)(cid:12)(cid:12)

∂mf (w)

j=1 ∂wij(cid:12)(cid:12)(cid:12)(cid:12)
Qm

+ E|(Σ−1/2Z)lZ ri

i |(cid:1)(cid:21).

(2.6)

Suppose now that Σ is non-negative deﬁnite and h ∈ C m
for m ≥ 1. Then, for all w ∈ Rd,
m (cid:20)A +

∂mf (w)

hm

≤

d

Xi=1

2riBi(cid:0)|wi|ri + E|Zi|ri(cid:1)(cid:21).

b (R) and g ∈ C m

P (Rd)

Let h ∈ C 6

j=1 ∂wij(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)
Qm
b (R) and g ∈ C 6
∂wa∂wb∂wc(cid:12)(cid:12)(cid:12)(cid:12)

∂3ψjkl(w)

(cid:12)(cid:12)(cid:12)(cid:12)

P (Rd). Then, for all w ∈ Rd,
18(cid:20)A +

h6

≤

d

3riBi(cid:0)|wi|ri + 2E|Zi|ri(cid:1)(cid:21).

Xi=1

(2.7)

(2.8)

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

12

Lemma 2.4. Let Xi denote the vector (Xi,1, . . . , Xi,d)T and let u : Rd → R+
be such that E|X rj
ij u(Xi)| < ∞ for all i = 1, . . . , n and j = 1, . . . , d. Then,
for all θ ∈ (0, 1),
∂mf
j=1 ∂wij

2rj Bj(cid:18)2rj Eu(Xi)E|Wj|rj
m (cid:20)AEu(Xi) +
Xj=1
2rj E|X
ij u(Xi)|
+ E|Zj|rj Eu(Xi)(cid:19)(cid:21),
nrj/2

θ )(cid:12)(cid:12)(cid:12)(cid:12)

Qm

E(cid:12)(cid:12)(cid:12)(cid:12)

(W(i)

u(Xi)

hm

≤

+

rj

d

(2.9)

u(Xi)

E(cid:12)(cid:12)(cid:12)(cid:12)

∂mf
j=1 ∂wij

Qm

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

E|(Σ−1/2Z)l|(cid:20)AEu(Xi)

≤ hm−1 min
1≤l≤d
2rj Bj(cid:18)2rj Eu(Xi)E|Wj|rj

+

d

Xj=1
2rj E|X rj
ij u(Xi)|
nrj/2

+

+

E|(Σ−1/2Z)lZ rj
j |
E|(Σ−1/2Z)l|

Eu(Xi)(cid:19)(cid:21),

d

∂3ψabc

h6

≤

u(Xi)

(W(i)

E(cid:12)(cid:12)(cid:12)(cid:12)

∂wj∂wk∂wl

θ )(cid:12)(cid:12)(cid:12)(cid:12)

18(cid:20)AEu(Xi) +
3rj Bj(cid:18)2rj Eu(Xi)E|Wj|rj
Xj=1
2rj E|X rj
ij u(Xi)
| + 2E|Zj|rj +1Eu(Xi)(cid:19)(cid:21),
nrj/2
P (Rd), C k−1
P (Rd),
where the inequalities are for g in the classes C k
respectively. For the second inequality, we must assume that Σ is positive
deﬁnite; for the other inequalities it suﬃces for Σ to be non-negative deﬁnite.

(Rd) and C 6

+

P

Proof. Let us prove the ﬁrst inequality. From inequality (2.7) we have

u(Xi)

E(cid:12)(cid:12)(cid:12)(cid:12)

∂mf
j=1 ∂wij

Qm

(W(i)

θ )(cid:12)(cid:12)(cid:12)(cid:12)

≤

d

hm

m (cid:20)AEu(Xi) +
Xj=1
+ E|Z|rj Eu(Xi)(cid:17)(cid:21),

2rj Bj(cid:16)E|u(Xi)(W (i)

j,θ )rj|

j,θ is the j-th component of W(i)

where W (i)
θ . By using the crude inequality
|a + b|s ≤ 2s(|a|s +|b|s), which holds for any s ≥ 0, and independence of Xij

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

13

and W (i)

j

, we have

E|u(Xi)(W (i)

j,θ )rj| ≤ 2rj E(cid:12)(cid:12)(cid:12)(cid:12)

u(Xi)(cid:18)|W (i)
≤ 2rj(cid:18)Eu(Xi)E|W (i)

j

j

|rj +
|rj +

θrj

nrj/2|Xij|rj(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)

1

E|X rj

ij u(Xi)|(cid:19),

nrj/2

(2.10)

Using that E|W (i)

j

|rj ≤ E|Wj|rj leads to the desired inequality. This can be

seen by using Jensen’s inequality:

E|Wj|rj = E[E[|W (i)
≥ E|E[W (i)

j + n−1/2Xij|rj | W (i)
j + n−1/2Xij | W (i)

j

j

]]

]|rj = E|W (i)

j

|rj .

Thus we obtain the ﬁrst inequality. The proofs of the other two inequalities
are similar; we just use inequalities (2.6) and (2.8) instead of inequality
(2.7).

By applying the inequalities of Lemma 2.4 to the bounds of Lemmas 2.1
and 2.2, we can obtain the following four theorems for the distributional
distance between g(W) and g(Σ1/2Z) when the derivatives of g have poly-
nomial growth. Theorem 2.2 follows from using inequality (2.9) in the bound
of Lemma 2.1, and the other theorems are proved similarly. Theorems 2.4
and 2.5 give some simple suﬃcient conditions under which a O(n−1) bound
can be obtained for smooth test functions. We could obtain analogues of
Theorems 2.4 and 2.5 for the case of a positive deﬁnite covariance matrix Σ
(which would impose weaker conditions on g and h) by appealing to results
from Section 2 of [8]. However, for space reasons, we do not present them
(our applications involve covariance matrices that are only non-negative def-
inite).

Theorem 2.2. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as in Lemma
2.1, but with the additional assumption that E|Xij|rk+3 < ∞ for all i, j and
1 ≤ k ≤ d. Suppose Σ is non-negative deﬁnite and that g ∈ C 3
P (Rd). Let

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

14

Zi = (Σ1/2Z)i ∼ N (0, σii). Then, for h ∈ C 3
|Eh(g(W)) − Eh(g(Σ1/2Z))|
≤

(cid:26)AE|XijXikXil| +

6n3/2

h3

n

d

d

b (R),

Xj,k,l=1
Xi=1
E|XijXikXilX rt
2rtBt(cid:18)2rt E|Xil|E|Wt|rt +

+

2rt
nrt/2
d

+

Xt=1

Xt=1

2rtBt(cid:18)2rt E|XijXikXil|E|Wt|rt
it | + E|Zt|rt E|XijXikXil|(cid:19) + 2|EXij Xik|(cid:20)AE|Xil|

2rt
nrt/2

E|XilX rt

it | + E|Zt|rt E|Xil|(cid:19)(cid:21)(cid:27).

Theorem 2.3. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as in Lemma
2.1, but with the additional assumption that E|Xij|rk+3 < ∞ for all i, j and
1 ≤ k ≤ d. Suppose Σ is positive deﬁnite and that g ∈ C 2
P (Rd). Then, for
h ∈ C 2

b (R),

h2

2n3/2

r

Xt=1

E|(Σ−1/2Z)s|

min
1≤s≤d
2rt Bt(cid:18)2rt E|XijXikXil|E|Wt|rt

E|XijXikXil|(cid:19)

E|(Σ−1/2Z)sZ rt
t |
E|(Σ−1/2Z)s|
2rtBt(cid:18)2rt E|Xil|E|Wt|rt +

2rt
nrt/2

E|XilX rt
it |

d

n

+

×

Xi=1

2rt
nrt/2

|Eh(g(W)) − Eh(g(Σ1/2Z))| ≤
(cid:26)AE|XijXikXil| +

Xj,k,l=1
E|XijXikXilX rt
it | +
+ 2|EXijXik|(cid:20)AE|Xil| +
Xt=1
E|(Σ−1/2Z)sZ rt
E|Xil|(cid:19)(cid:21)(cid:27).
t |
E|(Σ−1/2Z)s|

+

r

Theorem 2.4. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as in Lemma
2.1, but with the additional assumption that E|Xij|rk+4 < ∞ for all i, j and
1 ≤ k ≤ d. Suppose Σ is non-negative deﬁnite and that g ∈ C 6
P (Rd) is an

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

15

even function. Then, for h ∈ C 6

b (R),

|Eh(g(W)) − Eh(g(Σ1/2Z))| ≤ M :=

h4
24n2

n

d

Xi=1

Xj,k,l,m=1

(cid:26)AE|XijXikXilXim|

+

2rtBt(cid:18)2rt E|XijXikXilXim|E|Wt|rt +

Xt=1
+ E|Zt|rt E|XijXikXilXim|(cid:19) + 9|EXij Xik|(cid:20)AE|XilXim|

2rt
nrt/2

E|XijXikXilXimX rt
it |

d

d

2rt
nrt/2

E|XilXimX rt

it | + E|Zt|rt E|XilXim|(cid:19)(cid:21)

2rtBt(cid:18)2rt E|Xim|E|Wt|rt +

2rt
nrt/2

d

|EXαaXαbXαc|

n

d

Xi=1

Xj,k,l=1

E|X rt
it |
(cid:26)AE|XijXikXil|

2rtBt(cid:18)2rt E|XilXim|E|Wt|rt +

+

Xt=1
+ 3|EXij XikXil|(cid:20)AE|Xim| +
+ E|Zt|rt E|Xim|(cid:19)(cid:21)(cid:27) +

h6
72n3

d

Xt=1
Xα=1

n

d

Xa,b,c=1
3rtBt(cid:18)2rt E|XijXikXil|E|Wt|rt +

+

Xt=1
+ 2E|Zt|rt+1E|XijXikXil|(cid:19) + 2|EXijXik|(cid:20)AE|Xil|

2rt
nrt/2

E|XijXikXilX rt
it |

+

d

Xt=1

3rtBt(cid:18)2rt E|Xil|E|Wt|rt +

2rt
nrt/2

E|XilX rt

it | + 2E|Zt|rt+1E|Xil|(cid:19)(cid:21)(cid:27).

(2.11)

Theorem 2.5. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as in Lemma
2.1, but with the additional assumption that E|Xij|rk+4 < ∞ for all i, j and
1 ≤ k ≤ d. Suppose Σ is non-negative deﬁnite and that EXijXikXil = 0 for

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

16

all 1 ≤ i ≤ n and 1 ≤ j, k, l ≤ d. Suppose g ∈ C 4

|Eh(g(W)) − Eh(g(Σ1/2Z))| ≤

h4
24n2

n

Xi=1

d

Xj,k,l,m=1

b (R),

P (Rd). Then, for h ∈ C 4
(cid:26)AE|XijXikXilXim|

d

+

2rt Bt(cid:18)2rt E|XijXikXilXim|E|Wt|rt +

Xt=1
+ E|Zt|rt E|XijXikXilXim|(cid:19) + 9|EXijXik|(cid:20)AE|XilXim|

2rt
nrt/2

E|XijXikXilXimX rt
it |

+

d

Xt=1

2rt Bt(cid:18)2rt E|XilXim|E|Wt|rt +

2rt
nrt/2

E|XilXimX rt

it | + E|Zt|rt E|XilXim|(cid:19)(cid:21)(cid:27).

(2.12)

Proof. Notice that in the proof of Lemma 2.2 the bound (2.4) reduces to
|R1| + |R2| + |R3| + |R4| when EXijXikXil = 0 for all 1 ≤ i ≤ n and
1 ≤ j, k, l ≤ d. Therefore the terms involving a multiple of EXijXikXil
vanish from the bound (2.11), and we no longer require that g is even and
also only need g to belong to the class C 4

P (Rd) and h to belong to C 4

b (R).

2.3. Relaxing the condition that g is even

∂ 3f

For our application to the rate of convergence of the power divergence statis-
tics we shall need a slight relaxation of the assumption from Theorem 2.4
that g is an even function. Looking back at the proof of Lemma 2.2, we see
that a crucial step in obtaining the O(n−1) rate of Theorem 2.4 was the
(W) is of order n−1/2 when g is even function satis-
result that E
fying suitable diﬀerentiability and boundedness conditions. We were able to
(Σ1/2Z) = 0 for such g.
obtain this result by using the fact that E
∂ 3f
(Σ1/2Z) = O(n−1/2) in order
However, it actually suﬃces that E
to obtain a ﬁnal bound of order n−1. This oﬀers the scope for relaxing the
condition that g is an even function. Suppose g : Rd → R is such that

∂wj∂wk∂wl

∂wj∂wk∂wl

∂wj∂wk∂wl

∂ 3f

g(w) = a(w) + δb(w),

(2.13)

where a : Rd → R and b : Rd → R satisfy suitable boundedness and diﬀer-
entiability conditions, a is an even function and 0 ≤ δ < 1 is a constant that
we shall often think of as being ‘small’. Through a sequence of lemmas we
(Σ1/2Z) = O(δ). This will
shall see that, for such a g, we have E

∂ 3f

∂wj∂wk∂wl

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

17

enable us to obtain an extension of Theorem 2.4 to the case that g is of the
form (2.13). This theorem will enable us to obtain O(n−1) bounds for the
rate of convergence of the power divergence statistics for certain values of
the index parameter λ; see Section 3.3.

We begin by obtaining simple useful formula for the partial derivatives
of the test function h(g(·)), where g is of the form (2.13). Before deriving
this formula, we state some preliminary results. The ﬁrst is a multivariate
generalisation of the Fa`a di Bruno formula for n-th order derivatives of
composite functions, due to [19]:

∂m

j=1 ∂wij

Qn

h(g(w)) = Xπ∈Π

h(|π|)(g(w)) · YB∈π

∂|B|g(w)
Qj∈B ∂wj

,

(2.14)

where π runs through the set Π of all partitions of the set {1, . . . , m}, the
product is over all of the parts B of the partition π, and |S| is the cardinality
of the set S. It is useful to note that the number of partitions of {1, . . . , m}
into k non-empty subsets is given by the Stirling number of the second kind
(cid:8)m
k(cid:9) (see [24]).
We now introduce a class of functions that will be play a similar role
P (Rd) of Section 2.2. We say that the function
to the class of functions C m
Q,δ(Rd) if g can be written in the form
g : Rd → R belongs to the class C m
(2.13), that all m-th order partial derivatives of a and b exist and there
exists a dominating function Q : Rd → R+ such that, for all w ∈ Rd, the
quantities

(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

∂kb(w)
j=1 ∂wij

m/k

,

∂ka(w)
j=1 ∂wij

m/k

,

Qk
Qk
are all bounded by Q(w). If g ∈ C m
w ∈ Rd, the quantities
∂|B|a(w)

(cid:12)(cid:12)(cid:12)(cid:12)

∂ka(w)
j=1 ∂wij

|b(w)|(cid:12)(cid:12)(cid:12)(cid:12)

Qk

(cid:12)(cid:12)(cid:12)(cid:12)

m/k

,

1 ≤ k ≤ m,

Q,δ(Rd) then it is easy to see that, for all

YB∈π

(cid:12)(cid:12)(cid:12)(cid:12)

,

Qj∈B ∂wj(cid:12)(cid:12)(cid:12)(cid:12)

YB∈π

(cid:12)(cid:12)(cid:12)(cid:12)

,

∂|B|b(w)

Qj∈B ∂wj(cid:12)(cid:12)(cid:12)(cid:12)

b(w) YB∈π

(cid:12)(cid:12)(cid:12)(cid:12)

∂|B|a(w)

Qj∈B ∂wj(cid:12)(cid:12)(cid:12)(cid:12)

are all bounded Q(w). With these inequalities we are able to prove the
following lemma.
Lemma 2.5. Suppose h ∈ C m
δb(w), is in the class C m

b (R) and that g, deﬁned by g(w) = a(w) +

Q,δ(Rd). Then, for all w ∈ Rd,

∂m

j=1 ∂wij

Qm

h(g(w)) =

∂m

j=1 ∂wij

Qm

h(a(w)) + δq(w),

(2.15)

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

18

where

|q(w)| ≤ δ˜hmQ(w)

and ˜hm = Pm

k=1(cid:8)m

k(cid:9)(cid:0)2mkh(k)k + kh(k+1)k(cid:1).

Proof. By (2.14), we have that

(2.16)

+ δ

∂|B|b(w)

Qj∈B ∂wj(cid:19)

+ r1(w),

∂m

j=1 ∂wij

Qm

h(g(w)) = Xπ∈Π
= Xπ∈Π

h(|π|)(g(w)) · YB∈π
h(|π|)(g(w)) · YB∈π

(cid:18) ∂|B|a(w)
Qj∈B ∂wj
∂|B|a(w)
Qj∈B ∂wj
where r1 satisﬁes the crude inequality, for all w ∈ Rd,
(cid:26)m
k(cid:27)2mkh(k)kQ(w),

|r1(w)| ≤ δ

m

Xk=1

as δ < 1. By the mean value theorem we have that

∂m

j=1 ∂wij

Qm

h(g(w)) = Xπ∈Π
Qm

=

∂m

j=1 ∂wij

where r2 is bounded for all w ∈ Rd by

h(|π|)(a(w)) · YB∈π

∂|B|a(w)
Qj∈B ∂wj

+ r1(w) + r2(w)

h(a(w)) + r1(w) + r2(w),

|r2(w)| ≤ δ Xπ∈Π
Xk=1

≤ δ

m

kh(|π|+1)k(cid:12)(cid:12)(cid:12)(cid:12)
b(w) YB∈π
(cid:26)m
k(cid:27)kh(k+1)kQ(w).

∂|B|a(w)

Qj∈B ∂wj(cid:12)(cid:12)(cid:12)(cid:12)

Summing up the remainders r1(w) + r2(w) completes the proof.

So far, we have imposed no conditions on the dominating function Q. How-
ever, from now on, we shall suppose that Q(w) = A +Pd
i=1 Bi|wi|ri, where
A ≥ 0, B1, . . . , Bd ≥ 0 and r1, . . . , rd ≥ 0. Thus, Q takes the same form as
P did in Section 2.2. We shall restrict our attention to such a dominating
function in this paper, but we note that we could obtain an analogue of
the following lemma for dominating functions that have exponential growth
(see [8], Section 2). However, for our applications, we shall not need such a
lemma, so we omit it for space reasons.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

19

Lemma 2.6. Let m ≥ 1 be odd. Suppose that h ∈ C m
Let f denote the solution (1.6). Then

b (R) and g ∈ C m

Q,δ(Rd).

(cid:12)(cid:12)(cid:12)(cid:12)
E(cid:20)

∂mf
j=1 ∂wij

˜hm
m (cid:20)A +

≤ δ

d

Xi=1

2ri+1BiE|Zi|ri(cid:21).

Qm
s,w = e−sw+√1 − e−2sΣ1/2Z, where Σ1/2Z is an independent
Proof. Let zΣ1/2Z
copy of Σ1/2Z ∼ MVN(0, Σ). Then, by dominated convergence and Lemma
2.5,

(Σ1/2Z)(cid:21)(cid:12)(cid:12)(cid:12)(cid:12)

(2.17)

∂mf (w)
j=1 ∂wij

Qm

0

= −Z ∞
= −Z ∞
− δZ ∞

0

0

∂m

j=1 ∂wij

e−msE(cid:20)
e−msE(cid:20)
j=1 ∂wij
e−msEq(zΣ1/2Z′

Qm
Qm

∂m

s,w ) ds,

h(g(zΣ1/2 Z′

s,w ))(cid:21) ds
s,w ))(cid:21) ds

h(a(zΣ1/2 Z′

where q is deﬁned as per equation (2.15). Evaluating both sides at the ran-
dom variable Σ1/2Z and taking expectations gives that

E(cid:20) ∂mf (Σ1/2Z)

j=1 ∂wij (cid:21) = −Z ∞
Qm
− δZ ∞

0

0

∂m

e−msE(cid:20)
j=1 ∂wij
e−msEq(zΣ1/2Z′

Qm

s,Σ1/2Z) ds.

h(a(zΣ1/2 Z′

s,Σ1/2Z))(cid:21) ds

(2.18)

s,Σ1/2Z = e−sΣ1/2Z + √1 − e−2sΣ1/2Z′ D= Σ1/2Z, which is equal in
Now, zΣ1/2Z′
distribution to −Σ1/2Z. Since a is an even function and m is odd, it therefore
follows that the ﬁrst integral on the right-hand side of (2.18) is equal to 0,
and so

e−msEq(zΣ1/2Z′

s,Σ1/2Z) ds,

e−msEQ(zΣ1/2Z′

s,Σ1/2Z) ds.

(2.19)

and thus, by (2.16),

0

E(cid:20) ∂mf (Σ1/2Z)

j=1 ∂wij (cid:21) = −δZ ∞
Qm
E(cid:20) ∂mf (Σ1/2Z)
j=1 ∂wij (cid:21)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)
Qm

≤ δ˜hmZ ∞

0

It was shown in [8] (see Lemma 2.3 and Corollary 2.2 of that work) that,
for all w ∈ Rd,

Z ∞

0

e−msEQ(zΣ1/2Z′

s,Σ1/2Z) ds ≤

1

m(cid:20)A + B

d

Xi=1

2ri(cid:0)|wi|ri + E|Zi|ri(cid:1)(cid:21).

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

20

Applying this inequality to (2.19) gives that

(cid:12)(cid:12)(cid:12)(cid:12)

E(cid:20)∂mf (Σ1/2Z)
j=1 ∂wij (cid:21)(cid:12)(cid:12)(cid:12)(cid:12)
Qm

≤ δ

= δ

d

˜hm
m (cid:20)A + B
˜hm
m (cid:20)A +

2ri(cid:0)E|Zi|ri + E|Zi|ri(cid:1)(cid:21)
Xi=1
2ri+1BiE|Zi|ri(cid:21),
Xi=1

d

as required.

Theorem 2.6. Let Xij, i = 1, . . . , n, j = 1, . . . , d, be deﬁned as in Lemma
2.1, but with the additional assumption that E|Xij|rk+4 < ∞ for all i, j and
Q,n−1/2(Rd).
1 ≤ k ≤ d. Suppose Σ is non-negative deﬁnite and that g ∈ C 6
Then, for h ∈ C 6

b (R),

|Eh(g(W)) − Eh(g(Σ1/2Z))|
≤ M +

˜h3
6n2

Xj,k,l=1

Xi=1

n

d

|EXijXikXil|(cid:20)A +

d

Xt=1

2rt+1BtE|Zt|rt(cid:21),

where M is deﬁned as in Theorem 2.4.

Proof. Theorem 2.4 was obtained by applying Lemma 2.2 together with the
bounds of (2.3). Examining the proof of Lemma 2.2 (particularly equation
(2.4)), we see that we can obtain a bound for the quantity |Eh(g(W)) −
Eh(g(Σ1/2Z))| that is the bound M of Theorem 2.4 plus the additional term

1

2n3/2

n

d

Xi=1

Xj,k,l=1

|EXijXikXil|(cid:12)(cid:12)(cid:12)(cid:12)

E

∂3f

∂wj∂wk∂wl

,

(2.20)

(Σ1/2Z)(cid:12)(cid:12)(cid:12)(cid:12)

which arises because it is no longer assumed that g is an even function. Ap-
plying inequality (2.17), with δ = n−1/2, to bound (2.20) yields the desired
O(n−1) bound.

3. Application to Freidman’s chi-square and the power

divergence statistics

In this section, we consider the application of the approximation theorems
of Section 2 to the statistics for complete block designs that were introduced
in Section 1.1.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

21

3.1. Friedman’s statistic

We begin be observing the Friedman’s statistic falls into the class of statistics

√12√r(r+1)(cid:0)πi(j)−
covered by Theorem 2.5. Let Wj = 1√n Pn
2 (cid:1), and under the null hypothesis, for ﬁxed j, the collection of random
variables π1(j), . . . , πn(j) are i.i.d. with uniform distribution on {1, . . . , r}.
Friedman’s statistic is given by

i=1 Xij, where Xij =

r+1

Fr =

r

Xj=1

W 2
j ,

and is asymptotically χ2

(r−1) distributed under the null hypothesis.

By the central limit theorem, for any j, we have that Wj converges in
distribution to a mean zero normal random variables as n → ∞. However,
the Wj are not independent (see Lemma 3.1 for the (non-negative deﬁ-
nite) covariance matrix ΣW), and we have that W = (W1, . . . , Wr)T D→
MVN(0, ΣW) as n → ∞. However, for a ﬁxed j, the random variables
X1,j, . . . , Xn,j are independent because it is assumed that trials are inde-
pendent. Also, we can write χ2 = g(W), where g(w) = Pm
j . The
function g : Rr → R is an even function with partial derivatives of poly-
nomial growth. Finally, since the Xij have ﬁnite support, their moments of
any order exist. Therefore, Friedman’s statistic falls into the framework of
Theorem 2.4. However, since the distribution of the random variables Xij
is symmetric about 0, it follows that EXijXikXil = 0 for all 1 ≤ i ≤ n
and 1 ≤ j, k, l ≤ d. Thus, we can in fact apply Theorem 2.5 to bound the
rate of convergence of Friedman’s statistic. We present an explicit bound in
Theorem 3.1, but before stating the theorem we note the following lemma.

j=1 w2

Lemma 3.1. The (non-negative deﬁnite) covariance matrix of W, denoted
by ΣW = (σjk), has entries

σjj =

r − 1

r

and σjk = −

1
r

(j 6= k).

Proof. For ﬁxed j, π1(j), . . . , πn(j) are independent Unif{1, . . . , r} random
variables, and therefore

σjj = VarWj =

12

r(r + 1)n

n

Xi=1

Varπi(j) =

12

r(r + 1)n × n ×

r2 − 1
12

=

r − 1

r

.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

22

Suppose now that j 6= k. Since Pr
j +Xl6=j

Wl(cid:21) = EW 2

0 = E(cid:20)Wj

Xl=1

r

j=1 Wj = 0, we have

EWjWl = EW 2

j + (r − 1)EWjWk,

where we used that the Wj are identically distributed to obtain the ﬁ-
nal equality. On rearranging, and using that EW 2
r , we have that
EWjWk = − 1
r for j 6= k. As EWj = 0, it follows that σjk = Cov(Wj, Wk) =
EWjWk = − 1
r , for j 6= k, as required.
Theorem 3.1. Suppose r ≥ 2. Then, for h ∈ C 4

j = r−1

b (R+),
(r−1)h| ≤ 10797r5n−1h4,
(r−1)h denotes the expectation of h(Y ) for Y ∼ χ2

|Eh(Fr) − χ2

(r−1).

(3.1)

where χ2

Remark 3.2.

1. The bound (3.1) is of order n−1, which is the fastest
rate of convergence in the literature for Friedman’s statistic. However,
the numerical constants and the dependence of the bound on r are
far from optimal. This is the price we pay for deriving the bound by
applying the more general bound of Theorem 2.5. In proving Theorem
2.5, we used local couplings to deal with the dependence structure,
and this approach enabled us to obtain a O(n−1) bound for a class of
statistics for complete block designs. However, for Friedman’s statistic,
local couplings are quite crude, and their use leads to a bound with a
poor dependence on r. A direction for future research is to obtain a
O(n−1) bound with a better dependence on r.

2. As using the Theorem 2.5 to obtain a O(n−1) bound for Friedman’s
statistic will lead to one with a far from optimal dependence on r
and large numerical constants, we make use of a number of crude
inequalities to derive when applying Theorem 2.5 to derive our bound.
This simpliﬁes the calculations, but still allows us to obtain the desired
O(n−1) rate.

3. We could also apply Theorem 2.2 to derive a O(r3n−1/2) bound for
Friedman’s statistic, which may be preferable when the numerical con-
stants are large compared to n. Note that we cannot apply Theorem
2.3 because the covariance matrix ΣS is not positive-deﬁnite.

Proof of Theorem 3.1. As described above, Friedman’s statistic falls into
the framework of Theorem 2.5, so to derive the bound we need to ﬁnd
j and then bound the

a suitable dominating function for g(w) = Pm

j=1 w2

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

23

expectations that appear in the bound (2.12). For all k = 1, . . . , d we have
that ∂g(w)
(w) = 2 and all other derivatives are equal to
∂wk
2 = 4, meaning that we can take
j as our dominating function. We therefore apply the

= 2wk, ∂ 2g(w)
∂w2
k
4 = 16w4
∂g(w)
j=1 w4

k and (cid:12)(cid:12)

k (cid:12)(cid:12)

∂ 2g(w)

∂w2

bound (2.12) with A = 4, B1 = . . . = Br = 16 and r1 = . . . = rr = 4.

∂wk (cid:12)(cid:12)
0. Now, (cid:12)(cid:12)
P (w) = 4 + 16Pr

Now, let X be a random variable that has the same distribution as the
Xij. We shall need some formulas for the moments of X, which can be
computed from the following sum:

EX m = (cid:18) 12

r(r + 1)(cid:19)m/2 r
Xj=1

(cid:18)j −

r + 1

2 (cid:19)m

.

In particular,

EX 2 =

EX 6 =

EX 8 =

r − 1

r ≤ 1,
123

r3(r + 1)3 ·

124

r4(r + 1)4 ·

EX 4 =

144

r2(r + 1)2 ·

1
240

(r2 − 1)(3r2 − 7) ≤

9
5

,

1

1344
1

33792

(r2 − 1)(3r4 − 18r2 + 31) ≤
(r2 − 1)(r2 − 5)(3r6 − 37r4 + 225r2 − 511) ≤ 9.

,

27
7

With these inequalities and H¨older’s inequality we can bound the following
terms that arise in (2.12) for all 1 ≤ i ≤ n and 1 ≤ j, k, l, m, t ≤ d:

|EXijXik| ≤ E|XijXik| ≤ (EX 2)1/2 ≤ 1,

E|XijXikXilXim| ≤ (EX 4)1/4 ≤ (9/5)1/4,
il| ≤ (EX 6)1/6 ≤ (27/7)1/6,
it| ≤ (EX 8)1/8 ≤ 91/8.

E|XijXikX 4
E|XijXikXilXimX 4

We also have that, for all 1 ≤ j ≤ d,

EW 4

j =

3(n − 1)

n

(EX 2)2 + EX 4 ≤ 3 +

9
5n ≤

24
5

,

as EX = 0 and n ≥ 1. Finally, EZ 4
Plugging these inequalities into the bound (2.12) and simplifying using that

r (cid:1)2 < 3 for Zj ∼ N (0, σjj).

j = 3(cid:0) r−1

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

24

r, n ≥ 1 gives that
|Eh(Fr) − χ2
(r−1)h|
5(cid:19)1/4
r4h4
24n (cid:20)4(cid:18) 9
≤
+ 9(cid:18)4 + 28r(cid:18)16 ·
≤ 10797r5n−1h4,

+ 28r(cid:18)16 ·(cid:18) 9
n2(cid:18) 27

5(cid:19)1/4
7 (cid:19)1/6

24
5

16

+

+ 3 ·(cid:18) 9

5(cid:19)1/4(cid:19)

16 · 91/8

n2

24
5

+

·
+ 3(cid:19)(cid:19)(cid:21)

which is our ﬁnal bound.

(cid:3)

3.2. Pearson’s statistic

Here, we consider the application of Theorem 2.4 to Pearson’s statistic.
Recall that Pearson’s statistic is given by

χ2 =

r

Xj=1

(Uj − npj)2

npj

,

and is asymptotically χ2
(r−1) distributed provided np∗ → ∞, where p∗ =
min1≤j≤r pj. The cell counts Uj ∼ Bin(n, pj), 1 ≤ j ≤ r, are dependent
random variables that satisfy Pr
j=1 Uj = n. Now, let Iij ∼ Ber(pj) denote
the indicator that the i-th trial falls in the j-th cell. Then letting Xij = Iij−pj√pj
and Wj = 1√n Pn

i=1 Xij, we can write

r

χ2 = g(W) =

W 2
j ,

Xj=1

j=1 w2

where g(w) = Pr

j . As was the case for Friedman’s statistic, the func-
tion g is even and has derivatives of polynomial growth. Also, because trials
are assumed to be independent, the random variables X1,j, . . . , Xn,j are in-
dependent for ﬁxed j. The covariance matrix of W = (W1, . . . , Wr)T is non-
negative deﬁnite, with entries σjj = 1 − pj and σjk = −√pjpk, j 6= k (see

[10]). It is therefore the case that Pearson’s statistics falls within the class
of statistics covered by Theorem 2.4. However, unlike, Friedman’s statis-
tic, we cannot apply Theorem 2.5 to Pearson’s statistic. This is because
EXijXikXil 6= 0 in general.
case for Friedman’s statistic, for all k = 1, . . . , d we have that ∂g(w)
∂wk

We can apply Theorem 2.4 to Pearson’s statistic as follows. As was the
= 2wk,

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

25

∂ 2g(w)

∂w2
k

(w) = 2 and all other derivatives are equal to 0. However, because we
are applying Theorem 2.4 instead of Theorem 2.5, we need a diﬀerent dom-
3 = 8, meaning
inating function. We have that (cid:12)(cid:12)
k and (cid:12)(cid:12)
∂wk (cid:12)(cid:12)
that we can take P (w) = 8 + 64Pr
j as our dominating function. We
can therefore bound the quantity |Eh(χ2) − χ2
(r−1)| by applying the bound
(2.11) with A = 8, B1 = . . . = Br = 64 and r1 = . . . = rr = 6. We do not
compute this bound, but note that we can obtain one of the form

6 = 64w6

k (cid:12)(cid:12)

∂ 2g(w)

∂w2

∂g(w)

j=1 w6

|Eh(χ2) − χ2

(r−1)| ≤ Cn−1(h4 + h6),

(3.2)

Km(np∗)−1P5

where C is a constant depending on r and p1, . . . , pr, but not n. We do
not explicitly ﬁnd such a C because a superior upper bound of the form
k=1 kh(k)k has already been obtained by [10]. This bound
holds for a weaker class of test functions than (3.2) and has a much better
dependence on r and p1, . . . , pr than a bound that would result from an ap-
plication of Theorem 2.4. That the bound of [10] outperforms ours is perhaps
to be expected, given that their approach was target speciﬁcally at Pearson’s
statistic rather than the general class of statistics that are considered in this
paper.

3.3. The power divergence family of statistics

Recall that the power divergence statistic with index λ ∈ R is given by

Tλ =

2

λ(λ + 1)

r

Xj=1

Uj(cid:20)(cid:18) Uj

npj(cid:19)λ

− 1(cid:21).

Letting W be deﬁned as in Section 3.2, we can write (3.3) as

Tλ(W) = g(W) =

2

λ(λ + 1)(cid:20) r
Xj=1

npj(cid:18)1 +

Wj

√npj(cid:19)λ+1

− n(cid:21),

(3.3)

(3.4)

and Pr

since Wj = Uj−npj√npj
j=1 Uj = n. For general λ, the function g, deﬁned
as per equation (3.4), is not an even function; the notable exception being the
case λ = 1, which corresponds to Pearson’s statistic. Therefore, for λ 6= 1,
we cannot apply Theorems 2.4 and 2.5 to obtain O(n−1) bounds for the rate
of convergence of the statistic Tλ to its limiting χ2
(r−1) distribution. However,
for certain values of λ, the statistic Tλ falls into the class of statistics covered

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

26

by Theorem 2.6. Let us now see why this is the case. We can write

Tλ(W) =

r

Xj=1

W 2

j + R(W),

(3.5)

where

R(W) =

2

λ(λ + 1)

r

Xj=1

(cid:20)npj(cid:18)1 +

Wj

√npj(cid:19)λ+1

− npj − (λ + 1)√npjWj −
j=1 √pjWj = Pr

λ(λ + 1)

2

j (cid:21),
W 2

j=1 pj = 1 andPr

asPr
j=1(Uj−npj) = 0. Equation (3.5) tells
us that Tλ(w) is of the form (2.13), in the sense that it can be expressed as
the sum of an even term Pr
j (which corresponds to Pearson’s statistic)
and a ‘small’ term R(w). We can argue informally to see that this term
is small. Recall the binomial series formula (1 + x)α = P∞k=0
(−x)k
which is valid for |x| < 1, and the Pochhammer symbol is deﬁned by (β)n =
β(β + 1)··· (β + n − 1). Then, provided |wj| < √npj for all 1 ≤ j ≤ r, we
can use the binomial series formula to obtain that

j=1 w2

(−α)k

k!

R(w) =

2

λ(λ + 1)

r

Xj=1

npj(cid:20) ∞
Xk=0

(−λ − 1)k

k!

√npj(cid:19)k
(cid:18) −wj

− 1 −
2

=

λ(λ + 1)

λ + 1
wj −
√npj
∞
Xk=3
Xj=1

r

w2
j

2

λ(λ + 1)

npj(cid:21)
(−λ − 1)k(−wj)k

k!(npj)k/2−1

,

(3.6)

which is O(n−1/2) as n → ∞. Whilst the series expansion (3.6) shows that
R(w) is O(n−1/2), provided |wj| < √npj for all 1 ≤ j ≤ r, we still need
to argue carefully to apply Theorem 2.6 to obtain a bound for the rate
of convergence of Tλ; in fact, as we shall now see, the theorem cannot be
directly applied for all λ ∈ R. We shall now prove the following theorem and
end by discussing the corresponding conjecture.
Theorem 3.3. Let r ≥ 2 and suppose that λ is a positive integer or any
real number greater than 5. Then, for h ∈ C 6

b (R+),

|Eh(Tλ(W)) − χ2

(r−1)h| ≤ C(λ, p1, . . . , pr)r7n−1(h6 + ˜h3),

(3.7)

where C(λ, p1, . . . , pr) is a constant involving λ and p1, . . . , pr, but not n and
r.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

27

Conjecture 3.1. The O(n−1) rate of Theorem 3.3 holds for all λ ∈ R.
j and b(w) = √nR(w), so that
Proof of Theorem 3.3. Let a(w) = Pr
Tλ(w) = a(w) + n−1/2b(w). To apply Theorem 2.6, we need to ﬁnd a poly-
Q,n−1/2(Rr). We shall now
nomial dominating function Q such that Tλ ∈ C 6
show that we can ﬁnd such a dominating function if either λ is a positive
integer or any real number greater than 5. We have that ∂a(w)
= 2wk and
∂wk
∂ 2a(w)
= 2 and all other derivatives are equal to 0. Recall that

j=1 w2

∂w2
k

b(w) =

2√n

λ(λ + 1)

r

Xj=1

npj(cid:20)(cid:18)1 +

− 1 − (λ + 1)

wj
√npj −

wj

√npj(cid:19)λ+1
npj(cid:21).

w2
j

2

λ(λ + 1)

If λ is a positive integer greater than 1 (b(w) = 0 when λ = 1), then

b(w) =

2√n

λ(λ + 1)

r

Xj=1

npj(cid:26)(cid:18)λ + 1

3 (cid:19)(cid:18) wj

√npj(cid:19)3

+ ··· +(cid:18) wj

√npj(cid:19)λ+1(cid:27).

Q(w) = A +Pr

Thus, when λ is a positive integer, the function b is a O(1) polynomial in r
variables, and all its partial derivatives of any order are O(1) polynomials
or simply 0. As the derivatives of a are also O(1) polynomials or 0, it fol-
lows that there exists a O(1) polynomial dominating function of the form
Q,n−1/2(Rr). The random vari-
ables Xij have bounded support and all their moments exist and are O(1)
(with respect to n) and also all moments of the Wj are O(1). Thus, applying
Theorem 2.6 for the case λ ∈ Z+ yields a bound of the form (3.7). To obtain
an explicit form for C(λ, p1, . . . , pr), we would need to compute the relevant
expectations involving the Xij and Wj.

i=1 Bi|wi|ri such that Tλ ∈ C 6

Now let us suppose that λ is not necessarily an integer. For 1 ≤ k ≤ r,

the derivatives of b are given by

λwk

√npk(cid:21),

2n√pk

λ

=

wk

√npk(cid:19)λ
√npk(cid:19)λ−1

(cid:20)(cid:18)1 +
− 1 −
= 2√n(cid:20)(cid:18)1 +
− 1(cid:21),
2(λ − 1)··· (λ + 2 − m)√n

wk

=

∂b(w)
∂wk
∂2b(w)

∂w2
k

∂mb(w)

∂wm
k

(npk)m/2−1

(cid:18)1 +

wk

√npk(cid:19)λ+1−m

, m ≥ 3,

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

28

and all other derivatives are equal to 0. Recall that to apply Theorem
2.6, we need to ﬁnd a polynomial dominating function Q such that Tλ ∈
Q,n−1/2(Rr). This is not possible if λ is strictly less than 5 and not a posi-
C 6
tive integer, because in such cases there will be singularity at wk = −√npk

(note that this value is in the support of Wk) for at least one of the deriva-
tives of order 6 or less. Since we have already covered the positive integer
case, we suppose λ ≥ 5.
x ≥ −1,

Let us ﬁrst note the following crude inequalities. Let α ≥ 3. Then, for any

(cid:12)(cid:12)(1 + x)α − 1 − αx − 1

2 α(α − 1)x2(cid:12)(cid:12) ≤ 2α(|x|3 + |x|α),
(cid:12)(cid:12)(1 + x)α − 1 − αx(cid:12)(cid:12) ≤ 2α(x2 + |x|α),
(cid:12)(cid:12)(1 + x)α − 1(cid:12)(cid:12) ≤ 2α(|x| + |x|α),
(1 + x)α ≤ 2α(1 + |x|α).

With these inequalities, we obtain that, for wk ≥ −√npk for all k = 1, . . . , r,

|b(w)| ≤

(cid:12)(cid:12)(cid:12)(cid:12)

∂b(w)

∂wk (cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)

λ+1(cid:19),

r

3

2λ+2

wj

wj

≤

√npj(cid:12)(cid:12)(cid:12)(cid:12)
√npj(cid:12)(cid:12)(cid:12)(cid:12)
+(cid:12)(cid:12)(cid:12)(cid:12)
n3/2pj(cid:18)(cid:12)(cid:12)(cid:12)(cid:12)
Xj=1
λ(λ + 1)
2λ+1n√pk
√npk(cid:19)2
λ(cid:19),
+(cid:12)(cid:12)(cid:12)(cid:12)
√npk(cid:12)(cid:12)(cid:12)(cid:12)
(cid:18)(cid:18) wk
λ−1(cid:19),
≤ 2λ√n(cid:18)(cid:12)(cid:12)(cid:12)(cid:12)
√npk(cid:12)(cid:12)(cid:12)(cid:12)
√npk(cid:12)(cid:12)(cid:12)(cid:12)
+(cid:12)(cid:12)(cid:12)(cid:12)
2λ+2−m(λ − 1)··· (λ + 2 − m)√n

wk

wk

wk

λ

∂2b(w)

≤

∂w2
k

∂wm
k

∂mb(w)

(npk)m/2−1

(cid:12)(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)(cid:12)
for 3 ≤ m ≤ 6. Thus, if λ ≥ 5, all derivatives up to sixth order of b are
bounded above by a O(1) polynomial in the region wk ≥ −√npk, k =
1, . . . , r. We can therefore argue as we did for the λ ∈ Z+ case to conclude
that when λ ≥ 5 there exists a O(1) polynomial dominating function Q(w) =
A + Pr
Q,n−1/2(Rr). That the bound is of the
form (3.7) also follows by the same argument. Having dealt with the cases
λ ∈ Z+ and λ ≥ 5, we have completed the proof.
(cid:3)
Remark 3.4.

i=1 Bi|wi|ri such that Tλ ∈ C 6

1. To prove Theorem 3.3, it suﬃced to prove that there ex-

(cid:18)1 +(cid:12)(cid:12)(cid:12)(cid:12)

wk

√npk(cid:12)(cid:12)(cid:12)(cid:12)

λ+m−1(cid:19),

ists a O(1) polynomial dominating function Q such that Tλ ∈ C 6
for λ ∈ Z+ and λ ≥ 5. However, it is easy to verify that we could have

Q,n−1/2(Rr)

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

29

taken the following dominating function:

Q(w) = Aλ +

j(cid:18)|wj|12 +(cid:12)(cid:12)(cid:12)(cid:12)

wj

6λ(cid:19)
√npj(cid:12)(cid:12)(cid:12)(cid:12)

(3.8)

(3.9)

r

Bλ

r

Xj=1
Xj=1
r and Bλ

≤ ˜Aλ +

˜Bλ
j |wj|6λ,

j=1 Bλ

1 , . . . , Bλ

1 , . . . , ˜Bλ

where Aλ, ˜Aλ, ˜Bλ
r are O(1) non-negative con-
stants involving only λ. We could directly apply Theorem 2.6 with
the dominating function (3.9) to obtain a bound for |Eh(Tλ(W)) −
χ2
(r−1)h|. Alternatively, we that we could easily derive a variant of
Theorem 2.6 for dominating functions of the form (3.8). This would
result the same bound as that given in Theorem 2.6, but with an addi-
tional O(n−3λ) term. Thus, the leading order term (in n) of our bound
for |Eh(Tλ(W)) − χ2
(r−1)h| would result from applying Theorem 2.6
with the dominating function Aλ +Pr
j |wj|12. The bound would
then be computed by bounding the appropriate expectations involving
the Xij and Wj. Since r1 = . . . = rr = 12, the values of these expecta-
tions would not depend on λ. Therefore the performance of the bound
based on p1, . . . , pr would remain the same for any r ∈ Z or r ≥ 5.
2. Given that the application of Theorem 2.4 to Pearson’s statistic re-
sulted in a bound with a poor dependence on p1, . . . , pr and r compared
to the existing bound of [10], we would also expect that the applica-
tion of Theorem 2.6 to the power divergence statistics would result in
a bound with far from optimal dependence on these values. Again, we
expect this to be the case, because we obtain our bounds by apply-
ing a general bound. A possible direct for future research would be to
proceed in the spirit of [10] and use an approach speciﬁcally targeted
at the power divergence statistics to obtain a bound with a better
dependence on these values.

Remark 3.5. Unless λ ∈ Z+ or λ ≥ 5, the presence of a singularity at wk =
−√npk for a least one of the partial derivatives up to sixth order of b means
we cannot apply Theorem 2.6 to Tλ(W). We do, however, conjecture that
the O(n−1) rate holds for smooth test functions for any λ. This conjecture
is based on the fact that the O(n(r−1)/r) Kolmogorov distance bounds of [1]
and [29] are valid for all λ ∈ R and also the O(n−1/2) series formula (3.6)
for R(w). Extending the theory of this paper to deal with the whole family
of power divergence is an interesting direct for future research.

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

30

Acknowledgements

The authors would like to thank Persi Diaconis for bringing this problem
to our attention. RG is supported by EPSRC grant EP/K032402/1. GR ac-
knowledges support from EPSRC grants GR/R52183/01 and EP/K032402/1.

References

[1] Asylebekov, Z. A., Zubov, V. N. and Ulyanov V. V. On approximating
some statistics of goodness-of-ﬁt tests in the case of three-dimensional
discrete data. Siberian Math. J. 52 (2011), pp. 571–584.

[2] Barbour, A. D. Stein’s method for diﬀusion approximations. Probab.

Theory Rel. 84 (1990), pp. 297–322.

[3] Chatterjee, S., Fulman, J. and R¨ollin, A. Exponential approximation by
Stein’s method and spectral graph theory. ALEA Lat. Am. J. Probab.
Math. Stat. 8 (2011), pp. 197–223.

[4] Chatterjee, S. and Meckes, E. Multivariate normal approximation using
exchangeable pairs. ALEA Lat. Am. J. Probab. Math. Stat. 4 (2008),
pp. 257-283.

[5] Cressie, N. and Read, T. R. C. Multinomial Goodness-of-Fit Tests J.

Roy. Stat. Soc. B Met. 46 (1984), pp. 440–464.

[6] Friedman, M. The use of ranks to avoid the assumption of normality
implicit in the analysis of variance. J. Am. Stat. Assoc. 32 (1937), pp.
675–701.

[7] Gaunt, R. E. Variance-Gamma approximation via Stein’s method. Elec-

tron. J. Probab. 19 No. 38 (2014), pp. 1–33.

[8] Gaunt, R. E. Stein’s method for functions of multivariate normal ran-

dom variables. arXiv:1507.08688, 2015.

[9] Gaunt, R. E. Rates of Convergence in Normal Approximation Under
Moment Conditions Via New Bounds on Solutions of the Stein Equa-
tion. J. Theor. Probab. 29 (2016), pp. 231-247.

[10] Gaunt, R. E., Pickett, A. and Reinert, G. Chi-square approxi-
mation by Stein’s method with application to Pearson’s statistic.
arXiv:1507.01707, 2015.

[11] Goldstein, L. and Reinert, G. Zero biasing in one and higher dimensions,
and applications. In Stein’s Method and Applications. Lect. Notes Ser.
Inst. Math. Sci. Natl. Univ. Singap. 5 (2005), pp. 1-18, Singapore Univ.
Press, Singapore.

[12] Goldstein, L. and Rinott, Y. Multivariate normal approximations by

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

31

Stein’s method and size bias couplings. J. Appl. Probab. 33 (1996), pp.
1–17.

[13] G¨otze, F. On the rate of convergence in the multivariate CLT. Ann.

Probab. 19 (1991), pp. 724–739.

[14] G¨otze, F. and Ulyanov, V. V. Asymptotic distribution of χ2-type statis-
tics. Preprint 03–033 Research group Spectral analysis, asymptotic dis-
tributions and stochastic dynamics, Bielefeld Univ., Bielefeld.

[15] Jensen, D. R. On approximating the distributions of Friedman’s χ2

r and

related statistics. Metrika 24 (1977), pp. 75–86.

[16] Ley, C., Reinert, G. and Swan, Y. Approximate computation of expec-

tations : a canonical Stein operator. arXiv:1408.2998, 2014.

[17] Loh, W. L. Stein’s method and multinomial approximation. Ann. Appl.

Probab. 2 (1992), pp. 536–554.

[18] Luk, H. Stein’s Method for the Gamma Distribution and Related Statis-
tical Applications. PhD thesis, University of Southern California, 1994.
[19] Ma., T. W. Higher chain formula proved by combinatorics. Elec. J.

Comb. 16, Issue 1 (2009), N21.

[20] Mann, B. Stein’s method for χ2 of a multinomial. Unpublished

manuscript, 1997.

[21] Mann, B. Convergence rate for χ2 of a multinomial. Unpublished

manuscript, 1997.

[22] Meckes, E. On Stein’s method for multivariate normal approximation.

IMS Collect. 5 (2009), pp. 153-178.

[23] Nourdin, I. and Peccati, G. Stein’s method on Wiener chaos. Probab.

Theory Rel. 145 (2011), pp. 75–118.

[24] Olver, F. W. J., Lozier, D. W., Boisvert, R. F. and Clark, C. W. NIST
Handbook of Mathematical Functions. Cambridge University Press,
2010.

[25] Pearson, K. On the criterion that a given system of deviations is such
that it can be reasonably supposed to have arisen from random sam-
pling. Phil. Mag. 50 (1900), pp. 157–175.

[26] Pek¨oz, E. and R¨ollin, A. New rates for exponential approximation and
the theorems of R´enyi and Yaglom. Ann. Probab. 39 (2011) pp. 587–
608.

[27] Reinert, G. and R¨ollin, A. Multivariate Normal Approximations with
Stein’s Method of Exchangeable Pairs Under a General Linearity Con-
dition. Ann. Probab. 37 (2009), pp. 2150–2173.

[28] Stein, C. A bound for the error in the normal approximation to the the
distribution of a sum of dependent random variables. In Proc. Sixth
Berkeley Symp. Math. Statis. Prob. (1972), vol. 2, Univ. California

Gaunt and Reinert/Approximation of chi-square statistics by Stein’s method

32

Press, Berkeley, pp. 583–602.

[29] Ulyanov, V. V. and Zubov, V. N. Reﬁnement on the convergence of
one family of goodness-of-ﬁt statistics to chi-squared distribution. Hi-
roshima Math. J. 39 (2009), pp. 133–161.

[30] Yarnold, J. K. Asymptotic approximations for the probability that a
sum of lattice random vectors lies in a convex set. Ann. Math. Stat. 43,
(1972) pp. 1566-1580.

