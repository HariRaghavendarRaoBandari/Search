6
1
0
2

 
r
a

 

M
5
1

 
 
]

C
D
.
s
c
[
 
 

1
v
1
9
8
4
0

.

3
0
6
1
:
v
i
X
r
a

Distributed Newest Vertex Bisection

Martin Alk¨ampera and Robert Kl¨ofkornb

aInstitut f¨ur Angewandte Analysis und Numerische Simulation,
Fachbereich Mathematik, Universit¨at Stuttgart, Pfaﬀenwaldring

57, D-70569 Stuttgart, Germany,

www.ians.uni-stuttgart.de/nmh/,
alkaemper@ians.uni-stuttgart.de

bInternational Research Institute of Stavanger, P. O. Box 8046,

4068 Stavanger, Norway, http://www.iris.no,

robert.kloefkorn@iris.no

March 17, 2016

Abstract

Distributed adaptive conforming reﬁnement requires multiple itera-
tions of the serial reﬁnement algorithm and global communication as the
reﬁnement can be propagated over several processor boundaries. We show
bounds on the maximum number of iterations. The algorithm is imple-
mented within the software package Dune-ALUGrid.

Keywords: Adaptive method, mesh reﬁnement, parallel, Dune

1

Introduction

Conforming ﬁnite elements over conforming, unstructured, adaptive grids have
been shown to behave very well for numerical simulations of diﬀusive processes
([7]). On the other hand new computer architectures demand parallelism in
algorithms and grids to reach their full potential. For an adaptive, parallel, un-
structured and conforming grid we need a parallel (or distributed) reﬁnement
strategy.
In this paper we analyze the distributed reﬁnement strategy called Distributed
Newest Vertex Bisection. It is the straightforward extension [11] of the serial
Newest Vertex Bisection (NVB) introduced by Sewell [18] and we will show that
the parallel overhead is bounded, in particular by a constant independent of the
number of processors (Theorem 4.8). The Distributed NVB as described in this
paper has been implemented in the open-source package Dune-ALUGrid [1]
which is a module for the Dune software framework [3, 4]. Domain decompo-
sition in combination with adaptivity requires load balancing to equidistribute
In Dune-ALUGrid this is done by equilibrating the number
the workload.
of cells belonging to each processor. We make the common assumption that

1

load balancing is done after the reﬁnement algorithm is ﬁnished. Hence we will
not consider its eﬀect on the computational cost of the reﬁnement algorithm.
However, we will show that it is possible to implement the Distributed NVB
using modern techniques of parallel computing such as communication hiding
to achieve excellent strong scaling on a petascale super computer.

Most implementations of parallel adaptive grids use nonconforming hexahedral
(or quadrilateral in 2 dimensions) cells with some mesh-balance to acquire a
mesh grading required for stability estimates. Implementations of conforming
adaptive parallel meshes are scarce, as especially in more than two dimensions
the reﬁnement propagation is non-trivial.
The Distributed NVB reﬁnement strategy is also implemented in the toolbox
AMDiS [21], and we will show, that the bound they give on the communication
(O(log P ), where P is the number of partitions in [21, Sec. 2.4]) is too weak for
large P , unless the decomposition fulﬁlls additional assumptions.
Another approach to parallel simplex reﬁnement has been published by Rivara
et al. [17]. In this work a parallel algorithm is introduced that produces an un-
structured conforming mesh, which is not parallel in the domain decomposition
sense, but instead the whole grid is known on each processor and the algorithm
itself is executed in parallel. Furthermore, the reﬁnement strategy diﬀers, as it
is not Newest Vertex Bisection(NVB), but Longest Edge Bisection which was
introduced by Rivara in [16]. In [9] a fully distributed parallel Longest Edge
Bisection is implemented based on the package DOLFIN and reasonable scaling
results up to 1024 cores are presented, however, by sacriﬁcing the theoretical
backing of the adaptation algorithm.
The rest of the paper is structured as follows. First we introduce NVB with
examples for 2-dimensional grids. Then the NVB reﬁnement algorithm is ex-
tended to work in decomposed domains. Afterwards we analyze the Distributed
NVB and show bounds on the parallel overhead which are reﬂected in the nu-
merical experiments. The results hold for grids of any dimension unless stated
otherwise.

2 Newest Vertex Bisection

In this section we shortly introduce NVB for conforming triangulations in two
space dimensions. It was introduced by Sewell [18] and enhanced by Mitchell
with a recursive reﬁnement algorithm [13, 14]; compare also with [2, 12, 19, 20].
We follow the notation of [8].

2.1 Recurrent bisection of a simplex

−→

−→

Figure 2.1: NVB: a triangle with its two children and four grandchildren. The
reﬁnement edges are indicated in red.

2

In order to easily describe NVB we identify a simplex T with its set of ordered
vertices

T = [z0, z1, z2].

The edge between the ﬁrst and last vertex we call reﬁnement edge. NVB reﬁnes
T by inserting a new vertex in the midpoint ¯z = 1
2 (z0 + z2) of the reﬁnement
edge z0z2 and

T1 = [z0, ¯z, z1]

and

T2 = [z2, ¯z, z1]

are the two children of T . This procedure automatically presets the children’s
reﬁnement edges by the local ordering of their vertices. NVB thereby determines
the reﬁnement edge of any descendant produced by recurrent bisection of a given
initial element T0 from the vertex order of T0; see Figure 2.1.
Recurrent bisection induces the structure of an inﬁnite binary tree F(T0): Any
node T inside the tree is an element generated by recurrent application of NVB.
The two successors of a node T are the children T1, T2 created by a applying
NVB to T .

A

B

C

D D

A

A

B C

C B

A

A

Figure 2.2: NVB: The four similarity classes for an initial element T0.

Finally, NVB produces shape regular descendants since all T ∈ F(T0) belong to
at most four similarity classes; compare with Figure 2.2. This is a consequence
of the fact that NVB always bisects the angle at the newest vertex. In the end,
any angle of any simplex is bisected at most once. This can be extended to
any dimension d, see e.g.
[19]. In the following, unless speciﬁed explicitly, we
assume a general d ≥ 2.

2.2 Recurrent reﬁnement of triangulations with NVB
Let T0 be a conforming and exact triangulation of a bounded polygon Ω ⊂ Rd.
We can reﬁne T0 or a reﬁnement T of T0 by applying the NVB to selected
simplices. More than the selected elements have to be reﬁned when striking
for conforming triangulations. Here we refer to [13] for a recursive reﬁnement
algorithm and to [2] for an iterative one.
We next introduce notations related to triangulations. The master forest

F := F(T0) =

F(T0)

(cid:91)

T0∈T0

The ﬁnite element star at a vertex z is then Ωz := (cid:83){T : T ∈ T (z)}. We let

holds full information about all possible reﬁnements of T0. We denote by T =
T(T0) the class of all conforming reﬁnements of T0.
For T ∈ T the sets of all its vertices and edges are V and E, respectively. For
T ∈ T we set V(T ) := V ∩ T and for z ∈ V we deﬁne T (z) := {T ∈ T | z ∈ T}.
hT ∈ L∞(Ω) be the piecewise constant mesh-size function with hT |T = hT :=
|T|1/2 (cid:104) diam(T ) for T ∈ T . We use hmin,max(T ) for the smallest and largest
element size of T . We say T, T (cid:48) ∈ T are direct neighbours iﬀ there is an E ∈ E
with E ⊂ T ∩ T (cid:48).

3

Important in the course of this article is the generation of an element. For each
T ∈ T there is a T0 ∈ T0 such that T ∈ F(T0). The generation gen(T ) is
the number of its ancestors in the tree F(T0), or, equivalently, the number of
bisections needed to create T from T0.
The following simple properties are useful.
Lemma 2.1. (1) For T ∈ F(T0) with T0 ∈ T0 we have

hT = 2− gen(T )/2hT0 .

(2) Deﬁning α0 := max{#T (z0) | z0 ∈ V0} we have for d = 2 and z ∈ V the

bound

#T (z) ≤

8
2α0

if z ∈ V \ V0,
if z ∈ V0.

(cid:40)

Proof. Bisection halves the volume of a simplex. The deﬁnition of gen(T ) then
gives the ﬁrst claim. During reﬁnement any angle is bisected at most once,
which yields the second assertion.

The following assumption on a compatible distribution of reﬁnement edges in
T0 is instrumental in the analysis of NVB, like the complexity estimates in
[5, 19, 10].
Assumption 2.2 (Compatibility Condition). Suppose T, T (cid:48) ∈ T0 are direct
neighbours with common edge T ∩ T (cid:48) = E ∈ E0. Then either E is the common
reﬁnement edge of both T and T (cid:48), or E is the reﬁnement edge of descendants
T (cid:48)(cid:48) of T and T (cid:48)(cid:48)(cid:48) of T (cid:48) such that gen T (cid:48)(cid:48) = gen T (cid:48)(cid:48)(cid:48) < d.

Mitchell has shown that a distribution of reﬁnement edges, s.t. assumption
2.2 holds, can be found for any initial triangulation T0 [13, Theorem 2.9] in 2
dimensions; compare also with [5, Lemma 2.1]. The assumption particularly
implies that any uniform reﬁnement of T0 is conforming, i. e., for any g ∈ N0
we ﬁnd that {T ∈ F(T0) | gen(T ) = g} ∈ T. The proof of this property is a
combination of [20, §4] and [19, Theorem 4.3]. It is the key to show the following
property of NVB; compare with [19, Corollary 4.6].

Proposition 2.3 (Characteristics of NVB). Suppose that the initial triangula-
tion T0 satisﬁes Assumption 2.2. Let T ∈ T be given and suppose that T, T (cid:48) ∈ T
are direct neighbours such that the common edge E = T ∩ T (cid:48) is the reﬁnement
edge of T . Then we either have gen(T (cid:48)) = gen(T ) and E is also the reﬁnement
edge of T (cid:48), or gen(T (cid:48)) = gen(T ) − i with 1 ≤ i < d.
A simple consequence is |gen(T ) − gen(T (cid:48))| ≤ d−1 for direct neighbours T, T (cid:48) ∈
T .

3 Distributed Newest Vertex Bisection

The extension of NVB to the domain decomposition case is necessary, as the
decomposed grid needs to be conforming across processor/partition boundaries.
The basic idea is to execute the serial algorithm on each partition, communicate
the reﬁnement status of the partition boundary to the corresponding neighbour,
reﬁne conformingly and iterate.

4

In [11] it is shown that this parallel Algorithm 3.1 yields the same ﬁnal trian-
gulation as the serial version for meshes that fulﬁll the compatibility condition
2.2. This is essentially due to the fact that there is a unique mapping from the
set of marked elements to the ﬁnal reﬁnement situation.

Algorithm 3.1: Distributed Newest Vertex Bisection
1 Initialize set of elements marked for reﬁnement on each Partition Mi,
2 while Mi (cid:54)= ∅∀ i do

0 ≤ i < P .

Reﬁne Partition Pi using NVB until Mi is empty
Communicate reﬁnement status of partition boundary to
corresponding neighbour
Add nonconforming simplices to Mi
Communicate globally, whether Mi is empty.

3

4

5

6
7 end

We improved the algorithm introduced in [11] by additionally communicating
the edge status (i.e. whether the edge has been bisected) of edges belonging
to the process boundaries. This is slightly more communication expensive in
3 or more dimensions but it reduces the number of iterations needed. For 2
dimensions both algorithms coincide as faces are always 1 dimensional.
The stopping criteria of the while loop requires a global communication (Allre-
duce, O(log p) where p is the number of partitions), which cannot be expected
to scale well onto many cores. On the other hand communicating the reﬁne-
ment status to the neighbour can be expected to scale quite well as long as the
number of neighbouring partitions stays small, which relates to the quality of
the decomposition.

4 Communication of the Distributed Newest Ver-

tex Bisection

Bounds for the amount of communication necessary to reach a conforming trian-
gulation are directly related to bounding the number of iterations in Algorithm
3.1. While the ﬁrst bound from Theorem 4.6 does not need more assumptions
than Compatibility Condition 2.2, Theorem 4.8 additionally requires dimension
d = 2 and a certain form of mesh decomposition.
The following ﬁrst lemma helps to understand the direct consequences of a single
reﬁnement.
Lemma 4.1. For all direct neighbours T (cid:48) of an element T ∈ T with reﬁnement
edge E with E ⊂ T (cid:48) ∩ T one of the following two statements holds
1 Reﬁnement of E in T (cid:48) induces no further reﬁnement (it already is the reﬁne-
ment edge)
2 E is the reﬁnement edge of a child of T (cid:48) and reﬁnement of E induces up to
d − 1 reﬁnements of elements Ti ⊂ T (cid:48) with gen(Ti) < gen(T ).
Proof. Two cases:
1 gen(T ) = gen(T (cid:48)) ⇒ no further reﬁnement. It is the reﬁnement edge of both
elements because of the compatibility condition.

5

2 gen(T ) = gen(T (cid:48)) + i with 1 ≤ i ≤ d − 1 ⇒ induces i further reﬁnements.
The reﬁnement edge can only be the same, if both elements have the same
generation and direct neighbours can only diﬀer in generation by d at most.
The generation is increased by one with each reﬁnement, so there have to be
i reﬁnements of descendants of T (cid:48) that are reﬁned, until the i-th descendant
shares the reﬁnement edge with T and yields the conforming closure of that
element.

Lemma 4.1 can be applied recursively. A single reﬁnement may lead to reﬁne-
ments of direct neighbours at 1 to (d− 1) generations lower and these may again
lead to reﬁnements at even lower generations.

Example 4.2. Let us assume a simplex T with generation gen(T ) = 0 and its
direct neighbour T (cid:48) with gen(T (cid:48)) = d− 1 and reﬁnement edge E = T ∩ T (cid:48). Now
we reﬁne T (cid:48), so we reﬁne E and hence T . The compatibility condition 2.2 yields
that E is the reﬁnement edge of a descendant T (cid:48)(cid:48) of T with gen(T (cid:48)(cid:48)) = d − 1.
We denote by T i
E the descendant of T with generation i that contains E and we
denote its reﬁnement edge by Ei. So T (cid:48)(cid:48) = T d−1
E and Ed−1 = E. Then
the Reﬁnement Propagation can be depicted in the following graph of ﬁgure 4.1.
The dashed lines denote the direct closure. It cannot induce further reﬁnement

E , T = T 0

T (cid:48)

E

gen 3

gen 2

gen 1

gen 0

T 2
E

T 1
E

T

T (cid:48)(cid:48)

E2

E1

E0

Figure 4.1: The direct Reﬁnement Propagation of example 4.2 with d = 4.

and can be neglected. More general we have to analyze the direct Reﬁnement
Propagation for any element that contains E and additionally for all elements
containing any of the edges Ei, as their reﬁnement may also induce further
reﬁnement in the grid.

This leads us to the following deﬁnition.

Deﬁnition 4.3. Reﬁnement of an element T with reﬁnement edge e0 and gen-
eration gen(T ) = l induces reﬁnement propagation in form of a directed graph
with root e0. For any element T (cid:48) with e0 ⊂ T (cid:48) and gen(T (cid:48)) =: l(cid:48) < l we have
for l(cid:48) ≤ i < l as new
a directed edge from e0 to the reﬁnement edge E(cid:48)
nodes. We repeat by setting every newly introduced node as a local root.
We call this the Reﬁnement Propagation Graph.

i of T (cid:48)i

e0

Example 4.4. Figure 4.2 depicts an example of the Reﬁnement Propagation
graph of an initial reﬁnement of an element T with reﬁnement edge e0. For some
elements the reﬁnement results in the direct closure, so they are not included in

6

gen l

(T1)l−1

e0

gen l-1

e1

e0

T1

T2

e3

T3

(T4)l−2

e4

T7

e2

e5

gen l-2

gen l-3

e4

T4

T5

T6

e7

e8

e6

Figure 4.2: An example for an Reﬁnement Propagation Graph.

the graph as well as T . For three direct neighbours T1, T2, T3 of T the reﬁnement
does not result in the direct closure. For T1 it even results in an additional
reﬁnement of its child (T1)l−1
that contains e0. Bisection of e4 to reﬁne T3 is
locally similar to the reﬁnement of T by e0. Note that the graph is not a tree,
as reﬁnement edges may be shared (e5 in our example). All leafs do not induce
further reﬁnement, so all adjacent elements are of the same level and reﬁnement
is the direct closure, which is not included in the graph.

e0

Remark 4.5. In 2 dimensions the Reﬁnement Propagation Path consists solely
of nodes of degree 2 (and the root and the leaf), since in 2 dimensions every
edge is shared by exactly two elements and the direct closure is not included.
Hence in 2 dimensions we call it the Reﬁnement Propagation Path.

With this preliminary work and exploiting the compatibility condition 2.2 we
state the following theorem.
Theorem 4.6. Let M ⊂ T be the set of elements marked for reﬁnement. Then
the number N of iterations in the Algorithm 3.1 to reach a conforming state
satisﬁes

N ≤ max
T∈M

T (cid:48)∈T (gen(T ) − gen(T (cid:48))) + 2.

max

Proof. Let T ∈ M with gen(T ) = l. We will bound the maximum depth of the
Reﬁnement Propagation Graph of T , which is an upper bound for the number
of iterations as in the worst-case scenario reﬁnement needs to be communicated
at every edge.
Due to Lemma 4.1 reﬁnement can be propagated at generation l−d < gen(T (cid:48)) <
l, in particular at generation l − 1 and no propagation at generation l. So
the maximum number of propagations NT resulting from reﬁning T is l −
minT (cid:48)∈T gen(T (cid:48)). This is clearly also the maximum depth of the Reﬁnement
Propagation graph.
We have to take into account, that the Reﬁnement Propagation graph does not
consider the direct closure, which could need an additional communication. It
follows

If we now take the maximum over all T ∈ M this results in

NT ≤ l − min

T (cid:48)∈T gen(T (cid:48)) + 1

T (cid:48)∈T (l(T ) − l(T (cid:48))) + 1 .

max

max
T∈M

7

We have to add another 1 as Algorithm 3.1 has to communicate that it has
ﬁnished.

The following example demonstrates that this bound is sharp and that we cannot
expect anything better even in the simple case of 2 partitions. In particular the
bound O(log p) from [21, Sec. 2.4] cannot hold without further assumptions on
the decomposition.

Figure 4.3: A distributed reﬁned mesh to illustrate that the bound of theorem
4.6 is sharp. Partitions are indicated by the color of the cells. Black lines denote
macro element borders. Dotted lines denote the initial reﬁnement situation. The
reﬁnement request is marked in red. Blue dashed lines denote its Reﬁnement
Propagation.

Example 4.7. Figure 4.3 shows a mesh consisting of three initial triangles fulﬁll-
ing the compatibility condition 2.2. One triangle has been reﬁned into a corner,
so the minimum generation in the mesh is minT (cid:48)∈T gen(T (cid:48)) = 0 and the gener-
ation of the marked element T ∈ M = {T} is gen(T ) = 6, so the bound from
Theorem 4.6 is 8 iterations. Every reﬁnement induces additional reﬁnement at
exactly one generation lower, so the reﬁnement propagation path traverses 7
edges. The mesh is partitioned in such a way that every edge lies on a processor
boundary, which implies that after every reﬁnement Algorithm 3.1 has to stop
and globally communicate. This means we get 7 iterations, where the marked
set is not empty on all processors and one ﬁnal iteration to communicate, that
we are ﬁnished. In total this is 8 iterations, which is the bound predicted from
Theorem 4.6.
Distributing the elements into partitions as depicted in ﬁgure 4.3 is not purely
artiﬁcial. Sorting the leaf elements in vertical direction with respect to their
center coordinates leads to these partitions.

Example 4.7 demonstrates that we have to impose additional assumptions on
the decomposition to expect better bounds on the number of iterations of Al-
gorithm 3.1.
A reasonable assumption could be that the partitions are created by a hierarchi-
cal space-ﬁlling curve, such that elements that are close in the reﬁnement-tree
are probably on the same partition.
Another assumption is that the mesh is partitioned solely on elements of a
generation l∗ which are then distributed onto partitions together with their

8

respective reﬁnement trees. This second assumption will be analyzed in this pa-
per, because this is the partitioning currently implemented in our grid manager
Dune-ALUGrid. Without loss of generality we can assume that we distribute
elements on the macro level (i.e. elements T with gen(T ) = 0) with their re-
spective reﬁnement trees. If this was not the case we could set the uniformly
reﬁned grid as our new initial grid, as for this kind of partitioning coarsening
below generation l∗ is forbidden.
The following results hold for partitioning on any ﬁxed level but only for 2-
dimensional grids, as we rely on the fact that we have a Reﬁnement Propagation
Path instead of a full graph.

Theorem 4.8. Let dimension d = 2 and the mesh be partitioned as described
above. Let z ∈ V and let Nz = {T ∈ T0 : z ⊂ T} the set of macro elements
containing that vertex. For an element T in the set of marked elements M
let T0(T ) ⊃ T be the element of the macro grid T0 that contains T . Then the
number of global communications N in Algorithm 3.1 satisﬁes

N ≤ max
T∈M

max
z∈T0(T )

3
4

#Nz +

7
4

≤ max
z∈T0

3
4

#Nz +

7
4

.

Proof. The second inequality is trivial. The proof of the ﬁrst inequality splits
into two parts.

1. Reﬁnement propagation around vertex z.

2. Reﬁnement propagation inside of macro elements that contain vertex z.

We start with a similar observation as in the proof of Theorem 4.6. By bound-
ing the traversals of edges of T0 within the reﬁnement propagation path, we
bound the number of global communications. We count edges of the reﬁnement
propagation path that are contained in edges of T0.
Let T ∈ M with z ∈ T0(T ) be the element to be reﬁned. Reﬁnement of T
leads to elements of generation l = gen(T ) + 1. All reﬁnement propagation of
reﬁnement of T is contained in the reﬁnement propagation of uniformly reﬁning
T0 to this level, which we will investigate. (cf. Figure 4.4)
(1): Reﬁnement propagation around vertex z.
We are now investigating the eﬀect of reﬁnement of T0 at its vertex z. There
are two possibilities:
a. z is opposite of the initial reﬁnement edge of T0.
Then there are two leaf elements T 0,1 with z ∈ T 0,1 ⊂ T0 and gen(T 0) =
gen(T 1).
If gen(T 0,1)/2 mod 2 = 0, the reﬁnement edge of T 0 and T 1 is
the shared edge. If gen(T 0,1)/2 mod 2 = 1 the reﬁnement edge of T 0,1 is a
subedge of an edge of T0 containing z and as we are uniformly reﬁning up to
level l, every odd level there is reﬁnement propagation across these edges.
b. z is contained in the initial reﬁnement edge of T0.
Then there is one leaf element with z ∈ T (cid:48) ⊂ T0. The reﬁnement edge of T (cid:48)
is always contained in one of the edges of T0. So every level reﬁnement of T (cid:48)
leads to reﬁnement propagation across one of the two edges of T0 containing
z.

We know that elements around the vertex z form the reﬁnement propagation
path of T (cid:48), as they all diﬀer by one in generation and due to the argument above.

9

The path evolves around the vertex until it encounters an element with the
lowest level. The maximum level diﬀerence around the vertex is (#T (z) − 1)/2
as there have to exist at least two elements with lowest generation. So the
maximum length of the reﬁnement propagation path around z is (#T (z)− 1)/2.
We want to bound the reﬁnement propagation path edge traversals with respect
to #Nz. #Nz is smaller than #T (z), as for every element in #Nz where the
reﬁnement edge is opposite of z, there are two elements in #T (z). Now there
are two cases:

a. #Nz is even:

The worst case is #T (z) = 3/2#Nz and all reﬁned macro angles are neigh-
bouring. Then, in one of the circumvention direction all edge traversals
are traversals in Nz and so we may need (3/2#Nz − 1)/2 traversals in Nz
until we encounter the element with the lowest level.

b. #Nz is odd:

The worst case is #T (z) = 3/2#Nz + 1/2 and all reﬁned angles are neigh-
bouring. Then, in one of the circumvention direction all edge traversals
are traversals in Nz and so we may need (3/2(#Nz)+1/2−1)/2 traversals
in Nz until we encounter the element with the lowest level.

So the number of macro edge traversals N e
path around z satisﬁes

z within the reﬁnement propagation

z ≤ (3/2(#Nz − 1/2)/2 = 3/4#Nz − 1/4.
N e

(2): Reﬁnement propagation inside of macro elements that contain vertex z.
We already know that the uniform reﬁnement propagates into all macro ele-
ments, which share z. So we can neglect macro elements that share an edge
with T0 as we know that their reﬁnement propagation does not yield any addi-
tional information.
So we consider a macro element T1 that contains z and does not share an edge
with T0. We know that we have a reﬁnement at vertex z and want to investigate,
whether we can reach the edge opposite of z. The other edge does not matter,
as it contains z.
The size of an element of generation l is 2−l|T0| (Lemma 2.1). The reﬁne-
ment propagation path consists of elements that diﬀer by one in level. So the
k 2−k|T1| =
|T1|(2−n − 2−l). So to get to another element from the opposite vertex it has
to include an element of level 0, a macro element. This is only possible, if the
initial reﬁnement edge is opposite of z.
In combination with the previous result this yields

size of the reﬁnement propagation path inside the element T1 is(cid:80)

N ≤ (3/2#Nz − 1/2)/2 + 1 = 3/4#Nz + 3/4.

Now we ﬁnish the proof by adding another +1 for communicating the ﬁnal
status and taking the maximum over all vertices of T0 and over all marked
elements.

Remark 4.9. From part (2) of the proof one can see, that if the mesh is uni-
formly reﬁned up to one level below the macro level, then the +1 from this part
disappears and we get.
N ≤ max
T∈M

3/4#Nz + 3/4 ≤ max
z∈T0

3/4#Nz + 3/4

max
z∈T0(T )

10

Figure 4.4: Reﬁnement propagation from uniform reﬁnement of a single macro
element.

Remark 4.10. If we do not count all edges of T0, but only those that are actually
processor boundaries, we get the following bound that is better as long as every
processor gets ”nice” partitions.

N ≤ max
T∈M

max
z∈T0(T )

#Pz − 1 + 1 = max
T∈M

max
z∈T0(T )

#Pz

where #Pz is now the number of partitions that share a vertex. The proof is
similar to the proof of theorem 4.8, but we get #Pz − 1 as we cannot argue with
circumventions in both directions and the +1 is again due to the ﬁnal commu-
nication. Note that if a processors partition p has several elements containing
z and there is no path of elements T ∈ p containing z connecting two elements,
every connected subdomain has to be counted as a partition.

Remark 4.11. Theorem 4.8 provides a mesh constant. So no dependence on
number of processors is required, but just a regular initial mesh (see α0 in
Lemma 2.1).

Remark 4.12. We believe that theorem 4.8 holds in a similar way for higher
dimensions. It is a hard problem as the shape of the Reﬁnement Propagation
graph is not known.

Based on the estimate in remark 4.10 we propose a new improved algorithm for

11

compatible meshes.

Algorithm 4.1: Improved Distributed Newest Vertex Bisection
1 Initialize set of elements marked for reﬁnement on each Partition Mi,
2 for i = 0, . . . , maxz∈T0#Pz − 1 do

0 ≤ i < P .

Reﬁne Partition Pi using NVB until Mi is empty
Communicate reﬁnement status of partition boundary to
corresponding neighbour
Add nonconforming simplices to Mi

3

4

5
6 end

For compatible meshes we have proven, that this algorithm yields the conforming
closure and reaches the ﬁnal status. So communicating the ﬁnal status is no
longer necessary. Hence we take the better bound maxz∈T0 #Pz − 1 instead of
maxz∈T0 #Pz. We can directly use the bound from Theorem 4.8 and get an
algorithm, which does not need global communication at all. Unfortunately
we cannot expect meshes to be compatible, especially in 3 dimensions. In this
case we propose to use a mixture of both algorithms, where a ﬁxed number of
loops is done like in 4.1 before switching to the Algorithm 3.1 after a global
communication, whether Mi (cid:54)= ∅ ∀ i.

5

Implementation

line 4 in Algorithm 3.1 and 4.1.

The NVB algorithm is implemented in the open-source package Dune-ALUGrid
available at https://gitlab.dune-project.org/extensions/dune-alugrid.
[1] contains a description of the software and various examples.
In this section we discuss the implementation of the communication procedures
which is not contained in detail in [1]. Communication is needed to exchange
the reﬁnement ﬂags, e.g.
It is essential for
the Distributed NVB that this is done in a very eﬃcient way to guarantee ex-
cellent scalability. In Dune-ALUGrid we have chosen to interleave the send
and receive procedures with the packing and unpacking of reﬁnement informa-
tion. This way we are able to hide some of the communication latency behind
the necessary pack and unpack of information. We brieﬂy sketch the send and
pack routine as well as the receive and unpack routine used in Dune-ALUGrid.
Let Ls
p be the set of all ranks that process p ∈ [0, P − 1] sends data to and
Lr
p the corresponding set p received messages from. We call the communication
symmetric if Ls
p. Asymmetric communication occurs, for example, during
the load balancing, where the list of send and receive ranks can diﬀer. The
communication algorithm, however, is the same. Using the sets Ls
p the
corresponding methods for pack-and-send and receive-and-unpack are brieﬂy
explained in Algorithm 5.1 and 5.2, respectively. In the following T q
p denotes
the set of simplices on process p with linkage to rank q ∈ Ls,r
p .
Both algorithms are implemented in Dune-ALUGrid and work for very general
data sets and are thus used for all point to point communications in the package.

p = Lr

p,Lr

12

Algorithm 5.1: Pack and send
1 for q ∈ Ls

p do
for T ∈ T q

p do

2

3

4

5
6 end

pack reﬁnement information for simplex T and communication
link q

end
post non-blocking MPI Isend for communication link q

Algorithm 5.2: Receive and unpack
1 for q ∈ Lr
rq ← 0

p do

2
3 end
4 nr ← 0
5 while nr < |Lr
for q ∈ Lr

6

p| do
p do

7

8

9

10

11

12

13

14

15

16

17

18

if rq = 0 then

rq ← MPI Iprobe( q )
if rq = 1 then

s ← MPI Getcount( q )
resize buﬀer for received message size s
post MPI Recv( q ) to write message from q to buﬀer
for T ∈ T q

p do

unpackData( T , q )

end
nr ← nr + 1

end

end

end

19
20 end
21 MPI Waitall( Ls

p ), see Algorithm 5.1

6 Numerical Experiments

In this section we show for various examples that the theoretical results can
be reproduced and that very good scalability for the adaptation algorithm is
observed on a petascale super computer.

6.1 Veriﬁcation of theoretical results

The ﬁrst experiment aims to reﬂect the theoretical results as we construct a
worst-case experiment. A mesh is partitioned such that each process gets exactly
one macro element. Then we reﬁne a single element at one of its vertices up
to level 20 and we examine the number of iterations necessary to reach the
conforming status.
From ﬁgure 6.1 we see that for compatible 2d grids both bounds(red lines) are

13

7

6

5

4

3

2

s
p
o
o
L

t
n
e
m
e
n
ﬁ
e
R

0

5

10

15

20

Max Level

Figure 6.1: A 2d unit square with 18 macro elements on 18 processors. The
central yellow element gets reﬁned at the top vertex. The number of macro
neighbours #Nz = 6. In the right plot red lines denote the two bounds from
the Theorems 4.8 and 4.6.

not violated by the current implementation. As this is a worst-case scenario, in
the average case the behaviour is better. Now we perform the same experiment
on a non-compatible grid.

s
p
o
o
L

t
n
e
m
e
n
ﬁ
e
R

8

6

4

2

0

5

10

15

20

Max Level

Figure 6.2: A non-compatible 2d grid with 60 macro elements on 60 processors.
An element (with #Nz = 6) gets reﬁned at a vertex. In the right plot red lines
denote the two bounds from the Theorems 4.8 and 4.6.

As expected, the plot in Figure 6.2 illustrates that compatibility is a necessary
condition for both theorems. This means although the implementation is ca-
pable of handling non-compatible 2d grids, the bounds from the theory do not
hold.
We expect the bound from Theorem 4.6 to hold in any dimension. This is not
the case in ﬁgure 6.3. This failure arises from an implementation detail, that
reﬁnement status is communicated for faces instead of edges. After implementa-
tion of an additional communication of edges statuses during reﬁnement we see
that the theoretical result holds. In addition, the plot indicates the existence of
a constant to bound the number of iterations in 3d similar to Theorem 4.8.

14

12

10

8

6

4

2

s
p
o
o
L

t
n
e
m
e
n
ﬁ
e
R

12

10

8

6

4

2

s
p
o
o
L

t
n
e
m
e
n
ﬁ
e
R

0

5

10

15

20

0

5

10

15

20

Max Level

Max Level

Figure 6.3: Unit cube. 162 Macro Elements/ 162 processors (3 × 3 × 3 Kuhn-
dice). Central element gets reﬁned at one vertex. On the left reﬁnement status
is communicated on faces. On the right reﬁnement status is ﬁrst communicated
over edges and then additionally over faces.

6.2 Strong scaling experiments

In Figure 6.4 we show the reﬁnement of a doughnut that rotates around the
center (doughnut reﬁnement). Triangles inside the doughnut are reﬁned and
triangles outside are coarsened. This test was introduced in [1] and serves as an
excellent test for the Distributed NVB since frequent reﬁnement and coarsening
occurs throughout the simulation. In fact, the adaptation and load balancing is
performed in each time step. The domain decomposition is based on the Hilbert
space ﬁlling curve approach implemented in Zoltan [6]
Figures 6.5 and 6.6 we provide strong scaling results obtained for the doughnut
reﬁnement test in 2d and 3d, respectively. The scaling experiment have been
performed on the super computer Yellowstone [15]. The observed strong scaling
for the adaptation cycle (green triangular line) is excellent for all experiments
and very close to the optimal scaling. The load balancing (pink boxed line) on
the other hand at some points fails to scale well because the number of macro
simplices per core becomes to small as the number of processes grows which
results from the drawback of basing the partitioning upon the macro mesh.
This is currently under investigation and will be reported in a separate article.
In contrast to [21, Fig. 8], where for a diﬀerent adaptation experiment the
mesh adaptation loop yielded non-optimal strong scaling, we conclude from our
investigations that the Distributed NVB scales well and depending on the macro
mesh a ﬁxed or very limited number global communications is needed.

Figure 6.4: Reﬁnement and coarsening of a doughnut like area that rotates
around the center. From left to right the simulation time is increased from
t = 0 to t = 1 by ∆t = 0.25.

15

Figure 6.5: 2d results for the doughnut reﬁnement test on a coarse triangular
macro mesh (left) and a ﬁner triangular macro mesh (right). For diﬀerent
number of cores the graph shows average run time per timestep in seconds for
the diﬀerent parts of the algorithm: a full time step (TS), the adaptation loop
(AD), the load balancing (LB), and the expected optimal scaling (OPT). The
scaling study has been performed on Yellowstone [15]. The test case is part of
the Dune-ALUGrid code and described in [1].

Figure 6.6: 3d results for the doughnut reﬁnement test on a coarse tetrahedral
macro mesh (left) and a ﬁner tetrahedral macro mesh (right). For diﬀerent
number of cores the graph shows average run time per timestep in seconds for
the diﬀerent parts of the algorithm: a full time step (TS), the adaptation loop
(AD), the load balancing (LB), and the expected optimal scaling (OPT). The
scaling study has been performed on Yellowstone [15]. The test case is part of
the Dune-ALUGrid code and described in [1].

7 Summary

We have shown (and proven in 2d), that the number of iterations in Algorithm
3.1 to reach a conforming situation is bounded. In particular for grid imple-
mentations that do not partition the mesh on the leaf level, but on a certain
ﬁxed level, the bound is constant and independent of the current reﬁnement
situation. As the purpose of conforming grids is usually solving elliptic equa-
tions, the total run time is usually dominated by solving the equation. The
performed worst-case experiments are reﬂected by the theory. These experi-
ments also prove that the compatibility condition in Assumption 2.2 is essential
and cannot be neglected. In addition, we presented a state of the art implemen-
tation of the Distributed NVB including asynchronous communication which is

16

 0.01 0.13264128256512#coresmacro triangles: 8192OPTTSADLB 0.01 0.1 1326412825651210242048#coresmacro triangles: 131072OPTTSADLB 0.01 0.1 13264128256512102420484096run time#coresmacro tetrahedron: 48000OPTTSADLB 0.1 1 10641282565121024204840968192run time#coresmacro tetrahedron: 196608OPTTSADLBneeded to achieve excellent scaling on a petascale super computer.
As a next step we will improve the ﬂexibility of the load balancing algorithm
which currently only allows to partition the macro mesh. For certain prob-
lems where singularities might arise, this might not be suﬃcient and yield poor
scalability.

Acknowledgements

Martin Alk¨amper acknowledges the Cluster of Excellence in Simulation Tech-
nology (SimTech) at the University of Stuttgart for ﬁnancial support.
Robert Kl¨ofkorn acknowledges NCAR/CISL’s Research and Supercomputing
Visitor Program (RSVP) and the Research Council of Norway and the industry
partners – ConocoPhillips Skandinavia AS, BP Norge AS, Det Norske Oljesel-
skap AS, Eni Norge AS, Maersk Oil Norway AS, DONG Energy A/S, Denmark,
Statoil Petroleum AS, ENGIE E&P NORGE AS, Lundin Norway AS, Hallibur-
ton AS, Schlumberger Norge AS, Wintershall Norge AS – of The National IOR
Centre of Norway for ﬁnancial support.

References

[1] Alk¨amper, M., Dedner, A., Kl¨ofkorn, R., and Nolte, M. The
DUNE-ALUGrid Module. Archive of Numerical Software 4, 1 (2016), 1–
28.

[2] B¨ansch, E. Local mesh reﬁnement in 2 and 3 dimensions. IMPACT of

Computing in Science and Engineering 3, 3 (1991), 181 – 191.

[3] Bastian, P., Blatt, M., Dedner, A., Engwer, C., Kl¨ofkorn, R.,
Kornhuber, R., Ohlberger, M., and Sander, O. A Generic Grid
Interface for Parallel and Adaptive Scientiﬁc Computing. Part II: Imple-
mentation and Tests in DUNE. Computing 82, 2–3 (2008), 121–138.

[4] Bastian, P., Blatt, M., Dedner, A., Engwer, C., Kl¨ofkorn, R.,
Ohlberger, M., and Sander, O. A Generic Grid Interface for Parallel
and Adaptive Scientiﬁc Computing. Part I: Abstract Framework. Comput-
ing 82, 2–3 (2008), 103–119.

[5] Binev, P., Dahmen, W., and DeVore, R. Adaptive Finite Element
Methods with convergence rates. Numerische Mathematik 97, 2 (2004),
219–268.

[6] Boman, E. G., Catalyurek, U. V., Chevalier, C., and Devine,
K. D. The Zoltan and Isorropia parallel toolkits for combinatorial scientiﬁc
computing: Partitioning, ordering, and coloring. Scientiﬁc Programming
20, 2 (2012).

[7] Bonito, A., and Nochetto, R. H. Quasi-optimal convergence rate of
an adaptive discontinuous Galerkin method. SIAM J. Numer. Anal. 48, 2
(2010), 734–771.

17

[8] Gaspoz, F. D., Heine, C.-J., and Siebert, K. G. Optimal grading
of the newest vertex bisection and H 1-stability of the L2-projection. IMA
Journal of Numerical Analysis (2015).

[9] Jansson, N., Hoffman, J., and Jansson, J. Framework for massively
parallel adaptive ﬁnite element computational ﬂuid dynamics on tetrahe-
dral meshes. SIAM J. Sci. Comput. 34, 1 (Feb. 2012), 24–41.

[10] Karkulik, M., Pavlicek, D., and Praetorius, D. On 2D Newest
Vertex Bisection: Optimality of Mesh-Closure and H 1-Stability of L2-
Projection. Constructive Approximation 38, 2 (2013), 213–234.

[11] Liu, Q., Mo, Z., and Zhang, L. A parallel adaptive ﬁnite-element pack-
age based on ALBERTA. International Journal of Computer Mathematics
85, 12 (2008), 1793–1805.

[12] Maubach, J. Local Bisection Reﬁnement for N-Simplicial Grids Generated
by Reﬂection. SIAM Journal on Scientiﬁc Computing 16, 1 (1995), 210–
227.

[13] Mitchell, W. F. Uniﬁed multilevel adaptive ﬁnite element methods for

elliptic problems. Phd thesis, University of Illinois, Urbana, IL,, 1988.

[14] Mitchell, W. F. A comparison of adaptive reﬁnement techniques for

elliptic problems. ACM Trans. Math. Softw. 15, 4 (1989), 326–347.

[15] NCAR/CISL. Computational and Information Systems Laboratory. Yel-
lowstone: IBM iDataPlex System (Climate Sim ulation Laboratory). Boul-
der, CO: National Center for Atmospheric Research, 2012.

[16] Rivara, M.-C. Mesh Reﬁnement Processes Based on the Generalized
Bisection of Simplices. SIAM Journal on Numerical Analysis 21, 3 (1984),
604–613.

[17] Rivara, M.-C., Calderon, C., Fedorov, A., and Chrisochoides, N.
Parallel decoupled terminal-edge bisection method for 3D mesh generation.
Engineering with Computers 22, 2 (2006), 111–119.

[18] Sewell, E. Automatic Generation of Triangulations for Piecewise Poly-

nomial Approximation. Phd thesis, Purdue University, 1972.

[19] Stevenson, R. The completion of locally reﬁned simplicial partitions

created by bisection. Math. Comput. 77, 261 (2008), 227–241.

[20] Traxler, C. An algorithm for adaptive mesh reﬁnement in n dimensions.

Computing 59, 2 (1997), 115–137.

[21] Witkowski, T., Ling, S., Praetorius, S., and Voigt, A. Software
concepts and numerical algorithms for a scalable adaptive parallel ﬁnite
element method. Advances in Computational Mathematics (2015), 1–33.

18

