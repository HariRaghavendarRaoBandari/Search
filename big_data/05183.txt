6
1
0
2

 
r
a

 

M
6
1

 
 
]

C
C
.
s
c
[
 
 

1
v
3
8
1
5
0

.

3
0
6
1
:
v
i
X
r
a

On the eﬀect of randomness on planted 3-coloring

models

Roee David∗

Uriel Feige†

March 17, 2016

Abstract

We present the hosted coloring framework for studying algorithmic and hardness
results for the k-coloring problem. There is a class H of host graphs. One selects a
graph H ∈ H and plants in it a balanced k-coloring (by partitioning the vertex set
into k roughly equal parts, and removing all edges within each part). The resulting
graph G is given as input to a polynomial time algorithm that needs to k-color G
(any legal k-coloring would do – the algorithm is not required to recover the planted
k-coloring). Earlier planted models correspond to the case that H is the class of all
n-vertex d-regular graphs, a member H ∈ H is chosen at random, and then a balanced
k-coloring is planted at random. Blum and Spencer [1995] designed algorithms for this
model when d = nδ (for 0 < δ ≤ 1), and Alon and Kahale [1997] managed to do so
even when d is a suﬃciently large constant.

The new aspect in our framework is that it need not involve randomness. In one
model within the framework (with k = 3) H is a d regular spectral expander (meaning
that except for the largest eigenvalue of its adjacency matrix, every other eigenvalue
has absolute value much smaller than d) chosen by an adversary, and the planted 3-
coloring is random. We show that the 3-coloring algorithm of Alon and Kahale [1997]
can be modiﬁed to apply to this case. In another model H is a random d-regular graph
but the planted balanced 3-coloring is chosen by an adversary, after seeing H. We show
n, ﬁnding a 3-coloring
that for a certain range of average degrees somewhat below
is NP-hard. Together these results (and other results that we have) help clarify which
aspects of randomness in the planted coloring model are the key to successful 3-coloring
algorithms.

√

76100, Israel. E-mail: roee.david@weizmann.ac.il.

∗Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot
†Department of Computer Science and Applied Mathematics, Weizmann Institute of Science, Rehovot

76100, Israel. E-mail: uriel.feige@weizmann.ac.il.

1

Introduction

1
A k-coloring of a graph G(V, E) is an assignment χ : V −→ [k] of colors to vertices such
that for every edge (u, v) ∈ E one has χ(u) (cid:54)= χ(v). The problem of deciding whether a
given graph is k-colorable is NP-hard for every k ≥ 3 [24, 19]. Moreover, even the most
sophisticated coloring algorithms known require (on worst case instances) |V |δ colors (for
some δ (cid:39) 0.2) in order to properly color a 3-colorable graph [25].

An approach for coping with NP-hardness is by restricting the class of input instances in
a way that either excludes the most diﬃcult instances, or makes them unlikely to appear (in
models in which there is a probability distribution over inputs). Along this line, a model that
is very relevant to our current work is the so called random planted coloring model Gn,k,p
in which the vertex set (of cardinality n) is partitioned at random into k parts, and edges
between vertices in diﬀerent parts are placed independently with probability p. Such graphs
are necessarily k-colorable. Following initial work by Blum and Spencer [7], it was shown
by Alon and Kahale [2] that for every k there is a polynomial time algorithm that with high
probability k-colors such input graphs (the probability is taken over random choice of input
graphs) provided that p > ck

, where ck is some constant that depends only on k.

In the current work we propose a framework that contains several diﬀerent models for
generating instances of k-colorable graphs. We call this framework the hosted coloring
framework. The random planted coloring model is one of the models that is contained in
the hosted coloring framework. We consider several other planted coloring models within our
framework, and obtain both new algorithmic results and new hardness results. In particular,
our results help clarify the role that randomness plays in the random planted model.

n

1.1 The hosted coloring framework
We describe our framework for generating instances with planted solutions. In the current
manuscript, the framework is described only in the special case of the k-coloring problem,
though it is not diﬃcult to extend it to other NP-hard problems.

The hosted coloring framework is a framework for generating k-colorable graphs. We
alert the reader that graphs within this framework are labeled, meaning that every n-vertex
graph is given together with a naming of its vertices from 1 to n. A model within this
framework involves two components:

1. A class H of host graphs. Let Hn denote the set of graphs in H that have n vertices.
2. A class P of planted solutions. Formally, in the context of k-coloring, a planted solution
can be thought of as a complete k-partite graph. Let Pn denote the set of planted
solutions in P that have n vertices.

To generate a k-colorable graph with n vertices, one selects one graph H from Hn, and
plants in it one solution P from Pn. Formally, the planting can be described as generating
the graph G(V, E) whose edge set is the intersection of the edge sets of the host graph H
and of the complete k-partite graph P . Namely, the vertex set of G(V, E) is V = [n], and
(u, v) ∈ E iﬀ both (u, v) ∈ E(H) and (u, v) ∈ E(P ).
To complete the description of the hosted framework, we explain how the host graph
H ∈ Hn is selected, and how the planted solution P ∈ Pn is selected. Here, the framework
allows for four selection rules:

2

1. Adversarial/adversarial. An adversary selects H ∈ Hn and P ∈ Pn.
2. Random/random. The class of host graphs is equipped with a probability distribu-
tion (typically simply the uniform distribution) and likewise for the class of planted
solutions. The selections of host graph and planted solution are done independently
at random, each according to its own distribution. We use the notation H ∈R Hn and
P ∈R Pn to describe such selections.

3. Adversarial/random. An adversary ﬁrst selects H ∈ Hn, and then P ∈R Pn is selected

at random.

4. Random/adversarial. A host graph H ∈R Hn is selected at random, and then an

adversary, upon seeing H, selects P ∈ Pn.

The hosted k-coloring framework allows for many diﬀerent planted k-coloring models, de-
pending on the choice of H, P and the selection rule. The random planted Gn,k,p model can
be described within the hosted k-coloring framework by taking Hn to be the class of all n-
vertex graphs equipped with the Erdos-Renyi probability distribution Gn,p, taking Pn to be
the class of all n-vertex complete k-partite graphs equipped with the uniform distribution,
and using the random/random selection rule.

One of the goals of our work is to remove randomness from planted models. The hosted
k-coloring framework allows us to do this. Moreover, one can control separately diﬀerent
aspects of randomness. Let us explain how this is done in our work.

√

Regular expanders as host graphs. Randomness is eliminated from the choice of
host graph by allowing the adversary to select an arbitrary host graph from the class of
d-regular λ-expanders, for given d (that may be a function of n) and λ (which is a function
of d). The term λ-expander refers to the spectral manifestation of graph expansion. Namely,
let λ1 ≥ . . . ≥ λn denote the eigenvalues of the adjacency matrix of an n node graph G, and
let λ = max[λ2,|λn|]. As is well known, a d-regular graph has λ1 = d and λ ≥ Ω(
d) [33].
A d-regular graph is referred to as a spectral expander if λ is signiﬁcantly smaller than d –
the smaller λ is the better the guaranteed expansion properties are [20].

Random d-regular graphs are essentially the best possible spectral expanders, satisfying
d) almost surely [15, 18, 17]. The same holds for random graphs in the Gn,p
λ = O(
model, taking d to be the average degree (roughly pn). We remark that our results extend
to graphs that are approximately d-regular (e.g., with degree distribution similar to Gn,p),
and regularity is postulated only so as to keep the presentation simple.

Balanced coloring. Randomness is eliminated from the choice of planted coloring
(the choice of P ) by allowing the adversary, after seeing H, to plant an arbitrary balanced
.
k-coloring, namely, to select an arbitrary k-partite graph in which all parts are of size n
k
(Also here, our results extend to having part sizes of roughly n
rather than exactly, and
k
exact balance is postulated only for simplicity.) Observe that a random k-partition is nearly
balanced almost surely.

√

1.2 Main results
For simplicity we focus here on the special case of k = 3, namely, 3-coloring. Extensions of
our results to k > 3 are discussed in Section E. In our main set of results, we shall consider
four related planted models, all within the hosted k-coloring framework.

3

The four models will have selection rules referred to as HA/PA, HA/PR, HR/PA, and
HR/PR, where H and P refer to host graph and planted coloring respectively, and A and
R stand for adversarial and random respectively.

• HA means that the adversary chooses an arbitrary d-regular λ-expander (for an ap-
propriate choice of d and λ) host graph – we refer to this as an adversarial expander;
• HR means that the host graph is chosen as a random Erdos-Renyi random graph Gn,p

(for an appropriate choice of p) – we refer to this as a random host graph.

• PR refers to a random planted coloring (complete tripartite graph) chosen uniformly

at random – we refer to this is random planting;

• PA refers to a balanced planted coloring chosen adversarially (after the adversary sees

H) – we refer to this is adversarial planting.

In all cases, n denotes the number of vertices in the graph, and d denotes the average
degree of the host graph (where d (cid:39) pn for random host graphs). We shall say that two
colorings of the same set of vertices are identical if the partitions that the color classes induce
on the vertices are the same (the actual names of colors are irrelevant).

In presenting our results it will be instructive to consider the following notions of coloring:

• The planted 3-coloring P .
• A legal 3-coloring (but not necessarily the planted one).

• For a given b < n, a b-approximated coloring is a 3-coloring that is not necessarily

legal, but it is identical to the planted 3-coloring on a set of at least n − b vertices.

• For a given b < n, a b-partial coloring is a 3-coloring of n − b vertices from the graph
that is identical to the planted coloring on these vertices. The remaining b vertices are
left uncolored and are referred to as free.

Our ﬁrst theorem oﬀers a unifying theme for all four models. For the HR/PR model a similar
theorem was known [2]. (Recall that λ, the second largest in absolute value eigenvalue, is a
√
measure of expansion and satisﬁes λ = Θ(
Theorem 1.1. For a suﬃciently large constant c, let the average degree in the host graph
satisfy c < d < n. Then in all four models (HA/PA, HA/PR, HR/PA, HR/PR) there
n). For the
models with random host graphs (HR) and/or random planted colorings (PR), the algorithm
succeeds with high probability over choice of random host graph H and/or random planted
coloring P .

is a polynomial time algorithm that ﬁnds a b-partial coloring for b = O((cid:0) λ

d) for random graphs.)

(cid:1)2

d

Given that Theorem 1.1 obtains a b-partial coloring, the task that remains is to 3-color
the set of b free vertices, in a way that is both internally consistent (for edges between free
vertices) and externally consistent (for edges with only one endpoint free). From [2] it is
known that this task can be completed in the HR/PR model. Here are our main results for
the other planted models. In all cases, d is the average degree of the host graph.

4

√

d).

Theorem 1.2. In the HA/PA model, for every d in the range C < d < n1− (where C is
a suﬃciently large constant and  > 0 is arbitrarily small), it is NP-hard to 3-color a graph
with a planted 3-coloring, even when λ = O(
Theorem 1.3. In the HA/PR model, for some constants 0 < c < 1 and C > 1 there
is a polynomial time algorithm with the following properties. For every d in the range
C < d ≤ n − 1 and every λ ≤ cd, for every host graph within the model, the algorithm with
high probability (over the choice of random planted coloring) ﬁnds a legal 3-coloring.
Theorem 1.4. In the HR/PA model:
a There is a polynomial time algorithm that with high probability (over the choice of host
graph) ﬁnds a legal 3-coloring whenever d ≥ Cn2/3 (for a suﬃciently large constant
C).

b There is a constant 1

3 < δ0 < 1

, no polynomial time algorithm
has constant probability (over the random choice of host graph of average degree nδ, for
adversarially planted coloring) to produce a legal 3-coloring, unless NP has expected
polynomial time algorithms.

such that for δ0 < δ < 1

2

2

Let us brieﬂy summarize our main ﬁndings as to the role of randomness in planted 3-
coloring models. For partial coloring, randomness in the model can be replaced by degree
and expansion requirements for the host graph, and balance requirements for the planted
coloring (see Theorem 1.1). For ﬁnding a legal (complete) 3-coloring, randomness of the
planted coloring is the key issue, in which case it suﬃces that the host graph is an arbitrary
spectral expander, and in fact, quite a weak one (λ can even be linear in d – see Theorem 1.3).
If the planted 3-coloring is not random, then spectral expansion does not suﬃce (not even
√
d) – see Theorem 1.2), and moreover, even randomness of the host graph does not
λ = O(
suﬃce (for some range of degrees – see Theorem 1.4b). Finally, comparing Theorem 1.4a to
Theorem 1.2 shows that spectral expansion cannot always replace randomness of the host
graph.

1.3 Related work
There is a vast body of work on models with planted solutions, and here we shall survey
only a sample of it that suﬃces in order to understand the context for our results.

In our framework we ask for algorithms that k-color a graph that has a planted k-coloring,
and allow the algorithm to return any legal k-coloring, not necessarily the planted one. We
refer to this as the optimization version. The optimization version regards planted models
as a framework for studying possibly tractable instances for otherwise NP-hard problems.
In certain other contexts (signal processing, statistical inference) the goal in planted models
is to recover the planted object, either exactly, or approximately. We refer to this as the
recovery version. It is often motivated by practical needs (e.g., to recover a a true signal from
a noisy version, to cluster noisy data, etc.). Our Theorem 1.1 addresses the approximate
recovery question, but for many of our models and settings of parameters, exact recovery
of the planted k-coloring is information theoretically impossible (one reason being that the
input graph might have multiple legal k-coloring with no indication which is the planted
one). In general, optimization becomes more diﬃcult when exact recovery is impossible, but

5

still in many of our models we manage to exactly solve the optimization problem (e.g., in
Theorem 1.3). In the context of random planted k-coloring, the k-coloring algorithms of [7]
could work only in the regime in which exact recovery is possible, whereas the algorithms
of [2] work also in regimes where exact recovery is not possible.

There are planted models and corresponding algorithms for many other optimization
problems, including graph bisection [8], 3-SAT [16], general graph partitioning [32], and
others. A common algorithmic theme used in many of this works is that (depending on
the parameters) exact or approximate solutions can be found using spectral techniques.
The reason why the class of host graphs that we consider is that of spectral expanders is
precisely because we can hope that spectral techniques will be applicable in this case. Indeed,
the ﬁrst step of our algorithm (in the proof of Theorem 1.1) employs spectral techniques.
Nevertheless, its proof diﬀers from previous proofs in some of its parts, because it uses only
weak assumptions on the planted model (there is no randomness involved, the host graph
is an arbitrary spectral expander, and moreover not necessarily a very good one, and the
k-coloring is planted in a worst case manner in the host graph).

Our hosted coloring framework allows the input to be generated in a way that is partly
random and partly adversarial. Such models are often referred to as semi-random models [7,
14]. Among the motivations to semi-random models one can mention attempts to capture
real life instances better than purely random models (smoothed analysis [34] is a prominent
example of this line of reasoning, but there are also other recent attempts such as [29]
and [30]), and attempts to understand better how worst case input instances to a problem
may look like (e.g., see the semirandom models for unique games in [26], which consider
four diﬀerent aspects of an input instance, and study all combinations in which three of
these aspects are adversarial and only one is random). Another attractive aspect of semi-
random models is the possibility of matching algorithmic results by NP-hardness results,
which become possible (in principle) due to the presence of an adversary (there are no
known NP-hardness results in purely random planted models). NP-hardness results for
certain semi-random models of k-coloring (in which an adversary is allowed to add arbitrary
edges between color classes in a random planted Gn,k,p graph) have been shown in [14],
thus explaining why the algorithmic results that were obtained there for certain values of
p cannot be pushed to considerably lower values of p. Typically these NP-hardness results
are relatively easy to prove, due to a strong adversarial component in the planted model.
In contrast, our NP-hardness result in Theorem 1.4b is proved in a context in which the
adversary seems to have relatively little power (has no control whatsoever over the host
graph and can only choose the planted coloring). Its proof appears to be diﬀerent from any
previous NP-hardness proof that we are aware of.

In [5] an algorithm that outputs an Ω(n) size independent set for d-regular 3-colorable
graphs is designed. The running time of the algorithm is nO(D), where D is the threshold
rank of the input graph (namely, the adjacency matrix of the input graph has at most D
eigenvalues more negative than −t, where t = Ω(d)). Graphs generated in our HA/PR
model are nearly regular and have low threshold rank. Graphs generated in our HA/PA
model might have vertices of degree much lower than the average degree, but they have
large subgraphs of low threshold rank in which all degrees are within constant multiplicative
factors of each other (and presumably the algorithms of [5] can be adapted to such graphs).
The hardness results presented in the current paper do not directly give regular graphs,
but one can modify the hardness results for k-coloring in the HA/PA model (speciﬁcally,

6

Theorem E.2, for k > 3) to obtain hardness of k-coloring regular graphs of low threshold
rank.

Let us end this survey with two unpublished works (available online) that are related to
the line of research presented in the current paper. A certain model for planted 3SAT was
studied in [4]. It turns out that in that model a b-partial solution (even for a very small
value of b) can be found eﬃciently, but it is not known whether a satisfying assignment can
be found. As that model is purely random, it is unlikely that one can prove that ﬁnding
a satisfying assignment is NP-hard. In [11] a particular model within the hosted coloring
framework was introduced. In that model the class of host graphs is that of so called anti-
geometric graphs, and both the choice of host graph and planted coloring are random. The
motivation for choosing the class of anti-geometric graphs as host graphs is that these are
the graphs on which [13] showed integrality gaps for the semi-deﬁnite program of [23]. Hence
spectral algorithms appear to be helpless in these planted model settings. Algorithms for
3-coloring were presented in [11] for this class of planted models when the average degree is
suﬃciently large (above n0.29), and it is an interesting open question whether this can be
pushed down to lower degrees. If so, this may give 3-coloring algorithms that do well on
instances on which semideﬁnite programming seems helpless.

2 Overview of proofs
In this section we explain the main ideas in the proof. The full proofs, which often include
additional technical content beyond the ideas overviewed in this section, appear in the
appendix.

2.1 An algorithm for partial colorings
Here we explain how Theorem 1.1 (an algorithm for partial coloring) is proved. Our algo-
rithm can be thought of as having the following steps, which mimic the steps in the algorithm
of Alon and Kahale [2] who addressed the HR/PR model.

1. Spectral clustering. Given an input graph G, compute the eigenvectors corresponding
to the two most negative eigenvalues of the adjacency matrix of G. The outcome
can be thought of as describing an embedding of the vertices of G in the plane (the
coordinates of each vertex are its corresponding entries in the eigenvectors). Based
on this embedding, use a distance based clustering algorithm to partition the vertices
into three classes. These classes form the (not necessarily legal) coloring χ1.

2. Iterative recoloring. Given some (illegal) coloring, a local improvement step moves
a vertex v from its current color class to a class where v has fewer neighbors, thus
reducing the number of illegally colored edges. Perform local improvement steps (in
parallel) until no longer possible. At this point one has a new (not necessarily legal)
coloring χ2.

3. Cautious uncoloring. Uncolor some of the vertices, making them free. Speciﬁcally,
using an iterative procedure, every suspect vertex is uncolored, where a vertex v is
colored neighbors, or there is a color
suspect if it either has signiﬁcantly less than 2d
3

7

class other than χ2(v) with fewer than d
is referred to as χ3.

6

neighbors of v. The resulting partial coloring

The analysis of the three steps of the algorithm is based on that of [2], but with modiﬁcations
due to the need to address adversarial settings. Consequently, the values that we obtain for
the parameter b after the iterative recoloring and cautious uncoloring steps are weaker than
the corresponding bounds in [2].
Lemma 2.1. The coloring χ1 is a b-approximated coloring for b ≤ O( λ

d n).

For the proof of Lemma 2.1, the underlying idea is that d-regular λ-expander graphs do
not have any eigenvalues more negative than −λ. On the other hand, planting a 3-coloring
can be shown to create exactly two eigenvalues of value roughly − d
. This is quite easy
to show in the random planting model such as the one used in [2] because the resulting
-regular. We show that this also holds in the adversarial planted model.
graph is nearly 2d
3
3 > λ, it makes sense (though of course it needs a proof) that the eigenvalues
Thereafter, if d
corresponding to the two most negative eigenvalues contain some information about the
planted coloring. An appropriate choice of clustering algorithm can be used to extract this
information. We remark that our choice of clustering algorithm diﬀers from and is more
eﬃcient than that of [2], a fact that is of little importance in the context of planted 3-coloring,
but does oﬀer signiﬁcant advantages for planted k-coloring when k is large.
Lemma 2.2. The coloring χ2 is a b-approximated coloring for b ≤ O( λ2
d2 n).

3

In [2] a statement similar to Lemma 2.2 was proved using probabilistic arguments (their
setting is equivalent to HR/PR). Our setting (speciﬁcally, that of HA/PA) involves no
randomness. We replace the proof of [2] by a proof that uses only deterministic arguments.
Speciﬁcally, we use the well known expander mixing lemma [1].
Lemma 2.3. The partial coloring χ3 is a b-partial coloring for b ≤ O( λ2

d2 n).

For the proof of Lemma 2.3, the deﬁnition of suspect vertex strikes the right balance
between two conﬂicting requirements. One is ensuring that no colored vertex remaining is
wrongly colored. The other is that most of the graph should remain remain colored. In [2]
a statement similar to Lemma 2.2 was proved using probabilistic arguments, whereas our
proof uses only deterministic arguments.

The full proof of Theorem 1.1 appears in Section C.1.

2.2 Adversarial expanders with adversarial planting
Here we sketch how Theorem 1.2 is proved, when the average degree of the host graph is
d = nδ for some 0 < δ < 1. Suppose (for the sake of contradiction) that there is a polynomial
time 3-coloring algorithm ALG for the planted HA/PA model. We show how ALG could be
used to solve NP-hard problems, thus implying P=NP.
Let Q be a class of sparse graphs on which the problem of 3-coloring is NP-hard. For
concreteness, we can take Q to be the class of 4-regular graphs. For simplicity, assume
further that if a graph in Q is 3-colorable, all color classes are of the same size. (This can
easily be enforced, e.g., by making three copies of the graph.)

8

4d

Given a graph Q ∈ Q on n1 (cid:39) n1−δ < n

vertices for which one wishes to determine
3-colorability, do the following. Construct an arbitrary spectral expander Z on n2 = n − n1
vertices, in which n1(d − 4) vertices (called connectors) have degree d − 1 and the rest of
the vertices have degree d. Plant an arbitrary balanced 3-coloring in Z (each color class has
a third of the connector vertices and a third of the other vertices), obtaining a graph that
we call Z3. Now give the graph G that is a disjoint union of Q and Z3 as input to ALG. If
ALG ﬁnds a 3-coloring in G declare Q to be 3-colorable, and else declare Q as not having a
3-coloring.

Let us now prove correctness of the above procedure. If Q is not 3-colorable, then clearly
ALG cannot 3-color G. It remains to show that if Q is 3-colorable, then we can trust ALG to
ﬁnd a 3-coloring of G. Namely, we need to show the existence of an expander host graph H
and a planted 3-coloring in H that after the removal of the monochromatic edges produces
exactly the graph G. An adversary with unlimited computation power can derive H from
Q and Z as follows. It ﬁnds a balanced 3-coloring χ in Q. Then it connects each vertex v
of Q to d − 4 distinct connector vertices that have exactly the same color as v (under Z3).
This gives the graph H which is d-regular, and for which planting the 3-coloring χ on its Q
part and Z3 on its Z part gives the graph G. It only remains to prove that H is a spectral
expander, but this is not diﬃcult.

The full proof of Theorem 1.2 appears in Section C.2.

2.3 Adversarial expanders with random planting
Here we sketch the proof of Theorem 1.3 (concerning HA/PR). It would be instructive to
ﬁrst recall how [2] completed the 3-coloring algorithm in the HR/PR case. First, in this case
Theorem 1.1 can be considerably strengthened, showing that one gets a b-partial coloring
exponentially small in d. Hence when d >> log n this by itself recovers the planted
with b
n
3-coloring. The diﬃcult case that remains is when d is sublogarithmic (e.g., d is some large
constant independent of n). In this case it is shown in [2] that the subgraph induced on
the free vertices decomposes into connected components each of which is smaller than log n.
Then each component by itself can be 3-colored in polynomial time by exhaustive search,
ﬁnding a legal 3-coloring (not necessarily the planted one) for the whole graph.

In the HA/PR model it is still true that Theorem 1.1 can be strengthened to show that
one gets a b-partial coloring with b
exponentially small in d. However, we do not know if it is
true that the subgraph induced on the free vertices decomposes into connected components
smaller than log n. To overcome this, we add another step to the algorithm (which is not
required in the [2] setting), which we refer to as safe recoloring. In this step, iteratively,
if an uncolored vertex v has neighbors colored by two diﬀerent colors, then v is colored by
the remaining color. Clearly, if one starts with a b-partial coloring, meaning that all colored
vertices agree with the planted coloring, this property is maintained by safe recoloring.
We prove that with high probability (over choice of random planting), after the recoloring
stage the remaining free vertices break up into connected components of size O
d2 log n
Thereafter, a legal 3-coloring can be obtained in polynomial time using exhaustive search.

(cid:16) λ2

(cid:17).

The full proof of Theorem 1.3 appears in Section B.2.

n

9

2.4 Algorithm for random graphs with adversarial planting
Here we sketch the proof of Theorem 1.4a (concerning an algorithm for HR/PA). Given the
negative result for HA/PA, our algorithm must use a property that holds for random host
graphs but need not hold for expander graphs. The property that we use is that when the
degree d is very large, the number of common neighbors of every two vertices is larger than
d ). For random graphs this holds (w.h.p.) whenever d ≥ Cn2/3 for a suﬃciently large
O( n
constant C, but for expander graphs this property need not hold. Recall that b ≤ O( n
√
d )
in the b-partial coloring from Theorem 1.1 (because λ = O(
d)). Hence the pigeon-hole
principle implies that every two free vertices u and v had at least one common neighbor w
(common neighbor in the host graph H) that is not free, namely, it is colored. Hence if in the
input graph G neither of them have a colored neighbor in the b-partial coloring, it must be
that both of them lost their edge to w because of the planted coloring, meaning that u and
v have the same color in the planted coloring. Consequently, the set F0 of all free vertices
with no colored neighbor must be monochromatic in the planted coloring. This leads to the
following algorithm for legally 3-coloring the free vertices. Guess the color that should be
given to the set F0. There are only three possibilities for this. Each of the remaining free
vertices has at least one colored neighbor, and hence at most two possible colors. Hence we
are left with a list-coloring problem with at most two colors per list. This problem can be
solved in polynomial time by reduction to 2SAT.

The full proof of Theorem 1.4a appears in Section D.1.

2.5 Hardness for random graphs with adversarial planting
Here we sketch the proof of Theorem 1.4b (hardness for HR/PA). The proof plan is similar
to that of the proof of Theorem 1.2 (hardness for HA/PA, see Section 2.2), but making this
plan work is considerably more diﬃcult.

Let us start with the proof plan. Suppose (for the sake of contradiction) that there is a
polynomial time 3-coloring algorithm ALG for the planted HR/PA model with host graphs
coming from Gn,p, and hence of average degree d (cid:39) pn. We show how ALG could be used
to solve NP-hard problems, thus implying P=NP.
Let Q be a (carefully chosen, a point that we will return to later) class of sparse graphs
on which the problem of 3-coloring is NP-hard. As in the proof of Theorem 1.2, we may
assume that if a graph in Q is 3-colorable, all color classes are of the same size.
Given a graph Q ∈ Q on n1 = n vertices (for some small  > 0 to be determined later)
for which one wishes to determine 3-colorability, do the following. Construct a random
graph Z on n2 = n− n vertices, distributed like Gn2,p. Plant a random balanced 3-coloring
in Z, obtaining a graph that we call Z3. Now give the graph G that is a disjoint union of
Q and Z3 as input to ALG. If ALG ﬁnds a 3-coloring declare Q to be 3-colorable, and else
declare Q as not having a 3-coloring.

If Q is not 3-colorable, then clearly ALG cannot 3-color G. What we need to prove is
that if Q is 3-colorable, then ALG will indeed ﬁnd a 3-coloring of G. For this we need to
show that the distribution over graphs G constructed in the above manner (we speak of
distributions because Z is a random) is the same (up to some small statistical distance) as
a distribution that can be generated by an adversary in the HR/PA model (otherwise we
do not know what ALG would answer given G). The diﬃculty is that the adversary does
not control the host graph (which is random) and its only power is in choosing the planted

10

coloring. But still, given a random Gn,p host graph H, we propose the following three step
procedure for the (exponential time) adversary.

1. If Q is not a vertex induced subgraph of H then fail, and plant a random 3-coloring

in H.

2. Else, pick a random vertex-induced copy of Q in H (note that H could contain more
than one copy of Q). Let Z(cid:48) denote the graph induced on the remaining part of H. Let
χ be a balanced 3-coloring of Q. If there are two vertices u, v ∈ Q with χ(u) (cid:54)= χ(v)
which have a common neighbor w ∈ Z(cid:48), then fail, and plant a random 3-coloring in
H.

3. Else, extend χ to a balanced planted 3-coloring on the whole of H, while taking care
that if a vertex w ∈ Z(cid:48) has a neighbor v ∈ Q, then χ(w) = χ(v). After dropping
the monochromatic edges, one gets a graph G(cid:48) composed of two components: Q, and
another component that we call Z(cid:48)

.

3

3

has a distribution similar to Z3).

What needs to be shown is that the probability (over choice of H ∈R Gn,p) of failing in
either step 1 or 2 is small, and that conditioned on not failing, G(cid:48) has a distribution similar
to that of G (equivalently, Z(cid:48)
For the ﬁrst step not to fail, one needs graphs Q ∈ Q to occur in a random Gn,p graph
by chance rather than by design. This requires average degree d > n1/3, as shown by the
following proposition (the proof can be found in Section D.4).
Proposition 2.4. Let Q be an arbitrary class of graphs. Then either there is a polynomial
time algorithm for solving 3-colorability on every graph in Q, or Q contains graphs that are
unlikely to appear as subgraphs of a random graph from Gn,p, if p ≤ n− 2
3 (namely, if the
average degree is d ≤ n 1

3 ).

Moreover, it is not hard to show that if the average degree is too large, namely, d > n 1
2 ,
the second step is likely to fail (there are likely to be pairs of vertices in Q that have common
neighbors in Z(cid:48)). Hence we restrict attention to average degrees satisfying n 1
2−.
Consequently, the class of 4-regular graphs cannot serve as the NP-hard class Q (in contrast
to the proof of Theorem 1.2), because any particular 4-regular graph is expected not to be a
subgraph of a random graph of average degree below √
n. Given the above, we choose Q to
be the class of balanced graphs of average degree 3.75. (The choice of 3.75 is for convenience.
With extra work in the proof of Lemma 2.6, one can replace 3.75 by any constant larger
than 10/3 and consequently decrease the value of δ0 in Lemma 2.7 to any constant above
2/5.)
Deﬁnition 2.5. A graph Q is balanced if no subgraph of Q has average degree larger than
the average degree of Q.

3 < d < n 1

This choice of Q is justiﬁed by the combination of Lemmas 2.6 and 2.7.

Lemma 2.6. The problem of 3-coloring is NP-hard on the class of balanced graphs of average
degree 3.75.
Lemma 2.7. Let Q be an arbitrary balanced graph on n vertices and of average degree 3.75.
Then a random graph of degree d > nδ0 is likely to contain Q as a vertex induced subgraph,
for δ0 = 7+16

.

15

11

62

2− (this interval is nonempty for  < 1

The above implies that if Q is the class of balanced graphs of average degree 3.75 and if
), then the adversary is likely not to
nδ0 < d < n 1
fail in steps 1 and 2. What remains to prove is that the distribution over Z(cid:48)
is statistically
close to the distribution over Z3. (It may seem strange that this is needed, given that Q
is isolated from Z3/Z(cid:48)
is constructed by a procedure that depends on Q
and is not known to run in polynomial time, we need to argue that it does not contain
information that can be used by a 3-coloring algorithm for Q. Being statistically close to
the polynomial time constructible Z3 serves this purpose.) Proving this claim is nontrivial.
Our proof for this claim is partly inspired by work of [22] that showed that the distribution
2 log n is statistically close
of graphs from Gn, 1
to the Gn, 1

in which one plants a random clique of size 3

distribution (with no planting).

. However, as Z(cid:48)

Full proofs for this section appear in Section D.2 (see Theorem D.13).

2

3

3

3

2

2.6 Some open questions
An intriguing question left open by Theorem 1.4b is the following:

Is there a polynomial time 3-coloring algorithm for the HR/PA model at average degrees

signiﬁcantly below n 1
3 ?

We believe that the hosted coloring framework (and similar frameworks for other NP-
hard problems) is a fertile ground for further research. A fundamental question is whether
the choice of host graph matters at all. Speciﬁcally:

Does Theorem 1.3 (existence of 3-coloring algorithms for HA/PR) continue to hold if the

class of host graphs is that of all regular graphs (with no restriction on λ)?

The answer to the above question is positive for host graphs of minimum degree linear
in n (left as exercise to the reader), and it will be very surprising if the answer is positive
in general.

Acknowledgements
Work supported in part by the Israel Science Foundation (grant No. 621/12) and by the
I-CORE Program of the Planning and Budgeting Committee and the Israel Science Foun-
dation (grant No. 4/11).

References
[1] Noga Alon and Fan RK Chung. Explicit construction of linear sized tolerant networks.

Annals of Discrete Mathematics, 38:15–19, 1988. 8, 56

[2] Noga Alon and Nabil Kahale. A spectral technique for coloring random 3-colorable
graphs. SIAM Journal on Computing, 26(6):1733–1748, 1997. 2, 4, 6, 7, 8, 9, 15, 24,
25

[3] Noga Alon and Joel H Spencer. The probabilistic method. John Wiley & Sons, 2004.

39

12

[4] Alina Arbitman.

fraction of 1-clauses.
MSC Thesis, Weizmann Institute, http: // www. wisdom. weizmann. ac. il/ ~feige/
TechnicalReports/ AlinaArbitmanThesis. pdf , 2012. 7

Planted random 3SAT with a small

[5] Sanjeev Arora and Rong Ge. New tools for graph coloring. In Approximation, Ran-
domization, and Combinatorial Optimization. Algorithms and Techniques, pages 1–12.
Springer, 2011. 6

[6] Rajendra Bhatia. Matrix analysis, volume 169. Springer Science & Business Media,

2013. 36

[7] Avrim Blum and Joel Spencer. Coloring random and semi-random k-colorable graphs.

Journal of Algorithms, 19(2):204–234, September 1995. 2, 6

[8] Ravi B Boppana. Eigenvalues and graph bisection: An average-case analysis. In Foun-
dations of Computer Science, 1987., 28th Annual Symposium on, pages 280–285. IEEE,
1987. 6

[9] Rowland Leonard Brooks. On colouring the nodes of a network. In Mathematical Pro-
ceedings of the Cambridge Philosophical Society, volume 37, pages 194–197. Cambridge
Univ Press, 1941. 47

[10] Herman Chernoﬀ. A measure of asymptotic eﬃciency for tests of a hypothesis based on
the sum of observations. The Annals of Mathematical Statistics, pages 493–507, 1952.
55

[11] Roee David.

Thesis, Weizmann Institute,
TechnicalReports/ RoeeDavidThesis. pdf , 2013. 7

Finding planted k-coloring in vector k-colorable graphs. MSC
http: // www. wisdom. weizmann. ac. il/ ~feige/

[12] P Erdos and A Renyi. On random graphs i. Publ. Math. Debrecen, 6:290–297, 1959. 37

[13] Feige, Langberg, and Schechtman. Graphs with tiny vector chromatic numbers and

huge chromatic numbers. SICOMP: SIAM Journal on Computing, 33, 2004. 7

[14] Uriel Feige and Joe Kilian. Heuristics for semirandom graph problems. Journal of

Computer and System Sciences, 63(4):639–671, 2001. 6

[15] Uriel Feige and Eran Ofek. Spectral techniques applied to sparse random graphs.

Random Structures & Algorithms, 27(2):251–275, 2005. 3, 37, 52

[16] Abraham Flaxman. A spectral technique for random satisﬁable 3CNF formulas. In
Proceedings of the fourteenth annual ACM-SIAM symposium on Discrete algorithms,
pages 357–363. Society for Industrial and Applied Mathematics, 2003. 6

[17] Joel Friedman, Jeﬀ Kahn, and Endre Szemeredi. On the second eigenvalue of random
regular graphs. In Proceedings of the twenty-ﬁrst annual ACM symposium on Theory
of computing, pages 587–598. ACM, 1989. 3, 37, 52

[18] Zoltán Füredi and János Komlós. The eigenvalues of random symmetric matrices.

Combinatorica, 1(3):233–241, 1981. 3, 37, 52

13

[19] Michael R Garey, David S. Johnson, and Larry Stockmeyer. Some simpliﬁed NP-
complete graph problems. Theoretical computer science, 1(3):237–267, 1976. 2, 35,
41

[20] Shlomo Hoory, Nathan Linial, and Avi Wigderson. Expander graphs and their appli-

cations. Bulletin of the American Mathematical Society, 43(4):439–561, 2006. 3

[21] Roger A Horn and Charles R Johnson. Matrix analysis. Cambridge university press,

2012. 56

[22] Ari Juels and Marcus Peinado. Hiding cliques for cryptographic security. In Des. Codes

Cryptogr, pages 678–684. ACM, 1998. 12, 44

[23] David Karger, Rajeev Motwani, and Madhu Sudan. Approximate graph coloring by

semideﬁnite programming. Journal of the ACM (JACM), 45(2):246–265, 1998. 7

[24] Richard M. Karp. Reducibility among combinatorial problems. In Complexity of Com-

puter Computations, pages 85–103, 1972. 2

[25] Ken-ichi Kawarabayashi and Mikkel Thorup. Coloring 3-colorable graphs with o(n1/5)

colors. pages 458–469, 2014. 2

[26] Alexandra Kolla, Konstantin Makarychev, and Yury Makarychev. How to play unique
games against a semi-random adversary: Study of semi-random models of unique games.
In IEEE 52nd Annual Symposium on Foundations of Computer Science (FOCS), 2011,
pages 443–452. IEEE, 2011. 6

[27] Michael Krivelevich, Daniel Reichman, and Wojciech Samotij. Smoothed analysis on
connected graphs. SIAM Journal on Discrete Mathematics, 29(3):1654–1669, 2015. 31

[28] László Lovász. Three short proofs in graph theory. Journal of Combinatorial Theory,

Series B, 19(3):269–271, 1975. 47

[29] Konstantin Makarychev, Yury Makarychev, and Aravindan Vijayaraghavan. Approxi-
mation algorithms for semi-random partitioning problems. In Proceedings of the forty-
fourth annual ACM symposium on Theory of computing, pages 367–384. ACM, 2012.
6

[30] Konstantin Makarychev, Yury Makarychev, and Aravindan Vijayaraghavan. Constant
In Proceedings of the 46th

factor approximation for balanced cut in the pie model.
Annual ACM Symposium on Theory of Computing, pages 41–49. ACM, 2014. 6

[31] Colin McDiarmid. On the method of bounded diﬀerences. Surveys in combinatorics,

141(1):148–188, 1989. 55

[32] Frank McSherry. Spectral partitioning of random graphs. In Foundations of Computer
Science, 2001. Proceedings. 42nd IEEE Symposium on, pages 529–537. IEEE, 2001. 6

[33] A. Nilli. On the second eigenvalue of a graph. Discrete Mathematics, 91(2):207–210,

1991. 3

14

[34] Daniel A Spielman and Shang-Hua Teng. Smoothed analysis of algorithms: Why
the simplex algorithm usually takes polynomial time. Journal of the ACM (JACM),
51(3):385–463, 2004. 6

[35] Salil P Vadhan. Pseudorandomness. Now, 2012. 56

A Organization of the technical sections
The technical sections are organized in an order somewhat diﬀerent than that of the main
text. Speciﬁcally, we consider the models HA/PR, HA/PA and HR/PA one by one (the
model HR/PR need not be considered because it is handled in [2]). Consequently, diﬀerent
parts of the proof of Theorem 1.1 appear in diﬀerent sections.

Section B contains all proofs for the model with an adversarial expander host graph and
a random planted coloring, namely, HA/PR. It is divided into subsections as follows. Sec-
tion B.1 analyzes the spectrum of an expander graph with a random planted coloring (this
relates to Lemma 2.1 in the HA/PR model). Speciﬁcally, we show a generalization to Propo-
sition 2.1 in [2], see Theorem B.1. Section B.2 presents in a uniﬁed manner the algorithm
that 3-color graphs in the HA/PR model, combining into one algorithm the parts of Theo-
rem 1.1 related to the HA/PR model and Theorem 1.3. The proofs related to this algorithm
are presented in Section B.3. Our ﬁrst step is to show (using Theorem B.1) that a spectral
clustering algorithm gives a good approximation to the planted coloring. We provide a new
spectral clustering algorithm that is based on sampling within the lowest eigenvectors, lead-
ing to improved eﬃciency (in the case of random k-color planting, the algorithm’s expected
running time is roughly ekn as opposed to nk in [2]) – see Lemma B.16. In the rest of the
section we show how to attain a full legal coloring. Our proofs of Lemmas 2.2 and 2.3 are
formulated in terms of a parameter sb that upper bounds the number of vertices with “bad
statistics". The actual value of this parameter depends on whether the planted coloring is
random (as in Lemma B.14) or adversarial, but other than that the proofs do not assume
that the planting is random. Instead they use the expander mixing lemma. The place where
we do use the randomness of the planted coloring is in Lemma B.21 that shows that after
the safe recoloring stage the remaining free vertices break up into connected components of
size O
The analysis of Lemma B.21 is tailored to the randomness of the planted coloring and to
the recoloring step that we added.

(cid:17). (This bound is smaller and hence better than the bound of logd n in [2]).

(cid:16) λ2

d2 log n

Section C contains all proofs for the model with an adversarial expander host graph and
an adversarial planted balanced coloring, namely, HA/PA. Section C.1 shows how to obtain
a b-partial coloring for graphs in the HA/PA model (Theorem 1.1). For HA/PA, Lemma C.4
replaces Theorem B.1 in the spectral analysis. Section C.2 proves Theorem 1.2 (hardness
result for the HA/PA model).

Section D contains all proofs for the model with a random host graph and an adversarial
planted balanced coloring, namely, HR/PA. Section D.1 proves Theorem 1.4a (a 3-coloring
algorithm for HR/PA). Section D.2 proves Theorem 1.4b (hardness for HR/PA).

Section E discusses extensions of our results to k > 3. The main new proof there is in
Section E.1 which shows a hardness result for k-coloring in the HR/PA model (for k > 3).
The range of degrees for this proof is not upper bounded (unlike the case of 3-coloring in
Theorem 1.4). This implies that Theorem 1.4a does not extend to k ≥ 4, unless P = N P .

15

Section F demonstrates (within our context of planted models) that even if a graph G
contains a vertex induced subgraph that is diﬃcult to 3-color, this by itself does not imply
that it is diﬃcult to 3-color G. It is useful to bear this fact in mind when trying to prove
NP-hardness results within our framework.

Section G contains some useful facts (Chernoﬀ bounds, the expander mixing lemma, and

more) that are used throughout this manuscript.

A.1 Extended notations and deﬁnitions
Given a graph G we denote its adjacency matrix by AG. We denote AG’s normalized
eigenvectors by e1 (G) , e2 (G) , .., en (G) and the corresponding real eigenvalues by λ1 (G) ≥
λ2 (G) ≥ ... ≥ λn (G). We denote by V (G) the vertex set of the graph and by E (G) the
edge set of the graph. We denote by dv the degree of v ∈ V (G). For any H ⊆ V (G) let GH
be the induced sub-graph of G on the vertices of H. Given a vertex v ∈ V (G) we denote by
N (v) the neighborhood of v, excluding v. For a set S ⊆ V , N (S) denotes the neighborhood
of S, i.e. , N (S) = ∪s∈SN (s) (note that with this deﬁnition we can have S ∩ N (S) (cid:54)= ∅).
For S, T ⊆ V (G), EG (S, T ) denotes the number of edges between S and T in G. If S, T are
not disjoint then the edges in the induced sub-graph of S ∩ T are counted twice.

Given a vector (cid:126)v ∈ Rn we denote by ((cid:126)v)i

the i-th coordinate of (cid:126)v.

Deﬁnition A.1. [Graph Sparsity]. Let G = (V, E) be a d-regular graph, S ⊆ V . The
sparsity of S is

and the sparsity of the graph G is

φ (S) :=

EG (S, V − S)
n |S||V − S| ,

d

φ (G) := minS⊆V φ (S)

Deﬁnition A.2. [Vertex expander]. A graph G is an (s, α) vertex expander if for every
S ⊆ V (G) of size at most s it holds that the neighborhood of S is of size at least α|S|.
Deﬁnition A.3. [λ − expander]. A graph G is a λ-expander if max (λ2 (G) ,|λn (G)|) ≤ λ.
Deﬁnition A.4. Let P3 (G) := (V1 ∪ V2 ∪ V3, E(cid:48)) be the following random graph:

1. Each vertex of V is in each Vi with probability 1
2. Each edge of (u, v) ∈ E is in E(cid:48) iﬀ u ∈ Vi and v ∈ Vj for i (cid:54)= j.

3

, independently over all the vertices.

Deﬁnition A.5. For v ∈ Vi we say v is colored with i. We call this coloring of P3 (G) the
planted coloring.
Deﬁnition A.6. Given P3 (G) and i ∈ {1, 2, 3} we denote by Gi the subgraph of G induced
on the vertex set Vi.
Deﬁnition A.7. Deﬁne the following vectors in Rn (where i ranges from 1 to n).
1 vi ∈ V3
,
0 vi /∈ V3

1 vi ∈ V1
0 vi /∈ V1

1 vi ∈ V2
0 vi /∈ V2

= 1, ( (cid:126)p1)i :=

(cid:16)(cid:126)1n

, ( (cid:126)p2)i :=

, ( (cid:126)p3)i :=

(cid:17)

i

(cid:40)

(cid:40)

(cid:40)

16

2

vi ∈ V1
−1 vi ∈ V2
−1 vi ∈ V3

0

vi ∈ V1
vi ∈ V2
1
−1 vi ∈ V3

.

((cid:126)x)i :=
We denote by ¯v a normalized vector, i.e., ¯x := (cid:126)x/|(cid:126)x|2

.

and ((cid:126)y)i :=

B Adversarial host and random planting, HA/PR
Section B contains the proofs for the model with an adversarial expander host graph and a
random planted coloring, namely, HA/PR. Section B.1 analyzes the spectrum of an expander
graph with a random planted coloring (this relates to Lemma 2.1 in the HA/PR model).
Section B.2 presents in a uniﬁed manner the algorithm that 3-colors graphs in the HA/PR
model, combining into one algorithm the parts of Theorem 1.1 related to the HA/PR model
and Theorem 1.3. The proofs related to this algorithm are presented in Section B.3.

Theorem B.1. Let G be a d regular λ-expander, where λ ≤(cid:0) 1

B.1 The eigenvalues of an expander with a random planted coloring
). Let
G(cid:48) = P3 (G) (the graph G after a random 3-color planting). Then with high probability the
following holds.

3 − (cid:1) d (for 0 <  < 1

3

d

d

(cid:17).

1 − 3√

1. The eigenvalues of G(cid:48) have the following spectrum.

(a) λ1 (G(cid:48)) ≥(cid:0)1 − 2−Ω(d)(cid:1) 2
(cid:16)√

3 d.
(b) λn (G(cid:48)) ≤ λn−1 (G(cid:48)) ≤ − 1
3 d
(c) |λi (G(cid:48))| ≤ 2λ + O

(cid:16)
(cid:17) for all 2 ≤ i ≤ n − 2.
(cid:16) 1√
(cid:17).
(cid:17) and ¯x + (cid:126)¯x ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
(cid:17) and ¯y + (cid:126)¯y ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
(cid:17).
(cid:16) 1√
3 d(cid:1) ¯y + (cid:126)δ¯y and AG(cid:48)¯1 =(cid:0) 2
3 d(cid:1) ¯x + (cid:126)δ¯x, AG(cid:48) ¯y =(cid:0)− 1
deﬁnition A.7, satisfy AG(cid:48) ¯x =(cid:0)− 1

2. The following vectors exist.
(a) (cid:126)¯x such that (cid:107)(cid:126)¯x(cid:107)2 = O
(b) (cid:126)¯y such that (cid:107)(cid:126)¯y(cid:107)2 = O

In the rest of this section we prove Theorem B.1.

d

d

Here (cid:126)δ¯x, (cid:126)δ¯y, (cid:126)δ¯1 are vectors with (cid:96)2 norm of at most

√

d.

Lemma B.2. Let G(cid:48) be as in Theorem B.1. With high probability the vectors ¯1, ¯x, ¯y, see

3 d(cid:1) ¯1 + (cid:126)δ¯1.

Proof. We prove the lemma for ¯1, (cid:126)δ¯1 (the other cases have a similar proof). We assume
√
n) since for large values of d one can show a diﬀerent proof using the union bound,
d = o (
details omitted.

3 d(cid:1)(cid:126)1. We give an upper bound (that holds with high

Consider the vector AG(cid:48)(cid:126)1 −(cid:0) 2

probability) on the sum of squares of its coordinates.

17

3

(cid:17)

AG(cid:48)(cid:126)1

i

(cid:17)

AG(cid:48)(cid:126)1

AG(cid:48)(cid:126)1

(cid:17)

E

AG(cid:48)(cid:126)1

= nE

AG(cid:48)(cid:126)1

i

(cid:17)

= nd

2
9

.

− 2
3 d

i

− 2
3 d

i

− 2
3

d

1

− 2
3

d

i

(cid:19)2(cid:35)

between 0 and 4

Let i ∈ [n]. As E

(cid:34)(cid:88)
(cid:17)

(cid:16)(cid:16)
(cid:18)(cid:16)

can be seen as the variance of d independent

Bernoulli variables, (each with variance 2
3

9 d2, and hence xi can eﬀect it by at most 4

Let xi be a random variable that indicates the color of a the i-th vertex of the graph. Set

(cid:17)2(cid:21)
(cid:0)1 − 2
(cid:1)), it holds that
(cid:34)(cid:18)(cid:16)
(cid:19)2(cid:35)

(cid:20)(cid:16)(cid:16)
(cid:18)(cid:16)
(cid:17)2 to be a function of xi’s. Consider the terms of f that are eﬀected
(cid:17)2. Its value is bounded
(cid:19)2

9 d2. Other terms that are aﬀected
, where j ranges over neighbors of i in G. As i has degree d in
3 d (which lies between
− 2
changes by at
3 d

f =(cid:80)
by a particular random variable xi. One such term is(cid:16)(cid:16)
G, there are d such terms. For each neighbor j, the value(cid:16)
(cid:18)(cid:16)
(cid:18)(cid:16)
(cid:17)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ c1nd

. Overall, the eﬀect of xi on(cid:80)

(cid:16) n
(cid:16)−Ω
(cid:17)(cid:17)
(cid:17)
(cid:13)(cid:13)(cid:13)2
. Overall , with high probability,(cid:13)(cid:13)(cid:13)AG(cid:48)(cid:126)1 −(cid:0) 2
3 d(cid:1)(cid:126)1
thus, by normalization,(cid:13)(cid:13)AG(cid:48)¯1 −(cid:0) 2

(cid:19)2 − nd
3 d(cid:1) ¯1(cid:13)(cid:13)2 ≤ √

where c1 is a constant, say 1

By the above we can apply McDiarmid’s Inequality (Theorem G.2) with c = 2d2 to

not eﬀect any other term in f, its total eﬀect on f is at most 2d2

) changes by at most 1 by xi, implying that

3 + 4d2

9 = 10d2

9 < 2d2.

(cid:34)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:88)

i

(cid:17)
(cid:19)2

≤ √

nd and

is at most 2d2
3

. As xi does

and − 2d

3

− 2
3

d

i

− 2

(cid:17)

j

− 2
3 d

i

− 2
3 d

j

by xi are

most 2d
3

j∈N (i)

AG(cid:48)(cid:126)1

AG(cid:48)(cid:126)1

j

Pr

AG(cid:48)(cid:126)1

2
9

d.

− 2
3 d

j

(cid:35)

≤ 2 exp

(cid:18)(cid:16)

9

d
3

deduce

AG(cid:48)(cid:126)1

(cid:17)

AG(cid:48)(cid:126)1

(cid:19)2

,

d2

.

Lemma B.3. Let A be a symmetric matrix of order n with eigenvalues λ1, . . . , λn and
associated eigenvectors v1 . . . , vn. For a unit vector ¯u and scalar λ, suppose that A¯u = λ¯u+(cid:126),
where the (cid:96)2 norm of (cid:126) is at most .
Let Sδ ⊂ {1, . . . , n} be the set of those indices i for which |λi − λ| ≤ δ. Then there exists
a vector (cid:126)¯u such that ¯u + (cid:126)¯u is a vector spanned by the eigenvectors associated with Sδ and
(cid:107)(cid:126)¯u(cid:107)2 ≤ 

Proof. Write ¯u =(cid:80)n
Hence (cid:126) = (cid:80)(λi − λ)αivi, implying (cid:80)(λi − λ)2(αi)2 ≤ 2. By averaging, it follows that
(cid:80)

i=1 αivi, with(cid:80)(αi)2 = 1. Then
(cid:88)

(cid:88)
δ2 . Let (cid:126)¯u := −(cid:80)

(λi − λ)αivi.

λiαivi = λ¯u +

(αi)2 < 2

αivi.

A¯u =

i(cid:54)∈Sδ

i(cid:54)∈Sδ

δ

18

Lemma B.4. Let G(cid:48) be as in Theorem B.1, and let the unite vectors ¯1, ¯x, ¯y be as in deﬁni-
tion A.7. Deﬁne Sδ (x) ⊂ {1, . . . , n} to be the set of those indices i for which |λ (G(cid:48))i−(x)| ≤
δ. The following vectors exist with high probability.

d
δ

• (cid:126)¯1 such that (cid:107)(cid:126)¯1(cid:107)2 ≤ √
• (cid:126)¯x such that (cid:107)(cid:126)¯x(cid:107)2 ≤ √
• (cid:126)¯y such that (cid:107)(cid:126)¯y(cid:107)2 ≤ √

d
δ

d
δ

and ¯1 + (cid:126)¯1 ∈ span(cid:16){ei (G(cid:48))}i∈Sδ( 2
and ¯x + (cid:126)¯x ∈ span(cid:16){ei (G(cid:48))}i∈Sδ(− 1
and ¯y + (cid:126)¯y ∈ span(cid:16){ei (G(cid:48))}i∈Sδ(− 1

3 d)

(cid:17).
(cid:17).
(cid:17).

3 d)

3 d)

Proof. By Lemma B.2 and Lemma B.3 the statement of the lemma holds with high proba-
bility.
Lemma B.5. Let G be a d-regular λ-expander. Let G1 be a random induced graph of G
where each vertex of G is in G1 independently with probability 1
. With high probability the
vector ¯1|V (G1)|, see deﬁnition A.7, satisﬁes AG1
Here (cid:126)δ¯1 is a vector with (cid:96)2 norm of at most

3 d(cid:1) ¯1|V (G1)| + (cid:126)δ¯1.

¯1|V (G1)| =(cid:0) 1

√

d.

3

Proof. The proof is similar to the proof of Lemma B.2.
Lemma B.6. Let G be a d-regular λ-expander. Let G1 be a random induced graph of G
where each vertex of V (G) is in V (G1) independently with probability 1
. It holds that G1
is a λ-expander.
Proof. The proof follows by Cauchy interlacing theorem, (Theorem G.3).
Lemma B.7. Let G(cid:48) be as in Theorem B.1, the vector ¯p1 be as in Deﬁnition A.7, and
δ ≤ d

d − λ . The following vector exists with high probability.
such that (cid:107)(cid:126) ¯p1(cid:107)2 ≤ √

and ¯p1 + (cid:126) ¯p1 ∈ span ({e1 (G1)}).

3 − √
• (cid:126) ¯p1

d
δ

3 d| ≤ δ. By Lemma B.6
Proof. Let Sδ (G1) be the set of those indices i for which |λ (G1)i − 1
it follows that Sδ (G1) = {1}. By Lemma B.5 and Lemma B.3 the following vector exists
with high probability. (cid:126) ¯p1

and

3

such that (cid:107)(cid:126) ¯p1(cid:107)2 ≤ √
¯p1 + (cid:126) ¯p1 ∈ span(cid:16){ei (G1)}i∈Sδ(G1)

d
δ

(cid:17)

= span ({e1 (G1)}) .

Now we prove Theorem B.1.

2 d and (cid:126)¯1,(cid:126)¯x,(cid:126)¯y,(cid:126) ¯p1

which either |λ (G(cid:48))i −(cid:0)− 1

be the vectors that were deﬁned in
Proof. [Theorem B.1]. Let δ = 
Lemma B.4 and Lemma B.7. Deﬁne Sδ ⊂ {1, . . . , n} to be the set of those indices i for
following two claims.
Claim B.8. For {i} /∈ Sδ it holds that |λ (G(cid:48))i | ≤ 2λ + O

3 d(cid:1)| ≤ δ. We conclude the proof by the

3 d(cid:1)| ≤ δ or |λ (G(cid:48))i −(cid:0) 2

(cid:16) d1.5

(cid:17).

δ

19

be the adjacency matrix of the induced sub-graph on j-colored vertices, i.e.,

(cid:1)

(cid:40)(cid:0)AGj
(cid:40)

0

(cid:16)

A(cid:48)

Gj

=

(cid:17)
(cid:0)ei (Gj)
(cid:48)(cid:1)

i,k

i,k

vi ∈ V (Gj), vk ∈ V (Gj)
Otherwise.

.

k =

(ei (Gj))k
0

vk ∈ V (V (Gj))
Otherwise.

.

Proof. Let A(cid:48)

Gj

Let

AG −(cid:0)Σ3

j=1AGj

(cid:1).

For brevity, the last two notation are used without the apostrophe. Note that AG(cid:48) =

Let i /∈ Sδ, by the triangle inequality it holds that,

(cid:107)AG(cid:48)ei (G(cid:48))(cid:107)2 ≤ (cid:107)AGei (G(cid:48))(cid:107)2 +

(cid:16) d1.5

(cid:17).

δ

First we show (cid:107)AGei (G(cid:48))(cid:107)2 ≤ λ + O

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 3(cid:88)

j=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

AGj ei (G(cid:48))

.

(1)

(cid:107)AGei (G(cid:48))(cid:107)2

j (G)(cid:104)ei (G(cid:48)) , ej (G)(cid:105)2
j=1λ2
1 (G)(cid:104)ei (G(cid:48)) , e1 (G)(cid:105)2 + Σn
1 (G)(cid:104)ei (G(cid:48)) , e1 (G)(cid:105)2 + λ2.
The last inequality follows since G is a λ-expander.

2 = Σn
= λ2
≤ λ2

j=2λ2

j (G)(cid:104)ei (G(cid:48)) , ej (G)(cid:105)2

= d2 (cid:104)ei (G(cid:48)) , ¯1(cid:105)2 + λ2
= d2 (cid:104)ei (G(cid:48)) , ¯1 + (cid:126)¯1 − (cid:126)¯1(cid:105)2 + λ2
= d2 (cid:104)ei (G(cid:48)) ,(cid:126)¯1(cid:105)2 + λ2

(2)

The last equality holds since ¯1 + (cid:126)¯1 and ei (G(cid:48)) are orthogonal.

.

2 + λ2

on (cid:107)(cid:126)¯1(cid:107)2

The last inequality follows by Cauchy–Schwarz inequality and now we use the assumption

≤ d2 (cid:107)(cid:126)¯1(cid:107)2
(cid:33)2
(cid:32)√
We left to show that with high probability(cid:13)(cid:13)(cid:13)(cid:80)3
by nj the Gj’s number of vertices. Note that(cid:80)3
are the eigenvectors of(cid:80)3
with at least three connected components, ({Gj}j∈{1,2,3}), thus {ei (Gj)|1 ≤ i ≤ nj, j ∈ {1, 2, 3}}

j=1 AGj ei (G(cid:48))
j=1 AGj

, (up to appropriate padding with zeros).

is the adjacency matrix of a graph

(cid:17). Denote

(cid:16) d1.5

≤ λ + O

(cid:13)(cid:13)(cid:13)2

≤ d2

+ λ2.

d
δ

δ

j=1 AGj

20

expanders with degree at most d.

3(cid:88)

j=1

= d2

(cid:10)ei (G(cid:48)) , ¯pj + (cid:126) ¯pj

(cid:11)2

3(cid:88)
3(cid:88)

j=1

j=1

+ λ2 = d2

≤ d2

+ λ2

(cid:11) + (cid:104)ei (G(cid:48)) , ¯pj(cid:105)(cid:1)2

(cid:0)(cid:10)ei (G(cid:48)) ,(cid:126) ¯pj
(cid:0)(cid:13)(cid:13)(cid:126) ¯pj
(cid:13)(cid:13)2 + (cid:104)ei (G(cid:48)) , ¯pj(cid:105)(cid:1)2
(cid:33)2

+ λ2

+ (cid:104)ei (G(cid:48)) , ¯pj(cid:105)

+ λ2

The last inequality follows by Cauchy–Schwarz inequality.

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 3(cid:88)

j=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

2

AGj ei (G(cid:48))

=

=

j=1

k=1

nj(cid:88)

3(cid:88)
3(cid:88)
1 (Gj)(cid:104)ei (G(cid:48)) , e1 (Gj)(cid:105)2 +
λ2
3(cid:88)

k (Gj)(cid:104)ei (G(cid:48)) , ek (Gj)(cid:105)2
λ2
3(cid:88)

(cid:104)ei (G(cid:48)) , e1 (Gj)(cid:105)2 + λ2

j=1

j=1

j=2

≤ d2

j=1

nj(cid:88)

j (G1)(cid:104)ei (G(cid:48)) , ej (G1)(cid:105)2
λ2

The last inequality follows since by Lemma B.6 it follows that {Gj}j∈{1,2,3} are λ-

(cid:32)√

d
δ

(cid:68)

≤ d2

j=1

3(cid:88)
(cid:32)√
(cid:111)

d
δ

The last inequality follows by the assumption on |(cid:126) ¯p1|2

.

(cid:69)(cid:33)2

+

ei (G(cid:48)) , cj

1

¯1 + cj

2 ¯x + cj
3 ¯y

+ λ2

3(cid:88)
With high probability(cid:110)

= d2

j=1

cj
k

stants exist with high probability note that for example (cid:126)p1 = 1
√
spans (cid:126)p1, (cid:126)p2, (cid:126)p3 using universal constants), thus by normalization ¯p1 = 1
√
√
n
|V1|

3
are constants.

√
√
|V1| ,

(cid:107)(cid:126)x(cid:107)2√
|V1|

¯1 +

n

3

3

are universal constants. To see that such con-
3 (cid:126)x, (In general (cid:126)1, (cid:126)x, (cid:126)y
|V1| (cid:126)x =

(cid:126)1 + 1√

(cid:126)1 + 1

|V1|

3

k,j∈{1,2,3}

(cid:107)(cid:126)x(cid:107)2√
|V1| ¯x and with high probability
(cid:32)√
(cid:32)√

ei (G(cid:48)) , cj

d
δ

+

(cid:68)
(cid:68)

ei (G(cid:48)) , cj

d
δ

+

3(cid:88)
3(cid:88)

j=1

j=1

= d2

= d2

2 (¯x + (cid:126)¯x − (cid:126)¯x) + cj
1 (¯1 + (cid:126)¯1 − (cid:126)¯1) + cj
(cid:33)2
(cid:69)
3 (−(cid:126)¯y)
2 (−(cid:126)¯x)

1 (−(cid:126)¯1) + cj

+ cj

+ λ2

3 (¯y + (cid:126)¯y − (cid:126)¯y)

(cid:69)(cid:33)2

+ λ2

(3)

21

The last equality holds since ¯1 + (cid:126)¯1, ¯x + (cid:126)¯x, ¯y + (cid:126)¯y are orthogonal to ei (G(cid:48)).

(cid:32)√

3(cid:88)

j=1

d
δ

+

(cid:32) 3(cid:88)

k=1

(cid:12)(cid:12)(cid:12)(cid:33)(cid:32)√

(cid:12)(cid:12)(cid:12)cj

k

d
δ

(cid:33)(cid:33)2

≤ d2

(cid:18) d3

(cid:19)

δ2

+ λ2 = O

+ λ2

The last inequality follows by Cauchy–Schwarz inequality and the assumption on (cid:107)(cid:126)¯1(cid:107)2 ,(cid:107)(cid:126)¯x(cid:107)2 ,(cid:107)(cid:126)¯y(cid:107)2

.

Claim B.9. |Sδ| = 3.

Proof. Clearly ¯1 + (cid:126)¯1, ¯x + (cid:126)¯x, ¯y + (cid:126)¯y ∈ span(cid:0){ei (G(cid:48))}i∈Sδ

(cid:1) and since they are independent,

(the vectors ¯1, ¯x, ¯y are nearly orthogonal, adding to them the vectors (cid:126)¯1,(cid:126)¯x,(cid:126)¯y, each of small
(cid:96)2 norm, doesn’t change this.), it follows that |Sδ| ≥ 3.

Now we show |Sδ| = 3. Let W = span{¯1 + (cid:126)¯1, ¯x + (cid:126)¯x, ¯y + (cid:126)¯y} and let

(cid:1)|∀w ∈ W , (cid:104)w, v(cid:105) = 0(cid:9) .

Assume, towards a contradiction, that exists 0 (cid:54)= v ∈ W ⊥. Note that we can write

W ⊥ :=(cid:8)v ∈ span(cid:0){ei (G(cid:48))}i∈Sδ
(cid:88)

αiei (G(cid:48)) ,

v =

i∈Sδ

where(cid:80)

i∈Sδ

i = 1. Now we give a lower bound on (cid:107)AG(cid:48)v(cid:107)2
α2
(cid:107)AG(cid:48)v(cid:107)2

.

(cid:33)(cid:43)
(cid:43)

(cid:33)

(cid:32)(cid:88)

i∈Sδ

, AG(cid:48)

(cid:88)

i∈Sδ

(cid:18)(cid:18) 1

α2

i =

− 
2

3

αiei (G(cid:48))

i∈Sδ
λi (G(cid:48)) αiei (G(cid:48)) ,

αiei (G(cid:48))

λi (G(cid:48)) αiei (G(cid:48))

i

(cid:19)2(cid:88)

(cid:19)

(cid:19)2

d

.

=

=

=

AG(cid:48)

(cid:32)(cid:88)

i∈Sδ
i (G(cid:48)) α2
(cid:19)
λ2

(cid:42)
2 = (cid:104)AG(cid:48)v, AG(cid:48)v(cid:105)
(cid:42)(cid:88)
(cid:88)
(cid:18)(cid:18) 1
(cid:13)(cid:13)(cid:13)2
(cid:17) and (cid:13)(cid:13)(cid:13)(cid:80)3

− 

i∈Sδ

≥

d

3

(cid:16) d1.5

i∈Sδ
2 d. By the triangle inequality at least one of the

The last inequality uses the fact δ = 

following is(cid:0) 1
3 − 
(cid:107)AGv(cid:107)2

(cid:1) d:
and (cid:13)(cid:13)(cid:13)(cid:80)3

2

j=1 AGj v

, see Equation 1. But applying the proof Claim B.8 shows

that (cid:107)AGv(cid:107)2 = λ + O
from the vector ei (G(cid:48)) is to be orthogonal to ¯1 + (cid:126)¯1, ¯x + (cid:126)¯x, ¯y + (cid:126)¯y, see Equation 2 and

Equation 3. v ∈ W ⊥ satisﬁes these requirements by deﬁnition). As λ <(cid:0) 1

2 d this is a contradiction (for large enough d). Since W ⊥ = φ Claim B.9 follows.

j=1 AGj v

= λ + O

δ = 

δ

δ

(cid:16) d1.5

(cid:17), (The only requirement
3 − (cid:1) d and since

(cid:13)(cid:13)(cid:13)2

22

By Claim B.8 and Claim B.9 items 1.(a) and 1.(c) of Theorem B.1 hold and − (1 + ) 1

3 d ≤
λn (G(cid:48)) ≤ λn−1 (G(cid:48)) ≤ − (1 − ) 1
3 d. Items 2(a),2(b) and 2(c) hold with respect to the vectors
(cid:126)¯1,(cid:126)¯x,(cid:126)¯y deﬁned above. To establish Item 1.(b) of Theorem B.1 note that by Lemma B.2
and by the Courant-Fischer theorem the following holds with high probability

λn (G(cid:48)) ≤ λn−1 (G(cid:48)) =

max
v∈S

vtAv
vtv

min
S ∈ Rn

dim (S) = 2

≤ max

v∈span{(cid:126)x,(cid:126)y}
√

vtAv
vtv

≤ − 1
3

d +

d .

B.2 Coloring expander graphs with a random planted coloring
Let G(cid:48) = (V, E) be a graph as in Theorem B.1 (G(cid:48) is a d-regular λ-expander graph after a
random 3-color planting). Theorem B.1 gives some of the mathematical background that is
needed in order to analyze our algorithm for 3-coloring G(cid:48). The following theorem restates
in a combined form the parts of Theorem 1.1 that relate to the HA/PR model together with
Theorem 1.3.
Theorem B.10. Let G(cid:48) be as above and assume λ ≤ d
and d ≥ dmin. Here dmin is a large
enough constant. Algorithm 1, see below, colors G(cid:48), with high probability over choice of the
random planted 3-coloring.

24

First we deﬁne the following.

Deﬁnition B.11. Given any coloring of G(cid:48), say C, denote by colC (v) the color of vertex
v according to C. Denote by P the planted coloring of G(cid:48). We say a coloring is partial if
some of the vertices are not colored.
Deﬁnition B.12. An f-approximated coloring is a 3-coloring of G(cid:48), possibly not legal, that
agrees with the planted coloring, colP , of G(cid:48) on at least n − f vertices.

Throughout this section, let  = 0.01. Consider Algorithm 1.

Algorithm 1 3-Coloring

1. Apply Algorithm 2 (spectral clustering) on G(cid:48), obtaining a coloring C1.
2. Apply Algorithm 4 (iterative recoloring) on (G(cid:48), C1), obtaining a coloring C2.
3. Apply Algorithm 5 (cautious uncoloring) on (G(cid:48), C2), obtaining a partial coloring C3.
4. Apply Algorithm 6 (safe recoloring) on (G(cid:48), C3), obtaining a partial coloring C4.
5. Apply Algorithm 7 (brute force) on (G(cid:48), C4), obtaining a coloring C5.

23

Algorithm 3-Coloring is patterned after the algorithm of Alon and Kahale for the ran-
dom planted model. The main diﬀerences between the two algorithms are as follows. (There
are also diﬀerences in the analysis) Similar to [2], Step 1 (spectral 3-clustering) starts with
computing the eigenvectors corresponding to the two most negative eigenvalues. However,
it diﬀers from [2] in the way C1 is derived from these eigenvector. Our approach is com-
putationally more eﬃcient, an aspect that is only of minor signiﬁcance in the context of
3-coloring, but may become signiﬁcant for k-coloring with k > 3. See more details in Sec-
tion B.3. Another diﬀerence is the introduction of Step 4 in our algorithm, that is not
present in [2]. The purpose of introducing this additional step is so as to be able to prove
the last statement of Lemma B.21. In [2] such a statement could be proved already after
Step 3.

B.3 Proof Of Theorem B.10
The following lemmas outline the desired outcome of the respective steps of Algorithm 1
and the proof of Theorem B.10 follows by applying them.

At a high level, one may think of most of our proofs as adaptations (some immediate,
some requiring work) of proofs of corresponding statements made in [2]. The exception to
this is the proof of the last statement in Lemma 4, which involves ideas not present in [2].
Deﬁnition B.13. The set SB ⊆ V , statistically bad, is the the following vertex set. v ∈ SB

if for some color class other than colP (v), v has either has more than (cid:0) 1
or less than(cid:0) 1

3 − (cid:1) d neighbors in that color class.

3 + (cid:1) d neighbors

Lemma B.14. It holds that |SB| ≤ n2−Ω(d) with high probability over the random planting
process.

In expectation v has 1

3 d neighbors in G(cid:48) with original color
Proof. (Of Lemma B.14).
k ∈ {1, 2, 3} \ {colP (v)}. By Chernoﬀ bound, Theorem G.1, the probability that a random
vertex v ∈ G(cid:48) is in SB is at most 2−Ω(d), thus E [SB] = 2−Ω(d)n. If d ≥ η1 log n, for a
large enough constant η1, then, by using the union bound, the probability that |SB| ≥ 1
is bounded by 2−Ω(d)n = n−Ω(1). Assume d ≤ η2 log n, where η2 is a constant.
|SB| is a
function of n independent random variables that were used to create G(cid:48). By changing one of
the above random variables |SB| changes by at most d. By applying McDiarmid’s theorem,
Theorem G.2, it follows that for a small enough constant η2 the following holds,

Pr [||SB| −E [|SB|]| ≥ dE [|SB|]] ≤ 2 exp

(cid:32)
− 2 (dE [|SB|])2

(cid:33)

2nd2
− n
2Ω(d) = 2−nΩ(1)

.

= 2

For (constant) large enough values of d and a suitable choice of  we can assure η1 ≤ η2

and the proof follows.

The following lemma is the ﬁrst step towards coloring G(cid:48).

Lemma B.15. Let G(cid:48) as above and assume λ ≤ 1
24 d. Algorithm 4, see below, outputs an
O (|SB|)-approximated coloring with high probability over the colors of the vertices in the
random planting process.

24

Note that if d = η log n, (for large enough constant η), then Lemma B.15 implies that
Algorithm 4 recovers the original coloring of G(cid:48). To prove Lemma B.15 we ﬁrst show
Lemma B.16 and Lemma B.17 presented below.

The next lemma shows, using Theorem B.1, that we can derive an approximated coloring

from the eigenvectors en−1 (G(cid:48)) , en (G(cid:48)) (see Algorithm 2 bellow).

Algorithm 2 Spectral Clustering
Input: A graph G(cid:48) and a positive constant c ≤ 1

2

.

1. Calculate en−1 := en−1 (G(cid:48)) and en := en (G(cid:48)).
2. For every triplet of vertices v1, v2, v3 ∈ V (G(cid:48)) do
(a) Put a vertex u ∈ V (G(cid:48)) in Si if it holds that

(cid:0)(en−1)u − (en−1)vi

(cid:1)2

+(cid:0)(en)u − (en)vi

.

1

<

(cid:1)2
(cid:1) n and that (cid:80)3

70n

(b) If for every i = 1, 2, 3 it holds that |Si| ≥ (cid:0) 1

In case that two deferent sets, Si and Sj, satisfy the above condition with respect
to u, go to Step 2.
i=1 |Si| ≥
d ) then output any coloring C of G(cid:48) that satisﬁes colC (u) = i if and only

3 − 1

d2c

n − θ( n
if u ∈ Si and stop.

2

d

.

Lemma B.16. (Restatement of Lemma 2.1). Let G(cid:48) be as above and c be a positive constant.
Algorithm 2 runs in polynomial time and if the following vectors exist (recall Deﬁnition A.7).

(cid:126)¯x such that (cid:107)(cid:126)¯x(cid:107)2 = O (d−c) and ¯x + (cid:126)¯x ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
O (d−c) and ¯y + (cid:126)¯y ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
(cid:16) 1√

(cid:17). (cid:126)¯y such that (cid:107)(cid:126)¯y(cid:107)2 =
(cid:17). Then Algorithm 2 outputs an O(cid:0)nd−2c(cid:1)-
(cid:17) and respectively for y so we can run Algo-

By Theorem B.1 we have (cid:107)(cid:126)¯x(cid:107)2 = O

approximated coloring.

rithm 2 with c = 1
Proof. [Lemma B.16]. We note that [2] present a diﬀerent algorithm to get an approximate
coloring from the eigenvectors. Our algorithm generalizes more easily to the case of planting
k colors. The running time of Step 1 is roughly linear (it is enough to get an approximation
of en−1, en). The running time of each iteration in Step 2 is O (n). The number of iteration

in Step 2 is O(cid:0)n3(cid:1) (for a planted coloring with k colors it is O(cid:0)nk(cid:1) ) but choosing at each

iteration a random triplet reduces the (expected) number of iterations to be constant (for
, see details below). Thus
a planted coloring with k colors it is expected to be less than kk
for a planted coloring with a constant number of vertices the running time of Algorithm 2
is linear.

Assume, for simplicity, that the planted color classes are balanced. Deﬁne the following

subset Good ⊆ V (G(cid:48)). A vertex v ∈ V (G(cid:48)) is in Good if both (((cid:126)¯x)v)2 ≤ 1

, for a = 70. By averaging argument it holds that |Good| ≥ (cid:0)1 − 2a

(cid:1)2 ≤
and(cid:0)((cid:126)¯y)v
(cid:1) n. Note that as

an

k!

1
an

d2c

25

¯x, ¯y are almost orthogonal then ¯x + (cid:126)¯x, ¯y + (cid:126)¯y tend to be almost orthogonal as d gets larger.
Formally, by the triangle’s inequality and the Cauchy-Schwartz inequality it follows that,

|(cid:104)¯x + (cid:126)¯x, ¯y + (cid:126)¯y(cid:105)| ≤ |(cid:104)¯x, ¯y(cid:105)| + |(cid:126)¯x| + |(cid:126)¯y| + |(cid:126)¯x||(cid:126)¯y|

= O(cid:0)d−c(cid:1) .

(4)

Deﬁne the vector ˜x to be the second Gram–Schmidt orthonormalization vector with

respect to ¯y + (cid:126)¯y, ¯x + (cid:126)¯x, i.e.,

˜x =

By Equation 4 it follows that

¯x + (cid:126)¯x − (cid:104)¯x + (cid:126)¯x, ¯y + (cid:126)¯y(cid:105) (¯y + (cid:126)¯y)
(cid:107)¯x + (cid:126)¯x − (cid:104)¯x + (cid:126)¯x, ¯y + (cid:126)¯y(cid:105) (¯y + (cid:126)¯y)(cid:107)2

(cid:107)¯x + (cid:126)¯x − ˜x(cid:107)2 ≤ O(cid:0)d−c(cid:1) ,

.

Assume for simplicity that (cid:107)¯x + (cid:126)¯x − ˜x(cid:107)2 ≤ d−c. Since

(cid:107)˜x(cid:107)2 ≥ (cid:107)¯x + (cid:126)¯x(cid:107) − (cid:107)¯x + (cid:126)¯x − ˜x(cid:107)2

≥ 1 − d−c > 0,
then ˜x (cid:54)= 0 and by deﬁnition (cid:104)˜x, ¯y + (cid:126)¯y(cid:105) = 0. Hence

span (˜x, ¯y + (cid:126)¯y) = span (en−1, en) .

(5)
Deﬁne the following subset Good2 ⊆ V (G(cid:48)). A vertex v ∈ V (G(cid:48)) is in Good2 if both
. By averaging argument it holds that |Good2| ≥
v ∈ Good and ((¯x + (cid:126)¯x − ˜x)v)2 ≤ 1
x, y ∈ R that satisfy x2 + y2 = 1 the condition

(cid:1) n. If the condition in Step 2.a of Algorithm 2 holds for u, w ∈ V (G(cid:48)) then for any

(cid:0)1 − 3a

d2c

an

|x ((en−1)u − (en−1)w) + y ((en)u − (en)w)| ≤ 1√

an

holds as well, and By Equation 5

(cid:12)(cid:12)x ((˜x)u − (˜x)w) + y(cid:0)(¯y + (cid:126)¯y)u − (¯y + (cid:126)¯y)w

(cid:1)(cid:12)(cid:12) ≤ 1√

an

,

(6)

holds for every x, y such that x2 + y2 = 1 as well. If v1 and u are both in Good2 and they
both have the same planted color, by Equation 6 it follows that v1, u ∈ S1. This is since for

every x, y(cid:12)(cid:12)(cid:12)x(cid:0)(˜x)v1

− (˜x)u

(cid:16)
(cid:1) + y
≤(cid:12)(cid:12)(cid:0)(¯x + (cid:126)¯x)v1

(¯y + (cid:126)¯y)v1

(cid:17)(cid:12)(cid:12)(cid:12)
(cid:1)(cid:12)(cid:12) +
(cid:114) 1
(cid:1)(cid:12)(cid:12) +

− (¯y + (cid:126)¯y)u
− (˜x)u

≤(cid:12)(cid:12)x(cid:0)(˜x)v1
(cid:1)(cid:12)(cid:12) + 2
≤(cid:12)(cid:12)(cid:0)((cid:126)¯x)v1

an
− ((cid:126)¯x)u

+

− (¯x + (cid:126)¯x)u

(cid:16)

(cid:12)(cid:12)(cid:12)y
(cid:12)(cid:12)(cid:12)(cid:16)
(cid:12)(cid:12)(cid:12)(cid:16)

(cid:17)(cid:12)(cid:12)(cid:12)
(cid:17)(cid:12)(cid:12)(cid:12)
(cid:114) 1

− (¯y + (cid:126)¯y)u
− (¯y + (cid:126)¯y)u

(cid:17)(cid:12)(cid:12)(cid:12) ≤ 6

.

an

(¯y + (cid:126)¯y)v1

(¯y + (cid:126)¯y)v1

((cid:126)¯y)v1

− ((cid:126)¯y)u

26

(cid:12)(cid:12)(cid:12)(cid:16)

(¯y + (cid:126)¯y)v1

− (¯y + (cid:126)¯y)u

If v1 and u are both in Good and u has a diﬀerent planted color than v then by Equation 6
it follows that u /∈ S1. To see this set x = 0 and y = 1, it follows that

− (¯y)u

(cid:1)(cid:12)(cid:12) − 2|(cid:126)¯x|

(cid:17)(cid:12)(cid:12)(cid:12) ≥(cid:12)(cid:12)(cid:0)(¯y)v1
(cid:1)-approximated coloring. Note that a random set of

(cid:114) 1

≥ 1√
n

− 2

an

.

If v1, v2 and v3 are all in Good and have diﬀerent planted coloring then by the above Step 2.b
three vertices from V (G(cid:48)) has a constant probability to satisfy this (speciﬁcally by assuming
) so by choosing v1, v2 and v3 at random the
d is much larger than k it is roughly p = k!
kk
expected number of the iterations that Algorithm B.16 performs is constant (more precisely
it is 1/p). By similar arguments it is straight forward to prove that any coloring that

(cid:1)-approximated coloring.

d2c

of Algorithm 2 will output an O(cid:0) n
Algorithm 2 outputs is an O(cid:0) n
(cid:1)-approximated coloring.
O(cid:0) n

d2c

24

Recall Deﬁnition B.13. The following lemma shows that Algorithm 3 reﬁnes any f =

Algorithm 3 One Step Reﬁnement
Input: A graph G(cid:48) and a coloring C.

1. For each vertex v,

set colC2 (v)

{colC (u)|u ∈ N (v)} (break ties arbitrarily).

to be the minority color

in the multiset

d

(cid:1)2

Lemma B.17. Algorithm 3 runs in polynomial time (O (nd)). Let G(cid:48) be as above and let
f be such that C is an f-approximated coloring for G(cid:48). If f ≤ n
then Algorithm 3 outputs

f + |SB|(cid:17)-approximated coloring for G(cid:48).

an(cid:16)(cid:0) 24λ
is that any v ∈ WC2 \ SB has at least(cid:0) 1

Proof. [Lemma B.17]. Let WC be the set of vertices colored with a diﬀerent color than the
original coloring in step 1 of the algorithm. Let WC2
be the set of vertices colored with a
diﬀerent color than the original in C2. Let k = |WC2 \ SB|. The key point, in bounding k,
correctly.

6 − (cid:1) d neighbors in WC as otherwise v was colored

24

So on the one hand, by using the Expander Mixing Lemma, (Lemma G.4), the following

holds

EG(cid:48) (WC, WC2 \ SB) ≤ EG (WC, WC2 \ SB)

≤ λ(cid:112)|WC||WC2 \ SB| +
≤ λ(cid:112)f k +
(cid:18) 1

f k .

d
n

EG(cid:48) (WC, WC2 \ SB) ≥ 1
2

k

− 

6

(cid:19)

d .

|WC||WC2 \ SB|

d
n

On the other hand

27

It follows that if k > 0 and f ≤ n

24

then

k ≤

(cid:18) 24λ

(cid:19)2

d

f .

24 d then we can improve the approximation.

Thus if λ < 1
To prove Lemma B.15 consider Algorithm 4.
[Lemma B.15].

Algorithm 4 Iterative Recoloring
Input: A graph G(cid:48) and a coloring F1.

1. For i taking values from 2 to k = Ω (d) do.

(a) Apply Algorithm 3 where the speciﬁed coloring is Fi−1 to get fi-approximated

coloring, namely Fi.

Lemma B.18. (Restatement of Lemma 2.2). Algorithm 4 runs in polynomial time (the
then Algorithm 4 outputs an O (|SB|)-approximated coloring for G(cid:48).

running time is O(cid:0)d2n(cid:1)). Let G(cid:48) be as above. If F1 is a(cid:0) n
Proof. (Of Lemma B.18). By Lemma B.17, it holds that fi ≤ (cid:0) 24λ
2 ≤ i ≤ k. It follows that fk ≤(cid:0) 24λ

(cid:1)2k n
fi−1 + |SB| for all
d + O (|SB|), substituting k = Ω (d)1 in the last

(cid:1)-approximated coloring for G(cid:48)

(cid:1)2

24

d

d

inequality resolves the proof.

The following lemma shows a structural property of expander graphs and is used in the

16 d, |S| < 

proof of Lemma B.20.
Lemma B.19. Let G be a d-regular λ-expander graph with n vertices and consider an
arbitrary S ⊂ V (G). If λ ≤ 
4 n and d is large enough then there exists CC ⊆
V (G)\ S such that GCC is a graph with a minimum degree of (1 − ) d and |CC| ≥ n− 2|S|.
Before we give the proof note that if G was the complete graph, as a toy example, then
we can take CC = V (G)\ S. This lemma can be seen as a relaxed version for this property
that holds in expander graphs.

Proof. (Of Lemma B.19). Consider the following iterative procedure. Repeatedly remove

a vertex vt from V (G) \(cid:16)
(cid:16)(cid:83)t−1

(cid:17)(cid:17) if vt has more than d neighbors in St = S ∪
(cid:17). Denote by S(cid:48) the union of S and the removed vertices. Assume towards a

S ∪(cid:16)(cid:83)t−1

i=1 vi

contradiction that this process stops after more than t = |S| steps. The graph GSt
average degree of at least 

2 d. By the expander mixing lemma it holds that

i=1 vi

has an

d|St| ≤ EG (St, St)


4

≤ d
n

|St|2 + λ|St|

1If λ = o (d) then less iterations are needed.

28

It follows that 
d (as λ ≤ 
follows.

4 d−λ)

8 n ≤ ( 

8 n, which is a contradiction for large enough
8 d). Clearly every vertex in GV (G)\S(cid:48) has degree at least (1 − ) d and the proof

n ≤ |St|, but |St| < 

d

To prove Theorem B.10 consider Algorithm 5.

Algorithm 5 Cautious Uncoloring
Input: A graph G(cid:48) and a coloring C.

1. Repeatedly uncolor the following vertices v ∈ G(cid:48) (denote the set of uncolored vertices

by H1):

(a) Vertices with less than(cid:0) 2
(b) Vertices with less than(cid:0) 1

3 − 2(cid:1) d neighbors.
(cid:1) d neighbors of color l ∈ {1, 2, 3} \ colC (v).

6

Lemma B.20. (Restatement of Lemma 2.3). Algorithm 5 runs in polynomial time. Let G(cid:48)
be as above. If C is an O (|SB|)-approximated coloring then the set of the uncolored vertices
(H1) is of size O (|SB|) and the set of the colored vertices agree with the planted coloring of
G(cid:48).
Proof. (Of Lemma B.20). Deﬁne

B := {v ∈ V (G(cid:48)) | colP (v) (cid:54)= colC (v)} .

has at least (cid:0) 1
set CC. Since v /∈ SB it holds that v ∈ CC has at at least(cid:0) 1

3 − 2(cid:1) d neighbors in CC with color i, for all i ∈ {1, 2, 3} \ colP (v). To see
3 − 2(cid:1) d neighbors in CC with

To derive the proof we show B ⊆ H1 and that |H1| ≤ O (|SB|). By Lemma B.19 there
exist a set CC ⊆ V (G(cid:48)) \ (SB ∪ B) such that |CC| ≥ n − 2|SB ∪ B|, and every v ∈ GCC
this, apply Lemma B.19 on G, the graph before the planting, with S = SB ∪ B to get the
color i, for all i ∈ {1, 2, 3} \ colP (v).
It holds that no vertex from CC is uncolored, (at the ﬁrst iteration of Step 1 this clearly
holds. Assume that no vertex from CC is uncolored in the ﬁrst i iterations of Step 1, in the
i + 1 iteration this still holds.).

least (cid:0) 2
least(cid:0) 1

that the sub-graph of G(cid:48) induced on BV (G(cid:48))\H1
mixing lemma, Lemma G.4, it holds that

Now we show that all of V (G(cid:48))\ H1 is colored correctly. Assume towards a contradiction
that there exists a vertex v in (V (G(cid:48)) \ H1) \ CC such that v ∈ B. Let BV (G(cid:48))\H1 :=
{v ∈ V (G(cid:48)) \ H1 | colP (v) (cid:54)= colC (v)}. Since that any vertex v ∈ BV (G(cid:48))\H1
has degree at

3 − 2(cid:1) d neighbors (as otherwise Step 1.a of Algorithm 5 removes v) then v has at
6 − (cid:1) d neighbors colored by colp (v) which means they are in BV (G(cid:48))\H1
6 − (cid:1) d. By the expander
has degree at least(cid:0) 1
(cid:12)(cid:12) ≤ EG(cid:48)(cid:0)BV (G(cid:48))\H1, BV (G(cid:48))\H1
(cid:1)
(cid:0)BV (G(cid:48))\H1, BV (G(cid:48))\H1
(cid:1)
(cid:12)(cid:12)BV (G(cid:48))\H1
+ λ(cid:12)(cid:12)BV (G(cid:48))\H1

d(cid:12)(cid:12)BV (G(cid:48))\H1

. It follows

(cid:18) 1

(cid:12)(cid:12) .

(cid:12)(cid:12)2

− 

6

(cid:19)

≤ EG
≤ d
n

29

It follows that if (cid:12)(cid:12)BV (G(cid:48))\H

holds that

(cid:12)(cid:12) > 0, as we assumed, then (cid:12)(cid:12)BV (G(cid:48))\H
(cid:12)(cid:12) ≤ n − |CC| = O (|SB|) ,
(cid:12)(cid:12)BV (G(cid:48))\H

(cid:12)(cid:12) ≥ Ω(cid:0) d−λ

d

(cid:1) n but as it

we derive a contradiction.

Algorithm 6 Safe Recoloring
Input: A graph G(cid:48) and a partial coloring C. Denote the set of uncolored vertices by H1.

1. Repeatedly color any vertex that has 2 neighbors colored with i, j, (for i (cid:54)= j), by

{1, 2, 3} \ {i, j}.

Lemma B.21. Algorithm 6 runs in polynomial time. Let G(cid:48) be as above and H be the set
of vertices that were left uncolored by Algorithm 6. Let G(cid:48)
be the induced sub-graph of G(cid:48)
on the vertices of H. If H1 ≤ 1
11 n then with high probability (over the distribution of G(cid:48))
each connected component in G(cid:48)

is of size O

(cid:16) λ2

(cid:17).

H

d2 log n

H

Proof. (Of Lemma B.21). Recall that G is the graph before the planted coloring process
occurred. We use Claim B.22 extensively.
Claim B.22. Let C ⊂ V (G) be any set of vertices of size k, let D be NG (C) \ C and let
t = |D|. If t ≥ 2k then C is in H and D ⊆ V (G) \ H with probability at most 2−ηt, for
some constant η.
Proof. Partition the vertices of D to disjoint subsets {Dv}, where v ∈ C and Dv ⊆ NG (v)
(this can be done by choosing for each vertex in D an arbitrary neighbor in S). Consider
some Dv and assume that v is colored by 1. If both v ∈ H and Dv ⊆ V (G)\ H then the set
of colors that vertices in Dv are using can be contained in exactly one of the sets {1, 2} or
{1, 3} (otherwise Algorithm 6 will color v at Step 1). Therefore the probability that both

v ∈ H and Dv ⊆ V (G) \ H is at most 2(cid:0) 2
H and D ⊆ V (G) \ H is at most(cid:89)
(cid:18) 2
(cid:19)|Dv|

3

2

3

Dv∈{Dv}

(cid:19)t

(cid:1)|Dv|. Hence, the probability that both C is in
= 2|{Dv}|(cid:18) 2
(cid:19)t
(cid:18) 2
(cid:19)t+k log 2
(cid:18) 2

(cid:19)0.14t

(cid:18) 2

≤ 2k

3

3

3

=

2 ≤

.

3
The last inequality follows by the assumption that t ≥ 2k.

3

Let C ⊂ H be any set of vertices of size k such that G(cid:48)

is connected. Note that if G(cid:48)
is connected then GC is connected. Hence we can consider the set ¯C to be a connected set

C

C

30

(cid:16) λ2

in G such that C ⊆ ¯C ⊂ H and N(cid:0) ¯C(cid:1) \ ¯C ⊆ V (G) \ H (as long as there exist vertices in
(cid:0)N(cid:0) ¯C(cid:1) \ ¯C(cid:1) ∩ H we repeatedly add them to ¯C, and it is straight forward to show that ¯C
(cid:17) are in H if N(cid:0) ¯C(cid:1) ⊆ V (G) \ H then the proof follows. The

is connected in G). Thus if we show that with high probability no connected subsets ¯C of
G with cardinality Ω
key point of the proof is that (since H is small) no (small connected) subsets of H with with
a small neighborhood are in V (G) \ H (due to G’s expansion) and when a connected set
have a large enough neighborhood we can use Claim B.22 to show they are likely to not be
contained in H. To fully exploit Claim B.22 we use the union bound in a delicate manner
that depends on the neighborhood size of the (connected) sets in order to sum sets with
large neighborhood size with small probabilities. In order to do so we use Lemma B.23.

d2 log n

Denote by NG (n, k, d) the number of connected components of size k with a neighbor-

hood of size exactly t in a graph G with n vertices.
Lemma B.23. For any graph G the following holds,

(cid:18)k + t

(cid:19)

.

k

NG (n, k, t) ≤ n

Several proofs of Lemma B.23 are known, and one such a proof can be found in [27].
Lemma B.23 holds for any graph, regardless of its degree or expansion. Let α be such that
λ = d
α

. Let

ps,t :=

max

C⊂G,|C|=s,|N (C)|=t

Pr [C is in H] .

By the union bound the probability that there exists a connected component in G(cid:48)
Ω

H

d2 log n

(cid:16) λ2

(cid:17) is at most
ds(cid:88)
|H|(cid:88)

s= λ2

d2 log n

t=1

s= λ2

d2 log n

t=

λ )2

s

NG (n, s, t) Ps,t =

≤

≤

≤

2 ( d

ds(cid:88)
(cid:108) 1
ds(cid:88)
(cid:108) α2
ds(cid:88)
(cid:108) α2

2 s

2 s

(cid:109) n

(cid:109) n

(cid:19)

(cid:109) NG (n, s, t) 2−ηt
(cid:18)s + t
(cid:18)

(cid:19)s

2−ηt

s

s + t

2−ηt

e

s

2(log2(e(c+1))−ηc)s

nds max
2 ≤c≤d

α2

2(log2(e(c+1))−ηc)s

|H|(cid:88)
|H|(cid:88)
|H|(cid:88)
|H|(cid:88)

s= λ2

d2 log n

t=

s= λ2

d2 log n

t=

s= λ2

d2 log n
≤ n4 max
2 ≤c≤d
≤ n−Ω(1) .

α2

31

of size

(7)

(8)

(9)

(10)

(11)

Equality 7 follows since by Lemma G.5 if λ ≤ d/
11 n it
holds that its neighborhood is of size t ≥ 1
s (thus NG (n, s, t) = 0) and by Claim B.22
(for some constant η). Inequality 8 follows by Lemma B.23. Inequality 9 follows by the

(cid:1)k. Inequality 11 follows if α ≥ α(cid:48) , where α(cid:48) is a large enough

binomial identity(cid:0)n

12 then for a set of size s ≤ |H| ≤ 1

(cid:1) ≤(cid:0)e n

λ

2

k

k

√

(cid:0) d

(cid:1)2

constant.

Algorithm 7 Brute Force
Input: A graph G(cid:48) and a partial coloring C.

1. If the induced graph of the uncolored vertices, H, contains a connected component of

size log n abort.

2. Enumerate over all possible coloring of each connected component of H and return a

legal 3-coloring of G(cid:48).

C Adversarial host and adversarial planting, HA/PA
Section C contains the proofs for the model with an adversarial expander host graph and
an adversarial planted balanced coloring, namely, HA/PA. Section C.1 shows how to obtain
a b-partial coloring for graphs in the HA/PA model (Theorem 1.1). Section C.2 proves
Theorem 1.2 (hardness result for the HA/PA model).

C.1 Partial coloring of expander graphs with adversarial planting
Given a d-regular λ-expander graph G and a partition, C, of V (G) to 3 sets, c1, c2, c3, we
denote by PC (G) the graph obtained after removing all edges from G with both endpoints in
the same set ci. If all the sets c1, c2, c3 have the same cardinality we say that C is balanced.
In this section we consider the computational problem of coloring PC (G) when C is given
by an adversary.

In this section we show the following theorem.

Theorem C.1. (Restatement of Theorem 1.1). Let G be a d-regular λ-expander graph. If
λ ≤ cd (for some constant c) then for every balanced 3-color planting C Algorithm 8 outputs
an O

(cid:1)2(cid:17)-approximated coloring for PC (G).

n(cid:0) λ

(cid:16)

d

Throughout this section, let  = 0.01.

3 + (cid:1) d or neighbors, or less than(cid:0) 1

Deﬁnition C.2. The set SB ⊆ V , statistically bad, is the the following vertex set. v ∈ SB
color k ∈ {1, 2, 3} \ {colC (v)}.

if v has more than(cid:0) 1
(see Algorithm 8 below) we can ﬁnd the planted coloring of a set of(cid:0)1 − O(cid:0) 1

3 − (cid:1) d or neighbors, with original
(cid:1)(cid:1) n vertices.

It turns out that by applying Algorithm 4 and the uncoloring procedure of Algorithm 5

d

32

Algorithm 8 Iterative Coloring and Uncoloring

1. Color PC (G) with an O (|SB|)-approximated coloring ,CAlg (use Algorithm 4).

2. Repeatedly uncolor vertices v ∈ PC (G) with less than (cid:0) 2
less than(cid:0) 1

3 − 2(cid:1) d neighbors or with
(cid:1) d neighbors of color l ∈ {1, 2, 3}\ colCAlg (v), denote the set of uncolored

vertices by H1.

6

3. If |H1| = O (log n) then enumerate over all the possible colorings (3|H1|) of the vertices

in H1.

Throughout the rest of this section we denote G(cid:48) = PC (G). The main point of the proof
of Theorem C.1 is that en−1 (PC (G)) , en (PC (G)) are related to C even when C is arbitrary
balanced (rather than random as in the previous sections). This is stated in Lemma C.4
which is similar to Theorem B.1. To state Lemma C.4 let us deﬁne the following.

Deﬁnition C.3. Given C deﬁne the following vectors in Rn. (cid:16)(cid:126)1n
2

vi ∈ c1
vi ∈ c2
1
−1 vi ∈ c3

vi ∈ c1
−1 vi ∈ c2
−1 vi ∈ c3

0

and ((cid:126)y)i :=

((cid:126)x)i :=

.

(cid:17)

(cid:40)

= 1, ((cid:126)pi)j :=

i

1 vj ∈ ci
0 vj /∈ ci

,

Lemma C.4. Let G be a d regular λ-expander, where λ ≤ cd (for some constant c). If
G(cid:48) = PC (G) for a balanced C then with high probability the following holds.

1. The eigenvalues of G(cid:48) have the following spectrum.

dλ.

dλ.

(cid:16)√

3 d − √
(a) λ1 (G(cid:48)) ≥ 2
(b) λn (G(cid:48)) ≤ λn−1 (G(cid:48)) ≤ − 1
(c) |λi (G(cid:48))| ≤ 2λ + O
dλ

2. The following vectors exist.
(a) (cid:126)¯x such that (cid:107)(cid:126)¯x(cid:107)2 = O
(b) (cid:126)¯y such that (cid:107)(cid:126)¯y(cid:107)2 = O

(cid:17) for all 2 ≤ i ≤ n − 2.
3 d − √
(cid:19)
(cid:18)(cid:113) λ
and ¯x + (cid:126)¯x ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
(cid:17).
(cid:19)
(cid:18)(cid:113) λ
(cid:17).
and ¯y + (cid:126)¯y ∈ span(cid:16){ei (G(cid:48))}i∈{n−1,n}
set  to be(cid:113) λ
G(cid:48),i,j =(cid:8)v ∈ ci||NG(cid:48) (v) ∩ cj| ≥(cid:0) 1
3 + (cid:1) dn(cid:9) and
3 − (cid:1) dn(cid:9). By the expander mixing lemma, Lemma G.4,
G(cid:48),i,j =(cid:8)v ∈ ci||NG(cid:48) (v) ∩ cj| ≤(cid:0) 1
(cid:18) 1
(cid:12)(cid:12)(cid:12) ≤(cid:12)(cid:12)(cid:12)EG(cid:48)
(cid:17)(cid:12)(cid:12)(cid:12) =
(cid:16)

Proof. The proof goes by showing an equivalent statement as in Lemma B.2. In this proof we

c−
it follow that for all i (cid:54)= j

(rather than 0.01). Denote c+

G(cid:48),i,j, G(cid:48)
c+

(cid:12)(cid:12)(cid:12)c+

c+
G,i,j, Gcj

(cid:19)

G(cid:48),i,j

+ 

d

d

d

cj

d

3

(cid:12)(cid:12)(cid:12)EG
(cid:16)
(cid:12)(cid:12)(cid:12)c+

≤ d
3

G(cid:48),i,j

(cid:17)(cid:12)(cid:12)(cid:12)
(cid:114) n
(cid:12)(cid:12)(cid:12) + λ

3

(cid:12)(cid:12)(cid:12)c+

G(cid:48),i,j

(cid:12)(cid:12)(cid:12) .

33

The above simpliﬁes to

and similarly

G(cid:48),i,j
Recall the deﬁnition of (cid:126)x, it follows that

(cid:18)

n/3(cid:88)

i=1

(cid:18)

(cid:19)

(cid:19)2

(cid:126)x

i

AG(cid:48)(cid:126)x −

− d
3

G(cid:48),i,j

d

(cid:18) λ
(cid:12)(cid:12)(cid:12) ≤
(cid:18) λ
(cid:12)(cid:12)(cid:12) ≤
(cid:12)(cid:12)(cid:12)c−
(cid:12)(cid:12)(cid:12) +
(cid:19)2
(cid:18) λ

d

,

3

(cid:19)2 n
(cid:19)2 n
(cid:12)(cid:12)(cid:12) +
(cid:33)

3

.

+ (2)2

G(cid:48),1,2

G(cid:48),1,2

(cid:12)(cid:12)(cid:12)c+
(cid:12)(cid:12)(cid:12)c−
≤ d2(cid:16)(cid:12)(cid:12)(cid:12)c+
(cid:32)

≤ d2 n
3

4

≤ 8
3

ndλ .

d

(cid:18)

i=1

(cid:18)
n(cid:88)
(cid:13)(cid:13)(cid:13)(cid:13)AG(cid:48) ¯x −

AG(cid:48)(cid:126)x −

− d
3

(cid:18)

− d
3

(cid:19)

¯x

(cid:19)2

i

(cid:126)x

≤ O

≤ 8ndλ ,

(cid:16)√

(cid:17)

.

dλ

(cid:19)
(cid:13)(cid:13)(cid:13)(cid:13)2

(cid:12)(cid:12)(cid:12)c+

G(cid:48),1,3

(cid:12)(cid:12)(cid:12) +

(cid:12)(cid:12)(cid:12)c−

G(cid:48),1,3

(cid:12)(cid:12)(cid:12)(cid:17)

+ (2d)2 n
3

By similar calculations we can conclude that

and if we normalize then

Similarly we can show equivalent statements with respect to ¯y, ¯1 and {¯pi | i ∈ {1, 2, 3}}. By
applying Lemma B.3 we can conclude an equivalent statement as in Lemma B.4, namely
the following claim.
Claim C.5. Deﬁne Sδ (x) ⊂ {1, . . . , n} to be the set of those indices i for which |λ (G(cid:48))i −
(x)| ≤ δ. The following vectors exist.

• (cid:126)¯1 such that (cid:107)(cid:126)¯1(cid:107)2 ≤ O(
• (cid:126)¯x such that (cid:107)(cid:126)¯x(cid:107)2 ≤ O(
δ
√
• (cid:126)¯y such that (cid:107)(cid:126)¯y(cid:107)2 ≤ O(
Using Claim C.5 and applying the same arguments as in the proof of Theorem B.1 ends

3 d)

and ¯1 + (cid:126)¯1 ∈ span(cid:16){ei (G(cid:48))}i∈Sδ( 2
and ¯x + (cid:126)¯x ∈ span(cid:16){ei (G(cid:48))}i∈Sδ(− 1
and ¯y + (cid:126)¯y ∈ span(cid:16){ei (G(cid:48))}i∈Sδ(− 1
(cid:16)
n(cid:0) λ

(cid:1)2(cid:17).

the proof.
Lemma C.6. It holds that |SB| ≤ O

(cid:17).
(cid:17).
(cid:17).

3 d)

3 d)

√

δ
√

dλ)

dλ)

dλ)

δ

d

34

Proof. Recall the deﬁnition of c+

from the proof of Lemma C.4. It holds that

(cid:12)(cid:12)(cid:12) +

(cid:12)(cid:12)(cid:12)c−

(cid:12)(cid:12)(cid:12)(cid:17)

G(cid:48),i,j

G(cid:48),i,j

G(cid:48),i,j

G(cid:48),i,j

and c−

(cid:16)(cid:12)(cid:12)(cid:12)c+
SB ≤(cid:88)
(cid:18) λ
(cid:19)2

i(cid:54)=j
≤ 4

n .

d

Now we continue with the proof of Theorem C.1.

Algorithm 2 outputs an O(cid:0)n λ

Proof. [Theorem C.1]. Using Lemma C.4 and the proof of Lemma B.16 we conclude that
shows that Algorithm 4 gets O (|SB|)-approximate coloring of G(cid:48). Deﬁne

(cid:1)-approximate coloring of G(cid:48). The proof of Lemma B.15

d

B :=(cid:8)v ∈ V (G(cid:48)) | colC (v) (cid:54)= colCAlg (v)(cid:9) .
(cid:1)2(cid:17) and proof follows.
n(cid:0) λ

(cid:16)

d

The proof of Lemma B.20 shows that |H1| ≤ O (|SB|) and B ⊆ H1. By Lemma C.6 it
follows that SB ≤ O

corollary.

When G has an high degree (with respect to its expansion) we obtain the following

(cid:16) n

(cid:17)-regular λ-expander graph. If λ = O

(cid:16)√

d

(cid:17) then for

Corollary C.7. Let G be an Ω
every balanced C Algorithm 8 colors PC (G).

log n

C.2 Hardness of coloring expander graphs with adversarial plant-

ing

It is well known [19] that 3-coloring 4-regular graphs is NP-hard. In this section we show
the following theorem.

d

Theorem C.8. (Restatement of Theorem 1.2). Let c be a constant equals 4 and d = Ω (1)
be large enough. Let H be an arbitrary c-regular graph with n
vertices that is 3-colorable.
Any (polynomial time) algorithm that (fully) colors d-regular O
an adversarial planted 3-coloring that is balanced can be used to color H.
Proof. Assume the graph H is 3-colorable in such a way that all the color classes are of
the same size (this can be obtained by taking a disjoint union of 3 copies of H), denote
this coloring by PH = P1 ∪ P2 ∪ P3. Let G be any d-regular O

(cid:16)√
(cid:1) n vertices. Let A be an algorithm that colors d-regular O

(cid:17)-expander graphs with
(cid:17)-expander graph with
(cid:16)√
(cid:17)-expander graphs

(cid:0)1 − 1

(cid:16)√

cd

with an adversarial planted coloring. We show that this implies that A colors the disjoint
union H and P (G) (P (G) is an arbitrary balanced planted coloring of G), denote this union
by (P (G) + H). Consider the graph GH obtained as follows. Add 3 sets, S1, S2, S3 of n
vertices to G such that each of the added vertices has d − c unique neighbors in G and all
the vertices from the i-th set have their neighborhood contained in Pi. Replace the induced

3cd

cd

d

d

35

sub-graph on the vertices of(cid:83) Si (it is an independent set) with H (permute the vertices of

H such that the sets {Si} agrees with P ). It is clear from this construction that there exists
an (adversarial) planting such that after it has been applied on GH we obtain (P (G) + H).
The following claim ends the proof.

(cid:16)√

(cid:17) expander.

Claim C.9. GH is a O
Proof. Consider the following inequality from perturbation theory for matrices that holds
for any two symmetric matrices A, N ∈ Rn,n (see, for example, [6])

d

max
i:1≤i≤n

|λi (A + N ) − λi (A)| ≤ max
i:1≤i≤n

|λi (N )| .

(12)

Namely, the inequality shows that by adding a matrix N to a matrix A, the eigenvalues

of A + N change by at most maxi:1≤i≤n |λi (N )|.
We can write the adjacency matrix of GH as
G + A(cid:48)

AGH = A(cid:48)

H + A(cid:48)
S .

cd

Here S is the disjoint union of n

star graphs Sd−c (the graph Sk is a bipartite graph of
(k + 1) vertices with one vertex connected to all the other vertices) and A(cid:48)
is the adjacency
matrix of the graph obtained from G an independent set of vertices were added to it (similarly
for H and S). Note that adding an independent set to a graph only adds zero entries to its
spectrum.
k. Hence, since S is the
disjoint union of star graphs then every i it holds that |λi (AS)| ≤ √
d − c. Since H is c
regular, for every i it holds that |λi (H)| ≤ c. By Inequality 12 it follows that for every
i ∈ [n] it holds that

It is a known fact that for every i it holds that |λi (Sk)| ≤ √

G

|λi (AG)| −(cid:16)

√

d − c

c +

(cid:17) ≤ |λi (AGH )|
(cid:16)√

≤ |λi (AG)| +

Recall that c is a constant and G is a d-regular O
(by construction) vertices of GH have degrees between d and d + 1 (actually, this implies
that d ≤ λ1 (GH ) ≤ d + 1). Hence by Inequality 13 GH is (roughly d-regular) O
expander.

d

d

.

c +

√

(cid:17)

(13)

d − c

(cid:16)
(cid:17)-expander graph and note that
(cid:17)-
(cid:16)√

D Random host and adversarial planting, HR/PA
Section D contains the proofs for the model with a random host graph and an adversarial
planted balanced coloring, namely, HR/PA. Section D.1 proves Theorem 1.4a (a 3-coloring
algorithm for HR/PA). Section D.2 proves Theorem 1.4b (hardness for HR/PA).

36

3-coloring random graphs with adversarial color planting

D.1
We start with a deﬁnition for a distribution for random graphs, following [12],
Deﬁnition D.1. A graph with n vertices G is distributed by Gn,d if each edge is included
in the graph with probability p = d
n−1

, independently from every other edge.

In this section we consider the following planting model. The host graph G ∼ Gn,d is
a random graph on n vertices with average degree d and the planting is adversarial. As
opposed to the previous sections, here our techniques can be applied only to 3 colors (or
less) planting (see Section E.1 for details). Consider the following algorithm.

Algorithm 9 3-coloring for random graphs with adversarial planting
1. Use Algorithm 4 to color PC (G) with a partial coloring ,CAlg.

2. Repeatedly uncolor vertices v ∈ PC (G) with less than (cid:0) 2
less than(cid:0) 1
(cid:1) d neighbors of color l ∈ {1, 2, 3} \ colCAlg (v).

6

3 − 2(cid:1) d neighbors or with

3. Repeatedly color every vertex that has 2 neighbors colored with i, j, (for i (cid:54)= j), by

{1, 2, 3} \ {i, j}.

4. For every vertex that has a colored neighbor create a variable that takes values corre-

sponding to the two remaining colors.

5. For each i ∈ {1, 2, 3} do as follows.

(a) Any uncolored vertex that has no colored neighbor is colored by i.
(b) If there exists a legal coloring for PC (G) that agrees with the above (use any

algorithm that solves 2SAT ) return it.

6. Return the partial coloring of PC (G).

We prove the following theorem.

Theorem D.2. (Restatement of Theorem 1.4a). Let d = ω
be the graph G with an adversarial 3-coloring. With high probability, Algorithm 9 outputs a
legal coloring for PC (G).

n 2

The starting point in the proof of Theorem D.2 is that random graphs are very good

expanders. Speciﬁcally, it is a well known fact that with high probability λ2 (G) = Θ
d
(for example, see [15, 18, 17]). This enables us to employ our techniques from Section C.1

(mainly to apply Theorem C.1) to get an O(cid:0) n

a better coloring of PC (G) than suggested by Theorem C.1, we use speciﬁc properties of
random graphs. Mainly that every pair of vertices has roughly d2
n

common neighbors.

d

3

(cid:16)

(cid:17), G ∼ Gn,d and PC (G)
(cid:16)√
(cid:17)
(cid:1)-approximated coloring for PC (G). To get
(cid:17). Hence, by

(cid:16)√

Proof. (Of Theorem D.2). Recall that with high probability λ2 (G) = Θ
Theorem C.1, it follows that after Step 2 we have a partial coloring of PC (G) that colors

d

37

d

all but O(cid:0) n

(cid:1) vertices exactly as in the planted coloring. Clearly, in Step 3 all the vertices
(cid:17) common neighbors
(cid:1) > 0 vertices in A are neighbors

we color are colored as in the planted coloring. Denote the set of colored vertices by A and
the remaining vertices by B. Denote by B1 ⊆ B the set of vertices with a colored neighbor,
and by B2 ⊆ B the rest. The proof follows by showing that all the vertices in B2 are of the
same planted color. By applying the Chernoﬀ and the union bounds it follows that, with
high probability, for every pair of vertices u, v ∈ V (G) there are Θ
(assume this event holds). By our assumption on d, it follows that given a pair of vertices
u, v of diﬀerent planted color classes at least Θ
of both u, v in G, take one such vertex w. Hence, for every planting, w ∈ A is still a neighbor
of at least one of u, v, say v. But this is a contradiction for v ∈ B2.

(cid:17)− O(cid:0) n

(cid:16) d2

(cid:16) d2

n

n

d

2 ≤ d ≤ n 2

When n 1

(cid:16) n2

Note that when d ≥ √

3 it holds that all pairs have a lot of common neighbors and Theo-
rem D.2 does not give any advantage when that is the case. The following generalization to
Theorem D.2 deals with that regime.
Theorem D.3. Let G ∼ Gn,d and PC (G) be the graph G with an adversarial 3-coloring.
With high probability, Algorithm 9 outputs a partial coloring for PC (G) that is legal on the
colored vertices such that at most ˜O

(cid:17) vertices are not colored.
n then Theorem C.1 gives a better guarantee of O(cid:0) n
(cid:1)-approximated coloring).
(cid:17). Hence, by
(cid:1) vertices exactly as in the planted coloring. Clearly, in Step 3 all the vertices
(cid:1) and let

all but O(cid:0) n
neighbor, and by B2 ⊆ B the rest. Fix an arbitrary set A(cid:48) ⊂ V (G) of size n(cid:0)1 − 1

we color are colored as in the planted coloring. Denote the set of colored vertices by A
and the remaining vertices by B. Denote by B1 ⊆ B the set of vertices with a colored
B(cid:48) = V (G) \ A(cid:48).

Proof. (Of Theorem D.3). Recall that with high probability λ2 (G) = Θ
Theorem C.1, it follows that after Step 2 we have a partial coloring of PC (G) that colors

n then indeed we get advantage from applying Theorem D.3 (and

when d <

(cid:16)√

√

d3

d

d

d

d

For every vertex w ∈ A(cid:48) it hold that

Pr

G∼Gn,d

[|NG (w) ∩ A(cid:48)| ≥ 2] = 1 − (1 − p)

n

d − n
d

p (1 − p)

n

d −1

= Θ (1) .

Consider the set C(cid:48) = {w ∈ V (G) | |N (w) ∩ A(cid:48)| ≥ 2}. By applying the Chernoﬀ bound

it follows that

Pr [|C(cid:48)| < 0.1n] ≤ 2−Ω(n) .

Condition on the event that |C(cid:48)| ≥ 0.1n. For every vertex v ∈ B(cid:48) deﬁne the set Bv,A(cid:48) =

{u ∈ B(cid:48) | (cid:64)w ∈ A(cid:48) s.t. {u, v} ⊆ NG (w)}. It holds that for any t ≥ 0

Pr [|Bv,A(cid:48)| ≥ t] ≤ n
d

(cid:33)0.1n

(cid:32)
1 − t(cid:0) n
(cid:1)2

d

− t
d )2 0.1n
( n

.

≤ n
d

e

38

Let η be some constant and Bad be the following event

, ∃v ∈ B(cid:48) s.t. |Bv,A(cid:48)| ≥ n2
By the the above and the union bound it follows that for every η > 1

∃A(cid:48) ⊆ V (G) s.t. |A(cid:48)| =

n
d

d3 logη d .

[Bad] ≤

Pr

G∼Gn,d

(cid:18) n

(cid:19)(cid:32)

n/d
≤ eΘ( n

2−Ω(n) +

n2
d2 e
d logη d) .

− t
( n

d )2 0.1n(cid:33)
(cid:1) ≤ (cid:0)e n

k

k

The last inequality follows from the approximation (cid:0)n

d log d)−Θ( n

(cid:1)k, and the last term

approaches zero as n grows.

Assume that no legal coloring of PC (G) was found in Step 5. It follows that the set
B2 was colored by C with at least two colors. Let u be a vertex such that colC (u) = i.
Let j (cid:54)= i be any other color class in C. Suppose J = |{v | colC (v) = j}| ≥ n2
d3 logη d then,
conditioned on the complement event Bad, there exist a vertex v ∈ J and w ∈ A such that
{u, v} ⊆ NG (w). Since u, v are in diﬀerent color classes it follows that at least one of them
is not in B2, as no meter what colC (w) , at least one of u, v remains a neighbor of w in
PC (G), which is a contradiction. It follows that the remaining set of uncolored vertices is
of size at most 3 n2

d3 logη d.

D.2 Hardness of 3-coloring random graphs with adversarial planted

3-coloring

The following deﬁnition can be found in [3] (see Chapter 4).
Deﬁnition D.4. [balanced graph]. Given a graph H, denote by α its average degree. A
graph H is balanced if every induced subgraph of H has an average degree of at most α.
Theorem D.5. (Restatement of Lemma 2.7). For 0 <  ≤ 1
and 3 < α < 4, suppose
dα ≤ 2. Let H be an arbitrary balanced graph on k vertices with an
that k2d2
average degree α and let G ∼ Gn,d be a random graph. Then with probability at least 1 − 4
(over choice of G), G contains a set S of k vertices such that:

n ≤  and k4nα−2

7

1. The subgraph induced on S is H.
2. No two vertices of S have a common neighbor outside S.

be the edge probability in G. Suppose for simplicity (an assumption
Proof. Let p = d
n−1
that can be removed) that k divides n. Partition the vertex set of G into k equal parts of
size n/k each. Vertex i of H will be required to come from part i. A set S with such a
property is said to obey the partition.

Let X be a random variable counting the number of sets S obeying the partition that
satisfy the theorem. Let Y be a random variable counting the number of sets S obeying the
partition that have H as an edge induced subgraph (but may have additional edges, and
may not satisfy item 2 of the theorem).

39

(cid:17)k

(cid:16) n

(cid:18) dα
with probability at least 1−(cid:0)k
(cid:1) d2
S (which happens with probability at least 1 −(cid:0)k
(cid:19)

(cid:1) d

E[Y ] =

(cid:18)

2 =

k

p

αk

n

n

2

2

k2nα−2

(cid:19) k

2

.

E[X] ≥ E[Y ]

1 − k2d2
n

≥ (1 − )E[Y ].

A set S in Y contributes to X if it has no internal edges beyond those of H (which happens
) and no two of its vertices has a common neighbor outside

). Consequently:

2

k
2 .

t

k

t

2

t .

t

dα

(cid:1)t

k2nα−2

≥ α
2

− α|V (GH∩H(cid:48))|

2 . The number of ways to choose

(cid:1)(cid:12)(cid:12) ≥ α|V (G)|

p αt
We have:
1. µk < E[Y ].

Hence, the probability that H(cid:48) is realized is at most p αt

Now let us compute E[Y 2]. Given one occurrence of H, consider another potential

occurrence H(cid:48) that diﬀers from it by t vertices. Since H is balanced graph then

(cid:12)(cid:12)E(cid:0)GH(cid:48)\H
the t other vertices is (cid:0)k
(cid:1)(cid:0) n
(cid:0)k

(cid:1)(cid:12)(cid:12) +(cid:12)(cid:12)E(cid:0)GH(cid:48)\H , GH
(cid:1)t. Hence the expected number of such occurrences is µt ≤
(cid:1)(cid:0) n
(cid:1) t

2 =(cid:0)k
(cid:1)(cid:0)
E[Y ] ≤ 2k(cid:0)
2. (cid:80)
3. (cid:80)k−1
E[Y ] ≤ (cid:80)k−1
dominates (when dα ≥ 2k4nα−2) and hence the sum is at most roughly(cid:113) k4nα−2
dα ≤ 2. Then(cid:80) µi ≤ (1 + ) E[Y ]. Hence E[Y 2] ≤ (1 + ) (E[Y ])2. Recall

(cid:16) 16k2nα−2
(cid:1) t−k
2 = (cid:80)k−1

Recall that k4nα−2
that X ≤ Y and that E[X] ≥ (1 − )E[Y ]. Hence E[X 2] ≤ 1+
(the last inequality holds because  ≤ 1
By Chebychev’s inequality we conclude that P r[X ≥ 0] ≥ 1 − σ2[X]

(1−)2 E[X]2 ≤ (1 + 4)E[X]2
). We get that σ2[X] = E[X 2] − E[X]2 ≤ 4E[X]2.
E[X]2 ≥ 1 − 4.

2 . The term t = k − 1

(cid:1) −k
kk−t(cid:0)

(cid:1) t−k

(cid:17) k

k2nα−2

k2nα−2

k4nα−2

t≥ k

2

t≥ k

2

t≤ k

2

t≥ k

2

µt

µt

.

dα

dα

4 =

4 .

dα

(cid:0)

dα

dα

7

Remark: The proof of Theorem D.5 shows that the number of copies of H in G is likely
to be close to its expectation, and hence large (this will be useful in the next section). Also,
simple modiﬁcations to the proof can be used in order to show the existence of many disjoint
copies (where the number grows as  decreases).
there is some ρ > 0 such that the
Corollary D.6. For every 0.467 < δ < 1
following holds for every large enough n. Let H be an arbitrary balanced graph with average
degree 3.75 on k = nρ vertices. Let G be a random graph on n vertices with average degree
d = nδ (which we refer to as Gn,d). Then with probability larger than 1 − 4 (over choice of
G), G contains a set S of k vertices such that:

and  < 1

2

8

40

1. The subgraph induced on S is H.
2. No two vertices of S have a common neighbor outside S.

(cid:104)√

(cid:105)

n

4

Proof. In Theorem D.5, choose  < 1
dα ≤ 2. Speciﬁcally, one may choose k = min
k4nα−2

, α = 3.75, and choose k such that k2d2
= nΩ(1).

αδ−α+2

√

n

1−2δ

2

,

8

n ≤  and

Theorem D.7. (Restatement of Lemma 2.6). Coloring a balanced graph with an average
degree 3.75 with a balanced 3-coloring is NP-hard.
Proof. It is known that 3-coloring 4-regular graphs is NP-hard, see [19] (and actually, with
slight modiﬁcations, this proof shows it as well). Therefore it is enough to show that there
exists a polynomial time reduction R such that for any given 4-regular graph H it holds
that

1. R (H) is a balanced graph with an average degree of 3.75.
2. H is a 3-colorable graph if and only if R (H) is 3-colorable and given a (legal) 3-coloring

to R (H) one can (legally) 3-color H in a polynomial time.

3. If R (H) is 3-colorable then it has a balanced coloring.

The reduction is as follows. For every vertex v of H consider its four edges e1, e2, e3, e4,
replace v by the graph in Figure 1 (denote this graph by R (H, v)) and then connect edge
ei to vertex ui. Note that the average degree of R (H) is 3.75. Also note that in any legal
3-coloring of R (H) the vertices vi, ui get all the same color and the second assertion of R
follows.
We show that R (H) is a balanced graph. For a vertex v of H let R (H, vi) be the set
{vi, ui, Ai, Bi}. Consider a subset S∗ of the vertices of R (H) such that the average degree
on the induced subgraph R (H)S∗ is maximized to α∗. Let α∗ (R (H, vi)) be the average
degree of the vertices R (H, vi) ∩ S∗ in R (H)S∗. As the sets R (H, vi) are disjoint and their
union is the vertex set of R (H) it follows that α∗ is upper bounded by α∗ (R (H, vi)) for
some vi. But for every vi and S∗ we are averaging at most 4 vertices of degree bounded by
4, where at least one of them is of degree bounded by 3. It follows that

α∗ ≤ max

vi

α∗ (R (H, vi)) ≤ 3 ∗ 4 + 3

4

= 3.75 .

To show the third assertion of R it is enough to take a disjoint union of 3 copies of the

above construction (note that the disjoint union of two balanced graphs is balanced).

for every  > 0, 3-coloring of balanced graphs with average degree (cid:0) 10

Remark: The construction and analysis of Theorem D.7 can be modiﬁed to show that

3 + (cid:1) is NP-hard.

Every vertex vi in the graph of Figure 1 is replaced by a 4-vertex gadget with ﬁve edges of
structure similar to the graph induced on v1, A1, B1, v2, with the v vertices as endpoints of
the gadget. For example, if v2 is replaced then one endpoint is connected to A1 and B1,
and the other endpoint is connected to A2 and B2. Observe that the two endpoints of the
gadget must have the same color in every legal 3-coloring. Each such replacement increases
the number of vertices by three and the number of edges by ﬁve, hence bringing the average

41

degree closer to 10
3
and A2 becomes Ω( 1
details omitted.

. Repeating this replacement recursively (until the distance between A1

 )) gives a balanced graph with average degree below(cid:0) 10

Figure 1: The construction of Theorem D.7.

3 + (cid:1). Further

For the sake of intuition, we temporarily restrict attention to algorithms that we refer

to as decomposable (a restriction that will be lifted later).

Deﬁnition D.8. An algorithm A for 3-coloring is decomposable if for every disconnected
input graph G, algorithm A is applied independently to each of G’s connected components.
Natural 3-coloring algorithms are decomposable. In fact, we are not aware of any coloring
algorithm that is not decomposable. Moreover, in works on random and semi-random models
of inputs, it makes sense to require coloring algorithms to be decomposable, as an algorithm
that is not decomposable would presumably involve aspects that are very speciﬁc to the
model and would not generalize to other models.

One can imagine that in some contexts the use of algorithms that are not decomposable
may oﬀer advantages. This may happen if the input graph is generated in such a way that
the structure of one component contains hints as to how to color other components. Perhaps
the simplest form of a hint is the following. Suppose that the input graph is known to be
generated with a balanced coloring (in which each color class is of size n/3), and furthermore,
is known to be generated such that in each component the 3-coloring is unique. Then for
an input graph with two components, once one colors the ﬁrst component, one knows how
many vertices of each color class there should be in the second component. This simple
form of a hint saves at most polynomial factors in the running time, because it involves only

42

O(log n) bits of information, and hence the hint can be guessed. Nevertheless, it illustrates
the point that under some generation models of input graphs, it is possible that algorithms
that are not decomposable will be faster than algorithm that are decomposable.

Here we consider 3-coloring Gn,d with an adversarially planted balanced 3-coloring. We
show that given the decomposable-algorithm assumption, a hardness result can be derived.
In Section D.3 a full proof is given without the decomposability assumption.

2

Theorem D.9. Suppose that for some 0.467 < δ < 1
algorithm that with probability at least 1
2
3-colors Gn,d with an adversarially planted balanced 3-coloring. Then P=NP.
Proof. By Theorem D.7 it follows that 3-coloring balanced graphs of average degree 3.75 is
NP-hard.

and d = nδ there is a decomposable
(over choice from Gn,d and for every adversary)

Suppose there was an algorithm A for 3-coloring Gn,d with an adversarially planted
balanced 3-coloring as in the statement of the theorem. Consider now an arbitrary balanced
graph H with average degree 3.75 of size k = nρ (where ρ is as in Corollary D.6), and
associate with it an adversary H(cid:48). On input a random graph G from Gn,d, the graph has
of satisfying the conclusion of Theorem D.5. The adversary H(cid:48)
probability more than 1
2
(who is not computationally bounded) does the following.

1. If G does not satisfy the conclusion of Theorem D.5 with respect to H, then the

adversary H(cid:48) plants in it a random balanced coloring.

2. If G satisﬁes the conclusion of Theorem D.5 with respect to H then the adversary H(cid:48)

leaves H untouched and then:

(a) If H is 3-colorable, for each color class of H it colors its neighborhood outside H
with the same color as in H, and then completes to a balanced planted 3-coloring
at random. Observe that this planted coloring disconnects H from the rest of
G, because all original edges between H and the rest of G are between pairs of
vertices of the same color.

(b) If H is not 3-colorable, the adversary removes all edges between H and the rest

of G, and randomly produces a balanced planted coloring of the rest of G.

Case 2 above happens with probability greater than 1
2

, by Corollary D.6.

Suppose that H is not 3-colorable (case 2(b)). Then A must fail to 3-color H.
Suppose now that H is 3-colorable (case 2(a)). Because A is decomposable, it must color
H without seeing the rest of G. Because A succeeds for every adversary on at least half the
inputs (over choice from Gn,d), and for adversary H(cid:48) over half the inputs generate H, A
must succeed to 3-color H. (We assumed here that A is deterministic. If A is randomized
In this case
then choose  < 1
the conclusion will be that NP has randomized polynomial time algorithms with one sided
error.)

and then A must succeed with probability at least 2

Hence the output of A(H) determines whether H is 3-colorable. As this applies to
every H, and the sizes of H and G are polynomially related, this implies that A solves in
polynomial time an NP-hard problem, implying P = N P .

16

.

3

43

There are two weaknesses of Theorem D.9. One is that it requires d > n0.467: at lower
densities the input graph is unlikely to contain a given H with average degree 3.75. The
degree d can be lowered to roughly n0.4 using the remark following the proof of Theorem D.7.
However, it cannot be lowered below n1/3 (using our techniques), because of Proposition 2.4.
The other weakness is that it requires A to be decomposable. The decomposability weakness
can be overcome using the following approach.

Suppose there was an algorithm A for 3-coloring Gn,d with an adversarially planted
over choice of G (for every
balanced 3-coloring, that succeeds with probability at least 1
adversary). Given a 3.75-balanced graph H on k vertices, give A as input a graph G(cid:48)
2
composed of two disjoint parts. One is H and the other is a random subgraph of size n − k
of a random graph from Gn,d with a randomly planted balanced 3-coloring. This would
prove Theorem D.9 if the distribution generated by this process is statistically close to the
one generated by the adversary H(cid:48). The techniques in [22] can be extended in order to prove
statistical closeness and this is done in the next section.

D.3 Hardness result without the decomposable-algorithm assump-

tion

Let H be an arbitrary balanced graph with average degree α and k vertices, for α = 3.75.
Let G be a graph with n vertices. Assume that k divides n (this assumption can be removed)
and consider a ﬁxed partition of the vertex set of G to k disjoint subsets of vertices, each
. Let CH (G) be the number of induced sub-graphs of G that are isomorphic to H
of size n
k
such that they obey the partition (see the deﬁnition in the proof of Theorem D.9) and let
EH be EG∼Gn,d [CH (G)].

α

2 k (1 − p)(k

2)− α

2 k ,

p

(14)

Note that

EH =

where p = d
n−1

.

(cid:16) n

(cid:17)k

k

We consider the following distribution of random graphs with the graph H being planted

as an induced sub-graph.
Deﬁnition D.10. A graph G with n vertices is distributed by Gn,d,H if it is created by the
following random process.

1. Take a random graph G(cid:48) distributed by Gn,d.
2. Choose a random subset K of k vertices from G(cid:48) that obeys the partition.
3. Replace the induced subgraph of G(cid:48) on K by H (we say that H is randomly planted

in G(cid:48)).

Given a graph G, we denote by p (G) the probability to output G according to Gn,d and

by p(cid:48) (G) the probability to output G according to Gn,d,H.
Claim D.11. For any given graph G it holds that p(cid:48) (G) = CH (G)

p (G).

EH

44

Proof. Let e be the number of edges in G and consider p(cid:48) (G). Out of the(cid:0) n

(cid:1)k options to

choose K (in Gn,d,H) only CH (G) options are such that the induced sub graph on K is H
so that the resulting graph could be G. Given that we chose a suitable K, the rest of the
edges (e − α

2 k) should agree with G. It follows that

k

p(cid:48) (G) =

CH (G)

2 k (1 − p)(n

2)−(k

2)−e+ α
2 k

(cid:1)k pe− α

(cid:0) n

k

=

=

CH (G)

EH

CH (G)

EH

pe (1 − p)(n

2)−e

p (G) .

The second equality follows from Equation 14.

Recall the deﬁnition of the random variables X, Y from the proof of Theorem D.9.

Moreover, the following claim follows from the proof of Theorem D.9.
Claim D.12.

σ2 [X] = 4E [X]2 .

2

Theorem D.13. (Restatement of Theorem 1.4b). Let G ∼ Gn,d be a random graph, where
d = nδ for 0.467 ≤ δ < 1
, and let γ be an arbitrary small constant. If there exists a ran-
domized algorithm that colors G ∼ Gn,d after an adversarial color-planting with probability
γ (over the distribution Gn,d and the randomness of the algorithm) then RP = N P .
Proof. Consider  = γ
= nΩ(1) (so that the
conditions of Corollary D.6 and Theorem D.5 hold). Assume that there exists an algorithm
A as in the theorem. The probability measure of graphs from Gn,d that A colors with respect
to all possible color planting with probability (over the randomness of A) at least γ
is at
. This holds by averaging and because we can consider an adversary that, given any
least γ
2
input graph, simulates A and try all possible color planting in order fail A with the largest
probability (over the randomness of A).

and set k = min

(cid:104)√

αδ−α+2

(cid:105)

√

1−2δ

n

n

100

2

2

,

4

By Chebychev’s inequality and Claim D.12 it holds that

Pr

G∼Gn,d

[X ≤ ρE [X]] ≤

4

(1 − ρ)2 .

Note that X ≤ CH (G) ≤ Y . By the proof of Theorem D.5 it hold that

E [CH (G)] ≤ E [Y ] ≤ 1
1 − 

E [X] .

Hence

(1 − ρ)2 .
. Therefore that the probability
measure of graphs that A colors (with probability, over the randomness of A, of at least

[X ≤ ρ (1 − ) E [CH (G)]] ≤
2 ρ ≥ 1

Set ρ to be such that

4 γ and that 1

(1−ρ)2 ≤ 1

G∼Gn,d

Pr

4

10

4

45

γ
2

11 γ.

) is at least 1

for every color planting) with X ≥ ρ (1 − ) E [CH (G)] is at least 1

4 γ. By Claim D.11 it
follows that the probability measure with respect to Gn,d,H of graphs that A colors (after
any adversarial planting with probability at least γ
2

2 γρ (1 − ) ≥ 1

has a balanced 3-coloring. Now we show that we can use A to color H.

Fix H to be an arbitrary balanced graph with average degree 3.75 with k vertices that
Given G ∼ Gn,d,H we consider the following distribution ˜GH for graphs with an adver-
sarial coloring. If any vertex that is not on the induced planted (by Gn,d,H) graph H has
two or more neighbors in the planted induced graph, denote this event by S1, then color
G arbitrarily. Otherwise for the planted graph use a coloring that agrees with the coloring
of H. For the rest of the vertices, if a vertex has a neighbor in the planted graph color
it by the same color of its neighbor and the rest of the vertices are colored in such away
that the coloring is balanced. More speciﬁcally, from all the balanced coloring we choose
one at random (again, if there is no possible balanced coloring then we color G arbitrarily).
then (1 + c1) d neighbors with probability at most n2−Ω(c1d) ≤ γ/44. Hence there are such
balanced colorings with high probability. Denote the event that no such balanced coloring
n ≤ γ/44. A graph
is possible by S2. The event S1 happens with probability at most k2 d2
from ˜GH is called good if the events S1, S2 do not hold. Given that G is a good graph, all
possible balanced coloring on G \ H are equally distributed.

(cid:1) then, by the union bound and the Chernoﬀ bound, no vertex in G has more

Since k = o(cid:0) n

d

If an adversary knows the subset S of vertices that the distribution Gn,d,H plants H
on then the distribution ˜GH can be created by this adversary. A subtle point is that the
adversary can guess S. Given a graph G ∼ Gn,d,H the adversary can calculate for every
subset S(cid:48) (that obeys the partition) that satisﬁes GS(cid:48) = H what is the probability that S(cid:48)
is the planted subset, then choose a subset S(cid:48) with the calculated probability and behave
as S(cid:48) is the planted subset. It follows that the distribution after the above preprocessing is
the same distribution as if the adversary knows S.

In total, the probability measure of good graphs in ˜GH that A can color (with probability,
over the randomness of A, of at least γ
for every color planting) is at least γ/22. The key
point is that the conditional, on being good, distribution of graphs ˜GH can be sampled in
a polynomial time by taking the vertex disjoint union of the graph H and a random graph
from Gn−k,d with a random balanced planted coloring (and apply an appropriate random
permutation). If we run algorithm A on Ω
we can sample eﬃciently) then with high probability A will color H (that is a graph with a
poly (n) vertices) with high probability. By Theorem D.7 the proof follows.

(cid:17) random instances from ˜GH (which again

(cid:16) 44

γ2

2

D.4 Proof of Proposition 2.4
Proposition D.14. (Restatement of Proposition 2.4). Let Q be an arbitrary class of graphs.
Then either there is a polynomial time algorithm for solving 3-colorability on every graph in
Q, or Q contains graphs that are unlikely to appear as subgraphs of a random graph from
Gn,p, if p = n−2/3.
Proof. We say that a class Q is 3-sparse if every graph in Q has average degree at most 3, and
furthermore, has no subgraph of average degree above 3. There are two cases to consider.
Suppose that Q is 3-sparse. In this case, there is a polynomial time algorithm that solves
3-colorably on all graphs from Q. Let Q ∈ Q be an arbitrary such graph. Iteratively remove

46

from Q vertices of degree less than 3 until no longer possible, and let Q(cid:48) be the remaining
graph. Every 3-coloring of Q(cid:48) can be extended to Q by inductive coloring. Hence it remains
to 3-color Q(cid:48). If Q(cid:48) is empty then we are done. If Q(cid:48) is nonempty, then 3-sparseness of Q
implies that Q(cid:48) is 3-regular. In this case, Brook’s theorem [9] (see [28] for an algorithmic
version of it) implies that we can decide whether Q(cid:48) is 3-colorable, and if so, 3-color it in
polynomial time.
Suppose that Q is not 3-sparse. Then it contains some graph Q and within it some
subgraph Q(cid:48) such that Q(cid:48) contains at least 3k
2 + 1 edges, where k denotes the number of
vertices in Q(cid:48). The probability that a random Gn,p graph with p = n−2/3 contains an
induced copy of Q(cid:48) is at most nkp3k/2+1 = p = n−2/3.

(cid:1)2

d

algorithm that ﬁnds a b-partial coloring for b = Ok((cid:0) λ

E Extending the results to more than 3 colors
In this section we elaborate on our results when using k ≥ 4 colors. When stating our results
we shall use the notation Ok(.) to denote hidden constants whose value may depend on the
number k of colors. We derive the following theorems.
Theorem E.1. (Generalization of Theorem 1.1). For any positive k there exists a constant
ck, such that if the average degree in the host graph satisfy ck < d < n then the following
holds. In all four models (HA/PA, HA/PR, HR/PA, HR/PR) there is a polynomial time
n). For the models with random
host graphs (HR) and/or random planted colorings (PR), the algorithm succeeds with high
probability over choice of random host graph H and/or random planted coloring P .
Theorem E.2. (Generalization of Theorem 1.2). For any positive k there exists a constant
Ck, such that the following holds. In the HA/PA model, for every d in the range Ck <
d < n1− (where  > 0 is arbitrarily small), it is NP-hard to k-color a graph with a planted
√
k-coloring, even when λ = Ok(
Theorem E.3. (Generalization of Theorem 1.3). For any positive k there exist constants
0 < ck < 1 and Ck > 1, such that the following holds. In the HA/PR model there is a
polynomial time algorithm with the following properties. For every d in the range Ck < d ≤
n − 1 and every λ ≤ ckd, for every host graph within the model, the algorithm with high
probability (over the choice of random planted k-coloring) ﬁnds a legal k-coloring.
Theorem E.4. (Generalization of Theorem 1.4b). Let G ∼ Gn,d be a random graph, where
d = nδ for 0.467 ≤ δ < 1, let k ≥ 4, and let γ be an arbitrary small constant. If there
exists a randomized algorithm that k-colors G ∼ Gn,d after an adversarial color-planting
with probability γ (over the distribution Gn,d and the randomness of the algorithm) then
RP = N P .

d).

It turns out that theorems 1.1, 1.2, 1.3 and 1.4b extend to k ≥ 4. Theorem 1.4a does

not extend to k ≥ 4 as this would contradict Theorem E.4.

Theorems 1.1, 1.2 and 1.3 follow in a rather straightforward way from our proofs of the

respective theorems 1.1, 1.2 and 1.3. We provide some more details.

47

We start with the generalization of Theorem B.1 to k ≥ 4. The statement of Theo-
rem B.1 uses two predeﬁned vectors (¯x and ¯y) that encodes the planted 3-coloring (see
Deﬁnition A.7). Here we describe how to deﬁne k − 1 vectors when k ≥ 4.

Let Pk(G) be the graph G after a random k-color-planting has been applied. Let
V1, V2, ..., Vk be a partition of V induced by the color planting and let P be a function
that maps each vertex to its color class. Let Pk = 1k×k − Ik be the matrix obtained by the
all-one matrix minus the identity matrix and let the vectors p0, p1, ..., pk−1 be an orthogonal
set of eigenvectors of P where p0 is the all-one vector. For a vector (cid:126)x we denote by (cid:126)x(j) its
j-th coordinate and recall that we denote by ¯x the vector
Deﬁnition E.5. We deﬁne the following k vectors (cid:126)x0, . . . , (cid:126)xk−1 in Rn. For each j, 0 ≤ j ≤
k − 1, the vector (cid:126)xj gives to coordinate i the value pj(P (i)).

(cid:126)x(cid:107)(cid:126)x(cid:107)2

.

One can check that Deﬁnition A.7 is an instantiation of Deﬁnition E.5 in the case k = 3.
Moreover Theorem E.6 bellow follows by a direct generalization of the proof of Theorem B.1.
Theorem E.6. Let G be a d regular λ-expander and Pk (G) be the graph G after a random
k-color planting, where λ ≤ Θ(d). With high probability the following holds.

1. The eigenvalues of Pk (G) have the following spectrum.

(a) λ1 (Pk (G)) ≥(cid:0)1 − 2−Ω(d)(cid:1) k−1
(cid:16)
(cid:17).
(cid:17) for all 2 ≤ i ≤ n − k + 1.
(cid:16)√
(cid:17) and ¯xj +(cid:126)¯xj ∈ span(cid:16){ei (Pk(G))}i∈{n−k+2,...,n}
(cid:16) 1√

(b) λn−k+2 (Pk (G)) ≤ − 1
k d
(c) |λi (Pk (G))| ≤ 2λ + Ok
2. The following vectors exist.

such that(cid:13)(cid:13)(cid:126)¯xj

(cid:13)(cid:13)2 = Ok

d

k d.
1 − k√

d

d

(cid:17), for

(cid:126)¯xj
1 ≤ j ≤ k − 1.

Lemma C.4 is a variant of Theorem B.1 for the case of adversarial balanced 3-coloring.
Lemma C.4 can be generalized in a similar manner as the above for the case of adversarial
balanced k-coloring.
We now present a clustering algorithm (which is a generalization of Algorithm 2) to the
case planted k ≥ 4-coloring. We chose here a randomized version due to improvement in
the running times over the deterministic version.

48

Algorithm 10 Random Spectral k-Clustering
Input: A graph Pk(G) and three positive constants c ≤ 1
depend on k).

2

, c1

k

and c2

k

(the last two constants

1. Compute the eigenvectors en−l := en−l (Pk(G)) for 0 ≤ l ≤ k − 2.
2. Choose uniformly at random a set of k vertices v1, v2, ..., vk ∈ V (Pk(G)).
3. If there are 1 ≤ i < j ≤ k satisfying

l=k−2(cid:88)

(cid:16)

(cid:17)2

(en−l)vi

− (en−l)vj

<

4
c1
kn

.

go to Step 2.

l=0

4. Put a vertex u ∈ V (G(cid:48)) in Si if it holds that

(cid:0)(en−l)u − (en−l)vi
5. If for every i = 1, 2, ..., k it holds that |Si| ≥(cid:16) 1

l=k−2(cid:88)

l=0

(cid:1)2

<

1
c1
kn

.

(cid:17)

n then output a coloring C
of G(cid:48) that sets colC (u) = i for every 1 ≤ i ≤ k and u ∈ Si, and colors the remaining
vertices (if there are any) arbitrarily. Otherwise go to Step 2.

c2
kd2c

k − 1

The following lemma shows that under suﬃcient conditions the above clustering algo-
rithm, Algorithm 10, outputs a good approximated coloring. These conditions are stated in
the lemma and by Theorem E.6 these conditions hold with high probability.

k

Lemma E.7. (Generalization of Lemma B.16). For any positive k there exist constants c1
and c2
such that the following holds. Let Pk(G) be as above and c be a positive constant.
Suppose that the following vectors exist for 0 ≤ l ≤ k − 1 (recall Deﬁnition E.5): (cid:126)¯x(l) such

that (cid:107)(cid:126)¯xl(cid:107)2 = Ok (d−c) and ¯xl + (cid:126)¯xl ∈ span(cid:16){ei (Pk(G))}i∈{n−k+1,n}
(cid:13)(cid:13)(cid:126)¯x(l)

(cid:17). Then Algorithm 10
(cid:0)nd−2c(cid:1)-approximated coloring. The expected running time of Algorithm 10
(cid:17). Thus running Algorithm 10 with c = 1
(cid:16) 1√
(cid:1)-approximated

An example of how to use Lemma E.7 is as follows. For Pk(G) by Theorem E.6 we have

(cid:13)(cid:13)2 = Ok

outputs an Ok
is ˜O( kk

k! n).

results in Ok

k

(cid:0) n

d

2

d

coloring.

The analysis of Algorithm 10 running time is discussed in the poof of Lemma B.16. We

note that one can show an expected running time of ˜O( kk

k! + n) for Algorithm 10.

49

E.1 Hardness result for random graphs with adversarial 4-color

planting

In this section we extend Theorem D.13 to the case of adversarial planting with k > 3 colors.
For simplicity, we present the proof only for the case k = 4, but it is not diﬃcult to extend
it to any constant k.

Let us begin with an overview of the proof. Recall the overview of the proof of Theo-
rem 1.4b given in Section 2.5, and the terminology that was used there. The hardness of
3-coloring in HR/PA was by reduction from the class Q of balanced graphs with average
degree 3.75, on which 3-coloring is NP-hard. For this class, 4-coloring is easy (by inductive
coloring), but nevertheless we shall use the same class Q in the hardness result for 4-coloring.
We have already seen (in Lemma 2.7) that for every graph Q ∈ Q of size n, random graphs
of suﬃciently high average degree nδ are likely to contain Q as a subgraph. For hardness
of 3-coloring, given a random Gn,nδ host graph H, the adversary plants in H a 3-coloring
that isolates a copy of Q. For hardness of 4-coloring, it is useless to plant in H a 4-coloring
that isolates a copy a copy of Q, because 4-coloring of Q is easy. Instead, the plan is for the
adversary to plant in H a 4-coloring in which all neighbors of Q outside Q have the same
color. This leaves only three colors for Q, and hence 4-coloring of H would imply 3-coloring
of Q.
To make this plan work, one needs every vertex of Q to have at least one neighbor in
H−Q, and all vertices of Q combined should have less than n/4 neighbors in H−Q. Luckily,
for a random copy of Q in H, both these properties happen with overwhelming probability
as long as  + δ < 1. Consequently, the hardness result for 4-coloring has the following
two advantages over the one for 3-coloring (that required vertices in Q not to have common
2 − . In particular,
neighbors in H − Q). One is that there is no need to require that δ < 1
this shows that the positive results of Theorem 1.4a do not hold when k ≥ 4. The other
advantage is that the fraction of host graphs H ∈R Gn,nδ on which the reduction fails is
smaller than the corresponding fraction in the proof of Theorem 1.4b. (For simplicity, we
shall not address this point in our proofs.)

There is a property that is required for hardness of 4-coloring but was not needed for the
hardness of 3-coloring. That property is that after the adversary plants the 4-coloring, we
need that in every 4-coloring of G, there is some color c such every vertex of Q has at least
one neighbor in H − Q of color c. This ensures that every 4-coloring of G indeed 3-colors
Q. The way we show that this property holds is through Lemma E.11 that shows that in a
suﬃciently dense random graph, a planted random k-coloring is almost surely the only legal
k-coloring of the resulting graph.

This completes the overview of our proof approach.
We start with a variant of Theorem D.5.

Theorem E.8. For 0 <  ≤ 1
dα ≤ 2. Let
H be an arbitrary balanced graph on k vertices with an average degree α and let G ∼ Gn,d
be a random graph. Then with probability at least 1 − 4 (over choice of G), G contains a
set S of k vertices such that:

and 3 < α < 4, suppose that k2d

n ≤  and k4nα−2

7

1. The subgraph induced on S is H.
2. Each vertex of S has a neighbor outside S.

50

3. The total sum of degrees of vertices in S is at most n−k

4

.

Proof. Let p = d
be the edge probability in G. Suppose for simplicity (an assumption
n−1
that can be removed) that k divides n. Partition the vertex set of G into k equal parts of
size n/k each. Vertex i of H will be required to come from part i. A set S with such a
property is said to obey the partition.

Let X be a random variable counting the number of sets S obeying the partition that
satisfy the theorem. Let Y be a random variable counting the number of sets S obeying the
partition that have H as an edge induced subgraph (but may have additional edges, and
may not satisfy item 2 of the theorem).

(cid:16) n

(cid:17)k

k

(cid:18) dα

(cid:19) k

2

E[Y ] =

αk

2 =

p

k2nα−2

.

A set S in Y contributes to X if the following conditions hold
1. It has no internal edges beyond those of H (which happens with probability at least

1 −(cid:0)k

(cid:1) d

).

2

n

2. Every vertex of it has a neighbor outside S (which happens with probability at least

1 − ke− dn
4 ).

3. The total sum of degrees of vertices in S is at most n−k

n2−Ω(c1d). Since k = o(cid:0) n

. By the union and the Chernoﬀ
bounds no vertex in G has more then (1 + c1) d neighbors with probability at most
n2−Ω(c1d) as well.

(cid:1) this assertion is satisﬁed (for S in Y ) with probability

d

4

Consequently:

(cid:19)

(cid:18)

1 − k2d2
n

E[X] ≥ E[Y ]

≥ (1 − )E[Y ].

Using k4nα−2
in Theorem D.5.

dα ≤ 2 the computation of E[Y 2] and the rest of the proof are the same as

8

Corollary E.9. For every δ ≥ 0.467 and  < 1
there is some ρ > 0 such that the following
holds for every large enough n. Let H be an arbitrary balanced graph with average degree
3.75 on k = nρ vertices. Let G be a random graph on n vertices with average degree d = nδ
(which we refer to as Gn,d). Then with probability larger than 1 − 4 (over choice of G), G
contains a set S of k vertices such that:
1. The subgraph induced on S is H.
2. Each vertex of S has a neighbor outside S.
3. The total sum of degrees of vertices in S is at most n−k

.

Proof. In Theorem D.5, choose  < 1
dα ≤ 2. Speciﬁcally, one may choose k = min
k4nα−2

, α = 3.75, and choose k such that k2d
= nΩ(1).

1−δ
2 ,

αδ−α+2

√

n

n

8

4

n ≤  and

4

(cid:104)√

(cid:105)

51

(cid:105)

100

√

1−δ
2 ,

n

αδ−α+2

4

n

(cid:104)√

) is at least 1

Theorem E.10. (Generalization of Theorem 1.4b for the k = 4 case). Let G ∼ Gn,d be a
random graph, where d = nδ for 0.467 ≤ δ < 1, and let γ be an arbitrary small constant. If
there exists a randomized algorithm that colors G ∼ Gn,d after an adversarial color-planting
with probability γ (over the distribution Gn,d and the randomness of the algorithm) then
RP = N P .
and
Proof. Suppose that there exists an algorithm A as in the theorem. Consider  = γ
= nΩ(1) (so that the conditions of Corollary E.9 and
set k = min
Theorem E.8 hold). Let H be an arbitrary balanced graph with average degree 3.75 with k
vertices that has a balanced 3-coloring. We show how A can be used in order to color H.
Recall Deﬁnition D.10 for the graphs distribution Gn,d,H. By the proof of Theorem D.13 it
follows that the probability measure with respect to Gn,d,H of graphs that A colors (after
any adversarial planting, with probability at least γ
2
Given G ∼ Gn,d,H we consider the following distribution ˜GH for graphs with an adver-
sarial coloring. Let S1 be the event that some vertex in the induced planted graph H (in
Gn,d,H) has no neighbors outside H. Let S2 be the event that the total number of neighbors
(among the remaining vertices in G) that the induced planted graph H has is larger than
n/4. If either event S1 or S2 happen (these are considered bad events), then plant an arbi-
trary balanced 4-coloring in G. If neither event S1 nor S2 happens (this will be shown to be
the typical case), plant in G a balanced 4-coloring chosen uniformly at random, conditioned
on the following two events: the planted graph is colored by a balanced 3-coloring that
agrees with the coloring of H, and all neighbors of H (outside H) are colored by the fourth
color.
4 ≤ γ/44. As to event S2, since
(1 + c1) d neighbors with probability at most n2−Ω(c1d) ≤ γ/44. Consequently, event S2
happens with probability at most γ/44 as well.
One last event S3 to consider is that the 4-coloring of the graph induced on vertices

(cid:1) then, by the union bound and the Chernoﬀ bound, no vertex in G has more then
(cid:16)√
(cid:17)-

The event S1 happens with probability at most k2e− dn

not in H is not unique. By Lemma E.11 below and since a random graph is a O
expander [15, 18, 17], it follows that S3 happens with probability at most γ
graph from ˜GH is called good if the events S1, S2, S3 do not hold.

k = o(cid:0) n

2 γρ (1 − ) ≥ 1

11 γ.

In total, the probability measure of good graphs in ˜GH that A colors with probability
for every color planting (over the randomness of A) is at least γ/50. Moreover,

of at least γ
2
the distribution ˜GH of good graphs can be sampled in a polynomial time as follows:

as well. A

d

44

d

1. Take the vertex disjoint union of the graph H and a random graph from G(cid:48) ∼ Gn−k,p

(with p = d/n).

2. Add edges between H and G(cid:48) (each edge is added independently with probability p).
4 − k
3. 4-color G(cid:48) randomly conditioned on three color classes each containing exactly n
) containing all neighbors of H. Remove

vertices and the remaining color class (of size n
all monochromatic edges from G(cid:48).
4

3

By the above, the probability that this procedure fails to construct a good graph is
bounded by some small constant. Every 4-coloring of a good graph gives 3-coloring of H
(because the 4-coloring of G(cid:48) is unique, and in this 4-coloring every vertex of H is adjacent

52

(cid:16) 50

(cid:17) random

γ2

to some vertex of G(cid:48) of the fourth color class). Running algorithm A on Ω
instances from ˜GH (which we can sample eﬃciently) then with high probability A will 4-color
at least one of these instances. By Theorem D.7 the proof follows.
Lemma E.11. Let k ∈ N+ be a constant. Let G be a d-regular λ-expander graph with
d = Ω(log(n)) and λ ≤ c 1
k2.5 d, where c is a suﬃciently small constant. Let G(cid:48) be the graph
G with a random balanced k-color planting. Then with high probability G(cid:48) has only one legal
k-coloring (namely, the planted k-coloring).
Proof. Assume, towards a contradiction, that there exist two diﬀerent k-colorings χ1 (the
planted coloring) and χ2 of G(cid:48). Deﬁne their distance d (χ1, χ2) to be the Hamming distance
between two strings that represents the colors of G(cid:48)’s vertices with respect to χ1, χ2 (choose
a naming of the colors that minimizes the distance). Throughout the proof we treat χi as a
string with the naming of the colors that meets the above deﬁnition of distance.
, and let colχi(v) denote the color of
vertex v in the coloring χi. Let SB ⊆ V denote the following vertex set. v ∈ SB if there is

Let δ be a constant which is much smaller than 1

some color class other than colχ1 (v) such that v has either more than(cid:0) 1
or less than(cid:0) 1

k + δ(cid:1) d neighbors
k − δ(cid:1) d neighbors in that color class. By a similar proof as of Lemma B.14, it

We ﬁrst show that d(χ1, χ2) ≥ d/k−αd

follows that with high probability there are no vertices in SB. We assume throughout the
proof that indeed SB is empty, and that δ is negligible compared to 1
n. Let H be the sub-graph of G induced on the
vertices {v ∈ V (G) | χ1 (v) (cid:54)= χ2 (v)}. Since that χ2 is legal then for v ∈ H it holds that any
neighbor u of v such that colχ1(u) = colχ2(v) is in H as well. By our assumption on SB,
it follows that H has a minimal degree of roughly d/k. Recall that EG (H, H) is twice the
number of edges in the induced subgraph H. By the expander mixing lemma it holds that

.

k

k

d

|H| ≤ |EG (H, H)|

d
k

≤ d
n

|H|2 + λ|H| .

Hence |H| ≥ d/k−λ

d n.

Now we show the following claim

Claim E.12. d(χ1, χ2) ≤ n, for

(k − 1)1 + (k − 1)

(cid:18) λ

(cid:19)2

d

1

k − (k − 1)1)

1

k ( 1

(cid:33)

,

(cid:32)
(cid:1)2.

 = k

where 1 = k(k − 1)(cid:0) λ

d

We prove Claim E.12 below. Note that if λ ≤ c 1

k2.5 d, for suﬃciently small constant c,
d n. Hence, there is no other legal coloring for G(cid:48) other than the planted

then n < d/k−λ
coloring.

In remains to prove Claim E.12.

53

Thus |col2,j| ≤ ( 1
Since χ2 is legal and by the expander mixing lemma, for every j2 (cid:54)= j1 it holds that

By the above, for every j there exists j1 such that |col1,j1 ∩ col2,j| ≥ 1

k − (k − 1)1)n.

k ( 1

k − (k − 1)1)n.

k −(k−1)1) n. Since this holds for any j2 (cid:54)= j1 then

(cid:113)|col1,j2 ∩ col2,j||col1,j1 ∩ col2,j| .
n − (cid:88)

|col1,j2 ∩ col2,j|
(cid:19)2

(cid:18) λ

1

(cid:33)

d

k − (k − 1)1)

1

k ( 1

n

1

1

d

d
n

|col1,j2 ∩ col2,j||col1,j1 ∩ col2,j| ≤ λ
(cid:19)

(cid:1)2
Therefore |col1,j2 ∩ col2,j| ≤(cid:0) λ
(cid:18) 1
(cid:32)
(cid:18) 1

|col1,j1 ∩ col2,j| ≥

k ( 1
− (k − 1)1

(cid:19)

≥

1
k

k

j2(cid:54)=j1
− (k − 1)1 − (k − 1)

=

− 1
k



n .

Proof. (of Claim E.12). Let coli,j be vertices with color j in coloring χi. We claim that
|col2,j| ≤ ( 1
k n. We claim that for some
j1 (cid:54)= j2 ∈ {1, 2, .., k} it holds that

k + 1)n for all j ∈ {1, 2, .., k}. Given that |col2,j| ≥ 1

|col2,j ∩ col1,j1||col2,j ∩ col1,j2| ≥ 1
k

n
.
To see this, denote by xi a possible size for col2,j ∩ col1,j1
i=1 xk = |col2,j|. For
notational convenience we may assume that x1 and x2 are largest among the {xi}. Fixing
the sum x1 +x2, the product x1x2 is minimized when their values are unbalanced as possible.
are all equal and
In the worst case, x1 = n
the lower bound is established.

. Now to get minimal x1x2, we assume {xi}i(cid:54)=1

(15)

|col2,j| − 1
k n
k − 1

. Clearly(cid:80)k

k

Since χ2 is legal, by Equation 15 and the expander mixing lemma, it holds that

(cid:115)

≤ λ

|col2,j| − 1
k n
k − 1

1
k

n

.

d
n

|col2,j| − 1
k n
k − 1
k + 1)n and col2,j ≥ ( 1

1
k

n

k

In other words, it holds that for every color j ∈ {1, 2, .., k} in χ1 there exists a matching

color j1 in χ2 such that both colors agree on at least(cid:0) 1
that this is a matching). Hence d(χ1, χ2) ≤(cid:0) k

k (cid:1) n = n, as desired.

k (cid:1) n vertices (it is easy to see

k − 1

F NP-hard subgraphs are not always an obstacle to eﬃ-

cient coloring

Consider the following proposition.
Proposition F.1. Let Q(VQ, EQ) be an arbitrary 3-colorable 4-regular graph on k = n1−
vertices. There exists a spectral expander graph H (with n vertices) such that if a random 3-
coloring P is planted in H and monochromatic edges are dropped, then with high probability
the resulting graph G contains a vertex induced copy of Q.

4 log n

54

Proof. (Sketch.) For simplicity, the host graph H in our reduction will not be regular, but
rather only nearly regular. However, it is not diﬃcult to modify the reduction so that H is
regular.

Based on Q, the host graph H is constructed in two steps:
1. Select an arbitrary d-regular spectral expander H(cid:48)(V, E) on n vertices, with d = n.
2. Let S ⊂ V be an arbitrary independent set in H(cid:48) on 3k log n vertices. Partition S into
k equal size parts S1, . . . , Sk. For each 1 ≤ i < j ≤ k, if (i, j) ∈ EQ then add to E all
9 log2 n edges between Si and Sj.

H constructed above is a spectral expander. This follows from Inequality 12 in Sec-
tion C.2, which implies that no eigenvalue of H(cid:48) is shifted by more than 12 log n (the maxi-
mum number of edges added to a vertex in H(cid:48) in order to construct H).
Let χ be a legal 3-coloring of Q. Then with high probability over the choice of planted
coloring in H, for every 1 ≤ i ≤ k there is some faithful vertex v ∈ Si such that P (v) = χ(i).
Edges in H connecting faithful vertices are not dropped in G. Hence taking one faithful
vertex from each part gives a copy of Q.

The above proposition shows that any 3-colorable 4-regular graph Q can be embedded
as a vertex induced subgraph in a graph G generated by the HA/PR model. In general,
such graphs Q are NP-hard to 3-color. Nevertheless our Theorem 1.3 shows that the graph
G can be 3-colored in polynomial time. As Q is a subgraph of G, this also produces a legal
3-coloring of Q, thus solving an NP-hard problem. However, this of course does not imply
that P=NP. Rather, it implies that it is NP-hard to ﬁnd in G a subgraph that is isomorphic
to Q.

G Useful facts
In this section we state several well known theorems which we use throughout this manuscript.

The following theorem is due to [10].

0 ≤ Xi ≤ 1 always, for each i. Let X =(cid:80)n

Theorem G.1. [Chernoﬀ]. Let X1, ..., Xn be independent random variables.. Assume that

i=1 Xi and µ = E [X]. For any  ≥ 0

Pr [X ≥ (1 + ) µ] ≤ exp

and

− 2
2 + 

Pr [X ≤ (1 − ) µ] ≤ exp

− 2
2

µ

.

(cid:18)
(cid:18)

(cid:19)
(cid:19)

µ

,

The following theorem can be found in [31].

Theorem G.2. [McDiarmid]. Let X1, ..., Xm ∈ X m be a set of m ≥ 1 independent random
variables and assume that there exist c > 0 such that f : Rn → R satisﬁes the following
conditions:

|f (x1, ..., xi, ..., xm) − f (x1, ..., x(cid:48)

i, ..., xm)| ≤ c ,

55

for all i ∈ [1, m] and any points x1, ..., xm, x(cid:48)
f (X1, ..., Xm), then, for all  > 0, the following inequalities hold:

i ∈ X . Let f (S) denote the random variable

Pr [|f (S) − E [f (S)]| ≥ ] ≤ 2 exp

(cid:19)

(cid:18)

− 22
mc2

The following theorem is well known, see for example [21] (p.185).

Theorem G.3. [Cauchy interlacing theorem]. Let A be a symmetric n × n matrix. Let B
be a m × m sub-matrix of A , where m ≤ n.
If the eigenvalues of A are α1 ≤ ... ≤ αn and those of B are β1 ≤ ... ≤ βj ≤ ... ≤ βm,
then for all j ≤ m,

αj ≤ βj ≤ αn−m+j.

Recall that for S, T ⊆ V (G), EG (S, T ) denotes the number of edges between S and T
in G. If S, T are not disjoint then the edges in the induced sub-graph of S ∩ T are counted
twice. The following lemma can be found in [1].

Lemma G.4. [Expander Mixing Lemma]. Let G = (V, E) be a d-regular λ-expander graph
with n vertices, see Deﬁnition A.3. Then for any two, not necessarily disjoint, subsets
S, T ⊆ V the following holds:

The following lemma is well known, a proof can be found for example in [35] (Chapter

4).

Lemma G.5. [Spectral to Vertex Expansion]. If G is a d-regular λ-expander graph, then,
for every α ∈ [0, 1], G is an

vertex expander, see Deﬁnition A.2.

αn,

(cid:12)(cid:12)(cid:12)(cid:12) ≤ λ(cid:112)|S| · |T| .

(cid:12)(cid:12)(cid:12)(cid:12)EG(S, T ) − d · |S| · |T|
(cid:19)
(cid:18)

n

1
(1−α)( λ
d )2

+α

56

