Self-triggered Model Predictive Control for
Nonlinear Input-Afﬁne Dynamical Systems

via Adaptive Control Samples Selection

Kazumune Hashimoto, Shuichi Adachi, Member, IEEE, and Dimos V. Dimarogonas, Member, IEEE

1

6
1
0
2

 
r
a

 

M
1
1
 
 
]

.

C
O
h
t
a
m

[
 
 

1
v
7
7
6
3
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—In this paper, we propose a self-triggered formula-
tion of Model Predictive Control for continuous-time nonlinear
input-afﬁne networked control systems. Our control method
speciﬁes not only when to execute control tasks but also provides
a way to discretize the optimal control trajectory into several
control samples, so that the reduction of communication load
will be obtained. Stability analysis under the sample-and-hold
implementation is also given, which guarantees that the state
converges to a terminal region where the system can be stabilized
by a local state feedback controller. Some simulation examples
validate our proposed framework.

Index Terms—Model Predictive Control, Optimal Control,

Event-triggered Control, Nonlinear systems.

I. INTRODUCTION

E VENT-TRIGGERED control

is one of the sampled-
data control schemes that has been receiving increased
attention in recent years [1]–[25]. In contrast to time-triggered
control where the control execution is periodic, event-triggered
control requires the executions only when desired control
speciﬁcations cannot be guaranteed. This may have several
advantages over time-triggered control for networked control
systems, since this leads to the reduction of over-usage of
communication resources and energy consumption when lim-
ited battery powered devices exist. Two main event-triggered
control approaches have been proposed, namely event-based
control [1]–[8], and self-triggered control [9]–[12]. The main
difference of these two approaches is that, for the event-based
case the control input is executed based on the continuous state
measurement of the plant, while for the self-triggered case the
control execution is pre-determined based on the prediction
from the plant model.

The event-triggered control framework has been analyzed
for many different types of systems with different performance
guarantees. For example, in [8], [9] the authors propose the
event-triggered strategy based on L2 and L∞ gain stability
performance for linear systems. Another research line for-
mulates the triggering rules based on Input-to-State Stability

Manuscript submitted to IEEE Transaction on Automatic Control.
Kazumune Hashimoto is with the Department of Applied Physics and
Japan (e-mail: kazu-

Physico-Informatics, Keio University, Yokohama,
mune.hashimoto@z5.keio.jp).

Shuichi Adachi

Physico-Informatics, Keio University, Yokohama,
adachi@appi.keio.ac.jp).

is with the Department of Applied Physics and
(e-mail:

Japan

Dimos V. Dimarogonas is with the ACCESS Linnaeus Center, School of
Electrical Engineering, KTH Royal Institute of Technology, 10044 Stockholm,
Sweden (e-mail : dimos@ee.kth.se). His work was supported by the Swedish
Research council (VR) and the Knut and Alice Wallenberg Foundation.

(ISS) for linear systems, e.g., [10], which is followed by the
extension to the nonlinear case [18].

In this paper, we are interested in applying the event-
triggered scheme to Model Predictive Control (MPC). This
has been motivated due to the fact that MPC not only takes
into account several constraints such as actuator limitations
explicitly by solving the Optimal Control Problem (OCP) on-
line, but also stability can be analyzed even for the nonlinear
case. The application of event-triggered strategies to MPC
has been receiving attention in recent years and some results
include [13]–[24], where many results have been proposed
for discrete time systems. For example, in [13], the authors
propose event-based strategy for discrete time linear system
under additive bounded disturbances, where the OCP is solved
when the difference of actual state and predictive state exceeds
a certain threshold, and they also analyze stability depending
on the size of the disturbances. The reader can also refer
to [15], and to more recent results in [16], [17] for linear
systems where inﬁnite horizon quadratic cost is evaluated.
The concept of event-triggered MPC has also been applied to
cooperative control of multi-agent systems, see e.g., [18], [19].
For the continuous case, the reader can refer to [20], [21], [22].
For example, in [20], the authors derive self-triggered MPC
based on the optimal cost function as a Lyapunov candidate
for controlling a non-holonomic vehicle, where the controlled
plant solves an OCP only when it is needed.

this paper

The contribution of

is to propose a new
input-afﬁne
self-triggered MPC framework for nonlinear
continuous-time networked control systems, where the plant
with actuator and sensor systems are connected to the con-
troller through wired or wireless channels. The derivation
of our self-triggered strategy follows the previous ideas that
the OCP is solved by checking if the optimal cost function,
regarded as a Lyapunov candidate, is decreasing. In networked
control systems, however, one of the main constraints is the
bandwidth limitation [26], meaning that the controller can
send only a limited number of control samples. In the up-to-
date results of event-triggered MPC for continuous systems
presented in [20], [21], [22], the event-triggered strategies
for the continuous system are based on the assumption that
the current and future (continuous) optimal control trajectory
can be applied until the next OCP is solved. Therefore, this
framework cannot be applied to our case, since continuous
information cannot be transmitted to the plant needing an
inﬁnite transmission bandwidth. Even though the continuous
trajectory may be approximated by using a large
control

number of control samples, it may lead to the over-usage
of communication resources since it requires transmissions of
many control samples.

Therefore, in our proposed control method, the controller
not only solves an OCP but also discretizes the obtained opti-
mal control input trajectory into several control input samples,
so that these can be transmitted as a packet to the plant.
Then, the plant applies the control samples as in a sample-
and-hold implementation. The discretizing method is to some
extent relevant to “Roll-out event-triggered control”, which is
introduced in [17], where the authors propose a way to pick
up the transmission time step for linear discrete time systems,
and then show that the proposed control policy provides better
performance than the conventional periodic optimal control in
terms of the reduced value function. In contrast to [17], we
will propose a way to adaptively select sampling time intervals
to reduce the communication load. While this may lead to
additional optimization problems, we will provide an efﬁcient
way of choosing the sampling intervals. Moreover, while the
results presented in [17] considers linear systems, we deal with
nonlinear systems.

One of the main difﬁculties regarding MPC under sample-
and-hold implementation is to guarantee stability, since
sample-and-hold controllers lead to an error between the
predicted optimal state and the actual state of the system, even
when the system has no disturbances. Regarding this stability
problem, some results were provided in [27], [28]. The key
idea is to use Lyapunov-based MPC, where a Lyapunov
based controller is assumed to exist to show that the state
converges to a certain invariant set under sample-and-hold
implementation. However, it was not concluded whether the
state converges to the terminal region where an assumed local
controller exists stabilizing the system to the origin. In the
MPC framework, it is desirable to achieve the convergence
to the terminal region, since then the local state feedback
controller can be applied to stabilize the system without
needing to solve the OCP. The strategy of switching MPC
to the local controller is referred to as ‘Dual-mode MPC’.
Motivated by this, in this paper we also show that the state
reaches the terminal region in ﬁnite time. Instead of using
Lyapunov based MPC, an additional control input constraint
and a restricted terminal constraint are used.

As illustrative examples, we simulate both linear and non-
linear systems. For the linear system case, the problem of
stabilizing an un-stable system under control input constraints
is considered and we compare the control performance with
periodic MPC under sample-and-hold implementation with the
same average transmission interval. For the nonlinear system
case, we consider position control of a non-holonomic vehicle
in two dimensions. For both cases, we will show that the
system is stabilized under our proposed self-triggered MPC.
The remainder of this paper is organized as follows. In
Section II, the problem formulation is set up for the networked
control system. In Section III, the self-triggered rule is given.
In Section IV, we propose an efﬁcient way to choose optimal
sampling intervals. In Section V, the stability analysis is given.
In Section VI, some simulation results are given. Finally, we
summarize the results of this paper in Section VII.

2

Actuator

Plant

Sensor

Network

Network

MPC

Fig. 1. Networked Control System

II. PROBLEM FORMULATION

A. Notations

We make use of the following notations. Let R, R≥0,
N≥0, N≥1 be the real, non-negative real, non-negative integers
and positive integers, respectively. The operator || · || denotes
Euclidean norm of a vector. The function φ(x, u) : Rn×Rm →
Rn is locally Lipschitz continuous with Lipschitz constant Lφ
in x ∈ Ω ⊂ Rn, if ||φ(x1, u) − φ(x2, u)|| ≤ Lφ||x1 − x2|| for
all x1, x2 ∈ Ω. The difference between two sets Ω1 and Ω2
is denoted by Ω1\Ω2 = {x | x ∈ Ω1, x /∈ Ω2}. A continuous
function α : [0, a) → [0,∞) is said to be K∞ function if α is
strictly increasing with α(0) = 0, and α(r) → ∞ as r → ∞.
Given a compact set Ω ⊆ Rn, we denote ∂Ω as the boundary
of Ω.

B. System Deﬁnition

Consider the networked control system in Fig. 1, where
the plant with sensor and actuator systems are connected to
the Model Predictive Controller (MPC) through the network
channels. The dynamics of the plant are given by the following
continuous-time nonlinear input afﬁne system:

˙x(t) = φ(x, u) = f (x) + g(x)u

(1)
where x ∈ Rn is the state of the plant, and u ∈ Rm is the
control input. We assume that the constraint for the control
input is given by ||u|| ≤ umax. Our control objective is
to asymptotically stabilize the system (1) to the origin, i.e.,
x(t) → 0 as t → ∞. To achieve this goal, we assume
that the nonlinear system given by (1) satisﬁes the following
conditions:
Assumption 1. The nonlinear function φ(x, u) : Rn × Rm →
Rn satisﬁes φ(0, 0) = 0, and is Lipschitz continuous in x ∈
Rn with Lipschitz constant Lφ. Furthermore, there exists a
positive constant LG > 0, such that ||g(x)|| ≤ LG.
C. Optimal Control Problem

In this subsection the Optimal Control Problem (OCP) is
deﬁned. Let the sequence {tk}k∈N≥0 denote the sampling
instants when the OCP is solved. At tk, the controller solves
the OCP involving the predictive states denoted as x(s), and
the control input u(s) for s ∈ [tk, tk +Tp] based on the current
state measurement x(tk), where Tp is the prediction horizon.
In this paper, we consider the following cost function to be
minimized (not necessarily quadratic costs)

J(x(tk), u(·)) =Z tk+Tp

tk

F (x(s), u(s))ds + Vf (x(tk + Tp))

3

Fig. 3. Optimal control input obtained at tk: the controller picks up N control
input samples (Red circles) from the obtained optimal control trajectory (Black
line), and these samples are transmitted to the plant and applies them as
sample-and-hold fashion (Red line).

Denote J ∗(x(tk)) as the optimal cost obtained by Problem 1

J ∗(x(tk)) = min
u(·)

J(x(tk), u(·)).

Moreover, we consider a following set as a stability region
characterized by J ∗(x(tk)) :
Deﬁnition 1. ΣV is the set given by ΣV = {x ∈ Rn : J ∗(x) ≤
J0}, where J0 is deﬁned such that Ω(ε) ⊆ ΣV .
The illustration of the three regions considered in this paper
ΣV , Ω(ε), Ω(εf ), and an example of optimal trajectory x∗(s)
that is constrained to be in Ω(εf ) by the prediction horizon
Tp, are all shown in Fig. 2.

We will show in this paper that if the state initially starts
from inside the set x ∈ ΣV \Ω(ε), then the state trajectory
enters Ω(ε) in ﬁnite time. Since the local control law κ(x)
is given from Assumption 2, the system (1) can be stabilized
by using κ(x) once the state reaches Ω(ε) without needing to
solve the OCP. For this reason, we consider that the control
law switches from the solution to Problem 1 to the utilization
of κ(x) once the state enters Ω(ε). This control scheme is
in general referred to as ‘Dual-mode MPC’, and is adopted in
many works in the literature, see e.g., [21], [34]. Using the sets
deﬁned above, the following conditions are further assumed to
be satisﬁed for the stage and terminal cost F , Vf :
Assumption 3. F (x, u) ≥ α1(||x||), and Vf (x) ≤ α2(||x||),
where α1 and α2 are K∞ functions. Moreover, F (x, u) and
Vf (x) are Lipschitz continuous in x ∈ ΣV with corresponding
Lipschitz constants 0 < LF < ∞, 0 < LVf < ∞.
Remark 1. Assumptions 2 and 3 are fairly standard as-
sumptions to guarantee stability for nonlinear systems under
MPC. Several methods to numerically obtain Ω(ε) and κ(x)
satisfying (7) were proposed in e.g., [33], [34]. Furthermore,
several ways to compute Lipschitz parameters LF , LVf for the
case of quadratic stage and terminal cost have been proposed
in [20].

In the following, let the optimal control input and the state

trajectories obtained by Problem 1 be given by
u∗(s), x∗(s), s ∈ [tk, tk + Tp]

where x∗(tk) = x(tk).

(8)

Note that in earlier results of periodic or event-triggered
MPC for continuous systems, e.g., [20], [21], [22], [34],
[37], [42], the current and future continuous optimal control

Fig. 2. The illustration of three regions ΣV , Ω(ε), Ω(εf ), and an example
of optimal state trajectory x∗(s).

where F (x, u) and Vf (x) is a stage and terminal cost, and
several assumed conditions are described later in this section.
Using the cost function above, the OCP to be solved is

deﬁned as follows:
Problem 1 (OCP) : At any update time tk, k ∈ N≥0, given
x(tk) and Tp, ﬁnd the optimal control input and corresponding
state trajectory u∗(s), x∗(s) for all s ∈ [tk, tk + Tp] that
minimizes J(x(tk), u(·)), subject to

˙x(s) = φ(x(s), u(s)), s ∈ [tk, tk + Tp]
u(s) ∈ U
x(tk + Tp) ∈ Ω(εf ),




(2)
(3)
(4)

(5)

where U is the control input constraint set given by
U = {u(s) ∈ Rm : ||u(s)|| ≤ umax,|| ˙u(s)|| ≤ Ku},

and for given εf > 0, Ω(εf ) is the terminal constraint set
given by

Ω(εf ) = {x ∈ Rn : Vf (x) ≤ εf}.

(6)

Regarding the control input constraint set in (5), we ad-
ditionally consider a constant Ku satisfying || ˙u(s)|| ≤ Ku.
Although this puts a limit on the slope of the optimal control
input and is sometimes used when the actuator has a physical
limitation with the rate of its position change [19], [29], in
this paper we will make use of this constraint to guarantee the
stability analyzed in subsequent sections. For the (terminal)
set Ω(·), we further assume the following.
Assumption 2. There exists a positive constant ε > εf and a
local stabilizing controller κ(x) ∈ U, satisfying

∂Vf
∂x

(f (x) + g(x)κ(x)) ≤ −F (x, κ(x)),

(7)

for all x ∈ Ω(ε).

Note that since ε > εf , the terminal set Ω(εf ) used in
Problem 1 is smaller than Ω(ε) in Assumption 2, i.e., Ω(εf ) ⊂
Ω(ε).

N

(9)

δi)},

trajectory u∗(s) is considered to be applied to the plant for
s ∈ [tk, tk+1]. However, this situation cannot be applied
to the networked control system in Fig. 1 considered in
this paper, since sending continuous information requires an
inﬁnite transmission bandwidth. Therefore, we consider that
only N (N ∈ N≥1) control input samples, i.e.,
Xi=1

{u∗(tk), u∗(tk + δ1),··· , u∗(tk +

lustration in Fig. 3. As shown in Fig. 3, tk+1 = tk +PN

should be determined to be picked up by the controller and
then transmitted to the plant. The plant then applies the ob-
tained control inputs in a sample-and-hold fashion, see the il-
i=1 δi is
the next transmission time when the plant sends x(tk+1) as the
new current state information, which is obtained by the self-
triggered strategy proposed in the next section. Furthermore,
by making use of the ﬂexibility of selecting control samples
when multiple control inputs are allowed to be transmitted
(namely when N > 1), we will provide an efﬁcient way of
how to pick up control samples to be transmitted, such that
the reduction of the communication load is achieved.
Remark 2. Since κ(x) is a continuous control law, applying
κ(x) over the network as a dual mode strategy would in fact
require an inﬁnite transmission bandwidth. One way to avoid
this issue is to apply κ(x) under sample-and-hold fashion;

u(t) = κ(x(tk)),

t ∈ [tk, tk + δl],

where the sampling time δl is constant and needs to be small
enough such that asymptotic stability is still guaranteed in
x ∈ Ω(ε); see [44] for the related analysis.
Another way would be to apply κ(x) directly at the plant
as a stand-alone to stabilize the system, without needing any
communication with the controller as soon as x enters Ω(ε).
This situation could be the case when the computation of κ(x)
is possible locally at the plant, while at the same time it is only
feasible to solve the OCPs through the networked controller
due to computational limitations. For this case, κ(x) does not
need to be discretized since no communication is required
locally at the plant.

III. DERIVING SELF-TRIGGERED CONDITION

In this section we propose a self-triggered strategy for
networked control systems as in Fig. 1, under MPC with
sample-and-hold controllers. Our self-triggered strategy will
be derived based on the stability analysis by taking the optimal
cost J ∗(x(tk)) as a Lyapunov candidate. Suppose again that
at tk when the OCP is solved the optimal control input and
the state trajectory are given by (8) and the optimal cost is
J ∗(x(tk)).

Denoting ∆n = Pn
i=1 δi < Tp for 1 ≤ n ≤ N , let
x(tk + ∆n) be the actual state when sample-and-hold con-
trollers {u∗(tk),··· , u∗(tk + ∆n)} are applied with sampling
intervals δ1,··· , δn. Moreover, let J ∗(x(tk + ∆N )) be the
optimal cost obtained by solving Problem 1 based on the new
current state x(tk + ∆N ). Then, the self-triggered condition,
which determines the next transmission time tk+1, is obtained

4

by checking if the optimal cost regarded as a Lyapunov
candidate is guaranteed to decrease, i.e.,

J ∗(x(tk + ∆N )) − J ∗(x(tk)) < 0.

For deriving this condition more in detail, we ﬁrst recap from
Lemma 3 in [37] that for a quadratic stage cost (or Theorem
2.1 in [42] for the non-quadratic case), the following result
holds:

J ∗(x∗(tk + ∆N )) − J ∗(x(tk))
≤ −Z tk+∆N
F (x∗(s), u∗(s))ds

tk

(10)

(11)

where J ∗(x∗(tk+∆N )) is the optimal cost obtained by solving
Problem 1 if the current state at tk +∆N is x∗(tk +∆N ). This
means that the optimal cost would be guaranteed to decrease
if the actual state followed the optimal state trajectory x(s) =
x∗(s) for s ∈ [tk, tk + ∆N ]. From (10), we obtain

J ∗(x(tk + ∆N )) − J ∗(x(tk))
≤ J ∗(x(tk + ∆N )) − J ∗(x∗(tk + ∆N ))
−Z tk+∆N

F (x∗(s), u∗(s))ds

tk

where F (x∗(s), u∗(s)) is known at tk when the OCP is solved.

Remark 3 (Feasibility of Problem 1). In order to obtain
the stability property given by (10), one can see that the
feasibility of Problem 1 needs to be guaranteed, see e.g.,
[37]. Regarding establishing the feasibility of Problem 1, the
existing procedures of event-triggered MPC (see e.g., [24]) or
periodic MPC (see e.g., [37]) can be utilized; we can consider
a feasible controller candidate given by ¯u(s) = u∗(s) for all
s ∈ [tk+1, tk +Tp] and κ(¯x(s)) for all s ∈ (tk +Tp, tk+1 +Tp],
to obtain (10). However, compared with the existing proce-
dures, the condition ˙κ(x) ≤ Ku is additionally required for
the existence of the local controller, such that this controller
candidate becomes admissible. More speciﬁcally, since we
have ˙κ(x) = ∂κ(x)

∂x φ(x, κ(x)), Ku must satisfy

Ku ≥ max

x∈Ω(εf )(cid:26)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

∂κ(x)

∂x · φ(x, κ(x))(cid:12)(cid:12)(cid:12)(cid:12)

(cid:27) ,

(cid:12)(cid:12)(cid:12)(cid:12)

and this needs to be computed off-line.

For notational simplicity in the sequel, let Ex(δ1,··· , δn)
be the upper bound of ||x∗(tk + ∆n) − x(tk + ∆n)|| for 1 ≤
n ≤ N . The following lemmas are useful to derive a more
detailed expression of (11):
Lemma 1. Under the Assumptions 1 − 3, the optimal cost
J ∗(x) is Lipschitz continuous in x ∈ ΣV , with Lipschitz
constant LJ given by

LJ =  LF

Lφ

+ LVf! eLφTp −

LF
Lφ

(12)

For the proof of Lemma 1, see Appendix.

Lemma 2. Suppose that the sample-and-hold controllers given
by (9) are applied to the plant (1) from tk. Then, the up-
per bound of ||x∗(tk + ∆N ) − x(tk + ∆N )||, denoted as
Ex(δ1,··· , δN ), is obtained by the following recursion for

2 ≤ n ≤ N :

Ex(δ1,··· , δn) = Ex(δ1 ··· , δn−1)eLφδn + hx(δn)

(13)

with Ex(δ1) = hx(δ1), where

hx(t) =

2KuLG

L2
φ

(eLφt − 1) −

2KuLG

Lφ

t

(14)

Proof: We ﬁrst show Ex(δ1) = hx(δ1). Observe that

x(tk + δ1) and x∗(tk + δ1) are given by

Therefore, letting

where 0 < σ < 1, we obtain

tk

σ

Ex(δ1,··· , δN ) <

LJZ tk+∆N
J ∗(x(tk + ∆N )) − J ∗(x(tk))
< (σ − 1)Z tk+∆N

tk

< 0

5

F (x∗(s), u∗(s))ds

(18)

F (x∗(s), u∗(s))ds

(19)

φ(x(s), u∗(tk))ds,

φ(x∗(s), u∗(s))ds

tk

x(tk + δ1) = x(tk) +Z tk+δ1
x∗(tk + δ1) = x(tk) +Z tk+δ1
||x(tk + δ1) − x∗(tk + δ1)||
≤Z tk+δ1

Lφ||x(s) − x∗(s)||ds +

tk

tk

We obtain

1
LGKuδ2
1
2

(15)

where we have used

||g(x(s))(u∗(tk) − u∗(s))|| ≤ LGKu(s − tk)

(16)
from Assumption 1 and the control input constraint || ˙u(s)|| ≤
Ku. Therefore, by applying the Gronwall-Bellman inequality,
we obtain

||x(tk + δ1) − x∗(tk + δ1)||
≤

(eLφδ1 − 1) −

2KuLG

L2
φ

2KuLG

δ1

Lφ

and thus Ex(δ1) = hx(δ1). Now assume that Ex(δ1 ··· , δn−1)
is given for n ≥ 2. We similarly obtain

||x(tk + ∆n) − x∗(tk + ∆n)||
≤ ||x(tk + ∆n−1) − x∗(tk + ∆n−1)||
+Z tk+∆n
Lφ||x(s) − x∗(s)||ds +

tk+∆n−1

(17)

1
2

LGKuδ2
n

The only difference between (15) and (17) is that the initial
difference ||x(tk + ∆n−1) − x∗(tk + ∆n−1)|| that is upper
bounded by Ex(δ1,··· , δn−1) is included in (17). By applying
the Gronwall-Bellman inequality again, we obtain

||x(tk + ∆n) − x∗(tk + ∆n)||
≤ Ex(δ1 ··· , δn−1)eLφδn +

2KuLG

L2
φ

(eLφδn − 1)

2KuLG

Lφ

−

δn

Thus (13) holds. Therefore, the upper bound Ex(δ1,··· , δN )
is obtained by using Ex(δ1) = hx(δ1) at ﬁrst, and then
recursively using (13) for n = 2,··· , N . This completes the
proof.

Using Lemma 1 and Lemma 2, (11) is rewritten by
J ∗(x(tk + ∆N )) − J ∗(x(tk))
≤ LJ Ex(δ1,··· , δN ) −Z tk+∆N

F (x∗(s), u∗(s))ds.

tk

and the cost is guaranteed to decrease. In our proposed self-
triggered MPC strategy, therefore, the next transmission time
tk+1 is determined by the time when the violation of (18)
takes place, i.e.,

σ

ˆtk+1

LJZ

(20)
i=1 δi and Γ(δ1,··· , δN ) is given by

tk+1 = inf(cid:8)ˆtk+1 | ˆtk+1 > tk, Γ(δ1,··· , δN ) = 0(cid:9) ,
where ˆtk+1 = tk +PN
Γ(δ1, δ2,··· , δN )
= Ex(δ1,··· , δN ) −

tk
Note that between tk and tk+1,
there exists an inﬁnite
number of patterns for the selection of sampling time in-
tervals δ1,··· , δN . Since Ex(δ1,··· , δN ) in the left-hand-
side (L.H.S) of (18) depends on these intervals, the way to
select δ1,··· , δN clearly affects the next transmission time
tk+1 obtained by (20). In the next section, we propose a way
to adaptively select δ1,··· , δN , such that the communication
load can be reduced as much as possible.

F (x∗(s), u∗(s))ds.

IV. CHOOSING SAMPLING INTERVALS

1, δ∗

2 ,··· , δ∗

In this section we provide an efﬁcient way of adaptively
selecting sampling intervals δ1, δ2,··· , δN , aiming at reducing
the communication load for networked control systems. In
the following, we let δ∗
N be the selected sam-
pling intervals by the controller to transmit corresponding
optimal control samples. In order to satisfy (18) as long as
possible, one may select the intervals δ∗
N such that
Ex(δ1,··· , δN ) is minimized. This is formulated as follows:
(21)

tk+1 = inf{ˆtk+1 | ˆtk+1 > tk, Γ(δ∗
N ) = 0},
where ˆtk+1 = tk + PN
N are optimal
i and δ∗
sampling time intervals between tk and ˆtk+1 such that
Ex(δ1,··· , δN ) is minimized:

1 ,··· , δ∗
1,··· , δ∗

1,··· , δ∗

i=1δ∗

δ∗
n = argmin
δ1,δ2,··· ,δN

Ex(δ1,··· , δN ), n = 1,··· , N

(22)

s.t. ˆtk+1 = tk +XN

i=1

δi.

In this approach, it is required to solve the optimization
problem (22) for each ˆtk+1 and check if the self-triggered
condition (18) is satisﬁed. This means that
the controller
needs to both solve (22) and check (18) until the violation
N ) = 0 occurs. Therefore, trying to obtain (21)
Γ(δ∗
is in fact not practical from a computational point, since the
optimization problem (22) needs to be solved for a possibly
large number of times. Moreover, since the solution to (22)
does not provide an explicit solution, numerical calculations

1,··· , δ∗

of solving (22) would become more complex as N becomes
larger.

R.H.S

R.H.S

6

Therefore, we propose a following alternative algorithm to
make the problem of searching for the sampling intervals
easier. In contrast to the above approach, this scheme requires
only N local optimizations to obtain the sampling intervals,
and furthermore, a more explicit solution can be found.
Algorithm 1 (Choosing sampling time intervals):
(i) Suppose that only u∗(tk) is applied for t ≥ tk as a
constant controller, and ﬁnd the time tk + τ1 when the
triggering condition (18) is violated, see Fig. 4 (a). We
obtain Ex(τ1) as the upper bound of ||x∗(tk + τ1) −
x(tk + τ1)||. If N = 1, we set δ∗
in the following
way. Suppose that u∗(tk) and u∗(tk + δ1) are applied
for [tk, tk + δ1], [tk + δ1, tk + τ1] respectively. This
means we obtain Ex(δ1, τ1 − δ1) as the upper bound of
||x(tk +τ1)−x∗(tk +τ1)||. Then, ﬁnd δ∗
1 ∈ [0, τ1] which
maximizes the difference of two upper bounds, i.e.,

(ii) If N ≥ 2, we set δ∗

1 ∈ [0, τ1]

1 = τ1.

δ∗
1 = argmax

δ1∈[0,τ1] {Ex(τ1) − Ex(δ1, τ1 − δ1)},

see Fig. 4 (b). As shown in Fig. 4 (c), by maximizing the
1) can continue to be applied
above difference, u∗(tk + δ∗
until the time when (18) is again violated. We denote
τ2 as the time interval when the violation of (18) takes
2 = τ2.
place after the time tk + δ∗
(iii) We follow the above steps until we get N intervals. That
n−1 for 2 ≤
is, given n − 1 sampling intervals δ∗
n < N , ﬁnd τn when the triggering condition is violated
to obtain Ex(δ∗
n ∈ [0, τn]
maximizing Ex(δ∗
n, τn−
n), i.e.,
δ∗

1 ,··· , δ∗
n−1, τn). Then, ﬁnd δ∗

1. If N = 2, we set δ∗

n−1, τn)−Ex(δ∗

1 ,··· , δ∗

1 ,··· , δ∗

1 ,··· , δ∗

δ∗
n = argmax

δn∈[0,τn] {Ex(δ∗

1,··· , δ∗

n−1, τn)

For the last step at n = N , we set δ∗
time interval.

−Ex(δ∗

1,··· , δ∗

n, τn − δ∗

n)}.
N = τN , as the ﬁnal

1,··· , δ∗

Instead of solving the optimization problem (22) possibly
for a very large number of times, Algorithm 1 requires
only N local optimization problems to obtain the sampling
intervals δ∗
N . Algorithm 1 may not provide the largest
possible next transmission time, since it does not minimize
Ex(δ1,··· , δN ). However, as we will see through several
comparisons in simulation results presented in Section VI,
Algorithm 1 is more practical
than the method to obtain
(21), as it requires much less computation time. Furthermore,
compared with (22) that provides no explicit solutions, the fol-
lowing lemma states that the solutions to the local optimization
problems can be obtained by a simple numerical procedure.
Lemma 3. Given δ∗
n−1, and τn for 1 ≤ n < N ,
the transmission interval δ∗
n maximizing
n) in Algo-
Ex(δ∗
1,··· , δ∗
n, τn − δ∗
rithm 1, step (iii), is obtained by the solution to

2,··· , δ∗
n−1, τn) − Ex(δ∗

1 ,··· , δ∗

1, δ∗

eLφ(τn−δ∗

n) =

1

(1 − Lφδ∗
n)

(23)

L.H.S

L.H.S

(a) Step 1: Assume u∗(tk ) is
applied, and ﬁnd τ1 when (18)
is violated.

(b) Step 2-1: Find 0 < δ∗
1 < τ1
maximizing the difference Ex(τ1) −
Ex(δ1, τ1 − δ1).

R.H.S

R.H.S

L.H.S

L.H.S

(c) Step 2-2: We can continue
to use u∗(tk + δ∗
1 ) to ﬁnd the
time interval τ2 until (18) is
violated.

2 < τ2
1 , τ2) −
1 , δ2, τ2 − δ2) and follow the steps

(d) Similarly to (b), ﬁnd 0 < δ∗
maximizing the difference Ex(δ∗
Ex(δ∗
until we obtain N samples.

Fig. 4. The way to ﬁnd sampling intervals: the L.H.S and the R.H.S are the
evolutions of left-hand-side and right-hand side in (18).

Furthermore, there always exists a solution of (23) satisfying
0 < δ∗

n < τn.
Proof: From (13), Ex(δ∗

1 ,··· , δ∗

n−1, τn) is given by

(24)

(25)

Ex(δ∗

1 ,··· , δ∗

= Ex(δ∗

1 ,··· , δ∗

n−1, τn)

n−1)eLφτn + hx(τn)

For Ex(δ∗

1,··· , δ∗
1,··· , δn, τn − δn)

Ex(δ∗

n−1, δn, τn − δn), we obtain

= Ex(δ∗
= Ex(δ∗

1,··· , δ∗
1,··· , δ∗

2KuLG

−

Lφ
Thus, we obtain

Ex(δ∗

1,··· , δ∗
2KuLG

=

Lφ

n−1, δn)eLφ(τn−δn) + hx(τn − δn)
n−1)eLφτn + hx(τn)
(cid:0)eLφ(τn−δn) − 1(cid:1) δn
n−1, τn) − Ex(δ∗
δn(cid:0)eLφ(τn−δn) − 1(cid:1) > 0

1,··· , τn − δn)

Therefore, by differentiating (25) with respect
solving for 0, we obtain (23).

to δn and

Now it is shown that we can always ﬁnd 0 < δ∗

n < τn

satisfying (23). As δn → 0, we get

eLφ(τn−δn) >

Moreover, we obtain

eLφ(τn−δn) <

1

1 − Lφδn

1

1 − Lφδn

as δn → τn if τn < 1/Lφ, or δn → 1/Lφ if τn > 1/Lφ.
Therefore, there always exists δ∗
n < τn.

n satisfying 0 < δ∗

This completes the proof.
Lemma 3 states that δ∗

n can be found by solving (23), once
τn is obtained. Note that the difference (25) is positive for any
0 < δn < τn. This means that if we use larger N , then we
obtain longer transmission intervals.

To conclude, the over-all self-triggered algorithm, including

the OCP and Algorithm 1, is now stated:

Algorithm 2: (Self-triggered strategy via adaptive control

samples selection)
(i) At an update time tk, k ∈ N≥0, if x(tk) ∈ Ω(ε),
then switch to the local controller κ(x) to stabilize the
system. Otherwise, solve Problem 1 to obtain u∗(s),
x∗(s) for all [tk, tk + Tp].

(ii) For a given N , calculate δ∗

2,··· , δ∗
next transmission time tk+1 = tk +PN

N and obtain the
i , accord-
ing to Algorithm 1. Then the controller transmits the
following control samples to the plant;

i=1δ∗

1 , δ∗

N

{u∗(tk), u∗(tk + δ∗

1),··· , u∗(tk +

δ∗
i )}.

(26)

Xi=1

(iii) The plant applies (26) in a sample-and-hold fashion, and
transmits x(tk+1) to the controller as the new current
state to solve the next OCP.

(iv) k ← k + 1 and go back to Step (i).
Remark 4 (Effect of time delays). So far we have ignored
time delays arising in transmissions or calculations solving
OCPs. In practical applications, however, it may be important
to take delays into account. A method for dealing with the
delays for MPC has been proposed in the recent paper [22],
where the authors proposed delay compensation schemes by
using forward prediction, i.e., even though the delays occur,
the actual state is still able to be obtained from the system
model (1) (see Eq. (11) in [22]). Note, however, that in order
to compensate time delays and guarantee stability, the network
delays need to be upper bounded. More speciﬁcally, denoting
¯τd as the total maximum time delay which could arise, then
¯τd needs to satisfy ¯τd < Tp − ∆N so that the inter-sampling
time and the delay cannot exceed the prediction horizon Tp.
Thus, assuming that ¯τd is known, the condition

∆N < Tp − ¯τd,

(27)

is required in the self-triggered strategy in addition to (18).
Remark 5 (Effect of model uncertainties). For simplicity rea-
sons, we have not considered the effect of model uncertainties
or disturbances. However, with a slight modiﬁcation of the
self-triggered condition, these effects can be taken into ac-
count. Suppose that the actual state is xa(t) and the dynamics
are given by ˙xa = φ(xa, u) + w where w represents the
disturbance or modeling error satisfying ||w|| ≤ wmax. In this
case, the new upper bound of ||x∗(tk + ∆N )− xa(tk + ∆N )||,
denoted as ˆEx(δ1,··· , δN ) is given by
ˆEx(δ1,··· , δN ) = Ex(δ1,··· , δN ) +
where we use Gronwall-Bellman inequality, see [20] for the

Lφ (cid:0)eLφ∆N − 1(cid:1) ,

wmax

7

related analysis. The corresponding self-triggered condition is
thus given by replacing Ex with ˆEx in (18). Similarly to
n by maximizing the
Algorithm 1, it is required to obtain δ∗
difference of two upper bounds ˆEx. However, we can easily
see that

ˆEx(δ∗

1 ,··· , δ∗

n−1, τn) − ˆEx(δ∗

1 ,··· , τn − δn)

= Ex(δ∗

1 ,··· , δ∗

n−1, τn) − Ex(δ∗

1 ,··· , τn − δn)

as the effect of the disturbance can be canceled by taking the
difference of the two ˆEx. Thus, Algorithm 1 does not need to
be modiﬁed as the way to obtain sampling time intervals is
not affected.
Remark 6 (On the selection of the number of control samples).
From (25) the difference of two upper bounds is always
positive, so that more time is allowed for the self-triggered
condition to be satisﬁed by setting a new sampling time
(see the illustration in Fig. 4(c)). Thus we obtain longer
transmission time intervals as N is chosen larger. However, N
needs to be carefully chosen such that the network bandwidth
limitation can be taken into account; large values of N may not
be allowed for the network due to narrow bandwidth. More-
over, even though Algorithm 2 makes efﬁcient calculations
of N sampling intervals, a larger selection of N means more
iterations of (23), which may induce larger network delays. As
we have already mentioned in Remark 4, the delays can be
compensated. However, the allowable delays must be limited
as shown in (27). Thus, when implementing Algorithm 2, N
needs to be appropriately selected such that it satisﬁes not
only the constraint for network bandwidth but also for network
delays fulﬁlling (27).

V. STABILITY ANALYSIS

In this section, we establish stability under our proposed
self-triggered strategy. As the ﬁrst step, it is shown that if the
current state x(tk) is outside of Ω(ε), there always exists a
positive minimum inter-execution time for the self-triggered
condition (18), i.e., there exists δmin > 0 satisfying (18) for
all [tk, tk + δmin]. We will show this only for the case where
one control sample is transmitted, i.e, N = 1, since larger N
allows for longer transmission intervals according to Lemma 3
and Remark 6.

tk

LJR tk+δ1

The self-triggered condition for the case N = 1 is given
F (x∗(s), u∗(s))ds, where x∗(tk) =
by Ex(δ1) < σ
x(tk) and Ex(δ1) = hx(δ1). By using F (x, u) ≥ α1(||x||)
from Assumption 3, the condition can be replaced by
(eLφη − 1)) dη > 0
0 ( σ
Z δ1

α1(||x∗(tk + η)||) −

(28)
where hx(δ1) is included in the integral. A sufﬁcient condition
to satisfy (28) is that the integrand is positive for all 0 ≤ η ≤
δ1, i.e.,

2KuLG

Lφ

LJ

α1(||x∗(tk + η)||) >

2KuLGLJ

Lφσ

(eLφη − 1)

(29)

for all 0 ≤ η ≤ δ1. We will thus show that if x(tk) ∈ ΣV \Ω(ε)
there exists a positive time interval δmin > 0 satisfying (29)
for all 0 ≤ η ≤ δmin.

Since there exists δmin > 0, we obtain

tk−1

J ∗(x(tk)) − J ∗(x(tk−1))
< (σ − 1)Z tk
< (σ − 1)Z tk−1+δmin
= −(1 − σ)α1(α−1
= −¯δJ < 0

tk−1

F (x∗(s), u∗(s))ds

α1(α−1

2 (εf ))ds

2 (εf )) δmin

8

(32)

(33)

where we denote ¯δJ = (1 − σ)α1(α−1
obtain

2 (εf )) δmin. Thus, we

J ∗(x(tk)) − J ∗(x(tk−1)) < −¯δJ
J ∗(x(tk−1)) − J ∗(x(tk−2)) < −¯δJ
J ∗(x(tk−2)) − J ∗(x(tk−3)) < −¯δJ

...

J ∗(x(t1)) − J ∗(x(t0)) < −¯δJ

Summing over both sides of (33) yields

J ∗(x(tk)) < −k¯δJ + J ∗(x(t0)) < −k¯δJ + J0,

(34)
where J0 is deﬁned in Deﬁnition 1. This implies J ∗(tk) →
−∞ as k → ∞, which contradicts the fact that J ∗(x(tk)) ≥ 0.
Therefore, there exists a ﬁnite time when the state enters Ω(ε).

Note again that as soon as the state reaches Ω(ε), the local
control law κ(x) is applied as a dual mode strategy. Therefore,
our control objective to asymptotically stabilize the system to
the origin is achieved, i.e., x(t) → 0 as t → ∞.

VI. SIMULATION EXAMPLES

In this section we illustrate our proposed self-triggered
scheme for both linear and nonlinear systems. Simulations
were implemented in MATLAB on a PC having 2.50 GHz
Intel (R) Core (TM) CPU and 4.00 GB RAM. As a software
package, we used SNOPT in order to solve (non)linear optimal
control problems, see [43].

Fig. 5. The illustration of Ω(ε) and the restricted terminal region Ω(εf ).

Suppose at a certain time tk + δε, the optimal state x∗(tk +
δε) enters Ω(ε) from x(tk) ∈ ΣV \Ω(ε), i.e., x∗(tk + δε) ∈
∂Ω(ε), and it enters Ω(εf ) at tk + δεf , i.e., x∗(tk + δεf ) ∈
∂Ω(εf ), as shown in Fig. 5. Since Ω(εf ) ⊂ Ω(ε), it holds that
δεf − δε > 0.

To guarantee the existence of δmin, the following two cases

are considered:

(i) x∗(tk + η) is outside of Ω(εf ) for all the time until (29)
is violated. That is, x∗(tk +η) /∈ Ω(εf ) for all η ∈ [0, ¯η],
where

α1(||x∗(tk + ¯η)||) =

2KuLGLJ

Lφσ

(eLφ ¯η − 1)

(30)

(ii) x∗(tk+η) enters Ω(εf ) by the time (29) is violated. That
is, there exists η′ ∈ [0, ¯η] where we obtain x∗(tk + η′) ∈
∂Ω(εf ).

Denote δmin,1, δmin,2 as minimum inter-execution times
for the above cases (i), (ii), respectively. For the case (i),
it holds that α1(||x∗(tk + η)||) ≥ α1(α−1
2 (εf )) > 0, since
we have F (x, u) ≥ α1(||x||) and Vf (x) ≤ α2(||x||) from
Assumption 3. Thus the minimum inter-execution time δmin,1
is given by the time interval when the R.H.S in (29) reaches
α1(α−1

2 (εf )), i.e.,

δmin,1 =

1
Lφ

ln 1 +

σLφα1(α−1

2 (εf ))

2KuLGLJ ! > 0

(31)

A. Linear case

For the case of (ii), the minimum inter-execution time is
δmin,2 = δεf − δε, since x(tk) ∈ ΣV \Ω(ε) and it takes at
least δεf − δε for the state to reach Ω(εf ). Thus, considering
both cases, the over-all minimum inter-execution time δmin is
positive and given by δmin = min {δmin,1, δmin,2}.

Based on this result, we ﬁnally obtain the following stability

theorem.

Theorem 1. Consider the networked control system in Fig. 1
where the plant follows the dynamics given by (1), and the
proposed self-triggered strategy (Algorithm 2) is implemented.
Then, if the initial state starts from x(t0) ∈ ΣV \Ω(ε), then
the state is guaranteed to enter Ω(ε) in ﬁnite time.

Proof: We prove the statement by contradiction. Starting
from x(t0) ∈ ΣV \Ω(ε), assume that the state is outside of
Ω(ε) for all the time, i.e., x(t) ∈ ΣV \Ω(ε), for all t ∈ [t0,∞).

An interesting example is to check if we can guarantee
to stabilize un-stable systems under our proposed aperiodic
control execution. Therefore, as one of such examples we
consider the following linearized system of inverted pendulum
on a cart problem (see [5]);

˙x = Ax + Bu

0

where we denote x = [x1 x2 x3 x4]T ∈ R4, u ∈ R and



0 1
0
0 0 −mg/M 0
1
0 0
0 0
0

, B =


A =


−1/M l

We set m = 0.55 as the point mass, M = 15 as the mass
of the cart, and l = 9 as the length of the massless rod. The
system is unstable having a positive eigenvalue 1 in matrix A.
The constraint for the control input is assumed to be given by
||u|| ≤ 8.5. The computed Lipschitz constants Lf and LG are




0
g/l

1/M

0

0

5

4

3

2

1

0

e
t
a
t
S

−1

−2

−3

−4
 
0

0.1

0.05

e
t
a
t

S

0

−0.05

−0.1

 
0

 

x1 (Self−triggered: σ =0.99)
x1 (Periodic: 0.19)
x2 (Self−triggered: σ =0.99)
x2 (Periodic: 0.19)

5

10

15

Time 

20

25

30

(a) State trajectories of x1 and x2

 

x3 (Self−triggered: σ =0.99)
x3 (Periodic: 0.19)
x4 (Self−triggered: σ =0.99)
x4 (Periodic: 0.19)

5

10

15
Time 

20

25

30

5

4

3

2

1

0

e
t
a
t
S

−1

−2
 
0

0.1

0.05

e
t
a
t

S

0

−0.05

−0.1

 
0

9

 

x1 (Self−triggered: σ =0.6)
x1 (Periodic: 0.13)
x2 (Self−triggered: σ =0.6)
x2 (Periodic: 0.13)

5

10

15

Time 

20

25

30

(a) State trajectories of x1 and x2

 

x3 (Self−triggered: σ =0.6)
x3 (Periodic: 0.13)
x4 (Self−triggered: σ =0.6)
x4 (Periodic: 0.13)

5

10

15

Time 

20

25

30

(b) State trajectories of x3 and x4

(b) State trajectories of x3 and x4

Fig. 6. State trajectories under the self-triggered MPC with σ = 0.99 (solid
lines) and periodic MPC with the same average transmission interval 0.19
(dot lines).

Fig. 7. State trajectories under the self-triggered MPC with σ = 0.6 (solid
lines) and periodic MPC with the same average transmission interval 0.13
(dot lines).

Pf =


70
374

490
2866

507
21
70
2968
490 2866 39212 40002
507 2968 40002 40822




given by Lf = 1.05, LG = 0.067. The stage and the terminal
cost are assumed to be quadratic and given by F (x, u) =
xTQx + uTRu where Q = 3.0I4 and R = 1.5. The terminal
cost is given by Vf = xTPf x, where

.

(35)

The matrix Pf and the local terminal controller κ(x) = Kx
are obtained by the procedure presented in [37], and given by

K =(cid:2) −1.414 −9.739 −228.1 −230.9 (cid:3)

and ε = 0.43. We set εf = 0.2 and Ku = 2.0. The prediction
horizon is Tp = 14 and the number of control input is simply
given by N = 1. The initial state is assumed to be x0 =
[1 0 0.1 0]T. From (19), σ is the parameter that restricts how
much the optimal cost J ∗ is guaranteed to decrease. Thus we
consider two cases for the choice of σ; σ = 0.6 and 0.99 in
order to compare the control performance.

Fig. 6 and Fig. 7 show the state trajectories under Algo-

rithm 2 with σ = 0.6 and σ = 0.99. Fig. 8 shows the control
input u. Fig. 9 plots the transmission intervals at each update
time until the state reaches Ω(ε). Table I shows the average
transmission intervals for both σ = 0.6 and σ = 0.99. Fig. 10
shows the sequence of the optimal costs obtained by solving
the OCPs.

As shown in Fig. 6, 7 and 8, the system is stabilized to
the origin while satisfying the input constraint ||u(t)|| ≤ 8.5.
Furthermore, as shown in Table I the average transmission
interval becomes smaller for the case σ = 0.6 than for the
case σ = 0.99, meaning that it requires more transmissions
for smaller choice of σ. As for the result of optimal costs,
on the other hand, selecting smaller σ leads to better control
performances since it enforces the optimal cost to decrease
more, see Fig. 10. Thus the result implies the trade-off be-
tween obtaining control performance and the transmission rate;
selecting larger σ leads to smaller number of transmissions,
but it degrades the control performances. On the other hand,
selecting smaller σ leads to better control performances but
requires more transmissions.

To make further comparisons, we also plotted the result
of state trajectories under the periodic (standard) MPC with

 

σ = 0.99
σ = 0.6

8

6

4

2

0

−2

−4

−6

−8

 
0

5

10

Time 

15

20

25

10

 

Self−triggered : σ = 0.99
Self−triggered : σ = 0.6

5

10

Time 

15

20

25

1200

1000

800

t
s
o
C

600

400

200

0
 
0

t
u
p
n
i
 
l
o
r
t
n
o
C

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

s
l
a
v
r
e
t
n
i
 

n
o
i
s
s
i

m

s
n
a
r
T

Fig. 8. Control input u

Fig. 10. Cost sequence

 σ =0.99)
σ =0.6

 

TABLE I

AVERAGE TRANSMISSION INTERVAL

Triggering interval

0.13

0.19

σ = 0.6

σ = 0.99

0
 
0

5

10

Time 

15

20

25

Fig. 9. Transmission interval

sample-and-hold implementation in Fig. 6 and 7 as red and
blue dotted lines. In order to compare control performances
under the same transmission rate, the sampling times were
selected as 0.13 and 0.19, which are same as the average
transmission intervals obtained by Algorithm 2 in Table I.
From Fig. 7, the state trajectories under the self-triggered
strategy with σ = 0.6 have similar convergences to the
periodic case. However, as shown in Fig. 6, the state for the
periodic case with σ = 0.99 fails to be stabilized. This means
that the sampling time was not appropriately selected as it was
not chosen to guarantee stability, even though the transmission
rate is the same as the self-triggered case. Therefore, we show
by considering the unstable system that the system is stabilized
under our proposed self-triggered strategy.

B. Nonlinear case

For the nonlinear case, we consider the position control of a
non-holonomic vehicle regulation problem in two dimensions
[40]. The dynamics can be modeled as

d

dt


x
y

θ 
 =


cos θ
sin θ

0

0
0

1 
(cid:20) v
ω (cid:21) .

(36)

Here we denote the state as χ = [x y θ]T, consisting of the
position of the vehicle [x y], and its orientation θ (see Fig. 11).
u = [v ω]T is the control input and the constraints are assumed
to be given by ||v|| ≤ ¯v = 1.5 and ||ω|| ≤ ¯ω = 0.5. The
computed Lipschitz constant Lφ and a positive constant LG
are given by Lφ = √2¯v and LG = 1.0 (see [20]). The stage
and the terminal cost are given by F = χT Qχ + uT Ru, and
Vf = χT χ where Q = 0.1I3 and R = 0.05I2. The prediction
horizon is Tp = 7. Since the linearized system around the
origin is uncontrollable, the procedure presented in [39] is
adopted to obtain a local controller satisfying Assumption 2,
and the parameter for characterizing the terminal set is ε =
0.8. We set εf = 0.4 and the local controller is admissible if
Ku = 1.5.

Fig. 12 shows the trajectory of the vehicle under Algo-
rithm 2 with σ = 0.99 and N = 2, starting from the initial
point [−5 4 −π/2] and its goal is the origin. The blue triangles
show the position of the vehicle, where the triangle appears
when control samples are transmitted to solve the OCP. The
heading of the triangle shows the moving direction of the
vehicle. Fig. 13 shows the control input v. The triggering
intervals are plotted in Fig. 14.

In Section IV, it is stated that the sampling time intervals
N can also be obtained by solving the optimization
δ∗
1,··· , δ∗
problem (22) to obtain (21). To make a comparison, we
also plotted the state trajectory and control input in Fig. 12,
Fig. 13 as red dotted lines, where the next transmission time
is given by (21). The result of transmission time intervals is
also plotted as red marks in Fig. 14. Table II(a) shows the
average transmission time intervals under both Algorithm 1
and the method of obtaining (21) by solving (22) with different
values of N . Furthermore, Table II(b) shows the average
online computation time per each time step, including the
time to solve the OCP and to select sampling time intervals

11

Self−triggered (Algorithm 1)
Self−triggered (obtain (21))

 

1.6

1.4

1.2

1

0.8

0.6

0.4

0.2

v
 
 
t
u
p
n
i
 
l
o
r
t
n
o
C

 
0
0

2

4

6

8

Time

10

12

14

16

Fig. 13. Control input of the self-triggered strategy by applying Algorithm 1
(blue line) and by obtaining (21) (red dotted line).

Self−triggered (Algorithm 1)
Self−triggered (obtain (21))

 

3

2.5

2

1.5

1

0.5

e
m

i
t
 
g
n
i
r
e
g
g
i
r
T

 
0
0

2

4

6

8
Time

10

12

14

16

Fig. 14.
Algorithm 1 (Blue) and the method of obtaining (21) (Red).

Transmission time intervals of the self-triggered strategy under

APPENDIX

(Proof of Lemma 1): Consider the optimal costs J ∗(x1),
J ∗(x2) obtained by different initial states x(0) = x1, x(0) =
x2. Here the current time is assumed to be 0 without loss of
generality. Let x∗
2(s)
2(0) = x2) be the optimal state and control trajectory for
(x∗
s ∈ [0, Tp], obtained by solving Problem 1. These optimal
costs are then given by

1(0) = x1), and x∗

1(s) (x∗

1(s), u∗

2(s), u∗

F (x∗

i (s), u∗

i (s))ds + Vf (x∗

i (Tp))

(37)

J ∗(xi) =Z Tp

0

for i = 1, 2. Now consider the difference J ∗(x1) − J ∗(x2).
Assume that from the initial state x1, an alternative control
input ¯u1(s) = u∗
2(s) ∈ U (s ∈ [0, Tp]) is applied and let ¯x1(s)
be the corresponding state obtained by applying ¯u1(s). Also
let ¯J(x1) be the corresponding cost. Since J ∗(x1) ≤ ¯J(x1),
we obtain
J ∗(x1) − J ∗(x2) ≤ Z Tp

LF||¯x1(s) − x∗
+LVf||¯x(Tp) − x∗

2(s)||ds
2(Tp)||

(38)

0

Fig. 11.
dimensions.

The state variables for a vehicle regulation problem in two

y

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0
−5

−4.5

−4

−3.5

−3

−2.5
x

−2

−1.5

−1

−0.5

0

Fig. 12.
State trajectories under the self-triggered MPC (triangles) and
periodic MPC (red dotted line). The triangles appear when the control input
samples are transmitted.

N . Since the minimum values of Ex are obtained
δ∗
1,··· , δ∗
by solving (22), larger average transmission time intervals
are obtained than by applying Algorithm 1, as shown in
Table II(a). However, as shown in Table II(b), obtaining (21)
requires much more computation time, since (22) needs to be
solved for a large number of times. Therefore, it is shown
that Algorithm 1 is more useful for practical applications than
obtaining (21), in terms of the calculation cost to obtain the
sampling time intervals δ∗

N .
1,··· , δ∗

VII. CONCLUSION AND FUTURE WORK

We proposed an aperiodic formulation of MPC for net-
worked control systems, where the plant with actuator and
sensor systems are connected to the controller through wired
or wireless sensor networks. Our proposed scheme not only
provided when to solve OCPs but also the efﬁcient way
to select sampling intervals to achieve transmission inter-
vals as large as possible. Stability under sample-and-hold
implementation was also shown by guaranteeing the positive
minimum inter-execution time of the self-triggered strategy.
Our proposed framework was also validated through both
linear and nonlinear simulation examples. Future work is to
consider more detailed analysis of self-triggered strategies
under additive noise or uncertainties.

AVERAGE TRANSMISSION INTERVALS AND THE CALCULATION TIMES

TABLE II

(a) Average transmission intervals

N

Algorithm 1
Obtain (21)

1

0.17
0.17

2

0.24
0.30

3

0.41
0.58

4

0.58
0.74

5

0.68
0.83

(b) Average calculation time per each step (sec)
N

1

2

3

4

Algorithm 1
Obtain (21)

0.31
0.31

0.35
7.78

0.41
11.9

0.47
16.3

5

0.52
35.8

where the Lipschitz continuities of F and Vf are used. From
Gronwall-Bellman inequality, we have ||¯x1(s) − x∗
2(s)|| ≤
eLφs||x1 − x2|| for s ∈ [0, Tp]. Thus, we obtain

J ∗(x1) − J ∗(x2)
≤ LF||x1 − x2||Z Tp
=(  LF

+ LVf! eLφTp −

Lφ

0

eLφsds + LVf eLφTp||x1 − x2||

LF

Lφ)||x1 − x2||

Thus the proof is complete.

REFERENCES

[1] W. P. M. H. Heemels, K. H. Johansson, and P. Tabuada: ‘An Introduction
to Event-triggered and Self-triggered Control’, in Proceedings of IEEE
Conference on Decision and Control, pp. 3270 - 3285, 2012.

[2] P. Tabuada : ‘Event-triggered real-time scheduling of stabilizing control
tasks’, IEEE Transactions on Automatic Control, 52(9), pp. 1680-1685,
2007.

[3] G. S. Seyboth, D. V. Dimagoronas, and K. H. Johansson: ‘Event-based
broadcasting for multi-agent average consensus’, Automatica, 49(1), pp.
245-252, 2013.

[4] W. P. M. H. Heemels and M. C. F Donkers: ‘Model-based periodic event-
triggered control for linear systems’, Automatica, 49(3), pp. 698-711,
2013.

[5] X. Wang and M. D. Lemmon: ‘On event design in event-triggered

feedback systems’, Automatica, 47(10), pp. 2319-2322, 2011.

[6] W. P. M. H. Heemels, J. Sandee, and P. van den Boshch: ‘Analysis
of event-driven controllers for linear systems’, International Journal of
Control , 81(4) pp. 571-590, 2008.

[7] S. Hu, D. Yue, M. Shi, et al.: ‘Discrete-Time Event-Triggered Control of
Nonlinear Wireless Networked Control systems’, Abstract and Applied
Analysis, 2014.

[8] M. C. F. Donkers and W. P. M. H. Heemels: ‘Output-Based Event-
Triggered Control with Guaranteed L∞ gain and Decentralized Event-
triggering’, IEEE Transactions on Automatic Control, 57(6), pp. 1362-
1376, 2011.

[9] X. Wang and M. D. Lemmon: ‘Self-triggered feedback control systems
with ﬁnite L2 gain stability’, IEEE Transactions on Automatic Control,
54(3), pp. 452-467, 2009.

[10] Jr. M. Mazo, A. Anta, and P. Tabuada: ‘An ISS self-triggered implemen-

tation of linear controllers’, Automatica, 46(8), pp. 1310-1314, 2010.

[11] A. Anta and P. Tabuada: ‘Self-triggered stabilization of homogeneous
control systems’, in Proceedings of American Control Conference, pp.
4129-4134, 2008.

[12] A. Anta and P. Tabuada: ‘To Sample or not to Sample: Self-Triggered
Control for Nonlinear Systems’, IEEE Transactions on Automatic Control,
55(9) pp. 2030-2042, 2010.

[13] D. Lehmann, E. Henriksson, and K. H. Johansson: ‘Event-Triggered
Model Predictive Control of Discrete-Time Linear Systems subject to
Disturbances’, in Proceedings of European Control Conference, pp. 1156-
1161, 2013.

[14] E. Henriksson, D. E. Quevedo, H. Sandberg et al.: ‘Self-triggered Model
Predictive Control for Network scheduling and control’, in Proceedings
of IFAC Symposium on Advanced Control of Chemical Processes, pp.
432-438, 2012.

12

[15] J. D. J. B. Berglind, T. M. P. Gommans, and W. P. M. H. Heemels: ‘Self-
Triggered MPC for Constrainted Linear Systems and Quadratic Costs’,
in Proceedings of IFAC Nonlinear Model Predictive Control Conference,
pp. 342-348, 2012.

[16] T. Gommans, D. Antunes, T. Donkers et al.: ‘Self-triggered linear

quadratic control’, Automatica, 50(4), pp. 1279-1287, 2014.

[17] D. Antunes and W. P. M. H. Heemels: ‘Rollout Event-triggered Control:
Beyond Periodic Control Performance’, IEEE Transactions on Automatic
Control, 59(12), pp. 3296-3311, 2014.

[18] A. Eqtami, D. V. Dimarogonas, and K. J. Kyriakopoulos: ‘Event-
triggered Control for Discrete time systems’, in Proceedings of American
Control Conference, pp. 4719-4724, 2010.

[19] S. Liu, J. Zhang, Y. Feng, et al.: ‘Distributed Model Predictive Control
with Asynchronous Controller Evaluations’, The Canadian Journal of
Chemical Engineering, 91(10), pp. 1609-1620, 2013.

[20] A. Eqtami, S. Heshmati-Alamdari, D. V. Dimarogonas, and K. J. Kyr-
iakopoulos: ‘Self-triggered Model Predictive Control for nonholonomic
systems’, in Proceedings of European Control Conference, pp. 638 - 643,
2013.

[21] H. Li and Y. Shi: ‘Event-triggered robust model predictive control of
continuous-time nonlinear systems’, Automatica, 50(5), pp. 1507-1513,
2014.

[22] P. Varutti, B. Kern, T. Faulwasser, and R. Findeisen: ‘Event-based Model
Predictive Control for Networked Control Systems’,
in Proceedings
of IEEE Conference Decision and Control and 28th Chinese Control
Conference, pp. 567-572, 2009.

[23] F. D. Brunner, W. P. M. H. Heemels, and F. Allgower:

‘Robust
self-triggered MPC for constrained linear systems’, in Proceedings of
American Control Conference, pp. 472-477, 2014.

[24] K. Hashimoto, S. Adachi, and D. V. Dimarogonas: ‘Distributed Ape-
riodic Model Predictive Control for Multi-Agent Systems’, IET Control
Theory and Applications, 9(1), pp. 10-20, 2015.

[25] D. V. Dimagoronas, E. Frazzoli, and K. H. Johansson: ‘Distributed event-
triggered control for multi-agent systems’, Automatica, 57(5), pp. 1291-
1297, 2012.

[26] J. P. Hespanha, P. Naghshtabrizi, and Xu Yonggang: ‘A Survey of Recent
Results in Networked Control Systems’, Proceedings of the IEEE, 95(1),
2007.

[27] P. Mhaskar, N. H. El-Farra, and P. D. Christoﬁdes: ‘Stabilization of
nonlinear systems with state and control constraints using Lyapunov based
predictive control’, System Control Letters, 55(8), pp. 650-659, 2006.

[28] D. M. de la Pena and P. D. Christoﬁdes: ‘Lyapunov-Based Model
Predictive control of Nonlinear Systems subject to Data Losses’, IEEE
Transactions on Automatic Control, 53(9), pp. 2076-2089, 2008.

[29] D. D. Ruscio: ‘Model Predictive Control with Integral Action: A simple
MPC algorithm’, Modeling, Identiﬁcation and Control, 34(3), pp. 119-
129, 2013.

[30] P. Varutti, T. Faulwasser, B. Kern, M. Kogel, and R. Findeisen: ‘Event-
based reduced-attention predictive control for nonlinear uncertain sys-
tems’ in Proceedings of IEEE International Sysmposium on Computer-
Aided Control System Design , pp. 1085-1090, 2010.

[31] D. Bernardini and A. Bemporad: ‘Energy-aware robust model predictive
control based on noisy wireless sensors’, Automatica, 48(1), pp. 36-44,
2012.

[32] G. Goodwin, H. Haimovich, D. Quevedo, and J. Welsh: ‘A moving
horizon approach to networked control system design’, IEEE Transactions
on Automatic Control, 49(9), pp. 1427-1445, 2004.

[33] D. Q. Mayne, J. B. Rawlings, C. V. Rao, and P. O. M. Scokaert: ‘Con-
strained model predictive control: Stability and optimality’, Automatica,
36(6), 789-814, 2000.

[34] H. Michalska and D. Q. Mayne: ‘Robust receding horizon control of
constrained nonlinear systems’, IEEE Transactions on Automatic Control,
38(11), pp. 1623-1633, 1993.

[35] D. Q. Mayne, M. M. Seron, and S. V. Rakovic: ‘Robust model pre-
dictive control of constrained linear systems with bounded disturbances’,
Automatica, 41(2), 219-229, 2000.

[36] L. Magni, D. M. Raimondo, and R. Scattolini: ‘Input-to-State Stability
for Nonlinear Model Predictive Control’, in Proceedings of IEEE Con-
ference on Decision and Control, pp. 4836-4841, 2006.

[37] H. Chen and F. Allogower: ‘A Quasi-Inﬁnite Horizon Nonlienar Model
Predictive Control with Guaranteed Stability’, Automatica, 34(10), pp.
1205-1217, 1998.

[38] D. L. Marruedo, T. Alamo and E. F. Camacho: ‘Input-to-state stable
MPC for constrained discrete-time nonlinear systems with bounded
additive uncertainties’, in Proceedings of IEEE Conference on Decision
and Control, pp. 4619-4624, 2002.

13

[39] Y. Zhu and U. Ozuner: ‘Robustness Analysis on Constrained Model
Predictive Control for Nonholonomic Vehicle Regulation’, in Proceedings
of American Control Conference, pp. 3896-3901, 2009.

[40] W. B. Dunbar and R. M. Murray: ‘Distributed Receding Horizon Control
for Multi-Vehicle Formation Stabilization’, Automatica, 42(4), pp. 549-
558, 2006.

[41] W. B. Dunbar: ‘Distributed Receding Horizon Control of Vehicle Pla-
toons: Stability and String Stability’, IEEE Transactions on Automatic
Control, 57(3), pp. 620-633, 2012.

[42] R. Findeisen, L. Imsland, F. Allgower, and B. A. Foss: ‘State and
Oputput Feedback Nonlinear Model Predictive Control: An Overview’,
European Journal of Control, 9(9), pp. 190-206, 2003.

[43] P. E. Gill, W. M. Murray, and M.A. Saunders:‘User’s Manual for SNOPT
Version 7: Software for Large-Scale Nonlinear Programming’ University
of California, San Diego Report, 2007.

[44] L. Magni and R. Scattolini: ‘Model Predictive Control of Continuous-
Time Nonlinear Systems With Piecewise Constant Control’, IEEE Trans-
actions on Automatic Control, 49(6), pp. 900-906, 2004.

