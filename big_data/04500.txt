6
1
0
2

 
r
a

 

M
4
1

 
 
]
T
S
h
t
a
m

.

[
 
 

1
v
0
0
5
4
0

.

3
0
6
1
:
v
i
X
r
a

Optimal designs for dose response curves with common

parameters

Chrystel Feller∗, Kirsten Schorning#, Holger Dette#

Georgina Bermann∗, Bj¨orn Bornkamp∗

∗Statistical Methodology

Novartis Pharma AG

4002 Basel, Switzerland

#Ruhr-Universit¨at Bochum

Fakult¨at f¨ur Mathematik

44780 Bochum, Germany

March 16, 2016

Abstract

A common problem in Phase II clinical trials is the comparison of dose response curves
corresponding to diﬀerent treatment groups. If the eﬀect of the dose level is described by
parametric regression models and the treatments diﬀer in the administration frequency (but
not in the sort of drug) a reasonable assumption is that the regression models for the diﬀerent
treatments share common parameters.
This paper develops optimal design theory for the comparison of diﬀerent regression models
with common parameters. We derive upper bounds on the number of support points of
admissible designs, and explicit expressions for D-optimal designs are derived for frequently
used dose response models with a common location parameter.
If the location and scale
parameter in the diﬀerent models coincide, minimally supported designs are determined and
suﬃcient conditions for their optimality in the class of all designs derived. The results are
illustrated in a dose-ﬁnding study comparing monthly and weekly administration.

Keywords and Phrases: Nonlinear regression, diﬀerent treatment groups, D-optimal design, mod-
els with common parameters, admissible design, Bayesian optimal design
AMS Subject Classiﬁcation: Primary 62K05; Secondary 62F03

1

Introduction

Adequately describing the dose-response relationship of a pharmaceutical compound is of paramount
importance for achieving a successful clinical development. Sacks et al. (2014) recently conducted
a review of the reasons for delay or denial of approval of drugs by the Food and Drug Administra-
tion (FDA). For those drug submissions that were not approved in the ﬁrst-time application, one

1

of the most frequent deﬁciencies was a statistical uncertainty related to the selected dose, illus-
trating the importance of clearly determining an eﬃcacious and safe dose in Phase II dose-ﬁnding
trials.
Eﬀorts to improve this situation have led to the introduction of dose-response modeling approaches
in a prospective manner as the primary analysis method in dose ﬁnding studies, and have become
increasingly widespread in the past few years [see among many others, Grieve and Krams (2005),
Bretz et al. (2005), Thomas (2006), Dragalin et al. (2007), Bornkamp et al. (2007), Thomas et al.
(2014)]. These methods can more adequately address the main questions of interest in Phase
II dose-ﬁnding studies (i.e. determination of the dose-response curve and estimation of target
doses of interest) than AN(C)OVA based pairwise comparisons. Moreover, it was pointed out by
numerous authors that an appropriate choice of the experimental conditions can improve the sta-
tistical accuracy in dose-ﬁnding studies substantially. For this reason there exists a large amount
of literature discussing the problem of constructing optimal experimental designs for regression
models, which are commonly used to describe the dose relationships [see Dragalin et al. (2007),
Dette et al. (2008), Dragalin et al. (2008), Fang and Hedayat (2008), Gilbert (2010), or Bretz
et al. (2010) among many others].
For many compounds a question closely related to “dose”, the amount of drug, is the administra-
tion frequency of the drug. In most situations it is not adequate to assume that the same amount
of drug per time unit (e.g. total daily dose) administered at diﬀerent dosing intervals (e.g. once
a day or twice a day) will lead to the same pharmacological eﬀect. For example for once a day
administration the drug exposure inside the body will generally be higher just after administration
and lower just before the next administration, compared to a twice a day administration, where
the same amount of drug is split into two doses in the morning and the evening, leading to more
uniform drug exposure over the day.
These considerations often lead to the need of evaluating the question of ﬁnding the right dose as
well as dosing frequency dose-ﬁnding studies in Phase II. One way of modeling the dose-response
curves in the diﬀerent treatment groups is to estimate the dose response curve corresponding to
each of them separately. This can, however, be wasteful as certain aspects of the dose-response
curves for diﬀerent group can be similar for both groups, suggesting a borrowing of strength. When
dose-response modeling is done in terms of parametric dose-response models, one can often assume
that certain parameters of the dose-response curves for the two (or more) groups are shared, while
other parameters might be assumed to be diﬀerent between the curves. For example, if the Emax
function

f (d, θ1, θ(i)

2 ) = θ(i)

0 +

θ(i)
1 d
θ(i)
2 + d

, i = 1, 2

(1.1)

is used to model the dose response relationship for both groups [see Gabrielsson and Weiner
(2007) or Thomas et al. (2014)], it is often reasonable to assume that the placebo eﬀect is the
same between groups, that is θ(1)
0 = ϑ11. In some situations it might also make sense to

0 = θ(2)

2

(cid:54)= θ(2)

1 = θ(2)

assume that the maximum eﬃcacy for high doses is similar, i.e. θ(1)
1 = ϑ12, as a biological
maximum attainable eﬀect might exist. However it might not be adequate to assume that the
dose providing half of the maximum eﬃcacy is the same for diﬀerent treatment frequencies, which
means θ(1)
2 . The common parameters can then be estimated more precisely allowing for a
2
more accurate statistical analysis. An example motivating the research of this paper can be found
in Section 5.
The major question when planning such a dose-ﬁnding study then is which doses to utilize in the
diﬀerent treatment groups and how to split the total sample size between the groups. Statistically,
this corresponds to the construction of optimal designs for diﬀerent regression models (modeling
the eﬀect of the drug in the diﬀerent groups) which share some common parameters. To our best
knowledge, design problems in this case have not been considered in the literature, and the goal
of the present paper is to derive optimal designs for such situations. In Section 2 the model (in
the context of M treatment groups) is introduced and the main diﬀerences between the situation
considered in the paper and the common optimal design problems are explained. In Section 3
we derive some results on the comparison of diﬀerent designs for regression models with common
parameters with respect to the Loewner ordering. In particular we generalize recent results of
admissible designs as presented in Yang (2010), Dette and Melas (2011) and Yang and Stufken
(2012) and derive upper bounds on the number of support points which cannot be improved upon
in the Loewner ordering. Section 4 is devoted to the construction of D-optimal designs which
are well suited for a “global” inference as they minimize the maximum conﬁdence interval length
around the predicted dose-response curve. Explicit expressions for locally D-optimal designs for
the commonly used dose response models are derived, if some parameters of the models for the
diﬀerent groups coincide. We also discuss minimally supported optimal designs and investigate if
these designs are optimal within the class of all designs. In Section 5 we illustrate the developed
methods in a particular clinical dose-ﬁnding study investigating two diﬀerent treatment groups.
Finally, all technical details and proofs are given in Section 6 while Section 7 provides some more
background on the modeling problem discussed in Section 5.
For the sake of brevity and transparency, most parts of this paper consider locally optimal designs
which require a-priori information about the unknown model parameters if the models are non-
linear [see Chernoﬀ (1953)]. In several situations preliminary knowledge regarding the unknown
parameters of a nonlinear model is available but not in a form that is accurate enough to specify
one parameter guess. As illustrated in Section 5, locally optimal designs can be used as bench-
marks for commonly used designs and also serve as basis for constructing optimal designs with
respect to more sophisticated optimality criteria, which are robust against a misspeciﬁcation of
the unknown parameters (and model) [see Pronzato and Walter (1985) or Chaloner and Verdinelli
(1995), Dette (1997) among others]. Following this line of research the methodology introduced
in the present paper can be further developed to address uncertainty in the preliminary informa-
tion on the unknown parameters, and we will illustrate this approach in Section 5, where we also

3

discuss robust designs for the data example under consideration.

2 Models with common parameters

Consider the regression models
j , θ1, θ(i)

Yij(cid:96) = f (d(i)

2 ) + εij(cid:96)

1 , . . . , d(i)
ki

i = 1, . . . , M ; j = 1, . . . , ki; (cid:96) = 1, . . . , nij,

given by n = (cid:80)M

i=1 ni. In general, the regression model f (·, θ1, θ(i)

, which vary in possibly diﬀerent design spaces, say Xi = [0, d(i)

the experimenter can take nij observations and ni = (cid:80)ki

(2.2)
where εij(cid:96) are independent centered normally distributed random variables, i.e. εij(cid:96) ∼ N (0, σ2
i ).
The assumption of a normal distribution in (2.2) is made for the sake of transparency. Other
distributional assumptions can be treated exactly in the same way. This means that M diﬀerent
groups are investigated and in each group observations are taken at diﬀerent experimental condi-
tions d(i)
max] (i = 1, . . . , M ).
At each dose level d(i)
j=1 nij denotes
j
the number of observations in the i-th group (i = 1, . . . , M ). Moreover, the total sample size is
2 ) with a (p + q)-dimensional
parameter vector θ(i) = (θ1, θ(i)
2 ) is used to describe the dependency between the response and
the eﬀect in every group. We consider the same parametric form for all groups. Moreover, the
parameter vector θ1 ∈ Rp is assumed to be the same in all groups (i = 1, . . . , M ), while θ(i)
2 ∈ Rq
is diﬀerent for diﬀerent groups. Consequently, the vector of unknown parameters is given by
) ∈ Rm, where m = p + qM . The components of the vector are denoted by
θ = (θ1, θ(1)
θ1 = (ϑ1, . . . , ϑp) and θ(i)
2 = (ϑ(i)
Following Kiefer (1974) we deﬁne for i = 1, . . . , M approximate designs ξi (on the design space Xi)
j ∈ Xi (j = 1, . . . , ki)
as probability measures with masses ξij at the experimental conditions d(i)
and a design µ as a probability measure on the set {1, . . . , M} assigning mass λi to the ith
group. We collect these designs in the vector ξ = (ξ1, . . . , ξM , µ), which is also called design (on
the design space X1 × . . . × XM × {1, . . . , M}) throughout this paper. If an approximate design
ξ = (ξ1, . . . , ξM , µ) is given and N observations can be taken, a rounding procedure is applied
to obtain integers ni and nij (i = 1, . . . M, j = 1, . . . , ki) from the not necessarily integer valued
quantities λin and ξijni, respectively [see Pukelsheim and Rieder (1992)]. Then, under common
assumptions of regularity and the assumption

2 , . . . , θ(M )

2

1 , . . . , ϑ(i)

q ) (i = 1, . . . , M ).

lim
ni→∞

nij
ni

= ξij ∈ (0, 1) and lim
n→∞

ni

n = λi ∈ (0, 1)

(i = 1, . . . , M , j = 1, . . . , ki), the maximum likelihood estimate ˆθ = (ˆθ1, ˆθ(1)
n → ∞)

2 , . . . , ˆθ(M )

2

where the symbol

D−→ N (0, M−1(ξ, θ)) ,
D−→ denotes weak convergence. Here the matrix

n(ˆθ − θ)

(2.3)

) satisﬁes (as

√

(cid:90) (cid:90)

Xz

M(cid:88)

i=1

4

M (ξ, θ) =

hz(d)hT

z (d)dξz(d)dµ(z) =

λiM (i)(ξi, θ)

(2.4)

is called the information matrix of the design ξ = (ξ1, . . . , ξM , µ) and will be derived in Section
6.1. In (2.4) the matrices M (i) are deﬁned by

(cid:90)

Xi

(i = 1, . . . , M ) and

hT
i (d) =

(cid:16) ∂

∂θ1

1
σi

f (d, θ1, θ(i)

2 ), 0T

M (i)(ξi, θ) =

hi(d)hT

i (d)dξi(d)

(2.5)

(cid:17) ∈ Rm

(cid:124)

∂

,

(cid:125)

q , . . . , 0T
q

f (d, θ1, θ(i)

(cid:123)(cid:122)
2 ) with respect to the parameter θ ∈ Rm, where, m =

q , . . . , 0T
q

2 ), 0T

(cid:123)(cid:122)

(2.6)

M−i

(cid:125)

(cid:124)

∂θ(i)
2

i−1

is the gradient of the function f (d, θ1, θ(i)
p + qM , 0q ∈ Rq denotes a vector with all entries equal to 0.
Example 2.1 We assume that M = 2 and that the regression functions f (·, θ1, θ(i)
as

f (·, θ1, θ(i)

2 ) = ϑ1 + ϑ2f0(·, θ(i)
2 )

2 ) can be written

(2.7)

with a given function f0 [see Bretz et al. (2005)]. Here the location and scale parameters θ1 =
(ϑ1, ϑ2)T ∈ R2 are the same for all groups, while the parameters θ(i)
2 ∈ Rq are diﬀerent. In this
case we have p = 2 and the vectors h1(d) and h1(d) are given by

(cid:0)1, f0(d, θ(1)
(cid:0)1, f0(d, θ(2)

hT
1 (d) =

hT
2 (d) =

1
σ1
1
σ2

(cid:1),
2 )(cid:1).

2 ),

∂

∂θ(1)

2

f0(d, θ(1)

2 ), 0T
q

2 ), 0T
q ,

∂

∂θ(2)

2

f0(d, θ(2)

As a further example, consider a regression function f (·, θ1, θ(i)

2 ) of the form

f (·, θ1, θ(i)

2 ) = θ1 + f0(·, θ(i)
2 );

i = 1, 2,

(2.8)

with a given function f0. If the location parameter θ1 is the same for the two groups and the
2 ∈ Rq are diﬀerent, we have p = 1 and the vectors h1(d) and h1(d) are given by
parameters θ(i)
1 (d) = 1
hT
(1,
σ1

2 (d) = 1
σ2

q ) and hT

f0(d, θ(1)

f0(d, θ(2)

2 ), 0T

(1, 0T
q ,

2 )).

∂

∂

∂θ(2)

2

∂θ(1)

2

3 Comparing designs in the Loewner ordering

An optimal design ξ = (ξ1, . . . , ξM , µ) maximizes a concave real valued function, say Φ, of the
information matrix. Numerous criteria have been proposed in the literature (see Pukelsheim (2006)
among others) which can be used to discriminate between competing designs and the particular
case of D-optimality will be discussed in the subsequent section. The commonly used optimality
criteria are monotone with respect to the Loewner ordering, that is the relation M (ξ1, θ) ≤

5

M (ξ2, θ) implies Φ(M (ξ1, θ)) ≤ Φ(M (ξ2, θ)). For this reason we discuss at ﬁrst some results for
this ordering, which will be very helpful for the explicit determination of optimal designs in the
following sections.
Throughout this paper let |A| denote the cardinality of a set A and we denote by supp(ξ) the
support of the design ξ = (ξ1, . . . , ξM , µ). Moreover, we deﬁne the index I(ξi) of the design ξi on
the interval [0, d(i)
max are
only counted by 1/2 if they are support points of the design ξi (i = 1, . . . , M ).
Note that the gradient (2.6) can be rewritten in the form

max] as the number of support points, where the boundary points 0 and d(i)

hi(d) = 1
σi

0(i−1)q×p 0(i−1)q×q

0(M−i)q×p 0(M−i)q×p

f (d, θ1, θ(i)
2 )
f (d, θ1, θ(i)
2 )

∂θ1
∂

∂θ(i)
2

:= Pi g(d, θ1, θ(i)
2 )

(3.1)

where Pi is a (p + M q) × (p + q) block matrix, Ip×p is the p-dimensional identity matrix and
g(d, θ1, θ(i)
2 ) (i = 1, . . . , M ).
Consequently, for the information matrix (2.5) the representation

2 ) is the p+q-dimensional gradient of f (d, θ1, θ(i)

2 ) with respect to (θ1, θ(i)

(cid:32) ∂



0p×q

Iq×q

(cid:33)

0q×p

 Ip×p
(cid:90)

M (i)(ξi, θ) = Pi

2 )g(d, θ1, θ(i)
holds, where the (p + q) × (p + q) matrix C(ξi, θ1, θ(i)

g(d, θ1, θ(i)

Xi

2 )dξi(d) P T
i

:= Pi C(ξi, θ1, θ(i)

2 ) P T
i

 Ψ1,1(d, θ1, θ(i)

...

2 )

(cid:90)

Xi

2 ) is deﬁned by

. . . Ψ1,p+q(d, θ1, θ(i)
2 )
. . .

...

 dξi(d)

Ψp+q,1(d, θ1, θ(i)

2 ) . . . Ψp+q,p+q(d, θ1, θ(i)
2 )

C(ξi, θ1, θ(i)

2 ) =

for i = 1, . . . , M .
In the following we will present a generalization of results in Yang (2010), Dette and Melas
(2011) and Yang and Stufken (2012). To be precise for i = 1, . . . , M we deﬁne Ψ0(d) ≡ 1 and
choose a basis, say {Ψ0(·), Ψi
2 )|1 ≤ s, t ≤
p + q} ∪ {1}), where the dependence on the parameters is reﬂected by the upper index i for the
k(·) is a diagonal element of
sake of a transparent notation. We also assume that the function Ψi
the matrix C(ξi, θ1, θ(i)
2 ) and that
{Ψ0(·), Ψi

2 ), does not coincide with any of the other elements Ψs,t(·, θ1, θ(i)
k−1(·)} is a basis of the space

k(·)} for the space span(Ψs,t(·, θ1, θ(i)

1(·), . . . , Ψi

1(·), . . . , Ψi

k−1(·), Ψi

For our ﬁrst results we require the notation of Chebyshev system [see Karlin and Studden (1966)].
A set of k real valued functions f0, . . . , fk−1 : [A, B] → R is called Chebychev system on the interval
[A, B] if and only if it fulﬁlls the inequality

span(cid:0){Ψs,t | s, t ∈ {1, . . . , p + q}; Ψs,t (cid:54)= Ψi
k} ∪ {1}(cid:1).
 > 0

 f0(x0)

. . . f0(xk−1)
. . .

det

...

...

fk−1(x0) . . . fk−1(xk−1)

6

for any points x0, . . . , xk−1 with A ≤ x0 < x1 . . . < xk−1 ≤ B.

Lemma 3.1
(1) If for all i = 1, . . . , M the sets {Ψ0(·), Ψi
are Chebychev systems on the interval Xi = [0, d(i)
i )| ≤ k+2
ξ+ = (ξ+
2
the index of the design ξi satisﬁes I(ξi) < k
I(ξi) ≥ k

2 , the following two assertions are valid.

M , µ) with |supp(ξ+

1 , . . . , ξ+

1(·), . . . , Ψi

k−1(·)} and {Ψ0(·), Ψi

k(·)}
max], then for any design ξ there exists a design
(i = 1, . . . , M ), such that M (ξ+, θ) ≥ M (ξ, θ). If
2 the design coincides with the design ξ. In the case

1(·), . . . , Ψi

k−1(·), Ψi

(1a) If k is odd, then ξ+

i has at most k+1
2

contains d(i)

max (i = 1, . . . , M ).

support points and ξ+

i can be chosen such that its support

support points and ξ+

i can be chosen such that its

max (i = 1, . . . , M ).
1(·), . . . , Ψi

1(·), . . . , Ψi

k−1(·)} and {Ψ0(·), Ψi

k(·)}
max], then for any design ξ there exists a design
(i = 1, . . . , M ), such that M (ξ−, θ) ≥ M (ξ, θ). If
2 the design coincides with the design ξ. In the case

k−1(·),−Ψi

(1b) If k is even, then ξ+

i has at most k+2
2
support contains the points 0 and d(i)
(2) If for all i = 1, . . . , M the sets {Ψ0(·), Ψi
are Chebychev systems on the interval Xi = [0, d(i)
i )| ≤ k+2
ξ− = (ξ−
2
the index of the design ξi satisﬁes I(ξi) < k
I(ξi) ≥ k
(2a) If k is odd, then ξ−

2 , the following two assertions are valid.

M , µ) with |supp(ξ−

1 , . . . , ξ−

i has at most k+1
2

support points and ξ−

i can be chosen such that its support

contains 0.

(2b) If k is even, then ξ−

i has at most k

2 support points.

k−1(·), Ψi

1(·), . . . , Ψi

1(·), . . . , Ψi

k−1(·) and Ψ0(·), Ψi

Lemma 3.1 provides an upper bound for the maximal number of support points if the functions
Ψ0(·), Ψi
k(·) are Chebychev systems for the diﬀer-
ent groups i = 1, . . . , M . Note that this bound is the same independently from the dimension of
θ1, since the number of support points is bounded in every group 1, . . . , M separately. The next
lemma shows that (for the commonly used dose response models) it is suﬃcient to allocate only
patients from the group with the smallest population variance to placebo.
Lemma 3.2 Assume that the design spaces are given by Xi = [0, d(i)
max] (i = 1, . . . , M ) and that
the regression models are given by (2.7) or by (2.8), where the function f0 is diﬀerentiable with
respect to θ(i)
If
2
η = (η1, . . . , ηM , ν) denotes a design with 0 ∈ supp(ηj) for (at least) one index j, then there exists
a design ξ = (ξ1, . . . , ξM , µ) with the following properties

(i = 1, . . . , M ). Moreover, assume that f0(0, θ2) = 0 and ∂
∂θ2

f0(0, θ2) = 0.

M (η, θ) ≤ M (ξ, θ), 0 ∈ supp(ξj∗), 0 (cid:54)∈ supp(ξj) for all j (cid:54)= j∗,

where j∗ ∈ argmini=1,...,M σ2
i .

7

model

Emax

Linear-in-log

Exponential

location

location and scale

θ1 + ϑ(i)
1

d
ϑ(i)
2 +d

(3.2)

ϑ1 + ϑ2

d
θ(i)
2 +d

(3.5)

θ1 + ϑ(i)

1 log(d/ϑ(i)

2 + 1) (3.3)

θ1 + ϑ(i)

1 (exp(d/ϑ(i)

2 )− 1) (3.4)

ϑ1 + ϑ2 log(d/θ(i)

2 + 1)

(3.6)

(cid:16)

(cid:17)
2 ) − 1

exp(d/θ(i)

ϑ1 + ϑ2

(3.7)

Table 1: Commonly used dose response models for i = 1, . . . , M . Left column: The placebo eﬀect
is the same in every group (common location). Right column: Both the placebo eﬀect and the scale
parameter coincide in every group (common location and scale).

In the following discussion we will apply the previous results to some of the commonly used dose
response models, namely the Emax model, linear-in-log and exponential model [see Gabrielsson
and Weiner (2007)], which are listed in Table 1. In this table we also illustrate our notation again.
The left part of the table corresponds to a model with a common location parameter (namely θ1),
while the right part of the table shows a model with a common location (ϑ1) and scale parameter
(ϑ2). We note that all these models satisfy the conditions of Lemma 3.1 and Lemma 3.2.
Corollary 3.3 Let ξ = (ξ1, . . . , ξM , µ) denote an arbitrary design with |supp(ξi)| ≥ 3 (i =
1, . . . , M ) and assume (w.l.o.g) that σ2

1 = mini=1,...,M σ2
i .

(1) If the regression model is given by the Emax model (3.2) or (3.5), then there exists a de-
M , µ) with at most 2M + 1 support points such that M (ξ+, θ) ≥ M (ξ, θ).
i )| =

sign ξ+ = (ξ+
Moreover, ξ+ can be chosen such that |supp(ξ+
2 with d(i)

1 , . . . , ξ+
max ∈ supp(ξ+

1 )| = 3 with 0, d(1)

1 ) and |supp(ξ+

max ∈ supp(ξ+

i ) (i = 2, . . . , M ).

(2) If the regression model is given by the linear-in-log model (3.3) or (3.6), then there exists
M , µ) with at most 2M + 1 support points such that M (ξ+, θ) ≥
1 ) and

a design ξ+ = (ξ+
M (ξ, θ). Moreover, ξ+ can be chosen such that |supp(ξ+
|supp(ξ+

1 )| = 3 with 0, d(1)

max ∈ supp(ξ+

max ∈ supp(ξ+

i )| = 2 with d(i)

i ) (i = 2, . . . , M ).

1 , . . . , ξ+

(3) If the regression model is given by the exponential model (3.4) or (3.7), then there exists a
M , µ) with at most 3M support points such that M (ξ+, θ) ≥ M (ξ, θ).
i ) (i = 1, . . . , M ).

i can be chosen such that |supp(ξ+

design ξ+ = (ξ+
Moreover, ξ+

i )| = 3 and d(i)

max ∈ supp(ξ+

1 , . . . , ξ+

8

4 D-optimal designs

When one of the major purposes of the study is to determine the dose-response curve, D-optimal
designs are well suited as they minimize the maximum conﬁdence interval length around the
predicted dose-response curve [see Silvey (1980)]. Following Chernoﬀ (1953), a design ξ =
(ξ1, . . . , ξM , µ) is called (locally) D-optimal for the information matrix given in (2.4) if it max-
imizes the determinant of the information matrix det(M (ξ, θ)) in the class of all designs ξ on
X1 × . . . × XM × {1, . . . , M}. A main tool of optimal design theory are equivalence theorems
which, on the one hand provide a simple checking condition for the optimality of a given de-
sign, and on the other hand, are the basis of many procedures for their numerical construction.
Moreover, these characterizations of optimality can also be used to derive structural properties
of optimal designs. The following result provides the equivalence theorem for the D-optimality
criterion corresponding to the matrix given in (2.4). The proof follows by standard arguments of
optimal design theory and is therefore omitted.

Theorem 4.1 The design ξ(cid:63) = (ξ(cid:63)

1, . . . , ξ(cid:63)

M , µ(cid:63)) is D-optimal if and only if the M inequalities

κi(d, ξ(cid:63), θ) = hT

(4.1)
are satisﬁed for all d ∈ Xi, i = 1, . . . , M . Equality holds in (4.1) for any points (d1, . . . , dM , z) ∈
supp(ξ(cid:63)

1) × . . . × supp(ξ(cid:63)

M ) × supp(µ(cid:63)).

i (d)M−1(ξ(cid:63), θ)hi(d) ≤ m = p + qM,

ΞM

i=1

m =

ξ = (ξ1, . . . , ξM , µ)

(4.2)
as the set of all designs on X1 × . . . × XM × {1, . . . , M} with exactly m diﬀerent dose levels in the
M groups. The proof of the next lemma follows by similar arguments as in the standard case [see
Silvey (1980) among others], and is therefore also omitted.
Lemma 4.2 Let ξ = (ξ1, . . . , ξM , µ) ∈ ΞM

denote the number of support points of ξi (i = 1, . . . , M ). Assume that the m =(cid:80)M

m denote a design on X1× . . .×XM ×{1, . . . , M} and mi
i=1 mi vectors
j ∈ supp(ξi)

mM ) are linearly independent where d(i)

1 ), . . . , h1(d(1)

m1), . . . , hM (d(M )

h1(d(1)
j = 1, . . . , mi, i = 1, . . . , M .
If ξ is locally D-optimal in the class ΞM
points. Moreover, the weights of µ at the points 1, . . . , M are given by m1

), . . . , hM (d(M )

m , then each component ξi has equal weights at its support

1

m , . . . , mM

m , respectively.

In the following two sections we present some locally D-optimal designs for the Emax, the ex-
ponential and the linear-in-log model. The proofs of these results are complicated and therefore
deferred to Section 6.

9

Denote

(cid:110)

(cid:12)(cid:12)(cid:12) M(cid:88)

(cid:111)

|supp(ξi)| = m

4.1 Models with the same location parameter

First, we consider the case where only the location parameter is the same in the diﬀerent models.
In applications this reﬂects the situation of a common placebo eﬀect for all groups (cf. the ﬁrst
column of Table 1), and we are able to identify the locally D-optimal design explicitly. We begin
with a general result for the regression functions of the form (2.8) where the unknown parameter
)T ∈ Rm with m = 1 + M q. The following result
vector is given by θ = (θ1, θ(1),T
provides a solution of the D-optimal design problem if the D-optimal design for the single models
are known.

, . . . , θ(M ),T

2

2

Theorem 4.3 Let σ2

1 = mini=1,...,M σ2

i and consider the model given by (2.8), which satisﬁes

f0(0, θ(i)

2 ) = 0 ,

f0(d, θ(i)

∂

∂θ(i)
2

2 )|d=0 = 0q
(cid:33)

(i = 1, . . . , M ). If the design

˜ξ(i) =

0 d(i)
1
1
1
q+1 . . .

. . . d(i)
q
1

q+1

q+1

(4.3)

(4.4)

(cid:32)

(cid:33)

(cid:32)

is locally D-optimal for the single model f (d, θ1, θ(i)
design for model (2.8) is given by ξ(cid:63) = (ξ(cid:63)

1, . . . , ξ(cid:63)

M , µ(cid:63)) where

2 ) (i = 1, . . . , M ), then the locally D-optimal

(cid:32)

(cid:33)

1 = ˜ξ(1),
ξ(cid:63)

ξ(cid:63)
i =

d(i)
1
1
q

. . . d(i)
q
1
. . .
q

, i = 2, . . . , M, µ(cid:63) =

.

(4.5)

1
q+1
m

2 . . . M
q
q
m . . .
m

Using Theorem 4.3 the placebo eﬀect θ1 is estimated in the group where the variance is smallest
(see also Lemma 3.2 and Corollary 3.3). Moreover, it follows from the proof of Lemma 3.2 that
the D-optimal design given by Theorem 4.3 is not unique if there exist two groups, say j∗
1 and
j∗
2, with σ2
j . We now use these results to determine D-optimal designs for the
j∗
Emax, exponential and linear-in-log model explicitly.

= minM

j=1 σ2

= σ2
j∗

1

2

Corollary 4.4 Let σ2
and linear-in-log model (3.2) is of the form ξ(cid:63) = (ξ(cid:63)

1 = mini=1,...,M σ2

1, . . . , ξ(cid:63)

M , µ(cid:63)), where

i . The locally D-optimal design for the Emax, exponential

(cid:32)

(cid:33)

(cid:32)

(cid:33)

ξ(cid:63)
1 =

0 x(cid:63),(1) d(1)
max
1
1
3
3

1
3

,

ξ(cid:63)
i =

x(cid:63),(i) d(i)
max
1
2

1
2

, i = 2, . . . , M, µ(cid:63) =

1 2 . . . M
2
3
m
m

2
m . . .

(cid:32)

(cid:33)

.

and the point x(cid:63),(i) is given by

x(cid:63),(i) = x(cid:63),(i)

emax =

max

ϑ(i)
2 d(i)
d(i)
max + 2ϑ(i)
2

,

(i = 1, . . . , M )

(4.6)

10

for the Emax model, by

x(cid:63),(i) = x(cid:63),(i)

exp =

for the exponential model and by

(cid:0)d(i)

max − ϑ(i)

max/ϑ(i)
2

2

(cid:1) exp(cid:0)d(i)
exp(cid:0)d(i)
(cid:1)ϑ(i)
2 log(cid:0)d(i)

max/ϑ(i)
2

2

(cid:1) + ϑ(i)
(cid:1) − 1
2 + 1(cid:1) − ϑ(i)

max/ϑ(i)
d(i)
max

(cid:0)d(i)

max + ϑ(i)
2

, (i = 1, . . . , M )

(4.7)

x(cid:63),(i) = x(cid:63),(i)

log =

2 d(i)

max

, (i = 1, . . . , M )

(4.8)

for the linear-in-log model.

It is worthwhile to mention that the locally D-optimal design for model (2.8) with an Emax curve
consists of the designs which are locally D-optimal for the models given by an individual Emax
model with parameter (θ1, θ(1)
2 ) and by an Emax model with location parameter equal to zero
and parameter θ(i)
2 , i = 2, . . . , M . This eﬀect can also be observed for the exponential and the
linear-in-log model.

4.2 Models with the same location and scale parameters

In this section we consider model (2.7) and assume that the location and scale parameter coincide
across the diﬀerent models (cf. the second column in Table 1). It turns out that in this case the
D-optimal design problem is substantially harder, and for the sake of a transparent presentation,
we restrict ourselves to the case of M = 2 groups. Similar results can be obtained in the case
M > 2 with an additional amount of notation. We begin with some general properties of locally
D-optimal designs for the model (2.7) in the case of an Emax, linear-in-log and exponential curve.
For this purpose we deﬁne

r =

as the ratio of the two population variances.

Lemma 4.5

σ2
1
σ2
2

(A) The locally D-optimal design ξ(cid:63) = (ξ(cid:63)

1, ξ(cid:63)

2, µ) for the Emax model (3.5) and the linear-in-log

1)| + |supp(ξ(cid:63)

(3.6) have the following properties:
(A1) |supp(ξ(cid:63)
2)| ∈ {4, 5}.
(A2) If |supp(ξ(cid:63)
(A3) If |supp(ξ(cid:63)

1)| + |supp(ξ(cid:63)
1)| + |supp(ξ(cid:63)

2)| = 5, then d(i)
2)| = 4, then d(1)

max ∈ supp(ξ(cid:63)
max ∈ supp(ξ(cid:63)

i ), i = 1, 2.
1) or d(2)

max ∈ supp(ξ(cid:63)
2).

(B) The locally D-optimal design ξ(cid:63) = (ξ(cid:63)
|supp(ξ(cid:63)

1, ξ(cid:63)
1)| + |supp(ξ(cid:63)

2)| ∈ {4, 5, 6}.

2, µ) for the exponential model (3.7) satisﬁes

11

By the previous lemma the number of support points of the locally D-optimal designs is at most
5 for the Emax and linear-in-log model and at most 6 for the exponential model. On the other
hand, at least four support points are required to estimate all parameters in both models (note
that the scale and location are assumed to be the same throughout this section). In the following
discussion we determine such “minimally” supported D-optimal designs explicitly for the Emax,
exponential and linear-in-log model.

4.2.1 Minimally supported designs

Recall the deﬁnition of the set ΞM
m in (4.2). We call a design of the ξ = (ξ1, ξ2, µ) minimally
supported (for the Emax, linear-in-log and exponential model) if ξ ∈ Ξ2
4 (note that for these
models the information matrix is of size 4× 4 as the scale and location parameter coincide in both
models). It turns out the the minimally supported D-optimal designs for the three models under
consideration have a very similar structure. On the other hand the question, if these designs are
D-optimal in the class of all designs does not have a simple answer and will be discussed in the
following section.

2 = θ(i)
2
d(i)
max

Theorem 4.6 Let ¯θ(i)
x(cid:63),(i) = x(cid:63),(i)
(1) If r ≤ 1, the locally D-optimal design for model (3.5) in the class Ξ2

, i = 1, 2 and 0 < ¯θ(1)

emax by (4.6) (i = 1, 2).

2 < ¯θ(2)

4 is given by

2 < 1, deﬁne y(cid:63) = θ(2)

2 , z(cid:63) = θ(1)

2

and

,

ξa,(cid:63)
2 =

, µa,(cid:63) =

.

(4.9)

2

(2) If 1 < r ≤(cid:16) 1+¯θ(2)
(cid:17)6
(cid:16) 1+¯θ(2)

1+¯θ(1)

2

(3) If r >

1+¯θ(1)

2

2

0 x(cid:63),(1) d(1)
max
1
1
3
3

1
3

ξa,(cid:63)
1 =

(cid:17)6

(cid:33)

(cid:33)

(cid:32)

(cid:32)

y(cid:63)
1

(cid:32)

0 y(cid:63)
1
1
2
2

(cid:33)

(cid:33)

(cid:33)

(cid:32)

(cid:32)

(cid:32)

(cid:33)

z(cid:63)
1

, the locally D-optimal design for model (3.5) in the class Ξ2

4 is given by

ξb,(cid:63)
1 =

x(cid:63),(1) d(1)
max
1
2

1
2

,

ξb,(cid:63)
2 =

, µb,(cid:63) =

.

(4.10)

, the locally D-optimal design for model (3.5) in the class Ξ2

4 is given by

ξc,(cid:63)
1 =

,

ξc,(cid:63)
2 =

, µc,(cid:63) =

.

(4.11)

0 x(cid:63),(2) d(2)
max
1
1
3
3

1
3

(cid:32)

(cid:32)

(cid:32)

(cid:33)

(cid:33)

(cid:33)

1 2
1
3
4
4

1 2
1
1
2
2

1 2
3
1
4
4

We can also obtain the minimally supported D-optimal designs for the exponential model and the
linear-in-log with common location and scale parameter.

Theorem 4.7 Let ¯θ(i)

2 = θ(i)
2
d(i)
max

, i = 1, 2, 0 < ¯θ(1)

g(θ, x) =(cid:0)1 + (x − 1) exp( x

2 < ¯θ(2)

2 < 1, deﬁne
θ ) − x exp( x−1

θ )(cid:1)2

and y(cid:63) = d(2)

max, z(cid:63) = d(1)

max and the point x(cid:63),(i) = x(cid:63),(i)

exp by (4.7) for i = 1, 2.

12

(1) If r ≤ 1, the D-optimal design for model (3.7) in the class Ξ2
(2) If 1 < r ≤ g(θ(1)
g(θ(2)

, the D-optimal design for model (3.7) in the class Ξ2

2 ,x(cid:63),(1)
exp )
2 ,x(cid:63),(2)
exp )

4 is given by (4.9).

4 is given by (4.10).

(3) If r > g(θ(1)
g(θ(2)

2 ,x(cid:63),(1)
exp )
2 ,x(cid:63),(2)
exp )

, the D-optimal design for model (3.7) in the class Ξ2

4 is given by (4.11).

Theorem 4.8 Let ¯θ(i)

2 = θ(i)
2
d(i)
max

g(θ, x) = (1 + θ)2(cid:0) log( 1

θ + 1)(cid:1)2(cid:16)

θ + 1) log( x

i = 1, 2, 0 < ¯θ(1)

2 < ¯θ(2)

2 < 1, deﬁne

x

(x + θ) log( x

θ + 1)

−

1

(1 + θ) log( 1

θ + 1)

(cid:17)2

max, z(cid:63) = d(1)

max and the point x(cid:63),(i) = x(cid:63),(i)

and y(cid:63) = d(2)
(1) If r ≤ 1, the D-optimal design for model (3.6) in the class Ξ2
(2) If 1 < r ≤ g(θ(1)
g(θ(2)

2 ,x(cid:63),(1)
log )
2 ,x(cid:63),(2)
log )

log by (4.8) for i = 1, 2.

4 is given by (4.9).

, the D-optimal design for model (3.6) in the class Ξ2

4 is given by (4.10).

(3) If r >

g(θ(1)
g(θ(2)

2 ,x(cid:63),(1)
log )
2 ,x(cid:63),(2)
log )

, the D-optimal design for model (3.6) in the class Ξ2

4 is given by (4.11).

4.2.2 D-optimal designs in the class of all designs

The question if a minimally supported D-optimal design for one of the models considered in
Section 4.2.1 is in fact D-optimal in the class of all designs is an extremely diﬃcult one.
Its
answer depends sensitively on the particular parameters in the model under consideration and
diﬀers for the three dose response models under consideration. We exemplarily state a result
for the Emax model, which provides suﬃcient conditions for the D-optimality of a minimally
supported D-optimal design, and illustrates the general structure and diﬃculties in results of this
type. The proof is based on the equivalence Theorem 4.1 and given in the appendix. Similar
but substantially more complicated statements can also be obtained of the linear-in-log and the
exponential model (note that in contrast to the Emax model these models contain transcendental
functions).

Theorem 4.9 Let ¯θ(i)
(1) Let r ≤ 1. The design ξa,(cid:63) deﬁned in (4.9) is locally D-optimal for model (3.5) if the

, i = 1, 2 and assume 0 < ¯θ(1)

2 < ¯θ(2)

2 < 1.

2 = θ(i)
2
d(i)
max

2 ≥ r(cid:0)6¯θ(1)

¯θ(2)

2 + 1)2(cid:1) −(cid:0)1 − r(cid:1)

2 (¯θ(1)

2 + 1)(2¯θ(1)
(6 + 2r ¯θ(1)

2 (1 + 2¯θ(1)

2 ))

(4.12)

condition

is satisﬁed.

13

Figure 1: The marked regions describe the parameter spaces, where the minimally supported
D-optimal design is optimal in the Emax model (3.5) (see Theorem 4.9). The diﬀerent ﬁgures
correspond to diﬀerent values of r = σ2
2. The domain for the ﬁrst case of Theorem 4.9 is
represented in gray for the case r = 1/10, r = 1/2 and r = 1 (see the ﬁrst three panels from the
left). In the right panel we display the case r = 2 of Theorem 4.9 (here the gray region corresponds
to case (2), while the dark gray region corresponds to case (3)).

1/σ2

(2) Let r > 1. The design ξb,(cid:63) deﬁned in (4.10) is locally D-optimal for model (3.5) if and only

if the condition

2 ≥ (¯θ(1)
¯θ(2)

2 )2(1 + 2¯θ(1)

2 )2 + r(1 + ¯θ(1)

2 )2(1 + 4¯θ(1)

2 + 20(¯θ(1)

2 )2) − 1

6 + 2¯θ(1)

2 (1 + 2¯θ(1)
2 )

is satisﬁed.

(3) Let r > 1. The design ξc,(cid:63) deﬁned in (4.11) is locally D-optimal for model (3.5) if the

(4.13)

(4.14)

(cid:16)

condition

is satisﬁed.

1
r

2 ≥
¯θ(1)

2 + 1)2(cid:17) −(cid:16)

1 − 1

r

(cid:17)

6¯θ(2)

2 (¯θ(2)

2 + 1)(2¯θ(2)
(6 + 2 1
r

¯θ(2)
2 (1 + 2¯θ(2)

2 ))

Figure 1 illustrates the parameter domains for diﬀerent ratios r = σ2
. The case where the variance
1
σ2
2
is equal in both groups is presented in the third panel. Obviously, there are several parameter
2 ≥ θ(2)
constellations θ(1)
2 where the minimally supported D-optimal design ξa,(cid:63) is not optimal in
the class of all designs.

14

5 Application to a dose-ﬁnding study

In this section we illustrate the application of the results of the previous sections and discuss the
problem of designing experiments for a dose ﬁnding study with diﬀerent treatment groups. Our
example refers to a Phase II study on a drug that works by increasing the level of a biomarker
that induces a beneﬁcial clinical eﬀect in patients. The dosing groups under consideration are
monthly and weekly administration. The primary objective of the study is the characterization of
dose-response relationships at a given time-point, say T , after initiation of treatment for each of
these two dosing groups. This will support the selection of an appropriate dose level and group to
be used in phase III clinical trials. To maintain the conﬁdentiality of the trial the dose-range has
been rescaled and the considered range (in terms of total monthly dose) is [0, 400] for the weekly
group and [0, 1000] for the once-a-month group. The natural questions for the design of this study
are (i) which doses should be studied in each treatment group and (ii) how to split the total sample
size between the two treatment groups. Here the objectives of the study are addressed by deriving
the best estimates of the dose response curves, a task for which a D-optimal design is best suited.
To arrive at a suitable design for the Phase II study, we need to quantify the information. This
quantiﬁcation can generate a best guess for the dose-response curves, but, even better, it can
be used to obtain a candidate set of dose-group-response scenarios to reﬂect the uncertainty
about the true dose-group-response relationship. The available information was data from a very
small early trial, which was used to develop a nonlinear mixed eﬀects pharmacokinetics (PK) /
pharmacodynamics (PD) model linking drug concentrations to biomarker levels. Using this model,
data of the new trial were predicted for the time-point T of the dose-response analysis and dose-
group-response models were ﬁtted to the data. Under the assumption of a normal distribution for
the logarithm of the biomarker level, it turned out that the Emax function was able to adequately
describe the population average predicted by the PK/PD model. The Emax model utilized total
monthly dose as input and had diﬀerent ED50 parameters in the two groups (θ(1)
2 ), but
2
the same placebo ϑ11 and Emax parameter ϑ12, so that the model function in the weekly and
monthly group is given by

and θ(2)

f (d, θ1, θ(i)

2 ) = ϑ11 + ϑ12

d
θ(i)
2 + d

,

i = 1, 2,

Here group i = 1 contains patients receiving monthly administration and the group i = 2 the
weekly administration. The parameter estimates can be found in Table 2 as model 1, which can
be considered as population average ﬁt. We now use these estimates as a guess and determine
the locally D-optimal design for these values. The variability is expected to be the same in both
treatment groups. Recalling the design spaces for the monthly and weekly doses are X1 = [0, 1000]
and X2 = [0, 400], respectively, we obtain from Theorem 4.6 and Theorem 4.9 the (locally) D-

15

Figure 2: Candidate models for the dose-response curve in monthly and weekly group.
In the
ﬁrst row models 1-5 are depicted and in the second row models 6-10 (see Table 2). The solid line
represents the population average of the new trial data generated with the PK/PD model. The grey
area represents the biomarker level between the 25th and 75th quantiles of the patient responses
of the new trial data. Dotted curves correspond to the Emax models. Sigmoid Emax models are
depicted as dotted-dashed lines and the linear-in-log models as dashed lines.

optimal design ξ(cid:63) = (ξ(cid:63)

1, ξ(cid:63)

2, µ(cid:63)) as

(cid:33)

(cid:32)

(cid:32)

ξ(cid:63)
1 =

0 x(cid:63),(1)
1
3

emax d(1)
max
1
1
3
3

=

0 13.45 1000
1
3

1
3

1
3

(cid:33)

,

ξ(cid:63)
2 =

(cid:33)

(cid:32)

=

(cid:32)

θ(2)
2
1

(cid:33)

10.46

1

, µ(cid:63) =

(cid:32)

(cid:33)

.

1 2
1
3
4
4

2 /d(1)

2 /d(2)

max < θ(2)

It can be seen that based on the population average ﬁt, it is suﬃcient to investigate the low
dose-range in both groups and a high dose in one of the two groups. Here the maximum dose is
placed in the monthly group because θ(1)
max, so relative to the allowed maximum
dose a larger ED50 parameter exists for the weekly group and thus patients are allocated to the
monthly group.
In practice, it is not realistic to assume that the data and model from previous small trials com-
pletely represent the underlying truth (otherwise no further study would need to be conducted).
So it is important to derive ranges covering the uncertainty about the available information to
use for the design of the new study. In particular, because the population to be included in the
Phase II trial will cover a broader range of characteristics than in the small proof of concept
trial. For this purpose the PK/PD model was used to predict individual dose-response curves and

16

model type

Emax
Emax
Emax
Emax
Emax

Sigmoid Emax

Model type

Emax

Sigmoid Emax
Sigmoid Emax

Log

id
1
2
3
4
5
6
id
7
8
9
10

ϑ11
5.48
5.47
5.47
5.47
5.47
5.48
θ1
5.48
5.48
5.48
5.44

ϑ12
0.90
0.93
0.93
0.93
0.93
0.90
ϑ(1)
1
0.85
0.65
0.95
0.13

ϑ(2)
1
0.95
0.75
1.05
0.14

θ(1)
2
13.82
2.93
2.93
53.49
53.49
13.82
ϑ(1)
2
13.82
2.93
53.49
0.32

θ(2)
2
10.46
2.39
40.40
2.39
40.40
10.46
ϑ(2)
2
10.46
2.39
40.40
0.41

γ
1
1
1
1
1
3
γ
1
3
3

Table 2: Set of candidate models used in the robust criterion (5.1)

the Emax model was ﬁtted to the individual dose-response curves to derive a range of plausible
dose-response parameters. Quantiles of the derived parameter distributions were used to derive
four additional candidate model shapes. More details on how these candidate shapes were derived
can be found in Appendix 7. The parameters for these four additional candidate models can be
found in Table 2 under the numbers 2-5. These models are depicted in the ﬁrst row of Figure 2.
With this set of candidate models, the design maximizing the mean eﬃciency

gc(ξ, s) =

πiEﬀi(ξ)

(5.1)

s(cid:88)

i=1

can be calculated, where s is the number of candidate models (here 5 or 10), π1, . . . , πs are non-
negative model weights chosen to reﬂect prior probability associated the model function 1, . . . , s
(throughout this paper we will use πi = 1/s, i = 1, . . . , s). The eﬃciencies Eﬀi(ξ) of the exper-
imental design ξ with respect to the (locally) D-optimal design ξ(cid:63),i associated to the model i is
deﬁned as

(cid:19)1/mi

,

(cid:18) |Mi(ξ, θi))|

|Mi(ξ(cid:63),i, θi)|

Eﬀi(ξ) =

where Mi is the Fisher information matrix associated to the model i with parameter speciﬁcation
θi and mi is the number of parameters of this model. The criterion (5.1) is called Bayesian
or compound optimality criterion in the literature [see Dette (1990), Cook and Wong (1994) or
Tsai and Zen (2004); Zen and Tsai (2004) among many others]. In the following we will denote
the designs maximizing (5.1) by ξ(cid:63)
c,s) and call it compound optimal design.
We emphasize that the deﬁnition of the criterion (5.1) requires knowledge of the locally optimal
designs ξ(cid:63),i, which have been determined in Section 4.

c,s = (ξ(cid:63)

1,c,s, ξ(cid:63)

2,c,s, µ(cid:63)

17

The compound optimal design based on the ﬁrst 5 models in Table 2 can be calculated numerically
and is given by ξ(cid:63)

c,5 = (ξ(cid:63)

1,c,5, ξ(cid:63)

2,c,5, µ(cid:63)

c,5), where

(cid:33)

(cid:32)

(cid:33)

(cid:32)

(cid:33)

(cid:32)

1,c,5 ≈
ξ(cid:63)

0

3.02 43.67 1000
0.26 0.24 0.25 0.25

,

ξ(cid:63)
2,c,5 =

2.53 37.51
0.48 0.52

, µ(cid:63)

c,5 =

1

2

0.67 0.33

,

and its optimality can be proved by an analogue of Theorem 4.1 for the Bayesian optimality
criterion (5.1). Compared to the design using only the best guess model, now the low dose-range
is investigated in ﬁner granularity by using two instead of one dose (safeguarding against diﬀerent
possible values of the ED50). In addition still more patients are evaluated for the monthly group,
as the high dose is only used there.
Based on general plausibility considerations ﬁve further candidate shapes were included as example
of models diﬀerent from the Emax function (e.g. the sigmoid Emax and the linear-in-log function),
or of models where the maximum eﬃcacy diﬀered between the two groups. These models are shown
in the second row of Figure 2 and the corresponding parameters are given in the rows with ids
6-10 in Table 2. First a sigmoid Emax model

f (d, θ1, θ(i)

2 , γ) = ϑ11 + ϑ12

dγ

(θ(i)

2 )γ + dγ

,

i = 1, 2,

with Hill coeﬃcient γ = 3 (model 6) is also considered as a possible dose response function. Note
that this model provides a steeper dose-response curve compared to the Emax model, but with
the same ED50 values as model 1. Furthermore, an Emax and a sigmoid Emax model

f (d, θ1, θ(i)

2 , γ) = θ1 +

ϑ(i)
1 dγ
2 )γ + dγ

(ϑ(i)

,

i = 1, 2.

is added that allows for diﬀerent Emax parameters in the two treatment group (models 7, 8, 9). In
addition a linear-in-log model (id 10) is utilized. The locally D-optimal designs for these models
can be computed using the results of Section 4. For the sigmoid Emax models, a transformation
has to be used to reduce it to the case of an Emax model, such that the derived theory is applicable
(note that the parameter γ is assumed to be ﬁxed).
When using all s = 10 candidate models we obtain ξ(cid:63)

c,10 = (ξ(cid:63)

1,c,10, ξ(cid:63)

2,c,10, µ(cid:63)

c,10) where

(cid:33)

1,c,10 ≈
ξ(cid:63)

0

2.90 12.98 41.91 1000
0.27 0.13 0.22 0.13 0.24

,

ξ(cid:63)
2,c,10 =

3.01 13.16 49.46 400
0.33 0.21 0.31 0.15

,

(cid:32)

(cid:33)
(cid:32)

(cid:32)

(cid:33)

µ(cid:63)
c,10 =

1

2

0.58 0.42

.

This design investigates the lower dose range comparably to the previous design based on the ﬁrst
ﬁve candidate models, but the maximum dose is studied in both groups. The eﬃciencies of the

18

gc(·, s)
0.823
0.747

ξ(cid:63)
c,5
ξ(cid:63)
c,10

1

2

3

4

5

6

7

8

9

0.708
0.831

0.835
0.749

0.877
0.779

0.845
0.767

0.847
0.786

0.098
0.749

0.795
0.903

0.927
0.760

0.906
0.749

10

0.625
0.747

Table 3: Eﬃciency Eﬀi(ξ(cid:63)
D-optimal designs for the 10 models.

c,s) of the two compound optimal designs compared to each of the locally

c,5 and ξ(cid:63)

two designs ξ(cid:63)
c,10 in the diﬀerent models are displayed in Table 3. We observe that the
design ξ(cid:63)
c,5 has reasonable eﬃciencies in all models except in the sigmoid Emax (6). Note that
this design has been constructed on the basis of the models (1) - (5). On the other hand the
the design ξ(cid:63)
c,10 maximizes the criterion (5.1), where uncertainty with respect to all models (1)
- (10) is addressed. As a consequence this design has eﬃciencies varying between 75% - 90% in
all competing models under consideration. Moreover, it can be used for a goodness-of-ﬁt test of
the Emax model, as both components have more than 3 support points. For these reasons we
recommend this design for the Phase II study under consideration.

Acknowledgements The authors would like to thank Antoine Soubret for the PK/PD model
and Martina Stein, who typed parts of this manuscript with considerable technical expertise. We
are also grateful to Katrin Kettelhake for computational assistance and to Antoine Soubret, who
built the original PK/PD model that was used to derive the candidate models for the designs
calculated in Section 5. This work has been supported in part by the Collaborative Research
Center ”Statistical modeling of nonlinear dynamic processes” (SFB 823, Teilprojekt C2) of the
German Research Foundation (DFG) and by a grant from the National Institute Of General
Medical Sciences of the National Institutes of Health under Award Number R01GM107639. The
content is solely the responsibility of the authors and does not necessarily represent the oﬃcial
views of the National Institutes of Health.

References

Bornkamp, B., Bretz, F., Dmitrienko, A., Enas, G., Gaydos, B., Hsu, C.-H., K¨onig, F., Krams, M., Liu,
Q., Neuenschwander, B., Parke, T., Pinheiro, J. C., Roy, A., Sax, R., and Shen, F. (2007). Innovative
approaches for designing and analyzing adaptive dose-ranging trials. Journal of Biopharmaceutical
Statistics, 17:965–995.

Bretz, F., Dette, H., and Pinheiro, J. (2010). Practical considerations for optimal designs in clinical dose

ﬁnding studies. Statistics in Medicine, 29:731–742.

Bretz, F., Pinheiro, J. C., and Branson, M. (2005). Combining multiple comparisons and modeling

techniques in dose-response studies. Biometrics, 61(3):738–748.

19

Chaloner, K. and Verdinelli, I. (1995). Bayesian experimental design: A review. Statistical Science,

10(3):273–304.

Chernoﬀ, H. (1953). Locally optimal designs for estimating parameters. Annals of Mathematical

Statistics, 24:586–602.

Cook, R. D. and Wong, W. K. (1994). On the equivalence of constrained and compound optimal designs.

Journal of the American Statistical Association, 89:687–692.

Dette, H. (1990). A generalization of D- and D1-optimal designs in polynomial regression. Annals of

Statistics, 18:1784–1805.

Dette, H. (1997). Designing experiments with respect to “standardized” optimality criteria. Journal of

the Royal Statistical Society, Ser. B, 59:97–110.

Dette, H., Bretz, F., Pepelyshev, A., and Pinheiro, J. C. (2008). Optimal designs for dose ﬁnding studies.

Journal of the American Statisical Association, 103:1225–1237.

Dette, H., Kiss, C., Bevanda, M., and Bretz, F. (2010). Optimal designs for the EMAX, log-linear and

exponential models. Biometrika, 97(2):513–518.

Dette, H. and Melas, V. B. (2011). A note on the de la Garza phenomenon for locally optimal designs.

Annals of Statistics, 39(2):1266–1281.

Dragalin, V., Fedorov, V. V., and Wu, Y. (2008). Two-stage design for dose-ﬁnding that accounts for

both eﬃcacy and safety. Statistics in Medicine, 27:5156–5176.

Dragalin, V., Hsuan, F., and Padmanabhan, S. K. (2007). Adaptive designs for dose-ﬁnding studies based

on the sigmoid emax model. Journal of Biopharmaceutical Statistics, 17:1051–1070.

Fang, X. and Hedayat, A. S. (2008). Locally D-optimal designs based on a class of composed models

resulted from blending Emax and one-compartment models. Annals of Statistics, 36:428–444.

Gabrielsson, J. and Weiner, D. (2007). Pharmacokinetic and Pharmacodynamic Data Analysis: Concepts

and Applications. Swedish Pharmaceutical Press, Stockholm, 4th edition.

Gilbert, P. B. (2010). Some design issues in phase 2B vs phase 3 prevention trials for testing eﬃcacy of

products or concepts. Statistics in Medicine, 29(10):1061–1071.

Grieve, A. P. and Krams, M. (2005). ASTIN: a Bayesian adaptive dose-response trial in acute stroke.

Clinical Trials, 2:340–351.

Harville, D. A. (1997). Matrix Algebra from a Statistician’s Perspective. Springer.

Karlin, S. and Studden, W. J. (1966). Tchebysheﬀ Systems: With Application in Analysis and Statistics.

Wiley, New York.

20

Kiefer, J. (1974). General equivalence theory for optimum designs (approximate theory). Annals of

Statistics, 2:849–879.

Pronzato, L. and Walter, E. (1985). Robust experimental design via stochastic approximation.

Mathematical Biosciences, 75:103–120.

Pukelsheim, F. (2006). Optimal Design of Experiments. SIAM, Philadelphia.

Pukelsheim, F. and Rieder, S. (1992). Eﬃcient rounding of approximate designs. Biometrika, 79:763–770.

Sacks, L. V., Shamsuddin, H. H., Yasinskaya, Y. I., Bouri, K., Lanthier, M. L., and Sherman, R. E.
(2014). Scientiﬁc and regulatory reasons for delay and denial of FDA approval of initial applications
for new drugs, 2000-2012. Journal of the American Medical Association, 311(4):378–384.

Silvey, S. D. (1980). Optimal Design. Chapman and Hall.

Thomas, N. (2006). Hypothesis testing and Bayesian estimation using a sigmoid Emax model applied to

sparse dose designs. Journal of Biopharmaceutical Statistics, 16:657–677.

Thomas, N., Sweeney, K., and Somayaji, V. (2014). Meta-analysis of clinical dose-response in a large

drug development portfolio. Statistics in Biopharmaceutical Research, 6:302–317.

Tsai, M.-H. and Zen, M.-M. (2004). Criterion-robust optimal designs for model discrimination and

parameter estimation: Multivariate polynomial regression case. Statistica Sinica, 14:591–601.

Yang, M. (2010). On the de la Garza phenomenon. Annals of Statistics, 38(4):2499–2524.

Yang, M. and Stufken, J. (2012).

Identifying locally optimal designs for nonlinear models: A simple

extension with profound consequences. Annals of Statistics, 40:1665–1685.

Zen, M.-M. and Tsai, M.-H. (2004). Criterion-robust optimal designs for model discrimination and
parameter estimation in Fourier regression models. Journal of Statistical Planning and Inference,
124:475–487.

21

6 Appendix: technical details

6.1 Deviation of the information matrix
Assuming a normal distribution of the errors (εij(cid:96) ∼ N (0, σ2
the corresponding log-likelihood function (cid:96)(θ) with respect to θ1 and θ(i)

i ) independent) partial derivatives of

2 are given by

(cid:16)

1
σ2
i

M(cid:88)
ki(cid:88)

i=1

ki(cid:88)
nij(cid:88)

j=1

j=1

(cid:96)=1

nij(cid:88)
(cid:16)

(cid:96)=1

1
σ2
i

∂
∂θ1

∂

∂θ(i)
2

(cid:96)(θ) =

(cid:96)(θ) =

Yij(cid:96) − f (d(i)

j , θ1, θ(i)

f (d(i)

j , θ1, θ(i)
2 ),

Yij(cid:96) − f (d(i)

j , θ1, θ(i)
2 )

f (d(i)

j , θ1, θ(i)
2 ),

(cid:17) ∂

∂θ1

2 ))

(cid:17) ∂

∂θ(i)
2

(i = 1, . . . , M ). Note that

(cid:96)(θ)

(cid:96)(θ)

∂θ(i)
2

E(cid:104) ∂
E(cid:104) ∂
E(cid:104) ∂

∂θ1

∂θ(i)
2

(cid:16) ∂
(cid:16) ∂
(cid:16) ∂

∂θ(i)
2

(cid:96)(θ)

(cid:96)(θ)

(cid:96)(θ)

(cid:96)(θ)

∂θ1

∂θ1

(cid:17)T(cid:105)
(cid:17)T(cid:105)
(cid:17)T(cid:105)

=

=

=

(cid:40)

j=1

(cid:80)nij
(cid:80)ki
nij(cid:88)
ki(cid:88)
nij(cid:88)
ki(cid:88)
M(cid:88)

1
σ2
i

j=1

(cid:96)=1

i=1

j=1

(cid:96)=1

1
σ2
i

0
ηi(d(i)

j )ηT

i (d(i)

if i (cid:54)= i(cid:48)
j ) if i = i(cid:48)

(cid:96)=1

1
σ2
i

ηi(d(i)

j )ηi(d(i)
j )

ηi(d(i)

j )ηT

i (d(i)
j ),

and

i (d) = ∂
where ηT
∂θ1
Fisher information

f (d(i)

j , θ1, θ(i)

2 ), ηT

i (d) = ∂
∂θ(i)
2

f (d(i)

j , θ1, θ(i)

2 ). Consequently, we obtain for the

M(cid:88)

ki(cid:88)

M(cid:88)

ki(cid:88)

Mn :=

nijhi(d(i)

j )hT

i (d(i)

j ) = n

i=1

j=1

i=1

j=1

ni
n

nij
ni

hi(d(i)

j )hT

i (d(i)
j ),

where the vector hi is deﬁned in (2.6). Observing the assumption (2.3) it follows that 1
converges to the matrix M (ξ, θ) deﬁned in (2.4).

n Mn

6.2 Proof of main results

Proof of Lemma 3.1: We only discuss the ﬁrst part of the proof. The second assertion follows
by similar argument. Let ξ = (ξ1, . . . , ξM , µ) be an arbitrary design with |supp(ξi)| ≥ (k+2)
(i = 1, . . . , M ) and assume that there exists a design ξ+ = (ξ+
2 ) ≥ C(ξ, θ1, θ(i)
2 )

M , µ) such that

C(ξ+, θ1, θ(i)

1 , . . . , ξ+

2

22

for all i = 1, . . . , M . Recalling the deﬁnition of the matrix Pi in (3.1) it then follows by Theorem
14.2.9 of Harville (1997) that

M (i)(ξ+, θ) = PiC(ξ+, θ1, θ(i)

2 )P T

i ≥ PiC(ξ, θ1, θ(i)

2 )P T

i = M (i)(ξ, θ)

i = 1, . . . , M.

This implies

M(cid:88)

i , θ) ≥ M(cid:88)

λiM (i)(ξ+

M (ξ+, θ) =

λiM (i)(ξi, θ) = M (ξ, θ)

i=1

i=1

and the design ξ+ increases the information matrix M (·, θ) with respect to the Loewner ordering.
It now follows from Theorem 3.1 of Dette and Melas (2011) that there exists a design ξ+ with
components ξ+
support points (i = 1, . . . , M ). The statements (1a) and (1b) in
Lemma 3.1 also follows from Theorem 3.1 in Dette and Melas (2011).

i with at most k+2
2

(cid:0)1, f0(d, θ(i)

Proof of Lemma 3.2: We only prove the Lemma for the model given by (2.7). The proof for
model (2.8) is analogous. Note that in the model under consideration we have ∂
2 ) =
∂θ1

2 )(cid:1) for the gradient in (2.6). Consequently, if δ0 denotes the Dirac measure at the point

f (d, θ1, θ(i)

0, it follows for the matrices M (i) deﬁned in (2.5) that

σ2
i M (i)(δ0, θ) = σ2

1M (1)(δ0, θ) , i = 1, . . . , M.

(6.1)

Now, we consider the design η = (η1, . . . , ηM , ν) and represent its components as

ηi = ω(i)

0 δ0 + (1 − ω(i)

0 )η0
i

i = 1, . . . , M,

ν =

λiδi .

M(cid:88)

i=1

M(cid:88)

Here δt is the Dirac measure at the point t, λi, ω(i)
designs with 0 /∈ supp(η0
We now assume without loss of generality that j∗ = 1 and construct a “better” design ξ =
(ξ1, . . . , ξM , µ) as follows

0 ∈ [0, 1], i = 1, . . . , M and η0
i ). Moreover, at least for one i ∈ {1, . . . , M} we have λiω(i)

1, . . . , η0
0 > 0.

M denote

ξ1 = ω(cid:63)δ0 + (1 − ω(cid:63))η0

1, ξi = η0

i , (i = 2, . . . , M ), µ =

λ(cid:63)
i δi,

where

M(cid:88)

i=2

λ(cid:63)
1 = λ1 +

λiω(i)

0 ∈ [0, 1], λ(cid:63)

i = λi(1 − ω(i)

0 ) (i = 2, . . . , M ), ω(cid:63) =

i=1

(cid:80)M
λ1+(cid:80)M

i=1 λiω(i)

0

i=2 λiω(i)

0

.

Note that we shift the weights of the measures ηi at the point 0 to the design for the group with

23

the smallest population variance. Observing (6.1) gives for the diﬀerence

M (ξ, θ) − M (η, θ) = ω(cid:63)λ(cid:63)

1M (1)(δ0, θ) + (1 − ω(cid:63))λ(cid:63)
M(cid:88)

ω(0)
i λiM (i)(δ0, θ) +

−(cid:16) M(cid:88)
(cid:16)
1 − M(cid:88)

ω(cid:63)λ(cid:63)

i=1

=

(cid:17)

i=1

M (1)(δ0, θ) ≥(cid:16)

σ2
1
σ2
i

ω(0)
i λi

1M (1)(η0

1, θ) +

λ(cid:63)
i M (i)(η0

i , θ)

λi(1 − ω(0)

i )M (i)(η0

i , θ)

M(cid:88)

i=2

1 − M(cid:88)

i=1

(cid:17)
(cid:17)

ω(cid:63)λ(cid:63)

λiω(i)
0

M (1)(δ0, θ) = 0,

since σ2

1 ≤ σ2

i (i = 1, . . . , M ).

i=1

Proof of Corollary 3.3: Lemma 3.1 can be applied in the case of an Emax model or linear-in-log
model with k = 4 [see Yang (2010)]. Consequently, there exists a design ξ+ with 3M support points
and each component ξ+
max i = 1, . . . , M . Now we apply Lemma
3.2 with η = ξ+ and we allocate the placebo 0 in the group with the smallest variance. For the
exponential model Lemma 3.1 can be applied with k = 5 [see Yang (2010)]. Consequently, there
exists a design ξ+ with 3M support points and each component ξ+

i contains the placebo 0 and d(i)

max i = 1, . . . , M .

i contains d(i)

Proof of Theorem 4.3: For the sake of transparency we restrict ourselves to the case M = 2
such that m = M q +1 = 2q +1. We use the equivalence Theorem 4.1 to establish the D-optimality
of the design ξ(cid:63). In the present situation this means that the D-optimality of the design ξ(cid:63) deﬁned
in (4.5) for model (2.8) with assumption (4.3) can be proved by checking the two inequalities

(cid:1)M−1(ξ(cid:63), θ)(cid:0)1, ηT
2 )(cid:1)M−1(ξ(cid:63), θ)(cid:0)1, 0T

0 (t, θ(1)
q , ηT

2 ), 0T
q
0 (t, θ(2)

(cid:1)T ≤ 2q + 1, t ∈ [0, d(1)
2 )(cid:1)T ≤ 2q + 1, t ∈ [0, d(2)

max],

max],

0 (t, θ(1)
q , ηT

2 ), 0T
q
0 (t, θ(2)

(cid:0)1, ηT
(cid:0)1, 0T

κ1(t, ξ(cid:63), θ) = 1
σ2
1
κ2(t, ξ(cid:63), θ) = 1
σ2
2

(6.2)

(6.3)

f0(d, θ(i)
where η0(d, θ(i)
design ξ(cid:63) can be represented as

2 ) = ∂
∂θ(i)
2

2 ). A straightforward calculation shows that the information of the

X(σ1, θ(1)

2 , σ2, θ(2)

2 )X T (σ1, θ(1)

2 , σ2, θ(2)

2 ) ,

where the matrix X(σ1, θ(1)

X(σ1, θ(1)

2 , σ2, θ(2)

2 ) is given by

(cid:0)σ1, 0, d(1)

M (ξ(cid:63), θ) =

1
m
2 , σ2, θ(2)

(cid:32)
(cid:0)σ, 0, d(1)

2 ) =

X11

and the matrices X11
X12(σ) ∈ R(q+1)×q are deﬁned by
1
σ
1
σ

X11(σ, 0, d(1)

1 , . . . , d(2)

X22(σ, d(2)

1 , . . . d(1)

q , θ(2)

q , θ(1)

2 ) =

2 ) =

1 , . . . , d(1)

q , θ(1)
2

(cid:0)η0(d(2)
(cid:32)

1 , θ(2)

(cid:1)

0

X22

q , θ(1)
2

1 , . . . , d(1)

(cid:0)σ2, d(2)
(cid:1) ∈ R(q+1)×(q+1), X22(σ, d(2)
2 )(cid:1) ,
(cid:33)

2 ), . . . , η0(d(2)

q , θ(2)

(6.4)

(cid:1)(cid:33)

,

X12(σ2)
1 , . . . , d(2)

q , θ(2)
2

1 , . . . , d(2)

q , θ(2)

2 ) ∈ Rq×q and

(cid:32)

1
σ

1 . . . 1
0q . . . 0q

(cid:33)

.

1
0q X22(σ, d(1)

1T
q

1 , . . . , d(1)

q , θ(1)
2 )

, X12(σ) =

24

Consequently, the inverse of M (ξ(cid:63), θ) is obtained as

M−1(ξ(cid:63), θ) = m(X T (σ1, θ(1)

2 , σ2, θ(2)

2 ))−1X−1(σ1, θ(1)

2 , σ2, θ(2)
2 ),

where

X−1(σ1, θ(1)

2 , σ2, θ(2)

2 ) =

(cid:32)

X−1
11 (σ, 0, d(1)
0

1 , . . . d(1)

q , θ(1)

2 ) −X−1

11 (σ, 0, d(1)

1 , . . . d(1)

q , θ(1)
X−1
22 (σ, d(2)

2 )X12(σ2) X−1
1 , . . . , d(2)

22 (σ, d(2)
q , θ(2)
2 )

1 , . . . , d(2)

q , θ(2)

2 , θ(2)
2 )

(cid:33)

.

Using these block structures the function κ1(t, ξ(cid:63), θ) deﬁned in (6.2) reduces for the design ξ(cid:63) =
1, ξ(cid:63)
(ξ(cid:63)

2, µ(cid:63)) to

q )(cid:0)1, ηT

2 )(cid:1)T

11 (σ, 0, d(1)

1 , . . . d(1)

0 (t, θ(1)

κ1(t, ξ(cid:63), θ) = m
σ2
1

(cid:0)1, ηT
(cid:0)1, ηT

m

0 (t, θ(1)

11 (σ, 0, d(1)

2 )(cid:1)(cid:0)X−1
2 )(cid:1)M−1
(cid:0)1, ηT
(cid:82) 1

0 (t, θ(1)

q )(cid:1)T X−1
2 )(cid:1)T ,
2 )(cid:1)dξ(cid:63)

0 (t, θ(1)

1 , . . . d(1)

1, θ(1))(cid:0)1, ηT
2 )(cid:1)T(cid:0)1, ηT

1 (ξ(cid:63)

=

(q+1)σ2
1

0

0 (t, θ(1)

0 (t, θ(1)

2 ) only depends on the ﬁrst component ξ(cid:63)

2 ) = 1
σ2
1
1 in the single model with parameter (θ1, θ(1)

1, θ1, θ(1)
where M1(ξ(cid:63)
1(t) denotes the information ma-
trix of the design ξ(cid:63)
2 ). Consequently, the function
κ1(t, ξ(cid:63), θ1, θ(1)
1 and is proportional to the left-hand
side of the standard equivalence theorem for D-optimality for the single model. The inequal-
ity κ1(t, ξ(cid:63), θ) ≤ m for all t ∈ [0, d(1)
1 given in (4.4) is
locally D-optimal for the single model with parameter (θ1, θ(1)
In order to show the remaining inequality (6.3) for all t ∈ [0, d(2)
information matrix in (6.4) can be represented as

max] follows from the fact that the design ξ(cid:63)

max] we use the fact that the

2 ) and this proves (6.2).

M (ξ(cid:63), θ) = SX(σ2, θ(2)

2 , σ1, θ(1)

2 )diag( σ2

, 1
m , . . . , 1

m)X T (σ2, θ(2)

2 , σ1, θ(1)

2 )S,

2
mσ2
1

where S denotes a m × m permutation matrix, deﬁned by

0q×q denotes a matrix with all entries equal to zero and Iq×q the q × q identity matrix. Observ-
ing that Sh2(t) = 1
σ2
represented as

0 (t, θ(2)

2 ), 0T
q

S =

0T
q

 ,

0T
q
0q 0q×q Iq×q
0q Iq×q 0q×q

 1
(cid:1)T it follows that the function κ2(t, ξ(cid:63), θ) in (6.3) can be
(cid:0)σ2, 0, d(2)
(cid:105)
2 )(cid:1)T
(cid:0)σ2, 0, d(2)

(cid:1)(cid:1)T(cid:104)
(cid:0)σ2, 0, d(2)
2 )(cid:1)T
2 )(cid:0)1, ηT
(cid:1)(cid:0)1, ηT

(cid:1)(cid:0)1, ηT
2 )(cid:1)T(cid:105)2

X−1
2 ( ˜ξ2, θ1, θ(2)

1 , . . . , d(2)

1 , . . . , d(2)

1 , . . . , d(2)

mIq+1×q+1

0 (t, θ(2)

0 (t, θ(2)

0 (t, θ(2)

q , θ(2)

q , θ(2)

q , θ(2)

q )X−1

11

11

,

2

2

2

)diag(1, 0q)

(cid:0)1, ηT
(cid:0)1, ηT
(cid:0)1, ηT

m

11

2 )(cid:1)(cid:0)X−1
2 )(cid:1)M−1
(cid:104)

0 (t, θ(2)
− m(1 − σ2
1
σ2
2
0 (t, θ(2)

(1, 0T

−m(1 − σ2

1
σ2
2

) 1
σ2
2

=

(q+1)σ2
2

κ2(t, ξ(cid:63), θ) = 1
σ2
2

25

where M2( ˜ξ2, θ1, θ(2)
2 ) is the information matrix of the design ˜ξ2 given by (4.4) for the single model.
The ﬁrst term of this expression is proportional to the left hand side of the equivalence theorem
corresponding to the D-optimality in the single model with parameter (θ1, θ(2)
2 ). Moreover, it
follows that the design ˜ξ2 is D-optimal for the single model with parameter (θ1, θ(2)
2 ), which
implies that the ﬁrst term is always smaller than m. By the assumption σ2
2 we obtain that
the second term of this expression is nonpositive, which shows κ2(t, ξ(cid:63), θ) ≤ m for all t ∈ [0, d(2)
max].
This proves the inequality (6.3) and completes the proof of Theorem 4.3 in the case M = 2.

1 ≤ σ2

Proof of Corollary 4.4: The locally D-optimal designs for the (single) Emax, the linear-in-log
and the exponential model were calculated by Dette et al. (2010). The corollary now follows by
an application of Theorem 4.3.

Proof of Lemma 4.5: Let ξ(cid:63) = (ξ(cid:63)
2, µ(cid:63)) denote the locally D-optimal design for the Emax,
the linear-in-log or the exponential model. Since the information matrix M (ξ(cid:63), θ) of a locally
D-optimal design must be nonsingular one can easily deduce the following implications

1, ξ(cid:63)

|supp(ξ(cid:63)
If |supp(ξ(cid:63)
If |supp(ξ(cid:63)

1)| + |supp(ξ(cid:63)

2)| ≥ 4

1)| + |supp(ξ(cid:63)
i )| = 1 ,

2)| = 4 ,

then 0 /∈ supp(ξ(cid:63)

1) ∩ supp(ξ(cid:63)
2)

then 0 /∈ supp(ξ(cid:63)

i ), i = 1, 2.

(6.5)

(6.6)

1)|,|supp(ξ(cid:63)
2. If (|supp(ξ(cid:63)

Moreover, it follows by Corollary 3.3 that the locally D-optimal design has at most 5 support
points for the Emax and the linear-in-log model and at most 6 support points for the exponential
model. This proves Assertion (A1) and (B). Assertion (A2) also follows by Corollary 3.3.
2)|) ∈ {(1, 3), (2, 2), (3, 1)} if the locally D-
For a proof of (A3) we note that (|supp(ξ(cid:63)
1)|,|supp(ξ(cid:63)
optimal design is given by a design in Ξ4
2 must contain the
boundary points 0, d(2)
max, otherwise it could be improved with respect to the Loewner ordering (see
2)|) = (2, 2), both designs must contain at least one of the
Theorem 3.1). If (|supp(ξ(cid:63)
boundary points, otherwise I(ξ(cid:63)
i ) = 2 (i = 1, 2) and the designs could be improved with respect
to the Loewner ordering (see again Theorem 3.1). Using (6.6) it follows that at least one of the
designs contains the corresponding upper boundary point. If (|supp(ξ(cid:63)
2)|) = (3, 1), ξ(cid:63)
1
must contain the boundary points 0, d(1)
max, otherwise it could be improved with respect to the
Loewner ordering (see Theorem 3.1). Assertion (A3) now follows.

2)|) = (1, 3), ξ(cid:63)

1)|,|supp(ξ(cid:63)

1)|,|supp(ξ(cid:63)

Proof of Theorem 4.6: For the sake of brevity we restrict the discussion to the Emax model.
The proof consists of two steps. At ﬁrst we show that it is suﬃcient to prove the result on the
design space [0, 1]. Secondly, we determine the D-optimal design in the class Ξ4
2.
(1) Recall the deﬁnition of the information matrix in (2.4) (with M = 2) in model (3.5) with
2 )T ∈ R4. Let ξ = (ξ1, ξ2, µ) denote an arbitrary design
the parameter vector θ = (ϑ11, ϑ12, θ(1)
with components ξ1 and ξ2 deﬁned on the design space [0, d(1)
max], respectively, and

max] and [0, d(2)

2 , θ(2)

26

h2(t2)hT

2 (t2)dξ2(t2),

(cid:90) d(1)
(cid:90) 1

0

max

(cid:90) d(2)
(cid:90) 1
1 (t1)dξ1(t1) + (1 − λ)

0

max

M (ξ, θ) = λ

= λ

h1(t1)hT

˜h1(t1)˜hT

0

˜hT
1 (t1) =

˜hT
2 (t2) =

1
σ1
1
σ2

where

where

˜h2(t2)˜hT

2 (t2)d ˜ξ2(t2),

0

(cid:17)
(cid:17)

, 0

P,

P ,

−t1
2 /d(1)
(t1 + θ(1)
−t2
(t2 + θ(2)
2 /d(2)

max)2

max)2

1 (t1)d ˜ξ1(t1) + (1 − λ)
(cid:16)
(cid:16)

t1
t1 + θ(1)
2 /d(1)
t2
t2 + θ(2)
2 /d(2)

, 0,

max

1,

1,

,

max

P = diag(cid:0)1, 1, ϑ1

(cid:1)

denote by ˜ξ1 and ˜ξ2 the corresponding measures on the interval [0, 1] induced by the transformation
t → t/d(i)

max (i = 1, 2). Now a straightforward calculation gives

, ϑ2
d(1)
d(2)
max
max
is a 4×4 matrix. This shows that the components ξ(cid:63)
1 and ξ(cid:63)
2 of the locally D-optimal design for the
Emax model on the design spaces [0, d(1)
max] and [0, d(2)
max] can be obtained by a linear transformation
of the corresponding locally D-optimal designs on the design space [0, 1], where the parameters

in the Emax model are given by ˜θ =(cid:0)θ1, 1, θ(1)

(cid:1)T . Therefore it is suﬃcient to

max

2 /d(2)

max, 1, θ(2)
consider the case X1 = X2 = [0, 1] in the following discussion.
(2) According to (1) we restrict ourselves to the case d(1)
main assumption of the theorem reduces to 0 < θ(1)
the class Ξ2

2 < θ(2)

2 /d(1)

4 must have a nonsingular information matrix it follows that

max = d(2)

max = 1 and θ1 = 1. Therefore the
2 < 1. Because a D-optimal design in

|supp(ξi)| ≥ 1,

i = 1, 2 .

By an application of Lemma 4.2 we obtain the following candidates for the D-optimal design in
the class Ξ2
4

(cid:32)
(cid:32)
(cid:32)

ξa
1 =

ξb
1 =

ξc
1 =

(cid:33)

(cid:32)

d(2)
1
1

(cid:33)
(cid:33)
(cid:33)

d(1)
3
1
3

(cid:33)

,

d(1)
2
1
3
d(1)
2
1
2

(cid:33)

,

ξc
2 =

d(1)
1
1
3
d(1)
1
1
2
d(1)
1
1

,

ξa
2 =

(cid:32)

ξb
2 =

(cid:32)

d(2)
1
1
3

d(2)
1
1
2
d(2)
2
1
3

d(2)
2
1
2
d(2)
3
1
3

, µa =

, µb =

, µc =

(cid:32)
(cid:32)
(cid:32)

(cid:33)
(cid:33)
(cid:33)

1 2
3
1
4
4

1 2
1
1
2
2

1 2
3
1
4
4

,

,

.

(6.7)

(6.8)

(6.9)

Next we evaluate the determinants for these three candidate designs and maximize them with

27



respect to the support points. For example we obtain for the design D-optimal ξa = (ξa

1 , ξa

2 , µa)

2

4

σ2
1

σ2
2

1
d(1)
1
1 +θ(1)
d(1)
−d(1)
1 +θ(1)

(cid:1)3(cid:0) 1
(cid:1)3(cid:0) 1

det(M (ξa, θ)) = (cid:0) 1
(cid:1)4(cid:16) (d(1)
= (cid:0) 1
2 < 1 we obtain that the factor(cid:0)

(cid:1)4det2
(cid:1)4(cid:0)θ(1)

(cid:1)(cid:0) 1
(cid:1)(cid:0) 1

(d(1)

(d(1)

σ2
2

σ2
1

0

4

2

1

2 )2

1
d(1)
2
2 +θ(1)
d(1)
−d(1)
2 +θ(1)

2

2

2 )2

(d(1)

1
d(1)
3
3 +θ(1)
d(1)
−d(1)
3 +θ(1)

2

3

2 )2

(d(1)

0

0

1
d(2)
1
1 +θ(2)
d(2)

2

0

−d(2)
1 +θ(2)

1

2 )2

(d(2)

(cid:17)2(cid:16)

(cid:17)2

.

2 −d(1)
1 +θ(1)

1 )(d(1)
2 )2(d(1)

3 −d(1)
2 +θ(1)

d(2)
1

3 −d(1)
2 )
3 +θ(1)
2 )2

1 )(d(1)
2 )2(d(1)

(cid:1)2 is maximized for d(2)

(d(2)

1 +θ(2)

2 )2

Observing that θ(2)
follows by a straightforward calculation that the support points of the design ξa
maximizing the determinant are given by

1 +θ(2)

2 )2

(d(2)

d(2)
1

1 = θ(2)
1 and ξa

2 , and it
2 in (6.7)



d(1)
1 = 0,

2 = θ(1)
d(1)
1+2θ(1)

2

2

,

d(1)
3 = 1,

1 = θ(2)
d(2)
2 ,

respectively. The resulting determinant of the information matrix of the corresponding design,
say ξa,(cid:63), is obtained as

det(M (ξa,(cid:63), θ)) =

Analogously, we get that the support points

1 = θ(1)
d(1)
2 ,

d(2)
1 = 0,

(cid:0) 1
(cid:0)θ(1)

σ2
1

(cid:1)3(cid:0) 1
(cid:1)1(cid:0) 1
(cid:1)8
(cid:1)2(cid:0)1 + θ(1)

σ2
2

4

2

2 θ(2)

2

(cid:1)6 .

2 = θ(2)
d(2)
1+2θ(2)

2

2

,

d(2)
3 = 1,

(cid:0) 1
(cid:0)θ(1)

σ2
1
2 θ(2)

2

(cid:1)8
(cid:1)3(cid:0) 1
(cid:1)(cid:0) 1
(cid:1)2(cid:0)1 + θ(2)

σ2
2

4

2

(cid:1)6 .

yield a maximal determinant for the designs ξc
the information matrix of the corresponding design, say ξc,(cid:63) is given by

1, ξc

2 in (6.9), respectively, and the determinant of

det(M (ξc,(cid:63), θ)) =

Finally, we consider the determinant of the candidate design (6.8), that is

det(M (ξb, θ)) =(cid:0) 1

(cid:1)2(cid:0) 1

σ2
1

σ2
2

(cid:1)2(cid:0) 1

4

(cid:1)4 (d(1)
2 − d(1)
(d(1)

1 )2(d(2)

2 − d(2)

1 )2(d(2)

2 d(2)
2 )4(d(2)

1

1 + θ(1)

2 )4(d(1)

2 + θ(1)

1 + θ(2)

2 )4(d(2)

(cid:0)θ(1)

2

(cid:1)2 − d(1)

(cid:0)θ(2)

(cid:1)2)2

.

1

2 d(1)
2 + θ(2)

2
2 )4

We assume without loss of generality that d(i)
the design ξb the smallest support points d(1)
d(1)
1 + d(2)

i = 1, 2. Note that for D-optimality of
2 must satisfy
1 > 0 (otherwise the determinant vanishes). Consequently there exist two possible cases

2
1 of the components ξb

1 < d(i)
1 and d(2)

1 and ξb

28

for the design ξb,(cid:63) corresponding to the cases d(1)

1 = 0, namely

(cid:33)

(cid:32)
(cid:32)

ξb1
1 =

ξb2
1 =

0 d(1)
2
1
1
2
2
d(1)
d(1)
2
1
1
1
2
2

ξb1
2 =

,

(cid:33)

,

ξb2
2 =

(cid:32)

(cid:33)
(cid:33)

1 = 0 or d(2)
d(2)
1
1
2

(cid:32)

d(2)
2
1
2
0 d(2)
2
1
1
2
2

, µb1 =

, µb2 =

(cid:32)
(cid:32)

(cid:33)
(cid:33)

,

.

1 2
1
1
2
2

1 2
1
1
2
2

Now a straightforward calculation gives for the design ξb1
1

det(M (ξb1, θ)) = (cid:0) 1
= (cid:0) 1

σ2
1

σ2
2

(cid:1)2(cid:0) 1
(cid:1)2(cid:0) 1

4

(cid:1)2(cid:0) 1
(cid:1)2(cid:0) 1

(cid:1)4det2
(cid:1)4(cid:16) (d(2)

1

0

0

0

1
d(1)
2
2 +θ(1)
d(1)
−d(1)
2 +θ(1)

2

2

2 )2

(d(1)

0

2 −d(2)
1 +θ(2)
Maximizing with respect to the support points yields

(d(2)

σ2
2

σ2
1

4

1 )d(2)
2 )(d(2)

1 d(2)
2
2 +θ(2)
2 )

1
d(2)
1
1 +θ(2)
d(2)

2

0

1
d(2)
2
2 +θ(2)
d(2)

2

0

−d(2)
1 +θ(2)

1

2 )2

(d(2)

(cid:17)2(cid:16)

−d(2)
2 +θ(2)

2

2 )2

(d(2)

(cid:17)2

d(1)
2

(d(1)

2 +θ(1)

2 )2



d(1)
1 = 0,

2 = θ(1)
d(1)
2 ,

d(2)
2 = 1,

and we obtain for the determinant of the design ξb1,(cid:63)

det(M (ξb1,(cid:63), θ)) =



(6.10)

1 = θ(2)
d(2)
1+2θ(2)

2

,

σ2
1

2 θ(2)

2

(cid:0) 1
(cid:0)θ(1)
(cid:0) 1
(cid:0)θ(1)

σ2
1

2

4

σ2
2

(cid:1)6

(cid:1)8
(cid:1)2(cid:0) 1
(cid:1)2(cid:0) 1
(cid:1)2(cid:0)1 + θ(2)
(cid:1)2(cid:0) 1
(cid:1)2(cid:0) 1
(cid:1)8
(cid:1)6 .
(cid:1)2(cid:0)1 + θ(1)

σ2
2

4

2

2 θ(2)

2

2

A similar optimization of the determinant of the information matrix of the design ξb2,(cid:63) gives

det(M (ξb2,(cid:63), θ)) =

(6.11)

By a comparison of (6.10) and (6.11) it follows that the determinant of design ξb2,(cid:63) is always larger
than the determinant of the design ξb1,(cid:63), since θ(1)
2 . Finally, the assertion of the theorem
follows by straightforward calculations comparing the determinants of the designs ξa,(cid:63), ξb,(cid:63), ξc2,(cid:63) in
the diﬀerent scenarios for the ratio r = σ2
1
σ2
2

2 < θ(2)

.

max = d(2)

Proof of Theorem 4.9: By similar arguments as given in the proof of Theorem 4.6 we obtain
that it is suﬃcient to consider the case d(1)
(1) In the case r ≤ 1 it follows from Theorem 4.1 that the design ξa,(cid:63) deﬁned in (4.9) is locally
D-optimal for model (3.5) if and only if the two inequalities
M−1(ξa,(cid:63), θ)
M−1(ξa,(cid:63), θ)

(cid:17)T ≤ 4
(cid:17)T ≤ 4

κ1(t, ξa,(cid:63), θ) = 1
σ2
1

(cid:17)
(cid:17)

(cid:16)
(cid:16)

(cid:16)
(cid:16)

max = 1.

(6.12)

(6.13)

t+θ(1)

t+θ(1)

, 0,

, 0,

1,

1,

1,

1,

,

,

t

t

t

t

2

2

κ2(t, ξa,(cid:63), θ) = 1
σ2
2

t+θ(2)

2

, 0

−t
(t+θ(1)
2 )2
−t
(t+θ(2)
2 )2

, 0

−t
(t+θ(1)
2 )2
−t
(t+θ(2)
2 )2

t+θ(2)

2

29

hold for all t ∈ [0, 1] [see Theorem 4.1]. The information matrix of the design ξa,(cid:63) can be repre-
sented as

M (ξa,(cid:63), θ) = 1
4

where

˜X(σ1, θ(1)

2 , σ2, θ(2)

2 ) ˜X T (σ1, θ(1)

2 , σ2, θ(2)
2 ),

˜X(σ1, θ(1)

2 , σ2, θ(2)

2 ) =

θ(1)
2
2θ(1)
2 +1

, 1) ˜X12(σ2, θ(2)
2 )
˜X22(σ2, θ(2)
2 )

and the matrices X11, ˜X12 and ˜X22 are deﬁned by

X11(σ1, d(1)

1 , d(1)

2 , d(1)

3 ) =


 ,
(cid:17)

,

0

X11(σ1, 0,

(cid:32) 1

1
d(1)
1
1 +θ(1)
d(1)
−d(1)
1 +θ(1)

(cid:33)

(d(1)

1

2

2 )2

σ2
1
2σ2

1
d(1)
2
2 +θ(1)
d(1)
−d(1)
2 +θ(1)

2

2

2 )2

(d(1)

2

1
d(1)
3
3 +θ(1)
d(1)
−d(1)
3 +θ(1)

(cid:16) −1

3

(d(1)

2 )2

4θ(2)

2 σ2

˜X12(σ2, θ(2)

2 ) =

, ˜X12(σ2, θ(2)

2 ) =

 ,
(cid:17)T

respectively. A straightforward calculation of the inverse of the matrix ˜X yields

˜X−1(σ1, θ(1)

2 , σ2, θ(2)

2 ) =

θ(1)
2
2θ(1)
2 +1

, 1) −X−1

11 (σ1, 0,

θ(1)
2
2θ(1)
2 +1

2 ) ˜X−1

22 (σ2, θ(2)
2 )

, 1) ˜X12(σ2, θ(2)
˜X−1
22 (σ2, θ(2)
2 )

X−1

11 (σ1, 0,
0

and we obtain for the function κ1(t, ξa,(cid:63), θ) in (6.12) the representation

κ1(t, ξa,(cid:63), θ) = 4
3σ2
1

= 4
3σ2
1

1,

1,

t

t+θ(1)

2

t

t+θ(1)

2

,

,

−t
(t+θ(1)
2 )2
−t
(t+θ(1)
2 )2

3X−T
M−1

11 (σ1, 0,

, 1)X−1

11 (σ1, 0,

1 (ξa,(cid:63)

1 , θ(1))

1,

t

t+θ(1)

2

,

−t
(t+θ(1)
2 )2

θ(1)
2
2θ(1)
2 +1

(cid:16)

θ(1)
2
2θ(1)
2 +1

(cid:17)T

,

(cid:17)
(cid:17)

(cid:16)
(cid:16)

(cid:16)

, 1)

1,

t

t+θ(1)

2

,

−t
(t+θ(1)
2 )2

1 , θ(1)) is the information matrix of the design ξa,(cid:63)
2 )T . Because the design ξa,(cid:63)

where M1(ξa,(cid:63)
in the Emax model with parameter
vector (θ1, θ(1)
1 given in (4.9) is in fact locally D-optimal for this model,
it follows that κ1(t, ξa,(cid:63), θ) ≤ 4, which proves the ﬁrst inequality of the equivalence theorem.
In order to show that the inequality in (6.13) holds for all t ∈ [0, 1] we note that this inequality is
equivalent to

1

where the last identity deﬁnes the coeﬃcients α2j in an obvious manner. For example, the leading
coeﬃcient and the intercept are given by

2 )4(cid:0)κ2(t, ξa,(cid:63), θ) − 4(cid:1) = α21t4 + α22t3 + α23t2 + α24t + α25 ≤ 0,
2 + 1)2 − 4(cid:0)1 − r(cid:1),

2 + 1)(2θ(1)

(6.14)

α21 = 1
σ2
2
α25 = (θ(2)

(1, 1, 0, 0)M−1(ξa,(cid:63), θ)(1, 1, 0, 0)T − 4 = 24rθ(1)
2 )4( 1
σ2
2

(1, 0, 0, 0)M−1(ξa,(cid:63), θ)(1, 0, 0, 0)T − 4) = 4(θ(2)

2 (θ(1)

2 )4(cid:0)r − 1(cid:1),

P (t) = (t + θ(2)

30

respectively. Consider the case r < 1 (the case r ≤ 1 is ﬁnally obtained considering the corre-
sponding limit) and note that P (0) = α25 < 0. Consequently, (6.14) holds if either there are no
roots of P in the interval (0, 1) or all roots of P in the interval (0, 1) have multiplicity 2. The
roots of P (t) are easily calculated as

(cid:113)

s(θ(1)
2 )

(cid:113)

˜d2 = θ(2)

2

3+rθ(1)

2 (1+2θ(1)
2 )+
α21

1
4

s(θ(1)
2 )

,

d(2)
1 = θ(2)

2

˜d1 = θ(2)

2

where we use the notation

3+rθ(1)

2 )−
2 (1+2θ(1)
α21

1
4

2 ) = 8 − r2(1 + θ(1)

s(θ(1)

2 + 21(θ(1)

2 )3 + 12(θ(1)

2 )2(1 + 4θ(1)

2 )2 + 24(θ(1)

2 + 20(θ(1)
2 ) is positive (because θ(1)

2 )2) + 2r(1 + 6θ(1)
2 > 0 and r ≤ 1) and that θ(2)

2 )4) .
2 ∈ (0, 1) is a root of
2 ) > 0 (since M−1(ξa,(cid:63), θ) is positive deﬁnite), and it follows from
2 , 0). This is either ˜d1 or ˜d2 depending on the sign

Note that s(θ(1)
multiplicity 2. Moreover, P (−θ(2)
P (0) < 0 that P has a root in the interval (−θ(2)
of the leading coeﬃcient α21. The inequality (6.14) holds, if the other root is neither in (0, 1).
In order to check the location of the roots ˜d1 and ˜d2 we consider the condition (4.12) and the
case that the right hand side of (4.12) is positive. This implies that the leading coeﬃcient α21
is positive and the root ˜d2 is also positive. We obtain from the condition ˜d1 ∈ (−θ(2)
2 , 0) the
inequality

(cid:113)

3 + r θ(1)

2 (1 + 2θ(1)

2 ) <

s(θ(1)

2 ) .

This gives for the second root

˜d2 > θ(2)

2

2 (1 + 2θ(1)
6 + 2r θ(1)
2 )
1
4α21

.

Therefore it follows from (4.12) (with positive right hand side) that the inequality ˜d2 ≥ 1 is
satisﬁed.
On the other hand, if the right hand side of (4.12) is negative, the leading coeﬃcient α21 is negative
and the conditions P (0) < 0 and P (−θ(2)
2 ) > 0 imply that both roots ˜d1 and ˜d2 must be negative,
because otherwise the polynomial P does not satisfy (6.14). Observing that ˜d2 < ˜d1 in this case,
it is easy to see that the condition (4.12) (with negative right hand side) implies ˜d1 < 0.
Summarizing, in the case r ≤ 1 the inequality (4.12) implies (6.14) for all t ∈ [0, 1] and the
D-optimality of the designs ξa,(cid:63) follows by an application of Theorem 4.1.
(2) At ﬁrst, we show that the condition (4.13) and r > 1 imply that 1 < r ≤ (1+θ(2)
2 )6
(1+θ(1)
2 )6
inequality is equivalent to θ(2)

2 ) − 1 and we have to show that:

2 ≥ r1/6(1 + θ(1)

. The last

(θ(1)

2 )2(1 + 2θ(1)

2 )2 + r(1 + θ(1)

2 )2(1 + 4θ(1)

2 + 20(θ(1)

2 )2) − 1

6 + 2θ(1)

2 (1 + 2θ(1)
2 )

> r1/6(1 + θ(1)

2 ) − 1.

(6.15)

This inequality can be rewritten by

(20r + 4)(θ(1)

√
2 )4 + (44r− 6

r + 1)(θ(1)

√
2 )3 + (29r− 6 6

r + 5)(θ(1)

√
2 )2 + (6r− 8 6
r + 2)(θ(1)

√
2 ) + (r− 6 6

r + 5) > 0.

31

Note that the coeﬃcients of the polynomial are positive for all r > 1. It follows by the rule of
Decartes that this polynomial has no positive roots and consequently, (6.15) is satisﬁed for all
positive θ(1)
2 .
Thus, if r ≥ 1 and the inequality (4.13) holds, we investigate the D-optimality of the design ξb,(cid:63)
deﬁned by (4.10) checking the two inequalities

(cid:17)

(cid:16)

κ1(t, ξb,(cid:63), θ) = 1
σ2
1

κ2(t, ξb,(cid:63), θ) = 1
σ2
2

1,

t

t+θ(1)

2

,

−t
(t+θ(1)
2 )2

, 0

1, 0,

t

t+θ(2)

2

, 0,

−t
(t+θ(2)
2 )2

(cid:17)

M−1(ξb,(cid:63), θ)

1,
M−1(ξb,(cid:63), θ)

(cid:16)

t

t+θ(1)

2

,

−t
(t+θ(1)
2 )2

, 0

1,

t

t+θ(2)

2

, 0,

−t
(t+θ(2)
2 )2

(cid:17)T ≤ 4
(cid:17)T ≤ 4

(6.16)

(6.17)

(cid:16)
(cid:16)

on the interval [0, 1] [see Theorem 4.1].
Analogously to the proof of part (1) it can be shown that the ﬁrst inequality (6.16) is satisﬁed for
all t ∈ [0, 1]. In order to establish the inequality (6.17) for all t ∈ [0, 1] we consider the polynomial

2 )4(cid:0)κ2(t, ξb,(cid:63), θ) − 4(cid:1) = α21t4 + α22t3 + α23t2 + α24t + α25,
(cid:17) − 4,
(cid:16)
(cid:17)

2 )2 + r(1 + θ(1)

2 )2(1 + 4θ(1)

2 )2(1 + 2θ(1)

2 + 20(θ(1)

2 )2)

(θ(1)

P (t) = (t + θ(2)

α21 = α21(θ(1)

2 ) = 4

α25 = 4(θ(2)

− 1

= 0.

2 )4(cid:16) σ2

2
σ2
2

where the leading coeﬃcient and the intercept are now given by

Moreover, P (−θ(2)
always positive, since α21(0) = 4r − 4 > 0 and α21 is increasing for θ(1)
given by

2 ) > 0 (since M−1(ξb,(cid:63), θ) is positive deﬁnite) and the leading coeﬃcient α21 is
2 ≥ 0. The roots of P (t) are

d(2)
1 = 0,

2 = θ(2)
d(2)
2 ,

˜d1 = θ(2)

2

6+2θ(1)
2 (1+2θ(1)
2 )
1
4

α21

is a root of second order. Now the inequality P (t) ≤ 0 holds for all t ∈ [0, 1] if and only

where d(2)
2
if ˜d1 ≥ 1. It is easy to see that this condition is equivalent to

2 ≥ (θ(1)
θ(2)

2 )2(1 + 2θ(1)

2 )2 + r(1 + θ(1)

2 )2(1 + 4θ(1)

2 + 20(θ(1)

2 )2) − 1

6 + 2θ(1)

2 (1 + 2θ(1)
2 )

which coincides with (4.13).
(3) At ﬁrst, one can show that the condition (4.14) and r > 1 imply that r ≥ (1+θ(2)
2 )6
(1+θ(1)
2 )6
result follows by similar arguments as given in the proof of part (1), which are omitted for the
sake of brevity.

. Then the

7 Appendix: Derivation of candidate models based on a

preliminary PK/PD model

The PK/PD model was a nonlinear mixed eﬀects longitudinal model describing the PK of the
drug and linking this to the PD of the drug. The model was used to simulate longitudinal proﬁles

32

per patient. The simulation took into account parameter uncertainty from the model ﬁt. Then an
Emax dose-group-response model was ﬁtted to the cross-sectional data at time T , that assumed
that the placebo and maximum eﬀect of the curve are the same, but the ED50 are diﬀerent in the
two group. First this model was ﬁt to the whole population of simulations to give a population
best guess, giving

ϑ11 = 5.48, ϑ12 = 0.90, θ(1)

2 = 13.82, θ(2)

2 = 10.46.

In addition 200 individual patient proﬁles were simulated (see Figure 3) and each individual dose-
response curve was ﬁtted at time T to give 200 parameter estimates, representing the variability
on the dose-response curve in the population. These 200 parameter sets are used to compute the
distribution of each parameter (ϑ11, ϑ12, θ(1)
2 ) and their summary statistics are given in Table
7. The logarithm of biomarker Y was modeled to achieve a better approximation through the
normal distribution.

2 , θ(2)

Table 4: Summary statistics

Parameter

10% quantile median 90% quantile

ϑ11
ϑ12
θ(1)
2
θ(2)
2

5.47
0.93
20.39
14.99

5.09
0.66
2.93
2.39

5.84
1.20
53.49
40.40

Based on that, we propose 4 extreme models using the 10% and 90% quantile for the ED50’s
parameter.

33

Figure 3: 200 simulated dose-response curves at timepoint T for monthly (group 1, right panel)
and for the weekly (group 2, left panel) in grey. In red is the ﬁt of the population dose-response
curve.

34

