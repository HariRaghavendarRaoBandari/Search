6
1
0
2

 
r
a

M
7

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
7
1
2
2
0

.

3
0
6
1
:
v
i
X
r
a

LIMIT THEOREMS FOR THE LEFT RANDOM WALK ON GLd(R)

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

Abstract. Motivated by a recent work of Benoist and Quint and extending results
from the PhD thesis of the third author, we obtain limit theorems for products of in-
dependent and identically distributed elements of GLd(R), such as the Marcinkiewicz-
Zygmund strong law of large numbers, the CLT (with rates in Wasserstein’s distances)
and almost sure invariance principles with rates.

1. Introduction

Let (Yn)n≥1 be independent random matrices taking values in G := GLd(R), d ≥ 2
(the group of invertible d-dimensional real matrices), with common distribution µ. Let
k · k be the euclidean norm on Rd. We wish to study the asymptotic behaviour of
(log kYn ··· Y1k)n≥1, where for every g ∈ GLd(R), kgk := supx,kxk=1 kgxk.

We shall say that µ has a (polynomial) moment of order p ≥ 1, if

(1)

ZG
where N (g) := max(kgk,kg−1k).
order 1,

(log N (g))pµ(dg) < ∞ ,

It follows from Furstenberg and Kesten [13] that, as soon as µ admits a moment of

1
n

1
n

lim

n→+∞

log kYn ··· Y1k = λµ

P-a.s. ,

where λµ := limn→+∞ n−1E(log kYn ··· Y1k) is the so-called ﬁrst Lyapounov exponent.
If moreover, no proper subspace of Rd is invariant by the closed semi-group generated
by the support of µ, then (see for instance Proposition 7.2 page 72 in [6]), for every
x ∈ Rd − {0},
(2)

P-a.s. ,

lim

n→+∞

log kYn ··· Y1xk = λµ

Our goal is to study the rate in the above convergences, assuming higher moments
(and stronger algebraic conditions), as well as the Central Limit Theorem (CLT) or
the Law of the Iterated Logarithm (LIL), and the rates of convergence in those limit
theorems.

The CLT question beneﬁted from several papers under an exponential moment, i.e.

RG(N (g))αµ(dg) < ∞ for some α > 0, and some algebraic conditions, see the next

section for more details. Let us mention among others the papers by Le Page [21] and
Guivarc’h and Raugi [14].

Quite recently, Benoist and Quint [4] proved the CLT under the existence of a moment
of order 2. Their proof is based on Gordin’s martingale approximation method. By an

1

2

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

elegant but somewhat tricky argument, they provide an explicit martingale-coboundary
decomposition adapted to the problem. Moreover, as intermediary steps, they proved
a result about complete convergence as well as an integrability property with respect
to the invariant probability measure on X := Pd−1(R) (the projective space of Rd), see
the next section for further details and deﬁnitions. Let us mention here that most of
the results of [4] hold for linear groups on any local ﬁeld.

Rates in the CLT under polynomial moments have been announced in Jan [18] (with
proof in [17]) and the CLT has been proved in the PhD thesis of the third author [17]
under a moment of order 2 + ε, for any ε > 0. His method of proof is also based on
martingale approximation, but relies on estimates that seem more suitable to obtain
precise rates of convergence (in the CLT and the strong invariance principle) than the
approach of Benoist and Quint, at least in the case of GLd(R).

In Section 2 below, we give our main results for the sequence (log kYn ··· Y1xk)n≥0
and any starting point x ∈ Rd − {0}. We follow the approach described in Jan’s PhD
thesis [17] (reﬁning some of his computations), combined with recent or new results
about rates in the strong invariance principle and rates in the CLT (see Section 3). At
the very end of the paper (cf. Section 8), we also borrow one main argument from
Benoist and Quint [4], to prove that the rates of convergence in the CLT apply to the
sequence (log kYn ··· Y1k)n≥1, and to obtain some results for the sequence of matrix
coeﬃcients (log |hYn ··· Y1x, yi|)n≥1. In the same ﬁnal section, we also brieﬂy explain
how to weaken the assumption of proximality (see the next section for the deﬁnition)
by using another argument from [4].

2. Results

Let G := GLd(R), d ≥ 2, endowed with its Borel σ-algebra B(G). Let X := Pd−1(R)
be the projective space of Rd − {0}, and write x as the projection of x ∈ Rd − {0} to
X. Then G acts continuously on X in a natural way : g · x = gx.

Let µ be a probability measure on B(G). Denote by Γµ the closed semi-group gen-
erated by the support of µ. Assume that µ is strongly irreducible, i.e. that no proper
ﬁnite union of subspaces of Rd are invariant by Γµ and that it is proximal, i.e. that
there exists a matrix in Γµ admiting a unique (with multiplicity one) eigenvalue with
maximum modulus.

For such a measure µ, it is known that there exists a unique invariant measure ν on
B(X) (see for instance Theorem 3.1 of [6]) in the following sense: for any continuous
and bounded function h from X to R

ZX

h(x)ν(dx) =ZGZX

h(g · x)µ(dg)ν(dx) .

We consider the left random walk of law µ on X. Let us recall its construction.
Let Ω := X × GN∗ and F := B(X) ⊗ B(G)⊗N∗ , where N∗ = {1, 2, . . .}. For every
probability measure τ on B(X), we deﬁne Pτ := τ ⊗ µ⊗N∗
. As usual we note Px :=
Pδx, for every x ∈ X. Deﬁne the coordinate process (Yn)n∈N (N = {0, 1, . . .}), i.e.
Y0((x, g1, g2, . . .)) = x and for every n ∈ N∗, Yn((x, g1, g2, . . .)) = gn, and then Fn, the
σ-algebra generated by {Y0, . . . , Yn}.

LIMIT THEOREMS FOR GLd(R)

3

Finally, deﬁne a measurable transformation η on Ω by

η((x, g1, g2, . . .)) = (g1 · x, g2, g3, . . .) .

The left random walk of law µ is the process (Wn)n∈N, deﬁned by W0 := Y0 and for
every n ∈ N∗, Wn = W0 ◦ ηn. Hence, it is a Markov chain deﬁned by the recursive
equation Wn = YnWn−1 for n ∈ N∗.

Recall that for every probability measure Pτ , Y0 is a random variable with law τ
independent from the sequence (Yn)n∈N∗ of independent and identically distributed
(iid) random variables. Recall also that Pν is η-invariant hence, under Pν, (Wn)n∈N
is identically distributed with common marginal distribution ν. Moreover, since ν is the
unique µ-invariant probability, then (Ω,F, Pν , η) is ergodic (see e.g. Proposition 1.14
page 36 of [3]).
We want to study the process (Xn)n∈N∗ given by Xn := σ(Yn, Wn−1) for every n ∈ N∗,

where for every g ∈ G and every ¯x ∈ X,

kxk (cid:19) .
σ(g, ¯x) = log(cid:18)kg · xk

Let us denote A0 = Id and, for every n ∈ N∗, An := Yn ··· Y1, so that Xn =
0 k, where W ∗

σ(Yn, An−1W0). Let Sn := X1 + ··· + Xn, and note that Sn = log kAnW ∗
is an element of Rd such that W ∗
0 k = 1. Finally, let
(X[nt]+1 − λµ), t ∈ [0, 1](cid:27)

Bn =(cid:26) S[nt] − [nt]λµ

√n

0

0 = W0 and kW ∗
(nt − [nt])

√n

−

be the partial sum process with values in the space C([0, 1]) of continuous functions on
[0, 1] equipped with the uniform metric.

As usual in the Markov chain setting, we denote by Xn,x the random variable Xn
for which W0 = x. Let also Sn,x be the corresponding partial sum, and Bn,x be the
corresponding process. Note that Sn,x = log kAnxk if kxk = 1.
Note that the distribution of the sequence (Xn,x)n∈N∗ is the same for any probability
Pτ on Ω (in fact (Xn,x)n∈N∗ is a function of x and (Yn)n∈N∗ , so that its distribution
depends only on x and µ). Hence, we shall write “P-almost surely” (P-a.s.) instead
of “Pτ -almost surely”, and E(·) instead of Eτ (·), for all the quantities involving the se-
quence (Xn,x)n∈N∗ (and more generally for all the quantities involving only the sequence
(Yn)n∈N∗). With these notations, for any positive and measurable function f ,

E(f (Xn,x)) = Ex(f (Xn)) = E(f (Xn)|W0 = x) .

Our study will only require polynomial moments for µ. As already mentionned, when
µ has a moment of order 1, the strong law of large numbers (2) holds for any starting
point. Moreover, one can identify the limit λµ via the ergodic theorem for strictly
stationary sequences. It follows that, for every x ∈ X,

Sn,x
n −→n→+∞

λµ =ZGZX

σ(g, u)µ(dg)ν(du) P-a.s.,

see for instance Corollary 3.4 page 54 of [6] or Theorem 3.28 of [3]. Our goal is to
strengthen that strong law of large numbers when higher moments are assumed.

4

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

As already mentionned, in the next theorem, item (ii) has been obtained by Benoist
and Quint [4]. As observed in the introduction of [4], their method also allow to prove
item (ii) of the next theorem when p = 2.
Theorem 1. Let µ be a proximal and strongly irreducible probability measure on B(G).
Assume that µ has a moment of order p ≥ 1.

(i) If 1 ≤ p < 2 then, for every x ∈ X,

Sn,x − nλµ

n1/p

−→n→+∞

0 P-a.s..

(ii) If p = 2 then n−1Eν((Sn − nλµ)2) −→ σ2 as n → ∞, and, for any continuous

and bounded function ϕ from C([0, 1]) (equipped with the sup norm) to R,

lim
n→∞

sup

x∈X(cid:12)(cid:12)(cid:12)(cid:12)

E(ϕ(Bn,x)) −Z ϕ(σ̟)w(d̟)(cid:12)(cid:12)(cid:12)(cid:12)

= 0 ,

where w is the distribution of a standard Wiener process.

(iii) If 2 ≤ p < 4 then, for every (ﬁxed) ¯x ∈ X, one can redeﬁne (Sn,¯x)n≥1 without
changing its distribution on a (richer) probability space on which there exists iid
random variables (Wn)n≥1 with common distribution N (0, σ2), such that,

n

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xi=1
(Vi − E(Vi)) −

n

Xi=1

Zi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

= o(cid:16)n1/p(cid:17) a.s. .

Hence, for p ∈ (2, 4], our results are close to the iid situation. The logarithmic loss
seems to be diﬃcult to avoid with our approach based on martingale approximation.
It follows from Theorem 4.11 c) of [4] that σ 6= 0 when Γµ has unbounded
Remark.
image in P GL(V ).

The proof of Theorem 1 will result from general limit theorems under projective
conditions. When 1 < p < 2 those results are new and when p > 2, the obtained rates
slightly improve previous results (see for instance [10]).

We also obtain rates of convergence for Wasserstein’s distances in the central limit
theorem. Let us ﬁrst recall the deﬁnition of these minimal distances. Let L(ν1, ν2)

Sn,¯x − nλµ −

= o(rn) P-a.s. ,

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

Xi=1

Wi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where rn = √n log log n when p = 2 and rn = n1/p√log n when 2 < p < 4.

(iv) If p = 4 then, for every (ﬁxed) ¯x ∈ X, one can redeﬁne (Sn,¯x)n≥1 without
changing its distribution on a (richer) probability space on which there exists iid
random variables (Wn)n≥1 with common distribution N (0, σ2), such that,

Sn,¯x − nλµ −

= O(cid:16)n1/4plog n (log log n)1/4(cid:17) P-a.s. .

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

Xi=1

Wi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

Let us recall the famous result by Koml´os, Major and Tusn´ady [19].
Remark.
Let (Vn)n∈N be iid variables in Lp, p > 2. Then, extending the probability space
if necessary, it is possible to construct iid random variables (Zn)n≥1 with common
distribution N (0, Var(X1)) such that

LIMIT THEOREMS FOR GLd(R)

5

be the set of the probability laws on R2 with marginals ν1 and ν2. The Wasserstein
distances of order r between ν1 and ν2 are deﬁned as follows:

Wr(ν1, ν2) =


inf(cid:26)Z |x − y|rP (dx, dy) : P ∈ L(µ, ν)(cid:27)
inf((cid:18)Z |x − y|rP (dx, dy)(cid:19)1/r

: P ∈ L(µ, ν)) if r ≥ 1 .

if 0 < r < 1

It is well known that, for r ∈ (0, 1],

Wr(ν1, ν2) = sup{ν1(f ) − ν2(f ) : f ∈ Λr} ,

where Λr is the set of r-H¨older functions such that |f (x)− f (y)| ≤ |x− y|r for any reals
x, y. For r ≥ 1, one has

Wr(ν1, ν2) =(cid:18)Z 1

0 |F −1

1

(u) − F −1

2

(u)|rdu(cid:19)1/r

,

where F1 and F2 are the respective distribution functions of ν1 and ν2, and F −1
F −1

are their generalized inverse.

1

and

2

We obtain

Theorem 2. Let µ be a proximal and strongly irreducible probability measure on B(G).
For any x ∈ X, denote by νn,x the distribution of n−1/2(Sn,x − nλµ). Let also Gσ be the
normal distribution with mean zero and variance σ2 given in Theorem 1(ii) (provided µ
has a moment of ordrer 2).

(i) Assume that µ has a moment of order p ∈ (2, 3). Then, for any r ∈ [p − 2, p],

sup
x∈X

Wr (νn,x, Gσ) = O(cid:16)n−(p−2)/2 max(1,r)(cid:17) .

(ii) Assume that µ has a moment of order 3. Then, for any r in (1, 3],

and for r = 1,

(3)

sup
x∈X

sup
x∈X

Wr (νn,x, Gσ) = O(cid:16)n−1/2r(cid:17) ,
W1 (νn,x, Gσ) = O(cid:16)n−1/2 log n(cid:17) .

Remark. Except for p = 3, r = 1, the rates given in Theorem 2 are consistent with the
iid case, in the following sense: let (Vi)i≥1 be a sequence of iid random variables, where
the Vi’s are centered and have a moment of order p ∈ (2, 3). Let νn be the distribution
of n−1/2(V1 + ··· + Vn). Then the rates given in Theorem 2 hold for νn instead of νn,x
and σ2 = E(V 2
1 ). Moreover, these are the best known rates under the stated conditions
(see the introduction of the paper [11]). For p = 3, r = 1 the rate in the iid case is
O(n−1/2), so there is a loss of order log n in (3).
Remark. Starting from Remark 2.3 of [11], we derive from Theorem 2 the following
rates of convergence in the Berry-Esseen theorem: If µ has a moment of order p ∈ (2, 3),
then

sup
x∈X

sup

t∈R(cid:12)(cid:12)(cid:12)
P(cid:16)n−1/2(Sn,x − nλµ) ≤ t(cid:17) − φσ(t)(cid:12)(cid:12)(cid:12) ≤ O(cid:16)n−(p−2)/2(p−1)(cid:17) ,

6

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

where φσ is the distribution function of Gσ. If µ has a moment of order 3, then

P(cid:16)n−1/2(Sn,x − nλµ) ≤ t(cid:17) − φσ(t)(cid:12)(cid:12)(cid:12) ≤ O(cid:16)n−1/4plog n(cid:17) .

Note that, when µ has moments of any order, Jan [17] obtained the rate O(n−a) for
any a < 1/2 in the Berry-Esseen theorem.

sup
x∈X

sup

t∈R(cid:12)(cid:12)(cid:12)

3. Auxiliary results on the cocycle

In all this section µ is a proximal and strongly irreducible probability measure on
B(G). Let ˜Xk = Xk − λµ and ˜Xk,x = Xk,x − λµ. For p ≥ 1, let k · kp,τ be the Lp-norm
with respect to the probability Pτ on Ω. For the quantities involving Xk,x, we shall
write k · kp instead of k · kp,τ , in accordance with the notations of Section 2.

The proofs of Theorem 1 and Theorem 2 will make use of general results for sta-
tionary sequences under projective conditions, i.e. conditions relying on the quantities
kE( ˜Xn|W0)kp,ν for p ≥ 1 and kE( ˜Xn ˜Xk|W0) − Eν( ˜Xn ˜Xk)kp/2,ν for p ≥ 2.

Those quantities were already studied in [17], where polynomial rates of convergence
(to 0) were obtained. By reﬁning the arguments of [17] we obtain the following improve-
ments.

Proposition 3. Assume that µ has a moment of order p > 1. Then, for q ∈ [1, p),

∞

(4)

and for q ∈ (0, 1],

(5)

kp−q−1 sup
x,y∈X

E (|Xk,x − Xk,y|q) < ∞ .

Xk=1

∞

Xk=1

kp−2 sup
x,y∈X

E (|Xk,x − Xk,y|q) < ∞ .

Remark. Since E(Xk,x) = Ex(Xk) = E(Xk|W0 = x), and since Eν(Xk) = λµ, we easily
infer from (4) that

(6)

kp−2 sup

x∈X |Ex(Xk) − λµ| < ∞ .

Xk≥1

In particular, using that p + 1/p > 2 whenever p > 1, it follows from (6) that

(7)

k−1/p sup

x∈X |Ex(Xk) − λµ| < ∞ .

Xk≥1

Remark. Let us notice that the third author [17] proved that for every p ≥ 2 and
every α ∈ [0, 1), there exists Cp,α such that supx,y∈X
kp(α−1/2) . In
particular, when p = 2, using a Theorem of Maxwell and Woodroofe [22], that estimate
is suﬃcient for the CLT under a second moment and even for the invariance principle
(see Peligrad and Utev [24]). Hence, the full conclusion of item (ii) in Theorem 1 follows
from the latter estimate.

E(|Xk,x − Xk,y|) ≤ Cp,α

We shall also need the following controls.

Proposition 4. Assume that µ has a moment of order p > 2. Then

LIMIT THEOREMS FOR GLd(R)

7

Remark. As in the previous remark, we easily infer that

kp−3 sup
x,y∈X

(8)

Xk≥1
and for every γ < p − 3 + 1/p,
(9)

kγ sup
x,y∈X

sup

k≤j<i≤2k

Xk≥1

(10)

Xk≥1

and for every γ < p − 3 + 1/p,
(11)

kγ sup
x∈X

Xk≥1

kp−3 sup

x∈X(cid:12)(cid:12)(cid:12)
k≤j<i≤2k(cid:12)(cid:12)(cid:12)

sup

k,x − ˜X 2
˜X 2

k,y(cid:12)(cid:12)(cid:12)(cid:17) < ∞ ,

E(cid:16)(cid:12)(cid:12)(cid:12)
E(cid:16)(cid:12)(cid:12)(cid:12)
˜Xi,x ˜Xj,x − ˜Xi,y ˜Xj,x(cid:12)(cid:12)(cid:12)(cid:17) < ∞ .
k(cid:17)(cid:12)(cid:12)(cid:12)
k(cid:17) − Eν(cid:16) ˜X 2
Ex(cid:16) ˜X 2
Ex(cid:16) ˜Xi ˜Xj(cid:17) − Eν(cid:16) ˜Xi ˜Xj(cid:17)(cid:12)(cid:12)(cid:12)

< ∞ ,

< ∞ .

The proof of Propositions 3 and 4 are based on two auxiliary lemmas. The ﬁrst one
gives the regularity of the cocycle σ with respect to a suitable metric, that we introduce
right now.

For x, y ∈ X, deﬁne

d(x, y) := kx ∧ yk
kxkkyk

,

where ∧ stands for the exterior product, see e.g. [6, page 61] for the deﬁnition and some
properties. Then, d is a metric on X.

For every q > 0, deﬁne a non decreasing, concave function Hq on [0, 1] by Hq(0) = 0

and for every x ∈ (0, 1], Hq(x) =(cid:12)(cid:12) log(xe−q−1)(cid:12)(cid:12)

−q.

The next lemma may be seen as a version of Lemma 17 of Jan [17].

Lemma 5. For every κ > 1, there exists Cκ > 0 such that for every g ∈ G and every
x, y ∈ X,
(12)
Proof. By Lemma 12.2 of [3], there exists C > 0 such that for every x, y ∈ X,
(13)

|σ(g, x) − σ(g, y)| ≤ Cκ(1 + log N (g))κ Hκ−1(d(x, y)) .

|σ(g, x) − σ(g, y)| ≤ CN (g)d(x, y) .

Now, it is not hard to prove that (notice that kg−1k−1 ≤ kxk−1kgxk ≤ kgk for every

g ∈ G and every x ∈ Rd − {0}), for every x ∈ X and every g ∈ G,
(14)

σ(g, x) ≤ log(N (g)) .

Assume that d(x, y) ≤ 1/N (g). Using that t 7→ t(Hκ−1(t))−1 is non decreasing on

(0, e] and that N (g) ≥ 1, we have

N (g)d(x, y) ≤

Hκ−1(d(x, y))
Hκ−1(N (g)−1)

.

8

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

Hence, by (13),

(15)

|σ(g, x) − σ(g, y)| ≤ CHκ−1(N (g)−1) Hκ−1(d(x, y))

Assume now that d(x, y) > 1/N (g). By (14),

≤ C(κ + log N (g))κ−1Hκ−1(d(x, y)) .

(16)

|σ(g, x) − σ(g, y)| ≤

log N (g)Hκ−1(N (g)−1)

Hκ−1(N (g)−1)

≤ (κ + log(N (g))κHκ−1(d(x, y)) .

Combining (15) and (16), we see that (12) holds.

(cid:3)

The next lemma is a result about complete convergence that may be derived from

Proposition 4.1 of Benoist and Quint [4]. A diﬀerent proof is given in Section 7.

Lemma 6. Assume that µ has a moment of order p > 1. Then, there exists ℓ > 0, such
that

sup

kp−2 max
k≤j≤2k

(17) Xk≥1
Proof of Proposition 3. Let x, y ∈ X. Let ℓ > 0 be as in Lemma 6. We start from the
elementary inequality: If A = {log N (Yk) ≥ k} and B = {log d(Ak−1·x, Ak−1·y) ≥ −ℓk},
(18)

P (log (d(Aj−1 · x, Aj−1 · y)) ≥ −ℓk) < ∞ .

x,y∈X,x6=y

|Xk,x − Xk,y| ≤ |σ(Yk, Ak−1x) − σ(Yk, Ak−1y)|1A + |σ(Yk, Ak−1x) − σ(Yk, Ak−1y)|1B
+ |σ(Yk, Ak−1x) − σ(Yk, Ak−1y)|1{Ac∩Bc} .

Using (14) and (12) (with κ = (p + q)/q), we infer from (18) that
E (|Xk,x − Xk,y|q) ≤ C E (| log N (Yk)|q1A) + C E (|log N (Yk)|q 1B)

(1 + (log N (Yk))p+q

kp

+ C(cid:13)(cid:13)(cid:13)(cid:13)

,

1Ac(cid:13)(cid:13)(cid:13)(cid:13)1

for some positive constant C, and consequently

(19) E(|Xk,x − Xk,y|q) ≤ CZ{log N (g)≥k}

(log N (g))q µ(dg)

+ C P(log d(Ak−1 · x, Ak−1 · y) ≥ −ℓk)ZG

(log N (g))q µ(dg)

kp
Now, for q ∈ (0, p) there exist two positive constants K and L such that
(20) Xk≥1

(log N (g))q µ(dg) ≤ KZG

kp−q−1Z{log N (g)≥k}

(log N )p dµ < ∞ ,

+ CZ{log N (g)<k}

(log N (g))p+q

µ(dg) .

and

(21) Xk≥1

kp−q−1Z{log N (g)<k}

(log N (g))p+q

kp

µ(dg) ≤ LZG

(log N )p dµ < ∞ .

LIMIT THEOREMS FOR GLd(R)

9

In the case where q ∈ [1, p), since p − q − 1 ≤ p − 2, we infer from (19), (20), (21) and
(17) that (4) holds. In the case where q ≤ 1, since p − q − 1 ≥ p − 2, the condition (17)
implies (5). This completes the proof of Proposition 3.
Proof of Proposition 4. Let us ﬁrst prove (8). Using (14), we see that

(cid:3)

Proceeding as in (18) and (19), we obtain that

(cid:12)(cid:12)(cid:12)

k,x − ˜X 2
˜X 2

k,y(cid:12)(cid:12)(cid:12) ≤ 2(log N (Yk) + |λµ|)|σ(Yk, Ak−1 · x) − σ(Yk, Ak−1 · y)|
k,y(cid:12)(cid:12)(cid:12)(cid:17) ≤ CZ{log N (g)≥k}

˜X 2
k,x − ˜X 2
+ C P(log d(Ak−1 · x, Ak−1 · y) ≥ −ℓk)Z log N (g)(log N (g) + |λµ|) µ(dg)
(log N (g))p(log N (g) + |λµ|)

log N (g)(log N (g) + |λµ|) µ(dg)

E(cid:16)(cid:12)(cid:12)(cid:12)

+ CZ{log N (g)<k}

kp−1

µ(dg) ,

for some positive constant C. We conclude as in Proposition 3 (using similar arguments
as in (20) and (21)).

Let us prove (9). Let 2k ≥ i > j ≥ k. We start from the simple decomposition
˜Xi,x ˜Xj,x − ˜Xi,y ˜Xj,y = ˜Xi,x (σ(Yj, Aj−1 · x) − σ(Yj, Aj−1 · y))

+ (σ(Yi, Ai−1 · x) − σ(Yi, Ai−1 · y)) ˜Xj,y := Wi,j + Zi,j .
Using (14), (12) (with κ = p) and independence, and proceeding as in (18) and (19),
we obtain that

E(|Wi,j|) ≤ (|λµ| + k log Nk1,µ)Z{log N (g)≥j}

log N (g) µ(dg)

+ k log Nk1,µ (|λµ| + k log Nk1,µ) P (log d(Aj−1 · x, Aj−1 · y) ≥ −ℓj/2)
(log N (g))p+1

+ C (|λµ| + k log Nk1,µ)Z{log N (g)<j}

and

µ(dg) ,

µ(dg) ,

jp

kp

Eν(|Zi,j|) ≤ (|λµ| + k log Nk1,µ)Z{log N (g)≥k}

log N (g) µ(dg)

+ k log Nk1,µE(cid:0)(|λµ| + log(N (Yj)) 1{log d(Ai−1·x,Ai−1·y)≥−iℓ/2}(cid:1)

(log N (g))p+1

+ C (|λµ| + k log Nk1,µ)Z{log N (g)<k}

Xk≥1

kγ max

for some positive constant C. Let γ < p − 3 + 1/p. It suﬃces to prove that
E(cid:0)log(N (Yj)) 1{log d(Ai−1·x,Ai−1·y)≥−iℓ/2}(cid:1) < ∞ .
(P(log d(Ai−1 · x, Ai−1 · y) ≥ −iℓ/2))(p−1)/p < ∞ .

Using the H¨older inequality, it is enough to prove that

kγ max
k≤i≤2k

k≤j<i≤2k

Xk≥1

10

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

Using the H¨older inequality again it suﬃces to ﬁnd δ > 1 such that

kδ/(p−1)kγp/(p−1) max
k≤i≤2k

(P(log d(Ai−1 · x, Ai−1 · y) ≥ −iℓ/2)) .

Xk≥1

By Lemma 6, it suﬃces to ﬁnd δ > 1, such that δ/(p − 1) + γp/(p − 1) ≤ p − 2.
particular, it suﬃces that (p − 2)(p − 1) − γp > 1, which holds by assumption.

in
(cid:3)

4. General results under projective conditions

In this section, we state general results under projective conditions, that will be
needed to prove versions of Theorems 1 and 2 in stationary regime. Proposition 7 is new
and is somewhat optimal. Proposition 8 slightly improves previous results. Proposition
9 is taken from Dedecker, Merlev`ede and Rio [11]. Finally Proposition 10 is a new
moment inequality, in the spirit of von Bahr and Esseen [2], that will be useful to prove
that the results hold for any starting points.

The proofs of Propositions 7, 8 and 10 are given in Section 7.
We shall state Propositions 7 and 8 in presence of an invertible measure preserving
transformation, since Proposition 9 has been proved in that situation. This will be
enough for our purpose.

Let (Ω,F, P) be a probability space and θ be an invertible measure preserving trans-
formation. Let G0 ⊂ F be a σ-algebra, such that G0 ⊂ θ−1(G0). For every n ∈ Z deﬁne
Gn := θ−n(G0).

For every Z ∈ Lp(Ω,F, P), we consider the following maximal functions

(22)

Mp(Z, θ) := sup

,

if 1 ≤ p < 2.

n≥1(cid:12)(cid:12)(cid:12)Pn−1

k=0 Z ◦ θk(cid:12)(cid:12)(cid:12)

n1/p

Write also Tn := Z + ··· + Z ◦ θn−1, and, for any real-valued random variable V and

p ≥ 1, let kV kp,∞ = supt>0 t (P(|V | > t))1/p.
Proposition 7. Let 1 < p < 2. Let Z ∈ Lp(Ω,G0, P) be such that
(23)

kE(Tn|G0)kp

n1+1/p

< ∞ .

Xn≥1

There exists a constant Cp > 0, depending only on p such that

kMp(Z)kp,∞ ≤ Cp

kZkp +Xn≥1

n1+1/p 
kE(Tn|G0)kp
 .

P-a.s.

Tn = o(cid:16)n1/p(cid:17)
2d/p kZkp +

K
p − 1

2−k/pkE(T2k|G−2k )kp! .

d

Xk=0

and, there exists K > 0 such that for every positive integer d,

(24)

Moreover,

(25)

(26)

max

(cid:13)(cid:13)(cid:13)(cid:13)
1≤i≤2d |Ti|(cid:13)(cid:13)(cid:13)(cid:13)p ≤

LIMIT THEOREMS FOR GLd(R)

11

Remarks. An inequality similar to (26) is given in Theorem 3 of [28]. It is not hard
to prove that (23) holds as soon as

(27)

kE(Z ◦ θn|G0)kp

n1/p

< ∞ .

Xn≥1

Condition (23) may be seen as an Lp-analogue of the so-called Maxwell-Woodroofe
condition [22]. As in the papers [24], [25] or [8] (see Section D.3), it can be shown that
(23) is somewhat optimal for (25).
Proposition 8. Let 2 ≤ p ≤ 4 and assume that θ is ergodic if p = 2. Let Z ∈
Lp(Ω,G0, P) be such that
Xn≥1
(28)
Xn≥1

log(n)kE(Z ◦ θn|G0)kp < ∞ ,

kE(Z ◦ θn|G0)kp < ∞ ,

for p ∈ [2, 4),

for p = 4.

(29)

and

If p ∈ (2, 4], assume also that
Xn≥1

Then E(T 2

n )/n −→ σ2 as n → ∞, and

kE(T 2

n|G0) − E(T 2

n )kp/2

n1+2/p

< ∞ .

(30)

(31)

(i) If 2 ≤ p < 4, one can redeﬁne (Tn)n≥1 without changing its distribution on a
(richer) probability space on which there exists iid random variables (Wn)n≥1
with common distribution N (0, σ2), such that

= o(rn) P-a.s. ,

Tn −

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

Xi=1

Wi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

where rn = √n log log n when p = 2 and rn = n1/p√log n when 2 < p < 4.

(ii) If p = 4, one can redeﬁne (Tn)n≥1 without changing its distribution on a (richer)
probability space on which there exists iid random variables (Wn)n≥1 with com-
mon distribution N (0, σ2), such that

Tn −

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

n

Xi=1

Wi(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

= O(cid:16)n1/4plog n (log log n)1/4(cid:17) P-a.s. .

those reﬁnements.

decomposition. It is possible to weaken this condition as done for instance in [10]. Since

Remark. The condition Pn≥1 kE(Z ◦ θn|G0)kp < ∞ ensures a martingale-coboundary
in our application the condition Pn≥1 kE(Z ◦ θn|G0)kp < ∞ is satisﬁed, we do not state
Proposition 9. Let 2 < p ≤ 3. Let Z ∈ Lp(Ω,G0, P) be such that
for p ∈ (2, 3),

kE(Z ◦ θn|G0)kp < ∞ ,

Xn≥1

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

12

and

Assume also that

log(n)kE(Z ◦ θn|G0)k3 < ∞ ,

for p = 3.

Xn≥1

kE(T 2

n|G0) − E(T 2

n )kp/2

n3−p/2

< ∞ .

Xn≥1

Then n−1E(T 2
by Gσ the normal distribution with mean zero and variance σ2, one has:

n ) −→ σ2 as n → ∞, and, denoting by Ln the distribution of n−1/2Tn and

(i) If p ∈ (2, 3), then, for any r ∈ [p − 2, p],

Wr (Ln, Gσ) = O(cid:16)n−(p−2)/2 max(1,r)(cid:17) .

(ii) If p = 3, then, for any r ∈ (1, 3],

and for r = 1,

Wr (Ln, Gσ) = O(cid:16)n−1/2r(cid:17) ,
W1 (Ln, Gσ) = O(cid:16)n−1/2 log n(cid:17) .

To prove Theorem 2 we shall also need the following von Bahr-Esseen type inequality.
This inequality is stated in the non-starionary case: the Zi’s are real-valued random
variables adapted to an increasing ﬁltration (Fi)i≥0, and Tn = Z1 + ··· + Zn.
Proposition 10. Let r ∈ (1, 2]. The following inequality holds:

kTnkr
Moreover, letting T ∗

r ≤ 22−r  n
Xi=1

kZikr

r + r

n−1

Xi=1

E(cid:0)|Zi|r−1|E(Tn − Ti|Fi)|(cid:1)! .

n = max(0, T1, . . . , Tn),

kT ∗
nkr

r ≤

4
r − 1

n

Xi=1

kZikr

r +

6r
r − 1

n−1

Xi=1

E(cid:0)|Zi|r−1|E(Tn − Ti|Fi)|(cid:1) .
n|G0) − E(T 2

E(T 2

5. On the convergence of series Pn n−(1+β)(cid:13)(cid:13)

We keep the same notations as in previous section. For simplicity, if Z belongs to

L1(Ω,F, P), we shall write Zn := Z ◦ θn.
We want to ﬁnd conditions relying on series of the type considered in Proposition 3
such that the above series converges for a given p > 2 and a given β ∈ [1/2, 1). To do so
we shall use computations as well as notations from Dedecker, Doukhan and Merlev`ede
[10].

n )(cid:13)(cid:13)p/2

For every k, m ∈ N, deﬁne

γp(m, k) := kE(ZmZm+k|G0) − E(ZmZm+k)kp/2

˜γp(m) :=

sup

m≤j<i≤2mkE(ZiZj|G0) − E(ZiZj)kp/2 .

Notice that in our deﬁnition of ˜γp(m) we take the supremum supm≤j<i≤2m while in [10]
they use supi≥j≥m.

with the usual convention that an empty sum equals 0. We derive that the sum

n

E(T 2

n|G0) − E(T 2

(notice that [mγ] + 1 ≤ 2[mγ], for m ≥ 1)
(cid:13)(cid:13)
Pn n−(1+β)(cid:13)(cid:13)

n )(cid:13)(cid:13)p/2 ≤
n|G0) − E(T 2

(recall that γ − β > −1):

E(T 2

n

n

n

γp(m, k) ,

Xm=1

Xm=1

γp(k, 0) + 4

[mγ]˜γp(m) + 2

Xk=[mγ ]+1

Xk=1
n )(cid:13)(cid:13)p/2 is ﬁnite provided that the following conditions hold
Xm≥1
m−βγp(m, 0) < ∞ ,
Xn≥1
nγ−β ˜γp(n) < ∞ ,
Xn≥1

γp(m, k) < ∞ .

1

n

n

LIMIT THEOREMS FOR GLd(R)

13

Let γ ∈ (0, 1), be ﬁxed for the moment. Proceeding as in (4.18) in [10], we see that

(32)

(33)

(34)

Xk=[mγ]+1
For every m, k ∈ N, using the notation Z (0)

Xm=1

n1+β

m := Zm − E(Zm|G0), deﬁne

γ∗

p(m, k) :=(cid:13)(cid:13)(cid:13)

m Z (0)

E(cid:16)Z (0)

m+k(cid:12)(cid:12)(cid:12)G0(cid:17) − E(cid:16)Z (0)

m Z (0)

.

m+k(cid:17)(cid:13)(cid:13)(cid:13)p/2

Writing P1(·) := E(·|G1) − Eν(·|G0), and combining (4.20), (4.23) and (4.24) of [10], we
infer that,

n

n

Xm=1

Xk=[mγ]+1

γp(m, k) ≤

n

Xm=1

+

≤

n

Xm=1

n

m

n

n

Xk=[mγ ]+1
Xm=1
Xk=0
Xk=[mγ ]+1

kP1Zℓkp kP1Zℓ+kkp

Xℓ=1
kE(Zm|G0)kp kE(Zm+k|G0)kp
kP1Zℓkp kP1Zℓ+kkp +  2n
Xm=1

Xℓ=1

m

n

Hence (34) holds provided that the following conditions are satisﬁed

kE(Zm|G0)kp!2

.

(35)

(36)

Xn≥1
Xn≥1

1

kE(Zm|G0)kp!2
n1+β   2n
Xm=1
Xm=1
Xk=[mγ]+1

Xℓ=1

n1+β

m

1

n

n

< ∞ ,

kP1Zℓkp kP1Zℓ+kkp < ∞ .

14

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

n

n

m

Now, using that Pn
k=[mγ]+1 ≤Pk≥[mγ]+1 in the second equation, we see that
Xℓ=1
Xk=[mγ]+1
Xn≥1
≤ C Xm≥1

n−1−βkP1Zℓkp kP1Zℓ+kkp

m−βkP1Zℓkp kP1Zℓ+kkp

Xk=[mγ ]+1

Xm=1

m

m

Xℓ=1
+ C Xm≥1 Xk≥m+1

m

so that

n

n

m

[k1/γ]

n−1−βkP1Zℓkp kP1Zℓ+kkp

Xℓ=1
Xm=1
Xk=[mγ]+1
Xn≥1
≤ CXk≥1Xℓ≥1
m−βkP1Zℓkp kP1Zℓ+kkp + CXk≥1Xℓ≥1
Xm=1
≤ ˜C Xk,ℓ≥1
k(1−β)/γkP1Zℓkp kP1Zℓ+kkp ≤Xℓ≥1

Xm=1
kP1ZℓkpXk≥1

Hence, (36) holds as soon as

Xk≥1

k(1−β)/γkP1Zkkp ≤ CXℓ≥0

2ℓ((1−β)/γ

≤ CXℓ≥0

2ℓ+1−1

kP1Zℓkp

Xk=2ℓ
2ℓ((1−β)/γ+1−1/p


k−βkP1Zℓkp kP1Zℓ+kkp ,

Xℓ=1

k

k−βkP1Zℓkp kP1Zℓ+kkp

k(1−β)/γkP1Zkkp .

2ℓ+1−1

Xk=2ℓ

p
kP1Zℓkp


1/p

< ∞ ,

where we used H¨older for the last inequality. Applying Lemma 5.2 of [10] with q = p
we infer that (36) holds as soon as

(37)

Xn≥1

n(1−β)/γ−1/p
Xk≥n

kE(Zk|G0)kp

p

k

1/p

.




By stationarity, the sequence (kE(Zk|G0)kp)k≥1 is non increasing. Hence, using that
k · kℓp ≤ k · kℓ1, we see that (37) holds provided that

Xℓ≥0

2ℓ((1−β)/γ−1/p+1)
Xk≥ℓ

1/p

p
kE(Z2k|G0)kp

≤Xℓ≥0

2ℓ((1−β)/γ−1/p+1)Xk≥ℓ

kE(Z2k|G0)kp < ∞ .

LIMIT THEOREMS FOR GLd(R)

15

Changing the order of summation and using again that (kE(Zk|G0)kp)k≥1 is non increas-
ing, we infer that (37) holds provided that

k(1−β)/γ−1/pkE(Z2k|G0)kp < ∞ .

Xk≥1

(38)

(39)

Collecting all the above estimates and taking care of Proposition 3, we obtain the
following result:
Proposition 11. Let p > 2 and β ∈ [1/2, 1). Assume that (32) and (35) hold and that
there exists γ ∈ (0, 1) such that (33) and (38) hold. Then,

Xn>0(cid:13)(cid:13)

E(T 2

n|G0) − E(T 2

n1+β

n )(cid:13)(cid:13)p/2

< ∞ .

6. Proofs of Theorems 1 and 2

6.1. Proof of Theorem 1. We ﬁrst prove a version in stationary regime, i.e. under
Pν. The proof makes use of Proposition 7 and Proposition 8. Those results are stated
in the context of an invertible dynamical system. Let us explain how to circumvent
that technical matter. Theorem 1 is a limit theorem for the process (Xn)n≥1, which is a
functional of the Markov chain ((Yn, Wn−1))n≥1 with state space G × X and stationary
distribution µ ⊗ ν. Since that Markov chain is stationary, it is well-known that, by
Kolmogorov’s theorem, there exists a probability ˆP on the measurable space ( ˆΩ, ˆF) =
((G × X)Z, (B(G) ⊗ B(X))⊗Z), invariant by the shift ˆη on ˆΩ, and such that the law of
the coordinate process ( ˆVn)n∈Z (with values in G × X ) under ˆP is the same as the one
of the process ((Yn, Wn−1))n≥1 under Pν. In particular they both are Markov chains.
Moreover, ( ˆΩ, ˆF , ˆP, ˆη) is ergodic, which is not diﬃcult to prove.

For every n ∈ Z, deﬁne ˆXn := σ( ˆV0) ◦ ˆηn − ˆE(σ( ˆV0)) and ˆGn := σ{ ˆXk : k ≤ n}.
Then, using the Markov property one can prove easily that for every p ≥ 1, and every
m ≥ n ≥ 1,
(40)

kˆE( ˆXn| ˆG0)kp = kEν( ˜Xn| ˜X0)kp ≤ sup

E (|Xn,x − Xn,y|) ,

x,y∈X

Let us prove (i). Let us apply Proposition 7 with Z := ˆX1. Notice that by (40) and

(41)

(cid:13)(cid:13)(cid:13)

≤ sup

x,y∈X

=(cid:13)(cid:13)(cid:13)

Proposition 3 (see the remark after it), (27) holds. It follows that

ˆE( ˆXnXm| ˆG0) − ˆE( ˆXnXm)(cid:13)(cid:13)(cid:13)p

Eν( ˜Xn ˜Xm| ˜X0) − Eν( ˜Xn ˜Xm))(cid:13)(cid:13)(cid:13)p
E(cid:16)(cid:12)(cid:12)(cid:12)
˜Xn,x ˜Xm,x − ˜Xn,y ˜Xm,y(cid:12)(cid:12)(cid:12)(cid:17) .
ˆX1 + ··· + ˆXn = o(cid:16)n1/p(cid:17)
Sn − nλµ = o(cid:16)n1/p(cid:17)
or equivalently that for ν-almost every x ∈ X,
Sn,x − nλµ = o(cid:16)n1/p(cid:17) P-a.s.

Then, we infer that

Pν-a.s.

ˆP-a.s.

16

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

In particular, there exists y ∈ Rd with kyk = 1 such that

log kAnyk − nλµ = o(cid:16)n1/p(cid:17) P-a.s.

Let x ∈ Rd be such that kxk = 1. By Proposition 3.2 page 52 of [6], there exists a
random variable C satisfying C(ω) > 0 for P-almost every ω ∈ Ω, and such that, for
every n ∈ N,
(42)

C ≤ kAnxk

kAnk ≤ 1 .

Applying this inequality with x = y, we infer that

and then that for every x ∈ Rd such that kxk = 1,

log kAnk − nλµ = o(cid:16)n1/p(cid:17) P-a.s.
log kAnxk − nλµ = o(cid:16)n1/p(cid:17) P-a.s.

Let us prove items (iii) and (iv). Let us apply Proposition 8 with Z = ˆX1. Then
clearly, the conclusion of Proposition 8 will hold for Z = ˜X1 and, arguing as above,
items (iii) and (iv) of Theorem 1 will follow from Lemma 4.1 of Berkes, Liu and Wu
[5].

Notice ﬁrst that by (40) and (6), (28) (or (29)) holds. Hence, it remains to check

(39) with β = 2/p, which follows from Proposition 12 below.
Proposition 12. Let p > 2 and β ∈ [1/2, 1). Take Z := ˜X1. Then, (39) holds if
β > 3 − p. For instance, one may take β = 2 − p/2 when 2 < p ≤ 3 and β = 2/p when
2 < p ≤ 4.
Proof of Proposition 12. Let β > 3 − p (with β ≥ 1/2). Using (6) and (40), we see
that (35) is satisﬁed, since β > 0. Using, (6), (8) and (9) combined with (40) and (41),
we infer that (39) holds if

(43)

(44)

(45)

−β ≤ p − 3 ;

γ − β ≤ p − 3 + 1/p ;

(1 − β)/γ − 1/p ≤ p − 2 .

Now, (43) holds by assumption and then (44) holds with γ = 1/p. It is then not diﬃcult
to prove that (45) also holds with γ = 1/p.
(cid:3)

Let us prove item (ii). By Proposition 3, we have

Xn≥1(cid:18)ZX |Eu(Xn) − λµ|2 ν(du)(cid:19)1/2

< ∞ .

It is well-known then that Gordin’s method applies, i.e. that we have a martingale-
coboundary decomposition (with respect to Pν), and the martingale has stationary and
ergodic increments. Hence we have the weak invariance principle under Pν (see [15])
meaning that, for any continuous and bounded function ϕ from C([0, 1]) to R,

(46)

lim

n→∞(cid:12)(cid:12)(cid:12)(cid:12)

Eν(ϕ(Bn)) −Z ϕ(σ̟)w(d̟)(cid:12)(cid:12)(cid:12)(cid:12)

= 0 ,

LIMIT THEOREMS FOR GLd(R)

17

where w is the distribution of a standard Wiener process.

Assume now that (ii) does not hold. Then, there exists a continuous and bounded

function ϕ0 from C([0, 1]) to R, and a sequence xn of elements of X such that

(47)

(cid:12)(cid:12)(cid:12)(cid:12)
E(ϕ0(Bn,xn)) −Z ϕ0(σ̟)w(d̟)(cid:12)(cid:12)(cid:12)(cid:12)

the ﬁrst assertion of Lemma 13 below that

does not converge to 0 as n → ∞.

Now, if ψ is any bounded and Lipschitz function from C([0, 1]) to R, it follows frow

(48)

n→∞|E(ψ(Bn,xn)) − Eν(ψ(Bn))| = 0 .
lim

Putting together (46) and (48), we infer that Bn,xn converges in distribution to σW ,
where W is a standard Wiener process. This is in contradiction with (47), which
completes the proof of (ii).
(cid:3)

It remains to prove the following lemma (note that the ﬁrst assertion has already

been proved in [17] when p > 2).
Lemma 13. Assume that µ has a moment of order p ≥ 2. Then
x,y,kxk=kyk=1klog kAnxk − log kAnykk1 < ∞ ,

sup

for r ∈ (1, 2],

x,y,kxk=kyk=1klog kAnxk − log kAnykkr =(O(1)

sup

if r ≤ p − 1
if r > p − 1,

O(cid:0)n(r+1−p)/r(cid:1)

and for p ∈ [2, 3],

sup

x,y,kxk=kyk=1klog kAnxk − log kAnykkp = O(cid:16)n1/p(cid:17) .

Proof of Lemma 13. For any x, y ∈ Rd such that kxk = kyk = 1, one has

n

Hence

(49)

log kAnxk − log kAnyk =

Xk,x − Xk,y .

Xk=1

n

klog kAnxk − log kAnykk1 ≤

kXk,x − Xk,yk1 .

Xk=1

Using (49) and (4) (with q = 1 and p ≥ 2), the ﬁrst assertion of Lemma 13 follows.
For the case r ∈ (1, 2], we apply Proposition 10. Let sn(x, y) = Pn

k=1 Xk,x − Xk,y.

Then

n

(50)

klog kAnxk − log kAnykkr

r ≤ 2

r

n−1

kXk,x − Xk,ykr

Xk=1
Xk=1
k|Xk,x − Xk,y|r−1E(sn(x, y) − sk(x, y)|Fk)k1 .

+ 4

18

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

From equality (3.9) in [4] (which can also be deduced from (6)) we infer that

Xk,x − Xk,y = dk(x, y) + ψ(Ak−1x, Ak−1y) − ψ(Akx, Aky) ,

(51)
where dk(x, y) is Fk-measurable and such that E(dk(x, y)|Fk−1) = 0, and ψ is a bounded
function (with |ψ| < M ). In particular, it follows from (51) that

k|Xk,x − Xk,y|r−1E(sn(x, y) − sk(x, y)|Fk)k1 ≤ 2Mk|Xk,x − Xk,y|r−1k1 ,

so that, by (50),

n

(52)

r ≤ D

klog kAnxk − log kAnykkr

Xk=1(cid:0)kXk,x − Xk,ykr

r + k|Xk,x − Xk,y|r−1k1(cid:1) ,
for some positive constant D. Applying (4) (with p ≥ 2 and q = r) and (5) (with p ≥ 2
and q = r − 1), we infer that
Xk=1(cid:0)kXk,x − Xk,ykr

r + k|Xk,x − Xk,y|r−1k1(cid:1) = O(cid:16)max(cid:16)1, n(r+1−p)(cid:17)(cid:17) ,

n

and the second assertion of Lemma 13 follows from (52).

Let us prove the last assertion. Let

n

Zn,x,y = Xn,x − Xn,y

and Tn(x, y) =

Zk,x,y := gn(x, y, Y1, . . . , Yn) .

Xk=1

With these notations, let ˆTn(x, y) = gn(x, y, Y2, . . . , Yn+1). Now, it is easy to see that
Tn(x, y) = Z1,x,y + ˆTn−1(Y1x, Y1y). Letting ψp(t) = |t|p, we have

Hence

|Tn(x, y)|p =(cid:12)(cid:12)(cid:12)
|Tn(x, y)|p ≤ (cid:12)(cid:12)(cid:12)

ˆTn−1(Y1x, Y1y)(cid:12)(cid:12)(cid:12)
ˆTn−1(Y1x, Y1y)(cid:12)(cid:12)(cid:12)

p

0

p

ψ′

+ Z1,x,yZ 1
+ 2p−2|Z1,x,y|p + p2p−2|Z1,x,y|(cid:12)(cid:12)(cid:12)

p(cid:16) ˆTn−1(Y1x, Y1y) + tZ1,x,y(cid:17) dt .
ˆTn−1(Y1x, Y1y)(cid:12)(cid:12)(cid:12)

Let Gn,p(x, y) = E (|Tn(x, y)|p). Taking the conditional expectation with respect to Y1,
we get
E (|Tn(x, y)|p|Y1) ≤ Gn−1,p(Y1x, Y1y) + 2p−2|Z1,x,y|p + p2p−2|Z1,x,y|Gn−1,p−1(Y1x, Y1y) .
Let un = supx,y,x6=0,y6=0 Gn,p(x, y) and vn = supx,y,x6=0,y6=0 Gn,p−1(x, y). It follows that

p−1

.

E (|Tn(x, y)|p|Y1) ≤ un−1 + 2p−2|Z1,x,y|p + p2p−2|Z1,x,y|vn−1 .

Taking ﬁrst the expectation, and then the maximum, we get

un ≤ un−1 + 2p−2

sup

x,y,x6=0,y6=0

E (|Z1,x,y|p) + p2p−2

sup

x,y,x6=0,y6=0

E (|Z1,x,y|) vn−1 .

Since p − 1 ∈ [1, 2], we know from the second assertion of the lemma that vn = O(1) .
Consequently, there exists a positive constant C such that

un ≤ un−1 + C .

It follows that un = O(n), which is the desired result, since

LIMIT THEOREMS FOR GLd(R)

19

un =

sup

x,y,x6=0,y6=0(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

n

Xk=1

Xk,x − Xk,y(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

p

p

=

x,y,kxk=kyk=1klog kAnxk − log kAnykkp
p .

sup

(cid:3)

6.2. Proof of Theorem 2. Let νn be the distribution of n−1/2(Sn − nλµ) under Pν.
As in the proof of Theorem 1, it is enough to apply Proposition 9 with Y = ˆX1.
From Proposition 12 (with β = 2 − p/2) combined with (40) and (41), we see that the
assumptions of Proposition 9 are satisﬁed. It follows that:

(i) If µ has a moment of order p ∈ (2, 3), then, for any r ∈ [p − 2, p],

Wr (νn, Gσ) = O(cid:16)n−(p−2)/2 max(1,r)(cid:17) .
(ii) If µ has a moment of order 3, then, for any r ∈ (1, 3],

and for r = 1,

Wr (νn, Gσ) = O(cid:16)n−1/2r(cid:17) ,
W1 (νn, Gσ) = O(cid:16)n−1/2 log n(cid:17) .

Recall that W ∗

0 is an element of Rd such that W ∗

0 = W0 and kW ∗

0 k = 1. To prove the

results for any starting point, we use the following elementary inequalities:

For r ≤ 1,

sup
x∈X

For r > 1,

Wr (νn, νn,x) ≤ n−r/2

sup
x∈X

Wr (νn, νn,x) ≤ n−1/2

sup

x,kxk=1klog kAnxk − log kAnW ∗

0 kkr

1,ν .

sup

x,kxk=1klog kAnxk − log kAnW ∗

0 kkr,ν .

sup
x∈X

From the ﬁrst assertion of Lemma 13, we infer that: for r ≤ 1,

Wr (νn, νn,x) = O(cid:16)n−r/2(cid:17) .
This proves Theorem 2 for r ∈ [p − 2, 1], since in that case
Wr (νn, νn,x) = O(cid:16)n−(p−2)/2(cid:17) .
Wp (νn, νn,x) = O(cid:16)n−(p−2)/2p(cid:17) .

From the last assertion of Lemma 13, we infer that: for p ∈ (2, 3],

sup
x∈X

sup
x∈X

This proves the result for r = p.

It follows form the preceding upper bounds for W1 (νn, νn,x) and Wp (νn, νn,x) that

It remains to consider the case r ∈ (1, p). We use the elementary inequality
(Wr (νn, νn,x))r ≤ (W1 (νn, νn,x))(p−r)/(p−1) (Wp (νn, νn,x))p(r−1)/(p−1) .
(Wr (νn, νn,x))r = O(cid:16)n−(p−2)(p−r)/2(p−1)n−(p−2)(r−1)/2(p−1)(cid:17) = O(cid:16) n−(p−2)/2(cid:17) ,

sup
x∈X

which concludes the proof.

(cid:3)

20

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

7. Proofs of the intermediate results

7.1. Proof of Lemma 6. We ﬁrst recall the following notation: for any x ∈ Rd − {0}
and g in G, g · ¯x = g · x.
Since RG log N (g) µ(dg) < ∞, we may deﬁne a bounded function F1, by setting
F1(¯x, ¯y) =ZG

log(d(g · ¯x, g · ¯y)/(d(¯x, ¯y)))µ(dg)

∀¯x, ¯y ∈ X, ¯x 6= ¯y .

Then, we deﬁne a cocycle as follows. For every g ∈ G and every ¯x, ¯y ∈ X with ¯x 6= ¯y,
set σ1(g, (¯x, ¯y)) := log(d(g · ¯x, g · ¯y)/(d(¯x, ¯y))) − F1(¯x, ¯y).

Finally, write

with

and

log(d(An ¯x, An ¯y)/d(¯x, ¯y)) = Mn + Rn ,

Rn = Rn(¯x, ¯y) :=

n

Xk=1

n

F1(Ak−1 ¯x, Ak−1 ¯y) .

Mn :=

σ1(Yk, (Ak−1 ¯x, Ak−1 ¯y)) ,

Xk=1

and notice that (Mn)n≥1 is a martingale in Lp, since µ has a moment of order p.

Using that d(¯x, ¯y) ≤ 1, the proposition will be proved if we can prove that there exists

ℓ > 0, such that

(53)

and

(54)

Xk≥1
Xk≥1

kp−2 max
k≤j≤2k

sup

¯x,¯y∈X,¯x6=¯y

P (Rj(¯x, ¯y) ≥ −2ℓk) < ∞ ,

kp−2 max
k≤j≤2k

sup

¯x,¯y∈X,¯x6=¯y

P(|Mj(¯x, ¯y)| ≥ ℓk) < ∞ .

Proof of (53). Let K > 0 be such that |F1| ≤ K. Let n ≥ 1 be an integer. Then
|Rn| ≤ 2nK and using that |ex − 1 − x| ≤ x2e|x| for every x ∈ R, we see that, for every
a > 0,

By Proposition 6.4 (ii) in [6], there exists n0 ∈ N and δ > 0, such that

|E(eaRn ) − 1 − aE(Rn)| ≤ a2K 2eaK .

E (Rn0(¯x, ¯y)) ≤ −δ .
For this n0, we can ﬁnd a0 > 0 small enough such that

sup
¯x,¯y∈X

sup
¯x,¯y∈X

E(cid:16)ea0Rn0 (¯x,¯y))(cid:17) ≤ 1 − a0δ/2 := ρ < 1

Using that R(k+1)n0 = Rkn0 + Rn0 ◦ ηkn0 and conditioning with respect to Fkn0, we

infer that

sup
¯x,¯y∈X

E(cid:16)ea0R(k+1)n0 (¯x,¯y)(cid:17) ≤ sup

¯x,¯y∈X

E(cid:16)ea0Rkn0 (¯x,¯y)(cid:17) sup

¯x,¯y∈X

E(cid:16)ea0Rn0 (¯x,¯y)(cid:17) ≤ ρk+1 .

LIMIT THEOREMS FOR GLd(R)

21

Hence, there exists C > 0, such that for every n ∈ N,
E(cid:16)ea0Rn(¯x,¯y)(cid:17) ≤ Cρn/n0 .

sup
¯x,¯y∈X

Let k ≥ 1 and k ≤ j ≤ 2k and let α := | log ρ|/(2a0n0). Then

P(Rj(¯x, ¯y) ≥ −αk) ≤ ea0αkE(cid:16)ea0Rj(¯x,¯y)(cid:17) ≤ Cea0αkρk/n0 ≤ Cρk/(2n0) ,

and (53) holds with ℓ = α/2.
Proof of (54). The proof makes use of a result about complete convergence for mar-
tingales that we recall below. This result represents a very small sample of the general
situations treated by Alsmeyer [1], and later generalized by Hao and Liu [16].

(cid:3)

Recall that a sequence of random variables (Dn)n≥1 is said to be dominated by a
(non negative) random variable X, if there exists C > 0 such that for every x > 0,
P(|Dn| > x) ≤ C P(X > x).

The next theorem follows directly from Theorem 2.2 of [16].

Theorem 14 (Alsmeyer [1], Hao and Liu [16]). Let (Dn)n∈N be a sequence of (Fn)n∈N-
martingale diﬀerences dominated by a variable X. For every q > 1, every γ ∈ (1, 2] and
every L ∈ N, there exists C > 0, such that for every n ≥ 1 and every ε > 0,
(55) P(cid:18) max

1≤k≤n|D1 + ··· + Dk| ≥ εn(cid:19) ≤ nP(cid:18)X >

4(L + 1)(cid:19)

εn

+

C

(εn)qγ(L+1)/(q+L) kE(|D1|γ|F0) + ··· + E(|Dn|γ|Fn−1)kq(L+1)/(q+L)

q

.

We apply Theorem 14 with Dk := σ1(Yk, (Ak−1 ¯x, Ak−1 ¯y)), X := 2 log N (Y1), γ =
min(p, 2) and q = L (to be chosen later). Notice that (Dn)n∈N is dominated by X, see
for instance Lemma 5.3 page 62 of [6].

Since E(X p) < ∞, it is easy to check that for every δ > 0,

np−2P(X > δn) < ∞ .

Xn≥1

Moreover,

Hence, the series

kE(|D1|γ|F0) + ··· + E(|Dn|γ|Fn−1)kq ≤ 2nkXkp .

np−2P(cid:18) max

1≤k≤n|D1 + ··· + Dk| ≥ εn(cid:19)

Xn≥1

converges for every ε > 0, as soon as

np−2

n(γ−1)(q+1)/2

< ∞ ,

Xn≥1

which holds provided that q > 2(p − 1)/(γ − 1) − 1. In particular, we infer that (54)
holds by taking ε = ℓ.

(cid:3)

22

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

7.2. Proof of Proposition 7. We ﬁrst give a maximal inequality in the spirit of
Proposition 2 of [23]. The present form is just Proposition 4.1 of [8].
Proposition 15. Let X ∈ L1(Ω,G0, P). For every k ≥ 0, write uk := |E(T2k|G−2k )|
and dk := E(T2k|G−2k ) + (E(T2k|G−2k )) ◦ θ2k − E(T2k+1|G−2k+1). Then, for every integer
d ≥ 0, we have (with the convention P−1

k=0 = 0)

d−1

i−1

i−1

+

max

Xk=0

(56) max

1≤i≤2d |Ti| ≤ max

1≤i≤2d(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xℓ=0

(Z − E(Z|G−1)) ◦ θℓ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

1≤i≤2d−k−1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Xℓ=0
Xk=0
In particular, there exists C > 0, such that for every p ≥ 1,
)(cid:1)1/p
(57) Mp(X, θ) ≤ C(cid:16)Xk≥0

+Xk≥0(cid:0)M1(up

k, θ2k+1
2k/p

uk
2k/p

+ ud +

max

d−1

0≤ℓ≤2d−1−k−1

dk ◦ θ2k+1ℓ(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

uk ◦ θ2k+1ℓ .

+ Mp(X − E−1(X), θ) +Xk≥0

Mp(dk, θ2k+1

2k/p

(cid:17) .

By Hopf’s dominated ergodic theorem (see Corollary 2.2 page 6 of [20]), for every

f ∈ L1(Ω, P) and every k ∈ N,

kM1(f, θ2k

)k1,∞ ≤ kfk1 .

Then, (24) follows from Proposition 15 combined with Proposition 2.1 of [7].

Let us prove (25). Deﬁne M Wp := {Z ∈ Lp(Ω,G0, P)
: kZkM Wp < ∞}. Then,
For every Z ∈ L1(Ω,G0, P) deﬁne QZ = E0(Z ◦ θ). Notice that Qn(Z) = E0(Z ◦ θn).

(M Wp,k · kM Wp) is a Banach space.
Then, clearly Q is a contraction of Lp(Ω,G0). Now, we see that

kZkM Wp =Xn≥0

kP2n−1

k=0 QkZkp
2n/p

, if 1 < p < 2 .

Hence, in any case, Q is a contraction on M Wp.

Writing Vn := I + ··· + Qn−1 and using that kVnVkZkp ≤ C min(kkVnkp, nkVkZkp),

we see that, for every Z ∈ M Wp,
≤ Cp


kV2nZkM Wp

(58)

2n

kV2n Zkp

2n/p

+ Xk≥n+1

2k/p 
kV2k Zkp

0 .

 −→n→+∞

Now, for every n ≥ 1, taking m such that 2m ≤ n < 2m+1, we have kVnZkM Wp ≤
CPm
In particular, we see that Q is mean ergodic on M Wp and has no non trivial ﬁxed

k=0 kV2k ZkM Wp = o(n).

point (see e.g. Theorem 1.3 p. 73 of [20]), i.e.,

(59)

M Wp = (I − Q)M Wp

M Wp .

LIMIT THEOREMS FOR GLd(R)

23

Now, by (24) and the Banach principle (see Proposition C.1 of [7]) it is enough to
prove (25) for a set of elements of M Wp that is dense, in particular on (I − Q)M Wp. So
let Z = (I − Q)Y , with Y ∈ M Wp. Then, Z = Y ◦ θ − QY + Y − Y ◦ θ, is a martingale-
coboundary decomposition in Lp(Ω, P). Hence (25) holds since Y ◦ θn = o(n1/p) P-a.s.
(by the Borel Cantelli-Lemma) and by the Marcinkiewicz-Zygmund strong law of large
numbers for martingales with stationary diﬀerences in Lp.

It remains to prove (26). We shall apply once more (56). The Lp-norm of the ﬁrst
two terms may be estimated thanks to Proposition 10. To estimate the Lp-norm of the
last term in (56), we just notice that

max

0≤ℓ≤2d−1−k−1

and (26) follows.

uk ◦ θ2k+1ℓ ≤

 X0≤ℓ≤2d−1−k−1

1/p

,

up

k ◦ θ2k+1ℓ


(cid:3)

7.3. Proof of Proposition 8. Since Pn≥1 kE(Zn|G1)kp < ∞, we deﬁne a variable R
in Lp(Ω,F, P) by setting

Then, we have

R := Xn≥1

E(Zn|G1) .

Z1 = R ◦ θ − E(R ◦ θ|G1) + R − R ◦ θ := D + R − R ◦ θ .

Since R ∈ Lp(Ω,F, P) it is a standard consequence of the Borel-Cantelli lemma that
n−1/pR ◦ θn −→ 0 P-a.s. as n tends to inﬁnity. Hence, it suﬃces to prove (30) with
Mn := D + ··· + D ◦ θn−1 in place of Sn.
Since D ∈ Lp, it follows from Theorem 2.1 of Shao [27] (see the proofs of Corollaries
2.5, 2.7 and 2.8 in Cuny and Merlev`ede [9]) that we only have to prove that:

n

(60)

(E(D2|G1) − E(D2)) ◦ θi−1 = o(cid:16)n2/p(cid:17) P-a.s. ,
Xi=1
if 2 ≤ p < 4, and that
(61)

(E(D2|G1) − E(D2)) ◦ θi−1 = O(cid:16)(n log log n)1/2(cid:17) P-a.s. ,

n

Xi=1

if p = 4.

When p = 2, (60) follows from the ergodic theorem. Now, by Proposition 7 (the
ergodicity of θ is not required) and using orthogonality of martingale increments, (60)
holds provided that

< ∞ .
Similary, using Theorem 5.2 of [8], (61) holds provided that

n1+2/p

E(M 2

Xn≥1(cid:13)(cid:13)
Xn≥1(cid:13)(cid:13)

n|G0) − E(M 2

n)(cid:13)(cid:13)p/2
n|G0) − E(M 2
n)(cid:13)(cid:13)2

n3/2

E(M 2

< ∞ .

24

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

Since by assumption, for p ∈ (2, 4],
E(T 2

it suﬃces to prove that

Xn≥1(cid:13)(cid:13)
Xn≥1(cid:13)(cid:13)

n|G0) − E(T 2

n1+2/p

n )(cid:13)(cid:13)p/2

< ∞ ,

E(M 2

n|G0) − E(T 2

n1+2/p

n|G0)(cid:13)(cid:13)p/2

< ∞ .

In case p ∈ (2, 4), this can be done as to prove (5.38) in [11] (see the proof of Theorem
3.1 in [11]). In case p = 4, this can be done as to prove (5.43) in [11] (see the proof of
Theorem 3.2 in [11]).
(cid:3)

7.4. Proof of Proposition 10. We proceed as in the proof of Proposition 1 of [12].
For r ∈ (1, 2], let ψr be the function from R to R+ deﬁned by ψr(x) = |x|r. We start
from the following elementary decomposition (using the convention T0 = 0):

|Tn|r = ψr(Tn) =

=

Consequently,

n

n

Xi=1
Xi=1

n

Xi=1
r(Ti−1 + tYi) − ψ′

ψr(Ti) − ψr(Ti−1) =
YiZ 1
0 (cid:0)ψ′

Yiψ′

r(Ti−1) .

r(Ti−1 + tYi) dt

n

Xi=1

0

ψ′

YiZ 1
r(Ti−1)(cid:1) dt +
Yi
Xi=1
Xj=1

Xi=1(cid:0)ψ′
r(Ti) − ψ′

n−1

i−1

n

n−1

Xi=1

E(cid:0)|Yi|r−1|E(Tn − Ti|Fi)|(cid:1) ,

|Tn|r =

=

n

Xi=1
Xi=1

n

YiZ 1
0 (cid:0)ψ′
YiZ 1
0 (cid:0)ψ′

r(Ti−1 + tYi) − ψ′

r(Ti−1 + tYi) − ψ′
r(x) − ψ′

ψ′
r(Tj) − ψ′

r(Tj−1)
r(Ti−1)(cid:1) dt +

r(Ti−1)(cid:1) (Tn − Ti).
r(Ti−1)(cid:1) dt +
r(y)| ≤ r22−r|x − y|r−1. Using this simple fact

Now, it is easy to check that |ψ′
and taking the conditional expectation, we obtain
E(|Yi|r)Z 1

E (|Tn|r) ≤ 22−r

rtr−1dt + r22−r

n

0

Xi=1

and the inequality is proved.

Let us prove the second inequality. We ﬁrst write that

n

(T ∗

n )r =

(T ∗

i )r − (T ∗

i−1)r .

Xi=1

Note that for a ≥ b ≥ 0, (r − 1)(ar − br) ≤ ra(ar−1 − br−1). Hence,
(62)
Ti(cid:0)(T ∗

i−1)r−1(cid:1) =

i )r−1 − (T ∗

i (cid:0)(T ∗

r
r − 1

r
r − 1

n )r ≤

Xi=1

Xi=1

(T ∗

T ∗

n

n

i )r−1 − (T ∗

i−1)r−1(cid:1) ,

LIMIT THEOREMS FOR GLd(R)

25

the last equality being true because (T ∗

i )r−1 − (T ∗

i−1)r−1 is non zero iﬀ T ∗

i = Ti. Now

Ti(cid:0)(T ∗

i )r−1 − (T ∗

i−1)r−1(cid:1) =

n

Xi=1

n

Xi=1

(63)

Ti(T ∗

i )r−1 − Ti−1(T ∗

i−1)r−1 −

= Tn(T ∗

n )r−1 −

Zi(T ∗

i−1)r−1 .

n

Xi=1

Zi(T ∗

i−1)r−1

n

Xi=1

Recall Young’s inequality (based on the concavity of the logarithm): for any a, b ≥ 0
and any p, q > 1 such that 1/p + 1/q = 1,

ap
p

+

bq
q

.

ab ≤

xyr−1 ≤

2r−1

r

xr +

r − 1
2r

yr .

Hence, for x, y ≥ 0

We infer that

r

(64)

n )r−1 ≤
Combining (62), (63) and (64), we get that

r − 1|Tn|(T ∗

2r−1

r − 1|Tn|r +

1
2

(T ∗

n )r .

2r
r − 1
Proceeding as for the ﬁrst inequality, we get that

r − 1|Tn|r −

n )r ≤

(T ∗

2r

n

Xi=1

Zi(T ∗

i−1)r−1 .

(T ∗

n )r ≤

2r

r − 1|Tn|r −

2r
r − 1

n−1

Xi=1(cid:0)(T ∗

i )r−1 − (T ∗

i−1)r−1)(cid:1) (Tn − Ti) .

Since, for x, y ≥ 0, |xr−1 − yr−1| ≤ |x − y|r−1, we ﬁnally get that

E ((T ∗

n )r) ≤

2r
r − 1

E (|Tn|r) +

2r
r − 1

n−1

Xi=1

E(cid:0)|Yi|r−1|E(Tn − Ti|Fi)|(cid:1) .

Combining this inequality with the ﬁrst inequality of the proposition, the result follows.
(cid:3)

8. Extension of the results

In this section, we shall ﬁrst explain why the results of Section 2 still hold for the
sequence (log kAnk)n≥1 (with obvious changes in the statements). Next, we shall brieﬂy
explain how to deal with (log |hAnx, yi|)n≥1.

26

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

8.1. Matrix norm. The fact that the statements of Theorem 1 hold for log kAnk in-
stead of Sn,¯x is clear from the proof Theorem 1 (cf. Subsection 6.1). The crucial point
here is Inequality (42).

hold for µn instead of νn,¯x requires some explanations.

Let µn be the distribution of log kAnk. The fact that the statements of Theorem 2
Let ˜µn be the distribution of

log Sn,u ν(du) .

ZX

The ﬁrst point to notice is that the statements of Theorem 2 are valid for ˜µn instead
νn,¯x. This can be proved exactly as for the proof of Theorem 2, by using some easy
consequences of Lemma 13, such as

log kAnxk −ZX

sup

x,kxk=1(cid:13)(cid:13)(cid:13)(cid:13)

Sn,u ν(du)(cid:13)(cid:13)(cid:13)(cid:13)p

= O(cid:16)n1/p(cid:17) ,

if µ has a moment of order p ∈ [2, 3].

The next step is to replace ˜µn by µn. To do this, we need to introduce

(65)

δ(¯x, ¯y) := |hx, yi|
kxkkyk

.

It follows from Proposition 4.5 of [4] that if µ has a moment of order p > 1, then

(66)

sup

v∈XZX |log(δ(u, v))|p−1 ν(du) < ∞ .

Now, from [6] pages 52-53, we know that there exists a random variable V (ω) with
values in X, such that, for any x ∈ Rd such that kxk = 1,

0 ≤ log kAnk − log kAnxk ≤ |log δ(¯x, V )| .

Integrating this inequality, we get

log kAnk −ZX

(cid:13)(cid:13)(cid:13)(cid:13)

Sn,u ν(du)(cid:13)(cid:13)(cid:13)(cid:13)∞ ≤ sup

v∈XZX |log(δ(u, v))| ν(du) < ∞

the term on right hand being ﬁnite because µ has a moment of order 2. The result
easily follows.

8.2. Results without proximality. Proceeding as in the proof of Theorem 4.11 of
[4] (using their Lemma 4.13) we infer that the results for matrix norm hold without
proximality. Then, we see that the results of Theorems 1 and 2 hold also without
proximality, since (42) do not require proximality but only strong irreducibility.

8.3. Matrix coeﬃcients. We shall now explain how to derive results for matrix co-
eﬃcients, i.e. for any given x, y ∈ Rd with kxk = kyk = 1, we study the behaviour of
(log |hAnx, yi|)n≥1.
We were not able to extend Theorem 2 to the matrix coeﬃcients. We only succeeded
to extend Theorem 1, but under a stronger moment assumption (and it does not seem
possible to get rid of the proximality assumption here). Our argument is inspired by
[17]. We shall use the distance δ deﬁned in (65) and the upper bound (66).

LIMIT THEOREMS FOR GLd(R)

27

Let 1 < p ≤ 4. Assume that µ has a moment of order p + 1. Let us explain why
the results from Theorem 1 may be extended to the matrix coeﬃcients. Actually, using
similar arguments as below, one may see that a moment of order 2 is enough to derive
item (ii) of Theorem 1 for the matrix coeﬃcients.
Let x, y ∈ Rd such that kxk = kyk = 1. We have

log |hAnx, yi| = log kAnxk + log kyk + log |hAnx, yi|
kAnxkkyk

.

The behaviour of (log kAnxk)n≥1 is described in Theorem 1.

It is obvious (using Lemma 4 of [5] to deal with items (iii) and(iv)) that the results

of Theorem 1 will hold for the matrix coeﬃcients if we can prove that

or, equivalently, that

log |hAnx, yi|

kAnxkkyk(cid:12)(cid:12)(cid:12)
log δ(An ¯x, ¯y)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)

= o(n1/p)

P-a.s.

= o(n1/p)

P-a.s.

(recall that An ¯x = Anx). Since δ ≤ 1, we are back to prove that for every ε > 0, P-a.s.,
we have

δ(An ¯x, ¯y) ≥ e−εn1/p

for all n large enough .

Now, it is well-known (see e.g. Deﬁnition 4.1 page 55 and (9) page 61 of [6]), that,

for any x′, y′ in Rd − {0},

(67)

Hence

Now,

|hx′, y′i|
=q1 −(cid:0)d(cid:0)x′, y′(cid:1)(cid:1)2
kx′kky′k
δ2(An ¯x, ¯y) = 1 − d2(An ¯x, ¯y) .

.

1 − d2(An ¯x, ¯y) ≥ 1 −(cid:0)d(An ¯x, Wn) + d(Wn, ¯y)(cid:1)2(cid:1)
≥ 1 − d2(An ¯x, Wn) − 2d(An ¯x, Wn)d(Wn, ¯y) − d2(Wn, ¯y) .
Since for every n ∈ N, Wn has law ν, the variables (log δ(Wn, ¯y))n∈N are identically
distributed in Lp(Ω,F, P). In particular, it follows from the Borel-Cantelli lemma that
(68)

| log δ(Wn, ¯y)| = o(n1/p) Pν-a.s.

Hence, for every ε > 0, Pν-a.s., we have
δ(Wn, ¯y) ≥ e−εn1/p

and using (67) again, for every ε > 0, Pν-a.s., we have

for all n large enough ,

(69)

for all n large enough .

As in the proof of Lemma 6, we may write

d(Wn, ¯y) ≤p1 − e−2εn1/p
log(cid:18) d(An ¯x, Wn)

d(¯x, W0) (cid:19) := Mn + Rn ,

28

CHRISTOPHE CUNY, J´ER ˆOME DEDECKER, AND CHRISTOPHE JAN

where (Mn)n≥1 is a (centered) martingale with increments dominated by a variable in
Lp+1 and (Rn)n≥1 is such that there exists ℓ > 0 such that

P(Rn ≥ −ℓn) < ∞ .

Xn≥1

It is well-known, since p + 1 ≥ 2, that (Mn)n≥1 satisﬁes the strong law of large

numbers (actually even the law of the iterated logarithm). Hence, we have, Pν-a.s.

Finally, we infer that, for every ε, Pν-a.s., we have

log d(An ¯x, Wn) ≤ −ℓn/2 for every n large enough .
1 − d2(An ¯x, ¯y) ≥ 1 − e−ℓn − e−ℓnp1 − e−2εn1/p − (1 − e−2εn1/p

which is exactly what we wanted to prove.

) ≥ Ce−2εn1/p

,

(cid:3)

References

[1] G. Alsmeyer, Convergence rates in the law of large numbers for martingales, Stochastic Process.

Appl. 36 (1990), no. 2, 181-194.

[2] B. von Bahr and C.-G. Esseen, Inequalities for the r-th absolute moment of a sum of random

variables, 1 ≤ r ≤ 2. Ann. Math. Statist 36 1965 299-303.
Random walks

J.-F. Quint,

[3] Y. Benoist

and

on

reductive

groups manuscript,

http://www.math.u-psud.fr/∼benoist/prepubli/prepublication.html

[4] Y. Benoist and J.-F. Quint, Central limit theorem for linear groups, accepted for publication in

Ann. Probab.

[5] I. Berkes, W. Liu and W. B. Wu, Koml´os-Major-Tusn´ady approximation under dependence, Ann.

Probab. 42 (2014), no. 2, 794-817.

[6] P. Bougerol and J. Lacroix, Products of random matrices with applications to Schr¨odinger opera-

tors. Progress in Probability and Statistics, 8. Birkh¨auser Boston, Inc., Boston, MA, 1985

[7] C. Cuny, ASIP for martingales in 2-smooth Banach spaces. Applications to stationary processes,

Bernoulli 21 (2015), no 1, 374-400

[8] C. Cuny, Limit

theorems under

the Maxwell-Woodroofe

condition in Banach spaces,

arXiv:1403.0772, accepted for publication in Ann. Probab.

[9] C. Cuny and F. Merlev`ede, Strong invariance principles with rate for “reverse” martingale diﬀer-

ences and applications, J. Theoret. Probab. 28 (2015), no. 1, 137-183.

[10] J. Dedecker, P. Doukhan and F. Merlev`ede, Rates of convergence in the strong invariance principle

under projective criteria, Electron. J. Probab. 17 (2012), no. 16, 31 pp.

[11] J. Dedecker, F. Merlev`ede and E. Rio, Rates of convergence for minimal distances in the central

limit theorem under projective criteria, Electron. J. Probab. 14 (2009), no. 35, 978-1011.

[12] J. Dedecker and E. Rio, On the functional central limit theorem for stationary processes, Ann. Inst.

H. Poincar´e Probab. Statist. 36 (2000) 1-34.

[13] H. Furstenberg and H. Kesten, Products of random matrices, Ann. Math. Statist. 31 (1960) 457-469.
[14] Y. Guivarc’h and A. Raugi, Fronti`ere de Furstenberg, propri´et´es de contraction et th´eor`emes de

convergence, Z. Wahrsch. Verw. Gebiete 69 (1985), no. 2, 187-242.

[15] C. C. Heyde, On the central limit theorem and iterated logarithm law for stationary processes, Bull.

Austral. Math. Soc. 12 (1975), 1-8.

[16] S. Hao and Q. Liu, Convergence rates in the law of large numbers for arrays of martingale diﬀer-

ences, J. Math. Anal. Appl. 417 (2014), no. 2, 733-773.

[17] C. Jan, Vitesse de convergence dans le TCL pour des processus associ´es `a des syst`emes dynamiques
ou des produits de matrices al´eatoires, Th`ese de l’universit´e de Rennes 1 (2001), thesis number
01REN10073.

[18] C. Jan, Vitesse de convergence dans le TCL pour des chaˆınes de Markov et certains processus
associ´es des syst`emes dynamiques, C. R. Acad. Sci. Paris S´er. I Math. 331 (2000), no. 5, 395-398.

LIMIT THEOREMS FOR GLd(R)

29

[19] J. Koml´os, P. Major and G. Tusn´ady, An approximation of partial sums of independent RV’s, and

the sample DF. I. Z. Warsch. Verw. Gebiete 32 (1975), 111-131.

[20] U. Krengel, Ergodic theorems, de Gruyter Studies in Mathematics, 6. Walter de Gruyter & Co.,

Berlin, (1985).

[21] E. Le Page, Th´eor`emes limites pour les produits de matrices al´eatoires, Probability measures on
groups (Oberwolfach, 1981), pp. 258303, Lecture Notes in Math., 928, Springer, Berlin-New York,
1982.

[22] M. Maxwell and M. Woodroofe, Central limit theorems for additive functionals of Markov chains,

Ann. Probab. 28 (2000), no. 2, 713-724.

[23] F. Merlev`ede and M. Peligrad, Rosenthal-type inequalities for the maximum of partial sums of

stationary processes and examples, Ann. Probab. 41 (2013), no. 2, 914-960.

[24] M. Peligrad and S. Utev, A new maximal inequality and invariance principle for stationary se-

quences, Ann. Probab. 33 (2005), no. 2, 798-815.

[25] M. Peligrad, S. Utev, and W. B. Wu, A maximal Lp-inequality for stationary sequences and its

applications, Proc. Amer. Math. Soc. 135 (2007), no. 2, 541-550.

[26] E. Rio, Inequalities for sums of dependent random variables under projective conditions, J. Theoret.

Probab. 22 (2009), no. 1, 146-163.

[27] Shao, Q.M. Almost sure invariance principles for mixing sequences of random variables. Stochastic

Process. Appl. 48 (1993), 319-334.

[28] W. B. Wu, and Z. Zhao, Moderate deviations for stationary processes, Statist. Sinica 18 (2008), no.

2, 769-782.

Laboratoire MICS, Centrale-Supelec, Grande Voie des Vignes, 92295 Chatenay-Malabry

cedex, France.

E-mail address: christophe.cuny@centralesupelec.fr

Laboratoire MAP5 (UMR 8145), Universit´e Paris Descartes, Sorbonne Paris Cit´e, 45

rue des Saints P`eres, 75270 Paris Cedex 06, France
E-mail address: jerome.dedecker@parisdescartes.fr

Lyc´ee Claude Fauriel, Avenue de la lib´eration, 42000 Saint-Etienne, France
E-mail address: christophe.jan@ac-lyon.fr

