6
1
0
2

 
r
a

M
7

 

 
 
]
T
I
.
s
c
[
 
 

1
v
3
4
9
1
0

.

3
0
6
1
:
v
i
X
r
a

Partially Block Markov Superposition

Transmission of Gaussian Source with Nested

1

Lattice Codes

Shancheng Zhao and Xiao Ma

Abstract

This paper studies the transmission of Gaussian sources through additive white Gaussian noise (AWGN)

channels in bandwidth expansion regime, i.e., the channel bandwidth is greater than the source band-

width. To mitigate the error propagation phenomenon of conventional digital transmission schemes, we

propose in this paper a new capacity-approaching joint source channel coding (JSCC) scheme based

on partially block Markov superposition transmission (BMST) of nested lattice codes. In the proposed

scheme, ﬁrst, the Gaussian source sequence is discretized by a lattice-based quantizer, resulting in a

sequence of lattice points. Second, these lattice points are encoded by a short systematic group code.

Third, the coded sequence is partitioned into blocks of equal length and then transmitted in the BMST

manner. Main characteristics of the proposed JSCC scheme include: 1) Entropy coding is not used

explicitly. 2) Only parity-check sequence is superimposed, hence, termed partially BMST (PBMST).

This is different from the original BMST. To show the superior performance of the proposed scheme,

we present extensive simulation results which show that the proposed scheme performs within 1.0 dB

of the Shannon limits. Hence, the proposed scheme provides an attractive candidate for transmission of

Gaussian sources.

Index Terms

Gaussian sources, joint source channel coding, nested lattice codes, partially block Markov super-

position transmission.

Shancheng Zhao is with the College of

Information Science

and Technology,

Jinan University, Guangzhou,

China (shanchengzhao@jnu.edu.cn).

Xiao Ma is with the School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China (max-

iao@mail.sysu.edu.cn).

This work was partially supported by the NSF of China (No. 91438101 and No. 61501206) and the 863 Pro-

gram (No. 2015AA01A709).

2

I. INTRODUCTION

Transmission of analog-valued source through additive white Gaussian noise (AWGN) chan-

nels is of both theoretical and practical importance. Based on modulation techniques used,

commonly implemented transmission schemes can be categorized into three types: analog, digital,

and hybrid analog-digital (HDA). Digital transmission scheme, guided by Shannon’s separation

theorem, consists of source encoder and channel encoder at the transmitter. One of the advantages

of digital transmission scheme is that, based on sophisticated source encoder and channel encoder,

it performs asymptotically close to the theoretical limit, as was proved in [1, 2]. However, to

achieve the optimality, sufﬁciently large blocklengths are required, which lead to large buffer

and long delay. This is unacceptable for most practical applications. Hence, in practice, source

encoder is implemented through the concatenation of a vector quantizer (VQ) and an entropy

encoder, and channel encoder is implemented with high-performance ﬁnite-length codes, e.g.,

turbo codes [3] and low-density parity-check (LDPC) codes [4]. To improve performances in

ﬁnite-length regime, various joint source channel coding (JSCC) schemes have been proposed.

The simplest JSCC scheme is based on separated source encoder and channel encoder, but with

rate allocations between them [5]. In [6], the authors presented a JSCC scheme based on joint

optimization of the source quantizer and the channel encoder/decoder pair. They also developed

necessary conditions for the joint optimality of the source and the channel encoder pair. If

suboptimal source encoder is used, extra redundancy exists in the output of the source encoder.

These redundancy can be incorporated into channel decoding [7] to improve the performance.

Joint design of the source and channel encoder was investigated in [8, 9]. JSCC scheme based

on the concatenation of two LDPC codes are proposed and analyzed in [10]. More on JSCC

schemes can be found in [11–13] and references therein.

Digital transmission scheme suffers from the so-called threshold effect and the leveling-off

effect. The threshold effect refers to the fact that the distortion degrades drastically when the

signal-to-noise ratio (SNR) is below a certain threshold and the leveling-off effect refers to

fact that the distortion remains constant even increasing the SNR. Analogy transmission scheme

via direct amplitude modulation offers the simplest way to cope with these two issues. As an

important example, it was shown in [14] that uncoded transmission, hence analog transmission,

of Gaussian sources through AWGN channels achieves the optimal power-distortion trade-offs

3

in matched bandwidth regime, i.e., the source bandwidth is equal to the channel bandwidth.

However, in unmatched bandwidth regimes, analog transmission schemes typically perform far

away from the Shannon limits. To combine the advantages of digital and analog transmission

schemes, various hybrid digital-analog (HDA) joint source channel coding (JSCC) schemes

have been proposed, see [15–17] and the references therein. In [15], the authors analyzed the

asymptotic performances of serval HDA-JSCC schemes. In [16], a low-complexity and low-

delay HDA-JSCC scheme based on VQ was presented for bandwidth expansion regime, i.e.,

the channel bandwidth is greater than the source bandwidth. This scheme was extended in [17]

for both the bandwidth expansion and the bandwidth compression regime by implementing the

digital part with turbo codes. More on analog and HDA schemes can be found in [18–20] and

references therein.

Another fundamental issue associated with conventional digital transmission schemes is the

catastrophic error propagation phenomenon due to the lack of robustness of entropy coding.

That is, a few bit errors after channel decoding may lead to bursty breakdown of the source

decoder and then result in severe distortion. This abrupt change of distortion is undesired for

some important applications, e.g., deep-space applications and multimedia applications. One

simple but inefﬁcient approach to this issue is to add redundant bits intentionally in the entropy

coding stage to detect the erroneous bits or to prevent error propagation. In [21], a different

approach was proposed based on the concatenation of VQ and systematic rateless LDPC codes

over groups. A scheme similar to that of [21] was proposed in [22] for image transmission in

deep-space applications.

In this paper, we attempt to design capacity-approaching digital JSCC scheme for Gaussian

sources transmitted through AWGN channels in bandwidth expansion regime. We focus on digital

transmission scheme for the following reasons.

• First, with advanced quantization and error correction techniques, digital transmission schemes

can be designed to perform very close to the Shannon limits.

• Second, the leveling-off effect is desired in some applications. For an example, high-quality

multimedia applications are required in daily life. In these applications, we expect that

the decoded signal quality remains constant even channel conditions are varying, as large

variations in the received signal quality over a short periods of time may be annoying to

end users.

4

• Third, digital parts of serval high-performance HDA-JSCC schemes [17, 23] are imple-

mented with digital transmission schemes. Hence, we may improve performances of these

HDA-JSCC schemes by designing new high-performance digital transmission scheme.

The proposed JSCC scheme is based on partially block Markov superposition transmission (BMST)

of nested lattice codes. In the proposed scheme, ﬁrst, the Gaussian source sequence is discretized

by a lattice-based quantizer, resulting in a sequence of lattice points. Second, these lattice points

are encoded by a short systematic group code. Third, the coded sequence is partitioned into blocks

of equal length and then transmitted in the BMST manner. Main characteristics of the proposed

scheme include: 1) In the proposed scheme, only the parity lattice points are superimposed,

hence, termed partially BMST (PBMST). This is different from the original BMST. 2) The

proposed scheme avoids the explicit use of entropy coding, hence mitigates the error propagation

phenomenon of conventional digital scheme. To assess the performance of the proposed scheme,

numerous simulations are presented, which show that the proposed scheme performs close to the

Shannon limits (within 1.0 dB). Hence, the proposed scheme provides an attractive candidate

for digital transmission of analogy source. It may also ﬁnd applications in some HDA-JSCC

schemes proposed in the literature.

II. PROBLEM STATEMENTS

Let S = (s0, s1, s2, ...) denote a discrete-time Gaussian source, where si is a sample of
Gaussian random variable with zero mean and variance σ2 = 1. In this paper, we will consider

both memoryless Gaussian sources and correlated Gaussian sources. We further assume that the

source emits Rs symbols in time interval T and the channel can transmit at most Rc symbols
in time interval T . If Rs≈Rc, which is equivalent to saying that the source and the channel
have comparable bandwidth, it has been shown that coding is not required [14]. However, if
Rs ≪ Rc, we can always ﬁnd a coding scheme to achieve a better performance. In this paper,
we will assume that Rs ≪ Rc.

A general coding scheme can be described as follows.

1) Encoding:

φ : (s0, s1, ...sk−1) 7→ (x0, x1, ....xn−1),

(1)

where xi’s satisfy the power constraint 1

nPi x2

i ≤ P .

S

U

Vector

Quantizer

Source
Encoder

V

Channel
Encoder

X

5

Z

Channel

S(cid:1062)

U(cid:1062)

Look-up

Table

Source
Decoder

V(cid:1062)

Y

Channel
Decoder

Fig. 1. The conventional digital transmission scheme.

2) Transmitting: Assume that xi is transmitted and yi = xi + zi is received, where zi is the

additive Gaussian noise.

3) Decoding:

ψ : (y0, y1, ...yn−1) 7→ (ˆs0, ˆs1, ...ˆsk−1).

(2)

The performance of the above (general) coding scheme can be measured by the average trans-

mitted power P versus the distortion calculated as

D =

1

kXi

(si − ˆsi)2.

(3)

Conventionally, the general coding scheme can be implemented as follows, see Fig. 1 for a

reference.

1) Encoding:

φ1 : S 7→ U, φ2 : U 7→ V, φ3 : V 7→ X,

(4)

where U, V and X are sequences of representative points, binary digits and transmitted

signals, respectively.

2) Decoding:

ψ3 : Y 7→ ˆV, ψ2 : ˆV 7→ ˆU, ψ1 : ˆU 7→ ˆS,

(5)

where ˆV, ˆU and ˆS are estimates of V, U and S, respectively.

6

Typically, φ1 is implemented with a VQ, φ2 is implemented with an entropy encoding al-
gorithm, and φ3 is implemented a high-performance error correction code. One critical issue
associated with this conventional coding scheme is: a few errors in the channel coding stage

may cause the breakdown of the source decoder, owing to the lack of robustness of entropy

coding. To resolve this issue, we propose in the next section a new JSCC scheme which avoids

the explicit use of entropy coding.

III. THE JSCC SCHEME BASED ON PARTIALLY BLOCK MARKOV SUPERPOSITION

TRANSMISSION OF NESTED LATTICE CODES

The transmission diagram of the propose JSCC scheme is shown in Fig. 2(a). First, the

Gaussian source sequence S is quantized with a lattice-based VQ to generate U, a sequence of

lattice points. Second, these lattice points are encoded in the partially block Markov superposition

transmission (PBMST) manner (to be explained later) to obtain the sequence of lattice points

X = (U, P), which serves as the input to the channel. That is, the sequence U is directly

transmitted through the channel, then followed by parity-check lattice points P.

A. Vector Quantizers Based on Nested Lattice Codes

Nested Lattice Codes: Let Λ ∈ Rℓ be a lattice with Λ′ as a sub-lattice. A nested lattice code
G [24] is deﬁned as the coset code Λ/Λ′ by taking the Voronoi region of Λ′ as the shaping
region. That is, G = ΛTV(Λ′), where V(Λ′) denotes the Voronoi region of Λ′. We use the

notation G to emphasize the group structure of nested lattice codes. Note that, to improve the

performance of the nested lattice codes, as source code or channel code, a shifted version of the
Voronoi region V(Λ′) is typically used as the shaping region [25].

Vector quantizer: Without loss of generality, we can rewrite the source as S = (s0, s1, s2, ...),

where st ∈ Rℓ. For s ∈ Rℓ, we deﬁne a quantizer based on the nested lattice code G as

Q(s) = arg min

v∈G ||v − s||2,

(6)

where ||v − s||2 is the squared distance between v and s. Evidently, we can deﬁne a family of
quantizer Qα,v based on a transformed (inﬂation and shifting) nested lattice code, denoted as
α(G + v) = α(Λ + v)TV(α(Λ′)), of the original nested lattice codes G. In this family, we can

choose α > 0 and v such that the distortion D(S, V) is minimized. The parameters α and v

can be optimized to match the characteristics of the source. In this paper, we will present an

iterative optimization procedure, similar to the algorithm in [26], to determine suboptimal α and

7

v. It should be pointed out that the group structure of nested lattice based quantizer is used in
the proposed JSCC scheme. For each v ∈ α(G + v), we deﬁne Av = {s ∈ Rℓ : Qα,v(s) = v}.
Hence the probability of v ∈ G is

P (v) ∝ZAv

fS(s) ds,

(7)

where fS(s) is the ℓ-dimensional joint probability density function of the source.

B. Encoding of Partially Block Markov Superposition Transmission of Nested Lattice Codes

Given a nested lattice code G and a systematic group code C[n, k] with Rs/Rc ≥ k/n deﬁned
on G. We denote the codeword of C[n, k] corresponding to the information sequence u as
x = (u, v), where v is the parity-check sequence. Let s(0), s(1),· · · , s(L−1) be L blocks of
source sequences, each of length-k. The proposed transmission scheme is described as follows,

see Fig. 2(a) and Fig. 2(b) for reference.

Algorithm 1 Encoding of the Proposed JSCC Scheme

1) Initialization: For t < 0, set v(t) = 0 ∈ Gn−k.
2) Recursion: For t = 0, 1, · · · , L − 1,

• Quantization: Quantize the t-th source block s(t) based on G, resulting the sequence

u(t).

• Encoding: Encode u(t) with the encoding algorithm of the systematic group code

C[n, k], the resulting parity-check sequence is denoted as v(t) ∈ Gn−k;

resulting in w(i);

• Interleaving: For 1 ≤ i ≤ m, interleave v(t−i) by the i-th symbol interleaver Πi
• Superposition: Compute p(t) = v(t) +P1≤i≤m w(i) and take x(t) = (u(t), p(t)) ∈ Gn
3) Termination: For t = L, L + 1,· · · , L + m − 1, set s(t) = 0 and compute p(t) and x(t)

as the t-th transmitted block.

following Step. 2).

S

Vector

Quantizer

U

Encoder of

PBMST

X

8

Z

Channel

U(cid:1062)

Look-up

Table

Decoder of

PBMST

Y

(a) The proposed JSCC scheme.

S(cid:1062)

u(t)

+
w(1)

P1

+
w(2)

P2

(cid:258)
+
w(m-1)
(cid:258)

Pm-1

+
w(m)

Pm

u(t)

p(t)

C

v(t)

D

v(t-1)

D

v(t-2)

(cid:258)

v(t-m+1)

D

v(t-m)

(b) Encoder of a partially block Markov superposition transmission system with memory m.

Fig. 2. Block diagram the proposed digital transmission schemes.

Note that, when m = 0, the parity-check sequences are transmitted without superposition.

It can be seen that the proposed JSCC scheme avoids the use of an explicit entropy coding

the bandwidth requirement is satisﬁed. For large L, the discrepancy between

module. Note that a length kL sequence is encoded into a length n(L + m) sequence. Hence
n is
negligible. The addition operation of the group G is used in Step. 2). In the proposed scheme, only

kL

n(L+m) and k

parity-check sequences are superimposed, hence termed partially block Markov superposition

transmission (PBMST). This is different from the original BMST scheme proposed in [27]. The

motivation behind is explained as follows.

• First, it was shown in [28] that systematic JSCC schemes are optimal for a wide class of

sources and channels.

9

• Second, in low SNR region, digital JSCC schemes may fail to decode and the resulting dis-

tortion would be large. If this is the case, the systematic part which is received directly from

the channel can be taken as the decoding output. This ability to obtain the systematic part

is critical for real-time applications and feedback-limited applications, such as multimedia

streaming and deep-space communication [22].

C. Decoding Algorithms of PBMST of Nested Lattice Codes

The proposed transmission scheme can be decoded by a sliding-window decoding algorithm

with a decoding delay delay d over its normal graph, similar to the decoding algorithm of original

BMST codes [27]. We show in Fig. 3 a high-level normal graph of the proposed transmission

scheme with L = 4 and m = 2. A decoding layer consists of nodes and edges in the dashed

box of Fig. 3.

Algorithm 2 Iterative Sliding-Window Decoding Algorithm

• Global Initialization: Assume that y(t), 0 ≤ t ≤ L+m−1, have been received. First, consid-
ering the channel transition probability and the initial probability in (7), compute the proba-
bility of the information sequence P (|→+)
probability, compute the a posteriori probability of the parity sequence P (|→+)
(p(t)). All
messages over the other edges within and connecting to the t-th layer (0 ≤ t ≤ d − 1) are
initialized as uniformly distributed variables. Set a maximum iteration number Imax > 0.

(u(t)). Second, consider only the channel transition

P (t)

U (t)

• Recursion: For t = 0, 1, · · · , L − 1,

1) Local initialization: If t + d ≤ L + m − 1, compute P (|→+)

U (t)

(u(t)) and P (|→+)

P (t)

(p(t))

based on the received sequence y(t). Initialize all the other edges within connecting

to the (t + d)-th layer as uniformly distributed variables.

2) Iteration: For 1 ≤ i ≤ Imax

– Forward recursion: For i = 0, 1,· · · , min(d, L + m − t − 1), the (t + i)-th layer

performs a message processing/passing algorithm scheduled as
+ → Π → = → C → = → Π → + .

– Backward recursion: For i = min(d, L + m − t − 1),· · · , 1, 0, the (t + i)-th layer

performs a message processing/passing algorithm scheduled as

10

+ → Π → = → C → = → Π → + .
– Hard decision: Make hard decisions on u(t) resulting bu(t). If certain conditions are
satisﬁed, output bu(t) and exit the iteration. Stopping criterion will be given later.
3) Cancelation: Remove the effect of bv(t) on all layers by updating the a posteriori

probability as

P (|→+)

(t+i)
j

P

(h) ←Xg∈G

P (|→+)

(g)P (Πi→+)

(h + Πi(g)),

P

(t+i)
j

V t+i

j

for h ∈ G, j = 0, 1,· · · , n − 1, and i = 1, 2,· · · , m.

Remarks: Similar to the sliding-window decoding algorithm of spatial-coupled non-binary

LDPC codes, the following entropy-based stopping criterion can be used in Algorithm 2. Initially,

we set a threshold ǫ > 0 and initialize the entropy rate h0(Y(t)) = 0, where Y(t) is the random
vector corresponding to y(t). For the i-th iteration, we estimate the entropy rate of Y(t) by

hi(Y(t)) = −

−

1
k

k−1Xj=0

1

n − k

Y

(t)
j

(y(t)

log(cid:18)P (C→|)
n−k−1Xj=0

j )(cid:19)
log(cid:18)P (+→|)

(t)
k+j

Y

k+j)(cid:19)

(y(t)

where

P (C→|)

Y

(t)
j

(y(t)

j ) =Xg∈G

P (C→|)

U t
j

(g)Pr{Y (t)

j = y(t)

j

|U t

j = g}

for 0 ≤ j ≤ k − 1 and

P (+→|)

Y

(t)
k+j

(y(t)

k+j) =Xg∈G

P (+→|)

P t
j

(g)Pr{Y (t)

k+j = y(t)

k+j|P t

j = g}

for 1 ≤ j ≤ n − k − 1. If |hi(Y(t)) − hi−1(Y(t))| < ǫ, exit the iteration.

D. Complexity Analysis

Let q denote the cardinality of the nested lattice code G. The decoding complexity of the

sliding-window decoding algorithm is analyzed as follows. Let Opt(A) denote the number of
operations of the node A in the normal graph. Each layer has n − k parallel nodes = of

U(0)

U(1)

U(2)

U(3)

V(0)

V(1)

V(2)

V(3)

1

2

1

2

1

2

1

2

11

P(0)

P(1)

P(2)

P(3)

P(4)

P(5)

Fig. 3. The normal graphical representation of the proposed transmission scheme with L = 4 and m = 2.

degree m + 2, n − k parallel nodes + of degree m + 2, and a node of type C . Hence, in
each iteration, the total number of operations for each decoding layer is (n − k)Opt( + ) +
(n − k)Opt( = ) + Opt( C ). With trellis based implementation, we have Opt( = ) = O(mq) and
Opt( + ) = O(mq2). Decoding complexity of the node C will be given in the next subsection.

E. Design Considerations

The proposed JSCC scheme is speciﬁed by the systematic group code C[n, k], the encod-
ing memory m, and the decoding window size d. Performances of the proposed scheme are

jointly determined by these factors. Typically, similar to the original BMST, we impose that the
systematic group code C[n, k] has simple encoding algorithm and low-complexity maximum a
posteriori (MAP) decoding algorithm. We list in the following several possible candidates of

12

OPTIMIZED QUANTIZER BASED ON Z/3Z FOR MEMORYLESS GAUSSIAN SOURCE (ℓ = 1, α = 1.22).

TABLE I

Intervals
(−∞,−0.61]
-1.22
Representative points
Probability
0.2709
Entropy : H = 1.53 bits/symbol

(−0.61, 0.61]
0
0.4582

(0.61, +∞)
1.22
0.2709

Distortion : D = 0.190.

C[n, k]. Note that other systematic codes with efﬁcient MAP decoding algorithm can also be
used in the proposed scheme.

• The B-fold Cartesian product of repetition group code, denoted as Cr[nB, B]

△
= [n, 1]B,
where [n, 1] represents the repetition code deﬁned over G. The encoder of Cr[nB, B] takes
the sequence u of length-B as input and outputs the sequence (u, v) length-nB, where
. The MAP decoding algorithm of C[nB, B] can be implemented on a
v = (u, u,· · · , u)
}
q-state trellis with decoding complexity O(nqB).

|

n−1

{z

△

• The B-fold Cartesian product of single parity-check group code, denoted as Cs[nB, (n −
= [n, n − 1]B, where [n, n − 1] represents the single parity-check code deﬁned over
1)B]
G. The encoder of Cs[nB, (n − 1)B] takes the sequence u = (u0, u1,· · · , un−2) of length-
(n− 1)B as input and outputs the sequence (u, v) of length-nB, where v =Pn−2
i=0 ui. The
MAP decoding algorithm of C[nB, (n − 1)B] can be implemented on a q-state trellis with
decoding complexity O(nq2B).

• The group code C[n(B1+B2), B1(n−1)+B2] formed by time-sharing between Cs[nB1, (n−

1)B1] and Cr[nB2, B2].

Given the group code C[n, k], the encoding memory m along with the decoding window
size d have impact not only on the performances but also on the complexities. For different

systematic group codes, the required encoding memories to achieve the optimal performance are
different. From our numerical results, we ﬁnd that m ≥ 10 is sufﬁcient. Considering the window
size, larger window size d typically corresponds to better performance. In practice, acceptable
performances are obtained by setting d = 2m ∼ 3m.

OPTIMIZED QUANTIZER BASED ON Z/5Z FOR MEMORYLESS GAUSSIAN SOURCE (ℓ = 1, α = 0.83).

TABLE II

13

Intervals
(−∞,−1.24]
-1.66
Representative points
Probability
0.1075
Entropy : H = 2.19 bits/symbol

(−1.24,−0.41]
-0.83
0.2334

(−0.41, 0.41)
0
0.3182
Distortion : D = 0.082.

(0.41, 1.24)
0.83
0.2334

(1.24, +∞)
1.66
0.1075

-1.22

-0.61

-1.66

-1.24

-

0.83

-0.41

0

0

0.61

1.22

0.83 1.24

1.66

0.41

Fig. 4. The representative points and their corresponding Voronoi regions of the optimized quantizer based on Z/3Z and Z/5Z.

IV. PBMST WITH ONE-DIMENSIONAL NESTED LATTICE CODES

For ℓ = 1, we take the nested lattice codes Z/3Z and Z/5Z for illustrations. For each

nested lattice code, the optimized lattice quantizer is obtained by searching the scaling factor

α to minimize the distortion. The parameters of the optimized lattice quantizers are shown

in Table I and Table II. As expected the distortion of the lattice quantizer based on Z/5Z

is lower than the distortion of the quantizer based on Z/3Z. Graphical illustrations of the

optimized lattice quantizers based on Z/3Z and Z/5Z are shown in Fig. 4. We assume that
Rs/Rc = 1/2. The systematic group code is selected as the 1000-fold Cartesian product repetition
code Cr[2000, 1000]. The simulation results for different encoding memories are shown in Fig. 5
and Fig. 6, where the distortion is measured by the normalized squared errors (average over

frames) between the output of the source and the output from the decoder, as deﬁned in (3).

The simulation results are shown in terms of signal-to-distortion ratio (SDR), deﬁned as

SDR =

1
D

.

(8)

In the following, performances of the proposed JSCC scheme is analyzed and compared.

For digital transmission system with quanziter based on Z/3Z, the source encoder takes Rs
symbols/T as input and delivers at least RsH = 1.53Rs bits/T as output. Hence the channel
coding rate is at least 0.765 bits/channel-use, which implies that the required SNR for reliable

14

digital transmission must be greater than 2.76 dB. This analysis shows that the proposed JSCC

scheme performs 0.59 dB away from the theoretical limit, but with ﬁnite length and simple

implementation.

For digital transmission system with quanziter based on Z/5Z, the source encoder takes Rs
symbols/T as input and delivers at least RsH = 2.19Rs bits/T as output. Hence the channel
coding rate is at least 1.095 bits/channel-use, which implies that the required SNR for reliable

digital transmission must be greater than 5.52 dB. This analysis shows that the proposed JSCC

scheme performs 0.68 dB away from the theoretical limit.

We also compare the proposed scheme with the optimal performance theoretically attain-

able (OPTA) [29]. For D = 0.19, according to the rate-distortion function of Gaussian sources [30],

at least 1.198 bits are required to represent each source symbol. Hence, the required SNR for

reliable transmission, without constraints on the quantizer, the source encoder, and the channel

encoder, is 1.20 dB. It can be seen that the proposed transmission scheme based on Z/3Z

performs 2.15 dB away from the unconstrained theoretical limit. Similar analysis shows that the

proposed transmission scheme based on Z/5Z performs 2.0 dB away from the unconstrained

theoretical limit. From the above analysis, we conclude that the proposed scheme performs well

with respect to both the constrained and the unconstrained limits.

V. PBMST WITH TWO-DIMENSIONAL NESTED LATTICE CODES

A. Optimization of Two-dimensional Nested Lattice Codes

For two-dimensional nested lattice code, two consecutive symbols from the source are quan-

tized jointly, resulting in a point in the nested lattice code. The following algorithm can be

implemented to optimize the parameters of the lattice quantizer to lower down the distortion.

Algorithm 3 An Iterative Optimization Algorithm of Two-dimensional Nested Lattice Code

1) Initialization: Set α = 1 and v = (0, 0). Select the parameter δ.
2) Iteration:

a) Scaling: scale the lattice to ﬁnd α which results in the least distortion D with shifting

vector equal to v. This is an one-dimensional optimization problem and can be solved

by existing optimization algorithms.

15

 

]

B
d
[
 

R
D
S

7.2

7

6.8

6.6

6.4

6.2

6

5.8

5.6

m=0
m=1
m=2
m=3
m=4
m=6
m=8

8
7
SNR [dB]

9

10

11

12

 
3

4

5

6

Fig. 5. The performances of the proposed JSCC scheme: Z/3Z and memoryless Gaussian source.

11

10.5

10

9.5

9

8.5

8

7.5

]

B
d

[
 

R
D
S

7

 
6

8

 

m=0
m=1
m=2
m=3
m=4
m=6
m=8
m=10

10

12

SNR [dB]

14

16

Fig. 6. The performances of the proposed JSCC scheme: Z/5Z and memoryless Gaussian source.

16

b) Shifting: choose the four shifting vectors v1 = (√2/2,√2/2), v2 = (−√2/2,√2/2),
v3 = (√2/2,−√2/2), v4 = (−√2/2,−√2/2) and the step size δ. Compute the

distortion, denoted by Di, of the nested lattice code α(A2 + δvi)/3αA2. Find the
minimal distortion D′ as

D′ = min
1≤i≤4

Di.

(9)

The shifting vector associated with D′ is denoted by v′. If D′ < D, set v = δv′, go

to Step 2 (a).

c) Bi-section: set δ = δ/2, if δ < 0.001, exit the iteration; else go to Step 2 (b).

Remark: Note that in Step 2 b) only one direction is chosen for shifting in each iteration. In

our simulations, the parameter δ is set to be 1.0.

B. Nested Lattice Code Based on Hexagonal Lattice

For ℓ = 2, a nested lattice code based on the two-dimensional hexagonal lattice A2 is
selected for simulation. The sublattice chosen for shaping is 3A2. The lattice points in A2

are integer combinations of the base vectors g1 = (1/2,√3/6), g2 = (1/2,−√3/6). That is
A2 = {α1g1 + α2g2 : α1 ∈ Z and α2 ∈ Z}. The sublattice 3A2 is generated by basis vectors
g3 = (3/2,√3/2), g4 = (3/2,−√3/2). The nested lattice code is shown in Fig. 7. Note that only

the points in the doted hexagon are chosen as codewords of the nested lattice code. According
to the labels in Fig 7, we can deﬁne a ﬁnite abelian group G ∆= {o, a, b, c, d, e, f, g, h} with
the operation rule deﬁned in Table III. The identity element is o. Actually, the group G is the
quotient group deﬁned by A2 and its subgroup 3A2, that is, G = A2/3A2.

1) Memoryless Gaussian Sources: We have simulated the proposed scheme based on two-

dimensional nested lattice code for memoryless Gaussian source. Algorithm 3 is implemented

to optimize the inﬂation factor α and the shifting vector v. The results are shown in Table IV.

Also shown in Table IV are the coordinates of the representative points. It can be seen that

two-dimensional quantizer reveals lower distortion than one-dimensional quantizer. We assume

that RS/RC = 1/2. The systematic group code is selected as the 1000-fold Cartesian product
repetition code Cr[2000, 1000]. The simulation results for different encoding memories are shown
in Fig. 8.

17

(cid:73)

(cid:72)

(cid:75)

(cid:69)

(cid:70)

(cid:68)

v

(cid:71)

(cid:74)

Fig. 7. The nested lattice code based on A2/3A2: A2 is the hexagonal lattice, v is the shifting vector and the shaping region
is the doted hexagon.

symbols/T as input and delivers at least Rs

For digital transmission system with quanziter based on A2/3A2, the source encoder takes Rs
2 H = 1.525Rs bits/T as output. Hence the channel
coding rate is at least 0.763 bits/channel-use, which implies that the required SNR of digital

transmission scheme must be greater than 2.73 dB. This analysis shows that the proposed JSCC

scheme performs 0.5 dB away from the theoretical limit, but with ﬁnite length and simple

implementation.

It can be seen from Fig. 8 that the proposed scheme based on two-dimensional lattice performs

about 0.15 dB better than that based on one-dimensional lattice. Also note that distortion of

two-dimensional lattice based scheme is slightly lower than that of one-dimensional lattice based

scheme. This is consistent with the results in Table I and Table IV. However, the two-dimensional

lattice based scheme requires more computation than the scheme based on one-dimensional

THE ADDITION TABLE OF THE QUOTIENT GROUP A2/3A2, WHERE O IS THE IDENTITY ELEMENT.

TABLE III

18

+ a
a
e
h
b
b
c
o
d
f
e
g
f
e
g
h
c
o
a

b c
h b
e
g
g f
c
h
o d
o
a
d a
f
e
b c

d e
o f
o
c
h d
a
g
g b
h
e
f
c
b a
d e

g h
f
c
g e
d f
a
o a
e
b
e
f
a
h c
c
b d
b h o
d o g
g h
f

o
a
b
c
d
e
f
g
h
o

]

B
d

[
 

R
D
S

7.2

7

6.8

6.6

6.4

6.2

6

5.8

5.6

 
3

4

5

6

 

m=0
m=1
m=2
m=3
m=4
m=6
m=8
m=10

8
7
SNR [dB]

9

10

11

12

Fig. 8. The performances of the proposed JSCC scheme: A2/3A2 and memoryless Gaussian source.

lattice.

2) Correlated Gaussian Sources: Consider a correlated discrete-time Gaussian source S =
(S0, S1, S2, ...), where Si is a Gaussian random variable with zero mean and variance σ2 = 1,
deﬁned as

S2k+1 = ρS2k +p1 − ρ2Z2k,

(10)

OPTIMIZED VECTOR QUANTIZER BASED ON TWO-DIMENSIONAL LATTICE FOR MEMORYLESS GAUSSIAN

SOURCE (ℓ = 2, α = 2.26, v = (−0.151, −0.088)).

TABLE IV

19

symbol
a
b
c
d
e
f
g
h
o

coordinates
probability
0.1369
(−0.3413, 1.1059)
0.1529
(0.7887, 0.4535)
0.1361
(0.7887,−0.8513)
(−0.3413,−1.5037) 0.0940
(−1.4713,−0.8513) 0.0716
0.0942
(−1.4713, 0.4535)
0.0597
(1.9187,−0.1989)
0.0595
(0.7887, 1.7583)
(−0.3413,−0.1989) 0.1951

Entropy : H = 3.05 bits/two-dimension
Distortion : D = 0.188.

where Z2k is a Gaussian random variable with zero mean and variance σ2 = 1 and ρ ∈ [0, 1] is the
correlation factor. Note that ρ = 1 corresponds to completely correlated Gaussian source, while
ρ = 0 corresponds to memoryless Gaussian source. For different correlation factors, Algorithm
3 is executed to ﬁnd optimized lattice quantizers. The optimization results are shown in Table V

for 0.707. We assume that RS/RC = 1/2. The systematic group code is selected as the 1000-fold
Cartesian product repetition code Cr[2000, 1000]. The simulation results are shown in Fig. 9 for
m = 8.

For conventional digital transmission system with quanziter based on A2/3A2, the source
encoder takes Rs symbols/T as input and delivers at least Rs
2 H = 1.375Rs bits/T as output.
Hence the channel coding rate is at least 0.6875 bits/channel-use, which implies that the required

SNR of digital transmission scheme must be greater than 2.02 dB. This analysis shows that the

proposed JSCC scheme performs 0.88 dB away from the theoretical limit, but with ﬁnite length

and simple implementation.

For comparison, we have also simulated the proposed JSCC scheme with the lattice quantizer

in Table IV (optimized for memoryless Gaussian sources) for the transmission of correlated

Gaussian sources. Simulation results are shown in Fig. 9 with m = 8. It can be seen from

Fig. 9 that, for correlated Gaussian sources, the proposed schemes based on optimized nested

lattice codes reveal lower distortions than the scheme based on nested lattice code designed for

]

B
d
[
 

R
D
S

7.5

7

6.5

6

5.5

5

4.5

4

3.5

 
3
2.5

20

 

A2/3A2 optimzed for ρ=0.707
A2/3A2 optimzed for memoryless Gaussian sources

3

3.5

SNR [dB]

4

4.5

Fig. 9. The performances of the proposed JSCC scheme: two-dimensional lattice quantizers, m = 8, and correlated Gaussian
source.

memoryless Gaussian sources. This shows that the optimization of nested lattice codes is critical

to the proposed JSCC scheme.

VI. CONCLUSION

We studied in this paper the digital transmission of Gaussian sources, memoryless or correlated,

through AWGN channels in bandwidth expansion regime. We proposed a new JSCC scheme

based on the partially block Markov superposition transmission of nested lattice codes. Advan-

tages of the proposed scheme include: 1) It avoids the explicit use of entropy coding module,

hence mitigates the error propagation phenomenon of conventional pure digital scheme. 2) Its

performs well for different nested lattice codes and different Gaussian sources. The proposed

scheme provides an attractive candidate for digital transmission of Gaussian sources through

AWGN channels, either in purely digital systems or in HDA systems.

The authors would like to thank Mr. Zheng Yang for helpful discussion.

ACKNOWLEDGMENT

OPTIMIZED VECTOR QUANTIZER BASED ON TWO-DIMENSIONAL LATTICE FOR A CORRELATED GAUSSIAN SOURCE:

ρ = √2/2. (m = 2, α = 2.27, v = (−0.0375, −0.225)).

TABLE V

21

symbol
a
b
c
d
e
f
g
h
o

coordinates
probability
0.1660
(−0.0855, 0.8034)
0.1454
(1.0545, 0.1452)
0.0135
(1.0545,−1.1712)
(−0.0855,−1.8294) 0.0310
0.1696
(−1.2255,−1.171)
0.0817
(−1.2255, 0.1452)
0.0047
(2.194,−0.5130)
0.1559
(1.0545, 1.4614)
(−0.0855,−0.5130) 0.2322

Entropy : H = 2.75 bits/two-dimension
Distortion : D = 0.189.

REFERENCES

[1] C. Shannon, “A mathematical theory of communications,” Bell Systems Technical Journal, vol. 27, pp. 379–423 (part I)

and 623–656 (part II), 1948.

[2] T. Berger, Rate distortion theory: A mathematical basis for data compression. Prentice-Hall, 1971.

[3] C. Berrou, A. Glavieux, and P. Thitimajshima, “Near Shannon limit error-correcting coding and decoding: Turbo-codes,”

in Proc. IEEE Int. Conf. on Communications, Geneva, Switzerland, May 1993, pp. 1064–1070.

[4] R. Gallager, Low-Density Parity-Check Codes. Cambridge, MA: MIT Press, 1962.

[5] M. Stoufs, A. Munteanu, J. Cornelis, and P. Schelkens, “Scalable joint source-channel coding for the scalable extension

of H.264/AVC,” IEEE Trans. Circuits and Systems for Video Technology, vol. 18, no. 12, pp. 1657 –1670, Dec. 2008.

[6] N. Farvardin and V. Vaishampayan, “Optimal quantizer design for noisy channels: An approach to combined source-channel

coding,” IEEE Trans. Inform. Theory, vol. 33, no. 6, pp. 827 – 838, Nov. 1987.

[7] Y. Wang and Q. Zhu, “Error control and concealment for video communication-A review,” Proceedings of the IEEE,

vol. 86, no. 5, pp. 974 –997, May 1998.

[8] D. Goodman and C. Sundberg, “Combined source and channel coding for variable-bit-rate speech transmission,” Bell

Syst.Tech. J., vol. 62, pp. 2017 – 2036, 1983.

[9] D. Daut and J. Modestino, “Two-dimensional DPCM image transmission over fading channels,” IEEE Trans. Comm.,

vol. 31, no. 3, pp. 315 – 328, March 1983.

[10] M. Fresia, F. Perez-Cruz, and H. Poor, “Optimized concatenated LDPC codes for joint source-channel coding,” in 2009

IEEE International Symposium on Information Theory, June 2009, pp. 2131–2135.

[11] R. Hamzaoui, V. Stankovic, and Z. Xiong, “Rate-based versus distortion-based optimal joint source-channel coding,” in

2002 Data Compression Conference, 2002, pp. 63–72.

[12] Q. Xu, V. Stankovic, and Z. Xiong, “Distributed joint source-channel coding of video using raptor codes,” IEEE Journal

on Selected Areas in Communications, vol. 25, no. 4, pp. 851–861, May 2007.

22

[13] M. Fresia, F. Perez-Cruz, H. Poor, and S. Verdu, “Joint source and channel coding,” IEEE Signal Processing Magazine,

vol. 27, no. 6, pp. 104–113, Nov. 2010.

[14] T. Goblick, “Theoretical limitations on the transmission of data from analog sources,” IEEE Trans. Inform. Theory, vol. 11,

pp. 558 – 567, Oct, 1965.

[15] U. Mittal and N. Phamdo, “Hybrid digital-analog (HDA) joint source-channel codes for broadcasting and robust

communications,” IEEE Trans. Inform. Theory, vol. 48, no. 5, pp. 1082–1102, May 2002.

[16] M. Skoglund, N. Phamdo, and F. Alajaji, “Design and performance of VQ-based hybrid digital-analog joint source-channel

codes,” IEEE Trans. Inform. Theory, vol. 48, no. 3, pp. 708–720, Mar 2002.

[17] ——, “Hybrid digital-analog source-channel coding for bandwidth compression/expansion,” IEEE Trans. Inform. Theory,

vol. 52, no. 8, pp. 3757–3763, Aug. 2006.

[18] M. Wilson, K. Narayanan, and G. Caire, “Joint source channel coding with side information using hybrid digital analog

codes,” IEEE Trans. Inform. Theory, vol. 56, no. 10, pp. 4922–4940, Oct. 2010.

[19] Y. Gao and E. Tuncel, “New hybrid digital/analog schemes for transmission of a Gaussian source over a Gaussian channel,”

IEEE Trans. Inform. Theory, vol. 56, no. 12, pp. 6014–6019, Dec. 2010.

[20] Y. Hu, J. Garcia-Frias, and M. Lamarca, “Analog joint source-channel coding using non-linear curves and MMSE decoding,”

IEEE Trans. Commun., vol. 59, no. 11, pp. 3016–3026, Nov. 2011.

[21] Z. Yang, S. Zhao, X. Ma, and B. Bai, “A new joint source-channel coding scheme based on nested lattice codes,” IEEE

Communications Letters, vol. 16, no. 5, pp. 730 –733, May 2012.

[22] O. Bursalioglu, G. Caire, and D. Divsalar, “Joint source-channel coding for deep-space image transmission using rateless

codes,” IEEE Trans. Commun., vol. 61, no. 8, pp. 3448–3461, Aug. 2013.

[23] M. Rungeler, J. Bunte, and P. Vary, “Design and evaluation of hybrid digital-analog transmission outperforming purely

digital concepts,” IEEE Trans. Commun., vol. 62, no. 11, pp. 3983–3996, Nov. 2014.

[24] R. Zamir, S. Shamai, and U. Erez, “Nested linear/lattice codes for structured multiterminal binning,” IEEE Trans. Inform.

Theory,, vol. 48, no. 6, pp. 1250 –1276, June 2002.

[25] J. Conway and N. Sloane, “A fast encoding method for lattice codes and quantizers,” IEEE Trans. Inform. Theory, vol. 29,

no. 6, pp. 820 –824, Nov. 1983.

[26] V. Vaishampayan and N. Farvardin, “Optimal block cosine transform image coding for noisy channels,” IEEE Trans. Com-

mun., vol. 38, no. 3, pp. 327–336, Mar 1990.

[27] X. Ma, C. Liang, K. Huang, and Q. Zhuang, “Block Markov superposition transmission: Construction of big convolutional

codes from short codes,” IEEE Trans. Inform. Theory, vol. 61, no. 6, pp. 3150–3163, June 2015.

[28] S. Shamai, S. Verdu, and R. Zamir, “Systematic lossy source/channel coding,” IEEE Trans. Inform. Theory, vol. 44, no. 2,

pp. 564–579, March 1998.

[29] E. Akyol, K. Viswanatha, K. Rose, and T. Ramstad, “On zero-delay source-channel coding,” IEEE Trans. Inform. Theory,

vol. 60, no. 12, pp. 7473–7489, Dec. 2014.

[30] T. M. Cover and J. A. Thomas, Elements of Information Theory. New York: John Wiley and Sons, 1991.

