Turbo-Equalization Using Partial Gaussian

Approximation

Chuanzong Zhang, Zhongyong Wang, Carles Navarro Manch´on, Peng Sun, Qinghua Guo

and Bernard Henri Fleury, Senior member, IEEE

1

6
1
0
2

 
r
a

 

M
4
1

 
 
]
T
I
.
s
c
[
 
 

1
v
2
4
1
4
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—This paper deals with turbo-equalization for coded
data transmission over intersymbol
interference (ISI) chan-
nels. We propose a message-passing algorithm that uses the
expectation-propagation rule to convert messages passed from
the demodulator-decoder to the equalizer and computes mes-
sages returned by the equalizer by using a partial Gaussian
approximation (PGA). Results from Monte Carlo simulations
show that this approach leads to a signiﬁcant performance
improvement compared to state-of-the-art turbo-equalizers and
allows for trading performance with complexity. We exploit the
speciﬁc structure of the ISI channel model to signiﬁcantly reduce
the complexity of the PGA compared to that considered in the
initial paper proposing the method.

Index Terms—Turbo equalization, partial Gaussian approxi-

mation, message-passing.

I. INTRODUCTION

H ISTORICALLY, turbo equalization of coded data trans-

mission across a known inter-symbol interference (ISI)
channel found its inspiration from turbo-decoding of turbo-
codes, see [1] and references therein. Since its introduction
turbo equalization has prevailed over more traditional equal-
ization techniques available at that time due to its tremendous
performance gain. Turbo-equalization is a collective name
for joint data decoding and channel equalization algorithms
that pass messages iteratively along the edges of a factor
graph representing the probabilistic model of the considered
transmission system. The most prominent message-passing
algorithm – inherited from turbo-decoding of turbo-codes – is
the sum-product algorithm [2], which is also known as belief
propagation (BP) [3].

Two different factor graphs [2] representing the ISI chan-
nel can be drawn, which lead to different message-passing
algorithms for equalization, see [4] and [5] for more details.
In this letter, we use the one that exhibits a tree structure

This work is supported by the National Natural Science Foundation of

China (NSFC 61571402, NSFC U1204607, NSFC 61201251).

C. Zhang is with the School of Information Engineering, Zhengzhou Uni-
versity, Zhengzhou 450001, China, and the Department of Electronic Systems,
Aalborg University, Aalborg 9220, Denmark (e-mail: ieczzhang@gmail.com).
Information Engi-
iezy-

neering, Zhengzhou University, Zhengzhou 450001, China (e-mail:
wang@zzu.edu.cn; iepengsun@gmail.com).

Z. Wang and P. Sun are with the School of

C. Navarro Manch´on and B. H. Fleury are with the Department of
Electronic Systems, Aalborg University, Aalborg 9220, Denmark (e-mail:
cnm@es.aau.dk; ﬂeury@es.aau.dk).

Q. Guo is with the School of Electrical, Computer and Telecommunications
Engineering, University of Wollongong, Wollongong, NSW 2522, Australia,
and also with the School of Electrical, Electronic and Computer Engineering,
the University of Western Australia, Crawley, WA 6009, Australia (e-mail:
qguo@uow.edu.au).

[4]. This factor graph explicitly represents the channel state
evolution, see Fig. 1. Applying BP on this graph yields BCJR-
like equalization algorithms [4]. The complexity of these
algorithms scales exponentially with the modulation order and
the channel memory. Proposed solutions that circumvent this
complexity problem convert the discrete messages returned
by the demodulator-decoder into Gaussian functions that are
passed as messages to the equalizer [6]–[8]. The complexity
reduction results from the fact that the equalizer then processes
Gaussian messages. The conversion can be done in two ways:
either directly by matching the ﬁrst and second moments of
any of these discrete messages [7], or indirectly by using the
formal rule of expectation propagation (EP) [9]: ﬁrst a Gaus-
sian approximation matching the ﬁrst and second moments of
the belief of the channel symbol node is computed from which
the Gaussian message is then obtained [6], [8]. Numerical
studies have shown that the latter conversion leads to better
BER performance [6], [8].

Inspired by the partial Gaussian approximation (PGA) pro-
posed in [10] we modify the messages returned from the
equalizer and passed to the demodulator-decoder in [8]. The
messages returned by the equalizer in [8] are computed from
the above Gaussian-converted messages from the demodulator-
decoder. By contrast, to equalize one channel symbol the new
equalizer combines discrete messages from the demodulator-
decoder for the symbols strongly interfering with said symbol
and Gaussian-converted messages for the weakly interfering
symbols. The reported simulation results show that doing so
leads to a signiﬁcant performance improvement compared to
the turbo-equalizers in [7], [10] and [8]. Finally, our turbo-
equalizer allows for trading complexity with performance by
varying the set of symbols that are considered as strong
interferers.

Our turbo-equalizer differs from the PGA-based one in [10]
in two respects. First, in the former the conversion of the
discrete messages returned by the demodulator-decoder into
Gaussian functions is done using the formal EP rule, while it
is performed by direct conversion of the discrete messages in
the latter. Secondly, due to the particular structure of the ISI
channel model, the messages returned by our equalizer can
be computed from the Gaussian messages passed to it in a
simple way. This leads to a signiﬁcant complexity reduction
compared to the turbo-equalizer in [10].

Notation- For a natural number N, we write [N ] =
{1, . . . , N}. Boldface lowercase and uppercase letters denote
vectors and matrices, respectively. The identity matrix of
size M is represented by I M . Superscript (·)T designates

transposition of a vector or matrix. We write N(x; m, V )
for the pdf of a multivariate Gaussian distribution with mean
vector m and covariance matrix V . Depending on the context
δ(·) denotes either the Dirac delta function or the Kronecker
delta. The relation f (·) = cg(·) for some positive constant
x\y f (x) and

c is written as f (·) ∝ g(·). The notations (cid:80)
(cid:82) f (x) d(x \ y) denote respectively the partial summation

and partial integration of the function f (x) with respect to
all entries of the vector x except those entries common to x
and y.

II. SYSTEM MODEL

i ,··· , cQ

The vector b = [b1, . . . , bK]T of information bits is encoded
and interleaved, yielding the codeword c = [cT
N ]T with
i ]T. The coded bits are then mapped onto a
ci = [c1
Q-order modulation alphabet X ⊆ R 1, resulting in the vector
of symbols x = [x1, . . . , xN ]T ∈ X N . These symbols are
transmitted over a linear, time-invariant, frequency-selective
channel corrupted by additive white Gaussian noise (AWGN).
The received vector r = [r1, . . . , rN +L−1]T has entries

1, . . . , cT

ri =

hlxi−l + ni = hTsi + ni,

i ∈ [N + L − 1]

(1)

where si = [xi−L+1, . . . , xi]T with xi = 0 for i < 1 and
i > N, h = [hL−1, . . . , h0]T represents the channel impulse
response, and n = [n1, . . . , nN +L−1]T is a white noise vector
with component variance σ2.

A. Probabilistic Model and Factor Graph

The posterior probability mass function (pmf) of vectors b,

c, x and s given the received signal r reads

L−1(cid:88)

l=0

k=1

K(cid:89)
N(cid:89)
N +L−1(cid:89)

i=1

i=N +1

p (b, c, x, s|r) ∝

×

×

fBk (bk) × fC (c, b)

fOi (ri, si) fTi (si, si−1, xi) fMi (xi, ci)

fOi (ri, si) fTi (si, si−1, 0)

(2)

where fBk (bk) is the uniform prior pmf of the kth infor-
mation bit, fC(c, b) stands for the coding and interleaving
constraints, fOi(ri, si) (cid:44) p(ri|si) = N(ri; hTsi, σ2) denotes
the likelihood of si, and fMi(xi, ci) represents the modulation
mapping. Finally, fTi (si, si−1, xi) expresses the deterministic
relationship between si, si−1 and xi, i.e.,

fTi (si, si−1, xi) = δ(Gsi−1 + exi − si)

with the L × L matrix G = (cid:2) 0 I L−1; 0 0T (cid:3), e =
(cid:2) 0; 1 (cid:3) and 0 being a zero column vector of length L − 1.

Fig. 1 depicts the factor graph [11] representing the fac-
torization of the posterior pmf in (2). The factorization and
its graph will be used as the baseline for the derivation

(3)

1For simplicity we consider a real baseband model. The extension to a

complex model is straightforward.

2

Fig. 1. Factor graph representing the probabilistic model (2).

of the turbo-equalizer described in Section III. To ease the
subsequent discussions we identify two subgraphs. The chan-
nel subgraph includes the nodes of the channel symbols xi,
i ∈ [N ] and all factor nodes, variable nodes and edges “to the
left” of these symbol nodes. The transmitter subgraph includes
the channel symbol nodes and all factor nodes, variable nodes,
and edges “to the right” of these symbol nodes.

III. DESIGN OF THE ITERATIVE RECEIVER

i.e. from nodes fTi

In a nutshell, we obtain the new turbo-equalizer by replacing
the messages passed from the equalizer to the demodulator-
decoder,
in
the turbo-equalizer in [8] by messages computed using the
PGA approach in [10]. The next two subsections describe
the messages computed in the new turbo-equalizer. The last
subsection sketches the scheduling of these messages.

to nodes xi, i ∈ [N ],

A. Equalization and Demodulation-decoding

Equalization and demodulation-decoding are implemented
by passing messages along the edges of the channel subgraph
and the transmitter subgraph respectively. Unless otherwise
stated, these messages are computed using the BP rule [3].

1) Demodulation-decoding: The variables in the transmitter
subgraph are discrete and so are the computed messages and
beliefs. Decoding of the convolution code is done using the
(cid:80)
BCJR algorithm, an instance of BP. The messages from the
modulator nodes to the channel symbol nodes are of the form
x∈X βxδ (xi − x) with βx ≥ 0, xi ∈ X ,
mfMi→xi(xi) ∝
i ∈ [N ].
2) Equalization: The latent variables si, i ∈ [N ] in the
channel subgraph are approximated as Gaussian variables.
Since the channel is linear and noise is additive and Gaussian,
the messages and beliefs are Gaussian functions. We write for
the belief of node si (i ∈ [N ]),

(4)
The computation of this belief is given in [7] and [8, Eq. (28)].

bG(si) ∝ N(si; msi, Vsi).

B. Messages Exchanged Between the Equalizer and the
Demodulator-decoder
Demodulator-decoder (D) → Equalizer (E): The EP rule [9]
is used to convert the discrete messages mfMi→xi(xi), i ∈ [N ]
into Gaussian messages [6], [8, Eq. (29)]:

mG

fMi→xi

(xi) =

ProjG[mfMi→xi(xi)nG
(xi)
i ∈ [N ].

nG
xi→fMi
∝ N(xi; mxi, vxi ),

xi→fMi

(xi)]

(5)

fOi−1si−1fOifOi+1sisi+1fTifTi+1xixi+1c1i+1cQib1bKbkfBKfBkfB1fCfMifMi+1cQi+1c1iFor a pdf b(z), ProjG[b(z)] = arg minb(cid:48)(z)∈G D (b(z)||b(cid:48)(z)),
with D(·||·) denoting the Kullback-Leibler divergence and
G being the family of Gaussian pdfs. The parameters mxi
and vxi in (5) are given by [8, Eq. (10) & (11)]. With this
conversion, Gaussian messages nG
(xi),
i ∈ [N ] are passed to the equalizer.
E → D: This is where the new turbo-equalizer differs from
the one described in [6], [8].
In [6], [8] the Gaussian messages from fTi to xi, i ∈ [N ]

are converted into discrete messages 2

(xi) = mG

fMi→xi

xi→fTi

(xi),

fTi→xi

xj→fTj

xi ∈ X , i ∈ [N ].

mfTi→xi (xi) ∝ mG

The discrete messages nxi→fMi
are then passed to the demodulator-decoder.

(6)
(xi) = mfTi→xi(xi), i ∈ [N ]
Consider a speciﬁc symbol xi (i ∈ [N ]). Clearly the
computation of mfTi→xi(xi) using (6) makes use of the
Gaussian approximation of the messages from the other sym-
bols, i.e. nG
(xj), j ∈ [N ] \ {i} by the conversion (5).
The idea is to use the original discrete messages rather than
their Gaussian approximation for a selected subset of channel
symbols which signiﬁcantly interfere with xi. It is inspired
from the PGA proposed in [10].

interfering with symbol xi. Let qk = (cid:80)L−1
First we identify those channel symbols “signiﬁcantly”
l=0 hlhl+k, k ∈ Z
with hl = 0 whenever l ∈ Z \ {0, . . . , L − 1} be the
impulse response.
autocorrelation function of the channel
Deﬁne Kρ = {k ∈ {−(L−1), . . . , L−1} : |qk| > ρq0} the set
of lag indices at which the magnitude of the autocorrelation
function is larger than ρq0, ρ ∈ [0, 1). Then ID
i = {i + k : k ∈
Kρ} ⊆ Ii = {i − (L − 1), . . . , i + L − 1} contains the indices
of the modulation symbol xi and those symbols that interfere
with xi at correlation level ρ. We collect these symbols in the
i ]T, with M = |Kρ|.
i = [xj : j ∈ ID
M-dimensional vector xD
We assume that ¯k = max Kρ fulﬁlls 1 + 2¯k ≤ L. Then we
i are components of
can readily show that all entries in xD
si(cid:48) whenever i + ¯k ≤ i(cid:48)
≤ i + (L − 1) − ¯k. Notice that the
assumption on ¯k guarantees that i + ¯k ≤ i + (L − 1) − ¯k.
(cid:81)
With the above deﬁnitions we can now specify the message
(cid:88)
from fTi to xi:
(cid:81)

i(cid:48) (xD
bG
i )

(xi) =

fTi→xi

mPG

(8)

κ∈ID
k∈ID

i \i nxκ→fTκ
nG
xk→fTk

(xκ)
(xk)

i

i \xi
xD

(cid:82) bG(si(cid:48)) d(si(cid:48)\xD

where nxκ→fTκ

i(cid:48) (xD

(xκ) = mfMκ→xκ(xκ) and bG
i ) =
i ) with bG(si(cid:48)) given in (4). The latter term
is the belief of xD
i obtained by marginalization of the belief
bG(si(cid:48)). The index i(cid:48)
i ) indicates that this belief
depends on the time instant i(cid:48), i + ¯k ≤ i(cid:48)
≤ i + (L − 1) − ¯k.
Notice that the selection i(cid:48) = i + ¯k minimizes the time instant
ahead of i to wait for computing mfTi→xi(xi). The derivation
of (8) is provided in the appendix.

i(cid:48) (xD

in bG

All Gaussian functions occurring in (8) combine as

(cid:89)

κ∈ID

i

−1

nG
xκ→fTκ

(xκ)

i(cid:48) (xD
bG

i ) ∝ N(xD

i ; me
xD
i

, V e

xD
i

)

(9)

2Strictly speaking, the message mfTi
fTi

(xi) to X .

→xi

mG

→xi (xi) in (6) is the restriction of

3

)−1(cid:105)−1

with

(cid:104)

i

=

xD
i

xD
i

xD
i

V e

(cid:104)

= V e

)−1mxD

(P i(cid:48)V si(cid:48) P T

(P i(cid:48)V si(cid:48) P T

i(cid:48))−1 − (V xD

i(cid:48))−1P i(cid:48)msi(cid:48) − (V xD

(cid:105)
me
.
In these expressions, the M × L selection matrix P i(cid:48) extracts
the vector xD
i = P i(cid:48)si(cid:48). The entries of
i
and the diagonal entries of the diagonal
the vector mxD
are the ﬁrst moments mxκ and the second central
matrix V xD
moments vxκ respectively of the messages nG
(xκ),
κ ∈ ID
i . Inserting (9) into (8) yields the PGA-based messages
mPG

from si(cid:48), i.e. xD

(cid:88)

(cid:89)

xκ→fTκ

N(xD

, V e

(xi) =

(xκ),

nxκ→fTκ

i

i

i

i

fTi→xi

i ; me
xD
i

xD
i

)
κ∈ID

i \i

i \xi
xD

that replace the messages mG

fTi→xi

C. Messages Scheduling

i ∈ [N ]
(xi), i ∈ [N ] in (6).

(10)

and

(si)

(si−1)

xi→fTi

fTi→si−1

The turbo-equalizer implements the following scheduling:
(xi) =

S1: Initialization: nxi→fTi

(xi) ∝ 1 and nG
fTi→si

nG
si−1→fTi−1

S2: Equalization:

The messages mG

N (xi; 0, 1), i ∈ [N ].
and
(si), i ∈ [N + L − 1] are recursively computed
nG
si→fTi+1
using (12) and (15) respectively in [8]. In parallel, the
(si),
messages mG
i ∈ {N + L − 1, . . . , 1} are recursively calculated from
the beliefs
(18) and (21) respectively in [8]. Finally,
bG(si), i ∈ [N ] (see (4)) are obtained by (28) in [8].
from (9) and (10).

S3: E → D: The messages mPG
S4: Demodulation-decoding: The messages mPG

(xi), i ∈ [N ] are obtained
(xi), i ∈
[N ] are passed to the demodulator. The BCJR algorithm,
an instance of BP, is run in the decoder, yielding the
(xi) = mfMi→xi(xi), i ∈ [N ].
discrete messages nxi→fTi
(xi) =

S5: D → E: The Gaussian messages nG
(xi), i ∈ [N ] are updated using (5).
Steps S2–S5 constitute an iteration that is repeated until a
maximum number of iterations is reached.

fTi→xi

fTi→xi

fMi→xi

xi→fTi

mG

IV. ANALYSIS, PERFORMANCE AND COMPLEXITY

A. Comparison with Existing Turbo-equalizers

We compare the performance of the new turbo-equalizer
(we denote it as BP-EP-PGA) with that of three other turbo-
equalizers published in the literature by means of Monte Carlo
simulations: (1) BP-EP: the combined BP-EP algorithm in
[8]; (2) BP-PGA: an implementation of the PGA algorithm
in [10] for the equalization of ISI channels; (3) BP-GA:
the LMMSE-based turbo-equalizer, which is equivalent
to
Gaussian-approximated BP [7]. In our implementation BP-
PGA is obtained from BP-EP-PGA by substituting the EP
rule (5) with a direct Gaussian approximation of the discrete
messages from fMi to xi, i ∈ [N ]. All four turbo-equalizers
solely differ in the types of messages exchanged between
the equalizer and the demodulator-decoder. The table below
reports these distinctive features.

(cid:34)L−1(cid:89)
(cid:35)

l=0

i(cid:48) →si(cid:48)(si(cid:48))

(cid:35)

nG
xi(cid:48)−l→fT

(xi(cid:48)−l)

i(cid:48)−l

mG
fO

i(cid:48)−l

→si(cid:48)−l

(si(cid:48)−l)

nG
si(cid:48)−L→fT

i(cid:48)−L+1

(si(cid:48)−L) dsi(cid:48)−L

bG(si(cid:48)) = mG
fT

→si(cid:48)(si(cid:48)) mG
fO

i(cid:48)+1

(cid:90) (cid:34)L−1(cid:89)

l=1

×

4

(7)

Turbo-equalizer
BP-GA [7]
BP-EP [8]
BP-PGA [10]
BP-EP-PGA (new)

Direct conversion

Direct conversion

D → E

EP-rule

EP-rule

E → D
GA
GA
PGA
PGA

i

As the selected threshold ρ in BP-EP-PGA approaches 1, ID
typically shrinks to the singleton {i} (M = 1). With this
, i ∈ [N ] in (10) coincide
conﬁguration, the messages mPG
fTi→xi
with the messages mG
, i ∈ [N ] in (6) and, consequently,
BP-EP-PGA and BP-EP become equivalent. Notice that both
schemes compute the same messages in stage S2-Equalization.
They solely differ in S5-D → E.
B. Computational Complexity

fTi→xi

The complexity of the PGA algorithm in [10], which was
designed for generic channel matrices, is O(N 2 + M 2QM )
per symbol. The main contribution to the complexity of the
BP-EP-PGA is at (4), which requires L × L matrix inver-
sions (see [8, Eq. (28)]), and at (8). Thus, the complexity
is O(L3 + M 2QM ) per symbol. The complexity reduction
method described in [8, Subsec. IV.C] can, however, also be
applied to BP-PGA and BP-EP-PGA. Since the beliefs bG
i(cid:48) (xD
i )
(see (8)) are obtained from the beliefs bG(si(cid:48)), i ∈ [N ] (4)
needs only be computed once every (L−M +1) symbols when
Kρ = {−¯k, . . . , ¯k} (M = 1+2¯k). In this case, the complexity
of BP-PGA and BP-EP-PGA is O(L3/(L−M +1)+M 2QM )
per symbol.

C. Numerical Assessment

We compare the BER performance of the four above turbo-
equalizers and a receiver designed for and operating in a non-
dispersive AWGN channel.

A sequence of 2048 information bits is encoded using
a 1/2 rate convolutional code with generator polynomials
(23, 35)8. The coded bits are interleaved and then mapped
onto BPSK symbols (X = {−1, +1}), which are transmitted
over a severely distorted ISI channel with impulse response
h = [0.227 0.460 0.668 0.460 0.227]T. The BER performance
is evaluated after 30 turbo-equalization iterations. For BP-PGA
and BP-EP-PGA, we set ρ so that M = 3.

The results are depicted in Fig. 2. We observe a remarkable
performance improvement of BP-EP-PGA compared to the
other turbo-equalizers. We attribute this improvement to the
fact that BP-EP-PGA combines the advantages from both BP-
EP and BP-PGA. Firstly, implementing the EP-based conver-
sion (5) instead of a direct conversion of the discrete messages
from fMi
to xi, i ∈ [N ] provides an advantage over BP-
GA and BP-PGA. Secondly, implementing (10) leads to better
performance than when computing the right-hand messages in

Fig. 2. BER performance of the considered turbo-equalizers.

(6) at the expense of a complexity increase, as can be seen
by comparing BP-EP and BP-EP-PGA. Since BP-EP can be
seen as an instance of our proposed BP-EP-PGA with the
setting M = 1, we conclude that the tuning of the parameter
M (or equivalently ρ) allows for trading performance and
computational complexity in the receiver.

APPENDIX

fT

fO

i(cid:48)+1

i(cid:48)→si(cid:48)(si(cid:48))mG

i(cid:48) →si(cid:48)(si(cid:48))mG

We compute (8) for a speciﬁc symbol xi (i ∈ [N ]). Select
si(cid:48) with i(cid:48) satisfying i + ¯k ≤ i(cid:48)
≤ i + (L− 1)− ¯k, see E → D
in Subsection III-B. By applying the BP rule we obtain for
the Gaussian belief of si(cid:48)
bG(si(cid:48)) = mG
fT

→si(cid:48)(si(cid:48)). (11)
To compute mG
i(cid:48)→si(cid:48)(si(cid:48)) we use the BP rule in a
fT
forward recursion along the variable and factor nodes
fTi(cid:48)−L+1, si(cid:48)−L+1, . . . , si(cid:48)−1, fTi(cid:48) . Doing so and inserting in
(11) yields the expression in (7). Notice that the product in
the ﬁrst pair of brackets and the integral are functions of
si = [xi−L+1, . . . , xi]T. From the choice of i(cid:48), the entries
i ]T are also entries of si(cid:48), see E → D
of xD
in Subsection III-B. Thus, the product in the ﬁrst bracket in
(7) contains as factors the messages nG
i . We
implement a PGA by substituting these messages with their
discrete counterparts nxj→fTj
i . This substitution
can be formally expressed as

i = [xj : j ∈ ID

(xj), j ∈ ID

xj→fTj
(xj), j ∈ ID
nxκ→fTκ
nG
xκ→fTκ

(xκ)
(xκ)

(cid:89)

κ∈ID

i

bPG(si(cid:48)) =

bG(si(cid:48)).

(12)

By using the marginalization constraint of BP we can write

mPG

fTi→xi

(xi)nxi→fTi

(xi) =

bPG(si(cid:48)) d(si(cid:48)\xD

i ). (13)

Notice that the right-hand term is a marginal belief of xi.
Solving for mPG

(xi) in (13) yields (8).

fTi→xi

(cid:90)

(cid:88)

i \xi
xD

44.555.566.510−510−410−310−210−1100Eb/N0 (dB)BER  BP−GABP−EPBP−PGABP−EP−PGAAWGNREFERENCES

5

[1] M. T¨uchler, R. Koetter, and A. Singer, “Turbo equalization: Principles
and new results,” IEEE Trans. Commun., vol. 50, pp. 754 – 767, May
2002.

[2] H.-A. Loeliger, “An introduction to factor graphs,” IEEE Trans. Signal

Processing, pp. 28 – 40, Jan. 2004.

[3] J. Pearl, “Reverend Bayes on inference engines: a distributed hierarchical
approach,” in in Proceedings of the National Conference on Artiﬁcial
Intelligence, 1982, pp. 133 – 136.

[4] B. Kurkoski, P. Siegel, and J. Wolf, “Joint message-passing decoding
of ldpc codes and partial-response channels,” IEEE Transactions on
Information Theory, vol. 48, no. 6, pp. 1410 – 1422, Jun 2002.

[5] G. Colavolpe and G. Germi, “On the application of factor graphs and
the sum-product algorithm to ISI channels,” IEEE Trans. Commun., vol.
53, no. 5, pp. 818 – 825, Apr. 2005.

[6] J. Hu, H.-A. Loeliger, J. Dauwels, and F. Kschischang, “A general
computation rule for lossy summaries/messages with examples from
equalization,” in Proc. 44th Allerton Conf. Communication, Control,
and Computing, Sep. 2006, pp. 27 – 29.

[7] Q. Guo and L. Ping, “LMMSE turbo equalization based on factor
graphs,” IEEE J. Select. Areas Commun., vol. 26, no. 2, pp. 311 –
319, Feb. 2008.

[8] P. Sun, C. Zhang, Z. Wang, C. N. Manch´on, and B. H. Fleury, “Iterative
receiver design for ISI channels using combined belief- and expectation-
propagation,” IEEE Signal Processing Lett., vol. 22, no. 10, pp. 1733 –
1737, Oct. 2015.

[9] T. P. Minka, “Expectation propagation for approximate Bayesian in-
ference,” in Proceedings of the Seventeenth Conf. on Uncertainty in
Artiﬁcial Intelligence, 2001, pp. 362 – 369.

[10] Q. Guo, D. Huang, L. Ping, S. Nordholm, J. Xi, and P. Li, “Soft-in
soft-out detection using partial Gaussian approximation,” IEEE Access,
vol. 2, pp. 427 – 436, May 2014.

[11] F. Kschischang, B. Frey, and H.-A. Loeliger, “Factor graphs and the
sum-product algorithm,” IEEE Trans. Inform. Theory, vol. 47, no. 2,
pp. 498 – 519, Feb. 2001.

