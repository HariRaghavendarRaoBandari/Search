Flow of Information in Feed-Forward Deep Neural

Networks

Pejman Khadivi

Computer Science Department
Virginia Tech, Virginia, USA

Email: pejman@vt.edu

Ravi Tandon

Electrical and Computer Engineering Department

University of Arizona, Arizona, USA
Email: tandonr@email.arizona.edu

Naren Ramakrishnan

Computer Science Department
Virginia Tech, Virginia, USA

Email: naren@cs.vt.edu

6
1
0
2

 
r
a

 

M
0
2

 
 
]
T
I
.
s
c
[
 
 

1
v
0
2
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Abstract‚ÄîFeed-forward deep neural networks have been used
extensively in various machine learning applications. Developing
a precise understanding of the underling behavior of neural
networks is crucial for their efÔ¨Åcient deployment. In this paper,
we use an information theoretic approach to study the Ô¨Çow of
information in a neural network and to determine how entropy of
information changes between consecutive layers. Moreover, using
the Information Bottleneck principle, we develop a constrained
optimization problem that can be used in the training process
of a deep neural network. Furthermore, we determine a lower
bound for the level of data representation that can be achieved
in a deep neural network with an acceptable level of distortion.

I. INTRODUCTION

With the increasing demand for data analytics, Big Data, and
artiÔ¨Åcial intelligence, efÔ¨Åcient machine learning algorithms are
required now more than anytime before [1]. Deep learning and
deep neural networks (DNNs) have been shown to be among
the most efÔ¨Åcient machine learning paradigms, speciÔ¨Åcally
for supervised learning tasks. Due to their fascinating perfor-
mance, different deep learning structures have been deployed
in various applications in the past decades [1], [2], [3].
However, despite of their great performance, more theoretical
effort is required to understand the dynamic behavior of DNNs
both from learning and design perspectives.

Deep neural networks are considered as multi-layer struc-
tures, constructed by simple processing units known as neu-
rons that process the input information to generate a desired
output [4], [5]. These structures have been used previously in
a variety of applications, such as dimensionality reduction [6],
face representation [2], robotic grasps detection [3], and object
detection [7].

While DNNs have shown their capability in solving machine
learning problems, they have been traditionally deployed in
a heuristic manner [8], [9]. However,
to be able to use
these structures more efÔ¨Åciently, we need to have a deeper
understanding of their underling dynamic behavior [9].

Mehta and Schwab shown in [10] that deep learning is
related to renormalization groups in theoretical physics and
provide a mapping between deep learning methods and vari-
ational renormalization groups using Restricted Boltzmann
Machines. In [8], Tishby and Zaslavsky proposed a theoretical
framework, based on the principle of Information Bottleneck
[11], to analyze the DNNs where, the ultimate goal of deep

learning has been formulated as a trade-off between com-
pression and prediction. In [8],
the authors claim that an
optimal point exists on the compression-distortion plane that
can efÔ¨Åciently address that trade-off. Moreover, they suggest
that an Information Bottleneck based learning algorithm may
achieve the optimal information representation.

In this paper, we analyze the Ô¨Çow of information in a deep
neural network using an information theoretic approach. While
different structures have been developed for DNNs, in this
paper, we consider the multi-layer feed-forward structure and
we assume that the network is used in a supervised setting.
We determine an upper bound on the total compression rate in
a neural network that can be achieved with an acceptable level
of distortion. Furthermore, using the fundamental concepts of
Information Bottleneck and based on the approach of Tishby
and Zaslavsky in [8], we develop an optimization problem that
can be used in the learning process of DNNs. A case study
supports the justiÔ¨Åcations of the paper. Thus, our contributions
and the structure of the paper are as follows:

‚Ä¢ In Section II, we focus on the information Ô¨Çow across
any two consecutive layers of a DNN by characterizing
the relative change in the entropy across layers and also
developing some properties of the same.

‚Ä¢ In Section III, motivated by the Information Bottleneck
principle, we deÔ¨Åne an optimization problem for training
a DNN, in which the goal is to minimize the overall log-
loss distortion. Moreover, we prove an upper bound on
the total data compression which is achievable in a DNN
with an acceptable level of distortion.

‚Ä¢ In Section IV we modify the optimization problem of
Section III to address the practical limitations of neural
computation. We Ô¨Årst illustrate that how the results of the
original optimization model may be unfeasible and then,
by adding sufÔ¨Åcient constraints to the model we propose
a modiÔ¨Åed optimization problem that can be used in the
training process of a DNN.

II. FLOW OF ENTROPY IN DEEP NEURAL NETWORKS
The typical structure of a feed-forward DNN is illustrated
in Fig 1. In this Ô¨Ågure, input layer is represented by X and
the representation of data in the ith hidden layer is shown
by Xi. We assume that the network has ŒΩ layers and the
output layer, i.e. XŒΩ, should estimate a desired output, Y .

and in this case, we have kn < kn‚àí1.

It worth mentioning that the mapping in each layer of DNN is
also a partitioning of the layer‚Äôs input space and hence, what a
DNN does is multiple consecutive of partitioning and mapping
processes with goal of estimating of a desired output.

DeÔ¨Ånition 1: In the nth layer of a feed-forward DNN, layer
partition is the partitioning of the nth layer‚Äôs input space
which occurs due to the neural computations performed in
layer n. We illustrate this partitioning by Sn = {Sn
}
1 ,¬∑¬∑¬∑ , Sn
kn
is the set of all the output combinations in layer
where, Sn
j
n ‚àí 1 that are mapped to the jth output combination in layer
n, i.e. xn

j . In other words,
j = { xn‚àí1
Sn

‚àà Xn‚àí1 | xn

i
Note that we have:
i (cid:54)= j ‚áí Sn

)}

i

j = Gn(xn‚àí1
kn(cid:91)

j=1

i ‚à© Sn

j = ‚àÖ

and

j = Xn‚àí1.
Sn

Let us assume that Pn(xn

j ) is the probability of xn

j . Then,

it can be observed that

Pn(xn

j ) =

Pn‚àí1(x(cid:48))

(3)

(cid:88)

x(cid:48)‚ààSn

j

Furthermore, considering this fact that Sn is a partitioning of
Xn‚àí1, one can easily show that Pn(xn
j ) is the probability of
partition Sn

j . It can be shown that

(cid:40)

Œ†n

j =

‚àÄx ‚àà Sn
j |

(cid:41)

(cid:80)

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

x(cid:48)‚ààSn

j

(4)

is the probability distribution of all the combinations in Sn
j .
DeÔ¨Ånition 2: In a feed-forward DNN, the entropy of layer
n, H(Xn), is the entropy of the neuron outputs at this layer
and we have:

H(Xn) = ‚àí kn(cid:88)

i=1

Pn(xn

i ) log Pn(xn

i ).

DeÔ¨Ånition 3: The entropy of partition Sn

j , H(Sn
entropy of the output combinations that belong to Sn
words:

j ), is the
j . In other

j ) = ‚àí (cid:88)

(cid:80)

H(Sn

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

log

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

x(cid:48)‚ààSn

j

x‚ààSn

j

x(cid:48)‚ààSn

j

(cid:80)

In the following lemma we show how entropy of informa-

tion changes in a feed-forward neural network.

Lemma 1: In a feed-forward DNN, the entropy of informa-
tion that Ô¨Çows from layer n ‚àí 1 to layer n is decreased by
the expected entropy of the partitions on the possible output
combinations in layer n ‚àí 1. The amount of this reduction is
shown by ‚àÜn and we have

‚àÜn = H(Xn‚àí1) ‚àí H(Xn) =

Pn(xn

j )H(Sn

j ).

(5)

kn(cid:88)

j=1

(cid:32)mn‚àí1(cid:88)

Fig. 1. General structure of a feed-forward deep neural network.

Each layer is constructed by multiple neurons that process the
information in parallel and the output of the jth neuron in
layer n is calculated as follows:

(cid:33)

i=1

wn

xn,j = gn

i,jxn‚àí1,i + bn
j

j (xn‚àí1) = f n

(1)
where mn‚àí1 is the number of neurons in layer n‚àí 1 and wn
i,j
is a weight that connects the output of the ith neuron in layer
n ‚àí 1 to the input of the jth neuron in layer n. Also, bn
j is
the bias of the jth neuron in layer n and f n(¬∑) is the output
function of the neurons in this layer. To illustrate (1) in vector
notation we say:

xn = Gn(xn‚àí1)

(2)
where xn is a combination of neuron outputs in layer n,
i.e. xn = [xn,1,¬∑¬∑¬∑ , xn,mn ]. The total number of possible
output combinations in the nth layer is illustrated by kn which
depends on the output functions and the input space. As an
example, with binary output functions, kn = 2mn. At the nth
layer, Xn = {xn
} is the set of all possible output
combinations. It should be noted that a single neuron has a
very limited processing capability. As a matter of fact, an
individual neuron can only implement a hyper-plane in its
input space and hence, not all the mappings from its input
to its output are feasible. This limitation is one of the main
reasons that neural networks are constructed by multiple layers
of interacting neurons.

1,¬∑¬∑¬∑ , xn

kn

The neural computation that occurs in each layer performs
a mapping between the outputs of the consecutive layers. In
other words, various output combinations in layer n ‚àí 1 are
mapped to certain output combinations in layer n. Depending
on the weights, bias, and the output function in layer n, there
are two possibilities:
‚Ä¢ Each unique combination of neuron outputs in layer n‚àí1
is uniquely mapped to a combination of neuron outputs
in layer n. In other words:

‚àÄx1, x2 ‚àà Xn‚àí1 ‚à¥ Gn(x1) (cid:54)= Gn(x2)

In this case, regardless of the number of neurons in each
layer, we have kn = kn‚àí1.
‚Ä¢ Multiple (at least two) combinations of neuron outputs in
layer n‚àí1 are mapped to a single combination of neuron
outputs in layer n. In other words:

‚àÉx1, x2 ‚àà Xn‚àí1 ‚à¥ Gn(x1) = Gn(x1)

............ùëãùëã1ùëã2‚Ä¶ùëãùúà‚àí1ùëãùúà= ùëåInput SpaceOutput Spacekn‚àí1(cid:88)

i=1

i=1

Ô£±Ô£≤Ô£≥kn‚àí1(cid:88)
Ô£ÆÔ£∞Ô£´Ô£≠(cid:88)
kn(cid:88)
Ô£´Ô£≠(cid:88)

j=1

x‚ààSn

j

x‚ààSn

j

H(Xn) = ‚àí

+

‚àí

j

x‚ààSn

(cid:16)(cid:80)
hand, we have:Ô£´Ô£≠(cid:88)
Ô£´Ô£≠(cid:88)
= ‚àí (cid:88)

x‚ààSn

x‚ààSn

‚àí

j

j

In other words, we started from the entropy of Xn‚àí1 and
substituted the individual
the output combi-
j with their new equivalent term,
nations that belong to Sn
. On the other
i.e.
log

terms of all

Pn‚àí1(x)

Pn‚àí1(x)

(cid:17)

(cid:16)(cid:80)
Ô£∂Ô£∏ log

j

x‚ààSn

Ô£´Ô£≠(cid:88)

x‚ààSn

j

Pn‚àí1(x)

Pn‚àí1(x)

Pn‚àí1(x) log Pn‚àí1(x)

(cid:80)

Pn‚àí1(x) log

x‚ààSn

j

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

x(cid:48)‚ààSn

j

then, considering (6), we can rewrite (7) as follows:

kn(cid:88)

(cid:88)

j

x‚ààSn
Equivalently, we have

+

j=1

kn(cid:88)

Pn‚àí1(x) log

H(Xn) = H(Xn‚àí1)

H(Xn) = H(Xn‚àí1) +

(cid:80)
Ô£´Ô£≠ (cid:88)
Ô£´Ô£≠(cid:88)
(cid:80)
(cid:80)
H(Xn) = H(Xn‚àí1) ‚àí kn(cid:88)

Pn‚àí1(x(cid:48))

Pn‚àí1(x)

x(cid:48)‚ààSn

x(cid:48)‚ààSn

x‚ààSn

log

j=1

Then, based on DeÔ¨Ånition 3 we can say:

j

j

j

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

x(cid:48)‚ààSn

j

(8)

Ô£∂Ô£∏

Pn‚àí1(x(cid:48))

Ô£∂Ô£∏ (9)

Pn‚àí1(x)

Pn‚àí1(x(cid:48))

x(cid:48)‚ààSn

j

The following lemma proves a similar result for the Ô¨Çow of

conditional entropy in a deep neural network.

Lemma 2: In a feed-forward DNN, the conditional entropy
i.e.

of each layer, conditioned on the desired outputs, Y ,
H(Xn|Y ), is a non-increasing function of n and we have:

n = H(Xn‚àí1|Y ) ‚àí H(Xn|Y )
‚àÜ(cid:48)

(cid:88)

kn(cid:88)

y‚ààY

j=1

=

PY (y)Pn(xn

j |Y = y)H(Sn

j |y)

(11)

where

Pn(xn

j |Y = y) =

(cid:88)

x‚ààSn

j

Pn‚àí1(x|Y = y)

and

(7)

j |y) = ‚àí (cid:88)

x‚ààSn

j

H(Sn

Pn‚àí1(x|Y = y)
j |Y = y)
Pn(xn

log

Pn‚àí1(x|Y = y)
j |Y = y)
Pn(xn

.

Proof: The proof of Lemma 2 follows on similar lines as
Lemma 1 by conditioning on the random variable Y and is
therefore omitted.

III. OPTIMAL MAPPING AND INFORMATION BOTTLENECK

Extraction of relevant information from an input data with
respect to a desired output is one of the central issues in super-
vised learning [12]. In information theoretic terms, assuming
that X and Y are the input and output random variables,
I(X; Y ) is the relevant information between X and Y . In
order to improve the efÔ¨Åciency of a machine learning task, we
generally need to extract the minimal sufÔ¨Åcient statistics of X
with respect to Y . Hence, as the Information Bottleneck prin-
ciple [11] indicates, we need to Ô¨Ånd a maximally compressed
representation of X by extracting the relevant information with
respect to Y [8]. In this section, we follow the approach of
[8] to deÔ¨Åne an optimization problem that can be used in the
learning process of a DNN. We also prove an upper bound on
the achievable compression rate of the input in DNNs.
Consider a DNN with ŒΩ layers. Let us assume that ÀÜX =
[X1,¬∑¬∑¬∑ , XŒΩ] denotes the output of these layers. To Ô¨Ånd
the maximally compressed representation of X, we need to
minimize the mutual information between the input, i.e. X,
and the representation of data by the DNN, ÀÜX. This can
be formulated as minimizing the mutual information between
the input and the representation of data in each layer, i.e.
Xi, i = 1,¬∑¬∑¬∑ , ŒΩ which can be modeled as

ŒΩ(cid:88)

min

I(X; Xi).

(12)

Proof: Let us assume that the information has been pro-
cessed up to layer Xn‚àí1. Using DeÔ¨Ånition 2, the entropy of
layer n ‚àí 1 is

H(Xn‚àí1) = ‚àí

Pn‚àí1(xn‚àí1

i

) log Pn‚àí1(xn‚àí1

i

)

(6)

To determine H(Xn), we can say

Pn‚àí1(xn‚àí1

) log Pn‚àí1(xn‚àí1

)

i

Ô£∂Ô£∏ log

Pn‚àí1(x)

Pn‚àí1(x)

Ô£∂Ô£∏

Pn‚àí1(x) log Pn‚àí1(x)

j

i

x‚ààSn

Ô£´Ô£≠(cid:88)
Ô£∂Ô£∏Ô£πÔ£ªÔ£ºÔ£ΩÔ£æ
(cid:17)

Ô£∂Ô£∏

Ô£∂Ô£∏

Pn(xn

j )H(Sn
j )

(10)

i=1

j=1

and n is(cid:80)kn

and from here, we can observe that H(Xn) ‚â§ H(Xn‚àí1).
Furthermore, the difference between the entropy in layers n‚àí1
j ) which is the expected entropy
of the partitions on Xn‚àí1. This proves the lemma.

j=1 Pn(xn

j )H(Sn

To measure the Ô¨Ådelity of the training process of a feed-
forward DNN, we focus on the Logarithmic-loss distortion
function. Let p(y|x) denotes the conditional distribution of Y
given X (i.e., the original input data) and similarly, let p(y|ÀÜx)
denotes the conditional distribution of Y given ÀÜX (i.e., given

the outputs of all the layers). Then, one measure of Ô¨Ådelity is
the KL-divergence between these distributions:
P (y|x)
P (y|ÀÜx)

P (y|x) log

dIB(x, ÀÜx) =

(cid:88)

(13)

y

and taking the expectation of dIB(x, ÀÜx) we get:
DIB = E [dIB(x, ÀÜx)] = I(X; Y | ÀÜX)

(14)

Using the Markov chain properties of the feed-forward net-
work, one can show that
I(X; Y | ÀÜX) = I(X; Y | [X1,¬∑¬∑¬∑ , XŒΩ]) = I(X; Y |XŒΩ) (15)
and hence, the overall distortion of the DNN will be DIB =
I(X; Y |XŒΩ). Therefore, using the Information Bottleneck
principle, the training criteria for a feed-forward DNN can
be formulated as follows

ŒΩ(cid:88)

min
I(X; Xi)
I(X; Y |XŒΩ) ‚â§ 

i=1

s.t.

(16)

As we have mentioned in Section II, in the ith layer, each
input combination is mapped to a speciÔ¨Åc output combination.
Therefore, it can be easily shown that H(Xi|X) = 0 and
hence, I(X; Xi) = H(Xi). Then, using Lemma 1 we have:

I(X; Xi) = H(X) ‚àí i(cid:88)

‚àÜj.

(17)

j=1

Note that in the above equation, H(X) is constant, i.e. it does
not depend on the neural network settings.

Regarding the constraint of (16), it can be shown that

I(X; Y |XŒΩ) = I(X; Y ) ‚àí I(XŒΩ; Y )

(18)
On the other hand, we know that I(XŒΩ; Y ) = H(XŒΩ) ‚àí
H(XŒΩ|Y ) and using Lemma 1 and Lemma 2, we have

(cid:40)

H(XŒΩ) = H(X) ‚àí(cid:80)ŒΩ
H(XŒΩ|Y ) = H(X|Y ) ‚àí(cid:80)ŒΩ

i=1 ‚àÜi

i=1 ‚àÜ(cid:48)

i

which results in the following equation:

I(X; Y |XŒΩ) =

(‚àÜi ‚àí ‚àÜ(cid:48)

i) .

(19)

Using (17) and (19) and by minor manipulation, the opti-

mization problem of (16) can be rewritten as follows:

In the optimization problem of (20), ‚àÜi

is the amount
of entropy reduction in layer i which can be interpreted
as the amount of data compression that has been occurred
at this layer. Moreover, we can observe that the total data
compression (i.e. reduction in entropy) that occurs in DNN is

(cid:80) ‚àÜi and is deÔ¨Åned in the following deÔ¨Ånition:

DeÔ¨Ånition 4: The total compression in a feed forward DNN

with ŒΩ layers is illustrated by CŒΩ and we have:

ŒΩ(cid:88)

i=1

CŒΩ =

‚àÜi

ŒΩ(cid:88)

ŒΩ(cid:88)

i=1

The following lemma shows an upper bound on CŒΩ:
Lemma 3: In a multilayer neural network with input X, out-
put layer XŒΩ, and the desired output Y , the maximum possible
entropy reduction from the input space to the output space that
satisÔ¨Åes the distortion constraint is H(X|Y ) ‚àí H(XŒΩ|Y ).

Proof: From the constraint of (20) we have:

‚àÜ(cid:48)

‚àÜi ‚â§  +
(21)
i = H(Xi‚àí1|Y )‚àíH(Xi|Y ). Hence,

i=1

i

ŒΩ(cid:88)

However, we know that ‚àÜ(cid:48)
we have
i = H(X|Y ) ‚àí H(X1|Y ) + H(X1|Y ) ‚àí H(X2|Y )
‚àÜ(cid:48)
+ H(X2|Y ) ‚àí ¬∑¬∑¬∑ ‚àí H(XŒΩ|Y ) = H(X|Y ) ‚àí H(XŒΩ|Y )

i=1

Therefore, using DeÔ¨Ånition 4 and (21) and when  ‚Üí 0 we
have:

CŒΩ ‚â§ H(X|Y ) ‚àí H(XŒΩ|Y )

(22)

This proves the lemma.

The Ô¨Årst consequence of Lemma 3 is that, regardless of the
number of layers, CŒΩ cannot be greater than H(X|Y ). In fact,
considering Lemma 2, H(Xi|Y ) is a non-increasing function
of i, and hence we have:

CŒΩ ‚â§ H(X|Y )

(23)

However, it should be noted that higher number of layers
may result in a more compressed representation of data. In
other words, based on Lemma 2, for ŒΩ1 > ŒΩ2 we have
H(XŒΩ1|Y ) ‚â• H(XŒΩ2|Y ) and hence, CŒΩ1 ‚â§ CŒΩ2. In the next
section, we indicate that due to the structural limitations of
an artiÔ¨Åcial neuron, not all the mappings determined by (20)
can be implemented using one layer. Therefore, in addition
to have a more compressed representation of information, in
a neural network multiple layers may be required to achieve
feasible mappings from the input space to the output space.

ŒΩ(cid:88)

i=1

ŒΩ‚àí1(cid:88)

(ŒΩ ‚àí i)‚àÜi+1

i=0

(‚àÜi ‚àí ‚àÜ(cid:48)

i) ‚â§ 

max

ŒΩ(cid:88)

i=1

s.t.

This is a convex optimization problem and due to its com-
plexity, it is generally difÔ¨Åcult to Ô¨Ånd an analytic solution for
that. However, numerical solutions (such as algorithms based
on Blahut-Arimoto [13]) may be deployed here to solve (20).

(20)

IV. FEASIBLE OPTIMAL MAPPINGS

While the optimization problem of (20) can be used to Ô¨Ånd
the optimal mappings between consecutive layers of a neural
network, it may result in unfeasible solutions. As a matter of
fact, a single neuron implements a single hyperplane in the
input space and hence, only linearly separable classiÔ¨Åcation

{ ÀúŒò1,n,¬∑¬∑¬∑ , ÀúŒòŒ∫n,n} is the set of forbidden mappings. Then,
the optimization problem of (20) can be modiÔ¨Åed as follows:

(ŒΩ ‚àí n)Œ∏n+1

ij Pn(xn

i ) log

Pn+1(xn+1
j
Pn(xn
i )

)

(cid:18)

Pn‚àí1(xn‚àí1

i

Œ∏n
ijPY (y)

‚àíPn‚àí1(xn‚àí1

i

|Y = y) log

kn(cid:88)
kn+1(cid:88)
ŒΩ‚àí1(cid:88)
kn‚àí1(cid:88)
kn(cid:88)
(cid:88)

n=0

j=1

i=1

max

s.t.

ŒΩ(cid:88)

n=1

y‚ààY

j=1

i=1

kn(cid:88)

j=1

Pn(xn
j )
Pn‚àí1(xn‚àí1

i

) log
j |Y = y)

(cid:19)

Pn(xn

)
‚â§ 

i

Pn‚àí1(xn‚àí1

|Y = y)
i = 1,¬∑¬∑¬∑ , kn‚àí1
i = 1,¬∑¬∑¬∑ , Œ∫n

,

ij = 1 , n = 1,¬∑¬∑¬∑ , ŒΩ
Œ∏n
, n = 1,¬∑¬∑¬∑ , ŒΩ

,

Œòn (cid:54)= ÀúŒòi,n
where the solution to (28) is the set of Œ∏ij‚Äôs. Note that the
last statement is used to exclude the forbidden mappings from
the set of solutions. The optimization problem of (28) Ô¨Ånds
the optimal mappings between any two consecutive layers in a
feed-forward DNN. These mappings can then be implemented
by proper selection of neuron weights.

(28)

V. CASE STUDY: BOOLEAN FUNCTIONS

In this section, we perform a case study to observe how
the proposed optimization problem of (28) may be used to
determine optimal mappings between consecutive layers in
a DNN. For this study, we try to implement basic boolean
functions and show how entropy changes from the input to the
output layer. In this set of experiments we use AND, OR, and
XOR functions with two and three inputs and we assume that
ŒΩ ‚àà {1, 2, 3}. Results are illustrated in Table I. It is clear from
these results that feasible mappings cannot be determined for
two and three input XOR functions when ŒΩ = 1. As we have
mentioned before, this is due to the processing limitations of
a single neuron. However, for AND and OR functions even
one single neuron was able to implement the function. Figure 3
shows an example set of mappings between consecutive layers
for XOR function using a two-layer neural network.
Table I also illustrates the achievable compression rate, i.e.
CŒΩ, and its corresponding upper bound, i.e. H(X|Y ). As we
can observe, in the cases that the function was implementable
using the neural network, CŒΩ is equal to H(X|Y ), which
means that for these functions we have been able to achieve
the minimum representation of data at the output layer. As we
proved in Lemma 3, we observe that the maximum achievable
level of data compression in a feed-forward DNN is H(X|Y ).
Moreover, results indicate that the main reason to add an extra
layer to a DNN is to achieve feasible mappings. However, as
Lemma 3 shows, extra layers may lead to a more compressed
representation of the input data.

VI. CONCLUSION

In this paper, we used information theory methods to study
the Ô¨Çow of information in DNNs. We determined how entropy

(a)

(b)

Fig. 2.
(a) Examples of feasible and unfeasible mappings. Black and white
circles are mapped to outputs ‚Äô1‚Äô and ‚Äô0‚Äô respectively. (b) Unfeasible mappings
resulted from the optimization problem of (20) with a single neuron.

problems may be solved with a single neuron. As an example,
in binary input/output space (i.e. when the inputs and the
output of the neuron are binary), an XOR function cannot
be implemented with a single neuron. Examples of feasible
and unfeasible mappings with a single neuron are illustrated
in Fig. 2(a). In this Ô¨Ågure, black and white circles are mapped
to outputs ‚Äô1‚Äô and ‚Äô0‚Äô, respectively. However, a single neuron
can only divide the space into two parts and hence,
the
top mapping (i.e. boolean OR function) can be implemented
by a single neuron while the bottom mapping (i.e. boolean
XOR function) is not implementable. The unfeasible mappings
which are resulted from the optimization problem of (20) for a
boolean XOR function are illustrated in Fig. 2(b). Therefore,
we need to add more constraints to the above optimization
problems to exclude the unfeasible mappings.

Using (5) and the deÔ¨Ånition of H(Sn

j ) we can show that

kn(cid:88)

(cid:88)
(cid:40)

‚àÜn =

j=1

x‚ààSn

j

Pn‚àí1(x) log

Pn(xn
j )
Pn‚àí1(x)

Let us deÔ¨Åne the following parameter:
‚àà Sn
, xn‚àí1
j
, Otherwise

Œ∏n
ij =

1

0

i

(24)

(25)

j=1 Œ∏ij = 1. Moreover, in vector notations, Œòn is a
ij. Then, (24) can be

kn‚àí1 √ó kn matrix such that Œòn[i, j] = Œ∏n
written as follows

where,(cid:80)kn
kn(cid:88)

‚àÜn =

kn‚àí1(cid:88)

Furthermore, using a similar notation, it can be shown that

Pn(xn
j )
Pn‚àí1(xn‚àí1

i

(26)

)

i

) log

ijPn‚àí1(xn‚àí1
Œ∏n
kn‚àí1(cid:88)
Œ∏ijPY (y)Pn‚àí1(xn‚àí1
j |Y = y)

i=1
Pn(xn

i

j=1

i=1

(cid:88)

kn(cid:88)

j=1

y‚ààY

log

Pn‚àí1(xn‚àí1

i

|Y = y)

‚àÜ(cid:48)
n =

|Y = y)

(27)

As we mentioned before, not all the mappings between
the inputs and outputs of a neuron are feasible. Unfeasible
mappings depend on the structure of the network, number of
neurons in each layer, and the corresponding output functions
in each layer. Let us assume that at the nth layer, ÀúŒòn =

‚Äô00‚Äô‚Äô01‚Äô‚Äô10‚Äô‚Äô11‚Äô‚Äô00‚Äô‚Äô01‚Äô‚Äô10‚Äô‚Äô11‚ÄôFeasibleUnfeasible‚Äô00‚Äô‚Äô01‚Äô‚Äô10‚Äô‚Äô11‚Äôùëãùëã1= ùëå[12] T.G. Dietterich, Structural, Syntactic, and Statistical Pattern Recogni-
tion: Joint IAPR International Workshops SSPR 2002 and SPR 2002
Windsor, Ontario, Canada, August 6‚Äì9, 2002 Proceedings, chapter
Machine Learning for Sequential Data: A Review, pp. 15‚Äì30, Springer
Berlin Heidelberg, Berlin, Heidelberg, 2002.

[13] R.E. Blahut,

‚ÄúComputation of channel capacity and rate-distortion
functions,‚Äù Information Theory, IEEE Trans. on, vol. 18, no. 4, pp.
460‚Äì473, April 1972.

CASE STUDY RESULTS FOR BOOLEAN FUNCTIONS.

TABLE I

Function
(Inputs)
AND (2)
OR (2)‚àó
XOR (2)
AND (2)
XOR (2)
AND (2)
XOR (2)
AND (3)
XOR (3)

ŒΩ

1
1
1
2
2
3
3
1
1

Neurons
per Layer

[1]
[1]
[1]
[2 1]
[2 1]
[2 2 1]
[2 2 1]

[1]
[1]

Solution
Exists?

Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
No

Optimization

Function

1.189
0.888

2.377
1.500
3.566
2.500
2.456

-

-

CŒΩ

H(X|Y )

1.189
0.888

1.189
1.000
1.189
1.000
2.456

-

-

1.189
0.888

1.189
1.000
1.189
1.000
2.456

-

-

(*) Distribution is not uniform: Probability of 00 is 0.7 and others are 0.1.

Fig. 3. An example sequence of mappings for XOR.

and conditional entropy of information changes between con-
secutive layers and using the Information Bottleneck principle
we modeled the learning process of a feed-forward neural
network as a constrained optimization problem. Furthermore,
we proved an upper bound for the total compression rate of
information that can be achieved in a neural network while the
overall distortion in the output layer with respect to a desired
output is in an acceptable range. In this paper, we assumed that
the neural network is used for supervised learning tasks and
the input/output spaces are based on discrete alphabets. For the
future work, we aim to extend our work to a broader range of
learning problems and to include continues input/output spaces
in our model.

REFERENCES

[1] X.W. Chen and X.Lin,

‚ÄúBig data deep learning: Challenges and

perspectives,‚Äù IEEE Access, vol. 2, no. 2, pp. 514‚Äì525, 1991.

[2] Y. Sun, X. Wang, and X. Tang, ‚ÄúDeep learning face representation
from predicting 10,000 classes,‚Äù in Proc. of the CVPR‚Äô14, 2014, pp.
1891‚Äì1898.

[3] I. Lenz, H. Lee, and A. Saxena, ‚ÄúDeep learning for detecting robotic
grasps,‚Äù The International Journal of Robotics Research, vol. 34, no.
4-5, April 2015.

[4] T.M. Mitchell, Machine Learning, McGraw-Hill, 1997.
[5] J. Schmidhuber, ‚ÄúDeep learning in neural networks: An overview,‚Äù Tech.
Rep. IDSIA-03-14, The Swiss AI Lab IDSIA, University of Lugano &
SUPSI, Swiss, 2014.

[6] G. E. Hinton and R. R. Salakhutdinov, ‚ÄúReducing the dimensionality of
data with neural networks,‚Äù Science, vol. 313, no. 5786, pp. 504‚Äì507,
2006.

[7] C. Szegedy, A. Toshev, and D. Erhan, ‚ÄúDeep neural networks for object

detection,‚Äù in Proc. of NIPS‚Äô13, 2013, pp. 2553‚Äì2561.

[9] C. M. Bishop,

‚ÄúTheoretical foundations of neural networks,‚Äù

in

Proceedings of Physics Computing, 1996, pp. 500‚Äì507.

[10] P. Mehta and D. J. Schwab, ‚ÄúAn exact mapping between the Variational
Renormalization Group and Deep Learning,‚Äù ArXiv e-prints, Oct. 2014.
[11] N. Tishby, F. C. Pereira, and W. Bialek, ‚ÄúThe information bottleneck
in Proceedings of 37th Annual Allerton Conference on

method,‚Äù
Communication, Control and Computing, 1999.

[8] N.Tishby and N.Zaslavsky, ‚ÄúDeep learning and the information bottle-

neck principle,‚Äù in Proc. of ITW‚Äô15, 2015.

‚Äô00‚Äô‚Äô01‚Äô‚Äô10‚Äô‚Äô11‚Äôùëãùëã1ùëã2= ùëå