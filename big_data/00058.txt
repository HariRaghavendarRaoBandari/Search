6
1
0
2

 

 

b
e
F
9
2
 
 
]

.

C
N
o
i
b
-
q
[
 
 

1
v
8
5
0
0
0

.

3
0
6
1
:
v
i
X
r
a

Neural and perceptual signatures of eﬃcient sensory coding

Deep Ganguli and Eero P. Simoncelli

Howard Hughes Medical Institute

Center for Neural Science, and

Courant Institute of Mathematical Sciences

New York University
New York, NY 10003

{dganguli,eero}@cns.nyu.edu

The mammalian brain is a metabolically expensive device, and evolutionary pressures
have presumably driven it to make productive use of its resources. For sensory areas,
this concept has been expressed more formally as an optimality principle: the brain
maximizes the information that is encoded about relevant sensory variables, given
available resources 1,2,3. Here, we develop this eﬃciency principle for encoding a sen-
sory variable with a heterogeneous population of noisy neurons, each responding to
a particular range of values. The accuracy with which the population represents any
particular value depends on the number of cells that respond to that value, their selec-
tivity, and their response levels. We derive the optimal solution for these parameters
in closed form, as a function of the probability of stimulus values encountered in the
environment. This optimal neural population also imposes limitations on the ability of
the organism to discriminate diﬀerent values of the encoded variable. As a result, we
predict an explicit relationship between the statistical properties of the environment,
the allocation and selectivity of neurons within populations, and perceptual discrim-
inability. We test this relationship for three visual and two auditory attributes, and
ﬁnd that it is remarkably consistent with existing data.

Neurons in sensory systems are commonly characterized in terms of their selectivity or “tuning” for
particular stimulus variables (e.g., acoustic frequency, or visual orientation). It is generally believed
that for any given variable, populations of cells, each with diﬀerent selectivity, and arranged so as
to cover the full range of stimulus values, form a distributed representation or code for that variable
within the brain. These codes are believed to both enable, and limit, subsequent perception. In
particular, the ability of an observer to discriminate stimuli that diﬀer in terms of these same stim-
ulus variables depends on the number, selectivity, and noise properties of neurons in the underlying
neural population 4.

Nearly all theoretical analyses of neural population codes have used homogeneous populations, in
which the neurons cover the stimulus space with tuning curves that are identical shifted copies of a
common function 5,6,7,8,9. For many sensory variables, however, measurements of neural population
properties suggest that the representation is heterogeneous. Moreover, measured perceptual dis-
crimination thresholds for many sensory variables also exhibit heterogeneity. A common example
arises in the form of Weber’s law, in which discriminability is found to be proportional to stimulus
value. Despite the ubiquity of neural and perceptual heterogeneity, no current theory explains why

1

this should be the case, or how these heterogeneities might be related to each other.

We have recently proposed that these variations could arise when the tuning curves of a neu-
ral population are arranged so as to maximize the information transmitted about stimuli that are
heterogeneous in their frequency of occurrence 10,11. Here, we show that this theory provides remark-
ably accurate predictions of neural and perceptual heterogeneity for a variety of diﬀerent sensory
attributes. Consider a stimulus variable, s, that is to be encoded in the responses of a population of
N noisy neurons. For simplicity, assume that the neuronal response variability is Poisson-distributed
with a rate parameter deﬁned by the tuning curve 5, and that for any stimulus, the responses of the
neurons in the population are uncorrelated. 1 In addition to ﬁxing the number of neurons, we also
restrict the the total spike rate of the population to a maximum value of R, reﬂecting a limitation
on metabolic resources 13,14.

The presence of neural response noise, in concert with the two resource constraints, place limits on
the accuracy with which stimuli can be represented by the population. The literature on population
coding has thoroughly examined this issue in the case of a homogeneous population. If one assumes
that the population covers the stimulus space, with adjacent cells overlapping so as to leave no gaps,
the accuracy with which a decoder can recover the stimulus value from the population response 2
scales inversely with N 2R. Thus, the accuracy of the representation improves when either N or R
are increased.

Suppose the environment is inhomogeneous, in that the frequency of occurrence of a stimulus vari-
able, expressed as a probability distribution, p(s), varies signiﬁcantly over the range of s. Intuitively,
a “good” sensory system would allocate a higher proportion of neurons or spikes (or both) to the
most frequently occurring stimuli, improving the encoding accuracy of those stimuli at the cost of
decreasing the encoding accuracy of infrequently occurring stimuli. Is there a choice that is optimal?
In order to answer this question, we parameterize a nonuniform allocation of neurons using a con-
tinuous function, d(s), that represents the cell density. The heterogeneous population is formed by
using this density function to warp a homogenous population, as depicted in (Fig. 1). An important
feature of this parameterization is that it enforces an inverse relationship between tuning widths
and cell density, and thus preserves the relative overlap between adjacent tuning curves.
If the
homogeneous population is chosen so that the tuning curves cover their stimulus space with modest
overlap, then the warped heterogeneous population will do the same. Similarly, we parameterize a
nonuniform allocation of spikes using a continuous gain function, g(s), which is simply multiplied
by each of the warped tuning curves. Under this local parameterization of resource allocation,
the accuracy of the representation scales inversely with d(s)2g(s), analogous to the homogeneous
case 10.

This parameterization allows us to optimize the population for the transmission of stimulus in-
formation. Speciﬁcally, the average of the log accuracy provides a lower bound on transmitted
information 17, and thus we need to solve the following constrained optimization problem:

argmax

d(s),g(s)Z p(s) log(cid:0)d2(s)g(s)(cid:1) ds,

subject to

Z d(s) ds = N,

and

Z p(s)g(s) ds = R,

1The derivation can be generalized to a class of distributions that include correlations 12 without changing the

form of the result 11.

2Technically, the result is stated in terms of the Fisher information, which provides a bound on the variance of
any unbiased estimator that attempts to recover the stimulus value from the population 15. The Fisher information
also provides a bound on the perceptual discriminability that can be achieved using any estimator, even one that is
biased 16.

2

a

Firing rate

b

c

8

7

6

5

4

3

2

1

t

e
a
r
 
g
n
i
r
i
F

Figure 1: Heterogeneous population parameterization. a, An initial homoge-
neous population containing N cells with shifted copies of a bell-shaped tuning curve,
u(s), arranged such that the cells evenly “tile” the unit lattice: un(s) = u(s − n) such
that PN
n=1 u(s − n) ≈ 1. b, The space is non-uniformly warped so as to achieve a
desired cell density, d(s), which speciﬁes the number of cells per unit stimulus (shown
in inset). The integral of this density function, D(s) = R s
−∞ d(t) dt, provides a warping
function that achieves the desired density, resulting in a set of heterogeneous tuning
curves: hn(s) = u(D(s) − n). The entire population is warped together, ensuring that
the width of each tuning curve is inversely proportional to the cell density, and that
the warped population will also cover the stimulus space: PN
n=1 u(D(s) − n) ≈ 1. c,
The heterogeneous population (with tick marks denoting the preferred stimulus of each
cell, sn = D−1(n)) is multiplied by the gain function, g(s) (blue), which controls the
maximum average ﬁring rate of each cell. A single tuning curve is highlighted (red) to il-
lustrate the eﬀect of the warping and scaling operations. The total resource constraints
(N cells and R total spikes) can be expressed in terms of the cell density function:

N = R d(s) ds, and gain: R = R p(s)g(s) ds.

3

δmin(s) ∝

pd2(s)g(s)

1

1

=

N√Rp(s)

(2)

A closed form solution is readily obtained using calculus of variations:

d(s) = N p(s),

w(s) ∝

1

d(s)

=

1

N p(s)

,

g(s) = R.

(1)

The structure of the optimally eﬃcient population directly reﬂects the statistical properties of the
environment, as speciﬁed by p(s). Speciﬁcally, the cell density is proportional to the stimulus
distribution, ensuring that frequently occurring stimuli are encoded with greater precision, using
a larger number of cells with correspondingly narrower tuning. On the other hand, we see that
the maximal response (gain) of the cells in the optimal population is constant, independent of the
preferred stimulus value. Since we have assumed the tuning widths are inversely proportional to
cell density, and thus to the stimulus distribution, this solution implies that the average response of
each neuron (over stimuli encountered in the world), is identical for all neurons in the population.
Finally, the unknown total resource values {N, R} appear only as multiplicative scale factors in
the expressions for gain and density, and thus the optimal solution provides a unique and testable
predictions for the shapes of both the cell density and tuning width as a function of preferred
stimulus.

Finally, substituting the optimal cell density and gain into the expression for accuracy given above al-
lows us to make a prediction about the minimum discriminination thresholds that could be achieved
based on this population :

The solution predicts that frequently occurring stimuli should be more discriminable (speciﬁcally, in-
verse discrimination thresholds should be proportional to the probability of encountering a stimulus
value). The shape of this solution is again a simple function of the stimulus probability, p(s), scaled
by a multiplicative factor that depends on neural resources and an additional factor that depends
on the experimental conditions under which discrimination thresholds are measured (e.g., criterion
value, stimulus duration, or intensity). As a result, the solution provides a unique prediction of the
shape of perceptual discrimination as a function of stimulus value.

Eﬃcient population coding predicts explicit relationships between sensory statistics, physiological
tuning properties, and perceptual discriminability (Eqs. 1 & 2). We tested these relationships in the
context of two auditory attributes (acoustic frequency and modulation frequency), and three visual
attributes (local orientation, spatial frequency, and retinal speed) (Fig. 2). Each of these attributes
exhibits substantial heterogeneity in their statistical, physiological, and perceptual representations.
Data in the ﬁrst column (Fig. 2a-e) correspond to stimulus distributions for each attribute, as esti-
mated from large databases of photographic images or sounds obtained from natural environments
(see Methods). Physiological data (Fig. 2f-j) are taken from single-cell electrophysiological record-
ings in primate or cat that report the independently measured tuning widths of a large population
of neurons as a function of their preferred stimuli. These measurements were gathered across mul-
tiple animals, and in a diverse set of brain areas (the auditory nerve ﬁbers, the inferior colliculus,
the primary visual cortex, and the middle temporal cortex), each chosen based on a substantial
literature identifying the tuning properties of those neurons for the stimulus feature of interest. For
the case of local orientation, we also analyzed another physiological data set in which tuning widths
are reported (see Appendix). Estimates of the cell density in each area (Fig. 2k-o) are obtained
with a histogram binned over the preferred stimuli. Discrimination thresholds for each sensory
attribute (Fig. 2p-t) were measured in human perceptual experiments. In some cases, data are re-

4

(cid:239)(cid:23)(cid:19)
(cid:239)(cid:25)(cid:19)
(cid:239)(cid:27)(cid:19)

0.1

1

10

f

)
z
H
k
(
 

i

t

h
d
w
d
n
a
B

10

1

0.1

0.1

k

s

l
l

e
C
#

 

200

100

1

10

0

0

1

2

3

Acoustic Freq. (kHz) 

Preferred Stim. (kHz) 

Preferred Stim. (kHz) 

g

)
z
H

(
 

i

t

h
d
w
d
n
a
B

256

64

16

l

s

l
l

e
C
#

 

100

50

0

1

10

100

16

64

256

25

125

225

0

(cid:239)(cid:24)(cid:19)

(cid:239)(cid:20)(cid:19)(cid:19)

0.1

Modulation Freq. (Hz) 

Preferred Stim. (Hz) 

Preferred Stim. (Hz) 

h

)
º
(
 

i

t

h
d
w
d
n
a
B

75

50

25

0

m

s

l
l

e
C
#

 

20

10

0

p

)
z
H

(
 

l

d
o
h
s
e
r
h
T

q

)
z
H

(
 

l

d
o
h
s
e
r
h
T

r

l

)
º
(
 
d
o
h
s
e
r
h
T

100

10

1

0.1

1

10

Acoustic Freq. (kHz) 

4

16

64

256

Modulation Freq. (Hz) 

64

16

4

1

20

10

0

0

45

90

135 180

0

45

90

135 180

0

45

90 135 180

0

45

90

135 180

Orientation (º)

Preferred Stim. (º)

Preferred Stim. (º)

Orientation (º)

a

)

B
d
(
 
r
e
w
o
P

b

)

B
d
(
 
r
e
w
o
P

c

y
t
i
l
i

b
a
b
o
r
P

d

)

B
d
(
 
y
g
r
e
n
E

e

y
t
i
l
i

b
a
b
o
r
P

0.012

0.006

0

0

(cid:239)(cid:20)(cid:24)
(cid:239)(cid:22)(cid:19)
(cid:239)(cid:23)(cid:24)

i

)
d
p
c
(
 

i

t

h
d
w
d
n
a
B

100

10

1

0.1

0.01

0.1

1

10

0.1

1

10

Spatial Freq. (cpd)

Preferred Stim. (cpd) 

1

0.1

0.01

j

 

h

t

i

d
w
d
n
a
B

)
c
e
s
/

g
e
d
(

100

10

1

1

10

100

1

10

100

n

s

l
l

e
C
#

 

o

s

l
l

e
C
#

 

300

150

0

0

40

20

0

0

s

)
d
p
c
(
 

l

d
o
h
s
e
r
h
T

t

 

2

4

6

Preferred Stim. (cpd) 

l

d
o
h
s
e
r
h
T

)
c
e
s
/

g
e
d
(

2

4

8

16

Spatial Freq. (cpd)

6.4

1.6

0.4

0.1

10

1

0.1

25

50

1

10

100

Speed (deg/sec)

Preferred Stim. (deg/sec) 

Preferred Stim. (deg/sec) 

Speed (deg/sec)

5

Figure 2: Tests of theoretical predictions. Comparison of predicted relationship
between environmental distributions, neural population properties, and psychophysical
discrimination thresholds to data. Each row corresponds to a particular sensory at-
tribute: acoustic frequency, modulation frequency, local orientation, spatial frequency,
and speed. a-e, Environmental distributions.
f-j, Tuning widths as a function of
preferred stimulus, for neural populations known to be tuned for each attribute. k-o,
Histograms of the preferred stimulus values for all neurons in each population. p-t, Dis-
crimination thresholds, averaged across multiple human subjects. For each row, the data
in the starred panel was ﬁt with a parametric form or histogram density estimate (thick
black lines, see Methods for ﬁtting details). These curves were transformed according
to Eqs. (1) or (2) to generate predictions for all other panels in the same row. Since the
predictions include an unknown scale factor (which is a function of the resources, N and
R), each curve is rescaled to minimize the squared error of the associated data. Environ-
mental distributions were estimated from ensembles of images or sounds (see Methods
for details): a-b, Distributions of acoustic and modulation frequencies computed from
a compilation of animal vocalizations, background sounds 18,19,20, and recordings made
while walking around a suburban university campus. c-d, Distributions of local orien-
tations and spatial frequencies, respectively, computed from a compilation of three large
databases of images containing both natural and man-made scenes 21,22,23. Physiological
data (tuning widths and cell densities) were estimated from published data sets: f,k,
553 auditory nerve ﬁbers measured in cats 24, adapted from 25. g,l, 262 neurons in the
central nucleus of the inferior colliculus measured in cats 26. h,m, 79 orientation-tuned
V1 simple cells recorded foveally 27 (note: data set does not include tuning widths, so
only the theoretical prediction is shown). i,n, 538 neurons in Macaque primary visual
cortex (V1) 28. j,o, 76 speed-tuned cells in Macaque middle temporal cortex (MT) 29.
Perceptual discrimination thresholds were taken from published data sets: p, Acoustic
frequency data from two diﬀerent studies shown in red 30 and blue 31. q, Modulation
frequency data from two diﬀerent studies shown in red 32 and blue 33. r, Orientation
discrimination data 34. s, Spatial frequency discrimination thresholds measured with
sinusoidal gratings at 10% contrast (red) 35, and 25% contrast (blue) 36 (note that theo-
retical predictions are scaled diﬀerently, to allow for diﬀerences in stimulus conditions).
t, Speed discrimination data from two diﬀerent studies shown in red 37 and blue 38.

6

spikes/neuron:

0.1

1

10

1

0

n
o
i
t
a
m
r
o
f
n
I
 
d
e
z

i
l

a
m
r
o
N

optimal heterogeneous
population

homogeneous population

Acoustic 
Frequency

Modulation 
Frequency

Spatial 

Frequency

Speed

Figure 3: Information transmitted by the physiologically measured neural
populations. Normalized information for data sets in Fig. 2f,g,i,j computed for three
diﬀerent average ﬁring rates, relative to a homogeneous population and an optimal
heterogeneous population (all matched for number of cells and average ﬁring rate). Error
bars denote the 5th and 95th percentiles estimated from 1000 bootstrap re-samplings
of the data.

ported from two perceptual data sets (distinguished by color) obtained under diﬀerent experimental
conditions.

For each attribute, we ﬁnd that the predicted relationships between the environment, physiology,
and perception (Fig. 2, thick black lines) are consistent with the data.
In most cases, we used
the histogram of the environmental data as an estimate of p(s), and then used this to predict the
physiological and perceptual data. Predicted curves for tuning width and perceptual discriminability
are individually re-scaled to best match the corresponding data (since the true scale factors depend
on the unknown values of N and R).
In the case of local image speed (Fig. 2e,j,o,t) for which
environmental data are technically diﬃcult to estimate, we used the theory in reverse, ﬁtting the
perceptual data and using this to generate a prediction for p(s). For all other sensory attributes, we
ﬁnd that predictions of perceptual discrimination data are remarkably accurate. For all attributes,
both physiological predictions are well supported by the data and conﬁrm our assumption that
tuning widths are inversely proportional to cell density. For tuning widths, the predictions account
for (39.6, 69.1, 47.7, 67.4)% of the variance in the data, which corresponds to (95.8, 93.5, 97.1, 98.8)%
of the data variance that is accounted for by the best-ﬁtting power law with two additional free
parameters. Estimates of cell density may not be appropriately represented in the data, as they
are limited by sample size, uncontrolled variables (such as eccentricity for visual neurons) and
potential biases in electrode sampling (see Appendix). Finally, we examined the gain of several
neural populations (see Appendix). We ﬁnd that, although there is signiﬁcant variation in these
values across the population, it exhibits no systematic relationship to the stimulus value.

The neural data exhibit scatter about their predicted values, and we wondered how much this
variability might degrade the transmitted information. To quantify this, we compared the amount of
information transmitted by each observed neural population, to that transmitted by the theoretically
optimal populations (see Methods). We ﬁnd that, relative to a homogeneous population with the
same resources, the observed neural populations encode most of the information that would be
transmitted by the optimal population (Fig. 3). Thus, despite the variability of the physiological
data, we conclude that neural populations are near-optimal in their eﬃciency for transmitting signals
drawn from their associated environmental distributions.

7

The notion that an organism is adapted both physiologically and perceptually to the statistics of
the natural environment is of fundamental importance to evolutionary biology. We have developed
a precise instantiation of this notion, and used it to derive a novel set of predictions relating environ-
mental distributions, the tuning of properties neural populations, and perceptual discriminability.
We showed that, despite the simplicity of the formulation, the resulting predictions are supported
by physiological data from a diverse set of brain areas, as well as human perceptual data.

Perhaps the strongest assumption our formulation is the one embedded in the parameterization: the
tuning curves are obtained by warping a homogeneous population to achieve a desired cell density.
It is this assumption that allows for the closed form solution to the optimization problem - without
it, the solution is under constrained. The assumption is based on the intuitively sensible notion that
the optimal shape and overlap of tuning curves, whatever it is, should be the same regardless of cell
density. Comparison of the measured cell density and tuning widths shows that this assumption
is consistent with the physiological data, although one would like to see conﬁrmation on a single
population, measured in a single animal. Finally, it is worth noting that if one takes the warping
solution seriously as a physiological model (as opposed to merely a useful computational trick),
it makes additional predictions regarding the skewed shapes of tuning curves (e.g., see Fig. 1).
Details of tuning curve shapes are not usually reported in physiological literature, but qualitatively
appropriate asymmetries in tuning curves have been noted in some cases 39 e.g., .

Our results generalize and extend a number of previously published results on eﬃcient sensory cod-
ing. For populations of identical tuning curves, a non-uniform distribution of preferred stimuli was
found to be optimal 17,40. However, these results were not compared directly to physiological data,
and because they assumed uniform tuning widths, cannot account for perceptual discriminability
(Fig. 2p-t). A number of studies have examined coding eﬃciency for single neurons with mono-
tonic response functions, demonstrating that the optimal solution is proportional to the cumulative
stimulus distribution 41,42,43, consistent with some physiological data 41.

As with nearly all previous studies of neural population coding, our results are limited to the de-
scription of single stimulus variables, and generalization to the joint encoding of multiple attributes
is not straightforward. Nevertheless, we ﬁnd that our physiological predictions are consistent with
populations of linear receptive ﬁelds are that are numerically optimized to encode ensembles of
natural images 44,45 or sounds 25. Speciﬁcally, the tuning characteristics of these optimized recep-
tive ﬁelds are consistent with our predictions of cell density and tuning width for the encoding of
orientation, spatial frequency, and acoustic frequency (see Appendix).

Our predictions arise from the principle of coding eﬃciency, which many have argued is a reasonable
objective for early stages of sensory processing, but seems unlikely to explain more specialized later
stages such as those responsible for producing actions 46. But for the cases tested here, when we
examined the predictions of an alternative theoretical proposal − that neural systems are optimized
for discrimination performance 47 - we found that they were far less consistent with the data (see
Appendix). Thus, our results provide additional support to the notion that information provides
the strongest generic criterion for sensory system design.

An additional unexpected, but powerful beneﬁt of our optimal population solution emerges in the
context of decoding, or “readout” of the population. If we take seriously the notion that perception is
a process of inference 48, then later stages of processing must be aware not just of the noise properties
of the representation 12,49, but must also have knowledge of the frequency of occurrence of sensory
attributes in the environment. Although such prior information has been widely used in formulating

8

Bayesian explanations for perceptual phenomena 50, the means by which it is represented within the
brain is currently unknown 51. Our results provide a potential solution, in which prior probabilities
are implicitly embedded in the arrangement and selectivity of tuning curves. The responses of an
eﬃcient population can be decoded in a biologically plausible mechanism that correctly combines
current sensory information with the embedded prior 52. Thus, an eﬃcient coding strategy may oﬀer
unforeseen beneﬁts for explaining later stages of sensory processing.

Methods

Fisher information and resource constraints for a heterogeneous population

The Fisher information, Iu(s), for a uniform population (Fig. 1a) with independent Poisson re-
sponses is:

Iu(s) =

N

Xn=1

u′2(s − n)
u(s − n)

=

N

Xn=1

φ(s − n) = Iu,

where u′(s − n) is the derivative of the nth tuning curve 5. We assume that the uniform tuning
curves, and their Fisher kernels, φ(s − n), evenly “tile” the stimulus space: PN
n=1 u(s − n) = 1, and
PN
n=1 φ(s−n) = Iu. The heterogeneous population is formed by warping the tuning curves according
to the cell density function (Fig. 1b), which preserves these tiling properties: PN
n=1 u(D(s)−n) = 1,
and PN
n=1 φ(D(s) − n) = Iu. Each tuning curve, hn(s), is then scaled by a gain factor, gn, that
controls the maximum average ﬁring rate of the cell: hn(s) = gnu (D(s) − n). We deﬁne a smooth
continuous version of the gain as: g(s) = PN
n=1 gnu (D(s) − n) (Fig. 1c) taking advantage of the
fact that the tuning curves tile. The Fisher information for the heterogeneous population may then
be expressed in terms of the cell density and gain 10 as:

Ih(s) = d2(s)

N

Xn=1

gnφ(D(s) − n) ≈ d2(s)g(s)Iu,

(3)

where we have assumed that PN
straint on the total number of spikes is: R = R p(s)PN
the constraint on the number of neurons is N = D(∞), or N = R d(s) ds.

n=1 gnφ (D(s) − n) ≈ g(s)Iu. For this parameterization, the con-
n=1 gnu(D(s) − n) ds = R p(s)g(s) ds, and

Fisher bound on mutual information

The mutual information between the stimulus and the population response is bounded from below
by the Fisher information 17:

I(~r; s) = H(s) +Z Z p(~r, s) log(cid:18) p(~r|s)p(s)
2 Z p(s) log(cid:18) Iud2(s)g(s)

≥ H(s) +

1

p(~r) (cid:19) ds d~r

(cid:19) ds.

2πe

(4)

(5)

9

We veriﬁed that this bound is tight by numerically computing and comparing the two quantities for
the physiological and environmental conditions reported here. We used estimates of the stimulus
distributions, p(s), and cell densities for each attribute (Fig 2a-o thick black lines). We assumed
an independent Poisson noise model for p(~r|s), witha N set to the sample size of each population,
and varied the total number of spikes per neuron in a metabolically relevant regime: 0.1, 1, and 10
spikes per neuron 53. The stimulus entropy, H(s) = −R p(s) log p(s) ds, and the integral in the

Fisher approximation (Eq. 5) were computed by numerical integration. The multidimensional
integral in Eq. (4) was computed via Monte-Carlo integration with 10, 000 samples from the joint
distribution p(~r, s) 54. We found that the bound was always within 1% of the Monte-Carlo estimate
of the Shannon information. We conclude that our eﬃcient population solution, which optimizes
the Fisher bound, is near-optimal for the Shannon information.

Estimating Environmental Distributions

The environmental distributions for the two auditory attributes (acoustic frequency and modula-
tion frequency) were computed from commercially available compilations of animal vocalizations
(58 min) 18,19, background environmental sounds (113 min) 20, and recordings made while walking
around a suburban university campus (62 min). The campus sounds were recorded with a Sennheiser
omnidirectional microphone (ME62) and a Marantz solid state recorder (PMD670). The distribu-
tions for local orientation and spatial frequency were computed from three publicly available image
databases comprised of a total of 816 natural scenes 21,22,23.

Acoustic Frequency

We used the ensemble power spectral density as an estimate of the probability of acoustic frequencies
occurring in the natural environment. We computed the power spectral density for each sound ﬁle
in the database using Welch’s method 55, with non-overlapping 500 millisecond segments windowed
with a hamming ﬁlter to mitigate boundary eﬀects. The ensemble power spectrum, S(f ), was ﬁt
to all recordings with a modiﬁed power-law 56:

S(f ) =

A
0 + f p .
f p

(6)

The parameters were chosen to minimize squared error to the data (A = 2.4×106, f0 = 1.52×103, p =
2.61).

Modulation Frequency

We used the ensemble modulation power spectral density to estimate the probability of modula-
tion frequencies occurring in the natural environment. Each sound in the auditory database was
decomposed into subbands using a physiologically motived bank of 30 raised cosine ﬁlters 57. The
center frequencies of the ﬁlters were equally spaced on an equivalent rectangular bandwidth (ERBN)
scale, and the ﬁlter bandwidths (as a function of center frequency) were comparable to those of the

10

human ear 58. The temporal envelope of the output of each frequency channel was extracted by
computing the magnitude of the analytic signal. The temporal modulation power spectrum was
computed by averaging the power spectral density of each envelope across all frequency channels.
The modulation spectrum of the envelope of a bandpass ﬁlter output is inevitably low-pass (with
a cutoﬀ determined by the ﬁlter bandwidth). To avoid biasing our measurements of modulation
statistics, we only included frequencies below this ﬁlter cutoﬀ in our average. The ensemble mod-
ulation spectrum was ﬁt to all recordings with a modiﬁed power law, (Eq. 6), with parameters
chosen to minimize squared error to the data (A = 0.06, f0 = 0, p = 0.84).

Local Orientation

We used a Gaussian pyramid 59 to decompose each image in the database into a spatial scale that
matched that of the grating stimuli used in the orientation discrimination experiment (4 cycles/deg)
(Fig. 2r) 34. The horizontal and vertical gradients, centered on each pixel in the resulting image,
were computed with local rotation-invariant 5-tap derivative ﬁlters 60. We computed an orientation
tensor 61, deﬁned as covariance matrix of the gradients pooled across a local region. A pooling size
of 1 degree was chosen to best match the physiological data, which was measured foveally (between
0 − 3 deg retinal eccentricity) (Fig. 2m,h) 27. We computed three quantities from the eigenvector
decomposition of the orientation tensor: the energy (sum of the eigenvalues), orientedness (ratio
of the eigenvalue diﬀerence to the eigenvalue sum), and the dominant orientation (angle of the
eigenvector with the larger eigenvalue). We formed a histogram of the dominant orientations of all
tensors for which the energy exceeded the 68th percentile of all energies in the database, and the
orientedness exceeded 0.8. We veriﬁed that the resulting distribution did not change signiﬁcantly
for modest changes in both thresholds.

Spatial Frequency

We used the radially integrated power spectral density of natural images to estimate the probability
of spatial frequencies occurring in the natural environment. The power spectral density for each im-
age in the database was computed by taking the magnitude of the windowed Fourier Transform of the
image, and integrating the result over orientation. The units of the power spectrum were converted
from cycles per pixel to cycles per degree of visual angle by using the appropriate camera settings for
which each image was captured. The ensemble spectra were ﬁt with a modiﬁed power law (Eq. 6)
with parameters chosen to minimize squared error to the data (A = 0.21, f0 = 0.11, p = 1.14). The
form of the estimated spectrum is approximately 1/f , consistent with previous studies 62,63.

Speed

The psychophysical data were ﬁt with a power law,

δ(s) = asp + b,

with parameters chosen to minimize squared error to the data (a = 0.05, p = 0.93, b = 0.11).
According to the theory (Eq. 2), the predicted environmental distribution for speed is estimated as

11

p(s) ∝ δ(s)−1 (Fig. 2e). This “slow speed prior” is qualitatively consistent with previous estimates
of the distribution of retinal speed 64,65,66.

Estimating normalized information

The normalized mutual information, Inorm(~r; s), is deﬁned as:

Inorm(~r; s) =

Idat(~r; s) − Ihom(~r|s)
Ihet(~r; s) − Ihom(~r; s)

.

Here, Ihom(~r; s) is the information transmitted by the homogeneous population, Ihet(~r; s) is the
information transmitted by the optimal heterogeneous population, and Idat(~r|s) is the informa-
tion transmitted by the observed neural populations. A value of 0 indicates the measured neural
population transmits as much information as a comparable homogeneous population, and a value
of 1 indicates that the measured neural population transmits as much information as the optimal
heterogeneous population. Note that the values can exceed the range [0, 1].

To compute the normalized information for each attribute (Fig. 3), we ﬁrst constructed a homoge-
neous population of equal-width Gaussian tuning curves, evenly spaced across the domain of the
sensory prior. The number of tuning curves, N , was matched to the number of cells observed for
each attribute. We used three diﬀerent values for the average number of spikes, R
N ∈ {0.1, 1, 10}
spikes per neuron. The width of the Gaussian was chosen such that, after warping the homogeneous
population by the optimal density function, the tuning widths of the resulting optimal heteroge-
neous population (measured as the full width at half maximum value) were well-matched to the
predicted tuning widths (Fig. 2f-j, thick black lines). For the physiological datasets, we did not
have access to the empirically measured acoustic or modulation frequency tuning curves. We chose
to model them with Gamma functions, with rate and shape parameters chosen to minimize the
squared error with the values observed in the data (Fig. 2f-g). For spatial frequency and speed, we
used the measured tuning curves, which were ﬁt to the data with a log Gaussian function 39. These
tuning curves exhibited substantial variability in their gains (Fig. A2). To ensure a comparison
of information transmission for identical resources, we scaled the gains of tuning curves in each of
these populations by a single value such that R was the same as in the corresponding homogeneous
and optimal heterogeneous populations.

Given the tuning curves, we estimated the normalized mutual information with Monte Carlo in-
tegration with L = 10, 000 samples. We veriﬁed that this was a suﬃcient number of samples
by repeating the procedure with 100, 000 samples and obtaining similar results. We also veriﬁed
that the precise shape of the tuning curve used to model the physiological data for acoustic and
modulation frequency did not signiﬁcantly inﬂuence the normalized information by comparing the
analysis with Gaussian and raised cosine tuning functions. 95% conﬁdence intervals for the normal-
ized information were obtained with 1, 000 bootstrap estimates of Idat(~r|s). For all attributes and
resource constraints (except for speed, under condition R
N = 0.1), the normalized information was
signiﬁcantly greater than 0 and quite close to 1, indicating that the observed neural populations are
nearly optimal for information transmission despite signiﬁcant heterogeneity in cell density, tuning
width, and (for spatial frequency and speed) gain.

12

Acknowledgements

We thank Tony Movshon and Helena Wang for providing physiological data, Josh McDermott
for providing a database of natural sounds and helpful discussions about auditory coding, and
Jeremy Freeman for helpful comments on the manuscript. This work was funded by an HHMI
investigatorship to EPS.

References

[1] Attneave, F. Some informational aspects of visual perception. Psychological Review 61, 183–

193 (1954).

[2] Barlow, H. Possible principles underlying the transformation of sensory messages. Sensory

Communication 217–234 (1961).

[3] Simoncelli, E. & Olshausen, B. Natural image statistics and neural representation. Annual

Review of Neuroscience 24, 1193–1216 (2001).

[4] Shadlen, M., Britten, K., Newsome, W. & Movshon, J. A computational analysis of the
relationship between neuronal and behavioral responses to visual motion. The Journal of
Neuroscience 16, 1486–1510 (1996).

[5] Seung, H. & Sompolinsky, H. Simple models for reading neuronal population codes. Proceedings

of the National Academy of Sciences 90, 10749–10753 (1993).

[6] Zemel, R., Dayan, P. & Pouget, A. Probabilistic interpretation of population codes. Neural

Computation 10, 403–430 (1998).

[7] Zhang, K. & Sejnowski, T. Neuronal tuning: To sharpen or broaden? Neural Computation

11, 75–84 (1999).

[8] Pouget, A., Deneve, S., Ducom, J. & Latham, P. Narrow versus wide tuning curves: What’s

best for a population code? Neural Computation 11, 85–90 (1999).

[9] Dayan, P. & Abbott, L. Theoretical Neuroscience: Computational and Mathematical Modeling

of Neural Systems (The MIT Press, 2001). Published: Hardcover.

[10] Ganguli, D. & Simoncelli, E. P.

Implicit encoding of prior probabilities in optimal neural
populations.
In Laﬀerty, J., Williams, C. K. I., Shawe-Taylor, J., Zemel, R. & Culotta, A.
(eds.) Adv. Neural Information Processing Systems (NIPS*10), vol. 23, 658–666 (MIT Press,
Cambridge, MA, 2010). Presented at Neural Information Processing Systems 23, Vancouver,
Dec 6-9 2010.

[11] Ganguli, D. & Simoncelli, E. P.

Implicit embedding of prior probabilities in optimally ef-
ﬁcient neural populations. Tech. Rep. 1209.5006, ArXiv e-prints (arXiv.org) (2012). URL
http://arxiv.org/abs/1209.5006.

[12] Ma, W., Beck, J., Latham, P. & Pouget, A. Bayesian inference with probabilistic population

codes. Nature Neuroscience 9, 1432–1438 (2006).

[13] Lennie, P. The cost of cortical computation. Current Biology 13, 493–497 (2003).

13

[14] Laughlin, S. B., de Ruyter van Steveninck, R. & Anderson, J. C. The metabolic cost of

information. Nature neuroscience 1, 36–41 (1998).

[15] Cox, D. & Hinkley, D. Theoretical statistics (London: Chapman and Hall., 1974).

[16] Seriès, P., Stocker, A. & EP, S. Is the homunculus “aware” of sensory adaptation? Neural

Computation 21, 3271–3304 (2009).

[17] Brunel, N. & Nadal, J. Mutual information, ﬁsher information, and population coding. Neural

Computation 10, 1731–1757 (1998).

[18] Storm, J. Great smokey mountains national park: winter and spring. in: The macaulay library

of natural sounds. ithaca, NY: cornell laboratory of ornithology. (1994).

[19] Storm, J. Great smokey mountains national park: summer and fall. in: The macaulay library

of natural sounds. ithaca, NY: cornell laboratory of ornithology. (1994).

[20] Emmons, L., Whitney, B. & Ross, D. Sounds of neotropical rainforrest mammals. in: The

macaulay library of natural sounds. ithaca, NY: cornell laboratory of ornithology. (1997).

[21] van Hateren, J. & van der Schaaf, A. Independent component ﬁlters of natural images compared
with simple cells in primary visual cortex. Proceedings of the Royal Society B: Biological
Sciences 265, 359–366 (1998).

[22] Doi, E., Inui, T., Lee, T., Wachtler, T. & Sejnowski, T. Spatiochromatic receptive ﬁeld prop-
erties derived from information-theoretic analyses of cone mosaic responses to natural scenes.
Neural Comput 15, 397–417 (2003).

[23] Olmos, A. & Kingdom, F. McGill Calibrated Image Database, http://tabby.vision.mcgill.ca

(2004).

[24] Carney, L., McDuﬀy, M. & Shekhter, I. Frequency glides in the impulse responses of auditory-

nerve ﬁbers. The Journal of the Acoustical Society of America 105, 2384 (1999).

[25] Smith, E. & Lewicki, M. Eﬃcient auditory coding. Nature 439, 978–982 (2006).

[26] Rodríguez, F., Chen, C., Read, H. & MA, E. Neural modulation tuning characteristics scale
to eﬃciently encode natural sound statistics. The Journal of Neuroscience 30, 15969 –15980
(2010).

[27] Mansﬁeld, R. Neural basis of orientation perception in primate vision. Science 186, 1133 –1135

(1974).

[28] Cavanaugh, J., Bair, W. & Movshon, J. Nature and interaction of signals from the receptive
ﬁeld center and surround in macaque v1 neurons. Journal of Neurophysiology 88, 2530 –2546
(2002).

[29] Wang, H. & Movshon, J. Properties of pattern and component direction selective cells in area

MTof the macaque. J Neurophysiology (2015).

[30] Moore, B. Frequency diﬀerence limens for short-duration tones. The Journal of the Acoustical

Society of America 54, 610 (1973).

[31] Wier, C. Frequency discrimination as a function of frequency and sensation level. The Journal

of the Acoustical Society of America 61, 178 (1977).

14

[32] Formby, C. Diﬀerential sensitivity to tonal frequency and to the rate of amplitude modulation
of broadband noise by normally hearing listeners. The Journal of the Acoustical Society of
America 78, 70 (1985).

[33] Lemanska, J., Sek, A. & EB, S. Discrimination of the amplitude modulation rate. Archives of

Acoustics 27, 3–21 (2002).

[34] Girshick, A., Landy, M. & Simoncelli, E. Cardinal rules: visual orientation perception reﬂects

knowledge of environmental statistics. Nature Neuroscience 14, 926–932 (2011).

[35] Caeli, T., Brettel, H., Rentschler, I. & Hilz, R. Discrimination thresholds in the two-dimensional

spatial frequency domain. Vision Research 23, 129–133 (1983).

[36] Regan, D., Bartol, S., Beverly, T. & Murray, T. Spatial frequency discrimination in normal

vision and in patients with multiple sclerosis. Brain 105, 735 –754 (1982).

[37] McKee, S. & Nakayama, K. The detection of motion in the peripheral visual ﬁeld. Vision

Research 24, 25–32 (1984).

[38] De Bruyn, B. & Orban, G. Human velocity and direction discrimination measured with random

dot patterns. Vision Research 28, 1323–1335 (1988).

[39] Nover, H., Anderson, C. & DeAngelis, G. A logarithmic, Scale-Invariant representation of
speed in macaque middle temporal area accounts for speed discrimination performance. The
Journal of Neuroscience 25, 10049–10060 (2005).

[40] Harper, N. & McAlpine, D. Optimal neural population coding of an auditory spatial cue.

Nature 430, 682–686 (2004).

[41] Laughlin, S. A simple coding procedure enhances a neuron’s information capacity. Zeitschrift

Für Naturforschung. 36, 910–912 (1981).

[42] Nadal, J. & Parga, N. Non linear neurons in the low noise limit: A factorial code maximizes

information transfer. Network: Computation in Neural Systems (1994).

[43] McDonnell, M. & Stocks, N. Maximally informative stimuli and tuning curves for sigmoidal

rate-coding neurons and populations. Physical Review Letters 101, 58103 (2008).

[44] Olshausen, B. & Field, D. Emergence of simple-cell receptive ﬁeld properties by learning a

sparse code for natural images. Nature 381, 607–609 (1996).

[45] Bell, A. & Sejnowski, T. The "independent components" of natural scenes are edge ﬁlters.

Vision Research 37, 3327–3338 (1997).

[46] Geisler, W., Najemnik, J. & Ing, A. Optimal stimulus encoders for natural tasks. Journal of

Vision 9, 17.1–16 (2009).

[47] von der Twer, T. & MacLeod, D. Optimal nonlinear codes for the perception of natural colours.

Network 12, 395–407 (2001).

[48] Helmholtz, H. Treatise on physiological optics (Thoemmes Press, Bristol, UK, 2000).

[49] Jazayeri, M. & Movshon, J. Optimal representation of sensory information by neural popula-

tions. Nature Neuroscience 9, 690–696 (2006).

[50] Knill, D. & Richards, W. Perception as Bayesian inference (Cambridge University Press,

Cambridge, UK, 1996).

15

[51] Simoncelli, E. Optimal estimation in sensory systems. In Gazzaniga, M. (ed.) The Cognitive

Neurosciences, IV, 525–535 (MIT Press, 2009).

[52] Ganguli, D. & Simoncelli, E. P. Neural implementation of Bayesian inference using eﬃcient
population codes. In Computational and Systems Neuroscience (CoSyNe), II-9 (Salt Lake City,
Utah, 2012).

[53] Lennie, P. The cost of cortical computation. Current Biology 13, 493–497 (2003).

[54] Yarrow, S., Challis, E. & Seriès, P. Fisher and shannon information in ﬁnite neural populations.

Neural Computation 24, 1740–1780 (2012).

[55] Welch, P. The use of fast fourier transform for the estimation of power spectra: A method
based on time averaging over short, modiﬁed periodograms. Audio and Electroacoustics, IEEE
Transactions on 15, 70 – 73 (1967).

[56] Attias, H. & Schreiner, C. Temporal Low-Order statistics of natural sounds. NIPS 9, 27—33

(1997).

[57] McDermott, J. & Simoncelli, E. Sound texture perception via statistics of the auditory periph-

ery: Evidence from sound synthesis. Neuron 71, 926–940 (2011).

[58] Glasberg, B. & Moore, B. Derivation of auditory ﬁlter shapes from notched-noise data. Hearing

Research 47, 103–138 (1990).

[59] Burt, P. & Adelson, E. The laplacian pyramid as a compact image code. Communications,

IEEE Transactions on 31, 532 – 540 (1983).

[60] Farid, H. & Simoncelli, E. Diﬀerentiation of discrete multidimensional signals. Image Process-

ing, IEEE Transactions on 13, 496 –508 (2004).

[61] Granlund, G. & Knutsson, H. Signal Processing for Computer Vision (Kluwer Academic

Publishers, Norwell, Massachusetts, 1995).

[62] Field, D. Relations between the statistics of natural images and the response properties of

cortical cells. Journal of the Optical Society of America A 4, 2379–2394 (1987).

[63] Ruderman, D. & Bialek, W. Statistics of natural images: Scaling in the woods. Physical Review

Letters 73, 814–817 (1994).

[64] Dong, D. & Atick, J. Statistics of natural Time-Varying images. Network: Computation in

Neural Systems 6, 345—358 (1995).

[65] Roth, S. & Black, M. On the spatial statistics of optical ﬂow. International Journal of Computer

Vision 74, 33–50 (2007).

[66] Stocker, A. & Simoncelli, E. Noise characteristics and prior expectations in human visual speed

perception. Nature Neuroscience 9, 578–585 (2006).

[67] Baowang, L., Peterson, M. & Freeman, R. Oblique eﬀect: A neural basis in the visual cortex.

Journal of Neurophysiology 90, 204 –217 (2003).

[68] Appelle, S. Perception and discrimination as a function of stimulus orientation: The "oblique

eﬀect" in man and animals. Psychological Bulletin 78, 266–278 (1972).

16

[69] Rothkopf, C., Weisswange, T. & Triesch, J. Learning independent causes in natural images
explains the spacevariant oblique eﬀect. In Development and Learning, 2009. ICDL 2009. IEEE
8th International Conference on, 1 –6 (2009).

[70] Freeman, J., Brouwer, G., Heeger, D. & Merriam, E. Orientation decoding depends on maps,

not columns. The Journal of Neuroscience 31, 4792–4804 (2011).

[71] Hyvarinen, A. Fast and robust ﬁxed-point algorithms for independent component analysis.

Neural Networks, IEEE Transactions on 10, 626 –634 (1999).

[72] Ganguli, D. & Simoncelli, E. Implicit encoding of prior probabilities in optimal neural popula-
tions. In Laﬀerty, J., Williams, C., Shawe-Taylor, J., Zemel, R. & Culotta, A. (eds.) Advances
in Neural Information Processing Systems (NIPS), vol. 23, 658–666 (Salt Lake City, Utah,
2010).

17

Appendix

Statistical test for cell density estimates

To quantify the accuracy of our prediction for cell density, we compared the cumulative density func-
tion (CDF) of the environmental distribution, and the empirical CDF of the cell density (Fig. A1).
For all attributes, we ﬁnd that the data are much closer to our predictions than a uniform distribu-
tion (Fig. A1, grey lines). As can be seen here (and in the density plots of (Fig. 2k-o)), empirically
measured cell densities deviate systematically from the predictions. This may be attributable to
inherent biases in experimental procedures: In single-cell electrophysiology experiments, the re-
ported cells are typically found and isolated by advancing the electrode while delivering stimuli,
and those stimuli tend to be drawn from the center of some typical parameter range. We quan-
tiﬁed the accuracy of the predictions with a single sample Kolmogorov-Smirnov (KS) test, which
computes the maximal diﬀerence between the empirical and predicted CDFs. For the attribute
of retinal speed, we cannot reject the null hypothesis that the cell population is drawn from the
estimated environmental distribution (p = 0.15, KS test). For acoustic frequency, modulation fre-
quency, and spatial frequency, the cell densities deviated more signiﬁcantly from the corresponding
environmental distributions (p < 0.001 for each attribute, KS test).

a

 

e
v
i
t

l

a
u
m
u
C

y
t
l
i

b
a
b
o
r
p

 

1

0.5

0

0

b

1

0.5

1

2

3

4

0

0

125

250

c

1

0.5

0

0

d

1

0.5

2

4

6

0

0

20

40

60

Acoustic Freq. (kHz) 

Modulation Freq. (Hz) 

Spatial Freq. (cpd)

Speed (deg/sec)

Fig A1. Cumulative cell density comparisons. Cumulative distribution of the
optimally eﬃcient cell density (black line), a homogeneous cell density (grey diagonal
line), and that of the measured physiological population (blue line). Blue shaded regions
denote 95% conﬁdence intervals of the empirical cumulative distributions, obtained from
1, 000 bootstrap samples. a, Acoustic frequency. b, Modulation frequency. c, Spatial
frequency. d, Speed.

Comparison of gain predictions to physiological data

Our framework predicts that the tuning curves of cells in an optimal population should all have
the same maximum ﬁring rate (“gain”). We examined this prediction in the V1 spatial frequency 28,
and MT speed 29 data sets (Fig. A2), as well as an orientation-tuned population recorded in cat
area 17 67 (Fig. A3c). Although we ﬁnd signiﬁcant variability in gain values, it is not systematically
related to the stimulus values (r = 0.065, p = 0.13 for spatial frequency and r = 0.104, p = 0.37 for
speed).

To test for possible nonlinear relationships between the gain, g, and preferred stimuli, µ, we con-
structed null model in which the two quantities are statistically independent: p(µ, g) = p(µ)p(g).
The distribution for p(µ) was ﬁt with an exponential distribution with mean parameter 1.53 cpd for

18

a

b

i

)
c
e
s
/
s
e
k
p
s
(
 
n
a
G

i

150

100

50

0

2

0
Preferred Stim. (cpd) 

4

6

i
i

)
)
c
c
e
e
s
s
/
/
s
s
e
e
k
k
p
p
s
s
(
(
 
 
n
n
a
a
G
G

i
i

150

100

50

0

20

0
Preferred Stim. (deg/sec) 

40

60

Fig A2. Relationship of response maximum (gain) to preferred stimulus
value. Cell gain (measured as the maximum average ﬁring rate of each cell) plotted as
a function of preferred stimulus value. a, Data from 538 cells in Macaque V1 (same data
shown in Fig. 2i,n). b, Data from 76 Macaque MT cells (same data shown in Fig. 2j,o).

spatial frequency and 17.35 deg/sec for speed, chosen to maximize the log likelihood computed over
the data. The distribution for p(g) was also ﬁt with an exponential distribution with maximum like-
lihood parameters of 27.01 spikes/sec for spatial frequency and 29.71 spikes/sec for speed. For each
attribute, we generated samples of preferred stimuli and gain from the ﬁtted null model, matched to
the sample size of the data. We computed the log likelihood for 10, 000 of these simulated data sets,
and then compared the log likelihood of the actual data set to this distribution. For each attribute,
we found that the log likelihood of the data under the independent model was well within the 95%
conﬁdence intervals computed from the distribution of log likelihoods of synthetic data sampled
from the model. Therefore we cannot reject the hypothesis that the gain and preferred stimuli of
the cells are statistically independent.

Another physiological data set for orientation tuning

Visually oriented stimuli are more perceptually discriminable about horizontal and vertical axes than
oblique axes. This “oblique eﬀect” has been conﬁrmed empirically in numerous behavioral studies in
humans and animals published over the past century 68. Our eﬃcient coding framework makes strong
predictions about the magnitude of the oblique eﬀect: orientation discrimination thresholds should
be inversely proportional to the frequency of occurrence of orientations in the natural environment.
We found that this prediction is highly accurate (Fig. 2r). However, it relies on the intermediate
physiological prediction, that more frequently occurring orientations should be coded with more
cells, and that those cells should have narrower tuning. Although we have shown that this holds
for a data set drawn from near-foveal macaque V1 (Fig. 2m), other physiological investigations into
the anisotropy of orientation tuning preferences have yielded mixed results 67.

We analyzed a second data set containing measurements of orientation tuning in simple cells,
recorded from cat area 17 67 (Fig. A3). There are again more cells with narrower tuning for more
frequently occurring orientations. However, the magnitudes of these biases are signiﬁcantly smaller
than those found in the Macaque V1 data (Fig. 2m) and are not well-matched to the predictions
of our theory that come from either the environmental or perceptual data (Fig. A3, thick black
lines). There are several possible reasons for these inconsistencies. First, the measurements are
made in diﬀerent species, and may reﬂect diﬀerences in either the neurophysiology, or perhaps the

19

a

s

l
l

e
C
 
#

700

350

0

b

i

)
º
(
 
h
t
d
w
d
n
a
B

50

25

0

0

45

90

135 180

0

45

90

135 180

c

i

)
c
e
s
/
s
e
k
p
s
(
 
n
a
G

i

15

10

5

0

0

45

90

135 180

Preferred Stim. (º)

Preferred Stim. (º)

Preferred Stim. (º)

Fig A3. Orientation tuning in cat area 17. Orientation tuning preferences of 2, 598
simple cells in cat area 17 67, and predictions derived from the environmental distribution
(black curves). a, Number of cells tuned to each orientation. The distribution shows
clear peaks at horizontal and vertical orientations that are statistically signiﬁcant (p <
0.05, χ2 test). b, Orientation tuning width as a function of preferred orientation. The
cells show a signiﬁcant narrowing of orientation tuning at horizontal orientations, but
not to vertical orientations. c, Mean response amplitude (gain) as a function of preferred
orientation.

corresponding visual environments, of cats and monkeys. Second, the cells in the Macaque data
set had receptive ﬁelds near the fovea. In the same study, it was found that the density of cells
recorded in the periphery was nearly uniform 27. The cells in the cat data set, on the other hand,
had receptive ﬁelds at a wide range of eccentricities, potentially diminishing the magnitude of the
reported heterogeneity in cell density. Finally, there is theoretical and physiological evidence that
orientation tuning biases may also vary as a function of the angular position receptive ﬁelds relative
to the fovea 69,70. A resolution of these discrepancies await a large-scale study that can disentangle
these eﬀects.

Comparison to alternative eﬃcient coding frameworks

We examined the tuning properties of populations of linear receptive ﬁelds that are numerically
optimized to encode ensembles of natural images or sounds, and ﬁnd that they are qualitatively
consistent with our physiological predictions of cell density and tuning width (Fig. A4). Speciﬁcally,
we computed populations of visual receptive ﬁelds using independent components analysis (ICA) 45,
and auditory receptive ﬁelds using sparse coding 44,25. These optimal solutions each arise from
principles that may be interpreted as variants of the eﬃcient coding hypothesis, each using a diﬀerent
objective function and constraints, and making diﬀerent assumptions about input distributions,
neural response properties, and noise. These diﬀerences are further elaborated in the following
paragraphs.

ICA is designed to recover a linear generative model of natural images,

where x is a matrix with each column representing a diﬀerent natural image, A is a matrix of basis

x = As,

(7)

20

a

ICA on natural images

f

Sparse coding on 
natural sounds

b

)
g
e
d
(
 
h
t
d
w
d
n
a
B

i

d

)
d
p
c
(
 

i

t

h
d
w
d
n
a
B

g

)
z
H
k
(
 

i

t

h
d
w
d
n
a
B

120

90

60

30

0

0

90

45

135 180
Preferred Stim. (deg) 

1

2

4

8

Preferred Stim. (cpd) 

16

8

4

2

1

10

1

c

s

l
l

e
C
 
#

e

s

l
l

e
C
#

 

h

s

l
l

e
C
#

 

20

10

0

40

20

45

0
135 180
Preferred Stim. (deg) 

90

0

1

3

5

7

Preferred Stim. (cpd) 

15

10

5

0

0.1

0.1

1

10

0

1

2

3

4

Preferred Stim. (kHz) 

Preferred Stim. (kHz) 

Fig A4. Comparison to ICA and sparse coding. a, Linear receptive ﬁelds, derived
from natural images using independent components analysis (ICA) 45, resemble the re-
ceptive ﬁelds of V1 simple cells. b - e, The tuning characteristics of this population
is consistent with the predictions of our eﬃcient coding solution (thick black lines). b,
Orientation tuning widths computed from the receptive ﬁelds in a. Blue bars show the
mean and standard deviation of the bandwidths in 16.37 degree bins. c, Histogram den-
sity estimate of the preferred orientations of these receptive ﬁelds. d, Spatial frequency
tuning widths computed for these receptive ﬁelds. e, Histogram of preferred spatial
frequencies of these receptive ﬁelds. Low spatial frequencies are underestimated due
to the small patch sizes. f, Linear receptive ﬁelds, derived from natural sounds (red)
using sparse coding 25, resemble the receptive ﬁelds of auditory nerve ﬁbers (blue). g-h,
Tuning characteristics of these receptive ﬁelds are consistent with the predictions of our
eﬃcient coding solution (thick black lines). g, Acoustic frequency tuning widths 25. h,
Histogram density estimate of the preferred acoustic frequencies of the receptive ﬁelds.

21

functions, and s is a matrix of coeﬃcients. The ICA method aims to simultaneously estimate the
basis functions, A, and the coeﬃcients, s = A−1x, such that the coeﬃcients are as statistically
independent as possible. Assuming no neuronal noise, this procedure is equivalent to picking the
neural responses, (often equated to the coeﬃcients s), and linear receptive ﬁelds (often equated to the
columns of A) to maximize the information transmitted about the natural image ensemble. For our
comparison, we ran the Fast ICA algorithm 71 (with the default parameters) on one million 16X16
pixel image patches sampled randomly from the same database of natural images used to compute
the environmental distributions for local orientation and spatial frequency 21,22. The dimensionality
of each patch was reduced by a factor of two using principle components analysis, eﬀectively low-pass
ﬁltering the images, in order to aid convergence. Consistent with previous literature, the optimal
receptive ﬁelds (Fig. A4a) are seen to closely resemble those of simple cells in V1 45,21.

To derive the orientation and spatial frequency tuning properties of these receptive ﬁelds, we ﬁrst
computed the magnitude of the two dimensional Fourier transform of each ﬁlter and found the
orientation and spatial frequency of the maximum amplitude. We estimated the orientation tuning
curve by interpolating the values of the magnitude as a function of angle about this peak value, and
the spatial frequency tuning curve by interpolating the values of the magnitude radially through
the location of the peak magnitude. We found that 98 of the 128 receptive ﬁelds exhibited clear
tuning to both orientation and spatial frequency. For these units, we computed the bandwidths of
the derived tuning curves as the full width at half maximum (Fig. A4b,d). A histogram of the
preferred stimuli was used as an estimate for the local cell density (Fig. A4c,e). For both attributes,
we ﬁnd that the predictions of our framework are qualitatively consistent with the derived tuning
characteristics (Fig. 4b-e, thick black lines).

Sparse coding also assumes a linear generative model of the input (Eq. 7), but attempts to learn
basis functions and coeﬃcients that minimize squared reconstruction error subject to a sparsity
constraint on the coeﬃcients:

arg min

A,s kx − Ask2 + λksk0.

(8)

The ﬁrst term is the mean squared error between the generative model and the inputs, and the
second term is the number of non-zero coeﬃcients (interpreted as the number of active neurons),
which enforces sparsity. The parameter λ controls the tradeoﬀ between sparsity and reconstruction
error.

When the inputs consist of natural sounds, an approximate numerical solution to this objective
function yields receptive ﬁelds that resemble those of auditory nerve ﬁbers 25 (Fig. A4f). The tuning
widths of these ﬁlters, as function of their preferred stimulus values, closely match the predictions
of our eﬃcient coding framework (Fig. A4g). We computed a histogram of the preferred stimuli
as a local estimate of cell density and ﬁnd that it is also qualitatively consistent with our results
(Fig. A4h).

22

Predictions of an alternative optimality principle

We compared our predictions to those that arise from another theory for early sensory systems
− that they are optimized for the discrimination of stimulus values 47. Speciﬁcally, we derived a
solution for a population that minimizes the average squared stimulus discriminability. Using the
Fisher bound on stimulus discriminability 16, we express the average discriminability in terms of cell
density and gain 72, yielding the following optimization problem:

d(s),g(s)Z p(s)d−2(s)g−1(s) ds,

argmax

subject to

Z d(s) ds = N,

and

Z p(s)g(s) ds = R.

As for the case of coding eﬃciency, a closed form solution is readily obtained using calculus of
variations:

d(s) ∝ N p

1

2 (s),

w(s) ∝

1

d(s)

=

1

N p

1

2 (s)

,

g(s) ∝

R

1

2 (s)

p

.

(9)

The structure of this “discrimax” population diﬀers signiﬁcantly from that of the optimally eﬃcient
population. Speciﬁcally, the cell density is proportional to the square root of the stimulus probability,
thus allocating more cells, relative to the eﬃcient coding solution, to less frequently occurring stimuli.
The gain of the cells in the discrimax population is inversely proportional to the square root of the
stimulus distribution. Since we have assumed the tuning widths are inversely proportional to cell
density, and thus to the square root of the stimulus distribution, this solution again implies that
the average response of each neuron (over stimuli encountered in the world), is identical across the
population, as in the eﬃcient coding solution. The unknown total resource values {N, R} again
appear only as multiplicative scale factors in the expressions for gain and density, and thus the
optimal solution provides a unique and testable prediction for the shapes of both the cell density
and tuning width as a function of preferred stimulus. Finally, the optimized population places limits
on discrimination performance as follows:

δmin(s) ∝

1

pd2(s)g(s)

=

1
N√Rp

.

1

4 (s)

(10)

The solution is again a simple function of the stimulus probability, p(s), scaled by a multiplicative
factor that depends on neural resources and an additional factor that depends on the experimental
conditions under which discrimination thresholds are measured. Although this solution predicts
that frequent stimuli should be more discriminable, the form of this dependency diﬀers signiﬁ-
cantly.

We compared these discrimax predictions to those of eﬃcient coding (Fig. A5). For each at-
tribute, we ﬁnd that the predicted relationships between the environment, physiology, and per-
ception for the discrimax hypothesis (Fig. A5, thick green lines) deviate more signiﬁcantly from the
data than those of the eﬃcient coding hypothesis (Fig. A5, thick black lines). For tuning widths,
the discrimax predictions account for (32.0, 55.8, 36.0, 55.0)% of the variance in the data, which is
(7.6, 13.32, 11.7, 12.4)% less than that accounted for by eﬃcient coding. The predicted cell densities
also deviate signiﬁcantly from data (p < 0.001 for all attributes, one sample KS test). Finally,
the new predictions of gain is inconsistent with the data, which lack any systematic relationship
between the preferred stimuli and the gains (Figs. A2 and A3c).

23

−40
−40

−60
−60

−80
−80

0.1
0.1

1
1

10
10
Acoustic Freq. (kHz) 

0

−50

−100

f

t

)
z
H
k
(
 
h
d
w
d
n
a
B

i

g

)
z
H

i

t

(
 
h
d
w
d
n
a
B

10

1

0.1

0.1

1

10

Preferred Stim. (kHz) 

256

64

16

k

s

l
l

e
C
#

 

l

s

l
l

e
C
#

 

200

100

0

0

100

50

0

1

2

3

Preferred Stim. (kHz) 

0.1

1

10

100

16

64

256

25

125

225

Modulation Freq. (Hz) 

Preferred Stim. (Hz) 

Preferred Stim. (Hz) 

h

i

)
º
(
 
h
t
d
w
d
n
a
B

75

50

25

0

m

s

l
l

e
C
 
#

20

10

0

p

)
z
H

l

(
 
d
o
h
s
e
r
h
T

q

)
z
H

l

(
 
d
o
h
s
e
r
h
T

r

l

)
º
(
 
d
o
h
s
e
r
h
T

100

10

1

0.1

1

10

Acoustic Freq. (kHz) 

4

16

64

256

Modulation Freq. (Hz) 

64

16

4

1

20

10

0

a

)

B
d
(
 
r
e
w
o
P

b

)

B
d
(
 
r
e
w
o
P

c

y
t
i
l
i

b
a
b
o
r
P

d

)

B
d
(
 
y
g
r
e
n
E

e

y
t
i
l
i

b
a
b
o
r
P

0.012

0.006

0

0

−15

−30

−45

0

45

90

135 180

0

45

90

135 180

0

45

90 135 180

0

45

90

135 180

Orientation (º)

Preferred Stim. (º)

Preferred Stim. (º)

Orientation (º)

i

)
d
p
c
(
 
h
t
d
w
d
n
a
B

i

j

i

 
h
t
d
w
d
n
a
B

)
c
e
s
/
g
e
d
(

0.1

1

10

Preferred Stim. (cpd) 

100

10

1

0.1

0.01

100

10

1

n

s

l
l

e
C
 
#

o

s

l
l

e
C
 
#

300

150

0

0

40

20

0

0

s

l

)
d
p
c
(
 
d
o
h
s
e
r
h
T

t

2

4

6

Preferred Stim. (cpd) 

l

 
d
o
h
s
e
r
h
T

)
c
e
s
/
g
e
d
(

2

4

8

16

Spatial Freq. (cpd)

6.4

1.6

0.4

0.1

10

1

0.1

25

50

1

10

100

0.1

1

10

Spatial Freq. (cpd)

1

0.1

0.01

1

10

100

1

10

100

Speed (deg/sec)

Preferred Stim. (deg/sec) 

Preferred Stim. (deg/sec) 

Speed (deg/sec)

Fig A5. Comparison to discrimination-optimizing solution. Predicted rela-
tionships between sensory priors, neural population properties (tuning width and cell
density) and psychophysical discrimination thresholds when optimizing coding eﬃciency
(thick black lines) and or average squared discrimination (thick green lines). Each panel
is the same as in Fig. 2, except that the green curves are computed by transforming the
curve in the starred panel using the discrimax solutions of Eqs. (9) or (10). Each curve
is rescaled to minimize the squared error of the associated data.

24

