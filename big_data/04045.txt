A case of a multivariate

Hermite interpolation

Gil Goldman∗

∗ Department of Mathematics, The Weizmann Institute of Science, Re-

hovot 76100, Israel. e-mail: gilgoldm@gmail.com

Abstract

We consider a speciﬁc scheme of Hermite polynomial interpolations. Our samples
are derivatives of various orders kj at ﬁxed points vj along ﬁxed straight lines
through vj in directions uj, under the following assumption: the total number
of sampled derivatives of order k, k = 0, 1, . . . is equal to the dimension of the
space homogeneous polynomials of degree k. We show that the necessary and
suﬃcient condition on vj, uj for this problem to be unisolvent depends only on
the sampling directions uj , but not on the sampling points vj , and it hold for the
generic directions uj .

Next we prove a kind of “Hermite-Remez” inequality for our sampling scheme
extended to larger sampling sets. It bounds the norm of the interpolation polyno-
mial through the norm of the samples, in terms of the geometry of the sampling
set.

6
1
0
2

 
r
a

 

M
3
1
 
 
]

.

A
C
h
t
a
m

[
 
 

1
v
5
4
0
4
0

.

3
0
6
1
:
v
i
X
r
a

1

Introduction

In this paper we study a speciﬁc scheme of Hermite polynomial interpola-
tions. As in many other cases (compare [1, 6, 7, 8]) our samples are derivatives
of various orders kj at ﬁxed points vj along ﬁxed straight lines through vj in
directions uj. It is convenient to assume that for each j exactly one derivative
is sampled, but the points and the directions are allowed to coincide. How-
ever, we make the following additional assumption: as we consider sampling
of polynomials of degree d, the total number of sampled derivatives of order
k, k = 0, 1, . . . , d, is equal to the dimension of the space of homogeneous
polynomials of degree k.

We show that the necessary and suﬃcient conditions on vj, uj for this
Hermite interpolation problem to be well-posed take a rather simple form,
they depend only on the sampling directions uj, but are independent of the
sampling points vj.

Our second result is an “Hermite-Remez” (see [11]) inequality for the
sampling scheme considered (extended to larger sampling sets). It bounds
the norm of the interpolation polynomial through the norm of the samples,
in terms of the geometry of the sampling set.

Our results are motivated by the following two basic questions:

1. For a prescribed type of Hermite interpolation problem ﬁnd the conditions
for its unisolvency, that is, the conditions by which there exists a unique so-
lution. This problem is central in Approximation Theory (see [2, 10, 12] and
references therein). It was traditionally considered, from a somewhat diﬀer-
ent point of view, also in Algebraic geometry (see [1, 5, 6, 7] and references
therein). In particular, one of central open problems in this direction is the
general dimensionality problem. Consider the following multivariate Hermite
interpolation problem.

Problem 1.1 (Hermite Interpolation). Let {v1, .., vr} ⊂ Rn be a set of
points and let {m1, .., mr} be a set of non negative integers such that Pr
(cid:0)mk−1+n
n). For each k = 1, .., r, let {ψα,k}|α|<mk be a given set of
real values. Find P ∈ P d

(cid:1) = dim(P d

k=1

n

n that satisﬁes

DαP (vk) = ψα,k,

|α| < mk,

k = 1, .., r.

(1.1)

Above and forth we use the standard multi-index notation. For α =
(α1, .., αn), α ∈ {N∪ 0}, we deﬁne: Absolute value, |α| = α1 + .. + αn; Power,

1

for u ∈ Rn, uα = uα1
Dα = ∂|α|

∂xα =

∂|α|
α1
1 ..∂xαn
n

∂x

1

· .. · uαn
. We also deﬁne D0P (v) = P (v).

n ; Partial derivative, for x = (x1, . . . , xn) ∈ Rn,

Let A be the left hand side matrix form of the above system, then A is

given by

Ai,α = vα
i ,

i = 1, .., r,

|α| ≤ d.

Since the determinate of A is polynomial in the points v1, .., vn, A is either sin-
gular for every set of points or it is regular for almost all sets. Consequently
we say that an interpolation problem is unisolvent given that the points are
in general position if it is uniquely solved for almost all sets of points. The
general dimensionality problem asks, for which n, d, r, m1, . . . , mr, this prob-
lem is unisolvent on P d
n, assuming that the points vj are in general position?
In particular, this is not the case for n = d = r = 2 and m1, m2 = 1. Indeed,
here the number of sampled parameters is 6 which is the dimension of the
space of quadratic polynomials. However, for any two points v1, v2 ∈ R2 let
ax + by + c = 0 be the equation of the straight line through v1.v2. Then
P (x, y) = (ax + by + c)2 is a nonzero polynomial of degree 2, vanishing to-
gether with its ﬁrst order derivatives both at v1 and at v2. See [5] for a
stimulating discussion of this problem.

Many speciﬁc Hermite interpolation schemes were shown to be unisolvent
under a generic choice of the points and directions ([1, 6, 7, 8]).
In our
scheme unisolvency is achieved for any choice of the points, if the directions
are generic.
2. The second question is to provide explicit estimates of the robustness of
a certain polynomial interpolation (or reconstruction) scheme. This leads to
“Remez-type” (or “Norming”) inequalities (see [11] and references therein).
Our second main result is an “Hermite-Remez” inequality for our interpola-
tion scheme.

2 The problem and its unisolvency

Let us give now an accurate setting of the problem. Denote by P d
of polynomials of degree at most d on Rn and by Ld
homogeneous polynomials of degree d on Rn. The dimension of P d
(cid:0)d+n
n (cid:1), that is, the number of distinct monomials in n-variables of degree at
n−1 (cid:1). We deﬁne Nn,d = dim (Ld
most d, and the dimension of Ld
n is a direct sum of L0
n, hence dim(P d
Note that P d

n the space
n the space of
n is thus

n is (cid:0)d+n−1
n, . . . ,Ld

n ⊂ P d

k=0 Nn,k.

n).

n) =Pd

2

Let P ∈ P d
uP (v) the k-th derivative dkP (v+tu)

n. For a point v and a direction u in Rn, we denote by
Dk
|t=0 of P at v along the straight line in
the direction u. With a slight abuse of this notation, we will also deﬁne
D0

uP (v) = P (v).

dtk

let Zk = {(vk,j, uk,j)}, j = 1,
Problem 2.1. For each k = 0, 1, . . . , d:
. . . , Nn,k, be a given set of pairs of a point vk,j ∈ Rn and a direction vector
uk,j ∈ Rn. For each k = 0, 1, . . . , d: let Ψk = {ψk,j} ⊂ R, j = 1, . . . , Nn,k, be
a given set of real values. We seek a polynomial P ∈ P d

n which satisﬁes

Dk

uk,j

P (vk,j) = ψk,j,

j = 1, .., Nn,k,

k = 0, .., d.

(2.1)

Problem 2.1 is called unisolvent on P d

n, given Z0, . . . , Zd, if it has a unique

solution P ∈ P d

n, for all Ψk = {ψk,j} ⊂ R, j = 1, . . . , Nn,k, k = 0, . . . , d.

Here is our ﬁrst main result:

Theorem 2.1. For any sample points vk,j, and for general directions uk,j,
Problem 2.1 is unisolvent. Moreover, sets of directions that do not deﬁne a
unique solution are exactly those for which there exists at least one 1 ≤ k ≤ d
such that the directions uk,1, .., uk,Nn,k are roots of some non zero, n-variate
homogeneous polynomial of degree k.

Note that Theorem 2.1 is independent of the conﬁguration of the points.

Proving Theorem 2.1, we now consider the following intermediate prob-

lem.
Problem 2.2. Let the sets ˜Z = {sj} ⊂ Rn, j = 1, . . . , Nn,k, and Ψ = {ψj} ⊂
R, j = 1, . . . , Nn,k be given. We seek for P ∈ Lk

n that satisﬁes

P (sj) = ψj,

j = 1, . . . , Nn,k.

(2.2)

n for each Ψ.

n given ˜Z, if it has a unique solution

Problem 2.2 is called unisolvent on Lk
P ∈ Lk
For ˜Z = {sj} ⊂ Rn, j = 1, . . . , Nn,k, consider the following multidimen-
sional homogeneous Vandermonde matrix An,k( ˜Z), [An,k( ˜Z)]i,j = sαj
, i, j =
1, . . . , Nn,k, where the multi-indices α,|α| = k, are ordered lexicographically.
An,k( ˜Z) is the matrix associated with Problem 2.2, written in the mono-
mial basis. Consequently Problem 2.2 is unisolvent on ˜Z if and only if the
determinant of An,k( ˜Z) is nonzero. Since this determinant is homogeneous

i

3

in coordinates of each of the vectors si, this property depends only on the
directions of the vectors si, but not on their length.

Let us return to Problem 2.1. For a set Zk = {(vk,j, uk,j)}, j = 1, . . . , Nn,k,
of pairs of a point vk,j and a direction uk,j in Rn, denote by ˜Zk = (uk,1,
. . . , uk,Nn,d) ⊂ Rn, the set of the corresponding directions uk,j.
Proposition 2.1. Problem 2.1 is unisolvent on P d
n given Z0, . . . , Zd, if and
n given ˜Zk, for each k = 1, . . . , d.
only if, Problem 2.2 is unisolvent on Lk
Equivalently, the determinant of An,k( ˜Zk) is nonzero for each k = 1, . . . , d. In
particular, the unisolvency of Problem 2.1 is determined only by the directions
of the vectors uk,j, and is invariant with respect to their length, and with
respect to the position of the points vk,j.

n, and for each k =

Proof. For each polynomial P = P|α|≤d aαxα ∈ P d
0, 1, . . . , d, denote by Pk = P|α|=k aαxα the k-th homogeneous component
of P , and put ˜Pk =Pd
u in Rn we denote by Dk
the straight line in the direction u.
Lemma 2.1. For P, Pk, ˜Pk as above, for each v, u ∈ Rn, and for each k =
1, . . . , d, we have

l=k Pl. Let us recall that for a point v and a direction
uP (v) the k-th derivative dkP (v+tu)
|t=0 of P at v along

dtk

Dk

uPl(v) = 0, l < k, Dk

uP (v) = Dk

u

˜Pk(v), Dk

uPk(v) = k!Pk(u).

(2.3)

Proof. The ﬁrst equality is immediate, and the second follows directly from
the ﬁrst. The third one is Euler’s identity for homogeneous polynomials. It
follows directly from the fact that for P (x) being the monomial xα, |α| = k,
the highest k-th degree term in P (v + tu) is uα · tk.

Assume now that Problem 2.2 is unisolvent on Lk

n given ˜Zk, for each
k = 1, . . . , d. Consider the part of the interpolation equations (2.1) for
Problem 2.1 with the highest order derivatives:

Dd

ud,j

P (vd,j) = ψd,j,

j = 1, .., Nn,d.

(2.4)

By Lemma 2.1 these equations are reduced to Pd(ud,j) = 1
d! ψd,j, j = 1, .., Nn,d.
This is an instance of Problem 2.2, and by our assumption this system is
unisolvent. Hence, the highest homogeneous component Pd of a solution P ,

4

is uniquely determined by (2.4). Next we consider ˆPd = P − Pd. This is a
polynomial of degree d− 1, and it satisﬁes the corrected system of equations
(2.1), which for the derivatives of order d − 1 takes the form:

Dd−1

ud−1,j

P (vd−1,j) = ψd−1,j − Dd−1

ud−1,j

Pd(vd−1,j),

j = 1, .., Nn,d−1.

As above, from this system we ﬁnd the unique homogeneous component
Pd−1 of P . Continuing in this way till the degree one and then recovering
k=1 Pk(v0,1), we have

the constant term of P by setting P0(v0,1) = ψ0,1 −Pd

uniquely reconstructed P .

In the opposite direction, assume that given Problem 2.1 with the sets
Z1, . . . , Zd, some of the associated Problems 2.2 are not unisolvent. Fix the
smallest index l ≤ d for which this happens. Then, we can ﬁnd a nonzero
homogeneous polynomial Pl such that

Dl

ul,j

Pl(vl,j) = 0,

j = 1, .., Nn,l.

Now we construct the right hand side in Problem 2.1 for which it has a
nonzero solutions. Start with the solution P = Pl and put

ψk,j := Dk

uk,j

Pl(vk,j),

j = 1, .., Nn,k,

k = 0, .., d.

By the construction, ψk,j = 0, k ≥ l. However, ψk,j may be nonzero for
k = 0, 1, . . . , l − 1. We consider now Problem 2.1 on the sets Z0, Z1, . . . , Zl−1
for P l−1
n , that is, for polynomials of degree l − 1. Since by construction
Problem 2.2 is unisolvent on each of the sets ˜Z0, ˜Z1, . . . , ˜Zl−1, we conclude,
by the already proved part of Proposition 2.1, that Problem 2.1 is unisolvent
for P l−1
on Z0, Z1, . . . , Zl−1. So we can ﬁnd (uniquely) a polynomial P ′ of
degree l − 1, such that

n

Dk

ukj

P ′(vk,j) = ψk,j,

j = 1, .., Nn,k,

k = 0, .., l − 1.

Therefore, P = Pl − P ′ is a nonzero polynomial such that

Dk

ukj

P (vk,j) = 0,

j = 1, .., Nn,k,

k = 0, .., d.

We conclude that Problem 2.1 on Z0, Z1, . . . , Zd is not unisolvent. This
completes the proof of Proposition 2.1.

We now prove Theorem 2.1.

5

Proof. By Proposition 2.1, the unisolvency of Problem 2.1 on P d
n given the
sets Z0, Z1, . . . , Zd, is equivalent to the unisolvency of Problem 2.2 on Lk
n
given the set ˜Zk = (uk,1, . . . , uk,Nn,k), for each k = 1, . . . , d.
In turn, for
n given ˜Zk = (uk,1, . . . , uk,Nn,k), is the
each k = 1, . . . , d, Problem 2.2 on Lk
standard Lagrange interpolation on Lk
n which is unisolvent exactly when
(uk,1, . . . , uk,Nn,k) ⊂ Rn are not the roots of some P ∈ Lk
n.
Theorem 2.2. In the planar case, for n = 2, Problem 2.1 is unisolvent if
and only if for each k = 1, . . . , d, the directions of the vectors uk,j are pairwise
linearly independent.

Proof. In the planar case, for each k, the homogeneous Vandermonde deter-
minants of the matrix A2,k( ˜Zk) takes the following particularly convenient
form (see appendix for derivation of this fact):

det(cid:16)A2,k( ˜Zk)(cid:17) = Y1≤i<j≤k+1

det[uk,i, uk,j],

where det[uk,i, uk,j] denotes the determinant of the two by two matrix having

uk,i and uk,j as its rows. It follows that det(cid:16)A2,k( ˜Zk)(cid:17) is non zero is equivalent

to the directions of kth Homogeneous Problem being pairwise independent.
Finally, by Proposition 2.1, the unisolvence of the homogeneous problems is
equivalent to the unisolvence of Problem 2.1.

3 Hermite-Remez inequality for Problem 2.1

3.1 Norming inequalities

The classical Remez inequality and its generalizations compare maxima of a
polynomial P on two sets U ⊂ G (see [3, 4, 11, 14] and references therein).
We would like to extend this setting, in order to include into sampling in-
formation on U the derivatives of P . Such an extension is provided by a
wider (and also classical) setting of “norming sets” and “norming inequali-
ties”. Let G ⊂ Rn be a compact domain, and let L ⊂ P d
n be a normed linear
subspace of the space of polynomials of degree d, equipped with the norm
||P||G = max G|P|. Let L∗ denote the dual space of all the linear functionals
on L.

6

Deﬁnition 3.1. Let U ⊂ L∗ be a bounded set of linear functionals on L. A
semi-norm ||P||U on L is deﬁned as

||P||U = sup

u∈U |u(P )|.

(3.1)

The set U is said to be L-norming if the semi-norm ||P||U is in fact a norm on
L, that is, if for P ∈ L we have that if ||P||U = 0 then P = 0. Equivalently,
U is L-norming if

NL(G, U) := supP ∈L,P 6=0||P||G

||P||U ≤ ∞.

NL(G, U) is called the L-norming constant of U on G.

(3.2)

The usual Remez-type inequalities are included in the new setting by iden-
tifying x ∈ U ⊂ G with the linear functional δx of sampling at x.

3.2 Robust polynomial reconstruction

To illustrate the role of the norming constant in estimating the robustness
of polynomial reconstruction, let us consider the following reconstruction
scheme: our goal is to ﬁnd the best polynomial approximation of a given
In other words, the “ideal approx-
function f on G in the norm || · ||G.
imation” is a polynomial ¯P = arg min P ∈P d
n||f − P||G. Let us denote the
error ||f − ¯P|| of this ideal approximation by E. Now, let us assume that
our input consists of noisy measurements of f on a subset U ⊂ G (this set-
ting can be easily extended to the measurements being more general linear
functionals). So we start with a function ˜f = f + ν on U, where ν is the
measurement error function, satisfying max |ν(x)| ≤ h. As an output we take
n|| ˜f − P||U . The following result shows that the output error
ˆP = arg min P ∈P d
|| ˆP − ¯P||G can be bounded in terms of the norming constant N = NP d
n(G, U),
E and h.

Proposition 3.1.

|| ˆP − ¯P||G ≤ 2N(E + h).

Proof. We have || ˜f − ¯P||U ≤ E + h. Indeed, by the construction of ¯P we get
|| ˜f − ¯P||U ≤ ||f − ¯P||U +||ν||U ≤ E + h. Now, for ˆP = arg min P ∈P d
n|| ˜f − P||U
the norm || ˜f− ˆP||U cannot be larger than for ¯P , and hence || ˜f− ˆP||U ≤ E +h.
We conclude that || ¯P − ˆP||U ≤ 2(E + h), and hence || ¯P − ˆP||G ≤ 2N(E +
h).

7

3.3 Norming inequality for extended Problem 2.1

n ⊂ P d

l=k Pl ∈ P d,k
n .

n the subspace of all the polynomials P of the form

n we denote ˜Pk =Pd

Let us recall (and extend) notations introduced in the proof of Theorem 2.1.
n, and for each k = 0, 1, . . . , d, we

For each polynomial P =P|α|≤d aαxα ∈ P d
have denoted by Pk = P|α|=k aαxα the k-th homogeneous component of P .
We will denote by P d,k
P =Pk≤|α|≤d aαxα. Finally, for P ∈ P d
Returning to Problem 2.1, we now extend its setting, allowing larger sets
Zk. So now Zk ⊂ Rn × Rn may be any bounded set of couples (v, u) of the
points and of the direction vectors.
For any linear subspace L ⊂ P d
n the sets Zk can be considered as subsets
¯Zk ⊂ L∗, if we identify the couple (v, u) ∈ Zk with the linear functional Dk
u,v
u,v(P ) = Dk
on L deﬁned by Dk
uP (v). For the sampling sets Z0, . . . , Zd, we
¯Zk ⊂ L∗, and Uk = ∪d
deﬁne U = U(Z0, . . . , Zd) = ∪d
k=0
On the other hand, extending the notations used in Theorem 2.1, we
denote by ˜Zk = {u : ∃v, (v, u) ∈ Zk} ⊂ Rn the set of the directions u that
n the set ˜Zk can be
appear in Zk. As above, for any linear subspace L ⊂ P d
considered as a subset ˜Zk ⊂ L∗, via identifying u ∈ ˜Zk with the δ-function
δu ∈ L∗.
To simplify the presentation we ﬁx G to be equal to the unit ball B =
Bn
1 ⊂ Rn, and assume that for each k = 0, . . . , d, the sets Zk satisfy Zk ⊂
B × B, that is, both the sampling points v and the directions u belong to
the unit ball B.

¯Zl ⊂ L∗.

l=k

Theorem 3.1. For each k = 0, . . . , d, set Lk = Lk
n to be the subspace of
homogeneous polynomials of degree k. Let each of the directions sets ˜Zk ⊂ L∗
k on B, with the norming constant θk = NLk(B, ˜Zk). Then
be norming for L∗
U = U(Z0, . . . , Zd) is norming for P d
n(B, U)
satisfying

n, with the norming constant NP d

n ⊂ P d

k

NP d

n(B, U) ≤

d

Xl=k

θl
l! ·

l−1

Yj=k

(1 + mj ·

θj
j!

),

where ml = m(n, d, l) = T (l)
mial, and T (k)

d (x) is its k-th derivative.

d (√n). Here Td(x) is the d-th Chebychev polyno-

Proof. Let us denote by κk the norming constant NLk (B, ¯Zk). Then for each
k = 0, . . . , d, we have

8

κk =

θk
k!

(3.3)

Indeed, by Lemma 2.1, the sets of linear functionals on Lk, ˜Zk and ¯Zk satisfy
¯Zk = k! ˜Zk.

Next we prove by induction (starting from k = d and going down) the

following result:
Lemma 3.1. For each k = 0, . . . , d, the set Uk is norming for P d,k
The norming constant ηk = NP d,k

(B, Uk) satisﬁes

n

n

ηd = κd,
ηk ≤ κk + (1 + mk · κk)ηk+1,

k < d.

on B.

(3.4)

Proof. For k = d our problem is reduced to Problem 2 on the space Ld =
n ⊂ P d
Ld
n of homogeneous polynomials of degree d. By assumptions, and
by (3.3), we have NLd(B, Ud) = NLd(B, ¯Zd) = κd = θd
d! > 0. Consequently
Lemma 3.1 holds for the case k = d. Assume that (3.4) is satisﬁed for
k = l + 1 ≤ d and prove it for k = l. Let P ∈ P d,l
satisfy |u(P )| ≤ 1 for
each u ∈ Ul. In particular, this is true for u ∈ Ul+1. Since for u ∈ Ul+1 we
have u(P ) = u( ˜Pl+1), we have that for u ∈ Ul+1 the condition |u( ˜Pl+1)| ≤ 1
is satisﬁed. By the induction assumption, and by deﬁnition of the norming
constant we conclude that

n

|| ˜Pl+1||B ≤ ηl+1.

(3.5)
Now, for the homogeneous component Pl of P we have Pl = P − ˜Pl+1,
and thus for u ∈ ¯Zl, |u(Pl)| = |u(P − ˜Pl+1)| ≤ 1 + |u( ˜Pl+1)|. To estimate
the values u( ˜Pl+1), which are the directional derivatives of order l of ˜Pl+1, we
apply the classical Markov inequality, in the form presented in [9, 13]:
Theorem 3.2. For P ∈ P d

n, and for any direction vector u ∈ Rn, ||u|| ≤ 1,
||Dk

uP||B ≤ mk||P||B,

where mk = T (k)

d (√n).

Applying this result to ˜Pl+1 we conclude, using (3.5) that for u ∈ ˜Zl the
bound |u( ˜Pl+1)| ≤ ml · ηl+1 holds. Therefore, for u ∈ ¯Zl we get |u(Pl)| ≤
1 + ml · ηl+1.

9

By the assumptions of the theorem the set ˜Zl is norming for Ll, with
the norming constant NLl(B, ˜Zk) = θl. Therefore, by (3.3), the set ¯Zl is
also norming for Ll, with the norming constant κl = NLl(B, ¯Zk) = θl
k! . We
conclude that

Finally, since ˜Pl = Pl + ˜Pl+1, we obtain

||Pl||B ≤ κl(1 + ml · ηl+1).

||P||B ≤ || ˜Pl+1||B + ||Pl||B ≤ ηl+1 + κl(1 + ml · ηl+1).
n , and hence

This inequality is true for each polynomial P ∈ P d,l

ηl ≤ ηl+1 + κl(1 + ml · ηl+1) = κl + (1 + ml · κl)ηl+1.

This completes the proof of Lemma 3.1.

To complete the proof of Theorem 3.1 it remains to solve explicitly the

recurrence inequality (3.4).

Lemma 3.2. Let τk, k = 0, . . . , d, satisfy recurrence relation

τk = κk + (1 + mk · κk)τk+1,

τd = κd.

(3.6)

Then for each k = 0, . . . , d, we have

ηk ≤ τk =

d

Xl=k

l−1

κl ·

Yj=k
(1 + mj · κj).

(3.7)

Here the empty product (for l = k) is assumed to be equal to one.

Proof. First we prove by induction the expression for τk. For k = d we have
τd = κd, which is the right hand side of (3.7). Now, for k < d, using induction
assumption, we have

d

l−1

τk = κk + (1 + mk · κk)τk+1 = κk + (1 + mk · κk)

κl ·

(1 + mj · κj)

Yj=k+1

(1 + mj · κj).

Xl=k+1
Yj=k

l−1

= κk +

d

Xl=k+1

l−1

κl ·

Yj=k
(1 + mj · κj) =

d

Xl=k

10

κl ·

Now we compare recurrence inequality (3.4) and recurrence relation (3.6).
All the coeﬃcients are positive, as well as the common starting value: τd =
ηd = κd. Therefore, by the Cauchy majorization argument, we conclude that
for each k = 0, . . . , d we have ηk ≤ τk. This completes the proof of Lemma
3.2.

To complete the proof of Theorem 3.1 it remains to substitute into (3.7)

the values κk = θk
k! .

3.3.1 Hermite-Remez inequality

The classical Remez inequality of [11] bounds the maximum of a univariate
polynomial P on the interval [−1, 1] through its maximum on a subset Z ⊂
[−1, 1] of a positive measure. This theorem was extended to several variables
in [3], and then further generalized in [14], where the Lebesgue measure
µn(Z) was replaced by a certain quantity ωn,d(Z), expressed through the
metric entropy of Z:

Theorem 3.3. ([14], Theorem 2.3.)
polynomial P ∈ P d

n

If ωn,d(Z) = ω > 0, then for each

sup

x∈B |P (x)| ≤ Td  1 + (1 − ω)
1 − (1 − ω)

1
n

n! sup

1

x∈Z |P (x)|.

For any measurable Z we have ωn,d(Z) ≥ µn(Z), and ωn,d(Z) may be
positive for discrete and ﬁnite Z. We will not give here an accurate deﬁnition
of ωn,d(Z), referring the reader to [14]. Replacing in Theorem 3.3 ωd,n(Z)
with a smaller value µn(Z) we obtain the result of [3], and putting n = 1 we
get back the classical Remez inequality.

Theorem 3.1 reduces estimation of the norming constant in our setting
of Hermite interpolation to the norming constants θk of the direction sets
˜Zk ⊂ Rn, in the spaces of homogeneous polynomials of degree k.
In this
situation the Remez-type inequality of Theorem 3.1 is applicable. We obtain
the following bound:

Corollary 3.1. Assume that for each k = 0, . . . , d we have ωk = ωn,k( ˜Zk) >

0. Then we can put in Theorem 3.1 the values θk = Td(cid:18) 1+(1−ωk)

1−(1−ωk)

11

1

1
n

n(cid:19) .

Appendix A. Homogeneous Vandermonde determinant

Proposition A.1. Let (u0, . . . , ud) ⊂ R2 and deﬁne the matrix Ad = Ad(u0,
. . . , ud) as

Then,

Ad(i, j) = ud−j

i,1 uj

i,2,

det(Ad) = Y0≤i<j≤d

i, j = 0, .., d.

det[ui, uj],

where det[ui, uj] denotes the determinant of the two by two matrix having ui
and uj as its rows.

Proof by induction on d. For d = 1,

|A1(u0, u1)| =(cid:12)(cid:12)(cid:12)(cid:12)

u01 u02

u11 u12(cid:12)(cid:12)(cid:12)(cid:12)

= det[u0, u1].

Inductive step: we assume the claim for d−1 and prove it for d. We note that
if u0 = 0 then the claim holds with both sides being zero. Then, without loss
of generality, we can assume that u01 6= 0. We perform the following column
operations leaving the determinant unchanged. For j = d down to 0, set:

˜Ad(:, j) = Ad(:, j) +

)j−kAd(:, k),

j−1

Xk=0(cid:18)j

k(cid:19)(−u02

u01

where Ad(:, j) denotes the jth column of Ad. We get that for 0 ≤ i ≤ d and
0 < j ≤ d:

˜Ad(i, j) =ud−j

i,1 uj

)j−kud−k

i,1 uk
i,2

k(cid:19)(−u02

u01

)j−kud−k

i,1 uk
i,2

=

j

Xk=0(cid:18)j

=ud−j
i,1

j−1

i,2 +

Xk=0(cid:18)j
k(cid:19)(−u02
Xk=0(cid:18)j

k(cid:19)(−u02

u01

j

u01
u02
u01

=ud−j

i,1 (ui,2 − ui,1(

))j.

)j−kuj−k

i,1 uk
i,2

We note that for j > 0:

˜Ad(0, j) = ud−j

0,1 (u0,2 − u0,1(

u02
u01

))j = 0

12

and that for i > 0, j > 0:

˜Ad(i, j) = ud−j

i,1 (ui,2 − ui,1(

01 det[u0, ui](ui,2 − ui,1(
Consequently, for 0 < j ≤ d, we can extract the common factor u−1
from the jth column. Or, in a more presentable form,

))j = ud−j

i,1 u−1

u02
u01

u02
u01

))j−1.

01 det[u0, ui]

det(Ad) = det( ˜Ad) = u−d
01 (

d

Yi=1

..

det[u0, ui])·

0

0

0

01

ud
11 ud−1
ud
..
d1 ud−1
ud

0
1,1 ud−2
..
d,1 ud−2

1,1 (u1,2−u1,1( u02
d,1 (ud,2−ud,1( u02

u01

..

u01

)) .. u1,1(u1,2−u1,1( u02
u01
)) .. ud,1(ud,2−ud,1( u02
u01

..

..

))d−2 (u1,2−u1,1( u02
u01
))d−2 (ud,2−ud,1( u02
u01

..

Developing the determinant by the ﬁrst row cancels out u−d

01 and we get:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

(cid:12)(cid:12)(cid:12)(cid:12)

.

))d−1

))d−1(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

.

))d−1

))d−1(cid:12)(cid:12)(cid:12)(cid:12)

det(Ad) = (

det[u0, ui])·

d

Yi=1

1,1 ud−2
ud−1
..
ud−1
d,1 ud−2

1,1 (u1,2−u1,1( u02
d,1 (ud,2−ud,1( u02

u01

..

u01

)) .. u1,1(u1,2−u1,1( u02
u01
)) .. ud,1(ud,2−ud,1( u02
u01

..

..

))d−2 (u1,2−u1,1( u02
u01
))d−2 (ud,2−ud,1( u02
u01

..

But the above matrix is Ad−1(˜u1, .., ˜un), where ˜ui = (ui1, ui,2 − ui,1( u02
therefore

u01

)),

d

det(Ad) = |Ad−1(˜u1, .., ˜un)|

By the induction hypothesis we have that:

det[u0, ui].

(1.8)

Yi=1

|Ad−1(˜u1, .., ˜un)| = Y1≤i<j≤d

det[ ˜ui, ˜uj].

(1.9)

Looking at one term of this product we get

det[ ˜ui, ˜uj] =(cid:12)(cid:12)(cid:12)(cid:12)

ui1
ui2 − ui1

u02
u01

uj1
uj2 − uj1

u02

u01(cid:12)(cid:12)(cid:12)(cid:12)

Combining (1.10),(1.9) and (1.8) concludes the proof.

= det[ui, uj].

(1.10)

13

References

[1] J. Alexander, A. Hirschovitz, Interpolation on Jets, J. of Algebra 192,

1997, 412-417.

[2] L. Bos, J.-P. Calvi, Multipoint Taylor interpolation, Calcolo 45, no. 1,

2008, 3551.

[3] Yu. Brudnyi and M. Ganzburg, On an extremal problem for polynomials

of n variables, Math. USSR Izv, 37, 1973, 344–355.

[4] A. Brudnyi, Y. Yomdin, Norming sets, to appear, arXiv:1312.6050, 2013.

[5] C. Ciliberto, Geometric aspects of polynomial interpolation in more vari-
ables and of Waring’s problem, In European Congress of Mathematics,
pages 289-316, Springer, 2001.

[6] C. Ciliberto, R. Miranda, Interpolation on Curvilinear Schemes, J. of

Algebra 203, 1998, 677-678.

[7] A. Eastwood, Interpolation `a N Variables, J. of Algebra 139, 1991, 273-

310.

[8] M. Gasca, J. I. Maeztu, On Lagrange and Hermite Interpolation in Rk,

Numer. Math. 39, 1982, 1-14.

[9] L. A. Harris. Multivariate Markov polynomial inequalities and Cheby-

shev nodes, J. Math. Anal. and Appl., 338 (1), 2008, 350-357.

[10] R. A. Lorentz, Multivariate Hermite interpolation by algebraic polyno-
mials: a survey, J. Comp. Appl. Mathematics, 122 (1), 2000, 167-201.

[11] E. J. Remez, Sur une propriete des polynomes de Tchebycheﬀ, Comm.

Inst. Sci. Kharkov, 13, 193), 93–95.

[12] T. Sauer, Y. Xu, On multivariate Hermite interpolation, Advances in

Computational Mathematics, 4 (1), 1995, 207-259.

[13] V. I. Skalyga, Bounds for the derivatives of polynomials on centrally
symmetric convex bodies, Izvestiya: Mathematics, 69 (3), 2005, 607-
621.

14

[14] Y. Yomdin, Remez-type inequality for discrete sets, Israel J. of Mathe-

matics, 186 (1), 2011, 45-60.

15

