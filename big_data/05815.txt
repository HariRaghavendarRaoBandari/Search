Minkowski’s question mark measure

Giorgio Mantica

Center for Non-linear and Complex Systems,
Dipartimento di Scienza ed Alta Tecnologia,
Universit`a dell’ Insubria, 22100 Como, Italy

and

CNISM unit`a di Como, INFN sezione di Milano,

Istituto Nazionale di Alta Matematica,

Gruppo Nazionale per la Fisica Matematica.

6
1
0
2

 
r
a

 

M
8
1
 
 
]

.

A
C
h
t
a
m

[
 
 

1
v
5
1
8
5
0

.

3
0
6
1
:
v
i
X
r
a

Abstract

Minkowski’s question mark function is the distribution function of a singular continuous
measure: we study this measure from the point of view of logarithmic potential theory and
orthogonal polynomials. We conjecture that it is regular, in the sense of Ullman–Stahl–Totik
and moreover it belongs to a Nevai class: we provide numerical evidence of the validity of
these conjectures. In addition, we study the zeros of its orthogonal polynomials and the as-
sociated Christoﬀel functions, for which asymptotic formulae are derived. Rigorous results
and numerical techniques are based upon Iterated Function Systems composed of M¨obius
maps.

Keywords: Minkowski’s question mark function; Orthogonal polynomials, Jacobi matrices;
Regular Measures; M¨obius Iterated Function Systems; Nevai class; Gaussian integration;
Christoﬀel functions.
MATH Subj. Class. 42C05; 47B36; 11A55; 11B57; 37D40

1

Introduction: Minkowski’s Q function and its singular
measure

1.1 Deﬁnitions and goals of the paper

Minkowski’s question–mark function Q(x) can be concisely deﬁned—though not in the the most
transparent way—by writing the point x ∈ [0, 1] in its continued fraction representation, x =
[n1, n2, . . . , ], by setting Nj(x) =Pj
l=1 nl, and by deﬁning Q(x) as the sum of the series [15, 45]

∞

(1)

Q(x) =

(−1)j+12−Nj(x)+1.

Xj=1

This function was originally constructed to map the rationals to the solutions of quadratic equa-
tions with rational coeﬃcients in a continuous, order preserving way [39], but it successively
appeared that it has much wider implications in many ﬁelds of mathematics. A graph of Q(x)
is part of Figures 9 and 11 below. It is remarkable that this graph can be seen as the attractor
of an Iterated Function System (IFS) composed of M¨obius maps [12], so that Q(x) also belongs
to the family of fractal interpolation functions [10, 11].

In this paper we are interested in the singular-continuous measure µ for which Q(x) is the

distribution function:

Q(x) =Z x

0

dµ.

1

(2)

For short, in this paper we will call this measure the Minkowski’s measure and we will reserve the
symbol µ to denote it. It has been investigated in relation to singularity [15], H¨older continuity
[45], the so–called thermodynamical formalism [26, 30, 31, 32], the asymptotic behavior of its
moments [2, 3] and of its Fourier transform [29, 41, 45, 56, 57], so that many of its properties
have been fully clariﬁed.

To the contrary, the characterization of this measure from the point of view of orthogonal
polynomials and logarithmic potential theory [44, 48] is still an open problem. This problem
is the object of a recent publication by Dresse and Van Assche [16]; by using a more powerful
technique, which describes Minkowski’s measure as the balanced measure of an IFS (to be deﬁned
below), we are in the position to correct their ﬁndings and to provide theoretical arguments
and compelling numerical evidence in favor of the precise characterization of µ in terms of two
principal conjectures:

Conjecture 1 Minkowski’s measure µ is regular in the sense of Ullman-Stahl-Totik.

Conjecture 2 Minkowski’s measure µ belongs to the Nevai class N ( 1

4 , 1

2 ).

Let us brieﬂy deﬁne the terms of these conjectures. They are linked to diﬀerent asymp-
totic behaviors of the orthogonal polynomials {pj(µ; x)}j∈N of Minkowski’s measure µ. Quite
generally, given a positive Borel measure µ supported on a compact subset E of the real axis,
orthogonal polynomials are deﬁned by the relation R pj(µ; x)pm(µ; x)dµ(x) = δjm, where δjm is

the Kronecker delta. They satisfy the three-terms recurrence relation

xpj (µ; x) = aj+1pj+1(µ; x) + bjpj(µ; x) + ajpj−1(µ; x),

(3)

initialized by a0 = 0 and p−1(µ; s) = 0, p0(µ; s) = 1, that can be encoded in the Jacobi matrix
J(µ):

.

(4)

J(µ) :=


b0
a1

a1
b1
. . .

a2
. . .

. . .




For compact support E the moment problem is determined [1] and the matrix J(µ) is in one–
to–one relation with the measure µ. At times, it is also important to consider monic orthogonal
polynomials, Pj(µ; x), normalized so that Pj(µ; x) = xj + qj−1(x), in which qj−1 is a polynomial
of degree j − 1. Of course, the two diﬀer by a constant factor: pj = γjPj and from eq. (3) it
easily follows that 1/γj =Qj
A well established theory, started by the classical works of Geronimus and Szeg¨o [23, 49],
classiﬁes diﬀerent asymptotic behaviors of these polynomials, which can be summarized as follows,
in the case of a measure whose support is [0, 1]:

l=1 al.

Root asymptotics: For z not in [0, 1], when the degree j tends to inﬁnity, pj(µ; z)1/j tends

to φ(z) = 2z − 1 + 2√z2 − z, the function that maps [0, 1] to the unit circle in the complex plane;
equivalently, γ−1/j

j → Cap([0, 1]) = 1
4 .

Ratio asymptotics: For z not in [0, 1], when the degree j tends to inﬁnity, pj+1(µ; z)/pj(µ; z)

Power asymptotics: For z not in [0, 1], when the degree j tends to inﬁnity, pj(µ; z)/φ(z)j

tends to φ(z); equivalently, aj = γj−1/γj → 1
4 , bj → 0.
tends to a function g(z); equivalently, γj/4j → γ > 0.
Convergence in the above is understood to be uniform for z in compact sets in the complement
of [0, 1] in the complex plane. Observe from the start that Minkowski’s singular continuous
measure µ can not fulﬁll power asymptotics, for otherwise it would belong to Szeg¨o class, i.e.
it would be absolutely continuous, with a density satisfying the well known Szeg¨o condition.
Therefore, if validated, Conjectures 1 (which is equivalent to root asymptotics) and 2 (equivalent
to ratio asymptotics) would grant the strongest possible regularity to which µ can aspire, in the
above hierarchy.

It is remarkable that these asymptotics have a simple, equivalent deﬁnition in terms of the
Jacobi matrix of µ. Therefore, the ﬁrst goal of this paper is its precise computation—for which
we will employ an algorithm that we have introduced in [35]—and the numerical veriﬁcation of
the above conjectures.

2

The second main goal of the paper, linked to the ﬁrst, is the investigation of three sequences
of discrete measures that are related to µ and of their limits. In this paper, convergence in the
space M([0, 1]) of regular Borel probability measures on [0, 1] will always be understood in weak
star sense, weakly for short, even when not speciﬁed: a sequence µj converges to µ if and only
if the integrals of any continuous function f with respect to µj tend to the integral of f with
respect to µ. The measures under investigation are supported on the zeros of the orthogonal
polynomials of µ. We will use the notation ζj

l to denote these zeros:

pj(µ; ζj

l ) = 0, l = 1, . . . , j.

(5)

These measures are: the so–called measure of the zeros, the measure underlying Gaussian inte-
gration, the measure linked to root asymptotics. Let us brieﬂy review their deﬁnition and main
properties.

The measure of zeros νj is obtained by placing atomic measures of equal weight at the zeros

of the orthogonal polynomials:

νj =

1
j

j

Xl=1

.

δζ j

l

(6)

Here and in the following, δx is the unit mass atomic measure supported at x. The measure νj is
termed the density of states in the physical literature. It can be used to deﬁne a further regularity
property. Suppose that E, the support of µ, has positive capacity and that νj converges weakly to
the equilibrium measure νE on this support [44] when the polynomial degree j tends to inﬁnity.
Then, the orthogonal polynomials of µ are said to have regular asymptotic zero distribution:
this is deﬁnition 3.1.3 of [48], that is a reference also for the following result. Observe that the
support of Minkowski’s measure is the interval E = [0, 1], which has empty interior (as a set in
the complex plane) and positive capacity. In such a case, regularity of the zero distribution is
equivalent to regularity of the measure µ (Theorem 3.1.4 [48]), which is also equivalent to root
asymptotics (Theorems 3.1.1 and 3.2.1 [48]).

The measure underlying Gaussian integration µj is obtained replacing the equal weights in
l (that we shall also call Gaussian weights and

eq. (6) with the so–called Christoﬀel numbers wj
are deﬁned in eq. (37) below):

j

µj =

wj

l δζ j

l

.

(7)

Xl=1

At diﬀerence with νj, the sequence µj always converge: it is well known that integrals of poly-
nomials up to degree 2j − 1 with respect to µ and µj coincide, so that µj tends to µ weakly.
The measure linked to root asymptotics σj is the third type of measure that we will study in
the paper. It is deﬁned via yet another choice of the weights placed at the location of the zeros:

σj =

j

Xl=1

wj
l p2

j−1(µ; ζj

l )δζ j

l

.

(8)

Weak star convergence of the sequence σj is equivalent to the fact that µ belongs to the Nevai class
of measures N (a, b) [53]. Measures in this class are those for which diagonal and out-diagonal
Jacobi matrix entries tend to a limit as j tends to inﬁnity:

lim
j→∞

(aj, bj) = (a, b).

(9)

In our case, because of symmetry, bj = 1/2 for all values of j. In turn, Nevai class is related, as
seen above, to ratio asymptotics.

Clearly, since the Nevai class is a subset of that of regular measures, proving that Minkowski’s
measure µ belongs to this class also implies that it is regular, so that we could have focused only
on this last problem. Nonetheless, we will describe both conjectures separately and in order of
diﬃculty, because much is to be learned in each step.

3

1.2 Organization of the paper and summary of results

The peculiarities of the Minskowski measure are best revealed when seeing it as a balanced
measure of a M¨obius Iterated Function System. In the next section we review two IFS, composed
of M¨obius maps, that can be associated to Minkowski’s question mark function [12, 35] and we
brieﬂy comment on their relations with the theory of dynamical systems. We show how they
can be used to construct diﬀerent sequences of probability measures that converge weakly to
Minkowski’s measure µ.

In Section 3 the previous theory is translated into two algorithms for the computation of the
Jacobi matrix J(µ). The ﬁrst is based upon the Jacobi matrix of a ﬁnite sum of atomic measures,
which approximates µ. We show that it is largely ineﬃcient, when applied to the present case.
This also explains the lack of convergence observed in Section 2 of [16]. The second is the
technique proposed in [35]: in two subsections we test it for speed of convergence and precision.
These tests are mandatory, since the numerical results of this paper rely on the computed entries
of the Jacobi matrix J(µ). We justify experimentally the claim that this algorithm, when run in
double precision Fortran on a standard desktop computer, can provide Jacobi matrices of rank
of about 60,000 with a controlled error.

The main part of the paper presents the investigation of the conjectures mentioned before,
as well as further conjectures and ﬁner details of Minkowski’s measure and of its orthogonal
polynomials. We start in Section 4 by analyzing the regularity of the measure µ, i.e. Conjecture
1, via convergence of the sequence γ−1/j
4 . We observe that this convergence holds
and is of power–law type: there exist two positive constants A and B so that |γ−1/j
4| ∼ Aj−B.
The capital letters A and B will indicate throughout the paper diﬀerent pairs of constants that
appear in power-law behaviors.

to the value 1

j

j

− 1

Next, we study the regular asymptotic distribution of the zeros, as deﬁned above. In Section

5 we provide numerical evidence of a stronger property, expressed by
Conjecture 3: The zeros of Minkowski’s polynomials converge uniformly to the zeros of the
Chebyshev polynomials of the same order, as j tends to inﬁnity.
In Section 6 regularity of the distribution of the zeros is established via the analysis of the so–
called discrepancy [4, 5, 6] between the equilibrium measure νE and the sequence of measures νj.
Our ﬁndings are summarized in
Conjecture 4: As j tends to inﬁnity, the discrepancy D(νE, νj) tends to zero and convergence
is power–law.

In the central Section 7 we examine the measure of Gaussian integration µj in eq. (7). This
detailed analysis best reveals the characteristic features of Minkowski’s measure µ. Together
with Gaussian nodes (i.e. the zeros of the orthogonal polynomials) that have been studied in the
previous sections, we here investigate Christoﬀel numbers. They can be numerically computed
in diﬀerent ways [19, 20], the most common being the Golub–Welsh algorithm [24]. To the
contrary, this latter fails in the case of Minkowski’s measure, but in its stead we proﬁtably use a
formula due to Shohat [47] (see eq. (37) below) based on the reproducing kernel of the orthogonal
polynomials.

The reason behind the failure of Golub–Welsh in this case is a distinctive feature of Minkowski’s
measure µ: the presence of extremely small Christoﬀel numbers even at moderate polynomial
orders j—that become of the order of 10−1000 for j ≃ 60, 000. We describe a reliable technique
for the computation of the atoms composing the measure µj, which can be appropriately dubbed
mathematical neutrinos, for their elusive mass. The technique is inspired by a common practice
in the calculation of Lyapunov exponents.

The theoretical analysis of Gaussian weights–Christoﬀel functions is carried out to a large
detail in Sections 7.2 and 7.3, Propositions 1 and 2, which can be brieﬂy and informally summa-
rized as follows:
Proposition 1: For suﬃciently large j, the logarithm of the average amplitude of weights wj
l ,
when ζj
q , is bounded between two explicit functions
reported in eq. (53).
Proposition 2: The logarithm of the Christoﬀel functions λj (x) has an asymptotic singular
behavior of the kind log(λj (x)) ∼ − log(2)/(q2|x − 1
q|) − log(j), for x in the neighborhood of 1
q .

l is in the neighborhood of the rational point 1

4

These results are a consequence of regularity of the measure µ and of the non–analytic behavior
of Q at rational values, described in Lemma 4. The theory presented in Section 7 contains much
more information, which is discussed at length with the aid of detailed ﬁgures and ﬁts with the
hierarchical structure of the so-called Farey tree, deﬁned in Remark 1. We perform the analysis
around the Farey points 1
q , q integer, but the techniques employed in Lemma 4 permit to treat
the case of any rational point.

4 , 1

Finally, in Section 8, we try to assess whether Minkowski’s question mark measure belongs to
the Nevai class N ( 1
2 ). We do this in two ways. The ﬁrst is the direct veriﬁcation of convergence
of Jacobi matrix elements. Our data reveal that the out–diagonal entries tend to the limit value
one quarter at a slow pace, which nonetheless seems to be power–law. This yields a stronger
version of Conjecture 2:
Conjecture 5: Convergence of the Jacobi matrix elements of Minkowski’s measure is power–law:
there exist two positive constants A, B such that |aj − 1
In the process, we also show that the computed matrix elements are consistent with the theoretical
result that stronger regularity properties, such as Szeg¨o asymptotics, do not hold. The second
method is via the analysis of the measures σj deﬁned above in eq. (8), which are associated
with ratio asymptotics: by showing numerically that the Hutchinson distance between σj and
the expected limit measure σE vanishes when j tends to inﬁnity we provide further evidence in
favor of enlisting µ in the Nevai class:
Conjecture 6: Convergence of the sequence of measures σj to σE is power–law: there exist two
positive constants A, B such that the Hutchinson distance veriﬁes d(σj , σE) < Aj−B.

4| < Aj−B.

In the Conclusion we brieﬂy comment on the relevance of these results and on possible ex-

tensions of this analysis.

2 M¨obius Iterated Function Systems

Minkowski’s question mark function also appears in dynamical systems: it makes the conjugation
of the two dynamical systems generated by the tent and Farey maps on the unit interval [43, 14,
13]. But a second aspect is more important for the present work.

In 1988 Gutzwiller and Mandelbrot [26] studied coding functions for the motion of billiards
in hyperbolic space [46]. Because of the negative curvature of these spaces, these trajectories are
highly unstable and indeed they provide a principal model of chaotic system [7]. Gutzwiller’s
motivation was to ﬁnd a purely abstract analogue of the coding function of the anisotropic Kepler
problem [27], another strongly chaotic system. By its very nature, a coding function encodes
in its value the inﬁnite symbolic history of a trajectory. Without entering in the details of
the deﬁnition of this function, it is enough to remark that, in the case of a particular triangular
billiard, the Gutzwiller–Mandelbrot coding function can be re-written in the form (1) and hence it
coincides with Minkowski’s Q function. By employing the symmetry properties of such hyperbolic
billiards, we were able to show that this function—as well as the coding functions of more general
hyperbolic billiards and also of the anisotropic Kepler system—can be described by Iterated
Function Systems composed of M¨obius maps [12].

Recall that a hyperbolic IFS [28, 9, 8] is a collection of contractive maps Φi : X → X,
i = 1, . . . , M , on a compact metric space X. For these systems, there exists a unique compact
set A, called the attractor of the IFS, that solves the equation
Φi(A) := Φ(A).

(10)

A = [i=1,...,M

The ﬁrst IFS associated with Minkowski’s function Q acts on the unit square, X = [0, 1]2,
and has the graph of Q as attractor. This IFS can be constructed as follows. Let the maps Mi
and Pi, i = 1, 2 be deﬁned as

and let us write

M1(x) = x
M2(x) = 1

1+x , P1(y) = y
2 ,
2−x , P2(y) = y+1
2

Φi(x, y) = (Mi(x), Pi(y)), i = 1, 2.

5

(11)

(12)

Then, the following results hold [12]:
Theorem 1 Let {Φi(x, y), i = 1, 2} be the IFS on the unit square deﬁned in eqs. (11),(12). Its
attractor is A = {(x, Q(x)), x ∈ [0, 1]} and A = limn→∞ Φn(K) in the Hausdorﬀ metric, where
K is any non–empty compact set in [0, 1]2.
Corollary 1 It is convenient to take K = {(x, x), x ∈ [0, 1]}, the graph of the identity function:
then, for any n, Φn(K) is the graph of a function Qn(x) that tends to Minkowski’s function Q(x)
uniformly when n tends to inﬁnity. Thanks to the above, one also proves the symmetries

Q(Mi(x)) = Pi(Q(x)), i = 1, 2.

(13)

This procedure was used to produce the graph of Q(x) in Fig. 2 of [12], Fig. 1 of [16] and Figures
9 and 11 herein.

The second IFS we consider is associated with µ and acts in X = [0, 1]. It is composed of the
two M¨obius maps φi = Mi just introduced. Clearly, using now the lower case maps φi to deﬁne
the IFS in eq. (10) implies that A = [0, 1], but our interest at this point is not in the attractor.
Rather, recall that a balanced measure can be uniquely associated with a hyperbolic IFS
{φi : [0, 1] → [0, 1], i = 1, . . . , M}, through the choice of a set of probabilities ρi > 0, i =
1, . . . , M : Pi ρi = 1 [8, 9, 28]. The theory has been extended by Mendivil to transformations
that are contractive on average [38]. A transformation T ∗ on the space M([0, 1]) of regular Borel
probability measures on [0, 1] can be deﬁned as follows: T ∗η is the unique measure that veriﬁes
the equation

Z f d(T ∗η) =

M

Xi=1

ρi Z (f ◦ φi) dη,

for any continuous function f . T ∗ is also known as the Perron–Frobenius operator. This operator
is contractive in the Hutchinson–Wesserstein–Kantorovich metrics (which is a metric that entails
weak star convergence) under which M([0, 1]) is a complete metric space: if η and θ belong to
M([0, 1]), their distance can be deﬁned as

(14)

(15)

d(η, θ) = sup{Z f dη −Z f dθ},

where the supremum is taken over the set of Lip1 functions. The general theory applied to our
case provides the following results [12, 35]:
Theorem 2 Let {Mi(x), i = 1, 2} be the IFS maps deﬁned in eq. (11), let ρ1 = ρ2 = 1
2 and let
T ∗ be the Perron–Frobenius operator deﬁned in eq. (14) with φi = Mi. The balanced measure of
this IFS coincides with Minkowski’s measure µ:

(16)
Moreover, for any η ∈ M([0, 1]), the sequence of measures ηn converges weakly in M([0, 1]) to
Minkowski’s measure µ
(17)

ηn := (T ∗)nη → µ when n → ∞.

T ∗µ = µ.

Corollary 2 On a par with Corollary 1, one can take η as the uniform measure in [0, 1] and
compute Minkowski’s measure µ as the limit of (T ∗)nη.

3 The M¨obius IFS algorithm

3.1 Supportive theory and brief description

Let us now describe how the Jacobi matrix of µ can be computed. The full supportive theory
has indeed been presented in [35], so that only a brief summary of it is reviewed here. The
ﬁrst immediate observation is that, being the moment problem for η and ηn determinate, weak
convergence of ηn implies strong convergence of the corresponding Jacobi matrices (Theorem 1
in [35]):

6

Theorem 3 Let J(ηn) be the Jacobi matrix of ηn, deﬁned as in eq. (17) and let (aj(ηn), bj(ηn))
be its entries. Then,

(aj (ηn), bj(ηn)) → (aj (µ), bj(µ)) when n → ∞

(18)

for any value of j.

This result can be used in two ways. Firstly, one can compute the sequence of measures ηn
and successively J(ηn). This is similar to the approach followed by Dresse and Van Assche in
Sect. 2 of [16]: they have chosen a weakly convergent sequence of discrete measures ηn, composed
of 2n + 1 atoms, and computed by the discretized Stieltjes algorithm the corresponding Jacobi
matrices. In the IFS setting, one can take an initial measure η composed of a ﬁnite number L of
atoms, like e.g. η = δ 1

or η = 1

2 (δ0 + δ1). Therefore, if

2

the action of the Perron–Frobenius operator T ∗ yields

ηn =

L

Xl=1

cn
l δxn

l

,

ηn+1 = T ∗ηn =

1
2

2

L

Xi=1

Xl=1

cn
l δMi(xn

l ).

(19)

(20)

The new measure is still composed of a ﬁnite number of atoms, 2L, at the positions Mi(xn
with the new weights cn

l ) and

Remark 1 If η = δ 1
Farey tree, rooted at x0

2

l /2.
the atoms of ηn are located at xn
1 = 1

2 . This tree can therefore be deﬁned recursively via eq. (20).

l , which are the nodes of level n of the

The Farey tree obviously plays a major role in the theory of the Minkowski measure, as will
appear below.

To compute the Jacobi matrix of the discrete measure ηn, one can use the discretized Stieltjes
algorithm [16], or better Gragg and Harrod’s algorithm [25], which is more stable and can be
enhanced to treat large sets of atoms [37]. Nonetheless, this approach is only helpful if relatively
small values of n are suﬃcient to yield a signiﬁcant number of Jacobi matrix entries (at conver-
gence), because of the geometrical increase with n of the computational complexity. As remarked
in [16] and proven below we are in the opposite situation, which jeopardizes this approach.

Therefore, a diﬀerent approach is needed. While Dresse and Van Assche considered a Cheby-
shev method based on ordinary moments, we employ the technique that we developed in [35]. We
start from equations (14) and (17), but we read them diﬀerently, as a transformation of Jacobi
matrices into Jacobi matrices, in which the measures ηn neither appear nor have to be computed.
This magic is eﬀected in two steps [35].

1: Using the spectral theorem for J(η), one deﬁnes Mi(J(η)) for the two M¨obius maps in eq.
(11): this is the content of Theorem 4 in [35], that also shows that numerical computation of
Mi(J(η)) requires the solution of a tridiagonal linear system.

2: The two Jacobi matrices Mi(J(η)), for i = 1, 2 are in one–to–one correspondence with
two measures, so that we use the algorithm of Elhay–Golub–Kautsky [17] to compute the Jacobi
matrix of their arithmetical average, which is precisely J(T ∗(η)).

From an abstract point of view, the combination of 1 and 2 deﬁnes a mapping on the set of

Jacobi matrices of measures in M([0, 1]): we call it T : J ([0, 1]) → J ([0, 1]),

T (J(η)) = J(T ∗(η)),

(21)

so that one can compute iteratively the left hand side (aj(ηn), bj(ηn)) in Theorem 3, eq. (18).

Original numerical experiments [35] showed convergence of Jacobi matrix elements up to
j = 4, 000 (see Fig. 3 in Sect. 6 of [35], where following Gutzwiller–Mandelbrot [26] Minkowski’s
Q function is called the slippery devil’s staircase). In this paper we need to push the technique
of [35] to much larger orders, to resolve the conjectures presented in the Introduction. To do this
without peril, we must ﬁrst assess convergence and reliability of the M¨obius IFS algorithm.

7

10-2

10-4

10-6

10-8

j

n
∆

10-10

10-12

10-14

10-16

10-18

 100

 200

 400

 800

 1600

 3200

n

Figure 1: Diﬀerence ∆n
j =
125, 250, 500, 1000, 2000, 4000, 8000, 16000, 32000. Diﬀerent curves can be ordered according to
the location of their sudden drop, increasing with j from left to right.

| versus generation numbers n,

j = |an

j − an−1

j

for

3.2 Speed of convergence

First of all, we test the speed of convergence in eq. (18). We start from the Jacobi matrix of
the uniform measure on [0, 1] (that is, from the recurrence relation of Legendre polynomials).
Of course, implementation of (21) requires a truncation of the Jacobi matrices involved: we ﬁx
a large truncation, jmax = 40, 000, and we compute ∆n
|, that is, the variation
of an element of the Jacobi matrix from the n-th iteration of the algorithm to the next. These
diﬀerences are plotted versus n in Figure 1, for geometrically increasing values of j. We observe
that the oscillations ∆n
j suddenly drop by orders of magnitude. This is a clear indication that
convergence has been reached in a ﬁnite subspace.

j − an−1

j = |an

j

To verify this assumption and to quantify the number of iterations required, we deﬁne the

rank of the Jacobi matrix at numerical convergence within a threshold ǫ after n iterations as

Nǫ(n) := max{N s.t.

N

Xj=1

j − an+1
|an

j

| ≤ ǫ}.

(22)

In fact, according to eq. (22) the vector of matrix elements aj with 1 ≤ j ≤ Nǫ(n) vary less than
ǫ in L1 norm when one further iteration of the algorithm is eﬀected after the n-th. This quantity
is plotted versus n in Figure 2: one observes a regular increase of Nǫ(n) with n which indicates
three facts. The ﬁrst is that convergence has been stably reached in the range 1 ≤ j ≤ Nǫ(n)
independently of truncation. The second is that the number of converged components increases
at a power–law rate: Nǫ(n) ∼ AnB. The third is that, while this increase is fully manageable in
the M¨obius algorithm, it prevents the usage of discrete measures, as mentioned in the previous
subsection: in fact, assuming the same rate of convergence and required precision, a number of
atoms of the order of the exponential of N 1/B would be needed in eqs. (19),(20) to compute N
Jacobi matrix elements.

The L1 norm employed in eq. (22) entails a rather cogent test since it also implies a bound
on the inﬁnity norm. We can now compare our results with the table published in [16]. These
latter data were obtained via the Chebyshev algorithm from ordinary moments, programmed in

8

105

104

103

)
n
(
ε

N

102

 100

 200

 400

 800

 1600

 3200

n

Figure 2: Range of numerical convergence Nǫ(n) (red) versus n in the case of Fig. 1 with
ǫ = 10−3. The ﬁtting line (green) is a power–law, Nǫ(n) = AnB with A = .11 and B = 1.48.

Maple with 400 digits arithmetics, to cope with the numerical instability of the technique. It
can be assumed that all digits reported are correct. We have therefore taken the square roots of
the tabulated a2
j coeﬃcients and retained the same number of signiﬁcant digits, 20. We compare
these values with the values provided by M¨obius IFS algorithm, coded in double precision Fortran
on a common desktop computer, reported with 15 signiﬁcant digits. We observe almost perfect
agreement, the diﬀerence between the two data sets being less than 10−15 in all cases. This fact
is consistent with the data of Figure 1: the values of ∆n
j , for j = 125 (ﬁrst curve, red) drop to a
value of about 10−15 after convergence, which takes place at about n = 150.

Unfortunately, the comparison in Table 3.2 cannot be exploited much further, because the
Chebyshev technique of [16] cannot be easily extended beyond j = 40. We have therefore to
develop diﬀerent tests that rely uniquely on our data. A ﬁrst indication follows again from
Figure 1, in which we observe that, after convergence, the values of ∆n
j oscillate around an
average value that increases with j. This increase is a clear sign of loss of precision that we now
investigate.

j Algorithm aj
1 M¨obius
1 Chebyshev
10 M¨obius
10 Chebyshev
20 M¨obius
20 Chebyshev
30 M¨obius
30 Chebyshev
40 M¨obius
40 Chebyshev

0.202302932329981
0.20230293232998066551
0.215070562228327
0.21507056222832743181
0.224458577806858
0.22445857780685732313
0.221516521450380
0.22151652145038000730
0.236423204888560
0.23642320488855968894

Table 1: Jacobi matrix elements aj, for j = 1, 10, 20, 30, 40 from the M¨obius algorithm and from
Table 2 in [16] (Chebyshev algorithm).

9

j=125
j=250
j=500
j=1,000
j=2,000
j=4,000
j=8,000
j=16,000
j=32,000
j=40,000
j=60,000
j=64,000

j

n
∆

10-4

10-6

10-8

10-10

10-12

10-14

10-16

10-18

 100

 200

 300

 400

 500

 600

n

Figure 3: Diﬀerences ∆n
Jacobi matrix is Jnum, the limit matrix obtained after 8,000 iterations of the algorithm.

| versus iteration n, for the values of j reported. Initial

j = |an

j − an−1

j

3.3 Precision of the truncated, ﬁxed point Jacobi matrix

The M¨obius IFS algorithm is an iterative technique that converges to a ﬁxed point. The details
of such convergence clearly depend on the initial point of the iteration, i.e. the Jacobi matrix
input to the procedure. In our case, we have used the Jacobi matrix of Legendre polynomials on
[0, 1]. In any case, as observed in Figures 1 and 2, after a certain number of iterations, numerical
convergence is reached in a ﬁnite subspace. To investigate this phenomenon we set the size of
Jacobi matrices to the largest experimented value, jmax = 64, 000 and we run the algorithm for
N = 8, 000 iterations. We observe that all matrix elements in the range 1 ≤ j ≤ 64, 000 reach
numerical convergence: an approximation of the ﬁxed point Jacobi matrix,

T (J(µ)) = J(µ),

(23)

has been evaluated. To verify numerically the precision of this approximation, we now take
as input the computed Jacobi matrix Jnum(µ) and we further run the algorithm, that is, we
act on Jnum(µ) by T for another N = 700 iterations. Of course, the values of aj(n) are not
constant, but ﬂuctuate, due to numerical errors and ﬁnite truncation.
In Figure 3 we plot
again ∆n
|, for n = 1, . . . , N . As in Fig. 1, the average values increase with j.
Nonetheless, at the largest value, j = 64, 000, they are always smaller than 10−4. We can take
this as an indication of the precision of the computed values aj’s.

j − an−1

j = |an

j

A more reﬁned analysis follows from considering the sequence aj(n) at convergence as a
superposition of the true value aj and of a numerical error ǫj(n). Taking ǫj(n), for n = 1, . . . , N ,
as independent equally distributed random variables, we estimate their standard deviation sj,
that we take as a reliable measure of the error. Observe that we could have divided such standard

deviation by the statistical factor √N − 1, to yield the standard deviation of the sample average
PN
n=1 aj(n)/N . We prefer not to do this, because do not know whether the sample average
converges to the true value aj and because we want to have a conservative estimate of the error
of our technique. Results are plotted in Figure 4, that shows an initial linear growth of the error,
sj ∼ Aj, which lasts until j ≃ 10, 000, being later replaced by a more rapid increase, which
appears to be faster than polynomial.
To investigate this second region we plot the data in semi–logarithmic scale, where a pure

10

10-2

10-4

10-6

10-8

10-10

10-12

10-14

j

s

10-16

 10

 100

 1000

j

 10000

 100000

Figure 4: Standard deviation sj of the numerical error ǫj versus matrix index j (red) and power–
law law sj = Aj, with A = 1.18 · 10−16 (green). A second power law, with exponent B = 12 is
also shown for comparison with the data for j larger than 10,000 (blue).

10-2

10-3

10-4

10-5

10-6

10-7

10-8

10-9

10-10

10-11

10-12

j

s

10-13

 10000

 15000

 20000

 25000

 30000

 35000

 40000

 45000

 50000

 55000

 60000

j

Figure 5: Standard deviation sj of the numerical error ǫj versus matrix index j (red) and the
exponential law sj = AeBj, with A = 3 · 10−13, B = 4 · 10−4 (green).

11

exponential appears as a straight line. This comparison shows that the error growth is less than
exponential. The reasons beyond this behavior are not easily found, but we can nonetheless
conclude that this technique allows us to compute reliably about 60,000 coeﬃcients aj, with the
precision displayed in Figure 4. An indirect, a posteriori proof of the precision of the computed
Jacobi matrix is oﬀered by the results of Section 7.3.

4 Regularity of Minkowski’s measure

We can now enter the heart of the matter. We start by investigating the regularity of Minkowski’s
measure µ, deﬁned as the existence of the limit limj→∞ γ−1/j
= Cap([0, 1]), where Cap([0, 1]) = 1
4
l=1 al;
therefore, we need to compute the geometric average Γj of the matrix entries al, for l = 1, . . . , j:

is the logarithmic capacity of the support of µ. From eq. (3) it easily follows that 1/γj =Qj

j

Γj = γ−1/j

j

1/j

al#

.

=" j
Yl=1

(24)

We plot the results in Figure 6: we observe that the conclusions of [16] (convergence to a smaller
value than 1
4 ) were clearly due to the far–too–small range of j–values considered and to the
deeper fact that the initial entries of the Jacobi matrix “perceive” a smaller support than [0, 1].
We will explain this hitherto obscure remark in Section 5 and following. In the much wider range
presented here convergence to the correct value appears.

This conclusion can be put on even stronger grounds by studying the convergence rate. In

fact, log(Γj ) is the Ces`aro average of the logarithm of the matrix entries aj: the diﬀerence

δj = log(

1
4

) −

1
j

j

Xl=1

log(al),

(25)

features a very clear asymptotic power-law decay of the kind δj = Aj−B (Figure 7). The
pleasingly simple form of this law, its accuracy and the theoretical arguments of the following
sections that explain the power–law convergence from below, all conﬁrm that the constant 1
4
is the limit of Γj when j tends to inﬁnity. We can therefore pretend that the conjecture that
measure is regular is proven numerically to a large degree of conﬁdence. We will add further
evidence in favor of this conclusion in the following sections. Notice that having at our disposal
matrix elements over various orders of magnitude of the index is essential.

Finally notice that the same data also show that j log 4 +Pj log al does not converge to a

ﬁnite value as j tends to inﬁnity. In Sect. 8 we will frame theoretically this result, relating it to
the obvious lack of Szeg¨o asymptotics. We now turn to further veriﬁcations of the fact that the
measure is regular.

5 Zeros Minkowski’s polynomials and their regularity

We now focus on regularity of the distribution of zeros of the polynomials, which, in our case,
is equivalent to regularity of the measure. In this section and in the next we study whether the
sequence νj in eq. (6) converges to νE, the equilibrium measure on [0, 1], which is an absolutely
continuous measure with density νE(x):

νE(x) =

1
π

.

(26)

We compute the zeros of pj(µ; x) via diagonalization of the truncated Jacobi matrix J(µ). The
algorithm (the implicit QL method) is notoriously stable and can be easily carried out to large
orders. It yields the values ζj

l , for l = 1, . . . , j, and j in the range from 1 to 60,000.

1

px(1 − x)

12

 0.25

 0.24

 0.23

j

Γ

 0.22

 0.21

 0.2

 0.19

 1

 10

 100

 1000

 10000

 100000

j

Figure 6: Geometric average Γj in eq. (24) versus matrix index j.

 1

 0.1

 0.01

j

δ

 0.001

 1

 10

 100

 1000

 10000

 100000

j

Figure 7: Diﬀerence δj in eq. (25) versus matrix index j (red). Also plotted is the power-law
decay δj = Aj−B, with A = 1.6186, B = 0.65424 (green).

13

To prove regularity, we check numerically a stronger property. Recall that the equilibrium
measure νE is linked to the (properly shifted and normalized) Chebyshev polynomials, pj(νE; x),
whose zeros can be explicitly computed: Let ϕj

for l = 1, . . . , j. Then,

l = 2l−1
2j

pj(νE; θj

l ) = 0 when θj

l =

1
2

[1 − cos(ϕj

l π)],

l = 1, . . . , j.

(27)

Numerical data support the validity of the following conjecture:

Conjecture 3 As j tends to inﬁnity, the zeros ζj
l of Minkowski’s measure orthogonal polynomials
converge uniformly to the zeros of the Chebyshev polynomials of the same order. In addition,
convergence is power–law: there exist positive constants A and B such that

l − ζj
From the above, a simple consequence follows.

Uj = max{|θj

l |, l = 1, . . . , j} ≤ Aj−B.

(28)

Lemma 1 Conjecture 3 implies regularity of the distribution of zeros.

Proof. Letting f be a continuous function on [0, 1], for any ǫ > 0 there exists δ > 0 such that
|θj
l −ζj
l )| < ǫ, where we use the trivial fact that continuity on a compact
is necessarily uniform. Then, for any ǫ there exists J such that

l | < δ implies |f (θj

l )−f (ζj

1
j

|

j

Xl=1

[f (θj

l ) − f (ζj

l )]| ≤

1
j

j

Xl=1

|f (θj

l ) − f (ζj

l )| ≤ ǫ

(29)

if j > J. Since the discrete measures generated by Chebyshev nodes converge weakly to νE, so
does the sequence νj. Observe that we do not need the estimate on the convergence rate. ✷

l − ζj

l | versus θj

Numerical support to Conjecture 3 is oﬀered in Figure 8. In Figure 9 we plot the absolute
diﬀerence |θj
l : this drawing reveals the locations where the two sequences diﬀer
the most. When compared to the graph of Minkowski’s function Q, we observe that this pattern
follows the structure of the Farey tree (deﬁned in Remark 1): around rational values Minkowski’s
function has a non–analytic behavior, with large “slippery plateaus” (i.e. intervals of very low
measure), which tend to ward oﬀ the zeros of pj(µ; x). The phenomenon is stronger the higher
the rational point is in the Farey tree. This fact is not surprising and will be further studied in
the next sections.

To the contrary, the novel result of this investigation is that, this repulsion notwithstanding,
Minkowski’s measure is regular—said otherwise, zeros of the orthogonal polynomials ﬁnd a way
to “creep in” these regions and eventually populate them accordingly to the equilibrium measure.
They do so at a power–law rate in the polynomial index, which explains the power–law behaviors
found in Sections 4 – 6. In Section 7 we will encounter a dramatic consequence of these facts:
the creation of mathematical neutrinos.

6 Discrepancy Analysis

Two measures λ, η on [0, 1] diﬀer as much as their integral over sub-intervals is diﬀerent. This
quantity is discrepancy:

D(λ, η) = sup{|λ(I) − η(I)|, I = (a, b) ⊂ [0, 1]}.

(30)

Discrepancy has been intensely investigated [4, 5, 18], since it is linked with root distribution
and the logarithmic potential.

Consider the measures νj and νE.

If the sequence D(νj , νE) converges to zero, then νj
converges weakly to νE and this implies regularity of the zero distribution. Zeros of the Chebyshev
polynomials are best seen as projection on the real axis of equi-spaced points on the unit circle
in the complex plane. When lifted to this set, the measure νE becomes the uniform Lebesgue

14

 1

 0.1

j

V

,

j

U

 0.01

 0.001

 0.0001

 10

 100

 1000

j

 10000

 100000

Figure 8: Upper bound Uj from eq. (28) versus matrix index j (crosses), ﬁtted by the power-law
decay uj = Aj−B, with A = 0.45, B = 0.59. Upper bound Vj from eq. (32) (asterisks), ﬁtted
similarly, with A = .35, B = 0.32

 0.0008

 0.0007

 0.0006

 0.0005

|

l

j

ζ
-

l

j

θ

|

 0.0004

 0.0003

 0.0002

 0.0001

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

)

l

j

θ
(
Q

 0

 0

 0.1

 0.2

 0.3

 0.4

 0.6

 0.7

 0.8

 0.9

 0

 1

 0.5
θj

l

Figure 9: Absolute diﬀerence |θj
l , for j = 60, 000 (left vertical scale). Each dot
corresponds to a diﬀerent value of l. Also plotted is the graph of the function Q (continuous line,
right vertical scale).

l | versus θj

l − ζj

15

measure. Therefore, it is convenient to also lift to the unit circle the zeros ζj
orthogonal polynomials: this leads to the deﬁnition of the normalized angles

l of Minkowski’s

ψj

l =

1
π

arccos(1 − 2ζj
l ).

(31)

The second set of data in Figure 8 compares these values and the Chebyshev angles ϕj
quantity Vj:

l ; the

Vj = max{|ϕj

l − ψj

l |, l = 1, . . . , j},

(32)

coherently with Conjecture 3, features a power–law decay.

Numerical computation of the discrepancy D(νj , νE) is easily performed via a simple lemma

that can be proven by straightforward computation:

Lemma 2 The discrepancy D(νj , νE) between the discrete measure νj and the Chebyshev mea-
sure νE on [0, 1] is the maximum of the following three quantities:

D1 = max{|ψj

l −

l − i
j

|, l = 1, . . . , j; i = 0, 1},

D2 = max{|1 − ψj

l −

j − l + i

j

|, l = 1, . . . , j; i = 0, 1},

D3 = max{|ψj

l − ψj

k −

l − k + i

j

|, l, k = 1, . . . , j; i = −1, 1}.

(33)

(34)

(35)

Thanks to the lemma, numerical computation of D(νj , νE) can be performed by a ﬁnite
summation. This leads to the results plotted in Figure 10. Again, not only we observe convergence
towards zero of D(νj , νE), but we can also extrapolate a power–law behavior with exponent close
to B = 0.35. Observe that by necessity, being νj discrete with atoms of equal weight, decay
is bounded from below by D(νj, νE) > 1/j for all j. We therefore formulate the following
conjecture:

Conjecture 4 As j tends to inﬁnity, the discrepancy D(νj , νE) tends to zero.
In addition,
convergence is power–law: there exist positive constants A and B such that D(νj , νE) ≤ Aj−B.

7 Gaussian integration of Minkowski’s measure

We have seen that Minkowski’s measure is singular (with respect to the Lebesgue measure) and
at the same time regular (in the Ullman-Stahl-Totik sense). This hectic combination produces
fascinating results, for what concerns Christoﬀel numbers—also called Gaussian weights. Recall
eq. (7), which deﬁnes the discrete measure µj, and let us focus on the weights wj
l . It is convenient
to start their analysis from a visual examination: in Figure 11 we plot the logarithm of the inverse
of the weights (in base 10) versus their location ζj
l , for j = 60, 000. The ﬁgure is extremely
instructive.

First of all, observe that the vertical scale at the left of the picture is also logarithmic, so that
what appears graphically is minus the logarithm of the logarithm of the weight: the largest of these
are of the order of 10−3, while the smallest are below 10−1000. There are about one thousand
orders of magnitude of diﬀerence between the two! We believe that it is then appropriate to
call the latter mathematical neutrinos, for their elusive mass. Their detection poses a serious
challenge and requires a speciﬁc technique, by which it has been possible to compute Figure 11:
this is explained in subsection 7.1.

Secondly, observe that small weights appear when Gaussian nodes ζj

l approach the locations of
rational points on the Farey tree (deﬁned in Remark 1): this is the same to say, where Minkowski’s
Q function (the continuous curve in the ﬁgure) appears to be “almost ﬂat”. Therefore, Gaussian
points and weights reﬂect the structure of Minkowski’s measure and of the distribution of rationals

16

 1

j

)
ν
,
ν
(
D

 0.1

 0.01

 1

 10

 100

 1000

 10000

 100000

j

Figure 10: Discrepancy D(νj, νE) versus j and ﬁt by the power-law decay dj = Aj−B, with
A = .849, B = 0.351.

on the real line [55], in a signiﬁcant way. In subsection 7.2 we develop an asymptotic theory which
explicitly computes the “cusps” that appear in Figure 11.

Finally, in subsection 7.3 we deal with the fact that Farey points—the rationals—are dense in
[0, 1]: one must expect a dense set of these cusps. We show that their appearance is hierarchically
ordered, this fact being well described by the asymptotic theory.

l = ζj

l uj

l . In the standard Golub-Welsch algorithm [24], wj

7.1 Numerical computation of mathematical neutrinos
Let again eq. (7) deﬁne the discrete measure µj, with atoms at the Gaussian nodes ζj
l . It is well
known that they can be proﬁtably computed as the eigenvalues of the truncated Jacobi matrix
of rank j: J (j)uj
is obtained as the
positive, ﬁrst component of the normalized eigenvector uj
l . The advantage of this algorithm lies
in the fact that this component can be obtained without having to compute the full eigenvector.
Unfortunately, this procedure is viable only as far as the amplitude of the weights does not fall
below the level of numerical noise. When this happens—and Figure 11 shows that this is the
present case—the numerical detection of these weights poses challenges comparable to those of
detecting neutrino’s mass in physical experiments. In this subsection we describe a technique that
can reveal these weights even when the ratio between the largest and the smallest is hundreds
orders of magnitude smaller than machine precision.

l

Among many equivalent deﬁnition of the weights, we choose the one originally due to Shohat

[47, 20]. Let Kj(x, y) be the Christoﬀel-Darboux kernel:

Kj(x, y) =

j−1

Xl=0

pl(µ; x)pl(µ; y),

(36)

The weights wj
are computed as the eigenvalues of the truncated Jacobi matrix):

l can be obtained from the diagonal values of this kernel at the roots of pj (that

(wj

l )−1 = Kj(ζj

l , ζj

l ) =

pl(ζj

l )2.

j−1

Xl=0

(37)

17

 10000

 1000

 100

 10

 1

 0.9

 0.8

 0.7

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

)

l

j

ζ
(
Q

l

j

 

w
0
1
g
o
l
-

 1

 0

 0.1

 0.2

 0.3

 0.4

 0.6

 0.7

 0.8

 0.9

 0

 1

 0.5
ζj

l

Figure 11: Base 10 logarithm of the inverse of the Gaussian weights wj
l , plotted as dots at the
abscissae ζj
l , for j = 60, 000 (left vertical scale). Weights near ζ = 0 and ζ = 1 are smaller than
10−1000. Also plotted is the graph of the function Q(ζ) (continuous line, right vertical scale).
The region near x = 1

4 is magniﬁed in Fig. 12 below.

It is customary to call the inverse of the diagonal kernels the Christoﬀel functions λj (x):

λj(x) =

1

Kj(x, x)

.

(38)

The numerical calculation of these values is similar to the calculation of Lyapunov exponents
in dynamical systems or in random matrix theory: according to eq. (36), Kj(x, x) is a summation
of positive values. Low weights correspond to large values of the sum, which, in turn, arise from
the fact that the norm of the two–components column vector vl = (pl(µ; x), pl−1(µ; x))t becomes
very large and may overﬂow. The three–terms recurrence relation (3) implies that vl+1 is uniquely
deﬁned from the action of a transfer matrix acting upon vl:

vl+1 =(cid:18) x−bl

al+1 − al
al+1
1
0

(cid:19) vl.

(39)

It is therefore not needed to store the full sequence pl(µ; x) when calculating Kj(x, x). We then
act as follows: starting from l = 1, we compute the ﬁnite summation (37) term by term, until
Kl(x, x) exceeds a ﬁxed threshold. At that moment, we let V be the maximum of the absolute
values of the two components of vl, and we renormalize vl to vl/V and Kl(x, x) to Kl(x, x)/V 2,
while accumulating the logarithm of V in a resummation variable W (x), initially set to zero. At
the end of the procedure, when l = j − 1, the logarithm of the true value of Kl(x, x) is obtained
by the renormalized variables as log Kl(x, x) + 2W (x) and the ﬁnal formula follows:

log λj(x) = − log Kl(x, x) − 2W (x).

(40)

Numerical values of Christoﬀel functions and numbers reported in this paper have been obtained
using this procedure.

18

7.2 Asymptotic analysis: Minkowski’s slippery plateaus

Let us now derive an asymptotic theory for the explanation of the Figure 11, which derives from
the nature of Minkowski’s question mark measure.
In this subsection, we study the average
value of Gaussian weights in certain subintervals I ⊂ [0, 1], when the polynomial degree tends to
inﬁnity. This average is deﬁned by

wj

l ∈I wj
I = Pζ j
#{l s.t. ζj

l

l ∈ I}

.

(41)

Since the vertical scale of Figure 11 is logarithmic, we ﬁnd appropriate to consider the logarithm
of the average weight wj

I . We start proving the following Lemma:

Lemma 3 If Conjecture 1 is veriﬁed,

log(wj

I ) = − log(j) + log(µ(I) − log(ν(I)) + o(j),

where o(j) indicates as usual an inﬁnitesimal sequence.

Proof. Divide and multiply the denominator in eq. (41) by the order j, to obtain

jwj

I =

l ∈I wj
Pζ j
#{l s.t. ζj

l

l ∈ I}/j

.

(42)

(43)

Because of weak convergence of the sequence µj to µ, one has that the numerator at r.h.s. tends
to the µ–measure of I:

wj

l = µ(I).

(44)

lim

j→∞ Xζ j

l ∈I

Since the measure is regular (Conjecture 1), the denominator tends to ν(I). Taking logarithms
yields lim log(j) + log wj

I = log(µ(I)/ν(I)). ✷

We now specialize this result to particular intervals of the kind [ p

q + y], in the neighborhood
of the rational point p
q , where we observe numerically the cusps in the logarithm of the Christoﬀel
numbers. For sake of deﬁniteness we consider the case 1
q , which lies on the (q − 2)-th level of
the Farey tree (according to Remark 1 we root the tree at 1
2 , level zero). Our technique can be
applied also to the general case, with a minor additional eﬀort. We need the following technical
Lemma:

q , p

Lemma 4 The function Q(x) is non-analytic around all Farey points x = 0, x = 1
integer, in the following sense: for any integer k ≥ 0 and q > 0

q with q

µ([0,

1

k + 1

]) = 2−k; µ([

1
q

,

k + 1

qk + q − 1

]) = 2−k−q+1.

(45)

Proof. Let Σ be the set of ﬁnite words in the letters 1 and 2. We denote by |σ| the length of
σ ∈ Σ:
if |σ| = n then σ is the n-letters sequence s1, s2, . . . , sn where si is either 1 or 2. We
associate to σ the composite maps

and

Mσ = Ms1 ◦ Ms2 ◦ ··· ◦ Msn

Φσ = Φs1 ◦ Φs2 ◦ ··· ◦ Φsn ,

where the basic maps Mi and Φi have been deﬁned in eqs. (11) and (12). Consider now the set
Σn of cardinality 2n composed of all words of length n. For any n, the graph G of Q is contained
in a union of images of the unit square:

G ⊂ [σ s.t. |σ|=n

Φσ([0, 1]2).

19

In the above, each image Φσ([0, 1]2) is a rectangle of basis Mσ([0, 1]) and height of length 2−|σ|.
Since the graph G is continuous and since these rectangles are joined by the corners, it follows
that the graph of Q passes through these corners, so that

µ(Mσ([0, 1])) = 2−|σ|.

(46)

The basis intervals Mσ([0, 1]) are the partition of [0, 1] produced by the Farey tree up to level
n − 1.
shrinking at the point zero. In fact,

Consider now the word σ = 1k composed of k ones: we can use it to produce nested intervals

M1k ([0, 1]) = [0,

1

k + 1

], µ(M1k ([0, 1])) = 2−k.

(47)

This proves the ﬁrst part of eq. (45).

We now consider the point 1

1 M2(0).
This permits to map the intervals of the previous case, which were shrinking at the point zero,
into a new sequence at the point 1

q , with q ≥ 2. Observe that 1

q . Deﬁne σ = 1q−221k, to obtain

2 = M2(0) and that 1

q = M q−2

M1q−221k ([0, 1]) = [

1
q

,

k + 1

qk + q − 1

], µ(M1q−221k ([0, 1])) = 2−k−q+1.

(48)

The ﬁrst part of the above equation can be proven by explicit calculation, while the second
follows easily by computing the symbolic length of the word σ. This proves the second part of
eq. (45). ✷

Combining the previous results we have the following

Lemma 5 Let q ≥ 2 and k ≥ 0. Let lq,k =
1
q

Iq,k = [

1

q(qk+q−1) . Deﬁne the intervals

+ lq,k+1,

1
q

+ lq,k].

The average amplitude of Gaussian points of order j in Iq,k behaves asymptotically as

log(wj

Iq,k

) = −[(k + q) log(2) + log(j) + log(ν(Iq,k))] + o(j).

Proof. Using the notations of Lemma 4 the interval Iq,k can be written as

Iq,k = M1q−221k ([0, 1]) \ M1q−221k+1([0, 1]),

(49)

(50)

(51)

and the ﬁrst set at r.h.s. completely contains the second. To prove these facts, observe that the
geometric length of the interval M1q−221k ([0, 1]) = [ 1
q ,

qk+q−1 ] in eq. (51) is

k+1

k + 1

qk + q − 1 −

1
q

=

1

q(qk + q − 1)

= lq,k.

(52)

Using eq. (48) we then show that the measure of Iq,k is 2−q−k. The thesis then follows using eq.
(42). ✷

We can now state the principal result of this section:

Proposition 1 Assume that Conjecture 1 holds. Let 0 < y < 1
large j, the logarithmic amplitude log(wj

2 , q ≥ 2. Then, for suﬃciently

Iq,k

), where y ∈ Iq,k, veriﬁes the inequalities

− log(wj

Iq,k

) ≤ log(2)[

− log(wj

Iq,k

) ≥ log(2)[

1
q2y

1
q2y

+

+

1
q

1
q

+ q − 2] + log(j) −

+ q − 3] + log(j) −

1
2

1
2

H−(q; y) + 2 log(qy) − log(1 − q2y);

(53)

H+(q; y) + 2 log(qy) − log(1 + q2y),

(54)

where H±(q; y) are continuous functions that tend to log( 1

q − 1

q2 ) when y tends to zero.

20

q + y ∈ Iq,k, the last set being
deﬁned in eq. (49) (see also eq. (51)). Since the measure νE is absolutely continuous, we use
q,k, where tq,k is a point in Iq,k

Proof. Let k be such that y ∈ (lq,k+1, lq,k). This means that 1
its density to write in the obvious way ν(Iq,k) = |Iq,k|/2qtq,k − t2
and where |Iq,k| is the length of the interval Iq,k:
|Iq,k| = lq,k − lq,k+1 = q2lq,klq,k+1.

Therefore, eq. (50) becomes

− log(wj

Iq,k

) = (k + q − 1) log(2) + log(j) −

1
2

log(tq,k − t2

q,k) + log(q2lq,klq,k+1) + o(j).

(55)

Since k is such that y ∈ (lq,k+1, lq,k), we have that

and

1

(k + 1)q2 + q(q − 1) ≤ y ≤

1

kq2 + q(q − 1)

,

1
q2y

+

1
q − 2 ≤ k ≤

1
q2y

+

1
q − 1.

(56)

(57)

Using this result, we can estimate the various quantities in eq. (55).

2 log(qy) − log(1 + q2y) ≤ log(q2lq,klq,k+1) ≤ 2 log(qy) − log(1 − q2y);

tq,k ≤
1
q

tq,k ≥

1
q

+ lq,k ≤

1
q

+ lq,k+1 ≥

;

1 + qy
1 − q2y
1 + qy
1
1 + q2y
q

.

Let h±(q; y) = 1+qy
1∓q2y . These are bounded functions that tend to one as y tends to zero. Consider
the function f (s) = s(1−s). This is a monotonic function, increasing for s < 1
2 and decreasing for
s > 1
2 . Therefore, the quantity log(tq,k(1 − tq,k)) can be estimated via the last two inequalities.
We assume the ﬁrst case, which corresponds to q ≥ 3, the other consisting of reversed inequalities:
in so doing, the deﬁnition

H±(q; y) = log[

1
q

h±(q; y)(1 −

1
q

h±(q; y))]

completes the proof. ✷

7.3 Hierarchical Christoﬀel functions of Minkowski’s measure

Proposition 1 deals with the average value of Christoﬀel numbers over intervals in the neighbor-
hood of the point 1
q + y. As a matter of facts, only the value y enters the formulae. In addition,
since wj
as the typical logarithm of the
l
Christoﬀel function at the point 1
q + y. This permits to derive an asymptotic relation for this
latter:

is determined via eqs. (37), (38) we can think of wj
Jk

Proposition 2 Assume that Conjecture 1 holds. The typical logarithmic amplitude of the Christof-
fel function λj (x) of order j at the point x = 1
comprises the sum of four contributions:

q + y is given by an asymptotic formula that

log(λj (

1
q

+ y)) ∼ Λj(q; y) = Λ1(q; y) + Λ2(q) + Λ3(q; y) + Λ4(j),

(58)

in which the ﬁrst is a geometrical factor that comes from the projection of the unit circle on the
real axis:

Λ1(q; y) =

log[

+ y)2] + log 2;

(59)

1
2

1
q

1
q

+ y − (

21

the second depends only on q, that is on the level in the Farey tree :

Λ2(q) = (−q + 2 −

1
q

) log(2) + log(log(2));

(60)

the third contribution is determined by the distance from the rational point 1
in the limit of null distance:

q and it is singular

Λ3(q; y) = −

log 2
q2y − 2 log(qy);

the fourth is minus the logarithm of the polynomial order:
Λ4(j) = − log(j).

(61)

(62)

Proof. We use the results of Proposition 1. Notice that the ﬁrst term, Λ1(q; y), can be written

as log(| sin ϑ|), where ϑ = arccos[2( 1

q + y − 1)]. In particular, it lies between the two bounds

1
2

H−(q; y) + log(2) ≤ Λ1(q; y) ≤

1
2

H+(q; y) + log 2.

(63)

The second contribution, Λ2(q), interpolates the purely q dependent terms in eqs. (53),(54).
The choice of the interpolating constant log(log(2)) stems from a formal calculation of the asymp-
totics, not reproduced here. The estimate is justiﬁed by the inequalities

(−q −

1
q

+ 1) log(2) < Λ2(q) < (−q −

1
q

+ 2) log(2)

Notice that in the bounds in the above equation diﬀer from those of eqs. (53),(54) by a single
log(2) contribution, since this has been already included in the above eq. (63).

The third contribution, Λ3(q; y), collects the y dependent quantities in eqs. (53),(54) that
diverge as y tends to zero and therefore are at the origin of the cusps. Clearly, Λ3(q; y) interpolates
the bounds because of the obvious inequalities log(1 − q2y) < 0 < log(1 + q2y). Furthermore,
both of the latter functions are inﬁnitesimal when y tends to zero.

Finally, the last quantity, Λ4(j), directly follows by eqs. (53),(54). ✷

Remark 2 By using the symbolic approach of Lemma 4, similar results can also be derived for
µ([ p
q +s]), for any relatively prime p and q, so that the local structure of the Christoﬀel function
and of the diagonal Christoﬀel-Darboux kernel can be fully explained.

q , p

Let us now illustrate the theoretical results with a series of ﬁgures, in which we will use the
symbol Kj, to underline the fact that the Christoﬀel functions are computed from eq. (36) using
the techniques of Section 7.1.

We start from Figure 12, where we plot the logarithm of the diagonal kernel Kj(x, x) for x in
the right neighborhood of the rational point 1
4 (there is no particular reason behind this choice,
l ,− log(wj
other than it is a point on the second level of the Farey tree). The Gaussian pairs (ζj
l ))
lie on this graph, because of the fundamental property (37) and are plotted as crosses. Also, the
asymptotic estimate −Λj( 1
4 here and everywhere in
the remainder of this section. The value of the polynomial order chosen is j = 60, 000.

4 ; y) is drawn in the picture, where y = x − 1

Let us begin the analysis from the left part of the ﬁgure, i.e. x values smaller than 0.2525. The
distribution of Gaussian pairs reveals the detail of the cusp behavior already observed in Figure
11. The asymptotic formula −Λj( 1
4 ; y) reproduces the cusp on which Gaussian points lie almost
perfectly. At the same time, −Λj( 1
4 ; y) and log(Kj(x, x)) are almost coincident as far as Gaussian
pairs populate the graph and start parting at the location of the leftmost polynomial zero in the
ﬁgure. In the innermost interval around 1
4 the logarithm of the Christoﬀel kernel Kj(x, x) stops
following the cusp–like divergence: it is a continuous, bounded function and therefore it smoothly
tends to a ﬁnite value when x tends to 1
4 .

These facts are all explained by the asymptotic theory. In fact, its derivation rests on the
assumption that the measure is regular; since it describes the behavior of Gaussian weights,
where there are no Gaussian points there is no reason to expect agreement with the kernel and

22

 100

)

j

K
(
g
o

l
,

j

Λ

-
,
)

jl

w
(
g
o
l
-

 10

-log(wj
l)
-Λ
j
log(Kj)
j/log(Kj)

-Λ

 1

)

j

K
(
g
o

l
/

j

Λ

-

 10

 0.25

 0.251

 0.252

 0.253

 0.254

 0.255

x, ζj

l

4 (blue), with j = 60, 000, Gaussian pairs (ζj

Figure 12: Logarithm of the Christoﬀel-Darboux kernel Kj(x, x) in the right neighbourhood
of x = 1
l )) (crosses) and asymptotic
estimate −Λj( 1
4 ) (green). The right vertical scale measures the ratio
−Λj( 1

4 ; y)/ log(Kj(x, x)) (magenta). See text for discussion.

4 ; y) (with y = x − 1

l ,− log(wj

one needs to wait for the asymptotic zero distribution to set in—see Sections 5, 6 and Figure 13.
The ratio between −Λj( 1
it is divergent for
x = 1
4 , but it rapidly approaches one when x is equal to the leftmost polynomial zero, staying
very close to this value in a certain interval. In the right part of the ﬁgure this ratio begins to
oscillate while new peaks of the kernel appear: we will examine these momentarily, with the aid
of a more detailed ﬁgure.

4 ; y) and log(Kj(x, x)) is also plotted in Figure 12:

Let us now concentrate on the role of the polynomial order j. It enters the asymptotic relation
(58) in a very simple way, via the term Λ4(j) = − log(j). It neither determines the shape of
the cusp, which is given by Λ3(q; y), nor it combines with the rational denominator q or the
location x. Also, when compared to other factors, the logarithmic dependence of Λ4(j) is rather
mild. Yet, there is a hidden role of j which does not appear explicitly and it is fully appreciated
when considering the asymptotic nature of the expansion (58) in Proposition 2: Λj( 1
q ; x − 1
q )
approximates log λj (x) = − log(Kj(x, x)) better and better, in an interval which approaches 1
q ,
as j tends to inﬁnity.
In fact, let us ﬁrst consider Figure 13. It is analogous to Figure 12 but it plots quantities at
geometrically increasing values of j, from j = 7, 500 to j = 60, 000, in a magniﬁed range of values
close to 1
l are approximately equally spaced, with density given by the equilibrium
measure νE, in a region which excludes the immediate neighborhood of 1
4 . As before, the closest
point ζj
4 marks the boundary of the region in which agreement between
log(K(x, x)) and −Λj( 1
4 ; y) takes place. This range moves to the left when j increases, according
to Conjecture 3 in Section 5.

l to the rational value 1

4 . Zeros ζj

Secondly, eq.

(58) holds exactly in the inﬁnite j limit for the average value of Christof-
fel numbers–Gaussian weights over the intervals Iq,k (as follows from Proposition 1), yet it is
asymptotic for the individual weights, which are pointwise values of the Christoﬀel functions.
This is seen in Figure 14 that plots the magniﬁcation of the right part of Figure 12. We observe
the growth of new cusps superimposed to the leading asymptotics −Λj( 1
4 ; y), as the polynomial
degree j increases. These cusps are associated with other rational points of higher order than

23

-Λ

-Λ

-log(w60000)
60000
log(K60000)
-log(w30000)
30000
log(K30000)
-log(w15000)
15000
log(K15000)
-log(w7500)
7500
log(K7500)

-Λ

-Λ

 220

 200

 180

 160

 140

 120

 100

 80

 60

 40

)

j

K
(
g
o

l
 
,

j

Λ

-
,
)

l

j

w
(
g
o
l
-

 20
 0.2502

 0.2504

 0.2506

 0.2508
x, ζj

l

 0.251

 0.2512

 0.2514

Figure 13: As in Figure 12:
neighbourhood of x = 1
y = x − 1

4 , Gaussian pairs (ζj

logarithm of the Christoﬀel-Darboux kernel Kj(x, x) in the right
4 ; y) (with

l )) and asymptotic estimate −Λj( 1

l ,− log(wj

4 ). Geometrically increasing values of j are plotted.

1
q in the Farey tree. The same local asymptotic analysis leading to eq. (58) can be carried out
at these new rational points, in a hierarchical construction that parallels that of Minkowski’s
question mark function by M¨obius IFS.

We can conclude that the behavior of Gaussian points–Christoﬀel numbers, described in
this asymptotic analysis, reveals the hierarchical structure of Minkowski’s measure in a very
transparent way. This structure is also hierarchically encoded in the Jacobi matrix of the measure,
in the sense that the ﬁner structure the higher the index of the Jacobi matrix entries that
reproduce it. This happens much in the same way as what observed in [37] for the Jacobi matrix
of the equilibrium measure on fractal sets.

Finally, the ﬁne details and the precision of the numerical results prove a posteriori that the
procedures employed to compute Jacobi matrix, eigenvalues and Christoﬀel functions are stable
and precise to the point of allowing such reﬁned observations.

8 The Nevai class of measures

In our case, being all bj’s equal to one half, this amounts to the limit aj → 1
4 .

The Nevai class of measures is deﬁned by the fact that the matrix elements aj and bj tend to
In
a limit.
Figure 15 we plot the absolute diﬀerence |aj − 1
4| in double logarithmic scale. Observe that the
data, plotted with dots, range over orders of magnitude; yet, even the largest distances from
the expected limit clearly tend to zero when j grows. We also plot the numerical upper bound
function u(x), deﬁned as u(x) = max{|aj − 1
4|, x ≤ j ≤ 60, 000}. This function decreases by
deﬁnition, but it does so regularly. For comparison, we also plot a power-law decay: although
with a lesser degree of conﬁdence than all other numerical estimates in this paper, we may put
forward the following

Conjecture 5 Convergence of the Jacobi matrix elements of Minkowski’s measure is power–law:
there exist two positive constants A, B such that |aj − 1

4| < Aj−B.

24

-Λ

-Λ

-log(w60000)
60000
log(K60000)
-log(w30000)
30000
log(K30000)
-log(w15000)
15000
log(K15000)
-log(w7500)
7500
log(K7500)

-Λ

-Λ

 26

 24

 22

 20

 18

 16

 14

 12

)

j

K
(
g
o

l
 
,

j

Λ

-
,
)

l

j

w
(
g
o
l
-

 10

 0.252

 0.2525

 0.253

 0.2535

 0.254
x, ζj

l

 0.2545

 0.255

 0.2555

 0.256

Figure 14: As in Figure 13, for larger values of x. See text for analysis.

This convergence appears to be characterized by a considerably smaller exponent B than the one
observed in Figure 7. In fact, Figure 7 is related to the average behavior of the logarithm of aj
(regularity of the measure). To the contrary, the decay is here piloted by outliers that we need
to master to prove the stronger requirements of the Nevai class.

In addition to the direct investigation of Jacobi matrix elements, a further analysis can be
performed to test whether µ belongs to the Nevai class. Let us consider the ratio of the orthogonal
2 ) this ratio tends to the function
polynomials pj−1(µ; z) and pj(µ; z).
φE(z) = 1/(z − 1
(see the Introduction). At the same time, following e.g. [53], the above ratio can be written as
the Stieltjes transform of a discrete measure σj(µ):

2 +pz(z − 1)), uniformly on compact subsets of the complement of E = [0, 1]

If µ belongs to N ( 1

4 , 1

where, as in eq. (8), we have put

pj−1(µ; z)
pj(µ; z)

= ajZ dσj(µ; s)
z − s

,

σj(µ) =

n

Xl=1

wj

l p2

j−1(µ; ζj

l )δζ j

,

l

(64)

(65)

and, as in eq. (37), the Christoﬀel weights are (wj
l )2. They obviously depend
on µ, even if this dependence is left implicit, not to overburden the notation. We ﬁnd convenient
to introduce a short–hand notation for the weights in eq. (65):

l )−1 =Pj−1

l=0 pl(µ; ζj

Sj
l (µ) = wj

l p2

j−1(µ; ζj

l ).

(66)

Observe that σj (µ) is a sort of weighted version of the discrete measure µj associated with
Gaussian integration, eq. (7). While the sequence of these latter always converges weakly (to µ),
convergence of σj (µ), when j tends to inﬁnity, is not always assured and we can use this fact for
our purpose.

In fact, Nevai class N ( 1

4 , 1

2 ), via convergence of the polynomial ratios to φE(z) and eq. (64)

implies convergence of σj (µ) to the absolutely continuous measure dσE(x) = 1
Viceversa, if σj (µ) converges weakly to a measure σ, then µ belongs to a Nevai class, since
j−1. This proves the following criterion [53]:

2πpx(1 − x)dx.

j−1 + a2

R x dσj (µ; x) = bj−1 and R x2 dσj (µ; x) = b2

25

|aj-1/4|
u(x)
j-3/10/5

 0.1

 0.01

 0.001

 0.0001

 10

 100

 1000
j

 10000

Figure 15: Convergence of the Jacobi matrix elements:
bound u(x) and the power law j−3/10/5. Each red dot corresponds to a matrix element.

4| versus j, the numerical upper

|aj − 1

Theorem 4 The Minkowski’s measure µ belongs to the Nevai class N ( 1
sequence of measures σj(µ) converges weakly to σE.

4 , 1

2 ) if and only if the

A ﬁrst way to use this criterion comes from Conjecture 3 in Section 5: we have noticed
that zeros of the orthogonal polynomials pj(µ; x) orderly converge to those of the Chebychev
polynomials pj(νE; x). It is immediate that νE belongs to the Nevai class N ( 1
2 ) and therefore
σj (νE) tends to σE. If we can control the distance between σj (µ) and σj(νE) we may expect to
be able to prove convergence of σj(µ) to σE.

4 , 1

Indeed, let θj

l = 1

2 [1 − cos(ϕj

polynomials pj(νE; x). We can compute σj (νE) explicitly, since p2
This yields

l π)] as in eq. (27) be the location of the roots of the Chebyshev
2n π).

l ) = 2 sin2( 2l−1

j−1(νE; θj

Sj
l (νE) = 2 sin2(

2l − 1
2n

π)/n.

(67)

Next, one might think of operating like in Lemma 1: let again f be a continuous function,

|Z f dσj(µ) −Z f dσj(νE)| = |
Xl=1
l ) − f (θj
l )| +

Sj
l (νE)|f (ζj

≤

j

Xl=1

j

j

Sj
l (µ)f (ζj

l ) −

l (νE)f (θj
Sj
l )|

Xl=1
l (νE) − Sj
l )||Sj

l (µ)|

j

|f (ζj

Xl=1
l )| + kfk∞

≤ sup

l

|f (ζj

l ) − f (θj

j

Xl=1

|Sj
l (νE) − Sj

l (µ)|.

(68)

The ﬁrst term of the above inequality is inﬁnitesimal, when j tends to inﬁnity, according to Con-
jecture 3. We can also verify numerically (see below, Fig. 16) that sj(νE, µ) = maxl{|Sj
l (νE) −
Sj
l (µ)|} tends to zero as j tends to inﬁnity, and yet we ﬁnd that the second summation at rhs,
j = Pj
Σ0
l (µ)| is not inﬁnitesimal, but it seems to converge to a positive value:
therefore, we cannot conclude from these estimates that σj(µ) converges to σE. We attribute

l (νE) − Sj

l=1 |Sj

26

 1

 0.1

 0.01

0
Σ

 
 
 
;
)
µ

,
E

j

ν
(
s
 
 
 
 
;
)
E

j

σ
,
)
µ
(
σ
(
d

j

 0.001

 10

 100

 1000

j

 10000

 100000

Figure 16: Quantities Σ0
j (red), sj(νE, µ) (green) and d(σj(µ), σE) (blue) versus matrix index j.
Lines are merely to guide the eye and connect data at exponentially spaced values of j. See text
for deﬁnition and discussion.

this to the fact that the majorization made in eq. (68) is too crude, with respect to the ﬁne
properties of σj(µ).

We therefore need to compute numerically the Hutchinson distance d(σj (µ), σE). This can
be done via an equivalent form of the deﬁnition (15), which considers the distribution functions

of the two measures: for any measure η let F (η; x) =R χ(0,x](y) dη(y). The Hutchinson distance

becomes an integral of the absolute diﬀerence of the distribution functions:

d(σj (µ), σE) =Z 1

0 |F (σj (µ); x) − F (σE; x)| dx.

(69)

It is apparent that F (σj (µ); x) is a piece–wise constant function, which permits to split [0, 1]
into intervals over which F (σj(µ); x) is constant and the diﬀerence F (σj(µ); x) − F (σE; x) has a
ﬁxed sign. The integral in eq. (69) so becomes a ﬁnite sum of integrals which can be explicitly
computed in terms of elementary functions. The results obtained in this way are displayed in
Figure 16. We observe a slow convergence towards zero of the distance d(σj (µ), σE) which is
again dominated by a power–law:

Conjecture 6 Convergence of the sequence of measures σj (µ) to σE is power–law: there exist
two positive constants A, B such that the Hutchinson distance veriﬁes d(σj (µ), σE) < Aj−B

We conclude this work by showing that our numerical data are fully consistent with the the-
oretical fact that stronger convergence properties do not hold. For instance, power asymptotics,
i.e. γj/4j → α, with 0 < α < ∞, can be easily seen to be equivalent to convergence of the series
Σ3, whose partial summation is deﬁned, with other quantities, as follows:

Σ1

j =

Σ2

j =

j

j

Xl=1
Xl=1

|al − al−1|;

|1 − 16 a2
l |;

27

(70)

(71)

Σ1
j
Σ2
j
Σ3
j
j/10

 10000

 1000

 100

 10

 1

 0.1

 1

 10

 100

 1000

 10000

 100000

j

Figure 17: Quantities Σm
j
comments.

(m = 1, 2, 3) versus matrix index j. See text for deﬁnition and

Σ3
j = −

j

Xl=1

(log(al) + log(4)).

(72)

Convergence of the other series is regulated by the following “collection” theorem (reviewed

e.g. in [52, 53]):

Theorem 5 If Σ2 is ﬁnite, then the measure µ is absolutely continuous with respect to Lebesgue
and its density belongs to Szeg¨o class. Convergence of Σ2 implies convergence of Σ1. In turn, this
latter implies that µ is absolutely continuous with respect to Lebesgue and its density is strictly
positive and continuous on (0, 1).

We expect divergence of the three series. This fact is clearly observed in Figure 17. We
also observe numerically that divergence of Σ3 is power–law with exponent less than one. Since
Σ3

j = jδj (see eq. (25) and Fig. 7), this is consistent with regularity of the measure µ.

9 Conclusions

As remarked by Totik [51], the Nevai class seems to contain all sorts of measures.
In fact,
it contains pure point measures [54] as well as singular measures [33]. In addition, given any
measure whose support is [0, 1], Totik has shown that there is a second measure, absolutely
continuous with respect to the ﬁrst, which is in Nevai class. Therefore, it might seem that
enlisting Minkowski’s measure in this family is just another addition of minor interest. We
think that this attitude is reductive, for two reasons. Firstly, since Minkowski’s measure encodes
the distribution of the rationals [55] and their inner structure, proving that it does belong to the
Nevai class might possibly reveal this structure from a diﬀerent perspective. Secondly, no spectral
characterization of Nevai class is known. Minkowski’s measure falls short of verifying Rakhmanov
suﬃcient condition [42, 40] i.e. almost everywhere positivity of the Radon Nikodyn derivative
of µ with respect to Lebesgue—which is probably the widest suﬃcient condition known so far
to this scope. Perhaps this fact is to be welcomed: Minkowski’s measure could be the model of
a possible widening of Rakhmanov condition. This investigation, as well as the simpler proof of
regularity of Minkowski’s measure, will be the object of future publications.

28

References

[1] N.I. Akhiezer, The Classical Moment Problem, Hafner, New York, NY. (1965).

[2] G. Alkauskas, The Minkowski question mark function: explicit series for the dyadic period
function and moments, Math. Comp. 79 (2010) 383–418; Addenda and corrigenda, Math.
Comp. 80 (2011) 2445–2454.

[3] G. Alkauskas, Semi-regular continued fractions and an exact formula for the moments of the

Minkowski question mark function, Ramanujan J. 25 (2011) 359–367.

[4] V.V. Andrievskii, H.-P. Blatt, On Lp -discrepancy of signed measures, Constr. Approx. 18,

19–36 (2002).

[5] V.V. Andrievskii, H.-P. Blatt, Discrepancy of signed measures and polynomial approximation,

Springer Monographs in Mathematics. Springer-Verlag, New York, (2002).

[6] V.V. Andrievskii, H.-P. Blatt, and H.N. Mhaskar A local discrepancy theorem, Indag.

Mathem., N.S. 12 (200l) 23–39.

[7] V. I. Arnold et A. Avez, Probl´emes ergodiques de la m´ecanique classique, Gauthier-Villars,

Paris (1967).

[8] M. F. Barnsley, Fractals Everywhere, Academic Press, New York, (1988).

[9] M. F. Barnsley and S. G. Demko, Iterated function systems and the global construction of

fractals, Proc. R. Soc. London A 399 (1985) 243–275.

[10] M. F. Barnsley, Fractal functions and interpolation, Constr. Approx. 2 (1986) 303–329.

[11] M. F. Barnsley, A. Vince, Fractal Continuation, Constr. Approx. 38 (2013) 311–337.

[12] D. Bessis and G. Mantica, Construction of Multifractal Measures in Dynamical Systems

from their Invariance Properties, Phys. Rev. Lett. 66 (1991) 2939-2942.

[13] C. Bonanno, S. Isola, Orderings of the rationals and dynamical systems, Colloq. Math. 116

(2009) 165–189;

[14] M. Degli Esposti, S. Isola, Stefano, A. Knauf, Generalized Farey trees, transfer operators

and phase transitions, Comm. Math. Phys. 275 (2007) 297–329.

[15] A. Denjoy, Sur une fonction r´eelle de Minkowski, J. Math. Pures Appl. 17 (1938) 105–151.

[16] Z. Dresse and W. Van Assche, Orthogonal polynomials for Minkowski’s question mark func-

tion, J. Comput. Appl. Math. 284 (2015) 171–183.

[17] S. Elhay, G. H. Golub, J. Kautsky, Jacobi matrices for sums of weight functions, BIT 32

(1992) 143–166.

[18] P. Erd¨os and P. Turan, On the distribution of roots of polynomials, Annals of Math. 51

(1950) 105–119.

[19] W. Gautschi, Orthogonal polynomials: computation and approximation. Numerical Math-
ematics and Scientiﬁc Computation. Oxford Science Publications. Oxford University Press,
New York, (2004)

[20] W. Gautschi, A survey of Gauss–Christoﬀel quadrature formulae, in E. B. Christoﬀel, the
inﬂuence of his work in mathematics and the physical sciences, P. L. Butzer and F. Feh´er,
eds., 72–147, Birkh¨auser, Basel (1981).

[21] J. S. Geronimo, W. Van Assche, Orthogonal polynomials with asymptotically periodic recur-

rence coeﬃcients, J. Approx. Theory 46 (1986) 251–283 .

29

[22] J. S. Geronimo, W. Van Assche, Orthogonal polynomials on several intervals via a polynomial

mapping, Trans. Amer. Math. Soc. 308 (1988) 559–581.

[23] Ya. L. Geronimus, On certain asymptotic properties of polynomials, Mat. Sbornik N. S. 23

(1948) 77–88.

[24] G. H. Golub and J. H. Welsch, Calculation of Gauss quadrature rules, Math. Comput. 23

(1969) 221–230.

[25] W. B. Gragg and W. J. Harrod, The numerically stable reconstruction of Jacobi matrices

from spectral data, Numer. Math. 44, 317–335 (1984).

[26] M. C. Gutzwiller, B. B. Mandelbrot, Invariant multifractal measures in chaotic Hamiltonian

systems, and related structures, Phys. Rev. Lett. 60 (1988) 673–676.

[27] M. C. Gutzwiller, Bernoulli sequences and trajectories in the anisotropic Kepler problem, J.

Mathematical Phys. 18 (1977) 806–823.

[28] J. Hutchinson, Fractals and self–similarity, Indiana J. Math. 30 (1981) 713–747.

[29] T. Jordan, T. Sahlsten, Fourier transforms of Gibbs measures for the Gauss map, preprint,

arXiv:1312.3619

[30] M. Kessebohmer, B. O. Stratmann, A multifractal analysis for Stern-Brocot intervals, con-

tinued fractions and diophantine growth rates, J. Reine Angew. Math. 605 (2007) 133–163.

[31] M. Kessebohmer, B. O. Stratmann, Fractal analysis for sets of non- diﬀerentiability of

Minkowski’s question mark function, J. Number Theory 128 (2008) 2663–2686.

[32] J. R. Kinney, Note on a singular function of Minkowski, Proc. Amer. Math. Soc. 11 (1960)

788-794.

[33] D. S. Lubinsky, Singularly continuous measures in Nevai’s class, Proc. Amer. Math. Soc.

111 (1991) 413–420.

[34] A. Magnus, Recurrence coeﬃcients for orthogonal polynomials on connected and noncon-
nected sets, in Pad´e approximation and its applications (Proc. Conf., Univ. Antwerp, Antwerp,
1979), Lecture Notes in Math. 765, 150–171, Springer, Berlin, (1979).

[35] G. Mantica, On Computing Jacobi Matrices associated with Recurrent and M¨obius Iterated

Functions Systems, J. Comp. and Appl. Math. 115 (2000) 419–431.

[36] G. Mantica, Direct and inverse computation of Jacobi matrices of inﬁnite IFS, Numerische

Math. 125 (2013) 705–731.

[37] G. Mantica, Orthogonal polynomials of equilibrium measures supported on Cantor sets, J.

Comp. App. Math. 290 (2015) 239–258.

[38] F. Mendivil, A generalization of IFS with probabilities to inﬁnitely many maps, Rocky Moun-

tain J. Math. 28 (1998) 1043–1051.

[39] H. Minkowski, Zur Geometrie der Zahlen, Verhandlungen des

III

Internationalen

Mathematiker-Kongresses, Heidelberg, (1904) 164–173.

[40] A. M´at´e, P. Nevai, Paul and V. Totik, Asymptotics for the ratio of leading coeﬃcients of

orthonormal polynomials on the unit circle, Constr. Approx. 1 (1985) 63–69.

[41] T. Persson, On a problem by R. Salem concerning Minkowski’s question mark function,

preprint arXiv:1501.00876

[42] E. A. Rakhmanov, The asymptotic behavior of the ratio of orthogonal polynomials. II, Mat.

Sb. (N.S.) 118 (1982) 104–117.

30

[43] H. H. Rugh, Intermittency and regularized Fredholm determinants, Invent. Math. 135 (1999)

1–24.

[44] E. B. Saﬀ, Logarithmic potential theory with applications to approximation theory, Surveys

in Approx. Theory 5 (2010) 165–200.

[45] R. Salem, On some singular monotonic functions which are strictly increasing, Trans. Amer.

Math. Soc. 53 (1943) 427–439.

[46] C. Series, The modular surface and continued fractions, J. London Math. Soc. 31 (1985)

69–80.

[47] J. A. Shohat, On a certain formula of mechanical quadratures with non-equidistant ordinates,

Trans. Amer. Math. Soc. 31 (1929) 448–463.

[48] H. Stahl, V. Totik, General Orthogonal Polynomials, Cambridge University Press, Cam-

bridge (2010).

[49] G. Szeg¨o, Orthogonal polynomials, Am. Math. Soc. Colloq. Publ. 23 (1939).

[50] V. Totik, Metric properties of harmonic measures, Mem. Am. Math. Soc. 184 n. 867, (2006).

[51] V. Totik, Orthogonal polynomials, Surv. Approx. Theory 1 (2005) 70–125.

[52] W. Van Assche, Asymptotics for orthogonal polynomials and three-term recurrences, in Or-

thogonal Polynomials; Theory and Practice, NATO-ASI series C 294, 435–462 (1990).

[53] W. Van Assche, Asymptotics for orthogonal polynomials, Lect. Notes Math. 1265 Springer,

Berlin (1987).

[54] W. Van Assche, A. P. Magnus, Sieved orthogonal polynomials and discrete measures with

jumps dense in an interval, Proc. Amer. Math. Soc. 106 (1989) 163-173.

[55] P. Viader, J. Parad´ıs and L. Bibiloni, A new light on Minkowski’s ?(x) function, J. Num.

Th. 73 (1998) 212–227.

[56] S. Yakubovich, On some Rajchman measures and equivalent Salem’s problem, Commun.

Math. Anal. 14 (2013) 28–41.

[57] S. Yakubovich, The aﬃrmative

solution to Salem’s problem revisited,

preprint

arXiv:1501.00141.

31

