Astronomy & Astrophysics manuscript no. main˙Joseph
March 3, 2016

c(cid:13) ESO 2016

Multi-band morpho-Spectral Component Analysis Deblending Tool

(MuSCADeT): Deblending colourful objects

R. Joseph1, F. Courbin1, and J.-L. Starck2

1 Laboratoire d’astrophysique, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Observatoire de Sauverny, CH-1290 Versoix,

2 Laboratoire AIM, CEA/DSM-CNRS-Universite Paris Diderot, Irfu, Service d’Astrophysique, CEA Saclay, Orme des Merisiers,

Switzerland

91191 Gif-sur-Yvette, France

6
1
0
2

 
r
a

M
 
1

 
 
]

M

I
.

h
p
-
o
r
t
s
a
[
 
 

1
v
3
7
4
0
0

.

3
0
6
1
:
v
i
X
r
a

Received ; accepted

ABSTRACT

We introduce a new algorithm for colour separation and deblending of multi-band astronomical images called MuSCADeT which is
based on Morpho-spectral Component Analysis of multi-band images. The MuSCADeT algorithm takes advantage of the sparsity of
astronomical objects in morphological dictionaries such as wavelets and their diﬀerences in spectral energy distribution (SED) across
multi-band observations. This allows us to devise a model independent and automated approach to separate objects with diﬀerent
colours. We show with simulations that we are able to separate highly blended objects and that our algorithm is robust against SED
variations of objects across the ﬁeld of view. To confront our algorithm with real data, we use HST images of the strong lensing galaxy
cluster MACS J1149+2223 and we show that MuSCADeT performs better than traditional proﬁle-ﬁtting techniques in deblending the
foreground lensing galaxies from background lensed galaxies. Although the main driver for our work is the deblending of strong
gravitational lenses, our method is ﬁt to be used for any purpose related to deblending of objects in astronomical images. An example
of such an application is the separation of the red and blue stellar populations of a spiral galaxy in the galaxy cluster Abell 2744.
We provide a python package along with all simulations and routines used in this paper to contribute to reproducible research eﬀorts.
Codes can be found at http://lastro.epfl.ch/page-126973.html.
Key words. Methods: data analysis – Gravitational lensing: strong – Galaxies: surveys – stellar populations

1. Introduction

Astronomical objects are often seen merged or blended on the
plane of the sky. This blending can be apparent, because objects
at diﬀerent distances are seen in projection on the plane of the
sky or, real, because diﬀerent objects at the same distance are
physically overlapping.

Whatever the reason for the blending, reliable deblending
techniques are mandatory for astrophysical projects to meet their
scientiﬁc objectives. Among the many possible examples, blends
of galaxies of diﬀerent colours can impact performances of pho-
tometric redshift algorithms (e.g. P´erez-Gonz´alez et al. 2010;
Bellagamba et al. 2012; Parker et al. 2012; Hsu et al. 2014) and
conclusions of stellar populations studies (e.g. Yan et al. 2014).
Obviously, blending also aﬀects the determination of morpho-
logical properties of astronomical objects, for example the shape
measurement of faint galaxies in weak lensing cosmological sur-
veys (e.g. Chang et al. 2013; Arneson 2013). In strong gravita-
tional lensing, deblending of the foreground lensing object from
the background lensed sources is essential, for example as shown
at galaxy scale by Gavazzi et al. (2007) and at cluster-scale by
Massey et al. (2015). This is true for at least two reasons. First,
one needs to map the visible mass in the lensing object precisely,
either to use it as a prior to guide the lens modelling or to infer
the mass-to-light ratio in the lens. Second, the image of lensed
source must be isolated in the best possible way. Any faint ex-
tended arc-like structure, clump, or star-forming region must be
seen precisely with minimum light contamination from the lens-
ing object. Our ability to constrain the mass model is completely

driven by the amount of details seen in the lensed source, which
represent as many observational constraints.

Many of the current techniques to deblend astronomical ob-
jects are limited to analytical modelling of their light distribution
either in single band (e.g. PSFex, Bertin 2011) or multi bands,
sometimes including a simultaneous ﬁt of many overlapping ob-
jects (Megamorph; Vika et al. 2013, 2015). Alternatively, some
methods make use of high resolution images to ﬂag blended ob-
jects and then measure them at diﬀerent wavelengths using im-
ages of lower spatial resolution (e.g. Laidler et al. 2007). Popular
softwares like Sextractor (Bertin & Arnouts 1996) use image
segmentation to separate blends, which is a technique that was
further improved by Zheng et al. (2015). Other techniques in-
clude machine learning, recently used in the area of strong grav-
itational lensing to subtract the light of bright galaxies and to
unveil possible lensed background objects without invoking any
analytical representation of the galaxies to subtract. This tech-
nique is based on a principal component decomposition of the
galaxy images using large samples of single-band imaging data
(Joseph et al. 2014). A step forwards is to use multi-band im-
ages to separate the objects in the lens plane and source plane,
also using the colour information. Recent methods have started
to make use of multi-band information and combine source po-
sition from high resolution images with proﬁle ﬁtting to deblend
lower resolution bands (Merlin et al. 2015). Another example is
given in Hocking et al. (2015) where neural networks are used
to identify objects with diﬀerent colours in multi-band images.
With the current burst of wide-ﬁeld sky surveys (DES, KIDS,
HSC, Euclid, LSST and WFIRST), data in many optical and

1

R. Joseph et al.: MCA-based lens-source separator

near-IR bands will become available. The present paper de-
scribes a technique taking advantage of these multi-band data to
address the deblending problem using both colour information
and a spatial prior, but not involving any analytical modelling
of the light distribution of the lensed and lensing objects. Our
work is based on a multi-channel extension of the morphological
component analysis (MCA) presented in Starck et al. (2004). We
illustrate the performances of the algorithm with numerical ex-
periments and with real HST data of strong gravitational lenses.
This paper is organised as follows: In section 2, we intro-
duce the mathematical model we use to understand and sep-
arate objects with diﬀerent colours. In section 3, we describe
the mathematical technique used to solve the problem of colour
separation in our approach, that is to say morphological com-
ponent analysis. In section 4, we detail our implementation of
the MuSCADeT algorithm. Section 5 shows the performance of
our algorithm on simulations that test realistic problems encoun-
tered in deblending. We apply our method to real astronomical
images from the Hubble Space Telescope in section 6 with the
galaxy clusters MACS J1149+2223 and Abell 2744. We com-
pare our results with current model ﬁtting methods. Section A
provides useful information to reproduce our results from the
code we made freely available.

2. Deblending and strong lensing
2.1. The source separation problem
We assume the observed data {yi}i=1,..,Nb in the band i can be rep-
resented as

yi[k] =

si, jo j[k] + zi[k],

(1)

No(cid:88)

j=1

Ns(cid:88)

where o j are the diﬀerent observed sources, si, j is the contri-
bution of the j-th source in the observation yi, No the number
of sources, Nb the number of bands, zi is an additive Gaussian
noise, k is the pixel index (k = 1...Np), and Np is the number of
pixels.

The parameter s∗, j corresponds to the spectral energy distri-
bution (SED) of the source o j. The deblending problem consists
in ﬁnding the diﬀerent objects o j, which is somewhat compli-
cated since their SED are not known and even the number of
objects is not known.

However, several galaxies may have similar colour proper-
ties and, therefore, share the same SED, so we can simplify Eq. 1
by considering the data containing only Ns groups of sources,
such as, for instance early- and late-type galaxies, and we can
restrict the deblending problem to only extract these two groups.
We note x j ( j = 1..Ns) the image which contains the sum of all
l=1 ol[k], where

objects belonging to the group j, i.e. x j[k] = (cid:80)N( j)

o

is the number of sources in the group j. We can write

N( j)
o

yi[k] =

ai, jx j[k] + zi[k].

(2)

j=1

Even if this equation looks very similar to Eq. 1, it is in fact sim-
pler since Ns is smaller than No. As a given component x j con-
tains several astrophysical sources, it also gives us more statistics
to derive its SED. This linear mixture model can be recast in the
following matrix form

Y = AX + Z,

(3)

2

Fig. 1. Illustration of the blind source separation in the case of
two sources. To make the ﬁgure simple, the images in each band
are represented as lines in the Y matrix. Sources are lines in the
X matrix. On the sketch we ﬁgure a red object in the ﬁrst source
and two blue objects in the second source. Matrix A contains the
mixing coeﬃcients that allow various combinations of elements
of X to produce Y.

where Y is a Nb × Np matrix, A is the SED mixing matrix, and X
is the Ns × Np matrix, which contains the components x j.
To sum up, we consider that each band is a weighted mix of
ns colour components. In the statistical literature, each compo-
nent is called a source (and it should not be mixed with an astro-
physical source). This general problem is called a blind source
separation problem (BSS), i.e. estimating both A and X knowing
only Y. The weight for a given source is the value of the associ-
ated SED at the corresponding wavelength. Figure 1 illustrates
the BSS in the case of two sources relative to two populations of
galaxies (red and blue galaxies in the ﬁgure).

2.2. Determination of the mixing matrix A
The A matrix is central to modelling of multi-band data as it de-
scribes the contribution of the diﬀerent sources to the images
taken at diﬀerent wavelengths. In practice, the elements of A
are the SEDs of the objects in the sources X. They can be as-
sumed, for example as template spectra for objects of a given
type, or they can be measured because spectroscopic data are
available for at least some of the objects in the ﬁeld of view. In
most cases, however, the matrix A needs to be estimated solely
from the multi-band imaging data, Y. In order to do this, we use
a method based on a principal component analysis (PCA; Jolliﬀe
1986) of the data.
We consider the multi-band data as an ensemble of vec-
tors {yi=1..Nb[k]}, where the pixel values in band i at the spa-
tial location k are stored in yi[k], as previously. In other words,
{yi=1..Nb[k]} is the measured SED at location k.
Following our deﬁnition of a source, two pixels belonging to
a given source x have proportional SEDs. To build the mixing
matrix A, one solution is to preselect obvious objects belong-
ing to a same source and to average their SEDs, thus approxi-
mating the mixing coeﬃcients corresponding to their source. A
more subtle way to do this is to perform a principal component
analysis of all SEDs belonging to bright objects and to look for
proportional vectors. The details of this procedure can be sum-
marised as follows:
– We select the brightest objects in all bands and perform the
PCA of the SEDs at pixel locations with high signal to noise.
In practice, this is done by applying a wavelet ﬁltering of all
bands. Also, to save computation time, we rebin images to
64 × 64 pixels in size.

– We perform a clustering analysis of the ﬁrst two PCA com-
ponents: the linearity and orthogonality of the PCA decom-
position implies that proportional vectors see their respec-
tive PCA coeﬃcients distributed along the same hyperplane

R. Joseph et al.: MCA-based lens-source separator

therefore a tensorial product of a spectral dictionary S j with the
spatial dictionary Ψ j, i.e. Φ j = S jΨ j

3.2.1. Spatial dictionary
In the case of strong lensing, the diversity between the com-
ponents is mainly related to a diﬀerent spectral morphology.
Therefore we can reasonably use the same spatial dictionary,
and in this strong lensing application we use the starlet dictio-
nary (Starck et al. 2007). Starlet transform is an isotropic, un-
decimated wavelet transform that is computed using consecutive
convolutions by a B−spline proﬁle as a scaling function (Starck
& Murtagh 2007). The resulting starlet representation is an over-
complete set of coeﬃcients that represent variations in an image
at diﬀerent scales, and is particularly suited to represent astro-
nomical images (Starck & Murtagh 2006).

3.2.2. Morpho-spectral dictionary
We note Ψ the starlet dictionary, we have x j = Ψα j where α j
are the starlet coeﬃcients of the jth source. A good choice for
the morpho-spectral dictionary is to take Φ j = a jΨ, where a j
is the jth column of the matrix A. The data attachment term for
multichannel data can be written as

Φ jα j (cid:107)2=(cid:107) Y − J(cid:88)

a jΨα j (cid:107)2

j=1

a jx j (cid:107)2=(cid:107) Y − AX (cid:107)2 .

(5)

L = (cid:107) Y − J(cid:88)
= (cid:107) Y − J(cid:88)

j=1

j=1

The multichannel MCA hence consists in changing the data at-
tachment term only, and we need to solve

(cid:107) Ψ∗x j (cid:107)0

s.t. (cid:107) Y − AX (cid:107)2≤ σ.

(6)

J(cid:88)

j=1

min
X

3.2.3. Lagrangian form and positivity
The sparse recovery problem can be formulated under an aug-
mented Lagrangian form

(cid:107) Y − AX (cid:107)2 +

min
X

λ j (cid:107) Ψ∗x j (cid:107)0

(7)

J(cid:88)

j=1

and we can add a positivity constraint to the solution, so we need
to solve

in the PCA space. In other words, vectors with proportional
SEDs have their ﬁrst two components, PC1 and PC2, dis-
tributed along lines in the PC1-PC2 space, as illustrated in
Fig. 2,

– We identify the SEDs that have proportional PC1 and PC2
coeﬃcients and average them. Coeﬃcients that are judged
too faint or too ambiguous (i.e. they could be a mix of both
sources) are rejected,

– We store the resulting mean SEDs as a column in the A ma-

trix.

This algorithm shows good results in identifying objects with
diﬀerent dominant colours (Fig. 2), but its capabilities in terms
of deblending are rather limited when distinct sources spatially
overlap. The above PCA analysis is only a spectral analysis. The
MCA method proposed in this paper combines the strengths of
the morphological analysis and spectral analysis to design a re-
liable deblending algorithm.

3. Morphological component analysis
The morphological component analysis (MCA) method (Starck
et al. 2004; Starck et al. 2010) allows us to separate several com-
ponents in a given image based on their morphological diversity.
Indeed, it was shown that it is possible to disentangle two (or
more) signals mixed into one observable, this is only based on
the fact that each of those signals can be sparsely represented
in their respective data representation domains, called dictionar-
ies, but not in the other’s. For instance, one could separate a
periodic signal from a Gaussian proﬁle in an image based on
Fourier transform (associated with the periodic signal) and the
wavelet transform (for the Gaussian proﬁle). The projection of
the mixing over the Fourier dictionary shows enhanced contribu-
tion from the periodic component whereas wavelet space shows
higher coeﬃcients for the Gaussian component.

sented, such that x = Φα = (cid:80)

3.1. Separation using a sparsity prior
MCA is based on the concept of sparse signal representation.
A signal is sparse in a dictionary Φ when it can be well repre-
i φiαi and only few coeﬃcients
α are diﬀerent from zero. Some dictionaries, such as Fourier
or wavelets, have implicit fast transformation and reconstruction
operators that allows us to derive the coeﬃcients α from x (and
also to derive x from α) eﬃciently without having the elements
of matrix Φ in memory. In inverse problems, a sparse solution
is imposed by adding an (cid:96)0-norm penalisation term to the data
ﬁdelity attachment term. MCA is an iterative algorithm, which
separates a single image Y into J components x j, by solving

J(cid:88)

s.t. (cid:107) Y − J(cid:88)

min
x1,...,xJ

(cid:107) Φ∗x j (cid:107)0

j=1

j=1

where Φ∗x = α and σ is the noise standard deviation of the noise.
Full details can be found in Starck et al. (2010). This method has
been used to extract ﬁlamentary clouds in Herschel data (Andr´e
et al. 2010) or, more recently, to improve SNIa detection in the
SuperNova Legacy Survey data set (M¨oller et al. 2015).

3.2. Multi-band dictionaries
As we have multi-band data, we need to use morpho-spectral
diversity. The dictionary Φi related to a given component xi is

x j (cid:107)2≤ σ,

(4)

(cid:107) Y − AX (cid:107)2 +

min
X

λ j (cid:107) Ψ∗x j (cid:107)0

s.t. ∀ j, x j ≥ 0,

(8)

J(cid:88)

j=1

where λ j accounts for the sparsity of each component x j in
its own morpho-spectral dictionary. The next section describes
how this equation can be solved.

strong lens

4. MuSCADeT algorithm
The
algorithm
(MuSCADeT) is an extension of the MCA algorithm, con-
sisting in applying at each iteration three main steps:
1. Perform a gradient step: U = X(n) + µAt(Y − AX(n)).

sparse deblending iterative

3

R. Joseph et al.: MCA-based lens-source separator

Fig. 2. Illustration of the PCA colour selection. Left: HST image of the ”Refsdal lens” in the galaxy cluster MACS J1149.6+2223.
Middle: distribution of the ﬁrst two PCA coeﬃcients. The red and green dots correspond to the coeﬃcients attributed to the ﬁrst and
second sources by MuSCADeT, respectively. Blue dots are rejected coeﬃcients. Right: corresponding spatial distribution of colours
as detected via PCA.

2. Solve for each j: minx(n+1)

(cid:107) u j − x(n+1)
and set to zero negative entries in x(n+1)

j

j

|| + λ j (cid:107) Ψ∗x(n+1)
.

j

(cid:107)0,

j

j

In this algorithm µ is the gradient step, derived from the 2-

3. Decrease λ j.
norm of matrix A (Higham 1992) such that µ = 2/||A||2.
This algorithm is also directly related to the proximal
forward-backward algorithm (Combettes & Wajs 2005). A very
nice aspect of this algorithm is that the minimisation involved
in the second step do not require any iteration, and is obtained
by x(n+1)
= ∆Ψ,λ j(u j), where ∆Ψ,λ j is the operator which per-
forms the starlet transform, hard thresholds the starlet coeﬃ-
cients, and reconstructs an image from the thresholded coeﬃ-
cients. Here, λ j is the threshold that allows us to select only
coeﬃcients that are signiﬁcant enough to represent the signal.
Thresholds are updated at each iteration as described in the fol-
lowing paragraphs. Full details can be found in Starck et al.
(2010). Pseudo-algorithm 1 shows the principle of this itera-
tive scheme. MuSCADeT is an iterative process that alternates
between a gradient step (line 6) and a ﬁltering of the components
in transformed space through iterative hard thresholding (line 9)
.

˜X ← 0
for 0 < i ≤ Niter do

Algorithm 1 MuSCADeT algorithm
1: procedure MuSCADeT(Y, K, A, J, Niter)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13: end procedure

R = µ(AT (Y − A ˜X))
Update λ
˜X ← ˜X + R
λ ← mi(
λ−K
Niter−i−6 , MOM(X))
for 0 < j ≤ J do
˜x j ← ∆Ψλ j( ˜x j)
end for

end for
return ˜X

4.1. Thresholding strategy
Thresholding aims at selecting the coeﬃcients in transformed
space that allow us to reconstruct the desired signal only. In this

4

case, this means that for a given component, we want to select
coeﬃcients above noise level that accounts for this component
and not for the others. It is therefore crucial to devise an adequate
method to adapt thresholds at each iteration of algorithm 1.

Since each iteration moves our solution for components
closer to a good separation, the thresholds have to be decreased
to capture fainter and fainter structures. A classical way is to
operate a linear decrease for instance, where values for λ j are
linearly sampled between an initial threshold chosen high above
noise levels and a sensitivity value K. In general, K is chosen
between three and ﬁve. The sensitivity value three allows for
good completeness of detected coeﬃcients and ﬁve ensures a
selection that is free from noise-related coeﬃcients. Noise lev-
els are computed using median absolute deviation (Donoho &
Johnstone 1994). Although linear or exponential laws are well
suited to such problems (Starck et al. 2004), we choose here to
rely on a more adaptive strategy based on minimum of maxi-
mums (MOM, see Bobin et al. 2007):

At each iteration, we simply estimate the maximum coeﬃ-
cient of each component in its own morpho-spectral dictionary
and choose the smallest maxima plus a margin as a threshold. If
the result is smaller than the threshold given by a linear decrease,
the threshold is updated with the value estimated from MOM as
illustrated in line 7 of the MuSCADeT algorithm (1). Full details
on this thresholding scheme can be found in Starck et al. (2010).

5. Tests on simulations
In this section, we present several tests conducted on simulated
multi-band images that emulate realistic problems. We show
that MuSCADeT is able to separate highly blended sources and
is robust to the approximation made that several astronomical
sources (e.g. galaxies in a cluster) with similar but, not identical,
SEDs can be considered a single source.

5.1. Simulations

In all following simulations we generate objects with Gaussian
proﬁles and realistic SEDs. For the ﬁrst two simulations, all
SEDs were extracted from real HST observations of the galaxy
cluster MACS J1149+2223 cluster (Kelly et al. 2015) using the
PCA method described in Sect. 2.2. Each simulation comprises
seven bands. We also add a white Gaussian noise with standard

R. Joseph et al.: MCA-based lens-source separator

Fig. 3. Source separation with MuSCADeT in the case of a simple colour separation with SEDs estimated from PCA. From left to
right: original simulated image of colour sources, ﬁrst and second components (elements of X in eq. 3) as extracted by MuSCADeT,
and the residual image after subtracting both components from the original image.

Fig. 4. Separation of blended sources with SEDs estimated from PCA (as in Fig. 3).

Fig. 5. Left: part of an HST image of the galaxy cluster MACS J1149+2223, where the four objects used to extract SEDs are
indicated with red contours. Middle: extracted SEDs. Each curve corresponds to the SEDs of the galaxies circled in red in the
ﬁrst panel. Right: simulated SEDs. The seven red SEDs are used to produce the upper row of galaxies in Fig. 6. The blue SEDs
correspond to the lower row of galaxies (see text).

deviation σ = 0.01. An example of the impact of higher noise
levels on our image separation is given in appendix B.

We ﬁrst apply MuSCADeT to data with four red objects with
exactly the same SED and four blue objects with exactly the
same SED. All objects have elliptical Gaussian proﬁles. Three
of the simulated bands are used to produce the colour image in
Fig. 3. Results of the separation after 100 iterations of MuSCADeT
are shown in the other panels of ﬁg 3. We observe no contam-
ination between sources since no structure contaminates either
component. Since the residuals present no structure, we also
conclude that each component has been fully reconstructed.

The second simulation tests the deblending capacities of our
algorithm in the ideal case where there is no SED variation be-

tween objects of a same component. We generate an extended el-
liptical Gaussian proﬁle at the centre of the image aﬀected with
a red SED. Thirteen blue proﬁles are evenly spread between the
centre and edges of the image such that proﬁles at the centre are
completely blended. Results of the separation are shown in Fig. 4
along with a colour image of our simulated objects. No con-
tamination between sources is visible either and residuals show
no structure. We see in particular no diﬀerence between blue
sources at the centre of the image (the most blended ones) and
blue sources on the edges (less blended), meaning that the de-
blending of each proﬁle is successful whether a proﬁle is highly
blended or not. We used 200 iterations of MuSCADeT to produce
this result.

5

R. Joseph et al.: MCA-based lens-source separator

Fig. 6. Results of a separation of sources with poorly known SEDs (as in Fig. 3).

The last simulation tests the robustness of our algorithm to
SED variation across objects from a same component. To ac-
count for realistic SED variation, we extracted the SEDs from
four red galaxies in the MACS J1149+2223 cluster (see 5),
which appear to have the same colour by integrating the ﬂux in
each galaxy proﬁle. The resulting SEDs can be seen in the mid-
dle panel of ﬁg 5. We recorded the slopes of the SEDs and gener-
ated a set of eight slopes linearly spread between the maximum
and minimum slope estimated. These slopes are then applied to
SEDs extracted from cluster MACS J1149+2223 via PCA (see
Fig. 5). This way, we have two sets of SEDs that account for
red and blue sources and that mimic a range of variations as ob-
served in real images. Sixteen Gaussian proﬁles (eight red, eight
blue) are then generated and each of them is associated with one
of the previously generated SEDs. The left panel of Fig. 6 shows
three bands of the simulated images as RGB images. Figure 6
shows a colour image of our simulated images and the result of
a separation by MuSCADeT. We see again that no structure ap-
pears in the residuals and no contamination is found between
components. However, the great similarity between SEDs from
diﬀerent components forced us to increase the number of itera-
tions of MuSCADeT to 5000 in order to obtain such results, thus
increasing computation time. In each, we used the full algorithm
described in this paper including an automated estimation of
SEDs through PCA.

6. Application to real data

6.1. Lens-source separation on MACS J1149+2223

We now apply MuSCADeT to real multi-band data and we com-
pare the performances to traditional model ﬁtting.

We use the deep HST data set of the galaxy cluster
MACS J1149+2223 (”Refsdal SN”; Kelly et al. 2015) to carry
out this experiment, we show bright cluster members producing
strongly lensed images of a distant spiral galaxies with clumpy
structures. Our goal is to separate the data into two sources con-
taining the foreground lens galaxies and background lensed ob-
ject(s). As the cluster contains many member galaxies and as the
background galaxy has complex structure, the deblending task is
challenging, making this data set a good test for our method.

MACS J1149+2223 has been observed with the ACS in
seven bands: F435W, F475W, F555W, F606W, F625W, F775W
and F814W (proposal ID: 12068, principal investigator: M.
Postman), providing a good spectral coverage for MuSCADeT to
work. The data are publicly available from the STScI website1

1 https://archive.stsci.edu/

6

and drizzled so that the combined frames in each band have the
same orientation and pixel scale.

We estimate both SEDs in the mixing matrix using our PCA
technique. The result after 2000 iterations of MuSCADeT is shown
in Fig. 7, where the two separated sources are shown in the mid-
dle panels. In the two lower panels of the ﬁgure, we also show
the result of the subtraction of source 1 and source 2 from the
original data. The colour scale in these images is the same as
in the original data. The overall residual image, i.e. with both
sources subtracted from the data, is shown with ±5σ cut levels.
The source separation works very well, with the exception
of a few objects with ”green” SEDs. One such object is visi-
ble in the centre of the image, resulting in a signal in both red
and blue sources. This is an intrinsic limitation to our algorithm
that separates objects using a limited number of sources, each
one with its own SED. Although the SEDs do not need to be
known perfectly (as shown in our tests with simulated images),
objects with SEDs falling ”in between” the SEDs allocated to
each source, may lead to inaccurate separation. A possible miti-
gation strategy is to add extra sources to the decomposition with
for example a blue, a green, and a red SED. Deciding whether to
do this or not depends on the exact scientiﬁc application.

In our example, we do not take the PSF convolution into ac-
count. A variation of the PSF with wavelength can introduce
artefacts in the separation, especially for objects whose angu-
lar size is comparable with the size of the PSF. The central parts
of galaxies show such structures and, indeed, in the present data
small structures are seen in the residual image at the location of
the foreground galaxies. Introducing the PSF convolution can be
done in principle, and it might be needed at least for some ap-
plications, but at a cost of increased computation time and com-
plexity in the minimisation process.

6.1.1. Comparison with proﬁle ﬁtting

A popular way to carry out source separation in galaxy clusters is
to ﬁt two-dimensional proﬁles to the cluster members and to sub-
tract from the data. We apply such a procedure to the HST data of
the MACS J1149+2223 cluster and compare with MuSCADeT. In
this exercise, we identiﬁed nine red objects with elliptical pro-
ﬁles that we ﬁt using the galfit (Peng et al. 2002) software.
Each red object is ﬁtted with either one or two Sersic proﬁles
depending on its morphology. Fitting is performed in each of
the three bands used to build the colour image (F475W, F606W,
and F814W) using the same initial conditions. Since no PSF was
used in applying MuSCADeT to this cluster, we used a Dirac func-
tion as an input PSF for galfit. The result is presented in the

R. Joseph et al.: MCA-based lens-source separator

Fig. 7. Application of MuSCADeT to the MACSJ1149+2223 cluster. Top left: colour image generated using the F475W, F606W, and
F814W bands. Our goal is to separate the foreground cluster galaxies (red) from the background lensed galaxy (blue). Middle: the
two sources extracted with 2000 iterations of MuSCADeT. Bottom left: original image minus the blue source found by MuSCADeT.
Bottom right: same as the bottom left, with the red source subtracted. Top right: residual image obtained after subtraction of the two
estimated sources from the original data.

7

R. Joseph et al.: MCA-based lens-source separator

Fig. 8. Comparison between the MuSCADeT and that galfit separations. The original colour image of MACS J1149+2223 is shown
on the left, followed by the galfit subtraction of the galaxy members and the subtraction using MuSCADeT. The colour cuts are
exactly the same in all three images. The red ellipse in the middle panel indicates an area where the galfit ﬁt leads to under-
subtraction of a galaxy halo.

middle panel of Fig. 8 along with the MuSCADeT result. We note
that:

– Proﬁle ﬁtting leaves signiﬁcant artefacts in the central parts
of the ﬁtted galaxies even when a double Sersic model is
used.

– Proﬁle ﬁtting does not model the extended halos of galaxies
well, as shown in the circled region in middle panel of Fig. 8.
This is both because extended halos are not simple analytical
proﬁles and because the many background lensed structures
inﬂuence the ﬁt. In principle, these structures can be masked
but 1- designing the mask can be diﬃcult and is time con-
suming, 2- in some parts of the image there is no clean area
with no contamination by the background object. The mask
would take the majority of the data.

– The top left lensed image appears to be more blue af-
ter galfit’s run than with MuSCADeT. This could mean
that MuSCADeT performs badly at extracting extended halo.
However, it would imply that too much signal from the red
source has been attributed to the blue source. Therefore,
when subtracting the blue source from the original images
one would see holes in the extended proﬁles of the red galax-
ies that are not observed here (see lower left panel of Fig. 7).
This implies that galfit is overﬁtting the extend halo to
compensate for blue structures, as pointed out in the previ-
ous note, thus removing part of the ﬂux from blue sources.
– The human time involved in proﬁle ﬁtting can be a limiting
factor for large data sets. The user has to decide where to put
a galaxy and to ﬁnd a strategy to estimate the initial guesses
for the many parameters involved in the ﬁt. MuSCADeT is
fully automated procedure with only one parameter to be
chosen, i.e. the sensitivity value K involved in the threshod-
ing scheme.

6.2. Bulge-disk separation on spiral galaxy in Abell 2744

Another possible application of our algorithm is the separa-
tion of coloured disk and bulge components in a spiral galaxy.
To illustrate this, we use a spiral galaxy in the galaxy cluster
Abell 2744, which was imaged with the HST as part of the
Hubble Frontier Fields programme.

8

Abell 2744 was observed with the ACS in three bands:
F435W, F606W, and F814W, resulting in the colour image in
Fig. 9(Proposal ID: 11689, principal investigator: R. Dupke).
The data are publicly available from the STScI website2 and
drizzled so that the combined frames in each band have the same
orientation and pixel scale.

Spiral galaxies represent an obvious test bench for our algo-
rithm as they are composed of a red bulge of older stars and of a
blue disk dominated by young stars. The ability to separate both
colour components in an unbiased way allows us to trace stel-
lar populations in galaxies and/or highlight morphological rela-
tions between bulge and disk shapes. Numerous examples can be
found in the literature of studies where bulge and disk compo-
nents are separated morphologically, using proﬁle-ﬁtting tech-
niques featuring Sersic, exponential, or DeVaucouleurs func-
tions in either single or multiple bands (e.g. Vika et al. 2014;
Maltby et al. 2012; Pastrav et al. 2013; Kendall et al. 2011).

With MusCADeT, we are able to capture the morphology of
the young and old stellar populations of the spiral galaxy in
Abell 2744 under the single assumption that they do not dis-
play the same colour. Our decomposition in Fig. 9 shows an
elliptical red bulge with extended and smooth features along
the spiral arms, which elliptical proﬁle-ﬁtting methods would
fail to model. The separation of the blended blue and red com-
ponents in Fig. 9 is overall excellent except for slight cross-
contamination of the two colour channels due to features smaller
than the PSF size. Adding the PSF in our separation technique is
under development. However, even without this reﬁnement, the
decomposition presented in our example would be impossible to
achieve with proﬁle-ﬁtting techniques given the morphological
complexity of the galaxy.

7. Conclusion
We have developed a new model-independent tool to deblend the
images of astronomical objects based on their colour contrast.
This is made possible via modern techniques for image analysis
based on sparsity of objects in an appropriate dictionary.

More speciﬁcally, we created a morpho-spectral dictionary
combining Starlets and SEDs to separate images of galaxies with

2 https://archive.stsci.edu/pub/hlsp/frontier/

R. Joseph et al.: MCA-based lens-source separator

Fig. 9. Separation of the red and blue stellar populations in a spiral galaxy. From left to right we show the original HST colour
image of a spiral galaxy in the galaxy cluster Abell 2744, the same colour image after subtraction of the blue component estimated
with MuSCADeT, the colour image after subtraction of the red component estimated with MuSCADeT, and the residual image after
subtraction of both components. The three ﬁrst images have the same colour cuts. The residuals are shown with cut levels set to ﬁve
times the noise level in each colour channel.

diﬀerent colours. We show from simulated data that our algo-
rithm is robust against very strong blending as well as against
SED variations among objects belonging to the same colour
component (source) of our model. SED variations across the
ﬁeld result in an increase of the computing time by one order
of magnitude with respect to the ideal case where all objects in a
given source have the same SED. This does not hamper a reliable
source separation, however.

The method is successfully applied to the deep HST images
of the galaxy cluster MACS J1149+2223, in which we sepa-
rate the foreground red galaxies from background blue clumpy
lensed galaxies, and to Abell 2744, where we separate the red
and blue stellar populations of a spiral galaxy. This is done in an
automated way and with better eﬃciency that with standard pro-
ﬁle ﬁtting. All codes used to produce the results presented here
are made freely available for the sake of reproducible research
and to make our tool usable for the community.

Future developments of our method include accounting for
the PSF in each band and including explicit SED variations
across the ﬁeld of view. These SED variations multiply the com-
plexity of the problem by Np × Ns × Nb, but the eﬀect of the
increased complexity can likely be minimised by using sparse
priors and physical constrains on the SED proﬁles. Also, the in-
creased computation time resulting from the extra complexity
should be partially compensated by a reduced number of itera-
tions.

The deblending method described here was devised speci-
ﬁcally to address the problem of object deblending in the case
of strong lensing systems. Deblending is essential in this case
to see small and faint details in the lensed structures, which are
free of contamination by the bright foreground. The range of ap-
plications of the method is nevertheless much broader. Among
the numerous possible applications are the identiﬁcation of star-
forming regions in galaxies, model-independent bulge-disk de-
compositions of galaxies, or even the improvement of photomet-
ric redshift in large sky surveys where blending can be a serious
issue given the depth of the data.

Acknowledgements. This work is supported by the Swiss National Science
Foundation (SNSF), and by the European Community through grant PHySIS
(contract no. 640174) and DEDALE (contract no. 665044) within the H2020
Framework Program. The HST images used in this paper were obtained from
the Mikulski Archive for Space Telescopes (MAST). STScI is operated by the
Association of Universities for Research in Astronomy, Inc., under NASA con-
tract NAS5-26555. Support for MAST for non-HST data is provided by the
NASA Oﬃce of Space Science via grant NNX09AF08G and by other grants

and contracts. We would like to thank the members of the CosmoStat team for
useful discussions on inverse problem solving using sparse prior.

References
Andr´e, P., Men’shchikov, A., Bontemps, S., et al. 2010, A&A, 518, L102
Arneson, R. A. 2013, PhD thesis, University of California, Irvine
Bellagamba, F., Meneghetti, M., Moscardini, L., & Bolzonella, M. 2012,

MNRAS, 422, 553

Bertin, E. 2011, in Astronomical Society of the Paciﬁc Conference Series, Vol.
442, Astronomical Data Analysis Software and Systems XX, ed. I. N. Evans,
A. Accomazzi, D. J. Mink, & A. H. Rots, 435
Bertin, E. & Arnouts, S. 1996, A&AS, 117, 393
Bobin, J., Starck, J.-L., Fadili, J., Moudden, Y., & Donoho, D. 2007, Image

Processing, IEEE Transactions on, 16, 2675

Chang, C., Jarvis, M., Jain, B., et al. 2013, MNRAS, 434, 2121
Combettes, P. L. & Wajs, V. R. 2005, Multiscale Modeling & Simulation, 4, 1168
Donoho, D. L. & Johnstone, J. M. 1994, Biometrika, 81, 425
Gavazzi, R., Treu, T., Rhodes, J. D., et al. 2007, ApJ, 667, 176
Higham, N. J. 1992, Numer. Math, 62, 511
Hocking, A., Geach, J. E., Davey, N., & Sun, Y. 2015
Hsu, L.-T., Salvato, M., Nandra, K., et al. 2014, ApJ, 796, 60
Jolliﬀe, I. T. 1986, Principal Component Analysis (Berlin; New York: Springer-

Verlag)

Joseph, R., Courbin, F., Metcalf, R. B., et al. 2014, A&A, 566, A63
Kelly, P. L., Rodney, S. A., Treu, T., et al. 2015, Science, 347, 1123
Kendall, S., Kennicutt, R. C., & Clarke, C. 2011, MNRAS, 414, 538
Laidler, V. G., Papovich, C., Grogin, N. A., et al. 2007, PASP, 119, 1325
Maltby, D. T., Hoyos, C., Gray, M. E., Arag´on-Salamanca, A., & Wolf, C. 2012,

MNRAS, 420, 2475

Massey, R., Williams, L., Smit, R., et al. 2015, MNRAS, 449, 3393
Merlin, E., Fontana, A., Ferguson, H. C., et al. 2015, A&A, 582, A15
M¨oller, A., Ruhlmann-Kleider, V., Lanusse, F., et al. 2015, J. Cosmology

Parker, A., Bard, D., & Bragg, A. 2012, in APS Ohio Sections Spring Meeting

Pastrav, B. A., Popescu, C. C., Tuﬀs, R. J., & Sansom, A. E. 2013, A&A, 553,

Astropart. Phys., 4, 41

Abstracts, C1002

A80

Peng, C. Y., Ho, L. C., Impey, C. D., & Rix, H.-W. 2002, AJ, 124, 266
P´erez-Gonz´alez, P. G., Egami, E., Rex, M., et al. 2010, A&A, 518, L15
Starck, J., Elad, M., & Donoho, D. 2004, Advances in Imaging and Electron

Physics Series

Transactions on, 16, 297

Starck, J.-L., Fadili, J., & Murtagh, F. 2007,

Image Processing,

IEEE

Starck, J.-L. & Murtagh, F. 2006, Astronomical Image and Data Analysis
Starck, J.-L. & Murtagh, F. 2007, Astronomical

image and data analysis

(Springer Science & Business Media)

Starck, J.-L., Murtagh, F., & Fadili, M. 2010, Sparse Image and Signal

Processing (Cambridge University Press)

Vika, M., Bamford, S. P., H¨außler, B., & Rojas, A. L. 2014, MNRAS, 444, 3603
Vika, M., Bamford, S. P., H¨außler, B., et al. 2013, MNRAS, 435, 623
Vika, M., Vulcani, B., Bamford, S. P., H¨außler, B., & Rojas, A. L. 2015, A&A,

577, A97

Yan, H., Stefanon, M., Ma, Z., et al. 2014, ApJS, 213, 2

9

R. Joseph et al.: MCA-based lens-source separator

Zheng, C., Pulido, J., Thorman, P., & Hamann, B. 2015, MNRAS, 451, 4445

Appendix A: Reproducible research
In the spirit of carrying out reproducible research, we make
pubic all codes and resulting products describes in this paper.
Table A.1 lists all products that will be made available along
with this paper. The MuSCADeT itself is made available as well
as input ﬁles and routines needed for all benchmark tests and for
the application to real data. The routines provide simple exam-
ples of how to execute the MuSCADeT algorithm. We encourage
potential users to modify them as they wish for their own scien-
tiﬁc applications.

Appendix B: Deblending noisy data with known

SED

We show here that the MuSCADeT algorithm is capable of sepa-
rating blended sources even in the case of high noise levels. We
generate simulations of blended objects as in Fig. 4, but with a
noise level ten times larger. The high noise levels along with the
strong blending make it hard for the PCA estimator to estimate
a good SED for the separation.

Although the PCA technique fails in such conditions, the
main feature of our algorithm, which is the morphological com-
ponent analysis-based inversion, still manages to estimate good
sources. The price to pay in this case is that the SEDs must be
known. Figure B.1 shows the result of a separation performed by
MuSCADeT on very noisy data using known SEDs, showing that
our algorithm is still able to separate sources. Our PCA SED
estimator might replaced in the near future to cope with noisy
data. For the present example, we decided to show the residu-
als after separation of both colour components (middle panels of
Fig. B.1) to show that we estimate the sources down to the noise
level.

10

Product name
Software products:
MuSCADeT
Routines:
Example simple.py
Example big.py
Example real.py
Example refsdal.py
Example 2744.py
Example SNR.py
Example nottoosimple.py
Simulations:
Cube.fits
Simu A.fits

R. Joseph et al.: MCA-based lens-source separator

Type

Description

python package

includes MuSCADeT implementation and visualisation tools

code (python)
code (python)
code (python)
code (python)
code (python)
code (python)
code (python)

routines to reproduce Fig. 3.
routines to reproduce Fig. 4.
routines to reproduce Fig. 6.
routines to reproduce Fig. 7.
routines to reproduce Fig. 9.
routines to reproduce Fig. B.1.
An other example of a MuSCADeT run on simulations.

ﬁts data cube

ﬁts table

cube with all simulated images for each benchmark
table with the simulated spectra used in our simulations

Table A.1. List of products made available in this paper in the spirit of reproducible research. All above material is available here:
http://lastro.epfl.ch/page-126973.html.

Fig. B.1. Separation of blended sources at low S/N. From left to right are shown the original simulated images, the original image
after subtraction of the blue component as estimated from MuSCADeT, the original image after subtraction of the red component and
the residual image after subtraction of both components.

11

