6
1
0
2

 
r
a

 

M
9
1

 
 
]
I

A
.
s
c
[
 
 

1
v
1
4
1
6
0

.

3
0
6
1
:
v
i
X
r
a

Evolving Shepherding Behavior with Genetic

Programming Algorithms

Joshua Brul´e

Kevin Engel

Department of Computer Science

Department of Computer Science

University of Maryland

jtcbrule@gmail.com

University of Maryland

kevin.t.engel@gmail.com

Nick Fung

Isaac Julien

Department of Computer Science

Department of Computer Science

University of Maryland
nfung13@gmail.com

University of Maryland

ijulien6@gmail.com

outperform a (naive) human-designed algo-
rithm.

Abstract

We apply genetic programming techniques to
the ‘shepherding’ problem, in which a group
of one type of animal (sheep dogs) attempts
to control the movements of a second group
of animals (sheep) obeying ﬂocking behavior.
Our genetic programming algorithm evolves
an expression tree that governs the move-
ments of each dog. The operands of the
tree are hand-selected features of the simu-
lation environment that may allow the dogs
to herd the sheep eﬀectively. The algorithm
uses tournament-style selection, crossover re-
production, and a point mutation. We ﬁnd
that the evolved solutions generalize well and

1 Introduction

While ﬂocking is a popular topic, algorithms
for shepherding are less well-studied. Exist-
ing approaches to shepherding typically train
a predictive model as in [1], or employ pre-
deﬁned strategies which may be combined to
achieve a goal [2]. Typically, the goal of shep-
herding is to herd the ﬂock to some location
which we will refer to as the ‘pen’.

In our approach, the shepherding system
has no predeﬁned strategies nor predictive
modeling. Using standard genetic program-
ming techniques, we evolve the expression

1

tree for a pure (stateless) function which acts
as the ‘force update’ for each simulated sheep
dog at each time step. The parameters of this
function can include some combination of the
dog’s position, the position of the other dogs
(in cooperative herding), the position of the
nearest ‘free’ (uncaptured) sheep, the center
of mass of the ﬂock, and a ‘steering point,’ a
position such that the line between the steer-
ing point and entrance to the pen crosses
some sheep [4].

Our simulated sheep all obey the same sim-
ple, ﬁxed ﬂocking rules designed such that the
sheep attempt to cluster with each other and
avoid the sheep dog(s). The ﬁtness of the
evolved ‘dog-AI’ is the fraction of the sheep
‘captured’ after some ﬁxed number of simu-
lation steps.

2 Related Work

(Lien et. al, 2005) studies shepherding be-
havior in an environment with multiple shep-
herds cooperating to control a ﬂock [4]. Shep-
herds, which exert a repulsive force on the
ﬂock, must ﬁnd steering points to inﬂuence
the direction of the ﬂock as desired. The
steering points for the group of shepherds
form either a line or an arc on a side of the
ﬂock, and each shepherd chooses a steering
point to approach based on one of several pro-
posed heuristics.

(Sumpter et. al, 1998) presents a machine
vision system that models the position and
velocity of a ﬂock of animals [1]. A Point Dis-
tribution Mode is used to generate features

based on input from a camera mounted on a
”Robotic Sheepdog,” and these features are
then used to estimate a probability distribu-
tion of the movement of the ﬂock over time,
conditional on its previous locations and ve-
locities. This probability distribution is esti-
mated using competitive learning in a neural
network. Finally, the robot can herd a ﬂock
of animals toward a goal by a maximum like-
lihood estimate of the robot’s own path.

(Bennet and Trafankowski, 2012) provides
an analysis of ﬂocking and herding algo-
rithms, and also introduces a herding algo-
rithm based on speciﬁc strategies inspired by
real sheepdogs[2]. [2] also considers using one
of several ﬂocking strategies for the animals
being herded, and ﬁnds that the success of
diﬀerent a herding algorithm is often depen-
dent on the ﬂocking behavior.

(Cowling and Gmeinwieser, 2010) uses a
combined top-down and bottom-up approach
to provide realistic sheep herding in the con-
text of a game. A ﬁnite state machine associ-
ated with each sheepdog represents possible
herding strategies, such as circling, and the
state of the FSM is controlled at the top level
by an AI ”shepherd” [3].

3 Simulation

3.1 Environment

The simulation environment
takes place
within an enclosed, square area designated as
the ﬁeld. The ﬁeld boundaries can be thought

2

of as fences, which act as barriers to both
sheep and dogs. If an agent attempts to pass
through a fence, the penetrating coordinate
is reset to the fence coordinate and the cor-
responding velocity is set to zero.

rules, updating their position based on a set
of force vectors:

Sheep clustering force: Sheep which are
within distance ds of one another are at-
tracted/repelled with magnitude:

(cid:18)

(cid:19)
|(cid:126)xs1 − (cid:126)xs2|2 − 1

d2
s

Fa − Fr

.

(1)

Dog avoidance force:

Sheep which are
within distance dd of a dog are repelled with
magnitude:

(cid:18)

(cid:19)
|(cid:126)xs − (cid:126)xd|2 − 1

d2
d

Fd

.

(2)

Fence avoidance force: Sheep which are
within distance df of a fence are repelled with
magnitude:

df − d⊥

df

Ff

,

(3)

Figure 1: Screenshot of Simulation Environment

The goal of the sheep dogs are to move the
sheep into the pen, located in the top left cor-
ner of the ﬁeld. Only the bottom side of the
pen is open to the ﬁeld, with the fence on the
right side of the pen present to increase the
diﬃculty of the task and help prevent sheep
from randomly drifting in.

3.2 Agents

The simulation agents consist of sheep and
dogs. The sheep all follow the same ﬁxed

3

where d⊥ is the perpendicular distance be-
tween the sheep and the fence.

The above forces apply to free sheep mov-
ing in the open ﬁeld area. Upon entering
the pen, a sheep is captured - its position is
ﬁxed to the corner of the pen and is no longer
updated, eﬀectively removing the sheep from
the simulation.

The dogs, on the other hand, are con-
trolled by an evolved genetic program (the
‘dog AI’) which outputs a force for each dog
at each time step in the simulation. The only
constraint on the dog behavior is that they,
like the sheep, are not allowed to penetrate
fences, as described in the previous section.

3.3 Initial conditions and simulation

parameters

To encourage the evolution of general solu-
tions to the shepherding problem, random
initial conditions were used for the agents.
Dogs spawn randomly inside the pen with no
initial velocity, and sheep spawn randomly in
the right half of the ﬁeld with random initial
velocities. The right half of the ﬁeld was cho-
sen to minimize the possibility of sheep wan-
dering into the pen without guidance from
the dogs.

Each simulation was run with δt = 1 for
500 time steps, returning the number of cap-
tured sheep at the end. The ﬁeld and pen
were chosen to be squares of sizes 100 × 100
and 25 × 25 respectively. For the majority of
the results discussed in this paper, the follow-
ing parameters were used:

Fa = .1 , Fr = .05 , Fd = 5 , Ff = 1 ,
ds = 20 , dd = 30 , df = 5 ,
vs = 1 , vd = 3 .

(4)

The last two parameters are maximum al-
lowed velocities - if a force increases a veloc-
ity past the maximum, it is rescaled to vs for
sheep or vd for dogs.

4 Genetic Program

4.1 Expression Trees

A ‘dog AI’ is a pair of pure (memoryless)
functions which act on a set of parameters

4

passed in by the simulation. We experi-
mented with several diﬀerent parameter sets,
detailed in Section 5. The functions are
stored as s-expressions (i.e.
trees) whose
leaves are either one of the parameters of
the function, or some random number (drawn
from a normal distribution).

Since updating the dog’s position requires
two values (Fx and Fy), the root node of the
tree is always ‘pair’, with two subtrees rep-
resenting the logic for the x and y forces, re-
spectively. The internal nodes of a ‘dog AI’
expression tree are one of the following opera-
tors: − (unary), − (binary), +, ∗, div (where
div is protected division; attempting to divide
by zero will return 1 instead).

In addition to these basic mathematical op-
erations, we included qif(a, b, c, d), ‘quater-
nary if’, which evaluates to c if a ≤ b and d
otherwise. Note that all functions in the ex-
pression trees are functions of real numbers
(implemented as JVM doubles), guarantee-
ing closure under the genetic operators .

4.2 Genetic Operators and Initial-

ization

The design of the genetic programming sys-
tem closely followed standard practice as de-
scribed in [5]. We used generational GP with
a ﬁxed population size P initialized using the
ramped half-and-half method; half of the ini-
tial population was fully grown to some ‘ramp
depth’ Dramp (set to 5 in our evaluations), and
half of the initial population grown randomly
beginning from the root, with each node ei-

ther being a leaf (terminal) node or interior
(function) node with equal probability. Trees
were depth limited to Dmax, which due to lim-
itations of the JVM, was set to 10 for all runs.
Parent selection was done with binary tour-
nament selection.

Oﬀspring were generated either via point
mutation (with probability pm) or crossover.
Point mutation was done by replacing a (uni-
formly) randomly selected subtree of the par-
ent with a new randomly grown tree, depth
limited such that the oﬀspring’s size would re-
spect Dmax. Crossover was performed by ran-
domly selecting a crossover point in each par-
ent and generating new oﬀspring by swapping
the subtrees in each parent. In the event that
one of the oﬀspring resulting from crossover
exceeded Dmax, it was discarded.

In addition to the generated oﬀspring, one
elite clone was carried over from the previous
generation to the next.

4.3 Fitness

The ﬁtness of each algorithm was measured
as the percentage of sheep that were success-
fully shepherded into the pen. The main dis-
advantage of this ﬁtness measure was the dif-
ﬁculty in obtaining a ﬁtness greater than zero
for an initial random population. Another
ﬁtness measurement considered was the av-
erage distance of each sheep from the pen.
However, this ﬁtness measurement was often
misleading in that sheep on the opposite side
of the pen fence had very high ﬁtness, despite
require additional complex inﬂuences to force
them around the fence into the pen. The

5

average distance ﬁtness was ultimately dis-
carded in favor of the original ﬁtness func-
tion.

An additional problem for both ﬁtness
functions was the high variance in the results
of a simulation run due to the random initial
conditions. For some simple test cases, the
genetic algorithm could not make signiﬁcant
progress, due to the misleading ﬂuctuations
in the ﬁtness. These issues were partially
mitigated by redeﬁning the ﬁtness to be the
average ﬁtness over 10 simulations.

5 Experimentation

5.1 One Dog

Initial experimentation took place under the
conditions of a single dog attempting to shep-
herd 20 sheep into the pen. The ‘dog AI’ was
given access to a limited set of only 4 pa-
rameters: its position (x and y coordinates)
as well as those of the nearest free sheep.
This simpliﬁed scenario was targeted as an
early goal because it restricts the complexity
of the problem and provides good conditions
for evolved behaviors. The experiment took
place using a population size of 250 over 220
generations with the mutation rate pm was
held at 0.05.

5.2 Multiple Dogs

After achieving reasonable success in the sin-
gle dog scenario, we extended the simulation
to multiple dogs to determine if the dogs
could develop team-like behaviors or if the
genetic algorithm would just rediscover its
successful single dog algorithm. Simulations
were run for 3 dogs attempting to herd the
same 20 sheep. To encourage teamwork, the
‘dog AI’ was given an expanded set of param-
eters: dog position, other dog positions, near-
est free sheep, average sheep position, and a
steering point. The steering point was de-
ﬁned as the point a constant distance (10)
behind the nearest free sheep position, in a
line with it and the pen. Note that because
the dogs spawn in diﬀerent locations, many
of these parameters will be unique for each
dog, allowing for divergent behavior.

The other

simulation parameters were
mostly carried over from the single dog sce-
nario. In this case, a population size of 250
was used and the algorithms were evolved for
100 generations.

6 Results

As a baseline behavior from which evolved ge-
netic algorithms could be compared, a hand-
crafted algorithm (referred to as ‘simple-dog’)
was created and evaluated. To maintain fair-
ness, the handcrafted algorithm was limited
to the same parameters and operators that
were available to the genetic algorithms. This
algorithm was applied only to the single dog

6

scenario over 10, 000 simulation runs, achiev-
ing an average ﬁtness of 0.640 ± 0.002. For
comparison, we also evaluated the eﬀective-
ness of ‘rand-dog’, a dog that applies a (uni-
formly) random force vector to itself each
time step, which achieved an average ﬁtness
of only 0.054 ± 0.001.

The earliest evolved algorithm that suc-
ceeded in shepherding any sheep into the pen
we dubbed ‘split-dog’, due to its tendency to
shepherd the sheep by moving towards the
ﬂock at maximum velocity, splitting the ﬂock
apart. Remarkably, this algorithm evolved
to split the ﬂock apart in such a way that
the sheep clustering force would cause the
ﬂock to reassemble itself in the pen despite
no further interactions with the dog (which
tended to get ‘stuck’ in the bottom right cor-
ner of the simulation environment).
In one
particularly successful simulation, ‘split-dog’
achieved 15/20 ﬁtness; however, this relied
on very speciﬁc environmental/initial condi-
tions, and ‘split-dog’ achieved very poor ﬁt-
ness on average.

However, given suﬃcient generations, the
genetic program produced an evolved behav-
ior that performed well. Figure 2 shows the
growth of the maximum and average ﬁtness
values for the genetic algorithm population
at each generation. The maximum ﬁtness
value converges close to perfect shepherding
within 50 generations. Although the ﬁtness
growth can change between trials due to the
nondeterministic nature of genetic program-
ming and the simulation environment, typical
results matched the growth curve seen here.
After 220 generations, the best evolved al-
gorithm had an average ﬁtness of 0.743 ±

Figure 2: Growth of Fitness Over Generation for a
Single Dog, 150 Population Run

Figure 3: Evaluated Fitness Over 10,000 Trials

0.003, surpassing the ‘simple-dog’ human-
written algorithm. Although the genetically
evolved code is practically unreadable, the
basic strategy can be inferred from the sim-
ulation visualization. The dog waits for the
sheep to cluster, then moves to the right of
the ﬁeld, pushing the sheep cluster to the left
and underneath the pen. The dog then moves
back to the left and up, pushing the majority
of the sheep into the pen.
The best evolved multiple dog algorithm
had a ﬁtness of 0.780 ± 0.003, slightly bet-
ter than the single dog. The dogs behaved
in a similar manner, overlapping each other
for most of the simulation, but near the end,
as the sheep neared the pen, they would sep-
arate, some pushing from below, and others
nearer the pen, pushing in from the sides to
keep the sheep from escaping. Although lim-
ited, this teamwork was enough to improve
upon the results of the single dog algorithm.
Due to the stochastic nature of the sim-

ulation (caused by the random initial place-
ment of the sheep), we tested the evolved al-
gorithms over a very large number of trials to
conﬁrm their eﬀectiveness. The results in 3
show that the evolved single and three dog al-
gorithms obtained a high average ﬁtness over
10,000 trials. The ‘split-dog’ serves as a com-
parison to the best evolved algorithms; ‘split-
dog’, evolved for only 10 generations actually
fails to outperform ‘rand-dog’.

6.1 Adaptability to Other Environ-

mental Conditions

One danger of genetic programming is the
potential to overﬁt an algorithm.
In some
cases, an evolved algorithm could excel at
completing its intended task but falter when
confronted with slightly diﬀerent task. To
this end, the genetic algorithms were mea-
sured for ﬁtness against tasks that were al-
tered from the training task.

7

‘split-dog’ serves as an interesting demon-
stration of both genetic programming’s abil-
ity to ﬁnd novel solutions, and its tendency
to produce drastically overﬁt solutions. How-
ever, given suﬃcient generations, the random
initial sheep positions appeared to success-
fully force the genetic program to develop
more generally good solutions. The evolved
solutions still perform very well, even un-
der environmental conditions that the genetic
program was not trained on. Unfortunately,
however, the evolved genetic programs are
generally very diﬃcult, if not impossible for
humans to understand.

There is ample room for further investiga-
tion using the presented framework. An in-
teresting adaptation would be to increase the
complexity of the problem by moving the pen
away from the corner or limiting the vision of
the dogs.
In addition, the sheep could also
be allowed evolve and adapt to the dog pop-
ulation.

8 Implementation

The entire genetic programming system and
simulation environment for this project was
implemented in Clojure (a dialect of Lisp) us-
ing only the standard library functions avail-
able with the language. The simulation visu-
alizations were implemented in Java.

The full code repository (with links to
videos of the simulations) is available online:
https://github.com/jtcb/ﬂock

Figure 4: Effect of Changing Simulation Parameters
on Algorithmic Fitness

A small sample is shown in Figure 4, in-
cluding runs with less sheep (5), more sheep
(100), faster sheep (vs = 3), and weaker sheep
clustering force (ds = 5) and diﬀerent ini-
tial conditions (sheep spawn in the lower half
of the ﬁeld). Comparing the human written
simple-dog algorithm to our evolved three-
dog one, we see that both remain reasonably
eﬀective despite the changes to the environ-
ment. For these simple tests, the evolved al-
gorithm appears as adaptive and general as
the human written one.

7 Discussion

The experimental results demonstrates the
potential of evolving complex behaviors
through genetic programming. Although the
operators and parameters made available to
the genetic algorithms were quite limited,
successful capabilities were evolved within 50
generations.

8

References

[1] N. Sumpter, A.J. Rulpitt, R. Vaughan,
R.D. Tillett, and R.D. Boylel. Learning
Models of Animal Behaviour for a Robotic
Sheepdog 1998; IAPR Wotkrhop on Ma-
chine Vision Applications. Nov 17-t9. 19

[2] Brandon

Bennett

and Matthew
Trafankowski. A Comparative
Inves-
tigation of Herding Algorithms. 2012; In
proceeding of: Proceedings of the Sym-
posium on Understanding and Modeling
Collective Phenomena (UMoCoP) at the
Artiﬁcial Intelligence and Simulation of
Behaviour World Congress (AISB-12)

[3] Peter Cowling and Christian Gmein-
wieser. AI for Herding Sheep 2010; Pro-
ceedings of the Sixth AAAI Conference
on Artiﬁcial Intelligence and Interactive
Digital Entertainment.

[4] Jyh-Ming Lien, Samuel Rodriguez, Jean-
Phillipe Malric, and Nancy M. Am-
ato. Shepherding Behaviors with Multi-
ple Shepherds. 2005. Proceedings of the
2005 IEEE International Conference on
Robotics and Automation

[5] Eiben, A.E. and Smith, J.E. (2007) Intro-
duction to Evolutionary Computing. New
York, New York: Springer.

9

