Proof of Threshold Saturation for

Spatially Coupled Sparse Superposition Codes

Jean Barbier, Member IEEE, Mohamad Dia and Nicolas Macris, Member IEEE.

Laboratoire de Théorie des Communications, Ecole Polytechnique Fédérale de Lausanne.

{jean.barbier, mohamad.dia, nicolas.macris}@epﬂ.ch

6
1
0
2

 
r
a

M
6

 

 
 
]
T
I
.
s
c
[
 
 

1
v
7
1
8
1
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Recently, a new class of codes, called sparse su-
perposition or sparse regression codes, has been proposed for
communication over the AWGN channel. It has been proven
that they achieve capacity using power allocation and various
forms of iterative decoding. Empirical evidence has also strongly
suggested that the codes achieve capacity when spatial coupling
and approximate message passing decoding are used, without
need of power allocation. In this note we prove that state evolution
(which tracks message passing) indeed saturates the potential
threshold of the underlying code ensemble, which approaches
in a proper limit the optimal threshold. Our proof uses ideas
developed in the theory of low-density parity-check codes and
compressive sensing.

I. INTRODUCTION

Sparse superposition (SS) codes introduced by Barron and
Joseph for reliable communication over the additive white
Gaussian noise channel (AWGNC) have been proven to ap-
proach capacity using power allocation and various efﬁcient
decoders [1–3]. An approximate message passing (AMP)
decoder was introduced in [4], and the recent analysis [5]
proves that this allows to reach capacity with the help of
power allocation. Spatially coupled SS codes were introduced
in [6, 7] and empirically shown to reach capacity under AMP
without any need for power allocation. The empirical evidence
shows that spatially coupled SS codes perform better than
power allocated ones in the sense that they approach capacity
faster in a proper limit [7]. Given this evidence, it is of interest
to develop a rigorous theory for such coding constructions.

It is natural to address two conjectures. First, that spatially
coupled SS codes allow to reach the so-called potential thresh-
old of state evolution (SE). Second, that SE correctly tracks
the AMP decoder. As we will argue, the potential threshold
tends to capacity in a proper limit, so this would prove that
the codes are capacity achieving.

The purpose of this note is to settle the ﬁrst conjecture. We
prove that for a general ensemble of spatially coupled coding
matrices, the AMP threshold attains (in a suitable limit) the
potential threshold of SE. This phenomenon is called threshold
saturation. The precise statements of our main results are
Theorem 5.7 and Corollary 5.8.

Threshold saturation was ﬁrst established in the context of
spatially coupled Low-Density Parity-Check codes for general
binary input memoryless symmetric channels in [8], and is
recognized as the basic mechanism underpinning the excellent
performance of such codes [9]. It is interesting that essentially

the same phenomenon can be established for a coding system
operating on a channel with continuous inputs. This result is a
stepping-stone towards establishing that spatially coupled SS
codes achieve capacity on the AWGNC under AMP decoding.
The remaining analysis to settle the second conjecture would
require extending the one given for compressive sensing [10]
to signals with correlated components in a spatially coupled
system, as already done for the power allocated system [5].

To establish threshold saturation, we use the potential
method along the lines of [11, 12] developed for LDPC and
LDGM codes. Note that a similar (but different) potential to
the one used here has been introduced in the context of scalar
compressive sensing [13, 14]. It is interesting that the potential
method goes through for the present system involving a dense
coding matrix and a fairly wide class of spatial couplings [15].
Coding constructions of the underlying and coupled en-
sembles are described in Sec. II. Sec. III reviews SE and
potential formulations adapted to the present context. The
AMP thresholds of underlying and coupled ensembles as well
as the potential threshold are given precise deﬁnitions. Sec. IV
introduces a notion of degradation and settles monotonicity
properties of SE. The essential steps for the proof of threshold
saturation are presented in Sec. V.

II. CODE ENSEMBLES

We ﬁrst deﬁne the underlying and spatially coupled ensem-
bles of SS codes for transmission over an AWGNC. We will
often use the shorter notations [a1 : an] and {b1 : bn} instead
of [a1, . . . , an] and {b1, . . . , bn} for n-tuples.
A. The underlying ensemble

In the framework of SS codes, the information word s =
[s1 : sL] is a vector made of L sections. Each section sl, l ∈
{1 : L}, is a B-dimensional vector with one component equal
to 1 and B − 1 components equal to 0. For example if (B =
3, L = 4), a valid information word is s = [001, 010, 100, 010].
We call B the section size (or alphabet size) and set N =
LB. A codeword Fs ∈ RM is generated from a ﬁxed coding
matrix F ∈ RM×N . We consider random codes generated by
F drawn from the ensemble of random matrices with i.i.d real
Gaussian entries with distribution N (0, 1/L). The cardinality
of the code is BL, the block length is M, and the (design)
rate is R = L log2(B)/M = N log2(B)/(M B). The code is
thus speciﬁed by the basic parameters (M, R, B).

a rate loss in the effective rate of the code, Reff = R(1− 8w
Γ ).
However, this loss vanishes as Γ → ∞.
III. STATE EVOLUTION AND POTENTIAL FORMULATION
We now give the state evolution associated to the underlying
and spatially coupled ensembles, which is conjectured to track
the performance of the AMP decoder. We then deﬁne an
appropriate potential function for each ensemble.

A. State evolution

Es,y[(cid:80)N

j=1(ˆs(t)

The goal is to iteratively compute the mean square error
(cid:112)
(MSE) ˜E(t) = 1
j − sj)2] of the AMP estimates
L
j } at iteration t ∈ N. We need a few deﬁnitions to express
{ˆs(t)
R(σ2 + E). We deﬁne a de-
the iterations. Let Σ(E) :=
noiser fi(Σ(E)) as the minimum mean square error (MMSE)
estimator of the i-th component of a section sent through
an effective AWGNC with a noise N (0, Σ(E)2/ log2(B)),
when the input signal is uniformly distributed. Explicitly, if
z = [z1 : zB] denote B independent standardized Gaussian
random variables (with zero mean and unit variance), and
p0(x) = 1

(cid:81)B
k(cid:54)=i δxk,0, we set for i = 1 : B

(cid:80)B
(cid:80)
(cid:80)
e(sk−si) log2(B)/Σ(E)2+(zk−zi)√log2(B)/Σ(E)

(cid:107)x−(s+zΣ(E)/√log2(B))(cid:107)2

(cid:107)x−(s+zΣ(E)/√log2 (B))(cid:107)2

(cid:35)−1

.

x e−
x e−

fi(Σ(E)) :=

B(cid:88)

p0(x)xi

i=1 δxi,1

2Σ(E)2/ log2 (B)

2Σ(E)2/ log2(B)

p0(x)

=

1 +

(cid:34)

B

2

2

k(cid:54)=i

(1)

(2)

Note that the denoiser also depends on s, z. Furthermore, we
deﬁne the SE operator of the underlying system as

(cid:20) B(cid:88)

i=1

(cid:0)fi(Σ(E)) − si

(cid:21)

(cid:1)2

.

Tu(E) := Es,z

This
is nothing else than the MSE associated to the
MMSE estimator of
the effective AWGNC with noise
N (0, Σ(E)2/ log2(B)). The SE iterations for the underlying
system’s MSE can now be expressed as

˜E(t+1) = Tu( ˜E(t)),

t ≥ 0.

To track the performance of the AMP decoder the iterations are
initialized with ˜E(0) = 1. The monotonicity and boundedness
of the iterations of SE, discussed in Sec. IV, ensure that
actually all initial conditions reach a ﬁxed point.

Deﬁnition 3.1 (MSE Floor): The MSE ﬂoor E0 is deﬁned
as the ﬁxed point reached from the initial condition ˜E(0) = 0.
In other words E0 = T (∞)

of the MSE ﬂoor E0 is V0 :=(cid:8)E | T (∞)

Deﬁnition 3.2 (Bassin of attraction): The basin of attraction

Deﬁnition 3.3 (Threshold of underlying ensemble): The
AMP threshold is Ru := sup{R > 0 | T (∞)
(1) = E0}.
It can be shown that for the present system T (∞)
(0) and
T (∞)
(1) are the only two possible ﬁxed points. For R < Ru,
u
there is only one ﬁxed point, namely the “good” one T (∞)
(0),
and for large section size B the MSE ﬂoor and section error

(E) = E0

(cid:9).

(0).

u

u

u

u

u

Fig. 1. A spatially coupled coding matrix ∈ RM×N made of Γ × Γ blocks
indexed by (r, c), each with N/Γ columns and M/Γ = αN/Γ rows. The
i.i.d elements in block (r, c) have distribution N (0, Jr,c/L). Away from
the boundaries, in addition to the diagonal (in red), there are w forward
and backward coupling blocks. In this example, the design function gw
(cid:80)Γ
enforces a stronger backward coupling. Blocks are darker at the boundaries
(cid:80)Γ
r=1 Jr,k/Γ =(cid:80)Γ
because the variances are larger so as to enforce the variance normalization
c=1 Jr,c/Γ = 1 ∀ r. The yellow shape emphasizes variance symmetry
c=1 Jk,c/Γ = 1 veriﬁed if k ∈ {2w + 1 : Γ − 2w}.

Codewords are transmitted through an AWGNC, i.e., the
received signal is y = Fs + ξ where ξµ ∼ N (0, σ2) ∀ µ.
Power is normalized thanks to the 1/L variance of the entries
of F, so that the signal-to-noise ratio is snr = 1/σ2.

The decoding task is to infer the information word s from
channel observations y. This is obviously very similar in spirit
to compressive sensing, where one wants to infer a sparse
signal from a certain number of measurements. For this reason,
our language and techniques are sometimes borrowed from
compressive sensing. In particular, the code rate can be linked
to a “measurement rate” α := M/N = log2(B)/(BR).
B. The spatially coupled ensemble

The construction has similarities with [16]. We consider
spatially coupled codes based on coding matrices in RM×N
as described in details in Fig. 1. This ensemble of matrices is
parametrized by (M, R, B, Γ, w, gw), where w is the coupling
window and gw is the design function. This is any function ver-
ifying gw(x) = 0 if |x| > 1 and gw(x) ≥ g0 > 0 else, which
is Lipschitz continuous on its support with Lipschitz constant
g∗. The constants g0, g∗ are independent of w. Moreover, we
k=−w gw(k/w)/(2w + 1) = 1.
From gw, we construct the variances of the blocks: the i.i.d
entries inside the block (r, c) are distributed as N (0, Jr,c/L),
where Jr,c := γrΓgw((r − c)/w)/(2w + 1). Here γr enforces
(cid:80)M
c=1 Jr,c/Γ = 1 ∀ r. This implies
(by the law of large numbers) that [Fs]2
µ → 1 ∀ µ as L → ∞,
µ=1[Fs]2
µ/M = 1, and
i.e. the asymptotic power limL→∞
the snr = 1/σ2 is homogeneous.

impose the normalization(cid:80)w
the variance normalization(cid:80)Γ

The spatial coupling induces a natural decomposition of the
signal into Γ blocks (associated with the block-columns of the
matrix), each made of L/Γ sections. One key element of spa-
tially coupled codes is the seed introduced at the boundaries.
We assume the sections in the ﬁrst and last 4w blocks of the
information word s to be known by the decoder. This boundary
condition can be interpreted as perfect side measurements that
propagate inward and boost the performance. The seed induces

0ww  N/ ↵N/ u

(cid:80)

rate are small. Instead if R > Ru, the decoder is blocked by
the “bad” ﬁxed point T (∞)
(1) (cid:54)= E0 and AMP cannot decode.
We now turn our attention to SE for the spatially coupled
system. The perfomance of AMP is described by an MSE
proﬁle { ˜Ec | c = 1 : Γ} along the “spatial dimension”.
Since we assume that the boundary sections are known to
the decoder, we enforce the pinning condition ˜Ec = 0 for
c ∈ {1 : 4w} ∪ {Γ − 4w + 1 : Γ}. For c not
in this
set, by deﬁnition ˜Ec := Γ
2], where the
L
sum l ∈ c is over the set of indices of the L/Γ sections
composing the c-th block of s. It is more convenient to work
with a smoothed error proﬁle (referred as the error proﬁle)
E = {Er | r = 1 : Γ}, Er := 1
c=1 Jr,c ˜Ec. Indeed, this
change of variables makes the problem mathematically more
tractable for spatially coupled codes. The pinning condition
becomes Er = 0 for r ∈ A := {1 : 3w} ∪ {Γ − 3w + 1 : Γ}.

Es,y[(cid:107)ˆsl − sl(cid:107)2
(cid:80)Γ

We deﬁne an effective noise for block c ∈ {1 : Γ},

l∈c

Γ

(cid:20) 1

Γ

R(σ2 + Er)

Γ(cid:88)
(cid:20) B(cid:88)

Jr,c

(cid:21)−1/2
(cid:0)fi(Σc(E)) − si

(3)

(4)

(cid:1)2

(cid:21)

.

Σc(E) :=

Γ(cid:88)

r=1
and the coupled SE operator

[Tc(E)]r =

1
Γ

Jr,cEs,z

c=1

i=1

Tc(E) is vector valued and here we have written its r-th
component. The SE iterations then read for r /∈ A

E(t+1)

r

= [Tc(E(t))]r,

t ≥ 0.

(5)

r = 0 is enforced at all

r = 1 for r /∈ A.

For r ∈ A, the pinning condition E(t)
times. SE is initialized with E(0)
Let E0 := [Er = E0, r = 1 : Γ] be the MSE ﬂoor proﬁle.
Deﬁnition 3.4 (Threshold of coupled ensemble): The AMP
threshold of
:=
(1) ≺ E0} where 1 is the all
lim inf Γ,w→∞sup{R > 0 | T (∞)
ones vector. Here the lim inf Γ,w→∞ is taken along sequences
where ﬁrst Γ → ∞ and then w → ∞.
B. Potential formulation

the coupled system is deﬁned as Rc

c

The ﬁxed point equations associated to SE iterations can
be reformulated as stationary point equations for suitable
potential functions. These are in general not unique. However,
the “correct” guess (i.e. the one that allows to prove full
threshold saturation) can be derived by the replica method of
statistical physics [4] .

(σ2 + E)e− E

The potential of the underlying ensemble is Fu(E) :=

(cid:16)
(cid:40)
Uu(E) − Su(Σ(E)), with
i=2 ei(Σ(E))(cid:1)(cid:3),
(cid:0)1 +(cid:80)B
(cid:2) logB
Uu(E) := 1
2R log2
(cid:112)
where ei(x) := exp(cid:0)(zi − z1)
log2(B)/x − log2(B)/x2(cid:1).
Su(Σ(E)) := Ez
Uc(E) :=(cid:80)Γ
Sc(E) :=(cid:80)Γ

The potential of the spatially coupled ensemble is Fc(E) =
Uc(E) − Sc(E) where

r=1 Uu(Er),
c=1 Su(Σc(E)).

(cid:40)

(cid:17)

(6)

(7)

σ2+E

,

Let us pause for an instant and give the statistical physics
interpretation of these formulas. The posterior distribution
p(s|y) = exp(−(cid:107)y − Fs(cid:107)2
2/2σ2)p0(s)/Z (Z the normalizing
factor) can be interpreted as the Gibbs distribution of a
disordered spin system (s being the annealed “spin” degrees
of freedom, y and F the quenched “disorder”). The potential
functions F are “Bethe free energies” averaged over the
disorder. They are equal to “energy” terms U minus “entropy”
terms S. One can prove that both terms are increasing in Σ.
This is “physically” natural if the effective channel noise Σ is
interpreted as a kind of effective “temperature”.

Deﬁnition 3.5 (Free energy gap): The free energy gap is
∆Fu := inf E /∈V0(Fu(E) − Fu(E0)), with the convention that
the inﬁmum over the empty set is ∞ (this happens for R <
Ru).
Deﬁnition 3.6 (Potential threshold): The potential threshold

is Rpot := sup{R > 0 | ∆Fu > 0}.
the following Lemma.

The connection between these potentials and SE is given by

then [ ∂Fu
ﬁxed point of (5) then [ ∂Fc
∂Er

Lemma 3.7: If ˚E is a ﬁxed point of (2), i.e., Tu( ˚E) = ˚E,
∂E ] ˚E = 0. Similarly for the coupled system, if ˚E is a
]˚E = 0 ∀ r ∈ {3w + 1 : Γ − 3w}.
The proof is technical and we skip it here. Let us just
indicate that it proceeds by computing the derivatives of the
potentials, uses Gaussian integration by parts formulas and
channel symmetry. Similar results can be found in [11, 12].

(cid:80)B

It is noteworthy that what is called a “Bethe entropy” in the
statistical physics literature, has an information theoretic inter-
(cid:81)B
pretation, and is actually a Shannon conditionnal entropy for
an effective channel. Let X be a B-dimensional random vector
with distribution p0(x) = 1
k(cid:54)=i δxk,0. Take the
output Y of an AWGNC with i.i.d noise N (0, Σ2/ log2(B))
for each component, when the input is X. Then it is an exercise
to check that H(X|Y) = Su(Σ) log2(B). This identiﬁcation
clearly shows that Su(Σ) must be an increasing function of Σ.
Also, it allows to give information theoretic expressions for the
potential functions. We note that such expressions have already
been written down for scalar compressive sensing [13, 14].

i=1 δxi,1

B

that

We also point out

there is another way to derive
potential functions by integrating out
the SE ﬁxed point
equations after premultiplication by an “integrating factor”.
When the correct “integrating factor” is used, one recovers the
information theoretic expressions of the potential functions.
This method is discussed in [14] for a wide range of problems
including scalar compressive sensing, and one can check it
extends to the present setting. A key point for this method
is the well known relation between mutual information (or
conditional entropy) and MMSE [17]. Here this relation takes
the form dH(X|Y)
2 mmse(Σ) (here mmse = Tu where
Tu is the r.h.s of (1) viewed as a function of Σ).

d(Σ−2) = − 1

C. Large B analysis and connection with Shannon’s capacity

Let us now emphasize the connection between the potential
2 log2(1 + snr).

threshold Rpot and Shannon’s capacity C = 1

The large section size limit of the potential of the underlying
system becomes [18]

lim
B→∞

Fu(E) = Uu(E) − max

0, 1 −

1

2 ln(2)Σ(E)2

,

(8)

(cid:16)

(cid:17)

(where we recall Σ(E)2 := R(σ2 + E)). The analysis of
this function of E ∈ [0, 1] shows the following. For R <
[(1 + σ2)2 ln(2)]−1 there is a unique minimum at E = 0.
For [(1 + σ2)2 ln(2)]−1 < R < C, E = 0 is the global
minimum but there exists a local minimum at E = 1. When
R > C the global minimum is at E = 1 and E = 0 is a local
minimum. Therefore we can identify limB→∞ Rpot = C and
limB→∞ Ru = [(1 + σ2)2 ln(2)]−1.
Let us also point out that these are static properties of the
system which are independent of the decoding algorithms. In
a sense they conﬁrm in an alternative way that the codes must
achieve capacity under optimal decoding [19].

IV. PROPERTIES OF THE COUPLED SYSTEM

Monotonicity properties of the SE operators Tu and Tc are
key elements in the analysis. We start by deﬁning a suitable
notion of degradation.

Deﬁnition 4.1 (Degradation): A proﬁle E is degraded (resp.
strictly degraded) with respect to another one G, denoted as
E (cid:23) G (resp. E (cid:31) G), if Er ≥ Gr ∀ r (resp. if E (cid:23) G and
there exists some r such that Er > Gr).
Lemma 4.2: The SE operator of the coupled system main-
tains degradation in space, i.e., if E (cid:23) G, then Tc(E) (cid:23) Tc(G).
This property is veriﬁed by Tu for a scalar error as well.
Proof: From (3) it is immediately seen that E (cid:23) G
implies Σc(E) ≥ Σc(G) ∀ c. Now, the SE operator (4) can be
interpreted as an average over the spatial dimension of local
MMSE’s. The local MMSE’s are the ones of B-dimensional
c/ log2(B)). The
AWGN channels with effective noise N (0, Σ2
c: this is intuitively clear
MMSE’s are increasing functions of Σ2
but we provide an explicit formula for the derivative below.
Thus [Tc(E)]r ≥ [Tc(G)]r ∀ r, which means Tc(E) (cid:23) Tc(G).
The derivative of the MMSE of the Gaussian channel with
(cid:2)
i.i.d noise N (0, Σ2) can be computed as
(cid:107)X − E[X|Y](cid:107)2

2Var[X|Y](cid:3).

= −2EX,Y

d mmse(Σ)

(9)

d(Σ−2)

This formula is valid for vector distributions p0(x), and in par-
ticular, for our B-dimensional sections. It explicitly conﬁrms
that Tu (resp. [Tc]r) is an increasing function of Σ (resp. Σc).

Corollary 4.3: The SE operator of the coupled system
maintains degradation in time, i.e., Tc(E(t)) (cid:22) E(t), implies
Tc(E(t+1)) (cid:22) E(t+1). Similarly Tc(E(t)) (cid:23) E(t)
implies
Tc(E(t+1)) (cid:23) E(t+1). Furthermore, the limiting error proﬁle
E(∞) := T (∞)
(E(0)) exists. This property is veriﬁed by Tu
for the underlying system as well.

c

Proof: The degradation statements are a consequence of
Lemma 4.2. The existence of the limits follows from the
monotonicity of the operator and boundedness of the MSE.

Fig. 2. A proﬁle E∗ (solid) and its associated saturated non decreasing proﬁle
E (dashed). The former has a plateau at 0 for all r ≤ 3w and it increases
until rmax where it reaches its maximum value Emax. Then it decreases to
0 at Γ − 3w + 1 and remains null after. The saturated proﬁle starts with a
plateau at E0 for all r ≤ r∗, where r∗ is the position deﬁned by E∗
r∗ = E0,
and then matches E∗ for all r ∈ {r∗ : rmax}. It then saturates to Emax for
all r ≥ rmax. By construction, E is non decreasing and veriﬁes E (cid:31) E∗.

V. PROOF OF THRESHOLD SATURATION

The pinning step together with the monotonicity properties
of the coupled SE imply that the ﬁxed point proﬁle E∗ must
adopt a shape similar to Fig. 2 (note Emax ∈ [0, 1]). We
associate to E∗ a saturated proﬁle denoted E. Its construction
is described in detail in Fig. 2. The saturated proﬁle E is
strictly degraded with respect to E∗, thus E serves as an upper
bound in our proof.

A. Coupled potential change evaluation by Taylor expansion
Deﬁnition 5.1 (Shift operator): The shift operator is deﬁned

pointwise as [S(E)]1 := E0, [S(E)]r := Er−1.
Lemma 5.2: Let E be a saturated proﬁle. If ˆE := (1− ˆt)E+
(cid:21)
ˆtS(E) and ∆Er := Er − Er−1, then for a proper ˆt ∈ [0, 1],

(cid:20) ∂2Fc

Γ(cid:88)

1
2

r,r(cid:48)=1

∆Er∆Er(cid:48)

Fc(S(E)) − Fc(E) =
Γ(cid:88)
Proof: Fc(S(E)) − Fc(E) can be expressed as

(cid:20) ∂2Fc

(cid:20) ∂Fc

Γ(cid:88)

∂Er∂Er(cid:48)

(cid:21)

.

ˆE

. (10)

∆Er∆Er(cid:48)

∂Er∂Er(cid:48)

∆Er

r=1

∂Er

E

(cid:21)
ˆE −

1
2

r,r(cid:48)=1

By saturation of E, ∆Er = 0 ∀ r ∈ B := {1 : r∗} ∪ {rmax +
1 : Γ}. Moreover for r /∈ B, Er = [Tc(E)]r, and thus by
Lemma 3.7 the potential derivative cancels at these positions.
Hence the last sum in (10) cancels.
Lemma 5.3: The saturated proﬁle E is smooth, i.e. |∆Er| <
(g∗ + ˜g)/w where ˜g := max(1 + g∗, g0 + 2g∗). Recall g0 and
g∗ are independent of w and Γ.
Proof: ∆Er = 0 for all r ∈ B. By construction of {Jr,c}
and using Lipschitz continuity of gw, we have for all r /∈ B

Lemma 5.4: The coupled potential veriﬁes

c(Jr,c − Jr−1,c) ˜Ec

(cid:12)(cid:12)/Γ < (g∗ + ˜g)/w.
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) < K/w,
(cid:21)

ˆE

(cid:20) ∂2Fc

∂Er∂Er(cid:48)

that |∆Er| =(cid:12)(cid:12)(cid:80)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)
Γ(cid:88)

r,r(cid:48)=1

1
2

∆Er∆Er(cid:48)

(11)

where K is independent of w and Γ.

The proof uses Lemma 5.3 and the monotonicity of Er.
Bounding the Hessian is rather long but does not present major
difﬁculties.

3wrE0r⇤Emaxrmax  3w+1  3w+1B. Direct evaluation of the coupled potential change
Lemma 5.5: Let E be a saturated proﬁle such that E (cid:31) E0.
Then Emax /∈ V0.
Proof: The non decreasing error proﬁle and the assump-
tion that E (cid:31) E0 imply that Emax > E0. Moreover, Emax ≤
[Tc(E)]rmax ≤ Ts(Emax) where the ﬁrst inequality follows
from E (cid:31) E∗ and the monotonicity of Tc, while the second
comes from the variance symmetry at rmax and the fact that
E is non decreasing. Combining these with the monotonicity
of Ts gives: Ts(Emax) ≥ Emax ⇒ T (∞)
(Emax) ≥ Emax >
E0 ⇒ Emax /∈ V0.
Lemma 5.6: Let E be a saturated proﬁle such that E (cid:31) E0.
Then Fc(S(E)) − Fc(E) ≤ −∆Fu.
Proof: The contribution of the change in the energy term
is a perfect telescoping sum:

s

Uc(S(E)) − Uc(E) = Uu(E0) − Uu(Emax).

(12)

We now deal with the contribution of the change in the
entropy term. We ﬁrst notice that, using the variance symmetry,
Σc(E) = Σc+1(S(E)) ∀ c ∈ {2w + 1 : Γ − 2w − 1}, which
makes the sum telescoping in this set. Thus
(cid:88)
Sc(E) − Sc(S(E)) = Su(ΣΓ−2w(E)) − Su(Σ2w+1(S(E)))
(13)
−

[Su(Σc(S(E))) − Su(Σc(E))],

c∈S

where S := {1 : 2w} ∪ {Γ − 2w + 1 : Γ}. By saturation,
E possesses the following property: [S(E)]r = [E]r ∀ r ∈
{1 : r∗} ∪ {rmax + 1 : Γ} ⇒ Σc(S(E)) = Σc(E) ∀ c ∈
S and thus the sum in (13) cancels. Furthermore, one can
show, using the saturation of E and the variance symmetry,
that Σ2w+1(S(E)) = Σ(E0). Using the same arguments, in
addition to the fact that E (cid:31) E0 ⇒ rmax ≤ Γ− 3w, we obtain
ΣΓ−2w(E) = Σ(Emax). Hence, (13) yields the following:

Sc(E) − Sc(S(E)) = Su(Σ(Emax)) − Su(Σ(E0)).
Combining (12) with (14) and using Lemma 5.5 gives

(14)

Fc(S(E)) − Fc(E) = −Fu(Emax) + Fu(E0) ≤ −∆Fu.

Theorem 5.7: Assume a spatially coupled SS code ensemble
is used for communication through an AWGNC. Fix R < Rpot,
w > K/∆Fu (K is independent of w and Γ) and Γ > 8w
(such that the code is well deﬁned). Then any ﬁxed point error
proﬁle E∗ of the coupled SE satisﬁes E∗ ≺ E0.
Proof: Assume that, under these hypotheses, there exists
a saturated proﬁle E associated to E∗ such that E (cid:31) E0. By
Lemma 5.6 and the positivity of ∆Fu as R < Rpot, we have
|Fc(E) − Fc(S(E))| ≥ ∆Fu. Therefore, by Lemmas 5.2 and
5.4 we get K/w > ∆Fu ⇒ w < K/∆Fu, a contradiction.
Hence, E (cid:22) E0. Since E (cid:31) E∗ we have E∗ ≺ E0.
Corollary 5.8: By ﬁrst taking Γ → ∞ and then w → ∞, the
AMP threshold of the coupled ensemble satisﬁes Rc ≥ Rpot.
This result follows from Theorem 5.7 and Deﬁnition 3.4. It
says that the AMP threshold for the coupled codes saturates
the potential threshold. To prove it cannot surpass it requires a

separate treatment. For our purposes this is not really needed
because we have necessarily Rc < C and we know (Sec. III-C)
that limB→∞ Rpot = C. Thus limB→∞ Rc = C.

ACKNOWLEDGMENTS

J.B and M.D acknowledge funding from the Swiss National
Science Foundation grant num. 200021-156672. We thank
Marc Vuffray and Rüdiger Urbanke for discussions.

REFERENCES

[1] A. Barron and A. Joseph, “Toward fast reliable communication at rates
near capacity with gaussian noise,” in Information Theory Proceedings
(ISIT), 2010 IEEE International Symposium on, June 2010, pp. 315–319.
[2] A. Joseph and A. R. Barron, “Fast sparse superposition codes have
near exponential error probability for R<C,” IEEE Transactions on
Information Theory, vol. 60, no. 2, pp. 919–942, 2014.

[3] A. R. Barron and S. Cho, “High-rate sparse superposition codes with
iteratively optimal estimates,” in Information Theory Proceedings (ISIT),
2012 IEEE International Symposium on.

IEEE, 2012, pp. 120–124.

[4] J. Barbier and F. Krzakala, “Replica analysis and approximate message
passing decoder for superposition codes,” in Information Theory Pro-
ceedings (ISIT), 2014 IEEE International Symposium on, 2014.

[5] C. Rush, A. Greig, and R. Venkataramanan, “Capacity-achieving sparse
superposition codes via approximate message passing decoding,” arXiv
preprint arXiv:1501.05892, 2015.

[6] J. Barbier, C. Schülke, and F. Krzakala, “Approximate message-passing
with spatially coupled structured operators, with applications to com-
pressed sensing and sparse superposition codes,” Journal of Statistical
Mechanics: Theory and Experiment, vol. 2015, no. 5, 2015.

[7] J. Barbier and F. Krzakala, “Approximate message-passing decoder
and capacity-achieving sparse superposition codes,” 2015. [Online].
Available: http://arxiv.org/abs/1503.08040

[8] S. Kudekar, T. Richardson, and R. Urbanke, “Spatially coupled ensem-
bles universally achieve capacity under belief propagation,” Information
Theory, IEEE Transactions on, vol. 59, no. 12, pp. 7761–7813, 2013.
[9] M. Lentmaier, A. Sridharan, J. Costello, D.J., and K. Zigangirov,
“Iterative decoding threshold analysis for ldpc convolutional codes,”
Information Theory, IEEE Transactions on, vol. 56, no. 10, pp. 5274–
5289, 2010.

[10] A. Javanmard and A. Montanari, “State evolution for general approxi-
mate message passing algorithms, with applications to spatial coupling,”
Journal of Information and Inference, vol. 2, no. 2, pp. 115–144, 2013.
[11] A. Yedla, Y.-Y. Jian, P. S. Nguyen, and H. Pﬁster, “A simple proof
of threshold saturation for coupled scalar recursions,” in 7th Interna-
tional Symposium on Turbo Codes and Iterative Information Processing
(ISTC), 2012, pp. 51–55.

[12] S. Kumar, A. J. Young, N. Macris, and H. Pﬁster, “Threshold saturation
for spatially-coupled ldpc and ldgm codes on bms channels,” IEEE
Transactions on Information Theory, vol. 60, pp. 7389–7415, 2013.

[13] M. Bayati and A. Montanari, “The dynamics of message passing on
dense graphs, with applications to compressed sensing,” IEEE Transac-
tions on Information Theory, vol. 57, no. 2, pp. 764 –785, 2011.

[14] A. Yedla, Y.-Y. Jian, P. Nguyen, and H. Pﬁster, “A simple proof of
maxwell saturation for coupled scalar recursions,” Information Theory,
IEEE Transactions on, vol. 60, no. 11, pp. 6943–6965, 2014.

[15] F. Krzakala, M. Mézard, F. Sausset, Y. Sun, and L. Zdeborová,
“Probabilistic reconstruction in compressed sensing: Algorithms, phase
diagrams, and threshold achieving matrices,” Journal of Statistical
Mechanics: Theory and Experiment, vol. P08009, 2012.

[16] F. Caltagirone and L. Zdeborová, “Properties of spatial coupling in

compressed sensing,” CoRR, vol. abs/1401.6380, 2014.

[17] D. Guo, Y. Wu, S. Shamai, and S. Verdú, “Estimation in gaussian noise:
Properties of the minimum mean-square error,” Information Theory,
IEEE Transactions on, vol. 57, no. 4, pp. 2371–2385, 2011.

[18] J. Barbier, “Statistical physics and approximate message-passing
algorithms for sparse linear estimation problems in signal processing
and coding theory,” Ph.D. dissertation, Université Paris Diderot, 2015.
[Online]. Available: http://arxiv.org/abs/1511.01650

[19] A. Joseph and A. R. Barron, “Least squares superposition codes of
moderate dictionary size are reliable at rates up to capacity,” IEEE
Transactions on Information Theory, vol. 58, no. 5, pp. 2541–2557,
2012.

