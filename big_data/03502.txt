Checkpointing to minimize completion time for
Inter-dependent Parallel Processes on Volunteer

Grids

Mohammad Tanvir Rahman Hien Nguyen

Jaspal Subhlok Gopal Pandurangan

Department of Computer Science, University of Houston

Houston, TX 77204, USA

Email: mtrahman3@uh.edu, hxnguyen4@uh.edu, jaspal@uh.edu, gopal@cs.uh.edu

6
1
0
2

 
r
a

 

M
1
1

 
 
]

C
D
.
s
c
[
 
 

1
v
2
0
5
3
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Volunteer computing is being used successfully for
large scale scientiﬁc computations. This research is in the context
of Volpex, a programming framework that supports communicat-
ing parallel processes in a volunteer environment. Redundancy
and checkpointing are combined to ensure consistent forward
progress with Volpex in this unique execution environment char-
acterized by heterogeneous failure prone nodes and interdepen-
dent replicated processes. An important parameter for optimizing
performance with Volpex is the frequency of checkpointing. The
paper presents a mathematical model to minimize the completion
time for inter-dependent parallel processes running in a volunteer
environment by ﬁnding a suitable checkpoint interval. Validation
is performed with a sample real world application running on
a pool of distributed volunteer nodes. The results indicate that
the performance with our predicted checkpoint interval is fairly
close to the best performance obtained empirically by varying
the checkpoint interval.

Index Terms—Fault tolerant execution; checkpointing; volun-

teer computing; PC grids

I. INTRODUCTION

The goal of the research presented in this paper is to
minimize the completion time for inter-dependent parallel pro-
cesses running in a volunteer environment. The pool of hosts
in a volunteer environment consists of distributed computers
which can be used for performing large scale computations
when “idle”. Here “idle” implies the conditions under which
the owner of the machine allows his/her computer’s use for
volunteer computing. The computers can be geographically
distributed and connected through the internet. At present,
volunteer computing is being used successfully for large scale
scientiﬁc computations, commonly employing BOINC [4].
Current large volunteer communities can provide computation
power in the range of Petaﬂops. This CPU power is completely
free and comes from volunteer idle computers located all
over the globe. The parallel processes running on different
volunteer clients can coordinate and communicate with each
other with Volpex [20] which provides a custom-deﬁned
put/get model for communicating processes.

One of the key characteristics of volunteer computing is that
the hosts are highly unreliable as they can leave the available
pool simply because the owner turns them off or starts using
them. Periodic checkpointing and maintaining redundant repli-
cas are important for making continuous forward progress in a
volunteer environment. In this paper, our goal is to minimize

the overall completion time by predicting a suitable checkpoint
interval in the presence of process replication. Hence, this
research is important for effective use of volunteer nodes for
large parallel applications. Our proposed solution is deployed
and evaluated on a pool of volunteer nodes managed by
BOINC and Volpex.

Creating checkpoints is an effective technique to deal with
failures. It is important for minimizing completion time and
increases collective throughput. However, creating checkpoints
consumes time and resources. Making checkpoints too fre-
quently will waste a lot of time and resources, but on the
other hand, making infrequent checkpoints will result in a
signiﬁcant amount of work-loss in case of client failures. The
presence of redundant replicas of individual processes makes
the optimal checkpoint
interval calculation more complex.
To the best of our knowledge, state-of-the-art in checkpoint
optimization does not provide any solution for replicated
coordinated parallel processes.

There is a large body of research on optimizing the check-
point interval, some examples being [12], [22], [17]. However,
most of the earlier work focuses on ﬁnding the optimal check-
point for a single process or independent distributed processes.
Presence of communicating processes fundamentally changes
the execution model as the slowdown or failure of a single
process impacts the entire computation. Presence of replicated
processes further complicates the execution model, as the
computation can continue seamlessly despite failures as long
as at least one replica of each process is alive. Current Volpex
framework uses a heuristic predeﬁned checkpoint
interval
for application execution that is based on the programmer’s
intuition. Work presented in this paper automates the process
of checkpoint interval selection for multiple inter-dependent
parallel processes, each possibly with multiple replicas.

The mathematical model developed for computing the opti-
mal checkpoint interval uses four input parameters: the number
of processes, the number of replicas for each process, time
to create a checkpoint, and the process success distribution
(distribution that gives the probability that the process will
survive till a given time). The model allows the calculation of
the theoretically optimal checkpoint interval. The checkpoint
prediction model was validated in Volpex by running a real
world application with varying number of processes, levels

of replication and checkpoint size. The results show that the
predicted checkpoint interval calculated by our analysis yields
a job completion time that is close to the minimum.

The proposed approach requires success distribution of
computation hosts as input. To ﬁnd an accurate success dis-
tribution, we analyzed client availability over a period of time
for the pool of volunteer hosts available to us. This approach
is time consuming which is a limitation of our approach. On
the other hand, prior knowledge regarding the process failures
in similar settings can be used for estimating the optimal
checkpoint interval.

To summarize, our main contributions are:
1) Designing a probability based mathematical model to
predict a checkpoint interval with the lowest completion
time for inter-dependent parallel processes with mul-
tiple replicas. The true optimal checkpoint interval is
unknown and can only be estimated empirically.

2) Implementation and evaluation of the checkpoint pre-
in a real world volunteer computing
diction model
framework with a real world application to validate our
theoretical analysis.

II. PREVIOUS WORK

Simple optimum checkpoint interval for a single process:
Young [26] initiated the work on approximating the optimum
checkpoint interval for minimizing application run time. He
gave a ﬁrst order approximation to the optimum checkpoint
interval for a single process as:

c ≈(cid:112)2Ts ∗ Tf

T opt

√

c = Time interval between Checkpoints, Ts= Time
where T opt
to save information at a Checkpoint, and Tf = Mean Time
to Failure (MTTF). This is a simple mathematical equation
to ﬁnd the optimal checkpoint interval and very easy to apply
in practice. However, Young did not consider multiple parallel
processes in his work. Our approach is very similar to Young’s
approach (for one process), but we do a simpler analysis,
since we assume that when a process fails it has to wait till
checkpointing to restart. In fact, when we use a crude (ﬁrst-
order) approximation, we get T opt
IV.A) which is essentially the same as Young’s approximation
(but without the factor of
2). The advantage of our approach
is that it is simpler, and also leads to more accurate equation
for T opt
(under the assumptions) and generalizes easily for
multiple processes and many replicas.

c ≈(cid:112)Ts ∗ Tf (see Section

c = (cid:112)2δ(M + R) − δ is an excellent estimator of the

Higher order optimum checkpoint interval for a sin-
gle process: Daly discussed three models for predicting
the runtime and optimum restart interval [8]. He evaluated
these models and used the results to derive a simple method
for calculating the optimum restart interval. He showed that
T opt
optimum compute interval between restart dumps for values
2, where, M = mean time between system
of (T opt
failures, δ = time to write a checkpoint and R = Restart
overhead. Daly continued the work further and developed a
higher order model for ﬁnding the optimum restart interval

c +δ)/M < 1

c

on a system exhibiting Poisson single component failures
[7]. He derived a complete cost function and demonstrated a
perturbation solution that provides accurate high order approx-
imations (99.8% of the exact solution time) to the optimum
checkpoint interval. However, checkpoint interval for inter-
dependent parallel processes are not discussed in Daly’s work.
Multi-level checkpointing (SCR): Moody et al. [19] de-
signed Scalable Checkpoint/Restart(SCR), a multi-level check-
point system that writes checkpoints to RAM, Flash or disk on
the compute node in addition to the parallel ﬁle system. They
developed low-cost checkpointing schemes that are 100x-
1000x faster than a parallel ﬁle system for MPI processes.
However, the problem we are trying to solve is in the context
of Volpex Dataspace API which is a Put/Get communication
model. MPI processes with different level of storage hierarchy
simply do not apply in this framework. Moreover, our problem
considers process replication which is not considered in this
work.

Impact of parameters: Zheng et al. [27] summarized fail-
ure and availability patterns of volatile distributed computing
systems. The authors proposed simple models for characteriz-
ing the impact of parameters on the efﬁciency of checkpointing
with restart and replication schemes. They showed that when
the number of processors and/or the failure rate is high,
it
to use a replication scheme rather than a
checkpoint-restart scheme. However, there is no formulation
for calculating optimal checkpoint interval for inter-dependent
parallel processes in their work.

is beneﬁcial

Host Availability Analysis: One of the key inputs for
measuring the optimal checkpoint in a volunteer environment
is “success distribution” of the system. Success distribution is
dependent on system’s host availability. Several projects have
addressed ﬁnding host availability of a system [16], [10], [6].
Although there is no straightforward way of determining host
availability in a heterogeneous environment, proﬁle modeling
can give a rough estimate of host availability in a volunteer
system. In proﬁle modeling, the client availability pattern [18]
is studied to understand when a computer will be available
for performing a volunteer job. Kondo et al. [13] described an
effective method for classifying subsets of hosts’ availability
in a large distributed heterogeneous system. These methods
and models are critical for the design of stochastic scheduling
algorithms across large systems where host availability is
uncertain. The process of ﬁnding host availability for a large
heterogeneous system is out of the scope for this paper. We
assume that the success distribution will be provided as an
input parameter at the beginning of program execution. More-
over, using workload data and simulation, Jones et al. [14]
showed that application efﬁciency is fairly insensitive to error
in estimation of application’s mean time to interrupt (AMTTI)
or, in other words, mean time to failure.

III. EXECUTION MODEL

The research in this paper is motivated by the challenges
faced in application execution under Volpex. We provide a

brief introduction to the Volpex execution framework as that
also forms the context for the results developed in this paper.
Volpex employs BOINC [5], [4], a well-known middleware
for running scientiﬁc applications over volunteer nodes, for
the basic control and management of execution. Volpex [20]
provides a programming framework and runtime support for
the execution of communicating parallel codes on volunteer
nodes. Volpex has developed two programming frameworks:
the Dataspace API [15], [21] with a Put/Get communication
model and an implementation of a subset of the MPI standard
called the VolpexMPI [2], [3]. Volpex uses BOINC middleware
to recruit and manage volunteer nodes to run the application.
The number of hosts to be recruited depends on the number of
processes, level of replication, the number of requested spare
hosts, and other user-deﬁned parameters. During the execution
of the application, new process instances can be created by
selecting nodes from a pool of “hot spares”. Additional nodes
can be recruited during execution when the pool of spares is
diminished to a preset value because of host failures.

In the Volpex framework, an application executes with n
processes, each with r concurrent executing replicas. Volpex
can explicitly create process replicas during program invo-
cation or a new instance may be created from a checkpoint
to replace a slow or failed process instance. Process replicas
are not aware of the existence of, or coordinate with, other
process replicas and usually act autonomously. A process can
checkpoint its state independently without the coordination
of other processes. The system can recreate a process from
a checkpoint irrespective of whether the original process is
dead or alive, and without coordinating with other replicas
or processes. Volpex uses “heartbeat monitoring” to detect
process failure.

In a checkpointing Volpex application, each process instance
makes a StoreCheckpoint request to the server after performing
a ﬁxed amount of work (for example, ﬁnishing a ﬁxed number
of loop iterations), rather than after a ﬁxed time period.
A fast client will send this request more frequently than a
slower machine. The server determines if the StoreCheckpoint
request will lead to the recording of an actual checkpoint. A
StoreCheckpoint request normally leads to an actual recording
of a checkpoint, if: (1) it represents the most recent checkpoint
state, i.e., there does not already exist a checkpoint on the
server that represents a process state later in logical time
(this is possible with replicas) and (2) a speciﬁed checkpoint
interval has elapsed since the recording of the last checkpoint.
If these conditions are satisﬁed, the server will accept that
StoreCheckpoint request and store a checkpoint on the server.
Otherwise, the server will ignore the request. The pseudo-code
for checking conditions to store a checkpoint in Volpex is as
follows:

If (requested checkpoint number > last saved checkpoint number and
elapsed time from last saved checkpoint > checkpoint interval)

server saves the checkpoint

Else

server ignores the StoreCheckpoint request

Each application is conﬁgured to execute with a ﬁxed
number of replicas for each process. When all replicas of
a process are dead (less common), a new process is created
immediately from the most recent checkpoint on the server.
When a process replica is dead but other replicas remain (more
common), a new instance of the process is created after getting
the next valid StoreCheckpoint request from another replica.
The pseudo-code for checking conditions to start a process
after client failure in Volpex is as follows:

If there is no other replica

If there is another alive replica,

server immediately creates a thread starting from latest checkpoint

server waits till the next StoreCheckpoint request,
then creates a new replica thread starting from latest checkpoint

By default, Volpex applications have to be conﬁgured with
a heuristic ﬁxed checkpoint interval for all the processes as
input before the execution begins. The goal of this work is
to determine the checkpoint interval automatically for appli-
cations that optimizes performance.

IV. A MATHEMATICAL MODEL AND ANALYSIS

In this section, we develop the mathematical framework for
predicting the optimal checkpointing interval. We assume a
simple probabilistic model for process failures and analyze the
optimal checkpoint interval under this assumption. Following
are the input parameters:

1) Number of processes: n
2) Number of replicas for each process: r
3) Time to create a checkpoint: Ts. Ts depends on various
factors like checkpoint size, network congestion, link
bandwidth, client/server conﬁguration etc. We used the
following cost function to calculate the Ts.

Ts = Ts(cl) + Ts(lat) + Ts(up) + Ts(ack)

(1)

where, Ts(cl) = time to create checkpoint
in client,
Ts(lat) = time to send checkpoint from client to server,
Ts(up) = time to upload checkpoint
to server and
Ts(ack)= time to send acknowledgment to client.

4) Success probability distribution (of a single process with
no replica): p = f (t). The success distribution gives,
for a single process having no replica, the probability
p (which depends on t) to reach a checkpoint without
failure. In other words, the probability of a process being
alive till time t is f (t). In this work, we will assume
the success probability distribution to be the exponential
distribution function [23]. The exponential distribution
is commonly used to model failures in similar settings
(e.g., [23], [26]). In particular, it is also used by Young
[26] to model process failures. The main property of the
exponential distribution is the memorylessness property:
given that there is no failure till time t, the probability of
failure till time t + s is exactly the probability of failure
till time s, i.e., f (t + s), given that there is no failure
of the process till time t, is f (s). An equivalent way is
to assume that the occurrence of failures is a Poisson

process with failure rate λ. In other words, failures
are assumed to occur independently and at random.
The success probability distribution of the exponential
distribution is deﬁned as

f (t) = e−λt
where λ is the failure rate or 1
failure (MTTF).

(2)
λ is the mean time to

c

,

Our goal

is to compute T opt

the optimum checkpoint
interval. To do this we will compute the expected time incurred
(under the given success distribution) to successfully reach a
checkpoint (including the time to create a checkpoint). Let’s
denote this expected time by G(Tc), which is a function of Tc.
G(Tc) can be considered the (expected) overhead associated
with having checkpoint interval as Tc under success distribu-
tion p. The “normalized” overhead is G(Tc)/Tc, i.e., the ratio
of the expected overhead time to the actual checkpoint interval
(Tc is the time when “useful” work is done). This captures
the amount of overhead incurred per checkpoint interval. The
is the checkpoint interval
optimum checkpoint interval T opt
that minimizes G(Tc)/Tc.

To simplify our analysis, we make the following assump-

c

tions:

1) A faulty process can be restarted only after every check-
point interval. This is a valid assumption in this context
because Volpex server cannot detect a dead process
immediately. Recruited client sends periodic heartbeat
signals to the server. If server misses a particular client’s
heartbeat for a threshold amount of time, it assumes that
the client is dead and reassigns the job to a new client.
2) Time to detect fault and restart is negligible. This is
also a valid assumption in the context of Volpex because
time to detect and restart is very small compared to the
checkpoint interval. Rarely, a client failure occurs at the
very last moment of the checkpoint interval period. If
a client failure occurs even a few seconds earlier than
the checkpoint interval, then the failure detection and
restart time is overlapped by the remaining interval time.
As a result, no extra time is wasted for fault detection
and restart. Volpex does not have a fail-stop model like
MPI where one process failure triggers other processes’
immediate termination. Moreover, Volpex maintains a
hot standby pool of spare nodes all the time so that a
restart can be done as soon as a process is dead.

3) All the nodes in volunteer network follow the same
success probability distribution. While this is certainly
not the case in practice, it is unrealistic to model each
node individually in a heterogeneous volunteer environ-
ment. It is also unrealistic to have different checkpoint
interval for different nodes. Our hypothesis is that an
analysis based on a success distribution derived from
the average MTTF for a pool of nodes will provide
a realistic estimate of the optimal checkpoint interval.
(Our experimental results validate this hypothesis.)

4) The success probability distribution is an exponential
distribution function. We consider this as a valid as-

sumption because the exponential distribution is com-
monly used to model failures in similar settings (e.g.,
[23], [26]).

A. Analysis for single process with single replica

Assuming that the checkpoint interval is Tc, we calculate
G(Tc), the expected overhead. See Figure 1 which uses a tree
to explain the calculation.

Fig. 1: Illustration to calculate the expected overhead G(Tc).
Edges of the tree denote the probability to reach the next node
and labels outside the nodes denote the time to reach that node
from root.

We start from the root (node 0). After time Tc, the prob-
ability to reach the next checkpoint (node 1) successfully is
given by p = f (Tc) = e−λTc. Since we assumed that a faulty
process can be restarted only after every checkpoint interval
period, if the process fails, after time Tc we will end up in
node 2. In that case we shall try to reach next checkpoint (node
3) in the next Tc time. There is again the probability p to reach
node 3 successfully after time 2Tc. If the process fails again,
we will be on node 4 at time 2Tc. From node 4, we shall
try to reach the next checkpoint (node 5) by 3Tc and so on.
The edges of the tree denote the probability to reach the next
node and labels outside the nodes denote the time to reach
that node from root. For simplicity, we have the time labels
outside the left nodes only. Note that once we successfully
reach the end of a checkpoint interval, we spend Ts time to
create a checkpoint which contributes to the overhead.

From the above discussion, for a single process with no

replica, the expected overhead G(Tc) is

G(Tc) = p(Tc + Ts) + (1 − p)p(2Tc + Ts)+

(1 − p)2p(3Tc + Ts) + (1 − p)3p(4Tc + Ts) + ...
Tc
p
Tc

+ Ts

+ Ts (replacing p with f (Tc))

(3)

=

=

f (Tc)

Thus the normalized overhead is:

G(Tc)

Tc

=

1

f (Tc)

+

Ts
Tc

Thus, replacing f (Tc)n by (1− (1− p)r)n in eq: 3, we get,
for n processes each with r replicas, the expected overhead
is:

(4)

To minimize the normalized overhead for a single process
with no replica, we will differentiate equation 4 with respect
to Tc and set the value to zero.

d
dTc

G(Tc)

d
=
Tc
dTc
f(cid:48)(Tc)
f (Tc)2 +

+

d
dTc

Ts
Tc

1

f (Tc)
Ts
T 2
c

or, 0 =

(since we assume the exponential

where f (Tc) = e−λTc
distribution) and Ts is a constant.
−λe−λTc
(e−λTc)2 +

or, 0 =
or, λTc + 2 ln Tc = ln Ts − ln λ

Ts
T 2
c

(5)

Using WolframAlpha’s [1] computational engines, we can
solve equation 5 and get the optimal checkpoint interval T opt
as follows:

c

√

T opt
c =

2W (

λ

λTs
2

)

(6)

(cid:113) Ts

where W (z) is the Lambert W function. (The Lambert
W function is the inverse function of the function f (W ) =
W eW .)
Using a ﬁrst order approximation, ex ≈ 1 + x, we can get a
λ . Of course, using higher
closed form formula for T opt
order approximations for the exponential function gives more
. Another option is to use compute W
accurate values of T opt
function using mathematical software such as Mathematica.
For example, if checkpoint size = 50KB, λ = 0.0000348074
and Ts = 1 sec then we get, T opt

= 169 sec.

c =

c

c

B. Generalization to multiple processes with many replicas

Next we will consider replication for each process. Suppose
there are 2 replicas for each process. The process will restart
only if both the replicas are dead. For a single process and
without replica, probability to reach a checkpoint without fail-
ure = p. Then for a single process, probability to restart without
ﬁnishing the job = 1− p. If there are 2 replicas, probability to
restart without ﬁnishing the job = (1− p)∗ (1− p) = (1− p)2.
Hence, for a single process and with 2 replicas, the probability
to reach a checkpoint without failure = 1 − (1 − p)2. Hence,
we have that for a single process and with r replicas, the
probability to reach a checkpoint without failure = 1−(1−p)r.
Generalizing, we have for n inter-dependent parallel processes
and with r replicas for each process, the probability for all the
n processes to successfully reach a checkpoint without failure
= (1−(1−p)r)n. This is because, each of the n processes will
successfully reach a checkpoint, if at least one of the replicas
of each process reaches a checkpoint.

G(Tc) =

Tc

(1 − (1 − p)r)n + Ts

And normalized expected overhead is:

G(Tc)

Tc

=

1

(1 − (1 − p)r)n +

Ts
Tc

(7)

(8)

To ﬁnd the optimal checkpoint interval, we will replace p
by f (Tc) in the above equation, differentiate it with respect to
Tc and then set the value to zero.
0 = −n(1 − (1 − f (Tc))r)

−n−1∗ d
dTc

(1−(1−f (Tc))r)− Ts
T 2
c(9)

Setting f (Tc) = e−λTc in eq 9 we get,
0 = −n(1 − (1 − e−λTc)r)

−n−1

∗ d
dTc

(1 − (1 − e−λTc)r) − Ts
T 2
c

or, 0 = n(1 − (1 − e−λTc)r)

−n−1

∗ rλe−λTc(1 − e−λTc)r−1 − Ts
T 2
c
nrλe−λTc (1 − e−λTc )r−1
(1 − (1 − e−λTc)r)n+1

or, Ts
T 2
c

=

(10)

Solving eq 10, we can get optimal checkpoint interval T opt

.

c

As an example, if r = 1 from equation 10 we get,

Ts
T 2
c

= nλenλTc

(11)

By solving equation 11 we can get the optimal checkpoint

interval Tc for r = 1 as below:

2W ( 1

2 λn

Tc =

λnTs

Ts)

(12)

(cid:113) 1

λn

Where W (z) is the Lambert W function. As a numerical
example, if checkpoint size = 50 KB, λ = 0.0000348074 and
c ≈ 42 seconds
Ts = 1 seconds then for n = 16 we get, T opt
c ≈ 29 seconds. For r > 1, we
and for n = 32 we get, T opt
can get T opt
by solving equation 10 using WolframAlpha’s
computational engines.

c

V. EXPERIMENTS AND RESULTS

The theoretical results developed in this paper predict the
checkpoint interval that minimizes the execution time, but they
are based on several assumptions that are, at best, approxima-
tions of real world behavior. The experimental evaluation in
this paper is to determine if the predicted optimal checkpoints
are practically useful, despite the imperfect assumptions.

A. Platform for experiments

Experiments were performed on a testbed of volunteer
nodes managed by BOINC and Volpex. The testbed consisted
of approximately 350 active volunteer nodes. Approximately
20% of the nodes were on the university campus and the
remaining 80% were distributed worldwide. For the pur-
pose of evaluation, Replica Exchange Molecular Dynamics
(REMD) [11], [24], [25], [9] code was executed repeatedly.
This application consists of a set of independent processes
that coordinate and communicate regularly using the Volpex
Dataspace API. The application is instrumented to include
ﬂexible checkpointing; every application process makes fre-
quent checkpoint requests, but an actual checkpoint is stored
only when a request is accepted by the server. Hence the server
can be conﬁgured to deﬁne the actual checkpoint interval.

B. Measurement of parameters for checkpoint prediction

The key system parameters for estimating the optimal
checkpoint interval are the failure distribution that is based
on mean time to failure (MTTF) and the time to record a
checkpoint. We recorded all failures of our system nodes for
a substantial duration of time. Note that failure of a volunteer
node can be caused simply by a system being turned off by
the owner or a temporary loss of network activity, not just
software or hardware faults. We estimated the MTTF for the
nodes in our volunteer pool using the following equation:

M T T F =

Total hours of operation
Total Number of failures

(13)

For the measurement made on our system, we get:

Total Hours of Operation = 13678.67
Total Number of Failures = 1714

MTTF = 7.9805hrs = 28730sec

λ =

1

M T T F

= 0.0000348074

From Equation 1, we know that the checkpointing time
Ts includes the time to save the checkpoint on the client,
the network delay to send the checkpoint information from
user PC to the checkpoint server, the time to upload check-
point on the server and time to send acknowledgment to the
client. Experiments were conducted with 50 KB and 5 MB
checkpoint sizes. The network delay depends on a number of
factors including the network latency between the client PC
and the server, network congestion, and link bandwidth. The
time taken for the creation of a checkpoint on the server can
also vary depending on the workload on the server. In our
experiments, we recorded the time to save every checkpoint
in the server in a log ﬁle. We observed that Ts varies between
200 ms to 1200 ms for 50 KB checkpoints and between
1 second to 290 seconds for 5 MB checkpoints. However,
when multiple processes create independent checkpoints, the
maximum checkpoint interval is the time for which the overall
computation is stalled.

To ﬁnd the Ts value from the recorded log, we computed the
average of the maximum of n∗r random readings from the log
ﬁle (n = number of process and r = number of replica). This
computation was performed by iteratively selecting a large set
of random readings and computing the average.

For 50 KB checkpoints, we employed Ts = 1 second as the
estimated time to create a checkpoint. For 5 MB checkpoints,
we estimated Ts = 156, 187 and 212 s for 16, 32 and 64
processes respectively. Please note that we used one Ts value
for different n ∗ r values for 50 KB checkpoints since they
differ very little. Finally, the predicted optimal checkpoint
intervals were computed from the model developed in section
III using WolframAlpha’s [1] computational engines.

C. Experimental results

We executed the REMD code on 16 and 32 processes with
no replicas, 2 replicas for each process and 3 replicas for each
process. When going from 16 to 32 nodes, the problem size is
scaled up (doubled) such that the computation workload per
process is unchanged. The checkpoint sizes were 50 KB and 5
MB. A ﬁxed checkpoint interval between 12 to 3200 seconds
was employed for each run and the completion times were
recorded. Each experiment was run ten times. Note that it is
very important to have multiple runs for volunteer nodes as
the execution time is expected to vary signiﬁcantly between
the runs based on the failure patterns of nodes in a run as well
as the CPU and network characteristics of the speciﬁc sets of
nodes selected for execution in each run.

Once we completed all the experiments, we picked the low-
est median completion time from each scenario and the corre-
sponding heuristically computed optimal checkpoint interval.
We used these lowest completion times and the corresponding
optimal checkpoint intervals for performance evaluation.

The pattern of completion time for varying checkpoint
intervals is illustrated in Figures 2 and 3 with different levels
of replication. These box plots represent the results as quartiles
of execution times, including the minimum, maximum and
the median execution time. Substantial variation is observed
between execution runs due to the nature of a volunteer
computing platform. We observe that in Figure 2, minimum
completion time is achieved with a lower checkpoint interval
compared to Figure 3. The reason is that, with a larger
checkpoint size, it is often better to save a checkpoint less
frequently. We note that there is often a signiﬁcant difference
between the predicted optimal checkpoint interval and the
checkpoint interval for which the lowest median execution
time is recorded. However, we note that the actual execution
time with the predicted optimal checkpoint interval is typically
very close to the measured lowest median execution time. This
is examined further in this section.

Table I presents the application performance with predicted
checkpoint intervals, along with the best and worst measured
performance over the entire range of checkpoint intervals. Lin-
ear interpolation was employed for ﬁnding the job completion
time for the predicted optimal checkpoint interval when the in-
terval was between points for which measurements were made.

Fig. 2: Completion times for varying checkpoint intervals in different execution scenarios with 50 KB checkpoints. The box
plot shows the lowest, 25th quartile(bottom of green box), median, 75th quartile(top of purple box), and the highest execution
times over multiple runs. Solid red arrow indicates the checkpoint interval with the lowest median completion time, while the
blue blank arrow indicates our predicted optimal checkpoint interval.

The percentage difference between the lowest completion time
and completion time with the predicted optimal checkpoint
interval is the performance prediction error.

We observe from Table I that percentage difference between
the lowest measured completion time and completion time
with the predicted optimal checkpoint
interval (prediction
error) ranges between 0.82% and 33.45% with an average
prediction error of 14.26%. In a volunteer framework this is
a low error given the inherent performance variations in a
volunteer framework. Hence, the predicted checkpoints are
practically useful; in other words only an improvement of
around 14% is expected with an exhaustive search for the best

checkpoint interval.

Table I also lists the percentage difference between the high-
est(worst) measured completion time and the completion time
with the predicted optimal checkpoint interval, which ranges
between 14.52% and 188.19% with an average difference of
63.79%. The point is that selecting a good checkpoint interval
is important and selecting a poor checkpoint interval heuristi-
cally can have substantial implications for performance. The
predicted checkpoint interval always leads to a performance
fairly close to the optimal performance, and far superior than
the performance with a poorly selected checkpoint interval.

Figure 4 shows the performance penalty with employing

0500100015002000250030003500400012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 2, n = 16, size = 50KB020004000600080001000012000140001600012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 1, n = 32, size = 50KB                                            05001000150020002500300035004000450012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r= 2, n = 32, size = 50KB0500100015002000250030003500400012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 3, n = 16, size = 50KB050010001500200025003000350012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 3, n = 32, size = 50KB02000400060008000100001200014000160001800012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 1, n = 16, size = 50KB                                            Fig. 3: Completion times for varying checkpoint intervals in different execution scenarios with 5 MB checkpoints. The box
plot shows the lowest, 25th quartile(bottom of green box), median, 75th quartile(top of purple box), and the highest execution
times over multiple runs. Solid red arrow indicates the checkpoint interval with the lowest median completion time, while the
blue blank arrow indicates our predicted optimal checkpoint interval.

Checkpoint

size

n

r

Median
of lowest
completion

time,
Tbest
(s)

Median

of

highest
completion

time,
Tworst

(s)

50 KB
50 KB
50 KB
50 KB
50 KB
50 KB
5 MB
5 MB
5 MB
5 MB

16
16
16
32
32
32
16
16
32
32

1
2
3
1
2
3
1
2
1
2

3344
1946
1463
4362
2081
1348
5028
2217
10934
2906

5191
2383
1973
6108
2388
1732
10333
4222
17298
18374

Our

predicted
Checkpoint
Interval,

Tc
(s)

42
297
851
29
235
714
465
1708
339
1398

Calculated
completion

time
for Tc,
Tpredict

(s)

Abs. %

of

difference
between
Tbest
and

Abs. %

of

difference
between
Tbest
and

Tpredict

(%)
1.34
13.74
7.74
0.82
9.11
23.93
33.45
17.50
31.08
3.94
14.26
33.45

Tworst

(%)
55.26
22.43
34.87
40.03
14.52
28.49
105.50
90.46
58.21
188.19
63.79
188.19

3388
2213
1576
4398
2270
1671
6710
2604
14331
3020

Average

Max

TABLE I: Performance comparison among measured best,
worst and our predicted optimal checkpoint interval

a ﬁxed predeﬁned checkpoint
interval for all scenarios in
comparison with the measured lowest completion time in
each scenario. It also shows the performance penalty with
a predicted optimal checkpoint
interval (ﬁrst set of bars)
for all scenarios in comparison with the measured lowest
completion time in each scenario. Clearly using the predicted
optimal checkpoint interval fares much better on average than
employing any predeﬁned checkpoint interval all the time.

Fig. 4: Performance penalty with always using a predeﬁned
ﬁxed checkpoint interval versus the performance penalty using
our predicted optimal checkpoint interval (Tc).

Moreover, even for the worst case, employing a predicted
checkpoint yields a performance within
33% of the best
measured performance, whereas it ranges between 39% and

0200040006000800010000120001400016000180002000012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 1, n = 16, size = 5MB                                            05000100001500020000250003000012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 1, n = 32, size = 5MB                                            020004000600080001000012000140001600012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 2, n=32, size = 5MB0100020003000400050006000700012255010020040080016003200Completion Time(sec)Check Point Interval(sec)r = 2, n=16, size = 5MB020406080100120140160180200Tc12255010020040080016003200% of performance decreasewith lowest measured completion timeCheckpoint Interval (s)AvgMax188% for a ﬁxed checkpoint interval.

it

Hence our predicted checkpoint interval is not truly optimal
but
leads to an execution time close to the minimum
possible job execution time. We did not know the true optimal
checkpoint interval that results in the lowest completion time
beforehand as it is determined empirically. The goal was to
predict a checkpoint interval that yields an execution time
close to the optimal. Given that the performance difference
with two different checkpoints can be 188% or higher, we
claim that the predicted checkpoint interval is an excellent
choice in practice. We do expect some error in identifying the
optimal checkpoint interval given the nature of the volunteer
environment where the execution performance typically varies
signiﬁcantly between runs. Also, this work makes a number
of pragmatic assumptions detailed earlier that are the likely
reasons for suboptimal experimental results.

VI. CONCLUDING REMARKS

This paper introduces a mathematically-based methodology
to estimate a checkpoint interval that minimizes completion
time for communicating inter-dependent parallel processes
running in a high failure volunteer environment employing
checkpointing and replication for fault tolerance. The results of
the model are evaluated with the Volpex execution framework
by running a real world application with various checkpoint
size and replication. The results indicate that the model is
effective in identifying a checkpoint interval that leads close
to best possible application performance in this environment.
Since the true optimal checkpoint interval can only be deter-
mined empirically after extensive experimentation, a predicted
checkpoint interval is the only reasonable choice, which is
much better than taking an arbitrary value.

We believe, this is the ﬁrst research project which addresses
the optimization of checkpointing for communicating paral-
lel processes that must employ checkpointing and process
replication for effective execution because of the high node
failure rates. A number of assumptions were made in this work
regarding the failure distribution of nodes and the modeling of
execution with checkpointing and replication. Future work will
generalize the checkpoint interval prediction model. However,
we believe, the current model can predict checkpoint intervals
that are valuable in practice. Future work will also address
evaluation in a larger number of scenarios and different size
checkpoints.

Finally, while the checkpoint prediction model is evaluated
in a volunteer environment, this work presents a fundamental
contribution towards fault tolerant distributed systems. The
results are applicable to other distributed systems such as
computation clouds where replication and checkpointing are
used together to gain acceptable performance in the face of
failures.

REFERENCES

[1] Wolframalpha. http://www.wolframalpha.com.
[2] R. Anand, E. Gabriel, and J. Subhlok, “Communication target selection
for replicated MPI processes,” in R. Keller, E. Gabriel, M. Resch, J.
Dongarra (Eds.) Recent Advances in the Message Passing Interface,
LNCS 6305, Stuttgart, Germany, September 2010, pp. 198–207.

[3] R. Anand, T. LeBlanc, E. Gabriel, and J. Subhlok, “A robust and efﬁcient
message passing library for volunteer computing environments,” Journal
of Grid Computing, vol. 9, no. 3, pp. 325–344, 2011.

[4] D. P. Anderson, “BOINC: a system for public-resource computing and
storage,” in GRID ’04: Proceedings of the 5th IEEE/ACM International
Workshop on Grid Computing. Washington, DC, USA: IEEE Computer
Society, 2004, pp. 4–10.

[5] D. Anderson, C. Christensen, and B. Allen, “Designing a runtime system
for volunteer computing,” in Proceedings of the Supercomputing (SC),
2006.

[6] A. Andrzejak, D. Kondo, and D. Anderson, “Exploiting non-dedicated
resources for cloud computing,” in Proceedings of the Network Opera-
tions and Management Symposium (NOMS), 2010, pp. 341 – 348.

[7] J. T. Daly, “A higher order estimate of the optimum checkpoint interval
for restart dumps,” Future Generation Computer Systems, vol. 22, no. 3,
pp. 303–312, 2006.

[8] J. Daly, “A model for predicting the optimum checkpoint interval for
restart dumps,” Proceedings of the 2003 International Conference on
Computational Science, pp. 3–12, 2003.

[9] A. Dhar, A. Samiotakis, S. Ebbinghaus, L. Nienhaus, D. Homouz,
M. Gruebele, and M. S. Cheung, “Structure, function and folding
of phosphoglycerate kinase are strongly perturbed by macromolecular
crowding,” PNAS, vol. 107, pp. 17 586–17 591, 2010.

[10] T. Estrada, M. Taufer, and D. P. Anderson, “Performance prediction
and analysis of BOINC projects: An empirical study with EmBOINC,”
Journal of Grid Computing, vol. 7, no. 4, pp. 537–554, 2009.

[11] D. Homouz, M. Perham, A. Samiotakis, M. S. Cheung, and P. Wittung-
Stafshede, “Crowded, cell-like environment induces shape changes in
aspherical protein,” Proceedings of the National Academy of Sciences,
vol. 105, no. 33, pp. 11 754–11 759, 2008.
[Online]. Available:
http://www.pnas.org/content/105/33/11754.abstract

[12] J. Hursey, T. I. Mattox, and A. Lumsdaine, “Interconnect agnostic
checkpoint/restart in Open MPI,” in HPDC ’09: Proceedings of the
18th ACM International Symposium on High Performance Distributed
Computing. New York, NY, USA: ACM, 2009, pp. 49–58.

[13] B. Javadi, D. Kondo, J. Vincent, and D. Anderson, “Discovering statis-
tical models of availability in large distributed systems: An empirical
study of SETI@home,” IEEE Transactions on Parallel and Distributed
Systems,, vol. 22, no. 11, pp. 1896–1903, Nov 2011.

[14] W. M. Jones, J. T. Daly, and N. DeBardeleben, “Application monitoring
and checkpointing in HPC: Looking towards exascale systems,” in
Proceedings of the 50th Annual Southeast Regional Conference, ser.
ACM-SE ’12, 2012, pp. 262–267.

[15] N. Kanna, J. Subhlok, E. Gabriel, and D. Anderson, “A communication
framework for fault-tolerant parallel execution,” in Proceedings of the
22nd International Workshop on Languages and Compilers for Parallel
Computing, Newark, DE, 2009.

[16] D. Kondo, A. Andrzejak, and D. P. Anderson, “On correlated avail-
ability in internet-distributed systems,” in 9th IEEE/ACM International
Conference on Grid Computing (Grid 2008), Tsukuba, Japan, Sep 2008.
[17] Y. Liu, R. Nassar, C. Leangsuksun, N. Naksinehaboon, M. Paun, and
S. Scott, “An optimal checkpoint/restart model for a large scale high
performance computing system,” in IEEE International Symposium on
Parallel and Distributed Processing, April 2008, pp. 1–9.

[18] D. Lzaro, D. Kondo, and J. M. Marqus, “Long-term availability pre-
diction for groups of volunteer resources,” Journal of Parallel and
Distributed Computing, vol. 72, no. 2, pp. 281 – 296, 2012.

[19] A. Moody, G. Bronevetsky, K. Mohror, and B. de Supinski, “Design,
modeling, and evaluation of a scalable multi-level checkpointing sys-
tem,” in International Conference for High Performance Computing,
Networking, Storage and Analysis (SC), 2010, Nov 2010, pp. 1–11.

[20] H. Nguyen, E. Pedamallu, J. Subhlok, E. Gabriel, Q. Wang, M. Che-
ung, and D. Anderson, “An execution environment for robust parallel
computing on volunteer PC grids,” in ICPP 2012: 2012 International
Conference on Parallel Processing, Pittsburgh, PA, Sep 2012.

[21] E. Pedamallu, H. Nguyen, N. Kanna, Q. Wang, J. Subhlok, E. Gabriel,
M. Cheung, and D. Anderson, “A robust communication framework
for parallel execution on volunteer PC grids,” in CCGrid 2011: The
11th IEEE/ACM International Symposium on Clusters, Cloud and Grid
Computing, Newport Beach, CA, May 2011.

[22] S. Priya, M. Prakash, and K. Dhawan, “Fault tolerance-genetic algorithm
for grid task scheduling using check point,” in Sixth International
Conference on Grid and Cooperative Computing, 2007, Aug 2007, pp.
676–680.

[23] S. Ross, Applied Probability Models with Optimization Applications.

Dover Publications, 1992.

[24] L. Stagg, S.-Q. Zhang, M. S. Cheung, and P. Wittung-Stafshede,
“Molecular crowding enhances native structure and stability of
Alpha/Beta protein ﬂavodoxin,” Proceedings of the National Academy
of Sciences, vol. 104, no. 48, pp. 18 976–18 981, 2007. [Online].
Available: http://www.pnas.org/content/104/48/18976.abstract

[25] Q. Wang, K.-C. Liang, A. Czader, M. N. Waxham, and M. S. Cheung,
“The effect of macromolecular crowding ionic strength and calcium
binding on calmodulin dynamics,” PLoS Comput Biol, vol. 7, no. 7,

2011.

[26] J. W. Young, “A ﬁrst order approximation to the optimum checkpoint
interval,” Communications of the ACM, vol. 17, no. 9, pp. 530–531,
1974.

[27] R. Zheng and J. Subhlok, “A quantitative comparison of checkpoint with
restart and replication in volatile environments,” University of Houston,
Tech. Rep. UH-CS-08-06, June 2008.

