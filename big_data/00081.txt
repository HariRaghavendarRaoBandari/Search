6
1
0
2

 

b
e
F
9
2

 

 
 
]

.

R
P
h
t
a
m

[
 
 

1
v
1
8
0
0
0

.

3
0
6
1
:
v
i
X
r
a

ON THE POTTS ANTIFERROMAGNET ON RANDOM GRAPHS

AMIN COJA-OGHLAN∗ AND NOR JAAFARI

ABSTRACT. Extending a prior result of Contucci et al. [Comm. Math. Phys. 2013], we determine the free energy of the Potts

antiferromagnet on the Erd˝os-Rényi random graph at all temperatures for average degrees d ≤ (2k − 1)ln k − 2− k−1/2. In

particular, we show that for this regime of d there does not occur a phase transition.

Mathematics Subject Classiﬁcation: 05C80 (primary), 05C15 (secondary)

1. INTRODUCTION

Zβ(G)

and Zβ(G) = Xτ:V →[k]

1.1. Background and motivation. The Gibbs measure of the k-spin Potts antiferromagnet at inverse temperature
β ≥ 0 on a graph G = (V, E ) is the probability measure on the set of all maps σ : V → [k] = {1, . . . , k} deﬁned by
exp(−βHG (τ)).

, where HG (σ) = |{e ∈ E : |σ(e)| = 1}|

exp(−βHG (σ))

µG,β(σ) =

(1.1)

Thus, if we think of [k] as a set of colors, then the function HG , the Hamiltonian of G, maps a color assignment σ to
the number of monochromatic edges. Moreover, β ∈ [0,∞) 7→ Zβ(G) is known as the partition function. The Potts
antiferromagnet is one of the best-known models of statistical physics. Accordingly, it has been studied extensively
on a wide class of graphs, particularly lattices [10, 25, 27]. The aim of the present paper is to study the model on
the Erd˝os-Rényi random graph G = G(n, m). Throughout the paper, we let m = ⌈dn/2⌉ for a number d > 0 that
remains ﬁxed as n → ∞. We also assume that the number k ≥ 3 of colors remains ﬁxed as n → ∞.

The Potts model on the random graph G is of interest partly due to the connection to the k-colorability problem.
Indeed, the larger β, the more severe the “penalty factor” of exp(−β) that each monochromatic edge induces in
(1.1). Thus, if the underlying graph is k-colorable, then for large β the Gibbs measure will put most of its weight on
color assignments that leave few edges monochromatic. Ultimately, one could think of the uniform distribution
on k-colorings as the “β = ∞”-case of the Gibbs measure (1.1). Now, consider the problem of ﬁnding a k-coloring
of the random graph by a local search algorithm such as Simulated Annealing. Then most likely the algorithm will
start from a color assignment that has quite a few monochromatic edges. As the algorithm proceeds, it will attempt
to gradually reduce the number of monochromatic edges by running the Metropolis process for the Gibbs measure
(1.1) with a value of β that increases over time. Speciﬁcally, β has to be large enough to make progress but small
enough so that the algorithm does not get trapped in a local minimum of the Hamiltonian. Hence, to ﬁgure out
whether such a local search algorithm will ﬁnd a proper k-coloring in polynomial time, it is instrumental to study
the “shape” of the Hamiltonian.

To this end, it is key to get a handle on the free energy, deﬁned as E[ln Zβ(G)]. We take the logarithm because
Zβ(G) scales exponentially in the number n of vertices. As a standard application of Azuma’s inequality shows
that ln Zβ(G) is concentrated about its expectation (see Fact 1.2 below), 1
n | ln Zβ(G)− E[ln Zβ(G)]| converges to 0
in probability. Furthermore, if E[ln Zβ(G)] ∼ ln E[Zβ(G)] for certain d, β, then the Hamiltonian can be studied via
an easily accessible probability distribution called the planted model. This trick has been applied to the “proper”
graph coloring problem as well as to other random constraint satisfaction problems successfully [2, 26].

1.2. The main result. Because our motivation largely comes from the random graph coloring problem, we are
going to conﬁne ourselves to values of d where the random graph G is k-colorable w.h.p. Although the precise
k-colorability threshold dk−col is not currently known, we have [12, 14]

(2k − 1) ln k − 2ln 2+ ok (1) ≤ dk−col ≤ (2k − 1) ln k − 1+ ok (1),

(1.2)

Date: March 2, 2016.
∗The research leading to these results has received funding from the European Research Council under the European Union’s Seventh

Framework Programme (FP/2007-2013) / ERC Grant Agreement n. 278857–PTCC.

1

where ok (1) hides a term that tends to 0 in the limit of large k. The following theorem determines 1
n
almost up to the lower bound from (1.2).
Theorem 1.1. There is k0 > 0 such that for all k ≥ k0, d ≤ d⋆ = (2k − 1) ln k − 2− k−1/2, β > 0 we have

E[ln Zβ(G)]

1
n

lim
n→∞

E[ln Zβ(G)] = lim
n→∞

1
n

ln E[Zβ(G)] = ln k +

ln(1− (1− exp(−β))/k).

(1.3)

d
2

Clearly, the function on the r.h.s. of (1.3) is analytic in β ∈ (0,∞). Thus, in the language of mathematical physics
Theorem 1.1 implies that the Potts antiferromagnet on the random graph does not exhibit a phase transition for
any average degree d < d⋆.
1.3. Related work. The problem of determining the k-colorability threshold of the random graph was raised in
the seminal paper by Erd˝os and Rényi and is thus the longest-standing open problem in the theory of random
graphs [20]. Achlioptas and Friedgut [1] proved the existence of a non-uniform sharp threshold. Moreover, a
simple greedy algorithm ﬁnds a k-coloring for degrees up to about k ln k, approximately half the k-colorability
threshold [3]. Further, Achlioptas and Naor [4] used the second moment method to establish a lower bound of
dk−col ≥ 2(k−1) ln k+ok (1), which matches the ﬁrst-moment upper bound dk−col ≤ (2k−1) ln k+ok (1) up to about
an additive ln k. Coja-Oghlan and Vilenchik [14] improved the lower bound to dk−col ≥ (2k−1) ln k−2ln 2+ok (1) via
a second moment argument that incorporates insights from non-rigorous physics work [28]. On the other hand,
Coja-Oghlan [12] proved dk−col ≤ (2k − 1) ln k − 1+ ok (1). The results from [4, 14] were subsequently generalized to
various other models, including random regular graphs and random hypergraphs [5, 13, 17, 22].

The Potts antiferromagnet on the random graph was studied before by Contucci, Dommers, Giardina and
Starr [15], who generalized the second moment argument from [4] to the Potts model. In particular, [15] shows
that (1.3) holds for all β ≥ 0 if d ≤ (2k − 2) ln k − 2. An analogous result was recently obtained (among other things)
by Banks and Moore [6] for a variant of the stochastic block model that resembles the Potts antiferromagnet. Their
proof is based on [4] as well. In the present paper we improve the corresponding results of [6, 15] by extending the
physics-enhanced second moment argument from [14] to the Potts antiferromagnet.

1
n

Physics considerations suggest that for average degrees d > (2k − 1) ln k − 2ln 2+ ok (1) a phase transition does
occur, i.e., the function β ∈ (0,∞) 7→ limn→∞
E[ln Zβ(G)] is non-analytic [23, 24, 28]. The existence and location
of the condensation phase transition has been established asymptotically in the hypergraph 2-coloring and the
hardcore model and precisely in the regular k-SAT model and the k-colorability problem [7, 8, 9, 11]. However, the
Potts antiferromagnet is conceptually more challenging than hardcore, k-SAT or hypergraph 2-coloring because
the “variables” (viz. vertices) can take more than two values (colors). Potts is also more difﬁcult than k-coloring
because of the presence of the inverse temperature parameter β. In fact, the present work is partly motivated by
studying condensation in the Potts antiferromagnet, and we hope that Theorem 1.1 and its proof may pave the way
to pinpointing the phase transition precisely, see Section 2.5 below. Additionally, as mentioned above, Theorem 1.1
implies that for d ≤ (2k−1) ln k−2−k−1/2 the Hamiltonian can be studied by way of the planted model. Finally, the
ferromagnetic Potts model (where the Gibbs measure favors monochromatic edges) is far better understood than
the antiferromagnetic version [16].

1.4. Preliminaries. Throughout the paper we assume that k ≥ k0 for a large enough constant k0 > 0. Moreover, let

cβ = 1− exp(−β).

Unless speciﬁed otherwise, the standard O-notation refers to the limit n → ∞. We always assume tacitly that n is
sufﬁciently large. Additionally, we use asymptotic notation in the limit of large k with a subscript k.

Fact 1.2. For any δ > 0 there is ε = ε(δ, β, d) > 0 such that limsupn→∞
Proof. If G,G′ are multi-graphs such that G′ can be obtained from G by adding or deleting a single edge, then
| ln Zβ(G)− ln Zβ(G′)| ≤ 2β. Hence, the assertion follows from Azuma’s inequality.
(cid:3)

n ln P[| ln Zβ(G)− E[ln Zβ(G)]| > δn] < −ε.

1

If s is an integer, we write [s] for the set {1, . . . , s}. Further, if v is a vertex of a graph G, then ∂v = ∂G (v) is the set
of neighbors of v in G. If ρ is a matrix, then by ρi we denote the i th row of ρ and by ρi j the j th entry of ρi . Further,
the Frobenius norm of a k × k-matrix ρ is

kρk2 =" Xi,j∈[k]

2

ρ2

i j#1/2

.

For a probability distribution p : Ω → [0, 1] on a ﬁnite set Ω we denote by

H (p) = − Xx∈Ω

p(x) ln p(x)

the entropy of p (with the convention that 0ln 0 = 0). Additionally, if ρ is a k × k-matrix with non-negative entries,
then we let

Further, h : [0, 1] → R denotes the function

H (ρ) = − Xi,j∈[k]

ρi j ln ρi j .

We will use the following standard fact about the entropy.

h(z) = −z ln z − (1− z) ln(1− z).

Fact 1.3. Let p ∈ [0, 1]k be such thatPk

i=1 pi = 1. Let I ⊂ [k] and suppose that q =Pi∈I pi ∈ (0, 1). Then
H (p) ≤ h(q)+ q ln|I|+ (1− q) ln(k −|I|).

Lemma 1.4 (Chernoff bound, e.g. [21]). Let X be a binomial random variable with mean µ > 0. Then for any t > 1,
we have P[X > t µ] ≤ exp[−t µ ln(t /e)].

2. OUTLINE

We prove Theorem 1.1 by generalizing the second moment argument for k-colorings from [14] to the partition
function of the Potts antiferromagnet. In this section we describe the proof strategy. Most of the technical details
are left to the subsequent sections.

2.1. The ﬁrst moment. As a ﬁrst step we calculate the ﬁrst moment E[Zβ(G)]. This is pretty straightforward; in
fact, it has been done before [15]. Nonetheless, we go over the calculations to introduce a few concepts that will
prove important in the second moment argument as well.

To lower-bound Zβ(G) we follow Achlioptas and Naor [4] and work with “balanced” color assignments whose

Proposition 2.1 ([15]). For all β, d > 0 we have E[Zβ(G)] = Θ¡kn¡1− cβ/k¢m¢ .
color classes are all about the same size. Speciﬁcally, call σ : [n] → [k] balanced if ¯¯|σ−1(i )|− n
1, . . . , k. Of course, by Stirling’s formula the set B = B(n, k) of all balanced σ : [n] → [k] has size |B| = Θ(kn). Let

k¯¯ ≤ pn for all i =

be the partition function restricted to balanced maps. Moreover, let

be the number of monochromatic edges of the complete graph. Then uniformly for all balanced σ,

Zβ,bal(G) = Xσ∈B

HKn (σ) =

k

exp¡−βHG (σ)¢
Xi=1Ã|σ−1(i )|
!.
! =Ãn
2! 1
k + O(n).

2

HKn (σ) = kÃ n

k + O(pn)

2

Hence, by Stirling’s formula

E£exp¡−βHG (σ)¢¤ =

Combining (2.1) and (2.2), we ﬁnd

E[Zβ,bal(G)] = Xσ∈B

m

Xm1=0
= Θ(1)

2¢m!−1
!Ã¡n
!m−m1

m

m1

!Ã¡n
2¢− HKn (σ)
m − m1
!m1Ã1−

exp(−βm1)ÃHKn (σ)
Xm1=0Ã m
m1!Ã HKn (σ)
exp(β)¡n
¡n
2¢
2¢
E£exp¡−βHG (σ)¢¤ = Θ³kn¡1− cβ/k¢

HKn (σ)

nd

2 ´ .

3

(2.1)

.

(2.2)

(2.3)

k¡n
On the other hand, for all σ we have HKn (σ) ≥ 1
2¢− n by convexity. Therefore, (2.2) yields
E£exp¡−βHG (σ)¢¤ ≤ O³kn¡1− cβ/k¢

E[Zβ(G)] =Xσ

2 ´.

nd

Combining (2.3) and (2.4), we obtain Proposition 2.1. Moreover, comparing (2.3) and (2.4), we see that E[Zβ,bal(G)]
and E[Zβ(G)] are of the same order of magnitude. Since it is technically more convenient to work with Zβ,bal(G),
we are going to perform the second moment argument for that random variable.

(2.4)

2.2. The second moment. Following [4], we deﬁne the overlap matrix ρ(σ, τ) = (ρi j (σ, τ))i,j∈[k] of σ, τ : [n] → [k]
by letting

ρi j (σ, τ) =

k

n |σ−1(i )∩ τ−1( j )|.

(2.5)

Thus, k−1ρi j (σ, τ) is the fraction of vertices with color i under σ and color j under τ. Let R = R(n, k) = {ρ(σ, τ) :
σ, τ ∈ B} be the set of all possible overlap matrices and set

Zρ,bal(G) = X(σ,τ)∈B2

ρ(σ,τ)=ρ

exp¡−β (HG (σ)+ HG (τ))¢ .

Then

Further, deﬁne

E[Zβ,bal(G)2] = X(σ,τ)∈B2

E£exp¡−β (HG (σ)+ HG (τ))¢¤ = Xρ∈R
kρk2
β# .
k2 c2

ln"1−

cβ +

d
2

2
k

2

fd ,β(ρ) = H (k−1ρ)+

E[Zρ,bal(G)].

Then an elementary argument similar to the proof of Proposition 2.1 yields

Proposition 2.2 ([15]). Uniformly for all ρ ∈ R we have E[Zρ,bal(G)] = exp(n fd ,β(ρ)+ o(n)).
The function fd ,β is a sum of an entropy term H (k−1ρ) and an “energy term”

E (ρ) = Ed ,β(ρ) =

d
2

ln"1−

2
k

cβ +

2

kρk2
β#.
k2 c2

For future reference we note that

∂
∂ρi j

H (k−1ρ) =

∂
∂ρi j

E (ρ) =

1

k ¡−1− ln(ρi j )¢,
c2
βρi j
1− 2
k cβ +kρk2

d
k2

.

2cβ/k2

The number |R| of summands on the right hand side of (2.6) is easily bounded by nk 2

. Therefore,

1

n

ln E[Zβ,bal(G)2] =

1

n

ln Xρ∈R

E[Zρ,bal(G)] ∼ max
ρ∈R

ln E[Zρ,bal(G)] ∼ max
ρ∈R

fd ,β(ρ).

1

n

Denote by S the set of all singly-stochastic matrices and by D the set of all doubly-stochastic k × k matrices, re-
spectively. ThenSn≥1 R(n, k)∩ D is a dense subset of D. Together with (2.10) the continuity of f therefore implies

1

Setting ¯ρ = k−11 to be the barycenter of D, we obtain from Proposition 2.2 that

(2.6)

(2.7)

(2.8)

(2.9)

(2.10)

(2.11)

(2.12)

ln E[Zβ,bal(G)2] ∼ max
ρ∈D

n

fd ,β(ρ).

fd ,β( ¯ρ) ∼

2
n

ln E£Zβ,bal(G)¤ .

4

Hence, just as in the case of proper k-colorings [4, 15], a necessary condition for the success of the second moment
method is that the function fd ,β attains its maximum on D at the point ¯ρ.

2.3. Small average degree or high temperature. Contucci, Dommers, Giardina and Starr [15] proved that the max-
imum in (2.11) is indeed attained at ¯ρ if the average degree is a fair bit below the k-colorability threshold.

Theorem 2.3 ([15]). Assume that d < 2(k − 1) ln(k − 1). Then (1.3) holds for all β > 0.

Comparing this result with (1.2), we see that Theorem 2.3 applies to degrees about an additive ln k below the
k-colorability threshold. The proof of Theorem 2.3 builds upon ideas of Achlioptas and Naor [4]. More precisely,
solving the maximization problem from (2.11) directly emerges to be surprisingly difﬁcult. Hence, Achlioptas and
Naor suggested to enlarge the domain to the set of singly stochastic matrices. Clearly, the maximum over the larger
space is an upper bound on the maximum over the set of doubly-stochastic matrices. Further, because the set of
singly-stochastic matrices is a product of simplices, the relaxed optimization problem can be tackled with a fair
bit of technical work. Crucially, for d < 2(k − 1) ln(k − 1) the maximum of the relaxed problem is attained at ¯ρ.
However, for only slightly larger values of d the maximum is attained at a different point, and thus the relaxed
second moment argument fails.

Apart from the case of small d, the second case that is relatively straightforward is that of small β (the “high

temperature” case in physics jargon). More precisely, in Section 3 we will prove the following.

Proposition 2.4. If d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] and β ≤ ln k, then (1.3) holds.

For d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] Proposition 2.4 improves upon the result from [15], which yields (1.3)
merely for β ≤ β0 for an absolute constant β0 (independent of k). The proof of Proposition 2.4 is by way of relaxing
(2.10) to singly-stochastic matrices as well and builds upon arguments developed in [14] for k-colorability.

2.4. Large degree and low temperature. The most challenging constellation is that of d beyond 2(k − 1) ln(k − 1)
and β large. In this regime we do not know how to solve the maximization problem (2.10). In particular, the trick of
relaxing the problem to the set of all singly-stochastic matrices does not work. Instead, following [14] we are going
add further constraints to the problem. That is, we are going to apply the second moment method to a modiﬁed
random variable that is constructed so as to ensure that certain parts of the domain D cannot contribute to (2.10)
signiﬁcantly.

The construction is guided by the physics prediction [23] that for large d and β the Gibbs measure µG “decom-
poses” into an exponential number of well-separated clusters. Of course, it would be non-trivial to turn this notion
into a precise mathematical statement because the support of µG is the entire cube [k]n . However, the probability
mass is expected to be distributed very unevenly, with large swathes of the cube carrying very little mass.

Fortunately, we do not need to deﬁne clusters etc. precisely. Instead, adapting the construction from [14], we
just deﬁne a new random variable Zβ,sep(G) that comes with a “hard-wired” notion of well-separated clusters. To
be precise, for a graph G denote by ΣG,β the set of all τ ∈ B that enjoy the following property.

SEP1: for every i ∈ [k] the set τ−1(i ) spans at most 2n exp(−β)k−1 ln k edges.

Further, let κ = ln20 k/k. We call σ ∈ B separable if σ ∈ ΣG,β and if

SEP2: for every τ ∈ ΣG,β and all i , j ∈ [k] such that ρi j (σ, τ) ≥ 0.51 we have ρi j (σ, τ) ≥ 1− κ.

Let Bsep = Bsep (G, β) ⊂ B denote the set of all separable maps and deﬁne

Zβ,sep(G) = Xσ∈Bsep (G ,β)

exp(−βHG (σ)).

To elaborate, condition SEP1 provides that the subgraphs induced on the individual color classes are quite
sparse. Indeed, recalling that each monochromatic edge incurs a “penalty factor” of exp(−β), we expect that in
a typical sample from the Gibbs measure the total number of monochromatic edges is about nd exp(−β)/(2k).
Moreover, suppose that σ ∈ ΣG,β satisﬁes SEP2 and τ ∈ ΣG,β is another color assignment. Let i , j ∈ [k]. Then SEP2
provides that there are only two possible scenarios.

belonging to different “clusters”.

(i) If ρi j (σ, τ) < 0.51, then the color classes σ−1(i ), τ−1( j ) are “quite distinct” and we may think of σ, τ as
(ii) If ρi j (σ, τ) ≥ 0.51, then in fact ρi j (σ, τ) ≥ 1− κ. Thus, the color classes σ−1(i ), τ−1( j ) are nearly identical.
Hence, if there is a permutation π : [k] → [k] such that ρiπ(i) (σ, τ) ≥ 0.51 for all i ∈ [k], then we may think of
σ, τ as belonging to the same “cluster”.

5

The upshot is that separability rules out the existence of any “middle ground”, i.e., we do not have to consider
overlaps ρ with entries ρi j ∈ (0, 51, 1− κ).

The following proposition, which we prove in Section 4, shows that imposing separability has no discernible

effect on the ﬁrst moment.
Proposition 2.5. Assume that d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] and β ≥ ln k. Then

E[Zβ,sep(G)] ∼ E[Zβ,bal(G)].

The point of working with separable color assignments is that the maximization problem that arises in the sec-
ond moment computation of Zβ,sep(G) comes with further constraints that are not present in (2.10). Speciﬁcally,
we only need to optimize over ρ ∈ D such that ρi j 6∈ (0.51, 1− κ) for all i , j ∈ [k]. In Section 5 we will use these
constraints to derive the following.
Proposition 2.6. Let d ∈ [2(k − 1) ln(k − 1), d⋆] and β ≥ ln k. Then 1
Corollary 2.7. If d ∈ [2(k − 1) ln(k − 1), d⋆] and β ≥ ln k, then (1.3) holds.
Proof. On the one hand, Jensen’s inequality gives

n ln E[Zβ,sep(G)2] ∼ 2

n ln E[Zβ,bal(G)].

On the other hand, by Propositions 2.5 and 2.6 and the Paley-Zigmund inequality,

E[ln Zβ(G)] ≤ ln E[Zβ(G)].

P[Zβ(G) ≥ E[Zβ,sep(G)]/2] ≥ P[Zβ,sep(G) ≥ E[Zβ,sep(G)]/2] ≥

E[Zβ,sep(G)]2
4E[Zβ,sep(G)2] = exp(o(n)).

Combining (2.14) with Proposition 2.1 , (2.3) and Proposition 2.5, we obtain

(2.13)

(2.14)

(2.15)
Further, (2.15) and Fact 1.2 yield n−1E[ln Zβ(G)] ≥ n−1 ln E[Zβ(G)]+ o(1). Finally, combining this lower bound with
the upper bound (2.13) completes the proof.

P[ln Zβ(G) ≥ ln E[Zβ(G)]− ln ln n] ≥ exp(o(n)).

(cid:3)

Finally, Theorem 1.1 follows from Theorem 2.3, Proposition 2.4 and Corollary 2.7.

2.5. Outlook: the condensation phase transition. According to non-rigorous physics methods [23, 24] for d only
slightly above the bound from Theorem 1.1 the formula (1.3) does not hold for all β > 0 anymore. While the exact
formula is quite complicated (e.g., it involves the solution to a distributional ﬁxed point problem), the critical
degree satisﬁes dk,cond = (2k − 1) ln k − 2ln 2 + ok (1). Thus, for d > dk,cond there occurs a phase transition at a
certain critical inverse temperature βk,cond(d). The existence of a critical βk,cond(d) follows from prior results on
the random graph coloring problem [8]. However, the value of βk,cond(d) is not (rigorously) known.

The physics intuition of how this phase transition comes about is as follows. For β < βk,cond(d) the Gibbs mea-
sure decomposes into an exponential number of clusters that each have probability mass exp(−Ω(n)). Hence, if
we sample σ, τ independently from the Gibbs measure, then most likely they belong to different clusters, in which
case their overlap should be very close to ¯ρ. By contrast, for β > βk,cond(d) a bounded number of clusters dominate
the Gibbs measure, i.e., there are individual clusters whose probability mass is Ω(1). In effect, for β > βk,cond(d)
the overlap of two randomly chosen color assignments is not concentrated on the single value ¯ρ anymore, because
there is a non-vanishing probability that both belong to the same cluster. In effect, the second moment method
fails. In fact, we expect that E[ln Zβ(G)] < ln E[Zβ(G)]− Ω(n) for all β > βk,cond(d).

But even the second moment argument for separable color assignments does not quite reach the expected criti-
cal degree dk,cond. Indeed, for d > (2k−1) ln k−2+ok(1) the maximum over the set of separable overlaps is attained
at ρi j = α1{i = j }+ 1−α
k−1 1{i 6= j } with α = 1− 1/k + ok (1/k). In terms of the physics intuition, this overlap matrix cor-
responds to pairs of color assignments that belong to the same cluster. In other words, the second moment method
fails because the expected cluster size blows up. A similar problem occurs in the k-colorability problem [14]. There
the issue was resolved by explicitly controlling the median cluster size, which is by an exponential factor smaller
than the expected cluster size [8]. We expect that a similar remedy applies to the Potts model, although the fact that
monochromatic edges are allowed entails that the proof method from [8] does not apply. In any case, Theorem 1.1
reduces the task of determining the phase transition to the problem of controlling the median cluster size.

Furthermore, also in the case of degrees above dk−col at least the existence of a phase transition has been estab-
lished rigorously [15]. It would be most interesting to see if the present methods can be extended to d > dk−col in
order to obtain a more precise estimate of βk,cond(d).

6

3. SINGLY STOCHASTIC ANALYSIS

We prove Proposition 2.4 by way of the following proposition regarding the maximum of fd ,β over the set of singly-
stochastic matrices.

Proposition 3.1. If d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] and β ≤ ln k, then fd ,β( ¯ρ) > fd ,β(ρ) for all ρ ∈ S \ { ¯ρ}.

To prove Proposition 3.1 we will closely follow the proof strategy developed for the graph coloring problem in
[14, Section 4]. Basically, that argument dealt with optimizing the function fd ,∞ (i.e., cβ is replaced by 1) over S and
we extend that argument to ﬁnite values of β. In fact, the following monotonicity statement shows that it sufﬁces
to prove Proposition 3.1 for β = ln k; related monotonicity statements were used in [9] for hypergraph 2-coloring
and in [7] for regular k-SAT.

Lemma 3.2. For all d > 0, β ≥ 0, ρ ∈ S we have
∂
∂β

fd ,β( ¯ρ) ≤

∂
∂β

fd ,β(ρ) < 0.

Hence, if fd ,β′ ( ¯ρ) ≥ fd ,β′ (ρ) for β′ ∈ [0,∞], then fd ,β( ¯ρ) ≥ fd ,β(ρ) for all β < β′.
Proof. Differentiating by β reveals that β 7→ fd ,β(ρ) is monotonous.
2cβ
k 2 e−β
k cβ + kρk2
k 2 c2

k −kρk2
1− 2

fd ,β(ρ) = −

∂
∂β

< 0.

d
2

β

2

2

2

Setting y = kρk2

2 and construing ∂

∂β fd ,β(ρ) as a map of y,

φ : [1, k] → R, φ(y) 7→ −

d

2

differentiating ∂

∂β fd ,β(ρ) by y, we obtain

2

k − y
1− 2

k cβ +

2cβ
k 2 e−β
k 2 c2

y

β

(3.1)

,

∂
∂y

φ(y) =

1

k 2 2cβe−β³1− 2

2cβe−β

k 2

=

cβ

k ´+ y
k cβ +

³1−
³1− 2

k 2 c2

β´2

y

y

β´−³− 2
k e−β +
k 2 c2
k cβ +
β´2
³1− 2
k 2 c2
k cβ +
¡1− 1
k¢
≥ 0

βe−β
k 3

2c 3

y

y

k 2 2cβe−β´ c 2

β
k 2

for y ∈ [1, k].

(3.2)

Hence, y 7→ ∂
of (3.1) and (3.2) yields the assertion.

∂β fd ,β(ρ) has a global minimum at y = 1. Because kρk2

2 = 1 is only the case for ρ = ¯ρ the combination

(cid:3)

The following basic observation concerning the partial derivatives of fd ,β is reminiscent of [14, Lemma 4.11].

Claim 3.3. Let ρ ∈ S. With i , j , l ∈ [k] such that ρil , ρi j > 0 set δ = ρil − ρi j .
i) Then
ρi j − expÃ

fd ,β(ρ)¶ = signÃ1+

signµ ∂

fd ,β(ρ)−

∂
∂ρil

∂ρi j

δ

dcβδ
k − 2cβ + c2

βkρk2

2/k!! .

ii) If ∂E (ρ)/∂ρi j < 1/k then there is δ∗ > 0 such that for all 0 < δ < δ∗

2/k! > 0.
If ∂E (ρ)/∂ρi j ≥ 1/k, the left hand side of (3.3) is negative for all δ > 0.

dcβδ
k − 2cβ + c2

ρi j − expÃ

βkρk2

1+

δ

7

(3.3)

Proof. By (2.8), (2.9) and the choice of δ,

1

δ

∂
∂ρil

∂
∂ρi j

fd ,β(ρ)−

fd ,β(ρ) =

k "lnµ1+
The ﬁrst part of the claim follows because the signs of the terms in (3.4) are invariant under exponentiation of the
minuend φ(δ) = ln(1+ δ/ρi j ) and subtrahend ψ(δ) = dc2
2/k). The second part follows from
the observation that the linear function exp(φ) : R+ → R intersects at most once with the strictly convex function
exp(ψ) : R+ → R. This is only the case if the derivative of exp(φ) in δ = 0 is strictly greater than that of exp(ψ).
The following lemma provides a general “maximum entropy” principle that we will use repeatedly (cf. [14, Propo-
sition 4.7]).

βδ/(k − 2cβ + cβkρk2

k − 2cβ + cβkρk2

ρi j ¶−

2/k#.

(3.4)

(cid:3)

dc2

βδ

Lemma 3.4. Let d ≤ (2k−1) ln k and β > 0. For ρ ∈ S, a ﬁxed row i and a set of columns J ⊂ [k], set ˆρab =P j∈J ρi j /|J|
for all (a, b) ∈ {i }× J and ˆρab = ρab for all (a, b) ∉ {i }× J . Let λ ≥ 3ln ln k/ ln k. If |J| ≥ kλ and max j∈J ρi j < λ/2−
ln ln k/ ln k, then fd ,β( ˆρ) > fd ,β(ρ) if ρ 6= ˆρ.
Proof. We may assume that 0 ≤ min j∈J ρi j < max j∈J ρi,j . Otherwise, we would have ˆρ = ρ and there is nothing to
prove. Now let

Sρ =½ ˜ρ : ˜ρab = ρab for all (a, b) ∈ {i }× J and max

j∈J

˜ρi j ≤ max
j∈J

ρi,j¾

denote the set of all possible overlaps. Sρ is a closed subset of S and therefore contains a maximal overlap ˇρ ∈
argmax ˜ρ∈S fd ,β( ˜ρ). Evidently the derivative of H tends to inﬁnity as ρi j tends to zero, while the derivative of E
remains bounded. Therefore in a maximal overlap each entry ˇρi j , j ∈ J is positive. As a whole, we know that
0 < min j∈J ˇρi j ≤ max j∈J ˇρi j ≤ 1. By means of Claim 3.3 it remains to show that ˇδ = max j∈J ˇρi j − min j∈J ˇρi j = 0.
Let a ∈ J denote the index of ˇρi a = min j∈J ˇρi j . Because |J| ˇρi a ≤P j∈J ˇρi j and d ≤ 2k ln k − ln k, we have

1

ˇρi a ≥ |J| ≥ kλ ≥ 3ln k > 2ln kÃ
2 ≥ 1 and d ≤ 2k ln k − ln k,

kc2
β

k − 2cβ + c2

β/k! ≥

k
ˇρi a

∂

∂ ˇρi a

E ( ˇρ).

1

ln ln k

β! ≤ exp(2 ˆδ ln k)
ˇρi a µ λ
ln k ¶ ≤
2 −
2/k!! = 1

ˆδ
ˇρi a

As ˆδ = λ/2− ln ln k/ ln k, k ˇρk2
exp


ˆδ
dc2
β
βk ˇρk2
k − 2cβ + c2
≤kλ ln−2 k ≤ |J| ln−2 k ≤

2/k
 ≤ expÃ

1
ˇρi a

1
ln2 k <

d ˆδ

k(1− cβ/k)2 c2
ln ln k
2ln k ≤

1
ˇρi a

conﬁrms that

signÃ1+

δ

ˇρi a − expÃ

dcβδ
k − 2cβ + c2

βk ˇρk2

holds for any δ < ˆδ. Suppose that ˇδ > 0. Then 0 < δ ≤ max j∈J ˇρi j ≤ ˆδ and Claim 3.3 imply that a matrix ˇρ′ obtained
from ˇρ′ by decreasing max j∈J ˇρi j by a sufﬁciently small ξ > 0 and increasing ˇρi a by the same value ξ results in
fd ,β( ˇρ′) > fd ,β( ˇρ), which contradicts the maximality of ˇρ. Hence, a maximal overlap ρ satisﬁes ˇδ = max j∈J ˇρi j −
min j∈J ˇρi j = 0 for any i , J chosen according to our assumption.

(cid:3)

In order to achieve a global bound on maxρ∈S fd ,β(ρ) we need to pin down the structure of a maximizing matrix
p1− 2/ ln k). Then ξ is decreasing

ρ. To this end, the following elementary fact is going to be useful.
Fact 3.5 ([14, Lemma 4.15]). Let ξ : ε ∈ (0, k/2) 7→ k2ε/k (ε−1 − k−1). Let µ = k
on the interval (0, µ) and increasing on (µ, k/2). Furthermore, we have −1/2 ≤ ξ′(ε) ≤ −3/2 for b ∈ (0.99, 1.01).
The following lemma rules out the possibility that the maximizer of fd ,β has an entry close to 1/2 (cf. [14, Lemma 4.13]).
Lemma 3.6. Let β > 0 and d = 2k ln k − c, where c = Ok (ln k). If ρ ∈ S has an entry ρi j ∈ [0.49, 0.51], then there is
ρ′ ∈ S such that fd ,β(ρ′) ≥ fd ,β(ρ)+ ln k
5k .

2 (1−

8

Proof. By means of Lemma 3.4 we will specify ρ′ and provide above bound for fd ,β(ρ)− fd ,β(ρ′) in a distinction of
two cases. Without loss of generality we may assume that the entry in the interval [0.49, 0.51] is ρ11. Suppose ρ
maximizes fd ,β subject to the condition that ρ11 ∈ [0.49, 0, 51].
For the ﬁrst case, suppose that ρ1 j < 0.49 for all j ≥ 2. By setting J = {2, . . . , k} and λ = ln(k−1)/ ln k in Lemma 3.4,
we have ρ1 j = (1− ρ11)/(k − 1) for all j ≥ 2. Let ρ′ denote the matrix obtained from ρ by setting ρ′1 = (1/k, . . . , 1/k)
and ρ′i = ρi for i ≥ 2. In the following assume that k is sufﬁciently large. By Fact 1.3 we have

H (ρ1) ≤ h(ρ11)+ (1− ρ11) ln(k − 1) ≤ ln 2+ 0.51ln k.

Consequently

In comparison, the Frobenius norm of ρ1 is bounded by

H (k−1ρ′1)− H (k−1ρ1) ≥

0.48ln k

k

.

kρ1k2

k − 1¶2
2 ≤ 0.512 + (k − 1)µ 0.51

≤ 0.261,

∂

∂kρk2

2

E (ρ) =

d
2k2

c2
β

1− 2/kcβ +kρk2

2/k2c2
β

2k ln k + Ok (ln k)

2k

=

Okµ 1

k¶ ≤

ln k

k µ1+ Okµ 1
k¶¶ .

while

Therefore

The combination of (3.5) and (3.7) veriﬁes

E (ρ)− E (ρ′) ≤

0.262ln k

k

.

for β ≥ ln k. By Lemma 3.2

fd ,β(ρ′) ≥ fd ,β(ρ)+ 0.218

ln k
k ≥ fd ,β(ρ)+

ln k
5k

fd ,β(ρ′) ≥ fd ,β(ρ)+

ln k
5k

(3.5)

(3.6)

(3.7)

(3.8)

holds for any 0 ≤ β ≤ ln k. Finally we show (3.8) for the case that a row consists of two entries greater than 0.49.
Without loss of generality we may assume that ρ11 ≥ ρ12 ≥ 0.49 and ρ1 j < 0.02 for j ≥ 3. Lemma 3.4 with parameters
J = {2, . . . , k} and λ = ln(k − 1)/ ln k gives ρ1 j = (1− ρ11 − ρ12)/(k − 2) for all j ≥ 3. Hence, for sufﬁciently large k

H (ρ1) ≤ h(ρ11)+ h(ρ12)+ (0.02) ln(k − 2) ≤ 2ln 2+ 0.02ln k ≤ 0.03ln k.

Moreover the norm is bounded by

Consequently

kρ1k2

2 = ρ2

11 + ρ2

12 + (k − 2)µ 1− ρ11 − ρ12

k − 2

¶2

≤ 0.501.

E (ρ)− E (ρ′) ≤

0.51ln k

H (k−1ρ′1)− H (k−1ρ1) ≥ 0.97

k

k
ln k

,

.

(3.9)

(3.10)

The combination of (3.9) and (3.10) yields (3.8) for β ≥ ln k. By Lemma 3.2 the assertion follows for 0 ≤ β ≤ ln k. (cid:3)
Generalizing [14, Lemma 4.16], as a next step we characterize the structure of the local maxima of fd ,β on S.
Lemma 3.7. Let β > 0 and d = 2k ln k − c, where c = Ok (ln k). Let ρ ∈ S.
(1) Suppose that row i ∈ [k] has no entries in [0.49, 0.51] and ρi j ≤ 0.49 for all j ∈ [k]. Let ρ′ be the stochastic matrix

with entries

ρ′h j = ρh j and ρ′i j =

1
k

for all j ∈ [k], h ∈ [k] \ {i }.

(3.11)

Then fd ,β(ρ) ≤ fd ,β(ρ′).

9

(2) Suppose that row i ∈ [k] has no entries in [0.49, 0.51] and ρi j ≥ 0.51 for some j ∈ [k]. Then there is a number

α = 1

k + ˜Ok (1/k2) such that for the stochastic matrix ρ′′ with entries

ρ′′h j = ρh j and ρ′′ii = 1− α, ρ′′ih =

for all j ∈ [k], h ∈ [k] \ {i }

(3.12)

α
k − 1

(3) Let β ≤ ln k. Suppose that row i ∈ [k] has an entry ρi j ∈ [0.49, 0.51]. Then the matrix ρ′ with (3.11) satisﬁes

we have fd ,β(ρ) ≤ fd ,β(ρ′′).
fd ,β(ρ) ≤ fd ,β(ρ′).

Proof. Claim (1) is an immediate consequence of Lemma 3.4 when setting J = [k], λ = 1 and applying the ρ 7→ ˆρ
operation on the i -th row.
For Claim (2) we may again assume that i = j = 1 and therefore ρ11 ≥ 0.51. Let ˆρ ∈ S maximize fd ,β subject to
the conditions that ˆρ coincides with ρ everywhere but in the ﬁrst row and ˆρ11 ≥ 0.51. A necessary condition for ˆρ
to be maximal is that the mass in the remaining open entries is equally distributed. ˆρ11 ≥ 0.51 implies that for all
j ≥ 2 the entries ˆρ1 j are bounded by 0.49. Setting λ = ln(k−1)/ ln k, Lemma 3.4 applies to row i = 1 and J = {2, . . . , k}
conﬁrming that for all j ≥ 2 we have ˆρ1 j = (1− ˆρ11)/(k − 1).
Let 0 ≤ ε ≤ 0.49k be such that ˆρ11 = 1− ε/k. To prove the assertion we need to show that ε = 1+ ˜Ok (1/k). Set

δ = ˆρ11 − ˆρ12. Then because ˆρ maximizes fd ,β Claim 3.3 implies that

either ε ∈ {0, 0.49k}, or 1+

.

(3.13)

δ

ˆρ12 = exp


dc2

βδ
k − 2cβ + c2

β

k ˆρk2
k

2




Equations (3.4) and (2.8) show that ∂/∂ρ11H (ρ1) tends to −∞ as ρ11 tends to 1, while ∂/∂ρ11E (ρ1) remains bounded.
Hence, a maximal ˆρ is bound to satisfy ε > 0.

By k ˆρk2

2 ≥ 1 we have k − 2cβ + cβ k ˆρk2

2

k ≥ k(1− cβ/k)2. Moreover we have δ = ˆρ11 −Ok (1/k) due to all entries in the

ﬁrst row being (1− ˆρ11)/(k − 1). With d = 2k ln k + Ok (ln k) and β ≥ ln k we obtain

exp


and

dc2

βδ
k − 2cβ + c2

β

k ˆρk2
k

2

δ
ˆρ12 =

1+

ˆρ11
ˆρ12 =


 = k2 ˆρ11¡1+ ˜Ok (1/k)¢ = k2(1−ε/k) (1+ Ok (1/k))
(k − 1) ˆρ11
1− ˆρ11 = k2(1/ε− 1/k)(1+ Ok (1/k)).

Thus, setting ξ : ε 7→ k2ε/k (1/ε− 1/k) there is η = Ok (ln k/k) such that

(1− η)ξ(ε) ≤µ1+

δ

ˆρ12¶ exp


dc2

βδ

k − 2cβ + cβ k ˆρk2

k

2


 ≤ (1+ η)ξ(ε).

(3.14)

p1− 2/ ln k) while ξ is decreasing on (0, µ) and
Fact 3.5 reveals that ξ has a unique local minimum in µ = k
increasing on (µ, k/2). Furthermore we have ξ(ε) ∈ [−3/2,−1/2] for ε ∈ (0.99, 1.01). Therefore, setting γ = ln2 k/k,
we have

2 (1−

ξ(ε) ≤(ξ(0.49k) ≤ k0.98¡

ξ(1+ γ) < 1
1+η

1

0.49k − 1

k¢ < 1

1+η

for ε ∈ [µ, 0.49k]
for ε ∈ [1+ γ, µ]

and

These bounds applied to (3.14) yield

ξ(ε) ≥ ξ(1− γ) >

1
1− η

,

for ε ∈ (0, 1− γ).

1+

δ

ˆρ12 − exp


dc2

βδ

k − 2cβ + cβ k ˆρk2

k

2

10

(> 0
< 0




for ε ∈ (0, 1− γ),
for ε ∈ [1+ γ, 0.49k].

(3.15)

Altogether (3.13) and (3.15) with ε > 0 imply ε = 1+ ˜Ok (1/k) and therefore ˆρ11 = 1− 1/k + ˜Ok (1/k2) by Claim 3.3.
Hence ˆρ satisﬁes (3.12) and fd ,β( ˆρ) ≥ fd ,β(ρ) for any β ≥ ln k. By Lemma 3.2 fd ,β( ˆρ) ≥ fd ,β(ρ) holds for any 0 ≤ β ≤
ln k as well.

By deﬁnition of ρ′ Claim (3) is a Corollary of Lemma 3.6.

(cid:3)

The following Lemma, which extends [14, Lemma 4.14] to ﬁnite β, estimates the function values attained at points
near the “candidate maxima” from Lemma 3.7.

Lemma 3.8. Let ρs denote the matrix whose the top s rows coincide with the identity matrix and whose last k − s
rows coincide with ¯ρ. If β = ln k and d ≤ (2k − 1) ln k then fd ,β( ¯ρ) > fd ,β(ρs ) for all s = 1, . . . , k.
Proof. We have

H (k−1 ¯ρ) = ln k +

1
k

k

Xi=1

H (ρi ) = 2ln k,

E ( ¯ρ) =

d
2

ln·1−

2
k

cβ +

1

k2 c2

β¸ = d ln·1−

cβ

k ¸ .

H (k−1ρs ) = ln k +

E (ρs) =

d
2

k

1
k

Xi=1
ln"1−

2
k

k − s
k

ln k,

H (ρi ) = ln k +
cβ +µ k − s

k + s¶ c2
k2#.

β

Further,

Hence,

fd ,β(ρs ) =

fd ,β( ¯ρ) = 2ln k + d ln[1− cβ/k],

k
The assertion fd ,β( ¯ρ) > fd ,β(ρs ) holds iff H (k−1 ¯ρ)− H (k−1ρs ) = s

 =

k cβ +³ k−s
(1−

k + s´ c 2

ln


1− 2

cβ
k )2

d
2

β
k 2

d
2

a mercator series expansion

Setting x = (s − s/k) c2

E (ρs)− E ( ¯ρ) =
β/k2¡1− cβ/k¢−2
2 ·x −

x2

d

ln(1+ x) =

d
2

2 + Ok (x3)¸ ≤

2k ln k − ln k

2

·x −

k + s¶ c2
k2#.

β

2k − s

k ln k > E (ρs)− E ( ¯ρ), i.e.

ln k +

2

2

k

d

c 2
β
k 2

ln"1−

cβ +µ k − s
k ´2 
1+¡s − s
k¢
 <
³1−
2 ¸ = ln k·kx − k

x2
2 −

cβ

k

s

ln


x2

x
2 +

ln k.

(3.16)

(3.17)

(3.18)

x2

4 ¸

[as β = ln k]

along with the representation

c 2
β
k 2

¡s − s
k¢
k ´2 =
³1−

cβ

=

c2
β

k

1
k

s

1

1

k µ1−
k µ1−

k¶
(1− cβ/k)2 =
k + Ok (k−2)¶µ1+

2

s

k¶¡1+ 2cβ/k + Ok (1/k2)¢

c2
β

s

1

k

k µ1−
k + Ok (k−2)¶

1

reduces the proof to validating the inequality

1

2

1

2

k

k2

µ1−

(k − 1/2)

·µ1−

(1/4− k/2)

k + Ok (k−2)¶+

k + Ok (k−2)¶µ1+

k + Ok (k−2)¶µ1+

k + Ok (k−2)¶¸2 s
k < 1.
This is indeed true, since the ﬁrst summand is bounded by 1− k−2 and the second summand is negative.
Corollary 3.9. With ρs deﬁned as in Lemma 3.8 the inequality fd ,β( ¯ρ) > fd ,β(ρs ) holds for all s < k and 0 < β ≤ ln k.
Proof of Proposition 3.1. In the case β = 0 we have fd ,β(ρ) = H (k−1ρ). On [0, 1]k×k ⊃ S the entropy function is
maximized by the uniform distribution on [k]2, i.e. the matrix ¯ρ. Consider the case 0 < β ≤ ln k. Because ρ is
stochastic each row of ρ has at most one entry greater than 0.51. We call ρ s-stable if there are precisely s rows with
entries greater than 0.51. Let ρs denote the matrix where the top s rows coincide with the identity matrix and the
last k− s rows with ¯ρ. For any s ∈ {0, 1, . . . , k} and any s-stable matrix ρ, using Lemma 3.7 we obtain a matrix ρ′ such

(3.19)

(cid:3)

11

that fd ,β(ρ′) ≥ fd ,β(ρ) where ρ′ is achieved by moving from ρ in direction ρs . Together with Corollary 3.9 this yields
the assertion.

(cid:3)

Proof of Proposition 2.4. For any choice of n, β or d Jensen’s inequality shows

1
n

ln E[Zβ(G)] ≥

1
n

E[ln Zβ(G)].

We claim that d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] and β ≤ ln k allows for
E[ln Zβ(G)]+ o(1).

ln E[Zβ(G)] ≤

1
n

1
n

By (2.3), there is Cb > such that

Hence, combining Propositions 2.2 and 3.1 we have

E[Zβ(G)] ≤ Cb E[Zβ,bal(G)].

E[Zβ,bal(G)2] = Xρ∈R

exp(n fd ,β(ρ)+ o(n)) ≤ exp(o(n)) exp(n fd ,β( ¯ρ)/2) ≤ exp(o(n))E[Zβ,bal(G)]2.

Analogously to the proof of Corollary 2.7 we apply the Paley-Zigmund inequality and obtain

The concentration result in Fact 1.2 therefore yields 1
n

liminf
n→∞

P[n−1 ln(Zβ(G)) ≥ n−1 ln E[Zβ(G)]− o(1)] ≥ exp(o(n)).
n ln E[Zβ(G)]− o(1).

E[ln Zβ(G)] ≥ 1

(3.20)

(3.21)

(3.22)

(cid:3)

4. HIGH DEGREE, LOW TEMPERATURE: THE FIRST MOMENT

Throughout this section we assume that d ∈ [2(k − 1) ln(k − 1), (2k − 1) ln k − 2] and β ≥ ln k. In this section we
prove Proposition 2.5. The principal tool is going to be the following experiment called the planted model; similar
constructions for hypergraph 2-coloring or k-SAT played an important role in [7, 9].

PM1: Choose a map ˆσ : [n] → [k] uniformly at random.
PM2: Letting

p1 =

dk exp(−β)
n(k − cβ)

,

p2 =

dk

n(k − cβ)

,

obtain a random graph ˆG on [n] by independently including every edge {v, w} of the complete graph such
that ˆσ(v) 6= ˆσ(w) with probability p2 and every edge {v, w} such that ˆσ(v) = ˆσ(w) with probability p1.

The following lemma sets out the connection between the planted model and the ﬁrst moment.

Lemma 4.1. If A is a set of graph/color assignment pairs (G, σ) such that P£( ˆG, ˆσ) ∈ A| ˆσ ∈ B¤ = o(n−1/2), then
Proof. Because k−1p1+(1−1/k)p2 = d/n, the expected number of edges of ˆG is m+O(pn). Hence, the assumption
P£( ˆG, ˆσ) ∈ A| ˆσ ∈ B¤ = o(n−1/2) implies that

exp(−βHG (σ))1{(G,σ)∈A} = o(E[Zβ,bal(G)]).

E Xσ∈B

(4.1)

Writing out the l.h.s. of (4.1), we obtain

P£( ˆG, ˆσ) ∈ A| ˆσ ∈ B, |E ( ˆG)| = m¤ = o(1).

P£( ˆG, ˆσ) ∈ A| ˆσ ∈ B, |E ( ˆG)| = m¤

(G,σ)∈A,σ∈B,|E (G)|=m

= Θ(k−n)
X
n¶m
(1− cβ/k)m µ d

Θ(k−n)

=

(G,σ)∈A,σ∈B,|E (G)|=m

X

p

HG (σ)
1

p m−HG (σ)
2

(1− p1)HKn (σ)−HG (σ)(1− p2)¡n

2¢−HKn (σ)−m+HG (σ)

P£|E ( ˆG) = m|¤
exp(−βHG (σ))(1− p1)k−1¡n
P£Bin(¡n

12

2¢−HG (σ)(1− p2)(1−k−1)¡n
2¢, d/n) = m¤

2¢−m+HG (σ)

;

in the last step we used (2.1) and the observation that k−1p1 + (1− 1/k)p2 = d/n. Further, combining the above
with (2.3), we get
P£( ˆG, ˆσ) ∈ A| ˆσ ∈ B, |E ( ˆG)| = m¤ E[Zβ,bal(G)]
X
X

1− p ¶k−1¡n
exp(−βHG (σ))µ 1− p1
exp(−βHG (σ)) = Θ(1) Xσ∈B

1− p ¶(1−k−1)¡n
2¢−HG (σ)µ 1− p2
E£exp(−βHG (σ))1{(G,σ)∈A}¤ .

= Θ(1)Ã¡n
= Θ(1)Ã¡n

2¢m!−1
2¢m!−1

(G,σ)∈A,σ∈B,|E (G)|=m

(G,σ)∈A,σ∈B,|E (G)|=m

2¢−m+HG (σ)

Thus, the assertion follows from (4.1).

(cid:3)

We are going to combine Lemma 4.1 with the following proposition, which shows that separability is a likely event
in the planted model.
Proposition 4.2. We have P[ ˆσ is separable in ˆG| ˆσ ∈ B] = 1− o(n−1/2).

To prove Proposition 4.2 we generalize the argument for proper k-colorings from [14, Section 3] to the Potts

antiferromagnet. In the following we let Vi = ˆσ−1(i ) for i ∈ [k].
Lemma 4.3. Let i ∈ [k]. For S ⊂ Vi let XS,i = |©v ∈ V \ Vi : ∂ ˆG v ∩ S = ;ª|. Given ˆσ ∈ B the following statement holds
with probability 1− exp(−Ω(n)).

Let i ∈ [k]. Then for all S ⊂ Vi of size k

n |S| ∈ [0, 501, 1− k−0.499] we have XS,i ≤ n

k (1− α− κ)− n2/3.

(4.2)

Proof. It sufﬁces to prove the statement for i = 1 and we set XS = XS,1. Moreover, let α ∈ [0.501, 1− k−0.499]. For
a ﬁxed S ⊂ V1 and v ∈ V \ V1 the number |∂ ˆG v ∩ S| is a binomial random variable with parameters |S| = αn
k and
p2. Hence, P[∂v ∩ S = ;] = (1− p2)|S|. Consequently, XS itself is a binomial variable with mean |V \ V1|(1− p2)|S|.
Because σ is balanced, we have |V \ V1| ∼ n(1− 1/k). Further, our assumptions on d, β entail
k − cβ¶ ≤ (1+ ok (1))k−2α.

(1− p2)|S| ≤ exp(−p2|S|) ≤ expµ−α

k − cβ + α
Therefore, E[XS ] ≤ n(1+ ok (1))(1− 1/k)k−2α. Thus, Lemma 1.4 yields

2k ln k

3ln k

P[XS > (1− α− κ)

The total number of sets S of size αn/k is¡|V1|α n

n

Ph∃S : XS ≥ (1− α− κ)

k

n

n

k¢ ≤ exp£ n

k − n2/3] ≤ exp·−(1− α− κ+ o(1))

ek1−2α ¶¸ .
lnµ 1− α− κ
k h(α)¤ . Hence, by the union bound
(2h(α)+ (1− α)+ (1− 2α)(1− α− κ) ln k + o(1))i

k − n2/3i ≤ exph n
k ¡(1− α)(3− 2ln(1− α))+ (2(1− α)2 − (1− 2κ)(1− α)+ κ) ln k + o(1)¢i .

k

≤ exph n

(4.3)

Substituting y = 1− α and differentiating, we obtain

y(3− 2ln y)+ (2y 2 − (1− 2κ)y + κ) ln k = 1− 2ln y + 4y ln k − (1− 2κ) ln k,

∂
∂y
∂2
∂y 2 y(3− 2ln y)+ (2y 2 − (1− 2κ)y + κ) ln k = −

2
y + 4ln k,

∂3
∂y 3 y(3− 2ln y)+ (2y 2 − (1− 2κ)y + κ) ln k = 2.

Hence, the ﬁrst derivative is negative at the left boundary point y = k−0.499, positive at the right boundary point
y = 0.499 and convex on the entire interval. Furthermore, we check that y(3− 2ln y)+ (2y 2 − (1− 2κ)y + κ) ln k < 0
for y ∈ {0.499, k−0.499}. Therefore, the assertion follows from (4.3).
Lemma 4.4. Given ˆσ ∈ B the random graph ˆG has the following property with probability 1− exp(−Ω(n)).
Let i ∈ [k] and let Y = Y ( ˆG, ˆσ) be the number of vertices v 6∈ Vi with fewer than 15 neighbors in Vi .
Then Y ≤ κn

3k lnk .

(4.4)

(cid:3)

13

Proof. Suppose i = 1. Given ˆσ ∈ B for v ∉ V1 the number |∂ ˆG v ∩ V1| of neighbors in V1 is a binomial variable with
mean λ = |V1|p2 ∼ d/¡k − cβ¢ > 2ln k + Ok (ln k/k). Hence, the probability of a vertex having at most 14 neighbors
in V1 is upper bounded by 2λ14 exp(−λ) ≤ 3k−2 ln14 k. Therefore, Y is dominated by a binomial variable with mean
µ ≤ 3nk−2 ln14 k. Finally, the assertion follows from Lemma 1.4 and the choice of κ.
Claim 4.5. Given ˆσ ∈ B the random graph ˆG has the following property with probability 1− O(n−1).

(cid:3)

If W ⊂ V has size W ≤ k−4/3n, then W spans no more than 5|W | edges.

(4.5)

Proof. Given ˆσ for any edge of the complete graph the probability of being present in ˆG is bounded by p2. There-
fore, by the union bound and with room to spare, for any 0 < γ ≤ k−4/3 we ﬁnd

P£∃W ⊂ V, |W | = γn : W spans 5|W | edges¯¯ ˆσ ∈ B] ≤Ã n

γn!Ã¡γn
2¢5γn!p

γn

5γn

2 ≤· e

γµ eγd

5 ¶5¸

≤¡γ4d 5¢γn

.

Summing over 1/n ≤ γ ≤ k−4/3 completes the proof.
Proof of Proposition 4.2. Suppose that ˆσ is balanced. By our assumptions on d, β for each i the number of edges
spanned by ˆσ−1(i ) in ˆG is a binomial random variable with mean

(cid:3)

(1+ o(1))Ãn/k

2 !p1 ≤ (1+ o(1))

dn

2k(k − cβ)

exp(−β) ≤ (1+ ok (1))nk−1 exp(−β) ln k.

Hence, Lemma 1.4 shows that ( ˆG, ˆσ) satisﬁes SEP1 with probability 1− exp(−Ω(n)).
With respect to SEP2, we continue to condition on ˆσ ∈ B. By Lemma 4.3, Lemma 4.4 and Claim 4.5 we may as-
sume that ˆG has the properties (4.2), (4.4) and (4.5). In order to show separability we may without loss of generality
restrict ourselves to the case of i = j = 1. Thus, suppose that τ ∈ ΣG ,β satisﬁes ρ11( ˆσ, τ) ≥ 0.51 n
k and assume for
contradiction that α = k

n |S| = ρ11( ˆσ, τ) < 1− κ. Let

S = ˆσ−1(1)∩ τ−1(1), R = ˆσ−1(1) \ τ−1(1), T = τ−1(1) \ ˆσ−1(1).

Because σ and τ are balanced, we have

|T ∪ S| ∼

n
k ∼ |R ∪ S|.

(4.6)

Let T0 = {v ∈ T : ∂ ˆG v ∩ S = ;} and let T1 = T \ T0. Then SEP1 and our assumptions on d and β ensure that |T1| ≤
k exp(β) . Consequently, the assumption β ≥ ln k yields

4n ln k

|T0| ≥

n

k

(1− α− Ok (ln k/k)).

Since the vertices in T0 do not have neighbors in S, (4.2) implies that

α > 1− k−0.49.

(4.7)

Further, let U = {v ∈ T : |∂v ∩ ˆσ−1(1)| ≥ 15}. Then (4.4) implies that |T| ≤ |U|+ κn/(k ln k). Therefore, (4.6) and our
assumption α < 1− κ yield

|U| ≥ (1− ok (1))

κn
k

and

|R|− ok (κ)

n
k ≤ |U| ≤ |R|+ o(n).

(4.8)

Hence, SEP1 implies that S ∪U spans no more than 2nk−1 exp(−β) ln k ≤ |U| edges. Consequently, U ∪ R spans at
least 14|U| edges. Thus, combining (4.5) and (4.8), we conclude that |U ∪R| > nk−4/3. But then (4.6) and (4.8) show
that 1− α+ o(1) ≥ k
Proof of Proposition 2.5. By linearity of expectation, applying Lemma 4.1 to Proposition 4.2 yields E[Zβ,bal(G)] ∼
E[Zβ,sep(G)].

3 k−1/3, in contradiction to (4.7).

3n|U ∪ R| ≥ 1

n |R| > k

(cid:3)

(cid:3)

14

5. HIGH DEGREE, LOW TEMPERATURE: THE SECOND MOMENT

To prove Proposition 2.6 we call a doubly-stochastic k × k-matrix ρ separable if ρi j 6∈ (0.51, 1− κ) for all i , j ∈ [k].
Moreover, ρ is s-stable if s = |{(i , j ) ∈ [k]2 : ρi j > 0.51}|. Let Dsep ⊂ D be the set of all separable matrices and let
Ds,sep ⊂ Dsep be the set of all s-stable matrices so that Dsep =Sk
Ds,sep. The key step is to optimize the function
fd ,β over Dsep.
Proposition 5.1. If 2(k − 1) ln(k − 1) ≤ d ≤ d⋆ and β ≥ ln k, then fd ,β(ρ) < fd ,β( ¯ρ) for all ρ ∈ Dsep \ { ¯ρ}.

s=0

A similar statement for the function

kρk2
k2 # ,
the limit of fd ,β(ρ) as β → ∞, played a key role in [14]. Speciﬁcally, we have
Proposition 5.2 ([14, Propositions 4.4–4.6, 4.8]). Assume that d = (2k−1) ln k−2ln 2. Then fd ,∞(ρ) < fd ,∞( ¯ρ) for all
0 ≤ s < k, ρ ∈ Ds,sep \ { ¯ρ}.

fd ,∞(ρ) = H (k−1ρ)+

ln"1−

2
k +

(5.1)

d

2

2

We prove Proposition 5.1 by combining Proposition 5.2 with monotonicity in both d and β. In fact, Lemma 3.2

readily provided monotonicity in β. Further, with respect to d we have the following.

Lemma 5.3. For every d > 0, ρ ∈ S we have

∂
∂d

fd ,∞( ¯ρ) ≤

∂
∂d

fd ,∞(ρ) < 0.

Hence, if fd′,β( ¯ρ) ≥ fd′,β(ρ), then fd ,β( ¯ρ) ≥ fd ,β(ρ) for all 0 ≤ d < d′.
Proof. Recalling that 1 ≤ kρk2

2 ≤ k, we ﬁnd
∂
∂d

fd ,∞(ρ) =

1
2

lnÃ1−

2
k +

2

kρk2
k2 ! < 0.

The assertion follows because ¯ρ minimizes the Frobenius norm on S.

Corollary 5.4. Let β ≥ 0 and d ≤ d⋆. For all 1 ≤ s ≤ k − 1 and ρ ∈Ss<k Ds,sep \ { ¯ρ} we have fd ,β(ρ) < fd ,β( ¯ρ).
Proof. Suppose that ρ ∈Ss<k Ds,sep \ { ¯ρ}. Combining Proposition 5.2 with Lemma 5.3, we see that
Hence, fd ,γ(ρ) < fd ,γ( ¯ρ) for γ > β sufﬁciently large. Therefore, Lemma 3.2 entails that fd ,β(ρ) < fd ,β( ¯ρ).
Observe that Proposition 5.2 (and hence Corollary 5.4) does not cover the k-stable case.

fd ,γ(ρ) = fd ,∞(ρ) < fd ,∞( ¯ρ) = lim
γ→∞

lim
γ→∞

fd ,γ( ¯ρ).

(cid:3)

(cid:3)

Lemma 5.5. Let β ≥ 0 and d ≤ d⋆. For all ρ ∈ Dk,sep we have fd ,β(ρ) < fd ,β( ¯ρ).
Proof. Because ρ ∈ Dk,sep for each i ∈ [k] there is precisely one entry greater than 0.51. Without loss of generality
we may assume that ρii ≥ 0.51. By Lemma 3.7 there is α = k−1+ ˜Ok (k−2) such that the matrix ρ′ obtained from ρ by
substituting any row ρi for a row ρ′i with ρ′ii = 1− α and ρ′i j = α/(k − 1) for j 6= i satisﬁes fd ,β(ρ′) ≥ fd ,β(ρ). Hence,
a maximizer of ρ ∈ Dk,sep is of the form ρstable = (1− 1/k)id + 1/k21. Because the matrix ρstable does not further
improve from applying the transformation in Lemma 3.7, it remains to show that

In the zero temperature case with d = (2k − 1) ln k − c, we have
1+k ¯ρk2

fd ,∞( ¯ρ) = ln k +

H ( ¯ρi )+

1

2

fd ,β( ¯ρ) > fd ,β(ρstable).

1

2
k

d
2

ln·1−

k2¸ = 2ln k + d ln·1−
k¸
2k2 + Ok¡k−3¢¶
2k2 + Ok¡k−3¢¶ = 2ln k − (2k ln k − ln k − c)µ 1
k +

1

1

1

k Xi≤k
= 2ln k − dµ 1
k +
k2 ¶ .
k + Okµ ln k
=

c

(5.2)

[as k ¯ρk2

2 = 1]

(5.3)

15

On the other hand the matrix ρstable satisﬁes
H (k−1ρstable) = ln k +

1

Because kρstablek2

2 = k(k−1)

E (ρstable) =

1

k2

ln k2.

1
k +

1

k2¶+

H¡(1− 1/k + 1/k2, 1/k2, . . . , 1/k2)¢
k Xi≤k
= ln k −µ1−
k2¶ lnµ1−
1
(k − 1)
k +
k + 1
k 4 + k(1− 1
k 2 )2 and β ≥ ln k, setting d = (2k − 1) ln k − c we obtain
k2¶2¶¸
k2 µ k(k − 1)
+ kµ1−
ln·1−
1
2
k +
k +
k2 + Ok¡k−3¢¶¸ = −
ln·1−µ 1
2 µ 1
1
d
=
k2 +
k +
k +
= −µk ln k −
2k2 + Ok¡k−3¢¶
2¶µ 1
ln k
k +
2 −
k2 ¶ .
2k + Okµ ln k
= − ln k −

2µ 1
k +

2ln k
k +

k2¶2

d
2

d
2

1

2

c

c

1

2

k4

5

1

+ Ok¡k−3¢¶

(5.4)

(5.5)

(5.6)

Consequently

fd ,∞(ρstable) =

1
k +

c

k2 ¶ .
2k + Okµ ln k

From (5.3) and (5.6) we see that fd ,β( ¯ρ) > fd ,β(ρstable) holds for any d ≤ (2k − 1) ln k − 2− ωk(ln k/k) and β = ∞.
Lemma 3.2 concludes the proof by extending (5.2) to β ≥ ln k.
Proof of Proposition 5.1. Because Dsep decomposes into disjoint subsets Ds,sep, s = 0, 1, . . . , k Proposition 5.1 is im-
mediate from Corollary 5.4 and Lemma 5.5.

(cid:3)

(cid:3)

Proof of Proposition 2.6. By deﬁnition of Bsep and Proposition 4.2 we have

E[Zβ,sep(G)2] ∼ Xρ∈R∩Bsep

E[Zρ,bal(G)].

By Propositions 2.2 and 5.1,

Xρ∈R∩Bsep

E[Zρ,bal(G)] = Xρ∈R∩Bsep

exp(n fd ,β(ρ)+ o(n)) = exp¡2n ln k + nd ln¡1− cβ/k¢+ o(n)¢ .

Combining (5.7)–(5.8) with (2.3) and taking logarithms yields the assertion.

(5.7)

(5.8)

(cid:3)

REFERENCES

[1] D. Achlioptas, E. Friedgut: A sharp threshold for k-colorability. Random Struct. Algorithms 14 (1999) 63–70.
[2] D. Achlioptas, A. Coja-Oghlan: Algorithmic barriers from phase transitions. Proc. 49th FOCS (2008) 793–802.
[3] D. Achlioptas, M. Molloy: The analysis of a list-coloring algorithm on a random graph. Proc. 38th FOCS (1997) 204–212.
[4] D. Achlioptas, A. Naor: The two possible values of the chromatic number of a random graph. Annals of Mathematics 162 (2005), 1333–1349.
[5] P. Ayre, A. Coja-Oghlan, C. Greenhill: Hypergraph coloring up to condensation. arXiv:1508.01841 (2015).
[6] J. Banks, C. Moore: Information-theoretic thresholds for community detection in sparse networks. arXiv:1601.02658 (2016).
[7] V. Bapst, A. Coja-Oghlan: The condensation phase transition in the regular k-SAT model. arXiv:1507.03512 (2015).
[8] V. Bapst, A. Coja-Oghlan, S. Hetterich, F. Raßmann, Dan Vilenchik: The condensation phase transition in random graph coloring. Com-

munications in Mathematical Physics 341 (2016) 543–606.

[9] V. Bapst, A. Coja-Oghlan, F. Raßmann: A positive temperature phase transition in random hypergraph 2-coloring. Annals of Applied Prob-

ability, in press.

[10] R. Baxter: Exactly solved models in statistical mechanics. Courier Corporation, (2007).
[11] N. Bhatnagar, A. Sly, P. Tetali: Decay of correlations for the hardcore model on the d -regular random graph. arXiv:1405.6160 (2014).
[12] A. Coja-Oghlan: Upper-bounding the k-colorability threshold by counting covers. Electronic Journal of Combinatorics 20 (2013) P32.
[13] A. Coja-Oghlan, C. Efthymoiu, S. Hetterich: On the chromatic number of random regular graphs. Journal of Combinatorial Theory, Series

B 116 (2016) 367–439.

[14] A. Coja-Oghlan, D. Vilenchik: The chromatic number of random graphs for most average degrees. International Mathematics Research

Notices, in press.

[15] P. Contucci, S. Dommers, C. Giardina, S. Starr: Antiferromagnetic Potts model on the Erd˝os-Rényi random graph. Communications in

Mathematical Physics 323 (2013) 517–554.

16

[16] A. Dembo, A. Montanari, A. Sly, N. Sun: The replica symmetric solution for Potts models on d -regular graphs. Comm. Math. Phys. 327

(2014) 551–575.

[17] M. Dyer, A. Frieze, C. Greenhill: On the chromatic number of a random hypergraph. Journal of Combinatorial Theory, Series B. 113 (2015),

68-122

[18] C. Efthymiou: MCMC sampling colourings and independent sets of G(n, d/n) near uniqueness threshold. Proc. 25th SODA (2014) 305–316.
[19] C. Efthymiou: Switching colouring of G(n,d /n) for sampling up to Gibbs uniqueness threshold. Proc. 22nd ESA (2014) 371-381
[20] P. Erd˝os, A. Rényi: On the evolution of random graphs. Magayar Tud. Akad. Mat. Kutato Int. Kozl. 5 (1960) 17–61.
[21] S. Janson, T. Luczak, A. Rucinski: Random graphs. Vol. 45. John Wiley & Sons, (2011).
[22] G. Kemkes, X. Pérez-Giménez, N. Wormald: On the chromatic number of random d -regular graphs. Advances in Mathematics 223 (2010)

300–328.

[23] F. Krzakala, A. Montanari, F. Ricci-Tersenghi, G. Semerjian, L. Zdeborova: Gibbs states and the set of solutions of random constraint

satisfaction problems. Proc. National Academy of Sciences 104 (2007) 10318–10323.

[24] M. Mézard, A. Montanari: Information, physics and computation. Oxford University Press 2009.
[25] M. Mézard, A. Montanari: Reconstruction on trees and spin glass transition. Journal of statistical physics 124.6 (2006): 1317-1350.
[26] M. Molloy: The freezing threshold for k-colourings of a random graph. Proc. 43rd STOC (2012) 921–930.
[27] L. Zdeborová, F. Krzakala: Potts Glass on Random Graphs. EPL (Europhysics Letters) 81.5 (2008): 57005.
[28] L. Zdeborová, F. Krzakala: Phase transition in the coloring of random graphs. Phys. Rev. E 76 (2007) 031131.

AMIN COJA-OGHLAN, acoghlan@math.uni-frankfurt.de, GOETHE UNIVERSITY, MATHEMATICS INSTITUTE, 10 ROBERT MAYER ST, FRANK-

FURT 60325, GERMANY.

NOR JAAFARI, jaafari@math.uni-frankfurt.de, GOETHE UNIVERSITY, MATHEMATICS INSTITUTE, 10 ROBERT MAYER ST, FRANKFURT

60325, GERMANY.

17

