6
1
0
2

 
r
p
A
4

 

 
 
]

V
C
.
s
c
[
 
 

3
v
3
6
4
6
0

.

3
0
6
1
:
v
i
X
r
a

CONTROLLING EXPLANATORY HEATMAP RESOLUTION AND SEMANTICS VIA

DECOMPOSITION DEPTH

Sebastian Bach1, Alexander Binder2,∗, Klaus-Robert M¨uller3,4,∗ and Wojciech Samek1,∗

1 Fraunhofer Heinrich Hertz Institute, Einsteinufer 37, 10587 Berlin, Germany

2 Singapore University of Technology (SUTD), 8 Somapah Road, Singapore 487372, Singapore
3 Berlin Institute of Technology (TU Berlin), Straße des 17. Juni 135, 10623 Berlin, Germany

4 Korea University, 145 Anam-ro, Seongbuk-gu, Seoul, 02841, Korea

∗ Member, IEEE

ABSTRACT

We present an application of the Layer-wise Relevance
Propagation (LRP) algorithm to state of the art deep convo-
lutional neural networks and Fisher Vector classiﬁers to com-
pare the image perception and prediction strategies of both
classiﬁers with the use of visualized heatmaps. Layer-wise
Relevance Propagation (LRP) is a method to compute scores
for individual components of an input image, denoting their
contribution to the prediction of the classiﬁer for one particu-
lar test point. We demonstrate the impact of different choices
of decomposition cut-off points during the LRP-process, con-
trolling the resolution and semantics of the heatmap on test
images from the PASCAL VOC 2007 test data set.

1. INTRODUCTION

Nonlinear models play an integral part in many well-predicting
machine learning algorithms. They include, for example, ker-
nel machines, artiﬁcal neural networks, and other nonlinear
mapping functions and feature space transformations e.g.
during preprocessing steps. Many high-performing predic-
tors consist of multiple layers of such mappings resulting in
powerful predictive capabilities, which comes at the cost of
an obfuscation of the decision making. Oftentimes, however,
knowledge about how a prediction comes to pass is as equally
important as the conﬁdence of the prediction, as it may e.g.
help to identify the weaknesses of a classiﬁer, the training
data or reveal the policies followed by the predictor.

Quite recently, multiple endeavours have been made to
gain insight into those black box classiﬁers, e.g. for neural
network type classiﬁers by highlighting dominant ﬁlter acti-
vations [1], computing saliency maps visualizing local sen-
sitivities [2] or the identiﬁcation of support regions [3] criti-
cal to the prediction for SVM [4] classiﬁers with max-pooling
feature mapping and the explanation of hard feature mappings
with HIK kernels [5].

With Layer-wise Relevance Propagation [6] (LRP), a
principled approach applicable to a wide range of classiﬁer

architectures and problem domains has been introduced. LRP
is a method for explaining the output of a classiﬁer wrt to the
input data. Speciﬁcally, the method allows to generate an
explanation of how the individual components of the input
in their given state cause the evaluating model to arrive at
its decision. LRP assigns relevance scores to each input
(or intermediate representation) component, which can then
be visualized as a heatmap. In [7], the algorithm has been
used to compare the perception of Deep Neural Network
(DNN) classiﬁers and a state-of the art conﬁguration of the
improved Fisher Vector [8] (FV) classiﬁer, demonstrating
the method’s general applicably to a wide range of classiﬁer
architectures. However, due to limits in the transparencies
of the feature extraction process which in general apply to
Bag of Feature (BoF) classiﬁers, heuristic steps have been
incorporated into the decomposition process [7, 6, 3], leaving
the decision-explaining heatmaps to appear much less sparse
and at a lower resolution when compared to the output of
LRP applied to DNNs. To alleviate this issue, we introduce
the notion of a mapping inﬂuence cut-off point with allows
to control the degree of detail and semantics of a heatmap.
A qualitative analysis on heatmaps at different resolutions
computed for images of the PASCAL VOC 2007 [9] and both
predictors is performed.

2. LAYER-WISE RELEVANCE PROPAGATION

j

The aim of LRP is to attribute shares of upper layer relevances
R(l+1)
to all components i of the adjacent lower layer l, such
that each component of l receives a relevance score R(l)
i pro-
portionally to its contribution to the output values at layer l+1
when performing a forward pass.
In its simplest and most
general formulation, this is realized via the local decomposi-
tion rule

R(l)

i =

zij
zj

R(l+1)

j

(1)

(cid:88)

j

with zij representing the outcome of a forward mapping oper-
ation from component i of layer l to component j in layer l+1
and zj being the combined output at layer l + 1. Note that the
case 0/0 is being treated as 0. Starting at the predictor output
with R(l+1) = f (x), this decomposition is then performed
iteratively layer-by-layer under consideration of the classiﬁer
architecture until relevance scores at the input layer have been
obtained. Several pertinent adaptions of Equation 1 speciﬁc
to different forward mappings have been discussed and evalu-
ated in [10, 6, 7], with select variants relevant to the classiﬁers
used within the scope of this paper being remarked in below
Sections 2.1 and 2.2.

2.1. LRP for Deep Neural Networks

Neural network type classiﬁers typically consist of a sequence
of mapping layers

(cid:88)

zij = xiwij ; zj =

zij + bj ; xj = g(zj)

(2)

j

where xi is the input, wij and bj are the learned weights
and bias terms and g(·) incorporates a non-linear activation
or/and pooling function. This formulation of a network is in
general enough to encompass a wide range or architectures,
including convolution operations. Equation 1 and variants
thereof are directly applicable to DNN classiﬁers, resulting
in (sub)pixel-accurate1 relevance scores R(1)
p per input pixel
p. For the ConvNet models with ReLu activation layers con-
sidered throughout this paper, we apply the α/β-weighted de-
composition formula with β = 1, which has been identiﬁed
to result in heatmaps best representing the classiﬁer decision
in [11].

2.2. LRP for Bag of Feature Classiﬁers

The computations performed in the context of Bag of Feature
methods ﬁt well into the framework described by LRP. Sim-
ilar to DNNs, BoF classiﬁers operate by executing consec-
utive layers of feature extraction, mappings and transforma-
tions relative to a visual vocabulary and pooling steps. The
resulting vector description is then being fed into a support
vector classiﬁer for training and classiﬁcation. LRP decom-
poses the prediction of such a pipeline in inverse direction,
starting with R(4) = f (x). [6] points out solutions for de-
composing any kernel-based classiﬁcation function to com-
pute relevances R(3)
for the dimensions d of the vector repre-
d
sentation of the input image. Also, relevance scores R(2)
for
all local descriptors l ∈ L as extracted from an input image
can easily be computed for sum- and max-pooled (and any-
thing in between) mappings. In previous work, the notation

l

1E.g. for DNNs receiving rgb color images as input, each color channel
for vizualiza-

per pixel receives a relevance score. We use their sum as R(1)
tions.

p

m(l)d has been used to describe the output of such a map-
ping function m with input l to output dimension d, which
corresponds to zij (as zld) in Equation 1.

Since feature extraction algorithms encode and compress
the image within a the receptive ﬁeld of a local descriptor,
the relationship between single pixels and local descriptor di-
mensions – or even visual prototypes – is not inherently clear
in general. This is especially true for quantile-based feature
descriptors. For that reason [6, 7] uniformly distribute a lo-
cal feature’s relevance score across all pixels within its recep-
tive ﬁeld to compute R(1)
for each input pixel. This leads to
p
heatmaps appearing more coarse when compared to heatmaps
produced from DNN classiﬁers (see Fig. 1. and [6, 7]), with
heatmap granularity being limited by descriptor size.

Within the scope of this paper we use a FV classiﬁer to
represent the class of BoF models, in a setup as described
in [12]. The mappings of features l onto a FV representation
may be of both positive and negative sign, potentially destabi-
lizing the relevance decomposition. We therefore employ the
following -stabilized decomposition formula with  = 100.
This redistribution rule has been found to compute explana-
tory heatmaps matching the classiﬁer decision well [7].

3. CONTROLLING HEATMAP DETAIL AND

SEMANTIC

We introduce the notion of an mapping inﬂuence cut-off point,
describing the step from which on the forward mapping func-
tion of the classiﬁer does not inﬂuence relevance propagation
anymore and only the receptive ﬁeld of the classiﬁer does. For
the DNN architecture as described in Section 2.1, there is no
such cut-off point being used in previous work, whereas for
the BoF architecture as of Section 2.2 the cut-off is located
at the decomposition layer resulting in R(1)
(for brevity, we
p
say the cut-off is “at R(1)
p ”) and has been chosen out of ne-
cessity in past work. In this Section our aim is to explain how
the choice of such a cut-off point may be voluntary for both
considered predictor architectures by potentially increasing or
decreasing the heatmap resolution for BoF models and DNNs
respectively.

For neural network type classiﬁers, decreasing the reso-
lution of LRP-computed heatmaps follows the procedure to
compute scores R(1)
for BoF classiﬁers. For ConvNets, in-
p
stead of applying the local decomposition rule from Equation
1 to the bottom-most convolution layer, relevance scores com-
puted for the succeeding pooling layer are to be distributed
uniformly across all of its inputs. This is equivalent to apply-
ing Equation 1 and then averaging lower layer relevances for
each convolution operator – or in general, choosing a cut-off
point at a higher layer is equal to substituting any mappings
from that layer on with ﬂat weights. Note that for simple
fully connected layers, this approach will render the resulting
lower layer relevances meaningless, since spatial structure –

as it is the case with convolution layers – is not present and
the resulting heatmap will be uniform. Here, the w2-rule pro-
posed in [10] might yield satisfactory results by distributing
relevance values according to mapping weights only

To bridge the gap from local feature relevance scores to
pixel relevance scores with BoF classiﬁers, two obstacles
need to be outmanoeuvred, namely (i) one has to be able
to compute relevance scores for each dimension of a local
descriptor l and (ii) the local feature dimensions need to be
relatable to a grid of pixel coordinates. In this work, we con-
centrate on the FV classiﬁcation model as described in [12],
where the requirements to solve (i) are given fully and (ii)
partially, as explained below.

(i) Computing relevances R(2)
li

for local feature all local
feature dimensions i: To compute relevance scores at such
a ﬁne granularity, the forward mapping contribution of each
feature dimension needs to be known (or at least its inﬂuence.
This, however, will not be subject of this work). For the FV
model considered here, this is the case, such that an exact
relevance composition can be performed for each li. For one,
[12] compute projections

(cid:19)

(cid:18) l − µk
(cid:32)

σk
(l − µk)2

σ2
k

Ψµk (l) =

Ψσk (l) =

1√
πk
1√
2πk

γk(l)

γk(l)

(cid:33)

− 1

(3)

(4)

relating l to all K components of a GMM λ = {(πk, µk, Σk)}1..K
ﬁt during training wrt to its 1st and 2nd moments, with
l ∈ RD and also Ψµk (l) and Ψσk (l) ∈ RD. Further, the con-
variance matrices of the trained GMM have been constrained
to be diagonal (e.g. ∀k : Σk = diag(σk)). We therefore
know that each li corresponds to exactly one dimension in
the mapping output space of Ψµk (l) and Ψσk (l) for all k,
which are concatenated to form the full FV representation
),
Ψλ(l). For simplicity, suppose a function d = δ(i, Ψ{µ,σ}k
which computes for a local feature dimension i and mapping
of choice the output dimension d of the FV representation.
We compute relevance scores for each li as

R(2)
li

=

(cid:18)

K(cid:88)

k=1

+

(cid:80)
(cid:80)

Ψµk (l)i
l(cid:48)∈L Ψµk (l(cid:48))i

R(3)

δ(i,Ψµk )

Ψσk (l)i
l(cid:48)∈L Ψσk (l(cid:48))i

R(3)

δ(i,Ψσk )

(cid:19)

.

(5)

(6)

Note that in practice we do still apply the -stabilized decom-
position variant. Above decomposition describes the basic
approach. Before mapping the local descriptors into the FV
space, the reference model from [12] projects the initial 128-
dimensional SIFT [13] features onto a 80-dimensional sub-
space via mapping components computed with PCA [14] dur-
ing training. The now also 80-dimensional R(2)
can easily be
projected into the original SIFT space by applying Equation

l

aer
79.1
88.1
cat
59.9
81.1
per
85.1
92.4

bic
66.4
79.7
cha
51.9
51.0
pot
28.6
50.0

bir
45.9
80.8
cow
47.6
61.1
she
49.6
74.0

boat
70.9
77.2
din
58.1
64.6
sof
49.3
49.5

bot
27.6
35.5
dog
42.3
76.2
tra
82.7
87.1

bus
car
69.7
81.0
72.7
86.3
hor
mot
80.5
69.3
81.6
79.3
tvm mAP
60.0
54.3
67.1
72.1

F
N

F
N

F
N

Table 1: Prediction performance of the FV and DNN clas-
siﬁers used in this paper, in average precision (AP) per class
and in percent.

1, since the appropriate operation in the forward pass realizes
a linear projection. A numerical stabilization of the denomi-
nator was necessary for good results, and  = 100 has been
chosen as the best suited parameter after visual inspection.

(ii) Relating local feature dimensions to a spatial pixel
grid: Many local feature types aggregate information ex-
tracted from an image area, such that the relation between
feature dimension and pixel coordinate is lost in the process
on the interaction between groups pixel values. An appro-
propriate example are quantile-based local descriptors, for
the computation of which all scanned pixel values are of
importance, yet only a select few are grouped into the ﬁnal
descriptor, maybe even in an interpolated manner. However,
knowledge about spatial bin placement and local feature ge-
ometry can be used whenever possible in order to intelligently
merge R(2)
and assign relevance scores to pixels at a higher
li
resolution. The reference FV predictor uses SIFT descriptors
at different sizes with 4 × 4 spatial bins, with each capturing
a histogram of gradient magnitudes in 8 directions. We use
knowledge about the feature geometry and indexing [15, 16]
to evenly distribute the summed relevances corresponding to
each spatial bin evenly over the covered pixels, thus increas-
ing the resolution of each SIFT feature’s relevance feedback
16-fold.

4. RESULTS

We compute heatmap explanations for the FV model conﬁg-
ured after [12] and trained for [7] and the BVLC reference
model from the Caffe package [17] which has been retrained
for the 20 classes of PASCAL VOC 2007 [9]. Classiﬁcation
results for both models in average precision (AP) are listed
in Table 1. For both models, we compute heatmaps with cut-
off points at R(1) and no cut-off (as far as possible for FV.
See Section 3) and show results in Figure 1. We observe that
heatmaps without cut-off are still sparser for DNNs due to the
limits set to the FV classiﬁer, despite images being fed into
the network at a lower resolution. Nonetheless, the higher
resolution heatmaps for the FV classiﬁer allow for a better
understanding of the classiﬁer decision when compared to

the heatmaps with cut-off at R(1). In the example for class
“chair” the high resolution relevances demonstrate that the
FV classiﬁer mostly uses the object structure itself for clas-
siﬁcation, which was difﬁcult to read for the lower resolution
heatmaps. Both models seem to follow similar higher level
strategies for most object classes, e.g. with the bottom half of
cars, (also wheels of the bicycles, faces and clothing of peo-
ple) or the faces of dogs capturing the models’ focus of atten-
tion. Both classiﬁers strongly react to deﬁning aspects of the
object, while still focussing on most of it as can be reasoned
from the input images with the lower resolution heatmap con-
trolling the alpha channel, visualizing the respective model’s
focus of attention. We also observe that both classiﬁers seem
to prefer the use of hard edges (e.g. cutlery for class table) for
detection as the result of training (DNN) or due to design (FV
with SIFT), rather than texture. The more deep and complex
DNN classiﬁer seems to be in general more adept at abstract-
ing object appearances and is therefore less prone to mislead-
ing noise information while using more sophisticated rules
for prediction. For the image showing a dog, for example,
the FV model reacts strongly to eye-like black pebbles in the
snow, next to the dog’s eyes themselves, whereas the network
model is reacting to a structure resembling a dog’s face (nose
below eyes). However, this increased concentration of the
DNN on higher structural information includes regularly co-
appearing image features into the detection process, whereas
the FV model tends to concentrate on simpler rules. Note the
chandelier for class “chair” in living room scenes.

5. CONCLUSION

In this work we introduce the notion of a mapping inﬂu-
ence cut-off point, which allows to control the resolution
of the computed heatmap and simultaneously its semantics.
We have compared heatmap explanations for state-of-the art
DNN and FV models at different degrees of detail. While
(very) high resolution relevance maps provide information
about the kind of visual cues a classiﬁer has been conditioned
on a very local level, lower resolution heatmaps shed light
to the the classiﬁer’s focus of attention by directly mapping
the relevance scores assigned to its receptive ﬁelds onto pixel
level. By voluntarily choosing a mapping inﬂuence cut-off
point, we are able to explain decisions wrt a desired aspect
of the perception of the model. In combination with image-
wise predictions, heatmaps computed at different degrees
of detail open up the possibility of automated assistance in
different problem settings, e.g.
in localizing target content
upon detection, and then highlighting characteristic features.
We see possible applications for instance in the medical do-
main, where the screening of large images of stained tissue
by a medical expert might be assisted with low resolution
heatmaps for malignant tissue localization and a high resolu-
tion heatmap verifying the decision of the classiﬁer.

Fig. 1: Each two rows of images shows images corresponding to the
CNN (left four images) and FV (right four) models. In clock-wise
order: ((cid:45)) Input image, ((cid:37)) high resolution heatmap without cut-off
point, ((cid:38)) low resolution heatmap with cut-off at R(1)
and ((cid:46)) the
p
same heatmap added as α-channel to the input. Green heatmap areas
are rated neutral to the classiﬁer prediction, yellow to dark red hues
indicate a positive contribution to the target class with image areas
marked with blue color receiving negative relevance ratings.

[10] Gr´egoire Montavon, Sebastian Bach, Alexander Binder,
Wojciech Samek, and Klaus-Robert M¨uller, “Explain-
ing nonlinear classiﬁcation decisions with deep tay-
lor decomposition,” arXiv preprint arXiv:1512.02479,
2015.

[11] Wojciech Samek, Alexander Binder, Gr´egoire Mon-
tavon, Sebastian Bach, and Klaus-Robert M¨uller, “Eval-
uating the visualization of what a deep neural network
has learned,” arXiv preprint arXiv:1509.06321, 2015.

[12] Ken Chatﬁeld, Victor S Lempitsky, Andrea Vedaldi, and
Andrew Zisserman, “The devil is in the details: an eval-
uation of recent feature encoding methods.,” in BMVC,
2011, p. 8.

[13] David G Lowe, “Distinctive image features from scale-
invariant keypoints,” International journal of computer
vision, vol. 60, no. 2, pp. 91–110, 2004.

[14] Karl Pearson, “Liii. on lines and planes of closest ﬁt to
systems of points in space,” The London, Edinburgh,
and Dublin Philosophical Magazine and Journal of Sci-
ence, vol. 2, no. 11, pp. 559–572, 1901.

[15] Andrea Vedaldi and Brian Fulkerson, “Vlfeat: An open
and portable library of computer vision algorithms,” in
Proceedings of the international conference on Multi-
media. ACM, 2010, pp. 1469–1472.

[16] “SIFT - vl phow,” http://www.vlfeat.org/
matlab/vl_phow.html, last accessed 2016-01-31.

[17] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey
Karayev, Jonathan Long, Ross Girshick, Sergio Guadar-
rama, and Trevor Darrell,
“Caffe: Convolutional ar-
chitecture for fast feature embedding,” in Proceedings
of the ACM International Conference on Multimedia.
ACM, 2014, pp. 675–678.

Acknowledgment
This work was supported by the German Ministry for Ed-
ucation and Research as Berlin Big Data Center BBDC
(01IS14013A),
the Deutsche Forschungsgesellschaft (MU
987/19-1) and the Brain Korea 21 Plus Program through the
National Research Foundation of Korea funded by the Min-
istry of Education. AB acknowledges support by the SUTD
Startup grant. Correspondence to KRM and WS.

6. REFERENCES

[1] Matthew D. Zeiler and Rob Fergus, “Visualizing and
understanding convolutional networks,” in ECCV, 2014,
pp. 818–833.

[2] Karen Simonyan, Andrea Vedaldi, and Andrew Zisser-
man, “Deep inside convolutional networks: Visualis-
ing image classiﬁcation models and saliency maps,” in
ICLR Workshop, 2014.

[3] Lingqiao Liu and Lei Wang, “What has my classiﬁer
learned? visualizing the classiﬁcation rules of bag-of-
feature model by support region detection,” in Computer
Vision and Pattern Recognition (CVPR), 2012 IEEE
Conference on. IEEE, 2012, pp. 3586–3593.

[4] Corinna Cortes and Vladimir Vapnik, “Support-vector
networks,” Machine learning, vol. 20, no. 3, pp. 273–
297, 1995.

[5] Jasper RR Uijlings, Arnold WM Smeulders, and
Remko JH Scha, “The visual extent of an object,” Inter-
national journal of computer vision, vol. 96, no. 1, pp.
46–63, 2012.

[6] Sebastian Bach, Alexander Binder, Gr´egoire Montavon,
Frederick Klauschen, Klaus-Robert M¨uller, and Woj-
ciech Samek,
“On pixel-wise explanations for non-
linear classiﬁer decisions by layer-wise relevance prop-
agation,” PloS one, vol. 10, no. 7, pp. e0130140, 2015.

[7] Sebastian Bach, Alexander Binder, Gr´egoire Montavon,
Klaus-Robert M¨uller, and Wojciech Samek, “Analyzing
classiﬁers: Fisher vectors and deep neural networks,”
arXiv preprint arXiv:1512.00172, 2015.

[8] Florent Perronnin,

Jorge S´anchez,

and Thomas
Mensink, “Improving the ﬁsher kernel for large-scale
image classiﬁcation,” in Computer Vision–ECCV 2010,
pp. 143–156. Springer, 2010.

[9] M Everingham, L Van Gool, CKI Williams, J Winn, and
A Zisserman, “The pascal visual object classes chal-
lenge 2007 (voc 2007) results (2007),” 2008.

