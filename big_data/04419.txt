6
1
0
2

 
r
a

 

M
4
1

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
9
1
4
4
0

.

3
0
6
1
:
v
i
X
r
a

DRAFT

1

Modeling and Estimation of Discrete-Time

Reciprocal Processes via Probabilistic

Graphical Models

Francesca P. Carli

Abstract

Reciprocal processes are acausal generalizations of Markov processes introduced by Bernstein in
1932. In the literature, a signiﬁcant amount of attention has been focused on developing dynamical
models for reciprocal processes. In this paper, we provide a probabilistic graphical model for reciprocal
processes. This leads to a principled solution of the smoothing problem via message passing algorithms.
For the ﬁnite state space case, convergence analysis is revisited via the Hilbert metric.

I. Introduction

Non causal random processes arise in many areas of science and engineering. These processes
are usually indexed by space instead of time. The class of non causal reciprocal processes was
introduced by Bernstein in 1932 [3] and studied by many authors [17], [18], [19], [9], [23], [25],
[22], [7], [8], [11], [33]. A Rn–valued stochastic process Xk deﬁned over the interval I = [0, N]
is said to be reciprocal if for any subinterval [K, L] ⊂ I, the process in the interior of [K, L] is
conditionally independent of the process in I − [K, L] given XK and XL. Reciprocal processes
are a natural generalization of Markov processes: from the deﬁnition it immediately follows
that Markov processes are necessarily reciprocal, but the converse is not true [17]. Moreover
multidimensional Markov random ﬁelds reduce in one dimension to reciprocal processes, not
Markov processes. To attest the relevance of reciprocal processes from an engineering point of
view, note, for example, that the steady-state distribution of the temperature along a heated ring

March 15, 2016

DRAFT

DRAFT

2

or a beam subjected to random loads along its length can be modeled in terms of reciprocal
processes. Applications to tracking of a ship-trajectory [12], estimation of arm movements [30],
and synthesis of textured images [29] were also considered in the literature.

Starting with Krener’s work [23], a signiﬁcant amount of attention has been focused on
developing state–space dynamical models for reciprocal processes. Both the continuos and
discrete–time case has been addressed. In this paper, our focus is on discrete–time reciprocal
processes. In [25] it has been shown that discrete–time Gaussian reciprocal processes admit self–
adjoint second–order models driven by a locally correlated noise, where the noise correlation
structure is speciﬁed by the model dynamics. These models recall state–space models for Markov
processes but are acausal (the system does not evolve recursively in the direction of increasing
or decreasing value of k) and the driving noise is not white. Second order state space models
for discrete–time ﬁnite–state reciprocal processes has been derived in [11] (see also [10]).

In this paper, we provide probabilistic graphical models for reciprocal processes with cyclic
boundary conditions. This approach is distribution–independent and leads to a principled solution
of the smoothing problem via sum–product (a.k.a. belief propagation) algorithms. Sum–product
algorithms are a powerful class of algorithms for performing inference in graphical models. For
tree-structured graphs sum–product algorithms are guaranteed to converge to the correct marginal
posterior. As it will be shown in the paper, the graphical model associated to a reciprocal process
is a single–loop network and is not a tree. Convergence of sum–product algorithms for single–
loop networks has been studied in the literature (see [31], [32] and references therein). For
the ﬁnite state space case, we revisit convergence analysis via the Hilbert metric. This approach
seems suitable for extensions to the analysis of convergence of message passing algorithms in
more general settings (state–spaces and graph topologies).

II. Reciprocal Processes

A stochastic process Xt deﬁned on a time interval I is said to be Markov if, for any t0 ∈ I,
the past and the future (with respect to t0) are conditionally independent given Xt0. A process is
said to be reciprocal if, for any t0, t1 ∈ I with t0 < t1, the process in the interior of the interval
(t0, t1) and the process in the exterior of the same interval are conditionally independent given
the boundary values Xt0 and Xt1. Formally [18]

Deﬁnition 2.1: Let {Xt, a ≤ t ≤ b} be a (S , Σ)–valued stochastic process on the ﬁnite closed

March 15, 2016

DRAFT

DRAFT

3

interval [a, b] with underlying probability space (Ω,A, P). We say that {Xt, a ≤ t ≤ b} is recip-
rocal if, for each a ≤ s < t ≤ b,

P(AB | Xs, Xt) = P(A | Xs, Xt)P(B | Xs, Xt)

for every A in the σ–ﬁeld generated by the random variables {Xr : a ≤ r < s or t < r ≤ b} and
B in the σ-ﬁeld generated by {Xr : s < r < t}.
From the deﬁnition we have that the class of reciprocal processes is larger than the class of
Markov processes: Markov processes are necessarily reciprocal, while the converse is generally
not true [17]. Moreover, multidimensional Markov random ﬁelds reduce in one dimension to
reciprocal processes, not to Markov processes.

Starting with Krener’s work [23], a signiﬁcant amount of attention has focused on developing
dynamical models for reciprocal processes. In this paper, our focus is on discrete–time reciprocal
processes. In the next Section we brieﬂy review dynamical models for discrete–time reciprocal
processes, that were ﬁrst introduced in [25]. In Section V we provide a probabilistic graphical
model representation of reciprocal processes.

III. Second–order Models of Reciprocal Processes

Let Xk be a zero-mean process deﬁned over the ﬁnite interval I = [0, N] and taking values

in Rn. It is well–known that if Xk satisﬁes the recursion equation

where Wk is a zero–mean random process with

Xk+1 = AkXk + Wk

and X0 is a zero–mean random variable such that

E(cid:2)WkW(cid:62)
E(cid:2)WkX(cid:62)

(cid:3) = I δkl
(cid:3) = 0

l

0

(1)

(2)

(3)

then Xk is Markov. If Xk is Gaussian, then the converse is also true, namely it can be shown
(see e.g. [1]) that a Gaussian process is Markov if and only if it satisﬁes (1) with noise structure
(2), (3).

For a reciprocal process, the following holds. Let 1 ≤ k ≤ N − 1, and consider the model

March 15, 2016

− M−

k Xk−1 + M0

kXk − M+

k Xk+1 = Ek ,

(4)

DRAFT

DRAFT

where M0

k, M+

k , M−

k are such that

M0
k

k)(cid:62)
= (M0

,

M+
k

= (M−

k+1)(cid:62)

.

and the driving noise E(k) satisﬁes

and is locally correlated with covariance Σe

4

(5)

(6)

(7)

E [EkX(cid:62)

l ] = I δkl

M0
k,
−M+

k

for l = k

for l = k + 1

0

otherwise



[Σe]k,l =

It is straightforward to prove that a process {Xk} satisfying the model (4)–(7) is reciprocal.
Moreover, if the process is Gaussian, the converse is also true. To be more precise [25, Thm
3.1]

Theorem 3.1: Let Xk be a zero–mean Gaussian process whose covariance Σx is nonsingular,
i.e. Σx (cid:31) 0. Then Xk is reciprocal if and only if it admits a well–posed second–order descriptor
model of the form (4)–(7).
Notice that, in order to specify completely the reciprocal process Xk in terms of the model (4),
some boundary conditions must be provided. Following [25], in this paper we consider cyclic
boundary conditions, namely we assume

X−1 = XN,

XN+1 = X0 .

(8)

These conditions are equivalent to extending cyclically the model (4) and the noise structure
(6), (7) to the whole interval I = [0, N], provided that, in these identities, k − 1 and k + 1 are
deﬁned modulo N + 1.

Equation (4) with cyclic boundary conditions (8) can be written in matrix for as

MX = E

 , E =





X0
X1
...
XN

E0
E1
...
EN

 ,

X =

where

March 15, 2016

(9)

DRAFT

DRAFT

and matrix M given by

M =



−M+
M0
0
0
−M−
1 M0
. . .

0
1 −M+

1

0
−M+

N

. . .

0

0

. . .

. . .

0

0

. . .

−M−
0

0

. . .

N−1 −M+
−M−
N−1 M0
N−1
−M−
N M0
0
N



.

5

(10)

Remark 3.1: Equations (4)–(8) specify a second–order nearest–neighbor model for a discrete–
time reciprocal process. The model recalls standard ﬁrst–order state–space models for Markov
processes but it is acausal (the system does not evolve recursively in the direction of increasing
or decreasing value of k). Also, the driving noise Ek is not white, but locally correlated.

IV. Probabilistic Graphical Models

In this section, we brieﬂy review some relevant theory about probabilistic graphical models
that will be needed in the sequel for the derivation of the probabilistic graphical model associated
to a reciprocal process (see Section V). We refer the reader to [27], [24], [21], [5] for a thorough
treatment of the subject.

Graph–related terminology and background

Let G = (V, E) be a graph where V denotes the set of vertices and E denotes the set of edges.
An edge may be directed or undirected. In case of a directed edge from node i to node j, we say
that i is a parent of its child j. Two nodes i and j are adjacent in G if the directed or undirected
edge (i, j) is contained in E. An undirected path is a sequence of distinct nodes {1, . . . , m} such
that there exists an undirected or directed edge for each pair of nodes {l, l + 1} on the path. A
graph is connected if every pair of points are joined by a path. A graph is singly-connected if
there exists only one undirected path between any two nodes in the graph. A (un)directed cycle
is a path such the beginning and ending nodes on the (un)directed path are the same.

If E contains only undirected edges then the graph G is an undirected graph (UG). If E

contains only directed edges then the graph G is a directed graph (DG).

Two important classes of graphs for modeling probability distributions that we consider in this
paper are UGs and directed acyclic graphs (DAGs), namely directed graphs having no directed
cycles.

March 15, 2016

DRAFT

DRAFT

6

A graph G is complete if there are edges between all pairs of nodes. A clique in a undirected
graph is a fully connected set of nodes. A maximal clique is a clique that is not a strict subset
of another clique. An undirected graph G is chordal if every cycle of length greater than three
has an edge connecting nonconsecutive nodes, see e.g. [15]. The distance d(u, v) between two
vertices u and v in a graph G is the length of a shortest path between them. If there is no path
connecting the two vertices d(u, v) = ∞. A shortest path between any two vertices is often called
a geodesic. The diameter of a (connected) graph G, d(G), is the length of any longest geodesic,
i.e. d(G) = max{d(u, v), u, v ∈ V}.

Probabilistic graphical models

Now that we have introduced some terminology about graphs, we turn to the main object of this
paper, namely probabilistic graphical models. Probabilistic graphical models are graph–based
representations that compactly encode complex distributions over a high-dimensional space. In
a probabilistic graphical model, each node represents a random variable and the links express
probabilistic relationships between these variables. There are diﬀerent types of graphical models.
Two major classes are Bayesian networks, that use directed graphs, and Markov networks that
are based on undirected graphs. A third class are factor graphs.

There are two ways of deﬁning a graphical model: (i) as a representation of a set of inde-
pendencies, and (ii) as a skeleton for factorizing a distribution. For Bayesian networks, the two
deﬁnitions are equivalent, while for Markov networks additional assumptions, such as having a
strictly positive distribution, are needed to get factorization from independences (Hammersely–
Cliﬀord theorem). The primary deﬁnition of Markov networks will thus be in terms of (global)
conditional independencies.

The two formalisms, Bayesian and Markov networks, can express diﬀerent sets of conditional
independencies and factorizations, and one or the other may be more appropriate, or even the
only suitable, for a particular application. This will be discussed to some extent in the following.
In this paper, we will be mainly interested in undirected graphical models, directed ones being
mainly useful for expressing causal relationships between random variables.

In this Section, we ﬁrst brieﬂy introduce Markov and Bayesian networks and then describe
relevant theory that allows one to go from a given set of conditional independences (a distribution)
to its graph representation. The graphical model associated to a reciprocal process is derived in

March 15, 2016

DRAFT

DRAFT

Section V.

Markov Networks

7

The semantic of undirected graphical models is as follows.

a) Conditional independence property: An undirected graph deﬁnes a family of probability

distributions which satisfy the following graph separation property.

Property 4.1 (Graph separation property): Let A, B, and C denote three disjoint sets of
nodes in a undirected graphical model H and let us denote by XA, XB and XC the corresponding
variables in the associated probability distribution P. Then we say that XA (cid:121) XB | XC (in P)
whenever (in H) there is no path from a node in A to a node in B which does not pass through
a node in C. An alternative way to view this conditional independence test is as follows: remove
all nodes in set C from the graph together with any edge that connects to those nodes. If the
resulting graph decomposes into multiple connected components such that A and B belong to
diﬀerent components, then XA (cid:121) XB | XC.

b) Factorization property:

Property 4.2 (Factorization property): Let H be an undirected graphical model. Let C be
a clique and let XC be the set of variables in that clique. Let C denote a set of maximal cliques.
Deﬁne the following representation of the joint distribution

(cid:89)

C∈C

p(x) = 1
Z

ψC(xC) .

(11)

where the functions ψC can be any nonnegative valued functions (i.e. do not need to sum to
1), and are sometimes referred to as potential functions or compatibility functions and Z, called
the partition function, is a normalization constant chosen in such a way that the probabilities
corresponding to all joint assignments sum up to 1. For discrete random variables, it is given by

(cid:88)

(cid:89)

C∈C

x

Z =

ψC(xC) .

If continuous variables are considered it suﬃces to replace the summation by an integral.

For strictly positive distributions, the set of distributions that are consistent with the conditional
independence statements that can be read from the graph using graph separation and the set of
distributions that can be expressed as a factorization of the form (11) with respect to the maximal
cliques of the graph are identical. This is the Hammersley–Cliﬀord theorem.

March 15, 2016

DRAFT

DRAFT

8

Notice that, diﬀerently to what happens for directed graphs, potential functions in undirected
graphical models generally do not have a speciﬁc probabilistic interpretation as marginal or con-
ditional distributions. Only in special cases, for instance when the undirected graph is constructed
by starting with a directed graph, they can admit such interpretation.

Bayesian Networks

A second class of probabilistic graphical models we shall brieﬂy touch upon are Bayesian
networks. The core of the Bayesian network representation are directed acyclic graphs (DAGs).
Similarly to Markov networks, Bayesian networks can be deﬁned both in terms of conditional
independences and factorization properties, but for Bayesian networks, the two deﬁnitions are
equivalent with no need of additional assumptions. Reading the set of conditional independences
encoded by a Bayesian network again needs testing whether or not the paths connecting two sets
of nodes are “blocked”, but the deﬁnition of “blocked” is this time more involved than it was for
undirected graphs. For what concern the factorization property, in a Bayesian network, factors
of the induced distribution represent the conditional distribution of a given variable conditioned
on its parents. We do not enter here in further details about Bayesian networks models since, as
we shall see, reciprocal processes do not admit a directed graph representation.

Factor graphs

A third type of probabilistic graphical models are factor graphs. A factor graph F is an
undirected graph containing two types of nodes: variable nodes and factor nodes. Suppose we
have a function of several variables x = {x1, x2, . . . , xN} and that this function factors into a
product of several functions, each having some subset of {x1, x2, . . . , xN} as arguments

(cid:89)

g(x) =

fs(xs),

xs subset of variables

(12)

s

This function can be represented by a factor graph having a variable node for each variable xi,
a factor node (depicted by small squares) for each local function fs and an edge connecting the
variable node xi to the factor node fs if and only if xi is an argument of fs.

Notice that every undirected graph can be represented by an equivalent factor graph. The way
to do this is to create a factor graph with the same set of variable nodes, and one factor node
for each maximal clique in the graph.

March 15, 2016

DRAFT

DRAFT

9

From Models to Undirected Graphs

So far, we have been addressing the problem of associating a distribution to a given graphical
model via the set of conditional independences/factorization properties that it encodes. In this
paper, we are interested in ﬁnding the probabilistic graphical model associated to a reciprocal
process. We are thus interested in the opposite question, and namely: given a process deﬁned by
a set of conditional independencies, ﬁnd a graphical model that encodes such a set, possibly in
an “eﬃcient” way. In other words, we want to ﬁnd a graphical model that encodes all and only
the conditional independencies implied by the distribution that we want to represent. Relevant
to this aim are the notions of I-map, D-map and P-map, that we are now going to introduce.
Consider a probability distribution P and a graphical model H. Let CI(P) denote the set
of conditional independencies satisﬁed by P and let CI(H) denote the set of all conditional
independencies implied by H.

Deﬁnition 4.1 (I–map, D–map, P–map): We say that
• H is an independence map (I–map) for P if CI(H) ⊂ CI(P);
• H is a dependence map (D–map) for P if CI(H) ⊃ CI(P);
• H is a perfect map (P-map) for P if CI(H) = CI(P).

In other words, if H is an I–map for P, then every conditional independence statement implied
by H is satisﬁed by P. If H is an D–map for P then every conditional independence statement
satisﬁed by P is reﬂected by H. If it is the case that every conditional independence property of
the distribution is reﬂected in the graph, and vice versa, then the graph is said to be a perfect map
for that distribution. Clearly a fully connected graph will be a trivial I–map for any distribution
because it implies no conditional independencies and a graph with no edges will be a trivial
D–map for any distribution because it implies every conditional independence.

Generating Minimal I–maps

Back to our original question, we have that an approach to ﬁnding a graph that represents a
distribution P is simply to take any graph that is an I–map for P. Yet a complete graph is an
I-map for any distribution, but there are redundant edges in it. What we are really interested
in, are I–maps that represent a family of distributions in a “minimal” way, as speciﬁed by the
following deﬁnition.

March 15, 2016

DRAFT

DRAFT

10

Deﬁnition 4.2 (Minimal I–map): A minimal I-map is an I-map with the property that re-
moving any single edge (i.e. adding any conditional independence) would cause the graph to no
longer be an I-map.

How can we construct a minimal I-map for a distribution P? A possible approach that uses

local independencies, is based on the notion of Markov blanket, that is deﬁned as follows.

Deﬁnition 4.3: Consider a graph H = (V, E). A set U is a Markov blanket of X in a

distribution P if X (cid:60) U and if U is a minimal set of nodes such that

(X (cid:121) V − {X} − U | U) ∈ CI(P) .

(13)

The approach is as follows [21, Chap. 4].

Theorem 4.1: Let P be a positive distribution. For each node X, let MBP(X) be a minimal
set of nodes U satisfying equation (13). We deﬁne a graph H by introducing an edge {X, Y} for
all X and Y ∈ MBP(X). Then the Markov network H is the unique minimal I-map for P.

(a)

(b)

Fig. 1: Wrapped time line (on the left) and graphical model (on the right).

Nonchordal Markov networks do not admit a Bayesian network as a perfect map

It turns out that some distributions can be perfectly represented by a directed graphical model
while others can be perfectly represented by an undirected one. (EXAMPLE). On the other hand,
some sets of independence assumptions can be perfectly represented both by a Bayesian network
and by a Markov network. This is the case of undirected chordal graphs. The precise statement
is as follows.

March 15, 2016

DRAFT

DRAFT

11

Theorem 4.2: Let H be a Markov network. Then there is a Bayesian network G such that

CI(H) = CI(G) if and only if H is chordal.
An example of distribution that can be perfectly represented both by a Bayesian network and
by a Markov network is a Markov process, whose associated Markov network is a tree.

V. Probabilistic Graphical Models of Reciprocal Processes

We are now ready to state our main result, namely to ﬁnd the graphical model associated to
a reciprocal process. We ﬁrst derive the minimal I–map associated to a reciprocal process on
the interval I = [0, N] (Theorem 5.1) and then show that this minimal I–map is indeed also a
P-map (perfect map) for the reciprocal process on I (Theorem 5.2).

Theorem 5.1: The graphical model in Figure 1b composed of the N +1 nodes X0, X1, . . . , XN

arranged in a loop is the unique minimal I–map for a reciprocal process on I = [0, N].

Proof via Theorem 4.1: Let PR denote the distribution of a reciprocal process on I. A
Markov blanket of Xk in PR is the set UR = {Xk−1, Xk+1}. The undirected graphical model in
Figure 1b thus follows by using the construction criterion in Theorem 4.1.

Theorem 5.2: The graphical model in Figure 1b composed of the N +1 nodes X0, X1, . . . , XN

arranged in a loop is a P–map for a reciprocal process on I = [0, N].

Proof: Consider a reciprocal process deﬁned on the interval [0, N] with cyclic boundary
conditions X−1 = XN, XN+1 = X0. Because cyclic boundary conditions hold, one may think
to the process as deﬁned on the wrapped timeline in Figure 1b. The thesis follows from the
deﬁnition of reciprocal process and the separation property 4.1 by noting that any interval on
the (wrapped) timeline deﬁnes a set (pair) of nodes on the corresponding graphical model that
decomposes the graph into multiple connected components such that nodes corresponding to the
“interior” and the “exterior” of the interval belong to diﬀerent components.

From now on, we shall refer to the graphical model in Figure 1b composed of N + 1 nodes

X0, X1, . . . , XN arranged in a loop as a reciprocal chain.

Reciprocal processes do not admit a directed graph as perfect map

The Markov network in Figure 1b is not chordal, thus, by Theorem 4.2 reciprocal processes
do not admit a directed graph as perfect map. This is in contrast with Markov processes that
admit both a directed and an undirected graphical model as perfect map.

March 15, 2016

DRAFT

DRAFT

12

Fig. 2: Factor Graph associated with a reciprocal process on [0, 4].

Factor graph representation of a Reciprocal Process

As observed above, every undirected graph can be represented by an equivalent factor graph
having the same set of variable nodes, and one factor node for each maximal clique in the graph.
The factor graph corresponding to the indirected graph in Figure 1b is shown in Figure 2.

Remark 5.1: The set of independencies

X0 (cid:121) X2 {X1, X3} ,

X1 (cid:121) X3 {X0, X2}

cannot be expressed/encoded by a Bayesian network while they can be perfectly captured by
a single–loop undirected graphical model with 4 nodes. For this reason, the graphical model
in Figure 1b (or, more precisely, its analogous with four nodes) has been extensively used in
the graphical model literature as a motivating example for the introduction of Markov networks
(see [27, Chap. 3] or, equivalently, the misconception example in [21, Chap. 4]). Nevertheless,
to the best of our knowledge, this is the ﬁrst time that such graphical model is associated to
a reciprocal process (distribution). In other words, our contribution establishes a link between
a well-known graphical structure in the graphical models literature and the class of reciprocal
processes studied in Statistics.

VI. Smoothing of Reciprocal Processes via Belief Propagation

Consider the graphical model in Figure 3 where to the single loop in Figure 1b one observed
node Yk has been attached to each unobserved node Xk, k = 0, . . . , N, We shall refer to the

March 15, 2016

DRAFT

1x0f40x4f34x3f23x2f12x1f01DRAFT

13

Fig. 3: Hidden reciprocal model.

graphical model in 3 as a hidden reciprocal chain. The (ﬁxed–interval) smoothing problem is
to compute, for all k ∈ [0, N], the conditional distribution of Xk given Y0, . . . , YN.

A. Belief Propagation (a.k.a. sum–product) algorithm

Let H = (E, V) be an undirected graphical model over the variables {X0, . . . , XN}, Xi ∈ X,
i = 0, . . . , N. In Section IV, we have seen that the joint distribution associated with H can be
factored as

p(x) = 1
Z

ψC(xC) ,

(14)
where C denote a set of maximal cliques in the graph. In the following, we will be interested
in pairwise Markov random ﬁelds – i.e. a Markov random ﬁeld in which the joint probability
factorizes into a product of bivariate potentials (potentials involving only two variables) – where
each unobserved node Xi has an associated observed node Yi. Factorization (14) then becomes

C∈C

(cid:89)

p(x0:N, y0:N) =

ψi j(xi, x j)

ψi(xi, yi) ,

(15)

(cid:89)

(i, j)∈E

(cid:89)

i

where the ψi j(xi, x j)’s are often referred to as the edge potentials and the ψi(xi, yi)’s are often
referred to as the node potentials. The problem we are interested in is ﬁnding marginals of the
type p(xi, y0:N) for some hidden variable Xi. The basic idea behind belief propagation is to exploit
the factorization properties of the distribution to allow eﬃcient computation of the marginals.
To ﬁx ideas, consider the graph in Figure 4 and suppose we want to compute the conditional
marginal p(x0 | y0:N). A naive application of the deﬁnition, would suggest that p(x0 | y0:N) can
be obtained by summing the joint distribution over all variables except X0 and then normalize

p(x0 | y0:3) ∝

March 15, 2016

p(x, y)dx1dx2dx3 .

(16)

DRAFT

(cid:90)

(cid:90)

(cid:90)

x1

x2

x3

DRAFT

14

Nevertheless notice that the joint distribution can be factored as:

p(x0:3, y0:3) = ψ0(x0)ψ01(x0, x1)ψ1(x1)ψ12(x1, x2)

ψ2(x2)ψ13(x1, x3)ψ3(x3) .

(17)

By plugging in factorization (17) into equation (16) and interchanging the summations and
products order, we obtain

(cid:34)(cid:90)
(cid:90)
p(x0 | y0:3) ∝ ψ0(x0)

(cid:90)
(cid:35)

ψ01(x0, x1)ψ1(x1)

ψ13(x1, x3)ψ3(x3)

x2

ψ12(x1, x2)ψ2(x2)

(18)

x1

x3

(cid:90)

xi

where exponential enumeration has now been converted into a series of enumerations over each
variable separately. This forms the basis for the message–passing algorithm.

Algorithm 1 (Belief propagation): Let Xi and X j be two neighboring nodes in the graph.
We denote by mi j the message that node Xi sends to node X j, by mii the message that Yi sends
to Xi, and by bi the belief at node Xi. The belief propagation algorithm is as follows:

mi j(x j) = α

ψi j(xi, x j)mii(xi)

bi(xi) = α mii(xi)

mki(xi)

mki(xi)

(19a)

(19b)

(cid:89)

xk∈N(xi)\x j

(cid:89)

xk∈N(xi)

where N(Xi) denotes denotes the set of neighbours of node Xi and α is a normalization constant.
For example, if one considers (18), by setting mii(xi) := ψi(xi) and applying deﬁnition (19a) for
the messages, (18) becomes

(cid:40)(cid:90)

(cid:41)
ψ01(x0, x1) [m11(x1) · m21(x1) · m31(x1)]

p(x0| y0:3) = m00(x0)

x1

= m00(x0) · m10(x0)

which is of the form (19b), where the marginal p(x0, y0:3) is computed as the product of incoming
messages in the node X1.

Observed nodes do not receive messages, and they always transmit the same vector. The
normalization of messages in equation (19a) is not theoretically necessary (whether the messages
are normalized or not, the beliefs bi will be identical) but helps improving numerical stability of
the algorithm. Finally, notice that equation (19a) does not specify the order in which the messages

March 15, 2016

DRAFT

DRAFT

15

Fig. 4: An example of graphical model with four unobserved nodes X0, . . . , X4 and four observed
nodes Y0, . . . , Y4.

are updated. In this paper we assume that all nodes simultaneously update their messages in
parallel. This naturally leads to loopy belief propagation, where the update rule (19a) is applied
to graphs that are not a tree.

Remark 6.1: The key idea of the belief propagation algorithm is that the scope of the factors
in (17) is limited. This allows us to “push in” some of the summations, performing them a
subset of variables at a time. For a tree structured graph with variables taking values in a
ﬁnite alphabet X, if we denote with |X| the cardinality of the set X, the computational cost
passes from exponential O(|X|N) in the number of nodes (computational cost of the brute force
marginalization in (16)) to linear O(N|X|2) in the number of nodes (computational cost of the
“principled” marginalization via belief propagation in (18)).

B. Belief propagation for reciprocal chains

If the graph is a reciprocal chain of N + 1 nodes, each node having only two neighbors, the
product over incoming messages from neighboring nodes reduces to a single factor in (19a) and
to two factors in (19b) and we can distinguish two classes of messages, one propagating forward
(clockwise – in the direction of increasing indexes) and one propagating backward (anticlockwise
– in the direction of decreasing indexes) along the chain. The overall algorithm with parallel
scheduling policy is as follows:

Algorithm 2 ((Parallel) belief propagation algorithm for a hidden reciprocal chain):

1)

March 15, 2016

DRAFT

1X0X1X2X3Y0Y1Y2Y3DRAFT

Initialize all messages m(0)
i j
2) Iteratively apply the updates

to some initial value ¯m(0)
i j .

m(t+1)
k−1, k(xk) =

m(t+1)
k+1, k(xk) =

ψk−1,k(xk−1, xk)mk−1,k−1(xk−1)m(t)
xk−1
ψk+1,k(xk+1, xk)mk+1,k+1(xk+1)m(t)
xk+1

k−2,k−1(xk−1)

k+2,k+1(xk+1) .

3) for each Xi ∈ V compute the marginals

(cid:90)
(cid:90)

(cid:104)

(cid:105)

bk(xk) = α mkk(xk)

k−1,k(xk) · m(tmax)
m(tmax)

k+1,k(xk)

16

(20a)

(20b)

(21)

For tree-structured graphs, when tmax is larger than the diameter of the tree (the length of longest
shortest path between any two vertices of the graph), the algorithm converges to the correct
marginal. Convergence of the iteration for a hidden reciprocal chain (whose graph is not a tree)
will be discussed in Section IX. The argument we will use in Section IX to prove convergence
of the belief propagation algorithm is based on contraction properties of the Hilbert metric, that
we are now going to introduce.

VII. Hilbert metric

The Hilbert metric was introduced in [16] and is deﬁned as follows. Let B be a real Banach
space and let K be a closed solid cone in B that is a closed subset K with the properties that
(i) K + is non–empty; (ii) K + K ⊆ K; (iii) K ∩ −K = {0}; (iv) λK ⊂ K for all λ ≥ 0. Deﬁne
the partial order

x (cid:22) y ⇔ y − x ∈ K ,

and for x, y ∈ K\{0}, let

M(x, y) := inf {λ|x − λy (cid:22) 0}
m(x, y) := sup{λ|x − λy (cid:23) 0}

(cid:33)
The Hilbert metric dH(·,·) induced by K is deﬁned by

(cid:32) M(x, y)

dH (x, y) := log

, x, y ∈ K\{0} .

m(x, y)

For example, if B = Rn and the cone K is the positive orthant, K = O := {(x1, . . . , xn) : xi ≥ 0, 1 ≤ i ≤ n},
then M(x, y) = maxi(xi/y j) and m(x, y) = mini(xi/yi) and the Hilbert metric can be expressed as

dH(x, y) = log

maxi(xi/yi)
mini (xi/yi)

March 15, 2016

DRAFT

(22)

DRAFT

17

On the other hand, if B = S := (cid:8)X = X(cid:62) ∈ Rn×n(cid:9) is the set of symmetric matrices and K =
(cid:16)
XY−1(cid:17)

P := {X (cid:23) 0 | X ∈ S} is the cone of positive semideﬁnite matrices, then for X, Y (cid:31) 0, M(X, Y) =
λmax

. Hence the Hilbert metric is

(cid:16)
XY−1(cid:17)

and m(X, Y) = λmin

(cid:16)
XY−1(cid:17)
(cid:0)XY−1(cid:1)

λmax

λmin

dH(X, Y) = log

The Hilbert metric is a projective metric on K i.e. it is nonnegative, symmetric, it satisﬁes
the triangle inequality and is such that, for every x, y ∈ K, dH(x, y) = 0 if and only if x = λy for
some λ > 0. It follows easily that dH(x, y) is constant on rays, that is

dH (λx, µy) = dH (x, y)

for λ, µ > 0 .

(23)

VIII. Positive systems

A linear time invariant system xk+1 = Axk over the positive orthant O is positive if the mapping
A takes O into itself. Positive systems have a long history in the literature, both because of the
relevance of the property for applications (the positivity constraint arises quite naturally when
modeling real systems whose state variables represent quantities that are intrinsically nonnegative,
such as pressures, concentrations, population levels, etc) and because the property signiﬁcantly
restricts the behavior, as established by Perron–Frobenius theory: if the cone invariance is strict,
that is, if the boundary of the cone is eventually mapped to the interior of the cone, then the
asymptotic behavior of the system lies on a one dimensional object. In this Section, we brieﬂy
review contraction properties of positive operators as derived by Birkhoﬀ [4] (see also [6]) and
then show how they can be used to prove existence of a ﬁxed point for a linear time invariant
positive dynamical system which is also a global attractor.

A. Contraction of the Hilbert metric

Let (X, d) be a metric space. We recall that a mapping f : X → X is called a contraction with

respect to d if there exists 0 ≤ K < 1 such that

d( f (x), f (y)) ≤ Kd(x, y),

for all x, y ∈ X .

A map A from B to B is said to be non-negative if it takes K into itself, i.e.

A : K\{0} → K\{0} ,

March 15, 2016

(24)

DRAFT

DRAFT

and positive if it takes the interior of K into itself, i.e.
A : K + → K + .

For a strictly positive linear map deﬁne its contraction ratio

k(A) := inf(cid:8)λ : d(Ax, Ay) ≤ λd(x, y) ∀x, y,∈ K +(cid:9)

and projective diameter

∆(A) := sup(cid:8)d(Ax, Ay) : x, y,∈ K +(cid:9) .

18

(25)

(26)

It is easy to show that a positive map does not expand the Hilbert metric [20]. In [4] (see also
[6]), Birkhoﬀ showed that positivity of a mapping implies contraction in the Hilbert metric, a
result that paved the way to many contraction–based results in the literature of positive operators.
The formal statement is as follows.

Theorem 8.1: If x, y ∈ K, then the following holds
(i) if A is a non–negative linear map on K, then dH(Ax, Ay) ≤ dH(x, y), i.e. the Hilbert metric

contracts weakly under the action of a non–negative linear transformation.

(ii) [Birkhoﬀ, 1957] If A is a positive linear map in B, then

k(A) = tanh

1
4

∆(A) .

(27)

In other words, if the diameter ∆(A) is ﬁnite, then positivity of a mapping implies strict
contraction of the Hilbert metric.

B. Perron–Frobenius vector

As mentioned above, positivity signiﬁcantly restricts the behavior of a linear time invariant
system as established by Perron–Frobenius theory. Exploiting contraction properties of positive
maps, in [4] (see also [6]) Birkhoﬀ provided an alternative proof of the the Perron–Frobenius
theorem as a special case of the Banach ﬁxed-point theorem. With respect to others ﬁxed-
point arguments used to prove the Perron-Frobenius theorem (see e.g. [13]), this proof has
the advantage that not only it yields to the existence of a positive eigenvector x f , but also to
convergence to this same eigenvector (for the latter, in the approach in [13], one still needs
to show how positivity implies that the eigenvalue associated with x f dominates all the other
eigenvalues). Along the same lines, we exploit contraction properties of positive maps with

March 15, 2016

DRAFT

DRAFT

19

respect to the Hilbert metric to prove existence of a ﬁxed point of the projective space for a
linear time invariant positive dynamical system which is global attractor for the system.

Theorem 8.2: Consider the dynamical system xk+1 = Axk with A a D × D matrix with non–

negative entries and suppose that A is such that there exists an integer h such that

[Ah]r,s > 0, ∀ r, s ∈ {1, 2, . . . , N} .

Then there exists a unique positive eigenvector x f ∈ O+ such that for all non–negative x0 ∈ O\{0},
An x0 converges in direction to x f , i.e.

dH(An x0, x f ) → 0

as n → ∞

and the rate of convergence is at least linear (i.e. the error decreases exponentially).
To prove Theorem 8.2 we need the two following lemmas.

Lemma 8.1: [6, Theorem 4.1] Consider the cone K = O := {(x1, . . . , xn) : xi ≥ 0, 1 ≤ i ≤ n}
(positive orthant) and let U denote the unit sphere in B = RD. Then the metric space E :=
{K + ∩ U, dH} is complete.

Lemma 8.2: [4] Let A = (ai j) be a D× D matrix with ai j > 0, for all i, j. Then A is a positive

map with ﬁnite projective diameter given by
ai japq
aiqap j

∆(A) = max

log

(cid:40)

(cid:41)

: 1 ≤ i, j, p, q ≤ D

< ∞ .

Proof of Theorem 8.2: Ah is a positive linear mapping in the interior of the positive orthant
O+ in RD with ﬁnite projective diameter (see Lemma 8.2). Then F(x) := Ahx(cid:107)Ahx(cid:107) is a map from
E := {O+ ∩ U, dH} into E and is the composition of a strict contraction (see Theorem 8.1(ii)) and
a normalizing isometry (see (23)). Since the metric space E is complete (Lemma 8.1), then, by
the Banach ﬁxed-point theorem, there exists a unique ﬁxed point ¯x f in E such that F
= ¯x f ,
i.e. ¯x f is a strictly positive eigenvector of Ah (and of A), associated to a positive eigenvalue,
that, starting from an arbitrary ¯x0 ∈ E (indeed for every (¯x0 ∈ O ∩ U)) can be computed as the
limit of the sequence ¯xk = F(¯xk−1) so that for every  > 0, there exists a natural number ¯k such
= dH(Ckh ¯x0, ¯x f ) = dH(Ckhx0, x f ) <  for all
that dH(¯xk, ¯x f ) = dH(Fk(¯x0), ¯x f ) = dH
k > ¯k. That the rate of convergence is at least linear follows by the fact that An is a contractive
map. QED.

Ckh ¯x0
(cid:107)Ckh ¯x0(cid:107) , ¯x f

(cid:18)

(cid:19)

(cid:17)

(cid:16)

¯x f

March 15, 2016

DRAFT

DRAFT

20

IX. Convergence of Loopy Belief Propagation for Reciprocal Processes

When the graph is singly connected, local propagation rules are guaranteed to converge to the
correct posterior probabilities [21]. For general graphs with loops, theoretical understanding of
the performance of local propagation schemes is the subject of ongoing research. Convergence
of loopy belief propagation for networks with a single loop has been studied in [31] where it
has been shows that, for latent variables taking values in a ﬁnite alphabet the estimated beliefs
converge (although the computed marginals will be incorrect). Correction formulas that give the
actual posteriors starting from the estimated beliefs have also been provided. In this section,
we revisit convergence analysis in [31] by providing a contraction–based argument that leverage
on contraction properties of positive operators with respect to the Hilbert metric that has been
introduced in Sections VII and VIII. The Section is organized as follows. Similarly to [31], we
ﬁrst rewrite iteration (20a), (20b) for a reciprocal chain with ﬁnite state space and show that
convergence analysis of belief propagation for a single loop network essentially boils down to the
analysis of asymptotic stability of a linear positive time–invariant dynamical system. Convergence
of the updates is then derived as a consequence of contraction properties of positive operators
that has been introduced in Section VIII.

A. Belief propagation and positive systems

In case of ﬁnite state space, the belief propagation algorithm can be written in matrix notation
as follows. If one denotes with Mi j the transition matrix associated with the edge potential
ψi j(xi, x j) relative to the message from Xi to X j and by mi j (resp., mii) the vector messages
obtained by staking the mi j(xi)’s (resp., the mii(xi)’s) for each value of Xi ∈ X = {0, . . . , D},
namely



mi j(0)

...

mi j(D)

 ,



ψi(0)

...

ψi(D)

 ,

terms of the form(cid:80)

we denote

mi j =

mii =

xi ψi j(xi, x j)mki(xi) can be expressed in matrix notation as Mi jmki. Moreover



bi(0)

...

bi(D)

 ,

bi :=

March 15, 2016

DRAFT

DRAFT

21

and indicate by (cid:12) the Hadamard (entrywise) product between two vectors of the same size. The
message updates for a reciprocal chain (20a)–(20b) can be expressed in matrix notation as

m(t+1)
k−1,k
m(t+1)
k+1,k

= α Mk−1,k

= α Mk+1,k

(cid:16)
(cid:16)
mk−1,k−1 (cid:12) m(t)
mk+1,k+1 (cid:12) m(t)

k−2,k−1

k+2,k+1

(cid:17)
(cid:17)

(cid:16)
mkk (cid:12) m(tmax)

k−1,k (cid:12) m(tmax)

k+1,k

(cid:17)

and the beliefs (30) as

bk = α

Note that if Mi j is the transition matrix associated with the message from Xi to X j, then the
transition matrix associated to the message from X j to Xi (same link but opposite direction), is
given by M ji = M(cid:62)
i j.

Now consider the reciprocal chain in Figure 3. Without loss of generality, consider the belief

at node X0 at a certain time t + N + 1

= α m00 (cid:12)(cid:16)

b(t+N+1)
0

(cid:17)

m(t+N+1)

N0

(cid:12) m(t+N+1)

10

(cid:16)
mNN (cid:12) m(t+N)
N−1,N

(cid:17)

m(t+N+1)

N0

= αMN0

By the belief update equation (28), the message that XN sends to X0 at time t + N + 1 depends
on the message that XN received from XN−1 at time t + N

(28)

(29)

(30)

(31)

(32)

(33)

(35)

DRAFT

Similarly, the message that XN−1 sends to XN at time t + N depends on the message that XN−1
received from XN−2 at time t + N − 1

(cid:16)
mN−1,N−1 (cid:12) m(t+N−1)
N−2,N−1

(cid:17)

m(t+N)
N−1,N

= αMN−1,N

and so on. One can continue expressing each message in terms of the one received from the
neighbor until we go back in the loop to X0: the message that X0 sends to X1 is a function of
the message that XN sent to X0

(cid:16)

(cid:17)

m(t+1)

01

= αM0,1

m00 (cid:12) m(t)

N0

.

(34)

By putting together (32)–(34), one gets that the message that XN sends to X0 at a given time
step depends on the message that XN sent to X0 N time steps ago. In particular, if we denote
by CN0 the matrix

CN0 = MN0DNMN−1,NDN−1 · ··· · M01D0

March 15, 2016

DRAFT

22

where the Di’s are the diagonal matrices whose diagonal elements are the entries of the constant
messages mii, the message that XN sends to X0 satisfy the recursion

m(t+N+1)

N0

= αCN0m(t)
N0 .

(36)

In a similar way, we can express the message that X1 sends to X0 at a given time step as a
function of the message that X1 sent to X0 N + 1 time steps ago

m(t+N+1)

10

= αC10m(t)
10 ,

where the matrix C1,0 is given by

C10 = M10D1M21D2 · ··· · M0ND0 .

(37)

(38)

B. Contraction–based Convergence Analysis

(cid:16)

(cid:17)

b(t+kN+1)
0

From (31) we have that

k∈N converges if the sequences

k∈N
in (36) and (37) converge. Now recall that the ψi j’s and ψi’s are nonnegative valued functions. It
follows that the entries of CN,0 and C1,0 are nonnegative. The following theorem is an immediate
consequence of Theorem 8.2 in Section VIII and establishes convergence of belief propagation as
a consequence of contraction of the Hilbert metric under the action of a positive linear operator.

k∈N,

m(t+kN+1)

N0

m(t+kN+1)

10

(cid:16)

(cid:17)

(cid:16)

(cid:17)

Theorem 9.1: Consider the hidden reciprocal chain in Figure 3 with unobserved variables Xi
taking values in X = {0, 1, . . . , D} and denote by v f and w f the principal eigenvector of CN0 and
C10, respectively. Then the messages mN0 and m10 in (36), (37) converge in direction to v f and
w f , respectively and the steady state belief at node X0 converges to b0 = m00 · v f · w f . The rate
of convergence is at least linear.

Finally, recall that conditions for asymptotic stability of the positive linear discrete-time
systems have been provided in the literature [26], [14], [2]. In particular, the necessary and
suﬃcient condition that the spectrum of the system matrix is contained in the open unitary disk of
Cn, still holds for a positive system. On the other hand, many necessary and suﬃcient conditions
for asymptotic stability (e.g. the Jury criterion) become simpler in the case of positive systems.
Even the Lyapunov theorem takes a simpler form for positive systems and one can restrict to
consider “pure” quadratic functions, namely quadratic functions not containing the mixed terms
of the form xix j with i (cid:44) j. Relevant necessary and suﬃcient conditions for asymptotic stability

March 15, 2016

DRAFT

DRAFT

23

of linear positive systems are summarized in the following theorem (see [2], [14, Chapter 5] for
details).

Theorem 9.2: [14] Consider the linear positive dynamical system xk+1 = Axk and denote by

Λ(A) be the spectrum of A. The following are equivalent:

• |Λ(A)| < 1;
• all the leading principal minors of the matrix I − A are positive;
• the coeﬃcients of the characteristic polynomial of A − I are positive;
• there exists a diagonal matrix P with positive diagonal elements such that the matrix A(cid:62)PA−
P is negative deﬁnite.

(cid:16)

(cid:17)

C. Accuracy of the approximation

So far, we have been dealing with convergence of the sequence of the beliefs

k∈N.
In [31], the following result about accuracy of the estimated marginals and on how they can be
corrected using locally available information is provided.

b(t+kN+1)
0

Theorem 9.3: [31, Claims p.12 and p. 17] Consider the reciprocal chain in Figure 3. Then
(i) The steady-state beliefs bi, i = 0, . . . , N are related to the correct posterior marginal pi by:

bi = βpi + (1 − β)qi

(39)

where, by reading the subscripts modulo N + 1,

• β is the ratio of the largest eigenvalue of Ci−1,i to the sum of all eigenvalues, and in

particular, if we denote by λi the eigenvalues of Ci−1,i it is

j λ j

β =

λ1(cid:80)
(cid:80)D
(cid:80)D
j=2 S(k, j)λ jS−1( j, k)

j=2 S(k, j)λ j

[qi]k =

• qi depends on the eigenvectors of Ci−1,i, and in particular if Ci+1,i = SΛS−1 then

(ii) Let X = {0, 1} (i.e. consider binary latent variables) and let λ1 > λ2 be the eigenvalues of
Ci−1,i. Then the correct posterior at node Xi, pi, can be obtained from the estimated belief
bi as

pi = 1
1 + r

bi +

r

1 + r

(1 − bi) ,

where r := λ2/λ1.

March 15, 2016

(40)

DRAFT

DRAFT

24

Remark 9.1: Note the fundamental role played by the ratio λ1/λ2: When this ratio is small,
loopy belief propagation converges rapidly and the approximation error is small. Indeed from
(39) we have

pi − bi = (1 − β) (qi + pi) ,

i.e. the error is small when the maximum eigenvalue dominates the eigenvalue spectrum.

X. Conclusions

In this paper, we have provided probabilistic graphical models for reciprocal processes. While
in the literature a signiﬁcant amount of attention has been focused on developing dynamical
models for reciprocal processes, probabilistic graphical models for reciprocal processes seems
not to have been considered before. This has led to a principled solution of the smoothing
problem via message passing algorithms for graphical models. For the ﬁnite state space case,
convergence analysis has been revisited via the Hilbert metric, an approach that seems suitable
for extensions to the study of convergence analysis of message passing algorithms to more
general settings (state–spaces and graph topologies).

References

[1] R. Ackner and T. Kailath. Discrete-time complementary models and smoothing.

International Journal of Control,

49(5):1665–1682, 1989.

[2] A. Berman and R. J. Plemmons. Nonnegative matrices in the Mathematical Sciences. SIAM Press, Philadelphia, 1994.
[3] S Bernstein. Sur les liaisons entre les grandeurs al´eatoires. Verh. Internat. Math.-Kongr., Zurich, pages 288–309, 1932.
[4] G. Birkhoﬀ. Extensions of Jentzch’s Theorem. Trans. Amer. Math. Soc., 85:219–227, 1957.
[5] C. Bishop. Pattern recognition and machine learning. Springer, 2006.
[6] P.J. Bushell. Hilbert’s metric and positive contraction mappings in a Banach space. Archive for Rational Mechanics and

Analysis, 52(4):330–338, 1973.

[7] F. P. Carli, A. Ferrante, M. Pavon, and G. Picci. A maximum entropy solution of the covariance extension problem for

reciprocal processes. IEEE Trans. on Automatic Control, 56(9):1999–2012, 2011.

[8] F. P. Carli, A. Ferrante, M. Pavon, and G. Picci. An eﬃcient algorithm for maximum entropy extension of block-circulant

covariance matrices. Linear Algebra and its Applications, 439(8):2309–2329, 2013.

[9] J-P. Carmichael, J-C. Mass´e, and R. Theodorescu. Processus gaussiens stationnaires r´eciproques sur un intervalle. CR

Acad. Sci. Paris S´er. I Math, 295(3):291–293, 1982.

[10] F. Carravetta. Nearest-neighbor modelling of reciprocal chains. Stochastics: An International Journal of Probability and

Stochastics Processes, 80(6):525–584, 2008.

[11] F. Carravetta and L. B. White. Modelling and estimation for ﬁnite state reciprocal processes.

IEEE Transactions on

Automatic Control, 57(9):2190–2202, 2012.

March 15, 2016

DRAFT

DRAFT

25

[12] D. A. Casta˜non, B.C. Levy, and A.S. Willsky. Algorithms for the incorporation of predictive information in surveillance

theory? International journal of systems science, 16(3):367–382, 1985.

[13] G. Debreu and I.N. Herstein. Nonnegative square matrices. Econometrica, pages 597–607, 1953.
[14] L. Farina and S. Rinaldi. Positive linear systems: theory and applications, volume 50. John Wiley & Sons, 2000.
[15] M. Golumbic. Algorithmic Graph Theory and Perfect Graphs. Academic Press, New York, 1980.
[16] D. Hilbert. ¨Uber die gerade linie als k¨urzeste verbindung zweier punkte. Mathematische Annalen, 46(1):91–96, 1895.
[17] B. Jamison. Reciprocal Processes: The stationary Gaussian case. The Annals of Mathematical Statistics, 41:1624–1630,

1970.

[18] B. Jamison. Reciprocal processes. Probability Theory and Related Fields, 30(1):65–86, 1974.
[19] B. Jamison. The Markov processes of Schroedinger. Probability Theory and Related Fields, 32(4):323–331, 1975.
[20] E. Kohlberg and J.W. Pratt. The contraction mapping approach to the Perron–Frobenius theory: Why Hilbert’s metric?

Mathematics of Operations Research, 7(2):198–210, 1982.

[21] D. Koller and N. Friedman. Probabilistic graphical models: principles and techniques. MIT press, 2009.
[22] A. J. Krener, R. Frezza, and B. C. Levy. Gaussian reciprocal processes and self-adjoint stochastic diﬀerential equations

of second order. Stochastics and stochastic reports, 34(1-2):29–56, 1991.

[23] A.J. Krener. Reciprocal diﬀusions and stochastic diﬀerential equations of second order. Stochastics, 24(4):393–422, 1988.
[24] S.L. Lauritzen. Graphical models. Oxford Univ. Press, 1996.
[25] B.C. Levy, R. Frezza, and A.J. Krener. Modeling and estimation of discrete-time gaussian reciprocal processes. IEEE

Transactions on Automatic Control, 35(9):1013–1023, 1990.

[26] David Luenberger. Introduction to dynamic systems: theory, models, and applications. Wiley, 1979.
[27] J. Pearl. Probabilistic reasoning in intelligent systems: Networks of plausible reasoning, 1988.
[28] J. Pearl and A. Paz. Graphoids: A graph-based logic for reasoning about relevance relations. Technical report, University

of California (Los Angeles), 1985.

[29] G. Picci and F. Carli. Modelling and simulation of images by reciprocal processes. In Computer Modeling and Simulation,

2008. UKSIM 2008. Tenth International Conference on, pages 513–518, 2008.

[30] L. Srinivasan, U.T. Eden, A.S. Willsky, and E.N. Brown. A state-space analysis for reconstruction of goal-directed

movements using neural signals. Neural computation, 18(10):2465–2494, 2006.

[31] Y. Weiss. Correctness of local probability propagation in graphical models with loops. Neural computation, 12(1):1–41,

2000.

[32] Y. Weiss and W.T. Freeman. Correctness of belief propagation in gaussian graphical models of arbitrary topology. Neural

computation, 13(10):2173–2200, 2001.

[33] L.B. White and F. Carravetta. Optimal smoothing for ﬁnite state hidden reciprocal processes.

IEEE Transactions on

Automatic Control, 56(9):2156–2161, 2011.

March 15, 2016

DRAFT

