6
1
0
2

 
r
a

 

M
1
2

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
5
1
4
6
0

.

3
0
6
1
:
v
i
X
r
a

Technical Report 12:02

Statistics Group, School of Mathematics

University of Bristol, UK

Simulation Study Comparing Two Tests of Second-order

Stationarity and Conﬁdence Intervals for Localized

Autocovariance

G. P. Nason

July 4th 2012

Abstract

This report compares two tests of second-order stationarity through simulation. It also pro-
vides several examples of localised autocovariances and their approximate conﬁdence intervals
on different real and simulated data sets. An empirical veriﬁcation of an asymptotic Gaussianity
result is also demonstrated. The commands use to produce ﬁgures in a companion paper are also
described.

1 Introduction

This report is a companion to the article Nason (2013).

This technical report contains two sets of simulation studies. The ﬁrst set concerns the perfor-
mance of two different tests of second-order stationarity described in Section 2. The second set
examines conﬁdence intervals for a particular form of localized autocovariance in Section 3 and also
provides an empirical justiﬁcation of approximate normality of a statistic deﬁned in the companion
paper. Finally, Section 4 provides R commands for the locits package (which implements the new
ideas in the companion paper) showing how the ﬁgures were produced in the companion paper.

In the following we refer to the Priestley-Subba Rao (1969) test as PSR and the test introduced in

the companion paper, the Haar wavelet on wavelet spectrum test, as HWTOS.

Further explanation appears in the sections below, however the main conclusions of this report

concerning the tests are:

1. the HWTOS tends to be more conservative than PSR, but not always;

2. for light-tailed noise the HWTOS’s empirical size tends to be less than its nominal size, whereas

the PSR tests tend to be slightly above;

3. for heavy-tailed data the PSR test does not perform well, giving many false positives by re-
jecting the null hypothesis erroneously about 60% of the time for all models we tried. By
comparison the HWTOS tests have much better empirical size values, although greater than
their nominal size.

1

4. The PSR test has problems (empirical size of about 12%) for an AR(1) process with AR pa-
rameter of 0.9. Similarly, the HWTOS tests have problems (empirical size of about 20%) for an
AR(1) process with parameter −0.9.

5. Sometimes PSR is much more powerful than HWTOS and vice versa, sometimes both tests do
not have much power to detect particular nonstationary alternatives and sometimes both have
excellent power. As expected power depends on the alternative and the sample size.

2 Tests of Stationarity

The two tests are the Priestley-Subba Rao test of stationarity implemented by the stationarity
function in the fractal package in R and (ii) the test of stationarity obtained by examining the
Haar wavelet coefﬁcients of an evolutionary wavelet spectrum estimate modelled by locally stationary
wavelet processes, implemented in the hwtos2 function and introduced by the companion paper. We
augment the HWTOS test with two forms of multiple comparison control: FDR and Bonferonni and,
as such, refer to two tests.
For both cases we are concerned with a given time series xt for t = 1, . . . , T which is a realisation
from a stochastic process {Xt}t∈Z. The null hypothesis that we wish to test concerning Xt is H0 : the
process is stationary versus HA : it is not!

2.1 Evaluation of statistical size
In this section we provide simulation evidence of the empirical statistical size of the various station-
arity tests. Recall that the size of a hypothesis test is γ = P(Reject H0|H0). To empirically evaluate
this we ﬁrst set a nominal size in our test procedure γ = 0.05. (Note that α is often used as the symbol
for size but here we used γ and α is reserved for the parameter of an AR(1) model.) Then we run
the testing procedure on N realisations from a known stationary model and count how many times
the test rejects the null hypothesis, R. The empirical size of the test is then given by R/N. A test is
conservative if R/N < γ and conservative tests are generally thought of as desirable and not given to
reporting false positives.

The various stationary models that we have considered are:

S1 iid standard normal;
S2 AR(1) model with AR parameter of 0.9 with standard normal innovations;
S3 As S2 but with AR parameter of −0.9;
S4 MA(1) model with parameter of 0.8;
S5 As S4 but with parameter of −0.8.
S6 ARMA(1, 0, 2) with AR parameter of -0.4, and MA parameters of (−0.8, 0.4).
S7 AR(2) with AR parameters of α1 = 1.385929 and α2 − 0.9604. The roots associated with the
auxiliary equation, (see Chatﬁeld, The Analysis of Time Series, book) are β1 = ¯β2 = 0.98eiπ/4.
This process is stationary, but close to the ‘unit root’: a ‘rough’ stochastic process with spectral
peak near π/4.

The empirical size values are given in Table 1, these are all computed over N = 1000 realisations

with a sample size of T = 512 for the realization.

2

Table 1: Empirical size estimates (%) for stationary models with nominal size of 5%

Model PSR HWTOS (Bon) HWTOS (FDR)
4.3
4.7
20.5
3.8
0.7
0.1
7.4

5.6
12.4
6.2
6.0
6.5
7.5
23.9

S1
S2
S3
S4
S5
S6
S7

4.3
4.0
20.3
3.4
0.7
0.1
7.3

2.2 Further investigation of S3
In the previous section the empirical size values from the S3 model were about 20% for the Haar
wavelet based test of stationarity, even the Priestley-Subba Rao test has a estimated power at 6.2%,
a full 1.1% above the nominal. What is going on? Figure 1 shows a realisation from the AR(1)
process with parameter of α = −0.9 and this indicates what might be happening. The realisation in
Figure 1 clearly shows a kind of ‘volatility clustering’, which is reminiscent with what can happen
with GARCH processes although, in this case, unlike GARCH, the regular autocorrelation is non-zero.
The Haar wavelet test appears to be reading the volatility clustering as non-stationarity. However, one
might well ask what a human would say if confronted with just Figure 1 the local variance appears
to be changing quite markedly and so we would submit that there is a strong chance that a human
observer might regard the series at non-stationary or at least be suspicious.

Another thing to note is that about 17% of the occasions that the series was deemed non-stationary
(out of the 20%) only one Haar wavelet coefﬁcient out the 186 tested simultaneously each time was
assessed to be signiﬁcantly different from zero. So, in roughly 17% of cases one would probably
practically say that the series is, in fact, very close to stationarity as a more markedly non-stationary
series would result in many more Haar coefﬁcients to be assessed as signiﬁcant. Note, that for this
AR process only 3% had two signiﬁcant coefﬁcients and only 0.2% had three signiﬁcant coefﬁcients
and there were never more than three. Hence, the empirical size values are a bit of blunt instrument.
In practice, we believe users will be more interested in the numbers of signiﬁcant Haar coefﬁcients,
where they are and maybe not pay too much attention to situations where very few coefﬁcients are
signiﬁcant. This remains to be seen.
If α = −0.8 in an AR(1) model then the estimated size values are 5.0% for PSR, 3.7% for
HWTOS(Bon) and 3.9% for HWTOS(FDR), so for this less extreme value of the AR parameter the
HWTOS again becomes more conservative than PSR and we have the desirable characteristic of em-
pirical size smaller than nominal size.
If α = −0.99 then the estimated size values are 7.3% for PSR and about 80% for the Haar wavelet
tests. So, the empirical size for this extreme case for the Haar wavelet test is not good, but on further
examination the largest number of signiﬁcant Haar coefﬁcients out the 186 tested each time is never
more than 4. Indeed, about 34% involve one signiﬁcant coefﬁcient, 33% involve two, 12% involve
three and only about 0.3% involve four. So, pragmatically, even for the extreme AR case the Haar test
indicates that the series is very close to stationarity.

3

Figure 1: Realization of stationary AR(1) process with AR parameter of -0.9

4

TimeX: AR(1) alpha=−0.90100200300400500−6−4−20246Table 2: Simulated size estimates (%) for stationary exponential-tailed models with nominal size of
5%

7.3
5.8
20.5
7.1
15
11
10.6

Model PSR HWTOS (Bon) HWTOS (FDR)
7.9
SHD1
SHD2
7.0
20.8
SHD3
7.8
SHD4
19
SHD5
SHD6
12
11.4
SHD7

43.8
48.9
40.6
44.5
46.8
45.1
57.6

Table 3: Simulated size estimates (%) for stationary t-distribution models with nominal size of 5%

Model PSR HWTOS (Bon) HWTOS (FDR)
16.7
SHT1
11.3
SHT2
SHT3
28.7
18.0
SHT4
8.1
SHT5
6.8
SHT6
SHT7
15.4

60.3
64.9
63.9
62.7
63.0
63.0
69.0

15.1
9.8
28.3
15.8
7.1
6.6
14.1

2.3 Empirical size results for heavy tailed data
We still would like our test to perform well with heavy-tailed data and for it still to assess station-
arity accurately. Data with heavy tails tends to cause the number of false positives to increase (i.e.
detect non-stationarity when the series is, in fact, stationary). Hence, we repeat our empirical size
analysis, but this time replace all the normal variates and/or innovations by samples from the (a)
double-exponential distribution and (b) Student’s-t distribution on four degrees of freedom. (This can
be achieved in arima.sim in R through its rand.gen argument). We denote the new models by
SHD1–SHD7 and SHT1–SHT7 respectively which are the same as S1–S7 but with heavy-tailed in-
novations. Note that the SHD models fall into the class of processes that adhere to the distributional
constraints indicated in the companion paper (Assumption 3), but the SHT do not (and hence the latter
are an extreme test of the methods).

The results in Table 3 are interesting: both the HWTOS and PSR test’s empirical size is greater
than the nominal size of 5%. However, the PSR is much less robust than the HWTOS options. One
could not recommend PSR for heavy-tailed observations, whereas HWTOS is a more realistic propo-
sition (because if even if the series was stationary PSR will falsely reject the null hypothesis approxi-
mately 60% of the time).

2.4 Power Simulations
To explore statistical power we need to create nonstationary processes and then count the number of
times each test decides a realisation is not stationary over multiple realisations. The models we choose
are:

P1 Time-varying AR model Xt = αtXt−1 + t with iid standard normal innovations and the AR

5

Table 4: Empirical power estimates (%) for models P1–P4 with nominal size of 5%

Model PSR HWTOS (Bon) HWTOS (FDR)
99.9
19.2
1.3
97.8

37.2
100
44.3
100

99.7
17.3
1.3
94.8

P1
P2
P3
P4

parameter evolving linearly from 0.9 to -0.9 over the 512 observations.

1

4 − (z − 1

P2 A LSW process based on Haar wavelets with spectrum Sj(z) = 0 for j > 1 and S1(z) =
2 )2 for z ∈ (0, 1). This process is, of course, a time-varying moving average process.
P3 A LSW process based on Haar wavelets with spectrum Sj(z) = 0 for j > 2 and S1(z) as for P2
2 ) using periodic boundaries (for the construction of the spectrum only).
P4 A LSW process based on Haar wavelets with spectrum Sj(z) = 0 for j = 2, j > 4 and S1(z) =
4 ) again assuming periodic boundaries.

2 )2}, S3(z) = S1(z− 1

4 ), S4(z) = S1(z + 1

and S2(z) = S1(z + 1

exp{−4(z− 1

The parameter proﬁle for P1 and the spectra are associated with P2-P4 are plotted in Figure 2. A
realisation from each of P1–P4 is shown in Figure 3.

Empirical power values for the PSR and Haar wavelet test can be found in Table 4. Once again,
these are computed over N = 1000 realisations and the nominal size of the test was 5%. The simula-
tion results for power paint an interesting picture. Sometimes the HWTOS tests are good and the PSR
is not (P1), sometimes PSR is good and HWTOS is not (P2), sometimes both are not that good (P3)
and sometimes both are very good (P4).

Sample size is an important determining factor in power: increasing sample size should increase
power of detection of alternatives. For example, with P2 which has a sample size of T = 512 the
HWTOS tests have fairly low powers of 17.3%/19.2% respectively. For T = 1024 the tests are more
powerful having powers of 70.7%/75.2% and for T = 2048 the empirical powers are both 100%.

3 Localized Autocovariance
3.1 Examples of Localized Autocovariance and CI computation
In this section we show some examples of the localised autocovariance and 95% conﬁdence intervals.
We start with four models and draw one realisation of length T = 512 from each. The four models
are:

AC1 IID standard normal random variables (stationary).

AC2 Stationary AR(1) process with AR parameter of 0.8.

AC3 Time-varying AR(1) process with AR parameter ranging from 0.9 to -0.9 (same model as P1,

above).

AC4 Time-varying MA(1) process with MA parameter ranging from 1 to -1 over length of the series:

Xt = Zt + βtZt−1.

6

Figure 2: a. AR(1) parameter as it varies over time for model P1. b.– d. evolutionary wavelet spectra
underlying processes P2, P3 and P4 respectively.

7

0.00.20.40.60.81.0−0.50.00.5a.TimeAR(1) parameterb.TimeScale1357900.20.40.60.81c.TimeScale1357900.20.40.60.81d.TimeScale1357900.20.40.60.81Figure 3: a.–d. A single realisation from each of P1 thru P4 respectively.

8

a.Timex10100200300400500−4−202b.Timex20100200300400500−2−1012c.Timex30100200300400500−3−10123d.Timex40100200300400500−2−1012All innovations are standard normal.

We then compute the localized autocovariance estimate ˆc(z, τ ) for z = 100/512, 200/512,
300/512, 400/512 in rescaled time. Hence, for each model we display a Figure with four localised
autocovariance estimates: these are in Figures 4, 5, 6 and 7.

Broadly speaking, Figure 4 shows the correct kind of autocovariance plot for each local time point
in that it is very near to one at lag zero, and very near zero for all other lags. The actual ˆc(z, 0) value is
very close to 1 in plots b.–d. a bit further in plot a. but all of the 95% CI cover 1. The acfs at the other
lags for the other time points are all very close to zero: the lag 1 CI always covers zero. However, it
should be said that for a few of the acfs at some lags (notably plot a.) are very small, but their CIs do
not cover zero.

Each of the plots in Figure 5 look pretty reasonable to each arise from an AR(1) model.
Figure 6 shows localised acf plots for a time-varying AR(1) model where the AR parameter
varies smoothly from 0.9 to -0.9 over the period of the series. In each of the autocovariance plots the
horizontal dashed line shows the value of the AR parameter at the particular time point. So, for plot a.
in Figure 6 the true value of the AR parameter is approximately 0.551 and the estimated ˆc(100/512, 1)
is very close to that value and is easily covered by the associated CI. Plots b. and c. show similar
things (albeit with different AR parameters). In plot d. the true value of the parameter is about -0.505,
but the estimate is nearly -1.0 and the CI does not cover the true value.

Figure 7 shows localised acf plots for a time-varying MA(1) model where the MA parameter
varies from 1 to -1 over the length of the series. The horizontal lines show the value of the true lag 0
(variance) and lag 1 acfs, which are also changing over the length of the series. The CIs all cover the
true values (at lags 0 and 1) apart from plot a. where the estimate underestimates the truth. Nearly all
of the other lags look good (estimated near zero, and a CI which covers zero) apart from, again, plot
a. where lags 7,8 and 9 appear to be signiﬁcantly different from zero, but note, still very small.

3.2 Asymptotic normality check
This section describes the results of simulations designed to check the asymptotic normality assump-
tion for the ˆc(z, τ ) quantity. To do this we used models AC2 and AC3 and simulated the value of
ˆc(z, τ ) N = 1000 times evaluated at z = 200/512 for different values of T = 512, 1024, 2048 and
T = 4096.

Figures 8 to 11 show density estimates for the ˆc(200/512, τ ) values for τ = 0, 1, 2, 3 and, in each
ﬁgure, for four different realisation sizes T = 512, 1024, 2048 and 4096 with the realisations coming
from a stationary AR(1) model with α = 0.8. The vertical dotted line in each plot is the theoretical
parameter. Even the plot for T = 512 in each case does not look too far from normal and would be
at least tenable to use its variance for the basis of a conﬁdence interval. In each plot one can see that
as the sample size increases the density estimate of the relevant ˆc exhibits far less skew, less kurtosis,
less biased and hence suggests that the asymptotic normal assumption is tenable.
Figures 12 to 15 provide additional evidence for the asymptotic normality but using a nonsta-
tionary TVAR(1) model selected at the particular time point z∗ = 200/512. The equivalent AR(1)
parameter at this time point is 0.199.

All the density estimates were produced with the density() function in R with default argu-

ments.

9

Figure 4: Localized autocovariance estimates from a single realisation from stationary model AC1.
Plots a. to d. correspond to localizing at (rescaled) times of 100/512, 200/512, 300/512, 400/512
respectively.

10

05101520250.00.40.81.2a.LagACF (cov)0510152025−0.20.20.61.0b.LagACF (cov)0510152025−0.20.20.61.0c.LagACF (cov)0510152025−0.20.20.61.0d.LagACF (cov)Figure 5: Localized autocovariance estimates from a single realisation from stationary model AC2.
Plots a. to d. correspond to localizing at (rescaled) times of 100/512, 200/512, 300/512, 400/512
respectively.

11

05101520250246a.LagACF (cov)05101520250246b.LagACF (cov)05101520250246c.LagACF (cov)05101520250246d.LagACF (cov)Localized autocovariance estimates

from a single realisation from non-
Figure 6:
stationary model AC3.
correspond to localizing at (rescaled) times of
100/512, 200/512, 300/512, 400/512 respectively. The horizontal dashed line in each ﬁgure cor-
responds to the true value of the AR parameter at that time point

Plots a.

to d.

12

0510152025−1.00.01.0a.LagACF (cov)0510152025−1.00.01.0b.LagACF (cov)0510152025−1.00.01.0c.LagACF (cov)0510152025−1.00.01.0d.LagACF (cov)Localized autocovariance estimates

from a single realisation from non-
Figure 7:
stationary model AC4.
correspond to localizing at (rescaled) times of
100/512, 200/512, 300/512, 400/512 respectively. The horizontal dashed line corresponds to the
true variance (lag 0 acf) of the process at that time point. The horizontal dotted line corresponds to
the true values of the lag-1 coefﬁcient at that point.

Plots a.

to d.

13

0510152025−0.50.00.51.01.5a.LagACF (cov)0510152025−0.50.00.51.01.5b.LagACF (cov)0510152025−0.50.00.51.01.5c.LagACF (cov)0510152025−0.50.00.51.01.5d.LagACF (cov)Figure 8: Solid line: Density estimates of values of ˆc(200/512, 0) for a. T = 512, b. T = 1024,
c. T = 2048 and d. T = 4096 all computed from AR(1) model simulations with AR parameter
α = 0.8. Dashed lines: these are the normal density functions with mean and variance equal to the
sample mean and variance of the ˆc values. Vertical dotted line: The theoretical value of the parameter.

14

123450.00.51.01.5a.Density23450.00.51.01.5b.Density2.02.53.03.54.04.50.00.51.01.5c.Density2.02.53.03.54.00.00.51.01.5d.DensityFigure 9: Solid line: Density estimates of values of ˆc(200/512, 1) for a. T = 512, b. T = 1024,
c. T = 2048 and d. T = 4096 all computed from AR(1) model simulations with AR parameter
α = 0.8. Dashed lines: these are the normal density functions with mean and variance equal to the
sample mean and variance of the ˆc values. Vertical dotted line: The theoretical value of the parameter.

15

123450.00.51.01.5a.Density1.01.52.02.53.03.54.00.00.51.01.5b.Density1.52.02.53.03.50.00.51.01.5c.Density1.01.52.02.53.03.50.00.51.01.5d.DensityFigure 10: Solid line: Density estimates of values of ˆc(200/512, 2) for a. T = 512, b. T = 1024,
c. T = 2048 and d. T = 4096 all computed from AR(1) model simulations with AR parameter
α = 0.8. Dashed lines: these are the normal density functions with mean and variance equal to the
sample mean and variance of the ˆc values. Vertical dotted line: The theoretical value of the parameter.

16

012340.00.51.01.5a.Density0.51.01.52.02.53.03.50.00.51.01.5b.Density1.01.52.02.53.00.00.51.01.5c.Density1.01.52.02.53.00.00.51.01.5d.DensityFigure 11: Solid line: Density estimates of values of ˆc(200/512, 3) for a. T = 512, b. T = 1024,
c. T = 2048 and d. T = 4096 all computed from AR(1) model simulations with AR parameter
α = 0.8. Dashed lines: these are the normal density functions with mean and variance equal to the
sample mean and variance of the ˆc values. Vertical dotted line: The theoretical value of the parameter.

17

012340.00.51.01.5a.Density0.51.01.52.02.53.03.50.00.51.01.5b.Density0.51.01.52.02.50.00.51.01.5c.Density0.51.01.52.02.50.00.51.01.5d.DensitySolid line: Density estimates of values of ˆc(z∗ = 200/512, 0) for a. T = 512, b.
Figure 12:
T = 1024, c. T = 2048 and d. T = 4096 all computed from TVAR(1) model simulations with
TVAR parameter α(z∗) = 0.199. Dashed lines: these are the normal density functions with mean and
variance equal to the sample mean and variance of the ˆc values. Vertical dotted line: The theoretical
value of the parameter.

18

0.60.81.01.21.41.6051015a.Density0.70.80.91.01.11.21.31.4051015b.Density0.80.91.01.11.21.3051015c.Density0.901.001.101.20051015d.DensitySolid line: Density estimates of values of ˆc(z∗ = 200/512, 1) for a. T = 512, b.
Figure 13:
T = 1024, c. T = 2048 and d. T = 4096 all computed from TVAR(1) model simulations with
TVAR parameter α(z∗) = 0.199. Dashed lines: these are the normal density functions with mean and
variance equal to the sample mean and variance of the ˆc values. Vertical dotted line: The theoretical
value of the parameter.

19

−0.20.00.20.40.6051015a.Density0.00.10.20.30.4051015b.Density0.00.10.20.30.4051015c.Density0.100.150.200.250.300.35051015d.DensitySolid line: Density estimates of values of ˆc(z∗ = 200/512, 2) for a. T = 512, b.
Figure 14:
T = 1024, c. T = 2048 and d. T = 4096 all computed from TVAR(1) model simulations with
TVAR parameter α(z∗) = 0.199. Dashed lines: these are the normal density functions with mean and
variance equal to the sample mean and variance of the ˆc values. Vertical dotted line: The theoretical
value of the parameter.

20

−0.3−0.10.10.20.30.4051015a.Density−0.2−0.10.00.10.20.3051015b.Density−0.10.00.10.2051015c.Density−0.050.000.050.100.150.20051015d.DensitySolid line: Density estimates of values of ˆc(z∗ = 200/512, 3) for a. T = 512, b.
Figure 15:
T = 1024, c. T = 2048 and d. T = 4096 all computed from TVAR(1) model simulations with
TVAR parameter α(z∗) = 0.199. Dashed lines: these are the normal density functions with mean and
variance equal to the sample mean and variance of the ˆc values. Vertical dotted line: The theoretical
value of the parameter.

21

−0.3−0.10.00.10.2051015a.Density−0.2−0.10.00.10.2051015b.Density−0.100.000.050.100.15051015c.Density−0.050.000.050.10051015d.Density4 Reproducing ﬁgures in the Companion Paper

In the interests of reproducible research we explain how we produce the ﬁgures in the companion
paper, Nason (2013)

4.1 Figure 1: Earthquake P data
The data for this section are described in Shumway and Stoffer (2006). The earthquake and explosion
data can be obtained from David Stoffer’s website at

\protect\vrule width0pt\protect\href{http://www.stat.pitt.edu/stoffer/tsa.html}{http://www.stat.pitt.edu/stoffer/tsa.html}

The data is stored in a ﬁle eq5exp6.dat as a single vector of 4096 observations. The earth-
quake P and Q waves are stored ﬁrst, then the explosion P and Q waves. We’ve stored them as
eqP, eqQ, exP and exQ each vectors of 1024 values. With this information Figure 1 in the main
paper can be produced using the following commands:

eqP.hwtos2 <- hwtos2(eqP)
plot(eqP.hwtos2)

4.2 Figure 2: Explosion P data
Similarly, the explosion P data test of stationarity plot can be obtained by

exP.hwtos2 <- hwtos2(exP)
plot(exP.hwtos2)

4.3 Figure 3: dBabyECG data
The dBabyECG data is constructed by

dBabyECG <- diff(c(BabyECG[2], BabyECG))

Note: the book is actually incorrect (typos), but a correct version is on the errata list of the book. The
commands to produce Figure 3 are:

dBabyECG.hwtos2 <- hwtos2(dBabyECG)
plot(dBabyECG.hwtos2)

4.4 Figure 4: various acfs of EqP data
Figure 4 produced by the following bespoke set of commands:

tmp <- acf(eqP[100:200], plot = FALSE, lag.max = 30)$acf

tmp2 <- acf(eqP[1:300], plot = FALSE, lag.max = 30)$acf
tmp <- tmp[, , 1]
tmp2 <- tmp2[, , 1]
eqP.lacvCI <- Rvarlacv(eqP, nz=150)
plot(eqP.lacvCI, type = "acf", main = "", segandcross=FALSE, sub="")
symbols(0:30, tmp, circles = rep(0.2, 31), inches = FALSE,

fg = 1, add = TRUE)

22

sm1 <- rep(0.3, length(tmp2))
sm2 <- rep(0.3, length(tmp2))
sm <- cbind(sm1, sm2, sm1, sm2, sm1, sm2)
n <- 18
points(0:30, tmp2, pch = n)
lin1 <- 2/sqrt(100)
abline(h = lin1, lty = 2)
lin2 <- 2/sqrt(300)
abline(h = lin2, lty = 3)

4.5 Figure 5: Localized ACV of EqQ at two points
Figure 5 was produced by:

exQ.lacv.50 <- Rvarlacv(x=exQ, nz=50, var.lag.max=30)
exQ.lacv.900 <- Rvarlacv(x=exQ, nz=900, var.lag.max=30)
plot(exQ.lacv.50, plotcor=FALSE, type="acf")
plot(exQ.lacv.900, plotcor=FALSE, type="acf")

4.6 Figure 6: Localized ACV of TVAR(1) process
The four ﬁgures in Figure 6 were produced by

#
# Plot a.
#
x <- tvar1sim()
x.100.tvar1 <- Rvarlacv(x, nz=100, var.lag.max=25)
plot(x.100.tvar1, plotcor=FALSE, type="acf", sub="a.")
#
# Plot b.
#
x.200.tvar1 <- Rvarlacv(x, nz=200, var.lag.max=25)
plot(x.200.tvar1, plotcor=FALSE, type="acf", sub="b.")
#
# Plot c.
#
x.300.tvar1 <- Rvarlacv(x, nz=300, var.lag.max=25)
plot(x.300.tvar1, plotcor=FALSE, type="acf", sub="c.")
#
# Plot d.
#
x.400.tvar1 <- Rvarlacv(x, nz=400, var.lag.max=25)
plot(x.400.tvar1, plotcor=FALSE, type="acf", sub="d."

Of course, the ﬁgures will be different as the realisations from the tvar1sim() will be different on
different machines and for different invocations.

23

References

Nason, G.P. (2013) A test for second-order stationarity and approximate conﬁdence intervals for lo-
calized autocovariances for locally stationary time series. J. R. Statist. Soc. B, 75, 879–904.

Priestley, M.B. and Subba Rao, T. (1969) A test for non-stationarity of time series. J. R. Statist. Soc.
B, 31, 140–149.

Shumway, R.H. and Stoffer, D.S. (2006) Time Series Analysis and Its Applications with R Examples,
Springer: New York.

24

