The landscape of bounds for binary search trees
Parinya Chalermsook1, Mayank Goswami1, László Kozma2, Kurt
Mehlhorn1, and Thatchaphol Saranurak3

1 Max-Planck Institute for Informatics, Germany.

{parinya,gmayank,mehlhorn}@mpi-inf.mpg.de
Saarland University, Germany.

2
kozma@cs.uni-saarland.de
3 KTH Royal Institute of Technology, Sweden. thasar@kth.se

Abstract

Binary search trees (BSTs) with rotations can adapt to various kinds of structure in search
sequences, achieving amortized access times substantially better than the Θ(log n) worst-case
guarantee. Classical examples of structural properties include static optimality, sequential access,
working set, key-independent optimality, and dynamic ﬁnger, all of which are now known to be
achieved by the two famous online BST algorithms (Splay and Greedy). Beyond the insight on
how “eﬃcient sequences” might look like, structural properties are important as stepping stones
towards proving or disproving dynamic optimality, the elusive 1983 conjecture of Sleator and
Tarjan that postulates the existence of an asymptotically optimal online BST. A BST can be
optimal only if it satisﬁes all “sound” properties (those achieved by the oﬄine optimum).

In this paper, we introduce novel properties that explain the eﬃciency of sequences not
captured by any of the previously known properties, and which provide new barriers to dynamic
optimality. We also establish connections between various properties, old and new. For instance,
we show the following.

A tight bound of O(n log d) on the cost of Greedy for d-decomposable sequences, improving
our earlier n2O(d2) bound (FOCS 2015). The result builds on the recent lazy ﬁnger result
of Iacono and Langerman (SODA 2016). On the other hand, we show that lazy ﬁnger alone
cannot explain the eﬃciency of pattern avoiding sequences even in some of the simplest cases.
A hierarchy of bounds using multiple lazy ﬁngers, addressing a recent question of Iacono and
Langerman.
The optimality of the Move-to-root heuristic in the key-independent setting introduced by
Iacono (Algorithmica 2005).
A new tool that allows combining any ﬁnite number of sound structural properties. As an
application, we show an upper bound on the cost of a class of sequences that all known
properties fail to capture.
The equivalence between two families of BST properties. The observation on which this
connection is based was known before – we make it explicit, and apply it to classical BST
properties. This leads to a clearer picture of the relations between BST properties and to a
new proof of several known properties of Splay and Greedy that is arguably more intuitive
than the current textbook proofs.

Digital Object Identiﬁer 10.4230/LIPIcs.xxx.yyy.p

Introduction

1
In the dynamic BST model a sequence of keys are accessed in a binary search tree, and
after each access, the tree can be reconﬁgured via a sequence of rotations and pointer moves
starting from the root. (There exist several alternative but essentially equivalent cost models,
see e.g. [11,34].) Two classical online algorithms in this model are the Splay tree of Sleator and
Tarjan [31] and Greedy, an algorithm discovered independently by Lucas [21] and Munro [26]
and turned into an online algorithm by Demaine et al. [11].

6
1
0
2

 
r
a

 

M
5
1

 
 
]
S
D
.
s
c
[
 
 

1
v
2
9
8
4
0

.

3
0
6
1
:
v
i
X
r
a

© Parinya Chalermsook, Mayank Goswami, László Kozma, Kurt Mehlhorn, Thatchaphol Saranurak;
licensed under Creative Commons License CC-BY

Conference title on which this volume is based on.
Editors: Billy Editor and Bill Editors; pp. 1–32

Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany

2

The landscape of bounds for binary search trees

Our understanding of the BST model goes far beyond the usual paradigm of worst-case
complexity. For broad classes of access sequences the Θ(log n) worst-case bound is too
pessimistic, and both Splay and Greedy are able to achieve better amortized access times.
Understanding the kinds of structure in sequences that facilitate eﬃcient access has been
the main focus of BST research in the past decades. The description of useful structure is
typically given in the form of formulaic bounds.
Given an access sequence X = (x1, . . . , xm) ∈ [n]m, a formulaic BST bound (or simply
BST bound) is a function f(X) computable in polynomial time, intended to capture the
access cost of BST algorithms on sequence X. We say that a BST bound f(X) is sound
if OPT(X) ≤ O(f(X) + |X|) where OPT(X) is the optimal cost achievable by an oﬄine
algorithm. The bound f(X) is achieved by algorithm A if the cost of accessing sequence X
by A (denoted A(X)) is at most O(f(X) + |X|). BST bounds play two crucial roles:

algorithms. For instance, the dynamic ﬁnger bound P

(i) They shed light on the structures that make sequences eﬃciently accessible by BST
i log |xi − xi+1 + 1| intuitively captures
the “encoding length” of the distances between consecutive accesses (algorithms can take
advantage of the proximity of keys).

(ii) A sound BST bound is a concrete intermediate step towards the dynamic optimality
conjecture [31], which postulates that a simple online algorithm can asymptotically match
the optimum on every access sequence, i.e. that it can be O(1)-competitive. This has been
conjectured for both Splay and Greedy, but the conjecture remains unsettled after decades of
research. An O(1)-competitive algorithm needs to achieve all sound BST bounds. Proposing
concrete bounds and verifying whether candidate algorithms such as Splay or Greedy achieve
them has been so far the main source of progress towards dynamic optimality.

Several such bounds appear in the literature: besides the classical dynamic ﬁnger [9,31],
working set [19,31], uniﬁed bound [14,31], etc. recently studied bounds include lazy ﬁnger
and weighted dynamic ﬁnger [4,20], and bounds pertaining to pattern-avoidance [7]. In some
cases the interrelation between these bounds is unclear (i.e. whether one subsumes the other).
Our contributions. In this paper we systematically organize the known bounds into a
coherent picture, and study the pairwise relations between bounds. We introduce new
sound BST bounds (in fact, a hierarchy of them). Some of these bounds serve as bridges
between existing bounds, whereas others explain the easiness of certain sequences, hitherto
not captured by any known bound. (We only focus on bounds deﬁned on access sequences,
we ignore therefore the deque [32], and split [22] conjectures, that concern other operations.)
We highlight in this section the contributions that we ﬁnd most interesting, with an
informal discussion of their implications. We refer to § 2 for a more precise deﬁnition of the
bounds considered in this paper. Our current knowledge of sound BST bounds and their
relations, i.e. the “landscape” of BST bounds is presented in Figure 2. In the following, let
X ∈ [n]m be an arbitrary access sequence.
Lazy ﬁnger results. Our ﬁrst set of contributions is a study of lazy ﬁnger bounds, their
generalizations, and their connections with other BST bounds. The lazy ﬁnger bound [4],
denoted LF(X), captures the “proximity” of successive accesses in a reference tree. Bose et
al. [4] proved that lazy ﬁnger generalizes the classical dynamic ﬁnger bound. It was recently
shown [20] that Greedy(X) ≤ O(LF(X)). We prove a new connection between lazy ﬁnger
and a recently studied [7] decomposability parameter d(X).
(cid:73) Theorem 1. For permutation sequence X ∈ [n]n and decomposability parameter d = d(X),
we have LF(X) ≤ O(n log d).

As a corollary, we obtain the tight bound Greedy(X) ≤ O(n log d) which improves the
earlier bound of O(n2O(d2)) and resolves an open question from [7]. We remark that d(X) is a

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

3

natural parameter whose special case d(X) = 2 includes the well-known traversal sequences.

Next, inspired by [13], we deﬁne the k-lazy ﬁnger parameter LF k(X).

(cid:73) Theorem 2. Let X ∈ [n]m be a sequence and k ∈ N. Then OPT(X) ≤ O(log k) · LF k(X).
This improves the O(k) · LF k(X) bound, which is implicit in [13]. Moreover, our bound
is tight in the sense that there exists X for which OPT(X) ≥ Ω(log k) · LF k(X). Remark
that LF 1(X) ≥ LF 2(X) ≥ . . . ≥ LF n(X), giving a hierarchy of sound BST bounds. For
k ≥ 2, this bound is not known to be achieved by any online algorithm.

The bounds in the k-lazy ﬁnger hierarchy are not implied by each other. In fact, we
show a strongest possible separation between LF k and LF k−1. That is, for any k, there is a
sequence X for which LF k−1(X)/LF k(X) ≥ Ω(log(n/k)). This result yields a large number
of intermediate steps towards dynamic optimality: A candidate algorithm not only needs to
achieve the ﬁnger bounds for constantly many ﬁngers, but also has to match the asymptotic
ratio of O(log k).

We show an application of multiple lazy ﬁngers by giving a new upper bound on OPT: Let
m(X) denote the monotone complexity parameter of X. In [7], we showed that Greedy(X) ≤
|X|·2O(k2) for k = m(X). Here we show that OPT(X) ≤ O(log k)·LF k(X) ≤ O(k log k)·|X|,
raising the open question of whether there is any online algorithm matching this bound.
Interleave results. We introduce a simulation technique that allows combining any ﬁnite
number of sound BST bounds.
Let X(1), . . . , X(‘) be a collection of sequences where X(i) ∈ [ni]mi (each
X(i) is a sequence of length mi on key space of size ni). We consider a
natural way to compose these sequences by using a sequence ˜X ∈ [‘]m as
i ni. The “composed sequence”
( ˜Xt)
σ(t) + Nt, where Nt =

i mi and n =P
a template, where m =P
i=1 ni, and σ(t) = |(cid:8)t0 ≤ t : ˜Xt0 = ˜Xt
P ˜Xt−1

(cid:9)|. Denote the composed sequence

S = (S1, . . . , Sm) ∈ [n]m is deﬁned as St = X

Figure 1 The sequence
X = (1, 5, 3, 2, 4) (left) res-
ulting from composing the
sequences X(1) = (1, 3, 2)
(circles) and X(2) = (2, 1)
(squares) with the template
˜X = (1, 2, 1, 1, 2) (right).

by X = ˜X{X1, . . . , X‘}. Intuitively, the sequences are interleaved spatially,
and the order in which they produce the next element of the composed
sequence is governed by the template sequence. See Figure 1 for illustration.
(cid:73) Theorem 3. Let X = ˜X{X1, . . . , X‘}, and let ˜f , f1, . . . , f‘ be sound BST

bounds. Then f(X) = ˜f( ˜X) +P‘

i=1 fi(Xi) is also a sound BST bound.

This result allows us to analyze the optimum of natural classes of

sequences whose easiness was not implied by any of the known bounds.

Key-independent setting. We revisit the key-independent setting, in which Iacono showed
that optimality is equivalent to working set [19]. We show the following.
(cid:73) Theorem 4. In the key-independent case Move-to-root is optimal.

This may seem surprising, since Move-to-root is a rather simple heuristic, not guaranteed
to achieve even sublinear amortized access time. The result is nevertheless consistent with
intuition, since in other key-independent models (e.g. list update problem) heuristics similar
to Move-to-root have already been known to be asymptotically optimal [30]. Moreover, in
such key-independent problems, “useful structure” has typically been described via bounds
resembling the working set bound (see e.g. [1,2,27]), which in the key-independent BST case
is indeed the “full story” of optimality.
Relations between classical bounds. We make explicit the equivalence between two
popular notions in BST bounds, namely, information-theoretic proximity with weighted
elements (such as in weighted dynamic ﬁnger) and proximity of keys in a reference tree (such

4

The landscape of bounds for binary search trees

as in static optimality and lazy ﬁnger). This equivalence has implicitly appeared several
times in the literature, but it has not been applied to some of the classical BST bounds.

By making the connection explicit, the landscape of known bounds becomes clearer. In
particular, the following become obvious: (i) static optimality is just an access lemma with
ﬁxed weight function, and (ii) static ﬁnger is an unweighted version of static optimality.
Using these observations, we prove some of the known properties of Splay and Greedy in a
way that is arguably simpler and more intuitive than existing textbook proofs.
Open problems. Some of the sound BST bounds presented in the paper are not known
to be achieved by online algorithms. In particular, does any online algorithm achieve the
k-lazy ﬁnger (times O(log k)) bound when k ≥ 2? Does any online algorithm achieve the
interleave bound? Are there broad classes of linear cost sequences not captured by any of
the known bounds? Does any online algorithm achieve the bound of O(k log k)|X|, where
k = m(X)? These questions serve as concrete intermediate steps for proving or disproving
dynamic optimality.

Our result for the decomposability parameter of a sequence is tight. The bounds for
general pattern avoidance and monotone pattern parameter (deﬁned in § 2) are not known
to be tight.

There exist other ways of composing sequences (diﬀerent from the operation used in
our interleave bound). Do these operations similarly lead to composite BST bounds? In
particular, if X is the merge of X1 and X2 (i.e. X can be partitioned into two subsequences
X1 and X2), does a linear cost of both X1 and X2 imply the linear cost of X?

2 Dictionary of BST bounds
In this section we list the BST bounds considered in the paper, marking those that are new
with ?. Let S = (s1, . . . , sm) ∈ [n]m be an access sequence. A weight function w : [n] → R+
i=min{i1,i2} w(i), let
i∈X w(i) for any set X ⊂ [n]. The following bounds can be

maps elements to positive reals. For convenience, denote w[i1 : i2] =Pmax{i1,i2}
W = w[1 : n], and w(X) =P

deﬁned for any access sequence S ∈ [n]m.
Basic bounds.

Balance: The balance bound is B(S) = m log n. It describes the fact that accesses take

amortized O(log n) time. We can generalize it with weights as follows.

Weighted Balance?: For any weight function w, let WBw(S) = Pm

w(sj). The
weighted balance bound is WB(S) = minw WBw(S). Note that for the uniform weight
function wi = 1, WBw(S) = B(S). The reader might observe the similarity of the weighted
balance bound with the access lemma, a statement that bounds the amortized cost of a
single access. The access lemma has been used to prove properties of Splay and other
algorithms [6,17,31]. We observe that matching the bound WB is a weaker condition than
satisfying the access lemma, since here the weights are ﬁxed throughout the sequence of
accesses, whereas the access lemma makes no such assumption.

j=1 log W

Entropy: Let mi be the number of times element i is accessed. The entropy bound [31] is

i=1 mi log m
.
mi
Locality in keyspace.

H(S) =Pn
element f ∈ [n], let SF f(S) = Pm
For any weight function w and any element f, let WSF w,f(S) =Pm

SF(S) = minf SF f(S). We deﬁne a weighted version as follows.

Static Finger: this bound depends on the distances from a ﬁxed key. For an arbitrary
j=1 log(|f − sj| + 1). The static ﬁnger bound [31] is

j=1 log

w[f:sj]

min{w(f),w(sj)}.

The weighted static ﬁnger? bound is WSF(S) = minw WSF w(S).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

5

Figure 2 BST bounds and relations between them. Each box represents a BST bound. Arrows
indicate asymptotic domination: the source of the arrow is “smaller” than the target. Bounds
grouped into larger boxes are asymptotically equivalent. Shaded boxes indicate bounds that are
either new or strengthened in this paper (with the exception of the k-avoiding bound for which we
prove in this paper a stronger lower bound only). The following remarks are in order.
1. We deﬁne pattern-avoiding bounds in a parameterized way, such that they are well-deﬁned for
all access sequences. Let k be an arbitrary positive integer. If X is k-avoiding, then the value of
the k-avoiding bound for X is 2α(n)O(k), and otherwise the value of the bound is deﬁned to be +∞.
Similarly, the value of the k-decomposable bound is O(n log k) if X is k-decomposable, and +∞
otherwise. We deﬁne two k-monotone bounds, a strong, and a weak bound. Both bounds are set to
+∞ if X is not k-monotone. In other cases, the value of the strong, respectively weak, k-monotone
bound is O(nk log k), respectively n2O(k2). The traversal and sequential bounds are deﬁned similarly:
the value of the bound is O(n) for a permutation sequence X ∈ [n]n, if X is a preorder traversal,
respectively monotone increasing sequence, and +∞ otherwise.
2. Boxes with a parameter k indicate families of bounds: there is a diﬀerent bound deﬁned for each
value of k. Bounds in the same box for diﬀerent values of k are not always comparable, i.e. the
parameterized families of bounds are not necessarily increasing or decreasing with k.
3. In case of the arrows from (k-lazy ﬁnger ×O(log k)) to (k-monotone), and from the stronger
(k-monotone) to the weaker (k-monotone), it is meant that the former bound with a given ﬁxed
value of k dominates the latter bound with the same value k.
4. The arrows from (lazy ﬁnger) to (k-decomposable), from (OPT) to (k-lazy ﬁnger ×O(log k)), and
from (OPT) to (k-avoiding) indicate that the former dominates the latter for all values of k.
5. The arrows from (k-monotone) to (sequential), from (k-decomposable) to (traversal), and from
(k-lazy ﬁnger ×O(log k)) to (lazy ﬁnger) indicate domination for any constant k ≥ 2.

SplayGreedy6

The landscape of bounds for binary search trees

w[sj−1:sj]

min{w(sj−1),w(sj)}. The weighted

Dynamic Finger: these bounds depend on the distances between consecutive accesses.

The dynamic ﬁnger bound [9,10,31] is DF(S) =Pm
For any weight function w, let WDF w(S) =Pm

j=2 log(|sj − sj−1| + 1).
j=2 log
dynamic ﬁnger bound [4,20] is WDF(S) = minw WDF w(S).
Locality in time.
j | sk = sj}. If j is the ﬁrst time that sj is accessed, then we set ρS(j) = 0.

Working set: For any j ≤ m, let the last touch time of the element sj be ρS(j) = max{k <
The working set at time j is deﬁned as wS(j) = {si | ρS(j) < i ≤ j}. In words, it is the

set of distinct elements accessed since the last touch time of the current element.

The working set bound [31] is WS(S) =Pm
Static Optimality: For any ﬁxed BST T on [n], let SOT (S) =Pm
Fixed Finger?: For any ﬁxed BST T and any element f, let FF T,f(S) =Pm

j=1 dT (sj), where dT (sj)
is the depth of sj in T i.e. the distance from the root to sj. The static optimality bound [31]
is SO(S) = minT SOT (S).

j=1 dT (f, sj)
where dT (f, sj) is the distance from f to sj in T. The ﬁxed ﬁnger? bound is FF(S) =
minT,f FF T,f(S).

Locality in a reference tree.

j=1 log(|wS(j)|).

accesses in a reference tree. For any ﬁxed BST T on [n], let LF T (S) =Pm

Lazy Finger: The previous two bounds capture the proximity of an access to the root and
to a ﬁxed key f respectively. The lazy ﬁnger bound [4] captures the proximity of consecutive
j=2 dT (sj−1, sj)
where dT (sj−1, sj) is the distance from sj−1 to sj in T. The lazy ﬁnger bound is LF(S) =
minT LF T (S).
k-Lazy Finger?: We generalize the lazy ﬁnger bound to allow multiple ﬁngers. Our
deﬁnition is inspired by [4, 13]. Let k ∈ N and T be a binary search tree on [n]. A ﬁnger
strategy consists of a sequence ~f ∈ [k]m where ft ∈ [k] speciﬁes the ﬁnger that will serve
the request st, and an initial vector ~‘ ∈ [n]k where ‘i ∈ [n] speciﬁes the initial location of
t=1(1 + dT (st, sσ(ft,t))) where σ(i, t)
ﬁnger i. The cost of strategy ( ~f, ~‘) is LF k
is the location of ﬁnger i before time t, and σ(i, 1) = ‘i. Let LF k
T, ~f ,~‘(S).
T (S) is the optimal k-server solution
In other words, for a ﬁxed BST T on key set [n], LF k
that serves access sequence S in tree T. We deﬁne LF k(S) = minT LF k
T (S). It is clear form
the deﬁnition that LF 1(S) ≥ LF 2(S) ≥ . . . ≥ LF n(S) = m.

T, ~f ,~‘(S) =Pm

T (S) = min ~f ,~‘ LF k

Pm
Uniﬁed Bound: The uniﬁed bound [14, 31] computes for every access the minimum
among the static ﬁnger, static optimality, and working set bounds. It is deﬁned as UB =
j=1 log(min{|f − sj| + 1, dT (sj),|wS(j)|}). The bound should not be confused with
minT,f
the uniﬁed conjecture [5], which subsumes the working set and dynamic ﬁnger bounds but is
not currently known to be achieved by OPT.

The described bounds are summarized in Table 1 in § B. We defer the deﬁnition of

key-independent bounds to § 3.3.
Pattern avoidance.

Pattern avoidance bounds are, in some sense, diﬀerent from the other BST bounds; they
capture a more “global” structure, whereas other bounds all measure a broadly understood
“locality of reference”.

The pattern avoidance parameter p(X) is the smallest integer such that X avoids some
permutation pattern σ of length p(X). If k ≥ p(X), we say that X is k-avoiding. The
following are special cases of this parameter.

The monotone pattern parameter m(X) is the smallest integer such that X avoids one of
the patterns (1, . . . , m(X)) or (m(X), . . . , 1). If k ≥ m(X), we say that X is k-monotone.

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

7

The monotone pattern parameter of sequential access is m(X) = 2.

The decomposability parameter is deﬁned for permutation access sequences (X ∈ [n]n).
Parameter d(X) is the smallest integer such that X avoids all simple permutations of length
d(X)+1 and d(X)+2. If k ≥ d(X), we say that X is k-decomposable. There is an equivalent
deﬁnition of k-decomposability in terms of a block decomposition of X, see § 4.1. For a
traversal sequence X (i.e. the preorder sequence of some BST) we have d(X) = 2.

We refer to [7] for more details on pattern-avoiding bounds. The fact that OP T is linear
for traversal and for sequential access is well-known. The following relations are shown in [7]
between pattern avoidance parameters and OPT.
(cid:73) Theorem 5 ( [7]). Let X be a permutation input sequence in [n]n, let p = p(X), let
d = d(X), and m = m(X). The following relations hold:

Greedy(X) ≤ n2α(n)O(p)
Greedy(X) ≤ n2O(d2) and OPT(X) ≤ O(m log d)
Greedy(X) ≤ n2O(m2)

Known relations between bounds. We refer to Figure 2 for illustration. By deﬁnition,
the weighted bounds are stronger than their unweighted counterparts because of the uniform
weight function mapping all elements to 1, therefore WB(S) ≤ B(S), WSF(S) ≤ SF(S),
WDF(S) ≤ DF(S) for any sequence S. In [7] it is shown that pattern-avoidance bounds are
incomparable with the dynamic ﬁnger and working set bounds.
(cid:73) Theorem 6. The following relations hold for any sequence S:

[25] SO(S) = Θ(H(S)).
[4] LF(S) = Θ(WDF(S)).
[14] UB(S) = Θ(WS(S)).

Known competitiveness of algorithms. We only focus on the complexity of the Splay
and Greedy algorithms. Other algorithms considered in the literature include Tango trees [12]
and Multi-splay [33]. We summarize the bounds known to be achieved by Splay and Greedy
in Theorem 22 deferred to § A. These facts are also illustrated in Figure 2.

3 New equivalences between classical bounds
In this section we revisit some of the classical BST bounds and establish new equivalences. In
§ 3.1 we prove that the weighted balance, weighted static ﬁnger, static optimality, and ﬁxed
ﬁnger bounds are equivalent. As an application, a new proof is presented that Splay and
Greedy satisfy these properties in § 3.2. In § 3.3 we show that Move-to-root is the optimal
algorithm, when key values are randomly permuted.
3.1 Static optimality and equivalent bounds
The conceptual message of this section is that the weighted version of information-theoretic
proximity is equivalent to proximity in a reference tree. We start by stating the technical
tools that allow the conversion between the two settings.
Weight ⇒ Tree: We refer to the randomized construction of a BST from an arbitrary
weight function due to Seidel and Aragon [29].
(cid:73) Lemma 7 ( [29]). Given a weight function w, there is a randomized construction of a BST
Tw with the following properties:

the expected depth of element i is E[dTw(i)] = Θ(log W
w(i)), and
the expected distance from element i to j is E[dTw(i, j)] = Θ(log

w[i:j]

min{w(i),w(j)}).

8

The landscape of bounds for binary search trees

i ∈ [n],P
Ti. Therefore, w(i) ≤P

j∈Ti

w(j) = Θ(w(i)).

w(j) ≤P∞

j∈Ti

d0=0 2d04−dT (i)−d0 ≤ 2w(i).

When only the ﬁrst property is needed, we can use a deterministic construction, see § C.
Tree ⇒ Weight: Given a tree T, the following assignment of weights is folklore.
(cid:73) Lemma 8. Let T be a BST and deﬁne w(i) = 4−dT (i) for all i ∈ [n]. Then for any key

Proof. From the BST property, there are at most 2d nodes that are at depth d in the subtree

We show that for any sequence S, the following bounds are equivalent: weighted balance,
static optimality, weighted static ﬁnger, and ﬁxed ﬁnger. We defer the proofs to § D. We
remark that all proofs in this section are inspired by the equivalence between the weighted
dynamic ﬁnger and lazy ﬁnger bounds in [4].
(cid:73) Theorem 9. For all sequences S, we have WB(S) = SO(S) = WSF(S) = FF(S) (up to
constant factors).
Discussion. We can interpret the theorem as follows: (i) Any algorithm satisfying the access
lemma [31] obviously satisﬁes static optimality, because SO = WB, and WB is equivalent
to the access lemma with the restriction that the weight function is ﬁxed throughout the
sequence. (ii) In static BSTs, ﬁxing the ﬁnger at the root is the best choice up to a constant
factor, because SO = FF. (iii) SO is now obviously stronger than SF because SO = WSF,
and WSF is the weighted version of SF.
3.2 New proofs of static optimality
In this section we give a simple direct proof that Splay and Greedy achieve static optimality.
By Theorem 9, this implies that the other bounds are also achieved. These facts are well-
known [17, 31], but we ﬁnd the new proofs to provide additional insight. We present the
proof for Splay and defer the proof for Greedy to § E.

We use a potential function with a a clear combinatorial interpretation.

Min-depth potential function. Fix a BST R, called a reference tree. Let T be the current
tree maintained by our BST algorithm (either Splay or Greedy). Let T(i) denote the set
of elements in the subtree rooted at i. For each element i, the potential of i with respect
to R is ϕR(i) = −2 · minj∈T (i) dR(j). The min-depth potential of T with respect to R is
i=1 ϕR(i). We will drop the subscript R for convenience. We present an easy but

ϕR(T) =Pn

crucial fact.
(cid:73) Fact 1. For any interval [a, b] and any BST R, there is a unique element c ∈ [a, b] with
smallest depth in R.
Proof. Suppose there are at least two elements c and c0 with smallest depth. Then the lowest
common ancestor LCA(c, c0) would have smaller depth, which is a contradiction.
(cid:73) Theorem 10. The amortized cost of splay for accessing element i is O(dR(i)).
Proof. Let ϕb(i) and ϕa(i) be the potential of i before and after splaying i. We have ϕa(i) = 0
because i is the root, and ϕb(i) ≥ −2dR(i).
For each zigzig or zigzag step (see [31] for the description of the Splay algorithm), let
x, y, z be the elements in the step where dT (x) > dT (y) > dT (z). Let ϕ(i) and ϕ0(i) be the
potential before and after the step, and let T and T 0 be the tree before and after the step. It
suﬃces to prove that the cost is at most 3(ϕ0(x) − ϕ(x)). This is because by telescoping, the
total cost for splaying i will be O(ϕa(i) − ϕb(i)) = O(dR(i)), and the amortized cost in the
ﬁnal zig step is trivially at most 1 + 2(ϕ0(x) − ϕ(x)). We analyze the two cases.

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

9

Zigzig: we have that T(x) and T 0(z) are such that T(x)∩T 0(z) = ∅ and T(x), T 0(z) ⊂ T 0(x).
By Fact 1, either ϕ(x) + 2 ≤ ϕ0(x) or ϕ0(z) + 2 ≤ ϕ0(x), so we have 2 ≤ 2ϕ0(x)− ϕ(x)− ϕ0(z).
Therefore, the amortized cost is
2 + ϕ0(x) + ϕ0(y) + ϕ0(z) − ϕ(x) − ϕ(y) − ϕ(z) = 2 + ϕ0(y) + ϕ0(z) − ϕ(x) − ϕ(y)

≤ 2 + ϕ0(x) + ϕ0(z) − 2ϕ(x)
≤ (2ϕ0(x) − ϕ(x) − ϕ0(z)) + ϕ0(x) + ϕ0(z) − 2ϕ(x)
= 3(ϕ0(x) − ϕ(x)).

Zigzag: we have that T 0(y) and T 0(z) are such that T 0(y) ∩ T 0(z) = ∅ and T 0(y), T 0(z) ⊂

T 0(x). By Fact 1, we have 2 ≤ 2ϕ0(x) − ϕ0(y) − ϕ0(z). Therefore, the amortized cost is
2 + ϕ0(x) + ϕ0(y) + ϕ0(z) − ϕ(x) − ϕ(y) − ϕ(z) = 2 + ϕ0(y) + ϕ0(z) − ϕ(x) − ϕ(y)

≤ (2ϕ0(x) − ϕ0(y) − ϕ0(z)) + ϕ0(y) + ϕ0(z) − ϕ(x) − ϕ(y)
≤ 2(ϕ0(x) − ϕ(x)).

It is instructive to observe the similarity between the min-depth potential and the sum-of-logs
potential [31], which is essentially the “soft-min” version of min-depth, if the weights are set
to 4−dR(i). Such a weight assignment is used in proving static optimality e.g. in [15].

3.3 Move-to-root is optimal when elements are randomly permuted
Let π : [n] → [n] be a permutation. For any sequence S ∈ [n]m, we denote by π(S) =
(π(s1), . . . , π(sm)) the permuted sequence of S by π. The key-independent optimality bound is
deﬁned as KI-OPT(S) = Eπ[OP T(π(S)], where the expectation is over the uniform random
distribution of permutations of size n.
(cid:73) Theorem 11 ( [19]). KI-OPT(S) = Θ(WS(S) + n log n) for any sequence S.1

This shows that the expected cost over a random order of the elements, of the optimal
algorithm is equivalent to the working set bound up to a constant factor if the length of the
sequence is m ≥ n log n. In this section we show that in the key-independent setting even
the very simple heuristic that just rotates the accessed element to the root, is optimal. This
algorithm is called Move-to-root [3], and we denote its total cost for accessing a sequence S
from initial tree T by M T RT (S).
(cid:73) Deﬁnition 12. For any sequence S and any initial tree T, the key-independent move-to-root
bound is KI-MTRT (S) = Eπ[M T RT (π(S)] where π is a random permutation.

The following theorem shows that key-independent move-to-root (starting from a balanced
tree), key-independent optimality, and working set bounds are all equivalent when the length
of the sequence is m ≥ n log n. The proof is deferred to § F.
(cid:73) Theorem 13. Let T be a BST of logarithmic depth. Then, KI-MTRT (S) = Θ(KI-OPT(S)+
n log n) = Θ(WS(S) + n log n) for any sequence S.

We remark that Move-to-root is known to have another property related to randomized
inputs: If accesses are drawn independently from some distribution, then Move-to-root
achieves static optimality for that distribution [3].

1The term n log n is missing in [19].

10

The landscape of bounds for binary search trees

A new landscape via k-lazy ﬁngers

4
In this section we study the lazy ﬁnger bound and its generalization to multiple ﬁngers. In
§ G.1 we argue that OPT(X) ≤ O(log k) · LF k(X) for all sequences X, reﬁning the result
of [13], which had an overhead factor of O(k) instead of O(log k). This bound is essentially
tight: We show in § 6 that there is a sequence X for which OPT(X) = Θ(log k) · LF k(X).

(S

4.1 Applications of lazy ﬁngers
Application 1: Lazy ﬁngers and decomposability.
First, we give necessary deﬁnitions. Let σ = (σ(1), . . . , σ(n)) be a permutation. For
a, b : 1 ≤ a < b ≤ n, we say that [a, b] is a block of σ if {σ(a), . . . , σ(b)} = {c, . . . , d} for some
integer c, d ∈ [n]. A block partition of σ is a partition of [n] into k blocks [ai, bi] such that
i[ai, bi]) ∩ N = [n]. For such a partition, for each i = 1, . . . , k, consider a permutation
σi ∈ Sbi−ai+1 obtained as an order-isomorphic permutation when restricting σ on [ai, bi].
For each i, let qi ∈ [ai, bi] be a representative element of i. The permutation ˜σ ∈ [k]k that is
order-isomorphic to {σ(q1), . . . , σ(qk)} is called a skeleton of the block partition. We may
view σ as a deﬂation ˜σ[σ1, . . . , σk].

Now we provide a recursive deﬁnition of d-decomposable permutations. We refer to [7]
for more details. A permutation σ is d-decomposable if σ = (1), or σ = ˜σ[σ1, . . . , σd0] for
some d0 ≤ d and each permutation σi is d-decomposable.
(cid:73) Lemma 14. Let S be a k-decomposable permutation of length n. Then LF(S) ≤ 4(|S| −
1)dlog ke.
Proof. It is suﬃcient to deﬁne a reference tree T for which LFT (S) achieves such bound. We
remark that the tree will have auxiliary elements. We construct T recursively. If S has length
one, T has a single node and this node is labeled by the key in S. Clearly, LF T (S) = 0.
Otherwise, let S = ˜S[S1, . . . , Sj] with j ∈ [k] the outermost partition of S. Denote by Ti
the tree for Si that has been inductively constructed. Let T0 be a BST of depth at most
dlog je and with j leaves. Identify the i-th leaf with the root of Ti and assign keys to the
internal nodes of T0 such that the resulting tree is a valid BST. Let ri be the root of Ti,
0 ≤ i ≤ j and let r = r0 be the root of T. Then

dT (r, s1) ≤ dlog ke + dT1(r1, s1)
dT (r, sn) ≤ dlog ke + dTj(rj, sn)

(
dS‘(si−1, si)
2dlog ke + dT‘(r‘, si−1) + dT‘+1(r‘+1, si)

dT (si−1, si) ≤

if si−1, si ∈ S‘
if si−1 ∈ S‘ and si ∈ S‘+1,

and hence

LF T (S) = dT (r, s0) +X
≤ 2j dlog ke + X
≤ (2j − 4j + 4 X

i≥2

1≤‘≤j

where the last inequality uses j ≥ 2.

1≤‘≤j

dT (si−1, si) + dT (sn, r)

LFT‘(S‘) ≤ 2j dlog ke + X

|Si|)dlog ke ≤ 4(|S| − 1),

4(|S‘| − 1)dlog ke

1≤‘≤j

Combining this with the Iacono-Langerman result [20], we conclude that for any k-
decomposable sequence S, we have Greedy(S) ≤ O(|S| log k). This strengthens our earlier
result [7] that Greedy(S) ≤ n2O(k2).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

11

Application 2: Improved relation between OPT(S) and m(S).
Let k = m(S), i.e. the smallest integer such that S is k-monotone. In [7] we show that
OP T(S) ≤ Greedy(S) ≤ |S|2O(k2). Here we show the substantially stronger bound
OPT(S) ≤ O(|S|k log k), raising the obvious open question of whether any online BST can
match this bound.
(cid:73) Lemma 15. Let S be a k-monotone sequence of length n. Then LF k(S) = O(nk).
Proof. S avoids (k+1, . . . , 1) or (1, . . . , k+1). Assume that the ﬁrst case holds (the argument
for the other case is symmetric). Then, S can be partitioned into k subsequences S1, . . . , Sk,
each of them increasing, furthermore, such a partition can be computed online. We argue
that LF k

T (S) = O(nk) for any BST T.

Let T be any binary search tree containing [n] as elements. Consider k lazy ﬁngers
f1, . . . , fk in T. We deﬁne the strategy for the ﬁngers as follows: When sj is accessed, if
sj ∈ Si, then move ﬁnger fi to serve this request. Observe that fi only needs to do in-order
traversal in T (since the subsequence Si is increasing), which takes at most O(n) steps. Thus,
LF k

T (S) = O(nk).

By Theorem 2, we can simulate k-ﬁnger with an overhead factor of O(log k), concluding with
the following theorem.
(cid:73) Theorem 16. Let S be a k-monotone sequence. Then OP T(S) = O(|S| · k log k).

Combining easy sequences

5
Recall that for any sequence S ∈ [n]m, OPT(S) denotes the optimal cost for executing S on
a BST which contains [n] as elements. Let P = ([a1, b1], . . . , [ak, bk]) be a partitioning of [n]
into k intervals. That is, a1 = 1, bk = n and bi = ai+1 − 1. Given P, we can deﬁne S1, . . . , Sk
and ˜S as follows. For each 1 ≤ i ≤ k, Si is obtained from S by restriction to [ai, bi]. That is,
for each sj ∈ [ai, bi] starting from j = 1 to m, we append sj − ai + 1 to the sequence Si. Let
i=1 mi = m. Next, we deﬁne ˜S = (˜s1, . . . , ˜sm) ∈ [k]m.
For each j ≤ m, if sj ∈ [ai, bi], then ˜sj = i.

The main theorem of this section is the following. See Appendix H for the proof.

mi be the length of Si and hencePk
k intervals, OPT(S) ≤Pk

(cid:73) Theorem 17 (Time-interleaving Bound). For any sequence S and a partition P of [n] into

i=1 OPT(Si) + 3OPT( ˜S).

√

This theorem bounds the optimal cost of any sequence S that can be obtained by “interleaving”
k sequences S1, . . . , Sk according to ˜S. To illustrate the power of this result, we give a bound
for the optimal cost of the “tilted grid” sequence. Let ‘ =
n and consider the point set
P = {(i‘ + (j − 1), j‘ + i − 1) : i, j ∈ [‘]} . It is easy to check that there are no two points
aligning on x or y coordinates, therefore P corresponds to a permutation S ∈ [n]n. In [7]
it is shown that none of the known bounds imply OPT(S) = O(n). We observe that the
tilted grid sequence can be seen as a special case of a broad family of “perturbed grid”-type
sequences, amenable to similar analysis.
(cid:73) Corollary 18. Let S be the tilted grid sequence. Then OPT(S) = O(n).
Proof. For 1 ≤ i ≤ √
and OPT( ˜S) = O(n). By Theorem 17, OPT(S) ≤P√
length

√
√
n, let [ai, bi] = [1 + (i − 1)
√
n, i
n, and ˜S is a sequential access of length
n repeated

n]. Then Si is a sequential access of
√
n)

n times. So OPT(Si) = O(
i=1 OPT(Si) + 3OPT( ˜S) = O(n).

√

√

n

12

The landscape of bounds for binary search trees

Separations between BST bounds

6
In this section we show examples that separate the bounds to the largest extent possible.
For lack of space, we defer the proofs to § I.

We ﬁrst discuss the gap between OPT and other BST bounds. When we say that
a BST bound f is tight, we mean that there are inﬁnitely many sequences X for which
OPT(X) ≥ cf(X) for some constant c (not depending on X). It is in this sense that many
classical bounds (working set, static optimality, dynamic ﬁnger) are tight. We emphasize
that many bounds, such as k-lazy ﬁnger, k-monotone, and k-avoiding, are in fact families
of bounds (parameterized by k ∈ N), e.g. the k-monotone bounds are given by {fk} where
fk(X) = |X| · k log k if X avoids (k, . . . , 1) or (1, . . . , k). Therefore, the concept of tightness
for these bounds is somewhat diﬀerent. Our results are summarized in the following theorem.
(cid:73) Theorem 19. For each k (possibly a function that depends on n), there are inﬁnitely many
sequences S1, S2, S3, for which the following holds:

LF k(S1) · log k ≤ OPT(S1),
m(S2) = k, and OPT(S2) = Ω(|S2| · log k),
p(S3) = k, and OPT(S3) = Ω(|S3| · √
The results are derived using information-theoretic arguments. For k-monotone bounds,
this technique cannot prove OPT(S) ≥ |S| · g(k) for a super-logarithmic function g(k). For
k-avoiding bounds, the information-theoretic limit is |S| · k.

k).

Next, we show a strong separation in the hierarchy of lazy ﬁnger bounds. The results are

summarized in the following theorem.
(cid:73) Theorem 20. For any k and inﬁnitely many n, there is a sequence Sk of length n, such
that:

k log(n/k))

LF k−1(Sk) = Ω( n
LF k(Sk) = O(n) (independent of k)
Sk avoids (k + 1, k, . . . , 1)
OPT(Sk) = O(n) (independent of k)
This theorem also implies a weak separation in the class of lazy ﬁnger bounds and
monotone pattern bounds: For constant k, a sequence Sk is linear when applying the
monotone BST bound, but the lazy ﬁnger bound with k − O(1) ﬁngers would not give better
than Ω(n log n).

Finally, we show that lazy ﬁngers are not strong enough to subsume the classical bounds.
(cid:73) Theorem 21. For any k and inﬁnitely many n, there are sequences S1 and S2 of length n,
such that:

WS(S1) = o(LF k(S1)), and
LF k(S2) = o(WS(S2)).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

13

1

2

References
Susanne Albers, Lene M. Favrholdt, and Oliver Giel. On paging with locality of reference.
Journal of Computer and System Sciences, 70(2):145 – 175, 2005.
Susanne Albers and Sonja Lauer. On list update with locality of reference. In Automata,
Languages and Programming, 35th International Colloquium, ICALP 2008, Reykjavik, Ice-
land, July 7-11, 2008, Proceedings, Part I: Tack A: Algorithms, Automata, Complexity,
and Games, pages 96–107, 2008.

4

3 Brian Allen and Ian Munro. Self-organizing binary search trees. J. ACM, 25(4):526–535,

October 1978.
Prosenjit Bose, Karim Douïeb, John Iacono, and Stefan Langerman. The power and limit-
ations of static binary search trees with lazy ﬁnger. In Algorithms and Computation - 25th
International Symposium, ISAAC 2014, Jeonju, Korea, December 15-17, 2014, Proceedings,
pages 181–192, 2014.

6

5 Mihai Bădoiu, Richard Cole, Erik D. Demaine, and John Iacono. A uniﬁed access bound
on comparison-based dynamic dictionaries. Theoretical Computer Science, 382(2):86–96,
August 2007. Special issue of selected papers from the 6th Latin American Symposium on
Theoretical Informatics, 2004.
P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, and T. Saranurak. Self-adjusting
binary search trees: What makes them tick? ESA, 2015.
Parinya Chalermsook, Mayank Goswami, László Kozma, Kurt Mehlhorn, and Thatchaphol
Saranurak. Pattern-avoiding access in binary search trees. In IEEE 56th Annual Symposium
on Foundations of Computer Science, FOCS 2015, Berkeley, CA, USA, 17-20 October,
2015, pages 410–423, 2015.
Josef Cibulka. On constants in the Füredi–Hajnal and the Stanley–Wilf conjecture. Journal
of Combinatorial Theory, Series A, 116(2):290 – 302, 2009.

7

8

9 R. Cole. On the dynamic ﬁnger conjecture for splay trees. part ii: The proof. SIAM Journal

on Computing, 30(1):44–85, 2000.

11

10 Richard Cole, Bud Mishra, Jeanette Schmidt, and Alan Siegel. On the dynamic ﬁnger
conjecture for splay trees. part i: Splay sorting log n-block sequences. SIAM J. Comput.,
30(1):1–43, April 2000.
Erik D. Demaine, Dion Harmon, John Iacono, Daniel M. Kane, and Mihai Pˇatraşcu. The
geometry of binary search trees. In SODA 2009, pages 496–505, 2009.
Erik D. Demaine, Dion Harmon, John Iacono, and Mihai Pˇatraşcu. Dynamic optimality -
almost. SIAM J. Comput., 37(1):240–251, 2007.
Erik D. Demaine, John Iacono, Stefan Langerman, and Özgür Özkan. Combining binary
search trees. In Automata, Languages, and Programming - 40th International Colloquium,
ICALP 2013, Riga, Latvia, July 8-12, 2013, Proceedings, Part I, pages 388–399, 2013.

12

13

14 Amr Elmasry, Arash Farzan, and John Iacono. On the hierarchy of distribution-sensitive

properties for data structures. Acta Inf., 50(4):289–295, 2013.

15 David Eppstein. Static optimality for splay trees. http://11011110.livejournal.com/

131530.html. Accessed: 2016-02-17.
Jacob Fox. Stanley-Wilf limits are typically exponential. arXiv preprint arXiv:1310.8378,
2013.

16

18

19

17 Kyle Fox. Upper bounds for maximally greedy binary search trees. In WADS 2011, pages

411–422, 2011.
Jesse T. Geneson and Peter M. Tian. Extremal functions of forbidden multidimensional
matrices. CoRR, abs/1506.03874, 2015.
John Iacono. Key-independent optimality. Algorithmica, 42(1):3–10, 2005.

14

The landscape of bounds for binary search trees

2008.

20

21

22

John Iacono and Stefan Langerman. Weighted dynamic ﬁnger in binary search trees. In
Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms,
SODA ’16, pages 672–691. SIAM, 2016.
Joan M. Lucas. Canonical forms for competitive binary search tree algorithms. Tech. Rep.
DCS-TR-250, Rutgers University, 1988.
Joan M. Lucas. On the competitiveness of splay trees: Relations to the union-ﬁnd problem.
On-line Algorithms, DIMACS Series in Discrete Mathematics and Theoretical Computer
Science, 7:95–124, 1991.

23 Adam Marcus and Gábor Tardos. Excluded permutation matrices and the Stanley–Wilf

conjecture. Journal of Combinatorial Theory, Series A, 107(1):153 – 160, 2004.

24 K. Mehlhorn and P. Sanders. Algorithms and Data Structures: The Basic Toolbox. Springer,

25 Kurt Mehlhorn. Nearly optimal binary search trees. Acta Informatica, 5(4):287–295, 1975.
26
J.Ian Munro. On the competitiveness of linear search. In Mike S. Paterson, editor, Al-
gorithms - ESA 2000, volume 1879 of Lecture Notes in Computer Science, pages 338–345.
Springer Berlin Heidelberg, 2000.

27 Konstantinos Panagiotou and Alexander Souza. On adequate performance measures for pa-
ging. In Proceedings of the Thirty-eighth Annual ACM Symposium on Theory of Computing,
STOC ’06, pages 487–496, New York, NY, USA, 2006. ACM.

28 Amitai Regev. Asymptotic values for degrees associated with strips of Young diagrams.

Advances in Mathematics, 41(2):115–136, 1981.

29 Raimund Seidel and Cecilia R. Aragon. Randomized search trees. Algorithmica,

16(4/5):464–497, 1996.

30 Daniel D. Sleator and Robert E. Tarjan. Amortized eﬃciency of list update and paging

rules. Commun. ACM, 28(2):202–208, February 1985.

31 Daniel D. Sleator and Robert E. Tarjan. Self-adjusting binary search trees. J. ACM,

32(3):652–686, July 1985.

5(4):367–378, 1985.

32 Robert E. Tarjan. Sequential access in splay trees takes linear time. Combinatorica,

33 Chengwen C. Wang, Jonathan C. Derryberry, and Daniel D. Sleator. O(log log n)-
competitive dynamic binary search trees. In Proceedings of the Seventeenth Annual ACM-
SIAM Symposium on Discrete Algorithm, SODA ’06, pages 374–383, Philadelphia, PA,
USA, 2006. Society for Industrial and Applied Mathematics.

34 R. Wilber. Lower bounds for accessing binary search trees with rotations. SIAM Journal

on Computing, 18(1):56–67, 1989.

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

15

Bounds known to be achieved by Splay and Greedy

A
(cid:73) Theorem 22. The following relations hold for any sequence S:

[31] Splay achieves the WB, SO, SF, WS bounds.
[32] Splay achieves the sequential bound.
[9,10] Splay achieves the DF bound.
[17] Greedy achieves the WB, SO, SF, WS, and sequential bounds.
[20] Greedy achieves the WDF bound.
[7] Greedy achieves the traversal, k-avoiding, and weak k-monotone bounds.

16

The landscape of bounds for binary search trees

B

Table of BST bounds

Bounds
Balance

Weighted Balance

Entropy

Static Finger

Weighted Static Finger?

Uniﬁed Bound
Dynamic Finger

Weighted Dynamic Finger

Working Set

Static Optimality

Fixed Finger?
Lazy Finger

Acronym

B
WB
H
SF
WSF
UB
DF
WDF
WS
SO
FF
LF

minT,f

Table 1 Summary of BST bound deﬁnitions

Formula
m log n
j=1 log W
w(sj)
i=1 mi log m
j=1 log(|f − sj| + 1)
j=1 log
min{w(f),w(sj)}

w[f:sj]

mi

Pm

minf
minw,f
j=1 log(min{|f − sj| + 1, dT (sj),|wS(j)|})

minw

Pm
Pn
Pm
Pm
Pm
Pm
Pm
Pm
Pm
Pm

minT
minT,f
minT

minw

min{w(sj−1),w(sj)}

j=2 log(|sj − sj−1| + 1)
w[sj−1:sj]
j=2 log
j=1 log(|wS(j)|)
j=1 dT (sj)
j=1 dT (f, sj)
j=2 dT (sj−1, sj)

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

17

C Deterministic construction of a BST for given weights
(cid:73) Theorem 23. Given a weight function W, there is a deterministic construction of a BST
Tw such that the depth of every key i ∈ [n] is dTw(i) = O(log W
Proof. Let w1, . . . wn be a sequence of weights. We show how to construct a tree in which
the depth of element ‘ is O(log w[1 : ‘]/ min(w1, w‘)).
For i ≥ 1, let ji be minimal such that w[1 : ji] ≥ 2iw1. Then w[1 : ji − 1] < 2iw1 and
w[ji−1 + 1 : ji] ≤ 2i−1w1 + wji.
is a tree in which element ‘ has depth O(log 2i−1w1/w‘).

Let Ti be the following tree. The right child of the root is the element ji. The left subtree

w(i)).

spine to the left. In this way the depth of the root of Ti is O(i).

The entire tree has w1 in the root and then a long right spine. The trees Ti hang oﬀ the
Consider now an element ‘ in Ti. Assume ﬁrst that ‘ 6= ji. The depth is
i + log 2i−1w1
(cid:18)

(cid:18) w[1 : ‘]

For ‘ = ji, the depth is

(cid:18)
(cid:19)

= O

i + log

2i−1w1

min(w1, w‘)

2i−1w1

min(w1, w‘)

(cid:18)

O

min(w1, w‘)

= O

log

(cid:19)

= O

(cid:19)

(cid:18)

(cid:18)

(cid:19)

w‘

O (i) = O

log 2iw1
w1

= O

log w[1 : ji]
min(w1, wji)

(cid:19)

.

(cid:19)

.

18

The landscape of bounds for binary search trees

w(i) = Θ(dT (i)).

D Missing proofs from § 3.1
(cid:73) Theorem 24. WB(S) = Θ(SO(S)) for any sequence S.
Proof. WB(S) = O(SO(S)): (note2) Fix any BST T.
It suﬃces to show the existence
of a weight function w such that WBw(S) = O(SOT (S)). Deﬁne the weight function
w(i) = 4−dT (i). Observe ﬁrst that W ≤ 2 from Lemma 8 applied at the root r ∈ [n]. This
implies that for each key i ∈ [n], we have log W

SO(S) = O(WB(S)): Fix any weight function w.

tribution in Lemma 7, we have E[SOTw(S)] = E[Pm
Θ(Pm

It suﬃces to show the existence
of a BST T such that SOT (S) = O(WBw(S)). By choosing Tw according to the dis-
j=1 E[dTw(sj)] =
w(sj)) = Θ(WBw(S)). Since the expectation satisﬁes the bound, there exists a

j=1 dTw(sj)] = Pm

j=1 log W

tree T satisfying the bound.
(cid:73) Theorem 25. WSF(S) = O(FF(S)) for any sequence S.
Proof. Fix any BST T and any element f. It suﬃces to show the existence of a weight
function w such that WSF w,f(S) = O(FF T,f(S)). In particular, for all i, we show that
min{w(f),w(i)} = Θ(dT (f, i)) when we set w(i) = 4−dT (i). Let a = LCA(f, i) and hence
log
dT (f, i) = dT (f, a) + dT (a, i).
w(j) ≤ 2w(a). Therefore,

From Lemma 8 applied at node a, we have w[f : i] ≤P
min{w(f), w(i)} ≤ log
≤ log
≤ O(1) + 2 · max{dT (f) − dT (a), dT (i) − dT (a)}
= O(1) + 2 · max{dT (f, a), dT (i, a)}
≤ O(1) + 2 · dT (f, i).

min{w(f), w(i)}
2 · 4−dT (a)

min{4−dT (f), 4−dT (i)}

2w(a)

j∈Ta

w[f:i]

w[f : i]

log

(cid:73) Theorem 26. FF(S) = O(WSF(S)) for any sequence S.
Proof. Fix any weight function w and any element f. It suﬃces to show a BST T such
that FF T,f(S) = O(WSF w,f(S)). By invoking Lemma 7 with weight w, we have a distri-
j=1 E[dTw(f, sj)] =
min{w(f),w(sj)}) = Θ(WSF w,f(S)). Since the expectation satisﬁes the bound,

bution of BST Tw that satisﬁes E[FF Tw,f(S)] = E[Pm
O(Pm

j=1 dTw(f, sj)] =Pm

j=1 log

w[f:sj]

there must exist a tree T satisfying the bound.
(cid:73) Theorem 27. WSF(S) = Θ(FF(S)) for any sequence S.

So far, we have shown the equivalences between two pairs WB ⇔ SO and F F ⇔ WSF.

The following two (very simple) connections complete the proof.
(cid:73) Theorem 28. FF(S) = O(SO(S)) for any sequence S.
Proof. Fix any tree T. We set f to be the root of T, then FF T,f(S) = SOT (S).

2In [31] it is shown that WB(S) = O(H(S)) and since H(S) = Θ(SO(S)), this implies that WB(S) =

O(SO(S)). We include a proof for completeness.

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

19

(cid:73) Theorem 29. WB(S) = O(FF(S)) for any sequence S.

Proof. Fix any weight function w associated with the weighted static ﬁnger bound. It suﬃces
to show a weight function w such that WBw(S) = O(FF T,f(S)). In particular, for all i,
w(i) = Θ(dT (f, i)) when we set w(i) = 4−dT (f,i). This follows because
we show that log W
i=1 w(i) ≤

the number of elements with distance d from i is at most 3d, and so W = Pn
P
d<∞ 3d · 4−d = O(1).

20

The landscape of bounds for binary search trees

The static optimality of Greedy

E
In the geometric view where Greedy is deﬁned [11], the role of the subtree T(i) rooted at i is
played be the neighborhood T(i) of element i. The deﬁnition of neighborhood can be found
in [6,17].
(cid:73) Theorem 30. The amortized cost of Greedy for accessing element i is O(dR(i)).
Proof. Suppose that Greedy, for accessing i, touches x−l, x−l+1, . . . , x0 = i, x1, . . . , xr. We
only bound the amortized cost for touching x0, x1, . . . , xr. The analysis for the other elements
is symmetric. Let ϕ(x) and ϕ0(x) be the potential of an element x before, respectively after
accessing i. Deﬁne ϕ(xi) = ϕ0(xi) = 0 for i > r. Note that ϕ(i), ϕ0(i) ≤ 0 for all i. Also, for
any j ∈ T(i), ϕ(j) ≤ ϕ(i). The crucial observation is that, for any i ≤ r − 3,

2 + ϕ0(xi) + ϕ0(xi+2) ≤ 2ϕ(xi+3).

This follows from Fact 1 and the facts that T 0(xi) ∩ T 0(xi+2) = ∅ and T 0(xi), T 0(xi+2) ⊂
T 0(xi+3). Therefore, the amortized cost is

X
X
X
X

4 + ϕ0(xi) + ϕ0(xi+1) + ϕ0(xi+2) + ϕ0(xi+3) − X
(2 + ϕ0(xi) + ϕ0(xi+2)) + (2 + ϕ0(xi+1) + ϕ0(xi+3)) − X
2ϕ(xi+3) + 2ϕ(xi+4) − X
ϕ(xi+3) + ϕ(xi+4) + ϕ(xi+5) + ϕ(xi+6) − X

ϕ(xi)

ϕ(xi)

ϕ(xi)

0≤i≤r

0≤i≤r

0≤i≤r

ϕ(xi)

0≤i≤r

X

0≤i≤r

1 + ϕ0(xi) − ϕ(xi) =

=

≤

0≤i≤r−3,i mod 4=0

0≤i≤r−3,i mod 4=0

0≤i≤r−3,i mod 4=0

0≤i≤r−3,i mod 4=0

≤
≤ −ϕ(x0) − ϕ(x1) − ϕ(x2)
≤ −3ϕ(x0)
= O(dR(x0)).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

21

F Missing proofs from § 3.3
(cid:73) Lemma 31 ( [3]). Let i < k. Then i is an ancestor of k after serving S if either i was
accessed and there was no access to a key in [i + 1, . . . , k] after the last access to i or i and k
were not accessed and i is an ancestor of k in the initial tree.

This implies that we obtain the same ﬁnal tree if we delete all but the last access to each

element from the access sequence.

We use the following property of the Move-to-root algorithm.

(cid:73) Fact 2. Let S = (s1, . . . , sm) be an access sequence. Before accessing sj, for any j0 < j,
the keys sj0, sj0+1, . . . , sj form a connected component containing the root of T 0.

Now we are ready to prove the main theorem of the section.

where f(n) =Pn

(cid:73) Theorem 32. For any sequence S and any initial tree T, KI-MTRT (S) = O(WS(S)+f(n))

i=1 dT (i) depends only on n (and not on m).

Proof. We ﬁrst ananalyze the cost of non-ﬁrst accesses sπ(j). Consider the accesses sρS(j), sρS(j)+1, . . . , sj−1
where sρS(j) = sj, and s‘ 6= s‘0 for all ‘, ‘0 ∈ {ρS(j), . . . , j − 1}: These elements are stored in
a connected subtree T 0 containing the root and T 0 is also formed if we deleted all but the last
access to any element from this sequence. More formally, let J ⊆ {ρS(j), . . . , j − 1} be the
set indices i for which si is the last appearance of its key in wS(j). So we have |J| = |wS(j)|.
The expected access cost of π(sj) is exactly the expected number of its ancestors in T 0:

X

P rπ[ π(s‘) is ancestor of π(sρS(j))]

‘∈J
If π(s‘) > π(sj), then the key π(s‘) is an ancestor of π(sj) only if π(s‘) = min {π(s‘0)}‘0∈J,‘0≥‘

(due to Lemma 31). Otherwise,
max {π(s‘0)}‘0∈J,‘0≥‘. In any case, this probability is exactly

expected access cost of π(sj) is at mostP

if π(s‘) < π(sj),

1

‘∈J

it is an ancestor only if π(s‘) =
|J ∩ [‘, j]|. Therefore, the

1

|J ∩ [‘, j]| = O(log |J|) = O(log |wS(j)|).

Consider next a ﬁrst access sj. By 2, the elements s1, s2, . . . , sj−1 form a connected
subtree T 0 containing the root. An argument similar to the one above shows that the expected
depth of T 0 is O(log |wS(j)|). So the expected length of the search path of sj is at most
O(log |wS(j)|) + dT (sj)).

Thus, the total cost isPm

j=1 O(log |wS(j)|) + O(Pn

i=1 dT (i)) = O(WS(S) + f(n)).

It follows that key-independent Move-to-root (starting from a balanced tree), key-independent
optimality, and working set bounds are all equivalent when the length of the sequence is
m ≥ n log n.
(cid:73) Corollary 33. Let T be a BST of logarithmic depth. Then, KI-MTRT (S) = Θ(KI-OPT(S)+
n log n) = Θ(WS(S) + n log n) for any sequence S.
Proof. We trivially have KI-OPT(S) ≤ KI-MTRT (S). By Theorems 11 and 32, we have
KI-MTRT (S) = O(WS(S) + n log n) = O(KI-OPT(S) + n log n). This sandwiches the
quantities.

22

The landscape of bounds for binary search trees

Proofs from Section 4

G
G.1 Simulating k-Lazy ﬁngers
(cid:73) Theorem 34. For any sequence S, OP T(S) ≤ O(log k) · LF k(S).

To prove this theorem, we reﬁne the result in [13] which shows how to simulate a k-ﬁnger
BST using a standard BST. In a k-ﬁnger BST there are k pointers, and each of these can
move to its parent or to one of its children. Moreover, the position of a ﬁnger is maintained
while performing rotations.

When we execute an access sequence using k-ﬁnger BST, each ﬁnger is initially at the
root. We specify an initial tree. For each access, one of the k ﬁngers must move to the
accessed element. After each access the ﬁngers remain in their position, instead of moving to
the root, as in the standard BST model.

The cost for accessing a sequence is the total number of ﬁnger moves and rotations.
Given an online k-ﬁnger algorithm AkBST , we deﬁne an online BST algorithm Asim(AkBST )
that simulates AkBST . In [13] it is shown that this can be achieved with a factor O(k)
increase in cost. We strengthen the result by showing the following result.
(cid:73) Theorem 35. There is a BST algorithm for simulating a k-ﬁnger BST with overhead
factor O(log k).

From Theorem 35 we immediately get Theorem 34 as a corollary. This is because
the model which deﬁnes the k-lazy ﬁnger bound LF k(·) is exactly k-ﬁnger BST except
that the tree is static. LF k(S) is the cost of k-ﬁnger BST on the optimal static tree. If
we can simulate any k-ﬁnger BST algorithm with overhead O(log k), then we can indeed
simulate any k-ﬁnger BST algorithm on any static tree, including the optimal tree. Therefore,
OP T(S) ≤ LF k(S) · O(log k) for any sequence S.

The rest of this section is devoted to the proof of Theorem 35. We use the approach
from [13]. We are simulating a k-ﬁnger BST T using a standard BST T 0. The ingredients of
the proof are: (1) To make sure that each element with a ﬁnger on it in T has depth at most
O(log k) in T 0. (In [13], each ﬁnger may have depth up to O(k) in T 0.) (2) To implement a
deque data structure within T 0 so that each ﬁnger in T can move to any of its neighbors
with cost O(log k) amortized. (In [13], this cost is O(1) amortized.) Therefore, to move a
ﬁnger f to its neighbor x in T, we can simply access f from the root of T 0 in O(log k) steps,
and then move f to x in T 0 in O(1) amortized steps. Hence, the overhead factor is O(log k).

G.1.1 DequeBST
We describe how to implement a deque in the BST model, called dequeBST. This is be used
later in the simulation. The following construction appears to be folklore, and it is the same
as the one used in [13]. As we have not found an explicit description in the literature, we
include it here for completeness.
(cid:73) Lemma 36. The minimum and maximum element from a dequeBST can be deleted in
O(1) amortized operations.

Proof. The simulation is inspired by the well-known simulation of a queue by two stacks
with constant amortized time per operation ( [24, Exercise 3.19]). We split the deque at
some position (determined by history) and put the two parts into structures that allow us to
access the ﬁrst and the last element of the deque. It is obvious how to simulate the deque

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

23

operations as long as the sequences are non-empty. When one of the sequences becomes
empty, we split the other sequence at the middle and continue with the two parts. A simple
potential function argument shows that the amortized cost of all deque operations is constant.
Let ‘1 and ‘2 be the length of the two sequences, and deﬁne the potential Φ = |‘1 − ‘2|. As
long as neither of the two sequences are empty, for every insert and delete operation both
the cost and the change in potential are O(1). If one sequence becomes empty, we split the
remaining sequence into two equal parts. The decrease in potential is equal to the length of
the sequence before the splitting (the potential is zero after the split). The cost of splitting
is thus covered by the decrease of potential.

The simulation by a BST is easy. We realize both sequences by chains attached to the
root. The right chain contains the elements in the second stack with the top element as the
right child of the root, the next to top element as the left child of the top element, and so
on.

G.1.2 Extended Hand
To describe the simulation precisely, we borrow terminology from [13]. Let T be a BST with a
set F of k ﬁngers f1, . . . , fk. For convenience we assume the root of T to be one of the ﬁngers.
Let S(T, F) be the Steiner tree with terminals F. A knuckle is a connected component of
T after removing S(T, F). Let P(T, F) be the union of ﬁngers and the degree-3 nodes in
S(T, F). We call P(T, F) the set of pseudoﬁngers. A tendon τx,y is the path connecting two
pseudoﬁngers x, y ∈ P(T, F) (excluding x and y) such that there is no other z ∈ P(T, F)
inside. We assume that x is an ancestor of y.

The next deﬁnitions are new. For each tendon τx,y, there are two half tendons, τ <

x,y, τ >

x,y | τx,y is a tendon} be the set of all half tendons.

x,y, τ >
x,y
containing all elements in τx,y which are less than y and greater than y respectively. Let
H(T, F) = {τ <
For each τ ∈ H(T, F), we can treat τ as an interval [min(τ), max(τ)] where min(τ), max(τ)
are the minimum and maximum elements in τ respectively. For each f ∈ P(T, F), we can
treat f as an trivial interval [f, f].
Let E(T, F) = P(T, F) ∪ H(T, F) be the set of intervals deﬁned by all pseudoﬁngers
P(T, F) and half tendons H(T, F). We call E(T, F) an extended hand3. Note that when we
treat P(T, F) ∪ H(T, F) as a set of elements, such a set is exactly S(T, F). So E(T, F) can
be viewed as a partition of S(T, F) into pseudoﬁngers and half-tendons.

We ﬁrst state two facts about the extended hand.

(cid:73) Lemma 37. Given any T and F where |F| = k, there are O(k) intervals in E(T, F).
Proof. Note that |P(T, F)| ≤ 2k because there are k ﬁngers and there can be at most k
nodes with degree 3 in S(T, F). Consider the graph where pseudoﬁngers are nodes and
tendons are edges. That graph is a tree. So |H(T, F)| = O(k) as well.
(cid:73) Lemma 38. Given any T and F, all the intervals in E(T, F) are disjoint.
Proof. Suppose that there are two intervals τ, x ∈ E(T, F) that intersect each other. One of
them, say τ, must be a half tendon. Because the intervals of pseudoﬁngers are of length zero
and they are distinct, they cannot intersect. We write τ = {t1, . . . , tk} where t1 < ··· < tk.
Assume w.l.o.g. that ti is an ancestor of ti+1 for all i < k, and so tk is an ancestor of a
pseudoﬁngers f where tk < f.

3In [13], they deﬁne a hand which involves only the pseudoﬁngers.

24

The landscape of bounds for binary search trees

Suppose that x is a pseudoﬁnger and tj < x < tj+1 for some j. Since tj is the ﬁrst
left ancestor of tj+1, x cannot be an ancestor of tj+1 in T. So x is in the left subtree of
tj+1. But then tj+1 is a common ancestor of two pseudoﬁngers x and f, and tj+1 must be a
pseudoﬁnger which is a contradiction.
Suppose next that x = {x1, . . . , x‘} is a half tendon where x1 < ··· < x‘. We claim that
either [x1, x‘] ⊂ [tj, tj+1] for some j or [t1, tk] ⊂ [xj0, xj0+1] for some j0. Suppose not. Then
there exist two indices j and j0 where tj < xj0 < tj+1 < xj0+1. Again, xj0 cannot be an
ancestor of tj+1 in T, so xj0 is in the left subtree of tj+1. We know either xj0 is the ﬁrst left
ancestor of xj0+1 or xj0+1 is the ﬁrst right ancestor of xj0. If xj0 is an ancestor of xj0+1, then
xj0+1 < tj+1 which is a contradiction. If xj0+1 is the ﬁrst right ancestor of xj0, then tj+1
is not the ﬁrst right ancestor of xj0 and hence xj0+1 < tj+1 which is a contradiction again.
Now suppose w.l.o.g. [x1, x‘] ⊂ [tj, tj+1]. Then there must be another pseudoﬁnger f0 in the
left subtree of tj+1, hence τ cannot be a half tendon, which is a contradiction.

G.1.3 The structure of the simulating BST
In this section, we describe the structure of the BST T 0 that we maintain given a k-ﬁnger
BST T and the set of ﬁngers F.

For each half tendon τ ∈ H(T, F), let T 0

τ be the tree with min(τ) as a root which has
max(τ) as a right child. max(τ)’s left child is a subtree containing the remaining elements
τ \ {min(τ), max(τ)}. We implement a dequeBST on this subtree as deﬁned in § G.1.1. By
Lemma 38, intervals in E(T, F) are disjoint and hence they are totally ordered. Since E(T, F)
is an ordered set, we can deﬁne T 0
E0 to be a balanced BST such that its elements correspond
to elements in E(T, F). Let T 0
E0 by replacing each node a in
E0 that corresponds to a half tendon τ ∈ H(T, F) by T 0
T 0
τ. That is, suppose that the parent,
left child, and right child are au, al and ar respectively. Then the parent in T 0
E of the root of
T 0
τ which is min(τ) is aup. The left child in T 0
E of
max(τ) is ar.

E of min(τ) is al and the right child in T 0

E be the BST obtained from T 0

E as its top part and each knuckle of T hangs from T 0

E in a determined

The BST T 0 has T 0

E, and hence in T 0.

way.
(cid:73) Lemma 39. Each element corresponding to pseudoﬁnger f ∈ P(T, F) has depth O(log k)
in T 0
Proof. By Lemma 37, |E(T, F)| = O(k). So the depth of T 0
corresponding to a pseudoﬁnger f ∈ P(T, F), observe that the depth of a in T 0
twice the depth of a in T 0

E0 is O(log k). For each node a
E is at most

E0 by the construction of T 0
E.

G.1.4 The cost for simulating the k-ﬁnger BST
We ﬁnally prove Theorem 35. That is, we prove that whenever one of the ﬁngers in a k-ﬁnger
BST T moves to its neighbor or rotates, we can update the maintained BST T 0 to have the
structure as described in the last section with cost O(log k).

We state two observations which follow from the structure of our maintained BST T 0

described in § G.1.3. The ﬁrst observation follows immediately from Lemma 36.
(cid:73) Fact 3. For any half tendon τ ∈ H(T, F), we can insert or delete the minimum or maximum
element in T 0
Next, it is convenient to deﬁne a set A, called active set, as a set of pseudoﬁngers, the roots
of knuckles whose parents are pseudoﬁngers, and the minimum or maximum of half tendons.

τ with cost O(1) amortized.

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

25

(cid:73) Fact 4. When a ﬁnger f in a k-ﬁnger BST T moves to its neighbor or rotates with its
parent, the extended hand E(T, F) = P(T, F) ∪ H(T, F) is changed as follows.
1 There are at most O(1) half tendons τ ∈ H(T, F) whose elements are changed. Moreover,
for each changed half tendon τ, either the minimum or maximum is inserted or deleted.
The inserted or deleted element a was or will be in the active set A.

2 There are at most O(1) elements added or removed from P(T, F). Moreover, the added

or removed elements were or will be in the active set A.

(cid:73) Lemma 40. Let a ∈ A be an element in the active set. We can move a to the root with
cost O(log k) amortized. Symmetrically, the cost for updating the root r to become some
element in the active set is O(log k) amortized.

τ (make a a parent of T 0

Proof. There are two cases. If a is a pseudoﬁnger or a root of a knuckle whose parent is
pseudoﬁnger, we know that the depth of a was O(log k) by Lemma 39. So we can move a to
root with cost O(log k). Next, if a is the minimum or maximum of a half tendon τ, we know
that the depth of the root of the subtree T 0
τ is O(log k). Moreover, by 3, we can delete a
from T 0
τ) with cost O(1) amortized. Then we move a to root with
cost O(log k) worst-case. The total cost is then O(log k) amortized. The proof for the second
statement is symmetric.
(cid:73) Lemma 41. When a ﬁnger f in a k-ﬁnger BST T moves to its neighbor or rotates with
its parent, the BST T 0 can be updated accordingly with cost O(log k) amortized.
Proof. According to 4, we separate our cost analysis into two parts.

For the ﬁst part, let a ∈ A be the element to be inserted into a half tendon τ. By
Lemma 40, we move a to root with cost O(log k) and then insert a as a minimum or
maximum element in T 0
τ with cost O(log k). Deleting a from some half tendon with cost
O(log k) is symmetric.
For the second part, let a ∈ A be the element to be inserted into a half tendon τ. By
E0 with

Lemma 40 again, we move a to root and move back to the appropriate position in T 0
cost O(log k). We also need rebalance T 0
Proof. [Proof of Theorem 35] We describe the simulation algorithm Asim with overhead
O(log k). Let AkBST be an arbitrary algorithm for the k-ﬁnger BST T. Whenever there is an
update in the k-ﬁnger BST T (i.e. a ﬁnger moves to its neighbor or rotates), Asim(AkBST )
updates the BST T 0 according to Lemma 41 with cost O(log k) amortized. T 0 is maintained
so that its structure is as described in § G.1.3. By Lemma 39, we can access any ﬁnger f
of T from the root of T 0 with cost O(log k). Therefore, the cost of Asim(AkBST ) is at most
O(log k) times the cost of AkBST .

E0 but this also takes cost O(log k).

G.2 Lazy ﬁnger bounds with auxiliary elements
Recall that LF(S) is deﬁned as the minimum over all BSTs T over [n] of LFT (S). It is
convenient to deﬁne a slightly stronger lazy ﬁnger bound that also allows auxiliary elements.

DeﬁnedLF(S) as the minimum over all binary search trees T that contains the keys [n] (but
the size of T can be much larger than n). We deﬁne dLF
(cid:73) Theorem 42. For any integer k, LF k(S) = Θ(dLF

k(S) as the k-lazy ﬁnger bound
when the tree is allowed to have auxiliary elements. We argue that the two deﬁnitions are
equivalent.

k(S)) for all S.

26

The landscape of bounds for binary search trees

Proof. It is clear thatdLF

k(S) ≤ LF k(S). We only need to show the converse.
Let T be the binary search tree (with auxiliary elements) such that LF k

k(S).
Denote by ~f the optimal ﬁnger strategy on T. Let [n] ∪ X be the elements of T where X is
the set of auxiliary elements in T. For each a ∈ [n] ∪ X, let dT (a) be the depth of key a in
T, and let w(i) = 4−dT (i). For any two elements i and j and set Y ⊆ [n] ∪ X, let wY [i : j]
k∈Y ∩[i,j] w(i). For any i, j ∈ [n] ∪ X such that i ≤ j, we have

T (S) =dLF

be the sum of the weightP
lg w[n]∪X[i : j]
min(w(i), w(j)) = O(dT (i, j)),

where dT (i, j) is the distance from i to j in T. So, this same bound also holds when
considering only keys in [n]. That is, for i, j ∈ [n], we have

lg

w[n][i : j]

min(w(i), w(j)) = O(dT (i, j)).

Given the weight of {w(a)}a∈[n], the BST T 0 (without auxiliary elements) is constructed

by invoking Lemma 7. We bound the term LF k

O(X

t

dT 0(sσ(ft,t), st)) = O(

lg

dT (sσ(ft,t), st)) = O(LF k

T (S))

m−1X

t=1

w[n][st : sσ(ft,t)]

T 0(S) (using strategy ~f) by

m−1X
min(w(si), w(sσ(ft,t)))) = O(
T (S)) = O(dLF

T 0(S) = O(LF k

t=1

k(S)).

where S = (s1, . . . , sm). Therefore, LF k(S) ≤ LF k

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

27

H Proofs from Section 5
H.1 Auxiliary Elements
For any X ⊂ Q ﬁnite subset of rational numbers, we let OPTX(S) be the optimal cost for
executing S on a BST which contains [n] ∪ X as elements. We call X auxiliary elements. Let
OPTaux(S) = minX OPTX(S). The following theorem shows that auxiliary elements never
improve the optimal cost.
(cid:73) Theorem 43. OPT(S) = OPTX(S) for any sequence S and auxiliary elements X.
Proof. It is clear that OPTX(S) ≤ OPT(S), because we can start with the initial tree such
that no element in X is above any element in [n], and then use an optimal algorithm on a
BST with [n] as elements to arrange the tree without touching any element in X.
Next, to show that OPT(S) ≤ OPTX(S), we will prove that for any Y ⊂ Q and another
number y ∈ Q \ Y , OPTY (S) ≤ OPTY ∪{y}(S). It suﬃces to prove that, given an optimal
BST algorithm A for executing S on a BST TA with [n]∪ Y ∪{y} as elements, we can obtain
another BST algorithm B on a BST TB with [n] ∪ Y as elements whose cost for execute S is
at most the cost of A which is OPTY ∪{y}(S).
Let y0 ∈ [n] ∪ Y be either the predecessor or successor of y. At each time, the algorithm
B arranges the elements such that the depth of y0 is dTB(y0) = min{dTA(y0), dTA(y)} and
the relative depth of other elements [n] ∪ Y \ {y0} in TB are equivalent as the corresponding
elements in TA. Observe that, for any element i ∈ [n] ∪ Y , the search path of i in TB is a
subset of the search path of i in TA. So the cost of B at any access is at most of the cost of
A. This conclude the proof.

H.2 Proof of Interleaving Bound
Before we can prove Theorem 17, we need one lemma.
(cid:73) Lemma 44. For any sequence S ∈ [n]m, there is a BST algorithm A on a BST TA with
[n] ∪ X as elements where X is some set of auxiliary elements and all elements in [n] are
maintained as leaves in TA. Moreover, the cost of A is at most 3OPT(S).

Proof. Let B be an optimal BST algorithm on a BST TB with [n] as elements for executing
S. To construct TA, for each element i, we replace i in TB with three elements iL, iR, i where
i − 1 < iL < i < iR < i + 1 and iL is always a parent of iR which is always a parent of i.
Therefore, dTA(i) = 3dTB(3) and i is leaf, for each i ∈ [n]. After each access, if B rearranges
TB, we rearrange TA accordingly, which costs at most 3 times as much.

the cost for accessing S is at mostPk

Proof. [Proof of Theorem 17] Let P = ([a1, b1], . . . , [ak, bk]) be the partition of [n] from the
theorem. We show a BST algorithm A on a BST TA with some auxiliary elements such that
i=1 OPT(Si) + 3OPT( ˜S).
To describe TA, we construct a BST ˜TA that has [k] as leaves using Lemma 44. Then, for
each leaf i ∈ [k], we replace i with the root of a subtree T
(i)
A containing elements in [ai, bi].
A for all i ∈ [k]. To
That is, the auxiliary elements in ˜TA are always above elements in T
(i)
describe the algorithm A, if an element x ∈ [ai, bi] is accessed, we ﬁrst access the root of T
(i)
A
(i)
using an algorithm from Lemma lem:integer as leaves, and then we access x inside T
A using
the optimal algorithm for executing Si. By Lemma lem:integer as leaves, the total cost spent
in ˜TA is 3OPT( ˜S), and the total cost spent in T

(i)
A is OPT(Si) for each i.

28

The landscape of bounds for binary search trees

I Omitted Proofs from Section 6
I.1 Proof of Theorem 19
All bounds are derived via information-theoretic arguments. To avoid the need to do
probabilistic analysis, we use instead the language of Kolmogorov complexity, which is
applicable to a speciﬁc input, rather than a distribution on inputs. First, we state the
following proposition.
(cid:73) Lemma 45 ( [7]). For any sequence S, let K(S) denote Kolmogorov complexity of S. We
have K(S) = O(OPT(S)).

We also use the following standard fact in the theory of Kolmogorov complexity.

(cid:73) Lemma 46. Let S be a subset of sequences in [n]m. There exists a sequence S ∈ S with
K(S) = Ω(log |S|).

We are now ready to derive all bounds.

(cid:73) Theorem 47 (k-lazy ﬁngers). For each k (possibly a function that depends on n), there
are inﬁnitely many sequences X, for which LF k(S) · log k ≤ OPT(S).
Proof. Let J ⊆ [n] : |J| = k. We choose a sequence S ∈ J m that has Kolmogorov complexity
at least K(S) = Ω(m log k), so we have OPT(S) = Ω(m log k). Now we argue that the lazy
ﬁnger cost is low. Choose the reference tree as an arbitrary balanced tree T. Notice that the
lazy ﬁnger bound is LF k
T (S) = O(m): Initial ﬁngers can be chosen to be the location of keys
in J. Afterwards, each key in J is served by its private ﬁnger.
(cid:73) Theorem 48 (Monotone). For each k, there are inﬁnitely many sequences S for which
m(S) = k, and K(S) ≥ |S| · log k.

Proof. This follows from the result of Regev [28] (who proved much more general results) which
implies that for suﬃciently large n, the number of permutations S ∈ [n]n that avoid (1, . . . , k)
is at least kΩ(n). Therefore, there exists a permutation S with K(S) = Ω(n log k).

√

Pattern avoidance.
We argue that there is a permutation sequence S of size n that avoids a pattern of size k (an
indication of easiness) but nevertheless has high Kolmogorov complexity K(S) = Ω(n
k).
Let π be a permutation of size k. Let Sπ(n) be the number of permutations of size n
avoiding π, and let L(π) = limn→∞ Sπ(n)1/n. Let ex(n, π) be the maximum number of
non-zeros of an n × n matrix that avoids π, and let c(π) = ex(n, π)/n. Cibulka [8] shows
that c(π) = O(L(π)4.5) and L(π) = c(π)2; for a simpler proof of the second result see [16].
(cid:73) Theorem 49 ( [8,16]). c(π) = L(π)Θ(1).
In [16], Fox also shows the surprising result that there exists a permutation π of size k such
that c(π) = 2Ω(k1/4)It is also shown in [16] that for any π of size k, c(π) = 2O(k), improving
the celebrated result of 2O(k log k) by Marcus and Tardos [23]. Geneson and Tian [18] improve
the lower bound as follows.
(cid:73) Theorem 50 ( [18]). There exists π of size k where c(π) = 2Ω(k1/2).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

29

Combining Theorem 49 and Theorem 50, we have that there exists π such that L(π) =
2Ω(k1/2). By the deﬁnition of L(π), we conclude that there is a permutation π of size k and
inﬁnitely many integers n such that Sπ(n) = Ω(2n
k). Let P be such a set of permutations.
We know that there must be a permutation S ∈ P such that the Kolmogorov complexity of
S is K(S) = Ω(n

k).

√

√

I.2 Proof of Theorem 20
Let n be an integer multiple of k and ‘ = n/k. Consider the tilted k-by-‘ grid Sk. The access
sequence is 1, ‘ + 1, . . . , ‘ · (k − 1) + 1, 2, ‘ + 2, . . . , (k − 1)‘ + 2,. . . , (k − 1)‘ + ‘. It is clear
that this sequence avoids (k + 1, k, . . . , 1), so the third part of the theorem follows easily.

(cid:9)k

2

with k leaves. Each leaf of T0 corresponds to the keys(cid:8)‘ · (i − 1) + 1

We now show that LF k(Sk) = O(n). We write Sk = (s1, . . . , sn). The idea is to partition
the keys into blocks, and use each ﬁnger to serve only the keys inside blocks. In particular,
for each i = 1, . . . , k, denote by Bi ⊆ [n] the set of keys in [‘(i − 1) + 1, ‘ · i]. We create a
reference tree T and argue that LF k
T (Sk) = O(n). Let T0 be a BST of height O(log k) and
i=1. The non-leafs
of T0 are assigned arbitrary fractional keys that are consistent with the BST properties.
For each i, path Pi is deﬁned as a BST with key ‘ · (i − 1) + 1 at the root, where for each
j = 0, . . . , (‘ − 1), the key ‘(i − 1) + j has ‘(i − 1) + (j + 1) as its only (right) child. The
ﬁnal tree T is obtained by hanging each path Pi as a left subtree of a leaf ‘ · (i − 1) + 1
2. The
k-server strategy is simple: The ith ﬁnger only takes care of the elements in block Bi. The
cost for the ﬁrst access in block Bi is O(log k), and afterwards, the cost is only O(1) per
access. So the total access cost is O( n
k be obtained from Sk by restriction to Bi for
(i)
each i = 1, . . . , k. Let ˜Sk = (˜s1, . . . , ˜sn) ∈ [k]n where ˜sj = i iﬀ sj ∈ Bi. By Theorem 17,
(i)
k
is just a sequential access of size ‘. OPT( ˜Sk) = O(k · ‘) = O(n) because ˜Sk a sequential
access of size k repeated ‘ times. Therefore, OPT(Sk) = O(n).
The rest of this section is devoted to proving the following:

k ) + O(OPT( ˜Sk)). But, for each i, OPT(S
(i)

OPT(Sk) ≤Pk

To see that OPT(Sk) = O(n), let S

k log k + n) = O(n).

i=1 OPT(S

(i)
k ) = O(‘) because S

(cid:73) Theorem 51. LF k−1(Sk) = Ω( n

k log(n/k))

A ﬁnger conﬁguration ~f = (f(1), . . . , f(k − 1)) ∈ [n]k−1 speciﬁes to which keys the ﬁngers
are currently pointing. Let T be a reference tree. Any ﬁnger strategy can be described by a
sequence ~f1, . . . , ~fn, where ~ft is a conﬁguration after element st is accessed. Just like in a
general k-server problem, we may assume w.l.o.g. the following:
(cid:73) Fact 5. For each time t, the conﬁgurations ~ft and ~ft+1 diﬀer at exactly one position. In
other words, we only move the ﬁnger that is used to access st+1.

We see the input sequence Sk as having ‘ phases: The ﬁrst phase contains the subsequence

1, ‘ + 1, . . . , ‘(k − 1) + 1, and so on. Each phase is a subsequence of length k.
(cid:73) Lemma 52. For each phase p ∈ {1, . . . , ‘}, there is time t ∈ [(p− 1)‘ + 1, p· ‘] such that st
is accessed by ﬁnger j such that ft−1(j) and ft(j) are in diﬀerent blocks, and ft−1(j) < ft(j).
That is, this ﬁnger moves to the block Bb, b = t mod k, from some block Bb0, where b0 < b,
in order to serve st.

Proof. Suppose not. By 5, this implies that each ﬁnger is used to access each element only
once in this phase (because accesses in this phase are done in blocks B1, . . . ,Bk in this order).
This is impossible because we only have k − 1 ﬁngers.

30

The landscape of bounds for binary search trees

For each phase p ∈ [‘], let tp denote the time for which such a ﬁnger moves across
the blocks from left to right; if they move more than once, we choose tp arbitrarily. Let
p=1. For each ﬁnger j ∈ [k − 1], each block i ∈ [k] and block i0 ∈ [k] : i < i0, let
J = {tp}‘
J(j, i, i0) be the set containing the time t for which ﬁnger f(j) is moved from block Bi to
k = ‘, due
to the lemma. Let P(j, i, i0) denote the phases p for which tp ∈ J(j, i, i0).

block Bi0 to access st. Let c(j, i, i0) = |J(j, i, i0)|. Notice thatP
(cid:73) Lemma 53. P

j,i,i0:c(j,i,i0)≥16 c(j, i, i0) ≥ n/2k if n = Ω(k4).

j,i,i0 c(j, i, i0) = n

Proof. There are only at most k3 triples (j, i, i0), so the terms for which c(j, i, i0) < 16
contribute to the sum at most 16k3. This means that the sum of the remaining is at least
n/k − 16k3 ≥ n/2k if n satisﬁes n = Ω(k4).

From now on, we consider the sets J0 and J0(j, i, i0) that only concern those c(j, i, i0) with

c(j, i, i0) ≥ 16 instead.
(cid:73) Lemma 54. There is a constant η > 0 such that the total access cost during the phases
P(j, i, i0) is at least ηc(j, i, i0) log c(j, i, i0).

Once we have this lemma, everything is done. Since the function g(x) = x log x is convex,

we apply Jensen’s inequality to obtain:

X

j,i,i0

1
|J0|

ηc(j, i, i0) log c(j, i, i0) ≥ η( n

2k|J0|) log(n/2k|J0|).

Note that the left side is the term E[g(x)], while the right side is g(E(x)). Therefore, the
8k log(n/2k), due to the fact that |J0| ≤ k3. We now prove the
total access cost is at least ηn
lemma.

Proof. [Proof of Lemma 54] We recall that, in the phases P(j, i, i0), the ﬁnger-j moves from
block Bi to Bi0 to serve the request at corresponding time. For simplicity of notation, we
use ˜J and C to denote J(j, i, i0) and c(j, i, i0) respectively. Also, we use ˜f to denote the
ﬁnger-j. For each t ∈ ˜J, let at ∈ Bi be the key for which the ﬁnger ˜f moves from at to st
when accessing st ∈ Bi0. Let ˜J = {t1, . . . , tC} such that at1 < at2 < . . . < atC. Let R be the
lowest common ancestor in T of keys in [atbC/2c+1, atC].
(cid:73) Lemma 55. For each r ∈ {1, . . . ,bC/2c}, the access cost of str and stC−r is together at
least min{dT (R, str), dT (R, stC−r)}.

Proof. Let ur be the lowest common ancestor between atr and str. If str is in the subtree
rooted at R, then the cost must also be at least dT (ur, str) ≥ dT (R, str) as ur must be an
ancestor of R (because atr < atbC/2c < atC < str). Otherwise, we know that str is outside of
the subtree rooted at R, and so is stC−r. On the other hand, atC−r is in such subtree, so
moving the ﬁnger from atC−r to stC−r must touch R, therefore costing at least dT (R, stC−r).

Lemma 55 implies that, for each r = 1, . . . ,bC/2c, we pay the distance between some
r dT (R, vr). Applying the
fact that (i) vr’s are diﬀerent and (ii) there are at most 3d vertices at distance d from a

element vr ∈(cid:8)str , stC−r
vertex R, we conclude that this sum is at leastP

(cid:9) to R. The total such costs would beP

r dT (R, vr) ≥ Ω(C log C).

P. Chalermsook, M. Goswami, L. Kozma, K. Mehlhorn, T. Saranurak

31

I.3 Working set and k-lazy ﬁnger bounds are incomparable

We show the following.

(cid:73) Theorem 56.

There exists a sequence S such that WS(S) = o(LF k(S)), and
There exists a sequence S

0 such that LF k(S

0) = o(WS(S

0)).

The sequence S

0 above is straightforward: For k = 1, just consider the sequential access
1, . . . , n repeated m/n times. For m large enough, the working set bound is Ω(m log n).
However, if we start with the ﬁnger on the root of the tree which is just a path, then the
lazy ﬁnger bound is O(m). The k-lazy ﬁnger bound is always less than lazy ﬁnger bound, so
this sequence works for the second part of the theorem.

The existence of the sequence S is slightly more involved (the special case for k = 1 was
proved in [4]), and is guaranteed by the following theorem, the proof of which comprises the
remainder of this section.

(cid:73) Theorem 57. For all k = O(n1/2−), there exists a sequence S of length m such that
WS(S) = O(m log k) whereas LF k(S) = Ω(m log(n/k)).

We construct a random sequence S and show that while WS(S) = O(m log k) with
T (S) ≤ cm log3(n/k)
probability one, the probability that there exists a tree T such that LF k
is less than 1/2 for some constant c < 1. This implies the existence of a sequence S such
that for all trees T, LF k

T (S) = Ω(m log(n/k)).

The sequence is as follows. We have Y phases. In each phase we select 2k elements
j}2k
Ri = {ri
j=1 uniformly at random from [n]. We order them arbitrarily in a sequence Si,
and access [Si]X/2k (access Si X/2k times). The ﬁnal sequence S is a concatenation of the
sequences [Si]X/2k for 1 ≤ i ≤ Y . Each phase has X accesses, for a total of m = XY accesses
overall. We will choose X and Y appropriately later.
Working set bound. One easily observes that WS(S) = O(Y (2k log n+(X −2k) log(2k))),
because after the ﬁrst 2k accesses in a phase, the working set is always of size 2k. We choose
X such that the second term dominates the ﬁrst, say X ≥ 5k log n
log 2k. We then have that the
working set bound is O(XY log k) = O(m log k), with probability one.
k-lazy ﬁnger bound. Fix a BST T. We classify the selection of the set Ri as being d-good
‘ ∈ Ri such that their distance in T is less than d. The
for T if there exists a pair ri
following lemma bounds the probability of a random selection being d-good for T.

j, ri

(cid:73) Lemma 58. Let T be any BST. The probability that Ri is d-good for T is at most 8k23d/n.

Proof. We may assume 8k23d/n < 1 as the claim is void otherwise. We compute the
probability that a selection Ri is not d-good ﬁrst. This happens if and only if the balls of
radius d around every element ri
j are disjoint. The volume of such a ball is at most 3d, so we
can bound this probability as

32

The landscape of bounds for binary search trees

P[Ri is not d-good for T] = Π2k−1
i=1

⇒ P[Ri is d-good for T] ≤ 1 −

(cid:18)

(cid:19)

n

n

≥

(cid:18)

1 − i3d
(cid:19)2k
(cid:19)2k
(cid:18)
1 − 2k3d
≤ 1 − exp(cid:0)−8k23d/n(cid:1)

1 − 2k3d
(cid:18)
1 − 2k3d
(cid:18)

= 1 − exp

2k ln

n

n

≤ 8k23d/n,

(cid:19)(cid:19)

where the last two inequalities follow from ln(1−x) > −2x for x ≤ 1/2 (note that 8k23d/n < 1
implies 2k3d/n ≤ 1/2) and ex > 1 + x, respectively.

Observe that if Ri is not d-good, then the k-lazy ﬁnger bound of the access sequence
[Si]X/2k is Ω(d(X − k)) = Ω(dX). This is because in every occurrence of Si, there will be
some k elements out of the 2k total that will be outside the d-radius balls centered at the
current k ﬁngers.

We call the entire sequence S d-good for T if at least half of the sets Ri are d-good for T.

Proof. By the previous lemma and by deﬁnition of goodness of S, we have that

.

n

T (S) = Ω(XY d).

Thus if S is not d-good, then LF k

(cid:73) Lemma 59. P[S is d-good for T] ≤(cid:16) 32k23d
(cid:17)Y /2
(cid:19)(cid:18)8k23d
(cid:19)Y /2
(cid:18)8k23d
(cid:19)Y /2
(cid:19)Y /2
(cid:18)32k23d

P[S is d-good for T] ≤

Y /2
≤ 4Y /2

(cid:18) Y

n

n

=

n

.

The theorem now follows easily. Taking a union bound over all BSTs on [n], we have

P[S is d-good for some BST T] ≤ 4n

Now set Y = 2n. We have that
P[∃ a BST T : LF k

Putting d = log3
P[∃ a BST T : LF k

T (S) ≤ md/4] ≤ 4n
256k2 gives that for some constant c < 1,
T (S) ≤ c(m log(n/k))] ≤ 4n

n

.

n

(cid:19)n

= 1/2

.

n

(cid:18)32k23d
(cid:19)Y /2
(cid:19)n
(cid:18)32k23d
(cid:18)32k23d

n

which implies that with probability at least 1/2 one of the sequences in our random construc-
tion will have k-lazy ﬁnger bound that is Ω(m log(n/k)). The working set bound is always
O(m log k). This establishes the theorem.

