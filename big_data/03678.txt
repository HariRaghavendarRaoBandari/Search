Distance Metric Tracking

6
1
0
2

 
r
a

 

M
1
1

 
 
]
L
M

.
t
a
t
s
[
 
 

1
v
8
7
6
3
0

.

3
0
6
1
:
v
i
X
r
a

Kristjan Greenewald
University of Michigan, 1301 Beal Ave, Ann Arbor, MI USA
Stephen Kelley
MIT Lincoln Laboratory, 244 Wood Street., Lexington, MA 02420 USA
Alfred O. Hero III
University of Michigan, 1301 Beal Ave, Ann Arbor, MI USA

GREENEWK@UMICH.EDU

STEPHEN.KELLEY@LL.MIT.EDU

HERO@EECS.UMICH.EDU

Abstract

Recent work in distance metric learning focused
on learning transformations of data that best
align with provided sets of pairwise similarity
and dissimilarity constraints. The learned trans-
formations lead to improved retrieval, classiﬁca-
tion, and clustering algorithms due to the more
accurate distance or similarity measures. Here,
we introduce the problem of learning these trans-
formations when the underlying constraint gen-
eration process is dynamic. These dynamics can
be due to changes in either the ground-truth la-
bels used to generate constraints or changes to
the feature subspaces in which the class structure
is apparent. We propose and evaluate an adap-
tive, online algorithm for learning and tracking
metrics as they change over time. We demon-
strate the proposed algorithm on both real and
synthetic data sets and show signiﬁcant perfor-
mance improvements relative to previously pro-
posed batch and online distance metric learning
algorithms.

1. Introduction
The effectiveness of many machine learning and data min-
ing applications rely on an appropriate measure of pairwise
distance between data points that accurately reﬂects the ob-
jective, e.g., prediction, clustering or classiﬁcation. In set-
tings with clean, appropriately-scaled spherical Gaussian
data, standard Euclidean distance can be utilized. However,
when the data is heavy tailed, multimodal, contaminated
by outliers, irrelevant or replicated features, or observation

Proceedings of the 33 rd International Conference on Machine
Learning, New York, NY, USA, 2016. JMLR: W&CP volume
48. Copyright 2016 by the author(s).

noise, Euclidean inter-point distance can be problematic,
leading to bias or loss of discriminative power.
As a result, many unsupervised, data-driven approaches for
identifying appropriate distances between points have been
proposed. These methodologies, broadly taking the form
of dimensionality reduction or data “whitening”, aim to
utilize the data itself to learn a transformation of the data
that embeds it into a space where Euclidean distance is ap-
propriate. Examples of such unsupervised techniques in-
clude Principal Component Analysis (Bishop, 2006), Mul-
tidimensional Scaling (Hastie et al., 2005), covariance es-
timation (Hastie et al., 2005; Bishop, 2006), and mani-
fold learning (Lee & Verleysen, 2007). Such unsupervised
methods do not have the beneﬁt of human input on the dis-
tance metric, and overly rely on prior assumptions, e.g.,
local linearity or smoothness.
This paper proposes methods for distance metric learning.
In this problem one seeks to learn linear transformations of
the data that are well matched to a particular task speciﬁed
by the user. In this case, point labels or constraints indicat-
ing point similarity or dissimilarity are used to learn a trans-
formation of the data such that similar points are “close” to
one another and dissimilar points are distant in the trans-
formed space. Learning distance metrics in this manner
allows a more precise notion of distance or similarity to be
deﬁned that is related to the task at hand.
Many supervised and semi-supervised distance metric
learning approaches have been developed (Kulis, 2012).
This includes online algorithms (Kunapuli & Shavlik,
2012) with regret guarantees for situations where similarity
constraints are received in a stream. In this paper, we pro-
pose a new way of formulating the distance metric learning
task. We assume the underlying ground-truth distance met-
ric from which constraints are generated is evolving over
time. This problem formulation suggests an adaptive, on-
line approach to track the underlying metric as constraints

Distance Metric Tracking

are received. We present an algorithm for tracking dis-
tance metrics based on recent advances in composite ob-
jective mirror descent for metric learning (Duchi et al.,
2010b) (COMID) and the Strongly Adaptive Online Learn-
ing (SAOL) framework proposed in (Daniely et al., 2015).

1.1. Related Work

Linear Discriminant Analysis (LDA) and Principal Com-
ponent Analysis (PCA) are classic examples of linear trans-
formations for projecting data into more interpretable low
dimensional spaces. Unsupervised PCA seeks to identify
a set of axes that best explain the variance contained in
the data. LDA takes a supervised approach, minimizing
the intra-class variance and maximizing the inter-class vari-
ance given class labeled data points.
Much of the recent work in Distance Metric Learning has
focused on learning Mahalanobis distances on the basis of
pairwise similarity/dissimilarity constraints. These meth-
ods have the same goals as LDA; pairs of points labeled
“similar” should be close to one another while pairs labeled
“dissimilar” should be distant. MMC (Xing et al., 2002), a
method for identifying a Mahalanobis metric for clustering
with side information, uses semideﬁnite programming to
identify a metric that maximizes the sum of distances be-
tween points labeled with different classes subject to the
constraint that the sum of distances between all points with
similar labels be less than some constant.
Large Margin Nearest Neighbor (LMNN) (Weinberger
et al., 2005) similarly uses semideﬁnite programming to
identify a Mahalanobis distance, however it modiﬁes the
constraints to only take into account a small, local neigh-
borhood for each point.
In this setting, the algorithm
minimizes the sum of distances between a given point
and its similarly labeled neighbors while forcing differ-
ently labeled neighbors outside of its neighborhood. This
method has been shown to be computationally efﬁcient
(Weinberger & Saul, 2008) and, in contrast to the simi-
larly motivated Neighborhood Component Analysis (Gold-
berger et al., 2004), is guaranteed to converge to a globally
optimal solution.
Information Theoretic Metric Learning (ITML) (Davis
et al., 2007) is another popular Distance Metric Learning
technique.
ITML minimizes the Kullback-Liebler diver-
gence between an initial guess of the matrix that param-
eterizes the Mahalanobis distance and a solution that sat-
isﬁes a set of constraints. The constraints in this setting
are based on similarity and dissimilarity pairs and are con-
structed such that similar pairs be within some closeness
constant and dissimilar pairs be more distant than some
larger constant. Online and non-linear extensions to the
ITML methodology are presented as well.

In a dynamic environment, it is necessary to be able to
compute multiple estimates of the changing metric at dif-
ferent times, and to be able to compute those estimates on-
line. Online learning (Cesa-Bianchi & Lugosi, 2006) meets
these criteria by efﬁciently updating the estimate every time
a new data point is obtained, instead of solving an objective
function formed from the entire dataset.
Many online learning methods have regret guarantees, that
is, the loss in performance relative to a batch method is
provably small (Cesa-Bianchi & Lugosi, 2006; Duchi et al.,
2010b). In practice, however, the performance of an on-
line learning method is strongly inﬂuenced by the learning
rate which may need to vary over time in a dynamic envi-
ronment (Daniely et al., 2015; McMahan & Streeter, 2010;
Duchi et al., 2010a).
Adaptive online learning methods attempt to address this
problem by continuously updating the learning rate as new
observations become available. For example, AdaGrad-
style methods (McMahan & Streeter, 2010; Duchi et al.,
2010a) perform gradient descent steps with the step size
adapted based on the magnitude of recent gradients. Follow
the regularized leader (FTRL) type algorithms adapt the
regularization to the observations (McMahan, 2014). Re-
cently, a method called Strongly Adaptive Online Learning
(SAOL) has been proposed, which maintains several learn-
ers with different learning rates and selects the best one
based on recent performance (Daniely et al., 2015). Sev-
eral of these adaptive methods have provable regret bounds
(McMahan, 2014; Herbster & Warmuth, 1998; Hazan &
Seshadhri, 2007). These typically guarantee low total re-
gret (i.e. regret from time 0 to time t) at every time (McMa-
han, 2014). SAOL, on the other hand, is guaranteed to have
low regret on every subinterval, as well as low regret over-
all (Daniely et al., 2015).
The remainder of this paper is structured as follows.
In
Section 2 we formalize the distance metric tracking prob-
lem, and section 3 reviews the existing COMID learning
framework. Section 4 introduces our adaptive approaches
to solving the distance metric tracking problem, and section
5 presents our Strongly Adaptive Online Metric Learning
algorithm. Results on both synthetic data and a text review
dataset are presented in Section 6 with discussion and fu-
ture work presented in Section 7.

2. Problem Formulation
The goal of this work is to use analyst feedback to learn
a metric on the data space that best matches the goals of
the analyst. We formulate the problem as a cooperative
dynamic game between the learner and the analyst. Both
players’ goal is for the learner to learn the internal metric
M used by the analyst. The metric is changing over time,

Distance Metric Tracking

making the game dynamic.
The analyst selects pairs of data points (xt, zt) and labels
them as similar or dissimilar. The labels are assumed to
arrive in a temporal sequence, hence the labels at the be-
ginning may have arisen from a different metric than those
at the end of the sequence.
In sum, the learning goals include tracking the analyst’s in-
ternal metric in the presence of metric changes and noise,
and (equivalently) ﬁnding an embedding which results in
maximal separation of the clusters of interest to the ana-
lyst, enabling better interpretation and/or future feedback
from the analyst. Potential extensions which we do not
have the space to treat here include exploiting unlabeled
data points (Bilenko et al., 2004), and/or choosing which
pairs or groups of pairs to present to the analyst (i.e. active
learning (Settles, 2012)).

2.1. Objective function

Metric learning seeks to learn a metric that encourages data
points marked as similar to be close and data points marked
as different to be far apart. The Mahalonobis distance is
parameterized by M as

M (x, z) = (x − z)T M(x − z)
d2

(1)

where M ∈ Rn×n (cid:23) 0.
Suppose a set of similarity constraints are given, where
each constraint is the triplet (xt, zt, yt), xt and zt are data
points in Rn, and the label yt = +1 if the points xt, zt are
similar and yt = −1 if they are dissimilar.
Following (Kunapuli & Shavlik, 2012), we introduce the
following margin based constraints:

M (xt, zt) ≤ µ − 1,
d2
M (xt, zt) ≥ µ + 1,
d2

∀{t|yt = 1}
∀{t|yt = −1}

(2)

where µ is a threshold that controls the margin between
similar and dissimilar points. A diagram illustrating these
constraints and their effect is shown in Figure 1.
In typical fashion, these constraints are softened by penal-
izing violation of the constraints with a convex loss func-
tion (cid:96)t. This gives the following objective:

T(cid:88)

min

M(cid:23)0,µ≥1

1
T

t=1

(cid:96)t(M, µ) + ρr(M)

(3)
t Mut), ut = xt − zt
(cid:96)t(M, µ) =(cid:96)(mt), mt = yt(µ − uT
where r is the regularizer. Kunapuli and Shavlik propose
using nuclear norm regularization (r(M) = (cid:107)M(cid:107)∗) to en-
courage projection of the data onto a low dimensional sub-
space (feature selection/dimensionality reduction).

Figure 1. Visualization of the margin based constraints (2), with
colors indicating class. The goal of the metric learning con-
straints is to move target neighbors towards the point of interest
(POI), while moving points from other classes away from the tar-
get neighborhood.

3. Composite Objective Mirror Descent
One principled approach to online learning involves view-
ing the acquisition of new data points as stochastic real-
izations of the underlying distribution, suggesting the use
of stochastic mirror descent techniques. The authors of
(Kunapuli & Shavlik, 2012) propose a composite objective
mirror descent (COMID) approach to online metric learn-
ing that solves a regularized positive semideﬁnite learning
problem.
Using the COMID framework (Duchi et al., 2010b), for the
objective (3) we have online learning updates that iterate
through the constraints

ˆMt+1 = arg min
M(cid:23)0

Bψ(M, ˆMt)

(4)

+ ηt(cid:104)∇M (cid:96)t( ˆMt, µt), M − ˆMt(cid:105) + ηtρ(cid:107)M(cid:107)∗

Bψ(µ, ˆµt) + ηt∇µ(cid:96)t( ˆMt, ˆµt)(cid:48)(µ − ˆµt),

ˆµt+1 = arg min
µ≥1

where Bψ is any Bregman divergence and ηt is the learning
rate parameter. ˆM0, ˆµ0 are initialized to some initial value.
In (Kunapuli & Shavlik, 2012) a closed-form algorithm for
solving the minimization in (15) is developed for a vari-
ety of common losses and Bregman divergences, involving
rank one updates and eigenvalue shrinkage. A kernel ver-
sion of the algorithm is also available for the batch case.
this method has
By standard mirror descent analysis,
√
T ) regret for the static case when the learning rate is
O(
set as ηt = η/
t. For online learning of a static objec-
tive, the learning rate will decay to zero. However, in the
case of a dynamic objective, the learning rate must not de-
cay to zero so that the estimate of the parameters will be
most strongly inﬂuenced by the recent constraint history.
This was proposed in a generic online learning scenario in
(Hall & Willett, 2015), where low regret guarantees were

√

Distance Metric Tracking

derived, which we extend to metric learning in the supple-
mentary material. Critically, the optimal learning rate de-
pends on how fast the objective is changing. We propose
two methods for addressing this issue and for learning dis-
tance metrics that change over time in an arbitrary way.

4. Dynamic Metric Learning Algorithms
4.1. Windowed Batch Approach

Intuitively, if the underlying metric is changing smoothly,
the most recent samples are the most relevant. Similarly
to the covariance estimation method of (Zhou et al., 2010),
it is possible to apply batch methods to learn a changing
metric. At any given time the importance of past samples
are weighted by their recency, and a batch method is used
to estimate the current metric. This is then repeated at var-
ious times, giving in effect a weighted sliding window of
samples from which to learn. The resulting objective is

Figure 2. Strongly Adaptive Online Learning - Learners at mul-
tiple scales run in parallel. Observed losses for each are used to
create weights that are used to select the current scale.

Figure 3. Stochastic mirror descent learners and initialization.
Each yellow and red learner is initialized by the output of the pre-
vious learner of the same color, that is, the learner of the next
shorter scale.

on every subinterval, as opposed to the traditional bounds
on regret over the entire learning period. This guarantees
that the estimate will be sufﬁciently responsive to make it
accurate at all times.
We use the COMID online learners of Section 3 (with
learning rate ηt) as the base learners. Algorithm 1 shows
the SAOL algorithm applied to the metric learning prob-
lem. The next section explains SAOL and its implementa-
tion.

5. SAOML
5.1. SAOL Framework

We ﬁrst describe the SAOL framework of (Daniely et al.,
2015). SAOL is based on dyadically partitioning the tem-
poral axis into intervals and assigning a black box learner
to each interval. Speciﬁcally, deﬁne a set I of intervals
I = [tI1, tI2] such that the lengths |I| of the intervals are
proportional to powers of two, i.e. |I| = I02j, with an ar-
rangement that is a dyadic partition of the temporal axis.
The ﬁrst interval of length |I| starts at t = |I| (see Figure
2), and additional intervals of length |I| exist such that the
rest of time is covered.
Every interval I is associated with a base learner that op-
erates on that interval. Hence, at a given time t, a set

K(cid:88)
where ak is such that(cid:80)K

Mt(cid:23)0,µt≥1

min

ak(cid:96)k+t−K(Mt, µt) + ρr(Mt)

(5)

k=1

k=1 ak = 1. This function is con-
vex. Nonrectangular windows can be more difﬁcult com-
putationally, and repeated batch processing is not efﬁcient.
In our experiments, we use COMID to solve the objective
(5) at each step. Since from t to t + 1 the objective function
only changes slightly if K is large enough and a is suf-
ﬁciently smooth, computational complexity is reduced by
initializing the current update with the previous estimate.

4.2. Adaptive Online Approach

In an online learning scenario where drift is occurring, as
noted above, the choice of the learning rate ηt can be crit-
ical. Furthermore, if discrete shifts and/or changes in drift
occur, the optimal ηt may change with time, and setting a
drift rate dependent ηt using cross validation is not practi-
cal in a truly online setting. Hence, a method of adaptively
choosing the learning rate in an online fashion is desirable.
While any method of adaptively setting ηt may be used, in
this work we chose the Strongly Adaptive Online Learning
(SAOL) framework of (Daniely et al., 2015) because of its
ability to perform well on every time subinterval.
SOAL proposes running a bank of multiple online base
learners in parallel, each having parameters optimized for
learning on an interval of a different length, or alternatively
in our case, for learning a metric that has its drift spread out
over an interval of a different length. SAOL then uses the
recent history of losses suffered by each learner to select
the learner that is most accurate at the current time (Figure
2). SAOL has strong theoretical guarantees on the regret

Distance Metric Tracking

SAOL learner with probability

Pr( ˆMt = Mt(I), ˆµt = µt(I)) =

(cid:80)

wt(I)

I∈ACTIVE(t) wt(I)

,

∀I ∈ ACTIVE(t).

(7)
In (Daniely et al., 2015), SAOL assumes that the loss (cid:96)(·)
lies between 0 and 1. We propose a way to apply this to our
unbounded loss in the next subsection.

5.2. Implementation

We note that (Daniely et al., 2015) does not provide any
further implementation details, and that selecting a learner
at random can be problematic.
For stochastic mirror descent learners, we propose the fol-
lowing approach. Let each learner be a stochastic compos-
ite mirror descent learner (15) having a constant learning
rate proportional to the inverse square of the length of the

interval, i.e. ηt(I) = η0/(cid:112)|I|.

Each mirror descent learner (besides the coarsest) at level
j (|I| = I02j) is initialized to the current estimate of the
next coarsest learner (level j − 1). Furthermore, the weight
wt is carried over from said coarser learner. This strategy
is equivalent to “backdating” the interval learners so as to
ensure appropriate convergence has occurred before the in-
terval of interest is reached, and is effectively a “quantized
square root decay” of the learning rate (Figure 3).
In the SAOL framework, the loss must lie between 0 and
1. For convexity reasons, the loss function we use in (3) is
unbounded. However, this is a relaxation of the underlying
0-1 loss. Hence for purposes of updating the weights, we
use the logistic loss

(cid:96)t,log(xt|Mt, µt) = logistic

(8)

(cid:18) cmt

(cid:19)

µt

ACTIVE(t) ⊆ I of ﬂoor(log2 t) intervals/learners are ac-
tive, running in parallel. The base learner of given interval

I is designed to have low total regret (O((cid:112)|I|)) on that

interval in the static case. Because the parameters being
learned are changing with time, learners designed for low
regret at different scales will have different performance
(analogous to the classic bias/variance tradeoff). In other
words, there is an optimal scale |I| that can be selected
from the base learning ensemble.

Algorithm 1 Strongly Adaptive Online Metric Learning
1: Initialize: w1(I)
2: for t = 1 to T do
Initialize new learner if needed.
3:
Choose ˆI ∈ ACTIVE(t) according to (10).
4:
5: Mirror Descent update (15) for all active learners.
Set Mt ← Mt( ˆI), µt ← µt( ˆI)
6:
Obtain constraint (xt, zt, yt), compute loss (cid:96)t,log(·).
7:
Update weights for all t ∈ I:

(cid:32)(cid:88)

(cid:33)
wt+1(I) =wt(I)(1 + min{1/2, 1/(cid:112)|Ti|}rt(I))

− (cid:96)t,log(Mt(I), µt(I))

(cid:96)t,log(Mt(I), µt(I))

wt(I)
Wt

rt(I) =

8:

I

9: end for
10: Return {Mt, µt}.

It remains to select the output of one of the active learn-
ers and use it as the ﬁnal estimate at any given time t. In
(Daniely et al., 2015), it is proposed to compute weights
for each learner. These weights are updated based on the
learner’s recent estimated regret, which is estimated as de-
scribed below, and are used to randomly select a learner. In
our work, we update the weights according to

wt+1(I) =wt(I)(1 + ηI rt(I)),

(cid:32)(cid:88)

I

wt(I)
Wt

rt(I) =

(cid:96)t(Mt(I), µt(I))

− (cid:96)t(Mt(I), µt(I))

for all I ∈ I, where ηI = min{1/2, 1/(cid:112)|I|}, where

Mt(I), µt(I) are the outputs at time t of the learner on
interval I, and rt(I) is called the estimated regret of the
learner on interval I at time t. Essentially, this is highly
weighting low loss learners and lowly weighting high loss
learners.
For any given time t, the output of the learner of interval
I ∈ ACTIVE(t) is randomly selected as the output of the

∀t ∈ I

(cid:33)

(6)

where the argument is scaled by µt because only the rela-
tive scale of µt and Mt is relevant to the similar/dissimilar
boundary. The constant c scales the “buffer region” created
by the loss. We set c = 2 in all our experiments. Incorpo-
rating the logistic loss into (6),

(cid:32)(cid:88)

wt(I)
Wt

(cid:33)

rt(I) =

(cid:96)t,log(Mt(I), µt(I))

(9)

I

− (cid:96)t,log(Mt(I), µt(I))

wt+1(I) =wt(I)(1 + ηI rt(I)),

∀t ∈ I.

In the original SAOL framework, the current estimates are
selected randomly. While this gives useful bounds on the
expected regret, it means that a known poor estimate is
chosen with nonzero probability. We instead propose the

Distance Metric Tracking

following: Choose the I that minimizes the expected total
Bregman divergence.

ˆI(t) =

arg min

J∈ACT IV E(t)

(cid:88)

I∈ACT IV E(t)

Bψ(θt(I), θt(J))

wt(I)(cid:80)

I wt(I)

(10)

.

If Bψ is the Frobenius norm, then this is equivalent to
choosing the estimate closest to the expectation.

5.3. Performance Guarantees

In the game theory literature, learning rates for stochastic
mirror descent techniques have been developed to be able
to play dynamic games, i.e., to solve optimization prob-
lems that are changing over time (Cesa-Bianchi et al., 2012;
Cesa-Bianchi & Lugosi, 2012; Hall & Willett, 2015; Jad-
babaie et al., 2015).
In this section, we parameterize our convex loss as ft(θt) =
(cid:96)t(θt)+r(θt), where θ = [M, µ]. Since the optimal param-
eter value is changing in a dynamic environment, deﬁning
the static regret of an algorithm B on an interval I as

RB(I) =

ft(ˆθt) − min
θ∈Θ

ft(θ)

(11)

(cid:88)

t∈I

(cid:88)

t∈I

(cid:88)

t∈I

Low strongly adaptive regret implies that the dynamic re-
gret is low on every subinterval, instead of only low in the
aggregate. As a result, a strongly adaptive algorithm must
quickly adapt to changes, otherwise the subintervals imme-
diately following the change will not have low regret, even
if the total regret over all time is low.
In the supplementary material, we prove the following:

Theorem 1 (SAOML). Let W = {w|(cid:80)
η0/(cid:112)|I| and ﬁxed µ. Then the strongly adaptive online

t (cid:107)θt+1 − θt(cid:107) ≤
γ} and B be the COMID algorithm of (15) with ηt(I) =
learner SAOLB using B as the black box learners satisﬁes
RSAOL(I) ≤

C(1 + γ)|I|1/2 + 40 log(s + 1)|I|1/2

4

21/2 − 1

(14)

for some constant C and every interval I = [q, s]. In par-
ticular, SAOLB is strongly adaptive.

6. Results
6.1. Synthetic Data

We run our metric learning algorithms on synthetic datasets
undergoing different types of simulated metric drift. The
ﬁrst dataset we consider has three classes, with a 50-20-
30% split of the prior probability. Each class is associated
with a Gaussian blob in 3-dimensional space, with each
class having a different mean and covariance. For each of
2000 data points, we select a class at random and generate
a 3-dimensional point from that classes’ Gaussian distribu-
tion. We then embed the 3-dimensional dataset in a ran-
dom subspace of a 25-dimensional space. The remaining
22-dimensional subspace is ﬁlled with iid Gaussian noise.
We generate a series of T constraints from random pairs
of points in the dataset, incorporating simulated drift (de-
scribed below), running each experiment with 1000 ran-
dom trials. For each experiment conducted in this section,
we evaluate performance using three metrics. First the data
points in the ﬁrst two dimensions (as determined by the
SVD of ˆMT ) of the ﬁnal learned embedding, color coded
according to their true classes are shown. We plot the K-
nearest neighbor error rate, using the learned embedding
at each time point, averaging over all trials. We quantify
the clustering performance by plotting the empirical prob-
ability that the normalized mutual information (NMI) of
the K-means clustering of the unlabeled data points in the
learned embedding at each time point exceeds 0.85 (out of
a possible 1). We believe clustering NMI, rather than k-NN
performance, is a more realistic indicator of metric learning
performance, at least in the case where ﬁnding a relevant
embedding is the primary goal.
Figure 4 shows the static drift-free results for nonadap-
tive COMID, SAOML, LMNN (batch), our weighted batch

is not useful.
A more useful generalization of the standard static regret is
as follows. Let W be a possible set of actions, in this case
the set of possible sequences w = {θt}t∈I satisfying some
criterion. This allows for a dynamically changing estimate.
Then, the dynamic regret of an algorithm B is deﬁned as

ft(ˆθt) − min
w∈W

ft(θt).

(12)

RB(I) =

(cid:88)
by setting W = {w|(cid:80)

t∈I

In (Hall & Willett, 2015) the authors deﬁne dynamic regret
t∈I (cid:107)θt+1 − θt(cid:107) ≤ γ}, i.e. bound-
ing the total amount of variation in the estimated parame-
ter. Without temporal regularization, minimizing the loss
would cause θt to grossly overﬁt, hence the constraint on
how fast θt can change.
We now use this notion of dynamic regret and extend it to
the stronger notion of strongly adaptive regret. Following
(Daniely et al., 2015), we deﬁne strongly adaptive regret of
an algorithm A as

SA-RegretTA(τ ) =

max

I=[q,q+τ−1]⊂[0,T ]

E[RA(I)]

(13)

where the expectation is with respect to the possibly ran-
dom output of the algorithm. We call an algorithmstrongly
adaptive if SA-RegretTA(τ ) = O(poly(log T )RP (τ )),
where RP (τ ) is the regret of the learning problem, i.e. the
best possible regret bound.

Distance Metric Tracking

Figure 4. Dataset 1. The dataset remains ﬁxed throughout, no drift
occurs as the constraints are observed. Shown as a function of
time is the mean k-NN error rate and the probability the k-means
NMI > 0.85. Note the failure of ITML and similar performance
of the remaining online and batch methods.

method, and online ITML. All parameters were set via
cross validation and remain constant through all experi-
ments on the dataset. Online ITML fails due to its bias
agains low-rank solutions (Davis et al., 2007), and the other
methods perform comparably as there is no drift. Discrete
drift where at time T /2 the 25 dimensions are randomly
permuted is shown in Figure 5, and continuous drift with a
changing rate is shown in Figure 6. To simulate continuous
drift, at each time step we perform a small random rotation
of the dataset, and at time T /2 the rate of rotation is in-
creased by a factor of 6. It can be seen that the weighted
batch and especially SAOML respond quickly to drift, per-
forming signiﬁcantly better than the nonadaptive COMID.

Figure 6. Dataset 1. Continuous slow rotational drift of the dataset
occurs, followed by more rapid drift. From top to bottom: Non-
adaptive COMID, SAOML, and the weighted batch method. The
nonadaptive method with its ﬁxed learning rate performs poorly
during rapid drift relative to the adaptive methods.

used. For each of data points, we assign two classes (cor-
responding to different possible partitions A and B of the
data), both selected at random, and for both generate a
3-dimensional point from that classes’ Gaussian distribu-
tion. The two points are then concatenated into a sin-
gle 6-dimensional point. We then embed the entire 6-
dimensional dataset in a random subspace, with the remain-
ing dimensions ﬁlled with iid Gaussian noise as before.

Figure 5. Dataset 1. Random permutation of the data dimensions
occurs at the halfway point. Top to bottom: Nonadaptive CO-
MID, adaptive SAOML, and the windowed batch method. Note
the slow recovery of the nonadaptive method after the change.

A second dataset identical to the one described above, ex-
cept with an alternative generative cluster model, was also

Figure 7. Dataset 2. The dataset and labeling remains ﬁxed
throughout, no drift occurs. Shown is the average performance
for each method.

The results for no drift are shown in Figure 7, similar to
those found with the ﬁrst dataset. We also consider drift
between partitions (Figure 8): At ﬁrst, partition A is used,
and at time T /2, the labeling is changed to partition B. By
way of interpretation, the goal of metric learning is to iden-
tify the 3-dimensional subspace corresponding to the label-
ing of interest, and project away the noisy subspaces, thus
improving the performance of secondary algorithms. The

0100020003000400050006000Time (constraints)00.020.040.060.080.10.120.140.160.18Mean K-NN Error RateNonadaptiveAdaptiveBatchWindowed BatchOnline ITML010002000300040005000Time (constraints)00.20.40.60.81K-Means NMI Probability-1.5-1-0.500.5-0.8-0.6-0.4-0.200.20.40.60200040006000Time (constraints)0123456789Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability-2024-1-0.500.511.520200040006000Time (constraints)0123456789Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability-4-202-2.5-2-1.5-1-0.500.510200040006000Time (constraints)0123456789Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability-505-4-2024680200040006000Time (constraints)00.511.522.533.544.5Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability-30-20-10010-20-15-10-505100200040006000Time (constraints)012345Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability-10-50510-4-202468100200040006000Time (constraints)0123456Mean K-NN Error Rate×10-3020004000Time (constraints)00.20.40.60.81K-Means NMI Probability0100020003000400050006000Time (constraints)00.050.10.150.2Mean K-NN Error RateNonadaptiveAdaptiveBatchWindowed BatchOnline ITML010002000300040005000Time (constraints)00.20.40.60.81K-Means NMI ProbabilityDistance Metric Tracking

dimensional embedding, we computed the k-NN error after
projecting the data into the ﬁrst 5 dimensions of the em-
bedding. Also shown are the results for a learner where an
oracle allows reinitialization of the metric to the identity at
time zero, and the nonadaptive learner for which the learn-
ing rate is not increased. Figure 11 (left) shows the results
when the clustering changes from the four class sentiment
+ type partition to the two class product type only partition,
and Figure 11 (right) shows the results when the partition
changes from sentiment to product type. In the ﬁrst case,
the similar clustering allows SAOML to signiﬁcantly out-
perform even the reinitialized method, and in the second
remain competitive where the clusterings are unrelated.

Figure 9. Metric learning for product type clustering. Book re-
views blue, electronics reviews red. Original LOO k-NN error
rate 15.3%. Left: First two dimensions of learned SAOML em-
bedding (LOO k-NN error rate 11.3%). Right: embedding from
standard PCA (k-NN error 20.4%).

Figure 10. Metric learning for sentiment clustering. Positive re-
views blue, negative red. Original LOO k-NN error rate 35.7%.
Left: First two dimensions of learned SAOML embedding (LOO
k-NN error rate 23.5%). Right: embedding from standard PCA
(k-NN error 41.9%).

7. Conclusion and Future Work
We introduced the problem of metric learning in a chang-
ing environment, and presented an efﬁcient, strongly adap-
tive online algorithm having strong theoretical performance
guarantees. Performance of our algorithms was evaluated
both on synthetic and real datasets, demonstrating the abil-
ity of SAOML to learn and adapt quickly in the presence of
changes both in the clustering of interest and in the under-
lying data distribution.
Potential directions for future work include the learning
of more expressive metrics beyond the Mahalanobis met-

Figure 8. Dataset 2: two possible clusterings of the data exist. For
the ﬁrst half, the ﬁrst clustering is used to generate the labels,
and in the second half a switch is made to the second possible
clustering. Top: Average performance; Bottom: an example ﬁnal
embedding for each method. Note the failure of the batch method
(LMNN), and the poor performance of the nonadaptive method.

nonadaptive method fails to quickly catch up to the shift,
whereas SAOML effectively increases the learning rate pa-
rameter to quickly learn the new paradigm.

6.2. Clustering Product Reviews

As an example real data task, we consider clustering
Amazon text reviews, using the Multi-Domain Sentiment
Dataset (Blitzer et al., 2007). We use the 11402 reviews
from the Electronics and Books categories, and preprocess
the data by computing word counts for each review and
2369 commonly occurring words. Two possible cluster-
ings of the reviews are considered: product category (books
or electronics) and sentiment (positive: star rating 4/5 or
greater, or negative: 2/5 or less).
Figures 9 and 10 show the ﬁrst two dimensions of the em-
beddings learned by static COMID for the category and
sentiment clusterings respectively. Also shown are the 2-
dimensional standard PCA embeddings, and the k-NN clas-
siﬁcation performance both before embedding and in each
embeddings. As expected, metric learning is able to ﬁnd
embeddings with improved class separability. We empha-
size that while improvements in k-NN classiﬁcation are ob-
served, we use k-NN merely as a way to quantify the sep-
arability of the classes in the learned embeddings. In these
experiments, we set the regularizer r(·) to the L1 norm.
We then conducted drift experiments where the cluster-
ing changes. The change happens after the metric learner
for the original clustering has converged, hence the non-
adaptive learning rate is effectively zero. For each change,
we show the k-NN error rate in the learned SAOML em-
bedding as it adapts to the new clustering. Emphasizing
the visualization and computational advantages of a low-

0100020003000400050006000Time (constraints)00.020.040.060.080.1Mean K-NN Error RateNonadaptiveAdaptiveBatchWindowed Batch010002000300040005000Time (constraints)00.20.40.60.81K-Means NMI Probability-1012-0.500.511.52Nonadaptive-505-3-2-1012345Adaptive-202-1-0.500.511.522.5Batch-4-202-4-3-2-1012Windowed Batch-300-250-200-150-100-500-60-40-20020406080-300-250-200-150-100-500-60-40-20020406080Distance Metric Tracking

sequence in W{w|(cid:80)

ηt+1 ≤ ηt gives

t∈I (cid:107)θt+1 − θt(cid:107) ≤ γ}. Then using

T(cid:88)

t=1

RT (ΘT ) ≤ Dmax
ηT +1

+

4φmax

ηT

γ +

G2
(cid:96)
2σ

ηt

(16)

Using a decaying learning rate ηt, we can then prove a
bound on the dynamic regret for a quite general set of
stochastic optimization problems.
Applying this to our problem, we obtain the following. As-
sume a ﬁxed µ. Then for the estimation of Mt we have

Figure 11. Metric drift in Amazon review data. Left: Change
from product type + sentiment clustering to simply product
type; Right: Change from sentiment to product type clustering.
SAOML performance shown as it adapts to the new clustering,
as well as the results for a reinitialized COMID learner and the
nonadaptive learner for which the learning rate is not increased.

ric, the incorporation of unlabeled data points in a semi-
supervised learning framework, and the incorporation of
an active learning framework to select which pairs of data
points to obtain labels for at any given time.

8. Acknowledgments
The Lincoln Laboratory portion of this work was spon-
sored by the Assistant Secretary of Defense for Research
and Engineering under Air Force Contract #FA8721-05-C-
0002. Opinions, interpretations, conclusions and recom-
mendations are those of the author and are not necessarily
endorsed by the United States Government.

9. Appendix: Online DML Dynamic Regret
In this section, we derive the dynamic regret of our CO-
MID metric learning algorithm. Recall that the COMID
algorithm is given by

ˆMt+1 = arg min
M(cid:23)0

Bψ(M, ˆMt)

(15)

+ ηt(cid:104)∇M (cid:96)t( ˆMt, µt), M − ˆMt(cid:105) + ηtρ(cid:107)M(cid:107)∗

Bψ(µ, ˆµt) + ηt∇µ(cid:96)t( ˆMt, ˆµt)(cid:48)(µ − ˆµt),

ˆµt+1 = arg min
µ≥1

where Bψ is any Bregman divergence and ηt is the learning
rate parameter. From (Hall & Willett, 2015) we have:
Theorem 2.

G(cid:96) = max

θ∈Θ,(cid:96)∈L(cid:107)∇f (θ)(cid:107)
(cid:107)∇ψ(θ)(cid:107)
Bψ(θ(cid:48)(cid:107)θ)

1
2

φmax =

max
θ∈Θ
Dmax = max
θ,θ(cid:48)∈Θ

Let the sequence ˆθt = [ ˆMt, ˆµt], t = 1,··· , T be gener-
ated via the COMID algorithm, and let w be an arbitrary

(cid:107)∇((cid:96)t(M, µ) + ρ(cid:107)M(cid:107)∗)(cid:107)2
(cid:107)∇ψ(M)(cid:107)2

Bψ(M(cid:48)(cid:107)M)

φmax =

Dmax =

G(cid:96) = max

(cid:107)M(cid:107)≤c,t,µ
1
2

max
(cid:107)M(cid:107)≤c
max

(cid:107)M(cid:107),(cid:107)M(cid:48)(cid:107)≤c

G(cid:96) ≤(cid:113)

t

(max
√
φmax = c
n
√
Dmax = 2c

n

For (cid:96)t(·) being the hinge loss and ψ = (cid:107) · (cid:107)2
F ,

d2(xt, zt) + ρ)2

where d(x, z) = (cid:107)x − z(cid:107)2 is the standard Euclidean dis-
tance. The other two quantities are guaranteed to exist and
depend on the choice of Bregman divergence and c. Thus,
an arbitrary sequence with (cid:107)Mt(cid:107) ≤ c and(cid:80)T
Corollary 1 (Dynamic Regret: ML COMID). Let the se-
quence ˆMt, ˆµt be generated by (15), and let {Mt}T
t=1 be
t=1 (cid:107)Mt+1−
Mt(cid:107)F ≤ γ. Then using ηt+1 ≤ ηt gives
T(cid:88)
(cid:18) Dmax + 4φmaxV ({Mt})
(cid:32)√

RT ({Mt}) ≤ Dmax
ηT +1
√

and setting ηt = η0/

RT ({Mt}) ≤

η0G2
(cid:96)
2σ

(cid:33)

G2
(cid:96)
2σ

4φmax

(17)

η0
(cid:107)Mt+1 − Mt(cid:107)F ]

(cid:88)

T [1 +

√

T

(18)

ηt

t=1

=O

+

γ +

ηT

T ,

+

(cid:19)

t

for any sequence {θt}.
Corollary 1 is a bound on the regret relative to the batch
estimate of Mt that minimizes the total batch loss subject
t (cid:107)Mt+1 − Mt(cid:107)F . Furthermore,

to a bounded variation(cid:80)

t gives the same bound as (18).

ηt = η0/
In other words, we pay a linear penalty on the total amount
of variation in the underlying parameter sequence. From
(18), it can be seen that the bound-minimizing η0 increases

√

020406080100Time (constraints)0.050.10.150.20.250.30.350.40.450.50.55Embedding k-NN Error RateAdaptiveReinitializedNonadaptive020406080100Time (constraints)0.050.10.150.20.250.30.350.40.450.50.55Embedding k-NN Error RateAdaptiveReinitializedNonadaptivewith increasing(cid:80)

Distance Metric Tracking

References
Bilenko, Mikhail, Basu, Sugato, and Mooney, Raymond J.
Integrating constraints and metric learning in semi-
supervised clustering. In Proceedings of the twenty-ﬁrst
International Conference on Machine learning, pp. 11.
ACM, 2004.

Bishop, Christopher M. Pattern Recognition and Machine

Learning. Springer, 2006.

Blitzer, John, Dredze, Mark, Pereira, Fernando, et al. Bi-
ographies, bollywood, boom-boxes and blenders: Do-
In ACL,
main adaptation for sentiment classiﬁcation.
volume 7, pp. 440–447, 2007.

Cesa-Bianchi, Nicolo and Lugosi, G´abor.

Prediction,
learning, and games. Cambridge University Press, 2006.

Cesa-Bianchi, Nicolo and Lugosi, G´abor. Combinatorial
bandits. Journal of Computer and System Sciences, 78
(5):1404–1422, 2012.

Cesa-Bianchi, Nicol`o, Gaillard, Pierre, Lugosi, G´abor, and
Stoltz, Gilles. Mirror descent meets ﬁxed share (and
feels no regret). In Advances in Neural Information Pro-
cessing Systems, pp. 980–988, 2012.

Daniely, Amit, Gonen, Alon, and Shalev-Shwartz, Shai.

Strongly adaptive online learning. ICML, 2015.

Davis, Jason V, Kulis, Brian, Jain, Prateek, Sra, Suvrit, and
Dhillon, Inderjit S. Information-theoretic metric learn-
ing. In Proceedings of the 24th international conference
on Machine learning, pp. 209–216. ACM, 2007.

Duchi, John C, Hazan, Elad, and Singer, Yoram. Adaptive
subgradient methods for online learning and stochastic
optimization. In COLT, 2010a.

Duchi, John C, Shalev-Shwartz, Shai, Singer, Yoram, and
Tewari, Ambuj. Composite objective mirror descent. In
COLT, pp. 14–26. Citeseer, 2010b.

Goldberger, Jacob, Hinton, Geoffrey E, Roweis, Sam T,
and Salakhutdinov, Ruslan. Neighbourhood components
analysis. In Advances in neural information processing
systems, pp. 513–520, 2004.

Hall, E.C. and Willett, R.M. Online convex optimization in
dynamic environments. Selected Topics in Signal Pro-
cessing, IEEE Journal of, 9(4):647–662, June 2015.

Hastie, Trevor, Tibshirani, Robert, Friedman, Jerome, and
Franklin, James. The elements of statistical learning:
data mining, inference and prediction. The Mathematical
Intelligencer, 27(2):83–85, 2005.

t (cid:107)Mt+1 − Mt(cid:107)F , indicating the need

for an adaptive learning rate.
For comparison,
if the metric is in fact static then by
standard stochastic mirror descent results (Hall & Willett,
2015)
Theorem 3 (Static Regret).
T ), then
(2σDmax)1/2/(Gf

If ˆM1 = 0 and ηt =

√

RT ({Mt}) ≤ Gf (2T Dmax/σ)1/2.

(19)

10. Appendix: Strongly Adaptive Regret
The following theorem is from (Daniely et al., 2015),
slightly modiﬁed to accomodate our different deﬁnition of
strongly adaptive regret.
Theorem 4. Fix a set W and choose an algorithm B such
that

(20)
for all T > 0 and some constants α ∈ (0, 1), C > 0. Then
the strongly adaptive online learner SAOLB using B as
the black box learners satisﬁes

RB(T ) ≤ CT α

SAOL(I) ≤ 4
RB

2α − 1

C|I|α + 40 log(s + 1)|I|1/2

(21)

for every interval I = [q, s]. In particular, SAOLB will be
strongly adaptive if α ≥ 1

2 and B has low regret.

Apply to low dynamic regret of mirror descent. (18) Corol-
lary 1.
√
From Corollary 1, COMID with ηt = η0/
T satisﬁes the
black-box learner condition (20) with α = 1/2. Hence, to
apply Theorem 4 to SAOML, it remains to normalize the
loss function to between 0 and 1.
As noted in Corollary 1, it is reasonable to assume that
(cid:107)M(cid:107) ≤ c. Hence the loss function is bounded by
(cid:96)t(Mt, µt) ≤ k = (cid:96)(c maxt (cid:107)xt − zt(cid:107)2
2) and can be nor-
malized to the appropriate range. We thus have
t (cid:107)θt+1 − θt(cid:107) ≤
γ} and B be the COMID algorithm of (15) with ηt(I) =
learner SAOLB using B as the black box learners satisﬁes
RSAOL(I) ≤

Theorem 5 (SAOML). Let W = {w|(cid:80)
η0/(cid:112)|I| and ﬁxed µ. Then the strongly adaptive online

C(1 + γ)|I|1/2 + 40 log(s + 1)|I|1/2

4

21/2 − 1

(22)

for some constant C and every interval I = [q, s]. In par-
ticular, SAOLB is strongly adaptive.

We note that this bound is stronger than those considered
in (Daniely et al., 2015) as it incorporates dynamic regret
in the deﬁnition of strongly adaptive regret.

Distance Metric Tracking

Hazan, Elad and Seshadhri, C. Adaptive algorithms for
online decision problems. In Electronic Colloquium on
Computational Complexity (ECCC), volume 14, 2007.

Herbster, Mark and Warmuth, Manfred K. Tracking the

best expert. Machine Learning, 32(2):151–178, 1998.

Jadbabaie, Ali, Rakhlin, Alexander, Shahrampour, Shahin,
and Sridharan, Karthik. Online optimization: Com-
arXiv preprint
peting with dynamic comparators.
arXiv:1501.06225, 2015.

Kulis, Brian. Metric learning: A survey. Foundations and

Trends in Machine Learning, 5(4):287–364, 2012.

Kunapuli, Gautam and Shavlik, Jude. Mirror descent for
metric learning: a uniﬁed approach. In Machine Learn-
ing and Knowledge Discovery in Databases, pp. 859–
874. Springer, 2012.

Lee, John A and Verleysen, Michel. Nonlinear dimension-
ality reduction. Springer Science & Business Media,
2007.

McMahan, H Brendan. Analysis techniques for adaptive
online learning. arXiv preprint arXiv:1403.3465, 2014.

McMahan, H Brendan and Streeter, Matthew. Adaptive
bound optimization for online convex optimization. In
COLT, 2010.

Settles, Burr. Active learning. Synthesis Lectures on Ar-
tiﬁcial Intelligence and Machine Learning, 6(1):1–114,
2012.

Weinberger, Kilian Q and Saul, Lawrence K. Fast solvers
and efﬁcient implementations for distance metric learn-
ing. In International Conference on Machine Learning,
pp. 1160–1167. ACM, 2008.

Weinberger, Kilian Q, Blitzer, John, and Saul, Lawrence K.
Distance metric learning for large margin nearest neigh-
In Advances in Neural Information
bor classiﬁcation.
Processing System, pp. 1473–1480, 2005.

Xing, Eric P, Jordan, Michael I, Russell, Stuart, and Ng,
Andrew Y. Distance metric learning with application to
clustering with side-information. In Advances in Neural
Information Processing Systems, pp. 505–512, 2002.

Zhou, Shuheng, Lafferty, John, and Wasserman, Larry.
Time varying undirected graphs. Machine Learning, 80
(2-3):295–319, 2010.

