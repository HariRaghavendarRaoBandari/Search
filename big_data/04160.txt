Data assimilation for massive autonomous systems based on

second-order adjoint method

Shin-ichi Ito,1 Hiromichi Nagao,1, 2 Akinori Yamanaka,3 Yuhki

Tsukada,4 Toshiyuki Koyama,4 Masayuki Kano,5 and Junya Inoue6

1Earthquake Research Institute, The University of Tokyo, Japan

2Graduate School of Information Science and Technology, The University of Tokyo, Japan

3Division of Advanced Mechanical Systems Engineering,

Institute of Engineering, Tokyo University of Agriculture and Technology, Japan

4Graduate School of Engineering, Nagoya University, Japan

5Earthquake Research Institute,The University of Tokyo, Japan

6School of Engineering, The University of Tokyo, Japan

(Dated: March 15, 2016)

6
1
0
2

 
r
a

 

M
4
1

 
 
]
E
M

.
t
a
t
s
[
 
 

1
v
0
6
1
4
0

.

3
0
6
1
:
v
i
X
r
a

1

Abstract

Data assimilation (DA) is a fundamental computational technique that integrates numerical

simulation models and observation data on the basis of Bayesian statistics. Originally developed for

meteorology, especially weather forecasting, DA is now an accepted technique in various scientiﬁc

ﬁelds. One key issue that remains controversial is the implementation of DA in massive simulation

models under limited computation time and resources.

In this paper, we propose an adjoint-

based DA method for massive autonomous models that produces optimum estimates and their

uncertainties within practical computation time and resource constraints. The uncertainties are

given as several diagonal components of an inverse Hessian matrix, which is the covariance matrix

of a normal distribution that approximates the target posterior probability density function in the

neighborhood of the optimum. Conventional algorithms for deriving the inverse Hessian matrix

require O(CN 2 + N 3) computations and O(N 2) memory, where N is the number of degrees of

freedom of a given autonomous system and C is the number of computations needed to simulate

time series of suitable length. The proposed method using a second-order adjoint method allows us

to directly evaluate the diagonal components of the inverse Hessian matrix without computing all

of its components. This drastically reduces the number of computations to O(C) and the amount

of memory to O(N ) for each diagonal component. The proposed method is validated through

numerical tests using a massive two-dimensional Kobayashi’s phase-ﬁeld model. We conﬁrm that

the proposed method correctly reproduces the parameter and initial state assumed in advance, and

successfully evaluates the uncertainty of the parameter. Such information regarding uncertainty is

valuable, as it can be used to optimize the design of experiments.

2

I.

INTRODUCTION

Determining the model parameters and initial states of simulation models is an important

task in various scientiﬁc ﬁelds, as it enables the temporal evolution of the target system to be

observed. However, in many practical cases, this procedure is somewhat complex, because it

is often impossible to observe the parameters and initial states experimentally. In materials

engineering, for example, phase-ﬁeld (PF) models are often used to simulate the evolution

of microstructures during the processes of solidiﬁcation and phase transformation [1–7].

PF models phenomenologically describe the dynamics of phases using ﬁeld variables that

evolve in time depending on the gradient of the total free energy. Since a PF model usually

requires a huge number of grid points to discretize the ﬁeld variables, the computational cost

tends to be prohibitive. Nonetheless, PF models are accepted beyond the ﬁeld of materials

engineering, such as in hydrodynamics [8–10], as they can be employed to model phases and

their dynamics using mathematical expressions that are easy to manipulate. In PF models,

the parameters and initial states perfectly determine the dynamical properties of the phases.

However, various limitations in practical experiments sometimes prevent such parameters

and initial states from being estimated.

Data assimilation (DA) is a computational technique that integrates numerical simula-

tion models and observational data on the basis of Bayesian statistics. Thus, DA enables

the parameters and initial states of PF models to be estimated by systematically extract-

ing as much information as possible from the given observational/experimental data. The

process of DA evaluates a probability density function (PDF) (or the “posterior PDF,” to

be precise) of the unknown parameters and unobservable states that is conditional on the

given observation data [11]. DA was originally developed in the ﬁelds of meteorology and

oceanography [12–14], but is now applied in areas such as seismology, marketing science,

and industrial science [15–18]. Several sequential Bayesian ﬁlters and other non-sequential

estimation methods have been used in DA. Common sequential Bayesian ﬁlters such as

the ensemble Kalman ﬁlter [19–21] and particle ﬁlter [22–24] estimate the target posterior

PDF using Bayes’ theorem. This approximation is formed using an ensemble of realizations,

meaning that the computational cost is proportional to the number of realizations. The im-

plementation of one sequential Bayesian ﬁlter on a given simulation model is not especially

complex, and a suﬃciently accurate estimate of the posterior PDF can be achieved when

3

the number of degrees of freedom N of the simulation model is suﬃciently small. However,

Bayesian ﬁlters become ineﬃcient when applied to massive simulation models, as the number

of realizations required to obtain a converged posterior PDF is proportional to eO(N ). Unlike

sequential Bayesian ﬁlters, adjoint methods [25–27] directly determine the optimum solution

using a gradient method to maximize the target posterior PDF. Although this achieves a

drastic reduction in the computational cost, the ordinary adjoint method cannot evaluate

the uncertainty in its estimations, something which sequential Bayesian ﬁlters obtain in a

straightforward manner. Such uncertainties provide valuable information related to both

the estimations and the optimum solution. For example, the uncertainties provide feedback

for the experimental design that helps to identify the parameters of interest with the re-

quired accuracy. The quantiﬁcation of uncertainty is currently a very important issue in the

application of DA to massive simulation models.

This paper describes an adjoint-based DA methodology that simultaneously estimates

the optimum solution and its uncertainty, and is capable of being applied to simulation

models with a huge number of degrees of freedom. We ﬁrst construct a method to estimate

the parameters and initial states involved in an autonomous system, and then validate

our approach using a PF model as a testbed. Section II introduces the formulation of an

adjoint-based DA method to simultaneously obtain an estimation and its uncertainty using

second-order information of the posterior PDF. Section III describes the formulation of an

estimation test using synthetic data generated from the time series given by Kobayashi’s PF

model [1]. Section IV presents and discusses the results of estimation tests, and Section V

concludes this paper by summarizing the results of this study.

II. METHOD

A. State-space model and cost function

DA based on Bayesian statistics always starts by deﬁning a state-space model, which

consists of a system model and an observation model. The system model describes how

a state vector evolves over time in accordance with a given simulation model. The state

vector contains all time-dependent variables used in the simulation model and sometimes

the model parameters.

4

Suppose an autonomous simulation model is given by ∂z/∂t = A(z; a), where z(t) ∈ RNz

denotes a time-dependent variable and A : RNz → RNz is a function of z and a time-invariant

parameter vector a ∈ RNa. The system model describes the time evolution of a state vector

consisting of z and a. Let X(t) = (cid:0)z⊤, a⊤(cid:1)⊤ ∈ RN be the state vector, where •⊤ denotes

the transpose of • and N = Nz + Na. Since a is time-invariant, i.e., ∂a/∂t = 0, the system

model can be represented by

∂X
∂t

= f (X) ,

(1)

where f : RN → RN is deﬁned as fi = Ai for 1 ≤ i ≤ Nz and fi = 0 for Nz + 1 ≤ i ≤ N.

The observation model describes how X(t) relates to a time series of observation data

D(t) ∈ RK, where K denotes the dimension of the observations. Considering that the data

include noise, the observation model can be described as

D = ˇh (X) + Ω,

(2)

where ˇh : RN → RK is an observation operator that outputs quantities from X comparable
with the data and Ω(t) denotes observation noise. In this paper, we assume that f and ˇh are

nonlinear functions, and Ω is white noise that follows a normal distribution with a diagonal

covariance matrix. Our purpose is to obtain the optimum initial state X(0) together with

the uncertainties of the variables of interest.

In consideration of PF models, we also assume that X(0) is constrained by

X Lower

i

< Xi(0) < X Upper

i

(i = 1, · · · , N),

(3)

where X Lower ∈ RN and X Upper ∈ RN denote the lower and upper bounds of X(0), respec-

tively.

To simplify our formulation, we normalize X as

θi(t) =

Xi(t) − X Lower
X Upper
− X Lower

i

i

i

(i = 1, · · · , N).

This leads to the following θ-dependent forms of Eqs. (1)-(3):

∂θ
∂t

= F (θ),

D = h (θ) + Ω,

0 < Θi < 1

(i = 1, · · · , N),

5

(4)

(5)

(6)

(7)

where Fi(θ) = fi(X)/(cid:16)X Upper

ing X to θ, and Θ = θ(0).

i

− X Lower

i

(cid:17), h (θ) is an observation operator after transform-

Bayes’ theorem states that a conditional PDF p (Θ|D), which is called the posterior

PDF, can be described as

p(Θ|D) =

p(Θ)p (D|Θ)

p(D)

,

(8)

where p(Θ) and p (D|Θ) are called the prior PDF and likelihood, respectively. Note that

p(D) is constant, since D is a deﬁnite vector. Thus, Eq. (8) implies that p (Θ|D) is

proportional to a product of the prior PDF and the likelihood.

The prior PDF contains prior information provided by experience and intuition. If we

suppose that this prior information is the constraint condition given by Eq. (7) and that Θi

is independent for each i, p(Θ) is given by a product of prior PDFs of Θi,

where

When observation data are obtained at t = t1, t2, · · · , tn, p (D|Θ) can be written as

p(Θ) =

p(Θi),

N

Yi=1

1 for 0 < Θi < 1

0

otherwise.

p(Θi) =


p (D|Θ) =

p (Ωk(ts)) ,

n

K

Ys=1
Yk=1
exp"−

1

k

p2πσ2

(9)

(10)

(11)

(12)

where

p (Ωk(ts)) =

{Dk(ts) − hk (θ(ts))}2

2σ2
k

# ,

and σk is the standard deviation of Ωk (k = 1, · · · , K). We consider σk to be a hyper-

parameter.

This paper deﬁnes the optimum solution ˆΘ to be the Θ that maximizes the posterior

PDF p (Θ|D). For the convenience of numerical computation, we aim to minimize a cost

function

n

J =

k)

K

Xk=1"log(2πσ2

2

Xs=1

+

{Dk(ts) − hk (θ(ts))}2

2σ2
k

# subject to 0 < Θi < 1,

(13)

which comes from a negative logarithmic posterior PDF, i.e., p(Θ|D) ∝ e−J , to ﬁnd ˆΘ,

rather than maximizing p (Θ|D). The constraint in Eq. (13) arises from the term − log p (Θ),

which appears when calculating − log p(Θ|D).

6

An optimum solution ˆσk for σk can be determined as follows. By letting ∂J/∂σk = 0, we

obtain

[Dk(ts) − hk (θ(ts))]2.

(14)

σk =vuut

1
n

n

Xs=1

Then, ˆσk is obtained by substituting θ, which is calculated by Eq. (5) using θ(0) = ˆΘ, into

Eq. (14).

B. Optimization via an adjoint method

Typically, J is optimized using a gradient method such as steepest gradient descent, the

nonlinear conjugate gradient method, or the Limited-memory Broyden-Fletcher-Goldfarb-

Shanno (LBFGS) method [28]. Gradient methods require ∂J/∂Θ to update J, but it is

diﬃcult to calculate this quantity because J does not explicitly include Θ, as seen in Eq.

(13). Generally, J is fully determined by setting Θ = θ(0) through Eq. (5), so that J must

be written as a function of Θ, i.e., J(Θ). According to Eq. (13), J is also a function of θ (ts)

(s = 1, · · · , n) that satisﬁes Eq. (5), not including Θ. Summarizing these two expressions

for J:

J(Θ) =Z tf

0

dt J (θ) +Z tf

0

dt λ⊤(cid:18)F −

∂θ

∂t(cid:19) ,

(15)

where tf is an arbitrary time later than tn, and λ(t) ∈ RN denotes a vector of the Lagrange

multipliers that impose Eq.(5) as the constraint condition of θ. J is the time-dependent

function

n

J (θ) =

δ(t − ts)

Xs=1

k)

K

Xk=1"log(2πσ2

2

+

{Dk(t) − hk (θ(t))}2

2σ2
k

# ,

(16)

that satisﬁes J =R tf

of Eq. (15), we have a time evolution equation for λ:

0 dt J , where δ(t) denotes the Dirac delta function. Taking a variation

where

∂λ
∂t

∂θ(cid:19)⊤
+(cid:18)∂F

λ +

∂J
∂θ

= 0,

λ(0) =

∂J
∂Θ
λ(tf ) = 0.

,

(17)

(18)

(19)

Details of the derivation can be found in [26, 29]. Solving Eq. (17) backwardly in time with

the condition in Eq. (19), we obtain the objective ∂J/∂Θ as λ(0). Such a procedure to

7

obtain the gradient of the cost function using the adjoint equation (Eq. (17)) is called the

adjoint method.

When we apply the adjoint method to our problem, a variable transformation is needed

in the process of updating Θ based on a gradient method, since Θ has the constraint shown

in Eq. (7). The variable transformation

Ψi = log Θi − log (1 − Θi)

(i = 1, · · · , N)

(20)

converts the constrained optimization problem of Θ into an unconstrained one with respect

to Ψ. The update procedure is as follows. After obtaining ∂J/∂Θ by the adjoint method

based on Eqs. (17)-(19), we convert Θ to Ψ using Eq. (20) and ∂J/∂Θ to ∂J/∂Ψ as

∂J
∂Ψi

= Θi (1 − Θi)

∂J
∂Θi

(i = 1, · · · , N).

(21)

Using this formulation to update Ψ, we can obtain an updated Θ from the inverse trans-

formation of Eq. (20):

Θi =

1

1 + exp (−Ψi)

(i = 1, · · · , N).

(22)

Although this update procedure does not allow Θi to be exactly 0 or 1, owing to the deﬁnition

of Eq. (22), Θi can be suﬃciently close to 0 or 1 to pose no problem in practical cases.

The adjoint method calculates ∂J/∂Θ for a ﬁxed σk, so that an optimization of σk is

to be done at the same time as Θ by substituting Eq. (14) into Eq. (16) every time Θ is

updated.

The advantages of the adjoint method over sequential Bayesian ﬁlters are that only O(C)
computations and O(N) memory are required to ﬁnd ˆΘ, where C is the number of compu-

tations needed to run the given simulation model from t = 0 to t = tf .

C. Evaluation of uncertainty via a second-order adjoint method

The adjoint method described in Section II B gives the optimum solution ˆΘ that max-

imizes p (Θ|D). However, it does not provide information about the behavior of p (Θ|D)
in the neighborhood of Θ = ˆΘ, which reﬂects the uncertainty in the estimation of ˆΘ. To

extract such information, another procedure must be implemented on the adjoint method.
Considering that ∂J/∂Θ|Θ= ˆΘ = 0, the Taylor expansion of J with respect to Θ − ˆΘ is

J(Θ) ∼ J( ˆΘ) +

1
2

(Θ − ˆΘ)⊤H(Θ − ˆΘ),

(23)

8

We normalize p(Θ|D) ∝ e−J into which Eq. (23) is substituted as

∂2J

∂Θi∂Θj(cid:12)(cid:12)(cid:12)(cid:12)Θ= ˆΘ
exph− 1

2(Θ − ˆΘ)⊤H(Θ − ˆΘ)i

(2π)N/2 |H −1|1/2

where terms of order higher than three have been neglected, and H is a Hessian matrix

given by

Hi,j =

(i, j = 1, · · · , N).

(24)

p(Θ|D) ∼

,

(25)

where H −1 is the inverse of H and |•| denotes the determinant of •. Equation (25) indicates
that, in the neighborhood of Θ = ˆΘ, p (Θ|D) can be approximated by a multivariate normal
distribution with mean vector ˆΘ and covariance matrix H −1. Let Θl (1 ≤ l ≤ N) be a

component of interest in Θ. Integrating Eq. (25) over all variables except for Θl, the marginal
distribution with respect to Θl is the normal distribution with mean ˆΘl and variance (H −1)l,l,
which is the l-th diagonal element of H −1. This means that the uncertainty of Θl is given by
(H −1)l,l. When N ≫ 1, it is unrealistic to obtain H −1 directly by numerically diﬀerentiating
H, which is generally dense, as this would require O(CN 2 + N 3) computations and O(N 2)

memory. In practical cases, it is not necessary to evaluate all elements of H −1, since the

number of elements of interest is usually much smaller than N. Therefore, we propose to

use a second-order adjoint method [30, 31] to eﬃciently obtain such uncertainties in massive

autonomous systems. The following procedure to obtain the uncertainties requires O(C)

computations and O(N) memory for each uncertainty. When evaluating the uncertainty of

Θl, we consider a linear equation of r ∈ RN :

Hr = q,

(26)

where q ∈ RN is a vector with elements ql = 1 and qi6=l = 0. The solution ˆr obviously
j=1(H −1)l,jqj = (H −1)l,l. Note that H is a constant matrix that
requires complex computations because of its large dimension. We must obtain ˆr from an

includes (H −1)l,l as ˆrl =PN

initial guess via an iterative technique such as the conjugate gradient method or conjugate

residual method. The iterative method needs, in the way of the iteration, to compute each

of the Hessian-vector products Hγ for a vector γ. The second-order adjoint method enables

us to compute such Hessian-vector products.

Let ξ(t) ∈ RN and ζ(t) ∈ RN be perturbations of ˆθ and ˆλ, which respectively correspond

9

to θ and λ when Θ = ˆΘ. Their time evolutions are given by

ξ,

ˆθ

=

∂F

∂ξ
∂t

∂θ(cid:12)(cid:12)(cid:12)(cid:12)θ=
∂θ2 ξ(cid:19)⊤(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)θ=
ζ + (cid:18) ∂2F

ˆλ +

ˆθ

∂2J

∂θ2(cid:12)(cid:12)(cid:12)(cid:12)θ=

(27)

(28)

ξ = 0.

ˆθ

∂ζ
∂t

∂θ(cid:19)⊤(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)θ=
+ (cid:18)∂F

ˆθ

The combination of Eqs. (27) and (28), which are called the tangent linear model and second-

order adjoint model, respectively, gives the Hessian-vector product for an arbitrary vector.

Solving Eq. (27) forwardly in time for a given vector ξ(0) = γ, we obtain the time series of

ξ. Then, solving Eq. (28) backwardly with the given ζ(tf ) = 0 and the time series ξ, we

obtain the objective Hessian-vector product ζ(0) = Hγ. The detailed derivation is given

in [30].

III. TWIN EXPERIMENT

A. Kobayashi’s phase-ﬁeld model

The accuracy of the proposed method is veriﬁed through numerical simulations termed

“twin experiments,” details of which are given in Section III B. We choose a two-dimensional

Kobayashi’s PF model as the testbed in the twin experiments. Kobayashi’s PF model

describes the fundamental growth dynamics of two phases, such as in solidiﬁcation or a

phase transformation. The time evolution of one of the phases is described by

τ

∂φ
∂t

= ǫ2 △ φ + φ (1 − φ)(cid:18)φ + m −

1

2(cid:19) , −

1
2

< m <

1
2

(29)

where the PF variable φ(x, t) denotes the existence probability of the relevant phase, e.g.,

solid or liquid. The parameters τ and ǫ non-dimensionalize time and space, respectively,

and m characterizes the velocity of the interface between the two phases. We assume that

these parameters are time-invariant constants. We know that φ(x, t) should be constrained

in 0 ≤ φ(x, t) ≤ 1, as it describes a probability. This condition is automatically satisﬁed by

setting the initial phase to 0 ≤ φ(x, 0) ≤ 1, since φ = 0 and φ = 1 are the ﬁxed points of

Eq. (29).

Kobayashi’s PF model underlies various PF models that describe physical phenomena

such as dendrite growth [1, 5], crack propagation [32, 33], and interface-driven pattern

10

(a)(cid:1)Initial state (cid:1)t = 0.0τ(cid:1)(b)(cid:1)

t = 5.0τ(cid:1)

(c)(cid:1)

t = 10.0τ(cid:1)

(cid:1)
ε
0
0
2

300ε(cid:1)

(d)(cid:1)

t = 20.0τ(cid:1)

(e)(cid:1)

t = 50.0τ(cid:1)

(f)(cid:1)

t = 100.0τ(cid:1)

1.0(cid:1)

0.8(cid:1)

0.6(cid:1)

0.4(cid:1)

0.2(cid:1)

0.0(cid:1)

FIG. 1. Time evolution of phase ﬁeld φ starting from the initial state shown in (a) for m = 0.1.

(b)-(f) show φ at t = 5.0τ , 10.0τ , 20.0τ , 50.0τ , and 100.0τ , respectively. The color indicates the

magnitude of φ.

formation [34]. Therefore, Kobayashi’s PF model is a good choice for verifying whether the

proposed DA method works well, and is a ﬁrst step towards future applications in more

complex PF models.

B.

Synthetic data

Twin experiments are often conducted in the ﬁeld of DA to verify a newly developed

method on the basis of synthetic data. The synthetic data are usually generated using the

given simulation model, in which the true parameters and initial state are pre-determined.

Veriﬁcation then proceeds by checking whether the DA method applied to the synthetic

data reproduces the true parameters and initial state. In our case, the synthetic dataset is a

time series of φ that is numerically calculated by Kobayashi’s PF model with a true initial

state and parameter m. The synthetic data are then contaminated by observation noise

that follows a normal distribution with mean zero and variance σ2. The twin experiments

are intended to conﬁrm that the proposed method estimates the initial state and parameter

with the associated uncertainty.

Let nx and ny be the numbers of grid points in the x- and y-directions, respectively, M

be the total number of grid points, i.e., M = nxny, and h be the grid spacing. A periodic

boundary condition is imposed on the boundary of the computational domain. Letting φi(t)

be the phase at the i-th grid point, Eq. (29) can be rewritten as

τ

∂φi
∂t

= ǫ2 △i φi + φi (1 − φi)(cid:18)φi + m −

1

2(cid:19) ,

(30)

11

where △i denotes a second-order diﬀerence operator acting on the four nearest neighbors of

the i-th grid point Si, i.e., △iφi =Pj∈Si

(φj − φi) /h2.

Figure 1 shows the time evolution of φ in two-dimensional space, where nx = 300, ny =

200, h = ǫ, and the time increment in the Euler method is 0.1τ . The assumed initial

state is shown in Fig. 1(a), and the true value for the parameter m is assumed to be 0.1.

Figures 1(b)-(f) show snapshots indicating that the interface between the phases φ = 0 and

φ = 1 migrates, expanding the area of φ = 1. Motivated by the fact that such snapshots are

sometimes obtained as observation data in practical experiments, we use snapshots such as

in Figs. 1(b)-(f) with added observation noise as the synthetic data for the twin experiments.

The synthetic data are given by

φobs

i

(t) = φi(t) + ωi(t)

(i = 1, .., M),

(31)

where ωi(t) is normally-distributed observation noise with mean zero and variance σ2.

When DA is applied to Kobayashi’s PF model, the time evolution equation with respect

to m is needed to construct a system model within the state-space model (Section II A).

The time evolution equation can be written as

τ

∂b
∂t

= 0,

(32)

where b = m + 1/2, which denotes the normalization of m, i.e., 0 < b < 1.

C. Cost function

We consider the synthetic observation data to be the snapshots of φ obtained from t =

Tmin to t = Tmax with time interval ∆T . Let T be the set of observation times and n be the

number of observations. Combining Eqs. (13) and (31), J can be rewritten as

J =

nM
2

log(2πσ2) +

1

2σ2 Xts∈T

M

i

Xi=1 (cid:0)φobs

(ts) − φi(ts)(cid:1)2

The values of φi(0) and b(0) that minimize Eq. (33) also minimize

where

J ′ =Z T

0

dt J ′,

J ′ =

1

2 Xts∈T

δ(t − ts)

M

i

Xi=1 (cid:0)φobs

(t) − φi(t)(cid:1)2

,

12

.

(33)

(34)

(35)

since σ is independent of φi(0) and b(0). When the optimum ˆφi(0) for φi(0) and ˆb(0) for
b(0) are obtained by minimizing J ′, the optimum σ can be obtained as

ˆσ =vuut

1

nM Xts∈T

M

Xi=1 (cid:16)φobs

i

(ts) − ˆφi(ts)(cid:17)2

,

(36)

where ˆφi(t) denotes φi(t) simulated using ˆφi(0) and ˆb(0).

D. Procedures

Prior to applying the proposed method to the PF model, the constraint for the initial

state 0 ≤ φi(0) ≤ 1 is to be changed to 0 < φi(0) < 1 to satisfy the domain of the variable

transformation Eq. (20). The state variables θ(t) ∈ RM +1 and Θ ∈ RM +1 can be deﬁned as

θ = (φ1, · · · , φM , b)⊤

Θ = (φ1(0), · · · , φM (0), b(0))⊤ .

(37)

The constraint for Θ becomes 0 < Θi < 1 (i = 1, · · · , M + 1). The system models of

Eqs. (30) and (32) are rewritten in terms of θ as

=


τ

∂θi
∂t

ǫ2 △i θi + θi (1 − θi) (θi + θM +1 − 1) for i = 1, · · · , M,

0

otherwise.

(38)

Substituting the right-hand side of this equation for F in Eq. (17), replacing J (Eq. (17))

with J ′ (Eq. (35)), and replacing J (Eq. (18)) with J ′ (Eq. (34)), the adjoint method

described by Eqs. (17)-(19) is rewritten as

− τ

∂λi
∂t

=


M

ǫ2 △i λi +(cid:8)−3θ2
Xj=1

θj (1 − θj) λj

i + (4 − 2θM +1) θi + θM +1 − 1(cid:9) λi +

otherwise,

λ(0) =

∂J ′
∂Θ

,

λ(tf ) = 0.

∂J ′
∂θi

for i = 1, · · · , M,

(39)

(40)

(41)

We adopt the LBFGS technique [28] as the gradient method for optimizing Θ. Starting

from an initial guess, the LBFGS method updates Θ by satisfying 0 < Θi < 1 for all i owing

to the variable transformation mentioned in Section II B. To tune the LBFGS method, we

13

set the tolerance to 10−8 and determine the step length by Armijo’s rule [35]. Once the
optimum ˆΘ has been obtained, the optimum standard deviation ˆσ can be estimated by
Eq. (36) and the optimum ˆm for m is given by ˆΘM +1 − 1/2 or ˆb(0) − 1/2.

One of the most remarkable features of the proposed method is its evaluation of the

uncertainties. These uncertainties can provide important information that is beneﬁcial to

updating the experimental design.
In accordance with the procedure mentioned in Sec-
tion II C, we consider a linear equation H ′r = q, where H ′ = ∂2J ′/∂Θ2|Θ= ˆΘ is a Hessian
matrix, r ∈ RM +1 is a vector to be determined, and q ∈ RM +1 is a vector containing the

elements qM +1 = 1 and qi6=M +1 = 0. The uncertainty δ ˆm can be computed from the solution

ˆr as

δ ˆm = ˆσpˆrM +1.

(42)

The conjugate residual method, in which the tolerance is set to 10−8, is adopted to solve

the linear equation. The second-order adjoint method computes each of the Hessian-vector

products H ′γ that appears in the optimization process of the conjugate residual method.

Substituting the right-hand side of Eq. (38) for F in Eq. (27), the tangent linear model can

be rewritten as




τ

∂ξi
∂t

=

ǫ2 △i ξi + ˆθi(cid:16)1 − ˆθi(cid:17) ξM +1 +n−3ˆθ2

i +(cid:16)4 − 2ˆθM +1(cid:17) ˆθi + ˆθM +1 − 1o ξi

for i = 1, · · · , M,

(43)

0

otherwise,

with the initial condition ξ(0) = γ, where ˆθ denotes the state vector corresponding to ˆΘ.

Substituting the right-hand side of Eq. (38) for F in Eq. (28) and replacing J (Eq. (28))

with J ′ (Eq. (35)), the second-order adjoint model in Eq. (28) becomes

− τ

∂ζi
∂t

=




ǫ2 △i ζi

∂2J ′

+n−3ˆθ2
i +(cid:16)4 − 2ˆθM +1(cid:17) ˆθi + ˆθM +1 − 1o ζi
−(cid:16)6ˆθi + 2ˆθM +1 − 4(cid:17) ˆλiξi −(cid:16)2ˆθi − 1(cid:17) ˆλiξM +1
∂θi∂θj(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)θ=
Xj=1
Xj=1hˆθj(cid:16)1 − ˆθj(cid:17) ζj −(cid:16)2ˆθj − 1(cid:17) ˆλjξji

ξj

ˆθ

otherwise,

M

+

M

for i = 1, · · · , M,

14

(44)

where ˆλ is the perturbation of ˆθ. Solving Eq. (44) with the condition ζ(tf ) = 0, we obtain
the objective Hessian-vector product as ζ(0) = H ′γ.

IV. RESULTS AND DISCUSSION

The proposed method is veriﬁed through three twin experiments: (I) estimation of the

parameter m conditional on the true initial state φtrue

i

(0) (Section IV A), (II) simultaneous

estimation of the parameter m and the initial state φi(0) (Section IV B), and (III) estima-
tion of the initial state φi(0) conditional on the true parameter mtrue (Section IV C). Twin

experiment I investigates how the estimation depends on observation data, twin experiment

II veriﬁes whether the proposed method outputs correct estimations, even for massive sim-

ulation models, and twin experiment III validates the unknown phenomena that appear in

the results of experiment II.

A. Twin experiment I: Parameter estimation

Twin experiment I investigates the inﬂuences of three parameters related to the observa-

tion data: (i) the length of the observation time Tmax, (ii) the time interval of the observations

∆T , and (iii) the standard deviation of the observation noise σ. Table I summarizes the

parameter values used in the experiments. The ﬁrst observation is assumed to occur at

Tmin = 0.1τ , and the true value of m is assumed to be mtrue = 0.1. The initial guess used

in the LBFGS method is m = −0.1. In this experiment, the true phase ﬁeld at t = 0, i.e.,

φtrue

i

(0) (see Fig. 1(a)) is given as the initial state. The results reported here are the average

values of ˆm and δ ˆm over twenty trials with diﬀerent random seeds.

Figure 2 shows the results of Test I-(i). Figure 2 (a) indicates that the parameter esti-

mation is successful, because the true parameter is included in the range ˆm − δ ˆm < mtrue <

ˆm + δ ˆm. The estimation of the uncertainty δ ˆm fails when Tmax is at its minimum, i.e.,

Tmax = 0.2τ , because insuﬃcient data cause ˆrM +1 to become negative. Figure 2(b) indicates

that δ ˆm is proportional to T −1.5

max in this range. The reason that the decrease is more rapid
than the law of large numbers would suggest is related to the nonlinearity of Kobayashi’s

PF model. A theoretical evaluation actually indicates that δ ˆm is proportional to T −2.5
max

when Tmax ≪ τ , and will converge with a constant value as Tmax increases. This is because

15

Tmax

Test I-(i) 0.2τ − 102.4τ

∆T

0.1τ

Test I-(ii)

102.5τ

0.1τ − 51.2τ

σ

0.01

0.01

Test I-(iii)

102.4τ

0.1τ

10−5 − 1.0

TABLE I. Length of the observation time Tmax, time interval of observations ∆T , and standard

deviation of observation noise σ used in twin experiment I, where τ is the unit of time in the

simulation. Test I-(i), (ii) and (iii) investigate how the estimation depends on Tmax, ∆T and σ,

respectively.

(a)

-3

-3

-3

6!10

4!10

2!10

0!10

0
0!10

-2!10

-2!10

-3

-3

-4!10

-6!10

-3

-3

-1

10

0

10

1

10

2

10

(b)

-2

10

-3

10

-4

10

-5

10

-6

10

-1.5

-7

10

10

-1

0

10

1

10

2

10

FIG. 2. Results of twin experiment I-(i). The length of each error bar for the optimum parameter

ˆm in (a) corresponds to the estimated uncertainty δ ˆm in (b). The uncertainty cannot be determined

when Tmax = 0.2τ . The black solid line in (b) indicates a power function of order −1.5.

no additional information is included in the observation data after φ(x, t) becomes almost

uniform across the entire computational domain. Figure 3 shows the results of Test I-(ii).

Figure 3(a) indicates that the proposed method successfully reproduces the true parameter,

and Fig. 3(b) shows that δ ˆm is proportional to ∆T 0.5 when ∆T < τ , which seems to follow

the law of large numbers. Figure 4 shows the results of Test I-(iii). Figure 4(a) indicates that

(a)

-6

8!10

-6

4!10

0!10

0
0!10

-3

-2!10

-6

-4!10

(b)

-5

10

0.5

-6

10

-6

-8!10

-1

10

0

10

1

10

2

10

-1

10

0

10

1

10

2

10

FIG. 3. Results of twin experiment I-(ii). The length of each error bar for optimum parameter ˆm

in (a) corresponds to the estimated uncertainty δ ˆm in (b). The black solid line in (b) indicates a

power function of order of 0.5.

16

(a)

8!10

6!10

4!10

2!10

-5

-5

-5

-5

0

0!10

0!10

-5

-2!10

-2!10

-3

-5

-5

-4!10

-6!10

-5

10

-4

10

-3

10

-2

10

-1

10

0

10

(b)

-4

10

-5

10

-6

10

-7

10

-8

10

-9

10

-10

10

1.0

-5

10

-4

10

-3

10

-2

10

-1

10

0

10

FIG. 4. Results of twin experiment I-(iii). The length of each error bar for optimum parameter

ˆm in (a) corresponds to the estimated uncertainty δ ˆm in (b). The black solid line in (b) indicates

a linear function.

(a)

 0.3

 0.2

 0.1

 0

-0.1

   
   

   
   

(b)

(c)

0

10

1

10

2

10

3

10

4

10

5

10

6

10

Iteration steps

FIG. 5. Results of twin experiment II. (a) How the LBFGS method updates m when the obser-

vation data noise has a small (red) and large (green) standard deviation. (b) The optimum initial

state of the phase ﬁeld φi(0) in the case of small noise, and (c) that in the case of large noise.

the parameter estimation is again successful, and Fig. 4(b) shows that δ ˆm is proportional

to σ. In summary, the results of Test I demonstrate that the proposed method is capable of

estimating the true parameter and the associated uncertainty.

B. Twin experiment II: Simultaneous estimation

Twin experiment II investigates the inﬂuence of the observation noise in two cases: (i)

when the noise has a small standard deviation (σ = 10−4) and (ii) when the noise has a

large standard deviation (σ = 0.3). The true parameter is assumed to be mtrue = 0.1, and

the true initial state φtrue

i

(0) is assumed to be the phase ﬁeld shown in Fig. 1(a). The other

observational conditions are Tmin = 5.0τ , Tmax = 30.0τ , ∆T = 0.1τ , and the initial guesses

are φi(0) = 0.2 and m = −0.2.

Figure 5 shows the results of Test II. Figure 5(a) indicates how each iteration of the

LBFGS method updates the estimation of m.

It is clear that each estimation converges

17

(b)

(a)

(c)

1.5!10

1.0!10

5.0!10

6

6

5

0

10

1

10

2

10

3

10

4

10

5

10

6

10

Iteration steps

FIG. 6. Results of twin experiment III. Estimated initial states of the phase ﬁeld φi(0) (a) after

the 31st step and (b) after the ﬁnal step in the iteration of the LBFGS method. (c) Improvement

in the cost function J ′.

with mtrue. Figures 5(b) and (c) indicate the estimated initial states ˆφi(0) in Test II-(i)

and (ii), respectively. These results appear to be almost consistent with the true initial

states, although “spot-like” pattern appears in Fig. 5(c). This spot-like pattern would be

conspicuous if the observation noise was large or if the time of the ﬁrst observation Tmin was

far from t = 0. Additionally, the spot-like pattern does not disappear under lower tolerance

levels.

C. Twin experiment III: Estimation of initial state

Twin experiment III conﬁrms whether the estimation of m aﬀects the generation of the

spot-like pattern found in twin experiment II-(ii). Therefore, twin experiment III is set up

to estimate only the initial state φi(0) with a ﬁxed parameter m = 0.1. The true initial

state φtrue

i

(0) is assumed to be the phase ﬁeld shown in Fig. 1(a). The other observational

conditions are Tmin = 8.0τ , Tmax = 30.0τ , ∆T = 0.1τ and σ = 0.3, and the initial guess is

φi(0) = 0.2.

Figures 6(a) and (b) show the estimated initial states after the 31st and after the ﬁnal

iterations, respectively, and Fig. 6(c) shows how the cost function J ′ varies with the iteration.

A spot-like pattern again appears in the estimated initial state (Fig. 6(b)) as the number

of iterations increases. Note that the cost function J ′ is almost the same after the 31st step

and after the ﬁnal step, although Figs. 6(a) and (b) are much diﬀerent.

This is caused by a feature inherent in the two-dimensional Kobayashi’s PF model. When

18

FIG. 7. Phase diagram for an axisymmetric two-dimensional Kobayashi’s PF model. The red line

indicates the critical radius as a function of the parameter m. The region above or below the

critical line corresponds to a spot growing or decaying with time, respectively.

(a)

(b)

(c)

FIG. 8. Time evolutions of the phase ﬁelds starting from diﬀerent initial states φi(0): (a) the esti-

mated initial state obtained after the 31st step (Fig. 6(a)), (b) that after the ﬁnal step (Fig. 6(b)),

and (c) the true initial state (Fig. 1(a)).

a spot of radius R0 evolves with time based on the PF model, whether it grows or decays

depends on the relation between m and R0. Figure 7 shows the phase diagram obtained by

the two-dimensional Kobayashi’s PF model under the assumption of the axial symmetry.

The destiny of a given spot depends on whether the radius is above or below the critical line,

which means the critical radius is approximately inversely proportional to m [36]. The radius

of each spot in Fig. 6(b) is actually smaller than the critical radius, which is approximately

7.3ǫ in the case of m = 0.1.

Time evolutions starting from three diﬀerent initial states shown in Fig. 6. These results

indicate that the phase ﬁelds at the time of the ﬁrst observation, i.e., t = 8.0τ , are completely

coincident (Fig. 8).

19

V. CONCLUSIONS

This paper has described an adjoint-based DA method for massive autonomous models

that not only determines the optimum estimates but also gives their uncertainties within a

practical computation time and reasonable resource requirements. The uncertainties can be

obtained as several diagonal components of the inverse Hessian matrix, which is the covari-

ance matrix of the normal distribution that approximates the posterior PDF in the neighbor-

hood of the optimum estimates. This proposed approach provides a new methodology for

evaluating uncertainties using a second-order adjoint method that obtains Hessian-vector

products in the process of the computation. Twin experiments using a two-dimensional

Kobayashi PF model demonstrated the validity of the proposed method.

The uncertainties associated with physical quantities of interest depend on the quality

and amount of data. Thus, conducting twin experiments prior to practical experiments

allows us to determine how many observations are required to obtain the physical quantities

of interest to the desired accuracy. Such feedback to practical experiments is already possible

in systems with only a few degrees of freedom, but the proposed method makes this possible

for massive simulation models.

The proposed method is not only applicable to PF models, but to various models de-

scribed by autonomous systems, e.g., shallow water equations, Navier equations for elastic

materials, and Boltzmann equations. The proposed method is of great utility for evaluating

the uncertainties of model parameters through DA, which is important in various ﬁelds of

science, even when using massive models.

ACKNOWLEDGMENTS

This study is supported by the Cross-ministerial Strategic Innovation Promotion Program

(SIP). The authors are grateful to Prof. Munekazu Ohno, Prof. Peter XK Song and Dr.

Jonggyu Baek for useful discussions.

[1] R. Kobayashi, Physica D 63, 410 (1993).

20

[2] W. J. Boettinger, J. A. Warren, C. Beckermann, and A. Karma, Annu. Rev. Mater. Res. 32,

163 (2002).

[3] L.-Q. Chen, Annu. Rev. Mater. Res. 32, 113 (2002).

[4] Y. Tsukada, Y. Murata, T. Koyama, and M. Morinaga, Mater. Trans. 49, 484 (2008).

[5] T. Shimokawabe, T. Aoki, T. Takaki, T. Endo, A. Yamanaka, N. Maruyama, A. Nukada, and

S. Matsuoka, in Proceedings of 2011 International Conference for High Performance Com-

puting, Networking, Storage and Analysis, SC ’11 (ACM, New York, NY, USA, 2011) pp.

3:1–3:11.

[6] M. Ohno, T. Yamaguchi, D. Sato, and K. Matsuura, Comp. Mater. Sci. 69, 7 (2013).

[7] T. Takaki, ISIJ Int. 54, 437 (2014).

[8] D. Jacqmin, J. Comput. Phys. 155, 96 (1999).

[9] M. De Menech, Phys. Rev. E 73, 031505 (2006).

[10] H. G. Lee, K. Kim, and J. Kim, Int. J. Numer. Meth. Eng. 85, 1633 (2011).

[11] S. Reich and C. Cotter, Probabilistic Forecasting and Bayesian Data Assimilation (Cambridge

University Press, 2015).

[12] E. Kalnay, Atmospheric Modeling, Data Assimilation and Predictability (Cambridge Univer-

sity Press, 2003).

[13] T. Tuyuki and T. Miyoshi, J. Meteorol. Soc. Jpn. Ser. II 85B, 331 (2007).

[14] M. Ghil and P. Malanotte-Rizzoli, Advances in Geophysics, Vol. 33 (Elsevier, 1991) pp. 141 –

266.

[15] M. Kano, S. Miyazaki, Y. Ishikawa, Y. Hiyoshi, K. Ito, and K. Hirahara, Geophys. J. Int.

203, 646 (2015).

[16] T. Maeda, K. Obara, M. Shinohara, T. Kanazawa, and K. Uehira, Geophys. Res. Lett. 42,

7923 (2015).

[17] E. Motohashi, N. Isozaki, H. Nagao, and T. Higuchi, J. Oper. Res. Soc. Jpn. 57, 574 (2012).

[18] K. Sasaki, A. Yamanaka, S.-i. Ito, and H. Nagao (unpublished)

[19] G. Evensen, Ocean Dynam. 53, 343 (2003).

[20] P. L. Houtekamer and H. L. Mitchell, Mon. Weather Rev. 126, 796 (1998).

[21] G. Ueno, T. Higuchi, T. Kagimoto, and N. Hirose, SOLA 3, 5 (2007).

[22] G. Kitagawa, Introduction to Time Series Modeling, Chapman & Hall/CRC Monographs on

Statistics & Applied Probability (CRC Press, 2010).

21

[23] A. Doucet, S. Godsill, and C. Andrieu, Stat. Comput. 10, 197 (2000).

[24] H. Nagao, T. Higuchi, S. Miura, and D. Inazu, Comput. J. 56, 355 (2013).

[25] J. M. Lewis and J. C. Derber, Tellus A 37A, 309 (1985).

[26] F.-X. Le Dimet and O. Talagrand, Tellus A 38A, 97 (1986).

[27] M. Iri and K. Kubota, JSIAM 1, 17 (1991).

[28] J. Nocedal, Math. Comput. 35, 773 (1980).

[29] Z. Wang, I. Navon, F. Le Dimet, and X. Zou, Meteorol. Atmos. Phys. 50, 3 (1992).

[30] Z. Wang, K. Droegemeier, and L. White, Comput. Optim. Appl. 10, 283 (1998).

[31] F.-X. Le Dimet, I. Navon, and D. N. Daescu, Mon. Weather Rev. 130, 629 (2002).

[32] I. S. Aranson, V. A. Kalatsky, and V. M. Vinokur, Phys. Rev. Lett. 85, 118 (2000).

[33] R. Spatschek, M. Hartmann, E. Brener, H. M¨uller-Krumbhaar, and K. Kassner, Phys. Rev.

Lett. 96, 015502 (2006).

[34] S. Komura and Y. Yamazaki, J. Phys. Soc. Jpn. 76, 083801 (2007).

[35] L. Armijo, Paciﬁc J. Math. 16, 1 (1966).

[36] M. Castro, Phys. Rev. B 67, 035412 (2003).

22

