Moment dynamics for a class of time-triggered stochastic hybrid

systems

Mohammad Soltani1, Abhyudai Singh2

6
1
0
2

 
r
a

 

M
6
1

 
 
]
S
D
h
t
a
m

.

[
 
 

1
v
0
2
2
5
0

.

3
0
6
1
:
v
i
X
r
a

Abstract— Stochastic Hybrid Systems (SHS) constitute an
important class of mathematical models that integrate discrete
stochastic events with continuous dynamics. The time evolution
of statistical moments is generally not closed for SHS, in the
sense that the time derivative of the lower-order moments de-
pends on higher-order moments. Here, we identify an important
class of SHS where moment dynamics is automatically closed,
and hence moments can be computed exactly by solving a
system of coupled differential equations. This class is referred
to as linear time-triggered SHS (TTSHS), where the state
evolves according to a linear dynamical system. Stochastic
events occur at discrete times and the intervals between them
are independent random variables that follow a general class of
probability distributions. Moreover, whenever the event occurs,
the state of the SHS changes randomly based on a probability
distribution. Our approach relies on embedding a Markov chain
based on phase-type processes to model timing of events, and
showing that the resulting system has closed moment dynamics.
Interestingly, we identify a subclass of linear TTSHS, where
the ﬁrst and second-order moments depend only on the mean
time interval between events and invariant of their higher-
order statistics. Finally, we discuss applicability of our results
to different application areas such as network control systems
and systems biology.

I. INTRODUCTION

Stochastic hybrid systems (SHS) are increasingly being
used to model noise and uncertainty in physical, biological
and engineering systems. Speciﬁc applications include com-
munication networks [1]–[3], network control systems [4],
[5], air trafﬁc control [6], [7], biological systems [8]–[15],
power grids [16], [17], modeling of energy grids and smart
buildings [18], [19]. We refer interested readers to [20]–[22]
for a detailed mathematical characterization of SHS.

Traditional analysis of SHS relies heavily on various
Monte Carlo simulation techniques, which come at a sig-
niﬁcant computational cost [23], [24]. Since one is often
interested in computing only the lower-order moments of
the state variables, much time and effort can be saved by
directly computing these statistical moments without having
to run Monte Carlo simulations. Unfortunately, moment
calculations in SHS can be non-trivial due to the problem
of unclosed dynamics: the time evolution of lower-order mo-
ments depends on higher-order moments [25]. Closure meth-
ods, that approximate higher-order moments as nonlinear

1M. Soltani

Engineering, University
msoltani@udel.edu

is with Department of Electrical

and Computer
of Delaware, Newark, DE USA 19716.

2A. Singh is with the Department of Electrical and Computer Engineer-
ing, Biomedical Engineering, Mathematical Sciences, Center for Bioinfor-
matics and Computational Biology, University of Delaware, Newark, DE
USA 19716. absingh@udel.edu

functions of lower-order moments, are generally employed
in such cases [26]–[31].

The problem of moment closure leads to an interesting
question: are there classes of SHS where moments can be
computed exactly without the need for closure techniques?
Here, we identify such a class of SHS known as time-
triggered SHS (TTSHS) that are a special case of piecewise-
deterministic Markov processes [32], [33]. The main ingre-
dients of TTSHS are as follows:

1) A continuous state x(t) ∈ Rn that evolves according

to a stable linear dynamical system

˙x(t) = ˆa + Ax(t),

(1)

for some constant vector ˆa and Hurwitz matrix A.

2) Timing of events is determined by a renewal process.
In particular, stochastic events occur at discrete times
ts, s ∈ {1, 2, . . .}, and the intervals ts − ts−1 are in-
dependent and identical random variables drawn from
a given probability density function.

3) A reset map deﬁning the change in x when the event

occurs

x(ts) (cid:55)→ x+(ts),

(2)

where x+(ts) denotes the state of the system just
after the event. While prior work has considered a
deterministic linear reset map

x(ts) (cid:55)→ Jx(ts)

(3)

[34]–[36], we allow x+(ts) to be probabilistically
determined.

Our goal is to connect moments of the continuous state
to the statistics of the time interval T ≡ ts − ts−1. The
key contribution of this work is to model arrival of events
using a phase-type processes [37], and show that the resulting
systems has closed moment dynamics. More speciﬁcally,
the time derivative of an appropriately selected vector of
moments depends only on itself, and not on higher-order
moments. As a consequence, moments can be computed
exactly by solving a system of differential equations. For
the sake of simplicity, we focus on computing the ﬁrst and
second-order moments, but
the ideas can be generalized
to obtain any higher-order moment. In addition, a subclass
of TTSHS is identiﬁed, where the ﬁrst and second order
moments of x depend only on the mean time interval
between events. In this case, making the arrival of events
more random (for ﬁxed mean arrival times) will not result
in higher noise in x. While TTSHS have been considerably

used in context of network control systems [38], we illustrate
the above methods on an example drawn from cell biology.

II. TTSHS MODEL FORMULATION

of TTSHS, where events only impart noise to the system, in
the sense that the average value of x just after the event is
the same as its value just before the event.

The timing of events in TTSHS can be modeled through a
timer τ , that measures the time elapsed since the last event.
This timer is reset to zero whenever an event occurs and
increases over time as ˙τ = 1 in between events. Let the
time intervals between events follow a continuous positively-
valued probability density function f. Then, the transition
intensity for the event is given by the hazard function

h(τ ) :=

,

(4)

1 −(cid:82) τ

f (τ )
y=0 f (y)dy

[39], [40]. In particular, the probability that an event occurs
in the next inﬁnitesimal time interval (t, t + dt] is h(τ )dt.
This formulation of the event arrival process via a timer
allows representation of TTSHS as a state-driven SHS (Fig.
1). Hence, existing tools such as, Kolmogorov equations
and Dynkin’s formulas for obtaining time evolution of mo-
ments can be employed for studying stochastic dynamics of
TTSHS. Having deﬁned the timing of events, we next focus
on how the events alter the state of the system.

Fig. 1. Schematic of a linear time-triggered stochastic hybrid system.
The state evolves according to a linear dynamical system and events (green
arrow) occur randomly with hazard rate h(τ ), where the timer τ measures
the time since the last event. Choosing the hazard rate as (4), ensures that
the time between events follows a continuous probability density function
f. Whenever the event occurs the timer is set to zero and x changes via (5)

.

Whenever an event occurs, x is reset to x+, where x+ is

a random variable with following statistics
(cid:104)x+(ts)(cid:105) = Jx(ts) + R,

+(ts)(cid:11) − (cid:104)x+(ts)(cid:105)(cid:104)x+(ts)(cid:105)T =

(cid:10)x+(ts)xT

(5a)

Qx(ts)xT (ts) + Dx(ts)1n + E,

(5b)
where the symbol (cid:104) (cid:105) denotes the expected value. Here J ∈
Rn×n, R ∈ Rn×1, Q ∈ Rn×n, D ∈ Rn×n, and E ∈ Rn×n
are constant matrices, 1n is a 1 × n unit matrix. Note that
the mean of x+ is a linear afﬁne function x, which is a
generalization over the linear map (3) previously used. The
covariation matrix of x+ is deﬁned by (5b) and covers a wide
range of possibilities. For example, Q = D = E = 0 imply
x+ = Jx + R with probability one. Moreover, non-zero
Q, D and E can be used to incorporate constant or state-
dependent noise in x+. In the following sections, we show
how statistical moments of x(t) can be computed exactly
for TTSHS illustrate in Fig 1. We ﬁrst consider a subclass

(Lϕ)(x, τ ) ≡

h(τ ) × ∆ϕ(x, τ )

(cid:42) (cid:88)
(cid:28) ∂ϕ(x, τ )

Events

+

(cid:43)

(cid:29)

(cid:28) ∂ϕ(x, τ )

(cid:29)

III. MOMENT DYNAMICS OF TTSHS WITH

NOISE-IMPARTING EVENTS

Consider a subclass of the TTSHS with J = I, R = Q =

0 reducing (5) to

(cid:10)x+xT

(cid:104)x+(ts)(cid:105) = x(ts),

+(ts) − (cid:104)x+(ts)(cid:105)(cid:104)x+(ts)(cid:105)T(cid:11) =

(6a)
(6b)

Dx(ts)1n + E.

In essence, this reset corresponds to addition of a zero-mean
noise term, whenever the event occurs. This noise term can
be potentially state-dependent through D in (6b).

The time derivative of the expected value of a vector of

continuously differentiable functions
ϕ(x, τ ) = [ϕ1(x, τ ), ϕ2(x, τ ), . . . , ϕn(x, τ )]T ∈ Rn (7)
can be derived using

d(cid:104)ϕ(x, τ )(cid:105)

dt

=(cid:104)(Lϕ)(x, τ )(cid:105) ,

(8)

where L is an operator (also called the extended generator
of the SHS) which maps ϕ to (Lϕ)(x, τ ) according to

+

∂x

(Ax + ˆa)

,
(9)
[41]. Here, ∆ϕ is the change in vector ϕ whenever an event
∂x ∈ Rn×n is deﬁned as
occurs and elements of matrix ∂ϕ(x,τ )
∂ϕi(x, τ )

(cid:18) ∂ϕ(x, τ )

(cid:19)

∂τ

(10)

=

.

∂x

ij

∂xj

Setting ϕ(x, τ ) to be x in (9) and using (6a), the time
evolution of the ﬁrst-order moments is obtained as

d(cid:104)x(cid:105)
dt

=ˆa + A(cid:104)x(cid:105) + (cid:104)h(τ ) ((cid:104)x+(cid:105) − x)(cid:105) = ˆa + A(cid:104)x(cid:105).

(11)
For deriving the second-order moments we need the
following theorem.

Theorem 1: Consider the TTSHS illustrated in Fig. 1 with
noise-imparting events, i.e, reset deﬁned by (6). Then for
deterministic initial conditions

(cid:104)x|τ(cid:105) = (cid:104)x(cid:105)

∀t > 0.
A direct result of this theorem is that

(cid:104)h(τ )x(cid:105) = (cid:104)h(τ )(cid:105)(cid:104)x(cid:105).

(12)
(cid:4)

(13)

xˆxAa1τ0τxx)(τh(14)

(15)

Using (9) and the above result, the time evolution of the
second order moments is obtained as
d(cid:104)xxT(cid:105)

=A(cid:104)xxT(cid:105) + (cid:104)xxT(cid:105)AT + ˆa(cid:104)xT(cid:105) + (cid:104)x(cid:105)ˆaT

dt

+ (cid:104)h(τ )(xxT + Dx(ts)1n + E − xxT )(cid:105)

=A(cid:104)xxT(cid:105) + (cid:104)xxT(cid:105)AT + ˆa(cid:104)xT(cid:105) + (cid:104)x(cid:105)ˆaT

+ D(cid:104)h(τ )(cid:105)(cid:104)x(cid:105)1n + E(cid:104)h(τ )(cid:105).

At steady-state

A(cid:104)xxT(cid:105) + (cid:104)xxT(cid:105)AT + ˆa(cid:104)xT(cid:105) + (cid:104)x(cid:105)ˆaT =
− D(cid:104)h(τ )(cid:105) (cid:104)x(cid:105)1n − (cid:104)h(τ )(cid:105)E,

where (cid:104) (cid:105) denotes expected value as t → ∞. Let the random
variable T ≡ ts − ts−1 denote the time interval between
events for the TTSHS illustrated in Fig. 1. Then, the mean
interval is given by

(cid:104)T(cid:105) =

1

(cid:104)h(τ )(cid:105)

(16)

[42]. Using (16) and (cid:104)x(cid:105) = −A−1ˆa from (11), the above
equation reduces to

AC + CAT = − 1

(cid:104)T(cid:105) D(cid:104)x(cid:105)1n − 1

(cid:104)T(cid:105) E,

where the steady-state covariance matrix
C = (cid:104)xxT(cid:105) − (cid:104)x(cid:105)(cid:104)xT(cid:105)

(17)

(18)

is a unique solution to the Lyapunov equation (17). Inter-
estingly, C only depend on (cid:104)T(cid:105) and independent of higher-
order statistics of T. Thus, making timing of events more
random for a ﬁxed (cid:104)T(cid:105) will not affect noise levels in x. It is
important to point out that this result only holds for steady-
state, and the transient covariance matrix will depend on the
entire distribution of T. Next, we illustrate these result on
an example drawn from systems biology.

IV. SYSTEMS BIOLOGY EXAMPLE

In the previous section, we presented results on moment
dynamics of TTSHS with noise-imparting events. Here we
consider an example of such a system drawn from cellular
biology. Advances in experimental technologies have shown
that synthesis of protein molecules from its corresponding
gene is an inherently random process [43], [44]. Such
stochasticity results in random ﬂuctuations in the level of
a protein inside an individual cell, and critically impacts
functioning of intracellular biological pathways [45]–[51].
Below we present and analyze a TTSHS model that captures
different sources of noise in protein levels.
Let x(t) ∈ R denote the concentration of a given protein
inside a single cell at time t. We model the time evolution of
x using a TTSHS that incorporates three noise mechanisms:
1) Stochastic production of protein molecules in bursts of
gene activity, as has been experimentally seen [52]–
[54].

2) Timer controlled cell-division events occur at random
times. Whenever, cell division occurs, both the cell

volume and the number of protein molecules reduce
by half (assuming symmetric division). Thus, in the
sense of average concentrations, there is no change

(cid:104)x+(ts)(cid:105) = x(ts),

(19)

3) During cell division, protein molecules are partitioned
between two daughters cells based on a binomial dis-
tribution, i.e., each molecule has an equal probability
of being in one of the two cells [55], [56]. This
binomial partitioning process introduces noise in the
concentration that can be represented by

(cid:10)x2
+(ts) − (cid:104)x+(ts)(cid:105)2(cid:11) = βx(ts).

(20)

for some positive constant β. The linear dependence
in (20) comes from the fact that the variance of a
binomially distributed random variable is proportion
to its mean.

Before considering the stochastic case, we ﬁrst consider
deterministic protein production, where the concentration
evolves as

˙x(t) = kx(cid:104)B(cid:105) − γxx(t).

(21)
Here kx and (cid:104)B(cid:105) denote the frequency and size of protein
bursts, resulting in a net production rate of kx(cid:104)B(cid:105) in the
deterministic model. The concentration is diluted at a rate
γx, which is the rate of exponential growth in cell volume.
Cell-division events are assumed to occur randomly at times
ts, where T ≡ ts − ts−1 follows an arbitrary positively-
valued distribution. The mean cell-division time is intimately
connected to the growth rate via

(cid:104)T(cid:105) =

ln(2)
2γx

(22)

[57]. The TTSHS deﬁned by (19)-(21) is of the form
discussed in the Section III, and time evolution of moments
is obtained as

d(cid:104)x(cid:105)
dt
d(cid:104)x2(cid:105)
dt

= kx(cid:104)B(cid:105) − γx(cid:104)x(cid:105),
= 2kx(cid:104)B(cid:105)(cid:104)x(cid:105) − 2γx(cid:104)x2(cid:105) + β(cid:104)h(τ )(cid:105)(cid:104)x(cid:105).

(23a)

(23b)

Steady-state analysis yields the following mean and noise (as
quantiﬁed by the coefﬁcient of variation squared)

(cid:104)x(cid:105) =

kx(cid:104)B(cid:105)
γx

,

CV 2

x =

(cid:104)x2(cid:105) − (cid:104)x(cid:105)2

(cid:104)x(cid:105)2

=

ln(2)β
2(cid:104)x(cid:105) ,

(24)

respectively. As predicted by theory, the noise in the protein
level only depends on (cid:104)T(cid:105), which enters the equation via
γx (see (22)). Thus remarkably, making the timing of cell
division more random (for a ﬁxed mean) will not result in
higher stochasticity in the protein concentration.

Next, we consider stochastic production of proteins, which
involves adding a second family of resets in the above
TTSHS model. As pointed earlier, production of proteins is
assumed to occur in random bursts that happen at random
times. In particular, burst events are assumed to occur at

Fig. 2. Modeling stochasticity in the level of protein using TTSHS. Left: Time evolution of the protein level x ∈ R in a single cell is modeled via a
SHS with two stochastic resets representing production of proteins in bursts and cell-division events. The latter is controlled by a timer τ , and whenever it
occurs the state is reset via (19)-(20). In between events, protein concentrations decay exponentially with rate γx due to cellular growth. Right: A sample
trajectory of x is shown with cell division events (dashed lines). The steady-state distribution of x obtained via a large number Monte Carlo simulations
is shown on the right.

exponentially distributed times with rate kx. Whenever the
event occurs the concentration changes as
x(ts) (cid:55)→ x(ts) + B,

(25)

where B is a random variable denoting the size of protein
bursts and follows an arbitrary positively-valued distribution.
The overall model with both stochastic production and cell
division events is shown in Fig. 2. In between events, the
concentration is diluted as

˙x(t) = −γxx(t).

(26)

The time evolution of moments for this new SHS is given
by the corresponding extended generator and given by
d(cid:104)x(cid:105)
dt
d(cid:104)x2(cid:105)
dt

= kx(cid:104)B(cid:105) − γx(cid:104)x(cid:105),
(27a)
= kx(cid:104)B2(cid:105) + 2kx(cid:104)B(cid:105)(cid:104)x(cid:105) − 2γx(cid:104)x2(cid:105) + β(cid:104)h(τ )(cid:105)(cid:104)x(cid:105)
(27b)
Steady-state analysis of the above moment equations yields

(cid:104)x(cid:105) =

kx(cid:104)B(cid:105)
γx

,

CV 2

x =

ln(2)β
2(cid:104)x(cid:105) +

1
2

(cid:104)B2(cid:105)
(cid:104)B(cid:105)(cid:104)x(cid:105) ,

(28)

providing the ﬁrst results connecting the protein noise level
to randomness in the underlying bursty synthesis and cell
division events. As before, the noise only depends on (cid:104)T(cid:105)
and independent of its higher-order statistics.

V. MOMENT DYNAMICS OF TTSHS

In the previous sections, we have considered a sub-class
of TTSHS with resets given by (6) (i.e., noise-imparting
events). Here, we return to the original TTSHS described
by (1) & (5), and show how time evolution of moments can
be computed for these systems.

In general, moment equations cannot be solved exactly for
any arbitrary function h(τ ) in Fig. 1. Our strategy for exact
moment computations relies on two steps: i) Modeling the
timing of stochastic events through a phase-type distribution,
which can be represented by embedding a continuous-time

Markov chain (Fig. 3) and ii) Showing that the time evolution
of moments in the resulting system becomes automatically
closed at some high-order moment. Here we focus on phase-
type distributions that consists of a mixture of Erlang distri-
butions [37], and use them as a practical tool for modeling
the timing of stochastic events in TTSHS.

Embedded Markov chain for event timing: Recall that
an Erlang distribution of order i is the distribution of the sum
of i independent and identical exponential random variables.
The interval T ≡ ts − ts−1 is assumed to have an Erlang
distribution of order mi with probability pi, i = {1, . . . , n}
and can be represented by a continuous-time Markov chain
with states Sij, j = {1, . . . , mi},
i = {1, . . . , n} (Fig.
3). Let Bernoulli random variables sij = 1 if the system
resides in state Sij and 0 otherwise. The probability of
transition Sij → Si(j+1)
time
interval (t, t + dt] is given by kisijdt, implying that the
time spent
in each state Sij is exponentially distributed
with mean 1/ki. To summarize, just after an event occurs
a state Si1, i = {1, . . . , n} is chosen with probability pi
and the next event occurs after transitioning through mi
exponentially distributed steps. Based on this formulation,
the probability of the stochastic event occurring in the time
j=1 kjsjjdt, and whenever
interval (t, t+dt] is given by pi
the event occurs, the state is reset as per (5). For a mixture
of Erlang distributions, the moment are given by
, q ∈ {1, 2, . . .}

inﬁnitesimal

in the next

(cid:80)n

(cid:104)Tq(cid:105) =

(mi + q − 1)!
(mi − 1)!

pi
kq
i

n(cid:88)

i=1

(29)

[58]. Given a speciﬁc distribution of timing of events,
the above equation can in principle be used to construct a
complex enough appropriate Marko chain that matches some
lower orders moments of the given distribution.

The overall model is now given by the linear system

˙x(t) = ˆa + Ax.

(30)

together with stochastic transitions associated with the
embedded Markov chain illustrated in Table I. The theorem

Time (minutes) Probability Protein concentration Cell cycle 250 300 350 0 20 40 60 0.05 0.1 80 xxx1τ0τxx)(τhCell division BxxProtein production xk200 STOCHASTIC EVENTS IN THE TTSHS WITH TIMING OF EVENTS DESCRIBED BY THE EMBEDDED MARKOV CHAIN IN FIG. 3.

TABLE I

Stochastic events

Phase-type evolution

sij (t) (cid:55)→ sij (t) − 1,

Reset
si(j+1)(t) (cid:55)→ si(j+1)(t) + 1

Events changing x

x(ts) (cid:55)→ x+(ts),

sjmj (ts) (cid:55)→ 0,

si1(ts) (cid:55)→ si1(ts) + 1

pi

kisij,

(cid:80)n

Transitions intensity

j ∈ {1, . . . , mi − 1}

j=1 kj sjmj ,

i&j ∈ {1, . . . , n}

kj

n(cid:88)

= ˆa + Ax +

(cid:0)(J − I)(cid:104)xsjmj(cid:105) + R(cid:104)sjmj(cid:105)(cid:1) ,
(cid:43)

dynamics of the means can be written as
d(cid:104)x(cid:105)
dt
d(cid:104)si1(cid:105)
dt
d(cid:104)sij(cid:105)
dt

= ki(cid:104)si(j−1)(cid:105) − ki(cid:104)sij(cid:105),

i = {1, . . . , n},

(cid:42) n(cid:88)

− ki(cid:104)si1(cid:105),

kjsjmj

= pi

j=1

j=1

i = {1, . . . , n},

j = {2, . . . , mi}.

(34a)

(34b)

(34c)

Note the the ﬁrst equation is not closed since it depends
on the second order moments of the form (cid:104)xsij(cid:105). The time
evolution of the moments (cid:104)xsij(cid:105) depends on third order
moments of the form (cid:104)xs2
ij(cid:105) and (cid:104)sijsrqxb(cid:105). However, using
the fact that sij are Bernoulli random variables

(cid:104)sq
ij(cid:105) = (cid:104)sij(cid:105),

(cid:104)sq
ijxb(cid:105) = (cid:104)sijxb(cid:105), q & b ∈ {1, 2, . . .}.
(35)
Moreover, since only one of the states sij can be 1 at a time

(cid:104)sijsrqxb(cid:105) = 0, if i (cid:54)= r or j (cid:54)= q.

(36)
Exploiting (35)-(36), moment dynamics of (cid:104)xsij(cid:105) becomes
automatically closed and given by
d(cid:104)xsi1(cid:105)

= ˆa(cid:104)xsi1(cid:105) + A(cid:104)xsi1(cid:105) − ki(cid:104)xsi1(cid:105)

(cid:0)(J − I)(cid:10)xsjmj

(cid:11) + R(cid:104)sjmj(cid:105)(cid:1) , i = {1, . . . , n},

(37a)

n(cid:88)

kj

dt

dt

= ˆa(cid:104)xsij(cid:105) + A(cid:104)xsij(cid:105) − ki(cid:104)xsij(cid:105)
i = {1, . . . , n},
+ ki(cid:104)xsi(j−1)(cid:105),

(37b)
j = {2, . . . , mi}.
Thus (34) and (37) represent a closed set of equations
that can be used to obtain the mean dynamics (cid:104)x(cid:105). A
similar approach can be taken for obtaining the second
the time evolution of (cid:104)xxT(cid:105)
order moments. Brieﬂy,
would depend on moments of the form (cid:104)xxT sij(cid:105). Moment
dynamics of (cid:104)xxT sij(cid:105) can be closed automatically using
(cid:4)
(35)-(36).

Given space limitations, we do not present any example
illustrating the results of Theorem 2. In summary, our results
show that if timing events in TTSHS of can be modeled via
a phase-type process (as in Fig. 3), then time evolution of
moments can be obtained by solving a linear systems of
differential equations.

+ pi
d(cid:104)xsij(cid:105)

j=1

Fig. 3. A continuous-time Markov chain model for timing of events
in TTSHS. The time interval T ≡ ts − ts−1 between two successive
stochastic events is assumed to follow a mixture of Erlang distributions.
After an event occurs, a state Si1, i = {1, . . . , n} is chosen with probability
pi. The systems transitions through states Sij , j = {1, . . . , mi} residing
for an exponentially distributed time in each state. The next event occurs
after exit from Simi and the above process is repeated.

below outlines the main result.

Theorem 2: Consider the TTSHS where timing of events are
modeled through the Markov chain in Fig. 3, and reset are
given by (5). Then, there exists a vector µ of all ﬁrst and
second order moments of stochastic processes x and sij, and
selected third order moments, such that its time evolution is
given by a linear dynamical system

˙µ = a1 + A1µ,

for an appropriate vector a1 and matrix A1.

(31)
(cid:4)

Proof of Theorem 2: Time derivative of the expected
value of any vector of continuously differentiable functions
ϕ(x, sij) is given by

d(cid:104)ϕ(x, sij)(cid:105)

= (cid:104)(Lϕ)(x, sij)(cid:105) ,

(32)

where the extended generator (Lϕ) for this SHS is

(Lϕ)(x, sij) =

∆ϕ(x, sij) × ψ(x, sij)

dt

(cid:42) (cid:88)
(cid:28) ∂ϕ(x, sij)

Events

+

∂x

(cid:29)

(ˆa + Ax)

.

(cid:43)

(33)

Here ψ(x, sij) denotes the transition intensities for the events
and determine how often these events occur [41].

Using the transition intensities shown in Table I,

the

New event New event 2pnp1pnkPrevious event nnmS2nS1nSnknknk2k22mS22S21S2k2k2k1k11mS12S11S1k1k1kNew event VI. CONCLUSION

Here we studied stochastic dynamics for a class of
piecewise-deterministic Markov processes, known as TTSHS
(Fig. 1). In essence, TTSHS are linear dynamical systems,
whose state is initialized by random initial conditions at
random times. The main contribution of this study is to show
how moments can be obtained exactly by solving a closed
system of differential equations. Our study also identiﬁes a
subclass of TTSHS given by (6), where moments of x depend
only on the mean time interval between events. This result
leads to an intriguing ﬁnding in the context of cell biology:
the magnitude of noise in the concentration of a protein is
invariant of the noise in cell-division times. We are currently
working closely with experimental collaborators to test this
prediction in living cells.

It is important to point out that the results presented here
can be easily generalized to consider the following scenarios:
1) The state evolves according to a linear stochastic

differential equation between events.

2) Multiple family of resets, where some resets are timer-
dependent, while other are state-dependent. In the latter
case, the probability of event occurrence is a linear
afﬁne function of x.

The second point is exempliﬁed from the example shown in
Fig. 2 with two families of stochastic resets, albeit the timing
of one of the resets was memoryless.

Our study also presents exciting avenues for future re-
search. One direction of research would be to ﬁnd time
evolution of moments for TTSHS with multiple discrete
modes, allowing for switching between linear dynamical
systems (Fig. 4). The current formulation of TTSHS con-
siders time intervals between events to be independent. It
will be interesting to add some form of correlation be-
tween successive events. This is particularly important for
cell division, where the cell-cycle lengths of mother and
daughter cells are generally correlated. Finally, recent work
has identiﬁed classes of nonlinear stochastic systems, where
moment dynamics becomes automatically closed at some
higher-order moment [59]. In light of this study, one can
explore nonlinearities in TTSHS such that moments can be
computed without requiring closure schemes.

ACKNOWLEDGMENT

AS is supported by the National Science Foundation Grant

DMS-1312926.

REFERENCES

[1] J. P. Hespanha, “Stochastic hybrid systems: Applications to commu-
nication networks,” in Hybrid Systems: Computation and Control,
R. Alur and G. J. Pappas, Eds. Springer-Verlag, 2004, pp. 387–401.
[2] S. Bohacek, J. P. Hespanha, J. Lee, and K. Obraczka, “A hybrid
systems modeling framework for fast and accurate simulation of
data communication networks,” in Proc. of the ACM Int. Conf. on
Measurements and Modeling of Computer Systems (SIGMETRICS),
vol. 31, 2003, pp. 58–69.

[3] J. Hu, “Application of stochastic hybrid systems in power management
of streaming data,” in Proc. of the 2006 Amer. Control Conference,
Minneapolis, MN.

Schematic of a TTSHS with multiple discrete modes.
Fig. 4.
In each discrete model, the state evolves according a linear dynamical
system. Transition between discrete states occur based on hazard functions
hi(τ ), i = {1, 2, . . .}, and whenever the transition occurs, the state is reset
based on maps similar to (5).

[4] D. Antunes, J. P. Hespanha, and C. Silvestre, “Stochastic hybrid
systems with renewal transitions: Moment analysis with application
to networked control systems with delays,” SIAM Journal on Control
and Optimization, vol. 51, pp. 1481–1499, 2013.

[5] J. P. Hespanha, “Modeling and analysis of networked control systems
using stochastic hybrid systems,” Annual Reviews in Control, vol. 38,
pp. 155–170, 2014.

[6] A. Visintini, W. Glover, J. Lygeros, and J. Maciejowski, “Monte
carlo optimization for conﬂict resolution in air trafﬁc control,” IEEE
Transactions on Intelligent Transportation Systems, vol. 7, pp. 470–
482, 2006.

[7] M. Prandini and J. Hu, “Application of reachability analysis for
stochastic hybrid systems to aircraft conﬂict prediction,” Automatic
Control, IEEE Transactions on, vol. 54, pp. 913–917, 2009.

[8] B. Daigle, M. Soltani, L. Petzold, and A. Singh, “Inferring single-cell
gene expression mechanisms using stochastic simulation,” Bioinfor-
matics, vol. 31, pp. 1428–1435, 2015.

[9] D. Antunes and A. Singh, “Quantifying gene expression variability
arising from randomness in cell division times,” Journal of Mathe-
matical Biology, vol. 71, pp. 437–463, 2014.

[10] A. Singh and J. P. Hespanha, “Stochastic hybrid systems for study-
ing biochemical processes,” Philosophical Transactions of the Royal
Society A, vol. 368, pp. 4995–5011, 2010.

[11] J. Lygeros, K. Johansson, S. Simic, J. Zhang, and S. Sastry, “Dynam-
ical properties of hybrid automata,” IEEE Transactions on Automatic
Control, vol. 48, pp. 2–17, 2003.

[12] L. Bortolussi and A. Policriti, “Hybrid Systems and Biology,” in

Formal Methods for Computational Systems Biology. Springer.

[13] H. El-Samad, M. Fazel, X. Liu, A. Papachristodoulou, and S. Prajna,
“Stochastic reachability analysis in complex biological networks,” in
acc06, 2006, pp. 4748–4753.

[14] J. Hu, J. Lygeros, and S. Sastry, “Modeling subtilin production in
bacillus subtilis using stochastic hybrid systems,” in Hybrid Systems:
Computation and Control. Springer, 2004, pp. 417–431.

[15] D. Riley, X. Koutsoukos, and K. Riley, “Modelling and analysis of the
sugar cataract development process using stochastic hybrid systems,”
IET systems biology, vol. 3, pp. 137–154, 2009.

[16] S. Dhople, Y. Chen, L. DeVille, and A. Dominguez-Garcia, “Analysis
of power system dynamics subject to stochastic power injections,”
IEEE Transactions on Circuits and Systems I, vol. 60, pp. 3341–3353,
2013.

[17] K. Wang and M. Crow, “Numerical simulation of stochastic differential
algebraic equations for power system transient stability with random
loads,” in Power and Energy Society General Meeting, 2011, pp. 1–8.
[18] M. Strelec, K. Macek, and A. Abate, “Modeling and simulation

xˆx11Aa1xx3xx2xx)(τ1h1τxˆx22Aa1τxˆx33Aa1τ)(τ2h)(τ3h0τ0τ0τ[43] A. Bar-Even, J. Paulsson, N. Maheshri, M. Carmi, E. O’Shea, Y. Pilpel,
and N. Barkai, “Noise in protein expression scales with natural protein
abundance,” Nature Genetics, vol. 38, pp. 636–643, 2006.

[44] J. M. Raser and E. K. O’Shea, “Noise in gene expression: Origins,
consequences, and control,” Science, vol. 309, pp. 2010 – 2013, 2005.
[45] R. Losick and C. Desplan, “Stochasticity and cell fate,” Science, vol.

320, pp. 65–68, 2008.

[46] J.-W. Veening, W. K. Smits, and O. P. Kuipers, “Bistability, epige-
netics, and bet-hedging in bacteria,” Annual Review of Microbiology,
vol. 62, pp. 193–210, 2008.

[47] L. S. Weinberger, R. D. Dar, and M. L. Simpson, “Transient-mediated
fate determination in a transcriptional circuit of HIV,” Nature Genetics,
vol. 40, pp. 466 – 470, 2008.

[48] A. Singh and L. S. Weinberger, “Stochastic gene expression as a
molecular switch for viral latency,” Current Opinion in Microbiology,
vol. 12, pp. 460–466, 2009.

[49] A. Singh and J. J. Dennehy, “Stochastic holin expression can account
for lysis time variation in the bacteriophage λ,” Journal of the Royal
Society Interface, vol. 11, p. 20140140, 2014.

[50] P. Bokes and A. Singh, “Protein copy number distributions for a self-
regulating gene in the presence of decoy binding sites,” PLOS ONE,
vol. 10, p. e0120555, 2015.

[51] M. Soltani, P. Bokes, Z. Fox, and A. Singh, “Nonspeciﬁc transcription
factor binding can reduce noise in the expression of downstream
proteins,” Physical Biology, vol. 12, p. 055002, 2015.

[52] A. Raj, C. Peskin, D. Tranchina, D. Vargas, and S. Tyagi, “Stochastic
mRNA synthesis in mammalian cells,” PLOS Biology, vol. 4, p. e309,
2006.

[53] A. Singh, B. Razooky, C. D. Cox, M. L. Simpson, and L. S.
Weinberger, “Transcriptional bursting from the HIV-1 promoter is
a signiﬁcant source of stochastic noise in HIV-1 gene expression,”
Biophysical Journal, vol. 98, pp. L32–L34, 2010.

[54] D. M. Suter, N. Molina, D. Gatﬁeld, K. Schneider, U. Schibler, and
F. Naef, “Mammalian genes are transcribed with widely different
bursting kinetics,” Science, vol. 332, pp. 472–474, 2011.

[55] I. Golding, J. Paulsson, S. Zawilski, and E. Cox, “Real-time kinetics
of gene activity in individual bacteria,” Cell, vol. 123, pp. 1025–1036,
2005.

[56] M. Soltani, C. Vargas, D. Antunes, and A. Singh, “Decomposing
variability in protein levels from noisy expression, genome duplication
and partitioning errors during cell-divisions,” Submitted to PLOS
Computational Biology, 2015. [Online]. Available: arXiv:1509.04559
[57] U. Alon, An Introduction to Systems Biology: Design Principles of

Biological Circuits. Chapman and Hall/CRC, 2011.

[58] P. Buchholz, J. Kriege, and I. Felko, Input Modeling with Phase-Type
Distributions and Markov Models, ser. SpringerBriefs in Mathematics.
Springer, 2014.

[59] E. Sontag and A. Singh, “Exact moment dynamics for feedforward
nonlinear chemical reaction networks,” IEEE Life Sciences Letters,
vol. 1, pp. 26–29, 2015.

of a microgrid as a stochastic hybrid system,” in 3rd IEEE PES
International Conference and Exhibition on Innovative Smart Grid
Technologies (ISGT Europe), 2012, pp. 1–9.

[19] A. David, D. Du, K. Larsen, M. Mikuionis, and A. Skou, “An
evaluation framework for energy aware buildings using statistical
model checking,” Science China Information Sciences, vol. 55, pp.
2694–2707, 2012.

[20] J. Hespanha, “Modelling and analysis of stochastic hybrid systems,”
IEE Proceedings Control Theory and Applications, vol. 153, pp. 520–
535, 2006.

[21] A. R. Teel, A. Subbaraman, and A. Sferlazza, “Stability analysis for
stochastic hybrid systems: A survey,” Automatica, vol. 50, no. 10, pp.
2435–2456, 2014.

[22] J. Hu, J. Lygeros, and S. Sastry, “Towards a theory of stochastic hybrid
systems,” in Hybrid Systems: Computation and Control, ser. Lecture
Notes in Computer Science. Springer, 2000, pp. 160–173.

[23] J. P. Hespanha, “A model for stochastic hybrid systems with ap-
plication to communication networks,” Nonlinear Analysis: Theory,
Methods & Applications, vol. 62, pp. 1353–1383, 2005.

[24] A. Julius and G. Pappas, “Approximations of stochastic hybrid sys-
tems,” IEEE Transactions on Automatic Control, vol. 54, pp. 1193–
1203, 2009.

[25] A. Singh and J. P. Hespanha, “Models for multi-specie chemical reac-
tions using polynomial stochastic hybrid systems,” in IEEE Conference
on Decision and Control, 2005.

[26] C. H. Lee, K. Kim, and P. Kim, “A moment closure method for
stochastic reaction networks,” Journal of Chemical Physics, vol. 130,
p. 134107, 2009.

[27] A. Singh and J. P. Hespanha, “Approximate moment dynamics for
chemically reacting systems,” IEEE Transactions on Automatic Con-
trol, vol. 56, pp. 414–418, 2011.

[28] C. S. Gillespie, “Moment closure approximations for mass-action

models,” IET Systems Biology, vol. 3, pp. 52–58, 2009.

[29] M. Soltani, C. Vargas, and A. Singh, “Conditional moment closure
schemes for studying stochastic dynamics of genetic circuits,” IEEE
Transactions on Biomedical Systems and Circuits, vol. 9, pp. 518–526,
2015.

[30] J. Zhang, L. DeVille, S. Dhople, and A. Dominguez-Garcia, “A max-
imum entropy approach to the moment closure problem for stochastic
hybrid systems at equilibrium,” in IEEE Conference on Decision and
Control, 2014, pp. 747–752.

[31] A. Singh and J. P. Hespanha, “Stochastic analysis of gene regulatory
networks using moment closure,” in Proc. of the 2007 Amer. Control
Conference, New York, NY, 2006.

[32] M. H. A. Davis, Markov models and Optimization. Chapman and

Hall, 1993.

[33] O. L. V. Costa and F. Dufour, “Stability and ergodicity of piecewise
deterministic markov processes,” SIAM Journal on Control and Opti-
mization, vol. 47, pp. 1053–1077, 2008.

[34] D. Antunes, J. Hespanha, and C. Silvestre, “Impulsive systems trig-
gered by superposed renewal processes,” in IEEE Conference on
Decision and Control, 2010, pp. 1779–1784.

[35] ——, “Volterra integral approach to impulsive renewal systems:
Application to networked control,” IEEE Transactions on Automatic
Control, vol. 57, pp. 607–619, 2012.

[36] ——, “Stability of networked control systems with asynchronous
renewal links: An impulsive systems approach,” Automatica, vol. 49,
pp. 402–413, 2013.

[37] H. C. Tijms, Stochastic models: an algorithmic approach. John Wiley

& Sons, 1994.

[38] J. P. Hespanha, “Modeling and analysis of networked control systems
using stochastic hybrid systems,” Annual Reviews in Control, vol. 38,
pp. 155–170, 2014.

[39] S. M. Ross, “Reliability theory,” in Introduction to Probability Models,

10th ed. Academic Press, 2010, pp. 579 – 629.

[40] M. Evans, N. Hastings, and B. Peacock, Statistical Distributions,

3rd ed. Wiley, 2000.

[41] J. P. Hespanha and A. Singh, “Stochastic models for chemically react-
ing systems using polynomial stochastic hybrid systems,” International
Journal of Robust and Nonlinear Control, vol. 15, pp. 669–689, 2005.
[42] M. Finkelstein, “Failure Rate and Mean Remaining Lifetime,” in
Failure Rate Modelling for Reliability and Risk, ser. Springer Series
in Reliability Engineering. Springer, 2008, pp. 9–44.

