Towards Seamless Tracking-Free Web: Improved

Detection of Trackers via One-class Learning

Muhammad Ikram†1, Hassan Jameel Asghar†,

Mohamed Ali Kaafar†, Anirban Mahanti†

1 School of EET UNSW, Australia

† NICTA, Australia

Balachander Krishnamurthy
AT&T Labs–Research, USA

6
1
0
2

 
r
a

 

M
0
2

 
 
]

R
C
.
s
c
[
 
 

1
v
9
8
2
6
0

.

3
0
6
1
:
v
i
X
r
a

Abstract—Numerous tools have been developed to aggressively
block the execution of popular JavaScript programs in Web
browsers. Such blocking also affects functionality of webpages
and impairs user experience. As a consequence, many privacy
preserving tools that have been developed to limit online tracking,
often executed via JavaScript programs, may suffer from poor
performance and limited uptake. A mechanism that can isolate
JavaScript programs necessary for proper functioning of the
website from tracking JavaScript programs would thus be useful.
Through the use of a manually labelled dataset composed of 2,612
JavaScript programs, we show how current privacy preserving
tools are ineffective in ﬁnding the right balance between blocking
tracking JavaScript programs and allowing functional JavaScript
code. To the best of our knowledge, this is the ﬁrst study to assess
the performance of current web privacy preserving tools.

To improve this balance, we examine the two classes of
JavaScript programs and hypothesize that tracking JavaScript
programs share structural similarities that can be used to
differentiate them from functional JavaScript programs. The
rationale of our approach is that web developers often “borrow”
and customize existing pieces of code in order to embed tracking
(resp. functional) JavaScript programs into their webpages. We
then propose one-class machine learning classiﬁers using syntactic
and semantic features extracted from JavaScript programs. When
trained only on samples of tracking JavaScript programs, our
classiﬁers achieve an accuracy of 99%, where the best of the
privacy preserving tools achieved an accuracy of 78%. The
performance of our classiﬁers is comparable to that of traditional
two-class SVM. One-class classiﬁcation, where a training set of
only tracking JavaScript programs is used for learning, has the
advantage that it requires fewer labelled examples that can be
obtained via manual
inspection of public lists of well-known
trackers.

We further test our classiﬁers and several popular privacy
preserving tools on a larger corpus of 4,084 websites with 135,656
JavaScript programs. The output of our best classiﬁer on this
data is between 20 to 64% different from the tools under study.
We manually analyse a sample of the JavaScript programs for
which our classiﬁer is in disagreement with all other privacy
preserving tools, and show that our approach is not only able
to enhance user web experience by correctly classifying more
functional JavaScript programs, but also discovers previously
unknown tracking services.

I.

INTRODUCTION

Recently, several tools have been developed to aggressively
block the execution of popular JavaScript programs in the web
browser.

JavaScript programs are frequently used to track users

and tailor advertisements on websites to the browsing history
and web activities of users [1], [2], [3]. The class of tools
(including web browser plugins), developed in an attempt to
preserve user privacy (e.g., NoScript [4], Ghostery [5], and
Adblock Plus [6]), aims to block JavaScript programs and other
components of a webpage that may compromise user privacy
and enable tracking. However, aggressive blocking can hinder
proper functioning of the website and impact user’s browsing
experience [7], [8] (See Appendix E for an example of how
a tool blocks content necessary for proper website function.).
A mechanism that can properly isolate JavaScript programs
necessary for “legitimate” web functioning of the website from
others that are likely to be privacy-intrusive would therefore
be useful.

Web tracking in general happens through the use of numer-
ous technologies, e.g., cookies, supercookies, Flash cookies,
ETag cookies, HTTP referrers and JavaScript programs [9],
[10].1 Third-party tracking, where “unauthorised” third parties
retrieve information from the “ﬁrst party” websites visited
by users, enable a plethora of services including analytics,
advertisement and online social interactions. While third-party
tracking [12] may happen through various techniques, trackers
frequently use

JavaScript programs [1], [2], [3], [13] for tracking, and
as such, most
tracking can be avoided by controlling the
execution of JavaScript programs on webpages. We refer to
these JavaScript programs as tracking. Consequently, most
privacy preserving tools (PP-Tools in short) are either based
on pre-deﬁned (black)lists of URLs of third-party trackers for
which the execution of JavaScript code is blocked or simply
rely on blocking any third-party JavaScript program.

However, not all JavaScript programs are used for tracking
and many are essential for proper functioning of a website,
e.g., JavaScript programs that enable media players to show an
embedded video on a webpage. We refer to these JavaScript
programs as functional JavaScript programs. In this paper, we
show that the current generation of PP-Tools are unable to
achieve a balance between blocking tracking and functional
JavaScript programs, which we believe has contributed to their
poor uptake with a recent study showing about 3 to 20% uptake
among web users [14].

1Tracking can also be generalised to the use of multiple user identiﬁers for
host-tracking including IP addresses, login IDs, web browser user-agents, etc.
This is generally referred to as stateless tracking. Interested readers may refer
to [11] for further details.

This motivates our goal to develop a machine learning
classiﬁcation framework that is more effective in separating
tracking from functional JavaScript programs on a webpage.
We impose two important design constraints. One is to avoid
detection through regular expressions based on blacklists,
which is used by existing PP-Tools and, as measured later
in the paper, is ineffective. Another constraint is to enable
classiﬁcation using a small single class of JavaScript programs
that are known to be either exclusively functional or tracking.
Our motivation for this is that
in the real-world one can
expect to have knowledge of only a subset of tracking or
functional JavaScript programs, i.e., we cannot expect to have
an exhaustive list of either classes of programs. The key
rationale of our proposed approach is that web developers often
embed JavaScript code used by popular tracking libraries or
re-use pieces of known JavaScript code which they customise.
Likewise, code of several functional web components (includ-
ing search buttons, media players embedding, shopping carts,
content fetching, etc.) are generally borrowed from previously
published code. From that perspective, our technique resembles
approaches taken to detect code plagiarism and malware code
signatures.

In this paper, we develop machine learning approaches that
classify functional and tracking JavaScript programs based on
syntactic and semantic features extracted from a number of
JavaScript programs. We ﬁnd that traditional two-class support
vector machine (SVM) trained on labelled data from both
functional and tracking JavaScript programs can accurately
distinguish these JavaScript programs. More importantly, we
show that one-class machine learning classiﬁers, namely one-
class SVM and positive and unlabelled (PU) learning, trained
using only tracking JavaScript programs can achieve perfor-
mance comparable to two-class SVM. We believe the latter
approach is more practical as it requires fewer labelled samples
for training which can be obtained from well-known tracking
and advertising services, e.g., through blacklists of PP-Tools
(although manual effort would still be required to remove
wrong labels, since, as we show later, not all JavaScript pro-
grams from known trackers are tracking JavaScript programs).

In summary, we make the following contributions:
• We propose two machine learning approaches for
automatic classiﬁcation of tracking and functional
JavaScript programs that rely only on partial knowl-
edge of the former class. Instead of using static code
analysis or regular expression matching on blacklists,
we use an automated way to extract features from
JavaScript programs using syntactic and structural
models proposed in the literature to quantitatively
determine similarity between functional and track-
ing JavaScript programs. Our proposed approaches
achieve accuracy of up to 99%,2 well above the
accuracy achievable by existing PP-Tools (≤ 78%) as
validated through our manually labelled dataset.

• We evaluate the effectiveness of ﬁve major PP-Tools
by comparing their output against a set of 2,612
manually labelled JavaScript programs extracted from

2Accuracy is deﬁned as the sum of true positives and negatives normalized
by the population size (total number of JavaScript programs). In our study,
the tracking JavaScript programs constitute the positive class.

95 different domains. Among these ﬁve, Ghostery
achieves the best balance between true and false
positive rates, 0.65 to 0.08. Others who fare better
in terms of the false positive rate (≤ 0.06) pay the
penalty with a considerably lower true positive rate
of 0.44 or less. NoScript achieves the highest true
positive rate (0.78), at the expense of the poorest false
positive rate (0.21). Our results indicate that existing
PP-Tools need considerable improvement in ﬁnding
an optimal balance between true and false positives.
To the best of our knowledge, this is the ﬁrst study
that analyses and assesses the performance of current
privacy preserving tools.

• We run our classiﬁers on a larger dataset of 4,084
websites, representing 135,656 JavaScript programs
and compare their output against the above mentioned
PP-Tools to analyse their respective effectiveness in
the wild. Choosing our best classiﬁer as a benchmark,
we observe that NoScript, Ghostery and Adblock Plus
agree with the output of our classiﬁer between 75 to
80%, whereas Disconnect and Privacy Badger showed
an agreement of only 36% and 43%, respectively. Be-
tween 11% to 14% of the JavaScript programs labelled
as functional by our classiﬁer were contradictorily
classiﬁed as tracking by the ﬁrst three. The remaining
two PP-Tools had this number less than 7%.

•

From this larger dataset we randomly sample two sub-
sets of 100 JavaScript programs each, corresponding
to the two sets of JavaScript programs labelled as func-
tional and tracking by our classiﬁer in disagreement
with all ﬁve PP-Tools. Through manual inspection, we
found that our classiﬁer was correct in classifying 75
out of 100 JavaScript programs it labelled tracking,
and 81 out of 100 JavaScript programs it labelled
functional, meaning that the PP-Tools were only cor-
rect in labelling 25 and 19 JavaScript programs in the
two subsets, respectively. We discuss, with examples,
the main reasons for misclassiﬁcation by our classiﬁer
and PP-Tools. Notably, we further show how our
classiﬁer is capable of revealing previously unknown
tracking services simply by relying on JavaScript
code structure and semantic similarity from popular
tracking services.

The rest of this paper is organised as follows. In Section II,
we give a background on JavaScript based web tracking and
how the PP-Tools considered in our study attempt to mitigate
this. We discuss our main objectives, methodology and data
collection in Section III. In Section IV, we evaluate the
effectiveness of PP-Tools using our labelled data set. Details
on our choice of classiﬁers and their validation are described in
Section V. We evaluate the effectiveness of our classiﬁers and
PP-Tools in the wild in Section VI. In Section VII, we discuss
possible limitations and challenges as well as avenues for
improvement of our proposed scheme. We review the related
work in Section VIII and provide some concluding remarks in
Section IX.

2

II. BACKGROUND

A. Web Tracking and JavaScript programs

A typical webpage consists of several web-components,
e.g., JavaScript programs, Flash-content, images, CSS, etc.
When a user opens a website in a web browser, the fetched
webpage typically generates several other HTTP(S) connec-
tions for downloading additional components of the webpage.
These components can be downloaded from the website visited
by the user (referred to as ﬁrst-party domain) or downloaded
from other third-party domains. Here, we focus on one type
of web-component, namely JavaScript programs, which is
loaded both from ﬁrst- and third-party domains. JavaScript
programs are widely used by ad networks, content distribution
networks (CDNs), tracking services, analytics platforms, and
online social networks (e.g., Facebook uses them to implement
plugins).

Figure 1 illustrates a typical scenario of web tracking
via JavaScript programs. Upon fetching a webpage from
ﬁrst-party domains (steps 1 & 2), the user’s web browser
interprets the HTML tags and executes JavaScript programs
within the HTML script tags. JavaScript program execution
enables the web browser to send requests to retrieve additional
content from third-party domains (step 3). Depending on the
implemented functionalities, the JavaScript programs can be
considered as useful (functional), e.g., fetching content from
a CDN, or as tracking. In the latter case, when the webpage
is completely rendered (step 4), the JavaScript programs track
user’s activities on the webpage [15], write to or read from
the cookie database [7], [16] (steps 5 & 6), or reconstruct user
identiﬁers [3], [17]. Tracking JavaScript programs may also be
used to transfer private and sensitive information to third-party
domains (step 7) [9].

Fig. 1. Overview of a webpage rendering process and web tracking. Websites
(in this case cnn.com) use third-party domains for content provisions and
analytics services.

B. Privacy Preserving Tools (PP-Tools)

In the following we brieﬂy introduce ﬁve common PP-

Tools considered in our study.

NoScript (NS) blocks JavaScript programs, Java programs,
Silverlight, Flash and other executable content on a webpage

3

that may undermine security including tracking [4]. The default
behaviour is to deny, thus only allowing content that the user
has explicitly permitted (whitelists). This however requires
frequent user intervention and may cause usability issues.

Adblock Plus (AP) is primarily an advertisement blocking
tool based on blacklists [6]. It provides the option to choose
from different blacklists, e.g., EasyList [18], to block unwanted
advertisements. It searches the rendered HTML page (DOM
tree) through regular expressions and blocks the downloading
of web-components such as web bugs, ads or JavaScript
programs that belong to blacklisted tracking and advertising
services.

Disconnect (DC) is also a blacklist based tool [19], which
mainly blocks third-party tracking cookies and JavaScript
programs from social networks such as Facebook and Twitter.
Ghostery (GT) ﬁnds and disables cookies and scripts that
are used for tracking [5]. It also searches the DOM tree through
regular expressions for advertisers and trackers identiﬁed in
a predeﬁned blacklist. It provides feedback to the user to
selectively unblock tracking domains.

Privacy Badger (PB) uses a blacklist [20] of third-party
tracking cookies that track users on multiple ﬁrst-party do-
mains. It further uses a heuristic algorithm that blocks content
(JavaScript programs and ads) from third-party domains who
either read high entropy cookies, or read cookies on multiple
(at least 3) ﬁrst-party domains, or do not comply with an
acceptable “Do Not Track” policy statement [21].

III. METHODOLOGY
A. Objectives and Overview of our Work

Our objectives can be summarised as follows:

1)

2)

3)

Assess the effectiveness of existing PP-Tools in
terms of correctly classifying tracking and functional
JavaScript programs.
Propose an effective machine learning approach to
classify tracking and functional JavaScript programs,
trained on a subset of tracking JavaScript programs
only.
Analyse PP-Tools and our classiﬁer(s) in the wild and
identify any trackers missed by the PP-Tools.

For the ﬁrst objective, we use a labelled dataset, composed
of JavaScript programs, to evaluate the outcome of each of the
aforementioned ﬁve PP-Tools as observed by a user navigating
through a list of webpages. We used a set of 95 websites
and extracted 2,612 unique JavaScript programs which were
manually inspected and labelled as either tracking or functional
according to a set of pre-identiﬁed rules (cf. Table I). This
dataset is referred to as the labelled dataset (cf. §III-C).

For the second objective, we build classiﬁers trained only
on partial knowledge, i.e., on knowledge of labels from a
subset of tracking JavaScript programs only. These tracking
JavaScript programs were extracted from the above mentioned
labelled dataset. The accuracy of our classiﬁers is also val-
idated using the labelled dataset, and compared against a
traditional two-class classiﬁer trained on both functional and
tracking JavaScript programs from the labelled dataset.

Cookie Databasecnn.comUser’s Browser - Rendered DOMThird Party DomainsFirst Party DomainsClient SideServer Side1234567We assess the effectiveness of our classiﬁers and the PP-
Tools in the wild, i.e., our third objective, by further extracting
135,656 JavaScript programs from a set of 4,084 websites. We
call this dataset, the wild dataset (cf. §VI-A). We apply and
compare results of the PP-Tools and our classiﬁers on this
wild dataset. We also manually inspect two random samples
of 100 JavaScript programs each on which our classiﬁer and all
the other PP-Tools disagree. As a result, we identify trackers
that are missed by the PP-Tools and reveal several functional
JavaScript programs that are being mistakenly blocked by the
PP-Tools.

B. Obtaining JavaScript programs

We developed a crawler based on the Selenium web-
driver [22] for automated downloading of target webpages. The
Selenium framework allows us to retrieve the whole content
of a rendered webpage (DOM tree). Our crawling process
is as follows: 1) use Firefox’s Selenium webdriver to fetch
the landing page from a given list of webpages, 2) dump
the DOM tree and save it locally, 3) parse all script tags
to ﬁnd in-page JavaScript programs, i.e., programs embedded
within the HTML script tag, and save them in ﬁles, and 4)
download all external JavaScript programs, i.e., programs that
are linked via external URLs. Due to the dynamic nature of
webpages, the content of a webpage is likely to change when
downloaded at different times. Moreover, webpage content
may be dynamic, however our focus is JavaScript programs
contained in the webpage. JavaScript programs are indeed
likely to load dynamic content (ads, media content, etc.), but
a JavaScript codes’ nature (functional/tracking) is unlikely
to change for a particular tracking domain; neither does its
syntax/structure. To download the same version of a webpage
for each PP-Tool, we simultaneously download webpages with
PP-Tools on and off.

For extracting JavaScript programs when the PP-Tools are
turned off, referred to as PP-Tools off, we obtain JavaScript
programs for both labelled and wild datasets as above. For
the labelled dataset, these JavaScript programs are additionally
assigned a label (tracking or functional) using Firefox and
Firebug as detailed in Section III-C. Likewise, when PP-Tools
are turned on (referred to as PP-Tool on), we simultaneously
obtain the set of JavaScript programs for each of the PP-Tools
under consideration, by creating a separate Firefox proﬁle for
each tool. To unpack the compressed JavaScript codes, we use
jsbeautifier [23] python library for each set of JavaScript
programs when PP-Tools are on and off.

C. The Labelled Dataset

We deﬁned a set of 12 rules to guide our manual classiﬁca-
tion of JavaScript programs as tracking or functional. Table I
summarises the classiﬁcation rules we used.

Rules R1 and R2 in Table I label all JavaScript programs
that create panels and set margins for ads within a webpage or
the ones that fetch ads and display them, as tracking. Likewise
we also label all programs that enable social media widgets,
such as Facebook ‘Likes’ and Twitter ‘Follow’, as tracking
(rule R3). We went through all the script tags, i.e., in-
page JavaScript programs, and labelled them as tracking if
they include an external JavaScript code (within the body)

Rule

JS

R1
R2
R3
R4

R5
R6
R7

R8
R9

R10

R11
R12


















#

216
115
45
324

353
180
542

509
132

103

40
53

Description

in-page JS that

include external JS from third-party

All JS that create panels and set margins for ads
All JS that access and display ads
All social media widgets
All
analytics and advertisers
All external JS from third-party analytics and advertisers
All cookie enablers, readers or writers
All external JS that provide useful functionality such as
navigation menus, search and login
All in-page JS that provide useful functionality
All JS that fetch content from ﬁrst-party content domains or
third-party CDNs
All JS in hidden iframe that belong to third-party analytics,
advertisers and social media
All JS in hidden iframe that enable, read or modify cookies
All JS that track mouse or keyboard events

TABLE I.

RULES FOR LABELLING JAVASCRIPT PROGRAMS - R STANDS

FOR RULE; JS STANDS FOR JAVASCRIPT PROGRAM; # DENOTES THE

NUMBER OF JAVASCRIPT PROGRAMS SATISFYING THE CORRESPONDING
RULE IN THE LABELLED DATASET;  REPRESENTS TRACKING JAVASCRIPT
PROGRAMS AND  REPRESENTS FUNCTIONAL JAVASCRIPT PROGRAMS.

belonging to a known third-party advertiser or analytic service
(R4). It follows that all external JavaScript programs contained
in a webpage that belong to a known third-party advertiser or
analytics are labelled tracking (R5).

External

JavaScript programs

In-page Average Total Tracking Functional

1,353

1,256

27.5

2,612

57%

43%

TABLE II.

CHARACTERISTICS OF JAVASCRIPT PROGRAMS FROM 95
WEBSITES IN OUR LABELLED DATASET.

To uniquely identify users, trackers enable, read, write
or update cookies on the users’ machine. We used Firebug’s
‘Cookies’ panel to obtain a list of cookies. This list contains
the name and ID of a cookie as well as the domain the cookie
is stored for. We then searched the DOM tree by the cookie
name and ID to ﬁnd the JavaScript that enables, reads or
modiﬁes this cookie. Note that the JavaScript corresponding to
the cookie contains its name and ID in its source code. If the
domain for which the cookie is stored is a known analytic or
advertiser then we mark the JavaScript as tracking; otherwise
the JavaScript is marked as functional (R6). We are aware
that, in principle, cookie names can be dynamically generated.
However, during manual labelling we did not encounter this
except for session cookies (which may not set by JavaScript
programs).

Similarly, we used Firebug’s ‘Network’ panel to identify
invisible iframes that belong to third-party analytics, adver-
tisers, or social media. We label
the JavaScript programs
belonging to these iframes as tracking JavaScript programs
(R10). We also label the JavaScript programs inside iframes
that enable, read, or modify cookies as tracking JavaScript
programs (cf. rules R10 and R11). Analytics and advertisers
employ hidden iframes by specifying the height and width of
the iframe to zero or by positioning it so that it is out of
the visible area on a webpage. A hidden iframe is positioned
so that when a user interacts with a certain component of a
webpage, his action and potentially the information contained
in corresponding cookie(s) are redirected to the advertiser’s or
analytic’s networks.

4

All JavaScript programs that facilitate user interaction
with the webpage’s content and ensure normal functionality
are labelled as functional. For instance, webpages contain
JavaScript programs that enable search boxes, accessibility
options, authentication services, shopping carts, prompts, lo-
gins, navigation menu and breadcrumbs (rules R7 and R8).
Similarly, some JavaScript programs are used to track mouse
and keyboard events, such as right click or caps lock on or
off (R12) while others are used to retrieve content from either
ﬁrst-party content domains or third-party CDNs like Akamai
(R9). We used manual list of third-party CDNs to differentiate
from other content.

Note that we considered social widgets to be privacy-
intrusive as they allow social networks to track users [24];
however, these could potentially be perceived as providing
functional features as they allow users to interact with their
social network. Notably, mouse or keyboard related JavaScript
programs are only considered functional if they do not send
information to third-party servers (unlike JavaScript programs
that belong to e.g., ‘Moat’[25] that
track users and send
collected data to third-party servers). Likewise, JavaScript
programs that tracks user’s comments and send them to an
external server (e.g., ‘Disqus’[26]) were labelled as tracking
JavaScript programs.

We selected 95 web domains such that 50 of them were
the top 50 Alexa websites, and the remaining 45 were ran-
domly chosen from websites with Alexa rank in the range
5,000-45,000. In total, we collected 2,612 JavaScript pro-
grams, which consisted of 1,376 tracking and 1,236 func-
tional JavaScript programs according to our labelling. This
constitutes our labelled dataset. Note that the 2,612 JavaScript
programs obtained correspond to the PP-Tool off setting in our
terminology. Table II summarizes the key characteristics of the
JavaScript programs in our labelled dataset. Note that 43% of
the JavaScript programs are functional indicating that the scale
of the problem we are addressing is signiﬁcant. Misclassifying
even a small part of this can signiﬁcantly impair user’s web
experience.

IV. EFFECTIVENESS OF PP-TOOLS

We ﬁrst introduce metrics used in our evaluation.

A. Aggressiveness of PP-Tools and Surrogate JavaScript Pro-
grams

Let H denote the set of DOM trees (webpages) in a
given dataset (in our case, H could be the labelled or the
wild dataset). Let J denote the set of all JavaScript programs
from H. Given a DOM tree h ∈ H, js(h) denotes the set
of JavaScript programs contained in h. This corresponds to
the PP-Tools’ off setting. Let p denote a given PP-Tool. Then
p(h) denotes the DOM tree obtained after applying p to h,
and js(p(h)) denotes the set of JavaScript programs in the
DOM tree p(h). This corresponds to the PP-Tools’ on setting.
We have the condition that js(p(h)) ⊆ js(h), i.e., the set of
JavaScript programs obtained when a PP-Tool is on will always
be a subset of the set of JavaScript programs obtained when
the PP-Tool is off.

However, in our experiments, we found that some PP-
Tools, such as Ghostery and NoScript, replace some JavaScript

programs by new JavaScript programs, called surrogate
JavaScript programs, to ensure smooth viewing of the web-
page [27], [28]. For instance, Ghostery replaces the JavaScript
code enabling Twitter
‘Follow’ button with a surrogate
JavaScript code that displays a Ghostery button, while still
blocking the functionality of the Twitter button. When a
surrogate JavaScript codes is present in the DOM tree p(h),
we consider the replaced JavaScript code to be blocked by the
PP-Tool p, and as a result we do not include the surrogate
JavaScript code in the overall count. This is consistent with
our manual inspection of the surrogate lists of Ghostery and
NoScript, as all the surrogates turned out to be functional
(according to our labelling rules).

Appendix E contains more details of surrogate JavaScript

programs.

We deﬁne the aggressiveness of a privacy-preserving tool

p as

a(h) = 1 − |js(p(h))|
|js(h)|

,

which is the fraction of JavaScript programs blocked by a PP-
Tool p from the DOM tree h. In settings with PP-Tools off,
aggressiveness is 0. A PP-Tool is said to be aggressive if it
has high aggressiveness (i.e., closer to 1) for a high portion of
webpages from H.

B. Evaluation Results

We conﬁgured the PP-Tools so that their deﬁnitions of
tracking and functional JavaScript programs are consistent
with our labelling rules in Table I. Speciﬁcally, we conﬁgured
NoScript so that it does not allow iframes, consistent with rules
R10 and R11 in Table I. Likewise, we disabled the default
option “Allow all non-intrusive ads” for Adblock Plus and
we used The EasyList
[18] and Fanboy’s Social Blocking
List [29] as blacklists for Adblock Plus. We enabled “Blocking
all Trackers and Cookies” option for Ghostery. We used the
default settings for Privacy Badger and Disconnect since they
do not provide the user with any conﬁguration options. To
account for any “heating” phase of the PP-Tools, we run each
of the tools over another set of 100 random (non-labeled)
webpages (with no overlap with the labelled dataset) prior to
applying them to our labeled dataset. Summary of the set up
used for PP-Tools is shown in Table IX in Appendix A.

JS

External
In-page
Total
Average per webpage

Blocked (%)
Allowed (%)

NS

570
1,118
1,688
17.6

35.38
64.6

GT

813
1,173
1,986
20.1

24.0
76.0

PP-Tools On

AP

1,141
1,197
2,338
24.4

10.5
89.5

DC

1,206
1,218
2,424
25.3

7.2
92.8

PB

1,230
1,208
2,438
25.4

6.7
93.3

TABLE III.

CHARACTERISTICS OF JAVASCRIPT PROGRAMS (JS) FROM

THE LABELLED DATASET MARKED AS FUNCTIONAL (ALLOWED) BY

PP-TOOLS.

Table III shows the view of JavaScript programs from the
95 webpages in the labelled dataset when the different PP-
Tools were on. The top-half of the table shows the number
of JavaScript programs (in-page and external) that are allowed
when a particular PP-Tool is used. The last two rows of the

5

table show the number of JavaScript programs that are blocked
and allowed as a percentage of the total number of JavaScript
programs in our dataset (2,612).

Fig. 2. Aggressiveness of PP-Tools.

We further analyse the performance of the PP-Tools by
measuring their aggressiveness, i.e., a(h). Figure 2 shows the
cumulative distribution function of a(h) for the ﬁve PP-Tools
when applied on the 95 websites. We observe that NoScript’s
aggressiveness is more than 0.2 for about 60% of the web
domains whilst Ghostery’s aggressiveness is more than 0.2 for
about 40%. In contrast, Adblock Plus, Disconnect, and Privacy
Badger have an aggressiveness of more than 0.2 for only about
10% of domains, which indicates that they are comparatively
less aggressive in blocking JavaScript programs.

We are also interested to know whether there is an inverse
relation between aggressiveness and effectiveness of PP-Tools,
i.e., an aggressive PP-Tool breaks useful functionality in a
webpage (by incorrectly blocking functional JavaScript pro-
grams), and a less aggressive PP-Tool allows more tracking
JavaScript programs go undetected. Effectiveness is deﬁned
as the balance between correctly blocking tracking JavaScript
programs (true positives) and incorrectly blocking functional
JavaScript programs (false positives).

PP-Tool
NoScript
Ghostery

Adblock Plus
Disconnect

Privacy Badger

0.78
0.65
0.44
0.40
0.37

Tracking

Functional

Allowed

Blocked

Allowed

Blocked

0.22
0.35
0.56
0.60
0.63

0.21
0.08
0.06
0.06
0.06

0.79
0.92
0.94
0.94
0.94

TABLE IV.
COMPARISON OF THE OUTPUT OF PP-TOOLS AGAINST OUR
LABELLED SET OF TRACKING AND FUNCTIONAL JAVASCRIPT PROGRAMS.
FALSE POSITIVES AND NEGATIVES.

TRUE POSITIVES AND NEGATIVES,

For this, we measure the true positive and false positive

rates of each of the PP-Tools.

Our results are shown in Table IV. We ﬁnd that PP-Tools’
true positive rates vary from 37% to 78% and false positives
range from 6% to 21%. Not surprisingly, NoScript has the
highest true positive rate of 78% at the expense of the poorest
false positive rate of 21%. Adblock Plus, Disconnect, and
Privacy Badger fair better in terms of false positive rate (6%)

6

but pay the penalty with considerably lower true positives
rates of 44%, 40% and 37%, respectively. Both Ghostery and
NoScript achieve the lowest average error rate (AER) of 0.215,
where AER is deﬁned as the average of false positive and
negative rates. However, Ghostery is better in terms of allowing
functional JavaScript programs, achieving a false positive rate
of only 8% with a lower true positive rate (65%) than NoScript.
To summarise, these results suggest that current PP-Tools
are ineffective in terms of striking a good balance between
limiting tracking and adversely affecting useful functional-
ities on webpages. There are several possible reasons for
this ineffectiveness. One reason could be that some of these
PP-Tools collaborate with trackers and advertisers to allow
some JavaScript programs that follow the PP-Tool’s acceptable
ads and tracking policy. For instance, on behalf of trackers
and publishers, PageFair pays Adblock Plus not
to block
trackers and advertisements that follow their Acceptable Ads
standard [30]. Another, more relevant reason for their low
ineffectiveness is that current PP-Tools use rather elementary
techniques such as manually maintained blacklists (whose
maintenance is hard amidst the rapid growth of trackers), regu-
lar expression matching only on URLs within the script tag
or even completely blocking the use of JavaScript programs.
In our work, we go further by inspecting JavaScript code itself.

V. CLASSIFICATION AND VALIDATION

In a real setting, we cannot expect to know a priori all
the possible instances of tracking and functional JavaScript
programs due to the sheer prevalence of JavaScript programs
on the web. Thus, realistically we may only expect to collect
a small subset of JavaScript programs known to be functional
or tracking. Instead of focusing on labelling both functional
and tracking JavaScript programs, we hypothesise that it is
to have partial knowledge of only the tracking
sufﬁcient
JavaScript class. Our intuition is that
tracking JavaScript
programs potentially share similar characteristics and these
characteristics can be leveraged in a one-class classiﬁcation
framework.

In what follows, we ﬁrst introduce the various models to
extract JavaScript code features and then present our machine
learning approaches.

A. Feature Models

The intuition. Consider the cookie setting code snippets
from Google Analytics [31] and Visual Revenue [32] shown as
Trackers 1 and 2, respectively. Notice that the two are func-
tionally and structurally similar, with differences in variable
names. More technically, the snippets result in similar canon-
ical representations which we shall explain in Section V-A2.
Similar examples indicate that a similarity measure based on a
feature space composed of semantic or syntactic tokens from
these JavaScript programs should be effective in differentiating
between functional and tracking JavaScript programs.
GOOGLE ANALYTICS COOKIE SETTING

Tracker 1.

var _gaq = _gaq || [];
_gaq.push([’_setAccount’, ’UA-1627489-1’]);
_gaq.push([’_setDomainName’, ’geo.tv’]);
_gaq.push([’_trackPageview’]);

0.00.20.40.60.81.0a(h)0.00.20.40.60.81.0Empirical CDFPrivacy BadgerGhosteryNoScriptAdblock PlusDisconnectTracker 2.

VISUAL REVENUE COOKIE SETTING

var _vrq = _vrq || [],
_vrqIsOnHP = (document.body.className ||

’’).search(’pg-section’) >=0 ? true : false;

_vrq.push([’id’, 396]);
_vrq.push([’automate’, _vrqIsOnHP]);
_vrq.push([’track’, function() {}]);

To exemplify the existence of such similarity, we create
three distinct sets of 500 JavaScript programs (tracking-only,
functional-only, and tracking and functional) from our labelled
dataset and calculate the term frequency with inverse document
frequency (tf-idf) based cosine similarity values based on our
feature model. Note that, being a na¨ıve approach, the cosine
similarity metric is shown here for illustrative purposes only.
We shall use our classiﬁer later (cf. §V-B) to more efﬁciently
classify tracking and functional JavaScript programs.

Fig. 3. Similarity between disjoint sets of functional and tracking JavaScript
programs (JS).

Figure 3 plots the cumulative distribution function (CDF)
of the similarity values obtained. The long tail we observe
for “tracking vs. tracking” and “functional vs. tracking” as
compared to “tracking vs. functional” suggests that tracking
(resp. functional) components do indeed have higher intra-
similarity.

In Appendix F, we show further examples of tracking

JavaScript programs that illustrates code similarity.

In the rest of this section, we give details of the syntactic
and semantic models in use. But ﬁrst, we introduce some
notation.
Notation and Problem Formulation. Recall that J represents
the set of all JavaScript programs in a corpus. We have
a small subset J(cid:48) of JavaScript programs that are labelled.
Furthermore, the labels only belong to tracking JavaScript
programs, which we call positive labels. The totality of the
negative labels, i.e., functional JavaScript programs, are not
known beforehand. So, we have a classiﬁcation problem in
which we have a set J whose elements can belong to two
possible classes, and we only have a subset J(cid:48) of J labelled
with only one of the classes. The JavaScript programs from
J − J(cid:48) can be either functional or tracking. The goal of the
classiﬁer is to obtain a correct labelling of the JavaScript
programs in J. Assume that we have a feature vector j

7

corresponding to some JavaScript code j obtained through one
of the feature extraction models, to be discussed shortly. Let
y represent the class j belongs to. If j is a tracking JavaScript,
then y = +1; otherwise y = −1. Let us also introduce the
label ﬂag l. If j is labelled, i.e., is assigned a class via y = +1
or −1, then l = 1; otherwise l = 0.

To quantitatively measure similarity between different
JavaScript programs, we use the tf-idf measure. Central to this
measure is the term t. How the term t is deﬁned gives rise to
the different semantic and syntactic models to be discussed
shortly. For now let us assume that each JavaScript program
j ∈ J is composed of one or more terms. We then use the
boolean term frequency (tf) measure such that tf(t, j) = 1
if t ∈ j and 0 otherwise. The inverse document frequency
measure idf is deﬁned as: idf(t, j, J) = log
|{j∈J:t∈j}|. Finally,
we obtain tf with idf for each t ∈ j over the corpus J,
as: tf-idf(t, j, J) = tf(t, j) · idf(t, j, J). Note that, intuitively,
the tf-idf measure gives more weight to terms that are less
common in J, since such terms are more likely to make the
corresponding JavaScript program stand out. The tf-idf thus
transforms our corpus J to the feature vector space. The feature
vector corresponding to JavaScript program j is denoted by j.
The ith component of j, denoted j[i] corresponds to the term
ti and is equal to tf-idf(ti, j, J).

|J|

1) Syntactic Model:

In the syntactic model, the term t
is deﬁned as a string of characters representing one line of
JavaScript code. Note that we used jsbeautifier python
library to unpack compressed JavaScript programs as discussed
in Section III-B. Due to a large number of JavaScript programs
contained in J the dimension of the resulting feature space can
become impractically large. We therefore needed to “cap” the
feature vector space. For this we experimented with different
sizes of the feature space by using the top 200, 500, 1,000,
1,500 and 2,500 terms as ranked by their tf-idf scores, in turn.
We found no considerable improvement in classiﬁcation over
the smallest size, i.e., 200, and since this size was also the
most computationally efﬁcient, we chose it as a cap on the
feature vector space.

2) Semantic Models: In addition to the syntactic similarity
between JavaScript programs, we are interested in a richer
model
that captures the structure of JavaScript programs.
For this, we use the n-gram model introduced in [33]. This
approach identiﬁes tokens in programs whose importance can
then be determined through some statistical measure such as
tf-idf. An example of a token is one line of JavaScript code,
as used in the syntactic model. An n-gram, where n ≥ 1,
refers to n tokens which are dependent on each other. To
construct n-grams, the approach taken in [33] converts the code
into a canonical form. The canonical form is an intermediate
representation of a JavaScript program where variable names
and loop speciﬁcs are abstracted away in an effort to apply
natural language processing-like techniques on the resulting
code representation. From the resultant canonical form, two
different models can be derived based on how the n-grams are
constructed. The difference lies in how different lines of the
canonical code are perceived to be dependent on each other.
One model relies on sequential dependency, wherein a line of
code is dependent on the execution of the previous line, and
so on. Thus, an n-gram of a statement in the canonical code
is a sequence of n lines. We call this the sequential n-gram

0.00.20.40.60.81.0PDG 7-grams tf-idf Cosine Similarity of JavaScript Programs0.00.20.40.60.81.0Commulative Distribution of JavaScript ProgramsTracking JS - Tracking JSFunctional JS - Functional JSTracking JS - Functional JSmodel.

Alternatively, since consecutive lines in source code are
often unrelated to each other, instead of computing n-grams
via this trivial ordering, program dependency graphs (PDGs)
can be employed [34], [33]. In such a graph, a node represents
a single statement from the canonical form. A node a of the
graph is dependent on a node b if its execution depends on
the result of b or if it takes as input a value written by b. If
this is true, node a is connected to b via a directed edge in
the direction of the latter. An n-gram of a particular gram
x is then the subgraph of the program dependency graph
consisting of all (backward) paths of length n − 1 starting
from x. This represents the second model and is referred to as
the PDG n-gram model. See Appendix B for an example of
canonicalization and the resulting PDG.

Once n-grams have been constructed via the sequential or
the PDG model, we use them in our tf-idf measure to calculate
their relative importance [33], where the term t is an n-gram
We can have different models depending on the value of n in
n-gram. For this study, we use 4-gram and 7-gram variants.
We also tried several values of n in our n-gram models, but
found no signiﬁcant improvement beyond n=7.

B. Machine Learning Classiﬁers

We present two machine learning approaches that apply to
our problem of binary classiﬁcation with only partially known
instances from one of the classes used in training.

1) One-Class SVM: One-class SVM (OCSVM) maps the
feature vectors belonging to the training data to a higher
dimensional space through the use of an appropriate kernel,
and then ﬁnds the hyperplane whose margin from the origin
is maximized. One can view one-class SVM as a regular two-
class SVM with the difference that the origin represents the
only member of the second class [35]. Given the feature vector
j corresponding to the JavaScript program j, one-class SVM
gives us the classiﬁer f (j) = (cid:104)w, j(cid:105) + b, where the right hand
side term is the equation of the hyperplane, with w being the
vector normal to this hyperplane and b being the intercept.
If f (j) ≥ 0, j is considered as functional; otherwise it is
considered as tracking JavaScript code.

2) Positive and Unlabelled (PU) Learning: The PU learn-
ing technique, translated to our problem space, constructs a
probabilistic classiﬁer that decides whether a JavaScript code
is tracking or functional from a probabilistic classiﬁer that
decides whether a JavaScript program is labelled or unlabelled.
More precisely, it constructs the classiﬁer f (j) = Pr[y =
+1| j] from the classiﬁer g(j) = Pr[l = 1| j]. The two classes
in g(j) are the labelled and unlabelled JavaScript programs,
whereas the two classes in f (j) are positive (tracking) and
negative (functional) JavaScript programs. To understand the
concept behind PU learning, notice that the assumptions (a)
only positive examples (tracking JavaScript programs) are
labelled, (b) the set of labelled examples is chosen uniformly
at random from all positive examples,
lead to the result
Pr[l = 1| j, y = −1] = 0 and Pr[l = 1| j, y = +1] =
Pr[l = 1| y = +1]. The probability Pr[l = 1| y = +1] is
the constant probability that a positive example is labelled (as

it is independent of j). Now we can have Pr[l = 1| j] as
Pr[l = 1| j] = Pr[l = 1| j, y = −1] Pr[y = −1| j]
+ Pr[l = 1| j, y = +1] Pr[y = +1| j]
= Pr[l = 1| y = +1] Pr[y = +1| j].

As Pr[l = 1| y = +1] is a constant, we get the classiﬁer f (j)
from g(j). We need only to estimate Pr[l = 1| y = +1]. For
this, a validation set consisting of only labelled examples, say
P , can be used. Note that, according to the assumption above,
the labelled examples are all positive. Therefore, in the above
equation, for j ∈ P , the term Pr[y = +1| j] is 1. This means
that g(j) is equal to the constant Pr[l = 1| y = +1] for the
validation set P . Thus, we can use the trained classiﬁer g(j)
on the validation set P to estimate this constant probability by
j∈P g(j). In this work, we choose SVM as the trained
1|P|
classiﬁer, i.e. g(j). The Reader can refer to [36], [37] for a
more comprehensive treatment on PU learning.

(cid:80)

C. Validation

We use the traditional supervised two-class support vector
machine (SSVM) [38], [39] as a benchmark for the perfor-
mance of our one-class classiﬁers. We run the three classiﬁers
(one-class SVM, PU-Learning and SSVM) fed by syntactic
and semantic features extracted from the JavaScript programs
in the labelled dataset. Syntactic features are extracted simply
by treating each line of JavaScript code as an individual term.
To extract semantic features, we ﬁrst transform each JavaScript
program into its canonical form. Then, for the sequential n-
gram model, a term is extracted as n lines preceding each line
of the canonical code. For the PDG n-gram model, we further
construct the program dependency graph from the canonical
code by analysing the abstract syntax trees produced by the
V8 JavaScript engine.3 A term in the PDG n-gram model is
extracted as the subgraph (consisting of paths of length n− 1)
of the PDG corresponding to each line of the canonical code.
As mentioned before, feature vectors for the syntactic model
were constructed by considering the top 200 terms ranked by
their tf-idf score. On the other hand, no “cap” was used for
the sequential n-gram and PDG n-gram models, as the feature
vector size was already around 200.

For PU-learning and one-class SVM, we use 80% of
the tracking JavaScript programs from the labelled dataset to
constitute the training set (i.e., the training set only contains
members of the positive class). We mixed the remaining 20%
of tracking JavaScript programs with functional JavaScript
programs in the labelled dataset for the testing of these two
classiﬁers. For SSVM, we use 80% and 20% of JavaScript
programs (both functional and tracking) from the labelled
dataset for training and testing, respectively. We empirically
ﬁnd the appropriate values for γ, a parameter for radial
basis function kernel [35], and ν, a parameter for SVMs by
performing a grid search on the ranges 2−15 ≤ γ ≤ 20 and
2−10 ≤ ν ≤ 20 with 5-fold cross-validation on each training
group. We use scikit-learn [40], an open source machine
learning library for Python that includes a modiﬁed version of
LIBSVM [41].

3We used the software shared by authors of [33] to transform JavaScript
programs into canonical forms and to construct PDGs from the canonical
forms.

8

1) Performance of Classiﬁers: Table V shows the perfor-
mance of our classiﬁers. Note that for each feature model,
we use the same training set for PU-learning and one-class
SVM. We observe that, regardless of the feature model in use,
PU-learning and one-class SVM exhibit similar performance.
They also perform similar to supervised SVM in terms of
false and true negative rates (related to functional JavaScript
programs). In general, except for the syntactic feature model
where supervised SVM outperforms our one-class classiﬁers
in terms of false and true positives, the three classiﬁers achieve
very similar rates, with true positive and negative rates of up
to 0.99 and false positive and negative rates of only 0.01.

Tracking

Functional

Blocked

Allowed

Blocked

Allowed

Feature
Model
Syntactic

PDG
4-gram

Sequential

4-gram

PDG
7-gram

Sequential

7-gram

Classiﬁer
SSVM
OCSVM

PU

SSVM
OCSVM

PU

SSVM
OCSVM

PU

SSVM
OCSVM

PU

SSVM
OCSVM

PU

0.93
0.88
0.86
0.96
0.95
0.93
0.98
0.98
0.96
0.99
0.99
0.98
0.99
0.99
0.98

0.07
0.12
0.14
0.04
0.05
0.07
0.02
0.02
0.04
0.01
0.01
0.02
0.01
0.01
0.02

0.01
0.02
0.02
0.03
0.03
0.04
0.01
0.02
0.03
0.01
0.01
0.02
0.01
0.01
0.02

0.99
0.98
0.98
0.97
0.97
0.96
0.99
0.98
0.97
0.99
0.99
0.98
0.99
0.99
0.98

TABLE V.
PERFORMANCE OF THE CLASSIFIERS AGAINST THE
LABELLED DATASET OF TRACKING AND FUNCTIONAL JAVASCRIPT

PROGRAMS.

TRUE POSITIVES AND NEGATIVES,

FALSE POSITIVES AND

NEGATIVES.

In comparison with the tested PP-Tools (cf. Table IV), this
shows an improvement in the true positive rate by 21% to
62% and in the false positive rate by 5% to 20%.4 Not only do
our classiﬁers outperform the PP-Tools in effectively detecting
tracking JavaScript programs, but they also do not suffer from
high misclassiﬁcation of functional JavaScript programs which
would result in poor user web experience.

2) Effect of Feature Models: Table V suggests that the
feature models have an effect on the classiﬁcation accuracy.
The syntactic model has the worst performance for all three
classiﬁers. The PDG 7-gram and sequential 7-gram models
in contrast show the best results for all the classiﬁers. We
improve the false negative rate by 11-12% in the case of the
one-class classiﬁers by using the 7-gram models. Interestingly,
the performance of the classiﬁers for classifying functional
JavaScript programs is similar across all feature models, which
suggests that perhaps functional JavaScript programs have
more inter-similarity than the inter-similarity between tracking
JavaScript programs.

Our

results

show that one-class classiﬁers, as non-
expensive learning techniques, perform similarly. Now we
aim to apply our one-class SVM and PU-learning classiﬁers
in the wild and compare their output to PP-Tools. For this
purpose, we choose the best and the worst performers of the
lot: sequential 7-gram and the syntactic model, respectively.
Note that although, performance wise, sequential 7-gram and

4We reiterate that our comparison is fair since we conﬁgured these PP-Tools

to be consistent with our rules in Table I.

9

PDG 7-gram are similar, we chose the former as it requires
less pre-processing (no construction of PDGs).

VI. EVALUATION IN THE WILD

We evaluate and compare the output of our classiﬁers and
the PP-Tools on a set of JavaScript programs collected from a
large number of websites, called the wild dataset.

A. The Wild Dataset

The wild dataset consists of JavaScript programs extracted
from the landing page of 4,084 websites. These websites were
selected such that 3,500 of them were top Alexa websites
ranked between 51 to 3,550 inclusive (since the top 50 websites
were already used in the labelled dataset), with the remaining
584 having a rank in excess of 5,000 (excluding the 45
websites with rank in this range used in the labelled dataset (cf.
§III-C)). A total of 135,656 JavaScript programs were present
in these websites. The composition of JavaScript programs
into external and in-page JavaScript programs is shown in
Table VI (under the column labelled PP-Tools off ). The table
also shows the number of in-page and external JavaScript
programs allowed by each PP-Tool considered in our work.
Again, we observe that NoScript is the most aggressive tool,
blocking on average 37.7% of the JavaScript programs per
website, closely followed by Ghostery (34.8%) and AdBlock
Plus (26%). In comparison, Privacy Badger and Disconnect
block 11.5% of JavaScript programs per website.

PP-Tools

off

PP-Tools on

AP

NS

GT

71,582
64,074
135,656

33.2

JS
External
In-page
Total
Average per webpage
29.4
Blocked (%)
11.5
Allowed (%)
88.5
TABLE VI.
CHARACTERISTICS OF JAVASCRIPT PROGRAMS (JS)
COLLECTED FROM 4,084 WEBSITES WITH PP-TOOLS on AND off AS

29,345
54,972
84,428
20.7
37.7
63.3

48,191
51,389
99,580
24.4
26.6
73.4

38,492
49,952
88,444
21.7
34.8
65.2

DC

59,488
60,546
120,034

29.4
11.5
88.5

PB

60,817
59,250
120,067

-
-

VIEWED FROM A FIREFOX SELENIUM-CONTROLLED BROWSER.

B. Comparing PP-Tools and our Classiﬁers

We trained our PU-Learning and one-class SVM classiﬁers
using only the tracking JavaScript programs from the labelled
dataset. The trained classiﬁers were then run on the wild
dataset. Next, we assess the extent to which our two classiﬁers
agree or disagree with each PP-Tool.

1) Agreement Ratio: Denote by Tc and Fc the set of
tracking and functional JavaScript programs, respectively, in
the wild dataset as classiﬁed by a classiﬁer c (i.e., one-class
SVM or PU learning). Likewise, Tp, resp. Fp, denotes tracking,
resp. functional, JavaScript programs as marked by the PP-
Tools p.

Then the ratio of agreement between c and p on tracking
JavaScript programs is |Tc ∩ Tp|/|J|, where J is the set
of JavaScript programs in the wild dataset. Similarly,
the
ratio of agreement on the functional JavaScript programs is
|Fc ∩ Fp|/|J|. The ratio of agreement between a classiﬁer c
and a PP-Tool p is simply (|Tc ∩ Tp| + |Fc ∩ Fp|)/|J|. To
avoid excessive notation, we shall denote the ratios simply
by their constituent sets. For instance, the agreement ratio for

tracking JavaScript programs will simply be written as Tc∩Tp.
Table VII lists the values of agreement and the corresponding
disagreement ratios (deﬁned as 1 minus the agreement ratio).
Figure 5 in Appendix C illustrates these ratios graphically.

2) Performance of Classiﬁers: From Table VII, we ﬁrst
note that
the two classiﬁers are similar in terms of their
agreement/disagreement with PP-Tools, yielding very high
disagreement ratio in the syntactic model (ranging from 39%
to 58%) and signiﬁcant disagreement
in the sequential 7-
gram model (20% to 64%). Overall, the two classiﬁers are
relatively more in agreement with NoScript, followed closely
by Ghostery and Adblock Plus. This agreement, however, is
mostly in terms of classifying tracking JavaScript programs.
In terms of agreement on functional JavaScript programs,
the two classiﬁers are more in tune with Disconnect and
Privacy Badger. These two PP-Tools however are the least in
agreement with our classiﬁers in terms of tracking JavaScript
programs (ranging between 13% and 27%). One possible
explanation for this, in-line with previous research results [42],
is that Disconnect mostly blocks social plugins and buttons
such as Facebook Likes and Twitter Follow. This leaves a
host of other trackers allowed. The results for Privacy Badger
are similar because it mainly blocks JavaScript programs that
track users across multiple websites through cookies, which is
routinely done by social widgets.

3) Effect of Feature Models: Table VII also shows that
the sequential 7-gram model of the two classiﬁers is more
in agreement with NoScript, Ghostery and Adblock Plus as
compared to the syntactic model, by around 20%. However,
the difference is nominal for Disconnect and Privacy Badger,
with our classiﬁers agreeing more with these two PP-Tools in
the syntactic model. In the following, we further analyse the
observed disagreement by using the sequential 7-gram model
of the one-class SVM as it showed superior results during our
validation experiments (Section V-C).

C. Analysing Disagreements

We delve into the set of JavaScript programs on which
all PP-Tools and our one-class SVM with sequential 7-grams
classiﬁer disagree. We are interested in the two facets of
disagreement: JavaScript programs that our classiﬁer considers
tracking but all the PP-Tools consider functional, i.e., the set
Tc ∩p Fp, and JavaScript programs that our classiﬁer deems
tracking while all PP-Tools consider functional, i.e., Fc ∩p Tp.
The number of JavaScript programs for which our classiﬁer
and all PP-Tools are in disagreement is 9,071, representing
a surprisingly high 6% of the total number of JavaScript
programs in the wild dataset. These JavaScript programs are
split as 4,610 for Tc ∩p Fp and 4,461 for Fc ∩p Tp.

Inspecting these sets of disagreement would shed light on
the main reasons for disagreement. Unfortunately, manually
inspecting thousands of JavaScript programs (using the process
used for producing our labelled dataset) is a tedious and time
consuming process. We instead took a pragmatic approach,
where we randomly sampled 100 JavaScript programs each
from the two sets of disagreement. We then manually inspected
each JavaScript from the two samples and classiﬁed them as
tracking or functional following the rules and methodology

described in Section III-C. The results of this manual process
are shown in Table VIII.

implying that

the PP-Tools are correct

Our classiﬁer is correct in its labelling of 75 out of the
100 JavaScript programs it considered tracking. All
these
JavaScript programs are marked as functional by all the PP-
Tools,
in labelling
only 25 of these JavaScript programs. Moreover, our classiﬁer
correctly deemed 81 out of the 100 JavaScript programs as
functional, implying that the PP-Tools correctly labelled only
19 of the JavaScript programs in the random sample. Note
that
these numbers should not be taken as reﬂecting the
overall classiﬁcation performance of our classiﬁer, which was
validated in Section V-C. These samples merely represent the
corner cases of complete disagreement with all other PP-tools.
In other words, these numbers do not directly give us the true
and false positive rates of our classiﬁcation methodology.

Disagreement Total Sample Manual Labelling
Tracking Functional
Tc ∩p Fp
25
Fc ∩p Tp
81

4,610
4,461

100
100

75
19

TABLE VIII.
COMPARISON OF RANDOM SAMPLES OF DISAGREEMENT
BETWEEN OUR CLASSIFIER AND All PP-TOOLS. MANUAL LABELLING
AGREES WITH CLASSIFIER AND DISAGREES WITH PP-TOOLS, MANUAL
LABELLING DISAGREES WITH CLASSIFIER AND AGREES WITH PP-TOOLS.

We ﬁrst look at the 75 JavaScript programs correctly la-
belled as tracking by our classiﬁer, and incorrectly considered
as functional by the PP-Tools. Table X in Appendix C shows
10 representative JavaScript programs from this sample. We
identify two typical reasons the PP-Tools miss blocking these
JavaScript programs:

1)

2)

PP-Tools do not perform regular expression match-
ing on the body of JavaScript programs to identify
known trackers. Examples from these “misses” are
JavaScript programs #2 and #3 in Table X, which
are allowed by all PP-Tools even though the referred
domain doubleclick.net is included in their
blacklists; this is because these JavaScript programs
refer to this domain in their body, and the PP-Tools
perform a regular expression match only on the URL
of the JavaScript within the script tag.
As expected PP-Tools are unable to block trackers
that are not in the blacklist. An example is JavaScript
#9 in the table which we manually check to be a
social widget allowing users to ‘like’ comments on
the webpage while tracking the user activity which
is then transmitted to the ﬁrst party domain. All
PP-Tools miss this JavaScript because it does not
belong to a popular social media domain. Similarly,
JavaScript #4 in the table belongs to a Russian track-
ing and advertising service domain i-vengo.com,
but it is not in the blacklists of PP-Tools.

Our classiﬁer correctly marked these JavaScript programs
as tracking as these scripts were syntactically and structurally
similar to the tracking JavaScript programs used for training
our classiﬁers. We stress that our classiﬁers do not need to
know about all tracking scripts a priori; in fact, our classiﬁers
are able to ﬁnd new tracking scripts leveraging the syntactic
and semantic similarity between known tracking scripts and
previously unknown tracking JavaScript programs.

10

Feature Model

Syntactic

Classiﬁer
OCSVM

Sequential 7-gram

OCSVM

Syntactic

PU

Sequential 7-gram

PU

PP-Tool
NoScript
Ghostery

Adblock Plus
Privacy Badger

Disconnect
NoScript
Ghostery

Adblock Plus
Privacy Badger

Disconnect
NoScript
Ghostery

Adblock Plus
Privacy Badger

Disconnect
NoScript
Ghostery

Adblock Plus
Privacy Badger

Disconnect

Tc ∩ Tp

0.56
0.54
0.47
0.23
0.17
0.71
0.67
0.62
0.27
0.19
0.50
0.47
0.43
0.18
0.13
0.70
0.65
0.61
0.18
0.26

Tc ∩ Fp

0.10
0.13
0.20
0.44
0.50
0.06
0.10
0.15
0.5
0.58
0.07
0.10
0.14
0.38
0.44
0.05
0.10
0.14
0.57
0.49

Fc ∩ Tp

0.29
0.27
0.25
0.11
0.08
0.14
0.15
0.11
0.07
0.06
0.36
0.35
0.30
0.15
0.12
0.16
0.16
0.12
0.07
0.07

Fc ∩ Fp

0.05
0.06
0.09
0.22
0.25
0.09
0.08
0.13
0.16
0.17
0.07
0.08
0.13
0.28
0.31
0.09
0.09
0.13
0.18
0.18

Agreement

0.61
0.60
0.56
0.45
0.42
0.80
0.75
0.75
0.43
0.36
0.57
0.55
0.56
0.46
0.44
0.79
0.74
0.74
0.36
0.44

Disagreement

0.39
0.40
0.44
0.55
0.58
0.20
0.25
0.25
0.57
0.64
0.43
0.45
0.44
0.54
0.56
0.21
0.26
0.26
0.64
0.56

TABLE VII.

AGREEMENT AND DISAGREEMENT IN CLASSIFICATION OF TRACKING AND FUNCTIONAL JAVASCRIPT PROGRAMS BETWEEN OUR

CLASSIFIERS AND PP-TOOLS ON THE WILD DATASET;
DISAGREEMENT; Tp AND Fp REPRESENT JAVASCRIPT PROGRAMS CLASSIFIED AS
TRACKING AND FUNCTIONAL, RESPECTIVELY, BY THE PP-TOOL p, AND Tc AND Fc REPRESENT JAVASCRIPT PROGRAMS CLASSIFIED AS TRACKING AND

AGREEMENT,

FUNCTIONAL, RESPECTIVELY, BY THE CLASSIFIER c.

Next, we look at the 81 JavaScript programs correctly
labelled as functional by our classiﬁer, and incorrectly con-
sidered as tracking by the PP-Tools. Table XI in Appendix C
shows 10 JavaScript programs from this sample. The pre-
dominant reason for the PP-Tools mistakenly blocking these
JavaScript programs is because they belong to a tracking
domain, even though the JavaScript itself performs a useful
functionality. A typical example is JavaScript #10 in the
table, which fetches content from the ﬁrst party domain
buzzfeed.com without sending or collecting user informa-
tion.

Lastly, we believe that

the main reason our classiﬁer
misclassiﬁed 25 functional JavaScript programs and 19 track-
ing JavaScript programs is due to their structural similarity
with representatives of the opposite class. For instance, the
JavaScript jquery.cookie.js in the website pnc.com
modiﬁes cookies for
this non-tracking domain. The PP-
Tools rightly allow this JavaScript because pnc.com is
not a tracking domain. But, due to the structural similar-
ity of this JavaScript with JavaScript programs that modify
cookies for tracking domains, our classiﬁer deemed it as
tracking. Similarly, our classiﬁer misclassiﬁed the JavaScript
count.js that gathers comment statistics on the website
listverse.com and sends this information to the domain
disqus.com, which is listed as a tracker by the PP-Tools.
Our classiﬁer misread this due to its similarity with JavaScript
programs that maintain comments on a webpage but do not
send this information through to third party trackers. For
brevity, we do not enlist samples of these two categories of
JavaScript programs misclassiﬁed by our classiﬁer.

VII. DISCUSSION

In the following, we discuss possible uses and limitations

of our approach.

A. Possible Uses

We envision at least two different uses of our technique:

1) Browser Extension: A natural application of our tech-
nique is a client-based browser extension to evade trackers. We
are currently developing a Firefox browser extension which
extracts the JavaScript programs while a webpage is being
loaded (prior to rendering) and calculates the similarities of
the observed JavaScript programs against the training model
which is kept locally. As discussed later in this section, we
aim to periodically update the training model using a semi-
supervised learning technique [43]. We believe that such an
extension is practical, as our current system classiﬁes in the
order of milliseconds per website.

2) Updating Blacklists and Whitelists: Another possible
use of our technique is to improve the accuracy of existing
PP-Tools by updating their ﬁltering lists. These tools could
submit sets of JavaScript programs embedded in webpages
(randomly chosen via a web scanner) to the classiﬁer which
would identify them as functional or tracking. The domains
corresponding to the URLs linking these JavaScript programs
can then be deemed tracking or tracking-free. The newly
identiﬁed URLs can be used to update the PP-tool’s blacklists
(generally locally stored on the user browser) or to reﬁne
whitelists used by some tools such as NoScript. However, it is
important to note that the generated URLs might lead to errors,
potential false positives and negatives, as the same domain may
produce both functional and tracking JavaScript programs, and
thus the decision to mark the domain tracking or tracking-
free lacks the contextual information used by the classiﬁer.
One trivial example is http://static.bbci.co.uk do-
main which can be observed in both functional and tracking
JavaScript programs. Another important caveat
the
blacklist based approach inherently does not ﬁlter in-page
JavaScript programs, and as such the PP-Tools considered in
this paper do not block their execution, with the exception
of NoScript (which, as we have seen, aggressively blocks
execution of JavaScript programs).

is that

B. Limitations and Possible Improvements

1) Classiﬁcation Arms Race - Feature-exploit Case:

In
principle, machine learning based detection is prone to exploits

11

that introduce features absent from the training set [44]. In our
case, the tracker could introduce some unique or rare piece of
tracking code in the JavaScript program. Due to the uniqueness
of the resulting JavaScript program, its feature set is unlikely
to be present in the training model, and is therefore likely
to go undetected. This can particularly be the case with non-
pervasive “hand-crafted” trackers. However, as these pieces of
code become ubiquitous and with periodic re-training of the
classiﬁer, this exploit can be circumvented.

2) Classiﬁcation Arms Race - Code Obfuscation Case: A
tracker might also evade detection by obfuscating a tracking
JavaScript program either by renaming it or by making changes
to its code. In the ﬁrst case, since our approach is based on
code similarity of JavaScript programs, renaming does not
affect the efﬁciency of our classiﬁers (unlike blacklist based
PP-Tools). In the latter case, the attacker might (i) rename
function or variable names, (ii) add or remove whitespaces, (iii)
add zero-impact or dummy code, (iv) or encode the JavaScript
code [45].

the ﬁrst

In the semantic feature models, our classiﬁers are resilient
against
two types of JavaScript code obfuscation
strategies. Appendix D illustrates this via an example. On the
other hand, the attacker might evade detection by applying the
last two types of JavaScript code obfuscation techniques. We
believe that this again presents the classical arms race issue,
in which the trackers pay higher cost in trying to obfuscate
their code to evade detection. Moreover, the obfuscation will
need the additional guarantee of being detection proof as our
machine learning techniques can re-learn newly introduced
tracking JavaScript code (if enough trackers decide to obfus-
cate and the obfuscated JavaScript code still have structural
similarities). It is also important to mention that blacklist based
approaches still persist in spite of the fact that trackers can
change their URLs to evade popular patterns. Note that despite
the availability of obfuscation tools, our classiﬁers achieve
higher efﬁciency and detect trackers missed by contemporary
PP-Tools. We nevertheless regard this as a limitation and
believe it to be an interesting area of future research.

3) The manual labelling challenge: In this work, we used
a relatively small set of labelled tracking and functional
JavaScript programs (2, 612 to be precise). Our choice was
dictated largely by the time consuming nature of the labelling
process. Obviously, the performance of the classiﬁer can be
improved by increasing this number. One approach is to rely
on crowdsourcing and recruit “tech-savvy” users as reviewers
of a JavaScript program. This is not a trivial task as it requires
considerable effort in providing guidelines (i.e., Table I) to the
reviewers, a platform for interaction, and the need to resolve
conﬂicts in labelling due to variable technical expertise of
reviewers.

Alternatively, hybrid schemes such as semi-supervised
learning [43] can be used. The basic idea behind semi-
supervised learning is to use unlabelled data to improve the
training model
that has been previously built using only
labelled data. Semi-supervised learning has previously been
successfully applied to real-time trafﬁc classiﬁcation prob-
lems [46], showing that automated identiﬁcation of re-training
points is possible. Note that our model does not have to be
re-trained as frequently as updating the blacklists of PP-Tools.
Blacklists need to be frequently updated so that PP-Tools can

keep track of new tracker URLs. In our case, re-training is
only required in case new tracking JavaScript programs with
unconventional code structure emerge. This is expected to
occur far less frequently.

VIII. RELATED WORK

In recent years, there has been much research on privacy
implications of web tracking [47], [9], [48], [15], [3], [49],
[50], [17]. For a recent and comprehensive survey on web
tracking techniques and tracking prevention policies, see [12].
Speciﬁc to automated detection of trackers, recently Gugel-
mann et al. [51] analysed HTTP trafﬁc traces and identiﬁed
statistical features of privacy-intrusive advertisements and an-
alytics services. These features were extracted from HTTP
requests sent from users’ browsers to train machine-learning
classiﬁers to detect privacy-intrusive services on the web. Their
proposed scheme augments the blacklist of Adblock Plus by
identifying previously unknown trackers. Our classiﬁcation
approach relies on the code structure of JavaScript programs
instead of analysing HTTP request statistics which can be
hard to gather and can have privacy issues of their own [51].
While our approach can be used as only a client-side (browser)
service, their methodology requires collaboration and gathering
of network traces that includes other services and nodes; a task
difﬁcult to do in a privacy-preserving manner. Lastly, the tool
from [51] can only be used jointly with a blacklist based PP-
Tool such as Adblock Plus. Our approach completely dismisses
blacklists, and hence the need to manually update and maintain
them frequently.

Similarly, Orr et al. [2] proposed a machine learning
approach to detect JavaScript-based advertisements. They iden-
tify 20 key features of advertisement related JavaScript pro-
grams using static code analysis, and use SVM to achieve a
classiﬁcation accuracy of 98%. Our work uses a much broader
class of trackers in addition to advertisements including ana-
lytics, cookie readers/writers and social media widgets. Static
code analysis to identify features from such a broad category of
trackers is not feasible, and hence we use an approach that uses
a dynamic feature space automatically extracted from code
structure of JavaScript programs. Furthermore, Orr et al. do
not compare the performance of their classiﬁer against PP-
Tools that speciﬁcally block advertisement.

Tran et al. [13] use JavaScript tainting to privacy leakage
and to detect one tracking website in addition to the services
listed by Ghostery. In contrast, our framework reveals more
than 4K new sites (i.e., JavaScript programs) showing tracker-
like behavior, and based on a representative sample we es-
timate that 75% indeed offer traditional advertisement and
analytics services.

Our use of n-grams from program dependency graphs
of JavaScript programs is adopted from the work of Hsiao,
Cafarella and Narayanasamy [33], who demonstrated this tech-
nique to detect plagiarism in JavaScript code. However, they
directly use tf-idf scores of JavaScript programs to measure
their similarities instead of using a machine learning approach.
By comparison, the focus of our work is binary classiﬁcation of
functional and tracking JavaScript programs, and we use one-
class machine learning algorithms on top of features extracted
from tf-idf scores of n-grams.

12

IX. CONCLUDING REMARKS

This paper presented a new automated mechanism to
ﬁlter tracking JavaScript programs from functional JavaScript
programs both embedded and externally linked within the
DOM trees of webpages. We ﬁrst study the (in)effectiveness
of popular privacy-preserving tools with respect to balancing
blocking of tracking JavaScript programs and allowing func-
tional JavaScript programs. We then postulate and verify that
one-class machine learning techniques that utilize similarities
between tracking JavaScript programs based on syntactic and
semantic features can effectively improve user’s web experi-
ence. One key aspect of our work is the ability of our classiﬁers
to discover previously unseen tracking JavaScript programs.
We stress that our methodology is generic and can be adapted
to more conservative choices of what are considered functional
JavaScript programs (e.g., JavaScript programs related to social
media). Our current labelling is strict on what is considered
tracking. Our classiﬁers can easily be tuned by simply adding
or removing few instances of JavaScript programs from the
tracking set used in training.

REFERENCES

[1] C. Yue and H. Wang, “Characterizing insecure javascript practices on

the web,” ser. WWW 2009.

[2] C. R. Orr, A. Chauhan, M. Gupta, C. J. Frisz, and C. W. Dunn, “An
approach for identifying javascript-loaded advertisements through static
program analysis,” in WPES, 2012.

[3] G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, and
C. Diaz, “The web never forgets: Persistent tracking mechanisms in
the wild,” in Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, ser. CCS ’14. New York,
NY, USA: ACM.
“NoScript,” https://www.noscript.net.
“Ghostery,” https://www.ghostery.com.
“Adblock Plus,” https://www.adblockplus.org.

[4]
[5]
[6]
[7] L. Olejnik, C. Castelluccia, and A. Janc, “Why Johnny Can’t Browse
in Peace: On the Uniqueness of Web Browsing History Patterns,” in
HotPETs, 2012.
in Ghostery - 381 Topics Found for Break-
“Search Results
ing,” https://getsatisfaction.com/ghostery/searches?query=breaking&x=
15&y=10&style=topics.

[8]

[9] B. Krishnamurthy, K. Naryshkin, and C. Wills, “Privacy leakage vs.

protection measures: the growing disconnect,” in W2SP, 2011.

[10] F. Roesner, T. Kohno, and D. Wetherall, “Detecting and Defending

Against Third-party Tracking on the Web,” in NSDI, 2012.

[11] T.-F. Yen, Y. Xie, F. Yu, R. P. Yu, and M. Abadi, “Host ﬁngerprinting
and tracking on the web: Privacy and security implications.” in NDSS,
2012.
J. R. Mayer and J. C. Mitchell, “Third-party web tracking: Policy and
technology,” in IEEE S&P, 2012.

[12]

[13] M. Tran, X. Dong, Z. Liang, and X. Jiang, “Tracking the trackers: Fast
and scalable dynamic analysis of web content for privacy violations,”
ser. ACNS, 2012.

[14] M. M. Hassan Metwalley, Stefano Traverso, “The online tracking horde:

a view from passive measurements,” in TMA, 2015.

[15] M. Tran, X. Dong, Z. Liang, and X. Jiang, “Tracking the trackers: Fast
and scalable dynamic analysis of web content for privacy violations,”
in ACNS, 2012.

[16] D. Jang, R. Jhala, S. Lerner, and H. Shacham, “An empirical study of
privacy-violating information ﬂows in javascript web applications,” in
CCS, 2010.

[17] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel, F. Piessens, and
G. Vigna, “Cookieless monster: Exploring the ecosystem of web-based
device ﬁngerprinting,” in IEEE S&P, 2013.

13

[18]
[19]
[20]

https://github.com/EFForg/

“Easylist,” https://easylist-downloads.adblockplus.org/easylist.txt.
“Disconnect,” https://www.disconnect.me/.
“Privacy Badger Cookies Blocklist,”
privacybadgerﬁrefox/blob/master/data/cookieblocklist.txt.
“EFF DNT Policy,” https://www.eff.org/dnt-policy.
[21]
“Selenium Webdriver,” http://www.seleniumhq.org/.
[22]
“JavaScript (js) beautiﬁer,” https://github.com/beautify-web/js-beautify.
[23]
[24] A. Chaabane, M. A. Kaafar, and R. Boreli, “Big Friend is Watching You:
Analyzing Online Social Networks Tracking Capabilities,” in WOSN,
2012.
“Moat,” http://www.moat.com/.
“Disqus,” http://www.disqus.com/.
“Surrogate JavaScript Code,” https://news.ycombinator.com/item?id=
5182359.
“NoScript’s Surrogates JavaScript Code,” https://hackademix.net/2011/
09/29/script-surrogates-quick-reference/.
“Fanboylist,” https://easylist-downloads.adblockplus.org/fanboy-social.
txt.
“PageFair: Why aren’t PageFair Ads blocked?” https://pagefair.com/
about/.
“Google analytics,” https://www.google.com/analytics/.
“Visual revenue,” http://www.visualrevenue.com.

[31]
[32]
[33] C.-H. Hsiao, M. Cafarella, and S. Narayanasamy, “Using web corpus

statistics for program analysis,” in OOPSLA, 2014.

[25]
[26]
[27]

[28]

[29]

[30]

[34] S. S. Muchnick, Advanced Compiler Design and Implementation. MK

Publishers Inc., 1997.

[35] B. Sch¨olkopf, J. C. Platt, J. C. Shawe-Taylor, A. J. Smola, and R. C.
Williamson, “Estimating the support of a high-dimensional distribu-
tion,” NC, 2001.

[36] C. Elkan and K. Noto, “Learning classiﬁers from only positive and

unlabeled data,” in KDD, 2008.

[37] B. Liu, Y. Dai, X. Li, W. S. Lee, and P. S. Yu, “Building text classiﬁers

using positive and unlabeled examples,” in ICDM, 2003.

[38] K. Rieck, T. Krueger, and A. Dewald, “Cujo: Efﬁcient detection and

prevention of drive-by-download attacks,” in ACSAC, 2010.

[39] K. R. Muller, S. Mika, G. Ratsch, K. Tsuda, and B. Scholkopf, “An

introduction to kernel-based learning algorithms,” ToNN, 2001.

[40] P. F. et al., “Scikit-learn: Machine learning in Python,” MLR, 2011.
[41] C.-C. Chang and C.-J. Lin, “Libsvm: A library for support vector

machines,” ACM ToIST, 2011.

[42] N. Nikiforakis, L. Invernizzi, A. Kapravelos, S. Van Acker, W. Joosen,
C. Kruegel, F. Piessens, and G. Vigna, “You are what you include:
Large-scale evaluation of remote javascript inclusions,” in CCS, 2012.
[43] S. Basu, M. Bilenko, and R. J. Mooney, “A probabilistic framework for

semi-supervised clustering,” in KDD, 2004.

[44] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert, “Zozzle: Fast and
precise in-browser javascript malware detection,” in Proceedings of the
20th USENIX Conference on Security, ser. SEC, 2011.

[45] W. Xu, F. Zhang, and S. Zhu, “The power of obfuscation techniques
in malicious javascript code: A measurement study,” ser. MALWARE,
2012.
J. Erman, A. Mahanti, M. Arlitt, I. Cohen, and C. Williamson,
“Ofﬂine/realtime trafﬁc classiﬁcation using semi-supervised learning,”
Perform. Eval., 2007.

[46]

[47] P. Gill, V. Erramilli, A. Chaintreau, B. Krishnamurthy, K. Papagiannaki,
and P. Rodriguez, “Follow the money: Understanding economics of
online aggregation and advertising,” in IMC, 2013.

[48] B. Krishnamurthy, D. Malandrino, and C. E. Wills, “Measuring privacy
loss and the impact of privacy protection in web browsing,” in SOUPS,
2007.

[49] D. Jang, R. Jhala, S. Lerner, and H. Shacham, “An empirical study of
privacy-violating information ﬂows in javascript web applications,” in
CCS, 2010.

[50] B. Krishnamurthy, “I know what you will do next summer,” SIGCOMM

CCR, 2010.

[51] D. Gugelmann, B. Ager, and V. Lenders, “An automated approach for

complementing ad blockers’ blacklists,” in PETs, 2015.

A. PP-Tools Settings

APPENDIX

We used the following PP-Tools settings in our experiments

to collect the dataset discussed in Section III-B.

PP-Tool
NS (v2.6.9.11)

Filtering Method
Block all JS

GT (v5.4.1)

Blacklist

AP (v2.6.7)

Blacklist

DC (v3.14.0)
PB (v0.1.4)

Blacklist
Heuristics and
cookies blacklist

Setting
Default blocking mode with iframes block-
ing option on
Enabled ‘Blocking all tracker and cookies’
option
EasyList and Fanboy’s list and disabled ‘Al-
low non-intrusive ads’ option
Default
Default

TABLE IX.

PP-TOOLS’ SETTINGS USED WITH FIREFOX V32.0

B. Canonicalization of JavaScript programs

The canonical form is an intermediate representation of the
JavaScript program where variable names and loop speciﬁcs
are abstracted away in an effort to apply natural language
processing-like techniques on the resulting code representation.
To explain the canonical form and PDG of a JavaScript
program, consider the following (toy) ‘equalTest’ Javascript
function:

Listing 1.

AN EXAMPLE OF JAVASCRIPT PROGRAM

function equalTest(a, b){

if(a == b){

return true;}

return false;}

The canonical form of this routine is:

Listing 2.

CANONICAL FORM OF JAVASCRIPT CODE IN LISTING # 3

begin;
$0 = a === b;
if($0){

function equalTest(a, b){
1:
2:
3:
4:
5:
6:

return true;}

return false;
end;}

One line of the canonical form consists of a binary opera-
tion, its operands or an assignment. The PDG of this routine
is shown in Figure 4a. The 2 and 3-grams of line 3 above
is shown in Figure 4b. For a more detailed example of these
concepts, see [33].

C. Analyzing Disagreement : Examples

Examples where there is disagreement between our clas-
siﬁer and PP-Tools are shown in Table X and Table XI.
In essence, we show examples of JavaScript codes that are
classiﬁed as tracking JavaScript codes (resp. functional) while
classiﬁed as functional (resp. tracking) by the ensemble of PP-
Tools. We discuss these details in Section VI-C. For reference,
the ratio of agreement and disagreement between our classiﬁer
and PP-Tools on the wild dataset is also illustrated in Figure 5.

14

(a)

(b)

(a) Program dependency graph of the equalTest canonical form.
Fig. 4.
(b) 2-gram (top) and 3-gram (bottom) of line 3 of the program dependency
graph.

D. JavaScript Code Obfuscation

Criteo5 sets its tracking cookies at dailymotion.com
with the JavaScript code shown in Listing 3. By using an
online obfuscation tool,6 the obfuscated version of this code
is shown in Listing 4, with variable names replaced and white
spaces removed, i.e., type (i) and (ii) obfuscation mentioned in
Section VII-B2. The canonical form of both the original code
and the obfuscated code is the same, as shown in Listing 5,
meaning that our semantic feature models based classiﬁers will
still detect the obfuscated trackers.

Listing 3.

AN EXAMPLE OF JAVASCRIPT PROGRAM

var crtg_nid="1822";
var crtg_cookiename="co_au";
var crtg_varname="crtg_content";
function crtg_getCookie(c_name){

var i,x,y,ARRCookies=document.cookie.split(";");
for(i=0;i<ARRCookies.length;i++){
x=ARRCookies[i].substr(0,ARRCookies[i]

.indexOf("="));

y=ARRCookies[i].substr(ARRCookies[i]

.indexOf("=")+1);

x=x.replace(/ˆ\s+|\s+$/g,"");
if(x==c_name){

return unescape(y);
}}

return "";

}

Listing 4.

TYPE (i) AND (ii) OBFUSCATION.

var a="1822";var b="co_au";var c="crtg_
content";function crtg_getCookie(e){var i,x,y,
d=document.cookie.split(";");while(i<d.length)
{x=d[i].substr(0,d[i].indexOf("="));y=d[i].sub
str(d[i].indexOf("=")+1);x=x.replace(/ˆ\s+|\s+
$/g,"");if(x==e){return unescape(y)}i++}
return""}

Listing 5.
function crtg_getCookie =

CANONCIAL FORM OF ORIGINAL AND OBFUSCATED CODE.

function crtg_getCookie(e)

{begin;$0 = document.cookie;

d = $0.split(";");

5http://www.criteo.com
6http://www.danstools.com/javascript-obfuscate/

begin===ifreturnendreturn123465===if23begin===if123(a) Syntactic OCSVM.

(b) Sequential 7-gram OCSVM.

(c) Syntactic PU.

(d) Sequential 7-gram PU.

Fig. 5. Agreement ( & ) and disagreement ( & ) in classiﬁcation of tracking and functional JavaScript programs between our classiﬁers and PP-Tools
on the wild dataset. Tp and Fp represent JavaScript programs classiﬁed as tracking and functional, respectively, by the PP-Tool p, and Tc and Fc represent
JavaScript programs classiﬁed as tracking and functional, respectively, by the classiﬁer c; NS, GT, AP, PB, and DC stand for NoScript, Ghostery, Adblock Plus,
Privacy Badger, and Disconnect, respectively.

$1 = d.length; $2 = i < $1;
while ($2) {

$3 = d[i];$4 = d[i];
$5 = $4.indexOf("=");
x = $3.substr(0, $5);
$6 = d[i];$7 = d[i];
$8 = $7.indexOf("=");
$9 = $8 + 1;
y = $6.substr($9);
x = x.replace(RegExp("ˆ\s+|\s+$","g"), "");
$10 = x == e;
if ($10) {

$11 = unescape(y);
return $11;}

$12 = i; i = i + 1;
$13 = d.length;
$2 = i < $13;}

return "";
end;};
$14 = %InitializeVarGlobal("a", 0, "1822");
$15 = %InitializeVarGlobal("b", 0, "co_au");
$16 = %InitializeVarGlobal("c", 0,

"crtg_content");

end;

E. Surrogate JavaScript Programs

While using PP-Tools, certain content might not be work-
ing properly [8]. This is known as broken web-pages. This
happens when certain web-components are blocked on a
website which might be necessary for smooth browsing. In
order to tackle broken pages, exceptions and errors, PP-Tools
often inject snippets of non-tracking JavaScript programs, also
called surrogate scripts, when they block content from loading.
Through manual inspection, we observed that both Ghostery
and NoScript inject surrogate scripts. We investigated Ghostery
and NoScript source codes to derive a comprehensive list of
surrogates.

Interestingly, however, we noticed that using its ‘block
all trackers’ setting, certain Ghostery surrogate scripts do not
necessarily facilitate smooth browsing. Instead,
they block
useful content. For instance, Figure 6 shows an example where
Ghostery injects a surrogate script for the brightcove
widget. The resulting surrogate script blocks the video content
on the webpage, which is arguably a useful functionality.

F. JavaScript Program Similarity

In this section, we present examples of JavaScript programs
in the wild dataset that are labelled as tracking by our classiﬁer.

15

(a)

(b)

Fig. 6.
Ghostery’s ﬁlters (a) video content by blocking brightcove
widget on www.9news.com.au. Once unblocked, brightcove loads (b)
video content on the web-page.

Our aim is to show how our classiﬁer trained on the labelled
dataset was successful in ﬁnding tracking JavaScript codes that
were absent from the training set. The JavaScript programs
in listing 8 and listing 9 from the test set were marked as
tracking by our classiﬁer. These two were not present in the
training set. Two JavaScript programs that were present in the
training data are shown in listing 6 and listing 7. We ﬁnd that
these two have normalized cosine similarity values of 0.89
and 0.73 with JavaScript programs in listing 8 and listing 9,
respectively. On the other hand the JavaScript programs in
listing 8 and listing 9 had cosine similarities of ≤ 0.17 and ≤
0.21, respectively, with all functional JavaScripts (cf. § V-A).
This suggests that these JavaScript programs are distinct from
functional JavaScript programs while being similar to tracking
JavaScript programs, the key idea exploited in our approach.

Listing 6.
CLICKTALE-BEHAVIOURAL TRACKER JAVASCRIPT CODE
SNIPPET ON CNN.COM. IT WRITES AND READS COOKIE TO TRACK USER

ON CNN.COM.

createCookie: function (name,value,days)
{

if (days)
{

var date = new Date();
date.setTime(date.getTime( )+( days*24*60*
60*1000));
var expires = "; expires="+date.toGMTString( );

}

else var expires = "";

document.cookie = name+"="+value+expires+";
path=/";

},
readCookie : function (name)
{

var nameEQ = name + "=";
var ca = document.cookie.split( ’;’);
for( var i=0;i < ca.length;i++) {
var c = ca[i];

NSGTAPPBDC0.00.20.40.60.81.0Tc∩TpFc∩FpTc∩FpFc∩Tp030K60K90K120K135KNSGTAPPBDC0.00.20.40.60.81.0Tc∩TpFc∩FpTc∩FpFc∩Tp030K60K90K120K135KNSGTAPPBDC0.00.20.40.60.81.0Tc∩TpFc∩FpTc∩FpFc∩Tp030K60K90K120K135KNSGTAPPBDC0.00.20.40.60.81.0Tc∩TpFc∩FpTc∩FpFc∩Tp030K60K90K120K135Kwhile ( c.charAt( 0)==’ ’) c = c.substring( 1,
c.length);
if ( c.indexOf( nameEQ) == 0)
return c.substring( nameEQ.length,c.length);

(’script’)[0];
fscr.parentNode.insertBefore(mt, fscr);

})();

In the future, we aim to characterize and study JavaScript
code obfuscation techniques employed by trackers. In essence,
we aim to investigate JavaScript’s dynamic code genera-
tion and run-time evaluation functions, e.g., eval() and
document.write(). We believe that the investigation of
the arguments supplied to these functions can be leveraged in
the re-training of our classiﬁers and in the detection of possible
obfuscated tracking and malicious JavaScript programs.

}

return null;
}

}

Listing 7.

COOKIE SETTING JAVASCRIPT CODE ON BBC.COM. THE

CODE SNIPPET SETS GOOGLE ANALYTIC COOKIES TO TRACK ON BBC.COM.

var _gaq = _gaq || [];
_gaq.push([’_setAccount’, ’UA-1627489-1’]);
_gaq.push([’_setDomainName’, ’bbc.com’]);
_gaq.push([’_trackPageview’]);
(function ()
{
var ga = document.createElement(’script’);
ga.type = ’text/javascript’;
ga.async
ga.src = (’https:’ == document.location.protocol

= true;

? ’https://ssl’ : ’http://www’) +
’.google-analytics.com/ga.js’;

var s = document.getElementsByTagName
(’script’)[0];
s.parentNode.insertBefore(ga, s);

})();

Listing 8.
THE CODE EXCERPT FROM BROWSER-DETECTION.JS ON
GEO.TV. THE CODE WRITES AND READS COOKIES AND FINGER-PRINTS

USER’S BROWSER ON GEO.TV.

writeCookie: function(name, value, days){
var expiration = "";
if(parseInt(days) > 0)
{

var date = new Date();
date.setTime(date.getTime() + parseInt(days)
* 24 * 60 * 60 * 1000);
expiration = ’; expires=’ + date.toGMTString();

}

document.cookie = name + ’=’ + value +
expiration + ’; path=/’;

},
readCookie: function(name){

if(!document.cookie){ return ’’; }
var searchName = name + ’=’;
var data = document.cookie.split(’;’);
for(var i = 0; i < data.length; i++){
while(data[i].charAt(0) == ’ ’){
data[i] = data[i].substring(1,
data[i].length);

}
if(data[i].indexOf(searchName) == 0){

return data[i].substring(searchName.length,
data[i].length);

}

return ’’;

}

}

Listing 9.
COOKIE SETTING JAVASCRIPT CODE ON DAILYMOTION.COM.
THE CODE SETS MARIN SOFTWARE’S (MARINSOFTWARE.COM) TRACKING

AND ADVERTISEMENT COOKIE ON DAILYMOTION.COM.

var _mTrack = _mTrack || [];
_mTrack.push([’trackPage’]);
(function() {

var mClientId = ’f52zgtujz0’;
var mProto = (’https:’ == document.location
.protocol ? ’https://’ : ’http://’);
var mHost = ’tracker.marinsm.com’;
var mt = document.createElement(’script’);
mt.type = ’text/javascript’;
mt.async = true; mt.src = mProto + mHost +
’/tracker/async/’ + mClientId + ’.js’;
var fscr = document.getElementsByTagName

16

# Website

JavaScript Program

Referred Domain

Function Performed

cdn2-b.examiner.com/.../ex omniture/s code.js
static.bbci.co.uk/bbcdotcom/.../adverts.js
telegraph.co.uk/template/ver1-0/js/gpt.js
s.i-vengo.com/js/ivengo.min.js

examiner.com
1
bbc.com
2
telegraph.co.uk
3
vesti.ru
4
climatempo.com.br http://s1.trrsf.com/metrics/inc/br/201411250000d.js
5
amc.com
6
lancer.com
7
iqiyi.com
8
9
babyblog.ru
10 autoscout.de
TABLE X.

amc.com/wp-content/plugins/amcn-common-analytics/js/common-analytics.js
static.lancers.jp/js/ga social tracking.js
static.iqiyi.com/js/pingback/qa.js
act.babyblog.ru/static844/likes.js
s.autoscout24.net/uniﬁedtracking/gtm.js

Social widgets
Tracks user activities
TEN JAVASCRIPT PROGRAMS OUR CLASSIFIER CORRECTLY CLASSIFIED AS TRACKING AND ALL THE PP-TOOLS WRONGLY CLASSIFIED AS

FUNCTIONAL VERIFIED THROUGH MANUAL LABELLING.

Analytics
omniture.com
Analytics + Ads
pubads.g.doubleclick.net
Analytics + Ads
pubads.g.doubleclick.net
Analytics + Ads
www.i-vengo.com
Analytics
scorecardresearch.com
Track user activities
omniture.com
google.com
Tracker user activities
pps.tv, baidu.com, 71.com Tracker user activities
babyblog.ru
autoscout.de

# Website

JavaScript Program

Referred Domain

Function Performed

ing.nl

crateandbarrel.com
suomi24.ﬁ
nhl.com

1
2
3
4 michael.com
5
6 worldoftanks.ru
7
8
9
10 buzzfeed.com
TABLE XI.

divyabhaskar.co.in
15min.lt
abovetopsecret.com

j.c-b.co/js/account 1505080410.js
kiwi27.leiki.com/focus/mwidget.js
b3.mookie1.com/2/LB/3115965742.js
edgesuite.net/js/pictureﬁll.min.js
ensighten.com/ing/NL-ingnl-prod/code/fc 90aaa8fc7.js
mc.wargaming.net/tsweb.js
nr.taboola.com/newsroom/bhaskar-divyabhaskar/getaction.js
15minadlt.hit.gemius.pl/ 1431091788674/redot.js
casalemedia.com/j.js
ct-ak.buzzfeed.com/wd/UserWidget.js

Creates user accounts
Magnifying widget

crateandbarrel.com
leiki.com
cdn-akamai.mookie1.com Fetches content
Fetches content
-
Fetches content
ing.nl
Sets session cookie
wargaming.net
Enables user interaction
taboola.com
Timestamps user login
squarespace.com
abovetorespect.com
Fetches content
Fetches content
s3.amazonaws.com

TEN JAVASCRIPT PROGRAMS OUR CLASSIFIER CORRECTLY CLASSIFIED AS FUNCTIONAL AND ALL THE PP-TOOLS INCORRECTLY

CLASSIFIED AS TRACKING VERIFIED THROUGH MANUAL LABELLING.

17

