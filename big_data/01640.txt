6
1
0
2

 
r
a

M
4

 

 
 
]
n
a
-
a
t
a
d

.
s
c
i
s
y
h
p
[
 
 

1
v
0
4
6
1
0

.

3
0
6
1
:
v
i
X
r
a

REVERSIBLE MARKOV CHAIN ESTIMATION USING

CONVEX-CONCAVE PROGRAMMING

BENJAMIN TRENDELKAMP-SCHROER † ‡, HAO WU † §, AND FRANK NOE † ¶

Abstract. We present a convex-concave reformulation of the reversible Markov chain estimation
problem and outline an eﬃcient numerical scheme for the solution of the resulting problem based on
a primal-dual interior point method for monotone variational inequalities. Extensions to situations
in which information about the stationary vector is available can also be solved via the convex-
concave reformulation. The method can be generalized and applied to the discrete transition matrix
reweighting analysis method to perform inference from independent chains with speciﬁed couplings
between the stationary probabilities. The proposed approach oﬀers a signiﬁcant speed-up compared
to a ﬁxed-point iteration for a number of relevant applications.

Key words. Markov chain estimation, Reversible Markov chain, Convex-concave program

AMS subject classiﬁcations. 62M05, 65K15, 62F30, 62P10

1. Introduction. The study of reversible Markov chains is a recurrent theme
in probability theory with many important applications, [1, 13, 20]. Surprisingly, sta-
tistical inference for reversible Markov chains has been studied only recently. The
reversible maximum likelihood estimation (MLE) problem was previously discussed
in [3, 18, 22]. [2, 9, 14, 16, 22] study the the posterior ensemble of reversible stochas-
tic matrices and discuss algorithms for Bayesian posterior inference. For a given
stochastic matrix the best approximation which is reversible with respect to a given
stationary vector was found in [15].

Maximum likelihood estimation and posterior inference of reversible stochas-
tic matrices have important applications in the context of Markov state models
[4]. Markov state models are simpliﬁed kinetic models for the complex dynamics
of biomolecules. Transition probabilities between relevant molecular conformations
are estimated from simulation data. The estimated transition matrix is then used
to compute quantities of interest and to extract a simpliﬁed picture of the kinetic
pathways present in the dynamics. In [21] it is shown that a signiﬁcant speed-up in
the estimation of rare events is possible if additional information about the stationary
vector is incorporated via a detailed balance constraint.

The reversible MLE problem was previously solved using a self consistent iteration
method which can require a large number of iterations to converge [3, 18, 22]. Here
we outline an eﬃcient numerical algorithm for solving the reversible MLE problem
via a convex-concave reformulation of the problem based on a duality argument from
[23]. Convex-concave programs cannot be solved by standard nonlinear programming
approaches which aim to minimize some objective subject to constrains. They can be
treated as ﬁnite dimensional monotone variational inequalities and they can be solved
using the primal-dual interior-point outlined in [19].

The reversible MLE problem is a nonlinear programming problem with a convex
objective and non-convex constraints. The number of unknowns in the problem is
quadratic in the number of states of the chain. The dual problem has only linear
constraints and the number of unknowns grows linearly with the number of states of

†Institut f¨ur Mathematik und Informatik, Freie Universit¨at Berlin, Arnimallee 6, 14195 Berlin
‡B. T.-S. was supported by Deutsche Forschungsgemeinschaft (DFG) Grant No. SFB 740
§H. W. was supported by DFG Grant No. SFB 1114
¶F. N. was supported by European Research Council (ERC) starting grant pcCell

1

the chain. The reformulation can also be applied in order to solve a number of related
MLE problems arising if additional information about the chain is available a priori.
A broader class of interesting MLE problems for reversible Markov chains can thus
be solved.

In [23, 24] the reversible MLE problem has been extended to the discrete tran-
sition matrix reweighting analysis method (dTRAM). For dTRAM, simulation data
at multiple biasing conditions, also called thermodynamic states, is collected in order
to eﬃciently estimate the stationary vector at the unbiased condition. A positive
reweighting transformation relates each stationary vector at a biased condition to the
stationary vector at the unbiased condition. This coupling between unbiased and bi-
ased condition makes it possible to combine the information from all ensembles into
the desired estimate for the unbiased situation.

The dTRAM problem was previously solved through an application of a self con-
sistent iteration procedure to the dual reformulation [23]. This approach can require
a large number of iterations to converge. We show that the convex-concave refor-
mulation of the reversible MLE problem can be extended to also cover the dTRAM
problem. The resulting convex-concave program can be solved using the algorithm
outlined in [19]. The large linear systems arising during the computation of the search
direction can be eﬃciently solved using a Schur complement approach similar to the
one outlined in [11, 25]. The resulting algorithm achieves a signiﬁcant speed-up com-
pared to the self consistent iteration.

2. Markov chain estimation. A Markov chain on a ﬁnite state space is com-
pletely characterized by a square matrix of conditional probabilities, P = (pij ) ∈
Rn×n. The entry pij is the probability for the chain to make a transition to state j

given that it currently resides in state i. The matrix P is stochastic, i.e. Pj pij = 1

If P is irreducible then there exists a unique vector, π = (πi) ∈ Rn, of
for all i.
positive probabilities such that π is invariant under the action of P , πT P = πT . The
vector π is called the stationary vector of the chain.

If there is a vector, π, of probabilities for which P fulﬁlls the following detailed

balance condition,

(2.1)

πipij = πjpji

then the chain is a reversible Markov chain with stationary vector π, [12].

In Markov chain estimation one is interested in ﬁnding an optimal transition ma-
trix estimate P from a given ﬁnite observation X = {X0, X1, . . . , XN } of a Markov
chain with unknown transition matrix. The matrix of transition counts C = (cij) to-
gether with the initial state X0 = x0 is a minimal suﬃcient statistics for the transition
matrix [8]. The element cij denotes the observed number of transitions between state
i and state j in X. The matrix P is optimal if it maximizes the following log-likelihood

(2.2)

L(C|P ) =Xi,j

cij log pij.

For ﬁnite ensembles consisting of ﬁnite length observations one can simply add the
matrices of transition counts for each observation. The accumulated counts together
with the empirical measure of the initial states is then a suﬃcient statistics for the
ﬁnite ensemble of observations.

For reversible Markov chain estimation one constrains the general Markov chain
MLE problem to the set of all stochastic matrices for which detailed balance with

2

respect to some vector of probabilities holds. Thus we can ﬁnd the reversible MLE
transition matrix from the following nonlinear program,

min
π,P

(2.3)

cij log pij

−Xi,j

subject to pij ≥ 0, Xj

pij = 1, πi > 0, Xi

πi = 1, πipij = πjpji.

In [23, 24] problem (2.3) has been extended to the discrete transition matrix
reweighting analysis method (dTRAM). For dTRAM, simulation data at multiple
thermodynamic states α = 0, . . . , M is collected in order to eﬃciently estimate the
stationary vector at the unbiased condition, α = 0. A positive reweighting transfor-
mation relates the stationary vector at the biased condition, α > 0, to the stationary
vector at the unbiased condition,

(2.4)

i = U (α)
π(α)

i π(0)

i = exp(u(α)

i

)π(0)

i

.

This coupling allows us to combine the information from all ensembles into the esti-
mate for π(0).

The dTRAM problem consists of reversible MLE problems for each thermody-
namic state coupled via the reweighting transformation (2.4). The desired stationary
vector can be obtained as the optimal point of the following nonlinear program,

min

π(α),P (α)

(2.5)

subject to p(α)

log p(α)
ij

c(α)
ij

−Xα Xi,j
ij ≥ 0, Xj

ij = 1, π(α)
p(α)

π(α)
i = 1,

i > 0, Xi

i p(α)
π(α)

ij = π(α)

j p(α)

ji , π(α)

i = U (α)

i π(0)

i

.

We show that the convex-concave reformulation of the reversible MLE prob-
lem can be extended to derive an eﬃcient numerical algorithm for the solution of
the dTRAM problem. Additional structure in the linear systems arising during the
primal-dual iteration can be used so that the problem can be solved eﬃciently for
many coupled chains.

3. Dual of the reversible MLE problem. In [23] a duality argument was
used to show that ﬁnding the MLE of (2.3) for given positive weights πi is equivalent
to the following concave maximization problem,

max

x

(3.1)

Xi,j

cij log(πixj + πjxi) −Xi,j

cij log πj −Xi

xi

subject to xi ≥ 0.

The xi correspond to the Lagrange multipliers for the row normalization constraint
in the primal problem (2.3). The optimal transition probabilities can be recovered
according to

(3.2)

p∗
ij =

(cij + cji)πj
j + πj x∗
πix∗
i

,

j 6= i.

The vector x∗ denotes the optimal point of (3.1) and the diagonal entries p∗
mined by the row normalization condition. It is clear that p∗

ii are deter-
ij is a proper probability

3

irrespective of the normalization of the weights since any scaling of πi cancels out in
(3.2).

In [23] the inequality constraints on xi were not made explicit. The non-negativity

requirement can be seen from the following splitting of the Lagrangian Lπ in [23],

(3.3)

Lπ(P, λ, ν) = − Xi,j∈I
+ Xi,j /∈I

cij log pij + Xi,j∈I
(πi(λij − λji) + xi)pij −Xi

xi

(πi(λij − λji) + xi)pij

with index set I = {(i, j)|cij > 0} and the constraint pij ≥ 0. The value minx Lπ is
not bounded from below if πi(λij − λji) + xi < 0 for some (i, j) /∈ I. Therefore xi ≥ 0
for all (i, i) /∈ I. It is also not bounded from below if πi(λij − λji) + xi ≤ 0 for some
(i, j) ∈ I, so that xi > 0 for all (i, i) ∈ I,

Using the dual function from [23] the reformulation of the reversible MLE prob-

lem, (2.3), as a saddle-point problem with constraints is

(3.4)

min

π

max

x Xi,j

cij log(πixj + πjxi) −Xi,j

cij log πj −Xi

xi

subject to xi ≥ 0, πi > 0, Xi

πi = 1.

is concave in x but non-convex in π. The problem can however be easily cast into a
convex-concave form by the following change of variables,

(3.5)

πi ∝ eyi,

and by replacing the normalization condition with the simpler constraint

(3.6)

y1 = 0.

The constraint in (3.6) removes the invariance of the objective in (3) with respect
to a constant shift of y. Proper stationary probabilities πi can be obtained from the
new variables yi according to (3.5) followed by straightforward normalization. The
variable yi is the negative free energy of the state i.

The ﬁnal form of the dual reversible MLE problem is

max

y

min

x

(3.7)

−Xi,j

cij log (xieyj + xj eyi) +Xi

xi +Xi,j

cij yj

subject to xi ≥ 0, y1 = 0.

The objective in (3.7) is convex in x and concave in y. The feasible set is convex so
that (3.7) is a convex-concave program.

For a given state space with n states the original reversible MLE problem (2.3),
a non-convex constrained minimization problem in O(n2) unknowns, is reduced to a
convex-concave programming problem in O(n) unknowns with simple constraints.

3.1. Scaling. We observe that the number of iterations needed for the solution
of (3.7) using the algorithm from [19] can be drastically reduced by scaling the count-
matrix by a constant factor γ chosen as

(3.8)

γ =(cid:18)max

i,j

4

cij(cid:19)−1

.

With scaled entries ˜cij = γcij and scaled variables ˜x = γx, ˜y = y we have

(3.9)

˜f0(˜x, ˜y) = γf0(x, y) + const.

The constraints in (3.7) are invariant under the scaling so that the optimal point

for (3.7) can be obtained from the optimal solution to the scaled problem.

The resulting stationary probabilities as well as the transition probabilities are

invariant under the scaling,

(3.10)

˜pij =

(˜cij + ˜cji)e˜yj
˜xie˜yj + ˜xj e˜yi

=

(cij + cji)eyj
xieyj + xj eyi

= pij.

3.2. Special cases and extensions. The reversible estimation problem with

ﬁxed stationary vector π

min

P

(3.11)

cij log pij

−Xi,j

subject to pij ≥ 0, Xj

pij = 1, πipij = πjpji

is a convex problem and can eﬃciently be solved in its dual formulation (3.1) using
an interior-point method for convex programming problems.

The reversible estimation problem with partial information about the stationary

vector

(3.12)

min
π,P

cij log pij

−Xi,j

subject to pij ≥ 0, Xj

pij = 1, πi > 0, Xi

πipij = πjpji, πi = νi i ∈ I,

πi = 1,

with I ( {1, . . . , n} and given positive weights (νi)i∈I can be solved via its dual

max

y

min

x

(3.13)

−Xi,j

cij log (xieyj + xj eyi) +Xi

xi +Xi,j

cij yj

subject to xi ≥ 0, yi = log νi i ∈ I.

The reversible estimation problem with bound-constrained information about the

stationary vector

min
π,P

(3.14)

cij log pij

−Xi,j

subject to pij ≥ 0, Xj

pij = 1, πi > 0, Xi

πipij = πjpji, ηi ≤ πi ≤ ξi i ∈ I.

πi = 1,

with I ⊆ {1, . . . , n} and given positive bounds (ηi)i∈I , (ξi)i∈I can be solved via the
dual

max

y

min

x

(3.15)

−Xi,j

cij log (xieyj + xj eyi) +Xi

log ηi ≤ yi ≤ log ξi i ∈ I.

xi +Xi,j

cij yj

subject to xi ≥ 0,

5

The two problems (3.13), (3.15) are convex-concave programming problems. Non-
linear, convex inequality and linear equality constraints possibly coupling x and y can
also be treated within the algorithmic framework of [19]. A special case with possible
interest for applications are bound constraints on the integrated stationary weights
on subsets S ⊆ {1, . . . , n},

(3.16)

πi ≤ ν.

Xi∈S

Equation (3.16) can be expressed in terms of variables yi as

(3.17)

eyi ≤ log νk,

logXi∈S

The logarithm of a sum of exponentials is a convex function, [5].

3.3. dTRAM. We can apply the duality argument to each thermodynamic state
in (2.5) and introduce the coupling between diﬀerent ensembles, (2.4), through linear
equality constraints. The resulting convex-concave programming problem is

(3.18)

max
y(α)

min
x(α)

subject to

−Xα Xi,j

cij log(cid:16)x(α)

i ey(α)

j + x(α)

j ey(α)

i (cid:17) +Xi

x(α)

i +Xi,j

cijy(α)

j

i ≥ 0, y(α)
x(α)

i − y(0)

i = u(α)

i

, y(0)

1 = 0.

The number of iterations required to solve the dTRAM problem is also greatly

reduced by scaling each count-matrix according to

(3.19)

with

(3.20)

ij = γc(α)
˜c(α)

ij

γ = max
α,i,j

c(α)
ij

As for the reversible MLE problem a larger class of related dTRAM problems
can be solved by augmenting the dual problem (3.18) with convex constraints, e.g.
dTRAM with partial or bound constrained information about the unbiased stationary
vector. It must be ensured that the additional constraints on the biased stationary
probabilities do not result in an infeasible problem, i.e. the reweighting condition
(2.4) and the constraints cannot be fulﬁlled simultaneously.

4. Convex-concave programs and variational inequalities. A convex-concave

program is the following saddle point problem,

(4.1)

max

y

min

x

f (x, y)

subject to

(x, y) ∈ K

with f convex in x, concave in y, and K ⊆ Rn a convex set.

Convex-concave programs can be treated as special cases of ﬁnite-dimensional
variational inequality (VI) problems, [10]: For a given feasible set K ⊆ Rn and a
mapping Φ : K → Rn ﬁnd a point z ∗ ∈ K such that

(4.2)

(z − z ∗)T Φ(z ∗) ≥ 0 ∀z ∈ K.

6

Any point z ∗ satisfying (4.2) is a solution or optimal point for the VI. The convex-
concave program is cast into the VI-form by deﬁning

(4.3)

Φ(z) =(cid:18) ∇xf (x, y)

−∇yf (x, y) (cid:19) ,

z = (x, y).

A mapping Φ is said to be monotone if

(4.4)

(z ′ − z)T (Φ(z ′) − Φ(z)) ≥ 0 ∀z ′, z ∈ K.

Monotonicity of (4.3) follows from the convex-concave property of f .

If K is a convex polyhedral set, i.e. solely deﬁned in terms of linear equalities and

inequalities,

(4.5)

K = {z ∈ Rn|Az − b = 0, Gz − h ≤ 0},

then z solves the VI (4.2) if and only if there are vectors λ, ν, s, such that the following
KKT-conditions are fulﬁlled [10],

(4.6)

Φ(z) + AT ν + GT λ = 0
Az − b = 0

Gz − h + s = 0
λT s = 0
λ, s ≥ 0

The vectors λ and ν are dual variables associated with the inequality and equality
constraints. The vector of slack variables, s = (h − Gz), transforms the linear in-
equality constraints for z into simple non-negativity constraints for s. Optimality
conditions for convex K in standard form, i.e. deﬁned by a ﬁnite number of linear
equalities and convex inequalities, are also available, cf. [10].

A direct application of a Newton type method to (4.6) ensuring positivity of λ
and s is usually unsuccessful since the solution progress rapidly stagnates once the
iterates approach the boundary of the feasible set.

A possible strategy to circumvent this problem is numerical path-following. In-
stead of attempting a direct solution of (4.6) path-following proceeds by solving a
sequence of problems with perturbed complementarity condition,

(4.7)

Φ(z) + AT ν + GT λ = 0
Az − b = 0

Gz − h + s = 0
λT s = µ
λ, s ≥ 0

tracing the central path of solutions z ∗(µ) towards z ∗(0) with µ → 0+. Perturbing
the complementarity condition ensures that the boundary of the feasible set is not
reached prematurely and the iteration makes good progress along the computed search
direction.

Interior-point methods ensure the positivity of λ and s at each step of the itera-
tion. If in addition a strictly feasible starting point Az(0) − b = 0, Gz(0) − h + s(0) = 0

7

is used then all iterates produced by the algorithm lie in the interior of the feasible
region.

Progress towards a solution of the perturbed KKT-conditions (4.7) is usually
made by taking steps along the Newton direction computed from the following linear
system,

(4.8)

DΦ(z) AT GT
0
0
S

A
G
0

0
0
0

0
0
I
Λ




∆z
∆ν
∆λ
∆s










= −


Φ(z) + AT ν + GT λ

Az − b

Gz − h + s
SΛe − µe

,




with diagonal matrices S = diag(s1, s2, . . . ), Λ = diag(λ1, λ2, . . . ), the vector e =
(1, 1, . . . ), and the perturbation parameter µ > 0.

We use the following short-hand notation for the dual residuum,

(4.9)

rd = Φ(z) + AT ν + GT λ,

the primal residuals,

(4.10)

rp,1 = Az − b,
rp,2 = Gz − h + s,

and the perturbed complementary slackness,

(4.11)

rc(µ) = SΛe − µe.

Solving the linear system (4.8) is the most expensive part of the algorithm. The
sparse block structure of (4.8) can be used to signiﬁcantly speed up the solution
process. Elimination of ∆s and ∆λ reduces (4.8) to the augmented system

(4.12)

(cid:18) H AT

0 (cid:19)(cid:18) ∆z

∆ν (cid:19) = −(cid:18) rd + GT Σrp,2 − GT S−1rc(µ)

rp,1

A

(cid:19) ,

with diagonal matrix Σ = S−1Λ and augmented Jacobian H = DΦ + GT ΣG. The
increments ∆λ and ∆s can be computed from ∆z,

(4.13)

∆s = −rp,2 − G∆z
∆λ = −Σ∆s − S−1rc(µ).

For nonsingular H further elimination of ∆z from (4.12) is possible. The resulting

normal equations for ∆ν are,

(4.14)

S∆ν = r2 − AH −1r1.

The vectors ri are the two components of the RHS of (4.12) and the matrix S =

(cid:0)AH −1AT(cid:1) is the Schur complement of H. The increment ∆z can then be computed

according to

(4.15)

∆z = −H −1(r1 + AT ∆ν).

A singular matrix H can for example occur for an equality-constrained convex
programming problem for which the objective is not strictly convex. Even if the

8

constraints ensure that the problem has a unique solution, H will be singular so that
the normal equations can not be formed.

For convex programming problems a non-singular H can be eﬃciently factorized
using a symmetric positive-deﬁnite Cholesky factorization. In the convex-concave case
the Jacobian of the mapping Φ is not symmetric,

(4.16)

DΦ(z) =(cid:18) ∇x∇xf (x, y) ∇y∇xf (x, y)T

−∇y∇xf (x, y) −∇y∇yf (x, y) (cid:19) .

In that case the augmented system is not symmetric and the Cholesky factorization
can not be used.

A further speed-up in the computation of the Newton direction can be achieved
through the exploitation of sparse or block-sparse structure possibly present in DΦ,
G, A. In this situation solution via an iterative method can be particularly eﬃcient
if a good preconditioner is available.

5. Implementation details. In order to apply the algorithm in [19] to the
reversible MLE problem (3.7) we transform the convex-concave program into the VI
form using the mapping Φ = (∇xf, −∇yf ) in (4.3). The gradient of the objective in
(3.7) is given by

(5.1)

∂xk f = −Xj
∂yk f = −Xj

(ckj + cjk)eyj
xkeyj + xj eyk

+ 1

(ckj + cjk)xj eyk
xkeyj + xj eyk

cik.

+Xi

For the computation of the Newton direction we also need the Jacobian DΦ. The

diagonal blocks are given by

(5.2)

∂xk ∂xlf =Xj
∂yk ∂ylf = −Xj

(ckj + cjk)eyj eyj
(xkeyj + xjeyk )2 δk,l +
(ckj + cjk)xkeyj xjeyk

(xkeyj + xj eyk )2

(ckl + clk)eyk eyl
(xkeyl + xleyk )2 ,

δk,l +

(ckl + clk)xkeylxleyk

(xkeyl + xleyk )2

,

and oﬀ-diagonal blocks are given by

(5.3)

(ckj + cjk)eyk xjeyj
(xkeyj + xj eyk)2 δk,l −

(ckl + clk)xkeyk eyl
(xkeyl + xleyk)2 ,

∂yk ∂xlf =Xj

∂xk ∂ylf = ∂yl∂xkf.

It is straightforward to encode the equality and inequality constraints in (3.7)

into matrices A, G and vectors b, h.

(5.4)

(5.5)

(5.6)

A = (0, . . . , 0

, 1, 0, . . . , 0

),

| {z }n

|

b = 0,

n

{z

}

G = (−In, 0n),

9

(5.7)

h = (0, . . . , 0)T

with In the identity and 0n the zero matrix in Rn×n.

The Jacobian DΦ is singular because of the invariance of the objective f under a
constant shift of y; this is also true for the augmented Jacobian H since the inequalities
act only on x. Therefore the normal equations (4.14) cannot be formed and the search
direction has to be computed from the augmented system (4.12).

The blocks of DΦ have the same sparsity pattern as the matrix Cs = C +CT . This
matrix is usually sparse. The augmented Jacobian diﬀers from the original Jacobian
only on the diagonal so that it is also sparse in a situation in which Cs is sparse. The
equality constraints for the reversible MLE problem do only aﬀect the y variables, i.e.
A = (0, Ay). The augmented system, (4.12), can be cast into the following symmetric
form,

(5.8)




Hxx Hyx
H T
yx −Hyy −AT
y
0

−Ay

0

0 





∆x
∆y

∆ν 
 =


bx
−by
−bν


 .

The augmented system matrix, W , on the left-hand side of (5.8) is indeﬁnite so
that a symmetric indeﬁnite factorization, [6], or the minimum residual (MINRES)
method, [17], can be used to solve (5.8). If an iterative method is used, a suitable
preconditioner needs to remove the ill-conditioning due to the Σ = S−1Λ term in
H. MINRES requires a positive deﬁnite preconditioner. We use a positive deﬁnite
diagonal preconditioning matrix, T , with diagonal entries,

(5.9)

tii =(|wii|

1

if |wii| > 0
else

.

5.1. dTRAM. We can also apply the primal-dual interior-point method to the
convex-concave reformulation of the dTRAM problem, (3.18). The dTRAM problem
consists of a reversible MLE problem for each thermodynamic state coupled via an
equality constraint. The resulting VI-mapping for dTRAM is given by the vector

Φ = (Φ0, . . . , Φm).

The entry Φα is the mapping for the reversible MLE problem at thermodynamic
state α. Since Φα depends only on variables (x(α), y(α)) the Jacobian of Φα has a
block-diagonal structure

DΦ =


DΦ0

. . .

DΦm




The matrix DΦα is the mapping for the reversible MLE problem at thermodynamic
state α. The linear inequality constraints at diﬀerent α are decoupled so that G is
also block diagonal,

G0

G =


. . .

10

.




Gm

The block G(α) is the matrix of inequality constraints at thermodynamic state α,

Gα = (−In, 0n) ,

and h = 0 is the corresponding RHS. The matrix for the equality constraints has the
following form,

A =


0
A0
A1,0 A1
...
...
0
Am,0

0
. . .
0
. . .
...
. . .
. . . Am




with A0 = (0, . . . , 0, 1, . . . , 0) the constraint matrix for the unbiased ensemble, α = 0,
and Aα = (0n, In) the constraint matrix at condition α 6= 0. The matrix Aα,0 =
(0n, −In) is the coupling matrix between biased and unbiased ensemble. The corre-
sponding RHS is

b =


b0
...
bm




) the vector of energy diﬀerences with respect to the

with b0 = 0, and bα = (u(α)
unbiased condition.

i

The block-diagonal form of DΦ and G can be exploited for the solution of the aug-
mented system. The block diagonal structure of DΦ and G implies a block diagonal
structure for H,

(5.10)

(5.12)

H =


H1

. . .

Hm,

.




∆ξ0
∆ξ1
...
∆ξm




= −


˜b0
˜b1
...
˜bm




. . . BT
m,0
0
. . .
...
. . .
. . . Wm





Wα =(cid:18) Hα AT

Aα

α

0 (cid:19) .

The block Hα = DΦα + GT
α ΣαGα is the augmented Jacobian at thermodynamic
state α. Using the block structure of H and A, the augmented system (4.12) can be
reordered resulting in the following linear system,

(5.11)

W0 BT
1,0
B1,0 W1
...
...
0
Bm,0




The augmented system matrix at condition α is

The coupling between the biased condition and the unbiased condition is encoded in
the matrix

(5.13)

Bα,0 =(cid:18) 0

Aα,0

11

0

0 (cid:19) α 6= 0.

The vector ∆ξα = (∆zα, ∆να) is the resulting increment for the augmented sys-
tem at condition α. The vector ˜bα in (5.11) is given by the RHS of the augmented
system at condition α,

(5.14)

˜bα =  r(α)

d + GT

α Σαr(α)

α S−1

α r(α)

c

p,2 − GT
r(α)
p,1

(µ)

! .

The arrow-shaped structure of the linear system in (5.11) allows us to apply the
Schur complement method, [11,25], to eliminate ∆ξ1, . . . , ∆ξm and solve the following
condensed system for ∆ξ0,

(5.15)

S∆ξ0 = − ˜b0 −

m

Xα=1

BT

α,0W −1
α

˜bα!

The Schur complement matrix is

(5.16)

S = W0 −

m

Xα=1

BT

α,0W −1

α Bα,0! .

All other increments can be computed from ∆ξ0 via

(5.17)

∆ξα = −W −1

α (cid:16)˜bα + Bα,0∆ξ0(cid:17)

For a system with n states at m thermodynamic conditions the complexity for
a direct factorization of the Newton system (4.8) is O(m3n3). The Schur comple-
ment approach reduces complexity to O(mn3). In addition, assembly of the Schur
complement in (5.16) and solution of (5.17) can be easily paralellized.

As for the reversible MLE case, the blocks of DΦα have the same sparsity pattern
as the matrix C(α)
s = C(α) + C(α)T . The same is true for the augmented Jacobian
Hα except for the diagonal. Since C(α)
is usually sparse we use a sparse LU method
to factor the augmented system matrices Wα for α > 0. The direct assembly of the
Schur complement in (5.16) is expensive since the computation of W −1
α Bα,0 requires
O(n) solves.

s

If an iterative method is used to solve the condensed system (5.15) one would like
to avoid assembly of the Schur complement S in (5.16) all together. Instead only few
matrix-vector products involving S should be computed. As for the reversible MLE
case, we can transform the condensed system into a symmetric indeﬁnite form and
use MINRES to obtain a solution. Obtaining a good preconditioner without explicit
assembly of S is diﬃcult. We use the probing method outlined in [7] to obtain an
approximation of the diagonal of S using only few matrix-vector products. We then
construct a positive deﬁnite diagonal preconditioning matrix T with entries

tii =(|˜sii|

1

if |˜sii| > 0
else

.

The entry ˜sii denotes the diagonal entry estimated by the probing approach.

The Schur complement based solution can also be applied to the dTRAM problem
with additional constraints whenever those constraints do not couple diﬀerent biasing
conditions.

12

Table 1

Reversible MLE problem. Newton-IP algorithm vs. SC-iteration. We report the number of
states N , the growth factor for states N/n (n is the number of states in the previous row), the total
algorithm run time T (in seconds), the growth factor for run time T /t (t is the run time in the
previous row), the scaling exponent for run time with increasing number of states p, (T ∝ N p), and
the speedup of the Newton-IP method over the SC-iteration SC/IP. The scaling is subquadratic for
both methods. The Newton-IP algorithm achieves a signiﬁcant speed-up over the SC-iteration for
all examples except the pentapeptide.

System

N N/n

Newton-IP
T

T /t

p

SC-iteration

SC/IP

T

T /t

p

Three-well

Alanine

Pentapeptide

Birth death

361
2134
8190
29618

292
1059
3835
5826

250
500
1000
2000

100
200
500
1000

1.1
7.3
56.8
286.8

0.7
4.2
32.2
61.8

0.6
1.2
3.6
5.4

1.0
2.1
5.8
13.9

5.9
3.8
3.6

3.6
3.6
1.5

2.0
2.0
2.0

2.0
2.5
2.0

6.4
7.7
5.0

6.4
7.6
1.9

1.9
3.0
1.5

2.1
2.8
2.4

1.0
1.5
1.3

1.4
1.6
1.6

0.9
1.6
0.6

1.1
1.1
1.3

4.6
75.1
400.3
1076.9

4.2
32.3
214.0
347.7

0.2
0.6
1.0
1.3

10.4
34.1
185.3
338.7

16.2
5.3
2.7

7.8
6.6
1.6

2.4
1.8
1.3

3.3
5.4
1.8

1.6
1.2
0.8

1.6
1.5
1.2

1.3
0.9
0.4

1.7
1.8
0.9

4.0
10.2
7.0
3.8

6.3
7.6
6.6
5.6

0.4
0.5
0.3
0.2

10.6
16.3
31.7
24.3

6. Results. Below we report results for the primal-dual interior-point (Newton-
IP) and the self consistent iteration (SC-iteration) approach to solving the reversible
MLE and dTRAM problem. We compare the eﬃciency of both algorithms for a
number of examples. Using iterative methods for the solution of the linear systems
arising in the Newton-IP approach we achieve a similar scaling behavior as for the SC-
iteration. We demonstrate that the Newton-IP approach oﬀers a signiﬁcant speedup
for nearly all examples.

6.1. Reversible MLE. In Table 1 we compare the performance of the algorithm
for diﬀerent example data-sets. The count matrix was estimated from the full data
set using the sliding-window method [18]. The tolerance indicating convergence was
tol = 10−12 for both algorithms. Both methods exhibit a subquadratic scaling in the
number of states. The Newton-IP method is able to achieve a signiﬁcant speed-up
over the SC-iteration for all examples except for the pentapeptide data.

In Figure 1 we show the performance of both methods for the alanine dipeptide
system with 361 states. For the SC-iteration the number of iterations required to
converge to a given tolerance is very variable across diﬀerent data sets. The total
number of iterations required to converge deteriorates with increasing amount of input
data. For the Newton-IP method the required number of iterations is consistent across
all data sets. Both methods exhibit subquadratic scaling in the number of observed
states.

13

100

10−2

10−4

10−6

10−8

10−10

10−12

10−14

10−16

k
∗
π
−

)
k
(
π
k

,
r
o
r
r
E

T = 200ns

T = 1µs

T = 2µs

T = 5µs

T = 10µs

10−3

10−4

10−5

10−6

10−7

10−8

10−9

10−10

k
∗
π
−

)
k
(
π
k

,
r
o
r
r
E

T = 200ns

T = 1µs

T = 2µs

T = 5µs

T = 10µs

0

2

4

6

8

10

12

14

16

0

1000

2000

3000

4000

5000

6000

7000

Number of iterations, N

Number of iterations, N

(b)

(a)

s

n

i

t

,
e
m
T

i

103

102

101

100

Newton-IP

sc-iteration
t ∝ n2

10−1

102

103

104

Number of states, n

(c)

Figure 1. Comparison of Newton interior-point method, a), and self-consistent iteration, b) for
the alanine dipeptide example. Convergence is plotted for diﬀerent data sets corresponding to diﬀer-
ent amounts of total simulation time. The vector π∗ is a reference stationary distribution obtained
from the converged Newton interior-point method. The Newton interior-point method converges
superlinearly, the self-consistent iteration converges linearly. The number of required iterations is
very sensitive to the input data set for the SC-iteration while the Newton-IP method is only mildly
aﬀected. c) Both methods exhibit a subquadratic scaling in the number of states. The Newton-IP
method achieves a signiﬁcant speed-up over the SC-iteration.

6.2. dTRAM . In Table 2 we compare the performance of the Newton-IP and
the SC-iteration for diﬀerent examples. The count matrix was estimated from the full
data set using the sliding-window method [18]. The tolerance indicating convergence
was tol = 10−10 for both algorithms. The Newton-IP method is more eﬃcient for all
three examples and achieves a dramatic speed-up (orders of magnitude). The Schur
complement probing approach is successful for the alanine and the doublewell umbrella
sampling example. For the multi-temperature example the Schur complement was
assembled and the condensed system was solved using a direct method. For the
SC-iteration method the required time to solve the multi-temperature example was
very large so that computations were only carried out for two examples with a small
number of states.

Both methods scale linearly in the number of thermodynamic states. The Newton-
IP method with Schur complement probing scales at most quadratic in the number
of states. If the Schur complement is assembled and factored by a direct method the
scaling is between quadratic and cubic. The SC-iteration exhibits quadratic scaling in
the number of states. The Newton-IP method achieves orders of magnitude speed-up
compared to the SC-iteration for all examples.

In Figure 2 we show performance of the Newton-IP and SC-iteration for the dou-

14

Table 2

Newton-IP algorithm vs. SC-iteration for the dTRAM problem. We report the number of states
N , the number of thermodynamic state M , the growth factor for states N/n (n is the number of
states in the previous row), the total algorithm run time T (in seconds), the growth factor for run
time T /t (t is the run time in the previous row), the scaling exponent for run time with increasing
number of states p, (T ∝ N p), and the speedup of the Newton IP method over the SC method
SC/IP. In one case we report instead the growth factor of the number of thermodynamic states
M/m (m is the number of states in the previous row) and the scaling exponent for run time with
increasing number of thermodynamic states (T ∝ M p). Both method scale linearly in the number of
thermodynamic states. The Newton-IP method with Schur complement probing (alanine, doublewell
with umbrella sampling) scales at most quadratic in the number of states. If the Schur complement
is assembled and factored by a direct method (doublewell with independent temperature sampling) the
scaling is between quadratic and cubic. The SC-iteration exhibits quadratic scaling in the number of
states. The Newton-IP method achieves orders of magnitude speed-up compared to the SC-iteration
for all examples.

System

N M N/n

Newton-IP
T

T /t

p

SC-iteration

SC/IP

T

T /t

p

Alanine

Doublewell,
umbrella

Doublewell,
umbrella

Doublewell,
multi-
temperature

292
1521

100
199
497
990
1978

100
100
100
100

100
200
500
1000

40
40

20
20
20
20
20

20
40
80
100

16
16
16
16

34.0
202.4

5.1
6.4
17.3
48.3
193.1

5.1
8.3
16.5
20.9

3.7
10.7
79.8
544.5

5.2

2.0
2.5
2.0
2.0

2.0
2.0
1.2

2.0
2.5
2.0

6.0

1.1

1.3
2.7
2.8
4.0

1.6
2.0
1.3

2.9
7.4
6.8

0.3
1.1
1.5
2.0

0.7
1.0
1.1

1.5
2.2
2.8

1263.9
66018.4

115.5
492.9
3258.4
13729.7
59890.5

115.5
244.5
721.1
1110.6

12223.2
50446.2

52.2

2.4

4.3
6.6
4.2
4.4

2.1
2.9
1.5

2.1
2.1
2.1
2.1

1.1
1.6
1.9

37.2
326.2

22.7
77.1
188.7
284.4
310.1

22.7
29.3
43.8
53.1

4.1

2.0

3285.8
4705.8

blewell umbrella-sampling example. The Newton-IP method achieves a signiﬁcant
speed-up (up to two orders of magnitude) over the SC-iteration.

7. Conclusion. We show that the problem of ﬁnding the maximum likelihood
reversible transition matrix on a ﬁnite state space is equivalent to a convex-concave
programming problem with a much smaller number of unknowns and constraints.

The primal-dual interior-point method for monotone variational inequalities out-
lined in [19] can be used to eﬃciently solve the arising convex-concave program. For a
number of examples the proposed algorithm signiﬁcantly speeds up the computation
of the reversible MLE compared to a previously proposed ﬁxed-point iteration.

The convex-concave reformulation makes it possible to eﬃciently solve a number

of related problems arising in the context of reversible Markov chain estimation.

One application of special interest is statistical reweighting of data from multiple
ensembles via the dTRAM method [23]. We extend the convex-concave reformulation
to the dTRAM problem so that it can also be solved by a primal-dual interior-point
method. We show that the arising linear systems can be eﬃciently solved using a

15

Newton-IP

sc-iteration
t ∝ n2

105

104

103

102

101

100

s

n

i

t

,
e
m
T

i

10−1

102

103

Number of states, n

(a)

104

103

102

101

s

n

i

t

,
e
m
T

i

100

101

Newton-IP

sc-iteration

t ∝ m

Number of thermodynamic states, m

102

(b)

Figure 2. Comparison of the Newton-IP method and the SC-iteration for the dTRAM problem.
We show results for the doublewell potential with harmonic umbrella forcing. a) Both methods exhibit
quadratic scaling in the number of states, but the Newton method is up to two orders of magnitude
faster then the sc iteration. b) Scaling is linear in the number of thermodynamic states for both
methods.

Schur complement approach. The outlined algorithm is shown to signiﬁcantly speed
up the solution process compared to a previously proposed ﬁxed-point iteration.

Similar to the reversible MLE problem a number of related dTRAM problems
can be solved using our method. The eﬃcient linear solution of the arising Newton
systems using the Schur-complement method can be retained no additional coupling
between the diﬀerent thermodynamic ensembles is introduced.

The investigation of eﬃcient preconditioning techniques for the presented prob-
lems remains a topic for future research. Obtaining a good preconditioner for the
Schur complement without direct assembly is of special interest for the dTRAM prob-
lem.

Acknowledgments. The authors would like to thank C. Wehmeyer and F. Paul
for stimulating discussions. B. T.-S. thanks E. Pipping and C. Gr¨aser for valuable
comments and suggestions.

REFERENCES

[1] D. Aldous

and

J. A. Fill, Reversible markov

on graphs,
http://www.stat.berkeley.edu/~aldous/RWG/book.html.

Unﬁnished monograph,

2002.

chains
recompiled

and
2014,

random walks
at

available

[2] J. Besag and D. Mondal, Exact goodness-of-ﬁt tests for markov chains, Biometrics, 69 (2013),

pp. 488–496.

[3] G. R. Bowman, K. A. Beauchamp, G. Boxer, and V. S. Pande, Progress and challenges in
the automated construction of markov state models for full protein systems, The Journal
of Chemical Physics, 131 (2009), pp. –.

[4] G. R. Bowman, V. S. Pande, and F. No´e, An introduction to markov state models and their
application to long timescale molecular simulation, vol. 797, Springer Science & Business
Media, 2013.

[5] S. Boyd and L. Vandenberghe, Convex optimization, Cambridge university press, 2004.
[6] J. R. Bunch and L. Kaufman, Some stable methods for calculating inertia and solving sym-

metric linear systems, Mathematics of computation, (1977), pp. 163–179.

[7] T. F. C. Chan and T. P. Mathew, The interface probing technique in domain decomposition,

SIAM Journal on Matrix Analysis and Applications, 13 (1992), pp. 212–238.

[8] J. Denny and A. Wright, On tests for markov dependence, Probability Theory and Related

Fields, 43 (1978), pp. 331–338.

16

[9] P. Diaconis and S. W. W. Rolles, Bayesian analysis for reversible markov chains, Ann.

Statist., 34 (2006), pp. 1270–1292.

[10] F. Facchinei and J.-S. Pang, Finite-dimensional variational inequalities and complementarity

problems, Springer Science & Business Media, 2007.

[11] J. Kang, Y. Cao, D. P. Word, and C. Laird, An interior-point method for eﬃcient solution
of block-structured {NLP} problems using an implicit schur-complement decomposition,
Computers & Chemical Engineering, 71 (2014), pp. 563 – 573.

[12] D. A. Levin, Y. Peres, and E. L. Wilmer, Markov chains and mixing times, American

Mathematical Society, 2009.

[13] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller,
Equation of state calculations by fast computing machines, The Journal of Chemical
Physics, 21 (1953), pp. 1087–1092.

[14] P. Metzner, F. No´e, and C. Sch¨utte, Estimation of transition matrix distributions by monte

carlo sampling, Phys. Rev. E, 80 (2009), p. 021106.

[15] A. J. N. Nielsen and M. Weber, Computing the nearest reversible markov chain, Numerical

Linear Algebra with Applications, 22 (2015), pp. 483–499.

[16] F. No´e, Probability distributions of molecular observables computed from markov models, J.

Chem. Phys., 128 (2008), p. 244103.

[17] C. C. Paige and M. A. Saunders, Solution of sparse indeﬁnite systems of linear equations,

SIAM journal on numerical analysis, 12 (1975), pp. 617–629.

[18] J. Prinz, H. Wu, M. Sarich, B. Keller, M. Senne, M. Held, J. Chodera, C. Sch¨utte,
and F. No´e, Markov models of molecular kinetics: Generation and validation, J. Chem.
Phys., 134 (2011), p. 174105.

[19] D. Ralph and S. J. Wright, Superlinear convergence of an interior-point method despite

dependent constraints, Mathematics of Operations Research, 25 (2000), pp. pp. 179–194.

[20] C. Robert and G. Casella, Monte Carlo statistical methods, Springer Science & Business

Media, 2013.

[21] B. Trendelkamp-Schroer and F. No´e, Eﬃcient estimation of rare-event kinetics, Phys. Rev.

X, 6 (2016), p. 011009.

[22] B. Trendelkamp-Schroer, H. Wu, F. Paul, and F. No´e, Estimation and uncertainty of

reversible markov models, J. Chem. Phys., 143 (2015).

[23] H. Wu, A. S. J. S. Mey, E. Rosta, and F. No´e, Statistically optimal analysis of state-
discretized trajectory data from multiple thermodynamic states, J. Chem. Phys., 141 (2014),
p. 214106.

[24] H. Wu and F. No´e, Optimal estimation of free energies and stationary densities from multiple

biased simulations, Multiscale Modeling & Simulation, 12 (2014), pp. 25–54.

[25] V. M. Zavala, C. D. Laird, and L. T. Biegler, Interior-point decomposition approaches for
parallel solution of large-scale nonlinear parameter estimation problems, Chemical Engi-
neering Science, 63 (2008), pp. 4834 – 4845.

17

