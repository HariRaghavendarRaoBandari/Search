. ARTICLES .

SCIENCE CHINA

Mathematics

In memory of 10 years since the pasted away of Professor Xiru Chen - a great Chinese Statistician

January 2015 Vol. 55 No. 1: 1–XX
doi: 10.1007/s11425-000-0000-0

6
1
0
2

 
r
a

M
3

 

A review of 20 years of naive tests of signiﬁcance for

high-dimensional mean vectors and covariance

matrices

HU Jiang1 & BAI Zhidong1,∗

 
 
]
T
S
h
t
a
m

.

[
 
 

1
v
3
0
0
1
0

.

3
0
6
1
:
v
i
X
r
a

1KLASMOE and School of Mathematics & Statistics, Northeast Normal University, Changchun, 130024, P.R.C.

Email: huj156@nenu.edu.cn, baizd@nenu.edu.cn

Received Month 00, 2015; accepted Month 00, 2015

Abstract
In this paper, we will introduce the so called naive tests and give a brief review on the newly
development. Naive testing methods are easy to understand and performs robust especially when the dimension
is large. In this paper, we mainly focus on reviewing some naive testing methods for the mean vectors and
covariance matrices of high dimensional populations and believe this naive test idea can be wildly used in many
other testing problems.

Keywords

Naive testing methods, Hypothesis testing, High-dimensional data, MANOVA.

MSC(2010)

62H15, 62E20

Citation: HU J, BAI Z D. A review of 20 years of naive tests of signiﬁcance for high-dimensional mean vectors and

covariance matrices. Sci China Math, 2015, 55, doi: 10.1007/s11425-000-0000-0

1

Introduction

Since its proposal by Hotelling (1931) [22], Hotelling T 2 test has served in multivariate analysis more
than eight decades as a good test due to its many good properties, e.g., it is uniformly most powerful
among aﬃne invariant tests for the hypotheses H0 : µ = 0 for the one-sample problem and H0 : µ1 = µ2
for the two-sample problem. However, it has a fatal defect that it is not well deﬁned when the dimension
is larger than the sample size or degrees of freedom. As a remedy, Dempster (1958) [15, 16] proposed his
NET (non-exact test) to test the hypotheses of the equality of two multivariate population means, that
is, the test of the locations in the two-sample problem. Bai and Saranadasa in 1996 [3] further found that
Dempster’s NET not only serves the test of the hypothesis as a remedy of Hotelling T 2 when the degrees
of freedom is lower than the dimension, it is also more powerful than Hotelling T 2 when the dimension
is large but not very large so that T 2 is well deﬁned. They also proposed an asymptotic normal test
(ANT) to test the same hypothesis and strictly proved that both NET and ANT have similar asymptotic
power functions higher than that of Hoteling T 2 test. Thus, this work raised an important question that
classical multivariate statistical procedures need to re-exam when the dimension is high. For attracting
attention on this problem, they entitled their paper by “The Eﬀect of High Dimension”.

The paper was published nearly 20 years yet, it has been cited by others more than 100 times yet
It is interesting that more than 95% of the citations were made in the recent 10

in Web of Science.

∗Corresponding author

c(cid:13) Science China Press and Springer-Verlag Berlin Heidelberg 2012

math.scichina.com www.springerlink.com

2

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

years. This reveals that the high-dimensional data analysis has attached much wider attention since
the year 2005 than earlier. In the theory of hypothesis test, of course, the most preferable test is the
uniformly most powerful test. However, it does not exist unless the distribution family has the property
of monotone likelihood ratio for which the parameter can only be univariate. Hence, there is no uniformly
most powerful test for multivariate analysis. Therefore, the optimal procedure can only be considered for
smaller domains of signiﬁcance tests, say the unbiased tests, or the invariant tests with respect to some
speciﬁc transformation groups. The Hotelling T 2 was derived based on the likelihood ratio principle and
to be proved being the most powerful invariant test with respect to the aﬃne transformation group (see
Page 174 of [1]). An important but serious thing is that the likelihood ratio test must be derived under
the assumption that the likelihood of the data set exists and is known, except the unknown parameters.
In a real application it is impossible to verify that the underlying distribution is multivariate normal
or has any other known forms of the likelihood functions. Thus, we would like to use another way
to set up a test for some given hypothesis: choose h(θ) as a target function for the hypotheses such
that the null hypothesis can be expressed as h(θ) = 0 and the alternative as h(θ) > 0; then one looks
for a proper estimator ˆθ of the parameter θ. Then, we reject the hypothesis if h( ˆθ) > h0 such that
PH0 (h( ˆθ) > h0) = α. For example, for the Hotelling test of the diﬀerence of two sample means, one can
choose h(µ1, µ2, ΣΣΣ) = (µ1− µ2)′ΣΣΣ−1(µ1− µ2) and the estimators being ˆµi = ¯Xi, i = 1, 2, and ˆΣΣΣ = S, the
sample means and sample covariance matrix. Dempster’s NET and Bai and Saranadasa’s ANT just use
h(µ1, µ2) = kµ1 − µ2k2 and ˆµi = ¯Xi, i = 1, 2. That is, the hotelling test uses the squared Mahalanobis
distance and the NET and the ANT use the squared Euclidean distance. We believe that the reason that
NET and ANT are more powerful when the dimension is large because the target function of Hotelling
test involves too many nuisance parameters in ΣΣΣ which can not be well estimated. Because the new test
replies only on the intuitive target function instead of the likelihood, we shall call them the naive tests,
especially for those being independent of the nuisance parameters, which generally ensure higher power.
Bai and Saranadasa in 1996 [3] raised an interesting question that one would prefer a test of higher
power to a test of exact size and much lower power. The naive tests have obtained rapid developments
in the passed twenty years, especially the recent 10 years. In this paper, we will give a brief review on
the newly developed naive tests, being widely applied to a wide array of disciplines such as genomics,
atmospheric sciences, wireless communications, biomedical imaging, economics and so on. However,
limited to the length of this paper, we could not review all developments and applications in all directions,
although some of them are very excellent and interesting achievement to the high dimensional data
analysis. In this paper, we mainly focus on reviewing some naive testing methods (NTM) for the mean
vectors and covariance matrices of high dimensional populations.

Based on the NTM, there are many test statistics have been proposed for high dimensional data anal-
ysis. Throughout this paper, we suppose there are k populations and the observations Xi1, . . . , Xini are
p-variate independent and identically distributed (i.i.d.) random samples vectors from the i-th popula-
tion, which have mean vector µi and covariance matrix ΣΣΣi. What is more, except where noted we will
work with the following model assumptions:

(A1) Xij = ΓiZij + µi,

m > p such that ΓiΓ′
and V ar(Zij ) = Im, the m × m identity matrix;
n → κi ∈ (0, 1)

(A2) ni
i=1 ni;
We denote P→ converge in probability, D→ converge in distribution,

for i = 1, . . . k, j = 1 . . . , ni, where Γi is a p × m non-random matrix for some
i = ΣΣΣi, and {Zij}ni
j=1 are m-variate i.i.d. random vectors satisfying E(Zij ) = 0
i = 1, . . . k, as n → ∞. Here n =Pk
niXj=1

(Xij − ¯Xi)(Xij − ¯Xi)′ = (s(i)
ij ).

Xij and Si =

1

ni − 1

niXj=1

¯Xi =

1
ni

When k = 1, the subscripts i or 1 will be suppressed from ni, n1, Γi, µi etc., for brevity.

The remainder of this paper will be organized as follows: In Section 2, we shall review on the sample
location parameters. In subsection 2.1 we will ﬁrst introduced what has been found in Bai and Saranadasa

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

3

[3]; In subsection 2.2 we will introduce Chen and Qin [13]’s test based on unbiased estimator of the target
function; In subsection 2.3, we will review Srivastava and Du’s work of scale invariant NTM, based on
the modiﬁed component-wise squared Mahalanobis distance; In subsection 2.4, we will introduce Cai et
al’s NTM based on Kolmogorov distance, i.e., maximum component diﬀerences; In subsection 2.5, we
will introduce some works on the extensions to MANOVA and contrast tests, that is, test for problems
of more than two samples. In Section 3, we will introduce some naive tests on hypotheses for sample
covariances. In subsection 3.1, we will introduce the naive test proposed by Ledoit and Wolf [26] on the
hypothesis of one-sample covariance matrix and the spherical test; In subsection 3.2 we will introduce
the NTM proposed by Li and Chen (2012) [27].
In subsection 3.3, we will introduce Cai’s NTM on
covariances based on the Kolmogorov distance. In Section 4, we will give some general remarks on the
developments of NTM.

2 Testing the population locations

2.1 Asymptotic powers of T 2, NET and ANT

In this section, we ﬁrst give a short description of the problem. In 1958 and 1960, Dempster published two
papers [15] and [16], considering the two-sample location problem of multivariate normal distributions,
H0 : µ1 = µ2 with a common covariance matrix ΣΣΣ. The classical test for this hypothesis is the renowned
Hotelling T 2 test

where ¯Xi = 1

j=1 Xij , i = 1, 2 and

niPni

T 2 =

n1n2

n1 + n2

( ¯X1 − ¯X2)′S−1( ¯X1 − ¯X2)

S =

1

n1 + n2 − 2
2Xi=1

niXj=1

(Xij − ¯Xi)(Xij − ¯Xi)′ .

Dempster argues that if p, the dimension of data, is larger than n1 + n2 − 2, the degrees of free-
dom, then T 2 is not well deﬁned and hence there is no way to do the signiﬁcance test by using it.
Therefore, he proposed the so-called NET (non-exact test) by the following way: Arrange the data
X = (X11,··· , X1n1 , X21,··· , X2n2) as a p× (n1 + n2) matrix. Select a (n1 + n2)× (n1 + n2) orthogonal
matrix H and transferm the data matrix to Y = X H = (y1,··· , yn1+n2) such that

y1 ∼ N(cid:16)
n1√n1 + n2
y2 ∼ N(cid:16)r n1n2
i.i.d.∼ N (0, ΣΣΣ).

n1 + n2

µ2, ΣΣΣ(cid:17)

µ1 +

n2√n1 + n2
(µ1 − µ2), ΣΣΣ(cid:17)

ky2k2

ky3k2 + ··· + kyn1+n2k2 .

y3,··· , yn1+n2

Then he deﬁnes his NET by

TD =

He claims that as n1 and n2 are larger, nTD ∼ Fr,nr where n = n1 + n2 − 2 by using the so-called chi-
square approximation of kyjk2 for i = 2, 3,··· , n1 + n2. Comparing nTD with T 2, we ﬁnd that Dempster
just replaced S by tr(S)Ip to smoothen the trouble when S is singular.
Bai and Saranadasa in [3] ﬁnd that Dempster’s NET is not only a remedy of T 2 test when it is not
well deﬁned, but also more powerful than T 2 even the latter is well deﬁned provided that the dimension
p is large compared with the degrees of freedom n. Based on Dempster’s NET, Bai and Saranadasa in [3]
also proposed the so-called ANT (asymptotic normality test) based on the normalization of ky2k2. They
established a CLT (central limit theorem) as follows

MnpV ar(Mn)

D→ N (0, 1),

4

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

where Mn = k ¯X1 − ¯X2k2 − n1+n2
proposed the ratio-consistent estimator of V ar(Mn) by

n1n2

tr(S). To perform the signiﬁcance test for H0, Bai and Saranadasa

\V ar(Mn) =

2(n + 2)(n + 1)n

2(n − 1) (cid:18)tr(S2) −

1
n

tr2S(cid:19) .

n2
1n2

Bai and Saranadasa [3] proved that when dimension p is large compared with n, both NET and ANT
are more powerful than T 2 test by deriving the asymptotic power functions of the three tests. Under
the conditions that p/n → y ∈ (0, 1) and n1/(n1 + n2) → κ ∈ (0, 1), the power function of T 2 test
asymptotically satisﬁes

βH (δ) − Φ −ξα +s n(1 − y)

2y

κ(1 − κ)kδk2! → 0,

where δ = ΣΣΣ−1/2(µ1 − µ2), Φ, here and throughout the paper, will be used for the distribution function
of standard normal random variable and ξα is its upper α quantile.

Under the assumption A2 and

µ′ΣΣΣµ = o(cid:18) n1 + n2
n1n2
λmax(ΣΣΣ) = o(√trΣΣΣ2),

tr(ΣΣΣ2)(cid:19)

(2.1)

(2.2)

where µ = µ1 − µ2, Bai and Saranadasa [3] also proved that the power function of Dempster’s NET
satisﬁes

βD(µ) − Φ(cid:18)−ξα +

nκ(1 − κ)kµk2

√2trΣΣΣ2

(cid:19) → 0.

Without the normality assumption, under the assumptions A1, A2 and the condition (2.1) and (2.2),
Bai and Saranadasa [3] proved that the power function of their ANT has similar asymptotic power as
the NET, that is

βBS(µ) − Φ(cid:18)−ξα +

nκ(1 − κ)kµk2

√2trΣΣΣ2

(cid:19) → 0.

In this section, we shall not exactly repeat what discussed in Bai and Saranadasa in [3]. But one
should notice that the three tests mentioned above are all NTM. Thus next we will consider the simpler
one-sample problem by NTM. That is, the null hypothesis is H0 : µ1 = µ0. Under the assumption (A1)
with k = 1, and for testing the hypothesis

H0 : µ = µ0 v.s. H1 : µ 6= µ0,

it is easy to check that E ¯X = µ. Thus we need to choose some norms. In the literature, there are two
kinds of norm are chosed, that are Euclidean norm and Maximum norm. Let us start from the classical
one.

The most famous statistic is the so called Hotelling T 2 statistic,

T 2 = n( ¯X − µ0)′S−1( ¯X − µ0)

(2.3)

which is proposed by Hotelling (1931) in [22] and is a natural generalization of the squared Student’s
t-statistic. If Zj ’s are normally distributed, it is shown that Hotelling T 2 statistic is the likelihood ratio
test for this one-sample problem and has many optimal properties, details can be found in any textbook
in multivariate statistical analysis, such as [1, 30]. Now let us view the Hotelling T 2 statistic by intuitive
test methods. Easy to check, ¯X and S are an unbiased estimators of µ and ΣΣΣ respectively, and, as
mentioned above, the target function is chosen as the Mahalanobis squared distance of the population
mean µ from the hypothesized mean µ0, which is the Euclidean norm of ΣΣΣ−1/2(µ − µ0), then we can
see that Hotelling T 2 statistic is a kind of NTM and we just need to get its (asymptotic) distribution. It

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

5

p(n−1) T 2 has an F-distribution with degrees of freedom p
is well known that under the null hypothesis,
and n − p, and when p is ﬁxed, as n tends to inﬁnity, T 2 tends to chi-squared distribution with degrees
of freedom p. If we assume yn = p/n → y ∈ (0, 1) and Xj are normally distributed, following Bai and
Saranadasa in [3], one may easily derive that

(n−p)

s (1 − yn)3

2nyn (cid:18)T 2 −

nyn

1 − yn −

nkδk2

1 − yn(cid:19) D→ N (0, 1),

as n → ∞,

(2.4)

where δ = ΣΣΣ−1/2(µ − µ0). By (2.4), it is easily to derive that the asymptotic power function of the T 2
test satisﬁes

βH − Φ −ξα +s n(1 − y)

2y

kδk2! → 0.

Here one should notice that the above asymptotic distribution of the Hotelling T 2 statistic (2.4) still

holds without normality assumption, details can be found in [32].

Next, we will derive the asymptotic power for ANT. In this case, the target function is chosen as

h(µ) = kµ − µ0k2 and the natural estimator of µ is ¯X = 1

i=1 Xi. It is easy to derive that

nPn

(2.5)

(2.6)

(2.7)

(2.8)

Ek ¯Xk2 = kµk2 +

1
n

trΣΣΣ

V ar(k ¯Xk2) =

2
n

+

trΣΣΣ2 + 4µ′ΣΣΣµ

2
√n

EZ 3
1

mXi=1

µ′γi(γ′

iγi) +

1
n1

(EZ 4

1 − 3)

(γ′

iγi)2

mXi=1

where γi is the i-th column of the matrix Γ. Let µ = µ − µ0, under the conditions

µ′ΣΣΣµ = o(

trΣΣΣ2),
λmax(ΣΣΣ) = o(√trΣΣΣ2),

1
n

we have

V ar(k ¯X − µ0k2) =  2

n

trΣΣΣ2 +

1
n

(EZ 4

1 − 3)

iγi)2! (1 + o(1)).

(γ′

mXi=1

Under the conditions (2.7) and (2.8), using moment method or martingale decomposition method, one
can prove that

k ¯X − µ0k2 − E(k ¯X − µ0k2)

pV ar(k ¯X − µ0k2)

→ N (0, 1)

(2.9)

To preform the test for the hypothesis H0 : µ = µ0 vs. H1 : µ 6= µ0, one need to construct ratio-
consistent estimators of E(k ¯X − µ0k2) and V ar(k ¯X − µ0k2) under the null hypothesis. It is obvious that
n tr2(S)(cid:1)
n trΣΣΣ can be estimated by 1
if EZ 4

n tr(S). As for the variance, it can be simply estimated by 1

1 = 3. In the general case, it can be estimated by 1

n(cid:0)tr(S2) − 1

n, where

n ˆσ2

1

ˆσ2
n =

1

(n)5 Xj1 ,··· ,j5

distinct

tr ((Xj1 − Xj2 )(Xj1 − Xj3 )′(Xj1 − Xj4 )(Xj1 − Xj5 )′) ,

(2.10)

where the summation is taken for all possibilities that j1 - j5 distinctly run over 1,··· , n, and (n)l =
n(n−1)··· (n−l+1). Using standard limiting theory approach, one may prove that ˆσ2
n is a ratio-consistent
estimator of σ2

n, where

σ2
n = 2trΣΣΣ2 + (EZ 4

1 − 3)

(γ′

iγi)2.

mXi=1

6

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

Therefore, the test reject H0 if

k ¯X − µ0k2 >

1
n

From this, it is easy to derive the asymptotic power for ANT as

tr(S) + ξαpˆσn → 0.
√nkµ − µ0k2

!

βAN T = Φ −ξα +
∼ Φ −ξα +
pσ2

pˆσ2
! .
√nkµ − µ0k2

n

n

Comparing the expressions of asymptotic powers of Hotelling test and ANT, one sees that the factor

√1 − y that appears in Hotelling’s test disappears from the ANT. Similarly, one may prove that the

NET has the same asymptotic power as ANT. This shows that ANT and NET have higher power than
T 2 test when y is close to 1.
Remark 1. In real calculation of ˆσ2
suming. To reduce the computing time, we should rewrite it as

n, the computation using the expression of (2.10) is very time con-

ˆσ2
n =

1
n

+

(X′

nXj=1
jXj)2 −
(n)3 Xj1 ,j2 ,j3

X′

distinct

6

4

(n)2 Xj1 ,j2

distinct

j1 Xj2 X′

j1 Xj3 −

X′

j1 Xj1 X′

j1 Xj2

3

(n)4 Xj1 ,j2 ,j3 ,j4

distinct

X′

j1 Xj2 X′

j3 Xj4 ,

(2.11)

where each summation runs over all possibilities that the indices involved are distinct. To further reduce
the time of computation, one may use the inclusion-exclusion principle to change the last three sums into
forms easier to compute, for example, the last sum can be written as

I4 = (X′X)2 − 2X′Xa − 4X′X(2)X + a2 + 2tr(X2

(2)) + 8X′X(3) − 6b,

where

X =

X(3) =

nXj=1
nXj=1

Xj,

a =

nXj=1

X′

j XjXj,

b =

X′

jXj, X(2) =

(X′

j Xj)2.

nXj=1

XjX′
j,

nXj=1

Here, the coeﬃcients of various terms can be ﬁnd by the following arguments: Let Aik denote the
restriction that ji = jk, i < k 6 4. For ease of arguments below, we consider Aik’s as the 6 edges
connecting the four vertices 1, 2, 3, 4; A12 and A34 called horizontal edges and the other 4 vertical edges.
The sum I4 is taken for ∩Ac
ik. By inclusion-exclusion principle, I4 can be calculated by the sum without
any restrictions, then subtract the sums restricted by one of Aik, then add the sums restricted by two
of Aik’s, and so on. It is obvious that the sum is (X′X)2 if j1,··· , j4 run from 1 to n freely. The sums
restricted by only one Aik; there are two cases, the two horizontal edges A12 or A34 give the second term,
i.e., the coeﬃcients is −2, say

X′

j1 Xj2 X′

j3 Xj4 =

XA12

nXj=1

nXj3=1

n1Xj4=1

X′

jXjX′

j3 Xj4 = aX′X;

For the other 4 vertical edges of the restrictions, one gets the coeﬃcient −4 for the third term. The
coeﬃcient 1 of the fourth term comes from the two horizontal restrictions A12 and A34; The coeﬃcient 2
for the ﬁfth term comes from pairs of two disconnected vertical Aik’s; There are 12 cases of two connected

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

7

restrictions give the coeﬃcient 12 of X′
(3)X; For the sums with three restrictions, there are two cases:
the three edges form a triangle which also gives the sum X′
(3)X; There are 4 possibilities which gives −4
to the coeﬃcients. Therefore, the coeﬃcients for X′
(3)X equals 12 − 4 = 8. There are other 16 cases of
three restrictions which imply all j1,··· , j4 are equal. Also, if there are more than three restrictions, the

indices j1,··· , j4 are also all equal; Thus, we get the coeﬃcient for b to be −16 +(cid:0)6

5(cid:1) + 1 = −6.

4(cid:1) −(cid:0)6

2.2 Chen and Qin’s approach

Chen and Qin (2010) [13] argued that the main term of Bai and Saranadasa’s ANT contains squared
terms of sample vectors that may cause the irrobustness of the test statistic against to outliers and thus
proposed an unbiased estimator of the target function kµ1 − µ2k2 given by
2

1

TCQ =

1

n1(n1 − 1)Xi6=j

X′

1iX1j +

n2(n2 − 1)Xi6=j

X′

2iX2j −

n1n2Xi,j

X′

1iX2j

Chen and Qin [13] proved that ETCQ = kµ1 − µ2k2 and under the null hypothesis

V ar(TCQ) =

2

n1(n1 − 1)

tr(ΣΣΣ2

1) +

2

n2(n2 − 1)

tr(ΣΣΣ2

2) +

4

n1n2

tr(ΣΣΣ1ΣΣΣ2)(1 + o(1)).

Similar to Bai and Saranadasa (1996), under the conditions

n1

n1 + n2 → κ

(µ1 − µ2)′ΣΣΣi(µ1 − µ2) = o(cid:0)n−1tr(ΣΣΣ1 + ΣΣΣ2)2(cid:1), for i = 1 or 2,

tr(ΣΣΣiΣΣΣjΣΣΣlΣΣΣh) = o(cid:0)tr2(ΣΣΣ1 + ΣΣΣ2)2(cid:1)
n−1tr(ΣΣΣ1 + ΣΣΣ2)2 = o(cid:0)(µ1 − µ2)′ΣΣΣi(µ1 − µ2)(cid:1), for i = 1 or 2,

or

(2.12)

(2.13)

(2.14)

Chen and Qin proved that

To perform the test for H0 : µ1 = µ2 with target function h(µ1, µ2) = kµ1 − µ2k2, they proposed the
estimator for the V ar(TCQ) by

TCQ − kµ1 − µ2k2

pV ar(TCQ)

D→ N (0, 1).

ˆσ2
n =

2

n1(n1 − 1)

\
tr(ΣΣΣ2

1) +

2

n2(n2 − 1)

\
tr(ΣΣΣ2

2) +

4

n1n2

\tr(ΣΣΣ1ΣΣΣ2),

where

\tr(ΣΣΣ2

i ) =

\tr(ΣΣΣ1ΣΣΣ2) =

1

ni(ni − 1)Xj6=k
n2Xk=1

n1Xj=1

n1n2

1

ik(Xij − ¯Xi(jk))X′
X′

ij (Xik − ¯Xi(jk)),

2k(X1j − ¯X1(j))X′
X′

1j(X2k − ¯X2(k)),

and ¯Xi(∗) denotes the sample mean of the i-th sample with vectors indicated in the braces excluded.

Applying the central limit theorem, Chen and Qin derived the asymptotic power functions for two

cases

βCQ ∼ 

Φ(cid:18)−ξα + nκ(1−κ)kµ1−µ2k2
√2tr(κΣΣΣ1+(1−κ)ΣΣΣ2)2(cid:19)
√2tr(κΣΣΣ1+(1−κ)ΣΣΣ2)2(cid:19)
Φ(cid:18) nκ(1−κ)kµ1−µ2k2

if (2.13) holds,

if (2.14) holds.

(2.15)

8

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

Remark 2. The expression of the asymptotic power under the condition (2.14) ((3.5) in Chen and
Qin [13]) may contains an error that the denominator of the quantity inside the function Φ should be σn2
(µ1 − µ2)′ΣΣΣ2(µ1 − µ2), instead
of σn1. Any way, the asymptotic power is 1 under the condition (2.14). So, the mistake doesn’t aﬀect
correctness of the expression of the asymptotic power. In fact, this can be see from the following facts:

in Chen and Qin’s notation, that is 2q 1

(µ1 − µ2)′ΣΣΣ1(µ1 − µ2) + 1

n1

n2

By the condition (2.12), we have

Therefore,

Consequently,

(µ1 − µ2)′ΣΣΣi(µ1 − µ2) 6 λmax(ΣΣΣi)kµ1 − µ2k2 6 o(cid:16)qtr(ΣΣΣ2

i )kµ1 − µ2k2(cid:17).

σ2

n2 6 o(cid:0)σn1kµ1 − µ2k2(cid:1).
>s σ2

n2
σ2
n1

o(σn1)

σn2

> M

kµ1 − µ2k2

>

σn2

for any ﬁxed constant M , where the last step follows from the condition (2.14). As for Chen and Qin’s
expression, one has

kµ1 − µ2k2

σn1

> kµ1 − µ2k2

σn2

> M.

For the one-sample location problem, Chen and Qin in 2010 [13] modiﬁed TBS and proposed a

TCQ =

1

n(n − 1)Xi6=j

X ′

iXj

and showed that under the condition trΣΣΣ4 = o(tr2ΣΣΣ2) (which is equivalent to (2.8)), as min{p, n} → ∞,

TCQ

q 2
n(n−1) tr(Pi6=j(Xi − ¯X(i,j))X′

i(Xj − ¯X(i,j))Xj )

D→ N (0, 1).

(2.16)

Note that the diﬀerence between statistics in (2.16) and that on the LHS of (2.9) with the denominator
was replaced by the estimator 1

n tr2S) is the denominators, which are the estimators of trΣΣΣ2.

n (trS2 − 1

Remark 3. It has been noted that the main part TCQ of Chen and Qin’s test is exactly the same as Bai
and saranadasa’s Mn because both of them are unbiased estimator of the target function kµ1 − µ2k2 and
functions of the complete and suﬃcient statistics of the mean vectors and covariance matrices for the two
samples. We believe that Chen and Qin’s idea of unbiased estimator of the target function helped them
to have proposed a better estimator of the asymptotic variance of the test so that their test performed
better than Bai and Saranadasa’s ANT. In addition, there is an improved statistic of Chen and Qin test
by thresholding methods recently, which is proposed by Chen et al.
in [12]. And Wang et. al in [46]
proposed a test for the hypothesis under elliptically distributed assumption, which can be viewed as a
nonparametric extension of TCQ.

2.3 Srivastava and Du’s approach

While agreeing the defect of the Hotelling test as indicated in [3, 15], Srivastava and Du (2008) [38] have
noted that NET and ANT are not scale invariant which may cause lower powerfulness when the scales
of diﬀerent components of the model are very diﬀerent. Thus, they proved the following modiﬁcation to
ANT by

TSD,1 = ( ¯X − µ0)′D−1

S ( ¯X − µ0),

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

9

where DS = Diag(s11,··· , spp) is the diagonal matrix of sample covariance matrix S. Let R be the
population correlation matrix. Then under conditions that

0 < lim
p→∞

lim
p→∞

trRi
p
λ(R)
√p

< ∞,

= 0,

for i = 1, 2, 3, 4;

n−3

2 < η 6 1,

as n → ∞,

D→ N (0, 1),

where R is the sample correlation matrix, i.e., R = D−1/2
showed that the asymptotic power of TSD,1 under the local alternative, as n → ∞,

SD−1/2

r2(cid:16)trR2 − p2

Srivastava and Du in [38] showed that if n ≍ pη and 1
nTSD,1 − (n−1)p
n−1(cid:17) cp,n
> ξ−α → Φ −ξα +
and the restriction for η relaxed to 0 < η 6 1. Further by excludingPn

nTSD,1 − (n−1)p
n−1(cid:17) cp,n

βSD = P

r2(cid:16)trR2 − p2

n(µ − µ0)′D−1
√2trR2

where DΣΣΣ is the diagonal matrix of population covariance matrix ΣΣΣ. Later Srivastava in [36] modiﬁed
the asymptotic results above to cases where the adjusting term cp,n1 in last test statistic replaced by 1
S (Xi − µ0) from

i=1(Xi − µ0)′D−1

TSD,1 and modifying DS, Park and Ayyala in [33] got another NTM test statistic:

and cp,n = 1 + trR2/p3/2. They

ΣΣΣ (µ − µ0)

! ,

n−3

S

S

TP A =

n − 5

n(n − 1)(n − 3)Xi6=j

X′

iD−1

S(i,j)

Xj

where DS(i,j) = Diag(s((i,j))

Xi and Xj, i.e., S(i,j) = (n − 3)−1Pk6=i,j (Xk − ¯X(i,j))′(Xk − ¯X(i,j)) and ¯X(i,j) = (n − 2)−1Pk6=i,j Xk.

Srivastava and Du have also considered the two-sample location problem with common covariance

) is the diagonal matrix of sample covariance matrix excluding

,··· , s((i,j))

pp

11

matrix ΣΣΣ in [38] and proposed the testing statistic

( ¯X1 − ¯X2)′D−1
Under similar conditions for the CLT of TSD,1, they proved that

TSD,2 =

n1 + n2

S ( ¯X1 − ¯X2)

n1n2

From this, they further derived the asymptotic power function

D→ N (0, 1)

(2.17)

n(cid:17) cn,p

n−2

TSD,2 − np

r2(cid:16)trR2 − p2
βSD(µ) ∼ Φ −ξα +

κ(1 − κ)µ′D−1
ΣΣΣ µ
√2trR2

! .

Remark 4. For the intuition as well as the proofs of Srivastava and Du, their theory would be strongly
depending on the assumption of normality. It is obvious that, if

then the LHS of (2.17) tends to ∞ and hence the conclusion of (2.17) cannot be true.

1
p

ETSD,2 −

(cid:12)(cid:12)(cid:12)(cid:12)

n

n − 2(cid:12)(cid:12)(cid:12)(cid:12) > δ > 0

10

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

Remark 5. The advantage of this statistic is that the terms Xi, DS(i,j) and Xj are all independent and
such that it is easy to get the expectation

ETP A = µ′D−1

ΣΣΣ µ,

which is the same as E(nTS−p(n − 1)/(n − 3)). This shows that both TSD,1 and TP A are NTM test based
on the target function µ′D−1
ΣΣΣ µ . The idea they used to exclude p(n − 1)/(n − 3) is similar to TCQ which
removes the bias estimator trS given in TBS. Park and Ayyala also gave the asymptotic distribution of
TP A under the null hypothesis, that is,

pn(n − 1)TP A
p2[trR2 → N (0, 1),

where [trR2 is a ratio-consistent estimator of trR2, i.e., [trR2/trR2 P→ 1, which has the form

[trR2 =

1

n(n − 1)Xi6=j

X ′

iD−1

S(i,j)

(Xj − ¯X(i,j))X′

j D−1

S(i,j)

(Xi − ¯X(i,j)).

And then they showed that the asymptotic power of the test TP A is the same as that of TSD. Recently,
Dong et al. in [17] gave an shrinkage estimator of the diagonal of the population covariance matrix DΣΣΣ1,
who shown that the shrinkage-based Hotelling test performs better when the dimension is larger than
the sample size.
Remark 6. If ΣΣΣ1 6= ΣΣΣ2, Srivastava et al. in [39] used D = DS1/ni+DS2/n2 to instead DS in TSD,2. If the
population covariance matrices are diagonal, Wu et al. in [48] construct a statistic obtained by summing
squared componentwise t-statistics for missing data and Dong et al.
in [17] propose a shrinkage-based
diagonal Hotellings test.

2.4 Cai et al’s idea

Cai et al in [9] have noted that all NTM tests associated with target functions by Euclidean distance or
Mahalanobis distance require a condition that

nkµk2/√p → ∞,

(2.18)

for distinguishing the null and alternative hypotheses with probability tending to 1. This condition does
not hold if only a few components of µ has the order O(1/√n) and all others are 0. So, they proposed
to use the L∞ norm, or equivalently, the Kolmogorov distance.

Indeed, Cai et al’s work gives a compensation to the case where

√n max

i6p |µi| → ∞.

(2.19)

Note that none of the conditions (2.18) and (2.19) implies the other. The condition (2.19) is weaker
than (2.18) only when the bias vector µ (= µ − µ0 or µ1 − µ2, respectively for the one- or two-sample
problems) is sparse.

Now, we introduce the work of Cai et al. in [7] which develops a NTM test based on the Kolmogorov

distance, that performs more powerful against sparse alternatives in the high dimensional setting.

Suppose ΣΣΣ1 = ΣΣΣ2 = ΣΣΣ and {X1, X2} satisfy the sub-Gaussian-type or polynomial-type tails condition,

Cai et al. proposed the test statistic

TCLX =

n1n2

n1 + n2

16i6p(cid:26)X 2
ωii(cid:27) ,

max

i

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

11

where dΣΣΣ−1( ¯X1 − ¯X2) := (X1, . . . ,Xp)′ and dΣΣΣ−1 := Ω = (ωij)p×p is the constrained l1-minimization for

inverse matrix estimator of ΣΣΣ−1. Here, the so-called constrained l1-minimization for the inverse matrix
estimator is deﬁned by

dΣΣΣ−1 = arg min

Ω=(ωij )nXij

|ωij|; subject to kSΩ − Ipk∞ 6 γno

where γn is a tuning parameter, that may generally be chosen as Cplog p/n for some large constant C.

For more details on the properties of l1-minimization estimators, the reader is referred to [5]. Under the
null hypothesis H0 and some spectral of the pupulation covariance matrix conditions, for any x ∈ R, as
min{n, p} → ∞,

P(TCLX − 2 log(p) − log log(p) 6 x) → Exp(cid:18)−

1
π

Exp(cid:16)−

x

2(cid:17)(cid:19) .

To evaluate the performance of their maximum absolute components test, they also prove the following
result:

Suppose that C−1

0 6 λmin(ΣΣΣ) 6 λmax(ΣΣΣ) 6 C0 for some constant C0 > 1; kp = O(pr) for some r 6 1/4;

maxi6p |µi|/√σii >p2β log(p)/n with β > 1/ mini(σiiωii) + ε for some ε > 0, then as p → ∞

PH1 (φα(Ω)) → 1,

where kp is the number of non-zero entries of µ.

2.5 MANOVA and Contrasts: more than two samples,

In this subsection, we consider the problem of testing the equality of several high dimensional mean
vectors, which is also called multivariate analysis of variance (MANOVA) problem. That is to test the
hypothesis:

H0 : µ1 = ··· = µk

vs H1 : ∃i 6= j, µi 6= µj.

(2.20)

If the samples are from normal distribution, MANOVA problem in this high-dimensional setting have
been considered widely in the literature, such as, among others, Tonda and Fujikoshi in [44] obtained
the asymptotic null distribution of the likelihood ratio test, Fujikoshi in [20] found the asymptotic null
distributions for the Lawley-Hotelling trace and the Pillai trace statistics, Fujikoshi et al [21] considered
the Dempster trace test, which is based on the ratio of the trace of between-class sample covariance
matrix to the trace of the within-class sample covariance matrix. Instead of investigating the ratio of
the traces of the two matrices, Schott in [34] proposed a test statistic based on the diﬀerence of the two
traces. Next we will introduce three NTM statistics which are the improvements from TSD, TCQ and
TCLX.

Recently, Srivastava and Kubokawa in [40] proposed a test statistic of testing the equality of mean
vectors of several groups with a common unknown non-singular covariance matrix. Denote by 1r =
(1, . . . , 1)′ an r-vector with all the elements equal to one and deﬁne

and

Y = (X11, . . . , X1n1, . . . , Xk1, . . . , Xknk ),
L = (Ik−1,−1k−1)(k−1)×k

E =



1n1
0
...
0

0

1n2
...
0

0

0
...
1nk

n×k

.

12

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

Then Srivastava and Kubokawa proposed the following test statistic

TSK =

tr(BD−1

S ) − (n − k)p(k − 1)(n − k − 2)−1

p2cp,n(k − 1)(trR2 − (n − k)−1p2)

,

S Y(In − E(E′E)−1E′)YD−1/2

where B = Y′E(E′E)−1L′[L(E′E)−1L′]−1L(E′E)−1E′Y, DS = Diag[(n− k)−1Y(In − E(E′E)−1E′)Y],
R = D−1/2
and cp,n = 1 + trR2)/p3/2. Notice that Diag[A] denotes the
diagonal matrix consisted by the diagonal elements of the matrix A. Under the null hypothesis and the
condition n ≍ pδ with δ > 1/2, TSK is asymptotically distributed as N (0, 1). Thus, as n, p → ∞,

S

PH0 (TSK > ξα) → Φ(−ξα).

Hence, by comparing the results in [38] and [36], it is easy to see that cp,n may be removable under some
conditions.

Hu et al. in [23] proposed a test motived by Chen and Qin test, that is

THB =

kXi<j

( ¯Xi − ¯Xj)′( ¯Xi − ¯Xj) − (k − 1)
kXi=1

ni(ni − 1) Xk16=k2

X′

1

ik1 Xik2 −

= (k − 1)

n−1
i

trSi

kXi=1

kXi<j

2

ninj Xk1,k2

X′

ik1 Xjk2 .

When k = 2, apparently it reduces to Chen and Qin’s test statistic. And they showed that as p → ∞
and n → ∞,

i<j kµi − µjk2

THB −Pk

pV ar(THB )

D→ N (0, 1).

and also proposed a ratio-consistent estimator of V ar(THB ) for the MANOVA test in their paper.

Cai and Xia in [9] has also extended their idea to the MANOVA case under homogeneous covariance

assumption, and proposed the following test statistic

TCX = max

16i6p X16j<l6k

ninj

ni + nj (X 2
ˆbii ) ,

jli

where dΣΣΣ−1( ¯Xj − ¯Xl) := (Xjl1, . . . ,Xjlp)′ and dΣΣΣ−1 := (ωij )p×p is the constrained l1-minimization for the

inverse matrix estimate of ΣΣΣ−1 and ˆbii are the diagonal elements of the matrix ˆB which is deﬁned by

Let

ˆB =

1

P ni − k

(Xij − ¯Xi)(Xij − ¯Xi)′bΣΣΣ

−1

niXj=1bΣΣΣ

kXi=1
( ¯X1 − ¯X2)i, . . . ,r nk−1nk

nk−1 + nk

( ¯Xk−1 − ¯Xk)i(cid:19) k(k−1)

−1

.

,

X ′
i =

1

ˆσii(cid:18)r n1n2

n1 + n2

2 ×1
where ˆσii is the estimate of the (i, i) entry of the covariance matrix ΣΣΣ. Let ˜ΣΣΣ : k(k−1)
be the
covariance matrix of Xi. Let ˜σ2 be the largest eigenvalue of ˜ΣΣΣ and d be the dimension of the eigenspace
i : 1 6 i < d′ be the positive eigenvalues of ˜ΣΣΣ arranged in a descending order and taking into
of ˜σ2. Let ˜σ2
account the multiplicities.

2 × k(k−1)

2

Under the null hypothesis H0 and some regularity conditions on the population covariance matrix, for

any x ∈ R, as min{n, p} → ∞,

PH0(TCX − 2˜σ2

1 log(p) − (d − 2)˜σ2

1 log log(p) 6 x) → exp(cid:18)−Γ−1(cid:18) d

2(cid:19) H(ΣΣΣ) exp(cid:18)−

x
2˜σ2

1(cid:19)(cid:19) ,

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

13

two-sample location problem, they also established a theorem to evaluate the consistency of their test:
i=1 I(µj−

where Γ is the gamma function and H = Q∞
µl 6= 0) = o(pr), for some r < 1/4 and maxi kδik2/√σii >p2σ2β log p with some β > 1/(mini σiiωii) + ε

0 6 λmin(ΣΣΣ) 6 λmax(ΣΣΣ) 6 C0 for some constant C0 > 1. If kp = maxj<l6kPp

for some constant ε > 0, then, as p → ∞,

i = 0 if i > d′. Similar to the

i=d+1(1 − ˜σ2

i
˜σ2
1

Suppose that C−1

)−1/2, where ˜σ2

PH1 (φα(Ω) = 1) → 1,

where δi = (µ1i − µ2i,··· , µk−1,i − µk,i)′.
2.6 Some related work on the tests of high-dimensional locations

There is another statistic proposed by Chen et al. in [11],

TRHT = ¯X′(S + λI)−1 ¯X, for λ > 0,

which is called regularized Hotelling T 2 test. The idea is to employ regularization techniques in the
nonparametric testing context. Speciﬁcally, regularization is introduced to stabilize the inverse of the
sample covariance matrix in (2.3) giving. It is proved that under the null hypothesis, for any λ > 0, as
p/n1 → y ∈ (0,∞)

1−p(1−λm(λ))/n(cid:17)
√p(cid:16)nTRHT /p −
(1−p/n+pλm(λ)/n)3 − λ m(λ)−λm′(λ)

1−λm(λ)

1−λm(λ)

(1−p/n+pλm(λ)/n)4

D→ N (0, 1),

p tr(S + λI)−1 and m′(λ) = 1

where m(λ) = 1
p tr(S + λI)−2. They also give an asymptotic approximation
methord to choose the degree of regularization λ. Recently, based on a supervised-learning strategy, Shen
and Lin in [35] proposed a statistic to pick up an optimal subset of features such that it maximizes the
asymptotic power of Hotelling T 2 test.

There is a so called Random Projection method which is proposed by Lopes et al.

in [28] and the
following papers [25, 43, 47, 49]. For Gaussian data, the procedure projects the high dimensional data
onto random subspaces of low enough dimensions so that the traditional Hotelling T 2 statistic may be
used. This method can be viewed as a two step procedure: First, a single random projection is drawn,
and is used to map the samples from the high-dimensional space to low-dimensional spaces. Second, the
Hotelling T 2 test is applied to a new hypothesis testing problem in the projected space. A decision is
then pulled back to the original problem by simply rejecting H0 whenever the Hotelling test rejects in
the projected spaces.

Some other related work on the tests of high-dimensional locations can be found in [4,10,18,19,24,29,45],

we will not discuss much in this paper.

3 NTM on covariance matrices

3.1 One-sample scatter test

The standard test for the scatters is to test the hypothesis H0 : ΣΣΣ = ΣΣΣ0 v.s H1 : ΣΣΣ 6= ΣΣΣ0. Because
ΣΣΣ0 is known, one can multiply ΣΣΣ−1/2
to the data set and then change the test to a simpler hypothesis
H0 : ΣΣΣ = Ip. The classical test for this hypothesis is the well known likelihood ratio which can be found
in any standard textbook, say Anderson (2003) [1]. The likelihood ratio test statistic is given by

0

TLR = trS − log det(S) − p.

When p is ﬁxed, the test based on TLR has many optimalities, such as the unbiasedness, consistency, etc.
However, similar to the Hotelling T 2 test, it has a fatal defect that it is not well deﬁned when p is larger
than n − 1. When p is large but smaller than n − 1, the null distribution is not very simple to use, even

14

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

under normality. The popularly used one is the Wilks theorem. However, when p is large, Wilks theorem
brings very serious error to the test, the size tends to close 1 as p tends to inﬁnity. A correction to the
likelihood ratio test based on the random matrix theory can be found in [2]. However, when p is large,
especially when p/n is close to 1, we believe that the asymptotic power will be low, similar to that for
the T 2 test. The idea of NTM can be applied to this hypothesis either. Now, we introduce the work by
Ledoit And Wolf in [26].

Ledoit and Wolf considered two hypotheses: H01 : ΣΣΣ = Ip and H02 : ΣΣΣ = aIp with a > 0 unknown.

Based on the idea of Nagao test (see Nagao (1973) [31]), they proposed two test statistics

V =

1
p

tr(S − Ip)2

and U =

1
p

tr  S

p trS − Ip!2

1

,

which can be viewed from the point of NTM as regarding S and 1
and a in the target functions

p trS as the estimators of parameters ΣΣΣ

h(ΣΣΣ) =

1
p

tr(ΣΣΣ − Ip)2

and h(ΣΣΣ, a) =

1
p

tr(cid:18)ΣΣΣ

a − Ip(cid:19)2

(3.1)

respectively. Notice that under the null hypothesis a = 1
p trΣΣΣ. They studied the asymptotic properties of
U and V under the large dimensional setting that p/n → c ∈ (0,∞) and ﬁnd that U to the hypothesis of
sphericity is robust against p is large, even larger than n. But V is not consistent against every alternative
and thus they proposed a new test statistic

Under the normality and the assumptions that

W =

1
p

tr(S − Ip)2 −

p

n(cid:20) 1

p

trS(cid:21)2

+

p
n

.

1
p

tr(ΣΣΣ) = α

1
p

tr(ΣΣΣ − αI)2 = δ2

1
p

tr(ΣΣΣj) → νj < ∞, for j = 3, 4,

They proved that:

(i) The law of large numbers

(ii) The CLT, if δ = 0

1
p
1
p

tr(S)

tr(S2)

P→ α
P→ (1 + c)α2 + δ2;

1

1

n α2#
n"
p tr(S) − α
p tr(S)2 − n+p+1
0# ,"
D→ N "0
4(cid:0)1 + 1
c(cid:1) α3

2α2

c

c + 5 + 2c(cid:1) α4#! .
4(cid:0)1 + 1
c(cid:1) α3
4(cid:0) 2

Based on these results, they derived that nU − p D→ N (1, 4). As for the inconsistency of the test based on
V can be seen from the following facts: When p is ﬁxed, by the law of large numbers, we have S → ΣΣΣ = Ip
and hence V = 1

p tr(S − Ip)2 P→ 0. However, when p/n → c > 0, we have

V =

1
p

tr(S)2 −

2
p

tr(S) + 1

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

15

P→ (1 + c)α2 + δ2 − 2α + 1 = cα2 + (α − 1)2 + δ2.
Since the target function is 1
p tr(ΣΣΣ − Ip)2 = (α − 1)2 + δ2, the null hypothesis can be regarded as (α −
1)2 + δ2 = 0 and the alternative can be considered as (α − 1)2 + δ2 > 0. But the limit of V has one
term more cα2 which is positive. Therefore, the test V is not consistent. In fact, it is easy to construct
a counterexample based on this limit: set

cα + (1 − α)2 + δ2 = c.

When δ = 0, the solution to the equation above is α = 1−c
the null α = 1 and the alternative α = 1−c
1+c .

1+c . That means, the limit of V is the same for

As for W , we have

W

P

→ cα2 + (α − 1)2 + δ2 − cα2 + c = c + (α − 1)2 + δ2.

When p is ﬁxed, they proved that as n → ∞
np
2

W P→ χ2

p(p+1)/2

or equivalently

nW − p P→

2
p

χ2
p(p+1)/2 − p

When p → ∞, the right hand side of the above tends to N (1, 4) which is the same as the limit when
p/n → c. This shows that the test based on W is robust against p increasing. Chen et al in [14] extended
the work to the case without normality assumptions.

Now rewrite the target functions (3.1) as

h1(ΣΣΣ) =

1
p

tr(ΣΣΣ − Ip)2 =

1
p

trΣΣΣ2 −

2
p

trΣΣΣ + 1

and

h2(a, ΣΣΣ) =

1
p

tr(cid:18)ΣΣΣ

a − Ip(cid:19)2

=

p trΣΣΣ)2

1

p trΣΣΣ2 − ( 1
( 1
p trΣΣΣ)2

.

Then under the normality assumption, Srivastava in [37] gave the unbiased and consistent estimators of
these parameters in last target functions, that are:

[1
trΣΣΣ =
p

1
p

trS and

\1
trΣΣΣ2 =
p

(n − 1)2

p(n − 2)(n + 1)(cid:18)trS2 −

(trS)2(cid:19) .

1

n − 1

Based on these estimators, he proposed the test statistics

TS1 =

\1
trΣΣΣ2 − 2
p

[1
trΣΣΣ + 1 and TS2 =
p

[1
p trΣΣΣ)2

\1
p trΣΣΣ2 − (
[1
p trΣΣΣ)2

(

,

and proved that under the assumption n ≍ pδ, 0 < δ 6 1, as {n, p} → ∞, we have asymptotically,

and

1
p

n

2(cid:18)TS1 −
2 TS2 −

tr(ΣΣΣ − Ip)2(cid:19) ∼ N (0, τ 2
! ∼ N (0, τ 2

p trΣΣΣ)2

p trΣΣΣ2 − ( 1
( 1
p trΣΣΣ)2

1 )

n

1

2 ),

16

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

1 = 2n

where τ 2
hypothesis, one can easily get

p (α2 − 2α3 + α4) + α2

2, τ 2

2 = 2n(α4α2

1−2α1α2α3+a3
2)

pα6
1

+ α2
2
α4
1

and αi = 1

p trΣΣΣi. Thus under the null

n
2

TS1

D→ N (0, 1) and

n
2

TS2

D→ N (0, 1).

Later Srivastava and Yanagihara in [41] and Srivastava et al. in [42] extended this work to the cases two
or more population covariance matrices and without normality assumptions respectively. Furthermore,
Cai and Ma in [8] showed that TS1 is rate optimal over this asymptotic regime.

3.2

Li and Chen’s test based on unbiased estimation of target function

Li and Chen (2012) in [27] considered the two-sample scatter problem, that is, testing the hypothesis
H0 : ΣΣΣ1 = ΣΣΣ2. They choose the target function as h(ΣΣΣ1, ΣΣΣ2) = tr(ΣΣΣ1 − ΣΣΣ2)2. They selected the test
statistic by the unbiased estimator of h(ΣΣΣ1, ΣΣΣ2) as

TLC = An1 + An2 − 2Cn1n2

where

Anh =

Cn1n2 =

+

1

1

X′

(X′

(nh)2Xi6=j
(nh)4 Xi,j,k,l
n1n2Xi,j
n1(n2)2Xi6=kXj

(X′

distinct

1

1

−

hiXhj)2 −

2

(nh)3 Xi,j,k

distinct

X′

hiXhjX′

hjXhk

hiXhjX′

hkXhl,

1iX2j)2 −

1

n2(n1)2Xi6=kXj

X′

2iX1j X′

1jX2k +

X′

1iX2jX′

2j X1k

1

(n1)2(n2)2Xi6=jXk6=l

X′

1iX2jX′

1kX2l.

Under the conditions A1 and A2, and for any i, j, k, l ∈ {1, 2},

tr(ΣΣΣiΣΣΣjΣΣΣkΣΣΣl) = o(tr(ΣΣΣiΣΣΣj)tr(ΣΣΣkΣΣΣl)),

we have

V ar(TLC) =

2Xi=1(cid:20) 4

n2
i

4
ni
8

+

+

n1n2

tr2ΣΣΣ2

i +

8
ni

tr(ΣΣΣ2

tr(Γ′

i(ΣΣΣ1 − ΣΣΣ2)Γi ◦ Γ′
tr2(ΣΣΣ1ΣΣΣ2),

i − ΣΣΣ1ΣΣΣ2)2
i(ΣΣΣ1 − ΣΣΣ2)Γi)(cid:21)

where A ◦ B = (aij bij) denotes the Hadamard product of the matrices A and B.

Li and Chen proved in [27] that

Li and Chen selected
under H0. Therefore, the test rejects H0 if

\pV ar(TCL) := 2

n1

An2 which is a ratio-consistent estimator ofpV ar(TLC )

TCL − tr(ΣΣΣ1 − ΣΣΣ2)2

pV ar(TLC )

An1 + 2
n2

D→ N (0, 1).

TLC > ξα(cid:18) 2

n1

An1 +

2
n2

An2(cid:19) .

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

17

3.3 Cai et al’s maximum diﬀerence test

Cai et al in [6] also applied their maximum elements of the diﬀerence of two sample covariance matrices
to test the hypothesis of the equality of the two population covariances. They deﬁned their test statistic
by

Mn = max

16i6j6p

Mij = max

16i6j6p

(sij1 − sij2)2

ˆθij1/n1 + ˆθij2/n2

,

where sijl is the (i, j)-th element of the sample covariance of the l-th sample, and

ˆθijl =

1
nl

nlXk=1(cid:2)(Xkil − ¯Xil)(Xkjl − ¯Xjl) − sijl(cid:3)2

1 6 i 6 j 6 p and l = 1, 2. Here, ˆθijl can be regarded as an estimator of the variance of sijl. Then, they
deﬁne the test by

where qα is the upper α quantile of the Type I extreme value distribution with the c.d.f.

φα = I(Mn > qα + 4 log p − log log p).

therefore

exp(cid:16) −

1
√8π

exp(−

x
2

)(cid:17),

qα = − log(8π) − 2 log log(1 − α)−1.

Under some sparse conditions on the diﬀerence of the population covariances ΣΣΣ1 − ΣΣΣ2 and some distri-
butional conditions, they proved that for any t ∈ R

P(M1 − 4 log p + log log p 6 t) → exp(cid:18)−

1
√8π

exp(cid:18)−

t

2(cid:19)(cid:19) .

As expected, Cai et al’s test is powerful when the diﬀerence of the two population covariances is spars
and hence it gives some compensation to Li and Chen’s test.

4 Conclusions and Comments

All the NTM procedures show a fact that the classical multivariate analysis are less powerful in some
parameter settings when the dimension of data is large. Thus, it is necessary to develop new procedures
to improve the classical ones. However, all NTM procedures developed up to date need some additional
conditions on the unknown parameters to guarantee the optimality of the new procedures, e.g., all proce-
dures based asymptotically normal estimations require that the eigenstructure of population covariance
matrix should not be too odd; and all NTM’s based on the Kolmogorov distance require the sparseness of
the known parameters. Therefore, we think, there is a strong need to develop some data based procedures
so that they are optimal in most of the cases.

J. Hu was partially supported by NSFC 11301063. Z. D. Bai was partially supported

Acknowledgements
by CNSF 11571067.

References

1 T. Anderson. An introduction to multivariate statistical analysis. Third Edition. Wiley New York, 2003.
2 Z. D. Bai, D. D. Jiang, J. F. Yao, and S. R. Zheng, Corrections to LRT on large- dimensional covariance matrix by

RMT. Ann. Statist. 37(6B): 3822–3840, 2009.

3 Z. D. Bai and H. Saranadasa. Eﬀect of high dimension: by an example of a two sample problem. Statistica Sinica,

6:311–329, 1996.

18

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

4 M. Biswas and A. K. Ghosh. A nonparametric two-sample test applicable to high dimensional data. Journal of

Multivariate Analysis, 123:160–171, 2014.

5 T. T. Cai, W. Liu, and X. Luo. A Constrained l1 Minimization Approach to Sparse Precision Matrix Estimation.

Journal of the American Statistical Association, 106(494):594–607, 2011.

6 T. T. Cai, W. Liu, and Y. Xia. Two-Sample Covariance Matrix Testing and Support Recovery in High-Dimensional

and Sparse Settings Journal of the American Statistical Association, 108(501):265–277, 2013.

7 T. T. Cai, W. Liu, and Y. Xia. Two-sample test of high dimensional means under dependence. Journal of the Royal

Statistical Society: Series B, 2014.

8 T. T. Cai and Z. Ma. Optimal hypothesis testing for high dimensional covariance matrices. Bernoulli, 19(5B):2359–

2388, 2013.

9 T. T. Cai and Y. Xia. High-dimensional sparse MANOVA. Journal of Multivariate Analysis, 131:174–196, 2014.

10 A. Chakraborty and P. Chaudhuri. A Wilcoxon-Mann-Whitney-type test for inﬁnite-dimensional data. Biometrika,

102(February):239–246, 2015.

11 L. Chen, D. Paul, R. Prentice, and P. Wang. A regularized Hotelling’s T (2) test for pathway analysis in proteomic

studies. Journal of the American Statistical Association, 106(496):1345–1360, 2011.

12 S. X. Chen, J. Li, and P. Zhong. Two-Sample Tests for High Dimensional Means with Thresholding and Data

Transformation. arXiv preprint arXiv:1410.2848, pages 1–44, 2014.

13 S. X. Chen and Y. L. Qin. A two-sample test for high-dimensional data with applications to gene-set testing. The

Annals of Statistics, 38(2):808–835, 2010.

14 Chen, S. X. Zhang, L. X. and Zhong, P. S. Tests for High-Dimensional Covariance Matrices Journal of the American

Statistical Association, 105(490):810–819, 2010.

15 Dempster, A. P. A high dimensional two sample signiﬁcance test. The Annals of Mathematical Statistics, 29(1):995–

1010, 1958.

16 Dempster, A. P. A signiﬁcance test for the separation of two highly multivariate small samples. Biometrics 16, 41-50.

1960.

17 K. Dong, H. Pang, T. Tong, and M. G. Genton. Shrinkage-based diagonal Hotelling T2s tests for high-dimensional

small sample size data. Journal of Multivariate Analysis, 143:127–142, 2016.

18 L. Feng. Scalar-Invariant Test for High-Dimensional Regression Coeﬃcients. (2005):1–19.
19 L. Feng and F. Sun. A note on high-dimensional two-sample test. Statistics & Probability Letters, 105:29–36, 2015.
20 Y. Fujikoshi. Multivariate analysis for the case when the dimension is large compared to the sample size. Journal of

the Korean Statistical Society, 33(1):1–24, 2004.

21 Y. Fujikoshi, T. Himeno, and H. Wakaki. Asymptotic results of a high dimensional MANOVA test and power
Journal of the Japan Statistical Society,

comparison when the dimension is large compared to the sample size.
34(1):19–26, 2004.

22 H. Hotelling. The generalization of student’s ratio. The Annals of Mathematical Statistics, 2(3):360–378, 1931.
23 J. Hu, Z. Bai, C. Wang, and W. Wang. On testing the equality of high dimensional mean vectors with unequal

covariance matrices. Annals of the Institute of Statistical Mathematics, pages 1–20, 2014.

24 M. Hyodo and T. Nishiyama. A one-sample location test based on weighted averaging of two test statistics in

high-dimensional data. 2014.

25 L. Jacob, P. Neuvial, and S. Dudoit. DEGraph : diﬀerential expression testing for gene networks. 2012.
26 O. Ledoit And M. Wolf Some hypothesis tests for the covariance matrix when the dimension is large compared to

the sample size The Annals of Statistics. Vol. 30, No. 4, 1081–1102, 2002.

27 J. Li and S. X. Chen two sample tests for high-dimensional covariance matrices. The Annals of Statistics 2012, Vol.

40, No. 2, 908940, 2012.

28 M. E. Lopes, L. Jacob, and M. J. Wainwright. A More Powerful Two-Sample Test in High Dimensions using Random

Projection. Advances in Neural Information Processing Systems, 1(2):1206–1214, 2011.

29 P. K. Mondal, M. Biswas, and A. K. Ghosh. On high dimensional two-sample tests based on nearest neighbors.

Journal of Multivariate Analysis, 141:168–178, 2015.

30 R. J. Muirhead. Aspects of multivariate statistical theory, volume 42. Wiley, 1982.
31 Nagao, H. On some test criteria for covariance matrix. Ann. Statist. 1 700–709, 1973.
32 G. Pan and W. Zhou. Central limit theorem for Hotelling’s T 2 statistic under large dimension. The Annals of Applied

Probability, 21(5):1860–1910, 2011.

33 J. Park and D. N. Ayyala. A test for the mean vector in large dimension and small samples. Journal of Statistical

Planning and Inference, 143(5):929–943, 2013.

34 J. R. Schott. Some high-dimensional tests for a one-way MANOVA. Journal of Multivariate Analysis, 98(9):1825–1839,

Oct. 2007.

35 Y. Shen and Z. Lin. An adaptive test for the mean vector in large-p-small-n problems. Computational Statistics &

Data Analysis, 89:25–38, 2015.

36 M. S. Srivastava. A test for the mean vector with fewer observations than the dimension under non-normality. Journal

Hu J & Bai Z.

Sci China Math

January 2015 Vol. 55 No. 1

19

of Multivariate Analysis, 100(3):518–532, Mar. 2009.

37 M. S. Srivastava. Some Tests Concerning the Covariance Matrix in High Dimensional Data. Journal of the Japan

Statistical Society, 35(2):251–272, 2005.

38 M. S. Srivastava and M. Du. A test for the mean vector with fewer observations than the dimension. Journal of

Multivariate Analysis, 99(3):386–402, Mar. 2008.

39 M. S. Srivastava, S. Katayama, and Y. Kano. A two sample test in high dimensional data. Journal of Multivariate

Analysis, 114:349–358, Feb. 2013.

40 M. S. Srivastava and T. Kubokawa. Tests for multivariate analysis of variance in high dimension under non-normality.

Journal of Multivariate Analysis, 115:204–216, 2013.

41 M. S. Srivastava and H. Yanagihara. Testing the equality of several covariance matrices with fewer observations than

the dimension. Journal of Multivariate Analysis, 101(6):1319–1329, July 2010.

42 M. S. Srivastava, H. Yanagihara, and T. Kubokawa. Tests for covariance matrices in high dimension with less sample

size. Journal of Multivariate Analysis, 130:289–309, 2014.

43 M. Thulin. A high-dimensional two-sample test for the mean using random subspaces. Computational Statistics &

Data Analysis, 74:26–38, 2014.

44 T. Tonda and Y. Fujikoshi. Asymptotic Expansion of the Null Distribution of LR Statistic for Multivariate Linear
Hypothesis when the Dimension is Large. Communications in Statistics - Theory and Methods, 33(5):1205–1220, Jan.
2004.

45 A. Touloumis, S. Tavar´e, and J. C. Marioni. Testing the mean matrix in high-dimensional transposable data. Bio-

metrics, 71(1):157–166, 2015.

46 L. Wang, B. Peng, and R. Li. A High-Dimensional Nonparametric Multivariate Test for Mean Vector. Journal of the

American Statistical Association, 1459(June 2015):00–00, 2015.

47 S. Wei, C. Lee, L. Wichers, G. Li, and J. Marron. Direction-projection-permutation for high dimensional hypothesis

tests. arXiv preprint arXiv:1304.0796, pages 1–29, 2013.

48 Y. Wu, M. G. Genton, and L. a. Stefanski. A multivariate two-sample mean test for small sample size and missing

data. Biometrics, 62(3):877–885, 2006.

49 J. Zhang and M. Pan. A high-dimension two-sample test for the mean using cluster. Computational Statistics and

Data Analysis, 97:87–97, 2016.

