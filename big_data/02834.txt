6
1
0
2

 
r
a

M
9

 

 
 
]

O
C

.
t
a
t
s
[
 
 

1
v
4
3
8
2
0

.

3
0
6
1
:
v
i
X
r
a

Inference and rare event simulation for stopped Markov processes

via reverse-time sequential Monte Carlo

Jere Koskela

Dario Span`o

j.j.koskela@warwick.ac.uk

d.spano@warwick.ac.uk

Mathematics Institute
University of Warwick

Coventry CV4 7AL

UK

Department of Statistics
University of Warwick

Coventry CV4 7AL

UK

Paul A. Jenkins

p.jenkins@warwick.ac.uk

Department of Statistics
University of Warwick

Coventry CV4 7AL

UK

March 10, 2016

Abstract

We present a sequential Monte Carlo algorithm for Markov chain paths with proposals
constructed in reverse time. This is advantageous when paths are conditioned to end in
a rare set. The reverse time proposal distribution is constructed by approximating the
ratio of Green’s functions in Nagasawa’s formula. These ratios can often be interpreted as
conditional sampling distributions of some co-ordinates given the others. The conditional
sampling distributions are typically much lower dimensional than the whole process, and
approximating them fully speciﬁes the proposal distribution. Hence the diﬃculty in designing
good SMC proposals in high dimension is greatly reduced. We illustrate our method on two
simple models, and derive the ﬁrst SMC inference algorithm for the spatial Λ-coalescent: a
very high dimensional model of spatially structured population genetics.

Keywords: intractable likelihood, rare event simulation, sequential Monte Carlo, spatial

Λ-coalescent, stopped Markov process, time-reversal

1

Introduction

Sequential Monte Carlo (SMC) is a very general technique for sampling from a sequence of
complicated distributions of increasing dimension and known pointwise up to a normalising
constant; for an introduction see e.g. Doucet et al. (2001); Liu (2001); Doucet and Johansen
(2011). Brieﬂy, a “cloud” of weighted particles is extended from one distribution to the next by
a combination of sequential importance sampling and resampling. Each set of weighted particles
then forms an empirical approximation of each subsequent distribution, provided adjacent dis-
tributions are suﬃciently similar. This is typically the case when interest is in inference from a
sequence of observations from e.g. a hidden Markov model, and thus SMC ﬁnds widespread use
in the ﬁltering literature (see e.g. Doucet et al. (2001); Liu (2001); Del Moral (2004); Fearnhead
(2008); Doucet and Johansen (2011), and references therein).

1

In this paper we present a SMC algorithm for sampling trajectories of Markov chains killed
at the ﬁrst hitting time of a terminal set with boundary T . Such Markov trajectories have a
wide range of applications, such as population genetics (Griﬃths and Tavar´e, 1994; Stephens
and Donnelly, 2000; De Iorio and Griﬃths, 2004a,b; Birkner and Blath, 2008; Hobolth et al.,
2008; Griﬃths et al., 2008; Birkner et al., 2011; Koskela et al., 2015), mathematical ﬁnance
(Casella and Roberts, 2008), neuroscience (Bibbona and Ditlevsen, 2013), physics (Del Moral
and Garnier, 2005; Johansen et al., 2006) and engineering (Blom et al., 2007; Lezaud et al.,
2010). In addition to end points given by a stopping time, the chains under consideration are
assumed to start in a random state given by its value at the ﬁrst exit time of an initial set with
boundary I. This problem is nonstandard in SMC (Fearnhead, 2008) because (1) the dimension
of a particle can be random and (2) an intermediate target distribution of interest, namely that
of a partially reconstructed chain conditioned on its eventual hitting of T , is usually unavailable.
In practice the intermediate target may be replaced with its unconditioned counterpart, in which
case the current importance weight of a particle is in very poor correlation with its ﬁnal weight.
This renders the resampling step of a SMC algorithm counterproductive. To circumvent this
problem, our algorithm consists of proposing trajectories in reverse time, started from T and
propagated until the ﬁrst hitting time of I. The distribution of the reverse-time process is
typically at least as intractable as the quantity of interest being estimated, but SMC techniques
are used to produce properly weighted particle ensembles for unbiased estimators and to heavily
mitigate the aforementioned problems.

While time-reversal has proved to be a successful tool for inference in population genetics (Grif-
ﬁths and Tavar´e, 1994; Stephens and Donnelly, 2000; De Iorio and Griﬃths, 2004a,b; Birkner
and Blath, 2008; Griﬃths et al., 2008; Hobolth et al., 2008; Birkner et al., 2011; Koskela et al.,
2015), and has also been used in rare event simulation (Frater et al., 1989; Anantharam et al.,
1990; Frater et al., 1990; Shwartz and Weiss, 1993) and physics (Jarzynski, 2006), its use in com-
bination with SMC has been limited to a few examples in population genetics (Chen et al., 2005;
Jenkins, 2012; Jasra et al., 2014; Koskela et al., 2015). It is in our opinion somewhat surprising
that such an approach has not been combined with SMC for more general inference in any other
area. The purpose of this paper is to demonstrate the usefulness of SMC proposals acting in
reverse time in estimating hitting probabilities of Markov chains, as well as other functionals of
stopped Markov trajectories. We will also clarify the contexts where a time-reversal approach
is advantageous, and provide a general method for designing backwards proposal distributions
based on approximating Nagasawa’s formula (see e.g. Section III.46 of Rogers and Williams
(1994)) for the law of the reverse-time process.

The method is fairly general but we can expect it to be particularly eﬃcient in contexts where

(i) the process of interest is high-dimensional and transitions only alter a small number of

components at a time.

(ii) One is interested in the probability of hitting a rare event (low-dimensional set T ) condi-

tional on an arbitrarily high-dimensional starting set I.

In such contexts, thanks to property (i) it is only necessary to come up with a distribution for
the co-ordinates which diﬀer between transitions, given the value of all other co-ordinates. This
dimensionality reduction can greatly reduce the diﬃculty of designing proposal distributions in
high dimension. See Proposition 1 in Section 3 for a precise formulation, and Sections 4, 5 and
6 for concrete examples.

Our method is reminiscent of existing forward-in-time SMC strategies known as multilevel SMC
(Del Moral, 2004; Chen et al., 2005; Jasra et al., 2014), against which our method should be
considered as a complementary rather than an alternative approach. Indeed, multilevel methods
are rather well-suited for contexts involving somewhat the opposite to the point (ii) above, i.e. a
low-dimensional entry set I and high-dimensional terminal set T .

2

The rest of the paper is laid out as follows. In Section 2 we review forwards-in-time SMC as well
as multilevel splitting, which is a popular alternative for estimating hitting probabilities in the
rare events setting. In Section 3 we present our reverse-time algorithm and Nagasawa’s formula
for distributions of reverse-time Markov chains as a tool for designing proposal distributions. In
Section 4 we make the general algorithm more concrete by the motivating example of Kingman’s
coalescent (Kingman, 1982). Section 5 consists of numerical examples of a queueing system and
a hyperbolic diﬀusion killed at a boundary, while Section 6 contains a novel application to a
very high-dimensional model for spatially structured population genetics. Section 7 concludes
with a discussion, and proofs are given in the Appendix.

2 Background and preliminaries

In this section we recall the basic SMC algorithm for estimating functionals of Markov chains.
In the following section we will specialise this generic algorithm to our particular choice of
reverse-time proposal. Since our reverse-time SMC is most advantageous when the initial set I
is typical and the terminal set T is rare under the law of the chain of interest, we also brieﬂy
present the competing approach of multilevel splitting for estimating rare event probabilities.
The interested reader is directed to e.g. Rubino and Tuﬃn (2009) and references therein for
more details on both methods.

We consider the canonical Markov chain

where Pµ is deﬁned via its ﬁnite dimensional distributions as

(cid:32)

∞(cid:89)

n=0

Ω :=

En, F :=

(cid:33)

∞(cid:79)

n=0

Fn, {Xn}∞

n=0, Pµ

n−1(cid:89)

Pµ(X0:n ∈ dx0:n) = µ(dx0)

P (xi, dxi+1).

,

(1)

(2)

i=0

Here x0:n := (x0, . . . , xn), and P is a given transition kernel. We assume both P and µ can
be evaluated pointwise. We do not assume that (1) is stationary or even has a stationary
distribution.
We now deﬁne three sets which specify our rare event problem. Let I ⊂ Ω be an entrance
set, and without loss of generality suppose µ(I) = 1. Let T ⊂ Ω be the target set and let
R ⊂ Ω be an overshoot set which is hit in ﬁnite time Pµ-almost surely. For a set A ∈ F, let
τA := inf{n ≥ 0 : Xn ∈ A} denote the hitting time of {Xn}∞
n=0 with initial distribution µ.
We are interested in estimating Pµ(τT < τR). Similar rare events in the case of in the case of
homogeneous Markov chains and recurrent overshoot sets were termed dynamic rare events by
Johansen et al. (2006).

2.1 Multilevel splitting

Multilevel splitting involves deﬁning a sequence of intermediate sets I = A0, A1, . . . , An = T
which interpolate between I and T in steps of reasonable probability. By interpolate we mean
that the sets must be hit by (1) in sequence, so that any trajectory reaches Aj−1 before Aj for
any j ∈ {1, . . . , n}. By the strong Markov property, the hitting probability of interest can then
be decomposed as

Pµ(τT < τR) =

. . .

x1∈A1

xj−1∈Aj−1

Pµ(τA1 < τR)

Pδxj−1

(τAj < τR)Pµ(XτA1:n−1

∈ dx1:n−1)

(cid:90)

(cid:90)

n(cid:89)

j=2

3

Any probability on the right hand side can now be estimated by naive Monte Carlo by as-
sumption, and all the probabilities can be estimated in the same simulation as follows: start
a collection of particles from I and let them evolve according to Pµ; let those particles which
reach an intermediate set Aj branch into a (typically random) number of particles which evolve
independently; count the number of particles which hit T before R, appropriately reweighted to
correct for bias introduced by the branching.

The asymptotic eﬃciency of multilevel splitting has been established (Glasserman et al., 1999)
and the algorithm is widely used, but in practice its eﬃciency is strongly dependent on the
choice of the intermediate levels and branching mechanism. Recent work on adaptive multilevel
splitting (C´erou et al., 2014) has reduced this design problem to specifying a score function
which maps the state space of interest onto R, with states mapped to higher numbers being
thought of as closer to the target event. However, designing good score functions can still be
diﬃcult, particularly when the state space is high-dimensional. Moreover, even well optimised
algorithms will still generate particles which hit R before T , and thus contribute zero weight to
the estimator. No computational eﬀort will be wasted in this way under our reverse-time SMC
scheme.

2.2 Sequential Monte Carlo

Sequential importance sampling consists of sampling from a sequence of proposal distributions to
build up a single, high-dimensional realisation. The proposals are typically not the conditional
distributions of the model of interest, and so samples must be reweighted by the Radon-Nikodym
derivative of the model and the proposal:

(cid:90)
(cid:90)
(cid:90)

Pµ(τT < τR) =

=

=

1{τT <τR}(x0:τT ∧τR)Pµ(dx0:τT ∧τR)

1{τT <τR}(x0:τT ∧τR)

1{τT <τR}(x0:τT ∧τR)

dPµ
dQη
µ(x0)
η(x0)

τT ∧τR−1(cid:89)

i=0

(x0:τT ∧τR)Qη(dx0:τT ∧τR)

P (xi, xi+1)
Q(xi, xi+1)

Q(xi, dxi+1).

Here Qη is a proposal distribution with initial law η and one-step transition kernel Q, and with
Pµ (cid:28) Qη.
Sequential Monte Carlo involves the combination of sequential importance sampling with a
resampling step, where particles and weights are built up in parallel. The weighted collection
can then be resampled at intermediary steps to discard particles with low weight and duplicate
promising ones with high weight. Good choices of Qη and resampling schedule can dramatically
reduce the variance of estimators, and achieve the same asymptotic eﬃciency as multilevel
splitting under mild conditions (C´erou et al., 2011). On the other hand, poor choices of Qη can
yield estimators with higher variance than naive Monte Carlo (Glasserman and Wang, 1997).
The optimal proposal is the law of the process conditioned on the event of interest, but computing
this law involves the quantity of interest so the optimal algorithm is unimplementable in practice.
The typical approach is to approximate the optimal proposal distribution using large deviations
(Sadowsky and Bucklew, 1990).

In the following section we show how the reverse-time approach can be used to design pro-
posal distributions based on the time-reversal of the process of interest. The distribution of the
time-reversal can be expressed via Nagasawa’s formula (3), which depends on unknown coeﬃ-
cients given by Green’s functions of the Markov chain under study. These Green’s functions are
typically at least as diﬃcult to compute as the quantity of interest, but we make progress by

4

introducing ad-hoc approximations to the Green’s functions and substituting them into Naga-
sawa’s formula. The closer the approximation to the true Green function, the more eﬃcient the
algorithm. Moreover, because the Green’s functions appear in (3) only as ratios, conditioning
arguments can often be used to cancel these ratios to a low-dimensional quantity that can be
approximated directly (c.f. property (i) in Section 1 and Proposition 1 in Section 3). This avoids
the need to design high-dimensional proposal distributions even when the state space is itself
high-dimensional.

In order to run a SMC algorithm one needs to design a resampling schedule as well as introduce
a proposal distribution, as without resampling the variance of estimators typically increases ex-
ponentially in the number of sequential steps (Doucet et al., 2001; Liu, 2001). In the context
of stopped processes resampling should take into account the weight of the particle and the
progress it has made towards the target set. This is achieved as in multilevel splitting: intro-
duce a sequence of intermediate sets; propagate all samples until they hit the next set; perform
resampling based on current weights once all particles have been stopped. This has been alterna-
tively termed multilevel SMC or stopping-time resampling in Section 12.2 of (Del Moral, 2004)
and in (Chen et al., 2005) respectively. A formal speciﬁcation of the multilevel SMC algorithm
with multinomial resampling for estimating hitting probabilities of Markov chains is given in
Algorithm 1.

The choice of resampling schedule also has a strong impact on the eﬃciency of the SMC al-
gorithm. Few theoretical guidelines are available, though developments have been made in
determining good schedules adaptively (C´erou et al., 2012; Jasra et al., 2014). In this paper we
neglect the problem of optimising the resampling schedule, and focus on obtaining good proposal
distributions from our reverse-time algorithm.

3 Time-reversal as a SMC proposal distribution

In this section we review some relevant facts about time-reversal of Markov chains and introduce
our generic SMC proposal distribution. Concrete examples are given in Sections 4, 5 and 6.

We deﬁne the time-reversal of (1) by extending the chain to the negative time-axis, and letting

(cid:32)−∞(cid:89)

−∞(cid:79)

n=0

En,

Fn,

(cid:111)−∞

(cid:110)(cid:101)Xn

n=0

(cid:33)

, (cid:101)Pν

denote the reverse-time chain. Note that the initial time-indices are set to 0 by convention,

and are not necessarily intended to coincide with the starting time of (1). The law(cid:101)Pν is again

n=0

deﬁned via its ﬁnite dimensional distributions as

(cid:101)Pν(dx0:−n) = ν(dx0)

(cid:101)P (xi, dxi−1).

−n+1(cid:89)

i=0

For simplicity we assume that all the transition kernels (resp. Green’s functions) are absolutely
continuous with respect to the same reference measure (e.g. Lebesgue or counting measure), and
we will use the same notation for both the kernels (resp. Green’s functions) and their densities.
The reverse transition kernel is related to its forward counterparts via Nagasawa’s formula

where for a measurable set A

G(µ, A) := Eµ

(cid:101)P (xi, xi−1) =
(cid:34)τT ∧τR(cid:88)

G(µ, xi−1)
G(µ, xi)

(cid:35)

1A(Xi)

=:

i=0

5

P (xi−1, xi),

(3)

(cid:90)

(cid:90)

I

A

g(x, y)dyµ(dx)

Algorithm 1 Multilevel SMC algorithm with multinomial resampling for Pµ(τT < τR).
Require: Particle number N , initial proposal distribution ν, proposal kernels {Qi}τT ∧τR−1

,

i=0

i=1 such that 0 < τ1 ≤ τ2 ≤ . . . ≤ τn = τT .

stopping times {τi}n
1: for j = 1 to N do
0 ∼ ν.
Sample X j
2:
Set wj = µ(X j
0 )
.
ν(X j
0 )
Set kj = 0.
Set ¯kj = 0.
Set Aj = j.

4:

3:

5:

6:
7: end for
8: Set ¯w = 0.
9: for i = 1 to n do
10:

2 then

k=1 wkδk.

if ESS(w1, . . . , wN ) < N

for j = 1 to N do

Sample Aj ∼(cid:80)N
Set ¯w =(cid:80)N

Set ¯kj = kAj .

end for

wk
N .

k=1

end if
for j = 1 to N do

(cid:16)

if ¯kj < τi ∧ τR then
Set kj = ¯kj + 1.
∼ Q
(cid:18)
Sample X j
kj
(cid:18)

Set wj = ¯w

X

P

Q

X

X Aj
¯kj

Aj
¯kj
Aj
¯kj

,X j
kj

,X j
kj

,·(cid:17)
(cid:19)
(cid:19) 1Rc

.

Set Aj = j.

end if
while kj < τi ∧ τR do

(cid:16)

kj−1,·(cid:17)
(cid:17)
(cid:17) 1Rc

.

Set kj = kj + 1.
∼ Q
(cid:16)
Sample X j
kj
(cid:16)
X j
kj−1,X j
kj
X j
kj−1,X j
kj

Set wj = wj

X j

Q

P

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

26:

27:

28:

end while

end for

29:
30: end for

return(cid:80)N

(cid:46) Initial particle locations.

(cid:46) Initial importance weights.

(cid:46) Time indices.

(cid:46) Ancestral indices are used for resampling.

(cid:46) Variable for storing mean weight when resampling.

(cid:46) Resample if the eﬀective sample size is too low.

(cid:46) Sample ancestral particle proportional to weights.

(cid:16)

X j
kj

(cid:17)

.

(cid:46) First step unless next level or R already hit.

(cid:46) Zero weight if the particle hits R.

(cid:46) Propagate until the next level or R is hit.

(cid:16)

X j
kj

(cid:17)

.

(cid:46) Zero weight if the particle hits R.

wj
N .

(cid:46) Unbiased estimator of Pµ(τT < τR).

j=1

is the Green’s function of (1), and Eµ denotes expectation with respect to Pµ. When A = {z}
is a null set (with respect to the reference measure) we deﬁne G(µ, z) via the Green’s density

(cid:90)

G(µ, z) :=

g(x, z)µ(dx),

I

which is assumed to exist. Reverse time proposal distributions akin to (3) have been studied
previously in (Birkner et al., 2011) for certain population genetic models.

The Green’s functions in (3) cannot be computed in most cases of interest, but their qualitative
behaviour can often be described. We assume that such a description is available, and that it
is possible to write down a family of tractable functions with similar qualitative behaviour. We

6

refer to these as approximate Green’s functions. It is not necessary for the match to be very
precise, though better approximations yield more eﬃcient SMC algorithms.

Our strategy for deﬁning an SMC proposal is as follows:

1. Design an approximate Green’s function (cid:98)G(µ, x) to be substituted into (3) to yield an
approximate reverse-time transition kernel (cid:98)P and a proposal Markov chain

(cid:32)−∞(cid:89)

−∞(cid:89)

En,

Fn,

(cid:111)−∞

(cid:110)(cid:98)Xn

(cid:33)

,(cid:98)Pν

(4)

n=0

n=0

n=0

where(cid:98)Pν is deﬁned from its ﬁnite dimensional distributions via (cid:98)P as before.
2. If necessary, modify (cid:98)Pν locally to incorporate ﬁrst hitting time constraints by preventing
(4) hits I in ﬁnite time with(cid:98)Pν-probability 1 so that the reverse-time chain terminates in

3. If necessary, introduce further local modiﬁcations to the proposal distribution to ensure

(4) from returning to T upon leaving it and from entering R at all.

ﬁnite time with certainty.

These steps can seem laborious because of their generality, but we will see in Sections 5 and 6
that they can be carried out in many cases of interest. Steps 2 and 3 could be incorporated auto-
matically and more eﬃciently by considering the time-reversal of an appropriately h-transformed
version of (1). However, the h-transform is typically intractable, whereas local modiﬁcations are
widely implementable and still result in eﬃcient algorithms when Pµ(τT < τR) (cid:28) 1. This is be-
cause the ratio of Green’s functions will drive the process away from T even without conditioning
on not returning to T .

Proposition 1 presents a practical way of designing approximate ratios of Green’s functions for
a wide class of models. For notational simplicity we assume a countable state space, but the
same argument holds for continuous state spaces provided the Green’s densities g(x, z) exist.

Proposition 1. Consider a transition of the Markov chain (1) from xi−1 to xi, and suppose the
state space can be partitioned so that xi−1 = (z, y) and xi = (z, ¯y). Assume that the conditional
sampling distribution (CSD)

π(y|z) := Pµ(Yi = y|Zi = z)

is independent of i ∈ N for Pµ-almost every z. Then the ratio of Green’s functions in (3) cancels
to the ratio of CSDs:

G(µ, (z, y))
G(µ, (z, ¯y))

=

π(y|z)
π(¯y|z)

.

Remark 1. The hypothesis of Proposition 1 can be seen as a weak conditional stationarity
condition, and is relatively mild. However, since we are only interested in ad hoc approximations
to the true ratio of Green’s functions, it is possible to extend the scope of the reverse-time

even when Proposition 1 fails. Because of their lower dimension, approximate CSDs are often
much easier to design than either proposal kernels {Q(·,·)} or approximate Green’s functions

framework by deﬁning the proposal distribution based on a family of approximate CSDs(cid:98)π(y|z)
{(cid:98)G(µ,·)}. Indeed, we consider this dimensionality reduction in the design task one of the main
Choosing a family of approximate CSDs {(cid:98)π(·|·)} and applying Proposition 1 to (3) yields proposal

advantages of the reverse-time framework.

transition probabilities of the following form

(cid:98)P (x, y) = (cid:98)π(y \ x|y ∩ x)
C(x)(cid:98)π(x \ y|x ∩ y)

P (y, x),

7

where C(x) is a normalising constant, x ∩ y is the vector of co-ordinates for which xi = yi,
and by x \ y the vector of co-ordinates of x for which xi (cid:54)= yi. The corresponding incremental
importance weights are given as

C(x)(cid:98)π(x \ y|x ∩ y)
(cid:98)π(y \ x|x ∩ y)

.

wj = wj−1

Once a proposal chain has been constructed, the hitting probability of a ﬁxed p ∈ T can be
unbiasedly estimated as

N(cid:88)

j=1

dPµ

d(cid:98)Pδp

(x(j)

0:τ (j)

p

) =

1
N

µ(x(j)
0 )

j=1

i=1

p(cid:89)

τ (j)

(cid:98)π(x(j)
i−1 \ x(j)
(cid:98)π(x(j)
i \ x(j)

i

|x(j)
i ∩ x(j)
i−1)
i−1|x(j)
i ∩ x(j)
i−1)

C(x(j)

i ),

(5)

Pµ(τp < τR) ≈ 1
N

N(cid:88)

(cid:90)

T

}N
where {x(j)
j=1 is a sample from the SMC algorithm that uses (4) as its proposal mechanism.
τ (j)
p :0
This pointwise estimator can be used to construct estimators of more complicated quantities,
such as non-singleton target sets:

Pµ(τT < τR) =

Pδp(τp < τR)µ(dp),

(6)

whenever the relevant integral can be approximated from pointwise estimates (5), e.g. by using
further Monte Carlo methods or deterministic quadrature.

Remark 2. Approximating the integral in (6) can be a computationally daunting task if T
is high-dimensional or has large Lebesgue-volume, which is the rationale for property (ii) in
Section 1. In such cases we do not expect the reverse-time approach to always be competitive
with the forwards-in-time algorithms outlined in Section 2, particularly if the initial set I is also
small and hence diﬃcult for the reverse-time chain to hit. An example of when the reverse-time
approach is advantageous even in the presence of a high-dimensional integration akin to (6) is
presented in Section 6.

Remark 3. Normalising constants C(x) in (5) would all be identically equal to one if an
algorithm using the true CSD could be implemented. Thus, the realised values of these constants
for a given approximate CSD could be used to design proposal distributions adaptively from
trial runs, at least for discrete systems where the constants can easily be computed. We do not
explore this possibility further in this paper.

We conclude this section with a formal speciﬁcation of our reverse-time SMC algorithm, to be
contrasted with Algorithm 1.

4 Kingman’s coalescent

The success of importance sampling based on time-reversal for coalescent processes is well docu-
mented, and indeed was the motivation for this work. In this section we present the motivating
example of the ﬁnite-alleles Kingman’s coalescent, with the purpose of making the sets I, T
and R and the dimensionality reduction of Proposition 1 more concrete. We refer to the exist-
ing literature on simulation and inference for coalescent processes (Griﬃths and Tavar´e, 1994;
Stephens and Donnelly, 2000; De Iorio and Griﬃths, 2004a,b; Chen et al., 2005; Birkner and
Blath, 2008; Griﬃths et al., 2008; Hobolth et al., 2008; Birkner et al., 2011; Jenkins, 2012;
Koskela et al., 2015) for details and simulation results.
Let [d] := {1, . . . , d} be a ﬁnite set of genetic types, let n ∈ Nd denote a vector of type counts with
h=1 nh, and let eh denote the canonical unit vector with 1 in the hth position

total count n =(cid:80)d

8

Algorithm 2 Reverse-time multilevel SMC algorithm for Pµ(τx < τR).

Require: Particle number N , approximate conditional distributions {(cid:98)π(·|·)}, stopping times

{τi}1

i=n such that 0 < τn ≤ τn−1 ≤ . . . ≤ τ1 = τI .

3:

4:

5:

11:

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

22:

23:

24:

25:

26:

27:

28:

1: for j = 1 to N do
2:

Set X j
0 = x.
Set wj = 1.
Set kj = 0.
Set ¯kj = 0.
Set Aj = j.

6:
7: end for
8: Set ¯w = 0.
9: for i = n to 1 do
10:

2 then

k=1 wkδk.

if ESS(w1, . . . , wN ) < N

for j = 1 to N do

Sample Aj ∼(cid:80)N
Set ¯w =(cid:80)N

Set ¯kj = kAj .

end for

wk
N .

k=1

end if
for j = 1 to N do
if ¯kj < τi then

Aj
¯kj

·\X

X j
kj

kj
Aj
¯kj

Aj
¯kj
Aj
¯kj
∩X

(cid:18)
(cid:18)
(cid:18)

Aj
¯kj
Aj
X
¯kj
\X j
kj
\X

(cid:12)(cid:12)·∩X
\·(cid:12)(cid:12)·∩X
(cid:12)(cid:12)X j
(cid:12)(cid:12)X j
(cid:12)(cid:12)·∩X j
(cid:16)·\X j
kj−1\·(cid:12)(cid:12)·∩X j
∼ (cid:98)π
(cid:16)
(cid:12)(cid:12)X j
(cid:98)π
(cid:16)
(cid:12)(cid:12)X j
(cid:98)π
X j
(cid:16)
kj−1\X j
X j
(cid:98)π
X j
kj

kj
kj
\X j
kj

kj−1

kj

Sample X j
kj

Set kj = ¯kj + 1.
∼ (cid:98)π
(cid:98)π
(cid:18)
(cid:98)π
(cid:98)π

Set wj = ¯w

X

Set Aj = j.

end if
while kj < τi do

Set kj = kj + 1.

Sample X j
kj

Set wj = wj

end while

end for

29:
30: end for
31: for j = 1 to N do
Set wj = wjµ

(cid:16)

(cid:17)

.

X j
kj

32:
33: end for

return(cid:80)N

wj
N .

j=1

(cid:46) Initial particle locations.
(cid:46) Initial importance weights.
(cid:46) Time indices.

(cid:46) Ancestral indices are used for resampling.

(cid:46) Variable for storing mean weight when resampling.

(cid:46) Resample if the eﬀective sample size is too low.

(cid:46) Sample ancestral particle proportional to weights.

(cid:46) First step if next level not yet hit.

(cid:19)
(cid:19) 1T c∩Rc(·). (cid:46) C is a normalising constant.
(cid:19)

.

(cid:46) Weights are always positive.

·,X

(cid:19)
(cid:18)
(cid:19) P
(cid:18)
(cid:18)
(cid:19)
(cid:19)

Aj
C
¯kj
∩X

X

C

Aj
¯kj

Aj
¯kj
Aj
¯kj

X

Aj
¯kj

(cid:46) Propagate until the next level is hit.

(cid:17)
(cid:17) 1T c∩Rc(·).
(cid:17)

(cid:17)
(cid:17) P

(cid:16)·,X j
(cid:16)
(cid:16)
(cid:17)
(cid:17)

X j

C

kj−1

C

kj−1
∩X j

kj

kj−1
kj−1
∩X j

kj−1
kj−1
X j

kj−1

.

(cid:46) Account for entrance law µ.

(cid:46) Unbiased estimator of Pµ(τT < τR).

and zeros elsewhere. Let M := (Mhh(cid:48))d
the allele resulting from a mutation event, and let θ > 0 be a mutation parameter.

h,h(cid:48)=1 be a stochastic matrix encoding the distribution of

A common way of realising paths of the coalescent is by means of a continuous time Markov
process X = (Xt)t≥0. Assume X starts from a single lineage whose type is drawn from an initial
distribution µ on [d]. At time 0+ this most recent common ancestor (MRCA) splits into two
lineages. From here, every lineage splits into two with rate (n − 1)/2 when there are n lineages,

9

each inheriting the type of the parent, and independently each lineage mutates at rate θ/2 with
mutations drawn from M . These forwards dynamics can be written as

P (n − eh, n) =
P (n − eh + eh(cid:48), n) =

nh − 1
n − 1 + θ
n − 1 + θ

θ

for h ∈ [d],
nh(cid:48) + 1 − δhh(cid:48)

n

Mh(cid:48)h for h, h(cid:48) ∈ [d].

In a slight abuse of notation we henceforth denote by X = {Xk}k∈N the jump skeleton of this
Markov process. We also remark that as the state space of X is increasing in dimension, it
cannot possibly have a stationary distribution or be reversible.
In order to introduce the three sets of interest we deﬁne the family of stopping times {τn}n≥2
as the ﬁrst time X reaches a given sample size:

τn := inf{k ∈ N : |Xk| = n}.

The three sets deﬁning the bridge of interest are

I = {eh : h ∈ [d]}, the MRCA,
T = {Xτn+1−1 = n∗}, a ﬁxed conﬁguration of n types immediately before the nth branch,
R = {m ∈ Nd : |m| = n + 1}, any conﬁguration of n + 1 lineages.

The Green’s functions G(µ, n) are intractable in all cases except the parent-independent muta-
tion model in which M has identical rows. In typical settings the values of both n and d are

at least several hundred, so designing an approximate Green’s function (cid:98)G(µ, n) that bears any

resemblance to the truth would be a formidable task. However, we can apply Proposition 1 to
write

G(µ, n − eh + eh(cid:48))
G(µ, n)
G(µ, n − eh)

G(µ, n)

π(eh(cid:48)|n − eh)
π(eh|n − eh)
π(eh|n − eh)

1

.

=

=

All possible transitions of the process are of one of these two forms, so that an approximation

(cid:98)π(·|n) is all that is needed to deﬁne a proposal distribution. Such approximate conditional sam-

pling distributions are an active area of research in population genetics (Stephens and Donnelly,
2000; Fearnhead and Donnelly, 2001; Li and Stephens, 2003; De Iorio and Griﬃths, 2004a,b;
Paul and Song, 2010; Paul et al., 2011; Sheehan et al., 2013; Steinr¨ucken et al., 2013; Koskela
et al., 2015).

Given an approximate conditional sampling distribution(cid:98)π(·|·), the approximately optimal pro-

posal distribution can be written as (c.f. Theorem 1, Stephens and Donnelly (2000))

(cid:98)P (n, n − eh) =
(cid:98)P (n, n − eh + eh(cid:48)) =

nh − 1
n − 1 + θ

θ

n − 1 + θ

nh
n
nh
n

1

(cid:98)π(eh|n − eh)
(cid:98)π(eh(cid:48)|n − eh)
(cid:98)π(eh|n − eh)

for h ∈ [d],

Mh(cid:48)h for h, h(cid:48) ∈ [d].

5 Numerical examples

In this section we present two numerical simulations illustrating the reverse-time approach: the
hyperbolic diﬀusion (Section 5.1) and the asynchronous transfer mode (ATM) network (Section
5.2). These examples would be tractable under existing, forwards-in-time algorithms, but are

10

included to make our reverse-time scheme more concrete. In contrast, the application to the
spatial Λ-coalescent in Section 6 is very high dimensional, and we are not aware of any forwards-
in-time algorithm which would remain feasible for non-trivial data sets. It also incorporates an
outer integration akin to (6) over a very large space, providing an example where this approach
is practical.

5.1 The hyperbolic diﬀusion

The one-dimensional hyperbolic diﬀusion is the solution of the SDE

−Xt(cid:112)1 + X 2

t

dXt =

dt + dWt,

(7)

where (Wt)t≥0 is a Brownian motion. It was introduced by Barndorﬀ-Nielsen (1978) in con-
nection to hyperbolic distributions in geostatistical modelling (Barndorﬀ-Nielsen, 1977), and its
heavier-than-normal tails have also made it a popular model in mathematical ﬁnance (Bibby
and Sørensen, 2003).

The transition probabilities of the diﬀusion are intractable, but the stationary distribution is
known to be the hyperbolic distribution

π(x) =

1

2K1(1)

e−√

1+x2,

(8)

where K1 is the modiﬁed Bessel function of the second kind. We focus on estimating the hitting
probability of a level b > 0 before returning to 0, given X0 = 0. The sets deﬁning the bridge are

I = R = {0},
T = {b}.

We consider a discretisation of (7) and use the Euler scheme with grid spacing ∆ to deﬁne a
family of approximate transition densities forwards in time:

(cid:32)

(cid:26)

(cid:27)(cid:21)2(cid:33)

P∆(x, y) =

1√
2π∆

exp

− 1
2∆

y − x

1 −

∆√
1 + x2

.

(9)

(cid:18)(cid:90) 0

(cid:98)P∆(y, x) ∝

π(z)
π(y)

−∞

Note that in this case (9) is also the Milstein scheme because of the unit diﬀusion coeﬃcient.
We can use the discretised transition density (9) and the unconditional stationary distribution
(8) to deﬁne a discretised reverse-time proposal:

P∆(z, y)dz

δ0(x) +

π(x)
π(y)

P∆(x, y)1[0,b)(x).

(cid:17)

(cid:16)
with probability e−√

1+x2

1 − ∆√

This family of proposal distributions can be normalised numerically, and sampled by proposing
from a N (y, ∆) proposal distribution, solving for x and accepting the proposal
x
1+x2. In the above deﬁnition, we have incorporated Step 2 of our strategy
(see page 6) by automatically rejecting proposed values greater than or equal to b, while step 3
is implemented by setting any accepted value below 0 equal to 0.
We also employ stopping-time resampling with trajectories stopped upon falling below {b −
β(cid:99)β}. Resampling is performed once all trajectories have been stopped if the
β, b − 2β, . . . , b − (cid:98) b
eﬀective sample size is less than half the number of trajectories.

Figure 1 presents estimated probabilities of excursions hitting a given level before returning
to zero. Note that the quality of the estimators increases with barrier height because the

11

(cid:20)

(cid:19)

Figure 1: Simulated hitting probabilities of a hyperbolic diﬀusion discretised with ∆ = 0.01 and
β = 0.1. An independent simulation of 500 particles was run for each value of b on an Intel
i5-2520M 2.5 GHz processor. Each simulation is labelled with an eﬀective sample size (above)
and run time (below).

truncated stationary distribution becomes a more accurate proxy for the true stationary law.
This compensates for the increase in problem diﬃculty, at least for the investigated range of
barriers. The increased computational cost is due almost entirely to the fact that the acceptance
1+x2 decays exponentially in x, so that many more proposal loops are needed

for high values of x. A more uniformly eﬃcient method for simulating from (cid:98)P would yield run
probability e−√

times which increase only weakly as a function of b.

5.2 The asynchronous transfer mode network

Our second example is the ATM network studied by Glasserman et al. (1999) in the context of
rare events. The network consists of N sources, each of which is either on or oﬀ. Sources which
are oﬀ do nothing, while sources which are on produce packets at rate λ. Packets are serviced
by a common server with rate µ using the ﬁrst-in-ﬁrst-out policy. Oﬀ sources turn on at rate α0
and on sources turn oﬀ at rate α1. The state of the system is speciﬁed as (i, j) ∈ N0×{0, . . . , N},
where i denotes the number of packets in the queue and j the number of on sources.

In (Glasserman et al., 1999) the authors estimated the probability of the queue length hitting a
barrier b ∈ N before emptying, given an empty initial queue and N α0/(α0 + α1) open sources.
Reverse-time SMC could be used for this example by summing over all possible numbers of
terminal open sources akin to (6), but this results in an N -fold increase in computational burden
and hence cannot be expected to be competitive with a forwards-in-time approach in this case.
We focus instead on the joint probability of an initially empty queue hitting a barrier b before

12

lllllllllllllllllll5.05.56.06.5−8−7−6−5−4−3Barrier blog (base 10) hitting probability9111413113913813313313912914713513814613712614314122540965s73s78s85s85s92s98s106s121s123s141s143s150s155s167s191s190s220s234semptying with exactly k sources open at the hitting time, and assume the initial number of
open sources is Bin(N, α0/(α0 + α1)) distributed. In this scenario a forwards-in-time algorithm
would face the same diﬃculties as a reverse-time algorithm does in the scenario of Glasserman
et al. (1999).

The three sets which deﬁne our bridge of interest are

N(cid:91)

I = R =

{(0, j)}

j=0

T = {(b, k)}

(cid:18)N

(cid:19)(cid:18) α0

(cid:19)j(cid:18) α1

j

α0 + α1

α0 + α1

(cid:19)N−j

.

and the initial law is

µ({(0, j)}) =

we choose them to be

To deﬁne our proposal distribution it is only necessary to specify approximate conditional dis-

tributions of i given j and j given i. These are denoted by(cid:98)πi(i|j) and(cid:98)πj(j|i) respectively, and
(cid:18) λj
(cid:19)i
(cid:98)πi(i|j) ∝
(cid:18)N
(cid:98)πj(j|i) ∝(cid:98)πi(i|j)

for i ∈ {0, . . . , b} and j ∈ {0, . . . , N}.

for i ∈ {0, . . . , b} and j ∈ {0, . . . , N},

(cid:19)j(cid:18) α1

(cid:19)(cid:18) α0

(cid:19)N−j

µ

j

α0 + α1

α0 + α1

The former is the true distribution of a queue with arrival rate λj and service rate µ whenever
µ > λj, and well-deﬁned otherwise as well because the range of possible values of i is ﬁnite. The
latter is obtained from the former via Bayes’ rule.

We also employ stopping time resampling again, with simulations stopped every time a new
minimum queue length is reached in reverse time. Once all simulations have been stopped,
resampling takes place if the eﬀective sample size is below half of the number of particles.

Figure 2 presents simulated hitting probabilities of a queue length of 30 across all possible ﬁxed
numbers of terminal on sources. Despite some residual noise the shape and magnitude of the
surface can be distinguished clearly, and again the eﬀective sample size shows at most weak
decay as the estimated probability decreases.

6 The spatial Λ-coalescent

In Section 4 we gave a construction of Kingman’s coalescent as a labelled process splitting
out from a most recent common ancestor (MRCA). This is in contrast to the more classical
construction from the leaves to the root, in which each pair of n ∈ N lineages (with no assigned
types) merge with rate 1. Types are sampled conditional on the realised tree by picking an
ancestral type from a desired distribution, and then running the Poisson process of mutations
with rate θ/2 and jump matrix M along the branches of the coalescent tree.

In this section we present the spatial Λ-coalescent, which is a generalisation of Kingman’s coa-
lescent for structured populations in a spatial continuum. In this setting the coalescent process
from the leaves to the root is far more transparent, so we begin the section with a description of
it. We will then introduce another lookdown particle system, which embeds the coalescent and
will play the role of the process splitting out from the MRCA. We emphasize that these two
processes propagate in diﬀerent directions of time, and it is the lookdown system which will be
the subject of our reverse-time algorithm.

13

Figure 2: Simulated hitting probabilities of an ATM network with parameters N = 20, b = 30,
λ = 0.5, µ = 10.0, α0 = 1.0, α1 = 3.0. An independent simulation of 500 000 particles was run
for each value of k for a runtime of around 20 minutes for each k on an Intel i5-2520M 2.5 GHz
processor. Particles are labelled with their corresponding eﬀective sample sizes.

The spatial Λ-coalescent was introduced by Etheridge (2008) and Barton et al. (2010) as a model
for genealogies of samples from a population structured across a continuous, two-dimensional
geography, which we take to be a torus of side length L > 0 denoted by T(L). In the same
notation as in Section 4 let [d] be the set of genetic types, θ > 0 be the mutation rate and
M := {Mij}d
i,j=1 be a stochastic matrix governing mutation jumps. We assume M has a unique
stationary distribution m. Let z1:n ∈ T(L)n be ﬁxed, distinct sampling locations, and let h1:n
denote a corresponding conﬁguration of sampled types, each hi from the ﬁxed location zi. We
have assumed locations are distinct for simplicity.
The dynamics of the spatial Λ-coalescent are driven by a Poisson process Π on R × T(L) with
rate dt ⊗ dx. The points (t, x) ∈ Π model extinction-recolonisation events, with the two co-
ordinates specifying the time and place of the event respectively. Tracing backwards in time, at
each point (t, x) ∈ Π all lineages within Br(x), a closed ball of radius r > 0 centred at x, ﬂip a
coin with success probability u ∈ (0, 1]. Successful lineages merge to a common ancestor with
location sampled uniformly from Br(x), while lineages which fail their coin ﬂip are unaﬀected
by the event. Once the whole sample has coalesced to a single lineage (the MRCA), an ancestral
type is sampled from m and the mutation process is propagated at rate θ along the branches of
the coalescent tree according to the stochastic matrix M . The types and locations of the leaves
specify a labelled sample h1:n at speciﬁed locations z1:n.

Since it models ancestral trees, the coalescent described above is already a process in reverse
time from the point of view of the reproductive evolution of the population. However, it can
be embedded in a forwards-in-time particle system, provided we ﬁrst condition on a realisa-

14

llllllllllllllllllll05101520−26−24−22−20−18Number of terminal on−sourceslog (base 10) hitting probability49074977788247605754632865695797384458569576447257523464655642922442431826114121tion (ti, xi)∞
i=−∞ of Π. This lookdown construction of the quenched spatial Λ-coalescent was
introduced by V´eber and Wakolbinger (2015), and we recall their particle system brieﬂy below.
Let N0 be a Poisson point process on T(L) × [d] × R+ with intensity dx ⊗ m(h) ⊗ dl and let
(zi, hi, li)∞
i=1 denote the resulting (a.s. inﬁnite) particle conﬁguration. The ﬁrst two co-ordinates
correspond to locations and types as before. The ﬁnal co-ordinates remain ﬁxed forever, and
are known as levels. Types evolve independently at rate θ according to mutation matrix M as
before, and these are the only dynamics between events (t, x) ∈ Π. At an event each particle
with zi ∈ Br(x) ﬂips a coin with success probability u, and the location of all successful particles
is resampled according to U (Br(x)). Then all particles “look down” and copy the type of the
participating particle with the lowest level, which is deemed to have been the parent of the
event. Tracing backwards in time, treating the “look down and copy” events as mergers into
a common ancestor and mixing uniformly over possible orderings of levels yields the quenched
spatial Λ–coalescent. Moreover, the evolution of a ﬁxed number of particles only depends on
the ﬁnitely many particles with lower levels. A realisation of a spatial Λ-coalescent tree and the
corresponding lookdown particle process in a one dimensional geography is shown in Figure 3.

Figure 3: (Left) Spatial Λ-coalescent in a one dimensional geography. Four lineages are sampled
at time S and traced until they reach a MRCA at time 0. At event A lineages 1 and 3 merge
to form lineage 5, while lineage 2 does not participate. Lineage 4 jumps at event B and merges
with lineage 5 at event C. The population reaches the MRCA at event D when lineage 2 and 6
merge. (Right) The corresponding four-particle lookdown process with lineages labelled by their
levels, taken to be 1, 2, 3 and 4 for simplicity. Four particles are started from a Poisson initial
condition at time 0 and propagated until time S. All particles which participate in an event have
their locations resampled, and the particle with the lowest participating level is selected as the
parent.
The likelihood of an observed conﬁguration, Pz1:n(h1:n) under the spatial Λ-coalescent is in-
tractable. However, it can be cast into the framework of stopped Markov processes by con-
ditioning on Π and using the lookdown construction to yield the following integral recursion,
which is the analogue of the seminal Griﬃths-Tavar´e recursion for the sampling distribution of
Kingman’s coalescent (Griﬃths and Tavar´e, 1994). Previous attempts at inference under the
spatial Λ-coalescent have been based on summary statistics (Barton et al., 2013), which discard
statistical signal. Guindon et al. (2016) have also recently introduced an Metropolis-Hastings
algorithm for full likelihood inference under a somewhat diﬀerent spatial Λ-coalescent model, in
which the kernels specifying the impact u and parental location at an extinction-recolonisation
event are taken to be Gaussian centred at the event location, as opposed to uniform. Their al-
gorithm relies on the fact that any lineage can participate in any event with positive probability,
and it would not be straightforward to extend it to bounded kernels.

15

Proposition 2. The likelihood of an observed conﬁguration Pz1:n(h1:n) solves

Pz1:n(h1:n) =

+

(cid:90)

L2 + θn

1

(cid:90)

d(cid:88)

h=1

(cid:40)
n(cid:88)
(cid:88)

i=1

θ

T(L)

Br(x)

J⊆N x
:
z1:n
hi=h ∀i∈J

Pz1:n(h1, . . . , hi−1, h, hi+1, . . . , hn)

Mhhi
u|J|(1 − u)

|N x
(|J| ∨ 1)πr2

z1:n

\J|

Pz1:n\J⊕z1∅c (J)(h1:n\J ⊕ h1∅c(J))dzdx

(10)

(cid:41)

,

with boundary condition Pz(h) = m(h) for any z ∈ T(L), where

z1:n := {i ∈ {1 . . . , n} : zi ∈ Br(x)}
N x

is the set of lineages within the disc of the extinction-recolonisation region Br(x), z1:n\J and
h1:n\J are the vectors z1:n and h1:n with indices in set J excluded, and z1:n ⊕ z = (z1, . . . , zn, z),
h1:n ⊕ h = (h1, . . . , hn, h), z1:n ⊕ 0 = z1:n and likewise h1:n ⊕ 0 = h1:n.

The coalescence rates in (10) are computationally intractable due to the(cid:82)

T(L) ··· dx-integral over

possible extinction-recolonisation event centres. To make progress we extend the state space to
include the sample conﬁguration h1:n and the almost surely ﬁnite, ordered vector of event centres
x := {xk}N
k=1 connecting the sample to the MRCA. We consider the joint likelihood Pz1:n(h1:n, x)
and recover the marginal likelihood of interest via

(cid:90)

(cid:90)

Pz1:n(h1:n) =

Pz1:n(h1:n, x)dx =

Px
z1:n(h1:n)Π(dx),

(11)

where we have abused notation by letting Π(dx) denote the marginal distribution of x, and
z1:n is the conditional law Pz1:n(·|x). Since the MRCA is reached using only ﬁnitely
where Px
i=1 of vectors of event centres as well as a conditional estimator (cid:98)Px
many events with probability 1 and Π(dx) is easy to sample, it is suﬃcient to obtain a sample
{xi}M
z1:n(h1:n), and estimate
(11) via

Pz1:n(h1:n) ≈ 1
M

M(cid:88)

k=1

(cid:98)Px(k)

z1:n (h1:n).

Note that this approach is an example of approximating an outer integral (6) using naive Monte
Carlo.

The analogue of (10) for the conditioned process given x is readily obtained from the lookdown
construction by mixing only on the times of the events of Π while retaining the conditioning
upon locations of centres:

(cid:40)

d(cid:88)

h=1

n(cid:88)

θ

Mhhi
u|J|(1 − u)|N

i=1

(|J| ∨ 1)πr2

xk

z1:n\J|

Px
z1:n(h1:n; k) =

(cid:90)

+ L2

L2 + θn

1

(cid:88)

Br(xk)

J⊆N
xk
z1:n :
hi=h ∀i∈J

Px
z1:n((h1, . . . , hi−1, h, hi+1, . . . , hn); k)

× Px

z1:n\J⊕z1∅c (J)(h1:n\J ⊕ h1∅c(J); k + 1)dz

(12)

(cid:41)

,

where the index k ∈ N has been introduced to track the index of the next event in x. The
z (h; k) = m(h) for any x, k ∈ N and z ∈ T(L). The
associated boundary condition is Px
coeﬃcient L2 in front of the second term arises as the rate of arrival of the next event given the
location of its centre.

16

The coeﬃcients in (12) are speciﬁed in closed form, and can be interpreted as the sought after
forwards transition probabilities:

P x((z1:n, (h1, . . . hi−1, h, hi+1, . . . , hn); k), (z1:n, h1:n; k)) =

P x((z1:n\J , h1:n\J ; k), (z1:n, h1:n; k + 1)) =

P x((z1:n, h1:n; k), (z1:n, h1:n; k + 1)) =

θ

L2 + θn

L2

L2 + θn

L2

L2 + θn

xk

z1:n\J|

Mhhi,
u|J|(1 − u)|N
|J|πr2
z1:n|.

(1 − u)|N

xk

,

Denote the corresponding stochastic process by {(zj, hj; kj)}j∈N with (z0, h0; 0) being the MRCA.
Let τ1 = 0 and {τn}n≥2 be a family of stopping times deﬁned inductively via

τn := inf{j ≥ τn−1 : |zj| ≥ n}.

Analogously to Section 4, the sets deﬁning the bridge of interest are

I = {(z, h; 0) : z ∈ T(L), h ∈ [d]}, the MRCA,
T = {(zτn+1−1, hτn+1−1) = (z∗, h∗)}, a ﬁxed (z∗, h∗) right before the sample size exceeds n,
R = {(zτn+1, hτn+1; kτn+1)}, any conﬁguration with size exceeding n.

z

The corresponding approximation to the optimal proposal distribution can then be written as

As in Section 4, the optimal reverse-time proposal distribution can be expressed in terms of the
(·|z1:n, h1:n)}z∈T(L), which can be
forwards transition probabilities and a family of CSDs {πx,k
interpreted as the distribution of a genetic type sampled from a point z ∈ T(L) between the
times of the (k − 1)th and kth events of a given realisation x given an observed conﬁguration
h1:n at locations z1:n. We immediately introduce our ﬁrst simplifying assumption and assume
the only dependence on x and k is via xk. The resulting approximate family is denoted by

{(cid:98)πxk
z (·|z1:n, h1:n)}z∈T(L).
(cid:98)P x((z1:n, h1:n; k), (z1:n, (h1, . . . , hi−1, h, hi+1, . . . , hn); k)) ∝ (cid:98)πxk
(cid:98)πxk
zi (h|z1:n\i, h1:n\i)θMhhi
zi (hi|z1:n\i, h1:n\i)(L2 + θn)
(cid:98)P x((z1:n, h1:n; k), (z1:n\J ⊕ z, h1:n\J ⊕ h; k + 1)) ∝ (cid:98)πxk
(cid:98)πxk
z (h|z1:n\J , h1:n\J )L2u|J|(1 − u)|N
(cid:124) (cid:123)(cid:122) (cid:125)
zJ (h, . . . , h
(cid:98)P x((z1:n, h1:n; k), (z1:n, h1:n; k + 1)) ∝ L2(1 − u)|N
where zJ denotes the vector of locations of lineages in J, and (cid:98)πxk
multivariate extension of (cid:98)πxk
will ensure that(cid:98)πxk
We consider coalescence and mutation separately, and focus ﬁrst on the univariate(cid:98)πxk

(h, . . . , h|z1:n, h1:n) is the
z (h|z1:n, h1:n). Our construction of the approximate CSDs below
(·|z1:n, h1:n) is invariant under permutations of J whenever all lineages in J
share a common type. These are the only kinds of mergers permitted by the spatial Λ-coalescent,
so that the multivariate extension will be well-deﬁned for all necessary arguments.

z (h|z1:n, h1:n)
for the mutation term. We ignore spatial structure and view a sample (z1:n, h1:n) as arising from
a standard Λ-coalescent with non-standard coalescence rates given by

z1:n\J|
|z1:n\J , h1:n\J )(L2 + θn)πr2 ,

L2 + θn

|J|

xk

z1:n|

,

,

xk

zJ

zJ

A family(cid:98)πK(·|h1:n) of approximate CSDs for Λ-coalescents was derived by Koskela et al. (2015),
and can be used here with the modiﬁcation (13) to yield a tractable family (cid:98)πxk
z (·|z1:n, h1:n) =

(13)

λn,k = L2uk(1 − u)n−k.

17

(cid:98)πK(·|h1:n). In brief, πK(·|h1:n) is the stationary distribution of the Markov chain on [d] with

transition probability matrix

(cid:16) 1

(cid:17)

(cid:0)n+1
(cid:1)λn+1,k
(cid:80)n+1
(cid:1)λn+1,k
(cid:0)n+1
(cid:80)n+1

k=2

k

k=2

k

θM +

n(n+1)

θ + 1
n+1

N

,

(14)

since the only crucial assumption is an aﬃne structure in N in (14).

where N is the d× d matrix with all rows equal to the type frequency counts in h1:n. An eﬃcient
Gauss quadrature for evaluating a slightly diﬀerent family of CSDs is provided in Appendix A of

(Stephens and Donnelly, 2000), but it can be adapted to(cid:98)πK(·|h1:n) with very minor modiﬁcations
we may sample the type and number of lineages to merge using(cid:98)πxk

For the coalescence terms we neglect all lineages outside the disc Br(xk), and again treat the
lineages in N xk
z1:n as a sample from a Λ-coalescent with coalescence rates given by (13). Thus
).
We then sample the precise set of lineages to merge uniformly at random among all those of the
correct type, and the parental location uniformly from Br(xk).

z (·|z1:n, h1:n) =(cid:98)πK(·|hN

xk
z1:n

Remark 4. Introducing approximations of the conditional distribution of parental locations,
and of the random environment Π, can be expected to yield more eﬃcient algorithms than
that outlined above. We attempted several heuristic models based on mixtures of Gaussian
distributions centred on the locations of remaining lineages, but obtained importance weights
with very high (and seemingly inﬁnite) variance (results not shown). Deriving practically useful
approximations remains an important open problem for likelihood-based inference for the spatial
Λ-coalescent.

The multivariate extensions (cid:98)πxk

zJ

tributions via

(cid:98)πxk

zJ

(h, . . . , h|z1:n\J , h1:n\J ) :=

(h, . . . , h|z1:n\J , h1:n\J ) can be deﬁned from the univariate dis-

|J|(cid:89)

(h(cid:12)(cid:12)z1:n\J ⊕i−1

j=1 (zJ )j, h1:n\J ⊕i−1

j=1 h).

(cid:98)πxk

(zJ )i

(15)

i=1

zJ

(cid:98)πxk

Despite the fact that the approximate CSDs are not exchangeable, the product on the R.H.S. of
(15) is uniquely deﬁned because it depends on the vector zJ only through the fact that all
locations satisfy (zJ )i ∈ Br(xk), and it is only evaluated for sets of lineages that are identi-
cal in type. Analogously to Remark 1 of (Koskela et al., 2015), these two facts ensure that
(h, . . . , h|z1:n\J , h1:n\J ) is invariant under permutations of J. This would not be true if more
than a single parent were permitted in each extinction-recolonisation event, because then simul-
taneous mergers of several types of lineages to diﬀerent parents would be possible. Strategies
for deﬁning approximate CSDs for such spatial Ξ-coalescents might include ﬁxing a canoni-
cal permutation to ensure (15) is well-deﬁned, or averaging over a small number of random
permutations as in (Li and Stephens, 2003).

In summary, our proposal distribution is deﬁned as

(cid:98)P x((z1:n, h1:n; k), (z1:n, (h1, . . . , hi−1, h, hi+1, . . . , hn); k)) ∝ (cid:98)πK(h|h1:n\i)
(cid:98)πK(hi|h1:n\i)
(cid:98)P x((z1:n, h1:n; k), (z1:n\J ⊕ z, h1:n\J ⊕ h; k + 1)) ∝ L2
(cid:98)πK(h, . . . , h
u|J|(1 − u)|N
(cid:124) (cid:123)(cid:122) (cid:125)
|hN
(cid:98)P x((z1:n, h1:n; k), (z1:n, h1:n; k + 1)) ∝ L2

L2 + θn

|J|−1

θ

Mhhi,

L2 + θn
z1:n\J|
xk
z1:n\J ⊕ h)

xk

1
πr2 ,

(1 − u)|N

xk

z1:n|

L2 + θn

with(cid:98)πK(·|h1:n) deﬁned in (14).

18

Eﬃcient algorithms for simulating samples from the spatial Λ-coalescent are available (Kelleher
et al., 2013, 2014) and were used to simulate a sample of 100 lineages from a torus with side
length L = 10 from uniformly distributed sampling locations. The type space consists of 10
binary loci, with mutations ﬂipping a randomly chosen locus at rate θ = 10−3. The resulting
sample is depicted in Figure 4.

Figure 4: Sampling locations and observed types of the simulated observation from a spatial
Λ-coalescent. The model parameters are L = 10, θ = 10−3, r = 1.0 and u = 0.3. The type space
consists of binary vectors of length 10, with mutations ﬂipping a randomly chosen element.

Natural parameters of interest which might be inferred from genetic data are the mutation rate
θ, the radius r and the impact u. The latter two can be related to classical population genetics
parameters: Wright’s neighbourhood size is N = 1/u, and the variance per unit time of the
spatial location of a lineage traced backwards in time is σ2 = πur4/2 (Barton et al., 2013).
We consider inferring all three parameters separately, assuming that the other two are known.
Likelihood surfaces for all three parameters are shown in Table 5. Stopping-time resampling has
been used in all simulation runs, with trajectories being stopped whenever the sample size ﬁrst
hits or falls below {99, 98, . . . , 3, 2} and resampling performed if the eﬀective sample size is lower
than one half of the number of particles. Note that because of multiple mergers it is possible for
a trajectory to hit multiple stopping times at once, in which case it will remain stopped until
all particles reach the same level provided it survives any intermediate resampling steps.

Figure 5 demonstrates that time reversal can produce convergent estimators for staggeringly
small likelihoods, even if the computational run times are daunting. The mutation rate θ can be
identiﬁed to within an order of magnitude, and the impact u to within a factor of 2. Radii which

19

lll02468100246810l110100010110110010110010010111010010Figure 5: Simulated likelihood surfaces for each of the three parameters of the spatial Λ-
coalescent, assuming the other two parameters are known and using 4 million particles. Points
correspond to independent simulations, and are labelled with their eﬀective sample sizes and
run times using 12 cores on the MidPlus cluster Minerva.

are too small can also be ruled out clearly, though large radii cannot be excluded similarly. We
believe this is due to the relatively small ratio of the torus side length L to the event radius r,
with larger tori resulting in greater radius identiﬁability. Simulations by Guindon et al. (2016)
reached similar conclusions, with accurately estimated neighbourhood sizes N = 1/u and higher
uncertainty estimates of dispersal rate σ2 = πur4/2.

As with SMC algorithms in general, the computational cost can be greatly reduced by parallelis-
ing the algorithm, which is typically straightforward, or by reducing the number of independent
simulations through use of driving values (Griﬃths and Tavar´e, 1994) or bridge sampling (Meng
and Wong, 1996).

20

lllllllllll0.0000.0020.0040.0060.0080.010−75−74−73−72thetalog (base 10) likelihood498m509m511m532m503m522m518m517m529m538m552m31624416133655146611477205561481591212391555llllllllll0.60.81.01.21.4−76−75−74−73−72rlog (base 10) likelihood1939m1255m891m651m512m435m382m348m323m307m2422752779521409886173455772399481410415950llllllll0.100.150.200.250.300.350.400.45−75.0−74.5−74.0−73.5−73.0−72.5ulog (base 10) likelihood2800m1453m955m667m513m432m379m344m71842828813778825526021024071847 Discussion

We have presented a general framework for designing SMC proposal distributions which proceed
backwards in time. Time-reversal makes it straightforward to ensure realisations of the process
hit desired regions of the state space, essentially irrespective of the probability assigned to them
by the law of the process of interest. Even the extreme case of conditioning paths on a terminal
point of probability 0 can be dealt with easily. This makes time-reversal a natural and eﬃcient
choice when the end point of a path is known with high accuracy, but its initial distribution is
ﬂat. As most existing rare event and path simulation algorithms make the opposite assumptions
about initial and terminal conditions, we expect time-reversal to be a useful tool in extending
the scope of simulation-based inference and computation.

Expressing the law of the reverse-time process via Nagasawa’s formula (3) often leads to a sub-
stantial reduction in the dimensionality of the design task of deﬁning a proposal distribution
(c.f. Proposition 1). The diﬃculty of designing eﬃcient proposal distributions in high dimension
is a central barrier to practical SMC, so this cancellation of dimensions is an important advan-
tage. Furthermore, we emphasize that it is not inherently linked to time-reversal: re-weighting
jump probabilities by an approximate stationary distribution and cancelling out common co-
ordinates would lead to a forwards-in-time proposal deﬁned by low dimensional approximate
CSDs. For rare terminal conditions a reverse-time approach is easier because the conditional
and unconditional dynamics share the qualitative behaviour of rapidly leaving the rare state for
a stationary mode. A forwards-in-time algorithm would have to use CSDs approximating the
behaviour of an appropriate Doob’s h-transform in order to drive the process away from modes
and into the rare state. Nevertheless, we believe analogues of Proposition 1 to be a useful design
tool beyond the scope of just this paper.

All three example simulations considered in this paper have had the property that the proposal
distribution could be normalised numerically, so that proposals could be sampled via standard
methods. This property is computationally convenient, but is often not necessary since impor-
tance weights typically only need to be evaluated up to a normalising constant. In such cases
samples from unnormalised proposals can be generated via Metropolis-Hastings and the only
modiﬁcation to Algorithm 2 is a step to self-normalise weights after lines 7 and 29.

Section 6 demonstrates that reverse-time SMC can handle very high-dimensional missing data
and events of extremely small probability, albeit at high computational cost. This cost can be
alleviated greatly by the fact that SMC algorithms are straightforward to parallelise. Use of
GPUs for parallel Monte Carlo simulations has been found to speed up computations by up to
500 fold in comparison to serial simulation (Lee et al., 2010). Further gains in eﬃciency can
be made by reducing the required number of independent simulations through driving values
(Griﬃths and Tavar´e, 1994) or bridge sampling (Meng and Wong, 1996). The combined eﬀect
of these improvements would make the simulations carried out in Section 6 much faster, thus
yielding practical algorithms even for very large models.

The algorithm introduced in Section 6 is also the ﬁrst SMC inference algorithm for the spatial Λ-
coalescent, which solves a number of long-standing problems in spatially structured population
genetics. It was made possible by a recursion of the form (12) in combination with the reverse-
time framework, and the cancellation of dimensions outlined in Proposition 1. The only other
full likelihood algorithm for a similar model is the Metropolis-Hastings chain of Guindon et al.
(2016), which relies on modelling assumptions (i.e. positive participation probability of any
lineage in any extinction-recolonisation event) which are not satisﬁed by the disc version of
the spatial Λ-coalescent considered here. As such, the disc version of the spatial Λ-coalescent
provides a concrete example of a model of practical interest which is rendered computationally
tractable by our method.

21

Acknowledgements

The authors are indebted Adam Johansen and Murray Pollock for their helpful comments on rare
event simulation; to Alison Etheridge, Jerome Kelleher, Adam Griﬃn and Felipe Medina Aguayo
for many insightful discussions about the spatial Λ-coalescent; and to Jerome Kelleher for making
his GitHub library available. Jere Koskela is supported by EPSRC as part of the MASDOC
DTC at the University of Warwick. Grant No. EP/HO23364/1. Paul Jenkins is supported in
part by EPSRC grant EP/L018497/1. Computational facilities were provided by the MidPlus
Regional Centre of Excellence for Computational Science, Engineering and Mathematics, under
EPSRC grant EP/K000128/1.

A Proofs

A.1 Proposition 1

Let ∂ be a cemetery state, and deﬁne the process

(cid:40)

X ∂

t =

Xt
∂

if t ≤ τT ∧ τR
otherwise

.

Note that the laws of {X ∂
coincide, and thus so do their Green’s functions
evaluated at states (z, y) ∈ (T ∪ R ∪ ∂)c. Hence, for any such state, Fubini’s theorem and
conditioning on Zi = z yield

and {Xi}τT ∧τR

i }τT ∧τR

i=0

i=0

G(µ, (z, y)) = Eµ

1{z,y}(Z∂

i , Y ∂
i )

=

Eµ

1{z,y}(Z∂

i , Y ∂
i )

(cid:34) ∞(cid:88)
(cid:104)Eµ
∞(cid:88)

Eµ

i=1

=

i=1

(cid:35)

(cid:104)

∞(cid:88)
(cid:105)

i=1

(cid:105)

(cid:105)

1{y}(Y ∂

(cid:104)
(cid:2)1{y}(Y ∂
∞(cid:88)
∞(cid:88)

Eµ

i=1

i )|Z∂

,

1{z}(Z∂
i )

i = z

i )|Z∂

i = z(cid:3) is independent of i by assumption.
(cid:2)1{z}(Zi)1i:∞(τT ∧ τR)(cid:3)
∞(cid:88)

Pµ(Zi = z, τT ∧ τR = t).

where (Z∂, Y ∂) := X ∂. Now π(y|z) = Eµ
Thus

G(µ, (z, y)) = π(y|z)

= π(y|z)

Now note that the ﬁnal double sum cancels whenever the Green’s functions are evaluated as
ratios, which completes the proof.

i=1

t=1

A.2 Proposition 2

Consider a conﬁguration (z1:n, (h1, . . . , hi−1, h, hi+1, . . . , hn)) evolving forwards in time as the n
particles with the lowest levels in the lookdown construction. The rate of particle i mutating
from type h to some other hi is θMh(cid:48)h:

(z1:n, (h1, . . . , hi−1, h, hi+1, . . . , hn)) (cid:55)→ (z1:n, h1:n) with rate θMhhi.

Ordering of levels plays no role in the mutation process, so the same rate holds for the spatial
Λ-coalescent.

22

(n−k+1):n with types h(cid:48)

To obtain the rate associated to extinction-recolonisation events, suppose the next such event is
centred at x ∈ T(L). Suppose there are k lineages with locations inside the disc Br(x), and that
these occupy positions z(cid:48)
(n−k+1):n. Let (z1:n, h1:n) be the conﬁguration
after the event centred on x, and let J ⊆ (n − k + 1) : n denote the set of indices which jumped
in the event. Note that this means zJ ∈ Br(x)|J| and hJ = (h(cid:48), . . . , h(cid:48)), where h(cid:48) is the type of
the particle with the lowest level in h(cid:48)
(n−k+1):n. The lookdown dynamics specify the rate
of the corresponding jump as
(n−k+1):n, h1:k ⊕ h(cid:48)

(n−k+1):n) (cid:55)→ (z1:n, h1:n) with rate L2(cid:16) u

(z1:k ⊕ z(cid:48)

(cid:17)|J|

J ⊆ h(cid:48)

\J|

πr2

(1 − u)

|N x

z1:n

.

It remains to sum over all jumps of the lookdown system which give rise to the same coalescence
event in the spatial Λ-coalescent, and mix over orderings of levels. Firstly, note that because the
parental location after a merger is determined by the position of the particle in z(cid:48)
J with lowest
level, all the other |J| − 1 particle locations can be integrated out, cancelling |J| − 1 powers
of πr2. Likewise, the particle at the parental location has to be the one with the lowest level
among particles with labels in J, but otherwise the levels play no role. Uniform mixing achieves
this with probability 1/|J|, giving a total rate of
L2u|J|(1 − u)
|J|πr2

|N x

\J|

z1:n

,

which completes the proof.

References

V. Anantharam, P. Heidelberg, and P. Tsoucas. Analysis of rare events in continuous time
Markov chains via time reversal and ﬂuid approximation. IBM Research Report, #RC 16280,
1990.

O. Barndorﬀ-Nielsen. Exponentially decreasing distributions for the logarithm of particle size.

Proc. R. Soc. London A, 353:401–419, 1977.

O. Barndorﬀ-Nielsen. Hyperbolic distributions and distributions on hyperbolae. Scand. J.

Statist., 5:151–157, 1978.

N. H. Barton, A. M. Etheridge, and A. V´eber. A new model for evolution in a spatial continuum.

Electron. J. Probab., 15(7):162–216, 2010.

N. H. Barton, A. M. Etheridge, J. Kelleher, and A. V´eber. Inference in two dimensions: allele

frequencies versus lengths of shared sequence blocks. Theor. Popln Biol., 87:105–119, 2013.

E. Bibbona and S. Ditlevsen. Estimation in discretely observed Markov processes killed at a

threshold. Scand. J. Stat., 40:274–293, 2013.

B. M. Bibby and M. Sørensen. Hyperbolic processes in ﬁnance. In S. Rachev, editor, Handbook

of heavy tailed distributions in ﬁnance, pages 211–248. Elsevier, Amsterdam, 2003.

M. Birkner and J. Blath. Computing likelihoods for coalescents with multiple collisions in the

inﬁnitely many sites model. J. Math. Biol., 57(3):435–463, 2008.

M. Birkner, J. Blath, and M. Steinr¨ucken. Importance sampling for Lambda-coalescents in the

inﬁnitely many sites model. Theor. Popln Biol., 79(4):155–173, 2011.

H. A. P. Blom, G. J. Bakker, and J. Krystul. Probabilistic reachability analysis for large scale
stochastic hybrid systems. In: Proc. 46th IEEE Conf. Dec. Contr., New Orleans, USA, 2007.

23

B. Casella and G. O. Roberts. Exact Monte Carlo simulation of killed diﬀusions. Adv. Appl.

Probab., 40:273–291, 2008.

F. C´erou, P. Del Moral, and A. Guyader. A non–asymptotic variance theorem for unnormalized

Feynman-Kac particle models. Ann. Inst. Henri Poincar´e Probab. Stat., 47:629–649, 2011.

F. C´erou, P. Del Moral, T. Furon, and A. Guyader. Sequential Monte Carlo for rare event

estimation. Stat. Comput., 22:795–808, 2012.

F. C´erou, P. Del Moral, A. Guyader, and F. Malrieu. Fluctuations analysis of adaptive multilevel

splitting. Preprint, arXiv:1408.6366 [math.ST], 2014.

Y. Chen, J. Xie, and J. S. Liu. Stopping-time resampling for sequential Monte Carlo methods.

J. R. Stat. Soc. B, 67:199–217, 2005.

M. De Iorio and R. C. Griﬃths. Importance sampling on coalescent histories I. Adv. in Appl.

Probab., 36(2):417–433, 2004a.

M. De Iorio and R. C. Griﬃths. Importance sampling on coalescent histories II: Subdivided

population models. Adv. in Appl. Probab., 36(2):434–454, 2004b.

P. Del Moral. Feynman-Kac formulae: genealogical and interacting particle systems with appli-

cations. Springer, New York, 2004.

P. Del Moral and J. Garnier. Genealogical particle analysis of rare events. Ann. Appl. Probab.,

15:2496–2534, 2005.

A. Doucet and A. M. Johansen. A tutorial on particle ﬁltering and smoothing: ﬁfteen years
In D. Crisan and B. Rozovskii, editors, The Oxford handbook of nonlinear ﬁltering.

later.
Oxford University Press, 2011.

A. Doucet, J. F. G. De Freitas, and N. J. Gordon. Sequential Monte Carlo methods in practice.

Springer, New York, 2001.

A. M. Etheridge. Drift, draft and structure: Some mathematical models of evolution. Banach

Center Publ., 80:121–144, 2008.

P. Fearnhead. Computational methods for complex stochastic systems: a review of some alter-

natives to MCMC. Stat. Comput., 18:151–171, 2008.

P. Fearnhead and P. Donnelly. Estimating recombination rates from population genetic data.

Genetics, 159:1299–1318, 2001.

M. R. Frater, R. A. Kennedy, and B. D. O. Anderson. Reverse-time modelling, optimal control

and large deviations. Syst. Control Lett., 12:351–356, 1989.

M. R. Frater, R. R. Bitmean, R. A. Kennedy, and B. D. O. Anderson. Fast simulation of rare

events using reverse-time models. Comput. Networks ISDN, 20:315–321, 1990.

P. Glasserman and Y. Wang. Counterexamples in importance sampling for large deviations

probabilities. Ann. Appl. Probab., 7(3):731–746, 1997.

P. Glasserman, P. Heidelberg, P. Shahabuddin, and T. Zajic. Multi-level splitting for estimating

rare event probabilities. Oper. Res., 47:585–600, 1999.

R. C. Griﬃths and S. Tavar´e. Simulating probability distributions in the coalescent. Theor.

Popln Biol., 46:131–159, 1994.

R. C. Griﬃths, P. A. Jenkins, and Y. S. Song. Importance sampling and the two-locus model

with subdivided population structure. Adv. in Appl. Probab., 40:473–500, 2008.

24

S. Guindon, H. Guo, and D. Welch. Demographic inference under the coalescent in a spatial

continuum. bioRxiv, 2016. doi: 10.1101/042135.

A. Hobolth, M. Uyenoyama, and C. Wiuf. Importance sampling for the inﬁnite sites model.

Stat. Appl. Genet. Mol., 7:Article 32, 2008.

C. Jarzynski. Rare events and the convergence of exponentially averaged work values. Phys.

Rev. E, 73, 2006.

A. Jasra, N. Kantas, and A. Persing. Bayesian parameter inference for partially observed stopped

processes. Stat Comput, 24:1–20, 2014.

P. A. Jenkins. Stopping-time resampling and population genetic inference under coalescent

models. Stat. Appl. Genet. Mol. Biol., 11(1):Article 9, 2012.

A. M. Johansen, P. Del Moral, and A. Doucet. Sequential Monte Carlo samplers for rare events.
Proceedings of the 6th international workshop on rare event simulation, pages 256–267, 2006.

J. Kelleher, N. H. Barton, and A. M. Etheridge. Coalescent simulation in continuous space.

Bioinformatics, 29(7):955–956, 2013.

J. Kelleher, A. M. Etheridge, and N. H. Barton. Coalescent simulation in continuous space:

algorithms for large neighbourhood size. Theor. Popln Biol., 95:13–23, 2014.

J. F. C. Kingman. The coalescent. Stochast. Process. Appllic., 13(3):235–248, 1982.

J. Koskela, P. A. Jenkins, and D. Span`o. Computational inference beyond Kingman’s coalescent.

to appear in J. Appl. Probab., 52(2), 2015.

A. Lee, C. Yau, M. B. Giles, A. Doucet, and C. C. Holmes. On the utility of graphics cards to
perform massively parallel simulation of advanced Monte Carlo methods. J. Comp. Graph.
Stat., 19(4):769–789, 2010.

P. Lezaud, J. Krystul, and F. Le Gland. Sampling per mode simulation for switching diﬀusions.

In: Proc. 8th Internk. Works. Rare–Event Simul., RESIM, Cambridge, 2010.

N. Li and M. Stephens. Modeling linkage disequilibrium and identifying recombination hotspots

using single-nucleotide polymorphism data. Genetics, 165:2213–2233, 2003.

J. S. Liu. Monte Carlo strategies in scientiﬁc computing. Springer, New York, 2001.

X. L. Meng and W. H. Wong. Simulating rations of normalizing constants via a simple identity:

a theoretical exploration. Statist. Sinica, 6:831–860, 1996.

J. S. Paul and Y. S. Song. A principled approach to deriving approximate conditional sampling
distributions in population genetic models with recombination. Genetics, 186:321–338, 2010.

J. S. Paul, M. Steinr¨ucken, and Y. S. Song. An accurate sequentially Markov conditional
sampling distribution for the coalescent with recombination. Genetics, 187:1115–1128, 2011.

L. C. G Rogers and D. Williams. Diﬀusions, Markov processes and martingales, volume 1.

Wiley, 2 edition, 1994.

G. Rubino and B. Tuﬃn. Rare event simulation using Monte Carlo methods. Wiley, 2009.

J. S. Sadowsky and J. A. Bucklew. On large deviation theory and asymptotically eﬃcient Monte

Carlo estimation. IEEE Trans. Inf. Theory, 36:579–588, 1990.

S. Sheehan, K. Harris, and Y. S. Song. Estimating variable eﬀective population sizes from mul-
tiple genomes: A sequentially Markov conditional sampling distribution approach. Genetics,
194:647–662, 2013.

25

A. Shwartz and A. Weiss. Induced rare events: analysis via large deviations and time reversal.

Adv. Appl. Probab., 25(3), 1993.

M. Steinr¨ucken, J. S. Paul, and Y. S. Song. A sequentially Markov conditional sampling distri-
bution for structured populations with migration and recombination. Theor. Popln Biol., 87:
51–61, 2013.

M. Stephens and P. Donnelly. Inference in molecular population genetics. J. R. Statist. Soc. B,

62(4):605–655, 2000.

A. V´eber and A. Wakolbinger. The spatial Lambda-Fleming-Viot process: an event-based
construction and a lookdown representation. Ann. Inst. H. Poincar Probab. Statist., 51(2):
570–598, 2015.

26

