6
1
0
2

 
r
a

 

M
3
1

 
 
]

V
C
.
s
c
[
 
 

1
v
5
1
0
4
0

.

3
0
6
1
:
v
i
X
r
a

LEARNING ZEROTH CLASS DICTIONARY FOR HUMAN ACTION RECOGNITION

Jia-xin Cai1∗

Xin Tang2

Lifang Zhang3

Guocan Feng3⋆

1 Xiamen University of Technology 2 Huazhong Agricultural University 3 Sun Yat-sen University

∗caijiaxin@xmut.edu.cn

⋆ mcsfgc@mail.sysu.edu.cn

ABSTRACT

In this paper, a discriminative two-layer dictionary learning
framework is proposed for classifying human action by sparse
shape representations, in which the ﬁrst-layer dictionary is
learned on the selected discriminative frames and the second-
layer dictionary is built for recognition using reconstruction
errors of the ﬁrst-layer dictionary as input features. We pro-
pose a ”zeroth class” trick for detecting undiscriminating
frames of the test video and eliminating them before voting
on the action categories. Experimental results on benchmarks
demonstrate the effectiveness of our method.

Index Terms— Human action recognition, sparse coding,

dictionary learning, fractional Fourier descriptor

1. INTRODUCTION

Recently, human action recognition has gained much interest
for its great potential in many application areas such as video
surveillance and human-computer interaction. The challenge
of human action recognition usually results from the problem
that different action classes often share some common motion
patterns. Moreover, the action videos usually include many
redundant frames indicating the background, large noise,
clutter or small movements that are with limited help for
recognition[1]. For action video classiﬁcation, if the training
and test videos contain some frames representing the common
motion components among different action classes, or some
redundant frames with large noise or useless clutters, then the
discriminability of classiﬁer learnt from training frames will
be corrupted, and the recognition result of test video will also
get corrupted when the labels of undiscriminating test frames
are used to determine the class label of test video.

Sparse representation based recognition approaches have
attracted much attention in the ﬁeld of computer vision. To
learn a well-adapted dictionary for obtaining good reconstruc-
tion and recognition performance, many algorithms[2, 3, 4]
for training dictionary with label information and discrimi-
native criterion have been proposed. These algorithms can
only work well for the cleaning training samples or training
samples with small corruption[5]. So the efforts for learning

Thanks to the National Natural Science Foundation of P. R. China

(61272338)

low-rank and discriminative dictionary are made in [5, 6, 7]
to solve this problem. However, the previous methods can
not handle the problem resulted from the undiscriminating
test frame samples for video recognition. Imagining the test
video contains many frames representing the useless clutters
or some common components among different video classes,
the label of test video will get corrupted by these undiscrimi-
nating test frames. So it is necessary to develop a discrimina-
tive dictionary for the situation that both the training and test
videos contain many corrupted or uninterest frame samples.
In this paper, we attempt to learn a discriminative dictio-
nary for action recognition to handle the situation that both the
training and test videos contain undiscriminating frames with
common components, redundant components, background,
clutter or large noise. We propose a recognition framework
for human action recognition in video by learning a discrim-
inative dictionary called zeroth class dictionary. The ”ze-
roth class” trick is proposed for detecting and ﬁltering out
the undiscriminating frames of the test video to eliminate the
negative effect resulted from these frames during voting the
action category of test video. The zeroth class dictionary
method is a two-layer dictionary learning system including
three steps:

(1)Firstly, the discriminative frames of training videos are
selected by Gentle Adaboost algorithm to learn the ﬁrst-layer
dictionary. The left undiscriminating frames are relabeled
and assigned to the zeroth class. The zeroth class is a virtual
class indicating undiscriminating frames which are with lim-
ited help for recognition, such as frames with common poses
shared by different actions, frames with clutter or noise, and
other redundant frames. Then the ﬁrst-layer dictionary is
learnt on the selected discriminative frames; the reconstruc-
tion errors of all frames corresponding to each dictionary
atom are collected to build the new frame representations.

(2)Using the new frame representations, we learn the
class-speciﬁc dictionary in which the sub-dictionary of each
action class is learned on the corresponding selected discrim-
inative frames and the zeroth class sub-dictionary is learnt on
the undiscriminating frames. Then we obtain the preliminary
labels of the test frames based on the learnt class-speciﬁc dic-
tionary. The zeroth class is used for recognizing the redundant
frames of test video, which are ﬁltered out afterwards.

(3)After the undiscriminating frames of test video are ex-

cluded, the ﬁnal action label is voted by all remained dis-
criminative frames of the test video. Experimental results
on benchmark data show that our method outperforms most
state-of-the-art approaches.

The rest of the paper is organized as follows: Sect.2 re-
views the relative works. Sect.3 presents the zeroth class
dictionary learning framework for human action recognition.
Experimental setup and results on benchmark datasets are
presented in Sect.4, and conclusions are given in Sect.5.

2. RELATIVE WORKS

Many efforts[8, 9, 10, 11, 12] have been devoted to study-
ing action recognition by sparse representation and dictionary
learning. Guha and Ward[8] provide a sparse representation
for human action recognition by learning the over-complete
bases on the local motion patterns. Bomma et al.[9] learn
the sparse representation on Gait Energy Images and motion-
descriptors of videos for human action and gesture recogni-
tion. Lu and Peng[10] propose a structure sparsity ℓ1-norm
graph to learn the high-level visual-words for representing hu-
man action. Cai et al.[11] present a framework of learning
class-speciﬁc dictionaries on shape-based human pose repre-
sentation. Wang et al.[12] propose a sparse model incorpo-
rating the similarity constrained term and the dictionary inco-
herence term for human action recognition.

Our work is also similar to the silhouette based action
recognition approaches[13, 14, 15, 16]. Chaaraoui et al.[13]
develop a human action recognition method through extract-
ing multi-view key poses sequences and handling variations
in shape by dynamic time warping. Cheema et al.[14] pro-
pose a human action recognition method by extracting a scale
invariant contour-based pose feature and clustering the fea-
tures to construct distinctive key poses. Cai and Feng[15]
present a human action recognition method by describing
contour-based shape feature using fractional Fourier trans-
form. Cheng et al.[16] propose a human action recognition
approach based on human silhouettes by supervised temporal
t-stochastic neighbor embedding and incremental learning
via low-dimensional embedding.

3. ZEROTH CLASS DICTIONARY LEARNING
BASED ACTION RECOGNITION FRAMEWORK

We use the fractional Fourier shape descriptor[15] to repre-
sent each frame of action videos. The fractional Fourier shape
descriptor is built on the human pose represented by contour
points of the binary silhouette. Given an image extracted from
the action video, its binary silhouette is obtained from the seg-
mented foreground region. Then the boundary of silhouette
is extracted and the position of all points {(x(i), y(i))}N
i=1
along the boundary is represented as a complex sequence
i=1, where x(i) and y(i) denote
{s(i)|s(i) = x(i) + jy(i)}N

the horizontal and vertical coordinate of the ith point respec-
tively. Here N is the total number of contour points, and j
denotes the imaginary unit.

Then we shift the base point of coordinate system to the
center of mass (xc, yc) of contour points along the boundary
to achieved the translation invariance.

˜x(i) = x(i) − xc

˜y(i) = y(i) − yc

(1)

After that, the length of sequence is normalized to a pre-
determined value L through down-sampling the contour. In
our experiments, the normalized length L is set as 100.

ˆx(i) = ˜x(⌈i ∗

N
L

⌉)

ˆy(i) = ˜y(⌈i ∗

N
L

⌉)

(2)

Afterwards, we compute the discrete fractional Fourier
i=1,
transform of the transformed contours {ˆs(i) : ˆx(i)+j ˆy(i)}L
and get the response {S(i)}L
i=1 in the fractional Fourier do-
main. For a continuous signal ˆs(t), its p order continuous
fractional Fourier transform is deﬁned as:

Bα R ∞

−∞ exp(j t2

+u2
2

Sp(u) =




ˆs(t)
ˆs(−t)

sinα )ˆs(t)dt

cotα − jtu
α 6= nπ
α = 2nπ

(3)

α = (2n ± 1)π

where α = pπ/2 is the rotation angle and Bα = q 1−jcotα
.
Here n denotes an integer. The order p is set as 0.9 in our ex-
periments. For digital computation, we use a sampling-type
discrete fractional Fourier transform proposed in [17] to cal-
culate the response {S(i)}L

2π

Then the amplitude of fractional response, |S(i)|, is cal-
culated and normalized to obtain a scale invariant descriptor.

i=1.

d(i) =

|S(i)|2
i=1 |S(i)|2

PL

(4)

{d(i)}L

i=1 consists the fractional Fourier shape descriptor
of human pose contour. For each training video, we assign its
action class label to its all afﬁliated frames.

A two-layer discriminative dictionary framework is learnt
by the fractional Fourier descriptor for recognizing action
videos. Firstly, the Gentle AdaBoost algorithm is employed
to select discriminative training frames. Gentle AdaBoost
provides an approach for reweighting data points by updating
weights of base classiﬁers and puts higher weights on undis-
criminating data points than discriminative points[18]. Re-
gression stump is used as the base classiﬁer. The regression
stump is a simple additive logistic regression based classi-
ﬁer, which classiﬁes data points according to only one input
dimension. For an input sample x whose kth dimensional fea-
ture is denote as x(k), the output class label f (x) of regres-
sion stump is deﬁned by only four parameters (w, v, k, th),
and represented as follows.

f (x) = w ∗ sign(x(k) − th) + v

(5)

The ”one-against-the-rest” technique is employed to extend
the primary binary classiﬁcation problem to multi-class case.
A training frame with high weight imply that it contains com-
mon and undiscriminating patterns between different action
categories. We select the frames with the lowest weights from
the training frame set of each action class at a rate of R to
build the discriminative subset for generating the ﬁrst-layer
dictionary, and the remained frames are pushed into a pool
where they are relabeled as the zeroth class and will be used
for detecting undiscriminating frames of the test video later.
After the discriminative subset of the training frames is
selected out, we generate a dictionary D on this set. The aim
is to learn a dictionary D so that the selected discriminative
frames have a sparse representation B over the dictionary. It
can be written as the following optimization problem:

minD,BkY − DBk2
F

s.t. |bik0 ≤ C, ∀i

(6)

where Y is the selected discriminative subset of training
frames represented by the fractional Fourier descriptor; D is
the learned dictionary on the discriminative subset; bi is the
ith column of sparse coefﬁcients matrix B, denoting the rep-
resenting coefﬁcient of ith frame. C is the parameter control-
ling the sparsity of coefﬁcients. k · kF denotes the Frobenius
norm, and k · k0 is the l0 norm enforcing the coefﬁcients to be
sparse.

Then for a frame y, the reconstruction error corresponding

to the ith atom of the dictionary D is computed as:

ei(y) = ky − Dδi( ˆβ)k2

ˆβ = argminβky − Dβk2

s.t. kβk0 ≤ C

(7)

where the function δi(β) sets the jth dimension of β as
0 if j 6= i. Suppose m is the atom number of dictionary D,
then the vector [e1(y), ..., em(y)]T makes up a new feature of
frame y, which would be used as the new frame feature in the
next layer dictionary learning.

After the new features of all frames in both training and
test videos are computed, the class-speciﬁc dictionary learn-
ing is performed. Suppose K is the number of action cate-
gories. Using the training frames belonging to the kth(k =
0, 1, ..., K) class (including the zeroth class), we learn the
class-speciﬁc dictionary Dk using the new feature represented
by reconstruction errors on the ﬁrst-layer dictionary. The sub-
dictionary Dk associated with the kth(k = 1, ..., K) nonzero
action class is learnt on the corresponding selected discrimi-
native frames of the kth class, and the zeroth class dictionary
D0 is learnt on the undiscriminating frames. Then the whole
dictionary ¯D is constructed by concatenating all the class-
speciﬁc dictionaries, that is to say, ¯D = [D0|D1|D2|...|DK].
After the whole dictionary ¯D is learned, the sparse repre-
sentation ai of a frame ˇxi of the test video can be estimated
as follows.

ai = argminakˇxi − ¯Dak2

s.t. kak0 ≤ C

(8)

The reconstruction error rk(ˇxi) associated with the kth class
can be deﬁned as:

rk(ˇxi) = kˇxi − ¯DΘk(ai)k2

k = 0, 1, ..., K (9)

where Θk(ai) produces a vector whose nonzero entries are
coefﬁcients of ai associated with the kth class .

Then each frame of the test video is assigned to the class
that corresponds to the minimum of reconstruction error with
respect to each class(including the zeroth class). The esti-
mated preliminary class ˇki of the test frame ˇxi is given as:

ˇki = argmink∈{0,1,...,K}rk(ˇxi)

(10)

Afterwards, we ﬁltered out the undiscriminating frames
in the test video which are labeled as the zeroth class. Then
the max pooling or sum pooling criteria is used to vote the ac-
tion label by the remained discriminative frames correspond-
ing to nonzero classes of the test video. For max pooling pol-
icy, each frame of the test video is classiﬁed to the nonzero
class that corresponds to the minimum of reconstruction error
with respect to each non-zero class. Then the estimated action
class ˆk of the test video is given as:

ˆk = argmink∈{1,...,K}minˆi∈{i| ˇki6=0}rk(ˇxˆi)

(11)

For sum pooling policy, an overall residual is constructed
by summing up the reconstruction errors corresponding to
nonzero classes of each frames in the test video; then the test
video is assigned to the nonzero class with respective to the
minimum of overall error. The estimated action class ˆk of the
test video is given as:

ˆk = argmink∈{1,...,K} X

ˆi∈{i| ˇki6=0}

rk(ˇxˆi)

(12)

4. EXPERIMENTAL RESULTS

In order to evaluate the performance and practicability of the
proposed approach, two human action recognition datasets,
the Weizmann dataset[19]and the MuHAVi-MAS14 dataset[20],
are used as benchmarks. For each class, we select frames with
the lowest Gentle Adaboost weights as the discriminative sub-
set at a rate of R. The K-SVD[21] and OMP[22] algorithm
are performed for learning dictionary and sparse representa-
tion respectively. The leave-one-out cross validation strategy
is employed to separate the training video set and test video
set. All parameters are tuned by grid searching. The recogni-
tion rates on Weizmann dataset and MuHAVI-MAS14 dataset
are achieved as 97.85% and 95.59% respectively. We also
compare the accuracy of our method to the reported accuracy
of other state-of-the-art methods. The comparison results are
presented in Table1. Although the action features employed
in most listed methods are different to ours, our method still
shows a considerable performance and outperforms most
listed methods on the benchmarks.

We have also analyzed the relation between accuracy of
our method and the parameter C. The experimental results
on Weizmann and MuHAVI-MAS14 dataset are illustrated in
Figure 3 and Figure 4 respectively. The results demonstrate
that it is easy to ﬁnd a proper parameter C for achieving good
classiﬁcation performance through the zeroth class dictionary
learning framework.

Fig. 3. Relation between accuracy and parameter C on Weiz-
mann dataset

Table 1. Comparison of methods on benchmarks

Method

Weizmann MuHAVi-

Our method(sum pooling)
Our method(max pooling)
Chaaraoui et al. [13]
Cheema et al. [14]
Singh et al. [20]
Wang et al. [12]
Cheng et al. [16]
Cai and Feng [15]

97.85%
95.70%
92.77%
91.6%

96.7%
94.44%
93.55%

MAS14

95.59%
95.59%
91.18%
86.03%
82.35%

Analysis of the relation between recognition accuracy and
the size of zeroth class set has also been carried out. Figure 1
and Figure 2 show the relation between accuracy and the rate
R on Weizmann and MuHAVI-MAS14 dataset respectively.
Experiment results demonstrate that our framework outper-
forms the ordinary two-layer dictionary learning framework
without the discriminative frame detection and ﬁltering stage
at most time. However, if too many undiscriminating frames
are selected into the zeroth class training set for the ﬁrst-layer
dictionary learning , the performance of the framework will
decline. The experimental results demonstrate introducing
the zeroth class is effective if a proper proration of zeroth class
of the training set is set.

Fig. 1. Relation between accuracy and the rate of selected
discriminative frames on Weizmann dataset

Fig. 2. Relation between accuracy and the rate of selected
discriminative frames on MuHAVI-MAS14 dataset

Fig. 4. Relation between accuracy and parameter C on
MuHAVI-MAS14 dataset

5. CONCLUSION

This paper presents a novel method for human action recog-
nition using zeroth class dictionary. The zeroth class dictio-
nary provides a method to detect and delete undiscriminating
frames of test video for improving the classiﬁcation accuracy.
The zeroth class dictionary learning based framework is vali-
dated on benchmarks, showing a considerable performance.

6. REFERENCES

[1] Jiaxin Cai, Guocan Feng, and Xin Tang, “Human action
recognition using oriented holistic feature,” in Image
Processing (ICIP), 2013 20th IEEE International Con-
ference on, Sept 2013, pp. 2420–2424.

[2] Zhuolin Jiang, Zhe Lin, and L.S. Davis, “Label con-
sistent k-svd: Learning a discriminative dictionary for
recognition,” IEEE Transactions on Pattern Analysis

and Machine Intelligence, vol. 35, no. 11, pp. 2651–
2664, Nov 2013.

[3] Meng Yang, Lei Zhang, Xiangchu Feng, and David
Zhang, “Sparse representation based ﬁsher discrimina-
tion dictionary learning for image classiﬁcation,” Inter-
national Journal of Computer Vision, vol. 109, no. 3, pp.
209–232, 2014.

[4] Ashish Shrivastava, Vishal M. Patel, and Rama Chel-
lappa, “Non-linear dictionary learning with partially la-
beled data,” Pattern Recognition, vol. 48, no. 11, pp.
3283 C 3292, 2015.

[5] Liangyue Li, Sheng Li, and Yun Fu, “Learning low-rank
and discriminative dictionary for image classiﬁcation,”
Image and Vision Computing, vol. 32, no. 10, pp. 814 –
823, 2014.

[6] Long Ma, Chunheng Wang, Baihua Xiao, and Wen
Zhou,
“Sparse representation for face recognition
based on discriminative low-rank dictionary learning,”
2014 IEEE Conference on Computer Vision and Pattern
Recognition, pp. 2586–2593, 2012.

[7] Yi-Fu Hou, Zhan-Li Sun, Yan-Wen Chong, and Chun-
Hou Zheng, “Low-rank and eigenface based sparse rep-
resentation for face recognition,” PLoS ONE, vol. 9, no.
10, pp. e110318, 10 2014.

[8] T. Guha and R.K. Ward, “Learning sparse representa-
tions for human action recognition,” IEEE Transactions
on Pattern Analysis and Machine Intelligence, vol. 34,
no. 8, pp. 1576–1588, 2012.

[9] Sushma Bomma, Paolo Favaro, and Neil Robertson,
“Sparse representation based action and gesture recogni-
tion,” in 20th IEEE International Conference on Image
Processing (ICIP 2013), 2013, pp. 141–145.

[10] Zhiwu Lu and Yuxin Peng, “Latent semantic learning
with structured sparse representation for human action
recognition,” Pattern Recognition, vol. 46, no. 7, pp.
1799 – 1809, 2013.

[11] Jiaxin Cai, Xin Tang, and Guocan Feng,

“Learning
pose dictionary for human action recognition,” in 2014
22nd International Conference on Pattern Recognition
(ICPR). IEEE, 2014, pp. 381–386.

[12] Haoran Wang, Chunfeng Yuan, Weiming Hu, and
Changyin Sun,
“Supervised class-speciﬁc dictionary
learning for sparse modeling in action recognition,” Pat-
tern Recognition, vol. 45, no. 11, pp. 3902 – 3911, 2012.

[13] Alexandros Andre Chaaraoui, Pau Climent-Prez, and
Francisco Flrez-Revuelta, “Silhouette-based human ac-
tion recognition using sequences of key poses,” Pat-
tern Recognition Letters, vol. 34, no. 15, pp. 1799–1807,
2013.

[14] S. Cheema, A. Eweiwi, C. Thurau, and C. Bauck-
hage,
“Action recognition by learning discriminative
key poses,” in 2011 IEEE International Conference on
Computer Vision Workshops (ICCV Workshops), 2011,
pp. 1302–1309.

[15] Jiaxin Cai and Guocan Feng, “Human action recogni-
tion in the fractional fourier domain,” in 3rd IAPR Asian
Conference on Pattern Recognition (ACPR2015). IEEE,
2015, pp. 1–5.

[16] Jian Cheng, Haijun Liu, Feng Wang, Hongsheng Li, and
Ce Zhu, “Silhouette analysis for human action recogni-
tion based on supervised temporal t-sne and incremental
learning,” IEEE Transactions on Image Processing, vol.
24, no. 10, pp. 3203–3217, Oct 2015.

[17] H.M. Ozaktas, N. Erkaya, and M.A. Kutay, “Effect of
fractional fourier transformation on time-frequency dis-
tributions belonging to the cohen class,” Signal Process-
ing Letters, IEEE, vol. 3, no. 2, pp. 40–41, 1996.

[18] Jerome Friedman, Trevor Hastie, and Robert Tibshirani,
“Additive logistic regression: a statistical view of boost-
ing,” Annals of Statistics, vol. 28, pp. 2000, 1998.

[19] Lena Gorelick, Moshe Blank, Eli Shechtman, Michal
Irani, and Ronen Basri, “Actions as space-time shapes,”
IEEE Transactions on Pattern Analysis and Machine In-
telligence, vol. 29, no. 12, pp. 2247–2253, December
2007.

[20] S. Singh, S.A. Velastin, and H. Ragheb, “Muhavi: A
multicamera human action video dataset for the evalu-
ation of action recognition methods,” in 2010 Seventh
IEEE International Conference on Advanced Video and
Signal Based Surveillance (AVSS), 2010, pp. 48–55.

[21] M. Aharon, M. Elad, and A. Bruckstein, “K-svd: An
algorithm for designing overcomplete dictionaries for
sparse representation,” Signal Processing, IEEE Trans-
actions on, vol. 54, no. 11, pp. 4311–4322, 2006.

[22] Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad, “Or-
thogonal matching pursuit: Recursive function approxi-
mation with applications to wavelet decomposition,” in
Proceedings of the 27 th Annual Asilomar Conference
on Signals, Systems, and Computers, 1993, pp. 40–44.

